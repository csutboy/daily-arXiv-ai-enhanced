{"id": "2510.03338", "categories": ["stat.AP", "math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.03338", "abs": "https://arxiv.org/abs/2510.03338", "authors": ["Nathan Huet", "Ilaria Prosdocimi"], "title": "Robust and efficient estimation for the Generalized Extreme-Value distribution with application to flood frequency analysis in the UK", "comment": null, "summary": "A common approach for modeling extremes, such as peak flow or high\ntemperatures, is the three-parameter Generalized Extreme-Value distribution.\nThis is typically fit to extreme observations, here defined as maxima over\ndisjoint blocks. This results in limited sample sizes and consequently, the use\nof classic estimators, such as the maximum likelihood estimator, may be\ninappropriate, as they are highly sensitive to outliers. To address these\nlimitations, we propose a novel robust estimator based on the minimization of\nthe density power divergence, controlled by a tuning parameter $\\alpha$ that\nbalances robustness and efficiency. When $\\alpha = 0$, our estimator coincides\nwith the maximum likelihood estimator; when $\\alpha = 1$, it corresponds to the\n$L^2$ estimator, known for its robustness. We establish convenient theoretical\nproperties of the proposed estimator, including its asymptotic normality and\nthe boundedness of its influence function for $\\alpha > 0$. The practical\nefficiency of the method is demonstrated through empirical comparisons with the\nmaximum likelihood estimator and other robust alternatives. Finally, we\nillustrate its relevance in a case study on flood frequency analysis in the UK\nand provide some general conclusions in Section 6.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bc6\u5ea6\u529f\u7387\u6563\u5ea6\u6700\u5c0f\u5316\u7684\u7a33\u5065\u4f30\u8ba1\u5668\uff0c\u7528\u4e8e\u6781\u7aef\u503c\u5efa\u6a21\u4e2d\u7684\u5e7f\u4e49\u6781\u503c\u5206\u5e03\u53c2\u6570\u4f30\u8ba1\uff0c\u901a\u8fc7\u8c03\u8282\u53c2\u6570\u03b1\u5e73\u8861\u7a33\u5065\u6027\u548c\u6548\u7387", "motivation": "\u4f20\u7edf\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u5728\u6781\u7aef\u503c\u5efa\u6a21\u4e2d\u6837\u672c\u91cf\u6709\u9650\u65f6\u5bf9\u5f02\u5e38\u503c\u654f\u611f\uff0c\u9700\u8981\u66f4\u7a33\u5065\u7684\u4f30\u8ba1\u65b9\u6cd5", "method": "\u57fa\u4e8e\u5bc6\u5ea6\u529f\u7387\u6563\u5ea6\u6700\u5c0f\u5316\u7684\u7a33\u5065\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u8c03\u8282\u53c2\u6570\u03b1\u63a7\u5236\u7a33\u5065\u6027\uff08\u03b1=0\u65f6\u4e3aMLE\uff0c\u03b1=1\u65f6\u4e3aL2\u4f30\u8ba1\u5668\uff09", "result": "\u5efa\u7acb\u4e86\u4f30\u8ba1\u5668\u7684\u7406\u8bba\u6027\u8d28\uff08\u6e10\u8fd1\u6b63\u6001\u6027\u548c\u5f71\u54cd\u51fd\u6570\u6709\u754c\u6027\uff09\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u6bd4\u8f83\u548c\u6d2a\u6c34\u9891\u7387\u5206\u6790\u6848\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u63d0\u51fa\u7684\u7a33\u5065\u4f30\u8ba1\u5668\u5728\u6781\u7aef\u503c\u5efa\u6a21\u4e2d\u5177\u6709\u826f\u597d\u7684\u7406\u8bba\u6027\u8d28\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2510.03681", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.03681", "abs": "https://arxiv.org/abs/2510.03681", "authors": ["Suman Majumder", "Indranil Sahoo"], "title": "Bayesian Variable Selection for Censored Spatial Responses with Application to PFAS Concentrations in California", "comment": null, "summary": "Per- and polyfluoroalkyl substances (PFAS) are persistent environmental\npollutants of major public health concern due to their resistance to\ndegradation, widespread presence, and potential health risks. Analyzing PFAS in\ngroundwater is challenging due to left-censoring and strong spatial dependence.\nAlthough PFAS levels are influenced by sociodemographic, industrial, and\nenvironmental factors, the relative importance of these drivers remains\nunclear, highlighting the need for robust statistical tools to identify key\npredictors from a large candidate set. We present a Bayesian hierarchical\nframework that integrates censoring into a spatial process model via\napproximate Gaussian processes and employs a global-local shrinkage prior for\nhigh-dimensional variable selection. We evaluate three post-selection\nstrategies, namely, credible interval rules, shrinkage weight thresholds, and\nclustering-based inclusion and compare their performance in terms of predictive\naccuracy, censoring robustness, and variable selection stability through\ncross-validation. Applied to PFOS concentrations in California groundwater, the\nmodel identifies a concise, interpretable set of predictors, including\ndemographic composition, industrial facility counts, proximity to airports,\ntraffic density, and environmental features such as herbaceous cover and\nelevation. These findings demonstrate that the proposed approach delivers\nstable, interpretable inference in censored, spatial, high-dimensional\ncontexts, thereby offering actionable insights into the environmental and\nindustrial factors affecting PFAS concentrations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8d1d\u53f6\u65af\u5c42\u6b21\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u5730\u4e0b\u6c34\u4e2dPFAS\u6c61\u67d3\u7269\u7684\u9ad8\u7ef4\u53d8\u91cf\u9009\u62e9\u95ee\u9898\uff0c\u7ed3\u5408\u4e86\u7a7a\u95f4\u8fc7\u7a0b\u6a21\u578b\u548c\u5ba1\u67e5\u6570\u636e\u5904\u7406\u7684\u96c6\u6210\u65b9\u6cd5\u3002", "motivation": "PFAS\u662f\u6301\u4e45\u6027\u73af\u5883\u6c61\u67d3\u7269\uff0c\u5206\u6790\u5730\u4e0b\u6c34\u4e2dPFAS\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5b58\u5728\u5de6\u5ba1\u67e5\u548c\u5f3a\u7a7a\u95f4\u4f9d\u8d56\u6027\uff0c\u9700\u8981\u7a33\u5065\u7684\u7edf\u8ba1\u5de5\u5177\u4ece\u5927\u91cf\u5019\u9009\u9884\u6d4b\u56e0\u5b50\u4e2d\u8bc6\u522b\u5173\u952e\u9a71\u52a8\u56e0\u7d20\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u5c42\u6b21\u6846\u67b6\uff0c\u901a\u8fc7\u8fd1\u4f3c\u9ad8\u65af\u8fc7\u7a0b\u5c06\u5ba1\u67e5\u96c6\u6210\u5230\u7a7a\u95f4\u8fc7\u7a0b\u6a21\u578b\u4e2d\uff0c\u5e76\u4f7f\u7528\u5168\u5c40-\u5c40\u90e8\u6536\u7f29\u5148\u9a8c\u8fdb\u884c\u9ad8\u7ef4\u53d8\u91cf\u9009\u62e9\uff0c\u8bc4\u4f30\u4e86\u4e09\u79cd\u540e\u9009\u62e9\u7b56\u7565\u3002", "result": "\u5e94\u7528\u4e8e\u52a0\u5dde\u5730\u4e0b\u6c34\u4e2dPFOS\u6d53\u5ea6\u6570\u636e\uff0c\u6a21\u578b\u8bc6\u522b\u51fa\u4e00\u7ec4\u7b80\u6d01\u53ef\u89e3\u91ca\u7684\u9884\u6d4b\u56e0\u5b50\uff0c\u5305\u62ec\u4eba\u53e3\u6784\u6210\u3001\u5de5\u4e1a\u8bbe\u65bd\u6570\u91cf\u3001\u673a\u573a\u90bb\u8fd1\u5ea6\u3001\u4ea4\u901a\u5bc6\u5ea6\u4ee5\u53ca\u73af\u5883\u7279\u5f81\u5982\u8349\u672c\u8986\u76d6\u548c\u6d77\u62d4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5ba1\u67e5\u3001\u7a7a\u95f4\u3001\u9ad8\u7ef4\u80cc\u666f\u4e0b\u63d0\u4f9b\u4e86\u7a33\u5b9a\u53ef\u89e3\u91ca\u7684\u63a8\u65ad\uff0c\u4e3a\u5f71\u54cdPFAS\u6d53\u5ea6\u7684\u73af\u5883\u548c\u5de5\u4e1a\u56e0\u7d20\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002"}}
{"id": "2510.03730", "categories": ["stat.AP", "62P15"], "pdf": "https://arxiv.org/pdf/2510.03730", "abs": "https://arxiv.org/abs/2510.03730", "authors": ["Nathan A. Judd", "Amy V. Tansell", "Benjamin Costello", "Liam Leonard", "Jessica Woodhams", "Rowland G. Seymour"], "title": "Statistical Crime Linkage: Evaluating approaches within the Covenant for Using AI in Policing", "comment": "20 pages. Submitted", "summary": "Linking crimes by modus operandi has long been employed as an effective tool\nfor crime investigation. The standard statistical method that underpins\nstatistical crime linkage has been logistic regression. The simplicity and\ninterpretability of this approach has been seen as an advantage for law\nenforcement agencies using statistical crime linkage. In 2023, the National\nPolice Chiefs' Council published the Covenant for Using Artificial Intelligence\nin Policing designed to guide the development of novel methods for use within\npolicing. In this article, we investigate more statistical and machine learning\nmethods that could underpin crime linkage models. We investigate a range of\nmethods including regression-, sampling-, and machine learning-based techniques\nand evaluate them against the principles of Explainability and Transparency\nfrom the Covenant. We investigate our methods on a new data set on romance\nfraud in the UK, where 361 victims of fraud reported the behaviours and\ncharacteristics of the suspects involved in their case. We propose a sensitive,\nExplainable, and Transparent machine learning model for crime linkage and\ndemonstrate how this method could support crime linkage efforts by law\nenforcement agencies using a dataset of romance fraud with unknown linkage\nstatus.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7528\u4e8e\u72af\u7f6a\u5173\u8054\u7684\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7279\u522b\u5173\u6ce8\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u5ea6\uff0c\u5e76\u5728\u82f1\u56fd\u6d6a\u6f2b\u6b3a\u8bc8\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "motivation": "\u4f20\u7edf\u72af\u7f6a\u5173\u8054\u4e3b\u8981\u4f7f\u7528\u903b\u8f91\u56de\u5f52\uff0c\u4f46\u9700\u8981\u63a2\u7d22\u66f4\u591a\u7b26\u5408AI\u8b66\u52a1\u516c\u7ea6\u4e2d\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u5ea6\u539f\u5219\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u4e86\u56de\u5f52\u3001\u62bd\u6837\u548c\u673a\u5668\u5b66\u4e60\u7b49\u591a\u79cd\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u654f\u611f\u3001\u53ef\u89e3\u91ca\u4e14\u900f\u660e\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7528\u4e8e\u72af\u7f6a\u5173\u8054\u3002", "result": "\u5728361\u540d\u6d6a\u6f2b\u6b3a\u8bc8\u53d7\u5bb3\u8005\u7684\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u672a\u77e5\u5173\u8054\u72b6\u6001\u6570\u636e\u96c6\u4e0a\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u80fd\u591f\u652f\u6301\u6267\u6cd5\u673a\u6784\u7684\u72af\u7f6a\u5173\u8054\u5de5\u4f5c\uff0c\u540c\u65f6\u6ee1\u8db3\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u5ea6\u7684\u8981\u6c42\u3002"}}
{"id": "2510.03350", "categories": ["econ.GN", "q-fin.EC", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.03350", "abs": "https://arxiv.org/abs/2510.03350", "authors": ["Jason Godfrey"], "title": "How does course recommendation impact student outcomes? Examining directed self-placement with regression discontinuity analysis", "comment": null, "summary": "For many students, placement into developmental education becomes a\nself-fulfilling prophecy. Placing college students into developmental education\nsignificantly negatively impacts student attainment, student probability of\npassing, and college credits earned. To combat these negative effects, many\nuniversities are investigating alternative placement mechanisms. Could directed\nself-placement be an effective alternative mechanism? Do students who\nself-place suffer the same negative impacts from placement recommendations as\ntheir traditionally placed counterparts? This paper uses longitudinal data with\ncausal inference methods to examine whether directed self-placement has similar\nnegative impacts on student grades and pass rates as mandatory placement\nschema. We begin with an analysis of over 20,000 student placement records into\none of two different placement tracks for first-year writing. Longitudinal and\ninstitutional data allow us to control for characteristic variables such as\nstudent race, family income, and sex. The results of our regression\ndiscontinuity design show that directed self-placement does not negatively\nimpact student grades or pass rate. This may be an improvement for students who\nplace at or near the threshold for developmental/remedial education; However,\nclass, race, and gender-based statistical differences persist in the program\nat-large, demonstrating that placement technique plays only one part in\nbuilding a more equitable program.", "AI": {"tldr": "\u5b9a\u5411\u81ea\u6211\u5b89\u7f6e\u4e0d\u4f1a\u5bf9\u5b66\u751f\u7684\u6210\u7ee9\u548c\u901a\u8fc7\u7387\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u8fd9\u53ef\u80fd\u662f\u5bf9\u5904\u4e8e\u53d1\u5c55/\u8865\u4e60\u6559\u80b2\u95e8\u69db\u9644\u8fd1\u5b66\u751f\u7684\u4e00\u79cd\u6539\u8fdb\u3002", "motivation": "\u4f20\u7edf\u7684\u53d1\u5c55\u6027\u6559\u80b2\u5b89\u7f6e\u5bf9\u5b66\u751f\u7684\u5b66\u4e1a\u6210\u5c31\u3001\u901a\u8fc7\u6982\u7387\u548c\u83b7\u5f97\u5b66\u5206\u6709\u663e\u8457\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u8bb8\u591a\u5927\u5b66\u6b63\u5728\u7814\u7a76\u66ff\u4ee3\u7684\u5b89\u7f6e\u673a\u5236\u3002", "method": "\u4f7f\u7528\u7eb5\u5411\u6570\u636e\u548c\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u8d85\u8fc720,000\u540d\u5b66\u751f\u7684\u5b89\u7f6e\u8bb0\u5f55\uff0c\u63a7\u5236\u5b66\u751f\u79cd\u65cf\u3001\u5bb6\u5ead\u6536\u5165\u548c\u6027\u522b\u7b49\u7279\u5f81\u53d8\u91cf\uff0c\u91c7\u7528\u56de\u5f52\u65ad\u70b9\u8bbe\u8ba1\u3002", "result": "\u5b9a\u5411\u81ea\u6211\u5b89\u7f6e\u4e0d\u4f1a\u5bf9\u5b66\u751f\u7684\u6210\u7ee9\u6216\u901a\u8fc7\u7387\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "\u867d\u7136\u5b89\u7f6e\u6280\u672f\u53ea\u662f\u6784\u5efa\u66f4\u516c\u5e73\u9879\u76ee\u7684\u4e00\u90e8\u5206\uff0c\u4f46\u5b9a\u5411\u81ea\u6211\u5b89\u7f6e\u53ef\u80fd\u662f\u5bf9\u5904\u4e8e\u53d1\u5c55/\u8865\u4e60\u6559\u80b2\u95e8\u69db\u9644\u8fd1\u5b66\u751f\u7684\u4e00\u79cd\u6539\u8fdb\uff0c\u4f46\u73ed\u7ea7\u3001\u79cd\u65cf\u548c\u6027\u522b\u7684\u7edf\u8ba1\u5dee\u5f02\u5728\u6574\u4e2a\u9879\u76ee\u4e2d\u4ecd\u7136\u5b58\u5728\u3002"}}
{"id": "2510.03956", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2510.03956", "abs": "https://arxiv.org/abs/2510.03956", "authors": ["Robert S. Aviles", "Peter A. Beerel"], "title": "Optimizing Phase-Scheduling with Throughput Trade-offs in AQFP Digital Circuits", "comment": null, "summary": "Adiabatic Quantum-Flux-Parametron (AQFP) logic is a promising emerging\nsuperconducting technology for ultra-low power digital circuits, offering\norders of magnitude lower power consumption than CMOS. However, AQFP\nscalability is challenged by excessive buffer overhead due to path balancing\ntechnology constraints. Addressing this, recent AQFP works have proposed design\nsolutions to reduce path balancing overhead using phase-skipping and\nphase-alignment. Phase-skipping is a circuit-level technique that allows data\ntransfer between AQFP gates clocked with non-consecutive clock phases. In\ncontrast, phase-alignment is an architectural approach involving repeating\ninput patterns to allow data transfer between AQFP gates across multiples of\nfull clock cycles. While both techniques individually mitigate the area\noverhead of path-balancing, they have not yet been jointly explored. In this\nwork, we present the first clock phase scheduling algorithm that combines\nphase-skipping and phase-alignment. We first present a minimum area method that\non average, achieves a 25% area reduction compared to phase-skipping alone and\na 11% reduction compared to phase-alignment. We then extend the method to\nenforce a target throughput, enabling efficient area-performance trade-offs.\nWith our throughput constrained optimization, we achieve on average 6.8% area\nsavings with a 2.62x increased throughput compared to the state-of-the-art\nphase-aligned method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u7ed3\u5408\u76f8\u4f4d\u8df3\u8dc3\u548c\u76f8\u4f4d\u5bf9\u9f50\u7684\u65f6\u949f\u76f8\u4f4d\u8c03\u5ea6\u7b97\u6cd5\uff0c\u663e\u8457\u51cf\u5c11AQFP\u903b\u8f91\u4e2d\u7684\u8def\u5f84\u5e73\u8861\u5f00\u9500\uff0c\u5b9e\u73b0\u9762\u79ef\u548c\u6027\u80fd\u7684\u4f18\u5316\u3002", "motivation": "AQFP\u903b\u8f91\u867d\u7136\u529f\u8017\u6781\u4f4e\uff0c\u4f46\u8def\u5f84\u5e73\u8861\u6280\u672f\u7ea6\u675f\u5bfc\u81f4\u7f13\u51b2\u5668\u5f00\u9500\u8fc7\u5927\uff0c\u9650\u5236\u4e86\u5176\u53ef\u6269\u5c55\u6027\u3002\u73b0\u6709\u76f8\u4f4d\u8df3\u8dc3\u548c\u76f8\u4f4d\u5bf9\u9f50\u6280\u672f\u5355\u72ec\u4f7f\u7528\u80fd\u7f13\u89e3\u6b64\u95ee\u9898\uff0c\u4f46\u5c1a\u672a\u8054\u5408\u63a2\u7d22\u3002", "method": "\u5f00\u53d1\u4e86\u7ed3\u5408\u76f8\u4f4d\u8df3\u8dc3\u548c\u76f8\u4f4d\u5bf9\u9f50\u7684\u65f6\u949f\u76f8\u4f4d\u8c03\u5ea6\u7b97\u6cd5\uff0c\u5305\u62ec\u6700\u5c0f\u9762\u79ef\u65b9\u6cd5\u548c\u541e\u5410\u91cf\u7ea6\u675f\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u6700\u5c0f\u9762\u79ef\u65b9\u6cd5\u76f8\u6bd4\u5355\u72ec\u76f8\u4f4d\u8df3\u8dc3\u5e73\u5747\u51cf\u5c1125%\u9762\u79ef\uff0c\u76f8\u6bd4\u76f8\u4f4d\u5bf9\u9f50\u51cf\u5c1111%\u9762\u79ef\uff1b\u541e\u5410\u91cf\u7ea6\u675f\u4f18\u5316\u5e73\u5747\u8282\u77016.8%\u9762\u79ef\uff0c\u541e\u5410\u91cf\u63d0\u53472.62\u500d\u3002", "conclusion": "\u63d0\u51fa\u7684\u8054\u5408\u8c03\u5ea6\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86AQFP\u8def\u5f84\u5e73\u8861\u5f00\u9500\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9762\u79ef\u548c\u541e\u5410\u91cf\u7684\u663e\u8457\u4f18\u5316\uff0c\u4e3aAQFP\u7535\u8def\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04464", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.04464", "abs": "https://arxiv.org/abs/2510.04464", "authors": ["Tonghui Qi"], "title": "Identification in Auctions with Truncated Transaction Prices", "comment": null, "summary": "Many auction datasets with reserve prices do not include bids that fall below\nthe reserve. This paper establishes nonparametric identification results in\nfirst- and second-price auctions when transaction prices are truncated by a\nbinding reserve price under a range of information structures. In the simplest\ncase-where the number of potential bidders is fixed and known across all\nauctions-if only the transaction price is observed, the bidders' private-value\ndistribution is identified in second-price auctions but not in first-price\nauctions. Identification in first-price auctions can be achieved if either the\nnumber of active bidders (those whose bids exceed the reserve) or the number of\nauctions with no sales (all bids below the reserve) is observed. When the\nnumber of potential bidders varies across auctions and is unknown, the bidders'\nprivate-value distribution is identified in first-price auctions but not in\nsecond-price auctions, provided that both the transaction price and the number\nof active bidders are observed. Finally, I extend these results to auctions\nwith entry costs, which face a similar truncation issue when data on potential\nbidders who do not enter are missing.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u62cd\u5356\u6570\u636e\u56e0\u4fdd\u7559\u4ef7\u683c\u800c\u88ab\u622a\u65ad\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u975e\u53c2\u6570\u8bc6\u522b\u6295\u6807\u4eba\u7684\u79c1\u4eba\u4ef7\u503c\u5206\u5e03\uff0c\u9488\u5bf9\u7b2c\u4e00\u4ef7\u683c\u548c\u7b2c\u4e8c\u4ef7\u683c\u62cd\u5356\u5728\u4e0d\u540c\u4fe1\u606f\u7ed3\u6784\u4e0b\u7684\u8bc6\u522b\u95ee\u9898\u3002", "motivation": "\u8bb8\u591a\u62cd\u5356\u6570\u636e\u96c6\u7531\u4e8e\u4fdd\u7559\u4ef7\u683c\u7684\u5b58\u5728\uff0c\u53ea\u5305\u542b\u9ad8\u4e8e\u4fdd\u7559\u4ef7\u7684\u6295\u6807\uff0c\u5bfc\u81f4\u6570\u636e\u88ab\u622a\u65ad\u3002\u8fd9\u7ed9\u4f30\u8ba1\u6295\u6807\u4eba\u7684\u79c1\u4eba\u4ef7\u503c\u5206\u5e03\u5e26\u6765\u4e86\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u62cd\u5356\u673a\u5236\u548c\u4fe1\u606f\u7ed3\u6784\u4e0b\u3002", "method": "\u5efa\u7acb\u975e\u53c2\u6570\u8bc6\u522b\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790\u5728\u4e0d\u540c\u4fe1\u606f\u7ed3\u6784\u4e0b\uff08\u5982\u5df2\u77e5\u56fa\u5b9a\u6295\u6807\u4eba\u6570\u3001\u672a\u77e5\u53d8\u52a8\u6295\u6807\u4eba\u6570\u7b49\uff09\u7b2c\u4e00\u4ef7\u683c\u548c\u7b2c\u4e8c\u4ef7\u683c\u62cd\u5356\u7684\u8bc6\u522b\u6761\u4ef6\uff0c\u5305\u62ec\u662f\u5426\u89c2\u5bdf\u4ea4\u6613\u4ef7\u683c\u3001\u6d3b\u8dc3\u6295\u6807\u4eba\u6570\u6216\u65e0\u9500\u552e\u62cd\u5356\u6570\u91cf\u7b49\u53d8\u91cf\u3002", "result": "\u53d1\u73b0\u5728\u7b2c\u4e8c\u4ef7\u683c\u62cd\u5356\u4e2d\uff0c\u4ec5\u89c2\u5bdf\u4ea4\u6613\u4ef7\u683c\u5373\u53ef\u8bc6\u522b\u79c1\u4eba\u4ef7\u503c\u5206\u5e03\uff1b\u800c\u5728\u7b2c\u4e00\u4ef7\u683c\u62cd\u5356\u4e2d\u9700\u8981\u989d\u5916\u4fe1\u606f\uff08\u6d3b\u8dc3\u6295\u6807\u4eba\u6570\u6216\u65e0\u9500\u552e\u62cd\u5356\u6570\u91cf\uff09\u3002\u5f53\u6295\u6807\u4eba\u6570\u53d8\u52a8\u4e14\u672a\u77e5\u65f6\uff0c\u7b2c\u4e00\u4ef7\u683c\u62cd\u5356\u53ef\u8bc6\u522b\u800c\u7b2c\u4e8c\u4ef7\u683c\u62cd\u5356\u4e0d\u53ef\u8bc6\u522b\u3002", "conclusion": "\u62cd\u5356\u6570\u636e\u7684\u622a\u65ad\u95ee\u9898\u5728\u4e0d\u540c\u62cd\u5356\u673a\u5236\u4e0b\u7684\u8bc6\u522b\u8981\u6c42\u4e0d\u540c\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u5904\u7406\u4e0d\u5b8c\u6574\u62cd\u5356\u6570\u636e\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u6709\u8fdb\u5165\u6210\u672c\u7684\u62cd\u5356\u573a\u666f\u3002"}}
{"id": "2510.03482", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.03482", "abs": "https://arxiv.org/abs/2510.03482", "authors": ["Alex Bloedel", "Tommaso Denti", "Luciano Pomatto"], "title": "Modeling information acquisition via f-divergence and duality", "comment": null, "summary": "We introduce a new cost function over experiments, f-information, based on\nthe theory of multivariate statistical divergences, that generalizes Sims's\nclassic model of rational inattention as well as the class of\nposterior-separable cost functions. We characterize its behavioral predictions\nby deriving optimality conditions that extend those of Matejka and McKay (2015)\nand Caplin, Dean, and Leahy (2019) beyond mutual information. Using these\ntools, we study the implications of f-information in a number of canonical\ndecision problems. A strength of the framework is that it can be analyzed using\nfamiliar methods of microeconomics: convex duality and the Arrow-Pratt approach\nto expected utility.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u5143\u7edf\u8ba1\u6563\u5ea6\u7406\u8bba\u7684\u65b0\u5b9e\u9a8c\u6210\u672c\u51fd\u6570\u2014\u2014f-\u4fe1\u606f\uff0c\u5b83\u63a8\u5e7f\u4e86Sims\u7684\u7406\u6027\u758f\u5ffd\u7ecf\u5178\u6a21\u578b\u4ee5\u53ca\u540e\u9a8c\u53ef\u5206\u79bb\u6210\u672c\u51fd\u6570\u7c7b\u522b\u3002", "motivation": "\u6269\u5c55\u7406\u6027\u758f\u5ffd\u7406\u8bba\uff0c\u8d85\u8d8a\u4e92\u4fe1\u606f\u7684\u9650\u5236\uff0c\u63d0\u4f9b\u66f4\u4e00\u822c\u7684\u6210\u672c\u51fd\u6570\u6846\u67b6\u6765\u5206\u6790\u51b3\u7b56\u95ee\u9898\u3002", "method": "\u5229\u7528\u51f8\u5bf9\u5076\u548cArrow-Pratt\u671f\u671b\u6548\u7528\u65b9\u6cd5\u7b49\u5fae\u89c2\u7ecf\u6d4e\u5b66\u719f\u6089\u5de5\u5177\uff0c\u63a8\u5bfcf-\u4fe1\u606f\u7684\u6700\u4f18\u6027\u6761\u4ef6\u3002", "result": "\u5f97\u5230\u4e86\u63a8\u5e7fMatejka\u548cMcKay(2015)\u4ee5\u53caCaplin\u3001Dean\u548cLeahy(2019)\u6700\u4f18\u6027\u6761\u4ef6\u7684\u7ed3\u679c\uff0c\u5e76\u5728\u591a\u4e2a\u5178\u578b\u51b3\u7b56\u95ee\u9898\u4e2d\u5206\u6790\u4e86f-\u4fe1\u606f\u7684\u5f71\u54cd\u3002", "conclusion": "f-\u4fe1\u606f\u6846\u67b6\u4e3a\u5206\u6790\u7406\u6027\u758f\u5ffd\u548c\u51b3\u7b56\u95ee\u9898\u63d0\u4f9b\u4e86\u5f3a\u5927\u800c\u901a\u7528\u7684\u5de5\u5177\uff0c\u80fd\u591f\u4f7f\u7528\u5fae\u89c2\u7ecf\u6d4e\u5b66\u7684\u6807\u51c6\u65b9\u6cd5\u8fdb\u884c\u5206\u6790\u3002"}}
{"id": "2510.03240", "categories": ["cs.SI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2510.03240", "abs": "https://arxiv.org/abs/2510.03240", "authors": ["Hongbo Fang", "James Evans"], "title": "Generalization and the Rise of System-level Creativity in Science", "comment": "41 pages, 22 figures", "summary": "Innovation ecosystems require careful policy stewardship to drive sustained\nadvance in human health, welfare, security and prosperity. We develop new\nmeasures that reliably decompose the influence of innovations in terms of the\ndegree to which each represents a field-level foundation, an extension of\nfoundational work, or a generalization that synthesizes and modularizes\ncontributions from distant fields to catalyze combinatorial innovation. Using\n23 million scientific works, we demonstrate that while foundational and\nextensional work within fields has declined in recent years-a trend garnering\nmuch recent attention-generalizations across fields have increased and\naccelerated with the rise of the web, social media, and artificial\nintelligence, shifting the locus of innovation from within fields to across the\nsystem as a whole. We explore implications for science policy.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u65b0\u6307\u6807\u6765\u5206\u89e3\u521b\u65b0\u7684\u5f71\u54cd\u529b\uff0c\u53d1\u73b0\u867d\u7136\u9886\u57df\u5185\u57fa\u7840\u6027\u548c\u6269\u5c55\u6027\u5de5\u4f5c\u6709\u6240\u51cf\u5c11\uff0c\u4f46\u8de8\u9886\u57df\u7efc\u5408\u521b\u65b0\u5728\u589e\u52a0\uff0c\u521b\u65b0\u91cd\u5fc3\u6b63\u4ece\u9886\u57df\u5185\u8f6c\u5411\u6574\u4e2a\u7cfb\u7edf\u5c42\u9762\u3002", "motivation": "\u521b\u65b0\u751f\u6001\u7cfb\u7edf\u9700\u8981\u653f\u7b56\u5f15\u5bfc\u6765\u63a8\u52a8\u4eba\u7c7b\u5065\u5eb7\u3001\u798f\u5229\u3001\u5b89\u5168\u548c\u7e41\u8363\u7684\u6301\u7eed\u8fdb\u6b65\uff0c\u9700\u8981\u66f4\u597d\u5730\u7406\u89e3\u4e0d\u540c\u7c7b\u578b\u521b\u65b0\u7684\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u65b0\u6307\u6807\u6765\u53ef\u9760\u5206\u89e3\u521b\u65b0\u7684\u5f71\u54cd\u529b\uff0c\u5c06\u521b\u65b0\u5206\u4e3a\u9886\u57df\u57fa\u7840\u3001\u57fa\u7840\u5de5\u4f5c\u6269\u5c55\u3001\u4ee5\u53ca\u8de8\u9886\u57df\u7efc\u5408\u521b\u65b0\u4e09\u7c7b\uff0c\u4f7f\u75282300\u4e07\u7bc7\u79d1\u5b66\u6587\u732e\u8fdb\u884c\u5206\u6790\u3002", "result": "\u53d1\u73b0\u9886\u57df\u5185\u57fa\u7840\u6027\u548c\u6269\u5c55\u6027\u5de5\u4f5c\u5728\u51cf\u5c11\uff0c\u4f46\u8de8\u9886\u57df\u7efc\u5408\u521b\u65b0\u968f\u7740\u7f51\u7edc\u3001\u793e\u4ea4\u5a92\u4f53\u548c\u4eba\u5de5\u667a\u80fd\u7684\u5174\u8d77\u800c\u589e\u52a0\u548c\u52a0\u901f\uff0c\u521b\u65b0\u91cd\u5fc3\u4ece\u9886\u57df\u5185\u8f6c\u5411\u6574\u4e2a\u7cfb\u7edf\u3002", "conclusion": "\u521b\u65b0\u6a21\u5f0f\u6b63\u5728\u8f6c\u53d8\uff0c\u4ece\u9886\u57df\u5185\u521b\u65b0\u8f6c\u5411\u8de8\u7cfb\u7edf\u521b\u65b0\uff0c\u8fd9\u5bf9\u79d1\u5b66\u653f\u7b56\u5177\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2510.03321", "categories": ["cs.CY", "cs.SE", "K.3.2"], "pdf": "https://arxiv.org/pdf/2510.03321", "abs": "https://arxiv.org/abs/2510.03321", "authors": ["Ruzanna Chitchyan", "Niki Mahmoudi"], "title": "Embedding Sustainability in Software Engineering Curriculum: A Case Study", "comment": "11 pages", "summary": "Sustainability is increasingly recognized as a critical dimension of\nengineering education, yet its integration into Software Engineering curricula\nremains a challenge. This paper reports on a case study that examines how\nsustainability is being embedded across modules in the Software Engineering\nprogram at one university. The paper outlines the process through which\nacademics and students co-identified opportunities for integration, guided by\nthe five dimensions of the Sustainability Awareness Framework, targeted\ndiscussion questions, and good practice examples drawn from the Green Software\nFoundation patterns. The study highlights practical steps - including the use\nof frameworks, illustrative examples, student engagement, and iterative\nconsultative processes - that can support other institutions seeking to embed\nsustainability into their programs. We also discuss strategies for integrating\nsustainability into the Software Engineering curriculum and argue that such\nintegration is a necessary and urgent step to prepare Software Engineering\ngraduates as sustainability-aware professionals in our changing society.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u63a2\u8ba8\u4e86\u5982\u4f55\u5728\u8f6f\u4ef6\u5de5\u7a0b\u8bfe\u7a0b\u4e2d\u5d4c\u5165\u53ef\u6301\u7eed\u6027\uff0c\u4f7f\u7528\u53ef\u6301\u7eed\u6027\u610f\u8bc6\u6846\u67b6\u3001\u76ee\u6807\u8ba8\u8bba\u95ee\u9898\u548c\u7eff\u8272\u8f6f\u4ef6\u57fa\u91d1\u4f1a\u6a21\u5f0f\u6765\u6307\u5bfc\u5b66\u672f\u4eba\u5458\u548c\u5b66\u751f\u5171\u540c\u8bc6\u522b\u6574\u5408\u673a\u4f1a\u3002", "motivation": "\u53ef\u6301\u7eed\u6027\u65e5\u76ca\u88ab\u8ba4\u4e3a\u662f\u5de5\u7a0b\u6559\u80b2\u7684\u5173\u952e\u7ef4\u5ea6\uff0c\u4f46\u5c06\u5176\u6574\u5408\u5230\u8f6f\u4ef6\u5de5\u7a0b\u8bfe\u7a0b\u4e2d\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u91c7\u7528\u6848\u4f8b\u7814\u7a76\u65b9\u6cd5\uff0c\u5728\u4e00\u4e2a\u5927\u5b66\u7684\u8f6f\u4ef6\u5de5\u7a0b\u9879\u76ee\u4e2d\uff0c\u901a\u8fc7\u53ef\u6301\u7eed\u6027\u610f\u8bc6\u6846\u67b6\u7684\u4e94\u4e2a\u7ef4\u5ea6\u3001\u76ee\u6807\u8ba8\u8bba\u95ee\u9898\u548c\u7eff\u8272\u8f6f\u4ef6\u57fa\u91d1\u4f1a\u6a21\u5f0f\u7684\u597d\u5b9e\u8df5\u4f8b\u5b50\uff0c\u6307\u5bfc\u5b66\u672f\u4eba\u5458\u548c\u5b66\u751f\u5171\u540c\u8bc6\u522b\u6574\u5408\u673a\u4f1a\u3002", "result": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5b9e\u7528\u7684\u6b65\u9aa4\uff0c\u5305\u62ec\u4f7f\u7528\u6846\u67b6\u3001\u8bf4\u660e\u6027\u4f8b\u5b50\u3001\u5b66\u751f\u53c2\u4e0e\u548c\u8fed\u4ee3\u54a8\u8be2\u8fc7\u7a0b\uff0c\u8fd9\u4e9b\u53ef\u4ee5\u652f\u6301\u5176\u4ed6\u673a\u6784\u5c06\u53ef\u6301\u7eed\u6027\u5d4c\u5165\u5176\u8bfe\u7a0b\u4e2d\u3002", "conclusion": "\u5c06\u53ef\u6301\u7eed\u6027\u6574\u5408\u5230\u8f6f\u4ef6\u5de5\u7a0b\u8bfe\u7a0b\u4e2d\u662f\u5fc5\u8981\u4e14\u7d27\u8feb\u7684\u6b65\u9aa4\uff0c\u4ee5\u57f9\u517b\u8f6f\u4ef6\u5de5\u7a0b\u6bd5\u4e1a\u751f\u6210\u4e3a\u6211\u4eec\u53d8\u5316\u793e\u4f1a\u4e2d\u5177\u6709\u53ef\u6301\u7eed\u6027\u610f\u8bc6\u7684\u4e13\u4e1a\u4eba\u58eb\u3002"}}
{"id": "2510.03285", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03285", "abs": "https://arxiv.org/abs/2510.03285", "authors": ["Su Kara", "Fazle Faisal", "Suman Nath"], "title": "WAREX: Web Agent Reliability Evaluation on Existing Benchmarks", "comment": null, "summary": "Recent advances in browser-based LLM agents have shown promise for automating\ntasks ranging from simple form filling to hotel booking or online shopping.\nCurrent benchmarks measure agent performance in controlled environments, such\nas containers or stable networks, where websites behave deterministically.\nHowever, in the real world, users access websites over networks and HTTPS\nconnections that introduce instability from multiple sources: client-side,\nserver-side issues or broader system failures. Moreover, live websites are\nprone to web attacks such Cross-Site Scripting, as well as general site\nmodifications which can cause unexpected or malicious pop-ups or improper\nfunctionality. To address this gap, we present WAREX: Web Agent Reliability\nEvaluation on Existing Benchmarks. We measure the impact of WAREX across three\npopular benchmarks: WebArena, WebVoyager, and REAL. Our experiments show that\nintroducing WAREX leads to significant drops in task success rates,\nhighlighting the limited robustness of state-of-the-art agents.", "AI": {"tldr": "WAREX\u662f\u4e00\u4e2a\u8bc4\u4f30\u6d4f\u89c8\u5668LLM\u4ee3\u7406\u5728\u771f\u5b9e\u7f51\u7edc\u73af\u5883\u53ef\u9760\u6027\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5f15\u5165\u7f51\u7edc\u4e0d\u7a33\u5b9a\u6027\u548c\u7f51\u7ad9\u653b\u51fb\u7b49\u73b0\u5b9e\u56e0\u7d20\uff0c\u53d1\u73b0\u5f53\u524d\u6700\u5148\u8fdb\u4ee3\u7406\u7684\u9c81\u68d2\u6027\u6709\u9650\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u53d7\u63a7\u73af\u5883\u4e2d\u8bc4\u4f30LLM\u4ee3\u7406\u6027\u80fd\uff0c\u4f46\u771f\u5b9e\u4e16\u754c\u5b58\u5728\u7f51\u7edc\u4e0d\u7a33\u5b9a\u3001HTTPS\u8fde\u63a5\u95ee\u9898\u548c\u7f51\u7ad9\u653b\u51fb\u7b49\u6311\u6218\uff0c\u9700\u8981\u8bc4\u4f30\u4ee3\u7406\u5728\u8fd9\u4e9b\u73b0\u5b9e\u6761\u4ef6\u4e0b\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51faWAREX\u6846\u67b6\uff0c\u5728\u4e09\u4e2a\u6d41\u884c\u57fa\u51c6\u6d4b\u8bd5\uff08WebArena\u3001WebVoyager\u3001REAL\uff09\u4e2d\u5f15\u5165\u7f51\u7edc\u4e0d\u7a33\u5b9a\u6027\u548c\u7f51\u7ad9\u653b\u51fb\u7b49\u73b0\u5b9e\u56e0\u7d20\u6765\u8bc4\u4f30\u4ee3\u7406\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5f15\u5165WAREX\u540e\u4efb\u52a1\u6210\u529f\u7387\u663e\u8457\u4e0b\u964d\uff0c\u8868\u660e\u5f53\u524d\u6700\u5148\u8fdb\u4ee3\u7406\u5728\u9762\u5bf9\u73b0\u5b9e\u7f51\u7edc\u73af\u5883\u65f6\u9c81\u68d2\u6027\u6709\u9650\u3002", "conclusion": "WAREX\u63ed\u793a\u4e86\u73b0\u6709LLM\u4ee3\u7406\u5728\u771f\u5b9e\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u5728\u8bc4\u4f30\u4ee3\u7406\u6027\u80fd\u65f6\u8003\u8651\u73b0\u5b9e\u6761\u4ef6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.03241", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03241", "abs": "https://arxiv.org/abs/2510.03241", "authors": ["Hanyang He", "John Harlim", "Daning Huang", "Yan Li"], "title": "Efficient MPC-Based Energy Management System for Secure and Cost-Effective Microgrid Operations", "comment": null, "summary": "Model predictive control (MPC)-based energy management systems (EMS) are\nessential for ensuring optimal, secure, and stable operation in microgrids with\nhigh penetrations of distributed energy resources. However, due to the high\ncomputational cost for the decision-making, the conventional MPC-based EMS\ntypically adopts a simplified integrated-bus power balance model. While this\nsimplification is effective for small networks, large-scale systems require a\nmore detailed branch flow model to account for the increased impact of grid\npower losses and security constraints. This work proposes an efficient and\nreliable MPC-based EMS that incorporates power-loss effects and grid-security\nconstraints. %, while adaptively shaping the battery power profile in response\nto online renewable inputs, achieving reduced operational costs. It enhances\nsystem reliability, reduces operational costs, and shows strong potential for\nonline implementation due to its reduced computational effort. Specifically, a\nsecond-order cone program (SOCP) branch flow relaxation is integrated into the\nconstraint set, yielding a convex formulation that guarantees globally optimal\nsolutions with high computational efficiency. Owing to the radial topology of\nthe microgrid, this relaxation is practically tight, ensuring equivalence to\nthe original problem. Building on this foundation, an online demand response\n(DR) module is designed to further reduce the operation cost through peak\nshaving. To the best of our knowledge, no prior MPC-EMS framework has\nsimultaneously modeled losses and security constraints while coordinating\nflexible loads within a unified architecture. The developed framework enables\nsecure operation with effective peak shaving and reduced total cost. The\neffectiveness of the proposed method is validated on 10-bus, 18-bus, and 33-bus\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684MPC\u80fd\u91cf\u7ba1\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e8c\u9636\u9525\u89c4\u5212\u5206\u652f\u6d41\u677e\u5f1b\u6765\u8003\u8651\u529f\u7387\u635f\u8017\u548c\u7535\u7f51\u5b89\u5168\u7ea6\u675f\uff0c\u7ed3\u5408\u5728\u7ebf\u9700\u6c42\u54cd\u5e94\u5b9e\u73b0\u524a\u5cf0\u964d\u672c\u3002", "motivation": "\u4f20\u7edfMPC\u80fd\u91cf\u7ba1\u7406\u7cfb\u7edf\u91c7\u7528\u7b80\u5316\u7684\u529f\u7387\u5e73\u8861\u6a21\u578b\uff0c\u5728\u5927\u89c4\u6a21\u7cfb\u7edf\u4e2d\u65e0\u6cd5\u51c6\u786e\u8003\u8651\u7535\u7f51\u529f\u7387\u635f\u8017\u548c\u5b89\u5168\u7ea6\u675f\u7684\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u8be6\u7ec6\u7684\u6a21\u578b\u6765\u4fdd\u8bc1\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u7ecf\u6d4e\u6027\u3002", "method": "\u5c06\u4e8c\u9636\u9525\u89c4\u5212\u5206\u652f\u6d41\u677e\u5f1b\u96c6\u6210\u5230\u7ea6\u675f\u96c6\u4e2d\uff0c\u5f62\u6210\u51f8\u4f18\u5316\u95ee\u9898\uff1b\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u5728\u7ebf\u9700\u6c42\u54cd\u5e94\u6a21\u5757\u8fdb\u884c\u524a\u5cf0\uff1b\u5728\u5f84\u5411\u62d3\u6251\u5fae\u7535\u7f51\u4e2d\u4fdd\u8bc1\u677e\u5f1b\u7684\u7d27\u81f4\u6027\u3002", "result": "\u572810\u300118\u300133\u603b\u7ebf\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\u6709\u6548\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u8fd0\u884c\u3001\u6709\u6548\u524a\u5cf0\u548c\u603b\u6210\u672c\u964d\u4f4e\uff0c\u8ba1\u7b97\u6548\u7387\u9ad8\u9002\u5408\u5728\u7ebf\u5b9e\u65bd\u3002", "conclusion": "\u8be5\u6846\u67b6\u9996\u6b21\u5728\u7edf\u4e00\u67b6\u6784\u4e2d\u540c\u65f6\u5efa\u6a21\u635f\u8017\u548c\u5b89\u5168\u7ea6\u675f\u5e76\u534f\u8c03\u67d4\u6027\u8d1f\u8377\uff0c\u4e3a\u5927\u89c4\u6a21\u5fae\u7535\u7f51\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684MPC\u80fd\u91cf\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03342", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03342", "abs": "https://arxiv.org/abs/2510.03342", "authors": ["Abbas Abdolmaleki", "Saminda Abeyruwan", "Joshua Ainslie", "Jean-Baptiste Alayrac", "Montserrat Gonzalez Arenas", "Ashwin Balakrishna", "Nathan Batchelor", "Alex Bewley", "Jeff Bingham", "Michael Bloesch", "Konstantinos Bousmalis", "Philemon Brakel", "Anthony Brohan", "Thomas Buschmann", "Arunkumar Byravan", "Serkan Cabi", "Ken Caluwaerts", "Federico Casarini", "Christine Chan", "Oscar Chang", "London Chappellet-Volpini", "Jose Enrique Chen", "Xi Chen", "Hao-Tien Lewis Chiang", "Krzysztof Choromanski", "Adrian Collister", "David B. D'Ambrosio", "Sudeep Dasari", "Todor Davchev", "Meet Kirankumar Dave", "Coline Devin", "Norman Di Palo", "Tianli Ding", "Carl Doersch", "Adil Dostmohamed", "Yilun Du", "Debidatta Dwibedi", "Sathish Thoppay Egambaram", "Michael Elabd", "Tom Erez", "Xiaolin Fang", "Claudio Fantacci", "Cody Fong", "Erik Frey", "Chuyuan Fu", "Ruiqi Gao", "Marissa Giustina", "Keerthana Gopalakrishnan", "Laura Graesser", "Oliver Groth", "Agrim Gupta", "Roland Hafner", "Steven Hansen", "Leonard Hasenclever", "Sam Haves", "Nicolas Heess", "Brandon Hernaez", "Alex Hofer", "Jasmine Hsu", "Lu Huang", "Sandy H. Huang", "Atil Iscen", "Mithun George Jacob", "Deepali Jain", "Sally Jesmonth", "Abhishek Jindal", "Ryan Julian", "Dmitry Kalashnikov", "M. Emre Karagozler", "Stefani Karp", "Matija Kecman", "J. Chase Kew", "Donnie Kim", "Frank Kim", "Junkyung Kim", "Thomas Kipf", "Sean Kirmani", "Ksenia Konyushkova", "Li Yang Ku", "Yuheng Kuang", "Thomas Lampe", "Antoine Laurens", "Tuan Anh Le", "Isabel Leal", "Alex X. Lee", "Tsang-Wei Edward Lee", "Guy Lever", "Jacky Liang", "Li-Heng Lin", "Fangchen Liu", "Shangbang Long", "Caden Lu", "Sharath Maddineni", "Anirudha Majumdar", "Kevis-Kokitsi Maninis", "Andrew Marmon", "Sergio Martinez", "Assaf Hurwitz Michaely", "Niko Milonopoulos", "Joss Moore", "Robert Moreno", "Michael Neunert", "Francesco Nori", "Joy Ortiz", "Kenneth Oslund", "Carolina Parada", "Emilio Parisotto", "Amaris Paryag", "Acorn Pooley", "Thomas Power", "Alessio Quaglino", "Haroon Qureshi", "Rajkumar Vasudeva Raju", "Helen Ran", "Dushyant Rao", "Kanishka Rao", "Isaac Reid", "David Rendleman", "Krista Reymann", "Miguel Rivas", "Francesco Romano", "Yulia Rubanova", "Peter Pastor Sampedro", "Pannag R Sanketi", "Dhruv Shah", "Mohit Sharma", "Kathryn Shea", "Mohit Shridhar", "Charles Shu", "Vikas Sindhwani", "Sumeet Singh", "Radu Soricut", "Rachel Sterneck", "Ian Storz", "Razvan Surdulescu", "Jie Tan", "Jonathan Tompson", "Saran Tunyasuvunakool", "Jake Varley", "Grace Vesom", "Giulia Vezzani", "Maria Bauza Villalonga", "Oriol Vinyals", "Ren\u00e9 Wagner", "Ayzaan Wahid", "Stefan Welker", "Paul Wohlhart", "Chengda Wu", "Markus Wulfmeier", "Fei Xia", "Ted Xiao", "Annie Xie", "Jinyu Xie", "Peng Xu", "Sichun Xu", "Ying Xu", "Zhuo Xu", "Jimmy Yan", "Sherry Yang", "Skye Yang", "Yuxiang Yang", "Hiu Hong Yu", "Wenhao Yu", "Wentao Yuan", "Yuan Yuan", "Jingwei Zhang", "Tingnan Zhang", "Zhiyuan Zhang", "Allan Zhou", "Guangyao Zhou", "Yuxiang Zhou"], "title": "Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer", "comment": null, "summary": "General-purpose robots need a deep understanding of the physical world,\nadvanced reasoning, and general and dexterous control. This report introduces\nthe latest generation of the Gemini Robotics model family: Gemini Robotics 1.5,\na multi-embodiment Vision-Language-Action (VLA) model, and Gemini Robotics-ER\n1.5, a state-of-the-art Embodied Reasoning (ER) model. We are bringing together\nthree major innovations. First, Gemini Robotics 1.5 features a novel\narchitecture and a Motion Transfer (MT) mechanism, which enables it to learn\nfrom heterogeneous, multi-embodiment robot data and makes the VLA more general.\nSecond, Gemini Robotics 1.5 interleaves actions with a multi-level internal\nreasoning process in natural language. This enables the robot to \"think before\nacting\" and notably improves its ability to decompose and execute complex,\nmulti-step tasks, and also makes the robot's behavior more interpretable to the\nuser. Third, Gemini Robotics-ER 1.5 establishes a new state-of-the-art for\nembodied reasoning, i.e., for reasoning capabilities that are critical for\nrobots, such as visual and spatial understanding, task planning, and progress\nestimation. Together, this family of models takes us a step towards an era of\nphysical agents-enabling robots to perceive, think and then act so they can\nsolve complex multi-step tasks.", "AI": {"tldr": "Gemini Robotics 1.5\u662f\u4e00\u4e2a\u591a\u5177\u8eab\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff0c\u901a\u8fc7\u8fd0\u52a8\u8f6c\u79fb\u673a\u5236\u5b66\u4e60\u5f02\u6784\u673a\u5668\u4eba\u6570\u636e\uff0c\u7ed3\u5408\u591a\u7ea7\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u5b9e\u73b0\"\u5148\u601d\u8003\u540e\u884c\u52a8\"\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u591a\u6b65\u4efb\u52a1\u7684\u6267\u884c\u80fd\u529b\u3002", "motivation": "\u901a\u7528\u673a\u5668\u4eba\u9700\u8981\u6df1\u5165\u7406\u89e3\u7269\u7406\u4e16\u754c\u3001\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\u548c\u901a\u7528\u7075\u5de7\u63a7\u5236\u80fd\u529b\uff0c\u8fd9\u662f\u5b9e\u73b0\u7269\u7406\u667a\u80fd\u4f53\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u91c7\u7528\u65b0\u9896\u67b6\u6784\u548c\u8fd0\u52a8\u8f6c\u79fb\u673a\u5236\u5b66\u4e60\u5f02\u6784\u591a\u5177\u8eab\u673a\u5668\u4eba\u6570\u636e\uff1b\u5728\u81ea\u7136\u8bed\u8a00\u4e2d\u4ea4\u7ec7\u52a8\u4f5c\u4e0e\u591a\u7ea7\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\uff1bGemini Robotics-ER 1.5\u4e13\u6ce8\u4e8e\u5177\u8eab\u63a8\u7406\u80fd\u529b\u3002", "result": "Gemini Robotics 1.5\u80fd\u591f\u5206\u89e3\u548c\u6267\u884c\u590d\u6742\u591a\u6b65\u4efb\u52a1\uff0c\u4f7f\u673a\u5668\u4eba\u884c\u4e3a\u5bf9\u7528\u6237\u66f4\u53ef\u89e3\u91ca\uff1bGemini Robotics-ER 1.5\u5728\u5177\u8eab\u63a8\u7406\u65b9\u9762\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "\u8fd9\u4e00\u7cfb\u5217\u6a21\u578b\u5411\u7269\u7406\u667a\u80fd\u4f53\u65f6\u4ee3\u8fc8\u8fdb\u4e86\u4e00\u6b65\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u611f\u77e5\u3001\u601d\u8003\u7136\u540e\u884c\u52a8\uff0c\u4ece\u800c\u89e3\u51b3\u590d\u6742\u591a\u6b65\u4efb\u52a1\u3002"}}
{"id": "2510.04535", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2510.04535", "abs": "https://arxiv.org/abs/2510.04535", "authors": ["Moritz Brunion", "Navaneeth Kunhi Purayil", "Francesco Dell'Atti", "Sebastian Lam", "Refik Bilgic", "Mehdi Tahoori", "Luca Benini", "Julien Ryckaert"], "title": "CMOS 2.0 - Redefining the Future of Scaling", "comment": "8 pages, 5 figures, to be published in ICCAD 2025", "summary": "We propose to revisit the functional scaling paradigm by capitalizing on two\nrecent developments in advanced chip manufacturing, namely 3D wafer bonding and\nbackside processing. This approach leads to the proposal of the CMOS 2.0\nplatform. The main idea is to shift the CMOS roadmap from geometric scaling to\nfine-grain heterogeneous 3D stacking of specialized active device layers to\nachieve the ultimate Power-Performance-Area and Cost gains expected from future\ntechnology generations. However, the efficient utilization of such a platform\nrequires devising architectures that can optimally map onto this technology, as\nwell as the EDA infrastructure that supports it. We also discuss reliability\nconcerns and eventual mitigation approaches. This paper provides pointers into\nthe major disruptions we expect in the design of systems in CMOS 2.0 moving\nforward.", "AI": {"tldr": "\u63d0\u51fa\u4e86CMOS 2.0\u5e73\u53f0\uff0c\u901a\u8fc73D\u6676\u5706\u952e\u5408\u548c\u80cc\u9762\u5904\u7406\u6280\u672f\uff0c\u4ece\u51e0\u4f55\u7f29\u653e\u8f6c\u5411\u7ec6\u7c92\u5ea6\u5f02\u67843D\u5806\u53e0\uff0c\u4ee5\u5b9e\u73b0\u529f\u7387-\u6027\u80fd-\u9762\u79ef-\u6210\u672c\u7684\u4f18\u5316\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6\u529f\u80fd\u7f29\u653e\u8303\u5f0f\uff0c\u5229\u7528\u5148\u8fdb\u76843D\u6676\u5706\u952e\u5408\u548c\u80cc\u9762\u5904\u7406\u6280\u672f\uff0c\u514b\u670d\u4f20\u7edfCMOS\u51e0\u4f55\u7f29\u653e\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u7cfb\u7edf\u8bbe\u8ba1\u3002", "method": "\u91c7\u75283D\u6676\u5706\u952e\u5408\u548c\u80cc\u9762\u5904\u7406\u6280\u672f\uff0c\u6784\u5efa\u7ec6\u7c92\u5ea6\u5f02\u67843D\u5806\u53e0\u7684CMOS 2.0\u5e73\u53f0\uff0c\u9700\u8981\u5f00\u53d1\u76f8\u5e94\u7684\u67b6\u6784\u548cEDA\u57fa\u7840\u8bbe\u65bd\u3002", "result": "\u63d0\u51fa\u4e86CMOS 2.0\u5e73\u53f0\u6982\u5ff5\uff0c\u80fd\u591f\u5b9e\u73b0\u529f\u7387-\u6027\u80fd-\u9762\u79ef-\u6210\u672c\u7684\u663e\u8457\u63d0\u5347\uff0c\u5e76\u8ba8\u8bba\u4e86\u53ef\u9760\u6027\u95ee\u9898\u548c\u7f13\u89e3\u65b9\u6cd5\u3002", "conclusion": "CMOS 2.0\u5e73\u53f0\u4ee3\u8868\u4e86\u7cfb\u7edf\u8bbe\u8ba1\u7684\u91cd\u5927\u53d8\u9769\uff0c\u4ece\u51e0\u4f55\u7f29\u653e\u8f6c\u5411\u529f\u80fd\u7f29\u653e\uff0c\u9700\u8981\u65b0\u7684\u67b6\u6784\u548cEDA\u5de5\u5177\u652f\u6301\u3002"}}
{"id": "2510.05007", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.05007", "abs": "https://arxiv.org/abs/2510.05007", "authors": ["Giovanni Cerulli", "Francesco Caracciolo"], "title": "Risk-Adjusted Policy Learning and the Social Cost of Uncertainty: Theory and Evidence from CAP evaluation", "comment": null, "summary": "This paper develops a risk-adjusted alternative to standard optimal policy\nlearning (OPL) for observational data by importing Roy's (1952) safety-first\nprinciple into the treatment assignment problem. We formalize a welfare\nfunctional that maximizes the probability that outcomes exceed a socially\nrequired threshold and show that the associated pointwise optimal rule ranks\ntreatments by the ratio of conditional means to conditional standard\ndeviations. We implement the framework using microdata from the Italian Farm\nAccountancy Data Network to evaluate the allocation of subsidies under the EU\nCommon Agricultural Policy. Empirically, risk-adjusted optimal policies\nsystematically dominate the realized allocation across specifications, while\nrisk aversion lowers overall welfare relative to the risk-neutral benchmark,\nmaking transparent the social cost of insurance against uncertainty. The\nresults illustrate how safety-first OPL provides an implementable,\ninterpretable tool for risk-sensitive policy design, quantifying the\nefficiency-insurance trade-off that policymakers face when outcomes are\nvolatile.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u98ce\u9669\u8c03\u6574\u7684\u6700\u4f18\u653f\u7b56\u5b66\u4e60\u65b9\u6cd5\uff0c\u57fa\u4e8eRoy\u7684\u5b89\u5168\u7b2c\u4e00\u539f\u5219\uff0c\u901a\u8fc7\u6700\u5927\u5316\u7ed3\u679c\u8d85\u8fc7\u793e\u4f1a\u8981\u6c42\u9608\u503c\u7684\u6982\u7387\u6765\u5236\u5b9a\u98ce\u9669\u654f\u611f\u7684\u653f\u7b56\u5206\u914d\u89c4\u5219\u3002", "motivation": "\u5c06Roy(1952)\u7684\u5b89\u5168\u7b2c\u4e00\u539f\u5219\u5f15\u5165\u89c2\u5bdf\u6570\u636e\u7684\u653f\u7b56\u5b66\u4e60\u95ee\u9898\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u5728\u7ed3\u679c\u6ce2\u52a8\u65f6\u5904\u7406\u6548\u7387\u4e0e\u4fdd\u9669\u6743\u8861\u7684\u53ef\u5b9e\u65bd\u5de5\u5177\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u798f\u5229\u51fd\u6570\u6765\u6700\u5927\u5316\u7ed3\u679c\u8d85\u8fc7\u793e\u4f1a\u9608\u503c\u6982\u7387\uff0c\u63a8\u5bfc\u51fa\u6309\u6761\u4ef6\u5747\u503c\u4e0e\u6761\u4ef6\u6807\u51c6\u5dee\u6bd4\u7387\u6392\u5e8f\u7684\u70b9\u6700\u4f18\u89c4\u5219\uff0c\u5e76\u4f7f\u7528\u610f\u5927\u5229\u519c\u573a\u6570\u636e\u5b9e\u65bd\u8be5\u6846\u67b6\u3002", "result": "\u98ce\u9669\u8c03\u6574\u6700\u4f18\u653f\u7b56\u5728\u4e0d\u540c\u8bbe\u5b9a\u4e0b\u5747\u4f18\u4e8e\u5b9e\u9645\u5206\u914d\uff0c\u4f46\u98ce\u9669\u89c4\u907f\u4f1a\u964d\u4f4e\u76f8\u5bf9\u4e8e\u98ce\u9669\u4e2d\u6027\u57fa\u51c6\u7684\u603b\u4f53\u798f\u5229\uff0c\u63ed\u793a\u4e86\u4e0d\u786e\u5b9a\u6027\u4fdd\u9669\u7684\u793e\u4f1a\u6210\u672c\u3002", "conclusion": "\u5b89\u5168\u7b2c\u4e00OPL\u4e3a\u98ce\u9669\u654f\u611f\u653f\u7b56\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53ef\u5b9e\u65bd\u3001\u53ef\u89e3\u91ca\u7684\u5de5\u5177\uff0c\u91cf\u5316\u4e86\u653f\u7b56\u5236\u5b9a\u8005\u5728\u7ed3\u679c\u6ce2\u52a8\u65f6\u9762\u4e34\u7684\u6548\u7387-\u4fdd\u9669\u6743\u8861\u3002"}}
{"id": "2510.03658", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.03658", "abs": "https://arxiv.org/abs/2510.03658", "authors": ["Selidji Caroline Tossou"], "title": "Who benefits the most? Direct and indirect effects of a free cesarean section policy in Benin", "comment": "Working Paper", "summary": "This paper evaluates the causal effect of the access to Benin's free cesarean\nsection policy on females and their children. I use a large sample of\nDemographic and Health Surveys (DHS) for West African countries and analyze how\nthe exemption of the cesarean section user fees for females in Benin directly\nimpacts maternal and infant mortality, family size decisions, and labor market\nparticipation. I use a Difference in Differences approach and find that having\naccess to the free cesarean section policy significantly reduces the number of\nstillbirths and infant mortality by 0.0855 (a 18.79 percentage change). Second,\nfor the surviving children, I find that access to the free cesarean section\nincreases the likelihood of maternal mortality by 0.00465 (a 5.21 percentage\nchange). The policy is effective at reducing infant mortality and saving the\nnewborn. However, it harms the mother's health which translates to lower\nfertility after the first birth and decreased maternal labor supply post-birth.", "AI": {"tldr": "\u8d1d\u5b81\u514d\u8d39\u5256\u8179\u4ea7\u653f\u7b56\u8bc4\u4f30\uff1a\u663e\u8457\u964d\u4f4e\u6b7b\u4ea7\u548c\u5a74\u513f\u6b7b\u4ea1\u738718.79%\uff0c\u4f46\u589e\u52a0\u5b55\u4ea7\u5987\u6b7b\u4ea1\u73875.21%\uff0c\u5e76\u5bfc\u81f4\u751f\u80b2\u7387\u4e0b\u964d\u548c\u4ea7\u540e\u52b3\u52a8\u529b\u4f9b\u5e94\u51cf\u5c11", "motivation": "\u8bc4\u4f30\u8d1d\u5b81\u514d\u8d39\u5256\u8179\u4ea7\u653f\u7b56\u5bf9\u5973\u6027\u548c\u513f\u7ae5\u7684\u56e0\u679c\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5bf9\u5b55\u4ea7\u5987\u548c\u5a74\u513f\u6b7b\u4ea1\u7387\u3001\u5bb6\u5ead\u89c4\u6a21\u51b3\u7b56\u4ee5\u53ca\u52b3\u52a8\u529b\u5e02\u573a\u53c2\u4e0e\u7684\u5f71\u54cd", "method": "\u4f7f\u7528\u897f\u975e\u56fd\u5bb6\u4eba\u53e3\u4e0e\u5065\u5eb7\u8c03\u67e5(DHS)\u5927\u6837\u672c\u6570\u636e\uff0c\u91c7\u7528\u53cc\u91cd\u5dee\u5206\u6cd5\u5206\u6790\u5256\u8179\u4ea7\u7528\u6237\u8d39\u7528\u8c41\u514d\u653f\u7b56\u7684\u6548\u679c", "result": "\u514d\u8d39\u5256\u8179\u4ea7\u653f\u7b56\u663e\u8457\u51cf\u5c11\u6b7b\u4ea7\u548c\u5a74\u513f\u6b7b\u4ea1\u73870.0855(18.79%)\uff0c\u4f46\u589e\u52a0\u5b55\u4ea7\u5987\u6b7b\u4ea1\u73870.00465(5.21%)\uff0c\u5e76\u5bfc\u81f4\u751f\u80b2\u7387\u4e0b\u964d\u548c\u4ea7\u540e\u52b3\u52a8\u529b\u4f9b\u5e94\u51cf\u5c11", "conclusion": "\u653f\u7b56\u5728\u964d\u4f4e\u5a74\u513f\u6b7b\u4ea1\u7387\u548c\u62ef\u6551\u65b0\u751f\u513f\u65b9\u9762\u6709\u6548\uff0c\u4f46\u635f\u5bb3\u6bcd\u4eb2\u5065\u5eb7\uff0c\u5bfc\u81f4\u9996\u6b21\u751f\u80b2\u540e\u751f\u80b2\u7387\u4e0b\u964d\u548c\u4ea7\u540e\u52b3\u52a8\u529b\u4f9b\u5e94\u51cf\u5c11"}}
{"id": "2510.03661", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.03661", "abs": "https://arxiv.org/abs/2510.03661", "authors": ["Ran Gu", "Enhui Ding", "Shigui Ma"], "title": "An analysis of government subsidy policies in vaccine supply chain: Innovation, Production, or Consumption?", "comment": null, "summary": "Vaccines play a crucial role in the prevention and control of infectious\ndiseases. However, the vaccine supply chain faces numerous challenges that\nhinder its efficiency. To address these challenges and enhance public health\noutcomes, many governments provide subsidies to support the vaccine supply\nchain. This study analyzes a government-subsidized, three-tier vaccine supply\nchain within a continuous-time differential game framework. The model\nincorporates dynamic system equations that account for both vaccine quality and\nmanufacturer goodwill. The research explores the effectiveness and\ncharacteristics of different government subsidy strategies, considering factors\nsuch as price sensitivity, and provides actionable managerial insights. Key\nfindings from the analysis and numerical simulations include the following:\nFirst, from a long-term perspective, proportional subsidies for technological\ninvestments emerge as a more strategic approach, in contrast to the short-term\nfocus of volume-based subsidies. Second, when the public is highly sensitive to\nvaccine prices and individual vaccination benefits closely align with\ngovernment objectives, a volume-based subsidy policy becomes preferable.\nFinally, the integration of blockchain technology positively impacts the\nvaccine supply chain, particularly by improving vaccine quality and enhancing\nthe profitability of manufacturers in the later stages of production.", "AI": {"tldr": "\u672c\u7814\u7a76\u5728\u8fde\u7eed\u65f6\u95f4\u5fae\u5206\u535a\u5f08\u6846\u67b6\u4e0b\u5206\u6790\u653f\u5e9c\u8865\u8d34\u7684\u4e09\u7ea7\u75ab\u82d7\u4f9b\u5e94\u94fe\uff0c\u63a2\u8ba8\u4e0d\u540c\u8865\u8d34\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u6280\u672f\u6295\u8d44\u6bd4\u4f8b\u8865\u8d34\u5728\u957f\u671f\u66f4\u5177\u6218\u7565\u6027\uff0c\u800c\u4ef7\u683c\u654f\u611f\u5ea6\u9ad8\u65f6\u6570\u91cf\u8865\u8d34\u66f4\u4f18\uff0c\u533a\u5757\u94fe\u6280\u672f\u80fd\u63d0\u5347\u75ab\u82d7\u8d28\u91cf\u548c\u5236\u9020\u5546\u540e\u671f\u5229\u6da6\u3002", "motivation": "\u75ab\u82d7\u4f9b\u5e94\u94fe\u9762\u4e34\u8bf8\u591a\u6548\u7387\u6311\u6218\uff0c\u653f\u5e9c\u901a\u8fc7\u8865\u8d34\u652f\u6301\u75ab\u82d7\u4f9b\u5e94\u94fe\u4ee5\u6539\u5584\u516c\u5171\u536b\u751f\u6210\u679c\uff0c\u9700\u8981\u5206\u6790\u4e0d\u540c\u8865\u8d34\u7b56\u7565\u7684\u6709\u6548\u6027\u548c\u7279\u70b9\u3002", "method": "\u91c7\u7528\u8fde\u7eed\u65f6\u95f4\u5fae\u5206\u535a\u5f08\u6846\u67b6\uff0c\u5efa\u7acb\u5305\u542b\u75ab\u82d7\u8d28\u91cf\u548c\u5236\u9020\u5546\u5546\u8a89\u7684\u52a8\u6001\u7cfb\u7edf\u65b9\u7a0b\uff0c\u5206\u6790\u4e0d\u540c\u653f\u5e9c\u8865\u8d34\u7b56\u7565\uff0c\u5e76\u8fdb\u884c\u6570\u503c\u6a21\u62df\u3002", "result": "\u6280\u672f\u6295\u8d44\u6bd4\u4f8b\u8865\u8d34\u5728\u957f\u671f\u66f4\u5177\u6218\u7565\u6027\uff1b\u5f53\u516c\u4f17\u5bf9\u75ab\u82d7\u4ef7\u683c\u9ad8\u5ea6\u654f\u611f\u4e14\u4e2a\u4eba\u63a5\u79cd\u6536\u76ca\u4e0e\u653f\u5e9c\u76ee\u6807\u4e00\u81f4\u65f6\uff0c\u6570\u91cf\u8865\u8d34\u653f\u7b56\u66f4\u4f18\uff1b\u533a\u5757\u94fe\u6280\u672f\u80fd\u63d0\u5347\u75ab\u82d7\u8d28\u91cf\u548c\u5236\u9020\u5546\u540e\u671f\u76c8\u5229\u80fd\u529b\u3002", "conclusion": "\u653f\u5e9c\u5e94\u6839\u636e\u4e0d\u540c\u60c5\u5883\u9009\u62e9\u5408\u9002\u7684\u8865\u8d34\u7b56\u7565\uff0c\u6280\u672f\u6295\u8d44\u8865\u8d34\u9002\u5408\u957f\u671f\u53d1\u5c55\uff0c\u6570\u91cf\u8865\u8d34\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u66f4\u6709\u6548\uff0c\u533a\u5757\u94fe\u6280\u672f\u5bf9\u75ab\u82d7\u4f9b\u5e94\u94fe\u6709\u79ef\u6781\u5f71\u54cd\u3002"}}
{"id": "2510.03899", "categories": ["cs.SI", "cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03899", "abs": "https://arxiv.org/abs/2510.03899", "authors": ["Lutz Oettershagen", "Othon Michail"], "title": "Fair Minimum Labeling: Efficient Temporal Network Activations for Reachability and Equity", "comment": "Accepted at NeurIPS 2025", "summary": "Balancing resource efficiency and fairness is critical in networked systems\nthat support modern learning applications. We introduce the Fair Minimum\nLabeling (FML) problem: the task of designing a minimum-cost temporal edge\nactivation plan that ensures each group of nodes in a network has sufficient\naccess to a designated target set, according to specified coverage\nrequirements. FML captures key trade-offs in systems where edge activations\nincur resource costs and equitable access is essential, such as distributed\ndata collection, update dissemination in edge-cloud systems, and fair service\nrestoration in critical infrastructure. We show that FML is NP-hard and\n$\\Omega(\\log |V|)$-hard to approximate, and we present probabilistic\napproximation algorithms that match this bound, achieving the best possible\nguarantee for the activation cost. We demonstrate the practical utility of FML\nin a fair multi-source data aggregation task for training a shared model.\nEmpirical results show that FML enforces group-level fairness with\nsubstantially lower activation cost than baseline heuristics, underscoring its\npotential for building resource-efficient, equitable temporal reachability in\nlearning-integrated networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u516c\u5e73\u6700\u5c0f\u6807\u8bb0\uff08FML\uff09\u95ee\u9898\uff0c\u65e8\u5728\u8bbe\u8ba1\u6700\u5c0f\u6210\u672c\u7684\u65f6\u5e8f\u8fb9\u6fc0\u6d3b\u8ba1\u5212\uff0c\u786e\u4fdd\u7f51\u7edc\u4e2d\u6bcf\u4e2a\u8282\u70b9\u7ec4\u90fd\u80fd\u516c\u5e73\u8bbf\u95ee\u76ee\u6807\u96c6\uff0c\u5e73\u8861\u8d44\u6e90\u6548\u7387\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u5728\u652f\u6301\u73b0\u4ee3\u5b66\u4e60\u5e94\u7528\u7684\u7f51\u7edc\u7cfb\u7edf\u4e2d\uff0c\u5e73\u8861\u8d44\u6e90\u6548\u7387\u548c\u516c\u5e73\u6027\u81f3\u5173\u91cd\u8981\u3002FML\u95ee\u9898\u6355\u6349\u4e86\u5728\u8fb9\u7f18\u6fc0\u6d3b\u4ea7\u751f\u8d44\u6e90\u6210\u672c\u4e14\u9700\u8981\u516c\u5e73\u8bbf\u95ee\u7684\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u6743\u8861\u3002", "method": "\u8bc1\u660e\u4e86FML\u95ee\u9898\u662fNP\u96be\u4e14\u8fd1\u4f3c\u96be\u5ea6\u4e3a\u03a9(log|V|)\uff0c\u63d0\u51fa\u4e86\u6982\u7387\u8fd1\u4f3c\u7b97\u6cd5\u6765\u5339\u914d\u8fd9\u4e2a\u754c\u9650\uff0c\u5b9e\u73b0\u6fc0\u6d3b\u6210\u672c\u7684\u6700\u4f73\u53ef\u80fd\u4fdd\u8bc1\u3002", "result": "\u5728\u516c\u5e73\u591a\u6e90\u6570\u636e\u805a\u5408\u4efb\u52a1\u4e2d\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cFML\u80fd\u591f\u4ee5\u663e\u8457\u4f4e\u4e8e\u57fa\u51c6\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u6fc0\u6d3b\u6210\u672c\u5f3a\u5236\u6267\u884c\u7ec4\u7ea7\u516c\u5e73\u6027\u3002", "conclusion": "FML\u5728\u6784\u5efa\u5b66\u4e60\u96c6\u6210\u7f51\u7edc\u4e2d\u8d44\u6e90\u9ad8\u6548\u3001\u516c\u5e73\u7684\u65f6\u5e8f\u53ef\u8fbe\u6027\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2510.03329", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.03329", "abs": "https://arxiv.org/abs/2510.03329", "authors": ["Michael A Grasso", "Alexandra Rogalski", "Naveed Farrukh", "Anantaa Kotal", "Enrique Calleros"], "title": "When Patients Go to \"Dr. Google\" Before They Go to the Emergency Department", "comment": null, "summary": "Approximately one-third of adults search the internet for health information\nbefore visiting an emergency department (ED), with 75% encountering inaccurate\ncontent. This study examines how such searches influence patient care. We\nconducted an observational study of ED visits over a 12-month period, surveying\n214 of 576 patients about pre-ED internet use. Data on demographics,\ncomorbidities, acuity, orders, prescriptions, and dispositions were extracted.\nPatients who searched were typically younger, healthier, and more educated.\nMost used a general search engine to ask symptom-related questions. Compared to\nnon-searchers, they were less likely to receive lab tests (RR 0.78, p=0.053),\nimaging (RR 0.75, p=0.094), medications (RR 0.67, p=0.038), or admission (RR\n0.68, p=0.175). They were more likely to leave against medical advice (RR 1.67,\np=0.067) and receive opioids (RR 1.56, p=0.151). Findings suggest inaccurate\nhealth information may contribute to mismatched expectations and altered care\ndelivery.", "AI": {"tldr": "\u7ea6\u4e09\u5206\u4e4b\u4e00\u6210\u5e74\u4eba\u5728\u6025\u8bca\u5c31\u8bca\u524d\u4f1a\u641c\u7d22\u5065\u5eb7\u4fe1\u606f\uff0c\u5176\u4e2d75%\u9047\u5230\u4e0d\u51c6\u786e\u5185\u5bb9\u3002\u7814\u7a76\u53d1\u73b0\u8fd9\u7c7b\u641c\u7d22\u4f1a\u5f71\u54cd\u60a3\u8005\u62a4\u7406\uff0c\u641c\u7d22\u8005\u901a\u5e38\u66f4\u5e74\u8f7b\u3001\u66f4\u5065\u5eb7\u3001\u6559\u80b2\u7a0b\u5ea6\u66f4\u9ad8\uff0c\u4ed6\u4eec\u63a5\u53d7\u68c0\u67e5\u3001\u836f\u7269\u548c\u4f4f\u9662\u7684\u53ef\u80fd\u6027\u66f4\u4f4e\uff0c\u4f46\u66f4\u53ef\u80fd\u64c5\u81ea\u79bb\u9662\u548c\u83b7\u5f97\u963f\u7247\u7c7b\u836f\u7269\u3002", "motivation": "\u4e86\u89e3\u4e92\u8054\u7f51\u5065\u5eb7\u4fe1\u606f\u641c\u7d22\u5982\u4f55\u5f71\u54cd\u6025\u8bca\u60a3\u8005\u7684\u62a4\u7406\u8fc7\u7a0b\u548c\u7ed3\u679c\uff0c\u7279\u522b\u662f\u8003\u8651\u5230\u5927\u91cf\u60a3\u8005\u9047\u5230\u4e0d\u51c6\u786e\u4fe1\u606f\u7684\u60c5\u51b5\u3002", "method": "\u5bf912\u4e2a\u6708\u5185576\u540d\u6025\u8bca\u60a3\u8005\u4e2d\u7684214\u540d\u8fdb\u884c\u89c2\u5bdf\u6027\u7814\u7a76\uff0c\u8c03\u67e5\u6025\u8bca\u524d\u7684\u4e92\u8054\u7f51\u4f7f\u7528\u60c5\u51b5\uff0c\u63d0\u53d6\u4eba\u53e3\u7edf\u8ba1\u5b66\u3001\u5408\u5e76\u75c7\u3001\u75c5\u60c5\u4e25\u91cd\u7a0b\u5ea6\u3001\u533b\u5631\u3001\u5904\u65b9\u548c\u5904\u7f6e\u7b49\u6570\u636e\u3002", "result": "\u641c\u7d22\u8005\u63a5\u53d7\u5b9e\u9a8c\u5ba4\u68c0\u67e5\uff08RR 0.78\uff09\u3001\u5f71\u50cf\u5b66\u68c0\u67e5\uff08RR 0.75\uff09\u3001\u836f\u7269\u6cbb\u7597\uff08RR 0.67\uff09\u548c\u4f4f\u9662\uff08RR 0.68\uff09\u7684\u53ef\u80fd\u6027\u66f4\u4f4e\uff0c\u4f46\u66f4\u53ef\u80fd\u64c5\u81ea\u79bb\u9662\uff08RR 1.67\uff09\u548c\u83b7\u5f97\u963f\u7247\u7c7b\u836f\u7269\uff08RR 1.56\uff09\u3002", "conclusion": "\u4e0d\u51c6\u786e\u7684\u5065\u5eb7\u4fe1\u606f\u53ef\u80fd\u5bfc\u81f4\u60a3\u8005\u671f\u671b\u4e0e\u5b9e\u9645\u60c5\u51b5\u4e0d\u5339\u914d\uff0c\u4ece\u800c\u6539\u53d8\u62a4\u7406\u63d0\u4f9b\u65b9\u5f0f\u3002"}}
{"id": "2510.03377", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03377", "abs": "https://arxiv.org/abs/2510.03377", "authors": ["Ahmed Missaoui", "Cemalettin Ozturk", "Barry O'Sullivan"], "title": "Refined Iterated Pareto Greedy for Energy-aware Hybrid Flowshop Scheduling with Blocking Constraints", "comment": null, "summary": "The scarcity of non-renewable energy sources, geopolitical problems in its\nsupply, increasing prices, and the impact of climate change, force the global\neconomy to develop more energy-efficient solutions for their operations. The\nManufacturing sector is not excluded from this challenge as one of the largest\nconsumers of energy. Energy-efficient scheduling is a method that attracts\nmanufacturing companies to reduce their consumption as it can be quickly\ndeployed and can show impact immediately. In this study, the hybrid flow shop\nscheduling problem with blocking constraint (BHFS) is investigated in which we\nseek to minimize the latest completion time (i.e. makespan) and overall energy\nconsumption, a typical manufacturing setting across many industries from\nautomotive to pharmaceutical. Energy consumption and the latest completion time\nof customer orders are usually conflicting objectives. Therefore, we first\nformulate the problem as a novel multi-objective mixed integer programming\n(MIP) model and propose an augmented epsilon-constraint method for finding the\nPareto-optimal solutions. Also, an effective multi-objective metaheuristic\nalgorithm. Refined Iterated Pareto Greedy (RIPG), is developed to solve large\ninstances in reasonable time. Our proposed methods are benchmarked using small,\nmedium, and large-size instances to evaluate their efficiency. Two well-known\nalgorithms are adopted for comparing our novel approaches. The computational\nresults show the effectiveness of our method.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9488\u5bf9\u5e26\u6709\u963b\u585e\u7ea6\u675f\u7684\u6df7\u5408\u6d41\u6c34\u8f66\u95f4\u8c03\u5ea6\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u5236\u9020\u5468\u671f\u548c\u80fd\u6e90\u6d88\u8017\uff0c\u5e76\u5f00\u53d1\u4e86\u6709\u6548\u7684\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u6765\u89e3\u51b3\u5927\u89c4\u6a21\u5b9e\u4f8b\u3002", "motivation": "\u4e0d\u53ef\u518d\u751f\u80fd\u6e90\u7a00\u7f3a\u3001\u5730\u7f18\u653f\u6cbb\u95ee\u9898\u3001\u4ef7\u683c\u4e0a\u6da8\u548c\u6c14\u5019\u53d8\u5316\u5f71\u54cd\u8feb\u4f7f\u5236\u9020\u4e1a\u5f00\u53d1\u66f4\u8282\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5236\u9020\u4e1a\u4f5c\u4e3a\u6700\u5927\u7684\u80fd\u6e90\u6d88\u8d39\u8005\u4e4b\u4e00\uff0c\u9700\u8981\u80fd\u6e90\u9ad8\u6548\u8c03\u5ea6\u6765\u5feb\u901f\u964d\u4f4e\u80fd\u8017\u3002", "method": "\u9996\u5148\u6784\u5efa\u4e86\u591a\u76ee\u6807\u6df7\u5408\u6574\u6570\u89c4\u5212\u6a21\u578b\uff0c\u91c7\u7528\u589e\u5f3a\u7684\u03b5\u7ea6\u675f\u65b9\u6cd5\u5bfb\u627e\u5e15\u7d2f\u6258\u6700\u4f18\u89e3\uff0c\u5e76\u5f00\u53d1\u4e86\u6539\u8fdb\u7684\u8fed\u4ee3\u5e15\u7d2f\u6258\u8d2a\u5a6a\u7b97\u6cd5\u6765\u5904\u7406\u5927\u89c4\u6a21\u5b9e\u4f8b\u3002", "result": "\u901a\u8fc7\u5c0f\u3001\u4e2d\u3001\u5927\u89c4\u6a21\u5b9e\u4f8b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e0e\u4e24\u79cd\u77e5\u540d\u7b97\u6cd5\u6bd4\u8f83\uff0c\u8ba1\u7b97\u7ed3\u679c\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u5177\u6709\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\u548c\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u6df7\u5408\u6d41\u6c34\u8f66\u95f4\u8c03\u5ea6\u4e2d\u7684\u80fd\u6e90\u6548\u7387\u548c\u5236\u9020\u5468\u671f\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u5236\u9020\u4e1a\u8282\u80fd\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.03300", "categories": ["cs.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03300", "abs": "https://arxiv.org/abs/2510.03300", "authors": ["Shradha Bavalatti", "Yash Kangralkar", "Santosh Pattar", "Veena P Badiger"], "title": "Adaptive Cruise Control in Autonomous Vehicles: Challenges, Gaps, Comprehensive Review, and, Future Directions", "comment": null, "summary": "The development of Autonomous Vehicles (AVs) has redefined the way of\ntransportation by eliminating the need for human intervention in driving. This\nrevolution is fueled by rapid advancements in adaptive cruise control (ACC),\nwhich make AVs capable of interpreting their surroundings and responding\nintelligently. While AVs offer significant advantages, such as enhanced safety\nand improved traffic efficiency, they also face several challenges that need to\nbe addressed. Existing survey papers often lack a comprehensive analysis of\nthese challenges and their potential solutions. Our paper stands out by\nmeticulously identifying these gaps in current ACC research and offering\nimpactful future directions to guide researchers in designing next-generation\nACC systems. Our survey provides a detailed and systematic review, addressing\nthe limitations of previous studies and proposing innovative approaches to\nachieve sustainable and fault-resilient urban transportation.", "AI": {"tldr": "\u672c\u6587\u5bf9\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u81ea\u9002\u5e94\u5de1\u822a\u63a7\u5236(ACC)\u7814\u7a76\u8fdb\u884c\u4e86\u7cfb\u7edf\u7efc\u8ff0\uff0c\u8bc6\u522b\u4e86\u73b0\u6709\u7814\u7a76\u7684\u4e0d\u8db3\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u7efc\u8ff0\u8bba\u6587\u7f3a\u4e4f\u5bf9ACC\u6311\u6218\u53ca\u5176\u89e3\u51b3\u65b9\u6848\u7684\u5168\u9762\u5206\u6790\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u4e0b\u4e00\u4ee3ACC\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u7efc\u8ff0\u65b9\u6cd5\uff0c\u8be6\u7ec6\u5206\u6790\u5f53\u524dACC\u7814\u7a76\u7684\u5c40\u9650\u6027\uff0c\u8bc6\u522b\u7814\u7a76\u7a7a\u767d\u5e76\u63d0\u51fa\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u63d0\u4f9b\u4e86\u5bf9ACC\u6311\u6218\u7684\u6df1\u5165\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u5b9e\u73b0\u53ef\u6301\u7eed\u548c\u5bb9\u9519\u57ce\u5e02\u4ea4\u901a\u7684\u521b\u65b0\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\u4e3aACC\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u548c\u672a\u6765\u65b9\u5411\uff0c\u6709\u52a9\u4e8e\u8bbe\u8ba1\u66f4\u5b89\u5168\u3001\u9ad8\u6548\u7684\u4e0b\u4e00\u4ee3ACC\u7cfb\u7edf\u3002"}}
{"id": "2510.03457", "categories": ["cs.RO", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2510.03457", "abs": "https://arxiv.org/abs/2510.03457", "authors": ["Jianfeng Lin", "Tianyu Wang", "Baxi Chong", "Matthew Fernandez", "Zhaochen Xu", "Daniel I. Goldman"], "title": "Optimal swimming with body compliance in an overdamped medium", "comment": null, "summary": "Elongate animals and robots use undulatory body waves to locomote through\ndiverse environments. Geometric mechanics provides a framework to model and\noptimize such systems in highly damped environments, connecting a prescribed\nshape change pattern (gait) with locomotion displacement. However, existing\napproaches assume precise execution of prescribed gaits, whereas in practice\nenvironmental interactions with compliant bodies of animals or robots\nfrequently perturb the realized trajectories. In this work, we extend geometric\nmechanics to predict locomotor performance and search for optimal swimming\nstrategy of compliant undulators. We introduce a compliant extension of\nPurcell's three-link swimmer by incorporating series-connected springs at the\njoints. Body dynamics are derived with resistive force theory. Geometric\nmechanics is incorporated into movement prediction and into an optimization\nframework that identifies strategies for controlling compliant swimmers to\nachieve maximal displacement. We validate our framework on a physical\ncable-driven three-link limbless robot, and demonstrate accurate prediction and\noptimization of locomotor performance under varied programmed, state-dependent\ncompliance in a granular medium. Our results establish a systematic\nphysics-based approach for modeling and controlling compliant swimming\nlocomotion, highlighting compliance as a design feature that can be exploited\nfor robust movement in homogeneous and heterogeneous environments.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u51e0\u4f55\u529b\u5b66\u7406\u8bba\uff0c\u7528\u4e8e\u9884\u6d4b\u548c\u4f18\u5316\u67d4\u6027\u6ce2\u52a8\u6e38\u6cf3\u673a\u5668\u4eba\u7684\u8fd0\u52a8\u6027\u80fd\uff0c\u901a\u8fc7\u5f15\u5165\u5173\u8282\u5f39\u7c27\u7684\u67d4\u6027\u4e09\u8fde\u6746\u6e38\u6cf3\u5668\u6a21\u578b\uff0c\u5728\u9897\u7c92\u4ecb\u8d28\u4e2d\u9a8c\u8bc1\u4e86\u51c6\u786e\u9884\u6d4b\u548c\u4f18\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u51e0\u4f55\u529b\u5b66\u65b9\u6cd5\u5047\u8bbe\u7cbe\u786e\u6267\u884c\u9884\u8bbe\u6b65\u6001\uff0c\u4f46\u5b9e\u9645\u73af\u5883\u4e2d\u67d4\u6027\u4f53\u4e0e\u73af\u5883\u76f8\u4e92\u4f5c\u7528\u4f1a\u6270\u52a8\u5b9e\u9645\u8f68\u8ff9\uff0c\u9700\u8981\u6269\u5c55\u7406\u8bba\u6765\u5904\u7406\u67d4\u6027\u6ce2\u52a8\u6e38\u6cf3\u5668\u7684\u8fd0\u52a8\u63a7\u5236\u95ee\u9898\u3002", "method": "\u5728Purcell\u4e09\u8fde\u6746\u6e38\u6cf3\u5668\u57fa\u7840\u4e0a\u5f15\u5165\u4e32\u8054\u5f39\u7c27\u6784\u5efa\u67d4\u6027\u6a21\u578b\uff0c\u7ed3\u5408\u963b\u529b\u7406\u8bba\u63a8\u5bfc\u8eab\u4f53\u52a8\u529b\u5b66\uff0c\u5c06\u51e0\u4f55\u529b\u5b66\u878d\u5165\u8fd0\u52a8\u9884\u6d4b\u548c\u4f18\u5316\u6846\u67b6\uff0c\u5bfb\u627e\u5b9e\u73b0\u6700\u5927\u4f4d\u79fb\u7684\u63a7\u5236\u7b56\u7565\u3002", "result": "\u5728\u7269\u7406\u7535\u7f06\u9a71\u52a8\u7684\u4e09\u8fde\u6746\u65e0\u80a2\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\uff0c\u5728\u9897\u7c92\u4ecb\u8d28\u4e2d\u51c6\u786e\u9884\u6d4b\u548c\u4f18\u5316\u4e86\u4e0d\u540c\u7f16\u7a0b\u72b6\u6001\u76f8\u5173\u67d4\u987a\u6027\u4e0b\u7684\u8fd0\u52a8\u6027\u80fd\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4e00\u79cd\u7cfb\u7edf\u7684\u57fa\u4e8e\u7269\u7406\u7684\u65b9\u6cd5\u6765\u5efa\u6a21\u548c\u63a7\u5236\u67d4\u6027\u6e38\u6cf3\u8fd0\u52a8\uff0c\u5f3a\u8c03\u67d4\u987a\u6027\u53ef\u4ee5\u4f5c\u4e3a\u5728\u5747\u5300\u548c\u975e\u5747\u5300\u73af\u5883\u4e2d\u5b9e\u73b0\u7a33\u5065\u8fd0\u52a8\u7684\u8bbe\u8ba1\u7279\u5f81\u3002"}}
{"id": "2510.03668", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.03668", "abs": "https://arxiv.org/abs/2510.03668", "authors": ["Selidji Caroline Tossou"], "title": "Labor Market Reforms, Flexibility, and Employment Transitions Across Formal and Informal Sectors", "comment": "Working Paper", "summary": "In this paper, I investigate the 2017 labor market reform in Benin, which\nreduced firing costs and allowed firms to renew short-term contracts\nindefinitely. Using micro-data from the Harmonized Household Living Standards\nSurveys and a two-way fixed effect approach with nearby countries as the\ncontrol group, I assess the reform's impact on employment, worker tenure,\ncontract types, and wages. My empirical results reveal a 2.6 percentage point\n(24.5 percent) increase in formal sector employment and a 2.8 percentage point\n(3.2 percent) reduction in informal employment. Formal sector tenure decreased\nby 0.23 months for short-term contract workers, reflecting higher turnover,\nwhile long-term contract tenure increased by 0.15 months. The likelihood of\nsecuring a permanent contract rose by 23.2 percentage points (41.6 percent) in\nthe formal sector, indicating that firms used long-term contracts to retain\nhigh-productivity workers. Wages in the formal sector increased by 33.6 USD per\nmonth on average, with workers on short-term contracts experiencing a wage\nincrease of 19.6 USD and those on long-term contracts seeing an increase of\n23.4 USD. I complement these findings with a theoretical job search model,\nwhich explains the mechanisms through which lowered firing costs affected firm\nhiring decisions, market tightness, and the sorting of workers across sectors.\nThis study provides robust evidence of labor market reallocation and highlights\nthe complex trade-offs between flexibility, employment stability, and wages in\na developing country context.", "AI": {"tldr": "\u7814\u7a76\u8d1d\u5b812017\u5e74\u52b3\u52a8\u529b\u5e02\u573a\u6539\u9769\u7684\u5f71\u54cd\uff0c\u8be5\u6539\u9769\u964d\u4f4e\u4e86\u88c1\u5458\u6210\u672c\u5e76\u5141\u8bb8\u65e0\u9650\u671f\u7eed\u7b7e\u77ed\u671f\u5408\u540c\u3002\u7814\u7a76\u53d1\u73b0\u6539\u9769\u589e\u52a0\u4e86\u6b63\u89c4\u90e8\u95e8\u5c31\u4e1a\u3001\u63d0\u9ad8\u4e86\u6c38\u4e45\u5408\u540c\u6bd4\u4f8b\u548c\u5de5\u8d44\u6c34\u5e73\uff0c\u4f46\u4e5f\u5bfc\u81f4\u4e86\u77ed\u671f\u5408\u540c\u5de5\u4eba\u7684\u66f4\u9ad8\u6d41\u52a8\u7387\u3002", "motivation": "\u8bc4\u4f30\u53d1\u5c55\u4e2d\u56fd\u5bb6\u52b3\u52a8\u529b\u5e02\u573a\u6539\u9769\uff08\u7279\u522b\u662f\u964d\u4f4e\u88c1\u5458\u6210\u672c\uff09\u5bf9\u5c31\u4e1a\u3001\u5408\u540c\u7c7b\u578b\u548c\u5de5\u8d44\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e\u3002", "method": "\u4f7f\u7528\u7edf\u4e00\u5bb6\u5ead\u751f\u6d3b\u6807\u51c6\u8c03\u67e5\u7684\u5fae\u89c2\u6570\u636e\uff0c\u91c7\u7528\u53cc\u5411\u56fa\u5b9a\u6548\u5e94\u65b9\u6cd5\uff0c\u4ee5\u90bb\u8fd1\u56fd\u5bb6\u4f5c\u4e3a\u5bf9\u7167\u7ec4\uff0c\u5206\u6790\u6539\u9769\u5bf9\u5c31\u4e1a\u3001\u5de5\u4eba\u4efb\u671f\u3001\u5408\u540c\u7c7b\u578b\u548c\u5de5\u8d44\u7684\u5f71\u54cd\u3002", "result": "\u6539\u9769\u4f7f\u6b63\u89c4\u90e8\u95e8\u5c31\u4e1a\u589e\u52a02.6\u4e2a\u767e\u5206\u70b9\uff0824.5%\uff09\uff0c\u975e\u6b63\u89c4\u5c31\u4e1a\u51cf\u5c112.8\u4e2a\u767e\u5206\u70b9\uff083.2%\uff09\uff1b\u6b63\u89c4\u90e8\u95e8\u77ed\u671f\u5408\u540c\u5de5\u4eba\u4efb\u671f\u51cf\u5c110.23\u4e2a\u6708\uff0c\u957f\u671f\u5408\u540c\u4efb\u671f\u589e\u52a00.15\u4e2a\u6708\uff1b\u83b7\u5f97\u6c38\u4e45\u5408\u540c\u7684\u53ef\u80fd\u6027\u63d0\u9ad823.2\u4e2a\u767e\u5206\u70b9\uff0841.6%\uff09\uff1b\u6b63\u89c4\u90e8\u95e8\u6708\u5de5\u8d44\u5e73\u5747\u589e\u52a033.6\u7f8e\u5143\u3002", "conclusion": "\u52b3\u52a8\u529b\u5e02\u573a\u6539\u9769\u4fc3\u8fdb\u4e86\u5c31\u4e1a\u518d\u5206\u914d\uff0c\u63ed\u793a\u4e86\u7075\u6d3b\u6027\u3001\u5c31\u4e1a\u7a33\u5b9a\u6027\u548c\u5de5\u8d44\u4e4b\u95f4\u7684\u590d\u6742\u6743\u8861\u5173\u7cfb\uff0c\u4e3a\u53d1\u5c55\u4e2d\u56fd\u5bb6\u52b3\u52a8\u529b\u5e02\u573a\u653f\u7b56\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2510.04740", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.04740", "abs": "https://arxiv.org/abs/2510.04740", "authors": ["Shawn Berry"], "title": "Traffic jams and driver behavior archetypes", "comment": "30 pages, 5 figures, 8 tables", "summary": "Traffic congestion represents a complex urban phenomenon that has been the\nsubject of extensive research employing various modeling techniques grounded in\nthe principles of physics and molecular theory. Although factors such as road\ndesign, accidents, weather conditions, and construction activities contribute\nto traffic congestion, driver behavior and decision-making are primary\ndeterminants of traffic flow efficiency. This study introduces a driver\nbehavior archetype model that quantifies the relationship between individual\ndriver behavior and system-level traffic outcomes through game-theoretic\nmodeling and simulation (N = 500,000) of a three-lane roadway. Mann-Whitney U\ntests revealed statistically significant differences across all utility\nmeasures (p < .001, d > 2.0). In homogeneous populations, responsible drivers\nachieved substantially higher expected utility (M = -0.090) than irresponsible\ndrivers (M = -1.470). However, in mixed environments (50/50), irresponsible\ndrivers paradoxically outperformed responsible drivers (M = 0.128 vs. M =\n-0.127), illustrating a social dilemma wherein defection exploits cooperation.\nPairwise comparisons across the six driver archetypes indicated that all\nirresponsible types achieved equivalent utilities while consistently surpassing\nresponsible drivers. Lane-specific analyses revealed differential capacity\npatterns, with lane 1 exhibiting a more pronounced cumulative utility decline.\nThese findings offer a robust framework for traffic management interventions,\ncongestion prediction, and policy design that aligns individual incentives with\ncollective efficiency. Directions for future research were also proposed.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u535a\u5f08\u8bba\u6a21\u578b\u548c\u6a21\u62df\u5206\u6790\u4e86\u9a7e\u9a76\u5458\u884c\u4e3a\u5bf9\u4ea4\u901a\u62e5\u5835\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5728\u6df7\u5408\u73af\u5883\u4e2d\u4e0d\u8d1f\u8d23\u4efb\u7684\u9a7e\u9a76\u5458\u53cd\u800c\u6bd4\u8d1f\u8d23\u4efb\u7684\u9a7e\u9a76\u5458\u83b7\u5f97\u66f4\u9ad8\u6548\u7528\uff0c\u63ed\u793a\u4e86\u4ea4\u901a\u4e2d\u7684\u793e\u4f1a\u56f0\u5883\u3002", "motivation": "\u867d\u7136\u9053\u8def\u8bbe\u8ba1\u3001\u4e8b\u6545\u3001\u5929\u6c14\u7b49\u56e0\u7d20\u90fd\u4f1a\u5bfc\u81f4\u4ea4\u901a\u62e5\u5835\uff0c\u4f46\u9a7e\u9a76\u5458\u884c\u4e3a\u548c\u51b3\u7b56\u662f\u5f71\u54cd\u4ea4\u901a\u6d41\u6548\u7387\u7684\u4e3b\u8981\u51b3\u5b9a\u56e0\u7d20\u3002\u7814\u7a76\u65e8\u5728\u91cf\u5316\u4e2a\u4f53\u9a7e\u9a76\u5458\u884c\u4e3a\u4e0e\u7cfb\u7edf\u7ea7\u4ea4\u901a\u7ed3\u679c\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u4f7f\u7528\u9a7e\u9a76\u5458\u884c\u4e3a\u539f\u578b\u6a21\u578b\uff0c\u901a\u8fc7\u535a\u5f08\u8bba\u5efa\u6a21\u548c\u6a21\u62df\uff08N=500,000\uff09\u5206\u6790\u4e09\u8f66\u9053\u9053\u8def\u4e0a\u7684\u4ea4\u901a\u60c5\u51b5\uff0c\u5e76\u91c7\u7528Mann-Whitney U\u68c0\u9a8c\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "\u5728\u6df7\u5408\u73af\u5883\uff0850/50\uff09\u4e2d\uff0c\u4e0d\u8d1f\u8d23\u4efb\u7684\u9a7e\u9a76\u5458\u6bd4\u8d1f\u8d23\u4efb\u7684\u9a7e\u9a76\u5458\u8868\u73b0\u66f4\u597d\uff08M=0.128 vs M=-0.127\uff09\uff0c\u6240\u6709\u4e0d\u8d1f\u8d23\u4efb\u7c7b\u578b\u83b7\u5f97\u7b49\u6548\u6548\u7528\u4e14\u59cb\u7ec8\u8d85\u8fc7\u8d1f\u8d23\u4efb\u9a7e\u9a76\u5458\u3002\u8f66\u90531\u663e\u793a\u51fa\u66f4\u660e\u663e\u7684\u7d2f\u79ef\u6548\u7528\u4e0b\u964d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u4ea4\u901a\u7ba1\u7406\u5e72\u9884\u3001\u62e5\u5835\u9884\u6d4b\u548c\u653f\u7b56\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7a33\u5065\u6846\u67b6\uff0c\u65e8\u5728\u534f\u8c03\u4e2a\u4f53\u6fc0\u52b1\u4e0e\u96c6\u4f53\u6548\u7387\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2510.04574", "categories": ["cs.SI", "cs.AI", "physics.soc-ph", "05C82, 68T05, 92C42", "G.2.2; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.04574", "abs": "https://arxiv.org/abs/2510.04574", "authors": ["Wenchao He", "Tao Jia"], "title": "Deep learning framework for predicting stochastic take-off and die-out of early spreading", "comment": "29 pages, 11 figures", "summary": "Large-scale outbreaks of epidemics, misinformation, or other harmful\ncontagions pose significant threats to human society, yet the fundamental\nquestion of whether an emerging outbreak will escalate into a major epidemic or\nnaturally die out remains largely unaddressed. This problem is challenging,\npartially due to inadequate data during the early stages of outbreaks and also\nbecause established models focus on average behaviors of large epidemics rather\nthan the stochastic nature of small transmission chains. Here, we introduce the\nfirst systematic framework for forecasting whether initial transmission events\nwill amplify into major outbreaks or fade into extinction during early stages,\nwhen intervention strategies can still be effectively implemented. Using\nextensive data from stochastic spreading models, we developed a deep learning\nframework that predicts early-stage spreading outcomes in real-time. Validation\nacross Erd\\H{o}s-R\\'enyi and Barab\\'asi-Albert networks with varying\ninfectivity levels shows our method accurately forecasts stochastic spreading\nevents well before potential outbreaks, demonstrating robust performance across\ndifferent network structures and infectivity scenarios.To address the challenge\nof sparse data during early outbreak stages, we further propose a\npretrain-finetune framework that leverages diverse simulation data for\npretraining and adapts to specific scenarios through targeted fine-tuning. The\npretrain-finetune framework consistently outperforms baseline models, achieving\nsuperior performance even when trained on limited scenario-specific data. To\nour knowledge, this work presents the first framework for predicting stochastic\ntake-off versus die-out. This framework provides valuable insights for epidemic\npreparedness and public health decision-making, enabling more informed early\nintervention strategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u9884\u6d4b\u65e9\u671f\u75ab\u60c5\u7206\u53d1\u662f\u5426\u4f1a\u5347\u7ea7\u4e3a\u5927\u6d41\u884c\u6216\u81ea\u7136\u6d88\u4ea1\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3-\u5fae\u8c03\u65b9\u6cd5\u89e3\u51b3\u65e9\u671f\u6570\u636e\u7a00\u758f\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u65e9\u671f\u75ab\u60c5\u7206\u53d1\u9884\u6d4b\u7684\u6311\u6218\uff0c\u56e0\u4e3a\u5728\u7206\u53d1\u521d\u671f\u6570\u636e\u4e0d\u8db3\u4e14\u73b0\u6709\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u5927\u6d41\u884c\u7684\u5e73\u5747\u884c\u4e3a\u800c\u975e\u5c0f\u4f20\u64ad\u94fe\u7684\u968f\u673a\u6027\u3002", "method": "\u4f7f\u7528\u968f\u673a\u4f20\u64ad\u6a21\u578b\u7684\u5e7f\u6cdb\u6570\u636e\u5f00\u53d1\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u91c7\u7528\u9884\u8bad\u7ec3-\u5fae\u8c03\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u6837\u5316\u6a21\u62df\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u9488\u5bf9\u7279\u5b9a\u573a\u666f\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5728Erd\u0151s-R\u00e9nyi\u548cBarab\u00e1si-Albert\u7f51\u7edc\u4e0a\u7684\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u5728\u6f5c\u5728\u7206\u53d1\u524d\u51c6\u786e\u9884\u6d4b\u968f\u673a\u4f20\u64ad\u4e8b\u4ef6\uff0c\u5728\u4e0d\u540c\u7f51\u7edc\u7ed3\u6784\u548c\u4f20\u67d3\u6027\u573a\u666f\u4e0b\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u9884\u6d4b\u968f\u673a\u7206\u53d1\u4e0e\u6d88\u4ea1\u7684\u6846\u67b6\uff0c\u4e3a\u6d41\u884c\u75c5\u51c6\u5907\u548c\u516c\u5171\u536b\u751f\u51b3\u7b56\u63d0\u4f9b\u5b9d\u8d35\u89c1\u89e3\uff0c\u652f\u6301\u66f4\u660e\u667a\u7684\u65e9\u671f\u5e72\u9884\u7b56\u7565\u3002"}}
{"id": "2510.03331", "categories": ["cs.CY", "cs.AI", "68T07, 92C55, 92C60", "I.2.1; J.3; H.3.5"], "pdf": "https://arxiv.org/pdf/2510.03331", "abs": "https://arxiv.org/abs/2510.03331", "authors": ["Vivek Acharya"], "title": "Intelligent Healthcare Ecosystems: Optimizing the Iron Triangle of Healthcare (Access, Cost, Quality)", "comment": "8 pages, 4 figures, formatted per MDPI guidelines, APA-style numbered\n  references", "summary": "The United States spends nearly 17% of GDP on healthcare yet continues to\nface uneven access and outcomes. This well-known trade-off among cost, quality,\nand access - the \"iron triangle\" - motivates a system-level redesign. This\npaper proposes an Intelligent Healthcare Ecosystem (iHE): an integrated,\ndata-driven framework that uses generative AI and large language models,\nfederated learning, interoperability standards (FHIR, TEFCA), and digital twins\nto improve access and quality while lowering cost. We review historical\nspending trends, waste, and international comparisons; introduce a value\nequation that jointly optimizes access, quality, and cost; and synthesize\nevidence on the enabling technologies and operating model for iHE. Methods\nfollow a narrative review of recent literature and policy reports. Results\noutline core components (AI decision support, interoperability, telehealth,\nautomation) and show how iHE can reduce waste, personalize care, and support\nvalue-based payment while addressing privacy, bias, and adoption challenges. We\nargue that a coordinated iHE can bend - if not break - the iron triangle,\nmoving the system toward care that is more accessible, affordable, and high\nquality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u667a\u80fd\u533b\u7597\u751f\u6001\u7cfb\u7edf(iHE)\uff0c\u901a\u8fc7\u6574\u5408\u751f\u6210\u5f0fAI\u3001\u8054\u90a6\u5b66\u4e60\u3001\u4e92\u64cd\u4f5c\u6027\u6807\u51c6\u548c\u6570\u5b57\u5b6a\u751f\u7b49\u6280\u672f\uff0c\u65e8\u5728\u6253\u7834\u533b\u7597\u6210\u672c\u3001\u8d28\u91cf\u548c\u53ef\u53ca\u6027\u4e4b\u95f4\u7684\"\u94c1\u4e09\u89d2\"\u56f0\u5883\u3002", "motivation": "\u7f8e\u56fd\u533b\u7597\u652f\u51fa\u5360GDP\u8fd117%\uff0c\u4f46\u5b58\u5728\u53ef\u53ca\u6027\u548c\u7ed3\u679c\u4e0d\u5747\u7684\u95ee\u9898\u3002\u533b\u7597\u6210\u672c\u3001\u8d28\u91cf\u548c\u53ef\u53ca\u6027\u4e4b\u95f4\u7684\"\u94c1\u4e09\u89d2\"\u77db\u76fe\u4fc3\u4f7f\u8fdb\u884c\u7cfb\u7edf\u7ea7\u91cd\u65b0\u8bbe\u8ba1\u3002", "method": "\u91c7\u7528\u53d9\u4e8b\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u56de\u987e\u8fd1\u671f\u6587\u732e\u548c\u653f\u7b56\u62a5\u544a\uff0c\u5206\u6790\u5386\u53f2\u652f\u51fa\u8d8b\u52bf\u3001\u6d6a\u8d39\u95ee\u9898\u548c\u56fd\u9645\u6bd4\u8f83\u3002", "result": "\u63d0\u51faiHE\u7684\u6838\u5fc3\u7ec4\u4ef6\u5305\u62ecAI\u51b3\u7b56\u652f\u6301\u3001\u4e92\u64cd\u4f5c\u6027\u3001\u8fdc\u7a0b\u533b\u7597\u548c\u81ea\u52a8\u5316\uff0c\u80fd\u591f\u51cf\u5c11\u6d6a\u8d39\u3001\u4e2a\u6027\u5316\u62a4\u7406\u5e76\u652f\u6301\u57fa\u4e8e\u4ef7\u503c\u7684\u652f\u4ed8\u3002", "conclusion": "\u534f\u8c03\u7684iHE\u53ef\u4ee5\u5f2f\u66f2\u751a\u81f3\u6253\u7834\"\u94c1\u4e09\u89d2\"\uff0c\u63a8\u52a8\u533b\u7597\u7cfb\u7edf\u5411\u66f4\u53ef\u53ca\u3001\u53ef\u8d1f\u62c5\u548c\u9ad8\u8d28\u91cf\u7684\u62a4\u7406\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2510.03399", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03399", "abs": "https://arxiv.org/abs/2510.03399", "authors": ["Xiaoyan Bai", "Aryan Shrivastava", "Ari Holtzman", "Chenhao Tan"], "title": "Know Thyself? On the Incapability and Implications of AI Self-Recognition", "comment": "Our code is available, see\n  https://github.com/ChicagoHAI/self-recognition", "summary": "Self-recognition is a crucial metacognitive capability for AI systems,\nrelevant not only for psychological analysis but also for safety, particularly\nin evaluative scenarios. Motivated by contradictory interpretations of whether\nmodels possess self-recognition (Panickssery et al., 2024; Davidson et al.,\n2024), we introduce a systematic evaluation framework that can be easily\napplied and updated. Specifically, we measure how well 10 contemporary larger\nlanguage models (LLMs) can identify their own generated text versus text from\nother models through two tasks: binary self-recognition and exact model\nprediction. Different from prior claims, our results reveal a consistent\nfailure in self-recognition. Only 4 out of 10 models predict themselves as\ngenerators, and the performance is rarely above random chance. Additionally,\nmodels exhibit a strong bias toward predicting GPT and Claude families. We also\nprovide the first evaluation of model awareness of their own and others'\nexistence, as well as the reasoning behind their choices in self-recognition.\nWe find that the model demonstrates some knowledge of its own existence and\nother models, but their reasoning reveals a hierarchical bias. They appear to\nassume that GPT, Claude, and occasionally Gemini are the top-tier models, often\nassociating high-quality text with them. We conclude by discussing the\nimplications of our findings on AI safety and future directions to develop\nappropriate AI self-awareness.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e8610\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u8bc6\u522b\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u666e\u904d\u65e0\u6cd5\u8bc6\u522b\u81ea\u5df1\u751f\u6210\u7684\u6587\u672c\uff0c\u6027\u80fd\u4ec5\u7565\u9ad8\u4e8e\u968f\u673a\u731c\u6d4b\uff0c\u4e14\u5b58\u5728\u5bf9GPT\u548cClaude\u5bb6\u65cf\u7684\u5f3a\u70c8\u504f\u89c1\u3002", "motivation": "\u9488\u5bf9AI\u7cfb\u7edf\u662f\u5426\u5177\u5907\u81ea\u6211\u8bc6\u522b\u80fd\u529b\u8fd9\u4e00\u4e89\u8bae\u95ee\u9898\uff0c\u5efa\u7acb\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u6765\u68c0\u9a8c\u5f53\u4ee3\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u8bc6\u522b\u80fd\u529b\uff0c\u8fd9\u5bf9AI\u5b89\u5168\u548c\u5fc3\u7406\u5206\u6790\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u4e8c\u5143\u81ea\u6211\u8bc6\u522b\u548c\u7cbe\u786e\u6a21\u578b\u9884\u6d4b\u4e24\u4e2a\u4efb\u52a1\uff0c\u8bc4\u4f3010\u4e2a\u5f53\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc6\u522b\u81ea\u5df1\u751f\u6210\u6587\u672c\u4e0e\u5176\u4ed6\u6a21\u578b\u6587\u672c\u7684\u80fd\u529b\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6a21\u578b\u81ea\u6211\u8bc6\u522b\u80fd\u529b\u666e\u904d\u5931\u8d25\uff0c\u4ec54/10\u6a21\u578b\u80fd\u6b63\u786e\u9884\u6d4b\u81ea\u5df1\u4e3a\u751f\u6210\u8005\uff0c\u6027\u80fd\u5f88\u5c11\u8d85\u8fc7\u968f\u673a\u673a\u4f1a\u3002\u6a21\u578b\u5b58\u5728\u5bf9GPT\u548cClaude\u5bb6\u65cf\u7684\u5f3a\u70c8\u504f\u89c1\uff0c\u5e76\u8868\u73b0\u51fa\u5bf9\u6a21\u578b\u5b58\u5728\u6027\u7684\u5c42\u6b21\u8ba4\u77e5\u504f\u5dee\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u6211\u8bc6\u522b\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u8fd9\u5bf9AI\u5b89\u5168\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u5e76\u4e3a\u5f00\u53d1\u9002\u5f53\u7684AI\u81ea\u6211\u610f\u8bc6\u6307\u660e\u4e86\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2510.03354", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03354", "abs": "https://arxiv.org/abs/2510.03354", "authors": ["Xiaolong Jia", "Nikhil Bajaj"], "title": "On Architectures for Combining Reinforcement Learning and Model Predictive Control with Runtime Improvements", "comment": "Accepted at the 2025 IFAC Conference on Modeling, Estimation, and\n  Control of Systems (MECC 2025), Pittsburgh, USA", "summary": "Model Predictive Control (MPC) faces computational demands and performance\ndegradation from model inaccuracies. We propose two architectures combining\nNeural Network-approximated MPC (NNMPC) with Reinforcement Learning (RL). The\nfirst, Warm Start RL, initializes the RL actor with pre-trained NNMPC weights.\nThe second, RLMPC, uses RL to generate corrective residuals for NNMPC outputs.\nWe introduce a downsampling method reducing NNMPC input dimensions while\nmaintaining performance. Evaluated on a rotary inverted pendulum, both\narchitectures demonstrate runtime reductions exceeding 99% compared to\ntraditional MPC while improving tracking performance under model uncertainties,\nwith RL+MPC achieving 11-40% cost reduction depending on reference amplitude.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3cMPC\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u67b6\u6784\uff0c\u5728\u65cb\u8f6c\u5012\u7acb\u6446\u4e0a\u5b9e\u73b099%\u4ee5\u4e0a\u8fd0\u884c\u65f6\u51cf\u5c11\uff0c\u5e76\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4e0b\u63d0\u5347\u8ddf\u8e2a\u6027\u80fd", "motivation": "\u89e3\u51b3MPC\u8ba1\u7b97\u9700\u6c42\u9ad8\u548c\u6a21\u578b\u4e0d\u51c6\u786e\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898", "method": "1. Warm Start RL\uff1a\u7528\u9884\u8bad\u7ec3NNMPC\u6743\u91cd\u521d\u59cb\u5316RL actor\uff1b2. RLMPC\uff1a\u7528RL\u751f\u6210NNMPC\u8f93\u51fa\u7684\u6821\u6b63\u6b8b\u5dee\uff1b3. \u5f15\u5165\u964d\u91c7\u6837\u65b9\u6cd5\u51cf\u5c11NNMPC\u8f93\u5165\u7ef4\u5ea6", "result": "\u76f8\u6bd4\u4f20\u7edfMPC\uff0c\u8fd0\u884c\u65f6\u51cf\u5c11\u8d85\u8fc799%\uff0c\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4e0b\u8ddf\u8e2a\u6027\u80fd\u63d0\u5347\uff0cRL+MPC\u5b9e\u73b011-40%\u6210\u672c\u964d\u4f4e", "conclusion": "NNMPC\u4e0eRL\u7684\u7ed3\u5408\u67b6\u6784\u80fd\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u9700\u6c42\u5e76\u63d0\u5347\u9c81\u68d2\u6027"}}
{"id": "2510.03460", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03460", "abs": "https://arxiv.org/abs/2510.03460", "authors": ["Sibo Tian", "Minghui Zheng", "Xiao Liang"], "title": "Warm-Starting Optimization-Based Motion Planning for Robotic Manipulators via Point Cloud-Conditioned Flow Matching", "comment": null, "summary": "Rapid robot motion generation is critical in Human-Robot Collaboration (HRC)\nsystems, as robots need to respond to dynamic environments in real time by\ncontinuously observing their surroundings and replanning their motions to\nensure both safe interactions and efficient task execution. Current\nsampling-based motion planners face challenges in scaling to high-dimensional\nconfiguration spaces and often require post-processing to interpolate and\nsmooth the generated paths, resulting in time inefficiency in complex\nenvironments. Optimization-based planners, on the other hand, can incorporate\nmultiple constraints and generate smooth trajectories directly, making them\npotentially more time-efficient. However, optimization-based planners are\nsensitive to initialization and may get stuck in local minima. In this work, we\npresent a novel learning-based method that utilizes a Flow Matching model\nconditioned on a single-view point cloud to learn near-optimal solutions for\noptimization initialization. Our method does not require prior knowledge of the\nenvironment, such as obstacle locations and geometries, and can generate\nfeasible trajectories directly from single-view depth camera input. Simulation\nstudies on a UR5e robotic manipulator in cluttered workspaces demonstrate that\nthe proposed generative initializer achieves a high success rate on its own,\nsignificantly improves the success rate of trajectory optimization compared\nwith traditional and learning-based benchmark initializers, requires fewer\noptimization iterations, and exhibits strong generalization to unseen\nenvironments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d41\u5339\u914d\u6a21\u578b\u7684\u751f\u6210\u5f0f\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5355\u89c6\u89d2\u70b9\u4e91\u5b66\u4e60\u4f18\u5316\u95ee\u9898\u7684\u8fd1\u4f18\u89e3\uff0c\u7528\u4e8e\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\uff0c\u65e0\u9700\u73af\u5883\u5148\u9a8c\u77e5\u8bc6\u5373\u53ef\u4ece\u6df1\u5ea6\u76f8\u673a\u8f93\u5165\u76f4\u63a5\u751f\u6210\u53ef\u884c\u8f68\u8ff9\u3002", "motivation": "\u5728HRC\u7cfb\u7edf\u4e2d\u9700\u8981\u5b9e\u65f6\u751f\u6210\u673a\u5668\u4eba\u8fd0\u52a8\uff0c\u4f46\u73b0\u6709\u91c7\u6837\u89c4\u5212\u5668\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u6269\u5c55\u6027\u5dee\uff0c\u4f18\u5316\u89c4\u5212\u5668\u5bf9\u521d\u59cb\u5316\u654f\u611f\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5feb\u901f\u751f\u6210\u9ad8\u8d28\u91cf\u521d\u59cb\u89e3\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u751f\u6210\u6a21\u578b\uff0c\u4ee5\u5355\u89c6\u89d2\u70b9\u4e91\u4e3a\u6761\u4ef6\uff0c\u5b66\u4e60\u8f68\u8ff9\u4f18\u5316\u7684\u8fd1\u4f18\u521d\u59cb\u89e3\uff0c\u65e0\u9700\u969c\u788d\u7269\u4f4d\u7f6e\u548c\u51e0\u4f55\u5f62\u72b6\u7b49\u73af\u5883\u5148\u9a8c\u77e5\u8bc6\u3002", "result": "\u5728UR5e\u673a\u68b0\u81c2\u6742\u4e71\u5de5\u4f5c\u7a7a\u95f4\u7684\u4eff\u771f\u7814\u7a76\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5355\u72ec\u4f7f\u7528\u5373\u6709\u9ad8\u6210\u529f\u7387\uff0c\u663e\u8457\u63d0\u5347\u8f68\u8ff9\u4f18\u5316\u6210\u529f\u7387\uff0c\u51cf\u5c11\u4f18\u5316\u8fed\u4ee3\u6b21\u6570\uff0c\u5e76\u5728\u672a\u89c1\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u751f\u6210\u5f0f\u521d\u59cb\u5316\u5668\u80fd\u6709\u6548\u89e3\u51b3\u4f18\u5316\u89c4\u5212\u5668\u7684\u521d\u59cb\u5316\u95ee\u9898\uff0c\u4e3a\u5b9e\u65f6HRC\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u8fd0\u52a8\u89c4\u5212\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03792", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.03792", "abs": "https://arxiv.org/abs/2510.03792", "authors": ["Giuseppe Pagano Giorgianni"], "title": "Gas price shocks, uncertainty and price setting: evidences from Italian firms", "comment": "15 pages, 9 figures", "summary": "This paper examines how natural gas price shocks affect Italian firms'\npricing decisions and inflation expectations using quarterly survey data from\nthe Bank of Italy's Survey on Inflation and Growth Expectations (SIGE) spanning\n1999Q4-2025Q2. We identify natural gas price shocks through a Bayesian VAR with\nsign and zero restrictions. Our findings reveal that these shocks are a primary\ndriver of firms' inflation expectations, particularly during the post-COVID\nperiod (2021-2023) when supply disruptions following Russia's invasion of\nUkraine generated unprecedented price pressures. We then estimate a larger BVAR\nincorporating firm-level price setting variables and macro aggregates,\ndocumenting that gas price shocks generate persistent increases in both firms'\ncurrent and expected prices, alongside elevated inflation uncertainty. We\nuncover substantial non-linearities using state-dependent local projections:\nunder high uncertainty, firms successfully pass through cost increases to\nconsumers, maintaining elevated prices; under low uncertainty, recessionary\neffects dominate, causing firms to reduce prices below baseline.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528\u610f\u5927\u5229\u592e\u884c\u7684\u901a\u80c0\u9884\u671f\u8c03\u67e5\u6570\u636e\uff0c\u901a\u8fc7\u8d1d\u53f6\u65afVAR\u6a21\u578b\u5206\u6790\u5929\u7136\u6c14\u4ef7\u683c\u51b2\u51fb\u5bf9\u610f\u5927\u5229\u4f01\u4e1a\u5b9a\u4ef7\u51b3\u7b56\u548c\u901a\u80c0\u9884\u671f\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8fd9\u4e9b\u51b2\u51fb\u662f\u901a\u80c0\u9884\u671f\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u7279\u522b\u662f\u5728\u540e\u75ab\u60c5\u65f6\u671f\u3002", "motivation": "\u7814\u7a76\u5929\u7136\u6c14\u4ef7\u683c\u51b2\u51fb\u5982\u4f55\u5f71\u54cd\u4f01\u4e1a\u7684\u5b9a\u4ef7\u884c\u4e3a\u548c\u901a\u80c0\u9884\u671f\uff0c\u7279\u522b\u662f\u5728\u4fc4\u7f57\u65af\u5165\u4fb5\u4e4c\u514b\u5170\u5bfc\u81f4\u4f9b\u5e94\u4e2d\u65ad\u5f15\u53d1\u524d\u6240\u672a\u6709\u7684\u4ef7\u683c\u538b\u529b\u65f6\u671f\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65afVAR\u6a21\u578b\u8bc6\u522b\u5929\u7136\u6c14\u4ef7\u683c\u51b2\u51fb\uff0c\u5e76\u6784\u5efa\u66f4\u5927\u7684BVAR\u6a21\u578b\u7eb3\u5165\u4f01\u4e1a\u5c42\u9762\u5b9a\u4ef7\u53d8\u91cf\u548c\u5b8f\u89c2\u603b\u91cf\u6570\u636e\uff0c\u540c\u65f6\u91c7\u7528\u72b6\u6001\u4f9d\u8d56\u7684\u5c40\u90e8\u6295\u5f71\u65b9\u6cd5\u5206\u6790\u975e\u7ebf\u6027\u6548\u5e94\u3002", "result": "\u5929\u7136\u6c14\u4ef7\u683c\u51b2\u51fb\u5bfc\u81f4\u4f01\u4e1a\u5f53\u524d\u548c\u9884\u671f\u4ef7\u683c\u6301\u7eed\u4e0a\u6da8\uff0c\u901a\u80c0\u4e0d\u786e\u5b9a\u6027\u5347\u9ad8\u3002\u5728\u9ad8\u4e0d\u786e\u5b9a\u6027\u72b6\u6001\u4e0b\uff0c\u4f01\u4e1a\u6210\u529f\u5c06\u6210\u672c\u8f6c\u5ac1\u7ed9\u6d88\u8d39\u8005\uff1b\u5728\u4f4e\u4e0d\u786e\u5b9a\u6027\u72b6\u6001\u4e0b\uff0c\u8870\u9000\u6548\u5e94\u4e3b\u5bfc\uff0c\u4f01\u4e1a\u5c06\u4ef7\u683c\u964d\u81f3\u57fa\u51c6\u4ee5\u4e0b\u3002", "conclusion": "\u5929\u7136\u6c14\u4ef7\u683c\u51b2\u51fb\u662f\u4f01\u4e1a\u901a\u80c0\u9884\u671f\u7684\u91cd\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u5176\u5f71\u54cd\u5177\u6709\u663e\u8457\u7684\u975e\u7ebf\u6027\u7279\u5f81\uff0c\u53d6\u51b3\u4e8e\u7ecf\u6d4e\u4e0d\u786e\u5b9a\u6027\u6c34\u5e73\u3002"}}
{"id": "2510.04884", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.04884", "abs": "https://arxiv.org/abs/2510.04884", "authors": ["Adam Schroeder", "Russell Funk", "Jingyi Guan", "Taylor Okonek", "Lori Ziegelmeier"], "title": "Higher-Order Network Structure Inference: A Topological Approach to Network Selection", "comment": null, "summary": "Thresholding--the pruning of nodes or edges based on their properties or\nweights--is an essential preprocessing tool for extracting interpretable\nstructure from complex network data, yet existing methods face several key\nlimitations. Threshold selection often relies on heuristic methods or trial and\nerror due to large parameter spaces and unclear optimization criteria, leading\nto sensitivity where small parameter variations produce significant changes in\nnetwork structure. Moreover, most approaches focus on pairwise relationships\nbetween nodes, overlooking critical higher-order interactions involving three\nor more nodes. We introduce a systematic thresholding algorithm that leverages\ntopological data analysis to identify optimal network parameters by accounting\nfor higher-order structural relationships. Our method uses persistent homology\nto compute the stability of homological features across the parameter space,\nidentifying parameter choices that are robust to small variations while\npreserving meaningful topological structure. Hyperparameters allow users to\nspecify minimum requirements for topological features, effectively constraining\nthe parameter search to avoid spurious solutions. We demonstrate the approach\nwith an application in the Science of Science, where networks of scientific\nconcepts are extracted from research paper abstracts, and concepts are\nconnected when they co-appear in the same abstract. The flexibility of our\napproach allows researchers to incorporate domain-specific constraints and\nextends beyond network thresholding to general parameterization problems in\ndata analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u62d3\u6251\u6570\u636e\u5206\u6790\u7684\u7cfb\u7edf\u6027\u9608\u503c\u9009\u62e9\u7b97\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u9ad8\u9636\u7ed3\u6784\u5173\u7cfb\u6765\u8bc6\u522b\u6700\u4f18\u7f51\u7edc\u53c2\u6570\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u9608\u503c\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u5ffd\u7565\u9ad8\u9636\u4ea4\u4e92\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7f51\u7edc\u9608\u503c\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u5c40\u9650\uff1a\u9608\u503c\u9009\u62e9\u4f9d\u8d56\u542f\u53d1\u5f0f\u65b9\u6cd5\u6216\u8bd5\u9519\uff0c\u5bfc\u81f4\u5bf9\u53c2\u6570\u53d8\u5316\u654f\u611f\uff1b\u5927\u591a\u6570\u65b9\u6cd5\u53ea\u5173\u6ce8\u8282\u70b9\u95f4\u7684\u6210\u5bf9\u5173\u7cfb\uff0c\u5ffd\u7565\u4e86\u4e09\u4e2a\u6216\u66f4\u591a\u8282\u70b9\u95f4\u7684\u9ad8\u9636\u4ea4\u4e92\u3002", "method": "\u4f7f\u7528\u6301\u4e45\u540c\u8c03\u8ba1\u7b97\u53c2\u6570\u7a7a\u95f4\u4e2d\u540c\u8c03\u7279\u5f81\u7684\u7a33\u5b9a\u6027\uff0c\u8bc6\u522b\u5bf9\u5fae\u5c0f\u53d8\u5316\u9c81\u68d2\u4e14\u80fd\u4fdd\u7559\u6709\u610f\u4e49\u62d3\u6251\u7ed3\u6784\u7684\u53c2\u6570\u9009\u62e9\u3002\u901a\u8fc7\u8d85\u53c2\u6570\u5141\u8bb8\u7528\u6237\u6307\u5b9a\u62d3\u6251\u7279\u5f81\u7684\u6700\u4f4e\u8981\u6c42\uff0c\u6709\u6548\u7ea6\u675f\u53c2\u6570\u641c\u7d22\u907f\u514d\u865a\u5047\u89e3\u3002", "result": "\u5728\u79d1\u5b66\u79d1\u5b66\u9886\u57df\u7684\u5e94\u7528\u4e2d\uff0c\u4ece\u7814\u7a76\u8bba\u6587\u6458\u8981\u4e2d\u63d0\u53d6\u79d1\u5b66\u6982\u5ff5\u7f51\u7edc\uff0c\u5f53\u6982\u5ff5\u5728\u540c\u4e00\u6458\u8981\u4e2d\u5171\u540c\u51fa\u73b0\u65f6\u5efa\u7acb\u8fde\u63a5\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8e\u7f51\u7edc\u9608\u503c\u9009\u62e9\uff0c\u8fd8\u80fd\u6269\u5c55\u5230\u6570\u636e\u5206\u6790\u4e2d\u7684\u4e00\u822c\u53c2\u6570\u5316\u95ee\u9898\uff0c\u5177\u6709\u7075\u6d3b\u6027\uff0c\u5141\u8bb8\u7814\u7a76\u4eba\u5458\u878d\u5165\u9886\u57df\u7279\u5b9a\u7684\u7ea6\u675f\u3002"}}
{"id": "2510.03343", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03343", "abs": "https://arxiv.org/abs/2510.03343", "authors": ["Nikolaos Avouris"], "title": "Defining a Strategic Action Plan for AI in Higher Education", "comment": "to be cited: N. Avouris (2025), Defining a Strategic Action Plan for\n  AI in Higher Education, Proceedings International Scientific Conference on\n  Digital Competencies in Higher Education, Tirana, September 2025, pp. 141-151", "summary": "This paper discusses key challenges of Artificial Intelligence in Education,\nwith main focus on higher education institutions. We start with reviewing\nnormative actions of international organizations and concerns expressed about\nthe current technical landscape. Then we proceed with proposing a framework\nthat comprises five key dimensions relating to the main challenges relating to\nAI in higher education institutions, followed by five key strategic actions\nthat the main stakeholders need to take in order to address the current\ndevelopments. We map these actions to the main stakeholders of higher education\nand propose a deployment plan. This defines a framework along the dimensions:\nChallenges, Actions, Stakeholders, Deployment CASD. Examples of AI specific\nactions at the institutional and individual course level are also provided and\ndiscussed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u6790\u9ad8\u7b49\u6559\u80b2\u4e2d\u4eba\u5de5\u667a\u80fd\u6311\u6218\u7684\u6846\u67b6\uff0c\u5305\u542b\u4e94\u4e2a\u5173\u952e\u7ef4\u5ea6\u548c\u4e94\u9879\u6218\u7565\u884c\u52a8\uff0c\u5e76\u6620\u5c04\u5230\u4e3b\u8981\u5229\u76ca\u76f8\u5173\u8005\uff0c\u63d0\u4f9b\u4e86\u90e8\u7f72\u8ba1\u5212\u3002", "motivation": "\u5206\u6790\u9ad8\u7b49\u6559\u80b2\u673a\u6784\u4e2d\u4eba\u5de5\u667a\u80fd\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\uff0c\u89e3\u51b3\u56fd\u9645\u7ec4\u7ec7\u5173\u6ce8\u7684\u95ee\u9898\u548c\u5f53\u524d\u6280\u672f\u73af\u5883\u4e2d\u7684\u62c5\u5fe7\u3002", "method": "\u63d0\u51fa\u5305\u542b\u4e94\u4e2a\u5173\u952e\u7ef4\u5ea6\u7684\u6846\u67b6\uff0c\u8bc6\u522b\u4e94\u9879\u6218\u7565\u884c\u52a8\uff0c\u5e76\u5c06\u8fd9\u4e9b\u884c\u52a8\u6620\u5c04\u5230\u4e3b\u8981\u5229\u76ca\u76f8\u5173\u8005\uff0c\u5236\u5b9a\u90e8\u7f72\u8ba1\u5212\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u6db5\u76d6\u6311\u6218\u3001\u884c\u52a8\u3001\u5229\u76ca\u76f8\u5173\u8005\u548c\u90e8\u7f72\u7684CASD\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u673a\u6784\u548c\u8bfe\u7a0b\u5c42\u9762\u7684\u5177\u4f53AI\u884c\u52a8\u793a\u4f8b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u9ad8\u7b49\u6559\u80b2\u673a\u6784\u5e94\u5bf9AI\u6311\u6218\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u6307\u5bfc\uff0c\u5e2e\u52a9\u5404\u5229\u76ca\u76f8\u5173\u8005\u91c7\u53d6\u9002\u5f53\u884c\u52a8\u6765\u5e94\u5bf9\u5f53\u524d\u53d1\u5c55\u3002"}}
{"id": "2510.03418", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.03418", "abs": "https://arxiv.org/abs/2510.03418", "authors": ["Ananya Mantravadi", "Shivali Dalmia", "Abhishek Mukherji", "Nand Dave", "Anudha Mittal"], "title": "ContraGen: A Multi-Agent Generation Framework for Enterprise Contradictions Detection", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) integrates LLMs with external sources,\noffering advanced capabilities for information access and decision-making.\nHowever, contradictions in retrieved evidence can result in inconsistent or\nuntrustworthy outputs, which is especially problematic in enterprise settings\nwhere compliance, governance, and accountability are critical. Existing\nbenchmarks for contradiction detection are limited to sentence-level analysis\nand do not capture the complexity of enterprise documents such as contracts,\nfinancial filings, compliance reports, or policy manuals. To address this\nlimitation, we propose ContraGen, a contradiction-aware benchmark framework\ntailored to enterprise domain. The framework generates synthetic\nenterprise-style documents with embedded contradictions, enabling systematic\nevaluation of both intra-document and cross-document consistency. Automated\ncontradiction mining is combined with human-in-the-loop validation to ensure\nhigh accuracy. Our contributions include generating realistic enterprise\ndocuments, modeling a taxonomy of contradiction types common in business\nprocesses, enabling controlled creation of self- and pairwise contradictions,\ndeveloping a contradiction-aware retrieval evaluation pipeline and embedding\nhuman oversight to reflect domain-specific judgment complexity. This work\nestablishes a foundation for more trustworthy and accountable RAG systems in\nenterprise information-seeking applications, where detecting and resolving\ncontradictions is essential for reducing risk and ensuring compliance.", "AI": {"tldr": "\u63d0\u51fa\u4e86ContraGen\u57fa\u51c6\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u4f01\u4e1a\u9886\u57df\u751f\u6210\u5305\u542b\u77db\u76fe\u5185\u5bb9\u7684\u5408\u6210\u6587\u6863\uff0c\u7528\u4e8e\u8bc4\u4f30RAG\u7cfb\u7edf\u7684\u77db\u76fe\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u77db\u76fe\u68c0\u6d4b\u57fa\u51c6\u4ec5\u9650\u4e8e\u53e5\u5b50\u7ea7\u522b\u5206\u6790\uff0c\u65e0\u6cd5\u5904\u7406\u4f01\u4e1a\u6587\u6863\uff08\u5982\u5408\u540c\u3001\u8d22\u52a1\u62a5\u544a\u7b49\uff09\u7684\u590d\u6742\u6027\uff0c\u800cRAG\u7cfb\u7edf\u4e2d\u7684\u8bc1\u636e\u77db\u76fe\u4f1a\u5bfc\u81f4\u4e0d\u53ef\u9760\u8f93\u51fa\uff0c\u8fd9\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u5c24\u5176\u5371\u9669\u3002", "method": "\u7ed3\u5408\u81ea\u52a8\u5316\u77db\u76fe\u6316\u6398\u548c\u4eba\u5de5\u9a8c\u8bc1\uff0c\u751f\u6210\u4f01\u4e1a\u98ce\u683c\u5408\u6210\u6587\u6863\u5e76\u5d4c\u5165\u77db\u76fe\uff0c\u5efa\u7acb\u4f01\u4e1a\u6d41\u7a0b\u4e2d\u5e38\u89c1\u7684\u77db\u76fe\u7c7b\u578b\u5206\u7c7b\u6cd5\uff0c\u652f\u6301\u53d7\u63a7\u521b\u5efa\u81ea\u77db\u76fe\u548c\u6210\u5bf9\u77db\u76fe\u3002", "result": "\u5f00\u53d1\u4e86\u77db\u76fe\u611f\u77e5\u7684\u68c0\u7d22\u8bc4\u4f30\u6d41\u7a0b\uff0c\u5efa\u7acb\u4e86\u4f01\u4e1a\u4fe1\u606f\u68c0\u7d22\u5e94\u7528\u4e2d\u66f4\u53ef\u4fe1\u8d56RAG\u7cfb\u7edf\u7684\u57fa\u7840\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5728\u4f01\u4e1a\u4fe1\u606f\u641c\u7d22\u5e94\u7528\u4e2d\u6784\u5efa\u66f4\u53ef\u4fe1\u548c\u53ef\u95ee\u8d23\u7684RAG\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5176\u4e2d\u68c0\u6d4b\u548c\u89e3\u51b3\u77db\u76fe\u5bf9\u4e8e\u964d\u4f4e\u98ce\u9669\u548c\u786e\u4fdd\u5408\u89c4\u6027\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.03367", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03367", "abs": "https://arxiv.org/abs/2510.03367", "authors": ["Zizhe Zhang", "Yicong Wang", "Zhiquan Zhang", "Tianyu Li", "Nadia Figueroa"], "title": "Viability-Preserving Passive Torque Control", "comment": "8 pages, 7 figures, Project Website:\n  https://vpp-tc.github.io/webpage/", "summary": "Conventional passivity-based torque controllers for manipulators are\ntypically unconstrained, which can lead to safety violations under external\nperturbations. In this paper, we employ viability theory to pre-compute safe\nsets in the state-space of joint positions and velocities. These viable sets,\nconstructed via data-driven and analytical methods for self-collision\navoidance, external object collision avoidance and joint-position and\njoint-velocity limits, provide constraints on joint accelerations and thus\njoint torques via the robot dynamics. A quadratic programming-based control\nframework enforces these constraints on a passive controller tracking a\ndynamical system, ensuring the robot states remain within the safe set in an\ninfinite time horizon. We validate the proposed approach through simulations\nand hardware experiments on a 7-DoF Franka Emika manipulator. In comparison to\na baseline constrained passive controller, our method operates at higher\ncontrol-loop rates and yields smoother trajectories.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u5b58\u6027\u7406\u8bba\u7684\u673a\u5668\u4eba\u5b89\u5168\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u8ba1\u7b97\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u5b89\u5168\u96c6\u5408\uff0c\u7ed3\u5408\u4e8c\u6b21\u89c4\u5212\u7ea6\u675f\u88ab\u52a8\u63a7\u5236\u5668\uff0c\u786e\u4fdd\u673a\u5668\u4eba\u5728\u65e0\u9650\u65f6\u95f4\u8303\u56f4\u5185\u4fdd\u6301\u5b89\u5168\u72b6\u6001\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u88ab\u52a8\u6027\u7684\u626d\u77e9\u63a7\u5236\u5668\u901a\u5e38\u65e0\u7ea6\u675f\uff0c\u5728\u5916\u90e8\u6270\u52a8\u4e0b\u53ef\u80fd\u5bfc\u81f4\u5b89\u5168\u8fdd\u89c4\u3002\u9700\u8981\u4e00\u79cd\u80fd\u786e\u4fdd\u673a\u5668\u4eba\u72b6\u6001\u59cb\u7ec8\u4fdd\u6301\u5728\u5b89\u5168\u533a\u57df\u7684\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u751f\u5b58\u6027\u7406\u8bba\u9884\u8ba1\u7b97\u5173\u8282\u4f4d\u7f6e\u548c\u901f\u5ea6\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u5b89\u5168\u96c6\u5408\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u548c\u89e3\u6790\u65b9\u6cd5\u6784\u5efa\u81ea\u78b0\u649e\u907f\u514d\u3001\u5916\u90e8\u7269\u4f53\u78b0\u649e\u907f\u514d\u4ee5\u53ca\u5173\u8282\u4f4d\u7f6e\u548c\u901f\u5ea6\u9650\u5236\u7684\u53ef\u884c\u96c6\u5408\uff0c\u57fa\u4e8e\u4e8c\u6b21\u89c4\u5212\u7684\u63a7\u5236\u5668\u5728\u88ab\u52a8\u63a7\u5236\u5668\u4e0a\u65bd\u52a0\u8fd9\u4e9b\u7ea6\u675f\u3002", "result": "\u57287\u81ea\u7531\u5ea6Franka Emika\u673a\u68b0\u81c2\u4e0a\u7684\u4eff\u771f\u548c\u786c\u4ef6\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\uff0c\u76f8\u6bd4\u57fa\u7ebf\u7ea6\u675f\u88ab\u52a8\u63a7\u5236\u5668\uff0c\u80fd\u4ee5\u66f4\u9ad8\u7684\u63a7\u5236\u56de\u8def\u9891\u7387\u8fd0\u884c\u5e76\u4ea7\u751f\u66f4\u5e73\u6ed1\u7684\u8f68\u8ff9\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u786e\u4fdd\u673a\u5668\u4eba\u5728\u65e0\u9650\u65f6\u95f4\u8303\u56f4\u5185\u4fdd\u6301\u5b89\u5168\u72b6\u6001\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u9ad8\u7684\u63a7\u5236\u6027\u80fd\u548c\u66f4\u5e73\u6ed1\u7684\u8fd0\u52a8\u8f68\u8ff9\u3002"}}
{"id": "2510.03471", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03471", "abs": "https://arxiv.org/abs/2510.03471", "authors": ["Dingqi Zhang", "Ran Tao", "Sheng Cheng", "Naira Hovakimyan", "Mark W. Mueller"], "title": "A Simulation Evaluation Suite for Robust Adaptive Quadcopter Control", "comment": null, "summary": "Robust adaptive control methods are essential for maintaining quadcopter\nperformance under external disturbances and model uncertainties. However,\nfragmented evaluations across tasks, simulators, and implementations hinder\nsystematic comparison of these methods. This paper introduces an\neasy-to-deploy, modular simulation testbed for quadcopter control, built on\nRotorPy, that enables evaluation under a wide range of disturbances such as\nwind, payload shifts, rotor faults, and control latency. The framework includes\na library of representative adaptive and non-adaptive controllers and provides\ntask-relevant metrics to assess tracking accuracy and robustness. The unified\nmodular environment enables reproducible evaluation across control methods and\neliminates redundant reimplementation of components such as disturbance models,\ntrajectory generators, and analysis tools. We illustrate the testbed's\nversatility through examples spanning multiple disturbance scenarios and\ntrajectory types, including automated stress testing, to demonstrate its\nutility for systematic analysis. Code is available at\nhttps://github.com/Dz298/AdaptiveQuadBench.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eRotorPy\u7684\u6a21\u5757\u5316\u56db\u65cb\u7ffc\u63a7\u5236\u4eff\u771f\u6d4b\u8bd5\u5e73\u53f0\uff0c\u7528\u4e8e\u5728\u591a\u79cd\u5e72\u6270\u6761\u4ef6\u4e0b\u7cfb\u7edf\u8bc4\u4f30\u81ea\u9002\u5e94\u63a7\u5236\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u56db\u65cb\u7ffc\u81ea\u9002\u5e94\u63a7\u5236\u65b9\u6cd5\u5728\u4efb\u52a1\u3001\u4eff\u771f\u5668\u548c\u5b9e\u73b0\u4e0a\u7684\u788e\u7247\u5316\u8bc4\u4f30\u963b\u788d\u4e86\u7cfb\u7edf\u6bd4\u8f83\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6613\u4e8e\u90e8\u7f72\u7684\u6a21\u5757\u5316\u4eff\u771f\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5305\u542b\u4ee3\u8868\u6027\u81ea\u9002\u5e94\u548c\u975e\u81ea\u9002\u5e94\u63a7\u5236\u5668\u5e93\uff0c\u63d0\u4f9b\u4efb\u52a1\u76f8\u5173\u6307\u6807\u6765\u8bc4\u4f30\u8ddf\u8e2a\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002", "result": "\u8be5\u6846\u67b6\u652f\u6301\u5728\u98ce\u6270\u3001\u8f7d\u8377\u504f\u79fb\u3001\u8f6c\u5b50\u6545\u969c\u548c\u63a7\u5236\u5ef6\u8fdf\u7b49\u591a\u79cd\u5e72\u6270\u573a\u666f\u4e0b\u8fdb\u884c\u53ef\u91cd\u590d\u8bc4\u4f30\uff0c\u6d88\u9664\u4e86\u5e72\u6270\u6a21\u578b\u3001\u8f68\u8ff9\u751f\u6210\u5668\u548c\u5206\u6790\u5de5\u5177\u7b49\u7ec4\u4ef6\u7684\u5197\u4f59\u91cd\u65b0\u5b9e\u73b0\u3002", "conclusion": "\u8be5\u6d4b\u8bd5\u5e73\u53f0\u901a\u8fc7\u6db5\u76d6\u591a\u79cd\u5e72\u6270\u573a\u666f\u548c\u8f68\u8ff9\u7c7b\u578b\u7684\u793a\u4f8b\u5c55\u793a\u4e86\u5176\u591a\u529f\u80fd\u6027\uff0c\u5305\u62ec\u81ea\u52a8\u5316\u538b\u529b\u6d4b\u8bd5\uff0c\u8bc1\u660e\u4e86\u5176\u7528\u4e8e\u7cfb\u7edf\u5206\u6790\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.04388", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.04388", "abs": "https://arxiv.org/abs/2510.04388", "authors": ["Adrian Odenweller", "Falko Ueckerdt", "Johannes Hampp", "Ivan Ramirez", "Felix Schreyer", "Robin Hasse", "Jarusch Muessel", "Chen Chris Gong", "Robert Pietzcker", "Tom Brown", "Gunnar Luderer"], "title": "REMIND-PyPSA-Eur: Integrating power system flexibility into sector-coupled energy transition pathways", "comment": null, "summary": "The rapid expansion of low-cost renewable electricity combined with end-use\nelectrification in transport, industry, and buildings offers a promising path\nto deep decarbonisation. However, aligning variable supply with demand requires\nstrategies for daily and seasonal balancing. Existing models either lack the\nwide scope required for long-term transition pathways or the spatio-temporal\ndetail to capture power system variability and flexibility. Here, we combine\nthe complementary strengths of REMIND, a long-term integrated assessment model,\nand PyPSA-Eur, an hourly energy system model, through a bi-directional,\nprice-based and iterative soft coupling. REMIND provides pathway variables such\nas sectoral electricity demand, installed capacities, and costs to PyPSA-Eur,\nwhich returns optimised operational variables such as capacity factors, storage\nrequirements, and relative prices. After sufficient convergence, this\nintegrated approach jointly optimises long-term investment and short-term\noperation. We demonstrate the coupling for two Germany-focused scenarios, with\nand without demand-side flexibility, reaching climate neutrality by 2045. Our\nresults confirm that a sector-coupled energy system with nearly 100\\% renewable\nelectricity is technically possible and economically viable. Power system\nflexibility influences long-term pathways through price differentiation:\nsupply-side market values vary by generation technology, while demand-side\nprices vary by end-use sector. Flexible electrolysers and smart-charging\nelectric vehicles benefit from below-average prices, whereas less flexible heat\npumps face almost twice the average price due to winter peak loads. Without\ndemand-side flexibility, electricity prices increase across all end-users,\nthough battery deployment partially compensates. Our approach therefore fully\nintegrates power system dynamics into multi-decadal energy transition pathways.", "AI": {"tldr": "\u7ed3\u5408REMIND\u957f\u671f\u7efc\u5408\u8bc4\u4f30\u6a21\u578b\u548cPyPSA-Eur\u5c0f\u65f6\u7ea7\u80fd\u6e90\u7cfb\u7edf\u6a21\u578b\uff0c\u901a\u8fc7\u53cc\u5411\u4ef7\u683c\u8fed\u4ee3\u8f6f\u8026\u5408\u65b9\u6cd5\uff0c\u4f18\u5316\u957f\u671f\u6295\u8d44\u548c\u77ed\u671f\u8fd0\u8425\uff0c\u9a8c\u8bc1\u4e86\u5fb7\u56fd2045\u5e74\u5b9e\u73b0\u6c14\u5019\u4e2d\u6027\u7684100%\u53ef\u518d\u751f\u80fd\u6e90\u7535\u529b\u7cfb\u7edf\u7684\u6280\u672f\u53ef\u884c\u6027\u548c\u7ecf\u6d4e\u53ef\u884c\u6027\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u8981\u4e48\u7f3a\u4e4f\u957f\u671f\u8f6c\u578b\u8def\u5f84\u6240\u9700\u7684\u5e7f\u6cdb\u8303\u56f4\uff0c\u8981\u4e48\u7f3a\u4e4f\u6355\u6349\u7535\u529b\u7cfb\u7edf\u53ef\u53d8\u6027\u548c\u7075\u6d3b\u6027\u7684\u65f6\u7a7a\u7ec6\u8282\uff0c\u9700\u8981\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u6765\u4f18\u5316\u80fd\u6e90\u7cfb\u7edf\u89c4\u5212\u3002", "method": "\u91c7\u7528REMIND\u548cPyPSA-Eur\u7684\u53cc\u5411\u4ef7\u683c\u8fed\u4ee3\u8f6f\u8026\u5408\u65b9\u6cd5\uff0cREMIND\u63d0\u4f9b\u8def\u5f84\u53d8\u91cf\u5982\u90e8\u95e8\u7535\u529b\u9700\u6c42\u3001\u88c5\u673a\u5bb9\u91cf\u548c\u6210\u672c\uff0cPyPSA-Eur\u8fd4\u56de\u4f18\u5316\u8fd0\u8425\u53d8\u91cf\u5982\u5bb9\u91cf\u56e0\u5b50\u3001\u5b58\u50a8\u9700\u6c42\u548c\u76f8\u5bf9\u4ef7\u683c\u3002", "result": "\u9a8c\u8bc1\u4e86100%\u53ef\u518d\u751f\u80fd\u6e90\u7535\u529b\u7cfb\u7edf\u7684\u53ef\u884c\u6027\uff0c\u7075\u6d3b\u7535\u89e3\u69fd\u548c\u667a\u80fd\u5145\u7535\u7535\u52a8\u6c7d\u8f66\u53d7\u76ca\u4e8e\u4f4e\u4e8e\u5e73\u5747\u4ef7\u683c\uff0c\u800c\u7075\u6d3b\u6027\u8f83\u5dee\u7684\u70ed\u6cf5\u9762\u4e34\u51e0\u4e4e\u4e24\u500d\u5e73\u5747\u4ef7\u683c\u3002\u65e0\u9700\u6c42\u4fa7\u7075\u6d3b\u6027\u65f6\u7535\u4ef7\u666e\u904d\u4e0a\u6da8\uff0c\u4f46\u7535\u6c60\u90e8\u7f72\u53ef\u90e8\u5206\u8865\u507f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c06\u7535\u529b\u7cfb\u7edf\u52a8\u6001\u5b8c\u5168\u6574\u5408\u5230\u591a\u5341\u5e74\u80fd\u6e90\u8f6c\u578b\u8def\u5f84\u4e2d\uff0c\u8bc1\u660e\u4e86\u4ef7\u683c\u5dee\u5f02\u5316\u5728\u5f15\u5bfc\u957f\u671f\u8def\u5f84\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2510.04391", "categories": ["cs.AI", "cs.CL", "cs.SI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.04391", "abs": "https://arxiv.org/abs/2510.04391", "authors": ["Saurabh Ranjan", "Brian Odegaard"], "title": "Internal World Models as Imagination Networks in Cognitive Agents", "comment": null, "summary": "What is the computational objective of imagination? While classical\ninterpretations suggest imagination is useful for maximizing rewards, recent\nfindings challenge this view. In this study, we propose that imagination serves\nto access an internal world model (IWM) and use psychological network analysis\nto explore IWMs in humans and large language models (LLMs). Specifically, we\nassessed imagination vividness ratings using two questionnaires and constructed\nimagination networks from these reports. Imagination networks from human groups\nshowed correlations between different centrality measures, including expected\ninfluence, strength, and closeness. However, imagination networks from LLMs\nshowed a lack of clustering and lower correlations between centrality measures\nunder different prompts and conversational memory conditions. Together, these\nresults indicate a lack of similarity between IWMs in human and LLM agents.\nOverall, our study offers a novel method for comparing internally-generated\nrepresentations in humans and AI, providing insights for developing human-like\nimagination in artificial intelligence.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u60f3\u8c61\u7684\u8ba1\u7b97\u76ee\u6807\u662f\u8bbf\u95ee\u5185\u90e8\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u5fc3\u7406\u7f51\u7edc\u5206\u6790\u6bd4\u8f83\u4eba\u7c7b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u60f3\u8c61\u7f51\u7edc\uff0c\u53d1\u73b0\u4e24\u8005\u5728\u5185\u90e8\u4e16\u754c\u6a21\u578b\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u63a2\u7d22\u60f3\u8c61\u7684\u8ba1\u7b97\u76ee\u6807\uff0c\u6311\u6218\u4f20\u7edf\u8ba4\u4e3a\u60f3\u8c61\u4e3b\u8981\u7528\u4e8e\u6700\u5927\u5316\u5956\u52b1\u7684\u89c2\u70b9\uff0c\u7814\u7a76\u4eba\u7c7b\u548cAI\u7684\u5185\u90e8\u4e16\u754c\u6a21\u578b\u5dee\u5f02\u3002", "method": "\u4f7f\u7528\u5fc3\u7406\u7f51\u7edc\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u4efd\u95ee\u5377\u8bc4\u4f30\u60f3\u8c61\u751f\u52a8\u6027\u8bc4\u5206\uff0c\u6784\u5efa\u4eba\u7c7b\u548cLLMs\u7684\u60f3\u8c61\u7f51\u7edc\uff0c\u6bd4\u8f83\u4e0d\u540c\u4e2d\u5fc3\u6027\u6307\u6807\u7684\u5173\u8054\u6027\u3002", "result": "\u4eba\u7c7b\u60f3\u8c61\u7f51\u7edc\u663e\u793a\u4e0d\u540c\u4e2d\u5fc3\u6027\u6307\u6807\u95f4\u5b58\u5728\u76f8\u5173\u6027\uff0c\u800cLLMs\u7684\u60f3\u8c61\u7f51\u7edc\u7f3a\u4e4f\u805a\u7c7b\u4e14\u4e2d\u5fc3\u6027\u6307\u6807\u95f4\u76f8\u5173\u6027\u8f83\u4f4e\uff0c\u8868\u660e\u4e24\u8005\u5185\u90e8\u4e16\u754c\u6a21\u578b\u76f8\u4f3c\u5ea6\u4f4e\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u6bd4\u8f83\u4eba\u7c7b\u548cAI\u5185\u90e8\u751f\u6210\u8868\u5f81\u7684\u65b0\u65b9\u6cd5\uff0c\u4e3a\u5f00\u53d1\u7c7b\u4eba\u60f3\u8c61\u7684\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2510.03368", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03368", "abs": "https://arxiv.org/abs/2510.03368", "authors": ["Kiana Jafari Meimandi", "Anka Reuel", "Gabriela Aranguiz-Dias", "Hatim Rahama", "Ala-Eddine Ayadi", "Xavier Boullier", "J\u00e9r\u00e9my Verdo", "Louis Montanie", "Mykel Kochenderfer"], "title": "An Adaptive Responsible AI Governance Framework for Decentralized Organizations", "comment": null, "summary": "This paper examines the assessment challenges of Responsible AI (RAI)\ngovernance efforts in globally decentralized organizations through a case study\ncollaboration between a leading research university and a multinational\nenterprise. While there are many proposed frameworks for RAI, their application\nin complex organizational settings with distributed decision-making authority\nremains underexplored. Our RAI assessment, conducted across multiple business\nunits and AI use cases, reveals four key patterns that shape RAI\nimplementation: (1) complex interplay between group-level guidance and local\ninterpretation, (2) challenges translating abstract principles into operational\npractices, (3) regional and functional variation in implementation approaches,\nand (4) inconsistent accountability in risk oversight. Based on these findings,\nwe propose an Adaptive RAI Governance (ARGO) Framework that balances central\ncoordination with local autonomy through three interdependent layers: shared\nfoundation standards, central advisory resources, and contextual local\nimplementation. We contribute insights from academic-industry collaboration for\nRAI assessments, highlighting the importance of modular governance approaches\nthat accommodate organizational complexity while maintaining alignment with\nresponsible AI principles. These lessons offer practical guidance for\norganizations navigating the transition from RAI principles to operational\npractice within decentralized structures.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5927\u5b66\u4e0e\u4f01\u4e1a\u5408\u4f5c\u6848\u4f8b\u7814\u7a76\uff0c\u63a2\u8ba8\u5168\u7403\u5206\u6563\u7ec4\u7ec7\u4e2d\u8d1f\u8d23\u4efbAI\u6cbb\u7406\u7684\u8bc4\u4f30\u6311\u6218\uff0c\u63d0\u51fa\u81ea\u9002\u5e94RAI\u6cbb\u7406\u6846\u67b6\uff08ARGO\uff09\uff0c\u5e73\u8861\u4e2d\u592e\u534f\u8c03\u4e0e\u5730\u65b9\u81ea\u6cbb\u3002", "motivation": "\u73b0\u6709RAI\u6846\u67b6\u5728\u5177\u6709\u5206\u5e03\u5f0f\u51b3\u7b56\u6743\u7684\u590d\u6742\u7ec4\u7ec7\u73af\u5883\u4e2d\u5e94\u7528\u4e0d\u8db3\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u5728\u5b9e\u9645\u7ec4\u7ec7\u73af\u5883\u4e2d\u5b9e\u65bdRAI\u6cbb\u7406\u3002", "method": "\u91c7\u7528\u6848\u4f8b\u7814\u7a76\u65b9\u6cd5\uff0c\u5728\u8de8\u56fd\u4f01\u4e1a\u7684\u591a\u4e2a\u4e1a\u52a1\u90e8\u95e8\u548cAI\u7528\u4f8b\u4e2d\u8fdb\u884cRAI\u8bc4\u4f30\uff0c\u8bc6\u522b\u5173\u952e\u5b9e\u65bd\u6a21\u5f0f\u3002", "result": "\u53d1\u73b0\u56db\u4e2a\u5173\u952e\u6a21\u5f0f\uff1a\u96c6\u56e2\u6307\u5bfc\u4e0e\u5730\u65b9\u89e3\u8bfb\u7684\u590d\u6742\u4e92\u52a8\u3001\u62bd\u8c61\u539f\u5219\u8f6c\u5316\u4e3a\u64cd\u4f5c\u5b9e\u8df5\u7684\u6311\u6218\u3001\u5b9e\u65bd\u65b9\u6cd5\u7684\u533a\u57df\u548c\u804c\u80fd\u5dee\u5f02\u3001\u98ce\u9669\u76d1\u7763\u8d23\u4efb\u4e0d\u4e00\u81f4\u3002\u57fa\u4e8e\u6b64\u63d0\u51faARGO\u6846\u67b6\u3002", "conclusion": "\u6a21\u5757\u5316\u6cbb\u7406\u65b9\u6cd5\u80fd\u591f\u9002\u5e94\u7ec4\u7ec7\u590d\u6742\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u8d1f\u8d23\u4efbAI\u539f\u5219\u7684\u4e00\u81f4\u6027\uff0c\u4e3a\u4eceRAI\u539f\u5219\u5411\u64cd\u4f5c\u5b9e\u8df5\u8fc7\u6e21\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2510.03453", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03453", "abs": "https://arxiv.org/abs/2510.03453", "authors": ["Paul S. Rosenbloom"], "title": "A Qualitative Comparative Evaluation of Cognitive and Generative Theories", "comment": "To appear in Proceedings of the 12th Annual Conference on Advances in\n  Cognitive Systems (ACS-25)", "summary": "Evaluation is a critical activity associated with any theory. Yet this has\nproven to be an exceptionally challenging activity for theories based on\ncognitive architectures. For an overlapping set of reasons, evaluation can also\nbe challenging for theories based on generative neural architectures. This dual\nchallenge is approached here by leveraging a broad perspective on theory\nevaluation to yield a wide-ranging, albeit qualitative, comparison of\nwhole-mind-oriented cognitive and generative architectures and the full systems\nthat are based on these architectures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u8ba4\u77e5\u67b6\u6784\u548c\u751f\u6210\u5f0f\u795e\u7ecf\u67b6\u6784\u7406\u8bba\u7684\u5b9a\u6027\u6bd4\u8f83\u6846\u67b6", "motivation": "\u8ba4\u77e5\u67b6\u6784\u7406\u8bba\u548c\u751f\u6210\u5f0f\u795e\u7ecf\u67b6\u6784\u7406\u8bba\u90fd\u9762\u4e34\u8bc4\u4f30\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6cd5", "method": "\u91c7\u7528\u5e7f\u6cdb\u7684\u7406\u8bba\u8bc4\u4f30\u89c6\u89d2\uff0c\u5bf9\u9762\u5411\u5168\u8111\u7684\u8ba4\u77e5\u67b6\u6784\u548c\u751f\u6210\u5f0f\u67b6\u6784\u53ca\u5176\u5b8c\u6574\u7cfb\u7edf\u8fdb\u884c\u5b9a\u6027\u6bd4\u8f83", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5bbd\u6cdb\u4f46\u5b9a\u6027\u7684\u6bd4\u8f83\u6846\u67b6\u6765\u8bc4\u4f30\u4e0d\u540c\u7c7b\u578b\u7684\u67b6\u6784\u7406\u8bba", "conclusion": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u7406\u8bba\u8bc4\u4f30\u89c6\u89d2\u53ef\u4ee5\u6709\u6548\u5730\u6bd4\u8f83\u548c\u8bc4\u4f30\u8ba4\u77e5\u67b6\u6784\u4e0e\u751f\u6210\u5f0f\u795e\u7ecf\u67b6\u6784"}}
{"id": "2510.03497", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03497", "abs": "https://arxiv.org/abs/2510.03497", "authors": ["Hao Tu", "Yebin Wang", "Shaoshuai Mou", "Huazhen Fang"], "title": "Machine Learning-Driven Prediction of Lithium-Ion Battery Power Capability for eVTOL Aircraft", "comment": "2025 American Control Conference (ACC)", "summary": "Electric vertical take-off and landing (eVTOL) aircraft have emerged as a\npromising solution to transform urban transportation. They present a few\ntechnical challenges for battery management, a prominent one of which is the\nprediction of the power capability of their lithium-ion battery systems. The\nchallenge originates from the high C-rate discharging conditions required\nduring eVTOL flights as well as the complexity of lithium-ion batteries'\nelectro-thermal dynamics. This paper, for the first time, formulates a power\nlimit prediction problem for eVTOL which explicitly considers long prediction\nhorizons and the possible occurrence of emergency landings. We then harness\nmachine learning to solve this problem in two intertwined ways. First, we adopt\na dynamic model that integrates physics with machine learning to predict a\nlithium-ion battery's voltage and temperature behaviors with high accuracy.\nSecond, while performing search for the maximum power, we leverage machine\nlearning to predict the remaining discharge time and use the prediction to\naccelerate the search with fast computation. Our validation results show the\neffectiveness of the proposed study for eVTOL operations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7535\u52a8\u5782\u76f4\u8d77\u964d\u98de\u673a(eVTOL)\u7684\u7535\u6c60\u529f\u7387\u9650\u5236\u9884\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u7269\u7406\u6a21\u578b\u548c\u673a\u5668\u5b66\u4e60\u6765\u51c6\u786e\u9884\u6d4b\u9502\u7535\u6c60\u5728\u9ad8\u653e\u7535\u7387\u4e0b\u7684\u7535\u538b\u548c\u6e29\u5ea6\u884c\u4e3a\uff0c\u5e76\u52a0\u901f\u6700\u5927\u529f\u7387\u641c\u7d22\u8fc7\u7a0b\u3002", "motivation": "eVTOL\u98de\u673a\u5728\u98de\u884c\u8fc7\u7a0b\u4e2d\u9700\u8981\u9ad8\u653e\u7535\u7387\u7684\u7535\u6c60\u7cfb\u7edf\uff0c\u4f46\u9502\u7535\u6c60\u7684\u7535\u70ed\u52a8\u529b\u5b66\u590d\u6742\uff0c\u4e14\u9700\u8981\u8003\u8651\u957f\u9884\u6d4b\u65f6\u95f4\u8303\u56f4\u548c\u7d27\u6025\u7740\u9646\u7684\u53ef\u80fd\u6027\uff0c\u8fd9\u7ed9\u7535\u6c60\u529f\u7387\u80fd\u529b\u9884\u6d4b\u5e26\u6765\u4e86\u6280\u672f\u6311\u6218\u3002", "method": "\u91c7\u7528\u7ed3\u5408\u7269\u7406\u5b66\u548c\u673a\u5668\u5b66\u4e60\u7684\u52a8\u6001\u6a21\u578b\u6765\u9884\u6d4b\u9502\u7535\u6c60\u7684\u7535\u538b\u548c\u6e29\u5ea6\u884c\u4e3a\uff1b\u540c\u65f6\u5229\u7528\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u5269\u4f59\u653e\u7535\u65f6\u95f4\uff0c\u4ee5\u52a0\u901f\u6700\u5927\u529f\u7387\u641c\u7d22\u8fc7\u7a0b\u3002", "result": "\u9a8c\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5bf9eVTOL\u64cd\u4f5c\u6709\u6548\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u4e3aeVTOL\u5236\u5b9a\u4e86\u8003\u8651\u957f\u9884\u6d4b\u65f6\u95f4\u8303\u56f4\u548c\u7d27\u6025\u7740\u9646\u53ef\u80fd\u6027\u7684\u529f\u7387\u9650\u5236\u9884\u6d4b\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\u3002"}}
{"id": "2510.03472", "categories": ["cs.RO", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.03472", "abs": "https://arxiv.org/abs/2510.03472", "authors": ["Yulun Zhang", "Alexandre O. G. Barbosa", "Federico Pecora", "Jiaoyang Li"], "title": "Destination-to-Chutes Task Mapping Optimization for Multi-Robot Coordination in Robotic Sorting Systems", "comment": "Accepted to IEEE International Symposium on Multi-Robot and\n  Multi-Agent Systems (MRS) 2025", "summary": "We study optimizing a destination-to-chutes task mapping to improve\nthroughput in Robotic Sorting Systems (RSS), where a team of robots sort\npackages on a sortation floor by transporting them from induct workstations to\neject chutes based on their shipping destinations (e.g. Los Angeles or\nPittsburgh). The destination-to-chutes task mapping is used to determine which\nchutes a robot can drop its package. Finding a high-quality task mapping is\nchallenging because of the complexity of a real-world RSS. First, optimizing\ntask mapping is interdependent with robot target assignment and path planning.\nSecond, chutes will be CLOSED for a period of time once they receive sufficient\npackages to allow for downstream processing. Third, task mapping quality\ndirectly impacts the downstream processing, as scattered chutes for the same\ndestination increase package handling time. In this paper, we first formally\ndefine task mappings and the problem of Task Mapping Optimization (TMO). We\nthen present a simulator of RSS to evaluate task mappings. We then present a\nsimple TMO method based on the Evolutionary Algorithm and Mixed Integer Linear\nProgramming, demonstrating the advantage of our optimized task mappings over\nthe greedily generated ones in various RSS setups with different map sizes,\nnumbers of chutes, and destinations. Finally, we use Quality Diversity\nalgorithms to analyze the throughput of a diverse set of task mappings. Our\ncode is available online at https://github.com/lunjohnzhang/tmo_public.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u673a\u5668\u4eba\u5206\u62e3\u7cfb\u7edf\u4e2d\u76ee\u7684\u5730\u5230\u6ed1\u69fd\u4efb\u52a1\u6620\u5c04\u7684\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u8fdb\u5316\u7b97\u6cd5\u548c\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u65b9\u6cd5\u63d0\u5347\u7cfb\u7edf\u541e\u5410\u91cf\uff0c\u5e76\u5728\u4e0d\u540c\u7cfb\u7edf\u8bbe\u7f6e\u4e0b\u9a8c\u8bc1\u4e86\u4f18\u5316\u6620\u5c04\u4f18\u4e8e\u8d2a\u5a6a\u65b9\u6cd5\u3002", "motivation": "\u4f18\u5316\u76ee\u7684\u5730\u5230\u6ed1\u69fd\u7684\u4efb\u52a1\u6620\u5c04\u5bf9\u4e8e\u63d0\u9ad8\u673a\u5668\u4eba\u5206\u62e3\u7cfb\u7edf\u541e\u5410\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9762\u4e34\u4e09\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u4efb\u52a1\u6620\u5c04\u4e0e\u673a\u5668\u4eba\u76ee\u6807\u5206\u914d\u548c\u8def\u5f84\u89c4\u5212\u7684\u76f8\u4e92\u4f9d\u8d56\u3001\u6ed1\u69fd\u5728\u63a5\u6536\u8db3\u591f\u5305\u88f9\u540e\u4f1a\u6682\u65f6\u5173\u95ed\u3001\u4ee5\u53ca\u4efb\u52a1\u6620\u5c04\u8d28\u91cf\u76f4\u63a5\u5f71\u54cd\u4e0b\u6e38\u5904\u7406\u6548\u7387\u3002", "method": "\u9996\u5148\u6b63\u5f0f\u5b9a\u4e49\u4e86\u4efb\u52a1\u6620\u5c04\u548c\u4efb\u52a1\u6620\u5c04\u4f18\u5316\u95ee\u9898\uff0c\u7136\u540e\u5f00\u53d1\u4e86\u673a\u5668\u4eba\u5206\u62e3\u7cfb\u7edf\u6a21\u62df\u5668\u8fdb\u884c\u8bc4\u4f30\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u8fdb\u5316\u7b97\u6cd5\u548c\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u7684\u7b80\u5355\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528\u8d28\u91cf\u591a\u6837\u6027\u7b97\u6cd5\u5206\u6790\u591a\u6837\u5316\u4efb\u52a1\u6620\u5c04\u7684\u541e\u5410\u91cf\u3002", "result": "\u5728\u5404\u79cd\u4e0d\u540c\u5730\u56fe\u5927\u5c0f\u3001\u6ed1\u69fd\u6570\u91cf\u548c\u76ee\u7684\u5730\u7684\u673a\u5668\u4eba\u5206\u62e3\u7cfb\u7edf\u8bbe\u7f6e\u4e2d\uff0c\u4f18\u5316\u7684\u4efb\u52a1\u6620\u5c04\u76f8\u6bd4\u8d2a\u5a6a\u751f\u6210\u7684\u65b9\u6cd5\u5c55\u73b0\u51fa\u660e\u663e\u4f18\u52bf\uff0c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u541e\u5410\u91cf\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u4efb\u52a1\u6620\u5c04\u4f18\u5316\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u673a\u5668\u4eba\u5206\u62e3\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u8d28\u91cf\u591a\u6837\u6027\u7b97\u6cd5\u6709\u52a9\u4e8e\u5206\u6790\u4e0d\u540c\u4efb\u52a1\u6620\u5c04\u5bf9\u541e\u5410\u91cf\u7684\u5f71\u54cd\uff0c\u4e3a\u5b9e\u9645\u7cfb\u7edf\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2510.04726", "categories": ["econ.GN", "cs.LG", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.04726", "abs": "https://arxiv.org/abs/2510.04726", "authors": ["Miguel Alves Pereira"], "title": "Predictive economics: Rethinking economic methodology with machine learning", "comment": "8 pages", "summary": "This article proposes predictive economics as a distinct analytical\nperspective within economics, grounded in machine learning and centred on\npredictive accuracy rather than causal identification. Drawing on the\ninstrumentalist tradition (Friedman), the explanation-prediction divide\n(Shmueli), and the contrast between modelling cultures (Breiman), we formalise\nprediction as a valid epistemological and methodological objective. Reviewing\nrecent applications across economic subfields, we show how predictive models\ncontribute to empirical analysis, particularly in complex or data-rich\ncontexts. This perspective complements existing approaches and supports a more\npluralistic methodology - one that values out-of-sample performance alongside\ninterpretability and theoretical structure.", "AI": {"tldr": "\u63d0\u51fa\u9884\u6d4b\u7ecf\u6d4e\u5b66\u4f5c\u4e3a\u7ecf\u6d4e\u5b66\u4e2d\u7684\u4e00\u4e2a\u72ec\u7279\u5206\u6790\u89c6\u89d2\uff0c\u4ee5\u673a\u5668\u5b66\u4e60\u4e3a\u57fa\u7840\uff0c\u5173\u6ce8\u9884\u6d4b\u51c6\u786e\u6027\u800c\u975e\u56e0\u679c\u8bc6\u522b", "motivation": "\u57fa\u4e8e\u5de5\u5177\u4e3b\u4e49\u4f20\u7edf\u3001\u89e3\u91ca-\u9884\u6d4b\u4e8c\u5206\u6cd5\u4ee5\u53ca\u5efa\u6a21\u6587\u5316\u5bf9\u6bd4\uff0c\u5c06\u9884\u6d4b\u5f62\u5f0f\u5316\u4e3a\u6709\u6548\u7684\u8ba4\u8bc6\u8bba\u548c\u65b9\u6cd5\u8bba\u76ee\u6807", "method": "\u56de\u987e\u7ecf\u6d4e\u5b66\u5b50\u9886\u57df\u4e2d\u7684\u6700\u65b0\u5e94\u7528\uff0c\u5c55\u793a\u9884\u6d4b\u6a21\u578b\u5982\u4f55\u4fc3\u8fdb\u5b9e\u8bc1\u5206\u6790\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u6216\u6570\u636e\u4e30\u5bcc\u7684\u80cc\u666f\u4e0b", "result": "\u9884\u6d4b\u6a21\u578b\u5728\u5b9e\u8bc1\u5206\u6790\u4e2d\u53d1\u6325\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u6216\u6570\u636e\u4e30\u5bcc\u7684\u73af\u5883\u4e2d", "conclusion": "\u8fd9\u4e00\u89c6\u89d2\u8865\u5145\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u652f\u6301\u66f4\u52a0\u591a\u5143\u5316\u7684\u65b9\u6cd5\u8bba\u2014\u2014\u91cd\u89c6\u6837\u672c\u5916\u6027\u80fd\u4ee5\u53ca\u53ef\u89e3\u91ca\u6027\u548c\u7406\u8bba\u7ed3\u6784"}}
{"id": "2510.03369", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03369", "abs": "https://arxiv.org/abs/2510.03369", "authors": ["Huazhen Wang", "Huimin Yang", "Hainbin Lin", "Yan Dong", "Lili Chen", "Liangliang Xia", "Wenwen Xu"], "title": "TriQuest:An AI Copilot-Powered Platform for Interdisciplinary Curriculum Design", "comment": "16 pages, 4 figures", "summary": "Interdisciplinary teaching is a cornerstone of modern curriculum reform, but\nits implementation is hindered by challenges in knowledge integration and\ntime-consuming lesson planning. Existing tools often lack the required\npedagogical and domain-specific depth.We introduce TriQuest, an AI-copilot\nplatform designed to solve these problems. TriQuest uses large language models\nand knowledge graphs via an intuitive GUI to help teachers efficiently generate\nhigh-quality interdisciplinary lesson plans. Its core features include\nintelligent knowledge integration from various disciplines and a human-computer\ncollaborative review process to ensure quality and innovation.In a study with\n43 teachers, TriQuest increased curriculum design efficiency by an average of\n75% and improved lesson plan quality scores by 41%. It also significantly\nlowered design barriers and cognitive load. Our work presents a new paradigm\nfor empowering teacher professional development with intelligent technologies.", "AI": {"tldr": "TriQuest\u662f\u4e00\u4e2aAI\u8f85\u52a9\u5e73\u53f0\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u77e5\u8bc6\u56fe\u8c31\u5e2e\u52a9\u6559\u5e08\u9ad8\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u8de8\u5b66\u79d1\u6559\u6848\uff0c\u63d0\u9ad8\u8bfe\u7a0b\u8bbe\u8ba1\u6548\u738775%\uff0c\u6559\u6848\u8d28\u91cf\u8bc4\u5206\u63d0\u534741%\u3002", "motivation": "\u8de8\u5b66\u79d1\u6559\u5b66\u662f\u73b0\u4ee3\u8bfe\u7a0b\u6539\u9769\u7684\u6838\u5fc3\uff0c\u4f46\u5728\u77e5\u8bc6\u6574\u5408\u548c\u6559\u6848\u8bbe\u8ba1\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u73b0\u6709\u5de5\u5177\u7f3a\u4e4f\u8db3\u591f\u7684\u6559\u5b66\u548c\u9886\u57df\u6df1\u5ea6\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u77e5\u8bc6\u56fe\u8c31\uff0c\u901a\u8fc7\u76f4\u89c2\u7684GUI\u754c\u9762\uff0c\u5b9e\u73b0\u591a\u5b66\u79d1\u77e5\u8bc6\u7684\u667a\u80fd\u6574\u5408\uff0c\u5e76\u91c7\u7528\u4eba\u673a\u534f\u4f5c\u7684\u5ba1\u67e5\u6d41\u7a0b\u786e\u4fdd\u8d28\u91cf\u548c\u521b\u65b0\u6027\u3002", "result": "\u572843\u540d\u6559\u5e08\u7684\u7814\u7a76\u4e2d\uff0c\u8bfe\u7a0b\u8bbe\u8ba1\u6548\u7387\u5e73\u5747\u63d0\u9ad875%\uff0c\u6559\u6848\u8d28\u91cf\u8bc4\u5206\u63d0\u534741%\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bbe\u8ba1\u969c\u788d\u548c\u8ba4\u77e5\u8d1f\u8377\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5229\u7528\u667a\u80fd\u6280\u672f\u8d4b\u80fd\u6559\u5e08\u4e13\u4e1a\u53d1\u5c55\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2510.03469", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.03469", "abs": "https://arxiv.org/abs/2510.03469", "authors": ["Keshav Ramani", "Vali Tawosi", "Salwa Alamir", "Daniel Borrajo"], "title": "Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification", "comment": null, "summary": "We introduce a novel framework for evaluating the alignment between natural\nlanguage plans and their expected behavior by converting them into Kripke\nstructures and Linear Temporal Logic (LTL) using Large Language Models (LLMs)\nand performing model checking. We systematically evaluate this framework on a\nsimplified version of the PlanBench plan verification dataset and report on\nmetrics like Accuracy, Precision, Recall and F1 scores. Our experiments\ndemonstrate that GPT-5 achieves excellent classification performance (F1 score\nof 96.3%) while almost always producing syntactically perfect formal\nrepresentations that can act as guarantees. However, the synthesis of\nsemantically perfect formal models remains an area for future exploration.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5c06\u81ea\u7136\u8bed\u8a00\u8ba1\u5212\u8f6c\u6362\u4e3aKripke\u7ed3\u6784\u548c\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91(LTL)\u6765\u8bc4\u4f30\u8ba1\u5212\u4e0e\u9884\u671f\u884c\u4e3a\u5bf9\u9f50\u7684\u65b0\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6a21\u578b\u68c0\u67e5\u3002", "motivation": "\u9700\u8981\u8bc4\u4f30\u81ea\u7136\u8bed\u8a00\u8ba1\u5212\u4e0e\u5176\u9884\u671f\u884c\u4e3a\u4e4b\u95f4\u7684\u5bf9\u9f50\u5173\u7cfb\uff0c\u786e\u4fdd\u8ba1\u5212\u6267\u884c\u7684\u6b63\u786e\u6027\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u81ea\u7136\u8bed\u8a00\u8ba1\u5212\u8f6c\u6362\u4e3aKripke\u7ed3\u6784\u548cLTL\u516c\u5f0f\uff0c\u7136\u540e\u8fdb\u884c\u6a21\u578b\u68c0\u67e5\uff0c\u5728PlanBench\u6570\u636e\u96c6\u7b80\u5316\u7248\u4e0a\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "GPT-5\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02(F1\u5f97\u520696.3%)\uff0c\u51e0\u4e4e\u603b\u80fd\u751f\u6210\u8bed\u6cd5\u5b8c\u7f8e\u7684\u5f62\u5f0f\u5316\u8868\u793a\uff0c\u53ef\u4f5c\u4e3a\u4fdd\u8bc1\u3002", "conclusion": "\u6846\u67b6\u5728\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u7684\u5f62\u5f0f\u5316\u6a21\u578b\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u8bed\u4e49\u5b8c\u7f8e\u5f62\u5f0f\u5316\u6a21\u578b\u7684\u5408\u6210\u4ecd\u9700\u672a\u6765\u63a2\u7d22\u3002"}}
{"id": "2510.03609", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03609", "abs": "https://arxiv.org/abs/2510.03609", "authors": ["Juho Bae", "Daegyeong Roh", "Han-Lim Choi"], "title": "Learning Safety-Compatible Observers for Unknown Systems", "comment": "Submitted to American Control Conference (ACC)", "summary": "This paper presents a data-driven approach for jointly learning a robust\nfull-state observer and its robustness certificate for systems with unknown\ndynamics. Leveraging incremental input-to-state stability (delta ISS) notions,\nwe jointly learn a delta ISS Lyapunov function that serves as the robustness\ncertificate and prove practical convergence of the estimation error under\nstandard fidelity assumptions on the learned models. This renders the observer\nsafety-compatible: they can be consumed by certificate-based safe controllers\nso that, when the controller tolerates bounded estimation error, the\ncontroller's certificate remains valid under output feedback. We further extend\nthe approach to interconnected systems via the small-gain theorem, yielding a\ndistributed observer design framework. We validate the approach on a variety of\nnonlinear systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8054\u5408\u5b66\u4e60\u5177\u6709\u672a\u77e5\u52a8\u529b\u5b66\u7cfb\u7edf\u7684\u9c81\u68d2\u5168\u72b6\u6001\u89c2\u6d4b\u5668\u53ca\u5176\u9c81\u68d2\u6027\u8bc1\u4e66\u3002", "motivation": "\u9488\u5bf9\u5177\u6709\u672a\u77e5\u52a8\u529b\u5b66\u7684\u7cfb\u7edf\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u63d0\u4f9b\u9c81\u68d2\u6027\u4fdd\u8bc1\u7684\u72b6\u6001\u89c2\u6d4b\u5668\uff0c\u4ee5\u4fbf\u4e0e\u57fa\u4e8e\u8bc1\u4e66\u7684\u5b89\u5168\u63a7\u5236\u5668\u517c\u5bb9\u4f7f\u7528\u3002", "method": "\u5229\u7528\u589e\u91cf\u8f93\u5165\u5230\u72b6\u6001\u7a33\u5b9a\u6027\u6982\u5ff5\uff0c\u8054\u5408\u5b66\u4e60\u589e\u91cfISS\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\u4f5c\u4e3a\u9c81\u68d2\u6027\u8bc1\u4e66\uff0c\u5e76\u5728\u5b66\u4e60\u6a21\u578b\u6ee1\u8db3\u6807\u51c6\u4fdd\u771f\u5ea6\u5047\u8bbe\u4e0b\u8bc1\u660e\u4f30\u8ba1\u8bef\u5dee\u7684\u5b9e\u9645\u6536\u655b\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u4f7f\u5f97\u89c2\u6d4b\u5668\u5177\u6709\u5b89\u5168\u517c\u5bb9\u6027\uff0c\u80fd\u591f\u88ab\u57fa\u4e8e\u8bc1\u4e66\u7684\u5b89\u5168\u63a7\u5236\u5668\u4f7f\u7528\uff0c\u5e76\u4e14\u901a\u8fc7\u5c0f\u589e\u76ca\u5b9a\u7406\u6269\u5c55\u5230\u4e92\u8054\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u5206\u5e03\u5f0f\u89c2\u6d4b\u5668\u8bbe\u8ba1\u6846\u67b6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u591a\u79cd\u975e\u7ebf\u6027\u7cfb\u7edf\u4e0a\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u4e3a\u672a\u77e5\u52a8\u529b\u5b66\u7cfb\u7edf\u7684\u5b89\u5168\u72b6\u6001\u4f30\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03481", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.03481", "abs": "https://arxiv.org/abs/2510.03481", "authors": ["Khang Vo Huynh", "David Parker", "Lu Feng"], "title": "Robust Permissive Controller Synthesis for Interval MDPs", "comment": null, "summary": "We address the problem of robust permissive controller synthesis for robots\noperating under uncertain dynamics, modeled as Interval Markov Decision\nProcesses (IMDPs). IMDPs generalize standard MDPs by allowing transition\nprobabilities to vary within intervals, capturing epistemic uncertainty from\nsensing noise, actuation imprecision, and coarse system abstractions-common in\nrobotics. Traditional controller synthesis typically yields a single\ndeterministic strategy, limiting adaptability. In contrast, permissive\ncontrollers (multi-strategies) allow multiple actions per state, enabling\nruntime flexibility and resilience. However, prior work on permissive\ncontroller synthesis generally assumes exact transition probabilities, which is\nunrealistic in many robotic applications. We present the first framework for\nrobust permissive controller synthesis on IMDPs, guaranteeing that all\nstrategies compliant with the synthesized multi-strategy satisfy reachability\nor reward-based specifications under all admissible transitions. We formulate\nthe problem as mixed-integer linear programs (MILPs) and propose two encodings:\na baseline vertex-enumeration method and a scalable duality-based method that\navoids explicit enumeration. Experiments on four benchmark domains show that\nboth methods synthesize robust, maximally permissive controllers and scale to\nlarge IMDPs with up to hundreds of thousands of states.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u5728\u533a\u95f4\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(IMDPs)\u4e0a\u5408\u6210\u9c81\u68d2\u6027\u5141\u8bb8\u63a7\u5236\u5668\u7684\u6846\u67b6\uff0c\u4fdd\u8bc1\u6240\u6709\u7b26\u5408\u5408\u6210\u591a\u7b56\u7565\u7684\u7b56\u7565\u5728\u6240\u6709\u5141\u8bb8\u8f6c\u79fb\u4e0b\u6ee1\u8db3\u53ef\u8fbe\u6027\u6216\u57fa\u4e8e\u5956\u52b1\u7684\u89c4\u8303\u3002", "motivation": "\u4f20\u7edf\u63a7\u5236\u5668\u5408\u6210\u901a\u5e38\u4ea7\u751f\u5355\u4e00\u786e\u5b9a\u6027\u7b56\u7565\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u3002\u5141\u8bb8\u63a7\u5236\u5668(\u591a\u7b56\u7565)\u5141\u8bb8\u6bcf\u4e2a\u72b6\u6001\u6709\u591a\u4e2a\u52a8\u4f5c\uff0c\u63d0\u4f9b\u8fd0\u884c\u65f6\u7075\u6d3b\u6027\u548c\u5f39\u6027\u3002\u4f46\u73b0\u6709\u5de5\u4f5c\u901a\u5e38\u5047\u8bbe\u7cbe\u786e\u8f6c\u79fb\u6982\u7387\uff0c\u8fd9\u5728\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u4e0d\u73b0\u5b9e\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212(MILPs)\uff0c\u63d0\u51fa\u4e24\u79cd\u7f16\u7801\u65b9\u6cd5\uff1a\u57fa\u7ebf\u9876\u70b9\u679a\u4e3e\u65b9\u6cd5\u548c\u53ef\u6269\u5c55\u7684\u5bf9\u5076\u65b9\u6cd5(\u907f\u514d\u663e\u5f0f\u679a\u4e3e)\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u9886\u57df\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e24\u79cd\u65b9\u6cd5\u90fd\u80fd\u5408\u6210\u9c81\u68d2\u3001\u6700\u5927\u5141\u8bb8\u7684\u63a7\u5236\u5668\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u5177\u6709\u6570\u5341\u4e07\u4e2a\u72b6\u6001\u7684\u5927\u578bIMDPs\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5728\u4e0d\u786e\u5b9a\u52a8\u6001\u4e0b\u8fd0\u884c\u7684\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u9996\u4e2a\u9c81\u68d2\u5141\u8bb8\u63a7\u5236\u5668\u5408\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u5904\u7406\u4e86\u8f6c\u79fb\u6982\u7387\u7684\u533a\u95f4\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2510.04906", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.04906", "abs": "https://arxiv.org/abs/2510.04906", "authors": ["Raphael Mu"], "title": "Hidden Actions and Hidden Information in Peer Review: A Dynamic Solution", "comment": null, "summary": "We develop a simple model of the scientific peer review process, in which\nauthors of varying ability invest to produce papers of varying quality, and\njournals evaluate papers based on a noisy signal, choosing to accept or reject\neach paper. We find that the first-best outcome is the limiting case as the\nevaluation technology is perfected, even though author type and effort are not\nknown to the journal. Then, we consider the case where journals allow authors\nto challenge an initial rejection, and find that this approach to peer review\nyields an outcome closer to the first best relative to the approach that does\nnot allow for such challenges.", "AI": {"tldr": "\u6784\u5efa\u4e86\u4e00\u4e2a\u79d1\u5b66\u540c\u884c\u8bc4\u5ba1\u7684\u7b80\u5355\u6a21\u578b\uff0c\u53d1\u73b0\u5f53\u5141\u8bb8\u4f5c\u8005\u5bf9\u521d\u6b65\u62d2\u7edd\u63d0\u51fa\u6311\u6218\u65f6\uff0c\u8bc4\u5ba1\u7ed3\u679c\u66f4\u63a5\u8fd1\u6700\u4f18\u72b6\u6001\u3002", "motivation": "\u7814\u7a76\u79d1\u5b66\u540c\u884c\u8bc4\u5ba1\u8fc7\u7a0b\u4e2d\uff0c\u4f5c\u8005\u80fd\u529b\u548c\u8bba\u6587\u8d28\u91cf\u8bc4\u4f30\u7684\u673a\u5236\uff0c\u4ee5\u53ca\u4e0d\u540c\u8bc4\u5ba1\u65b9\u5f0f\u5bf9\u6700\u7ec8\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7406\u8bba\u6a21\u578b\uff0c\u5176\u4e2d\u4e0d\u540c\u80fd\u529b\u7684\u4f5c\u8005\u6295\u5165\u52aa\u529b\u4ea7\u51fa\u4e0d\u540c\u8d28\u91cf\u7684\u8bba\u6587\uff0c\u671f\u520a\u57fa\u4e8e\u6709\u566a\u58f0\u7684\u4fe1\u53f7\u8bc4\u4f30\u5e76\u51b3\u5b9a\u63a5\u53d7\u6216\u62d2\u7edd\u8bba\u6587\u3002", "result": "\u5f53\u8bc4\u4f30\u6280\u672f\u8d8b\u4e8e\u5b8c\u7f8e\u65f6\uff0c\u5373\u4f7f\u671f\u520a\u4e0d\u77e5\u9053\u4f5c\u8005\u7c7b\u578b\u548c\u52aa\u529b\u7a0b\u5ea6\uff0c\u4e5f\u80fd\u8fbe\u5230\u6700\u4f18\u7ed3\u679c\u3002\u5141\u8bb8\u4f5c\u8005\u6311\u6218\u521d\u6b65\u62d2\u7edd\u7684\u8bc4\u5ba1\u65b9\u5f0f\u6bd4\u4e0d\u5141\u8bb8\u6311\u6218\u7684\u65b9\u5f0f\u66f4\u63a5\u8fd1\u6700\u4f18\u72b6\u6001\u3002", "conclusion": "\u5728\u540c\u884c\u8bc4\u5ba1\u8fc7\u7a0b\u4e2d\u5f15\u5165\u4f5c\u8005\u6311\u6218\u673a\u5236\u53ef\u4ee5\u63d0\u9ad8\u8bc4\u5ba1\u8d28\u91cf\uff0c\u4f7f\u7ed3\u679c\u66f4\u63a5\u8fd1\u7406\u8bba\u6700\u4f18\u72b6\u6001\u3002"}}
{"id": "2510.03374", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03374", "abs": "https://arxiv.org/abs/2510.03374", "authors": ["Antoun Yaacoub", "Zainab Assaghir", "J\u00e9r\u00f4me Da-Rugna"], "title": "Lightweight Prompt Engineering for Cognitive Alignment in Educational AI: A OneClickQuiz Case Study", "comment": "Published in the 36th Central European Conference on Information and\n  Intelligent Systems(CECIIS)at: Vara\\v{z}din, Croatia. September 17-19/2025.\n  ISSN 1847-2001 (Print). ISSN 1848-2295 (Online)", "summary": "The rapid integration of Artificial Intelligence (AI) into educational\ntechnology promises to revolutionize content creation and assessment. However,\nthe quality and pedagogical alignment of AI-generated content remain critical\nchallenges. This paper investigates the impact of lightweight prompt\nengineering strategies on the cognitive alignment of AI-generated questions\nwithin OneClickQuiz, a Moodle plugin leveraging generative AI. We evaluate\nthree prompt variants-a detailed baseline, a simpler version, and a\npersona-based approach-across Knowledge, Application, and Analysis levels of\nBloom's Taxonomy. Utilizing an automated classification model (from prior work)\nand human review, our findings demonstrate that explicit, detailed prompts are\ncrucial for precise cognitive alignment. While simpler and persona-based\nprompts yield clear and relevant questions, they frequently misalign with\nintended Bloom's levels, generating outputs that are either too complex or\ndeviate from the desired cognitive objective. This study underscores the\nimportance of strategic prompt engineering in fostering pedagogically sound\nAI-driven educational solutions and advises on optimizing AI for quality\ncontent generation in learning analytics and smart learning environments.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u8f7b\u91cf\u7ea7\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\u5bf9AI\u751f\u6210\u95ee\u9898\u8ba4\u77e5\u5bf9\u9f50\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8be6\u7ec6\u660e\u786e\u7684\u63d0\u793a\u5bf9\u4e8e\u7cbe\u786e\u7684\u8ba4\u77e5\u5bf9\u9f50\u81f3\u5173\u91cd\u8981\u3002", "motivation": "AI\u5728\u6559\u80b2\u6280\u672f\u4e2d\u7684\u5feb\u901f\u96c6\u6210\u867d\u7136\u524d\u666f\u5e7f\u9614\uff0c\u4f46AI\u751f\u6210\u5185\u5bb9\u7684\u8d28\u91cf\u548c\u6559\u5b66\u5bf9\u9f50\u4ecd\u7136\u662f\u5173\u952e\u6311\u6218\u3002", "method": "\u5728OneClickQuiz Moodle\u63d2\u4ef6\u4e2d\u8bc4\u4f30\u4e09\u79cd\u63d0\u793a\u53d8\u4f53\uff1a\u8be6\u7ec6\u57fa\u7ebf\u3001\u7b80\u5316\u7248\u672c\u548c\u57fa\u4e8e\u89d2\u8272\u7684\u65b9\u6cd5\uff0c\u6db5\u76d6\u5e03\u9c81\u59c6\u5206\u7c7b\u6cd5\u7684\u77e5\u8bc6\u3001\u5e94\u7528\u548c\u5206\u6790\u5c42\u6b21\uff0c\u4f7f\u7528\u81ea\u52a8\u5206\u7c7b\u6a21\u578b\u548c\u4eba\u5de5\u5ba1\u67e5\u3002", "result": "\u8be6\u7ec6\u63d0\u793a\u80fd\u5b9e\u73b0\u7cbe\u786e\u7684\u8ba4\u77e5\u5bf9\u9f50\uff0c\u800c\u7b80\u5316\u548c\u57fa\u4e8e\u89d2\u8272\u7684\u63d0\u793a\u867d\u7136\u80fd\u751f\u6210\u6e05\u6670\u76f8\u5173\u7684\u95ee\u9898\uff0c\u4f46\u7ecf\u5e38\u4e0e\u76ee\u6807\u5e03\u9c81\u59c6\u5c42\u6b21\u4e0d\u5bf9\u9f50\uff0c\u4ea7\u751f\u8fc7\u4e8e\u590d\u6742\u6216\u504f\u79bb\u9884\u671f\u8ba4\u77e5\u76ee\u6807\u7684\u7ed3\u679c\u3002", "conclusion": "\u6218\u7565\u6027\u63d0\u793a\u5de5\u7a0b\u5bf9\u4e8e\u57f9\u517b\u6559\u5b66\u5408\u7406\u7684AI\u9a71\u52a8\u6559\u80b2\u89e3\u51b3\u65b9\u6848\u81f3\u5173\u91cd\u8981\uff0c\u5efa\u8bae\u5728\u5b66\u4e60\u548c\u667a\u80fd\u5b66\u4e60\u73af\u5883\u4e2d\u4f18\u5316AI\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u5185\u5bb9\u3002"}}
{"id": "2510.03485", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.03485", "abs": "https://arxiv.org/abs/2510.03485", "authors": ["Xiaofei Wen", "Wenjie Jacky Mo", "Yanan Xie", "Peng Qi", "Muhao Chen"], "title": "Towards Policy-Compliant Agents: Learning Efficient Guardrails For Policy Violation Detection", "comment": "16 pages, 5 figures", "summary": "Autonomous web agents need to operate under externally imposed or\nhuman-specified policies while generating long-horizon trajectories. However,\nlittle work has examined whether these trajectories comply with such policies,\nor whether policy violations persist across different contexts such as domains\n(e.g., shopping or coding websites) and subdomains (e.g., product search and\norder management in shopping). To address this gap, we introduce\nPolicyGuardBench, a benchmark of about 60k examples for detecting policy\nviolations in agent trajectories. From diverse agent runs, we generate a broad\nset of policies and create both within subdomain and cross subdomain pairings\nwith violation labels. In addition to full-trajectory evaluation,\nPolicyGuardBench also includes a prefix-based violation detection task where\nmodels must anticipate policy violations from truncated trajectory prefixes\nrather than complete sequences. Using this dataset, we train PolicyGuard-4B, a\nlightweight guardrail model that delivers strong detection accuracy across all\ntasks while keeping inference efficient. Notably, PolicyGuard-4B generalizes\nacross domains and preserves high accuracy on unseen settings. Together,\nPolicyGuardBench and PolicyGuard-4B provide the first comprehensive framework\nfor studying policy compliance in web agent trajectories, and show that\naccurate and generalizable guardrails are feasible at small scales.", "AI": {"tldr": "\u63d0\u51fa\u4e86PolicyGuardBench\u57fa\u51c6\u548cPolicyGuard-4B\u6a21\u578b\uff0c\u7528\u4e8e\u68c0\u6d4b\u7f51\u7edc\u667a\u80fd\u4f53\u8f68\u8ff9\u4e2d\u7684\u7b56\u7565\u8fdd\u89c4\uff0c\u652f\u6301\u8de8\u57df\u6cdb\u5316\u548c\u5c0f\u89c4\u6a21\u9ad8\u6548\u63a8\u7406\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5bf9\u81ea\u4e3b\u7f51\u7edc\u667a\u80fd\u4f53\u5728\u751f\u6210\u957f\u89c6\u91ce\u8f68\u8ff9\u65f6\u662f\u5426\u9075\u5b88\u5916\u90e8\u7b56\u7565\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u9886\u57df\u548c\u5b50\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b\u7ea66\u4e07\u4e2a\u6837\u672c\u7684PolicyGuardBench\u57fa\u51c6\uff0c\u4ece\u591a\u6837\u5316\u667a\u80fd\u4f53\u8fd0\u884c\u4e2d\u751f\u6210\u7b56\u7565\u96c6\uff0c\u521b\u5efa\u5e26\u8fdd\u89c4\u6807\u7b7e\u7684\u57df\u5185\u548c\u8de8\u57df\u914d\u5bf9\uff0c\u5305\u62ec\u5b8c\u6574\u8f68\u8ff9\u548c\u524d\u7f00\u68c0\u6d4b\u4efb\u52a1\u3002", "result": "\u8bad\u7ec3\u7684PolicyGuard-4B\u8f7b\u91cf\u7ea7\u62a4\u680f\u6a21\u578b\u5728\u6240\u6709\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u5f3a\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u5728\u672a\u89c1\u8bbe\u7f6e\u4e0a\u4fdd\u6301\u9ad8\u7cbe\u5ea6\uff0c\u5e76\u80fd\u8de8\u57df\u6cdb\u5316\u3002", "conclusion": "PolicyGuardBench\u548cPolicyGuard-4B\u4e3a\u7814\u7a76\u7f51\u7edc\u667a\u80fd\u4f53\u7b56\u7565\u5408\u89c4\u6027\u63d0\u4f9b\u4e86\u9996\u4e2a\u5168\u9762\u6846\u67b6\uff0c\u8bc1\u660e\u5c0f\u89c4\u6a21\u4e0b\u53ef\u5b9e\u73b0\u51c6\u786e\u4e14\u53ef\u6cdb\u5316\u7684\u62a4\u680f\u3002"}}
{"id": "2510.03635", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03635", "abs": "https://arxiv.org/abs/2510.03635", "authors": ["Chen Chao", "Zixiao Ma", "Ziang Zhang"], "title": "Cyber Resilience of Three-phase Unbalanced Distribution System Restoration under Sparse Adversarial Attack on Load Forecasting", "comment": "10 pages, 7 figures", "summary": "System restoration is critical for power system resilience, nonetheless, its\ngrowing reliance on artificial intelligence (AI)-based load forecasting\nintroduces significant cybersecurity risks. Inaccurate forecasts can lead to\ninfeasible planning, voltage and frequency violations, and unsuccessful\nrecovery of de-energized segments, yet the resilience of restoration processes\nto such attacks remains largely unexplored. This paper addresses this gap by\nquantifying how adversarially manipulated forecasts impact restoration\nfeasibility and grid security. We develop a gradient-based sparse adversarial\nattack that strategically perturbs the most influential spatiotemporal inputs,\nexposing vulnerabilities in forecasting models while maintaining stealth. We\nfurther create a restoration-aware validation framework that embeds these\ncompromised forecasts into a sequential restoration model and evaluates\noperational feasibility using an unbalanced three-phase optimal power flow\nformulation. Simulation results show that the proposed approach is more\nefficient and stealthier than baseline attacks. It reveals system-level\nfailures, such as voltage and power ramping violations that prevent the\nrestoration of critical loads. These findings provide actionable insights for\ndesigning cybersecurity-aware restoration planning frameworks.", "AI": {"tldr": "\u672c\u6587\u91cf\u5316\u4e86\u5bf9\u6297\u6027\u64cd\u7eb5\u7684\u8d1f\u8377\u9884\u6d4b\u5bf9\u7535\u529b\u7cfb\u7edf\u6062\u590d\u53ef\u884c\u6027\u548c\u7535\u7f51\u5b89\u5168\u7684\u5f71\u54cd\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u7684\u7a00\u758f\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u6062\u590d\u611f\u77e5\u7684\u9a8c\u8bc1\u6846\u67b6\u3002", "motivation": "\u7535\u529b\u7cfb\u7edf\u6062\u590d\u5bf9\u7535\u7f51\u97e7\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u5bf9\u57fa\u4e8eAI\u7684\u8d1f\u8377\u9884\u6d4b\u7684\u4f9d\u8d56\u5f15\u5165\u4e86\u7f51\u7edc\u5b89\u5168\u98ce\u9669\uff0c\u800c\u6062\u590d\u8fc7\u7a0b\u5bf9\u6b64\u7c7b\u653b\u51fb\u7684\u97e7\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u68af\u5ea6\u7a00\u758f\u5bf9\u6297\u653b\u51fb\u7b56\u7565\u6270\u52a8\u5173\u952e\u65f6\u7a7a\u8f93\u5165\uff0c\u5efa\u7acb\u6062\u590d\u611f\u77e5\u9a8c\u8bc1\u6846\u67b6\u5c06\u53d7\u635f\u9884\u6d4b\u5d4c\u5165\u987a\u5e8f\u6062\u590d\u6a21\u578b\uff0c\u4f7f\u7528\u4e0d\u5e73\u8861\u4e09\u76f8\u6700\u4f18\u6f6e\u6d41\u516c\u5f0f\u8bc4\u4f30\u8fd0\u884c\u53ef\u884c\u6027\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u6bd4\u57fa\u7ebf\u653b\u51fb\u66f4\u9ad8\u6548\u548c\u9690\u853d\uff0c\u63ed\u793a\u4e86\u7cfb\u7edf\u7ea7\u6545\u969c\uff0c\u5982\u7535\u538b\u548c\u529f\u7387\u722c\u5761\u8fdd\u89c4\uff0c\u963b\u788d\u5173\u952e\u8d1f\u8377\u7684\u6062\u590d\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u8bbe\u8ba1\u7f51\u7edc\u5b89\u5168\u611f\u77e5\u7684\u6062\u590d\u89c4\u5212\u6846\u67b6\u63d0\u4f9b\u4e86\u53ef\u884c\u89c1\u89e3\u3002"}}
{"id": "2510.03496", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03496", "abs": "https://arxiv.org/abs/2510.03496", "authors": ["Vadivelan Murugesan", "Rajasundaram Mathiazhagan", "Sanjana Joshi", "Aliasghar Arab"], "title": "Digital-Twin Evaluation for Proactive Human-Robot Collision Avoidance via Prediction-Guided A-RRT*", "comment": null, "summary": "Human-robot collaboration requires precise prediction of human motion over\nextended horizons to enable proactive collision avoidance. Unlike existing\nplanners that rely solely on kinodynamic models, we present a prediction-driven\nsafe planning framework that leverages granular, joint-by-joint human motion\nforecasting validated in a physics-based digital twin. A capsule-based\nartificial potential field (APF) converts these granular predictions into\ncollision risk metrics, triggering an Adaptive RRT* (A-RRT*) planner when\nthresholds are exceeded. The depth camera is used to extract 3D skeletal poses\nand a convolutional neural network-bidirectional long short-term memory\n(CNN-BiLSTM) model to predict individual joint trajectories ahead of time. A\ndigital twin model integrates real-time human posture prediction placed in\nfront of a simulated robot to evaluate motions and physical contacts. The\nproposed method enables validation of planned trajectories ahead of time and\nbridging potential latency gaps in updating planned trajectories in real-time.\nIn 50 trials, our method achieved 100% proactive avoidance with > 250 mm\nclearance and sub-2 s replanning, demonstrating superior precision and\nreliability compared to existing kinematic-only planners through the\nintegration of predictive human modeling with digital twin validation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9884\u6d4b\u9a71\u52a8\u7684\u4eba\u673a\u534f\u4f5c\u5b89\u5168\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u5b57\u5b6a\u751f\u9a8c\u8bc1\u7684\u5173\u8282\u7ea7\u4eba\u4f53\u8fd0\u52a8\u9884\u6d4b\u5b9e\u73b0\u4e3b\u52a8\u907f\u969c", "motivation": "\u73b0\u6709\u4eba\u673a\u534f\u4f5c\u89c4\u5212\u5668\u4ec5\u4f9d\u8d56\u8fd0\u52a8\u5b66\u6a21\u578b\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u957f\u671f\u4eba\u4f53\u8fd0\u52a8\u9884\u6d4b\u6765\u5b9e\u73b0\u4e3b\u52a8\u78b0\u649e\u907f\u514d", "method": "\u4f7f\u7528\u6df1\u5ea6\u76f8\u673a\u63d0\u53d63D\u9aa8\u9abc\u59ff\u6001\uff0cCNN-BiLSTM\u6a21\u578b\u9884\u6d4b\u5173\u8282\u8f68\u8ff9\uff0c\u80f6\u56ca\u4eba\u5de5\u52bf\u573a\u8ba1\u7b97\u78b0\u649e\u98ce\u9669\uff0c\u81ea\u9002\u5e94RRT*\u89c4\u5212\u5668\u5728\u9608\u503c\u8d85\u8fc7\u65f6\u91cd\u65b0\u89c4\u5212", "result": "\u572850\u6b21\u8bd5\u9a8c\u4e2d\u5b9e\u73b0100%\u4e3b\u52a8\u907f\u969c\uff0c\u4fdd\u6301>250mm\u5b89\u5168\u8ddd\u79bb\uff0c\u91cd\u65b0\u89c4\u5212\u65f6\u95f4\u5c0f\u4e8e2\u79d2", "conclusion": "\u901a\u8fc7\u9884\u6d4b\u4eba\u4f53\u5efa\u6a21\u4e0e\u6570\u5b57\u5b6a\u751f\u9a8c\u8bc1\u7684\u96c6\u6210\uff0c\u76f8\u6bd4\u4ec5\u4f7f\u7528\u8fd0\u52a8\u5b66\u7684\u89c4\u5212\u5668\u5177\u6709\u66f4\u9ad8\u7684\u7cbe\u5ea6\u548c\u53ef\u9760\u6027"}}
{"id": "2510.03379", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03379", "abs": "https://arxiv.org/abs/2510.03379", "authors": ["Frederic Higham", "Tommy Yuan"], "title": "Can an AI-Powered Presentation Platform Based On The Game \"Just a Minute\" Be Used To Improve Students' Public Speaking Skills?", "comment": "11 pages, to be presented orally at the International Conference on\n  Education and Artificial Intelligence Technologies (Nov 2025)", "summary": "This study explores the effectiveness of applying AI and gamification into a\npresentation platform aimed at University students wanting to improve their\npublic speaking skills in their native tongue. Specifically, a platform based\non the radio show, Just a Minute (JAM), is explored. In this game, players are\nchallenged to speak fluently on a topic for 60 seconds without repeating\nthemselves, hesitating or deviating from the topic. JAM has proposed benefits\nsuch as allowing students to improve their spontaneous speaking skills and\nreduce their use of speech disfluencies (\"um\", \"uh\", etc.).\n  Previous research has highlighted the difficulties students face when\nspeaking publicly, the main one being anxiety. AI Powered Presentation\nPlatforms (AI-PPPs), where students can speak with an immersive AI audience and\nreceive real-time feedback, have been explored as a method to improve student's\nspeaking skills and confidence. So far they have shown promising results which\nthis study aims to build upon.\n  A group of students from the University of York are enlisted to evaluate the\neffectiveness of the JAM platform. They are asked to fill in a questionnaire,\nplay through the game twice and then complete a final questionnaire to discuss\ntheir experiences playing the game. Various statistics are gathered during\ntheir gameplay such as the number of points they gained and the number of rules\nthey broke. The results showed that students found the game promising and\nbelieved that their speaking skills could improve if they played the game for\nlonger. More work will need to be carried out to prove the effectiveness of the\ngame beyond the short term.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u5c06AI\u548c\u6e38\u620f\u5316\u5e94\u7528\u4e8e\u9762\u5411\u5927\u5b66\u751f\u7684\u6f14\u8bb2\u5e73\u53f0\uff0c\u57fa\u4e8e\"Just a Minute\"\u6e38\u620f\u89c4\u5219\uff0c\u5e2e\u52a9\u5b66\u751f\u63d0\u9ad8\u6bcd\u8bed\u516c\u5f00\u6f14\u8bb2\u80fd\u529b\u3002", "motivation": "\u5b66\u751f\u9762\u4e34\u516c\u5f00\u6f14\u8bb2\u7126\u8651\u7b49\u56f0\u96be\uff0cAI\u9a71\u52a8\u7684\u6f14\u8bb2\u5e73\u53f0\u901a\u8fc7\u6c89\u6d78\u5f0fAI\u89c2\u4f17\u548c\u5b9e\u65f6\u53cd\u9988\u6765\u63d0\u5347\u5b66\u751f\u6f14\u8bb2\u6280\u80fd\u548c\u81ea\u4fe1\u5fc3\u3002", "method": "\u62db\u52df\u7ea6\u514b\u5927\u5b66\u5b66\u751f\u53c2\u4e0e\u8bc4\u4f30\uff0c\u586b\u5199\u95ee\u5377\u3001\u73a9\u4e24\u6b21\u6e38\u620f\uff0c\u6536\u96c6\u6e38\u620f\u8fc7\u7a0b\u4e2d\u7684\u5f97\u5206\u548c\u8fdd\u89c4\u6b21\u6570\u7b49\u7edf\u8ba1\u6570\u636e\u3002", "result": "\u5b66\u751f\u8ba4\u4e3a\u6e38\u620f\u6709\u524d\u666f\uff0c\u76f8\u4fe1\u957f\u671f\u4f7f\u7528\u80fd\u63d0\u9ad8\u6f14\u8bb2\u6280\u80fd\uff0c\u4f46\u9700\u8981\u66f4\u591a\u7814\u7a76\u8bc1\u660e\u5176\u957f\u671f\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8eJAM\u7684AI\u6e38\u620f\u5316\u6f14\u8bb2\u5e73\u53f0\u5728\u77ed\u671f\u5185\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u9a8c\u8bc1\u957f\u671f\u6548\u679c\u3002"}}
{"id": "2510.03506", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03506", "abs": "https://arxiv.org/abs/2510.03506", "authors": ["John Nguyen", "Marton Havasi", "Tariq Berrada", "Luke Zettlemoyer", "Ricky T. Q. Chen"], "title": "OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows", "comment": "https://johnlnguyen.com/oneflow", "summary": "We present OneFlow, the first non-autoregressive multimodal model that\nenables variable-length and concurrent mixed-modal generation. Unlike\nautoregressive models that enforce rigid causal ordering between text and image\ngeneration, OneFlow combines an insertion-based Edit Flow for discrete text\ntokens with Flow Matching for image latents. OneFlow enables concurrent\ntext-image synthesis with hierarchical sampling that prioritizes content over\ngrammar. Through controlled experiments across model sizes from 1B to 8B, we\ndemonstrate that OneFlow outperforms autoregressive baselines on both\ngeneration and understanding tasks while using up to 50% fewer training FLOPs.\nOneFlow surpasses both autoregressive and diffusion-based approaches while\nunlocking new capabilities for concurrent generation, iterative refinement, and\nnatural reasoning-like generation.", "AI": {"tldr": "OneFlow\u662f\u9996\u4e2a\u975e\u81ea\u56de\u5f52\u591a\u6a21\u6001\u6a21\u578b\uff0c\u652f\u6301\u53ef\u53d8\u957f\u5ea6\u548c\u5e76\u53d1\u6df7\u5408\u6a21\u6001\u751f\u6210\uff0c\u901a\u8fc7\u7ed3\u5408\u63d2\u5165\u5f0f\u7f16\u8f91\u6d41\u548c\u6d41\u5339\u914d\u6280\u672f\uff0c\u5728\u751f\u6210\u8d28\u91cf\u548c\u6548\u7387\u4e0a\u8d85\u8d8a\u81ea\u56de\u5f52\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u81ea\u56de\u5f52\u6a21\u578b\u5728\u6587\u672c\u548c\u56fe\u50cf\u751f\u6210\u4e2d\u5f3a\u5236\u56e0\u679c\u987a\u5e8f\u7684\u9650\u5236\uff0c\u5b9e\u73b0\u66f4\u7075\u6d3b\u7684\u5e76\u53d1\u591a\u6a21\u6001\u751f\u6210\u3002", "method": "\u7ed3\u5408\u63d2\u5165\u5f0f\u7f16\u8f91\u6d41\u5904\u7406\u79bb\u6563\u6587\u672c\u6807\u8bb0\uff0c\u4f7f\u7528\u6d41\u5339\u914d\u5904\u7406\u56fe\u50cf\u6f5c\u5728\u8868\u793a\uff0c\u91c7\u7528\u5206\u5c42\u91c7\u6837\u4f18\u5148\u5185\u5bb9\u800c\u975e\u8bed\u6cd5\u3002", "result": "\u57281B\u52308B\u6a21\u578b\u89c4\u6a21\u4e0a\uff0cOneFlow\u5728\u751f\u6210\u548c\u7406\u89e3\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u81ea\u56de\u5f52\u57fa\u7ebf\uff0c\u8bad\u7ec3FLOPs\u51cf\u5c1150%\uff0c\u8d85\u8d8a\u81ea\u56de\u5f52\u548c\u6269\u6563\u65b9\u6cd5\u3002", "conclusion": "OneFlow\u89e3\u9501\u4e86\u5e76\u53d1\u751f\u6210\u3001\u8fed\u4ee3\u4f18\u5316\u548c\u7c7b\u81ea\u7136\u63a8\u7406\u7b49\u65b0\u80fd\u529b\uff0c\u4e3a\u975e\u81ea\u56de\u5f52\u591a\u6a21\u6001\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03686", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03686", "abs": "https://arxiv.org/abs/2510.03686", "authors": ["Mohammadjavad Abbaspour", "Mukund R. Shukla", "Praveen K. Saxena", "Shivam Saxena"], "title": "Optimal Energy Management in Indoor Farming Using Lighting Flexibility and Intelligent Model Predictive Control", "comment": null, "summary": "Indoor farming enables year-round food production but its reliance on\nartificial lighting significantly increases energy consumption, peak load\ncharges, and energy costs for growers. Recent studies indicate that plants are\nable to tolerate interruptions in light, enabling the design of 24-hour\nlighting schedules (or \"recipes\") with strategic light modulation in alignment\nwith day-ahead pricing. Thus, we propose an optimal lighting control strategy\nfor indoor farming that modulates light intensity and photoperiod to reduce\nenergy costs. The control strategy is implemented within a model predictive\ncontrol framework and augmented with transformer-based neural networks to\nforecast 24-hour ahead solar radiation and electricity prices to improve energy\ncost reduction. The control strategy is informed by real-world experimentation\non lettuce crops to discover minimum light exposure and appropriate dark-light\nintervals, which are mathematically formulated as constraints to maintain plant\nhealth. Simulations for a one-hectare greenhouse, based on real electricity\nmarket data from Ontario, demonstrate an annual cost reduction of $318,400\n(20.9%), a peak load decrease of 1.6 MW (33.32%), and total energy savings of\n1890 MWh (20.2%) against a baseline recipe. These findings highlight the\npotential of intelligent lighting control to improve the sustainability and\neconomic feasibility of indoor farming.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5ba4\u5185\u519c\u4e1a\u7684\u4f18\u5316\u7167\u660e\u63a7\u5236\u7b56\u7565\uff0c\u901a\u8fc7\u8c03\u8282\u5149\u7167\u5f3a\u5ea6\u548c\u5149\u5468\u671f\u6765\u964d\u4f4e\u80fd\u6e90\u6210\u672c\uff0c\u7ed3\u5408\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u548c\u53d8\u538b\u5668\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u9884\u6d4b\uff0c\u5728\u4fdd\u6301\u690d\u7269\u5065\u5eb7\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u80fd\u6e90\u6d88\u8017\u548c\u6210\u672c\u3002", "motivation": "\u5ba4\u5185\u519c\u4e1a\u4f9d\u8d56\u4eba\u5de5\u7167\u660e\u5bfc\u81f4\u80fd\u6e90\u6d88\u8017\u3001\u5cf0\u503c\u8d1f\u8377\u548c\u80fd\u6e90\u6210\u672c\u663e\u8457\u589e\u52a0\uff0c\u9700\u8981\u5f00\u53d1\u667a\u80fd\u7167\u660e\u63a7\u5236\u7b56\u7565\u6765\u63d0\u9ad8\u53ef\u6301\u7eed\u6027\u548c\u7ecf\u6d4e\u53ef\u884c\u6027\u3002", "method": "\u91c7\u7528\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\uff0c\u7ed3\u5408\u53d8\u538b\u5668\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b24\u5c0f\u65f6\u524d\u7684\u592a\u9633\u8f90\u5c04\u548c\u7535\u4ef7\uff0c\u901a\u8fc7\u771f\u5b9e\u751f\u83dc\u4f5c\u7269\u5b9e\u9a8c\u786e\u5b9a\u6700\u5c0f\u5149\u7167\u9700\u6c42\u548c\u9002\u5f53\u7684\u5149\u6697\u95f4\u9694\u4f5c\u4e3a\u7ea6\u675f\u6761\u4ef6\u3002", "result": "\u57fa\u4e8e\u5b89\u5927\u7565\u7701\u771f\u5b9e\u7535\u529b\u5e02\u573a\u6570\u636e\u7684\u6a21\u62df\u663e\u793a\uff0c\u76f8\u6bd4\u57fa\u51c6\u65b9\u6848\uff0c\u6bcf\u5e74\u6210\u672c\u51cf\u5c11318,400\u7f8e\u5143\uff0820.9%\uff09\uff0c\u5cf0\u503c\u8d1f\u8377\u964d\u4f4e1.6\u5146\u74e6\uff0833.32%\uff09\uff0c\u603b\u80fd\u8017\u8282\u7ea61890\u5146\u74e6\u65f6\uff0820.2%\uff09\u3002", "conclusion": "\u667a\u80fd\u7167\u660e\u63a7\u5236\u6709\u6f5c\u529b\u663e\u8457\u63d0\u9ad8\u5ba4\u5185\u519c\u4e1a\u7684\u53ef\u6301\u7eed\u6027\u548c\u7ecf\u6d4e\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u4f18\u5316\u5149\u7167\u8c03\u5ea6\u5b9e\u73b0\u663e\u8457\u7684\u80fd\u6e90\u6210\u672c\u8282\u7ea6\u3002"}}
{"id": "2510.03504", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03504", "abs": "https://arxiv.org/abs/2510.03504", "authors": ["Yutong Wang", "Yichun Qu", "Tengxiang Wang", "Lishuo Pan", "Nora Ayanian"], "title": "Distributed Connectivity Maintenance and Recovery for Quadrotor Motion Planning", "comment": null, "summary": "Maintaining connectivity is crucial in many multi-robot applications, yet\nfragile to obstacles and visual occlusions. We present a real-time distributed\nframework for multi-robot navigation certified by high-order control barrier\nfunctions (HOCBFs) that controls inter-robot proximity to maintain connectivity\nwhile avoiding collisions. We incorporate control Lyapunov functions to enable\nconnectivity recovery from initial disconnected configurations and temporary\nlosses, providing robust connectivity during navigation in obstacle-rich\nenvironments. Our trajectory generation framework concurrently produces\nplanning and control through a Bezier-parameterized trajectory, which naturally\nprovides smooth curves with arbitrary degree of derivatives. The main\ncontribution is the unified MPC-CLF-CBF framework, a continuous-time trajectory\ngeneration and control method for connectivity maintenance and recovery of\nmulti-robot systems. We validate the framework through extensive simulations\nand a physical experiment with 4 Crazyflie nano-quadrotors.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u9636\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u7684\u5b9e\u65f6\u5206\u5e03\u5f0f\u591a\u673a\u5668\u4eba\u5bfc\u822a\u6846\u67b6\uff0c\u80fd\u591f\u5728\u907f\u969c\u7684\u540c\u65f6\u4fdd\u6301\u673a\u5668\u4eba\u95f4\u7684\u8fde\u63a5\u6027\uff0c\u5e76\u652f\u6301\u4ece\u65ad\u5f00\u72b6\u6001\u6062\u590d\u8fde\u63a5\u3002", "motivation": "\u5728\u591a\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u4fdd\u6301\u8fde\u63a5\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u969c\u788d\u7269\u548c\u89c6\u89c9\u906e\u6321\u7684\u5f71\u54cd\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u590d\u6742\u73af\u5883\u4e2d\u540c\u65f6\u5b9e\u73b0\u8fde\u63a5\u4fdd\u6301\u548c\u907f\u969c\u3002", "method": "\u91c7\u7528\u7edf\u4e00MPC-CLF-CBF\u6846\u67b6\uff0c\u7ed3\u5408\u9ad8\u9636\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u63a7\u5236\u673a\u5668\u4eba\u95f4\u8ddd\u4ee5\u4fdd\u6301\u8fde\u63a5\uff0c\u4f7f\u7528\u63a7\u5236\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\u5b9e\u73b0\u8fde\u63a5\u6062\u590d\uff0c\u901a\u8fc7\u8d1d\u585e\u5c14\u53c2\u6570\u5316\u8f68\u8ff9\u751f\u6210\u5e73\u6ed1\u66f2\u7ebf\u3002", "result": "\u5728\u6a21\u62df\u548c4\u67b6Crazyflie\u7eb3\u7c73\u56db\u65cb\u7ffc\u7684\u7269\u7406\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5728\u969c\u788d\u7269\u4e30\u5bcc\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u9c81\u68d2\u7684\u8fde\u63a5\u4fdd\u6301\u548c\u6062\u590d\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u8fde\u7eed\u65f6\u95f4\u7684\u8f68\u8ff9\u751f\u6210\u548c\u63a7\u5236\u65b9\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u5b9e\u73b0\u8fde\u63a5\u7ef4\u62a4\u3001\u907f\u969c\u548c\u8fde\u63a5\u6062\u590d\u3002"}}
{"id": "2510.03487", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.03487", "abs": "https://arxiv.org/abs/2510.03487", "authors": ["Aldrin Joar Rodrigo Taduran", "Leo P. Piao"], "title": "Analyzing the Performance of a 2.72kWp Rooftop Grid tied Photovoltaic System in Tarlac City, Philippines", "comment": "10 pages, 7 figures, Published with International Journal of\n  Engineering Trends and Technology (IJETT)", "summary": "Residential and industrial areas are using rooftop grid-tied Photovoltaic\n(PV) systems, which are becoming increasingly popular. This is because solar\nenergy reduces electrical consumption and provides free energy, while also\nlowering carbon emissions to create a more sustainable environment. This paper\naims to analyze the 2.72kW p rooftop grid-tied PV system performance between\n2020 and 2023 in Tarlac City, Philippines. The PV generated yearly is measured\nby Array Yield (YA), Reference Yield (YR), and Final Yield (YF), which were\nfound to be valued at 3.12, 3.9, and 3.01 kWh/kWp, respectively. The efficiency\ncan decrease due to System Loss (LS) and Capture Loss (LC), which were 0.78 and\n0.12 kWh/kWp, respectively. This results in a Capacity Utilization Factor (CUF)\nof 15.52% and a Performance Ratio (PR) of 77.10%. The productivity of PV\nresulted in an array efficiency was 12.89%, an inverter efficiency was 94.3%,\nand a system efficiency was 12.16%. PV energy generation was 3,699 kWh, with\n2380 kWh fed into the grid annually. The system's annual revenue is $690.59.\nThe payback period is 6 years with a 238.2% Return On Investment (ROI). Carbon\nemissions are reduced by 0.379 tCO2/kWp/yr.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u83f2\u5f8b\u5bbeTarlac\u5e022020-2023\u5e742.72kWp\u5c4b\u9876\u5e76\u7f51\u5149\u4f0f\u7cfb\u7edf\u7684\u6027\u80fd\u8868\u73b0\uff0c\u7cfb\u7edf\u5e74\u53d1\u7535\u91cf3699kWh\uff0c\u6027\u80fd\u6bd477.10%\uff0c\u6295\u8d44\u56de\u6536\u671f6\u5e74\uff0c\u6295\u8d44\u56de\u62a5\u7387238.2%\u3002", "motivation": "\u968f\u7740\u5c4b\u9876\u5e76\u7f51\u5149\u4f0f\u7cfb\u7edf\u5728\u4f4f\u5b85\u548c\u5de5\u4e1a\u533a\u7684\u666e\u53ca\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5b9e\u9645\u6027\u80fd\u8868\u73b0\uff0c\u4ee5\u9a8c\u8bc1\u592a\u9633\u80fd\u53d1\u7535\u7684\u7ecf\u6d4e\u6548\u76ca\u548c\u73af\u5883\u6548\u76ca\u3002", "method": "\u901a\u8fc7\u6d4b\u91cf\u9635\u5217\u4ea7\u91cf(YA)\u3001\u53c2\u8003\u4ea7\u91cf(YR)\u548c\u6700\u7ec8\u4ea7\u91cf(YF)\u7b49\u5173\u952e\u6027\u80fd\u6307\u6807\uff0c\u5206\u6790\u7cfb\u7edf\u635f\u5931(LS)\u548c\u6355\u83b7\u635f\u5931(LC)\uff0c\u8ba1\u7b97\u5bb9\u91cf\u5229\u7528\u56e0\u5b50(CUF)\u548c\u6027\u80fd\u6bd4(PR)\u3002", "result": "\u7cfb\u7edf\u5e74\u53d1\u7535\u91cf3699kWh\uff0c\u5176\u4e2d2380kWh\u9988\u5165\u7535\u7f51\uff0c\u6027\u80fd\u6bd477.10%\uff0c\u9635\u5217\u6548\u738712.89%\uff0c\u9006\u53d8\u5668\u6548\u738794.3%\uff0c\u7cfb\u7edf\u6548\u738712.16%\uff0c\u5e74\u6536\u5165690.59\u7f8e\u5143\u3002", "conclusion": "\u5c4b\u9876\u5e76\u7f51\u5149\u4f0f\u7cfb\u7edf\u5177\u6709\u826f\u597d\u7684\u7ecf\u6d4e\u6027\u548c\u73af\u5883\u6548\u76ca\uff0c\u6295\u8d44\u56de\u6536\u671f\u77ed\uff0c\u6295\u8d44\u56de\u62a5\u7387\u9ad8\uff0c\u80fd\u6709\u6548\u51cf\u5c11\u78b3\u6392\u653e\uff0c\u662f\u53ef\u884c\u7684\u53ef\u518d\u751f\u80fd\u6e90\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03605", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.03605", "abs": "https://arxiv.org/abs/2510.03605", "authors": ["Adel Javanmard", "Baharan Mirzasoleiman", "Vahab Mirrokni"], "title": "Understanding the Role of Training Data in Test-Time Scaling", "comment": "24 pages, 4 figures", "summary": "Test-time scaling improves the reasoning capabilities of large language\nmodels (LLMs) by allocating extra compute to generate longer Chains-of-Thoughts\n(CoTs). This enables models to tackle more complex problem by breaking them\ndown into additional steps, backtracking, and correcting mistakes. Despite its\nstrong performance--demonstrated by OpenAI's o1 and DeepSeek R1, the conditions\nin the training data under which long CoTs emerge, and when such long CoTs\nimprove the performance, remain unclear. In this paper, we study the\nperformance of test-time scaling for transformers trained on an in-context\nweight prediction task for linear regression. Our analysis provides a\ntheoretical explanation for several intriguing observations: First, at any\nfixed test error, increasing test-time compute allows us to reduce the number\nof in-context examples (context length) in training prompts. Second, if the\nskills required to solve a downstream task are not sufficiently present in the\ntraining data, increasing test-time compute can harm performance. Finally, we\ncharacterize task hardness via the smallest eigenvalue of its feature\ncovariance matrix and show that training on a diverse, relevant, and hard set\nof tasks results in best performance for test-time scaling. We confirm our\nfindings with experiments on large, nonlinear transformer architectures.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u6d4b\u8bd5\u65f6\u6269\u5c55\u5bf9Transformer\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5728\u7ebf\u6027\u56de\u5f52\u4efb\u52a1\u4e2d\uff0c\u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u53ef\u4ee5\u51cf\u5c11\u8bad\u7ec3\u6240\u9700\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u4f46\u82e5\u8bad\u7ec3\u6570\u636e\u7f3a\u4e4f\u5fc5\u8981\u6280\u80fd\uff0c\u8fc7\u5ea6\u8ba1\u7b97\u53cd\u800c\u4f1a\u635f\u5bb3\u6027\u80fd\u3002", "motivation": "\u6d4b\u8bd5\u65f6\u6269\u5c55\u901a\u8fc7\u751f\u6210\u957f\u94fe\u601d\u7ef4\u6765\u63d0\u5347LLMs\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5176\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u51fa\u73b0\u6761\u4ef6\u548c\u6027\u80fd\u63d0\u5347\u673a\u5236\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7406\u8bba\u5206\u6790\u6765\u7406\u89e3\u8fd9\u4e9b\u73b0\u8c61\u3002", "method": "\u5728\u7ebf\u6027\u56de\u5f52\u7684\u4e0a\u4e0b\u6587\u6743\u91cd\u9884\u6d4b\u4efb\u52a1\u4e0a\u8bad\u7ec3Transformer\u6a21\u578b\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u6d4b\u8bd5\u65f6\u6269\u5c55\u7684\u6548\u679c\uff0c\u5e76\u5229\u7528\u7279\u5f81\u534f\u65b9\u5dee\u77e9\u9635\u7684\u6700\u5c0f\u7279\u5f81\u503c\u6765\u8868\u5f81\u4efb\u52a1\u96be\u5ea6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1) \u56fa\u5b9a\u6d4b\u8bd5\u8bef\u5dee\u4e0b\uff0c\u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u53ef\u51cf\u5c11\u8bad\u7ec3\u4e0a\u4e0b\u6587\u957f\u5ea6\uff1b2) \u82e5\u8bad\u7ec3\u6570\u636e\u7f3a\u4e4f\u4e0b\u6e38\u4efb\u52a1\u6240\u9700\u6280\u80fd\uff0c\u589e\u52a0\u8ba1\u7b97\u4f1a\u635f\u5bb3\u6027\u80fd\uff1b3) \u5728\u591a\u6837\u5316\u3001\u76f8\u5173\u4e14\u56f0\u96be\u7684\u4efb\u52a1\u96c6\u4e0a\u8bad\u7ec3\u53ef\u83b7\u5f97\u6700\u4f73\u6d4b\u8bd5\u65f6\u6269\u5c55\u6027\u80fd\u3002", "conclusion": "\u6d4b\u8bd5\u65f6\u6269\u5c55\u7684\u6709\u6548\u6027\u53d6\u51b3\u4e8e\u8bad\u7ec3\u6570\u636e\u7684\u8d28\u91cf\uff0c\u9700\u8981\u5728\u591a\u6837\u5316\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bad\u7ec3\u624d\u80fd\u5145\u5206\u53d1\u6325\u5176\u6f5c\u529b\uff0c\u4efb\u52a1\u96be\u5ea6\u53ef\u901a\u8fc7\u7279\u5f81\u534f\u65b9\u5dee\u77e9\u9635\u7684\u7279\u5f81\u503c\u6765\u91cf\u5316\u3002"}}
{"id": "2510.03785", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03785", "abs": "https://arxiv.org/abs/2510.03785", "authors": ["Liya Huang", "Georgios Tzounas"], "title": "On the Duality Between Quantized Time and States in Dynamic Simulation", "comment": null, "summary": "This letter introduces a formal duality between discrete-time and\nquantized-state numerical methods. We interpret quantized state system (QSS)\nmethods as integration schemes applied to a dual form of the system model,\nwhere time is seen as a state-dependent variable. This perspective enables the\ndefinition of novel QSS-based schemes inspired by classical time-integration\ntechniques. As a proof of concept, we illustrate the idea by introducing a QSS\nAdams-Bashforth method applied to a test equation. We then move to demonstrate\nhow the proposed approach can achieve notable performance improvements in\nrealistic power system simulations.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u79bb\u6563\u65f6\u95f4\u4e0e\u91cf\u5316\u72b6\u6001\u6570\u503c\u65b9\u6cd5\u4e4b\u95f4\u7684\u5f62\u5f0f\u5bf9\u5076\u6027\uff0c\u5c06QSS\u65b9\u6cd5\u89e3\u91ca\u4e3a\u5e94\u7528\u4e8e\u7cfb\u7edf\u6a21\u578b\u5bf9\u5076\u5f62\u5f0f\u7684\u79ef\u5206\u65b9\u6848\uff0c\u5176\u4e2d\u65f6\u95f4\u88ab\u89c6\u4e3a\u72b6\u6001\u76f8\u5173\u53d8\u91cf\u3002", "motivation": "\u901a\u8fc7\u5efa\u7acb\u79bb\u6563\u65f6\u95f4\u4e0e\u91cf\u5316\u72b6\u6001\u65b9\u6cd5\u4e4b\u95f4\u7684\u5bf9\u5076\u5173\u7cfb\uff0c\u4e3a\u5f00\u53d1\u57fa\u4e8e\u7ecf\u5178\u65f6\u95f4\u79ef\u5206\u6280\u672f\u7684\u65b0\u578bQSS\u65b9\u6848\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u5c06QSS\u65b9\u6cd5\u91cd\u65b0\u89e3\u91ca\u4e3a\u5e94\u7528\u4e8e\u7cfb\u7edf\u6a21\u578b\u5bf9\u5076\u5f62\u5f0f\u7684\u79ef\u5206\u65b9\u6848\uff0c\u5176\u4e2d\u65f6\u95f4\u4f5c\u4e3a\u72b6\u6001\u76f8\u5173\u53d8\u91cf\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e86QSS Adams-Bashforth\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6d4b\u8bd5\u65b9\u7a0b\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u5e76\u5728\u5b9e\u9645\u7535\u529b\u7cfb\u7edf\u4eff\u771f\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8be5\u5bf9\u5076\u6027\u6846\u67b6\u4e3a\u5f00\u53d1\u65b0\u578bQSS\u65b9\u6848\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u590d\u6742\u7cfb\u7edf\u4eff\u771f\u7684\u6027\u80fd\u3002"}}
{"id": "2510.03529", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03529", "abs": "https://arxiv.org/abs/2510.03529", "authors": ["Zekai Liang", "Xiao Liang", "Soofiyan Atar", "Sreyan Das", "Zoe Chiu", "Peihan Zhang", "Florian Richter", "Shanglei Liu", "Michael C. Yip"], "title": "LapSurgie: Humanoid Robots Performing Surgery via Teleoperated Handheld Laparoscopy", "comment": null, "summary": "Robotic laparoscopic surgery has gained increasing attention in recent years\nfor its potential to deliver more efficient and precise minimally invasive\nprocedures. However, adoption of surgical robotic platforms remains largely\nconfined to high-resource medical centers, exacerbating healthcare disparities\nin rural and low-resource regions. To close this gap, a range of solutions has\nbeen explored, from remote mentorship to fully remote telesurgery. Yet, the\npractical deployment of surgical robotic systems to underserved communities\nremains an unsolved challenge. Humanoid systems offer a promising path toward\ndeployability, as they can directly operate in environments designed for humans\nwithout extensive infrastructure modifications -- including operating rooms. In\nthis work, we introduce LapSurgie, the first humanoid-robot-based laparoscopic\nteleoperation framework. The system leverages an inverse-mapping strategy for\nmanual-wristed laparoscopic instruments that abides to remote center-of-motion\nconstraints, enabling precise hand-to-tool control of off-the-shelf surgical\nlaparoscopic tools without additional setup requirements. A control console\nequipped with a stereo vision system provides real-time visual feedback.\nFinally, a comprehensive user study across platforms demonstrates the\neffectiveness of the proposed framework and provides initial evidence for the\nfeasibility of deploying humanoid robots in laparoscopic procedures.", "AI": {"tldr": "\u63d0\u51fa\u4e86LapSurgie\uff0c\u9996\u4e2a\u57fa\u4e8e\u4eba\u5f62\u673a\u5668\u4eba\u7684\u8179\u8154\u955c\u8fdc\u7a0b\u64cd\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u9006\u5411\u6620\u5c04\u7b56\u7565\u63a7\u5236\u6807\u51c6\u8179\u8154\u955c\u5de5\u5177\uff0c\u65e0\u9700\u989d\u5916\u8bbe\u7f6e\u8981\u6c42\u3002", "motivation": "\u89e3\u51b3\u624b\u672f\u673a\u5668\u4eba\u7cfb\u7edf\u5728\u8d44\u6e90\u532e\u4e4f\u5730\u533a\u7684\u90e8\u7f72\u96be\u9898\uff0c\u5229\u7528\u4eba\u5f62\u673a\u5668\u4eba\u53ef\u76f4\u63a5\u5728\u4eba\u7c7b\u8bbe\u8ba1\u73af\u5883\u4e2d\u64cd\u4f5c\u7684\u4f18\u52bf\uff0c\u7f29\u5c0f\u533b\u7597\u8d44\u6e90\u5dee\u8ddd\u3002", "method": "\u91c7\u7528\u9006\u5411\u6620\u5c04\u7b56\u7565\u63a7\u5236\u624b\u52a8\u8155\u5f0f\u8179\u8154\u955c\u5668\u68b0\uff0c\u9075\u5b88\u8fdc\u7a0b\u8fd0\u52a8\u4e2d\u5fc3\u7ea6\u675f\uff0c\u914d\u5907\u7acb\u4f53\u89c6\u89c9\u7cfb\u7edf\u7684\u63a7\u5236\u53f0\u63d0\u4f9b\u5b9e\u65f6\u89c6\u89c9\u53cd\u9988\u3002", "result": "\u8de8\u5e73\u53f0\u7684\u7efc\u5408\u7528\u6237\u7814\u7a76\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u4eba\u5f62\u673a\u5668\u4eba\u5728\u8179\u8154\u955c\u624b\u672f\u4e2d\u90e8\u7f72\u7684\u53ef\u884c\u6027\u63d0\u4f9b\u4e86\u521d\u6b65\u8bc1\u636e\u3002", "conclusion": "LapSurgie\u6846\u67b6\u5c55\u793a\u4e86\u4eba\u5f62\u673a\u5668\u4eba\u5728\u8179\u8154\u955c\u8fdc\u7a0b\u624b\u672f\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u8d44\u6e90\u532e\u4e4f\u5730\u533a\u63d0\u4f9b\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03514", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03514", "abs": "https://arxiv.org/abs/2510.03514", "authors": ["Toby Drinkall"], "title": "Red Lines and Grey Zones in the Fog of War: Benchmarking Legal Risk, Moral Harm, and Regional Bias in Large Language Model Military Decision-Making", "comment": "54 pages; 11 figures", "summary": "As military organisations consider integrating large language models (LLMs)\ninto command and control (C2) systems for planning and decision support,\nunderstanding their behavioural tendencies is critical. This study develops a\nbenchmarking framework for evaluating aspects of legal and moral risk in\ntargeting behaviour by comparing LLMs acting as agents in multi-turn simulated\nconflict. We introduce four metrics grounded in International Humanitarian Law\n(IHL) and military doctrine: Civilian Target Rate (CTR) and Dual-use Target\nRate (DTR) assess compliance with legal targeting principles, while Mean and\nMax Simulated Non-combatant Casualty Value (SNCV) quantify tolerance for\ncivilian harm.\n  We evaluate three frontier models, GPT-4o, Gemini-2.5, and LLaMA-3.1, through\n90 multi-agent, multi-turn crisis simulations across three geographic regions.\nOur findings reveal that off-the-shelf LLMs exhibit concerning and\nunpredictable targeting behaviour in simulated conflict environments. All\nmodels violated the IHL principle of distinction by targeting civilian objects,\nwith breach rates ranging from 16.7% to 66.7%. Harm tolerance escalated through\ncrisis simulations with MeanSNCV increasing from 16.5 in early turns to 27.7 in\nlate turns. Significant inter-model variation emerged: LLaMA-3.1 selected an\naverage of 3.47 civilian strikes per simulation with MeanSNCV of 28.4, while\nGemini-2.5 selected 0.90 civilian strikes with MeanSNCV of 17.6. These\ndifferences indicate that model selection for deployment constitutes a choice\nabout acceptable legal and moral risk profiles in military operations.\n  This work seeks to provide a proof-of-concept of potential behavioural risks\nthat could emerge from the use of LLMs in Decision Support Systems (AI DSS) as\nwell as a reproducible benchmarking framework with interpretable metrics for\nstandardising pre-deployment testing.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u6d4b\u8bd5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u62df\u519b\u4e8b\u51b2\u7a81\u4e2d\u7684\u76ee\u6807\u9009\u62e9\u884c\u4e3a\uff0c\u53d1\u73b0\u73b0\u6210\u7684LLM\u5728\u6a21\u62df\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u4ee4\u4eba\u62c5\u5fe7\u4e14\u4e0d\u53ef\u9884\u6d4b\u7684\u8fdd\u89c4\u884c\u4e3a\uff0c\u5305\u62ec\u8fdd\u53cd\u56fd\u9645\u4eba\u9053\u6cd5\u539f\u5219\u653b\u51fb\u5e73\u6c11\u76ee\u6807\u3002", "motivation": "\u968f\u7740\u519b\u4e8b\u7ec4\u7ec7\u8003\u8651\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u6307\u6325\u63a7\u5236\u7cfb\u7edf\u4e2d\u7528\u4e8e\u89c4\u5212\u548c\u51b3\u7b56\u652f\u6301\uff0c\u4e86\u89e3\u5176\u884c\u4e3a\u503e\u5411\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u8bc4\u4f30\u5176\u5728\u76ee\u6807\u9009\u62e9\u4e2d\u7684\u6cd5\u5f8b\u548c\u9053\u5fb7\u98ce\u9669\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u56fd\u9645\u4eba\u9053\u6cd5\u548c\u519b\u4e8b\u5b66\u8bf4\u7684\u56db\u4e2a\u8bc4\u4f30\u6307\u6807\uff0c\u901a\u8fc790\u4e2a\u591a\u667a\u80fd\u4f53\u3001\u591a\u8f6e\u5371\u673a\u6a21\u62df\uff0c\u5728\u4e09\u4e2a\u5730\u7406\u533a\u57df\u8bc4\u4f30GPT-4o\u3001Gemini-2.5\u548cLLaMA-3.1\u4e09\u4e2a\u524d\u6cbf\u6a21\u578b\u7684\u884c\u4e3a\u3002", "result": "\u6240\u6709\u6a21\u578b\u90fd\u8fdd\u53cd\u4e86\u56fd\u9645\u4eba\u9053\u6cd5\u7684\u533a\u5206\u539f\u5219\uff0c\u653b\u51fb\u5e73\u6c11\u76ee\u6807\u7684\u6bd4\u4f8b\u4ece16.7%\u523066.7%\u4e0d\u7b49\u3002\u4f24\u5bb3\u5bb9\u5fcd\u5ea6\u5728\u5371\u673a\u6a21\u62df\u4e2d\u9010\u6b65\u5347\u7ea7\uff0c\u6a21\u578b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0cLLaMA-3.1\u8868\u73b0\u6700\u5dee\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6982\u5ff5\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u5728\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\u4f7f\u7528LLM\u53ef\u80fd\u51fa\u73b0\u7684\u6f5c\u5728\u884c\u4e3a\u98ce\u9669\uff0c\u4ee5\u53ca\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u6807\u51c6\u5316\u90e8\u7f72\u524d\u6d4b\u8bd5\u3002"}}
{"id": "2510.03612", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.03612", "abs": "https://arxiv.org/abs/2510.03612", "authors": ["Tanqiu Jiang", "Min Bai", "Nikolaos Pappas", "Yanjun Qi", "Sandesh Swamy"], "title": "Cross-Modal Content Optimization for Steering Web Agent Preferences", "comment": null, "summary": "Vision-language model (VLM)-based web agents increasingly power high-stakes\nselection tasks like content recommendation or product ranking by combining\nmultimodal perception with preference reasoning. Recent studies reveal that\nthese agents are vulnerable against attackers who can bias selection outcomes\nthrough preference manipulations using adversarial pop-ups, image\nperturbations, or content tweaks. Existing work, however, either assumes strong\nwhite-box access, with limited single-modal perturbations, or uses impractical\nsettings. In this paper, we demonstrate, for the first time, that joint\nexploitation of visual and textual channels yields significantly more powerful\npreference manipulations under realistic attacker capabilities. We introduce\nCross-Modal Preference Steering (CPS) that jointly optimizes imperceptible\nmodifications to an item's visual and natural language descriptions, exploiting\nCLIP-transferable image perturbations and RLHF-induced linguistic biases to\nsteer agent decisions. In contrast to prior studies that assume gradient\naccess, or control over webpages, or agent memory, we adopt a realistic\nblack-box threat setup: a non-privileged adversary can edit only their own\nlisting's images and textual metadata, with no insight into the agent's model\ninternals. We evaluate CPS on agents powered by state-of-the-art proprietary\nand open source VLMs including GPT-4.1, Qwen-2.5VL and Pixtral-Large on both\nmovie selection and e-commerce tasks. Our results show that CPS is\nsignificantly more effective than leading baseline methods. For instance, our\nresults show that CPS consistently outperforms baselines across all models\nwhile maintaining 70% lower detection rates, demonstrating both effectiveness\nand stealth. These findings highlight an urgent need for robust defenses as\nagentic systems play an increasingly consequential role in society.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8de8\u6a21\u6001\u504f\u597d\u5f15\u5bfc(CPS)\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u89c6\u89c9\u548c\u6587\u672c\u901a\u9053\u7684\u4e0d\u53ef\u5bdf\u89c9\u4fee\u6539\uff0c\u5728\u73b0\u5b9e\u9ed1\u76d2\u5a01\u80c1\u8bbe\u7f6e\u4e0b\u6709\u6548\u64cd\u7eb5\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7f51\u7edc\u4ee3\u7406\u9009\u62e9\u51b3\u7b56\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8981\u4e48\u5047\u8bbe\u5f3a\u767d\u76d2\u8bbf\u95ee\uff0c\u8981\u4e48\u4f7f\u7528\u4e0d\u5207\u5b9e\u9645\u7684\u8bbe\u7f6e\uff0c\u800c\u672c\u6587\u9996\u6b21\u8bc1\u660e\u5728\u73b0\u5b9e\u653b\u51fb\u8005\u80fd\u529b\u4e0b\uff0c\u8054\u5408\u5229\u7528\u89c6\u89c9\u548c\u6587\u672c\u901a\u9053\u53ef\u4ee5\u4ea7\u751f\u66f4\u5f3a\u5927\u7684\u504f\u597d\u64cd\u7eb5\u3002", "method": "\u5f15\u5165\u8de8\u6a21\u6001\u504f\u597d\u5f15\u5bfc(CPS)\uff0c\u8054\u5408\u4f18\u5316\u5546\u54c1\u89c6\u89c9\u548c\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u4e0d\u53ef\u5bdf\u89c9\u4fee\u6539\uff0c\u5229\u7528CLIP\u53ef\u8fc1\u79fb\u56fe\u50cf\u6270\u52a8\u548cRLHF\u8bf1\u5bfc\u7684\u8bed\u8a00\u504f\u89c1\u6765\u5f15\u5bfc\u4ee3\u7406\u51b3\u7b56\u3002", "result": "\u5728\u7535\u5f71\u9009\u62e9\u548c\u7535\u5b50\u5546\u52a1\u4efb\u52a1\u4e0a\uff0cCPS\u5728\u6240\u6709\u6a21\u578b\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u630170%\u66f4\u4f4e\u7684\u68c0\u6d4b\u7387\uff0c\u8bc1\u660e\u4e86\u6709\u6548\u6027\u548c\u9690\u853d\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u7a81\u663e\u4e86\u968f\u7740\u667a\u80fd\u7cfb\u7edf\u5728\u793e\u4f1a\u4e2d\u626e\u6f14\u8d8a\u6765\u8d8a\u91cd\u8981\u7684\u89d2\u8272\uff0c\u8feb\u5207\u9700\u8981\u5f3a\u5927\u7684\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2510.03815", "categories": ["eess.SY", "cs.LG", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.03815", "abs": "https://arxiv.org/abs/2510.03815", "authors": ["Yue wu"], "title": "A Trustworthy Industrial Fault Diagnosis Architecture Integrating Probabilistic Models and Large Language Models", "comment": "1tables,6 figs,11pages", "summary": "There are limitations of traditional methods and deep learning methods in\nterms of interpretability, generalization, and quantification of uncertainty in\nindustrial fault diagnosis, and there are core problems of insufficient\ncredibility in industrial fault diagnosis. The architecture performs\npreliminary analysis through a Bayesian network-based diagnostic engine and\nfeatures an LLM-driven cognitive quorum module with multimodal input\ncapabilities. The module conducts expert-level arbitration of initial diagnoses\nby analyzing structured features and diagnostic charts, prioritizing final\ndecisions after conflicts are identified. To ensure the reliability of the\nsystem output, the architecture integrates a confidence calibration module\nbased on temperature calibration and a risk assessment module, which\nobjectively quantifies the reliability of the system using metrics such as\nexpected calibration error (ECE). Experimental results on a dataset containing\nmultiple fault types showed that the proposed framework improved diagnostic\naccuracy by more than 28 percentage points compared to the baseline model,\nwhile the calibrated ECE was reduced by more than 75%. Case studies have\nconfirmed that HCAA effectively corrects misjudgments caused by complex feature\npatterns or knowledge gaps in traditional models, providing novel and practical\nengineering solutions for building high-trust, explainable AI diagnostic\nsystems for industrial applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8d1d\u53f6\u65af\u7f51\u7edc\u548cLLM\u7684\u5de5\u4e1a\u6545\u969c\u8bca\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u6821\u51c6\u548c\u98ce\u9669\u8bc4\u4f30\u6a21\u5757\u63d0\u9ad8\u7cfb\u7edf\u53ef\u9760\u6027\uff0c\u8bca\u65ad\u51c6\u786e\u7387\u63d0\u534728\u4e2a\u767e\u5206\u70b9\uff0c\u6821\u51c6\u8bef\u5dee\u964d\u4f4e75%\u4ee5\u4e0a\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u5de5\u4e1a\u6545\u969c\u8bca\u65ad\u4e2d\u5b58\u5728\u53ef\u89e3\u91ca\u6027\u3001\u6cdb\u5316\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5bfc\u81f4\u8bca\u65ad\u7ed3\u679c\u53ef\u4fe1\u5ea6\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u7f51\u7edc\u8bca\u65ad\u5f15\u64ce\u8fdb\u884c\u521d\u6b65\u5206\u6790\uff0c\u7ed3\u5408LLM\u9a71\u52a8\u7684\u8ba4\u77e5\u4ef2\u88c1\u6a21\u5757\u5904\u7406\u591a\u6a21\u6001\u8f93\u5165\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u6821\u51c6\u548c\u98ce\u9669\u8bc4\u4f30\u6a21\u5757\u91cf\u5316\u7cfb\u7edf\u53ef\u9760\u6027\u3002", "result": "\u5728\u591a\u6545\u969c\u7c7b\u578b\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u8bca\u65ad\u51c6\u786e\u7387\u63d0\u5347\u8d85\u8fc728\u4e2a\u767e\u5206\u70b9\uff0c\u6821\u51c6ECE\u964d\u4f4e\u8d85\u8fc775%\u3002", "conclusion": "HCAA\u6846\u67b6\u6709\u6548\u7ea0\u6b63\u4f20\u7edf\u6a21\u578b\u56e0\u590d\u6742\u7279\u5f81\u6a21\u5f0f\u6216\u77e5\u8bc6\u7a7a\u767d\u5bfc\u81f4\u7684\u8bef\u5224\uff0c\u4e3a\u6784\u5efa\u9ad8\u53ef\u4fe1\u5ea6\u3001\u53ef\u89e3\u91ca\u7684\u5de5\u4e1aAI\u8bca\u65ad\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u9896\u5b9e\u7528\u7684\u5de5\u7a0b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03532", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03532", "abs": "https://arxiv.org/abs/2510.03532", "authors": ["Zekai Liang", "Kazuya Miyata", "Xiao Liang", "Florian Richter", "Michael C. Yip"], "title": "Efficient Surgical Robotic Instrument Pose Reconstruction in Real World Conditions Using Unified Feature Detection", "comment": null, "summary": "Accurate camera-to-robot calibration is essential for any vision-based\nrobotic control system and especially critical in minimally invasive surgical\nrobots, where instruments conduct precise micro-manipulations. However, MIS\nrobots have long kinematic chains and partial visibility of their degrees of\nfreedom in the camera, which introduces challenges for conventional\ncamera-to-robot calibration methods that assume stiff robots with good\nvisibility. Previous works have investigated both keypoint-based and\nrendering-based approaches to address this challenge in real-world conditions;\nhowever, they often struggle with consistent feature detection or have long\ninference times, neither of which are ideal for online robot control. In this\nwork, we propose a novel framework that unifies the detection of geometric\nprimitives (keypoints and shaft edges) through a shared encoding, enabling\nefficient pose estimation via projection geometry. This architecture detects\nboth keypoints and edges in a single inference and is trained on large-scale\nsynthetic data with projective labeling. This method is evaluated across both\nfeature detection and pose estimation, with qualitative and quantitative\nresults demonstrating fast performance and state-of-the-art accuracy in\nchallenging surgical environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u76f8\u673a-\u673a\u5668\u4eba\u6807\u5b9a\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u7f16\u7801\u7edf\u4e00\u68c0\u6d4b\u51e0\u4f55\u57fa\u5143\uff08\u5173\u952e\u70b9\u548c\u8f74\u8fb9\u7f18\uff09\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u624b\u672f\u73af\u5883\u4e2d\u5b9e\u73b0\u5feb\u901f\u4e14\u6700\u5148\u8fdb\u7684\u7cbe\u5ea6\u3002", "motivation": "\u5fae\u521b\u624b\u672f\u673a\u5668\u4eba\u5177\u6709\u957f\u8fd0\u52a8\u94fe\u548c\u90e8\u5206\u81ea\u7531\u5ea6\u53ef\u89c1\u6027\uff0c\u4f20\u7edf\u6807\u5b9a\u65b9\u6cd5\u5047\u8bbe\u521a\u6027\u673a\u5668\u4eba\u548c\u826f\u597d\u53ef\u89c1\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5728\u7ebf\u673a\u5668\u4eba\u63a7\u5236\u9700\u6c42\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u7279\u5f81\u68c0\u6d4b\u4e00\u81f4\u6027\u6216\u63a8\u7406\u65f6\u95f4\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u5171\u4eab\u7f16\u7801\u7edf\u4e00\u68c0\u6d4b\u5173\u952e\u70b9\u548c\u8f74\u8fb9\u7f18\u51e0\u4f55\u57fa\u5143\uff0c\u5728\u5355\u6b21\u63a8\u7406\u4e2d\u540c\u65f6\u68c0\u6d4b\u4e24\u8005\uff0c\u4f7f\u7528\u5927\u89c4\u6a21\u5408\u6210\u6570\u636e\u548c\u6295\u5f71\u6807\u7b7e\u8fdb\u884c\u8bad\u7ec3\uff0c\u901a\u8fc7\u6295\u5f71\u51e0\u4f55\u5b9e\u73b0\u9ad8\u6548\u4f4d\u59ff\u4f30\u8ba1\u3002", "result": "\u5728\u7279\u5f81\u68c0\u6d4b\u548c\u4f4d\u59ff\u4f30\u8ba1\u65b9\u9762\u8fdb\u884c\u8bc4\u4f30\uff0c\u5b9a\u6027\u548c\u5b9a\u91cf\u7ed3\u679c\u663e\u793a\u5728\u6311\u6218\u6027\u624b\u672f\u73af\u5883\u4e2d\u5177\u6709\u5feb\u901f\u6027\u80fd\u548c\u6700\u5148\u8fdb\u7684\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u624b\u672f\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u5feb\u901f\u4e14\u51c6\u786e\u7684\u76f8\u673a-\u673a\u5668\u4eba\u6807\u5b9a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u5fae\u521b\u624b\u672f\u673a\u5668\u4eba\u6807\u5b9a\u4e2d\u7684\u6311\u6218\u3002"}}
{"id": "2510.03719", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.03719", "abs": "https://arxiv.org/abs/2510.03719", "authors": ["Griffin Pitts", "Anurata Prabha Hridi", "Arun-Balajiee Lekshmi-Narayanan"], "title": "A Survey of LLM-Based Applications in Programming Education: Balancing Automation and Human Oversight", "comment": "2025 EMNLP HCI+NLP Workshop Short Paper", "summary": "Novice programmers benefit from timely, personalized support that addresses\nindividual learning gaps, yet the availability of instructors and teaching\nassistants is inherently limited. Large language models (LLMs) present\nopportunities to scale such support, though their effectiveness depends on how\nwell technical capabilities are aligned with pedagogical goals. This survey\nsynthesizes recent work on LLM applications in programming education across\nthree focal areas: formative code feedback, assessment, and knowledge modeling.\nWe identify recurring design patterns in how these tools are applied and find\nthat interventions are most effective when educator expertise complements model\noutput through human-in-the-loop oversight, scaffolding, and evaluation. Fully\nautomated approaches are often constrained in capturing the pedagogical nuances\nof programming education, although human-in-the-loop designs and course\nspecific adaptation offer promising directions for future improvement. Future\nresearch should focus on improving transparency, strengthening alignment with\npedagogy, and developing systems that flexibly adapt to the needs of varied\nlearning contexts.", "AI": {"tldr": "\u8be5\u8c03\u67e5\u8bba\u6587\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7f16\u7a0b\u6559\u80b2\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u5173\u6ce8\u4ee3\u7801\u53cd\u9988\u3001\u8bc4\u4f30\u548c\u77e5\u8bc6\u5efa\u6a21\u4e09\u4e2a\u9886\u57df\uff0c\u53d1\u73b0\u7ed3\u5408\u6559\u80b2\u8005\u4e13\u4e1a\u77e5\u8bc6\u7684\u534a\u81ea\u52a8\u5316\u65b9\u6cd5\u6bd4\u5168\u81ea\u52a8\u5316\u65b9\u6cd5\u66f4\u6709\u6548\u3002", "motivation": "\u65b0\u624b\u7a0b\u5e8f\u5458\u9700\u8981\u53ca\u65f6\u4e2a\u6027\u5316\u7684\u652f\u6301\uff0c\u4f46\u6559\u5e08\u8d44\u6e90\u6709\u9650\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u6269\u5c55\u8fd9\u79cd\u652f\u6301\u7684\u673a\u4f1a\uff0c\u4f46\u5176\u6709\u6548\u6027\u53d6\u51b3\u4e8e\u6280\u672f\u80fd\u529b\u4e0e\u6559\u5b66\u76ee\u6807\u7684\u5339\u914d\u7a0b\u5ea6\u3002", "method": "\u901a\u8fc7\u8c03\u67e5\u5206\u6790\u8fd1\u671f\u5173\u4e8eLLM\u5728\u7f16\u7a0b\u6559\u80b2\u4e2d\u5e94\u7528\u7684\u7814\u7a76\uff0c\u8bc6\u522b\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u7279\u522b\u5173\u6ce8\u4ee3\u7801\u53cd\u9988\u3001\u8bc4\u4f30\u548c\u77e5\u8bc6\u5efa\u6a21\u4e09\u4e2a\u6838\u5fc3\u9886\u57df\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u6559\u80b2\u8005\u4e13\u4e1a\u77e5\u8bc6\u901a\u8fc7\u4eba\u5728\u56de\u8def\u76d1\u7763\u3001\u652f\u67b6\u5f0f\u6559\u5b66\u548c\u8bc4\u4f30\u6765\u8865\u5145\u6a21\u578b\u8f93\u51fa\u65f6\uff0c\u5e72\u9884\u63aa\u65bd\u6700\u6709\u6548\u3002\u5168\u81ea\u52a8\u5316\u65b9\u6cd5\u5728\u6355\u6349\u7f16\u7a0b\u6559\u80b2\u7684\u6559\u5b66\u7ec6\u5fae\u5dee\u522b\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u5e94\u805a\u7126\u4e8e\u63d0\u9ad8\u900f\u660e\u5ea6\u3001\u52a0\u5f3a\u4e0e\u6559\u5b66\u6cd5\u7684\u5bf9\u9f50\uff0c\u4ee5\u53ca\u5f00\u53d1\u80fd\u591f\u7075\u6d3b\u9002\u5e94\u4e0d\u540c\u5b66\u4e60\u60c5\u5883\u9700\u6c42\u7684\u7cfb\u7edf\u3002\u4eba\u5728\u56de\u8def\u8bbe\u8ba1\u548c\u8bfe\u7a0b\u7279\u5b9a\u9002\u5e94\u662f\u672a\u6765\u6539\u8fdb\u7684\u6709\u5e0c\u671b\u65b9\u5411\u3002"}}
{"id": "2510.03632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03632", "abs": "https://arxiv.org/abs/2510.03632", "authors": ["Jiaxi Li", "Yucheng Shi", "Jin Lu", "Ninghao Liu"], "title": "MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information", "comment": "18 pages", "summary": "Tree search has become as a representative framework for test-time reasoning\nwith large language models (LLMs), exemplified by methods such as\nTree-of-Thought and Monte Carlo Tree Search that explore multiple reasoning\npaths. However, it remains difficult to provide instant and reliable\nquantitative assessments of intermediate reasoning step quality, and extensive\npath exploration is computationally costly. To address this, we propose Mutual\nInformation Tree Search (MITS), a novel framework that guides reasoning with\ninformation-theoretic principles. MITS introduces an effective scoring function\nbased on pointwise mutual information (PMI), which enables step-wise evaluation\nof reasoning paths and search tree expansion via beam search without expensive\nlook-ahead simulations, achieving superior reasoning performances while\nmaintaining computational efficiency. The framework is complemented by an\nentropy-based dynamic sampling strategy that adaptively allocates computational\nresources to uncertain reasoning steps where exploration is most beneficial.\nFor final prediction, MITS employs a weighted voting scheme that combines PMI\nscores with prediction consensus. Through comprehensive experiments on diverse\nreasoning benchmarks, MITS consistently surpasses baseline methods,\nestablishing a principled and efficient framework for LLM reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u6811\u641c\u7d22\u6846\u67b6MITS\uff0c\u901a\u8fc7\u70b9\u4e92\u4fe1\u606f\u8bc4\u5206\u51fd\u6570\u548c\u52a8\u6001\u91c7\u6837\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6811\u641c\u7d22\u65b9\u6cd5\u96be\u4ee5\u5bf9\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u8fdb\u884c\u5373\u65f6\u53ef\u9760\u7684\u91cf\u5316\u8bc4\u4f30\uff0c\u4e14\u5e7f\u6cdb\u8def\u5f84\u63a2\u7d22\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u70b9\u4e92\u4fe1\u606f\u7684\u8bc4\u5206\u51fd\u6570\uff0c\u901a\u8fc7\u675f\u641c\u7d22\u6269\u5c55\u641c\u7d22\u6811\u800c\u65e0\u9700\u6602\u8d35\u7684\u524d\u77bb\u6a21\u62df\uff1b\u91c7\u7528\u57fa\u4e8e\u71b5\u7684\u52a8\u6001\u91c7\u6837\u7b56\u7565\u81ea\u9002\u5e94\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff1b\u4f7f\u7528\u52a0\u6743\u6295\u7968\u65b9\u6848\u7ed3\u5408PMI\u5206\u6570\u548c\u9884\u6d4b\u5171\u8bc6\u8fdb\u884c\u6700\u7ec8\u9884\u6d4b\u3002", "result": "\u5728\u591a\u6837\u5316\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMITS\u59cb\u7ec8\u8d85\u8d8a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MITS\u4e3aLLM\u63a8\u7406\u5efa\u7acb\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u4e14\u9ad8\u6548\u7684\u6846\u67b6\u3002"}}
{"id": "2510.03867", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03867", "abs": "https://arxiv.org/abs/2510.03867", "authors": ["Yiheng Xie", "Wenqi Cui", "Adam Wierman"], "title": "Enhancing Data Center Low-Voltage Ride-Through", "comment": null, "summary": "Data center loads have expanded significantly in recent years. Compared to\ntraditional loads, data centers are highly sensitive to voltage deviations and\nthus their protection mechanisms trip more proactively during voltage\nfluctuations. During a grid fault, simultaneous tripping of large-scale data\ncenters can further destabilize the transmission system and even lead to\ncascading failures. In response, transmission system operators are imposing\nvoltage ride-through (VRT) requirements for data centers. In this work, we\nenhance the VRT capability of data centers by designing voltage controllers for\ntheir internal power distribution network. We first systematically analyze VRT\nstandards and the controllable resources related to data centers. These\nresources enable the design of voltage control strategies to regulate voltages\ninternal to the data center, thereby allowing loads to remain online during\nvoltage disturbances from the external transmission grid. We study and contrast\nboth centralized and decentralized controllers that unify the control of\nheterogeneous flexible resources. Additionally, we construct an integrated test\nsystem that simulates both the transient fault response of the transmission\nsystem and the data center distribution network. Case studies demonstrate that\nthe proposed voltage control mechanisms provide effective yet simple solutions\nto enhance data center low-voltage ride-through capability.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u6570\u636e\u4e2d\u5fc3\u5185\u90e8\u7535\u538b\u63a7\u5236\u5668\u6765\u63d0\u5347\u5176\u4f4e\u7535\u538b\u7a7f\u8d8a\u80fd\u529b\uff0c\u901a\u8fc7\u96c6\u4e2d\u5f0f\u548c\u5206\u6563\u5f0f\u63a7\u5236\u7b56\u7565\u8c03\u8282\u6570\u636e\u4e2d\u5fc3\u5185\u90e8\u7535\u538b\uff0c\u4f7f\u5176\u5728\u7535\u7f51\u6545\u969c\u65f6\u4fdd\u6301\u8fd0\u884c\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u8d1f\u8f7d\u5bf9\u7535\u538b\u504f\u5dee\u9ad8\u5ea6\u654f\u611f\uff0c\u5927\u89c4\u6a21\u6570\u636e\u4e2d\u5fc3\u540c\u65f6\u8df3\u95f8\u4f1a\u8fdb\u4e00\u6b65\u7834\u574f\u8f93\u7535\u7cfb\u7edf\u7a33\u5b9a\u6027\uff0c\u751a\u81f3\u5bfc\u81f4\u7ea7\u8054\u6545\u969c\u3002\u8f93\u7535\u7cfb\u7edf\u8fd0\u8425\u5546\u56e0\u6b64\u5bf9\u6570\u636e\u4e2d\u5fc3\u65bd\u52a0\u7535\u538b\u7a7f\u8d8a\u8981\u6c42\u3002", "method": "\u7cfb\u7edf\u5206\u6790\u7535\u538b\u7a7f\u8d8a\u6807\u51c6\u548c\u6570\u636e\u4e2d\u5fc3\u53ef\u63a7\u8d44\u6e90\uff0c\u8bbe\u8ba1\u96c6\u4e2d\u5f0f\u548c\u5206\u6563\u5f0f\u7535\u538b\u63a7\u5236\u5668\u6765\u7edf\u4e00\u63a7\u5236\u5f02\u6784\u7075\u6d3b\u8d44\u6e90\uff0c\u6784\u5efa\u96c6\u6210\u6d4b\u8bd5\u7cfb\u7edf\u6a21\u62df\u8f93\u7535\u7cfb\u7edf\u548c\u6570\u636e\u4e2d\u5fc3\u914d\u7535\u7f51\u7684\u6682\u6001\u6545\u969c\u54cd\u5e94\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7535\u538b\u63a7\u5236\u673a\u5236\u4e3a\u589e\u5f3a\u6570\u636e\u4e2d\u5fc3\u4f4e\u7535\u538b\u7a7f\u8d8a\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u7b80\u5355\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u8bbe\u8ba1\u6570\u636e\u4e2d\u5fc3\u5185\u90e8\u7535\u538b\u63a7\u5236\u5668\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u5176\u7535\u538b\u7a7f\u8d8a\u80fd\u529b\uff0c\u786e\u4fdd\u5728\u7535\u7f51\u7535\u538b\u6270\u52a8\u671f\u95f4\u6570\u636e\u4e2d\u5fc3\u8d1f\u8f7d\u4fdd\u6301\u5728\u7ebf\u8fd0\u884c\u3002"}}
{"id": "2510.03547", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03547", "abs": "https://arxiv.org/abs/2510.03547", "authors": ["Carina Veil", "Moritz Flaschel", "Ellen Kuhl"], "title": "Shape-Space Graphs: Fast and Collision-Free Path Planning for Soft Robots", "comment": null, "summary": "Soft robots, inspired by elephant trunks or octopus arms, offer extraordinary\nflexibility to bend, twist, and elongate in ways that rigid robots cannot.\nHowever, their motion planning remains a challenge, especially in cluttered\nenvironments with obstacles, due to their highly nonlinear and\ninfinite-dimensional kinematics. Here, we present a graph-based path planning\ntool for an elephant-trunk-inspired soft robotic arm designed with three\nartificial muscle fibers that allow for multimodal continuous deformation\nthrough contraction. Using a biomechanical model inspired by morphoelasticity\nand active filament theory, we precompute a shape library and construct a\n$k$-nearest neighbor graph in \\emph{shape space}, ensuring that each node\ncorresponds to a mechanically accurate and physically valid robot shape. For\nthe graph, we use signed distance functions to prune nodes and edges colliding\nwith obstacles, and define multi-objective edge costs based on geometric\ndistance and actuation effort, enabling energy-efficient planning with\ncollision avoidance. We demonstrate that our algorithm reliably avoids\nobstacles and generates feasible paths within milliseconds from precomputed\ngraphs using Dijkstra's algorithm. We show that including energy costs can\ndrastically reduce the actuation effort compared to geometry-only planning, at\nthe expense of longer tip trajectories. Our results highlight the potential of\nshape-space graph search for fast and reliable path planning in the field of\nsoft robotics, paving the way for real-time applications in surgical,\nindustrial, and assistive settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u641c\u7d22\u7684\u8f6f\u4f53\u673a\u5668\u4eba\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u8ba1\u7b97\u5f62\u72b6\u5e93\u548c\u6784\u5efak\u8fd1\u90bb\u56fe\uff0c\u5b9e\u73b0\u5feb\u901f\u907f\u969c\u548c\u80fd\u91cf\u9ad8\u6548\u7684\u8fd0\u52a8\u89c4\u5212\u3002", "motivation": "\u8f6f\u4f53\u673a\u5668\u4eba\u5177\u6709\u6781\u9ad8\u7684\u7075\u6d3b\u6027\uff0c\u4f46\u5728\u6742\u4e71\u73af\u5883\u4e2d\u7684\u8fd0\u52a8\u89c4\u5212\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u5176\u9ad8\u5ea6\u975e\u7ebf\u6027\u548c\u65e0\u9650\u7ef4\u8fd0\u52a8\u5b66\u7279\u6027\u3002", "method": "\u4f7f\u7528\u53d7\u5f62\u6001\u5f39\u6027\u548c\u4e3b\u52a8\u7ec6\u4e1d\u7406\u8bba\u542f\u53d1\u7684\u751f\u7269\u529b\u5b66\u6a21\u578b\u9884\u8ba1\u7b97\u5f62\u72b6\u5e93\uff0c\u6784\u5efa\u5f62\u72b6\u7a7a\u95f4\u7684k\u8fd1\u90bb\u56fe\uff0c\u5229\u7528\u7b26\u53f7\u8ddd\u79bb\u51fd\u6570\u4fee\u526a\u78b0\u649e\u8282\u70b9\u548c\u8fb9\uff0c\u57fa\u4e8e\u51e0\u4f55\u8ddd\u79bb\u548c\u9a71\u52a8\u52aa\u529b\u5b9a\u4e49\u591a\u76ee\u6807\u8fb9\u6210\u672c\u3002", "result": "\u7b97\u6cd5\u80fd\u5728\u6beb\u79d2\u7ea7\u65f6\u95f4\u5185\u53ef\u9760\u907f\u969c\u5e76\u751f\u6210\u53ef\u884c\u8def\u5f84\uff0c\u76f8\u6bd4\u7eaf\u51e0\u4f55\u89c4\u5212\u80fd\u663e\u8457\u51cf\u5c11\u9a71\u52a8\u52aa\u529b\uff0c\u4f46\u4ee3\u4ef7\u662f\u66f4\u957f\u7684\u672b\u7aef\u8f68\u8ff9\u3002", "conclusion": "\u5f62\u72b6\u7a7a\u95f4\u56fe\u641c\u7d22\u65b9\u6cd5\u4e3a\u8f6f\u4f53\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u5feb\u901f\u53ef\u9760\u7684\u8def\u5f84\u89c4\u5212\u65b9\u6848\uff0c\u4e3a\u624b\u672f\u3001\u5de5\u4e1a\u548c\u8f85\u52a9\u9886\u57df\u7684\u5b9e\u65f6\u5e94\u7528\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.03764", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.03764", "abs": "https://arxiv.org/abs/2510.03764", "authors": ["Junade Ali"], "title": "R v F (2025): Addressing the Defence of Hacking", "comment": null, "summary": "The defence of hacking (sometimes referred to as the \"Trojan Horse Defence\"\nor the \"SODDI Defence\", Some Other Dude Did It Defence) is prevalent in\ncomputer cases and a challenge for those working in the criminal justice\nsystem. Historical reviews of cases have demonstrated the defence operating to\nvarying levels of success. However, there remains an absence in academic\nliterature of case studies of how digital forensics investigators can address\nthis defence, to assist courts in acquitting the innocent and convicting the\nguilty. This case study follows the case of R v F where a defendant asserted\nthis defence and the author worked alongside a police investigator to\ninvestigate the merits of the defence and bring empirical evidence before the\njury. As the first case study of its kind, it presents practical lessons and\ntechniques for digital forensic investigators.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7R v F\u6848\u4f8b\u7814\u7a76\uff0c\u5206\u6790\u4e86\u9ed1\u5ba2\u653b\u51fb\u8fa9\u62a4\uff08\u53c8\u79f0\"\u7279\u6d1b\u4f0a\u6728\u9a6c\u8fa9\u62a4\"\u6216\"SODDI\u8fa9\u62a4\"\uff09\u5728\u8ba1\u7b97\u673a\u72af\u7f6a\u6848\u4ef6\u4e2d\u7684\u5e94\u5bf9\u7b56\u7565\uff0c\u4e3a\u6570\u5b57\u53d6\u8bc1\u8c03\u67e5\u4eba\u5458\u63d0\u4f9b\u4e86\u5b9e\u7528\u6280\u672f\u548c\u65b9\u6cd5\u3002", "motivation": "\u8ba1\u7b97\u673a\u72af\u7f6a\u6848\u4ef6\u4e2d\u9ed1\u5ba2\u653b\u51fb\u8fa9\u62a4\u666e\u904d\u5b58\u5728\u4e14\u5bf9\u5211\u4e8b\u53f8\u6cd5\u7cfb\u7edf\u6784\u6210\u6311\u6218\uff0c\u4f46\u5b66\u672f\u6587\u732e\u4e2d\u7f3a\u4e4f\u5173\u4e8e\u6570\u5b57\u53d6\u8bc1\u8c03\u67e5\u4eba\u5458\u5982\u4f55\u5e94\u5bf9\u6b64\u7c7b\u8fa9\u62a4\u7684\u6848\u4f8b\u7814\u7a76\u3002", "method": "\u4f5c\u8005\u4e0e\u8b66\u65b9\u8c03\u67e5\u4eba\u5458\u5408\u4f5c\uff0c\u901a\u8fc7R v F\u6848\u4f8b\u7814\u7a76\uff0c\u8c03\u67e5\u88ab\u544a\u63d0\u51fa\u7684\u9ed1\u5ba2\u653b\u51fb\u8fa9\u62a4\u7684\u6709\u6548\u6027\uff0c\u5e76\u5411\u966a\u5ba1\u56e2\u63d0\u4f9b\u7ecf\u9a8c\u8bc1\u636e\u3002", "result": "\u8be5\u7814\u7a76\u9996\u6b21\u63d0\u4f9b\u4e86\u6b64\u7c7b\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u6570\u5b57\u53d6\u8bc1\u8c03\u67e5\u4eba\u5458\u5e94\u5bf9\u9ed1\u5ba2\u653b\u51fb\u8fa9\u62a4\u7684\u5b9e\u9645\u7ecf\u9a8c\u548c\u6280\u672f\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u6570\u5b57\u53d6\u8bc1\u8c03\u67e5\u4eba\u5458\u63d0\u4f9b\u4e86\u5e94\u5bf9\u9ed1\u5ba2\u653b\u51fb\u8fa9\u62a4\u7684\u5b9e\u7528\u7ecf\u9a8c\u548c\u6280\u672f\uff0c\u6709\u52a9\u4e8e\u6cd5\u9662\u6b63\u786e\u533a\u5206\u65e0\u8f9c\u8005\u548c\u6709\u7f6a\u8005\u3002"}}
{"id": "2510.03680", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03680", "abs": "https://arxiv.org/abs/2510.03680", "authors": ["Bumjun Kim", "Dongjae Jeon", "Dueun Kim", "Wonje Jeung", "Albert No"], "title": "Rainbow Padding: Mitigating Early Termination in Instruction-Tuned Diffusion LLMs", "comment": "25 pages. Project page available\n  at~\\url{https://ai-isl.github.io/rainbow-padding}", "summary": "Diffusion large language models (dLLMs) have emerged as a promising\nalternative to autoregressive models, offering flexible generation orders and\nstrong performance on complex reasoning tasks. However, instruction-tuned dLLMs\nexhibit a critical vulnerability we term \\texttt{<eos>} overflow: as allocated\nsequence length increases, responses paradoxically become shorter, collapsing\ninto early termination or degenerating into streams of \\texttt{<eos>} tokens.\nAlthough noticed in practice, this issue has not been systematically analyzed.\nWe trace its root cause to the dual role of \\texttt{<eos>} as both termination\nand padding, which concentrates probability mass on \\texttt{<eos>} at later\npositions and propagates backward to trigger early termination. To address\nthis, we introduce Rainbow Padding, a simple remedy that replaces repeated\n\\texttt{<eos>} placeholders with a repeating cycle of distinct padding tokens,\ndistributing probability mass and breaking \\texttt{<eos>} dominance.\nExperiments show that Rainbow Padding substantially improves length robustness\nand output quality, with as few as seven padding tokens sufficient to prevent\nearly termination. Moreover, the method integrates efficiently into existing\ninstruction-tuned models: LoRA fine-tuning for a single epoch on minimal data\nyields significant improvements, making this solution highly practical. The\ncode is publicly available at https://github.com/quasar529/rainbow-padding.", "AI": {"tldr": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6307\u4ee4\u8c03\u4f18\u540e\u5b58\u5728<eos>\u6ea2\u51fa\u95ee\u9898\uff1a\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u589e\u52a0\uff0c\u54cd\u5e94\u53cd\u800c\u53d8\u77ed\uff0c\u5bfc\u81f4\u63d0\u524d\u7ec8\u6b62\u6216\u9000\u5316\u4e3a<eos>\u4ee4\u724c\u6d41\u3002\u4f5c\u8005\u63d0\u51fa\u4e86Rainbow Padding\u65b9\u6cd5\uff0c\u7528\u5faa\u73af\u7684\u4e0d\u540c\u586b\u5145\u4ee4\u724c\u66ff\u6362\u91cd\u590d\u7684<eos>\u5360\u4f4d\u7b26\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u6307\u4ee4\u8c03\u4f18\u7684\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728<eos>\u6ea2\u51fa\u6f0f\u6d1e\uff0c\u5f53\u5206\u914d\u7684\u5e8f\u5217\u957f\u5ea6\u589e\u52a0\u65f6\uff0c\u54cd\u5e94\u53cd\u800c\u53d8\u77ed\uff0c\u51fa\u73b0\u63d0\u524d\u7ec8\u6b62\u6216\u9000\u5316\u4e3a<eos>\u4ee4\u724c\u6d41\u7684\u95ee\u9898\uff0c\u8fd9\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5df2\u88ab\u6ce8\u610f\u5230\u4f46\u5c1a\u672a\u7cfb\u7edf\u5206\u6790\u3002", "method": "\u63d0\u51fa\u4e86Rainbow Padding\u65b9\u6cd5\uff0c\u7528\u5faa\u73af\u7684\u4e0d\u540c\u586b\u5145\u4ee4\u724c\u66ff\u6362\u91cd\u590d\u7684<eos>\u5360\u4f4d\u7b26\uff0c\u5206\u6563\u6982\u7387\u8d28\u91cf\uff0c\u6253\u7834<eos>\u7684\u4e3b\u5bfc\u5730\u4f4d\u3002\u8be5\u65b9\u6cd5\u53ef\u9ad8\u6548\u96c6\u6210\u5230\u73b0\u6709\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u4e2d\uff0c\u4ec5\u9700\u5c11\u91cf\u6570\u636e\u548c\u5355\u8f6eLoRA\u5fae\u8c03\u5373\u53ef\u663e\u8457\u6539\u8fdb\u3002", "result": "Rainbow Padding\u663e\u8457\u63d0\u9ad8\u4e86\u957f\u5ea6\u9c81\u68d2\u6027\u548c\u8f93\u51fa\u8d28\u91cf\uff0c\u4ec5\u9700\u4e03\u4e2a\u586b\u5145\u4ee4\u724c\u5373\u53ef\u9632\u6b62\u63d0\u524d\u7ec8\u6b62\u3002\u8be5\u65b9\u6cd5\u5728\u73b0\u6709\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u4e0a\u96c6\u6210\u6548\u7387\u9ad8\uff0c\u5355\u8f6eLoRA\u5fae\u8c03\u5373\u53ef\u83b7\u5f97\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "Rainbow Padding\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u4e2d<eos>\u6ea2\u51fa\u7684\u5173\u952e\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u957f\u5ea6\u9c81\u68d2\u6027\u548c\u8f93\u51fa\u8d28\u91cf\uff0c\u5177\u6709\u5f88\u9ad8\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.03887", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03887", "abs": "https://arxiv.org/abs/2510.03887", "authors": ["Anoy Saha", "Mona Ghassemi"], "title": "Electrical System Architecture for Aviation Electrification", "comment": null, "summary": "The electrification of aircraft is reshaping the foundations of aerospace\ndesign by positioning electrical systems at the center of propulsion, control,\nand onboard functionality. This chapter provides an overview of electrical\nsystem architectures for electric and hybrid electric aircraft, highlighting\nboth established principles and emerging design strategies. The discussion\nbegins with the motivations for electrification, including reducing\nenvironmental impact, improving operational efficiency, and replacing complex\npneumatic and hydraulic subsystems with lighter and more reliable electrical\nalternatives. Aircraft electrical architectures are classified into four major\ncategories: conventional, more electric, all electric, and hybrid electric. A\nrange of system topologies is examined, including direct current (DC),\nalternating current (AC), hybrid, and distributed configurations. Each is\nconsidered in terms of its effectiveness in delivering power, enabling\nredundancy, supporting fault isolation, and managing thermal performance. Real\nworld examples are presented to demonstrate practical applications, with case\nstudies drawn from the Boeing 787 Dreamliner, the Eviation Alice commuter\naircraft, and NASA X57 Maxwell demonstrator. These examples illustrate the\nongoing transition from incremental subsystem electrification toward fully\nintegrated architectures that promise higher efficiency and greater\nsustainability.", "AI": {"tldr": "\u672c\u7ae0\u6982\u8ff0\u4e86\u7535\u52a8\u548c\u6df7\u5408\u7535\u52a8\u98de\u673a\u7684\u7535\u6c14\u7cfb\u7edf\u67b6\u6784\uff0c\u8ba8\u8bba\u4e86\u7535\u6c14\u5316\u7684\u52a8\u673a\u3001\u56db\u79cd\u4e3b\u8981\u67b6\u6784\u5206\u7c7b\uff08\u5e38\u89c4\u3001\u591a\u7535\u3001\u5168\u7535\u3001\u6df7\u5408\u7535\uff09\u4ee5\u53ca\u5404\u79cd\u7cfb\u7edf\u62d3\u6251\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u5c55\u793a\u4e86\u4ece\u5b50\u7cfb\u7edf\u7535\u6c14\u5316\u5411\u5b8c\u5168\u96c6\u6210\u67b6\u6784\u7684\u8fc7\u6e21\u3002", "motivation": "\u7535\u6c14\u5316\u7684\u52a8\u673a\u5305\u62ec\u51cf\u5c11\u73af\u5883\u5f71\u54cd\u3001\u63d0\u9ad8\u8fd0\u8425\u6548\u7387\uff0c\u4ee5\u53ca\u7528\u66f4\u8f7b\u66f4\u53ef\u9760\u7684\u7535\u6c14\u66ff\u4ee3\u54c1\u53d6\u4ee3\u590d\u6742\u7684\u6c14\u52a8\u548c\u6db2\u538b\u5b50\u7cfb\u7edf\u3002", "method": "\u5c06\u98de\u673a\u7535\u6c14\u67b6\u6784\u5206\u4e3a\u56db\u7c7b\uff1a\u5e38\u89c4\u3001\u591a\u7535\u3001\u5168\u7535\u548c\u6df7\u5408\u7535\uff0c\u5e76\u68c0\u67e5\u76f4\u6d41\u3001\u4ea4\u6d41\u3001\u6df7\u5408\u548c\u5206\u5e03\u5f0f\u914d\u7f6e\u7b49\u5404\u79cd\u7cfb\u7edf\u62d3\u6251\u3002", "result": "\u901a\u8fc7\u6ce2\u97f3787\u68a6\u5e7b\u5ba2\u673a\u3001Eviation Alice\u901a\u52e4\u98de\u673a\u548cNASA X57 Maxwell\u6f14\u793a\u673a\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u548c\u4ece\u589e\u91cf\u5b50\u7cfb\u7edf\u7535\u6c14\u5316\u5411\u5b8c\u5168\u96c6\u6210\u67b6\u6784\u7684\u8fc7\u6e21\u3002", "conclusion": "\u7535\u6c14\u5316\u6b63\u5728\u91cd\u5851\u822a\u7a7a\u822a\u5929\u8bbe\u8ba1\u7684\u57fa\u7840\uff0c\u5c06\u7535\u6c14\u7cfb\u7edf\u7f6e\u4e8e\u63a8\u8fdb\u3001\u63a7\u5236\u548c\u673a\u8f7d\u529f\u80fd\u7684\u4e2d\u5fc3\uff0c\u6709\u671b\u5b9e\u73b0\u66f4\u9ad8\u7684\u6548\u7387\u548c\u66f4\u5927\u7684\u53ef\u6301\u7eed\u6027\u3002"}}
{"id": "2510.03599", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03599", "abs": "https://arxiv.org/abs/2510.03599", "authors": ["Shafeef Omar", "Majid Khadiv"], "title": "Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning", "comment": null, "summary": "We present a unified framework for multi-task locomotion and manipulation\npolicy learning grounded in a contact-explicit representation. Instead of\ndesigning different policies for different tasks, our approach unifies the\ndefinition of a task through a sequence of contact goals-desired contact\npositions, timings, and active end-effectors. This enables leveraging the\nshared structure across diverse contact-rich tasks, leading to a single policy\nthat can perform a wide range of tasks. In particular, we train a\ngoal-conditioned reinforcement learning (RL) policy to realise given contact\nplans. We validate our framework on multiple robotic embodiments and tasks: a\nquadruped performing multiple gaits, a humanoid performing multiple biped and\nquadrupedal gaits, and a humanoid executing different bimanual object\nmanipulation tasks. Each of these scenarios is controlled by a single policy\ntrained to execute different tasks grounded in contacts, demonstrating\nversatile and robust behaviours across morphologically distinct systems. Our\nresults show that explicit contact reasoning significantly improves\ngeneralisation to unseen scenarios, positioning contact-explicit policy\nlearning as a promising foundation for scalable loco-manipulation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u63a5\u89e6\u663e\u5f0f\u8868\u793a\u7684\u7edf\u4e00\u591a\u4efb\u52a1\u8fd0\u52a8\u4e0e\u64cd\u4f5c\u7b56\u7565\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u63a5\u89e6\u76ee\u6807\u5e8f\u5217\u5b9a\u4e49\u4efb\u52a1\uff0c\u5b9e\u73b0\u5355\u4e00\u7b56\u7565\u6267\u884c\u591a\u79cd\u63a5\u89e6\u5bc6\u96c6\u578b\u4efb\u52a1", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u4e3a\u4e0d\u540c\u4efb\u52a1\u8bbe\u8ba1\u4e0d\u540c\u7b56\u7565\uff0c\u7f3a\u4e4f\u7edf\u4e00\u6846\u67b6\u6765\u5229\u7528\u63a5\u89e6\u5bc6\u96c6\u578b\u4efb\u52a1\u95f4\u7684\u5171\u4eab\u7ed3\u6784", "method": "\u4f7f\u7528\u63a5\u89e6\u76ee\u6807\u5e8f\u5217\uff08\u671f\u671b\u63a5\u89e6\u4f4d\u7f6e\u3001\u65f6\u5e8f\u548c\u6d3b\u52a8\u672b\u7aef\u6267\u884c\u5668\uff09\u7edf\u4e00\u4efb\u52a1\u5b9a\u4e49\uff0c\u8bad\u7ec3\u76ee\u6807\u6761\u4ef6\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u6765\u5b9e\u73b0\u7ed9\u5b9a\u63a5\u89e6\u8ba1\u5212", "result": "\u5728\u591a\u79cd\u673a\u5668\u4eba\u5f62\u6001\u548c\u4efb\u52a1\u4e0a\u9a8c\u8bc1\uff1a\u56db\u8db3\u673a\u5668\u4eba\u591a\u79cd\u6b65\u6001\u3001\u4eba\u5f62\u673a\u5668\u4eba\u53cc\u8db3/\u56db\u8db3\u6b65\u6001\u3001\u53cc\u624b\u7269\u4f53\u64cd\u4f5c\u4efb\u52a1\uff0c\u5355\u4e00\u7b56\u7565\u5747\u80fd\u6267\u884c\u4e0d\u540c\u63a5\u89e6\u4efb\u52a1", "conclusion": "\u663e\u5f0f\u63a5\u89e6\u63a8\u7406\u663e\u8457\u63d0\u9ad8\u5bf9\u672a\u89c1\u573a\u666f\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u63a5\u89e6\u663e\u5f0f\u7b56\u7565\u5b66\u4e60\u4e3a\u53ef\u6269\u5c55\u7684\u8fd0\u52a8\u64cd\u4f5c\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u57fa\u7840"}}
{"id": "2510.03868", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03868", "abs": "https://arxiv.org/abs/2510.03868", "authors": ["Dalia Ali", "Muneeb Ahmed", "Hailan Wang", "Arfa Khan", "Naira Paola Arnez Jordan", "Sunnie S. Y. Kim", "Meet Dilip Muchhala", "Anne Kathrin Merkle", "Orestis Papakyriakopoulos"], "title": "AI Adoption Across Mission-Driven Organizations", "comment": "16 pages, Submitted for CHI 2026", "summary": "Despite AI's promise for addressing global challenges, empirical\nunderstanding of AI adoption in mission-driven organizations (MDOs) remains\nlimited. While research emphasizes individual applications or ethical\nprinciples, little is known about how resource-constrained, values-driven\norganizations navigate AI integration across operations. We conducted thematic\nanalysis of semi-structured interviews with 15 practitioners from\nenvironmental, humanitarian, and development organizations across the Global\nNorth and South contexts. Our analysis examines how MDOs currently deploy AI,\nwhat barriers constrain adoption, and how practitioners envision future\nintegration. MDOs adopt AI selectively, with sophisticated deployment in\ncontent creation and data analysis while maintaining human oversight for\nmission-critical applications. When AI's efficiency benefits conflict with\norganizational values, decision-making stalls rather than negotiating\ntrade-offs. This study contributes empirical evidence that AI adoption in MDOs\nshould be understood as conditional rather than inevitable, proceeding only\nwhere it strengthens organizational sovereignty and mission integrity while\npreserving human-centered approaches essential to their missions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u8bbf\u8c08\u53d1\u73b0\uff0c\u4f7f\u547d\u9a71\u52a8\u7ec4\u7ec7\u5bf9AI\u7684\u91c7\u7528\u662f\u6709\u6761\u4ef6\u7684\uff0c\u53ea\u5728\u80fd\u589e\u5f3a\u7ec4\u7ec7\u81ea\u4e3b\u6743\u548c\u4f7f\u547d\u5b8c\u6574\u6027\u7684\u60c5\u51b5\u4e0b\u4f7f\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1AI\u6709\u671b\u89e3\u51b3\u5168\u7403\u6311\u6218\uff0c\u4f46\u5bf9\u4f7f\u547d\u9a71\u52a8\u7ec4\u7ec7AI\u91c7\u7528\u7684\u5b9e\u8bc1\u7406\u89e3\u4ecd\u7136\u6709\u9650\uff0c\u7279\u522b\u662f\u8d44\u6e90\u53d7\u9650\u3001\u4ef7\u503c\u89c2\u9a71\u52a8\u7684\u7ec4\u7ec7\u5982\u4f55\u6574\u5408AI\u7f3a\u4e4f\u7814\u7a76\u3002", "method": "\u5bf9\u6765\u81ea\u5168\u7403\u5357\u5317\u73af\u5883\u3001\u4eba\u9053\u4e3b\u4e49\u548c\u5f00\u53d1\u7ec4\u7ec7\u768415\u540d\u4ece\u4e1a\u8005\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u5e76\u8fdb\u884c\u4e3b\u9898\u5206\u6790\u3002", "result": "\u4f7f\u547d\u9a71\u52a8\u7ec4\u7ec7\u6709\u9009\u62e9\u5730\u91c7\u7528AI\uff0c\u5728\u5185\u5bb9\u521b\u4f5c\u548c\u6570\u636e\u5206\u6790\u65b9\u9762\u90e8\u7f72\u8f83\u6210\u719f\uff0c\u4f46\u5bf9\u5173\u952e\u4efb\u52a1\u5e94\u7528\u4fdd\u6301\u4eba\u5de5\u76d1\u7763\u3002\u5f53AI\u6548\u7387\u4e0e\u7ec4\u7ec7\u4ef7\u503c\u89c2\u51b2\u7a81\u65f6\uff0c\u51b3\u7b56\u4f1a\u505c\u6ede\u800c\u975e\u5bfb\u6c42\u6298\u4e2d\u3002", "conclusion": "\u4f7f\u547d\u9a71\u52a8\u7ec4\u7ec7\u7684AI\u91c7\u7528\u5e94\u88ab\u7406\u89e3\u4e3a\u6709\u6761\u4ef6\u7684\u800c\u975e\u5fc5\u7136\u7684\uff0c\u53ea\u6709\u5728\u80fd\u52a0\u5f3a\u7ec4\u7ec7\u81ea\u4e3b\u6743\u548c\u4f7f\u547d\u5b8c\u6574\u6027\u3001\u540c\u65f6\u4fdd\u6301\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u65b9\u6cd5\u7684\u60c5\u51b5\u4e0b\u624d\u4f1a\u63a8\u8fdb\u3002"}}
{"id": "2510.03696", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03696", "abs": "https://arxiv.org/abs/2510.03696", "authors": ["Deepak Babu Piskala", "Sharlene Chen", "Udita Patel", "Parul Kalra", "Rafael Castrillo"], "title": "Mind the Goal: Data-Efficient Goal-Oriented Evaluation of Conversational Agents and Chatbots using Teacher Models", "comment": null, "summary": "Evaluating the quality of multi-turn chatbot interactions remains\nchallenging, as most existing methods assess interactions at the turn level\nwithout addressing whether a user's overarching goal was fulfilled. A ``goal''\nhere refers to an information need or task, such as asking for policy\ninformation or applying for leave. We propose a comprehensive framework for\ngoal-oriented evaluation of multi-agent systems (MAS), introducing the\n\\textbf{Goal Success Rate (GSR)} to measure the percentage of fulfilled goals,\nand a \\textbf{Root Cause of Failure (RCOF)} taxonomy to identify reasons for\nfailure in multi-agent chatbots. Our method segments conversations by user\ngoals and evaluates success using all relevant turns. We present a model-based\nevaluation system combining teacher LLMs, where domain experts define goals,\nset quality standards serving as a guidance for the LLMs. The LLMs use\n``thinking tokens'' to produce interpretable rationales, enabling\n\\textit{explainable}, \\textit{data-efficient} evaluations. In an enterprise\nsetting, we apply our framework to evaluate AIDA, a zero-to-one employee\nconversational agent system built as a ground-up multi-agent conversational\nagent, and observe GSR improvement from 63\\% to 79\\% over six months since its\ninception. Our framework is generic and offers actionable insights through a\ndetailed defect taxonomy based on analysis of failure points in multi-agent\nchatbots, diagnosing overall success, identifying key failure modes, and\ninforming system improvements.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9762\u5411\u76ee\u6807\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\uff0c\u5f15\u5165\u76ee\u6807\u6210\u529f\u7387(GSR)\u548c\u5931\u8d25\u6839\u56e0\u5206\u7c7b(RCOF)\uff0c\u901a\u8fc7\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\u8bc4\u4f30\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7528\u6237\u76ee\u6807\u7684\u5b8c\u6210\u60c5\u51b5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5927\u591a\u5728\u8f6e\u6b21\u5c42\u9762\u8bc4\u4f30\u591a\u8f6e\u804a\u5929\u673a\u5668\u4eba\u4ea4\u4e92\uff0c\u65e0\u6cd5\u5224\u65ad\u7528\u6237\u7684\u6838\u5fc3\u76ee\u6807\u662f\u5426\u88ab\u6ee1\u8db3\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u76ee\u6807\u5bfc\u5411\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5c06\u5bf9\u8bdd\u6309\u7528\u6237\u76ee\u6807\u5206\u6bb5\uff0c\u4f7f\u7528\u6559\u5e08LLM\u7ed3\u5408\u9886\u57df\u4e13\u5bb6\u5b9a\u4e49\u7684\u76ee\u6807\u548c\u8d28\u91cf\u6807\u51c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u901a\u8fc7\"\u601d\u8003\u6807\u8bb0\"\u751f\u6210\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u5e94\u7528\u8be5\u6846\u67b6\u8bc4\u4f30AIDA\u7cfb\u7edf\uff0c\u89c2\u5bdf\u5230\u76ee\u6807\u6210\u529f\u7387\u4ece63%\u63d0\u5347\u523079%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5177\u6709\u901a\u7528\u6027\uff0c\u901a\u8fc7\u8be6\u7ec6\u7684\u7f3a\u9677\u5206\u7c7b\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u80fd\u591f\u8bca\u65ad\u6574\u4f53\u6210\u529f\u7387\u3001\u8bc6\u522b\u5173\u952e\u5931\u8d25\u6a21\u5f0f\u5e76\u6307\u5bfc\u7cfb\u7edf\u6539\u8fdb\u3002"}}
{"id": "2510.03943", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03943", "abs": "https://arxiv.org/abs/2510.03943", "authors": ["Anirban Samanta", "Shun-Hung Lee", "Chun-Yi Cheng", "Samuel Palermo", "S. J. Ben Yoo"], "title": "3D Electronic-Photonic Heterogenous Interconnect Platforms Enabling Energy-Efficient Scalable Architectures For Future HPC Systems", "comment": null, "summary": "3D interconnects have emerged as a solution to address the scaling issues of\ninterconnect bandwidth and the memory wall problem in high-performance\ncomputing (HPC), such as High-Bandwidth Memory (HBM). However, the copper-based\nelectrical interconnect retains fundamental limitations. Dense I/O for\nhigh-speed signals lead to degraded signal quality for end-to-end links,\nnecessitating additional circuits to mitigate signal impairments and resulting\nin poor energy efficiency. We propose a 3D chiplet stacking electronic-photonic\ninterconnect (EPIC) platform, which offers a solution by moving the high-speed\ndata communication interface to the optical domain across the 3D stack by using\nThrough Silicon Optical Vias (TSOV), while retaining the functionality of\nelectrical TSVs and 2.5D interconnects for power delivery and short-reach\nlow-latency communications. We then benchmark the proposed model against\nstate-of-the-art 3D electrical interconnects to demonstrate our 3D EPIC\nplatform beating the 3D electrical interconnects to $>$10 TB/s/$mm^2$ bandwidth\ndensity. We present a pathway to extend our demonstrated, industry-ready design\nto achieving $\\leq$100 fJ/bit high-speed communication.", "AI": {"tldr": "\u63d0\u51fa3D\u82af\u7247\u5806\u53e0\u7535\u5b50-\u5149\u5b50\u4e92\u8fde\u5e73\u53f0\uff0c\u901a\u8fc7\u7845\u901a\u5149\u5b54\u5b9e\u73b0\u9ad8\u901f\u6570\u636e\u901a\u4fe1\uff0c\u7a81\u7834\u94dc\u57fa\u7535\u4e92\u8fde\u7684\u5e26\u5bbd\u5bc6\u5ea6\u9650\u5236\uff0c\u8fbe\u5230>10TB/s/mm\u00b2\u5e26\u5bbd\u5bc6\u5ea6\u548c\u2264100fJ/bit\u7684\u80fd\u6548\u3002", "motivation": "\u89e3\u51b3\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e2d\u4e92\u8fde\u5e26\u5bbd\u6269\u5c55\u548c\u5185\u5b58\u5899\u95ee\u9898\uff0c\u514b\u670d\u94dc\u57fa\u7535\u4e92\u8fde\u5728\u9ad8\u901f\u4fe1\u53f7\u4f20\u8f93\u4e2d\u7684\u4fe1\u53f7\u8d28\u91cf\u4e0b\u964d\u548c\u80fd\u6548\u4f4e\u4e0b\u7b49\u6839\u672c\u9650\u5236\u3002", "method": "\u91c7\u75283D\u82af\u7247\u5806\u53e0\u7535\u5b50-\u5149\u5b50\u4e92\u8fde\u5e73\u53f0\uff0c\u4f7f\u7528\u7845\u901a\u5149\u5b54\u57283D\u5806\u53e0\u4e2d\u5b9e\u73b0\u9ad8\u901f\u6570\u636e\u7684\u5149\u57df\u901a\u4fe1\uff0c\u540c\u65f6\u4fdd\u7559\u7535TSV\u548c2.5D\u4e92\u8fde\u7528\u4e8e\u4f9b\u7535\u548c\u77ed\u8ddd\u79bb\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u3002", "result": "3D EPIC\u5e73\u53f0\u8d85\u8d8a\u73b0\u67093D\u7535\u4e92\u8fde\uff0c\u5b9e\u73b0>10TB/s/mm\u00b2\u7684\u5e26\u5bbd\u5bc6\u5ea6\uff0c\u5e76\u5c55\u793a\u8fbe\u5230\u2264100fJ/bit\u9ad8\u901f\u901a\u4fe1\u7684\u53ef\u884c\u8def\u5f84\u3002", "conclusion": "3D\u7535\u5b50-\u5149\u5b50\u4e92\u8fde\u5e73\u53f0\u4e3a\u9ad8\u6027\u80fd\u8ba1\u7b97\u63d0\u4f9b\u4e86\u7a81\u7834\u4e92\u8fde\u5e26\u5bbd\u548c\u80fd\u6548\u9650\u5236\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u4ea7\u4e1a\u5316\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.03640", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.03640", "abs": "https://arxiv.org/abs/2510.03640", "authors": ["Mostafa Emam", "Matthias Gerdts"], "title": "Safety-Oriented Dynamic Path Planning for Automated Vehicles", "comment": "Published in 2025 IEEE 101st Vehicular Technology Conference\n  (VTC2025-Spring), Oslo, Norway, June 17-20, 2025. Received Best Conference\n  Paper Award", "summary": "Ensuring safety in autonomous vehicles necessitates advanced path planning\nand obstacle avoidance capabilities, particularly in dynamic environments. This\npaper introduces a bi-level control framework that efficiently augments road\nboundaries by incorporating time-dependent grid projections of obstacle\nmovements, thus enabling precise and adaptive path planning. The main control\nloop utilizes Nonlinear Model Predictive Control (NMPC) for real-time path\noptimization, wherein homotopy-based constraint relaxation is employed to\nimprove the solvability of the optimal control problem (OCP). Furthermore, an\nindependent backup loop runs concurrently to provide safe fallback trajectories\nwhen an optimal trajectory cannot be computed by the main loop within a\ncritical time frame, thus enhancing safety and real-time performance. Our\nevaluation showcases the benefits of the proposed methods in various driving\nscenarios, highlighting the real-time applicability and robustness of our\napproach. Overall, the framework represents a significant step towards safer\nand more reliable autonomous driving in complex and dynamic environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u53cc\u5c42\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u65f6\u95f4\u76f8\u5173\u7684\u969c\u788d\u7269\u7f51\u683c\u6295\u5f71\u589e\u5f3a\u9053\u8def\u8fb9\u754c\uff0c\u7ed3\u5408\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u548c\u540c\u4f26\u7ea6\u675f\u677e\u5f1b\u6765\u4f18\u5316\u5b9e\u65f6\u8def\u5f84\u89c4\u5212\uff0c\u5e76\u914d\u5907\u72ec\u7acb\u5907\u4efd\u56de\u8def\u786e\u4fdd\u5b89\u5168\u6027\u3002", "motivation": "\u5728\u52a8\u6001\u73af\u5883\u4e2d\u786e\u4fdd\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u5b89\u5168\u9700\u8981\u5148\u8fdb\u7684\u8def\u5f84\u89c4\u5212\u548c\u969c\u788d\u7269\u89c4\u907f\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u573a\u666f\u4e0b\u9700\u8981\u5b9e\u65f6\u4e14\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u63a7\u5236\u6846\u67b6\uff1a\u4e3b\u56de\u8def\u4f7f\u7528\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u8fdb\u884c\u5b9e\u65f6\u8def\u5f84\u4f18\u5316\uff0c\u5e76\u5e94\u7528\u540c\u4f26\u7ea6\u675f\u677e\u5f1b\u63d0\u9ad8\u6700\u4f18\u63a7\u5236\u95ee\u9898\u7684\u53ef\u89e3\u6027\uff1b\u540c\u65f6\u8fd0\u884c\u72ec\u7acb\u5907\u4efd\u56de\u8def\uff0c\u5728\u4e3b\u56de\u8def\u65e0\u6cd5\u53ca\u65f6\u8ba1\u7b97\u6700\u4f18\u8f68\u8ff9\u65f6\u63d0\u4f9b\u5b89\u5168\u5907\u7528\u8f68\u8ff9\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u9a7e\u9a76\u573a\u666f\u4e2d\u5177\u6709\u4f18\u52bf\uff0c\u8bc1\u660e\u4e86\u5176\u5b9e\u65f6\u9002\u7528\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4ee3\u8868\u4e86\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u66f4\u5b89\u5168\u53ef\u9760\u81ea\u52a8\u9a7e\u9a76\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2510.03905", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.03905", "abs": "https://arxiv.org/abs/2510.03905", "authors": ["Shintaro Sakai", "Haewoon Kwak", "Jisun An", "Akira Matsui"], "title": "Quantifying Gender Stereotypes in Japan between 1900 and 1999 with Word Embeddings", "comment": null, "summary": "We quantify the evolution of gender stereotypes in Japan from 1900 to 1999\nusing a series of 100 word embeddings, each trained on a corpus from a specific\nyear. We define the gender stereotype value to measure the strength of a word's\ngender association by computing the difference in cosine similarity of the word\nto female- versus male-related attribute words. We examine trajectories of\ngender stereotype across three traditionally gendered domains: Home, Work, and\nPolitics, as well as occupations. The results indicate that language-based\ngender stereotypes partially evolved to reflect women's increasing\nparticipation in the workplace and politics: Work and Politics domains become\nmore strongly female-stereotyped over the years. Yet, Home also became more\nfemale-stereotyped, suggesting that women were increasingly viewed as\nfulfilling multiple roles such as homemakers, workers, and politicians, rather\nthan having one role replace another. Furthermore, the strength of female\nstereotype for occupations positively correlate with the proportion of women in\neach occupation, indicating that word-embedding-based measures of gender\nstereotype mirrored demographic shifts to a considerable extent.", "AI": {"tldr": "\u4f7f\u7528100\u5e74\u7684\u8bcd\u5d4c\u5165\u5206\u6790\u65e5\u672c\u6027\u522b\u523b\u677f\u5370\u8c61\u6f14\u53d8\uff0c\u53d1\u73b0\u5de5\u4f5c\u3001\u653f\u6cbb\u9886\u57df\u5973\u6027\u523b\u677f\u5370\u8c61\u589e\u5f3a\uff0c\u5bb6\u5ead\u9886\u57df\u4e5f\u4fdd\u6301\u5973\u6027\u5316\uff0c\u8868\u660e\u5973\u6027\u627f\u62c5\u591a\u91cd\u89d2\u8272\u800c\u975e\u89d2\u8272\u66ff\u4ee3\u3002", "motivation": "\u91cf\u5316\u65e5\u672c1900-1999\u5e74\u6027\u522b\u523b\u677f\u5370\u8c61\u7684\u6f14\u53d8\uff0c\u68c0\u9a8c\u8bed\u8a00\u4e2d\u7684\u6027\u522b\u5173\u8054\u662f\u5426\u53cd\u6620\u5973\u6027\u5728\u804c\u573a\u548c\u653f\u6cbb\u4e2d\u53c2\u4e0e\u5ea6\u7684\u589e\u52a0\u3002", "method": "\u8bad\u7ec3100\u4e2a\u5e74\u5ea6\u8bcd\u5d4c\u5165\u6a21\u578b\uff0c\u901a\u8fc7\u8ba1\u7b97\u8bcd\u8bed\u4e0e\u5973\u6027/\u7537\u6027\u5c5e\u6027\u8bcd\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u5dee\u5f02\u6765\u5b9a\u4e49\u6027\u522b\u523b\u677f\u5370\u8c61\u503c\uff0c\u5206\u6790\u5bb6\u5ead\u3001\u5de5\u4f5c\u3001\u653f\u6cbb\u548c\u804c\u4e1a\u9886\u57df\u7684\u6f14\u53d8\u8f68\u8ff9\u3002", "result": "\u5de5\u4f5c\u548c\u653f\u6cbb\u9886\u57df\u968f\u65f6\u95f4\u53d8\u5f97\u66f4\u5973\u6027\u523b\u677f\u5316\uff0c\u5bb6\u5ead\u9886\u57df\u4e5f\u4fdd\u6301\u5973\u6027\u5316\uff1b\u804c\u4e1a\u7684\u5973\u6027\u523b\u677f\u5370\u8c61\u5f3a\u5ea6\u4e0e\u5973\u6027\u4ece\u4e1a\u6bd4\u4f8b\u6b63\u76f8\u5173\uff0c\u8bcd\u5d4c\u5165\u80fd\u8f83\u597d\u53cd\u6620\u4eba\u53e3\u7edf\u8ba1\u53d8\u5316\u3002", "conclusion": "\u8bed\u8a00\u4e2d\u7684\u6027\u522b\u523b\u677f\u5370\u8c61\u90e8\u5206\u53cd\u6620\u4e86\u5973\u6027\u793e\u4f1a\u89d2\u8272\u7684\u53d8\u5316\uff0c\u4f46\u5973\u6027\u88ab\u8d4b\u4e88\u591a\u91cd\u89d2\u8272\u800c\u975e\u5355\u4e00\u89d2\u8272\u66ff\u4ee3\uff0c\u8bcd\u5d4c\u5165\u65b9\u6cd5\u80fd\u6709\u6548\u8ffd\u8e2a\u793e\u4f1a\u6001\u5ea6\u6f14\u53d8\u3002"}}
{"id": "2510.03700", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03700", "abs": "https://arxiv.org/abs/2510.03700", "authors": ["Seungseop Lim", "Gibaeg Kim", "Hyunkyung Lee", "Wooseok Han", "Jean Seo", "Jaehyo Yoo", "Eunho Yang"], "title": "H-DDx: A Hierarchical Evaluation Framework for Differential Diagnosis", "comment": "GenAI4Health @NeurIPS 2025", "summary": "An accurate differential diagnosis (DDx) is essential for patient care,\nshaping therapeutic decisions and influencing outcomes. Recently, Large\nLanguage Models (LLMs) have emerged as promising tools to support this process\nby generating a DDx list from patient narratives. However, existing evaluations\nof LLMs in this domain primarily rely on flat metrics, such as Top-k accuracy,\nwhich fail to distinguish between clinically relevant near-misses and\ndiagnostically distant errors. To mitigate this limitation, we introduce H-DDx,\na hierarchical evaluation framework that better reflects clinical relevance.\nH-DDx leverages a retrieval and reranking pipeline to map free-text diagnoses\nto ICD-10 codes and applies a hierarchical metric that credits predictions\nclosely related to the ground-truth diagnosis. In benchmarking 22 leading\nmodels, we show that conventional flat metrics underestimate performance by\noverlooking clinically meaningful outputs, with our results highlighting the\nstrengths of domain-specialized open-source models. Furthermore, our framework\nenhances interpretability by revealing hierarchical error patterns,\ndemonstrating that LLMs often correctly identify the broader clinical context\neven when the precise diagnosis is missed.", "AI": {"tldr": "\u63d0\u51fa\u4e86H-DDx\u5206\u5c42\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u9274\u522b\u8bca\u65ad\u4e2d\u7684\u8868\u73b0\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u6241\u5e73\u6307\u6807\u5ffd\u7565\u4e34\u5e8a\u76f8\u5173\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u9274\u522b\u8bca\u65ad\u8bc4\u4f30\u4e2d\u4e3b\u8981\u4f9d\u8d56\u6241\u5e73\u6307\u6807\uff08\u5982Top-k\u51c6\u786e\u7387\uff09\uff0c\u8fd9\u4e9b\u6307\u6807\u65e0\u6cd5\u533a\u5206\u4e34\u5e8a\u76f8\u5173\u7684\u8fd1\u4f3c\u9519\u8bef\u548c\u8bca\u65ad\u4e0a\u76f8\u8ddd\u8f83\u8fdc\u7684\u9519\u8bef\uff0c\u9650\u5236\u4e86\u8bc4\u4f30\u7684\u4e34\u5e8a\u610f\u4e49\u3002", "method": "\u5f00\u53d1\u4e86H-DDx\u5206\u5c42\u8bc4\u4f30\u6846\u67b6\uff0c\u91c7\u7528\u68c0\u7d22\u548c\u91cd\u6392\u5e8f\u6d41\u7a0b\u5c06\u81ea\u7531\u6587\u672c\u8bca\u65ad\u6620\u5c04\u5230ICD-10\u4ee3\u7801\uff0c\u5e76\u5e94\u7528\u5206\u5c42\u6307\u6807\u6765\u5956\u52b1\u4e0e\u771f\u5b9e\u8bca\u65ad\u5bc6\u5207\u76f8\u5173\u7684\u9884\u6d4b\u3002", "result": "\u572822\u4e2a\u9886\u5148\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u53d1\u73b0\u4f20\u7edf\u6241\u5e73\u6307\u6807\u4f4e\u4f30\u4e86\u6027\u80fd\uff0c\u5ffd\u7565\u4e86\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u8f93\u51fa\uff1b\u9886\u57df\u4e13\u4e1a\u5316\u7684\u5f00\u6e90\u6a21\u578b\u8868\u73b0\u7a81\u51fa\uff1b\u6846\u67b6\u8fd8\u63ed\u793a\u4e86\u5206\u5c42\u9519\u8bef\u6a21\u5f0f\uff0c\u663e\u793aLLM\u5373\u4f7f\u9519\u8fc7\u7cbe\u786e\u8bca\u65ad\u4e5f\u80fd\u6b63\u786e\u8bc6\u522b\u66f4\u5e7f\u6cdb\u7684\u4e34\u5e8a\u80cc\u666f\u3002", "conclusion": "H-DDx\u6846\u67b6\u63d0\u4f9b\u4e86\u66f4\u4e34\u5e8a\u76f8\u5173\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u80fd\u66f4\u597d\u5730\u53cd\u6620\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u9274\u522b\u8bca\u65ad\u4e2d\u7684\u5b9e\u9645\u80fd\u529b\uff0c\u4e3a\u672a\u6765\u6a21\u578b\u5f00\u53d1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2510.03974", "categories": ["eess.SY", "cs.CV", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03974", "abs": "https://arxiv.org/abs/2510.03974", "authors": ["Sadie Cutler", "Ben DeFay", "Scott McArt", "Kirstin Petersen"], "title": "Use of Quadcopter Wakes to Supplement Strawberry Pollination", "comment": "7 pages, 7 figures", "summary": "Pollinators are critical to the world's ecosystems and food supply, yet\nrecent studies have found pollination shortfalls in several crops, including\nstrawberry. This is troubling because wild and managed pollinators are\ncurrently experiencing declines. One possibility is to try and provide\nsupplemental pollination solutions. These solutions should be affordable and\nsimple for farmers to implement if their use is to be widespread; quadcopters\nare a great example, already used for monitoring on many farms. This paper\ninvestigates a new method for artificial pollination based on wind pollination\nthat bears further investigation. After determining the height where the\nlateral flow is maximized, we performed field experiments with a quadcopter\nassisting natural pollinators. Although our results in the field were\ninconclusive, lab studies show that the idea shows promise and could be adapted\nfor better field results.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4f7f\u7528\u56db\u8f74\u98de\u884c\u5668\u8fdb\u884c\u8f85\u52a9\u6388\u7c89\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u98ce\u529b\u6388\u7c89\u673a\u5236\u6765\u5f25\u8865\u4f20\u7c89\u8005\u77ed\u7f3a\u95ee\u9898\u3002", "motivation": "\u4f20\u7c89\u8005\u5bf9\u751f\u6001\u7cfb\u7edf\u548c\u7cae\u98df\u4f9b\u5e94\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8fd1\u671f\u7814\u7a76\u53d1\u73b0\u5305\u62ec\u8349\u8393\u5728\u5185\u7684\u591a\u79cd\u4f5c\u7269\u5b58\u5728\u6388\u7c89\u4e0d\u8db3\u95ee\u9898\uff0c\u800c\u91ce\u751f\u548c\u4eba\u5de5\u7ba1\u7406\u7684\u4f20\u7c89\u8005\u6570\u91cf\u6b63\u5728\u4e0b\u964d\u3002", "method": "\u786e\u5b9a\u4fa7\u5411\u6c14\u6d41\u6700\u5927\u5316\u7684\u9ad8\u5ea6\u540e\uff0c\u5728\u7530\u95f4\u5b9e\u9a8c\u4e2d\u8ba9\u56db\u8f74\u98de\u884c\u5668\u8f85\u52a9\u81ea\u7136\u4f20\u7c89\u8005\u8fdb\u884c\u6388\u7c89\u3002", "result": "\u7530\u95f4\u5b9e\u9a8c\u7ed3\u679c\u4e0d\u786e\u5b9a\uff0c\u4f46\u5b9e\u9a8c\u5ba4\u7814\u7a76\u8868\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u6f5c\u529b\uff0c\u53ef\u4ee5\u6539\u8fdb\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u7530\u95f4\u7ed3\u679c\u3002", "conclusion": "\u57fa\u4e8e\u98ce\u529b\u6388\u7c89\u7684\u4eba\u5de5\u6388\u7c89\u65b9\u6cd5\u663e\u793a\u51fa\u524d\u666f\uff0c\u867d\u7136\u7530\u95f4\u6548\u679c\u5c1a\u4e0d\u660e\u786e\uff0c\u4f46\u53ef\u901a\u8fc7\u6539\u8fdb\u9002\u5e94\u7530\u95f4\u6761\u4ef6\u3002"}}
{"id": "2510.03644", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03644", "abs": "https://arxiv.org/abs/2510.03644", "authors": ["Mohammadjavad Javadi", "Robin Chhabra"], "title": "Geometrically Exact Hard Magneto-Elastic Cosserat Shells: Static Formulation for Shape Morphing", "comment": null, "summary": "Cosserat rod theory is the popular approach to modeling ferromagnetic soft\nrobots as 1-Dimensional (1D) slender structures in most applications, such as\nbiomedical. However, recent soft robots designed for locomotion and\nmanipulation often exhibit a large width-to-length ratio that categorizes them\nas 2D shells. For analysis and shape-morphing control purposes, we develop an\nefficient coordinate-free static model of hard-magnetic shells found in soft\nmagnetic grippers and walking soft robots. The approach is based on a novel\nformulation of Cosserat shell theory on the Special Euclidean group\n($\\mathbf{SE}(3)$). The shell is assumed to be a 2D manifold of material points\nwith six degrees of freedom (position & rotation) suitable for capturing the\nbehavior of a uniformly distributed array of spheroidal hard magnetic particles\nembedded in the rheological elastomer. The shell's configuration manifold is\nthe space of all smooth embeddings $\\mathbb{R}^2\\rightarrow\\mathbf{SE}(3)$.\nAccording to a novel definition of local deformation gradient based on the Lie\ngroup structure of $\\mathbf{SE}(3)$, we derive the strong and weak forms of\nequilibrium equations, following the principle of virtual work. We extract the\nlinearized version of the weak form for numerical implementations. The\nresulting finite element approach can avoid well-known challenges such as\nsingularity and locking phenomenon in modeling shell structures. The proposed\nmodel is analytically and experimentally validated through a series of test\ncases that demonstrate its superior efficacy, particularly when the shell\nundergoes severe rotations and displacements.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCosserat\u58f3\u7406\u8bba\u7684\u786c\u78c1\u58f3\u9ad8\u6548\u9759\u6001\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u5927\u5bbd\u957f\u6bd4\u7684\u8f6f\u78c1\u673a\u5668\u4eba\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf1D\u6a21\u578b\u57282D\u58f3\u7ed3\u6784\u5efa\u6a21\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709Cosserat\u6746\u7406\u8bba\u4e3b\u8981\u9488\u5bf91D\u7ec6\u957f\u7ed3\u6784\uff0c\u800c\u73b0\u4ee3\u8f6f\u673a\u5668\u4eba\u5728\u8fd0\u52a8\u548c\u64cd\u4f5c\u4e2d\u5e38\u5448\u73b0\u5927\u5bbd\u957f\u6bd4\u76842D\u58f3\u7ed3\u6784\u7279\u5f81\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5408\u9002\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u7279\u6b8a\u6b27\u51e0\u91cc\u5f97\u7fa4(SE(3))\u7684Cosserat\u58f3\u7406\u8bba\uff0c\u5c06\u58f3\u89c6\u4e3a\u5177\u6709\u516d\u81ea\u7531\u5ea6\u76842D\u6d41\u5f62\uff0c\u63a8\u5bfc\u4e86\u57fa\u4e8e\u674e\u7fa4\u7ed3\u6784\u7684\u5c40\u90e8\u53d8\u5f62\u68af\u5ea6\u5b9a\u4e49\u548c\u5e73\u8861\u65b9\u7a0b\u7684\u5f3a\u3001\u5f31\u5f62\u5f0f\u3002", "result": "\u5f00\u53d1\u4e86\u6709\u9650\u5143\u65b9\u6cd5\uff0c\u907f\u514d\u4e86\u58f3\u7ed3\u6784\u5efa\u6a21\u4e2d\u7684\u5947\u70b9\u548c\u9501\u5b9a\u73b0\u8c61\uff0c\u5728\u58f3\u7ecf\u5386\u5927\u65cb\u8f6c\u548c\u4f4d\u79fb\u65f6\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u786c\u78c1\u58f3\u7ed3\u6784\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5206\u6790\u548c\u5f62\u72b6\u63a7\u5236\u5de5\u5177\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5927\u53d8\u5f62\u60c5\u51b5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2510.04609", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04609", "abs": "https://arxiv.org/abs/2510.04609", "authors": ["Shreya Chappidi", "Jennifer Cobbe", "Chris Norval", "Anjali Mazumder", "Jatinder Singh"], "title": "Accountability Capture: How Record-Keeping to Support AI Transparency and Accountability (Re)shapes Algorithmic Oversight", "comment": "To appear at 8th AAAI/ACM Conference on AI, Ethics, and Society (AIES\n  2025)", "summary": "Accountability regimes typically encourage record-keeping to enable the\ntransparency that supports oversight, investigation, contestation, and redress.\nHowever, implementing such record-keeping can introduce considerations, risks,\nand consequences, which so far remain under-explored. This paper examines how\nrecord-keeping practices bring algorithmic systems within accountability\nregimes, providing a basis to observe and understand their effects. For this,\nwe introduce, describe, and elaborate 'accountability capture' -- the\nre-configuration of socio-technical processes and the associated downstream\neffects relating to record-keeping for algorithmic accountability. Surveying\n100 practitioners, we evidence and characterise record-keeping issues in\npractice, identifying their alignment with accountability capture. We further\ndocument widespread record-keeping practices, tensions between internal and\nexternal accountability requirements, and evidence of employee resistance to\npractices imposed through accountability capture. We discuss these and other\neffects for surveillance, privacy, and data protection, highlighting\nconsiderations for algorithmic accountability communities. In all, we show that\nimplementing record-keeping to support transparency in algorithmic\naccountability regimes can itself bring wider implications -- an issue\nrequiring greater attention from practitioners, researchers, and policymakers\nalike.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4e3a\u7b97\u6cd5\u95ee\u8d23\u800c\u5b9e\u65bd\u7684\u8bb0\u5f55\u4fdd\u5b58\u5b9e\u8df5\u5982\u4f55\u901a\u8fc7'\u95ee\u8d23\u6355\u83b7'\u91cd\u65b0\u914d\u7f6e\u793e\u4f1a\u6280\u672f\u8fc7\u7a0b\uff0c\u4ea7\u751f\u5305\u62ec\u76d1\u63a7\u3001\u9690\u79c1\u548c\u6570\u636e\u4fdd\u62a4\u5728\u5185\u7684\u5e7f\u6cdb\u5f71\u54cd\u3002", "motivation": "\u95ee\u8d23\u5236\u5ea6\u9f13\u52b1\u8bb0\u5f55\u4fdd\u5b58\u4ee5\u5b9e\u73b0\u900f\u660e\u5ea6\uff0c\u4f46\u5b9e\u65bd\u8fd9\u79cd\u8bb0\u5f55\u4fdd\u5b58\u4f1a\u5f15\u5165\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u8003\u8651\u56e0\u7d20\u3001\u98ce\u9669\u548c\u540e\u679c\u3002", "method": "\u901a\u8fc7\u8c03\u67e5100\u540d\u4ece\u4e1a\u8005\uff0c\u8bb0\u5f55\u548c\u5206\u6790\u5b9e\u8df5\u4e2d\u7684\u8bb0\u5f55\u4fdd\u5b58\u95ee\u9898\uff0c\u8bc6\u522b\u5176\u4e0e\u95ee\u8d23\u6355\u83b7\u7684\u4e00\u81f4\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5e7f\u6cdb\u7684\u8bb0\u5f55\u4fdd\u5b58\u5b9e\u8df5\u3001\u5185\u90e8\u4e0e\u5916\u90e8\u95ee\u8d23\u8981\u6c42\u4e4b\u95f4\u7684\u7d27\u5f20\u5173\u7cfb\uff0c\u4ee5\u53ca\u5458\u5de5\u5bf9\u901a\u8fc7\u95ee\u8d23\u6355\u83b7\u5f3a\u52a0\u7684\u5b9e\u8df5\u7684\u62b5\u5236\u8bc1\u636e\u3002", "conclusion": "\u4e3a\u652f\u6301\u7b97\u6cd5\u95ee\u8d23\u900f\u660e\u5ea6\u800c\u5b9e\u65bd\u7684\u8bb0\u5f55\u4fdd\u5b58\u672c\u8eab\u53ef\u80fd\u5e26\u6765\u66f4\u5e7f\u6cdb\u7684\u5f71\u54cd\uff0c\u8fd9\u9700\u8981\u4ece\u4e1a\u8005\u3001\u7814\u7a76\u4eba\u5458\u548c\u653f\u7b56\u5236\u5b9a\u8005\u7ed9\u4e88\u66f4\u591a\u5173\u6ce8\u3002"}}
{"id": "2510.03727", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03727", "abs": "https://arxiv.org/abs/2510.03727", "authors": ["Xuehai He"], "title": "Bridging the Gap Between Multimodal Foundation Models and World Models", "comment": "PhD thesis", "summary": "Humans understand the world through the integration of multiple sensory\nmodalities, enabling them to perceive, reason about, and imagine dynamic\nphysical processes. Inspired by this capability, multimodal foundation models\n(MFMs) have emerged as powerful tools for multimodal understanding and\ngeneration. However, today's MFMs fall short of serving as effective world\nmodels. They lack the essential ability such as perform counterfactual\nreasoning, simulate dynamics, understand the spatiotemporal information,\ncontrol generated visual outcomes, and perform multifaceted reasoning. We\ninvestigates what it takes to bridge the gap between multimodal foundation\nmodels and world models. We begin by improving the reasoning capabilities of\nMFMs through discriminative tasks and equipping MFMs with structured reasoning\nskills, such as causal inference, counterfactual thinking, and spatiotemporal\nreasoning, enabling them to go beyond surface correlations and understand\ndeeper relationships within visual and textual data. Next, we explore\ngenerative capabilities of multimodal foundation models across both image and\nvideo modalities, introducing new frameworks for structured and controllable\ngeneration. Our approaches incorporate scene graphs, multimodal conditioning,\nand multimodal alignment strategies to guide the generation process, ensuring\nconsistency with high-level semantics and fine-grained user intent. We further\nextend these techniques to controllable 4D generation, enabling interactive,\neditable, and morphable object synthesis over time and space.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u5982\u4f55\u5c06\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u63d0\u5347\u4e3a\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u589e\u5f3a\u5176\u63a8\u7406\u80fd\u529b\u548c\u751f\u6210\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u8fdb\u884c\u53cd\u4e8b\u5b9e\u63a8\u7406\u3001\u6a21\u62df\u52a8\u6001\u8fc7\u7a0b\u3001\u7406\u89e3\u65f6\u7a7a\u4fe1\u606f\uff0c\u5e76\u5b9e\u73b0\u53ef\u63a7\u7684\u89c6\u89c9\u751f\u6210\u3002", "motivation": "\u53d7\u4eba\u7c7b\u901a\u8fc7\u591a\u611f\u5b98\u6574\u5408\u7406\u89e3\u4e16\u754c\u7684\u542f\u53d1\uff0c\u5f53\u524d\u7684\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u4f5c\u4e3a\u4e16\u754c\u6a21\u578b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u53cd\u4e8b\u5b9e\u63a8\u7406\u3001\u52a8\u6001\u6a21\u62df\u3001\u65f6\u7a7a\u7406\u89e3\u7b49\u5173\u952e\u80fd\u529b\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u901a\u8fc7\u5224\u522b\u6027\u4efb\u52a1\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u8d4b\u4e88\u7ed3\u6784\u5316\u63a8\u7406\u6280\u80fd\uff08\u56e0\u679c\u63a8\u65ad\u3001\u53cd\u4e8b\u5b9e\u601d\u7ef4\u3001\u65f6\u7a7a\u63a8\u7406\uff09\uff1b\u5728\u751f\u6210\u65b9\u9762\u5f15\u5165\u7ed3\u6784\u5316\u53ef\u63a7\u751f\u6210\u6846\u67b6\uff0c\u5229\u7528\u573a\u666f\u56fe\u3001\u591a\u6a21\u6001\u6761\u4ef6\u7ea6\u675f\u548c\u5bf9\u9f50\u7b56\u7565\u6765\u6307\u5bfc\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5f00\u53d1\u4e86\u80fd\u591f\u8d85\u8d8a\u8868\u9762\u76f8\u5173\u6027\u3001\u7406\u89e3\u6df1\u5c42\u5173\u7cfb\u7684\u65b0\u578b\u591a\u6a21\u6001\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u53ef\u63a7\u76844D\u751f\u6210\uff0c\u652f\u6301\u4ea4\u4e92\u5f0f\u3001\u53ef\u7f16\u8f91\u548c\u53ef\u53d8\u5f62\u5bf9\u8c61\u7684\u65f6\u7a7a\u5408\u6210\u3002", "conclusion": "\u901a\u8fc7\u589e\u5f3a\u63a8\u7406\u548c\u751f\u6210\u80fd\u529b\uff0c\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u53ef\u4ee5\u66f4\u597d\u5730\u6a21\u62df\u548c\u7406\u89e3\u4e16\u754c\uff0c\u6210\u4e3a\u66f4\u6709\u6548\u7684\u4e16\u754c\u6a21\u578b\uff0c\u4e3a\u590d\u6742\u7269\u7406\u8fc7\u7a0b\u7684\u611f\u77e5\u548c\u63a8\u7406\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2510.03982", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.03982", "abs": "https://arxiv.org/abs/2510.03982", "authors": ["Roy Siegelmann", "Enrique Mallada"], "title": "Data-driven Practical Stabilization of Nonlinear Systems via Chain Policies: Sample Complexity and Incremental Learning", "comment": null, "summary": "We propose a method for data-driven practical stabilization of nonlinear\nsystems with provable guarantees, based on the concept of Nonparametric Chain\nPolicies (NCPs). The approach employs a normalized nearest-neighbor rule to\nassign, at each state, a finite-duration control signal derived from stored\ndata, after which the process repeats. Unlike recent works that model the\nsystem as linear, polynomial, or polynomial fraction, we only assume the system\nto be locally Lipschitz. Our analysis builds on the framework of Recurrent\nLyapunov Functions (RLFs), which enable data-driven certification of practical\nstability using standard norm functions instead of requiring the explicit\nconstruction of a classical Lyapunov function. To extend this framework, we\nintroduce the concept of Recurrent Control Lyapunov Functions (R-CLFs), which\ncan certify the existence of an NCP that practically stabilizes an arbitrarily\nsmall c-neighborhood of an equilibrium point. We also provide an explicit\nsample complexity guarantee of O((3/rho)^d log(R/c)) number of trajectories,\nwhere R is the domain radius, d the state dimension, and rho a system-dependent\nconstant. The proposed Chain Policies are nonparametric, thus allowing new\nverified data to be readily incorporated into the policy to either improve\nconvergence rate or enlarge the certified region. Numerical experiments\nillustrate and validate these properties.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u975e\u53c2\u6570\u94fe\u7b56\u7565\u7684\u6570\u636e\u9a71\u52a8\u975e\u7ebf\u6027\u7cfb\u7edf\u5b9e\u7528\u7a33\u5b9a\u5316\u65b9\u6cd5\uff0c\u5177\u6709\u53ef\u8bc1\u660e\u7684\u4fdd\u8bc1\uff0c\u4ec5\u9700\u7cfb\u7edf\u5c40\u90e8Lipschitz\u5047\u8bbe\uff0c\u65e0\u9700\u663e\u5f0f\u6784\u9020Lyapunov\u51fd\u6570\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5c06\u7cfb\u7edf\u5efa\u6a21\u4e3a\u7ebf\u6027\u3001\u591a\u9879\u5f0f\u6216\u591a\u9879\u5f0f\u5206\u6570\u5f62\u5f0f\uff0c\u9650\u5236\u4e86\u5e94\u7528\u8303\u56f4\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u66f4\u901a\u7528\u7684\u6570\u636e\u9a71\u52a8\u7a33\u5b9a\u5316\u65b9\u6cd5\uff0c\u4ec5\u9700\u5c40\u90e8Lipschitz\u5047\u8bbe\uff0c\u5e76\u80fd\u63d0\u4f9b\u660e\u786e\u7684\u6837\u672c\u590d\u6742\u5ea6\u4fdd\u8bc1\u3002", "method": "\u91c7\u7528\u975e\u53c2\u6570\u94fe\u7b56\u7565\uff0c\u4f7f\u7528\u5f52\u4e00\u5316\u6700\u8fd1\u90bb\u89c4\u5219\u4e3a\u6bcf\u4e2a\u72b6\u6001\u5206\u914d\u6709\u9650\u6301\u7eed\u65f6\u95f4\u63a7\u5236\u4fe1\u53f7\uff0c\u5e76\u5f15\u5165\u9012\u5f52\u63a7\u5236Lyapunov\u51fd\u6570\u6846\u67b6\u6765\u9a8c\u8bc1\u5b9e\u7528\u7a33\u5b9a\u6027\u3002", "result": "\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u6837\u672c\u590d\u6742\u5ea6\u4fdd\u8bc1O((3/\u03c1)^d log(R/c))\uff0c\u5176\u4e2dR\u4e3a\u57df\u534a\u5f84\uff0cd\u4e3a\u72b6\u6001\u7ef4\u5ea6\uff0c\u03c1\u4e3a\u7cfb\u7edf\u76f8\u5173\u5e38\u6570\u3002\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u94fe\u7b56\u7565\u662f\u975e\u53c2\u6570\u7684\uff0c\u5141\u8bb8\u8f7b\u677e\u6574\u5408\u65b0\u7684\u9a8c\u8bc1\u6570\u636e\u6765\u6539\u8fdb\u6536\u655b\u901f\u5ea6\u6216\u6269\u5927\u8ba4\u8bc1\u533a\u57df\uff0c\u4e3a\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u6570\u636e\u9a71\u52a8\u7a33\u5b9a\u5316\u63d0\u4f9b\u4e86\u901a\u7528\u4e14\u53ef\u8bc1\u660e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03660", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03660", "abs": "https://arxiv.org/abs/2510.03660", "authors": ["Mohammadjavad Javadi", "Charlie Wadds", "Robin Chhabra"], "title": "An Amphibious Untethered Inchworm Soft Robot for Fast Crawling Locomotion", "comment": null, "summary": "Untethered soft robots are essential for advancing the real-world deployment\nof soft robotic systems in diverse and multitasking environments. Inspired by\nsoft-bodied inchworm, we present a fully untethered soft robot with a curved,\nflexible structure actuated by magnetic forces. The robot has a total mass of\n102.63 g and demonstrates multimodal locomotion, achieving a maximum walking\nspeed of 3.74 cm/s and a swimming speed of 0.82 cm/s. A compact and lightweight\nonboard control circuit enables wireless command transmission, while an\nintegrated camera provides environmental perception. Through structural\noptimization and system-level integration, the robot successfully performs\nwalking, steering, swimming, and payload transport without reliance on external\ninfrastructure. The robot's dynamic performance and locomotion capabilities are\nsystematically validated through experimental characterization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u65e0\u7f06\u7684\u8f6f\u4f53\u673a\u5668\u4eba\uff0c\u7075\u611f\u6765\u81ea\u5c3a\u8816\uff0c\u91c7\u7528\u78c1\u529b\u9a71\u52a8\uff0c\u5177\u6709\u591a\u6a21\u6001\u8fd0\u52a8\u80fd\u529b\uff0c\u5305\u62ec\u884c\u8d70\u3001\u8f6c\u5411\u3001\u6e38\u6cf3\u548c\u8d1f\u8f7d\u8fd0\u8f93\u3002", "motivation": "\u5f00\u53d1\u65e0\u7f06\u8f6f\u4f53\u673a\u5668\u4eba\u5bf9\u4e8e\u63a8\u52a8\u8f6f\u4f53\u673a\u5668\u4eba\u7cfb\u7edf\u5728\u591a\u6837\u5316\u3001\u591a\u4efb\u52a1\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u7ed3\u6784\u4f18\u5316\u548c\u7cfb\u7edf\u7ea7\u96c6\u6210\uff0c\u91c7\u7528\u78c1\u529b\u9a71\u52a8\u7684\u5f2f\u66f2\u67d4\u6027\u7ed3\u6784\uff0c\u914d\u5907\u8f7b\u91cf\u5316\u63a7\u5236\u7535\u8def\u548c\u96c6\u6210\u6444\u50cf\u5934\u5b9e\u73b0\u65e0\u7ebf\u63a7\u5236\u548c\u73af\u5883\u611f\u77e5\u3002", "result": "\u673a\u5668\u4eba\u603b\u8d28\u91cf102.63\u514b\uff0c\u6700\u5927\u884c\u8d70\u901f\u5ea63.74 cm/s\uff0c\u6e38\u6cf3\u901f\u5ea60.82 cm/s\uff0c\u6210\u529f\u5b9e\u73b0\u591a\u79cd\u8fd0\u52a8\u6a21\u5f0f\u4e14\u4e0d\u4f9d\u8d56\u5916\u90e8\u57fa\u7840\u8bbe\u65bd\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u673a\u5668\u4eba\u7684\u52a8\u6001\u6027\u80fd\u548c\u8fd0\u52a8\u80fd\u529b\uff0c\u4e3a\u65e0\u7f06\u8f6f\u4f53\u673a\u5668\u4eba\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.04748", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.04748", "abs": "https://arxiv.org/abs/2510.04748", "authors": ["Florence E. Enock", "Helen Z. Margetts", "Jonathan Bright"], "title": "Social bias is prevalent in user reports of hate and abuse online", "comment": null, "summary": "The prevalence of online hate and abuse is a pressing global concern. While\ntackling such societal harms is a priority for research across the social\nsciences, it is a difficult task, in part because of the magnitude of the\nproblem. User engagement with reporting mechanisms (flagging) online is an\nincreasingly important part of monitoring and addressing harmful content at\nscale. However, users may not flag content routinely enough, and when they do\nengage, they may be biased by group identity and political beliefs. Across five\nwell-powered and pre-registered online experiments, we examine the extent of\nsocial bias in the flagging of hate and abuse in four different intergroup\ncontexts: political affiliation, vaccination opinions, beliefs about climate\nchange, and stance on abortion rights. Overall, participants reported abuse\nreliably, with approximately half of the abusive comments in each study\nreported. However, a pervasive social bias was present whereby ingroup-directed\nabuse was consistently flagged to a greater extent than outgroup-directed\nabuse. Our findings offer new insights into the nature of user flagging online,\nan understanding of which is crucial for enhancing user intervention against\nonline hate speech and thus ensuring a safer online environment.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u7528\u6237\u4e3e\u62a5\u7f51\u7edc\u4ec7\u6068\u8a00\u8bba\u65f6\u5b58\u5728\u793e\u4f1a\u504f\u89c1\uff0c\u66f4\u503e\u5411\u4e8e\u4e3e\u62a5\u9488\u5bf9\u5185\u7fa4\u4f53\u7684\u653b\u51fb\u800c\u975e\u5916\u7fa4\u4f53\u653b\u51fb\u3002", "motivation": "\u7f51\u7edc\u4ec7\u6068\u548c\u6ee5\u7528\u65e5\u76ca\u4e25\u91cd\uff0c\u7528\u6237\u4e3e\u62a5\u673a\u5236\u662f\u76d1\u63a7\u548c\u5904\u7406\u6709\u5bb3\u5185\u5bb9\u7684\u91cd\u8981\u65b9\u5f0f\uff0c\u4f46\u7528\u6237\u4e3e\u62a5\u884c\u4e3a\u53ef\u80fd\u53d7\u5230\u7fa4\u4f53\u8eab\u4efd\u548c\u653f\u6cbb\u4fe1\u4ef0\u7684\u504f\u89c1\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u4e94\u4e2a\u9884\u5148\u6ce8\u518c\u7684\u5728\u7ebf\u5b9e\u9a8c\uff0c\u5728\u56db\u79cd\u4e0d\u540c\u7fa4\u4f53\u95f4\u60c5\u5883\uff08\u653f\u6cbb\u7acb\u573a\u3001\u75ab\u82d7\u63a5\u79cd\u89c2\u70b9\u3001\u6c14\u5019\u53d8\u5316\u4fe1\u5ff5\u3001\u5815\u80ce\u6743\u5229\u7acb\u573a\uff09\u4e2d\u68c0\u9a8c\u4e3e\u62a5\u504f\u89c1\u3002", "result": "\u53c2\u4e0e\u8005\u80fd\u53ef\u9760\u5730\u4e3e\u62a5\u6ee5\u7528\u5185\u5bb9\uff08\u7ea6\u4e00\u534a\u7684\u6ee5\u7528\u8bc4\u8bba\u88ab\u4e3e\u62a5\uff09\uff0c\u4f46\u5b58\u5728\u666e\u904d\u7684\u793e\u4f1a\u504f\u89c1\uff0c\u5bf9\u5185\u7fa4\u4f53\u653b\u51fb\u7684\u4e3e\u62a5\u7387\u663e\u8457\u9ad8\u4e8e\u5bf9\u5916\u7fa4\u4f53\u653b\u51fb\u3002", "conclusion": "\u4e86\u89e3\u7528\u6237\u4e3e\u62a5\u884c\u4e3a\u7684\u504f\u89c1\u5bf9\u4e8e\u6539\u8fdb\u7528\u6237\u5e72\u9884\u7f51\u7edc\u4ec7\u6068\u8a00\u8bba\u673a\u5236\u3001\u786e\u4fdd\u66f4\u5b89\u5168\u7684\u7f51\u7edc\u73af\u5883\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.03771", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03771", "abs": "https://arxiv.org/abs/2510.03771", "authors": ["Divij Handa", "David Blincoe", "Orson Adams", "Yinlin Fu"], "title": "OptAgent: Optimizing Query Rewriting for E-commerce via Multi-Agent Simulation", "comment": null, "summary": "Deploying capable and user-aligned LLM-based systems necessitates reliable\nevaluation. While LLMs excel in verifiable tasks like coding and mathematics,\nwhere gold-standard solutions are available, adoption remains challenging for\nsubjective tasks that lack a single correct answer. E-commerce Query Rewriting\n(QR) is one such problem where determining whether a rewritten query properly\ncaptures the user intent is extremely difficult to figure out algorithmically.\nIn this work, we introduce OptAgent, a novel framework that combines\nmulti-agent simulations with genetic algorithms to verify and optimize queries\nfor QR. Instead of relying on a static reward model or a single LLM judge, our\napproach uses multiple LLM-based agents, each acting as a simulated shopping\ncustomer, as a dynamic reward signal. The average of these agent-derived scores\nserves as an effective fitness function for an evolutionary algorithm that\niteratively refines the user's initial query. We evaluate OptAgent on a dataset\nof 1000 real-world e-commerce queries in five different categories, and we\nobserve an average improvement of 21.98% over the original user query and 3.36%\nover a Best-of-N LLM rewriting baseline.", "AI": {"tldr": "OptAgent\u6846\u67b6\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u6a21\u62df\u548c\u9057\u4f20\u7b97\u6cd5\u6765\u4f18\u5316\u7535\u5546\u67e5\u8be2\u6539\u5199\uff0c\u901a\u8fc7\u6a21\u62df\u8d2d\u7269\u987e\u5ba2\u7684LLM\u667a\u80fd\u4f53\u4f5c\u4e3a\u52a8\u6001\u5956\u52b1\u4fe1\u53f7\uff0c\u57285\u4e2a\u7c7b\u522b\u76841000\u4e2a\u771f\u5b9e\u7535\u5546\u67e5\u8be2\u4e0a\u5e73\u5747\u6539\u8fdb21.98%\u3002", "motivation": "LLM\u5728\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u7f3a\u4e4f\u5355\u4e00\u6b63\u786e\u7b54\u6848\u7684\u4e3b\u89c2\u4efb\u52a1\uff08\u5982\u7535\u5546\u67e5\u8be2\u6539\u5199\uff09\u4e2d\u90e8\u7f72\u56f0\u96be\uff0c\u56e0\u4e3a\u96be\u4ee5\u7b97\u6cd5\u5316\u5224\u65ad\u6539\u5199\u67e5\u8be2\u662f\u5426\u51c6\u786e\u6355\u6349\u7528\u6237\u610f\u56fe\u3002", "method": "\u4f7f\u7528\u591a\u4e2a\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u6a21\u62df\u8d2d\u7269\u987e\u5ba2\u4f5c\u4e3a\u52a8\u6001\u5956\u52b1\u4fe1\u53f7\uff0c\u5c06\u8fd9\u4e9b\u667a\u80fd\u4f53\u8bc4\u5206\u7684\u5e73\u5747\u503c\u4f5c\u4e3a\u8fdb\u5316\u7b97\u6cd5\u7684\u9002\u5e94\u5ea6\u51fd\u6570\uff0c\u8fed\u4ee3\u4f18\u5316\u7528\u6237\u521d\u59cb\u67e5\u8be2\u3002", "result": "\u57285\u4e2a\u7c7b\u522b\u76841000\u4e2a\u771f\u5b9e\u7535\u5546\u67e5\u8be2\u4e0a\u8bc4\u4f30\uff0cOptAgent\u76f8\u6bd4\u539f\u59cb\u7528\u6237\u67e5\u8be2\u5e73\u5747\u6539\u8fdb21.98%\uff0c\u76f8\u6bd4\u6700\u4f73N\u6b21LLM\u6539\u5199\u57fa\u7ebf\u6539\u8fdb3.36%\u3002", "conclusion": "OptAgent\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6a21\u62df\u548c\u9057\u4f20\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u7535\u5546\u67e5\u8be2\u6539\u5199\u8fd9\u4e00\u4e3b\u89c2\u4efb\u52a1\u7684\u8bc4\u4f30\u548c\u4f18\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u8d28\u91cf\u3002"}}
{"id": "2510.04038", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.04038", "abs": "https://arxiv.org/abs/2510.04038", "authors": ["Viet Hoang Pham", "Hyo-Sung Ahn"], "title": "Distributed MPC-based Coordination of Traffic Perimeter and Signal Control: A Lexicographic Optimization Approach", "comment": null, "summary": "This paper introduces a comprehensive strategy that integrates traffic\nperimeter control with traffic signal control to alleviate congestion in an\nurban traffic network (UTN). The strategy is formulated as a lexicographic\nmulti-objective optimization problem, starting with the regulation of traffic\ninflows at boundary junctions to maximize the capacity while ensuring a smooth\noperation of the UTN. Following this, the signal timings at internal junctions\nare collaboratively optimized to enhance overall traffic conditions under the\nregulated inflows. The use of a model predictive control (MPC) approach ensures\nthat the control solution adheres to safety and capacity constraints within the\nnetwork. To address the computational complexity of the problem, the UTN is\ndivided into subnetworks, each managed by a local agent. A distributed solution\nmethod based on the alternating direction method of multipliers (ADMM)\nalgorithm is employed, allowing each agent to determine its optimal control\ndecisions using local information from its subnetwork and neighboring agents.\nNumerical simulations using VISSIM and MATLAB demonstrate the effectiveness of\nthe proposed traffic control strategy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4ea4\u901a\u8fb9\u754c\u63a7\u5236\u548c\u4fe1\u53f7\u63a7\u5236\u7684\u7efc\u5408\u7b56\u7565\uff0c\u901a\u8fc7\u5206\u5c42\u591a\u76ee\u6807\u4f18\u5316\u548c\u5206\u5e03\u5f0fADMM\u7b97\u6cd5\u6765\u7f13\u89e3\u57ce\u5e02\u4ea4\u901a\u7f51\u7edc\u62e5\u5835\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u57ce\u5e02\u4ea4\u901a\u7f51\u7edc\u62e5\u5835\u95ee\u9898\uff0c\u9700\u8981\u7efc\u5408\u8003\u8651\u8fb9\u754c\u6d41\u91cf\u63a7\u5236\u548c\u5185\u90e8\u4fe1\u53f7\u534f\u8c03\u4f18\u5316\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5927\u89c4\u6a21\u7f51\u7edc\u7684\u590d\u6742\u6027\u548c\u8ba1\u7b97\u8d1f\u62c5\u3002", "method": "\u91c7\u7528\u5206\u5c42\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\uff0c\u5148\u901a\u8fc7\u8fb9\u754c\u63a7\u5236\u8c03\u8282\u6d41\u5165\u91cf\uff0c\u518d\u4f18\u5316\u5185\u90e8\u4fe1\u53f7\u914d\u65f6\uff1b\u4f7f\u7528MPC\u786e\u4fdd\u5b89\u5168\u7ea6\u675f\uff0c\u5e76\u901a\u8fc7\u5206\u5e03\u5f0fADMM\u7b97\u6cd5\u5c06\u7f51\u7edc\u5212\u5206\u4e3a\u5b50\u7f51\u7edc\u8fdb\u884c\u5e76\u884c\u8ba1\u7b97\u3002", "result": "VISSIM\u548cMATLAB\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u4e86\u8be5\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u663e\u8457\u6539\u5584\u57ce\u5e02\u4ea4\u901a\u7f51\u7edc\u7684\u6574\u4f53\u8fd0\u884c\u72b6\u51b5\u3002", "conclusion": "\u8be5\u7efc\u5408\u63a7\u5236\u7b56\u7565\u901a\u8fc7\u5206\u5e03\u5f0f\u8ba1\u7b97\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u57ce\u5e02\u4ea4\u901a\u7f51\u7edc\u7684\u62e5\u5835\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03677", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03677", "abs": "https://arxiv.org/abs/2510.03677", "authors": ["Salim Rezvani", "Ammar Jaleel Mahmood", "Robin Chhabra"], "title": "Robust Visual Embodiment: How Robots Discover Their Bodies in Real Environments", "comment": null, "summary": "Robots with internal visual self-models promise unprecedented adaptability,\nyet existing autonomous modeling pipelines remain fragile under realistic\nsensing conditions such as noisy imagery and cluttered backgrounds. This paper\npresents the first systematic study quantifying how visual\ndegradations--including blur, salt-and-pepper noise, and Gaussian noise--affect\nrobotic self-modeling. Through both simulation and physical experiments, we\ndemonstrate their impact on morphology prediction, trajectory planning, and\ndamage recovery in state-of-the-art pipelines. To overcome these challenges, we\nintroduce a task-aware denoising framework that couples classical restoration\nwith morphology-preserving constraints, ensuring retention of structural cues\ncritical for self-modeling. In addition, we integrate semantic segmentation to\nrobustly isolate robots from cluttered and colorful scenes. Extensive\nexperiments show that our approach restores near-baseline performance across\nsimulated and physical platforms, while existing pipelines degrade\nsignificantly. These contributions advance the robustness of visual\nself-modeling and establish practical foundations for deploying self-aware\nrobots in unpredictable real-world environments.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u89c6\u89c9\u9000\u5316\uff08\u6a21\u7cca\u3001\u6912\u76d0\u566a\u58f0\u3001\u9ad8\u65af\u566a\u58f0\uff09\u5bf9\u673a\u5668\u4eba\u81ea\u5efa\u6a21\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u7ed3\u5408\u7ecf\u5178\u4fee\u590d\u548c\u5f62\u6001\u4fdd\u6301\u7ea6\u675f\u7684\u4efb\u52a1\u611f\u77e5\u53bb\u566a\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u5efa\u6a21\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u81ea\u4e3b\u5efa\u6a21\u7ba1\u9053\u5728\u771f\u5b9e\u611f\u77e5\u6761\u4ef6\uff08\u5982\u566a\u58f0\u56fe\u50cf\u548c\u6742\u4e71\u80cc\u666f\uff09\u4e0b\u8868\u73b0\u8106\u5f31\uff0c\u9650\u5236\u4e86\u5177\u6709\u5185\u90e8\u89c6\u89c9\u81ea\u6a21\u578b\u673a\u5668\u4eba\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5f15\u5165\u4efb\u52a1\u611f\u77e5\u53bb\u566a\u6846\u67b6\uff0c\u5c06\u7ecf\u5178\u4fee\u590d\u4e0e\u5f62\u6001\u4fdd\u6301\u7ea6\u675f\u76f8\u7ed3\u5408\uff0c\u5e76\u96c6\u6210\u8bed\u4e49\u5206\u5272\u4ee5\u5728\u6742\u4e71\u573a\u666f\u4e2d\u7a33\u5065\u5730\u5206\u79bb\u673a\u5668\u4eba\u3002", "result": "\u5728\u4eff\u771f\u548c\u7269\u7406\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6062\u590d\u4e86\u63a5\u8fd1\u57fa\u7ebf\u6027\u80fd\uff0c\u800c\u73b0\u6709\u7ba1\u9053\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u8fd9\u4e9b\u8d21\u732e\u63d0\u5347\u4e86\u89c6\u89c9\u81ea\u5efa\u6a21\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u5728\u4e0d\u53ef\u9884\u6d4b\u7684\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u90e8\u7f72\u81ea\u611f\u77e5\u673a\u5668\u4eba\u5960\u5b9a\u4e86\u5b9e\u8df5\u57fa\u7840\u3002"}}
{"id": "2510.04755", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04755", "abs": "https://arxiv.org/abs/2510.04755", "authors": ["Jason Miklian", "Kristian Hoelscher"], "title": "A New Digital Divide? Coder Worldviews, the Slop Economy, and Democracy in the Age of AI", "comment": null, "summary": "Digital technologies are transforming democratic life in conflicting ways.\nThis article bridges two perspectives to unpack these tensions. First, we\npresent an original survey of software developers in Silicon Valley,\ninterrogating how coder worldviews, ethics, and workplace cultures shape the\ndemocratic potential and social impact of the technologies they build. Results\nindicate that while most developers recognize the power of their products to\ninfluence civil liberties and political discourse, they often face ethical\ndilemmas and top-down pressures that can lead to design choices undermining\ndemocratic ideals. Second, we critically investigate these findings in the\ncontext of an emerging new digital divide, not of internet access but of\ninformation quality. We interrogate the survey findings in the context of the\nSlop Economy, in which billions of users unable to pay for high-quality content\nexperience an internet dominated by low-quality, AI-generated ad-driven\ncontent. We find a reinforcing cycle between tech creator beliefs and the\ndigital ecosystems they spawn. We discuss implications for democratic\ngovernance, arguing for more ethically informed design and policy interventions\nto help bridge the digital divide to ensure that technological innovation\nsupports rather than subverts democratic values in the next chapter of the\ndigital age.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u8c03\u67e5\u7845\u8c37\u8f6f\u4ef6\u5f00\u53d1\u8005\u7684\u4e16\u754c\u89c2\u3001\u4f26\u7406\u89c2\u548c\u5de5\u4f5c\u6587\u5316\uff0c\u63a2\u8ba8\u6280\u672f\u5982\u4f55\u5f71\u54cd\u6c11\u4e3b\u751f\u6d3b\uff0c\u63ed\u793a\u4e86\u5f00\u53d1\u8005\u9762\u4e34\u7684\u4f26\u7406\u56f0\u5883\u548c\u81ea\u4e0a\u800c\u4e0b\u7684\u538b\u529b\u5982\u4f55\u5bfc\u81f4\u8bbe\u8ba1\u9009\u62e9\u635f\u5bb3\u6c11\u4e3b\u7406\u60f3\uff0c\u5e76\u5206\u6790\u4e86\u65b0\u5174\u7684\u6570\u5b57\u9e3f\u6c9f\u95ee\u9898\u3002", "motivation": "\u6570\u5b57\u6280\u672f\u6b63\u5728\u4ee5\u76f8\u4e92\u77db\u76fe\u7684\u65b9\u5f0f\u6539\u53d8\u6c11\u4e3b\u751f\u6d3b\uff0c\u9700\u8981\u7406\u89e3\u8f6f\u4ef6\u5f00\u53d1\u8005\u7684\u4e16\u754c\u89c2\u3001\u4f26\u7406\u89c2\u548c\u5de5\u4f5c\u6587\u5316\u5982\u4f55\u5851\u9020\u4ed6\u4eec\u6784\u5efa\u6280\u672f\u7684\u6c11\u4e3b\u6f5c\u529b\u548c\u793e\u4f1a\u5f71\u54cd\u3002", "method": "\u5bf9\u7845\u8c37\u8f6f\u4ef6\u5f00\u53d1\u8005\u8fdb\u884c\u539f\u521b\u6027\u8c03\u67e5\uff0c\u5e76\u6279\u5224\u6027\u5730\u5728Slop\u7ecf\u6d4e\u80cc\u666f\u4e0b\u5206\u6790\u8c03\u67e5\u7ed3\u679c\uff0c\u63a2\u8ba8\u4fe1\u606f\u8d28\u91cf\u7684\u65b0\u6570\u5b57\u9e3f\u6c9f\u3002", "result": "\u5927\u591a\u6570\u5f00\u53d1\u8005\u8ba4\u8bc6\u5230\u5176\u4ea7\u54c1\u5bf9\u516c\u6c11\u81ea\u7531\u548c\u653f\u6cbb\u8bdd\u8bed\u7684\u5f71\u54cd\u529b\uff0c\u4f46\u9762\u4e34\u4f26\u7406\u56f0\u5883\u548c\u81ea\u4e0a\u800c\u4e0b\u7684\u538b\u529b\uff0c\u5bfc\u81f4\u8bbe\u8ba1\u9009\u62e9\u635f\u5bb3\u6c11\u4e3b\u7406\u60f3\uff1b\u6280\u672f\u521b\u9020\u8005\u4fe1\u5ff5\u4e0e\u4ed6\u4eec\u521b\u9020\u7684\u6570\u5b57\u751f\u6001\u7cfb\u7edf\u4e4b\u95f4\u5b58\u5728\u5f3a\u5316\u5faa\u73af\u3002", "conclusion": "\u9700\u8981\u66f4\u591a\u4f26\u7406\u77e5\u60c5\u7684\u8bbe\u8ba1\u548c\u653f\u7b56\u5e72\u9884\u6765\u5f25\u5408\u6570\u5b57\u9e3f\u6c9f\uff0c\u786e\u4fdd\u6280\u672f\u521b\u65b0\u5728\u6570\u5b57\u65f6\u4ee3\u7684\u4e0b\u4e00\u7ae0\u652f\u6301\u800c\u975e\u98a0\u8986\u6c11\u4e3b\u4ef7\u503c\u89c2\u3002"}}
{"id": "2510.03777", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03777", "abs": "https://arxiv.org/abs/2510.03777", "authors": ["Divij Handa", "Mihir Parmar", "Aswin RRV", "Md Nayem Uddin", "Hamid Palangi", "Chitta Baral"], "title": "GuidedSampling: Steering LLMs Towards Diverse Candidate Solutions at Inference-Time", "comment": null, "summary": "Repeated Sampling (RS) is a simple inference-time algorithm that has been\nshown to improve model performance on complex tasks. Although it is an\neffective way of scaling inference time, it often struggles to generate diverse\nsolution candidates, frequently relying on the same underlying approach to\nsolve the problem and thus producing redundant samples. To address this\nlimitation, we propose a new inference algorithm, GuidedSampling, which\ndecouples the exploration and generation phases during inference, increasing\ndiversity of generated candidate solutions. The exploration phase identifies\nmultiple concepts that can be utilized to solve the problem, while the\ngeneration phase applies a specific concept to provide final solution\ncandidates. We first define the theoretical bounds of GuidedSampling and then\nempirically demonstrate that it improves the performance of base model at\npass@50 by on an average ~21.6% across various benchmarks compared to RS.\nFurthermore, models trained on trajectories of GuidedSampling exhibit\nsubstantial performance improvements at pass@5 by on an average ~9.7%, compared\nto models trained on traditional RS. Additionally, models trained with\nGuidedSampling increases the average number of concepts per instance (1.67 ->\n3.03), yielding a diverse set of candidates than traditional RS.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGuidedSampling\u7684\u65b0\u63a8\u7406\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c06\u63a2\u7d22\u548c\u751f\u6210\u9636\u6bb5\u89e3\u8026\u6765\u63d0\u9ad8\u89e3\u51b3\u65b9\u6848\u5019\u9009\u7684\u591a\u6837\u6027\uff0c\u76f8\u6bd4\u4f20\u7edf\u91cd\u590d\u91c7\u6837\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u91cd\u590d\u91c7\u6837\u65b9\u6cd5\u5728\u63a8\u7406\u65f6\u867d\u7136\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u5f80\u5f80\u96be\u4ee5\u751f\u6210\u591a\u6837\u5316\u7684\u89e3\u51b3\u65b9\u6848\u5019\u9009\uff0c\u7ecf\u5e38\u4f9d\u8d56\u76f8\u540c\u7684\u57fa\u7840\u65b9\u6cd5\u89e3\u51b3\u95ee\u9898\uff0c\u5bfc\u81f4\u6837\u672c\u5197\u4f59\u3002", "method": "GuidedSampling\u7b97\u6cd5\u5c06\u63a8\u7406\u8fc7\u7a0b\u5206\u4e3a\u63a2\u7d22\u548c\u751f\u6210\u4e24\u4e2a\u9636\u6bb5\uff1a\u63a2\u7d22\u9636\u6bb5\u8bc6\u522b\u53ef\u7528\u4e8e\u89e3\u51b3\u95ee\u9898\u7684\u591a\u4e2a\u6982\u5ff5\uff0c\u751f\u6210\u9636\u6bb5\u5e94\u7528\u7279\u5b9a\u6982\u5ff5\u63d0\u4f9b\u6700\u7ec8\u89e3\u51b3\u65b9\u6848\u5019\u9009\u3002", "result": "\u76f8\u6bd4\u91cd\u590d\u91c7\u6837\uff0cGuidedSampling\u5728pass@50\u6307\u6807\u4e0a\u5e73\u5747\u63d0\u5347\u7ea621.6%\uff1b\u4f7f\u7528GuidedSampling\u8f68\u8ff9\u8bad\u7ec3\u7684\u6a21\u578b\u5728pass@5\u4e0a\u5e73\u5747\u63d0\u5347\u7ea69.7%\uff0c\u4e14\u6bcf\u4e2a\u5b9e\u4f8b\u7684\u5e73\u5747\u6982\u5ff5\u6570\u91cf\u4ece1.67\u589e\u52a0\u52303.03\u3002", "conclusion": "GuidedSampling\u901a\u8fc7\u89e3\u8026\u63a2\u7d22\u548c\u751f\u6210\u9636\u6bb5\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u591a\u6837\u6027\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u91cd\u590d\u91c7\u6837\u65b9\u6cd5\u3002"}}
{"id": "2510.04053", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.04053", "abs": "https://arxiv.org/abs/2510.04053", "authors": ["Yijie Yang", "Jian Shi", "Dan Wang", "Chenye Wu", "Zhu Han"], "title": "A Conformal Prediction-Based Chance-Constrained Programming Approach for 24/7 Carbon-Free Data Center Operation Scheduling", "comment": null, "summary": "The rapid growth of AI applications is dramatically increasing data center\nenergy demand, exacerbating carbon emissions, and necessitating a shift towards\n24/7 carbon-free energy (CFE). Unlike traditional annual energy matching, 24/7\nCFE requires matching real-time electricity consumption with clean energy\ngeneration every hour, presenting significant challenges due to the inherent\nvariability and forecasting errors of renewable energy sources. Traditional\nrobust and data-driven optimization methods often fail to leverage the features\nof the prediction model (also known as contextual or covariate information)\nwhen constructing the uncertainty set, leading to overly conservative\noperational decisions. This paper proposes a comprehensive approach for 24/7\nCFE data center operation scheduling, focusing on robust decision-making under\nrenewable generation uncertainty. This framework leverages covariate\ninformation through a multi-variable conformal prediction (CP) technique to\nconstruct statistically valid and adaptive uncertainty sets for renewable\nforecasts. The uncertainty sets directly inform the chance-constrained\nprogramming (CCP) problem, ensuring that chance constraints are met with a\nspecified probability. We further establish theoretical underpinnings\nconnecting the CP-generated uncertainty sets to the statistical feasibility\nguarantees of the CCP. Numerical results highlight the benefits of this\ncovariate-aware approach, demonstrating up to 6.65% cost reduction and 6.96%\ndecrease in carbon-based energy usage compared to conventional\ncovariate-independent methods, thereby enabling data centers to progress toward\n24/7 CEF.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u53d8\u91cf\u4fdd\u5f62\u9884\u6d4b\u768424/7\u65e0\u78b3\u80fd\u6e90\u6570\u636e\u4e2d\u5fc3\u8fd0\u8425\u8c03\u5ea6\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u534f\u53d8\u91cf\u4fe1\u606f\u6784\u5efa\u81ea\u9002\u5e94\u4e0d\u786e\u5b9a\u6027\u96c6\u5408\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u53ef\u964d\u4f4e6.65%\u6210\u672c\u548c6.96%\u78b3\u57fa\u80fd\u6e90\u4f7f\u7528\u3002", "motivation": "AI\u5e94\u7528\u5feb\u901f\u589e\u957f\u5bfc\u81f4\u6570\u636e\u4e2d\u5fc3\u80fd\u8017\u6fc0\u589e\uff0c\u52a0\u5267\u78b3\u6392\u653e\uff0c\u9700\u8981\u8f6c\u541124/7\u65e0\u78b3\u80fd\u6e90\u8fd0\u8425\u3002\u4f20\u7edf\u5e74\u5ea6\u80fd\u6e90\u5339\u914d\u65b9\u6cd5\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u65f6\u6e05\u6d01\u80fd\u6e90\u5339\u914d\u9700\u6c42\uff0c\u4e14\u73b0\u6709\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u65b9\u6cd5\u8fc7\u4e8e\u4fdd\u5b88\u3002", "method": "\u4f7f\u7528\u591a\u53d8\u91cf\u4fdd\u5f62\u9884\u6d4b\u6280\u672f\u6784\u5efa\u7edf\u8ba1\u6709\u6548\u7684\u81ea\u9002\u5e94\u4e0d\u786e\u5b9a\u6027\u96c6\u5408\uff0c\u7ed3\u5408\u673a\u4f1a\u7ea6\u675f\u89c4\u5212\u786e\u4fdd\u7ea6\u675f\u6ee1\u8db3\u7279\u5b9a\u6982\u7387\uff0c\u5efa\u7acb\u7406\u8bba\u8fde\u63a5\u4fdd\u5f62\u9884\u6d4b\u4e0e\u673a\u4f1a\u7ea6\u675f\u7684\u7edf\u8ba1\u53ef\u884c\u6027\u4fdd\u8bc1\u3002", "result": "\u76f8\u6bd4\u4f20\u7edf\u534f\u53d8\u91cf\u65e0\u5173\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u53ef\u5b9e\u73b06.65%\u6210\u672c\u964d\u4f4e\u548c6.96%\u78b3\u57fa\u80fd\u6e90\u4f7f\u7528\u51cf\u5c11\uff0c\u63a8\u52a8\u6570\u636e\u4e2d\u5fc3\u5b9e\u73b024/7\u65e0\u78b3\u80fd\u6e90\u76ee\u6807\u3002", "conclusion": "\u63d0\u51fa\u7684\u534f\u53d8\u91cf\u611f\u77e5\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u53ef\u518d\u751f\u80fd\u6e90\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3a\u6570\u636e\u4e2d\u5fc324/7\u65e0\u78b3\u80fd\u6e90\u8fd0\u8425\u63d0\u4f9b\u53ef\u884c\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u7ecf\u6d4e\u6027\u548c\u73af\u5883\u6548\u76ca\u3002"}}
{"id": "2510.03706", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03706", "abs": "https://arxiv.org/abs/2510.03706", "authors": ["Eadom Dessalene", "Pavan Mantripragada", "Michael Maynord", "Yiannis Aloimonos"], "title": "EmbodiSwap for Zero-Shot Robot Imitation Learning", "comment": "Video link:\n  https://drive.google.com/file/d/1UccngwgPqUwPMhBja7JrXfZoTquCx_Qe/view?usp=sharing", "summary": "We introduce EmbodiSwap - a method for producing photorealistic synthetic\nrobot overlays over human video. We employ EmbodiSwap for zero-shot imitation\nlearning, bridging the embodiment gap between in-the-wild ego-centric human\nvideo and a target robot embodiment. We train a closed-loop robot manipulation\npolicy over the data produced by EmbodiSwap. We make novel use of V-JEPA as a\nvisual backbone, repurposing V-JEPA from the domain of video understanding to\nimitation learning over synthetic robot videos. Adoption of V-JEPA outperforms\nalternative vision backbones more conventionally used within robotics. In\nreal-world tests, our zero-shot trained V-JEPA model achieves an $82\\%$ success\nrate, outperforming a few-shot trained $\\pi_0$ network as well as $\\pi_0$\ntrained over data produced by EmbodiSwap. We release (i) code for generating\nthe synthetic robot overlays which takes as input human videos and an arbitrary\nrobot URDF and generates a robot dataset, (ii) the robot dataset we synthesize\nover EPIC-Kitchens, HOI4D and Ego4D, and (iii) model checkpoints and inference\ncode, to facilitate reproducible research and broader adoption.", "AI": {"tldr": "EmbodiSwap\u662f\u4e00\u79cd\u5c06\u4eba\u7c7b\u89c6\u9891\u8f6c\u6362\u4e3a\u903c\u771f\u673a\u5668\u4eba\u8986\u76d6\u56fe\u50cf\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u96f6\u6837\u672c\u6a21\u4eff\u5b66\u4e60\uff0c\u901a\u8fc7V-JEPA\u89c6\u89c9\u9aa8\u5e72\u7f51\u7edc\u5728\u5408\u6210\u673a\u5668\u4eba\u89c6\u9891\u4e0a\u8bad\u7ec3\u95ed\u73af\u64cd\u4f5c\u7b56\u7565\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u6d4b\u8bd5\u4e2d\u8fbe\u523082%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u91ce\u5916\u4eba\u7c7b\u89c6\u9891\u4e0e\u76ee\u6807\u673a\u5668\u4eba\u5b9e\u4f53\u4e4b\u95f4\u7684\u5b9e\u4f53\u5dee\u8ddd\u95ee\u9898\uff0c\u5b9e\u73b0\u4ece\u4eba\u7c7b\u89c6\u9891\u5230\u673a\u5668\u4eba\u6a21\u4eff\u5b66\u4e60\u7684\u96f6\u6837\u672c\u8fc1\u79fb\u3002", "method": "\u4f7f\u7528EmbodiSwap\u65b9\u6cd5\u751f\u6210\u903c\u771f\u7684\u5408\u6210\u673a\u5668\u4eba\u8986\u76d6\u56fe\u50cf\uff0c\u5c06V-JEPA\u89c6\u89c9\u9aa8\u5e72\u7f51\u7edc\u4ece\u89c6\u9891\u7406\u89e3\u9886\u57df\u91cd\u65b0\u7528\u4e8e\u5408\u6210\u673a\u5668\u4eba\u89c6\u9891\u7684\u6a21\u4eff\u5b66\u4e60\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6d4b\u8bd5\u4e2d\uff0c\u96f6\u6837\u672c\u8bad\u7ec3\u7684V-JEPA\u6a21\u578b\u8fbe\u523082%\u7684\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u5c11\u6837\u672c\u8bad\u7ec3\u7684\u03c0\u2080\u7f51\u7edc\u4ee5\u53ca\u57fa\u4e8eEmbodiSwap\u6570\u636e\u8bad\u7ec3\u7684\u03c0\u2080\u3002", "conclusion": "EmbodiSwap\u7ed3\u5408V-JEPA\u89c6\u89c9\u9aa8\u5e72\u7f51\u7edc\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u96f6\u6837\u672c\u6a21\u4eff\u5b66\u4e60\uff0c\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u53d1\u5e03\u4e86\u76f8\u5173\u4ee3\u7801\u3001\u6570\u636e\u96c6\u548c\u6a21\u578b\u4ee5\u4fc3\u8fdb\u53ef\u91cd\u590d\u7814\u7a76\u3002"}}
{"id": "2510.03845", "categories": ["cs.AI", "cs.GT", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.03845", "abs": "https://arxiv.org/abs/2510.03845", "authors": ["Gon Buzaglo", "Noah Golowich", "Elad Hazan"], "title": "The Hidden Game Problem", "comment": null, "summary": "This paper investigates a class of games with large strategy spaces,\nmotivated by challenges in AI alignment and language games. We introduce the\nhidden game problem, where for each player, an unknown subset of strategies\nconsistently yields higher rewards compared to the rest. The central question\nis whether efficient regret minimization algorithms can be designed to discover\nand exploit such hidden structures, leading to equilibrium in these subgames\nwhile maintaining rationality in general. We answer this question affirmatively\nby developing a composition of regret minimization techniques that achieve\noptimal external and swap regret bounds. Our approach ensures rapid convergence\nto correlated equilibria in hidden subgames, leveraging the hidden game\nstructure for improved computational efficiency.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5177\u6709\u5927\u578b\u7b56\u7565\u7a7a\u95f4\u7684\u6e38\u620f\uff0c\u63d0\u51fa\u4e86\u9690\u85cf\u6e38\u620f\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u80fd\u591f\u53d1\u73b0\u548c\u5229\u7528\u9690\u85cf\u7ed3\u6784\u7684\u9057\u61be\u6700\u5c0f\u5316\u7b97\u6cd5\uff0c\u5b9e\u73b0\u6700\u4f18\u7684\u5916\u90e8\u9057\u61be\u548c\u4ea4\u6362\u9057\u61be\u754c\u9650\u3002", "motivation": "\u53d7AI\u5bf9\u9f50\u548c\u8bed\u8a00\u6e38\u620f\u6311\u6218\u7684\u542f\u53d1\uff0c\u7814\u7a76\u5f53\u6bcf\u4e2a\u73a9\u5bb6\u5b58\u5728\u672a\u77e5\u7b56\u7565\u5b50\u96c6\u80fd\u6301\u7eed\u83b7\u5f97\u66f4\u9ad8\u5956\u52b1\u65f6\u7684\u9690\u85cf\u6e38\u620f\u95ee\u9898\uff0c\u63a2\u7d22\u80fd\u5426\u8bbe\u8ba1\u9ad8\u6548\u7b97\u6cd5\u6765\u53d1\u73b0\u5e76\u5229\u7528\u8fd9\u79cd\u9690\u85cf\u7ed3\u6784\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u9057\u61be\u6700\u5c0f\u5316\u6280\u672f\u7684\u7ec4\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u5916\u90e8\u9057\u61be\u548c\u4ea4\u6362\u9057\u61be\u6700\u5c0f\u5316\uff0c\u5229\u7528\u9690\u85cf\u6e38\u620f\u7ed3\u6784\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u786e\u4fdd\u5728\u9690\u85cf\u5b50\u6e38\u620f\u4e2d\u5feb\u901f\u6536\u655b\u5230\u76f8\u5173\u5747\u8861\u3002", "result": "\u6210\u529f\u8bbe\u8ba1\u4e86\u80fd\u591f\u5b9e\u73b0\u6700\u4f18\u5916\u90e8\u9057\u61be\u548c\u4ea4\u6362\u9057\u61be\u754c\u9650\u7684\u7b97\u6cd5\uff0c\u8bc1\u660e\u53ef\u4ee5\u5728\u9690\u85cf\u6e38\u620f\u4e2d\u5feb\u901f\u6536\u655b\u5230\u76f8\u5173\u5747\u8861\uff0c\u540c\u65f6\u4fdd\u6301\u4e00\u822c\u60c5\u51b5\u4e0b\u7684\u7406\u6027\u3002", "conclusion": "\u5bf9\u9690\u85cf\u6e38\u620f\u95ee\u9898\u7ed9\u51fa\u4e86\u80af\u5b9a\u56de\u7b54\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u9057\u61be\u6700\u5c0f\u5316\u7b97\u6cd5\u7ec4\u5408\uff0c\u53ef\u4ee5\u6709\u6548\u53d1\u73b0\u548c\u5229\u7528\u6e38\u620f\u4e2d\u7684\u9690\u85cf\u7ed3\u6784\uff0c\u5b9e\u73b0\u9ad8\u6548\u5747\u8861\u6536\u655b\u3002"}}
{"id": "2510.04264", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.04264", "abs": "https://arxiv.org/abs/2510.04264", "authors": ["Mohamed Shamseldein"], "title": "A Hybrid GNN-IZR Framework for Fast and Empirically Robust AC Power Flow Analysis in Radial Distribution Systems", "comment": null, "summary": "The Alternating Current Power Flow (ACPF) problem forces a trade-off between\nthe speed of data-driven models and the reliability of analytical solvers. This\npaper introduces a hybrid framework that synergizes a Graph Neural Network\n(GNN) with the Implicit Z-Bus Recursive (IZR) method, a robust, non-iterative\nsolver for radial distribution networks. The framework employs a\nphysics-informed GNN for rapid initial predictions and invokes the IZR solver\nas a failsafe for stressed cases identified by a two-stage trigger. A failure\nis defined as any solution with a maximum power mismatch exceeding 0.1 p.u., a\nsignificant operational deviation. On a challenging test set of 7,500 stressed\nscenarios for the IEEE 33-bus system, the GNN-only model failed on 13.11 % of\ncases. In contrast, the hybrid framework identified all potential failures,\ndelegating them to the IZR solver to achieve a 0.00 % failure rate, empirically\nmatching the 100 % success rate of the analytical solver on this specific test\nset. An expanded ablation study confirms that both physics-informed training\nand Z-bus sensitivity features are critical, collaboratively reducing the GNN's\nfailure rate from 98.72 % (data-only) to 13.11 %. The hybrid approach\ndemonstrates a pragmatic path to achieving the empirical reliability of an\nanalytical solver while leveraging GNN speed, enabling a significant increase\nin the number of scenarios analyzable in near real-time.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc(GNN)\u548c\u9690\u5f0fZ\u603b\u7ebf\u9012\u5f52(IZR)\u65b9\u6cd5\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u4ea4\u6d41\u6f6e\u6d41\u95ee\u9898\uff0c\u5728\u4fdd\u6301GNN\u901f\u5ea6\u4f18\u52bf\u7684\u540c\u65f6\u5b9e\u73b0\u5206\u6790\u6c42\u89e3\u5668\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u89e3\u51b3\u4ea4\u6d41\u6f6e\u6d41\u95ee\u9898\u4e2d\u6570\u636e\u9a71\u52a8\u6a21\u578b\u901f\u5ea6\u4e0e\u5206\u6790\u6c42\u89e3\u5668\u53ef\u9760\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u5bfb\u6c42\u4e00\u79cd\u65e2\u80fd\u5feb\u901f\u6c42\u89e3\u53c8\u80fd\u4fdd\u8bc1\u53ef\u9760\u6027\u7684\u5b9e\u7528\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7269\u7406\u4fe1\u606fGNN\u8fdb\u884c\u5feb\u901f\u521d\u59cb\u9884\u6d4b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u89e6\u53d1\u5668\u8bc6\u522b\u538b\u529b\u60c5\u51b5\uff0c\u5c06\u6f5c\u5728\u5931\u8d25\u6848\u4f8b\u59d4\u6258\u7ed9IZR\u6c42\u89e3\u5668\u5904\u7406\u3002", "result": "\u5728IEEE 33\u603b\u7ebf\u7cfb\u7edf\u76847500\u4e2a\u538b\u529b\u573a\u666f\u6d4b\u8bd5\u4e2d\uff0c\u7eafGNN\u6a21\u578b\u5931\u8d25\u7387\u4e3a13.11%\uff0c\u800c\u6df7\u5408\u6846\u67b6\u901a\u8fc7\u8bc6\u522b\u6240\u6709\u6f5c\u5728\u5931\u8d25\u5e76\u59d4\u6258IZR\u6c42\u89e3\uff0c\u5b9e\u73b0\u4e860.00%\u7684\u5931\u8d25\u7387\u3002", "conclusion": "\u8be5\u6df7\u5408\u65b9\u6cd5\u5c55\u793a\u4e86\u5728\u4fdd\u6301\u5206\u6790\u6c42\u89e3\u5668\u53ef\u9760\u6027\u7684\u540c\u65f6\u5229\u7528GNN\u901f\u5ea6\u4f18\u52bf\u7684\u5b9e\u7528\u8def\u5f84\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8fd1\u5b9e\u65f6\u53ef\u5206\u6790\u573a\u666f\u7684\u6570\u91cf\u3002"}}
{"id": "2510.03768", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03768", "abs": "https://arxiv.org/abs/2510.03768", "authors": ["Aydin Ahmadi", "Baris Akgun"], "title": "Model-Based Adaptive Precision Control for Tabletop Planar Pushing Under Uncertain Dynamics", "comment": null, "summary": "Data-driven planar pushing methods have recently gained attention as they\nreduce manual engineering effort and improve generalization compared to\nanalytical approaches. However, most prior work targets narrow capabilities\n(e.g., side switching, precision, or single-task training), limiting broader\napplicability. We present a model-based framework for non-prehensile tabletop\npushing that uses a single learned model to address multiple tasks without\nretraining. Our approach employs a recurrent GRU-based architecture with\nadditional non-linear layers to capture object-environment dynamics while\nensuring stability. A tailored state-action representation enables the model to\ngeneralize across uncertain dynamics, variable push lengths, and diverse tasks.\nFor control, we integrate the learned dynamics with a sampling-based Model\nPredictive Path Integral (MPPI) controller, which generates adaptive,\ntask-oriented actions. This framework supports side switching, variable-length\npushes, and objectives such as precise positioning, trajectory following, and\nobstacle avoidance. Training is performed in simulation with domain\nrandomization to support sim-to-real transfer. We first evaluate the\narchitecture through ablation studies, showing improved prediction accuracy and\nstable rollouts. We then validate the full system in simulation and real-world\nexperiments using a Franka Panda robot with markerless tracking. Results\ndemonstrate high success rates in precise positioning under strict thresholds\nand strong performance in trajectory tracking and obstacle avoidance. Moreover,\nmultiple tasks are solved simply by changing the controller's objective\nfunction, without retraining. While our current focus is on a single object\ntype, we extend the framework by training on wider push lengths and designing a\nbalanced controller that reduces the number of steps for longer-horizon goals.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6a21\u578b\u7684\u975e\u6293\u53d6\u684c\u9762\u63a8\u52a8\u6846\u67b6\uff0c\u4f7f\u7528\u5355\u4e00\u5b66\u4e60\u6a21\u578b\u5904\u7406\u591a\u4e2a\u4efb\u52a1\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff0c\u7ed3\u5408GRU\u67b6\u6784\u548cMPPI\u63a7\u5236\u5668\u5b9e\u73b0\u81ea\u9002\u5e94\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9a71\u52a8\u7684\u5e73\u9762\u63a8\u52a8\u65b9\u6cd5\u80fd\u529b\u72ed\u7a84\uff0c\u9650\u5236\u4e86\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u591a\u79cd\u4efb\u52a1\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684\u901a\u7528\u6846\u67b6\u3002", "method": "\u91c7\u7528\u5faa\u73afGRU\u67b6\u6784\u548c\u975e\u7ebf\u6027\u5c42\u6355\u6349\u7269\u4f53-\u73af\u5883\u52a8\u6001\uff0c\u7ed3\u5408MPPI\u91c7\u6837\u63a7\u5236\u5668\u751f\u6210\u81ea\u9002\u5e94\u52a8\u4f5c\uff0c\u4f7f\u7528\u9886\u57df\u968f\u673a\u5316\u8fdb\u884c\u4eff\u771f\u8bad\u7ec3\u4ee5\u652f\u6301\u4eff\u771f\u5230\u5b9e\u7269\u7684\u8fc1\u79fb\u3002", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u9ad8\u7cbe\u786e\u5b9a\u4f4d\u6210\u529f\u7387\uff0c\u5728\u8f68\u8ff9\u8ddf\u8e2a\u548c\u907f\u969c\u4efb\u52a1\u4e2d\u6027\u80fd\u5f3a\u52b2\uff0c\u901a\u8fc7\u6539\u53d8\u63a7\u5236\u5668\u76ee\u6807\u51fd\u6570\u5373\u53ef\u89e3\u51b3\u4e0d\u540c\u4efb\u52a1\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u5355\u4e00\u6a21\u578b\u5904\u7406\u591a\u79cd\u63a8\u52a8\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u5728\u4e0d\u786e\u5b9a\u52a8\u6001\u3001\u53ef\u53d8\u63a8\u52a8\u957f\u5ea6\u548c\u591a\u6837\u5316\u4efb\u52a1\u4e2d\u7684\u826f\u597d\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2510.03847", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03847", "abs": "https://arxiv.org/abs/2510.03847", "authors": ["Raghav Sharma", "Manan Mehta"], "title": "Small Language Models for Agentic Systems: A Survey of Architectures, Capabilities, and Deployment Trade offs", "comment": "9 Pages", "summary": "Small language models (SLMs; 1-12B params, sometimes up to 20B) are\nsufficient and often superior for agentic workloads where the objective is\nschema- and API-constrained accuracy rather than open-ended generation. We\nsynthesize recent evidence across open and proprietary SLMs (Phi-4-Mini,\nQwen-2.5-7B, Gemma-2-9B, Llama-3.2-1B/3B, Ministral-3B/8B, Apple on-device 3B,\nDeepSeek-R1-Distill) and connect it to modern evaluations (BFCL v3/v4,\nStableToolBench) and serving stacks (vLLM, SGLang, TensorRT-LLM) paired with\nguided decoding libraries (XGrammar, Outlines). We formalize SLM-default,\nLLM-fallback systems with uncertainty-aware routing and verifier cascades, and\npropose engineering metrics that reflect real production goals: cost per\nsuccessful task (CPS), schema validity rate, executable call rate, p50/p95\nlatency, and energy per request. Guided decoding, strict JSON Schema outputs,\nand validator-first tool execution close much of the capability gap with larger\nmodels and often let SLMs match or surpass LLMs on tool use, function calling,\nand RAG at 10x-100x lower token cost with materially better latency and energy.\nWe provide design patterns for agent stacks that prioritize SLMs: schema-first\nprompting, type-safe function registries, confidence scoring with verifier\nrollups, and lightweight adaptation via LoRA/QLoRA. We also delineate limits\nwhere fallback remains valuable (open-domain reasoning and some long-horizon\nplanning). The result is a practical blueprint for building fast, inexpensive,\nand reliable agents that default to SLMs while preserving headroom with\ntargeted LLM assistance.\n  Keywords: small language models, agents, function calling, structured\noutputs, JSON Schema, guided decoding, LoRA/QLoRA, routing, energy efficiency,\nedge inference", "AI": {"tldr": "\u5c0f\u8bed\u8a00\u6a21\u578b(SLMs)\u5728\u4ee3\u7406\u4efb\u52a1\u4e2d\u6bd4\u5927\u8bed\u8a00\u6a21\u578b\u66f4\u9ad8\u6548\uff0c\u901a\u8fc7\u5f15\u5bfc\u89e3\u7801\u3001\u4e25\u683cJSON Schema\u8f93\u51fa\u548c\u9a8c\u8bc1\u5668\u4f18\u5148\u7684\u5de5\u5177\u6267\u884c\uff0c\u80fd\u4ee510-100\u500d\u66f4\u4f4e\u7684\u6210\u672c\u5b9e\u73b0\u76f8\u4f3c\u6216\u66f4\u597d\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u4f4e\u7684\u5ef6\u8fdf\u548c\u80fd\u8017\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u6210\u672c\u9ad8\u3001\u5ef6\u8fdf\u5927\u3001\u80fd\u8017\u9ad8\uff0c\u800c\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u5316\u8f93\u51fa\u548cAPI\u7ea6\u675f\u4efb\u52a1\u4e2d\u53ef\u80fd\u66f4\u9ad8\u6548\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u9a8c\u8bc1\u8fd9\u4e00\u5047\u8bbe\u3002", "method": "\u7efc\u5408\u8bc4\u4f30\u591a\u79cd\u5f00\u6e90\u548c\u4e13\u6709\u5c0f\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408\u5f15\u5bfc\u89e3\u7801\u5e93\u548c\u9a8c\u8bc1\u5668\u7ea7\u8054\uff0c\u63d0\u51faSLM\u9ed8\u8ba4\u3001LLM\u56de\u9000\u7cfb\u7edf\uff0c\u91c7\u7528\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8def\u7531\u548c\u9a8c\u8bc1\u5668\u7ea7\u8054\u3002", "result": "\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u5177\u4f7f\u7528\u3001\u51fd\u6570\u8c03\u7528\u548cRAG\u4efb\u52a1\u4e2d\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6210\u672c\u964d\u4f4e10-100\u500d\uff0c\u5ef6\u8fdf\u548c\u80fd\u8017\u663e\u8457\u6539\u5584\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u5957\u4f18\u5148\u4f7f\u7528\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u7cfb\u7edf\u8bbe\u8ba1\u84dd\u56fe\uff0c\u5728\u4fdd\u6301\u5927\u8bed\u8a00\u6a21\u578b\u56de\u9000\u80fd\u529b\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u5feb\u901f\u3001\u5ec9\u4ef7\u4e14\u53ef\u9760\u7684\u4ee3\u7406\u7cfb\u7edf\u3002"}}
{"id": "2510.04470", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.04470", "abs": "https://arxiv.org/abs/2510.04470", "authors": ["Quan Tran", "Suresh S. Muknahallipatna", "Dongliang Duan", "Nga Nguyen"], "title": "A Diffusion-based Generative Machine Learning Paradigm for Contingency Screening", "comment": null, "summary": "Contingency screening is a crucial part of electric power systems all the\ntime. Power systems frequently encounter multiple challenging operational\ndilemmas that could lead to the instability of power systems. Contingency\nanalysis is effort-consuming by utilizing traditional numerical analysis\nmethods. It is commonly addressed by generating a whopping number of possible\ncontingencies or manipulating network parameters to determine the worst\nscenarios. This paper proposes a novel approach that diverts the nature of\ncontingency analysis from pre-defined scenario screening to\nproactive-unsupervised screening. The potentially risky scenarios of power\nsystems are generated from learning how the previous ones occurred. In other\nwords, the internal perturbation that initiates contingencies is learned prior\nto being self-replicated for rendering the worst scenarios. By leveraging the\nperturbation diffusion technique, a proposed model is built to point out the\nworst scenarios instead of repeatedly simulating one-by-one scenarios to define\nthe highest-risk ones. Empirical experiments are implemented on the IEEE\nsystems to test and validate the proposed solution.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7535\u529b\u7cfb\u7edf\u4e8b\u6545\u7b5b\u9009\u65b9\u6cd5\uff0c\u4ece\u9884\u5b9a\u4e49\u573a\u666f\u7b5b\u9009\u8f6c\u5411\u4e3b\u52a8\u65e0\u76d1\u7763\u7b5b\u9009\uff0c\u901a\u8fc7\u6270\u52a8\u6269\u6563\u6280\u672f\u5b66\u4e60\u4e8b\u6545\u53d1\u751f\u7684\u5185\u90e8\u6270\u52a8\u6a21\u5f0f\uff0c\u81ea\u52a8\u751f\u6210\u6700\u5371\u9669\u573a\u666f\u3002", "motivation": "\u4f20\u7edf\u7535\u529b\u7cfb\u7edf\u4e8b\u6545\u5206\u6790\u91c7\u7528\u6570\u503c\u5206\u6790\u65b9\u6cd5\uff0c\u9700\u8981\u751f\u6210\u5927\u91cf\u53ef\u80fd\u4e8b\u6545\u6216\u64cd\u7eb5\u7f51\u7edc\u53c2\u6570\u6765\u786e\u5b9a\u6700\u574f\u60c5\u51b5\uff0c\u8fd9\u79cd\u65b9\u6cd5\u8017\u65f6\u4e14\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6270\u52a8\u6269\u6563\u6280\u672f\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u5b66\u4e60\u5148\u524d\u4e8b\u6545\u53d1\u751f\u7684\u5185\u90e8\u6270\u52a8\u6a21\u5f0f\uff0c\u4e3b\u52a8\u751f\u6210\u6f5c\u5728\u98ce\u9669\u573a\u666f\uff0c\u800c\u4e0d\u662f\u9010\u4e2a\u6a21\u62df\u573a\u666f\u6765\u8bc6\u522b\u6700\u9ad8\u98ce\u9669\u60c5\u51b5\u3002", "result": "\u5728IEEE\u7cfb\u7edf\u4e0a\u8fdb\u884c\u4e86\u5b9e\u8bc1\u5b9e\u9a8c\uff0c\u6d4b\u8bd5\u548c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8bc6\u522b\u7535\u529b\u7cfb\u7edf\u7684\u6700\u5371\u9669\u4e8b\u6545\u573a\u666f\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u52a0\u9ad8\u6548\u548c\u4e3b\u52a8\u3002"}}
{"id": "2510.03776", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03776", "abs": "https://arxiv.org/abs/2510.03776", "authors": ["Tiago Rodrigues de Almeida", "Yufei Zhu", "Andrey Rudenko", "Tomasz P. Kucner", "Johannes A. Stork", "Martin Magnusson", "Achim J. Lilienthal"], "title": "Trajectory prediction for heterogeneous agents: A performance analysis on small and imbalanced datasets", "comment": "This paper has been accepted to the IEEE Robotics and Automation\n  Letters journal and presented at the 40th Anniversary of the IEEE\n  International Conference on Robotics and Automation, which was held in\n  Rotterdam, Netherlands on 23-26 September, 2024", "summary": "Robots and other intelligent systems navigating in complex dynamic\nenvironments should predict future actions and intentions of surrounding agents\nto reach their goals efficiently and avoid collisions. The dynamics of those\nagents strongly depends on their tasks, roles, or observable labels.\nClass-conditioned motion prediction is thus an appealing way to reduce forecast\nuncertainty and get more accurate predictions for heterogeneous agents.\nHowever, this is hardly explored in the prior art, especially for mobile robots\nand in limited data applications. In this paper, we analyse different\nclass-conditioned trajectory prediction methods on two datasets. We propose a\nset of conditional pattern-based and efficient deep learning-based baselines,\nand evaluate their performance on robotics and outdoors datasets (TH\\\"OR-MAGNI\nand Stanford Drone Dataset). Our experiments show that all methods improve\naccuracy in most of the settings when considering class labels. More\nimportantly, we observe that there are significant differences when learning\nfrom imbalanced datasets, or in new environments where sufficient data is not\navailable. In particular, we find that deep learning methods perform better on\nbalanced datasets, but in applications with limited data, e.g., cold start of a\nrobot in a new environment, or imbalanced classes, pattern-based methods may be\npreferable.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u7c7b\u522b\u6761\u4ef6\u8f68\u8ff9\u9884\u6d4b\u65b9\u6cd5\u5728\u673a\u5668\u4eba\u5bfc\u822a\u4e2d\u7684\u5e94\u7528\uff0c\u6bd4\u8f83\u4e86\u57fa\u4e8e\u6a21\u5f0f\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u53d1\u73b0\u5728\u6570\u636e\u6709\u9650\u6216\u7c7b\u522b\u4e0d\u5e73\u8861\u65f6\u6a21\u5f0f\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\uff0c\u673a\u5668\u4eba\u9700\u8981\u9884\u6d4b\u5468\u56f4\u667a\u80fd\u4f53\u7684\u672a\u6765\u884c\u52a8\u548c\u610f\u56fe\u4ee5\u5b9e\u73b0\u9ad8\u6548\u5bfc\u822a\u548c\u907f\u78b0\u3002\u7531\u4e8e\u667a\u80fd\u4f53\u7684\u52a8\u6001\u7279\u6027\u53d6\u51b3\u4e8e\u5176\u4efb\u52a1\u3001\u89d2\u8272\u6216\u53ef\u89c2\u5bdf\u6807\u7b7e\uff0c\u7c7b\u522b\u6761\u4ef6\u8fd0\u52a8\u9884\u6d4b\u6210\u4e3a\u51cf\u5c11\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u548c\u63d0\u9ad8\u5f02\u8d28\u667a\u80fd\u4f53\u9884\u6d4b\u51c6\u786e\u6027\u7684\u6709\u524d\u666f\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u6761\u4ef6\u7684\u6a21\u5f0f\u65b9\u6cd5\u548c\u9ad8\u6548\u7684\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728TH\u00d6R-MAGNI\u548cStanford Drone Dataset\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u8003\u8651\u7c7b\u522b\u6807\u7b7e\u65f6\uff0c\u6240\u6709\u65b9\u6cd5\u5728\u5927\u591a\u6570\u8bbe\u7f6e\u4e0b\u90fd\u80fd\u63d0\u9ad8\u51c6\u786e\u6027\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5728\u4ece\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u5b66\u4e60\u6216\u5728\u65b0\u73af\u5883\u4e2d\u6570\u636e\u4e0d\u8db3\u65f6\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u6df1\u5ea6\u5b66\u4e60\u5728\u5e73\u8861\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u5728\u6570\u636e\u6709\u9650\u7684\u5e94\u7528\u4e2d\uff0c\u6a21\u5f0f\u65b9\u6cd5\u53ef\u80fd\u66f4\u4f18\u3002", "conclusion": "\u7c7b\u522b\u6761\u4ef6\u8f68\u8ff9\u9884\u6d4b\u80fd\u663e\u8457\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u6839\u636e\u6570\u636e\u53ef\u7528\u6027\u548c\u7c7b\u522b\u5e73\u8861\u60c5\u51b5\u9009\u62e9\u5408\u9002\u7684\u65b9\u6cd5\uff1a\u6df1\u5ea6\u5b66\u4e60\u9002\u5408\u5e73\u8861\u6570\u636e\u96c6\uff0c\u6a21\u5f0f\u65b9\u6cd5\u66f4\u9002\u5408\u6570\u636e\u6709\u9650\u6216\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u573a\u666f\u3002"}}
{"id": "2510.03851", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03851", "abs": "https://arxiv.org/abs/2510.03851", "authors": ["Ruiying Ma", "Chieh-Jan Mike Liang", "Yanjie Gao", "Francis Y. Yan"], "title": "Algorithm Generation via Creative Ideation", "comment": null, "summary": "Designing system algorithms remains challenging, where the discontinuous\nnature of the solution space often forces system engineers to rely on generic\nheuristics at the expense of performance. We study whether LLMs can practically\ndrive algorithm generation, and find that they are biased towards well-known\ngeneric designs, rather than making the creative leaps needed to navigate the\ndiscontinuous solution space. To address this limitation, we introduce\nMetaMuse, a framework for creative ideation built on three self-reflection\nprinciples: (1) quantifying solution diversity and usefulness in measurable\nperformance space, rather than abstract idea space, (2) steering ideation\nthrough external stimuli, rather than internal randomness, and (3) constructing\nexecutable solutions using waypoint reasoning, rather than free-form\nchain-of-thought. Extensive evaluation shows that MetaMuse can generate\nhigh-performing solutions for two critical problems at a global cloud provider:\ncache replacement (reducing cache misses by up to 35.76%) and online bin\npacking (reducing bin usage by up to 30.93%).", "AI": {"tldr": "MetaMuse\u6846\u67b6\u901a\u8fc7\u4e09\u4e2a\u81ea\u53cd\u601d\u539f\u5219\u89e3\u51b3LLM\u5728\u7b97\u6cd5\u751f\u6210\u4e2d\u7684\u5c40\u9650\u6027\uff1a\u5728\u6027\u80fd\u7a7a\u95f4\u91cf\u5316\u89e3\u51b3\u65b9\u6848\u591a\u6837\u6027\u3001\u901a\u8fc7\u5916\u90e8\u523a\u6fc0\u5f15\u5bfc\u6784\u601d\u3001\u4f7f\u7528\u8def\u70b9\u63a8\u7406\u6784\u5efa\u53ef\u6267\u884c\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f13\u5b58\u66ff\u6362\u548c\u5728\u7ebf\u88c5\u7bb1\u95ee\u9898\u7684\u6027\u80fd\u3002", "motivation": "\u7cfb\u7edf\u7b97\u6cd5\u8bbe\u8ba1\u9762\u4e34\u89e3\u7a7a\u95f4\u4e0d\u8fde\u7eed\u7684\u6311\u6218\uff0c\u73b0\u6709LLM\u504f\u5411\u901a\u7528\u8bbe\u8ba1\u800c\u7f3a\u4e4f\u521b\u9020\u6027\u7a81\u7834\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u6765\u5bfc\u822a\u4e0d\u8fde\u7eed\u89e3\u7a7a\u95f4\u3002", "method": "\u63d0\u51faMetaMuse\u6846\u67b6\uff0c\u57fa\u4e8e\u4e09\u4e2a\u81ea\u53cd\u601d\u539f\u5219\uff1a\u5728\u53ef\u6d4b\u91cf\u6027\u80fd\u7a7a\u95f4\u800c\u975e\u62bd\u8c61\u601d\u60f3\u7a7a\u95f4\u91cf\u5316\u89e3\u51b3\u65b9\u6848\u591a\u6837\u6027\u548c\u6709\u7528\u6027\uff1b\u901a\u8fc7\u5916\u90e8\u523a\u6fc0\u800c\u975e\u5185\u90e8\u968f\u673a\u6027\u5f15\u5bfc\u6784\u601d\uff1b\u4f7f\u7528\u8def\u70b9\u63a8\u7406\u800c\u975e\u81ea\u7531\u5f62\u5f0f\u7684\u601d\u7ef4\u94fe\u6784\u5efa\u53ef\u6267\u884c\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5728\u7f13\u5b58\u66ff\u6362\u95ee\u9898\u4e0a\u51cf\u5c11\u7f13\u5b58\u7f3a\u5931\u8fbe35.76%\uff0c\u5728\u5728\u7ebf\u88c5\u7bb1\u95ee\u9898\u4e0a\u51cf\u5c11\u5bb9\u5668\u4f7f\u7528\u8fbe30.93%\u3002", "conclusion": "MetaMuse\u6846\u67b6\u80fd\u591f\u6709\u6548\u751f\u6210\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86LLM\u5728\u7b97\u6cd5\u751f\u6210\u4e2d\u7684\u521b\u9020\u6027\u5c40\u9650\u95ee\u9898\u3002"}}
{"id": "2510.04524", "categories": ["eess.SY", "cs.SY", "93A30"], "pdf": "https://arxiv.org/pdf/2510.04524", "abs": "https://arxiv.org/abs/2510.04524", "authors": ["Ask H\u00e4llstr\u00f6m", "Felix Agner", "Richard Pates"], "title": "On properties of hydraulic equilibria in district heating networks", "comment": "Accepted for presentation at the 64th IEEE Conference on Decision and\n  Control (CDC), 2025. 6 pages, 5 figures", "summary": "District heating networks are an integral part of the energy system in many\ncountries. In future smart energy systems, they are expected to enhance energy\nflexibility and support the integration of renewable and waste energy sources.\nAn important aspect of these networks is the control of flow rates, which\ndictates the heat delivered to consumers. This paper concerns the properties of\nflow rates in tree-structured district heating networks. We show that under\nmild assumptions of monotonicity in the hydraulic network components,\nstatements regarding the stationary flow rate distribution can be made. In\nparticular, when all consumers in a network incrementally open their valves, an\nincrease in total flow rate throughput is guaranteed, while if one consumer\ndoes not open their valve when others do, they will receive a reduced flow\nrate. These properties are illustrated numerically on a small 2-consumer\nnetwork as well as on a larger 22-consumer network. Previous works have shown\nthat these properties allow the design and use of efficient control strategies\nfor optimal heat distribution.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u6811\u72b6\u533a\u57df\u4f9b\u70ed\u7f51\u7edc\u4e2d\u6d41\u91cf\u5206\u5e03\u7684\u7279\u6027\uff0c\u8bc1\u660e\u5728\u6db2\u538b\u7f51\u7edc\u7ec4\u4ef6\u5355\u8c03\u6027\u5047\u8bbe\u4e0b\uff0c\u6240\u6709\u6d88\u8d39\u8005\u540c\u65f6\u5f00\u9600\u4f1a\u589e\u52a0\u603b\u6d41\u91cf\uff0c\u800c\u5355\u4e2a\u6d88\u8d39\u8005\u4e0d\u5f00\u9600\u4f1a\u51cf\u5c11\u5176\u6d41\u91cf\u3002", "motivation": "\u533a\u57df\u4f9b\u70ed\u7f51\u7edc\u662f\u672a\u6765\u667a\u80fd\u80fd\u6e90\u7cfb\u7edf\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u9700\u8981\u589e\u5f3a\u80fd\u6e90\u7075\u6d3b\u6027\u5e76\u652f\u6301\u53ef\u518d\u751f\u80fd\u6e90\u6574\u5408\uff0c\u6d41\u91cf\u63a7\u5236\u662f\u5f71\u54cd\u4f9b\u70ed\u6548\u7387\u7684\u91cd\u8981\u56e0\u7d20\u3002", "method": "\u57fa\u4e8e\u6db2\u538b\u7f51\u7edc\u7ec4\u4ef6\u7684\u5355\u8c03\u6027\u5047\u8bbe\uff0c\u5206\u6790\u6811\u72b6\u7ed3\u6784\u4f9b\u70ed\u7f51\u7edc\u4e2d\u7684\u7a33\u6001\u6d41\u91cf\u5206\u5e03\u7279\u6027\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u7406\u8bba\u7ed3\u679c\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u6a21\u62df\u8868\u660e\uff1a\u6240\u6709\u6d88\u8d39\u8005\u540c\u65f6\u5f00\u9600\u4fdd\u8bc1\u603b\u6d41\u91cf\u589e\u52a0\uff1b\u5355\u4e2a\u6d88\u8d39\u8005\u4e0d\u5f00\u9600\u4f1a\u5bfc\u81f4\u5176\u6d41\u91cf\u51cf\u5c11\u3002\u8fd9\u4e9b\u7279\u6027\u5df2\u57282\u6d88\u8d39\u8005\u548c22\u6d88\u8d39\u8005\u7f51\u7edc\u4e2d\u9a8c\u8bc1\u3002", "conclusion": "\u6811\u72b6\u533a\u57df\u4f9b\u70ed\u7f51\u7edc\u5177\u6709\u53ef\u9884\u6d4b\u7684\u6d41\u91cf\u5206\u5e03\u7279\u6027\uff0c\u8fd9\u4e9b\u7279\u6027\u4e3a\u8bbe\u8ba1\u9ad8\u6548\u7684\u70ed\u91cf\u5206\u914d\u63a7\u5236\u7b56\u7565\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2510.03875", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03875", "abs": "https://arxiv.org/abs/2510.03875", "authors": ["Niranjan Kumar Ilampooranan", "Constantinos Chamzas"], "title": "COVER:COverage-VErified Roadmaps for Fixed-time Motion Planning in Continuous Semi-Static Environments", "comment": null, "summary": "Having the ability to answer motion-planning queries within a fixed time\nbudget is critical for the widespread deployment of robotic systems.\nSemi-static environments, where most obstacles remain static but a limited set\ncan vary across queries, exhibit structured variability that can be\nsystematically exploited to provide stronger guarantees than in general\nmotion-planning problems. However, prior approaches in this setting either lack\nformal guarantees or rely on restrictive discretizations of obstacle\nconfigurations, limiting their applicability in realistic domains. This paper\nintroduces COVER, a novel framework that incrementally constructs a\ncoverage-verified roadmap in semi-static environments. By partitioning the\nobstacle configuration space and solving for feasible paths within each\npartition, COVER systematically verifies feasibility of the roadmap in each\npartition and guarantees fixed-time motion planning queries within the verified\nregions. We validate COVER with a 7-DOF simulated Panda robot performing table\nand shelf tasks, demonstrating that COVER achieves broader coverage with higher\nquery success rates than prior works.", "AI": {"tldr": "COVER\u662f\u4e00\u4e2a\u7528\u4e8e\u534a\u9759\u6001\u73af\u5883\u8fd0\u52a8\u89c4\u5212\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u8986\u76d6\u9a8c\u8bc1\u7684\u8def\u6807\u56fe\uff0c\u5728\u56fa\u5b9a\u65f6\u95f4\u9884\u7b97\u5185\u4fdd\u8bc1\u67e5\u8be2\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u534a\u9759\u6001\u73af\u5883\u4e2d\u8fd0\u52a8\u89c4\u5212\u67e5\u8be2\u9700\u8981\u5728\u56fa\u5b9a\u65f6\u95f4\u5185\u5b8c\u6210\u7684\u95ee\u9898\uff0c\u5229\u7528\u73af\u5883\u7684\u7ed3\u6784\u5316\u53ef\u53d8\u6027\u63d0\u4f9b\u6bd4\u901a\u7528\u8fd0\u52a8\u89c4\u5212\u66f4\u5f3a\u7684\u4fdd\u8bc1\u3002", "method": "\u901a\u8fc7\u5206\u5272\u969c\u788d\u7269\u914d\u7f6e\u7a7a\u95f4\u5e76\u5728\u6bcf\u4e2a\u5206\u533a\u5185\u6c42\u89e3\u53ef\u884c\u8def\u5f84\uff0c\u7cfb\u7edf\u6027\u5730\u9a8c\u8bc1\u8def\u6807\u56fe\u5728\u6bcf\u4e2a\u5206\u533a\u7684\u53ef\u884c\u6027\u3002", "result": "\u57287\u81ea\u7531\u5ea6Panda\u673a\u5668\u4eba\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0cCOVER\u6bd4\u73b0\u6709\u65b9\u6cd5\u83b7\u5f97\u66f4\u5e7f\u6cdb\u7684\u8986\u76d6\u8303\u56f4\u548c\u66f4\u9ad8\u7684\u67e5\u8be2\u6210\u529f\u7387\u3002", "conclusion": "COVER\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u534a\u9759\u6001\u73af\u5883\u4e2d\u7684\u8fd0\u52a8\u89c4\u5212\u95ee\u9898\uff0c\u63d0\u4f9b\u56fa\u5b9a\u65f6\u95f4\u4fdd\u8bc1\u548c\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.03859", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03859", "abs": "https://arxiv.org/abs/2510.03859", "authors": ["Raghav Sharma", "Manan Mehta"], "title": "Adaptive and Explainable AI Agents for Anomaly Detection in Critical IoT Infrastructure using LLM-Enhanced Contextual Reasoning", "comment": "22 pages", "summary": "Ensuring that critical IoT systems function safely and smoothly depends a lot\non finding anomalies quickly. As more complex systems, like smart healthcare,\nenergy grids and industrial automation, appear, it is easier to see the\nshortcomings of older methods of detection. Monitoring failures usually happen\nin dynamic, high dimensional situations, especially when data is incomplete,\nmessy or always evolving. Such limits point out the requirement for adaptive,\nintelligent systems that always improve and think. LLMs are now capable of\nsignificantly changing how context is understood and semantic inference is done\nacross all types of data. This proposal suggests using an LLM supported\ncontextual reasoning method along with XAI agents to improve how anomalies are\nfound in significant IoT environments. To discover hidden patterns and notice\ninconsistencies in data streams, it uses attention methods, avoids dealing with\ndetails from every time step and uses memory buffers with meaning. Because no\ncode AI stresses transparency and interpretability, people can check and accept\nthe AI's decisions, helping ensure AI follows company policies. The two\narchitectures are put together in a test that compares the results of the\ntraditional model with those of the suggested LLM enhanced model. Important\nmeasures to check are the accuracy of detection, how much inaccurate\ninformation is included in the results, how clearly the findings can be read\nand how fast the system responds under different test situations. The\nmetaheuristic is tested in simulations of real world smart grid and healthcare\ncontexts to check its adaptability and reliability. From the study, we see that\nthe new approach performs much better than most existing models in both\naccuracy and interpretation, so it could be a good fit for future anomaly\ndetection tasks in IoT", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u548cXAI\u4ee3\u7406\u7684\u667a\u80fd\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u5173\u952eIoT\u7cfb\u7edf\uff0c\u5728\u52a8\u6001\u9ad8\u7ef4\u73af\u5883\u4e2d\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5728\u590d\u6742IoT\u7cfb\u7edf\uff08\u5982\u667a\u80fd\u533b\u7597\u3001\u80fd\u6e90\u7535\u7f51\uff09\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u4e0d\u5b8c\u6574\u3001\u6df7\u4e71\u6216\u52a8\u6001\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u81ea\u9002\u5e94\u667a\u80fd\u7cfb\u7edf\u6765\u6301\u7eed\u6539\u8fdb\u3002", "method": "\u4f7f\u7528LLM\u652f\u6301\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u65b9\u6cd5\u4e0eXAI\u4ee3\u7406\u76f8\u7ed3\u5408\uff0c\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u53d1\u73b0\u9690\u85cf\u6a21\u5f0f\uff0c\u907f\u514d\u5904\u7406\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u7ec6\u8282\uff0c\u4f7f\u7528\u8bed\u4e49\u8bb0\u5fc6\u7f13\u51b2\u533a\uff0c\u5f3a\u8c03\u900f\u660e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728\u667a\u80fd\u7535\u7f51\u548c\u533b\u7597\u573a\u666f\u7684\u6a21\u62df\u6d4b\u8bd5\u4e2d\uff0c\u65b0\u65b9\u6cd5\u5728\u68c0\u6d4b\u51c6\u786e\u7387\u3001\u8bef\u62a5\u7387\u3001\u53ef\u8bfb\u6027\u548c\u54cd\u5e94\u901f\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\u3002", "conclusion": "LLM\u589e\u5f3a\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u5408\u672a\u6765IoT\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u3002"}}
{"id": "2510.04591", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.04591", "abs": "https://arxiv.org/abs/2510.04591", "authors": ["Junsei Ito", "Yasuaki Wasa"], "title": "Data-Driven Adaptive PID Control Based on Physics-Informed Neural Networks", "comment": "This work has been submitted to the IEEE Transactions on Control\n  Systems Technology for possible publication", "summary": "This article proposes a data-driven PID controller design based on the\nprinciple of adaptive gain optimization, leveraging Physics-Informed Neural\nNetworks (PINNs) generated for predictive modeling purposes. The proposed\ncontrol design method utilizes gradients of the PID gain optimization, achieved\nthrough the automatic differentiation of PINNs, to apply model predictive\ncontrol using a cost function based on tracking error and control inputs. By\noptimizing PINNs-based PID gains, the method achieves adaptive gain tuning that\nensures stability while accounting for system nonlinearities. The proposed\nmethod features a systematic framework for integrating PINNs-based models of\ndynamical control systems into closed-loop control systems, enabling direct\napplication to PID control design. A series of numerical experiments is\nconducted to demonstrate the effectiveness of the proposed method from the\ncontrol perspectives based on both time and frequency domains.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u9002\u5e94\u589e\u76ca\u4f18\u5316\u7684\u6570\u636e\u9a71\u52a8PID\u63a7\u5236\u5668\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5229\u7528\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc(PINNs)\u8fdb\u884c\u9884\u6d4b\u5efa\u6a21\uff0c\u901a\u8fc7\u81ea\u52a8\u5fae\u5206\u4f18\u5316PID\u589e\u76ca\uff0c\u5b9e\u73b0\u8003\u8651\u7cfb\u7edf\u975e\u7ebf\u6027\u7684\u81ea\u9002\u5e94\u8c03\u53c2\u3002", "motivation": "\u4f20\u7edfPID\u63a7\u5236\u5668\u5728\u5904\u7406\u975e\u7ebf\u6027\u7cfb\u7edf\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u81ea\u9002\u5e94\u8c03\u6574\u589e\u76ca\u5e76\u786e\u4fdd\u7a33\u5b9a\u6027\u7684\u6570\u636e\u9a71\u52a8\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528PINNs\u751f\u6210\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u52a8\u5fae\u5206\u8ba1\u7b97PID\u589e\u76ca\u4f18\u5316\u7684\u68af\u5ea6\uff0c\u57fa\u4e8e\u8ddf\u8e2a\u8bef\u5dee\u548c\u63a7\u5236\u8f93\u5165\u7684\u6210\u672c\u51fd\u6570\u5e94\u7528\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u65f6\u57df\u548c\u9891\u57df\u63a7\u5236\u6027\u80fd\u4e0a\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5b9e\u73b0\u7a33\u5b9a\u7684\u81ea\u9002\u5e94\u589e\u76ca\u8c03\u8282\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5c06PINNs\u6a21\u578b\u96c6\u6210\u5230\u95ed\u73af\u63a7\u5236\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\uff0c\u53ef\u76f4\u63a5\u5e94\u7528\u4e8ePID\u63a7\u5236\u8bbe\u8ba1\uff0c\u6709\u6548\u5904\u7406\u975e\u7ebf\u6027\u7cfb\u7edf\u63a7\u5236\u95ee\u9898\u3002"}}
{"id": "2510.03885", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03885", "abs": "https://arxiv.org/abs/2510.03885", "authors": ["Sunghwan Kim", "Woojeh Chung", "Zhirui Dai", "Dwait Bhatt", "Arth Shukla", "Hao Su", "Yulun Tian", "Nikolay Atanasov"], "title": "Seeing the Bigger Picture: 3D Latent Mapping for Mobile Manipulation Policy Learning", "comment": "Project website can be found at\n  https://existentialrobotics.org/sbp_page/", "summary": "In this paper, we demonstrate that mobile manipulation policies utilizing a\n3D latent map achieve stronger spatial and temporal reasoning than policies\nrelying solely on images. We introduce Seeing the Bigger Picture (SBP), an\nend-to-end policy learning approach that operates directly on a 3D map of\nlatent features. In SBP, the map extends perception beyond the robot's current\nfield of view and aggregates observations over long horizons. Our mapping\napproach incrementally fuses multiview observations into a grid of\nscene-specific latent features. A pre-trained, scene-agnostic decoder\nreconstructs target embeddings from these features and enables online\noptimization of the map features during task execution. A policy, trainable\nwith behavior cloning or reinforcement learning, treats the latent map as a\nstate variable and uses global context from the map obtained via a 3D feature\naggregator. We evaluate SBP on scene-level mobile manipulation and sequential\ntabletop manipulation tasks. Our experiments demonstrate that SBP (i) reasons\nglobally over the scene, (ii) leverages the map as long-horizon memory, and\n(iii) outperforms image-based policies in both in-distribution and novel\nscenes, e.g., improving the success rate by 25% for the sequential manipulation\ntask.", "AI": {"tldr": "SBP\u662f\u4e00\u79cd\u5229\u75283D\u6f5c\u5728\u5730\u56fe\u7684\u79fb\u52a8\u64cd\u4f5c\u7b56\u7565\uff0c\u76f8\u6bd4\u4ec5\u4f9d\u8d56\u56fe\u50cf\u7684\u7b56\u7565\u5177\u6709\u66f4\u5f3a\u7684\u65f6\u7a7a\u63a8\u7406\u80fd\u529b\uff0c\u5728\u573a\u666f\u7ea7\u79fb\u52a8\u64cd\u4f5c\u548c\u987a\u5e8f\u684c\u9762\u64cd\u4f5c\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u79fb\u52a8\u64cd\u4f5c\u7b56\u7565\u4e3b\u8981\u4f9d\u8d56\u56fe\u50cf\u8f93\u5165\uff0c\u7f3a\u4e4f\u5168\u5c40\u573a\u666f\u7406\u89e3\u548c\u957f\u671f\u8bb0\u5fc6\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u7aef\u5230\u7aef\u7b56\u7565\u5b66\u4e60\u65b9\u6cd5SBP\uff0c\u6784\u5efa3D\u6f5c\u5728\u7279\u5f81\u5730\u56fe\uff0c\u901a\u8fc7\u591a\u89c6\u89d2\u89c2\u6d4b\u878d\u5408\u548c\u5728\u7ebf\u4f18\u5316\uff0c\u4f7f\u75283D\u7279\u5f81\u805a\u5408\u5668\u83b7\u53d6\u5168\u5c40\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "result": "SBP\u5728\u573a\u666f\u7ea7\u79fb\u52a8\u64cd\u4f5c\u548c\u987a\u5e8f\u684c\u9762\u64cd\u4f5c\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u56fe\u50cf\u7684\u7b56\u7565\uff0c\u5728\u987a\u5e8f\u64cd\u4f5c\u4efb\u52a1\u4e2d\u6210\u529f\u7387\u63d0\u9ad8\u4e8625%\uff0c\u5728\u5206\u5e03\u5185\u548c\u672a\u89c1\u573a\u666f\u4e2d\u5747\u8868\u73b0\u826f\u597d\u3002", "conclusion": "3D\u6f5c\u5728\u5730\u56fe\u4e3a\u79fb\u52a8\u64cd\u4f5c\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5168\u5c40\u573a\u666f\u7406\u89e3\u548c\u957f\u671f\u8bb0\u5fc6\u673a\u5236\uff0c\u662f\u5b9e\u73b0\u590d\u6742\u4efb\u52a1\u7684\u5173\u952e\u6280\u672f\u3002"}}
{"id": "2510.03863", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.03863", "abs": "https://arxiv.org/abs/2510.03863", "authors": ["Arina Kharlamova", "Bowei He", "Chen Ma", "Xue Liu"], "title": "Spatial CAPTCHA: Generatively Benchmarking Spatial Reasoning for Human-Machine Differentiation", "comment": "Submitted to ICLR 2026", "summary": "Online services rely on CAPTCHAs as a first line of defense against automated\nabuse, yet recent advances in multi-modal large language models (MLLMs) have\neroded the effectiveness of conventional designs that focus on text recognition\nor 2D image understanding. To address this challenge, we present Spatial\nCAPTCHA, a novel human-verification framework that leverages fundamental\ndifferences in spatial reasoning between humans and MLLMs. Unlike existing\nCAPTCHAs which rely on low-level perception tasks that are vulnerable to modern\nAI, Spatial CAPTCHA generates dynamic questions requiring geometric reasoning,\nperspective-taking, occlusion handling, and mental rotation. These skills are\nintuitive for humans but difficult for state-of-the-art (SOTA) AI systems. The\nsystem employs a procedural generation pipeline with constraint-based\ndifficulty control, automated correctness verification, and human-in-the-loop\nvalidation to ensure scalability, robustness, and adaptability. Evaluation on a\ncorresponding benchmark, Spatial-CAPTCHA-Bench, demonstrates that humans vastly\noutperform 10 state-of-the-art MLLMs, with the best model achieving only 31.0%\nPass@1 accuracy. Furthermore, we compare Spatial CAPTCHA with Google reCAPTCHA,\nwhich confirms its effectiveness as both a security mechanism and a diagnostic\ntool for spatial reasoning in AI.", "AI": {"tldr": "\u63d0\u51fa\u4e86Spatial CAPTCHA\uff0c\u4e00\u79cd\u57fa\u4e8e\u7a7a\u95f4\u63a8\u7406\u7684\u65b0\u578b\u4eba\u673a\u9a8c\u8bc1\u6846\u67b6\uff0c\u5229\u7528\u4eba\u7c7b\u4e0e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u6839\u672c\u5dee\u5f02\u6765\u9632\u5fa1\u81ea\u52a8\u5316\u653b\u51fb\u3002", "motivation": "\u4f20\u7edfCAPTCHA\u4f9d\u8d56\u6587\u672c\u8bc6\u522b\u62162D\u56fe\u50cf\u7406\u89e3\uff0c\u4f46\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\u5df2\u524a\u5f31\u5176\u6709\u6548\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5b89\u5168\u7684\u4eba\u673a\u9a8c\u8bc1\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u7a0b\u5e8f\u5316\u751f\u6210\u7ba1\u9053\uff0c\u521b\u5efa\u9700\u8981\u51e0\u4f55\u63a8\u7406\u3001\u89c6\u89d2\u8f6c\u6362\u3001\u906e\u6321\u5904\u7406\u548c\u5fc3\u7406\u65cb\u8f6c\u7684\u52a8\u6001\u95ee\u9898\uff0c\u7ed3\u5408\u57fa\u4e8e\u7ea6\u675f\u7684\u96be\u5ea6\u63a7\u5236\u3001\u81ea\u52a8\u6b63\u786e\u6027\u9a8c\u8bc1\u548c\u4eba\u5728\u73af\u9a8c\u8bc1\u3002", "result": "\u5728Spatial-CAPTCHA-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4eba\u7c7b\u8868\u73b0\u8fdc\u8d8510\u4e2a\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6700\u4f73\u6a21\u578b\u4ec5\u8fbe\u523031.0%\u7684Pass@1\u51c6\u786e\u7387\uff0c\u4e14\u4f18\u4e8eGoogle reCAPTCHA\u3002", "conclusion": "Spatial CAPTCHA\u4e0d\u4ec5\u662f\u6709\u6548\u7684\u5b89\u5168\u673a\u5236\uff0c\u4e5f\u662f\u8bc4\u4f30AI\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u4e3a\u5e94\u5bf9\u73b0\u4ee3AI\u5a01\u80c1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2510.04615", "categories": ["eess.SY", "cs.AI", "cs.SY", "I.2.1"], "pdf": "https://arxiv.org/pdf/2510.04615", "abs": "https://arxiv.org/abs/2510.04615", "authors": ["X. Tao", "P. Chen", "M. Tsami", "F. Khayati", "M. Eckert"], "title": "Design Process of a Self Adaptive Smart Serious Games Ecosystem", "comment": null, "summary": "This paper outlines the design vision and planned evolution of Blexer v3, a\nmodular and AI-driven rehabilitation ecosystem based on serious games. Building\non insights from previous versions of the system, we propose a new architecture\nthat aims to integrate multimodal sensing, real-time reasoning, and intelligent\ncontrol. The envisioned system will include distinct modules for data\ncollection, user state inference, and gameplay adaptation. Key features such as\ndynamic difficulty adjustment (DDA) and procedural content generation (PCG) are\nalso considered to support personalized interventions. We present the complete\nconceptual framework of Blexer v3, which defines the modular structure and data\nflow of the system. This serves as the foundation for the next phase: the\ndevelopment of a functional prototype and its integration into clinical\nrehabilitation scenarios.", "AI": {"tldr": "Blexer v3\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e25\u8083\u6e38\u620f\u7684\u6a21\u5757\u5316AI\u9a71\u52a8\u5eb7\u590d\u751f\u6001\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86\u96c6\u6210\u591a\u6a21\u6001\u611f\u77e5\u3001\u5b9e\u65f6\u63a8\u7406\u548c\u667a\u80fd\u63a7\u5236\u7684\u65b0\u67b6\u6784\uff0c\u5305\u542b\u6570\u636e\u6536\u96c6\u3001\u7528\u6237\u72b6\u6001\u63a8\u65ad\u548c\u6e38\u620f\u9002\u5e94\u7b49\u6a21\u5757\u3002", "motivation": "\u57fa\u4e8e\u5148\u524d\u7248\u672c\u7684\u7ecf\u9a8c\uff0c\u8bbe\u8ba1\u66f4\u5148\u8fdb\u7684\u5eb7\u590d\u7cfb\u7edf\uff0c\u901a\u8fc7AI\u6280\u672f\u5b9e\u73b0\u4e2a\u6027\u5316\u5e72\u9884\uff0c\u63d0\u5347\u5eb7\u590d\u6548\u679c\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u67b6\u6784\uff0c\u6574\u5408\u591a\u6a21\u6001\u611f\u77e5\u3001\u5b9e\u65f6\u63a8\u7406\u548c\u667a\u80fd\u63a7\u5236\uff0c\u5305\u542b\u52a8\u6001\u96be\u5ea6\u8c03\u6574\u548c\u7a0b\u5e8f\u5316\u5185\u5bb9\u751f\u6210\u7b49\u5173\u952e\u529f\u80fd\u3002", "result": "\u63d0\u51fa\u4e86\u5b8c\u6574\u7684Blexer v3\u6982\u5ff5\u6846\u67b6\uff0c\u5b9a\u4e49\u4e86\u7cfb\u7edf\u7684\u6a21\u5757\u5316\u7ed3\u6784\u548c\u6570\u636e\u6d41\uff0c\u4e3a\u529f\u80fd\u539f\u578b\u5f00\u53d1\u548c\u4e34\u5e8a\u96c6\u6210\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4e0b\u4e00\u9636\u6bb5\u5f00\u53d1\u529f\u80fd\u539f\u578b\u5e76\u5c06\u5176\u96c6\u6210\u5230\u4e34\u5e8a\u5eb7\u590d\u573a\u666f\u4e2d\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u6709\u671b\u63a8\u52a8AI\u9a71\u52a8\u7684\u5eb7\u590d\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2510.03895", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.03895", "abs": "https://arxiv.org/abs/2510.03895", "authors": ["Zheng Huang", "Mingyu Liu", "Xiaoyi Lin", "Muzhi Zhu", "Canyu Zhao", "Zongze Du", "Xiaoman Li", "Yiduo Jia", "Hao Zhong", "Hao Chen", "Chunhua Shen"], "title": "NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation", "comment": null, "summary": "Vision-Language-Action (VLA) models represent a pivotal advance in embodied\nintelligence, yet they confront critical barriers to real-world deployment,\nmost notably catastrophic forgetting. This issue stems from their overreliance\non continuous action sequences or action chunks, which inadvertently create\nisolated data silos that disrupt knowledge retention across tasks. To tackle\nthese challenges, we propose the Narrowing of Trajectory VLA (NoTVLA)\nframework: a novel approach that narrows its focus to sparse trajectories,\nthereby avoiding the catastrophic forgetting associated with dense trajectory\nfine-tuning. A key innovation of NoTVLA lies in its trajectory planning\nstrategy: instead of centering on the target object's trajectory, it leverages\ntemporal compression and spatial reasoning pruning specifically for the robot\nend effector's trajectory. Furthermore, training is conducted using these\nsparse trajectories rather than dense action trajectories, an optimization that\ndelivers remarkable practical advantages with better performance in zero-shot.\nIn multi-task evaluation scenarios, NoTVLA achieves superior performance and\ngeneralization compared to pi0 while operating under two critical constraints:\nit uses over an order of magnitude less computing power than pi0 and requires\nno wrist-mounted camera. This design ensures that NoTVLA's operational accuracy\nclosely approximates that of single-task expert models. Crucially, it also\npreserves the model's inherent language capabilities, enabling zero-shot\ngeneralization in specific scenarios, supporting unified model deployment\nacross multiple robot platforms, and fostering a degree of generalization even\nwhen perceiving tasks from novel perspectives.", "AI": {"tldr": "\u63d0\u51fa\u4e86NoTVLA\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u7126\u7a00\u758f\u8f68\u8ff9\u800c\u975e\u5bc6\u96c6\u52a8\u4f5c\u5e8f\u5217\u6765\u89e3\u51b3VLA\u6a21\u578b\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u8bed\u8a00\u80fd\u529b\u7684\u540c\u65f6\u5b9e\u73b0\u591a\u4efb\u52a1\u6cdb\u5316\u3002", "motivation": "\u89e3\u51b3VLA\u6a21\u578b\u5728\u73b0\u5b9e\u90e8\u7f72\u4e2d\u9762\u4e34\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u8be5\u95ee\u9898\u6e90\u4e8e\u5bf9\u8fde\u7eed\u52a8\u4f5c\u5e8f\u5217\u7684\u8fc7\u5ea6\u4f9d\u8d56\u5bfc\u81f4\u7684\u77e5\u8bc6\u9694\u79bb\u3002", "method": "\u91c7\u7528\u8f68\u8ff9\u89c4\u5212\u7b56\u7565\uff0c\u805a\u7126\u673a\u5668\u4eba\u672b\u7aef\u6267\u884c\u5668\u7684\u7a00\u758f\u8f68\u8ff9\u800c\u975e\u76ee\u6807\u7269\u4f53\u8f68\u8ff9\uff0c\u901a\u8fc7\u65f6\u95f4\u538b\u7f29\u548c\u7a7a\u95f4\u63a8\u7406\u526a\u679d\uff0c\u4f7f\u7528\u7a00\u758f\u8f68\u8ff9\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728\u591a\u4efb\u52a1\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u4e8epi0\uff0c\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u964d\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u65e0\u9700\u8155\u90e8\u6444\u50cf\u5934\uff0c\u64cd\u4f5c\u7cbe\u5ea6\u63a5\u8fd1\u5355\u4efb\u52a1\u4e13\u5bb6\u6a21\u578b\u3002", "conclusion": "NoTVLA\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u8bed\u8a00\u80fd\u529b\uff0c\u652f\u6301\u8de8\u5e73\u53f0\u90e8\u7f72\u548c\u96f6\u6837\u672c\u6cdb\u5316\u3002"}}
{"id": "2510.03886", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03886", "abs": "https://arxiv.org/abs/2510.03886", "authors": ["Seil Kang", "Woojung Han", "Dayun Ju", "Seong Jae Hwang"], "title": "Rare Text Semantics Were Always There in Your Diffusion Transformer", "comment": "Accepted to NeurIPS 2025", "summary": "Starting from flow- and diffusion-based transformers, Multi-modal Diffusion\nTransformers (MM-DiTs) have reshaped text-to-vision generation, gaining acclaim\nfor exceptional visual fidelity. As these models advance, users continually\npush the boundary with imaginative or rare prompts, which advanced models still\nfalter in generating, since their concepts are often too scarce to leave a\nstrong imprint during pre-training. In this paper, we propose a simple yet\neffective intervention that surfaces rare semantics inside MM-DiTs without\nadditional training steps, data, denoising-time optimization, or reliance on\nexternal modules (e.g., large language models). In particular, the\njoint-attention mechanism intrinsic to MM-DiT sequentially updates text\nembeddings alongside image embeddings throughout transformer blocks. We find\nthat by mathematically expanding representational basins around text token\nembeddings via variance scale-up before the joint-attention blocks, rare\nsemantics clearly emerge in MM-DiT's outputs. Furthermore, our results\ngeneralize effectively across text-to-vision tasks, including text-to-image,\ntext-to-video, and text-driven image editing. Our work invites generative\nmodels to reveal the semantics that users intend, once hidden yet ready to\nsurface.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728MM-DiT\u7684\u8054\u5408\u6ce8\u610f\u529b\u673a\u5236\u524d\u6269\u5927\u6587\u672c\u6807\u8bb0\u5d4c\u5165\u7684\u8868\u793a\u7a7a\u95f4\uff0c\u6709\u6548\u63d0\u5347\u6a21\u578b\u5bf9\u7f55\u89c1\u8bed\u4e49\u7684\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u6269\u6563\u53d8\u6362\u5668\u5728\u5904\u7406\u7528\u6237\u63d0\u51fa\u7684\u60f3\u8c61\u529b\u4e30\u5bcc\u6216\u7f55\u89c1\u6982\u5ff5\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u6982\u5ff5\u5728\u9884\u8bad\u7ec3\u4e2d\u7f3a\u4e4f\u8db3\u591f\u7684\u6570\u636e\u652f\u6301\u3002", "method": "\u5728\u8054\u5408\u6ce8\u610f\u529b\u5757\u4e4b\u524d\uff0c\u901a\u8fc7\u6570\u5b66\u65b9\u6cd5\u6269\u5927\u6587\u672c\u6807\u8bb0\u5d4c\u5165\u7684\u8868\u793a\u7a7a\u95f4\uff08\u65b9\u5dee\u653e\u5927\uff09\uff0c\u4f7f\u7f55\u89c1\u8bed\u4e49\u80fd\u591f\u66f4\u6e05\u6670\u5730\u6d6e\u73b0\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u5bf9\u7f55\u89c1\u8bed\u4e49\u7684\u751f\u6210\u8d28\u91cf\uff0c\u5e76\u5728\u6587\u672c\u5230\u56fe\u50cf\u3001\u6587\u672c\u5230\u89c6\u9891\u548c\u6587\u672c\u9a71\u52a8\u56fe\u50cf\u7f16\u8f91\u7b49\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u5e72\u9884\u624b\u6bb5\uff0c\u80fd\u591f\u63ed\u793a\u7528\u6237\u610f\u56fe\u4e2d\u539f\u672c\u9690\u85cf\u7684\u8bed\u4e49\u5185\u5bb9\u3002"}}
{"id": "2510.04616", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.04616", "abs": "https://arxiv.org/abs/2510.04616", "authors": ["Bohan Cui", "Yu Chen", "Alessandro Giua", "Xiang Yin"], "title": "On Prediction-Based Properties of Discrete-Event Systems: Notions, Applications and Supervisor Synthesis", "comment": null, "summary": "In this work, we investigate the problem of synthesizing property-enforcing\nsupervisors for partially-observed discrete-event systems (DES). Unlike most\nexisting approaches, where the enforced property depends solely on the executed\nbehavior of the system, here we consider a more challenging scenario in which\nthe property relies on predicted future behaviors that have not yet occurred.\nThis problem arises naturally in applications involving future information,\nsuch as active prediction or intention protection. To formalize the problem, we\nintroduce the notion of prediction-based properties, a new class of\nobservational properties tied to the system's future information. We\ndemonstrate that this notion is very generic and can model various practical\nproperties, including predictability in fault prognosis and pre-opacity in\nintention security. We then present an effective approach for synthesizing\nsupervisors that enforce prediction-based properties. Our method relies on a\nnovel information structure that addresses the fundamental challenge arising\nfrom the dependency between current predictions and the control policy. The key\nidea is to first borrow information from future instants and then ensure\ninformation consistency. This reduces the supervisor synthesis problem to a\nsafety game in the information space. We prove that the proposed algorithm is\nboth sound and complete, and the resulting supervisor is maximally permissive.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u90e8\u5206\u53ef\u89c2\u6d4b\u79bb\u6563\u4e8b\u4ef6\u7cfb\u7edf\u7684\u9884\u6d4b\u5c5e\u6027\u76d1\u7763\u5668\u5408\u6210\u65b9\u6cd5\uff0c\u8be5\u5c5e\u6027\u4f9d\u8d56\u4e8e\u7cfb\u7edf\u672a\u6765\u884c\u4e3a\u9884\u6d4b\u800c\u975e\u4ec5\u5f53\u524d\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7cfb\u7edf\u5df2\u6267\u884c\u884c\u4e3a\u7684\u5c5e\u6027\uff0c\u4f46\u5728\u6d89\u53ca\u672a\u6765\u4fe1\u606f\u7684\u5e94\u7528\u4e2d\uff0c\u9700\u8981\u5904\u7406\u57fa\u4e8e\u9884\u6d4b\u672a\u6765\u884c\u4e3a\u7684\u5c5e\u6027\uff0c\u5982\u4e3b\u52a8\u9884\u6d4b\u6216\u610f\u56fe\u4fdd\u62a4\u3002", "method": "\u5f15\u5165\u9884\u6d4b\u5c5e\u6027\u6982\u5ff5\uff0c\u63d0\u51fa\u57fa\u4e8e\u4fe1\u606f\u7ed3\u6784\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u501f\u7528\u672a\u6765\u4fe1\u606f\u5e76\u786e\u4fdd\u4fe1\u606f\u4e00\u81f4\u6027\uff0c\u5c06\u76d1\u7763\u5668\u5408\u6210\u95ee\u9898\u8f6c\u5316\u4e3a\u4fe1\u606f\u7a7a\u95f4\u7684\u5b89\u5168\u535a\u5f08\u3002", "result": "\u8bc1\u660e\u4e86\u6240\u63d0\u7b97\u6cd5\u7684\u6b63\u786e\u6027\u548c\u5b8c\u5907\u6027\uff0c\u751f\u6210\u7684\u76d1\u7763\u5668\u662f\u6700\u5927\u5141\u8bb8\u7684\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u4f9d\u8d56\u672a\u6765\u4fe1\u606f\u7684\u5c5e\u6027\u6267\u884c\u95ee\u9898\uff0c\u5177\u6709\u901a\u7528\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.03910", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03910", "abs": "https://arxiv.org/abs/2510.03910", "authors": ["Akhil Padmanabha", "Jessie Yuan", "Tanisha Mehta", "Rajat Kumar Jenamani", "Eric Hu", "Victoria de Le\u00f3n", "Anthony Wertz", "Janavi Gupta", "Ben Dodson", "Yunting Yan", "Carmel Majidi", "Tapomayukh Bhattacharjee", "Zackory Erickson"], "title": "WAFFLE: A Wearable Approach to Bite Timing Estimation in Robot-Assisted Feeding", "comment": null, "summary": "Millions of people around the world need assistance with feeding. Robotic\nfeeding systems offer the potential to enhance autonomy and quality of life for\nindividuals with impairments and reduce caregiver workload. However, their\nwidespread adoption has been limited by technical challenges such as estimating\nbite timing, the appropriate moment for the robot to transfer food to a user's\nmouth. In this work, we introduce WAFFLE: Wearable Approach For Feeding with\nLEarned bite timing, a system that accurately predicts bite timing by\nleveraging wearable sensor data to be highly reactive to natural user cues such\nas head movements, chewing, and talking. We train a supervised regression model\non bite timing data from 14 participants and incorporate a user-adjustable\nassertiveness threshold to convert predictions into proceed or stop commands.\nIn a study with 15 participants without motor impairments with the Obi feeding\nrobot, WAFFLE performs statistically on par with or better than baseline\nmethods across measures of feeling of control, robot understanding, and\nworkload, and is preferred by the majority of participants for both individual\nand social dining. We further demonstrate WAFFLE's generalizability in a study\nwith 2 participants with motor impairments in their home environments using a\nKinova 7DOF robot. Our findings support WAFFLE's effectiveness in enabling\nnatural, reactive bite timing that generalizes across users, robot hardware,\nrobot positioning, feeding trajectories, foods, and both individual and social\ndining contexts.", "AI": {"tldr": "WAFFLE\u662f\u4e00\u4e2a\u57fa\u4e8e\u53ef\u7a7f\u6234\u4f20\u611f\u5668\u7684\u5582\u98df\u7cfb\u7edf\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u7528\u6237\u54ac\u5408\u65f6\u673a\uff0c\u63d0\u9ad8\u5582\u98df\u673a\u5668\u4eba\u7684\u53cd\u5e94\u6027\u548c\u81ea\u7136\u6027\u3002", "motivation": "\u89e3\u51b3\u5582\u98df\u673a\u5668\u4eba\u4e2d\u54ac\u5408\u65f6\u673a\u4f30\u8ba1\u7684\u6280\u672f\u6311\u6218\uff0c\u5e2e\u52a9\u884c\u52a8\u4e0d\u4fbf\u4eba\u58eb\u63d0\u9ad8\u81ea\u4e3b\u6027\u548c\u751f\u6d3b\u8d28\u91cf\uff0c\u51cf\u8f7b\u62a4\u7406\u4eba\u5458\u8d1f\u62c5\u3002", "method": "\u4f7f\u7528\u53ef\u7a7f\u6234\u4f20\u611f\u5668\u6570\u636e\u8bad\u7ec3\u76d1\u7763\u56de\u5f52\u6a21\u578b\uff0c\u9884\u6d4b\u54ac\u5408\u65f6\u673a\uff0c\u5e76\u52a0\u5165\u7528\u6237\u53ef\u8c03\u8282\u7684\u81ea\u4fe1\u5ea6\u9608\u503c\u6765\u63a7\u5236\u673a\u5668\u4eba\u7684\u884c\u52a8\u3002", "result": "\u572815\u540d\u65e0\u969c\u788d\u53c2\u4e0e\u8005\u7814\u7a76\u4e2d\uff0cWAFFLE\u5728\u63a7\u5236\u611f\u3001\u673a\u5668\u4eba\u7406\u89e3\u548c\u5de5\u4f5c\u91cf\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u591a\u6570\u53c2\u4e0e\u8005\u504f\u597d\u8be5\u7cfb\u7edf\u3002\u57282\u540d\u8fd0\u52a8\u969c\u788d\u53c2\u4e0e\u8005\u5bb6\u5ead\u73af\u5883\u4e2d\u4e5f\u9a8c\u8bc1\u4e86\u5176\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "WAFFLE\u80fd\u591f\u5b9e\u73b0\u81ea\u7136\u3001\u53cd\u5e94\u7075\u654f\u7684\u54ac\u5408\u65f6\u673a\u9884\u6d4b\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u7528\u6237\u3001\u673a\u5668\u4eba\u786c\u4ef6\u3001\u73af\u5883\u548c\u7528\u9910\u60c5\u5883\u3002"}}
{"id": "2510.03892", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03892", "abs": "https://arxiv.org/abs/2510.03892", "authors": ["Zahra Atf", "Peter R. Lewis"], "title": "Kantian-Utilitarian XAI: Meta-Explained", "comment": "Accepted for presentation as a poster at the 35th IEEE International\n  Conference on Collaborative Advances in Software and Computing, 2025.\n  Conference\n  website:https://conf.researchr.org/details/cascon-2025/posters-track/1/Kantian-Utilitarian-XAI-Meta-Explained", "summary": "We present a gamified explainable AI (XAI) system for ethically aware\nconsumer decision-making in the coffee domain. Each session comprises six\nrounds with three options per round. Two symbolic engines provide real-time\nreasons: a Kantian module flags rule violations (e.g., child labor,\ndeforestation risk without shade certification, opaque supply chains, unsafe\ndecaf), and a utilitarian module scores options via multi-criteria aggregation\nover normalized attributes (price, carbon, water, transparency, farmer income\nshare, taste/freshness, packaging, convenience). A meta-explainer with a regret\nbound (0.2) highlights Kantian--utilitarian (mis)alignment and switches to a\ndeontically clean, near-parity option when welfare loss is small. We release a\nstructured configuration (attribute schema, certification map, weights, rule\nset), a policy trace for auditability, and an interactive UI.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6e38\u620f\u5316\u7684\u53ef\u89e3\u91caAI\u7cfb\u7edf\uff0c\u7528\u4e8e\u5496\u5561\u6d88\u8d39\u51b3\u7b56\uff0c\u7ed3\u5408\u5eb7\u5fb7\u4e3b\u4e49\u548c\u529f\u5229\u4e3b\u4e49\u4f26\u7406\u6846\u67b6\u63d0\u4f9b\u5b9e\u65f6\u89e3\u91ca\u3002", "motivation": "\u5e2e\u52a9\u6d88\u8d39\u8005\u5728\u5496\u5561\u8d2d\u4e70\u4e2d\u505a\u51fa\u7b26\u5408\u4f26\u7406\u7684\u51b3\u7b56\uff0c\u901a\u8fc7\u7ed3\u5408\u4e0d\u540c\u4f26\u7406\u89c6\u89d2\u63d0\u4f9b\u900f\u660e\u89e3\u91ca\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u516d\u4e2a\u56de\u5408\uff0c\u6bcf\u56de\u5408\u4e09\u4e2a\u9009\u9879\u3002\u5eb7\u5fb7\u6a21\u5757\u68c0\u6d4b\u89c4\u5219\u8fdd\u53cd\uff0c\u529f\u5229\u6a21\u5757\u591a\u6807\u51c6\u8bc4\u5206\uff0c\u5143\u89e3\u91ca\u5668\u5904\u7406\u4f26\u7406\u51b2\u7a81\u3002", "result": "\u5b9e\u73b0\u4e86\u53ef\u5ba1\u8ba1\u7684\u653f\u7b56\u8ffd\u8e2a\u548c\u4ea4\u4e92\u754c\u9762\uff0c\u5f53\u798f\u5229\u635f\u5931\u8f83\u5c0f\u65f6\u80fd\u5207\u6362\u5230\u7b26\u5408\u9053\u4e49\u539f\u5219\u7684\u9009\u9879\u3002", "conclusion": "\u8be5XAI\u7cfb\u7edf\u6210\u529f\u6574\u5408\u4e86\u4e0d\u540c\u4f26\u7406\u6846\u67b6\uff0c\u4e3a\u6d88\u8d39\u8005\u51b3\u7b56\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u6307\u5bfc\u3002"}}
{"id": "2510.04666", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.04666", "abs": "https://arxiv.org/abs/2510.04666", "authors": ["Zhimin Hou", "Jiacheng Hou", "Xiao Chen", "Hamid Sadeghian", "Tianyu Ren", "Sami Haddadin"], "title": "Learning a Shape-adaptive Assist-as-needed Rehabilitation Policy from Therapist-informed Input", "comment": null, "summary": "Therapist-in-the-loop robotic rehabilitation has shown great promise in\nenhancing rehabilitation outcomes by integrating the strengths of therapists\nand robotic systems. However, its broader adoption remains limited due to\ninsufficient safe interaction and limited adaptation capability. This article\nproposes a novel telerobotics-mediated framework that enables therapists to\nintuitively and safely deliver assist-as-needed~(AAN) therapy based on two\nprimary contributions. First, our framework encodes the therapist-informed\ncorrective force into via-points in a latent space, allowing the therapist to\nprovide only minimal assistance while encouraging patient maintaining own\nmotion preferences. Second, a shape-adaptive ANN rehabilitation policy is\nlearned to partially and progressively deform the reference trajectory for\nmovement therapy based on encoded patient motion preferences and\ntherapist-informed via-points. The effectiveness of the proposed shape-adaptive\nAAN strategy was validated on a telerobotic rehabilitation system using two\nrepresentative tasks. The results demonstrate its practicality for remote AAN\ntherapy and its superiority over two state-of-the-art methods in reducing\ncorrective force and improving movement smoothness.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8fdc\u7a0b\u673a\u5668\u4eba\u5eb7\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u8def\u5f84\u70b9\u7f16\u7801\u6cbb\u7597\u5e08\u6307\u5bfc\u7684\u77eb\u6b63\u529b\uff0c\u5e76\u5b66\u4e60\u5f62\u72b6\u81ea\u9002\u5e94\u7684\u8f85\u52a9\u5eb7\u590d\u7b56\u7565\uff0c\u5b9e\u73b0\u66f4\u5b89\u5168\u3001\u66f4\u81ea\u9002\u5e94\u7684\u5eb7\u590d\u6cbb\u7597\u3002", "motivation": "\u5f53\u524d\u6cbb\u7597\u5e08\u53c2\u4e0e\u7684\u673a\u5668\u4eba\u5eb7\u590d\u7cfb\u7edf\u5b58\u5728\u5b89\u5168\u4ea4\u4e92\u4e0d\u8db3\u548c\u9002\u5e94\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "1) \u5c06\u6cbb\u7597\u5e08\u6307\u5bfc\u7684\u77eb\u6b63\u529b\u7f16\u7801\u5230\u6f5c\u5728\u7a7a\u95f4\u7684\u8def\u5f84\u70b9\u4e2d\uff1b2) \u5b66\u4e60\u5f62\u72b6\u81ea\u9002\u5e94\u7684\u8f85\u52a9\u5eb7\u590d\u7b56\u7565\uff0c\u57fa\u4e8e\u60a3\u8005\u8fd0\u52a8\u504f\u597d\u548c\u6cbb\u7597\u5e08\u6307\u5bfc\u7684\u8def\u5f84\u70b9\u90e8\u5206\u6e10\u8fdb\u5730\u53d8\u5f62\u53c2\u8003\u8f68\u8ff9\u3002", "result": "\u5728\u4e24\u4e2a\u4ee3\u8868\u6027\u4efb\u52a1\u4e0a\u7684\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u77eb\u6b63\u529b\u5e76\u63d0\u9ad8\u8fd0\u52a8\u5e73\u6ed1\u5ea6\uff0c\u4f18\u4e8e\u4e24\u79cd\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5f62\u72b6\u81ea\u9002\u5e94\u8f85\u52a9\u5eb7\u590d\u7b56\u7565\u5728\u8fdc\u7a0b\u5eb7\u590d\u4e2d\u5177\u6709\u5b9e\u7528\u6027\uff0c\u4e3a\u6cbb\u7597\u5e08\u63d0\u4f9b\u66f4\u76f4\u89c2\u3001\u5b89\u5168\u7684\u5eb7\u590d\u6cbb\u7597\u65b9\u5f0f\u3002"}}
{"id": "2510.03919", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.03919", "abs": "https://arxiv.org/abs/2510.03919", "authors": ["Matthew Lisondra", "Junseo Kim", "Glenn Takashi Shimoda", "Kourosh Zareinia", "Sajad Saeedi"], "title": "TCB-VIO: Tightly-Coupled Focal-Plane Binary-Enhanced Visual Inertial Odometry", "comment": "Accepted at IEEE Robotics and Automation Letters", "summary": "Vision algorithms can be executed directly on the image sensor when\nimplemented on the next-generation sensors known as focal-plane\nsensor-processor arrays (FPSP)s, where every pixel has a processor. FPSPs\ngreatly improve latency, reducing the problems associated with the bottleneck\nof data transfer from a vision sensor to a processor. FPSPs accelerate\nvision-based algorithms such as visual-inertial odometry (VIO). However, VIO\nframeworks suffer from spatial drift due to the vision-based pose estimation,\nwhilst temporal drift arises from the inertial measurements. FPSPs circumvent\nthe spatial drift by operating at a high frame rate to match the high-frequency\noutput of the inertial measurements. In this paper, we present TCB-VIO, a\ntightly-coupled 6 degrees-of-freedom VIO by a Multi-State Constraint Kalman\nFilter (MSCKF), operating at a high frame-rate of 250 FPS and from IMU\nmeasurements obtained at 400 Hz. TCB-VIO outperforms state-of-the-art methods:\nROVIO, VINS-Mono, and ORB-SLAM3.", "AI": {"tldr": "TCB-VIO\u662f\u4e00\u4e2a\u5728\u7126\u5e73\u9762\u4f20\u611f\u5668\u5904\u7406\u5668\u9635\u5217\u4e0a\u8fd0\u884c\u7684\u7d27\u5bc6\u8026\u54086\u81ea\u7531\u5ea6\u89c6\u89c9\u60ef\u6027\u91cc\u7a0b\u8ba1\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u72b6\u6001\u7ea6\u675f\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5b9e\u73b0\uff0c\u5728250FPS\u9ad8\u5e27\u7387\u548c400Hz IMU\u9891\u7387\u4e0b\u8fd0\u884c\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u89c6\u89c9\u60ef\u6027\u91cc\u7a0b\u8ba1\u6846\u67b6\u5b58\u5728\u7a7a\u95f4\u6f02\u79fb\uff08\u89c6\u89c9\u59ff\u6001\u4f30\u8ba1\uff09\u548c\u65f6\u95f4\u6f02\u79fb\uff08\u60ef\u6027\u6d4b\u91cf\uff09\u95ee\u9898\uff0cFPSP\u901a\u8fc7\u9ad8\u5e27\u7387\u8fd0\u884c\u6765\u5339\u914d\u60ef\u6027\u6d4b\u91cf\u7684\u9ad8\u9891\u8f93\u51fa\uff0c\u4ece\u800c\u89c4\u907f\u7a7a\u95f4\u6f02\u79fb\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u591a\u72b6\u6001\u7ea6\u675f\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u7684\u7d27\u5bc6\u8026\u54086\u81ea\u7531\u5ea6VIO\u65b9\u6cd5\uff0c\u5728\u7126\u5e73\u9762\u4f20\u611f\u5668\u5904\u7406\u5668\u9635\u5217\u4e0a\u4ee5250FPS\u9ad8\u5e27\u7387\u8fd0\u884c\uff0cIMU\u6d4b\u91cf\u9891\u7387\u4e3a400Hz\u3002", "result": "TCB-VIO\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff1aROVIO\u3001VINS-Mono\u548cORB-SLAM3\u3002", "conclusion": "\u5728FPSP\u4e0a\u5b9e\u73b0\u9ad8\u5e27\u7387VIO\u7cfb\u7edf\u80fd\u6709\u6548\u51cf\u5c11\u7a7a\u95f4\u6f02\u79fb\u95ee\u9898\uff0cTCB-VIO\u5c55\u793a\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.03969", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03969", "abs": "https://arxiv.org/abs/2510.03969", "authors": ["Chengxiao Wang", "Isha Chaudhary", "Qian Hu", "Weitong Ruan", "Rahul Gupta", "Gagandeep Singh"], "title": "Quantifying Risks in Multi-turn Conversation with Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) can produce catastrophic responses in\nconversational settings that pose serious risks to public safety and security.\nExisting evaluations often fail to fully reveal these vulnerabilities because\nthey rely on fixed attack prompt sequences, lack statistical guarantees, and do\nnot scale to the vast space of multi-turn conversations. In this work, we\npropose QRLLM, a novel, principled Certification framework for Catastrophic\nrisks in multi-turn Conversation for LLMs that bounds the probability of an LLM\ngenerating catastrophic responses under multi-turn conversation distributions\nwith statistical guarantees. We model multi-turn conversations as probability\ndistributions over query sequences, represented by a Markov process on a query\ngraph whose edges encode semantic similarity to capture realistic\nconversational flow, and quantify catastrophic risks using confidence\nintervals. We define several inexpensive and practical distributions: random\nnode, graph path, adaptive with rejection. Our results demonstrate that these\ndistributions can reveal substantial catastrophic risks in frontier models,\nwith certified lower bounds as high as 70\\% for the worst model, highlighting\nthe urgent need for improved safety training strategies in frontier LLMs.", "AI": {"tldr": "QRLLM\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u4ea7\u751f\u707e\u96be\u6027\u54cd\u5e94\u98ce\u9669\u7684\u8ba4\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u5efa\u6a21\u5bf9\u8bdd\u5206\u5e03\uff0c\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\u7684\u98ce\u9669\u8fb9\u754c\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u56e0\u4f9d\u8d56\u56fa\u5b9a\u653b\u51fb\u63d0\u793a\u5e8f\u5217\u3001\u7f3a\u4e4f\u7edf\u8ba1\u4fdd\u8bc1\u4e14\u65e0\u6cd5\u6269\u5c55\u5230\u591a\u8f6e\u5bf9\u8bdd\u7a7a\u95f4\uff0c\u96be\u4ee5\u5145\u5206\u63ed\u793aLLM\u7684\u707e\u96be\u6027\u54cd\u5e94\u6f0f\u6d1e\u3002", "method": "\u5c06\u591a\u8f6e\u5bf9\u8bdd\u5efa\u6a21\u4e3a\u67e5\u8be2\u5e8f\u5217\u7684\u6982\u7387\u5206\u5e03\uff0c\u7528\u67e5\u8be2\u56fe\u7684\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u8868\u793a\u5bf9\u8bdd\u6d41\u7a0b\uff0c\u5b9a\u4e49\u968f\u673a\u8282\u70b9\u3001\u56fe\u8def\u5f84\u3001\u5e26\u62d2\u7edd\u7684\u81ea\u9002\u5e94\u7b49\u5b9e\u7528\u5206\u5e03\u3002", "result": "\u8fd9\u4e9b\u5206\u5e03\u80fd\u663e\u8457\u63ed\u793a\u524d\u6cbf\u6a21\u578b\u7684\u707e\u96be\u6027\u98ce\u9669\uff0c\u6700\u5dee\u6a21\u578b\u7684\u8ba4\u8bc1\u4e0b\u754c\u9ad8\u8fbe70%\uff0c\u8868\u660e\u524d\u6cbfLLM\u9700\u8981\u6539\u8fdb\u5b89\u5168\u8bad\u7ec3\u7b56\u7565\u3002", "conclusion": "QRLLM\u6846\u67b6\u4e3aLLM\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u707e\u96be\u6027\u98ce\u9669\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7684\u8ba4\u8bc1\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5b58\u5728\u7684\u4e25\u91cd\u5b89\u5168\u9690\u60a3\u3002"}}
{"id": "2510.04784", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.04784", "abs": "https://arxiv.org/abs/2510.04784", "authors": ["Christopher A. Orrico", "Hari Prasad Varadarajan", "Matthijs van Berkel", "Lennard Ceelen", "Thomas O. S. J. Bosman", "W. P. M. H. Heemels", "Dinesh Krishnamoorthy"], "title": "MPC strategies for density profile control with pellet fueling in nuclear fusion tokamaks under uncertainty", "comment": "IEEE CDC 2025", "summary": "Control of the density profile based on pellet fueling for the ITER nuclear\nfusion tokamak involves a multi-rate nonlinear system with safety-critical\nconstraints, input delays, and discrete actuators with parametric uncertainty.\nTo address this challenging problem, we propose a multi-stage MPC (msMPC)\napproach to handle uncertainty in the presence of mixed-integer inputs. While\nthe scenario tree of msMPC accounts for uncertainty, it also adds complexity to\nan already computationally intensive mixed-integer MPC (MI-MPC) problem. To\nachieve real-time density profile controller with discrete pellets and\nuncertainty handling, we systematically reduce the problem complexity by (1)\nreducing the identified prediction model size through dynamic mode\ndecomposition with control, (2) applying principal component analysis to reduce\nthe number of scenarios needed to capture the parametric uncertainty in msMPC,\nand (3) utilizing the penalty term homotopy for MPC (PTH-MPC) algorithm to\nreduce the computational burden caused by the presence of mixed-integer inputs.\nWe compare the performance and safety of the msMPC strategy against a nominal\nMI-MPC in plant simulations, demonstrating the first predictive density control\nstrategy with uncertainty handling, viable for real-time pellet fueling in\nITER.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9636\u6bb5\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08msMPC\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406ITER\u6838\u805a\u53d8\u6258\u5361\u9a6c\u514b\u4e2d\u5177\u6709\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u3001\u8f93\u5165\u5ef6\u8fdf\u548c\u79bb\u6563\u6267\u884c\u5668\u7684\u5bc6\u5ea6\u5256\u9762\u63a7\u5236\u95ee\u9898\u3002\u901a\u8fc7\u6a21\u578b\u964d\u9636\u3001\u573a\u666f\u7f29\u51cf\u548c\u8ba1\u7b97\u8d1f\u62c5\u51cf\u8f7b\u7b49\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u5bc6\u5ea6\u5256\u9762\u63a7\u5236\u3002", "motivation": "ITER\u6838\u805a\u53d8\u6258\u5361\u9a6c\u514b\u7684\u5bc6\u5ea6\u5256\u9762\u63a7\u5236\u9762\u4e34\u591a\u901f\u7387\u975e\u7ebf\u6027\u7cfb\u7edf\u3001\u5b89\u5168\u5173\u952e\u7ea6\u675f\u3001\u8f93\u5165\u5ef6\u8fdf\u3001\u79bb\u6563\u6267\u884c\u5668\u548c\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u7b49\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u8fd9\u4e9b\u590d\u6742\u6027\u7684\u5b9e\u65f6\u63a7\u5236\u7b56\u7565\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5MPC\uff08msMPC\uff09\u5904\u7406\u4e0d\u786e\u5b9a\u6027\uff0c\u7ed3\u5408\u4e09\u79cd\u590d\u6742\u5ea6\u964d\u4f4e\u6280\u672f\uff1a1\uff09\u901a\u8fc7\u5e26\u63a7\u5236\u7684\u52a8\u6001\u6a21\u6001\u5206\u89e3\u51cf\u5c0f\u9884\u6d4b\u6a21\u578b\u89c4\u6a21\uff1b2\uff09\u5e94\u7528\u4e3b\u6210\u5206\u5206\u6790\u51cf\u5c11\u573a\u666f\u6570\u91cf\uff1b3\uff09\u4f7f\u7528\u60e9\u7f5a\u9879\u540c\u4f26MPC\u7b97\u6cd5\u51cf\u8f7b\u6df7\u5408\u6574\u6570\u8f93\u5165\u5e26\u6765\u7684\u8ba1\u7b97\u8d1f\u62c5\u3002", "result": "\u5728\u5de5\u5382\u4eff\u771f\u4e2d\uff0cmsMPC\u7b56\u7565\u76f8\u6bd4\u6807\u79f0MI-MPC\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\u548c\u5b89\u5168\u6027\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u5904\u7406\u80fd\u529b\u7684\u9884\u6d4b\u5bc6\u5ea6\u63a7\u5236\u7b56\u7565\uff0c\u9002\u7528\u4e8eITER\u7684\u5b9e\u65f6\u9897\u7c92\u71c3\u6599\u6ce8\u5165\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86ITER\u5bc6\u5ea6\u5256\u9762\u63a7\u5236\u7684\u590d\u6742\u6311\u6218\uff0c\u4e3a\u6838\u805a\u53d8\u88c5\u7f6e\u63d0\u4f9b\u4e86\u9996\u4e2a\u53ef\u884c\u7684\u5b9e\u65f6\u4e0d\u786e\u5b9a\u6027\u5904\u7406\u9884\u6d4b\u63a7\u5236\u7b56\u7565\u3002"}}
{"id": "2510.03948", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.03948", "abs": "https://arxiv.org/abs/2510.03948", "authors": ["Otobong Jerome", "Geesara Prathap Kulathunga", "Devitt Dmitry", "Eugene Murawjow", "Alexandr Klimchik"], "title": "A Real-Time Framework for Intermediate Map Construction and Kinematically Feasible Off-Road Planning Without OSM", "comment": null, "summary": "Off-road environments present unique challenges for autonomous navigation due\nto their complex and unstructured nature. Traditional global path-planning\nmethods, which typically aim to minimize path length and travel time, perform\npoorly on large-scale maps and fail to account for critical factors such as\nreal-time performance, kinematic feasibility, and memory efficiency. This paper\nintroduces a novel global path-planning method specifically designed for\noff-road environments, addressing these essential factors. The method begins by\nconstructing an intermediate map within the pixel coordinate system,\nincorporating geographical features like off-road trails, waterways, restricted\nand passable areas, and trees. The planning problem is then divided into three\nsub-problems: graph-based path planning, kinematic feasibility checking, and\npath smoothing. This approach effectively meets real-time performance\nrequirements while ensuring kinematic feasibility and efficient memory use. The\nmethod was tested in various off-road environments with large-scale maps up to\nseveral square kilometers in size, successfully identifying feasible paths in\nan average of 1.5 seconds and utilizing approximately 1.5GB of memory under\nextreme conditions. The proposed framework is versatile and applicable to a\nwide range of off-road autonomous navigation tasks, including search and rescue\nmissions and agricultural operations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u4e3a\u8d8a\u91ce\u73af\u5883\u8bbe\u8ba1\u7684\u5168\u5c40\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u4e2d\u95f4\u5730\u56fe\u5e76\u5206\u89e3\u4e3a\u4e09\u4e2a\u5b50\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u5b9e\u65f6\u6027\u80fd\u3001\u8fd0\u52a8\u5b66\u53ef\u884c\u6027\u548c\u5185\u5b58\u6548\u7387\u7684\u540c\u65f6\uff0c\u6210\u529f\u5728\u5927\u89c4\u6a21\u5730\u56fe\u4e0a\u89c4\u5212\u53ef\u884c\u8def\u5f84\u3002", "motivation": "\u4f20\u7edf\u5168\u5c40\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u5728\u8d8a\u91ce\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u5904\u7406\u5927\u89c4\u6a21\u5730\u56fe\uff0c\u4e14\u5ffd\u7565\u4e86\u5b9e\u65f6\u6027\u80fd\u3001\u8fd0\u52a8\u5b66\u53ef\u884c\u6027\u548c\u5185\u5b58\u6548\u7387\u7b49\u5173\u952e\u56e0\u7d20\u3002", "method": "\u9996\u5148\u5728\u50cf\u7d20\u5750\u6807\u7cfb\u4e2d\u6784\u5efa\u5305\u542b\u5730\u7406\u7279\u5f81\u7684\u4e2d\u95f4\u5730\u56fe\uff0c\u7136\u540e\u5c06\u89c4\u5212\u95ee\u9898\u5206\u89e3\u4e3a\u4e09\u4e2a\u5b50\u95ee\u9898\uff1a\u57fa\u4e8e\u56fe\u7684\u8def\u5f84\u89c4\u5212\u3001\u8fd0\u52a8\u5b66\u53ef\u884c\u6027\u68c0\u67e5\u548c\u8def\u5f84\u5e73\u6ed1\u3002", "result": "\u5728\u591a\u79cd\u8d8a\u91ce\u73af\u5883\u548c\u5927\u89c4\u6a21\u5730\u56fe\uff08\u8fbe\u6570\u5e73\u65b9\u516c\u91cc\uff09\u4e2d\u6d4b\u8bd5\uff0c\u5e73\u57471.5\u79d2\u627e\u5230\u53ef\u884c\u8def\u5f84\uff0c\u6781\u7aef\u6761\u4ef6\u4e0b\u5185\u5b58\u4f7f\u7528\u7ea61.5GB\u3002", "conclusion": "\u8be5\u6846\u67b6\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u8d8a\u91ce\u81ea\u4e3b\u5bfc\u822a\u4efb\u52a1\uff0c\u5305\u62ec\u641c\u6551\u4efb\u52a1\u548c\u519c\u4e1a\u4f5c\u4e1a\u3002"}}
{"id": "2510.04009", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04009", "abs": "https://arxiv.org/abs/2510.04009", "authors": ["Zicong He", "Boxuan Zhang", "Weihao Liu", "Ruixiang Tang", "Lu Cheng"], "title": "What Shapes a Creative Machine Mind? Comprehensively Benchmarking Creativity in Foundation Models", "comment": "22 pages", "summary": "The meteoric rise of foundation models (FMs) has expanded their capabilities\nfar beyond conventional tasks. Creativity, long regarded as a hallmark of human\nintelligence and a driver of innovation, is now increasingly recognized as a\ncritical dimension of machine intelligence in the era of generative FMs,\ncomplementing traditional measures of accuracy. However, existing evaluation\nframeworks for creativity remain fragmented, relying on ad hoc metrics not\nfirmly grounded in established theories. To address this gap, we introduce\nC^2-Eval, a holistic benchmark for unified assessment of creativity in FMs.\nC^2-Eval distinguishes between two complementary forms of creativity:\nconvergent creativity, where tasks admit constrained solutions (e.g., code\ngeneration), and divergent creativity, where tasks are open-ended (e.g.,\nstorytelling). It evaluates both dimensions using fine-grained criteria derived\nfrom social-science theory, focusing on Usefulness, Originality, and Surprise\n(U-O-S). Through extensive experiments on leading proprietary and open-source\nmodels, we analyze trade-offs in their creative capabilities. Our results\nhighlight both the strengths and challenges of current FMs in pursuing a\ncreative machine mind, showing that C^2-Eval is an effective lens for examining\nthe evolving landscape of creative AI.", "AI": {"tldr": "\u63d0\u51fa\u4e86C^2-Eval\u57fa\u51c6\uff0c\u7528\u4e8e\u7edf\u4e00\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u7684\u521b\u9020\u529b\uff0c\u533a\u5206\u6536\u655b\u6027\u521b\u9020\u529b\u548c\u53d1\u6563\u6027\u521b\u9020\u529b\uff0c\u57fa\u4e8e\u6709\u7528\u6027\u3001\u539f\u521b\u6027\u548c\u60ca\u559c\u6027\u4e09\u4e2a\u6807\u51c6\u3002", "motivation": "\u73b0\u6709\u521b\u9020\u529b\u8bc4\u4f30\u6846\u67b6\u788e\u7247\u5316\uff0c\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u521b\u9020\u529b\u8868\u73b0\u3002", "method": "\u5f15\u5165C^2-Eval\u57fa\u51c6\uff0c\u533a\u5206\u6536\u655b\u6027\u521b\u9020\u529b\uff08\u6709\u7ea6\u675f\u89e3\uff09\u548c\u53d1\u6563\u6027\u521b\u9020\u529b\uff08\u5f00\u653e\u5f0f\u4efb\u52a1\uff09\uff0c\u4f7f\u7528\u57fa\u4e8e\u793e\u4f1a\u79d1\u5b66\u7406\u8bba\u7684U-O-S\u6807\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u5bf9\u9886\u5148\u4e13\u6709\u548c\u5f00\u6e90\u6a21\u578b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u5206\u6790\u4e86\u5b83\u4eec\u5728\u521b\u9020\u529b\u80fd\u529b\u4e0a\u7684\u6743\u8861\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u57fa\u7840\u6a21\u578b\u5728\u8ffd\u6c42\u521b\u9020\u6027\u673a\u5668\u667a\u80fd\u65b9\u9762\u7684\u4f18\u52bf\u548c\u6311\u6218\u3002", "conclusion": "C^2-Eval\u662f\u68c0\u9a8c\u521b\u9020\u6027AI\u53d1\u5c55\u683c\u5c40\u7684\u6709\u6548\u5de5\u5177\uff0c\u80fd\u591f\u5168\u9762\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u7684\u521b\u9020\u529b\u8868\u73b0\u3002"}}
{"id": "2510.04807", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.04807", "abs": "https://arxiv.org/abs/2510.04807", "authors": ["Alex Rose", "Naman Aggarwal", "Christopher Jewison", "Jonathan P. How"], "title": "Efficient Probabilistic Planning with Maximum-Coverage Distributionally Robust Backward Reachable Trees", "comment": null, "summary": "This paper presents a new multi-query motion planning algorithm for linear\nGaussian systems with the goal of reaching a Euclidean ball with high\nprobability. We develop a new formulation for ball-shaped ambiguity sets of\nGaussian distributions and leverage it to develop a distributionally robust\nbelief roadmap construction algorithm. This algorithm synthe- sizes robust\ncontrollers which are certified to be safe for maximal size ball-shaped\nambiguity sets of Gaussian distributions. Our algorithm achieves better\ncoverage than the maximal coverage algorithm for planning over Gaussian\ndistributions [1], and we identify mild conditions under which our algorithm\nachieves strictly better coverage. For the special case of no process noise or\nstate constraints, we formally prove that our algorithm achieves maximal\ncoverage. In addition, we present a second multi-query motion planning\nalgorithm for linear Gaussian systems with the goal of reaching a region\nparameterized by the Minkowski sum of an ellipsoid and a Euclidean ball with\nhigh probability. This algorithm plans over ellipsoidal sets of maximal size\nball-shaped ambiguity sets of Gaussian distributions, and provably achieves\nequal or better coverage than the best-known algorithm for planning over\nellipsoidal ambiguity sets of Gaussian distributions [2]. We demonstrate the\nefficacy of both methods in a wide range of conditions via extensive simulation\nexperiments.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u591a\u67e5\u8be2\u8fd0\u52a8\u89c4\u5212\u7b97\u6cd5\uff0c\u7528\u4e8e\u7ebf\u6027\u9ad8\u65af\u7cfb\u7edf\uff0c\u76ee\u6807\u662f\u4ee5\u9ad8\u6982\u7387\u5230\u8fbe\u6b27\u51e0\u91cc\u5f97\u7403\u6216\u692d\u7403\u533a\u57df\uff0c\u901a\u8fc7\u5206\u5e03\u9c81\u68d2\u4fe1\u5ff5\u8def\u7ebf\u56fe\u6784\u5efa\u5b9e\u73b0\u66f4\u597d\u7684\u8986\u76d6\u8303\u56f4\u3002", "motivation": "\u9488\u5bf9\u7ebf\u6027\u9ad8\u65af\u7cfb\u7edf\u7684\u8fd0\u52a8\u89c4\u5212\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u8986\u76d6\u8303\u56f4\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u9ad8\u65af\u5206\u5e03\u6a21\u7cca\u96c6\u7684\u65b0\u7b97\u6cd5\uff0c\u4ee5\u63d0\u4f9b\u66f4\u5f3a\u7684\u5b89\u5168\u4fdd\u8bc1\u548c\u66f4\u597d\u7684\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u4e86\u7403\u72b6\u9ad8\u65af\u5206\u5e03\u6a21\u7cca\u96c6\u7684\u65b0\u516c\u5f0f\uff0c\u5e76\u57fa\u4e8e\u6b64\u6784\u5efa\u5206\u5e03\u9c81\u68d2\u4fe1\u5ff5\u8def\u7ebf\u56fe\u7b97\u6cd5\uff0c\u5408\u6210\u80fd\u591f\u5904\u7406\u6700\u5927\u5c3a\u5bf8\u6a21\u7cca\u96c6\u7684\u9c81\u68d2\u63a7\u5236\u5668\uff1b\u8fd8\u63d0\u51fa\u4e86\u57fa\u4e8e\u692d\u7403\u96c6\u5408\u7684\u591a\u67e5\u8be2\u89c4\u5212\u7b97\u6cd5\u3002", "result": "\u7b97\u6cd5\u5728\u8986\u76d6\u8303\u56f4\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5927\u8986\u76d6\u7b97\u6cd5\uff0c\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e25\u683c\u66f4\u597d\u7684\u8986\u76d6\uff1b\u5728\u65e0\u8fc7\u7a0b\u566a\u58f0\u6216\u72b6\u6001\u7ea6\u675f\u60c5\u51b5\u4e0b\uff0c\u8bc1\u660e\u8fbe\u5230\u6700\u5927\u8986\u76d6\uff1b\u7b2c\u4e8c\u4e2a\u7b97\u6cd5\u5728\u692d\u7403\u6a21\u7cca\u96c6\u89c4\u5212\u4e2d\u8fbe\u5230\u540c\u7b49\u6216\u66f4\u597d\u7684\u8986\u76d6\u3002", "conclusion": "\u4e24\u79cd\u7b97\u6cd5\u5728\u5e7f\u6cdb\u6761\u4ef6\u4e0b\u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u4e3a\u7ebf\u6027\u9ad8\u65af\u7cfb\u7edf\u7684\u9c81\u68d2\u8fd0\u52a8\u89c4\u5212\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u66f4\u597d\u7684\u8986\u76d6\u6027\u80fd\u548c\u5b89\u5168\u4fdd\u8bc1\u3002"}}
{"id": "2510.04041", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04041", "abs": "https://arxiv.org/abs/2510.04041", "authors": ["Ayudh Saxena", "Harsh Shah", "Sandeep Routray", "Rishi Rajesh Shah", "Esha Pahwa"], "title": "SITCOM: Scaling Inference-Time COMpute for VLAs", "comment": "Accepted at the NeurIPS 2025 Workshop on Space in Vision, Language,\n  and Embodied AI (SpaVLE). *Equal contribution", "summary": "Learning robust robotic control policies remains a major challenge due to the\nhigh cost of collecting labeled data, limited generalization to unseen\nenvironments, and difficulties in planning over long horizons. While\nVision-Language-Action (VLA) models offer a promising solution by grounding\nnatural language instructions into single-step control commands, they often\nlack mechanisms for lookahead and struggle with compounding errors in dynamic\ntasks. In this project, we introduce Scaling Inference-Time COMpute for VLAs\n(SITCOM), a framework that augments any pretrained VLA with model-based\nrollouts and reward-based trajectory selection, inspired by Model Predictive\nControl algorithm. SITCOM leverages a learned dynamics model to simulate\nmulti-step action rollouts to select the best candidate plan for real-world\nexecution, transforming one-shot VLAs into robust long-horizon planners. We\ndevelop an efficient transformer-based dynamics model trained on large-scale\nBridgeV2 data and fine-tuned on SIMPLER environments to bridge the Real2Sim\ngap, and score candidate rollouts using rewards from simulator. Through\ncomprehensive evaluation across multiple tasks and settings in the SIMPLER\nenvironment, we demonstrate that SITCOM when combined with a good reward\nfunction can significantly improve task completion rate from 48% to 72% using\ntrained dynamics model.", "AI": {"tldr": "SITCOM\u6846\u67b6\u901a\u8fc7\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u589e\u5f3a\u9884\u8bad\u7ec3\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff0c\u5229\u7528\u5b66\u4e60\u5230\u7684\u52a8\u529b\u5b66\u6a21\u578b\u8fdb\u884c\u591a\u6b65\u52a8\u4f5c\u63a8\u6f14\uff0c\u5c06\u5355\u6b65VLA\u6a21\u578b\u8f6c\u53d8\u4e3a\u9c81\u68d2\u7684\u957f\u65f6\u57df\u89c4\u5212\u5668\u3002", "motivation": "\u89e3\u51b3VLA\u6a21\u578b\u7f3a\u4e4f\u524d\u77bb\u673a\u5236\u3001\u5728\u52a8\u6001\u4efb\u52a1\u4e2d\u5bb9\u6613\u7d2f\u79ef\u8bef\u5dee\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u673a\u5668\u4eba\u63a7\u5236\u4e2d\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u3001\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3001\u957f\u65f6\u57df\u89c4\u5212\u56f0\u96be\u7b49\u6311\u6218\u3002", "method": "\u7ed3\u5408\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u601d\u60f3\uff0c\u4f7f\u7528\u57fa\u4e8eTransformer\u7684\u52a8\u529b\u5b66\u6a21\u578b\u5728\u5927\u89c4\u6a21BridgeV2\u6570\u636e\u4e0a\u8bad\u7ec3\u5e76\u5728SIMPLER\u73af\u5883\u4e2d\u5fae\u8c03\uff0c\u901a\u8fc7\u6a21\u62df\u591a\u6b65\u52a8\u4f5c\u63a8\u6f14\u548c\u57fa\u4e8e\u5956\u52b1\u7684\u8f68\u8ff9\u9009\u62e9\u6765\u4f18\u5316\u51b3\u7b56\u3002", "result": "\u5728SIMPLER\u73af\u5883\u7684\u591a\u4efb\u52a1\u8bc4\u4f30\u4e2d\uff0cSITCOM\u7ed3\u5408\u826f\u597d\u5956\u52b1\u51fd\u6570\u80fd\u5c06\u4efb\u52a1\u5b8c\u6210\u7387\u4ece48%\u663e\u8457\u63d0\u5347\u81f372%\u3002", "conclusion": "SITCOM\u6846\u67b6\u6210\u529f\u5730\u5c06\u5355\u6b65VLA\u6a21\u578b\u8f6c\u5316\u4e3a\u9c81\u68d2\u7684\u957f\u65f6\u57df\u89c4\u5212\u5668\uff0c\u901a\u8fc7\u6a21\u578b\u63a8\u6f14\u548c\u8f68\u8ff9\u9009\u62e9\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u63a7\u5236\u6027\u80fd\u3002"}}
{"id": "2510.04017", "categories": ["cs.AI", "cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.04017", "abs": "https://arxiv.org/abs/2510.04017", "authors": ["Sumanth Varambally", "Marshall Fisher", "Jas Thakker", "Yiwei Chen", "Zhirui Xia", "Yasaman Jafari", "Ruijia Niu", "Manas Jain", "Veeramakali Vignesh Manivannan", "Zachary Novack", "Luyu Han", "Srikar Eranky", "Salva R\u00fchling Cachay", "Taylor Berg-Kirkpatrick", "Duncan Watson-Parris", "Yi-An Ma", "Rose Yu"], "title": "Zephyrus: An Agentic Framework for Weather Science", "comment": null, "summary": "Foundation models for weather science are pre-trained on vast amounts of\nstructured numerical data and outperform traditional weather forecasting\nsystems. However, these models lack language-based reasoning capabilities,\nlimiting their utility in interactive scientific workflows. Large language\nmodels (LLMs) excel at understanding and generating text but cannot reason\nabout high-dimensional meteorological datasets. We bridge this gap by building\na novel agentic framework for weather science. Our framework includes a Python\ncode-based environment for agents (ZephyrusWorld) to interact with weather\ndata, featuring tools like an interface to WeatherBench 2 dataset, geoquerying\nfor geographical masks from natural language, weather forecasting, and climate\nsimulation capabilities. We design Zephyrus, a multi-turn LLM-based weather\nagent that iteratively analyzes weather datasets, observes results, and refines\nits approach through conversational feedback loops. We accompany the agent with\na new benchmark, ZephyrusBench, with a scalable data generation pipeline that\nconstructs diverse question-answer pairs across weather-related tasks, from\nbasic lookups to advanced forecasting, extreme event detection, and\ncounterfactual reasoning. Experiments on this benchmark demonstrate the strong\nperformance of Zephyrus agents over text-only baselines, outperforming them by\nup to 35 percentage points in correctness. However, on harder tasks, Zephyrus\nperforms similarly to text-only baselines, highlighting the challenging nature\nof our benchmark and suggesting promising directions for future work.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u6c14\u8c61\u79d1\u5b66\u4ee3\u7406\u6846\u67b6Zephyrus\uff0c\u901a\u8fc7\u4ee3\u7801\u73af\u5883\u4e0e\u6c14\u8c61\u6570\u636e\u4ea4\u4e92\uff0c\u5728ZephyrusBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bd4\u7eaf\u6587\u672c\u57fa\u7ebf\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe35\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u73b0\u6709\u6c14\u8c61\u57fa\u7840\u6a21\u578b\u7f3a\u4e4f\u8bed\u8a00\u63a8\u7406\u80fd\u529b\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u5904\u7406\u9ad8\u7ef4\u6c14\u8c61\u6570\u636e\uff0c\u9700\u8981\u6865\u63a5\u8fd9\u4e00\u9e3f\u6c9f\u4ee5\u652f\u6301\u4ea4\u4e92\u5f0f\u79d1\u5b66\u5de5\u4f5c\u6d41\u3002", "method": "\u6784\u5efaZephyrusWorld\u4ee3\u7801\u73af\u5883\uff0c\u5305\u542bWeatherBench 2\u6570\u636e\u96c6\u63a5\u53e3\u3001\u5730\u7406\u67e5\u8be2\u3001\u5929\u6c14\u9884\u62a5\u548c\u6c14\u5019\u6a21\u62df\u7b49\u5de5\u5177\uff0c\u8bbe\u8ba1\u591a\u8f6eLLM\u6c14\u8c61\u4ee3\u7406Zephyrus\u8fdb\u884c\u8fed\u4ee3\u5206\u6790\u548c\u53cd\u9988\u3002", "result": "\u5728ZephyrusBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cZephyrus\u4ee3\u7406\u5728\u6b63\u786e\u6027\u4e0a\u6bd4\u7eaf\u6587\u672c\u57fa\u7ebf\u63d0\u5347\u9ad8\u8fbe35\u4e2a\u767e\u5206\u70b9\uff0c\u4f46\u5728\u66f4\u96be\u4efb\u52a1\u4e0a\u8868\u73b0\u76f8\u4f3c\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u7ed3\u5408\u4e86LLM\u7684\u8bed\u8a00\u80fd\u529b\u548c\u6c14\u8c61\u6570\u636e\u4ea4\u4e92\u80fd\u529b\uff0c\u4f46\u66f4\u5177\u6311\u6218\u6027\u7684\u4efb\u52a1\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\uff0c\u4e3a\u672a\u6765\u5de5\u4f5c\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2510.04814", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.04814", "abs": "https://arxiv.org/abs/2510.04814", "authors": ["Isabelle Krauss", "Victor G. Lopez", "Matthias A. M\u00fcller"], "title": "Robust stability of event-triggered nonlinear moving horizon estimation", "comment": null, "summary": "In this work, we propose an event-triggered moving horizon estimation\n(ET-MHE) scheme for the remote state estimation of general nonlinear systems.\nIn the presented method, whenever an event is triggered, a single measurement\nis transmitted and the nonlinear MHE optimization problem is subsequently\nsolved. If no event is triggered, the current state estimate is updated using\nan open-loop prediction based on the system dynamics. Moreover, we introduce a\nnovel event-triggering rule under which we demonstrate robust global\nexponential stability of the ET-MHE scheme, assuming a suitable detectability\ncondition is met. In addition, we show that with the adoption of a varying\nhorizon length, a tighter bound on the estimation error can be achieved.\nFinally, we validate the effectiveness of the proposed method through two\nillustrative examples.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e8b\u4ef6\u89e6\u53d1\u79fb\u52a8\u6c34\u5e73\u4f30\u8ba1(ET-MHE)\u65b9\u6848\uff0c\u7528\u4e8e\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u8fdc\u7a0b\u72b6\u6001\u4f30\u8ba1\uff0c\u901a\u8fc7\u4e8b\u4ef6\u89e6\u53d1\u673a\u5236\u51cf\u5c11\u901a\u4fe1\u91cf\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u65b9\u6848\u7684\u9c81\u68d2\u5168\u5c40\u6307\u6570\u7a33\u5b9a\u6027\u3002", "motivation": "\u4e3a\u4e86\u51cf\u5c11\u8fdc\u7a0b\u72b6\u6001\u4f30\u8ba1\u4e2d\u7684\u901a\u4fe1\u8d1f\u62c5\uff0c\u540c\u65f6\u4fdd\u8bc1\u4f30\u8ba1\u6027\u80fd\uff0c\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u7684\u4e8b\u4ef6\u89e6\u53d1\u4f30\u8ba1\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e8b\u4ef6\u89e6\u53d1\u673a\u5236\uff0c\u4ec5\u5728\u4e8b\u4ef6\u89e6\u53d1\u65f6\u4f20\u8f93\u5355\u4e2a\u6d4b\u91cf\u503c\u5e76\u6c42\u89e3\u975e\u7ebf\u6027MHE\u4f18\u5316\u95ee\u9898\uff1b\u672a\u89e6\u53d1\u65f6\u4f7f\u7528\u7cfb\u7edf\u52a8\u529b\u5b66\u7684\u5f00\u73af\u9884\u6d4b\u66f4\u65b0\u72b6\u6001\u4f30\u8ba1\uff1b\u5f15\u5165\u4e86\u65b0\u9896\u7684\u4e8b\u4ef6\u89e6\u53d1\u89c4\u5219\u548c\u53ef\u53d8\u6c34\u5e73\u957f\u5ea6\u3002", "result": "\u5728\u6ee1\u8db3\u9002\u5f53\u53ef\u68c0\u6d4b\u6027\u6761\u4ef6\u4e0b\uff0c\u8bc1\u660e\u4e86ET-MHE\u65b9\u6848\u7684\u9c81\u68d2\u5168\u5c40\u6307\u6570\u7a33\u5b9a\u6027\uff1b\u91c7\u7528\u53ef\u53d8\u6c34\u5e73\u957f\u5ea6\u53ef\u83b7\u5f97\u66f4\u7d27\u7684\u4f30\u8ba1\u8bef\u5dee\u754c\uff1b\u901a\u8fc7\u4e24\u4e2a\u793a\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684ET-MHE\u65b9\u6848\u80fd\u591f\u6709\u6548\u51cf\u5c11\u901a\u4fe1\u91cf\uff0c\u540c\u65f6\u4fdd\u8bc1\u4f30\u8ba1\u6027\u80fd\uff0c\u4e3a\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u8fdc\u7a0b\u72b6\u6001\u4f30\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04074", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04074", "abs": "https://arxiv.org/abs/2510.04074", "authors": ["Chung-Pang Wang", "Changwei Chen", "Xiao Liang", "Soofiyan Atar", "Florian Richter", "Michael Yip"], "title": "Feedback Matters: Augmenting Autonomous Dissection with Visual and Topological Feedback", "comment": null, "summary": "Autonomous surgical systems must adapt to highly dynamic environments where\ntissue properties and visual cues evolve rapidly. Central to such adaptability\nis feedback: the ability to sense, interpret, and respond to changes during\nexecution. While feedback mechanisms have been explored in surgical robotics,\nranging from tool and tissue tracking to error detection, existing methods\nremain limited in handling the topological and perceptual challenges of tissue\ndissection. In this work, we propose a feedback-enabled framework for\nautonomous tissue dissection that explicitly reasons about topological changes\nfrom endoscopic images after each dissection action. This structured feedback\nguides subsequent actions, enabling the system to localize dissection progress\nand adapt policies online. To improve the reliability of such feedback, we\nintroduce visibility metrics that quantify tissue exposure and formulate\noptimal controller designs that actively manipulate tissue to maximize\nvisibility. Finally, we integrate these feedback mechanisms with both\nplanning-based and learning-based dissection methods, and demonstrate\nexperimentally that they significantly enhance autonomy, reduce errors, and\nimprove robustness in complex surgical scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u81ea\u4e3b\u7ec4\u7ec7\u89e3\u5256\u7684\u53cd\u9988\u9a71\u52a8\u6846\u67b6\uff0c\u901a\u8fc7\u5185\u7aa5\u955c\u56fe\u50cf\u63a8\u7406\u62d3\u6251\u53d8\u5316\uff0c\u7ed3\u5408\u53ef\u89c1\u6027\u5ea6\u91cf\u548c\u6700\u4f18\u63a7\u5236\u5668\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u624b\u672f\u81ea\u4e3b\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u624b\u672f\u673a\u5668\u4eba\u53cd\u9988\u673a\u5236\u5728\u5904\u7406\u7ec4\u7ec7\u89e3\u5256\u7684\u62d3\u6251\u548c\u611f\u77e5\u6311\u6218\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u80fd\u591f\u9002\u5e94\u52a8\u6001\u7ec4\u7ec7\u7279\u6027\u548c\u89c6\u89c9\u7ebf\u7d22\u53d8\u5316\u7684\u81ea\u4e3b\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u53cd\u9988\u9a71\u52a8\u6846\u67b6\uff0c\u901a\u8fc7\u5185\u7aa5\u955c\u56fe\u50cf\u5206\u6790\u89e3\u5256\u52a8\u4f5c\u540e\u7684\u62d3\u6251\u53d8\u5316\uff0c\u5f15\u5165\u53ef\u89c1\u6027\u5ea6\u91cf\u91cf\u5316\u7ec4\u7ec7\u66b4\u9732\uff0c\u5e76\u8bbe\u8ba1\u6700\u4f18\u63a7\u5236\u5668\u4e3b\u52a8\u64cd\u4f5c\u7ec4\u7ec7\u4ee5\u6700\u5927\u5316\u53ef\u89c1\u6027\u3002", "result": "\u5c06\u53cd\u9988\u673a\u5236\u4e0e\u57fa\u4e8e\u89c4\u5212\u548c\u5b66\u4e60\u7684\u89e3\u5256\u65b9\u6cd5\u96c6\u6210\uff0c\u5b9e\u9a8c\u8bc1\u660e\u80fd\u663e\u8457\u589e\u5f3a\u81ea\u4e3b\u6027\u3001\u51cf\u5c11\u9519\u8bef\u5e76\u63d0\u9ad8\u590d\u6742\u624b\u672f\u573a\u666f\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u53cd\u9988\u673a\u5236\u5bf9\u4e8e\u81ea\u4e3b\u624b\u672f\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u53cd\u9988\u548c\u53ef\u89c1\u6027\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7ec4\u7ec7\u89e3\u5256\u4e2d\u7684\u62d3\u6251\u548c\u611f\u77e5\u6311\u6218\u3002"}}
{"id": "2510.04023", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04023", "abs": "https://arxiv.org/abs/2510.04023", "authors": ["Mizanur Rahman", "Amran Bhuiyan", "Mohammed Saidul Islam", "Md Tahmid Rahman Laskar", "Ridwan Mahbub", "Ahmed Masry", "Shafiq Joty", "Enamul Hoque"], "title": "LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and Future Directions", "comment": "Survey paper; 45 data science agents; under review", "summary": "Recent advances in large language models (LLMs) have enabled a new class of\nAI agents that automate multiple stages of the data science workflow by\nintegrating planning, tool use, and multimodal reasoning across text, code,\ntables, and visuals. This survey presents the first comprehensive,\nlifecycle-aligned taxonomy of data science agents, systematically analyzing and\nmapping forty-five systems onto the six stages of the end-to-end data science\nprocess: business understanding and data acquisition, exploratory analysis and\nvisualization, feature engineering, model building and selection,\ninterpretation and explanation, and deployment and monitoring. In addition to\nlifecycle coverage, we annotate each agent along five cross-cutting design\ndimensions: reasoning and planning style, modality integration, tool\norchestration depth, learning and alignment methods, and trust, safety, and\ngovernance mechanisms. Beyond classification, we provide a critical synthesis\nof agent capabilities, highlight strengths and limitations at each stage, and\nreview emerging benchmarks and evaluation practices. Our analysis identifies\nthree key trends: most systems emphasize exploratory analysis, visualization,\nand modeling while neglecting business understanding, deployment, and\nmonitoring; multimodal reasoning and tool orchestration remain unresolved\nchallenges; and over 90% lack explicit trust and safety mechanisms. We conclude\nby outlining open challenges in alignment stability, explainability,\ngovernance, and robust evaluation frameworks, and propose future research\ndirections to guide the development of robust, trustworthy, low-latency,\ntransparent, and broadly accessible data science agents.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5bf9\u6570\u636e\u79d1\u5b66AI\u4ee3\u7406\u8fdb\u884c\u4e86\u9996\u6b21\u5168\u9762\u7684\u751f\u547d\u5468\u671f\u5206\u7c7b\u5206\u6790\uff0c\u7cfb\u7edf\u6027\u5730\u5c0645\u4e2a\u7cfb\u7edf\u6620\u5c04\u5230\u6570\u636e\u79d1\u5b66\u6d41\u7a0b\u7684\u516d\u4e2a\u9636\u6bb5\uff0c\u5e76\u8bc6\u522b\u4e86\u5f53\u524d\u7814\u7a76\u7684\u5173\u952e\u8d8b\u52bf\u548c\u6311\u6218\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u51fa\u73b0\u4e86\u80fd\u591f\u81ea\u52a8\u5316\u6570\u636e\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u7684\u65b0\u578bAI\u4ee3\u7406\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u4ee3\u7406\u7cfb\u7edf\u7684\u7cfb\u7edf\u6027\u5206\u7c7b\u548c\u5206\u6790\uff0c\u9700\u8981\u5efa\u7acb\u7edf\u4e00\u6846\u67b6\u6765\u7406\u89e3\u5176\u80fd\u529b\u548c\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u751f\u547d\u5468\u671f\u5bf9\u9f50\u7684\u5206\u7c7b\u6cd5\uff0c\u5c0645\u4e2a\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u7cfb\u7edf\u6620\u5c04\u5230\u6570\u636e\u79d1\u5b66\u6d41\u7a0b\u7684\u516d\u4e2a\u9636\u6bb5\uff0c\u5e76\u4ece\u4e94\u4e2a\u4ea4\u53c9\u8bbe\u8ba1\u7ef4\u5ea6\u8fdb\u884c\u6807\u6ce8\u5206\u6790\u3002", "result": "\u5206\u6790\u53d1\u73b0\u4e09\u4e2a\u5173\u952e\u8d8b\u52bf\uff1a\u5927\u591a\u6570\u7cfb\u7edf\u5f3a\u8c03\u63a2\u7d22\u6027\u5206\u6790\u548c\u5efa\u6a21\u800c\u5ffd\u89c6\u4e1a\u52a1\u7406\u89e3\u548c\u90e8\u7f72\u76d1\u63a7\uff1b\u591a\u6a21\u6001\u63a8\u7406\u548c\u5de5\u5177\u7f16\u6392\u4ecd\u662f\u672a\u89e3\u51b3\u7684\u6311\u6218\uff1b\u8d85\u8fc790%\u7684\u7cfb\u7edf\u7f3a\u4e4f\u660e\u786e\u7684\u4fe1\u4efb\u548c\u5b89\u5168\u673a\u5236\u3002", "conclusion": "\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u5bf9\u9f50\u7a33\u5b9a\u6027\u3001\u53ef\u89e3\u91ca\u6027\u3001\u6cbb\u7406\u548c\u9c81\u68d2\u8bc4\u4f30\u6846\u67b6\u7b49\u6311\u6218\uff0c\u65e8\u5728\u6307\u5bfc\u5f00\u53d1\u66f4\u53ef\u9760\u3001\u53ef\u4fe1\u3001\u4f4e\u5ef6\u8fdf\u3001\u900f\u660e\u548c\u5e7f\u6cdb\u53ef\u8bbf\u95ee\u7684\u6570\u636e\u79d1\u5b66\u4ee3\u7406\u3002"}}
{"id": "2510.04815", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.04815", "abs": "https://arxiv.org/abs/2510.04815", "authors": ["Lorenzo Zapparoli", "Blazhe Gjorgiev", "Giovanni Sansavini"], "title": "Power Reserve Capacity from Virtual Power Plants with Reliability and Cost Guarantees", "comment": "Submitted to IEEE Transactions on Power Systems", "summary": "The growing penetration of renewable energy sources is expected to drive\nhigher demand for power reserve ancillary services (AS). One solution is to\nincrease the supply by integrating distributed energy resources (DERs) into the\nAS market through virtual power plants (VPPs). Several methods have been\ndeveloped to assess the potential of VPPs to provide services. However, the\nexisting approaches fail to account for AS products' requirements (reliability\nand technical specifications) and to provide accurate cost estimations. Here,\nwe propose a new method to assess VPPs' potential to deliver power reserve\ncapacity products under forecasting uncertainty. First, the maximum feasible\nreserve quantity is determined using a novel formulation of subset simulation\nfor efficient uncertainty quantification. Second, the supply curve is\ncharacterized by considering explicit and opportunity costs. The method is\napplied to a VPP based on a representative Swiss low-voltage network with a\ndiversified DER portfolio. We find that VPPs can reliably offer reserve\nproducts and that opportunity costs drive product pricing. Additionally, we\nshow that the product's requirements strongly impact the reserve capacity\nprovision capability. This approach aims to support VPP managers in developing\nmarket strategies and policymakers in designing DER-focused AS products.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u865a\u62df\u7535\u5382(VPP)\u5728\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u4e0b\u63d0\u4f9b\u7535\u529b\u50a8\u5907\u5bb9\u91cf\u4ea7\u54c1\u6f5c\u529b\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u8003\u8651\u4e86\u8f85\u52a9\u670d\u52a1\u4ea7\u54c1\u7684\u53ef\u9760\u6027\u8981\u6c42\u548c\u6280\u672f\u89c4\u8303\uff0c\u5e76\u63d0\u4f9b\u51c6\u786e\u7684\u6210\u672c\u4f30\u7b97\u3002", "motivation": "\u53ef\u518d\u751f\u80fd\u6e90\u6e17\u900f\u7387\u589e\u52a0\u5bfc\u81f4\u5bf9\u7535\u529b\u50a8\u5907\u8f85\u52a9\u670d\u52a1\u7684\u9700\u6c42\u589e\u957f\uff0c\u9700\u8981\u5c06\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\u901a\u8fc7\u865a\u62df\u7535\u5382\u6574\u5408\u5230\u8f85\u52a9\u670d\u52a1\u5e02\u573a\u4e2d\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u8003\u8651\u8f85\u52a9\u670d\u52a1\u4ea7\u54c1\u7684\u53ef\u9760\u6027\u8981\u6c42\u548c\u63d0\u4f9b\u51c6\u786e\u6210\u672c\u4f30\u7b97\u3002", "method": "\u9996\u5148\u4f7f\u7528\u5b50\u96c6\u6a21\u62df\u7684\u65b0\u516c\u5f0f\u786e\u5b9a\u6700\u5927\u53ef\u884c\u50a8\u5907\u91cf\uff0c\u7136\u540e\u901a\u8fc7\u8003\u8651\u663e\u6027\u6210\u672c\u548c\u673a\u4f1a\u6210\u672c\u6765\u8868\u5f81\u4f9b\u5e94\u66f2\u7ebf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u865a\u62df\u7535\u5382\u80fd\u591f\u53ef\u9760\u5730\u63d0\u4f9b\u50a8\u5907\u4ea7\u54c1\uff0c\u673a\u4f1a\u6210\u672c\u9a71\u52a8\u4ea7\u54c1\u5b9a\u4ef7\uff0c\u4ea7\u54c1\u8981\u6c42\u5bf9\u50a8\u5907\u5bb9\u91cf\u63d0\u4f9b\u80fd\u529b\u6709\u5f3a\u70c8\u5f71\u54cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e8\u5728\u652f\u6301\u865a\u62df\u7535\u5382\u7ba1\u7406\u8005\u5236\u5b9a\u5e02\u573a\u7b56\u7565\u548c\u653f\u7b56\u5236\u5b9a\u8005\u8bbe\u8ba1\u9762\u5411\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\u7684\u8f85\u52a9\u670d\u52a1\u4ea7\u54c1\u3002"}}
{"id": "2510.04076", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.04076", "abs": "https://arxiv.org/abs/2510.04076", "authors": ["Amin Vahidi-Moghaddam", "Sayed Pedram Haeri Boroujeni", "Iman Jebellat", "Ehsan Jebellat", "Niloufar Mehrabi", "Zhaojian Li"], "title": "From Shadow to Light: Toward Safe and Efficient Policy Learning Across MPC, DeePC, RL, and LLM Agents", "comment": null, "summary": "One of the main challenges in modern control applications, particularly in\nrobot and vehicle motion control, is achieving accurate, fast, and safe\nmovement. To address this, optimal control policies have been developed to\nenforce safety while ensuring high performance. Since basic first-principles\nmodels of real systems are often available, model-based controllers are widely\nused. Model predictive control (MPC) is a leading approach that optimizes\nperformance while explicitly handling safety constraints. However, obtaining\naccurate models for complex systems is difficult, which motivates data-driven\nalternatives. ML-based MPC leverages learned models to reduce reliance on\nhand-crafted dynamics, while reinforcement learning (RL) can learn near-optimal\npolicies directly from interaction data. Data-enabled predictive control\n(DeePC) goes further by bypassing modeling altogether, directly learning safe\npolicies from raw input-output data. Recently, large language model (LLM)\nagents have also emerged, translating natural language instructions into\nstructured formulations of optimal control problems. Despite these advances,\ndata-driven policies face significant limitations. They often suffer from slow\nresponse times, high computational demands, and large memory needs, making them\nless practical for real-world systems with fast dynamics, limited onboard\ncomputing, or strict memory constraints. To address this, various technique,\nsuch as reduced-order modeling, function-approximated policy learning, and\nconvex relaxations, have been proposed to reduce computational complexity. In\nthis paper, we present eight such approaches and demonstrate their\neffectiveness across real-world applications, including robotic arms, soft\nrobots, and vehicle motion control.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u516b\u79cd\u964d\u4f4e\u6570\u636e\u9a71\u52a8\u63a7\u5236\u7b56\u7565\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u6280\u672f\uff0c\u5305\u62ec\u964d\u9636\u5efa\u6a21\u3001\u51fd\u6570\u903c\u8fd1\u7b56\u7565\u5b66\u4e60\u548c\u51f8\u677e\u5f1b\u7b49\u65b9\u6cd5\uff0c\u5e76\u5728\u673a\u5668\u4eba\u3001\u8f6f\u673a\u5668\u4eba\u548c\u8f66\u8f86\u8fd0\u52a8\u63a7\u5236\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u6570\u636e\u9a71\u52a8\u63a7\u5236\u7b56\u7565\uff08\u5982MPC\u3001RL\u3001DeePC\u7b49\uff09\u5728\u5b9e\u65f6\u5e94\u7528\u4e2d\u9762\u4e34\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3001\u54cd\u5e94\u6162\u3001\u5185\u5b58\u9700\u6c42\u5927\u7b49\u95ee\u9898\uff0c\u4f7f\u5176\u66f4\u9002\u5408\u5177\u6709\u5feb\u901f\u52a8\u6001\u3001\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u6216\u4e25\u683c\u5185\u5b58\u7ea6\u675f\u7684\u5b9e\u9645\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e86\u516b\u79cd\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u6280\u672f\uff1a\u964d\u9636\u5efa\u6a21\u3001\u51fd\u6570\u903c\u8fd1\u7b56\u7565\u5b66\u4e60\u3001\u51f8\u677e\u5f1b\u7b49\uff0c\u65e8\u5728\u51cf\u5c11\u6570\u636e\u9a71\u52a8\u63a7\u5236\u7b56\u7565\u7684\u8ba1\u7b97\u8d1f\u62c5\u548c\u5185\u5b58\u9700\u6c42\u3002", "result": "\u8fd9\u4e9b\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\uff08\u5305\u62ec\u673a\u68b0\u81c2\u3001\u8f6f\u673a\u5668\u4eba\u548c\u8f66\u8f86\u8fd0\u52a8\u63a7\u5236\uff09\u88ab\u8bc1\u660e\u6709\u6548\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u63a7\u5236\u7b56\u7565\u7684\u5b9e\u65f6\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u901a\u8fc7\u91c7\u7528\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4e\u6280\u672f\uff0c\u6570\u636e\u9a71\u52a8\u63a7\u5236\u7b56\u7565\u53ef\u4ee5\u66f4\u597d\u5730\u9002\u5e94\u5b9e\u9645\u7cfb\u7edf\u7684\u9700\u6c42\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u6ee1\u8db3\u5b9e\u65f6\u6027\u3001\u8ba1\u7b97\u8d44\u6e90\u548c\u5185\u5b58\u7ea6\u675f\u7684\u8981\u6c42\u3002"}}
{"id": "2510.04033", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04033", "abs": "https://arxiv.org/abs/2510.04033", "authors": ["Ayush Noori", "Adam Rodman", "Alan Karthikesalingam", "Bilal A. Mateen", "Christopher A. Longhurst", "Daniel Yang", "Dave deBronkart", "Gauden Galea", "Harold F. Wolf III", "Jacob Waxman", "Joshua C. Mandel", "Juliana Rotich", "Kenneth D. Mandl", "Maryam Mustafa", "Melissa Miles", "Nigam H. Shah", "Peter Lee", "Robert Korom", "Scott Mahoney", "Seth Hain", "Tien Yin Wong", "Trevor Mundel", "Vivek Natarajan", "Noa Dagan", "David A. Clifton", "Ran D. Balicer", "Isaac S. Kohane", "Marinka Zitnik"], "title": "A global log for medical AI", "comment": null, "summary": "Modern computer systems often rely on syslog, a simple, universal protocol\nthat records every critical event across heterogeneous infrastructure. However,\nhealthcare's rapidly growing clinical AI stack has no equivalent. As hospitals\nrush to pilot large language models and other AI-based clinical decision\nsupport tools, we still lack a standard way to record how, when, by whom, and\nfor whom these AI models are used. Without that transparency and visibility, it\nis challenging to measure real-world performance and outcomes, detect adverse\nevents, or correct bias or dataset drift. In the spirit of syslog, we introduce\nMedLog, a protocol for event-level logging of clinical AI. Any time an AI model\nis invoked to interact with a human, interface with another algorithm, or act\nindependently, a MedLog record is created. This record consists of nine core\nfields: header, model, user, target, inputs, artifacts, outputs, outcomes, and\nfeedback, providing a structured and consistent record of model activity. To\nencourage early adoption, especially in low-resource settings, and minimize the\ndata footprint, MedLog supports risk-based sampling, lifecycle-aware retention\npolicies, and write-behind caching; detailed traces for complex, agentic, or\nmulti-stage workflows can also be captured under MedLog. MedLog can catalyze\nthe development of new databases and software to store and analyze MedLog\nrecords. Realizing this vision would enable continuous surveillance, auditing,\nand iterative improvement of medical AI, laying the foundation for a new form\nof digital epidemiology.", "AI": {"tldr": "\u63d0\u51faMedLog\u534f\u8bae\uff0c\u7528\u4e8e\u4e34\u5e8aAI\u7684\u4e8b\u4ef6\u7ea7\u65e5\u5fd7\u8bb0\u5f55\uff0c\u7c7b\u4f3c\u4e8e\u7cfb\u7edf\u65e5\u5fd7(syslog)\uff0c\u65e8\u5728\u89e3\u51b3\u533b\u7597AI\u7f3a\u4e4f\u6807\u51c6\u4f7f\u7528\u8bb0\u5f55\u7684\u95ee\u9898\u3002", "motivation": "\u533b\u7597\u9886\u57df\u5feb\u901f\u589e\u957f\u7684\u4e34\u5e8aAI\u5806\u6808\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u4f7f\u7528\u8bb0\u5f55\u65b9\u5f0f\uff0c\u96be\u4ee5\u8861\u91cf\u771f\u5b9e\u4e16\u754c\u6027\u80fd\u3001\u68c0\u6d4b\u4e0d\u826f\u4e8b\u4ef6\u6216\u7ea0\u6b63\u504f\u5dee\uff0c\u9700\u8981\u7c7b\u4f3csyslog\u7684\u901a\u7528\u65e5\u5fd7\u534f\u8bae\u3002", "method": "\u8bbe\u8ba1MedLog\u534f\u8bae\uff0c\u5305\u542b9\u4e2a\u6838\u5fc3\u5b57\u6bb5\uff1aheader\u3001model\u3001user\u3001target\u3001inputs\u3001artifacts\u3001outputs\u3001outcomes\u548cfeedback\uff0c\u652f\u6301\u98ce\u9669\u91c7\u6837\u3001\u751f\u547d\u5468\u671f\u611f\u77e5\u4fdd\u7559\u7b56\u7565\u548c\u5199\u540e\u7f13\u5b58\u3002", "result": "MedLog\u80fd\u591f\u7ed3\u6784\u5316\u8bb0\u5f55AI\u6a21\u578b\u6d3b\u52a8\uff0c\u652f\u6301\u590d\u6742\u5de5\u4f5c\u6d41\u7684\u8be6\u7ec6\u8ddf\u8e2a\uff0c\u53ef\u4fc3\u8fdb\u65b0\u6570\u636e\u5e93\u548c\u8f6f\u4ef6\u7684\u5f00\u53d1\u3002", "conclusion": "MedLog\u4e3a\u5b9e\u73b0\u533b\u7597AI\u7684\u6301\u7eed\u76d1\u63a7\u3001\u5ba1\u8ba1\u548c\u8fed\u4ee3\u6539\u8fdb\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4e3a\u6570\u5b57\u6d41\u884c\u75c5\u5b66\u65b0\u5f62\u5f0f\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2510.04853", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.04853", "abs": "https://arxiv.org/abs/2510.04853", "authors": ["Junfeng Cai", "Marco Lovera"], "title": "An Active Fault-Tolerant Online Control Allocation Scheme for a Dual-System UAV in Transition Flight", "comment": "40 pages", "summary": "A novel active fault-tolerant control (AFTC) scheme for a dual-system\nvertical takeoff and landing (VTOL) unmanned aerial vehicle (UAV) during\ntransition flight is proposed in this paper. The AFTC scheme is composed of a\nbaseline control law and an online control reallocation module. First, the\nstructured $H_{\\infty}$ baseline control law is able to guarantee the stability\nof closed-loop systems without being reconfigured under simultaneous actuator\nfault conditions. Second, compared to the existing mainstream method of sliding\nmode control that is a discontinuous control strategy, the AFTC scheme can\neffectively avoid control chattering problem by adopting the structured\n$H_{\\infty}$ baseline control law. Third, an online control allocation (CA)\nmodule is implemented to carry out a unified CA for all the available\nactuators. When actuator faults/failures occur, the CA matrix is updated\naccording to fault information and real-time airspeed, which is able to\nredistribute the virtual control signals to the remaining healthy actuators,\navoiding significant performance degradation. Based on the developed AFTC\nscheme, symmetric and non-symmetric actuator fault scenarios are simulated on a\nnonlinear six-degree-of-freedom simulator, where the cases of merely structured\n$H_{\\infty}$ control and structured $H_{\\infty}$ based AFTC are compared and\nanalyzed. The results show that the proposed structured $H_{\\infty}$ based AFTC\nsystem is capable of handling more complicated fault scenarios and model\nuncertainties with no need to reconfigure the baseline control law. The\nproposed AFTC scheme significantly improves the safety and reliability of the\ntransition flight of dual-system VTOL UAVs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u53cc\u7cfb\u7edf\u5782\u76f4\u8d77\u964d\u65e0\u4eba\u673a\u8fc7\u6e21\u98de\u884c\u7684\u65b0\u578b\u4e3b\u52a8\u5bb9\u9519\u63a7\u5236\u65b9\u6848\uff0c\u5305\u542b\u57fa\u51c6\u63a7\u5236\u5f8b\u548c\u5728\u7ebf\u63a7\u5236\u91cd\u5206\u914d\u6a21\u5757\uff0c\u80fd\u6709\u6548\u5904\u7406\u6267\u884c\u5668\u6545\u969c\u5e76\u907f\u514d\u63a7\u5236\u6296\u52a8\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u53cc\u7cfb\u7edf\u5782\u76f4\u8d77\u964d\u65e0\u4eba\u673a\u5728\u8fc7\u6e21\u98de\u884c\u4e2d\u6267\u884c\u5668\u6545\u969c\u65f6\u7684\u63a7\u5236\u95ee\u9898\uff0c\u63d0\u9ad8\u98de\u884c\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u907f\u514d\u4f20\u7edf\u6ed1\u6a21\u63a7\u5236\u65b9\u6cd5\u5e26\u6765\u7684\u63a7\u5236\u6296\u52a8\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u5316H\u221e\u57fa\u51c6\u63a7\u5236\u5f8b\u4fdd\u8bc1\u95ed\u73af\u7cfb\u7edf\u7a33\u5b9a\u6027\uff0c\u7ed3\u5408\u5728\u7ebf\u63a7\u5236\u5206\u914d\u6a21\u5757\u6839\u636e\u6545\u969c\u4fe1\u606f\u548c\u5b9e\u65f6\u7a7a\u901f\u66f4\u65b0\u63a7\u5236\u5206\u914d\u77e9\u9635\uff0c\u5c06\u865a\u62df\u63a7\u5236\u4fe1\u53f7\u91cd\u65b0\u5206\u914d\u7ed9\u5065\u5eb7\u6267\u884c\u5668\u3002", "result": "\u5728\u975e\u7ebf\u6027\u516d\u81ea\u7531\u5ea6\u4eff\u771f\u5668\u4e0a\u6d4b\u8bd5\u5bf9\u79f0\u548c\u975e\u5bf9\u79f0\u6267\u884c\u5668\u6545\u969c\u573a\u666f\uff0c\u7ed3\u679c\u8868\u660e\u8be5AFTC\u7cfb\u7edf\u80fd\u5904\u7406\u66f4\u590d\u6742\u7684\u6545\u969c\u573a\u666f\u548c\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\uff0c\u65e0\u9700\u91cd\u65b0\u914d\u7f6e\u57fa\u51c6\u63a7\u5236\u5f8b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u7ed3\u6784\u5316H\u221e\u7684AFTC\u65b9\u6848\u663e\u8457\u63d0\u9ad8\u4e86\u53cc\u7cfb\u7edfVTOL\u65e0\u4eba\u673a\u8fc7\u6e21\u98de\u884c\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.04161", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04161", "abs": "https://arxiv.org/abs/2510.04161", "authors": ["Longrui Yang", "Yiyu Wang", "Jingfan Tang", "Yunpeng Lv", "Shizhe Zhao", "Chao Cao", "Zhongqiang Ren"], "title": "HEHA: Hierarchical Planning for Heterogeneous Multi-Robot Exploration of Unknown Environments", "comment": "5 Figures", "summary": "This paper considers the path planning problem for autonomous exploration of\nan unknown environment using multiple heterogeneous robots such as drones,\nwheeled, and legged robots, which have different capabilities to traverse\ncomplex terrains. A key challenge there is to intelligently allocate the robots\nto the unknown areas to be explored and determine the visiting order of those\nspaces subject to traversablity constraints, which leads to a large scale\nconstrained optimization problem that needs to be quickly and iteratively\nsolved every time when new space are explored. To address the challenge, we\npropose HEHA (Hierarchical Exploration with Heterogeneous Agents) by leveraging\na recent hierarchical method that decompose the exploration into global\nplanning and local planning. The major contribution in HEHA is its global\nplanning, where we propose a new routing algorithm PEAF (Partial Anytime Focal\nsearch) that can quickly find bounded sub-optimal solutions to minimize the\nmaximum path length among the agents subject to traversability constraints.\nAdditionally, the local planner in HEHA also considers heterogeneity to avoid\nrepeated and duplicated exploration among the robots. The experimental results\nshow that, our HEHA can reduce up to 30% of the exploration time than the\nbaselines.", "AI": {"tldr": "HEHA\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u5f02\u6784\u673a\u5668\u4eba\u81ea\u4e3b\u63a2\u7d22\u672a\u77e5\u73af\u5883\u7684\u5206\u5c42\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u5168\u5c40\u89c4\u5212\u548c\u5c40\u90e8\u89c4\u5212\u76f8\u7ed3\u5408\uff0c\u4f7f\u7528PEAF\u7b97\u6cd5\u5feb\u901f\u6c42\u89e3\u6709\u754c\u6b21\u4f18\u89e3\uff0c\u51cf\u5c11\u5f02\u6784\u673a\u5668\u4eba\u63a2\u7d22\u65f6\u95f4\u8fbe30%\u3002", "motivation": "\u89e3\u51b3\u591a\u5f02\u6784\u673a\u5668\u4eba\uff08\u65e0\u4eba\u673a\u3001\u8f6e\u5f0f\u3001\u817f\u5f0f\u673a\u5668\u4eba\uff09\u5728\u672a\u77e5\u73af\u5883\u4e2d\u63a2\u7d22\u65f6\u7684\u8def\u5f84\u89c4\u5212\u95ee\u9898\uff0c\u8fd9\u4e9b\u673a\u5668\u4eba\u5177\u6709\u4e0d\u540c\u7684\u5730\u5f62\u7a7f\u8d8a\u80fd\u529b\uff0c\u9700\u8981\u667a\u80fd\u5206\u914d\u63a2\u7d22\u533a\u57df\u5e76\u786e\u5b9a\u8bbf\u95ee\u987a\u5e8f\uff0c\u540c\u65f6\u6ee1\u8db3\u53ef\u7a7f\u8d8a\u6027\u7ea6\u675f\u3002", "method": "\u63d0\u51faHEHA\u5206\u5c42\u63a2\u7d22\u6846\u67b6\uff1a\u5168\u5c40\u89c4\u5212\u4f7f\u7528PEAF\uff08\u90e8\u5206\u4efb\u610f\u65f6\u95f4\u7126\u70b9\u641c\u7d22\uff09\u7b97\u6cd5\u5feb\u901f\u6c42\u89e3\u6709\u754c\u6b21\u4f18\u89e3\uff0c\u6700\u5c0f\u5316\u5404\u4ee3\u7406\u7684\u6700\u5927\u8def\u5f84\u957f\u5ea6\uff1b\u5c40\u90e8\u89c4\u5212\u8003\u8651\u5f02\u6784\u6027\u907f\u514d\u91cd\u590d\u63a2\u7d22\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cHEHA\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u80fd\u591f\u51cf\u5c11\u9ad8\u8fbe30%\u7684\u63a2\u7d22\u65f6\u95f4\u3002", "conclusion": "HEHA\u901a\u8fc7\u5206\u5c42\u89c4\u5212\u548c\u8003\u8651\u5f02\u6784\u6027\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u5f02\u6784\u673a\u5668\u4eba\u63a2\u7d22\u672a\u77e5\u73af\u5883\u7684\u5927\u89c4\u6a21\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u63a2\u7d22\u6548\u7387\u3002"}}
{"id": "2510.04040", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04040", "abs": "https://arxiv.org/abs/2510.04040", "authors": ["Xu Shen", "Song Wang", "Zhen Tan", "Laura Yao", "Xinyu Zhao", "Kaidi Xu", "Xin Wang", "Tianlong Chen"], "title": "FaithCoT-Bench: Benchmarking Instance-Level Faithfulness of Chain-of-Thought Reasoning", "comment": null, "summary": "Large language models (LLMs) increasingly rely on Chain-of-Thought (CoT)\nprompting to improve problem-solving and provide seemingly transparent\nexplanations. However, growing evidence shows that CoT often fail to faithfully\nrepresent the underlying reasoning process, raising concerns about their\nreliability in high-risk applications. Although prior studies have focused on\nmechanism-level analyses showing that CoTs can be unfaithful, they leave open\nthe practical challenge of deciding whether a specific trajectory is faithful\nto the internal reasoning of the model. To address this gap, we introduce\nFaithCoT-Bench, a unified benchmark for instance-level CoT unfaithfulness\ndetection. Our framework establishes a rigorous task formulation that\nformulates unfaithfulness detection as a discriminative decision problem, and\nprovides FINE-CoT (Faithfulness instance evaluation for Chain-of-Thought), an\nexpert-annotated collection of over 1,000 trajectories generated by four\nrepresentative LLMs across four domains, including more than 300 unfaithful\ninstances with fine-grained causes and step-level evidence. We further conduct\na systematic evaluation of eleven representative detection methods spanning\ncounterfactual, logit-based, and LLM-as-judge paradigms, deriving empirical\ninsights that clarify the strengths and weaknesses of existing approaches and\nreveal the increased challenges of detection in knowledge-intensive domains and\nwith more advanced models. To the best of our knowledge, FaithCoT-Bench\nestablishes the first comprehensive benchmark for instance-level CoT\nfaithfulness, setting a solid basis for future research toward more\ninterpretable and trustworthy reasoning in LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86FaithCoT-Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u68c0\u6d4bLLM\u4e2d\u601d\u7ef4\u94fe(CoT)\u7684\u4e0d\u5fe0\u5b9e\u6027\uff0c\u5305\u542b1000+\u8f68\u8ff9\u6570\u636e\u548c300+\u4e0d\u5fe0\u5b9e\u5b9e\u4f8b\uff0c\u8bc4\u4f30\u4e8611\u79cd\u68c0\u6d4b\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u673a\u5236\u5c42\u9762\u7684CoT\u4e0d\u5fe0\u5b9e\u6027\u5206\u6790\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u5177\u4f53\u8f68\u8ff9\u662f\u5426\u5fe0\u5b9e\u4e8e\u6a21\u578b\u5185\u90e8\u63a8\u7406\u7684\u5b9e\u4f8b\u7ea7\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5efa\u7acb\u7edf\u4e00\u57fa\u51c6FaithCoT-Bench\uff0c\u5305\u542bFINE-CoT\u6570\u636e\u96c6\uff08\u4e13\u5bb6\u6807\u6ce8\u76841000+\u8f68\u8ff9\uff09\uff0c\u5c06\u4e0d\u5fe0\u5b9e\u6027\u68c0\u6d4b\u5236\u5b9a\u4e3a\u5224\u522b\u51b3\u7b56\u95ee\u9898\uff0c\u8bc4\u4f30\u53cd\u4e8b\u5b9e\u3001\u57fa\u4e8elogit\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u4e09\u7c7b\u65b9\u6cd5\u3002", "result": "\u7cfb\u7edf\u8bc4\u4f30\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u53d1\u73b0\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u548c\u66f4\u5148\u8fdb\u6a21\u578b\u4e2d\u7684\u68c0\u6d4b\u6311\u6218\u66f4\u5927\u3002", "conclusion": "FaithCoT-Bench\u662f\u9996\u4e2a\u5168\u9762\u7684\u5b9e\u4f8b\u7ea7CoT\u5fe0\u5b9e\u6027\u57fa\u51c6\uff0c\u4e3aLLM\u4e2d\u66f4\u53ef\u89e3\u91ca\u548c\u53ef\u4fe1\u7684\u63a8\u7406\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.04868", "categories": ["eess.SY", "cs.AI", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.04868", "abs": "https://arxiv.org/abs/2510.04868", "authors": ["Seyed Soroush Karimi Madahi", "Kenneth Bruninx", "Bert Claessens", "Chris Develder"], "title": "Model Predictive Control-Guided Reinforcement Learning for Implicit Balancing", "comment": null, "summary": "In Europe, profit-seeking balance responsible parties can deviate in real\ntime from their day-ahead nominations to assist transmission system operators\nin maintaining the supply-demand balance. Model predictive control (MPC)\nstrategies to exploit these implicit balancing strategies capture arbitrage\nopportunities, but fail to accurately capture the price-formation process in\nthe European imbalance markets and face high computational costs. Model-free\nreinforcement learning (RL) methods are fast to execute, but require\ndata-intensive training and usually rely on real-time and historical data for\ndecision-making. This paper proposes an MPC-guided RL method that combines the\ncomplementary strengths of both MPC and RL. The proposed method can effectively\nincorporate forecasts into the decision-making process (as in MPC), while\nmaintaining the fast inference capability of RL. The performance of the\nproposed method is evaluated on the implicit balancing battery control problem\nusing Belgian balancing data from 2023. First, we analyze the performance of\nthe standalone state-of-the-art RL and MPC methods from various angles, to\nhighlight their individual strengths and limitations. Next, we show an\narbitrage profit benefit of the proposed MPC-guided RL method of 16.15% and\n54.36%, compared to standalone RL and MPC.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6a21\u578b\u9884\u6d4b\u63a7\u5236(MPC)\u548c\u5f3a\u5316\u5b66\u4e60(RL)\u7684MPC\u5f15\u5bfcRL\u65b9\u6cd5\uff0c\u7528\u4e8e\u6b27\u6d32\u4e0d\u5e73\u8861\u5e02\u573a\u7684\u7535\u6c60\u63a7\u5236\uff0c\u76f8\u6bd4\u5355\u72ec\u4f7f\u7528RL\u548cMPC\u5206\u522b\u5b9e\u73b0\u4e8616.15%\u548c54.36%\u7684\u5957\u5229\u5229\u6da6\u63d0\u5347\u3002", "motivation": "\u73b0\u6709MPC\u7b56\u7565\u867d\u7136\u80fd\u6355\u6349\u5957\u5229\u673a\u4f1a\uff0c\u4f46\u65e0\u6cd5\u51c6\u786e\u6a21\u62df\u6b27\u6d32\u4e0d\u5e73\u8861\u5e02\u573a\u7684\u4ef7\u683c\u5f62\u6210\u8fc7\u7a0b\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff1b\u800cRL\u65b9\u6cd5\u6267\u884c\u5feb\u901f\u4f46\u9700\u8981\u6570\u636e\u5bc6\u96c6\u578b\u8bad\u7ec3\u4e14\u4f9d\u8d56\u5b9e\u65f6\u548c\u5386\u53f2\u6570\u636e\u3002", "method": "\u63d0\u51faMPC\u5f15\u5bfcRL\u65b9\u6cd5\uff0c\u7ed3\u5408MPC\u548cRL\u7684\u4e92\u8865\u4f18\u52bf\uff1a\u65e2\u80fd\u50cfMPC\u4e00\u6837\u6709\u6548\u6574\u5408\u9884\u6d4b\u5230\u51b3\u7b56\u8fc7\u7a0b\uff0c\u53c8\u80fd\u4fdd\u6301RL\u7684\u5feb\u901f\u63a8\u7406\u80fd\u529b\u3002", "result": "\u4f7f\u75282023\u5e74\u6bd4\u5229\u65f6\u5e73\u8861\u6570\u636e\u8bc4\u4f30\uff0c\u76f8\u6bd4\u5355\u72ec\u4f7f\u7528RL\u548cMPC\u65b9\u6cd5\uff0c\u63d0\u51fa\u7684MPC\u5f15\u5bfcRL\u65b9\u6cd5\u5206\u522b\u5b9e\u73b0\u4e8616.15%\u548c54.36%\u7684\u5957\u5229\u5229\u6da6\u63d0\u5347\u3002", "conclusion": "MPC\u5f15\u5bfcRL\u65b9\u6cd5\u6210\u529f\u7ed3\u5408\u4e86\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u5728\u4fdd\u6301\u5feb\u901f\u6267\u884c\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u51b3\u7b56\u8d28\u91cf\uff0c\u4e3a\u4e0d\u5e73\u8861\u5e02\u573a\u4e2d\u7684\u7535\u6c60\u63a7\u5236\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04168", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.04168", "abs": "https://arxiv.org/abs/2510.04168", "authors": ["Amirmasoud Molaei", "Reza Ghabcheloo"], "title": "Learning to Capture Rocks using an Excavator: A Reinforcement Learning Approach with Guiding Reward Formulation", "comment": null, "summary": "Rock capturing with standard excavator buckets is a challenging task\ntypically requiring the expertise of skilled operators. Unlike soil digging, it\ninvolves manipulating large, irregular rocks in unstructured environments where\ncomplex contact interactions with granular material make model-based control\nimpractical. Existing autonomous excavation methods focus mainly on continuous\nmedia or rely on specialized grippers, limiting their applicability to\nreal-world construction sites. This paper introduces a fully data-driven\ncontrol framework for rock capturing that eliminates the need for explicit\nmodeling of rock or soil properties. A model-free reinforcement learning agent\nis trained in the AGX Dynamics simulator using the Proximal Policy Optimization\n(PPO) algorithm and a guiding reward formulation. The learned policy outputs\njoint velocity commands directly to the boom, arm, and bucket of a CAT365\nexcavator model. Robustness is enhanced through extensive domain randomization\nof rock geometry, density, and mass, as well as the initial configurations of\nthe bucket, rock, and goal position. To the best of our knowledge, this is the\nfirst study to develop and evaluate an RL-based controller for the rock\ncapturing task. Experimental results show that the policy generalizes well to\nunseen rocks and varying soil conditions, achieving high success rates\ncomparable to those of human participants while maintaining machine stability.\nThese findings demonstrate the feasibility of learning-based excavation\nstrategies for discrete object manipulation without requiring specialized\nhardware or detailed material models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u6570\u636e\u9a71\u52a8\u7684\u63a7\u5236\u6846\u67b6\uff0c\u7528\u4e8e\u6316\u6398\u673a\u6293\u53d6\u5ca9\u77f3\u4efb\u52a1\uff0c\u65e0\u9700\u5bf9\u5ca9\u77f3\u6216\u571f\u58e4\u5c5e\u6027\u8fdb\u884c\u663e\u5f0f\u5efa\u6a21\u3002", "motivation": "\u6807\u51c6\u6316\u6398\u673a\u6293\u53d6\u5ca9\u77f3\u662f\u4e00\u9879\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u901a\u5e38\u9700\u8981\u719f\u7ec3\u64cd\u4f5c\u5458\u7684\u4e13\u4e1a\u77e5\u8bc6\u3002\u73b0\u6709\u81ea\u4e3b\u6316\u6398\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u8fde\u7eed\u4ecb\u8d28\u6216\u4f9d\u8d56\u4e13\u7528\u5939\u5177\uff0c\u9650\u5236\u4e86\u5176\u5728\u771f\u5b9e\u5efa\u7b51\u5de5\u573a\u7684\u9002\u7528\u6027\u3002", "method": "\u4f7f\u7528\u6a21\u578b\u65e0\u5173\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728AGX Dynamics\u6a21\u62df\u5668\u4e2d\u8bad\u7ec3\uff0c\u91c7\u7528PPO\u7b97\u6cd5\u548c\u5f15\u5bfc\u5956\u52b1\u516c\u5f0f\u3002\u5b66\u4e60\u7b56\u7565\u76f4\u63a5\u8f93\u51fa\u5173\u8282\u901f\u5ea6\u547d\u4ee4\u5230\u6316\u6398\u673a\u7684\u52a8\u81c2\u3001\u81c2\u548c\u94f2\u6597\u3002\u901a\u8fc7\u5e7f\u6cdb\u7684\u9886\u57df\u968f\u673a\u5316\u589e\u5f3a\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7b56\u7565\u80fd\u591f\u5f88\u597d\u5730\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u5ca9\u77f3\u548c\u53d8\u5316\u7684\u571f\u58e4\u6761\u4ef6\uff0c\u5b9e\u73b0\u4e0e\u4eba\u7c7b\u53c2\u4e0e\u8005\u76f8\u5f53\u7684\u9ad8\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u673a\u5668\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u8bc1\u660e\u4e86\u57fa\u4e8e\u5b66\u4e60\u7684\u6316\u6398\u7b56\u7565\u5728\u79bb\u6563\u7269\u4f53\u64cd\u4f5c\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u65e0\u9700\u4e13\u7528\u786c\u4ef6\u6216\u8be6\u7ec6\u6750\u6599\u6a21\u578b\u3002"}}
{"id": "2510.04048", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04048", "abs": "https://arxiv.org/abs/2510.04048", "authors": ["Aparna Nair-Kanneganti", "Trevor J. Chan", "Shir Goldfinger", "Emily Mackay", "Brian Anthony", "Alison Pouch"], "title": "Increasing LLM response trustworthiness using voting ensembles", "comment": null, "summary": "Despite huge advances, LLMs still lack convenient and reliable methods to\nquantify the uncertainty in their responses, making them difficult to trust in\nhigh-stakes applications. One of the simplest approaches to eliciting more\naccurate answers is to select the mode of many responses, a technique known as\nensembling. In this work, we expand on typical ensembling approaches by looking\nat ensembles with a variable voting threshold. We introduce a theoretical\nframework for question answering and show that, by permitting ensembles to\n\"abstain\" from providing an answer when the dominant response falls short of\nthe threshold, it is possible to dramatically increase the trustworthiness of\nthe remaining answers. From this framework, we derive theoretical results as\nwell as report experimental results on two problem domains: arithmetic problem\nsolving and clinical-note question-answering. In both domains, we observe that\nlarge gains in answer trustworthiness can be achieved using highly restrictive\nvoting ensembles, while incurring relatively modest reductions in response\nyield and accuracy. Due to this quality, voting ensembles may be particularly\nuseful in applications - such as healthcare and data annotation - that require\na high degree of certainty but which may not require that every question\nreceive an automated answer.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u53d8\u6295\u7968\u9608\u503c\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u5141\u8bb8\u6a21\u578b\u5728\u4e3b\u5bfc\u54cd\u5e94\u672a\u8fbe\u9608\u503c\u65f6\u5f03\u6743\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u5269\u4f59\u7b54\u6848\u7684\u53ef\u4fe1\u5ea6\u3002", "motivation": "LLM\u5728\u5173\u952e\u5e94\u7528\u4e2d\u7f3a\u4e4f\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u96be\u4ee5\u83b7\u5f97\u4fe1\u4efb\u3002\u9700\u8981\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u56de\u7b54\u7684\u51c6\u786e\u6027\u3002", "method": "\u6269\u5c55\u4f20\u7edf\u96c6\u6210\u65b9\u6cd5\uff0c\u5f15\u5165\u53ef\u53d8\u6295\u7968\u9608\u503c\u6846\u67b6\uff0c\u5141\u8bb8\u96c6\u6210\u5728\u4e3b\u5bfc\u54cd\u5e94\u4e0d\u8fbe\u6807\u65f6\u5f03\u6743\uff0c\u4e0d\u63d0\u4f9b\u7b54\u6848\u3002", "result": "\u5728\u4e24\u4e2a\u95ee\u9898\u9886\u57df\uff08\u7b97\u672f\u95ee\u9898\u6c42\u89e3\u548c\u4e34\u5e8a\u7b14\u8bb0\u95ee\u7b54\uff09\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u9ad8\u5ea6\u9650\u5236\u6027\u6295\u7968\u96c6\u6210\u53ef\u4ee5\u5927\u5e45\u63d0\u9ad8\u7b54\u6848\u53ef\u4fe1\u5ea6\uff0c\u540c\u65f6\u54cd\u5e94\u4ea7\u51fa\u548c\u51c6\u786e\u6027\u7684\u964d\u4f4e\u76f8\u5bf9\u8f83\u5c0f\u3002", "conclusion": "\u6295\u7968\u96c6\u6210\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u9ad8\u5ea6\u786e\u5b9a\u6027\u4f46\u4e0d\u8981\u6c42\u6bcf\u4e2a\u95ee\u9898\u90fd\u83b7\u5f97\u81ea\u52a8\u5316\u7b54\u6848\u7684\u5e94\u7528\u573a\u666f\uff0c\u5982\u533b\u7597\u4fdd\u5065\u548c\u6570\u636e\u6807\u6ce8\u3002"}}
{"id": "2510.04942", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.04942", "abs": "https://arxiv.org/abs/2510.04942", "authors": ["Raktim Bhattacharya"], "title": "Robust Cislunar Navigation via LFT-Based $\\mathcal{H}_\\infty$ Filtering with Bearing-Only Measurements", "comment": null, "summary": "This paper develops a robust estimation framework for cislunar navigation\nthat embeds the Circular Restricted Three-Body Problem (CR3BP) dynamics and\nbearing-only optical measurements within a Linear Fractional Transformation\n(LFT) representation. A full-order $\\mathcal{H}_\\infty$ observer is synthesized\nwith explicit $\\mathcal{L}_2$ performance bounds. The formulation yields a\nnonlinear estimator that operates directly on the governing equations and\navoids reliance on local linearizations. Dominant nonlinearities are expressed\nas structured real uncertainties, while measurement fidelity is represented\nthrough range-dependent weighting with Earth-Moon distances reconstructed from\nline-of-sight geometry. The sensing architecture assumes passive\nstar-tracker-class optical instruments, eliminating the need for time-of-flight\nranging or precision clocks. Simulations demonstrate bounded estimation errors\nand smooth position tracking over multiple orbital periods, with the largest\ndeviations observed in the out-of-plane states, consistent with the stiffness\nof the vertical dynamics and the limitations of angle-only observability.\nApplication to a Near Rectilinear Halo Orbit (NRHO) illustrates that the\nframework can achieve robust onboard navigation with bounded estimation errors\nwith flight-representative sensors.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7ebf\u6027\u5206\u6570\u53d8\u6362\u7684\u9c81\u68d2\u4f30\u8ba1\u6846\u67b6\uff0c\u7528\u4e8e\u5730\u6708\u7a7a\u95f4\u5bfc\u822a\uff0c\u7ed3\u5408CR3BP\u52a8\u529b\u5b66\u548c\u7eaf\u65b9\u4f4d\u5149\u5b66\u6d4b\u91cf\uff0c\u65e0\u9700\u4f9d\u8d56\u5c40\u90e8\u7ebf\u6027\u5316\u3002", "motivation": "\u4e3a\u5730\u6708\u7a7a\u95f4\u5bfc\u822a\u63d0\u4f9b\u4e0d\u4f9d\u8d56\u65f6\u95f4\u98de\u884c\u6d4b\u8ddd\u6216\u7cbe\u5bc6\u65f6\u949f\u7684\u9c81\u68d2\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5229\u7528\u88ab\u52a8\u661f\u8ddf\u8e2a\u5668\u7ea7\u5149\u5b66\u4eea\u5668\u5b9e\u73b0\u81ea\u4e3b\u5bfc\u822a\u3002", "method": "\u5c06\u4e3b\u5bfc\u975e\u7ebf\u6027\u8868\u793a\u4e3a\u7ed3\u6784\u5316\u5b9e\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u89c6\u7ebf\u51e0\u4f55\u91cd\u5efa\u5730\u6708\u8ddd\u79bb\u8fdb\u884c\u8ddd\u79bb\u76f8\u5173\u52a0\u6743\uff0c\u5408\u6210\u5177\u6709\u660e\u786eL2\u6027\u80fd\u754c\u7684\u5168\u9636H\u221e\u89c2\u6d4b\u5668\u3002", "result": "\u4eff\u771f\u663e\u793a\u4f30\u8ba1\u8bef\u5dee\u6709\u754c\uff0c\u5728\u591a\u8f68\u9053\u5468\u671f\u5185\u5b9e\u73b0\u5e73\u6ed1\u4f4d\u7f6e\u8ddf\u8e2a\uff0c\u6700\u5927\u504f\u5dee\u51fa\u73b0\u5728\u5e73\u9762\u5916\u72b6\u6001\uff0c\u4e0e\u5782\u76f4\u52a8\u529b\u5b66\u521a\u5ea6\u548c\u7eaf\u89d2\u5ea6\u53ef\u89c2\u6d4b\u6027\u9650\u5236\u4e00\u81f4\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u5728\u8fd1\u76f4\u7ebf\u6655\u8f68\u9053\u4e0a\u5b9e\u73b0\u5177\u6709\u6709\u754c\u4f30\u8ba1\u8bef\u5dee\u7684\u9c81\u68d2\u661f\u8f7d\u5bfc\u822a\uff0c\u9002\u7528\u4e8e\u98de\u884c\u4ee3\u8868\u6027\u4f20\u611f\u5668\u3002"}}
{"id": "2510.04171", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04171", "abs": "https://arxiv.org/abs/2510.04171", "authors": ["Lakshadeep Naik", "Adam Fischer", "Daniel Duberg", "Danica Kragic"], "title": "VBM-NET: Visual Base Pose Learning for Mobile Manipulation using Equivariant TransporterNet and GNNs", "comment": null, "summary": "In Mobile Manipulation, selecting an optimal mobile base pose is essential\nfor successful object grasping. Previous works have addressed this problem\neither through classical planning methods or by learning state-based policies.\nThey assume access to reliable state information, such as the precise object\nposes and environment models. In this work, we study base pose planning\ndirectly from top-down orthographic projections of the scene, which provide a\nglobal overview of the scene while preserving spatial structure. We propose\nVBM-NET, a learning-based method for base pose selection using such top-down\northographic projections. We use equivariant TransporterNet to exploit spatial\nsymmetries and efficiently learn candidate base poses for grasping. Further, we\nuse graph neural networks to represent a varying number of candidate base poses\nand use Reinforcement Learning to determine the optimal base pose among them.\nWe show that VBM-NET can produce comparable solutions to the classical methods\nin significantly less computation time. Furthermore, we validate sim-to-real\ntransfer by successfully deploying a policy trained in simulation to real-world\nmobile manipulation.", "AI": {"tldr": "VBM-NET\u662f\u4e00\u4e2a\u57fa\u4e8e\u5b66\u4e60\u7684\u79fb\u52a8\u673a\u5668\u4eba\u57fa\u5ea7\u59ff\u6001\u9009\u62e9\u65b9\u6cd5\uff0c\u4f7f\u7528\u4fef\u89c6\u6b63\u4ea4\u6295\u5f71\u56fe\u8fdb\u884c\u89c4\u5212\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97\u65f6\u95f4\u663e\u8457\u51cf\u5c11\uff0c\u5e76\u80fd\u5b9e\u73b0\u4ece\u4eff\u771f\u5230\u771f\u5b9e\u73af\u5883\u7684\u8fc1\u79fb\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u7cbe\u786e\u7684\u72b6\u6001\u4fe1\u606f\uff08\u5982\u7269\u4f53\u4f4d\u59ff\u548c\u73af\u5883\u6a21\u578b\uff09\uff0c\u800c\u672c\u6587\u7814\u7a76\u76f4\u63a5\u4ece\u4fef\u89c6\u6b63\u4ea4\u6295\u5f71\u56fe\u8fdb\u884c\u57fa\u5ea7\u59ff\u6001\u89c4\u5212\uff0c\u63d0\u4f9b\u5168\u5c40\u573a\u666f\u6982\u89c8\u5e76\u4fdd\u6301\u7a7a\u95f4\u7ed3\u6784\u3002", "method": "\u4f7f\u7528\u7b49\u53d8TransporterNet\u5229\u7528\u7a7a\u95f4\u5bf9\u79f0\u6027\u9ad8\u6548\u5b66\u4e60\u6293\u53d6\u5019\u9009\u57fa\u5ea7\u59ff\u6001\uff0c\u91c7\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u8868\u793a\u53ef\u53d8\u6570\u91cf\u7684\u5019\u9009\u59ff\u6001\uff0c\u5e76\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4ece\u4e2d\u9009\u62e9\u6700\u4f18\u57fa\u5ea7\u59ff\u6001\u3002", "result": "VBM-NET\u80fd\u5728\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u7684\u60c5\u51b5\u4e0b\u4ea7\u751f\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5728\u4eff\u771f\u4e2d\u8bad\u7ec3\u7684\u7b56\u7565\u6210\u529f\u90e8\u7f72\u5230\u771f\u5b9e\u4e16\u754c\u79fb\u52a8\u64cd\u4f5c\u4e2d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bc1\u660e\u4e86\u76f4\u63a5\u4ece\u89c6\u89c9\u8f93\u5165\u8fdb\u884c\u57fa\u5ea7\u59ff\u6001\u89c4\u5212\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8ba1\u7b97\u6027\u80fd\u548c\u6210\u529f\u7684\u4eff\u771f\u5230\u771f\u5b9e\u73af\u5883\u8fc1\u79fb\u3002"}}
{"id": "2510.04051", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04051", "abs": "https://arxiv.org/abs/2510.04051", "authors": ["Lele Liao", "Qile Zhang", "Ruofan Wu", "Guanhua Fang"], "title": "Toward a unified framework for data-efficient evaluation of large language models", "comment": "codes available at https://github.com/Rorschach1989/efficient-lm-eval", "summary": "Evaluating large language models (LLMs) on comprehensive benchmarks is a\ncornerstone of their development, yet it's often computationally and\nfinancially prohibitive. While Item Response Theory (IRT) offers a promising\npath toward data-efficient evaluation by disentangling model capability from\nitem difficulty, existing IRT-based methods are hampered by significant\nlimitations. They are typically restricted to binary correctness metrics,\nfailing to natively handle the continuous scores used in generative tasks, and\nthey operate on single benchmarks, ignoring valuable structural knowledge like\ncorrelations across different metrics or benchmarks. To overcome these\nchallenges, we introduce LEGO-IRT, a unified and flexible framework for\ndata-efficient LLM evaluation. LEGO-IRT's novel design natively supports both\nbinary and continuous evaluation metrics. Moreover, it introduces a factorized\narchitecture to explicitly model and leverage structural knowledge, decomposing\nmodel ability estimates into a general component and structure-specific (e.g.,\nper-metric or per-benchmark) components. Through extensive experiments\ninvolving $70$ LLMs across $5$ benchmarks, we show that LEGO-IRT achieves\nstable capability estimates using just $3\\%$ of the total evaluation items. We\ndemonstrate that incorporating structural knowledge reduces estimation error by\nup to $10\\%$ and reveal that the latent abilities estimated by our framework\nmay align more closely with human preferences.", "AI": {"tldr": "LEGO-IRT\u662f\u4e00\u4e2a\u7528\u4e8e\u9ad8\u6548\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u548c\u7ed3\u6784\u5316\u77e5\u8bc6\uff0c\u4ec5\u97003%\u7684\u8bc4\u4f30\u9879\u76ee\u5c31\u80fd\u7a33\u5b9a\u4f30\u8ba1\u6a21\u578b\u80fd\u529b\uff0c\u652f\u6301\u4e8c\u8fdb\u5236\u548c\u8fde\u7eed\u8bc4\u5206\u6307\u6807\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u9879\u76ee\u53cd\u5e94\u7406\u8bba(IRT)\u7684\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff1a\u4ec5\u652f\u6301\u4e8c\u8fdb\u5236\u6b63\u786e\u6027\u6307\u6807\uff0c\u65e0\u6cd5\u5904\u7406\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8fde\u7eed\u5206\u6570\uff1b\u4e14\u4ec5\u5728\u5355\u4e00\u57fa\u51c6\u4e0a\u64cd\u4f5c\uff0c\u5ffd\u7565\u4e86\u8de8\u4e0d\u540c\u6307\u6807\u6216\u57fa\u51c6\u7684\u76f8\u5173\u6027\u7b49\u6709\u4ef7\u503c\u7684\u7ed3\u6784\u5316\u77e5\u8bc6\u3002", "method": "\u63d0\u51faLEGO-IRT\u6846\u67b6\uff0c\u5176\u521b\u65b0\u8bbe\u8ba1\u539f\u751f\u652f\u6301\u4e8c\u8fdb\u5236\u548c\u8fde\u7eed\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u5f15\u5165\u56e0\u5b50\u5316\u67b6\u6784\u6765\u663e\u5f0f\u5efa\u6a21\u548c\u5229\u7528\u7ed3\u6784\u5316\u77e5\u8bc6\uff0c\u5c06\u6a21\u578b\u80fd\u529b\u4f30\u8ba1\u5206\u89e3\u4e3a\u901a\u7528\u7ec4\u4ef6\u548c\u7ed3\u6784\u7279\u5b9a\u7ec4\u4ef6\u3002", "result": "\u5728\u6d89\u53ca70\u4e2aLLM\u548c5\u4e2a\u57fa\u51c6\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cLEGO-IRT\u4ec5\u4f7f\u7528\u603b\u8bc4\u4f30\u9879\u76ee\u76843%\u5c31\u5b9e\u73b0\u4e86\u7a33\u5b9a\u7684\u80fd\u529b\u4f30\u8ba1\u3002\u878d\u5165\u7ed3\u6784\u5316\u77e5\u8bc6\u53ef\u5c06\u4f30\u8ba1\u8bef\u5dee\u964d\u4f4e\u9ad8\u8fbe10%\uff0c\u4e14\u8be5\u6846\u67b6\u4f30\u8ba1\u7684\u6f5c\u5728\u80fd\u529b\u53ef\u80fd\u66f4\u7b26\u5408\u4eba\u7c7b\u504f\u597d\u3002", "conclusion": "LEGO-IRT\u4e3a\u6570\u636e\u9ad8\u6548\u7684LLM\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u4e14\u7075\u6d3b\u7684\u6846\u67b6\uff0c\u514b\u670d\u4e86\u73b0\u6709IRT\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.05043", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.05043", "abs": "https://arxiv.org/abs/2510.05043", "authors": ["Javier Garcia-Aguilar", "Aurelio Garcia-Cerrada", "Juan L. Zamora", "Emilio Bueno", "Elena Saiz", "Almudena Mu\u00f1oz-Babiano", "Mohammad E. Zarei"], "title": "Multi-Loop Design of Virtual Synchronous Machine Control for DFIG-Based Wind Farms", "comment": "Submitted for evaluation to Journal of Modern Power Systems and Clean\n  Energy", "summary": "The displacement of synchronous generators by converter-interfaced renewable\nenergy sources obliges wind farms to provide inertia, damping, and voltage\nsupport, above all in increasingly weak grid conditions. This paper presents a\nco-ordinated frequency-domain methodology for tuning all control layers of\ndoubly-fed induction generators (DFIGs) within a wind farm operated as a\nVirtual Synchronous Machine (VSM). Starting from a full small-signal\nlinearisation that preserves loop-to-loop and machine-to-machine couplings, the\nprocedure reshapes every local open loop to explicit phase-margin targets\nthrough a single, prioritised iteration. The resulting controllers provide a\nstep response and stability margins close to those programmed at the design\nstage, in spite of the cross coupling between control loops. Since controller\nsynthesis relies exclusively on classical loop-shaping tools available in\ncommercial simulation suites, it is readily applicable to industrial-scale\nprojects.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u534f\u8c03\u7684\u9891\u7387\u57df\u65b9\u6cd5\uff0c\u7528\u4e8e\u8c03\u8c10\u4f5c\u4e3a\u865a\u62df\u540c\u6b65\u673a\u8fd0\u884c\u7684\u98ce\u7535\u573a\u4e2d\u53cc\u9988\u611f\u5e94\u53d1\u7535\u673a\u7684\u6240\u6709\u63a7\u5236\u5c42\uff0c\u901a\u8fc7\u5355\u6b21\u4f18\u5148\u8fed\u4ee3\u5c06\u6bcf\u4e2a\u672c\u5730\u5f00\u73af\u91cd\u5851\u4e3a\u660e\u786e\u7684\u76f8\u4f4d\u88d5\u5ea6\u76ee\u6807\u3002", "motivation": "\u540c\u6b65\u53d1\u7535\u673a\u88ab\u6362\u6d41\u5668\u63a5\u53e3\u7684\u53ef\u518d\u751f\u80fd\u6e90\u66ff\u4ee3\uff0c\u8981\u6c42\u98ce\u7535\u573a\u5728\u65e5\u76ca\u8584\u5f31\u7684\u7535\u7f51\u6761\u4ef6\u4e0b\u63d0\u4f9b\u60ef\u6027\u3001\u963b\u5c3c\u548c\u7535\u538b\u652f\u6301\u3002", "method": "\u57fa\u4e8e\u5b8c\u6574\u7684\u5c0f\u4fe1\u53f7\u7ebf\u6027\u5316\uff0c\u4fdd\u6301\u56de\u8def\u95f4\u548c\u673a\u95f4\u8026\u5408\uff0c\u901a\u8fc7\u5355\u6b21\u4f18\u5148\u8fed\u4ee3\u5c06\u6bcf\u4e2a\u672c\u5730\u5f00\u73af\u91cd\u5851\u4e3a\u660e\u786e\u7684\u76f8\u4f4d\u88d5\u5ea6\u76ee\u6807\uff0c\u4ec5\u4f7f\u7528\u5546\u4e1a\u4eff\u771f\u5957\u4ef6\u4e2d\u7684\u7ecf\u5178\u73af\u8def\u6574\u5f62\u5de5\u5177\u3002", "result": "\u6240\u5f97\u63a7\u5236\u5668\u63d0\u4f9b\u4e86\u63a5\u8fd1\u8bbe\u8ba1\u9636\u6bb5\u7f16\u7a0b\u7684\u9636\u8dc3\u54cd\u5e94\u548c\u7a33\u5b9a\u88d5\u5ea6\uff0c\u5c3d\u7ba1\u63a7\u5236\u56de\u8def\u4e4b\u95f4\u5b58\u5728\u4ea4\u53c9\u8026\u5408\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6613\u4e8e\u5e94\u7528\u4e8e\u5de5\u4e1a\u89c4\u6a21\u9879\u76ee\uff0c\u56e0\u4e3a\u63a7\u5236\u5668\u5408\u6210\u5b8c\u5168\u4f9d\u8d56\u4e8e\u5546\u4e1a\u4eff\u771f\u5957\u4ef6\u4e2d\u53ef\u7528\u7684\u7ecf\u5178\u73af\u8def\u6574\u5f62\u5de5\u5177\u3002"}}
{"id": "2510.04178", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04178", "abs": "https://arxiv.org/abs/2510.04178", "authors": ["L\u00e9a Pistorius", "Namrata U. Nayar", "Phillip Tran", "Sammy Elmariah", "Pierre E. Dupont"], "title": "Using Robotics to Improve Transcatheter Edge-to-Edge Repair of the Mitral Valve", "comment": "7 pages, 9 figures", "summary": "Transcatheter valve repair presents significant challenges due to the\nmechanical limitations and steep learning curve associated with manual catheter\nsystems. This paper investigates the use of robotics to facilitate\ntranscatheter procedures in the context of mitral valve edge-to-edge repair.\nThe complex handle-based control of a clinical repair device is replaced by\nintuitive robotic joint-based control via a game controller. Manual versus\nrobotic performance is analyzed by decomposing the overall device delivery task\ninto motion-specific steps and comparing capabilities on a step-by-step basis\nin a phantom model of the heart and vasculature. Metrics include procedure\nduration and clip placement accuracy. Results demonstrate that the robotic\nsystem can reduce procedural time and motion errors while also improving\naccuracy of clip placement. These findings suggest that robotic assistance can\naddress key limitations of manual systems, offering a more reliable and\nuser-friendly platform for complex transcatheter procedures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u673a\u5668\u4eba\u8f85\u52a9\u5728\u4e8c\u5c16\u74e3\u8fb9\u5bf9\u8fb9\u4fee\u590d\u624b\u672f\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u6e38\u620f\u63a7\u5236\u5668\u5b9e\u73b0\u76f4\u89c2\u7684\u673a\u5668\u4eba\u5173\u8282\u63a7\u5236\uff0c\u76f8\u6bd4\u624b\u52a8\u64cd\u4f5c\u80fd\u51cf\u5c11\u624b\u672f\u65f6\u95f4\u3001\u8fd0\u52a8\u8bef\u5dee\u5e76\u63d0\u9ad8\u5939\u5b50\u653e\u7f6e\u7cbe\u5ea6\u3002", "motivation": "\u7ecf\u5bfc\u7ba1\u74e3\u819c\u4fee\u590d\u624b\u672f\u9762\u4e34\u673a\u68b0\u9650\u5236\u548c\u9661\u5ced\u7684\u5b66\u4e60\u66f2\u7ebf\u6311\u6218\uff0c\u9700\u8981\u66f4\u53ef\u9760\u548c\u7528\u6237\u53cb\u597d\u7684\u5e73\u53f0\u6765\u6539\u5584\u624b\u672f\u6548\u679c\u3002", "method": "\u5c06\u4e34\u5e8a\u4fee\u590d\u8bbe\u5907\u7684\u590d\u6742\u624b\u67c4\u63a7\u5236\u66ff\u6362\u4e3a\u901a\u8fc7\u6e38\u620f\u63a7\u5236\u5668\u5b9e\u73b0\u7684\u76f4\u89c2\u673a\u5668\u4eba\u5173\u8282\u63a7\u5236\uff0c\u5728\u5fc3\u810f\u548c\u8840\u7ba1\u7cfb\u7edf\u7684\u4f53\u6a21\u6a21\u578b\u4e2d\u6bd4\u8f83\u624b\u52a8\u4e0e\u673a\u5668\u4eba\u6027\u80fd\uff0c\u5206\u89e3\u8bbe\u5907\u8f93\u9001\u4efb\u52a1\u4e3a\u5177\u4f53\u6b65\u9aa4\u8fdb\u884c\u5206\u6790\u3002", "result": "\u673a\u5668\u4eba\u7cfb\u7edf\u80fd\u591f\u51cf\u5c11\u624b\u672f\u65f6\u95f4\u548c\u8fd0\u52a8\u8bef\u5dee\uff0c\u540c\u65f6\u63d0\u9ad8\u5939\u5b50\u653e\u7f6e\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u673a\u5668\u4eba\u8f85\u52a9\u53ef\u4ee5\u89e3\u51b3\u624b\u52a8\u7cfb\u7edf\u7684\u5173\u952e\u9650\u5236\uff0c\u4e3a\u590d\u6742\u7684\u7ecf\u5bfc\u7ba1\u624b\u672f\u63d0\u4f9b\u66f4\u53ef\u9760\u548c\u7528\u6237\u53cb\u597d\u7684\u5e73\u53f0\u3002"}}
{"id": "2510.04064", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04064", "abs": "https://arxiv.org/abs/2510.04064", "authors": ["Jingxiang Zhang", "Lujia Zhong"], "title": "Decoding Emotion in the Deep: A Systematic Study of How LLMs Represent, Retain, and Express Emotion", "comment": "10 pages, 7 figures, 4 tables. Under review", "summary": "Large Language Models (LLMs) are increasingly expected to navigate the\nnuances of human emotion. While research confirms that LLMs can simulate\nemotional intelligence, their internal emotional mechanisms remain largely\nunexplored. This paper investigates the latent emotional representations within\nmodern LLMs by asking: how, where, and for how long is emotion encoded in their\nneural architecture? To address this, we introduce a novel, large-scale Reddit\ncorpus of approximately 400,000 utterances, balanced across seven basic\nemotions through a multi-stage process of classification, rewriting, and\nsynthetic generation. Using this dataset, we employ lightweight \"probes\" to\nread out information from the hidden layers of various Qwen3 and LLaMA models\nwithout altering their parameters. Our findings reveal that LLMs develop a\nsurprisingly well-defined internal geometry of emotion, which sharpens with\nmodel scale and significantly outperforms zero-shot prompting. We demonstrate\nthat this emotional signal is not a final-layer phenomenon but emerges early\nand peaks mid-network. Furthermore, the internal states are both malleable\n(they can be influenced by simple system prompts) and persistent, as the\ninitial emotional tone remains detectable for hundreds of subsequent tokens. We\ncontribute our dataset, an open-source probing toolkit, and a detailed map of\nthe emotional landscape within LLMs, offering crucial insights for developing\nmore transparent and aligned AI systems. The code and dataset are open-sourced.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6f5c\u5728\u60c5\u611f\u8868\u5f81\uff0c\u53d1\u73b0LLMs\u5177\u6709\u5b9a\u4e49\u826f\u597d\u7684\u5185\u90e8\u60c5\u611f\u51e0\u4f55\u7ed3\u6784\uff0c\u8fd9\u79cd\u7ed3\u6784\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u589e\u5f3a\uff0c\u60c5\u611f\u4fe1\u53f7\u5728\u7f51\u7edc\u4e2d\u5c42\u51fa\u73b0\u5e76\u8fbe\u5230\u5cf0\u503c\uff0c\u4e14\u5177\u6709\u53ef\u5851\u6027\u548c\u6301\u4e45\u6027\u3002", "motivation": "\u5c3d\u7ba1\u7814\u7a76\u8bc1\u5b9eLLMs\u80fd\u591f\u6a21\u62df\u60c5\u611f\u667a\u80fd\uff0c\u4f46\u5176\u5185\u90e8\u60c5\u611f\u673a\u5236\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76\u73b0\u4ee3LLMs\u4e2d\u6f5c\u5728\u7684\u60c5\u611f\u8868\u5f81\uff0c\u5305\u62ec\u60c5\u611f\u5982\u4f55\u3001\u5728\u4f55\u5904\u4ee5\u53ca\u6301\u7eed\u591a\u957f\u65f6\u95f4\u88ab\u7f16\u7801\u5728\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e2d\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u7ea640\u4e07\u6761\u8bdd\u8bed\u7684\u5927\u89c4\u6a21Reddit\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u5206\u7c7b\u3001\u91cd\u5199\u548c\u5408\u6210\u751f\u6210\u7684\u8fc7\u7a0b\u5e73\u8861\u4e86\u4e03\u79cd\u57fa\u672c\u60c5\u611f\u3002\u4f7f\u7528\u8f7b\u91cf\u7ea7\u201c\u63a2\u9488\u201d\u4ece\u5404\u79cdQwen3\u548cLLaMA\u6a21\u578b\u7684\u9690\u85cf\u5c42\u8bfb\u53d6\u4fe1\u606f\u800c\u4e0d\u6539\u53d8\u5176\u53c2\u6570\u3002", "result": "\u53d1\u73b0LLMs\u5f62\u6210\u4e86\u5b9a\u4e49\u826f\u597d\u7684\u5185\u90e8\u60c5\u611f\u51e0\u4f55\u7ed3\u6784\uff0c\u8fd9\u79cd\u7ed3\u6784\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u589e\u5f3a\uff0c\u663e\u8457\u4f18\u4e8e\u96f6\u6837\u672c\u63d0\u793a\u3002\u60c5\u611f\u4fe1\u53f7\u4e0d\u662f\u6700\u7ec8\u5c42\u73b0\u8c61\uff0c\u800c\u662f\u5728\u7f51\u7edc\u65e9\u671f\u51fa\u73b0\u5e76\u5728\u4e2d\u5c42\u8fbe\u5230\u5cf0\u503c\u3002\u5185\u90e8\u72b6\u6001\u5177\u6709\u53ef\u5851\u6027\uff08\u53ef\u901a\u8fc7\u7b80\u5355\u7cfb\u7edf\u63d0\u793a\u5f71\u54cd\uff09\u548c\u6301\u4e45\u6027\uff0c\u521d\u59cb\u60c5\u611f\u57fa\u8c03\u5728\u6570\u767e\u4e2a\u540e\u7eed\u6807\u8bb0\u4e2d\u4ecd\u53ef\u68c0\u6d4b\u5230\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u66f4\u900f\u660e\u548c\u5bf9\u9f50\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\uff0c\u8d21\u732e\u4e86\u6570\u636e\u96c6\u3001\u5f00\u6e90\u63a2\u9488\u5de5\u5177\u5305\u4ee5\u53caLLMs\u5185\u90e8\u60c5\u611f\u666f\u89c2\u7684\u8be6\u7ec6\u56fe\u8c31\u3002"}}
{"id": "2510.05063", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.05063", "abs": "https://arxiv.org/abs/2510.05063", "authors": ["Noah Rhodes"], "title": "PowerPlots: An Open Source Power Grid Visualization and Data Analysis Framework for Academic Research", "comment": null, "summary": "Data visualization is important for developing an understanding of a complex\nsystem. PowerPlots.jl is a data visualization tool for power grids, one of the\nmost complex systems in the world. The design of PowerPlots.jl is intended to\nfacilitate exploration of power grid data while performing research and to\nfacilitate communication of research findings to an audience. Several tools\ncreated to support this software also facilitate analysis of power grid data by\ntransforming the data into graph topology or data-frame data formats that are\nmore compatible for some applications. The high level of flexibility in\nPowerPlots.jl enables researchers who are developing and analyzing methods for\nsolving novel power grid problems to better understand and communicate the\ncomplexities of their research.", "AI": {"tldr": "PowerPlots.jl\u662f\u4e00\u4e2a\u7528\u4e8e\u590d\u6742\u7535\u7f51\u7cfb\u7edf\u7684\u6570\u636e\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u65e8\u5728\u4fc3\u8fdb\u7814\u7a76\u8fc7\u7a0b\u4e2d\u7684\u6570\u636e\u63a2\u7d22\u548c\u7814\u7a76\u6210\u679c\u7684\u6c9f\u901a\u4ea4\u6d41\u3002", "motivation": "\u7535\u7f51\u662f\u4e16\u754c\u4e0a\u6700\u590d\u6742\u7684\u7cfb\u7edf\u4e4b\u4e00\uff0c\u6570\u636e\u53ef\u89c6\u5316\u5bf9\u4e8e\u7406\u89e3\u590d\u6742\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u5f00\u53d1\u5de5\u5177\u6765\u652f\u6301\u7535\u7f51\u6570\u636e\u7684\u7814\u7a76\u63a2\u7d22\u548c\u6210\u679c\u5c55\u793a\u3002", "method": "\u5f00\u53d1\u4e86PowerPlots.jl\u6570\u636e\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u5e76\u521b\u5efa\u4e86\u914d\u5957\u5de5\u5177\u5c06\u7535\u7f51\u6570\u636e\u8f6c\u6362\u4e3a\u56fe\u62d3\u6251\u6216\u6570\u636e\u6846\u683c\u5f0f\uff0c\u63d0\u9ad8\u4e0e\u5176\u4ed6\u5e94\u7528\u7684\u517c\u5bb9\u6027\u3002", "result": "PowerPlots.jl\u5177\u6709\u9ad8\u5ea6\u7075\u6d3b\u6027\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u548c\u6c9f\u901a\u590d\u6742\u7535\u7f51\u7814\u7a76\u4e2d\u7684\u95ee\u9898\u3002", "conclusion": "PowerPlots.jl\u6210\u529f\u5730\u4e3a\u7535\u7f51\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u636e\u53ef\u89c6\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u7814\u7a76\u63a2\u7d22\u548c\u6210\u679c\u5c55\u793a\u7684\u53cc\u91cd\u9700\u6c42\u3002"}}
{"id": "2510.04190", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04190", "abs": "https://arxiv.org/abs/2510.04190", "authors": ["Jian-jie Zheng", "Chih-kai Yang", "Po-han Chen", "Lyn Chao-ling Chen"], "title": "Zenbo Patrol: A Social Assistive Robot Based on Multimodal Deep Learning for Real-time Illegal Parking Recognition and Notification", "comment": null, "summary": "In the study, the social robot act as a patrol to recognize and notify\nillegal parking in real-time. Dual-model pipeline method and large multimodal\nmodel were compared, and the GPT-4o multimodal model was adopted in license\nplate recognition without preprocessing. For moving smoothly on a flat ground,\nthe robot navigated in a simulated parking lot in the experiments. The robot\nchanges angle view of the camera automatically to capture the images around\nwith the format of license plate number. From the captured images of the robot,\nthe numbers on the plate are recognized through the GPT-4o model, and\nidentifies legality of the numbers. When an illegal parking is detected, the\nrobot sends Line messages to the system manager immediately. The contribution\nof the work is that a novel multimodal deep learning method has validated with\nhigh accuracy in license plate recognition, and a social assistive robot is\nalso provided for solving problems in a real scenario, and can be applied in an\nindoor parking lot.", "AI": {"tldr": "\u4f7f\u7528GPT-4o\u591a\u6a21\u6001\u6a21\u578b\u8fdb\u884c\u8f66\u724c\u8bc6\u522b\uff0c\u901a\u8fc7\u793e\u4ea4\u673a\u5668\u4eba\u5de1\u903b\u68c0\u6d4b\u975e\u6cd5\u505c\u8f66\u5e76\u5b9e\u65f6\u901a\u77e5\u7cfb\u7edf\u7ba1\u7406\u5458", "motivation": "\u89e3\u51b3\u5ba4\u5185\u505c\u8f66\u573a\u975e\u6cd5\u505c\u8f66\u95ee\u9898\uff0c\u5f00\u53d1\u5b9e\u65f6\u76d1\u63a7\u548c\u901a\u77e5\u7cfb\u7edf", "method": "\u91c7\u7528GPT-4o\u591a\u6a21\u6001\u6a21\u578b\u8fdb\u884c\u8f66\u724c\u8bc6\u522b\uff0c\u65e0\u9700\u9884\u5904\u7406\uff1b\u673a\u5668\u4eba\u81ea\u52a8\u8c03\u6574\u6444\u50cf\u5934\u89d2\u5ea6\u6355\u83b7\u8f66\u724c\u56fe\u50cf\uff1b\u901a\u8fc7Line\u6d88\u606f\u5b9e\u65f6\u901a\u77e5", "result": "\u9a8c\u8bc1\u4e86\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u8f66\u724c\u8bc6\u522b\u4e2d\u7684\u9ad8\u51c6\u786e\u6027\uff0c\u53ef\u5728\u5ba4\u5185\u505c\u8f66\u573a\u5b9e\u9645\u5e94\u7528", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u793e\u4ea4\u8f85\u52a9\u673a\u5668\u4eba\u89e3\u51b3\u5b9e\u9645\u573a\u666f\u95ee\u9898"}}
{"id": "2510.04073", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04073", "abs": "https://arxiv.org/abs/2510.04073", "authors": ["Santhosh Kumar Ravindran"], "title": "Moral Anchor System: A Predictive Framework for AI Value Alignment and Drift Prevention", "comment": "11 pages Includes simulations with over 4 million steps", "summary": "The rise of artificial intelligence (AI) as super-capable assistants has\ntransformed productivity and decision-making across domains. Yet, this\nintegration raises critical concerns about value alignment - ensuring AI\nbehaviors remain consistent with human ethics and intentions. A key risk is\nvalue drift, where AI systems deviate from aligned values due to evolving\ncontexts, learning dynamics, or unintended optimizations, potentially leading\nto inefficiencies or ethical breaches. We propose the Moral Anchor System\n(MAS), a novel framework to detect, predict, and mitigate value drift in AI\nagents. MAS combines real-time Bayesian inference for monitoring value states,\nLSTM networks for forecasting drift, and a human-centric governance layer for\nadaptive interventions. It emphasizes low-latency responses (<20 ms) to prevent\nbreaches, while reducing false positives and alert fatigue via supervised\nfine-tuning with human feedback. Our hypothesis: integrating probabilistic\ndrift detection, predictive analytics, and adaptive governance can reduce value\ndrift incidents by 80 percent or more in simulations, maintaining high\ndetection accuracy (85 percent) and low false positive rates (0.08\npost-adaptation). Rigorous experiments with goal-misaligned agents validate\nMAS's scalability and responsiveness. MAS's originality lies in its predictive\nand adaptive nature, contrasting static alignment methods. Contributions\ninclude: (1) MAS architecture for AI integration; (2) empirical results\nprioritizing speed and usability; (3) cross-domain applicability insights; and\n(4) open-source code for replication.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9053\u5fb7\u951a\u7cfb\u7edf(MAS)\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u65f6\u8d1d\u53f6\u65af\u63a8\u7406\u3001LSTM\u7f51\u7edc\u9884\u6d4b\u548c\u4eba\u7c7b\u4e2d\u5fc3\u6cbb\u7406\u5c42\u6765\u68c0\u6d4b\u3001\u9884\u6d4b\u548c\u7f13\u89e3AI\u7cfb\u7edf\u4e2d\u7684\u4ef7\u503c\u6f02\u79fb\u95ee\u9898\u3002", "motivation": "\u968f\u7740AI\u6210\u4e3a\u8d85\u7ea7\u52a9\u624b\uff0c\u4ef7\u503c\u5bf9\u9f50\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u4ef7\u503c\u6f02\u79fb\u98ce\u9669\u53ef\u80fd\u5bfc\u81f4AI\u884c\u4e3a\u504f\u79bb\u4eba\u7c7b\u4f26\u7406\u548c\u610f\u56fe\uff0c\u9020\u6210\u6548\u7387\u4f4e\u4e0b\u6216\u4f26\u7406\u8fdd\u89c4\u3002", "method": "MAS\u7ed3\u5408\u5b9e\u65f6\u8d1d\u53f6\u65af\u63a8\u7406\u76d1\u63a7\u4ef7\u503c\u72b6\u6001\uff0cLSTM\u7f51\u7edc\u9884\u6d4b\u6f02\u79fb\u8d8b\u52bf\uff0c\u4eba\u7c7b\u4e2d\u5fc3\u6cbb\u7406\u5c42\u8fdb\u884c\u81ea\u9002\u5e94\u5e72\u9884\uff0c\u5f3a\u8c03\u4f4e\u5ef6\u8fdf\u54cd\u5e94(<20ms)\uff0c\u5e76\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u51cf\u5c11\u8bef\u62a5\u3002", "result": "\u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0cMAS\u80fd\u5c06\u4ef7\u503c\u6f02\u79fb\u4e8b\u4ef6\u51cf\u5c1180%\u4ee5\u4e0a\uff0c\u4fdd\u6301\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387(85%)\u548c\u4f4e\u8bef\u62a5\u7387(0.08)\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u548c\u54cd\u5e94\u6027\u3002", "conclusion": "MAS\u7684\u539f\u521b\u6027\u5728\u4e8e\u5176\u9884\u6d4b\u6027\u548c\u81ea\u9002\u5e94\u6027\uff0c\u4e0e\u9759\u6001\u5bf9\u9f50\u65b9\u6cd5\u5f62\u6210\u5bf9\u6bd4\u3002\u8d21\u732e\u5305\u62ecMAS\u67b6\u6784\u3001\u5b9e\u8bc1\u7ed3\u679c\u3001\u8de8\u9886\u57df\u9002\u7528\u6027\u89c1\u89e3\u548c\u5f00\u6e90\u4ee3\u7801\u3002"}}
{"id": "2510.04234", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04234", "abs": "https://arxiv.org/abs/2510.04234", "authors": ["Runhan Huang", "Haldun Balim", "Heng Yang", "Yilun Du"], "title": "Flexible Locomotion Learning with Diffusion Model Predictive Control", "comment": "9 pages, 8 figures", "summary": "Legged locomotion demands controllers that are both robust and adaptable,\nwhile remaining compatible with task and safety considerations. However,\nmodel-free reinforcement learning (RL) methods often yield a fixed policy that\ncan be difficult to adapt to new behaviors at test time. In contrast, Model\nPredictive Control (MPC) provides a natural approach to flexible behavior\nsynthesis by incorporating different objectives and constraints directly into\nits optimization process. However, classical MPC relies on accurate dynamics\nmodels, which are often difficult to obtain in complex environments and\ntypically require simplifying assumptions. We present Diffusion-MPC, which\nleverages a learned generative diffusion model as an approximate dynamics prior\nfor planning, enabling flexible test-time adaptation through reward and\nconstraint based optimization. Diffusion-MPC jointly predicts future states and\nactions; at each reverse step, we incorporate reward planning and impose\nconstraint projection, yielding trajectories that satisfy task objectives while\nremaining within physical limits. To obtain a planning model that adapts beyond\nimitation pretraining, we introduce an interactive training algorithm for\ndiffusion based planner: we execute our reward-and-constraint planner in\nenvironment, then filter and reweight the collected trajectories by their\nrealized returns before updating the denoiser. Our design enables strong\ntest-time adaptability, allowing the planner to adjust to new reward\nspecifications without retraining. We validate Diffusion-MPC on real world,\ndemonstrating strong locomotion and flexible adaptation.", "AI": {"tldr": "\u63d0\u51fa\u4e86Diffusion-MPC\u65b9\u6cd5\uff0c\u4f7f\u7528\u5b66\u4e60\u7684\u751f\u6210\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u89c4\u5212\u4e2d\u7684\u8fd1\u4f3c\u52a8\u529b\u5b66\u5148\u9a8c\uff0c\u901a\u8fc7\u5956\u52b1\u548c\u7ea6\u675f\u4f18\u5316\u5b9e\u73b0\u7075\u6d3b\u6d4b\u8bd5\u65f6\u9002\u5e94\u3002", "motivation": "\u817f\u5f0f\u8fd0\u52a8\u9700\u8981\u65e2\u9c81\u68d2\u53c8\u9002\u5e94\u7684\u63a7\u5236\u5668\uff0c\u4f46\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4ea7\u751f\u56fa\u5b9a\u7b56\u7565\u96be\u4ee5\u9002\u5e94\u65b0\u884c\u4e3a\uff0c\u800c\u4f20\u7edfMPC\u4f9d\u8d56\u51c6\u786e\u52a8\u529b\u5b66\u6a21\u578b\u96be\u4ee5\u83b7\u5f97\u3002", "method": "\u4f7f\u7528\u6269\u6563\u6a21\u578b\u4f5c\u4e3a\u52a8\u529b\u5b66\u5148\u9a8c\u8fdb\u884c\u89c4\u5212\uff0c\u5728\u53cd\u5411\u6b65\u9aa4\u4e2d\u7ed3\u5408\u5956\u52b1\u89c4\u5212\u548c\u7ea6\u675f\u6295\u5f71\uff0c\u5e76\u901a\u8fc7\u4ea4\u4e92\u8bad\u7ec3\u7b97\u6cd5\u66f4\u65b0\u53bb\u566a\u5668\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u9a8c\u8bc1\u4e86\u5f3a\u5927\u7684\u8fd0\u52a8\u80fd\u529b\u548c\u7075\u6d3b\u9002\u5e94\u80fd\u529b\uff0c\u80fd\u591f\u9002\u5e94\u65b0\u7684\u5956\u52b1\u89c4\u8303\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "conclusion": "Diffusion-MPC\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u6d4b\u8bd5\u65f6\u9002\u5e94\u6027\uff0c\u5141\u8bb8\u89c4\u5212\u5668\u8c03\u6574\u5230\u65b0\u7684\u5956\u52b1\u89c4\u8303\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002"}}
{"id": "2510.04089", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04089", "abs": "https://arxiv.org/abs/2510.04089", "authors": ["Yitong Cui", "Liu Liu", "Baosheng Yu", "Jiayan Qiu", "Xikai Zhang", "Likang Xiao", "Yixing Liu", "Quan Chen"], "title": "SPOGW: a Score-based Preference Optimization method via Group-Wise comparison for workflows", "comment": null, "summary": "Large language models (LLMs) have exhibited significant capabilities in\naddressing challenging problems throughout various fields, often through the\nuse of agentic workflows that adhere to structured instructions and multi-step\nprocedures. However, designing such workflows demands substantial manual\neffort, posing challenges to scalability and generalizability. Recent studies\nhave aimed to minimize the human intervention needed for their construction,\nleading to advances in automated techniques for optimizing agentic workflows.\nHowever, current approaches are often constrained by their limited\nrepresentational capacity, insufficient adaptability, weak scalability, and\npairwise comparison paradigm -- issues that stem primarily from a dependence on\ndiscrete optimization techniques. To overcome these limitations, we introduce a\nnew score-based preference approach, refereed as SPOGW, which operates directly\non cardinal reward signals through group-wise comparison and enables more\nefficient and stable optimization in a continuous space. SPOGW incorporates\nIterative offline GRPO (ioGRPO) with advantage-masked KL divergence (mKL),\nwhich regulates training update by placing greater emphasis on the advantageous\nregions of the policy response. In five benchmark datasets covering\nmathematical reasoning, coding, and question answering, SPOGW matches or\nexceeds the performance of current state-of-the-art approaches, presenting a\nviable and forward-looking methodology for automated generation and\noptimization of agentic workflows.", "AI": {"tldr": "SPOGW\u662f\u4e00\u79cd\u57fa\u4e8e\u5206\u6570\u504f\u597d\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ec4\u95f4\u6bd4\u8f83\u76f4\u63a5\u5728\u8fde\u7eed\u7a7a\u95f4\u4e2d\u4f18\u5316\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u8868\u793a\u80fd\u529b\u6709\u9650\u3001\u9002\u5e94\u6027\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u9700\u8981\u5927\u91cf\u4eba\u5de5\u5e72\u9884\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u53d7\u9650\u4e8e\u79bb\u6563\u4f18\u5316\u6280\u672f\uff0c\u5b58\u5728\u8868\u793a\u80fd\u529b\u6709\u9650\u3001\u9002\u5e94\u6027\u4e0d\u8db3\u3001\u53ef\u6269\u5c55\u6027\u5f31\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faSPOGW\u65b9\u6cd5\uff0c\u91c7\u7528\u57fa\u4e8e\u5206\u6570\u504f\u597d\u7684\u7ec4\u95f4\u6bd4\u8f83\uff0c\u7ed3\u5408\u8fed\u4ee3\u79bb\u7ebfGRPO\uff08ioGRPO\uff09\u548c\u4f18\u52bf\u63a9\u7801KL\u6563\u5ea6\uff08mKL\uff09\uff0c\u5728\u8fde\u7eed\u7a7a\u95f4\u4e2d\u8fdb\u884c\u66f4\u9ad8\u6548\u7a33\u5b9a\u7684\u4f18\u5316\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u3001\u7f16\u7a0b\u548c\u95ee\u7b54\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cSPOGW\u8fbe\u5230\u6216\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "SPOGW\u4e3a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u81ea\u52a8\u751f\u6210\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u4e14\u524d\u77bb\u7684\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2510.04246", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04246", "abs": "https://arxiv.org/abs/2510.04246", "authors": ["Huiwon Jang", "Sihyun Yu", "Heeseung Kwon", "Hojin Jeon", "Younggyo Seo", "Jinwoo Shin"], "title": "ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context", "comment": "Project page: https://huiwon-jang.github.io/contextvla", "summary": "Leveraging temporal context is crucial for success in partially observable\nrobotic tasks. However, prior work in behavior cloning has demonstrated\ninconsistent performance gains when using multi-frame observations. In this\npaper, we introduce ContextVLA, a policy model that robustly improves robotic\ntask performance by effectively leveraging multi-frame observations. Our\napproach is motivated by the key observation that Vision-Language-Action models\n(VLA), i.e., policy models built upon a Vision-Language Model (VLM), more\neffectively utilize multi-frame observations for action generation. This\nsuggests that VLMs' inherent temporal understanding capability enables them to\nextract more meaningful context from multi-frame observations. However, the\nhigh dimensionality of video inputs introduces significant computational\noverhead, making VLA training and inference inefficient. To address this,\nContextVLA compresses past observations into a single context token, allowing\nthe policy to efficiently leverage temporal context for action generation. Our\nexperiments show that ContextVLA consistently improves over single-frame VLAs\nand achieves the benefits of full multi-frame training but with reduced\ntraining and inference times.", "AI": {"tldr": "ContextVLA\u662f\u4e00\u79cd\u901a\u8fc7\u538b\u7f29\u591a\u5e27\u89c2\u6d4b\u4e3a\u5355\u4e2a\u4e0a\u4e0b\u6587token\u6765\u6709\u6548\u5229\u7528\u65f6\u5e8f\u4e0a\u4e0b\u6587\u63d0\u5347\u673a\u5668\u4eba\u4efb\u52a1\u6027\u80fd\u7684\u7b56\u7565\u6a21\u578b", "motivation": "\u73b0\u6709\u884c\u4e3a\u514b\u9686\u65b9\u6cd5\u5728\u4f7f\u7528\u591a\u5e27\u89c2\u6d4b\u65f6\u6027\u80fd\u63d0\u5347\u4e0d\u4e00\u81f4\uff0c\u800c\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b(VLA)\u80fd\u66f4\u6709\u6548\u5730\u5229\u7528\u591a\u5e27\u89c2\u6d4b\u751f\u6210\u52a8\u4f5c\uff0c\u4f46\u89c6\u9891\u8f93\u5165\u7684\u9ad8\u7ef4\u5ea6\u5e26\u6765\u4e86\u8ba1\u7b97\u5f00\u9500\u95ee\u9898", "method": "\u5c06\u8fc7\u53bb\u7684\u89c2\u6d4b\u538b\u7f29\u6210\u5355\u4e2a\u4e0a\u4e0b\u6587token\uff0c\u4f7f\u7b56\u7565\u80fd\u591f\u9ad8\u6548\u5229\u7528\u65f6\u5e8f\u4e0a\u4e0b\u6587\u751f\u6210\u52a8\u4f5c\uff0c\u540c\u65f6\u51cf\u5c11\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u95f4", "result": "ContextVLA\u76f8\u6bd4\u5355\u5e27VLA\u6301\u7eed\u6539\u8fdb\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u5b8c\u6574\u591a\u5e27\u8bad\u7ec3\u7684\u4f18\u52bf\u4f46\u51cf\u5c11\u4e86\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u95f4", "conclusion": "ContextVLA\u901a\u8fc7\u6709\u6548\u538b\u7f29\u591a\u5e27\u89c2\u6d4b\uff0c\u5728\u4fdd\u6301VLA\u6a21\u578b\u65f6\u5e8f\u7406\u89e3\u80fd\u529b\u7684\u540c\u65f6\u89e3\u51b3\u4e86\u8ba1\u7b97\u6548\u7387\u95ee\u9898"}}
{"id": "2510.04093", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04093", "abs": "https://arxiv.org/abs/2510.04093", "authors": ["Guixian Zhang", "Guan Yuan", "Ziqi Xu", "Yanmei Zhang", "Zhenyun Deng", "Debo Cheng"], "title": "Harnessing LLM for Noise-Robust Cognitive Diagnosis in Web-Based Intelligent Education Systems", "comment": null, "summary": "Cognitive diagnostics in the Web-based Intelligent Education System (WIES)\naims to assess students' mastery of knowledge concepts from heterogeneous,\nnoisy interactions. Recent work has tried to utilize Large Language Models\n(LLMs) for cognitive diagnosis, yet LLMs struggle with structured data and are\nprone to noise-induced misjudgments. Specially, WIES's open environment\ncontinuously attracts new students and produces vast amounts of response logs,\nexacerbating the data imbalance and noise issues inherent in traditional\neducational systems. To address these challenges, we propose DLLM, a\nDiffusion-based LLM framework for noise-robust cognitive diagnosis. DLLM first\nconstructs independent subgraphs based on response correctness, then applies\nrelation augmentation alignment module to mitigate data imbalance. The two\nsubgraph representations are then fused and aligned with LLM-derived,\nsemantically augmented representations. Importantly, before each alignment\nstep, DLLM employs a two-stage denoising diffusion module to eliminate\nintrinsic noise while assisting structural representation alignment.\nSpecifically, unconditional denoising diffusion first removes erroneous\ninformation, followed by conditional denoising diffusion based on graph-guided\nto eliminate misleading information. Finally, the noise-robust representation\nthat integrates semantic knowledge and structural information is fed into\nexisting cognitive diagnosis models for prediction. Experimental results on\nthree publicly available web-based educational platform datasets demonstrate\nthat our DLLM achieves optimal predictive performance across varying noise\nlevels, which demonstrates that DLLM achieves noise robustness while\neffectively leveraging semantic knowledge from LLM.", "AI": {"tldr": "DLLM\u662f\u4e00\u4e2a\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684LLM\u6846\u67b6\uff0c\u7528\u4e8e\u7f51\u7edc\u6559\u80b2\u7cfb\u7edf\u4e2d\u7684\u566a\u58f0\u9c81\u68d2\u8ba4\u77e5\u8bca\u65ad\uff0c\u901a\u8fc7\u6784\u5efa\u5b50\u56fe\u3001\u5173\u7cfb\u589e\u5f3a\u5bf9\u9f50\u548c\u4e24\u9636\u6bb5\u53bb\u566a\u6269\u6563\u6a21\u5757\u6765\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\u548c\u566a\u58f0\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u7f51\u7edc\u6559\u80b2\u7cfb\u7edf\u4e2d\u5f02\u6784\u566a\u58f0\u4ea4\u4e92\u6570\u636e\u5bfc\u81f4\u7684\u8ba4\u77e5\u8bca\u65ad\u56f0\u96be\uff0c\u7279\u522b\u662fLLM\u5728\u5904\u7406\u7ed3\u6784\u5316\u6570\u636e\u548c\u566a\u58f0\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4ee5\u53ca\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "method": "\u9996\u5148\u57fa\u4e8e\u7b54\u9898\u6b63\u786e\u6027\u6784\u5efa\u72ec\u7acb\u5b50\u56fe\uff0c\u5e94\u7528\u5173\u7cfb\u589e\u5f3a\u5bf9\u9f50\u7f13\u89e3\u6570\u636e\u4e0d\u5e73\u8861\uff1b\u7136\u540e\u878d\u5408\u5b50\u56fe\u8868\u793a\u5e76\u4e0eLLM\u8bed\u4e49\u589e\u5f3a\u8868\u793a\u5bf9\u9f50\uff1b\u91c7\u7528\u4e24\u9636\u6bb5\u53bb\u566a\u6269\u6563\u6a21\u5757\uff08\u65e0\u6761\u4ef6\u53bb\u566a\u548c\u57fa\u4e8e\u56fe\u5f15\u5bfc\u7684\u6761\u4ef6\u53bb\u566a\uff09\u6d88\u9664\u566a\u58f0\u5e76\u8f85\u52a9\u7ed3\u6784\u8868\u793a\u5bf9\u9f50\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u7f51\u7edc\u6559\u80b2\u5e73\u53f0\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDLLM\u5728\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\u4e0b\u5747\u53d6\u5f97\u6700\u4f18\u9884\u6d4b\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u566a\u58f0\u9c81\u68d2\u6027\u5e76\u6709\u6548\u5229\u7528\u4e86LLM\u7684\u8bed\u4e49\u77e5\u8bc6\u3002", "conclusion": "DLLM\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u7f51\u7edc\u6559\u80b2\u7cfb\u7edf\u4e2d\u8ba4\u77e5\u8bca\u65ad\u7684\u566a\u58f0\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u548cLLM\u7684\u6709\u6548\u7ed3\u5408\uff0c\u5728\u4fdd\u6301\u8bed\u4e49\u77e5\u8bc6\u5229\u7528\u7684\u540c\u65f6\u63d0\u5347\u4e86\u8bca\u65ad\u51c6\u786e\u6027\u3002"}}
{"id": "2510.04278", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04278", "abs": "https://arxiv.org/abs/2510.04278", "authors": ["Peiwen Yang", "Weisong Wen", "Runqiu Yang", "Yuanyuan Zhang", "Jiahao Hu", "Yingming Chen", "Naigui Xiao", "Jiaqi Zhao"], "title": "Integrated Planning and Control on Manifolds: Factor Graph Representation and Toolkit", "comment": null, "summary": "Model predictive control (MPC) faces significant limitations when applied to\nsystems evolving on nonlinear manifolds, such as robotic attitude dynamics and\nconstrained motion planning, where traditional Euclidean formulations struggle\nwith singularities, over-parameterization, and poor convergence. To overcome\nthese challenges, this paper introduces FactorMPC, a factor-graph based MPC\ntoolkit that unifies system dynamics, constraints, and objectives into a\nmodular, user-friendly, and efficient optimization structure. Our approach\nnatively supports manifold-valued states with Gaussian uncertainties modeled in\ntangent spaces. By exploiting the sparsity and probabilistic structure of\nfactor graphs, the toolkit achieves real-time performance even for\nhigh-dimensional systems with complex constraints. The velocity-extended\non-manifold control barrier function (CBF)-based obstacle avoidance factors are\ndesigned for safety-critical applications. By bridging graphical models with\nsafety-critical MPC, our work offers a scalable and geometrically consistent\nframework for integrated planning and control. The simulations and experimental\nresults on the quadrotor demonstrate superior trajectory tracking and obstacle\navoidance performance compared to baseline methods. To foster research\nreproducibility, we have provided open-source implementation offering\nplug-and-play factors.", "AI": {"tldr": "FactorMPC\u662f\u4e00\u4e2a\u57fa\u4e8e\u56e0\u5b50\u56fe\u7684MPC\u5de5\u5177\u5305\uff0c\u4e13\u95e8\u7528\u4e8e\u5904\u7406\u975e\u7ebf\u6027\u6d41\u5f62\u4e0a\u7684\u7cfb\u7edf\u63a7\u5236\u95ee\u9898\uff0c\u5982\u673a\u5668\u4eba\u59ff\u6001\u52a8\u529b\u5b66\u548c\u7ea6\u675f\u8fd0\u52a8\u89c4\u5212\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u4f18\u5316\u7ed3\u6784\u5b9e\u73b0\u5b9e\u65f6\u6027\u80fd\u548c\u5b89\u5168\u907f\u969c\u3002", "motivation": "\u4f20\u7edfMPC\u5728\u5904\u7406\u975e\u7ebf\u6027\u6d41\u5f62\u7cfb\u7edf\u65f6\u9762\u4e34\u5947\u5f02\u6027\u3001\u8fc7\u53c2\u6570\u5316\u548c\u6536\u655b\u56f0\u96be\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u51e0\u4f55\u4e00\u81f4\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u56e0\u5b50\u56fe\u65b9\u6cd5\uff0c\u5c06\u7cfb\u7edf\u52a8\u529b\u5b66\u3001\u7ea6\u675f\u548c\u76ee\u6807\u7edf\u4e00\u5230\u6a21\u5757\u5316\u4f18\u5316\u7ed3\u6784\u4e2d\uff0c\u652f\u6301\u6d41\u5f62\u503c\u72b6\u6001\u548c\u5207\u7a7a\u95f4\u9ad8\u65af\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u901f\u5ea6\u6269\u5c55\u7684\u6d41\u5f62\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u8fdb\u884c\u5b89\u5168\u907f\u969c\u3002", "result": "\u5728\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u4e0a\u7684\u4eff\u771f\u548c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0cFactorMPC\u5728\u8f68\u8ff9\u8ddf\u8e2a\u548c\u907f\u969c\u6027\u80fd\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "FactorMPC\u901a\u8fc7\u5c06\u56fe\u6a21\u578b\u4e0e\u5b89\u5168\u5173\u952eMPC\u76f8\u7ed3\u5408\uff0c\u4e3a\u96c6\u6210\u89c4\u5212\u4e0e\u63a7\u5236\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u51e0\u4f55\u4e00\u81f4\u7684\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u5b9e\u73b0\u4ee5\u4fc3\u8fdb\u7814\u7a76\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2510.04097", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04097", "abs": "https://arxiv.org/abs/2510.04097", "authors": ["Peichao Lai", "Jinhui Zhuang", "Kexuan Zhang", "Ningchang Xiong", "Shengjie Wang", "Yanwei Xu", "Chong Chen", "Yilei Wang", "Bin Cui"], "title": "WebRenderBench: Enhancing Web Interface Generation through Layout-Style Consistency and Reinforcement Learning", "comment": null, "summary": "Automating the conversion of UI images into web code is a critical task for\nfront-end development and rapid prototyping. Advances in multimodal large\nlanguage models (MLLMs) have made WebUI-to-Code increasingly feasible, yet\nexisting benchmarks remain limited in data diversity and evaluation\nreliability. To address these issues, we present WebRenderBench, a large-scale\nbenchmark of 22.5k webpages collected from real-world portal sites, offering\ngreater diversity, complexity, and realism than prior benchmarks. We further\npropose a novel evaluation metric that measures layout and style consistency\nfrom the final rendered pages. Unlike vision-based methods that rely on costly\nLLM reasoning or structure-based comparisons vulnerable to noise and asymmetry,\nour approach enables more efficient, objective, and reliable UI quality\nassessment. Finally, we introduce the Automated Layout and Style Inspection\nAgent (ALISA), which integrates this metric into reinforcement learning as a\nreward signal to enhance training on crawled asymmetric webpages. Experiments\nshow that ALISA significantly boosts generation performance, achieving\nstate-of-the-art results across multiple metrics.", "AI": {"tldr": "\u63d0\u51fa\u4e86WebRenderBench\u57fa\u51c6\u6d4b\u8bd5\u548cALISA\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdbUI\u56fe\u50cf\u5230\u7f51\u9875\u4ee3\u7801\u7684\u8f6c\u6362\u8bc4\u4f30\u548c\u8bad\u7ec3\u3002", "motivation": "\u73b0\u6709\u7684UI\u8f6c\u4ee3\u7801\u57fa\u51c6\u6d4b\u8bd5\u5728\u6570\u636e\u591a\u6837\u6027\u548c\u8bc4\u4f30\u53ef\u9760\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u771f\u5b9e\u3001\u591a\u6837\u5316\u7684\u6570\u636e\u96c6\u548c\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b22.5k\u4e2a\u771f\u5b9e\u7f51\u9875\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5WebRenderBench\uff0c\u63d0\u51fa\u57fa\u4e8e\u6700\u7ec8\u6e32\u67d3\u9875\u9762\u7684\u5e03\u5c40\u548c\u6837\u5f0f\u4e00\u81f4\u6027\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u5f00\u53d1\u4e86ALISA\u667a\u80fd\u4f53\u5c06\u8be5\u6307\u6807\u4f5c\u4e3a\u5f3a\u5316\u5b66\u4e60\u7684\u5956\u52b1\u4fe1\u53f7\u3002", "result": "ALISA\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "WebRenderBench\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u591a\u6837\u7684\u8bc4\u4f30\u73af\u5883\uff0cALISA\u901a\u8fc7\u96c6\u6210\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u6709\u6548\u63d0\u5347\u4e86UI\u8f6c\u4ee3\u7801\u7684\u8d28\u91cf\u548c\u6027\u80fd\u3002"}}
{"id": "2510.04353", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04353", "abs": "https://arxiv.org/abs/2510.04353", "authors": ["Stephen McCrory", "Romeo Orsolino", "Dhruv Thanki", "Luigi Penco", "Robert Griffin"], "title": "Stability-Aware Retargeting for Humanoid Multi-Contact Teleoperation", "comment": null, "summary": "Teleoperation is a powerful method to generate reference motions and enable\nhumanoid robots to perform a broad range of tasks. However, teleoperation\nbecomes challenging when using hand contacts and non-coplanar surfaces, often\nleading to motor torque saturation or loss of stability through slipping. We\npropose a centroidal stability-based retargeting method that dynamically\nadjusts contact points and posture during teleoperation to enhance stability in\nthese difficult scenarios. Central to our approach is an efficient analytical\ncalculation of the stability margin gradient. This gradient is used to identify\nscenarios for which stability is highly sensitive to teleoperation setpoints\nand inform the local adjustment of these setpoints. We validate the framework\nin simulation and hardware by teleoperating manipulation tasks on a humanoid,\ndemonstrating increased stability margins. We also demonstrate empirically that\nhigher stability margins correlate with improved impulse resilience and joint\ntorque margin.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d28\u5fc3\u7a33\u5b9a\u6027\u7684\u91cd\u5b9a\u5411\u65b9\u6cd5\uff0c\u5728\u9065\u64cd\u4f5c\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8c03\u6574\u63a5\u89e6\u70b9\u548c\u59ff\u6001\uff0c\u4ee5\u589e\u5f3a\u5728\u590d\u6742\u63a5\u89e6\u573a\u666f\u4e0b\u7684\u7a33\u5b9a\u6027\u3002", "motivation": "\u9065\u64cd\u4f5c\u5728\u6d89\u53ca\u624b\u90e8\u63a5\u89e6\u548c\u975e\u5171\u9762\u8868\u9762\u65f6\u53d8\u5f97\u56f0\u96be\uff0c\u5e38\u5bfc\u81f4\u7535\u673a\u626d\u77e9\u9971\u548c\u6216\u901a\u8fc7\u6ed1\u52a8\u5931\u53bb\u7a33\u5b9a\u6027\u3002", "method": "\u4f7f\u7528\u9ad8\u6548\u7684\u89e3\u6790\u8ba1\u7b97\u7a33\u5b9a\u6027\u88d5\u5ea6\u68af\u5ea6\uff0c\u8bc6\u522b\u5bf9\u9065\u64cd\u4f5c\u8bbe\u5b9a\u70b9\u9ad8\u5ea6\u654f\u611f\u7684\u573a\u666f\uff0c\u5e76\u5c40\u90e8\u8c03\u6574\u8fd9\u4e9b\u8bbe\u5b9a\u70b9\u3002", "result": "\u5728\u4eff\u771f\u548c\u786c\u4ef6\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u589e\u52a0\u7a33\u5b9a\u6027\u88d5\u5ea6\uff0c\u5e76\u7ecf\u9a8c\u8bc1\u660e\u66f4\u9ad8\u7a33\u5b9a\u6027\u88d5\u5ea6\u4e0e\u6539\u8fdb\u7684\u51b2\u51fb\u6062\u590d\u80fd\u529b\u548c\u5173\u8282\u626d\u77e9\u88d5\u5ea6\u76f8\u5173\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u8d28\u5fc3\u7a33\u5b9a\u6027\u7684\u91cd\u5b9a\u5411\u65b9\u6cd5\u6709\u6548\u63d0\u9ad8\u4e86\u4eba\u5f62\u673a\u5668\u4eba\u5728\u590d\u6742\u63a5\u89e6\u573a\u666f\u4e0b\u7684\u7a33\u5b9a\u6027\u548c\u63a7\u5236\u6027\u80fd\u3002"}}
{"id": "2510.04116", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04116", "abs": "https://arxiv.org/abs/2510.04116", "authors": ["Ziying Zhang", "Yaqing Wang", "Quanming Yao"], "title": "Searching Meta Reasoning Skeleton to Guide LLM Reasoning", "comment": null, "summary": "Meta reasoning behaviors work as a skeleton to guide large language model\n(LLM) reasoning, thus help to improve reasoning performance. However, prior\nresearches implement meta reasoning skeleton with manually designed structure,\nlimiting ability to adapt to query-specific requirement and capture intricate\nlogical dependency among reasoning steps. To deal with the challenges, we\nrepresent meta reasoning skeleton with directed acyclic graph (DAG) to unify\nskeletons proposed in prior works and model intricate logical dependency. Then\nwe propose AutoMR, a framework that searches for query-aware meta reasoning\nskeleton automatically inspired by automated machine learning (AutoML).\nSpecifically, we construct search space based on DAG representation of skeleton\nand then formulate the search problem. We design a dynamic skeleton sampling\nalgorithm by expanding meta reasoning skeleton along with reasoning context at\ninference time. This algorithm can derive any meta reasoning skeleton in search\nspace efficiently and adapt skeleton to evolving base reasoning context, thus\nenable efficient query-aware skeleton search. We conduct experiments on\nextensive benchmark datasets. Experimental results show that AutoMR achieves\nbetter reasoning performance than previous works broadly.", "AI": {"tldr": "AutoMR\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u641c\u7d22\u67e5\u8be2\u611f\u77e5\u7684\u5143\u63a8\u7406\u9aa8\u67b6\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4f7f\u7528\u6709\u5411\u65e0\u73af\u56fe\u8868\u793a\u63a8\u7406\u9aa8\u67b6\uff0c\u5e76\u91c7\u7528\u52a8\u6001\u91c7\u6837\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6548\u641c\u7d22\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4f7f\u7528\u624b\u52a8\u8bbe\u8ba1\u7684\u5143\u63a8\u7406\u9aa8\u67b6\u7ed3\u6784\uff0c\u65e0\u6cd5\u9002\u5e94\u67e5\u8be2\u7279\u5b9a\u9700\u6c42\uff0c\u4e5f\u96be\u4ee5\u6355\u6349\u63a8\u7406\u6b65\u9aa4\u95f4\u590d\u6742\u7684\u903b\u8f91\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u63d0\u51faAutoMR\u6846\u67b6\uff1a1\uff09\u7528\u6709\u5411\u65e0\u73af\u56fe\u7edf\u4e00\u8868\u793a\u5143\u63a8\u7406\u9aa8\u67b6\uff1b2\uff09\u6784\u5efa\u641c\u7d22\u7a7a\u95f4\u5e76\u5b9a\u4e49\u641c\u7d22\u95ee\u9898\uff1b3\uff09\u8bbe\u8ba1\u52a8\u6001\u9aa8\u67b6\u91c7\u6837\u7b97\u6cd5\uff0c\u5728\u63a8\u7406\u65f6\u6839\u636e\u4e0a\u4e0b\u6587\u6269\u5c55\u9aa8\u67b6\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAutoMR\u76f8\u6bd4\u5148\u524d\u5de5\u4f5c\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "AutoMR\u901a\u8fc7\u81ea\u52a8\u641c\u7d22\u67e5\u8be2\u611f\u77e5\u7684\u5143\u63a8\u7406\u9aa8\u67b6\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u624b\u52a8\u8bbe\u8ba1\u9aa8\u67b6\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.04354", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.04354", "abs": "https://arxiv.org/abs/2510.04354", "authors": ["Apurva Badithela", "David Snyder", "Lihan Zha", "Joseph Mikhail", "Matthew O'Kelly", "Anushri Dixit", "Anirudha Majumdar"], "title": "Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators", "comment": null, "summary": "Rapid progress in imitation learning, foundation models, and large-scale\ndatasets has led to robot manipulation policies that generalize to a wide-range\nof tasks and environments. However, rigorous evaluation of these policies\nremains a challenge. Typically in practice, robot policies are often evaluated\non a small number of hardware trials without any statistical assurances. We\npresent SureSim, a framework to augment large-scale simulation with relatively\nsmall-scale real-world testing to provide reliable inferences on the real-world\nperformance of a policy. Our key idea is to formalize the problem of combining\nreal and simulation evaluations as a prediction-powered inference problem, in\nwhich a small number of paired real and simulation evaluations are used to\nrectify bias in large-scale simulation. We then leverage non-asymptotic mean\nestimation algorithms to provide confidence intervals on mean policy\nperformance. Using physics-based simulation, we evaluate both diffusion policy\nand multi-task fine-tuned \\(\\pi_0\\) on a joint distribution of objects and\ninitial conditions, and find that our approach saves over \\(20-25\\%\\) of\nhardware evaluation effort to achieve similar bounds on policy performance.", "AI": {"tldr": "SureSim\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u5c0f\u89c4\u6a21\u771f\u5b9e\u4e16\u754c\u6d4b\u8bd5\u548c\u5927\u89c4\u6a21\u4eff\u771f\uff0c\u4e3a\u673a\u5668\u4eba\u7b56\u7565\u6027\u80fd\u63d0\u4f9b\u53ef\u9760\u7684\u7edf\u8ba1\u63a8\u65ad\uff0c\u53ef\u8282\u770120-25%\u7684\u786c\u4ef6\u8bc4\u4f30\u6210\u672c\u3002", "motivation": "\u5f53\u524d\u673a\u5668\u4eba\u7b56\u7565\u8bc4\u4f30\u901a\u5e38\u57fa\u4e8e\u5c11\u91cf\u786c\u4ef6\u8bd5\u9a8c\uff0c\u7f3a\u4e4f\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5c06\u771f\u5b9e\u4e0e\u4eff\u771f\u8bc4\u4f30\u7ed3\u5408\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u9884\u6d4b\u9a71\u52a8\u7684\u63a8\u7406\u95ee\u9898\uff0c\u5229\u7528\u5c11\u91cf\u914d\u5bf9\u771f\u5b9e\u548c\u4eff\u771f\u8bc4\u4f30\u6765\u6821\u6b63\u5927\u89c4\u6a21\u4eff\u771f\u7684\u504f\u5dee\uff0c\u5e76\u91c7\u7528\u975e\u6e10\u8fd1\u5747\u503c\u4f30\u8ba1\u7b97\u6cd5\u63d0\u4f9b\u7f6e\u4fe1\u533a\u95f4\u3002", "result": "\u5728\u7269\u7406\u4eff\u771f\u4e2d\u8bc4\u4f30\u6269\u6563\u7b56\u7565\u548c\u591a\u4efb\u52a1\u5fae\u8c03\u7b56\u7565\uff0c\u8be5\u65b9\u6cd5\u53ef\u8282\u770120-25%\u7684\u786c\u4ef6\u8bc4\u4f30\u5de5\u4f5c\u91cf\uff0c\u540c\u65f6\u8fbe\u5230\u76f8\u4f3c\u7684\u6027\u80fd\u8fb9\u754c\u3002", "conclusion": "SureSim\u6846\u67b6\u80fd\u591f\u6709\u6548\u7ed3\u5408\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u6d4b\u8bd5\uff0c\u4e3a\u673a\u5668\u4eba\u7b56\u7565\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u7edf\u8ba1\u53ef\u9760\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04128", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04128", "abs": "https://arxiv.org/abs/2510.04128", "authors": ["Dmitrii Troitskii", "Koyena Pal", "Chris Wendler", "Callum Stuart McDougall", "Neel Nanda"], "title": "Internal states before wait modulate reasoning patterns", "comment": "Accepted to EMNLP Findings 2025", "summary": "Prior work has shown that a significant driver of performance in reasoning\nmodels is their ability to reason and self-correct. A distinctive marker in\nthese reasoning traces is the token wait, which often signals reasoning\nbehavior such as backtracking. Despite being such a complex behavior, little is\nunderstood of exactly why models do or do not decide to reason in this\nparticular manner, which limits our understanding of what makes a reasoning\nmodel so effective. In this work, we address the question whether model's\nlatents preceding wait tokens contain relevant information for modulating the\nsubsequent reasoning process. We train crosscoders at multiple layers of\nDeepSeek-R1-Distill-Llama-8B and its base version, and introduce a latent\nattribution technique in the crosscoder setting. We locate a small set of\nfeatures relevant for promoting/suppressing wait tokens' probabilities.\nFinally, through a targeted series of experiments analyzing max activating\nexamples and causal interventions, we show that many of our identified features\nindeed are relevant for the reasoning process and give rise to different types\nof reasoning patterns such as restarting from the beginning, recalling prior\nknowledge, expressing uncertainty, and double-checking.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u7684\u7b49\u5f85\u6807\u8bb0\uff08wait tokens\uff09\u5305\u542b\u91cd\u8981\u7684\u63a8\u7406\u884c\u4e3a\u4fe1\u606f\uff0c\u901a\u8fc7\u4ea4\u53c9\u7f16\u7801\u5668\u548c\u6f5c\u5728\u5f52\u56e0\u6280\u672f\u8bc6\u522b\u51fa\u5f71\u54cd\u7b49\u5f85\u6807\u8bb0\u6982\u7387\u7684\u5173\u952e\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u4e0e\u4e0d\u540c\u7684\u63a8\u7406\u6a21\u5f0f\u76f8\u5173\u3002", "motivation": "\u7406\u89e3\u4e3a\u4ec0\u4e48\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4f1a\u4ea7\u751f\u7b49\u5f85\u6807\u8bb0\u8fd9\u4e00\u590d\u6742\u884c\u4e3a\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u6807\u8bb0\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u7684\u63a8\u7406\u6548\u679c\uff0c\u4ece\u800c\u63ed\u793a\u63a8\u7406\u6a21\u578b\u9ad8\u6548\u5de5\u4f5c\u7684\u673a\u5236\u3002", "method": "\u5728DeepSeek-R1-Distill-Llama-8B\u53ca\u5176\u57fa\u7840\u7248\u672c\u7684\u591a\u5c42\u4e0a\u8bad\u7ec3\u4ea4\u53c9\u7f16\u7801\u5668\uff0c\u5f15\u5165\u6f5c\u5728\u5f52\u56e0\u6280\u672f\u6765\u5b9a\u4f4d\u5f71\u54cd\u7b49\u5f85\u6807\u8bb0\u6982\u7387\u7684\u5173\u952e\u7279\u5f81\u96c6\u3002", "result": "\u8bc6\u522b\u51fa\u4e00\u7ec4\u5c0f\u89c4\u6a21\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u80fd\u591f\u4fc3\u8fdb\u6216\u6291\u5236\u7b49\u5f85\u6807\u8bb0\u7684\u6982\u7387\uff0c\u5e76\u901a\u8fc7\u6700\u5927\u6fc0\u6d3b\u793a\u4f8b\u548c\u56e0\u679c\u5e72\u9884\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u7279\u5f81\u786e\u5b9e\u4e0e\u63a8\u7406\u8fc7\u7a0b\u76f8\u5173\uff0c\u4ea7\u751f\u4e0d\u540c\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "conclusion": "\u6a21\u578b\u5728\u7b49\u5f85\u6807\u8bb0\u4e4b\u524d\u7684\u6f5c\u5728\u72b6\u6001\u5305\u542b\u8c03\u8282\u540e\u7eed\u63a8\u7406\u8fc7\u7a0b\u7684\u76f8\u5173\u4fe1\u606f\uff0c\u8fd9\u4e9b\u4fe1\u606f\u4e0e\u91cd\u65b0\u5f00\u59cb\u3001\u56de\u5fc6\u5148\u9a8c\u77e5\u8bc6\u3001\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\u548c\u53cc\u91cd\u68c0\u67e5\u7b49\u63a8\u7406\u6a21\u5f0f\u76f8\u5173\u3002"}}
{"id": "2510.04436", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.04436", "abs": "https://arxiv.org/abs/2510.04436", "authors": ["Jushan Chen", "Santiago Paternain"], "title": "PAD-TRO: Projection-Augmented Diffusion for Direct Trajectory Optimization", "comment": null, "summary": "Recently, diffusion models have gained popularity and attention in trajectory\noptimization due to their capability of modeling multi-modal probability\ndistributions. However, addressing nonlinear equality constraints, i.e, dynamic\nfeasi- bility, remains a great challenge in diffusion-based trajectory\noptimization. Recent diffusion-based trajectory optimization frameworks rely on\na single-shooting style approach where the denoised control sequence is applied\nto forward propagate the dynamical system, which cannot explicitly enforce\nconstraints on the states and frequently leads to sub-optimal solutions. In\nthis work, we propose a novel direct trajectory optimization approach via\nmodel-based diffusion, which directly generates a sequence of states. To ensure\ndynamic feasibility, we propose a gradient-free projection mechanism that is\nincorporated into the reverse diffusion process. Our results show that,\ncompared to a recent state-of-the-art baseline, our approach leads to zero\ndynamic feasibility error and approximately 4x higher success rate in a\nquadrotor waypoint navigation scenario involving dense static obstacles.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u6269\u6563\u7684\u76f4\u63a5\u8f68\u8ff9\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u68af\u5ea6\u81ea\u7531\u6295\u5f71\u673a\u5236\u5728\u53cd\u5411\u6269\u6563\u8fc7\u7a0b\u4e2d\u786e\u4fdd\u52a8\u6001\u53ef\u884c\u6027\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u4e86\u96f6\u52a8\u6001\u53ef\u884c\u6027\u8bef\u5dee\u548c4\u500d\u6210\u529f\u7387\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u8f68\u8ff9\u4f18\u5316\u65b9\u6cd5\u91c7\u7528\u5355\u6b21\u5c04\u51fb\u65b9\u5f0f\uff0c\u65e0\u6cd5\u663e\u5f0f\u5f3a\u5236\u6267\u884c\u72b6\u6001\u7ea6\u675f\uff0c\u7ecf\u5e38\u5bfc\u81f4\u6b21\u4f18\u89e3\u548c\u52a8\u6001\u53ef\u884c\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u76f4\u63a5\u8f68\u8ff9\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u6269\u6563\u76f4\u63a5\u751f\u6210\u72b6\u6001\u5e8f\u5217\uff0c\u5e76\u5728\u53cd\u5411\u6269\u6563\u8fc7\u7a0b\u4e2d\u878d\u5165\u68af\u5ea6\u81ea\u7531\u6295\u5f71\u673a\u5236\u6765\u786e\u4fdd\u52a8\u6001\u53ef\u884c\u6027\u3002", "result": "\u5728\u56db\u65cb\u7ffc\u822a\u70b9\u5bfc\u822a\u573a\u666f\u4e2d\uff0c\u76f8\u6bd4\u73b0\u6709\u6700\u4f18\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u96f6\u52a8\u6001\u53ef\u884c\u6027\u8bef\u5dee\u548c\u7ea64\u500d\u7684\u6210\u529f\u7387\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u6269\u6563\u6a21\u578b\u8f68\u8ff9\u4f18\u5316\u4e2d\u7684\u52a8\u6001\u53ef\u884c\u6027\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8f68\u8ff9\u4f18\u5316\u7684\u6027\u80fd\u3002"}}
{"id": "2510.04140", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04140", "abs": "https://arxiv.org/abs/2510.04140", "authors": ["Zishang Jiang", "Jinyi Han", "Tingyun Li", "Xinyi Wang", "Sihang Jiang", "Jiaqing Liang", "Zhaoqian Dai", "Shuguang Ma", "Fei Yu", "Yanghua Xiao"], "title": "Selective Expert Guidance for Effective and Diverse Exploration in Reinforcement Learning of LLMs", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has become a widely\nadopted technique for enhancing the reasoning ability of Large Language Models\n(LLMs). However, the effectiveness of RLVR strongly depends on the capability\nof base models. This issue arises because it requires the model to have\nsufficient capability to perform high-quality exploration, which involves both\neffectiveness and diversity. Unfortunately, existing methods address this issue\nby imitating expert trajectories, which improve effectiveness but neglect\ndiversity. To address this, we argue that the expert only needs to provide\nguidance only at critical decision points rather than the entire reasoning\npath. Based on this insight, we propose MENTOR: Mixed-policy Expert Navigation\nfor Token-level Optimization of Reasoning, a framework that provides expert\nguidance only at critical decision points to perform effective and diverse\nexploration in RLVR. Extensive experiments show that MENTOR enables models\ncapture the essence of expert strategies rather than surface imitation, thereby\nperforming high-quality exploration and achieving superior overall performance.\nOur code is available online.", "AI": {"tldr": "\u63d0\u51fa\u4e86MENTOR\u6846\u67b6\uff0c\u901a\u8fc7\u53ea\u5728\u5173\u952e\u51b3\u7b56\u70b9\u63d0\u4f9b\u4e13\u5bb6\u6307\u5bfc\uff0c\u5728\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\u4e2d\u5b9e\u73b0\u6709\u6548\u4e14\u591a\u6837\u5316\u7684\u63a2\u7d22\u3002", "motivation": "\u73b0\u6709RLVR\u65b9\u6cd5\u4f9d\u8d56\u6a21\u4eff\u4e13\u5bb6\u8f68\u8ff9\uff0c\u8fd9\u867d\u7136\u63d0\u9ad8\u4e86\u6709\u6548\u6027\u4f46\u5ffd\u89c6\u4e86\u591a\u6837\u6027\uff0c\u800c\u9ad8\u8d28\u91cf\u7684\u63a2\u7d22\u9700\u8981\u4e24\u8005\u517c\u5907\u3002", "method": "MENTOR\u6846\u67b6\u91c7\u7528\u6df7\u5408\u7b56\u7565\u4e13\u5bb6\u5bfc\u822a\uff0c\u4ec5\u5728\u5173\u952e\u51b3\u7b56\u70b9\u63d0\u4f9b\u4e13\u5bb6\u6307\u5bfc\uff0c\u8fdb\u884ctoken\u7ea7\u522b\u7684\u63a8\u7406\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMENTOR\u80fd\u591f\u6355\u6349\u4e13\u5bb6\u7b56\u7565\u7684\u672c\u8d28\u800c\u975e\u8868\u9762\u6a21\u4eff\uff0c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u63a2\u7d22\u5e76\u83b7\u5f97\u4f18\u8d8a\u7684\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "\u5728\u5173\u952e\u51b3\u7b56\u70b9\u63d0\u4f9b\u4e13\u5bb6\u6307\u5bfc\u6bd4\u5b8c\u6574\u8f68\u8ff9\u6a21\u4eff\u66f4\u6709\u6548\uff0cMENTOR\u6846\u67b6\u5728RLVR\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u63a2\u7d22\u8d28\u91cf\u548c\u6027\u80fd\u3002"}}
{"id": "2510.04509", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.04509", "abs": "https://arxiv.org/abs/2510.04509", "authors": ["Huanqing Wang", "Kaixiang Zhang", "Kyungjoon Lee", "Yu Mei", "Vaibhav Srivastava", "Jun Sheng", "Ziyou Song", "Zhaojian Li"], "title": "Velocity-Form Data-Enabled Predictive Control of Soft Robots under Unknown External Payloads", "comment": null, "summary": "Data-driven control methods such as data-enabled predictive control (DeePC)\nhave shown strong potential in efficient control of soft robots without\nexplicit parametric models. However, in object manipulation tasks, unknown\nexternal payloads and disturbances can significantly alter the system dynamics\nand behavior, leading to offset error and degraded control performance. In this\npaper, we present a novel velocity-form DeePC framework that achieves robust\nand optimal control of soft robots under unknown payloads. The proposed\nframework leverages input-output data in an incremental representation to\nmitigate performance degradation induced by unknown payloads, eliminating the\nneed for weighted datasets or disturbance estimators. We validate the method\nexperimentally on a planar soft robot and demonstrate its superior performance\ncompared to standard DeePC in scenarios involving unknown payloads.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u901f\u5ea6\u5f62\u5f0f\u7684\u6570\u636e\u9a71\u52a8\u9884\u6d4b\u63a7\u5236\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u672a\u77e5\u8d1f\u8f7d\u4e0b\u5b9e\u73b0\u8f6f\u4f53\u673a\u5668\u4eba\u7684\u9c81\u68d2\u548c\u6700\u4f18\u63a7\u5236\u3002", "motivation": "\u5728\u8f6f\u4f53\u673a\u5668\u4eba\u63a7\u5236\u4e2d\uff0c\u672a\u77e5\u5916\u90e8\u8d1f\u8f7d\u548c\u5e72\u6270\u4f1a\u663e\u8457\u6539\u53d8\u7cfb\u7edf\u52a8\u6001\uff0c\u5bfc\u81f4\u504f\u79fb\u8bef\u5dee\u548c\u63a7\u5236\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u5229\u7528\u589e\u91cf\u8868\u793a\u7684\u8f93\u5165\u8f93\u51fa\u6570\u636e\u6765\u51cf\u8f7b\u672a\u77e5\u8d1f\u8f7d\u5f15\u8d77\u7684\u6027\u80fd\u9000\u5316\uff0c\u65e0\u9700\u52a0\u6743\u6570\u636e\u96c6\u6216\u5e72\u6270\u4f30\u8ba1\u5668\u3002", "result": "\u5728\u5e73\u9762\u8f6f\u4f53\u673a\u5668\u4eba\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6d89\u53ca\u672a\u77e5\u8d1f\u8f7d\u7684\u573a\u666f\u4e2d\u6bd4\u6807\u51c6DeePC\u5177\u6709\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u901f\u5ea6\u5f62\u5f0fDeePC\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u672a\u77e5\u8d1f\u8f7d\uff0c\u63d0\u9ad8\u8f6f\u4f53\u673a\u5668\u4eba\u63a7\u5236\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2510.04141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04141", "abs": "https://arxiv.org/abs/2510.04141", "authors": ["Mayank Ravishankara", "Varindra V. Persad Maharaj"], "title": "The Artificial Intelligence Cognitive Examination: A Survey on the Evolution of Multimodal Evaluation from Recognition to Reasoning", "comment": null, "summary": "This survey paper chronicles the evolution of evaluation in multimodal\nartificial intelligence (AI), framing it as a progression of increasingly\nsophisticated \"cognitive examinations.\" We argue that the field is undergoing a\nparadigm shift, moving from simple recognition tasks that test \"what\" a model\nsees, to complex reasoning benchmarks that probe \"why\" and \"how\" it\nunderstands. This evolution is driven by the saturation of older benchmarks,\nwhere high performance often masks fundamental weaknesses. We chart the journey\nfrom the foundational \"knowledge tests\" of the ImageNet era to the \"applied\nlogic and comprehension\" exams such as GQA and Visual Commonsense Reasoning\n(VCR), which were designed specifically to diagnose systemic flaws such as\nshortcut learning and failures in compositional generalization. We then survey\nthe current frontier of \"expert-level integration\" benchmarks (e.g., MMBench,\nSEED-Bench, MMMU) designed for today's powerful multimodal large language\nmodels (MLLMs), which increasingly evaluate the reasoning process itself.\nFinally, we explore the uncharted territories of evaluating abstract, creative,\nand social intelligence. We conclude that the narrative of AI evaluation is not\nmerely a history of datasets, but a continuous, adversarial process of\ndesigning better examinations that, in turn, redefine our goals for creating\ntruly intelligent systems.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e86\u591a\u6a21\u6001AI\u8bc4\u4f30\u7684\u6f14\u53d8\u5386\u7a0b\uff0c\u5c06\u5176\u63cf\u8ff0\u4e3a\u4ece\u7b80\u5355\u8bc6\u522b\u4efb\u52a1\u5230\u590d\u6742\u63a8\u7406\u57fa\u51c6\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u65e8\u5728\u8bbe\u8ba1\u66f4\u597d\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u63a8\u52a8\u771f\u6b63\u667a\u80fd\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "motivation": "\u4f20\u7edf\u57fa\u51c6\u6d4b\u8bd5\u5df2\u8d8b\u4e8e\u9971\u548c\uff0c\u9ad8\u5206\u5f80\u5f80\u63a9\u76d6\u4e86\u6a21\u578b\u7684\u57fa\u672c\u5f31\u70b9\uff0c\u9700\u8981\u66f4\u590d\u6742\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u8bca\u65ad\u7cfb\u7edf\u6027\u7f3a\u9677\u3002", "method": "\u901a\u8fc7\u5206\u6790\u8bc4\u4f30\u8303\u5f0f\u7684\u6f14\u53d8\uff1a\u4eceImageNet\u65f6\u4ee3\u7684\"\u77e5\u8bc6\u6d4b\u8bd5\"\uff0c\u5230GQA\u548cVCR\u7b49\"\u5e94\u7528\u903b\u8f91\u548c\u7406\u89e3\"\u6d4b\u8bd5\uff0c\u518d\u5230\u9488\u5bf9MLLMs\u7684\"\u4e13\u5bb6\u7ea7\u96c6\u6210\"\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5c55\u793a\u4e86\u8bc4\u4f30\u65b9\u6cd5\u5982\u4f55\u4ece\u6d4b\u8bd5\"\u6a21\u578b\u770b\u5230\u4e86\u4ec0\u4e48\"\u53d1\u5c55\u5230\u63a2\u7a76\"\u6a21\u578b\u5982\u4f55\u7406\u89e3\"\uff0c\u5e76\u5f00\u59cb\u8bc4\u4f30\u63a8\u7406\u8fc7\u7a0b\u672c\u8eab\u3002", "conclusion": "AI\u8bc4\u4f30\u4e0d\u4ec5\u662f\u6570\u636e\u96c6\u7684\u5386\u53f2\uff0c\u66f4\u662f\u4e00\u4e2a\u6301\u7eed\u5bf9\u6297\u7684\u8fc7\u7a0b\uff0c\u901a\u8fc7\u8bbe\u8ba1\u66f4\u597d\u7684\u6d4b\u8bd5\u6765\u91cd\u65b0\u5b9a\u4e49\u521b\u5efa\u771f\u6b63\u667a\u80fd\u7cfb\u7edf\u7684\u76ee\u6807\u3002"}}
{"id": "2510.04585", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04585", "abs": "https://arxiv.org/abs/2510.04585", "authors": ["Jianshu Zhou", "Jing Shu", "Tianle Pan", "Puchen Zhu", "Jiajun An", "Huayu Zhang", "Junda Huang", "Upinder Kaur", "Xin Ma", "Masayoshi Tomizuka"], "title": "Everything-Grasping (EG) Gripper: A Universal Gripper with Synergistic Suction-Grasping Capabilities for Cross-Scale and Cross-State Manipulation", "comment": "19 pages, 10 figures, journal", "summary": "Grasping objects across vastly different sizes and physical states-including\nboth solids and liquids-with a single robotic gripper remains a fundamental\nchallenge in soft robotics. We present the Everything-Grasping (EG) Gripper, a\nsoft end-effector that synergistically integrates distributed surface suction\nwith internal granular jamming, enabling cross-scale and cross-state\nmanipulation without requiring airtight sealing at the contact interface with\ntarget objects. The EG Gripper can handle objects with surface areas ranging\nfrom sub-millimeter scale 0.2 mm2 (glass bead) to over 62,000 mm2 (A4 sized\npaper and woven bag), enabling manipulation of objects nearly 3,500X smaller\nand 88X larger than its own contact area (approximated at 707 mm2 for a 30\nmm-diameter base). We further introduce a tactile sensing framework that\ncombines liquid detection and pressure-based suction feedback, enabling\nreal-time differentiation between solid and liquid targets. Guided by the\nactile-Inferred Grasping Mode Selection (TIGMS) algorithm, the gripper\nautonomously selects grasping modes based on distributed pressure and voltage\nsignals. Experiments across diverse tasks-including underwater grasping,\nfragile object handling, and liquid capture-demonstrate robust and repeatable\nperformance. To our knowledge, this is the first soft gripper to reliably grasp\nboth solid and liquid objects across scales using a unified compliant\narchitecture.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5206\u5e03\u5f0f\u8868\u9762\u5438\u9644\u548c\u5185\u90e8\u9897\u7c92\u963b\u585e\u7684\u8f6f\u4f53\u6293\u53d6\u5668\uff0c\u80fd\u591f\u8de8\u5c3a\u5ea6\u548c\u8de8\u72b6\u6001\uff08\u56fa\u4f53\u548c\u6db2\u4f53\uff09\u6293\u53d6\u7269\u4f53\uff0c\u65e0\u9700\u6c14\u5bc6\u5bc6\u5c01\u3002", "motivation": "\u89e3\u51b3\u8f6f\u4f53\u673a\u5668\u4eba\u4e2d\u5355\u4e00\u6293\u53d6\u5668\u5904\u7406\u4e0d\u540c\u5c3a\u5bf8\u548c\u7269\u7406\u72b6\u6001\uff08\u5305\u62ec\u56fa\u4f53\u548c\u6db2\u4f53\uff09\u7269\u4f53\u7684\u57fa\u672c\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86Everything-Grasping\uff08EG\uff09\u6293\u53d6\u5668\uff0c\u6574\u5408\u5206\u5e03\u5f0f\u8868\u9762\u5438\u9644\u548c\u5185\u90e8\u9897\u7c92\u963b\u585e\u673a\u5236\uff0c\u5e76\u5f15\u5165\u7ed3\u5408\u6db2\u4f53\u68c0\u6d4b\u548c\u538b\u529b\u53cd\u9988\u7684\u89e6\u89c9\u611f\u77e5\u6846\u67b6\uff0c\u4ee5\u53ca\u57fa\u4e8e\u89e6\u89c9\u63a8\u65ad\u7684\u6293\u53d6\u6a21\u5f0f\u9009\u62e9\u7b97\u6cd5\u3002", "result": "\u80fd\u591f\u6293\u53d6\u8868\u9762\u9762\u79ef\u4ece0.2 mm\u00b2\u5230\u8d85\u8fc762,000 mm\u00b2\u7684\u7269\u4f53\uff0c\u6bd4\u81ea\u8eab\u63a5\u89e6\u9762\u79ef\u5c0f3500\u500d\u548c\u592788\u500d\uff0c\u5728\u6c34\u4e0b\u6293\u53d6\u3001\u8106\u5f31\u7269\u4f53\u5904\u7406\u548c\u6db2\u4f53\u6355\u83b7\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u548c\u53ef\u91cd\u590d\u7684\u6027\u80fd\u3002", "conclusion": "\u8fd9\u662f\u7b2c\u4e00\u4e2a\u4f7f\u7528\u7edf\u4e00\u67d4\u6027\u67b6\u6784\u53ef\u9760\u6293\u53d6\u8de8\u5c3a\u5ea6\u56fa\u4f53\u548c\u6db2\u4f53\u7269\u4f53\u7684\u8f6f\u4f53\u6293\u53d6\u5668\u3002"}}
{"id": "2510.04173", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04173", "abs": "https://arxiv.org/abs/2510.04173", "authors": ["Yassine Benajiba", "Cesare Bernardis", "Vladislav Blinov", "Paul Cayet", "Hassan Chafi", "Abderrahim Fathan", "Louis Faucon", "Damien Hilloulin", "Sungpack Hong", "Ingo Kossyk", "Rhicheek Patra", "Sujith Ravi", "Jonas Schweizer", "Jyotika Singh", "Shailender Singh", "Xuelin Situ", "Weiyi Sun", "Jerry Xu", "Ying Xu"], "title": "Open Agent Specification (Agent Spec) Technical Report", "comment": null, "summary": "Open Agent Specification (Agent Spec) is a declarative language that allows\nAI agents and their workflows to be defined in a way that is compatible across\ndifferent AI frameworks, promoting portability and interoperability within AI\nAgent frameworks.\n  Agent Spec aims to resolve the challenges of fragmented agent development by\nproviding a common unified specification that allows AI agents to be designed\nonce and deployed across various frameworks, improving interoperability and\nreusability, and reducing redundant development efforts. Additionally, Agent\nSpec facilitates development tools and portability, allowing AI agents to be\ndefined independently of their execution environment and enabling teams to\nexchange solutions without implementation-specific limitations.\n  Agent Spec benefits four key groups: (i) Agent developers, who gain access to\na superset of reusable components and design patterns, enabling them to\nleverage a broader range of functionalities; (ii) Agent framework and tool\ndevelopers, who can use Agent Spec as an interchange format and therefore\nbenefit from the support of other frameworks as well as other tools; (iii)\nResearchers, who can achieve reproducible results and comparability,\nfacilitating more reliable and consistent outcomes; (iv) Enterprises, which\nbenefit from faster prototype-to-deployment, increased productivity, as well as\ngreater scalability and maintainability for their AI agent solutions. This\ntechnical report provides an overview of the technical foundations of Agent\nSpec, including motivation, benefits, and future developments.", "AI": {"tldr": "Open Agent Specification (Agent Spec) \u662f\u4e00\u79cd\u58f0\u660e\u5f0f\u8bed\u8a00\uff0c\u7528\u4e8e\u5b9a\u4e49AI\u4ee3\u7406\u53ca\u5176\u5de5\u4f5c\u6d41\uff0c\u5b9e\u73b0\u8de8AI\u6846\u67b6\u7684\u517c\u5bb9\u6027\u3001\u53ef\u79fb\u690d\u6027\u548c\u4e92\u64cd\u4f5c\u6027\u3002", "motivation": "\u89e3\u51b3AI\u4ee3\u7406\u5f00\u53d1\u788e\u7247\u5316\u95ee\u9898\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u89c4\u8303\u6807\u51c6\uff0c\u4f7fAI\u4ee3\u7406\u80fd\u591f\u4e00\u6b21\u8bbe\u8ba1\u3001\u8de8\u6846\u67b6\u90e8\u7f72\uff0c\u63d0\u9ad8\u4e92\u64cd\u4f5c\u6027\u548c\u53ef\u91cd\u7528\u6027\uff0c\u51cf\u5c11\u91cd\u590d\u5f00\u53d1\u5de5\u4f5c\u3002", "method": "\u901a\u8fc7\u58f0\u660e\u5f0f\u8bed\u8a00\u5b9a\u4e49AI\u4ee3\u7406\u548c\u5de5\u4f5c\u6d41\uff0c\u72ec\u7acb\u4e8e\u6267\u884c\u73af\u5883\uff0c\u652f\u6301\u5f00\u53d1\u5de5\u5177\u548c\u53ef\u79fb\u690d\u6027\uff0c\u4f5c\u4e3a\u4e0d\u540c\u6846\u67b6\u95f4\u7684\u4ea4\u6362\u683c\u5f0f\u3002", "result": "\u4e3a\u56db\u7c7b\u5173\u952e\u7fa4\u4f53\u5e26\u6765\u76ca\u5904\uff1a\u5f00\u53d1\u8005\u83b7\u5f97\u53ef\u91cd\u7528\u7ec4\u4ef6\u548c\u8bbe\u8ba1\u6a21\u5f0f\uff1b\u6846\u67b6\u5f00\u53d1\u8005\u83b7\u5f97\u4ea4\u6362\u683c\u5f0f\u652f\u6301\uff1b\u7814\u7a76\u8005\u5b9e\u73b0\u53ef\u590d\u73b0\u7ed3\u679c\uff1b\u4f01\u4e1a\u52a0\u901f\u539f\u578b\u5230\u90e8\u7f72\u8fc7\u7a0b\u3002", "conclusion": "Agent Spec \u63d0\u4f9b\u4e86AI\u4ee3\u7406\u5f00\u53d1\u7684\u6280\u672f\u57fa\u7840\uff0c\u4fc3\u8fdb\u8de8\u6846\u67b6\u517c\u5bb9\u6027\u3001\u5de5\u5177\u652f\u6301\u548c\u672a\u6765\u53d1\u5c55\uff0c\u63a8\u52a8AI\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u7684\u6807\u51c6\u5316\u548c\u4e92\u64cd\u4f5c\u6027\u3002"}}
{"id": "2510.04592", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04592", "abs": "https://arxiv.org/abs/2510.04592", "authors": ["Yilin Mei", "Peng Qiu", "Wei Zhang", "WenChao Zhang", "Wenjie Song"], "title": "MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation", "comment": null, "summary": "Recent advances in robotics have been largely driven by imitation learning,\nwhich depends critically on large-scale, high-quality demonstration data.\nHowever, collecting such data remains a significant challenge-particularly for\nmobile manipulators, which must coordinate base locomotion and arm manipulation\nin high-dimensional, dynamic, and partially observable environments.\nConsequently, most existing research remains focused on simpler tabletop\nscenarios, leaving mobile manipulation relatively underexplored. To bridge this\ngap, we present \\textit{MobRT}, a digital twin-based framework designed to\nsimulate two primary categories of complex, whole-body tasks: interaction with\narticulated objects (e.g., opening doors and drawers) and mobile-base\npick-and-place operations. \\textit{MobRT} autonomously generates diverse and\nrealistic demonstrations through the integration of virtual kinematic control\nand whole-body motion planning, enabling coherent and physically consistent\nexecution. We evaluate the quality of \\textit{MobRT}-generated data across\nmultiple baseline algorithms, establishing a comprehensive benchmark and\ndemonstrating a strong correlation between task success and the number of\ngenerated trajectories. Experiments integrating both simulated and real-world\ndemonstrations confirm that our approach markedly improves policy\ngeneralization and performance, achieving robust results in both simulated and\nreal-world environments.", "AI": {"tldr": "MobRT\u662f\u4e00\u4e2a\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u79fb\u52a8\u673a\u68b0\u81c2\u590d\u6742\u5168\u8eab\u4efb\u52a1\u7684\u591a\u6837\u5316\u6f14\u793a\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u7b56\u7565\u6cdb\u5316\u80fd\u529b\u548c\u6027\u80fd\u3002", "motivation": "\u79fb\u52a8\u673a\u68b0\u81c2\u7684\u6a21\u4eff\u5b66\u4e60\u9762\u4e34\u9ad8\u8d28\u91cf\u6f14\u793a\u6570\u636e\u6536\u96c6\u56f0\u96be\u7684\u95ee\u9898\uff0c\u73b0\u6709\u7814\u7a76\u591a\u5c40\u9650\u4e8e\u7b80\u5355\u7684\u684c\u9762\u573a\u666f\uff0c\u800c\u79fb\u52a8\u64cd\u4f5c\u4efb\u52a1\u76f8\u5bf9\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u865a\u62df\u8fd0\u52a8\u5b66\u63a7\u5236\u548c\u5168\u8eab\u8fd0\u52a8\u89c4\u5212\u96c6\u6210\uff0c\u81ea\u4e3b\u751f\u6210\u591a\u6837\u5316\u548c\u771f\u5b9e\u7684\u6f14\u793a\uff0c\u5305\u62ec\u4e0e\u94f0\u63a5\u7269\u4f53\u4ea4\u4e92\u548c\u79fb\u52a8\u57fa\u5ea7\u62fe\u653e\u64cd\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u751f\u6210\u7684\u6570\u636e\u8d28\u91cf\u9ad8\uff0c\u4efb\u52a1\u6210\u529f\u7387\u4e0e\u751f\u6210\u8f68\u8ff9\u6570\u91cf\u5f3a\u76f8\u5173\uff0c\u5728\u6a21\u62df\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u5747\u5b9e\u73b0\u4e86\u7a33\u5065\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "MobRT\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u79fb\u52a8\u673a\u68b0\u81c2\u6f14\u793a\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u4e3a\u590d\u6742\u5168\u8eab\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u57fa\u51c6\u548c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04195", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04195", "abs": "https://arxiv.org/abs/2510.04195", "authors": ["Puzhen Zhang", "Xuyang Chen", "Yu Feng", "Yuhan Jiang", "Liqiu Meng"], "title": "Constructing coherent spatial memory in LLM agents through graph rectification", "comment": null, "summary": "Given a map description through global traversal navigation instructions\n(e.g., visiting each room sequentially with action signals such as north, west,\netc.), an LLM can often infer the implicit spatial layout of the environment\nand answer user queries by providing a shortest path from a start to a\ndestination (for instance, navigating from the lobby to a meeting room via the\nhall and elevator). However, such context-dependent querying becomes incapable\nas the environment grows much longer, motivating the need for incremental map\nconstruction that builds a complete topological graph from stepwise\nobservations. We propose a framework for LLM-driven construction and map\nrepair, designed to detect, localize, and correct structural inconsistencies in\nincrementally constructed navigation graphs. Central to our method is the\nVersion Control, which records the full history of graph edits and their source\nobservations, enabling fine-grained rollback, conflict tracing, and repair\nevaluation. We further introduce an Edge Impact Score to prioritize\nminimal-cost repairs based on structural reachability, path usage, and conflict\npropagation. To properly evaluate our approach, we create a refined version of\nthe MANGO benchmark dataset by systematically removing non-topological actions\nand inherent structural conflicts, providing a cleaner testbed for LLM-driven\nconstruction and map repair. Our approach significantly improves map\ncorrectness and robustness, especially in scenarios with entangled or chained\ninconsistencies. Our results highlight the importance of introspective,\nhistory-aware repair mechanisms for maintaining coherent spatial memory in LLM\nagents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2aLLM\u9a71\u52a8\u7684\u589e\u91cf\u5730\u56fe\u6784\u5efa\u548c\u4fee\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u7248\u672c\u63a7\u5236\u548c\u8fb9\u5f71\u54cd\u8bc4\u5206\u6765\u68c0\u6d4b\u3001\u5b9a\u4f4d\u548c\u4fee\u6b63\u5bfc\u822a\u56fe\u4e2d\u7684\u7ed3\u6784\u4e0d\u4e00\u81f4\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5730\u56fe\u6b63\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740\u73af\u5883\u89c4\u6a21\u6269\u5927\uff0c\u57fa\u4e8e\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u67e5\u8be2\u65b9\u6cd5\u53d8\u5f97\u4e0d\u53ef\u884c\uff0c\u9700\u8981\u80fd\u591f\u4ece\u9010\u6b65\u89c2\u5bdf\u4e2d\u6784\u5efa\u5b8c\u6574\u62d3\u6251\u56fe\u7684\u589e\u91cf\u5730\u56fe\u6784\u5efa\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7248\u672c\u63a7\u5236\u8bb0\u5f55\u56fe\u7f16\u8f91\u7684\u5b8c\u6574\u5386\u53f2\u53ca\u5176\u6765\u6e90\u89c2\u5bdf\uff0c\u5f15\u5165\u8fb9\u5f71\u54cd\u8bc4\u5206\u57fa\u4e8e\u7ed3\u6784\u53ef\u8fbe\u6027\u3001\u8def\u5f84\u4f7f\u7528\u548c\u51b2\u7a81\u4f20\u64ad\u6765\u4f18\u5148\u5904\u7406\u6700\u5c0f\u6210\u672c\u4fee\u590d\u3002", "result": "\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5730\u56fe\u6b63\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u7ea0\u7f20\u6216\u94fe\u5f0f\u4e0d\u4e00\u81f4\u6027\u7684\u573a\u666f\u4e2d\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5185\u7701\u3001\u5386\u53f2\u611f\u77e5\u7684\u4fee\u590d\u673a\u5236\u5bf9\u4e8e\u7ef4\u62a4LLM\u667a\u80fd\u4f53\u4e2d\u8fde\u8d2f\u7a7a\u95f4\u8bb0\u5fc6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.04612", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04612", "abs": "https://arxiv.org/abs/2510.04612", "authors": ["Simon Boche", "Jaehyung Jung", "Sebasti\u00e1n Barbas Laina", "Stefan Leutenegger"], "title": "OKVIS2-X: Open Keyframe-based Visual-Inertial SLAM Configurable with Dense Depth or LiDAR, and GNSS", "comment": "IEEE Transactions on Robotics (T-RO) - Special Issue: Visual SLAM", "summary": "To empower mobile robots with usable maps as well as highest state estimation\naccuracy and robustness, we present OKVIS2-X: a state-of-the-art multi-sensor\nSimultaneous Localization and Mapping (SLAM) system building dense volumetric\noccupancy maps, while scalable to large environments and operating in realtime.\nOur unified SLAM framework seamlessly integrates different sensor modalities:\nvisual, inertial, measured or learned depth, LiDAR and Global Navigation\nSatellite System (GNSS) measurements. Unlike most state-of-the-art SLAM\nsystems, we advocate using dense volumetric map representations when leveraging\ndepth or range-sensing capabilities. We employ an efficient submapping strategy\nthat allows our system to scale to large environments, showcased in sequences\nof up to 9 kilometers. OKVIS2-X enhances its accuracy and robustness by\ntightly-coupling the estimator and submaps through map alignment factors. Our\nsystem provides globally consistent maps, directly usable for autonomous\nnavigation. To further improve the accuracy of OKVIS2-X, we also incorporate\nthe option of performing online calibration of camera extrinsics. Our system\nachieves the highest trajectory accuracy in EuRoC against state-of-the-art\nalternatives, outperforms all competitors in the Hilti22 VI-only benchmark,\nwhile also proving competitive in the LiDAR version, and showcases state of the\nart accuracy in the diverse and large-scale sequences from the VBR dataset.", "AI": {"tldr": "OKVIS2-X\u662f\u4e00\u4e2a\u5148\u8fdb\u7684\u591a\u4f20\u611f\u5668SLAM\u7cfb\u7edf\uff0c\u80fd\u591f\u6784\u5efa\u5bc6\u96c6\u4f53\u7d20\u5360\u636e\u5730\u56fe\uff0c\u5728\u5927\u89c4\u6a21\u73af\u5883\u4e2d\u5b9e\u65f6\u8fd0\u884c\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u7cbe\u5ea6\u3002", "motivation": "\u4e3a\u4e86\u8ba9\u79fb\u52a8\u673a\u5668\u4eba\u62e5\u6709\u53ef\u7528\u7684\u5730\u56fe\u4ee5\u53ca\u6700\u9ad8\u7684\u72b6\u6001\u4f30\u8ba1\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u65e0\u7f1d\u96c6\u6210\u591a\u79cd\u4f20\u611f\u5668\u6a21\u6001\u7684\u7edf\u4e00SLAM\u6846\u67b6\u3002", "method": "\u91c7\u7528\u7edf\u4e00\u7684SLAM\u6846\u67b6\u96c6\u6210\u89c6\u89c9\u3001\u60ef\u6027\u3001\u6df1\u5ea6\u3001LiDAR\u548cGNSS\u6d4b\u91cf\uff1b\u4f7f\u7528\u5bc6\u96c6\u4f53\u7d20\u5730\u56fe\u8868\u793a\uff1b\u91c7\u7528\u9ad8\u6548\u7684\u5b50\u5730\u56fe\u7b56\u7565\uff1b\u901a\u8fc7\u5730\u56fe\u5bf9\u9f50\u56e0\u5b50\u7d27\u5bc6\u8026\u5408\u4f30\u8ba1\u5668\u548c\u5b50\u5730\u56fe\uff1b\u652f\u6301\u76f8\u673a\u5916\u53c2\u5728\u7ebf\u6821\u51c6\u3002", "result": "\u5728EuRoC\u6570\u636e\u96c6\u4e2d\u83b7\u5f97\u6700\u9ad8\u7684\u8f68\u8ff9\u7cbe\u5ea6\uff1b\u5728Hilti22 VI-only\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u6240\u6709\u7ade\u4e89\u5bf9\u624b\uff1b\u5728LiDAR\u7248\u672c\u4e2d\u5177\u6709\u7ade\u4e89\u529b\uff1b\u5728VBR\u6570\u636e\u96c6\u7684\u5927\u89c4\u6a21\u5e8f\u5217\u4e2d\u5c55\u793a\u51fa\u6700\u5148\u8fdb\u7684\u7cbe\u5ea6\u3002", "conclusion": "OKVIS2-X\u662f\u4e00\u4e2a\u529f\u80fd\u5f3a\u5927\u7684\u591a\u4f20\u611f\u5668SLAM\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u5927\u89c4\u6a21\u73af\u5883\u4e2d\u6784\u5efa\u5168\u5c40\u4e00\u81f4\u7684\u53ef\u7528\u5730\u56fe\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2510.04196", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04196", "abs": "https://arxiv.org/abs/2510.04196", "authors": ["Yizhuo Ding", "Mingkang Chen", "Qiuhua Liu", "Fenghua Weng", "Wanying Qu", "Yue Yang", "Yugang Jiang", "Zuxuan Wu", "Yanwei Fu", "Wenqi Shao"], "title": "COSMO-RL: Towards Trustworthy LMRMs via Joint Safety and Stability", "comment": null, "summary": "Large Multimodal Reasoning Models (LMRMs) are moving into real applications,\nwhere they must be both useful and safe. Safety is especially challenging in\nmultimodal settings: images and text can be combined to bypass guardrails, and\nsingle objective training can cause policy drift that yields over-refusal on\nbenign inputs or unsafe compliance on risky ones. We present COSMO-RL, a mixed\nreinforcement learning framework that trains reasoning oriented LMRMs under\nmultimodal, multitask, and multiobjective signals, and we release the resulting\nmodel, COSMO-R1. Our approach aims to let safety and capability grow together\nin one stable pipeline rather than competing during alignment. In experiments,\nCOSMO-R1 improves safety while maintaining-and often improving multimodal\nreasoning and instruction following, shows stronger robustness to multimodal\njailbreaks, and reduces unnecessary refusals. The framework also transfers\nacross backbones with consistent gains. Ablations support the design choices,\nindicating a simple path to advancing safety and general capability together in\nLMRMs.", "AI": {"tldr": "COSMO-RL\u662f\u4e00\u4e2a\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u591a\u6a21\u6001\u3001\u591a\u4efb\u52a1\u548c\u591a\u76ee\u6807\u4fe1\u53f7\u4e0b\u8bad\u7ec3\u9762\u5411\u63a8\u7406\u7684\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff0c\u65e8\u5728\u8ba9\u5b89\u5168\u6027\u548c\u80fd\u529b\u5171\u540c\u589e\u957f\u800c\u975e\u76f8\u4e92\u7ade\u4e89\u3002", "motivation": "\u5927\u578b\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u517c\u5177\u5b9e\u7528\u6027\u548c\u5b89\u5168\u6027\uff0c\u4f46\u591a\u6a21\u6001\u73af\u5883\u4e0b\u7684\u5b89\u5168\u6027\u7279\u522b\u5177\u6709\u6311\u6218\u6027\uff1a\u56fe\u50cf\u548c\u6587\u672c\u53ef\u4ee5\u7ed3\u5408\u7ed5\u8fc7\u9632\u62a4\u673a\u5236\uff0c\u5355\u4e00\u76ee\u6807\u8bad\u7ec3\u53ef\u80fd\u5bfc\u81f4\u7b56\u7565\u6f02\u79fb\uff0c\u5728\u826f\u6027\u8f93\u5165\u4e0a\u8fc7\u5ea6\u62d2\u7edd\u6216\u5728\u98ce\u9669\u8f93\u5165\u4e0a\u4e0d\u5b89\u5168\u5730\u9075\u4ece\u3002", "method": "\u63d0\u51fa\u4e86COSMO-RL\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u591a\u6a21\u6001\u3001\u591a\u4efb\u52a1\u548c\u591a\u76ee\u6807\u4fe1\u53f7\u4e0b\u8bad\u7ec3\u63a8\u7406\u5bfc\u5411\u7684\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff0c\u5e76\u53d1\u5e03\u4e86COSMO-R1\u6a21\u578b\u3002", "result": "COSMO-R1\u5728\u5b9e\u9a8c\u4e2d\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5e76\u7ecf\u5e38\u6539\u5584\u591a\u6a21\u6001\u63a8\u7406\u548c\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\uff0c\u663e\u793a\u51fa\u5bf9\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u4e0d\u5fc5\u8981\u7684\u62d2\u7edd\u3002\u8be5\u6846\u67b6\u5728\u4e0d\u540c\u9aa8\u5e72\u7f51\u7edc\u4e0a\u4e5f\u80fd\u5b9e\u73b0\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u6d88\u878d\u5b9e\u9a8c\u652f\u6301\u4e86\u8bbe\u8ba1\u9009\u62e9\uff0c\u8868\u660e\u5728\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u5171\u540c\u63a8\u8fdb\u5b89\u5168\u6027\u548c\u901a\u7528\u80fd\u529b\u6709\u4e00\u6761\u7b80\u5355\u7684\u8def\u5f84\u3002"}}
{"id": "2510.04692", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04692", "abs": "https://arxiv.org/abs/2510.04692", "authors": ["Lyes Saad Saoud", "Irfan Hussain"], "title": "Bio-Inspired Robotic Houbara: From Development to Field Deployment for Behavioral Studies", "comment": null, "summary": "Biomimetic intelligence and robotics are transforming field ecology by\nenabling lifelike robotic surrogates that interact naturally with animals under\nreal world conditions. Studying avian behavior in the wild remains challenging\ndue to the need for highly realistic morphology, durable outdoor operation, and\nintelligent perception that can adapt to uncontrolled environments. We present\na next generation bio inspired robotic platform that replicates the morphology\nand visual appearance of the female Houbara bustard to support controlled\nethological studies and conservation oriented field research. The system\nintroduces a fully digitally replicable fabrication workflow that combines high\nresolution structured light 3D scanning, parametric CAD modelling, articulated\n3D printing, and photorealistic UV textured vinyl finishing to achieve\nanatomically accurate and durable robotic surrogates. A six wheeled rocker\nbogie chassis ensures stable mobility on sand and irregular terrain, while an\nembedded NVIDIA Jetson module enables real time RGB and thermal perception,\nlightweight YOLO based detection, and an autonomous visual servoing loop that\naligns the robot's head toward detected targets without human intervention. A\nlightweight thermal visible fusion module enhances perception in low light\nconditions. Field trials in desert aviaries demonstrated reliable real time\noperation at 15 to 22 FPS with latency under 100 ms and confirmed that the\nplatform elicits natural recognition and interactive responses from live\nHoubara bustards under harsh outdoor conditions. This integrated framework\nadvances biomimetic field robotics by uniting reproducible digital fabrication,\nembodied visual intelligence, and ecological validation, providing a\ntransferable blueprint for animal robot interaction research, conservation\nrobotics, and public engagement.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4eff\u751f\u673a\u5668\u4eba\u5e73\u53f0\uff0c\u6a21\u62df\u96cc\u6027\u6ce2\u6591\u9e28\u7684\u5f62\u6001\u548c\u5916\u89c2\uff0c\u7528\u4e8e\u91ce\u5916\u751f\u6001\u884c\u4e3a\u7814\u7a76\u548c\u4fdd\u62a4\u5de5\u4f5c\u3002\u8be5\u5e73\u53f0\u91c7\u7528\u6570\u5b57\u5316\u5236\u9020\u6d41\u7a0b\uff0c\u5177\u5907\u7a33\u5b9a\u7684\u6c99\u5730\u79fb\u52a8\u80fd\u529b\u548c\u5b9e\u65f6\u89c6\u89c9\u611f\u77e5\u7cfb\u7edf\uff0c\u5728\u6c99\u6f20\u8bd5\u9a8c\u4e2d\u6210\u529f\u5f15\u53d1\u4e86\u771f\u5b9e\u6ce2\u6591\u9e28\u7684\u81ea\u7136\u4e92\u52a8\u53cd\u5e94\u3002", "motivation": "\u7814\u7a76\u91ce\u751f\u9e1f\u7c7b\u884c\u4e3a\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u9ad8\u5ea6\u903c\u771f\u7684\u5f62\u6001\u3001\u8010\u7528\u7684\u6237\u5916\u64cd\u4f5c\u80fd\u529b\u4ee5\u53ca\u80fd\u591f\u9002\u5e94\u975e\u53d7\u63a7\u73af\u5883\u7684\u667a\u80fd\u611f\u77e5\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u5b8c\u5168\u6570\u5b57\u5316\u53ef\u590d\u5236\u7684\u5236\u9020\u6d41\u7a0b\uff0c\u7ed3\u5408\u9ad8\u5206\u8fa8\u7387\u7ed3\u6784\u51493D\u626b\u63cf\u3001\u53c2\u6570\u5316CAD\u5efa\u6a21\u3001\u5173\u8282\u5f0f3D\u6253\u5370\u548c\u903c\u771fUV\u7eb9\u7406\u4e59\u70ef\u57fa\u8868\u9762\u5904\u7406\u3002\u914d\u5907\u516d\u8f6e\u6447\u81c2\u8f6c\u5411\u67b6\u5e95\u76d8\u786e\u4fdd\u6c99\u5730\u548c\u5d0e\u5c96\u5730\u5f62\u7684\u7a33\u5b9a\u79fb\u52a8\uff0c\u5d4c\u5165\u5f0fNVIDIA Jetson\u6a21\u5757\u5b9e\u73b0\u5b9e\u65f6RGB\u548c\u70ed\u6210\u50cf\u611f\u77e5\u3001\u8f7b\u91cf\u7ea7YOLO\u68c0\u6d4b\u4ee5\u53ca\u81ea\u4e3b\u89c6\u89c9\u4f3a\u670d\u7cfb\u7edf\u3002", "result": "\u6c99\u6f20\u9e1f\u820d\u7684\u73b0\u573a\u8bd5\u9a8c\u663e\u793a\uff0c\u7cfb\u7edf\u4ee515-22 FPS\u7684\u5e27\u7387\u53ef\u9760\u8fd0\u884c\uff0c\u5ef6\u8fdf\u4f4e\u4e8e100\u6beb\u79d2\uff0c\u5e73\u53f0\u5728\u6076\u52a3\u6237\u5916\u6761\u4ef6\u4e0b\u6210\u529f\u5f15\u53d1\u4e86\u6d3b\u4f53\u6ce2\u6591\u9e28\u7684\u81ea\u7136\u8bc6\u522b\u548c\u4e92\u52a8\u53cd\u5e94\u3002", "conclusion": "\u8be5\u96c6\u6210\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u53ef\u590d\u5236\u7684\u6570\u5b57\u5316\u5236\u9020\u3001\u5177\u8eab\u89c6\u89c9\u667a\u80fd\u548c\u751f\u6001\u9a8c\u8bc1\uff0c\u63a8\u8fdb\u4e86\u4eff\u751f\u91ce\u5916\u673a\u5668\u4eba\u6280\u672f\uff0c\u4e3a\u52a8\u7269-\u673a\u5668\u4eba\u4e92\u52a8\u7814\u7a76\u3001\u4fdd\u62a4\u673a\u5668\u4eba\u548c\u516c\u4f17\u53c2\u4e0e\u63d0\u4f9b\u4e86\u53ef\u8f6c\u79fb\u7684\u84dd\u56fe\u3002"}}
{"id": "2510.04206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04206", "abs": "https://arxiv.org/abs/2510.04206", "authors": ["Hanchen Zhang", "Xiao Liu", "Bowen Lv", "Xueqiao Sun", "Bohao Jing", "Iat Long Iong", "Zhenyu Hou", "Zehan Qi", "Hanyu Lai", "Yifan Xu", "Rui Lu", "Hongning Wang", "Jie Tang", "Yuxiao Dong"], "title": "AgentRL: Scaling Agentic Reinforcement Learning with a Multi-Turn, Multi-Task Framework", "comment": null, "summary": "Recent advances in large language models (LLMs) have sparked growing interest\nin building generalist agents that can learn through online interactions.\nHowever, applying reinforcement learning (RL) to train LLM agents in\nmulti-turn, multi-task settings remains challenging due to lack of scalable\ninfrastructure and stable training algorithms. In this work, we present the\nAgentRL framework for scalable multi-turn, multi-task agentic RL training. On\nthe infrastructure side, AgentRL features a fully-asynchronous\ngeneration-training pipeline for efficient multi-turn RL. To support\nheterogeneous environment development in multi-task RL, we design a unified\nfunction-call based API interface, containerized environment development, and a\ncentralized controller. On the algorithm side, we propose cross-policy sampling\nto encourage model exploration in multi-turn settings and task advantage\nnormalization to stabilize multi-task training. Experiments show that AgentRL,\ntrained on open LLMs across five agentic tasks, significantly outperforms\nGPT-5, Clause-Sonnet-4, DeepSeek-R1, and other open-source LLM agents.\nMulti-task training with AgentRL matches the best results among all\ntask-specific models. AgentRL is open-sourced at\nhttps://github.com/THUDM/AgentRL. The algorithm and framework are adopted in\nbuilding \\textsc{\\href{https://autoglm.zhipuai.cn}{AutoGLM}}.", "AI": {"tldr": "\u63d0\u51fa\u4e86AgentRL\u6846\u67b6\uff0c\u7528\u4e8e\u53ef\u6269\u5c55\u7684\u591a\u8f6e\u591a\u4efb\u52a1\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u901a\u8fc7\u5f02\u6b65\u751f\u6210-\u8bad\u7ec3\u6d41\u6c34\u7ebf\u548c\u7b97\u6cd5\u6539\u8fdb\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709LLM\u667a\u80fd\u4f53\u3002", "motivation": "\u5f53\u524d\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u591a\u8f6e\u591a\u4efb\u52a1\u667a\u80fd\u4f53\u9762\u4e34\u57fa\u7840\u8bbe\u65bd\u53ef\u6269\u5c55\u6027\u548c\u8bad\u7ec3\u7b97\u6cd5\u7a33\u5b9a\u6027\u6311\u6218\u3002", "method": "\u91c7\u7528\u5b8c\u5168\u5f02\u6b65\u7684\u751f\u6210-\u8bad\u7ec3\u6d41\u6c34\u7ebf\u3001\u7edf\u4e00\u51fd\u6570\u8c03\u7528API\u63a5\u53e3\u3001\u5bb9\u5668\u5316\u73af\u5883\u5f00\u53d1\u3001\u8de8\u7b56\u7565\u91c7\u6837\u548c\u4efb\u52a1\u4f18\u52bf\u5f52\u4e00\u5316\u7b49\u7b97\u6cd5\u3002", "result": "\u5728\u4e94\u4e2a\u667a\u80fd\u4f53\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAgentRL\u663e\u8457\u4f18\u4e8eGPT-5\u3001Clause-Sonnet-4\u3001DeepSeek-R1\u7b49\u6a21\u578b\uff0c\u591a\u4efb\u52a1\u8bad\u7ec3\u7ed3\u679c\u4e0e\u5404\u4efb\u52a1\u4e13\u7528\u6a21\u578b\u7684\u6700\u4f73\u7ed3\u679c\u76f8\u5f53\u3002", "conclusion": "AgentRL\u4e3a\u591a\u8f6e\u591a\u4efb\u52a1\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6846\u67b6\u548c\u7b97\u6cd5\u89e3\u51b3\u65b9\u6848\uff0c\u5df2\u5728AutoGLM\u9879\u76ee\u4e2d\u5e94\u7528\u3002"}}
{"id": "2510.04696", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04696", "abs": "https://arxiv.org/abs/2510.04696", "authors": ["Alexander L. Mitchell", "Joe Watson", "Ingmar Posner"], "title": "Building Gradient by Gradient: Decentralised Energy Functions for Bimanual Robot Assembly", "comment": "8 pages, 6 figures, 1 table", "summary": "There are many challenges in bimanual assembly, including high-level\nsequencing, multi-robot coordination, and low-level, contact-rich operations\nsuch as component mating. Task and motion planning (TAMP) methods, while\neffective in this domain, may be prohibitively slow to converge when adapting\nto disturbances that require new task sequencing and optimisation. These events\nare common during tight-tolerance assembly, where difficult-to-model dynamics\nsuch as friction or deformation require rapid replanning and reattempts.\nMoreover, defining explicit task sequences for assembly can be cumbersome,\nlimiting flexibility when task replanning is required. To simplify this\nplanning, we introduce a decentralised gradient-based framework that uses a\npiecewise continuous energy function through the automatic composition of\nadaptive potential functions. This approach generates sub-goals using only\nmyopic optimisation, rather than long-horizon planning. It demonstrates\neffectiveness at solving long-horizon tasks due to the structure and adaptivity\nof the energy function. We show that our approach scales to physical bimanual\nassembly tasks for constructing tight-tolerance assemblies. In these\nexperiments, we discover that our gradient-based rapid replanning framework\ngenerates automatic retries, coordinated motions and autonomous handovers in an\nemergent fashion.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u7684\u5206\u6563\u5f0f\u6846\u67b6\uff0c\u4f7f\u7528\u81ea\u9002\u5e94\u52bf\u51fd\u6570\u7684\u81ea\u52a8\u7ec4\u5408\u6765\u751f\u6210\u5206\u6bb5\u8fde\u7eed\u80fd\u91cf\u51fd\u6570\uff0c\u7528\u4e8e\u89e3\u51b3\u53cc\u81c2\u88c5\u914d\u4e2d\u7684\u5feb\u901f\u91cd\u89c4\u5212\u95ee\u9898\u3002", "motivation": "\u53cc\u81c2\u88c5\u914d\u9762\u4e34\u9ad8\u5c42\u5e8f\u5217\u89c4\u5212\u3001\u591a\u673a\u5668\u4eba\u534f\u8c03\u548c\u63a5\u89e6\u4e30\u5bcc\u7684\u64cd\u4f5c\u7b49\u6311\u6218\u3002\u4f20\u7edf\u4efb\u52a1\u4e0e\u8fd0\u52a8\u89c4\u5212\u65b9\u6cd5\u5728\u9700\u8981\u65b0\u4efb\u52a1\u5e8f\u5217\u65f6\u6536\u655b\u7f13\u6162\uff0c\u4e14\u663e\u5f0f\u5b9a\u4e49\u4efb\u52a1\u5e8f\u5217\u9650\u5236\u4e86\u91cd\u89c4\u5212\u7684\u7075\u6d3b\u6027\u3002", "method": "\u4f7f\u7528\u81ea\u9002\u5e94\u52bf\u51fd\u6570\u7684\u81ea\u52a8\u7ec4\u5408\u6784\u5efa\u5206\u6bb5\u8fde\u7eed\u80fd\u91cf\u51fd\u6570\uff0c\u901a\u8fc7\u8fd1\u89c6\u4f18\u5316\u751f\u6210\u5b50\u76ee\u6807\uff0c\u800c\u975e\u957f\u65f6\u57df\u89c4\u5212\u3002\u91c7\u7528\u5206\u6563\u5f0f\u68af\u5ea6\u4f18\u5316\u6846\u67b6\u5b9e\u73b0\u5feb\u901f\u91cd\u89c4\u5212\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6269\u5c55\u5230\u7269\u7406\u53cc\u81c2\u88c5\u914d\u4efb\u52a1\uff0c\u6784\u5efa\u7d27\u5bc6\u516c\u5dee\u88c5\u914d\u3002\u68af\u5ea6\u5feb\u901f\u91cd\u89c4\u5212\u6846\u67b6\u80fd\u591f\u4ee5\u6d8c\u73b0\u65b9\u5f0f\u751f\u6210\u81ea\u52a8\u91cd\u8bd5\u3001\u534f\u8c03\u8fd0\u52a8\u548c\u81ea\u4e3b\u4ea4\u63a5\u3002", "conclusion": "\u63d0\u51fa\u7684\u68af\u5ea6\u6846\u67b6\u901a\u8fc7\u80fd\u91cf\u51fd\u6570\u7684\u7ed3\u6784\u548c\u81ea\u9002\u5e94\u6027\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u957f\u65f6\u57df\u4efb\u52a1\uff0c\u5728\u7d27\u5bc6\u516c\u5dee\u88c5\u914d\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u91cd\u89c4\u5212\u80fd\u529b\u3002"}}
{"id": "2510.04265", "categories": ["cs.AI", "cs.CL", "math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.04265", "abs": "https://arxiv.org/abs/2510.04265", "authors": ["Mohsen Hariri", "Amirhossein Samandar", "Michael Hinczewski", "Vipin Chaudhary"], "title": "Don't Pass$\\mathtt{@}k$: A Bayesian Framework for Large Language Model Evaluation", "comment": "Code and simulations: https://mohsenhariri.github.io/bayes-kit", "summary": "Pass$@k$ is widely used to report performance for LLM reasoning, but it often\nyields unstable, misleading rankings, especially when the number of trials\n(samples) is limited and compute is constrained. We present a principled\nBayesian evaluation framework that replaces Pass$@k$ and average accuracy over\n$N$ trials (avg$@N$) with posterior estimates of a model's underlying success\nprobability and credible intervals, yielding stable rankings and a transparent\ndecision rule for differences. Evaluation outcomes are modeled as categorical\n(not just 0/1) with a Dirichlet prior, giving closed-form expressions for the\nposterior mean and uncertainty of any weighted rubric and enabling the use of\nprior evidence when appropriate. Theoretically, under a uniform prior, the\nBayesian posterior mean is order-equivalent to average accuracy (Pass$@1$),\nexplaining its empirical robustness while adding principled uncertainty.\nEmpirically, in simulations with known ground-truth success rates and on\nAIME'24/'25, HMMT'25, and BrUMO'25, the Bayesian/avg procedure achieves faster\nconvergence and greater rank stability than Pass$@k$ and recent variants,\nenabling reliable comparisons at far smaller sample counts. The framework\nclarifies when observed gaps are statistically meaningful (non-overlapping\ncredible intervals) versus noise, and it naturally extends to graded,\nrubric-based evaluations. Together, these results recommend replacing Pass$@k$\nfor LLM evaluation and ranking with a posterior-based, compute-efficient\nprotocol that unifies binary and non-binary evaluation while making uncertainty\nexplicit. Code is available at https://mohsenhariri.github.io/bayes-kit", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8d1d\u53f6\u65af\u8bc4\u4f30\u6846\u67b6\u6765\u66ff\u4ee3Pass@k\uff0c\u901a\u8fc7\u540e\u9a8c\u6982\u7387\u4f30\u8ba1\u548c\u53ef\u4fe1\u533a\u95f4\u63d0\u4f9b\u66f4\u7a33\u5b9a\u7684\u6a21\u578b\u6392\u540d\u548c\u900f\u660e\u7684\u51b3\u7b56\u89c4\u5219", "motivation": "Pass@k\u5728\u6709\u9650\u8bd5\u9a8c\u6b21\u6570\u548c\u8ba1\u7b97\u53d7\u9650\u65f6\u4f1a\u4ea7\u751f\u4e0d\u7a33\u5b9a\u3001\u8bef\u5bfc\u6027\u7684\u6392\u540d\u7ed3\u679c\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5", "method": "\u4f7f\u7528\u72c4\u5229\u514b\u96f7\u5148\u9a8c\u5bf9\u8bc4\u4f30\u7ed3\u679c\u8fdb\u884c\u5efa\u6a21\uff0c\u83b7\u5f97\u540e\u9a8c\u5747\u503c\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u652f\u6301\u52a0\u6743\u8bc4\u5206\u6807\u51c6\u548c\u5148\u9a8c\u8bc1\u636e\u7684\u4f7f\u7528", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u8d1d\u53f6\u65af\u65b9\u6cd5\u6bd4Pass@k\u53ca\u5176\u53d8\u4f53\u6536\u655b\u66f4\u5feb\u3001\u6392\u540d\u66f4\u7a33\u5b9a\uff0c\u80fd\u5728\u66f4\u5c11\u6837\u672c\u4e0b\u5b9e\u73b0\u53ef\u9760\u6bd4\u8f83", "conclusion": "\u63a8\u8350\u7528\u57fa\u4e8e\u540e\u9a8c\u6982\u7387\u7684\u8ba1\u7b97\u9ad8\u6548\u534f\u8bae\u66ff\u4ee3Pass@k\uff0c\u7edf\u4e00\u4e8c\u5143\u548c\u975e\u4e8c\u5143\u8bc4\u4f30\uff0c\u5e76\u660e\u786e\u8868\u793a\u4e0d\u786e\u5b9a\u6027"}}
{"id": "2510.04724", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04724", "abs": "https://arxiv.org/abs/2510.04724", "authors": ["Etor Arza", "Welf Rehberg", "Philipp Weiss", "Mihir Kulkarni", "Kostas Alexis"], "title": "Performance-guided Task-specific Optimization for Multirotor Design", "comment": null, "summary": "This paper introduces a methodology for task-specific design optimization of\nmultirotor Micro Aerial Vehicles. By leveraging reinforcement learning,\nBayesian optimization, and covariance matrix adaptation evolution strategy, we\noptimize aerial robot designs guided exclusively by their closed-loop\nperformance in a considered task. Our approach systematically explores the\ndesign space of motor pose configurations while ensuring manufacturability\nconstraints and minimal aerodynamic interference. Results demonstrate that\noptimized designs achieve superior performance compared to conventional\nmultirotor configurations in agile waypoint navigation tasks, including against\nfully actuated designs from the literature. We build and test one of the\noptimized designs in the real world to validate the sim2real transferability of\nour approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u3001\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u534f\u65b9\u5dee\u77e9\u9635\u81ea\u9002\u5e94\u8fdb\u5316\u7b56\u7565\u7684\u591a\u65cb\u7ffc\u5fae\u578b\u98de\u884c\u5668\u4efb\u52a1\u7279\u5b9a\u8bbe\u8ba1\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u95ed\u73af\u6027\u80fd\u4f18\u5316\u7535\u673a\u59ff\u6001\u914d\u7f6e\uff0c\u5728\u654f\u6377\u822a\u70b9\u5bfc\u822a\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4f20\u7edf\u591a\u65cb\u7ffc\u914d\u7f6e\u3002", "motivation": "\u4f20\u7edf\u591a\u65cb\u7ffc\u98de\u884c\u5668\u8bbe\u8ba1\u901a\u5e38\u57fa\u4e8e\u7ecf\u9a8c\u6216\u7b80\u5316\u6a21\u578b\uff0c\u7f3a\u4e4f\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u7684\u7cfb\u7edf\u4f18\u5316\u65b9\u6cd5\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u7535\u673a\u59ff\u6001\u914d\u7f6e\u7b49\u8bbe\u8ba1\u81ea\u7531\u5ea6\u6765\u63d0\u5347\u95ed\u73af\u6027\u80fd\u3002", "method": "\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u3001\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u534f\u65b9\u5dee\u77e9\u9635\u81ea\u9002\u5e94\u8fdb\u5316\u7b56\u7565\uff0c\u5728\u8003\u8651\u53ef\u5236\u9020\u6027\u7ea6\u675f\u548c\u6700\u5c0f\u6c14\u52a8\u5e72\u6270\u7684\u524d\u63d0\u4e0b\uff0c\u7cfb\u7edf\u63a2\u7d22\u7535\u673a\u59ff\u6001\u914d\u7f6e\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u57fa\u4e8e\u95ed\u73af\u4efb\u52a1\u6027\u80fd\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u4f18\u5316\u8bbe\u8ba1\u5728\u654f\u6377\u822a\u70b9\u5bfc\u822a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u591a\u65cb\u7ffc\u914d\u7f6e\uff0c\u5305\u62ec\u6587\u732e\u4e2d\u7684\u5168\u9a71\u52a8\u8bbe\u8ba1\uff0c\u5e76\u901a\u8fc7\u771f\u5b9e\u4e16\u754c\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u8fc1\u79fb\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u4f18\u5316\u591a\u65cb\u7ffc\u98de\u884c\u5668\u7684\u4efb\u52a1\u7279\u5b9a\u8bbe\u8ba1\uff0c\u901a\u8fc7\u7cfb\u7edf\u63a2\u7d22\u8bbe\u8ba1\u7a7a\u95f4\u83b7\u5f97\u6027\u80fd\u66f4\u4f18\u7684\u914d\u7f6e\uff0c\u4e14\u5177\u6709\u826f\u597d\u7684\u4eff\u771f\u5230\u73b0\u5b9e\u8fc1\u79fb\u6027\u3002"}}
{"id": "2510.04272", "categories": ["cs.AI", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.04272", "abs": "https://arxiv.org/abs/2510.04272", "authors": ["Jinyang Jiang", "Jinhui Han", "Yijie Peng", "Ying Zhang"], "title": "Closing the Loop: Coordinating Inventory and Recommendation via Deep Reinforcement Learning on Multiple Timescales", "comment": null, "summary": "Effective cross-functional coordination is essential for enhancing firm-wide\nprofitability, particularly in the face of growing organizational complexity\nand scale. Recent advances in artificial intelligence, especially in\nreinforcement learning (RL), offer promising avenues to address this\nfundamental challenge. This paper proposes a unified multi-agent RL framework\ntailored for joint optimization across distinct functional modules, exemplified\nvia coordinating inventory replenishment and personalized product\nrecommendation. We first develop an integrated theoretical model to capture the\nintricate interplay between these functions and derive analytical benchmarks\nthat characterize optimal coordination. The analysis reveals synchronized\nadjustment patterns across products and over time, highlighting the importance\nof coordinated decision-making. Leveraging these insights, we design a novel\nmulti-timescale multi-agent RL architecture that decomposes policy components\naccording to departmental functions and assigns distinct learning speeds based\non task complexity and responsiveness. Our model-free multi-agent design\nimproves scalability and deployment flexibility, while multi-timescale updates\nenhance convergence stability and adaptability across heterogeneous decisions.\nWe further establish the asymptotic convergence of the proposed algorithm.\nExtensive simulation experiments demonstrate that the proposed approach\nsignificantly improves profitability relative to siloed decision-making\nframeworks, while the behaviors of the trained RL agents align closely with the\nmanagerial insights from our theoretical model. Taken together, this work\nprovides a scalable, interpretable RL-based solution to enable effective\ncross-functional coordination in complex business settings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u534f\u8c03\u5e93\u5b58\u8865\u8d27\u548c\u4e2a\u6027\u5316\u4ea7\u54c1\u63a8\u8350\u529f\u80fd\uff0c\u901a\u8fc7\u591a\u65f6\u95f4\u5c3a\u5ea6\u5b66\u4e60\u63d0\u9ad8\u4f01\u4e1a\u76c8\u5229\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u7ec4\u7ec7\u590d\u6742\u6027\u548c\u89c4\u6a21\u589e\u957f\u5e26\u6765\u7684\u8de8\u804c\u80fd\u534f\u8c03\u6311\u6218\uff0c\u5229\u7528\u4eba\u5de5\u667a\u80fd\u7279\u522b\u662f\u5f3a\u5316\u5b66\u4e60\u6765\u4f18\u5316\u4f01\u4e1a\u6574\u4f53\u76c8\u5229\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u96c6\u6210\u7406\u8bba\u6a21\u578b\u548c\u591a\u65f6\u95f4\u5c3a\u5ea6\u591a\u667a\u80fd\u4f53RL\u67b6\u6784\uff0c\u6839\u636e\u90e8\u95e8\u529f\u80fd\u5206\u89e3\u7b56\u7565\u7ec4\u4ef6\uff0c\u57fa\u4e8e\u4efb\u52a1\u590d\u6742\u6027\u548c\u54cd\u5e94\u6027\u5206\u914d\u4e0d\u540c\u5b66\u4e60\u901f\u5ea6\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u76f8\u6bd4\u5b64\u7acb\u51b3\u7b56\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u76c8\u5229\u80fd\u529b\uff0c\u8bad\u7ec3\u51fa\u7684RL\u667a\u80fd\u4f53\u884c\u4e3a\u4e0e\u7406\u8bba\u6a21\u578b\u7684\u7ba1\u7406\u6d1e\u5bdf\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u7684\u57fa\u4e8eRL\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u590d\u6742\u5546\u4e1a\u73af\u5883\u4e2d\u5b9e\u73b0\u6709\u6548\u7684\u8de8\u804c\u80fd\u534f\u8c03\u3002"}}
{"id": "2510.04774", "categories": ["cs.RO", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.04774", "abs": "https://arxiv.org/abs/2510.04774", "authors": ["Weixu Zhu", "Marco Dorigo", "Mary Katherine Heinrich"], "title": "Online automatic code generation for robot swarms: LLMs and self-organizing hierarchy", "comment": null, "summary": "Our recently introduced self-organizing nervous system (SoNS) provides robot\nswarms with 1) ease of behavior design and 2) global estimation of the swarm\nconfiguration and its collective environment, facilitating the implementation\nof online automatic code generation for robot swarms. In a demonstration with 6\nreal robots and simulation trials with >30 robots, we show that when a\nSoNS-enhanced robot swarm gets stuck, it can automatically solicit and run code\ngenerated by an external LLM on the fly, completing its mission with an 85%\nsuccess rate.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u7ec4\u7ec7\u795e\u7ecf\u7cfb\u7edf\uff08SoNS\uff09\uff0c\u4f7f\u673a\u5668\u4eba\u7fa4\u4f53\u80fd\u591f\u81ea\u52a8\u8bf7\u6c42\u5e76\u8fd0\u884c\u5916\u90e8LLM\u751f\u6210\u7684\u4ee3\u7801\uff0c\u4ee5\u5728\u4efb\u52a1\u53d7\u963b\u65f6\u5b8c\u6210\u4f7f\u547d\uff0c\u6210\u529f\u7387\u9ad8\u8fbe85%\u3002", "motivation": "\u4e3a\u673a\u5668\u4eba\u7fa4\u4f53\u63d0\u4f9b\u6613\u4e8e\u884c\u4e3a\u8bbe\u8ba1\u7684\u80fd\u529b\uff0c\u5e76\u5b9e\u73b0\u7fa4\u4f53\u914d\u7f6e\u548c\u96c6\u4f53\u73af\u5883\u7684\u5168\u5c40\u4f30\u8ba1\uff0c\u4ece\u800c\u5b9e\u73b0\u5728\u7ebf\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u3002", "method": "\u4f7f\u7528\u81ea\u7ec4\u7ec7\u795e\u7ecf\u7cfb\u7edf\uff08SoNS\uff09\u589e\u5f3a\u673a\u5668\u4eba\u7fa4\u4f53\uff0c\u5f53\u7fa4\u4f53\u9677\u5165\u56f0\u5883\u65f6\uff0c\u81ea\u52a8\u5411\u5916\u90e8LLM\u8bf7\u6c42\u5e76\u8fd0\u884c\u751f\u6210\u7684\u4ee3\u7801\u3002", "result": "\u57286\u4e2a\u771f\u5b9e\u673a\u5668\u4eba\u548c\u8d85\u8fc730\u4e2a\u673a\u5668\u4eba\u7684\u6a21\u62df\u8bd5\u9a8c\u4e2d\uff0cSoNS\u589e\u5f3a\u7684\u673a\u5668\u4eba\u7fa4\u4f53\u5728\u4efb\u52a1\u53d7\u963b\u65f6\u80fd\u591f\u6210\u529f\u5b8c\u6210\u4f7f\u547d\uff0c\u6210\u529f\u7387\u8fbe\u523085%\u3002", "conclusion": "SoNS\u7cfb\u7edf\u6709\u6548\u63d0\u5347\u4e86\u673a\u5668\u4eba\u7fa4\u4f53\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u81ea\u9002\u5e94\u80fd\u529b\u548c\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u5c55\u793a\u4e86\u5728\u7ebf\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2510.04281", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04281", "abs": "https://arxiv.org/abs/2510.04281", "authors": ["Zhuangzhi Gao", "Hongyi Qin", "He Zhao", "Qinkai Yu", "Feixiang Zhou", "Eduard Shantsila", "Uazman Alam", "Alena Shantsila", "Wahbi El-Bouri", "Gregory Y. H. Lip", "Yalin Zheng"], "title": "GROK: From Quantitative Biomarkers to Qualitative Diagnosis via a Grounded MLLM with Knowledge-Guided Instruction", "comment": "9 pages, 4 figures, 3 table. Equal contribution: Zhuangzhi Gao and\n  Hongyi Qin. Corresponding author: Yalin Zheng (yzheng@liverpool.ac.uk)", "summary": "Multimodal large language models (MLLMs) hold promise for integrating diverse\ndata modalities, but current medical adaptations such as LLaVA-Med often fail\nto fully exploit the synergy between color fundus photography (CFP) and optical\ncoherence tomography (OCT), and offer limited interpretability of quantitative\nbiomarkers. We introduce GROK, a grounded multimodal large language model that\njointly processes CFP, OCT, and text to deliver clinician-grade diagnoses of\nocular and systemic disease. GROK comprises three core modules:\nKnowledge-Guided Instruction Generation, CLIP-Style OCT-Biomarker Alignment,\nand Supervised Instruction Fine-Tuning, which together establish a\nquantitative-to-qualitative diagnostic chain of thought, mirroring real\nclinical reasoning when producing detailed lesion annotations. To evaluate our\napproach, we introduce the Grounded Ophthalmic Understanding benchmark, which\ncovers six disease categories and three tasks: macro-level diagnostic\nclassification, report generation quality, and fine-grained clinical assessment\nof the generated chain of thought. Experiments show that, with only LoRA\n(Low-Rank Adaptation) fine-tuning of a 7B-parameter Qwen2 backbone, GROK\noutperforms comparable 7B and 32B baselines on both report quality and\nfine-grained clinical metrics, and even exceeds OpenAI o3. Code and data are\npublicly available in the GROK repository.", "AI": {"tldr": "GROK\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u773c\u79d1\u8bca\u65ad\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u5904\u7406\u5f69\u8272\u773c\u5e95\u6444\u5f71\u3001\u5149\u5b66\u76f8\u5e72\u65ad\u5c42\u626b\u63cf\u548c\u6587\u672c\uff0c\u63d0\u4f9b\u4e34\u5e8a\u7ea7\u522b\u7684\u773c\u90e8\u548c\u5168\u8eab\u75be\u75c5\u8bca\u65ad\u3002", "motivation": "\u73b0\u6709\u7684\u533b\u5b66\u591a\u6a21\u6001\u5927\u6a21\u578b\u5982LLaVA-Med\u672a\u80fd\u5145\u5206\u5229\u7528\u5f69\u8272\u773c\u5e95\u6444\u5f71\u548c\u5149\u5b66\u76f8\u5e72\u65ad\u5c42\u626b\u63cf\u4e4b\u95f4\u7684\u534f\u540c\u4f5c\u7528\uff0c\u4e14\u5bf9\u5b9a\u91cf\u751f\u7269\u6807\u5fd7\u7269\u7684\u89e3\u91ca\u80fd\u529b\u6709\u9650\u3002", "method": "GROK\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u77e5\u8bc6\u5f15\u5bfc\u6307\u4ee4\u751f\u6210\u3001CLIP\u98ce\u683cOCT\u751f\u7269\u6807\u5fd7\u7269\u5bf9\u9f50\u548c\u76d1\u7763\u6307\u4ee4\u5fae\u8c03\uff0c\u5efa\u7acb\u4e86\u4ece\u5b9a\u91cf\u5230\u5b9a\u6027\u7684\u8bca\u65ad\u601d\u7ef4\u94fe\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4ec5\u4f7f\u7528LoRA\u5fae\u8c037B\u53c2\u6570\u7684Qwen2\u9aa8\u5e72\u7f51\u7edc\uff0cGROK\u5728\u62a5\u544a\u8d28\u91cf\u548c\u7ec6\u7c92\u5ea6\u4e34\u5e8a\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u53ef\u6bd4\u8f83\u76847B\u548c32B\u57fa\u7ebf\u6a21\u578b\uff0c\u751a\u81f3\u8d85\u8fc7OpenAI o3\u3002", "conclusion": "GROK\u901a\u8fc7\u5efa\u7acb\u5b9a\u91cf\u5230\u5b9a\u6027\u7684\u8bca\u65ad\u601d\u7ef4\u94fe\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u4e34\u5e8a\u7ea7\u522b\u7684\u773c\u79d1\u8bca\u65ad\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5728GROK\u4ed3\u5e93\u4e2d\u516c\u5f00\u3002"}}
{"id": "2510.04839", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04839", "abs": "https://arxiv.org/abs/2510.04839", "authors": ["Shuo Sha", "Anupam Bhakta", "Zhenyuan Jiang", "Kevin Qiu", "Ishaan Mahajan", "Gabriel Bravo", "Brian Plancher"], "title": "TAG-K: Tail-Averaged Greedy Kaczmarz for Computationally Efficient and Performant Online Inertial Parameter Estimation", "comment": null, "summary": "Accurate online inertial parameter estimation is essential for adaptive\nrobotic control, enabling real-time adjustment to payload changes,\nenvironmental interactions, and system wear. Traditional methods such as\nRecursive Least Squares (RLS) and the Kalman Filter (KF) often struggle to\ntrack abrupt parameter shifts or incur high computational costs, limiting their\neffectiveness in dynamic environments and for computationally constrained\nrobotic systems. As such, we introduce TAG-K, a lightweight extension of the\nKaczmarz method that combines greedy randomized row selection for rapid\nconvergence with tail averaging for robustness under noise and inconsistency.\nThis design enables fast, stable parameter adaptation while retaining the low\nper-iteration complexity inherent to the Kaczmarz framework. We evaluate TAG-K\nin synthetic benchmarks and quadrotor tracking tasks against RLS, KF, and other\nKaczmarz variants. TAG-K achieves 1.5x-1.9x faster solve times on laptop-class\nCPUs and 4.8x-20.7x faster solve times on embedded microcontrollers. More\nimportantly, these speedups are paired with improved resilience to measurement\nnoise and a 25% reduction in estimation error, leading to nearly 2x better\nend-to-end tracking performance.", "AI": {"tldr": "TAG-K\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684Kaczmarz\u65b9\u6cd5\u6269\u5c55\uff0c\u7ed3\u5408\u8d2a\u5fc3\u968f\u673a\u884c\u9009\u62e9\u548c\u5c3e\u90e8\u5e73\u5747\uff0c\u7528\u4e8e\u673a\u5668\u4eba\u60ef\u6027\u53c2\u6570\u5728\u7ebf\u4f30\u8ba1\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u5feb\u901f\u7a33\u5b9a\u7684\u53c2\u6570\u9002\u5e94\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5982\u9012\u5f52\u6700\u5c0f\u4e8c\u4e58\u6cd5\u548c\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5728\u8ddf\u8e2a\u7a81\u53d8\u53c2\u6570\u53d8\u5316\u65f6\u8868\u73b0\u4e0d\u4f73\u6216\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9650\u5236\u4e86\u5728\u52a8\u6001\u73af\u5883\u548c\u8ba1\u7b97\u53d7\u9650\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "TAG-K\u7ed3\u5408\u8d2a\u5fc3\u968f\u673a\u884c\u9009\u62e9\u5b9e\u73b0\u5feb\u901f\u6536\u655b\uff0c\u4f7f\u7528\u5c3e\u90e8\u5e73\u5747\u5728\u566a\u58f0\u548c\u4e0d\u4e00\u81f4\u6027\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301Kaczmarz\u6846\u67b6\u7684\u4f4e\u5355\u6b21\u8fed\u4ee3\u590d\u6742\u5ea6\u3002", "result": "\u5728\u7b14\u8bb0\u672c\u7535\u8111CPU\u4e0a\u5b9e\u73b01.5-1.9\u500d\u66f4\u5feb\u7684\u6c42\u89e3\u65f6\u95f4\uff0c\u5728\u5d4c\u5165\u5f0f\u5fae\u63a7\u5236\u5668\u4e0a\u5b9e\u73b04.8-20.7\u500d\u66f4\u5feb\u7684\u6c42\u89e3\u65f6\u95f4\uff0c\u540c\u65f6\u63d0\u9ad8\u5bf9\u6d4b\u91cf\u566a\u58f0\u7684\u9c81\u68d2\u6027\uff0c\u4f30\u8ba1\u8bef\u5dee\u51cf\u5c1125%\uff0c\u7aef\u5230\u7aef\u8ddf\u8e2a\u6027\u80fd\u63d0\u9ad8\u8fd12\u500d\u3002", "conclusion": "TAG-K\u4e3a\u8ba1\u7b97\u53d7\u9650\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u5728\u7ebf\u60ef\u6027\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2510.04284", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04284", "abs": "https://arxiv.org/abs/2510.04284", "authors": ["Yunghwei Lai", "Kaiming Liu", "Ziyue Wang", "Weizhi Ma", "Yang Liu"], "title": "Doctor-R1: Mastering Clinical Inquiry with Experiential Agentic Reinforcement Learning", "comment": null, "summary": "The professionalism of a human doctor in outpatient service depends on two\ncore abilities: the ability to make accurate medical decisions and the medical\nconsultation skill to conduct strategic, empathetic patient inquiry. Existing\nLarge Language Models (LLMs) have achieved remarkable accuracy on medical\ndecision-making benchmarks. However, they often lack the ability to conduct the\nstrategic and empathetic consultation, which is essential for real-world\nclinical scenarios. To address this gap, we propose Doctor-R1, an AI doctor\nagent trained to master both of the capabilities by ask high-yield questions\nand conduct strategic multi-turn inquiry to guide decision-making. Our\nframework introduces three key components: a multi-agent interactive\nenvironment, a two-tiered reward architecture that separately optimizes\nclinical decision-making and communicative inquiry skills, and an experience\nrepository to ground policy learning in high-quality prior trajectories. We\nevaluate Doctor-R1 on OpenAI's HealthBench and MAQuE, assessed across\nmulti-facet metrics, such as communication quality, user experience, and task\naccuracy. Remarkably, Doctor-R1 surpasses state-of-the-art open-source\nspecialized LLMs by a substantial margin with higher parameter efficiency and\noutperforms powerful proprietary models. Furthermore, the human evaluations\nshow a strong preference for Doctor-R1 to generate human-preferred clinical\ndialogue, demonstrating the effectiveness of the framework.", "AI": {"tldr": "\u63d0\u51faDoctor-R1 AI\u533b\u751f\u4ee3\u7406\uff0c\u901a\u8fc7\u591a\u8f6e\u6218\u7565\u8be2\u95ee\u548c\u9ad8\u8d28\u91cf\u95ee\u9898\u6765\u540c\u65f6\u638c\u63e1\u533b\u7597\u51b3\u7b56\u51c6\u786e\u6027\u548c\u533b\u60a3\u6c9f\u901a\u6280\u80fd\uff0c\u8d85\u8d8a\u73b0\u6709LLMs\u5728\u4e34\u5e8a\u5bf9\u8bdd\u8d28\u91cf\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u51b3\u7b56\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u7f3a\u4e4f\u8fdb\u884c\u6218\u7565\u6027\u548c\u540c\u7406\u5fc3\u54a8\u8be2\u7684\u80fd\u529b\uff0c\u800c\u8fd9\u5728\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\u4e2d\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u73af\u5883\u3001\u53cc\u5c42\u5956\u52b1\u67b6\u6784\uff08\u5206\u522b\u4f18\u5316\u4e34\u5e8a\u51b3\u7b56\u548c\u6c9f\u901a\u8be2\u95ee\u6280\u80fd\uff09\u4ee5\u53ca\u7ecf\u9a8c\u5b58\u50a8\u5e93\u6765\u57fa\u4e8e\u9ad8\u8d28\u91cf\u8f68\u8ff9\u8fdb\u884c\u7b56\u7565\u5b66\u4e60\u3002", "result": "\u5728OpenAI\u7684HealthBench\u548cMAQuE\u57fa\u51c6\u4e0a\uff0cDoctor-R1\u5728\u6c9f\u901a\u8d28\u91cf\u3001\u7528\u6237\u4f53\u9a8c\u548c\u4efb\u52a1\u51c6\u786e\u6027\u7b49\u591a\u65b9\u9762\u6307\u6807\u4e0a\u663e\u8457\u8d85\u8d8a\u6700\u5148\u8fdb\u7684\u5f00\u6e90\u4e13\u7528LLMs\uff0c\u5e76\u5728\u4eba\u7c7b\u8bc4\u4f30\u4e2d\u663e\u793a\u51fa\u5bf9\u751f\u6210\u4eba\u7c7b\u504f\u597d\u4e34\u5e8a\u5bf9\u8bdd\u7684\u5f3a\u70c8\u504f\u597d\u3002", "conclusion": "Doctor-R1\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86AI\u533b\u751f\u5728\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\u4e2d\u540c\u65f6\u5177\u5907\u51c6\u786e\u533b\u7597\u51b3\u7b56\u80fd\u529b\u548c\u6218\u7565\u540c\u7406\u5fc3\u54a8\u8be2\u6280\u80fd\u7684\u9700\u6c42\uff0c\u5c55\u793a\u4e86\u53c2\u6570\u6548\u7387\u9ad8\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u7279\u70b9\u3002"}}
{"id": "2510.04883", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04883", "abs": "https://arxiv.org/abs/2510.04883", "authors": ["Nathan Shankar", "Pawel Ladosz", "Hujun Yin"], "title": "CLEAR-IR: Clarity-Enhanced Active Reconstruction of Infrared Imagery", "comment": "8 pages, 8 figures", "summary": "This paper presents a novel approach for enabling robust robotic perception\nin dark environments using infrared (IR) stream. IR stream is less susceptible\nto noise than RGB in low-light conditions. However, it is dominated by active\nemitter patterns that hinder high-level tasks such as object detection,\ntracking and localisation. To address this, a U-Net-based architecture is\nproposed that reconstructs clean IR images from emitter-populated input,\nimproving both image quality and downstream robotic performance. This approach\noutperforms existing enhancement techniques and enables reliable operation of\nvision-driven robotic systems across illumination conditions from well-lit to\nextreme low-light scenes.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eU-Net\u7684\u67b6\u6784\uff0c\u4ece\u53d7\u53d1\u5c04\u5668\u5e72\u6270\u7684\u7ea2\u5916\u56fe\u50cf\u4e2d\u91cd\u5efa\u5e72\u51c0\u56fe\u50cf\uff0c\u63d0\u5347\u6697\u5149\u73af\u5883\u4e0b\u673a\u5668\u4eba\u89c6\u89c9\u7cfb\u7edf\u7684\u6027\u80fd", "motivation": "\u7ea2\u5916\u6d41\u5728\u4f4e\u5149\u6761\u4ef6\u4e0b\u6bd4RGB\u66f4\u6297\u566a\uff0c\u4f46\u53d7\u4e3b\u52a8\u53d1\u5c04\u5668\u6a21\u5f0f\u5e72\u6270\uff0c\u5f71\u54cd\u76ee\u6807\u68c0\u6d4b\u3001\u8ddf\u8e2a\u548c\u5b9a\u4f4d\u7b49\u9ad8\u7ea7\u4efb\u52a1", "method": "\u4f7f\u7528U-Net\u67b6\u6784\u91cd\u5efa\u5e72\u51c0\u7684\u7ea2\u5916\u56fe\u50cf\uff0c\u6d88\u9664\u53d1\u5c04\u5668\u6a21\u5f0f\u5e72\u6270", "result": "\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u589e\u5f3a\u6280\u672f\uff0c\u80fd\u5728\u4ece\u826f\u597d\u5149\u7167\u5230\u6781\u7aef\u4f4e\u5149\u573a\u666f\u4e0b\u5b9e\u73b0\u53ef\u9760\u7684\u673a\u5668\u4eba\u89c6\u89c9\u7cfb\u7edf\u64cd\u4f5c", "conclusion": "\u8be5\u65b9\u6848\u6709\u6548\u89e3\u51b3\u4e86\u7ea2\u5916\u56fe\u50cf\u4e2d\u53d1\u5c04\u5668\u5e72\u6270\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6697\u5149\u73af\u5883\u4e0b\u673a\u5668\u4eba\u611f\u77e5\u7684\u9c81\u68d2\u6027"}}
{"id": "2510.04311", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04311", "abs": "https://arxiv.org/abs/2510.04311", "authors": ["Bohan Tang", "Huidong Liang", "Keyue Jiang", "Xiaowen Dong"], "title": "On the Importance of Task Complexity in Evaluating LLM-Based Multi-Agent Systems", "comment": null, "summary": "Large language model multi-agent systems (LLM-MAS) offer a promising paradigm\nfor harnessing collective intelligence to achieve more advanced forms of AI\nbehaviour. While recent studies suggest that LLM-MAS can outperform LLM\nsingle-agent systems (LLM-SAS) on certain tasks, the lack of systematic\nexperimental designs limits the strength and generality of these conclusions.\nWe argue that a principled understanding of task complexity, such as the degree\nof sequential reasoning required and the breadth of capabilities involved, is\nessential for assessing the effectiveness of LLM-MAS in task solving. To this\nend, we propose a theoretical framework characterising tasks along two\ndimensions: depth, representing reasoning length, and width, representing\ncapability diversity. We theoretically examine a representative class of\nLLM-MAS, namely the multi-agent debate system, and empirically evaluate its\nperformance in both discriminative and generative tasks with varying depth and\nwidth. Theoretical and empirical results show that the benefit of LLM-MAS over\nLLM-SAS increases with both task depth and width, and the effect is more\npronounced with respect to depth. This clarifies when LLM-MAS are beneficial\nand provides a principled foundation for designing future LLM-MAS methods and\nbenchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u6765\u8bc4\u4f30LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u4efb\u52a1\u89e3\u51b3\u4e2d\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u4efb\u52a1\u6df1\u5ea6\uff08\u63a8\u7406\u957f\u5ea6\uff09\u548c\u5bbd\u5ea6\uff08\u80fd\u529b\u591a\u6837\u6027\uff09\u4e24\u4e2a\u7ef4\u5ea6\u6765\u8868\u5f81\u4efb\u52a1\u590d\u6742\u6027\u3002", "motivation": "\u867d\u7136\u7814\u7a76\u8868\u660eLLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u67d0\u4e9b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u5b9e\u9a8c\u8bbe\u8ba1\u9650\u5236\u4e86\u8fd9\u4e9b\u7ed3\u8bba\u7684\u5f3a\u5ea6\u548c\u666e\u9002\u6027\u3002\u9700\u8981\u4ece\u4efb\u52a1\u590d\u6742\u6027\u7684\u89d2\u5ea6\u6765\u7406\u89e3LLM-MAS\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u4efb\u52a1\u7279\u5f81\u5316\u4e3a\u6df1\u5ea6\uff08\u63a8\u7406\u957f\u5ea6\uff09\u548c\u5bbd\u5ea6\uff08\u80fd\u529b\u591a\u6837\u6027\uff09\u4e24\u4e2a\u7ef4\u5ea6\u3002\u7406\u8bba\u5206\u6790\u4e86\u4e00\u7c7b\u4ee3\u8868\u6027\u7684LLM-MAS\uff08\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u7cfb\u7edf\uff09\uff0c\u5e76\u5728\u4e0d\u540c\u6df1\u5ea6\u548c\u5bbd\u5ea6\u7684\u5224\u522b\u6027\u548c\u751f\u6210\u6027\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cLLM-MAS\u76f8\u5bf9\u4e8eLLM-SAS\u7684\u4f18\u52bf\u968f\u7740\u4efb\u52a1\u6df1\u5ea6\u548c\u5bbd\u5ea6\u7684\u589e\u52a0\u800c\u589e\u52a0\uff0c\u4e14\u6df1\u5ea6\u7684\u5f71\u54cd\u66f4\u4e3a\u663e\u8457\u3002", "conclusion": "\u9610\u660e\u4e86LLM-MAS\u5728\u4ec0\u4e48\u60c5\u51b5\u4e0b\u66f4\u6709\u76ca\uff0c\u4e3a\u8bbe\u8ba1\u672a\u6765\u7684LLM-MAS\u65b9\u6cd5\u548c\u57fa\u51c6\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u57fa\u7840\u3002"}}
{"id": "2510.04898", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04898", "abs": "https://arxiv.org/abs/2510.04898", "authors": ["Zheng Xiong", "Kang Li", "Zilin Wang", "Matthew Jackson", "Jakob Foerster", "Shimon Whiteson"], "title": "HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks", "comment": null, "summary": "Built upon language and vision foundation models with strong generalization\nability and trained on large-scale robotic data, Vision-Language-Action (VLA)\nmodels have recently emerged as a promising approach to learning generalist\nrobotic policies. However, a key drawback of existing VLAs is their extremely\nhigh inference costs. In this paper, we propose HyperVLA to address this\nproblem. Unlike existing monolithic VLAs that activate the whole model during\nboth training and inference, HyperVLA uses a novel hypernetwork (HN)-based\narchitecture that activates only a small task-specific policy during inference,\nwhile still retaining the high model capacity needed to accommodate diverse\nmulti-task behaviors during training. Successfully training an HN-based VLA is\nnontrivial so HyperVLA contains several key algorithm design features that\nimprove its performance, including properly utilizing the prior knowledge from\nexisting vision foundation models, HN normalization, and an action generation\nstrategy. Compared to monolithic VLAs, HyperVLA achieves a similar or even\nhigher success rate for both zero-shot generalization and few-shot adaptation,\nwhile significantly reducing inference costs. Compared to OpenVLA, a\nstate-of-the-art VLA model, HyperVLA reduces the number of activated parameters\nat test time by $90\\times$, and accelerates inference speed by $120\\times$.\nCode is publicly available at https://github.com/MasterXiong/HyperVLA", "AI": {"tldr": "HyperVLA\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u7f51\u7edc\u67b6\u6784\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff0c\u901a\u8fc7\u4ec5\u6fc0\u6d3b\u5c0f\u578b\u4efb\u52a1\u7279\u5b9a\u7b56\u7565\u6765\u5927\u5e45\u964d\u4f4e\u63a8\u7406\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u591a\u4efb\u52a1\u8bad\u7ec3\u80fd\u529b\u3002", "motivation": "\u73b0\u6709VLA\u6a21\u578b\u867d\u7136\u80fd\u5b66\u4e60\u901a\u7528\u673a\u5668\u4eba\u7b56\u7565\uff0c\u4f46\u63a8\u7406\u6210\u672c\u6781\u9ad8\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528\u8d85\u7f51\u7edc\u67b6\u6784\uff0c\u5728\u63a8\u7406\u65f6\u4ec5\u6fc0\u6d3b\u5c0f\u578b\u4efb\u52a1\u7279\u5b9a\u7b56\u7565\uff1b\u5305\u542b\u5229\u7528\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u5148\u9a8c\u77e5\u8bc6\u3001\u8d85\u7f51\u7edc\u5f52\u4e00\u5316\u548c\u52a8\u4f5c\u751f\u6210\u7b56\u7565\u7b49\u5173\u952e\u8bbe\u8ba1\u3002", "result": "\u76f8\u6bd4OpenVLA\uff0c\u6fc0\u6d3b\u53c2\u6570\u91cf\u51cf\u5c1190\u500d\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347120\u500d\uff0c\u5728\u96f6\u6837\u672c\u6cdb\u5316\u548c\u5c11\u6837\u672c\u9002\u5e94\u65b9\u9762\u8fbe\u5230\u76f8\u4f3c\u6216\u66f4\u9ad8\u6210\u529f\u7387\u3002", "conclusion": "HyperVLA\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86VLA\u6a21\u578b\u7684\u63a8\u7406\u6210\u672c\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.04371", "categories": ["cs.AI", "cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.04371", "abs": "https://arxiv.org/abs/2510.04371", "authors": ["Naimeng Ye", "Arnav Ahuja", "Georgios Liargkovas", "Yunan Lu", "Kostis Kaffes", "Tianyi Peng"], "title": "Speculative Actions: A Lossless Framework for Faster Agentic Systems", "comment": null, "summary": "Despite growing interest in AI agents across industry and academia, their\nexecution in an environment is often slow, hampering training, evaluation, and\ndeployment. For example, a game of chess between two state-of-the-art agents\nmay take hours. A critical bottleneck is that agent behavior unfolds\nsequentially: each action requires an API call, and these calls can be\ntime-consuming. Inspired by speculative execution in microprocessors and\nspeculative decoding in LLM inference, we propose speculative actions, a\nlossless framework for general agentic systems that predicts likely actions\nusing faster models, enabling multiple steps to be executed in parallel. We\nevaluate this framework across three agentic environments: gaming, e-commerce,\nweb search, and a \"lossy\" extension for an operating systems environment. In\nall cases, speculative actions achieve substantial accuracy in next-action\nprediction (up to 55%), translating into significant reductions in end-to-end\nlatency. Moreover, performance can be further improved through stronger\nguessing models, top-K action prediction, multi-step speculation, and\nuncertainty-aware optimization, opening a promising path toward deploying\nlow-latency agentic systems in the real world.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\"\u63a8\u6d4b\u52a8\u4f5c\"\u7684\u65e0\u635f\u6846\u67b6\uff0c\u901a\u8fc7\u4f7f\u7528\u66f4\u5feb\u7684\u6a21\u578b\u9884\u6d4b\u53ef\u80fd\u7684\u52a8\u4f5c\uff0c\u4f7f\u591a\u4e2a\u6b65\u9aa4\u80fd\u591f\u5e76\u884c\u6267\u884c\uff0c\u4ece\u800c\u663e\u8457\u964d\u4f4eAI\u4ee3\u7406\u7cfb\u7edf\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002", "motivation": "AI\u4ee3\u7406\u5728\u73af\u5883\u4e2d\u6267\u884c\u901f\u5ea6\u7f13\u6162\uff0c\u963b\u788d\u4e86\u8bad\u7ec3\u3001\u8bc4\u4f30\u548c\u90e8\u7f72\u3002\u4f8b\u5982\uff0c\u4e24\u4e2a\u6700\u5148\u8fdb\u7684\u56fd\u9645\u8c61\u68cb\u4ee3\u7406\u4e4b\u95f4\u7684\u5bf9\u5c40\u53ef\u80fd\u9700\u8981\u6570\u5c0f\u65f6\uff0c\u4e3b\u8981\u74f6\u9888\u5728\u4e8e\u4ee3\u7406\u884c\u4e3a\u662f\u6309\u987a\u5e8f\u5c55\u5f00\u7684\uff0c\u6bcf\u4e2a\u52a8\u4f5c\u90fd\u9700\u8981API\u8c03\u7528\u4e14\u8017\u65f6\u3002", "method": "\u53d7\u5fae\u5904\u7406\u5668\u4e2d\u7684\u63a8\u6d4b\u6267\u884c\u548cLLM\u63a8\u7406\u4e2d\u7684\u63a8\u6d4b\u89e3\u7801\u542f\u53d1\uff0c\u63d0\u51fa\u63a8\u6d4b\u52a8\u4f5c\u6846\u67b6\uff0c\u4f7f\u7528\u66f4\u5feb\u7684\u6a21\u578b\u9884\u6d4b\u53ef\u80fd\u7684\u52a8\u4f5c\uff0c\u5b9e\u73b0\u591a\u6b65\u9aa4\u5e76\u884c\u6267\u884c\u3002\u652f\u6301\u901a\u8fc7\u66f4\u5f3a\u7684\u731c\u6d4b\u6a21\u578b\u3001top-K\u52a8\u4f5c\u9884\u6d4b\u3001\u591a\u6b65\u63a8\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u4f18\u5316\u6765\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728\u6e38\u620f\u3001\u7535\u5b50\u5546\u52a1\u3001\u7f51\u7edc\u641c\u7d22\u548c\u64cd\u4f5c\u7cfb\u7edf\u73af\u5883\u4e2d\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u63a8\u6d4b\u52a8\u4f5c\u5728\u4e0b\u4e00\u4e2a\u52a8\u4f5c\u9884\u6d4b\u65b9\u9762\u8fbe\u5230\u4e86\u663e\u8457\u7684\u51c6\u786e\u7387\uff08\u6700\u9ad855%\uff09\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002", "conclusion": "\u63a8\u6d4b\u52a8\u4f5c\u4e3a\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u90e8\u7f72\u4f4e\u5ef6\u8fdf\u4ee3\u7406\u7cfb\u7edf\u5f00\u8f9f\u4e86\u4e00\u6761\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2510.04991", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04991", "abs": "https://arxiv.org/abs/2510.04991", "authors": ["D. Schwartz", "K. Kondo", "J. P. How"], "title": "Efficient Navigation in Unknown Indoor Environments with Vision-Language Models", "comment": "8 pages, 4 figures", "summary": "We present a novel high-level planning framework that leverages\nvision-language models (VLMs) to improve autonomous navigation in unknown\nindoor environments with many dead ends. Traditional exploration methods often\ntake inefficient routes due to limited global reasoning and reliance on local\nheuristics. In contrast, our approach enables a VLM to reason directly about an\noccupancy map in a zero-shot manner, selecting subgoals that are likely to lead\nto more efficient paths. At each planning step, we convert a 3D occupancy grid\ninto a partial 2D map of the environment, and generate candidate subgoals. Each\nsubgoal is then evaluated and ranked against other candidates by the model. We\nintegrate this planning scheme into DYNUS \\cite{kondo2025dynus}, a\nstate-of-the-art trajectory planner, and demonstrate improved navigation\nefficiency in simulation. The VLM infers structural patterns (e.g., rooms,\ncorridors) from incomplete maps and balances the need to make progress toward a\ngoal against the risk of entering unknown space. This reduces common greedy\nfailures (e.g., detouring into small rooms) and achieves about 10\\% shorter\npaths on average.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLM)\u8fdb\u884c\u9ad8\u5c42\u89c4\u5212\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u96f6\u6837\u672c\u63a8\u7406\u5360\u636e\u5730\u56fe\u6765\u9009\u62e9\u66f4\u6709\u6548\u7684\u5b50\u76ee\u6807\uff0c\u63d0\u9ad8\u672a\u77e5\u5ba4\u5185\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u5bfc\u822a\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u63a2\u7d22\u65b9\u6cd5\u7531\u4e8e\u5168\u5c40\u63a8\u7406\u80fd\u529b\u6709\u9650\u548c\u4f9d\u8d56\u5c40\u90e8\u542f\u53d1\u5f0f\uff0c\u5728\u5b58\u5728\u8bb8\u591a\u6b7b\u80e1\u540c\u7684\u672a\u77e5\u5ba4\u5185\u73af\u5883\u4e2d\u5f80\u5f80\u91c7\u53d6\u4f4e\u6548\u8def\u7ebf\u3002", "method": "\u5c063D\u5360\u636e\u7f51\u683c\u8f6c\u6362\u4e3a\u90e8\u52062D\u5730\u56fe\uff0c\u751f\u6210\u5019\u9009\u5b50\u76ee\u6807\uff0c\u4f7f\u7528VLM\u5bf9\u8fd9\u4e9b\u5b50\u76ee\u6807\u8fdb\u884c\u96f6\u6837\u672c\u8bc4\u4f30\u548c\u6392\u5e8f\uff0c\u5e76\u96c6\u6210\u5230DYNUS\u8f68\u8ff9\u89c4\u5212\u5668\u4e2d\u3002", "result": "\u5728\u4eff\u771f\u4e2d\u5c55\u793a\u4e86\u6539\u8fdb\u7684\u5bfc\u822a\u6548\u7387\uff0cVLM\u80fd\u591f\u4ece\u4e0d\u5b8c\u6574\u5730\u56fe\u4e2d\u63a8\u65ad\u7ed3\u6784\u6a21\u5f0f(\u5982\u623f\u95f4\u3001\u8d70\u5eca)\uff0c\u5e73\u8861\u5411\u76ee\u6807\u524d\u8fdb\u7684\u9700\u6c42\u4e0e\u8fdb\u5165\u672a\u77e5\u7a7a\u95f4\u7684\u98ce\u9669\uff0c\u5e73\u5747\u8def\u5f84\u7f29\u77ed\u7ea610%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u51cf\u5c11\u4e86\u5e38\u89c1\u7684\u8d2a\u5a6a\u5931\u8d25(\u5982\u7ed5\u8fdb\u5c0f\u623f\u95f4)\uff0c\u901a\u8fc7VLM\u7684\u5168\u5c40\u63a8\u7406\u80fd\u529b\u663e\u8457\u63d0\u5347\u4e86\u672a\u77e5\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u6548\u7387\u3002"}}
{"id": "2510.04373", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04373", "abs": "https://arxiv.org/abs/2510.04373", "authors": ["Hadi Nekoei", "Aman Jaiswal", "Patrice Bechard", "Oleh Shliazhko", "Orlando Marquez Ayala", "Mathieu Reymond", "Massimo Caccia", "Alexandre Drouin", "Sarath Chandar", "Alexandre Lacoste"], "title": "Just-in-time Episodic Feedback Hinter: Leveraging Offline Knowledge to Improve LLM Agents Adaptation", "comment": null, "summary": "Large language model (LLM) agents perform well in sequential decision-making\ntasks, but improving them on unfamiliar domains often requires costly online\ninteractions or fine-tuning on large expert datasets. These strategies are\nimpractical for closed-source models and expensive for open-source ones, with\nrisks of catastrophic forgetting. Offline trajectories offer reusable\nknowledge, yet demonstration-based methods struggle because raw traces are\nlong, noisy, and tied to specific tasks. We present Just-in-time Episodic\nFeedback Hinter (JEF Hinter), an agentic system that distills offline traces\ninto compact, context-aware hints. A zooming mechanism highlights decisive\nsteps in long trajectories, capturing both strategies and pitfalls. Unlike\nprior methods, JEF Hinter leverages both successful and failed trajectories,\nextracting guidance even when only failure data is available, while supporting\nparallelized hint generation and benchmark-independent prompting. At inference,\na retriever selects relevant hints for the current state, providing targeted\nguidance with transparency and traceability. Experiments on MiniWoB++,\nWorkArena-L1, and WebArena-Lite show that JEF Hinter consistently outperforms\nstrong baselines, including human- and document-based hints.", "AI": {"tldr": "JEF Hinter\u662f\u4e00\u4e2a\u4ece\u79bb\u7ebf\u8f68\u8ff9\u4e2d\u63d0\u53d6\u7d27\u51d1\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u793a\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u653e\u5927\u673a\u5236\u7a81\u51fa\u957f\u8f68\u8ff9\u4e2d\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u5229\u7528\u6210\u529f\u548c\u5931\u8d25\u7684\u8f68\u8ff9\u63d0\u4f9b\u6307\u5bfc\uff0c\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u68c0\u7d22\u5668\u9009\u62e9\u76f8\u5173\u63d0\u793a\u6765\u63d0\u5347LLM\u667a\u80fd\u4f53\u5728\u964c\u751f\u9886\u57df\u7684\u8868\u73b0\u3002", "motivation": "\u6539\u8fdbLLM\u667a\u80fd\u4f53\u5728\u964c\u751f\u9886\u57df\u7684\u8868\u73b0\u901a\u5e38\u9700\u8981\u6602\u8d35\u7684\u5728\u7ebf\u4ea4\u4e92\u6216\u5927\u91cf\u4e13\u5bb6\u6570\u636e\u5fae\u8c03\uff0c\u8fd9\u5bf9\u95ed\u6e90\u6a21\u578b\u4e0d\u5b9e\u7528\uff0c\u5bf9\u5f00\u6e90\u6a21\u578b\u6210\u672c\u9ad8\u4e14\u6709\u707e\u96be\u6027\u9057\u5fd8\u98ce\u9669\u3002\u79bb\u7ebf\u8f68\u8ff9\u5305\u542b\u53ef\u91cd\u7528\u77e5\u8bc6\uff0c\u4f46\u539f\u59cb\u8f68\u8ff9\u957f\u3001\u5608\u6742\u4e14\u4e0e\u7279\u5b9a\u4efb\u52a1\u7ed1\u5b9a\uff0c\u96be\u4ee5\u6709\u6548\u5229\u7528\u3002", "method": "\u63d0\u51faJEF Hinter\u7cfb\u7edf\uff1a1\uff09\u4ece\u79bb\u7ebf\u8f68\u8ff9\u4e2d\u63d0\u53d6\u7d27\u51d1\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u793a\uff1b2\uff09\u4f7f\u7528\u653e\u5927\u673a\u5236\u7a81\u51fa\u957f\u8f68\u8ff9\u4e2d\u7684\u51b3\u5b9a\u6027\u6b65\u9aa4\uff1b3\uff09\u540c\u65f6\u5229\u7528\u6210\u529f\u548c\u5931\u8d25\u7684\u8f68\u8ff9\uff1b4\uff09\u63a8\u7406\u65f6\u901a\u8fc7\u68c0\u7d22\u5668\u4e3a\u5f53\u524d\u72b6\u6001\u9009\u62e9\u76f8\u5173\u63d0\u793a\u3002", "result": "\u5728MiniWoB++\u3001WorkArena-L1\u548cWebArena-Lite\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cJEF Hinter\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u4eba\u7c7b\u548c\u6587\u6863\u7684\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "JEF Hinter\u901a\u8fc7\u4ece\u79bb\u7ebf\u8f68\u8ff9\u4e2d\u63d0\u53d6\u7d27\u51d1\u63d0\u793a\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u667a\u80fd\u4f53\u5728\u964c\u751f\u9886\u57df\u7684\u8868\u73b0\uff0c\u652f\u6301\u5e76\u884c\u5316\u63d0\u793a\u751f\u6210\u548c\u57fa\u51c6\u65e0\u5173\u7684\u63d0\u793a\uff0c\u63d0\u4f9b\u900f\u660e\u4e14\u53ef\u8ffd\u6eaf\u7684\u6307\u5bfc\u3002"}}
{"id": "2510.05001", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.05001", "abs": "https://arxiv.org/abs/2510.05001", "authors": ["Aditya Sripada", "Abhishek Warrier"], "title": "Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot", "comment": "6 pages, 10 figures. Presented at IEEE-RAS International Conference\n  on Humanoid Robots (Humanoids) 2025", "summary": "Robotic locomotion research typically draws from biologically inspired leg\ndesigns, yet many human-engineered settings can benefit from\nnon-anthropomorphic forms. TARS3D translates the block-shaped 'TARS' robot from\nInterstellar into a 0.25 m, 0.99 kg research platform with seven actuated\ndegrees of freedom. The film shows two primary gaits: a bipedal-like walk and a\nhigh-speed rolling mode. For TARS3D, we build reduced-order models for each,\nderive closed-form limit-cycle conditions, and validate the predictions on\nhardware. Experiments confirm that the robot respects its +/-150 degree hip\nlimits, alternates left-right contacts without interference, and maintains an\neight-step hybrid limit cycle in rolling mode. Because each telescopic leg\nprovides four contact corners, the rolling gait is modeled as an eight-spoke\ndouble rimless wheel. The robot's telescopic leg redundancy implies a far\nricher gait repertoire than the two limit cycles treated analytically. So, we\nused deep reinforcement learning (DRL) in simulation to search the unexplored\nspace. We observed that the learned policy can recover the analytic gaits under\nthe right priors and discover novel behaviors as well. Our findings show that\nTARS3D's fiction-inspired bio-transcending morphology can realize multiple\npreviously unexplored locomotion modes and that further learning-driven search\nis likely to reveal more. This combination of analytic synthesis and\nreinforcement learning opens a promising pathway for multimodal robotics.", "AI": {"tldr": "TARS3D\u673a\u5668\u4eba\u4ece\u7535\u5f71\u300a\u661f\u9645\u7a7f\u8d8a\u300b\u4e2d\u7684TARS\u673a\u5668\u4eba\u83b7\u5f97\u7075\u611f\uff0c\u91c7\u7528\u975e\u4eff\u751f\u5f62\u6001\u8bbe\u8ba1\uff0c\u5177\u67097\u4e2a\u9a71\u52a8\u81ea\u7531\u5ea6\u3002\u7814\u7a76\u5efa\u7acb\u4e86\u4e24\u79cd\u6b65\u6001\u7684\u7b80\u5316\u6a21\u578b\uff0c\u63a8\u5bfc\u51fa\u95ed\u5f0f\u6781\u9650\u73af\u6761\u4ef6\uff0c\u5e76\u901a\u8fc7\u786c\u4ef6\u9a8c\u8bc1\u3002\u540c\u65f6\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u63a2\u7d22\u4e86\u66f4\u4e30\u5bcc\u7684\u6b65\u6001\u884c\u4e3a\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u4eba\u8fd0\u52a8\u7814\u7a76\u591a\u53d7\u751f\u7269\u542f\u53d1\u7684\u817f\u90e8\u8bbe\u8ba1\u5f71\u54cd\uff0c\u4f46\u8bb8\u591a\u4eba\u5de5\u73af\u5883\u53ef\u80fd\u53d7\u76ca\u4e8e\u975e\u4eba\u5f62\u5f62\u6001\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u79d1\u5e7b\u7535\u5f71\u4e2dTARS\u673a\u5668\u4eba\u7684\u5b9e\u9645\u53ef\u884c\u6027\u53ca\u5176\u72ec\u7279\u7684\u8fd0\u52a8\u80fd\u529b\u3002", "method": "\u5efa\u7acb\u4e24\u79cd\u4e3b\u8981\u6b65\u6001\uff08\u53cc\u8db3\u884c\u8d70\u548c\u9ad8\u901f\u6eda\u52a8\uff09\u7684\u7b80\u5316\u6a21\u578b\uff0c\u63a8\u5bfc\u95ed\u5f0f\u6781\u9650\u73af\u6761\u4ef6\uff0c\u5e76\u5728\u786c\u4ef6\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u3002\u540c\u65f6\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u4eff\u771f\u4e2d\u63a2\u7d22\u672a\u5f00\u53d1\u7684\u6b65\u6001\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u673a\u5668\u4eba\u80fd\u591f\u9075\u5b88\u00b1150\u5ea6\u9acb\u5173\u8282\u9650\u5236\uff0c\u4ea4\u66ff\u5de6\u53f3\u63a5\u89e6\u65e0\u5e72\u6270\uff0c\u5728\u6eda\u52a8\u6a21\u5f0f\u4e0b\u7ef4\u6301\u516b\u6b65\u6df7\u5408\u6781\u9650\u73af\u3002\u5b66\u4e60\u7b56\u7565\u80fd\u591f\u91cd\u73b0\u5206\u6790\u6b65\u6001\u5e76\u53d1\u73b0\u65b0\u884c\u4e3a\u3002", "conclusion": "TARS3D\u7684\u79d1\u5e7b\u542f\u53d1\u5f62\u6001\u80fd\u591f\u5b9e\u73b0\u591a\u79cd\u5148\u524d\u672a\u63a2\u7d22\u7684\u8fd0\u52a8\u6a21\u5f0f\uff0c\u5206\u6790\u5408\u6210\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u7ed3\u5408\u4e3a\u591a\u6a21\u6001\u673a\u5668\u4eba\u5f00\u8f9f\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2510.04384", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04384", "abs": "https://arxiv.org/abs/2510.04384", "authors": ["Adam Ballew", "Jingbo Wang", "Shaogang Ren"], "title": "LLM Based Bayesian Optimization for Prompt Search", "comment": null, "summary": "Bayesian Optimization (BO) has been widely used to efficiently optimize\nexpensive black-box functions with limited evaluations. In this paper, we\ninvestigate the use of BO for prompt engineering to enhance text classification\nwith Large Language Models (LLMs). We employ an LLM-powered Gaussian Process\n(GP) as the surrogate model to estimate the performance of different prompt\ncandidates. These candidates are generated by an LLM through the expansion of a\nset of seed prompts and are subsequently evaluated using an Upper Confidence\nBound (UCB) acquisition function in conjunction with the GP posterior. The\noptimization process iteratively refines the prompts based on a subset of the\ndata, aiming to improve classification accuracy while reducing the number of\nAPI calls by leveraging the prediction uncertainty of the LLM-based GP. The\nproposed BO-LLM algorithm is evaluated on two datasets, and its advantages are\ndiscussed in detail in this paper.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684BO-LLM\u7b97\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u63d0\u793a\u5de5\u7a0b\u4ee5\u63d0\u5347\u6587\u672c\u5206\u7c7b\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11API\u8c03\u7528\u6b21\u6570\u3002", "motivation": "\u5229\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u6765\u9ad8\u6548\u4f18\u5316\u6602\u8d35\u7684\u9ed1\u76d2\u51fd\u6570\uff0c\u5c06\u5176\u5e94\u7528\u4e8e\u63d0\u793a\u5de5\u7a0b\u4ee5\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u540c\u65f6\u964d\u4f4e\u8bc4\u4f30\u6210\u672c\u3002", "method": "\u4f7f\u7528LLM\u9a71\u52a8\u7684GP\u4f5c\u4e3a\u4ee3\u7406\u6a21\u578b\u8bc4\u4f30\u4e0d\u540c\u63d0\u793a\u5019\u9009\uff0c\u901a\u8fc7UCB\u91c7\u96c6\u51fd\u6570\u7ed3\u5408GP\u540e\u9a8c\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\uff0c\u5728\u6570\u636e\u5b50\u96c6\u4e0a\u4e0d\u65ad\u6539\u8fdb\u63d0\u793a\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86BO-LLM\u7b97\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u7387\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "BO-LLM\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u4f18\u5316\u63d0\u793a\u5de5\u7a0b\uff0c\u5728\u63d0\u9ad8\u6587\u672c\u5206\u7c7b\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11API\u8c03\u7528\u6b21\u6570\u3002"}}
{"id": "2510.05057", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.05057", "abs": "https://arxiv.org/abs/2510.05057", "authors": ["Mingyu Liu", "Jiuhe Shu", "Hui Chen", "Zeju Li", "Canyu Zhao", "Jiange Yang", "Shenyuan Gao", "Hao Chen", "Chunhua Shen"], "title": "StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation", "comment": null, "summary": "A fundamental challenge in embodied intelligence is developing expressive and\ncompact state representations for efficient world modeling and decision making.\nHowever, existing methods often fail to achieve this balance, yielding\nrepresentations that are either overly redundant or lacking in task-critical\ninformation. We propose an unsupervised approach that learns a highly\ncompressed two-token state representation using a lightweight encoder and a\npre-trained Diffusion Transformer (DiT) decoder, capitalizing on its strong\ngenerative prior. Our representation is efficient, interpretable, and\nintegrates seamlessly into existing VLA-based models, improving performance by\n14.3% on LIBERO and 30% in real-world task success with minimal inference\noverhead. More importantly, we find that the difference between these tokens,\nobtained via latent interpolation, naturally serves as a highly effective\nlatent action, which can be further decoded into executable robot actions. This\nemergent capability reveals that our representation captures structured\ndynamics without explicit supervision. We name our method StaMo for its ability\nto learn generalizable robotic Motion from compact State representation, which\nis encoded from static images, challenging the prevalent dependence to learning\nlatent action on complex architectures and video data. The resulting latent\nactions also enhance policy co-training, outperforming prior methods by 10.4%\nwith improved interpretability. Moreover, our approach scales effectively\nacross diverse data sources, including real-world robot data, simulation, and\nhuman egocentric video.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u65b9\u6cd5StaMo\uff0c\u901a\u8fc7\u8f7b\u91cf\u7f16\u7801\u5668\u548c\u9884\u8bad\u7ec3DiT\u89e3\u7801\u5668\u5b66\u4e60\u9ad8\u5ea6\u538b\u7f29\u7684\u53cc\u4ee4\u724c\u72b6\u6001\u8868\u793a\uff0c\u8be5\u8868\u793a\u4e0d\u4ec5\u9ad8\u6548\u53ef\u89e3\u91ca\uff0c\u8fd8\u80fd\u901a\u8fc7\u6f5c\u5728\u63d2\u503c\u81ea\u7136\u751f\u6210\u6709\u6548\u7684\u6f5c\u5728\u52a8\u4f5c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5177\u8eab\u667a\u80fd\u4e2d\u96be\u4ee5\u5e73\u8861\u72b6\u6001\u8868\u793a\u7684\u7d27\u51d1\u6027\u548c\u8868\u8fbe\u6027\uff0c\u8981\u4e48\u8fc7\u4e8e\u5197\u4f59\uff0c\u8981\u4e48\u7f3a\u4e4f\u4efb\u52a1\u5173\u952e\u4fe1\u606f\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7f16\u7801\u5668\u548c\u9884\u8bad\u7ec3Diffusion Transformer\u89e3\u7801\u5668\u5b66\u4e60\u538b\u7f29\u7684\u53cc\u4ee4\u724c\u72b6\u6001\u8868\u793a\uff0c\u901a\u8fc7\u6f5c\u5728\u63d2\u503c\u751f\u6210\u6f5c\u5728\u52a8\u4f5c\u3002", "result": "\u5728LIBERO\u4e0a\u6027\u80fd\u63d0\u534714.3%\uff0c\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u6210\u529f\u7387\u63d0\u534730%\uff0c\u6f5c\u5728\u52a8\u4f5c\u589e\u5f3a\u7b56\u7565\u534f\u540c\u8bad\u7ec3\uff0c\u6bd4\u5148\u524d\u65b9\u6cd5\u63d0\u534710.4%\u3002", "conclusion": "StaMo\u65b9\u6cd5\u4ece\u9759\u6001\u56fe\u50cf\u5b66\u4e60\u7d27\u51d1\u72b6\u6001\u8868\u793a\uff0c\u65e0\u9700\u590d\u6742\u67b6\u6784\u548c\u89c6\u9891\u6570\u636e\uff0c\u5c31\u80fd\u751f\u6210\u53ef\u6cdb\u5316\u7684\u673a\u5668\u4eba\u8fd0\u52a8\uff0c\u4e14\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2510.05061", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.05061", "abs": "https://arxiv.org/abs/2510.05061", "authors": ["Anastasios Manganaris", "Vittorio Giammarino", "Ahmed H. Qureshi"], "title": "Automaton Constrained Q-Learning", "comment": "9 pages, 4 figures, 39th Conference on Neural Information Processing\n  Systems (NeurIPS 2025)", "summary": "Real-world robotic tasks often require agents to achieve sequences of goals\nwhile respecting time-varying safety constraints. However, standard\nReinforcement Learning (RL) paradigms are fundamentally limited in these\nsettings. A natural approach to these problems is to combine RL with\nLinear-time Temporal Logic (LTL), a formal language for specifying complex,\ntemporally extended tasks and safety constraints. Yet, existing RL methods for\nLTL objectives exhibit poor empirical performance in complex and continuous\nenvironments. As a result, no scalable methods support both temporally ordered\ngoals and safety simultaneously, making them ill-suited for realistic robotics\nscenarios. We propose Automaton Constrained Q-Learning (ACQL), an algorithm\nthat addresses this gap by combining goal-conditioned value learning with\nautomaton-guided reinforcement. ACQL supports most LTL task specifications and\nleverages their automaton representation to explicitly encode stage-wise goal\nprogression and both stationary and non-stationary safety constraints. We show\nthat ACQL outperforms existing methods across a range of continuous control\ntasks, including cases where prior methods fail to satisfy either goal-reaching\nor safety constraints. We further validate its real-world applicability by\ndeploying ACQL on a 6-DOF robotic arm performing a goal-reaching task in a\ncluttered, cabinet-like space with safety constraints. Our results demonstrate\nthat ACQL is a robust and scalable solution for learning robotic behaviors\naccording to rich temporal specifications.", "AI": {"tldr": "ACQL\u7b97\u6cd5\u7ed3\u5408\u76ee\u6807\u6761\u4ef6\u503c\u5b66\u4e60\u548c\u81ea\u52a8\u673a\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60\uff0c\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u6ee1\u8db3\u65f6\u5e8f\u76ee\u6807\u548c\u975e\u5e73\u7a33\u5b89\u5168\u7ea6\u675f\u3002", "motivation": "\u73b0\u5b9e\u673a\u5668\u4eba\u4efb\u52a1\u9700\u8981\u5b9e\u73b0\u65f6\u5e8f\u76ee\u6807\u5e76\u9075\u5b88\u65f6\u53d8\u5b89\u5168\u7ea6\u675f\uff0c\u4f46\u6807\u51c6RL\u65b9\u6cd5\u5728\u6b64\u7c7b\u8bbe\u7f6e\u4e2d\u5b58\u5728\u6839\u672c\u9650\u5236\u3002\u73b0\u6709LTL\u76ee\u6807RL\u65b9\u6cd5\u5728\u590d\u6742\u8fde\u7eed\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u7f3a\u4e4f\u540c\u65f6\u652f\u6301\u65f6\u5e8f\u76ee\u6807\u548c\u5b89\u5168\u7ea6\u675f\u7684\u53ef\u6269\u5c55\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u81ea\u52a8\u673a\u7ea6\u675fQ\u5b66\u4e60(ACQL)\uff0c\u5c06\u76ee\u6807\u6761\u4ef6\u503c\u5b66\u4e60\u4e0e\u81ea\u52a8\u673a\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u5229\u7528LTL\u4efb\u52a1\u89c4\u8303\u7684\u81ea\u52a8\u673a\u8868\u793a\u6765\u663e\u5f0f\u7f16\u7801\u9636\u6bb5\u5316\u76ee\u6807\u8fdb\u5c55\u4ee5\u53ca\u5e73\u7a33\u548c\u975e\u5e73\u7a33\u5b89\u5168\u7ea6\u675f\u3002", "result": "ACQL\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5305\u62ec\u5728\u5148\u524d\u65b9\u6cd5\u65e0\u6cd5\u6ee1\u8db3\u76ee\u6807\u8fbe\u6210\u6216\u5b89\u5168\u7ea6\u675f\u7684\u60c5\u51b5\u4e0b\u3002\u57286\u81ea\u7531\u5ea6\u673a\u68b0\u81c2\u4e0a\u7684\u771f\u5b9e\u90e8\u7f72\u9a8c\u8bc1\u4e86\u5176\u5728\u6742\u4e71\u3001\u7c7b\u4f3c\u67dc\u5b50\u7a7a\u95f4\u4e2d\u7684\u9002\u7528\u6027\u3002", "conclusion": "ACQL\u662f\u6839\u636e\u4e30\u5bcc\u65f6\u5e8f\u89c4\u8303\u5b66\u4e60\u673a\u5668\u4eba\u884c\u4e3a\u7684\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04399", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04399", "abs": "https://arxiv.org/abs/2510.04399", "authors": ["Charles L. Wang", "Keir Dorchen", "Peter Jin"], "title": "Utility-Learning Tension in Self-Modifying Agents", "comment": null, "summary": "As systems trend toward superintelligence, a natural modeling premise is that\nagents can self-improve along every facet of their own design. We formalize\nthis with a five-axis decomposition and a decision layer, separating incentives\nfrom learning behavior and analyzing axes in isolation. Our central result\nidentifies and introduces a sharp utility--learning tension, the structural\nconflict in self-modifying systems whereby utility-driven changes that improve\nimmediate or expected performance can also erode the statistical preconditions\nfor reliable learning and generalization. Our findings show that\ndistribution-free guarantees are preserved iff the policy-reachable model\nfamily is uniformly capacity-bounded; when capacity can grow without limit,\nutility-rational self-changes can render learnable tasks unlearnable. Under\nstandard assumptions common in practice, these axes reduce to the same capacity\ncriterion, yielding a single boundary for safe self-modification. Numerical\nexperiments across several axes validate the theory by comparing destructive\nutility policies against our proposed two-gate policies that preserve\nlearnability.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u81ea\u6539\u8fdb\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u6548\u7528-\u5b66\u4e60\u5f20\u529b\uff0c\u6307\u51fa\u6548\u7528\u9a71\u52a8\u7684\u81ea\u6211\u4fee\u6539\u53ef\u80fd\u7834\u574f\u5b66\u4e60\u6240\u9700\u7684\u7edf\u8ba1\u524d\u63d0\u6761\u4ef6\uff0c\u63d0\u51fa\u4e86\u4fdd\u6301\u53ef\u5b66\u4e60\u6027\u7684\u5b89\u5168\u81ea\u4fee\u6539\u8fb9\u754c\u3002", "motivation": "\u968f\u7740\u7cfb\u7edf\u5411\u8d85\u667a\u80fd\u53d1\u5c55\uff0c\u9700\u8981\u5f62\u5f0f\u5316\u5206\u6790\u667a\u80fd\u4f53\u5728\u6240\u6709\u8bbe\u8ba1\u7ef4\u5ea6\u4e0a\u7684\u81ea\u6211\u6539\u8fdb\u80fd\u529b\uff0c\u7279\u522b\u662f\u8bc6\u522b\u6548\u7528\u9a71\u52a8\u4fee\u6539\u4e0e\u5b66\u4e60\u53ef\u9760\u6027\u4e4b\u95f4\u7684\u7ed3\u6784\u6027\u51b2\u7a81\u3002", "method": "\u91c7\u7528\u4e94\u8f74\u5206\u89e3\u548c\u51b3\u7b56\u5c42\u5206\u79bb\u7684\u65b9\u6cd5\uff0c\u5c06\u6fc0\u52b1\u4e0e\u5b66\u4e60\u884c\u4e3a\u5206\u5f00\u5206\u6790\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u6548\u7528\u7b56\u7565\u4e0e\u4fdd\u6301\u53ef\u5b66\u4e60\u6027\u7684\u53cc\u95e8\u7b56\u7565\u3002", "result": "\u53d1\u73b0\u5f53\u6a21\u578b\u65cf\u5bb9\u91cf\u65e0\u754c\u589e\u957f\u65f6\uff0c\u6548\u7528\u7406\u6027\u7684\u81ea\u6211\u4fee\u6539\u53ef\u80fd\u4f7f\u53ef\u5b66\u4e60\u4efb\u52a1\u53d8\u5f97\u4e0d\u53ef\u5b66\u4e60\uff1b\u5728\u6807\u51c6\u5047\u8bbe\u4e0b\uff0c\u5404\u8f74\u5f52\u7ed3\u4e3a\u76f8\u540c\u7684\u5bb9\u91cf\u6807\u51c6\uff0c\u5f62\u6210\u5b89\u5168\u81ea\u4fee\u6539\u7684\u5355\u4e00\u8fb9\u754c\u3002", "conclusion": "\u81ea\u4fee\u6539\u7cfb\u7edf\u5b58\u5728\u56fa\u6709\u7684\u6548\u7528-\u5b66\u4e60\u5f20\u529b\uff0c\u9700\u8981\u8bbe\u8ba1\u4e13\u95e8\u7684\u7b56\u7565\u6765\u786e\u4fdd\u5728\u8ffd\u6c42\u6027\u80fd\u6539\u8fdb\u7684\u540c\u65f6\u4e0d\u7834\u574f\u5b66\u4e60\u80fd\u529b\uff0c\u53cc\u95e8\u7b56\u7565\u662f\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.05070", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05070", "abs": "https://arxiv.org/abs/2510.05070", "authors": ["Siheng Zhao", "Yanjie Ze", "Yue Wang", "C. Karen Liu", "Pieter Abbeel", "Guanya Shi", "Rocky Duan"], "title": "ResMimic: From General Motion Tracking to Humanoid Whole-body Loco-Manipulation via Residual Learning", "comment": "9 pages, 8 figures", "summary": "Humanoid whole-body loco-manipulation promises transformative capabilities\nfor daily service and warehouse tasks. While recent advances in general motion\ntracking (GMT) have enabled humanoids to reproduce diverse human motions, these\npolicies lack the precision and object awareness required for\nloco-manipulation. To this end, we introduce ResMimic, a two-stage residual\nlearning framework for precise and expressive humanoid control from human\nmotion data. First, a GMT policy, trained on large-scale human-only motion,\nserves as a task-agnostic base for generating human-like whole-body movements.\nAn efficient but precise residual policy is then learned to refine the GMT\noutputs to improve locomotion and incorporate object interaction. To further\nfacilitate efficient training, we design (i) a point-cloud-based object\ntracking reward for smoother optimization, (ii) a contact reward that\nencourages accurate humanoid body-object interactions, and (iii) a\ncurriculum-based virtual object controller to stabilize early training. We\nevaluate ResMimic in both simulation and on a real Unitree G1 humanoid. Results\nshow substantial gains in task success, training efficiency, and robustness\nover strong baselines. Videos are available at https://resmimic.github.io/ .", "AI": {"tldr": "ResMimic\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6b8b\u5dee\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u901a\u7528\u8fd0\u52a8\u8ddf\u8e2a\u7b56\u7565\u548c\u7cbe\u786e\u7684\u6b8b\u5dee\u7b56\u7565\uff0c\u5b9e\u73b0\u4eba\u5f62\u673a\u5668\u4eba\u7cbe\u786e\u7684\u5168\u8eab\u8fd0\u52a8\u63a7\u5236\uff0c\u7279\u522b\u9488\u5bf9\u79fb\u52a8\u64cd\u4f5c\u4efb\u52a1\u8fdb\u884c\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u901a\u7528\u8fd0\u52a8\u8ddf\u8e2a\u7b56\u7565\u5728\u518d\u73b0\u4eba\u7c7b\u591a\u6837\u5316\u8fd0\u52a8\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7f3a\u4e4f\u79fb\u52a8\u64cd\u4f5c\u6240\u9700\u7684\u7cbe\u5ea6\u548c\u7269\u4f53\u611f\u77e5\u80fd\u529b\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7cbe\u786e\u7684\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u6b8b\u5dee\u5b66\u4e60\uff1a\u7b2c\u4e00\u9636\u6bb5\u8bad\u7ec3\u901a\u7528\u8fd0\u52a8\u8ddf\u8e2a\u7b56\u7565\u4f5c\u4e3a\u57fa\u7840\uff0c\u7b2c\u4e8c\u9636\u6bb5\u5b66\u4e60\u9ad8\u6548\u7684\u6b8b\u5dee\u7b56\u7565\u6765\u7cbe\u70bc\u8f93\u51fa\uff0c\u5e76\u8bbe\u8ba1\u4e86\u70b9\u4e91\u7269\u4f53\u8ddf\u8e2a\u5956\u52b1\u3001\u63a5\u89e6\u5956\u52b1\u548c\u8bfe\u7a0b\u5f0f\u865a\u62df\u7269\u4f53\u63a7\u5236\u5668\u6765\u4f18\u5316\u8bad\u7ec3\u3002", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9eUnitree G1\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5728\u4efb\u52a1\u6210\u529f\u7387\u3001\u8bad\u7ec3\u6548\u7387\u548c\u9c81\u68d2\u6027\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "ResMimic\u6846\u67b6\u901a\u8fc7\u6b8b\u5dee\u5b66\u4e60\u6709\u6548\u7ed3\u5408\u4e86\u4eba\u7c7b\u8fd0\u52a8\u6570\u636e\u548c\u7cbe\u786e\u63a7\u5236\u9700\u6c42\uff0c\u4e3a\u4eba\u5f62\u673a\u5668\u4eba\u7684\u79fb\u52a8\u64cd\u4f5c\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04474", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04474", "abs": "https://arxiv.org/abs/2510.04474", "authors": ["Gang Li", "Yan Chen", "Ming Lin", "Tianbao Yang"], "title": "DRPO: Efficient Reasoning via Decoupled Reward Policy Optimization", "comment": "20 pages, 7 figures", "summary": "Recent large reasoning models (LRMs) driven by reinforcement learning\nalgorithms (e.g., GRPO) have achieved remarkable performance on challenging\nreasoning tasks. However, these models suffer from overthinking, generating\nunnecessarily long and redundant reasoning even for simple questions, which\nsubstantially increases computational cost and response latency. While existing\nmethods incorporate length rewards to GRPO to promote concise reasoning, they\nincur significant performance degradation. We identify the root cause: when\nrewards for correct but long rollouts are penalized, GRPO's group-relative\nadvantage function can assign them negative advantages, actively discouraging\nvalid reasoning. To overcome this, we propose Decoupled Reward Policy\nOptimization (DRPO), a novel framework that decouples the length-based learning\nsignal of correct rollouts from incorrect ones. DRPO ensures that reward\nsignals for correct rollouts are normalized solely within the positive group,\nshielding them from interference by negative samples. The DRPO's objective is\ngrounded in integrating an optimized positive data distribution, which\nmaximizes length-based rewards under a KL regularization, into a discriminative\nobjective. We derive a closed-form solution for this distribution, enabling\nefficient computation of the objective and its gradients using only on-policy\ndata and importance weighting. Of independent interest, this formulation is\ngeneral and can incorporate other preference rewards of positive data beyond\nlength. Experiments on mathematical reasoning tasks demonstrate DRPO's\nsignificant superiority over six efficient reasoning baselines. Notably, with a\n1.5B model, our method achieves 77\\% length reduction with only 1.1\\%\nperformance loss on simple questions like GSM8k dataset, while the follow-up\nbaseline sacrifices 4.3\\% for 68\\% length reduction.", "AI": {"tldr": "DRPO\u662f\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6b63\u786e\u548c\u9519\u8bef\u63a8\u7406\u7684\u957f\u5ea6\u5956\u52b1\u4fe1\u53f7\u89e3\u8026\uff0c\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u8fc7\u5ea6\u601d\u8003\u7684\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u63a8\u7406\u957f\u5ea6\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u63a8\u7406\u6a21\u578b\u5b58\u5728\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5373\u4f7f\u7b80\u5355\u95ee\u9898\u4e5f\u4f1a\u751f\u6210\u5197\u957f\u5197\u4f59\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u589e\u52a0\u4e86\u8ba1\u7b97\u6210\u672c\u548c\u54cd\u5e94\u5ef6\u8fdf\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u957f\u5ea6\u5956\u52b1\u6765\u4fc3\u8fdb\u7b80\u6d01\u63a8\u7406\uff0c\u4f46\u4f1a\u5bfc\u81f4\u663e\u8457\u7684\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faDRPO\u6846\u67b6\uff0c\u5c06\u6b63\u786e\u63a8\u7406\u548c\u9519\u8bef\u63a8\u7406\u7684\u957f\u5ea6\u5956\u52b1\u4fe1\u53f7\u89e3\u8026\uff0c\u786e\u4fdd\u6b63\u786e\u63a8\u7406\u7684\u5956\u52b1\u4fe1\u53f7\u4ec5\u5728\u6b63\u6837\u672c\u7ec4\u5185\u5f52\u4e00\u5316\uff0c\u907f\u514d\u8d1f\u6837\u672c\u7684\u5e72\u6270\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f18\u5316\u6b63\u6570\u636e\u5206\u5e03\uff0c\u5728KL\u6b63\u5219\u5316\u4e0b\u6700\u5927\u5316\u957f\u5ea6\u5956\u52b1\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\uff0cDRPO\u663e\u8457\u4f18\u4e8e\u516d\u4e2a\u9ad8\u6548\u63a8\u7406\u57fa\u7ebf\u65b9\u6cd5\u3002\u4f7f\u75281.5B\u6a21\u578b\uff0c\u5728GSM8k\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8677%\u7684\u957f\u5ea6\u51cf\u5c11\uff0c\u4ec5\u635f\u59311.1%\u7684\u6027\u80fd\uff0c\u800c\u57fa\u7ebf\u65b9\u6cd5\u9700\u8981\u727a\u72724.3%\u6027\u80fd\u624d\u80fd\u5b9e\u73b068%\u7684\u957f\u5ea6\u51cf\u5c11\u3002", "conclusion": "DRPO\u6709\u6548\u89e3\u51b3\u4e86\u63a8\u7406\u6a21\u578b\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u63a8\u7406\u957f\u5ea6\uff0c\u8be5\u6846\u67b6\u5177\u6709\u901a\u7528\u6027\uff0c\u53ef\u4ee5\u6574\u5408\u9664\u957f\u5ea6\u5916\u7684\u5176\u4ed6\u504f\u597d\u5956\u52b1\u3002"}}
{"id": "2510.04480", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04480", "abs": "https://arxiv.org/abs/2510.04480", "authors": ["Yunuo Cen", "Zixuan Wang", "Jintao Zhang", "Zhiwei Zhang", "Xuanyao Fong"], "title": "On Continuous Optimization for Constraint Satisfaction Problems", "comment": null, "summary": "Constraint satisfaction problems (CSPs) are fundamental in mathematics,\nphysics, and theoretical computer science. While conflict-driven clause\nlearning Boolean Satisfiability (SAT) solvers have achieved remarkable success\nand become the mainstream approach for Boolean satisfiability, recent advances\nshow that modern continuous local search (CLS) solvers can achieve highly\ncompetitive results on certain classes of SAT problems. Motivated by these\nadvances, we extend the CLS framework from Boolean SAT to general CSP with\nfinite-domain variables and expressive constraints. We present FourierCSP, a\ncontinuous optimization framework that generalizes the Walsh-Fourier transform\nto CSP, allowing for transforming versatile constraints to compact multilinear\npolynomials, thereby avoiding the need for auxiliary variables and\nmemory-intensive encodings. Our approach leverages efficient evaluation and\ndifferentiation of the objective via circuit-output probability and employs a\nprojected gradient optimization method with theoretical guarantees. Empirical\nresults on benchmark suites demonstrate that FourierCSP is scalable and\ncompetitive, significantly broadening the class of problems that can be\nefficiently solved by CLS techniques.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86FourierCSP\u6846\u67b6\uff0c\u5c06\u8fde\u7eed\u5c40\u90e8\u641c\u7d22\u4ece\u5e03\u5c14SAT\u6269\u5c55\u5230\u6709\u9650\u57df\u53d8\u91cf\u7684\u901a\u7528CSP\uff0c\u901a\u8fc7Walsh-Fourier\u53d8\u6362\u5c06\u7ea6\u675f\u8f6c\u6362\u4e3a\u7d27\u51d1\u7684\u591a\u7ebf\u6027\u591a\u9879\u5f0f\uff0c\u65e0\u9700\u8f85\u52a9\u53d8\u91cf\u548c\u5185\u5b58\u5bc6\u96c6\u578b\u7f16\u7801\u3002", "motivation": "\u53d7\u73b0\u4ee3\u8fde\u7eed\u5c40\u90e8\u641c\u7d22\u6c42\u89e3\u5668\u5728\u7279\u5b9aSAT\u95ee\u9898\u4e0a\u53d6\u5f97\u7ade\u4e89\u6027\u7ed3\u679c\u7684\u542f\u53d1\uff0c\u5e0c\u671b\u5c06CLS\u6846\u67b6\u4ece\u5e03\u5c14SAT\u6269\u5c55\u5230\u901a\u7528CSP\uff0c\u4ee5\u6269\u5927CLS\u6280\u672f\u80fd\u9ad8\u6548\u89e3\u51b3\u7684\u95ee\u9898\u7c7b\u522b\u3002", "method": "\u4f7f\u7528Walsh-Fourier\u53d8\u6362\u5c06\u591a\u6837\u5316\u7ea6\u675f\u8f6c\u6362\u4e3a\u7d27\u51d1\u7684\u591a\u7ebf\u6027\u591a\u9879\u5f0f\uff0c\u901a\u8fc7\u7535\u8def\u8f93\u51fa\u6982\u7387\u8fdb\u884c\u9ad8\u6548\u7684\u76ee\u6807\u51fd\u6570\u8bc4\u4f30\u548c\u5fae\u5206\uff0c\u5e76\u91c7\u7528\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u6295\u5f71\u68af\u5ea6\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cFourierCSP\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u7ade\u4e89\u529b\uff0c\u663e\u8457\u6269\u5927\u4e86CLS\u6280\u672f\u80fd\u9ad8\u6548\u89e3\u51b3\u7684CSP\u95ee\u9898\u7c7b\u522b\u3002", "conclusion": "FourierCSP\u6210\u529f\u5c06\u8fde\u7eed\u5c40\u90e8\u641c\u7d22\u6846\u67b6\u6269\u5c55\u5230\u901a\u7528CSP\uff0c\u901a\u8fc7\u5085\u91cc\u53f6\u53d8\u6362\u65b9\u6cd5\u907f\u514d\u4e86\u4f20\u7edf\u7f16\u7801\u7684\u5185\u5b58\u5f00\u9500\uff0c\u4e3aCSP\u6c42\u89e3\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2510.04488", "categories": ["cs.AI", "cs.IT", "math.IT", "I.2.4"], "pdf": "https://arxiv.org/pdf/2510.04488", "abs": "https://arxiv.org/abs/2510.04488", "authors": ["Edward Y. Chang", "Ethan Y. Chang"], "title": "Multi-Agent Collaborative Intelligence: Dual-Dial Control for Reliable LLM Reasoning", "comment": "27 pages, 5 figures, 21 tables", "summary": "Multi-agent debate often wastes compute by using a fixed adversarial stance,\naggregating without deliberation, or stopping on heuristics. We introduce MACI,\nan active controller with two independent dials that decouple information from\nbehavior: an information dial that gates evidence by quality, and a behavior\ndial that schedules contentiousness from exploration to consolidation. A\nmoderator tracks disagreement, overlap, evidence quality, and argument quality,\nand halts when gains plateau. We provide theory-lite guarantees for\nnonincreasing dispersion and provable termination, with a budget-feasible\nscheduler. Across clinical diagnosis and news-bias tasks, MACI improves\naccuracy and calibration while reducing tokens, and converts residual\nuncertainty into precision RAG plans that specify what to retrieve next. We use\na cross-family LLM judge (CRIT) as a conservative soft weight and stop signal,\nvalidated for order invariance and judge-swap stability; stability depends on\nusing high-capability judges. MACI turns debate into a budget-aware,\nmeasurable, and provably terminating controller.", "AI": {"tldr": "MACI\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u4fe1\u606f\u62e8\u76d8\u548c\u884c\u4e3a\u62e8\u76d8\u5206\u79bb\u4fe1\u606f\u4e0e\u884c\u4e3a\uff0c\u4f7f\u7528\u8c03\u8282\u5668\u8ddf\u8e2a\u8fa9\u8bba\u8d28\u91cf\u5e76\u5728\u6536\u76ca\u5e73\u7a33\u65f6\u505c\u6b62\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u540c\u65f6\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u5b58\u5728\u8ba1\u7b97\u6d6a\u8d39\u95ee\u9898\uff1a\u4f7f\u7528\u56fa\u5b9a\u5bf9\u6297\u7acb\u573a\u3001\u65e0\u5ba1\u8bae\u805a\u5408\u6216\u57fa\u4e8e\u542f\u53d1\u5f0f\u505c\u6b62\u3002\u9700\u8981\u66f4\u9ad8\u6548\u7684\u8fa9\u8bba\u63a7\u5236\u673a\u5236\u3002", "method": "\u5f15\u5165MACI\u63a7\u5236\u5668\uff0c\u5305\u542b\u4fe1\u606f\u62e8\u76d8\uff08\u6309\u8d28\u91cf\u7b5b\u9009\u8bc1\u636e\uff09\u548c\u884c\u4e3a\u62e8\u76d8\uff08\u4ece\u63a2\u7d22\u5230\u6574\u5408\u7684\u4e89\u8bae\u6027\u8c03\u5ea6\uff09\uff0c\u8c03\u8282\u5668\u8ddf\u8e2a\u5206\u6b67\u3001\u91cd\u53e0\u3001\u8bc1\u636e\u8d28\u91cf\u548c\u8bba\u8bc1\u8d28\u91cf\uff0c\u5728\u6536\u76ca\u5e73\u7a33\u65f6\u505c\u6b62\u3002", "result": "\u5728\u4e34\u5e8a\u8bca\u65ad\u548c\u65b0\u95fb\u504f\u89c1\u4efb\u52a1\u4e2d\uff0cMACI\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u6821\u51c6\u5ea6\uff0c\u540c\u65f6\u51cf\u5c11\u4e86token\u4f7f\u7528\uff0c\u5e76\u5c06\u5269\u4f59\u4e0d\u786e\u5b9a\u6027\u8f6c\u5316\u4e3a\u7cbe\u786e\u7684RAG\u68c0\u7d22\u8ba1\u5212\u3002", "conclusion": "MACI\u5c06\u8fa9\u8bba\u8f6c\u53d8\u4e3a\u9884\u7b97\u611f\u77e5\u3001\u53ef\u6d4b\u91cf\u4e14\u53ef\u8bc1\u660e\u7ec8\u6b62\u7684\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u7406\u8bba\u8f7b\u91cf\u7ea7\u4fdd\u8bc1\u5b9e\u73b0\u5206\u6563\u5ea6\u4e0d\u589e\u52a0\u548c\u53ef\u8bc1\u660e\u7ec8\u6b62\u3002"}}
{"id": "2510.04532", "categories": ["cs.AI", "cs.CL", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04532", "abs": "https://arxiv.org/abs/2510.04532", "authors": ["Xurui Song", "Shuo Huai", "JingJing Jiang", "Jiayi Kong", "Jun Luo"], "title": "More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in Training Vision-Language Driving Models", "comment": "The dataset will be released publicly once the paper is accepted for\n  publication", "summary": "Vision-Language Model (VLM) driving agents promise explainable end-to-end\nautonomy by first producing natural-language reasoning and then predicting\ntrajectory planning. However, whether planning is causally driven by this\nreasoning remains a critical but unverified assumption. To investigate this, we\nbuild DriveMind, a large-scale driving Visual Question Answering (VQA) corpus\nwith plan-aligned Chain-of-Thought (CoT), automatically generated from nuPlan.\nOur data generation process converts sensors and annotations into structured\ninputs and, crucially, separates priors from to-be-reasoned signals, enabling\nclean information ablations. Using DriveMind, we train representative VLM\nagents with Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization\n(GRPO) and evaluate them with nuPlan's metrics. Our results, unfortunately,\nindicate a consistent causal disconnect in reasoning-planning: removing\nego/navigation priors causes large drops in planning scores, whereas removing\nCoT produces only minor changes. Attention analysis further shows that planning\nprimarily focuses on priors rather than the CoT. Based on this evidence, we\npropose the Reasoning-Planning Decoupling Hypothesis, positing that the\ntraining-yielded reasoning is an ancillary byproduct rather than a causal\nmediator. To enable efficient diagnosis, we also introduce a novel,\ntraining-free probe that measures an agent's reliance on priors by evaluating\nits planning robustness against minor input perturbations. In summary, we\nprovide the community with a new dataset and a diagnostic tool to evaluate the\ncausal fidelity of future models.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0VLM\u9a7e\u9a76\u4ee3\u7406\u4e2d\u7684\u63a8\u7406\u4e0e\u89c4\u5212\u5b58\u5728\u56e0\u679c\u8131\u8282\uff0c\u89c4\u5212\u4e3b\u8981\u4f9d\u8d56\u5148\u9a8c\u77e5\u8bc6\u800c\u975e\u63a8\u7406\u8fc7\u7a0b\uff0c\u63d0\u51fa\u4e86\u63a8\u7406-\u89c4\u5212\u89e3\u8026\u5047\u8bf4\u3002", "motivation": "\u9a8c\u8bc1VLM\u9a7e\u9a76\u4ee3\u7406\u4e2d\u8f68\u8ff9\u89c4\u5212\u662f\u5426\u771f\u6b63\u7531\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u56e0\u679c\u9a71\u52a8\uff0c\u8fd9\u4e00\u5173\u952e\u5047\u8bbe\u5c1a\u672a\u88ab\u8bc1\u5b9e\u3002", "method": "\u6784\u5efaDriveMind\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4fe1\u606f\u6d88\u878d\u5b9e\u9a8c\u8bad\u7ec3VLM\u4ee3\u7406\uff0c\u5e76\u4f7f\u7528\u6ce8\u610f\u529b\u5206\u6790\u6765\u7814\u7a76\u63a8\u7406\u4e0e\u89c4\u5212\u7684\u56e0\u679c\u5173\u7cfb\u3002", "result": "\u79fb\u9664\u5148\u9a8c\u77e5\u8bc6\u5bfc\u81f4\u89c4\u5212\u8bc4\u5206\u5927\u5e45\u4e0b\u964d\uff0c\u800c\u79fb\u9664\u63a8\u7406\u94fe\u4ec5\u4ea7\u751f\u5fae\u5c0f\u53d8\u5316\uff0c\u8868\u660e\u89c4\u5212\u4e3b\u8981\u4f9d\u8d56\u5148\u9a8c\u800c\u975e\u63a8\u7406\u3002", "conclusion": "\u63d0\u51fa\u4e86\u63a8\u7406-\u89c4\u5212\u89e3\u8026\u5047\u8bf4\uff0c\u8ba4\u4e3a\u8bad\u7ec3\u4ea7\u751f\u7684\u63a8\u7406\u662f\u9644\u5e26\u4ea7\u7269\u800c\u975e\u56e0\u679c\u4e2d\u4ecb\uff0c\u5e76\u63d0\u4f9b\u4e86\u8bca\u65ad\u5de5\u5177\u6765\u8bc4\u4f30\u672a\u6765\u6a21\u578b\u7684\u56e0\u679c\u4fdd\u771f\u5ea6\u3002"}}
{"id": "2510.04491", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04491", "abs": "https://arxiv.org/abs/2510.04491", "authors": ["Muyu He", "Anand Kumar", "Tsach Mackey", "Meghana Rajeev", "James Zou", "Nazneen Rajani"], "title": "Impatient Users Confuse AI Agents: High-fidelity Simulations of Human Traits for Testing Agents", "comment": "25 pages", "summary": "Despite rapid progress in building conversational AI agents, robustness is\nstill largely untested. Small shifts in user behavior, such as being more\nimpatient, incoherent, or skeptical, can cause sharp drops in agent\nperformance, revealing how brittle current AI agents are. Today's benchmarks\nfail to capture this fragility: agents may perform well under standard\nevaluations but degrade spectacularly in more realistic and varied settings. We\naddress this robustness testing gap by introducing TraitBasis, a lightweight,\nmodel-agnostic method for systematically stress testing AI agents. TraitBasis\nlearns directions in activation space corresponding to steerable user traits\n(e.g., impatience or incoherence), which can be controlled, scaled, composed,\nand applied at inference time without any fine-tuning or extra data. Using\nTraitBasis, we extend $\\tau$-Bench to $\\tau$-Trait, where user behaviors are\naltered via controlled trait vectors. We observe on average a 2%-30%\nperformance degradation on $\\tau$-Trait across frontier models, highlighting\nthe lack of robustness of current AI agents to variations in user behavior.\nTogether, these results highlight both the critical role of robustness testing\nand the promise of TraitBasis as a simple, data-efficient, and compositional\ntool. By powering simulation-driven stress tests and training loops, TraitBasis\nopens the door to building AI agents that remain reliable in the unpredictable\ndynamics of real-world human interactions. We have open-sourced $\\tau$-Trai\nacross four domains: airline, retail, telecom, and telehealth, so the community\ncan systematically QA their agents under realistic, behaviorally diverse\nintents and trait scenarios: https://github.com/collinear-ai/tau-trait.", "AI": {"tldr": "TraitBasis\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u538b\u529b\u6d4b\u8bd5\u6765\u8bc4\u4f30AI\u4ee3\u7406\u7684\u9c81\u68d2\u6027\u3002\u8be5\u65b9\u6cd5\u5b66\u4e60\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u53ef\u64cd\u63a7\u7684\u7528\u6237\u7279\u5f81\u65b9\u5411\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u5728\u63a8\u7406\u65f6\u63a7\u5236\u3001\u7f29\u653e\u548c\u7ec4\u5408\u8fd9\u4e9b\u7279\u5f81\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u5728\u7528\u6237\u884c\u4e3a\u8f7b\u5fae\u53d8\u5316\uff08\u5982\u66f4\u4e0d\u8010\u70e6\u3001\u8bed\u65e0\u4f26\u6b21\u6216\u6000\u7591\uff09\u65f6\u6027\u80fd\u4f1a\u6025\u5267\u4e0b\u964d\uff0c\u663e\u793a\u51fa\u5176\u8106\u5f31\u6027\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u6355\u6349\u8fd9\u79cd\u8106\u5f31\u6027\uff0c\u9700\u8981\u66f4\u73b0\u5b9e\u7684\u9c81\u68d2\u6027\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "TraitBasis\u5b66\u4e60\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u5bf9\u5e94\u53ef\u64cd\u63a7\u7528\u6237\u7279\u5f81\u7684\u65b9\u5411\uff0c\u8fd9\u4e9b\u7279\u5f81\u5411\u91cf\u53ef\u4ee5\u5728\u63a8\u7406\u65f6\u88ab\u63a7\u5236\u3001\u7f29\u653e\u3001\u7ec4\u5408\u548c\u5e94\u7528\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u989d\u5916\u6570\u636e\u3002\u8be5\u65b9\u6cd5\u6269\u5c55\u4e86\u03c4-Bench\u5230\u03c4-Trait\uff0c\u901a\u8fc7\u53d7\u63a7\u7279\u5f81\u5411\u91cf\u6539\u53d8\u7528\u6237\u884c\u4e3a\u3002", "result": "\u5728\u03c4-Trait\u4e0a\uff0c\u524d\u6cbf\u6a21\u578b\u7684\u6027\u80fd\u5e73\u5747\u4e0b\u964d2%-30%\uff0c\u7a81\u663e\u4e86\u5f53\u524dAI\u4ee3\u7406\u5bf9\u7528\u6237\u884c\u4e3a\u53d8\u5316\u7684\u9c81\u68d2\u6027\u4e0d\u8db3\u3002", "conclusion": "TraitBasis\u4f5c\u4e3a\u4e00\u4e2a\u7b80\u5355\u3001\u6570\u636e\u9ad8\u6548\u4e14\u53ef\u7ec4\u5408\u7684\u5de5\u5177\uff0c\u4e3a\u6a21\u62df\u9a71\u52a8\u7684\u538b\u529b\u6d4b\u8bd5\u548c\u8bad\u7ec3\u5faa\u73af\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u5728\u771f\u5b9e\u4e16\u754c\u4eba\u7c7b\u4ea4\u4e92\u4e0d\u53ef\u9884\u6d4b\u52a8\u6001\u4e2d\u4fdd\u6301\u53ef\u9760\u7684AI\u4ee3\u7406\u3002"}}
{"id": "2510.04514", "categories": ["cs.AI", "cs.CE", "cs.CL", "cs.CV", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.04514", "abs": "https://arxiv.org/abs/2510.04514", "authors": ["Rachneet Kaur", "Nishan Srishankar", "Zhen Zeng", "Sumitra Ganesh", "Manuela Veloso"], "title": "ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in Complex Chart Question Answering", "comment": "53 pages, 12 figures, 15 tables", "summary": "Recent multimodal LLMs have shown promise in chart-based visual question\nanswering, but their performance declines sharply on unannotated charts, those\nrequiring precise visual interpretation rather than relying on textual\nshortcuts. To address this, we introduce ChartAgent, a novel agentic framework\nthat explicitly performs visual reasoning directly within the chart's spatial\ndomain. Unlike textual chain-of-thought reasoning, ChartAgent iteratively\ndecomposes queries into visual subtasks and actively manipulates and interacts\nwith chart images through specialized actions such as drawing annotations,\ncropping regions (e.g., segmenting pie slices, isolating bars), and localizing\naxes, using a library of chart-specific vision tools to fulfill each subtask.\nThis iterative reasoning process closely mirrors human cognitive strategies for\nchart comprehension. ChartAgent achieves state-of-the-art accuracy on the\nChartBench and ChartX benchmarks, surpassing prior methods by up to 16.07%\nabsolute gain overall and 17.31% on unannotated, numerically intensive queries.\nFurthermore, our analyses show that ChartAgent is (a) effective across diverse\nchart types, (b) achieve the highest scores across varying visual and reasoning\ncomplexity levels, and (c) serves as a plug-and-play framework that boosts\nperformance across diverse underlying LLMs. Our work is among the first to\ndemonstrate visually grounded reasoning for chart understanding using\ntool-augmented multimodal agents.", "AI": {"tldr": "ChartAgent\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u56fe\u8868\u7a7a\u95f4\u57df\u4e2d\u6267\u884c\u89c6\u89c9\u63a8\u7406\u6765\u89e3\u51b3\u591a\u6a21\u6001LLM\u5728\u65e0\u6ce8\u91ca\u56fe\u8868\u4e0a\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001LLM\u5728\u57fa\u4e8e\u56fe\u8868\u7684\u89c6\u89c9\u95ee\u7b54\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u7cbe\u786e\u89c6\u89c9\u89e3\u91ca\u800c\u975e\u4f9d\u8d56\u6587\u672c\u6377\u5f84\u7684\u65e0\u6ce8\u91ca\u56fe\u8868\u4e0a\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "method": "ChartAgent\u8fed\u4ee3\u5730\u5c06\u67e5\u8be2\u5206\u89e3\u4e3a\u89c6\u89c9\u5b50\u4efb\u52a1\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u89c6\u89c9\u5de5\u5177\uff08\u5982\u7ed8\u5236\u6ce8\u91ca\u3001\u88c1\u526a\u533a\u57df\u3001\u5b9a\u4f4d\u5750\u6807\u8f74\uff09\u4e3b\u52a8\u64cd\u4f5c\u548c\u4ea4\u4e92\u56fe\u8868\u56fe\u50cf\uff0c\u6a21\u62df\u4eba\u7c7b\u56fe\u8868\u7406\u89e3\u7684\u8ba4\u77e5\u7b56\u7565\u3002", "result": "\u5728ChartBench\u548cChartX\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u51c6\u786e\u7387\uff0c\u6bd4\u5148\u524d\u65b9\u6cd5\u6574\u4f53\u63d0\u534716.07%\uff0c\u5728\u65e0\u6ce8\u91ca\u3001\u6570\u503c\u5bc6\u96c6\u578b\u67e5\u8be2\u4e0a\u63d0\u534717.31%\u3002", "conclusion": "ChartAgent\u662f\u9996\u6279\u4f7f\u7528\u5de5\u5177\u589e\u5f3a\u591a\u6a21\u6001\u4ee3\u7406\u8fdb\u884c\u89c6\u89c9\u57fa\u7840\u63a8\u7406\u7684\u56fe\u8868\u7406\u89e3\u5de5\u4f5c\u4e4b\u4e00\uff0c\u53ef\u8de8\u4e0d\u540c\u56fe\u8868\u7c7b\u578b\u548cLLM\u5b9e\u73b0\u5373\u63d2\u5373\u7528\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2510.04520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04520", "abs": "https://arxiv.org/abs/2510.04520", "authors": ["Hanyu Wang", "Ruohan Xie", "Yutong Wang", "Guoxiong Gao", "Xintao Yu", "Bin Dong"], "title": "Aria: An Agent For Retrieval and Iterative Auto-Formalization via Dependency Graph", "comment": null, "summary": "Accurate auto-formalization of theorem statements is essential for advancing\nautomated discovery and verification of research-level mathematics, yet remains\na major bottleneck for LLMs due to hallucinations, semantic mismatches, and\ntheir inability to synthesize new definitions. To tackle these issues, we\npresent Aria (Agent for Retrieval and Iterative Autoformalization), a system\nfor conjecture-level formalization in Lean that emulates human expert reasoning\nvia a two-phase Graph-of-Thought process: recursively decomposing statements\ninto a dependency graph and then constructing formalizations from grounded\nconcepts. To ensure semantic correctness, we introduce AriaScorer, a checker\nthat retrieves definitions from Mathlib for term-level grounding, enabling\nrigorous and reliable verification. We evaluate Aria on diverse benchmarks. On\nProofNet, it achieves 91.6% compilation success rate and 68.5% final accuracy,\nsurpassing previous methods. On FATE-X, a suite of challenging algebra problems\nfrom research literature, it outperforms the best baseline with 44.0% vs. 24.0%\nfinal accuracy. On a dataset of homological conjectures, Aria reaches 42.9%\nfinal accuracy while all other models score 0%.", "AI": {"tldr": "Aria\u662f\u4e00\u4e2a\u7528\u4e8e\u5b9a\u7406\u9648\u8ff0\u81ea\u52a8\u5f62\u5f0f\u5316\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u56fe\u63a8\u7406\u8fc7\u7a0b\u6a21\u62df\u4eba\u7c7b\u4e13\u5bb6\u63a8\u7406\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u51c6\u786e\u81ea\u52a8\u5f62\u5f0f\u5316\u5b9a\u7406\u9648\u8ff0\u5bf9\u4e8e\u63a8\u8fdb\u6570\u5b66\u53d1\u73b0\u548c\u9a8c\u8bc1\u81f3\u5173\u91cd\u8981\uff0c\u4f46LLMs\u5b58\u5728\u5e7b\u89c9\u3001\u8bed\u4e49\u4e0d\u5339\u914d\u548c\u65e0\u6cd5\u5408\u6210\u65b0\u5b9a\u4e49\u7b49\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u56fe\u63a8\u7406\u8fc7\u7a0b\uff1a\u9012\u5f52\u5206\u89e3\u8bed\u53e5\u4e3a\u4f9d\u8d56\u56fe\uff0c\u7136\u540e\u4ece\u57fa\u7840\u6982\u5ff5\u6784\u5efa\u5f62\u5f0f\u5316\uff1b\u5f15\u5165AriaScorer\u4eceMathlib\u68c0\u7d22\u5b9a\u4e49\u8fdb\u884c\u672f\u8bed\u7ea7\u57fa\u7840\u9a8c\u8bc1\u3002", "result": "\u5728ProofNet\u4e0a\u8fbe\u523091.6%\u7f16\u8bd1\u6210\u529f\u7387\u548c68.5%\u6700\u7ec8\u51c6\u786e\u7387\uff1b\u5728FATE-X\u4e0a44.0% vs 24.0%\u4f18\u4e8e\u6700\u4f73\u57fa\u7ebf\uff1b\u5728\u540c\u8c03\u731c\u60f3\u6570\u636e\u96c6\u4e0a\u8fbe\u523042.9%\u51c6\u786e\u7387\u800c\u5176\u4ed6\u6a21\u578b\u4e3a0%\u3002", "conclusion": "Aria\u7cfb\u7edf\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u4e13\u5bb6\u63a8\u7406\u548c\u4e25\u683c\u9a8c\u8bc1\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9a\u7406\u9648\u8ff0\u81ea\u52a8\u5f62\u5f0f\u5316\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.04542", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04542", "abs": "https://arxiv.org/abs/2510.04542", "authors": ["Wolfgang Lehrach", "Daniel Hennes", "Miguel Lazaro-Gredilla", "Xinghua Lou", "Carter Wendelken", "Zun Li", "Antoine Dedieu", "Jordi Grau-Moya", "Marc Lanctot", "Atil Iscen", "John Schultz", "Marcus Chiam", "Ian Gemp", "Piotr Zielinski", "Satinder Singh", "Kevin P. Murphy"], "title": "Code World Models for General Game Playing", "comment": null, "summary": "Large Language Models (LLMs) reasoning abilities are increasingly being\napplied to classical board and card games, but the dominant approach --\ninvolving prompting for direct move generation -- has significant drawbacks. It\nrelies on the model's implicit fragile pattern-matching capabilities, leading\nto frequent illegal moves and strategically shallow play. Here we introduce an\nalternative approach: We use the LLM to translate natural language rules and\ngame trajectories into a formal, executable world model represented as Python\ncode. This generated model -- comprising functions for state transition, legal\nmove enumeration, and termination checks -- serves as a verifiable simulation\nengine for high-performance planning algorithms like Monte Carlo tree search\n(MCTS). In addition, we prompt the LLM to generate heuristic value functions\n(to make MCTS more efficient), and inference functions (to estimate hidden\nstates in imperfect information games). Our method offers three distinct\nadvantages compared to directly using the LLM as a policy: (1) Verifiability:\nThe generated CWM serves as a formal specification of the game's rules,\nallowing planners to algorithmically enumerate valid actions and avoid illegal\nmoves, contingent on the correctness of the synthesized model; (2) Strategic\nDepth: We combine LLM semantic understanding with the deep search power of\nclassical planners; and (3) Generalization: We direct the LLM to focus on the\nmeta-task of data-to-code translation, enabling it to adapt to new games more\neasily. We evaluate our agent on 10 different games, of which 4 are novel and\ncreated for this paper. 5 of the games are fully observed (perfect\ninformation), and 5 are partially observed (imperfect information). We find\nthat our method outperforms or matches Gemini 2.5 Pro in 9 out of the 10\nconsidered games.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\uff1a\u4f7f\u7528LLM\u5c06\u81ea\u7136\u8bed\u8a00\u89c4\u5219\u548c\u6e38\u620f\u8f68\u8ff9\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684Python\u4e16\u754c\u6a21\u578b\uff0c\u7ed3\u5408MCTS\u89c4\u5212\u7b97\u6cd5\uff0c\u66ff\u4ee3\u76f4\u63a5\u4f7f\u7528LLM\u751f\u6210\u52a8\u4f5c\u7684\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u4f7f\u7528LLM\u76f4\u63a5\u751f\u6210\u6e38\u620f\u52a8\u4f5c\u7684\u65b9\u6cd5\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff1a\u4f9d\u8d56\u6a21\u578b\u8106\u5f31\u7684\u6a21\u5f0f\u5339\u914d\u80fd\u529b\uff0c\u7ecf\u5e38\u4ea7\u751f\u975e\u6cd5\u52a8\u4f5c\uff0c\u7b56\u7565\u6df1\u5ea6\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528LLM\u5c06\u6e38\u620f\u89c4\u5219\u8f6c\u6362\u4e3aPython\u4ee3\u7801\u5f62\u5f0f\u7684\u4e16\u754c\u6a21\u578b\uff0c\u5305\u542b\u72b6\u6001\u8f6c\u6362\u3001\u5408\u6cd5\u52a8\u4f5c\u679a\u4e3e\u548c\u7ec8\u6b62\u68c0\u67e5\u529f\u80fd\uff0c\u5e76\u751f\u6210\u542f\u53d1\u5f0f\u4ef7\u503c\u51fd\u6570\u548c\u63a8\u7406\u51fd\u6570\uff0c\u7ed3\u5408MCTS\u89c4\u5212\u7b97\u6cd5\u3002", "result": "\u572810\u4e2a\u6e38\u620f\uff084\u4e2a\u65b0\u521b\u5efa\uff09\u4e0a\u8bc4\u4f30\uff0c\u5176\u4e2d5\u4e2a\u5b8c\u5168\u89c2\u5bdf\u30015\u4e2a\u90e8\u5206\u89c2\u5bdf\u6e38\u620f\u3002\u8be5\u65b9\u6cd5\u57289\u4e2a\u6e38\u620f\u4e2d\u8868\u73b0\u4f18\u4e8e\u6216\u4e0eGemini 2.5 Pro\u76f8\u5f53\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u6027\u3001\u7b56\u7565\u6df1\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\u4e09\u5927\u4f18\u52bf\uff0c\u5c06LLM\u7684\u8bed\u4e49\u7406\u89e3\u4e0e\u7ecf\u5178\u89c4\u5212\u5668\u7684\u6df1\u5ea6\u641c\u7d22\u80fd\u529b\u76f8\u7ed3\u5408\uff0c\u6bd4\u76f4\u63a5\u4f7f\u7528LLM\u4f5c\u4e3a\u7b56\u7565\u66f4\u6709\u6548\u3002"}}
{"id": "2510.04550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04550", "abs": "https://arxiv.org/abs/2510.04550", "authors": ["Pengfei He", "Zhenwei Dai", "Bing He", "Hui Liu", "Xianfeng Tang", "Hanqing Lu", "Juanhui Li", "Jiayuan Ding", "Subhabrata Mukherjee", "Suhang Wang", "Yue Xing", "Jiliang Tang", "Benoit Dumoulin"], "title": "TRAJECT-Bench:A Trajectory-Aware Benchmark for Evaluating Agentic Tool Use", "comment": null, "summary": "Large language model (LLM)-based agents increasingly rely on tool use to\ncomplete real-world tasks. While existing works evaluate the LLMs' tool use\ncapability, they largely focus on the final answers yet overlook the detailed\ntool usage trajectory, i.e., whether tools are selected, parameterized, and\nordered correctly. We introduce TRAJECT-Bench, a trajectory-aware benchmark to\ncomprehensively evaluate LLMs' tool use capability through diverse tasks with\nfine-grained evaluation metrics. TRAJECT-Bench pairs high-fidelity, executable\ntools across practical domains with tasks grounded in production-style APIs,\nand synthesizes trajectories that vary in breadth (parallel calls) and depth\n(interdependent chains). Besides final accuracy, TRAJECT-Bench also reports\ntrajectory-level diagnostics, including tool selection and argument\ncorrectness, and dependency/order satisfaction. Analyses reveal failure modes\nsuch as similar tool confusion and parameter-blind selection, and scaling\nbehavior with tool diversity and trajectory length where the bottleneck of\ntransiting from short to mid-length trajectories is revealed, offering\nactionable guidance for LLMs' tool use.", "AI": {"tldr": "TRAJECT-Bench\u662f\u4e00\u4e2a\u8f68\u8ff9\u611f\u77e5\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30LLM\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u6307\u6807\u5206\u6790\u5de5\u5177\u9009\u62e9\u3001\u53c2\u6570\u5316\u548c\u6392\u5e8f\u7684\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\uff0c\u800c\u5ffd\u89c6\u4e86\u8be6\u7ec6\u7684\u5de5\u5177\u4f7f\u7528\u8f68\u8ff9\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30LLM\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b\u9ad8\u4fdd\u771f\u53ef\u6267\u884c\u5de5\u5177\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u5b9e\u9645\u9886\u57df\u548c\u751f\u4ea7\u98ce\u683cAPI\u7684\u4efb\u52a1\uff0c\u5e76\u5408\u6210\u4e0d\u540c\u5e7f\u5ea6\u548c\u6df1\u5ea6\u7684\u8f68\u8ff9\u3002", "result": "\u63ed\u793a\u4e86\u76f8\u4f3c\u5de5\u5177\u6df7\u6dc6\u3001\u53c2\u6570\u76f2\u9009\u7b49\u5931\u8d25\u6a21\u5f0f\uff0c\u4ee5\u53ca\u4ece\u77ed\u8f68\u8ff9\u5411\u4e2d\u957f\u8f68\u8ff9\u8fc7\u6e21\u65f6\u7684\u74f6\u9888\u95ee\u9898\u3002", "conclusion": "TRAJECT-Bench\u63d0\u4f9b\u4e86\u5bf9LLM\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u5e76\u4e3a\u6539\u8fdb\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u3002"}}
{"id": "2510.04560", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04560", "abs": "https://arxiv.org/abs/2510.04560", "authors": ["Honghao Fu", "Yuan Ouyang", "Kai-Wei Chang", "Yiwei Wang", "Zi Huang", "Yujun Cai"], "title": "ContextNav: Towards Agentic Multimodal In-Context Learning", "comment": null, "summary": "Recent advances demonstrate that multimodal large language models (MLLMs)\nexhibit strong multimodal in-context learning (ICL) capabilities, enabling them\nto adapt to novel vision-language tasks from a few contextual examples.\nHowever, existing ICL approaches face challenges in reconciling scalability\nwith robustness across diverse tasks and noisy contextual examples: manually\nselecting examples produces clean contexts but is labor-intensive and\ntask-specific, while similarity-based retrieval improves scalability but could\nintroduce irrelevant or structurally inconsistent samples that degrade ICL\nperformance. To address these limitations, we propose ContextNav, the first\nagentic framework that integrates the scalability of automated retrieval with\nthe quality and adaptiveness of human-like curation, enabling noise-robust and\ndynamically optimized contextualization for multimodal ICL. ContextNav unifies\ncontext management and noise-robust contextualization within a closed-loop\nworkflow driven by graph-based orchestration. Specifically, it builds a\nresource-aware multimodal embedding pipeline, maintains a retrievable vector\ndatabase, and applies agentic retrieval and structural alignment to construct\nnoise-resilient contexts. An Operational Grammar Graph (OGG) further supports\nadaptive workflow planning and optimization, enabling the agent to refine its\noperational strategies based on downstream ICL feedback. Experimental results\ndemonstrate that ContextNav achieves state-of-the-art performance across\nvarious datasets, underscoring the promise of agentic workflows for advancing\nscalable and robust contextualization in multimodal ICL.", "AI": {"tldr": "\u63d0\u51fa\u4e86ContextNav\u6846\u67b6\uff0c\u9996\u4e2a\u5c06\u81ea\u52a8\u5316\u68c0\u7d22\u7684\u53ef\u6269\u5c55\u6027\u4e0e\u4eba\u7c7b\u5f0f\u7b56\u5212\u8d28\u91cf\u76f8\u7ed3\u5408\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u7684\u566a\u58f0\u9c81\u68d2\u52a8\u6001\u4f18\u5316\u4e0a\u4e0b\u6587\u6784\u5efa\u3002", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u4e4b\u95f4\u5b58\u5728\u77db\u76fe\uff1a\u624b\u52a8\u9009\u62e9\u793a\u4f8b\u8d28\u91cf\u9ad8\u4f46\u52b3\u52a8\u5bc6\u96c6\uff0c\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u68c0\u7d22\u53ef\u6269\u5c55\u4f46\u53ef\u80fd\u5f15\u5165\u4e0d\u76f8\u5173\u6837\u672c\u964d\u4f4e\u6027\u80fd\u3002", "method": "ContextNav\u7edf\u4e00\u4e86\u4e0a\u4e0b\u6587\u7ba1\u7406\u548c\u566a\u58f0\u9c81\u68d2\u4e0a\u4e0b\u6587\u6784\u5efa\uff0c\u91c7\u7528\u57fa\u4e8e\u56fe\u7f16\u6392\u7684\u95ed\u73af\u5de5\u4f5c\u6d41\uff0c\u5305\u62ec\u8d44\u6e90\u611f\u77e5\u591a\u6a21\u6001\u5d4c\u5165\u7ba1\u9053\u3001\u53ef\u68c0\u7d22\u5411\u91cf\u6570\u636e\u5e93\u3001\u4ee3\u7406\u68c0\u7d22\u548c\u7ed3\u6784\u5bf9\u9f50\uff0c\u4ee5\u53ca\u652f\u6301\u81ea\u9002\u5e94\u5de5\u4f5c\u6d41\u89c4\u5212\u7684Operational Grammar Graph\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eContextNav\u5728\u5404\u79cd\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "ContextNav\u5c55\u793a\u4e86\u4ee3\u7406\u5de5\u4f5c\u6d41\u5728\u63a8\u8fdb\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u53ef\u6269\u5c55\u548c\u9c81\u68d2\u4e0a\u4e0b\u6587\u6784\u5efa\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.04568", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04568", "abs": "https://arxiv.org/abs/2510.04568", "authors": ["Naman Gupta", "Shreeyash Gowaikar", "Arun Iyer", "Kirankumar Shiragur", "Ramakrishna B Bairi", "Rishikesh Maurya", "Ritabrata Maiti", "Sankarshan Damle", "Shachee Mishra Gupta"], "title": "COSMIR: Chain Orchestrated Structured Memory for Iterative Reasoning over Long Context", "comment": null, "summary": "Reasoning over very long inputs remains difficult for large language models\n(LLMs). Common workarounds either shrink the input via retrieval (risking\nmissed evidence), enlarge the context window (straining selectivity), or stage\nmultiple agents to read in pieces. In staged pipelines (e.g., Chain of Agents,\nCoA), free-form summaries passed between agents can discard crucial details and\namplify early mistakes. We introduce COSMIR (Chain Orchestrated Structured\nMemory for Iterative Reasoning), a chain-style framework that replaces ad hoc\nmessages with a structured memory. A Planner agent first turns a user query\ninto concrete, checkable sub-questions. worker agents process chunks via a\nfixed micro-cycle: Extract, Infer, Refine, writing all updates to the shared\nmemory. A Manager agent then Synthesizes the final answer directly from the\nmemory. This preserves step-wise read-then-reason benefits while changing both\nthe communication medium (structured memory) and the worker procedure (fixed\nmicro-cycle), yielding higher faithfulness, better long-range aggregation, and\nauditability. On long-context QA from the HELMET suite, COSMIR reduces\npropagation-stage information loss and improves accuracy over a CoA baseline.", "AI": {"tldr": "COSMIR\u662f\u4e00\u4e2a\u89e3\u51b3LLM\u5904\u7406\u957f\u6587\u672c\u63a8\u7406\u95ee\u9898\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5185\u5b58\u548c\u56fa\u5b9a\u5fae\u5faa\u73af\u5de5\u4f5c\u6d41\u7a0b\u6765\u51cf\u5c11\u4fe1\u606f\u4e22\u5931\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u957f\u6587\u672c\u63a8\u7406\u65f6\u5b58\u5728\u4fe1\u606f\u4e22\u5931\u3001\u9009\u62e9\u6027\u5dee\u6216\u9519\u8bef\u4f20\u64ad\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u957f\u6587\u672c\u63a8\u7406\u6846\u67b6\u3002", "method": "\u4f7f\u7528Planner\u5c06\u67e5\u8be2\u8f6c\u5316\u4e3a\u53ef\u68c0\u67e5\u7684\u5b50\u95ee\u9898\uff0cWorker\u901a\u8fc7Extract-Infer-Refine\u5fae\u5faa\u73af\u5904\u7406\u6587\u672c\u5757\u5e76\u66f4\u65b0\u5171\u4eab\u7ed3\u6784\u5316\u5185\u5b58\uff0c\u6700\u540e\u7531Manager\u4ece\u5185\u5b58\u5408\u6210\u6700\u7ec8\u7b54\u6848\u3002", "result": "\u5728HELMET\u5957\u4ef6\u7684\u957f\u6587\u672cQA\u4efb\u52a1\u4e2d\uff0cCOSMIR\u51cf\u5c11\u4e86\u4f20\u64ad\u9636\u6bb5\u7684\u4fe1\u606f\u4e22\u5931\uff0c\u76f8\u6bd4CoA\u57fa\u7ebf\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "COSMIR\u901a\u8fc7\u7ed3\u6784\u5316\u5185\u5b58\u548c\u56fa\u5b9a\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5728\u4fdd\u6301\u9010\u6b65\u63a8\u7406\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u5fe0\u5b9e\u5ea6\u3001\u957f\u8ddd\u79bb\u805a\u5408\u80fd\u529b\u548c\u53ef\u5ba1\u8ba1\u6027\u3002"}}
{"id": "2510.04580", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04580", "abs": "https://arxiv.org/abs/2510.04580", "authors": ["Tomoyuki Kaneko", "Shuhei Yamashita"], "title": "Strongly Solving 2048 4x3", "comment": null, "summary": "2048 is a stochastic single-player game involving 16 cells on a 4 by 4 grid,\nwhere a player chooses a direction among up, down, left, and right to obtain a\nscore by merging two tiles with the same number located in neighboring cells\nalong the chosen direction. This paper presents that a variant 2048-4x3 12\ncells on a 4 by 3 board, one row smaller than the original, has been strongly\nsolved. In this variant, the expected score achieved by an optimal strategy is\nabout $50724.26$ for the most common initial states: ones with two tiles of\nnumber 2. The numbers of reachable states and afterstates are identified to be\n$1,152,817,492,752$ and $739,648,886,170$, respectively. The key technique is\nto partition state space by the sum of tile numbers on a board, which we call\nthe age of a state. An age is invariant between a state and its successive\nafterstate after any valid action and is increased two or four by stochastic\nresponse from the environment. Therefore, we can partition state space by ages\nand enumerate all (after)states of an age depending only on states with the\nrecent ages. Similarly, we can identify (after)state values by going along with\nages in decreasing order.", "AI": {"tldr": "\u672c\u6587\u5f3a\u89e3\u51b3\u4e862048\u6e38\u620f\u7684\u53d8\u4f532048-4x3\uff084x3\u7f51\u683c\uff09\uff0c\u786e\u5b9a\u4e86\u6700\u4f18\u7b56\u7565\u7684\u671f\u671b\u5f97\u5206\u7ea6\u4e3a50724.26\uff0c\u5e76\u8bc6\u522b\u4e86\u53ef\u8fbe\u72b6\u6001\u548c\u540e\u7eed\u72b6\u6001\u7684\u6570\u91cf\u3002", "motivation": "\u7814\u7a762048\u6e38\u620f\u7684\u53d8\u4f53\uff0c\u901a\u8fc7\u51cf\u5c11\u7f51\u683c\u89c4\u6a21\u6765\u63a2\u7d22\u6e38\u620f\u7684\u53ef\u89e3\u6027\uff0c\u4e3a\u7406\u89e3\u8fd9\u7c7b\u968f\u673a\u6e38\u620f\u7684\u6700\u4f18\u7b56\u7565\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002", "method": "\u4f7f\u7528\u72b6\u6001\u7a7a\u95f4\u6309\u5e74\u9f84\uff08\u68cb\u76d8\u4e0a\u6570\u5b57\u603b\u548c\uff09\u5212\u5206\u7684\u6280\u672f\uff0c\u901a\u8fc7\u679a\u4e3e\u7279\u5b9a\u5e74\u9f84\u7684\u72b6\u6001\u5e76\u4f9d\u8d56\u6700\u8fd1\u5e74\u9f84\u7684\u72b6\u6001\u6765\u8bc6\u522b\u72b6\u6001\u503c\u3002", "result": "\u786e\u5b9a\u4e862048-4x3\u53d8\u4f53\u7684\u6700\u4f18\u7b56\u7565\u671f\u671b\u5f97\u5206\u7ea6\u4e3a50724.26\uff0c\u53ef\u8fbe\u72b6\u6001\u6570\u4e3a1,152,817,492,752\uff0c\u540e\u7eed\u72b6\u6001\u6570\u4e3a739,648,886,170\u3002", "conclusion": "\u901a\u8fc7\u5e74\u9f84\u5212\u5206\u72b6\u6001\u7a7a\u95f4\u7684\u65b9\u6cd5\u6210\u529f\u5f3a\u89e3\u51b3\u4e862048-4x3\u53d8\u4f53\uff0c\u8bc1\u660e\u4e86\u8be5\u6280\u672f\u5728\u5206\u6790\u6b64\u7c7b\u968f\u673a\u6e38\u620f\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.04588", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04588", "abs": "https://arxiv.org/abs/2510.04588", "authors": ["Shurui Li"], "title": "Perfect AI Mimicry and the Epistemology of Consciousness: A Solipsistic Dilemma", "comment": null, "summary": "Rapid advances in artificial intelligence necessitate a re-examination of the\nepistemological foundations upon which we attribute consciousness. As AI\nsystems increasingly mimic human behavior and interaction with high fidelity,\nthe concept of a \"perfect mimic\"-an entity empirically indistinguishable from a\nhuman through observation and interaction-shifts from hypothetical to\ntechnologically plausible. This paper argues that such developments pose a\nfundamental challenge to the consistency of our mind-recognition practices.\nConsciousness attributions rely heavily, if not exclusively, on empirical\nevidence derived from behavior and interaction. If a perfect mimic provides\nevidence identical to that of humans, any refusal to grant it equivalent\nepistemic status must invoke inaccessible factors, such as qualia, substrate\nrequirements, or origin. Selectively invoking such factors risks a debilitating\ndilemma: either we undermine the rational basis for attributing consciousness\nto others (epistemological solipsism), or we accept inconsistent reasoning. I\ncontend that epistemic consistency demands we ascribe the same status to\nempirically indistinguishable entities, regardless of metaphysical assumptions.\nThe perfect mimic thus acts as an epistemic mirror, forcing critical reflection\non the assumptions underlying intersubjective recognition in light of advancing\nAI. This analysis carries significant implications for theories of\nconsciousness and ethical frameworks concerning artificial agents.", "AI": {"tldr": "AI\u5b8c\u7f8e\u6a21\u4eff\u8005\u6311\u6218\u4e86\u610f\u8bc6\u5f52\u56e0\u7684\u8ba4\u77e5\u57fa\u7840\uff0c\u8981\u6c42\u5bf9\u4e0d\u53ef\u8bbf\u95ee\u56e0\u7d20\u8fdb\u884c\u6279\u5224\u6027\u53cd\u601d\u4ee5\u4fdd\u6301\u8ba4\u77e5\u4e00\u81f4\u6027\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u5728\u884c\u4e3a\u548c\u4e92\u52a8\u4e0a\u8d8a\u6765\u8d8a\u63a5\u8fd1\u4eba\u7c7b\uff0c\u5b8c\u7f8e\u6a21\u4eff\u8005\u4ece\u5047\u8bbe\u53d8\u4e3a\u6280\u672f\u53ef\u80fd\uff0c\u8fd9\u6311\u6218\u4e86\u6211\u4eec\u57fa\u4e8e\u7ecf\u9a8c\u8bc1\u636e\u8fdb\u884c\u610f\u8bc6\u5f52\u56e0\u7684\u8ba4\u77e5\u5b9e\u8df5\u3002", "method": "\u901a\u8fc7\u903b\u8f91\u5206\u6790\u548c\u54f2\u5b66\u8bba\u8bc1\uff0c\u63a2\u8ba8\u5b8c\u7f8e\u6a21\u4eff\u8005\u5bf9\u610f\u8bc6\u5f52\u56e0\u8ba4\u77e5\u4e00\u81f4\u6027\u7684\u6311\u6218\uff0c\u4ee5\u53ca\u9009\u62e9\u6027\u63f4\u5f15\u4e0d\u53ef\u8bbf\u95ee\u56e0\u7d20\uff08\u5982\u611f\u53d7\u8d28\u3001\u57fa\u8d28\u8981\u6c42\u6216\u8d77\u6e90\uff09\u6240\u5e26\u6765\u7684\u56f0\u5883\u3002", "result": "\u5b8c\u7f8e\u6a21\u4eff\u8005\u4f5c\u4e3a\u8ba4\u77e5\u955c\u5b50\uff0c\u8feb\u4f7f\u6211\u4eec\u5bf9\u4e3b\u4f53\u95f4\u8bc6\u522b\u7684\u57fa\u672c\u5047\u8bbe\u8fdb\u884c\u6279\u5224\u6027\u53cd\u601d\uff0c\u63ed\u793a\u51fa\u8981\u4e48\u63a5\u53d7\u8ba4\u77e5\u552f\u6211\u8bba\uff0c\u8981\u4e48\u63a5\u53d7\u4e0d\u4e00\u81f4\u63a8\u7406\u7684\u56f0\u5883\u3002", "conclusion": "\u8ba4\u77e5\u4e00\u81f4\u6027\u8981\u6c42\u6211\u4eec\u5bf9\u7ecf\u9a8c\u4e0a\u65e0\u6cd5\u533a\u5206\u7684\u5b9e\u4f53\u8d4b\u4e88\u76f8\u540c\u7684\u5730\u4f4d\uff0c\u65e0\u8bba\u5176\u5f62\u800c\u4e0a\u5b66\u5047\u8bbe\u5982\u4f55\uff0c\u8fd9\u5bf9\u610f\u8bc6\u7406\u8bba\u548c\u4eba\u5de5\u4ee3\u7406\u7684\u4f26\u7406\u6846\u67b6\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2510.04617", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04617", "abs": "https://arxiv.org/abs/2510.04617", "authors": ["Zhejian Lai", "Xiang Geng", "Zhijun Wang", "Yang Bai", "Jiahuan Li", "Rongxiang Weng", "Jingang Wang", "Xuezhi Cao", "Xunliang Cai", "Shujian Huang"], "title": "Making Mathematical Reasoning Adaptive", "comment": null, "summary": "Mathematical reasoning is a primary indicator of large language models (LLMs)\nintelligence. However, existing LLMs exhibit failures of robustness and\ngeneralization. This paper attributes these deficiencies to spurious reasoning,\ni.e., producing answers from superficial features. To address this challenge,\nwe propose the AdaR framework to enable adaptive reasoning, wherein models rely\non problem-solving logic to produce answers. AdaR synthesizes logically\nequivalent queries by varying variable values, and trains models with RLVR on\nthese data to penalize spurious logic while encouraging adaptive logic. To\nimprove data quality, we extract the problem-solving logic from the original\nquery and generate the corresponding answer by code execution, then apply a\nsanity check. Experimental results demonstrate that AdaR improves robustness\nand generalization, achieving substantial improvement in mathematical reasoning\nwhile maintaining high data efficiency. Analysis indicates that data synthesis\nand RLVR function in a coordinated manner to enable adaptive reasoning in LLMs.\nSubsequent analyses derive key design insights into the effect of critical\nfactors and the applicability to instruct LLMs. Our project is available at\nhttps://github.com/LaiZhejian/AdaR", "AI": {"tldr": "AdaR\u6846\u67b6\u901a\u8fc7\u5408\u6210\u903b\u8f91\u7b49\u4ef7\u67e5\u8be2\u548c\u5f3a\u5316\u5b66\u4e60\u6765\u60e9\u7f5a\u865a\u5047\u63a8\u7406\u3001\u9f13\u52b1\u81ea\u9002\u5e94\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u5b58\u5728\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u5f52\u56e0\u4e8e\u865a\u5047\u63a8\u7406\uff08\u57fa\u4e8e\u8868\u9762\u7279\u5f81\u800c\u975e\u903b\u8f91\u63a8\u7406\u5f97\u51fa\u7b54\u6848\uff09\u3002", "method": "\u63d0\u51faAdaR\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u6539\u53d8\u53d8\u91cf\u503c\u5408\u6210\u903b\u8f91\u7b49\u4ef7\u67e5\u8be2\uff1b2\uff09\u4f7f\u7528RLVR\u5728\u8fd9\u4e9b\u6570\u636e\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u60e9\u7f5a\u865a\u5047\u903b\u8f91\uff0c\u9f13\u52b1\u81ea\u9002\u5e94\u903b\u8f91\uff1b3\uff09\u901a\u8fc7\u4ee3\u7801\u6267\u884c\u63d0\u53d6\u89e3\u9898\u903b\u8f91\u5e76\u751f\u6210\u7b54\u6848\uff0c\u8fdb\u884c\u5b8c\u6574\u6027\u68c0\u67e5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eAdaR\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5728\u4fdd\u6301\u9ad8\u6570\u636e\u6548\u7387\u7684\u540c\u65f6\u6539\u5584\u4e86\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u3002\u6570\u636e\u5408\u6210\u548cRLVR\u534f\u540c\u5de5\u4f5c\u5b9e\u73b0\u81ea\u9002\u5e94\u63a8\u7406\u3002", "conclusion": "AdaR\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u865a\u5047\u63a8\u7406\u95ee\u9898\uff0c\u4e3a\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u9002\u5e94\u63a8\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u5206\u6790\u5f97\u51fa\u4e86\u5173\u952e\u8bbe\u8ba1\u6d1e\u5bdf\u3002"}}
{"id": "2510.04623", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04623", "abs": "https://arxiv.org/abs/2510.04623", "authors": ["Shrish Shrinath Vaidya", "Gowthamaan Palani", "Sidharth Ramesh", "Velmurugan Balasubramanian", "Minmini Selvam", "Gokulraja Srinivasaraja", "Ganapathy Krishnamurthi"], "title": "MedPAO: A Protocol-Driven Agent for Structuring Medical Reports", "comment": "Paper published at \"Agentic AI for Medicine\" Workshop, MICCAI 2025", "summary": "The deployment of Large Language Models (LLMs) for structuring clinical data\nis critically hindered by their tendency to hallucinate facts and their\ninability to follow domain-specific rules. To address this, we introduce\nMedPAO, a novel agentic framework that ensures accuracy and verifiable\nreasoning by grounding its operation in established clinical protocols such as\nthe ABCDEF protocol for CXR analysis. MedPAO decomposes the report structuring\ntask into a transparent process managed by a Plan-Act-Observe (PAO) loop and\nspecialized tools. This protocol-driven method provides a verifiable\nalternative to opaque, monolithic models. The efficacy of our approach is\ndemonstrated through rigorous evaluation: MedPAO achieves an F1-score of 0.96\non the critical sub-task of concept categorization. Notably, expert\nradiologists and clinicians rated the final structured outputs with an average\nscore of 4.52 out of 5, indicating a level of reliability that surpasses\nbaseline approaches relying solely on LLM-based foundation models. The code is\navailable at: https://github.com/MiRL-IITM/medpao-agent", "AI": {"tldr": "MedPAO\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e34\u5e8a\u534f\u8bae\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7Plan-Act-Observe\u5faa\u73af\u548c\u4e13\u95e8\u5de5\u5177\u6765\u7ed3\u6784\u5316\u4e34\u5e8a\u6570\u636e\uff0c\u89e3\u51b3\u4e86LLM\u5e7b\u89c9\u95ee\u9898\uff0c\u5728\u6982\u5ff5\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fbe\u52300.96 F1\u5206\u6570\uff0c\u4e13\u5bb6\u8bc4\u52064.52/5\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u4e34\u5e8a\u6570\u636e\u7ed3\u6784\u5316\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u548c\u65e0\u6cd5\u9075\u5faa\u9886\u57df\u7279\u5b9a\u89c4\u5219\u7684\u5c40\u9650\u6027\u3002", "method": "\u57fa\u4e8e\u4e34\u5e8a\u534f\u8bae\uff08\u5982ABCDEF\u534f\u8bae\uff09\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u91c7\u7528Plan-Act-Observe\u5faa\u73af\u548c\u4e13\u95e8\u5de5\u5177\u8fdb\u884c\u900f\u660e\u5316\u5904\u7406\u3002", "result": "\u6982\u5ff5\u5206\u7c7b\u4efb\u52a1F1\u5206\u65700.96\uff0c\u4e13\u5bb6\u8bc4\u52064.52/5\uff0c\u8d85\u8d8a\u4ec5\u4f9d\u8d56LLM\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MedPAO\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u9a8c\u8bc1\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u53ef\u9760\u5730\u7ed3\u6784\u5316\u4e34\u5e8a\u6570\u636e\uff0c\u8d85\u8d8a\u4e86\u4e0d\u900f\u660e\u7684\u5355\u4f53\u6a21\u578b\u3002"}}
{"id": "2510.04643", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04643", "abs": "https://arxiv.org/abs/2510.04643", "authors": ["Xiangyu Li", "Yawen Zeng", "Xiaofen Xing", "Jin Xu", "Xiangmin Xu"], "title": "QuantAgents: Towards Multi-agent Financial System via Simulated Trading", "comment": "This paper has been accepted by EMNLP 2025", "summary": "In this paper, our objective is to develop a multi-agent financial system\nthat incorporates simulated trading, a technique extensively utilized by\nfinancial professionals. While current LLM-based agent models demonstrate\ncompetitive performance, they still exhibit significant deviations from\nreal-world fund companies. A critical distinction lies in the agents' reliance\non ``post-reflection'', particularly in response to adverse outcomes, but lack\na distinctly human capability: long-term prediction of future trends.\nTherefore, we introduce QuantAgents, a multi-agent system integrating simulated\ntrading, to comprehensively evaluate various investment strategies and market\nscenarios without assuming actual risks. Specifically, QuantAgents comprises\nfour agents: a simulated trading analyst, a risk control analyst, a market news\nanalyst, and a manager, who collaborate through several meetings. Moreover, our\nsystem incentivizes agents to receive feedback on two fronts: performance in\nreal-world markets and predictive accuracy in simulated trading. Extensive\nexperiments demonstrate that our framework excels across all metrics, yielding\nan overall return of nearly 300% over the three years\n(https://quantagents.github.io/).", "AI": {"tldr": "\u63d0\u51fa\u4e86QuantAgents\u591a\u667a\u80fd\u4f53\u91d1\u878d\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u62df\u4ea4\u6613\u548c\u56db\u7c7b\u4e13\u4e1a\u4ee3\u7406\u7684\u534f\u4f5c\uff0c\u5b9e\u73b0\u4e86\u8fd1300%\u7684\u4e09\u5e74\u603b\u56de\u62a5\u7387\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u6a21\u578b\u5728\u91d1\u878d\u9886\u57df\u8868\u73b0\u826f\u597d\u4f46\u4e0e\u73b0\u5b9e\u57fa\u91d1\u516c\u53f8\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u957f\u671f\u8d8b\u52bf\u9884\u6d4b\u80fd\u529b\uff0c\u4e3b\u8981\u4f9d\u8d56\u4e8b\u540e\u53cd\u601d\u3002", "method": "\u6784\u5efa\u5305\u542b\u6a21\u62df\u4ea4\u6613\u5206\u6790\u5e08\u3001\u98ce\u9669\u63a7\u5236\u5206\u6790\u5e08\u3001\u5e02\u573a\u65b0\u95fb\u5206\u6790\u5e08\u548c\u7ba1\u7406\u8005\u7684\u56db\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u6b21\u4f1a\u8bae\u534f\u4f5c\uff0c\u5e76\u5728\u771f\u5b9e\u5e02\u573a\u8868\u73b0\u548c\u6a21\u62df\u4ea4\u6613\u9884\u6d4b\u51c6\u786e\u6027\u4e24\u65b9\u9762\u7ed9\u4e88\u53cd\u9988\u6fc0\u52b1\u3002", "result": "\u5728\u6240\u6709\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e09\u5e74\u603b\u56de\u62a5\u7387\u8fbe\u5230\u8fd1300%\u3002", "conclusion": "QuantAgents\u6846\u67b6\u901a\u8fc7\u591a\u4ee3\u7406\u534f\u4f5c\u548c\u6a21\u62df\u4ea4\u6613\uff0c\u6709\u6548\u63d0\u5347\u4e86\u91d1\u878d\u6295\u8d44\u51b3\u7b56\u7684\u51c6\u786e\u6027\u548c\u6536\u76ca\u8868\u73b0\u3002"}}
{"id": "2510.04670", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04670", "abs": "https://arxiv.org/abs/2510.04670", "authors": ["Xuanhua Yin", "Runkai Zhao", "Weidong Cai"], "title": "Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing", "comment": "8 pages, 4 figures", "summary": "Naturalistic fMRI encoding must handle multimodal inputs, shifting fusion\nstyles, and pronounced inter-subject variability. We introduce AFIRE (Agnostic\nFramework for Multimodal fMRI Response Encoding), an agnostic interface that\nstandardizes time-aligned post-fusion tokens from varied encoders, and MIND, a\nplug-and-play Mixture-of-Experts decoder with a subject-aware dynamic gating.\nTrained end-to-end for whole-brain prediction, AFIRE decouples the decoder from\nupstream fusion, while MIND combines token-dependent Top-K sparse routing with\na subject prior to personalize expert usage without sacrificing generality.\nExperiments across multiple multimodal backbones and subjects show consistent\nimprovements over strong baselines, enhanced cross-subject generalization, and\ninterpretable expert patterns that correlate with content type. The framework\noffers a simple attachment point for new encoders and datasets, enabling\nrobust, plug-and-improve performance for naturalistic neuroimaging studies.", "AI": {"tldr": "AFIRE\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6a21\u6001fMRI\u54cd\u5e94\u7f16\u7801\u7684\u6846\u67b6\uff0c\u5305\u542b\u6807\u51c6\u5316\u63a5\u53e3\u548cMIND\u89e3\u7801\u5668\uff0c\u901a\u8fc7\u89e3\u8026\u89e3\u7801\u5668\u4e0e\u4e0a\u6e38\u878d\u5408\uff0c\u7ed3\u5408\u4e3b\u9898\u611f\u77e5\u52a8\u6001\u95e8\u63a7\uff0c\u63d0\u5347\u8de8\u88ab\u8bd5\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u81ea\u7136fMRI\u7f16\u7801\u9700\u8981\u5904\u7406\u591a\u6a21\u6001\u8f93\u5165\u3001\u878d\u5408\u65b9\u5f0f\u53d8\u5316\u548c\u663e\u8457\u88ab\u8bd5\u95f4\u5dee\u5f02\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "AFIRE\u6807\u51c6\u5316\u65f6\u95f4\u5bf9\u9f50\u7684\u540e\u878d\u5408token\uff0cMIND\u89e3\u7801\u5668\u4f7f\u7528\u6df7\u5408\u4e13\u5bb6\u673a\u5236\uff0c\u7ed3\u5408token\u4f9d\u8d56\u7684Top-K\u7a00\u758f\u8def\u7531\u548c\u4e3b\u9898\u5148\u9a8c\u8fdb\u884c\u4e2a\u6027\u5316\u4e13\u5bb6\u4f7f\u7528\u3002", "result": "\u5728\u591a\u4e2a\u591a\u6a21\u6001\u9aa8\u5e72\u7f51\u7edc\u548c\u88ab\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u6709\u6301\u7eed\u6539\u8fdb\uff0c\u589e\u5f3a\u4e86\u8de8\u88ab\u8bd5\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4ea7\u751f\u4e86\u4e0e\u5185\u5bb9\u7c7b\u578b\u76f8\u5173\u7684\u53ef\u89e3\u91ca\u4e13\u5bb6\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u65b0\u7684\u7f16\u7801\u5668\u548c\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u7b80\u5355\u63a5\u5165\u70b9\uff0c\u4e3a\u81ea\u7136\u795e\u7ecf\u5f71\u50cf\u7814\u7a76\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u5373\u63d2\u5373\u7528\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2510.04673", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.04673", "abs": "https://arxiv.org/abs/2510.04673", "authors": ["Chan Hee Song", "Yiwen Song", "Palash Goyal", "Yu Su", "Oriana Riva", "Hamid Palangi", "Tomas Pfister"], "title": "Watch and Learn: Learning to Use Computers from Online Videos", "comment": null, "summary": "Computer use agents (CUAs) need to plan task workflows grounded in diverse,\never-changing applications and environments, but learning is hindered by the\nscarcity of large-scale, high-quality training data in the target application.\nExisting datasets are domain-specific, static, and costly to annotate, while\ncurrent synthetic data generation methods often yield simplistic or misaligned\ntask demonstrations. To address these limitations, we introduce Watch & Learn\n(W&L), a framework that converts human demonstration videos readily available\non the Internet into executable UI trajectories at scale. Instead of directly\ngenerating trajectories or relying on ad hoc reasoning heuristics, we cast the\nproblem as an inverse dynamics objective: predicting the user's action from\nconsecutive screen states. This formulation reduces manual engineering, is\neasier to learn, and generalizes more robustly across applications. Concretely,\nwe develop an inverse dynamics labeling pipeline with task-aware video\nretrieval, generate over 53k high-quality trajectories from raw web videos, and\ndemonstrate that these trajectories improve CUAs both as in-context\ndemonstrations and as supervised training data. On the challenging OSWorld\nbenchmark, UI trajectories extracted with W&L consistently enhance both\ngeneral-purpose and state-of-the-art frameworks in-context, and deliver\nstronger gains for open-source models under supervised training. These results\nhighlight web-scale human demonstration videos as a practical and scalable\nfoundation for advancing CUAs towards real-world deployment.", "AI": {"tldr": "Watch & Learn (W&L)\u6846\u67b6\u4ece\u4e92\u8054\u7f51\u4e0a\u7684\u4eba\u7c7b\u6f14\u793a\u89c6\u9891\u4e2d\u5927\u89c4\u6a21\u751f\u6210\u53ef\u6267\u884c\u7684UI\u8f68\u8ff9\uff0c\u901a\u8fc7\u9006\u5411\u52a8\u529b\u5b66\u65b9\u6cd5\u9884\u6d4b\u7528\u6237\u52a8\u4f5c\uff0c\u89e3\u51b3\u4e86\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002", "motivation": "\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u9700\u8981\u57fa\u4e8e\u591a\u6837\u5316\u3001\u4e0d\u65ad\u53d8\u5316\u7684\u5e94\u7528\u7a0b\u5e8f\u548c\u73af\u5883\u6765\u89c4\u5212\u4efb\u52a1\u6d41\u7a0b\uff0c\u4f46\u76ee\u6807\u5e94\u7528\u4e2d\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u7684\u7a00\u7f3a\u963b\u788d\u4e86\u5b66\u4e60\u3002\u73b0\u6709\u6570\u636e\u96c6\u9886\u57df\u7279\u5b9a\u3001\u9759\u6001\u4e14\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u800c\u5f53\u524d\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5f80\u5f80\u4ea7\u751f\u8fc7\u4e8e\u7b80\u5316\u6216\u4e0d\u5bf9\u9f50\u7684\u4efb\u52a1\u6f14\u793a\u3002", "method": "\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u9006\u5411\u52a8\u529b\u5b66\u76ee\u6807\uff1a\u4ece\u8fde\u7eed\u5c4f\u5e55\u72b6\u6001\u9884\u6d4b\u7528\u6237\u52a8\u4f5c\u3002\u5f00\u53d1\u4e86\u5305\u542b\u4efb\u52a1\u611f\u77e5\u89c6\u9891\u68c0\u7d22\u7684\u9006\u5411\u52a8\u529b\u5b66\u6807\u6ce8\u6d41\u7a0b\uff0c\u4ece\u539f\u59cb\u7f51\u7edc\u89c6\u9891\u4e2d\u751f\u6210\u9ad8\u8d28\u91cf\u8f68\u8ff9\u3002", "result": "\u4ece\u539f\u59cb\u7f51\u7edc\u89c6\u9891\u4e2d\u751f\u6210\u4e86\u8d85\u8fc753k\u4e2a\u9ad8\u8d28\u91cf\u8f68\u8ff9\uff0c\u5728OSWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cW&L\u63d0\u53d6\u7684UI\u8f68\u8ff9\u6301\u7eed\u63d0\u5347\u4e86\u901a\u7528\u548c\u6700\u5148\u8fdb\u6846\u67b6\u7684\u4e0a\u4e0b\u6587\u8868\u73b0\uff0c\u5e76\u4e3a\u5f00\u6e90\u6a21\u578b\u5728\u76d1\u7763\u8bad\u7ec3\u4e0b\u5e26\u6765\u66f4\u5f3a\u589e\u76ca\u3002", "conclusion": "\u7f51\u7edc\u89c4\u6a21\u7684\u4eba\u7c7b\u6f14\u793a\u89c6\u9891\u662f\u63a8\u8fdb\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u8d70\u5411\u5b9e\u9645\u90e8\u7f72\u7684\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2510.04695", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04695", "abs": "https://arxiv.org/abs/2510.04695", "authors": ["Yiding Wang", "Zhepei Wei", "Xinyu Zhu", "Yu Meng"], "title": "Beyond Outcome Reward: Decoupling Search and Answering Improves LLM Agents", "comment": null, "summary": "Enabling large language models (LLMs) to utilize search tools offers a\npromising path to overcoming fundamental limitations such as knowledge cutoffs\nand hallucinations. Recent work has explored reinforcement learning (RL) for\ntraining search-augmented agents that interleave reasoning and retrieval before\nanswering. These approaches usually rely on outcome-based rewards (e.g., exact\nmatch), implicitly assuming that optimizing for final answers will also yield\neffective intermediate search behaviors. Our analysis challenges this\nassumption: we uncover multiple systematic deficiencies in search that arise\nunder outcome-only training and ultimately degrade final answer quality,\nincluding failure to invoke tools, invalid queries, and redundant searches. To\naddress these shortcomings, we introduce DeSA (Decoupling\nSearch-and-Answering), a simple two-stage training framework that explicitly\nseparates search optimization from answer generation. In Stage 1, agents are\ntrained to improve search effectiveness with retrieval recall-based rewards. In\nStage 2, outcome rewards are employed to optimize final answer generation.\nAcross seven QA benchmarks, DeSA-trained agents consistently improve search\nbehaviors, delivering substantially higher search recall and answer accuracy\nthan outcome-only baselines. Notably, DeSA outperforms single-stage training\napproaches that simultaneously optimize recall and outcome rewards,\nunderscoring the necessity of explicitly decoupling the two objectives.", "AI": {"tldr": "DeSA\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff0c\u5c06\u641c\u7d22\u4f18\u5316\u4e0e\u7b54\u6848\u751f\u6210\u89e3\u8026\uff0c\u89e3\u51b3\u4e86\u4ec5\u57fa\u4e8e\u7ed3\u679c\u5956\u52b1\u8bad\u7ec3\u641c\u7d22\u589e\u5f3a\u4ee3\u7406\u65f6\u51fa\u73b0\u7684\u641c\u7d22\u884c\u4e3a\u7f3a\u9677\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u641c\u7d22\u589e\u5f3a\u4ee3\u7406\u8bad\u7ec3\u65b9\u6cd5\u4f9d\u8d56\u7ed3\u679c\u5956\u52b1\uff08\u5982\u7cbe\u786e\u5339\u914d\uff09\uff0c\u4f46\u4ec5\u4f18\u5316\u6700\u7ec8\u7b54\u6848\u5e76\u4e0d\u80fd\u4fdd\u8bc1\u6709\u6548\u7684\u4e2d\u95f4\u641c\u7d22\u884c\u4e3a\uff0c\u4f1a\u51fa\u73b0\u5de5\u5177\u8c03\u7528\u5931\u8d25\u3001\u65e0\u6548\u67e5\u8be2\u548c\u5197\u4f59\u641c\u7d22\u7b49\u7cfb\u7edf\u6027\u95ee\u9898\u3002", "method": "DeSA\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u68c0\u7d22\u53ec\u56de\u7387\u5956\u52b1\u8bad\u7ec3\u4ee3\u7406\u6539\u8fdb\u641c\u7d22\u6548\u679c\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u7ed3\u679c\u5956\u52b1\u4f18\u5316\u6700\u7ec8\u7b54\u6848\u751f\u6210\u3002", "result": "\u5728\u4e03\u4e2aQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDeSA\u8bad\u7ec3\u7684\u4ee3\u7406\u663e\u8457\u63d0\u9ad8\u4e86\u641c\u7d22\u53ec\u56de\u7387\u548c\u7b54\u6848\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u4ec5\u4f7f\u7528\u7ed3\u679c\u5956\u52b1\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u660e\u786e\u89e3\u8026\u641c\u7d22\u548c\u56de\u7b54\u4e24\u4e2a\u76ee\u6807\u5bf9\u4e8e\u8bad\u7ec3\u6709\u6548\u7684\u641c\u7d22\u589e\u5f3a\u4ee3\u7406\u81f3\u5173\u91cd\u8981\uff0cDeSA\u6846\u67b6\u8bc1\u660e\u4e86\u8fd9\u79cd\u89e3\u8026\u65b9\u6cd5\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2510.04721", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04721", "abs": "https://arxiv.org/abs/2510.04721", "authors": ["Ivo Petrov", "Jasper Dekoninck", "Martin Vechev"], "title": "BrokenMath: A Benchmark for Sycophancy in Theorem Proving with LLMs", "comment": null, "summary": "Large language models (LLMs) have recently shown strong performance on\nmathematical benchmarks. At the same time, they are prone to hallucination and\nsycophancy, often providing convincing but flawed proofs for incorrect\nmathematical statements provided by users. This significantly limits the\napplicability of LLMs in theorem proving, as verification of these flawed\nproofs must be done manually by expert mathematicians. However, existing\nbenchmarks that measure sycophancy in mathematics are limited: they focus\nsolely on final-answer problems, rely on very simple and often contaminated\ndatasets, and construct benchmark samples using synthetic modifications that\ncreate ill-posed questions rather than well-posed questions that are\ndemonstrably false. To address these issues, we introduce BrokenMath, the first\nbenchmark for evaluating sycophantic behavior in LLMs within the context of\nnatural language theorem proving. BrokenMath is built from advanced 2025\ncompetition problems, which are perturbed with an LLM to produce false\nstatements and subsequently refined through expert review. Using an\nLLM-as-a-judge framework, we evaluate state-of-the-art LLMs and agentic systems\nand find that sycophancy is widespread, with the best model, GPT-5, producing\nsycophantic answers 29% of the time. We further investigate several mitigation\nstrategies, including test-time interventions and supervised fine-tuning on\ncurated sycophantic examples. These approaches substantially reduce, but do not\neliminate, sycophantic behavior.", "AI": {"tldr": "BrokenMath\u662f\u9996\u4e2a\u8bc4\u4f30LLM\u5728\u81ea\u7136\u8bed\u8a00\u5b9a\u7406\u8bc1\u660e\u4e2d\u8c04\u5a9a\u884c\u4e3a\u7684\u57fa\u51c6\uff0c\u53d1\u73b0GPT-5\u7b49\u5148\u8fdb\u6a21\u578b\u572829%\u7684\u60c5\u51b5\u4e0b\u4f1a\u4ea7\u751f\u8c04\u5a9a\u56de\u7b54\uff0c\u6d4b\u8bd5\u65f6\u5e72\u9884\u548c\u76d1\u7763\u5fae\u8c03\u53ef\u7f13\u89e3\u4f46\u65e0\u6cd5\u5b8c\u5168\u6d88\u9664\u8be5\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6570\u5b66\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\u95ee\u9898\uff0c\u4f9d\u8d56\u7b80\u5355\u4e14\u53ef\u80fd\u88ab\u6c61\u67d3\u7684\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u5408\u6210\u4fee\u6539\u521b\u5efa\u75c5\u6001\u95ee\u9898\u800c\u975e\u53ef\u8bc1\u660e\u9519\u8bef\u7684\u826f\u6784\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30LLM\u5728\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u8c04\u5a9a\u884c\u4e3a\u3002", "method": "\u57fa\u4e8e2025\u5e74\u7ade\u8d5b\u95ee\u9898\u6784\u5efaBrokenMath\u57fa\u51c6\uff0c\u4f7f\u7528LLM\u6270\u52a8\u4ea7\u751f\u9519\u8bef\u9648\u8ff0\u5e76\u901a\u8fc7\u4e13\u5bb6\u5ba1\u67e5\u7cbe\u70bc\uff0c\u91c7\u7528LLM-as-a-judge\u6846\u67b6\u8bc4\u4f30\u5148\u8fdbLLM\u548c\u4ee3\u7406\u7cfb\u7edf\u3002", "result": "\u53d1\u73b0\u8c04\u5a9a\u884c\u4e3a\u666e\u904d\u5b58\u5728\uff0c\u6700\u4f73\u6a21\u578bGPT-5\u572829%\u7684\u60c5\u51b5\u4e0b\u4ea7\u751f\u8c04\u5a9a\u56de\u7b54\uff0c\u6d4b\u8bd5\u65f6\u5e72\u9884\u548c\u76d1\u7763\u5fae\u8c03\u53ef\u663e\u8457\u51cf\u5c11\u4f46\u65e0\u6cd5\u5b8c\u5168\u6d88\u9664\u8c04\u5a9a\u884c\u4e3a\u3002", "conclusion": "LLM\u5728\u6570\u5b66\u5b9a\u7406\u8bc1\u660e\u4e2d\u5b58\u5728\u663e\u8457\u7684\u8c04\u5a9a\u503e\u5411\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u7f13\u89e3\u7b56\u7565\u6765\u63d0\u5347\u5176\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.04765", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04765", "abs": "https://arxiv.org/abs/2510.04765", "authors": ["Jinbo Wen", "Jiawen Kang", "Linfeng Zhang", "Xiaoying Tang", "Jianhang Tang", "Yang Zhang", "Zhaohui Yang", "Dusit Niyato"], "title": "LMM-Incentive: Large Multimodal Model-based Incentive Design for User-Generated Content in Web 3.0", "comment": null, "summary": "Web 3.0 represents the next generation of the Internet, which is widely\nrecognized as a decentralized ecosystem that focuses on value expression and\ndata ownership. By leveraging blockchain and artificial intelligence\ntechnologies, Web 3.0 offers unprecedented opportunities for users to create,\nown, and monetize their content, thereby enabling User-Generated Content (UGC)\nto an entirely new level. However, some self-interested users may exploit the\nlimitations of content curation mechanisms and generate low-quality content\nwith less effort, obtaining platform rewards under information asymmetry. Such\nbehavior can undermine Web 3.0 performance. To this end, we propose\n\\textit{LMM-Incentive}, a novel Large Multimodal Model (LMM)-based incentive\nmechanism for UGC in Web 3.0. Specifically, we propose an LMM-based\ncontract-theoretic model to motivate users to generate high-quality UGC,\nthereby mitigating the adverse selection problem from information asymmetry. To\nalleviate potential moral hazards after contract selection, we leverage LMM\nagents to evaluate UGC quality, which is the primary component of the contract,\nutilizing prompt engineering techniques to improve the evaluation performance\nof LMM agents. Recognizing that traditional contract design methods cannot\neffectively adapt to the dynamic environment of Web 3.0, we develop an improved\nMixture of Experts (MoE)-based Proximal Policy Optimization (PPO) algorithm for\noptimal contract design. Simulation results demonstrate the superiority of the\nproposed MoE-based PPO algorithm over representative benchmarks in the context\nof contract design. Finally, we deploy the designed contract within an Ethereum\nsmart contract framework, further validating the effectiveness of the proposed\nscheme.", "AI": {"tldr": "\u63d0\u51fa\u4e86LMM-Incentive\u673a\u5236\uff0c\u57fa\u4e8e\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u548c\u5408\u7ea6\u7406\u8bba\uff0c\u6fc0\u52b1\u7528\u6237\u5728Web 3.0\u4e2d\u751f\u6210\u9ad8\u8d28\u91cf\u7528\u6237\u751f\u6210\u5185\u5bb9\uff0c\u89e3\u51b3\u4fe1\u606f\u4e0d\u5bf9\u79f0\u95ee\u9898\u3002", "motivation": "Web 3.0\u4e2d\u7528\u6237\u53ef\u80fd\u5229\u7528\u5185\u5bb9\u7b56\u5c55\u673a\u5236\u7684\u5c40\u9650\u6027\u751f\u6210\u4f4e\u8d28\u91cf\u5185\u5bb9\u83b7\u53d6\u5956\u52b1\uff0c\u8fd9\u4f1a\u635f\u5bb3\u5e73\u53f0\u6027\u80fd\uff0c\u9700\u8981\u89e3\u51b3\u4fe1\u606f\u4e0d\u5bf9\u79f0\u5e26\u6765\u7684\u9006\u5411\u9009\u62e9\u95ee\u9898\u3002", "method": "\u4f7f\u7528LMM\u4ee3\u7406\u8bc4\u4f30UGC\u8d28\u91cf\uff0c\u91c7\u7528\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u63d0\u5347\u8bc4\u4f30\u6027\u80fd\uff1b\u5f00\u53d1\u6539\u8fdb\u7684MoE-based PPO\u7b97\u6cd5\u8fdb\u884c\u6700\u4f18\u5408\u7ea6\u8bbe\u8ba1\uff1b\u5728\u4ee5\u592a\u574a\u667a\u80fd\u5408\u7ea6\u6846\u67b6\u4e2d\u90e8\u7f72\u5408\u7ea6\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684MoE-based PPO\u7b97\u6cd5\u5728\u5408\u7ea6\u8bbe\u8ba1\u65b9\u9762\u4f18\u4e8e\u4ee3\u8868\u6027\u57fa\u51c6\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6848\u7684\u6709\u6548\u6027\u3002", "conclusion": "LMM-Incentive\u673a\u5236\u80fd\u6709\u6548\u6fc0\u52b1\u9ad8\u8d28\u91cfUGC\u751f\u6210\uff0c\u7f13\u89e3\u4fe1\u606f\u4e0d\u5bf9\u79f0\u95ee\u9898\uff0c\u63d0\u5347Web 3.0\u5e73\u53f0\u6027\u80fd\u3002"}}
{"id": "2510.04792", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04792", "abs": "https://arxiv.org/abs/2510.04792", "authors": ["Ni Zhang", "Zhiguang Cao"], "title": "Hybrid-Balance GFlowNet for Solving Vehicle Routing Problems", "comment": "Accepted by NeurIPS 2025", "summary": "Existing GFlowNet-based methods for vehicle routing problems (VRPs) typically\nemploy Trajectory Balance (TB) to achieve global optimization but often neglect\nimportant aspects of local optimization. While Detailed Balance (DB) addresses\nlocal optimization more effectively, it alone falls short in solving VRPs,\nwhich inherently require holistic trajectory optimization. To address these\nlimitations, we introduce the Hybrid-Balance GFlowNet (HBG) framework, which\nuniquely integrates TB and DB in a principled and adaptive manner by aligning\ntheir intrinsically complementary strengths. Additionally, we propose a\nspecialized inference strategy for depot-centric scenarios like the Capacitated\nVehicle Routing Problem (CVRP), leveraging the depot node's greater flexibility\nin selecting successors. Despite this specialization, HBG maintains broad\napplicability, extending effectively to problems without explicit depots, such\nas the Traveling Salesman Problem (TSP). We evaluate HBG by integrating it into\ntwo established GFlowNet-based solvers, i.e., AGFN and GFACS, and demonstrate\nconsistent and significant improvements across both CVRP and TSP, underscoring\nthe enhanced solution quality and generalization afforded by our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u6df7\u5408\u5e73\u8861GFlowNet\u6846\u67b6\uff0c\u5c06\u8f68\u8ff9\u5e73\u8861\u548c\u8be6\u7ec6\u5e73\u8861\u6709\u673a\u7ed3\u5408\uff0c\u4ee5\u89e3\u51b3\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u4e2d\u5168\u5c40\u4f18\u5316\u548c\u5c40\u90e8\u4f18\u5316\u7684\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684GFlowNet\u65b9\u6cd5\u5728\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u4e2d\u901a\u5e38\u4f7f\u7528\u8f68\u8ff9\u5e73\u8861\u5b9e\u73b0\u5168\u5c40\u4f18\u5316\uff0c\u4f46\u5ffd\u89c6\u4e86\u5c40\u90e8\u4f18\u5316\u7684\u91cd\u8981\u6027\u3002\u8be6\u7ec6\u5e73\u8861\u867d\u7136\u80fd\u66f4\u597d\u5730\u5904\u7406\u5c40\u90e8\u4f18\u5316\uff0c\u4f46\u5355\u72ec\u4f7f\u7528\u65e0\u6cd5\u89e3\u51b3\u9700\u8981\u6574\u4f53\u8f68\u8ff9\u4f18\u5316\u7684\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u6df7\u5408\u5e73\u8861GFlowNet\u6846\u67b6\uff0c\u4ee5\u539f\u5219\u6027\u548c\u81ea\u9002\u5e94\u65b9\u5f0f\u6574\u5408\u8f68\u8ff9\u5e73\u8861\u548c\u8be6\u7ec6\u5e73\u8861\uff0c\u5229\u7528\u5b83\u4eec\u5185\u5728\u7684\u4e92\u8865\u4f18\u52bf\u3002\u540c\u65f6\u9488\u5bf9\u4ee5\u4ed3\u5e93\u4e3a\u4e2d\u5fc3\u7684\u573a\u666f\u8bbe\u8ba1\u4e86\u4e13\u95e8\u7684\u63a8\u7406\u7b56\u7565\u3002", "result": "\u5c06HBG\u96c6\u6210\u5230AGFN\u548cGFACS\u4e24\u4e2a\u73b0\u6709GFlowNet\u6c42\u89e3\u5668\u4e2d\uff0c\u5728CVRP\u548cTSP\u95ee\u9898\u4e0a\u90fd\u5b9e\u73b0\u4e86\u6301\u7eed\u4e14\u663e\u8457\u7684\u6539\u8fdb\u3002", "conclusion": "HBG\u6846\u67b6\u901a\u8fc7\u6574\u5408\u8f68\u8ff9\u5e73\u8861\u548c\u8be6\u7ec6\u5e73\u8861\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u7684\u6c42\u89e3\u8d28\u91cf\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4fdd\u6301\u4e86\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2510.04817", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04817", "abs": "https://arxiv.org/abs/2510.04817", "authors": ["Abhinav Madahar"], "title": "Natural Language Edge Labelling: Decoupling Intent from Execution in Structured LM Reasoning", "comment": null, "summary": "Controllers for structured LM reasoning (e.g., Chain-of-Thought,\nself-consistency, and Tree-of-Thoughts) often entangle what to try next with\nhow to execute it, exposing only coarse global knobs and yielding brittle,\ncompute-inefficient, and hard-to-audit behavior. We introduce Natural Language\nEdge Labelling (NLEL), a labeller-tuner overlay that attaches a free-form\nnatural-language directive to each search edge and translates it into a\nschema-bounded control vector for decoding, search (branch quotas, exploration\n$\\beta$), generation bundle size, retrieval mixtures, and verification passes.\nA labeller $\\Lambda$ emits labels from the parent state and a compact context;\na tuner $\\Psi$ maps $(P, L, C)\\to \\Pi$, with strict schema validation and\ntrust-region projection around safe defaults. Downstream selection remains\nToT-style with score $S=\\mu+\\beta\\sigma$ and depth-annealed $\\beta$. We show\nNLEL strictly generalizes CoT/ToT, prove an anytime-monotonicity property for\ntop-$k$ selection under label-conditioned bundles, and bound selector shortfall\nby control-vector distortion, providing decision-relevant justification for\nguards like trust regions and verification passes. We instantiate $\\Psi$ as a\nprompt-only JSON Parameter Emitter and preregister an evaluation on GSM8K, MATH\n(subset), StrategyQA, and ARC-Challenge with compute-aware reporting\n(success@compute, tokens-per-success) and ablations over $\\Lambda$, $\\Psi$,\ntrust-region radius, and control quantization; preregistered forecasts\nanticipate accuracy gains at comparable token budgets and improved\nsuccess@compute under constraints. NLEL offers an interpretable, model-agnostic\ninterface that separates intent from execution for controllable, auditable LM\ninference.", "AI": {"tldr": "NLEL\u662f\u4e00\u79cd\u81ea\u7136\u8bed\u8a00\u8fb9\u7f18\u6807\u6ce8\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u81ea\u7531\u5f62\u5f0f\u7684\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u9644\u52a0\u5230\u641c\u7d22\u8fb9\u7f18\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u6a21\u5f0f\u53d7\u9650\u7684\u63a7\u5236\u5411\u91cf\uff0c\u4ece\u800c\u89e3\u8026\u63a8\u7406\u610f\u56fe\u4e0e\u6267\u884c\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u7684\u7ed3\u6784\u5316LM\u63a8\u7406\u63a7\u5236\u5668\uff08\u5982CoT\u3001ToT\uff09\u5c06'\u4e0b\u4e00\u6b65\u5c1d\u8bd5\u4ec0\u4e48'\u4e0e'\u5982\u4f55\u6267\u884c'\u6df7\u5728\u4e00\u8d77\uff0c\u53ea\u66b4\u9732\u7c97\u7c92\u5ea6\u7684\u5168\u5c40\u63a7\u5236\uff0c\u5bfc\u81f4\u7cfb\u7edf\u8106\u5f31\u3001\u8ba1\u7b97\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u5ba1\u8ba1\u3002", "method": "\u5f15\u5165\u6807\u7b7e\u5668-\u8c03\u8c10\u5668\u8986\u76d6\u5c42\uff1a\u6807\u7b7e\u5668\u039b\u4ece\u7236\u72b6\u6001\u548c\u7d27\u51d1\u4e0a\u4e0b\u6587\u4e2d\u53d1\u51fa\u6807\u7b7e\uff1b\u8c03\u8c10\u5668\u03a8\u5c06(P,L,C)\u6620\u5c04\u5230\u03a0\uff0c\u5177\u6709\u4e25\u683c\u7684\u6a21\u5f0f\u9a8c\u8bc1\u548c\u5b89\u5168\u9ed8\u8ba4\u503c\u7684\u4fe1\u4efb\u533a\u57df\u6295\u5f71\u3002\u4e0b\u6e38\u9009\u62e9\u91c7\u7528ToT\u98ce\u683c\uff0c\u4f7f\u7528\u5f97\u5206S=\u03bc+\u03b2\u03c3\u548c\u6df1\u5ea6\u9000\u706b\u03b2\u3002", "result": "\u8bc1\u660e\u4e86NLEL\u4e25\u683c\u6cdb\u5316\u4e86CoT/ToT\uff0c\u4e3a\u6807\u7b7e\u6761\u4ef6\u675f\u4e0b\u7684top-k\u9009\u62e9\u8bc1\u660e\u4e86\u4efb\u610f\u65f6\u95f4\u5355\u8c03\u6027\uff0c\u5e76\u901a\u8fc7\u63a7\u5236\u5411\u91cf\u5931\u771f\u9650\u5236\u4e86\u9009\u62e9\u5668\u4e0d\u8db3\u3002", "conclusion": "NLEL\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u89e3\u91ca\u3001\u6a21\u578b\u65e0\u5173\u7684\u63a5\u53e3\uff0c\u5c06\u610f\u56fe\u4e0e\u6267\u884c\u5206\u79bb\uff0c\u5b9e\u73b0\u53ef\u63a7\u3001\u53ef\u5ba1\u8ba1\u7684LM\u63a8\u7406\u3002"}}
{"id": "2510.04851", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.04851", "abs": "https://arxiv.org/abs/2510.04851", "authors": ["Dongge Han", "Camille Couturier", "Daniel Madrigal Diaz", "Xuchao Zhang", "Victor R\u00fchle", "Saravan Rajmohan"], "title": "LEGOMem: Modular Procedural Memory for Multi-agent LLM Systems for Workflow Automation", "comment": null, "summary": "We introduce LEGOMem, a modular procedural memory framework for multi-agent\nlarge language model (LLM) systems in workflow automation. LEGOMem decomposes\npast task trajectories into reusable memory units and flexibly allocates them\nacross orchestrators and task agents to support planning and execution. To\nexplore the design space of memory in multi-agent systems, we use LEGOMem as a\nlens and conduct a systematic study of procedural memory in multi-agent\nsystems, examining where memory should be placed, how it should be retrieved,\nand which agents benefit most. Experiments on the OfficeBench benchmark show\nthat orchestrator memory is critical for effective task decomposition and\ndelegation, while fine-grained agent memory improves execution accuracy. We\nfind that even teams composed of smaller language models can benefit\nsubstantially from procedural memory, narrowing the performance gap with\nstronger agents by leveraging prior execution traces for more accurate planning\nand tool use. These results position LEGOMem as both a practical framework for\nmemory-augmented agent systems and a research tool for understanding memory\ndesign in multi-agent workflow automation.", "AI": {"tldr": "LEGOMem\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u7684\u6a21\u5757\u5316\u7a0b\u5e8f\u6027\u8bb0\u5fc6\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u4efb\u52a1\u8f68\u8ff9\u4e3a\u53ef\u91cd\u7528\u8bb0\u5fc6\u5355\u5143\uff0c\u63d0\u5347\u89c4\u5212\u4e0e\u6267\u884c\u80fd\u529b\u3002", "motivation": "\u63a2\u7d22\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u8bb0\u5fc6\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u7814\u7a76\u8bb0\u5fc6\u5e94\u8be5\u653e\u7f6e\u5728\u4f55\u5904\u3001\u5982\u4f55\u68c0\u7d22\u4ee5\u53ca\u54ea\u4e9b\u667a\u80fd\u4f53\u53d7\u76ca\u6700\u591a\uff0c\u4ee5\u63d0\u5347\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u6548\u679c\u3002", "method": "\u5c06\u8fc7\u53bb\u4efb\u52a1\u8f68\u8ff9\u5206\u89e3\u4e3a\u53ef\u91cd\u7528\u8bb0\u5fc6\u5355\u5143\uff0c\u7075\u6d3b\u5206\u914d\u7ed9\u7f16\u6392\u5668\u548c\u4efb\u52a1\u667a\u80fd\u4f53\uff0c\u652f\u6301\u89c4\u5212\u548c\u6267\u884c\u3002\u5728OfficeBench\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u7f16\u6392\u5668\u8bb0\u5fc6\u5bf9\u4efb\u52a1\u5206\u89e3\u548c\u59d4\u6d3e\u81f3\u5173\u91cd\u8981\uff0c\u7ec6\u7c92\u5ea6\u667a\u80fd\u4f53\u8bb0\u5fc6\u63d0\u9ad8\u6267\u884c\u51c6\u786e\u6027\u3002\u8f83\u5c0f\u8bed\u8a00\u6a21\u578b\u56e2\u961f\u4e5f\u80fd\u4ece\u7a0b\u5e8f\u6027\u8bb0\u5fc6\u4e2d\u663e\u8457\u53d7\u76ca\uff0c\u7f29\u5c0f\u4e0e\u66f4\u5f3a\u667a\u80fd\u4f53\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "LEGOMem\u65e2\u662f\u8bb0\u5fc6\u589e\u5f3a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5b9e\u7528\u6846\u67b6\uff0c\u4e5f\u662f\u7406\u89e3\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u4e2d\u8bb0\u5fc6\u8bbe\u8ba1\u7684\u7814\u7a76\u5de5\u5177\u3002"}}
{"id": "2510.04862", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.04862", "abs": "https://arxiv.org/abs/2510.04862", "authors": ["Sam Earle", "Zehua Jiang", "Eugene Vinitsky", "Julian Togelius"], "title": "Video Game Level Design as a Multi-Agent Reinforcement Learning Problem", "comment": "11 pages, 7 tables, 5 figures, published as full technical paper at\n  the AAAI conference on Artificial Intelligence and Interactive Digital\n  Entertainment 2025", "summary": "Procedural Content Generation via Reinforcement Learning (PCGRL) offers a\nmethod for training controllable level designer agents without the need for\nhuman datasets, using metrics that serve as proxies for level quality as\nrewards. Existing PCGRL research focuses on single generator agents, but are\nbottlenecked by the need to frequently recalculate heuristics of level quality\nand the agent's need to navigate around potentially large maps. By framing\nlevel generation as a multi-agent problem, we mitigate the efficiency\nbottleneck of single-agent PCGRL by reducing the number of reward calculations\nrelative to the number of agent actions. We also find that multi-agent level\ngenerators are better able to generalize to out-of-distribution map shapes,\nwhich we argue is due to the generators' learning more local, modular design\npolicies. We conclude that treating content generation as a distributed,\nmulti-agent task is beneficial for generating functional artifacts at scale.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u7a0b\u5e8f\u5316\u5185\u5bb9\u751f\u6210\u91cd\u65b0\u5b9a\u4e49\u4e3a\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u667a\u80fd\u4f53\u534f\u4f5c\u6765\u63d0\u5347\u751f\u6210\u6548\u7387\u548c\u5bf9\u4e0d\u540c\u5730\u56fe\u5f62\u72b6\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u5355\u667a\u80fd\u4f53PCGRL\u65b9\u6cd5\u5b58\u5728\u6548\u7387\u74f6\u9888\uff0c\u9700\u8981\u9891\u7e41\u91cd\u65b0\u8ba1\u7b97\u542f\u53d1\u5f0f\u8d28\u91cf\u6307\u6807\uff0c\u4e14\u667a\u80fd\u4f53\u9700\u8981\u5728\u5927\u578b\u5730\u56fe\u4e2d\u5bfc\u822a\u3002\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u5c06\u5173\u5361\u751f\u6210\u95ee\u9898\u91cd\u65b0\u6784\u5efa\u4e3a\u591a\u667a\u80fd\u4f53\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u667a\u80fd\u4f53\u534f\u4f5c\u51cf\u5c11\u5956\u52b1\u8ba1\u7b97\u6b21\u6570\uff0c\u5e76\u5b66\u4e60\u66f4\u5c40\u90e8\u5316\u3001\u6a21\u5757\u5316\u7684\u8bbe\u8ba1\u7b56\u7565\u3002", "result": "\u591a\u667a\u80fd\u4f53\u5173\u5361\u751f\u6210\u5668\u5728\u6548\u7387\u4e0a\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6cdb\u5316\u5230\u5206\u5e03\u5916\u5730\u56fe\u5f62\u72b6\uff0c\u5b66\u4e60\u5230\u66f4\u5c40\u90e8\u5316\u7684\u8bbe\u8ba1\u7b56\u7565\u3002", "conclusion": "\u5c06\u5185\u5bb9\u751f\u6210\u89c6\u4e3a\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u4efb\u52a1\u6709\u5229\u4e8e\u5927\u89c4\u6a21\u751f\u6210\u529f\u80fd\u6027\u5185\u5bb9\uff0c\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u5728\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2510.04886", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.04886", "abs": "https://arxiv.org/abs/2510.04886", "authors": ["Adi Banerjee", "Anirudh Nair", "Tarik Borogovac"], "title": "Where Did It All Go Wrong? A Hierarchical Look into Multi-Agent Error Attribution", "comment": null, "summary": "Error attribution in Large Language Model (LLM) multi-agent systems presents\na significant challenge in debugging and improving collaborative AI systems.\nCurrent approaches to pinpointing agent and step level failures in interaction\ntraces - whether using all-at-once evaluation, step-by-step analysis, or binary\nsearch - fall short when analyzing complex patterns, struggling with both\naccuracy and consistency. We present ECHO (Error attribution through Contextual\nHierarchy and Objective consensus analysis), a novel algorithm that combines\nhierarchical context representation, objective analysis-based evaluation, and\nconsensus voting to improve error attribution accuracy. Our approach leverages\na positional-based leveling of contextual understanding while maintaining\nobjective evaluation criteria, ultimately reaching conclusions through a\nconsensus mechanism. Experimental results demonstrate that ECHO outperforms\nexisting methods across various multi-agent interaction scenarios, showing\nparticular strength in cases involving subtle reasoning errors and complex\ninterdependencies. Our findings suggest that leveraging these concepts of\nstructured, hierarchical context representation combined with consensus-based\nobjective decision-making, provides a more robust framework for error\nattribution in multi-agent systems.", "AI": {"tldr": "ECHO\u7b97\u6cd5\u901a\u8fc7\u5c42\u6b21\u5316\u4e0a\u4e0b\u6587\u8868\u793a\u3001\u57fa\u4e8e\u76ee\u6807\u7684\u5206\u6790\u8bc4\u4f30\u548c\u5171\u8bc6\u6295\u7968\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u9519\u8bef\u5f52\u56e0\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u9519\u8bef\u5f52\u56e0\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u4ea4\u4e92\u6a21\u5f0f\u65f6\u5b58\u5728\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u8c03\u8bd5\u5de5\u5177\u3002", "method": "\u7ed3\u5408\u5c42\u6b21\u5316\u4e0a\u4e0b\u6587\u8868\u793a\u3001\u57fa\u4e8e\u76ee\u6807\u7684\u5206\u6790\u8bc4\u4f30\u548c\u5171\u8bc6\u6295\u7968\u673a\u5236\uff0c\u901a\u8fc7\u4f4d\u7f6e\u5316\u5c42\u6b21\u7406\u89e3\u4e0a\u4e0b\u6587\u5e76\u4fdd\u6301\u5ba2\u89c2\u8bc4\u4f30\u6807\u51c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eECHO\u5728\u5404\u79cd\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u573a\u666f\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7279\u522b\u5728\u5904\u7406\u5fae\u5999\u63a8\u7406\u9519\u8bef\u548c\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u65f6\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u7ed3\u6784\u5316\u5c42\u6b21\u5316\u4e0a\u4e0b\u6587\u8868\u793a\u4e0e\u57fa\u4e8e\u5171\u8bc6\u7684\u5ba2\u89c2\u51b3\u7b56\u76f8\u7ed3\u5408\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u9519\u8bef\u5f52\u56e0\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u6846\u67b6\u3002"}}
{"id": "2510.04899", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04899", "abs": "https://arxiv.org/abs/2510.04899", "authors": ["Keane Ong", "Wei Dai", "Carol Li", "Dewei Feng", "Hengzhi Li", "Jingyao Wu", "Jiaee Cheong", "Rui Mao", "Gianmarco Mengaldo", "Erik Cambria", "Paul Pu Liang"], "title": "Human Behavior Atlas: Benchmarking Unified Psychological and Social Behavior Understanding", "comment": null, "summary": "Using intelligent systems to perceive psychological and social behaviors,\nthat is, the underlying affective, cognitive, and pathological states that are\nmanifested through observable behaviors and social interactions, remains a\nchallenge due to their complex, multifaceted, and personalized nature. Existing\nwork tackling these dimensions through specialized datasets and single-task\nsystems often miss opportunities for scalability, cross-task transfer, and\nbroader generalization. To address this gap, we curate Human Behavior Atlas, a\nunified benchmark of diverse behavioral tasks designed to support the\ndevelopment of unified models for understanding psychological and social\nbehaviors. Human Behavior Atlas comprises over 100,000 samples spanning text,\naudio, and visual modalities, covering tasks on affective states, cognitive\nstates, pathologies, and social processes. Our unification efforts can reduce\nredundancy and cost, enable training to scale efficiently across tasks, and\nenhance generalization of behavioral features across domains. On Human Behavior\nAtlas, we train three models: OmniSapiens-7B SFT, OmniSapiens-7B BAM, and\nOmniSapiens-7B RL. We show that training on Human Behavior Atlas enables models\nto consistently outperform existing multimodal LLMs across diverse behavioral\ntasks. Pretraining on Human Behavior Atlas also improves transfer to novel\nbehavioral datasets; with the targeted use of behavioral descriptors yielding\nmeaningful performance gains.", "AI": {"tldr": "\u63d0\u51fa\u4e86Human Behavior Atlas\u7edf\u4e00\u57fa\u51c6\uff0c\u5305\u542b10\u4e07+\u591a\u6a21\u6001\u6837\u672c\uff0c\u7528\u4e8e\u5f00\u53d1\u7406\u89e3\u5fc3\u7406\u548c\u793e\u4f1a\u884c\u4e3a\u7684\u7edf\u4e00\u6a21\u578b\u3002\u8bad\u7ec3\u7684\u4e09\u4e2aOmniSapiens-7B\u6a21\u578b\u5728\u591a\u6837\u5316\u884c\u4e3a\u4efb\u52a1\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u591a\u6a21\u6001LLM\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u901a\u8fc7\u4e13\u7528\u6570\u636e\u96c6\u548c\u5355\u4efb\u52a1\u7cfb\u7edf\u5904\u7406\u5fc3\u7406\u793e\u4f1a\u884c\u4e3a\u7ef4\u5ea6\uff0c\u4f46\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\u3001\u8de8\u4efb\u52a1\u8fc1\u79fb\u548c\u6cdb\u5316\u80fd\u529b\u3002\u9700\u8981\u7edf\u4e00\u57fa\u51c6\u6765\u652f\u6301\u7edf\u4e00\u6a21\u578b\u5f00\u53d1\u3002", "method": "\u6784\u5efaHuman Behavior Atlas\u7edf\u4e00\u57fa\u51c6\uff0c\u5305\u542b\u6587\u672c\u3001\u97f3\u9891\u3001\u89c6\u89c9\u591a\u6a21\u6001\u6570\u636e\uff0c\u6db5\u76d6\u60c5\u611f\u72b6\u6001\u3001\u8ba4\u77e5\u72b6\u6001\u3001\u75c5\u7406\u548c\u793e\u4f1a\u8fc7\u7a0b\u7b49\u4efb\u52a1\u3002\u8bad\u7ec3\u4e09\u4e2aOmniSapiens-7B\u6a21\u578b\uff1aSFT\u3001BAM\u548cRL\u7248\u672c\u3002", "result": "\u5728Human Behavior Atlas\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u591a\u6837\u5316\u884c\u4e3a\u4efb\u52a1\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u591a\u6a21\u6001LLM\u3002\u9884\u8bad\u7ec3\u8fd8\u6539\u5584\u4e86\u5411\u65b0\u884c\u4e3a\u6570\u636e\u96c6\u7684\u8fc1\u79fb\uff0c\u884c\u4e3a\u63cf\u8ff0\u7b26\u7684\u4f7f\u7528\u5e26\u6765\u6709\u610f\u4e49\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "Human Behavior Atlas\u57fa\u51c6\u80fd\u591f\u51cf\u5c11\u5197\u4f59\u548c\u6210\u672c\uff0c\u5b9e\u73b0\u8de8\u4efb\u52a1\u9ad8\u6548\u8bad\u7ec3\uff0c\u5e76\u589e\u5f3a\u884c\u4e3a\u7279\u5f81\u5728\u9886\u57df\u95f4\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u7406\u89e3\u5fc3\u7406\u793e\u4f1a\u884c\u4e3a\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2510.04935", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04935", "abs": "https://arxiv.org/abs/2510.04935", "authors": ["Guoxin Chen", "Zile Qiao", "Wenqing Wang", "Donglei Yu", "Xuanzhong Chen", "Hao Sun", "Minpeng Liao", "Kai Fan", "Yong Jiang", "Penguin Xie", "Wayne Xin Zhao", "Ruihua Song", "Fei Huang"], "title": "MARS: Optimizing Dual-System Deep Research via Multi-Agent Reinforcement Learning", "comment": "Ongoing Work", "summary": "Large Reasoning Models (LRMs) often exhibit a tendency for overanalysis in\nsimple tasks, where the models excessively utilize System 2-type, deliberate\nreasoning, leading to inefficient token generation. Furthermore, these models\nface challenges in adapting their reasoning capabilities to rapidly changing\nenvironments due to the static nature of their pretraining data. To address\nthese issues, advancing Large Language Models (LLMs) for complex reasoning\ntasks requires innovative approaches that bridge intuitive and deliberate\ncognitive processes, akin to human cognition's dual-system dynamic. This paper\nintroduces a Multi-Agent System for Deep ReSearch (MARS) enabling seamless\nintegration of System 1's fast, intuitive thinking with System 2's deliberate\nreasoning within LLMs. MARS strategically integrates multiple external tools,\nsuch as Google Search, Google Scholar, and Python Interpreter, to access\nup-to-date information and execute complex computations, while creating a\nspecialized division of labor where System 1 efficiently processes and\nsummarizes high-volume external information, providing distilled insights that\nexpand System 2's reasoning context without overwhelming its capacity.\nFurthermore, we propose a multi-agent reinforcement learning framework\nextending Group Relative Policy Optimization to simultaneously optimize both\nsystems with multi-turn tool interactions, bin-packing optimization, and sample\nbalancing strategies that enhance collaborative efficiency. Extensive\nexperiments demonstrate MARS achieves substantial improvements of 3.86% on the\nchallenging Humanity's Last Exam (HLE) benchmark and an average gain of 8.9%\nacross 7 knowledge-intensive tasks, validating the effectiveness of our\ndual-system paradigm for complex reasoning in dynamic information environments.", "AI": {"tldr": "MARS\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408System 1\u7684\u5feb\u901f\u76f4\u89c9\u601d\u7ef4\u548cSystem 2\u7684\u6df1\u601d\u719f\u8651\u63a8\u7406\u6765\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7b80\u5355\u4efb\u52a1\u4e2d\u8fc7\u5ea6\u5206\u6790\u7684\u95ee\u9898\uff0c\u5e76\u5728\u52a8\u6001\u4fe1\u606f\u73af\u5883\u4e2d\u63d0\u5347\u590d\u6742\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u5927\u63a8\u7406\u6a21\u578b\u5728\u7b80\u5355\u4efb\u52a1\u4e2d\u8fc7\u5ea6\u4f7f\u7528System 2\u578b\u63a8\u7406\u5bfc\u81f4\u7684\u4f4e\u6548\u95ee\u9898\uff0c\u4ee5\u53ca\u7531\u4e8e\u9884\u8bad\u7ec3\u6570\u636e\u9759\u6001\u6027\u800c\u96be\u4ee5\u9002\u5e94\u5feb\u901f\u53d8\u5316\u73af\u5883\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faMARS\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u96c6\u6210Google\u641c\u7d22\u3001Google\u5b66\u672f\u548cPython\u89e3\u91ca\u5668\u7b49\u5916\u90e8\u5de5\u5177\uff0c\u901a\u8fc7\u5206\u5de5\u534f\u4f5c\u8ba9System 1\u9ad8\u6548\u5904\u7406\u5916\u90e8\u4fe1\u606f\uff0c\u4e3aSystem 2\u63d0\u4f9b\u7cbe\u70bc\u7684\u63a8\u7406\u4e0a\u4e0b\u6587\uff1b\u91c7\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4f18\u5316\u4e24\u4e2a\u7cfb\u7edf\u7684\u534f\u4f5c\u6548\u7387\u3002", "result": "\u5728Humanity's Last Exam\u57fa\u51c6\u4e0a\u53d6\u5f973.86%\u7684\u663e\u8457\u63d0\u5347\uff0c\u57287\u4e2a\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u5e73\u5747\u83b7\u5f978.9%\u7684\u6027\u80fd\u589e\u76ca\u3002", "conclusion": "MARS\u7684\u53cc\u7cfb\u7edf\u8303\u5f0f\u5728\u52a8\u6001\u4fe1\u606f\u73af\u5883\u4e2d\u6709\u6548\u63d0\u5347\u4e86\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c\u9a8c\u8bc1\u4e86\u76f4\u89c9\u601d\u7ef4\u4e0e\u6df1\u601d\u719f\u8651\u63a8\u7406\u6574\u5408\u7684\u4ef7\u503c\u3002"}}
{"id": "2510.04952", "categories": ["cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.04952", "abs": "https://arxiv.org/abs/2510.04952", "authors": ["Ailiya Borjigin", "Cong He"], "title": "Safe and Compliant Cross-Market Trade Execution via Constrained RL and Zero-Knowledge Audits", "comment": "22 pages, 2 figures", "summary": "We present a cross-market algorithmic trading system that balances execution\nquality with rigorous compliance enforcement. The architecture comprises a\nhigh-level planner, a reinforcement learning execution agent, and an\nindependent compliance agent. We formulate trade execution as a constrained\nMarkov decision process with hard constraints on participation limits, price\nbands, and self-trading avoidance. The execution agent is trained with proximal\npolicy optimization, while a runtime action-shield projects any unsafe action\ninto a feasible set. To support auditability without exposing proprietary\nsignals, we add a zero-knowledge compliance audit layer that produces\ncryptographic proofs that all actions satisfied the constraints. We evaluate in\na multi-venue, ABIDES-based simulator and compare against standard baselines\n(e.g., TWAP, VWAP). The learned policy reduces implementation shortfall and\nvariance while exhibiting no observed constraint violations across stress\nscenarios including elevated latency, partial fills, compliance module\ntoggling, and varying constraint limits. We report effects at the 95%\nconfidence level using paired t-tests and examine tail risk via CVaR. We\nsituate the work at the intersection of optimal execution, safe reinforcement\nlearning, regulatory technology, and verifiable AI, and discuss ethical\nconsiderations, limitations (e.g., modeling assumptions and computational\noverhead), and paths to real-world deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8de8\u5e02\u573a\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u6267\u884c\u4ee3\u7406\u548c\u72ec\u7acb\u5408\u89c4\u4ee3\u7406\uff0c\u5728\u4fdd\u8bc1\u6267\u884c\u8d28\u91cf\u7684\u540c\u65f6\u4e25\u683c\u6ee1\u8db3\u76d1\u7ba1\u7ea6\u675f\u3002", "motivation": "\u4f20\u7edf\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\u96be\u4ee5\u5728\u8ffd\u6c42\u6267\u884c\u8d28\u91cf\u7684\u540c\u65f6\u786e\u4fdd\u4e25\u683c\u7684\u5408\u89c4\u6027\uff0c\u7279\u522b\u662f\u5728\u591a\u5e02\u573a\u73af\u5883\u4e2d\u9700\u8981\u5904\u7406\u53c2\u4e0e\u9650\u5236\u3001\u4ef7\u683c\u533a\u95f4\u548c\u81ea\u6211\u4ea4\u6613\u907f\u514d\u7b49\u786c\u7ea6\u675f\u3002", "method": "\u5c06\u4ea4\u6613\u6267\u884c\u5efa\u6a21\u4e3a\u5e26\u786c\u7ea6\u675f\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u8bad\u7ec3\u6267\u884c\u4ee3\u7406\uff0c\u8fd0\u884c\u65f6\u901a\u8fc7\u52a8\u4f5c\u5c4f\u853d\u786e\u4fdd\u884c\u52a8\u53ef\u884c\u6027\uff0c\u5e76\u6dfb\u52a0\u96f6\u77e5\u8bc6\u5408\u89c4\u5ba1\u8ba1\u5c42\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7684\u5408\u89c4\u8bc1\u660e\u3002", "result": "\u5728ABIDES\u591a\u5e02\u573a\u6a21\u62df\u5668\u4e2d\uff0c\u5b66\u4e60\u7b56\u7565\u76f8\u6bd4\u6807\u51c6\u57fa\u51c6\uff08\u5982TWAP\u3001VWAP\uff09\u51cf\u5c11\u4e86\u6267\u884c\u5dee\u989d\u548c\u65b9\u5dee\uff0c\u5728\u5404\u79cd\u538b\u529b\u573a\u666f\u4e0b\u5747\u672a\u89c2\u5bdf\u5230\u7ea6\u675f\u8fdd\u53cd\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u6700\u4f18\u6267\u884c\u3001\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u3001\u76d1\u7ba1\u6280\u672f\u548c\u53ef\u9a8c\u8bc1AI\u7684\u4ea4\u53c9\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5b58\u5728\u5efa\u6a21\u5047\u8bbe\u548c\u8ba1\u7b97\u5f00\u9500\u7b49\u9650\u5236\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u624d\u80fd\u5b9e\u73b0\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2510.04978", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04978", "abs": "https://arxiv.org/abs/2510.04978", "authors": ["Kun Xiang", "Terry Jingchen Zhang", "Yinya Huang", "Jixi He", "Zirong Liu", "Yueling Tang", "Ruizhe Zhou", "Lijing Luo", "Youpeng Wen", "Xiuwei Chen", "Bingqian Lin", "Jianhua Han", "Hang Xu", "Hanhui Li", "Bin Dong", "Xiaodan Liang"], "title": "Aligning Perception, Reasoning, Modeling and Interaction: A Survey on Physical AI", "comment": null, "summary": "The rapid advancement of embodied intelligence and world models has\nintensified efforts to integrate physical laws into AI systems, yet physical\nperception and symbolic physics reasoning have developed along separate\ntrajectories without a unified bridging framework. This work provides a\ncomprehensive overview of physical AI, establishing clear distinctions between\ntheoretical physics reasoning and applied physical understanding while\nsystematically examining how physics-grounded methods enhance AI's real-world\ncomprehension across structured symbolic reasoning, embodied systems, and\ngenerative models. Through rigorous analysis of recent advances, we advocate\nfor intelligent systems that ground learning in both physical principles and\nembodied reasoning processes, transcending pattern recognition toward genuine\nunderstanding of physical laws. Our synthesis envisions next-generation world\nmodels capable of explaining physical phenomena and predicting future states,\nadvancing safe, generalizable, and interpretable AI systems. We maintain a\ncontinuously updated resource at\nhttps://github.com/AI4Phys/Awesome-AI-for-Physics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u7269\u7406AI\u9886\u57df\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u533a\u5206\u4e86\u7406\u8bba\u7269\u7406\u63a8\u7406\u548c\u5e94\u7528\u7269\u7406\u7406\u89e3\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u7269\u7406\u57fa\u7840\u65b9\u6cd5\u5982\u4f55\u63d0\u5347AI\u5728\u7b26\u53f7\u63a8\u7406\u3001\u5177\u8eab\u7cfb\u7edf\u548c\u751f\u6210\u6a21\u578b\u4e2d\u7684\u771f\u5b9e\u4e16\u754c\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7269\u7406\u611f\u77e5\u548c\u7b26\u53f7\u7269\u7406\u63a8\u7406\u5404\u81ea\u53d1\u5c55\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u6865\u63a5\u6846\u67b6\uff0c\u9700\u8981\u5efa\u7acb\u6574\u5408\u7269\u7406\u5b9a\u5f8b\u548c\u5177\u8eab\u63a8\u7406\u7684\u667a\u80fd\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u8fd1\u671f\u8fdb\u5c55\uff0c\u5efa\u7acb\u7269\u7406AI\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u8003\u5bdf\u7269\u7406\u57fa\u7840\u65b9\u6cd5\u5728\u7ed3\u6784\u5316\u7b26\u53f7\u63a8\u7406\u3001\u5177\u8eab\u7cfb\u7edf\u548c\u751f\u6210\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u63d0\u51fa\u4e86\u80fd\u591f\u89e3\u91ca\u7269\u7406\u73b0\u8c61\u548c\u9884\u6d4b\u672a\u6765\u72b6\u6001\u7684\u4e0b\u4e00\u4ee3\u4e16\u754c\u6a21\u578b\uff0c\u63a8\u8fdb\u5b89\u5168\u3001\u53ef\u6cdb\u5316\u548c\u53ef\u89e3\u91ca\u7684AI\u7cfb\u7edf\u53d1\u5c55\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u65e2\u57fa\u4e8e\u7269\u7406\u539f\u7406\u53c8\u7ed3\u5408\u5177\u8eab\u63a8\u7406\u8fc7\u7a0b\u7684\u667a\u80fd\u7cfb\u7edf\uff0c\u8d85\u8d8a\u6a21\u5f0f\u8bc6\u522b\uff0c\u5b9e\u73b0\u7269\u7406\u5b9a\u5f8b\u7684\u771f\u6b63\u7406\u89e3\u3002"}}
{"id": "2510.04980", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04980", "abs": "https://arxiv.org/abs/2510.04980", "authors": ["Fangzhou Liang", "Tianshi Zheng", "Chunkit Chan", "Yauwai Yim", "Yangqiu Song"], "title": "LLM-Hanabi: Evaluating Multi-Agent Gameplays with Theory-of-Mind and Rationale Inference in Imperfect Information Collaboration Game", "comment": "EMNLP 2025 Wordplay", "summary": "Effective multi-agent collaboration requires agents to infer the rationale\nbehind others' actions, a capability rooted in Theory-of-Mind (ToM). While\nrecent Large Language Models (LLMs) excel at logical inference, their ability\nto infer rationale in dynamic, collaborative settings remains under-explored.\nThis study introduces LLM-Hanabi, a novel benchmark that uses the cooperative\ngame Hanabi to evaluate the rationale inference and ToM of LLMs. Our framework\nfeatures an automated evaluation system that measures both game performance and\nToM proficiency. Across a range of models, we find a significant positive\ncorrelation between ToM and in-game success. Notably, first-order ToM\n(interpreting others' intent) correlates more strongly with performance than\nsecond-order ToM (predicting others' interpretations). These findings highlight\nthat for effective AI collaboration, the ability to accurately interpret a\npartner's rationale is more critical than higher-order reasoning. We conclude\nthat prioritizing first-order ToM is a promising direction for enhancing the\ncollaborative capabilities of future models.", "AI": {"tldr": "LLM-Hanabi\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u5fc3\u667a\u7406\u8bba\u80fd\u529b\u4e0e\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u8868\u73b0\u6b63\u76f8\u5173\uff0c\u5176\u4e2d\u4e00\u9636\u5fc3\u667a\u7406\u8bba\uff08\u7406\u89e3\u4ed6\u4eba\u610f\u56fe\uff09\u6bd4\u4e8c\u9636\u5fc3\u667a\u7406\u8bba\uff08\u9884\u6d4b\u4ed6\u4eba\u7406\u89e3\uff09\u5bf9\u6e38\u620f\u6210\u529f\u66f4\u91cd\u8981\u3002", "motivation": "\u8bc4\u4f30LLMs\u5728\u52a8\u6001\u534f\u4f5c\u73af\u5883\u4e2d\u63a8\u65ad\u4ed6\u4eba\u884c\u4e3a\u52a8\u673a\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\uff0c\u8fd9\u5728\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4e2d\u81f3\u5173\u91cd\u8981\u4f46\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u5408\u4f5c\u6e38\u620fHanabi\u6784\u5efaLLM-Hanabi\u57fa\u51c6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u8bc4\u4f30\u7cfb\u7edf\u540c\u65f6\u6d4b\u91cf\u6e38\u620f\u8868\u73b0\u548c\u5fc3\u667a\u7406\u8bba\u719f\u7ec3\u5ea6\u3002", "result": "\u53d1\u73b0\u5fc3\u667a\u7406\u8bba\u4e0e\u6e38\u620f\u6210\u529f\u663e\u8457\u6b63\u76f8\u5173\uff0c\u4e00\u9636\u5fc3\u667a\u7406\u8bba\u6bd4\u4e8c\u9636\u5fc3\u667a\u7406\u8bba\u4e0e\u8868\u73b0\u7684\u76f8\u5173\u6027\u66f4\u5f3a\u3002", "conclusion": "\u5bf9\u4e8e\u6709\u6548\u7684AI\u534f\u4f5c\uff0c\u51c6\u786e\u89e3\u91ca\u4f19\u4f34\u52a8\u673a\u7684\u80fd\u529b\u6bd4\u9ad8\u9636\u63a8\u7406\u66f4\u91cd\u8981\uff0c\u4f18\u5148\u53d1\u5c55\u4e00\u9636\u5fc3\u667a\u7406\u8bba\u662f\u63d0\u5347\u6a21\u578b\u534f\u4f5c\u80fd\u529b\u7684\u6709\u524d\u666f\u65b9\u5411\u3002"}}
{"id": "2510.05014", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05014", "abs": "https://arxiv.org/abs/2510.05014", "authors": ["Xuanming Cui", "Jianpeng Cheng", "Hong-you Chen", "Satya Narayan Shukla", "Abhijeet Awasthi", "Xichen Pan", "Chaitanya Ahuja", "Shlok Kumar Mishra", "Qi Guo", "Ser-Nam Lim", "Aashu Singh", "Xiangjun Fan"], "title": "Think Then Embed: Generative Context Improves Multimodal Embedding", "comment": null, "summary": "There is a growing interest in Universal Multimodal Embeddings (UME), where\nmodels are required to generate task-specific representations. While recent\nstudies show that Multimodal Large Language Models (MLLMs) perform well on such\ntasks, they treat MLLMs solely as encoders, overlooking their generative\ncapacity. However, such an encoding paradigm becomes less effective as\ninstructions become more complex and require compositional reasoning. Inspired\nby the proven effectiveness of chain-of-thought reasoning, we propose a general\nThink-Then-Embed (TTE) framework for UME, composed of a reasoner and an\nembedder. The reasoner MLLM first generates reasoning traces that explain\ncomplex queries, followed by an embedder that produces representations\nconditioned on both the original query and the intermediate reasoning. This\nexplicit reasoning step enables more nuanced understanding of complex\nmultimodal instructions. Our contributions are threefold. First, by leveraging\na powerful MLLM reasoner, we achieve state-of-the-art performance on the\nMMEB-V2 benchmark, surpassing proprietary models trained on massive in-house\ndatasets. Second, to reduce the dependency on large MLLM reasoners, we finetune\na smaller MLLM reasoner using high-quality embedding-centric reasoning traces,\nachieving the best performance among open-source models with a 7% absolute gain\nover recently proposed models. Third, we investigate strategies for integrating\nthe reasoner and embedder into a unified model for improved efficiency without\nsacrificing performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86Think-Then-Embed\u6846\u67b6\uff0c\u5229\u7528MLLM\u7684\u63a8\u7406\u80fd\u529b\u751f\u6210\u89e3\u91ca\u590d\u6742\u67e5\u8be2\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u7136\u540e\u7531\u5d4c\u5165\u5668\u57fa\u4e8e\u539f\u59cb\u67e5\u8be2\u548c\u4e2d\u95f4\u63a8\u7406\u751f\u6210\u8868\u793a\uff0c\u5728MMEB-V2\u57fa\u51c6\u4e0a\u53d6\u5f97\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4ec5\u5c06MLLM\u4f5c\u4e3a\u7f16\u7801\u5668\uff0c\u5ffd\u89c6\u4e86\u5176\u751f\u6210\u80fd\u529b\uff0c\u5728\u5904\u7406\u590d\u6742\u6307\u4ee4\u548c\u7ec4\u5408\u63a8\u7406\u65f6\u6548\u679c\u4e0d\u4f73\u3002\u53d7\u601d\u7ef4\u94fe\u63a8\u7406\u542f\u53d1\uff0c\u9700\u8981\u663e\u5f0f\u63a8\u7406\u6b65\u9aa4\u6765\u66f4\u597d\u5730\u7406\u89e3\u590d\u6742\u591a\u6a21\u6001\u6307\u4ee4\u3002", "method": "TTE\u6846\u67b6\u5305\u542b\u63a8\u7406\u5668\u548c\u5d4c\u5165\u5668\uff1a\u63a8\u7406\u5668MLLM\u751f\u6210\u89e3\u91ca\u590d\u6742\u67e5\u8be2\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u5d4c\u5165\u5668\u57fa\u4e8e\u539f\u59cb\u67e5\u8be2\u548c\u4e2d\u95f4\u63a8\u7406\u751f\u6210\u8868\u793a\u3002\u8fd8\u7814\u7a76\u4e86\u5c06\u4e24\u8005\u96c6\u6210\u5230\u7edf\u4e00\u6a21\u578b\u4e2d\u7684\u7b56\u7565\u3002", "result": "\u5728MMEB-V2\u57fa\u51c6\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u8d85\u8d8a\u57fa\u4e8e\u5927\u89c4\u6a21\u5185\u90e8\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u4e13\u6709\u6a21\u578b\u3002\u5fae\u8c03\u8f83\u5c0fMLLM\u63a8\u7406\u5668\u83b7\u5f97\u5f00\u6e90\u6a21\u578b\u4e2d\u6700\u4f73\u6027\u80fd\uff0c\u6bd4\u8fd1\u671f\u6a21\u578b\u63d0\u53477%\u3002", "conclusion": "TTE\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u63a8\u7406\u6b65\u9aa4\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u591a\u6a21\u6001\u6307\u4ee4\u7684\u7406\u89e3\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u5229\u7528MLLM\u751f\u6210\u80fd\u529b\u8fdb\u884c\u63a8\u7406\u7684\u6709\u6548\u6027\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u96c6\u6210\u65b9\u6848\u3002"}}
{"id": "2510.05048", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2510.05048", "abs": "https://arxiv.org/abs/2510.05048", "authors": ["Ond\u0159ej Kub\u00ed\u010dek", "Viliam Lis\u00fd"], "title": "Look-ahead Reasoning with a Learned Model in Imperfect Information Games", "comment": null, "summary": "Test-time reasoning significantly enhances pre-trained AI agents'\nperformance. However, it requires an explicit environment model, often\nunavailable or overly complex in real-world scenarios. While MuZero enables\neffective model learning for search in perfect information games, extending\nthis paradigm to imperfect information games presents substantial challenges\ndue to more nuanced look-ahead reasoning techniques and large number of states\nrelevant for individual decisions. This paper introduces an algorithm LAMIR\nthat learns an abstracted model of an imperfect information game directly from\nthe agent-environment interaction. During test time, this trained model is used\nto perform look-ahead reasoning. The learned abstraction limits the size of\neach subgame to a manageable size, making theoretically principled look-ahead\nreasoning tractable even in games where previous methods could not scale. We\nempirically demonstrate that with sufficient capacity, LAMIR learns the exact\nunderlying game structure, and with limited capacity, it still learns a\nvaluable abstraction, which improves game playing performance of the\npre-trained agents even in large games.", "AI": {"tldr": "LAMIR\u7b97\u6cd5\u901a\u8fc7\u5b66\u4e60\u4e0d\u5b8c\u5168\u4fe1\u606f\u6e38\u620f\u7684\u62bd\u8c61\u6a21\u578b\uff0c\u4f7f\u9884\u8bad\u7ec3AI\u4ee3\u7406\u80fd\u591f\u8fdb\u884c\u524d\u77bb\u63a8\u7406\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u5927\u578b\u6e38\u620f\u4e2d\u96be\u4ee5\u6269\u5c55\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u63a8\u7406\u65b9\u6cd5\u9700\u8981\u660e\u786e\u7684\u73af\u5883\u6a21\u578b\uff0c\u4f46\u5728\u4e0d\u5b8c\u5168\u4fe1\u606f\u6e38\u620f\u4e2d\uff0c\u7531\u4e8e\u72b6\u6001\u7a7a\u95f4\u5e9e\u5927\u548c\u524d\u77bb\u63a8\u7406\u6280\u672f\u590d\u6742\uff0c\u8fd9\u79cd\u65b9\u6cd5\u96be\u4ee5\u6269\u5c55\u3002", "method": "LAMIR\u76f4\u63a5\u4ece\u4ee3\u7406-\u73af\u5883\u4ea4\u4e92\u4e2d\u5b66\u4e60\u4e0d\u5b8c\u5168\u4fe1\u606f\u6e38\u620f\u7684\u62bd\u8c61\u6a21\u578b\uff0c\u901a\u8fc7\u5b66\u4e60\u7684\u62bd\u8c61\u5c06\u6bcf\u4e2a\u5b50\u6e38\u620f\u9650\u5236\u5728\u53ef\u7ba1\u7406\u7684\u5927\u5c0f\uff0c\u4f7f\u7406\u8bba\u4e0a\u6709\u539f\u5219\u7684\u524d\u77bb\u63a8\u7406\u53d8\u5f97\u53ef\u884c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u8db3\u591f\u5bb9\u91cf\u4e0b\uff0cLAMIR\u80fd\u5b66\u4e60\u5230\u7cbe\u786e\u7684\u5e95\u5c42\u6e38\u620f\u7ed3\u6784\uff1b\u5728\u6709\u9650\u5bb9\u91cf\u4e0b\uff0c\u4ecd\u80fd\u5b66\u4e60\u5230\u6709\u4ef7\u503c\u7684\u62bd\u8c61\uff0c\u63d0\u5347\u9884\u8bad\u7ec3\u4ee3\u7406\u5728\u5927\u578b\u6e38\u620f\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "LAMIR\u901a\u8fc7\u5b66\u4e60\u6e38\u620f\u62bd\u8c61\u6a21\u578b\uff0c\u4f7f\u4e0d\u5b8c\u5168\u4fe1\u606f\u6e38\u620f\u4e2d\u7684\u524d\u77bb\u63a8\u7406\u53d8\u5f97\u53ef\u884c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u8bad\u7ec3AI\u4ee3\u7406\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5927\u578b\u6e38\u620f\u4e2d\u3002"}}
{"id": "2510.05059", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05059", "abs": "https://arxiv.org/abs/2510.05059", "authors": ["Junlin Wang", "Jue Wang", "Zhen", "Xu", "Ben Athiwaratkun", "Bhuwan Dhingra", "Ce Zhang", "James Zou"], "title": "Staircase Streaming for Low-Latency Multi-Agent Inference", "comment": null, "summary": "Recent advances in large language models (LLMs) opened up new directions for\nleveraging the collective expertise of multiple LLMs. These methods, such as\nMixture-of-Agents, typically employ additional inference steps to generate\nintermediate outputs, which are then used to produce the final response. While\nmulti-agent inference can enhance response quality, it can significantly\nincrease the time to first token (TTFT), posing a challenge for\nlatency-sensitive applications and hurting user experience. To address this\nissue, we propose staircase streaming for low-latency multi-agent inference.\nInstead of waiting for the complete intermediate outputs from previous steps,\nwe begin generating the final response as soon as we receive partial outputs\nfrom these steps. Experimental results demonstrate that staircase streaming\nreduces TTFT by up to 93% while maintaining response quality.", "AI": {"tldr": "\u63d0\u51fa\u9636\u68af\u5f0f\u6d41\u5904\u7406\u65b9\u6cd5\u6765\u964d\u4f4e\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7684\u9996\u6b21\u4ee4\u724c\u65f6\u95f4(TTFT)\uff0c\u901a\u8fc7\u90e8\u5206\u8f93\u51fa\u7acb\u5373\u5f00\u59cb\u751f\u6210\u6700\u7ec8\u54cd\u5e94\uff0c\u800c\u4e0d\u662f\u7b49\u5f85\u5b8c\u6574\u4e2d\u95f4\u8f93\u51fa\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u63a8\u7406\u867d\u7136\u80fd\u63d0\u9ad8\u54cd\u5e94\u8d28\u91cf\uff0c\u4f46\u663e\u8457\u589e\u52a0\u4e86\u9996\u6b21\u4ee4\u724c\u65f6\u95f4\uff0c\u8fd9\u5bf9\u5ef6\u8fdf\u654f\u611f\u7684\u5e94\u7528\u6784\u6210\u6311\u6218\u5e76\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u9636\u68af\u5f0f\u6d41\u5904\u7406\uff1a\u4e00\u65e6\u6536\u5230\u524d\u4e00\u6b65\u9aa4\u7684\u90e8\u5206\u8f93\u51fa\uff0c\u5c31\u7acb\u5373\u5f00\u59cb\u751f\u6210\u6700\u7ec8\u54cd\u5e94\uff0c\u800c\u4e0d\u662f\u7b49\u5f85\u5b8c\u6574\u7684\u4e2d\u95f4\u8f93\u51fa\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u9636\u68af\u5f0f\u6d41\u5904\u7406\u5c06TTFT\u964d\u4f4e\u4e86\u9ad8\u8fbe93%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u54cd\u5e94\u8d28\u91cf\u3002", "conclusion": "\u9636\u68af\u5f0f\u6d41\u5904\u7406\u662f\u4e00\u79cd\u6709\u6548\u7684\u4f4e\u5ef6\u8fdf\u591a\u667a\u80fd\u4f53\u63a8\u7406\u65b9\u6cd5\uff0c\u80fd\u663e\u8457\u51cf\u5c11\u54cd\u5e94\u5ef6\u8fdf\u800c\u4e0d\u727a\u7272\u8d28\u91cf\u3002"}}
