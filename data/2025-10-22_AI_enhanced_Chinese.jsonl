{"id": "2510.17948", "categories": ["cs.RO", "cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.17948", "abs": "https://arxiv.org/abs/2510.17948", "authors": ["Christopher A McClurg", "Alan R Wagner"], "title": "Studying the Effects of Robot Intervention on School Shooters in Virtual Reality", "comment": "Preprint under review for conference publication. 10 pages, 9\n  figures, 3 tables (including 1-page appendix)", "summary": "We advance the understanding of robotic intervention in high-risk scenarios\nby examining their potential to distract and impede a school shooter. To\nevaluate this concept, we conducted a virtual reality study with 150 university\nparticipants role-playing as a school shooter. Within the simulation, an\nautonomous robot predicted the shooter's movements and positioned itself\nstrategically to interfere and distract. The strategy the robot used to\napproach the shooter was manipulated -- either moving directly in front of the\nshooter (aggressive) or maintaining distance (passive) -- and the distraction\nmethod, ranging from no additional cues (low), to siren and lights (medium), to\nsiren, lights, and smoke to impair visibility (high). An aggressive,\nhigh-distraction robot reduced the number of victims by 46.6% relative to a\nno-robot control. This outcome underscores both the potential of robotic\nintervention to enhance safety and the pressing ethical questions surrounding\ntheir use in school environments.", "AI": {"tldr": "\u865a\u62df\u73b0\u5b9e\u7814\u7a76\u8868\u660e\uff0c\u81ea\u4e3b\u673a\u5668\u4eba\u901a\u8fc7\u9884\u6d4b\u6821\u56ed\u67aa\u624b\u884c\u52a8\u5e76\u8fdb\u884c\u6218\u7565\u5e72\u6270\uff0c\u53ef\u5c06\u53d7\u5bb3\u8005\u6570\u91cf\u51cf\u5c1146.6%\uff0c\u4f46\u5f15\u53d1\u6821\u56ed\u73af\u5883\u4e2d\u4f7f\u7528\u673a\u5668\u4eba\u7684\u4f26\u7406\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u673a\u5668\u4eba\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u5e72\u9884\u6821\u56ed\u67aa\u51fb\u4e8b\u4ef6\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u901a\u8fc7\u5206\u6563\u67aa\u624b\u6ce8\u610f\u529b\u6765\u51cf\u5c11\u4f24\u4ea1\u3002", "method": "\u4f7f\u7528\u865a\u62df\u73b0\u5b9e\u6a21\u62df\uff0c150\u540d\u5927\u5b66\u751f\u626e\u6f14\u6821\u56ed\u67aa\u624b\u89d2\u8272\u3002\u673a\u5668\u4eba\u9884\u6d4b\u67aa\u624b\u79fb\u52a8\u5e76\u6218\u7565\u5b9a\u4f4d\u5e72\u6270\uff0c\u6d4b\u8bd5\u4e0d\u540c\u63a5\u8fd1\u7b56\u7565\uff08\u6fc0\u8fdbvs\u88ab\u52a8\uff09\u548c\u5e72\u6270\u65b9\u6cd5\uff08\u65e0\u63d0\u793a\u3001\u8b66\u7b1b\u706f\u5149\u3001\u8b66\u7b1b\u706f\u5149\u52a0\u70df\u96fe\uff09\u3002", "result": "\u6fc0\u8fdb\u4e14\u9ad8\u5e72\u6270\u7684\u673a\u5668\u4eba\uff08\u4f7f\u7528\u8b66\u7b1b\u3001\u706f\u5149\u548c\u70df\u96fe\uff09\u76f8\u6bd4\u65e0\u673a\u5668\u4eba\u63a7\u5236\u7ec4\uff0c\u53d7\u5bb3\u8005\u6570\u91cf\u51cf\u5c11\u4e8646.6%\u3002", "conclusion": "\u673a\u5668\u4eba\u5e72\u9884\u5728\u63d0\u9ad8\u6821\u56ed\u5b89\u5168\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5f15\u53d1\u4e86\u5728\u6821\u56ed\u73af\u5883\u4e2d\u4f7f\u7528\u673a\u5668\u4eba\u7684\u7d27\u8feb\u4f26\u7406\u95ee\u9898\u3002"}}
{"id": "2510.17950", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17950", "abs": "https://arxiv.org/abs/2510.17950", "authors": ["Adina Yakefu", "Bin Xie", "Chongyang Xu", "Enwen Zhang", "Erjin Zhou", "Fan Jia", "Haitao Yang", "Haoqiang Fan", "Haowei Zhang", "Hongyang Peng", "Jing Tan", "Junwen Huang", "Kai Liu", "Kaixin Liu", "Kefan Gu", "Qinglun Zhang", "Ruitao Zhang", "Saike Huang", "Shen Cheng", "Shuaicheng Liu", "Tiancai Wang", "Tiezhen Wang", "Wei Sun", "Wenbin Tang", "Yajun Wei", "Yang Chen", "Youqiang Gui", "Yucheng Zhao", "Yunchao Ma", "Yunfei Wei", "Yunhuan Yang", "Yutong Guo", "Ze Chen", "Zhengyuan Du", "Ziheng Zhang", "Ziming Liu", "Ziwei Yan"], "title": "RoboChallenge: Large-scale Real-robot Evaluation of Embodied Policies", "comment": "Authors are listed in alphabetical order. The official website is\n  located at https://robochallenge.ai", "summary": "Testing on real machines is indispensable for robotic control algorithms. In\nthe context of learning-based algorithms, especially VLA models, demand for\nlarge-scale evaluation, i.e. testing a large number of models on a large number\nof tasks, is becoming increasingly urgent. However, doing this right is highly\nnon-trivial, especially when scalability and reproducibility is taken into\naccount. In this report, we describe our methodology for constructing\nRoboChallenge, an online evaluation system to test robotic control algorithms,\nand our survey of recent state-of-the-art VLA models using our initial\nbenchmark Table30.", "AI": {"tldr": "\u6784\u5efaRoboChallenge\u5728\u7ebf\u8bc4\u4f30\u7cfb\u7edf\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u6d4b\u8bd5\u673a\u5668\u4eba\u63a7\u5236\u7b97\u6cd5\uff0c\u7279\u522b\u662fVLA\u6a21\u578b\uff0c\u5e76\u5229\u7528\u521d\u59cb\u57fa\u51c6Table30\u5bf9\u6700\u65b0VLA\u6a21\u578b\u8fdb\u884c\u8c03\u7814\u3002", "motivation": "\u5b66\u4e60\u578b\u7b97\u6cd5\uff08\u5c24\u5176\u662fVLA\u6a21\u578b\uff09\u9700\u8981\u5927\u89c4\u6a21\u8bc4\u4f30\uff0c\u5373\u5728\u5927\u91cf\u4efb\u52a1\u4e0a\u6d4b\u8bd5\u5927\u91cf\u6a21\u578b\uff0c\u4f46\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u548c\u53ef\u590d\u73b0\u6027\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u6784\u5efaRoboChallenge\u5728\u7ebf\u8bc4\u4f30\u7cfb\u7edf\uff0c\u91c7\u7528\u521d\u59cb\u57fa\u51c6Table30\u5bf9\u6700\u65b0VLA\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u548c\u8c03\u7814\u3002", "result": "\u5f00\u53d1\u4e86\u5728\u7ebf\u8bc4\u4f30\u7cfb\u7edf\uff0c\u5e76\u5bf9\u6700\u65b0VLA\u6a21\u578b\u8fdb\u884c\u4e86\u521d\u6b65\u8c03\u7814\u3002", "conclusion": "RoboChallenge\u7cfb\u7edf\u4e3a\u673a\u5668\u4eba\u63a7\u5236\u7b97\u6cd5\u7684\u5927\u89c4\u6a21\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8VLA\u6a21\u578b\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.18002", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.18002", "abs": "https://arxiv.org/abs/2510.18002", "authors": ["Junli Ren", "Junfeng Long", "Tao Huang", "Huayi Wang", "Zirui Wang", "Feiyu Jia", "Wentao Zhang", "Jingbo Wang", "Ping Luo", "Jiangmiao Pang"], "title": "Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints", "comment": null, "summary": "We present a reinforcement learning framework for autonomous goalkeeping with\nhumanoid robots in real-world scenarios. While prior work has demonstrated\nsimilar capabilities on quadrupedal platforms, humanoid goalkeeping introduces\ntwo critical challenges: (1) generating natural, human-like whole-body motions,\nand (2) covering a wider guarding range with an equivalent response time.\nUnlike existing approaches that rely on separate teleoperation or fixed motion\ntracking for whole-body control, our method learns a single end-to-end RL\npolicy, enabling fully autonomous, highly dynamic, and human-like robot-object\ninteractions. To achieve this, we integrate multiple human motion priors\nconditioned on perceptual inputs into the RL training via an adversarial\nscheme. We demonstrate the effectiveness of our method through real-world\nexperiments, where the humanoid robot successfully performs agile, autonomous,\nand naturalistic interceptions of fast-moving balls. In addition to\ngoalkeeping, we demonstrate the generalization of our approach through tasks\nsuch as ball escaping and grabbing. Our work presents a practical and scalable\nsolution for enabling highly dynamic interactions between robots and moving\nobjects, advancing the field toward more adaptive and lifelike robotic\nbehaviors.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u4eba\u5f62\u673a\u5668\u4eba\u81ea\u4e3b\u5b88\u95e8\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u4eba\u7c7b\u8fd0\u52a8\u5148\u9a8c\u548c\u5bf9\u6297\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e86\u81ea\u7136\u3001\u52a8\u6001\u7684\u5168\u8eab\u8fd0\u52a8\u63a7\u5236\u3002", "motivation": "\u89e3\u51b3\u4eba\u5f62\u673a\u5668\u4eba\u5b88\u95e8\u9762\u4e34\u7684\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u751f\u6210\u81ea\u7136\u7684\u7c7b\u4eba\u5168\u8eab\u8fd0\u52a8\uff0c\u4ee5\u53ca\u5728\u76f8\u540c\u54cd\u5e94\u65f6\u95f4\u5185\u8986\u76d6\u66f4\u5e7f\u7684\u9632\u5b88\u8303\u56f4\u3002", "method": "\u4f7f\u7528\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u65b9\u6848\u5c06\u57fa\u4e8e\u611f\u77e5\u8f93\u5165\u7684\u591a\u4e2a\u4eba\u7c7b\u8fd0\u52a8\u5148\u9a8c\u96c6\u6210\u5230RL\u8bad\u7ec3\u4e2d\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\uff0c\u4eba\u5f62\u673a\u5668\u4eba\u6210\u529f\u5b9e\u73b0\u4e86\u654f\u6377\u3001\u81ea\u4e3b\u548c\u81ea\u7136\u7684\u5feb\u901f\u79fb\u52a8\u7403\u62e6\u622a\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u7403\u9003\u8131\u548c\u6293\u53d6\u7b49\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u4e3a\u673a\u5668\u4eba\u4e0e\u79fb\u52a8\u7269\u4f53\u4e4b\u95f4\u7684\u9ad8\u5ea6\u52a8\u6001\u4ea4\u4e92\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u81ea\u9002\u5e94\u548c\u903c\u771f\u673a\u5668\u4eba\u884c\u4e3a\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.18063", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.18063", "abs": "https://arxiv.org/abs/2510.18063", "authors": ["Bin-Bin Hu", "Weijia Yao", "Ming Cao"], "title": "MOFM-Nav: On-Manifold Ordering-Flexible Multi-Robot Navigation", "comment": null, "summary": "This paper addresses the problem of multi-robot navigation where robots\nmaneuver on a desired \\(m\\)-dimensional (i.e., \\(m\\)-D) manifold in the\n$n$-dimensional Euclidean space, and maintain a {\\it flexible spatial\nordering}. We consider $ m\\geq 2$, and the multi-robot coordination is achieved\nvia non-Euclidean metrics. However, since the $m$-D manifold can be\ncharacterized by the zero-level sets of $n$ implicit functions, the last $m$\nentries of the GVF propagation term become {\\it strongly coupled} with the\npartial derivatives of these functions if the auxiliary vectors are not\nappropriately chosen. These couplings not only influence the on-manifold\nmaneuvering of robots, but also pose significant challenges to the further\ndesign of the ordering-flexible coordination via non-Euclidean metrics.\n  To tackle this issue, we first identify a feasible solution of auxiliary\nvectors such that the last $m$ entries of the propagation term are effectively\ndecoupled to be the same constant. Then, we redesign the coordinated GVF (CGVF)\nalgorithm to {\\it boost} the advantages of singularities elimination and global\nconvergence by treating $m$ manifold parameters as additional $m$ virtual\ncoordinates. Furthermore, we enable the on-manifold ordering-flexible motion\ncoordination by allowing each robot to share $m$ virtual coordinates with its\ntime-varying neighbors and a virtual target robot, which {\\it circumvents} the\npossible complex calculation if Euclidean metrics were used instead. Finally,\nwe showcase the proposed algorithm's flexibility, adaptability, and robustness\nthrough extensive simulations with different initial positions,\nhigher-dimensional manifolds, and robot breakdown, respectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u591a\u673a\u5668\u4eba\u5728n\u7ef4\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2dm\u7ef4\u6d41\u5f62\u4e0a\u5bfc\u822a\u7684\u534f\u8c03\u5f15\u5bfc\u5411\u91cf\u573a\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u6d41\u5f62\u53c2\u6570\u5f3a\u8026\u5408\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7075\u6d3b\u7a7a\u95f4\u6392\u5e8f\u7684\u534f\u8c03\u8fd0\u52a8\u3002", "motivation": "\u89e3\u51b3\u591a\u673a\u5668\u4eba\u5728m\u7ef4\u6d41\u5f62\u4e0a\u5bfc\u822a\u65f6\uff0c\u7531\u4e8e\u6d41\u5f62\u53c2\u6570\u5f3a\u8026\u5408\u5bfc\u81f4\u7684\u534f\u8c03\u63a7\u5236\u56f0\u96be\uff0c\u7279\u522b\u662f\u5f53\u4f7f\u7528\u975e\u6b27\u51e0\u91cc\u5f97\u5ea6\u91cf\u8fdb\u884c\u7075\u6d3b\u7a7a\u95f4\u6392\u5e8f\u534f\u8c03\u65f6\u9762\u4e34\u7684\u6311\u6218\u3002", "method": "\u9996\u5148\u8bc6\u522b\u53ef\u884c\u7684\u8f85\u52a9\u5411\u91cf\u89e3\u8026\u6d41\u5f62\u53c2\u6570\uff0c\u7136\u540e\u91cd\u65b0\u8bbe\u8ba1\u534f\u8c03\u5f15\u5bfc\u5411\u91cf\u573a\u7b97\u6cd5\uff0c\u5c06m\u4e2a\u6d41\u5f62\u53c2\u6570\u4f5c\u4e3a\u865a\u62df\u5750\u6807\uff0c\u901a\u8fc7\u673a\u5668\u4eba\u4e0e\u5176\u65f6\u53d8\u90bb\u5c45\u53ca\u865a\u62df\u76ee\u6807\u673a\u5668\u4eba\u5171\u4eab\u865a\u62df\u5750\u6807\u6765\u5b9e\u73b0\u534f\u8c03\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u4eff\u771f\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u5728\u4e0d\u540c\u521d\u59cb\u4f4d\u7f6e\u3001\u9ad8\u7ef4\u6d41\u5f62\u548c\u673a\u5668\u4eba\u6545\u969c\u60c5\u51b5\u4e0b\u7684\u7075\u6d3b\u6027\u3001\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u6d41\u5f62\u53c2\u6570\u8026\u5408\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u591a\u673a\u5668\u4eba\u5728\u6d41\u5f62\u4e0a\u7684\u7075\u6d3b\u6392\u5e8f\u534f\u8c03\u5bfc\u822a\uff0c\u5177\u6709\u6d88\u9664\u5947\u70b9\u548c\u5168\u5c40\u6536\u655b\u7684\u4f18\u52bf\u3002"}}
{"id": "2510.18481", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.18481", "abs": "https://arxiv.org/abs/2510.18481", "authors": ["Ga\u00eblle Aymeric", "Emmanuelle Lavaine", "Brice Magdalou"], "title": "Parental environment and student achievement: Does a Matthew effect exist?", "comment": null, "summary": "This paper investigates the causal impact of the parental environment on the\nstudent's academic performance in mathematics, literature and English (as a\nforeign language), using a new database covering all children aged 8 to 15 of\nthe Madrid community, from 2016 to 2019. Parental environment refers here to\nthe parents' level of education (i.e. the skills they acquired before bringing\nup their children), and parental investment (the effort made by parents to\nbring up their children). We distinguish the persistent effect of the parental\nenvironment from the so-called Matthew effect, which describes a possible\ntendency for the impact of the parental environment to increase as the child\ngrows up. Whatever the subject (mathematics, literature or English), our\nresults are in line with most studies concerning the persistent effect: a\nfavourable parental environment goes hand in hand with better results for the\nchildren. As regards the Matthew effect, the results differ between subjects:\nwhile the impact of the parental environment tends to diminish from the age of\n8 to 15 in mathematics, it forms a bell curve in literature (first increasing,\nthen decreasing) and increases steadily in English. This result, which is\nencouraging for mathematics and even literature, confirms the social dimension\ninvolved in learning a foreign language compared to more academic subjects.", "AI": {"tldr": "\u7814\u7a76\u7236\u6bcd\u73af\u5883\uff08\u6559\u80b2\u6c34\u5e73\u548c\u6295\u8d44\uff09\u5bf98-15\u5c81\u5b66\u751f\u6570\u5b66\u3001\u6587\u5b66\u548c\u82f1\u8bed\u6210\u7ee9\u7684\u56e0\u679c\u5f71\u54cd\uff0c\u53d1\u73b0\u7236\u6bcd\u73af\u5883\u5bf9\u5b66\u4e1a\u6210\u7ee9\u6709\u6301\u7eed\u6b63\u9762\u5f71\u54cd\uff0c\u4f46\u9a6c\u592a\u6548\u5e94\u5728\u4e0d\u540c\u5b66\u79d1\u8868\u73b0\u4e0d\u540c\u3002", "motivation": "\u63a2\u7a76\u7236\u6bcd\u73af\u5883\u5bf9\u5b66\u751f\u5b66\u4e1a\u6210\u7ee9\u7684\u56e0\u679c\u5f71\u54cd\uff0c\u533a\u5206\u6301\u7eed\u6548\u5e94\u548c\u9a6c\u592a\u6548\u5e94\uff08\u7236\u6bcd\u73af\u5883\u5f71\u54cd\u968f\u5e74\u9f84\u589e\u957f\u7684\u53d8\u5316\uff09\u3002", "method": "\u4f7f\u75282016-2019\u5e74\u9a6c\u5fb7\u91cc\u793e\u533a8-15\u5c81\u6240\u6709\u513f\u7ae5\u7684\u65b0\u6570\u636e\u5e93\uff0c\u5206\u6790\u7236\u6bcd\u6559\u80b2\u6c34\u5e73\u548c\u6295\u8d44\u5bf9\u4e0d\u540c\u5b66\u79d1\u6210\u7ee9\u7684\u5f71\u54cd\u3002", "result": "\u7236\u6bcd\u73af\u5883\u5bf9\u6240\u6709\u5b66\u79d1\u90fd\u6709\u6301\u7eed\u6b63\u9762\u5f71\u54cd\uff1b\u9a6c\u592a\u6548\u5e94\u5728\u6570\u5b66\u4e2d\u968f\u5e74\u9f84\u51cf\u5f31\uff0c\u5728\u6587\u5b66\u4e2d\u5448\u949f\u5f62\u66f2\u7ebf\uff0c\u5728\u82f1\u8bed\u4e2d\u6301\u7eed\u589e\u5f3a\u3002", "conclusion": "\u7236\u6bcd\u73af\u5883\u5bf9\u5b66\u4e1a\u6210\u7ee9\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4f46\u9a6c\u592a\u6548\u5e94\u56e0\u5b66\u79d1\u800c\u5f02\uff0c\u5916\u8bed\u5b66\u4e60\u7684\u793e\u4f1a\u7ef4\u5ea6\u66f4\u4e3a\u7a81\u51fa\u3002"}}
{"id": "2510.18236", "categories": ["econ.TH", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2510.18236", "abs": "https://arxiv.org/abs/2510.18236", "authors": ["Mario Ghossoub", "Qinghua Ren", "Ruodu Wang"], "title": "Optimal allocations with distortion risk measures and mixed risk attitudes", "comment": "39 pages", "summary": "We study Pareto-optimal risk sharing in economies with heterogeneous\nattitudes toward risk, where agents' preferences are modeled by distortion risk\nmeasures. Building on comonotonic and counter-monotonic improvement results, we\nshow that agents with similar attitudes optimally share risks comonotonically\n(risk-averse) or counter-monotonically (risk-seeking). We show how the general\n$n$-agent problem can be reduced to a two-agent formulation between\nrepresentative risk-averse and risk-seeking agents, characterized by the\ninfimal convolution of their distortion risk measures. Within this two-agent\nframework, we establish necessary and sufficient conditions for the existence\nof optimal allocations, and we identify when the infimal convolution yields an\nunbounded value. When existence fails, we analyze the problem under nonnegative\nallocation constraints, and we characterize optima explicitly, under\npiecewise-linear distortion functions and Bernoulli-type risks. Our findings\nsuggest that the optimal allocation structure is governed by the relative\nstrength of risk aversion versus risk seeking behavior, as intuition would\nsuggest.", "AI": {"tldr": "\u7814\u7a76\u5177\u6709\u5f02\u8d28\u98ce\u9669\u6001\u5ea6\u7684\u7ecf\u6d4e\u4f53\u4e2d\u5e15\u7d2f\u6258\u6700\u4f18\u98ce\u9669\u5206\u62c5\u95ee\u9898\uff0c\u4f7f\u7528\u5931\u771f\u98ce\u9669\u5ea6\u91cf\u5efa\u6a21\u504f\u597d\uff0c\u53d1\u73b0\u76f8\u4f3c\u98ce\u9669\u6001\u5ea6\u7684\u4ee3\u7406\u4eba\u6700\u4f18\u98ce\u9669\u5206\u62c5\u65b9\u5f0f\u4e0d\u540c\uff08\u98ce\u9669\u538c\u6076\u8005\u540c\u5355\u8c03\uff0c\u98ce\u9669\u5bfb\u6c42\u8005\u53cd\u5355\u8c03\uff09\u3002", "motivation": "\u7814\u7a76\u5728\u4ee3\u7406\u4eba\u5177\u6709\u4e0d\u540c\u98ce\u9669\u6001\u5ea6\uff08\u98ce\u9669\u538c\u6076\u548c\u98ce\u9669\u5bfb\u6c42\uff09\u7684\u7ecf\u6d4e\u4f53\u4e2d\uff0c\u5982\u4f55\u5b9e\u73b0\u5e15\u7d2f\u6258\u6700\u4f18\u7684\u98ce\u9669\u5206\u62c5\uff0c\u63a2\u7d22\u5f02\u8d28\u98ce\u9669\u504f\u597d\u4e0b\u7684\u6700\u4f18\u5206\u914d\u7ed3\u6784\u3002", "method": "\u57fa\u4e8e\u540c\u5355\u8c03\u548c\u53cd\u5355\u8c03\u6539\u8fdb\u7ed3\u679c\uff0c\u5c06n\u4e2a\u4ee3\u7406\u4eba\u95ee\u9898\u7b80\u5316\u4e3a\u4ee3\u8868\u6027\u98ce\u9669\u538c\u6076\u548c\u98ce\u9669\u5bfb\u6c42\u4ee3\u7406\u4eba\u4e4b\u95f4\u7684\u4e24\u4ee3\u7406\u4eba\u95ee\u9898\uff0c\u4f7f\u7528\u5931\u771f\u98ce\u9669\u5ea6\u91cf\u7684\u4e0b\u5377\u79ef\u8fdb\u884c\u8868\u5f81\u3002", "result": "\u5efa\u7acb\u4e86\u6700\u4f18\u5206\u914d\u5b58\u5728\u7684\u5145\u8981\u6761\u4ef6\uff0c\u8bc6\u522b\u4e86\u4e0b\u5377\u79ef\u4ea7\u751f\u65e0\u754c\u503c\u7684\u60c5\u51b5\u3002\u5f53\u5b58\u5728\u6027\u5931\u8d25\u65f6\uff0c\u5728\u975e\u8d1f\u5206\u914d\u7ea6\u675f\u4e0b\u5206\u6790\u95ee\u9898\uff0c\u5e76\u5728\u5206\u6bb5\u7ebf\u6027\u5931\u771f\u51fd\u6570\u548c\u4f2f\u52aa\u5229\u578b\u98ce\u9669\u4e0b\u663e\u5f0f\u523b\u753b\u6700\u4f18\u89e3\u3002", "conclusion": "\u6700\u4f18\u5206\u914d\u7ed3\u6784\u7531\u98ce\u9669\u538c\u6076\u4e0e\u98ce\u9669\u5bfb\u6c42\u884c\u4e3a\u7684\u76f8\u5bf9\u5f3a\u5ea6\u51b3\u5b9a\uff0c\u8fd9\u4e0e\u76f4\u89c9\u76f8\u7b26\uff0c\u63ed\u793a\u4e86\u5f02\u8d28\u98ce\u9669\u6001\u5ea6\u4e0b\u98ce\u9669\u5206\u62c5\u7684\u57fa\u672c\u89c4\u5f8b\u3002"}}
{"id": "2510.17882", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.DL"], "pdf": "https://arxiv.org/pdf/2510.17882", "abs": "https://arxiv.org/abs/2510.17882", "authors": ["Minfeng Qi", "Zhongmin Cao", "Qin Wang", "Ningran Li", "Tianqing Zhu"], "title": "Does GenAI Rewrite How We Write? An Empirical Study on Two-Million Preprints", "comment": null, "summary": "Preprint repositories become central infrastructures for scholarly\ncommunication. Their expansion transforms how research is circulated and\nevaluated before journal publication. Generative large language models (LLMs)\nintroduce a further potential disruption by altering how manuscripts are\nwritten. While speculation abounds, systematic evidence of whether and how LLMs\nreshape scientific publishing remains limited.\n  This paper addresses the gap through a large-scale analysis of more than 2.1\nmillion preprints spanning 2016--2025 (115 months) across four major\nrepositories (i.e., arXiv, bioRxiv, medRxiv, SocArXiv). We introduce a\nmulti-level analytical framework that integrates interrupted time-series\nmodels, collaboration and productivity metrics, linguistic profiling, and topic\nmodeling to assess changes in volume, authorship, style, and disciplinary\norientation. Our findings reveal that LLMs have accelerated submission and\nrevision cycles, modestly increased linguistic complexity, and\ndisproportionately expanded AI-related topics, while computationally intensive\nfields benefit more than others. These results show that LLMs act less as\nuniversal disruptors than as selective catalysts, amplifying existing strengths\nand widening disciplinary divides. By documenting these dynamics, the paper\nprovides the first empirical foundation for evaluating the influence of\ngenerative AI on academic publishing and highlights the need for governance\nframeworks that preserve trust, fairness, and accountability in an AI-enabled\nresearch ecosystem.", "AI": {"tldr": "\u901a\u8fc7\u5bf9210\u4e07\u7bc7\u9884\u5370\u672c\u7684\u5206\u6790\u53d1\u73b0\uff0cLLMs\u52a0\u901f\u4e86\u63d0\u4ea4\u548c\u4fee\u8ba2\u5468\u671f\uff0c\u7565\u5fae\u589e\u52a0\u4e86\u8bed\u8a00\u590d\u6742\u6027\uff0c\u4e0d\u6210\u6bd4\u4f8b\u5730\u6269\u5c55\u4e86AI\u76f8\u5173\u4e3b\u9898\uff0c\u8ba1\u7b97\u5bc6\u96c6\u578b\u9886\u57df\u53d7\u76ca\u66f4\u591a\u3002LLMs\u66f4\u591a\u662f\u9009\u62e9\u6027\u50ac\u5316\u5242\u800c\u975e\u666e\u904d\u98a0\u8986\u8005\u3002", "motivation": "\u9884\u5370\u672c\u5e93\u5df2\u6210\u4e3a\u5b66\u672f\u4ea4\u6d41\u6838\u5fc3\u57fa\u7840\u8bbe\u65bd\uff0cLLMs\u53ef\u80fd\u6539\u53d8\u8bba\u6587\u5199\u4f5c\u65b9\u5f0f\uff0c\u4f46\u7cfb\u7edf\u6027\u7684\u5b9e\u8bc1\u8bc1\u636e\u6709\u9650\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u4f7f\u7528\u591a\u7ea7\u5206\u6790\u6846\u67b6\uff0c\u6574\u5408\u4e2d\u65ad\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u3001\u5408\u4f5c\u4e0e\u751f\u4ea7\u529b\u6307\u6807\u3001\u8bed\u8a00\u5206\u6790\u548c\u4e3b\u9898\u5efa\u6a21\uff0c\u5206\u67902016-2025\u5e74\u56db\u4e2a\u4e3b\u8981\u9884\u5370\u672c\u5e93\u7684210\u4e07\u7bc7\u8bba\u6587\u3002", "result": "LLMs\u52a0\u901f\u4e86\u63d0\u4ea4\u548c\u4fee\u8ba2\u5468\u671f\uff0c\u7565\u5fae\u589e\u52a0\u4e86\u8bed\u8a00\u590d\u6742\u6027\uff0cAI\u76f8\u5173\u4e3b\u9898\u663e\u8457\u6269\u5c55\uff0c\u8ba1\u7b97\u5bc6\u96c6\u578b\u9886\u57df\u53d7\u76ca\u66f4\u591a\u3002", "conclusion": "LLMs\u66f4\u591a\u662f\u9009\u62e9\u6027\u50ac\u5316\u5242\u800c\u975e\u666e\u904d\u98a0\u8986\u8005\uff0c\u653e\u5927\u73b0\u6709\u4f18\u52bf\u5e76\u6269\u5927\u5b66\u79d1\u9e3f\u6c9f\uff0c\u9700\u8981\u5efa\u7acb\u4fdd\u62a4\u4fe1\u4efb\u3001\u516c\u5e73\u548c\u95ee\u8d23\u7684\u6cbb\u7406\u6846\u67b6\u3002"}}
{"id": "2510.17814", "categories": ["eess.SY", "cs.AI", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.17814", "abs": "https://arxiv.org/abs/2510.17814", "authors": ["Qun Wang", "Yingzhou Lu", "Guiran Liu", "Binrong Zhu", "Yang Liu"], "title": "LLM Assisted Alpha Fairness for 6 GHz WiFi and NR_U Coexistence: An Agentic Orchestrator for Throughput, Energy, and SLA", "comment": null, "summary": "Unlicensed 6GHz is becoming a primary workhorse for high-capacity access,\nwith Wi-Fi and 5G NR-U competing for the same channels under listen-before-talk\n(LBT) rules. Operating in this regime requires decisions that jointly trade\nthroughput, energy, and service-level objectives while remaining safe and\nauditable. We present an agentic controller that separates {policy} from\n{execution}. At the start of each scheduling epoch the agent summarizes\ntelemetry (per-channel busy and baseline LBT failure; per-user CQI, backlog,\nlatency, battery, priority, and power mode) and invokes a large language model\n(LLM) to propose a small set of interpretable knobs: a fairness index \\alpha,\nper-channel duty-cycle caps for Wi-Fi/NR-U, and class weights. A deterministic\noptimizer then enforces feasibility and computes an \\alpha-fair allocation that\ninternalizes LBT losses and energy cost; malformed or unsafe policies are\nclamped and fall back to a rule baseline. In a 6GHz simulator with two 160MHz\nchannels and mixed Wi-Fi/NR-U users, LLM-assisted policies consistently improve\nenergy efficiency while keeping throughput competitive with a strong rule\nbaseline. One LLM lowers total energy by 35.3% at modest throughput loss, and\nanother attains the best overall trade-off, finishing with higher total bits\n(+3.5%) and higher bits/J (+12.2%) than the baseline. We release code,\nper-epoch logs, and plotting utilities to reproduce all figures and numbers,\nillustrating how transparent, policy-level LLM guidance can safely improve\nwireless coexistence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u667a\u80fd\u63a7\u5236\u5668\uff0c\u7528\u4e8e6GHz\u9891\u6bb5Wi-Fi\u548c5G NR-U\u7684\u5171\u5b58\u7ba1\u7406\uff0c\u901a\u8fc7\u5206\u79bb\u7b56\u7565\u5236\u5b9a\u548c\u6267\u884c\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\u63d0\u5347\u80fd\u6548\u3002", "motivation": "\u89e3\u51b36GHz\u514d\u6388\u6743\u9891\u6bb5\u4e2dWi-Fi\u548c5G NR-U\u5728LBT\u89c4\u5219\u4e0b\u7684\u5171\u5b58\u95ee\u9898\uff0c\u9700\u8981\u5e73\u8861\u541e\u5410\u91cf\u3001\u80fd\u8017\u548c\u670d\u52a1\u8d28\u91cf\uff0c\u540c\u65f6\u786e\u4fdd\u7cfb\u7edf\u5b89\u5168\u548c\u53ef\u5ba1\u8ba1\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4ee3\u7406\u63a7\u5236\u5668\uff0c\u5728\u6bcf\u4e2a\u8c03\u5ea6\u5468\u671f\u5f00\u59cb\u65f6\u6536\u96c6\u9065\u6d4b\u6570\u636e\uff0c\u4f7f\u7528LLM\u751f\u6210\u53ef\u89e3\u91ca\u7684\u63a7\u5236\u53c2\u6570\uff08\u516c\u5e73\u6027\u6307\u6570\u3001\u4fe1\u9053\u5360\u7a7a\u6bd4\u9650\u5236\u7b49\uff09\uff0c\u7136\u540e\u901a\u8fc7\u786e\u5b9a\u6027\u4f18\u5316\u5668\u8ba1\u7b97\u53ef\u884c\u7684\u03b1-\u516c\u5e73\u5206\u914d\u3002", "result": "\u57286GHz\u4eff\u771f\u73af\u5883\u4e2d\uff0cLLM\u8f85\u52a9\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u80fd\u6548\uff0c\u4e00\u4e2aLLM\u6a21\u578b\u5728\u9002\u5ea6\u541e\u5410\u91cf\u635f\u5931\u4e0b\u964d\u4f4e\u4e8635.3%\u7684\u603b\u80fd\u8017\uff0c\u53e6\u4e00\u4e2a\u6a21\u578b\u5b9e\u73b0\u4e86\u6700\u4f73\u7efc\u5408\u6743\u8861\uff0c\u541e\u5410\u91cf\u63d0\u53473.5%\uff0c\u80fd\u6548\u63d0\u534712.2%\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u900f\u660e\u3001\u7b56\u7565\u7ea7\u7684LLM\u6307\u5bfc\u53ef\u4ee5\u5b89\u5168\u5730\u6539\u8fdb\u65e0\u7ebf\u5171\u5b58\u6027\u80fd\uff0c\u4e3a6GHz\u9891\u6bb5\u7684\u591a\u6280\u672f\u5171\u5b58\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.18252", "categories": ["stat.AP", "cs.AI", "cs.LG", "62H30", "I.2.6"], "pdf": "https://arxiv.org/pdf/2510.18252", "abs": "https://arxiv.org/abs/2510.18252", "authors": ["Luis H. Chia"], "title": "Finding the Sweet Spot: Optimal Data Augmentation Ratio for Imbalanced Credit Scoring Using ADASYN", "comment": "25 pages, 3 figures, 6 tables", "summary": "Credit scoring models face a critical challenge: severe class imbalance, with\ndefault rates typically below 10%, which hampers model learning and predictive\nperformance. While synthetic data augmentation techniques such as SMOTE and\nADASYN have been proposed to address this issue, the optimal augmentation ratio\nremains unclear, with practitioners often defaulting to full balancing (1:1\nratio) without empirical justification.\n  This study systematically evaluates 10 data augmentation scenarios using the\nGive Me Some Credit dataset (97,243 observations, 7% default rate), comparing\nSMOTE, BorderlineSMOTE, and ADASYN at different multiplication factors (1x, 2x,\n3x). All models were trained using XGBoost and evaluated on a held-out test set\nof 29,173 real observations. Statistical significance was assessed using\nbootstrap testing with 1,000 iterations.\n  Key findings reveal that ADASYN with 1x multiplication (doubling the minority\nclass) achieved optimal performance with AUC of 0.6778 and Gini coefficient of\n0.3557, representing statistically significant improvements of +0.77% and\n+3.00% respectively (p = 0.017, bootstrap test). Higher multiplication factors\n(2x and 3x) resulted in performance degradation, with 3x showing a -0.48%\ndecrease in AUC, suggesting a \"law of diminishing returns\" for synthetic\noversampling. The optimal class imbalance ratio was found to be 6.6:1\n(majority:minority), contradicting the common practice of balancing to 1:1.\n  This work provides the first empirical evidence of an optimal \"sweet spot\"\nfor data augmentation in credit scoring, with practical guidelines for industry\npractitioners and researchers working with imbalanced datasets. While\ndemonstrated on a single representative dataset, the methodology provides a\nreproducible framework for determining optimal augmentation ratios in other\nimbalanced domains.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4fe1\u7528\u8bc4\u5206\u4e2d\u6570\u636e\u589e\u5f3a\u7684\u6700\u4f73\u6bd4\u4f8b\uff0c\u53d1\u73b0ADASYN\u65b9\u6cd5\u4ee51\u500d\u4e58\u6570\uff08\u5c11\u6570\u7c7b\u7ffb\u500d\uff09\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff0c\u6700\u4f73\u7c7b\u522b\u4e0d\u5e73\u8861\u6bd4\u4f8b\u4e3a6.6:1\uff0c\u800c\u975e\u5e38\u7528\u76841:1\u5e73\u8861\u3002", "motivation": "\u4fe1\u7528\u8bc4\u5206\u6a21\u578b\u9762\u4e34\u4e25\u91cd\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff08\u8fdd\u7ea6\u7387\u901a\u5e38\u4f4e\u4e8e10%\uff09\uff0c\u73b0\u6709SMOTE\u548cADASYN\u7b49\u6570\u636e\u589e\u5f3a\u6280\u672f\u7f3a\u4e4f\u5bf9\u6700\u4f73\u589e\u5f3a\u6bd4\u4f8b\u7684\u7ecf\u9a8c\u4f9d\u636e\uff0c\u4ece\u4e1a\u8005\u901a\u5e38\u9ed8\u8ba4\u4f7f\u75281:1\u5e73\u8861\u6bd4\u4f8b\u3002", "method": "\u4f7f\u7528Give Me Some Credit\u6570\u636e\u96c6\uff0897,243\u4e2a\u89c2\u6d4b\u503c\uff0c7%\u8fdd\u7ea6\u7387\uff09\uff0c\u7cfb\u7edf\u8bc4\u4f3010\u79cd\u6570\u636e\u589e\u5f3a\u573a\u666f\uff0c\u6bd4\u8f83SMOTE\u3001BorderlineSMOTE\u548cADASYN\u5728\u4e0d\u540c\u4e58\u6570\uff081x\u30012x\u30013x\uff09\u4e0b\u7684\u8868\u73b0\uff0c\u4f7f\u7528XGBoost\u8bad\u7ec3\u6a21\u578b\u5e76\u572829,173\u4e2a\u771f\u5b9e\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\uff0c\u901a\u8fc71,000\u6b21bootstrap\u6d4b\u8bd5\u8bc4\u4f30\u7edf\u8ba1\u663e\u8457\u6027\u3002", "result": "ADASYN 1x\u589e\u5f3a\uff08\u5c11\u6570\u7c7b\u7ffb\u500d\uff09\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff0cAUC\u4e3a0.6778\uff0cGini\u7cfb\u6570\u4e3a0.3557\uff0c\u76f8\u6bd4\u57fa\u7ebf\u5206\u522b\u663e\u8457\u63d0\u53470.77%\u548c3.00%\u3002\u66f4\u9ad8\u7684\u4e58\u6570\uff082x\u548c3x\uff09\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c3x\u65f6AUC\u4e0b\u964d0.48%\u3002\u6700\u4f73\u7c7b\u522b\u4e0d\u5e73\u8861\u6bd4\u4f8b\u4e3a6.6:1\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u4e3a\u4fe1\u7528\u8bc4\u5206\u4e2d\u7684\u6570\u636e\u589e\u5f3a\u63d0\u4f9b\u4e86\u6700\u4f73\"\u751c\u70b9\"\u7684\u7ecf\u9a8c\u8bc1\u636e\uff0c\u63a8\u7ffb\u4e86\u5e38\u7528\u76841:1\u5e73\u8861\u5b9e\u8df5\uff0c\u4e3a\u884c\u4e1a\u4ece\u4e1a\u8005\u548c\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u5904\u7406\u6307\u5357\u3002"}}
{"id": "2510.18170", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.SE", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.18170", "abs": "https://arxiv.org/abs/2510.18170", "authors": ["Manik Rana", "Calissa Man", "Anotida Expected Msiiwa", "Jeffrey Paine", "Kevin Zhu", "Sunishchal Dev", "Vasu Sharma", "Ahan M R"], "title": "AgentChangeBench: A Multi-Dimensional Evaluation Framework for Goal-Shift Robustness in Conversational AI", "comment": "Accepted to 39th Conference on Neural Information Processing Systems\n  (NeurIPS 2025) Workshop: Multi-Turn Interactions in Large Language Models", "summary": "Goal changes are a defining feature of real world multi-turn interactions,\nyet current agent benchmarks primarily evaluate static objectives or one-shot\ntool use. We introduce AgentChangeBench, a benchmark explicitly designed to\nmeasure how tool augmented language model agents adapt to mid dialogue goal\nshifts across three enterprise domains. Our framework formalizes evaluation\nthrough four complementary metrics: Task Success Rate (TSR) for effectiveness,\nTool Use Efficiency (TUE) for reliability, Tool Call Redundancy Rate (TCRR) for\nwasted effort, and Goal-Shift Recovery Time (GSRT) for adaptation latency.\nAgentChangeBench comprises 2,835 task sequences and five user personas, each\ndesigned to trigger realistic shift points in ongoing workflows. Using this\nsetup, we evaluate several frontier models and uncover sharp contrasts obscured\nby traditional $\\text{pass}@k$ scores: for example, GPT-4o reaches $92.2\\%$\nrecovery on airline booking shifts while Gemini collapses to $48.6\\%$, and\nretail tasks show near perfect parameter validity yet redundancy rates above\n$80\\%$, revealing major inefficiencies. These findings demonstrate that high\nraw accuracy does not imply robustness under dynamic goals, and that explicit\nmeasurement of recovery time and redundancy is essential. AgentChangeBench\nestablishes a reproducible testbed for diagnosing and improving agent\nresilience in realistic enterprise settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86AgentChangeBench\u57fa\u51c6\uff0c\u4e13\u95e8\u8bc4\u4f30\u5de5\u5177\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u5bf9\u8bdd\u4e2d\u76ee\u6807\u53d8\u5316\u65f6\u7684\u9002\u5e94\u80fd\u529b\uff0c\u5305\u542b\u56db\u4e2a\u4e92\u8865\u6307\u6807\u6765\u8861\u91cf\u6548\u679c\u3001\u53ef\u9760\u6027\u3001\u6548\u7387\u548c\u9002\u5e94\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u591a\u8f6e\u4ea4\u4e92\u4e2d\u76ee\u6807\u53d8\u5316\u662f\u5e38\u89c1\u7279\u5f81\uff0c\u4f46\u73b0\u6709\u4ee3\u7406\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u9759\u6001\u76ee\u6807\u6216\u4e00\u6b21\u6027\u5de5\u5177\u4f7f\u7528\uff0c\u7f3a\u4e4f\u5bf9\u52a8\u6001\u76ee\u6807\u9002\u5e94\u80fd\u529b\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b2,835\u4e2a\u4efb\u52a1\u5e8f\u5217\u548c\u4e94\u4e2a\u7528\u6237\u89d2\u8272\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u5728\u4e09\u4e2a\u4f01\u4e1a\u9886\u57df\uff08\u5982\u822a\u7a7a\u9884\u8ba2\u3001\u96f6\u552e\u7b49\uff09\u4e2d\u89e6\u53d1\u73b0\u5b9e\u7684\u5de5\u4f5c\u6d41\u7a0b\u53d8\u5316\u70b9\uff0c\u901a\u8fc7\u56db\u4e2a\u6307\u6807\u8fdb\u884c\u5f62\u5f0f\u5316\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u53d1\u73b0\u524d\u6cbf\u6a21\u578b\u5728\u76ee\u6807\u53d8\u5316\u9002\u5e94\u80fd\u529b\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1aGPT-4o\u5728\u822a\u7a7a\u9884\u8ba2\u53d8\u5316\u4e2d\u8fbe\u523092.2%\u6062\u590d\u7387\uff0c\u800cGemini\u964d\u81f348.6%\uff1b\u96f6\u552e\u4efb\u52a1\u53c2\u6570\u6709\u6548\u6027\u63a5\u8fd1\u5b8c\u7f8e\u4f46\u5197\u4f59\u7387\u8d85\u8fc780%\uff0c\u63ed\u793a\u4e86\u4e3b\u8981\u6548\u7387\u95ee\u9898\u3002", "conclusion": "\u9ad8\u539f\u59cb\u51c6\u786e\u7387\u5e76\u4e0d\u4ee3\u8868\u5728\u52a8\u6001\u76ee\u6807\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u660e\u786e\u6d4b\u91cf\u6062\u590d\u65f6\u95f4\u548c\u5197\u4f59\u5ea6\u5bf9\u4e8e\u8bc4\u4f30\u4ee3\u7406\u5728\u73b0\u5b9e\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u97e7\u6027\u81f3\u5173\u91cd\u8981\uff0cAgentChangeBench\u4e3a\u8bca\u65ad\u548c\u6539\u8fdb\u4ee3\u7406\u97e7\u6027\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2510.17902", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17902", "abs": "https://arxiv.org/abs/2510.17902", "authors": ["Al Kari"], "title": "Activation Manifold Projection: Liberating Task-Specific Behaviors from LLM Architectures", "comment": null, "summary": "The proliferation of Large Language Model (LLM) architectures presents a\nfundamental challenge: valuable, task-specific behaviors learned through\nfine-tuning methods like Low-Rank Adaptation (LoRA) are effectively trapped\nwithin their source model's architecture, herein referred to architectural\nlock-in. Existing transfer methods attempt to bridge this gap by aligning the\nstatic weight spaces of models, a brittle and indirect approach that relies on\ntenuous correlations between parameter geometries. This paper introduces a\nfundamentally different and more direct paradigm: the Cartridge Activation\nSpace Transfer (CAST), a novel framework that liberates LoRA-encoded behaviors\nby learning a direct, nonlinear mapping between the activation manifolds, the\ngeometric structures formed by the model's internal neuron activations, of two\ndistinct LLM architectures. CAST treats a pre-trained LoRA as a frozen\n\"behavioral kernel.\" It learns a set of lightweight, bidirectional projection\nheads that translate the target model's activation stream into the source\nmodel's latent space, apply the frozen kernel, and project the result back.\nThis process, trained on a general text corpus without any task-specific data,\neffectively decouples the learned skill from the source architecture. We\ndemonstrate that CAST enables true \"zero-shot\" translation of any standard LoRA\nadapter. Our experiments, including transfers between heterogeneous model\nfamilies like Llama-2 and Mistral, show that CAST-translated adapters achieve\n85-95\\% of the performance of a LoRA fully retrained on the target model,\nquantitatively outperforming current weight-space transfer techniques and\nestablishing a new state-of-the-art in model interoperability.", "AI": {"tldr": "CAST\u6846\u67b6\u901a\u8fc7\u5728\u5b66\u4e60\u6fc0\u6d3b\u6d41\u5f62\u4e4b\u95f4\u5efa\u7acb\u975e\u7ebf\u6027\u6620\u5c04\uff0c\u5b9e\u73b0\u4e86LoRA\u9002\u914d\u5668\u5728\u4e0d\u540cLLM\u67b6\u6784\u95f4\u7684\u96f6\u6837\u672c\u8fc1\u79fb\uff0c\u89e3\u51b3\u4e86\u67b6\u6784\u9501\u5b9a\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5fae\u8c03\u65b9\u6cd5\uff08\u5982LoRA\uff09\u5bfc\u81f4\u5b66\u5230\u7684\u4efb\u52a1\u7279\u5b9a\u884c\u4e3a\u88ab\u9501\u5b9a\u5728\u6e90\u6a21\u578b\u67b6\u6784\u4e2d\uff0c\u73b0\u6709\u8fc1\u79fb\u65b9\u6cd5\u901a\u8fc7\u5bf9\u9f50\u6743\u91cd\u7a7a\u95f4\uff0c\u8fd9\u79cd\u65b9\u6cd5\u8106\u5f31\u4e14\u95f4\u63a5\u3002", "method": "CAST\u6846\u67b6\u5c06\u9884\u8bad\u7ec3\u7684LoRA\u89c6\u4e3a\u51bb\u7ed3\u7684\"\u884c\u4e3a\u5185\u6838\"\uff0c\u5b66\u4e60\u8f7b\u91cf\u7ea7\u53cc\u5411\u6295\u5f71\u5934\uff0c\u5728\u76ee\u6807\u6a21\u578b\u7684\u6fc0\u6d3b\u6d41\u548c\u6e90\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\u4e4b\u95f4\u8fdb\u884c\u8f6c\u6362\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u6570\u636e\u3002", "result": "\u5728Llama-2\u548cMistral\u7b49\u5f02\u6784\u6a21\u578b\u5bb6\u65cf\u95f4\u7684\u8fc1\u79fb\u5b9e\u9a8c\u4e2d\uff0cCAST\u8f6c\u6362\u7684\u9002\u914d\u5668\u6027\u80fd\u8fbe\u5230\u5728\u76ee\u6807\u6a21\u578b\u4e0a\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3LoRA\u768485-95%\uff0c\u4f18\u4e8e\u5f53\u524d\u6743\u91cd\u7a7a\u95f4\u8fc1\u79fb\u6280\u672f\u3002", "conclusion": "CAST\u5efa\u7acb\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u4e92\u64cd\u4f5c\u6027\u6807\u51c6\uff0c\u80fd\u591f\u771f\u6b63\u5b9e\u73b0\u6807\u51c6LoRA\u9002\u914d\u5668\u7684\u96f6\u6837\u672c\u8fc1\u79fb\uff0c\u6709\u6548\u5c06\u5b66\u4e60\u6280\u80fd\u4e0e\u6e90\u67b6\u6784\u89e3\u8026\u3002"}}
{"id": "2510.18280", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.18280", "abs": "https://arxiv.org/abs/2510.18280", "authors": ["Yongren Shi", "Edo Airoldi", "Nicholas A. Christakis"], "title": "Multiplex Networks Provide Structural Pathways for Social Contagion in Rural Social Networks", "comment": null, "summary": "Human social networks are inherently multiplex, comprising overlapping layers\nof relationships. Different layers may have distinct structural properties and\ninterpersonal dynamics, but also may interact to form complex interdependent\npathways for social contagion. This poses a fundamental problem in\nunderstanding behavioral diffusion and in devising effective network-based\ninterventions. Here, we introduce a new conceptualization of how much each\nnetwork layer contributes to critical contagion pathways and quantify it using\na novel metric, network torque. We exploit data regarding sociocentric maps of\n110 rural Honduran communities using a battery of 11 name generators and an\nexperiment involving an exogenous intervention. Using a novel statistical\nframework, we assess the extent to which specific network layers alter global\nconnectivity and support the spread of three experimentally introduced health\npractices. The results show that specific relationship types - such as close\nfriendships - particularly enable non-overlapping diffusion pathways,\namplifying behavioral change at the village level. For instance, non-redundant\npathways enabled by closest friends can increase the adoption of correct\nknowledge about feeding newborns inappropriate chupones and enhance attitudes\nregarding fathers' involvement in postpartum care. Non-overlapping multiplex\nsocial ties are relevant to social contagion and social coherence in\ntraditionally organized social systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f51\u7edc\u626d\u77e9\u6307\u6807\uff0c\u7528\u4e8e\u91cf\u5316\u591a\u5c42\u793e\u4ea4\u7f51\u7edc\u4e2d\u4e0d\u540c\u5173\u7cfb\u5c42\u5bf9\u5173\u952e\u4f20\u64ad\u8def\u5f84\u7684\u8d21\u732e\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7279\u5b9a\u5173\u7cfb\u7c7b\u578b\uff08\u5982\u4eb2\u5bc6\u53cb\u8c0a\uff09\u5728\u4fc3\u8fdb\u5065\u5eb7\u884c\u4e3a\u4f20\u64ad\u4e2d\u7684\u91cd\u8981\u4f5c\u7528\u3002", "motivation": "\u4eba\u7c7b\u793e\u4ea4\u7f51\u7edc\u672c\u8d28\u4e0a\u662f\u591a\u5c42\u7684\uff0c\u5305\u542b\u91cd\u53e0\u7684\u5173\u7cfb\u5c42\u3002\u4e0d\u540c\u5c42\u53ef\u80fd\u5177\u6709\u4e0d\u540c\u7684\u7ed3\u6784\u7279\u6027\u548c\u4eba\u9645\u52a8\u6001\uff0c\u5e76\u53ef\u80fd\u76f8\u4e92\u4f5c\u7528\u5f62\u6210\u590d\u6742\u7684\u76f8\u4e92\u4f9d\u8d56\u7684\u793e\u4f1a\u4f20\u64ad\u8def\u5f84\u3002\u8fd9\u7ed9\u7406\u89e3\u884c\u4e3a\u6269\u6563\u548c\u8bbe\u8ba1\u6709\u6548\u7684\u57fa\u4e8e\u7f51\u7edc\u7684\u5e72\u9884\u63aa\u65bd\u5e26\u6765\u4e86\u6839\u672c\u6027\u95ee\u9898\u3002", "method": "\u4f7f\u7528110\u4e2a\u6d2a\u90fd\u62c9\u65af\u519c\u6751\u793e\u533a\u7684\u793e\u4ea4\u7f51\u7edc\u6570\u636e\uff0c\u5305\u542b11\u79cd\u540d\u79f0\u751f\u6210\u5668\uff0c\u5e76\u8fdb\u884c\u4e86\u5916\u751f\u5e72\u9884\u5b9e\u9a8c\u3002\u91c7\u7528\u65b0\u7684\u7edf\u8ba1\u6846\u67b6\u8bc4\u4f30\u7279\u5b9a\u7f51\u7edc\u5c42\u5982\u4f55\u6539\u53d8\u5168\u5c40\u8fde\u901a\u6027\u5e76\u652f\u6301\u4e09\u79cd\u5b9e\u9a8c\u5f15\u5165\u7684\u5065\u5eb7\u5b9e\u8df5\u4f20\u64ad\u3002", "result": "\u7ed3\u679c\u663e\u793a\u7279\u5b9a\u5173\u7cfb\u7c7b\u578b\uff08\u5982\u4eb2\u5bc6\u53cb\u8c0a\uff09\u7279\u522b\u80fd\u591f\u5b9e\u73b0\u975e\u91cd\u53e0\u7684\u4f20\u64ad\u8def\u5f84\uff0c\u5728\u6751\u5e84\u5c42\u9762\u653e\u5927\u4e86\u884c\u4e3a\u6539\u53d8\u3002\u4f8b\u5982\uff0c\u7531\u6700\u4eb2\u5bc6\u670b\u53cb\u652f\u6301\u7684\u975e\u5197\u4f59\u8def\u5f84\u53ef\u4ee5\u589e\u52a0\u5bf9\u65b0\u751f\u513f\u5582\u517b\u4e0d\u5f53\u77e5\u8bc6\u7684\u6b63\u786e\u8ba4\u77e5\uff0c\u5e76\u589e\u5f3a\u5bf9\u7236\u4eb2\u53c2\u4e0e\u4ea7\u540e\u62a4\u7406\u7684\u6001\u5ea6\u3002", "conclusion": "\u975e\u91cd\u53e0\u7684\u591a\u5c42\u793e\u4ea4\u8054\u7cfb\u5728\u4f20\u7edf\u7ec4\u7ec7\u7684\u793e\u4f1a\u7cfb\u7edf\u4e2d\u4e0e\u793e\u4f1a\u4f20\u64ad\u548c\u793e\u4f1a\u51dd\u805a\u529b\u76f8\u5173\uff0c\u7279\u5b9a\u5173\u7cfb\u7c7b\u578b\u5728\u4fc3\u8fdb\u5065\u5eb7\u884c\u4e3a\u4f20\u64ad\u4e2d\u53d1\u6325\u7740\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2510.18085", "categories": ["cs.RO", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.18085", "abs": "https://arxiv.org/abs/2510.18085", "authors": ["Connor Mattson", "Varun Raveendra", "Ellen Novoseller", "Nicholas Waytowich", "Vernon J. Lawhern", "Daniel S. Brown"], "title": "R2BC: Multi-Agent Imitation Learning from Single-Agent Demonstrations", "comment": "9 pages, 6 figures", "summary": "Imitation Learning (IL) is a natural way for humans to teach robots,\nparticularly when high-quality demonstrations are easy to obtain. While IL has\nbeen widely applied to single-robot settings, relatively few studies have\naddressed the extension of these methods to multi-agent systems, especially in\nsettings where a single human must provide demonstrations to a team of\ncollaborating robots. In this paper, we introduce and study Round-Robin\nBehavior Cloning (R2BC), a method that enables a single human operator to\neffectively train multi-robot systems through sequential, single-agent\ndemonstrations. Our approach allows the human to teleoperate one agent at a\ntime and incrementally teach multi-agent behavior to the entire system, without\nrequiring demonstrations in the joint multi-agent action space. We show that\nR2BC methods match, and in some cases surpass, the performance of an oracle\nbehavior cloning approach trained on privileged synchronized demonstrations\nacross four multi-agent simulated tasks. Finally, we deploy R2BC on two\nphysical robot tasks trained using real human demonstrations.", "AI": {"tldr": "\u63d0\u51faR2BC\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f6e\u8be2\u884c\u4e3a\u514b\u9686\u8ba9\u5355\u4e2a\u64cd\u4f5c\u5458\u80fd\u591f\u901a\u8fc7\u987a\u5e8f\u7684\u5355\u667a\u80fd\u4f53\u6f14\u793a\u6765\u8bad\u7ec3\u591a\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u65e0\u9700\u5728\u8054\u5408\u591a\u667a\u80fd\u4f53\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u8fdb\u884c\u6f14\u793a\u3002", "motivation": "\u6a21\u4eff\u5b66\u4e60\u662f\u6559\u6388\u673a\u5668\u4eba\u7684\u81ea\u7136\u65b9\u5f0f\uff0c\u4f46\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\uff0c\u7279\u522b\u662f\u5f53\u5355\u4e2a\u4eba\u7c7b\u9700\u8981\u4e3a\u534f\u4f5c\u673a\u5668\u4eba\u56e2\u961f\u63d0\u4f9b\u6f14\u793a\u65f6\uff0c\u76f8\u5173\u7814\u7a76\u8f83\u5c11\u3002", "method": "R2BC\u65b9\u6cd5\u5141\u8bb8\u4eba\u7c7b\u64cd\u4f5c\u5458\u4e00\u6b21\u9065\u63a7\u4e00\u4e2a\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u987a\u5e8f\u7684\u5355\u667a\u80fd\u4f53\u6f14\u793a\u9010\u6b65\u6559\u6388\u591a\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u907f\u514d\u4e86\u8054\u5408\u591a\u667a\u80fd\u4f53\u52a8\u4f5c\u7a7a\u95f4\u7684\u6f14\u793a\u9700\u6c42\u3002", "result": "\u5728\u56db\u4e2a\u591a\u667a\u80fd\u4f53\u6a21\u62df\u4efb\u52a1\u4e2d\uff0cR2BC\u65b9\u6cd5\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u4e86\u57fa\u4e8e\u7279\u6743\u540c\u6b65\u6f14\u793a\u7684oracle\u884c\u4e3a\u514b\u9686\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u5e76\u5728\u4e24\u4e2a\u7269\u7406\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u6210\u529f\u90e8\u7f72\u3002", "conclusion": "R2BC\u662f\u4e00\u79cd\u6709\u6548\u7684\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u8bad\u7ec3\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u7b80\u5355\u7684\u5355\u667a\u80fd\u4f53\u6f14\u793a\u5b9e\u73b0\u590d\u6742\u591a\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u6559\u5b66\u3002"}}
{"id": "2510.18708", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.18708", "abs": "https://arxiv.org/abs/2510.18708", "authors": ["Debasis Mishra", "Soumendu Sarkar", "Arunava Sen", "Jay Sethuraman", "Sonal Yadav"], "title": "Teacher transfers: equalizing deficits across schools", "comment": null, "summary": "The Right to Free and Compulsory Education Act (2009) (RTE) of the Government\nof India prescribes student-teacher ratios for state-run schools. One method\nadvocated by the Act to achieve its goals is the redeployment of teachers from\nsurplus to deficit (in teacher strength) schools. We consider a model where\nteachers can either remain in their initially assigned schools or be\ntransferred to a deficit school in their acceptable set. The planner's\nobjective is specified in terms of the post-transfer deficit vector that can be\nachieved. We show that there exists a transfer whose post-transfer deficit\nvector Lorenz dominates all achievable post-transfer deficit vectors. We\nprovide a two-stage algorithm to derive the Lorenz-dominant post-transfer\ndeficit vector, and show that this algorithm is strategy-proof for teachers.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5370\u5ea6\u300a\u514d\u8d39\u4e49\u52a1\u6559\u80b2\u6743\u5229\u6cd5\u6848\u300b\u4e2d\u6559\u5e08\u91cd\u65b0\u90e8\u7f72\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u7b97\u6cd5\u6765\u627e\u5230\u6d1b\u4f26\u5179\u5360\u4f18\u7684\u6559\u5e08\u8f6c\u79fb\u540e\u77ed\u7f3a\u5411\u91cf\uff0c\u5e76\u8bc1\u660e\u8be5\u7b97\u6cd5\u5bf9\u6559\u5e08\u662f\u7b56\u7565\u8bc1\u660e\u7684\u3002", "motivation": "\u5370\u5ea6\u300a\u514d\u8d39\u4e49\u52a1\u6559\u80b2\u6743\u5229\u6cd5\u6848\u300b\u8981\u6c42\u901a\u8fc7\u5c06\u6559\u5e08\u4ece\u8fc7\u5269\u5b66\u6821\u91cd\u65b0\u90e8\u7f72\u5230\u77ed\u7f3a\u5b66\u6821\u6765\u5b9e\u73b0\u5b66\u751f-\u6559\u5e08\u6bd4\u4f8b\u76ee\u6807\uff0c\u9700\u8981\u8bbe\u8ba1\u6709\u6548\u7684\u6559\u5e08\u8f6c\u79fb\u673a\u5236\u3002", "method": "\u5efa\u7acb\u6559\u5e08\u8f6c\u79fb\u6a21\u578b\uff0c\u6559\u5e08\u53ef\u9009\u62e9\u7559\u5728\u539f\u6821\u6216\u8f6c\u79fb\u5230\u53ef\u63a5\u53d7\u5b66\u6821\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u7b97\u6cd5\u6765\u627e\u5230\u6d1b\u4f26\u5179\u5360\u4f18\u7684\u8f6c\u79fb\u540e\u77ed\u7f3a\u5411\u91cf\u3002", "result": "\u8bc1\u660e\u5b58\u5728\u4e00\u4e2a\u8f6c\u79fb\u65b9\u6848\uff0c\u5176\u8f6c\u79fb\u540e\u77ed\u7f3a\u5411\u91cf\u6d1b\u4f26\u5179\u5360\u4f18\u4e8e\u6240\u6709\u53ef\u8fbe\u7684\u8f6c\u79fb\u540e\u77ed\u7f3a\u5411\u91cf\uff0c\u4e14\u8be5\u7b97\u6cd5\u5bf9\u6559\u5e08\u662f\u7b56\u7565\u8bc1\u660e\u7684\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u6559\u5e08\u91cd\u65b0\u90e8\u7f72\u76ee\u6807\uff0c\u786e\u4fdd\u516c\u5e73\u6027\u5e76\u9632\u6b62\u6559\u5e08\u7b56\u7565\u6027\u884c\u4e3a\u3002"}}
{"id": "2510.17900", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17900", "abs": "https://arxiv.org/abs/2510.17900", "authors": ["Kush Juvekar", "Arghya Bhattacharya", "Sai Khadloya", "Utkarsh Saxena"], "title": "Are LLMs Court-Ready? Evaluating Frontier Models on Indian Legal Reasoning", "comment": null, "summary": "Large language models (LLMs) are entering legal workflows, yet we lack a\njurisdiction-specific framework to assess their baseline competence therein. We\nuse India's public legal examinations as a transparent proxy. Our multi-year\nbenchmark assembles objective screens from top national and state exams and\nevaluates open and frontier LLMs under real-world exam conditions. To probe\nbeyond multiple-choice questions, we also include a lawyer-graded,\npaired-blinded study of long-form answers from the Supreme Court's\nAdvocate-on-Record exam. This is, to our knowledge, the first exam-grounded,\nIndia-specific yardstick for LLM court-readiness released with datasets and\nprotocols. Our work shows that while frontier systems consistently clear\nhistorical cutoffs and often match or exceed recent top-scorer bands on\nobjective exams, none surpasses the human topper on long-form reasoning. Grader\nnotes converge on three reliability failure modes: procedural or format\ncompliance, authority or citation discipline, and forum-appropriate voice and\nstructure. These findings delineate where LLMs can assist (checks,\ncross-statute consistency, statute and precedent lookups) and where human\nleadership remains essential: forum-specific drafting and filing, procedural\nand relief strategy, reconciling authorities and exceptions, and ethical,\naccountable judgment.", "AI": {"tldr": "\u8be5\u7814\u7a76\u521b\u5efa\u4e86\u5370\u5ea6\u9996\u4e2a\u57fa\u4e8e\u6cd5\u5f8b\u8003\u8bd5\u7684LLM\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528\u5370\u5ea6\u516c\u5171\u6cd5\u5f8b\u8003\u8bd5\u4f5c\u4e3a\u57fa\u51c6\uff0c\u8bc4\u4f30LLM\u5728\u5370\u5ea6\u6cd5\u5f8b\u73af\u5883\u4e2d\u7684\u80fd\u529b\u8868\u73b0\u3002", "motivation": "\u7f3a\u4e4f\u9488\u5bf9\u7279\u5b9a\u53f8\u6cd5\u7ba1\u8f96\u533a\u7684LLM\u6cd5\u5f8b\u80fd\u529b\u8bc4\u4f30\u6846\u67b6\uff0c\u9700\u8981\u5efa\u7acb\u5370\u5ea6\u672c\u571f\u5316\u7684\u8bc4\u4f30\u6807\u51c6\u6765\u8861\u91cfLLM\u5728\u6cd5\u5f8b\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u4f7f\u7528\u5370\u5ea6\u56fd\u5bb6\u548c\u5dde\u7ea7\u6cd5\u5f8b\u8003\u8bd5\u7684\u5ba2\u89c2\u9898\u76ee\u6784\u5efa\u591a\u5e74\u57fa\u51c6\uff0c\u5728\u771f\u5b9e\u8003\u8bd5\u6761\u4ef6\u4e0b\u8bc4\u4f30\u5f00\u653e\u548c\u524d\u6cbfLLM\uff1b\u540c\u65f6\u8fdb\u884c\u5f8b\u5e08\u8bc4\u5206\u7684\u914d\u5bf9\u76f2\u5ba1\u7814\u7a76\uff0c\u8bc4\u4f30\u957f\u7bc7\u7b54\u6848\u8d28\u91cf\u3002", "result": "\u524d\u6cbfLLM\u7cfb\u7edf\u80fd\u591f\u901a\u8fc7\u5386\u53f2\u5206\u6570\u7ebf\uff0c\u5728\u5ba2\u89c2\u8003\u8bd5\u4e2d\u8fbe\u5230\u6216\u8d85\u8fc7\u9876\u5c16\u8003\u751f\u6c34\u5e73\uff0c\u4f46\u5728\u957f\u7bc7\u63a8\u7406\u65b9\u9762\u65e0\u4eba\u8d85\u8d8a\u4eba\u7c7b\u9876\u5c16\u8003\u751f\u3002\u8bc4\u4f30\u53d1\u73b0\u4e09\u4e2a\u53ef\u9760\u6027\u95ee\u9898\uff1a\u7a0b\u5e8f/\u683c\u5f0f\u5408\u89c4\u6027\u3001\u5f15\u7528\u89c4\u8303\u3001\u6cd5\u5ead\u9002\u5f53\u8868\u8fbe\u548c\u7ed3\u6784\u3002", "conclusion": "LLM\u53ef\u5728\u6cd5\u5f8b\u68c0\u67e5\u3001\u6cd5\u89c4\u4e00\u81f4\u6027\u3001\u6cd5\u89c4\u548c\u5224\u4f8b\u67e5\u627e\u65b9\u9762\u63d0\u4f9b\u5e2e\u52a9\uff0c\u4f46\u5728\u6cd5\u5ead\u7279\u5b9a\u6587\u4ef6\u8d77\u8349\u3001\u7a0b\u5e8f\u548c\u6551\u6d4e\u7b56\u7565\u3001\u6743\u5a01\u4e0e\u4f8b\u5916\u534f\u8c03\u4ee5\u53ca\u4f26\u7406\u5224\u65ad\u7b49\u65b9\u9762\u4ecd\u9700\u4eba\u7c7b\u4e3b\u5bfc\u3002"}}
{"id": "2510.17815", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.17815", "abs": "https://arxiv.org/abs/2510.17815", "authors": ["Wucheng Ying", "Jinwei Qi", "Hui Zhao", "Ameer Janabi", "Hui Li", "Biao Zhao", "Teng Long"], "title": "Towards the True Switching-ON of Transistors", "comment": "24 pages, 5 figures", "summary": "Transistors are core component across all domains of electrical and\nelectronic engineering (EEE), such as data centers, electrified transportation,\nrobotics, renewables and grid applications, etc. Transistors' switching\nbehavior governs energy loss, carbon emissions, cooling demand, water use,\nlifetime, material use and cost etc. throughout EEE. Despite near a century\nsince the transistor's invention, the understanding of transistor switching\nremains fragmented: switching is treated as a black box relying on observed\nwaveforms, cannot be explained using physical laws alone, and is not integrated\ninto circuit theory. This forms one of the most critical barriers to\nrecognizing the true physical boundaries, prohibiting more sustainable\nsolutions. For example, the conventional Eon prediction model, derived from the\nconventional switching analysis, exhibits significant prediction errors\n(ranging from 34.41% to 80.05%). Here we present a unified first-principles\nparadigm to explain the switching phenomena. Using this paradigm, we revealed\nthe physical origins and mechanisms of switching-ON phenomena across scenarios,\nand derived the proposed Eon prediction model, with error ranging from 0.88% to\n11.60%, achieving a 17-fold average improvement. These results demonstrate the\nunprecedented power of the proposed paradigm: textbook-level foundations are\nestablished, transforming the fundamental understanding of transistor switching\nfrom empirical to first-principles analysis, and simultaneously stimulating\nfollow-up research and applications for sustainable development across\ndisciplines.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u7684\u7b2c\u4e00\u6027\u539f\u7406\u8303\u5f0f\u89e3\u91ca\u6676\u4f53\u7ba1\u5f00\u5173\u73b0\u8c61\uff0c\u663e\u8457\u6539\u8fdb\u5f00\u5173\u80fd\u91cf\u635f\u8017\u9884\u6d4b\u6a21\u578b\u7cbe\u5ea6", "motivation": "\u6676\u4f53\u7ba1\u5f00\u5173\u884c\u4e3a\u5f71\u54cd\u80fd\u6e90\u635f\u8017\u3001\u78b3\u6392\u653e\u7b49\u5173\u952e\u6307\u6807\uff0c\u4f46\u73b0\u6709\u7406\u89e3\u788e\u7247\u5316\uff0c\u65e0\u6cd5\u7528\u7269\u7406\u5b9a\u5f8b\u89e3\u91ca\uff0c\u963b\u788d\u53ef\u6301\u7eed\u89e3\u51b3\u65b9\u6848\u53d1\u5c55", "method": "\u5efa\u7acb\u7edf\u4e00\u7684\u7b2c\u4e00\u6027\u539f\u7406\u8303\u5f0f\uff0c\u63ed\u793a\u5f00\u5173\u73b0\u8c61\u7684\u7269\u7406\u8d77\u6e90\u548c\u673a\u5236", "result": "\u63d0\u51fa\u7684Eon\u9884\u6d4b\u6a21\u578b\u8bef\u5dee\u4ece34.41-80.05%\u964d\u81f30.88-11.60%\uff0c\u5e73\u5747\u63d0\u534717\u500d\u7cbe\u5ea6", "conclusion": "\u5efa\u7acb\u4e86\u6559\u79d1\u4e66\u7ea7\u7684\u57fa\u7840\u7406\u8bba\uff0c\u5c06\u6676\u4f53\u7ba1\u5f00\u5173\u7406\u89e3\u4ece\u7ecf\u9a8c\u6027\u8f6c\u53d8\u4e3a\u7b2c\u4e00\u6027\u539f\u7406\u5206\u6790\uff0c\u63a8\u52a8\u8de8\u5b66\u79d1\u53ef\u6301\u7eed\u53d1\u5c55\u7814\u7a76"}}
{"id": "2510.18639", "categories": ["stat.AP", "q-fin.RM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.18639", "abs": "https://arxiv.org/abs/2510.18639", "authors": ["Samuel Perreault", "Silvana M. Pesenti", "Daniyal Shahzad"], "title": "Distributional regression for seasonal data: an application to river flows", "comment": null, "summary": "Risk assessment in casualty insurance, such as flood risk, traditionally\nrelies on extreme-value methods that emphasizes rare events. These approaches\nare well-suited for characterizing tail risk, but do not capture the broader\ndynamics of environmental variables such as moderate or frequent loss events.\nTo complement these methods, we propose a modelling framework for estimating\nthe full (daily) distribution of environmental variables as a function of time,\nthat is a distributional version of typical climatological summary statistics,\nthereby incorporating both seasonal variation and gradual long-term changes.\nAside from the time trend, to capture seasonal variation our approach\nsimultaneously estimates the distribution for each instant of the seasonal\ncycle, without explicitly modelling the temporal dependence present in the\ndata. To do so, we adopt a framework inspired by GAMLSS (Generalized Additive\nModels for Location, Scale, and Shape), where the parameters of the\ndistribution vary over the seasonal cycle as a function of explanatory\nvariables depending only on the time of year, and not on the past values of the\nprocess under study. Ignoring the temporal dependence in the seasonal variation\ngreatly simplifies the modelling but poses inference challenges that we clarify\nand overcome.\n  We apply our framework to daily river flow data from three hydrometric\nstations along the Fraser River in British Columbia, Canada, and analyse the\nflood of the Fraser River in early winter of 2021.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5efa\u6a21\u6846\u67b6\u6765\u4f30\u8ba1\u73af\u5883\u53d8\u91cf\u7684\u5b8c\u6574\u65e5\u5206\u5e03\uff0c\u4f5c\u4e3a\u65f6\u95f4\u7684\u51fd\u6570\uff0c\u8865\u5145\u4f20\u7edf\u6781\u7aef\u503c\u65b9\u6cd5\uff0c\u540c\u65f6\u6355\u6349\u5b63\u8282\u53d8\u5316\u548c\u957f\u671f\u8d8b\u52bf\u3002", "motivation": "\u4f20\u7edf\u4fdd\u9669\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7f55\u89c1\u6781\u7aef\u4e8b\u4ef6\uff0c\u4f46\u65e0\u6cd5\u6355\u6349\u73af\u5883\u53d8\u91cf\u7684\u5b8c\u6574\u52a8\u6001\uff0c\u5305\u62ec\u4e2d\u7b49\u548c\u9891\u7e41\u7684\u635f\u5931\u4e8b\u4ef6\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u8003\u8651\u5b63\u8282\u53d8\u5316\u548c\u957f\u671f\u8d8b\u52bf\u7684\u5206\u5e03\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u53d7GAMLSS\u542f\u53d1\u7684\u6846\u67b6\uff0c\u5c06\u5206\u5e03\u53c2\u6570\u5efa\u6a21\u4e3a\u4ec5\u4f9d\u8d56\u4e8e\u5e74\u5185\u65f6\u95f4\u7684\u89e3\u91ca\u53d8\u91cf\u7684\u51fd\u6570\uff0c\u5ffd\u7565\u65f6\u95f4\u5e8f\u5217\u4f9d\u8d56\u6027\u4ee5\u7b80\u5316\u6a21\u578b\uff0c\u540c\u65f6\u89e3\u51b3\u76f8\u5173\u63a8\u65ad\u6311\u6218\u3002", "result": "\u5c06\u8be5\u6846\u67b6\u5e94\u7528\u4e8e\u52a0\u62ff\u5927\u4e0d\u5217\u98a0\u54e5\u4f26\u6bd4\u4e9a\u7701\u5f17\u96f7\u6cfd\u6cb3\u4e09\u4e2a\u6c34\u6587\u7ad9\u7684\u65e5\u6cb3\u6d41\u6d41\u91cf\u6570\u636e\uff0c\u5206\u6790\u4e862021\u5e74\u521d\u51ac\u7684\u5f17\u96f7\u6cfd\u6cb3\u6d2a\u6c34\u4e8b\u4ef6\u3002", "conclusion": "\u63d0\u51fa\u7684\u5206\u5e03\u5efa\u6a21\u6846\u67b6\u80fd\u591f\u6709\u6548\u6355\u6349\u73af\u5883\u53d8\u91cf\u7684\u5b8c\u6574\u52a8\u6001\uff0c\u5305\u62ec\u5b63\u8282\u53d8\u5316\u548c\u957f\u671f\u8d8b\u52bf\uff0c\u4e3a\u4fdd\u9669\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u5de5\u5177\u3002"}}
{"id": "2510.17940", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17940", "abs": "https://arxiv.org/abs/2510.17940", "authors": ["Zhiming Lin"], "title": "Beyond More Context: Retrieval Diversity Boosts Multi-Turn Intent Understanding", "comment": "15 pages,6 figs", "summary": "Multi turn intent understanding is central to task oriented chatbots, yet\nreal deployments face tight token budgets and noisy contexts, and most\nretrieval pipelines emphasize relevance while overlooking set level diversity\nand confounds such as more context or exemplar order. We ask whether retrieval\ndiversity, rather than longer prompts, systematically improves LLM intent\nunderstanding under fixed budgets. We present a diversity aware retrieval\nframework that selects in context exemplars to balance intent coverage and\nlinguistic variety, and integrates this selection with standard LLM decoders;\nthe evaluation enforces budget matched prompts and randomized positions, and\nincludes sensitivity analyses over exemplar count, diversity strength, and\nbackbone size. On MultiWOZ 2.4 and SGD, the approach achieves strong gains in\nJoint Goal Accuracy under equal token budgets, surpassing strong LLM/DST\nbaselines, with consistent improvements across K from 4 to 7 and moderate\nlatency. Overall, the study isolates and validates the impact of content\ndiversity in retrieval and offers a simple, deployable selection principle for\nbuilding accurate, budget constrained multi turn intent systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6837\u6027\u611f\u77e5\u68c0\u7d22\u6846\u67b6\uff0c\u5728\u56fa\u5b9atoken\u9884\u7b97\u4e0b\u901a\u8fc7\u9009\u62e9\u591a\u6837\u5316\u7684\u4e0a\u4e0b\u6587\u793a\u4f8b\u6765\u63d0\u5347LLM\u610f\u56fe\u7406\u89e3\u80fd\u529b\uff0c\u5728MultiWOZ 2.4\u548cSGD\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u8054\u5408\u76ee\u6807\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u5b9e\u90e8\u7f72\u4e2d\u9762\u4e34\u4e25\u683c\u7684token\u9884\u7b97\u548c\u5608\u6742\u4e0a\u4e0b\u6587\uff0c\u73b0\u6709\u68c0\u7d22\u7ba1\u9053\u5f3a\u8c03\u76f8\u5173\u6027\u4f46\u5ffd\u7565\u4e86\u96c6\u5408\u5c42\u9762\u7684\u591a\u6837\u6027\u4ee5\u53ca\u66f4\u591a\u4e0a\u4e0b\u6587\u6216\u793a\u4f8b\u987a\u5e8f\u7b49\u6df7\u6dc6\u56e0\u7d20\u3002", "method": "\u5f00\u53d1\u4e86\u591a\u6837\u6027\u611f\u77e5\u68c0\u7d22\u6846\u67b6\uff0c\u9009\u62e9\u4e0a\u4e0b\u6587\u793a\u4f8b\u4ee5\u5e73\u8861\u610f\u56fe\u8986\u76d6\u548c\u8bed\u8a00\u591a\u6837\u6027\uff0c\u5e76\u5c06\u6b64\u9009\u62e9\u4e0e\u6807\u51c6LLM\u89e3\u7801\u5668\u96c6\u6210\uff1b\u8bc4\u4f30\u91c7\u7528\u9884\u7b97\u5339\u914d\u63d0\u793a\u548c\u968f\u673a\u5316\u4f4d\u7f6e\u3002", "result": "\u5728MultiWOZ 2.4\u548cSGD\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u76f8\u540ctoken\u9884\u7b97\u4e0b\u5b9e\u73b0\u4e86\u8054\u5408\u76ee\u6807\u51c6\u786e\u7387\u7684\u663e\u8457\u63d0\u5347\uff0c\u8d85\u8d8a\u4e86\u5f3a\u5927\u7684LLM/DST\u57fa\u7ebf\uff0c\u5728K=4\u52307\u8303\u56f4\u5185\u4fdd\u6301\u4e00\u81f4\u7684\u6539\u8fdb\uff0c\u5ef6\u8fdf\u9002\u4e2d\u3002", "conclusion": "\u7814\u7a76\u5206\u79bb\u5e76\u9a8c\u8bc1\u4e86\u68c0\u7d22\u4e2d\u5185\u5bb9\u591a\u6837\u6027\u7684\u5f71\u54cd\uff0c\u4e3a\u6784\u5efa\u51c6\u786e\u3001\u9884\u7b97\u53d7\u9650\u7684\u591a\u8f6e\u610f\u56fe\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u3001\u53ef\u90e8\u7f72\u7684\u9009\u62e9\u539f\u5219\u3002"}}
{"id": "2510.18155", "categories": ["cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.18155", "abs": "https://arxiv.org/abs/2510.18155", "authors": ["Man-Lin Chu", "Lucian Terhorst", "Kadin Reed", "Tom Ni", "Weiwei Chen", "Rongyu Lin"], "title": "LLM-Based Multi-Agent System for Simulating and Analyzing Marketing and Consumer Behavior", "comment": "Accepted for publication at IEEE International Conference on\n  e-Business Engineering ICEBE 2025, November 10-12, Buraydah, Saudi Arabia. 8\n  pages, 5 figures", "summary": "Simulating consumer decision-making is vital for designing and evaluating\nmarketing strategies before costly real-world deployment. However, post-event\nanalyses and rule-based agent-based models (ABMs) struggle to capture the\ncomplexity of human behavior and social interaction. We introduce an\nLLM-powered multi-agent simulation framework that models consumer decisions and\nsocial dynamics. Building on recent advances in large language model simulation\nin a sandbox environment, our framework enables generative agents to interact,\nexpress internal reasoning, form habits, and make purchasing decisions without\npredefined rules. In a price-discount marketing scenario, the system delivers\nactionable strategy-testing outcomes and reveals emergent social patterns\nbeyond the reach of conventional methods. This approach offers marketers a\nscalable, low-risk tool for pre-implementation testing, reducing reliance on\ntime-intensive post-event evaluations and lowering the risk of underperforming\ncampaigns.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6a21\u62df\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u6d88\u8d39\u8005\u51b3\u7b56\u548c\u793e\u4f1a\u52a8\u6001\uff0c\u4e3a\u8425\u9500\u7b56\u7565\u63d0\u4f9b\u4f4e\u6210\u672c\u9884\u5b9e\u65bd\u6d4b\u8bd5\u3002", "motivation": "\u4f20\u7edf\u7684\u4e8b\u540e\u5206\u6790\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u667a\u80fd\u4f53\u6a21\u578b\u96be\u4ee5\u6355\u6349\u4eba\u7c7b\u884c\u4e3a\u548c\u793e\u4f1a\u4e92\u52a8\u7684\u590d\u6742\u6027\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u8425\u9500\u7b56\u7565\u6d4b\u8bd5\u5de5\u5177\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6c99\u76d2\u73af\u5883\u4e2d\u6784\u5efa\u591a\u667a\u80fd\u4f53\u6a21\u62df\u6846\u67b6\uff0c\u667a\u80fd\u4f53\u53ef\u4ee5\u4ea4\u4e92\u3001\u8868\u8fbe\u5185\u90e8\u63a8\u7406\u3001\u5f62\u6210\u4e60\u60ef\u548c\u505a\u51fa\u8d2d\u4e70\u51b3\u7b56\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u89c4\u5219\u3002", "result": "\u5728\u4ef7\u683c\u6298\u6263\u8425\u9500\u573a\u666f\u4e2d\uff0c\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u7b56\u7565\u6d4b\u8bd5\u7ed3\u679c\uff0c\u5e76\u63ed\u793a\u4e86\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u7684\u65b0\u5174\u793e\u4f1a\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8425\u9500\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u4f4e\u98ce\u9669\u7684\u9884\u5b9e\u65bd\u6d4b\u8bd5\u5de5\u5177\uff0c\u51cf\u5c11\u4e86\u5bf9\u8017\u65f6\u7684\u4e8b\u540e\u8bc4\u4f30\u7684\u4f9d\u8d56\uff0c\u964d\u4f4e\u4e86\u8425\u9500\u6d3b\u52a8\u8868\u73b0\u4e0d\u4f73\u7684\u98ce\u9669\u3002"}}
{"id": "2510.18127", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.18127", "abs": "https://arxiv.org/abs/2510.18127", "authors": ["Dharmik Patel", "Antonio Rafael Vazquez Pantoja", "Jiuzhou Lei", "Kiju Lee", "Xiao Liang", "Minghui Zheng"], "title": "ANGEL: A Novel Gripper for Versatile and Light-touch Fruit Harvesting", "comment": null, "summary": "Fruit harvesting remains predominantly a labor-intensive process, motivating\nthe development of research for robotic grippers. Conventional rigid or\nvacuum-driven grippers require complex mechanical design or high energy\nconsumption. Current enveloping-based fruit harvesting grippers lack\nadaptability to fruits of different sizes. This paper introduces a\ndrawstring-inspired, cable-driven soft gripper for versatile and gentle fruit\nharvesting. The design employs 3D-printed Thermoplastic Polyurethane (TPU)\npockets with integrated steel wires that constrict around the fruit when\nactuated, distributing pressure uniformly to minimize bruising and allow\nversatility to fruits of varying sizes. The lightweight structure, which\nrequires few components, reduces mechanical complexity and cost compared to\nother grippers. Actuation is achieved through servo-driven cable control, while\nmotor feedback provides autonomous grip adjustment with tunable grip strength.\nExperimental validation shows that, for tomatoes within the gripper's effective\nsize range, harvesting was achieved with a 0% immediate damage rate and a\nbruising rate of less than 9% after five days, reinforcing the gripper's\nsuitability for fruit harvesting.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53d7\u62c9\u7ef3\u542f\u53d1\u7684\u7ebf\u9a71\u52a8\u8f6f\u6293\u53d6\u5668\uff0c\u7528\u4e8e\u6c34\u679c\u91c7\u6458\uff0c\u5177\u6709\u9002\u5e94\u4e0d\u540c\u5c3a\u5bf8\u6c34\u679c\u548c\u8f7b\u67d4\u6293\u53d6\u7684\u7279\u70b9\u3002", "motivation": "\u6c34\u679c\u91c7\u6458\u4e3b\u8981\u662f\u52b3\u52a8\u5bc6\u96c6\u578b\u8fc7\u7a0b\uff0c\u73b0\u6709\u521a\u6027\u6216\u771f\u7a7a\u9a71\u52a8\u6293\u53d6\u5668\u9700\u8981\u590d\u6742\u673a\u68b0\u8bbe\u8ba1\u6216\u9ad8\u80fd\u8017\uff0c\u800c\u73b0\u6709\u5305\u88f9\u5f0f\u6293\u53d6\u5668\u7f3a\u4e4f\u5bf9\u4e0d\u540c\u5c3a\u5bf8\u6c34\u679c\u7684\u9002\u5e94\u6027\u3002", "method": "\u91c7\u75283D\u6253\u5370TPU\u6750\u6599\u5236\u4f5c\u5e26\u6709\u96c6\u6210\u94a2\u4e1d\u7684\u53e3\u888b\u7ed3\u6784\uff0c\u901a\u8fc7\u4f3a\u670d\u9a71\u52a8\u7ebf\u7f06\u63a7\u5236\u5b9e\u73b0\u6536\u7f29\u6293\u53d6\uff0c\u5229\u7528\u7535\u673a\u53cd\u9988\u5b9e\u73b0\u81ea\u4e3b\u6293\u53d6\u529b\u8c03\u8282\u3002", "result": "\u5728\u6709\u6548\u5c3a\u5bf8\u8303\u56f4\u5185\u7684\u756a\u8304\u91c7\u6458\u4e2d\uff0c\u5b9e\u73b0\u4e860%\u7684\u5373\u65f6\u635f\u4f24\u7387\u548c5\u5929\u540e\u4f4e\u4e8e9%\u7684\u7600\u4f24\u7387\u3002", "conclusion": "\u8be5\u6293\u53d6\u5668\u7ed3\u6784\u8f7b\u91cf\u3001\u7ec4\u4ef6\u5c11\uff0c\u964d\u4f4e\u4e86\u673a\u68b0\u590d\u6742\u6027\u548c\u6210\u672c\uff0c\u9002\u5408\u6c34\u679c\u91c7\u6458\u5e94\u7528\u3002"}}
{"id": "2510.17910", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17910", "abs": "https://arxiv.org/abs/2510.17910", "authors": ["Sagnik Dakshit", "Sushmita Sinha Roy"], "title": "Interpretability Framework for LLMs in Undergraduate Calculus", "comment": null, "summary": "Large Language Models (LLMs) are increasingly being used in education, yet\ntheir correctness alone does not capture the quality, reliability, or\npedagogical validity of their problem-solving behavior, especially in\nmathematics, where multistep logic, symbolic reasoning, and conceptual clarity\nare critical. Conventional evaluation methods largely focus on final answer\naccuracy and overlook the reasoning process. To address this gap, we introduce\na novel interpretability framework for analyzing LLM-generated solutions using\nundergraduate calculus problems as a representative domain. Our approach\ncombines reasoning flow extraction and decomposing solutions into semantically\nlabeled operations and concepts with prompt ablation analysis to assess input\nsalience and output stability. Using structured metrics such as reasoning\ncomplexity, phrase sensitivity, and robustness, we evaluated the model behavior\non real Calculus I to III university exams. Our findings revealed that LLMs\noften produce syntactically fluent yet conceptually flawed solutions, with\nreasoning patterns sensitive to prompt phrasing and input variation. This\nframework enables fine-grained diagnosis of reasoning failures, supports\ncurriculum alignment, and informs the design of interpretable AI-assisted\nfeedback tools. This is the first study to offer a structured, quantitative,\nand pedagogically grounded framework for interpreting LLM reasoning in\nmathematics education, laying the foundation for the transparent and\nresponsible deployment of AI in STEM learning environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u5206\u6790LLM\u5728\u6570\u5b66\u6559\u80b2\u4e2d\u63a8\u7406\u8fc7\u7a0b\u7684\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u5fae\u79ef\u5206\u95ee\u9898\u8bc4\u4f30\u6a21\u578b\u89e3\u51b3\u65b9\u6848\u7684\u8d28\u91cf\u3001\u53ef\u9760\u6027\u548c\u6559\u5b66\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u6027\uff0c\u5ffd\u89c6\u4e86\u63a8\u7406\u8fc7\u7a0b\u7684\u8d28\u91cf\u3002LLM\u5728\u6570\u5b66\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u9700\u8981\u8bc4\u4f30\u5176\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u9760\u6027\u3001\u6559\u5b66\u6709\u6548\u6027\u548c\u6982\u5ff5\u6e05\u6670\u5ea6\u3002", "method": "\u7ed3\u5408\u63a8\u7406\u6d41\u7a0b\u63d0\u53d6\u3001\u8bed\u4e49\u6807\u8bb0\u64cd\u4f5c\u5206\u89e3\u548c\u63d0\u793a\u6d88\u878d\u5206\u6790\uff0c\u4f7f\u7528\u63a8\u7406\u590d\u6742\u6027\u3001\u77ed\u8bed\u654f\u611f\u6027\u548c\u9c81\u68d2\u6027\u7b49\u7ed3\u6784\u5316\u6307\u6807\uff0c\u5728\u771f\u5b9e\u5927\u5b66\u5fae\u79ef\u5206\u8003\u8bd5\u4e0a\u8bc4\u4f30\u6a21\u578b\u884c\u4e3a\u3002", "result": "\u53d1\u73b0LLM\u7ecf\u5e38\u751f\u6210\u8bed\u6cd5\u6d41\u7545\u4f46\u6982\u5ff5\u6709\u7f3a\u9677\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u7406\u6a21\u5f0f\u5bf9\u63d0\u793a\u63aa\u8f9e\u548c\u8f93\u5165\u53d8\u5316\u654f\u611f\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u5bf9\u63a8\u7406\u5931\u8d25\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bca\u65ad\uff0c\u652f\u6301\u8bfe\u7a0b\u5bf9\u9f50\uff0c\u5e76\u4e3a\u53ef\u89e3\u91caAI\u8f85\u52a9\u53cd\u9988\u5de5\u5177\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4fe1\u606f\uff0c\u4e3aAI\u5728STEM\u5b66\u4e60\u73af\u5883\u4e2d\u7684\u900f\u660e\u548c\u8d1f\u8d23\u4efb\u90e8\u7f72\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.17857", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.17857", "abs": "https://arxiv.org/abs/2510.17857", "authors": ["Dimitrios Voulanas", "Eduardo Gildin"], "title": "Introducing Coherent-Control Koopman to Reservoir Scale Porous Media Flow Studies", "comment": null, "summary": "Accurate and robust surrogate modeling is essential for the real time control\nand optimization of large-scale subsurface systems, such as geological CO2\nstorage and waterflood management. This study investigates the limits of\nclassical Dynamic Mode Decomposition with control (DMDc) in replicating\npressure and water saturation dynamics under challenging prediction scenarios.\nWe benchmark CCKM against DMDc and a Hybrid B-only surrogate that reuses DMDcs\nbottom B (same step feed through), showing that only CCKM remains stable and\naccurate under regime shifts. Two representative cases are considered: (i) an\nout of distribution shut in and restart case, and (ii) an in distribution\nbottom hole pressure (BHP) drawdown. Results show that only CCKM consistently\nmaintains stability and accuracy across both scenarios, achieving sub bar mean\nabsolute error and sub percent Frobenius norm percent change error even under\nregime shifts, while DMDc exhibit large unphysical errors during control\ntransients. The findings demonstrate that strict control coherence is critical\nfor reliable surrogate modeling, particularly in settings with abrupt changes\nin control strategy. The proposed framework is broadly applicable to real time\nreservoir optimization and can be integrated seamlessly into existing\noptimization and monitoring workflows, enabling fast and trustworthy decision\nsupport in the presence of both expected and unexpected actuation regimes.", "AI": {"tldr": "CCKM\u5728\u5177\u6709\u63a7\u5236\u7b56\u7565\u7a81\u53d8\u7684\u590d\u6742\u9884\u6d4b\u573a\u666f\u4e2d\uff0c\u6bd4DMDc\u548cHybrid B-only\u65b9\u6cd5\u8868\u73b0\u66f4\u7a33\u5b9a\u548c\u51c6\u786e\uff0c\u7279\u522b\u662f\u5728\u5206\u5e03\u5916\u548c\u5206\u5e03\u5185\u63a7\u5236\u53d8\u5316\u60c5\u51b5\u4e0b\u3002", "motivation": "\u4e3a\u5927\u89c4\u6a21\u5730\u4e0b\u7cfb\u7edf\uff08\u5982\u5730\u8d28CO2\u5c01\u5b58\u548c\u6c34\u9a71\u7ba1\u7406\uff09\u7684\u5b9e\u65f6\u63a7\u5236\u548c\u4f18\u5316\u5f00\u53d1\u51c6\u786e\u7a33\u5065\u7684\u4ee3\u7406\u6a21\u578b\u3002", "method": "\u6bd4\u8f83CCKM\u4e0eDMDc\u548cHybrid B-only\u65b9\u6cd5\u5728\u4e24\u79cd\u4ee3\u8868\u6027\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff1a(i)\u5206\u5e03\u5916\u7684\u5173\u4e95\u548c\u91cd\u542f\u6848\u4f8b\uff0c(ii)\u5206\u5e03\u5185\u7684\u4e95\u5e95\u538b\u529b\u964d\u538b\u6848\u4f8b\u3002", "result": "\u53ea\u6709CCKM\u5728\u4e24\u79cd\u573a\u666f\u4e0b\u90fd\u4fdd\u6301\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\uff0c\u8fbe\u5230\u4e9a\u5df4\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u548c\u4e9a\u767e\u5206\u6bd4Frobenius\u8303\u6570\u767e\u5206\u6bd4\u53d8\u5316\u8bef\u5dee\uff0c\u800cDMDc\u5728\u63a7\u5236\u77ac\u53d8\u671f\u95f4\u51fa\u73b0\u5927\u7684\u975e\u7269\u7406\u8bef\u5dee\u3002", "conclusion": "\u4e25\u683c\u7684\u63a7\u5236\u4e00\u81f4\u6027\u5bf9\u4e8e\u53ef\u9760\u7684\u4ee3\u7406\u5efa\u6a21\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u63a7\u5236\u7b56\u7565\u7a81\u7136\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\u3002CCKM\u6846\u67b6\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5b9e\u65f6\u50a8\u5c42\u4f18\u5316\uff0c\u5e76\u96c6\u6210\u5230\u73b0\u6709\u4f18\u5316\u548c\u76d1\u6d4b\u5de5\u4f5c\u6d41\u4e2d\u3002"}}
{"id": "2510.18818", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.18818", "abs": "https://arxiv.org/abs/2510.18818", "authors": ["Jay JH Park", "Rebecca K. Metcalfe", "Nathaniel Dyrkton", "Yichen Yan", "Shomoita Alam", "Kevin Phelan", "Ibrahim Sana", "Susan Shepherd"], "title": "Comparison of Simulation-Guided Design to Closed-Form Power Calculations in Planning a Cluster Randomized Trial with Covariate-Constrained Randomization: A Case Study in Rural Chad", "comment": null, "summary": "Current practices for designing cluster-randomized trials (cRCTs) typically\nrely on closed-form formulas for power calculations. For cRCTs using\ncovariate-constrained randomization, the utility of conventional calculations\nmight be limited, particularly when data is nested. We compared\nsimulation-based planning of a nested cRCT using covariate-constrained\nrandomization to conventional power calculations using OptiMAx-Chad as a case\nstudy. OptiMAx-Chad will examine the impact of embedding mass distribution of\nsmall-quantity lipid-based nutrient supplements within an expanded programme on\nimmunization on first-dose measles-containing vaccine (MCV1) coverage among\nchildren aged 12-24 months in rural villages in Ngouri. Within the 12 health\nareas to be randomized, a random subset of villages will be selected for\noutcome collection. 1,000,000 assignments of health areas with different\npossible village selections were generated using covariate-constrained\nrandomization to balance baseline village characteristics. The empirically\nestimated intracluster correlation coefficient (ICC) and the World Health\nOrganization (WHO) recommended values of 1/3 and 1/6 were considered. The\ndesired operating characteristics were 80% power at 0.05 one-sided type I error\nrate. Using conventional calculations target power for a realistic treatment\neffect could not be achieved with the WHO recommended values. Conventional\ncalculations also showed a plateau in power after a certain cluster size. Our\nsimulations matched the design of OptiMAx-Chad with covariate adjustment and\nrandom selection, and showed that power did not plateau. Instead, power\nincreased with increasing cluster size. Planning complex cRCTs with covariate\nconstrained randomization and a multi-nested data structure with conventional\nclosed-form formulas can be misleading. Simulations can improve the planning of\ncRCTs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u4f7f\u7528\u534f\u53d8\u91cf\u7ea6\u675f\u968f\u673a\u5316\u7684\u5d4c\u5957\u6574\u7fa4\u968f\u673a\u8bd5\u9a8c\u7684\u6a21\u62df\u89c4\u5212\u4e0e\u4f20\u7edf\u529f\u6548\u8ba1\u7b97\uff0c\u53d1\u73b0\u4f20\u7edf\u65b9\u6cd5\u5728\u590d\u6742\u8bbe\u8ba1\u4e0b\u53ef\u80fd\u4ea7\u751f\u8bef\u5bfc\uff0c\u800c\u6a21\u62df\u65b9\u6cd5\u80fd\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u8bd5\u9a8c\u529f\u6548\u3002", "motivation": "\u4f20\u7edf\u6574\u7fa4\u968f\u673a\u8bd5\u9a8c\u8bbe\u8ba1\u4f9d\u8d56\u95ed\u5f0f\u516c\u5f0f\u8fdb\u884c\u529f\u6548\u8ba1\u7b97\uff0c\u4f46\u5728\u4f7f\u7528\u534f\u53d8\u91cf\u7ea6\u675f\u968f\u673a\u5316\u548c\u5d4c\u5957\u6570\u636e\u7ed3\u6784\u65f6\uff0c\u4f20\u7edf\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\u6709\u9650\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e0d\u51c6\u786e\u7684\u8bd5\u9a8c\u89c4\u5212\u3002", "method": "\u4ee5OptiMAx-Chad\u7814\u7a76\u4e3a\u6848\u4f8b\uff0c\u751f\u6210\u4e86100\u4e07\u6b21\u4f7f\u7528\u534f\u53d8\u91cf\u7ea6\u675f\u968f\u673a\u5316\u7684\u5065\u5eb7\u533a\u57df\u5206\u914d\uff0c\u5e73\u8861\u57fa\u7ebf\u6751\u5e84\u7279\u5f81\uff0c\u5e76\u6bd4\u8f83\u6a21\u62df\u65b9\u6cd5\u4e0e\u4f7f\u7528WHO\u63a8\u8350ICC\u503c\u7684\u4f20\u7edf\u529f\u6548\u8ba1\u7b97\u3002", "result": "\u4f20\u7edf\u8ba1\u7b97\u663e\u793a\u5728\u8fbe\u5230\u4e00\u5b9a\u6574\u7fa4\u89c4\u6a21\u540e\u529f\u6548\u8d8b\u4e8e\u7a33\u5b9a\uff0c\u800c\u6a21\u62df\u65b9\u6cd5\u663e\u793a\u529f\u6548\u968f\u6574\u7fa4\u89c4\u6a21\u589e\u52a0\u800c\u6301\u7eed\u63d0\u5347\uff0c\u4e14\u4f7f\u7528WHO\u63a8\u8350ICC\u503c\u65f6\u65e0\u6cd5\u8fbe\u5230\u76ee\u6807\u529f\u6548\u3002", "conclusion": "\u5bf9\u4e8e\u5177\u6709\u534f\u53d8\u91cf\u7ea6\u675f\u968f\u673a\u5316\u548c\u591a\u5c42\u5d4c\u5957\u6570\u636e\u7ed3\u6784\u7684\u590d\u6742\u6574\u7fa4\u968f\u673a\u8bd5\u9a8c\uff0c\u4f20\u7edf\u95ed\u5f0f\u516c\u5f0f\u89c4\u5212\u53ef\u80fd\u4ea7\u751f\u8bef\u5bfc\uff0c\u6a21\u62df\u65b9\u6cd5\u80fd\u6539\u5584\u8bd5\u9a8c\u89c4\u5212\u8d28\u91cf\u3002"}}
{"id": "2510.17995", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17995", "abs": "https://arxiv.org/abs/2510.17995", "authors": ["Abhigya Verma", "Seganrasan Subramanian", "Nandhakumar Kandasamy", "Naman Gupta"], "title": "FABRIC: Framework for Agent-Based Realistic Intelligence Creation", "comment": "51 Pages, 38 Listings, 5 Figures", "summary": "Large language models (LLMs) are increasingly deployed as agents, expected to\ndecompose goals, invoke tools, and verify results in dynamic environments.\nRealizing these capabilities requires access to agentic data-structured\ninteraction records that couple user intents with tool specifications,\nargument-grounded calls, and verifiable execution traces. However, collecting\nsuch data from human annotators is costly, time-consuming, and difficult to\nscale. We present a unified framework for synthesizing agentic data using only\nLLMs, without any human-in-the-loop supervision. This framework decomposes\ngeneration into modular pipelines that produce complete interaction records\nspanning task specifications, tool definitions, policy pseudocode, natural\nlanguage exchanges, and execution traces. Records conform to strict syntactic\nand semantic constraints, ensuring machine-parseability and faithful alignment\nacross inputs, outputs, and tool calls. Beyond single tasks, there is support\nfor both multi-task and multi-turn agent interactions, enabling the\nconstruction of datasets that reflect the full spectrum of tool-use\ncompetencies. To ensure quality and consistency, the framework integrates\nconstrained generation formats, JSON-schema validation, and judge-based\nfiltering. This paper formalizes the schema for agentic records, details the\nprompt design principles that guide generation, and introduces scalable\npipelines for high-quality synthetic data. By providing a reproducible,\nLLM-only alternative to manual collection, hence advancing the development of\nagentic LLMs capable of robust tool use.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ec5\u4f7f\u7528LLM\u5408\u6210\u667a\u80fd\u4f53\u6570\u636e\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u65e0\u9700\u4eba\u5de5\u76d1\u7763\uff0c\u53ef\u751f\u6210\u5305\u542b\u4efb\u52a1\u89c4\u8303\u3001\u5de5\u5177\u5b9a\u4e49\u3001\u7b56\u7565\u4f2a\u4ee3\u7801\u3001\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u548c\u6267\u884c\u8f68\u8ff9\u7684\u5b8c\u6574\u4ea4\u4e92\u8bb0\u5f55\u3002", "motivation": "\u6536\u96c6\u667a\u80fd\u4f53\u6570\u636e\u9700\u8981\u4eba\u7c7b\u6807\u6ce8\uff0c\u6210\u672c\u9ad8\u3001\u8017\u65f6\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u6d41\u6c34\u7ebf\u751f\u6210\u7b26\u5408\u4e25\u683c\u8bed\u6cd5\u548c\u8bed\u4e49\u7ea6\u675f\u7684\u4ea4\u4e92\u8bb0\u5f55\uff0c\u652f\u6301\u5355\u4efb\u52a1\u3001\u591a\u4efb\u52a1\u548c\u591a\u8f6e\u4ea4\u4e92\uff0c\u7ed3\u5408\u7ea6\u675f\u751f\u6210\u683c\u5f0f\u3001JSON\u6a21\u5f0f\u9a8c\u8bc1\u548c\u57fa\u4e8e\u8bc4\u5224\u7684\u8fc7\u6ee4\u6765\u786e\u4fdd\u8d28\u91cf\u3002", "result": "\u6846\u67b6\u80fd\u591f\u751f\u6210\u673a\u5668\u53ef\u89e3\u6790\u4e14\u8f93\u5165\u3001\u8f93\u51fa\u548c\u5de5\u5177\u8c03\u7528\u4e4b\u95f4\u4fdd\u6301\u5fe0\u5b9e\u5bf9\u9f50\u7684\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u624b\u52a8\u6536\u96c6\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u3001\u4ec5\u4f7f\u7528LLM\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u80fd\u591f\u8fdb\u884c\u9c81\u68d2\u5de5\u5177\u4f7f\u7528\u7684\u667a\u80fd\u4f53LLM\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.18858", "categories": ["cs.CY", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.18858", "abs": "https://arxiv.org/abs/2510.18858", "authors": ["Rishav Sen", "Abhishek Dubey", "Ayan Mukhopadhyay", "Samitha Samaranayake", "Aron Laszka"], "title": "MoveOD: Synthesizing Origin-Destination Commute Distribution from U.S. Census Data", "comment": "11 pages, 4 figures (including 3 validation charts and 1 map\n  visualization). The MOVEOD pipeline is an end-to-end automated system for\n  generating granular, time-dependent origin-destination (OD) datasets for any\n  U.S. county, leveraging ACS and LODES data. Code and lightweight browser\n  interface are publicly available at https://github.com/rishavsen1/move_od", "summary": "High-resolution origin-destination (OD) tables are essential for a wide\nspectrum of transportation applications, from modeling traffic and signal\ntiming optimization to congestion pricing and vehicle routing. However, outside\na handful of data rich cities, such data is rarely available. We introduce\nMOVEOD, an open-source pipeline that synthesizes public data into commuter OD\nflows with fine-grained spatial and temporal departure times for any county in\nthe United States. MOVEOD combines five open data sources: American Community\nSurvey (ACS) departure time and travel time distributions, Longitudinal\nEmployer-Household Dynamics (LODES) residence-to-workplace flows, county\ngeometries, road network information from OpenStreetMap (OSM), and building\nfootprints from OSM and Microsoft, into a single OD dataset. We use a\nconstrained sampling and integer-programming method to reconcile the OD dataset\nwith data from ACS and LODES. Our approach involves: (1) matching commuter\ntotals per origin zone, (2) aligning workplace destinations with employment\ndistributions, and (3) calibrating travel durations to ACS-reported commute\ntimes. This ensures the OD data accurately reflects commuting patterns. We\ndemonstrate the framework on Hamilton County, Tennessee, where we generate\nroughly 150,000 synthetic trips in minutes, which we feed into a benchmark\nsuite of classical and learning-based vehicle-routing algorithms. The MOVEOD\npipeline is an end-to-end automated system, enabling users to easily apply it\nacross the United States by giving only a county and a year; and it can be\nadapted to other countries with comparable census datasets. The source code and\na lightweight browser interface are publicly available.", "AI": {"tldr": "MOVEOD\u662f\u4e00\u4e2a\u5f00\u6e90\u7ba1\u9053\uff0c\u901a\u8fc7\u6574\u5408\u4e94\u79cd\u516c\u5171\u6570\u636e\u6e90\uff0c\u4e3a\u7f8e\u56fd\u4efb\u4f55\u53bf\u751f\u6210\u9ad8\u5206\u8fa8\u7387\u7684\u901a\u52e4\u8d77\u70b9-\u7ec8\u70b9(OD)\u6d41\u91cf\u6570\u636e\uff0c\u5305\u542b\u7cbe\u7ec6\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\u7ef4\u5ea6\u3002", "motivation": "\u9ad8\u5206\u8fa8\u7387OD\u8868\u5bf9\u4ea4\u901a\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9664\u5c11\u6570\u6570\u636e\u4e30\u5bcc\u7684\u57ce\u5e02\u5916\uff0c\u8fd9\u7c7b\u6570\u636e\u5f88\u5c11\u53ef\u7528\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u4e3a\u7f8e\u56fd\u5404\u5730\u751f\u6210\u51c6\u786e\u7684\u901a\u52e4OD\u6570\u636e\u3002", "method": "\u7ed3\u5408ACS\u51fa\u53d1\u65f6\u95f4\u548c\u65c5\u884c\u65f6\u95f4\u5206\u5e03\u3001LODES\u5c45\u4f4f\u5730-\u5de5\u4f5c\u5730\u6d41\u91cf\u3001\u53bf\u51e0\u4f55\u5f62\u72b6\u3001OpenStreetMap\u9053\u8def\u7f51\u7edc\u4fe1\u606f\u4ee5\u53caOSM\u548c\u5fae\u8f6f\u7684\u5efa\u7b51\u8db3\u8ff9\uff0c\u4f7f\u7528\u7ea6\u675f\u91c7\u6837\u548c\u6574\u6570\u89c4\u5212\u65b9\u6cd5\u534f\u8c03\u6570\u636e\u96c6\u3002", "result": "\u5728\u7530\u7eb3\u897f\u5dde\u6c49\u5bc6\u5c14\u987f\u53bf\u6f14\u793a\u4e86\u8be5\u6846\u67b6\uff0c\u5728\u51e0\u5206\u949f\u5185\u751f\u6210\u7ea615\u4e07\u6761\u5408\u6210\u884c\u7a0b\uff0c\u5e76\u7528\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u7ecf\u5178\u548c\u57fa\u4e8e\u5b66\u4e60\u7684\u8f66\u8f86\u8def\u5f84\u7b97\u6cd5\u3002", "conclusion": "MOVEOD\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u7528\u6237\u53ea\u9700\u63d0\u4f9b\u53bf\u548c\u5e74\u4efd\u5373\u53ef\u5728\u7f8e\u56fd\u5404\u5730\u8f7b\u677e\u5e94\u7528\uff0c\u5e76\u53ef\u9002\u5e94\u5177\u6709\u7c7b\u4f3c\u4eba\u53e3\u666e\u67e5\u6570\u636e\u96c6\u7684\u5176\u4ed6\u56fd\u5bb6\u3002"}}
{"id": "2510.18137", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.18137", "abs": "https://arxiv.org/abs/2510.18137", "authors": ["Hrishikesh Sathyanarayan", "Victor Vantilborgh", "Ian Abraham"], "title": "Quality Over Quantity: Curating Contact-Based Robot Datasets Improves Learning", "comment": null, "summary": "In this paper, we investigate the utility of datasets and whether more data\nor the 'right' data is advantageous for robot learning. In particular, we are\ninterested on quantifying the utility of contact-based data as contact holds\nsignificant information for robot learning. Our approach derives a\ncontact-aware objective function for learning object dynamics and shape from\npose and contact data. We show that the contact-aware Fisher-information metric\ncan be used to rank and curate contact-data based on how informative data is\nfor learning. In addition, we find that selecting a reduced dataset based on\nthis ranking improves the learning task while also making learning a\ndeterministic process. Interestingly, our results show that more data is not\nnecessarily advantageous, and rather, less but informative data can accelerate\nlearning, especially depending on the contact interactions. Last, we show how\nour metric can be used to provide initial guidance on data curation for\ncontact-based robot learning.", "AI": {"tldr": "\u7814\u7a76\u6570\u636e\u96c6\u6548\u7528\uff0c\u53d1\u73b0\u63a5\u89e6\u6570\u636e\u5bf9\u673a\u5668\u4eba\u5b66\u4e60\u5f88\u91cd\u8981\uff0c\u63d0\u51fa\u57fa\u4e8eFisher\u4fe1\u606f\u5ea6\u91cf\u7684\u6570\u636e\u7b5b\u9009\u65b9\u6cd5\uff0c\u8bc1\u660e\u5c11\u91cf\u4f46\u4fe1\u606f\u4e30\u5bcc\u7684\u6570\u636e\u6bd4\u5927\u91cf\u6570\u636e\u66f4\u6709\u6548\u3002", "motivation": "\u63a2\u8ba8\u673a\u5668\u4eba\u5b66\u4e60\u4e2d\u6570\u636e\u96c6\u7684\u6548\u7528\u95ee\u9898\uff0c\u7279\u522b\u662f\u63a5\u89e6\u6570\u636e\u7684\u91cd\u8981\u6027\uff0c\u56e0\u4e3a\u63a5\u89e6\u5305\u542b\u4e86\u5bf9\u673a\u5668\u4eba\u5b66\u4e60\u81f3\u5173\u91cd\u8981\u7684\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u63a5\u89e6\u611f\u77e5\u7684\u76ee\u6807\u51fd\u6570\uff0c\u4ece\u59ff\u6001\u548c\u63a5\u89e6\u6570\u636e\u4e2d\u5b66\u4e60\u7269\u4f53\u52a8\u529b\u5b66\u548c\u5f62\u72b6\uff0c\u4f7f\u7528\u63a5\u89e6\u611f\u77e5\u7684Fisher\u4fe1\u606f\u5ea6\u91cf\u6765\u8bc4\u4f30\u548c\u7b5b\u9009\u63a5\u89e6\u6570\u636e\u7684\u4ef7\u503c\u3002", "result": "\u57fa\u4e8e\u4fe1\u606f\u5ea6\u91cf\u7b5b\u9009\u7684\u7f29\u51cf\u6570\u636e\u96c6\u80fd\u6539\u5584\u5b66\u4e60\u4efb\u52a1\u5e76\u4f7f\u5b66\u4e60\u8fc7\u7a0b\u66f4\u786e\u5b9a\uff0c\u5c11\u91cf\u4f46\u4fe1\u606f\u4e30\u5bcc\u7684\u6570\u636e\u80fd\u52a0\u901f\u5b66\u4e60\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u63a5\u89e6\u4ea4\u4e92\u3002", "conclusion": "\u66f4\u591a\u6570\u636e\u4e0d\u4e00\u5b9a\u66f4\u597d\uff0c\u7cbe\u5fc3\u7b5b\u9009\u7684\u63a5\u89e6\u6570\u636e\u80fd\u66f4\u6709\u6548\u5730\u4fc3\u8fdb\u673a\u5668\u4eba\u5b66\u4e60\uff0c\u63d0\u51fa\u7684\u5ea6\u91cf\u65b9\u6cd5\u53ef\u4e3a\u63a5\u89e6\u6570\u636e\u7b5b\u9009\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2510.17931", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17931", "abs": "https://arxiv.org/abs/2510.17931", "authors": ["Andrew Bowne"], "title": "Attracting Commercial Artificial Intelligence Firms to Support National Security through Collaborative Contracts", "comment": "312 pages, 42 figures", "summary": "Unlike other military technologies driven by national security needs and\ndeveloped with federal funding, AI is predominantly funded and advanced by\ncommercial industry for civilian applications. However, there is a lack of\nunderstanding of the reasons commercial AI firms decide to work with the DoD or\nchoose to abstain from the defence market. This thesis argues that the contract\nlaw and procurement framework are among the most significant obstacles. This\nresearch indicates that the commercial AI industry actually views the DoD as an\nattractive customer. However, this attraction is despite the obstacles\npresented by traditional contract law and procurement practices used to solicit\nand award contracts. Drawing on social exchange theory, this thesis introduces\na theoretical framework, optimal buyer theory, to understand the factors that\ninfluence a commercial decision to engage with the DoD. Interviews from a\nsample of the participants explain why the AI industry holds such perceptions,\nopinions, and preferences about contracts generally and the DoD, specifically,\nin its role as a customer. This thesis concludes that commercial AI firms are\nattracted to contracts that are consistent with their business and technology\nconsiderations. Additionally, it develops best practices for leveraging\nexisting contract law, primarily other transaction authority, to align\ncontracting practices with commercial preferences and the machine learning\ndevelopment and deployment lifecycle.", "AI": {"tldr": "\u5546\u4e1aAI\u516c\u53f8\u5bf9\u56fd\u9632\u90e8\u4f5c\u4e3a\u5ba2\u6237\u611f\u5174\u8da3\uff0c\u4f46\u4f20\u7edf\u5408\u540c\u6cd5\u5f8b\u548c\u91c7\u8d2d\u6846\u67b6\u662f\u4e3b\u8981\u969c\u788d\u3002\u7814\u7a76\u63d0\u51fa\u6700\u4f18\u4e70\u5bb6\u7406\u8bba\u6765\u89e3\u91ca\u5546\u4e1a\u51b3\u7b56\u56e0\u7d20\uff0c\u5e76\u5efa\u8bae\u5229\u7528\u5176\u4ed6\u4ea4\u6613\u6388\u6743\u7b49\u73b0\u6709\u5408\u540c\u6cd5\u5f8b\u6765\u5339\u914d\u5546\u4e1a\u504f\u597d\u548c\u673a\u5668\u5b66\u4e60\u751f\u547d\u5468\u671f\u3002", "motivation": "\u4e86\u89e3\u5546\u4e1aAI\u516c\u53f8\u51b3\u5b9a\u4e0e\u56fd\u9632\u90e8\u5408\u4f5c\u6216\u56de\u907f\u56fd\u9632\u5e02\u573a\u7684\u539f\u56e0\uff0c\u7279\u522b\u662f\u5408\u540c\u6cd5\u5f8b\u548c\u91c7\u8d2d\u6846\u67b6\u4f5c\u4e3a\u4e3b\u8981\u969c\u788d\u7684\u5f71\u54cd\u3002", "method": "\u57fa\u4e8e\u793e\u4f1a\u4ea4\u6362\u7406\u8bba\u63d0\u51fa\u6700\u4f18\u4e70\u5bb6\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u53c2\u4e0e\u8005\u7684\u8bbf\u8c08\u6765\u89e3\u91caAI\u884c\u4e1a\u5bf9\u5408\u540c\u548c\u56fd\u9632\u90e8\u4f5c\u4e3a\u5ba2\u6237\u7684\u770b\u6cd5\u3001\u610f\u89c1\u548c\u504f\u597d\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5546\u4e1aAI\u516c\u53f8\u5b9e\u9645\u4e0a\u5c06\u56fd\u9632\u90e8\u89c6\u4e3a\u6709\u5438\u5f15\u529b\u7684\u5ba2\u6237\uff0c\u4f46\u8fd9\u79cd\u5438\u5f15\u529b\u53d7\u5230\u4f20\u7edf\u5408\u540c\u6cd5\u5f8b\u548c\u91c7\u8d2d\u5b9e\u8df5\u7684\u963b\u788d\u3002\u516c\u53f8\u66f4\u503e\u5411\u4e8e\u4e0e\u5176\u4e1a\u52a1\u548c\u6280\u672f\u8003\u8651\u4e00\u81f4\u7684\u5408\u540c\u3002", "conclusion": "\u5546\u4e1aAI\u516c\u53f8\u88ab\u4e0e\u5176\u4e1a\u52a1\u548c\u6280\u672f\u8003\u8651\u4e00\u81f4\u7684\u5408\u540c\u6240\u5438\u5f15\u3002\u7814\u7a76\u5f00\u53d1\u4e86\u5229\u7528\u73b0\u6709\u5408\u540c\u6cd5\u5f8b\uff08\u4e3b\u8981\u662f\u5176\u4ed6\u4ea4\u6613\u6388\u6743\uff09\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u4ee5\u4f7f\u5408\u540c\u5b9e\u8df5\u4e0e\u5546\u4e1a\u504f\u597d\u548c\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u90e8\u7f72\u751f\u547d\u5468\u671f\u4fdd\u6301\u4e00\u81f4\u3002"}}
{"id": "2510.17859", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.17859", "abs": "https://arxiv.org/abs/2510.17859", "authors": ["Abdelrahman Sayed Sayed", "Pierre-Jean Meyer", "Mohamed Ghazel"], "title": "Mixed Monotonicity Reachability Analysis of Neural ODE: A Trade-Off Between Tightness and Efficiency", "comment": "27 pages, 11 figures", "summary": "Neural ordinary differential equations (neural ODE) are powerful\ncontinuous-time machine learning models for depicting the behavior of complex\ndynamical systems, but their verification remains challenging due to limited\nreachability analysis tools adapted to them. We propose a novel interval-based\nreachability method that leverages continuous-time mixed monotonicity\ntechniques for dynamical systems to compute an over-approximation for the\nneural ODE reachable sets. By exploiting the geometric structure of full\ninitial sets and their boundaries via the homeomorphism property, our approach\nensures efficient bound propagation. By embedding neural ODE dynamics into a\nmixed monotone system, our interval-based reachability approach, implemented in\nTIRA with single-step, incremental, and boundary-based approaches, provides\nsound and computationally efficient over-approximations compared with CORA's\nzonotopes and NNV2.0 star set representations, while trading tightness for\nefficiency. This trade-off makes our method particularly suited for\nhigh-dimensional, real-time, and safety-critical applications. Applying mixed\nmonotonicity to neural ODE reachability analysis paves the way for lightweight\nformal analysis by leveraging the symmetric structure of monotone embeddings\nand the geometric simplicity of interval boxes, opening new avenues for\nscalable verification aligned with the symmetry and geometry of neural\nrepresentations. This novel approach is illustrated on two numerical examples\nof a spiral system and a fixed-point attractor system modeled as a neural ODE.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u533a\u95f4\u548c\u6df7\u5408\u5355\u8c03\u6027\u7684\u795e\u7ecfODE\u53ef\u8fbe\u6027\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u795e\u7ecfODE\u5d4c\u5165\u6df7\u5408\u5355\u8c03\u7cfb\u7edf\uff0c\u63d0\u4f9b\u9ad8\u6548\u4f46\u4fdd\u5b88\u7684\u8fc7\u8fd1\u4f3c\u53ef\u8fbe\u96c6\u8ba1\u7b97\u3002", "motivation": "\u795e\u7ecfODE\u662f\u5f3a\u5927\u7684\u8fde\u7eed\u65f6\u95f4\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u9002\u914d\u7684\u53ef\u8fbe\u6027\u5206\u6790\u5de5\u5177\uff0c\u5176\u9a8c\u8bc1\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5229\u7528\u8fde\u7eed\u65f6\u95f4\u6df7\u5408\u5355\u8c03\u6027\u6280\u672f\uff0c\u901a\u8fc7\u540c\u80da\u6027\u8d28\u5229\u7528\u521d\u59cb\u96c6\u53ca\u5176\u8fb9\u754c\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u5b9e\u73b0\u9ad8\u6548\u8fb9\u754c\u4f20\u64ad\u3002\u5728TIRA\u4e2d\u5b9e\u73b0\u4e86\u5355\u6b65\u3001\u589e\u91cf\u548c\u57fa\u4e8e\u8fb9\u754c\u7684\u65b9\u6cd5\u3002", "result": "\u4e0eCORA\u7684zonotopes\u548cNNV2.0\u661f\u96c6\u8868\u793a\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u8fc7\u8fd1\u4f3c\uff0c\u5728\u7d27\u5bc6\u5ea6\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "conclusion": "\u5c06\u6df7\u5408\u5355\u8c03\u6027\u5e94\u7528\u4e8e\u795e\u7ecfODE\u53ef\u8fbe\u6027\u5206\u6790\u4e3a\u8f7b\u91cf\u7ea7\u5f62\u5f0f\u5206\u6790\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u7279\u522b\u9002\u5408\u9ad8\u7ef4\u3001\u5b9e\u65f6\u548c\u5b89\u5168\u5173\u952e\u5e94\u7528\u3002"}}
{"id": "2510.18032", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.18032", "abs": "https://arxiv.org/abs/2510.18032", "authors": ["Zhenyu Bi", "Meng Lu", "Yang Li", "Swastik Roy", "Weijie Guan", "Morteza Ziyadi", "Xuan Wang"], "title": "OPTAGENT: Optimizing Multi-Agent LLM Interactions Through Verbal Reinforcement Learning for Enhanced Reasoning", "comment": "8 pages for main content", "summary": "Large Language Models (LLMs) have shown remarkable reasoning capabilities in\nmathematical and scientific tasks. To enhance complex reasoning, multi-agent\nsystems have been proposed to harness the collective intelligence of LLM\nagents. However, existing collaboration structures are either predefined or\nrely on majority voting or round-table debates, which can suppress correct but\nless dominant agent contributions. Recent approaches model multi-agent systems\nas graph networks but optimize purely for agent performance, neglecting the\nquality of interactions. We hypothesize that effective agent communication is\ncrucial for multi-agent reasoning and that debating quality plays a significant\nrole. To address this, we propose $\\ours$, a multi-agent verbal reinforcement\nlearning algorithm that dynamically constructs and refines multi-agent\ncollaboration structures. Our method defines action spaces and a feedback\nmechanism that evaluates communication robustness and coherence throughout the\ndebate. The final decision is achieved through a majority vote over all the\nagents. We assess $\\ours$ on various reasoning tasks, including mathematical\nreasoning, creative writing, scientific reasoning, and numerical sorting.\nResults demonstrate that our approach significantly outperforms single-agent\nprompting methods and state-of-the-art multi-agent frameworks on diverse tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u53e3\u5934\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u6784\u5efa\u548c\u4f18\u5316\u534f\u4f5c\u7ed3\u6784\u6765\u63d0\u5347\u591a\u667a\u80fd\u4f53\u63a8\u7406\u80fd\u529b\uff0c\u5728\u591a\u79cd\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8981\u4e48\u91c7\u7528\u9884\u5b9a\u4e49\u7ed3\u6784\uff0c\u8981\u4e48\u4f9d\u8d56\u591a\u6570\u6295\u7968\u6216\u5706\u684c\u8fa9\u8bba\uff0c\u8fd9\u4f1a\u538b\u5236\u6b63\u786e\u4f46\u975e\u4e3b\u5bfc\u7684\u667a\u80fd\u4f53\u8d21\u732e\u3002\u4f5c\u8005\u5047\u8bbe\u6709\u6548\u7684\u667a\u80fd\u4f53\u901a\u4fe1\u5bf9\u591a\u667a\u80fd\u4f53\u63a8\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u53e3\u5934\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5b9a\u4e49\u52a8\u4f5c\u7a7a\u95f4\u548c\u53cd\u9988\u673a\u5236\u6765\u8bc4\u4f30\u8fa9\u8bba\u8fc7\u7a0b\u4e2d\u7684\u901a\u4fe1\u9c81\u68d2\u6027\u548c\u8fde\u8d2f\u6027\uff0c\u6700\u7ec8\u901a\u8fc7\u6240\u6709\u667a\u80fd\u4f53\u7684\u591a\u6570\u6295\u7968\u505a\u51fa\u51b3\u7b56\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u3001\u521b\u610f\u5199\u4f5c\u3001\u79d1\u5b66\u63a8\u7406\u548c\u6570\u503c\u6392\u5e8f\u7b49\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u63d0\u793a\u65b9\u6cd5\u548c\u6700\u5148\u8fdb\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u3002", "conclusion": "\u52a8\u6001\u4f18\u5316\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7ed3\u6784\u80fd\u591f\u6709\u6548\u63d0\u5347\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u667a\u80fd\u4f53\u901a\u4fe1\u8d28\u91cf\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.18316", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18316", "abs": "https://arxiv.org/abs/2510.18316", "authors": ["Chengshu Li", "Mengdi Xu", "Arpit Bahety", "Hang Yin", "Yunfan Jiang", "Huang Huang", "Josiah Wong", "Sujay Garlanka", "Cem Gokmen", "Ruohan Zhang", "Weiyu Liu", "Jiajun Wu", "Roberto Mart\u00edn-Mart\u00edn", "Li Fei-Fei"], "title": "MoMaGen: Generating Demonstrations under Soft and Hard Constraints for Multi-Step Bimanual Mobile Manipulation", "comment": "Project website: momagen.github.io. The first four authors contribute\n  equally", "summary": "Imitation learning from large-scale, diverse human demonstrations has proven\neffective for training robots, but collecting such data is costly and\ntime-consuming. This challenge is amplified for multi-step bimanual mobile\nmanipulation, where humans must teleoperate both a mobile base and two\nhigh-degree-of-freedom arms. Prior automated data generation frameworks have\naddressed static bimanual manipulation by augmenting a few human demonstrations\nin simulation, but they fall short for mobile settings due to two key\nchallenges: (1) determining base placement to ensure reachability, and (2)\npositioning the camera to provide sufficient visibility for visuomotor\npolicies. To address these issues, we introduce MoMaGen, which formulates data\ngeneration as a constrained optimization problem that enforces hard constraints\n(e.g., reachability) while balancing soft constraints (e.g., visibility during\nnavigation). This formulation generalizes prior approaches and provides a\nprincipled foundation for future methods. We evaluate MoMaGen on four\nmulti-step bimanual mobile manipulation tasks and show that it generates\nsignificantly more diverse datasets than existing methods. Leveraging this\ndiversity, MoMaGen can train successful imitation learning policies from a\nsingle source demonstration, and these policies can be fine-tuned with as few\nas 40 real-world demonstrations to achieve deployment on physical robotic\nhardware. More details are available at our project page: momagen.github.io.", "AI": {"tldr": "MoMaGen\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6b65\u9aa4\u53cc\u624b\u79fb\u52a8\u64cd\u4f5c\u7684\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u7ea6\u675f\u4f18\u5316\u65b9\u6cd5\u89e3\u51b3\u57fa\u5ea7\u653e\u7f6e\u548c\u76f8\u673a\u5b9a\u4f4d\u95ee\u9898\uff0c\u80fd\u591f\u4ece\u5355\u4e00\u6f14\u793a\u751f\u6210\u591a\u6837\u5316\u6570\u636e\u96c6\uff0c\u663e\u8457\u51cf\u5c11\u771f\u5b9e\u4e16\u754c\u6570\u636e\u6536\u96c6\u9700\u6c42\u3002", "motivation": "\u4ece\u5927\u89c4\u6a21\u4eba\u7c7b\u6f14\u793a\u4e2d\u5b66\u4e60\u5bf9\u673a\u5668\u4eba\u8bad\u7ec3\u6709\u6548\uff0c\u4f46\u6536\u96c6\u591a\u6b65\u9aa4\u53cc\u624b\u79fb\u52a8\u64cd\u4f5c\u6570\u636e\u6210\u672c\u9ad8\u6602\u4e14\u8017\u65f6\u3002\u73b0\u6709\u81ea\u52a8\u5316\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5728\u79fb\u52a8\u573a\u666f\u4e2d\u5b58\u5728\u57fa\u5ea7\u653e\u7f6e\u548c\u76f8\u673a\u5b9a\u4f4d\u4e24\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u5c06\u6570\u636e\u751f\u6210\u5efa\u6a21\u4e3a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u5f3a\u5236\u6267\u884c\u786c\u7ea6\u675f\uff08\u5982\u53ef\u8fbe\u6027\uff09\u540c\u65f6\u5e73\u8861\u8f6f\u7ea6\u675f\uff08\u5982\u5bfc\u822a\u671f\u95f4\u7684\u53ef\u89c1\u6027\uff09\uff0c\u4e3a\u591a\u6b65\u9aa4\u53cc\u624b\u79fb\u52a8\u64cd\u4f5c\u63d0\u4f9b\u539f\u5219\u6027\u6570\u636e\u751f\u6210\u6846\u67b6\u3002", "result": "\u5728\u56db\u4e2a\u591a\u6b65\u9aa4\u53cc\u624b\u79fb\u52a8\u64cd\u4f5c\u4efb\u52a1\u4e0a\u8bc4\u4f30\uff0cMoMaGen\u751f\u6210\u7684\u6570\u636e\u96c6\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u591a\u6837\u5316\uff0c\u80fd\u591f\u4ece\u5355\u4e00\u6e90\u6f14\u793a\u8bad\u7ec3\u6210\u529f\u7684\u6a21\u4eff\u5b66\u4e60\u7b56\u7565\uff0c\u4ec5\u970040\u4e2a\u771f\u5b9e\u4e16\u754c\u6f14\u793a\u5373\u53ef\u5fae\u8c03\u90e8\u7f72\u5230\u7269\u7406\u673a\u5668\u4eba\u786c\u4ef6\u3002", "conclusion": "MoMaGen\u4e3a\u89e3\u51b3\u591a\u6b65\u9aa4\u53cc\u624b\u79fb\u52a8\u64cd\u4f5c\u7684\u6570\u636e\u751f\u6210\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5bf9\u6602\u8d35\u4eba\u7c7b\u6f14\u793a\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u5b9e\u73b0\u4e86\u4ece\u6a21\u62df\u5230\u771f\u5b9e\u4e16\u754c\u7684\u6210\u529f\u8fc1\u79fb\u3002"}}
{"id": "2510.17938", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.17938", "abs": "https://arxiv.org/abs/2510.17938", "authors": ["Ana En\u00e9riz Janeiro", "Karina Pitombeira Pereira", "Julio Mayol", "Javier Crespo", "Fernando Carballo", "Juan B. Cabello", "Manel Ramos-Casals", "Bibiana P\u00e9rez Corbacho", "Juan Turnes"], "title": "The Integration of Artificial Intelligence in Undergraduate Medical Education in Spain: Descriptive Analysis and International Perspectives", "comment": "1 figure, 4 main tables, 2 supplementary tables", "summary": "AI is transforming medical practice and redefining the competencies that\nfuture healthcare professionals need to master. Despite international\nrecommendations, the integration of AI into Medicine curricula in Spain had not\nbeen systematically evaluated until now. A cross-sectional study\n(July-September 2025) including Spanish universities offering the official\ndegree in Medicine, according to the 'Register of Universities, Centers and\nDegrees (Registro de Universidades, Centros y T\\'itulos RUCT)'. Curricula and\npublicly available institutional documentation were reviewed to identify\ncourses and competencies related to AI in the 2025-2026 academic year. The\nanalysis was performed using descriptive statistics. Of the 52 universities\nanalyzed, ten (19.2%) offer specific AI courses, whereas 36 (69.2%) include no\nrelated content. Most of the identified courses are elective, with a credit\nload ranging from three to six ECTS, representing on average 1.17% of the total\n360 credits of the degree. The University of Ja\\'en is the only institution\noffering a compulsory course with AI content. The territorial analysis reveals\nmarked disparities: Andalusia leads with 55.5% of its universities\nincorporating AI training, while several communities lack any initiative in\nthis area. The integration of AI into the medical degree in Spain is incipient,\nfragmented, and uneven, with a low weight in ECTS. The limited training load\nand predominance of elective courses restrict the preparation of future\nphysicians to practice in a healthcare environment increasingly mediated by AI.\nThe findings support the establishment of minimum standards and national\nmonitoring of indicators.", "AI": {"tldr": "\u897f\u73ed\u7259\u533b\u5b66\u5b66\u4f4d\u4e2dAI\u6574\u5408\u7a0b\u5ea6\u7814\u7a76\uff1a52\u6240\u5927\u5b66\u4e2d\u4ec519.2%\u63d0\u4f9bAI\u8bfe\u7a0b\uff0c69.2%\u65e0\u76f8\u5173\u5185\u5bb9\uff0c\u8bfe\u7a0b\u591a\u4e3a\u9009\u4fee\u4e14\u5b66\u5206\u5360\u6bd4\u4f4e\uff08\u5e73\u57471.17%\uff09\uff0c\u5b58\u5728\u660e\u663e\u5730\u57df\u5dee\u5f02\u3002", "motivation": "\u8bc4\u4f30\u897f\u73ed\u7259\u533b\u5b66\u8bfe\u7a0b\u4e2dAI\u6574\u5408\u73b0\u72b6\uff0c\u5c3d\u7ba1\u6709\u56fd\u9645\u5efa\u8bae\uff0c\u4f46\u6b64\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u4ee5\u4e86\u89e3\u672a\u6765\u533b\u7597\u4e13\u4e1a\u4eba\u5458\u7684AI\u80fd\u529b\u57f9\u517b\u60c5\u51b5\u3002", "method": "\u6a2a\u65ad\u9762\u7814\u7a76\uff082025\u5e747-9\u6708\uff09\uff0c\u5206\u6790\u897f\u73ed\u7259\u5b98\u65b9\u533b\u5b66\u5b66\u4f4d\u5927\u5b66\u7684\u8bfe\u7a0b\u548c\u673a\u6784\u6587\u4ef6\uff0c\u4f7f\u7528\u63cf\u8ff0\u6027\u7edf\u8ba1\u8bc6\u522b2025-2026\u5b66\u5e74AI\u76f8\u5173\u8bfe\u7a0b\u548c\u80fd\u529b\u3002", "result": "52\u6240\u5927\u5b66\u4e2d10\u6240\uff0819.2%\uff09\u63d0\u4f9bAI\u8bfe\u7a0b\uff0c36\u6240\uff0869.2%\uff09\u65e0\u76f8\u5173\u5185\u5bb9\uff1b\u8bfe\u7a0b\u591a\u4e3a\u9009\u4fee\uff083-6\u5b66\u5206\uff09\uff0c\u4ec5\u54c8\u6069\u5927\u5b66\u6709\u5fc5\u4fee\u8bfe\uff1b\u5b89\u8fbe\u5362\u897f\u4e9a\u9886\u5148\uff0855.5%\uff09\uff0c\u90e8\u5206\u5730\u533a\u65e0AI\u57f9\u8bad\u3002", "conclusion": "\u897f\u73ed\u7259\u533b\u5b66\u5b66\u4f4dAI\u6574\u5408\u5904\u4e8e\u8d77\u6b65\u9636\u6bb5\uff0c\u96f6\u6563\u4e14\u4e0d\u5747\u8861\uff0c\u5b66\u5206\u6743\u91cd\u4f4e\uff1b\u6709\u9650\u7684\u57f9\u8bad\u91cf\u548c\u9009\u4fee\u8bfe\u4e3b\u5bfc\u9650\u5236\u4e86\u672a\u6765\u533b\u751f\u5728AI\u65e5\u76ca\u666e\u53ca\u7684\u533b\u7597\u73af\u5883\u4e2d\u7684\u51c6\u5907\uff1b\u5efa\u8bae\u5efa\u7acb\u6700\u4f4e\u6807\u51c6\u548c\u5168\u56fd\u76d1\u6d4b\u6307\u6807\u3002"}}
{"id": "2510.17860", "categories": ["eess.SY", "cs.CV", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.17860", "abs": "https://arxiv.org/abs/2510.17860", "authors": ["Zenghuang Fu", "Xiaofeng Han", "Mingda Jia", "Jin ming Yang", "Qi Zeng", "Muyang Zahng", "Changwei Wang", "Weiliang Meng", "Xiaopeng Zhang"], "title": "DMTrack: Deformable State-Space Modeling for UAV Multi-Object Tracking with Kalman Fusion and Uncertainty-Aware Association", "comment": null, "summary": "Multi-object tracking (MOT) from unmanned aerial vehicles (UAVs) presents\nunique challenges due to unpredictable object motion, frequent occlusions, and\nlimited appearance cues inherent to aerial viewpoints. These issues are further\nexacerbated by abrupt UAV movements, leading to unreliable trajectory\nestimation and identity switches. Conventional motion models, such as Kalman\nfilters or static sequence encoders, often fall short in capturing both linear\nand non-linear dynamics under such conditions. To tackle these limitations, we\npropose DMTrack, a deformable motion tracking framework tailored for UAV-based\nMOT. Our DMTrack introduces three key components: DeformMamba, a deformable\nstate-space predictor that dynamically aggregates historical motion states for\nadaptive trajectory modeling; MotionGate, a lightweight gating module that\nfuses Kalman and Mamba predictions based on motion context and uncertainty; and\nan uncertainty-aware association strategy that enhances identity preservation\nby aligning motion trends with prediction confidence. Extensive experiments on\nthe VisDrone-MOT and UAVDT benchmarks demonstrate that our DMTrack achieves\nstate-of-the-art performance in identity consistency and tracking accuracy,\nparticularly under high-speed and non-linear motion. Importantly, our method\noperates without appearance models and maintains competitive efficiency,\nhighlighting its practicality for robust UAV-based tracking.", "AI": {"tldr": "DMTrack\u662f\u4e00\u4e2a\u9488\u5bf9\u65e0\u4eba\u673a\u591a\u76ee\u6807\u8ddf\u8e2a\u7684\u53d8\u5f62\u8fd0\u52a8\u8ddf\u8e2a\u6846\u67b6\uff0c\u901a\u8fc7DeformMamba\u52a8\u6001\u805a\u5408\u5386\u53f2\u8fd0\u52a8\u72b6\u6001\u3001MotionGate\u878d\u5408\u5361\u5c14\u66fc\u548cMamba\u9884\u6d4b\u3001\u4ee5\u53ca\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u5173\u8054\u7b56\u7565\uff0c\u5728\u9ad8\u901f\u548c\u975e\u7ebf\u6027\u8fd0\u52a8\u573a\u666f\u4e0b\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u8ddf\u8e2a\u6027\u80fd\u3002", "motivation": "\u65e0\u4eba\u673a\u591a\u76ee\u6807\u8ddf\u8e2a\u9762\u4e34\u7269\u4f53\u8fd0\u52a8\u4e0d\u53ef\u9884\u6d4b\u3001\u9891\u7e41\u906e\u6321\u548c\u5916\u89c2\u7ebf\u7d22\u6709\u9650\u7b49\u6311\u6218\uff0c\u4f20\u7edf\u8fd0\u52a8\u6a21\u578b\u96be\u4ee5\u6355\u6349\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u52a8\u6001\uff0c\u5bfc\u81f4\u8f68\u8ff9\u4f30\u8ba1\u4e0d\u53ef\u9760\u548c\u8eab\u4efd\u5207\u6362\u95ee\u9898\u3002", "method": "\u63d0\u51faDMTrack\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1aDeformMamba\uff08\u53d8\u5f62\u72b6\u6001\u7a7a\u95f4\u9884\u6d4b\u5668\uff09\u3001MotionGate\uff08\u8f7b\u91cf\u7ea7\u95e8\u63a7\u6a21\u5757\uff09\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u5173\u8054\u7b56\u7565\uff0c\u65e0\u9700\u5916\u89c2\u6a21\u578b\u3002", "result": "\u5728VisDrone-MOT\u548cUAVDT\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDMTrack\u5728\u8eab\u4efd\u4e00\u81f4\u6027\u548c\u8ddf\u8e2a\u7cbe\u5ea6\u65b9\u9762\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u9ad8\u901f\u548c\u975e\u7ebf\u6027\u8fd0\u52a8\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u5916\u89c2\u6a21\u578b\uff0c\u4fdd\u6301\u7ade\u4e89\u6027\u6548\u7387\uff0c\u7a81\u663e\u4e86\u5176\u5728\u9c81\u68d2\u65e0\u4eba\u673a\u8ddf\u8e2a\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.18040", "categories": ["cs.AI", "cs.CL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.18040", "abs": "https://arxiv.org/abs/2510.18040", "authors": ["Alexander Boldachev"], "title": "Subject-Event Ontology Without Global Time: Foundations and Execution Semantics", "comment": "32 pages", "summary": "A formalization of a subject-event ontology is proposed for modeling complex\ndynamic systems without reliance on global time. Key principles: (1) event as\nan act of fixation - a subject discerns and fixes changes according to models\n(conceptual templates) available to them; (2) causal order via happens-before -\nthe order of events is defined by explicit dependencies, not timestamps; (3)\nmaking the ontology executable via a declarative dataflow mechanism, ensuring\ndeterminism; (4) models as epistemic filters - a subject can only fix what\nfalls under its known concepts and properties; (5) presumption of truth - the\ndeclarative content of an event is available for computation from the moment of\nfixation, without external verification. The formalization includes nine axioms\n(A1-A9), ensuring the correctness of executable ontologies: monotonicity of\nhistory (I1), acyclicity of causality (I2), traceability (I3). Special\nattention is given to the model-based approach (A9): event validation via\nschemas, actor authorization, automatic construction of causal chains (W3)\nwithout global time. Practical applicability is demonstrated on the boldsea\nsystem - a workflow engine for executable ontologies, where the theoretical\nconstructs are implemented in BSL (Boldsea Semantic Language). The\nformalization is applicable to distributed systems, microservice architectures,\nDLT platforms, and multiperspectivity scenarios (conflicting facts from\ndifferent subjects).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e3b\u4f53-\u4e8b\u4ef6\u7684\u672c\u4f53\u8bba\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u6ca1\u6709\u5168\u5c40\u65f6\u95f4\u7684\u6761\u4ef6\u4e0b\u5efa\u6a21\u590d\u6742\u52a8\u6001\u7cfb\u7edf\uff0c\u901a\u8fc7\u58f0\u660e\u5f0f\u6570\u636e\u6d41\u673a\u5236\u786e\u4fdd\u786e\u5b9a\u6027\u3002", "motivation": "\u89e3\u51b3\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u4e2d\u5bf9\u5168\u5c40\u65f6\u95f4\u7684\u4f9d\u8d56\u95ee\u9898\uff0c\u652f\u6301\u5206\u5e03\u5f0f\u7cfb\u7edf\u3001\u5fae\u670d\u52a1\u67b6\u6784\u548c\u591a\u65b9\u89c6\u89d2\u573a\u666f\u4e2d\u7684\u4e8b\u4ef6\u5efa\u6a21\u3002", "method": "\u57fa\u4e8e\u4e5d\u4e2a\u516c\u7406\uff08A1-A9\uff09\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u5305\u62ec\u4e8b\u4ef6\u4f5c\u4e3a\u56fa\u5b9a\u884c\u4e3a\u3001\u57fa\u4e8ehappens-before\u7684\u56e0\u679c\u987a\u5e8f\u3001\u6a21\u578b\u4f5c\u4e3a\u8ba4\u77e5\u8fc7\u6ee4\u5668\u7b49\u6838\u5fc3\u539f\u5219\uff0c\u5e76\u901a\u8fc7boldsea\u7cfb\u7edf\u5b9e\u73b0\u53ef\u6267\u884c\u672c\u4f53\u3002", "result": "\u5f00\u53d1\u4e86boldsea\u7cfb\u7edf\u4f5c\u4e3a\u53ef\u6267\u884c\u672c\u4f53\u7684\u5de5\u4f5c\u6d41\u5f15\u64ce\uff0c\u7406\u8bba\u6784\u9020\u5728BSL\u8bed\u8a00\u4e2d\u5b9e\u73b0\uff0c\u786e\u4fdd\u4e86\u5386\u53f2\u5355\u8c03\u6027\u3001\u56e0\u679c\u65e0\u73af\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\u3002", "conclusion": "\u8be5\u5f62\u5f0f\u5316\u65b9\u6cd5\u4e3a\u6ca1\u6709\u5168\u5c40\u65f6\u95f4\u7684\u590d\u6742\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u7cfb\u7edf\u3001\u5fae\u670d\u52a1\u67b6\u6784\u548c\u591a\u65b9\u89c6\u89d2\u573a\u666f\u3002"}}
{"id": "2510.18337", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.18337", "abs": "https://arxiv.org/abs/2510.18337", "authors": ["Wenhui Huang", "Changhe Chen", "Han Qi", "Chen Lv", "Yilun Du", "Heng Yang"], "title": "MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning", "comment": null, "summary": "Integrating visual-language instructions into visuomotor policies is gaining\nmomentum in robot learning for enhancing open-world generalization. Despite\npromising advances, existing approaches face two challenges: limited language\nsteerability when no generated reasoning is used as a condition, or significant\ninference latency when reasoning is incorporated.In this work, we introduce\nMoTVLA, a mixture-of-transformers (MoT)-based vision-language-action (VLA)\nmodel that integrates fast-slow unified reasoning with behavior policy\nlearning. MoTVLA preserves the general intelligence of pre-trained VLMs\n(serving as the generalist) for tasks such as perception, scene understanding,\nand semantic planning, while incorporating a domain expert, a second\ntransformer that shares knowledge with the pretrained VLM, to generate\ndomain-specific fast reasoning (e.g., robot motion decomposition), thereby\nimproving policy execution efficiency. By conditioning the action expert on\ndecomposed motion instructions, MoTVLA can learn diverse behaviors and\nsubstantially improve language steerability. Extensive evaluations across\nnatural language processing benchmarks, robotic simulation environments, and\nreal-world experiments confirm the superiority of MoTVLA in both fast-slow\nreasoning and manipulation task performance.", "AI": {"tldr": "MoTVLA\u662f\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u53d8\u6362\u5668\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff0c\u901a\u8fc7\u96c6\u6210\u5feb\u6162\u63a8\u7406\u4e0e\u884c\u4e3a\u7b56\u7565\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u8bed\u8a00\u53ef\u64cd\u63a7\u6027\u4e0d\u8db3\u6216\u63a8\u7406\u5ef6\u8fdf\u9ad8\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u673a\u5668\u4eba\u5b66\u4e60\u4e2d\u9762\u4e34\u4e24\u4e2a\u6311\u6218\uff1a\u5f53\u4e0d\u4f7f\u7528\u751f\u6210\u7684\u63a8\u7406\u4f5c\u4e3a\u6761\u4ef6\u65f6\uff0c\u8bed\u8a00\u53ef\u64cd\u63a7\u6027\u6709\u9650\uff1b\u6216\u8005\u5f53\u5f15\u5165\u63a8\u7406\u65f6\uff0c\u63a8\u7406\u5ef6\u8fdf\u663e\u8457\u589e\u52a0\u3002", "method": "MoTVLA\u7ed3\u5408\u4e86\u9884\u8bad\u7ec3VLM\u7684\u901a\u7528\u667a\u80fd\uff08\u4f5c\u4e3a\u901a\u624d\uff09\u548c\u9886\u57df\u4e13\u5bb6\uff08\u7b2c\u4e8c\u4e2a\u53d8\u6362\u5668\uff09\uff0c\u540e\u8005\u751f\u6210\u9886\u57df\u7279\u5b9a\u7684\u5feb\u901f\u63a8\u7406\uff08\u5982\u673a\u5668\u4eba\u8fd0\u52a8\u5206\u89e3\uff09\uff0c\u5e76\u901a\u8fc7\u5c06\u52a8\u4f5c\u4e13\u5bb6\u57fa\u4e8e\u5206\u89e3\u7684\u8fd0\u52a8\u6307\u4ee4\u6765\u5b66\u4e60\u591a\u6837\u5316\u884c\u4e3a\u3002", "result": "\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u57fa\u51c6\u3001\u673a\u5668\u4eba\u4eff\u771f\u73af\u5883\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8bc1\u5b9e\u4e86MoTVLA\u5728\u5feb\u6162\u63a8\u7406\u548c\u64cd\u4f5c\u4efb\u52a1\u6027\u80fd\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "MoTVLA\u901a\u8fc7\u96c6\u6210\u5feb\u6162\u7edf\u4e00\u63a8\u7406\u4e0e\u884c\u4e3a\u7b56\u7565\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bed\u8a00\u53ef\u64cd\u63a7\u6027\u548c\u7b56\u7565\u6267\u884c\u6548\u7387\uff0c\u5728\u591a\u4e2a\u8bc4\u4f30\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.17942", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17942", "abs": "https://arxiv.org/abs/2510.17942", "authors": ["Grant McKenzie", "Krzysztof Janowicz", "Carsten Kessler"], "title": "Trust in foundation models and GenAI: A geographic perspective", "comment": null, "summary": "Large-scale pre-trained machine learning models have reshaped our\nunderstanding of artificial intelligence across numerous domains, including our\nown field of geography. As with any new technology, trust has taken on an\nimportant role in this discussion. In this chapter, we examine the multifaceted\nconcept of trust in foundation models, particularly within a geographic\ncontext. As reliance on these models increases and they become relied upon for\ncritical decision-making, trust, while essential, has become a fractured\nconcept. Here we categorize trust into three types: epistemic trust in the\ntraining data, operational trust in the model's functionality, and\ninterpersonal trust in the model developers. Each type of trust brings with it\nunique implications for geographic applications. Topics such as cultural\ncontext, data heterogeneity, and spatial relationships are fundamental to the\nspatial sciences and play an important role in developing trust. The chapter\ncontinues with a discussion of the challenges posed by different forms of\nbiases, the importance of transparency and explainability, and ethical\nresponsibilities in model development. Finally, the novel perspective of\ngeographic information scientists is emphasized with a call for further\ntransparency, bias mitigation, and regionally-informed policies. Simply put,\nthis chapter aims to provide a conceptual starting point for researchers,\npractitioners, and policy-makers to better understand trust in (generative)\nGeoAI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5730\u7406AI\u4e2d\u4fe1\u4efb\u7684\u6982\u5ff5\uff0c\u5c06\u4fe1\u4efb\u5206\u4e3a\u4e09\u79cd\u7c7b\u578b\uff1a\u8bad\u7ec3\u6570\u636e\u7684\u8ba4\u77e5\u4fe1\u4efb\u3001\u6a21\u578b\u529f\u80fd\u7684\u64cd\u4f5c\u4fe1\u4efb\u548c\u6a21\u578b\u5f00\u53d1\u8005\u7684\u4eba\u9645\u4fe1\u4efb\uff0c\u5e76\u8ba8\u8bba\u4e86\u5730\u7406\u5e94\u7528\u4e2d\u7684\u6311\u6218\u548c\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u5730\u7406\u9886\u57df\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u7279\u522b\u662f\u5728\u5173\u952e\u51b3\u7b56\u4e2d\u7684\u4f9d\u8d56\u589e\u52a0\uff0c\u4fe1\u4efb\u6210\u4e3a\u4e00\u4e2a\u91cd\u8981\u4f46\u590d\u6742\u7684\u6982\u5ff5\uff0c\u9700\u8981\u5728\u5730\u7406\u80cc\u666f\u4e0b\u8fdb\u884c\u6df1\u5165\u5206\u6790\u3002", "method": "\u901a\u8fc7\u6982\u5ff5\u5206\u6790\u6846\u67b6\uff0c\u5c06\u4fe1\u4efb\u5206\u7c7b\u4e3a\u4e09\u79cd\u7c7b\u578b\uff0c\u5e76\u63a2\u8ba8\u6bcf\u79cd\u4fe1\u4efb\u7c7b\u578b\u5728\u5730\u7406\u5e94\u7528\u4e2d\u7684\u5177\u4f53\u542b\u4e49\u548c\u6311\u6218\u3002", "result": "\u63d0\u51fa\u4e86\u5730\u7406AI\u4e2d\u4fe1\u4efb\u7684\u4e09\u7ef4\u5206\u7c7b\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u6587\u5316\u80cc\u666f\u3001\u6570\u636e\u5f02\u8d28\u6027\u548c\u7a7a\u95f4\u5173\u7cfb\u7b49\u5730\u7406\u7279\u5b9a\u56e0\u7d20\u5bf9\u4fe1\u4efb\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u504f\u89c1\u3001\u900f\u660e\u5ea6\u548c\u4f26\u7406\u8d23\u4efb\u7b49\u6311\u6218\u3002", "conclusion": "\u5f3a\u8c03\u9700\u8981\u8fdb\u4e00\u6b65\u900f\u660e\u5ea6\u3001\u504f\u89c1\u7f13\u89e3\u548c\u533a\u57df\u77e5\u60c5\u653f\u7b56\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u3001\u4ece\u4e1a\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u7406\u89e3\u751f\u6210\u5f0f\u5730\u7406AI\u4e2d\u4fe1\u4efb\u7684\u6982\u5ff5\u8d77\u70b9\u3002"}}
{"id": "2510.17861", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.17861", "abs": "https://arxiv.org/abs/2510.17861", "authors": ["Zeeshan Kaleem", "Muhammad Afaq", "Chau Yuen", "Octavia A. Dobre", "John M. Cioffi"], "title": "Quantum-Driven State-Reduction for Reliable UAV Trajectory Optimization in Low-Altitude Networks", "comment": null, "summary": "This letter introduces a Graph-Condensed Quantum-Inspired Placement (GC-QAP)\nframework for reliability-driven trajectory optimization in Uncrewed Aerial\nVehicle (UAV) assisted low-altitude wireless networks. The dense waypoint graph\nis condensed using probabilistic quantum-annealing to preserve\ninterference-aware centroids while reducing the control state space and\nmaintaining link-quality. The resulting problem is formulated as a\npriority-aware Markov decision process and solved using epsilon-greedy\noff-policy Q-learning, considering UAV kinematic and flight corridor\nconstraints. Unlike complex continuous-action reinforcement learning\napproaches, GC-QAP achieves stable convergence and low outage with\nsubstantially and lower computational cost compared to baseline schemes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u538b\u7f29\u91cf\u5b50\u542f\u53d1\u5f0f\u5e03\u5c40\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u8f85\u52a9\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u53ef\u9760\u6027\u9a71\u52a8\u8f68\u8ff9\u4f18\u5316\uff0c\u901a\u8fc7\u91cf\u5b50\u9000\u706b\u538b\u7f29\u8def\u70b9\u56fe\uff0c\u4f7f\u7528Q\u5b66\u4e60\u89e3\u51b3\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u7a33\u5b9a\u6536\u655b\u548c\u4f4e\u4e2d\u65ad\u7387\u3002", "motivation": "\u89e3\u51b3\u65e0\u4eba\u673a\u8f85\u52a9\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u4e2d\u8f68\u8ff9\u4f18\u5316\u7684\u590d\u6742\u6027\u95ee\u9898\uff0c\u9700\u8981\u5728\u4fdd\u6301\u94fe\u8def\u8d28\u91cf\u7684\u540c\u65f6\u51cf\u5c11\u63a7\u5236\u72b6\u6001\u7a7a\u95f4\uff0c\u5e76\u8003\u8651\u65e0\u4eba\u673a\u8fd0\u52a8\u5b66\u548c\u98de\u884c\u8d70\u5eca\u7ea6\u675f\u3002", "method": "\u4f7f\u7528\u6982\u7387\u91cf\u5b50\u9000\u706b\u538b\u7f29\u5bc6\u96c6\u8def\u70b9\u56fe\uff0c\u4fdd\u7559\u5e72\u6270\u611f\u77e5\u7684\u8d28\u5fc3\uff1b\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u4f18\u5148\u7ea7\u611f\u77e5\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u91c7\u7528epsilon-greedy\u79bb\u7b56\u7565Q\u5b66\u4e60\u8fdb\u884c\u6c42\u89e3\u3002", "result": "\u4e0e\u57fa\u7ebf\u65b9\u6848\u76f8\u6bd4\uff0cGC-QAP\u5b9e\u73b0\u4e86\u7a33\u5b9a\u6536\u655b\u548c\u4f4e\u4e2d\u65ad\u7387\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "GC-QAP\u6846\u67b6\u4e3a\u65e0\u4eba\u673a\u8f68\u8ff9\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u907f\u514d\u4e86\u590d\u6742\u8fde\u7eed\u52a8\u4f5c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u95ee\u9898\u3002"}}
{"id": "2510.18043", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18043", "abs": "https://arxiv.org/abs/2510.18043", "authors": ["Joong Ho Choi", "Jiayang Zhao", "Jeel Shah", "Ritvika Sonawane", "Vedant Singh", "Avani Appalla", "Will Flanagan", "Filipe Condessa"], "title": "CompactPrompt: A Unified Pipeline for Prompt Data Compression in LLM Workflows", "comment": "Workshop on LLMs and Generative AI for Finance at ACM ICAIF 2025", "summary": "Large Language Models (LLMs) deliver powerful reasoning and generation\ncapabilities but incur substantial run-time costs when operating in agentic\nworkflows that chain together lengthy prompts and process rich data streams. We\nintroduce CompactPrompt, an end-to-end pipeline that merges hard prompt\ncompression with lightweight file-level data compression. CompactPrompt first\nprunes low-information tokens from prompts using self-information scoring and\ndependency-based phrase grouping. In parallel, it applies n-gram abbreviation\nto recurrent textual patterns in attached documents and uniform quantization to\nnumerical columns, yielding compact yet semantically faithful representations.\nIntegrated into standard LLM agents, CompactPrompt reduces total token usage\nand inference cost by up to 60% on benchmark dataset like TAT-QA and FinQA,\nwhile preserving output quality (Results in less than 5% accuracy drop for\nClaude-3.5-Sonnet, and GPT-4.1-Mini) CompactPrompt helps visualize real-time\ncompression decisions and quantify cost-performance trade-offs, laying the\ngroundwork for leaner generative AI pipelines.", "AI": {"tldr": "CompactPrompt\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u786c\u63d0\u793a\u538b\u7f29\u548c\u8f7b\u91cf\u7ea7\u6587\u4ef6\u7ea7\u6570\u636e\u538b\u7f29\uff0c\u5c06LLM\u4ee3\u7406\u5de5\u4f5c\u6d41\u4e2d\u7684\u603b\u4ee4\u724c\u4f7f\u7528\u91cf\u548c\u63a8\u7406\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe60%\uff0c\u540c\u65f6\u4fdd\u6301\u8f93\u51fa\u8d28\u91cf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7406\u5de5\u4f5c\u6d41\u4e2d\u8fd0\u884c\u65f6\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u5904\u7406\u5197\u957f\u7684\u63d0\u793a\u548c\u4e30\u5bcc\u7684\u6570\u636e\u6d41\uff0c\u56e0\u6b64\u9700\u8981\u964d\u4f4e\u8fd0\u884c\u6210\u672c\u3002", "method": "\u7ed3\u5408\u786c\u63d0\u793a\u538b\u7f29\u548c\u8f7b\u91cf\u7ea7\u6587\u4ef6\u7ea7\u6570\u636e\u538b\u7f29\uff1a\u4f7f\u7528\u81ea\u4fe1\u606f\u8bc4\u5206\u548c\u57fa\u4e8e\u4f9d\u8d56\u5173\u7cfb\u7684\u77ed\u8bed\u5206\u7ec4\u4fee\u526a\u4f4e\u4fe1\u606f\u4ee4\u724c\uff1b\u5bf9\u6587\u6863\u4e2d\u7684\u91cd\u590d\u6587\u672c\u6a21\u5f0f\u5e94\u7528n-gram\u7f29\u5199\uff0c\u5bf9\u6570\u503c\u5217\u5e94\u7528\u7edf\u4e00\u91cf\u5316\u3002", "result": "\u5728TAT-QA\u548cFinQA\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u603b\u4ee4\u724c\u4f7f\u7528\u91cf\u548c\u63a8\u7406\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe60%\uff0c\u8f93\u51fa\u8d28\u91cf\u4fdd\u6301\u826f\u597d\uff08Claude-3.5-Sonnet\u548cGPT-4.1-Mini\u7684\u51c6\u786e\u7387\u4e0b\u964d\u5c0f\u4e8e5%\uff09\u3002", "conclusion": "CompactPrompt\u4e3a\u66f4\u7cbe\u7b80\u7684\u751f\u6210\u5f0fAI\u6d41\u6c34\u7ebf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u80fd\u591f\u53ef\u89c6\u5316\u5b9e\u65f6\u538b\u7f29\u51b3\u7b56\u5e76\u91cf\u5316\u6210\u672c-\u6027\u80fd\u6743\u8861\u3002"}}
{"id": "2510.18347", "categories": ["cs.RO", "cs.SY", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.18347", "abs": "https://arxiv.org/abs/2510.18347", "authors": ["Muhammad Hanif", "Reiji Terunuma", "Takumi Sumino", "Kelvin Cheng", "Takeshi Hatanaka"], "title": "Coverage-Recon: Coordinated Multi-Drone Image Sampling with Online Map Feedback", "comment": "Submitted to IEEE Transactions on Control Systems Technology (under\n  review). Project page: https://htnk-lab.github.io/coverage-recon/", "summary": "This article addresses collaborative 3D map reconstruction using multiple\ndrones. Achieving high-quality reconstruction requires capturing images of\nkeypoints within the target scene from diverse viewing angles, and coverage\ncontrol offers an effective framework to meet this requirement. Meanwhile,\nrecent advances in real-time 3D reconstruction algorithms make it possible to\nrender an evolving map during flight, enabling immediate feedback to guide\ndrone motion. Building on this, we present Coverage-Recon, a novel coordinated\nimage sampling algorithm that integrates online map feedback to improve\nreconstruction quality on-the-fly. In Coverage-Recon, the coordinated motion of\ndrones is governed by a Quadratic Programming (QP)-based angle-aware coverage\ncontroller, which ensures multi-viewpoint image capture while enforcing safety\nconstraints. The captured images are processed in real time by the NeuralRecon\nalgorithm to generate an evolving 3D mesh. Mesh changes across the scene are\ninterpreted as indicators of reconstruction uncertainty and serve as feedback\nto update the importance index of the coverage control as the map evolves. The\neffectiveness of Coverage-Recon is validated through simulation and\nexperiments, demonstrating both qualitatively and quantitatively that\nincorporating online map feedback yields more complete and accurate 3D\nreconstructions than conventional methods. Project page:\nhttps://htnk-lab.github.io/coverage-recon/", "AI": {"tldr": "\u63d0\u51faCoverage-Recon\u7b97\u6cd5\uff0c\u901a\u8fc7\u5728\u7ebf\u5730\u56fe\u53cd\u9988\u6539\u8fdb\u591a\u65e0\u4eba\u673a\u534f\u540c3D\u91cd\u5efa\u8d28\u91cf\uff0c\u7ed3\u5408QP\u8986\u76d6\u63a7\u5236\u548cNeuralRecon\u5b9e\u65f6\u91cd\u5efa", "motivation": "\u5b9e\u73b0\u9ad8\u8d28\u91cf3D\u91cd\u5efa\u9700\u8981\u4ece\u591a\u89c6\u89d2\u6355\u83b7\u5173\u952e\u70b9\u56fe\u50cf\uff0c\u800c\u5b9e\u65f6\u91cd\u5efa\u7b97\u6cd5\u7684\u53d1\u5c55\u4f7f\u5f97\u80fd\u591f\u5728\u98de\u884c\u4e2d\u63d0\u4f9b\u5373\u65f6\u53cd\u9988\u6765\u6307\u5bfc\u65e0\u4eba\u673a\u8fd0\u52a8", "method": "\u4f7f\u7528\u57fa\u4e8eQP\u7684\u89d2\u5ea6\u611f\u77e5\u8986\u76d6\u63a7\u5236\u5668\u534f\u8c03\u65e0\u4eba\u673a\u8fd0\u52a8\uff0c\u901a\u8fc7NeuralRecon\u7b97\u6cd5\u5b9e\u65f6\u751f\u62103D\u7f51\u683c\uff0c\u5c06\u7f51\u683c\u53d8\u5316\u4f5c\u4e3a\u91cd\u5efa\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u6765\u66f4\u65b0\u8986\u76d6\u63a7\u5236\u7684\u91cd\u8981\u6027\u6307\u6570", "result": "\u4eff\u771f\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff0c\u5f15\u5165\u5728\u7ebf\u5730\u56fe\u53cd\u9988\u80fd\u4ea7\u751f\u66f4\u5b8c\u6574\u548c\u51c6\u786e\u76843D\u91cd\u5efa\u7ed3\u679c", "conclusion": "Coverage-Recon\u7b97\u6cd5\u901a\u8fc7\u96c6\u6210\u5728\u7ebf\u5730\u56fe\u53cd\u9988\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u65e0\u4eba\u673a\u534f\u540c3D\u5730\u56fe\u91cd\u5efa\u7684\u8d28\u91cf\u548c\u5b8c\u6574\u6027"}}
{"id": "2510.18026", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.18026", "abs": "https://arxiv.org/abs/2510.18026", "authors": ["Xinran Zhu", "Liam Magee", "Peg Mischler"], "title": "Integrating Generative AI into LMS: Reshaping Learning and Instructional Design", "comment": null, "summary": "Education in the era of generative AI faces a pivotal transformation. As AI\nsystems reshape professional practices-from software development to creative\ndesign-educators must reconsider how to prepare students for a future where\nhumans and machines co-construct knowledge. While tools like ChatGPT and Claude\nautomate tasks and personalize learning, their educational potential depends on\nhow meaningfully they are integrated into learning environments. This paper\nargues that Learning Management Systems (LMSs), as the core of educational\npractice, must evolve from static content repositories into dynamic ecosystems\nthat cultivate higher-order thinking and meaningful human-AI interaction. We\npropose two guiding principles for integrating generative AI into LMSs. First,\nFrom Content Delivery to Fostering Higher-Order Thinking, emphasizing AI's role\nin supporting inquiry, collaboration, and reflective knowledge building.\nSecond, Toward Meaningful Interaction with AI, highlighting the design of\nlearning environments that nurture critical, intentional, and socially mediated\nengagement with AI. Drawing on a case study of CheckIT Learning, we illustrate\nhow these principles can translate into practice. We conclude with the need for\nEdtech partnerships in an AI-powered world, underscoring that responsible AI\nintegration in education requires sustained collaboration among researchers,\neducators, and technologists to ensure ethical, pedagogically grounded, and\ncognitively informed innovation.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u5b66\u4e60\u7ba1\u7406\u7cfb\u7edf\u5e94\u4ece\u9759\u6001\u5185\u5bb9\u5e93\u8f6c\u53d8\u4e3a\u52a8\u6001\u751f\u6001\u7cfb\u7edf\uff0c\u901a\u8fc7\u751f\u6210\u5f0fAI\u57f9\u517b\u9ad8\u9636\u601d\u7ef4\u548c\u6709\u610f\u4e49\u7684\u4eba\u673a\u4e92\u52a8\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u91cd\u5851\u4e13\u4e1a\u5b9e\u8df5\uff0c\u6559\u80b2\u9700\u8981\u91cd\u65b0\u601d\u8003\u5982\u4f55\u57f9\u517b\u5b66\u751f\u9002\u5e94\u4eba\u673a\u5171\u540c\u6784\u5efa\u77e5\u8bc6\u7684\u672a\u6765\uff0c\u800c\u5b66\u4e60\u7ba1\u7406\u7cfb\u7edf\u4f5c\u4e3a\u6559\u80b2\u5b9e\u8df5\u6838\u5fc3\u5fc5\u987b\u8fdb\u5316\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u6307\u5bfc\u539f\u5219\uff1a\u4ece\u5185\u5bb9\u4f20\u9012\u8f6c\u5411\u57f9\u517b\u9ad8\u9636\u601d\u7ef4\uff0c\u4ee5\u53ca\u5b9e\u73b0\u4e0eAI\u7684\u6709\u610f\u4e49\u4e92\u52a8\uff1b\u901a\u8fc7CheckIT Learning\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u8fd9\u4e9b\u539f\u5219\u7684\u5b9e\u8df5\u5e94\u7528\u3002", "result": "\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u751f\u6210\u5f0fAI\u6574\u5408\u5230\u5b66\u4e60\u7ba1\u7406\u7cfb\u7edf\u4e2d\uff0c\u652f\u6301\u63a2\u7a76\u3001\u534f\u4f5c\u548c\u53cd\u601d\u6027\u77e5\u8bc6\u6784\u5efa\uff0c\u57f9\u517b\u6279\u5224\u6027\u3001\u6709\u610f\u56fe\u548c\u793e\u4f1a\u4e2d\u4ecb\u7684AI\u4e92\u52a8\u3002", "conclusion": "\u5728AI\u9a71\u52a8\u7684\u4e16\u754c\u4e2d\u9700\u8981\u6559\u80b2\u6280\u672f\u5408\u4f5c\u4f19\u4f34\u5173\u7cfb\uff0c\u8d1f\u8d23\u4efb\u7684\u6559\u80b2AI\u6574\u5408\u9700\u8981\u7814\u7a76\u4eba\u5458\u3001\u6559\u80b2\u5de5\u4f5c\u8005\u548c\u6280\u672f\u4e13\u5bb6\u4e4b\u95f4\u7684\u6301\u7eed\u5408\u4f5c\uff0c\u786e\u4fdd\u4f26\u7406\u3001\u6559\u5b66\u57fa\u7840\u548c\u8ba4\u77e5\u77e5\u60c5\u7684\u521b\u65b0\u3002"}}
{"id": "2510.17870", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.17870", "abs": "https://arxiv.org/abs/2510.17870", "authors": ["Nirmal D. Wickramasinghe", "John Dooley", "Dirk Pesch", "Indrakshi Dey"], "title": "Epistemology-Inspired Bayesian Games for Distributed IoT Uplink Power Control", "comment": "6 pages", "summary": "Massive number of simultaneous Internet of Things (IoT) uplinks strain\ngateways with interference and energy limits, yet devices often lack neighbors'\nChannel State Information (CSI) and cannot sustain centralized Mobile Edge\nComputing (MEC) or heavy Machine Learning (ML) coordination. Classical Bayesian\nsolvers help with uncertainty but become intractable as users and strategies\ngrow, making lightweight, distributed control essential. In this paper, we\nintroduce the first-ever, novel epistemic Bayesian game for uplink power\ncontrol under incomplete CSI that operates while suppressing interference among\nmultiple uplink channels from distributed IoT devices firing at the same time.\nNodes run inter-/intra-epistemic belief updates over opponents' strategies,\nreplacing exhaustive expected-utility tables with conditional belief\nhierarchies. Using an exponential-Gamma SINR model and higher-order utility\nmoments (variance, skewness, kurtosis), the scheme remains computationally lean\nwith a single-round upper bound of $O\\!\\left(N^{2} S^{2N}\\right)$. Precise\npower control and stronger coverage amid realistic interference: with channel\nmagnitude equal to $1$ and a signal-to-interference-plus-noise ratio (SINR)\nthreshold of $-18$ dB, coverage reaches approximately $60\\%$ at approximately\n$55\\%$ of the maximum transmit power; mid-rate devices with a threshold of\n$-27$ dB achieve full coverage with less than $0.1\\%$ of the maximum transmit\npower.Under $80\\%$ interference, a fourth-moment policy cuts average power from\napproximately $52\\%$ to approximately $20\\%$ of the maximum transmit power with\ncomparable outage, outperforming expectation-only baselines. These results\nhighlight a principled, computationally lean path to optimal power allocation\nand higher network coverage under real-world uncertainty within dense,\ndistributed IoT networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8ba4\u77e5\u8d1d\u53f6\u65af\u535a\u5f08\u7684\u8f7b\u91cf\u7ea7\u5206\u5e03\u5f0f\u4e0a\u884c\u94fe\u8def\u529f\u7387\u63a7\u5236\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5bc6\u96c6\u7269\u8054\u7f51\u7f51\u7edc\u4e2dCSI\u4e0d\u5b8c\u6574\u548c\u5e72\u6270\u4e25\u91cd\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u91cf\u7269\u8054\u7f51\u8bbe\u5907\u540c\u65f6\u4e0a\u884c\u4f20\u8f93\u7ed9\u7f51\u5173\u5e26\u6765\u4e25\u91cd\u5e72\u6270\u548c\u80fd\u8017\u95ee\u9898\uff0c\u4f46\u8bbe\u5907\u7f3a\u4e4f\u90bb\u5c45CSI\u4fe1\u606f\u4e14\u65e0\u6cd5\u652f\u6301\u96c6\u4e2d\u5f0fMEC\u6216\u590d\u6742ML\u534f\u8c03\uff0c\u9700\u8981\u8f7b\u91cf\u7ea7\u5206\u5e03\u5f0f\u63a7\u5236\u65b9\u6848\u3002", "method": "\u91c7\u7528\u8ba4\u77e5\u8d1d\u53f6\u65af\u535a\u5f08\u6846\u67b6\uff0c\u8282\u70b9\u8fd0\u884c\u8ba4\u77e5\u4fe1\u5ff5\u66f4\u65b0\u6765\u4f30\u8ba1\u5bf9\u624b\u7b56\u7565\uff0c\u4f7f\u7528\u6307\u6570-\u4f3d\u9a6cSINR\u6a21\u578b\u548c\u9ad8\u9636\u6548\u7528\u77e9\uff08\u65b9\u5dee\u3001\u504f\u5ea6\u3001\u5cf0\u5ea6\uff09\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e3aO(N\u00b2S\u00b2N)\u3002", "result": "\u5728SINR\u9608\u503c\u4e3a-18dB\u65f6\uff0c\u8986\u76d6\u7387\u8fbe\u5230\u7ea660%\u4e14\u4ec5\u9700\u7ea655%\u6700\u5927\u53d1\u5c04\u529f\u7387\uff1b\u5728-27dB\u9608\u503c\u4e0b\uff0c\u4e2d\u901f\u7387\u8bbe\u5907\u5b9e\u73b0\u5168\u8986\u76d6\u4e14\u4ec5\u9700\u5c0f\u4e8e0.1%\u6700\u5927\u529f\u7387\uff1b\u572880%\u5e72\u6270\u4e0b\uff0c\u56db\u9636\u77e9\u7b56\u7565\u5c06\u5e73\u5747\u529f\u7387\u4ece52%\u964d\u81f320%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5bc6\u96c6\u5206\u5e03\u5f0f\u7269\u8054\u7f51\u7f51\u7edc\u5728\u73b0\u5b9e\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u63d0\u4f9b\u4e86\u4e00\u6761\u8ba1\u7b97\u8f7b\u91cf\u3001\u539f\u7406\u6e05\u6670\u7684\u8def\u5f84\uff0c\u5b9e\u73b0\u6700\u4f18\u529f\u7387\u5206\u914d\u548c\u66f4\u9ad8\u7f51\u7edc\u8986\u76d6\u3002"}}
{"id": "2510.18087", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18087", "abs": "https://arxiv.org/abs/2510.18087", "authors": ["Daniel Israel", "Tian Jin", "Ellie Cheng", "Guy Van den Broeck", "Aditya Grover", "Suvinay Subramanian", "Michael Carbin"], "title": "Planned Diffusion", "comment": "10 pages, 8 figures", "summary": "A central challenge in large language model inference is the trade-off\nbetween generation speed and output quality. Autoregressive models produce\nhigh-quality text but generate tokens sequentially. Diffusion models can\ngenerate tokens in parallel but often need many iterations to match the same\nquality. We propose planned diffusion, a hybrid method that combines the\nstrengths of both paradigms. Planned diffusion works in two stages: first, the\nmodel creates a short autoregressive plan that breaks the output into smaller,\nindependent spans. Second, the model generates these spans simultaneously using\ndiffusion. This approach expands the speed-quality Pareto frontier and provides\na practical path to faster, high-quality text generation. On AlpacaEval, a\nsuite of 805 instruction-following prompts, planned diffusion achieves\nPareto-optimal trade-off between quality and latency, achieving 1.27x to 1.81x\nspeedup over autoregressive generation with only 0.87\\% to 5.4\\% drop in win\nrate, respectively. Our sensitivity analysis shows that the planning mechanism\nof planned diffusion is minimal and reliable, and simple runtime knobs exist to\nprovide flexible control of the quality-latency trade-off.", "AI": {"tldr": "Planned diffusion\u662f\u4e00\u79cd\u7ed3\u5408\u81ea\u56de\u5f52\u548c\u6269\u6563\u6a21\u578b\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u751f\u6210\uff08\u5148\u81ea\u56de\u5f52\u89c4\u5212\uff0c\u540e\u6269\u6563\u5e76\u884c\u751f\u6210\uff09\u6765\u4f18\u5316\u6587\u672c\u751f\u6210\u7684\u901f\u5ea6-\u8d28\u91cf\u6743\u8861\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u751f\u6210\u901f\u5ea6\u4e0e\u8f93\u51fa\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u81ea\u56de\u5f52\u6a21\u578b\u8d28\u91cf\u9ad8\u4f46\u901f\u5ea6\u6162\uff0c\u6269\u6563\u6a21\u578b\u53ef\u5e76\u884c\u4f46\u9700\u8981\u591a\u6b21\u8fed\u4ee3\u3002", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1\uff09\u81ea\u56de\u5f52\u89c4\u5212\u9636\u6bb5\uff0c\u5c06\u8f93\u51fa\u5206\u89e3\u4e3a\u72ec\u7acb\u7684\u5c0f\u7247\u6bb5\uff1b2\uff09\u6269\u6563\u751f\u6210\u9636\u6bb5\uff0c\u5e76\u884c\u751f\u6210\u8fd9\u4e9b\u7247\u6bb5\u3002", "result": "\u5728AlpacaEval\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u7eaf\u81ea\u56de\u5f52\u751f\u6210\u5b9e\u73b0\u4e861.27x\u52301.81x\u7684\u52a0\u901f\uff0c\u4ec5\u635f\u59310.87%\u52305.4%\u7684\u80dc\u7387\uff0c\u8fbe\u5230\u4e86Pareto\u6700\u4f18\u6743\u8861\u3002", "conclusion": "Planned diffusion\u6269\u5c55\u4e86\u901f\u5ea6-\u8d28\u91cf\u7684Pareto\u8fb9\u754c\uff0c\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u8d28\u91cf-\u5ef6\u8fdf\u6743\u8861\u63a7\u5236\uff0c\u662f\u9ad8\u8d28\u91cf\u5feb\u901f\u6587\u672c\u751f\u6210\u7684\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2510.18348", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18348", "abs": "https://arxiv.org/abs/2510.18348", "authors": ["Alexandros Ntagkas", "Chairi Kiourt", "Konstantinos Chatzilygeroudis"], "title": "PGTT: Phase-Guided Terrain Traversal for Perceptive Legged Locomotion", "comment": "9 pages, 9 figures, 2 tables", "summary": "State-of-the-art perceptive Reinforcement Learning controllers for legged\nrobots either (i) impose oscillator or IK-based gait priors that constrain the\naction space, add bias to the policy optimization and reduce adaptability\nacross robot morphologies, or (ii) operate \"blind\", which struggle to\nanticipate hind-leg terrain, and are brittle to noise. In this paper, we\npropose Phase-Guided Terrain Traversal (PGTT), a perception-aware deep-RL\napproach that overcomes these limitations by enforcing gait structure purely\nthrough reward shaping, thereby reducing inductive bias in policy learning\ncompared to oscillator/IK-conditioned action priors. PGTT encodes per-leg phase\nas a cubic Hermite spline that adapts swing height to local heightmap\nstatistics and adds a swing-phase contact penalty, while the policy acts\ndirectly in joint space supporting morphology-agnostic deployment. Trained in\nMuJoCo (MJX) on procedurally generated stair-like terrains with curriculum and\ndomain randomization, PGTT achieves the highest success under push disturbances\n(median +7.5% vs. the next best method) and on discrete obstacles (+9%), with\ncomparable velocity tracking, and converging to an effective policy roughly 2x\nfaster than strong end-to-end baselines. We validate PGTT on a Unitree Go2\nusing a real-time LiDAR elevation-to-heightmap pipeline, and we report\npreliminary results on ANYmal-C obtained with the same hyperparameters. These\nfindings indicate that terrain-adaptive, phase-guided reward shaping is a\nsimple and general mechanism for robust perceptive locomotion across platforms.", "AI": {"tldr": "PGTT\u662f\u4e00\u79cd\u611f\u77e5\u589e\u5f3a\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5956\u52b1\u5851\u5f62\u800c\u975e\u52a8\u4f5c\u5148\u9a8c\u6765\u5f15\u5bfc\u6b65\u6001\u7ed3\u6784\uff0c\u5728\u590d\u6742\u5730\u5f62\u4e0a\u5b9e\u73b0\u66f4\u9c81\u68d2\u7684\u56db\u8db3\u673a\u5668\u4eba\u8fd0\u52a8\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u8981\u4e48\u4f7f\u7528\u632f\u8361\u5668\u6216\u9006\u8fd0\u52a8\u5b66\u6b65\u6001\u5148\u9a8c\uff0c\u8fd9\u4f1a\u7ea6\u675f\u52a8\u4f5c\u7a7a\u95f4\u3001\u589e\u52a0\u7b56\u7565\u4f18\u5316\u504f\u5dee\u5e76\u964d\u4f4e\u8de8\u673a\u5668\u4eba\u5f62\u6001\u7684\u9002\u5e94\u6027\uff1b\u8981\u4e48\u91c7\u7528\"\u76f2\"\u63a7\u5236\u65b9\u6cd5\uff0c\u96be\u4ee5\u9884\u6d4b\u540e\u817f\u5730\u5f62\u4e14\u5bf9\u566a\u58f0\u654f\u611f\u3002", "method": "\u63d0\u51faPGTT\u65b9\u6cd5\uff0c\u901a\u8fc7\u5956\u52b1\u5851\u5f62\u800c\u975e\u52a8\u4f5c\u5148\u9a8c\u6765\u5b9e\u65bd\u6b65\u6001\u7ed3\u6784\uff0c\u4f7f\u7528\u4e09\u6b21Hermite\u6837\u6761\u7f16\u7801\u817f\u90e8\u76f8\u4f4d\uff0c\u6839\u636e\u5c40\u90e8\u9ad8\u5ea6\u56fe\u7edf\u8ba1\u8c03\u6574\u6446\u52a8\u9ad8\u5ea6\uff0c\u5e76\u6dfb\u52a0\u6446\u52a8\u76f8\u4f4d\u63a5\u89e6\u60e9\u7f5a\uff0c\u7b56\u7565\u76f4\u63a5\u5728\u5173\u8282\u7a7a\u95f4\u64cd\u4f5c\u4ee5\u652f\u6301\u5f62\u6001\u65e0\u5173\u90e8\u7f72\u3002", "result": "\u5728MuJoCo\u6a21\u62df\u5668\u4e2d\u8bad\u7ec3\uff0cPGTT\u5728\u63a8\u529b\u5e72\u6270\u4e0b\u6210\u529f\u7387\u4e2d\u4f4d\u6570\u6bd4\u6b21\u4f18\u65b9\u6cd5\u9ad87.5%\uff0c\u5728\u79bb\u6563\u969c\u788d\u7269\u4e0a\u9ad89%\uff0c\u901f\u5ea6\u8ddf\u8e2a\u6027\u80fd\u76f8\u5f53\uff0c\u6536\u655b\u901f\u5ea6\u6bd4\u5f3a\u7aef\u5230\u7aef\u57fa\u7ebf\u5feb\u7ea62\u500d\u3002\u5728Unitree Go2\u548cANYmal-C\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u6709\u6548\u3002", "conclusion": "\u5730\u5f62\u81ea\u9002\u5e94\u3001\u76f8\u4f4d\u5f15\u5bfc\u7684\u5956\u52b1\u5851\u5f62\u662f\u5b9e\u73b0\u8de8\u5e73\u53f0\u9c81\u68d2\u611f\u77e5\u8fd0\u52a8\u63a7\u5236\u7684\u7b80\u5355\u901a\u7528\u673a\u5236\u3002"}}
{"id": "2510.18050", "categories": ["cs.CY", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.18050", "abs": "https://arxiv.org/abs/2510.18050", "authors": ["Euzeli dos Santos"], "title": "Prompt-to-Primal Teaching", "comment": "9 pages, 5 figures", "summary": "This paper introduces Prompt-to-Primal (P2P) Teaching, an AI-integrated\ninstructional approach that links prompt-driven exploration with\nfirst-principles reasoning, guided and moderated by the instructor within the\nclassroom setting. In P2P teaching, student-generated AI prompts serve as entry\npoints for inquiry and initial discussions in class, while the instructor\nguides learners to validate, challenge, and reconstruct AI responses through\nfundamental physical and mathematical laws. The approach encourages\nself-reflective development, critical evaluation of AI outputs, and conceptual\nfoundational knowledge of the core engineering principles. A large language\nmodel (LLM) can be a highly effective tool for those who already possess\nfoundational knowledge of a subject; however, it may also mislead students who\nlack sufficient background in the subject matter. Results from two student\ncohorts across different semesters suggest the pedagogical effectiveness of the\nP2P teaching framework in enhancing both AI literacy and engineering reasoning.", "AI": {"tldr": "P2P\u6559\u5b66\u6cd5\u5c06AI\u63d0\u793a\u9a71\u52a8\u63a2\u7d22\u4e0e\u7b2c\u4e00\u6027\u539f\u7406\u63a8\u7406\u7ed3\u5408\uff0c\u6559\u5e08\u5f15\u5bfc\u5b66\u751f\u5728\u8bfe\u5802\u4e2d\u9a8c\u8bc1\u3001\u6311\u6218\u548c\u91cd\u6784AI\u56de\u7b54\uff0c\u63d0\u5347AI\u7d20\u517b\u548c\u5de5\u7a0b\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6709\u57fa\u7840\u77e5\u8bc6\u7684\u5b66\u751f\u5f88\u6709\u6548\uff0c\u4f46\u53ef\u80fd\u8bef\u5bfc\u7f3a\u4e4f\u80cc\u666f\u77e5\u8bc6\u7684\u5b66\u751f\uff0c\u9700\u8981\u4e00\u79cd\u6559\u5b66\u65b9\u6cd5\u6765\u5e73\u8861AI\u5de5\u5177\u7684\u4f7f\u7528\u4e0e\u57fa\u7840\u77e5\u8bc6\u7684\u5efa\u7acb\u3002", "method": "P2P\u6559\u5b66\u6cd5\uff1a\u5b66\u751f\u751f\u6210AI\u63d0\u793a\u4f5c\u4e3a\u8bfe\u5802\u63a2\u7a76\u8d77\u70b9\uff0c\u6559\u5e08\u5f15\u5bfc\u5b66\u751f\u901a\u8fc7\u7269\u7406\u548c\u6570\u5b66\u57fa\u672c\u5b9a\u5f8b\u9a8c\u8bc1\u3001\u6311\u6218\u548c\u91cd\u6784AI\u56de\u7b54\u3002", "result": "\u4e24\u4e2a\u5b66\u671f\u4e0d\u540c\u5b66\u751f\u7fa4\u4f53\u7684\u7ed3\u679c\u8868\u660e\uff0cP2P\u6559\u5b66\u6846\u67b6\u5728\u63d0\u5347AI\u7d20\u517b\u548c\u5de5\u7a0b\u63a8\u7406\u65b9\u9762\u5177\u6709\u6559\u5b66\u6709\u6548\u6027\u3002", "conclusion": "P2P\u6559\u5b66\u6cd5\u901a\u8fc7\u7ed3\u5408AI\u5de5\u5177\u4e0e\u7b2c\u4e00\u6027\u539f\u7406\u63a8\u7406\uff0c\u4fc3\u8fdb\u4e86\u81ea\u6211\u53cd\u601d\u53d1\u5c55\u3001AI\u8f93\u51fa\u7684\u6279\u5224\u6027\u8bc4\u4f30\u4ee5\u53ca\u6838\u5fc3\u5de5\u7a0b\u539f\u7406\u7684\u6982\u5ff5\u57fa\u7840\u77e5\u8bc6\u7684\u5efa\u7acb\u3002"}}
{"id": "2510.17877", "categories": ["eess.SY", "cs.AI", "cs.IT", "cs.SY", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.17877", "abs": "https://arxiv.org/abs/2510.17877", "authors": ["Yiheng Wang"], "title": "DRL-Based Resource Allocation for Energy-Efficient IRS-Assisted UAV Spectrum Sharing Systems", "comment": "7 pages, 3 figures, 1 algorithm. LaTeX class: IEEEtran", "summary": "Intelligent reflecting surface (IRS) assisted unmanned aerial vehicle (UAV)\nsystems provide a new paradigm for reconfigurable and flexible wireless\ncommunications. To enable more energy efficient and spectrum efficient IRS\nassisted UAV wireless communications, this paper introduces a novel\nIRS-assisted UAV enabled spectrum sharing system with orthogonal frequency\ndivision multiplexing (OFDM). The goal is to maximize the energy efficiency\n(EE) of the secondary network by jointly optimizing the beamforming, subcarrier\nallocation, IRS phase shifts, and the UAV trajectory subject to practical\ntransmit power and passive reflection constraints as well as UAV physical\nlimitations. A physically grounded propulsion-energy model is adopted, with its\ntight upper bound used to form a tractable EE lower bound for the spectrum\nsharing system. To handle highly non convex, time coupled optimization problems\nwith a mixed continuous and discrete policy space, we develop a deep\nreinforcement learning (DRL) approach based on the actor critic framework.\nExtended experiments show the significant EE improvement of the proposed\nDRL-based approach compared to several benchmark schemes, thus demonstrating\nthe effectiveness and robustness of the proposed approach with mobility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684IRS\u8f85\u52a9\u65e0\u4eba\u673a\u9891\u8c31\u5171\u4eab\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u3001\u5b50\u8f7d\u6ce2\u5206\u914d\u3001IRS\u76f8\u4f4d\u548c\u65e0\u4eba\u673a\u8f68\u8ff9\u6765\u6700\u5927\u5316\u6b21\u7ea7\u7f51\u7edc\u80fd\u6548", "motivation": "\u5b9e\u73b0\u66f4\u8282\u80fd\u548c\u9891\u8c31\u9ad8\u6548\u7684IRS\u8f85\u52a9\u65e0\u4eba\u673a\u65e0\u7ebf\u901a\u4fe1\uff0c\u89e3\u51b3\u9891\u8c31\u5171\u4eab\u7cfb\u7edf\u4e2d\u7684\u80fd\u6548\u4f18\u5316\u95ee\u9898", "method": "\u91c7\u7528\u57fa\u4e8e\u6f14\u5458-\u8bc4\u8bba\u5bb6\u6846\u67b6\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5904\u7406\u9ad8\u5ea6\u975e\u51f8\u3001\u65f6\u95f4\u8026\u5408\u7684\u6df7\u5408\u8fde\u7eed\u79bb\u6563\u4f18\u5316\u95ee\u9898", "result": "\u5b9e\u9a8c\u663e\u793a\u6240\u63d0\u65b9\u6cd5\u76f8\u6bd4\u591a\u4e2a\u57fa\u51c6\u65b9\u6848\u663e\u8457\u63d0\u9ad8\u4e86\u80fd\u6548\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u79fb\u52a8\u6027\u4e0b\u7684\u9c81\u68d2\u6027", "conclusion": "\u6240\u63d0\u51fa\u7684DRL\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3IRS\u8f85\u52a9\u65e0\u4eba\u673a\u9891\u8c31\u5171\u4eab\u7cfb\u7edf\u7684\u80fd\u6548\u4f18\u5316\u95ee\u9898\uff0c\u5177\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347"}}
{"id": "2510.18095", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.18095", "abs": "https://arxiv.org/abs/2510.18095", "authors": ["Nikhil Verma", "Manasa Bharadwaj", "Wonjun Jang", "Harmanpreet Singh", "Yixiao Wang", "Homa Fashandi", "Chul Lee"], "title": "SMaRT: Select, Mix, and ReinvenT -- A Strategy Fusion Framework for LLM-Driven Reasoning and Planning", "comment": null, "summary": "Large Language Models (LLMs) have redefined complex task automation with\nexceptional generalization capabilities. Despite these advancements,\nstate-of-the-art methods rely on single-strategy prompting, missing the synergy\nof diverse reasoning approaches. No single strategy excels universally,\nhighlighting the need for frameworks that fuse strategies to maximize\nperformance and ensure robustness. We introduce the Select, Mix, and ReinvenT\n(SMaRT) framework, an innovative strategy fusion approach designed to overcome\nthis constraint by creating balanced and efficient solutions through the\nseamless integration of diverse reasoning strategies. Unlike existing methods,\nwhich employ LLMs merely as evaluators, SMaRT uses them as intelligent\nintegrators, unlocking the \"best of all worlds\" across tasks. Extensive\nempirical evaluations across benchmarks in reasoning, planning, and sequential\ndecision-making highlight the robustness and adaptability of SMaRT. The\nframework consistently outperforms state-of-the-art baselines in solution\nquality, constraint adherence, and performance metrics. This work redefines\nLLM-driven decision-making by pioneering a new paradigm in cross-strategy\ncalibration, unlocking superior outcomes for reasoning systems and advancing\nthe boundaries of self-refining methodologies.", "AI": {"tldr": "SMaRT\u6846\u67b6\u901a\u8fc7\u878d\u5408\u591a\u79cd\u63a8\u7406\u7b56\u7565\u6765\u63d0\u5347LLM\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u5355\u4e00\u7b56\u7565\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5355\u4e00\u7b56\u7565\u63d0\u793a\uff0c\u7f3a\u4e4f\u4e0d\u540c\u63a8\u7406\u65b9\u6cd5\u7684\u534f\u540c\u6548\u5e94\uff0c\u9700\u8981\u80fd\u591f\u878d\u5408\u591a\u79cd\u7b56\u7565\u7684\u6846\u67b6\u6765\u6700\u5927\u5316\u6027\u80fd\u5e76\u786e\u4fdd\u9c81\u68d2\u6027\u3002", "method": "\u5f15\u5165SMaRT\u6846\u67b6\uff0c\u4f7f\u7528LLM\u4f5c\u4e3a\u667a\u80fd\u96c6\u6210\u5668\u800c\u975e\u4ec5\u4ec5\u8bc4\u4f30\u5668\uff0c\u901a\u8fc7\u9009\u62e9\u3001\u6df7\u5408\u548c\u91cd\u65b0\u53d1\u660e\u7b56\u7565\u6765\u65e0\u7f1d\u6574\u5408\u591a\u6837\u5316\u7684\u63a8\u7406\u65b9\u6cd5\u3002", "result": "\u5728\u63a8\u7406\u3001\u89c4\u5212\u548c\u987a\u5e8f\u51b3\u7b56\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSMaRT\u5728\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u3001\u7ea6\u675f\u9075\u5faa\u548c\u6027\u80fd\u6307\u6807\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u5f00\u521b\u8de8\u7b56\u7565\u6821\u51c6\u7684\u65b0\u8303\u5f0f\uff0c\u91cd\u65b0\u5b9a\u4e49\u4e86LLM\u9a71\u52a8\u7684\u51b3\u7b56\uff0c\u4e3a\u63a8\u7406\u7cfb\u7edf\u89e3\u9501\u4e86\u4f18\u8d8a\u7ed3\u679c\u5e76\u63a8\u8fdb\u4e86\u81ea\u6211\u7cbe\u5316\u65b9\u6cd5\u7684\u8fb9\u754c\u3002"}}
{"id": "2510.18371", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.18371", "abs": "https://arxiv.org/abs/2510.18371", "authors": ["Mingxin Li", "Haibo Hu", "Jinghuai Deng", "Yuchen Xi", "Xinhong Chen", "Jianping Wang"], "title": "MMRHP: A Miniature Mixed-Reality HIL Platform for Auditable Closed-Loop Evaluation", "comment": null, "summary": "Validation of autonomous driving systems requires a trade-off between test\nfidelity, cost, and scalability. While miniaturized hardware-in-the-loop (HIL)\nplatforms have emerged as a promising solution, a systematic framework\nsupporting rigorous quantitative analysis is generally lacking, limiting their\nvalue as scientific evaluation tools. To address this challenge, we propose\nMMRHP, a miniature mixed-reality HIL platform that elevates miniaturized\ntesting from functional demonstration to rigorous, reproducible quantitative\nanalysis. The core contributions are threefold. First, we propose a systematic\nthree-phase testing process oriented toward the Safety of the Intended\nFunctionality(SOTIF)standard, providing actionable guidance for identifying the\nperformance limits and triggering conditions of otherwise correctly functioning\nsystems. Second, we design and implement a HIL platform centered around a\nunified spatiotemporal measurement core to support this process, ensuring\nconsistent and traceable quantification of physical motion and system timing.\nFinally, we demonstrate the effectiveness of this solution through\ncomprehensive experiments. The platform itself was first validated, achieving a\nspatial accuracy of 10.27 mm RMSE and a stable closed-loop latency baseline of\napproximately 45 ms. Subsequently, an in-depth Autoware case study leveraged\nthis validated platform to quantify its performance baseline and identify a\ncritical performance cliff at an injected latency of 40 ms. This work shows\nthat a structured process, combined with a platform offering a unified\nspatio-temporal benchmark, enables reproducible, interpretable, and\nquantitative closed-loop evaluation of autonomous driving systems.", "AI": {"tldr": "MMRHP\u662f\u4e00\u4e2a\u5fae\u578b\u6df7\u5408\u73b0\u5b9e\u786c\u4ef6\u5728\u73af\u5e73\u53f0\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u6d4b\u8bd5\u6d41\u7a0b\u548c\u7edf\u4e00\u7684\u65f6\u7a7a\u6d4b\u91cf\u6838\u5fc3\uff0c\u5c06\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u6d4b\u8bd5\u4ece\u529f\u80fd\u6f14\u793a\u63d0\u5347\u5230\u4e25\u8c28\u7684\u5b9a\u91cf\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u5fae\u578b\u786c\u4ef6\u5728\u73af\u5e73\u53f0\u7f3a\u4e4f\u652f\u6301\u4e25\u8c28\u5b9a\u91cf\u5206\u6790\u7684\u7cfb\u7edf\u5316\u6846\u67b6\uff0c\u9650\u5236\u4e86\u5176\u4f5c\u4e3a\u79d1\u5b66\u8bc4\u4f30\u5de5\u5177\u7684\u4ef7\u503c\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u6d4b\u8bd5\u6d41\u7a0b\u9762\u5411SOTIF\u6807\u51c6\uff0c\u8bbe\u8ba1\u5b9e\u73b0\u4ee5\u7edf\u4e00\u65f6\u7a7a\u6d4b\u91cf\u6838\u5fc3\u4e3a\u4e2d\u5fc3\u7684\u786c\u4ef6\u5728\u73af\u5e73\u53f0\uff0c\u786e\u4fdd\u7269\u7406\u8fd0\u52a8\u548c\u7cfb\u7edf\u65f6\u5e8f\u7684\u4e00\u81f4\u53ef\u8ffd\u6eaf\u91cf\u5316\u3002", "result": "\u5e73\u53f0\u9a8c\u8bc1\u663e\u793a\u7a7a\u95f4\u7cbe\u5ea6\u8fbe\u523010.27\u6beb\u7c73RMSE\uff0c\u95ed\u73af\u5ef6\u8fdf\u57fa\u7ebf\u7ea645\u6beb\u79d2\u3002Autoware\u6848\u4f8b\u7814\u7a76\u53d1\u73b040\u6beb\u79d2\u6ce8\u5165\u5ef6\u8fdf\u65f6\u51fa\u73b0\u5173\u952e\u6027\u80fd\u60ac\u5d16\u3002", "conclusion": "\u7ed3\u6784\u5316\u6d41\u7a0b\u4e0e\u63d0\u4f9b\u7edf\u4e00\u65f6\u7a7a\u57fa\u51c6\u7684\u5e73\u53f0\u76f8\u7ed3\u5408\uff0c\u80fd\u591f\u5b9e\u73b0\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u53ef\u91cd\u73b0\u3001\u53ef\u89e3\u91ca\u7684\u5b9a\u91cf\u95ed\u73af\u8bc4\u4f30\u3002"}}
{"id": "2510.18581", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18581", "abs": "https://arxiv.org/abs/2510.18581", "authors": ["Katerina Drakos", "Eva Paraschou", "Simay Toplu", "Line Harder Clemmensen", "Christoph L\u00fctge", "Nicole Nadine L\u00f8nfeldt", "Sneha Das"], "title": "The Cost-Benefit of Interdisciplinarity in AI for Mental Health", "comment": "Accepted for poster presentation at the AI in Science Summit 2025", "summary": "Artificial intelligence has been introduced as a way to improve access to\nmental health support. However, most AI mental health chatbots rely on a\nlimited range of disciplinary input, and fail to integrate expertise across the\nchatbot's lifecycle. This paper examines the cost-benefit trade-off of\ninterdisciplinary collaboration in AI mental health chatbots. We argue that\ninvolving experts from technology, healthcare, ethics, and law across key\nlifecycle phases is essential to ensure value-alignment and compliance with the\nhigh-risk requirements of the AI Act. We also highlight practical\nrecommendations and existing frameworks to help balance the challenges and\nbenefits of interdisciplinarity in mental health chatbots.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u5fc3\u7406\u5065\u5eb7\u804a\u5929\u673a\u5668\u4eba\u4e2d\u8de8\u5b66\u79d1\u5408\u4f5c\u7684\u6210\u672c\u6548\u76ca\u6743\u8861\uff0c\u5f3a\u8c03\u9700\u8981\u6574\u5408\u6280\u672f\u3001\u533b\u7597\u3001\u4f26\u7406\u548c\u6cd5\u5f8b\u4e13\u5bb6\u6765\u786e\u4fdd\u4ef7\u503c\u5bf9\u9f50\u5e76\u7b26\u5408AI\u6cd5\u6848\u7684\u9ad8\u98ce\u9669\u8981\u6c42\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570AI\u5fc3\u7406\u5065\u5eb7\u804a\u5929\u673a\u5668\u4eba\u4f9d\u8d56\u6709\u9650\u7684\u5b66\u79d1\u8f93\u5165\uff0c\u672a\u80fd\u6574\u5408\u6574\u4e2a\u751f\u547d\u5468\u671f\u7684\u4e13\u4e1a\u77e5\u8bc6\uff0c\u8fd9\u5f71\u54cd\u4e86\u5176\u6548\u679c\u548c\u5408\u89c4\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u8de8\u5b66\u79d1\u5408\u4f5c\u5728AI\u5fc3\u7406\u5065\u5eb7\u804a\u5929\u673a\u5668\u4eba\u751f\u547d\u5468\u671f\u5404\u9636\u6bb5\u7684\u91cd\u8981\u6027\uff0c\u63d0\u51fa\u5b9e\u8df5\u5efa\u8bae\u548c\u73b0\u6709\u6846\u67b6\u6765\u5e73\u8861\u6311\u6218\u4e0e\u6536\u76ca\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u6280\u672f\u3001\u533b\u7597\u3001\u4f26\u7406\u548c\u6cd5\u5f8b\u7b49\u9886\u57df\u4e13\u5bb6\u7684\u5168\u9762\u53c2\u4e0e\u5bf9\u786e\u4fddAI\u5fc3\u7406\u5065\u5eb7\u804a\u5929\u673a\u5668\u4eba\u7684\u4ef7\u503c\u5bf9\u9f50\u548c\u5408\u89c4\u6027\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u8de8\u5b66\u79d1\u5408\u4f5c\u662f\u5f00\u53d1\u6709\u6548\u4e14\u5408\u89c4\u7684AI\u5fc3\u7406\u5065\u5eb7\u804a\u5929\u673a\u5668\u4eba\u7684\u5173\u952e\uff0c\u9700\u8981\u5e73\u8861\u5176\u6311\u6218\u4e0e\u6536\u76ca\uff0c\u5e76\u5229\u7528\u73b0\u6709\u6846\u67b6\u6307\u5bfc\u5b9e\u8df5\u3002"}}
{"id": "2510.17945", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.17945", "abs": "https://arxiv.org/abs/2510.17945", "authors": ["Sandro Andric"], "title": "An Exact Quantile-Energy Equality for Terminal Halfspaces in Linear-Gaussian Control with a Discrete-Time Companion, KL/Schrodinger Links, and High-Precision Validation", "comment": null, "summary": "We prove an exact equality between the minimal quadratic control energy and\nthe squared normal-quantile gap for terminal halfspaces in linear-Gaussian\nsystems with additive control and quadratic effort $E(u) = \\tfrac12\\!\\int\nu^\\top M u\\,dt$ where $M = B^\\top\\Sigma^{-1}B$. For terminal halfspace events,\nthe minimal energy equals the squared normal-quantile gap divided by twice a\ncontrollability-to-noise ratio $R_T^2(w)=(w^\\top W_c^M w)/(w^\\top V_T w)$ and\nis attained by a matched-filter control. We provide an exact zero-order-hold\ndiscrete-time companion via block exponentials, relate the result to\nminimum-energy control, Gaussian isoperimetry, risk-sensitive/KL control, and\nSchrodinger bridges, and validate to high precision with Monte Carlo. We state\nassumptions, singular-$M$ handling, and edge cases. The statement is a compact\nsynthesis and design-ready translator, not a universal principle. Novelty:\nwhile the ingredients (Gramians, Cauchy-Schwarz, Gaussian isoperimetry) are\nclassical, to our knowledge the explicit quantile-energy equality with a\nconstructive matched-filter achiever for terminal halfspaces, and its\ndiscrete-time companion, are not recorded together in the cited literature.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u7ebf\u6027\u9ad8\u65af\u7cfb\u7edf\u4e2d\u7ec8\u7aef\u534a\u7a7a\u95f4\u7684\u6700\u5c0f\u4e8c\u6b21\u63a7\u5236\u80fd\u91cf\u4e0e\u6b63\u6001\u5206\u4f4d\u6570\u95f4\u9699\u5e73\u65b9\u4e4b\u95f4\u7684\u7cbe\u786e\u7b49\u5f0f\u5173\u7cfb\uff0c\u5e76\u63d0\u4f9b\u4e86\u79bb\u6563\u65f6\u95f4\u7248\u672c\u548c\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u7814\u7a76\u7ec8\u7aef\u534a\u7a7a\u95f4\u4e8b\u4ef6\u7684\u6700\u5c0f\u63a7\u5236\u80fd\u91cf\u95ee\u9898\uff0c\u65e8\u5728\u5efa\u7acb\u63a7\u5236\u80fd\u91cf\u4e0e\u7edf\u8ba1\u91cf\u4e4b\u95f4\u7684\u7cbe\u786e\u6570\u5b66\u5173\u7cfb\uff0c\u4e3a\u63a7\u5236\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u9ad8\u65af\u7cfb\u7edf\u6a21\u578b\uff0c\u901a\u8fc7\u683c\u62c9\u59c6\u77e9\u9635\u3001\u67ef\u897f-\u65bd\u74e6\u8328\u4e0d\u7b49\u5f0f\u548c\u9ad8\u65af\u7b49\u5468\u4e0d\u7b49\u5f0f\u7b49\u7ecf\u5178\u5de5\u5177\uff0c\u63a8\u5bfc\u51fa\u6700\u5c0f\u80fd\u91cf\u4e0e\u6b63\u6001\u5206\u4f4d\u6570\u95f4\u9699\u7684\u7cbe\u786e\u7b49\u5f0f\uff0c\u5e76\u6784\u9020\u5339\u914d\u6ee4\u6ce2\u5668\u63a7\u5236\u7b56\u7565\u3002", "result": "\u8bc1\u660e\u4e86\u6700\u5c0f\u4e8c\u6b21\u63a7\u5236\u80fd\u91cf\u7b49\u4e8e\u6b63\u6001\u5206\u4f4d\u6570\u95f4\u9699\u5e73\u65b9\u9664\u4ee5\u4e24\u500d\u7684\u53ef\u63a7\u6027-\u566a\u58f0\u6bd4\uff0c\u4e14\u8be5\u6700\u5c0f\u503c\u53ef\u901a\u8fc7\u5339\u914d\u6ee4\u6ce2\u5668\u63a7\u5236\u5b9e\u73b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7d27\u51d1\u7684\u7efc\u5408\u6846\u67b6\u548c\u8bbe\u8ba1\u5c31\u7eea\u7684\u8f6c\u6362\u5668\uff0c\u867d\u7136\u4f7f\u7528\u4e86\u7ecf\u5178\u5de5\u5177\uff0c\u4f46\u7ec8\u7aef\u534a\u7a7a\u95f4\u7684\u663e\u5f0f\u5206\u4f4d\u6570-\u80fd\u91cf\u7b49\u5f0f\u53ca\u5176\u79bb\u6563\u65f6\u95f4\u5bf9\u5e94\u5173\u7cfb\u5728\u73b0\u6709\u6587\u732e\u4e2d\u672a\u88ab\u8bb0\u5f55\u3002"}}
{"id": "2510.18134", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18134", "abs": "https://arxiv.org/abs/2510.18134", "authors": ["Soheil Abbasloo"], "title": "Measuring Reasoning in LLMs: a New Dialectical Angle", "comment": null, "summary": "What does it truly mean for a language model to \"reason\"? Most current\nevaluations and benchmarks reward models' correct standalone answers--but\ncorrectness alone reveals little about the process that produced them. In this\nwork, we explore a different perspective: reasoning is not a static chain of\nsteps, but a dynamic trajectory where ideas interact, clash, and evolve into\ndeeper insights. To capture this dynamic, we draw on a well-established\nphilosophical tradition: \\textit{dialectics}, where reasoning unfolds through\nthesis, antithesis, and synthesis. Building on this, we present SIEV, a\nstructured framework that evaluates reasoning of LLMs through dialectics.\nUnlike conventional evaluations, SIEV assesses not only the conclusion a model\nreaches, but how it gets there: its ability to resolve tension, integrate\ndistinct ideas, and synthesize higher-order reasoning. This lens uncovers\nsignificant reasoning gaps in state-of-the-art models even under saturated\nbenchmarks like GSM and MMLU. For instance, GPT-5-chat, a recent model, loses\nover 40 points (out of 100) when evaluated with SIEV on GSM. Our findings\nhighlight that adopting a process-oriented, philosophically grounded approach\nenables a deeper, more rigorous, and more discriminative assessment of LLM\nreasoning.", "AI": {"tldr": "\u63d0\u51faSIEV\u6846\u67b6\uff0c\u57fa\u4e8e\u8fa9\u8bc1\u6cd5\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u800c\u975e\u4ec5\u5173\u6ce8\u7b54\u6848\u6b63\u786e\u6027\uff0c\u63ed\u793a\u5373\u4f7f\u57fa\u51c6\u6d4b\u8bd5\u9971\u548c\u7684\u5148\u8fdb\u6a21\u578b\u4e5f\u5b58\u5728\u663e\u8457\u63a8\u7406\u7f3a\u9677", "motivation": "\u5f53\u524d\u8bc4\u4f30\u4e3b\u8981\u5956\u52b1\u6a21\u578b\u7684\u6b63\u786e\u7b54\u6848\uff0c\u4f46\u6b63\u786e\u6027\u672c\u8eab\u65e0\u6cd5\u63ed\u793a\u4ea7\u751f\u7b54\u6848\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u63a8\u7406\u5e94\u662f\u52a8\u6001\u8f68\u8ff9\uff0c\u89c2\u70b9\u5728\u5176\u4e2d\u4e92\u52a8\u3001\u51b2\u7a81\u5e76\u6f14\u53d8\u4e3a\u6df1\u523b\u89c1\u89e3", "method": "\u501f\u9274\u8fa9\u8bc1\u6cd5\u4f20\u7edf\uff08\u6b63\u9898\u3001\u53cd\u9898\u3001\u5408\u9898\uff09\uff0c\u6784\u5efaSIEV\u7ed3\u6784\u5316\u6846\u67b6\uff0c\u8bc4\u4f30\u6a21\u578b\u89e3\u51b3\u77db\u76fe\u3001\u6574\u5408\u4e0d\u540c\u89c2\u70b9\u548c\u8fdb\u884c\u9ad8\u9636\u63a8\u7406\u7684\u80fd\u529b", "result": "SIEV\u6846\u67b6\u5728GSM\u548cMMLU\u7b49\u9971\u548c\u57fa\u51c6\u4e0a\u53d1\u73b0\u4e86\u6700\u5148\u8fdb\u6a21\u578b\u7684\u663e\u8457\u63a8\u7406\u7f3a\u9677\uff0c\u4f8b\u5982GPT-5-chat\u5728GSM\u4e0a\u635f\u5931\u8d85\u8fc740\u5206\uff08\u6ee1\u5206100\uff09", "conclusion": "\u91c7\u7528\u8fc7\u7a0b\u5bfc\u5411\u3001\u54f2\u5b66\u57fa\u7840\u7684\u65b9\u6cd5\u80fd\u591f\u5bf9LLM\u63a8\u7406\u8fdb\u884c\u66f4\u6df1\u5165\u3001\u4e25\u8c28\u548c\u533a\u5206\u6027\u7684\u8bc4\u4f30"}}
{"id": "2510.18373", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.18373", "abs": "https://arxiv.org/abs/2510.18373", "authors": ["Wanchen Li", "Kahina Chalabi", "Sabbah Maxime", "Thomas Bousquet", "Robin Passama", "Sofiane Ramdani", "Andrea Cherubini", "Vincent Bonnet"], "title": "Biomechanically consistent real-time action recognition for human-robot interaction", "comment": null, "summary": "This paper presents a novel framework for real-time human action recognition\nin industrial contexts, using standard 2D cameras. We introduce a complete\npipeline for robust and real-time estimation of human joint kinematics, input\nto a temporally smoothed Transformer-based network, for action recognition. We\nrely on a new dataset including 11 subjects performing various actions, to\nevaluate our approach. Unlike most of the literature that relies on joint\ncenter positions (JCP) and is offline, ours uses biomechanical prior, eg. joint\nangles, for fast and robust real-time recognition. Besides, joint angles make\nthe proposed method agnostic to sensor and subject poses as well as to\nanthropometric differences, and ensure robustness across environments and\nsubjects. Our proposed learning model outperforms the best baseline model,\nrunning also in real-time, along various metrics. It achieves 88% accuracy and\nshows great generalization ability, for subjects not facing the cameras.\nFinally, we demonstrate the robustness and usefulness of our technique, through\nan online interaction experiment, with a simulated robot controlled in\nreal-time via the recognized actions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e2D\u6444\u50cf\u5934\u7684\u5b9e\u65f6\u5de5\u4e1a\u52a8\u4f5c\u8bc6\u522b\u6846\u67b6\uff0c\u4f7f\u7528\u5173\u8282\u89d2\u5ea6\u800c\u975e\u5173\u8282\u4e2d\u5fc3\u4f4d\u7f6e\uff0c\u7ed3\u5408Transformer\u7f51\u7edc\u5b9e\u73b0\u5b9e\u65f6\u52a8\u4f5c\u8bc6\u522b\uff0c\u5728\u672a\u89c1\u8fc7\u7684\u6d4b\u8bd5\u5bf9\u8c61\u4e0a\u8fbe\u523088%\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u5173\u8282\u4e2d\u5fc3\u4f4d\u7f6e\u4e14\u4e3a\u79bb\u7ebf\u5904\u7406\uff0c\u7f3a\u4e4f\u5bf9\u4f20\u611f\u5668\u4f4d\u7f6e\u3001\u4eba\u4f53\u59ff\u6001\u548c\u4e2a\u4f53\u5dee\u5f02\u7684\u9c81\u68d2\u6027\uff0c\u9700\u8981\u5f00\u53d1\u5b9e\u65f6\u4e14\u9c81\u68d2\u7684\u5de5\u4e1a\u52a8\u4f5c\u8bc6\u522b\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u5b8c\u6574\u7684\u5173\u8282\u8fd0\u52a8\u5b66\u4f30\u8ba1\u6d41\u7a0b\uff0c\u7ed3\u5408\u65f6\u95f4\u5e73\u6ed1\u7684Transformer\u7f51\u7edc\uff0c\u5229\u7528\u751f\u7269\u529b\u5b66\u5148\u9a8c\uff08\u5173\u8282\u89d2\u5ea6\uff09\u8fdb\u884c\u5b9e\u65f6\u52a8\u4f5c\u8bc6\u522b\u3002", "result": "\u572811\u540d\u53d7\u8bd5\u8005\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4f18\u4e8e\u6700\u4f73\u57fa\u7ebf\u6a21\u578b\uff0c\u8fbe\u523088%\u51c6\u786e\u7387\uff0c\u5bf9\u672a\u9762\u5bf9\u6444\u50cf\u5934\u7684\u53d7\u8bd5\u8005\u8868\u73b0\u51fa\u826f\u597d\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u673a\u5668\u4eba\u5b9e\u65f6\u4ea4\u4e92\u5b9e\u9a8c\u9a8c\u8bc1\u5b9e\u7528\u6027\u3002", "conclusion": "\u57fa\u4e8e\u5173\u8282\u89d2\u5ea6\u7684\u65b9\u6cd5\u5177\u6709\u4f20\u611f\u5668\u548c\u59ff\u6001\u65e0\u5173\u6027\uff0c\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u5b9e\u65f6\u52a8\u4f5c\u8bc6\u522b\uff0c\u5c55\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.18806", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.18806", "abs": "https://arxiv.org/abs/2510.18806", "authors": ["Annapurna Vadaparty", "David H. Smith IV", "Samvrit Srinath", "Mounika Padala", "Christine Alvarado", "Jamie Gorson Benario", "Daniel Zingaro", "Leo Porter"], "title": "Integrating Large Language Models and Evaluating Student Outcomes in an Introductory Computer Science Course", "comment": null, "summary": "Generative AI (GenAI) models have broad implications for education in\ngeneral, impacting the foundations of what we teach and how we assess. This is\nespecially true in computing, where LLMs tuned for coding have demonstrated\nshockingly good performance on the types of assignments historically used in\nintroductory CS (CS1) courses. As a result, CS1 courses will need to change\nwhat skills are taught and how they are assessed. Computing education\nresearchers have begun to study student use of LLMs, but there remains much to\nbe understood about the ways that these tools affect student outcomes. In this\npaper, we present the design and evaluation of a new CS1 course at a large\nresearch-intensive university that integrates the use of LLMs as a learning\ntool for students. We describe the design principles used to create our new\nCS1-LLM course, our new course objectives, and evaluation of student outcomes\nand perceptions throughout the course as measured by assessment scores and\nsurveys. Our findings suggest that 1) student exam performance outcomes,\nincluding differences among demographic groups, are largely similar to\nhistorical outcomes for courses without integration of LLM tools, 2) large,\nopen-ended projects may be particularly valuable in an LLM context, and 3)\nstudents predominantly found the LLM tools helpful, although some had concerns\nregarding over-reliance on the tools.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bbe\u8ba1\u5e76\u8bc4\u4f30\u4e86\u4e00\u4e2a\u5c06\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u4f5c\u4e3a\u5b66\u4e60\u5de5\u5177\u6574\u5408\u5230CS1\u8bfe\u7a0b\u4e2d\u7684\u65b0\u6559\u5b66\u6a21\u5f0f\uff0c\u53d1\u73b0\u5b66\u751f\u8003\u8bd5\u6210\u7ee9\u4e0e\u4f20\u7edf\u8bfe\u7a0b\u76f8\u4f3c\uff0c\u5f00\u653e\u5f0f\u9879\u76ee\u5728LLM\u73af\u5883\u4e0b\u7279\u522b\u6709\u4ef7\u503c\uff0c\u5b66\u751f\u666e\u904d\u8ba4\u4e3aLLM\u5de5\u5177\u6709\u5e2e\u52a9\u4f46\u62c5\u5fc3\u8fc7\u5ea6\u4f9d\u8d56\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6a21\u578b\u7279\u522b\u662f\u9488\u5bf9\u7f16\u7801\u8c03\u4f18\u7684LLM\u5728\u4f20\u7edfCS1\u8bfe\u7a0b\u4f5c\u4e1a\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8fd9\u8981\u6c42CS1\u8bfe\u7a0b\u5fc5\u987b\u6539\u53d8\u6559\u5b66\u5185\u5bb9\u548c\u8bc4\u4f30\u65b9\u5f0f\uff0c\u9700\u8981\u7814\u7a76LLM\u5de5\u5177\u5982\u4f55\u5f71\u54cd\u5b66\u751f\u7684\u5b66\u4e60\u6210\u679c\u3002", "method": "\u5728\u4e00\u6240\u5927\u578b\u7814\u7a76\u578b\u5927\u5b66\u8bbe\u8ba1\u5e76\u5b9e\u65bd\u65b0\u7684CS1-LLM\u8bfe\u7a0b\uff0c\u91c7\u7528LLM\u4f5c\u4e3a\u5b66\u751f\u5b66\u4e60\u5de5\u5177\uff0c\u901a\u8fc7\u8bc4\u4f30\u5206\u6570\u548c\u95ee\u5377\u8c03\u67e5\u6765\u8bc4\u4ef7\u5b66\u751f\u6210\u679c\u548c\u611f\u77e5\u3002", "result": "1) \u5b66\u751f\u8003\u8bd5\u6210\u7ee9\u7ed3\u679c(\u5305\u62ec\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u7fa4\u4f53\u95f4\u7684\u5dee\u5f02)\u4e0e\u4f20\u7edf\u65e0LLM\u6574\u5408\u8bfe\u7a0b\u57fa\u672c\u76f8\u4f3c\uff1b2) \u5927\u578b\u5f00\u653e\u5f0f\u9879\u76ee\u5728LLM\u73af\u5883\u4e0b\u7279\u522b\u6709\u4ef7\u503c\uff1b3) \u5b66\u751f\u666e\u904d\u8ba4\u4e3aLLM\u5de5\u5177\u6709\u5e2e\u52a9\uff0c\u4f46\u90e8\u5206\u5b66\u751f\u62c5\u5fc3\u8fc7\u5ea6\u4f9d\u8d56\u5de5\u5177\u3002", "conclusion": "LLM\u53ef\u4ee5\u6210\u529f\u6574\u5408\u5230CS1\u8bfe\u7a0b\u4e2d\u4f5c\u4e3a\u5b66\u4e60\u5de5\u5177\uff0c\u4e0d\u4f1a\u663e\u8457\u5f71\u54cd\u5b66\u751f\u8003\u8bd5\u6210\u7ee9\uff0c\u5f00\u653e\u5f0f\u9879\u76ee\u5728\u8fd9\u79cd\u73af\u5883\u4e0b\u6548\u679c\u66f4\u597d\uff0c\u4f46\u9700\u8981\u6ce8\u610f\u5b66\u751f\u5bf9\u5de5\u5177\u8fc7\u5ea6\u4f9d\u8d56\u7684\u62c5\u5fe7\u3002"}}
{"id": "2510.18235", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.18235", "abs": "https://arxiv.org/abs/2510.18235", "authors": ["Zhitong He", "Zijing Wang", "Lingxi Li"], "title": "Urban Air Mobility: A Review of Recent Advances in Communication, Management, and Sustainability", "comment": "This work has been accepted by the 2025 International Conference on\n  Cyber-physical Social Intelligence (CPSI 2025)", "summary": "Urban Air Mobility (UAM) offers a transformative approach to addressing urban\ncongestion, improving accessibility, and advancing environmental\nsustainability. Rapid progress has emerged in three tightly linked domains\nsince 2020: (1) Communication, where dynamic spectrum allocation and\nlow-altitude channel characterization support reliable air-ground data\nexchange; (2) UAM management, with novel air-traffic control concepts for\ndense, largely autonomous urban airspace; and (3) Sustainability, driven by\nenergy-efficient propulsion, integrated charging infrastructure, and holistic\nenvironmental assessment. This paper reviews and synthesizes the latest\nresearch across these areas, compares the state-of-the-art solutions, and\noutlines the technological and infrastructural milestones that are critical to\nrealizing a scalable, sustainable UAM ecosystem.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7efc\u8ff0\u4e862020\u5e74\u4ee5\u6765\u57ce\u5e02\u7a7a\u4e2d\u4ea4\u901a(UAM)\u5728\u901a\u4fe1\u3001\u7ba1\u7406\u548c\u53ef\u6301\u7eed\u6027\u4e09\u4e2a\u5173\u952e\u9886\u57df\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u5c55\uff0c\u5e76\u6307\u51fa\u4e86\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u53ef\u6301\u7eedUAM\u751f\u6001\u7cfb\u7edf\u7684\u5173\u952e\u6280\u672f\u91cc\u7a0b\u7891\u3002", "motivation": "UAM\u4e3a\u89e3\u51b3\u57ce\u5e02\u62e5\u5835\u3001\u6539\u5584\u53ef\u8fbe\u6027\u548c\u63a8\u8fdb\u73af\u5883\u53ef\u6301\u7eed\u6027\u63d0\u4f9b\u4e86\u53d8\u9769\u6027\u65b9\u6cd5\uff0c\u4f46\u9700\u8981\u6574\u5408\u901a\u4fe1\u3001\u7ba1\u7406\u548c\u53ef\u6301\u7eed\u6027\u4e09\u4e2a\u7d27\u5bc6\u5173\u8054\u7684\u9886\u57df\u6765\u5b9e\u73b0\u8fd9\u4e00\u613f\u666f\u3002", "method": "\u901a\u8fc7\u56de\u987e\u548c\u7efc\u5408\u8fd9\u4e09\u4e2a\u9886\u57df\u7684\u6700\u65b0\u7814\u7a76\uff0c\u6bd4\u8f83\u6700\u5148\u8fdb\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5206\u6790\u6280\u672f\u53d1\u5c55\u8d8b\u52bf\u3002", "result": "\u8bc6\u522b\u4e86\u52a8\u6001\u9891\u8c31\u5206\u914d\u3001\u4f4e\u7a7a\u4fe1\u9053\u7279\u6027\u3001\u65b0\u578b\u7a7a\u4e2d\u4ea4\u901a\u63a7\u5236\u6982\u5ff5\u3001\u80fd\u6e90\u9ad8\u6548\u63a8\u8fdb\u7cfb\u7edf\u3001\u96c6\u6210\u5145\u7535\u57fa\u7840\u8bbe\u65bd\u7b49\u5173\u952e\u6280\u672f\u8fdb\u5c55\u3002", "conclusion": "\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u53ef\u6301\u7eed\u7684UAM\u751f\u6001\u7cfb\u7edf\u9700\u8981\u901a\u4fe1\u3001\u7ba1\u7406\u548c\u53ef\u6301\u7eed\u6027\u4e09\u4e2a\u9886\u57df\u7684\u534f\u540c\u53d1\u5c55\uff0c\u5e76\u8fbe\u5230\u7279\u5b9a\u7684\u6280\u672f\u548c\u57fa\u7840\u8bbe\u65bd\u91cc\u7a0b\u7891\u3002"}}
{"id": "2510.18143", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18143", "abs": "https://arxiv.org/abs/2510.18143", "authors": ["Huan Song", "Deeksha Razdan", "Yiyue Qian", "Arijit Ghosh Chowdhury", "Parth Patwa", "Aman Chadha", "Shinan Zhang", "Sharlina Keshava", "Hannah Marlowe"], "title": "Learning from Generalization Patterns: An Evaluation-Driven Approach to Enhanced Data Augmentation for Fine-Tuning Small Language Models", "comment": "Neural Information Processing Systems (NeurIPS 2025) Workshop:\n  Evaluating the Evolving LLM Lifecycle", "summary": "Small Language Models (SLMs) offer compelling advantages in deployment cost\nand latency, but their accuracy often lags behind larger models, particularly\nfor complex domain-specific tasks. While supervised fine-tuning can help bridge\nthis performance gap, it requires substantial manual effort in data preparation\nand iterative optimization. We present PaDA-Agent (Pattern-guided Data\nAugmentation Agent), an evaluation-driven approach that streamlines the data\naugmentation process for SLMs through coordinated operations. Unlike\nstate-of-the-art approaches that focus on model training errors only and\ngenerating error-correcting samples, PaDA-Agent discovers failure patterns from\nthe validation data via evaluations and drafts targeted data augmentation\nstrategies aiming to directly reduce the generalization gap. Our experimental\nresults demonstrate significant improvements over state-of-the-art LLM-based\ndata augmentation approaches for Llama 3.2 1B Instruct model fine-tuning.", "AI": {"tldr": "PaDA-Agent\u662f\u4e00\u79cd\u8bc4\u4f30\u9a71\u52a8\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d1\u73b0\u9a8c\u8bc1\u6570\u636e\u4e2d\u7684\u5931\u8d25\u6a21\u5f0f\u5e76\u5236\u5b9a\u9488\u5bf9\u6027\u7b56\u7565\uff0c\u6765\u63d0\u5347\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u90e8\u7f72\u6210\u672c\u548c\u5ef6\u8fdf\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5728\u590d\u6742\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u6027\u5f80\u5f80\u843d\u540e\u4e8e\u5927\u578b\u6a21\u578b\u3002\u867d\u7136\u6709\u76d1\u7763\u5fae\u8c03\u53ef\u4ee5\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u4f46\u9700\u8981\u5927\u91cf\u624b\u52a8\u6570\u636e\u51c6\u5907\u548c\u8fed\u4ee3\u4f18\u5316\u5de5\u4f5c\u3002", "method": "\u63d0\u51faPaDA-Agent\uff08\u6a21\u5f0f\u5f15\u5bfc\u6570\u636e\u589e\u5f3a\u4ee3\u7406\uff09\uff0c\u901a\u8fc7\u8bc4\u4f30\u53d1\u73b0\u9a8c\u8bc1\u6570\u636e\u4e2d\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u5236\u5b9a\u9488\u5bf9\u6027\u7684\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u76f4\u63a5\u51cf\u5c11\u6cdb\u5316\u5dee\u8ddd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728Llama 3.2 1B Instruct\u6a21\u578b\u5fae\u8c03\u4e0a\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u4e8eLLM\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002", "conclusion": "PaDA-Agent\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u624b\u52a8\u5de5\u4f5c\u91cf\u3002"}}
{"id": "2510.18402", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.18402", "abs": "https://arxiv.org/abs/2510.18402", "authors": ["Matthias Lorenzen", "Teodoro Alamo", "Martina Mammarella", "Fabrizio Dabbene"], "title": "MPC-based motion planning for non-holonomic systems in non-convex domains", "comment": "Preprint of ECC 2025 submission", "summary": "Motivated by the application of using model predictive control (MPC) for\nmotion planning of autonomous mobile robots, a form of output tracking MPC for\nnon-holonomic systems and with non-convex constraints is studied. Although the\nadvantages of using MPC for motion planning have been demonstrated in several\npapers, in most of the available fundamental literature on output tracking MPC\nit is assumed, often implicitly, that the model is holonomic and generally the\nstate or output constraints must be convex. Thus, in application-oriented\npublications, empirical results dominate and the topic of proving completeness,\nin particular under which assumptions the target is always reached, has\nreceived comparatively little attention. To address this gap, we present a\nnovel MPC formulation that guarantees convergence to the desired target under\nrealistic assumptions, which can be verified in relevant real-world scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u975e\u5b8c\u6574\u7cfb\u7edf\u548c\u975e\u51f8\u7ea6\u675f\u7684\u8f93\u51fa\u8ddf\u8e2a\u6a21\u578b\u9884\u6d4b\u63a7\u5236(MPC)\u65b9\u6cd5\uff0c\u4fdd\u8bc1\u5728\u73b0\u5b9e\u5047\u8bbe\u4e0b\u6536\u655b\u5230\u76ee\u6807\u70b9", "motivation": "\u73b0\u6709MPC\u7406\u8bba\u4e3b\u8981\u9488\u5bf9\u5b8c\u6574\u7cfb\u7edf\u548c\u51f8\u7ea6\u675f\uff0c\u800c\u5b9e\u9645\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u6d89\u53ca\u975e\u5b8c\u6574\u7cfb\u7edf\u548c\u975e\u51f8\u7ea6\u675f\uff0c\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1", "method": "\u8bbe\u8ba1\u65b0\u9896\u7684MPC\u516c\u5f0f\uff0c\u8003\u8651\u975e\u5b8c\u6574\u7cfb\u7edf\u7279\u6027\u548c\u975e\u51f8\u7ea6\u675f\u6761\u4ef6", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u4fdd\u8bc1\u5728\u53ef\u9a8c\u8bc1\u7684\u73b0\u5b9e\u5047\u8bbe\u4e0b\u6536\u655b\u5230\u671f\u671b\u76ee\u6807", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e86\u975e\u5b8c\u6574\u7cfb\u7edf\u548c\u975e\u51f8\u7ea6\u675f\u4e0bMPC\u7406\u8bba\u4fdd\u8bc1\u7684\u7a7a\u767d\uff0c\u4e3a\u5b9e\u9645\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6491"}}
{"id": "2510.18273", "categories": ["eess.SY", "cs.DC", "cs.MA", "cs.SY", "eess.SP", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.18273", "abs": "https://arxiv.org/abs/2510.18273", "authors": ["Mohammadreza Doostmohammadian", "Sergio Pequito"], "title": "Distributed Allocation and Resource Scheduling Algorithms Resilient to Link Failure", "comment": "European Journal of Control", "summary": "Distributed resource allocation (DRA) is fundamental to modern networked\nsystems, spanning applications from economic dispatch in smart grids to CPU\nscheduling in data centers. Conventional DRA approaches require reliable\ncommunication, yet real-world networks frequently suffer from link failures,\npacket drops, and communication delays due to environmental conditions, network\ncongestion, and security threats.\n  We introduce a novel resilient DRA algorithm that addresses these critical\nchallenges, and our main contributions are as follows: (1) guaranteed\nconstraint feasibility at all times, ensuring resource-demand balance even\nduring algorithm termination or network disruption; (2) robust convergence\ndespite sector-bound nonlinearities at nodes/links, accommodating practical\nconstraints like quantization and saturation; and (3) optimal performance under\nmerely uniformly-connected networks, eliminating the need for continuous\nconnectivity.\n  Unlike existing approaches that require persistent network connectivity and\nprovide only asymptotic feasibility, our graph-theoretic solution leverages\nnetwork percolation theory to maintain performance during intermittent\ndisconnections. This makes it particularly valuable for mobile multi-agent\nsystems where nodes frequently move out of communication range. Theoretical\nanalysis and simulations demonstrate that our algorithm converges to optimal\nsolutions despite heterogeneous time delays and substantial link failures,\nsignificantly advancing the reliability of distributed resource allocation in\npractical network environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5f39\u6027\u5206\u5e03\u5f0f\u8d44\u6e90\u5206\u914d\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u7f51\u7edc\u8fde\u63a5\u4e2d\u65ad\u3001\u94fe\u8def\u6545\u969c\u548c\u901a\u4fe1\u5ef6\u8fdf\u7684\u60c5\u51b5\u4e0b\u4fdd\u8bc1\u7ea6\u675f\u53ef\u884c\u6027\u548c\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u7f51\u7edc\u7ecf\u5e38\u906d\u53d7\u94fe\u8def\u6545\u969c\u3001\u6570\u636e\u5305\u4e22\u5931\u548c\u901a\u4fe1\u5ef6\u8fdf\uff0c\u800c\u4f20\u7edf\u5206\u5e03\u5f0f\u8d44\u6e90\u5206\u914d\u65b9\u6cd5\u9700\u8981\u53ef\u9760\u7684\u901a\u4fe1\u8fde\u63a5\uff0c\u8fd9\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u96be\u4ee5\u4fdd\u8bc1\u3002", "method": "\u57fa\u4e8e\u56fe\u8bba\u548c\u7f51\u7edc\u6e17\u900f\u7406\u8bba\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5f39\u6027\u5206\u5e03\u5f0f\u8d44\u6e90\u5206\u914d\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u4ec5\u9700\u5747\u5300\u8fde\u63a5\u7f51\u7edc\u7684\u60c5\u51b5\u4e0b\u5de5\u4f5c\uff0c\u65e0\u9700\u6301\u7eed\u8fde\u63a5\u6027\u3002", "result": "\u7b97\u6cd5\u5728\u6240\u6709\u65f6\u95f4\u4fdd\u8bc1\u7ea6\u675f\u53ef\u884c\u6027\uff0c\u5728\u5b58\u5728\u5f02\u6784\u65f6\u95f4\u5ef6\u8fdf\u548c\u5927\u91cf\u94fe\u8def\u6545\u969c\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u6536\u655b\u5230\u6700\u4f18\u89e3\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u5e03\u5f0f\u8d44\u6e90\u5206\u914d\u5728\u5b9e\u9645\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u79fb\u52a8\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7b49\u8fde\u63a5\u4e0d\u7a33\u5b9a\u7684\u573a\u666f\u3002"}}
{"id": "2510.18154", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.18154", "abs": "https://arxiv.org/abs/2510.18154", "authors": ["Antonio-Gabriel Chac\u00f3n Menke", "Phan Xuan Tan", "Eiji Kamioka"], "title": "Annotating the Chain-of-Thought: A Behavior-Labeled Dataset for AI Safety", "comment": null, "summary": "Recent work has highlighted the importance of monitoring chain-of-thought\nreasoning for AI safety; however, current approaches that analyze textual\nreasoning steps can miss subtle harmful patterns and may be circumvented by\nmodels that hide unsafe reasoning. We present a sentence-level labeled dataset\nthat enables activation-based monitoring of safety behaviors during LLM\nreasoning. Our dataset contains reasoning sequences with sentence-level\nannotations of safety behaviors such as expression of safety concerns or\nspeculation on user intent, which we use to extract steering vectors for\ndetecting and influencing these behaviors within model activations. The dataset\nfills a key gap in safety research: while existing datasets label reasoning\nholistically, effective application of steering vectors for safety monitoring\ncould be improved by identifying precisely when specific behaviors occur within\nreasoning chains. We demonstrate the dataset's utility by extracting\nrepresentations that both detect and steer safety behaviors in model\nactivations, showcasing the potential of activation-level techniques for\nimproving safety oversight on reasoning.\n  Content Warning: This paper discusses AI safety in the context of harmful\nprompts and may contain references to potentially harmful content.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53e5\u5b50\u7ea7\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u5728LLM\u63a8\u7406\u8fc7\u7a0b\u4e2d\u57fa\u4e8e\u6fc0\u6d3b\u7684\u5b89\u5168\u884c\u4e3a\u76d1\u63a7\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6570\u636e\u96c6\u4ec5\u6574\u4f53\u6807\u6ce8\u63a8\u7406\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6587\u672c\u63a8\u7406\u6b65\u9aa4\u7684\u5b89\u5168\u76d1\u63a7\u65b9\u6cd5\u53ef\u80fd\u9057\u6f0f\u7ec6\u5fae\u7684\u6709\u5bb3\u6a21\u5f0f\uff0c\u4e14\u53ef\u80fd\u88ab\u9690\u85cf\u4e0d\u5b89\u5168\u63a8\u7406\u7684\u6a21\u578b\u89c4\u907f\uff0c\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u5b89\u5168\u884c\u4e3a\u76d1\u63a7\u3002", "method": "\u6784\u5efa\u5305\u542b\u53e5\u5b50\u7ea7\u5b89\u5168\u884c\u4e3a\u6807\u6ce8\uff08\u5982\u5b89\u5168\u5173\u5207\u8868\u8fbe\u3001\u7528\u6237\u610f\u56fe\u63a8\u6d4b\uff09\u7684\u6570\u636e\u96c6\uff0c\u5e76\u4ece\u4e2d\u63d0\u53d6\u7528\u4e8e\u68c0\u6d4b\u548c\u5f71\u54cd\u8fd9\u4e9b\u884c\u4e3a\u7684\u5f15\u5bfc\u5411\u91cf\u3002", "result": "\u5c55\u793a\u4e86\u8be5\u6570\u636e\u96c6\u7684\u5b9e\u7528\u6027\uff0c\u901a\u8fc7\u63d0\u53d6\u7684\u8868\u5f81\u80fd\u591f\u5728\u6a21\u578b\u6fc0\u6d3b\u4e2d\u68c0\u6d4b\u548c\u5f15\u5bfc\u5b89\u5168\u884c\u4e3a\u3002", "conclusion": "\u6fc0\u6d3b\u7ea7\u6280\u672f\u6709\u6f5c\u529b\u6539\u5584\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u76d1\u7763\uff0c\u4e3aAI\u5b89\u5168\u76d1\u63a7\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2510.18518", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.18518", "abs": "https://arxiv.org/abs/2510.18518", "authors": ["Fang Nan", "Hao Ma", "Qinghua Guan", "Josie Hughes", "Michael Muehlebach", "Marco Hutter"], "title": "Efficient Model-Based Reinforcement Learning for Robot Control via Online Learning", "comment": null, "summary": "We present an online model-based reinforcement learning algorithm suitable\nfor controlling complex robotic systems directly in the real world. Unlike\nprevailing sim-to-real pipelines that rely on extensive offline simulation and\nmodel-free policy optimization, our method builds a dynamics model from\nreal-time interaction data and performs policy updates guided by the learned\ndynamics model. This efficient model-based reinforcement learning scheme\nsignificantly reduces the number of samples to train control policies, enabling\ndirect training on real-world rollout data. This significantly reduces the\ninfluence of bias in the simulated data, and facilitates the search for\nhigh-performance control policies. We adopt online learning analysis to derive\nsublinear regret bounds under standard stochastic online optimization\nassumptions, providing formal guarantees on performance improvement as more\ninteraction data are collected. Experimental evaluations were performed on a\nhydraulic excavator arm and a soft robot arm, where the algorithm demonstrates\nstrong sample efficiency compared to model-free reinforcement learning methods,\nreaching comparable performance within hours. Robust adaptation to shifting\ndynamics was also observed when the payload condition was randomized. Our\napproach paves the way toward efficient and reliable on-robot learning for a\nbroad class of challenging control tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7ebf\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u53ef\u76f4\u63a5\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u8bad\u7ec3\u590d\u6742\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u76f8\u6bd4\u6a21\u578b\u65e0\u5173\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u7684sim-to-real\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u79bb\u7ebf\u4eff\u771f\uff0c\u5b58\u5728\u6a21\u62df\u6570\u636e\u504f\u5dee\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u76f4\u63a5\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u9ad8\u6548\u5b66\u4e60\u63a7\u5236\u7b56\u7565\u3002", "method": "\u4ece\u5b9e\u65f6\u4ea4\u4e92\u6570\u636e\u6784\u5efa\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u57fa\u4e8e\u5b66\u4e60\u5230\u7684\u6a21\u578b\u6307\u5bfc\u7b56\u7565\u66f4\u65b0\uff0c\u91c7\u7528\u5728\u7ebf\u5b66\u4e60\u5206\u6790\u63a8\u5bfc\u6027\u80fd\u4fdd\u8bc1\u3002", "result": "\u5728\u6db2\u538b\u6316\u6398\u81c2\u548c\u8f6f\u4f53\u673a\u5668\u4eba\u81c2\u4e0a\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u6a21\u578b\u65e0\u5173\u65b9\u6cd5\u6837\u672c\u6548\u7387\u663e\u8457\u63d0\u5347\uff0c\u6570\u5c0f\u65f6\u5185\u8fbe\u5230\u53ef\u6bd4\u6027\u80fd\uff0c\u4e14\u80fd\u9002\u5e94\u52a8\u6001\u53d8\u5316\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6311\u6218\u6027\u63a7\u5236\u4efb\u52a1\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u5728\u7ebf\u673a\u5668\u4eba\u5b66\u4e60\u9014\u5f84\u3002"}}
{"id": "2510.18420", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.18420", "abs": "https://arxiv.org/abs/2510.18420", "authors": ["Abdullah Ajasa", "Mubarak Badamasi Aremu", "Ali Nasir"], "title": "Sliding-Mode Control Strategies for PMSM speed control: A Comprehensive Review, Taxonomy and Research Gaps", "comment": "30 Pages, 7 Fugures, 3 Tables", "summary": "Permanent Magnet Synchronous Motors (PMSMs) are widely employed in\nhigh-performance drive systems due to their high efficiency, power density, and\nprecise dynamic behavior. However, nonlinearities, load disturbances, and\nparameter uncertainties present persistent challenges to control. Sliding-Mode\nControl (SMC) remains one of the most reliable strategies for high-performance\nPMSM drives. Yet, the rapid proliferation of adaptive, fractional-order, and\nintelligent variants has fragmented recent literature. This paper presents a\ncomprehensive review and taxonomy of SMC-based PMSM speed-control methods\npublished between 2020 and 2025. More than 200 studies are systematically\nanalyzed and classified according to control order, surface design,\ndisturbance-observer integration, optimization approach, and intelligent\naugmentation. Trends in publication activity, dominant hybrid structures, and\napplication domains are quantitatively summarized. The review reveals a clear\nevolution from conventional discontinuous SMC toward adaptive, higher-order,\nand data-driven frameworks that mitigate chattering while preserving\nrobustness. Persistent research gaps are identified in hardware validation,\nenergy-efficiency assessment, and real-time tuning strategies. The taxonomy and\ncritical synthesis provided herein establish a coherent reference for\nresearchers and form the conceptual foundation for the companion paper (Part\nII), which delivers a unified benchmark and comparative simulation study of\nrepresentative SMC designs.", "AI": {"tldr": "\u672c\u6587\u5bf92020-2025\u5e74\u95f4\u57fa\u4e8e\u6ed1\u6a21\u63a7\u5236\u7684\u6c38\u78c1\u540c\u6b65\u7535\u673a\u901f\u5ea6\u63a7\u5236\u65b9\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\u548c\u5206\u7c7b\uff0c\u5206\u6790\u4e86200\u591a\u9879\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u4ece\u4f20\u7edf\u4e0d\u8fde\u7eed\u6ed1\u6a21\u63a7\u5236\u5411\u81ea\u9002\u5e94\u3001\u9ad8\u9636\u548c\u6570\u636e\u9a71\u52a8\u6846\u67b6\u7684\u6f14\u53d8\u8d8b\u52bf\u3002", "motivation": "\u6c38\u78c1\u540c\u6b65\u7535\u673a\u5728\u9ad8\u6027\u80fd\u9a71\u52a8\u7cfb\u7edf\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u975e\u7ebf\u6027\u3001\u8d1f\u8f7d\u6270\u52a8\u548c\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u7ed9\u63a7\u5236\u5e26\u6765\u6311\u6218\u3002\u6ed1\u6a21\u63a7\u5236\u662f\u53ef\u9760\u7b56\u7565\uff0c\u4f46\u81ea\u9002\u5e94\u3001\u5206\u6570\u9636\u548c\u667a\u80fd\u53d8\u79cd\u7684\u5feb\u901f\u6269\u6563\u4f7f\u8fd1\u671f\u6587\u732e\u788e\u7247\u5316\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u3002", "method": "\u5bf9200\u591a\u9879\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\u548c\u5206\u7c7b\uff0c\u6309\u7167\u63a7\u5236\u9636\u6570\u3001\u6ed1\u6a21\u9762\u8bbe\u8ba1\u3001\u6270\u52a8\u89c2\u6d4b\u5668\u96c6\u6210\u3001\u4f18\u5316\u65b9\u6cd5\u548c\u667a\u80fd\u589e\u5f3a\u8fdb\u884c\u5206\u7c7b\uff0c\u5b9a\u91cf\u603b\u7ed3\u53d1\u8868\u8d8b\u52bf\u3001\u4e3b\u5bfc\u6df7\u5408\u7ed3\u6784\u548c\u5e94\u7528\u9886\u57df\u3002", "result": "\u7efc\u8ff0\u63ed\u793a\u4e86\u4ece\u4f20\u7edf\u4e0d\u8fde\u7eed\u6ed1\u6a21\u63a7\u5236\u5411\u81ea\u9002\u5e94\u3001\u9ad8\u9636\u548c\u6570\u636e\u9a71\u52a8\u6846\u67b6\u7684\u6e05\u6670\u6f14\u53d8\uff0c\u8fd9\u4e9b\u6846\u67b6\u5728\u4fdd\u6301\u9c81\u68d2\u6027\u7684\u540c\u65f6\u51cf\u8f7b\u4e86\u6296\u632f\u95ee\u9898\u3002", "conclusion": "\u8bc6\u522b\u4e86\u786c\u4ef6\u9a8c\u8bc1\u3001\u80fd\u6548\u8bc4\u4f30\u548c\u5b9e\u65f6\u8c03\u8c10\u7b56\u7565\u65b9\u9762\u7684\u6301\u7eed\u7814\u7a76\u7a7a\u767d\uff0c\u5efa\u7acb\u7684\u5206\u7c7b\u6cd5\u548c\u6279\u5224\u6027\u7efc\u5408\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u8fde\u8d2f\u53c2\u8003\uff0c\u5e76\u4e3a\u540e\u7eed\u7edf\u4e00\u57fa\u51c6\u548c\u6bd4\u8f83\u4eff\u771f\u7814\u7a76\u5960\u5b9a\u4e86\u6982\u5ff5\u57fa\u7840\u3002"}}
{"id": "2510.18546", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18546", "abs": "https://arxiv.org/abs/2510.18546", "authors": ["Zebin Yang", "Sunjian Zheng", "Tong Xie", "Tianshi Xu", "Bo Yu", "Fan Wang", "Jie Tang", "Shaoshan Liu", "Meng Li"], "title": "EfficientNav: Towards On-Device Object-Goal Navigation with Navigation Map Caching and Retrieval", "comment": "NeurIPS 2025", "summary": "Object-goal navigation (ObjNav) tasks an agent with navigating to the\nlocation of a specific object in an unseen environment. Embodied agents\nequipped with large language models (LLMs) and online constructed navigation\nmaps can perform ObjNav in a zero-shot manner. However, existing agents heavily\nrely on giant LLMs on the cloud, e.g., GPT-4, while directly switching to small\nLLMs, e.g., LLaMA3.2-11b, suffer from significant success rate drops due to\nlimited model capacity for understanding complex navigation maps, which\nprevents deploying ObjNav on local devices. At the same time, the long prompt\nintroduced by the navigation map description will cause high planning latency\non local devices. In this paper, we propose EfficientNav to enable on-device\nefficient LLM-based zero-shot ObjNav. To help the smaller LLMs better\nunderstand the environment, we propose semantics-aware memory retrieval to\nprune redundant information in navigation maps. To reduce planning latency, we\npropose discrete memory caching and attention-based memory clustering to\nefficiently save and re-use the KV cache. Extensive experimental results\ndemonstrate that EfficientNav achieves 11.1% improvement in success rate on\nHM3D benchmark over GPT-4-based baselines, and demonstrates 6.7x real-time\nlatency reduction and 4.7x end-to-end latency reduction over GPT-4 planner. Our\ncode will be released soon.", "AI": {"tldr": "EfficientNav \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u96f6\u6837\u672c\u7269\u4f53\u5bfc\u822a\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u5185\u5b58\u68c0\u7d22\u548c\u79bb\u6563\u5185\u5b58\u7f13\u5b58\u6280\u672f\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7269\u4f53\u5bfc\u822a\u65b9\u6cd5\u4f9d\u8d56\u4e91\u7aef\u5de8\u578b\u6a21\u578b\uff0c\u65e0\u6cd5\u5728\u672c\u5730\u8bbe\u5907\u90e8\u7f72\u3002\u76f4\u63a5\u4f7f\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4f1a\u56e0\u6a21\u578b\u5bb9\u91cf\u9650\u5236\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u4e14\u5bfc\u822a\u5730\u56fe\u7684\u957f\u63d0\u793a\u4f1a\u5bfc\u81f4\u9ad8\u89c4\u5212\u5ef6\u8fdf\u3002", "method": "\u63d0\u51fa\u8bed\u4e49\u611f\u77e5\u5185\u5b58\u68c0\u7d22\u6765\u4fee\u526a\u5bfc\u822a\u5730\u56fe\u4e2d\u7684\u5197\u4f59\u4fe1\u606f\uff0c\u5e2e\u52a9\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u66f4\u597d\u5730\u7406\u89e3\u73af\u5883\uff1b\u91c7\u7528\u79bb\u6563\u5185\u5b58\u7f13\u5b58\u548c\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u5185\u5b58\u805a\u7c7b\u6765\u9ad8\u6548\u4fdd\u5b58\u548c\u91cd\u7528KV\u7f13\u5b58\uff0c\u51cf\u5c11\u89c4\u5212\u5ef6\u8fdf\u3002", "result": "\u5728HM3D\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u57fa\u4e8eGPT-4\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0cEfficientNav\u5b9e\u73b0\u4e8611.1%\u7684\u6210\u529f\u7387\u63d0\u5347\uff0c\u540c\u65f6\u5b9e\u73b0\u4e866.7\u500d\u7684\u5b9e\u65f6\u5ef6\u8fdf\u964d\u4f4e\u548c4.7\u500d\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u964d\u4f4e\u3002", "conclusion": "EfficientNav\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u672c\u5730\u8bbe\u5907\u4e0a\u9ad8\u6548\u8fd0\u884c\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u96f6\u6837\u672c\u7269\u4f53\u5bfc\u822a\uff0c\u5728\u6027\u80fd\u548c\u5ef6\u8fdf\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u4e8e\u4e91\u7aef\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.18645", "categories": ["eess.SY", "cs.CR", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.18645", "abs": "https://arxiv.org/abs/2510.18645", "authors": ["Sribalaji C. Anand", "Anh Tung Nguyen", "Andr\u00e9 M. H. Teixeira", "Henrik Sandberg", "Karl H. Johansson"], "title": "Quantifying Security for Networked Control Systems: A Review", "comment": "Journal submission", "summary": "Networked Control Systems (NCSs) are integral in critical infrastructures\nsuch as power grids, transportation networks, and production systems. Ensuring\nthe resilient operation of these large-scale NCSs against cyber-attacks is\ncrucial for societal well-being. Over the past two decades, extensive research\nhas been focused on developing metrics to quantify the vulnerabilities of NCSs\nagainst attacks. Once the vulnerabilities are quantified, mitigation strategies\ncan be employed to enhance system resilience. This article provides a\ncomprehensive overview of methods developed for assessing NCS vulnerabilities\nand the corresponding mitigation strategies. Furthermore, we emphasize the\nimportance of probabilistic risk metrics to model vulnerabilities under\nadversaries with imperfect process knowledge. The article concludes by\noutlining promising directions for future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u7f51\u7edc\u63a7\u5236\u7cfb\u7edf(NCSs)\u7684\u8106\u5f31\u6027\u8bc4\u4f30\u65b9\u6cd5\u548c\u7f13\u89e3\u7b56\u7565\uff0c\u5f3a\u8c03\u6982\u7387\u98ce\u9669\u6307\u6807\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u7f51\u7edc\u63a7\u5236\u7cfb\u7edf\u5728\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u786e\u4fdd\u8fd9\u4e9b\u5927\u89c4\u6a21\u7cfb\u7edf\u5bf9\u7f51\u7edc\u653b\u51fb\u7684\u5f39\u6027\u8fd0\u884c\u5bf9\u793e\u4f1a\u798f\u7949\u81f3\u5173\u91cd\u8981\u3002\u8fc7\u53bb\u4e8c\u5341\u5e74\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u91cf\u5316NCSs\u7684\u8106\u5f31\u6027\u6307\u6807\u4e0a\u3002", "method": "\u63d0\u4f9b\u5bf9NCSs\u8106\u5f31\u6027\u8bc4\u4f30\u65b9\u6cd5\u548c\u76f8\u5e94\u7f13\u89e3\u7b56\u7565\u7684\u5168\u9762\u6982\u8ff0\uff0c\u7279\u522b\u5f3a\u8c03\u4f7f\u7528\u6982\u7387\u98ce\u9669\u6307\u6807\u6765\u5efa\u6a21\u5177\u6709\u4e0d\u5b8c\u5168\u8fc7\u7a0b\u77e5\u8bc6\u7684\u5bf9\u624b\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u6027\u3002", "result": "\u7cfb\u7edf\u68b3\u7406\u4e86\u7f51\u7edc\u63a7\u5236\u7cfb\u7edf\u8106\u5f31\u6027\u91cf\u5316\u548c\u7f13\u89e3\u7b56\u7565\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u7efc\u5408\u6027\u7684\u5206\u6790\u6846\u67b6\u3002", "conclusion": "\u8bba\u6587\u603b\u7ed3\u4e86\u73b0\u6709\u7814\u7a76\u6210\u679c\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u51e0\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u5305\u62ec\u8fdb\u4e00\u6b65\u5b8c\u5584\u6982\u7387\u98ce\u9669\u6307\u6807\u548c\u5f00\u53d1\u66f4\u6709\u6548\u7684\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2510.18165", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18165", "abs": "https://arxiv.org/abs/2510.18165", "authors": ["Yihong Dong", "Zhaoyu Ma", "Xue Jiang", "Zhiyuan Fan", "Jiaru Qian", "Yongmin Li", "Jianha Xiao", "Zhi Jin", "Rongyu Cao", "Binhua Li", "Fei Huang", "Yongbin Li", "Ge Li"], "title": "Saber: An Efficient Sampling with Adaptive Acceleration and Backtracking Enhanced Remasking for Diffusion Language Model", "comment": null, "summary": "Diffusion language models (DLMs) are emerging as a powerful and promising\nalternative to the dominant autoregressive paradigm, offering inherent\nadvantages in parallel generation and bidirectional context modeling. However,\nthe performance of DLMs on code generation tasks, which have stronger\nstructural constraints, is significantly hampered by the critical trade-off\nbetween inference speed and output quality. We observed that accelerating the\ncode generation process by reducing the number of sampling steps usually leads\nto a catastrophic collapse in performance. In this paper, we introduce\nefficient Sampling with Adaptive acceleration and Backtracking Enhanced\nRemasking (i.e., Saber), a novel training-free sampling algorithm for DLMs to\nachieve better inference speed and output quality in code generation.\nSpecifically, Saber is motivated by two key insights in the DLM generation\nprocess: 1) it can be adaptively accelerated as more of the code context is\nestablished; 2) it requires a backtracking mechanism to reverse the generated\ntokens. Extensive experiments on multiple mainstream code generation benchmarks\nshow that Saber boosts Pass@1 accuracy by an average improvement of 1.9% over\nmainstream DLM sampling methods, meanwhile achieving an average 251.4%\ninference speedup. By leveraging the inherent advantages of DLMs, our work\nsignificantly narrows the performance gap with autoregressive models in code\ngeneration.", "AI": {"tldr": "\u63d0\u51faSaber\u7b97\u6cd5\uff0c\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b0\u578b\u91c7\u6837\u65b9\u6cd5\uff0c\u7528\u4e8e\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u5e73\u8861\u63a8\u7406\u901f\u5ea6\u4e0e\u8f93\u51fa\u8d28\u91cf\u3002", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u5b58\u5728\u63a8\u7406\u901f\u5ea6\u4e0e\u8f93\u51fa\u8d28\u91cf\u7684\u5173\u952e\u6743\u8861\u95ee\u9898\uff0c\u51cf\u5c11\u91c7\u6837\u6b65\u9aa4\u901a\u5e38\u5bfc\u81f4\u6027\u80fd\u707e\u96be\u6027\u4e0b\u964d\u3002", "method": "Saber\u7b97\u6cd5\u57fa\u4e8e\u4e24\u4e2a\u5173\u952e\u6d1e\u5bdf\uff1a1\uff09\u968f\u7740\u4ee3\u7801\u4e0a\u4e0b\u6587\u7684\u5efa\u7acb\u53ef\u4ee5\u81ea\u9002\u5e94\u52a0\u901f\uff1b2\uff09\u9700\u8981\u56de\u6eaf\u673a\u5236\u6765\u53cd\u8f6c\u751f\u6210\u7684\u6807\u8bb0\u3002", "result": "\u5728\u591a\u4e2a\u4e3b\u6d41\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSaber\u76f8\u6bd4\u4e3b\u6d41DLM\u91c7\u6837\u65b9\u6cd5\u5e73\u5747\u63d0\u5347Pass@1\u51c6\u786e\u73871.9%\uff0c\u540c\u65f6\u5b9e\u73b0\u5e73\u5747251.4%\u7684\u63a8\u7406\u52a0\u901f\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528DLM\u7684\u56fa\u6709\u4f18\u52bf\uff0c\u8be5\u5de5\u4f5c\u663e\u8457\u7f29\u5c0f\u4e86\u4e0e\u81ea\u56de\u5f52\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u7684\u6027\u80fd\u5dee\u8ddd\u3002"}}
{"id": "2510.18558", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.18558", "abs": "https://arxiv.org/abs/2510.18558", "authors": ["Yue Wang", "Lixian Zhang", "Yimin Zhu", "Yangguang Liu", "Xuwei Yang"], "title": "Flexbee: A Grasping and Perching UAV Based on Soft Vector-Propulsion Nozzle", "comment": "11 pages, 17 figures", "summary": "The aim of this paper is to design a new type of grasping and perching\nunmanned aerial vehicle (UAV), called Flexbee, which features a soft\nvector-propulsion nozzle (SVPN). Compared to previous UAVs, Flexbee integrates\nflight, grasping, and perching functionalities into the four SVPNs. This\nintegration offers advantages including decoupled position and attitude\ncontrol, high structural reuse, and strong adaptability strong adaptability for\ngrasping and perching. A dynamics model of Flexbee has been developed, and the\nnonlinear coupling issue of the moment has been resolved through linearization\nof the equivalent moment model. A hierarchical control strategy was used to\ndesign controllers for the two operational modes of Flexbee. Finally, flight,\ngrasping, and perching experiments were conducted to validate Flexbee's\nkinematic capabilities and the effectiveness of the control strategy.", "AI": {"tldr": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u578b\u6293\u53d6\u548c\u6816\u606f\u65e0\u4eba\u673aFlexbee\uff0c\u96c6\u6210\u4e86\u8f6f\u4f53\u77e2\u91cf\u63a8\u8fdb\u55b7\u5634\uff0c\u5b9e\u73b0\u4e86\u98de\u884c\u3001\u6293\u53d6\u548c\u6816\u606f\u529f\u80fd\u7684\u7edf\u4e00\uff0c\u5177\u6709\u89e3\u8026\u63a7\u5236\u3001\u9ad8\u7ed3\u6784\u590d\u7528\u6027\u548c\u5f3a\u9002\u5e94\u6027\u3002", "motivation": "\u4f20\u7edf\u65e0\u4eba\u673a\u901a\u5e38\u5c06\u98de\u884c\u3001\u6293\u53d6\u548c\u6816\u606f\u529f\u80fd\u5206\u5f00\u8bbe\u8ba1\uff0c\u5bfc\u81f4\u7cfb\u7edf\u590d\u6742\u4e14\u6548\u7387\u4f4e\u4e0b\u3002Flexbee\u65e8\u5728\u901a\u8fc7\u8f6f\u4f53\u77e2\u91cf\u63a8\u8fdb\u55b7\u5634\u5c06\u8fd9\u4e9b\u529f\u80fd\u96c6\u6210\u5230\u56db\u4e2a\u63a8\u8fdb\u5668\u4e2d\uff0c\u63d0\u9ad8\u7ed3\u6784\u6548\u7387\u548c\u9002\u5e94\u6027\u3002", "method": "\u5f00\u53d1\u4e86Flexbee\u7684\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u901a\u8fc7\u7b49\u6548\u529b\u77e9\u6a21\u578b\u7684\u7ebf\u6027\u5316\u89e3\u51b3\u4e86\u975e\u7ebf\u6027\u8026\u5408\u95ee\u9898\uff0c\u5e76\u91c7\u7528\u5206\u5c42\u63a7\u5236\u7b56\u7565\u8bbe\u8ba1\u4e24\u79cd\u64cd\u4f5c\u6a21\u5f0f\u7684\u63a7\u5236\u5668\u3002", "result": "\u901a\u8fc7\u98de\u884c\u3001\u6293\u53d6\u548c\u6816\u606f\u5b9e\u9a8c\u9a8c\u8bc1\u4e86Flexbee\u7684\u8fd0\u52a8\u5b66\u80fd\u529b\u548c\u63a7\u5236\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u591a\u79cd\u64cd\u4f5c\u6a21\u5f0f\u4e0b\u7684\u6027\u80fd\u3002", "conclusion": "Flexbee\u6210\u529f\u5b9e\u73b0\u4e86\u98de\u884c\u3001\u6293\u53d6\u548c\u6816\u606f\u529f\u80fd\u7684\u96c6\u6210\uff0c\u8bc1\u660e\u4e86\u8f6f\u4f53\u77e2\u91cf\u63a8\u8fdb\u55b7\u5634\u5728\u65e0\u4eba\u673a\u8bbe\u8ba1\u4e2d\u7684\u53ef\u884c\u6027\u548c\u4f18\u52bf\uff0c\u4e3a\u672a\u6765\u591a\u529f\u80fd\u65e0\u4eba\u673a\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2510.18738", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.18738", "abs": "https://arxiv.org/abs/2510.18738", "authors": ["Xin Zheng", "Yifei Jin", "Yujing Liu", "Lei Guo"], "title": "$\\ell_1$-Based Adaptive Identification under Quantized Observations with Applications", "comment": null, "summary": "Quantized observations are ubiquitous in a wide range of applications across\nengineering and the social sciences, and algorithms based on the $\\ell_1$-norm\nare well recognized for their robustness to outliers compared with their\n$\\ell_2$-based counterparts. Nevertheless, adaptive identification methods that\nintegrate quantized observations with $\\ell_1$-optimization remain largely\nunderexplored. Motivated by this gap, we develop a novel $\\ell_1$-based\nadaptive identification algorithm specifically designed for quantized\nobservations. Without relying on the traditional persistent excitation\ncondition, we establish global convergence of the parameter estimates to their\ntrue values and show that the average regret asymptotically vanishes as the\ndata size increases. Finally, we apply our new identification algorithm to a\njudicial sentencing problem using real-world data, which demonstrates its\nsuperior performance and practical significance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u2113\u2081\u8303\u6570\u7684\u81ea\u9002\u5e94\u8bc6\u522b\u7b97\u6cd5\uff0c\u4e13\u95e8\u7528\u4e8e\u91cf\u5316\u89c2\u6d4b\u6570\u636e\uff0c\u65e0\u9700\u4f20\u7edf\u6301\u7eed\u6fc0\u52b1\u6761\u4ef6\u5373\u53ef\u5b9e\u73b0\u53c2\u6570\u4f30\u8ba1\u7684\u5168\u5c40\u6536\u655b\u3002", "motivation": "\u91cf\u5316\u89c2\u6d4b\u5728\u5de5\u7a0b\u548c\u793e\u4f1a\u79d1\u5b66\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u57fa\u4e8e\u2113\u2081\u8303\u6570\u7684\u7b97\u6cd5\u5bf9\u5f02\u5e38\u503c\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4f46\u7ed3\u5408\u91cf\u5316\u89c2\u6d4b\u7684\u81ea\u9002\u5e94\u8bc6\u522b\u65b9\u6cd5\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u2113\u2081\u57fa\u81ea\u9002\u5e94\u8bc6\u522b\u7b97\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u91cf\u5316\u89c2\u6d4b\u8bbe\u8ba1\uff0c\u4e0d\u4f9d\u8d56\u6301\u7eed\u6fc0\u52b1\u6761\u4ef6\u3002", "result": "\u8bc1\u660e\u4e86\u53c2\u6570\u4f30\u8ba1\u80fd\u5168\u5c40\u6536\u655b\u5230\u771f\u5b9e\u503c\uff0c\u5e73\u5747\u9057\u61be\u968f\u6570\u636e\u91cf\u589e\u52a0\u6e10\u8fd1\u6d88\u5931\uff0c\u5728\u53f8\u6cd5\u91cf\u5211\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u5728\u91cf\u5316\u89c2\u6d4b\u573a\u666f\u4e0b\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u5728\u771f\u5b9e\u6570\u636e\u5e94\u7528\u4e2d\u5c55\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\u548c\u5b9e\u7528\u610f\u4e49\u3002"}}
{"id": "2510.18600", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.18600", "abs": "https://arxiv.org/abs/2510.18600", "authors": ["Shubham Vyas", "Franek Stark", "Rohit Kumar", "Hannah Isermann", "Jonas Haack", "Mihaela Popescu", "Jakob Middelberg", "Dennis Mronga", "Frank Kirchner"], "title": "Quadrupeds for Planetary Exploration: Field Testing Control Algorithms on an Active Volcano", "comment": "Presented at 18th Symposium on Advanced Space Technologies in\n  Robotics and Automation (ASTRA)", "summary": "Missions such as the Ingenuity helicopter have shown the advantages of using\nnovel locomotion modes to increase the scientific return of planetary\nexploration missions. Legged robots can further expand the reach and capability\nof future planetary missions by traversing more difficult terrain than wheeled\nrovers, such as jumping over cracks on the ground or traversing rugged terrain\nwith boulders. To develop and test algorithms for using quadruped robots, the\nAAPLE project was carried out at DFKI. As part of the project, we conducted a\nseries of field experiments on the Volcano on the Aeolian island of Vulcano, an\nactive stratovolcano near Sicily, Italy. The experiments focused on validating\nnewly developed state-of-the-art adaptive optimal control algorithms for\nquadrupedal locomotion in a high-fidelity analog environment for Lunar and\nMartian surfaces. This paper presents the technical approach, test plan,\nsoftware architecture, field deployment strategy, and evaluation results from\nthe Vulcano campaign.", "AI": {"tldr": "\u5728\u610f\u5927\u5229\u6b66\u5c14\u5361\u8bfa\u706b\u5c71\u8fdb\u884c\u7684\u56db\u8db3\u673a\u5668\u4eba\u5b9e\u5730\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u7528\u4e8e\u6708\u7403\u548c\u706b\u661f\u8868\u9762\u6a21\u62df\u73af\u5883\u7684\u65b0\u578b\u81ea\u9002\u5e94\u6700\u4f18\u63a7\u5236\u7b97\u6cd5\u3002", "motivation": "\u6269\u5c55\u884c\u661f\u63a2\u7d22\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u8ba9\u817f\u5f0f\u673a\u5668\u4eba\u80fd\u591f\u7a7f\u8d8a\u6bd4\u8f6e\u5f0f\u63a2\u6d4b\u5668\u66f4\u56f0\u96be\u7684\u5730\u5f62\uff0c\u5982\u8df3\u8fc7\u5730\u9762\u88c2\u7f1d\u6216\u5728\u5d0e\u5c96\u5730\u5f62\u4e2d\u79fb\u52a8\u3002", "method": "\u5728\u6b66\u5c14\u5361\u8bfa\u706b\u5c71\u8fdb\u884c\u5b9e\u5730\u5b9e\u9a8c\uff0c\u91c7\u7528\u65b0\u5f00\u53d1\u7684\u81ea\u9002\u5e94\u6700\u4f18\u63a7\u5236\u7b97\u6cd5\uff0c\u6d4b\u8bd5\u56db\u8db3\u673a\u5668\u4eba\u5728\u9ad8\u4fdd\u771f\u6a21\u62df\u73af\u5883\u4e2d\u7684\u8fd0\u52a8\u80fd\u529b\u3002", "result": "\u6210\u529f\u9a8c\u8bc1\u4e86\u72b6\u6001\u81ea\u9002\u5e94\u6700\u4f18\u63a7\u5236\u7b97\u6cd5\u5728\u6a21\u62df\u6708\u7403\u548c\u706b\u661f\u8868\u9762\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u817f\u5f0f\u673a\u5668\u4eba\u80fd\u591f\u663e\u8457\u589e\u5f3a\u672a\u6765\u884c\u661f\u63a2\u7d22\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u56f0\u96be\u5730\u5f62\u4e2d\u7684\u79fb\u52a8\u6027\u80fd\u3002"}}
{"id": "2510.18176", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18176", "abs": "https://arxiv.org/abs/2510.18176", "authors": ["Soumya Rani Samineni", "Durgesh Kalwar", "Vardaan Gangal", "Siddhant Bhambri", "Subbarao Kambhampati"], "title": "Local Coherence or Global Validity? Investigating RLVR Traces in Math Domains", "comment": "4 pages, 2 figures", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR)-based post-training of\nLarge Language Models (LLMs) has been shown to improve accuracy on reasoning\ntasks and continues to attract significant attention. Existing RLVR methods,\nhowever, typically treat all tokens uniformly without accounting for\ntoken-level advantages. These methods primarily evaluate performance based on\nfinal answer correctness or Pass@K accuracy, and yet make claims about RL\npost-training leading to improved reasoning traces. This motivates our\ninvestigation into the effect of RL post-training on intermediate tokens which\nare not directly incentivized. To study this, we design an experimental setup\nusing the GRPO algorithm with Qwen-2.5-0.5B model on the GSM8K dataset. We\nintroduce trace coherence, a First-Order Logic (FOL)-based measure to capture\nthe consistency of reasoning steps by identifying errors in the traces. We\ndistinguish between trace validity and trace coherence, noting that the former\nimplies logical soundness while the latter measures local coherence via lack of\nerrors. Our results show that RL post-training overall improves trace coherence\nwith the most significant gains on problems where the base model fails but the\nRL model succeeds. Surprisingly, RL enhances local coherence without\nnecessarily producing valid or correct solutions. This highlights a crucial\ndistinction: improved local coherence in reasoning steps does not guarantee\nfinal answer correctness. We argue that claims of improved reasoning via RL\nmust be examined with care, as these may be based on improved trace coherence,\nwhich may not translate into fully valid mathematical proofs.", "AI": {"tldr": "RLVR\u65b9\u6cd5\u5728LLM\u540e\u8bad\u7ec3\u4e2d\u901a\u5e38\u5747\u5300\u5904\u7406\u6240\u6709token\uff0c\u7f3a\u4e4f\u5bf9token\u7ea7\u4f18\u52bf\u7684\u8003\u91cf\u3002\u7814\u7a76\u53d1\u73b0RL\u540e\u8bad\u7ec3\u63d0\u9ad8\u4e86\u63a8\u7406\u8f68\u8ff9\u7684\u5c40\u90e8\u4e00\u81f4\u6027\uff0c\u4f46\u4e0d\u4e00\u5b9a\u4ea7\u751f\u6709\u6548\u6216\u6b63\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709RLVR\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\u8bc4\u4f30\u6027\u80fd\uff0c\u4f46\u58f0\u79f0RL\u540e\u8bad\u7ec3\u80fd\u6539\u5584\u63a8\u7406\u8f68\u8ff9\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76RL\u540e\u8bad\u7ec3\u5bf9\u672a\u76f4\u63a5\u6fc0\u52b1\u7684\u4e2d\u95f4token\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528GRPO\u7b97\u6cd5\u548cQwen-2.5-0.5B\u6a21\u578b\u5728GSM8K\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5f15\u5165\u57fa\u4e8e\u4e00\u9636\u903b\u8f91\u7684\u8f68\u8ff9\u4e00\u81f4\u6027\u5ea6\u91cf\u6765\u8bc4\u4f30\u63a8\u7406\u6b65\u9aa4\u7684\u4e00\u81f4\u6027\u3002", "result": "RL\u540e\u8bad\u7ec3\u603b\u4f53\u4e0a\u63d0\u9ad8\u4e86\u8f68\u8ff9\u4e00\u81f4\u6027\uff0c\u5728\u57fa\u7840\u6a21\u578b\u5931\u8d25\u4f46RL\u6a21\u578b\u6210\u529f\u7684\u95ee\u9898\u4e0a\u6539\u8fdb\u6700\u663e\u8457\u3002RL\u589e\u5f3a\u4e86\u5c40\u90e8\u4e00\u81f4\u6027\uff0c\u4f46\u4e0d\u4e00\u5b9a\u4ea7\u751f\u6709\u6548\u6216\u6b63\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u58f0\u79f0RL\u6539\u5584\u63a8\u7406\u7684\u4e3b\u5f20\u9700\u8981\u8c28\u614e\u5bf9\u5f85\uff0c\u56e0\u4e3a\u6539\u8fdb\u7684\u8f68\u8ff9\u4e00\u81f4\u6027\u53ef\u80fd\u4e0d\u4f1a\u8f6c\u5316\u4e3a\u5b8c\u5168\u6709\u6548\u7684\u6570\u5b66\u8bc1\u660e\uff0c\u5c40\u90e8\u4e00\u81f4\u6027\u7684\u63d0\u5347\u4e0d\u80fd\u4fdd\u8bc1\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\u3002"}}
{"id": "2510.18608", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18608", "abs": "https://arxiv.org/abs/2510.18608", "authors": ["Luigi Quarantiello", "Elia Piccoli", "Jack Bell", "Malio Li", "Giacomo Carf\u00ec", "Eric Nuertey Coleman", "Gerlando Gramaglia", "Lanpei Li", "Mauro Madeddu", "Irene Testa", "Vincenzo Lomonaco"], "title": "A Compositional Paradigm for Foundation Models: Towards Smarter Robotic Agents", "comment": null, "summary": "The birth of Foundation Models brought unprecedented results in a wide range\nof tasks, from language to vision, to robotic control. These models are able to\nprocess huge quantities of data, and can extract and develop rich\nrepresentations, which can be employed across different domains and modalities.\nHowever, they still have issues in adapting to dynamic, real-world scenarios\nwithout retraining the entire model from scratch. In this work, we propose the\napplication of Continual Learning and Compositionality principles to foster the\ndevelopment of more flexible, efficient and smart AI solutions.", "AI": {"tldr": "\u5e94\u7528\u6301\u7eed\u5b66\u4e60\u548c\u7ec4\u5408\u6027\u539f\u5219\u6765\u589e\u5f3a\u57fa\u7840\u6a21\u578b\u7684\u7075\u6d3b\u6027\u548c\u9002\u5e94\u6027", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u5904\u7406\u52a8\u6001\u73b0\u5b9e\u573a\u666f\u65f6\u5b58\u5728\u9002\u5e94\u6027\u95ee\u9898\uff0c\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u6574\u4e2a\u6a21\u578b", "method": "\u63d0\u51fa\u5c06\u6301\u7eed\u5b66\u4e60\u548c\u7ec4\u5408\u6027\u539f\u5219\u5e94\u7528\u4e8e\u57fa\u7840\u6a21\u578b", "result": "\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u8bf4\u660e\u5177\u4f53\u7ed3\u679c", "conclusion": "\u6301\u7eed\u5b66\u4e60\u548c\u7ec4\u5408\u6027\u539f\u5219\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u7075\u6d3b\u3001\u9ad8\u6548\u548c\u667a\u80fd\u7684AI\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.18193", "categories": ["cs.AI", "cs.CV", "cs.LG", "stat.ML", "68T01", "I.2.8"], "pdf": "https://arxiv.org/pdf/2510.18193", "abs": "https://arxiv.org/abs/2510.18193", "authors": ["Keivan Shariatmadar", "Ahmad Osman", "Ramin Ray", "Usman Dildar", "Kisam Kim"], "title": "FST.ai 2.0: An Explainable AI Ecosystem for Fair, Fast, and Inclusive Decision-Making in Olympic and Paralympic Taekwondo", "comment": "23 pages, 12 figures", "summary": "Fair, transparent, and explainable decision-making remains a critical\nchallenge in Olympic and Paralympic combat sports. This paper presents\n\\emph{FST.ai 2.0}, an explainable AI ecosystem designed to support referees,\ncoaches, and athletes in real time during Taekwondo competitions and training.\nThe system integrates {pose-based action recognition} using graph convolutional\nnetworks (GCNs), {epistemic uncertainty modeling} through credal sets, and\n{explainability overlays} for visual decision support. A set of {interactive\ndashboards} enables human--AI collaboration in referee evaluation, athlete\nperformance analysis, and Para-Taekwondo classification. Beyond automated\nscoring, FST.ai~2.0 incorporates modules for referee training, fairness\nmonitoring, and policy-level analytics within the World Taekwondo ecosystem.\nExperimental validation on competition data demonstrates an {85\\% reduction in\ndecision review time} and {93\\% referee trust} in AI-assisted decisions. The\nframework thus establishes a transparent and extensible pipeline for\ntrustworthy, data-driven officiating and athlete assessment. By bridging\nreal-time perception, explainable inference, and governance-aware design,\nFST.ai~2.0 represents a step toward equitable, accountable, and human-aligned\nAI in sports.", "AI": {"tldr": "FST.ai 2.0\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684AI\u751f\u6001\u7cfb\u7edf\uff0c\u7528\u4e8e\u652f\u6301\u8dc6\u62f3\u9053\u6bd4\u8d5b\u548c\u8bad\u7ec3\u4e2d\u7684\u5b9e\u65f6\u51b3\u7b56\uff0c\u901a\u8fc7\u59ff\u6001\u8bc6\u522b\u3001\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u548c\u53ef\u89c6\u5316\u89e3\u91ca\u6765\u63d0\u9ad8\u88c1\u5224\u51b3\u7b56\u7684\u516c\u5e73\u6027\u548c\u900f\u660e\u5ea6\u3002", "motivation": "\u89e3\u51b3\u5965\u6797\u5339\u514b\u548c\u6b8b\u5965\u4f1a\u683c\u6597\u8fd0\u52a8\u4e2d\u516c\u5e73\u3001\u900f\u660e\u548c\u53ef\u89e3\u91ca\u51b3\u7b56\u7684\u6311\u6218\uff0c\u63d0\u5347\u88c1\u5224\u3001\u6559\u7ec3\u548c\u8fd0\u52a8\u5458\u5728\u8dc6\u62f3\u9053\u6bd4\u8d5b\u548c\u8bad\u7ec3\u4e2d\u7684\u51b3\u7b56\u652f\u6301\u3002", "method": "\u96c6\u6210\u57fa\u4e8e\u59ff\u6001\u7684\u52a8\u4f5c\u8bc6\u522b\uff08\u4f7f\u7528\u56fe\u5377\u79ef\u7f51\u7edc\uff09\u3001\u901a\u8fc7\u7f6e\u4fe1\u96c6\u8fdb\u884c\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u3001\u53ef\u89c6\u5316\u89e3\u91ca\u53e0\u52a0\u5c42\uff0c\u4ee5\u53ca\u652f\u6301\u4eba\u673a\u534f\u4f5c\u7684\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\u3002", "result": "\u5728\u6bd4\u8d5b\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff0c\u51b3\u7b56\u5ba1\u67e5\u65f6\u95f4\u51cf\u5c11\u4e8685%\uff0c\u88c1\u5224\u5bf9AI\u8f85\u52a9\u51b3\u7b56\u7684\u4fe1\u4efb\u5ea6\u8fbe\u523093%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5efa\u7acb\u4e86\u4e00\u4e2a\u900f\u660e\u4e14\u53ef\u6269\u5c55\u7684\u7ba1\u9053\uff0c\u7528\u4e8e\u53ef\u4fe1\u8d56\u7684\u6570\u636e\u9a71\u52a8\u88c1\u5224\u548c\u8fd0\u52a8\u5458\u8bc4\u4f30\uff0c\u4ee3\u8868\u4e86\u5728\u4f53\u80b2\u4e2d\u5b9e\u73b0\u516c\u5e73\u3001\u8d1f\u8d23\u4efb\u548c\u4ee5\u4eba\u4e3a\u672c\u7684AI\u7684\u4e00\u6b65\u3002"}}
{"id": "2510.18643", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.18643", "abs": "https://arxiv.org/abs/2510.18643", "authors": ["Mattias Trende", "Petter \u00d6gren"], "title": "Least Restrictive Hyperplane Control Barrier Functions", "comment": null, "summary": "Control Barrier Functions (CBFs) can provide provable safety guarantees for\ndynamic systems. However, finding a valid CBF for a system of interest is often\nnon-trivial, especially if the shape of the unsafe region is complex and the\nCBFs are of higher order. A common solution to this problem is to make a\nconservative approximation of the unsafe region in the form of a\nline/hyperplane, and use the corresponding conservative Hyperplane-CBF when\ndeciding on safe control actions. In this letter, we note that conservative\nconstraints are only a problem if they prevent us from doing what we want.\nThus, instead of first choosing a CBF and then choosing a safe control with\nrespect to the CBF, we optimize over a combination of CBFs and safe controls to\nget as close as possible to our desired control, while still having the safety\nguarantee provided by the CBF. We call the corresponding CBF the least\nrestrictive Hyperplane-CBF. Finally, we also provide a way of creating a smooth\nparameterization of the CBF-family for the optimization, and illustrate the\napproach on a double integrator dynamical system with acceleration constraints,\nmoving through a group of arbitrarily shaped static and moving obstacles.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u63a7\u5236\u5c4f\u969c\u51fd\u6570(CBF)\u548c\u63a7\u5236\u5668\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u540c\u65f6\u4f18\u5316CBF\u548c\u63a7\u5236\u5668\u6765\u83b7\u5f97\u6700\u4e0d\u4fdd\u5b88\u7684\u5b89\u5168\u7ea6\u675f\uff0c\u800c\u4e0d\u662f\u5148\u9009\u62e9CBF\u518d\u9009\u62e9\u63a7\u5236\u5668\u3002", "motivation": "\u4f20\u7edfCBF\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u5f62\u72b6\u4e0d\u5b89\u5168\u533a\u57df\u65f6\u5f80\u5f80\u9700\u8981\u4fdd\u5b88\u8fd1\u4f3c\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u8fc7\u5ea6\u9650\u5236\u7684\u63a7\u5236\u52a8\u4f5c\u3002\u73b0\u6709\u65b9\u6cd5\u5148\u9009\u62e9CBF\u518d\u9009\u62e9\u63a7\u5236\u5668\uff0c\u800c\u672c\u6587\u8ba4\u4e3a\u4fdd\u5b88\u7ea6\u675f\u53ea\u6709\u5728\u963b\u6b62\u6211\u4eec\u505a\u60f3\u505a\u7684\u4e8b\u60c5\u65f6\u624d\u6210\u4e3a\u95ee\u9898\u3002", "method": "\u540c\u65f6\u4f18\u5316CBF\u548c\u63a7\u5236\u5668\uff0c\u627e\u5230\u6700\u4e0d\u9650\u5236\u7684\u8d85\u5e73\u9762CBF\uff0c\u5e76\u63d0\u4f9bCBF\u65cf\u7684\u5e73\u6ed1\u53c2\u6570\u5316\u65b9\u6cd5\u3002\u5728\u5177\u6709\u52a0\u901f\u5ea6\u7ea6\u675f\u7684\u53cc\u79ef\u5206\u5668\u52a8\u6001\u7cfb\u7edf\u4e2d\u9a8c\u8bc1\uff0c\u5904\u7406\u4efb\u610f\u5f62\u72b6\u7684\u9759\u6001\u548c\u52a8\u6001\u969c\u788d\u7269\u3002", "result": "\u5f00\u53d1\u4e86\u6700\u4e0d\u9650\u5236\u8d85\u5e73\u9762CBF\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\u6700\u5927\u5316\u63a7\u5236\u81ea\u7531\u5ea6\uff0c\u76f8\u6bd4\u4f20\u7edf\u4fdd\u5b88CBF\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u540c\u65f6\u4f18\u5316CBF\u548c\u63a7\u5236\u5668\uff0c\u53ef\u4ee5\u83b7\u5f97\u66f4\u63a5\u8fd1\u671f\u671b\u63a7\u5236\u7684\u5b89\u5168\u63a7\u5236\u7b56\u7565\uff0c\u540c\u65f6\u4fdd\u6301CBF\u63d0\u4f9b\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u4e3a\u89e3\u51b3\u590d\u6742\u5f62\u72b6\u4e0d\u5b89\u5168\u533a\u57df\u7684\u5b89\u5168\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2510.18212", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18212", "abs": "https://arxiv.org/abs/2510.18212", "authors": ["Dan Hendrycks", "Dawn Song", "Christian Szegedy", "Honglak Lee", "Yarin Gal", "Erik Brynjolfsson", "Sharon Li", "Andy Zou", "Lionel Levine", "Bo Han", "Jie Fu", "Ziwei Liu", "Jinwoo Shin", "Kimin Lee", "Mantas Mazeika", "Long Phan", "George Ingebretsen", "Adam Khoja", "Cihang Xie", "Olawale Salaudeen", "Matthias Hein", "Kevin Zhao", "Alexander Pan", "David Duvenaud", "Bo Li", "Steve Omohundro", "Gabriel Alfour", "Max Tegmark", "Kevin McGrew", "Gary Marcus", "Jaan Tallinn", "Eric Schmidt", "Yoshua Bengio"], "title": "A Definition of AGI", "comment": null, "summary": "The lack of a concrete definition for Artificial General Intelligence (AGI)\nobscures the gap between today's specialized AI and human-level cognition. This\npaper introduces a quantifiable framework to address this, defining AGI as\nmatching the cognitive versatility and proficiency of a well-educated adult. To\noperationalize this, we ground our methodology in Cattell-Horn-Carroll theory,\nthe most empirically validated model of human cognition. The framework dissects\ngeneral intelligence into ten core cognitive domains-including reasoning,\nmemory, and perception-and adapts established human psychometric batteries to\nevaluate AI systems. Application of this framework reveals a highly \"jagged\"\ncognitive profile in contemporary models. While proficient in\nknowledge-intensive domains, current AI systems have critical deficits in\nfoundational cognitive machinery, particularly long-term memory storage. The\nresulting AGI scores (e.g., GPT-4 at 27%, GPT-5 at 58%) concretely quantify\nboth rapid progress and the substantial gap remaining before AGI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u91cf\u5316\u7684AGI\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8eCattell-Horn-Carroll\u8ba4\u77e5\u7406\u8bba\u5c06\u901a\u7528\u667a\u80fd\u5206\u89e3\u4e3a10\u4e2a\u6838\u5fc3\u8ba4\u77e5\u9886\u57df\uff0c\u5e76\u5e94\u7528\u4eba\u7c7b\u5fc3\u7406\u6d4b\u91cf\u5de5\u5177\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u5bf9\u4eba\u5de5\u901a\u7528\u667a\u80fd(AGI)\u7684\u5177\u4f53\u5b9a\u4e49\uff0c\u96be\u4ee5\u8861\u91cf\u5f53\u524d\u4e13\u7528AI\u4e0e\u4eba\u7c7b\u6c34\u5e73\u8ba4\u77e5\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u53ef\u91cf\u5316\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u57fa\u4e8eCattell-Horn-Carroll\u8ba4\u77e5\u7406\u8bba\uff0c\u5c06\u901a\u7528\u667a\u80fd\u5206\u89e3\u4e3a10\u4e2a\u6838\u5fc3\u8ba4\u77e5\u9886\u57df\uff0c\u5e76\u91c7\u7528\u5df2\u5efa\u7acb\u7684\u4eba\u7c7b\u5fc3\u7406\u6d4b\u91cf\u5de5\u5177\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u7684\u8ba4\u77e5\u80fd\u529b\u3002", "result": "\u5e94\u7528\u8be5\u6846\u67b6\u53d1\u73b0\u5f53\u4ee3AI\u6a21\u578b\u5177\u6709\u9ad8\u5ea6\"\u952f\u9f7f\u72b6\"\u7684\u8ba4\u77e5\u7279\u5f81\uff0c\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u57fa\u7840\u8ba4\u77e5\u673a\u5236\uff08\u7279\u522b\u662f\u957f\u671f\u8bb0\u5fc6\u5b58\u50a8\uff09\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\u3002GPT-4\u5f97\u5206\u4e3a27%\uff0cGPT-5\u4e3a58%\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u5177\u4f53\u91cf\u5316AI\u7cfb\u7edf\u7684AGI\u6c34\u5e73\uff0c\u65e2\u663e\u793a\u4e86\u5feb\u901f\u8fdb\u5c55\uff0c\u4e5f\u63ed\u793a\u4e86\u5728\u5b9e\u73b0AGI\u4e4b\u524d\u4ecd\u5b58\u5728\u7684\u663e\u8457\u5dee\u8ddd\u3002"}}
{"id": "2510.18678", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.18678", "abs": "https://arxiv.org/abs/2510.18678", "authors": ["Alberto Sanchez-Delgado", "Jo\u00e3o Carlos Virgolino Soares", "David Omar Al Tawil", "Alessia Li Noce", "Matteo Villa", "Victor Barasuol", "Paolo Arena", "Claudio Semini"], "title": "Towards An Adaptive Locomotion Strategy For Quadruped Rovers: Quantifying When To Slide Or Walk On Planetary Slopes", "comment": "Published at the 18th Symposium on Advanced Space Technologies in\n  Robotics and Automation (ASTRA 2025)", "summary": "Legged rovers provide enhanced mobility compared to wheeled platforms,\nenabling navigation on steep and irregular planetary terrains. However,\ntraditional legged locomotion might be energetically inefficient and\npotentially dangerous to the rover on loose and inclined surfaces, such as\ncrater walls and cave slopes. This paper introduces a preliminary study that\ncompares the Cost of Transport (CoT) of walking and torso-based sliding\nlocomotion for quadruped robots across different slopes, friction conditions\nand speed levels. By identifying intersections between walking and sliding CoT\ncurves, we aim to define threshold conditions that may trigger transitions\nbetween the two strategies. The methodology combines physics-based simulations\nin Isaac Sim with particle interaction validation in ANSYS-Rocky. Our results\nrepresent an initial step towards adaptive locomotion strategies for planetary\nlegged rovers.", "AI": {"tldr": "\u6bd4\u8f83\u56db\u8db3\u673a\u5668\u4eba\u5728\u4e0d\u540c\u5761\u5ea6\u3001\u6469\u64e6\u6761\u4ef6\u548c\u901f\u5ea6\u4e0b\u7684\u884c\u8d70\u4e0e\u8eaf\u5e72\u6ed1\u52a8\u4e24\u79cd\u8fd0\u52a8\u65b9\u5f0f\u7684\u8fd0\u8f93\u6210\u672c\uff0c\u65e8\u5728\u786e\u5b9a\u4e24\u79cd\u7b56\u7565\u5207\u6362\u7684\u9608\u503c\u6761\u4ef6\u3002", "motivation": "\u4f20\u7edf\u817f\u5f0f\u8fd0\u52a8\u5728\u677e\u6563\u503e\u659c\u8868\u9762\uff08\u5982\u9668\u77f3\u5751\u58c1\u548c\u6d1e\u7a74\u659c\u5761\uff09\u4e0a\u53ef\u80fd\u6548\u7387\u4f4e\u4e0b\u4e14\u5371\u9669\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u8fd0\u52a8\u7b56\u7565\u3002", "method": "\u7ed3\u5408Isaac Sim\u4e2d\u7684\u7269\u7406\u4eff\u771f\u548cANSYS-Rocky\u4e2d\u7684\u7c92\u5b50\u4ea4\u4e92\u9a8c\u8bc1\uff0c\u5206\u6790\u884c\u8d70\u4e0e\u6ed1\u52a8\u4e24\u79cd\u8fd0\u52a8\u65b9\u5f0f\u7684\u8fd0\u8f93\u6210\u672c\u3002", "result": "\u901a\u8fc7\u8bc6\u522b\u884c\u8d70\u548c\u6ed1\u52a8\u8fd0\u8f93\u6210\u672c\u66f2\u7ebf\u7684\u4ea4\u70b9\uff0c\u5b9a\u4e49\u4e86\u89e6\u53d1\u4e24\u79cd\u7b56\u7565\u8f6c\u6362\u7684\u9608\u503c\u6761\u4ef6\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u884c\u661f\u817f\u5f0f\u6f2b\u6e38\u8f66\u7684\u81ea\u9002\u5e94\u8fd0\u52a8\u7b56\u7565\u5f00\u53d1\u8fc8\u51fa\u4e86\u521d\u6b65\u6b65\u9aa4\u3002"}}
{"id": "2510.18250", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18250", "abs": "https://arxiv.org/abs/2510.18250", "authors": ["Xiaohan Qin", "Xiaoxing Wang", "Ning Liao", "Cancheng Zhang", "Xiangdong Zhang", "Mingquan Feng", "Jingzhi Wang", "Junchi Yan"], "title": "ssToken: Self-modulated and Semantic-aware Token Selection for LLM Fine-tuning", "comment": null, "summary": "Data quality plays a critical role in enhancing supervised fine-tuning (SFT)\nfor large language models (LLMs), and token-level data selection has emerged as\na promising direction for its fine-grained nature. Despite their strong\nempirical performance, existing token-level selection methods share two key\nlimitations: (1) requiring training or accessing an additional reference model,\nand (2) relying solely on loss information for token selection, which cannot\nwell preserve semantically important tokens that are not favored by loss-based\nmetrics. To address these challenges, we propose ssToken, a Self-modulated and\nSemantic-aware Token Selection approach. ssToken leverages readily accessible\nhistory models to compute the per-token loss difference with the current model,\nwhich serves as a self-modulated signal that enables the model to adaptively\nselect tokens along its optimization trajectory, rather than relying on excess\nloss from an offline-trained reference model as in prior works. We further\nintroduce a semantic-aware, attention-based token importance estimation metric,\northogonal to loss-based selection and providing complementary semantic\ninformation for more effective filtering. Extensive experiments across\ndifferent model families and scales demonstrate that both self-modulated\nselection and semantic-aware selection alone outperform full-data fine-tuning,\nwhile their integration--ssToken--achieves synergistic gains and further\nsurpasses prior token-level selection methods, delivering performance\nimprovements while maintaining training efficiency.", "AI": {"tldr": "\u63d0\u51fassToken\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u8c03\u5236\u635f\u5931\u5dee\u5f02\u548c\u8bed\u4e49\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884ctoken\u7ea7\u6570\u636e\u9009\u62e9\uff0c\u65e0\u9700\u989d\u5916\u53c2\u8003\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u8bad\u7ec3\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347SFT\u6027\u80fd", "motivation": "\u73b0\u6709token\u7ea7\u9009\u62e9\u65b9\u6cd5\u9700\u8981\u989d\u5916\u53c2\u8003\u6a21\u578b\u4e14\u4ec5\u4f9d\u8d56\u635f\u5931\u4fe1\u606f\uff0c\u65e0\u6cd5\u5f88\u597d\u4fdd\u7559\u8bed\u4e49\u91cd\u8981\u4f46\u635f\u5931\u4e0d\u663e\u8457\u7684token", "method": "\u4f7f\u7528\u5386\u53f2\u6a21\u578b\u8ba1\u7b97token\u635f\u5931\u5dee\u5f02\u4f5c\u4e3a\u81ea\u8c03\u5236\u4fe1\u53f7\uff0c\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u4f30\u8ba1\u8bed\u4e49\u91cd\u8981\u6027\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94token\u9009\u62e9", "result": "\u5b9e\u9a8c\u663e\u793a\u81ea\u8c03\u5236\u9009\u62e9\u548c\u8bed\u4e49\u611f\u77e5\u9009\u62e9\u5355\u72ec\u4f7f\u7528\u5747\u4f18\u4e8e\u5168\u6570\u636e\u5fae\u8c03\uff0c\u4e24\u8005\u7ed3\u5408\u8fdb\u4e00\u6b65\u8d85\u8d8a\u73b0\u6709token\u7ea7\u9009\u62e9\u65b9\u6cd5", "conclusion": "ssToken\u901a\u8fc7\u81ea\u8c03\u5236\u548c\u8bed\u4e49\u611f\u77e5\u7684token\u9009\u62e9\u5b9e\u73b0\u4e86\u534f\u540c\u589e\u76ca\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\u548c\u89c4\u6a21\u4e0a\u5747\u53d6\u5f97\u6027\u80fd\u63d0\u5347"}}
{"id": "2510.18697", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.18697", "abs": "https://arxiv.org/abs/2510.18697", "authors": ["Phuoc Nguyen", "Francesco Verdoja", "Ville Kyrki"], "title": "Event-Grounding Graph: Unified Spatio-Temporal Scene Graph from Robotic Observations", "comment": "Submitted to RA-L", "summary": "A fundamental aspect for building intelligent autonomous robots that can\nassist humans in their daily lives is the construction of rich environmental\nrepresentations. While advances in semantic scene representations have enriched\nrobotic scene understanding, current approaches lack a connection between\nspatial features and dynamic events; e.g., connecting the blue mug to the event\nwashing a mug. In this work, we introduce the event-grounding graph (EGG), a\nframework grounding event interactions to spatial features of a scene. This\nrepresentation allows robots to perceive, reason, and respond to complex\nspatio-temporal queries. Experiments using real robotic data demonstrate EGG's\ncapability to retrieve relevant information and respond accurately to human\ninquiries concerning the environment and events within. Furthermore, the EGG\nframework's source code and evaluation dataset are released as open-source at:\nhttps://github.com/aalto-intelligent-robotics/EGG.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e8b\u4ef6\u57fa\u7840\u56fe\uff08EGG\uff09\u6846\u67b6\uff0c\u5c06\u4e8b\u4ef6\u4ea4\u4e92\u4e0e\u573a\u666f\u7a7a\u95f4\u7279\u5f81\u5173\u8054\u8d77\u6765\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u611f\u77e5\u3001\u63a8\u7406\u548c\u54cd\u5e94\u590d\u6742\u7684\u65f6\u7a7a\u67e5\u8be2", "motivation": "\u5f53\u524d\u8bed\u4e49\u573a\u666f\u8868\u793a\u65b9\u6cd5\u7f3a\u4e4f\u7a7a\u95f4\u7279\u5f81\u4e0e\u52a8\u6001\u4e8b\u4ef6\u4e4b\u95f4\u7684\u8fde\u63a5\uff0c\u9650\u5236\u4e86\u673a\u5668\u4eba\u5bf9\u73af\u5883\u7406\u89e3\u7684\u5b8c\u6574\u6027", "method": "\u5f00\u53d1\u4e86\u4e8b\u4ef6\u57fa\u7840\u56fe\uff08EGG\uff09\u6846\u67b6\uff0c\u5c06\u4e8b\u4ef6\u4ea4\u4e92\u4e0e\u573a\u666f\u7a7a\u95f4\u7279\u5f81\u8fdb\u884c\u5173\u8054", "result": "\u4f7f\u7528\u771f\u5b9e\u673a\u5668\u4eba\u6570\u636e\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEGG\u80fd\u591f\u68c0\u7d22\u76f8\u5173\u4fe1\u606f\u5e76\u51c6\u786e\u54cd\u5e94\u5173\u4e8e\u73af\u5883\u548c\u4e8b\u4ef6\u7684\u4eba\u7c7b\u67e5\u8be2", "conclusion": "EGG\u6846\u67b6\u6709\u6548\u8fde\u63a5\u4e86\u7a7a\u95f4\u7279\u5f81\u548c\u52a8\u6001\u4e8b\u4ef6\uff0c\u63d0\u5347\u4e86\u673a\u5668\u4eba\u7684\u573a\u666f\u7406\u89e3\u548c\u54cd\u5e94\u80fd\u529b\uff0c\u76f8\u5173\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90"}}
{"id": "2510.18254", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18254", "abs": "https://arxiv.org/abs/2510.18254", "authors": ["Sion Weatherhead", "Flora Salim", "Aaron Belbasis"], "title": "Illusions of reflection: open-ended task reveals systematic failures in Large Language Models' reflective reasoning", "comment": null, "summary": "Humans do not just find mistakes after the fact -- we often catch them\nmid-stream because 'reflection' is tied to the goal and its constraints.\nToday's large language models produce reasoning tokens and 'reflective' text,\nbut is it functionally equivalent with human reflective reasoning? Prior work\non closed-ended tasks -- with clear, external 'correctness' signals -- can make\n'reflection' look effective while masking limits in self-correction. We\ntherefore test eight frontier models on a simple, real-world task that is\nopen-ended yet rule-constrained, with auditable success criteria: to produce\nvalid scientific test items, then revise after considering their own critique.\nFirst-pass performance is poor (often zero valid items out of 4 required; mean\n$\\approx$ 1), and reflection yields only modest gains (also $\\approx$ 1).\nCrucially, the second attempt frequently repeats the same violation of\nconstraint, indicating 'corrective gains' arise largely from chance production\nof a valid item rather than error detection and principled,\nconstraint-sensitive repair. Performance before and after reflection\ndeteriorates as open-endedness increases, and models marketed for 'reasoning'\nshow no advantage. Our results suggest that current LLM 'reflection' lacks\nfunctional evidence of the active, goal-driven monitoring that helps humans\nrespect constraints even on a first pass. Until such mechanisms are\ninstantiated in the model itself, reliable performance requires external\nstructure that enforces constraints.", "AI": {"tldr": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684'\u53cd\u601d'\u529f\u80fd\u5728\u5f00\u653e\u4f46\u53d7\u89c4\u5219\u7ea6\u675f\u7684\u4efb\u52a1\u4e2d\u6548\u679c\u6709\u9650\uff0c\u65e0\u6cd5\u50cf\u4eba\u7c7b\u90a3\u6837\u8fdb\u884c\u76ee\u6807\u9a71\u52a8\u7684\u4e3b\u52a8\u76d1\u63a7\u548c\u7ea6\u675f\u654f\u611f\u7684\u9519\u8bef\u4fee\u590d\u3002", "motivation": "\u7814\u7a76\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684'\u53cd\u601d'\u80fd\u529b\u662f\u5426\u4e0e\u4eba\u7c7b\u53cd\u601d\u63a8\u7406\u529f\u80fd\u7b49\u4ef7\uff0c\u7279\u522b\u662f\u5728\u5f00\u653e\u4f46\u53d7\u89c4\u5219\u7ea6\u675f\u7684\u4efb\u52a1\u4e2d\u3002", "method": "\u5728\u516b\u4e2a\u524d\u6cbf\u6a21\u578b\u4e0a\u6d4b\u8bd5\u4e00\u4e2a\u7b80\u5355\u7684\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\uff1a\u751f\u6210\u6709\u6548\u7684\u79d1\u5b66\u6d4b\u8bd5\u9879\u76ee\uff0c\u7136\u540e\u5728\u81ea\u6211\u6279\u8bc4\u540e\u8fdb\u884c\u4fee\u8ba2\u3002", "result": "\u9996\u6b21\u5c1d\u8bd5\u8868\u73b0\u5dee\uff08\u5e73\u5747\u7ea61\u4e2a\u6709\u6548\u9879\u76ee\uff09\uff0c\u53cd\u601d\u540e\u53ea\u6709\u9002\u5ea6\u63d0\u5347\uff08\u4e5f\u7ea61\u4e2a\uff09\u3002\u7b2c\u4e8c\u6b21\u5c1d\u8bd5\u7ecf\u5e38\u91cd\u590d\u76f8\u540c\u7684\u7ea6\u675f\u8fdd\u53cd\uff0c\u8868\u660e'\u7ea0\u6b63\u6536\u76ca'\u4e3b\u8981\u6765\u81ea\u5076\u7136\u4ea7\u751f\u6709\u6548\u9879\u76ee\u800c\u975e\u9519\u8bef\u68c0\u6d4b\u548c\u539f\u5219\u6027\u4fee\u590d\u3002", "conclusion": "\u5f53\u524dLLM\u7684'\u53cd\u601d'\u7f3a\u4e4f\u4eba\u7c7b\u90a3\u79cd\u4e3b\u52a8\u3001\u76ee\u6807\u9a71\u52a8\u7684\u76d1\u63a7\u673a\u5236\uff0c\u53ef\u9760\u6027\u80fd\u9700\u8981\u5916\u90e8\u7ed3\u6784\u6765\u5f3a\u5236\u6267\u884c\u7ea6\u675f\u3002"}}
{"id": "2510.18766", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.18766", "abs": "https://arxiv.org/abs/2510.18766", "authors": ["Alexander Krawciw", "Sven Lilge", "Luka Antonyshyn", "Timothy D. Barfoot"], "title": "Sharing the Load: Distributed Model-Predictive Control for Precise Multi-Rover Cargo Transport", "comment": "8 pages, 4 figures", "summary": "For autonomous cargo transportation, teams of mobile robots can provide more\noperational flexibility than a single large robot. In these scenarios,\nprecision in both inter-vehicle distance and path tracking is key. With this\nmotivation, we develop a distributed model-predictive controller (MPC) for\nmulti-vehicle cargo operations that builds on the precise path-tracking of\nlidar teach and repeat. To carry cargo, a following vehicle must maintain a\nEuclidean distance offset from a lead vehicle regardless of the path curvature.\nOur approach uses a shared map to localize the robots relative to each other\nwithout GNSS or direct observations. We compare our approach to a centralized\nMPC and a baseline approach that directly measures the inter-vehicle distance.\nThe distributed MPC shows equivalent nominal performance to the more complex\ncentralized MPC. Using a direct measurement of the relative distance between\nthe leader and follower shows improved tracking performance in close-range\nscenarios but struggles with long-range offsets. The operational flexibility\nprovided by distributing the computation makes it well suited for real\ndeployments. We evaluate four types of convoyed path trackers with over 10 km\nof driving in a coupled convoy. With convoys of two and three rovers, the\nproposed distributed MPC method works in real-time to allow map-based convoying\nto maintain maximum spacing within 20 cm of the target in various conditions.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7528\u4e8e\u591a\u8f66\u8f86\u8d27\u7269\u8fd0\u8f93\u7684\u5206\u5e03\u5f0f\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u5171\u4eab\u5730\u56fe\u5b9e\u73b0\u8f66\u8f86\u95f4\u76f8\u5bf9\u5b9a\u4f4d\uff0c\u65e0\u9700GNSS\u6216\u76f4\u63a5\u89c2\u6d4b\uff0c\u572810\u516c\u91cc\u4ee5\u4e0a\u9a7e\u9a76\u6d4b\u8bd5\u4e2d\u4fdd\u6301\u95f4\u8ddd\u8bef\u5dee\u572820\u5398\u7c73\u5185\u3002", "motivation": "\u81ea\u4e3b\u8d27\u7269\u8fd0\u8f93\u4e2d\uff0c\u591a\u673a\u5668\u4eba\u56e2\u961f\u6bd4\u5355\u4e2a\u5927\u578b\u673a\u5668\u4eba\u66f4\u5177\u64cd\u4f5c\u7075\u6d3b\u6027\uff0c\u4f46\u9700\u8981\u7cbe\u786e\u7684\u8f66\u8f86\u95f4\u8ddd\u548c\u8def\u5f84\u8ddf\u8e2a\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u6fc0\u5149\u96f7\u8fbe\u6559\u5b66\u91cd\u590d\u7684\u7cbe\u786e\u8def\u5f84\u8ddf\u8e2a\uff0c\u5f00\u53d1\u5206\u5e03\u5f0fMPC\u63a7\u5236\u5668\uff0c\u4f7f\u7528\u5171\u4eab\u5730\u56fe\u8fdb\u884c\u673a\u5668\u4eba\u76f8\u5bf9\u5b9a\u4f4d\uff0c\u65e0\u9700GNSS\u6216\u76f4\u63a5\u89c2\u6d4b\u3002", "result": "\u5206\u5e03\u5f0fMPC\u4e0e\u96c6\u4e2d\u5f0fMPC\u6027\u80fd\u76f8\u5f53\uff0c\u57282-3\u8f86\u8f66\u7684\u8f66\u961f\u4e2d\u5b9e\u65f6\u8fd0\u884c\uff0c\u5728\u5404\u79cd\u6761\u4ef6\u4e0b\u80fd\u5c06\u6700\u5927\u95f4\u8ddd\u4fdd\u6301\u5728\u76ee\u6807\u503c\u768420\u5398\u7c73\u5185\u3002", "conclusion": "\u5206\u5e03\u5f0f\u8ba1\u7b97\u63d0\u4f9b\u7684\u64cd\u4f5c\u7075\u6d3b\u6027\u4f7f\u5176\u975e\u5e38\u9002\u5408\u5b9e\u9645\u90e8\u7f72\uff0c\u5206\u5e03\u5f0fMPC\u65b9\u6cd5\u5728\u5b9e\u65f6\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2510.18845", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.18845", "abs": "https://arxiv.org/abs/2510.18845", "authors": ["Ryan Teoh", "Sander Tonkens", "William Sharpless", "Aijia Yang", "Zeyuan Feng", "Somil Bansal", "Sylvia Herbert"], "title": "MADR: MPC-guided Adversarial DeepReach", "comment": "8 pages, under review", "summary": "Hamilton-Jacobi (HJ) Reachability offers a framework for generating safe\nvalue functions and policies in the face of adversarial disturbance, but is\nlimited by the curse of dimensionality. Physics-informed deep learning is able\nto overcome this infeasibility, but itself suffers from slow and inaccurate\nconvergence, primarily due to weak PDE gradients and the complexity of\nself-supervised learning. A few works, recently, have demonstrated that\nenriching the self-supervision process with regular supervision (based on the\nnature of the optimal control problem), greatly accelerates convergence and\nsolution quality, however, these have been limited to single player problems\nand simple games. In this work, we introduce MADR: MPC-guided Adversarial\nDeepReach, a general framework to robustly approximate the two-player, zero-sum\ndifferential game value function. In doing so, MADR yields the corresponding\noptimal strategies for both players in zero-sum games as well as safe policies\nfor worst-case robustness. We test MADR on a multitude of high-dimensional\nsimulated and real robotic agents with varying dynamics and games, finding that\nour approach significantly out-performs state-of-the-art baselines in\nsimulation and produces impressive results in hardware.", "AI": {"tldr": "\u63d0\u51fa\u4e86MADR\u6846\u67b6\uff0c\u7ed3\u5408MPC\u5f15\u5bfc\u548c\u5bf9\u6297\u6027\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u8fd1\u4f3c\u4e24\u4eba\u96f6\u548c\u5fae\u5206\u535a\u5f08\u7684\u503c\u51fd\u6570\uff0c\u89e3\u51b3\u4e86\u9ad8\u7ef4Hamilton-Jacobi\u53ef\u8fbe\u6027\u5206\u6790\u7684\u8ba1\u7b97\u96be\u9898\u3002", "motivation": "\u4f20\u7edfHamilton-Jacobi\u53ef\u8fbe\u6027\u5206\u6790\u9762\u4e34\u7ef4\u5ea6\u707e\u96be\uff0c\u800c\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6536\u655b\u7f13\u6162\u4e14\u4e0d\u51c6\u786e\u3002\u73b0\u6709\u65b9\u6cd5\u4ec5\u9650\u4e8e\u5355\u73a9\u5bb6\u95ee\u9898\u548c\u7b80\u5355\u535a\u5f08\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5904\u7406\u4e24\u4eba\u96f6\u548c\u5fae\u5206\u535a\u5f08\u7684\u901a\u7528\u6846\u67b6\u3002", "method": "MADR\u6846\u67b6\u7ed3\u5408\u6a21\u578b\u9884\u6d4b\u63a7\u5236(MPC)\u5f15\u5bfc\u548c\u5bf9\u6297\u6027\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e30\u5bcc\u81ea\u76d1\u7763\u8fc7\u7a0b\u7684\u6b63\u5219\u76d1\u7763\u6765\u8fd1\u4f3c\u4e24\u4eba\u96f6\u548c\u5fae\u5206\u535a\u5f08\u7684\u503c\u51fd\u6570\uff0c\u751f\u6210\u53cc\u65b9\u6700\u4f18\u7b56\u7565\u548c\u6700\u574f\u60c5\u51b5\u9c81\u68d2\u5b89\u5168\u7b56\u7565\u3002", "result": "\u5728\u591a\u79cd\u9ad8\u7ef4\u6a21\u62df\u548c\u771f\u5b9e\u673a\u5668\u4eba\u4ee3\u7406\u4e0a\u6d4b\u8bd5\uff0cMADR\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4eff\u771f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u786c\u4ef6\u5b9e\u9a8c\u4e2d\u4ea7\u751f\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u7ed3\u679c\u3002", "conclusion": "MADR\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u6846\u67b6\uff0c\u80fd\u591f\u9c81\u68d2\u5730\u8fd1\u4f3c\u4e24\u4eba\u96f6\u548c\u5fae\u5206\u535a\u5f08\u7684\u503c\u51fd\u6570\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u7ef4\u53ef\u8fbe\u6027\u5206\u6790\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u5728\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u548c\u535a\u5f08\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.18314", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18314", "abs": "https://arxiv.org/abs/2510.18314", "authors": ["Zheng Zhang", "Jiarui He", "Yuchen Cai", "Deheng Ye", "Peilin Zhao", "Ruili Feng", "Hao Wang"], "title": "Genesis: Evolving Attack Strategies for LLM Web Agent Red-Teaming", "comment": null, "summary": "As large language model (LLM) agents increasingly automate complex web tasks,\nthey boost productivity while simultaneously introducing new security risks.\nHowever, relevant studies on web agent attacks remain limited. Existing\nred-teaming approaches mainly rely on manually crafted attack strategies or\nstatic models trained offline. Such methods fail to capture the underlying\nbehavioral patterns of web agents, making it difficult to generalize across\ndiverse environments. In web agent attacks, success requires the continuous\ndiscovery and evolution of attack strategies. To this end, we propose Genesis,\na novel agentic framework composed of three modules: Attacker, Scorer, and\nStrategist. The Attacker generates adversarial injections by integrating the\ngenetic algorithm with a hybrid strategy representation. The Scorer evaluates\nthe target web agent's responses to provide feedback. The Strategist\ndynamically uncovers effective strategies from interaction logs and compiles\nthem into a continuously growing strategy library, which is then re-deployed to\nenhance the Attacker's effectiveness. Extensive experiments across various web\ntasks show that our framework discovers novel strategies and consistently\noutperforms existing attack baselines.", "AI": {"tldr": "Genesis\u662f\u4e00\u4e2a\u9488\u5bf9\u7f51\u7edc\u4ee3\u7406\u653b\u51fb\u7684\u65b0\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u548c\u6df7\u5408\u7b56\u7565\u8868\u793a\u751f\u6210\u5bf9\u6297\u6027\u6ce8\u5165\uff0c\u52a8\u6001\u53d1\u73b0\u6709\u6548\u653b\u51fb\u7b56\u7565\u5e76\u6301\u7eed\u4f18\u5316\u653b\u51fb\u6548\u679c\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u590d\u6742\u7f51\u7edc\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u867d\u7136\u63d0\u9ad8\u4e86\u751f\u4ea7\u529b\u4f46\u4e5f\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\u3002\u73b0\u6709\u7ea2\u961f\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u624b\u52a8\u6784\u5efa\u7684\u653b\u51fb\u7b56\u7565\u6216\u79bb\u7ebf\u8bad\u7ec3\u7684\u9759\u6001\u6a21\u578b\uff0c\u96be\u4ee5\u6355\u6349\u7f51\u7edc\u4ee3\u7406\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u65e0\u6cd5\u9002\u5e94\u591a\u6837\u5316\u73af\u5883\u3002", "method": "\u63d0\u51faGenesis\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff1a\u653b\u51fb\u8005\uff08\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u548c\u6df7\u5408\u7b56\u7565\u8868\u793a\u751f\u6210\u5bf9\u6297\u6027\u6ce8\u5165\uff09\u3001\u8bc4\u5206\u5668\uff08\u8bc4\u4f30\u76ee\u6807\u7f51\u7edc\u4ee3\u7406\u7684\u54cd\u5e94\uff09\u3001\u7b56\u7565\u5e08\uff08\u4ece\u4ea4\u4e92\u65e5\u5fd7\u4e2d\u52a8\u6001\u53d1\u73b0\u6709\u6548\u7b56\u7565\u5e76\u6784\u5efa\u6301\u7eed\u589e\u957f\u7684\u6218\u7565\u5e93\uff09\u3002", "result": "\u5728\u5404\u79cd\u7f51\u7edc\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u53d1\u73b0\u65b0\u9896\u7b56\u7565\uff0c\u5e76\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u7684\u653b\u51fb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Genesis\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u7b56\u7565\u53d1\u73b0\u548c\u6301\u7eed\u4f18\u5316\u7684\u65b9\u5f0f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7f51\u7edc\u4ee3\u7406\u653b\u51fb\u4e2d\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u4e3a\u7f51\u7edc\u4ee3\u7406\u5b89\u5168\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2510.18776", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.18776", "abs": "https://arxiv.org/abs/2510.18776", "authors": ["Emad Razavi", "Angelo Bratta", "Jo\u00e3o Carlos Virgolino Soares", "Carmine Recchiuto", "Claudio Semini"], "title": "Online Object-Level Semantic Mapping for Quadrupeds in Real-World Environments", "comment": "Published at the Italian Conference on Robotics and Intelligent\n  Machines (I-RIM) 3D, 2025", "summary": "We present an online semantic object mapping system for a quadruped robot\noperating in real indoor environments, turning sensor detections into named\nobjects in a global map. During a run, the mapper integrates range geometry\nwith camera detections, merges co-located detections within a frame, and\nassociates repeated detections into persistent object instances across frames.\nObjects remain in the map when they are out of view, and repeated sightings\nupdate the same instance rather than creating duplicates. The output is a\ncompact object layer that can be queried (class, pose, and confidence), is\nintegrated with the occupancy map and readable by a planner. In on-robot tests,\nthe layer remained stable across viewpoint changes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u56db\u8db3\u673a\u5668\u4eba\u7684\u5728\u7ebf\u8bed\u4e49\u5bf9\u8c61\u6620\u5c04\u7cfb\u7edf\uff0c\u5c06\u4f20\u611f\u5668\u68c0\u6d4b\u8f6c\u6362\u4e3a\u5168\u5c40\u5730\u56fe\u4e2d\u7684\u547d\u540d\u5bf9\u8c61\uff0c\u5b9e\u73b0\u8de8\u5e27\u7684\u6301\u4e45\u5bf9\u8c61\u5b9e\u4f8b\u5173\u8054\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u5728\u771f\u5b9e\u5ba4\u5185\u73af\u5883\u4e2d\u8fd0\u884c\u65f6\uff0c\u9700\u8981\u5c06\u4f20\u611f\u5668\u68c0\u6d4b\u7ed3\u679c\u6574\u5408\u4e3a\u53ef\u67e5\u8be2\u7684\u8bed\u4e49\u5bf9\u8c61\u5730\u56fe\uff0c\u652f\u6301\u89c4\u5212\u5668\u4f7f\u7528\u3002", "method": "\u96c6\u6210\u8ddd\u79bb\u51e0\u4f55\u4e0e\u76f8\u673a\u68c0\u6d4b\uff0c\u5728\u5e27\u5185\u5408\u5e76\u5171\u4f4d\u68c0\u6d4b\uff0c\u8de8\u5e27\u5173\u8054\u91cd\u590d\u68c0\u6d4b\u5f62\u6210\u6301\u4e45\u5bf9\u8c61\u5b9e\u4f8b\uff0c\u5bf9\u8c61\u5728\u89c6\u91ce\u5916\u4ecd\u4fdd\u7559\u5728\u56fe\u4e2d\u3002", "result": "\u7cfb\u7edf\u8f93\u51fa\u7d27\u51d1\u7684\u5bf9\u8c61\u5c42\uff08\u5305\u542b\u7c7b\u522b\u3001\u4f4d\u59ff\u548c\u7f6e\u4fe1\u5ea6\uff09\uff0c\u4e0e\u5360\u7528\u5730\u56fe\u96c6\u6210\uff0c\u5728\u673a\u5668\u4eba\u6d4b\u8bd5\u4e2d\u89c6\u89d2\u53d8\u5316\u65f6\u4fdd\u6301\u7a33\u5b9a\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u80fd\u591f\u7a33\u5b9a\u8fd0\u884c\u7684\u56db\u8db3\u673a\u5668\u4eba\u8bed\u4e49\u5bf9\u8c61\u6620\u5c04\u7cfb\u7edf\uff0c\u4e3a\u673a\u5668\u4eba\u89c4\u5212\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u73af\u5883\u8bed\u4e49\u4fe1\u606f\u3002"}}
{"id": "2510.18318", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18318", "abs": "https://arxiv.org/abs/2510.18318", "authors": ["Aaron Bell", "Amit Aides", "Amr Helmy", "Arbaaz Muslim", "Aviad Barzilai", "Aviv Slobodkin", "Bolous Jaber", "David Schottlander", "George Leifman", "Joydeep Paul", "Mimi Sun", "Nadav Sherman", "Natalie Williams", "Per Bjornsson", "Roy Lee", "Ruth Alcantara", "Thomas Turnbull", "Tomer Shekel", "Vered Silverman", "Yotam Gigi", "Adam Boulanger", "Alex Ottenwess", "Ali Ahmadalipour", "Anna Carter", "Charles Elliott", "David Andre", "Elad Aharoni", "Gia Jung", "Hassler Thurston", "Jacob Bien", "Jamie McPike", "Juliet Rothenberg", "Kartik Hegde", "Kel Markert", "Kim Philipp Jablonski", "Luc Houriez", "Monica Bharel", "Phing VanLee", "Reuven Sayag", "Sebastian Pilarski", "Shelley Cazares", "Shlomi Pasternak", "Siduo Jiang", "Stone Jiang", "Thomas Colthurst", "Yang Chen", "Yehonathan Refael", "Yochai Blau", "Yuval Carny", "Yael Maguire", "Avinatan Hassidim", "James Manyika", "Tim Thelin", "Genady Beryozkin", "Gautam Prasad", "Luke Barrington", "Yossi Matias", "Niv Efron", "Shravya Shetty"], "title": "Earth AI: Unlocking Geospatial Insights with Foundation Models and Cross-Modal Reasoning", "comment": null, "summary": "Geospatial data offers immense potential for understanding our planet.\nHowever, the sheer volume and diversity of this data along with its varied\nresolutions, timescales, and sparsity pose significant challenges for thorough\nanalysis and interpretation. This paper introduces Earth AI, a family of\ngeospatial AI models and agentic reasoning that enables significant advances in\nour ability to unlock novel and profound insights into our planet. This\napproach is built upon foundation models across three key domains--Planet-scale\nImagery, Population, and Environment--and an intelligent Gemini-powered\nreasoning engine. We present rigorous benchmarks showcasing the power and novel\ncapabilities of our foundation models and validate that when used together,\nthey provide complementary value for geospatial inference and their synergies\nunlock superior predictive capabilities. To handle complex, multi-step queries,\nwe developed a Gemini-powered agent that jointly reasons over our multiple\nfoundation models along with large geospatial data sources and tools. On a new\nbenchmark of real-world crisis scenarios, our agent demonstrates the ability to\ndeliver critical and timely insights, effectively bridging the gap between raw\ngeospatial data and actionable understanding.", "AI": {"tldr": "Earth AI\u662f\u4e00\u4e2a\u5730\u7406\u7a7a\u95f4AI\u6a21\u578b\u5bb6\u65cf\uff0c\u901a\u8fc7\u591a\u9886\u57df\u57fa\u7840\u6a21\u578b\u548cGemini\u9a71\u52a8\u7684\u63a8\u7406\u5f15\u64ce\uff0c\u89e3\u51b3\u5730\u7406\u7a7a\u95f4\u6570\u636e\u5206\u6790\u7684\u6311\u6218\u3002", "motivation": "\u5730\u7406\u7a7a\u95f4\u6570\u636e\u91cf\u5927\u3001\u591a\u6837\u4e14\u5206\u8fa8\u7387\u3001\u65f6\u95f4\u5c3a\u5ea6\u548c\u7a00\u758f\u6027\u5404\u5f02\uff0c\u7ed9\u6df1\u5165\u5206\u6790\u548c\u89e3\u91ca\u5e26\u6765\u91cd\u5927\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u4e09\u4e2a\u5173\u952e\u9886\u57df\uff08\u5168\u7403\u5c3a\u5ea6\u5f71\u50cf\u3001\u4eba\u53e3\u3001\u73af\u5883\uff09\u7684\u57fa\u7840\u6a21\u578b\uff0c\u7ed3\u5408Gemini\u9a71\u52a8\u7684\u667a\u80fd\u63a8\u7406\u5f15\u64ce\u548c\u591a\u6a21\u578b\u8054\u5408\u63a8\u7406\u4ee3\u7406\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u57fa\u7840\u6a21\u578b\u5177\u6709\u5f3a\u5927\u80fd\u529b\u548c\u65b0\u9896\u529f\u80fd\uff0c\u591a\u6a21\u578b\u534f\u540c\u4f7f\u7528\u53ef\u63d0\u4f9b\u4e92\u8865\u4ef7\u503c\u5e76\u89e3\u9501\u66f4\u4f18\u9884\u6d4b\u80fd\u529b\u3002\u5728\u771f\u5b9e\u5371\u673a\u573a\u666f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4ee3\u7406\u80fd\u591f\u63d0\u4f9b\u5173\u952e\u53ca\u65f6\u7684\u6d1e\u5bdf\u3002", "conclusion": "Earth AI\u80fd\u591f\u6709\u6548\u5f25\u5408\u539f\u59cb\u5730\u7406\u7a7a\u95f4\u6570\u636e\u4e0e\u53ef\u64cd\u4f5c\u7406\u89e3\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5730\u7403\u6d1e\u5bdf\u63d0\u4f9b\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2510.18342", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18342", "abs": "https://arxiv.org/abs/2510.18342", "authors": ["Peng Tang", "Xiaoxiao Yan", "Xiaobin Hu", "Yuning Cui", "Donghao Luo", "Jiangning Zhang", "Pengcheng Xu", "Jinlong Peng", "Qingdong He", "Feiyue Huang", "Song Xue", "Tobias Lasser"], "title": "ShortcutBreaker: Low-Rank Noisy Bottleneck with Global Perturbation Attention for Multi-Class Unsupervised Anomaly Detection", "comment": "Under Review", "summary": "Multi-class unsupervised anomaly detection (MUAD) has garnered growing\nresearch interest, as it seeks to develop a unified model for anomaly detection\nacross multiple classes, i.e., eliminating the need to train separate models\nfor distinct objects and thereby saving substantial computational resources.\nUnder the MUAD setting, while advanced Transformer-based architectures have\nbrought significant performance improvements, identity shortcuts persist: they\ndirectly copy inputs to outputs, narrowing the gap in reconstruction errors\nbetween normal and abnormal cases, and thereby making the two harder to\ndistinguish. Therefore, we propose ShortcutBreaker, a novel unified\nfeature-reconstruction framework for MUAD tasks, featuring two key innovations\nto address the issue of shortcuts. First, drawing on matrix rank inequality, we\ndesign a low-rank noisy bottleneck (LRNB) to project highdimensional features\ninto a low-rank latent space, and theoretically demonstrate its capacity to\nprevent trivial identity reproduction. Second, leveraging ViTs global modeling\ncapability instead of merely focusing on local features, we incorporate a\nglobal perturbation attention to prevent information shortcuts in the decoders.\nExtensive experiments are performed on four widely used anomaly detection\nbenchmarks, including three industrial datasets (MVTec-AD, ViSA, and Real-IAD)\nand one medical dataset (Universal Medical). The proposed method achieves a\nremarkable image-level AUROC of 99.8%, 98.9%, 90.6%, and 87.8% on these four\ndatasets, respectively, consistently outperforming previous MUAD methods across\ndifferent scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86ShortcutBreaker\u6846\u67b6\uff0c\u901a\u8fc7\u4f4e\u79e9\u566a\u58f0\u74f6\u9888\u548c\u5168\u5c40\u6270\u52a8\u6ce8\u610f\u529b\u673a\u5236\u89e3\u51b3\u591a\u7c7b\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u8eab\u4efd\u6377\u5f84\u95ee\u9898\uff0c\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u591a\u7c7b\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u9700\u8981\u7edf\u4e00\u6a21\u578b\u5904\u7406\u591a\u4e2a\u7c7b\u522b\uff0c\u4f46\u73b0\u6709Transformer\u67b6\u6784\u5b58\u5728\u8eab\u4efd\u6377\u5f84\u95ee\u9898\uff0c\u5373\u76f4\u63a5\u590d\u5236\u8f93\u5165\u5230\u8f93\u51fa\uff0c\u5bfc\u81f4\u6b63\u5e38\u548c\u5f02\u5e38\u6837\u672c\u7684\u91cd\u6784\u8bef\u5dee\u5dee\u5f02\u7f29\u5c0f\uff0c\u96be\u4ee5\u533a\u5206\u3002", "method": "1. \u57fa\u4e8e\u77e9\u9635\u79e9\u4e0d\u7b49\u5f0f\u8bbe\u8ba1\u4f4e\u79e9\u566a\u58f0\u74f6\u9888\uff0c\u5c06\u9ad8\u7ef4\u7279\u5f81\u6295\u5f71\u5230\u4f4e\u79e9\u6f5c\u5728\u7a7a\u95f4\uff0c\u9632\u6b62\u5e73\u51e1\u8eab\u4efd\u590d\u5236\uff1b2. \u5229\u7528ViT\u7684\u5168\u5c40\u5efa\u6a21\u80fd\u529b\uff0c\u5f15\u5165\u5168\u5c40\u6270\u52a8\u6ce8\u610f\u529b\u9632\u6b62\u89e3\u7801\u5668\u4e2d\u7684\u4fe1\u606f\u6377\u5f84\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\uff1aMVTec-AD(99.8%)\u3001ViSA(98.9%)\u3001Real-IAD(90.6%)\u548cUniversal Medical(87.8%)\u7684\u56fe\u50cf\u7ea7AUROC\uff0c\u5747\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002", "conclusion": "ShortcutBreaker\u901a\u8fc7\u6709\u6548\u89e3\u51b3\u8eab\u4efd\u6377\u5f84\u95ee\u9898\uff0c\u5728\u591a\u7c7b\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u5353\u8d8a\u6027\u80fd\uff0c\u4e3a\u7edf\u4e00\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.18395", "categories": ["cs.AI", "68T42, 68T37, 91A35", "I.2.6; I.2.11; I.2.8; K.8.0"], "pdf": "https://arxiv.org/pdf/2510.18395", "abs": "https://arxiv.org/abs/2510.18395", "authors": ["Runnan Qi", "Yanan Ni", "Lumin Jiang", "Zongyuan Li", "Kuihua Huang", "Xian Guo"], "title": "Memory-Augmented State Machine Prompting: A Novel LLM Agent Framework for Real-Time Strategy Games", "comment": "10 pages, 4 figures, 1 table, 1 algorithm. Submitted to conference", "summary": "This paper proposes Memory-Augmented State Machine Prompting (MASMP), a novel\nframework for LLM agents in real-time strategy games. Addressing key challenges\nlike hallucinations and fragmented decision-making in existing approaches,\nMASMP integrates state machine prompting with memory mechanisms to unify\nstructured actions with long-term tactical coherence. The framework features:\n(1) a natural language-driven state machine architecture that guides LLMs to\nemulate finite state machines and behavior trees through prompts, and (2) a\nlightweight memory module preserving strategic variables (e.g., tactics,\npriority units) across decision cycles. Experiments in StarCraft II demonstrate\nMASMP's 60% win rate against the hardest built-in AI (Lv7), vastly\noutperforming baselines (0%). Case studies reveal the method retains LLMs'\nsemantic comprehension while resolving the \"Knowing-Doing Gap\" through strict\nstate-action mapping, achieving both interpretability and FSM-like reliability.\nThis work establishes a new paradigm for combining neural and symbolic AI in\ncomplex decision-making.", "AI": {"tldr": "\u63d0\u51faMemory-Augmented State Machine Prompting (MASMP)\u6846\u67b6\uff0c\u901a\u8fc7\u72b6\u6001\u673a\u63d0\u793a\u548c\u8bb0\u5fc6\u673a\u5236\u89e3\u51b3LLM\u5728\u5b9e\u65f6\u7b56\u7565\u6e38\u620f\u4e2d\u7684\u5e7b\u89c9\u548c\u51b3\u7b56\u788e\u7247\u5316\u95ee\u9898\uff0c\u5728\u661f\u9645\u4e89\u9738II\u4e2d\u8fbe\u523060%\u80dc\u7387\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4e2dLLM\u4ee3\u7406\u5728\u5b9e\u65f6\u7b56\u7565\u6e38\u620f\u4e2d\u5b58\u5728\u7684\u5e7b\u89c9\u95ee\u9898\u548c\u51b3\u7b56\u788e\u7247\u5316\u95ee\u9898\uff0c\u7edf\u4e00\u7ed3\u6784\u5316\u52a8\u4f5c\u4e0e\u957f\u671f\u6218\u672f\u8fde\u8d2f\u6027\u3002", "method": "\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u7684\u72b6\u6001\u673a\u67b6\u6784\uff08\u6a21\u62df\u6709\u9650\u72b6\u6001\u673a\u548c\u884c\u4e3a\u6811\uff09\u548c\u8f7b\u91cf\u7ea7\u8bb0\u5fc6\u6a21\u5757\uff08\u4fdd\u5b58\u6218\u7565\u53d8\u91cf\u5982\u6218\u672f\u3001\u4f18\u5148\u7ea7\u5355\u4f4d\uff09\u3002", "result": "\u5728\u661f\u9645\u4e89\u9738II\u5b9e\u9a8c\u4e2d\uff0cMASMP\u5bf9\u6700\u5f3a\u5185\u7f6eAI\uff08Lv7\uff09\u8fbe\u523060%\u80dc\u7387\uff0c\u8fdc\u8d85\u57fa\u7ebf\u65b9\u6cd5\uff080%\uff09\u3002\u6848\u4f8b\u7814\u7a76\u663e\u793a\u8be5\u65b9\u6cd5\u4fdd\u6301\u4e86LLM\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u540c\u65f6\u901a\u8fc7\u4e25\u683c\u7684\u72b6\u6001-\u52a8\u4f5c\u6620\u5c04\u89e3\u51b3\u4e86\"\u77e5\u884c\u5dee\u8ddd\"\u95ee\u9898\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5728\u590d\u6742\u51b3\u7b56\u4e2d\u7ed3\u5408\u795e\u7ecf\u548c\u7b26\u53f7AI\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u7c7b\u4f3cFSM\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.18407", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18407", "abs": "https://arxiv.org/abs/2510.18407", "authors": ["Manjie Xu", "Xinyi Yang", "Jiayu Zhan", "Wei Liang", "Chi Zhang", "Yixin Zhu"], "title": "Heterogeneous Adversarial Play in Interactive Environments", "comment": "NeurIPS 2025", "summary": "Self-play constitutes a fundamental paradigm for autonomous skill\nacquisition, whereby agents iteratively enhance their capabilities through\nself-directed environmental exploration. Conventional self-play frameworks\nexploit agent symmetry within zero-sum competitive settings, yet this approach\nproves inadequate for open-ended learning scenarios characterized by inherent\nasymmetry. Human pedagogical systems exemplify asymmetric instructional\nframeworks wherein educators systematically construct challenges calibrated to\nindividual learners' developmental trajectories. The principal challenge\nresides in operationalizing these asymmetric, adaptive pedagogical mechanisms\nwithin artificial systems capable of autonomously synthesizing appropriate\ncurricula without predetermined task hierarchies. Here we present Heterogeneous\nAdversarial Play (HAP), an adversarial Automatic Curriculum Learning framework\nthat formalizes teacher-student interactions as a minimax optimization wherein\ntask-generating instructor and problem-solving learner co-evolve through\nadversarial dynamics. In contrast to prevailing ACL methodologies that employ\nstatic curricula or unidirectional task selection mechanisms, HAP establishes a\nbidirectional feedback system wherein instructors continuously recalibrate task\ncomplexity in response to real-time learner performance metrics. Experimental\nvalidation across multi-task learning domains demonstrates that our framework\nachieves performance parity with SOTA baselines while generating curricula that\nenhance learning efficacy in both artificial agents and human subjects.", "AI": {"tldr": "\u63d0\u51faHeterogeneous Adversarial Play (HAP)\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u81ea\u52a8\u8bfe\u7a0b\u5b66\u4e60\u5b9e\u73b0\u6559\u5e08-\u5b66\u751f\u534f\u540c\u8fdb\u5316\uff0c\u89e3\u51b3\u4f20\u7edf\u81ea\u535a\u5f08\u5728\u975e\u5bf9\u79f0\u5b66\u4e60\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u81ea\u535a\u5f08\u65b9\u6cd5\u4f9d\u8d56\u667a\u80fd\u4f53\u5bf9\u79f0\u6027\uff0c\u5728\u96f6\u548c\u7ade\u4e89\u73af\u5883\u4e2d\u6709\u6548\uff0c\u4f46\u65e0\u6cd5\u9002\u5e94\u5f00\u653e\u5f0f\u7684\u975e\u5bf9\u79f0\u5b66\u4e60\u573a\u666f\u3002\u4eba\u7c7b\u6559\u5b66\u7cfb\u7edf\u5c55\u793a\u4e86\u975e\u5bf9\u79f0\u6559\u5b66\u6846\u67b6\u7684\u4f18\u52bf\uff0c\u9700\u8981\u5c06\u5176\u673a\u5236\u64cd\u4f5c\u5316\u5230\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\u3002", "method": "HAP\u5c06\u5e08\u751f\u4e92\u52a8\u5f62\u5f0f\u5316\u4e3a\u6781\u5c0f\u6781\u5927\u4f18\u5316\uff0c\u4efb\u52a1\u751f\u6210\u6559\u5e08\u548c\u95ee\u9898\u89e3\u51b3\u5b66\u751f\u901a\u8fc7\u5bf9\u6297\u52a8\u6001\u534f\u540c\u8fdb\u5316\u3002\u5efa\u7acb\u53cc\u5411\u53cd\u9988\u7cfb\u7edf\uff0c\u6559\u5e08\u6839\u636e\u5b9e\u65f6\u5b66\u4e60\u8005\u8868\u73b0\u91cd\u65b0\u6821\u51c6\u4efb\u52a1\u590d\u6742\u5ea6\u3002", "result": "\u5728\u591a\u4efb\u52a1\u5b66\u4e60\u9886\u57df\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u6846\u67b6\u8fbe\u5230\u6700\u5148\u8fdb\u57fa\u7ebf\u7684\u6027\u80fd\u6c34\u5e73\uff0c\u540c\u65f6\u751f\u6210\u7684\u8bfe\u7a0b\u63d0\u9ad8\u4e86\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u548c\u4eba\u7c7b\u53d7\u8bd5\u8005\u7684\u5b66\u4e60\u6548\u7387\u3002", "conclusion": "HAP\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u975e\u5bf9\u79f0\u81ea\u9002\u5e94\u6559\u5b66\u673a\u5236\u5728\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u64cd\u4f5c\u5316\uff0c\u4e3a\u5f00\u653e\u5f0f\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u52a8\u8bfe\u7a0b\u751f\u6210\u65b9\u6cd5\u3002"}}
{"id": "2510.18412", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18412", "abs": "https://arxiv.org/abs/2510.18412", "authors": ["Mattia Pujatti", "Andrea Di Luca", "Nicola Peghini", "Federico Monegaglia", "Marco Cristoforetti"], "title": "Deep Learning-Based Control Optimization for Glass Bottle Forming", "comment": "37 pages, 17 figures, accepted for publication in \"Expert Systems\n  With Applications\"", "summary": "In glass bottle manufacturing, precise control of forming machines is\ncritical for ensuring quality and minimizing defects. This study presents a\ndeep learning-based control algorithm designed to optimize the forming process\nin real production environments. Using real operational data from active\nmanufacturing plants, our neural network predicts the effects of parameter\nchanges based on the current production setup. Through a specifically designed\ninversion mechanism, the algorithm identifies the optimal machine settings\nrequired to achieve the desired glass gob characteristics. Experimental results\non historical datasets from multiple production lines show that the proposed\nmethod yields promising outcomes, suggesting potential for enhanced process\nstability, reduced waste, and improved product consistency. These results\nhighlight the potential of deep learning to process control in glass\nmanufacturing.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u63a7\u5236\u7b97\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u73bb\u7483\u74f6\u5236\u9020\u4e2d\u7684\u6210\u578b\u8fc7\u7a0b\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u53c2\u6570\u53d8\u5316\u6548\u679c\u5e76\u786e\u5b9a\u6700\u4f73\u673a\u5668\u8bbe\u7f6e\u3002", "motivation": "\u5728\u73bb\u7483\u74f6\u5236\u9020\u4e2d\uff0c\u7cbe\u786e\u63a7\u5236\u6210\u578b\u673a\u5668\u5bf9\u4e8e\u786e\u4fdd\u8d28\u91cf\u548c\u51cf\u5c11\u7f3a\u9677\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u5b9e\u9645\u751f\u4ea7\u6570\u636e\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684\u53cd\u6f14\u673a\u5236\u8bc6\u522b\u5b9e\u73b0\u6240\u9700\u73bb\u7483\u6599\u6ef4\u7279\u6027\u7684\u6700\u4f18\u673a\u5668\u8bbe\u7f6e\u3002", "result": "\u5728\u591a\u4e2a\u751f\u4ea7\u7ebf\u7684\u5386\u53f2\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u5728\u73bb\u7483\u5236\u9020\u8fc7\u7a0b\u63a7\u5236\u4e2d\u5177\u6709\u589e\u5f3a\u5de5\u827a\u7a33\u5b9a\u6027\u3001\u51cf\u5c11\u6d6a\u8d39\u548c\u63d0\u9ad8\u4ea7\u54c1\u4e00\u81f4\u6027\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.18424", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18424", "abs": "https://arxiv.org/abs/2510.18424", "authors": ["Guangfu Guo", "Xiaoqian Lu", "Yue Feng"], "title": "Med-VRAgent: A Framework for Medical Visual Reasoning-Enhanced Agents", "comment": null, "summary": "Visual Language Models (VLMs) achieve promising results in medical reasoning\nbut struggle with hallucinations, vague descriptions, inconsistent logic and\npoor localization. To address this, we propose a agent framework named Medical\nVisual Reasoning Agent (\\textbf{Med-VRAgent}). The approach is based on Visual\nGuidance and Self-Reward paradigms and Monte Carlo Tree Search (MCTS). By\ncombining the Visual Guidance with tree search, Med-VRAgent improves the\nmedical visual reasoning capabilities of VLMs. We use the trajectories\ncollected by Med-VRAgent as feedback to further improve the performance by\nfine-tuning the VLMs with the proximal policy optimization (PPO) objective.\nExperiments on multiple medical VQA benchmarks demonstrate that our method\noutperforms existing approaches.", "AI": {"tldr": "\u63d0\u51faMed-VRAgent\u6846\u67b6\uff0c\u7ed3\u5408\u89c6\u89c9\u5f15\u5bfc\u3001\u81ea\u6211\u5956\u52b1\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u89e3\u51b3\u533b\u5b66\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u3001\u6a21\u7cca\u63cf\u8ff0\u7b49\u95ee\u9898\uff0c\u5e76\u901a\u8fc7PPO\u5fae\u8c03\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u533b\u5b66\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u5e7b\u89c9\u3001\u6a21\u7cca\u63cf\u8ff0\u3001\u903b\u8f91\u4e0d\u4e00\u81f4\u548c\u5b9a\u4f4d\u80fd\u529b\u5dee\u7b49\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u5176\u533b\u5b66\u89c6\u89c9\u63a8\u7406\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u89c6\u89c9\u5f15\u5bfc\u548c\u81ea\u6211\u5956\u52b1\u8303\u5f0f\uff0c\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6784\u5efaMed-VRAgent\u6846\u67b6\uff0c\u5e76\u4f7f\u7528PPO\u76ee\u6807\u5bf9VLM\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5728\u591a\u4e2a\u533b\u5b66VQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Med-VRAgent\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u533b\u5b66\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u5e7b\u89c9\u7b49\u5173\u952e\u95ee\u9898\u3002"}}
{"id": "2510.18425", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18425", "abs": "https://arxiv.org/abs/2510.18425", "authors": ["Chenxu Zhang", "Fuxiang Huang", "Lei Zhang"], "title": "Automated urban waterlogging assessment and early warning through a mixture of foundation models", "comment": "Submitted to Nature", "summary": "With climate change intensifying, urban waterlogging poses an increasingly\nsevere threat to global public safety and infrastructure. However, existing\nmonitoring approaches rely heavily on manual reporting and fail to provide\ntimely and comprehensive assessments. In this study, we present Urban\nWaterlogging Assessment (UWAssess), a foundation model-driven framework that\nautomatically identifies waterlogged areas in surveillance images and generates\nstructured assessment reports. To address the scarcity of labeled data, we\ndesign a semi-supervised fine-tuning strategy and a chain-of-thought (CoT)\nprompting strategy to unleash the potential of the foundation model for\ndata-scarce downstream tasks. Evaluations on challenging visual benchmarks\ndemonstrate substantial improvements in perception performance. GPT-based\nevaluations confirm the ability of UWAssess to generate reliable textual\nreports that accurately describe waterlogging extent, depth, risk and impact.\nThis dual capability enables a shift of waterlogging monitoring from perception\nto generation, while the collaborative framework of multiple foundation models\nlays the groundwork for intelligent and scalable systems, supporting urban\nmanagement, disaster response and climate resilience.", "AI": {"tldr": "UWAssess\u662f\u4e00\u4e2a\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u63a7\u56fe\u50cf\u81ea\u52a8\u8bc6\u522b\u79ef\u6c34\u533a\u57df\u5e76\u751f\u6210\u7ed3\u6784\u5316\u8bc4\u4f30\u62a5\u544a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u4eba\u5de5\u76d1\u6d4b\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u52a0\u5267\u5bfc\u81f4\u57ce\u5e02\u5185\u6d9d\u95ee\u9898\u65e5\u76ca\u4e25\u91cd\uff0c\u73b0\u6709\u76d1\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u62a5\u544a\uff0c\u65e0\u6cd5\u63d0\u4f9b\u53ca\u65f6\u5168\u9762\u7684\u8bc4\u4f30\u3002", "method": "\u91c7\u7528\u534a\u76d1\u7763\u5fae\u8c03\u7b56\u7565\u548c\u601d\u7ef4\u94fe\u63d0\u793a\u7b56\u7565\uff0c\u91ca\u653e\u57fa\u7840\u6a21\u578b\u5728\u6570\u636e\u7a00\u7f3a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u7ed3\u5408\u591a\u4e2a\u57fa\u7840\u6a21\u578b\u7684\u534f\u4f5c\u6846\u67b6\u3002", "result": "\u5728\u89c6\u89c9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u611f\u77e5\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0cGPT\u8bc4\u4f30\u786e\u8ba4\u80fd\u591f\u751f\u6210\u51c6\u786e\u63cf\u8ff0\u79ef\u6c34\u8303\u56f4\u3001\u6df1\u5ea6\u3001\u98ce\u9669\u548c\u5f71\u54cd\u7684\u53ef\u9760\u6587\u672c\u62a5\u544a\u3002", "conclusion": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u4ece\u611f\u77e5\u5230\u751f\u6210\u7684\u76d1\u6d4b\u6a21\u5f0f\u8f6c\u53d8\uff0c\u4e3a\u667a\u80fd\u53ef\u6269\u5c55\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u652f\u6301\u57ce\u5e02\u7ba1\u7406\u3001\u707e\u5bb3\u54cd\u5e94\u548c\u6c14\u5019\u97e7\u6027\u5efa\u8bbe\u3002"}}
{"id": "2510.18428", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18428", "abs": "https://arxiv.org/abs/2510.18428", "authors": ["Minwei Kong", "Ao Qu", "Xiaotong Guo", "Wenbin Ouyang", "Chonghe Jiang", "Han Zheng", "Yining Ma", "Dingyi Zhuang", "Yuhan Tang", "Junyi Li", "Hai Wang", "Cathy Wu", "Jinhua Zhao"], "title": "AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library", "comment": null, "summary": "Optimization modeling enables critical decisions across industries but\nremains difficult to automate: informal language must be mapped to precise\nmathematical formulations and executable solver code. Prior LLM approaches\neither rely on brittle prompting or costly retraining with limited\ngeneralization. We present AlphaOPT, a self-improving experience library that\nenables an LLM to learn from limited demonstrations (even answers alone,\nwithout gold-standard programs) and solver feedback - without annotated\nreasoning traces or parameter updates. AlphaOPT operates in a continual\ntwo-phase cycle: (i) a Library Learning phase that reflects on failed attempts,\nextracting solver-verified, structured insights as {taxonomy, condition,\nexplanation, example}; and (ii) a Library Evolution phase that diagnoses\nretrieval misalignments and refines the applicability conditions of stored\ninsights, improving transfer across tasks. This design (1) learns efficiently\nfrom limited demonstrations without curated rationales, (2) expands continually\nwithout costly retraining by updating the library rather than model weights,\nand (3) makes knowledge explicit and interpretable for human inspection and\nintervention. Experiments show that AlphaOPT steadily improves with more data\n(65% to 72% from 100 to 300 training items) and surpasses the strongest\nbaseline by 7.7% on the out-of-distribution OptiBench dataset when trained only\non answers. Code and data are available at:\nhttps://github.com/Minw913/AlphaOPT.", "AI": {"tldr": "AlphaOPT\u662f\u4e00\u4e2a\u81ea\u6539\u8fdb\u7684\u7ecf\u9a8c\u5e93\u7cfb\u7edf\uff0c\u8ba9LLM\u80fd\u591f\u4ece\u6709\u9650\u6f14\u793a\u548c\u6c42\u89e3\u5668\u53cd\u9988\u4e2d\u5b66\u4e60\u4f18\u5316\u5efa\u6a21\uff0c\u65e0\u9700\u6807\u6ce8\u63a8\u7406\u8f68\u8ff9\u6216\u53c2\u6570\u66f4\u65b0\u3002", "motivation": "\u4f18\u5316\u5efa\u6a21\u5728\u884c\u4e1a\u4e2d\u81f3\u5173\u91cd\u8981\u4f46\u96be\u4ee5\u81ea\u52a8\u5316\uff0c\u73b0\u6709LLM\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u8106\u5f31\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u8981\u4e48\u9700\u8981\u6602\u8d35\u7684\u91cd\u65b0\u8bad\u7ec3\u4e14\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002", "method": "\u91c7\u7528\u6301\u7eed\u4e24\u9636\u6bb5\u5faa\u73af\uff1a\u5e93\u5b66\u4e60\u9636\u6bb5\u4ece\u5931\u8d25\u5c1d\u8bd5\u4e2d\u63d0\u53d6\u6c42\u89e3\u5668\u9a8c\u8bc1\u7684\u7ed3\u6784\u5316\u89c1\u89e3\uff1b\u5e93\u6f14\u5316\u9636\u6bb5\u8bca\u65ad\u68c0\u7d22\u504f\u5dee\u5e76\u6539\u8fdb\u5b58\u50a8\u89c1\u89e3\u7684\u9002\u7528\u6761\u4ef6\u3002", "result": "\u5b9e\u9a8c\u663e\u793aAlphaOPT\u968f\u6570\u636e\u589e\u52a0\u7a33\u6b65\u6539\u8fdb\uff08\u4ece100\u5230300\u8bad\u7ec3\u9879\uff0c\u51c6\u786e\u7387\u4ece65%\u5347\u81f372%\uff09\uff0c\u5728\u4ec5\u4f7f\u7528\u7b54\u6848\u8bad\u7ec3\u65f6\u5728OptiBench\u6570\u636e\u96c6\u4e0a\u6bd4\u6700\u5f3a\u57fa\u7ebf\u9ad8\u51fa7.7%\u3002", "conclusion": "AlphaOPT\u80fd\u591f\u9ad8\u6548\u5730\u4ece\u6709\u9650\u6f14\u793a\u4e2d\u5b66\u4e60\uff0c\u901a\u8fc7\u66f4\u65b0\u5e93\u800c\u975e\u6a21\u578b\u6743\u91cd\u5b9e\u73b0\u6301\u7eed\u6269\u5c55\uff0c\u5e76\u4f7f\u77e5\u8bc6\u663e\u5f0f\u5316\u548c\u53ef\u89e3\u91ca\u3002"}}
{"id": "2510.18442", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18442", "abs": "https://arxiv.org/abs/2510.18442", "authors": ["Ziwei Deng", "Mian Deng", "Chenjing Liang", "Zeming Gao", "Chennan Ma", "Chenxing Lin", "Haipeng Zhang", "Songzhu Mei", "Cheng Wang", "Siqi Shen"], "title": "PlanU: Large Language Model Decision Making through Planning under Uncertainty", "comment": "38 pages, 19 figures, NeurIPS 2025 Accepted", "summary": "Large Language Models (LLMs) are increasingly being explored across a range\nof decision-making tasks. However, LLMs sometimes struggle with decision-making\ntasks under uncertainty that are relatively easy for humans, such as planning\nactions in stochastic environments. The adoption of LLMs for decision-making is\nimpeded by uncertainty challenges, such as LLM uncertainty and environmental\nuncertainty. LLM uncertainty arises from the stochastic sampling process\ninherent to LLMs. Most LLM-based Decision-Making (LDM) approaches address LLM\nuncertainty through multiple reasoning chains or search trees. However, these\napproaches overlook environmental uncertainty, which leads to poor performance\nin environments with stochastic state transitions. Some recent LDM approaches\ndeal with uncertainty by forecasting the probability of unknown variables.\nHowever, they are not designed for multi-step decision-making tasks that\nrequire interaction with the environment. To address uncertainty in LLM\ndecision-making, we introduce PlanU, an LLM-based planning method that captures\nuncertainty within Monte Carlo Tree Search (MCTS). PlanU models the return of\neach node in the MCTS as a quantile distribution, which uses a set of quantiles\nto represent the return distribution. To balance exploration and exploitation\nduring tree search, PlanU introduces an Upper Confidence Bounds with Curiosity\n(UCC) score which estimates the uncertainty of MCTS nodes. Through extensive\nexperiments, we demonstrate the effectiveness of PlanU in LLM-based\ndecision-making tasks under uncertainty.", "AI": {"tldr": "PlanU\u662f\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4e2d\u5efa\u6a21\u4e0d\u786e\u5b9a\u6027\u6765\u89e3\u51b3LLM\u51b3\u7b56\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6311\u6218\u3002", "motivation": "LLM\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u51b3\u7b56\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u5728\u968f\u673a\u73af\u5883\u4e2d\u89c4\u5212\u884c\u52a8\u65f6\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u53ea\u5904\u7406LLM\u4e0d\u786e\u5b9a\u6027\u800c\u5ffd\u7565\u73af\u5883\u4e0d\u786e\u5b9a\u6027\uff0c\u8981\u4e48\u4e0d\u9002\u5408\u591a\u6b65\u51b3\u7b56\u4efb\u52a1\u3002", "method": "PlanU\u5c06MCTS\u4e2d\u6bcf\u4e2a\u8282\u70b9\u7684\u56de\u62a5\u5efa\u6a21\u4e3a\u5206\u4f4d\u6570\u5206\u5e03\uff0c\u4f7f\u7528\u4e00\u7ec4\u5206\u4f4d\u6570\u8868\u793a\u56de\u62a5\u5206\u5e03\u3002\u5f15\u5165\u4e86\u5e26\u6709\u597d\u5947\u5fc3\u7684\u4e0a\u7f6e\u4fe1\u754c\u5206\u6570\u6765\u5e73\u8861\u6811\u641c\u7d22\u4e2d\u7684\u63a2\u7d22\u4e0e\u5229\u7528\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86PlanU\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u57fa\u4e8eLLM\u7684\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "PlanU\u6210\u529f\u89e3\u51b3\u4e86LLM\u51b3\u7b56\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u968f\u673a\u73af\u5883\u4e2d\u7684\u591a\u6b65\u51b3\u7b56\u4efb\u52a1\u3002"}}
{"id": "2510.18470", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18470", "abs": "https://arxiv.org/abs/2510.18470", "authors": ["Shaobo Wang", "Yongliang Miao", "Yuancheng Liu", "and Qianli Ma", "Ning Liao", "Linfeng Zhang"], "title": "CircuitSeer: Mining High-Quality Data by Probing Mathematical Reasoning Circuits in LLMs", "comment": "14 pages, 5 figures", "summary": "Large language models (LLMs) have demonstrated impressive reasoning\ncapabilities, but scaling their performance often relies on massive reasoning\ndatasets that are computationally expensive to train on. Existing data\nselection methods aim to curate smaller, high-quality subsets but often rely on\ncostly external models or opaque heuristics. In this work, we shift the focus\nfrom external heuristics to the model's internal mechanisms. We find that\ncomplex reasoning tasks consistently activate a sparse, specialized subset of\nattention heads, forming core reasoning circuits. Building on this insight, we\npropose CircuitSeer, a novel data selection method that quantifies the\nreasoning complexity of data by measuring its influence on these crucial\ncircuits. Extensive experiments on 4 models and 9 datasets demonstrate\nCircuitSeer's superiority. Notably, fine-tuning Qwen2.5-Math-7B on just 10% of\ndata selected by our method achieves a 1.4-point gain in average Pass@1 over\ntraining on the full dataset, highlighting its efficiency and effectiveness.", "AI": {"tldr": "CircuitSeer\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u5185\u90e8\u6ce8\u610f\u529b\u673a\u5236\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u5173\u952e\u63a8\u7406\u7535\u8def\u6765\u9009\u62e9\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u5728\u4ec5\u4f7f\u752810%\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u80fd\u8d85\u8d8a\u5168\u6570\u636e\u96c6\u8bad\u7ec3\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u5916\u90e8\u6a21\u578b\u6216\u4e0d\u900f\u660e\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u800c\u672c\u6587\u8f6c\u5411\u5229\u7528\u6a21\u578b\u5185\u90e8\u673a\u5236\u6765\u8bc4\u4f30\u6570\u636e\u8d28\u91cf\u3002", "method": "\u53d1\u73b0\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4f1a\u6fc0\u6d3b\u7a00\u758f\u7684\u4e13\u7528\u6ce8\u610f\u529b\u5934\u5f62\u6210\u6838\u5fc3\u63a8\u7406\u7535\u8def\uff0cCircuitSeer\u901a\u8fc7\u91cf\u5316\u6570\u636e\u5bf9\u8fd9\u4e9b\u5173\u952e\u7535\u8def\u7684\u5f71\u54cd\u6765\u8861\u91cf\u63a8\u7406\u590d\u6742\u5ea6\u3002", "result": "\u57284\u4e2a\u6a21\u578b\u548c9\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cCircuitSeer\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u4f7f\u7528\u4ec510%\u6570\u636e\u8bad\u7ec3\u7684Qwen2.5-Math-7B\u5728\u5e73\u5747Pass@1\u4e0a\u6bd4\u5168\u6570\u636e\u96c6\u8bad\u7ec3\u9ad8\u51fa1.4\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "CircuitSeer\u8bc1\u660e\u4e86\u5229\u7528\u6a21\u578b\u5185\u90e8\u673a\u5236\u8fdb\u884c\u6570\u636e\u9009\u62e9\u7684\u6709\u6548\u6027\uff0c\u4e3a\u9ad8\u6548\u8bad\u7ec3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2510.18476", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.18476", "abs": "https://arxiv.org/abs/2510.18476", "authors": ["Feifan Xia", "Yuyang Fang", "Defang Li", "Yantong Xie", "Weikang Li", "Yang Li", "Deguo Xia", "Jizhou Huang"], "title": "Probabilistic Modeling of Intentions in Socially Intelligent LLM Agents", "comment": null, "summary": "We present a probabilistic intent modeling framework for large language model\n(LLM) agents in multi-turn social dialogue. The framework maintains a belief\ndistribution over a partner's latent intentions, initialized from contextual\npriors and dynamically updated through likelihood estimation after each\nutterance. The evolving distribution provides additional contextual grounding\nfor the policy, enabling adaptive dialogue strategies under uncertainty.\nPreliminary experiments in the SOTOPIA environment show consistent\nimprovements: the proposed framework increases the Overall score by 9.0% on\nSOTOPIA-All and 4.1% on SOTOPIA-Hard compared with the Qwen2.5-7B baseline, and\nslightly surpasses an oracle agent that directly observes partner intentions.\nThese early results suggest that probabilistic intent modeling can contribute\nto the development of socially intelligent LLM agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u591a\u8f6e\u793e\u4ea4\u5bf9\u8bdd\u4e2dLLM\u667a\u80fd\u4f53\u7684\u6982\u7387\u610f\u56fe\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u7ef4\u62a4\u5bf9\u4f19\u4f34\u6f5c\u5728\u610f\u56fe\u7684\u4fe1\u5ff5\u5206\u5e03\u6765\u63d0\u5347\u5bf9\u8bdd\u7b56\u7565\u9002\u5e94\u6027\u3002", "motivation": "\u5728\u591a\u8f6e\u793e\u4ea4\u5bf9\u8bdd\u4e2d\uff0cLLM\u667a\u80fd\u4f53\u9700\u8981\u7406\u89e3\u4f19\u4f34\u7684\u6f5c\u5728\u610f\u56fe\u4ee5\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u4ea4\u4e92\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u610f\u56fe\u4e0d\u786e\u5b9a\u6027\u7684\u5efa\u6a21\u3002", "method": "\u6846\u67b6\u7ef4\u62a4\u4f19\u4f34\u6f5c\u5728\u610f\u56fe\u7684\u4fe1\u5ff5\u5206\u5e03\uff0c\u4ece\u4e0a\u4e0b\u6587\u5148\u9a8c\u521d\u59cb\u5316\uff0c\u5e76\u5728\u6bcf\u8f6e\u5bf9\u8bdd\u540e\u901a\u8fc7\u4f3c\u7136\u4f30\u8ba1\u52a8\u6001\u66f4\u65b0\uff0c\u4e3a\u7b56\u7565\u63d0\u4f9b\u989d\u5916\u4e0a\u4e0b\u6587\u57fa\u7840\u3002", "result": "\u5728SOTOPIA\u73af\u5883\u4e2d\u7684\u521d\u6b65\u5b9e\u9a8c\u663e\u793a\uff1a\u76f8\u6bd4Qwen2.5-7B\u57fa\u7ebf\uff0c\u603b\u4f53\u5f97\u5206\u5728SOTOPIA-All\u4e0a\u63d0\u53479.0%\uff0c\u5728SOTOPIA-Hard\u4e0a\u63d0\u53474.1%\uff0c\u751a\u81f3\u7565\u5fae\u8d85\u8fc7\u76f4\u63a5\u89c2\u5bdf\u4f19\u4f34\u610f\u56fe\u7684oracle\u667a\u80fd\u4f53\u3002", "conclusion": "\u6982\u7387\u610f\u56fe\u5efa\u6a21\u6709\u52a9\u4e8e\u5f00\u53d1\u5177\u6709\u793e\u4f1a\u667a\u80fd\u7684LLM\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5bf9\u8bdd\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5e76\u63d0\u5347\u4ea4\u4e92\u8d28\u91cf\u3002"}}
{"id": "2510.18477", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18477", "abs": "https://arxiv.org/abs/2510.18477", "authors": ["Haichao Ji", "Zibo Wang", "Yifei Zhu", "Meng han", "Dan Wang", "Zhu Han"], "title": "LAFA: Agentic LLM-Driven Federated Analytics over Decentralized Data Sources", "comment": null, "summary": "Large Language Models (LLMs) have shown great promise in automating data\nanalytics tasks by interpreting natural language queries and generating\nmulti-operation execution plans. However, existing LLM-agent-based analytics\nframeworks operate under the assumption of centralized data access, offering\nlittle to no privacy protection. In contrast, federated analytics (FA) enables\nprivacy-preserving computation across distributed data sources, but lacks\nsupport for natural language input and requires structured, machine-readable\nqueries. In this work, we present LAFA, the first system that integrates\nLLM-agent-based data analytics with FA. LAFA introduces a hierarchical\nmulti-agent architecture that accepts natural language queries and transforms\nthem into optimized, executable FA workflows. A coarse-grained planner first\ndecomposes complex queries into sub-queries, while a fine-grained planner maps\neach subquery into a Directed Acyclic Graph of FA operations using prior\nstructural knowledge. To improve execution efficiency, an optimizer agent\nrewrites and merges multiple DAGs, eliminating redundant operations and\nminimizing computational and communicational overhead. Our experiments\ndemonstrate that LAFA consistently outperforms baseline prompting strategies by\nachieving higher execution plan success rates and reducing resource-intensive\nFA operations by a substantial margin. This work establishes a practical\nfoundation for privacy-preserving, LLM-driven analytics that supports natural\nlanguage input in the FA setting.", "AI": {"tldr": "LAFA\u662f\u9996\u4e2a\u5c06\u57fa\u4e8eLLM\u4ee3\u7406\u7684\u6570\u636e\u5206\u6790\u4e0e\u8054\u90a6\u5206\u6790(FA)\u76f8\u7ed3\u5408\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u5c42\u591a\u4ee3\u7406\u67b6\u6784\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3a\u4f18\u5316\u7684\u53ef\u6267\u884cFA\u5de5\u4f5c\u6d41\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u652f\u6301\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u4ee3\u7406\u7684\u5206\u6790\u6846\u67b6\u5047\u8bbe\u96c6\u4e2d\u5f0f\u6570\u636e\u8bbf\u95ee\uff0c\u7f3a\u4e4f\u9690\u79c1\u4fdd\u62a4\uff1b\u800c\u8054\u90a6\u5206\u6790(FA)\u652f\u6301\u9690\u79c1\u4fdd\u62a4\u8ba1\u7b97\u4f46\u9700\u8981\u7ed3\u6784\u5316\u67e5\u8be2\u3002\u9700\u8981\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u652f\u6301\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u591a\u4ee3\u7406\u67b6\u6784\uff1a\u7c97\u7c92\u5ea6\u89c4\u5212\u5668\u5206\u89e3\u590d\u6742\u67e5\u8be2\u4e3a\u5b50\u67e5\u8be2\uff0c\u7ec6\u7c92\u5ea6\u89c4\u5212\u5668\u5c06\u5b50\u67e5\u8be2\u6620\u5c04\u4e3aFA\u64cd\u4f5c\u7684\u6709\u5411\u65e0\u73af\u56fe(DAG)\uff0c\u4f18\u5316\u4ee3\u7406\u91cd\u5199\u548c\u5408\u5e76\u591a\u4e2aDAG\u4ee5\u6d88\u9664\u5197\u4f59\u64cd\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLAFA\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf\u63d0\u793a\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6267\u884c\u8ba1\u5212\u6210\u529f\u7387\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u4e86\u8d44\u6e90\u5bc6\u96c6\u578b\u7684FA\u64cd\u4f5c\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5728FA\u8bbe\u7f6e\u4e2d\u652f\u6301\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u7684\u9690\u79c1\u4fdd\u62a4\u3001LLM\u9a71\u52a8\u7684\u5206\u6790\u5efa\u7acb\u4e86\u5b9e\u7528\u57fa\u7840\u3002"}}
{"id": "2510.18483", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18483", "abs": "https://arxiv.org/abs/2510.18483", "authors": ["Haoran Zhang", "Chenhao Zhu", "Sicong Guo", "Hanzhe Guo", "Haiming Li", "Donglin Yu"], "title": "StarBench: A Turn-Based RPG Benchmark for Agentic Multimodal Decision-Making and Information Seeking", "comment": null, "summary": "Human players do more than press buttons: they ground what they see on screen\ninto precise keyboard-mouse actions and, when stuck, they seek information\nbefore trying again. We ask whether current vision-language models (VLMs) can\ndo the same. Despite encouraging results under simplified control or tool\nscaffolds, human-like play in a real client - mapping raw screenshots to\ntemporally coherent low-level actions while deciding when to ask for guidance -\nremains an open challenge. We introduce StarBench, a turn-based RPG benchmark\nderived from Honkai: Star Rail that targets these two human-like competencies:\nmultimodal decision-making from pixels to actions and agentic information\nseeking. StarBench standardizes evaluation across eight combat tasks and two\nregimes with shared tasks and metrics: (i) direct control, where agents receive\nonly screenshots and must emit low-level primitives (click and keypress) with\nno semantic hints; and (ii) tool-assisted control, where higher-level intents\ncan be mapped to primitives by detectors and OCR outputs provide optional\ntextualized observations to ease UI grounding. To mirror human practice,\nStarBench also includes an ask-or-act diagnostic that measures whether and when\nagents choose to request brief guidance before proceeding, and how that choice\naffects subsequent performance. We report reference baselines for contemporary\nVLMs and a human reference. Results expose sizable gaps in\nperception-to-control fidelity in the direct regime, while showing that\njudicious information seeking correlates with improved success, establishing\nStarBench as a reproducible yardstick for agentic information seeking and\nmultimodal decision-making in real-client play.", "AI": {"tldr": "StarBench\u662f\u4e00\u4e2a\u57fa\u4e8e\u300a\u5d29\u574f\uff1a\u661f\u7a79\u94c1\u9053\u300b\u7684\u56de\u5408\u5236RPG\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u50cf\u7d20\u5230\u52a8\u4f5c\u7684\u591a\u6a21\u6001\u51b3\u7b56\u548c\u4e3b\u52a8\u4fe1\u606f\u5bfb\u6c42\u4e24\u4e2a\u4eba\u7c7b\u80fd\u529b\u65b9\u9762\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u5ba2\u6237\u7aef\u4e2d\u5b9e\u73b0\u4eba\u7c7b\u5f0f\u6e38\u620f\uff08\u5c06\u539f\u59cb\u622a\u56fe\u6620\u5c04\u5230\u65f6\u95f4\u4e00\u81f4\u7684\u4f4e\u7ea7\u52a8\u4f5c\uff0c\u540c\u65f6\u51b3\u5b9a\u4f55\u65f6\u5bfb\u6c42\u6307\u5bfc\uff09\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\u3002", "method": "StarBench\u5728\u516b\u4e2a\u6218\u6597\u4efb\u52a1\u548c\u4e24\u79cd\u63a7\u5236\u6a21\u5f0f\u4e0b\u8fdb\u884c\u6807\u51c6\u5316\u8bc4\u4f30\uff1a\u76f4\u63a5\u63a7\u5236\uff08\u4ec5\u63a5\u6536\u622a\u56fe\u5e76\u8f93\u51fa\u4f4e\u7ea7\u64cd\u4f5c\uff09\u548c\u5de5\u5177\u8f85\u52a9\u63a7\u5236\uff08\u5141\u8bb8\u4f7f\u7528\u68c0\u6d4b\u5668\u548cOCR\u8f93\u51fa\uff09\u3002\u8fd8\u5305\u62ec\u8be2\u95ee\u6216\u884c\u52a8\u8bca\u65ad\uff0c\u6d4b\u91cf\u4ee3\u7406\u9009\u62e9\u8bf7\u6c42\u6307\u5bfc\u7684\u65f6\u673a\u548c\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5728\u76f4\u63a5\u63a7\u5236\u6a21\u5f0f\u4e0b\u611f\u77e5\u5230\u63a7\u5236\u7684\u4fdd\u771f\u5ea6\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u800c\u660e\u667a\u7684\u4fe1\u606f\u5bfb\u6c42\u4e0e\u6539\u8fdb\u7684\u6210\u529f\u7387\u76f8\u5173\u3002", "conclusion": "StarBench\u4e3a\u771f\u5b9e\u5ba2\u6237\u7aef\u6e38\u620f\u4e2d\u7684\u4e3b\u52a8\u4fe1\u606f\u5bfb\u6c42\u548c\u591a\u6a21\u6001\u51b3\u7b56\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u8861\u91cf\u6807\u51c6\u3002"}}
{"id": "2510.18488", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18488", "abs": "https://arxiv.org/abs/2510.18488", "authors": ["Ho Fai Leung", "Xiaoyan Xi", "Fei Zuo"], "title": "AndroidControl-Curated: Revealing the True Potential of GUI Agents through Benchmark Purification", "comment": null, "summary": "On-device virtual assistants like Siri and Google Assistant are increasingly\npivotal, yet their capabilities are hamstrung by a reliance on rigid,\ndeveloper-dependent APIs. GUI agents offer a powerful, API-independent\nalternative, but their adoption is hindered by the perception of poor\nperformance, as even the best models (e.g. Qwen3-VL-235B) scores are capped at\naround 60% on benchmarks like AndroidControl, far from viability for real-world\nuse. Our research reveals that issue lies not only with the models but with the\nbenchmarks themselves. We identified notable shortcomings in AndroidControl,\nincluding ambiguities and factual errors, which systematically underrates agent\ncapabilities. To address this critical oversight, we enhanced AndroidControl\ninto AndroidControl-Curated, a refined version of the benchmark improved\nthrough a rigorous purification pipeline. On this enhanced benchmark,\nstate-of-the-art models achieve success rates nearing 75% on complex tasks (15%\nimprovement), reflecting that on-device GUI agents are actually closer to\npractical deployment than previously thought. We introduce our new SOTA model,\nMagma-R1- 3B, post-trained on just 2.4k curated samples using 60 hours of an\nH20 GPU (approximately $60). Despite being 200 times smaller in parameters,\nthis model delivers performance comparable to Qwen3- VL-235B. We release both\nAndroidControl-Curated benchmark and Magma-R1 model to the research community,\nencouraging adoption of this enhanced benchmark to better reflect model\ncapabilities and accelerate the development of robust, on-device virtual\nassistants.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709GUI\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5AndroidControl\u5b58\u5728\u7f3a\u9677\uff0c\u901a\u8fc7\u6539\u8fdb\u521b\u5efaAndroidControl-Curated\u57fa\u51c6\uff0c\u4f7fSOTA\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u6210\u529f\u7387\u4ece60%\u63d0\u5347\u81f375%\u3002\u540c\u65f6\u5f00\u53d1\u4e86\u4ec5\u9700\u5c11\u91cf\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u7684Magma-R1-3B\u6a21\u578b\uff0c\u6027\u80fd\u53ef\u4e0e\u5927200\u500d\u7684\u6a21\u578b\u5ab2\u7f8e\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u865a\u62df\u52a9\u624b\u4f9d\u8d56\u521a\u6027API\u7684\u95ee\u9898\uff0c\u4ee5\u53caGUI\u4ee3\u7406\u56e0\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u9677\u800c\u88ab\u4f4e\u4f30\u6027\u80fd\u7684\u95ee\u9898\uff0c\u63a8\u52a8\u8bbe\u5907\u7aefGUI\u4ee3\u7406\u7684\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u8bc6\u522bAndroidControl\u57fa\u51c6\u7684\u6a21\u7cca\u6027\u548c\u4e8b\u5b9e\u9519\u8bef\uff0c\u901a\u8fc7\u4e25\u683c\u51c0\u5316\u6d41\u7a0b\u6539\u8fdb\u4e3aAndroidControl-Curated\u57fa\u51c6\uff1b\u4f7f\u7528\u4ec52.4k\u7cbe\u9009\u6837\u672c\u548c60\u5c0f\u65f6H20 GPU\u8bad\u7ec3Magma-R1-3B\u6a21\u578b\u3002", "result": "\u5728\u6539\u8fdb\u540e\u7684\u57fa\u51c6\u4e0a\uff0cSOTA\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u6210\u529f\u7387\u4ece\u7ea660%\u63d0\u5347\u81f3\u8fd175%\uff1bMagma-R1-3B\u6a21\u578b\u867d\u5c0f200\u500d\uff0c\u4f46\u6027\u80fd\u4e0eQwen3-VL-235B\u76f8\u5f53\u3002", "conclusion": "\u8bbe\u5907\u7aefGUI\u4ee3\u7406\u7684\u5b9e\u9645\u80fd\u529b\u88ab\u4f4e\u4f30\uff0c\u901a\u8fc7\u6539\u8fdb\u57fa\u51c6\u6d4b\u8bd5\u548c\u9ad8\u6548\u6a21\u578b\u8bad\u7ec3\uff0c\u8bc1\u660e\u4e86GUI\u4ee3\u7406\u5df2\u63a5\u8fd1\u5b9e\u9645\u90e8\u7f72\u6c34\u5e73\uff0c\u4e3a\u5f00\u53d1\u7a33\u5065\u7684\u8bbe\u5907\u7aef\u865a\u62df\u52a9\u624b\u63d0\u4f9b\u4e86\u65b0\u8def\u5f84\u3002"}}
{"id": "2510.18491", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18491", "abs": "https://arxiv.org/abs/2510.18491", "authors": ["Lianchen Jia", "Chaoyang Li", "Qian Houde", "Tianchi Huang", "Jiangchuan Liu", "Lifeng Sun"], "title": "Crucible: Quantifying the Potential of Control Algorithms through LLM Agents", "comment": "NeurIPS 2025", "summary": "Control algorithms in production environments typically require domain\nexperts to tune their parameters and logic for specific scenarios. However,\nexisting research predominantly focuses on algorithmic performance under ideal\nor default configurations, overlooking the critical aspect of Tuning Potential.\nTo bridge this gap, we introduce Crucible, an agent that employs an LLM-driven,\nmulti-level expert simulation to turn algorithms and defines a formalized\nmetric to quantitatively evaluate their Tuning Potential. We demonstrate\nCrucible's effectiveness across a wide spectrum of case studies, from classic\ncontrol tasks to complex computer systems, and validate its findings in a\nreal-world deployment. Our experimental results reveal that Crucible\nsystematically quantifies the tunable space across different algorithms.\nFurthermore, Crucible provides a new dimension for algorithm analysis and\ndesign, which ultimately leads to performance improvements. Our code is\navailable at https://github.com/thu-media/Crucible.", "AI": {"tldr": "\u63d0\u51fa\u4e86Crucible\u6846\u67b6\uff0c\u4f7f\u7528LLM\u9a71\u52a8\u7684\u591a\u7ea7\u4e13\u5bb6\u6a21\u62df\u6765\u8bc4\u4f30\u7b97\u6cd5\u7684\u8c03\u4f18\u6f5c\u529b\uff0c\u5e76\u5b9a\u4e49\u4e86\u91cf\u5316\u6307\u6807\u6765\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u7b97\u6cd5\u7684\u53ef\u8c03\u4f18\u7a7a\u95f4\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7b97\u6cd5\u5728\u7406\u60f3\u6216\u9ed8\u8ba4\u914d\u7f6e\u4e0b\u7684\u6027\u80fd\uff0c\u5ffd\u7565\u4e86\u8c03\u4f18\u6f5c\u529b\u7684\u5173\u952e\u65b9\u9762\uff0c\u800c\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u63a7\u5236\u7b97\u6cd5\u901a\u5e38\u9700\u8981\u9886\u57df\u4e13\u5bb6\u9488\u5bf9\u7279\u5b9a\u573a\u666f\u8fdb\u884c\u53c2\u6570\u548c\u903b\u8f91\u8c03\u4f18\u3002", "method": "\u91c7\u7528LLM\u9a71\u52a8\u7684\u591a\u7ea7\u4e13\u5bb6\u6a21\u62df\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u62df\u4e0d\u540c\u9886\u57df\u4e13\u5bb6\u7684\u8c03\u4f18\u8fc7\u7a0b\u6765\u8bc4\u4f30\u7b97\u6cd5\u7684\u8c03\u4f18\u6f5c\u529b\uff0c\u5e76\u5b9a\u4e49\u4e86\u5f62\u5f0f\u5316\u7684\u91cf\u5316\u6307\u6807\u3002", "result": "\u5728\u4ece\u7ecf\u5178\u63a7\u5236\u4efb\u52a1\u5230\u590d\u6742\u8ba1\u7b97\u673a\u7cfb\u7edf\u7684\u5e7f\u6cdb\u6848\u4f8b\u7814\u7a76\u4e2d\u9a8c\u8bc1\u4e86Crucible\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u771f\u5b9e\u90e8\u7f72\u4e2d\u9a8c\u8bc1\u4e86\u5176\u53d1\u73b0\uff0c\u7ed3\u679c\u663e\u793aCrucible\u80fd\u591f\u7cfb\u7edf\u91cf\u5316\u4e0d\u540c\u7b97\u6cd5\u7684\u53ef\u8c03\u4f18\u7a7a\u95f4\u3002", "conclusion": "Crucible\u4e3a\u7b97\u6cd5\u5206\u6790\u548c\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u7ef4\u5ea6\uff0c\u6700\u7ec8\u80fd\u591f\u5e26\u6765\u6027\u80fd\u6539\u8fdb\uff0c\u4e3a\u7b97\u6cd5\u8c03\u4f18\u6f5c\u529b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.18526", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18526", "abs": "https://arxiv.org/abs/2510.18526", "authors": ["Hanze Guo", "Jing Yao", "Xiao Zhou", "Xiaoyuan Yi", "Xing Xie"], "title": "Counterfactual Reasoning for Steerable Pluralistic Value Alignment of Large Language Models", "comment": "41 pages, 7 figures", "summary": "As large language models (LLMs) become increasingly integrated into\napplications serving users across diverse cultures, communities and\ndemographics, it is critical to align LLMs with pluralistic human values beyond\naverage principles (e.g., HHH). In psychological and social value theories such\nas Schwartz's Value Theory, pluralistic values are represented by multiple\nvalue dimensions paired with various priorities. However, existing methods\nencounter two challenges when aligning with such fine-grained value objectives:\n1) they often treat multiple values as independent and equally important,\nignoring their interdependence and relative priorities (value complexity); 2)\nthey struggle to precisely control nuanced value priorities, especially those\nunderrepresented ones (value steerability). To handle these challenges, we\npropose COUPLE, a COUnterfactual reasoning framework for PLuralistic valuE\nalignment. It introduces a structural causal model (SCM) to feature complex\ninterdependency and prioritization among features, as well as the causal\nrelationship between high-level value dimensions and behaviors. Moreover, it\napplies counterfactual reasoning to generate outputs aligned with any desired\nvalue objectives. Benefitting from explicit causal modeling, COUPLE also\nprovides better interpretability. We evaluate COUPLE on two datasets with\ndifferent value systems and demonstrate that COUPLE advances other baselines\nacross diverse types of value objectives.", "AI": {"tldr": "\u63d0\u51fa\u4e86COUPLE\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u548c\u53cd\u4e8b\u5b9e\u63a8\u7406\u6765\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u591a\u5143\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u4ef7\u503c\u89c2\u590d\u6742\u6027\u548c\u53ef\u5f15\u5bfc\u6027\u65b9\u9762\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u5143\u6587\u5316\u5e94\u7528\u4e2d\u7684\u666e\u53ca\uff0c\u9700\u8981\u8d85\u8d8a\u5e73\u5747\u539f\u5219\uff08\u5982HHH\uff09\u4e0e\u591a\u5143\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u4ef7\u503c\u89c2\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\u548c\u4f18\u5148\u7ea7\u63a7\u5236\u3002", "method": "\u63d0\u51faCOUPLE\u6846\u67b6\uff0c\u4f7f\u7528\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u5efa\u6a21\u4ef7\u503c\u89c2\u95f4\u7684\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u548c\u4f18\u5148\u7ea7\uff0c\u5e76\u901a\u8fc7\u53cd\u4e8b\u5b9e\u63a8\u7406\u751f\u6210\u7b26\u5408\u7279\u5b9a\u4ef7\u503c\u76ee\u6807\u7684\u8f93\u51fa\u3002", "result": "\u5728\u4e24\u4e2a\u4e0d\u540c\u4ef7\u503c\u4f53\u7cfb\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cCOUPLE\u5728\u591a\u79cd\u4ef7\u503c\u76ee\u6807\u7c7b\u578b\u4e0a\u90fd\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "COUPLE\u901a\u8fc7\u663e\u5f0f\u56e0\u679c\u5efa\u6a21\u6709\u6548\u89e3\u51b3\u4e86\u4ef7\u503c\u89c2\u5bf9\u9f50\u4e2d\u7684\u590d\u6742\u6027\u548c\u53ef\u5f15\u5bfc\u6027\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.18535", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18535", "abs": "https://arxiv.org/abs/2510.18535", "authors": ["Sarth Dubey", "Subimal Ghosh", "Udit Bhatia"], "title": "Physics-guided Emulators Reveal Resilience and Fragility under Operational Latencies and Outages", "comment": "45 pages, 5 main figures, 10 supplementary figures, 5 supplementary\n  tables", "summary": "Reliable hydrologic and flood forecasting requires models that remain stable\nwhen input data are delayed, missing, or inconsistent. However, most advances\nin rainfall-runoff prediction have been evaluated under ideal data conditions,\nemphasizing accuracy rather than operational resilience. Here, we develop an\noperationally ready emulator of the Global Flood Awareness System (GloFAS) that\ncouples long- and short-term memory networks with a relaxed water-balance\nconstraint to preserve physical coherence. Five architectures span a continuum\nof information availability: from complete historical and forecast forcings to\nscenarios with data latency and outages, allowing systematic evaluation of\nrobustness. Trained in minimally managed catchments across the United States\nand tested in more than 5,000 basins, including heavily regulated rivers in\nIndia, the emulator reproduces the hydrological core of GloFAS and degrades\nsmoothly as information quality declines. Transfer across contrasting\nhydroclimatic and management regimes yields reduced yet physically consistent\nperformance, defining the limits of generalization under data scarcity and\nhuman influence. The framework establishes operational robustness as a\nmeasurable property of hydrological machine learning and advances the design of\nreliable real-time forecasting systems.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u64cd\u4f5c\u7684GloFAS\u6d2a\u6c34\u9884\u62a5\u6a21\u62df\u5668\uff0c\u7ed3\u5408\u957f\u77ed\u65f6\u8bb0\u5fc6\u7f51\u7edc\u548c\u677e\u5f1b\u6c34\u91cf\u5e73\u8861\u7ea6\u675f\uff0c\u5728\u6570\u636e\u5ef6\u8fdf\u6216\u7f3a\u5931\u65f6\u4ecd\u80fd\u4fdd\u6301\u7a33\u5b9a\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u6c34\u6587\u6d2a\u6c34\u9884\u62a5\u6a21\u578b\u5927\u591a\u5728\u7406\u60f3\u6570\u636e\u6761\u4ef6\u4e0b\u8bc4\u4f30\uff0c\u5f3a\u8c03\u51c6\u786e\u6027\u800c\u975e\u64cd\u4f5c\u97e7\u6027\u3002\u9700\u8981\u5f00\u53d1\u5728\u8f93\u5165\u6570\u636e\u5ef6\u8fdf\u3001\u7f3a\u5931\u6216\u4e0d\u4e00\u81f4\u65f6\u4ecd\u80fd\u4fdd\u6301\u7a33\u5b9a\u7684\u53ef\u9760\u9884\u62a5\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u957f\u77ed\u65f6\u8bb0\u5fc6\u7f51\u7edc\u8026\u5408\u677e\u5f1b\u6c34\u91cf\u5e73\u8861\u7ea6\u675f\u6765\u4fdd\u6301\u7269\u7406\u4e00\u81f4\u6027\uff0c\u8bbe\u8ba1\u4e86\u4e94\u79cd\u67b6\u6784\u6765\u6a21\u62df\u4ece\u5b8c\u6574\u6570\u636e\u5230\u6570\u636e\u5ef6\u8fdf\u548c\u4e2d\u65ad\u7684\u5404\u79cd\u4fe1\u606f\u53ef\u7528\u6027\u573a\u666f\u3002\u5728\u7f8e\u56fd\u548c\u5370\u5ea65000\u591a\u4e2a\u6d41\u57df\u8fdb\u884c\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002", "result": "\u6a21\u62df\u5668\u6210\u529f\u590d\u5236\u4e86GloFAS\u7684\u6c34\u6587\u6838\u5fc3\u529f\u80fd\uff0c\u5728\u4fe1\u606f\u8d28\u91cf\u4e0b\u964d\u65f6\u6027\u80fd\u5e73\u6ed1\u9000\u5316\u3002\u5728\u4e0d\u540c\u6c34\u6587\u6c14\u5019\u548c\u7ba1\u7406\u5236\u5ea6\u95f4\u7684\u8fc1\u79fb\u4ea7\u751f\u4e86\u964d\u4f4e\u4f46\u4ecd\u4fdd\u6301\u7269\u7406\u4e00\u81f4\u6027\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u64cd\u4f5c\u7a33\u5065\u6027\u786e\u7acb\u4e3a\u6c34\u6587\u673a\u5668\u5b66\u4e60\u53ef\u6d4b\u91cf\u7684\u5c5e\u6027\uff0c\u63a8\u8fdb\u4e86\u53ef\u9760\u5b9e\u65f6\u9884\u62a5\u7cfb\u7edf\u7684\u8bbe\u8ba1\uff0c\u5b9a\u4e49\u4e86\u5728\u6570\u636e\u7a00\u7f3a\u548c\u4eba\u7c7b\u5f71\u54cd\u4e0b\u6cdb\u5316\u7684\u6781\u9650\u3002"}}
{"id": "2510.18551", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.18551", "abs": "https://arxiv.org/abs/2510.18551", "authors": ["Yuncheng Hua", "Sion Weatherhead", "Mehdi Jafari", "Hao Xue", "Flora D. Salim"], "title": "SOCIA-Nabla: Textual Gradient Meets Multi-Agent Orchestration for Automated Simulator Generation", "comment": "11 pages, 1 figure, 2 tables. The paper is under review", "summary": "In this paper, we present SOCIA-Nabla, an end-to-end, agentic framework that\ntreats simulator construction asinstance optimization over code within a\ntextual computation graph. Specialized LLM-driven agents are embedded as graph\nnodes, and a workflow manager executes a loss-driven loop: code synthesis ->\nexecution -> evaluation -> code repair. The optimizer performs Textual-Gradient\nDescent (TGD), while human-in-the-loop interaction is reserved for task-spec\nconfirmation, minimizing expert effort and keeping the code itself as the\ntrainable object. Across three CPS tasks, i.e., User Modeling, Mask Adoption,\nand Personal Mobility, SOCIA-Nabla attains state-of-the-art overall accuracy.\nBy unifying multi-agent orchestration with a loss-aligned optimization view,\nSOCIA-Nabla converts brittle prompt pipelines into reproducible,\nconstraint-aware simulator code generation that scales across domains and\nsimulation granularities. This work is under review, and we will release the\ncode soon.", "AI": {"tldr": "SOCIA-Nabla\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u6a21\u62df\u5668\u6784\u5efa\u89c6\u4e3a\u4ee3\u7801\u5b9e\u4f8b\u4f18\u5316\uff0c\u901a\u8fc7\u6587\u672c\u8ba1\u7b97\u56fe\u4e2d\u7684LLM\u9a71\u52a8\u667a\u80fd\u4f53\u548c\u635f\u5931\u9a71\u52a8\u5faa\u73af\u5b9e\u73b0\u4ee3\u7801\u5408\u6210\u3001\u6267\u884c\u3001\u8bc4\u4f30\u548c\u4fee\u590d\u3002", "motivation": "\u5c06\u8106\u5f31\u7684\u63d0\u793a\u7ba1\u9053\u8f6c\u6362\u4e3a\u53ef\u91cd\u73b0\u3001\u7ea6\u675f\u611f\u77e5\u7684\u6a21\u62df\u5668\u4ee3\u7801\u751f\u6210\uff0c\u5b9e\u73b0\u8de8\u9886\u57df\u548c\u6a21\u62df\u7c92\u5ea6\u7684\u6269\u5c55\u3002", "method": "\u5728\u6587\u672c\u8ba1\u7b97\u56fe\u4e2d\u5d4c\u5165\u4e13\u95e8\u7684LLM\u9a71\u52a8\u667a\u80fd\u4f53\u4f5c\u4e3a\u56fe\u8282\u70b9\uff0c\u5de5\u4f5c\u6d41\u7ba1\u7406\u5668\u6267\u884c\u635f\u5931\u9a71\u52a8\u5faa\u73af\uff1a\u4ee3\u7801\u5408\u6210\u2192\u6267\u884c\u2192\u8bc4\u4f30\u2192\u4ee3\u7801\u4fee\u590d\uff0c\u4f18\u5316\u5668\u6267\u884c\u6587\u672c\u68af\u5ea6\u4e0b\u964d(TGD)\u3002", "result": "\u5728\u4e09\u4e2aCPS\u4efb\u52a1\uff08\u7528\u6237\u5efa\u6a21\u3001\u53e3\u7f69\u91c7\u7528\u548c\u4e2a\u4eba\u79fb\u52a8\u6027\uff09\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6574\u4f53\u51c6\u786e\u7387\u3002", "conclusion": "\u901a\u8fc7\u7edf\u4e00\u591a\u667a\u80fd\u4f53\u7f16\u6392\u4e0e\u635f\u5931\u5bf9\u9f50\u7684\u4f18\u5316\u89c6\u89d2\uff0cSOCIA-Nabla\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u6a21\u62df\u5668\u4ee3\u7801\u751f\u6210\uff0c\u6700\u5c0f\u5316\u4e13\u5bb6\u5de5\u4f5c\u91cf\u5e76\u4fdd\u6301\u4ee3\u7801\u4f5c\u4e3a\u53ef\u8bad\u7ec3\u5bf9\u8c61\u3002"}}
{"id": "2510.18554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18554", "abs": "https://arxiv.org/abs/2510.18554", "authors": ["Federico Barbero", "Xiangming Gu", "Christopher A. Choquette-Choo", "Chawin Sitawarin", "Matthew Jagielski", "Itay Yona", "Petar Veli\u010dkovi\u0107", "Ilia Shumailov", "Jamie Hayes"], "title": "Extracting alignment data in open models", "comment": null, "summary": "In this work, we show that it is possible to extract significant amounts of\nalignment training data from a post-trained model -- useful to steer the model\nto improve certain capabilities such as long-context reasoning, safety,\ninstruction following, and maths. While the majority of related work on\nmemorisation has focused on measuring success of training data extraction\nthrough string matching, we argue that embedding models are better suited for\nour specific goals. Distances measured through a high quality embedding model\ncan identify semantic similarities between strings that a different metric such\nas edit distance will struggle to capture. In fact, in our investigation,\napproximate string matching would have severely undercounted (by a conservative\nestimate of $10\\times$) the amount of data that can be extracted due to trivial\nartifacts that deflate the metric. Interestingly, we find that models readily\nregurgitate training data that was used in post-training phases such as SFT or\nRL. We show that this data can be then used to train a base model, recovering a\nmeaningful amount of the original performance. We believe our work exposes a\npossibly overlooked risk towards extracting alignment data. Finally, our work\nopens up an interesting discussion on the downstream effects of distillation\npractices: since models seem to be regurgitating aspects of their training set,\ndistillation can therefore be thought of as indirectly training on the model's\noriginal dataset.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u53ef\u4ee5\u4ece\u540e\u8bad\u7ec3\u6a21\u578b\u4e2d\u63d0\u53d6\u5927\u91cf\u5bf9\u9f50\u8bad\u7ec3\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u53ef\u7528\u4e8e\u6539\u8fdb\u6a21\u578b\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u3001\u5b89\u5168\u6027\u3001\u6307\u4ee4\u9075\u5faa\u548c\u6570\u5b66\u80fd\u529b\u3002\u4f7f\u7528\u5d4c\u5165\u6a21\u578b\u6bd4\u4f20\u7edf\u5b57\u7b26\u4e32\u5339\u914d\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u5730\u8bc6\u522b\u8bed\u4e49\u76f8\u4f3c\u6027\u3002", "motivation": "\u63ed\u793a\u4ece\u540e\u8bad\u7ec3\u6a21\u578b\u4e2d\u63d0\u53d6\u5bf9\u9f50\u6570\u636e\u7684\u53ef\u80fd\u6027\uff0c\u66b4\u9732\u53ef\u80fd\u88ab\u5ffd\u89c6\u7684\u6570\u636e\u63d0\u53d6\u98ce\u9669\uff0c\u5e76\u63a2\u8ba8\u84b8\u998f\u5b9e\u8df5\u7684\u4e0b\u6e38\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u9ad8\u8d28\u91cf\u5d4c\u5165\u6a21\u578b\u6d4b\u91cf\u5b57\u7b26\u4e32\u95f4\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u800c\u975e\u4f20\u7edf\u7684\u8fd1\u4f3c\u5b57\u7b26\u4e32\u5339\u914d\u65b9\u6cd5\uff0c\u4ece\u540e\u8bad\u7ec3\u6a21\u578b\uff08\u5982SFT\u6216RL\uff09\u4e2d\u63d0\u53d6\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5d4c\u5165\u6a21\u578b\u65b9\u6cd5\u6bd4\u5b57\u7b26\u4e32\u5339\u914d\u591a\u53d1\u73b010\u500d\u7684\u53ef\u63d0\u53d6\u6570\u636e\uff0c\u63d0\u53d6\u7684\u6570\u636e\u53ef\u7528\u4e8e\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\uff0c\u6062\u590d\u76f8\u5f53\u90e8\u5206\u7684\u539f\u59cb\u6027\u80fd\u3002", "conclusion": "\u6a21\u578b\u5bb9\u6613\u91cd\u73b0\u540e\u8bad\u7ec3\u9636\u6bb5\u4f7f\u7528\u7684\u6570\u636e\uff0c\u84b8\u998f\u5b9e\u8df5\u53ef\u88ab\u89c6\u4e3a\u95f4\u63a5\u5728\u6a21\u578b\u539f\u59cb\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u8fd9\u66b4\u9732\u4e86\u63d0\u53d6\u5bf9\u9f50\u6570\u636e\u7684\u98ce\u9669\u3002"}}
{"id": "2510.18569", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18569", "abs": "https://arxiv.org/abs/2510.18569", "authors": ["Junhyeog Yun", "Hyoun Jun Lee", "Insu Jeon"], "title": "QuantEvolve: Automating Quantitative Strategy Discovery through Multi-Agent Evolutionary Framework", "comment": "25 pages, 13 figures. Accepted for oral presentation at the 2nd\n  Workshop on LLMs and Generative AI for Finance (AI4F), part of ACM ICAIF\n  2025, Singapore. Non-archival workshop", "summary": "Automating quantitative trading strategy development in dynamic markets is\nchallenging, especially with increasing demand for personalized investment\nsolutions. Existing methods often fail to explore the vast strategy space while\npreserving the diversity essential for robust performance across changing\nmarket conditions. We present QuantEvolve, an evolutionary framework that\ncombines quality-diversity optimization with hypothesis-driven strategy\ngeneration. QuantEvolve employs a feature map aligned with investor\npreferences, such as strategy type, risk profile, turnover, and return\ncharacteristics, to maintain a diverse set of effective strategies. It also\nintegrates a hypothesis-driven multi-agent system to systematically explore the\nstrategy space through iterative generation and evaluation. This approach\nproduces diverse, sophisticated strategies that adapt to both market regime\nshifts and individual investment needs. Empirical results show that QuantEvolve\noutperforms conventional baselines, validating its effectiveness. We release a\ndataset of evolved strategies to support future research.", "AI": {"tldr": "QuantEvolve\u662f\u4e00\u4e2a\u7ed3\u5408\u8d28\u91cf-\u591a\u6837\u6027\u4f18\u5316\u548c\u5047\u8bbe\u9a71\u52a8\u7b56\u7565\u751f\u6210\u7684\u8fdb\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u5f00\u53d1\u9002\u5e94\u52a8\u6001\u5e02\u573a\u548c\u4e2a\u6027\u5316\u6295\u8d44\u9700\u6c42\u7684\u91cf\u5316\u4ea4\u6613\u7b56\u7565\u3002", "motivation": "\u52a8\u6001\u5e02\u573a\u4e2d\u81ea\u52a8\u5316\u5f00\u53d1\u91cf\u5316\u4ea4\u6613\u7b56\u7565\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u63a2\u7d22\u5e7f\u9614\u7b56\u7565\u7a7a\u95f4\u7684\u540c\u65f6\u4fdd\u6301\u591a\u6837\u6027\uff0c\u800c\u4e2a\u6027\u5316\u6295\u8d44\u89e3\u51b3\u65b9\u6848\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\u3002", "method": "\u91c7\u7528\u8fdb\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u8d28\u91cf-\u591a\u6837\u6027\u4f18\u5316\u548c\u5047\u8bbe\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u7279\u5f81\u6620\u5c04\uff08\u7b56\u7565\u7c7b\u578b\u3001\u98ce\u9669\u7279\u5f81\u3001\u6362\u624b\u7387\u3001\u6536\u76ca\u7279\u6027\u7b49\uff09\u7ef4\u62a4\u591a\u6837\u5316\u6709\u6548\u7b56\u7565\u96c6\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u663e\u793aQuantEvolve\u4f18\u4e8e\u4f20\u7edf\u57fa\u51c6\u65b9\u6cd5\uff0c\u80fd\u591f\u4ea7\u751f\u9002\u5e94\u5e02\u573a\u673a\u5236\u53d8\u5316\u548c\u4e2a\u6027\u5316\u6295\u8d44\u9700\u6c42\u7684\u591a\u6837\u5316\u3001\u590d\u6742\u7b56\u7565\u3002", "conclusion": "QuantEvolve\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u91cf\u5316\u7b56\u7565\u5f00\u53d1\u7684\u6311\u6218\uff0c\u53d1\u5e03\u4e86\u8fdb\u5316\u7b56\u7565\u6570\u636e\u96c6\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2510.18619", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18619", "abs": "https://arxiv.org/abs/2510.18619", "authors": ["Wei Cai", "Jian Zhao", "Yuchen Yuan", "Tianle Zhang", "Ming Zhu", "Haichuan Tang", "Chi Zhang", "Xuelong Li"], "title": "VAR: Visual Attention Reasoning via Structured Search and Backtracking", "comment": null, "summary": "Multimodal Large Language Models (MLLMs), despite their advances, are\nhindered by their high hallucination tendency and heavy reliance on brittle,\nlinear reasoning processes, leading to failures in complex tasks. To address\nthese limitations, we introduce Visual Attention Reasoning (VAR), a novel\nframework that recasts grounded reasoning as a structured search over a\nreasoning trajectory space. VAR decomposes the reasoning process into two key\nstages: traceable evidence grounding and search-based chain-of-thought (CoT)\ngeneration, which incorporates a backtracking mechanism for self-correction.\nThe search is guided by a multi-faceted reward function with semantic and\ngeometric self-verification components, which penalize outputs that are not\nfaithfully grounded in the visual input. We provide a theoretical analysis for\nour search strategy, validating its capability to find the correct solution\nwith high probability. Experimental results show that our 7B model, VAR-7B,\nsets a new state-of-the-art on a comprehensive suite of hallucination and\nsafety benchmarks, significantly outperforming existing open-source models and\ndemonstrating competitive performance against leading proprietary systems.", "AI": {"tldr": "\u63d0\u51faVAR\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u641c\u7d22\u548c\u56de\u6eaf\u673a\u5236\u89e3\u51b3MLLM\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u5e7b\u89c9\u503e\u5411\u548c\u8106\u5f31\u7684\u7ebf\u6027\u63a8\u7406\u95ee\u9898\uff0c\u63d0\u5347\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u73b0", "method": "\u5c06\u63a8\u7406\u91cd\u6784\u4e3a\u7ed3\u6784\u5316\u641c\u7d22\u8fc7\u7a0b\uff0c\u5305\u542b\u53ef\u8ffd\u6eaf\u7684\u8bc1\u636e\u57fa\u7840\u548c\u57fa\u4e8e\u641c\u7d22\u7684\u601d\u7ef4\u94fe\u751f\u6210\uff0c\u91c7\u7528\u591a\u7ef4\u5ea6\u5956\u52b1\u51fd\u6570\u8fdb\u884c\u8bed\u4e49\u548c\u51e0\u4f55\u81ea\u9a8c\u8bc1", "result": "VAR-7B\u6a21\u578b\u5728\u5e7b\u89c9\u548c\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u521b\u4e0b\u65b0\u7eaa\u5f55\uff0c\u663e\u8457\u8d85\u8d8a\u5f00\u6e90\u6a21\u578b\uff0c\u4e0e\u9886\u5148\u4e13\u6709\u7cfb\u7edf\u6027\u80fd\u76f8\u5f53", "conclusion": "VAR\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u641c\u7d22\u548c\u81ea\u9a8c\u8bc1\u673a\u5236\u6709\u6548\u51cf\u5c11\u5e7b\u89c9\uff0c\u4e3aMLLM\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u63a8\u7406\u80fd\u529b"}}
{"id": "2510.18628", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18628", "abs": "https://arxiv.org/abs/2510.18628", "authors": ["Gilles Audemard", "Sylvie Coste-Marquis", "Pierre Marquis", "Mehdi Sabiri", "Nicolas Szczepanski"], "title": "Leveraging Association Rules for Better Predictions and Better Explanations", "comment": "24 pages", "summary": "We present a new approach to classification that combines data and knowledge.\nIn this approach, data mining is used to derive association rules (possibly\nwith negations) from data. Those rules are leveraged to increase the predictive\nperformance of tree-based models (decision trees and random forests) used for a\nclassification task. They are also used to improve the corresponding\nexplanation task through the generation of abductive explanations that are more\ngeneral than those derivable without taking such rules into account.\nExperiments show that for the two tree-based models under consideration,\nbenefits can be offered by the approach in terms of predictive performance and\nin terms of explanation sizes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6570\u636e\u548c\u77e5\u8bc6\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u6316\u6398\u83b7\u53d6\u5173\u8054\u89c4\u5219\u6765\u63d0\u5347\u6811\u57fa\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u6539\u5584\u89e3\u91ca\u4efb\u52a1\u3002", "motivation": "\u4f20\u7edf\u5206\u7c7b\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u5229\u7528\u6570\u636e\u4e2d\u7684\u77e5\u8bc6\uff0c\u9700\u8981\u7ed3\u5408\u6570\u636e\u6316\u6398\u5f97\u5230\u7684\u5173\u8054\u89c4\u5219\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u89e3\u91ca\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u6570\u636e\u6316\u6398\u4ece\u6570\u636e\u4e2d\u63a8\u5bfc\u5173\u8054\u89c4\u5219\uff08\u53ef\u80fd\u5305\u542b\u5426\u5b9a\uff09\uff0c\u5c06\u8fd9\u4e9b\u89c4\u5219\u878d\u5165\u51b3\u7b56\u6811\u548c\u968f\u673a\u68ee\u6797\u7b49\u6811\u57fa\u6a21\u578b\uff0c\u7528\u4e8e\u5206\u7c7b\u4efb\u52a1\u548c\u751f\u6210\u66f4\u4e00\u822c\u7684\u6eaf\u56e0\u89e3\u91ca\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u63d0\u9ad8\u6811\u57fa\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u751f\u6210\u66f4\u7b80\u6d01\u7684\u89e3\u91ca\u3002", "conclusion": "\u7ed3\u5408\u6570\u636e\u6316\u6398\u5f97\u5230\u7684\u5173\u8054\u89c4\u5219\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u6811\u57fa\u5206\u7c7b\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\u548c\u89e3\u91ca\u8d28\u91cf\u3002"}}
{"id": "2510.18631", "categories": ["cs.AI", "cs.LO", "03B60"], "pdf": "https://arxiv.org/pdf/2510.18631", "abs": "https://arxiv.org/abs/2510.18631", "authors": ["Carlo Proietti", "Antonio Yuste-Ginel"], "title": "Comparative Expressivity for Structured Argumentation Frameworks with Uncertain Rules and Premises", "comment": null, "summary": "Modelling qualitative uncertainty in formal argumentation is essential both\nfor practical applications and theoretical understanding. Yet, most of the\nexisting works focus on \\textit{abstract} models for arguing with uncertainty.\nFollowing a recent trend in the literature, we tackle the open question of\nstudying plausible instantiations of these abstract models. To do so, we ground\nthe uncertainty of arguments in their components, structured within rules and\npremises. Our main technical contributions are: i) the introduction of a notion\nof expressivity that can handle abstract and structured formalisms, and ii) the\npresentation of both negative and positive expressivity results, comparing the\nexpressivity of abstract and structured models of argumentation with\nuncertainty. These results affect incomplete abstract argumentation frameworks,\nand their extension with dependencies, on the abstract side, and ASPIC+, on the\nstructured side.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5f62\u5f0f\u8bba\u8bc1\u4e2d\u5b9a\u6027\u4e0d\u786e\u5b9a\u6027\u7684\u5efa\u6a21\uff0c\u6bd4\u8f83\u4e86\u62bd\u8c61\u548c\u7ed3\u6784\u5316\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u8868\u8fbe\u80fd\u529b\u6982\u5ff5\uff0c\u5e76\u7ed9\u51fa\u4e86\u8d1f\u9762\u548c\u6b63\u9762\u7684\u8868\u8fbe\u80fd\u529b\u7ed3\u679c\u3002", "motivation": "\u5728\u5f62\u5f0f\u8bba\u8bc1\u4e2d\u5efa\u6a21\u5b9a\u6027\u4e0d\u786e\u5b9a\u6027\u5bf9\u4e8e\u5b9e\u9645\u5e94\u7528\u548c\u7406\u8bba\u7406\u89e3\u90fd\u5f88\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u62bd\u8c61\u6a21\u578b\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u8fd9\u4e9b\u62bd\u8c61\u6a21\u578b\u7684\u5408\u7406\u5b9e\u4f8b\u5316\u3002", "method": "\u5c06\u8bba\u8bc1\u7684\u4e0d\u786e\u5b9a\u6027\u57fa\u4e8e\u5176\u7ec4\u6210\u90e8\u5206\uff08\u89c4\u5219\u548c\u524d\u63d0\uff09\uff0c\u5f15\u5165\u5904\u7406\u62bd\u8c61\u548c\u7ed3\u6784\u5316\u5f62\u5f0f\u4e3b\u4e49\u7684\u8868\u8fbe\u80fd\u529b\u6982\u5ff5\uff0c\u6bd4\u8f83\u62bd\u8c61\u548c\u7ed3\u6784\u5316\u8bba\u8bc1\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u3002", "result": "\u63d0\u51fa\u4e86\u8d1f\u9762\u548c\u6b63\u9762\u7684\u8868\u8fbe\u80fd\u529b\u7ed3\u679c\uff0c\u5f71\u54cd\u4e86\u4e0d\u5b8c\u6574\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\u53ca\u5176\u4f9d\u8d56\u6269\u5c55\uff08\u62bd\u8c61\u4fa7\uff09\u548cASPIC+\uff08\u7ed3\u6784\u5316\u4fa7\uff09\u3002", "conclusion": "\u901a\u8fc7\u5c06\u8bba\u8bc1\u4e0d\u786e\u5b9a\u6027\u57fa\u4e8e\u5176\u7ec4\u6210\u90e8\u5206\uff0c\u4e3a\u62bd\u8c61\u6a21\u578b\u63d0\u4f9b\u4e86\u5408\u7406\u7684\u5b9e\u4f8b\u5316\uff0c\u5e76\u5efa\u7acb\u4e86\u62bd\u8c61\u548c\u7ed3\u6784\u5316\u6a21\u578b\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u7684\u6bd4\u8f83\u6846\u67b6\u3002"}}
{"id": "2510.18633", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18633", "abs": "https://arxiv.org/abs/2510.18633", "authors": ["Roxana Petcu", "Kenton Murray", "Daniel Khashabi", "Evangelos Kanoulas", "Maarten de Rijke", "Dawn Lawrie", "Kevin Duh"], "title": "Query Decomposition for RAG: Balancing Exploration-Exploitation", "comment": null, "summary": "Retrieval-augmented generation (RAG) systems address complex user requests by\ndecomposing them into subqueries, retrieving potentially relevant documents for\neach, and then aggregating them to generate an answer. Efficiently selecting\ninformative documents requires balancing a key trade-off: (i) retrieving\nbroadly enough to capture all the relevant material, and (ii) limiting\nretrieval to avoid excessive noise and computational cost. We formulate query\ndecomposition and document retrieval in an exploitation-exploration setting,\nwhere retrieving one document at a time builds a belief about the utility of a\ngiven sub-query and informs the decision to continue exploiting or exploring an\nalternative. We experiment with a variety of bandit learning methods and\ndemonstrate their effectiveness in dynamically selecting the most informative\nsub-queries. Our main finding is that estimating document relevance using rank\ninformation and human judgments yields a 35% gain in document-level precision,\n15% increase in {\\alpha}-nDCG, and better performance on the downstream task of\nlong-form generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u4fe1\u606f\u6700\u4e30\u5bcc\u7684\u5b50\u67e5\u8be2\u6765\u5e73\u8861\u68c0\u7d22\u7684\u5e7f\u5ea6\u548c\u6548\u7387\u3002", "motivation": "\u89e3\u51b3RAG\u7cfb\u7edf\u4e2d\u5728\u590d\u6742\u7528\u6237\u8bf7\u6c42\u5206\u89e3\u65f6\u9762\u4e34\u7684\u5173\u952e\u6743\u8861\uff1a\u65e2\u8981\u5145\u5206\u68c0\u7d22\u76f8\u5173\u6587\u6863\uff0c\u53c8\u8981\u907f\u514d\u8fc7\u591a\u566a\u58f0\u548c\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u5c06\u67e5\u8be2\u5206\u89e3\u548c\u6587\u6863\u68c0\u7d22\u5efa\u6a21\u4e3a\u5229\u7528-\u63a2\u7d22\u95ee\u9898\uff0c\u4f7f\u7528\u5404\u79cd\u8001\u864e\u673a\u5b66\u4e60\u65b9\u6cd5\u52a8\u6001\u9009\u62e9\u6700\u4fe1\u606f\u4e30\u5bcc\u7684\u5b50\u67e5\u8be2\uff0c\u5229\u7528\u6392\u540d\u4fe1\u606f\u548c\u4eba\u5de5\u5224\u65ad\u4f30\u8ba1\u6587\u6863\u76f8\u5173\u6027\u3002", "result": "\u4f7f\u7528\u6392\u540d\u4fe1\u606f\u548c\u4eba\u5de5\u5224\u65ad\u4f30\u8ba1\u6587\u6863\u76f8\u5173\u6027\uff0c\u5b9e\u73b0\u4e86\u6587\u6863\u7ea7\u7cbe\u5ea635%\u7684\u63d0\u5347\uff0c\u03b1-nDCG\u6307\u680715%\u7684\u589e\u957f\uff0c\u5e76\u5728\u957f\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u57fa\u4e8e\u8001\u864e\u673a\u5b66\u4e60\u7684\u52a8\u6001\u5b50\u67e5\u8be2\u9009\u62e9\u65b9\u6cd5\u80fd\u6709\u6548\u5e73\u8861\u68c0\u7d22\u7684\u5e7f\u5ea6\u548c\u6548\u7387\uff0c\u663e\u8457\u63d0\u5347RAG\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2510.18659", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18659", "abs": "https://arxiv.org/abs/2510.18659", "authors": ["Dong Yun", "Marco Schouten", "Dim Papadopoulos"], "title": "Sherlock Your Queries: Learning to Ask the Right Questions for Dialogue-Based Retrieval", "comment": null, "summary": "User queries in information retrieval are often ambiguous, making it\nchallenging for systems to identify a user's target from a single query. While\nrecent dialogue-based interactive retrieval systems can clarify user intent,\nthey are inefficient as they often lack an explicit strategy to ask the most\ninformative questions. To address this limitation, we propose SherlockLLM, a\ndialogue-driven retrieval framework that learns an optimal questioning strategy\nvia Reinforcement Learning (RL) and avoids the need for large-scale annotated\ndialogue data. In our framework, an agent is trained to generate a sequence of\nbinary questions to efficiently narrow down the search space. To validate our\napproach, we introduce a benchmark with both structured and unstructured tasks.\nExperimental results show that SherlockLLM is a robust and efficient solution.\nOn the structured tasks, its performance matches strong baselines and\napproaches the theoretical optimal defined by binary search. On the challenging\nunstructured task, our agent significantly outperforms these baselines,\nshowcasing its ability to learn a highly effective information-seeking dialogue\npolicy.", "AI": {"tldr": "SherlockLLM\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5bf9\u8bdd\u9a71\u52a8\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u4e8c\u8fdb\u5236\u95ee\u9898\u5e8f\u5217\u6765\u9ad8\u6548\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u89e3\u51b3\u7528\u6237\u67e5\u8be2\u6a21\u7cca\u6027\u95ee\u9898\u3002", "motivation": "\u4fe1\u606f\u68c0\u7d22\u4e2d\u7528\u6237\u67e5\u8be2\u901a\u5e38\u5177\u6709\u6a21\u7cca\u6027\uff0c\u73b0\u6709\u5bf9\u8bdd\u5f0f\u68c0\u7d22\u7cfb\u7edf\u7f3a\u4e4f\u660e\u786e\u7684\u63d0\u95ee\u7b56\u7565\u6765\u9ad8\u6548\u6f84\u6e05\u7528\u6237\u610f\u56fe\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4ee3\u7406\u751f\u6210\u4e8c\u8fdb\u5236\u95ee\u9898\u5e8f\u5217\uff0c\u65e0\u9700\u5927\u89c4\u6a21\u6807\u6ce8\u5bf9\u8bdd\u6570\u636e\uff0c\u80fd\u591f\u5b66\u4e60\u6700\u4f18\u63d0\u95ee\u7b56\u7565\u3002", "result": "\u5728\u7ed3\u6784\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0e\u5f3a\u57fa\u7ebf\u76f8\u5f53\uff0c\u63a5\u8fd1\u4e8c\u5206\u641c\u7d22\u7684\u7406\u8bba\u6700\u4f18\uff1b\u5728\u975e\u7ed3\u6784\u5316\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "SherlockLLM\u662f\u4e00\u4e2a\u9c81\u68d2\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5b66\u4e60\u9ad8\u5ea6\u6709\u6548\u7684\u4fe1\u606f\u5bfb\u6c42\u5bf9\u8bdd\u7b56\u7565\u3002"}}
{"id": "2510.18751", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.18751", "abs": "https://arxiv.org/abs/2510.18751", "authors": ["Patterson Hsieh", "Jerry Yeh", "Mao-Chi He", "Wen-Han Hsieh", "Elvis Hsieh"], "title": "Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation", "comment": null, "summary": "Climate change is intensifying the occurrence of harmful algal bloom (HAB),\nparticularly cyanobacteria, which threaten aquatic ecosystems and human health\nthrough oxygen depletion, toxin release, and disruption of marine biodiversity.\nTraditional monitoring approaches, such as manual water sampling, remain\nlabor-intensive and limited in spatial and temporal coverage. Recent advances\nin vision-language models (VLMs) for remote sensing have shown potential for\nscalable AI-driven solutions, yet challenges remain in reasoning over imagery\nand quantifying bloom severity. In this work, we introduce ALGae Observation\nand Segmentation (ALGOS), a segmentation-and-reasoning system for HAB\nmonitoring that combines remote sensing image understanding with severity\nestimation. Our approach integrates GeoSAM-assisted human evaluation for\nhigh-quality segmentation mask curation and fine-tunes vision language model on\nseverity prediction using the Cyanobacteria Aggregated Manual Labels (CAML)\nfrom NASA. Experiments demonstrate that ALGOS achieves robust performance on\nboth segmentation and severity-level estimation, paving the way toward\npractical and automated cyanobacterial monitoring systems.", "AI": {"tldr": "ALGOS\u7cfb\u7edf\u7ed3\u5408\u9065\u611f\u56fe\u50cf\u7406\u89e3\u548c\u4e25\u91cd\u7a0b\u5ea6\u4f30\u8ba1\uff0c\u7528\u4e8e\u6709\u5bb3\u85fb\u534e\u76d1\u6d4b\uff0c\u901a\u8fc7GeoSAM\u8f85\u52a9\u4eba\u5de5\u8bc4\u4f30\u548c\u5fae\u8c03\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u5206\u5272\u548c\u4e25\u91cd\u7a0b\u5ea6\u4f30\u8ba1\u65b9\u9762\u8868\u73b0\u7a33\u5065\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u52a0\u5267\u4e86\u6709\u5bb3\u85fb\u534e\u7684\u53d1\u751f\uff0c\u4f20\u7edf\u76d1\u6d4b\u65b9\u6cd5\u52b3\u52a8\u5bc6\u96c6\u4e14\u8986\u76d6\u8303\u56f4\u6709\u9650\uff0c\u9700\u8981\u53ef\u6269\u5c55\u7684AI\u9a71\u52a8\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u96c6\u6210GeoSAM\u8f85\u52a9\u4eba\u5de5\u8bc4\u4f30\u8fdb\u884c\u9ad8\u8d28\u91cf\u5206\u5272\u63a9\u7801\u6574\u7406\uff0c\u5e76\u5728NASA\u7684\u84dd\u85fb\u805a\u96c6\u624b\u52a8\u6807\u7b7e\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e25\u91cd\u7a0b\u5ea6\u9884\u6d4b\u3002", "result": "ALGOS\u5728\u5206\u5272\u548c\u4e25\u91cd\u7a0b\u5ea6\u7ea7\u522b\u4f30\u8ba1\u65b9\u9762\u90fd\u5b9e\u73b0\u4e86\u7a33\u5065\u6027\u80fd\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u5b9e\u7528\u548c\u81ea\u52a8\u5316\u7684\u84dd\u85fb\u76d1\u6d4b\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.18803", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18803", "abs": "https://arxiv.org/abs/2510.18803", "authors": ["Shirin Tavakoli Kafiabad", "Andrea Schiffauerova", "Ashkan Ebadi"], "title": "Decoding Funded Research: Comparative Analysis of Topic Models and Uncovering the Effect of Gender and Geographic Location", "comment": "35 pages", "summary": "Optimizing national scientific investment requires a clear understanding of\nevolving research trends and the demographic and geographical forces shaping\nthem, particularly in light of commitments to equity, diversity, and inclusion.\nThis study addresses this need by analyzing 18 years (2005-2022) of research\nproposals funded by the Natural Sciences and Engineering Research Council of\nCanada (NSERC). We conducted a comprehensive comparative evaluation of three\ntopic modelling approaches: Latent Dirichlet Allocation (LDA), Structural Topic\nModelling (STM), and BERTopic. We also introduced a novel algorithm, named\nCOFFEE, designed to enable robust covariate effect estimation for BERTopic.\nThis advancement addresses a significant gap, as BERTopic lacks a native\nfunction for covariate analysis, unlike the probabilistic STM. Our findings\nhighlight that while all models effectively delineate core scientific domains,\nBERTopic outperformed by consistently identifying more granular, coherent, and\nemergent themes, such as the rapid expansion of artificial intelligence.\nAdditionally, the covariate analysis, powered by COFFEE, confirmed distinct\nprovincial research specializations and revealed consistent gender-based\nthematic patterns across various scientific disciplines. These insights offer a\nrobust empirical foundation for funding organizations to formulate more\nequitable and impactful funding strategies, thereby enhancing the effectiveness\nof the scientific ecosystem.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6bd4\u8f83LDA\u3001STM\u548cBERTopic\u4e09\u79cd\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\uff0c\u5206\u6790\u52a0\u62ff\u5927NSERC 18\u5e74\u7684\u7814\u7a76\u63d0\u6848\uff0c\u53d1\u73b0BERTopic\u5728\u8bc6\u522b\u7ec6\u7c92\u5ea6\u4e3b\u9898\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u5e76\u5f00\u53d1\u4e86COFFEE\u7b97\u6cd5\u89e3\u51b3BERTopic\u7684\u534f\u53d8\u91cf\u5206\u6790\u95ee\u9898\u3002", "motivation": "\u4f18\u5316\u56fd\u5bb6\u79d1\u5b66\u6295\u8d44\u9700\u8981\u4e86\u89e3\u7814\u7a76\u8d8b\u52bf\u6f14\u53d8\u53ca\u4eba\u53e3\u5730\u7406\u56e0\u7d20\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u5173\u6ce8\u516c\u5e73\u3001\u591a\u6837\u6027\u548c\u5305\u5bb9\u6027\u7684\u80cc\u666f\u4e0b\u3002", "method": "\u5206\u6790NSERC 2005-2022\u5e74\u7814\u7a76\u63d0\u6848\uff0c\u6bd4\u8f83LDA\u3001STM\u548cBERTopic\u4e09\u79cd\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1COFFEE\u7b97\u6cd5\u7528\u4e8eBERTopic\u7684\u534f\u53d8\u91cf\u6548\u5e94\u4f30\u8ba1\u3002", "result": "\u6240\u6709\u6a21\u578b\u90fd\u80fd\u6709\u6548\u8bc6\u522b\u6838\u5fc3\u79d1\u5b66\u9886\u57df\uff0c\u4f46BERTopic\u5728\u8bc6\u522b\u7ec6\u7c92\u5ea6\u3001\u8fde\u8d2f\u548c\u65b0\u5174\u4e3b\u9898\uff08\u5982\u4eba\u5de5\u667a\u80fd\uff09\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff1b\u534f\u53d8\u91cf\u5206\u6790\u63ed\u793a\u4e86\u7701\u7ea7\u7814\u7a76\u4e13\u4e1a\u5316\u548c\u57fa\u4e8e\u6027\u522b\u7684\u4e3b\u9898\u6a21\u5f0f\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u8d44\u52a9\u673a\u6784\u5236\u5b9a\u66f4\u516c\u5e73\u6709\u6548\u7684\u8d44\u52a9\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u79d1\u5b66\u751f\u6001\u7cfb\u7edf\u7684\u6548\u7387\u3002"}}
