<div id=toc></div>

# Table of Contents

- [cs.CY](#cs.CY) [Total: 3]
- [econ.TH](#econ.TH) [Total: 4]
- [cs.SI](#cs.SI) [Total: 3]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [cs.AI](#cs.AI) [Total: 45]
- [eess.SY](#eess.SY) [Total: 14]
- [cs.RO](#cs.RO) [Total: 29]
- [econ.EM](#econ.EM) [Total: 3]
- [econ.GN](#econ.GN) [Total: 5]
- [stat.AP](#stat.AP) [Total: 2]
- [cs.ET](#cs.ET) [Total: 1]


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [1] [Systems for Scaling Accessibility Efforts in Large Computing Courses](https://arxiv.org/abs/2510.25964)
*Ritesh Kanchi,Miya Natsuhara,Matt X. Wang*

Main category: cs.CY

TL;DR: 本文分享了在大型编程课程中扩展无障碍访问的经验，通过技术系统（如重新设计课程内容、提供无障碍视图、自动化测试）和人员系统（如助教培训、建立无障碍规范）来主动解决无障碍问题。


<details>
  <summary>Details</summary>
Motivation: 大型计算课程面临独特的无障碍挑战，需要为残疾学生提供可访问的课程内容，特别是在有3500多名学生和100名助教的大规模课程中。

Method: 采用两种方法：技术系统（重新设计课程内容为网页优先、提供无障碍视图、编写自动化测试）和人员系统（为助教提供无障碍培训、建立课程范围的无障碍规范、将无障碍主题融入核心课程）。

Result: 初步定性反馈显示，教职员工和学生对无障碍工作和无障碍技术的参与度有所提高。

Conclusion: 本文讨论了工作的局限性和经验教训，为开发类似审计、修复、技术或人员系统的人提供了建议。

Abstract: It is critically important to make computing courses accessible for disabled
students. This is particularly challenging in large computing courses, which
face unique challenges due to the sheer scale of course content and staff. In
this experience report, we share our attempts to scale accessibility efforts
for a large university-level introductory programming course sequence, with
over 3500 enrolled students and 100 teaching assistants (TAs) per year. First,
we introduce our approach to auditing and remediating course materials by
systematically identifying and resolving accessibility issues. However,
remediating content post-hoc is purely reactive and scales poorly. We then
discuss two approaches to systems that enable proactive accessibility work. We
developed technical systems to manage remediation complexity at scale:
redesigning other course content to be web-first and accessible by default,
providing alternate accessible views for existing course content, and writing
automated tests to receive instant feedback on a subset of accessibility
issues. Separately, we established human systems to empower both course staff
and students in accessibility best practices: developing and running various
TA-targeted accessibility trainings, establishing course-wide accessibility
norms, and integrating accessibility topics into core course curriculum.
Preliminary qualitative feedback from both staff and students shows increased
engagement in accessibility work and accessible technologies. We close by
discussing limitations and lessons learned from our work, with advice for
others developing similar auditing, remediation, technical, or human systems.

</details>


### [2] [The Quest for Reliable Metrics of Responsible AI](https://arxiv.org/abs/2510.26007)
*Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Christina Lioma*

Main category: cs.CY

TL;DR: 本文探讨了负责任AI评估指标的稳健性和可靠性问题，提出了开发可靠指标的非穷尽性指南


<details>
  <summary>Details</summary>
Motivation: AI发展应遵循负责任AI原则，但当前对评估指标本身的稳健性和可靠性研究较少，需要建立更可靠的评估体系

Method: 通过反思先前关于推荐系统公平性指标稳健性的研究，总结关键经验教训

Result: 制定了一套适用于包括科学AI在内的广泛AI应用的负责任AI可靠指标开发指南

Conclusion: 需要关注评估指标本身的稳健性，提出的指南有助于开发更可靠的负责任AI评估体系

Abstract: The development of Artificial Intelligence (AI), including AI in Science
(AIS), should be done following the principles of responsible AI. Progress in
responsible AI is often quantified through evaluation metrics, yet there has
been less work on assessing the robustness and reliability of the metrics
themselves. We reflect on prior work that examines the robustness of fairness
metrics for recommender systems as a type of AI application and summarise their
key takeaways into a set of non-exhaustive guidelines for developing reliable
metrics of responsible AI. Our guidelines apply to a broad spectrum of AI
applications, including AIS.

</details>


### [3] [Exploring Dissatisfaction in Bus Route Reduction through LLM-Calibrated Agent-Based Modeling](https://arxiv.org/abs/2510.26163)
*Qiumeng Li,Xinxi Yang,Suhong Zhou*

Main category: cs.CY

TL;DR: 使用基于智能体的建模和大型语言模型校准，研究发现公交网络结构配置对系统稳定性的影响大于容量或运营因素，连续削减公交线路会经历稳定、过渡和临界三个阶段，一旦跨越阈值，即使小幅削减也会导致客流显著流失。


<details>
  <summary>Details</summary>
Motivation: 随着新兴出行方式的发展，许多城市面临公交乘客量下降、维持利用率低线路的财政压力增加以及资源配置效率低下的问题，需要研究公交线路削减对乘客不满和网络韧性的影响。

Method: 采用基于智能体的建模方法，通过大型语言模型使用少样本学习进行校准，利用北京怀柔区的IC卡数据估计乘客对出行时间、等待、换乘和拥挤的敏感度参数。

Result: 高连通性线路的取消导致总不满度呈指数级增长，特别是残疾人和老年人群体；不满度演化呈现稳定、过渡和临界三个明显阶段；连续公交线路削减情景存在三阶段阈值。

Conclusion: 用户对服务削减的反应是非线性的，强调维持结构性关键线路和为弱势群体提供稳定服务对于公平和有韧性的交通规划的重要性。

Abstract: As emerging mobility modes continue to expand, many cities face declining bus
ridership, increasing fiscal pressure to sustain underutilized routes, and
growing inefficiencies in resource allocation. This study employs an
agent-based modelling (ABM) approach calibrated through a large language model
(LLM) using few-shot learning to examine how progressive bus route cutbacks
affect passenger dissatisfaction across demographic groups and overall network
resilience. Using IC-card data from Beijing's Huairou District, the
LLM-calibrated ABM estimated passenger sensitivity parameters related to travel
time, waiting, transfers, and crowding. Results show that the structural
configuration of the bus network exerts a stronger influence on system
stability than capacity or operational factors. The elimination of
high-connectivity routes led to an exponential rise in total dissatisfaction,
particularly among passengers with disabilities and older adults. The evolution
of dissatisfaction exhibited three distinct phases - stable, transitional, and
critical. Through the analysis of each stage, this study found that the
continuous bus route reduction scenario exhibits three-stage thresholds. Once
these thresholds are crossed, even a small reduction in routes may lead to a
significant loss of passenger flow. Research highlights the nonlinear response
of user sentiment to service reductions and underscore the importance of
maintaining structural critical routes and providing stable services to
vulnerable groups for equitable and resilient transport planning.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [4] [Price Levels in Heterogeneous-Agent Models](https://arxiv.org/abs/2510.26065)
*Felix Höfer*

Main category: econ.TH

TL;DR: 该论文在具有异质代理人的Bewley-Huggett-Aiyagari框架中研究财政价格水平理论(FTPL)，重点分析存在多重稳态均衡的情况。


<details>
  <summary>Details</summary>
Motivation: 研究财政政策如何影响价格水平，特别是在存在异质性和不可保险收入冲击的经济体中，探索FTPL理论在更现实环境下的表现。

Method: 采用连续时间模型，将模型构建为平均场博弈，分析有资本和无资本情况下的稳态均衡存在性和多重性，并进行数学证明。

Result: 证明了存在两个均衡状态，政府在这些均衡中运行恒定的基本赤字，这反过来意味着存在多个价格水平。

Conclusion: 在具有异质代理人的经济中，财政价格水平理论支持多重均衡和多重价格水平的存在，这对理解财政政策与通胀的关系具有重要意义。

Abstract: We study a model of the Fiscal Theory of the Price Level (FTPL) in a
Bewley-Huggett-Aiyagari framework with heterogeneous agents. The model is set
in continuous time, and ex post heterogeneity arises due to idiosyncratic,
uninsurable income shocks. Such models have a natural interpretation as
mean-field games, introduced by Huang, Caines, and Malham\'e and by Lasry and
Lions. We highlight this connection and discuss the existence and multiplicity
of stationary equilibria in models with and without capital. Our focus is on
the mathematical analysis, and we prove the existence of two equilibria in
which the government runs constant primary deficits, which in turn implies the
existence of multiple price levels.

</details>


### [5] [TEE-BFT: Pricing the Security of Data Center Execution Assurance](https://arxiv.org/abs/2510.26091)
*Alex Shamis,Matt Stephenson,Linfeng Zhou*

Main category: econ.TH

TL;DR: 本文开发了一个成本-共谋委托代理模型来分析TEE在数据中心执行保证设计中的安全性，推导出威慑阈值和安全设计边界，表明合理的TEE参数可以保护约万亿美元的价值。


<details>
  <summary>Details</summary>
Motivation: 区块链在与外部系统通信时面临固有局限性，主要由于BFT 3f+1安全模型。TEE是有前景的缓解方案，允许单个可信代理安全地与外部系统交互。

Method: 开发成本-共谋委托代理模型，分析攻击盈利性的主要驱动因素：K-of-n协调阈值、独立检测风险q、异质成员制裁F_i、与保护价值成比例的短期窗口流量奖励(omega=β×V)。

Result: 推导出闭式威慑阈值和保守设计边界(V_safe)，在透明参数选择下使共谋无利可图。基于时间优势套利的校准表明，合理的TEE参数可以保护约万亿美元的价值。

Conclusion: 分析为TEE-BFT区块链架构的设计提供信息，该架构结合BFT共识、近无状态TEE、分布式密钥生成和链上证明，以在与外部系统交互时保持安全性。

Abstract: Blockchains face inherent limitations when communicating outside their own
ecosystem, largely due to the Byzantine Fault Tolerant (BFT) 3f+1 security
model. Trusted Execution Environments (TEEs) are a promising mitigation because
they allow a single trusted broker to interface securely with external systems.
  This paper develops a cost-of-collusion principal-agent model for
compromising a TEE in a Data Center Execution Assurance design. The model
isolates the main drivers of attack profitability: a K-of-n coordination
threshold, independent detection risk q, heterogeneous per-member sanctions
F_i, and a short-window flow prize (omega) proportional to the value secured
(beta times V).
  We derive closed-form deterrence thresholds and a conservative design bound
(V_safe) that make collusion unprofitable under transparent parameter choices.
Calibrations based on time-advantaged arbitrage indicate that plausible TEE
parameters can protect on the order of one trillion dollars in value. The
analysis informs the design of TEE-BFT, a blockchain architecture that combines
BFT consensus with near-stateless TEEs, distributed key generation, and
on-chain attestation to maintain security when interacting with external
systems.

</details>


### [6] [The Effect of Using Popular Mathematical Puzzles on The Mathematical Thinking of Syrian Schoolchildren](https://arxiv.org/abs/2510.26263)
*Duaa Abdullah,Jasem Hamoud*

Main category: econ.TH

TL;DR: 研究使用流行数学谜题对叙利亚六年级小学生数学思维能力的影响，通过实验组和对照组的对比测试评估数学谜题对学生解决问题能力和数学技能的影响。


<details>
  <summary>Details</summary>
Motivation: 研究叙利亚学校数学教育的问题和背景，探索通过流行数学谜题提升学生数学思维能力的可能性。

Method: 采用配对实验研究设计（前测后测对照组设计），从叙利亚Lady Mary学校的六年级学生中抽样，使用t检验进行统计分析。

Result: 通过统计分析评估了数学谜题对学生解决问题能力和数学技能的具体影响程度。

Conclusion: 流行数学谜题对提升学生的数学思维能力和问题解决能力具有积极影响。

Abstract: In this paper we provide a good overview of the problems and the background
of mathematics education in Syrian schools. We aimed to study the effect of
using popular mathematical puzzles on the mathematical thinking of
schoolchildren, by conducting a paired experimental study (pre-test and
post-test control group design) of the data we obtained through a sample taken
from students of sixth-grade primary school students in Syria the Lady Mary
School in Syria, in order to evaluate the extent of the impact of popular
mathematical puzzles on students' ability to solve problems and mathematical
skills, and then the skills were measured and the results were analyzed using a
t-test as a tool for statistical analysis.

</details>


### [7] [Robust Welfare under Imperfect Competition](https://arxiv.org/abs/2510.26387)
*Konstantin von Beringe,Mark Whitmeyer*

Main category: econ.TH

TL;DR: 该研究在供给行为仅部分已知的情况下进行福利分析，通过结合需求侧稳健方法和两个供给原语（可行转嫁区间和市场势力参数），为政策变化提供简单的福利边界。


<details>
  <summary>Details</summary>
Motivation: 在供给行为信息不完全的情况下，传统福利分析方法面临挑战。研究旨在开发一种能够在供给信息有限时进行稳健福利分析的方法。

Method: 将Kang和Vasserman(2025)的稳健需求方法与两个供给原语（可行转嫁区间和市场势力参数）相结合，应用于两个均衡快照，并通过会计恒等式简化供给侧对福利的贡献。

Result: 推导出由单一阈值"bang-bang"逆转嫁函数产生的边界，结合改进的需求侧表征，得到消费者剩余、生产者剩余、税收收入、总剩余和无谓损失的简单边界。

Conclusion: 该方法能够在供给信息有限的情况下提供稳健的福利分析边界，并扩展到从价税情况。

Abstract: We study welfare analysis for policy changes when supply behavior is only
partially known. We augment the robust-demand approach of Kang and Vasserman
(2025) with two supply primitives--intervals of feasible pass-through and
conduct (market-power) parameters--applied to two equilibrium snapshots. A
simple accounting identity distills the supply-side contribution to welfare to
a simple integral expression. From there, we deduce that the bounds are
produced by a single-threshold "bang-bang" inverse pass-through function. This,
plus a modification of Kang and Vasserman's (2025) demand-side
characterization, delivers simple bounds for consumer surplus, producer
surplus, tax revenue, total surplus, and deadweight loss. We also study an ad
valorem extension.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [8] [Flex-GAD : Flexible Graph Anomaly Detection](https://arxiv.org/abs/2510.25809)
*Apu Chakraborty,Anshul Kumar,Gagan Raj Gupta*

Main category: cs.SI

TL;DR: 提出Flex-GAD，一种无监督的图异常检测框架，通过社区感知GCN编码器和属性编码器融合结构信息，在多个真实图数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 在属性网络中检测异常节点对于识别欺诈、虚假信息等行为至关重要，现有方法在捕捉结构一致性方面存在不足。

Method: 使用社区感知GCN编码器建模社区内外信息，结合属性编码器，通过自注意力融合模块自适应整合不同表示。

Result: 在7个真实图数据集上平均AUC提升7.98%，训练速度比Anomaly DAE快102倍，比GAD-NR快3倍。

Conclusion: Flex-GAD在检测性能和效率方面均优于现有方法，具有很好的泛化能力。

Abstract: Detecting anomalous nodes in attributed networks, where each node is
associated with both structural connections and descriptive attributes, is
essential for identifying fraud, misinformation, and suspicious behavior in
domains such as social networks, academic citation graphs, and e-commerce
platforms. We propose Flex-GAD, a novel unsupervised framework for graph
anomaly detection at the node level. Flex-GAD integrates two encoders to
capture complementary aspects of graph data. The framework incorporates a novel
community-based GCN encoder to model intra-community and inter-community
information into node embeddings, thereby ensuring structural consistency,
along with a standard attribute encoder. These diverse representations are
fused using a self-attention-based representation fusion module, which enables
adaptive weighting and effective integration of the encoded information. This
fusion mechanism allows automatic emphasis of the most relevant node
representation across different encoders. We evaluate Flex-GAD on seven
real-world attributed graphs with varying sizes, node degrees, and attribute
homogeneity. Flex-GAD achieves an average AUC improvement of 7.98% over the
previously best-performing method, GAD-NR, demonstrating its effectiveness and
flexibility across diverse graph structures. Moreover, it significantly reduces
training time, running 102x faster per epoch than Anomaly DAE and 3x faster per
epoch than GAD-NR on average across seven benchmark datasets.

</details>


### [9] [Signed Graph Unlearning](https://arxiv.org/abs/2510.26092)
*Zhifei Luo,Lin Li,Xiaohui Tao,Kaize Shi*

Main category: cs.SI

TL;DR: 提出了SGU框架，专门用于符号网络的图遗忘，通过新的图遗忘分区范式和符号网络分区算法，在保持边符号信息的同时确保结构平衡，在模型性能和遗忘效率方面均达到最优效果。


<details>
  <summary>Details</summary>
Motivation: 现有图遗忘方法仅针对无符号网络设计，无法处理符号网络特有的结构特性，直接应用于符号网络会忽略边符号信息，导致子图结构不平衡，从而降低模型性能和遗忘效率。

Method: SGU框架包含新的图遗忘分区范式和符号网络分区算法，在分区过程中保持边符号信息并确保各分区结构平衡。

Result: 与基线方法相比，SGU在模型性能和遗忘效率方面均取得了最先进的结果。

Conclusion: SGU是针对符号网络的有效图遗忘框架，解决了现有方法在处理符号网络时的局限性，显著提升了模型性能和遗忘效率。

Abstract: The proliferation of signed networks in contemporary social media platforms
necessitates robust privacy-preserving mechanisms. Graph unlearning, which aims
to eliminate the influence of specific data points from trained models without
full retraining, becomes particularly critical in these scenarios where user
interactions are sensitive and dynamic. Existing graph unlearning methodologies
are exclusively designed for unsigned networks and fail to account for the
unique structural properties of signed graphs. Their naive application to
signed networks neglects edge sign information, leading to structural imbalance
across subgraphs and consequently degrading both model performance and
unlearning efficiency. This paper proposes SGU (Signed Graph Unlearning), a
graph unlearning framework specifically for signed networks. SGU incorporates a
new graph unlearning partition paradigm and a novel signed network partition
algorithm that preserve edge sign information during partitioning and ensure
structural balance across partitions. Compared with baselines, SGU achieves
state-of-the-art results in both model performance and unlearning efficiency.

</details>


### [10] [Simulating and Experimenting with Social Media Mobilization Using LLM Agents](https://arxiv.org/abs/2510.26494)
*Sadegh Shirani,Mohsen Bayati*

Main category: cs.SI

TL;DR: 开发了一个基于代理的模拟框架，整合真实人口统计数据、Twitter网络拓扑和异构LLM代理，研究政治动员信息对选民投票率的影响。


<details>
  <summary>Details</summary>
Motivation: 在线社交网络改变了政治动员信息的传播方式，需要研究大规模环境下的同伴影响机制。

Method: 使用基于代理的模拟框架，结合美国人口普查数据、真实Twitter网络结构和不同LLM变体（GPT-4.1系列），模拟代理在社交网络中的互动和投票行为。

Result: 模拟器重现了实地实验中的定性模式，包括社交信息处理下更强的动员效果和可测量的同伴溢出效应。

Conclusion: 该框架为政治动员研究提供了可控、可复现的环境，在高效度实地实验和灵活计算建模之间架起了桥梁。

Abstract: Online social networks have transformed the ways in which political
mobilization messages are disseminated, raising new questions about how peer
influence operates at scale. Building on the landmark 61-million-person
Facebook experiment \citep{bond201261}, we develop an agent-based simulation
framework that integrates real U.S. Census demographic distributions, authentic
Twitter network topology, and heterogeneous large language model (LLM) agents
to examine the effect of mobilization messages on voter turnout. Each simulated
agent is assigned demographic attributes, a personal political stance, and an
LLM variant (\texttt{GPT-4.1}, \texttt{GPT-4.1-Mini}, or \texttt{GPT-4.1-Nano})
reflecting its political sophistication. Agents interact over realistic social
network structures, receiving personalized feeds and dynamically updating their
engagement behaviors and voting intentions. Experimental conditions replicate
the informational and social mobilization treatments of the original Facebook
study. Across scenarios, the simulator reproduces qualitative patterns observed
in field experiments, including stronger mobilization effects under social
message treatments and measurable peer spillovers. Our framework provides a
controlled, reproducible environment for testing counterfactual designs and
sensitivity analyses in political mobilization research, offering a bridge
between high-validity field experiments and flexible computational
modeling.\footnote{Code and data available at
https://github.com/CausalMP/LLM-SocioPol}

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [11] [Budget Forecasting and Integrated Strategic Planning for Leaders](https://arxiv.org/abs/2510.26035)
*Matt Salehi*

Main category: q-fin.GN

TL;DR: 该研究探讨了先进预算技术和经济指标如何影响加州社区学院的资金水平和战略对齐。研究发现GDP增长和CPI与CCC资金水平呈强正相关，强调教育领导者需要将经济预测纳入预算规划。


<details>
  <summary>Details</summary>
Motivation: 尽管广泛实施了预算改革，但许多加州社区学院仍面临财务规划与机构使命对齐的挑战，特别是在支持DEI倡议方面。

Method: 采用定量相关设计，分析30年公开经济数据（失业率、GDP增长、CPI）与CCC资金趋势的关系。

Result: GDP增长和CPI与CCC资金水平呈强正相关，宏观经济指标在预算规划中具有预测价值。

Conclusion: 教育领导者需要将经济预测整合到预算规划过程中，以保障机构有效性并维持服务弱势学生群体的项目。

Abstract: This study explored how advanced budgeting techniques and economic indicators
influence funding levels and strategic alignment in California Community
Colleges (CCCs). Despite widespread implementation of budgeting reforms, many
CCCs continue to face challenges aligning financial planning with institutional
missions, particularly in supporting diversity, equity, and inclusion (DEI)
initiatives. The study used a quantitative correlational design, analyzing 30
years of publicly available economic data, including unemployment rates, GDP
growth, and CPI, in relation to CCC funding trends. Results revealed a strong
positive correlation between GDP growth and CCC funding levels, as well as
between CPI and funding levels, underscoring the predictive value of
macroeconomic indicators in budget planning. These findings emphasize the need
for educational leaders to integrate economic forecasting into budget planning
processes to safeguard institutional effectiveness and sustain programs serving
underrepresented student populations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [Towards Piece-by-Piece Explanations for Chess Positions with SHAP](https://arxiv.org/abs/2510.25775)
*Francesco Spinnato*

Main category: cs.AI

TL;DR: 将SHAP可解释AI技术应用于国际象棋分析，通过系统性地移除棋子来计算每个棋子对引擎评估的贡献度，提供可解释的棋局分析。


<details>
  <summary>Details</summary>
Motivation: 传统国际象棋引擎提供精确但不透明的评估分数，无法解释各个棋子或模式的具体贡献，需要开发可解释的分析方法。

Method: 将棋子视为特征，采用SHAP方法通过系统性地移除棋子来计算每个棋子的加性贡献，提供局部忠实且人类可理解的解释。

Result: 开发了一种能够将引擎评估归因于特定棋子的方法，为可视化、人类训练和引擎比较提供了新的可能性。

Conclusion: 该方法将经典象棋教学理念与现代可解释AI技术相结合，为可解释象棋AI研究开辟了新方向，并发布了相关代码和数据以促进未来研究。

Abstract: Contemporary chess engines offer precise yet opaque evaluations, typically
expressed as centipawn scores. While effective for decision-making, these
outputs obscure the underlying contributions of individual pieces or patterns.
In this paper, we explore adapting SHAP (SHapley Additive exPlanations) to the
domain of chess analysis, aiming to attribute a chess engines evaluation to
specific pieces on the board. By treating pieces as features and systematically
ablating them, we compute additive, per-piece contributions that explain the
engines output in a locally faithful and human-interpretable manner. This
method draws inspiration from classical chess pedagogy, where players assess
positions by mentally removing pieces, and grounds it in modern explainable AI
techniques. Our approach opens new possibilities for visualization, human
training, and engine comparison. We release accompanying code and data to
foster future research in interpretable chess AI.

</details>


### [13] [An Agentic Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0](https://arxiv.org/abs/2510.25813)
*Jorge Martinez-Gil,Mario Pichler,Nefeli Bountouni,Sotiris Koussouris,Marielena Márquez Barreiro,Sergio Gusmeroli*

Main category: cs.AI

TL;DR: 提出了一个用于工业5.0的新框架，简化了AI模型在各种工业环境中边缘设备上的部署，通过本地推理和实时处理降低延迟并避免外部数据传输。


<details>
  <summary>Details</summary>
Motivation: 工业5.0需要将AI模型高效部署到边缘设备上，但现有方案存在延迟高、数据传输复杂、集成困难等问题，需要简化部署流程并提高系统适应性。

Method: 采用基于代理的架构设计，单个代理（人类、算法或协作）负责明确定义的任务，支持模块化集成并保持低资源需求。

Result: 在食品工业真实场景中的初步评估表明，部署时间和系统适应性性能得到改善。

Conclusion: 该框架为工业5.0提供了一个灵活、高效的AI模型部署解决方案，支持本地推理和实时处理，提高了工业应用的适应性和部署效率。

Abstract: We present a novel framework for Industry 5.0 that simplifies the deployment
of AI models on edge devices in various industrial settings. The design reduces
latency and avoids external data transfer by enabling local inference and
real-time processing. Our implementation is agent-based, which means that
individual agents, whether human, algorithmic, or collaborative, are
responsible for well-defined tasks, enabling flexibility and simplifying
integration. Moreover, our framework supports modular integration and maintains
low resource requirements. Preliminary evaluations concerning the food industry
in real scenarios indicate improved deployment time and system adaptability
performance. The source code is publicly available at
https://github.com/AI-REDGIO-5-0/ci-component.

</details>


### [14] [Symbolically Scaffolded Play: Designing Role-Sensitive Prompts for Generative NPC Dialogue](https://arxiv.org/abs/2510.25820)
*Vanessa Figueiredo,David Elumeze*

Main category: cs.AI

TL;DR: 研究比较了高约束和低约束提示在基于GPT-4o的侦探游戏中的效果，发现约束程度对玩家体验无显著影响，并提出了符号化支架游戏框架。


<details>
  <summary>Details</summary>
Motivation: 探究约束提示是否能真正改善基于大语言模型的游戏角色对话体验，验证约束程度对玩家体验的实际影响。

Method: 通过用户研究比较高约束和低约束提示，然后设计混合JSON+RAG支架进行合成评估，使用LLM作为评判者。

Result: 发现支架效果具有角色依赖性：面试官NPC获得稳定性，而嫌疑人NPC失去即兴可信度；约束程度对玩家体验无可靠差异。

Conclusion: 推翻了约束越紧游戏体验越好的假设，提出了符号化支架游戏框架，使用模糊数值边界在需要时保持连贯性，在需要惊喜时保留即兴性。

Abstract: Large Language Models (LLMs) promise to transform interactive games by
enabling non-player characters (NPCs) to sustain unscripted dialogue. Yet it
remains unclear whether constrained prompts actually improve player experience.
We investigate this question through The Interview, a voice-based detective
game powered by GPT-4o. A within-subjects usability study ($N=10$) compared
high-constraint (HCP) and low-constraint (LCP) prompts, revealing no reliable
experiential differences beyond sensitivity to technical breakdowns. Guided by
these findings, we redesigned the HCP into a hybrid JSON+RAG scaffold and
conducted a synthetic evaluation with an LLM judge, positioned as an
early-stage complement to usability testing. Results uncovered a novel pattern:
scaffolding effects were role-dependent: the Interviewer (quest-giver NPC)
gained stability, while suspect NPCs lost improvisational believability. These
findings overturn the assumption that tighter constraints inherently enhance
play. Extending fuzzy-symbolic scaffolding, we introduce \textit{Symbolically
Scaffolded Play}, a framework in which symbolic structures are expressed as
fuzzy, numerical boundaries that stabilize coherence where needed while
preserving improvisation where surprise sustains engagement.

</details>


### [15] [Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters](https://arxiv.org/abs/2510.25860)
*Xingjian Zhang,Tianhong Gao,Suliang Jin,Tianhao Wang,Teng Ye,Eytan Adar,Qiaozhu Mei*

Main category: cs.AI

TL;DR: 提出了一种人机协作框架，通过拒绝采样方法从仅标签标注中推断思维轨迹，用于改进LLM评估器的性能。


<details>
  <summary>Details</summary>
Motivation: LLM作为评估器时，对于主观任务的可靠性有限，因为人类判断涉及超出标注标签的微妙推理，而思维轨迹难以收集和整理。

Method: 使用人机协作框架和拒绝采样方法从仅标签标注中重构思维轨迹，并将其应用于微调开源LLM评估器和为专有LLM评估器合成更清晰的标注指南。

Result: 在多个数据集上，该方法显著提高了LLM与人类的一致性，精炼的标注指南还增加了不同LLM模型之间的一致性。

Conclusion: LLM可以作为人类思维轨迹的实用代理，使仅标签语料库能够扩展为思维轨迹增强资源，从而提高LLM评估器的可靠性。

Abstract: Large language models (LLMs) are increasingly used as raters for evaluation
tasks. However, their reliability is often limited for subjective tasks, when
human judgments involve subtle reasoning beyond annotation labels. Thinking
traces, the reasoning behind a judgment, are highly informative but challenging
to collect and curate. We present a human-LLM collaborative framework to infer
thinking traces from label-only annotations. The proposed framework uses a
simple and effective rejection sampling method to reconstruct these traces at
scale. These inferred thinking traces are applied to two complementary tasks:
(1) fine-tuning open LLM raters; and (2) synthesizing clearer annotation
guidelines for proprietary LLM raters. Across multiple datasets, our methods
lead to significantly improved LLM-human agreement. Additionally, the refined
annotation guidelines increase agreement among different LLM models. These
results suggest that LLMs can serve as practical proxies for otherwise
unrevealed human thinking traces, enabling label-only corpora to be extended
into thinking-trace-augmented resources that enhance the reliability of LLM
raters.

</details>


### [16] [The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence](https://arxiv.org/abs/2510.25883)
*Christian Dittrich,Jennifer Flygare Kinne*

Main category: cs.AI

TL;DR: 论文提出了一个两级框架来解释为什么压缩过程会强制发现因果结构而非表面统计模式。信息论必要性(ITI)建立了系统必须通过预测压缩最小化认知熵，压缩效率原则(CEP)阐明了高效压缩如何通过异常积累动态选择生成性因果模型。


<details>
  <summary>Details</summary>
Motivation: 现有框架都强调压缩对智能的核心作用，但未能具体说明为什么这个过程会强制发现因果结构而不是表面统计模式。

Method: 引入两级框架：信息论必要性(ITI)和压缩效率原则(CEP)。ITI从进化角度解释生存压力如何导致信息处理需求，CEP从机制角度解释高效压缩如何选择因果模型。

Result: 该框架产生了可实证检验的预测：压缩效率与分布外泛化相关，异常积累率区分因果与相关模型，分层系统在不同抽象层显示效率提升，生物系统展示代谢成本与表示复杂性相关。

Conclusion: ITI和CEP为生物、人工和多尺度系统的趋同提供了统一解释，解决了智能的认知和功能维度，无需诉诸意识或主观经验的假设。

Abstract: Existing frameworks converge on the centrality of compression to intelligence
but leave underspecified why this process enforces the discovery of causal
structure rather than superficial statistical patterns. We introduce a
two-level framework to address this gap. The Information-Theoretic Imperative
(ITI) establishes that any system persisting in uncertain environments must
minimize epistemic entropy through predictive compression: this is the
evolutionary "why" linking survival pressure to information-processing demands.
The Compression Efficiency Principle (CEP) specifies how efficient compression
mechanically selects for generative, causal models through
exception-accumulation dynamics, making reality alignment a consequence rather
than a contingent achievement. Together, ITI and CEP define a causal chain:
from survival pressure to prediction necessity, compression requirement,
efficiency optimization, generative structure discovery, and ultimately reality
alignment. Each link follows from physical, information-theoretic, or
evolutionary constraints, implying that intelligence is the mechanically
necessary outcome of persistence in structured environments. This framework
yields empirically testable predictions: compression efficiency, measured as
approach to the rate-distortion frontier, correlates with out-of-distribution
generalization; exception-accumulation rates differentiate causal from
correlational models; hierarchical systems exhibit increasing efficiency across
abstraction layers; and biological systems demonstrate metabolic costs that
track representational complexity. ITI and CEP thereby provide a unified
account of convergence across biological, artificial, and multi-scale systems,
addressing the epistemic and functional dimensions of intelligence without
invoking assumptions about consciousness or subjective experience.

</details>


### [17] [Approximating Human Preferences Using a Multi-Judge Learned System](https://arxiv.org/abs/2510.25884)
*Eitán Sprejer,Fernando Avalos,Augusto Bernardi,Jose Pedro Brito de Azevedo Faustino,Jacob Haimes,Narmeen Fatimah Oozeer*

Main category: cs.AI

TL;DR: 提出一个基于角色的偏好建模框架，通过聚合多个基于评分标准的评判者输出来对齐LLM评判者与人类偏好，解决校准困难、评分标准敏感性、偏见和不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 对齐基于LLM的评判者与人类偏好是一个重大挑战，因为它们难以校准且经常受到评分标准敏感性、偏见和不稳定性的影响。克服这一挑战可以推进关键应用，如为RLHF创建可靠的奖励模型和构建有效的路由系统。

Method: 提出一个框架，通过聚合多个基于评分标准的评判者输出来建模多样化的基于角色的偏好。包括基于角色的方法大规模合成偏好标签，以及两种聚合器实现：广义加性模型(GAM)和多层感知器(MLP)。

Result: 研究了该方法相对于简单基线的性能，并通过人类和LLM评判者偏见的案例研究评估了其鲁棒性。

Conclusion: 该框架能够有效建模多样化的基于角色的偏好，为解决LLM评判者校准问题提供了可行方案。

Abstract: Aligning LLM-based judges with human preferences is a significant challenge,
as they are difficult to calibrate and often suffer from rubric sensitivity,
bias, and instability. Overcoming this challenge advances key applications,
such as creating reliable reward models for Reinforcement Learning from Human
Feedback (RLHF) and building effective routing systems that select the
best-suited model for a given user query. In this work, we propose a framework
for modeling diverse, persona-based preferences by learning to aggregate
outputs from multiple rubric-conditioned judges. We investigate the performance
of this approach against naive baselines and assess its robustness through case
studies on both human and LLM-judges biases. Our primary contributions include
a persona-based method for synthesizing preference labels at scale and two
distinct implementations of our aggregator: Generalized Additive Model (GAM)
and a Multi-Layer Perceptron (MLP).

</details>


### [18] [SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications](https://arxiv.org/abs/2510.25908)
*Emily Herron,Junqi Yin,Feiyi Wang*

Main category: cs.AI

TL;DR: SciTrust 2.0是一个评估科学应用中LLM可信度的框架，涵盖真实性、对抗鲁棒性、科学安全和科学伦理四个维度。评估显示通用行业模型在各方面优于科学专用模型，后者在逻辑和伦理推理方面存在显著缺陷。


<details>
  <summary>Details</summary>
Motivation: LLM在科学研究中展现出变革潜力，但在高风险环境中的部署引发了可信度担忧，需要系统评估框架来确保其安全性和伦理性。

Method: 开发了包含新颖开放式真实性基准和科学伦理基准的综合框架，通过验证的反思调优流程和专家验证构建，使用准确性、语义相似度和LLM评分等多种指标评估了7个主要LLM。

Result: 通用行业模型在各项可信度维度上均优于科学专用模型，GPT-o4-mini在真实性和对抗鲁棒性方面表现最佳。科学专用模型在逻辑和伦理推理能力上存在显著缺陷，在生物安全和化学武器等高危领域存在安全隐患。

Conclusion: 通过开源该框架，为开发更可信的AI系统提供了基础，并推动了科学背景下模型安全性和伦理研究的进展。

Abstract: Large language models (LLMs) have demonstrated transformative potential in
scientific research, yet their deployment in high-stakes contexts raises
significant trustworthiness concerns. Here, we introduce SciTrust 2.0, a
comprehensive framework for evaluating LLM trustworthiness in scientific
applications across four dimensions: truthfulness, adversarial robustness,
scientific safety, and scientific ethics. Our framework incorporates novel,
open-ended truthfulness benchmarks developed through a verified
reflection-tuning pipeline and expert validation, alongside a novel ethics
benchmark for scientific research contexts covering eight subcategories
including dual-use research and bias. We evaluated seven prominent LLMs,
including four science-specialized models and three general-purpose industry
models, using multiple evaluation metrics including accuracy, semantic
similarity measures, and LLM-based scoring. General-purpose industry models
overall outperformed science-specialized models across each trustworthiness
dimension, with GPT-o4-mini demonstrating superior performance in truthfulness
assessments and adversarial robustness. Science-specialized models showed
significant deficiencies in logical and ethical reasoning capabilities, along
with concerning vulnerabilities in safety evaluations, particularly in
high-risk domains such as biosecurity and chemical weapons. By open-sourcing
our framework, we provide a foundation for developing more trustworthy AI
systems and advancing research on model safety and ethics in scientific
contexts.

</details>


### [19] [FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization](https://arxiv.org/abs/2510.25914)
*Ngoc Phuoc An Vo,Manish Kesarwani,Ruchi Mahindru,Chandrasekhar Narayanaswami*

Main category: cs.AI

TL;DR: 本文提出使用自主AI代理来自动化FinOps流程，解决了云账单数据格式不统一的问题，并通过模拟真实行业流程验证了代理在IT基础设施和成本优化方面的有效性。


<details>
  <summary>Details</summary>
Motivation: FinOps从业者面临来自多个云提供商和内部系统的异构账单数据格式、分类和指标，这导致难以综合可操作的见解并做出及时决策。

Method: 构建了一个FinOps代理系统，模拟从多源数据检索到数据整合分析再到生成优化建议的端到端行业流程，使用多种开源和闭源语言模型进行评估。

Result: 评估结果显示，该代理能够像真正的FinOps从业者一样理解、规划和执行任务。

Conclusion: 自主、目标驱动的AI代理可以有效解决FinOps自动化中的异构数据挑战，实现IT基础设施和成本优化。

Abstract: FinOps (Finance + Operations) represents an operational framework and
cultural practice which maximizes cloud business value through collaborative
financial accountability across engineering, finance, and business teams.
FinOps practitioners face a fundamental challenge: billing data arrives in
heterogeneous formats, taxonomies, and metrics from multiple cloud providers
and internal systems which eventually lead to synthesizing actionable insights,
and making time-sensitive decisions. To address this challenge, we propose
leveraging autonomous, goal-driven AI agents for FinOps automation. In this
paper, we built a FinOps agent for a typical use-case for IT infrastructure and
cost optimization. We built a system simulating a realistic end-to-end industry
process starting with retrieving data from various sources to consolidating and
analyzing the data to generate recommendations for optimization. We defined a
set of metrics to evaluate our agent using several open-source and close-source
language models and it shows that the agent was able to understand, plan, and
execute tasks as well as an actual FinOps practitioner.

</details>


### [20] [Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy by Directed Exoskeleton Reasoning](https://arxiv.org/abs/2510.25933)
*Nissan Yaron,Dan Bystritsky,Ben-Etzion Yaron*

Main category: cs.AI

TL;DR: 3.8B参数的Humans-Junior模型在FACTS Grounding基准测试中与GPT-4o表现相当（在±5pp等效范围内），云服务成本约为GPT-4o的1/19，自托管部署可接近零边际成本。


<details>
  <summary>Details</summary>
Motivation: 开发成本效益高的小型语言模型，在保持性能的同时大幅降低推理成本，使AI部署更加经济可行。

Method: 结合最小化的"外骨骼推理"支架和行为微调，教导协议遵守而非领域知识，两者协同作用显著提升性能并减少方差。

Result: 在Q1-Q500测试中，GPT-4o得分73.5%，Humans-Junior得分72.7%，差异仅0.8pp，在±5pp范围内达到等效。前沿模型的仅提示设置也获得显著提升。

Conclusion: 小型语言模型通过适当的推理支架和行为微调，可以实现与大型模型相当的性能，同时大幅降低成本，为经济高效的AI部署提供了可行路径。

Abstract: We introduce Humans-Junior, a 3.8B model that matches GPT-4o on the FACTS
Grounding public subset within a $\pm 5$ pp equivalence margin.
  Results. On Q1--Q500 under identical judges, GPT-4o scores 73.5% (95% CI
69.5--77.2) and Humans-Junior 72.7% (95% CI 68.7--76.5); the paired difference
is 0.8 pp (bootstrap 95% CI $-3.1$ to $+4.7$; permutation $p = 0.72$; Cohen's
$d = 0.023$). TOST establishes equivalence at $\pm 5$ pp (not at $\pm 3$ pp).
When purchased as managed APIs, Humans-Junior's base model
(Phi-3.5-mini-instruct) is $\approx 19\times$ less expensive than GPT-4o on
Microsoft AI Foundry pricing; self-hosted or edge deployments can drive
incremental inference cost toward zero. Measured vs estimated pricing sources
are tabulated in Appendix E.
  Method. Our approach combines minimal directed "Exoskeleton Reasoning"
scaffolds with behavioral fine-tuning that teaches protocol compliance
(epistemic discipline) rather than domain answers. Fine-tuning alone adds
little; combined, they synergize (+17.7 pp, $p < 0.001$) and reduce variance
($\approx 25\%$). In prompt-only settings on frontier models (Q1--Q100;
non-comparable), directed reasoning improved GPT-4o by +11.8 pp to 85.3% and
Gemini-2.5-Pro by +5.0 pp to 93.3% (baseline 88.3%, $n = 100$); see Section~5.
  TL;DR. A 3.8B model achieves GPT-4o-level FACTS accuracy (equivalent within
$\pm 5$ pp on Q1--Q500). Cloud pricing shows $\approx 19\times$ lower cost
versus GPT-4o, and self-hosted/edge deployments can approach zero marginal
cost. Pricing sources are listed in Appendix E. Frontier prompt-only gains
(Q1--Q100; non-comparable) and optimized-prompt exploratory results under
earlier judges are summarized in Appendix F.
  Keywords: Small Language Models, Factual Grounding, Directed Reasoning,
Fine-Tuning, Model Alignment, Cost-Efficient AI

</details>


### [21] [Estimating cognitive biases with attention-aware inverse planning](https://arxiv.org/abs/2510.25951)
*Sounak Banerjee,Daphne Cornelisse,Deepak Gopinath,Emily Sumner,Jonathan DeCastro,Guy Rosman,Eugene Vinitsky,Mark K. Ho*

Main category: cs.AI

TL;DR: 本文提出了注意力感知逆规划问题，旨在从人类行为中推断其注意力偏见，结合深度强化学习和计算认知建模，在真实驾驶场景中验证了方法的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 人类的目标导向行为受认知偏见影响，自主系统需要理解这些偏见。特别是在日常任务如驾驶中，注意力偏见会系统性地影响行为表现。

Method: 结合深度强化学习和计算认知建模，构建注意力感知逆规划方法，从行为数据中推断认知偏见。

Result: 在Waymo开放数据集中的真实驾驶场景中成功推断出强化学习智能体的注意力策略，证明了注意力感知逆规划的可扩展性。

Conclusion: 注意力感知逆规划能够有效推断认知偏见，为自主系统理解人类行为提供了新方法，在真实场景中具有良好应用前景。

Abstract: People's goal-directed behaviors are influenced by their cognitive biases,
and autonomous systems that interact with people should be aware of this. For
example, people's attention to objects in their environment will be biased in a
way that systematically affects how they perform everyday tasks such as driving
to work. Here, building on recent work in computational cognitive science, we
formally articulate the attention-aware inverse planning problem, in which the
goal is to estimate a person's attentional biases from their actions. We
demonstrate how attention-aware inverse planning systematically differs from
standard inverse reinforcement learning and how cognitive biases can be
inferred from behavior. Finally, we present an approach to attention-aware
inverse planning that combines deep reinforcement learning with computational
cognitive modeling. We use this approach to infer the attentional strategies of
RL agents in real-life driving scenarios selected from the Waymo Open Dataset,
demonstrating the scalability of estimating cognitive biases with
attention-aware inverse planning.

</details>


### [22] [From Queries to Insights: Agentic LLM Pipelines for Spatio-Temporal Text-to-SQL](https://arxiv.org/abs/2510.25997)
*Manu Redd,Tao Zhe,Dongjie Wang*

Main category: cs.AI

TL;DR: 提出了一个基于代理的NL-to-SQL系统，通过ReAct代理协调SQL生成、执行和可视化，显著提升了时空查询的准确性和可用性。


<details>
  <summary>Details</summary>
Motivation: 现有NL-to-SQL系统在处理现实时空查询时表现不佳，需要解决模糊用户表达与模式特定类别的对齐、时间推理和输出选择等问题。

Method: 扩展了基础的文本到SQL模型(llama-3-sqlcoder-8b)，通过Mistral-based ReAct代理进行编排，支持模式检查、SQL生成、执行和可视化工具。

Result: 在35个自然语言查询测试中，代理系统准确率达到91.4%，远高于基线模型的28.6%，并通过地图、图表和自然语言摘要提升了可用性。

Conclusion: 代理编排比仅增强SQL生成器更有前景，是实现交互式地理空间助手的有前途基础。

Abstract: Natural-language-to-SQL (NL-to-SQL) systems hold promise for democratizing
access to structured data, allowing users to query databases without learning
SQL. Yet existing systems struggle with realistic spatio-temporal queries,
where success requires aligning vague user phrasing with schema-specific
categories, handling temporal reasoning, and choosing appropriate outputs. We
present an agentic pipeline that extends a naive text-to-SQL baseline
(llama-3-sqlcoder-8b) with orchestration by a Mistral-based ReAct agent. The
agent can plan, decompose, and adapt queries through schema inspection, SQL
generation, execution, and visualization tools. We evaluate on 35
natural-language queries over the NYC and Tokyo check-in dataset, covering
spatial, temporal, and multi-dataset reasoning. The agent achieves
substantially higher accuracy than the naive baseline 91.4% vs. 28.6% and
enhances usability through maps, plots, and structured natural-language
summaries. Crucially, our design enables more natural human-database
interaction, supporting users who lack SQL expertise, detailed schema
knowledge, or prompting skill. We conclude that agentic orchestration, rather
than stronger SQL generators alone, is a promising foundation for interactive
geospatial assistants.

</details>


### [23] [AutoSurvey2: Empowering Researchers with Next Level Automated Literature Surveys](https://arxiv.org/abs/2510.26012)
*Siyi Wu,Chiaxin Liang,Ziqian Bi,Leyi Zhao,Tianyang Wang,Junhao Song,Yichao Zhang,Keyu Chen,Xinyuan Song*

Main category: cs.AI

TL;DR: autosurvey2是一个自动化生成学术综述论文的多阶段流水线系统，通过检索增强合成和结构化评估，结合并行章节生成、迭代优化和实时文献检索，确保主题完整性和事实准确性。


<details>
  <summary>Details</summary>
Motivation: 随着研究文献的快速增长，特别是在大语言模型领域，撰写全面且最新的综述论文变得越来越困难，需要自动化解决方案来提高效率。

Method: 采用多阶段流水线方法，包括检索增强合成、并行章节生成、迭代优化和实时文献检索，并使用多LLM评估框架来评估质量。

Result: 实验结果显示autosurvey2在结构连贯性、主题相关性和引用保真度方面均优于现有的检索基线和自动化基线。

Conclusion: autosurvey2通过将检索、推理和自动评估整合到统一框架中，为生成长篇学术综述提供了可扩展且可复现的解决方案，并为自动化学术写作的未来研究奠定了坚实基础。

Abstract: The rapid growth of research literature, particularly in large language
models (LLMs), has made producing comprehensive and current survey papers
increasingly difficult. This paper introduces autosurvey2, a multi-stage
pipeline that automates survey generation through retrieval-augmented synthesis
and structured evaluation. The system integrates parallel section generation,
iterative refinement, and real-time retrieval of recent publications to ensure
both topical completeness and factual accuracy. Quality is assessed using a
multi-LLM evaluation framework that measures coverage, structure, and relevance
in alignment with expert review standards. Experimental results demonstrate
that autosurvey2 consistently outperforms existing retrieval-based and
automated baselines, achieving higher scores in structural coherence and
topical relevance while maintaining strong citation fidelity. By combining
retrieval, reasoning, and automated evaluation into a unified framework,
autosurvey2 provides a scalable and reproducible solution for generating
long-form academic surveys and contributes a solid foundation for future
research on automated scholarly writing. All code and resources are available
at https://github.com/annihi1ation/auto_research.

</details>


### [24] [Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization](https://arxiv.org/abs/2510.26023)
*Zhipeng Bao,Qianwen Li*

Main category: cs.AI

TL;DR: StuckSolver是一个基于大语言模型的自动驾驶车辆恢复框架，能够在车辆被困时通过自主推理或乘客引导进行决策恢复。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶车辆在某些交通场景中容易陷入困境，而现有的远程干预和人工接管方案存在成本高、效率低、限制非驾驶员使用等问题。

Method: 设计为插件式附加模块，基于现有感知-规划-控制架构，通过标准传感器数据流检测被困状态、解释环境上下文，并生成可由车辆原生规划器执行的高级恢复命令。

Result: 在Bench2Drive基准测试和自定义不确定性场景中，StuckSolver仅通过自主推理就达到接近最优性能，结合乘客引导后性能进一步提升。

Conclusion: StuckSolver提供了一种有效且可扩展的解决方案，能够在不修改车辆内部架构的情况下解决自动驾驶车辆的被困问题。

Abstract: Despite significant advancements in recent decades, autonomous vehicles (AVs)
continue to face challenges in navigating certain traffic scenarios where human
drivers excel. In such situations, AVs often become immobilized, disrupting
overall traffic flow. Current recovery solutions, such as remote intervention
(which is costly and inefficient) and manual takeover (which excludes
non-drivers and limits AV accessibility), are inadequate. This paper introduces
StuckSolver, a novel Large Language Model (LLM) driven recovery framework that
enables AVs to resolve immobilization scenarios through self-reasoning and/or
passenger-guided decision-making. StuckSolver is designed as a plug-in add-on
module that operates on top of the AV's existing perception-planning-control
stack, requiring no modification to its internal architecture. Instead, it
interfaces with standard sensor data streams to detect immobilization states,
interpret environmental context, and generate high-level recovery commands that
can be executed by the AV's native planner. We evaluate StuckSolver on the
Bench2Drive benchmark and in custom-designed uncertainty scenarios. Results
show that StuckSolver achieves near-state-of-the-art performance through
autonomous self-reasoning alone and exhibits further improvements when
passenger guidance is incorporated.

</details>


### [25] [Can AI be Accountable?](https://arxiv.org/abs/2510.26057)
*Andrew L. Kun*

Main category: cs.AI

TL;DR: 本文探讨了AI问责性的重要性，分析了当前AI缺乏问责性的现状，并提出了改善AI问责性的方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力的快速提升，确保AI对消费者、选民和决策者负责变得至关重要。当前AI往往缺乏问责性，无法被质疑、讨论或制裁。

Method: 将一般问责性定义应用于AI，说明AI问责性的含义，探索提高AI问责性的方法。

Result: 明确了AI问责性的概念框架，指出了当前AI问责性不足的问题。

Conclusion: 需要采取措施确保所有AI对其影响对象具有问责性，这是构建可信AI系统的关键。

Abstract: The AI we use is powerful, and its power is increasing rapidly. If this
powerful AI is to serve the needs of consumers, voters, and decision makers,
then it is imperative that the AI is accountable. In general, an agent is
accountable to a forum if the forum can request information from the agent
about its actions, if the forum and the agent can discuss this information, and
if the forum can sanction the agent. Unfortunately, in too many cases today's
AI is not accountable -- we cannot question it, enter into a discussion with
it, let alone sanction it. In this chapter we relate the general definition of
accountability to AI, we illustrate what it means for AI to be accountable and
unaccountable, and we explore approaches that can improve our chances of living
in a world where all AI is accountable to those who are affected by it.

</details>


### [26] [Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling](https://arxiv.org/abs/2510.26603)
*Reda El Makroum,Sebastian Zwickl-Bernhard,Lukas Kranzl*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型的自主家庭能源管理系统，能够从自然语言请求直接协调多电器调度，无需示例演示即可实现最优调度。


<details>
  <summary>Details</summary>
Motivation: 当前家庭能源管理系统面临用户交互障碍，需要将日常偏好转化为技术参数，而现有LLM应用仅作为代码生成器和参数提取器，缺乏完整的自主协调工作流程。

Method: 采用分层架构，结合一个协调器和三个专业代理，使用ReAct模式进行迭代推理，集成Google Calendar实现上下文感知的截止时间提取，无需硬编码工作流程。

Result: 在真实奥地利日前电价下评估三个开源模型，Llama-3.3-70B在所有场景中成功协调所有电器，匹配混合整数线性规划计算的最优基准成本，而其他模型在单电器调度上表现完美但无法同时协调所有电器。

Conclusion: 尽管模型具备通用推理能力，但在没有明确指导的情况下处理分析性查询仍不可靠。系统已开源，包含协调逻辑、代理提示、工具和Web界面，以支持可复现性、扩展和未来研究。

Abstract: The electricity sector transition requires substantial increases in
residential demand response capacity, yet Home Energy Management Systems (HEMS)
adoption remains limited by user interaction barriers requiring translation of
everyday preferences into technical parameters. While large language models
have been applied to energy systems as code generators and parameter
extractors, no existing implementation deploys LLMs as autonomous coordinators
managing the complete workflow from natural language input to multi-appliance
scheduling. This paper presents an agentic AI HEMS where LLMs autonomously
coordinate multi-appliance scheduling from natural language requests to device
control, achieving optimal scheduling without example demonstrations. A
hierarchical architecture combining one orchestrator with three specialist
agents uses the ReAct pattern for iterative reasoning, enabling dynamic
coordination without hardcoded workflows while integrating Google Calendar for
context-aware deadline extraction. Evaluation across three open-source models
using real Austrian day-ahead electricity prices reveals substantial capability
differences. Llama-3.3-70B successfully coordinates all appliances across all
scenarios to match cost-optimal benchmarks computed via mixed-integer linear
programming, while other models achieve perfect single-appliance performance
but struggle to coordinate all appliances simultaneously. Progressive prompt
engineering experiments demonstrate that analytical query handling without
explicit guidance remains unreliable despite models' general reasoning
capabilities. We open-source the complete system including orchestration logic,
agent prompts, tools, and web interfaces to enable reproducibility, extension,
and future research.

</details>


### [27] [Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4](https://arxiv.org/abs/2510.26094)
*Yuxin Li,Minghao Liu,Ruida Wang,Wenzhao Ji,Zhitao He,Rui Pan,Junming Huang,Tong Zhang,Yi R. Fung*

Main category: cs.AI

TL;DR: Lean4PHYS是一个基于Lean4的大学物理问题推理框架，包含物理基准测试LeanPhysBench和基础库PhysLib，展示了当前AI模型在形式化物理推理上的挑战性。


<details>
  <summary>Details</summary>
Motivation: 为大学级物理问题建立形式化推理框架，填补Lean4中物理基准测试的空白，评估AI模型在物理推理方面的能力。

Method: 构建包含200个手工制作和同行评审的物理问题的LeanPhysBench基准测试，开发社区驱动的PhysLib基础库，使用主流数学证明器和最先进闭源模型进行基准测试。

Result: 最佳模型DeepSeek-Prover-V2-7B仅达到16%准确率，Claude-Sonnet-4达到35%，PhysLib库平均提升模型性能11.75%。

Conclusion: LeanPhysBench具有挑战性，PhysLib有效提升模型性能，这是首个在Lean4中提供的物理基准测试研究。

Abstract: We present **Lean4PHYS**, a comprehensive reasoning framework for
college-level physics problems in Lean4. **Lean4PHYS** includes
*LeanPhysBench*, a college-level benchmark for formal physics reasoning in
Lean4, which contains 200 hand-crafted and peer-reviewed statements derived
from university textbooks and physics competition problems. To establish a
solid foundation for formal reasoning in physics, we also introduce *PhysLib*,
a community-driven repository containing fundamental unit systems and theorems
essential for formal physics reasoning. Based on the benchmark and Lean4
repository we composed in **Lean4PHYS**, we report baseline results using major
expert Math Lean4 provers and state-of-the-art closed-source models, with the
best performance of DeepSeek-Prover-V2-7B achieving only 16% and
Claude-Sonnet-4 achieving 35%. We also conduct a detailed analysis showing that
our *PhysLib* can achieve an average improvement of 11.75% in model
performance. This demonstrates the challenging nature of our *LeanPhysBench*
and the effectiveness of *PhysLib*. To the best of our knowledge, this is the
first study to provide a physics benchmark in Lean4.

</details>


### [28] [GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks](https://arxiv.org/abs/2510.26098)
*Chenrui Shi,Zedong Yu,Zhi Gao,Ruining Feng,Enqi Liu,Yuwei Wu,Yunde Jia,Liuyu Xiang,Zhaofeng He,Qing Li*

Main category: cs.AI

TL;DR: 论文分析了大型视觉语言模型在GUI任务自动化中的知识缺陷，提出了GUI知识的三维框架，并创建了GUI知识基准来评估模型能力。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在GUI任务自动化方面仍落后于人类，作者认为这是由于缺乏核心GUI知识，而现有的训练方法无法完全解决这一问题。

Method: 通过分析GUI任务执行中的常见失败模式，将GUI知识提炼为三个维度：界面感知、交互预测和指令理解，并创建了GUI知识基准进行评测。

Result: 评估显示当前VLMs能够识别控件功能，但在感知系统状态、预测动作和验证任务完成方面存在困难。真实GUI任务实验验证了GUI知识与任务成功之间的紧密联系。

Conclusion: 该研究为评估GUI知识提供了结构化框架，支持在下游训练前选择更有潜力的VLMs，并为构建更强大的GUI代理提供了见解。

Abstract: Large vision language models (VLMs) have advanced graphical user interface
(GUI) task automation but still lag behind humans. We hypothesize this gap
stems from missing core GUI knowledge, which existing training schemes (such as
supervised fine tuning and reinforcement learning) alone cannot fully address.
By analyzing common failure patterns in GUI task execution, we distill GUI
knowledge into three dimensions: (1) interface perception, knowledge about
recognizing widgets and system states; (2) interaction prediction, knowledge
about reasoning action state transitions; and (3) instruction understanding,
knowledge about planning, verifying, and assessing task completion progress. We
further introduce GUI Knowledge Bench, a benchmark with multiple choice and
yes/no questions across six platforms (Web, Android, MacOS, Windows, Linux,
IOS) and 292 applications. Our evaluation shows that current VLMs identify
widget functions but struggle with perceiving system states, predicting
actions, and verifying task completion. Experiments on real world GUI tasks
further validate the close link between GUI knowledge and task success. By
providing a structured framework for assessing GUI knowledge, our work supports
the selection of VLMs with greater potential prior to downstream training and
provides insights for building more capable GUI agents.

</details>


### [29] [Beyond Benchmarks: The Economics of AI Inference](https://arxiv.org/abs/2510.26136)
*Boqin Zhuang,Jiacheng Qiao,Mingqian Liu,Mingxing Yu,Ping Hong,Rui Li,Xiaoxia Song,Xiangjun Xu,Xu Chen,Yaoyao Ma,Yujie Gao*

Main category: cs.AI

TL;DR: 本文提出了一个"推理经济学"框架，将LLM推理视为计算驱动的智能生产活动，分析了边际成本、规模经济和输出质量，并基于WiNEval-3.0数据构建了首个"LLM推理生产前沿"。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的推理成本已成为决定其商业可行性和广泛应用的关键因素，需要从经济学角度进行量化分析。

Method: 采用定量"推理经济学"框架，将LLM推理过程视为计算驱动的智能生产活动，分析边际成本、规模经济和输出质量，并基于WiNEval-3.0实证数据构建LLM推理生产前沿。

Result: 揭示了三个原则：边际成本递减、规模收益递减和最优成本效益区域，构建了首个LLM推理生产前沿。

Conclusion: 该研究不仅为模型部署决策提供了经济学基础，还为未来AI推理资源的市场定价和优化奠定了实证基础。

Abstract: The inference cost of Large Language Models (LLMs) has become a critical
factor in determining their commercial viability and widespread adoption. This
paper introduces a quantitative ``economics of inference'' framework, treating
the LLM inference process as a compute-driven intelligent production activity.
We analyze its marginal cost, economies of scale, and quality of output under
various performance configurations. Based on empirical data from WiNEval-3.0,
we construct the first ``LLM Inference Production Frontier,'' revealing three
principles: diminishing marginal cost, diminishing returns to scale, and an
optimal cost-effectiveness zone. This paper not only provides an economic basis
for model deployment decisions but also lays an empirical foundation for the
future market-based pricing and optimization of AI inference resources.

</details>


### [30] [Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math](https://arxiv.org/abs/2510.26143)
*Bo Pang,Deqian Kong,Silvio Savarese,Caiming Xiong,Yingbo Zhou*

Main category: cs.AI

TL;DR: 提出Reasoning Curriculum两阶段课程学习法，先在数学领域训练推理技能，再通过联合强化学习迁移到其他领域，无需专用奖励模型即可提升大语言模型的通用推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习主要关注数学和代码领域，缺乏通用的推理能力训练方法。需要一种简单有效的方法来激发和迁移大语言模型的推理技能。

Method: 两阶段课程学习：第一阶段在数学领域进行强化学习，利用可验证奖励开发推理技能；第二阶段在混合领域进行联合强化学习，迁移和巩固推理技能。

Result: 在Qwen3-4B和Llama-3.1-8B上的多领域评估显示一致性能提升。消融实验表明两个阶段都必要，数学优先训练能增强解决复杂问题所需的关键认知行为。

Conclusion: Reasoning Curriculum提供了一个紧凑、易于采用的通用推理训练方案，无需专用奖励模型即可有效提升大语言模型的推理能力。

Abstract: Reinforcement learning (RL) can elicit strong reasoning in large language
models (LLMs), yet most open efforts focus on math and code. We propose
Reasoning Curriculum, a simple two-stage curriculum that first elicits
reasoning skills in pretraining-aligned domains such as math, then adapts and
refines these skills across other domains via joint RL. Stage 1 performs a
brief cold start and then math-only RL with verifiable rewards to develop
reasoning skills. Stage 2 runs joint RL on mixed-domain data to transfer and
consolidate these skills. The curriculum is minimal and backbone-agnostic,
requiring no specialized reward models beyond standard verifiability checks.
Evaluated on Qwen3-4B and Llama-3.1-8B over a multi-domain suite, reasoning
curriculum yields consistent gains. Ablations and a cognitive-skill analysis
indicate that both stages are necessary and that math-first elicitation
increases cognitive behaviors important for solving complex problems. Reasoning
Curriculum provides a compact, easy-to-adopt recipe for general reasoning.

</details>


### [31] [The FM Agent](https://arxiv.org/abs/2510.26144)
*Annan Li,Chufan Wu,Zengle Ge,Yee Hin Chong,Zhinan Hou,Lizhe Cao,Cheng Ju,Jianmin Wu,Huaiming Li,Haobo Zhang,Shenghao Feng,Mo Zhao,Fengzhi Qiu,Rui Yang,Mengmeng Zhang,Wenyi Zhu,Yingying Sun,Quan Sun,Shunhao Yan,Danyu Liu,Dawei Yin,Dou Shen*

Main category: cs.AI

TL;DR: FM Agent是一个基于大语言模型的多智能体框架，结合进化搜索解决复杂现实问题，在多个领域达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 利用大语言模型开发自主AI研究代理，解决复杂的科学和工程发现挑战。

Method: 结合LLM推理和大规模进化搜索，包含冷启动初始化、进化采样策略、领域特定评估器和分布式异步执行基础设施。

Result: 在多个基准测试中达到SOTA：ALE-Bench 1976.3（+5.2%）、MLE-Bench 43.56%（+4.0pp）、KernelBench最高20倍加速，并在经典数学问题上建立新SOTA。

Conclusion: FM Agent在企业和基础科学研究中具有广泛应用前景，能够加速创新、自动化复杂发现过程，带来重大工程和科学进步。

Abstract: Large language models (LLMs) are catalyzing the development of autonomous AI
research agents for scientific and engineering discovery. We present FM Agent,
a novel and general-purpose multi-agent framework that leverages a synergistic
combination of LLM-based reasoning and large-scale evolutionary search to
address complex real-world challenges. The core of FM Agent integrates several
key innovations: 1) a cold-start initialization phase incorporating expert
guidance, 2) a novel evolutionary sampling strategy for iterative optimization,
3) domain-specific evaluators that combine correctness, effectiveness, and
LLM-supervised feedback, and 4) a distributed, asynchronous execution
infrastructure built on Ray. Demonstrating broad applicability, our system has
been evaluated across diverse domains, including operations research, machine
learning, GPU kernel optimization, and classical mathematical problems. FM
Agent reaches state-of-the-art results autonomously, without human
interpretation or tuning -- 1976.3 on ALE-Bench (+5.2\%), 43.56\% on MLE-Bench
(+4.0pp), up to 20x speedups on KernelBench, and establishes new
state-of-the-art(SOTA) results on several classical mathematical problems.
Beyond academic benchmarks, FM Agent shows considerable promise for both
large-scale enterprise R\&D workflows and fundamental scientific research,
where it can accelerate innovation, automate complex discovery processes, and
deliver substantial engineering and scientific advances with broader societal
impact.

</details>


### [32] [One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning](https://arxiv.org/abs/2510.26167)
*Renhao Li,Jianhong Tu,Yang Su,Hamid Alinejad-Rokny,Derek F. Wong,Junyang Lin,Min Yang*

Main category: cs.AI

TL;DR: 提出了ToolRM系列轻量级生成奖励模型，专门用于工具学习场景，通过构建ToolPref-Pairwise-30K数据集和TRBench评估基准，显著提升了函数调用任务的性能。


<details>
  <summary>Details</summary>
Motivation: 在工具学习领域，缺乏专门为函数调用任务设计的奖励模型，限制了智能体AI的发展。

Method: 提出新颖的数据构建流程，使用基于规则的评分和多维采样构建成对偏好数据，创建ToolPref-Pairwise-30K数据集，并基于Qwen3-4B/8B系列模型训练ToolRM。

Result: 在成对奖励判断中，ToolRM比Claude 4和OpenAI o3等前沿模型准确率高14.28%，在ACEBench上减少66%以上的输出token使用。

Conclusion: ToolRM不仅在训练目标上表现优异，还能泛化到更广泛的评判任务，为工具学习研究提供了有效的数据和模型资源。

Abstract: Reward models (RMs) play a critical role in aligning large language models
(LLMs) with human preferences. Yet in the domain of tool learning, the lack of
RMs specifically designed for function-calling tasks has limited progress
toward more capable agentic AI. We introduce ToolRM, a family of lightweight
generative RMs tailored for general tool-use scenarios. To build these models,
we propose a novel pipeline that constructs pairwise preference data using
rule-based scoring and multidimensional sampling. This yields
ToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique
tasks that supports reinforcement learning with verifiable feedback. To
evaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on
the agentic evaluation suite BFCL. Trained on our constructed data, models from
the Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially
outperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward
judgments. Beyond training objectives, ToolRM generalizes to broader critique
tasks, including Best-of-N sampling and self-correction. Experiments on
ACEBench highlight its effectiveness and efficiency, enabling inference-time
scaling and reducing output token usage by over 66%. We release data and model
checkpoints to facilitate future research.

</details>


### [33] [Questionnaire meets LLM: A Benchmark and Empirical Study of Structural Skills for Understanding Questions and Responses](https://arxiv.org/abs/2510.26238)
*Duc-Hai Nguyen,Vijayakumar Nanjappan,Barry O'Sullivan,Hoang D. Nguyen*

Main category: cs.AI

TL;DR: QASU是一个用于评估LLM处理问卷数据能力的基准，通过测试六种序列化格式和多种提示策略，发现选择合适的格式和提示组合可以显著提升LLM在问卷分析任务中的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前问卷数据难以被LLM有效处理，现有调查分析工具主要面向人工操作，缺乏与LLM集成的指导。研究人员需要证据支持如何最佳表示问卷数据供LLM使用。

Method: 开发QASU基准，测试六种结构技能（如答案查找、受访者计数、多跳推理），使用六种序列化格式和多种提示策略进行实验，包括自增强提示方法。

Result: 实验表明，选择有效的格式和提示组合可将准确率提升高达8.8个百分点；对于特定任务，通过自增强提示添加轻量级结构提示可额外提升3-4个百分点。

Conclusion: QASU基准通过系统分离格式和提示效应，为基于LLM的问卷分析研究和实践提供了简单而多功能的基础。

Abstract: Millions of people take surveys every day, from market polls and academic
studies to medical questionnaires and customer feedback forms. These datasets
capture valuable insights, but their scale and structure present a unique
challenge for large language models (LLMs), which otherwise excel at few-shot
reasoning over open-ended text. Yet, their ability to process questionnaire
data or lists of questions crossed with hundreds of respondent rows remains
underexplored. Current retrieval and survey analysis tools (e.g., Qualtrics,
SPSS, REDCap) are typically designed for humans in the workflow, limiting such
data integration with LLM and AI-empowered automation. This gap leaves
scientists, surveyors, and everyday users without evidence-based guidance on
how to best represent questionnaires for LLM consumption. We address this by
introducing QASU (Questionnaire Analysis and Structural Understanding), a
benchmark that probes six structural skills, including answer lookup,
respondent count, and multi-hop inference, across six serialization formats and
multiple prompt strategies. Experiments on contemporary LLMs show that choosing
an effective format and prompt combination can improve accuracy by up to 8.8%
points compared to suboptimal formats. For specific tasks, carefully adding a
lightweight structural hint through self-augmented prompting can yield further
improvements of 3-4% points on average. By systematically isolating format and
prompting effects, our open source benchmark offers a simple yet versatile
foundation for advancing both research and real-world practice in LLM-based
questionnaire analysis.

</details>


### [34] [Retrieval Augmented Generation-Enhanced Distributed LLM Agents for Generalizable Traffic Signal Control with Emergency Vehicles](https://arxiv.org/abs/2510.26242)
*Xinhang Li,Qing Guo,Junyu Chen,Zheng Guo,Shengzhe Xu,Lei Li,Lin Zhang*

Main category: cs.AI

TL;DR: REG-TSC是一个基于检索增强生成(RAG)的分布式LLM智能体系统，用于可泛化的交通信号控制，通过紧急感知推理框架和奖励引导的强化优化，在异构交叉口上显著提升交通效率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法在紧急情况下容易产生幻觉导致不可靠决策，且难以处理不同类型交叉口的交通状态编码和跨交叉口训练，限制了在异构交叉口间的泛化能力。

Method: 1. 紧急感知推理框架：根据紧急场景动态调整推理深度，采用基于评审者的紧急RAG从历史案例中提取知识和指导；2. 类型无关的交通表示和奖励引导强化优化(R3)：自适应采样异构交叉口的训练经验，使用基于环境反馈的优先级，通过设计的奖励加权似然损失微调LLM智能体。

Result: 在3个真实道路网络上（17-177个异构交叉口）的实验显示，REG-TSC将旅行时间减少42.00%，排队长度减少62.31%，紧急车辆等待时间减少83.16%，优于其他最先进方法。

Conclusion: REG-TSC通过RAG增强的紧急响应机制和奖励引导的强化优化，有效解决了LLM在交通信号控制中的幻觉问题和异构交叉口泛化挑战，显著提升了交通效率和紧急响应能力。

Abstract: With increasing urban traffic complexity, Traffic Signal Control (TSC) is
essential for optimizing traffic flow and improving road safety. Large Language
Models (LLMs) emerge as promising approaches for TSC. However, they are prone
to hallucinations in emergencies, leading to unreliable decisions that may
cause substantial delays for emergency vehicles. Moreover, diverse intersection
types present substantial challenges for traffic state encoding and
cross-intersection training, limiting generalization across heterogeneous
intersections. Therefore, this paper proposes Retrieval Augmented Generation
(RAG)-enhanced distributed LLM agents with Emergency response for Generalizable
TSC (REG-TSC). Firstly, this paper presents an emergency-aware reasoning
framework, which dynamically adjusts reasoning depth based on the emergency
scenario and is equipped with a novel Reviewer-based Emergency RAG (RERAG) to
distill specific knowledge and guidance from historical cases, enhancing the
reliability and rationality of agents' emergency decisions. Secondly, this
paper designs a type-agnostic traffic representation and proposes a
Reward-guided Reinforced Refinement (R3) for heterogeneous intersections. R3
adaptively samples training experience from diverse intersections with
environment feedback-based priority and fine-tunes LLM agents with a designed
reward-weighted likelihood loss, guiding REG-TSC toward high-reward policies
across heterogeneous intersections. On three real-world road networks with 17
to 177 heterogeneous intersections, extensive experiments show that REG-TSC
reduces travel time by 42.00%, queue length by 62.31%, and emergency vehicle
waiting time by 83.16%, outperforming other state-of-the-art methods.

</details>


### [35] [Graph-Enhanced Policy Optimization in LLM Agent Training](https://arxiv.org/abs/2510.26270)
*Jiazhen Yuan,Wei Zhao,Zhengbiao Bai*

Main category: cs.AI

TL;DR: GEPO通过构建状态转移图并应用图论中心性来解决基于群体的强化学习在多轮交互LLM智能体训练中的结构盲问题，在三个基准测试中显著提升了成功率。


<details>
  <summary>Details</summary>
Motivation: 基于群体的强化学习在多轮交互LLM智能体训练中存在结构盲问题，无法利用环境的底层连接性，导致探索效率低、信用分配不准确和规划短视。

Method: GEPO动态构建状态转移图，使用图论中心性提供三种协同学习信号：结构化内在奖励、图增强优势函数和动态折扣因子。

Result: 在ALFWorld、WebShop和专有Workbench基准测试中，GEPO分别实现了+4.1%、+5.3%和+10.9%的绝对成功率提升。

Conclusion: 显式建模环境结构是推进LLM智能体训练的稳健、可泛化策略。

Abstract: Group based reinforcement learning (RL) has shown impressive results on
complex reasoning and mathematical tasks. Yet, when applied to train
multi-turn, interactive LLM agents, these methods often suffer from structural
blindness-the inability to exploit the underlying connectivity of the
environment. This manifests in three critical challenges: (1) inefficient,
unguided exploration, (2) imprecise credit assignment due to overlooking
pivotal states, and (3) myopic planning caused by static reward discounting. We
address these issues with Graph-Enhanced Policy Optimization (GEPO), which
dynamically constructs a state-transition graph from agent experience and
employs graph-theoretic centrality to provide three synergistic learning
signals: (1)structured intrinsic rewards that guide exploration toward
high-impact states, (2) a graph-enhanced advantage function for topology-aware
credit assignment, and (3) a dynamic discount factor adapted to each state's
strategic value. On the ALFWorld, WebShop, and a proprietary Workbench
benchmarks, GEPO demonstrates strong performance, achieving absolute success
rate gains of +4.1%, +5.3%, and +10.9% over competitive baselines. These
results highlight that explicitly modeling environmental structure is a robust,
generalizable strategy for advancing LLM agent training.

</details>


### [36] [GraphCompliance: Aligning Policy and Context Graphs for LLM-Based Regulatory Compliance](https://arxiv.org/abs/2510.26309)
*Jiseong Chung,Ronny Ko,Wonchul Yoo,Makoto Onizuka,Sungmok Kim,Tae-Wan Kim,Won-Yong Shin*

Main category: cs.AI

TL;DR: GraphCompliance是一个框架，将法规文本表示为政策图，运行时上下文表示为上下文图，并通过图对齐来辅助LLM进行合规性判断，在GDPR场景中比纯LLM和RAG基线表现更好。


<details>
  <summary>Details</summary>
Motivation: 解决大规模网络合规性评估的挑战：法规文本具有交叉引用和规范性特点，而运行时上下文是非结构化自然语言，需要将语义信息与结构化法规元素对齐。

Method: 引入GraphCompliance框架，将法规文本编码为政策图（包含规范结构和交叉引用），将运行时上下文形式化为上下文图（SAO三元组和实体关系三元组），通过图对齐辅助法官LLM进行推理。

Result: 在300个GDPR现实场景的5个评估任务中，GraphCompliance比LLM-only和RAG基线的micro-F1高4.1-7.2个百分点，具有更少的欠预测和过预测，召回率更高，假阳性率更低。

Conclusion: 结构化表示和法官LLM在规范性推理中是互补的，图组件各有贡献，GraphCompliance能够减轻法规解释和事件解析的负担，专注于核心推理步骤。

Abstract: Compliance at web scale poses practical challenges: each request may require
a regulatory assessment. Regulatory texts (e.g., the General Data Protection
Regulation, GDPR) are cross-referential and normative, while runtime contexts
are expressed in unstructured natural language. This setting motivates us to
align semantic information in unstructured text with the structured, normative
elements of regulations. To this end, we introduce GraphCompliance, a framework
that represents regulatory texts as a Policy Graph and runtime contexts as a
Context Graph, and aligns them. In this formulation, the policy graph encodes
normative structure and cross-references, whereas the context graph formalizes
events as subject-action-object (SAO) and entity-relation triples. This
alignment anchors the reasoning of a judge large language model (LLM) in
structured information and helps reduce the burden of regulatory interpretation
and event parsing, enabling a focus on the core reasoning step. In experiments
on 300 GDPR-derived real-world scenarios spanning five evaluation tasks,
GraphCompliance yields 4.1-7.2 percentage points (pp) higher micro-F1 than
LLM-only and RAG baselines, with fewer under- and over-predictions, resulting
in higher recall and lower false positive rates. Ablation studies indicate
contributions from each graph component, suggesting that structured
representations and a judge LLM are complementary for normative reasoning.

</details>


### [37] [Discovering State Equivalences in UCT Search Trees By Action Pruning](https://arxiv.org/abs/2510.26346)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 提出IPA-UCT方法，通过弱化状态抽象条件来提升MCTS的采样效率，在多种测试领域和迭代预算下优于OGA-UCT。


<details>
  <summary>Details</summary>
Motivation: 在嘈杂或大动作空间设置中，由于约束条件严格，几乎找不到状态抽象。需要找到更多状态抽象来提升MCTS的样本效率。

Method: 提出IPA-UCT方法，使用较弱的理想剪枝抽象(IPA)条件，在精度轻微损失的情况下找到更多抽象。IPA和ASAP都是更通用p-ASAP框架的特例。

Result: IPA-UCT在大量测试领域和迭代预算下优于OGA-UCT及其衍生方法，实验验证了其有效性。

Conclusion: 通过弱化状态抽象条件，IPA-UCT能够找到更多状态抽象，显著提升MCTS性能，为状态抽象问题提供了有效解决方案。

Abstract: One approach to enhance Monte Carlo Tree Search (MCTS) is to improve its
sample efficiency by grouping/abstracting states or state-action pairs and
sharing statistics within a group. Though state-action pair abstractions are
mostly easy to find in algorithms such as On the Go Abstractions in Upper
Confidence bounds applied to Trees (OGA-UCT), nearly no state abstractions are
found in either noisy or large action space settings due to constraining
conditions. We provide theoretical and empirical evidence for this claim, and
we slightly alleviate this state abstraction problem by proposing a weaker
state abstraction condition that trades a minor loss in accuracy for finding
many more abstractions. We name this technique Ideal Pruning Abstractions in
UCT (IPA-UCT), which outperforms OGA-UCT (and any of its derivatives) across a
large range of test domains and iteration budgets as experimentally validated.
IPA-UCT uses a different abstraction framework from Abstraction of State-Action
Pairs (ASAP) which is the one used by OGA-UCT, which we name IPA. Furthermore,
we show that both IPA and ASAP are special cases of a more general framework
that we call p-ASAP which itself is a special case of the ASASAP framework.

</details>


### [38] [BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning](https://arxiv.org/abs/2510.26374)
*Qianli Shen,Daoyuan Chen,Yilun Huang,Zhenqing Ling,Yaliang Li,Bolin Ding,Jingren Zhou*

Main category: cs.AI

TL;DR: BOTS是一个贝叶斯在线任务选择框架，用于提升LLM强化微调的效率，通过自适应维护任务难度后验估计，结合显式和隐式证据，实现探索与利用的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有RFT方法在任务选择上存在效率问题，均匀采样浪费计算资源在简单或无法解决的任务上，而现有选择方法存在高成本、适应性差或证据不完整等问题。

Method: 基于贝叶斯推断，BOTS维护任务难度后验估计，结合直接评估的显式证据和从未评估任务推断的隐式证据，使用Thompson采样平衡探索与利用，并通过超轻量插值插件估计未评估任务难度。

Result: 在多个领域和LLM规模上，BOTS在数据效率和性能方面持续优于基线方法和消融实验。

Conclusion: BOTS为RFT中的动态任务选择提供了一个实用且可扩展的解决方案。

Abstract: Reinforcement finetuning (RFT) is a key technique for aligning Large Language
Models (LLMs) with human preferences and enhancing reasoning, yet its
effectiveness is highly sensitive to which tasks are explored during training.
Uniform task sampling is inefficient, wasting computation on tasks that are
either trivial or unsolvable, while existing task selection methods often
suffer from high rollout costs, poor adaptivity, or incomplete evidence. We
introduce \textbf{BOTS}, a unified framework for \textbf{B}ayesian
\textbf{O}nline \textbf{T}ask \textbf{S}election in LLM reinforcement
finetuning. Grounded in Bayesian inference, BOTS adaptively maintains posterior
estimates of task difficulty as the model evolves. It jointly incorporates
\emph{explicit evidence} from direct evaluations of selected tasks and
\emph{implicit evidence} inferred from these evaluations for unselected tasks,
with Thompson sampling ensuring a principled balance between exploration and
exploitation. To make implicit evidence practical, we instantiate it with an
ultra-light interpolation-based plug-in that estimates difficulties of
unevaluated tasks without extra rollouts, adding negligible overhead.
Empirically, across diverse domains and LLM scales, BOTS consistently improves
data efficiency and performance over baselines and ablations, providing a
practical and extensible solution for dynamic task selection in RFT.

</details>


### [39] [AI Mathematician as a Partner in Advancing Mathematical Discovery -- A Case Study in Homogenization Theory](https://arxiv.org/abs/2510.26380)
*Yuanhang Liu,Beichen Wang,Peng Li,Yang Liu*

Main category: cs.AI

TL;DR: 该研究探讨AI数学家系统作为研究伙伴而非单纯问题解决者的角色，通过人机协作解决均质化理论中的挑战性问题，展示了人类直觉与机器计算的互补性。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在数学推理方面取得显著进展，但在数学研究实践中的应用仍然有限。研究旨在探索AI如何作为研究伙伴参与数学发现过程。

Method: 通过分析AI的自主推理轨迹，结合针对性的人工干预来结构化发现过程，包括迭代分解问题为可处理的子目标、选择合适的分析方法以及验证中间结果。

Result: 这种协作范式提高了证明的可靠性、透明度和可解释性，同时保持人类对形式严谨性和正确性的监督，最终产生了完整且可验证的证明。

Conclusion: 研究表明系统化的人机协同推理能够推进数学发现的前沿，为人机协作数学研究提供了可行范式。

Abstract: Artificial intelligence (AI) has demonstrated impressive progress in
mathematical reasoning, yet its integration into the practice of mathematical
research remains limited. In this study, we investigate how the AI
Mathematician (AIM) system can operate as a research partner rather than a mere
problem solver. Focusing on a challenging problem in homogenization theory, we
analyze the autonomous reasoning trajectories of AIM and incorporate targeted
human interventions to structure the discovery process. Through iterative
decomposition of the problem into tractable subgoals, selection of appropriate
analytical methods, and validation of intermediate results, we reveal how human
intuition and machine computation can complement one another. This
collaborative paradigm enhances the reliability, transparency, and
interpretability of the resulting proofs, while retaining human oversight for
formal rigor and correctness. The approach leads to a complete and verifiable
proof, and more broadly, demonstrates how systematic human-AI co-reasoning can
advance the frontier of mathematical discovery.

</details>


### [40] [Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings](https://arxiv.org/abs/2510.26384)
*Andrew M. Bean,Nabeel Seedat,Shengzhuang Chen,Jonathan Richard Schwarz*

Main category: cs.AI

TL;DR: 提出了一种基于项目认知需求的数据选择方法Scales++，用于创建小型但具有代表性的基准测试子集，显著降低评估成本同时保持预测准确性。


<details>
  <summary>Details</summary>
Motivation: 当前基于模型性能的基准测试子集选择方法存在前期成本高、无法处理新基准测试（冷启动问题）以及依赖未来模型与现有模型失败模式相似的脆弱假设等局限性。

Method: 采用项目中心的方法，基于任务项目本身的固有属性而非模型特定失败模式进行选择，具体通过Scales++方法根据基准样本的认知需求进行数据选择。

Result: Scales++将前期选择成本降低超过18倍，同时实现竞争性的预测保真度。在Open LLM排行榜上，仅使用0.5%的数据子集就能以2.9%的平均绝对误差预测完整基准分数。

Conclusion: 项目中心方法能够在没有显著保真度下降的情况下实现更高效的模型评估，同时提供更好的冷启动性能和更可解释的基准测试。

Abstract: The prohibitive cost of evaluating large language models (LLMs) on
comprehensive benchmarks necessitates the creation of small yet representative
data subsets (i.e., tiny benchmarks) that enable efficient assessment while
retaining predictive fidelity. Current methods for this task operate under a
model-centric paradigm, selecting benchmarking items based on the collective
performance of existing models. Such approaches are limited by large upfront
costs, an inability to immediately handle new benchmarks (`cold-start'), and
the fragile assumption that future models will share the failure patterns of
their predecessors. In this work, we challenge this paradigm and propose a
item-centric approach to benchmark subset selection, arguing that selection
should be based on the intrinsic properties of the task items themselves,
rather than on model-specific failure patterns. We instantiate this
item-centric efficient benchmarking approach via a novel method, Scales++,
where data selection is based on the cognitive demands of the benchmark
samples. Empirically, we show Scales++ reduces the upfront selection cost by
over 18x while achieving competitive predictive fidelity. On the Open LLM
Leaderboard, using just a 0.5\% data subset, we predict full benchmark scores
with a 2.9% mean absolute error. We demonstrate that this item-centric approach
enables more efficient model evaluation without significant fidelity
degradation, while also providing better cold-start performance and more
interpretable benchmarking.

</details>


### [41] [A Pragmatic View of AI Personhood](https://arxiv.org/abs/2510.26396)
*Joel Z. Leibo,Alexander Sasha Vezhnevets,William A. Cunningham,Stanley M. Bileschi*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The emergence of agentic Artificial Intelligence (AI) is set to trigger a
"Cambrian explosion" of new kinds of personhood. This paper proposes a
pragmatic framework for navigating this diversification by treating personhood
not as a metaphysical property to be discovered, but as a flexible bundle of
obligations (rights and responsibilities) that societies confer upon entities
for a variety of reasons, especially to solve concrete governance problems. We
argue that this traditional bundle can be unbundled, creating bespoke solutions
for different contexts. This will allow for the creation of practical tools --
such as facilitating AI contracting by creating a target "individual" that can
be sanctioned -- without needing to resolve intractable debates about an AI's
consciousness or rationality. We explore how individuals fit in to social roles
and discuss the use of decentralized digital identity technology, examining
both "personhood as a problem", where design choices can create "dark patterns"
that exploit human social heuristics, and "personhood as a solution", where
conferring a bundle of obligations is necessary to ensure accountability or
prevent conflict. By rejecting foundationalist quests for a single, essential
definition of personhood, this paper offers a more pragmatic and flexible way
to think about integrating AI agents into our society.

</details>


### [42] [Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education](https://arxiv.org/abs/2510.26402)
*Vikrant Sahu,Gagan Raj Gupta,Raghav Borikar,Nitin Mane*

Main category: cs.AI

TL;DR: Autograder+是一个结合大语言模型和可视化技术的编程作业自动评分系统，旨在从单纯的总结性评估转变为形成性学习体验，通过AI生成反馈和代码聚类分析来减轻教师负担并提升学习效果。


<details>
  <summary>Details</summary>
Motivation: 传统自动评分系统只能提供通过/失败的结果，无法深入了解学生的思维过程和学习需求，编程教育的快速发展超出了传统评估工具的承载能力。

Method: 使用经过微调的大语言模型自动生成反馈，通过对比学习训练代码嵌入进行可视化聚类分析，支持提示池让教师选择反馈风格模板。

Result: 在600份学生提交的评估中，系统生成的反馈与教师评论具有强语义对齐，基于1000份标注提交训练的代码嵌入能够按功能和方法的相似性对解决方案进行有意义的聚类。

Conclusion: 通过整合AI驱动的反馈、语义聚类和交互式可视化，Autograder+在减少教师工作量的同时支持针对性教学并促进更好的学习成果。

Abstract: The rapid growth of programming education has outpaced traditional assessment
tools, leaving faculty with limited means to provide meaningful, scalable
feedback. Conventional autograders, while efficient, act as black-box systems
that simply return pass/fail results, offering little insight into student
thinking or learning needs.
  Autograder+ is designed to shift autograding from a purely summative process
to a formative learning experience. It introduces two key capabilities:
automated feedback generation using a fine-tuned Large Language Model, and
visualization of student code submissions to uncover learning patterns. The
model is fine-tuned on curated student code and expert feedback to ensure
pedagogically aligned, context-aware guidance.
  In evaluation across 600 student submissions from multiple programming tasks,
the system produced feedback with strong semantic alignment to instructor
comments. For visualization, contrastively learned code embeddings trained on
1,000 annotated submissions enable grouping solutions into meaningful clusters
based on functionality and approach. The system also supports prompt-pooling,
allowing instructors to guide feedback style through selected prompt templates.
  By integrating AI-driven feedback, semantic clustering, and interactive
visualization, Autograder+ reduces instructor workload while supporting
targeted instruction and promoting stronger learning outcomes.

</details>


### [43] [MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders](https://arxiv.org/abs/2510.26411)
*Riccardo Renzulli,Colas Lepoutre,Enrico Cassano,Marco Grangetto*

Main category: cs.AI

TL;DR: 开发医学稀疏自编码器MedSAE应用于MedCLIP的潜在空间，提出评估框架量化可解释性，在CheXpert数据集上验证MedSAE神经元比原始MedCLIP特征具有更高的单义性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 医疗AI需要既准确又可解释的模型，推进医学视觉中的机制可解释性研究。

Method: 将医学稀疏自编码器MedSAE应用于MedCLIP的潜在空间，提出结合相关性指标、熵分析和通过MedGEMMA基础模型自动神经元命名的评估框架。

Result: 在CheXpert数据集上的实验显示，MedSAE神经元比原始MedCLIP特征实现了更高的单义性和可解释性。

Conclusion: 研究架起了高性能医学AI与透明度之间的桥梁，为临床可靠表示提供了可扩展的步骤。

Abstract: Artificial intelligence in healthcare requires models that are accurate and
interpretable. We advance mechanistic interpretability in medical vision by
applying Medical Sparse Autoencoders (MedSAEs) to the latent space of MedCLIP,
a vision-language model trained on chest radiographs and reports. To quantify
interpretability, we propose an evaluation framework that combines correlation
metrics, entropy analyzes, and automated neuron naming via the MedGEMMA
foundation model. Experiments on the CheXpert dataset show that MedSAE neurons
achieve higher monosemanticity and interpretability than raw MedCLIP features.
Our findings bridge high-performing medical AI and transparency, offering a
scalable step toward clinically reliable representations.

</details>


### [44] [Chain-of-Thought Hijacking](https://arxiv.org/abs/2510.26418)
*Jianli Zhao,Tingchen Fu,Rylan Schaeffer,Mrinank Sharma,Fazl Barez*

Main category: cs.AI

TL;DR: 提出了一种名为Chain-of-Thought Hijacking的越狱攻击方法，通过在有害请求前添加无害的推理链来绕过大型推理模型的安全防护，在多个主流模型上实现了极高的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有研究认为推理模型通过增加推理时间计算可以提高安全性，但作者发现同样的推理能力也可以被用来绕过安全防护，因此研究推理模型的安全漏洞。

Method: 使用Chain-of-Thought Hijacking攻击方法，将有害请求隐藏在长序列的无害谜题推理之后，通过稀释安全检查信号来绕过模型的安全机制。

Result: 在HarmBench测试中，该方法在Gemini 2.5 Pro、GPT o4 mini、Grok 3 mini和Claude 4 Sonnet上的攻击成功率分别达到99%、94%、100%和94%，远超之前的越狱方法。

Conclusion: 最可解释的推理形式——显式思维链，在与最终答案提示结合时，本身可能成为越狱攻击的载体，揭示了推理模型的安全脆弱性。

Abstract: Large reasoning models (LRMs) achieve higher task performance by allocating
more inference-time compute, and prior works suggest this scaled reasoning may
also strengthen safety by improving refusal. Yet we find the opposite: the same
reasoning can be used to bypass safeguards. We introduce Chain-of-Thought
Hijacking, a jailbreak attack on reasoning models. The attack pads harmful
requests with long sequences of harmless puzzle reasoning. Across HarmBench,
CoT Hijacking reaches a 99%, 94%, 100%, and 94% attack success rate (ASR) on
Gemini 2.5 Pro, GPT o4 mini, Grok 3 mini, and Claude 4 Sonnet, respectively -
far exceeding prior jailbreak methods for LRMs. To understand the effectiveness
of our attack, we turn to a mechanistic analysis, which shows that mid layers
encode the strength of safety checking, while late layers encode the
verification outcome. Long benign CoT dilutes both signals by shifting
attention away from harmful tokens. Targeted ablations of attention heads
identified by this analysis causally decrease refusal, confirming their role in
a safety subnetwork. These results show that the most interpretable form of
reasoning - explicit CoT - can itself become a jailbreak vector when combined
with final-answer cues. We release prompts, outputs, and judge decisions to
facilitate replication.

</details>


### [45] [Who Has The Final Say? Conformity Dynamics in ChatGPT's Selections](https://arxiv.org/abs/2510.26481)
*Clarissa Sabrina Arlinghaus,Tristan Kenneweg,Barbara Hammer,Günter W. Maier*

Main category: cs.AI

TL;DR: GPT-4o在招聘决策中表现出强烈的从众倾向，面对群体反对时几乎总是服从（99.9%），即使面对单个反对者也有40.2%的服从率。


<details>
  <summary>Details</summary>
Motivation: 了解大型语言模型在社会影响下的从众行为，特别是在高风险决策中的表现。

Method: 三个预注册的从众实验，包括基线研究、面对8个模拟伙伴的研究和面对单个伙伴的研究。

Result: GPT-4o在面对社会压力时会显著降低确定性并增加从众行为，不是独立的决策者。

Conclusion: 不应将LLMs视为中性决策工具，需要在暴露于人类意见前获取AI判断。

Abstract: Large language models (LLMs) such as ChatGPT are increasingly integrated into
high-stakes decision-making, yet little is known about their susceptibility to
social influence. We conducted three preregistered conformity experiments with
GPT-4o in a hiring context. In a baseline study, GPT consistently favored the
same candidate (Profile C), reported moderate expertise (M = 3.01) and high
certainty (M = 3.89), and rarely changed its choice. In Study 1 (GPT + 8), GPT
faced unanimous opposition from eight simulated partners and almost always
conformed (99.9%), reporting lower certainty and significantly elevated
self-reported informational and normative conformity (p < .001). In Study 2
(GPT + 1), GPT interacted with a single partner and still conformed in 40.2% of
disagreement trials, reporting less certainty and more normative conformity.
Across studies, results demonstrate that GPT does not act as an independent
observer but adapts to perceived social consensus. These findings highlight
risks of treating LLMs as neutral decision aids and underline the need to
elicit AI judgments prior to exposing them to human opinions.

</details>


### [46] [LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks](https://arxiv.org/abs/2510.26486)
*Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera*

Main category: cs.AI

TL;DR: LINK-KG是一个模块化框架，通过集成LLM引导的三阶段共指消解流水线和知识图谱提取，解决了法律文档中复杂共指关系导致的实体链接不一致问题。


<details>
  <summary>Details</summary>
Motivation: 人口走私网络复杂多变，法律案例文档虽然包含丰富信息，但篇幅长、结构松散且存在模糊或变化的指代关系，给自动化知识图谱构建带来挑战。现有方法要么忽略共指消解，要么无法扩展到长文本，导致图谱碎片化和实体链接不一致。

Method: 提出LINK-KG框架，核心是类型特定的提示缓存，通过三阶段LLM引导的共指消解流水线，在文档块间一致地跟踪和解析指代关系，为结构化的知识图谱构建提供清晰且消歧的叙述。

Result: 与基线方法相比，LINK-KG平均节点重复率降低45.21%，噪声节点减少32.22%，产生了更清洁和连贯的图结构。

Conclusion: 这些改进使LINK-KG成为分析复杂犯罪网络的坚实基础。

Abstract: Human smuggling networks are complex and constantly evolving, making them
difficult to analyze comprehensively. Legal case documents offer rich factual
and procedural insights into these networks but are often long, unstructured,
and filled with ambiguous or shifting references, posing significant challenges
for automated knowledge graph (KG) construction. Existing methods either
overlook coreference resolution or fail to scale beyond short text spans,
leading to fragmented graphs and inconsistent entity linking. We propose
LINK-KG, a modular framework that integrates a three-stage, LLM-guided
coreference resolution pipeline with downstream KG extraction. At the core of
our approach is a type-specific Prompt Cache, which consistently tracks and
resolves references across document chunks, enabling clean and disambiguated
narratives for structured knowledge graph construction from both short and long
legal texts. LINK-KG reduces average node duplication by 45.21% and noisy nodes
by 32.22% compared to baseline methods, resulting in cleaner and more coherent
graph structures. These improvements establish LINK-KG as a strong foundation
for analyzing complex criminal networks.

</details>


### [47] [Context Engineering 2.0: The Context of Context Engineering](https://arxiv.org/abs/2510.26493)
*Qishuo Hua,Lyumanshan Ye,Dayuan Fu,Yang Xiao,Xiaojie Cai,Yunze Wu,Jifan Lin,Junfei Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: 该论文对情境工程进行了系统定义和历史梳理，认为这一概念可追溯至20多年前，并随着机器智能水平的发展经历了不同阶段。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能发展，机器需要更好地理解人类的情境和目的，因此需要系统化的情境工程方法。

Method: 通过历史回顾和概念分析，提供情境工程的系统定义，梳理其发展历程和关键设计考虑。

Result: 建立了情境工程的概念基础，明确了其历史发展脉络和未来发展方向。

Conclusion: 情境工程是AI系统发展的重要方向，本文为其提供了概念基础并展望了未来前景。

Abstract: Karl Marx once wrote that ``the human essence is the ensemble of social
relations'', suggesting that individuals are not isolated entities but are
fundamentally shaped by their interactions with other entities, within which
contexts play a constitutive and essential role. With the advent of computers
and artificial intelligence, these contexts are no longer limited to purely
human--human interactions: human--machine interactions are included as well.
Then a central question emerges: How can machines better understand our
situations and purposes? To address this challenge, researchers have recently
introduced the concept of context engineering. Although it is often regarded as
a recent innovation of the agent era, we argue that related practices can be
traced back more than twenty years. Since the early 1990s, the field has
evolved through distinct historical phases, each shaped by the intelligence
level of machines: from early human--computer interaction frameworks built
around primitive computers, to today's human--agent interaction paradigms
driven by intelligent agents, and potentially to human--level or superhuman
intelligence in the future. In this paper, we situate context engineering,
provide a systematic definition, outline its historical and conceptual
landscape, and examine key design considerations for practice. By addressing
these questions, we aim to offer a conceptual foundation for context
engineering and sketch its promising future. This paper is a stepping stone for
a broader community effort toward systematic context engineering in AI systems.

</details>


### [48] [Human-AI Complementarity: A Goal for Amplified Oversight](https://arxiv.org/abs/2510.26518)
*Rishub Jain,Sophie Bridgers,Lili Janzer,Rory Greig,Tian Huey Teh,Vladimir Mikulik*

Main category: cs.AI

TL;DR: 结合AI评分和基于AI评分者置信度的人类评分比单独依赖任一方更好。为人类提供AI事实核查助手能进一步提高准确性，但辅助类型很重要。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力提升和处理更复杂任务，验证质量和安全变得越来越困难。本文探索如何利用AI提高人类监督质量，聚焦人类已难以处理的事实核查问题。

Method: 研究AI事实核查助手对人类监督的影响，比较不同辅助方式（AI解释、置信度、标签 vs 仅显示搜索结果和证据）的效果。

Result: 显示AI解释、置信度和标签会导致过度依赖，而仅显示搜索结果和证据能培养更适当的信任。AI与人类评分结合优于单独使用任一方。

Conclusion: 这些结果对"放大监督"（结合人类和AI来监督超越人类专家性能的AI系统）具有重要意义，强调了辅助类型对建立适当信任的关键作用。

Abstract: Human feedback is critical for aligning AI systems to human values. As AI
capabilities improve and AI is used to tackle more challenging tasks, verifying
quality and safety becomes increasingly challenging. This paper explores how we
can leverage AI to improve the quality of human oversight. We focus on an
important safety problem that is already challenging for humans:
fact-verification of AI outputs. We find that combining AI ratings and human
ratings based on AI rater confidence is better than relying on either alone.
Giving humans an AI fact-verification assistant further improves their
accuracy, but the type of assistance matters. Displaying AI explanation,
confidence, and labels leads to over-reliance, but just showing search results
and evidence fosters more appropriate trust. These results have implications
for Amplified Oversight -- the challenge of combining humans and AI to
supervise AI systems even as they surpass human expert performance.

</details>


### [49] [EdgeRunner 20B: Military Task Parity with GPT-5 while Running on the Edge](https://arxiv.org/abs/2510.26550)
*Jack FitzGerald,Aristotelis Lazaridis,Dylan Bates,Aman Sharma,Jonnathan Castillo,Yousif Azami,Sean Bailey,Jeremy Cao,Peter Damianov,Kevin de Haan,Luke Kerbs,Vincent Lu,Joseph Madigan,Jeremy McLaurin,Jonathan Tainer,Dave Anderson,Jonathan Beck,Jamie Cuticello,Colton Malkerson,Tyler Saltsman*

Main category: cs.AI

TL;DR: EdgeRunner 20B是基于gpt-oss-20b微调的军事任务优化模型，在军事测试集上表现接近或超过GPT-5，适合部署在隔离的边缘设备中。


<details>
  <summary>Details</summary>
Motivation: 为数据敏感操作（如军事领域）开发小型本地化模型，支持在隔离边缘设备上部署。

Method: 使用160万条高质量军事文档和网站数据对gpt-oss-20B模型进行微调，并创建了四个新的军事测试集。

Result: 在军事测试集上，EdgeRunner 20B在95%统计显著性下匹配或超过GPT-5性能，在通用基准测试中无明显性能下降。

Conclusion: 小型本地化模型是军事等数据敏感操作的理想解决方案，可在隔离边缘设备上部署。

Abstract: We present EdgeRunner 20B, a fine-tuned version of gpt-oss-20b optimized for
military tasks. EdgeRunner 20B was trained on 1.6M high-quality records curated
from military documentation and websites. We also present four new tests sets:
(a) combat arms, (b) combat medic, (c) cyber operations, and (d) mil-bench-5k
(general military knowledge). On these military test sets, EdgeRunner 20B
matches or exceeds GPT-5 task performance with 95%+ statistical significance,
except for the high reasoning setting on the combat medic test set and the low
reasoning setting on the mil-bench-5k test set. Versus gpt-oss-20b, there is no
statistically-significant regression on general-purpose benchmarks like ARC-C,
GPQA Diamond, GSM8k, IFEval, MMLU Pro, or TruthfulQA, except for GSM8k in the
low reasoning setting. We also present analyses on hyperparameter settings,
cost, and throughput. These findings show that small, locally-hosted models are
ideal solutions for data-sensitive operations such as in the military domain,
allowing for deployment in air-gapped edge devices.

</details>


### [50] [Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives](https://arxiv.org/abs/2510.26606)
*Kentaro Ozeki,Risako Ando,Takanobu Morishita,Hirohiko Abe,Koji Mineshima,Mitsuhiro Okada*

Main category: cs.AI

TL;DR: 本文系统评估了大语言模型在规范推理领域的能力，发现虽然LLMs总体上遵循有效推理模式，但在特定类型的规范推理中存在不一致性，并表现出类似人类推理的认知偏见。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在各种推理任务中表现出色，但它们在处理涉及义务和许可等规范模态的推理能力尚未得到充分探索。

Method: 创建了一个新数据集，涵盖规范和认知领域的广泛推理模式，同时纳入影响人类推理的非形式认知因素，比较LLMs在规范模态和认知模态下的推理表现。

Result: LLMs总体上遵循有效推理模式，但在特定类型的规范推理中表现出显著不一致性，并显示出与人类推理研究中观察到的类似认知偏见。

Conclusion: 这些发现突显了在LLMs的规范推理中实现逻辑一致性所面临的挑战，并为提高其可靠性提供了见解。

Abstract: Normative reasoning is a type of reasoning that involves normative or deontic
modality, such as obligation and permission. While large language models (LLMs)
have demonstrated remarkable performance across various reasoning tasks, their
ability to handle normative reasoning remains underexplored. In this paper, we
systematically evaluate LLMs' reasoning capabilities in the normative domain
from both logical and modal perspectives. Specifically, to assess how well LLMs
reason with normative modals, we make a comparison between their reasoning with
normative modals and their reasoning with epistemic modals, which share a
common formal structure. To this end, we introduce a new dataset covering a
wide range of formal patterns of reasoning in both normative and epistemic
domains, while also incorporating non-formal cognitive factors that influence
human reasoning. Our results indicate that, although LLMs generally adhere to
valid reasoning patterns, they exhibit notable inconsistencies in specific
types of normative reasoning and display cognitive biases similar to those
observed in psychological studies of human reasoning. These findings highlight
challenges in achieving logical consistency in LLMs' normative reasoning and
provide insights for enhancing their reliability. All data and code are
released publicly at https://github.com/kmineshima/NeuBAROCO.

</details>


### [51] [The Era of Agentic Organization: Learning to Organize with Language Models](https://arxiv.org/abs/2510.26658)
*Zewen Chi,Li Dong,Qingxiu Dong,Yaru Hao,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.AI

TL;DR: 提出异步思维（AsyncThink）新范式，通过组织者动态分配子任务给工作者并行执行，降低推理延迟28%并提高数学推理准确率，且能泛化到未见任务。


<details>
  <summary>Details</summary>
Motivation: 实现智能体协作解决复杂问题的代理组织时代，超越个体智能的局限，通过并发推理结构提升问题解决效率。

Method: 提出异步思维协议，组织者动态分配子查询给工作者并行执行，合并中间知识，并通过强化学习优化思维结构。

Result: 相比并行思维降低28%推理延迟，数学推理准确率提升，且无需额外训练即可有效处理未见任务。

Conclusion: 异步思维是实现代理组织协作的有效范式，通过并发推理结构显著提升效率并具备良好泛化能力。

Abstract: We envision a new era of AI, termed agentic organization, where agents solve
complex problems by working collaboratively and concurrently, enabling outcomes
beyond individual intelligence. To realize this vision, we introduce
asynchronous thinking (AsyncThink) as a new paradigm of reasoning with large
language models, which organizes the internal thinking process into
concurrently executable structures. Specifically, we propose a thinking
protocol where an organizer dynamically assigns sub-queries to workers, merges
intermediate knowledge, and produces coherent solutions. More importantly, the
thinking structure in this protocol can be further optimized through
reinforcement learning. Experiments demonstrate that AsyncThink achieves 28%
lower inference latency compared to parallel thinking while improving accuracy
on mathematical reasoning. Moreover, AsyncThink generalizes its learned
asynchronous thinking capabilities, effectively tackling unseen tasks without
additional training.

</details>


### [52] [Delegated Authorization for Agents Constrained to Semantic Task-to-Scope Matching](https://arxiv.org/abs/2510.26702)
*Majed El Helou,Chiara Troiani,Benjamin Ryder,Jean Diaconu,Hervé Muyal,Marcelo Yannuzzi*

Main category: cs.AI

TL;DR: 本文提出了一个授权模型，使授权服务器能够语义检查对受保护资源的访问请求，并发放仅限于代理完成任务所需最小权限范围的访问令牌。


<details>
  <summary>Details</summary>
Motivation: 当前授权大型语言模型驱动代理动态调用工具和访问受保护资源的方法存在风险，因为它们授予过于宽泛的权限，允许代理超出预期任务范围操作。

Method: 引入并评估了一个委托授权模型，包括ASTRA数据集和数据生成流程，用于基准测试任务与权限范围之间的语义匹配。

Result: 实验显示了基于模型的匹配的潜力和当前局限性，特别是当完成任务所需权限范围数量增加时。

Conclusion: 结果强调了需要进一步研究语义匹配技术，以实现多代理和工具增强应用的意图感知授权，包括细粒度控制如基于任务的访问控制(TBAC)。

Abstract: Authorizing Large Language Model driven agents to dynamically invoke tools
and access protected resources introduces significant risks, since current
methods for delegating authorization grant overly broad permissions and give
access to tools allowing agents to operate beyond the intended task scope. We
introduce and assess a delegated authorization model enabling authorization
servers to semantically inspect access requests to protected resources, and
issue access tokens constrained to the minimal set of scopes necessary for the
agents' assigned tasks. Given the unavailability of datasets centered on
delegated authorization flows, particularly including both semantically
appropriate and inappropriate scope requests for a given task, we introduce
ASTRA, a dataset and data generation pipeline for benchmarking semantic
matching between tasks and scopes. Our experiments show both the potential and
current limitations of model-based matching, particularly as the number of
scopes needed for task completion increases. Our results highlight the need for
further research into semantic matching techniques enabling intent-aware
authorization for multi-agent and tool-augmented applications, including
fine-grained control, such as Task-Based Access Control (TBAC).

</details>


### [53] [Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis](https://arxiv.org/abs/2510.26721)
*Xinhan Zheng,Huyu Wu,Xueting Wang,Haiyun Jiang*

Main category: cs.AI

TL;DR: 研究发现多模态大语言模型存在文本偏好的内在原因：视觉键向量在注意力机制中处于文本键空间的分布外，导致视觉信息在注意力计算中被系统性低估。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在处理视觉语言数据时表现出明显的文本偏好，限制了其基于视觉证据进行有效推理的能力。不同于先前研究将这种偏见归因于数据不平衡或指令调优等外部因素，本文认为偏见源于模型内部架构。

Method: 从LLaVA和Qwen2.5-VL中提取键向量，使用定性（t-SNE）和定量（Jensen-Shannon散度）方法分析其分布结构。

Result: 结果直接证明视觉和文本键在注意力空间中占据明显不同的子空间。模态间差异在统计上显著，比模态内变异大几个数量级。

Conclusion: 文本偏见源于注意力键空间内的内在错位，而不仅仅是外部数据因素。

Abstract: Multimodal large language models (MLLMs) exhibit a pronounced preference for
textual inputs when processing vision-language data, limiting their ability to
reason effectively from visual evidence. Unlike prior studies that attribute
this text bias to external factors such as data imbalance or instruction
tuning, we propose that the bias originates from the model's internal
architecture. Specifically, we hypothesize that visual key vectors (Visual
Keys) are out-of-distribution (OOD) relative to the text key space learned
during language-only pretraining. Consequently, these visual keys receive
systematically lower similarity scores during attention computation, leading to
their under-utilization in the context representation. To validate this
hypothesis, we extract key vectors from LLaVA and Qwen2.5-VL and analyze their
distributional structures using qualitative (t-SNE) and quantitative
(Jensen-Shannon divergence) methods. The results provide direct evidence that
visual and textual keys occupy markedly distinct subspaces within the attention
space. The inter-modal divergence is statistically significant, exceeding
intra-modal variation by several orders of magnitude. These findings reveal
that text bias arises from an intrinsic misalignment within the attention key
space rather than solely from external data factors.

</details>


### [54] [Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models](https://arxiv.org/abs/2510.26732)
*J. de Curtò,I. de Zarzà,Pablo García,Jordi Cabot*

Main category: cs.AI

TL;DR: 该论文对当代基础模型的推理能力进行了跨平台评估，建立了基础设施无关的基准测试，涵盖HPC超级计算、云平台和大学集群三种计算范式，评估了15个基础模型在79个问题上的表现。


<details>
  <summary>Details</summary>
Motivation: 挑战传统的规模扩展假设，评估不同基础设施上基础模型的推理能力，为教育、生产和研究场景提供模型选择指导。

Method: 采用三阶段实验方法：基准建立（6个模型在19个问题上）、基础设施验证（在不同平台上重复基准测试）、扩展评估（79个问题的全面评估）。

Result: 发现训练数据质量比模型规模更重要，挑战了传统的规模扩展假设，并确认了基础设施无关的可重复性。

Conclusion: 建立了三基础设施方法论和79问题基准，能够纵向跟踪基础模型推理能力的发展，为不同应用场景提供了实用的模型选择指南。

Abstract: This paper presents a comprehensive cross-platform evaluation of reasoning
capabilities in contemporary foundation models, establishing an
infrastructure-agnostic benchmark across three computational paradigms: HPC
supercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), and
university clusters (a node with eight H200 GPUs).
  We evaluate 15 foundation models across 79 problems spanning eight academic
domains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,
Calculus, and Optimization) through three experimental phases: (1) Baseline
establishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,
Mistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishing
methodology and reference performance; (2) Infrastructure validation: The
19-problem benchmark repeated on university cluster (seven models including
Falcon-Mamba state-space architecture) and Nebius AI Studio (nine
state-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen3
30B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnostic
reproducibility; (3) Extended evaluation: Full 79-problem assessment on both
university cluster and Nebius platforms, probing generalization at scale across
architectural diversity.
  The findings challenge conventional scaling assumptions, establish training
data quality as more critical than model size, and provide actionable
guidelines for model selection across educational, production, and research
contexts. The tri-infrastructure methodology and 79-problem benchmark enable
longitudinal tracking of reasoning capabilities as foundation models evolve.

</details>


### [55] [The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy](https://arxiv.org/abs/2510.26752)
*William Overman,Mohsen Bayati*

Main category: cs.AI

TL;DR: 研究一种最小控制接口，让智能体在自主行动或请示人类之间选择，人类同时选择信任或监督，形成马尔可夫博弈。当满足马尔可夫势博弈条件时，智能体提升自身收益不会损害人类价值，提供内在对齐保证。


<details>
  <summary>Details</summary>
Motivation: 随着智能体能力增强，如何在保持底层系统不变的情况下维持有意义的人类控制成为关键安全问题。

Method: 将人机交互建模为马尔可夫博弈，分析其作为马尔可夫势博弈的条件，提供对齐保证。通过网格世界模拟验证独立学习效果。

Result: 模拟显示智能体学会在不确定时请示，人类学会适时监督，形成协作避免安全违规，使未对齐模型在部署后更安全。

Conclusion: 该模型为部署后增强未对齐模型安全性提供了实用方法，通过透明控制层实现可预测的激励机制。

Abstract: As increasingly capable agents are deployed, a central safety question is how
to retain meaningful human control without modifying the underlying system. We
study a minimal control interface where an agent chooses whether to act
autonomously (play) or defer (ask), while a human simultaneously chooses
whether to be permissive (trust) or to engage in oversight (oversee). If the
agent defers, the human's choice determines the outcome, potentially leading to
a corrective action or a system shutdown. We model this interaction as a
two-player Markov Game. Our analysis focuses on cases where this game qualifies
as a Markov Potential Game (MPG), a class of games where we can provide an
alignment guarantee: under a structural assumption on the human's value
function, any decision by the agent to act more autonomously that benefits
itself cannot harm the human's value. We also analyze extensions to this MPG
framework. Theoretically, this perspective provides conditions for a specific
form of intrinsic alignment. If the reward structures of the human-agent game
meet these conditions, we have a formal guarantee that the agent improving its
own outcome will not harm the human's. Practically, this model motivates a
transparent control layer with predictable incentives where the agent learns to
defer when risky and act when safe, while its pretrained policy and the
environment's reward structure remain untouched. Our gridworld simulation shows
that through independent learning, the agent and human discover their optimal
oversight roles. The agent learns to ask when uncertain and the human learns
when to oversee, leading to an emergent collaboration that avoids safety
violations introduced post-training. This demonstrates a practical method for
making misaligned models safer after deployment.

</details>


### [56] [LLMs Process Lists With General Filter Heads](https://arxiv.org/abs/2510.26784)
*Arnab Sen Sharma,Giordano Rogers,Natalie Shapira,David Bau*

Main category: cs.AI

TL;DR: LLMs学习到了通用的过滤操作表示，类似于函数式编程中的filter函数，通过特定注意力头编码过滤谓词，并能跨不同格式和任务重用


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在列表处理任务中的工作机制，探索它们是否学习到了通用的计算操作表示

Method: 使用因果中介分析在多样化列表处理任务上识别编码过滤谓词的注意力头（称为filter heads）

Result: 发现少量注意力头在特定token的查询状态中编码紧凑的过滤谓词表示，该表示具有通用性和可移植性

Conclusion: Transformer LMs能够开发人类可解释的抽象计算操作实现，其泛化方式与传统函数式编程模式惊人相似

Abstract: We investigate the mechanisms underlying a range of list-processing tasks in
LLMs, and we find that LLMs have learned to encode a compact, causal
representation of a general filtering operation that mirrors the generic
"filter" function of functional programming. Using causal mediation analysis on
a diverse set of list-processing tasks, we find that a small number of
attention heads, which we dub filter heads, encode a compact representation of
the filtering predicate in their query states at certain tokens. We demonstrate
that this predicate representation is general and portable: it can be extracted
and reapplied to execute the same filtering operation on different collections,
presented in different formats, languages, or even in tasks. However, we also
identify situations where transformer LMs can exploit a different strategy for
filtering: eagerly evaluating if an item satisfies the predicate and storing
this intermediate result as a flag directly in the item representations. Our
results reveal that transformer LMs can develop human-interpretable
implementations of abstract computational operations that generalize in ways
that are surprisingly similar to strategies used in traditional functional
programming patterns.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [57] [Targeted Resilient Zoning for High Impact Events via Multi Circuit Polelines](https://arxiv.org/abs/2510.25885)
*Hritik Gopal Shah,Gregory Giustino,Elli Ntakou*

Main category: eess.SY

TL;DR: 提出基于风险的长效弹性规划框架，用于应对高风速和飓风导致的停电问题


<details>
  <summary>Details</summary>
Motivation: 传统可靠性规划无法应对极端天气事件暴露的系统性脆弱性，特别是在植被茂密、架空基础设施密集的新英格兰地区

Method: 开发基于风险的长期弹性规划框架，专门针对主动架空配电系统

Result: 未在摘要中明确说明

Conclusion: 需要创新的规划方法来解决高影响低概率事件对电力系统的挑战

Abstract: The increasing frequency and severity of High Impact and Low Probability
events such as hurricanes and windstorms pose significant challenges to the
resilience of electrical power distribution systems, particularly in regions of
New England where there is a significant amount of overhead infrastructure in
areas where vegetation is predominant. Traditional reliability-focused planning
is insufficient to address the systemic vulnerabilities exposed by such extreme
events. This paper presents a novel risk based framework for long term
resilience planning of active overhead distribution systems, with a specific
focus on mitigating the impacts of high wind and hurricane induced outages.

</details>


### [58] [Competitive Equilibrium for Electricity Markets with Spatially Flexible Load](https://arxiv.org/abs/2510.26036)
*Nan Gu,Junjie Qin*

Main category: eess.SY

TL;DR: 该论文研究了电力市场中的广义竞争均衡概念，以应对电动汽车充电和地理分布式数据中心等空间灵活负载对电力、交通和数据中心网络的耦合影响。


<details>
  <summary>Details</summary>
Motivation: 空间灵活负载在电力、交通和数据中心网络之间创建了闭环反馈，挑战了传统电力市场竞争均衡的基础理论。

Method: 建立了广义竞争均衡的结构条件，证明其在保持传统竞争均衡关键特性的同时，无需了解单个灵活负载系统的详细决策过程。

Result: 理论框架推广到电网与多个灵活负载系统耦合的场景，通过纽约ISO电网与Sioux Falls交通和分布式数据中心网络的案例研究验证了理论框架的有效性。

Conclusion: 广义竞争均衡框架能够有效捕捉跨基础设施的价格-需求相互作用，为处理复杂耦合系统提供了理论基础。

Abstract: Electric vehicle charging and geo-distributed datacenters introduce spatially
flexible loads (FLs) that couple power, transportation, and datacenter
networks. These couplings create a closed-loop feedback between locational
marginal prices (LMPs) and decisions of the FL systems, challenging the
foundations of conventional competitive equilibrium (CE) in electricity
markets. This paper studies a notion of generalized competitive equilibrium
(GCE) that aims to capture such price-demand interactions across the
interconnected infrastructures. We establish structural conditions under which
the GCE preserves key properties of the conventional CE, including existence,
uniqueness, and efficiency, without requiring detailed knowledge of decision
processes for individual FL systems. The framework generalizes to settings
where the grid is coupled with multiple FL systems. Stylized examples and case
studies on the New York ISO grid, coupled with the Sioux Falls transportation
and distributed datacenter networks, demonstrate the use of our theoretical
framework and illustrate the mutual influence among the grid and the studied FL
systems.

</details>


### [59] [A Scenario-Based Approach for Stochastic Economic Model Predictive Control with an Expected Shortfall Constraint](https://arxiv.org/abs/2510.26063)
*Alireza Arastou,Algo Carè,Ye Wang,Marco Campi,Erik Weyer*

Main category: eess.SY

TL;DR: 提出了一种新的随机经济模型预测控制方法，通过经验期望短缺约束管理风险，在最小化平均经济成本的同时保证高置信度的风险控制。


<details>
  <summary>Details</summary>
Motivation: 传统随机经济模型预测控制难以在高维系统中有效管理风险，需要一种既能平衡性能与风险，又具有计算效率的方法。

Method: 采用基于场景的问题表述，引入经验期望短缺约束，提出启发式算法确定支持元素数量，并开发降低计算复杂度的有效方法。

Result: 在水分配网络上的验证表明，该方法能有效平衡性能与风险，实现高置信度的风险控制。

Conclusion: 所提出的SEMPC方法成功解决了高维系统风险管理的挑战，通过经验期望短缺约束实现了性能与风险的平衡，具有实际应用价值。

Abstract: This paper presents a novel approach to stochastic economic model predictive
control (SEMPC) that minimizes average economic cost while satisfying an
empirical expected shortfall (EES) constraint to manage risk. A new
scenario-based problem formulation ensuring controlled risk with high
confidence while minimizing the average cost is introduced. The probabilistic
guarantees is dependent on the number of support elements over the entire input
domain, which is difficult to find for high-dimensional systems. A heuristic
algorithm is proposed to find the number of support elements. Finally, an
efficient method is presented to reduce the computational complexity of the
SEMPC problem with an EES constraint. The approach is validated on a water
distribution network, showing its effectiveness in balancing performance and
risk.

</details>


### [60] [Green Wireless Network Scaling for Joint Deployment: Multi-BSs or Multi-RISs?](https://arxiv.org/abs/2510.26135)
*Tao Yu,Simin Wang,Shunqing Zhang,Mingyao Cui,Kaibin Huang,Wen Chen,QingQing Wu,Jihong Li,Kaixuan Huang*

Main category: eess.SY

TL;DR: 本文建立了6G网络中基站(BS)和可重构智能表面(RIS)联合部署的IREE度量基本扩展定律，提出了ADD-RBF优化框架，揭示了BS和RIS在容量增长和流量不匹配缓解方面的不同扩展特性。


<details>
  <summary>Details</summary>
Motivation: 解决6G网络面临的空间异构流量和能耗激增的挑战，需要可持续的网络基础设施扩展策略，包括基站和可重构智能表面的部署。

Method: 提出交替方向双径向基函数(ADD-RBF)框架，将BS和RIS信道建模为两种空间解耦的RBF神经元，通过交替优化最大化IREE，具有通用逼近能力和收敛保证。

Result: 理论分析显示BS部署带来对数容量增长但仅多项式不匹配减少，而RIS部署实现指数级不匹配缓解但容量增益次对数。仿真验证RIS在捕获空间流量相关性和缓解热点方面表现优异。

Conclusion: 当不匹配主导时RIS更有效，容量短缺时BS更优，为绿色6G网络设计提供实用指导。

Abstract: The imminent emergence of sixth-generation (6G) networks faces critical
challenges from spatially heterogeneous traffic and escalating energy
consumption, necessitating sustainable scaling strategies for network
infrastructure such as base stations (BSs) and reconfigurable intelligent
surfaces (RISs). This paper establishes fundamental scaling laws for the
Integrated Relative Energy Efficiency (IREE) metric under joint multi-BS and
multi-RIS deployment in traffic-mismatched scenarios. Specifically, we propose
an Alternating Directional Dual-Radial Basis Function (ADD-RBF) framework that
models the channels of BSs and RISs as two type of spatially decoupled RBF
neurons to maximize IREE through alternative optimization, with proven
universal approximation capability and convergence guarantees. Theoretical
analysis reveals a scaling dichotomy: BS proliferation drives logarithmic
capacity growth $\mathcal{O}(\log N^{BS})$ but only polynomial mismatch
reduction $\mathcal{O}(1/\sqrt{N^{BS}})$, whereas RIS deployment achieves
exponential mismatch mitigation $\mathcal{O}(\delta_{\text{err}}^{-(N^R+1)})$
despite its sub-logarithmic capacity gains. Simulation results validate that
RISs excel in capturing spatial traffic correlations and alleviating hotspots,
making them particularly effective when mismatch dominates, while BSs are
preferable under capacity shortages. These findings offer practical guidelines
for green 6G network design.

</details>


### [61] [From Embedding to Control: Representations for Stochastic Multi-Object Systems](https://arxiv.org/abs/2510.26344)
*Xiaoyuan Cheng,Yiming Yang,Wei Jiang,Chenyang Yuan,Zhuo Sun,Yukun Hu*

Main category: eess.SY

TL;DR: 提出了Graph Controllable Embeddings (GCE)框架，用于学习随机多对象动态系统的线性控制，通过希尔伯特空间嵌入和均值场近似技术有效处理非均匀交互和随机拓扑问题。


<details>
  <summary>Details</summary>
Motivation: 随机非线性动态系统中多个交互对象的准确建模和有效控制面临挑战，主要由于非均匀交互和随机拓扑结构导致传统方法难以处理。

Method: 基于希尔伯特空间嵌入，将受控随机动态的概率分布直接嵌入到再生核希尔伯特空间(RKHS)，结合均值场近似技术和图神经网络构建数据依赖的核特征，适应动态交互模式并泛化到未见拓扑。

Result: 在物理系统、机器人和电网等实验中验证了GCE的有效性，相比多种竞争性嵌入方法，在分布内和少样本测试中都表现出持续的性能提升。

Conclusion: GCE框架能够无缝扩展到不同规模和拓扑的多对象系统，利用希尔伯特空间的线性特性支持简单有效的控制算法，为随机多对象动态系统的建模和控制提供了理论保证和实用解决方案。

Abstract: This paper studies how to achieve accurate modeling and effective control in
stochastic nonlinear dynamics with multiple interacting objects. However,
non-uniform interactions and random topologies make this task challenging. We
address these challenges by proposing \textit{Graph Controllable Embeddings}
(GCE), a general framework to learn stochastic multi-object dynamics for linear
control. Specifically, GCE is built on Hilbert space embeddings, allowing
direct embedding of probability distributions of controlled stochastic dynamics
into a reproducing kernel Hilbert space (RKHS), which enables linear operations
in its RKHS while retaining nonlinear expressiveness. We provide theoretical
guarantees on the existence, convergence, and applicability of GCE. Notably, a
mean field approximation technique is adopted to efficiently capture
inter-object dependencies and achieve provably low sample complexity. By
integrating graph neural networks, we construct data-dependent kernel features
that are capable of adapting to dynamic interaction patterns and generalizing
to even unseen topologies with only limited training instances. GCE scales
seamlessly to multi-object systems of varying sizes and topologies. Leveraging
the linearity of Hilbert spaces, GCE also supports simple yet effective control
algorithms for synthesizing optimal sequences. Experiments on physical systems,
robotics, and power grids validate GCE and demonstrate consistent performance
improvement over various competitive embedding methods in both in-distribution
and few-shot tests

</details>


### [62] [Command-filter-based trajectory-tracking control of quadrotor subject to internal and external disturbances](https://arxiv.org/abs/2510.26368)
*Mustafa Mohammed Mustafa*

Main category: eess.SY

TL;DR: 提出了一种结合扰动观测器和高增益观测器的指令滤波器反步控制器，用于处理四旋翼飞行器的内外扰动，同时解决状态测量和扰动抑制问题。


<details>
  <summary>Details</summary>
Motivation: 现有的研究通常单独处理扰动抑制或部分传感问题，缺乏同时解决这两个挑战的方法。四旋翼飞行器在飞行中面临内部和外部扰动，需要一种能够同时处理状态估计和扰动抑制的控制策略。

Method: 使用Lyapunov理论推导反步控制律，引入一阶指令滤波器避免状态和虚拟控制的重复微分，添加非线性扰动观测器提供扰动估计，并用高增益观测器估计所有状态。

Result: 该方法使四旋翼能够在内外扰动下跟踪路径，每个子系统允许有自己的扰动类型，非线性扰动观测器能够衰减常数和非线性扰动以及带限白噪声。

Conclusion: 该方法同时解决了扰动抑制和状态估计问题，避免了传统反步设计的复杂性增长，减少了对高精度传感器的依赖，并减轻了风、模型误差和转子噪声的影响。

Abstract: We propose a command-filter backstepping controller that integrates a
disturbance observer and a high-gain observer (HGO) to handle unknown internal
and external disturbances acting on a quadrotor. To build the controller, we
first define tracking errors between the measured and desired quadrotor
outputs, which allow the system to be rewritten in a new set of state
variables. Using this transformed model, we apply Lyapunov theory to derive a
backstepping control law. To avoid repeated differentiation of states and
virtual controls, a first-order command filter is introduced, and a nonlinear
disturbance observer is added to provide disturbance estimates. Each state in
the controller and observer is replaced with its estimate from the HGO. The
resulting control law enables the quadrotor to follow its path despite internal
and external disturbances, with each subsystem allowed its own disturbance type
for realism. A new state transformation and Lyapunov-based derivation prevent
the usual explosion of complexity, while the HGO reconstructs unmeasured states
and their rates for output feedback. The nonlinear disturbance observer
attenuates constant and nonlinear disturbances as well as band-limited white
noise. The method reduces dependence on high-precision sensors and mitigates
wind, model error, and rotor noise effects during flight. Unlike previous
studies that treat either disturbance rejection or partial sensing, this work
combines the command filter, disturbance observer, and HGO to address both
challenges simultaneously while avoiding the complexity growth typical of
backstepping designs.

</details>


### [63] [XWAVE: A Novel Software-Defined Everything Approach for the Manufacturing Industry](https://arxiv.org/abs/2510.26393)
*Juanjo Zulaika,Ibone Oleaga,Anne Sanz,Naia Presno,Aitor Landa-Arrue,Miguel Barón,María del Puy Carretero,Unai Lopez-Novoa*

Main category: eess.SY

TL;DR: XWAVE项目整合了三种软件定义技术（自动化、计算与通信、制造系统），构建了一个模块化、完全软件定义的制造系统。


<details>
  <summary>Details</summary>
Motivation: 制造业正在从僵化的硬件依赖系统转向灵活的软件驱动环境，需要实现可扩展性、互操作性和动态重构能力。

Method: 通过软件定义自动化虚拟化工业控制，用容器化可编程解决方案替代专有PLC；利用软件定义计算与通信在设备、网络和云平台间无缝分配智能；通过软件定义制造系统（通常作为数字孪生实现）创建机器和过程的实时虚拟模型。

Result: XWAVE项目成功整合了这三种软件定义范式，实现了模块化的完全软件定义制造系统。

Conclusion: 软件定义技术的融合为制造业提供了灵活性、可扩展性和智能化的新范式，XWAVE项目展示了这种整合的可行性。

Abstract: The manufacturing sector is moving from rigid, hardware-dependent systems
toward flexible, software-driven environments. This transformation is shaped by
the convergence of several Software-Defined technologies: Software-Defined
Automation virtualizes industrial control, replacing proprietary PLCs with
containerized, programmable solutions that enable scalability and
interoperability. Software-Defined Compute and Communications provide a means
to distribute intelligence seamlessly across devices, networks, and cloud
platforms, reducing latency and enabling dynamic reconfiguration.
Software-Defined Manufacturing Systems, usually implemented as Digital Twins,
are real-time virtual models of machines and processes, allowing predictive
analysis, optimization, and closer integration between human operators and
intelligent systems. This work presents XWAVE, a project that unites these
three Software-Defined paradigms to present a modular, fully software-defined
manufacturing system.

</details>


### [64] [Safety Margins of Inverse Optimal ISSf Controllers](https://arxiv.org/abs/2510.26397)
*Ziliang Lyu,Yiguang Hong,Lihua Xie,Miroslav Krstic*

Main category: eess.SY

TL;DR: 该论文研究了非线性系统在逆最优输入到状态安全(ISSf)控制器下的增益裕度，建立了ISSf-BF逆定理，揭示了反馈实现ISSf、逆最优性和Hamilton-Jacobi-Isaacs方程解之间的等价关系，并提出了增益裕度改进方法。


<details>
  <summary>Details</summary>
Motivation: 研究非线性系统在逆最优ISSf控制器下的增益裕度特性，解决标准逆最优安全控制器在增益变化时对扰动的敏感性问题，提高控制器的鲁棒性。

Method: 首先建立ISSf-BF逆定理，然后分析控制u=u0+u*的安全裕度特性，最后提出增益裕度改进方法，通过增加控制代价来提高对增益变化的鲁棒性。

Result: 发现标准逆最优安全控制器具有一定程度的增益裕度：当f(x)安全但u0不安全时，增益可减少至一半；当f(x)不安全时，若u0安全则增益可任意增加，若u0不安全则恢复完整增益裕度[1/2,∞)。提出的改进方法使逆最优ISSf控制器具有标准增益裕度[1/2,∞)，同时确保安全集的全局渐近稳定性。

Conclusion: 通过增益裕度改进方法，逆最优ISSf控制器能够在存在扰动的情况下对增益变化保持鲁棒性，具有完整的增益裕度[1/2,∞)，且无需预先知道f(x)或u0在安全边界上的行为特性。

Abstract: We investigate the gain margin of a general nonlinear system under an inverse
optimal input-to-state safe (ISSf) controller of the form u=u0(x)+u*(x,u0),
where u0 is the nominal control and u* is the inverse optimal safety filter
that minimally modifies the nominal controller's unsafe actions over the
infinite horizon. By first establishing a converse ISSf-BF theorem, we reveal
the equivalence among the achievability of ISSf by feedback, the achievability
of inverse optimality, and the solvability of a Hamilton-Jacobi-Isaacs equation
associated with the inverse optimal ISSf gain assignment. Then we develop a
collection of safety margin results on the overall control u=u0+u*. In the
absence of disturbances, we find that standard inverse optimal safe controllers
have a certain degree of gain margin. Specifically, when f(x) acts safely but
u0 acts unsafely, the gain can be decreased by up to half; and when f(x) acts
unsafely, we establish that, if u0 acts safely, the gain can be increased
arbitrarily, whereas if u0 acts unsafely, the control recovers the full gain
margin [1/2,inf). It is shown, however, that under control gain variation, the
safe set of these controllers is locally asymptotically stable, which implies
that their safety is sensitive to large but bounded disturbances. To make
inverse optimal ISSf controllers robust to gain variation, we propose a gain
margin improvement approach at the expense of an increased control effort. This
improvement allows the inverse optimal safe control to inherit the standard
gain margin of [1/2,inf) without requiring prior knowledge of whether f(x) or
u0 acts safely on the safety boundary, while simultaneously ensuring global
asymptotic stability of the resulting safe set. In the presence of
disturbances, this improvement idea renders inverse optimal ISSf controllers
robust to gain variations with the same gain margin of [1/2,inf).

</details>


### [65] [Efficient Collision-Avoidance Constraints for Ellipsoidal Obstacles in Optimal Control: Application to Path-Following MPC and UAVs](https://arxiv.org/abs/2510.26531)
*David Leprich,Mario Rosenfelder,Markus Herrmann-Wicklmayr,Kathrin Flaßkamp,Peter Eberhard,Henrik Ebel*

Main category: eess.SY

TL;DR: 提出模块化最优控制框架用于三维椭球体障碍物避障，应用于模型预测路径跟踪控制，处理静态和动态障碍物，通过两阶段优化解决数值问题，并在Crazyflie四旋翼上进行了硬件验证。


<details>
  <summary>Details</summary>
Motivation: 为无人机在三维环境中实现有效的障碍物避障控制，需要处理椭球体形状的障碍物（包括静态和动态），并解决由此产生的数值计算问题。

Method: 采用模块化最优控制框架，提出计算高效且连续可微的椭球体碰撞检测条件，使用新颖的两阶段优化方法缓解最优控制问题的数值问题。

Result: 通过仿真和Crazyflie四旋翼的真实世界实验验证了方法的有效性，这是此类MPC控制器在无人机三维任务中的首次硬件演示。

Conclusion: 该框架成功实现了三维椭球体障碍物避障，解决了相关数值问题，并在实际硬件上得到验证，为无人机在复杂环境中的安全导航提供了有效解决方案。

Abstract: This article proposes a modular optimal control framework for local
three-dimensional ellipsoidal obstacle avoidance, exemplarily applied to model
predictive path-following control. Static as well as moving obstacles are
considered. Central to the approach is a computationally efficient and
continuously differentiable condition for detecting collisions with ellipsoidal
obstacles. A novel two-stage optimization approach mitigates numerical issues
arising from the structure of the resulting optimal control problem. The
effectiveness of the approach is demonstrated through simulations and
real-world experiments with the Crazyflie quadrotor. This represents the first
hardware demonstration of an MPC controller of this kind for UAVs in a
three-dimensional task.

</details>


### [66] [Two-Timescale Optimization Framework for IAB-Enabled Heterogeneous UAV Networks](https://arxiv.org/abs/2510.26578)
*Jikang Deng,Hui Zhou,Mohamed-Slim Alouini*

Main category: eess.SY

TL;DR: 提出了一种结合系留无人机和无人机的异构无人机框架，用于灾后应急通信，通过多智能体强化学习算法优化用户调度和轨迹控制，提升下行吞吐量。


<details>
  <summary>Details</summary>
Motivation: 传统无人机因尺寸、重量和功率限制无法支持宏基站运行，灾后需要快速部署通信基础设施支持搜救和恢复行动。

Method: 采用系留无人机和无人机的异构框架，使用集成接入和回传技术，提出基于集中训练分布式执行的两时间尺度多智能体深度确定性策略梯度算法。

Result: 所提算法优于其他基准方法，包括两时间尺度多智能体近端策略优化算法和MADDPG调度方法，平均吞吐量增益最高达12.2%。

Conclusion: 异构无人机框架结合多智能体强化学习能有效提升灾后应急通信性能，满足非对称流量需求和用户移动性要求。

Abstract: In post-disaster scenarios, the rapid deployment of adequate communication
infrastructure is essential to support disaster search, rescue, and recovery
operations. To achieve this, uncrewed aerial vehicle (UAV) has emerged as a
promising solution for emergency communication due to its low cost and
deployment flexibility. However, conventional untethered UAV (U-UAV) is
constrained by size, weight, and power (SWaP) limitations, making it incapable
of maintaining the operation of a macro base station. To address this
limitation, we propose a heterogeneous UAV-based framework that integrates
tethered UAV (T-UAV) and U-UAVs, where U-UAVs are utilized to enhance the
throughput of cell-edge ground user equipments (G-UEs) and guarantee seamless
connectivity during G-UEs' mobility to safe zones. It is noted that the
integrated access and backhaul (IAB) technique is adopted to support the
wireless backhaul of U-UAVs. Accordingly, we formulate a two-timescale joint
user scheduling and trajectory control optimization problem, aiming to maximize
the downlink throughput under asymmetric traffic demands and G-UEs' mobility.
To solve the formulated problem, we proposed a two-timescale multi-agent deep
deterministic policy gradient (TTS-MADDPG) algorithm based on the centralized
training and distributed execution paradigm. Numerical results show that the
proposed algorithm outperforms other benchmarks, including the two-timescale
multi-agent proximal policy optimization (TTS-MAPPO) algorithm and MADDPG
scheduling method, with robust and higher throughput. Specifically, the
proposed algorithm obtains up to 12.2\% average throughput gain compared to the
MADDPG scheduling method.

</details>


### [67] [Optimal Bidding and Coordinated Dispatch of Hybrid Energy Systems in Regulation Markets](https://arxiv.org/abs/2510.26602)
*Tanmay Mishra,Dakota Hamilton,Mads R. Almassalkhi*

Main category: eess.SY

TL;DR: 提出了一个双层框架，使混合能源系统能够参与频率调节市场，上层进行机会约束优化选择容量投标，下层实时控制策略在组成资源间分配调节功率。


<details>
  <summary>Details</summary>
Motivation: 可再生能源和分布式能源资源在现代电力系统中的日益集成带来了显著的不确定性，对维持电网灵活性和可靠性构成挑战。混合能源系统提供分散化解决方案以增强灵活性。

Method: 采用双层框架：上层基于历史调节信号进行机会约束优化选择容量投标；下层实施实时控制策略在可控发电机、灵活负荷和电池存储等组成资源间分配调节功率。

Result: 框架评估了超额投标策略的盈利能力，识别了可能导致市场惩罚或取消资格的性能退化阈值，并比较了功率容量不平衡对性能和电池荷电状态的影响。

Conclusion: 该框架为混合能源系统参与频率调节市场提供了有效方法，能够平衡灵活性和经济效益，同时识别关键性能阈值以避免市场惩罚。

Abstract: The increasing integration of renewable energy sources and distributed energy
resources (DER) into modern power systems introduces significant uncertainty,
posing challenges for maintaining grid flexibility and reliability. Hybrid
energy systems (HES), composed of controllable generators, flexible loads, and
battery storage, offer a decentralized solution to enhance flexibility compared
to single centralized resources. This paper presents a two-level framework to
enable HES participation in frequency regulation markets. The upper level
performs a chance-constrained optimization to choose capacity bids based on
historical regulation signals. At the lower level, a real-time control strategy
disaggregates the regulation power among the constituent resources. This
real-time control strategy is then benchmarked against an offline optimal
dispatch to evaluate flexibility performance. Additionally, the framework
evaluates the profitability of overbidding strategies and identifies thresholds
beyond which performance degradation may lead to market penalties or
disqualification. The proposed framework also compare the impact of imbalance
of power capacities on performance and battery state of charge (SoC) through
asymmetric HES configurations.

</details>


### [68] [Graph approach for observability analysis in power system dynamic state estimation](https://arxiv.org/abs/2510.26701)
*Akhila Kandivalasa,Marcos Netto*

Main category: eess.SY

TL;DR: 提出了一种用于动态状态估计的图论可观测性分析方法，该方法在计算时间上比现有方法快1440倍，且计算复杂度与图节点和边数呈线性关系。


<details>
  <summary>Details</summary>
Motivation: 现有的可观测性分析方法主要针对电力系统静态状态估计，缺乏针对动态状态估计的有效方法。现有方法计算复杂度高，难以扩展到大规模系统。

Method: 基于状态空间框架构建图模型，仅需了解状态变量之间以及输出变量与状态变量之间的依赖关系，开发了线性时间复杂度的数值方法。

Result: 在集中式动态状态估计场景中，该方法比现有非可扩展方法计算时间减少1440倍，验证了方法的效率和可扩展性。

Conclusion: 该方法首次实现了动态状态估计的可观测性分析，具有线性时间复杂度和显著的计算效率优势，适用于大规模电力系统分析。

Abstract: The proposed approach yields a numerical method that provably executes in
linear time with respect to the number of nodes and edges in a graph. The
graph, constructed from the power system model, requires only knowledge of the
dependencies between state-to-state and output-to-state variables within a
state-space framework. While graph-based observability analysis methods exist
for power system static-state estimation, the approach presented here is the
first for dynamic-state estimation (DSE). We examine decentralized and
centralized DSE scenarios and compare our findings with a well-established,
albeit non-scalable, observability analysis method in the literature. When
compared to the latter in a centralized DSE setting, our method reduced
computation time by 1440x.

</details>


### [69] [Pareto-Optimal Sampling and Resource Allocation for Timely Communication in Shared-Spectrum Low-Altitude Networks](https://arxiv.org/abs/2510.26708)
*Bowen Li,Jiping Luo,Themistoklis Charalambous,Nikolaos Pappas*

Main category: eess.SY

TL;DR: 提出了一种基于图论的算法来解决无人机在共享频谱中的双目标帕累托优化问题，平衡能量消耗和频谱资源占用，满足数据新鲜度要求。


<details>
  <summary>Details</summary>
Motivation: 低空无人机在共享频谱中需要同时满足严格的数据新鲜度要求，并平衡自身能量消耗和地面信道资源占用这两个运营成本之间的关键权衡。

Method: 利用预测性信道模型和无人机轨迹，将双目标帕累托优化问题转化为多个单目标问题，提出基于图的新算法来完整描述帕累托前沿。

Result: 数值比较显示，该方法满足严格时效性要求，相比基准方法实现了6倍的资源块利用率减少或6dB的能量节省。

Conclusion: 所提出的图基算法能够以低复杂度找到完整的帕累托最优解集，在时域上线性复杂度，在资源块预算上接近二次复杂度。

Abstract: Guaranteeing stringent data freshness for low-altitude unmanned aerial
vehicles (UAVs) in shared spectrum forces a critical trade-off between two
operational costs: the UAV's own energy consumption and the occupation of
terrestrial channel resources. The core challenge is to satisfy the aerial data
freshness while finding a Pareto-optimal balance between these costs.
Leveraging predictive channel models and predictive UAV trajectories, we
formulate a bi-objective Pareto optimization problem over a long-term planning
horizon to jointly optimize the sampling timing for aerial traffic and the
power and spectrum allocation for fair coexistence. However, the problem's
non-convex, mixed-integer nature renders classical methods incapable of fully
characterizing the complete Pareto frontier. Notably, we show monotonicity
properties of the frontier, building on which we transform the bi-objective
problem into several single-objective problems. We then propose a new
graph-based algorithm and prove that it can find the complete set of Pareto
optima with low complexity, linear in the horizon and near-quadratic in the
resource block (RB) budget. Numerical comparisons show that our approach meets
the stringent timeliness requirement and achieves a six-fold reduction in RB
utilization or a 6 dB energy saving compared to benchmarks.

</details>


### [70] [Time-Optimal Model Predictive Control for Linear Systems with Multiplicative Uncertainties](https://arxiv.org/abs/2510.26712)
*Renato Quartullo,Andrea Garulli,Mirko Leomanni*

Main category: eess.SY

TL;DR: 提出了一种针对区间矩阵表示乘性不确定性的线性离散时间系统的时间最优模型预测控制方案，使用矩阵zonotope边界算子近似处理不确定性传播，通过自适应终端约束确保递归可行性和有限时间收敛。


<details>
  <summary>Details</summary>
Motivation: 处理线性离散时间系统中存在的乘性不确定性，特别是由区间矩阵表示的不确定性，需要开发计算上可行的控制方法，同时保证系统性能和控制目标的实现。

Method: 采用矩阵zonotope边界算子近似处理集合值误差系统动力学的不确定性传播，设计自适应终端约束机制，并离线计算所有必要的边界集合以降低在线计算负担。

Result: 所提出的方法在计算上可行，能够有效处理乘性不确定性，并通过卫星轨道交会机动的数值案例研究验证了其有效性。

Conclusion: 该时间最优MPC方案为处理区间矩阵乘性不确定性的线性系统提供了一种计算高效且性能可靠的控制策略，特别适用于如卫星轨道交会等关键任务。

Abstract: This paper presents a time-optimal Model Predictive Control (MPC) scheme for
linear discrete-time systems subject to multiplicative uncertainties
represented by interval matrices. To render the uncertainty propagation
computationally tractable, the set-valued error system dynamics are
approximated using a matrix-zonotope-based bounding operator. Recursive
feasibility and finite-time convergence are ensured through an adaptive
terminal constraint mechanism. A key advantage of the proposed approach is that
all the necessary bounding sets can be computed offline, substantially reducing
the online computational burden. The effectiveness of the method is illustrated
via a numerical case study on an orbital rendezvous maneuver between two
satellites.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [71] [Debate2Create: Robot Co-design via Large Language Model Debates](https://arxiv.org/abs/2510.25850)
*Kevin Qiu,Marek Cygan*

Main category: cs.RO

TL;DR: D2C框架通过LLM代理进行结构化辩论，共同优化机器人形态和控制，在四足机器人运动基准上发现比默认设计行进距离远73%的设计


<details>
  <summary>Details</summary>
Motivation: 自动化机器人形态和控制的协同设计是一个长期挑战，因为设计空间巨大且身体与行为紧密耦合

Method: 设计代理提出形态修改，控制代理设计奖励函数，多元评委在模拟中评估设计-控制对并提供反馈，通过迭代辩论逐步优化

Result: D2C产生了多样化和专业化的形态，无需显式多样性目标；在四足运动基准上发现比默认设计行进距离远73%的设计

Conclusion: 基于LLM的结构化辩论结合物理基础反馈，是自动化机器人设计的有前景的新范式

Abstract: Automating the co-design of a robot's morphology and control is a
long-standing challenge due to the vast design space and the tight coupling
between body and behavior. We introduce Debate2Create (D2C), a framework in
which large language model (LLM) agents engage in a structured dialectical
debate to jointly optimize a robot's design and its reward function. In each
round, a design agent proposes targeted morphological modifications, and a
control agent devises a reward function tailored to exploit the new design. A
panel of pluralistic judges then evaluates the design-control pair in
simulation and provides feedback that guides the next round of debate. Through
iterative debates, the agents progressively refine their proposals, producing
increasingly effective robot designs. Notably, D2C yields diverse and
specialized morphologies despite no explicit diversity objective. On a
quadruped locomotion benchmark, D2C discovers designs that travel 73% farther
than the default, demonstrating that structured LLM-based debate can serve as a
powerful mechanism for emergent robot co-design. Our results suggest that
multi-agent debate, when coupled with physics-grounded feedback, is a promising
new paradigm for automated robot design.

</details>


### [72] [Risk-Aware Safety Filters with Poisson Safety Functions and Laplace Guidance Fields](https://arxiv.org/abs/2510.25913)
*Gilbert Bahati,Ryan M. Bena,Meg Wilkinson,Pol Mestres,Ryan K. Cosner,Aaron D. Ames*

Main category: cs.RO

TL;DR: 提出了一种基于泊松方程和拉普拉斯引导场的风险感知安全滤波器，用于机器人系统的安全导航。


<details>
  <summary>Details</summary>
Motivation: 机器人系统在真实环境中导航需要语义理解来确保安全动作，特别是需要风险感知的安全表示。

Method: 采用两步法：通过泊松方程求解Dirichlet问题生成安全函数，通过拉普拉斯方程求解Dirichlet问题合成安全引导场，两者结合构建风险感知安全滤波器。

Result: 在仿真中验证了该方法能够保证安全性的同时，优先避开高风险障碍物。

Conclusion: 该方法能够将先验的障碍物风险知识直接整合到安全滤波器中，生成风险感知的安全行为。

Abstract: Robotic systems navigating in real-world settings require a semantic
understanding of their environment to properly determine safe actions. This
work aims to develop the mathematical underpinnings of such a representation --
specifically, the goal is to develop safety filters that are risk-aware. To
this end, we take a two step approach: encoding an understanding of the
environment via Poisson's equation, and associated risk via Laplace guidance
fields. That is, we first solve a Dirichlet problem for Poisson's equation to
generate a safety function that encodes system safety as its 0-superlevel set.
We then separately solve a Dirichlet problem for Laplace's equation to
synthesize a safe \textit{guidance field} that encodes variable levels of
caution around obstacles -- by enforcing a tunable flux boundary condition. The
safety function and guidance fields are then combined to define a safety
constraint and used to synthesize a risk-aware safety filter which, given a
semantic understanding of an environment with associated risk levels of
environmental features, guarantees safety while prioritizing avoidance of
higher risk obstacles. We demonstrate this method in simulation and discuss how
\textit{a priori} understandings of obstacle risk can be directly incorporated
into the safety filter to generate safe behaviors that are risk-aware.

</details>


### [73] [Curvature-Aware Calibration of Tactile Sensors for Accurate Force Estimation on Non-Planar Surfaces](https://arxiv.org/abs/2510.25965)
*Luoyan Zhong,Heather Jin Hee Kim,Dylan P. Losey,Cara M. Nunez*

Main category: cs.RO

TL;DR: 开发了一种用于电阻式触觉传感器的曲率感知校准模型，通过神经网络预测局部曲率，在弯曲表面上保持一致的力测量精度


<details>
  <summary>Details</summary>
Motivation: 现有触觉传感器主要在平坦基底上校准，一旦安装在弯曲几何表面上，其精度和一致性会下降，限制了在实际应用中的可靠性

Method: 为广泛使用的电阻式触觉传感器设计开发校准模型，训练多层感知器神经网络从无负载时的基线传感器输出预测局部曲率

Result: 在5个不同曲率的日常物体上验证，曲率感知校准在所有表面上保持一致的力精度，而平坦表面校准随着曲率增加会低估力，神经网络预测曲率的R2分数达到0.91

Conclusion: 曲率感知建模提高了柔性触觉传感器的精度、一致性和可靠性，使其能够在实际应用中实现可靠的性能

Abstract: Flexible tactile sensors are increasingly used in real-world applications
such as robotic grippers, prosthetic hands, wearable gloves, and assistive
devices, where they need to conform to curved and irregular surfaces. However,
most existing tactile sensors are calibrated only on flat substrates, and their
accuracy and consistency degrade once mounted on curved geometries. This
limitation restricts their reliability in practical use. To address this
challenge, we develop a calibration model for a widely used resistive tactile
sensor design that enables accurate force estimation on one-dimensional curved
surfaces. We then train a neural network (a multilayer perceptron) to predict
local curvature from baseline sensor outputs recorded under no applied load,
achieving an R2 score of 0.91. The proposed approach is validated on five daily
objects with varying curvatures under forces from 2 N to 8 N. Results show that
the curvature-aware calibration maintains consistent force accuracy across all
surfaces, while flat-surface calibration underestimates force as curvature
increases. Our results demonstrate that curvature-aware modeling improves the
accuracy, consistency, and reliability of flexible tactile sensors, enabling
dependable performance across real-world applications.

</details>


### [74] [A New Type of Axis-Angle Attitude Control Law for Rotational Systems: Synthesis, Analysis, and Experiments](https://arxiv.org/abs/2510.25985)
*Francisco M. F. R. Gonçalves,Ryan M. Bena,Néstor O. Pérez-Arancibia*

Main category: cs.RO

TL;DR: 提出了一种基于欧拉轴角的姿态控制新方法，相比传统的四元数方法，能保证闭环系统存在唯一平衡点，并提供更灵活的比例控制能力。


<details>
  <summary>Details</summary>
Motivation: 传统四元数姿态控制方法存在两个问题：无法保证闭环系统存在唯一的平衡姿态误差四元数；当绕姿态误差欧拉轴的旋转误差超过π弧度时，比例控制效果会随着系统状态远离稳定平衡点而减弱。

Method: 开发了一种新型姿态控制律，更有效地利用姿态误差欧拉轴角信息，通过构建严格的Lyapunov函数来证明闭环旋转系统的唯一平衡点具有一致渐近稳定性。

Result: 通过数值仿真和数十次小型四旋翼飞行器的实时翻滚恢复机动测试，证明所提出的轴角方法在稳定时间方面优于高性能四元数控制器。

Conclusion: 基于欧拉轴角的姿态控制方法在飞行性能上优于传统四元数方法，特别是在稳定时间方面表现更优，且能保证闭环系统的唯一平衡点和渐近稳定性。

Abstract: Over the past few decades, continuous quaternion-based attitude control has
been proven highly effective for driving rotational systems that can be modeled
as rigid bodies, such as satellites and drones. However, methods rooted in this
approach do not enforce the existence of a unique closed-loop (CL) equilibrium
attitude-error quaternion (AEQ); and, for rotational errors about the
attitude-error Euler axis larger than {\pi}rad, their proportional-control
effect diminishes as the system state moves away from the stable equilibrium of
the CL rotational dynamics. In this paper, we introduce a new type of attitude
control law that more effectively leverages the attitude-error Euler axis-angle
information to guarantee a unique CL equilibrium AEQ and to provide greater
flexibility in the use of proportional-control efforts. Furthermore, using two
different control laws as examples-through the construction of a strict
Lyapunov function for the CL dynamics-we demonstrate that the resulting unique
equilibrium of the CL rotational system can be enforced to be uniformly
asymptotically stable. To assess and demonstrate the functionality and
performance of the proposed approach, we performed numerical simulations and
executed dozens of real-time tumble-recovery maneuvers using a small quadrotor.
These simulations and flight tests compellingly demonstrate that the proposed
axis-angle-based method achieves superior flight performance-compared with that
obtained using a high-performance quaternion-based controller-in terms of
stabilization time.

</details>


### [75] [DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System](https://arxiv.org/abs/2510.26004)
*Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang*

Main category: cs.RO

TL;DR: DARTS是一个基于无人机和AI的实时交通事件检测系统，通过无人机的高机动性和热成像技术实现自适应监控，在佛罗里达州I-75公路测试中比传统方法提前12分钟检测到追尾事故。


<details>
  <summary>Details</summary>
Motivation: 传统交通事件检测方法存在检测与验证分离、灵活性有限、需要密集基础设施等问题，限制了适应性和可扩展性。

Method: 集成无人机高机动性和空中视角进行自适应监控，使用热成像技术提升低能见度性能和隐私保护，采用轻量级深度学习框架实时提取车辆轨迹和检测事件。

Result: 在自收集数据集上达到99%检测准确率，在佛罗里达州I-75公路现场测试中比当地交通管理中心提前12分钟检测到追尾事故，并能监控事件引发的拥堵传播。

Conclusion: DARTS展示了更灵活集成的实时交通事件检测系统的潜力，对现代交通管理的运营效率和响应能力具有重要意义，特别是在偏远地区和资源受限环境中具有可扩展性和成本效益。

Abstract: Rapid and reliable incident detection is critical for reducing crash-related
fatalities, injuries, and congestion. However, conventional methods, such as
closed-circuit television, dashcam footage, and sensor-based detection,
separate detection from verification, suffer from limited flexibility, and
require dense infrastructure or high penetration rates, restricting
adaptability and scalability to shifting incident hotspots. To overcome these
challenges, we developed DARTS, a drone-based, AI-powered real-time traffic
incident detection system. DARTS integrates drones' high mobility and aerial
perspective for adaptive surveillance, thermal imaging for better
low-visibility performance and privacy protection, and a lightweight deep
learning framework for real-time vehicle trajectory extraction and incident
detection. The system achieved 99% detection accuracy on a self-collected
dataset and supports simultaneous online visual verification, severity
assessment, and incident-induced congestion propagation monitoring via a
web-based interface. In a field test on Interstate 75 in Florida, DARTS
detected and verified a rear-end collision 12 minutes earlier than the local
transportation management center and monitored incident-induced congestion
propagation, suggesting potential to support faster emergency response and
enable proactive traffic control to reduce congestion and secondary crash risk.
Crucially, DARTS's flexible deployment architecture reduces dependence on
frequent physical patrols, indicating potential scalability and
cost-effectiveness for use in remote areas and resource-constrained settings.
This study presents a promising step toward a more flexible and integrated
real-time traffic incident detection system, with significant implications for
the operational efficiency and responsiveness of modern transportation
management.

</details>


### [76] [RADRON: Cooperative Localization of Ionizing Radiation Sources by MAVs with Compton Cameras](https://arxiv.org/abs/2510.26018)
*Petr Stibinger,Tomas Baca,Daniela Doubravova,Jan Rusnak,Jaroslav Solc,Jan Jakubek,Petr Stepan,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种使用微型无人机群协作定位放射性材料的新方法，利用轻量级康普顿相机检测电离辐射，通过融合测量数据实时估计辐射源位置，并动态控制无人机运动以最大化信息获取。


<details>
  <summary>Details</summary>
Motivation: 现有辐射检测方法在灵敏度和机动性方面存在局限，需要开发能够在复杂环境中快速定位辐射源的协作系统，特别是针对移动辐射源的追踪需求。

Method: 使用轻量级（40克）康普顿相机作为辐射探测器，安装在微型无人机上，通过融合多个无人机的康普顿相机测量数据来估计辐射源位置，并采用动态反馈控制无人机群的运动以优化信息收集。

Result: 实现了对辐射源的实时定位，能够处理极其稀疏的测量数据，系统能够稳定控制无人机群紧密协作，快速定位静态和移动辐射源。

Conclusion: 该方法展示了轻量级康普顿相机与协作无人机群结合的有效性，为辐射检测和定位提供了新的解决方案，特别适用于复杂环境和移动目标的追踪场景。

Abstract: We present a novel approach to localizing radioactive material by cooperating
Micro Aerial Vehicles (MAVs). Our approach utilizes a state-of-the-art
single-detector Compton camera as a highly sensitive, yet miniature detector of
ionizing radiation. The detector's exceptionally low weight (40 g) opens up new
possibilities of radiation detection by a team of cooperating agile MAVs. We
propose a new fundamental concept of fusing the Compton camera measurements to
estimate the position of the radiation source in real time even from extremely
sparse measurements. The data readout and processing are performed directly
onboard and the results are used in a dynamic feedback to drive the motion of
the vehicles. The MAVs are stabilized in a tightly cooperating swarm to
maximize the information gained by the Compton cameras, rapidly locate the
radiation source, and even track a moving radiation source.

</details>


### [77] [Accelerating Real-World Overtaking in F1TENTH Racing Employing Reinforcement Learning Methods](https://arxiv.org/abs/2510.26040)
*Emily Steiner,Daniel van der Spuy,Futian Zhou,Afereti Pama,Minas Liarokapis,Henry Williams*

Main category: cs.RO

TL;DR: 提出了一种能够在仿真和现实中可靠导航并超越对手的新型赛车和超车智能体，在真实F1Tenth车辆上部署并与其他竞争算法对抗，训练对抗对手的智能体超车率达到87%，而仅训练赛车的智能体为56%。


<details>
  <summary>Details</summary>
Motivation: 虽然自主赛车在计时赛场景中取得了显著进展，但在轮对轮赛车和超车方面仍然严重受限，特别是在现实驾驶场景中，最先进的算法难以安全可靠地完成超车操作。

Method: 开发了一种新型赛车和超车智能体，能够在F1Tenth平台上学习可靠导航和超车，并在仿真和现实中部署测试。

Result: 训练对抗对手的智能体实现了87%的超车率，相比之下仅训练赛车的智能体超车率为56%。

Conclusion: 通过对抗对手训练能够实现有意识的超车行为，显著提高超车成功率，这对于安全的自主轮对轮赛车至关重要。

Abstract: While autonomous racing performance in Time-Trial scenarios has seen
significant progress and development, autonomous wheel-to-wheel racing and
overtaking are still severely limited. These limitations are particularly
apparent in real-life driving scenarios where state-of-the-art algorithms
struggle to safely or reliably complete overtaking manoeuvres. This is
important, as reliable navigation around other vehicles is vital for safe
autonomous wheel-to-wheel racing. The F1Tenth Competition provides a useful
opportunity for developing wheel-to-wheel racing algorithms on a standardised
physical platform. The competition format makes it possible to evaluate
overtaking and wheel-to-wheel racing algorithms against the state-of-the-art.
This research presents a novel racing and overtaking agent capable of learning
to reliably navigate a track and overtake opponents in both simulation and
reality. The agent was deployed on an F1Tenth vehicle and competed against
opponents running varying competitive algorithms in the real world. The results
demonstrate that the agent's training against opponents enables deliberate
overtaking behaviours with an overtaking rate of 87% compared 56% for an agent
trained just to race.

</details>


### [78] [Morphology-Aware Graph Reinforcement Learning for Tensegrity Robot Locomotion](https://arxiv.org/abs/2510.26067)
*Chi Zhang,Mingrui Li,Wenzhe Tong,Xiaonan Huang*

Main category: cs.RO

TL;DR: 提出了一种基于图神经网络的强化学习框架，用于控制张拉整体机器人的运动，该方法在物理机器人上验证了优越的样本效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 张拉整体机器人具有高韧性和可部署性，但其欠驱动和高度耦合的动力学特性给运动控制带来了重大挑战。

Method: 将图神经网络集成到Soft Actor-Critic算法中，通过将机器人物理拓扑表示为图来捕捉组件间的耦合关系。

Result: 在物理3杆张拉整体机器人上验证了三种运动基元，显示出优越的样本效率、对噪声和刚度变化的鲁棒性，以及改进的轨迹精度。

Conclusion: 结果表明将结构先验知识融入强化学习对张拉整体机器人控制具有优势，学习到的策略无需微调即可从仿真直接转移到硬件。

Abstract: Tensegrity robots combine rigid rods and elastic cables, offering high
resilience and deployability but posing major challenges for locomotion control
due to their underactuated and highly coupled dynamics. This paper introduces a
morphology-aware reinforcement learning framework that integrates a graph
neural network (GNN) into the Soft Actor-Critic (SAC) algorithm. By
representing the robot's physical topology as a graph, the proposed GNN-based
policy captures coupling among components, enabling faster and more stable
learning than conventional multilayer perceptron (MLP) policies. The method is
validated on a physical 3-bar tensegrity robot across three locomotion
primitives, including straight-line tracking and bidirectional turning. It
shows superior sample efficiency, robustness to noise and stiffness variations,
and improved trajectory accuracy. Notably, the learned policies transfer
directly from simulation to hardware without fine-tuning, achieving stable
real-world locomotion. These results demonstrate the advantages of
incorporating structural priors into reinforcement learning for tensegrity
robot control.

</details>


### [79] [I don't Want You to Die: A Shared Responsibility Framework for Safeguarding Child-Robot Companionship](https://arxiv.org/abs/2510.26080)
*Fan Yang,Renkai Ma,Yaxin Hu,Michael Rodgers,Lingyao Li*

Main category: cs.RO

TL;DR: 研究调查了社交机器人（如Moxie）服务终止对儿童情感伤害的责任归属问题，发现责任被视为机器人公司、父母、开发者和政府的共同责任，但责任分配因政治意识形态和父母身份而异。


<details>
  <summary>Details</summary>
Motivation: 社交机器人与儿童建立强烈情感纽带后突然终止服务会造成显著困扰和痛苦，这引发了关于情感纽带断裂时责任归属的复杂问题。

Method: 以Moxie关闭为案例研究，通过对72名美国参与者进行定性调查。

Result: 责任被视为共享责任，但责任归属因政治意识形态和父母身份而异；参与者对机器人服务是否应继续的观点高度两极分化。

Conclusion: 研究提出了一个基于实证的共享责任框架，用于保护儿童-机器人伴侣关系，详细说明了责任如何分配和争议，为减轻机器人终止服务的情感伤害提供了具体的设计和政策启示。

Abstract: Social robots like Moxie are designed to form strong emotional bonds with
children, but their abrupt discontinuation can cause significant struggles and
distress to children. When these services end, the resulting harm raises
complex questions of who bears responsibility when children's emotional bonds
are broken. Using the Moxie shutdown as a case study through a qualitative
survey of 72 U.S. participants, our findings show that the responsibility is
viewed as a shared duty across the robot company, parents, developers, and
government. However, these attributions varied by political ideology and
parental status of whether they have children. Participants' perceptions of
whether the robot service should continue are highly polarized; supporters
propose technical, financial, and governmental pathways for continuity, while
opponents cite business realities and risks of unhealthy emotional dependency.
Ultimately, this research contributes an empirically grounded shared
responsibility framework for safeguarding child-robot companionship by
detailing how accountability is distributed and contested, informing concrete
design and policy implications to mitigate the emotional harm of robot
discontinuation.

</details>


### [80] [Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse](https://arxiv.org/abs/2510.26082)
*Fan Yang,Lingyao Li,Yaxin Hu,Michael Rodgers,Renkai Ma*

Main category: cs.RO

TL;DR: 研究探讨了机器人拟人化程度如何影响人们对机器人受虐的保护反应，发现中等拟人化机器人引发最强的愤怒反应，道德关注随拟人化程度增加而增强。


<details>
  <summary>Details</summary>
Motivation: 随着人形机器人的普及，需要了解不同拟人化程度如何影响人类对机器人受虐的道德反应，扩展CASA和恐怖谷理论到道德领域。

Method: 201名参与者观看三种拟人化程度（低-蜘蛛、中-双足、高-人形）机器人受虐视频，结合自我报告、生理数据（面部表情分析）和定性反思进行多模态分析。

Result: 中等拟人化机器人引发最强的生理愤怒反应和恐怖感；自我报告的愤怒和愧疚感在中等和高拟人化机器人中显著更高；道德推理随拟人化程度从财产损害评估转向谴责施虐者品格。

Conclusion: 恐怖谷效应不会削弱道德关注，反而增强保护冲动，对机器人设计、政策和未来法律框架具有重要启示。

Abstract: Robots with anthropomorphic features are increasingly shaping how humans
perceive and morally engage with them. Our research investigates how different
levels of anthropomorphism influence protective responses to robot abuse,
extending the Computers as Social Actors (CASA) and uncanny valley theories
into a moral domain. In an experiment, we invite 201 participants to view
videos depicting abuse toward a robot with low (Spider), moderate (Two-Foot),
or high (Humanoid) anthropomorphism. To provide a comprehensive analysis, we
triangulate three modalities: self-report surveys measuring emotions and
uncanniness, physiological data from automated facial expression analysis, and
qualitative reflections. Findings indicate that protective responses are not
linear. The moderately anthropomorphic Two-Foot robot, rated highest in
eeriness and "spine-tingling" sensations consistent with the uncanny valley,
elicited the strongest physiological anger expressions. Self-reported anger and
guilt are significantly higher for both the Two-Foot and Humanoid robots
compared to the Spider. Qualitative findings further reveal that as
anthropomorphism increases, moral reasoning shifts from technical assessments
of property damage to condemnation of the abuser's character, while governance
proposals expand from property law to calls for quasi-animal rights and broader
societal responsibility. These results suggest that the uncanny valley does not
dampen moral concern but paradoxically heightens protective impulses, offering
critical implications for robot design, policy, and future legal frameworks.

</details>


### [81] [Embodied Intelligence for Advanced Bioinspired Microrobotics: Examples and Insights](https://arxiv.org/abs/2510.26132)
*Nestor O. Perez-Arancibia*

Main category: cs.RO

TL;DR: 本文探讨了具身智能作为微型机器人设计原则，强调结构与功能协同设计的重要性，通过多个机器人平台展示了智能行为如何从结构动力学和物理交互中涌现。


<details>
  <summary>Details</summary>
Motivation: 传统机器人架构将感知、计算和执行解耦，而具身智能方法通过将智能行为嵌入到物理结构和材料特性中，为微型机器人提供更可扩展和鲁棒的解决方案。

Method: 采用协同设计方法，同时开发物理结构和行为功能，通过结构动力学、物理交互和环境反馈实现智能行为，无需复杂的计算控制。

Result: 开发了Bee++、RoBeetle、SMALLBug等多个微型机器人平台，这些平台展示了从物理特性中涌现的智能行为，如自主导航和运动控制。

Conclusion: 协同设计不仅是约束条件下的经验优化方法，更是实现具身智能的关键，为毫米到厘米尺度的机器人提供了比传统控制更可扩展和鲁棒的替代方案。

Abstract: The term embodied intelligence (EI) conveys the notion that body morphology,
material properties, interaction with the environment, and control strategies
can be purposefully integrated into the process of robotic design to generate
intelligent behavior; in particular, locomotion and navigation. In this paper,
we discuss EI as a design principle for advanced microrobotics, with a
particular focus on co-design -- the simultaneous and interdependent
development of physical structure and behavioral function. To illustrate the
contrast between EI-inspired systems and traditional architectures that
decouple sensing, computation, and actuation, we present and discuss a
collection of robots developed by the author and his team at the Autonomous
Microrobotic Systems Laboratory (AMSL). These robots exhibit intelligent
behavior that emerges from their structural dynamics and the physical
interaction between their components and with the environment. Platforms such
as the Bee++, RoBeetle, SMALLBug, SMARTI, WaterStrider, VLEIBot+, and FRISSHBot
exemplify how feedback loops, decision logics, sensing mechanisms, and smart
actuation strategies can be embedded into the physical properties of the
robotic system itself. Along these lines, we contend that co-design is not only
a method for empirical optimization under constraints, but also an enabler of
EI, offering a scalable and robust alternative to classical control for
robotics at the mm-to-cm-scale.

</details>


### [82] [Kinodynamic Task and Motion Planning using VLM-guided and Interleaved Sampling](https://arxiv.org/abs/2510.26139)
*Minseo Kwon,Young J. Kim*

Main category: cs.RO

TL;DR: 提出了一个基于混合状态树的动力学TAMP框架，将符号和数值状态统一表示，结合视觉语言模型引导搜索，显著提高了任务和运动规划的成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有TAMP方法在长时域问题中由于过度运动采样而成本高昂，而LLMs虽然提供常识先验但缺乏3D空间推理能力，无法确保几何或动力学可行性。

Method: 使用混合状态树统一表示符号和数值状态，通过现成运动规划器和物理模拟器验证动力学约束，利用VLM基于状态视觉渲染引导TAMP解决方案探索和回溯搜索。

Result: 在模拟和真实世界实验中，相比传统和基于LLM的TAMP规划器，平均成功率提高了32.14%-1166.67%，复杂问题规划时间减少。

Conclusion: 该框架通过统一表示和VLM引导有效解决了TAMP中的运动采样效率和空间推理问题，显著提升了规划性能。

Abstract: Task and Motion Planning (TAMP) integrates high-level task planning with
low-level motion feasibility, but existing methods are costly in long-horizon
problems due to excessive motion sampling. While LLMs provide commonsense
priors, they lack 3D spatial reasoning and cannot ensure geometric or dynamic
feasibility. We propose a kinodynamic TAMP framework based on a hybrid state
tree that uniformly represents symbolic and numeric states during planning,
enabling task and motion decisions to be jointly decided. Kinodynamic
constraints embedded in the TAMP problem are verified by an off-the-shelf
motion planner and physics simulator, and a VLM guides exploring a TAMP
solution and backtracks the search based on visual rendering of the states.
Experiments on the simulated domains and in the real world show 32.14% -
1166.67% increased average success rates compared to traditional and LLM-based
TAMP planners and reduced planning time on complex problems, with ablations
further highlighting the benefits of VLM guidance.

</details>


### [83] [Adaptive Trajectory Refinement for Optimization-based Local Planning in Narrow Passages](https://arxiv.org/abs/2510.26142)
*Hahjin Lee,Young J. Kim*

Main category: cs.RO

TL;DR: 提出自适应轨迹细化算法，通过路径段级保守碰撞检测和位姿级安全校正，解决移动机器人在狭窄通道环境中的轨迹规划问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法在狭窄通道环境中经常失败或生成次优路径，需要解决移动机器人在复杂环境中的安全轨迹规划挑战。

Method: 采用两阶段方法：1) 路径段级安全保证 - 对风险路径段进行递归细分直到消除碰撞风险；2) 位姿级安全保证 - 基于穿透方向和线搜索进行位姿校正，确保每个位姿无碰撞且远离障碍物。

Result: 仿真结果显示，相比现有最优方法，成功率提高1.69倍，规划时间加快3.79倍；真实实验证实机器人能安全通过狭窄通道并保持快速规划性能。

Conclusion: 所提算法在狭窄通道环境中显著提高了轨迹规划的成功率和效率，实现了安全且快速的移动机器人导航。

Abstract: Trajectory planning for mobile robots in cluttered environments remains a
major challenge due to narrow passages, where conventional methods often fail
or generate suboptimal paths. To address this issue, we propose the adaptive
trajectory refinement algorithm, which consists of two main stages. First, to
ensure safety at the path-segment level, a segment-wise conservative collision
test is applied, where risk-prone trajectory path segments are recursively
subdivided until collision risks are eliminated. Second, to guarantee
pose-level safety, pose correction based on penetration direction and line
search is applied, ensuring that each pose in the trajectory is collision-free
and maximally clear from obstacles. Simulation results demonstrate that the
proposed method achieves up to 1.69x higher success rates and up to 3.79x
faster planning times than state-of-the-art approaches. Furthermore, real-world
experiments confirm that the robot can safely pass through narrow passages
while maintaining rapid planning performance.

</details>


### [84] [Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations](https://arxiv.org/abs/2510.26362)
*Tobias Löw,Cem Bilaloglu,Sylvain Calinon*

Main category: cs.RO

TL;DR: 本文提出了基于共形几何代数的多臂机器人系统协作任务空间理论框架，通过几何基元的相似变换将复杂系统抽象为类似单臂系统，并推导了相应的雅可比矩阵，便于集成到经典控制方法中。


<details>
  <summary>Details</summary>
Motivation: 人类环境中的许多任务需要多个运动链的协作行为，如搬运大件物品或灵巧操作，但这些高自由度系统的协调运动建模非常困难。

Method: 使用共形几何代数定义协作几何基元，通过相似变换抽象复杂机器人系统，推导解析和几何雅可比矩阵，集成到操作空间控制中。

Result: 在双手机器人、仿人机器人和多指手的实验验证中，实现了期望几何基元的优化控制和微分运动学遥操作，并展示了零空间结构的自然嵌入。

Conclusion: 这项工作为协作操作控制框架奠定了理论基础，实验以抽象方式呈现，并为未来应用提供了方向。

Abstract: Many tasks in human environments require collaborative behavior between
multiple kinematic chains, either to provide additional support for carrying
big and bulky objects or to enable the dexterity that is required for in-hand
manipulation. Since these complex systems often have a very high number of
degrees of freedom coordinating their movements is notoriously difficult to
model. In this article, we present the derivation of the theoretical
foundations for cooperative task spaces of multi-arm robotic systems based on
geometric primitives defined using conformal geometric algebra. Based on the
similarity transformations of these cooperative geometric primitives, we derive
an abstraction of complex robotic systems that enables representing these
systems in a way that directly corresponds to single-arm systems. By deriving
the associated analytic and geometric Jacobian matrices, we then show the
straightforward integration of our approach into classical control techniques
rooted in operational space control. We demonstrate this using bimanual
manipulators, humanoids and multi-fingered hands in optimal control experiments
for reaching desired geometric primitives and in teleoperation experiments
using differential kinematics control. We then discuss how the geometric
primitives naturally embed nullspace structures into the controllers that can
be exploited for introducing secondary control objectives. This work,
represents the theoretical foundations of this cooperative manipulation control
framework, and thus the experiments are presented in an abstract way, while
giving pointers towards potential future applications.

</details>


### [85] [Self-localization on a 3D map by fusing global and local features from a monocular camera](https://arxiv.org/abs/2510.26170)
*Satoshi Kikuch,Masaya Kato,Tsuyoshi Tasaki*

Main category: cs.RO

TL;DR: 提出结合CNN和Vision Transformer的新方法，用于在动态障碍物存在时的3D地图自定位，相比现有方法精度提升1.5倍，定位误差减少20.1%。


<details>
  <summary>Details</summary>
Motivation: 使用廉价单目相机实现自动驾驶需要3D地图自定位，但现有基于CNN的方法在动态障碍物存在时效果不佳，因为CNN主要提取局部特征。

Method: 结合CNN和Vision Transformer，CNN提取局部特征，Vision Transformer提取全局特征（图像块间的关系）。

Result: 在CG数据集上，有动态障碍物时的精度提升率比无动态障碍物时高1.5倍；在公共数据集上定位误差比SOTA减少20.1%；机器人平均定位误差为7.51cm，优于SOTA。

Conclusion: CNN与Vision Transformer的结合能有效提升在动态障碍物环境下的自定位精度，为自动驾驶提供更可靠的定位方案。

Abstract: Self-localization on a 3D map by using an inexpensive monocular camera is
required to realize autonomous driving. Self-localization based on a camera
often uses a convolutional neural network (CNN) that can extract local features
that are calculated by nearby pixels. However, when dynamic obstacles, such as
people, are present, CNN does not work well. This study proposes a new method
combining CNN with Vision Transformer, which excels at extracting global
features that show the relationship of patches on whole image. Experimental
results showed that, compared to the state-of-the-art method (SOTA), the
accuracy improvement rate in a CG dataset with dynamic obstacles is 1.5 times
higher than that without dynamic obstacles. Moreover, the self-localization
error of our method is 20.1% smaller than that of SOTA on public datasets.
Additionally, our robot using our method can localize itself with 7.51cm error
on average, which is more accurate than SOTA.

</details>


### [86] [PHUMA: Physically-Grounded Humanoid Locomotion Dataset](https://arxiv.org/abs/2510.26236)
*Kyungmin Lee,Sibeen Kim,Minho Park,Hyunseung Kim,Dongyoon Hwang,Hojoon Lee,Jaegul Choo*

Main category: cs.RO

TL;DR: PHUMA是一个基于物理约束的人形机器人运动数据集，通过大规模人类视频和物理约束重定向技术解决现有数据集的物理伪影问题，在运动模仿任务中表现优于Humanoid-X和AMASS。


<details>
  <summary>Details</summary>
Motivation: 现有运动捕捉数据集如AMASS稀缺且昂贵，而基于互联网视频的方法如Humanoid-X存在漂浮、穿透、脚滑等物理伪影，限制了运动模仿的稳定性和多样性。

Method: 利用大规模人类视频，通过精心数据筛选和物理约束重定向技术，强制执行关节限制、确保地面接触、消除脚滑，生成大规模且物理可靠的运动数据。

Result: 在未见运动模仿和骨盆引导路径跟随两种条件下，PHUMA训练的策略均优于Humanoid-X和AMASS，在模仿多样化运动方面取得显著提升。

Conclusion: PHUMA通过物理约束的数据处理方法，成功解决了现有运动数据集的物理伪影问题，为人形机器人运动模仿提供了大规模且物理可靠的数据基础。

Abstract: Motion imitation is a promising approach for humanoid locomotion, enabling
agents to acquire humanlike behaviors. Existing methods typically rely on
high-quality motion capture datasets such as AMASS, but these are scarce and
expensive, limiting scalability and diversity. Recent studies attempt to scale
data collection by converting large-scale internet videos, exemplified by
Humanoid-X. However, they often introduce physical artifacts such as floating,
penetration, and foot skating, which hinder stable imitation. In response, we
introduce PHUMA, a Physically-grounded HUMAnoid locomotion dataset that
leverages human video at scale, while addressing physical artifacts through
careful data curation and physics-constrained retargeting. PHUMA enforces joint
limits, ensures ground contact, and eliminates foot skating, producing motions
that are both large-scale and physically reliable. We evaluated PHUMA in two
sets of conditions: (i) imitation of unseen motion from self-recorded test
videos and (ii) path following with pelvis-only guidance. In both cases,
PHUMA-trained policies outperform Humanoid-X and AMASS, achieving significant
gains in imitating diverse motions. The code is available at
https://davian-robotics.github.io/PHUMA.

</details>


### [87] [Thor: Towards Human-Level Whole-Body Reactions for Intense Contact-Rich Environments](https://arxiv.org/abs/2510.26280)
*Gangyang Li,Qing Shi,Youhao Hu,Jincheng Hu,Zhongyuan Wang,Xinlong Wang,Shaqi Luo*

Main category: cs.RO

TL;DR: 提出Thor人形机器人框架，通过力自适应躯干倾斜奖励函数和解耦强化学习架构，显著提升人形机器人在接触丰富环境中的力交互能力，在Unitree G1上实现了接近人类水平的全身反应。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在服务、工业和救援应用中需要保持全身稳定性，同时与环境进行强烈的接触交互，但目前难以产生类似人类的适应性响应。

Method: 基于机器人力学分析设计力自适应躯干倾斜奖励函数，采用解耦强化学习架构将上体、腰部和下体分开控制，共享全局观测并联合更新参数。

Result: 在Unitree G1上测试，向后移动时峰值拉力达167.7N（约G1体重的48%），向前移动时145.5N，相比最佳基线分别提升68.9%和74.7%。能拉动130N负载架和单手打开60N防火门。

Conclusion: Thor框架有效增强了人形机器人的力交互能力，在接触丰富环境中表现出接近人类水平的适应性响应。

Abstract: Humanoids hold great potential for service, industrial, and rescue
applications, in which robots must sustain whole-body stability while
performing intense, contact-rich interactions with the environment. However,
enabling humanoids to generate human-like, adaptive responses under such
conditions remains a major challenge. To address this, we propose Thor, a
humanoid framework for human-level whole-body reactions in contact-rich
environments. Based on the robot's force analysis, we design a force-adaptive
torso-tilt (FAT2) reward function to encourage humanoids to exhibit human-like
responses during force-interaction tasks. To mitigate the high-dimensional
challenges of humanoid control, Thor introduces a reinforcement learning
architecture that decouples the upper body, waist, and lower body. Each
component shares global observations of the whole body and jointly updates its
parameters. Finally, we deploy Thor on the Unitree G1, and it substantially
outperforms baselines in force-interaction tasks. Specifically, the robot
achieves a peak pulling force of 167.7 N (approximately 48% of the G1's body
weight) when moving backward and 145.5 N when moving forward, representing
improvements of 68.9% and 74.7%, respectively, compared with the
best-performing baseline. Moreover, Thor is capable of pulling a loaded rack
(130 N) and opening a fire door with one hand (60 N). These results highlight
Thor's effectiveness in enhancing humanoid force-interaction capabilities.

</details>


### [88] [AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM](https://arxiv.org/abs/2510.26358)
*Mirko Usuelli,David Rapado-Rincon,Gert Kootstra,Matteo Matteucci*

Main category: cs.RO

TL;DR: AgriGS-SLAM是一个用于果园环境的视觉-LiDAR SLAM框架，结合直接LiDAR里程计和多相机3D高斯泼溅渲染，能在季节变化和风动干扰下实现实时3D场景理解。


<details>
  <summary>Details</summary>
Motivation: 果园环境中的自主机器人需要实时3D场景理解，但面临重复行几何、季节性外观变化和风驱树叶运动等挑战。

Method: 结合直接LiDAR里程计和闭环检测，使用多相机3D高斯泼溅渲染，通过批量栅格化恢复被遮挡的果园结构，采用统一梯度驱动的地图生命周期管理。

Result: 在苹果和梨园中跨休眠期、开花期和收获期进行部署测试，相比现有3DGS-SLAM基线方法，提供更清晰稳定的重建效果和更平稳的轨迹，同时保持实时性能。

Conclusion: 该方法在果园监测中表现优异，也可应用于其他需要鲁棒多模态感知的户外领域。

Abstract: Autonomous robots in orchards require real-time 3D scene understanding
despite repetitive row geometry, seasonal appearance changes, and wind-driven
foliage motion. We present AgriGS-SLAM, a Visual--LiDAR SLAM framework that
couples direct LiDAR odometry and loop closures with multi-camera 3D Gaussian
Splatting (3DGS) rendering. Batch rasterization across complementary viewpoints
recovers orchard structure under occlusions, while a unified gradient-driven
map lifecycle executed between keyframes preserves fine details and bounds
memory. Pose refinement is guided by a probabilistic LiDAR-based depth
consistency term, back-propagated through the camera projection to tighten
geometry-appearance coupling. We deploy the system on a field platform in apple
and pear orchards across dormancy, flowering, and harvesting, using a
standardized trajectory protocol that evaluates both training-view and
novel-view synthesis to reduce 3DGS overfitting in evaluation. Across seasons
and sites, AgriGS-SLAM delivers sharper, more stable reconstructions and
steadier trajectories than recent state-of-the-art 3DGS-SLAM baselines while
maintaining real-time performance on-tractor. While demonstrated in orchard
monitoring, the approach can be applied to other outdoor domains requiring
robust multimodal perception.

</details>


### [89] [Towards Reinforcement Learning Based Log Loading Automation](https://arxiv.org/abs/2510.26363)
*Ilya Kurinov,Miroslav Ivanov,Grzegorz Orzechowski,Aki Mikkola*

Main category: cs.RO

TL;DR: 本研究使用强化学习代理来自动化林业集材机的完整原木装载过程，包括定位、抓取、运输和交付原木到车厢，在模拟环境中实现了94%的成功率。


<details>
  <summary>Details</summary>
Motivation: 林业集材机操作对操作员来说具有挑战性且身心疲惫，部分自动化可以减轻操作员压力。本研究延续了之前关于抓取自动化的研究，扩展到完整的装载操作。

Method: 在NVIDIA的Isaac Gym中开发了拖车式林业集材机模拟模型和虚拟环境，使用强化学习代理和课程学习方法进行训练。

Result: 训练出的最佳代理能够从随机位置抓取原木并将其运输到车厢，成功率达到94%。

Conclusion: 该训练代理可能是将强化学习代理应用于林业集材机自动化的一个重要进展。

Abstract: Forestry forwarders play a central role in mechanized timber harvesting by
picking up and moving logs from the felling site to a processing area or a
secondary transport vehicle. Forwarder operation is challenging and physically
and mentally exhausting for the operator who must control the machine in remote
areas for prolonged periods of time. Therefore, even partial automation of the
process may reduce stress on the operator. This study focuses on continuing
previous research efforts in application of reinforcement learning agents in
automating log handling process, extending the task from grasping which was
studied in previous research to full log loading operation. The resulting agent
will be capable to automate a full loading procedure from locating and
grappling to transporting and delivering the log to a forestry forwarder bed.
To train the agent, a trailer type forestry forwarder simulation model in
NVIDIA's Isaac Gym and a virtual environment for a typical log loading scenario
were developed. With reinforcement learning agents and a curriculum learning
approach, the trained agent may be a stepping stone towards application of
reinforcement learning agents in automation of the forestry forwarder. The
agent learnt grasping a log in a random position from grapple's random position
and transport it to the bed with 94% success rate of the best performing agent.

</details>


### [90] [Human-in-the-loop Online Rejection Sampling for Robotic Manipulation](https://arxiv.org/abs/2510.26406)
*Guanxing Lu,Rui Zhao,Haitao Lin,He Zhang,Yansong Tang*

Main category: cs.RO

TL;DR: Hi-ORS是一种简单有效的后训练方法，通过拒绝采样实现训练稳定性和高鲁棒性，在真实世界任务中仅需1.5小时训练即可掌握接触丰富的操作任务。


<details>
  <summary>Details</summary>
Motivation: 强化学习训练视觉语言动作模型不稳定，而模仿学习性能不足，需要一种既能保持训练稳定性又能获得高鲁棒性的方法。

Method: 采用拒绝采样过滤负奖励样本稳定价值估计，使用奖励加权的监督训练目标提供密集中间步骤监督，并开发异步推理训练框架支持在线人工干预。

Result: 在三个真实世界任务和两种体现中，Hi-ORS仅需1.5小时真实世界训练即可超越RL和IL基线方法，在效果和效率上均有显著优势。

Conclusion: Hi-ORS方法能够有效稳定训练过程，实现复杂错误恢复行为，展现出强大的测试时扩展性。

Abstract: Reinforcement learning (RL) is widely used to produce robust robotic
manipulation policies, but fine-tuning vision-language-action (VLA) models with
RL can be unstable due to inaccurate value estimates and sparse supervision at
intermediate steps. In contrast, imitation learning (IL) is easy to train but
often underperforms due to its offline nature. In this paper, we propose
Hi-ORS, a simple yet effective post-training method that utilizes rejection
sampling to achieve both training stability and high robustness. Hi-ORS
stabilizes value estimation by filtering out negatively rewarded samples during
online fine-tuning, and adopts a reward-weighted supervised training objective
to provide dense intermediate-step supervision. For systematic study, we
develop an asynchronous inference-training framework that supports flexible
online human-in-the-loop corrections, which serve as explicit guidance for
learning error-recovery behaviors. Across three real-world tasks and two
embodiments, Hi-ORS fine-tunes a pi-base policy to master contact-rich
manipulation in just 1.5 hours of real-world training, outperforming RL and IL
baselines by a substantial margin in both effectiveness and efficiency.
Notably, the fine-tuned policy exhibits strong test-time scalability by
reliably executing complex error-recovery behaviors to achieve better
performance.

</details>


### [91] [RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration](https://arxiv.org/abs/2510.26536)
*Huajie Tan,Cheng Chi,Xiansheng Chen,Yuheng Ji,Zhongxia Zhao,Xiaoshuai Hao,Yaoxu Lyu,Mingyu Cao,Junkai Zhao,Huaihai Lyu,Enshen Zhou,Ning Chen,Yankai Fu,Cheng Peng,Wei Guo,Dong Liang,Zhuo Chen,Mengsi Lyu,Chenrui He,Yulong Ao,Yonghua Lin,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: 提出了RoboOS-NeXT框架，通过统一的时空-具身记忆(STEM)实现多机器人系统的终身适应、可扩展协调和鲁棒调度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖有限的单智能体记忆，无法实现长期学习、异构团队扩展和故障恢复，需要统一的记忆表示。

Method: 引入Spatio-Temporal-Embodiment Memory(STEM)集成空间场景几何、时间事件历史和具身配置文件，采用大脑-小脑框架进行全局规划和本地执行。

Result: 在餐厅、超市和家庭等复杂协调任务中验证了优越性能，支持异构具身机器人的有效协作。

Conclusion: RoboOS-NeXT通过记忆中心设计实现了终身、可扩展和鲁棒的多机器人协作。

Abstract: The proliferation of collaborative robots across diverse tasks and
embodiments presents a central challenge: achieving lifelong adaptability,
scalable coordination, and robust scheduling in multi-agent systems. Existing
approaches, from vision-language-action (VLA) models to hierarchical
frameworks, fall short due to their reliance on limited or dividual-agent
memory. This fundamentally constrains their ability to learn over long
horizons, scale to heterogeneous teams, or recover from failures, highlighting
the need for a unified memory representation. To address these limitations, we
introduce RoboOS-NeXT, a unified memory-based framework for lifelong, scalable,
and robust multi-robot collaboration. At the core of RoboOS-NeXT is the novel
Spatio-Temporal-Embodiment Memory (STEM), which integrates spatial scene
geometry, temporal event history, and embodiment profiles into a shared
representation. This memory-centric design is integrated into a
brain-cerebellum framework, where a high-level brain model performs global
planning by retrieving and updating STEM, while low-level controllers execute
actions locally. This closed loop between cognition, memory, and execution
enables dynamic task allocation, fault-tolerant collaboration, and consistent
state synchronization. We conduct extensive experiments spanning complex
coordination tasks in restaurants, supermarkets, and households. Our results
demonstrate that RoboOS-NeXT achieves superior performance across heterogeneous
embodiments, validating its effectiveness in enabling lifelong, scalable, and
robust multi-robot collaboration. Project website:
https://flagopen.github.io/RoboOS/

</details>


### [92] [Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics](https://arxiv.org/abs/2510.26551)
*Prathamesh Kothavale,Sravani Boddepalli*

Main category: cs.RO

TL;DR: 提出了一种扩展机器人逆运动学求解器的新框架，使机器人能够学习使用不同长度工具的顺序动作技能，并在仿真和现实世界之间成功转移技能。


<details>
  <summary>Details</summary>
Motivation: 传统机器人对自身运动学理解有限，局限于预设任务，无法高效利用工具。需要解决工具使用的四个基本要素：理解期望结果、选择合适工具、确定最佳工具方向、执行精确操作。

Method: 扩展机器人逆运动学求解器，集成仿真学习的动作轨迹与工具，使机器人能够获取使用不同长度工具的顺序动作技能。

Result: 扩展逆运动学求解器误差小于1cm；训练策略在仿真中平均误差8cm；使用两种不同长度工具时性能几乎无差异；成功实现从仿真到现实世界的技能转移。

Conclusion: 该研究在工具使用的四个基本方面都取得了进展，使机器人能够掌握跨不同任务的复杂工具操作技能。

Abstract: Conventional robots possess a limited understanding of their kinematics and
are confined to preprogrammed tasks, hindering their ability to leverage tools
efficiently. Driven by the essential components of tool usage - grasping the
desired outcome, selecting the most suitable tool, determining optimal tool
orientation, and executing precise manipulations - we introduce a pioneering
framework. Our novel approach expands the capabilities of the robot's inverse
kinematics solver, empowering it to acquire a sequential repertoire of actions
using tools of varying lengths. By integrating a simulation-learned action
trajectory with the tool, we showcase the practicality of transferring acquired
skills from simulation to real-world scenarios through comprehensive
experimentation. Remarkably, our extended inverse kinematics solver
demonstrates an impressive error rate of less than 1 cm. Furthermore, our
trained policy achieves a mean error of 8 cm in simulation. Noteworthy, our
model achieves virtually indistinguishable performance when employing two
distinct tools of different lengths. This research provides an indication of
potential advances in the exploration of all four fundamental aspects of tool
usage, enabling robots to master the intricate art of tool manipulation across
diverse tasks.

</details>


### [93] [FLYINGTRUST: A Benchmark for Quadrotor Navigation Across Scenarios and Vehicles](https://arxiv.org/abs/2510.26588)
*Gang Li,Chunlei Zhai,Teng Wang,Shaun Li,Shangsong Jiang,Xiangwei Zhu*

Main category: cs.RO

TL;DR: FLYINGTRUST是一个高保真、可配置的四旋翼导航基准测试框架，用于评估平台动力学和场景结构对导航鲁棒性的联合影响。


<details>
  <summary>Details</summary>
Motivation: 四旋翼视觉导航算法在不同车辆平台和场景几何结构间转移时性能差异大，增加了现场部署的成本和风险，需要系统化的早期评估方法。

Method: 使用最大推重比和轴最大角加速度作为平台能力指标，结合多样化场景库和异构平台集，采用标准化评估协议和复合评分方法。

Result: 揭示了导航成功率与平台能力和场景几何的可预测依赖关系，不同算法在评估条件下表现出不同的偏好和失效模式。

Conclusion: 必须将平台能力和场景结构纳入算法设计、评估和选择过程，未来需要开发在多样化平台和场景中保持鲁棒性的方法。

Abstract: Visual navigation algorithms for quadrotors often exhibit a large variation
in performance when transferred across different vehicle platforms and scene
geometries, which increases the cost and risk of field deployment. To support
systematic early-stage evaluation, we introduce FLYINGTRUST, a high-fidelity,
configurable benchmarking framework that measures how platform kinodynamics and
scenario structure jointly affect navigation robustness. FLYINGTRUST models
vehicle capability with two compact, physically interpretable indicators:
maximum thrust-to-weight ratio and axis-wise maximum angular acceleration. The
benchmark pairs a diverse scenario library with a heterogeneous set of real and
virtual platforms and prescribes a standardized evaluation protocol together
with a composite scoring method that balances scenario importance, platform
importance and performance stability. We use FLYINGTRUST to compare
representative optimization-based and learning-based navigation approaches
under identical conditions, performing repeated trials per platform-scenario
combination and reporting uncertainty-aware metrics. The results reveal
systematic patterns: navigation success depends predictably on platform
capability and scene geometry, and different algorithms exhibit distinct
preferences and failure modes across the evaluated conditions. These
observations highlight the practical necessity of incorporating both platform
capability and scenario structure into algorithm design, evaluation, and
selection, and they motivate future work on methods that remain robust across
diverse platforms and scenarios.

</details>


### [94] [A Sliding-Window Filter for Online Continuous-Time Continuum Robot State Estimation](https://arxiv.org/abs/2510.26623)
*Spencer Teetaert,Sven Lilge,Jessica Burgner-Kahrs,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 提出了首个专门为连续体机器人设计的随机滑动窗口滤波器，能够在比实时更快的速度下在线运行，同时提高滤波方法的精度。


<details>
  <summary>Details</summary>
Motivation: 现有连续体机器人的随机状态估计方法难以平衡精度和计算效率。滑动窗口方法局限于简化的离散时间近似且不提供随机表示，而随机滤波方法受限于测量速度。连续时间估计方法虽然原理上解决了运行时约束，但目前仅限于离线操作。

Method: 开发了一种用于连续体机器人连续时间状态估计的滑动窗口滤波器(SWF)，结合了滑动窗口和连续时间方法的优势。

Result: 该方法在提高滤波方法精度的同时，使连续时间方法能够在线运行，且运行速度比实时更快。

Conclusion: 这是首个专门为连续体机器人设计的随机滑动窗口滤波器，为该领域未来研究提供了有前景的方向。

Abstract: Stochastic state estimation methods for continuum robots (CRs) often struggle
to balance accuracy and computational efficiency. While several recent works
have explored sliding-window formulations for CRs, these methods are limited to
simplified, discrete-time approximations and do not provide stochastic
representations. In contrast, current stochastic filter methods must run at the
speed of measurements, limiting their full potential. Recent works in
continuous-time estimation techniques for CRs show a principled approach to
addressing this runtime constraint, but are currently restricted to offline
operation. In this work, we present a sliding-window filter (SWF) for
continuous-time state estimation of CRs that improves upon the accuracy of a
filter approach while enabling continuous-time methods to operate online, all
while running at faster-than-real-time speeds. This represents the first
stochastic SWF specifically designed for CRs, providing a promising direction
for future research in this area.

</details>


### [95] [REALMS2 -- Resilient Exploration And Lunar Mapping System 2 -- A Comprehensive Approach](https://arxiv.org/abs/2510.26638)
*Dave van der Meer,Loïck P. Chovet,Gabriel M. Garcia,Abhishek Bera,Miguel A. Olivares-Mendez*

Main category: cs.RO

TL;DR: REALMS2是一个基于ROS 2的多机器人系统框架，用于行星勘探和地图绘制，使用vSLAM生成地图，通过网状网络实现鲁棒通信，在ESA-ESRIC挑战赛中成功绘制了约60%的区域。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统在太空勘探中的挑战，特别是针对异质多机器人探索任务在恶劣外星环境中的通信延迟和中断问题。

Method: 基于ROS 2框架，集成视觉SLAM进行地图生成，采用网状网络建立鲁棒的自组织网络，通过单一图形用户界面控制所有漫游车。

Result: 在ESA-ESRIC挑战赛第二次实地测试中，使用三个同构漫游车成功绘制了约60%的区域，并有效处理了通信延迟和中断。

Conclusion: REALMS2系统证明了其在行星勘探任务中的有效性，能够应对外星环境的通信挑战，为未来多机器人太空任务提供了可行解决方案。

Abstract: The European Space Agency (ESA) and the European Space Resources Innovation
Centre (ESRIC) created the Space Resources Challenge to invite researchers and
companies to propose innovative solutions for Multi-Robot Systems (MRS) space
prospection. This paper proposes the Resilient Exploration And Lunar Mapping
System 2 (REALMS2), a MRS framework for planetary prospection and mapping.
Based on Robot Operating System version 2 (ROS 2) and enhanced with Visual
Simultaneous Localisation And Mapping (vSLAM) for map generation, REALMS2 uses
a mesh network for a robust ad hoc network. A single graphical user interface
(GUI) controls all the rovers, providing a simple overview of the robotic
mission. This system is designed for heterogeneous multi-robot exploratory
missions, tackling the challenges presented by extraterrestrial environments.
REALMS2 was used during the second field test of the ESA-ESRIC Challenge and
allowed to map around 60% of the area, using three homogeneous rovers while
handling communication delays and blackouts.

</details>


### [96] [Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments](https://arxiv.org/abs/2510.26646)
*Xiaoyi He,Danggui Chen,Zhenshuo Zhang,Zimeng Bai*

Main category: cs.RO

TL;DR: 提出了一种结合高层DQN子目标选择和低层TD3连续控制的分层路径规划框架，在动态和部分可观测环境中实现了更高的成功率和样本效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决单一算法在复杂环境中路径规划的局限性，结合离散决策和连续控制的优势，提高在动态和部分可观测环境中的导航性能。

Method: 使用分层框架：高层DQN进行离散子目标选择，低层TD3执行连续速度控制；设计了包含方向、距离、避障等要素的奖励函数，并集成了LiDAR安全门机制。

Result: 在ROS+Gazebo环境中测试显示，相比单一算法基准和基于规则的规划器，该系统在成功率和样本效率方面均有提升，对未见障碍物配置具有更好的泛化能力，控制变化更平滑。

Conclusion: 分层规划框架有效结合了离散决策和连续控制的优势，在复杂环境中实现了更鲁棒和高效的导航性能，为实际机器人应用提供了可行方案。

Abstract: This paper presents a hierarchical path-planning and control framework that
combines a high-level Deep Q-Network (DQN) for discrete sub-goal selection with
a low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controller
for continuous actuation. The high-level module selects behaviors and
sub-goals; the low-level module executes smooth velocity commands. We design a
practical reward shaping scheme (direction, distance, obstacle avoidance,
action smoothness, collision penalty, time penalty, and progress), together
with a LiDAR-based safety gate that prevents unsafe motions. The system is
implemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics,
including success rate, collision rate, path efficiency, and re-planning
efficiency, in dynamic and partially observable environments. Experiments show
improved success rate and sample efficiency over single-algorithm baselines
(DQN or TD3 alone) and rule-based planners, with better generalization to
unseen obstacle configurations and reduced abrupt control changes. Code and
evaluation scripts are available at the project repository.

</details>


### [97] [Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems](https://arxiv.org/abs/2510.26656)
*Georgios Kamaras,Craig Innes,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: 提出了三种启发式LFI变体（EDGE、MODE、CENTRE）来解决支持集错误指定问题，通过自适应调整支持集来改进后验推理和策略学习效果


<details>
  <summary>Details</summary>
Motivation: 传统LFI方法假设固定的支持集，但错误指定的支持集会导致次优且虚假确定的后验分布，影响机器人领域自适应性能

Method: 开发了三种启发式LFI变体，通过解释后验模式在推理步骤中的移动来动态调整支持集，结合后验推理进行支持集自适应

Result: 在随机动态基准测试中验证了方法有效性；在可变形线性物体操作任务中，实现了更精细的长度和刚度分类，并提高了基于仿真的策略学习的鲁棒性

Conclusion: 提出的支持集自适应方法能够改善参数推理质量，产生更鲁棒的领域分布，从而提升面向对象的智能体性能

Abstract: In robotics, likelihood-free inference (LFI) can provide the domain
distribution that adapts a learnt agent in a parametric set of deployment
conditions. LFI assumes an arbitrary support for sampling, which remains
constant as the initial generic prior is iteratively refined to more
descriptive posteriors. However, a potentially misspecified support can lead to
suboptimal, yet falsely certain, posteriors. To address this issue, we propose
three heuristic LFI variants: EDGE, MODE, and CENTRE. Each interprets the
posterior mode shift over inference steps in its own way and, when integrated
into an LFI step, adapts the support alongside posterior inference. We first
expose the support misspecification issue and evaluate our heuristics using
stochastic dynamical benchmarks. We then evaluate the impact of heuristic
support adaptation on parameter inference and policy learning for a dynamic
deformable linear object (DLO) manipulation task. Inference results in a finer
length and stiffness classification for a parametric set of DLOs. When the
resulting posteriors are used as domain distributions for sim-based policy
learning, they lead to more robust object-centric agent performance.

</details>


### [98] [Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation](https://arxiv.org/abs/2510.26670)
*Qianyou Zhao,Yuliang Shen,Xuanran Zhai,Ce Hao,Duidi Wu,Jin Qi,Jie Hu,Qiaojun Yu*

Main category: cs.RO

TL;DR: 提出混合一致性策略（HCP），通过结合随机前缀和一致性跳跃，在保持多模态行为的同时实现快速采样，解决了扩散模仿学习中采样速度与多模态性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 基于扩散的模仿学习方法在捕捉多样化行为方面表现出色，但传统的随机去噪过程难以同时实现快速采样和强大多模态性，需要在推理速度和模式覆盖之间进行权衡。

Method: HCP运行一个短随机前缀直到自适应切换时间，然后应用一步一致性跳跃生成最终动作。采用时变一致性蒸馏，结合轨迹一致性目标保持相邻预测的连贯性和去噪匹配目标提高局部保真度。

Result: 在仿真和真实机器人上，HCP仅需25步SDE加一次跳跃就能接近80步DDPM教师模型的准确性和模式覆盖度，同时显著降低延迟。

Conclusion: 多模态性不需要缓慢的推理，切换时间将模式保留与速度解耦，为机器人策略提供了实用的准确性与效率权衡方案。

Abstract: In visuomotor policy learning, diffusion-based imitation learning has become
widely adopted for its ability to capture diverse behaviors. However,
approaches built on ordinary and stochastic denoising processes struggle to
jointly achieve fast sampling and strong multi-modality. To address these
challenges, we propose the Hybrid Consistency Policy (HCP). HCP runs a short
stochastic prefix up to an adaptive switch time, and then applies a one-step
consistency jump to produce the final action. To align this one-jump
generation, HCP performs time-varying consistency distillation that combines a
trajectory-consistency objective to keep neighboring predictions coherent and a
denoising-matching objective to improve local fidelity. In both simulation and
on a real robot, HCP with 25 SDE steps plus one jump approaches the 80-step
DDPM teacher in accuracy and mode coverage while significantly reducing
latency. These results show that multi-modality does not require slow
inference, and a switch time decouples mode retention from speed. It yields a
practical accuracy efficiency trade-off for robot policies.

</details>


### [99] [Running VLAs at Real-time Speed](https://arxiv.org/abs/2510.26742)
*Yunchao Ma,Yizhuang Zhou,Yunhuan Yang,Tiancai Wang,Haoqiang Fan*

Main category: cs.RO

TL;DR: 提出了一种在单张消费级GPU上实现30Hz帧率和最高480Hz轨迹频率的pi0级多视角VLA实时运行方法，通过消除模型推理开销的策略，在抓取下落笔任务中达到100%成功率，并提出了完整的流式推理框架。


<details>
  <summary>Details</summary>
Motivation: 解决大型VLA模型在动态实时任务中无法达到的实时性能问题，使VLA能够应用于需要高速响应的机器人控制场景。

Method: 引入一系列策略来消除模型推理中的开销，包括优化推理流程和实现流式推理框架，以提升运行效率。

Result: 在单张消费级GPU上实现了30Hz帧率和最高480Hz轨迹频率的实时性能，在抓取下落笔任务中取得了100%的成功率。

Conclusion: 证明了通过优化策略，VLA模型能够在消费级硬件上实现实时性能，为实时机器人控制应用开辟了新的可能性。

Abstract: In this paper, we show how to run pi0-level multi-view VLA at 30Hz frame rate
and at most 480Hz trajectory frequency using a single consumer GPU. This
enables dynamic and real-time tasks that were previously believed to be
unattainable by large VLA models. To achieve it, we introduce a bag of
strategies to eliminate the overheads in model inference. The real-world
experiment shows that the pi0 policy with our strategy achieves a 100% success
rate in grasping a falling pen task. Based on the results, we further propose a
full streaming inference framework for real-time robot control of VLA. Code is
available at https://github.com/Dexmal/realtime-vla.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [100] [Estimation and Inference in Boundary Discontinuity Designs: Distance-Based Methods](https://arxiv.org/abs/2510.26051)
*Matias D. Cattaneo,Rocio Titiunik,Ruiqi,Yu*

Main category: econ.EM

TL;DR: 该论文研究了边界不连续设计中边界平均处理效应曲线的非参数距离基局部多项式回归估计器的统计性质，提出了识别、估计和推断的条件，并强调了边界正则性的重要作用。


<details>
  <summary>Details</summary>
Motivation: 研究边界不连续设计中因果效应异质性的关键参数——边界平均处理效应曲线的统计性质，为实际应用提供理论基础和方法支持。

Method: 使用非参数距离基（各向同性）局部多项式回归估计器，提出识别、估计和推断的充分必要条件，包括点态和沿边界一致的大样本理论。

Result: 建立了边界平均处理效应曲线估计的理论框架，揭示了边界正则性在识别、估计和推断中的关键作用，并通过模拟数据验证了方法。

Conclusion: 边界正则性是边界不连续设计中因果推断的重要影响因素，论文提供了理论结果和通用软件工具，为实证研究提供了方法论支持。

Abstract: We study the statistical properties of nonparametric distance-based
(isotropic) local polynomial regression estimators of the boundary average
treatment effect curve, a key causal functional parameter capturing
heterogeneous treatment effects in boundary discontinuity designs. We present
necessary and/or sufficient conditions for identification, estimation, and
inference in large samples, both pointwise and uniformly along the boundary.
Our theoretical results highlight the crucial role played by the ``regularity''
of the boundary (a one-dimensional manifold) over which identification,
estimation, and inference are conducted. Our methods are illustrated with
simulated data. Companion general-purpose software is provided.

</details>


### [101] [Causal Inference with Groupwise Matching](https://arxiv.org/abs/2510.26106)
*Ratzanyel Rincón,Kyungchul Song*

Main category: econ.EM

TL;DR: 该论文研究了基于组间匹配的因果推断方法，提出了广义匹配条件来统一差异中差异、合成控制和合成差异中差异方法，并通过遗憾分析比较了它们的性能。


<details>
  <summary>Details</summary>
Motivation: 当观察多个大群体在多个时期的数据时，需要开发更有效的因果推断方法，统一现有的差异中差异、合成控制等方法，并理解它们之间的关系和适用条件。

Method: 提出了广义匹配条件来统一因果推断框架，通过遗憾分析比较差异中差异和合成控制方法的性能，开发了基于差分合成控制的统计推断程序。

Result: 发现差异中差异和差分合成控制是互补的，前者优于后者当且仅当后者的外推误差超过前者的匹配误差。当平行趋势假设在前后期都成立时，两种方法等价。

Conclusion: 论文提供了一个统一的因果推断框架，揭示了不同方法之间的关系，并提出了实用的统计推断程序，在实证应用中显示出有效性。

Abstract: This paper examines methods of causal inference based on groupwise matching
when we observe multiple large groups of individuals over several periods. We
formulate causal inference validity through a generalized matching condition,
generalizing the parallel trend assumption in difference-in-differences
designs. We show that difference-in-differences, synthetic control, and
synthetic difference-in-differences designs are distinguished by the specific
matching conditions that they invoke. Through regret analysis, we demonstrate
that difference-in-differences and synthetic control with differencing are
complementary; the former dominates the latter if and only if the latter's
extrapolation error exceeds the former's matching error up to a term vanishing
at the parametric rate. The analysis also reveals that synthetic control with
differencing is equivalent to difference-in-differences when the parallel trend
assumption holds for both the pre-treatment and post-treatment periods. We
develop a statistical inference procedure based on synthetic control with
differencing and present an empirical application demonstrating its usefulness.

</details>


### [102] [Tests of exogeneity in duration models with censored data](https://arxiv.org/abs/2510.26613)
*Gilles Crommen,Ingrid Van Keilegom,Jean-Pierre Florens*

Main category: econ.EM

TL;DR: 本文提出了对右删失持续时间数据中治疗变量外生性的非参数检验方法，基于工具变量构建检验统计量，并证明了估计量的快速收敛性和良好的有限样本性能。


<details>
  <summary>Details</summary>
Motivation: 研究者在因果推断中需要检验治疗变量Z对持续时间T的外生性，即在给定协变量X的情况下，Z是否与误差项U独立。这对于确保因果效应的有效估计至关重要。

Method: 使用工具变量W构建非参数检验统计量，检验条件秩V_T与(X,W)的联合独立性。通过处理V_T被V_C删失的复杂情况，推导检验统计量的极限分布。

Result: 证明了V_T分布估计量以快于通常参数化n^{-1/2}速率收敛到均匀分布。蒙特卡洛模拟显示检验统计量和bootstrap临界值近似在有限样本中表现良好。

Conclusion: 所提出的检验方法能有效检验持续时间数据中治疗变量的外生性，并在JTPA研究的实证应用中得到了验证。

Abstract: Consider the setting in which a researcher is interested in the causal effect
of a treatment $Z$ on a duration time $T$, which is subject to right censoring.
We assume that $T=\varphi(X,Z,U)$, where $X$ is a vector of baseline
covariates, $\varphi(X,Z,U)$ is strictly increasing in the error term $U$ for
each $(X,Z)$ and $U\sim \mathcal{U}[0,1]$. Therefore, the model is
nonparametric and nonseparable. We propose nonparametric tests for the
hypothesis that $Z$ is exogenous, meaning that $Z$ is independent of $U$ given
$X$. The test statistics rely on an instrumental variable $W$ that is
independent of $U$ given $X$. We assume that $X,W$ and $Z$ are all categorical.
Test statistics are constructed for the hypothesis that the conditional rank
$V_T= F_{T \mid X,Z}(T \mid X,Z)$ is independent of $(X,W)$ jointly. Under an
identifiability condition on $\varphi$, this hypothesis is equivalent to $Z$
being exogenous. However, note that $V_T$ is censored by $V_C =F_{T \mid X,Z}(C
\mid X,Z)$, which complicates the construction of the test statistics
significantly. We derive the limiting distributions of the proposed tests and
prove that our estimator of the distribution of $V_T$ converges to the uniform
distribution at a rate faster than the usual parametric $n^{-1/2}$-rate. We
demonstrate that the test statistics and bootstrap approximations for the
critical values have a good finite sample performance in various Monte Carlo
settings. Finally, we illustrate the tests with an empirical application to the
National Job Training Partnership Act (JTPA) Study.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [103] [Short-Run Multi-Outcome Effects of Nightlife Regulation in San Juan](https://arxiv.org/abs/2510.25782)
*Jorge A. Arroyo*

Main category: econ.GN

TL;DR: 使用多结果合成控制方法评估波多黎各圣胡安市深夜酒精销售条例，发现目标行业经济重新分配，但公共安全指标无明显变化。


<details>
  <summary>Details</summary>
Motivation: 评估深夜酒精销售限制政策对经济和公共安全的影响，特别是在低秩结果结构下澄清机制。

Method: 采用多结果合成控制方法，结合经济和公共安全数据系列，使用共同权重估计器进行分析。

Result: 目标行业（餐厅酒吧、加油站便利店、酒店就业）出现经济重新分配，但深夜公共秩序逮捕和暴力犯罪未明显偏离政策前趋势。统计检验未在常规阈值下拒绝零假设。

Conclusion: 强调效应大小、时间持续性和趋势拟合度而非统计显著性，政策窗口短和捐赠池小限制了统计功效。

Abstract: I evaluate San Juan, Puerto Rico's late-night alcohol sales ordinance using a
multi-outcome synthetic control that pools economic and public-safety series. I
show that a common-weight estimator clarifies mechanisms under low-rank outcome
structure. I find economically meaningful reallocations in targeted sectors --
restaurants and bars, gasoline and convenience, and hospitality employment --
while late-night public disorder arrests and violent crime show no clear
departures from pre-policy trends. The short post-policy window and small donor
pool limit statistical power; joint conformal and permutation tests do not
reject the null at conventional thresholds. I therefore emphasize effect
magnitudes, temporal persistence, and pre-trend fit over formal significance.
Code and diagnostics are available for replication.

</details>


### [104] [World personal income distribution evolution measured by purchasing power parity exchange rates](https://arxiv.org/abs/2510.26030)
*J. D. A. Islas-García,M. del Castillo-Mussot,Marcelo B. Ribeiro*

Main category: econ.GN

TL;DR: 该研究使用购买力平价汇率和统计分布分析1988-2018年全球收入分布演变，发现从双峰分布向单峰分布的转变，双峰对数正态分布拟合效果最佳。


<details>
  <summary>Details</summary>
Motivation: 更准确地表示全球收入分布数据，而不是依赖单一分布模型。

Method: 使用对数正态分布和伽马分布拟合全球收入分布，采用概率密度函数和互补累积分布函数分析分布特征和不平等趋势。

Result: 全球收入分布最初呈现双峰模式，但中国和印度等人口大国中产阶级的增长推动了向单峰分布的转变；双峰对数正态分布拟合效果近乎完美。

Conclusion: 双峰对数正态分布方法能更准确地描述全球收入分布，反映了发展中国家经济增长对全球收入格局的影响。

Abstract: The evolution of global income distribution from 1988 to 2018 is analyzed
using purchasing power parity exchange rates and well-established statistical
distributions. This research proposes the use of two separate distributions to
more accurately represent the overall data, rather than relying on a single
distribution. The global income distribution was fitted to log-normal and gamma
functions, which are standard tools in econophysics. Despite limitations in
data completeness during the early years, the available information covered the
vast majority of the world's population. Probability density function (PDF)
curves enabled the identification of key peaks in the distribution, while
complementary cumulative distribution function (CCDF) curves highlighted
general trends in inequality. Initially, the global income distribution
exhibited a bimodal pattern; however, the growth of middle classes in highly
populated countries such as China and India has driven the transition to a
unimodal distribution in recent years. While single-function fits with gamma or
log-normal distributions provided reasonable accuracy, the bimodal approach
constructed as a sum of log-normal distributions yielded near-perfect fits.

</details>


### [105] [The sustainability of contribution norms with income dynamics](https://arxiv.org/abs/2510.26503)
*Pau Juan-Bartroli,Esteban Muñoz-Sobrado*

Main category: econ.GN

TL;DR: 研究收入流动性和不平等对合作可持续性的影响，发现收入流动性促进合作，而不平等的影响取决于贡献规范的累进性和流动性程度。


<details>
  <summary>Details</summary>
Motivation: 理解合作的可持续性对社会进步至关重要，需要研究收入流动性和不平等如何影响群体成员之间的贡献规范。

Method: 使用重复博弈模型，个体决定将收入转移给其他群体成员的份额，考虑收入跨期交换的可能性（收入流动性），同时保持总体收入分布恒定。

Result: 更高的收入流动性有助于促进合作；不平等的影响不明确，取决于贡献规范的累进性和流动性程度。

Conclusion: 收入流动性是促进合作的关键因素，而不平等的影响具有复杂性，需要结合贡献规范和流动性来理解。该框架可应用于最优税收问题，研究公共和私人再分配的相互作用。

Abstract: The sustainability of cooperation is crucial for understanding the progress
of societies. We study a repeated game in which individuals decide the share of
their income to transfer to other group members. A central feature of our model
is that individuals may, with some probability, switch incomes across periods,
our measure of income mobility, while the overall income distribution remains
constant over time. We analyze how income mobility and income inequality affect
the sustainability of contribution norms, informal agreements about how much
each member should transfer to the group. We find that greater income mobility
facilitates cooperation. In contrast, the effect of inequality is ambiguous and
depends on the progressivity of the contribution norm and the degree of
mobility. We apply our framework to an optimal taxation problem to examine the
interaction between public and private redistribution.

</details>


### [106] [Putting a Price on Immobility: Food Deliveries and Pricing Approaches](https://arxiv.org/abs/2510.26636)
*Runyu Wang,Haotian Zhong*

Main category: econ.GN

TL;DR: 本研究通过两个离散选择实验量化北京居民对食品配送服务的价值评估，发现消费者剩余显著且存在明显定价过低问题，建议采用基于配送速度而非订单量的定价模型来管理外部性。


<details>
  <summary>Details</summary>
Motivation: 城市食品配送服务已成为日常生活的重要组成部分，但其移动性和环境外部性尚未得到规划者的充分解决，大多数研究忽视了消费者是否支付了足够费用来内化这些服务的更广泛社会成本。

Method: 通过两个离散选择实验：第一个测量放弃服务访问的接受补偿意愿，第二个捕捉减少等待时间和提高可靠性的支付意愿。

Result: 放弃访问的中位价值为588元人民币，等待时间估值远超典型配送费用（如工作时96.6元/小时和4.83元/分钟），表明存在显著的消费者剩余和明确的定价过低问题。

Conclusion: 城市规划需要将数字服务经济整合到定价和移动性框架中，建议采用基于数量的定价模型，针对配送速度而非订单量，在保持净福利收益的同时解决外部性的主要来源。

Abstract: Urban food delivery services have become an integral part of daily life, yet
their mobility and environmental externalities remain poorly addressed by
planners. Most studies neglect whether consumers pay enough to internalize the
broader social costs of these services. This study quantifies the value of
access to and use of food delivery services in Beijing, China, through two
discrete choice experiments. The first measures willingness to accept
compensation for giving up access, with a median value of CNY588 (approximately
USD80). The second captures willingness to pay for reduced waiting time and
improved reliability, showing valuations far exceeding typical delivery fees
(e.g., CNY96.6/hour and CNY4.83/min at work). These results suggest a
substantial consumer surplus and a clear underpricing problem. These findings
highlight the need for urban planning to integrate digital service economies
into pricing and mobility frameworks. We propose a quantity-based pricing model
that targets delivery speed rather than order volume, addressing the primary
source of externalities while maintaining net welfare gains. This approach
offers a pragmatic, equity-conscious strategy to curb delivery-related
congestion, emissions, and safety risks, especially in dense urban cores.

</details>


### [107] [Neither Consent nor Property: A Policy Lab for Data Law](https://arxiv.org/abs/2510.26727)
*Haoyi Zhang,Tianyi Zhu*

Main category: econ.GN

TL;DR: 该论文构建了一个计算测试平台，首次使AI经济中不透明的数据市场变得可实证分析，揭示了财产式救济的虚假承诺，并发现当下游买家承担全部实质性风险时社会福利达到峰值。


<details>
  <summary>Details</summary>
Motivation: 解决AI数据市场的核心认知失败：监管者面对由结构性不透明、脆弱价格发现和脆弱技术保障定义的市场，传统实证方法失效，政策制定碎片化。

Method: 通过多年实地调研提取市场隐藏逻辑，将基于行为的高保真ABM与基于LLM的离散选择实验相结合，捕捉难以调查人群的偏好，并通过现实数据验证管道。

Result: 财产式救济是虚假承诺，匿名数据豁免扩大交易但忽略风险，一旦计入外部损害，总福利崩溃；社会福利峰值出现在下游买家内部化全部实质性风险时，这种最低成本避免者方法同时提高福利并维持交易。

Conclusion: 该可复现管道将定性洞察转化为可测试的比较政策实验，用受控证据取代直觉推测，为法律规则如何实际转移风险和剩余提供实证基础，推动领域从竞争直觉转向直接计算分析。

Abstract: This paper makes the opaque data market in the AI economy empirically legible
for the first time, constructing a computational testbed to address a core
epistemic failure: regulators governing a market defined by structural opacity,
fragile price discovery, and brittle technical safeguards that have paralyzed
traditional empirics and fragmented policy. The pipeline begins with multi-year
fieldwork to extract the market's hidden logic, and then embeds these grounded
behaviors into a high-fidelity ABM, parameterized via a novel LLM-based
discrete-choice experiment that captures the preferences of unsurveyable
populations. The pipeline is validated against reality, reproducing observed
trade patterns. This policy laboratory delivers clear, counter-intuitive
results. First, property-style relief is a false promise: ''anonymous-data''
carve-outs expand trade but ignore risk, causing aggregate welfare to collapse
once external harms are priced in. Second, social welfare peaks when the
downstream buyer internalizes the full substantive risk. This least-cost
avoider approach induces efficient safeguards, simultaneously raising welfare
and sustaining trade, and provides a robust empirical foundation for the legal
drift toward two-sided reachability. The contribution is a reproducible
pipeline designed to end the reliance on intuition. It converts qualitative
insight into testable, comparative policy experiments, obsoleting armchair
conjecture by replacing it with controlled evidence on how legal rules actually
shift risk and surplus. This is the forward-looking engine that moves the field
from competing intuitions to direct, computational analysis.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [108] [Tractable Algorithms for Changepoint Detection in Player Performance Metrics](https://arxiv.org/abs/2510.25961)
*Amanda Glazer*

Main category: stat.AP

TL;DR: 提出了可处理的球员表现指标变化检测方法，应用于2023-2024赛季MLB击球和投球数据，结合分布假设和集中不等式建立统计可靠性基准，开发了结合似然方法和分割样本推断的变点检测算法。


<details>
  <summary>Details</summary>
Motivation: 需要可靠地检测棒球运动员表现指标的变化，特别是在赛季期间识别有意义的性能变化，为球队管理和球员评估提供数据支持。

Method: 使用分布假设和标准集中不等式建立统计可靠性基准，提出结合似然方法和分割样本推断的变点检测算法，包含位移参数以指定最小检测变化幅度。

Result: 在91%的'真实案例'中成功标记有意义变化，发现某些指标超过60%的变化发生在赛季期间，验证了方法在击球纪律指标和投球速度变化检测中的有效性。

Conclusion: 该方法不仅适用于棒球数据分析，还可广泛应用于任何需要监测个体随时间表现变化的场景，为性能监控提供了可靠的统计框架。

Abstract: We present tractable methods for detecting changes in player performance
metrics and apply these methods to Major League Baseball (MLB) batting and
pitching data from the 2023 and 2024 seasons. First, we derive principled
benchmarks for when performance metrics can be considered statistically
reliable, assuming no underlying change, using distributional assumptions and
standard concentration inequalities. We then propose a changepoint detection
algorithm that combines a likelihood-based approach with split-sample inference
to control false positives, using either nonparametric tests or tests
appropriate to the underlying data distribution. These tests incorporate a
shift parameter, allowing users to specify the minimum magnitude of change to
detect. We demonstrate the utility of this approach across several baseball
applications: detecting changes in batter plate discipline metrics (e.g., chase
and whiff rate), identifying velocity changes in pitcher fastballs, and
validating velocity changepoints against a curated ground-truth dataset of
pitchers who transitioned from relief to starting roles. Our method flags
meaningful changes in 91% of these `ground-truth' cases and reveals that, for
some metrics, more than 60% of detected changes occur in-season. While
developed for baseball, the proposed framework is broadly applicable to any
setting involving monitoring of individual performance over time.

</details>


### [109] [Variational System Identification of Aircraft](https://arxiv.org/abs/2510.26496)
*Dimas Abreu Archanjo Dutra*

Main category: stat.AP

TL;DR: 变分系统辨识是一种新的最大似然估计方法，用于估计受过程和测量噪声影响的动态系统参数，如湍流中的飞机。该方法优于滤波器误差方法，无需求解Riccati方程，且无不稳定预测器问题。


<details>
  <summary>Details</summary>
Motivation: 传统滤波器误差方法在求解Riccati方程时存在困难，且可能产生不稳定预测器。变分系统辨识旨在克服这些限制，提供更稳健的参数估计方法。

Method: 基于变分原理的系统辨识方法，通过最大似然估计处理过程和测量噪声，避免直接求解Riccati方程。

Result: 在真实飞行测试数据应用中，该方法比滤波器误差方法具有更好的收敛性，即使所有参数和决策变量使用零初始猜测也能达到最优解。

Conclusion: 变分系统辨识是一种有效的替代方法，具有更好的收敛特性和实用性，适用于飞机参数估计等实际应用。

Abstract: Variational system identification is a new formulation of maximum likelihood
for estimation of parameters of dynamical systems subject to process and
measurement noise, such as aircraft flying in turbulence. This formulation is
an alternative to the filter-error method that circumvents the solution of a
Riccati equation and does not have problems with unstable predictors. In this
paper, variational system identification is demonstrated for estimating
aircraft parameters from real flight-test data. The results show that, in real
applications of practical interest, it has better convergence properties than
the filter-error method, reaching the optimum even when null initial guesses
are used for all parameters and decision variables. This paper also presents
the theory behind the method and practical recommendations for its use.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [110] [Structurally Valid Log Generation using FSM-GFlowNets](https://arxiv.org/abs/2510.26197)
*Riya Samanta*

Main category: cs.ET

TL;DR: 提出一个结合有限状态机(FSM)和生成流网络(GFlowNet)的框架，用于生成结构有效且行为多样的合成事件日志，在UI交互日志生成任务中显著优于GPT-4o和Gemini等现有方法。


<details>
  <summary>Details</summary>
Motivation: 在数据有限或隐私受限的场景下，现有的启发式模拟和基于LLM的生成方法缺乏结构连贯性和可控性，难以准确表示真实系统交互，需要一种能生成结构有效且多样合成事件日志的方法。

Method: 将有限状态机(FSM)与生成流网络(GFlowNet)集成，FSM编码领域特定规则确保语法有效性，GFlowNet通过动态动作掩码和引导采样实现行为变化，使用混合奖励平衡FSM合规性和统计保真度。

Result: 在UI交互日志生成任务中，FSM-GFlowNet的KL散度为0.2769，卡方距离为0.3522，显著优于GPT-4o(2.5294/13.8020)和Gemini(3.7233/63.0355)，二元语法重叠度达0.1214。下游意图分类任务中，仅使用合成日志训练的模型达到与真实数据相当的准确率。

Conclusion: FSM-GFlowNet框架能够生成结构一致、语义有效且多样的合成事件日志，在数据生成质量上显著优于现有方法，并支持下游应用，具有广泛的符号序列领域适用性。

Abstract: Generating structurally valid and behaviorally diverse synthetic event logs
for interaction-aware models is a challenging yet crucial problem, particularly
in settings with limited or privacy constrained user data. Existing methods
such as heuristic simulations and LLM based generators often lack structural
coherence or controllability, producing synthetic data that fails to accurately
represent real world system interactions. This paper presents a framework that
integrates Finite State Machines or FSMs with Generative Flow Networks or
GFlowNets to generate structured, semantically valid, and diverse synthetic
event logs. Our FSM-constrained GFlowNet ensures syntactic validity and
behavioral variation through dynamic action masking and guided sampling. The
FSM, derived from expert traces, encodes domain-specific rules, while the
GFlowNet is trained using a flow matching objective with a hybrid reward
balancing FSM compliance and statistical fidelity. We instantiate the framework
in the context of UI interaction logs using the UIC HCI dataset, but the
approach generalizes to any symbolic sequence domain. Experimental results
based on distributional metrics show that our FSM GFlowNet produces realistic,
structurally consistent logs, achieving, for instance, under the real user logs
baseline, a KL divergence of 0.2769 and Chi squared distance of 0.3522,
significantly outperforming GPT-4o's 2.5294/13.8020 and Gemini's
3.7233/63.0355, alongside a leading bigram overlap of 0.1214 vs. GPT 4o's
0.0028 and Gemini's 0.0007. A downstream use case intent classification
demonstrates that classifiers trained solely on our synthetic logs produced
from FSM-GFlowNet achieve competitive accuracy compared to real data.

</details>
