<div id=toc></div>

# Table of Contents

- [stat.AP](#stat.AP) [Total: 4]
- [econ.TH](#econ.TH) [Total: 2]
- [econ.EM](#econ.EM) [Total: 3]
- [eess.SY](#eess.SY) [Total: 19]
- [econ.GN](#econ.GN) [Total: 8]
- [cs.RO](#cs.RO) [Total: 17]
- [cs.AI](#cs.AI) [Total: 37]
- [cs.CY](#cs.CY) [Total: 9]
- [cs.SI](#cs.SI) [Total: 4]


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [1] [From 'What-is' to 'What-if' in Human-Factor Analysis: A Post-Occupancy Evaluation Case](https://arxiv.org/abs/2512.02060)
*Xia Chen,Ruiji Sun,Philipp Geyer,André Borrmann,Stefano Schiavon*

Main category: stat.AP

TL;DR: 论文主张在人为因素分析中明确区分描述性问题和干预性问题，采用因果推断框架替代传统相关性分析，以解决混杂变量和碰撞变量带来的偏差问题。


<details>
  <summary>Details</summary>
Motivation: 传统人为因素分析主要使用相关性分析和显著性检验，这些描述性方法虽然能识别变量间的关联，但无法回答因果干预问题，容易忽略混杂变量和碰撞变量，导致决策偏差和错误。

Method: 提出在人为因素分析中明确区分描述性问题和干预性问题，应用因果推断框架。使用建筑环境中心（CBE）入住后评估（POE）调查数据作为案例，展示因果发现如何揭示传统关联分析遗漏的干预层次和方向性关系。

Result: 因果发现方法能够揭示传统关联分析无法发现的干预层次和方向性关系，系统区分因果关联变量和独立变量，结合干预优先级能力，为复杂人本系统提供更准确的决策支持。

Conclusion: 在人为因素分析中应用因果推断框架，明确区分描述性和干预性问题，能够避免方法错配，解开复杂变量关系，实现反事实推理，对建筑科学、人机工程学等需要理解干预效果的领域具有广泛适用性。

Abstract: Human-factor analysis typically employs correlation analysis and significance testing to identify relationships between variables. However, these descriptive ('what-is') methods, while effective for identifying associations, are often insufficient for answering causal ('what-if') questions. Their application in such contexts often overlooks confounding and colliding variables, potentially leading to bias and suboptimal or incorrect decisions.
  We advocate for explicitly distinguishing descriptive from interventional questions in human-factor analysis, and applying causal inference frameworks specifically to these problems to prevent methodological mismatches. This approach disentangles complex variable relationships and enables counterfactual reasoning. Using post-occupancy evaluation (POE) data from the Center for the Built Environment's (CBE) Occupant Survey as a demonstration case, we show how causal discovery reveals intervention hierarchies and directional relationships that traditional associational analysis misses. The systematic distinction between causally associated and independent variables, combined with intervention prioritization capabilities, offers broad applicability to complex human-centric systems, for example, in building science or ergonomics, where understanding intervention effects is critical for optimization and decision-making.

</details>


### [2] [Probabilistic Analysis of Various Squash Shots and Skill Study of Different Levels of Squash Players and Teams](https://arxiv.org/abs/2512.02210)
*Prathamesh Anwekar,Kaushal Kirpekar,Mahesh B,Sainath Bitragunta*

Main category: stat.AP

TL;DR: 提出紧凑的概率模型用于单双打壁球比赛，基于得分概率推导实用的技能比较规则，分析不同水平选手的击球分布差异


<details>
  <summary>Details</summary>
Motivation: 量化壁球中的战略差异，提供简单的方法来比较球员和团队技能，为体育分析和教练提供可操作的见解

Method: 引入紧凑的概率模型用于两人和四人（两队）壁球比赛，基于记录击球类型和球场位置分析不同水平选手的击球分布差异

Result: 专业选手使用更多样化的击球并偏爱后场打法以保持控制，中级选手更集中于中场击球，产生更多失误，位置控制能力较差

Conclusion: 该研究量化了壁球的战略差异，提供了比较球员和团队技能的简单方法，为体育分析和教练提供了有价值的见解

Abstract: We introduce a compact probabilistic model for two-player and two-team (four-player) squash matches, along with a practical skill-comparison rule derived from point-scoring probabilities. Using recorded shot types and court locations, we analyze how shot distributions differ between professional-level and intermediate-level players. Our analysis shows that professional players use a wider variety of shots and favor backcourt play to maintain control, while intermediate players concentrate more on mid-court shots, generate more errors, and exercise less positional control. These results quantify strategic differences in squash, offer a simple method to compare player and team skill, and provide actionable insights for sports analytics and coaching.

</details>


### [3] [Estimating excess mortality during the Covid-19 pandemic in Aotearoa New Zealand: Addendum](https://arxiv.org/abs/2512.02266)
*Michael J. Plank,Pubudu Senanayake,Richard Lyon*

Main category: stat.AP

TL;DR: 更新人口数据后，新西兰2020-2023年超额死亡率估计值从0.7%提高到2.0%，主要结论不变


<details>
  <summary>Details</summary>
Motivation: 新西兰统计局发布了更新的人口估计数据，需要基于新数据重新评估2020-2023年超额死亡率估计值

Method: 将原始模型应用于更新的人口数据，重新计算超额死亡率估计值

Result: 更新后的超额死亡率估计值为2.0%（95%置信区间[0.5%, 3.3%]），比原始估计值高1.3个百分点

Conclusion: 虽然超额死亡率估计值因人口数据更新而提高，但原始文章的主要结论仍然适用

Abstract: In our previous article, we estimated excess mortality during in Aotearoa New Zealand for 2020 to 2023. Since our work was published, updated population estimates have been released by Statistics NZ. In this short letter, we provide the results of applying our original model to the new population data. Our updated excess mortality estimate of 2.0% (95% CI [0.5%, 3.3%]) is 1.3 percentage points higher than our original estimate because the new population estimates for the period 2020 to 2023 are smaller, but the main conclusions of our original article still apply.

</details>


### [4] [Leveraging ontologies to predict biological activity of chemicals across genes](https://arxiv.org/abs/2512.02327)
*Jennifer N. Kampe,David B. Dunson,Celeste K. Carberry,Julia E. Rager,Daniel Zilber,Kyle P. Messier*

Main category: stat.AP

TL;DR: 提出DART方法，利用化学结构特性和基因本体信息，通过贝叶斯因子模型预测化学物质在基因上的生物活性，填补高通量筛选数据稀疏问题


<details>
  <summary>Details</summary>
Motivation: 高通量筛选(HTS)用于评估化学品对人类健康风险，但化学-基因对的剂量反应曲线数据极其稀疏，且基因本体虽然能表征基因相似性，但各通路对环境污染物敏感性仍不明确

Method: 提出剂量-活性反应追踪(DART)方法，结合化学结构特性和基因本体信息，在贝叶斯因子模型框架下预测化学物质在基因上的生物活性，揭示驱动剂量反应行为的潜在过程

Result: 通过模拟研究和实际应用验证DART性能，应用于PFAS暴露HepG2细胞的大规模多实验数据集，为化学品优先级排序提供可操作指导，并推断激活测定的结构和功能机制

Conclusion: DART为毒理学家提供适用于不同HTS测定平台的灵活工具，能够预测缺乏实验数据的化学-基因对的新活性谱，有助于化学品风险评估和机制理解

Abstract: High-throughput screening (HTS) is useful for evaluating chemicals for potential human health risks. However, given the extraordinarily large number of genes, assay endpoints, and chemicals of interest, available data are sparse, with dose-response curves missing for the vast majority of chemical-gene pairs. Although gene ontologies characterize similarity among genes with respect to known cellular functions and biological pathways, the sensitivity of various pathways to environmental contaminants remains unclear. We propose a novel Dose-Activity Response Tracking (DART) approach to predict the biological activity of chemicals across genes using information on chemical structural properties and gene ontologies within a Bayesian factor model. Designed to provide toxicologists with a flexible tool applicable across diverse HTS assay platforms, DART reveals the latent processes driving dose-response behavior and predicts new activity profiles for chemical-gene pairs lacking experimental data. We demonstrate the performance of DART through simulation studies and an application to a vast new multi-experiment data set consisting of dose-response observations generated by the exposure of HepG2 cells to per- and polyfluoroalkyl substances (PFAS), where it provides actionable guidance for chemical prioritization and inference on the structural and functional mechanisms underlying assay activation.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [5] [Localizing Preference Aggregation Conflicts: A Graph-Theoretic Approach Using Sheaves](https://arxiv.org/abs/2512.02416)
*Karen Sargsyan*

Main category: econ.TH

TL;DR: 提出基于离散层论的图论框架，用于诊断和定位偏好聚合中的不一致性，保留序数偏好的离散结构，识别导致聚合失败的特定投票者交互。


<details>
  <summary>Details</summary>
Motivation: 传统线性化方法（如HodgeRank）无法提供导致聚合失败的特定投票者交互信息。需要一种能够保留序数偏好离散结构的方法，以诊断和定位偏好聚合中的不一致性。

Method: 基于离散层论的图论框架，通过障碍轨迹识别不一致性，定义不相容指数量化局部冲突，使用Mallows模型分析随机变化下的行为，开发层论推送操作建模投票者合并，通过多项式时间约束DAG算法实现。

Result: 该方法能够识别导致聚合失败的特定投票者交互，图商将分布式边冲突转化为局部不可能性（空茎），提供了聚合悖论在不同尺度上持续存在的拓扑特征。

Conclusion: 基于离散层论的框架为偏好聚合不一致性提供了更精细的诊断和定位方法，超越了传统线性化方法，能够揭示聚合悖论在不同尺度上的拓扑特性。

Abstract: We introduce a graph-theoretic framework based on discrete sheaves to diagnose and localize inconsistencies in preference aggregation. Unlike traditional linearization methods (e.g., HodgeRank), this approach preserves the discrete structure of ordinal preferences, identifying which specific voter interactions cause aggregation failure -- information that global methods cannot provide -- via the Obstruction Locus. We formalize the Incompatibility Index to quantify these local conflicts and examine their behavior under stochastic variations using the Mallows model. Additionally, we develop a rigorous sheaf-theoretic pushforward operation to model voter merging, implemented via a polynomial-time constraint DAG algorithm. We demonstrate that graph quotients transform distributed edge conflicts into local impossibilities (empty stalks), providing a topological characterization of how aggregation paradoxes persist across scales.

</details>


### [6] [Convergence to stationary points in the Weisbuch-Kirman-Herreiner model for buyers' preferences in fish markets](https://arxiv.org/abs/2512.02883)
*Ali Ellouze,Bastien Fernandez*

Main category: econ.TH

TL;DR: 论文对Weisbuch等人的OTC鱼市买家偏好模型进行数学分析，证明在均匀买家群体下，几乎所有初始条件都会渐近趋于稳态，并确定了稳态及其稳定性条件。


<details>
  <summary>Details</summary>
Motivation: Weisbuch等人的OTC鱼市买家偏好模型已成为结合有限理性和近视推理的经济概念原型，但关于其渐近行为的文献仍然稀缺。本文旨在对该模型的动力学进行数学分析。

Method: 使用合作动力系统理论，在买家群体均匀的最简单情况下，对模型动力学进行数学分析，证明渐近行为并确定所有稳态及其参数依赖的稳定性。

Result: 证明无论卖家数量和参数如何，几乎所有初始条件的轨迹都会渐近趋于稳态。对于足够简单的卖家吸引力分布，确定了所有稳态及其稳定性。分析显示在大多数情况下，渐近偏好按吸引力排序，但也存在偏好最高的卖家并非利润最高的情况。

Conclusion: 该研究为Weisbuch等人的OTC鱼市模型提供了严格的数学分析，揭示了模型在均匀买家群体下的渐近行为特征，包括偏好排序与利润不一致的稳健运行模式。

Abstract: In a paper published in The Economic Journal in 2000, Weisbuch et al.\ introduce a model for buyers' preferences to the various sellers in over-the-counter (OTC) fish markets. While this model has become an archetype of economic conceptualization that combines bounded rationality and myopic reasoning, the literature on its asymptotic behaviours has remained scarce. In this paper, we proceed to a mathematical analysis of the dynamics and its full characterization in the simplest case of homogeneous buyer populations. By using elements of the theory of cooperative dynamical systems, we prove that, independently of the number of sellers and parameters, for almost every initial condition, the subsequent trajectory must asymptotically approach a stationary state. Moreover, for simple enough distributions of the sellers' attractiveness, we determine all stationary states and their parameter-dependent stability. This analysis shows that in most cases, the asymptotic preferences are ordered as the attractiveness are. However, depending on the parameters, there also exist robust functioning modes in which those sellers with highest preference are not the ones that provide highest profit.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [7] [Opening the Black Box: Nowcasting Singapore's GDP Growth and its Explainability](https://arxiv.org/abs/2512.02092)
*Luca Attolico*

Main category: econ.EM

TL;DR: 开发了一个用于新加坡季度GDP增长实时临近预测的高维框架，使用约70个指标，涵盖多种机器学习方法，相比基准模型将RMSFE降低了40-60%。


<details>
  <summary>Details</summary>
Motivation: 新加坡作为小型开放经济体，外部冲击会迅速传导至国内经济活动，因此需要及时评估当前经济状况，实时临近预测对于政策制定和经济监测至关重要。

Method: 使用高维面板数据（约70个指标），采用惩罚回归、降维方法、集成学习算法和神经网络架构，通过扩展窗口前向设计保留时间顺序，使用贝叶斯超参数优化和移动块自举法构建预测区间，结合模型置信集和多种加权方案进行模型聚合。

Result: 惩罚回归、降维模型和GRU网络在所有基准模型（随机游走、AR(3)、动态因子模型）中表现最优，将均方根预测误差降低了约40-60%，模型聚合进一步提升了预测性能。

Conclusion: 该实时临近预测框架为新加坡GDP增长提供了准确预测，特征归因方法识别出工业生产、对外贸易和劳动力市场指标是短期增长动态的主要驱动因素，模型聚合通过时变权重提供了可解释的模型贡献表示。

Abstract: Timely assessment of current conditions is essential especially for small, open economies such as Singapore, where external shocks transmit rapidly to domestic activity. We develop a real-time nowcasting framework for quarterly GDP growth using a high-dimensional panel of approximately 70 indicators, encompassing economic and financial indicators over 1990Q1-2023Q2. The analysis covers penalized regressions, dimensionality-reduction methods, ensemble learning algorithms, and neural architectures, benchmarked against a Random Walk, an AR(3), and a Dynamic Factor Model. The pipeline preserves temporal ordering through an expanding-window walk-forward design with Bayesian hyperparameter optimization, and uses moving block-bootstrap procedures both to construct prediction intervals and to obtain confidence bands for feature-importance measures. It adopts model-specific and XAI-based explainability tools. A Model Confidence Set procedure identifies statistically superior learners, which are then combined through simple, weighted, and exponentially weighted schemes; the resulting time-varying weights provide an interpretable representation of model contributions. Predictive ability is assessed via Giacomini-White tests. Empirical results show that penalized regressions, dimensionality-reduction models, and GRU networks consistently outperform all benchmarks, with RMSFE reductions of roughly 40-60%; aggregation delivers further gains. Feature-attribution methods highlight industrial production, external trade, and labor-market indicators as dominant drivers of Singapore's short-run growth dynamics.

</details>


### [8] [Unbiased Estimation of Multi-Way Gravity Models](https://arxiv.org/abs/2512.02203)
*Lucas Resende,Guillaume Lecué,Lionel Wilner,Philippe Choné*

Main category: econ.EM

TL;DR: 提出一种新的渐近无偏估计器，用于解决多向重力模型中的伴随参数问题，比PPML在稀疏数据环境下更准确、计算更快。


<details>
  <summary>Details</summary>
Motivation: 最大似然估计器（如PPML）存在伴随参数问题：在联合估计结构参数和伴随参数时会产生偏差。多向重力模型和网络形成文献中的稀疏数据环境需要更有效的解决方案。

Method: 将估计重新构建为一系列分类任务，对固定效应的数量和结构保持不可知论。在稀疏数据环境下比PPML计算更快。

Result: 新估计器比PPML及其偏差校正策略产生更准确的点估计和置信区间。即使在模型误设情况下也有效，在稀疏设置中改进更明显。PPML在密集低维数据中仍具竞争力。

Conclusion: 该方法为多向模型提供了稳健的替代方案，能有效适应稀疏性扩展，并应用于法国医疗保健空间可达性的政策改革效果估计。

Abstract: Maximum likelihood estimators, such as the Poisson Pseudo-Maximum Likelihood (PPML), suffer from the incidental parameter problem: a bias in the estimation of structural parameters that arises from the joint estimation of structural and nuisance parameters. To address this issue in multi-way gravity models, we propose a novel, asymptotically unbiased estimator. Our method reframes the estimation as a series of classification tasks and is agnostic to both the number and structure of fixed effects. In sparse data environments, common in the network formation literature, it is also computationally faster than PPML. We provide empirical evidence that our estimator yields more accurate point estimates and confidence intervals than PPML and its bias-correction strategies. These improvements hold even under model misspecification and are more pronounced in sparse settings. While PPML remains competitive in dense, low-dimensional data, our approach offers a robust alternative for multi-way models that scales efficiently with sparsity. The method is applied to estimate the effect of a policy reform on spatial accessibility to health care in France.

</details>


### [9] [Identification of Multivariate Measurement Error Models](https://arxiv.org/abs/2512.02970)
*Yingyao Hu*

Main category: econ.EM

TL;DR: 该论文提出了多维连续测量误差模型的新识别方法，无需测量值具有单射性，通过三阶交叉矩和张量分解识别潜在因子分布。


<details>
  <summary>Details</summary>
Motivation: 现有测量误差模型通常要求至少有一个测量值能单射映射潜在分布，这在实践中难以满足。许多实证研究（如因子模型、调查数据、计量经济学中的测量误差变量、心理学和营销学中的多维潜在特质模型）都面临所有观测值都被相关误差污染的问题，需要更一般的识别方法。

Method: 使用三阶交叉矩构造三阶张量，利用Kruskal定理保证的唯一张量分解识别因子载荷矩阵。对于线性结构，通过构造合适的测量值并应用Kotlarski恒等式（标量或多变量版本）恢复潜在因子的完整分布。对于非线性模型，使用新定义的广义Kruskal秩（信号秩）来建立识别结果。

Result: 证明了即使没有单射测量值，也能完全识别潜在向量和测量误差的联合分布，表明多维潜在结构可以在比先前认为更广泛的设置中恢复。在单射条件下，提供了用户友好的可测试识别条件。

Conclusion: 该研究扩展了测量误差模型的识别边界，为涉及噪声或间接测量的实证工作提供了广泛适用的理论框架，能够在无法获得干净测量值时实现更稳健的估计和解释。

Abstract: This paper develops new identification results for multidimensional continuous measurement-error models where all observed measurements are contaminated by potentially correlated errors and none provides an injective mapping of the latent distribution. Using third order cross moments, the paper constructs a three way tensor whose unique decomposition, guaranteed by Kruskal theorem, identifies the factor loading matrices. Starting with a linear structure, the paper recovers the full distribution of latent factors by constructing suitable measurements and applying scalar or multivariate versions of Kotlarski identity. As a result, the joint distribution of the latent vector and measurement errors is fully identified without requiring injective measurements, showing that multivariate latent structure can be recovered in broader settings than previously believed. Under injectivity, the paper also provides user-friendly testable conditions for identification. Finally, this paper provides general identification results for nonlinear models using a newly-defined generalized Kruskal rank - signal rank - of intergral operators. These results have wide applicability in empirical work involving noisy or indirect measurements, including factor models, survey data with reporting errors, mismeasured regressors in econometrics, and multidimensional latent-trait models in psychology and marketing, potentially enabling more robust estimation and interpretation when clean measurements are unavailable.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [10] [Scalable Distributed Nonlinear Control Under Flatness-Preserving Coupling](https://arxiv.org/abs/2512.02138)
*Fengjun Yang,Jake Welde,Nikolai Matni*

Main category: eess.SY

TL;DR: 研究分布式控制，针对具有动态耦合的非线性微分平坦子系统网络，识别保持平坦性的耦合类型，并设计基于局部信息的分布式跟踪控制器。


<details>
  <summary>Details</summary>
Motivation: 虽然微分平坦性简化了孤立子系统的规划与控制，但动态耦合会破坏整体系统的平坦性。需要找到保持平坦性的耦合类型，并设计可扩展的分布式控制器。

Method: 针对纯反馈形式的子系统，识别一类兼容的下三角动态耦合，证明其保持平坦性且子系统平坦输出仍为耦合系统的平坦输出。利用稀疏结构构建分布式跟踪控制器，仅使用局部信息计算控制动作。

Result: 通过平面四旋翼在空气动力学下洗流动态耦合的仿真验证，分布式控制器实现了精确的轨迹跟踪。

Conclusion: 识别了一类保持微分平坦性的动态耦合，并基于此设计了可扩展的分布式控制器，为耦合非线性系统的分布式控制提供了新方法。

Abstract: We study distributed control for a network of nonlinear, differentially flat subsystems subject to dynamic coupling. Although differential flatness simplifies planning and control for isolated subsystems, the presence of coupling can destroy this property for the overall joint system. Focusing on subsystems in pure-feedback form, we identify a class of compatible lower-triangular dynamic couplings that preserve flatness and guarantee that the flat outputs of the subsystems remain the flat outputs of the coupled system. Further, we show that the joint flatness diffeomorphism can be constructed from those of the individual subsystems and, crucially, its sparsity structure reflects that of the coupling. Exploiting this structure, we synthesize a distributed tracking controller that computes control actions from local information only, thereby ensuring scalability. We validate our proposed framework on a simulated example of planar quadrotors dynamically coupled via aerodynamic downwash, and show that the distributed controller achieves accurate trajectory tracking.

</details>


### [11] [Verifying Closed-Loop Contractivity of Learning-Based Controllers via Partitioning](https://arxiv.org/abs/2512.02262)
*Alexander Davydov*

Main category: eess.SY

TL;DR: 提出一种验证神经网络控制器和收缩度量闭环收缩性的方法，基于区间分析和域划分，在倒立摆系统上验证有效


<details>
  <summary>Details</summary>
Motivation: 解决非线性控制系统中使用神经网络参数化的控制器和收缩度量的闭环收缩性验证问题，传统方法难以处理神经网络参数化系统

Method: 利用区间分析和区间边界传播，推导出可处理且可扩展的充分条件，将收缩性验证简化为检查对称Metzler矩阵的主特征值非正性，结合域划分策略将条件整合到训练中

Result: 在倒立摆系统上验证了该方法能够学习到可证明满足收缩条件的神经网络控制器和收缩度量

Conclusion: 提出的方法能够有效验证神经网络参数化系统的闭环收缩性，为神经网络控制器的安全验证提供了可扩展的解决方案

Abstract: We address the problem of verifying closed-loop contraction in nonlinear control systems whose controller and contraction metric are both parameterized by neural networks. By leveraging interval analysis and interval bound propagation, we derive a tractable and scalable sufficient condition for closed-loop contractivity that reduces to checking that the dominant eigenvalue of a symmetric Metzler matrix is nonpositive. We combine this sufficient condition with a domain partitioning strategy to integrate this sufficient condition into training. The proposed approach is validated on an inverted pendulum system, demonstrating the ability to learn neural network controllers and contraction metrics that provably satisfy the contraction condition.

</details>


### [12] [Edge-Native, Behavior-Adaptive Drone System for Wildlife Monitoring](https://arxiv.org/abs/2512.02285)
*Jenna Kline,Rugved Katole,Tanya Berger-Wolf,Christopher Stewart*

Main category: eess.SY

TL;DR: 提出边缘原生、行为自适应的无人机野生动物监测系统，通过实时群体警觉监测和分级警报，解决操作员注意力瓶颈问题，改善动物福利和数据有效性。


<details>
  <summary>Details</summary>
Motivation: 无人机野生动物监测面临两难：需要足够接近以获取行为相关视频，又要避免引发动物应激反应。操作员存在注意力瓶颈，无法同时控制无人机和监控整个动物群体的警觉状态，当警觉升高明显时，动物的逃离反应可能已不可避免。

Method: 开发边缘原生、行为自适应的无人机决策支持系统，使用YOLOv11m检测和YOLO-Behavior分类持续跟踪个体行为，将警觉状态聚合成实时群体应激指标，提供分级警报（从警觉到逃离反应），操作员可调整阈值以适应特定情境。

Result: 边缘原生流水线在GPU加速硬件上实现23.8ms总推理时间，满足33ms的实时监测要求。回顾分析显示，手动操控平均产生14秒不良行为持续时间和71.9%可用帧；系统可在动物逃离前51秒发出可操作警报（57%任务中）。模拟5秒操作员干预可将可用帧提升至82.8%，不良行为持续时间降至1秒，相比手动操控减少93%。

Conclusion: 该系统通过自动化群体警觉监测和分级警报，有效解决操作员注意力瓶颈问题，显著改善野生动物监测中的动物福利和数据质量，为无人机野生动物监测提供了实用的决策支持工具。

Abstract: Wildlife monitoring with drones must balance competing demands: approaching close enough to capture behaviorally-relevant video while avoiding stress responses that compromise animal welfare and data validity. Human operators face a fundamental attentional bottleneck: they cannot simultaneously control drone operations and monitor vigilance states across entire animal groups. By the time elevated vigilance becomes obvious, an adverse flee response by the animals may be unavoidable. To solve this challenge, we present an edge-native, behavior-adaptive drone system for wildlife monitoring. This configurable decision-support system augments operator expertise with automated group-level vigilance monitoring. Our system continuously tracks individual behaviors using YOLOv11m detection and YOLO-Behavior classification, aggregates vigilance states into a real-time group stress metric, and provides graduated alerts (alert vigilance to flee response) with operator-tunable thresholds for context-specific calibration. We derive service-level objectives (SLOs) from video frame rates and behavioral dynamics: to monitor 30fps video streams in real-time, our system must complete detection and classification within 33ms per frame. Our edge-native pipeline achieves 23.8ms total inference on GPU-accelerated hardware, meeting this constraint with a substantial margin. Retrospective analysis of seven wildlife monitoring missions demonstrates detection capability and quantifies the cost of reactive control: manual piloting results in 14 seconds average adverse behavior duration with 71.9% usable frames. Our analysis reveals operators could have received actionable alerts 51s before animals fled in 57% of missions. Simulating 5-second operator intervention yields a projected performance of 82.8% usable frames with 1-second adverse behavior duration,a 93% reduction compared to manual piloting.

</details>


### [13] [On Frequency-Weighted Extended Balanced Truncation](https://arxiv.org/abs/2512.02298)
*Sribalaji C. Anand,Henrik Sandberg*

Main category: eess.SY

TL;DR: 该论文提出了频率加权扩展平衡截断方法，针对离散和连续时间线性时不变系统，给出了块对角Lyapunov不等式解，提出了递归算法和误差界。


<details>
  <summary>Details</summary>
Motivation: 解决频率加权扩展平衡截断问题，为离散和连续时间线性时不变系统提供有效的模型降阶方法。

Method: 证明了频率加权离散时间系统存在块对角Lyapunov不等式解，提出了扩展平衡截断的递归算法，并推导了相应的先验误差界。

Result: 理论结果扩展到连续时间系统，并通过数值例子验证了方法的有效性。

Conclusion: 论文成功解决了频率加权扩展平衡截断问题，为离散和连续时间系统提供了有效的模型降阶方法，具有理论保证和实际应用价值。

Abstract: This paper addresses the problem of frequency-weighted extended balanced truncation for discrete and continuous-time linear time-invariant plants. We show that the frequency-weighted discrete-time plant admits block-diagonal solutions to both the Lyapunov inequality and its extended form. A recursive algorithm for extended balanced truncation is proposed, together with corresponding a-priori error bounds. Theoretical results are extended to continuous-time systems and validated through numerical examples.

</details>


### [14] [On the Convergence of Density-Based Predictive Control for Multi-Agent Non-Uniform Area Coverage](https://arxiv.org/abs/2512.02367)
*Sungjun Seo,Kooktae Lee*

Main category: eess.SY

TL;DR: DPC是一种基于最优传输理论的多智能体控制策略，通过参考分布实现非均匀区域覆盖，优先覆盖高优先级区域。


<details>
  <summary>Details</summary>
Motivation: 大规模场景（如搜救、环境监测）中，传统均匀覆盖无法处理区域优先级差异，需要根据重要性分配覆盖资源。

Method: 基于最优传输理论，利用预构建的参考分布分配智能体覆盖努力；分析Wasserstein距离收敛条件，推导无约束情况下的解析最优控制律，提出约束场景的数值方法。

Result: 在一阶动力学和线性化四旋翼模型上的仿真显示，DPC能生成与参考分布高度匹配的轨迹，优于现有覆盖方法。

Conclusion: DPC为多智能体非均匀区域覆盖提供了一种有效的控制策略，基于最优传输理论，能根据区域优先级自适应分配覆盖资源。

Abstract: This paper presents Density-based Predictive Control (DPC), a novel multi-agent control strategy for efficient non-uniform area coverage, grounded in optimal transport theory. In large-scale scenarios such as search and rescue or environmental monitoring, traditional uniform coverage fails to account for varying regional priorities. DPC leverages a pre-constructed reference distribution to allocate agents' coverage efforts, spending more time in high-priority or densely sampled regions. We analyze convergence conditions using the Wasserstein distance, derive an analytic optimal control law for unconstrained cases, and propose a numerical method for constrained scenarios. Simulations on first-order dynamics and linearized quadrotor models demonstrate that DPC achieves trajectories closely matching the non-uniform reference distribution, outperforming existing coverage methods.

</details>


### [15] [Fleet Size and Mix Capacitated Vehicle Routing Problem with Time Windows for Mobile Fast Chargers](https://arxiv.org/abs/2512.02381)
*Farhang Motallebi Araghi,Armin Abdolmohammdi,Navid Mojahed,Shima Nazari*

Main category: eess.SY

TL;DR: 本文提出了一种用于移动快速充电车（MFCV）部署的混合整数线性规划模型，联合优化车队组成、充电器规格、路径规划和服务调度，以最小化总成本。


<details>
  <summary>Details</summary>
Motivation: 偏远地区重型设备的电气化面临固定充电基础设施有限的挑战。现有的MFCV规划方法通常将车队设计和路径规划作为独立问题处理，无法实现整体优化。

Method: 构建了带时间窗的车队规模与混合容量车辆路径问题（FSMCVRPTW）模型，整合了不同功率、电池容量、燃料续航和成本结构的MFCV类型，使用Python/Gurobi实现。

Result: 在洛杉矶（密集城市）和Truckee（稀疏山区）的案例研究中，同时优化产生了紧凑、利用率高的车队，满足所有服务时间窗，并显示单位成本对需求密度和地理环境高度敏感。

Conclusion: 提出的FSMCVRPTW框架提供了一个通用的决策支持方法，能够在单一优化层中共同设计车队规模、充电器功率、路径和服务调度，实现情境感知、成本高效的移动快速充电。

Abstract: The electrification of off-road heavy equipment presents operational challenges for agencies serving remote sites with limited fixed charging infrastructure. Existing mobile fast charging vehicle (MFCV) planning approaches typically treat fleet design and routing as separate problems, fixing vehicle characteristics before dispatch. This paper formulates a fleet size and mix capacitated vehicle routing problem with time windows (FSMCVRPTW) for MFCV deployment, jointly optimizing fleet composition, charger specifications, routing, and scheduling within a unified mixed-integer linear program. The model incorporates heterogeneous MFCV types with varying power ratings, battery capacities, fuel range, and cost structures, minimizing total daily cost from labor, fuel, amortized capital expenditure, and energy purchase under temporal service windows, resource budgets, and energy-delivery constraints. The formulation is implemented in Python/Gurobi and applied to two case studies using California Department of Transportation wheel-loader data in Los Angeles (dense urban) and Truckee (sparse mountainous). Results show that simultaneous optimization yields compact, well-utilized fleets that meet all service windows while revealing strong sensitivity of unit cost to demand density and geography. The proposed FSMCVRPTW framework provides a generalizable decision-support methodology that co-designs fleet size, charger power, routing, and service schedules in a single optimization layer for context-aware, cost-efficient mobile fast charging.

</details>


### [16] [Necessary and Sufficient Conditions for PID Design of MIMO Nonlinear Systems](https://arxiv.org/abs/2512.02452)
*Tianyou Xiang,Cheng Zhao*

Main category: eess.SY

TL;DR: 为非线性不确定MIMO二阶系统提供PID增益设计的充分必要条件区域，基于Jacobian界和输入增益下界给出闭式解


<details>
  <summary>Details</summary>
Motivation: 经典PID控制在工业过程中普遍应用，但对于非线性不确定MIMO二阶系统缺乏严格明确的设计理论。现有方法多为定性调参，需要建立基于系统不确定性的定量设计框架。

Method: 考虑一类具有不确定动态和未知但严格正输入增益的非线性MIMO二阶系统，用状态变量Jacobian的界来表征非线性不确定性。构造PID增益的三维区域，保证对所有满足Jacobian界的非线性系统都能实现全局稳定性和常数参考信号的渐近跟踪。

Result: 推导出保证全局稳定的充分条件区域和必要条件区域，揭示了应对最坏情况不确定性所需的保守性。在额外结构假设下，充分和必要区域重合，得到全局稳定PID增益的精确充要条件。所有区域都以闭式给出，仅依赖于预设的Jacobian界和已知的输入增益下界。

Conclusion: 为非线性不确定MIMO二阶系统建立了定量PID设计理论，提供了基于系统不确定性界限的闭式增益选择区域，相比文献中的定性调参方法更具理论严谨性和实用性。

Abstract: As is well known, classical PID control is ubiquitous in industrial processes, yet a rigorous and explicit design theory for nonlinear uncertain MIMO second-order systems remains underdeveloped. In this paper we consider a class of such systems with both uncertain dynamics and an unknown but strictly positive input gain, where the nonlinear uncertainty is characterized by bounds on the Jacobian with respect to the state variables. We explicitly construct a three-dimensional region for the PID gains that is sufficient to guarantee global stability and asymptotic tracking of constant references for all nonlinearities satisfying these Jacobian bounds. We then derive a corresponding necessary region, thereby revealing the inherent conservatism required to cope with worst-case uncertainties. Moreover, under additional structural assumptions on the nonlinearities, these sufficient and necessary regions coincide, yielding a precise necessary-and-sufficient characterization of all globally stabilizing PID gains. All these regions are given in closed form and depend only on the prescribed Jacobian bounds and the known lower bound of the input gain, in contrast to many qualitative tuning methods in the literature.

</details>


### [17] [Intervention Strategies for Fairness and Efficiency at Autonomous Single-Intersection Traffic Flows](https://arxiv.org/abs/2512.02562)
*Salman Ghori,Ania Adil,Melkior Ornik,Eric Feron*

Main category: eess.SY

TL;DR: 研究在无信号正交交叉口，通过MILP优化自动驾驶车辆协调，分析集中干预时机对安全、效率和公平性的影响，特别关注公平性约束对系统效率和车队形成的影响。


<details>
  <summary>Details</summary>
Motivation: 交叉口交通管理中，安全与效率目标往往以牺牲公平性为代价，而公平性对于可信度和长期可持续性至关重要。本文旨在研究集中干预时机如何影响无信号正交交叉口自动驾驶车辆的管理，在满足安全约束的同时评估效率和确保公平性。

Method: 采用混合整数线性规划（MILP）方法，在交叉口为中心的圆形控制区内优化车辆协调。引入通过成对反转次数衡量的公平性概念，并将公平性约束纳入MILP框架。研究公平性与系统效率的关系及其对车队形成的影响。

Result: 通过仿真研究分析了早期与晚期干预策略以及公平感知控制的有效性，重点关注控制区内车辆的安全、高效和鲁棒管理。

Conclusion: 该研究为无信号交叉口自动驾驶车辆管理提供了综合考虑安全、效率和公平性的优化框架，通过MILP方法和公平性约束实现了更平衡的交通管理策略，特别强调了干预时机对系统性能的影响。

Abstract: Intersections present significant challenges in traffic management, where ensuring safety and efficiency is essential for effective flow. However, these goals are often achieved at the expense of fairness, which is critical for trustworthiness and long-term sustainability. This paper investigates how the timing of centralized intervention affects the management of autonomous agents at a signal-less, orthogonal intersection, while satisfying safety constraints, evaluating efficiency, and ensuring fairness. A mixed-integer linear programming (MILP) approach is used to optimize agent coordination within a circular control zone centered at the intersection. We introduce the concept of fairness, measured via pairwise reversal counts, and incorporate fairness constraints into the MILP framework. We then study the relationship between fairness and system efficiency and its impact on platoon formation. Finally, simulation studies analyze the effectiveness of early versus late intervention strategies and fairness-aware control, focusing on safe, efficient, and robust management of agents within the control zone.

</details>


### [18] [Reduced-order Smith predictor for state feedback control with guaranteed stability](https://arxiv.org/abs/2512.02579)
*Jesus-Pablo Toledo-Zucco,Frédéric Gouaisbaut,Gaetan Chapput*

Main category: eess.SY

TL;DR: 提出一种基于动态控制器的Smith预测器实现方法，用于状态空间表示中的状态反馈控制，通过LMI条件保证闭环系统稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统Smith预测器控制律中包含需要近似实现的积分项，现有实现方法存在局限性，需要更有效的实现方案。

Method: 提出新的动态控制器实现方法，控制律由状态反馈项和逼近积分项的动态项组成，通过Lyapunov泛函和线性矩阵不等式(LMI)提供稳定性保证条件。

Result: 建立了保证闭环系统稳定性的充分条件，并通过三个文献中的示例验证了所提方法的优势。

Conclusion: 提出的动态控制器实现方法能有效近似Smith预测器中的积分项，通过LMI条件确保系统稳定性，相比现有方法具有明显优势。

Abstract: This article deals with the implementation of the Smith Predictor for state feedback control in state space representation. The desired control law, obtained using partial differential equations and backstepping control, contains an integral term that has to be approximated for implementation. In this article, we propose a new way to implement this control law using a dynamic controller. The control law is composed of a state feedback term and a dynamic term that approaches the integral term that has to be estimated for implementation. Using a Lyapunov functional, we provide sufficient conditions, in terms of a linear matrix inequality, to guarantee that the closed-loop system is stable when the proposed control law is applied. We use three examples, taken from the literature, to show the benefits of the proposed approach.

</details>


### [19] [Modal Analysis of Core Inertial Dynamics: Re-evaluating Grid-Forming Control Design Principles](https://arxiv.org/abs/2512.02662)
*Gerardo Medrano,Santiago Cóbreces*

Main category: eess.SY

TL;DR: 传统同步发电机与电网形成型换流器的惯性动态对比研究显示，当前行业模仿传统同步发电机的高惯性和大下垂控制策略可能并非最优，低下垂和低虚拟惯性反而能获得更好的稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 研究电网形成型(GFM)换流器与传统调速器控制同步发电机(GC-SG)的核心惯性动态及基本相互作用，评估当前行业模仿传统同步发电机控制策略的有效性，探索更优的逆变器控制设计原则。

Method: 采用模态分析方法，研究GC-SG和基于下垂控制的GFM换流器的核心惯性动态，分析它们的基本相互作用，比较不同控制参数（下垂常数、虚拟惯性）对系统稳定性和性能的影响。

Result: 研究发现：1) GC-SG存在基本权衡：充分阻尼涡轮-调速器模式需要大下垂常数，但会增加稳态频率偏差；2) GFM换流器相反：减小下垂常数同时降低稳态频率偏差并增加阻尼；3) 用GFM替换GC-SG能显著改善摆动模式和涡轮-调速器模式的阻尼；4) 大幅降低GFM虚拟惯性常数能获得更好的阻尼效果。

Conclusion: 当前行业趋势可能限制了逆变器资源的潜在效益，最优稳定性和性能通过低下垂和低虚拟惯性实现，能获得紧密有界的频率变化和强阻尼的机电模式，需要重新评估GFM控制设计原则和电网规范要求。

Abstract: This paper employs modal analysis to study the core inertial dynamics of governor-controlled synchronous generators (GC-SG), droop-based grid-forming (GFM) converters, and their most fundamental interactions. The results indicate that even in the simplest cases, the prevailing industry paradigm of emulating legacy GC-SG behaviour in GFM converters (high inertia to slow down the system and large droop to increase damping) could be a suboptimal policy. It is shown that GC-SGs exhibit a fundamental trade-off: adequate damping of the turbine-governor mode requires large droop constants, inevitably increasing steady-state frequency deviation and dependence on secondary regulation. In contrast, droop-based GFM converters invert this relationship: decreasing the droop constant simultaneously reduces steady-state frequency deviations and increases damping, while allowing virtual inertia to be freely chosen. When two GC-SGs are coupled, the poorly damped electromechanical swing mode emerges. Results show that replacing one GC-SG with a GFM converter of equivalent droop and inertia already significantly improves damping of both swing and turbine-governor modes. Counter-intuitively, further and remarkable damping gains are achieved by substantially lowering the GFM virtual inertia constant. These findings suggest that current industry trends may be constraining the potential benefits of Inverter Based Resources (IBRs). Optimal stability and performance are instead obtained with low droop and low virtual inertia, yielding tightly bounded frequency variations and strongly-damped electromechanical modes. The results indicate a need to re-evaluate GFM control design principles and emerging grid-code requirements.

</details>


### [20] [Off-grid solar energy storage system with lithium iron phosphate (LFP) batteries in high mountains: a case report of Tianchi Lodge in Taiwan](https://arxiv.org/abs/2512.02679)
*Hsien-Ching Chung*

Main category: eess.SY

TL;DR: 台湾天池山庄采用离网太阳能储能系统（LFP电池）解决高山小屋能源供应问题


<details>
  <summary>Details</summary>
Motivation: 高山小屋位于高海拔地区，为徒步者提供庇护所，但其能源供应一直是个挑战。使用可再生能源可能是合适的解决方案。

Method: 台湾天池山庄自2020年起运行离网太阳能储能系统，采用磷酸铁锂（LFP）电池。论文提供了该系统的能源架构、详细描述和历史运行状态。

Result: 通过案例报告展示了该系统的实际运行情况，为高山小屋可再生能源应用提供了具体实例。

Conclusion: 离网太阳能储能系统（特别是LFP电池）是解决高山小屋能源供应问题的可行方案，天池山庄的案例为类似场景提供了参考。

Abstract: Mountain huts are buildings located at high altitude, providing shelter and a place for hikers. Energy supply on mountain huts remains an open issue. Using renewable energies could be an appropriate solution. Tianchi Lodge, a famous mountain hut in Taiwan, has operated an off-grid solar energy storage system with lithium iron phosphate (LFP) batteries since 2020. In this case report, the energy architecture, detailed descriptions, and historical status of the system are provided.

</details>


### [21] [Gain-Scheduling Data-Enabled Predictive Control for Nonlinear Systems with Linearized Operating Regions](https://arxiv.org/abs/2512.02797)
*Sebastian Zieglmeier,Mathias Hudoba de Badyn,Narada D. Warakagoda,Thomas R. Krogstad,Paal Engelstad*

Main category: eess.SY

TL;DR: 提出基于多局部线性数据表示的增益调度数据驱动预测控制框架，通过分区Hankel矩阵和复合区域实现非线性系统控制


<details>
  <summary>Details</summary>
Motivation: 传统DeePC方法在处理非线性系统时性能有限，需要更有效的数据驱动控制框架来应对非线性动态

Method: 将可测量调度变量的操作范围划分为多个区域，为每个区域构建局部Hankel矩阵，引入复合区域实现平滑过渡和抗抖振，保持原始DeePC问题结构

Result: 在非线性直流电机不平衡盘实验中，相比标准DeePC方法，控制性能显著提升，同时计算复杂度降低

Conclusion: GS-DeePC框架通过局部线性数据表示有效处理非线性系统控制问题，在保持计算效率的同时实现优越的控制性能

Abstract: This paper presents a Gain-Scheduled Data-Enabled Predictive Control (GS-DeePC) framework for nonlinear systems based on multiple locally linear data representations. Instead of relying on a single global Hankel matrix, the operating range of a measurable scheduling variable is partitioned into regions, and regional Hankel matrices are constructed from persistently exciting data. To ensure smooth transitions between linearization regions and suppress region-induced chattering, composite regions are introduced, merging neighboring data sets and enabling a robust switching mechanism. The proposed method maintains the original DeePC problem structure and can achieve reduced computational complexity by requiring only short, locally informative data sequences. Extensive experiments on a nonlinear DC-motor with an unbalanced disc demonstrate the significantly improved control performance compared to standard DeePC.

</details>


### [22] [System Identification for Dynamic Modeling of a Bumper Car](https://arxiv.org/abs/2512.02803)
*Tobias Petri,Simone Baratto,Giancarlo Ferrari Trecate*

Main category: eess.SY

TL;DR: 论文提出了用于教育实验框架的高机动性自动驾驶车辆建模方法，开发了改进的平面自行车模型，结合参数和非参数识别技术，物理信息神经网络模型在精度和计算成本上优于纯物理基线模型。


<details>
  <summary>Details</summary>
Motivation: 标准自行车模型通常忽略宽转向角，无法满足高机动性自动驾驶车辆的教育实验需求，需要开发更准确的建模方法。

Method: 开发改进的平面自行车模型，结合参数化（物理知识）和非参数化识别技术，采用渐进式物理知识融合方法，系统比较不同模型的精度与计算需求。

Result: 物理信息神经网络模型在精度上超越了纯物理基线模型，同时具有更低的计算成本，实现了精度与计算效率的良好平衡。

Conclusion: 通过结合物理知识和数据驱动方法，物理信息神经网络为高机动性自动驾驶车辆建模提供了有效的解决方案，特别适合教育实验框架的应用。

Abstract: This paper presents the modeling of autonomous vehicles with high maneuverability used in an experimental framework for educational purposes. Since standard bicycle models typically neglect wide steering angles, we develop modified planar bicycle models and combine them with both parametric and non-parametric identification techniques that progressively incorporate physical knowledge. The resulting models are systematically compared to evaluate the tradeoff between model accuracy and computational requirements, showing that physics-informed neural network models surpass the purely physical baseline in accuracy at lower computational cost.

</details>


### [23] [Tempering the Bayes Filter towards Improved Model-Based Estimation](https://arxiv.org/abs/2512.02823)
*Menno van Zutphen,Domagoj Herceg,Giannis Delimpaltadakis,Duarte J. Antunes*

Main category: eess.SY

TL;DR: 提出"温度贝叶斯滤波器"，通过三种温度调节方式改进不完美模型下的预测性能，计算复杂度与原始贝叶斯滤波器相同，在特定条件下可提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 基于模型的滤波常面临模型不完美的问题，学习部分可观测随机系统仍然具有挑战性。现有贝叶斯推断研究发现，对不完美模型的似然或完整后验进行"温度调节"可以改善预测准确性。

Method: 开发了温度贝叶斯滤波器，通过三种调节方式改进估计性能：1) 似然温度调节（影响先验与似然平衡），2) 完整后验温度调节（调节最终信念分布的熵水平），3) 新引入的调节方式。该方法允许递归实现，计算复杂度不高于原始贝叶斯滤波器。

Result: 分析发现温度调节空间的一个区域可以理解为在贝叶斯滤波器和MAP滤波器之间插值，将两者作为特例恢复。理论分析建立了温度贝叶斯滤波器改善预测性能的条件。在线性高斯情况下得到温度卡尔曼滤波器，解释了参数如何影响卡尔曼状态估计和协方差传播。实证结果证实该方法在预测准确性上始终优于贝叶斯滤波器基线。

Conclusion: 温度贝叶斯滤波器通过多种温度调节方式有效改善了不完美模型下的预测性能，计算效率高，为模型不完美情况下的滤波问题提供了系统解决方案。

Abstract: Model-based filtering is often carried out while subject to an imperfect model, as learning partially-observable stochastic systems remains a challenge. Recent work on Bayesian inference found that tempering the likelihood or full posterior of an imperfect model can improve predictive accuracy, as measured by expected negative log likelihood. In this paper, we develop the tempered Bayes filter, improving estimation performance through both of the aforementioned, and one newly introduced, modalities. The result admits a recursive implementation with a computational complexity no higher than that of the original Bayes filter. Our analysis reveals that -- besides the well-known fact in the field of Bayesian inference that likelihood tempering affects the balance between prior and likelihood -- full-posterior tempering tunes the level of entropy in the final belief distribution. We further find that a region of the tempering space can be understood as interpolating between the Bayes- and MAP filters, recovering these as special cases. Analytical results further establish conditions under which a tempered Bayes filter achieves improved predictive performance. Specializing the results to the linear Gaussian case, we obtain the tempered Kalman filter. In this context, we interpret how the parameters affect the Kalman state estimate and covariance propagation. Empirical results confirm that our method consistently improves predictive accuracy over the Bayes filter baseline.

</details>


### [24] [PAC-Bayesian Optimal Control with Stability and Generalization Guarantees](https://arxiv.org/abs/2512.02858)
*Mahrokh Ghoddousi Boroujeni,Clara Lucía Galimberti,Andreas Krause,Giancarlo Ferrari-Trecate*

Main category: eess.SY

TL;DR: 提出一个PAC-Bayesian框架为随机非线性最优控制建立严格泛化界，平衡经验性能和先验知识，保证闭环稳定性


<details>
  <summary>Details</summary>
Motivation: 随机非线性最优控制中，使用有限噪声样本的经验成本替代期望成本会导致过拟合问题，特别是在数据集有限时，训练控制器在未见扰动下的性能无法保证

Method: 基于PAC-Bayesian理论建立严格泛化界，提出控制器设计方法平衡经验性能和先验知识，推导计算高效松弛界并使用近似推理方法，采用表达能力强的神经网络控制器参数化保证闭环稳定性

Result: 开发了理论框架和计算方法，通过仿真示例展示了如何将先验知识融入控制设计，并为协作机器人合成更可靠的控制器

Conclusion: 提出的PAC-Bayesian框架为随机非线性最优控制提供了严格的泛化保证，平衡了经验性能和先验知识，确保了控制器在未见扰动下的可靠性

Abstract: Stochastic Nonlinear Optimal Control (SNOC) seeks to minimize a cost function that accounts for random disturbances acting on a nonlinear dynamical system. Since the expectation over all disturbances is generally intractable, a common surrogate is the empirical cost, obtained by averaging over a finite dataset of sampled noise realizations. This substitution, however, introduces the challenge of guaranteeing performance under unseen disturbances. The issue is particularly severe when the dataset is limited, as the trained controllers may overfit, leading to substantial gaps between their empirical cost and the deployment cost. In this work, we develop a PAC-Bayesian framework that establishes rigorous generalization bounds for SNOC. Building on these bounds, we propose a principled controller design method that balances empirical performance and prior knowledge. To ensure tractability, we derive computationally efficient relaxations of the bounds and employ approximate inference methods. Our framework further leverages expressive neural controller parameterizations, guaranteeing closed-loop stability. Through simulated examples, we highlight how prior knowledge can be incorporated into control design and how more reliable controllers can be synthesized for cooperative robotics.

</details>


### [25] [AC/DC Frequency-Dependent Power Flow Jacobian: Quantifying Grid Support and Stability Implications](https://arxiv.org/abs/2512.02872)
*Dongyeong Lee,Eros Avdiaj,Jef Beerten*

Main category: eess.SY

TL;DR: 该论文提出了一种AC/DC频率相关潮流雅可比分析方法来识别系统支撑能力，并发现系统支撑能力不一定增强系统稳定裕度，表明窄频带和AC侧聚焦的技术要求可能无法实现预期的电网跟随型逆变器性能。


<details>
  <summary>Details</summary>
Motivation: 当前电网跟随型逆变器（GFM）的技术要求主要关注窄频带和AC侧规范，但缺乏对这些要求是否真正增强系统稳定性的系统分析。需要开发新的分析方法来评估GFM的系统支撑能力及其对稳定性的实际影响。

Method: 提出了一种AC/DC频率相关的潮流雅可比分析方法，通过分析系统在频率变化时的动态响应来识别和量化GFM的系统支撑能力，并评估这些能力对系统稳定裕度的影响。

Result: 分析表明，系统支撑能力并不总是增强系统稳定裕度，有时甚至可能降低稳定性。窄频带和AC侧聚焦的技术要求可能无法实现预期的GFM性能，需要更全面的系统级评估方法。

Conclusion: 传统的GFM技术要求需要重新审视，应开发更全面的系统级分析方法来评估GFM的实际性能，确保技术规范能够真正增强电力系统的稳定性。

Abstract: This letter proposes an AC/DC frequency-dependent power flow Jacobian analysis to identify the system support capabilities. In addition, the analyses reveal that system support capabilities do not necessarily enhance the system stability margin, suggesting that technical requirements of narrow-frequency-band and AC-side focused specifications may not lead to the expected performance of GFM.

</details>


### [26] [Statistical-Symbolic Verification of Perception-Based Autonomous Systems using State-Dependent Conformal Prediction](https://arxiv.org/abs/2512.02893)
*Yuang Geng,Thomas Waite,Trevor Turnquist,Radoslav Ivanov,Ivan Ruchkin*

Main category: eess.SY

TL;DR: 提出状态依赖的conformal prediction方法，结合遗传算法优化状态空间划分，以及分支合并可达性算法，用于神经感知系统的可验证性分析，减少保守性并提高可扩展性。


<details>
  <summary>Details</summary>
Motivation: 神经感知系统的可达性分析面临挑战，因为感知模型不完美或难以处理。现有方法通常结合统计分析和可达性，但时间序列数据的conformal prediction方法往往提供保守的边界，导致误差随时间累积，难以实现可证明、可扩展且保守性最小的验证。

Method: 1. 提出状态依赖的conformal prediction方法，利用感知误差随系统动态状态变化的特性构建紧致的高置信度边界；2. 使用遗传算法对状态空间进行划分，优化conformal边界的紧致性；3. 提出分支合并可达性算法，在混合系统中处理额外的不确定性和分支，平衡不确定性和可扩展性。

Result: 在两个互补的案例研究中评估了验证方法，与现有技术相比，显著减少了保守性。

Conclusion: 通过状态依赖的conformal prediction、遗传算法优化的状态空间划分和分支合并可达性算法，实现了神经感知系统的可扩展且紧致的验证，减少了保守性，为神经控制自主系统的安全保证提供了更有效的方法。

Abstract: Reachability analysis has been a prominent way to provide safety guarantees for neurally controlled autonomous systems, but its direct application to neural perception components is infeasible due to imperfect or intractable perception models. Typically, this issue has been bypassed by complementing reachability with statistical analysis of perception error, say with conformal prediction (CP). However, existing CP methods for time-series data often provide conservative bounds. The corresponding error accumulation over time has made it challenging to combine statistical bounds with symbolic reachability in a way that is provable, scalable, and minimally conservative. To reduce conservatism and improve scalability, our key insight is that perception error varies significantly with the system's dynamical state. This article proposes state-dependent conformal prediction, which exploits that dependency in constructing tight high-confidence bounds on perception error. Based on this idea, we provide an approach to partition the state space, using a genetic algorithm, so as to optimize the tightness of conformal bounds. Finally, since using these bounds in reachability analysis leads to additional uncertainty and branching in the resulting hybrid system, we propose a branch-merging reachability algorithm that trades off uncertainty for scalability so as to enable scalable and tight verification. The evaluation of our verification methodology on two complementary case studies demonstrates reduced conservatism compared to the state of the art.

</details>


### [27] [GNSS Array-Based Multipath Detection Employing UKF on Manifolds](https://arxiv.org/abs/2512.02994)
*Abdelgabar Ahmed,Tarig Ballal,Xing Liu,Mohanad Ahmed,Tareq Y. Al-Naffouri*

Main category: eess.SY

TL;DR: 该论文提出了一种结合GNSS阵列和IMU数据的多路径检测算法，通过UKF滤波器和RANSAC算法实时估计姿态并排除受多路径影响的卫星，显著提高了城市环境中的定位精度。


<details>
  <summary>Details</summary>
Motivation: GNSS应用在城市环境中常受多路径干扰影响，这是最具挑战性的误差源之一。现有方法需要改进以在动态场景中有效检测和排除多路径干扰，提高定位和姿态确定的准确性。

Method: 1. 实现GNSS阵列多路径检测算法，结合实时姿态估计；2. 使用流形上的Unscented Kalman Filter (UKF)融合GNSS和IMU数据，实现连续姿态跟踪；3. 利用卫星组合的姿态信息识别并排除受多路径影响的卫星；4. 采用Random Sample Consensus (RANSAC)算法减少卫星组合评估的计算量，同时保持高检测性能。

Result: 使用KITTI数据集的轨迹和IMU读数进行评估，基于真实位置和卫星星历模拟GNSS观测。结果表明该方法能有效检测受多路径干扰的卫星，在大量可见卫星受严重多路径污染的场景中，定位精度得到显著改善。

Conclusion: 提出的方法通过融合GNSS阵列和IMU数据，结合UKF滤波器和RANSAC算法，成功实现了动态场景下的实时多路径检测和排除，显著提高了城市环境中GNSS定位的准确性和可靠性。

Abstract: Global Navigation Satellite Systems (GNSS) applications are often hindered by various sources of error, with multipath interference being one of the most challenging, particularly in urban environments. In this work, we build on previous research by implementing a GNSS array-based multipath detection algorithm, incorporating real-time attitude estimation for dynamic scenarios. The method fuses GNSS and IMU data using an Unscented Kalman Filter (UKF) on a manifold, enabling continuous attitude tracking. The proposed approach utilizes attitude information from satellite combinations to identify and exclude multipath-affected satellites, improving the accuracy of both positioning and attitude determination. To address computational challenges associated with evaluating large numbers of satellite combinations, we propose the use of the Random Sample Consensus (RANSAC) algorithm, which reduces the number of combinations assessed while maintaining high detection performance. Performance evaluations are conducted using trajectories and IMU readings from the KITTI dataset. GNSS observations are simulated based on ground truth positions and satellite ephemeris. The results demonstrate the effectiveness of the proposed approach in detecting satellites affected by multipath interference. Significant improvements in positioning accuracy are observed, particularly in scenarios where a large portion of the visible satellites are contaminated by severe multipath.

</details>


### [28] [Learning Physically Consistent Lagrangian Control Models Without Acceleration Measurements](https://arxiv.org/abs/2512.03035)
*Ibrahim Laiche,Mokrane Boudaoud,Patrick Gallinari,Pascal Morin*

Main category: eess.SY

TL;DR: 提出一种基于原始损失函数的学习算法，用于提高拉格朗日系统的物理一致性，避免传统拉格朗日神经网络在有限、部分和噪声数据下产生不一致模型的问题。


<details>
  <summary>Details</summary>
Motivation: 拉格朗日或哈密顿神经网络虽然提供有用的结构保证，但在实际物理系统中，由于训练数据有限、部分和噪声，学习这类模型常常导致不一致的模型。为了将这些模型用于基于模型的非线性控制，需要提高模型的物理一致性。

Method: 提出一种混合方法，不需要加速度计算，使用原始损失函数的学习算法来改进拉格朗日系统的物理一致性。该方法专注于推导和识别物理一致的模型。

Result: 在模拟和实验系统上，与不同基于学习的建模方法进行比较分析，显示所提解决方案在学习模型的物理一致性方面有显著改进。在实验基准上展示了该方法对反馈线性化和基于能量控制技术的实际相关性。

Conclusion: 提出的学习算法能有效提高拉格朗日系统的物理一致性，为基于模型的非线性控制提供了实用的方法论，特别适用于实际物理系统。

Abstract: This article investigates the modeling and control of Lagrangian systems involving non-conservative forces using a hybrid method that does not require acceleration calculations. It focuses in particular on the derivation and identification of physically consistent models, which are essential for model-based control synthesis. Lagrangian or Hamiltonian neural networks provide useful structural guarantees but the learning of such models often leads to inconsistent models, especially on real physical systems where training data are limited, partial and noisy. Motivated by this observation and the objective to exploit these models for model-based nonlinear control, a learning algorithm relying on an original loss function is proposed to improve the physical consistency of Lagrangian systems. A comparative analysis of different learning-based modeling approaches with the proposed solution shows significant improvements in terms of physical consistency of the learned models, on both simulated and experimental systems. The model's consistency is then exploited to demonstrate, on an experimental benchmark, the practical relevance of the proposed methodology for feedback linearization and energy-based control techniques.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [29] [Reconstructing Large Scale Production Networks](https://arxiv.org/abs/2512.02362)
*Ashwin Bhattathiripad,Vipin P Veetil*

Main category: econ.GN

TL;DR: 提出一种基于企业规模和部门投入产出流重建大规模加权企业间网络的算法，可重建美国500万企业、1亿连接的完整生产网络。


<details>
  <summary>Details</summary>
Motivation: 需要从公开可得的有限数据（企业规模和部门投入产出流）重建大规模、细粒度的企业间网络，以研究生产网络结构特征。

Method: 四步法：1) 使用增强重力模型（企业规模为质量，部门间流量为参数）生成连接概率矩阵；2) 伯努利抽样构建有向无权随机图；3) 添加自环和强连通分量间连接使图非周期且不可约；4) 通过凸二次规划最小化权重欧几里得范数，将无权图转为加权图，同时保持观测的企业规模和部门流量。

Result: 成功重建美国完整生产网络（500万企业，1亿买方-卖方连接），网络拓扑特征（度分布肥尾、适度聚类、接近零互惠性）与真实美国买方-卖方网络小样本一致。算法复杂度最坏情况O(N²)，但可通过部门规模分箱降至O(N)（有近似误差）。

Conclusion: 该算法能从公开数据重建大规模细粒度生产网络，为研究者提供分析工具，开源代码促进相关研究。

Abstract: This paper develops an algorithm to reconstruct large weighted firm-to-firm networks using information about the size of the firms and sectoral input-output flows. Our algorithm is based on a four-step procedure. We first generate a matrix of probabilities of connections between all firms in the economy using an augmented gravity model embedded in a logistic function that takes firm size as mass. The model is parameterized to allow for the probability of a link between two firms to depend not only on their sizes but also on flows across the sectors to which they belong. We then use a Bernoulli draw to construct a directed but unweighted random graph from the probability distribution generated by the logistic-gravity function. We make the graph aperiodic by adding self-loops and irreducible by adding links between Strongly Connected Components while limiting distortions to sectoral flows. We convert the unweighted network to a weighted network by solving a convex quadratic programming problem that minimizes the Euclidean norm of the weights. The solution preserves the observed firm sizes and sectoral flows within reasonable bounds, while limiting the strength of the self-loops. Computationally, the algorithm is O(N2) in the worst case, but it can be evaluated in O(N) via sector-wise binning of firm sizes, albeit with an approximation error. We implement the algorithm to reconstruct the full US production network with more than 5 million firms and 100 million buyer-seller connections. The reconstructed network exhibits topological properties consistent with small samples of the real US buyer-seller networks, including fat-tails in degree distribution, mild clustering, and near-zero reciprocity. We provide open-source code of the algorithm to enable researchers to reconstruct large-scale granular production networks from publicly available data.

</details>


### [30] [Optimal Comprehensible Targeting](https://arxiv.org/abs/2512.02424)
*Walter W. Zhang*

Main category: econ.GN

TL;DR: 论文提出了一个框架，帮助企业设计可解释的个性化营销策略以符合GDPR等法规的"解释权"要求，量化了可解释性带来的利润成本。


<details>
  <summary>Details</summary>
Motivation: 欧盟GDPR等数据隐私法规要求企业提供可解释的营销策略，但机器学习和大数据技术通常产生难以理解的"黑箱"模型，企业需要在合规性和利润最大化之间找到平衡。

Method: 1) 构建由简单句子表示的可解释策略类别；2) 开发优化方法直接估计最优可解释策略；3) 比较最优黑箱策略与可解释策略的利润差异；4) 使用耐用消费品零售商的价格促销实验数据进行实证分析。

Result: 相比黑箱基准，可解释策略使利润减少7.5%（相当于每客户23美分），量化了"解释成本"。直接估计可解释策略优于将黑箱策略投影为可解释形式。

Conclusion: 企业可以通过直接优化可解释策略来满足法规要求，同时最小化利润损失。该框架为企业在数据隐私法规下平衡合规与盈利提供了实用解决方案。

Abstract: Developments in machine learning and big data allow firms to fully personalize and target their marketing mix. However, data and privacy regulations, such as those in the European Union (GDPR), incorporate a "right to explanation," which is fulfilled when targeting policies are comprehensible to customers. This paper provides a framework for firms to navigate right-to-explanation legislation. First, I construct a class of comprehensible targeting policies that is represented by a sentence. Second, I show how to optimize over this class of policies to find the profit-maximizing comprehensible policy. I further demonstrate that it is optimal to estimate the comprehensible policy directly from the data, rather than projecting down the black box policy into a comprehensible policy. Third, I find the optimal black box targeting policy and compare it to the optimal comprehensible policy. I then empirically apply my framework using data from a price promotion field experiment from a durable goods retailer. I quantify the cost of explanation, which I define as the difference in expected profits between the optimal black box and comprehensible targeting policies. Compared to the black box benchmark, the comprehensible targeting policy reduces profits by 7.5% or 23 cents per customer.

</details>


### [31] [How IFRS Affects Value Relevance and Key Financial Indicators? Evidence from the UK](https://arxiv.org/abs/2512.02480)
*Yhlas Sovbetov*

Main category: econ.GN

TL;DR: 该研究通过TEST-A和TEST-B分析，发现IFRS采纳对英国公司的价值相关性有积极影响，并对盈利能力比率（ROCE、ROA、PM）产生显著正面影响，但对效率-流动性比率无显著影响。


<details>
  <summary>Details</summary>
Motivation: 研究国际财务报告准则（IFRS）采纳对英国公司价值相关性和关键财务指标的影响，填补IFRS采纳文献中的研究空白。

Method: 采用TEST-A分析（非参数检验）检验IFRS对价值相关性的影响（H01假设），使用TEST-B分析检验IFRS对关键财务指标的影响（H02假设），包括Ohlson模型和逐步回归分析。

Result: TEST-A拒绝了H01假设，表明IFRS对价值相关性有积极影响；TEST-B拒绝了H02假设，显示IFRS对盈利能力比率（ROE、ROCE、ROA、PM）和杠杆比率有影响，但对效率-流动性比率无影响；逐步回归显示ROCE、ROA和PM比率受IFRS显著正面影响。

Conclusion: IFRS采纳对英国公司的价值相关性有正面影响，显著改善了盈利能力指标（特别是ROCE、ROA和PM），但对效率-流动性指标影响不显著。

Abstract: This paper has two contributions to the International Financial Reporting Stands (IFRS) adoption literature. First is the scrutinizing impact of IFRS adoption on value relevance in the UK with TEST-A analysis under the H01 hypothesis. The second contribution is capturing the impact of IFRS adoption on key financial indicators of firms with the TEST-B analysis that hypothesizes H02.The statistical differences of items of two different reporting standards are examined with non-parametric tests as all input variables failed the Shapiro-Wilk and Lilliefors normality tests in TEST-A. The finding rejects the H01 hypothesis for BvMv, and agrees that IFRS has impact on value relevance. Besides, Ohlson's (1995) model documents that the coefficient of dummy variable (MODE) is positive. Therefore, the analysis concludes that IFRS has positive impact on value relevance. The aftermath of TEST-B rejects the H02 hypothesis for all profitability ratios (ROE, ROCE, ROA, PM) and gearing ratios (GR). It concludes that profitability and gearing ratios are affected by IFRS adoption, whereas efficiency-liquidity ratios are not. Also, in Forward Stepwise regression analysis only ROCE, ROA, and PM ratios show significant results. The analysis documents positive and significant impact of IFRS on these three ratios.

</details>


### [32] [Impact of Brand Dynamics on Insurance Premiums in Turkey](https://arxiv.org/abs/2512.02481)
*Yhlas Sovbetov*

Main category: econ.GN

TL;DR: 品牌信任是土耳其保险保费生产的主要驱动力，品牌价值影响有限，客户忠诚度高且有从众效应


<details>
  <summary>Details</summary>
Motivation: 研究品牌动态（品牌信任和品牌价值）对土耳其保险业保费生产的影响，了解品牌因素在保险市场中的作用

Method: 使用动态GMM面板估计技术，对2005-2015年间31家保险公司进行抽样分析

Result: 品牌信任是保费生产的主要驱动力，每单位增加带来532万土耳其里拉保费增长；品牌价值影响显著但有限（每百万里拉仅带来0.02万里拉增长）；过去保费生产具有强持续性（1:0.85的权衡幅度）

Conclusion: 品牌信任比品牌价值对保费生产更重要，土耳其保险市场存在高客户忠诚度和"从众效应"，品牌管理应优先关注建立客户信任

Abstract: This paper examines influences of brand dynamics on insurance premium productions in Turkey using a dynamic GMM panel estimation technique sampling 31 insurance firms over 2005-2015. The results reveals that brands trust appears as a chief driving force behind premium production where its unit increase augments premium outputs by 5.32 million Turkish Liras (TL). Moreover, the brand value of firms also appears a statistically significant determinant of premium sales, but its size impact remains limited comparing to brand trust, i.e. a million TL increase in brand value generates only 0.02 million TL increase in sales. On the other hand, the study also documents a strong momentum driven from past years premium production with trade-off magnitude of 1 to 0.85. This might imply a higher loyalty-stickiness of customers in Turkey, as well as a self-feeding "bandwagon effect".

</details>


### [33] [Does Firm-Level AI Adoption Improve Early-Warning of Corporate Financial Distress? Evidence from Chinese Non-Financial Firms](https://arxiv.org/abs/2512.02510)
*Frederik Rech,Fanchen Meng,Hussam Musa,Martin Šebeňa,Siele Jean Tuo*

Main category: econ.GN

TL;DR: AI adoption improves corporate financial distress预测，超越传统财务比率，在召回率上提升最大


<details>
  <summary>Details</summary>
Motivation: 研究企业层面AI采用是否能提升财务困境预测模型的样本外预测能力，超越传统财务比率

Method: 使用中国上市公司数据(2008-2023)，采用新颖的修剪训练窗口方法处理稀疏AI数据，测试多种机器学习模型

Result: AI采用持续提升预测准确性，在识别困境企业的召回率上提升最大；树模型和AI密度指标最有效；使用更长历史数据的模型优于仅依赖近期"AI丰富"数据的模型

Conclusion: AI指标可作为稳定、互补的风险指标，与传统会计指标不同，为早期预警信号提供框架，研究结果虽基于中国数据但具有更广泛潜力

Abstract: This study investigates whether firm-level artificial intelligence (AI) adoption improves the out-of-sample prediction of corporate financial distress models beyond traditional financial ratios. Using a sample of Chinese listed firms (2008-2023), we address sparse AI data with a novel pruned training window method, testing multiple machine learning models. We find that AI adoption consistently increases predictive accuracy, with the largest gains in recall rates for identifying distressed firms. Tree-based models and AI density metrics proved most effective. Crucially, models using longer histories outperformed those relying solely on recent "AI-rich" data. The analysis also identifies divergent adoption patterns, with healthy firms exhibiting earlier and higher AI uptake than distressed peers. These findings, while based on Chinese data, provide a framework for early-warning signals and demonstrate the broader potential of AI metrics as a stable, complementary risk indicator distinct from traditional accounting measures.

</details>


### [34] [Retail Price Ripples](https://arxiv.org/abs/2512.02564)
*Xiao Ling,Sourav Ray,Daniel Levy*

Main category: econ.GN

TL;DR: 研究发现零售价格存在"小型不对称定价"现象：小幅涨价次数多于小幅降价，而大幅价格变动则无此不对称性，表明零售商可能利用消费者对小价格变化不敏感的特点来增加利润。


<details>
  <summary>Details</summary>
Motivation: 现有研究对小幅价格变化关注不足，且多为单一零售商、有限产品、短期数据或过时数据（1980-1990年代），其现实相关性存疑。同时，研究者质疑观察到的现象是否由数据聚合导致的测量误差造成。需要基于大规模现代数据验证小幅价格变化的不对称定价现象。

Method: 分析包含近790亿周度价格观测值的大型数据集（2006-2015年），涵盖527种产品、约35,000家门店和161家零售商。采用多种分析方法确保结果对测量误差的稳健性。

Result: 发现稳健的"小型不对称定价"证据：小幅涨价次数显著多于小幅降价次数，而大幅价格变动则无此不对称性。同时也观察到相反现象（小幅降价多于涨价）。结果对多种可能的测量问题均保持稳健。

Conclusion: 不对称定价实践在当前零售环境中的相关性和普遍性比现有文献认识到的更强。零售商可能利用消费者对小价格变化不敏感的特点，通过频繁小幅涨价或混淆大幅涨价来增加利润，这可能增加消费者支出并引发公平性担忧。

Abstract: Much like small ripples in a stream, which get lost in the larger waves, small changes in retail prices often fly under the radar of public perceptions, while large price changes appear as marketing moves associated with demand and competition. Unnoticed, these could increase consumers out of pocket expenses. Indeed, retailers could boost their profits by making numerous small price increases or by obfuscating large price increases with numerous small price decreases, thereby bypassing the consumers full attention and consideration, and triggering consumer fairness concerns. Yet only a handful of papers study small price changes. Extant results are often based on a single retailer, limited products, short time span, and legacy datasets dating back to the 1980s and 1990s, leaving their current practical relevance questionable. Researchers have also questioned whether the reported observations of small price changes are artifacts of measurement errors driven by data aggregation. In a series of analyses of a large dataset containing almost 79 billion weekly price observations from 2006 to 2015, covering 527 products, and about 35,000 stores across 161 retailers, we find robust evidence of asymmetric pricing in the small, where small price increases outnumber small price decreases, but no such asymmetry is present in the large. We also document the reverse phenomenon, where small price decreases outnumber small price increases. Our results are robust to several possible measurement issues. Importantly, our findings indicate a greater current relevance and generalizability of such asymmetric pricing practices than the existing literature recognizes.

</details>


### [35] [Exploring the Impacts of Economic Growth on Ecosystem and Its Subcomponents in Türkiye](https://arxiv.org/abs/2512.02676)
*Emre Akusta*

Main category: econ.GN

TL;DR: 土耳其经济增长对生态系统影响研究：使用1995-2021年数据和ARDL方法，发现经济增长对不同生态系统维度有正负不同影响


<details>
  <summary>Details</summary>
Motivation: 分析经济增长对土耳其生态系统的影响，探讨经济发展与环境保护之间的关系，为制定可持续发展政策提供依据

Method: 使用1995-2021年年度数据，采用ARDL（自回归分布滞后）方法，构建7个模型分析经济增长对生态系统不同维度的影响，使用环境绩效指数的生态系统活力指数作为衡量指标

Result: 经济增长对所有模型都有显著影响，但方向不同：对农业和水资源有正面影响（GDP增长1%使指数增加0.074-0.672%），对生物多样性、栖息地、生态系统服务、渔业、酸雨和总生态系统活力有负面影响（GDP增长1%使指数减少0.101-2.144%）

Conclusion: 经济增长过程需要考虑环境成本，应将环保政策与可持续发展战略结合，以减少经济增长的负面影响

Abstract: This study analyzes the impacts of economic growth on ecosystem in Türkiye. The study uses annual data for the period 1995-2021 and the ARDL method. The study utilizes the Ecosystem Vitality Index, a sub-dimension of the Environmental Performance Index. In addition, seven models were constructed to assess in detail the impact of economic growth on different dimensions of the ecosystem. The results show that economic growth has a significant impact in all models analyzed. However, the direction of this impact differs across ecosystem components. Economic growth is found to have a positive impact on agriculture and water resources. In these models, a 1% increase in GDP increases the agriculture and water resources indices by 0.074-0.672%. In contrast, economic growth has a negative impact on biodiversity and habitat, ecosystem services, fisheries, acid rain and total ecosystem vitality. In these models, a 1% increase in GDP reduces the indices of biodiversity and habitat, ecosystem services, fisheries, acid rain and total ecosystem vitality by 0.101-2.144%. The results suggest that the environmental costs of economic growth processes need to be considered. Environmentally friendly policies should be combined with sustainable development strategies to reduce the negative impacts of economic growth.

</details>


### [36] [Measuring and Rating Socioeconomic Disparities among Provinces: A Case of Turkiye](https://arxiv.org/abs/2512.02687)
*Emre Akusta*

Main category: econ.GN

TL;DR: 该研究构建了土耳其81个省份的社会经济发展指数，使用16个经济和社会指标，通过主成分分析和K-Means聚类将省份分为4个等级，结果显示东西部存在显著发展差距。


<details>
  <summary>Details</summary>
Motivation: 土耳其作为地理、文化和经济多元化的国家，各省份之间的社会经济差异对国家发展有重要影响。确定各省份的社会经济状况和区域差异是制定和实施有效政策的重要步骤。

Method: 研究构建了涵盖经济和社会维度的社会经济发展指数，使用16个指标，通过Min-Max归一化方法和主成分分析将指标转换为指数，然后使用K-Means聚类算法和Elbow方法将省份分组。

Result: 土耳其81个省份中：2个省份（伊斯坦布尔和安卡拉）具有非常高的社会经济指数，30个省份为高指数，25个中等，24个低指数。总体上，土耳其西部省份社会经济指数较高，而东部和东南部安纳托利亚地区面临严重挑战。

Conclusion: 研究揭示了土耳其各省份之间的显著社会经济差异，特别是东西部发展不平衡。这些发现为政策制定者提供了重要依据，有助于针对不同发展水平的地区制定差异化政策。

Abstract: Regional disparities in the economic and social structures of countries have a great impact on their development levels. In geographically, culturally and economically diverse countries like Turkiye, determining the socioeconomic status of the provinces and regional differences is an important step for planning and implementing effective policies. Therefore, this study aims to determine the socioeconomic disparities of the provinces in Turkiye. For this purpose, a socioeconomic development index covering the economic and social dimensions of 81 provinces was constructed. For the index, 16 different indicators representing economic and social factors were used. These indicators were converted into indices using the Min-Max normalization method and Principal Component Analysis. Afterwards, using these indices, the provinces were divided into groups using the K-Means clustering algorithm and the Elbow method. In the last part of the study, the results are presented in a visual format using Scatter Plots, clustering maps and QGIS mapping tools. The results of the study show that 2 of the 81 provinces in Turkiye have very high, 30 high, 25 medium and 24 low socioeconomic indices. Istanbul and Ankara have very high socioeconomic status. In general, the provinces in western Turkiye have a high socioeconomic index, while the provinces in eastern and southeastern Anatolia face serious challenges in terms of socioeconomic indicators.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [37] [Reinforcement Learning for Robotic Safe Control with Force Sensing](https://arxiv.org/abs/2512.02022)
*Nan Lin,Linrui Zhang,Yuxuan Chen,Zhenrui Chen,Yujun Zhu,Ruoxi Chen,Peichen Wu,Xiaoping Chen*

Main category: cs.RO

TL;DR: 论文提出将力与触觉感知融入强化学习，以提升机器人在复杂操作任务中的安全性和可靠性，特别是在仿真到现实的迁移中。


<details>
  <summary>Details</summary>
Motivation: 传统手工编码方法在非结构化环境的复杂操作任务中效果有限，而强化学习虽然能提供更通用的策略，但其稳定性和可靠性难以保证，存在安全隐患。此外，从仿真到现实的迁移也会带来不可预测的情况。

Method: 将力和触觉感知引入强化学习框架。力与触觉感知在机器人动态控制和人机交互中起关键作用，作者提出基于力的强化学习方法。

Result: 实验结果表明，在物体推动任务中，该方法在仿真和现实世界中都更安全、更高效。基于力的强化学习方法对环境更具适应性，特别是在仿真到现实的迁移中表现更好。

Conclusion: 引入力与触觉感知的强化学习方法能显著提升机器人的安全性和可靠性，在仿真到现实迁移中表现优异，具有广泛的机器人应用前景。

Abstract: For the task with complicated manipulation in unstructured environments, traditional hand-coded methods are ineffective, while reinforcement learning can provide more general and useful policy. Although the reinforcement learning is able to obtain impressive results, its stability and reliability is hard to guarantee, which would cause the potential safety threats. Besides, the transfer from simulation to real world also will lead in unpredictable situations. To enhance the safety and reliability of robots, we introduce the force and haptic perception into reinforcement learning. Force and tactual sensation play key roles in robotic dynamic control and human-robot interaction. We demonstrate that the force-based reinforcement learning method can be more adaptive to environment, especially in sim-to-real transfer. Experimental results show in object pushing task, our strategy is safer and more efficient in both simulation and real world, thus it holds prospects for a wide variety of robotic applications.

</details>


### [38] [Robust Geospatial Coordination of Multi-Agent Communications Networks Under Attrition](https://arxiv.org/abs/2512.02079)
*Jonathan S. Kent,Eliana Stefani,Brian K. Plancher*

Main category: cs.RO

TL;DR: 该论文提出了一种用于极端环境下多无人机网络鲁棒性维护的物理启发拓扑算法ΦIREMAN，解决了在无人机损耗情况下的任务网络鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 在野火等紧急响应中，需要快速高效的通信网络。使用自主无人机群形成临时网络连接应急人员，但在极端环境中无人机可能受损导致网络中断，因此需要解决网络鲁棒性问题。

Method: 提出了RTNUA问题（鲁棒任务网络在损耗下的维护），并开发了ΦIREMAN算法——一种基于物理启发势场的拓扑算法，通过主动冗余和损耗恢复来维护网络连接。

Result: 在25种问题配置的仿真中，ΦIREMAN始终优于DCCRS基线算法。在包含100个任务和500架无人机的大规模问题上，尽管存在显著损耗，仍能保持>99.9%的任务正常运行时间。

Conclusion: ΦIREMAN算法能够有效解决极端环境下多无人机网络的鲁棒性问题，具有高可扩展性，为应急响应通信提供了可靠的解决方案。

Abstract: Fast, efficient, robust communication during wildfire and other emergency responses is critical. One way to achieve this is by coordinating swarms of autonomous aerial vehicles carrying communications equipment to form an ad-hoc network connecting emergency response personnel to both each other and central command. However, operating in such extreme environments may lead to individual networking agents being damaged or rendered inoperable, which could bring down the network and interrupt communications.
  To overcome this challenge and enable multi-agent UAV networking in difficult environments, this paper introduces and formalizes the problem of Robust Task Networking Under Attrition (RTNUA), which extends connectivity maintenance in multi-robot systems to explicitly address proactive redundancy and attrition recovery. We introduce Physics-Informed Robust Employment of Multi-Agent Networks ($Φ$IREMAN), a topological algorithm leveraging physics-inspired potential fields to solve this problem. Through simulation across 25 problem configurations, $Φ$IREMAN consistently outperforms the DCCRS baseline, and on large-scale problems with up to 100 tasks and 500 drones, maintains $>99.9\%$ task uptime despite substantial attrition, demonstrating both effectiveness and scalability.

</details>


### [39] [VIGS-SLAM: Visual Inertial Gaussian Splatting SLAM](https://arxiv.org/abs/2512.02293)
*Zihan Zhu,Wei Zhang,Norbert Haala,Marc Pollefeys,Daniel Barath*

Main category: cs.RO

TL;DR: VIGS-SLAM是一个视觉-惯性3D高斯泼溅SLAM系统，实现实时鲁棒跟踪和高保真重建，通过紧密耦合视觉和惯性信息解决运动模糊、低纹理等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基于3DGS的SLAM方法虽然能实现密集和照片级真实感建图，但纯视觉设计在运动模糊、低纹理和曝光变化下性能下降。需要结合惯性测量单元(IMU)来提高鲁棒性。

Method: 提出视觉-惯性3D高斯泼溅SLAM系统，在统一优化框架中紧密耦合视觉和惯性线索，联合优化相机位姿、深度和IMU状态。包含鲁棒的IMU初始化、时变偏差建模和带一致高斯更新的闭环检测。

Result: 在四个具有挑战性的数据集上实验证明，VIGS-SLAM优于现有最先进方法，实现了鲁棒的实时跟踪和高保真重建。

Conclusion: VIGS-SLAM通过视觉-惯性紧密耦合成功解决了纯视觉SLAM在挑战性场景下的局限性，为实时高保真SLAM提供了有效解决方案。

Abstract: We present VIGS-SLAM, a visual-inertial 3D Gaussian Splatting SLAM system that achieves robust real-time tracking and high-fidelity reconstruction. Although recent 3DGS-based SLAM methods achieve dense and photorealistic mapping, their purely visual design degrades under motion blur, low texture, and exposure variations. Our method tightly couples visual and inertial cues within a unified optimization framework, jointly refining camera poses, depths, and IMU states. It features robust IMU initialization, time-varying bias modeling, and loop closure with consistent Gaussian updates. Experiments on four challenging datasets demonstrate our superiority over state-of-the-art methods. Project page: https://vigs-slam.github.io

</details>


### [40] [Vehicle Dynamics Embedded World Models for Autonomous Driving](https://arxiv.org/abs/2512.02417)
*Huiqian Li,Wei Pan,Haodong Zhang,Jin Huang,Zhihua Zhong*

Main category: cs.RO

TL;DR: VDD方法通过解耦自车动力学与环境动态建模，提升自动驾驶世界模型的泛化能力和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶世界模型通常将自车动力学与环境动态联合学习，导致效率低下且对车辆参数变化缺乏鲁棒性

Method: 提出VDD方法，分离自车动力学与环境动态建模；引入PAD（部署时策略调整）和PAT（训练时策略增强）两种策略增强鲁棒性

Result: 在仿真环境中显著提升驾驶性能和车辆动力学变化的鲁棒性，优于现有方法

Conclusion: 解耦建模方法能有效提升自动驾驶世界模型的泛化能力和鲁棒性，为不同车辆参数提供更好的适应性

Abstract: World models have gained significant attention as a promising approach for autonomous driving. By emulating human-like perception and decision-making processes, these models can predict and adapt to dynamic environments. Existing methods typically map high-dimensional observations into compact latent spaces and learn optimal policies within these latent representations. However, prior work usually jointly learns ego-vehicle dynamics and environmental transition dynamics from the image input, leading to inefficiencies and a lack of robustness to variations in vehicle dynamics. To address these issues, we propose the Vehicle Dynamics embedded Dreamer (VDD) method, which decouples the modeling of ego-vehicle dynamics from environmental transition dynamics. This separation allows the world model to generalize effectively across vehicles with diverse parameters. Additionally, we introduce two strategies to further enhance the robustness of the learned policy: Policy Adjustment during Deployment (PAD) and Policy Augmentation during Training (PAT). Comprehensive experiments in simulated environments demonstrate that the proposed model significantly improves both driving performance and robustness to variations in vehicle dynamics, outperforming existing approaches.

</details>


### [41] [AID: Agent Intent from Diffusion for Multi-Agent Informative Path Planning](https://arxiv.org/abs/2512.02535)
*Jeric Lew,Yuhong Cao,Derek Ming Siang Tan,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: AID是一个基于扩散模型的全去中心化多智能体信息路径规划框架，通过非自回归方式生成长时轨迹，相比现有方法实现4倍加速和17%信息增益提升


<details>
  <summary>Details</summary>
Motivation: 大规模或时间敏感场景（如环境监测、搜救）需要多智能体系统在有限时间内实现广泛覆盖。现有基于学习的方法使用自回归意图预测器，但计算成本高且容易产生累积误差

Method: 提出AID框架：1）在现有MAIPP规划器生成的轨迹上进行行为克隆；2）通过扩散策略策略优化（DPPO）使用强化学习微调策略。利用扩散模型以非自回归方式生成长时轨迹

Result: AID相比训练所用的MAIPP规划器持续改进，实现高达4倍执行加速和17%信息增益提升，并能有效扩展到更多智能体

Conclusion: 扩散模型作为表达性强的长时程策略，能够有效解决多智能体信息路径规划中的协调问题，AID框架展示了在保持去中心化架构的同时实现高效协调的潜力

Abstract: Information gathering in large-scale or time-critical scenarios (e.g., environmental monitoring, search and rescue) requires broad coverage within limited time budgets, motivating the use of multi-agent systems. These scenarios are commonly formulated as multi-agent informative path planning (MAIPP), where multiple agents must coordinate to maximize information gain while operating under budget constraints. A central challenge in MAIPP is ensuring effective coordination while the belief over the environment evolves with incoming measurements. Recent learning-based approaches address this by using distributions over future positions as "intent" to support coordination. However, these autoregressive intent predictors are computationally expensive and prone to compounding errors. Inspired by the effectiveness of diffusion models as expressive, long-horizon policies, we propose AID, a fully decentralized MAIPP framework that leverages diffusion models to generate long-term trajectories in a non-autoregressive manner. AID first performs behavior cloning on trajectories produced by existing MAIPP planners and then fine-tunes the policy using reinforcement learning via Diffusion Policy Policy Optimization (DPPO). This two-stage pipeline enables the policy to inherit expert behavior while learning improved coordination through online reward feedback. Experiments demonstrate that AID consistently improves upon the MAIPP planners it is trained from, achieving up to 4x faster execution and 17% increased information gain, while scaling effectively to larger numbers of agents. Our implementation is publicly available at https://github.com/marmotlab/AID.

</details>


### [42] [Robotic capabilities framework: A boundary object and intermediate-level knowledge artifact for co-designing robotic processes](https://arxiv.org/abs/2512.02549)
*Alessandro Ianniello,Dave Murray-Rust,Sara Muscolo,Olger Siebinga,Nicky Mol,Denis Zatyagov,Eva Verhoef,Deborah Forster,David Abbink*

Main category: cs.RO

TL;DR: 提出了一个机器人能力框架，作为跨学科协作的词汇表，帮助设计人类与机器人协作的未来工作方式，关注任务分配而非机器人内部技术细节。


<details>
  <summary>Details</summary>
Motivation: 当前机器人协作设计通常采用单学科方法，忽视了跨学科知识和实际工作者的经验知识，需要一种能够促进跨学科协作的工具来更有效地整合机器人系统到工作场所。

Method: 开发了机器人能力框架作为中间层知识工具，通过反思和迭代过程构建，并在两个场景中应用：1) 让机器人专家用该词汇描述现有商业机器人；2) 与从事机器人相关项目的学生进行设计活动。

Result: 该框架作为边界对象，成功连接了技术领域和经验领域，能够引导设计者、赋能工作者，促进更公正和协作的未来工作方式。

Conclusion: 机器人能力框架是一个有效的跨学科协作工具，通过关注高级能力而非技术细节，支持讨论任务分配，有助于塑造更合理的人类-机器人协作工作未来。

Abstract: As robots become more adaptable, responsive, and capable of interacting with humans, the design of effective human-robot collaboration becomes critical. Yet, this design process is typically led by monodisciplinary approaches, often overlooking interdisciplinary knowledge and the experiential knowledge of workers who will ultimately share tasks with these systems. To address this gap, we introduce the robotic capabilities framework, a vocabulary that enables transdisciplinary collaborations to meaningfully shape the future of work when robotic systems are integrated into the workplace. Rather than focusing on the internal workings of robots, the framework centers discussion on high-level capabilities, supporting dialogue around which elements of a task should remain human-led and which can be delegated to robots. We developed the framework through reflexive and iterative processes, and applied it in two distinct settings: by engaging roboticists in describing existing commercial robots using its vocabulary, and through a design activity with students working on robotics-related projects. The framework emerges as an intermediate-level knowledge artifact and a boundary object that bridges technical and experiential domains, guiding designers, empowering workers, and contributing to more just and collaborative futures of work.

</details>


### [43] [SAM2Grasp: Resolve Multi-modal Grasping via Prompt-conditioned Temporal Action Prediction](https://arxiv.org/abs/2512.02609)
*Shengkai Wu,Jinrong Yang,Wenqiu Luo,Linfeng Gao,Chaohui Shang,Meiyu Zhi,Mingshan Sun,Fangping Yang,Liangliang Ren,Yong Zhao*

Main category: cs.RO

TL;DR: SAM2Grasp通过将多模态抓取任务重构为单模态、提示条件预测问题，利用SAM2的视觉时序跟踪能力解决多目标场景中的冲突训练信号问题。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在多目标抓取任务中存在多模态问题：当场景包含多个有效目标时，对不同物体的抓取演示会产生冲突的训练信号，导致标准模仿学习策略平均这些不同动作而产生无效动作。

Method: 提出SAM2Grasp框架，利用冻结的SAM2模型提取视觉时序特征，引入轻量级可训练动作头与原生分割头并行工作。通过初始提示（如边界框）指定要抓取的具体对象，SAM2的时序跟踪能力自动维持目标跟踪，动作头预测唯一的抓取轨迹。

Result: 在杂乱多目标抓取任务中实现了最先进的性能，有效消除了视觉运动策略中的歧义。

Conclusion: 通过将多模态抓取任务重构为提示条件的单模态预测问题，结合SAM2的时序跟踪能力，成功解决了模仿学习中的多模态冲突问题，实现了精确的多目标抓取。

Abstract: Imitation learning for robotic grasping is often plagued by the multimodal problem: when a scene contains multiple valid targets, demonstrations of grasping different objects create conflicting training signals. Standard imitation learning policies fail by averaging these distinct actions into a single, invalid action. In this paper, we introduce SAM2Grasp, a novel framework that resolves this issue by reformulating the task as a uni-modal, prompt-conditioned prediction problem. Our method leverages the frozen SAM2 model to use its powerful visual temporal tracking capability and introduces a lightweight, trainable action head that operates in parallel with its native segmentation head. This design allows for training only the small action head on pre-computed temporal-visual features from SAM2. During inference, an initial prompt, such as a bounding box provided by an upstream object detection model, designates the specific object to be grasped. This prompt conditions the action head to predict a unique, unambiguous grasp trajectory for that object alone. In all subsequent video frames, SAM2's built-in temporal tracking capability automatically maintains stable tracking of the selected object, enabling our model to continuously predict the grasp trajectory from the video stream without further external guidance. This temporal-prompted approach effectively eliminates ambiguity from the visuomotor policy. We demonstrate through extensive experiments that SAM2Grasp achieves state-of-the-art performance in cluttered, multi-object grasping tasks.

</details>


### [44] [RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning](https://arxiv.org/abs/2512.02729)
*Yuhong Zhang,Zihan Gao,Shengpeng Li,Ling-Hao Chen,Kaisheng Liu,Runqing Cheng,Xiao Lin,Junjia Liu,Zhuoheng Li,Jingyi Feng,Ziyan He,Jintian Lin,Zheyan Huang,Zhifang Liu,Haoqian Wang*

Main category: cs.RO

TL;DR: Robowheel：从人类手-物交互视频生成跨形态机器人学习监督的数据引擎，通过重建、物理优化和重定向创建可执行动作，支持多种机器人形态。


<details>
  <summary>Details</summary>
Motivation: 解决机器人学习中监督数据获取困难的问题，利用丰富的人类手-物交互视频作为廉价、可扩展的监督来源，替代传统遥操作方式。

Method: 1) 从单目RGB(D)视频进行高精度手-物交互重建；2) 通过强化学习优化器在接触和穿透约束下细化相对姿态；3) 将重建轨迹重定向到不同机器人形态；4) 使用Isaac Sim进行仿真增强和数据增强。

Result: 生成的轨迹与遥操作数据质量相当，能持续提升机器人学习性能。首次定量证明手-物交互模态可作为有效的机器人学习监督。构建了大规模多模态数据集。

Conclusion: Robowheel提供了一种轻量级、通用的跨形态运动表示方法，仅需单目相机即可提取可重定向的运动监督，为机器人学习开辟了新的数据获取途径。

Abstract: We introduce Robowheel, a data engine that converts human hand object interaction (HOI) videos into training-ready supervision for cross morphology robotic learning. From monocular RGB or RGB-D inputs, we perform high precision HOI reconstruction and enforce physical plausibility via a reinforcement learning (RL) optimizer that refines hand object relative poses under contact and penetration constraints. The reconstructed, contact rich trajectories are then retargeted to cross-embodiments, robot arms with simple end effectors, dexterous hands, and humanoids, yielding executable actions and rollouts. To scale coverage, we build a simulation-augmented framework on Isaac Sim with diverse domain randomization (embodiments, trajectories, object retrieval, background textures, hand motion mirroring), which enriches the distributions of trajectories and observations while preserving spatial relationships and physical plausibility. The entire data pipeline forms an end to end pipeline from video,reconstruction,retargeting,augmentation data acquisition. We validate the data on mainstream vision language action (VLA) and imitation learning architectures, demonstrating that trajectories produced by our pipeline are as stable as those from teleoperation and yield comparable continual performance gains. To our knowledge, this provides the first quantitative evidence that HOI modalities can serve as effective supervision for robotic learning. Compared with teleoperation, Robowheel is lightweight, a single monocular RGB(D) camera is sufficient to extract a universal, embodiment agnostic motion representation that could be flexibly retargeted across embodiments. We further assemble a large scale multimodal dataset combining multi-camera captures, monocular videos, and public HOI corpora for training and evaluating embodied models.

</details>


### [45] [CogDrive: Cognition-Driven Multimodal Prediction-Planning Fusion for Safe Autonomy](https://arxiv.org/abs/2512.02777)
*Heye Huang,Yibin Yang,Mingfeng Fan,Haoran Wang,Xiaocong Zhao,Jianqiang Wang*

Main category: cs.RO

TL;DR: CogDrive提出了一种认知驱动的多模态预测与规划框架，通过显式模态推理与安全感知轨迹优化，解决自动驾驶在混合交通中的安全挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法难以捕捉罕见但安全关键的行为，而基于规则的系统在复杂交互中缺乏适应性。自动驾驶在混合交通中需要统一理解多模态交互和在不确定性下的动态规划。

Method: 采用认知驱动的多模态预测与规划框架：预测模块基于拓扑运动语义和最近邻关系编码构建交互模式的认知表示，使用可微分模态损失和多模态高斯解码；规划模块引入应急响应概念，优化安全稳定轨迹，包含短期一致分支和长期分支。

Result: 在Argoverse2和INTERACTION数据集上，CogDrive在轨迹精度和漏检率方面表现优异；闭环仿真验证了在汇入和交叉口场景中的自适应行为。

Conclusion: 通过结合认知多模态预测与安全导向规划，CogDrive为复杂交通中的安全自动驾驶提供了一个可解释且可靠的范式。

Abstract: Safe autonomous driving in mixed traffic requires a unified understanding of multimodal interactions and dynamic planning under uncertainty. Existing learning based approaches struggle to capture rare but safety critical behaviors, while rule based systems often lack adaptability in complex interactions. To address these limitations, CogDrive introduces a cognition driven multimodal prediction and planning framework that integrates explicit modal reasoning with safety aware trajectory optimization. The prediction module adopts cognitive representations of interaction modes based on topological motion semantics and nearest neighbor relational encoding. With a differentiable modal loss and multimodal Gaussian decoding, CogDrive learns sparse and unbalanced interaction behaviors and improves long horizon trajectory prediction. The planning module incorporates an emergency response concept and optimizes safety stabilized trajectories, where short term consistent branches ensure safety during replanning cycles and long term branches support smooth and collision free motion under low probability switching modes. Experiments on Argoverse2 and INTERACTION datasets show that CogDrive achieves strong performance in trajectory accuracy and miss rate, while closed loop simulations confirm adaptive behavior in merge and intersection scenarios. By combining cognitive multimodal prediction with safety oriented planning, CogDrive offers an interpretable and reliable paradigm for safe autonomy in complex traffic.

</details>


### [46] [Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols](https://arxiv.org/abs/2512.02787)
*Xianchao Zeng,Xinyu Zhou,Youcheng Li,Jiayou Shi,Tianle Li,Liangming Chen,Lei Ren,Yong-Lu Li*

Main category: cs.RO

TL;DR: ViFailback是一个用于机器人操作失败诊断和纠正的框架，包含大规模真实世界数据集、评估基准和8B参数VLM模型，能提供文本和视觉纠正指导。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在失败诊断和学习方面有限，且现有失败数据集大多在仿真中程序化生成，难以泛化到真实世界。

Method: 提出ViFailback框架，使用显式视觉符号提高标注效率；发布包含58,126个VQA对和5,202个真实世界操作轨迹的数据集；建立包含11个细粒度VQA任务的评估基准；构建ViFailback-8B VLM模型。

Result: ViFailback-8B在评估基准上取得显著性能提升，能生成视觉符号用于纠正指导；与VLA模型集成后，在真实世界机器人实验中成功帮助模型从失败中恢复。

Conclusion: ViFailback框架有效解决了机器人操作失败诊断和纠正的问题，通过真实世界数据集、评估基准和专用VLM模型，提升了VLA模型从失败中学习和恢复的能力。

Abstract: Vision-Language-Action (VLA) models have recently achieved remarkable progress in robotic manipulation, yet they remain limited in failure diagnosis and learning from failures. Additionally, existing failure datasets are mostly generated programmatically in simulation, which limits their generalization to the real world. In light of these, we introduce ViFailback, a framework designed to diagnose robotic manipulation failures and provide both textual and visual correction guidance. Our framework utilizes explicit visual symbols to enhance annotation efficiency. We further release the ViFailback dataset, a large-scale collection of 58,126 Visual Question Answering (VQA) pairs along with their corresponding 5,202 real-world manipulation trajectories. Based on the dataset, we establish ViFailback-Bench, a benchmark of 11 fine-grained VQA tasks designed to assess the failure diagnosis and correction abilities of Vision-Language Models (VLMs), featuring ViFailback-Bench Lite for closed-ended and ViFailback-Bench Hard for open-ended evaluation. To demonstrate the effectiveness of our framework, we built the ViFailback-8B VLM, which not only achieves significant overall performance improvement on ViFailback-Bench but also generates visual symbols for corrective action guidance. Finally, by integrating ViFailback-8B with a VLA model, we conduct real-world robotic experiments demonstrating its ability to assist the VLA model in recovering from failures. Project Website: https://x1nyuzhou.github.io/vifailback.github.io/

</details>


### [47] [Phase-Adaptive LLM Framework with Multi-Stage Validation for Construction Robot Task Allocation: A Systematic Benchmark Against Traditional Optimization Algorithms](https://arxiv.org/abs/2512.02810)
*Shyam prasad reddy Kaitha,Hongrui Yu*

Main category: cs.RO

TL;DR: 本文提出LTAA框架，首次系统比较LLM与传统方法在建筑机器人任务分配中的表现，通过动态提示等技术显著降低计算成本，在特定场景下优于传统优化算法。


<details>
  <summary>Details</summary>
Motivation: 传统建筑自动化中的多机器人任务分配主要依赖动态规划和强化学习等优化方法，而最近的LLM方法虽然显示出潜力，但缺乏严格的验证和与传统算法的基准比较。

Method: 提出LangGraph-based Task Allocation Agent (LTAA)框架，集成阶段自适应分配策略、多阶段验证与分层重试机制、动态提示技术，并结合自然语言推理与结构化验证机制。

Result: LTAA显著降低计算成本：token使用减少94.6%，分配时间减少86%。在Heavy Excels场景下，任务完成率达到77%，优于所有传统方法（动态规划、Q-learning、DQN），且具有更好的工作负载平衡。

Conclusion: LLM基于推理结合结构化验证的方法能够匹配传统优化算法，同时提供可解释性、适应性和无需重新训练即可更新任务逻辑等额外优势，为建筑机器人任务分配提供了新方向。

Abstract: Multi-robot task allocation in construction automation has traditionally relied on optimization methods such as Dynamic Programming and Reinforcement Learning. This research introduces the LangGraph-based Task Allocation Agent (LTAA), an LLM-driven framework that integrates phase-adaptive allocation strategies, multi-stage validation with hierarchical retries, and dynamic prompting for efficient robot coordination. Although recent LLM approaches show potential for construction robotics, they largely lack rigorous validation and benchmarking against established algorithms. This paper presents the first systematic comparison of LLM-based task allocation with traditional methods in construction scenarios.The study validates LLM feasibility through SMART-LLM replication and addresses implementation challenges using a Self-Corrective Agent Architecture. LTAA leverages natural-language reasoning combined with structured validation mechanisms, achieving major computational gains reducing token usage by 94.6% and allocation time by 86% through dynamic prompting. The framework adjusts its strategy across phases: emphasizing execution feasibility early and workload balance in later allocations.The authors evaluate LTAA against Dynamic Programming, Q-learning, and Deep Q-Network (DQN) baselines using construction operations from the TEACh human-robot collaboration dataset. In the Heavy Excels setting, where robots have strong task specializations, LTAA achieves 77% task completion with superior workload balance, outperforming all traditional methods. These findings show that LLM-based reasoning with structured validation can match established optimization algorithms while offering additional advantages such as interpretability, adaptability, and the ability to update task logic without retraining.

</details>


### [48] [Steering Vision-Language-Action Models as Anti-Exploration: A Test-Time Scaling Approach](https://arxiv.org/abs/2512.02834)
*Siyuan Yang,Yang Zhang,Haoran He,Ling Pan,Xiu Li,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: 提出TACO框架，通过测试时缩放和伪计数估计器解决VLA模型微调后的推理不稳定性问题，防止分布偏移同时保持泛化能力。


<details>
  <summary>Details</summary>
Motivation: VLA模型在预训练阶段整合了多种数据模式，而微调数据集通常包含运动学上不理想或次优的演示数据，存在与下游任务成功模式无关的冗余动作模式，导致推理时的不稳定性。

Method: 提出TACO测试时缩放框架，使用轻量级伪计数估计器作为动作块的高保真验证器，在推理时从所有采样的动作块中选择具有最大伪计数的动作执行。

Result: 在四个仿真基准（RoboTwin2.0、Robotwin、LIBERO、SimplerEnv）和双臂平台上进行广泛实验，证明该方法显著提高了下游任务适应中的推理稳定性和成功率。

Conclusion: TACO框架有效解决了VLA模型微调后的推理不稳定性问题，通过防止分布偏移同时保持模型的泛化能力，且无需梯度更新，计算效率高。

Abstract: Vision-Language-Action (VLA) models, trained via flow-matching or diffusion objectives, excel at learning complex behaviors from large-scale, multi-modal datasets (e.g., human teleoperation, scripted policies). However, since VLAs incorporate diverse data modes in the pre-training stage, and the finetuning dataset often contains demonstration data collected in a kinematically suboptimal or undesirable way, it exists redundant action modes that are irrelevant to the success action modes of the downstream task. Specifically, we observe a critical inference-time fragility among various sampled noises after supervised finetuning of pre-trained VLAs. In this paper, we attribute this instability to the distribution shift between the VLA policy and the policy induced by stable success modes of the downstream task dataset. Thus, we propose \textbf{TACO}, a test-time-scaling (TTS) framework that applies a lightweight pseudo-count estimator as a high-fidelity verifier of action chunks. The VLA models integrated with TACO can execute the actions with maximum pseudo-count from all sampled action chunks, thereby preventing distribution shifts while preserving the generalization ability of VLAs since the constraint is applied only during inference. Our method resembles the classical anti-exploration principle in offline reinforcement learning (RL), and being gradient-free, it incurs significant computational benefits compared to RL update, especially for flow or diffusion-based VLAs which are difficult to perform RL update due to denoising process. Extensive experiments across four simulation benchmarks (RoboTwin2.0, Robotwin, LIBERO, SimplerEnv) and a dual-arm platform demonstrate that our method significantly improves the inference stability and success rates in downstream-task adaptations.

</details>


### [49] [VLM as Strategist: Adaptive Generation of Safety-critical Testing Scenarios via Guided Diffusion](https://arxiv.org/abs/2512.02844)
*Xinzheng Wu,Junyi Chen,Naiting Zhong,Yong Shen*

Main category: cs.RO

TL;DR: 提出一个结合视觉语言模型和自适应引导扩散模型的安全关键测试场景生成框架，用于高效生成真实、多样且交互性强的自动驾驶测试场景。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统的安全部署需要全面测试，但现实世界中能有效暴露系统漏洞的安全关键场景极其稀少。现有场景生成方法难以高效构建同时保证保真度、关键性和交互性的长尾场景，尤其缺乏对被测车辆的实时动态响应能力。

Method: 提出三层分层架构：战略层使用VLM确定场景生成目标，战术层制定引导函数，操作层执行引导扩散。首先建立学习真实驾驶场景数据分布的基础扩散模型，然后设计自适应引导扩散方法实现闭环仿真中对背景车辆的实时精确控制，最后整合VLM通过深度场景理解和风险推理自主生成场景目标和引导函数。

Result: 实验结果表明，该方法能高效生成真实、多样且高度交互的安全关键测试场景。案例研究验证了方法的适应性和VLM指导的生成性能。

Conclusion: 提出的框架成功解决了现有场景生成方法在保真度、关键性、交互性和实时响应方面的挑战，为自动驾驶系统测试提供了有效的安全关键场景生成解决方案。

Abstract: The safe deployment of autonomous driving systems (ADSs) relies on comprehensive testing and evaluation. However, safety-critical scenarios that can effectively expose system vulnerabilities are extremely sparse in the real world. Existing scenario generation methods face challenges in efficiently constructing long-tail scenarios that ensure fidelity, criticality, and interactivity, while particularly lacking real-time dynamic response capabilities to the vehicle under test (VUT). To address these challenges, this paper proposes a safety-critical testing scenario generation framework that integrates the high-level semantic understanding capabilities of Vision Language Models (VLMs) with the fine-grained generation capabilities of adaptive guided diffusion models. The framework establishes a three-layer hierarchical architecture comprising a strategic layer for VLM-directed scenario generation objective determination, a tactical layer for guidance function formulation, and an operational layer for guided diffusion execution. We first establish a high-quality fundamental diffusion model that learns the data distribution of real driving scenarios. Next, we design an adaptive guided diffusion method that enables real-time, precise control of background vehicles (BVs) in closed-loop simulation. The VLM is then incorporated to autonomously generate scenario generation objectives and guidance functions through deep scenario understanding and risk reasoning, ultimately guiding the diffusion model to achieve VLM-directed scenario generation. Experimental results demonstrate that the proposed method can efficiently generate realistic, diverse, and highly interactive safety-critical testing scenarios. Furthermore, case studies validate the adaptability and VLM-directed generation performance of the proposed method.

</details>


### [50] [SwarmDiffusion: End-To-End Traversability-Guided Diffusion for Embodiment-Agnostic Navigation of Heterogeneous Robots](https://arxiv.org/abs/2512.02851)
*Iana Zhura,Sausar Karaf,Faryal Batool,Nipun Dhananjaya Weerakkodi Mudalige,Valerii Serpiva,Ali Alridha Abdulkarim,Aleksey Fedoseev,Didar Seyidov,Amjad Hajira,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: SwarmDiffusion：一个轻量级端到端扩散模型，从单张RGB图像联合预测可通行性和生成可行轨迹，无需提示工程或外部规划器，实现跨平台迁移。


<details>
  <summary>Details</summary>
Motivation: 现有基于VLM的可通行性估计方法依赖手工提示，跨平台泛化能力差，且只输出可通行性地图，需要外部规划器生成轨迹，速度慢。

Method: 提出无规划器的轨迹构建流程：随机航点采样、贝塞尔平滑和正则化（连通性、安全性、方向性、路径细度）。使用扩散模型联合预测可通行性和轨迹，并基于紧凑的机器人状态进行条件扩散。

Result: 在室内环境和两种机器人平台（四足和空中）上实现80-100%导航成功率，0.09秒推理时间。仅需500个额外视觉样本即可适应新机器人，在仿真和真实环境中可靠泛化。

Conclusion: SwarmDiffusion提供了一种可扩展、无需提示的统一可通行性推理和轨迹生成方法，能够学习稳定的运动先验而无需演示，实现跨平台物理一致性。

Abstract: Visual traversability estimation is critical for autonomous navigation, but existing VLM-based methods rely on hand-crafted prompts, generalize poorly across embodiments, and output only traversability maps, leaving trajectory generation to slow external planners. We propose SwarmDiffusion, a lightweight end-to-end diffusion model that jointly predicts traversability and generates a feasible trajectory from a single RGB image. To remove the need for annotated or planner-produced paths, we introduce a planner-free trajectory construction pipeline based on randomized waypoint sampling, Bezier smoothing, and regularization enforcing connectivity, safety, directionality, and path thinness. This enables learning stable motion priors without demonstrations. SwarmDiffusion leverages VLM-derived supervision without prompt engineering and conditions the diffusion process on a compact embodiment state, producing physically consistent, traversable paths that transfer across different robot platforms. Across indoor environments and two embodiments (quadruped and aerial), the method achieves 80-100\% navigation success and 0.09 s inference, and adapts to a new robot using only-500 additional visual samples. It generalizes reliably to unseen environments in simulation and real-world trials, offering a scalable, prompt-free approach to unified traversability reasoning and trajectory generation.

</details>


### [51] [VLA Models Are More Generalizable Than You Think: Revisiting Physical and Spatial Modeling](https://arxiv.org/abs/2512.02902)
*Weiqi Li,Quande Zhang,Ruifeng Zhai,Liang Lin,Guangrun Wang*

Main category: cs.RO

TL;DR: VLA模型在分布内表现良好但面对新视角和视觉扰动时性能急剧下降，研究发现主要问题是空间建模而非物理建模的对齐问题，提出一次性适应框架通过轻量级可学习更新重新校准视觉表示。


<details>
  <summary>Details</summary>
Motivation: VLA模型在分布内任务上表现优异，但在面对新的相机视角和视觉扰动时性能急剧下降，这种脆弱性限制了其在实际应用中的鲁棒性和泛化能力。

Method: 提出一次性适应框架，通过轻量级可学习更新重新校准视觉表示。具体包括两种方法：1) 特征令牌调制(FTM)，对视觉令牌应用全局仿射变换；2) 特征线性适应(FLA)，在ViT编码器中引入低秩更新。

Result: FTM仅用4K参数就将Libero视角准确率从48.5%提升到87.1%；FLA用4.7M参数达到90.8%的成功率，与LoRA规模微调相当但成本更低。两种方法都显著提升了VLA模型在视角变化下的鲁棒性。

Conclusion: 预训练的VLA模型中存在大量未开发的鲁棒性潜力，通过有针对性的、最小化的视觉适应就足以恢复视角泛化能力，这为VLA模型的实用化部署提供了有效途径。

Abstract: Vision-language-action (VLA) models achieve strong in-distribution performance but degrade sharply under novel camera viewpoints and visual perturbations. We show that this brittleness primarily arises from misalignment in Spatial Modeling, rather than Physical Modeling. To address this, we propose a one-shot adaptation framework that recalibrates visual representations through lightweight, learnable updates. Our first method, Feature Token Modulation (FTM), applies a global affine transformation to visual tokens and improves Libero viewpoint accuracy from 48.5% to 87.1% with only 4K parameters. Building on this, Feature Linear Adaptation (FLA) introduces low-rank updates to the ViT encoder, achieving 90.8% success with 4.7M parameters -- matching LoRA-scale finetuning at far lower cost. Together, these results reveal substantial untapped robustness in pretrained VLA models and demonstrate that targeted, minimal visual adaptation is sufficient to restore viewpoint generalization.

</details>


### [52] [Experimental Characterization of Fingertip Trajectory following for a 3-DoF Series-Parallel Hybrid Robotic Finger](https://arxiv.org/abs/2512.02951)
*Nicholas Baiata,Nilanjan Chakraborty*

Main category: cs.RO

TL;DR: 本文提出了一种具有解析正向运动学和封闭形式雅可比矩阵的三自由度连杆驱动串并联机器人手指，实现了任务空间轨迹跟踪控制，实验验证了毫米级精度。


<details>
  <summary>Details</summary>
Motivation: 任务空间控制对于灵巧操作至关重要，因为操作目标通常以指尖运动和施加力来指定。虽然任务空间规划和控制已在大型机械臂中得到广泛研究，但在紧凑的多自由度机器人手指中实现精确任务空间轨迹跟踪的演示仍然很少。

Method: 设计并物理原型化了一个三自由度连杆驱动串并联机器人手指，具有解析正向运动学和封闭形式雅可比矩阵。采用解析运动速率控制（RMRC）方案实现闭环任务空间轨迹跟踪。

Result: 实验评估了指尖在各种轨迹（包括直线、圆形和更复杂曲线）上的跟踪性能，报告了毫米级精度。这是连杆驱动机器人手指中精确任务空间轨迹跟踪的首批系统性实验演示之一。

Conclusion: 这项工作为未来旨在实现灵巧手内操作的设计建立了基准，展示了在紧凑多自由度机器人手指中实现精确任务空间控制的可行性。

Abstract: Task-space control of robotic fingers is a critical enabler of dexterous manipulation, as manipulation objectives are most naturally specified in terms of fingertip motions and applied forces rather than individual joint angles. While task-space planning and control have been extensively studied for larger, arm-scale manipulators, demonstrations of precise task-space trajectory tracking in compact, multi-DoF robotic fingers remain scarce. In this paper, we present the physical prototyping and experimental characterization of a three-degree-of-freedom, linkage-driven, series-parallel robotic finger with analytic forward kinematics and a closed-form Jacobian. A resolved motion rate control (RMRC) scheme is implemented to achieve closed-loop task-space trajectory tracking. We experimentally evaluate the fingertip tracking performance across a variety of trajectories, including straight lines, circles, and more complex curves, and report millimeter-level accuracy. To the best of our knowledge, this work provides one of the first systematic experimental demonstrations of precise task-space trajectory tracking in a linkage-driven robotic finger, thereby establishing a benchmark for future designs aimed at dexterous in-hand manipulation.

</details>


### [53] [Video2Act: A Dual-System Video Diffusion Policy with Robotic Spatio-Motional Modeling](https://arxiv.org/abs/2512.03044)
*Yueru Jia,Jiaming Liu,Shengbang Liu,Rui Zhou,Wanhe Yu,Yuyang Yan,Xiaowei Chi,Yandong Guo,Boxin Shi,Shanghang Zhang*

Main category: cs.RO

TL;DR: Video2Act：利用视频扩散模型提取空间和运动感知表示来指导机器人动作学习，通过异步双系统设计提高推理效率，在仿真和真实任务中显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用视频扩散模型增强机器人策略，但忽视了VDM中跨帧编码的连贯且物理一致的运动表示。需要更有效地利用这些表示来指导机器人动作学习。

Method: 1) 从VDM中提取前景边界和帧间运动变化，过滤背景噪声和任务无关偏差；2) 将这些精炼表示作为扩散变换器动作头的额外条件输入；3) 采用异步双系统设计：VDM作为慢速System 2，DiT头作为快速System 1协同工作。

Result: 在仿真任务中平均成功率比现有VLA方法提高7.7%，在真实世界任务中提高21.7%，展现出强大的泛化能力。

Conclusion: Video2Act通过显式整合空间和运动感知表示，有效指导机器人动作学习，异步双系统设计解决了推理效率问题，显著提升了机器人策略的性能和泛化能力。

Abstract: Robust perception and dynamics modeling are fundamental to real-world robotic policy learning. Recent methods employ video diffusion models (VDMs) to enhance robotic policies, improving their understanding and modeling of the physical world. However, existing approaches overlook the coherent and physically consistent motion representations inherently encoded across frames in VDMs. To this end, we propose Video2Act, a framework that efficiently guides robotic action learning by explicitly integrating spatial and motion-aware representations. Building on the inherent representations of VDMs, we extract foreground boundaries and inter-frame motion variations while filtering out background noise and task-irrelevant biases. These refined representations are then used as additional conditioning inputs to a diffusion transformer (DiT) action head, enabling it to reason about what to manipulate and how to move. To mitigate inference inefficiency, we propose an asynchronous dual-system design, where the VDM functions as the slow System 2 and the DiT head as the fast System 1, working collaboratively to generate adaptive actions. By providing motion-aware conditions to System 1, Video2Act maintains stable manipulation even with low-frequency updates from the VDM. For evaluation, Video2Act surpasses previous state-of-the-art VLA methods by 7.7% in simulation and 21.7% in real-world tasks in terms of average success rate, further exhibiting strong generalization capabilities.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [54] [The 4/$δ$ Bound: Designing Predictable LLM-Verifier Systems for Formal Method Guarantee](https://arxiv.org/abs/2512.02080)
*PIerre Dantas,Lucas Cordeiro,Youcheng Sun,Waldir Junior*

Main category: cs.AI

TL;DR: 提出LLM-Verifier收敛定理，为LLM辅助的形式验证提供首个具有可证明终止和收敛保证的形式框架，通过马尔可夫链建模和大量实验验证了理论预测。


<details>
  <summary>Details</summary>
Motivation: 当前使用形式验证工具与大型语言模型的方法虽然扩展了软件验证能力，但缺乏可靠的理论基础，导致精炼过程不稳定（可能收敛、循环或偏离稳定轨迹），需要建立具有可证明保证的形式框架。

Method: 将LLM与验证器的交互建模为离散时间马尔可夫链，状态转移由关键参数δ（错误减少概率）决定。通过理论分析证明程序对任意δ>0几乎必然终止，并推导出期望迭代次数上界E[n]≤4/δ。随后进行了超过90,000次试验的大规模实证验证。

Result: 理论预测与实证结果高度一致：所有运行都达到了验证状态，收敛因子紧密聚集在Cf≈1.0附近。基于此证据，将工作流划分为三个操作区域（边际、实用、高性能），并建立了可靠的设计阈值。

Conclusion: 理论保证和实验证据共同为LLM辅助验证提供了清晰的架构基础，消除了启发式调优的需求，为工程师提供了支持可预测资源规划和性能预算的框架，特别适用于安全关键软件环境的部署。

Abstract: The idea of using Formal Verification tools with large language models (LLMs) has enabled scaling software verification beyond manual workflows. However, current methods remain unreliable. Without a solid theoretical footing, the refinement process can wander; sometimes it settles, sometimes it loops back, and sometimes it breaks away from any stable trajectory. This work bridges this critical gap by developing an LLM-Verifier Convergence Theorem, providing the first formal framework with provable guarantees for termination and convergence. We model the interaction between the LLM and the verifier as a discrete-time Markov Chain, with state transitions determined by a key parameter: the error-reduction probability ($δ$). The procedure reaching the Verified state almost surely demonstrates that the program terminates for any $δ> 0$, with an expected iteration count bounded by $\mathbb{E}[n] \leq 4/δ$. We then stress-tested this prediction in an extensive empirical campaign comprising more than 90,000 trials. The empirical results match the theory with striking consistency. Every single run reached verification, and the convergence factor clustered tightly around $C_f\approx$ 1.0. Consequently, the bound mirrors the system's actual behavior. The evidence is sufficiently robust to support dividing the workflow into three distinct operating zones: marginal, practical, and high-performance. Consequently, we establish the design thresholds with absolute confidence. Together, the theoretical guarantee and the experimental evidence provide a clearer architectural foundation for LLM-assisted verification. Heuristic tuning no longer has to be carried out by the system. Engineers gain a framework that supports predictable resource planning and performance budgeting, precisely what is needed before deploying these pipelines into safety-critical software environments.

</details>


### [55] [Flowchart2Mermaid: A Vision-Language Model Powered System for Converting Flowcharts into Editable Diagram Code](https://arxiv.org/abs/2512.02170)
*Pritam Deka,Barry Devereux*

Main category: cs.AI

TL;DR: Flowchart2Mermaid：一个将流程图图像转换为可编辑Mermaid.js代码的轻量级Web系统，支持混合主动式编辑和AI助手


<details>
  <summary>Details</summary>
Motivation: 流程图是常见的流程沟通工具，但通常以静态图像形式分享，难以编辑和重用。现有工具缺乏结构化、版本可控的文本表示

Method: 使用详细的系统提示和视觉语言模型将流程图图像转换为Mermaid.js代码，支持内联文本编辑、拖放节点插入和自然语言命令的AI助手

Result: 开发了一个轻量级Web系统，能够生成结构化、版本可控的文本表示，并与渲染的图表保持同步。引入了评估结构准确性、流程正确性、语法有效性和完整性的指标

Conclusion: 该方法能够将静态流程图转换为可编辑的文本表示，支持混合主动式细化，为流程图重用和协作提供了新途径

Abstract: Flowcharts are common tools for communicating processes but are often shared as static images that cannot be easily edited or reused. We present \textsc{Flowchart2Mermaid}, a lightweight web system that converts flowchart images into editable Mermaid.js code which is a markup language for visual workflows, using a detailed system prompt and vision-language models. The interface supports mixed-initiative refinement through inline text editing, drag-and-drop node insertion, and natural-language commands interpreted by an integrated AI assistant. Unlike prior image-to-diagram tools, our approach produces a structured, version-controllable textual representation that remains synchronized with the rendered diagram. We further introduce evaluation metrics to assess structural accuracy, flow correctness, syntax validity, and completeness across multiple models.

</details>


### [56] [From monoliths to modules: Decomposing transducers for efficient world modelling](https://arxiv.org/abs/2512.02193)
*Alexander Boyd,Franz Nowak,David Hyland,Manuel Baltieri,Fernando E. Rosas*

Main category: cs.AI

TL;DR: 提出一个框架，用于将复杂的世界模型（用transducer表示）分解为可并行处理的子模块，提高计算效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现实世界模型通常计算需求高，但真实场景往往包含模块化交互的子组件。为了在AI安全所需的透明性和实际推理所需的计算效率之间架起桥梁，需要开发可分解的世界模型框架。

Method: 开发了一个框架，将transducer（一种比POMDP更通用的模型）表示的复杂世界模型分解为在独立输入-输出子空间上运行的子transducer，支持并行化和可解释的替代方案。

Result: 阐明了如何逆转transducer组合过程，推导出在独立子空间上运行的子transducer，为分布式推理提供支持，实现了比单一世界模型更高效和可解释的替代方案。

Conclusion: 这些结果为连接AI安全所需的结构透明性和实际推理所需的计算效率奠定了基础，为可分解、可并行处理的世界模型提供了理论框架。

Abstract: World models have been recently proposed as sandbox environments in which AI agents can be trained and evaluated before deployment. Although realistic world models often have high computational demands, efficient modelling is usually possible by exploiting the fact that real-world scenarios tend to involve subcomponents that interact in a modular manner. In this paper, we explore this idea by developing a framework for decomposing complex world models represented by transducers, a class of models generalising POMDPs. Whereas the composition of transducers is well understood, our results clarify how to invert this process, deriving sub-transducers operating on distinct input-output subspaces, enabling parallelizable and interpretable alternatives to monolithic world modelling that can support distributed inference. Overall, these results lay a groundwork for bridging the structural transparency demanded by AI safety and the computational efficiency required for real-world inference.

</details>


### [57] [STRIDE: A Systematic Framework for Selecting AI Modalities -- Agentic AI, AI Assistants, or LLM Calls](https://arxiv.org/abs/2512.02228)
*Shubhi Asthana,Bing Zhang,Chad DeLuca,Ruchi Mahindru,Hima Patel*

Main category: cs.AI

TL;DR: STRIDE框架帮助系统化决定何时使用自主AI代理，避免不必要的复杂部署，通过任务分解和动态性评估来推荐最合适的AI模态（直接LLM调用、引导助手或完全自主代理）。


<details>
  <summary>Details</summary>
Motivation: 随着AI从无状态大语言模型向自主目标驱动代理的快速转变，需要解决一个核心问题：何时真正需要代理式AI？不加区分地部署代理会导致更高的成本、复杂性和风险，因此需要原则性的决策框架。

Method: 提出STRIDE框架，通过结构化任务分解、动态性归因和自我反思需求分析，生成代理适用性分数，从而在三种AI模态中做出推荐：直接LLM调用、引导AI助手、完全自主代理式AI。

Result: 在30个真实世界任务（涵盖SRE、合规和企业自动化）中评估，STRIDE在模态选择上达到92%准确率，减少45%不必要的代理部署，降低37%资源成本。专家验证确认其实际效用。

Conclusion: 该工作将代理采用重新定义为必要性驱动的设计决策，确保自主性仅在收益证明成本合理时应用，为AI部署提供了系统化的决策框架。

Abstract: The rapid shift from stateless large language models (LLMs) to autonomous, goal-driven agents raises a central question: When is agentic AI truly necessary? While agents enable multi-step reasoning, persistent memory, and tool orchestration, deploying them indiscriminately leads to higher cost, complexity, and risk.
  We present STRIDE (Systematic Task Reasoning Intelligence Deployment Evaluator), a framework that provides principled recommendations for selecting between three modalities: (i) direct LLM calls, (ii) guided AI assistants, and (iii) fully autonomous agentic AI. STRIDE integrates structured task decomposition, dynamism attribution, and self-reflection requirement analysis to produce an Agentic Suitability Score, ensuring that full agentic autonomy is reserved for tasks with inherent dynamism or evolving context.
  Evaluated across 30 real-world tasks spanning SRE, compliance, and enterprise automation, STRIDE achieved 92% accuracy in modality selection, reduced unnecessary agent deployments by 45%, and cut resource costs by 37%. Expert validation over six months in SRE and compliance domains confirmed its practical utility, with domain specialists agreeing that STRIDE effectively distinguishes between tasks requiring simple LLM calls, guided assistants, or full agentic autonomy. This work reframes agent adoption as a necessity-driven design decision, ensuring autonomy is applied only when its benefits justify the costs.

</details>


### [58] [Benchmarking LLM Agents for Wealth-Management Workflows](https://arxiv.org/abs/2512.02230)
*Rory Milsom*

Main category: cs.AI

TL;DR: 该论文扩展了TheAgentCompany平台，创建了财富管理评估基准，发现LLM代理在端到端工作流可靠性方面存在局限，而非数学推理能力，且自主性水平显著影响性能。


<details>
  <summary>Details</summary>
Motivation: 尽管现代工作依赖各种数字协作工具，但常规流程仍受人为错误和延迟困扰。论文旨在研究通用LLM代理是否能准确且经济地完成财富管理任务，填补这一空白。

Method: 扩展TheAgentCompany平台，添加金融领域环境；创建合成领域数据；丰富同事模拟；原型化自动任务生成管道；构建包含12个任务对的财富管理助手基准，涵盖检索、分析和综合/沟通任务，具有明确的验收标准和确定性评分器。

Result: 代理的局限性更多在于端到端工作流可靠性，而非数学推理能力；自主性水平对性能有显著影响；不正确的模型评估阻碍了基准测试的有效性。

Conclusion: 需要创建有意义的评估集来衡量代理在财富管理助手工作中的适用性，并认识到工作流可靠性和自主性水平是影响代理性能的关键因素，而非单纯的数学推理能力。

Abstract: Modern work relies on an assortment of digital collaboration tools, yet routine processes continue to suffer from human error and delay. To address this gap, this dissertation extends TheAgentCompany with a finance-focused environment and investigates whether a general purpose LLM agent can complete representative wealth-management tasks both accurately and economically. This study introduces synthetic domain data, enriches colleague simulations, and prototypes an automatic task-generation pipeline. The study aims to create and assess an evaluation set that can meaningfully measure an agent's fitness for assistant-level wealth management work. We construct a benchmark of 12 task-pairs for wealth management assistants spanning retrieval, analysis, and synthesis/communication, with explicit acceptance criteria and deterministic graders. We seeded a set of new finance-specific data and introduced a high vs. low-autonomy variant of every task. The paper concluded that agents are limited less by mathematical reasoning and more so by end-to-end workflow reliability, and meaningfully affected by autonomy level, and that incorrect evaluation of models have hindered benchmarking.

</details>


### [59] [TradeTrap: Are LLM-based Trading Agents Truly Reliable and Faithful?](https://arxiv.org/abs/2512.02261)
*Lewen Yan,Jilin Mei,Tianyi Zhou,Lige Huang,Jie Zhang,Dongrui Liu,Jing Shao*

Main category: cs.AI

TL;DR: TradeTrap是一个统一的评估框架，用于系统性地压力测试自适应和程序化自主交易代理，通过针对四个核心组件施加受控扰动来评估其在对抗条件下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的交易代理在真实金融市场中部署越来越多，但其在对抗或故障条件下的可靠性和鲁棒性尚未得到充分检验，而金融环境具有高风险和不可逆的特性。

Method: TradeTrap针对自主交易代理的四个核心组件（市场情报、策略制定、投资组合和账本处理、交易执行）施加受控的系统级扰动，在真实美国股票市场数据的闭环历史回测环境中进行评估。

Result: 实验表明，单个组件的小扰动可以通过代理决策循环传播，导致极端集中、失控暴露和大幅投资组合回撤，证明当前自主交易代理在系统层面容易被系统性误导。

Conclusion: 当前自主交易代理在系统层面存在脆弱性，需要更鲁棒的设计和评估框架来确保其在对抗性金融环境中的可靠性。

Abstract: LLM-based trading agents are increasingly deployed in real-world financial markets to perform autonomous analysis and execution. However, their reliability and robustness under adversarial or faulty conditions remain largely unexamined, despite operating in high-risk, irreversible financial environments. We propose TradeTrap, a unified evaluation framework for systematically stress-testing both adaptive and procedural autonomous trading agents. TradeTrap targets four core components of autonomous trading agents: market intelligence, strategy formulation, portfolio and ledger handling, and trade execution, and evaluates their robustness under controlled system-level perturbations. All evaluations are conducted in a closed-loop historical backtesting setting on real US equity market data with identical initial conditions, enabling fair and reproducible comparisons across agents and attacks. Extensive experiments show that small perturbations at a single component can propagate through the agent decision loop and induce extreme concentration, runaway exposure, and large portfolio drawdowns across both agent types, demonstrating that current autonomous trading agents can be systematically misled at the system level. Our code is available at https://github.com/Yanlewen/TradeTrap.

</details>


### [60] [Bridging the Gap: Toward Cognitive Autonomy in Artificial Intelligence](https://arxiv.org/abs/2512.02280)
*Noorbakhsh Amiri Golilarz,Sindhuja Penchala,Shahram Rahimi*

Main category: cs.AI

TL;DR: 论文分析了当前AI系统的七大核心缺陷，提出需要向基于认知原理的AI架构转变，以实现真正的自主性和适应性。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在感知、语言、推理和多模态领域取得快速进展，但现有系统在自我监控、自我纠正和行为自主调节方面存在根本性限制。这些限制阻碍了AI实现稳健泛化、终身适应性和现实世界自主性。

Method: 通过识别和分析当代AI模型的七大核心缺陷：缺乏内在自我监控、元认知意识不足、学习机制固定非自适应、无法重组目标、表征维护能力缺失、具身反馈不足、内在能动性缺乏。结合人工系统与生物认知的比较分析，整合AI研究、认知科学和神经科学的见解。

Result: 论文指出当前架构（包括深度学习和基于Transformer的系统）存在结构性限制，仅靠扩展规模无法解决这些问题。这些缺陷导致AI系统无法实现真正的自主适应和动态行为管理。

Conclusion: 主张向认知基础AI（认知自主性）进行范式转变，这种AI能够实现自我导向适应、动态表征管理和有意图的目标导向行为，同时配备改革性监督机制，确保自主系统保持可解释性、可治理性并与人类价值观保持一致。

Abstract: Artificial intelligence has advanced rapidly across perception, language, reasoning, and multimodal domains. Yet despite these achievements, modern AI systems remain fundamentally limited in their ability to self-monitor, self-correct, and regulate their behavior autonomously in dynamic contexts. This paper identifies and analyzes seven core deficiencies that constrain contemporary AI models: the absence of intrinsic self-monitoring, lack of meta-cognitive awareness, fixed and non-adaptive learning mechanisms, inability to restructure goals, lack of representational maintenance, insufficient embodied feedback, and the absence of intrinsic agency. Alongside identifying these limitations, we also outline a forward-looking perspective on how AI may evolve beyond them through architectures that mirror neurocognitive principles. We argue that these structural limitations prevent current architectures, including deep learning and transformer-based systems, from achieving robust generalization, lifelong adaptability, and real-world autonomy. Drawing on a comparative analysis of artificial systems and biological cognition [7], and integrating insights from AI research, cognitive science, and neuroscience, we outline how these capabilities are absent in current models and why scaling alone cannot resolve them. We conclude by advocating for a paradigmatic shift toward cognitively grounded AI (cognitive autonomy) capable of self-directed adaptation, dynamic representation management, and intentional, goal-oriented behavior, paired with reformative oversight mechanisms [8] that ensure autonomous systems remain interpretable, governable, and aligned with human values.

</details>


### [61] [DialogGuard: Multi-Agent Psychosocial Safety Evaluation of Sensitive LLM Responses](https://arxiv.org/abs/2512.02282)
*Han Luo,Guy Laban*

Main category: cs.AI

TL;DR: DialogGuard是一个多智能体框架，用于评估LLM生成回复的心理社会风险，涵盖隐私侵犯、歧视行为、心理操纵、心理伤害和侮辱行为五个高风险维度，通过四种LLM-as-a-judge流程实现更准确的风险检测。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)现在被广泛应用于心理健康、危机干预和其他情感敏感服务中，但这些模型在这些场景中的心理社会安全性仍然缺乏深入理解和有效评估，存在潜在风险。

Method: 提出DialogGuard多智能体框架，包含四种LLM-as-a-judge评估流程：单智能体评分、双智能体修正、多智能体辩论和随机多数投票，基于共享的三级评估标准，可用于人类标注者和LLM评估者。

Result: 使用PKU-SafeRLHF数据集验证显示，多智能体机制比非LLM基线和单智能体评估更准确地检测心理社会风险；双智能体修正和多数投票在准确性、与人类评分对齐度和鲁棒性之间达到最佳平衡；辩论机制召回率更高但会过度标记边界案例。

Conclusion: DialogGuard作为开源软件发布，提供维度风险评分和可解释的自然语言推理，支持面向脆弱用户的网络应用进行提示设计、审计和监督，提高了LLM在敏感场景中的安全性评估能力。

Abstract: Large language models (LLMs) now mediate many web-based mental-health, crisis, and other emotionally sensitive services, yet their psychosocial safety in these settings remains poorly understood and weakly evaluated. We present DialogGuard, a multi-agent framework for assessing psychosocial risks in LLM-generated responses along five high-severity dimensions: privacy violations, discriminatory behaviour, mental manipulation, psychological harm, and insulting behaviour. DialogGuard can be applied to diverse generative models through four LLM-as-a-judge pipelines, including single-agent scoring, dual-agent correction, multi-agent debate, and stochastic majority voting, grounded in a shared three-level rubric usable by both human annotators and LLM judges. Using PKU-SafeRLHF with human safety annotations, we show that multi-agent mechanisms detect psychosocial risks more accurately than non-LLM baselines and single-agent judging; dual-agent correction and majority voting provide the best trade-off between accuracy, alignment with human ratings, and robustness, while debate attains higher recall but over-flags borderline cases. We release Dialog-Guard as open-source software with a web interface that provides per-dimension risk scores and explainable natural-language rationales. A formative study with 12 practitioners illustrates how it supports prompt design, auditing, and supervision of web-facing applications for vulnerable users.

</details>


### [62] [Model Recovery at the Edge under Resource Constraints for Physical AI](https://arxiv.org/abs/2512.02283)
*Bin Xu,Ayan Banerjee,Sandeep K. S. Gupta*

Main category: cs.AI

TL;DR: MERINDA是一个FPGA加速的模型恢复框架，通过并行化神经架构替代迭代求解器，显著降低边缘设备的内存和能耗，实现实时任务关键自主系统。


<details>
  <summary>Details</summary>
Motivation: 模型恢复（MR）在任务关键自主系统中能实现安全、可解释的决策，但现有基于神经ODE的迭代求解方法在FPGA上效率低下，内存和能耗限制了其在边缘设备上的实时部署。

Method: 提出MERINDA框架，用并行化神经架构替代神经ODE的迭代求解器，专门针对FPGA优化，减少DRAM使用并加速推理。

Result: 相比移动GPU，MERINDA实现近11倍DRAM使用降低和2.2倍运行速度提升，实验显示在固定精度下内存与能耗呈反比关系。

Conclusion: MERINDA特别适合资源受限的实时任务关键自主系统，解决了模型恢复在边缘设备部署的关键瓶颈。

Abstract: Model Recovery (MR) enables safe, explainable decision making in mission-critical autonomous systems (MCAS) by learning governing dynamical equations, but its deployment on edge devices is hindered by the iterative nature of neural ordinary differential equations (NODEs), which are inefficient on FPGAs. Memory and energy consumption are the main concerns when applying MR on edge devices for real-time operation. We propose MERINDA, a novel FPGA-accelerated MR framework that replaces iterative solvers with a parallelizable neural architecture equivalent to NODEs. MERINDA achieves nearly 11x lower DRAM usage and 2.2x faster runtime compared to mobile GPUs. Experiments reveal an inverse relationship between memory and energy at fixed accuracy, highlighting MERINDA's suitability for resource-constrained, real-time MCAS.

</details>


### [63] [Breast Cell Segmentation Under Extreme Data Constraints: Quantum Enhancement Meets Adaptive Loss Stabilization](https://arxiv.org/abs/2512.02302)
*Varun Kumar Dasoju,Qingsu Cheng,Zeyun Yu*

Main category: cs.AI

TL;DR: 该研究提出了一种用于乳腺细胞分割的量子增强深度学习框架，仅用599张训练图像就达到了95.5%的Dice分数，显著减少了医学图像标注所需的时间和专家投入。


<details>
  <summary>Details</summary>
Motivation: 医学图像标注需要大量时间和专业知识，特别是乳腺上皮细胞核数据集的标注需要病理学家投入数百小时。这是一个临床感知AI发展的关键瓶颈。

Method: 1) 使用多尺度Gabor滤波器进行量子启发的边缘增强，创建第四个输入通道；2) 提出稳定的多组件损失函数，结合自适应Dice损失和边界感知项；3) 引入基于复杂度的加权采样策略；4) 采用EfficientNet-B7/UNet++架构，支持4通道到3通道的投影；5) 通过指数移动平均和统计异常值检测进行鲁棒验证。

Result: 框架达到95.5% ± 0.3%的Dice分数和91.2% ± 0.4%的IoU。量子增强使边界精度提升2.1%，加权采样使小病灶检测提升3.8%。在仅有4%像素代表乳腺组织、60%图像不含乳腺区域的极端不平衡数据集上表现优异。

Conclusion: 该方法通过有限标注实现了突破性性能，显著减少了医学专家创建数据集所需的时间，解决了临床感知AI发展的根本瓶颈问题。

Abstract: Annotating medical images demands significant time and expertise, often requiring pathologists to invest hundreds of hours in labeling mammary epithelial nuclei datasets. We address this critical challenge by achieving 95.5% Dice score using just 599 training images for breast cell segmentation, where just 4% of pixels represent breast tissue and 60% of images contain no breast regions. Our framework uses quantum-inspired edge enhancement via multi-scale Gabor filters creating a fourth input channel, enhancing boundary detection where inter-annotator variations reach +/- 3 pixels. We present a stabilized multi-component loss function that integrates adaptive Dice loss with boundary-aware terms and automatic positive weighting to effectively address severe class imbalance, where mammary epithelial cell regions comprise only 0.1%-20% of the total image area. Additionally, a complexity-based weighted sampling strategy is introduced to prioritize the challenging mammary epithelial cell regions. The model employs an EfficientNet-B7/UNet++ architecture with a 4-to-3 channel projection, enabling the use of pretrained weights despite limited medical imaging data. Finally, robust validation is achieved through exponential moving averaging and statistical outlier detection, ensuring reliable performance estimates on a small validation set (129 images). Our framework achieves a Dice score of 95.5% +/- 0.3% and an IoU of 91.2% +/- 0.4%. Notably, quantum-based enhancement contributes to a 2.1% improvement in boundary accuracy, while weighted sampling increases small lesion detection by 3.8%. By achieving groundbreaking performance with limited annotations, our approach significantly reduces the medical expert time required for dataset creation, addressing a fundamental bottleneck in clinical perception AI development.

</details>


### [64] [OmniGuard: Unified Omni-Modal Guardrails with Deliberate Reasoning](https://arxiv.org/abs/2512.02306)
*Boyu Zhu,Xiaofei Wen,Wenjie Jacky Mo,Tinghui Zhu,Yanan Xie,Peng Qi,Muhao Chen*

Main category: cs.AI

TL;DR: OmniGuard是首个全模态安全护栏系统，通过精心策划的21万+多模态安全数据集和结构化标注，为处理文本、图像、视频、音频的OLLMs提供统一的安全保障框架。


<details>
  <summary>Details</summary>
Motivation: 现有安全护栏研究主要针对单模态场景，采用二元分类框架，在多模态和跨模态任务中鲁棒性不足。随着Omni-modal LLMs的出现，需要新的安全保障方法来应对多模态交互中的安全挑战。

Method: 提出OmniGuard框架，构建包含21万+样本的全模态安全数据集，涵盖所有模态的单模态和跨模态样本，通过专家模型针对性蒸馏生成结构化安全标签和安全评述，实现跨模态的深思熟虑推理能力。

Result: 在15个基准测试中，OmniGuard在广泛的多模态安全场景中展现出强大的有效性和泛化能力，成为首个能够跨所有模态执行安全保障的全模态护栏系统。

Conclusion: OmniGuard为全模态LLMs提供了统一的安全保障框架，能够执行策略并减轻风险，为构建更鲁棒和强大的全模态安全系统铺平了道路。

Abstract: Omni-modal Large Language Models (OLLMs) that process text, images, videos, and audio introduce new challenges for safety and value guardrails in human-AI interaction. Prior guardrail research largely targets unimodal settings and typically frames safeguarding as binary classification, which limits robustness across diverse modalities and tasks. To address this gap, we propose OmniGuard, the first family of omni-modal guardrails that performs safeguarding across all modalities with deliberate reasoning ability. To support the training of OMNIGUARD, we curate a large, comprehensive omni-modal safety dataset comprising over 210K diverse samples, with inputs that cover all modalities through both unimodal and cross-modal samples. Each sample is annotated with structured safety labels and carefully curated safety critiques from expert models through targeted distillation. Extensive experiments on 15 benchmarks show that OmniGuard achieves strong effectiveness and generalization across a wide range of multimodal safety scenarios. Importantly, OmniGuard provides a unified framework that enforces policies and mitigates risks in omni-modalities, paving the way toward building more robust and capable omnimodal safeguarding systems.

</details>


### [65] [Reasoning Path and Latent State Analysis for Multi-view Visual Spatial Reasoning: A Cognitive Science Perspective](https://arxiv.org/abs/2512.02340)
*Qiyao Xue,Weichen Liu,Shiqi Wang,Haoming Wang,Yuyang Wu,Wei Gao*

Main category: cs.AI

TL;DR: 论文提出了ReMindView-Bench基准测试，用于评估视觉语言模型在多视角空间推理中的表现，发现现有模型在跨视角对齐和视角转换方面存在系统性失败。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在多视角设置中难以保持几何一致性和跨视角一致性，缺乏能够隔离多视角推理与单视角感知和时间因素的细粒度基准测试。

Method: 开发了ReMindView-Bench基准测试，系统性地变化视角空间模式和查询类型来探测空间认知的关键因素。使用显式分阶段分析（LLM-as-a-judge和自一致性提示）和隐式分析（线性探测和熵动态）来诊断推理过程。

Result: 评估15个当前VLMs显示在跨视角对齐和视角转换方面存在一致失败。模型在帧内感知表现良好，但在跨视角信息整合时性能急剧下降。隐式分析显示任务相关信息逐渐丢失，正确与错误轨迹之间的不确定性分离。

Conclusion: 研究提供了基于认知科学的VLM空间推理诊断，揭示了多视角空间心理模型在推理过程中如何形成、退化和失稳，为改进模型的空间推理能力提供了基础。

Abstract: Spatial reasoning is a core aspect of human intelligence that allows perception, inference and planning in 3D environments. However, current vision-language models (VLMs) struggle to maintain geometric coherence and cross-view consistency for spatial reasoning in multi-view settings. We attribute this gap to the lack of fine-grained benchmarks that isolate multi-view reasoning from single-view perception and temporal factors. To address this, we present ReMindView-Bench, a cognitively grounded benchmark for evaluating how VLMs construct, align and maintain spatial mental models across complementary viewpoints. ReMindView-Bench systematically varies viewpoint spatial pattern and query type to probe key factors of spatial cognition. Evaluations of 15 current VLMs reveals consistent failures in cross-view alignment and perspective-taking in multi-view spatial reasoning, motivating deeper analysis on the reasoning process. Explicit phase-wise analysis using LLM-as-a-judge and self-consistency prompting shows that VLMs perform well on in-frame perception but degrade sharply when integrating information across views. Implicit analysis, including linear probing and entropy dynamics, further show progressive loss of task-relevant information and uncertainty separation between correct and incorrect trajectories. These results provide a cognitively grounded diagnosis of VLM spatial reasoning and reveal how multi-view spatial mental models are formed, degraded and destabilized across reasoning phases. The ReMindView-Bench benchmark is available at https://huggingface.co/datasets/Xue0823/ReMindView-Bench, and the source codes of benchmark construction and VLM reasoning analysis are available at https://github.com/pittisl/ReMindView-Bench.

</details>


### [66] [Beyond Playtesting: A Generative Multi-Agent Simulation System for Massively Multiplayer Online Games](https://arxiv.org/abs/2512.02358)
*Ran Zhang,Kun Ouyang,Tiancheng Ma,Yida Yang,Dong Fang*

Main category: cs.AI

TL;DR: 该论文提出了一种基于LLM的生成式智能体MMO模拟系统，用于数据驱动的数值设计优化，通过SFT和RL训练LLM模拟真实玩家行为，结合数据驱动的环境模型，实现低成本、高保真度的游戏系统优化。


<details>
  <summary>Details</summary>
Motivation: 传统MMO游戏数值系统和机制设计优化依赖大规模在线实验或预定义统计模型的参数调优，这些方法成本高、耗时长，且可能干扰玩家体验。简化离线模拟系统保真度有限，无法准确模拟真实玩家的推理和对干预的反应。

Method: 提出基于大语言模型的生成式智能体MMO模拟系统：1) 使用监督微调(SFT)和强化学习(RL)在大规模真实玩家行为数据上训练LLM，使其从通用先验适应到游戏特定领域；2) 基于真实游戏日志训练数据驱动的环境模型，重建动态游戏系统。

Result: 实验表明该系统与真实世界玩家行为具有强一致性，在干预下能产生合理的因果响应，为数据驱动的数值设计优化提供了可靠、可解释且成本效益高的框架。

Conclusion: 基于LLM的生成式智能体模拟系统能够克服传统优化方法的局限性，提供高保真度、可解释且经济高效的MMO游戏数值设计优化解决方案，显著降低实验成本并减少对玩家体验的干扰。

Abstract: Optimizing numerical systems and mechanism design is crucial for enhancing player experience in Massively Multiplayer Online (MMO) games. Traditional optimization approaches rely on large-scale online experiments or parameter tuning over predefined statistical models, which are costly, time-consuming, and may disrupt player experience. Although simplified offline simulation systems are often adopted as alternatives, their limited fidelity prevents agents from accurately mimicking real player reasoning and reactions to interventions. To address these limitations, we propose a generative agent-based MMO simulation system empowered by Large Language Models (LLMs). By applying Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on large-scale real player behavioral data, we adapt LLMs from general priors to game-specific domains, enabling realistic and interpretable player decision-making. In parallel, a data-driven environment model trained on real gameplay logs reconstructs dynamic in-game systems. Experiments demonstrate strong consistency with real-world player behaviors and plausible causal responses under interventions, providing a reliable, interpretable, and cost-efficient framework for data-driven numerical design optimization.

</details>


### [67] [Synthetic Error Injection Fails to Elicit Self-Correction In Language Models](https://arxiv.org/abs/2512.02389)
*David X. Wu,Shreyas Kapur,Anant Sahai,Stuart Russell*

Main category: cs.AI

TL;DR: 监督学习结合人工错误注入无法有效提升语言模型的自我纠错能力，尽管方法直观，但性能提升有限，且存在分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习虽然能激发大语言模型的推理和自我纠错能力，但计算成本高昂，因此探索替代方法。受自动驾驶和机器人技术启发，研究是否可以通过监督学习结合人工错误注入来诱导语言模型的自我纠错能力。

Method: 在推理链中插入人工错误，将其掩码，然后监督模型识别和纠正这些错误。通过合成错误注入的方式进行监督学习训练。

Result: 该方法即使在简单的合成任务上也无法显著提升多个模型的性能。即使模型捕捉到自己的错误，也常常重复原始错误。研究发现，从合成错误到在线策略错误的分布偏移显著降低了微调模型的纠错能力，即使合成错误覆盖了在线策略错误。

Conclusion: 解释了为什么在线策略强化学习方法在激发自我纠错能力方面特别有效，而监督学习结合人工错误注入的方法效果有限，主要受分布偏移问题影响。

Abstract: Reinforcement learning has become the dominant paradigm for eliciting reasoning and self-correction capabilities in large language models, but its computational expense motivates exploration of alternatives. Inspired by techniques from autonomous driving and robotics, we investigate whether supervised learning with synthetic error injection can induce self-correction abilities in language models. Our approach inserts artificial errors into reasoning chains, masks them, and supervises the model to recognize and correct these mistakes. Despite the intuitive appeal of this method, we find that it fails to significantly improve performance even on simple synthetic tasks across multiple models. Moreover, even when the model catches its own error, it often parrots the original mistake. We find that the distribution shift of synthetic errors to on-policy errors significantly degrades the error-correction capabilities of the fine-tuned model, even with good synthetic coverage of on-policy errors. Our results help explain why on-policy reinforcement learning methods have proven uniquely effective for eliciting self-correction.

</details>


### [68] [Semantic Trading: Agentic AI for Clustering and Relationship Discovery in Prediction Markets](https://arxiv.org/abs/2512.02436)
*Agostino Capponi,Alfio Gliozzo,Brian Zhu*

Main category: cs.AI

TL;DR: 本文提出了一种基于智能AI的管道，能够自动聚类预测市场并识别市场间的依赖关系，通过交易策略验证了这些关系的可操作性。


<details>
  <summary>Details</summary>
Motivation: 预测市场存在碎片化问题，包括重叠问题、隐含等价性和隐藏矛盾，需要一种自动化方法来发现市场间的潜在语义结构和依赖关系。

Method: 开发了一个智能AI管道，通过自然语言理解对市场合约文本和元数据进行聚类，然后在聚类内识别具有强依赖关系的市场对（包括正相关和反相关关系）。

Result: 在Polymarket历史数据集上的评估显示，AI识别的市场关系准确率达到60-70%，基于这些关系构建的简单交易策略在一周时间范围内获得约20%的平均回报。

Conclusion: 智能AI和大语言模型能够有效发现预测市场中的潜在语义结构，识别出的市场关系具有实际交易价值，为市场分析和交易策略提供了新方法。

Abstract: Prediction markets allow users to trade on outcomes of real-world events, but are prone to fragmentation through overlapping questions, implicit equivalences, and hidden contradictions across markets. We present an agentic AI pipeline that autonomously (i) clusters markets into coherent topical groups using natural-language understanding over contract text and metadata, and (ii) identifies within-cluster market pairs whose resolved outcomes exhibit strong dependence, including same-outcome (correlated) and different-outcome (anti-correlated) relationships. Using a historical dataset of resolved markets on Polymarket, we evaluate the accuracy of the agent's relational predictions. We then translate discovered relationships into a simple trading strategy to quantify how these relationships map to actionable signals. Results show that agent-identified relationships achieve roughly 60-70% accuracy, and their induced trading strategies earn about 20% average returns over week-long horizons, highlighting the ability of agentic AI and large language models to uncover latent semantic structure in prediction markets.

</details>


### [69] [Guided Self-Evolving LLMs with Minimal Human Supervision](https://arxiv.org/abs/2512.02472)
*Wenhao Yu,Zhenwen Liang,Chengsong Huang,Kishan Panaganti,Tianqing Fang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: R-Few是一个引导式自演化的Challenger-Solver框架，通过少量人类标注示例进行上下文引导和混合训练，实现稳定可控的AI自我进化，在数学和通用推理任务上取得持续改进。


<details>
  <summary>Details</summary>
Motivation: 传统无引导的自演化系统容易陷入平台期或性能退化，存在概念漂移、多样性崩溃和错误演化等问题。需要一种能够稳定可控地进行自我演化，同时最小化人类监督依赖的方法。

Method: 提出R-Few框架，包含Challenger和Solver两个组件。Challenger使用少量人类标注示例引导生成合成问题，Solver在在线难度课程下联合训练人类和合成示例。

Result: 在数学和通用推理基准测试中实现持续迭代改进。Qwen3-8B-Base在数学任务上比R-Zero提升3.0分，性能与使用20倍人类数据训练的General-Reasoner相当。消融研究证实了引导式Challenger训练和课程式Solver训练的互补贡献。

Conclusion: R-Few通过轻量级人类监督实现了稳定可控的自我演化，缓解了概念漂移问题，产生了更稳定可控的协同演化动态，为AI自我进化提供了一条可行路径。

Abstract: AI self-evolution has long been envisioned as a path toward superintelligence, where models autonomously acquire, refine, and internalize knowledge from their own learning experiences. Yet in practice, unguided self-evolving systems often plateau quickly or even degrade as training progresses. These failures arise from issues such as concept drift, diversity collapse, and mis-evolution, as models reinforce their own biases and converge toward low-entropy behaviors. To enable models to self-evolve in a stable and controllable manner while minimizing reliance on human supervision, we introduce R-Few, a guided Self-Play Challenger-Solver framework that incorporates lightweight human oversight through in-context grounding and mixed training. At each iteration, the Challenger samples a small set of human-labeled examples to guide synthetic question generation, while the Solver jointly trains on human and synthetic examples under an online, difficulty-based curriculum. Across math and general reasoning benchmarks, R-Few achieves consistent and iterative improvements. For example, Qwen3-8B-Base improves by +3.0 points over R-Zero on math tasks and achieves performance on par with General-Reasoner, despite the latter being trained on 20 times more human data. Ablation studies confirm the complementary contributions of grounded challenger training and curriculum-based solver training, and further analysis shows that R-Few mitigates drift, yielding more stable and controllable co-evolutionary dynamics.

</details>


### [70] [COPE: Chain-Of-Thought Prediction Engine for Open-Source Large Language Model Based Stroke Outcome Prediction from Clinical Notes](https://arxiv.org/abs/2512.02499)
*Yongkai Liu,Helena Feng,Bin Jiang,Yixin Wang,Max Wintermark,David S. Liebeskind,Michael Moseley,Maarten Lansberg,Gregory Albers,Jeremy Heit,Greg Zaharchuk*

Main category: cs.AI

TL;DR: COPE是一个基于思维链的LLM框架，用于从非结构化临床笔记预测急性缺血性卒中90天功能结局，性能优于传统模型，与GPT-4.1相当。


<details>
  <summary>Details</summary>
Motivation: 临床笔记包含丰富的上下文信息，但其非结构化特性限制了在传统预测模型中的应用。需要开发能够利用这些非结构化数据准确预测卒中结局的方法。

Method: 开发了两步思维链框架COPE：第一步生成临床推理，第二步输出mRS预测。基于LLaMA-3-8B模型，与GPT-4.1、ClinicalBERT、结构化机器学习模型和单步LLM进行比较。

Result: COPE的MAE为1.01，±1准确率为74.4%，精确准确率为32.8%，性能与GPT-4.1相当，优于ClinicalBERT、临床ML和单步LLM。在不同亚组中表现一致。

Conclusion: COPE作为一个轻量级、可解释、保护隐私的开源框架，为从非结构化临床文本进行结局预测提供了准确实用的解决方案。

Abstract: Predicting outcomes in acute ischemic stroke (AIS) guides clinical decision-making, patient counseling, and resource allocation. Clinical notes contain rich contextual information, but their unstructured nature limits their use in traditional predictive models. We developed and evaluated the Chain-of-Thought (CoT) Outcome Prediction Engine (COPE), a reasoning-enhanced large language model framework, for predicting 90-day functional outcomes after AIS from unstructured clinical notes. This study included 464 AIS patients with discharge summaries and 90-day modified Rankin Scale (mRS) scores. COPE uses a two-step CoT framework based on sequential open-source LLaMA-3-8B models: the first generates clinical reasoning, and the second outputs an mRS prediction. We compared COPE with GPT-4.1, ClinicalBERT, a structured variable-based machine learning model (Clinical ML), and a single-step LLM without CoT. Performance was evaluated using mean absolute error (MAE), accuracy within +/-1 mRS point, and exact accuracy. COPE achieved an MAE of 1.01 (95% CI 0.92-1.11), +/-1 accuracy of 74.4% (69.9, 78.8%), and exact accuracy of 32.8% (28.0, 37.6%), comparable to GPT-4.1 and superior to ClinicalBERT [MAE 1.24 (1.13-1.36)], Clinical ML [1.28 (1.18-1.39)], and the single-step LLM [1.20 (1.09-1.33)]. Subgroup analyses showed consistent performance across sex and age, with slightly higher error among older patients, those undergoing thrombectomy, and those with longer summaries. These findings demonstrate that COPE, a lightweight, interpretable, and privacy-preserving open-source framework, provides an accurate and practical solution for outcome prediction from unstructured clinical text.

</details>


### [71] [Aetheria: A multimodal interpretable content safety framework based on multi-agent debate and collaboration](https://arxiv.org/abs/2512.02530)
*Yuxiang He,Jian Zhao,Yuchen Yuan,Tianle Zhang,Wei Cai,Haojie Cheng,Ziyan Shi,Ming Zhu,Haichuan Tang,Chi Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: 提出Aetheria框架，基于多智能体辩论与协作的多模态可解释内容安全系统，通过动态辩论机制和RAG知识检索，显著提升内容安全准确性，特别是隐式风险识别能力。


<details>
  <summary>Details</summary>
Motivation: 数字内容爆炸式增长带来内容安全挑战，现有基于单一模型或固定流水线的审核系统在识别隐式风险和提供可解释判断过程方面存在局限。

Method: 采用五个核心智能体的协作架构，通过基于RAG知识检索的动态相互说服辩论机制，对多模态内容进行深度分析和裁决。

Result: 在提出的AIR-Bench基准测试中，Aetheria不仅生成详细可追溯的审核报告，而且在整体内容安全准确性上显著优于基线方法，特别是在隐式风险识别方面。

Conclusion: 该框架建立了透明可解释的范式，显著推进了可信AI内容审核领域的发展。

Abstract: The exponential growth of digital content presents significant challenges for content safety. Current moderation systems, often based on single models or fixed pipelines, exhibit limitations in identifying implicit risks and providing interpretable judgment processes. To address these issues, we propose Aetheria, a multimodal interpretable content safety framework based on multi-agent debate and collaboration.Employing a collaborative architecture of five core agents, Aetheria conducts in-depth analysis and adjudication of multimodal content through a dynamic, mutually persuasive debate mechanism, which is grounded by RAG-based knowledge retrieval.Comprehensive experiments on our proposed benchmark (AIR-Bench) validate that Aetheria not only generates detailed and traceable audit reports but also demonstrates significant advantages over baselines in overall content safety accuracy, especially in the identification of implicit risks. This framework establishes a transparent and interpretable paradigm, significantly advancing the field of trustworthy AI content moderation.

</details>


### [72] [Empathy Level Prediction in Multi-Modal Scenario with Supervisory Documentation Assistance](https://arxiv.org/abs/2512.02558)
*Yufei Xiao,Shangfei Wang*

Main category: cs.AI

TL;DR: 提出一种结合视频、音频和文本的多模态共情预测方法，利用监督文档作为特权信息提升文本特征提取，在训练阶段使用LDA模型约束文本特征，实验证明优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有共情预测技术主要集中于单一模态（通常是文本），忽略了多模态处理能力，同时未能利用某些特权信息（可能包含额外的共情内容）。

Method: 1. 多模态共情预测：使用预训练网络提取视频、音频和文本特征，进行跨模态融合得到多模态特征表示，用于预测共情标签。2. 监督文档辅助训练：在训练阶段引入监督文档作为特权信息，使用LDA模型识别潜在主题分布来约束文本特征。监督文档由监督者创建，关注咨询主题和咨询师的共情表现。

Result: 在多模态和对话共情数据集上的实验结果表明，该方法优于现有方法。

Conclusion: 提出的多模态共情预测方法通过整合视频、音频和文本信息，并利用监督文档作为特权信息进行辅助训练，有效提升了共情预测性能。

Abstract: Prevalent empathy prediction techniques primarily concentrate on a singular modality, typically textual, thus neglecting multi-modal processing capabilities. They also overlook the utilization of certain privileged information, which may encompass additional empathetic content. In response, we introduce an advanced multi-modal empathy prediction method integrating video, audio, and text information. The method comprises the Multi-Modal Empathy Prediction and Supervisory Documentation Assisted Training. We use pre-trained networks in the empathy prediction network to extract features from various modalities, followed by a cross-modal fusion. This process yields a multi-modal feature representation, which is employed to predict empathy labels. To enhance the extraction of text features, we incorporate supervisory documents as privileged information during the assisted training phase. Specifically, we apply the Latent Dirichlet Allocation model to identify potential topic distributions to constrain text features. These supervisory documents, created by supervisors, focus on the counseling topics and the counselor's display of empathy. Notably, this privileged information is only available during training and is not accessible during the prediction phase. Experimental results on the multi-modal and dialogue empathy datasets demonstrate that our approach is superior to the existing methods.

</details>


### [73] [PaperDebugger: A Plugin-Based Multi-Agent System for In-Editor Academic Writing, Review, and Editing](https://arxiv.org/abs/2512.02589)
*Junyi Hou,Andre Lin Huikai,Nuo Chen,Yiwei Gong,Bingsheng He*

Main category: cs.AI

TL;DR: PaperDebugger：一个基于多智能体、插件化的学术写作助手，直接在LaTeX编辑器（如Overleaf）中集成LLM驱动的推理，支持上下文感知的写作操作。


<details>
  <summary>Details</summary>
Motivation: 现有写作助手与编辑器分离，无法深度交互文档状态、结构和修订历史，限制了在LaTeX编辑器中实现智能、上下文感知的操作。

Method: 通过Chrome扩展、Kubernetes原生编排层和Model Context Protocol工具链，实现可靠的双向同步、细粒度版本控制、安全状态管理、多智能体调度和外部工具集成。

Result: 展示了完全集成的工作流程，包括本地化编辑、结构化评审、并行智能体执行和基于差异的更新，早期聚合分析显示用户积极参与。

Conclusion: PaperDebugger验证了编辑器原生、智能体驱动的写作助手的实用性，为学术写作提供了深度集成的LLM支持环境。

Abstract: Large language models are increasingly embedded into academic writing workflows, yet existing assistants remain external to the editor, preventing deep interaction with document state, structure, and revision history. This separation makes it impossible to support agentic, context-aware operations directly within LaTeX editors such as Overleaf. We present PaperDebugger, an in-editor, multi-agent, and plugin-based academic writing assistant that brings LLM-driven reasoning directly into the writing environment. Enabling such in-editor interaction is technically non-trivial: it requires reliable bidirectional synchronization with the editor, fine-grained version control and patching, secure state management, multi-agent scheduling, and extensible communication with external tools. PaperDebugger addresses these challenges through a Chrome-approved extension, a Kubernetes-native orchestration layer, and a Model Context Protocol (MCP) toolchain that integrates literature search, reference lookup, document scoring, and revision pipelines. Our demo showcases a fully integrated workflow, including localized edits, structured reviews, parallel agent execution, and diff-based updates, encapsulated within a minimal-intrusion user interface (UI). Early aggregated analytics demonstrate active user engagement and validate the practicality of an editor-native, agentic writing assistant. More details about this demo and video could be found at https://github.com/PaperDebugger/PaperDebugger.

</details>


### [74] [IACT: A Self-Organizing Recursive Model for General AI Agents: A Technical White Paper on the Architecture Behind kragent.ai](https://arxiv.org/abs/2512.02605)
*Pengju Lu*

Main category: cs.AI

TL;DR: IACT是一个动态、递归的代理拓扑模型，通过用户对话驱动，能够自主扩展组织结构以适应开放式任务，并通过双向对话机制减少错误传播。


<details>
  <summary>Details</summary>
Motivation: 解决静态、硬编码代理工作流的局限性，传统系统需要预定义图或专门编程，无法灵活适应复杂任务。

Method: 基于用户对话驱动的通用自主系统，通过动态递归代理拓扑结构，将刚性函数调用替换为双向、有状态的对话机制，实现运行时错误纠正和歧义解析。

Result: 在kragent.ai系统中进行了生产部署，提供了真实工作流的定性证据，展示了系统能够扩展组织复杂性以匹配开放式任务。

Conclusion: IACT模型通过交互式冗余和动态拓扑结构，为自主代理系统提供了更灵活、容错性更强的解决方案，能够有效处理复杂、开放式的任务。

Abstract: This technical white paper introduces the Interactive Agents Call Tree (IACT), a computational model designed to address the limitations of static, hard-coded agent workflows. Unlike traditional systems that require pre-defined graphs or specialized programming, IACT operates as a general-purpose autonomous system driven purely by user dialogue. Given a high-level objective, the system autonomously grows a dynamic, recursive agent topology incrementally tailored to the problem's structure. This allows it to scale its organizational complexity to match open-ended tasks. To mitigate the error propagation inherent in unidirectional function calls, IACT introduces interactional redundancy by replacing rigid invocations with bidirectional, stateful dialogues. This mechanism enables runtime error correction and ambiguity resolution. We describe the architecture, design principles, and practical lessons behind the production deployment of this model in the kragent.ai system, presenting qualitative evidence from real-world workflows rather than exhaustive benchmark results.

</details>


### [75] [Target-specific Adaptation and Consistent Degradation Alignment for Cross-Domain Remaining Useful Life Prediction](https://arxiv.org/abs/2512.02610)
*Yubo Hou,Mohamed Ragab,Min Wu,Chee-Keong Kwoh,Xiaoli Li,Zhenghua Chen*

Main category: cs.AI

TL;DR: 提出TACDA方法，通过目标域重构和聚类配对策略解决跨域剩余使用寿命预测中的领域差异问题，在对抗性领域适应中保留目标特定信息并实现退化阶段的一致性对齐。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的RUL预测方法通常假设训练和测试数据来自同一分布，但实际工业环境中存在领域差异问题。先前对抗性领域适应方法只关注领域不变特征，忽略了目标特定信息和退化阶段的一致性特征，导致性能不佳。

Method: 提出TACDA方法：1）在对抗性适应过程中加入目标域重构策略，在学习领域不变特征的同时保留目标特定信息；2）开发新的聚类和配对策略，实现相似退化阶段之间的一致性对齐。

Result: 通过大量实验证明，TACDA方法在两个不同的评估指标上均显著优于现有最先进方法，表现出卓越的性能。

Conclusion: TACDA方法有效解决了跨域RUL预测中的领域差异问题，通过目标域重构和退化阶段一致性对齐策略，在保留目标特定信息的同时实现了更好的领域适应性能。

Abstract: Accurate prediction of the Remaining Useful Life (RUL) in machinery can significantly diminish maintenance costs, enhance equipment up-time, and mitigate adverse outcomes. Data-driven RUL prediction techniques have demonstrated commendable performance. However, their efficacy often relies on the assumption that training and testing data are drawn from the same distribution or domain, which does not hold in real industrial settings. To mitigate this domain discrepancy issue, prior adversarial domain adaptation methods focused on deriving domain-invariant features. Nevertheless, they overlook target-specific information and inconsistency characteristics pertinent to the degradation stages, resulting in suboptimal performance. To tackle these issues, we propose a novel domain adaptation approach for cross-domain RUL prediction named TACDA. Specifically, we propose a target domain reconstruction strategy within the adversarial adaptation process, thereby retaining target-specific information while learning domain-invariant features. Furthermore, we develop a novel clustering and pairing strategy for consistent alignment between similar degradation stages. Through extensive experiments, our results demonstrate the remarkable performance of our proposed TACDA method, surpassing state-of-the-art approaches with regard to two different evaluation metrics. Our code is available at https://github.com/keyplay/TACDA.

</details>


### [76] [Zero-Shot Instruction Following in RL via Structured LTL Representations](https://arxiv.org/abs/2512.02633)
*Mattia Giuri,Mathias Jackermeier,Alessandro Abate*

Main category: cs.AI

TL;DR: 提出一种基于图神经网络编码布尔公式序列的新方法，用于强化学习智能体执行任意LTL指令，解决了多事件同时发生时的复杂交互问题。


<details>
  <summary>Details</summary>
Motivation: 现有将LTL指令解释为有限自动机的方法在多个高级事件同时发生且可能复杂交互的环境中表现不足，需要新的多任务策略学习方法。

Method: 提出基于布尔公式序列的策略条件化方法，这些公式直接对应自动机中的转移，并通过图神经网络编码以产生结构化任务表示。

Result: 在复杂的基于国际象棋的环境中进行的实验证明了该方法的优势。

Conclusion: 该方法能够有效处理多个事件同时发生的复杂环境，为LTL指令下的强化学习提供了更强大的多任务策略学习框架。

Abstract: Linear temporal logic (LTL) is a compelling framework for specifying complex, structured tasks for reinforcement learning (RL) agents. Recent work has shown that interpreting LTL instructions as finite automata, which can be seen as high-level programs monitoring task progress, enables learning a single generalist policy capable of executing arbitrary instructions at test time. However, existing approaches fall short in environments where multiple high-level events (i.e., atomic propositions) can be true at the same time and potentially interact in complicated ways. In this work, we propose a novel approach to learning a multi-task policy for following arbitrary LTL instructions that addresses this shortcoming. Our method conditions the policy on sequences of simple Boolean formulae, which directly align with transitions in the automaton, and are encoded via a graph neural network (GNN) to yield structured task representations. Experiments in a complex chess-based environment demonstrate the advantages of our approach.

</details>


### [77] [Exploring Depth Generalization in Large Language Models for Solving Recursive Logic Tasks](https://arxiv.org/abs/2512.02677)
*Zhiyuan He*

Main category: cs.AI

TL;DR: 本文研究大型语言模型在递归推理问题中的深度泛化能力不足，并提出了一种循环定位-替换管道方法来缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理递归推理问题（需要解决嵌套层次结构的问题）时面临显著挑战。虽然先前研究广泛探讨了长度泛化（模型处理比训练时更长序列的能力），但深度泛化（处理比训练时更深嵌套层次的能力）这一独特且未被充分探索的局限性尚未得到深入研究。

Method: 提出了一种新颖的循环定位-替换管道方法，将递归问题分解为可管理的子组件。该方法使用两个专门模型：定位器识别可解决的子表达式，替换器评估这些组件同时保持整体结构。

Result: 在三个精心设计的领域（布尔代数、递归算术和命题逻辑）进行评估，每个领域都有可控的递归深度。结果表明，该方法在测试超出分布范围的递归深度时，有效缓解了性能衰减。

Conclusion: 标准Transformer架构在处理比训练时更深的递归问题时存在困难，这源于其无法维持类似栈的行为来跟踪和解决多层嵌套依赖。提出的循环定位-替换管道方法为解决这一深度泛化挑战提供了有效途径。

Abstract: Large language models have demonstrated remarkable capabilities across many tasks, yet face significant challenges when dealing with recursive reasoning problems, those requiring the resolution of nested hierarchical structures. While prior research has extensively studied length generalization (a model's ability to handle longer sequences than seen during training), we investigate a distinct and underexplored limitation: depth generalization. Here, depth refers to the number of nested levels in a hierarchical problem, such as the layers of parentheses in a mathematical expression or the nesting of logical clauses in a Boolean formula. Our work reveals that standard transformer architectures struggle with problems involving deeper recursion than encountered during training, even when they perform well on longer but non-nested sequences. This limitation stems from their inability to maintain stack-like behavior, the capacity to track and resolve multiple levels of nested dependencies. Through systematic analysis, we demonstrate how this architectural constraint leads to rapid performance decay as the depth of the recursion increases. To address this challenge, we develop a novel looped locate-and-replace pipeline that decomposes recursive problems into manageable subcomponents. The approach employs two specialized models: a locator that identifies solvable subexpressions and a replacer that evaluates these components while preserving the overall structure. We evaluated this method in three carefully designed domains: Boolean algebra, recursive arithmetic, and propositional logic, each with a controllable depth of recursion. We show that our method effectively alleviates the performance decay when tested on out-of-distribution recursion depth.

</details>


### [78] [Learning What to Attend First: Modality-Importance-Guided Reasoning for Reliable Multimodal Emotion Understanding](https://arxiv.org/abs/2512.02699)
*Hyeongseop Rha,Jeong Hun Yeo,Junil Won,Se Jin Park,Yong Man Ro*

Main category: cs.AI

TL;DR: MIGR框架通过模态重要性引导推理，解决多模态情感理解中的推理漂移问题，显著提升解释的情感一致性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在情感理解中存在推理漂移问题：模型逐渐依赖自身生成的文本而非多模态证据，且解释过度受视觉推理路径影响，导致解释与情感不一致。

Method: 提出模态重要性机制识别情感主导模态，基于此重组推理序列，使解释从最关键的情感模态开始。采用两阶段框架：模态对齐监督微调和模态感知奖励优化。

Result: 在DFEW基准测试中，MIGR显著提升推理可靠性，将正确预测但情感不一致解释的比例从18.10%降至7.37%。

Conclusion: 从情感主导模态开始推理能有效提升多模态情感理解的可靠性，MIGR框架为解决推理漂移问题提供了有效方案。

Abstract: In this paper, we present Modality-Importance-Guided Reasoning (MIGR), a framework designed to improve the reliability of reasoning-based multimodal emotion understanding in multimodal large language models. Although existing methods have advanced emotion understanding, they often suffer from reasoning drift: models gradually rely on their own generated text instead of multimodal evidence, and their explanations are overly shaped by visually initiated reasoning paths. To address these issues, we introduce Modality Importance (MI), a simple yet effective mechanism for identifying the emotion-dominant modality. Using MI, MIGR reorganizes reasoning sequences so that explanations begin from the modality most critical to the target emotion, preventing early reasoning from being misled by less informative cues. Our two-stage framework-comprising modality-aligned supervised fine-tuning and modality-aware reward optimization-encourages models to generate emotionally grounded, causally relevant, and coherence-preserving explanations. Experimental results on the DFEW benchmark show that MIGR substantially improves reasoning reliability, decreasing instances of correct predictions accompanied by emotionally inconsistent explanations from 18.10% to 7.37%. These results confirm the benefit of initiating reasoning from the emotion-dominant modality.

</details>


### [79] [Training Data Attribution for Image Generation using Ontology-Aligned Knowledge Graphs](https://arxiv.org/abs/2512.02713)
*Theodoros Aivalis,Iraklis A. Klampanos,Antonis Troumpoukis,Joemon M. Jose*

Main category: cs.AI

TL;DR: 提出一个通过知识图谱对比分析生成模型输出与训练数据关系的框架，用于追溯版权影响和提高AI透明度


<details>
  <summary>Details</summary>
Motivation: 随着生成模型能力增强，透明度、问责制和版权侵权问题日益突出，需要理解训练数据如何影响模型输出

Method: 利用多模态大语言模型从图像中提取结构化三元组，构建与领域本体对齐的知识图谱，通过对比生成图像和训练图像的KG来追溯潜在影响

Result: 通过局部训练模型的遗忘实验和大规模模型的风格特定实验验证了方法的有效性，支持版权分析、数据集透明度和可解释AI

Conclusion: 该框架有助于开发促进人类协作、创造力和激发好奇心的AI系统，为生成模型的透明度和问责制提供技术支持

Abstract: As generative models become powerful, concerns around transparency, accountability, and copyright violations have intensified. Understanding how specific training data contributes to a model's output is critical. We introduce a framework for interpreting generative outputs through the automatic construction of ontologyaligned knowledge graphs (KGs). While automatic KG construction from natural text has advanced, extracting structured and ontology-consistent representations from visual content remains challenging -- due to the richness and multi-object nature of images. Leveraging multimodal large language models (LLMs), our method extracts structured triples from images, aligned with a domain-specific ontology. By comparing the KGs of generated and training images, we can trace potential influences, enabling copyright analysis, dataset transparency, and interpretable AI. We validate our method through experiments on locally trained models via unlearning, and on large-scale models through a style-specific experiment. Our framework supports the development of AI systems that foster human collaboration, creativity and stimulate curiosity.

</details>


### [80] [Menta: A Small Language Model for On-Device Mental Health Prediction](https://arxiv.org/abs/2512.02716)
*Tianyi Zhang,Xiangyuan Xue,Lingyan Ruan,Shiya Fu,Feng Xia,Simon D'Alfonso,Vassilis Kostakos,Hong Jia*

Main category: cs.AI

TL;DR: Menta是首个针对社交媒体心理健康预测优化的轻量级小语言模型，通过多任务训练在抑郁、压力、自杀倾向等任务上表现优于现有SLM和部分大型LLM，并能在移动设备上实时部署。


<details>
  <summary>Details</summary>
Motivation: 心理健康问题影响全球数亿人，但早期检测仍然有限。虽然大语言模型在心理健康应用中有潜力，但其规模和计算需求阻碍了实际部署。小语言模型提供了轻量级替代方案，但在基于社交媒体的心理健康预测方面尚未充分探索。

Method: 提出Menta模型，使用LoRA框架进行多任务联合训练，涵盖六个分类任务，采用跨数据集策略和平衡准确率导向的损失函数。与9个最先进的SLM基线进行比较。

Result: Menta在抑郁、压力、自杀倾向等任务上平均提升15.2%，优于未微调的SLM；在抑郁和压力分类任务上准确率超过130亿参数的大语言模型，同时模型大小缩小约3.25倍。可在iPhone 15 Pro Max上实时部署，仅需约3GB内存。

Conclusion: Menta展示了轻量级模型在可扩展、隐私保护的心理健康监测方面的潜力，为移动设备上的实时心理健康评估提供了实用解决方案。

Abstract: Mental health conditions affect hundreds of millions globally, yet early detection remains limited. While large language models (LLMs) have shown promise in mental health applications, their size and computational demands hinder practical deployment. Small language models (SLMs) offer a lightweight alternative, but their use for social media--based mental health prediction remains largely underexplored. In this study, we introduce Menta, the first optimized SLM fine-tuned specifically for multi-task mental health prediction from social media data. Menta is jointly trained across six classification tasks using a LoRA-based framework, a cross-dataset strategy, and a balanced accuracy--oriented loss. Evaluated against nine state-of-the-art SLM baselines, Menta achieves an average improvement of 15.2\% across tasks covering depression, stress, and suicidality compared with the best-performing non--fine-tuned SLMs. It also achieves higher accuracy on depression and stress classification tasks compared to 13B-parameter LLMs, while being approximately 3.25x smaller. Moreover, we demonstrate real-time, on-device deployment of Menta on an iPhone 15 Pro Max, requiring only approximately 3GB RAM. Supported by a comprehensive benchmark against existing SLMs and LLMs, Menta highlights the potential for scalable, privacy-preserving mental health monitoring. Code is available at: https://xxue752-nz.github.io/menta-project/

</details>


### [81] [StockMem: An Event-Reflection Memory Framework for Stock Forecasting](https://arxiv.org/abs/2512.02720)
*He Wang,Wenyilin Xiao,Songqiao Han,Hailiang Huang*

Main category: cs.AI

TL;DR: StockMem：一个事件-反思双层记忆框架，通过结构化新闻为事件，横向整合与纵向追踪来提取市场预期差异信息，构建事件知识库和因果经验库，用于股票价格预测。


<details>
  <summary>Details</summary>
Motivation: 股票价格预测面临市场波动性和对实时事件敏感性的挑战。虽然大语言模型为基于文本的预测提供了新途径，但在金融领域的应用受到噪声新闻数据和文本中缺乏明确答案的限制。通用记忆架构难以识别价格变动的关键驱动因素。

Method: 提出StockMem，一个事件-反思双层记忆框架：1）将新闻结构化处理为事件；2）横向整合每日事件；3）纵向追踪事件演化以提取反映市场预期差异的增量信息；4）构建时序事件知识库；5）分析事件-价格动态形成因果经验反思知识库；6）预测时检索类似历史场景，结合当前事件、增量数据和过去经验进行推理。

Result: 实验表明StockMem优于现有记忆架构，通过追踪影响价格的信息链提供更优且可解释的推理，增强了金融预测的决策透明度。

Conclusion: StockMem通过结构化事件处理和双层记忆设计，有效解决了金融新闻数据噪声和关键驱动因素识别问题，为股票价格预测提供了更准确、可解释的解决方案。

Abstract: Stock price prediction is challenging due to market volatility and its sensitivity to real-time events. While large language models (LLMs) offer new avenues for text-based forecasting, their application in finance is hindered by noisy news data and the lack of explicit answers in text. General-purpose memory architectures struggle to identify the key drivers of price movements. To address this, we propose StockMem, an event-reflection dual-layer memory framework. It structures news into events and mines them along two dimensions: horizontal consolidation integrates daily events, while longitudinal tracking captures event evolution to extract incremental information reflecting market expectation discrepancies. This builds a temporal event knowledge base. By analyzing event-price dynamics, the framework further forms a reflection knowledge base of causal experiences. For prediction, it retrieves analogous historical scenarios and reasons with current events, incremental data, and past experiences. Experiments show StockMem outperforms existing memory architectures and provides superior, explainable reasoning by tracing the information chain affecting prices, enhancing decision transparency in financial forecasting.

</details>


### [82] [AuditCopilot: Leveraging LLMs for Fraud Detection in Double-Entry Bookkeeping](https://arxiv.org/abs/2512.02726)
*Md Abdul Kadir,Sai Suresh Macharla Vasu,Sidharth S. Nair,Daniel Sonntag*

Main category: cs.AI

TL;DR: LLMs在复式记账异常检测中优于传统规则方法和机器学习基线，提供自然语言解释，支持AI增强审计


<details>
  <summary>Details</summary>
Motivation: 传统日记账测试(JETs)基于规则的方法产生大量误报且难以检测细微异常，需要更有效的异常检测方法

Method: 使用LLaMA和Gemma等最先进的大语言模型，在合成和真实匿名分类账上进行基准测试，与传统JETs和机器学习基线对比

Result: LLMs在异常检测方面持续优于传统规则方法和经典机器学习基线，同时提供增强可解释性的自然语言解释

Conclusion: LLMs展示了AI增强审计的潜力，人类审计师与基础模型协作可加强财务完整性

Abstract: Auditors rely on Journal Entry Tests (JETs) to detect anomalies in tax-related ledger records, but rule-based methods generate overwhelming false positives and struggle with subtle irregularities. We investigate whether large language models (LLMs) can serve as anomaly detectors in double-entry bookkeeping. Benchmarking SoTA LLMs such as LLaMA and Gemma on both synthetic and real-world anonymized ledgers, we compare them against JETs and machine learning baselines. Our results show that LLMs consistently outperform traditional rule-based JETs and classical ML baselines, while also providing natural-language explanations that enhance interpretability. These results highlight the potential of \textbf{AI-augmented auditing}, where human auditors collaborate with foundation models to strengthen financial integrity.

</details>


### [83] [Self-Improving AI Agents through Self-Play](https://arxiv.org/abs/2512.02731)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 将心理测量电池的模数理论框架扩展到动力系统领域，通过GVU算子将智能体形式化为计算资源参数化的流，推导出保证自我改进稳定性的方差不等式条件


<details>
  <summary>Details</summary>
Motivation: 现有AAI能力评分是静态函数，需要扩展到动态系统来形式化智能体的自我改进过程，统一理解语言自我对弈、自我纠正、合成数据引导等近期研究

Method: 将智能体形式化为参数化流ν_r，由递归的生成器-验证器-更新器(GVU)算子控制，证明该算子在参数流形Θ上生成向量场，将自我改进系数κ识别为能力函数沿该流的李导数

Result: 推导出方差不等式这一谱条件，在温和正则条件下足以保证自我改进的稳定性，证明κ>0的充分条件是生成和验证的联合噪声足够小，并将该形式化应用于统一LSP、自我纠正、合成数据引导等架构

Conclusion: GVU算子为理解智能体自我改进提供了统一的数学框架，方差不等式为设计稳定自我改进系统提供了理论指导，STaR、SPIN、Reflexion、GANs、AlphaZero等架构是该算子的具体拓扑实现

Abstract: We extend the moduli-theoretic framework of psychometric batteries to the domain of dynamical systems. While previous work established the AAI capability score as a static functional on the space of agent representations, this paper formalizes the agent as a flow $ν_r$ parameterized by computational resource $r$, governed by a recursive Generator-Verifier-Updater (GVU) operator. We prove that this operator generates a vector field on the parameter manifold $Θ$, and we identify the coefficient of self-improvement $κ$ as the Lie derivative of the capability functional along this flow.
  The central contribution of this work is the derivation of the Variance Inequality, a spectral condition that is sufficient (under mild regularity) for the stability of self-improvement. We show that a sufficient condition for $κ> 0$ is that, up to curvature and step-size effects, the combined noise of generation and verification must be small enough.
  We then apply this formalism to unify the recent literature on Language Self-Play (LSP), Self-Correction, and Synthetic Data bootstrapping. We demonstrate that architectures such as STaR, SPIN, Reflexion, GANs and AlphaZero are specific topological realizations of the GVU operator that satisfy the Variance Inequality through filtration, adversarial discrimination, or grounding in formal systems.

</details>


### [84] [A Framework for Causal Concept-based Model Explanations](https://arxiv.org/abs/2512.02735)
*Anna Rodum Bjøru,Jacob Lysnæs-Larsen,Oskar Jørgensen,Inga Strümke,Helge Langseth*

Main category: cs.AI

TL;DR: 提出基于因果概念的事后可解释AI框架，通过概念干预的充分概率生成局部和全局解释，强调解释需同时具备可理解性和忠实性


<details>
  <summary>Details</summary>
Motivation: 针对非可解释模型的解释需求，需要既能让人类理解，又能忠实反映模型行为的解释方法。现有方法往往难以同时满足可理解性和忠实性要求。

Method: 提出因果概念事后解释框架，通过计算概念干预的充分概率来生成局部和全局解释。使用基于概念的词汇表，并建立隐式因果解释。在CelebA数据集上构建概念验证模型进行演示。

Result: 展示了通过概念验证模型生成的示例解释，证明了方法的可理解性（通过清晰的概念词汇表）和忠实性（通过强调框架假设和解释上下文对齐）。

Conclusion: 提出的因果概念事后解释框架能够为不可解释模型提供既易于理解又忠实于模型的解释，但需要确保解释生成和解释理解的上下文保持一致。

Abstract: This work presents a conceptual framework for causal concept-based post-hoc Explainable Artificial Intelligence (XAI), based on the requirements that explanations for non-interpretable models should be understandable as well as faithful to the model being explained. Local and global explanations are generated by calculating the probability of sufficiency of concept interventions. Example explanations are presented, generated with a proof-of-concept model made to explain classifiers trained on the CelebA dataset. Understandability is demonstrated through a clear concept-based vocabulary, subject to an implicit causal interpretation. Fidelity is addressed by highlighting important framework assumptions, stressing that the context of explanation interpretation must align with the context of explanation generation.

</details>


### [85] [Enhancing Automated Paper Reproduction via Prompt-Free Collaborative Agents](https://arxiv.org/abs/2512.02812)
*Zijie Lin,Qilin Cai,Liang Shen,Mingjun Xiao*

Main category: cs.AI

TL;DR: 提出一种无需人工提示的协作智能体框架，通过验证和精炼代理自动提升论文到代码生成的准确性和完整性，相比基线提升约15%和13%。


<details>
  <summary>Details</summary>
Motivation: 现有自动化论文复现框架缺乏对每个生成步骤输出的验证和精炼机制，或者过度依赖人工设计的提示进行自我精炼，这限制了框架的适应性和可扩展性。

Method: 提出一个无需提示的协作智能体框架，包含两个代理：验证代理检查每个步骤输出是否满足系统提示要求，精炼代理根据识别的问题修正输出。仅利用原始系统提示实现自动验证和改进，无需人工为每个步骤设计特定精炼提示。

Result: 在PaperBench Code-Dev和Paper2CodeBench数据集上的实验表明，该方法显著提高了复现代码的准确性和完整性，相比无代理的基线分别获得约15%和13%的性能提升。与Self-Refine的对比实验验证了该无提示方法在不同数据集上的鲁棒性和一致性。

Conclusion: 提出的无提示协作智能体框架能够有效提升自动化论文到代码生成的质量，通过自动验证和精炼机制解决了现有方法的局限性，为科学研究的加速提供了更可靠的工具。

Abstract: Automated paper reproduction has emerged as a promising approach to accelerate scientific research, employing multi-step workflow frameworks to systematically convert academic papers into executable code. However, existing frameworks often lack mechanisms to verify and refine the outputs at each generation step, or rely heavily on manually designed prompts for self-refinement, which limits their adaptability and scalability. To address these limitations, we propose a prompt-free collaborative agent framework that automatically enhances the quality of paper-to-code generation. Our approach employs two collaborative agents: a verification agent that examines whether the outputs at each step satisfy the requirements specified in the corresponding system prompt, and a refinement agent that revises the outputs based on the identified issues. Unlike previous methods that require human experts to craft specific refinement prompts for each step, our framework achieves automatic verification and improvement by leveraging only the original system prompts. We integrate our collaborative agents into the Paper2Code framework and conduct comprehensive experiments on PaperBench Code-Dev and Paper2CodeBench datasets. Experimental results demonstrate that our approach significantly improves the accuracy and completeness of reproduced code, achieving performance gains of approximately 15\% and 13\%, respectively, compared to the baseline without our agents. Furthermore, comparative experiments against Self-Refine validate the robustness and consistency of our prompt-free approach across different datasets.

</details>


### [86] [Radiologist Copilot: An Agentic Assistant with Orchestrated Tools for Radiology Reporting with Quality Control](https://arxiv.org/abs/2512.02814)
*Yongrui Yu,Zhongzhen Huang,Linjie Mu,Shaoting Zhang,Xiaofan Zhang*

Main category: cs.AI

TL;DR: Radiologist Copilot：基于大语言模型的智能放射学报告助手，通过编排工具实现自动化报告生成与质量控制，超越现有方法


<details>
  <summary>Details</summary>
Motivation: 放射学报告是临床检查中重要但耗时且易出错的任务，现有自动化方法主要关注报告生成阶段，忽视了关键的质量控制环节，限制了为放射科医生提供全面支持的能力

Method: 以大语言模型为推理核心，构建智能代理系统，通过编排工具（区域定位、图像引导的区域分析规划、策略性模板选择、质量评估和反馈驱动的自适应优化）自主选择工具、规划和执行行动，模拟放射科医生在整个报告过程中的行为

Result: 实验结果表明，Radiologist Copilot在放射学报告任务上显著优于其他最先进方法

Conclusion: Radiologist Copilot能够促进准确、完整、高效的放射学报告，协助放射科医生并提高临床效率，源代码将在接受后发布

Abstract: Radiology reporting is an essential yet time-consuming and error-prone task for radiologists in clinical examinations, especially for volumetric medical images. Rigorous quality control is also critical but tedious, ensuring that the final report meets clinical standards. Existing automated approaches, including radiology report generation methods and medical vision-language models, focus mainly on the report generation phase and neglect the crucial quality control procedure, limiting their capability to provide comprehensive support to radiologists. We propose Radiologist Copilot, an agentic AI assistant equipped with orchestrated tools designed for automated radiology reporting with quality control. Leveraging large language models as the reasoning backbone, the agentic system autonomously selects tools, plans, and executes actions, emulating the behavior of radiologists throughout the holistic radiology reporting process. The orchestrated tools include region localization, think with image paradigm directed region analysis planning, strategic template selection for report generation, quality assessment and feedback-driven adaptive refinement for quality control. Therefore, Radiologist Copilot facilitates accurate, complete, and efficient radiology reporting, assisting radiologists and improving clinical efficiency. Experimental results demonstrate that Radiologist Copilot significantly surpasses other state-of-the-art methods in radiology reporting. The source code will be released upon acceptance.

</details>


### [87] [The future of AI in critical mineral exploration](https://arxiv.org/abs/2512.02879)
*Jef Caers*

Main category: cs.AI

TL;DR: 提出基于贝叶斯主义和证伪原则的新科学方法，利用AI减少认知偏差和假阳性，降低勘探成本


<details>
  <summary>Details</summary>
Motivation: 尽管投资增加，但过去二十年新矿床发现减少，需要解决关键矿物勘探效率低下的问题

Method: 基于贝叶斯主义和证伪原则的哲学方法，将数据采集视为证伪人类假设的手段，使用可验证指标进行理性决策，需要新型无监督学习和人机协同AI算法

Result: 提供可应用于任何勘探活动的实用协议模板

Conclusion: AI能够实现严谨的科学方法，减少认知偏差和假阳性，降低勘探成本，提高关键矿物勘探效率

Abstract: The energy transition through increased electrification has put the worlds attention on critical mineral exploration Even with increased investments a decrease in new discoveries has taken place over the last two decades Here I propose a solution to this problem where AI is implemented as the enabler of a rigorous scientific method for mineral exploration that aims to reduce cognitive bias and false positives drive down the cost of exploration I propose a new scientific method that is based on a philosophical approach founded on the principles of Bayesianism and falsification In this approach data acquisition is in the first place seen as a means to falsify human generated hypothesis Decision of what data to acquire next is quantified with verifiable metrics and based on rational decision making A practical protocol is provided that can be used as a template in any exploration campaign However in order to make this protocol practical various form of artificial intelligence are needed I will argue that the most important form are one novel unsupervised learning methods that collaborate with domain experts to better understand data and generate multiple competing geological hypotheses and two humanintheloop AI algorithms that can optimally plan various geological geophysical geochemical and drilling data acquisition where uncertainty reduction of geological hypothesis precedes the uncertainty reduction on grade and tonnage

</details>


### [88] [Martingale Score: An Unsupervised Metric for Bayesian Rationality in LLM Reasoning](https://arxiv.org/abs/2512.02914)
*Zhonghao He,Tianyi Qiu,Hirokazu Shirado,Maarten Sap*

Main category: cs.AI

TL;DR: 提出基于鞅性质的无监督评估框架，用于检测LLM推理中的信念固化现象，发现当前信念能正向预测未来信念更新，表明存在非贝叶斯理性更新偏差。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM推理能力提升，但迭代推理可能强化信念固化和确认偏误，而非促进真相寻求。需要系统评估LLM推理中的信念固化现象。

Method: 利用贝叶斯统计中的鞅性质，提出无监督、基于回归的鞅分数来衡量违反该性质的程度。该性质要求未来信念的期望值等于当前信念，即信念更新不可从当前信念预测。

Result: 在事件预测、价值负载问题和学术论文评审等开放领域，发现违反鞅性质的现象普遍存在，当前信念能正向预测未来信念更新，即信念固化。识别了易出现信念固化的模型、推理技术和领域。

Conclusion: 鞅分数可作为无监督指标有效评估LLM推理的真相寻求能力，即使在没有真实标签的领域也能作为真相寻求能力的代理指标，有助于识别和改进LLM推理中的非理性更新偏差。

Abstract: Recent advances in reasoning techniques have substantially improved the performance of large language models (LLMs), raising expectations for their ability to provide accurate, truthful, and reliable information. However, emerging evidence suggests that iterative reasoning may foster belief entrenchment and confirmation bias, rather than enhancing truth-seeking behavior. In this study, we propose a systematic evaluation framework for belief entrenchment in LLM reasoning by leveraging the Martingale property from Bayesian statistics. This property implies that, under rational belief updating, the expected value of future beliefs should remain equal to the current belief, i.e., belief updates are unpredictable from the current belief. We propose the unsupervised, regression-based Martingale Score to measure violations of this property, which signal deviation from the Bayesian ability of updating on new evidence. In open-ended problem domains including event forecasting, value-laden questions, and academic paper review, we find such violations to be widespread across models and setups, where the current belief positively predicts future belief updates, a phenomenon which we term belief entrenchment. We identify the models, reasoning techniques, and domains more prone to belief entrenchment. Finally, we validate the Martingale Score by showing that it predicts ground-truth accuracy on problem domains where ground truth labels are available. This indicates that, while designed as an unsupervised metric that operates even in domains without access to ground truth, the Martingale Score is a useful proxy of the truth-seeking ability of a reasoning process.

</details>


### [89] [Invasive Context Engineering to Control Large Language Models](https://arxiv.org/abs/2512.03001)
*Thomas Rivasseau*

Main category: cs.AI

TL;DR: 提出侵入式上下文工程，通过插入控制语句来增强LLM在长上下文场景下的安全性，防止越狱和恶意行为


<details>
  <summary>Details</summary>
Motivation: 当前LLM安全方法（偏好训练、提示工程、输入输出过滤）在长上下文场景下效果有限，越狱概率随上下文长度增加而增加，需要更鲁棒的LLM安全保证

Method: 提出侵入式上下文工程，在LLM上下文中插入控制语句，该方法可推广到思维链过程以防止策略性行为，不依赖LLM训练，避免长上下文场景下的数据短缺问题

Result: 该方法部分解决了长上下文场景下的LLM安全问题，提供了一种不依赖训练的轻量级安全增强方案

Conclusion: 侵入式上下文工程是增强LLM在长上下文场景下安全性的有效方法，可防止越狱和恶意行为，且避免了训练数据短缺的问题

Abstract: Current research on operator control of Large Language Models improves model robustness against adversarial attacks and misbehavior by training on preference examples, prompting, and input/output filtering. Despite good results, LLMs remain susceptible to abuse, and jailbreak probability increases with context length. There is a need for robust LLM security guarantees in long-context situations. We propose control sentences inserted into the LLM context as invasive context engineering to partially solve the problem. We suggest this technique can be generalized to the Chain-of-Thought process to prevent scheming. Invasive Context Engineering does not rely on LLM training, avoiding data shortage pitfalls which arise in training models for long context situations.

</details>


### [90] [From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?](https://arxiv.org/abs/2512.03005)
*Dawei Li,Abdullah Alnaibari,Arslan Bisharat,Manny Sandoval,Deborah Hall,Yasin Silva,Huan Liu*

Main category: cs.AI

TL;DR: LLMs can be used as online conflict mediators, not just moderators, through judgment and steering tasks, with API-based models outperforming open-source ones.


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地中介在线交流，它们促进同理心和建设性对话的潜力成为负责任AI研究的重要前沿。研究探索LLMs是否能作为理解并缓解在线冲突的调解者，而不仅仅是检测有害内容的仲裁者。

Method: 将调解分解为两个子任务：判断（评估对话的公平性和情感动态）和引导（生成具有同理心、缓解冲突的信息引导参与者解决问题）。构建大型Reddit数据集，并提出结合原则评分、用户模拟和人工比较的多阶段评估流程。

Result: 实验显示，API-based模型在推理和干预对齐方面优于开源模型。研究同时揭示了当前LLMs作为在线社交调解新兴代理的潜力和局限性。

Conclusion: LLMs在在线社交调解方面展现出前景，但当前模型仍存在局限性，API-based模型表现更佳，为负责任AI应用提供了新方向。

Abstract: The rapid advancement of large language models (LLMs) has opened new possibilities for AI for good applications. As LLMs increasingly mediate online communication, their potential to foster empathy and constructive dialogue becomes an important frontier for responsible AI research. This work explores whether LLMs can serve not only as moderators that detect harmful content, but as mediators capable of understanding and de-escalating online conflicts. Our framework decomposes mediation into two subtasks: judgment, where an LLM evaluates the fairness and emotional dynamics of a conversation, and steering, where it generates empathetic, de-escalatory messages to guide participants toward resolution. To assess mediation quality, we construct a large Reddit-based dataset and propose a multi-stage evaluation pipeline combining principle-based scoring, user simulation, and human comparison. Experiments show that API-based models outperform open-source counterparts in both reasoning and intervention alignment when doing mediation. Our findings highlight both the promise and limitations of current LLMs as emerging agents for online social mediation.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [91] [Global AI Governance Overview: Understanding Regulatory Requirements Across Global Jurisdictions](https://arxiv.org/abs/2512.02046)
*Mariia Kyrychenko,Mykyta Mudryi,Markiyan Chaklosh*

Main category: cs.CY

TL;DR: 论文提出多层过滤管道，将版权保护从训练后检测转向训练前预防，以解决AI训练数据中的版权侵权问题。


<details>
  <summary>Details</summary>
Motivation: 通用AI模型的快速发展加剧了训练数据版权侵权的担忧，现有监管框架主要是被动反应而非主动预防，存在执行机制上的关键缺口，威胁创作者权利和AI发展的可持续性。

Method: 分析主要司法管辖区（欧盟、美国、亚太地区）的AI训练数据治理监管格局，通过案例研究识别训练前数据过滤的关键缺口，提出结合访问控制、内容验证、机器学习分类器和持续数据库交叉引用的多层过滤管道。

Result: 识别出两个根本挑战：训练前许可收集和内容过滤面临大规模版权管理的不可能性，以及验证机制缺乏确认过滤是否防止侵权的工具。现有解决方案如透明度工具、感知哈希和访问控制机制只能解决问题的特定方面。

Conclusion: 提出的多层过滤管道为保护创作者权利同时促进AI持续创新提供了路径，将版权保护从训练后检测转向训练前预防。

Abstract: The rapid advancement of general-purpose AI models has increased concerns about copyright infringement in training data, yet current regulatory frameworks remain predominantly reactive rather than proactive. This paper examines the regulatory landscape of AI training data governance in major jurisdictions, including the EU, the United States, and the Asia-Pacific region. It also identifies critical gaps in enforcement mechanisms that threaten both creator rights and the sustainability of AI development. Through analysis of major cases we identified critical gaps in pre-training data filtering. Existing solutions such as transparency tools, perceptual hashing, and access control mechanisms address only specific aspects of the problem and cannot prevent initial copyright violations. We identify two fundamental challenges: pre-training license collection and content filtering, which faces the impossibility of comprehensive copyright management at scale, and verification mechanisms, which lack tools to confirm filtering prevented infringement. We propose a multilayered filtering pipeline that combines access control, content verification, machine learning classifiers, and continuous database cross-referencing to shift copyright protection from post-training detection to pre-training prevention. This approach offers a pathway toward protecting creator rights while enabling continued AI innovation.

</details>


### [92] [Copyright in AI Pre-Training Data Filtering: Regulatory Landscape and Mitigation Strategies](https://arxiv.org/abs/2512.02047)
*Mariia Kyrychenko,Mykyta Mudryi,Markiyan Chaklosh*

Main category: cs.CY

TL;DR: 论文提出多层级过滤管道，将AI训练数据的版权保护从训练后检测转向训练前预防，以解决版权侵权问题


<details>
  <summary>Details</summary>
Motivation: 通用AI模型的快速发展增加了训练数据版权侵权的担忧，但现有监管框架主要是被动反应而非主动预防。当前解决方案如透明度工具、感知哈希和访问控制机制只能解决特定方面问题，无法防止初始版权侵权

Method: 提出多层级过滤管道，结合访问控制、内容验证、机器学习分类器和持续数据库交叉引用，将版权保护从训练后检测转向训练前预防

Result: 识别了两个根本挑战：训练前许可证收集和内容过滤面临大规模全面版权管理的不可能性，以及验证机制缺乏确认过滤防止侵权的工具

Conclusion: 多层级过滤方法为保护创作者权利同时继续AI创新提供了途径，实现了从被动反应到主动预防的转变

Abstract: The rapid advancement of general-purpose AI models has increased concerns about copyright infringement in training data, yet current regulatory frameworks remain predominantly reactive rather than proactive. This paper examines the regulatory landscape of AI training data governance in major jurisdictions, including the EU, the United States, and the Asia-Pacific region. It also identifies critical gaps in enforcement mechanisms that threaten both creator rights and the sustainability of AI development. Through analysis of major cases we identified critical gaps in pre-training data filtering. Existing solutions such as transparency tools, perceptual hashing, and access control mechanisms address only specific aspects of the problem and cannot prevent initial copyright violations. We identify two fundamental challenges: pre-training license collection and content filtering, which faces the impossibility of comprehensive copyright management at scale, and verification mechanisms, which lack tools to confirm filtering prevented infringement. We propose a multilayered filtering pipeline that combines access control, content verification, machine learning classifiers, and continuous database cross-referencing to shift copyright protection from post-training detection to pre-training prevention. This approach offers a pathway toward protecting creator rights while enabling continued AI innovation.

</details>


### [93] [The Impact of Artificial Intelligence on Enterprise Decision-Making Process](https://arxiv.org/abs/2512.02048)
*Ernest Górka,Dariusz Baran,Gabriela Wojak,Michał Ćwiąkała,Sebastian Zupok,Dariusz Starkowski,Dariusz Reśko,Oliwia Okrasa*

Main category: cs.CY

TL;DR: AI在企业管理决策中主要应用于客户服务、数据预测和决策支持，能提升决策速度和清晰度，但面临员工抵制、高成本和监管模糊等组织障碍，成功关键是对算法机制的理解和变革管理而非编程技能。


<details>
  <summary>Details</summary>
Motivation: 研究AI如何影响企业管理决策，探索AI采用对管理绩效、决策效率和组织障碍的影响，为数字化转型背景下的管理实践提供实证依据。

Method: 对92家跨行业企业进行定量调查，分析AI采用情况及其对管理决策的影响，识别实施障碍和关键能力需求。

Result: 93%的企业使用AI，主要应用于客户服务、数据预测和决策支持；AI提升决策速度和清晰度；主要障碍是员工抵制、高成本和监管模糊；组织因素比技术限制更重要；成功关键是对算法机制的理解和变革管理，编程技能作用较小。

Conclusion: AI与人类判断和沟通实践相结合，在适应性领导和透明流程支持下，能增强组织敏捷性和决策绩效；研究为数字技术重塑管理和人机混合决策环境演进提供了重要见解。

Abstract: Artificial intelligence improves enterprise decision-making by accelerating data analysis, reducing human error, and supporting evidence-based choices. A quantitative survey of 92 companies across multiple industries examines how AI adoption influences managerial performance, decision efficiency, and organizational barriers. Results show that 93 percent of firms use AI, primarily in customer service, data forecasting, and decision support. AI systems increase the speed and clarity of managerial decisions, yet implementation faces challenges. The most frequent barriers include employee resistance, high costs, and regulatory ambiguity. Respondents indicate that organizational factors are more significant than technological limitations. Critical competencies for successful AI use include understanding algorithmic mechanisms and change management. Technical skills such as programming play a smaller role. Employees report difficulties in adapting to AI tools, especially when formulating prompts or accepting system outputs. The study highlights the importance of integrating AI with human judgment and communication practices. When supported by adaptive leadership and transparent processes, AI adoption enhances organizational agility and strengthens decision-making performance. These findings contribute to ongoing research on how digital technologies reshape management and the evolution of hybrid human-machine decision environments.

</details>


### [94] [Misalignment of LLM-Generated Personas with Human Perceptions in Low-Resource Settings](https://arxiv.org/abs/2512.02058)
*Tabia Tanzin Prama,Christopher M. Danforth,Peter Sheridan Dodds*

Main category: cs.CY

TL;DR: LLM生成的社会角色在低资源环境中无法准确反映真实人类体验，在文化特定问题上表现显著差于人类，尤其在共情和可信度方面存在巨大差距，并表现出系统性积极偏见。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM能够生成AI角色，但缺乏深度的情境、文化和情感理解，特别是在低资源环境中的局限性需要量化评估。

Method: 在孟加拉国低资源环境中，使用文化特定问题定量比较人类回答与8个LLM生成社会角色（如男性、女性、穆斯林、政治支持者）的回答。

Result: 人类回答在所有问题上显著优于所有LLM，在角色感知的所有维度上都有优势，特别是在共情和可信度方面差距最大。LLM生成内容表现出系统性积极偏见（Pollyanna原则），平均积极情感得分更高（LLM: 5.99 vs 人类: 5.60）。

Conclusion: LLM角色无法准确反映低资源环境中真实人类的体验，在社会科学研究中使用前必须用真实世界人类数据进行验证以确保一致性和可靠性。

Abstract: Recent advances enable Large Language Models (LLMs) to generate AI personas, yet their lack of deep contextual, cultural, and emotional understanding poses a significant limitation. This study quantitatively compared human responses with those of eight LLM-generated social personas (e.g., Male, Female, Muslim, Political Supporter) within a low-resource environment like Bangladesh, using culturally specific questions. Results show human responses significantly outperform all LLMs in answering questions, and across all matrices of persona perception, with particularly large gaps in empathy and credibility. Furthermore, LLM-generated content exhibited a systematic bias along the lines of the ``Pollyanna Principle'', scoring measurably higher in positive sentiment ($Φ_{avg} = 5.99$ for LLMs vs. $5.60$ for Humans). These findings suggest that LLM personas do not accurately reflect the authentic experience of real people in resource-scarce environments. It is essential to validate LLM personas against real-world human data to ensure their alignment and reliability before deploying them in social science research.

</details>


### [95] [Towards Modeling Road Access Deprivation in Sub-Saharan Africa Based on a New Accessibility Metric and Road Quality](https://arxiv.org/abs/2512.02190)
*Sebastian Hafner,Qunshan Zhao,Bunmi Alugbin,Kehinde Baruwa,Caleb Cheruiyot,Sabitu Sa'adu Da'u,Xingyi Du,Peter Elias,Helen Elsey,Ryan Engstrom,Serkan Girgin,Diego F. P. Grajales,Esther Judith,Caroline Kabaria,Monika Kuffer,Oluwatoyin Odulana,Francis C. Onyambu,Adenike Shonowo,Dana R. Thomson,Mingyu Zhu,João Porto de Albuquerque*

Main category: cs.CY

TL;DR: 开发了一个结合建筑连接性和道路质量的模型，用于评估非洲城市道路可达性剥夺水平，在三个城市测试显示大部分区域剥夺程度较低，但高剥夺区域比例差异显著。


<details>
  <summary>Details</summary>
Motivation: 在撒哈拉以南非洲等快速城市化地区，许多城市社区特别是非正规住区缺乏道路连接，需要可扩展的工具来识别这些被隔离的区域以支持城市规划。

Method: 提出了一个道路可达性剥夺模型，结合了新的可达性指标（衡量建筑与道路网络的连接程度）和道路表面类型数据（作为道路质量的代理），将城市区域分为低、中、高三个剥夺水平。

Result: 在三个城市（内罗毕、拉各斯、卡诺）的应用显示，大部分建成区属于低和中度剥夺水平，高剥夺区域比例差异显著（内罗毕11.8%，卡诺27.7%）。模型在识别低剥夺区域时表现良好（F1>0.74），中度剥夺识别准确度中等，高剥夺识别结果变化较大。

Conclusion: 该道路可达性剥夺建模方法展示了作为可扩展、可解释工具的潜力，可用于识别数据稀缺环境下的隔离区域并指导城市规划，但需要进一步改进模型与社区认知的对齐。

Abstract: Access to motorable roads is a critical dimension of urban infrastructure, particularly in rapidly urbanizing regions such as Sub-Saharan Africa. Yet, many urban communities, especially those in informal settlements, remain disconnected from road networks. This study presents a road access deprivation model that combines a new accessibility metric, capturing how well buildings are connected to the road network, with road surface type data as a proxy for road quality. These two components together enable the classification of urban areas into low, medium, or high deprivation levels. The model was applied to Nairobi (Kenya), Lagos (Nigeria), and Kano (Nigeria) using open geospatial datasets. Across all three cities, the majority of built-up areas fall into the low and medium road access deprivation levels, while highly deprived areas are comparatively limited. However, the share of highly deprived areas varies substantially, ranging from only 11.8 % in Nairobi to 27.7 % in Kano. Model evaluation against community-sourced validation data indicates good performance for identifying low deprivation areas (F1 > 0.74), moderate accuracy for medium deprivation in Nairobi and Lagos (F1 > 0.52, lower in Kano), and more variable results for high deprivation (F1 ranging from 0.26 in Kano to 0.69 in Nairobi). Furthermore, analysis of grid cells with multiple validations showed strong agreement among community members, with disagreements occurring mainly between adjacent deprivation levels. Finally, we discussed two types of sources for disagreement with community validations: (1) misalignment between the conceptual model and community perceptions, and (2) the operationalization of the conceptual model. In summary, our road access deprivation modeling approach demonstrates promise as a scalable, interpretable tool for identifying disconnected areas and informing urban planning in data-scarce contexts.

</details>


### [96] [The MEVIR Framework: A Virtue-Informed Moral-Epistemic Model of Human Trust Decisions](https://arxiv.org/abs/2512.02310)
*Daniel Schwabe*

Main category: cs.CY

TL;DR: MEVIR框架整合了理性推理、美德认识论和道德基础理论，解释人类信任决策的形成机制，揭示政治极化源于道德先验和认识论权威的深层分歧。


<details>
  <summary>Details</summary>
Motivation: 传统理性代理人模型无法捕捉人类信任形成的复杂性，需要整合理性、品格和前理性直觉的综合性描述模型，以应对21世纪信息环境中的复杂性、极化和错误信息挑战。

Method: 提出MEVIR框架，整合三个理论视角：(1)证据收集和推理链的程序模型；(2)Zagzebski美德认识论，描述智力品格驱动过程；(3)扩展道德基础理论(EMFT)，解释快速自动的道德直觉。引入本体论概念（真理承载者、真理制造者、本体论解包），并通过疫苗接种授权和气候政策案例研究进行验证。

Result: MEVIR框架将认知偏见重新定义为应用认识论美德的系统性失败，展示不同道德基础如何导致个体构建分离但内部一致的"信任格"。政治极化反映了道德先验、认识论权威和评估启发式的深层分歧。框架为决策支持系统提供基础，帮助增强元认知能力。

Conclusion: MEVIR框架为理解人类信任决策提供了全面描述模型，揭示了分歧的深层本体论根源，并为应对宣传、心理操作和回音室效应提供了分析工具，同时承认局限性并建议未来进行纵向研究。

Abstract: The 21st-century information landscape presents an unprecedented challenge: how do individuals make sound trust decisions amid complexity, polarization, and misinformation? Traditional rational-agent models fail to capture human trust formation, which involves a complex synthesis of reason, character, and pre-rational intuition. This report introduces the Moral-Epistemic VIRtue informed (MEVIR) framework, a comprehensive descriptive model integrating three theoretical perspectives: (1) a procedural model describing evidence-gathering and reasoning chains; (2) Linda Zagzebski's virtue epistemology, characterizing intellectual disposition and character-driven processes; and (3) Extended Moral Foundations Theory (EMFT), explaining rapid, automatic moral intuitions that anchor reasoning. Central to the framework are ontological concepts - Truth Bearers, Truth Makers, and Ontological Unpacking-revealing that disagreements often stem from fundamental differences in what counts as admissible reality. MEVIR reframes cognitive biases as systematic failures in applying epistemic virtues and demonstrates how different moral foundations lead agents to construct separate, internally coherent "trust lattices". Through case studies on vaccination mandates and climate policy, the framework shows that political polarization represents deeper divergence in moral priors, epistemic authorities, and evaluative heuristics. The report analyzes how propaganda, psychological operations, and echo chambers exploit the MEVIR process. The framework provides foundation for a Decision Support System to augment metacognition, helping individuals identify biases and practice epistemic virtues. The report concludes by acknowledging limitations and proposing longitudinal studies for future research.

</details>


### [97] [ACM COMPUTE 2025 Best Practices Track Proceedings](https://arxiv.org/abs/2512.02349)
*Ritwik Murali,Mrityunjay Kumar*

Main category: cs.CY

TL;DR: COMPUTE 2025最佳实践论文集，收录印度计算教育领域的最佳实践经验报告，涵盖课堂活动、作业设计、教学方法、AI评估和跨学科教学等主题


<details>
  <summary>Details</summary>
Motivation: 通过ACM印度和iSIGCSE支持的COMPUTE会议，为印度计算教育工作者提供平台，分享最佳实践，提升全国计算教育质量

Method: 会议设立最佳实践专题，征集五个类别的经验报告：新颖课堂活动、创意作业设计、多样化教学方法、AI相关评估设计、跨学科CS教学

Result: 从提交的报告中筛选出优秀论文收录于会议论文集，并在会议期间组织两个最佳实践专题会议进行展示和交流

Conclusion: COMPUTE 2025最佳实践论文集为印度计算教育工作者提供了宝贵的经验分享平台，促进了教学创新和质量提升

Abstract: COMPUTE is an annual Indian conference supported by ACM India and iSIGCSE. The focus of COMPUTE is to improve the quality of computing education in the country by providing a platform for academicians and researchers to interact and share best practices in teaching, learning, and education in general.
  The Best Practices Track of COMPUTE 2025 invited Computer Science Educators across the country to submit an experience report for the best practices under multiple categories: 1) Novel classroom activities, 2) Imaginative assignments that promote creativity and problem-solving, 3) Diverse pedagogical approaches (e.g., flipped classrooms, peer teaching, project-based learning), 4) Designing AI-resistant or AI-integrated assessment questions, and 5) Teaching CS to students from other disciplines (e.g., business, humanities, engineering).
  These proceedings contain papers selected from these submissions for presentation at the conference, as well as a report (written by the editors) from the two best practices sessions where these were presented.

</details>


### [98] [A Human-centric Framework for Debating the Ethics of AI Consciousness Under Uncertainty](https://arxiv.org/abs/2512.02544)
*Zhou Ziheng,Haiqiang Dai,Bin Ling,Ying Nian Wu,Demetri Terzopoulos*

Main category: cs.CY

TL;DR: 本文提出一个三层伦理框架，基于哲学不确定性处理AI意识问题，强调人类中心主义、无意识推定和风险审慎原则。


<details>
  <summary>Details</summary>
Motivation: 当前AI伦理框架存在三个主要问题：1）依赖有争议的功能主义假设；2）过度关注推测性的AI福利而忽视具体人类利益；3）缺乏连贯的理论基础。随着AI系统日益复杂，机器意识及其伦理影响已成为主流学术辩论话题，需要更坚实的伦理框架。

Method: 提出结构化三层框架：1）基础层：确立关于AI意识的五个事实性判定，并以人类中心主义作为元伦理立场；2）操作层：推导出三个操作原则：无意识推定（举证责任在意识主张方）、风险审慎（在不确定性下优先人类福利）、透明推理（支持系统评估和适应）；3）应用层：通过透明逻辑过程推导出紧迫伦理问题的默认立场。

Result: 该框架平衡了哲学严谨性与实践指导性，区分了意识与拟人化，为负责任的发展创造了路径，提供了以人类为中心的伦理基础。每个应用层立场都可以明确追溯到基础层承诺。

Conclusion: 该人类中心主义框架为应对AI意识伦理挑战提供了系统方法，在科学理解进步的同时保持伦理指导的连贯性，强调在不确定性下优先保护人类利益。

Abstract: As AI systems become increasingly sophisticated, questions about machine consciousness and its ethical implications have moved from fringe speculation to mainstream academic debate. Current ethical frameworks in this domain often implicitly rely on contested functionalist assumptions, prioritize speculative AI welfare over concrete human interests, and lack coherent theoretical foundations. We address these limitations through a structured three-level framework grounded in philosophical uncertainty. At the foundational level, we establish five factual determinations about AI consciousness alongside human-centralism as our meta-ethical stance. These foundations logically entail three operational principles: presumption of no consciousness (placing the burden of proof on consciousness claims), risk prudence (prioritizing human welfare under uncertainty), and transparent reasoning (enabling systematic evaluation and adaptation). At the application level, the third component of our framework, we derive default positions on pressing ethical questions through a transparent logical process where each position can be explicitly traced back to our foundational commitments. Our approach balances philosophical rigor with practical guidance, distinguishes consciousness from anthropomorphism, and creates pathways for responsible evolution as scientific understanding advances, providing a human-centric foundation for navigating these profound ethical challenges.

</details>


### [99] [AI-Driven Document Redaction in UK Public Authorities: Implementation Gaps, Regulatory Challenges, and the Human Oversight Imperative](https://arxiv.org/abs/2512.02774)
*Yijun Chen*

Main category: cs.CY

TL;DR: 该研究通过FOI请求调查英国公共机构AI驱动文件编辑的实施情况，发现AI采用率极低（仅1个机构使用），50%机构缺乏正式编辑政策，存在记录保存、标准化指南和人员培训三大障碍。


<details>
  <summary>Details</summary>
Motivation: 传统手动编辑方法难以平衡日益增长的透明度要求与数据保护需求，而AI技术虽提供潜在解决方案，但其在公共部门的实际实施情况尚未得到充分研究。

Method: 通过向英国公共机构发送信息自由请求，收集了来自医疗、政府和高等教育等领域的44个机构的回复数据。

Result: AI采用率极低（仅1个机构使用AI工具），50%机构报告"未持有信息"表明缺乏正式编辑政策，普遍存在员工培训不足，识别出三大障碍：记录保存实践差、缺乏标准化编辑指南、人类监督的专业培训不足。

Conclusion: 需要采取社会技术方法平衡技术自动化与有意义的人类专业知识，这是对英国公共机构AI编辑实践的首次实证评估，为政策制定者应对透明度义务、数据保护要求和新兴AI技术之间的复杂关系提供证据支持。

Abstract: Document redaction in public authorities faces critical challenges as traditional manual approaches struggle to balance growing transparency demands with increasingly stringent data protection requirements. This study investigates the implementation of AI-driven document redaction within UK public authorities through Freedom of Information (FOI) requests. While AI technologies offer potential solutions to redaction challenges, their actual implementation within public sector organizations remains underexplored. Based on responses from 44 public authorities across healthcare, government, and higher education sectors, this study reveals significant gaps between technological possibilities and organizational realities. Findings show highly limited AI adoption (only one authority reported using AI tools), widespread absence of formal redaction policies (50 percent reported "information not held"), and deficiencies in staff training. The study identifies three key barriers to effective AI implementation: poor record-keeping practices, lack of standardized redaction guidelines, and insufficient specialized training for human oversight. These findings highlight the need for a socio-technical approach that balances technological automation with meaningful human expertise. This research provides the first empirical assessment of AI redaction practices in UK public authorities and contributes evidence to support policymakers navigating the complex interplay between transparency obligations, data protection requirements, and emerging AI technologies in public administration.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [100] [Layered Division and Global Allocation for Community Detection in Multilayer Network](https://arxiv.org/abs/2512.02334)
*Fanghao Hu,Junhong Lin,Zhi Cai,Bang Wang*

Main category: cs.SI

TL;DR: 提出LDGA新范式：先分层划分再全局分配，通过多头Transformer编码层结构，结合社区原型编码，实现多层网络社区检测


<details>
  <summary>Details</summary>
Motivation: 现有基于神经网络的CDMN方法采用表示融合和全局划分范式，即使使用对比或注意力融合机制，融合后的全局表示仍缺乏捕捉每层结构细微差别的判别能力

Method: 提出分层划分与全局分配（LDGA）范式：1）使用多头Transformer作为主干表示编码器，每个头编码每层网络结构特征；2）结合社区潜在编码器捕捉每层社区原型；3）共享评分器生成分层软分配；4）全局分配为每个节点分配跨层置信度最高的社区标签

Result: 在合成和真实世界多层网络上进行广泛实验，LDGA在检测到的社区模块度方面优于现有最先进方法

Conclusion: LDGA通过先分层划分再全局分配的新范式，有效解决了现有方法在捕捉多层网络结构细微差别方面的不足，实现了更好的社区检测性能

Abstract: Community detection in multilayer networks (CDMN) is to divide a set of entities with multiple relation types into a few disjoint subsets, which has many applications in the Web, transportation, and sociology systems. Recent neural network-based solutions to the CDMN task adopt a kind of representation fusion and global division paradigm: Each node is first learned a kind of layer-wise representations which are then fused for global community division. However, even with contrastive or attentive fusion mechanisms, the fused global representations often lack the discriminative power to capture structural nuances unique to each layer. In this paper, we propose a novel paradigm for the CDMN task: Layered Division and Global Allocation (LDGA). The core idea is to first perform layer-wise group division, based on which global community allocation is next performed. Concretely, LDGA employs a multi-head Transformer as the backbone representation encoder, where each head is for encoding node structural characteristics in each network layer. We integrate the Transformer with a community-latent encoder to capture community prototypes in each layer. A shared scorer performs layered division by generating layer-wise soft assignments, while global allocation assigns each node the community label with highest confidence across all layers to form the final consensus partition. We design a loss function that couples differentiable multilayer modularity with a cluster balance regularizer to train our model in an unsupervised manner. Extensive experiments on synthetic and real-world multilayer networks demonstrate that our LDGA outperforms the state-of-the-art competitors in terms of higher detected community modularities. Our code with parameter settings and datasets are available at https://anonymous.4open.science/r/LDGA-552B/.

</details>


### [101] [UniCom: Towards a Unified and Cohesiveness-aware Framework for Community Search and Detection](https://arxiv.org/abs/2512.02460)
*Yifan Zhu,Hanchen Wang,Wenjie Zhang,Alexander Zhou,Ying Zhang*

Main category: cs.SI

TL;DR: UniCom是一个统一框架，通过跨域知识迁移同时解决社区搜索和检测任务，无需针对特定任务或数据集重新训练，在监督有限或无监督情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法将社区搜索（为给定查询定位最佳社区）和社区检测（对整个图进行分区）视为独立问题，需要针对特定任务和数据集重新训练，限制了模型的适用性和泛化能力。这些方法严重依赖目标数据集信息，在监督有限或不可用时性能不佳。

Method: 提出UniCom统一框架，包含两个核心组件：1）通用图学习（UGL）骨干网络，通过全面预训练从多个源域提取可迁移的语义和拓扑知识；2）域感知专业化（DAS）过程，通过轻量级提示范式动态适应未见过的图或任务，无需重新训练。

Result: 在16个基准数据集和22个基线的广泛实验中，UniCon在所有任务中一致优于所有最先进的基线方法，特别是在监督稀缺或无监督的设置下，同时保持了运行时效率。

Conclusion: UniCom通过跨域知识迁移的统一框架成功解决了社区搜索和检测任务，消除了针对特定任务重新训练的需求，在监督有限的情况下表现出色，具有良好的泛化能力和效率。

Abstract: Searching and detecting communities in real-world graphs underpins a wide range of applications. Despite the success achieved, current learning-based solutions regard community search, i.e., locating the best community for a given query, and community detection, i.e., partitioning the whole graph, as separate problems, necessitating task- and dataset-specific retraining. Such a strategy limits the applicability and generalization ability of the existing models. Additionally, these methods rely heavily on information from the target dataset, leading to suboptimal performance when supervision is limited or unavailable. To mitigate this limitation, we propose UniCom, a unified framework to solve both community search and detection tasks through knowledge transfer across multiple domains, thus alleviating the limitations of single-dataset learning. UniCom centers on a Domain-aware Specialization (DAS) procedure that adapts on the fly to unseen graphs or tasks, eliminating costly retraining while maintaining framework compactness with a lightweight prompt-based paradigm. This is empowered by a Universal Graph Learning (UGL) backbone, which distills transferable semantic and topological knowledge from multiple source domains via comprehensive pre-training. Both DAS and UGL are informed by local neighborhood signals and cohesive subgraph structures, providing consistent guidance throughout the framework. Extensive experiments on both tasks across 16 benchmark datasets and 22 baselines have been conducted to ensure a comprehensive and fair evaluation. UniCom consistently outperforms all state-of-the-art baselines across all tasks under settings with scarce or no supervision, while maintaining runtime efficiency.

</details>


### [102] [Identifying preferred routes of sharing information on social networks](https://arxiv.org/abs/2512.02483)
*Rozhin Mohammadikian,Parsa Bigdeli,Behrouz Askari,G. Reza Jafari*

Main category: cs.SI

TL;DR: 研究通过分析Twitter真实标签数据，发现信息在社交网络中的传播并非随机，而是遵循特定模式，提出了全局和局部优先选择模型来解释信息传播路径。


<details>
  <summary>Details</summary>
Motivation: 随着社交网络平台的兴起，信息传播变得更快更广。本研究旨在探究社交网络中的信息传播是随机的还是遵循可识别的结构模式。

Method: 使用真实世界的标签数据，提出并检验了两种优先选择模型：全局优先选择模型和局部优先选择模型，分析信息在网络中的传播路径。

Result: 研究发现标签传播不是随机的，而是遵循特定模式。信息传播与两种优先选择模型一致，新信息倾向于沿着与先前新闻相同的路径传播，具体路径因内容类型而异。

Conclusion: 通过Twitter政治标签传播的验证，确认了信息传播路径的存在，这些路径与两种优先选择模型预测的模式相符，表明社交网络中的信息传播具有结构性而非随机性。

Abstract: The spread of information has become faster and wider than ever with the advent of social network platforms. The question raised in this study is whether information dissemination in social networks is random or follows a discernible structure. Our results from real-world hashtag data suggest that the spread of hashtags is not random and follows specific patterns. This study proposes two preferential models to explore how news spreads on social media. Specifically, we examine global and local preferential selection models and demonstrate that information dissemination aligns with these patterns. According to these two models, information flows are distributed through specific paths on networks. This suggests that new information tends to propagate along the same paths as previous news, with the specific pathways varying depending on the type of content. Finally, an examination of the propagation of political hashtags on Twitter confirms the existence of these paths that also emerge from the two preferential models.

</details>


### [103] [Embedding networks with the random walk first return time distribution](https://arxiv.org/abs/2512.02694)
*Vedanta Thapar,Renaud Lambiotte,George T. Cantwell*

Main category: cs.SI

TL;DR: 提出首次返回时间分布（FRTD）作为可解释且数学基础扎实的节点嵌入方法，通过概率质量函数表示节点，使用离散分布度量定义节点间距离。


<details>
  <summary>Details</summary>
Motivation: 需要一种既具有数学理论基础又易于解释的节点嵌入方法，能够捕捉网络结构信息并优于传统手工设计的图度量。

Method: 使用随机游走的首次返回时间分布作为节点嵌入，为每个节点分配概率质量函数，通过离散分布的标准度量（如Wasserstein距离、Jensen-Shannon散度等）计算节点间距离。

Result: FRTD比特征值谱包含更多信息但不足以完全识别图结构；在节点对齐任务中优于手工设计的图度量；匹配目标FRTD的随机网络能保留其他重要特征。

Conclusion: FRTD是一种简单且数学原理清晰的复杂网络嵌入方法，在可解释性和性能之间取得了良好平衡。

Abstract: We propose the first return time distribution (FRTD) of a random walk as an interpretable and mathematically grounded node embedding. The FRTD assigns a probability mass function to each node, allowing us to define a distance between any pair of nodes using standard metrics for discrete distributions. We present several arguments to motivate the FRTD embedding. First, we show that FRTDs are strictly more informative than eigenvalue spectra, yet insufficient for complete graph identification, thus placing FRTD equivalence between cospectrality and isomorphism. Second, we argue that FRTD equivalence between nodes captures structural similarity. Third, we empirically demonstrate that the FRTD embedding outperforms manually designed graph metrics in network alignment tasks. Finally, we show that random networks that approximately match the FRTD of a desired target also preserve other salient features. Together these results demonstrate the FRTD as a simple and mathematically principled embedding for complex networks.

</details>
