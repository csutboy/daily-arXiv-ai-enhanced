{"id": "2601.10718", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10718", "abs": "https://arxiv.org/abs/2601.10718", "authors": ["Junyu Liu", "Siwen Yang", "Dexiu Ma", "Qian Niu", "Zequn Zhang", "Momoko Nagai-Tanima", "Tomoki Aoyama"], "title": "Japanese AI Agent System on Human Papillomavirus Vaccination: System Design", "comment": null, "summary": "Human papillomavirus (HPV) vaccine hesitancy poses significant public health challenges, particularly in Japan where proactive vaccination recommendations were suspended from 2013 to 2021. The resulting information gap is exacerbated by misinformation on social media, and traditional ways cannot simultaneously address individual queries while monitoring population-level discourse. This study aimed to develop a dual-purpose AI agent system that provides verified HPV vaccine information through a conversational interface while generating analytical reports for medical institutions based on user interactions and social media. We implemented a system comprising: a vector database integrating academic papers, government sources, news media, and social media; a Retrieval-Augmented Generation chatbot using ReAct agent architecture with multi-tool orchestration across five knowledge sources; and an automated report generation system with modules for news analysis, research synthesis, social media sentiment analysis, and user interaction pattern identification. Performance was assessed using a 0-5 scoring scale. For single-turn evaluation, the chatbot achieved mean scores of 4.83 for relevance, 4.89 for routing, 4.50 for reference quality, 4.90 for correctness, and 4.88 for professional identity (overall 4.80). Multi-turn evaluation yielded higher scores: context retention 4.94, topic coherence 5.00, and overall 4.98. The report generation system achieved completeness 4.00-5.00, correctness 4.00-5.00, and helpfulness 3.67-5.00, with reference validity 5.00 across all periods. This study demonstrates the feasibility of an integrated AI agent system for bidirectional HPV vaccine communication. The architecture enables verified information delivery with source attribution while providing systematic public discourse analysis, with a transferable framework for adaptation to other medical contexts."}
{"id": "2601.10719", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10719", "abs": "https://arxiv.org/abs/2601.10719", "authors": ["Gerard Yeo", "Svetlana Churina", "Kokil Jaidka"], "title": "Do You Trust Me? Cognitive-Affective Signatures of Trustworthiness in Large Language Models", "comment": null, "summary": "Perceived trustworthiness underpins how users navigate online information, yet it remains unclear whether large language models (LLMs),increasingly embedded in search, recommendation, and conversational systems, represent this construct in psychologically coherent ways. We analyze how instruction-tuned LLMs (Llama 3.1 8B, Qwen 2.5 7B, Mistral 7B) encode perceived trustworthiness in web-like narratives using the PEACE-Reviews dataset annotated for cognitive appraisals, emotions, and behavioral intentions. Across models, systematic layer- and head-level activation differences distinguish high- from low-trust texts, revealing that trust cues are implicitly encoded during pretraining. Probing analyses show linearly de-codable trust signals and fine-tuning effects that refine rather than restructure these representations. Strongest associations emerge with appraisals of fairness, certainty, and accountability-self -- dimensions central to human trust formation online. These findings demonstrate that modern LLMs internalize psychologically grounded trust signals without explicit supervision, offering a representational foundation for designing credible, transparent, and trust-worthy AI systems in the web ecosystem. Code and appendix are available at: https://github.com/GerardYeo/TrustworthinessLLM."}
{"id": "2601.10726", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10726", "abs": "https://arxiv.org/abs/2601.10726", "authors": ["Ross Chu", "Yuting Huang"], "title": "Building AI Agents to Improve Job Referral Requests to Strangers", "comment": null, "summary": "This paper develops AI agents that help job seekers write effective requests for job referrals in a professional online community. The basic workflow consists of an improver agent that rewrites the referral request and an evaluator agent that measures the quality of revisions using a model trained to predict the probability of receiving referrals from other users. Revisions suggested by the LLM (large language model) increase predicted success rates for weaker requests while reducing them for stronger requests. Enhancing the LLM with Retrieval-Augmented Generation (RAG) prevents edits that worsen stronger requests while it amplifies improvements for weaker requests. Overall, using LLM revisions with RAG increases the predicted success rate for weaker requests by 14\\% without degrading performance on stronger requests. Although improvements in model-predicted success do not guarantee more referrals in the real world, they provide low-cost signals for promising features before running higher-stakes experiments on real users."}
{"id": "2601.10729", "categories": ["cs.AI", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.10729", "abs": "https://arxiv.org/abs/2601.10729", "authors": ["Xinyue Ma", "Heelim Hong", "Taegeon Um", "Jongseop Lee", "Seoyeong Choy", "Woo-Yeon Lee", "Myeongjae Jeon"], "title": "ORBITFLOW: SLO-Aware Long-Context LLM Serving with Fine-Grained KV Cache Reconfiguration", "comment": "Accepted at the 52nd International Conference on Very Large Data Bases (VLDB 2026). Xinyue Ma and Heelim Hong contributed equally (co-first authors)", "summary": "Serving long-context LLMs is challenging because request lengths and batch composition vary during token generation, causing the memory footprint to fluctuate significantly at runtime. Offloading KV caches to host memory limits effective memory usage, but existing static and predetermined offloading strategies cannot adapt to the rapidly shifting memory demands of long-context serving. This often leads to excessive CPU-to-GPU KV transfers that translate into latency spikes and frequent SLO violations. To address these challenges, we introduce ORBITFLOW, a fine-grained and adaptive KV cache management system that meets latency SLOs in long-context LLM serving. ORBITFLOW employs a lightweight ILP solver to decide which layers' KV caches to retain on the GPU for each request, within memory capacity constraints. It continuously refines KV placements based on runtime feedback when the active plan becomes suboptimal during token generation. Under heavy load, ORBITFLOW invokes a fallback mechanism to temporarily defer in-flight requests with large memory footprints, preserving overall SLO attainment. Our experiments demonstrate that ORBITFLOW improves SLO attainment for TPOT and TBT by up to 66% and 48%, respectively, while reducing the 95th percentile latency by 38% and achieving up to 3.3x higher throughput compared to existing offloading methods."}
{"id": "2601.10851", "categories": ["econ.EM", "q-fin.PM", "q-fin.PR", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2601.10851", "abs": "https://arxiv.org/abs/2601.10851", "authors": ["Haibo Wang"], "title": "Event-Driven Market Co-Movement Dynamics in Critical Mineral Equities: An Empirical Framework Using Change Point Detection and Cross-Sectional Analysis", "comment": "42 pages", "summary": "This study examines market behavior in critical mineral investments using a novel analytical framework that combines change-point detection (PELT algorithm) with cross-sectional analysis. This research analyzes ESG-ranked critical mineral ETFs from March 31, 2014, to April 19, 2024, using the S&P 500 as a benchmark to evaluate market co-movements. The findings demonstrate that different critical mineral investments experienced change points at distinct times, but three major dates, July 23, 2015; March 17, 2020; and December 1, 2020, were common and aligned with global events such as the oil market shock, the COVID-19 pandemic, and later market adjustments. Herding behavior among investors increased after these shocks, following the 2015 and 2020 crises, but shifted to anti-herding after positive vaccine news in late 2020 and after the Russian invasion of Ukraine in 2022. The sensitivity analysis shows that investor coordination is strongest during market downturns but exhibits greater variation during stable periods or after major developments, with these dynamics sensitive to the length of the observation period. Additionally, anti-herding became more apparent during crises, suggesting investors reacted to specific risks rather than moving in lockstep, especially in response to geopolitical shocks."}
{"id": "2601.11115", "categories": ["cs.SI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11115", "abs": "https://arxiv.org/abs/2601.11115", "authors": ["Theofanis P. Raptis", "Chiara Boldrini", "Marco Conti", "Andrea Passarella"], "title": "Sparing User Time with a Socially-Aware Independent Metaverse Avatar", "comment": "Supported by PNNR projects SoBigDatait (IR0000013), FAIR (PE00000013), ICSC (CN00000013)", "summary": "The Metaverse is redefining digital interactions by merging physical, virtual, and social dimensions, yet its effects on social networking remain largely unexplored. This work examines the role of independent avatars (autonomous digital entities capable of managing social interactions on behalf of users), to optimize social time allocation and reshape Metaverse-based Online Social Networks. We propose a novel computational model that integrates a quantitative and realistic representation of user social life, grounded in evolutionary anthropology, with a framework for avatar-mediated interactions. Our model quantifies the effectiveness of a partial replacement of in-person interactions with independent avatar interactions. Additionally, it accounts for social conflicts and specific socialization constraints. We leverage our model to explore the benefits and trade-offs of an avatar-augmented social life in the Metaverse. Since the exact problem formulation leads to an NP-hard optimization problem when incorporating avatars into the social network, we tackle this challenge by introducing a heuristic solution. Through simulations, we compare avatar-mediated and non-avatar-mediated social networking, demonstrating the potential of independent avatars to enhance social connectivity and efficiency. Our findings provide a foundation for optimizing Metaverse-based social interactions, as well as useful insights for future digital social network design."}
{"id": "2601.10919", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2601.10919", "abs": "https://arxiv.org/abs/2601.10919", "authors": ["Michael T. Gorczyca"], "title": "A Note on Harmonic Underspecification in Log-Normal Trigonometric Regression", "comment": null, "summary": "Analysis of biological rhythm data often involves performing least squares trigonometric regression, which models the oscillations of a response over time as a sum of sinusoidal components. When the response is not normally distributed, an investigator will either transform the response before applying least squares trigonometric regression or extend trigonometric regression to a generalized linear model (GLM) framework. In this note, we compare these two approaches when the number of oscillation harmonics is underspecified. We assume data are sampled under an equispaced experimental design and that a log link function would be appropriate for a GLM. We show that when the response follows a generalized gamma distribution, least squares trigonometric regression with a log-transformed response, or log-normal trigonometric regression, produces unbiased parameter estimates for the oscillation harmonics, even when the number of oscillation harmonics is underspecified. In contrast, GLMs require correct specification to produce unbiased parameter estimates. We apply both methods to cortisol level data and find that only log-normal trigonometric regression produces parameter estimates that are invariant to the number of specified oscillation harmonics. Additionally, when a sufficiently large number of oscillation harmonics is specified, both methods produce identical parameter estimates for the oscillation harmonics."}
{"id": "2601.10852", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.10852", "abs": "https://arxiv.org/abs/2601.10852", "authors": ["Khondokar Fida Hasan", "William Hughes", "Adrita Rahman"], "title": "Gamifying Cyber Governance: A Virtual Escape Room to Transform Cybersecurity Policy Education", "comment": "10 pages", "summary": "Serious games are gaining popularity as effective teaching and learning tools, providing engaging, interactive, and practical experiences for students. Gamified learning experiences, such as virtual escape rooms, have emerged as powerful tools in bridging theory and practice, fostering deeper understanding and engagement among students. This paper presents the design, implementation, and evaluation of a virtual escape room tailored specifically for cybersecurity governance and policy education. Developed as a 3D immersive environment, the escape room simulates a virtual company scenario to facilitate risk-informed cyber policy development. It consists of three interactive zones, each offering distinct sets of scenario-based problems that target specific educational objectives. Through these zones, students analyze cybersecurity risks, match security frameworks, and draft appropriate policies, thereby developing critical thinking, decision-making skills, and practical cybersecurity competencies. The primary contribution of this work lies in its innovative integration of game-based learning and immersive technology to create robust, interactive learning materials that are also resilient to generative AI interventions, thereby maintaining academic integrity. Additionally, the escape room provides students with exposure to real-world cybersecurity scenarios in a virtual office environment that meets industry expectations. Results from a student survey indicated strong positive feedback, highlighting significant improvements in students engagement, practical understanding, and enthusiasm toward cybersecurity governance and policy concepts, underscoring the effectiveness and potential of gamification in cybersecurity education."}
{"id": "2601.10718", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10718", "abs": "https://arxiv.org/abs/2601.10718", "authors": ["Junyu Liu", "Siwen Yang", "Dexiu Ma", "Qian Niu", "Zequn Zhang", "Momoko Nagai-Tanima", "Tomoki Aoyama"], "title": "Japanese AI Agent System on Human Papillomavirus Vaccination: System Design", "comment": null, "summary": "Human papillomavirus (HPV) vaccine hesitancy poses significant public health challenges, particularly in Japan where proactive vaccination recommendations were suspended from 2013 to 2021. The resulting information gap is exacerbated by misinformation on social media, and traditional ways cannot simultaneously address individual queries while monitoring population-level discourse. This study aimed to develop a dual-purpose AI agent system that provides verified HPV vaccine information through a conversational interface while generating analytical reports for medical institutions based on user interactions and social media. We implemented a system comprising: a vector database integrating academic papers, government sources, news media, and social media; a Retrieval-Augmented Generation chatbot using ReAct agent architecture with multi-tool orchestration across five knowledge sources; and an automated report generation system with modules for news analysis, research synthesis, social media sentiment analysis, and user interaction pattern identification. Performance was assessed using a 0-5 scoring scale. For single-turn evaluation, the chatbot achieved mean scores of 4.83 for relevance, 4.89 for routing, 4.50 for reference quality, 4.90 for correctness, and 4.88 for professional identity (overall 4.80). Multi-turn evaluation yielded higher scores: context retention 4.94, topic coherence 5.00, and overall 4.98. The report generation system achieved completeness 4.00-5.00, correctness 4.00-5.00, and helpfulness 3.67-5.00, with reference validity 5.00 across all periods. This study demonstrates the feasibility of an integrated AI agent system for bidirectional HPV vaccine communication. The architecture enables verified information delivery with source attribution while providing systematic public discourse analysis, with a transferable framework for adaptation to other medical contexts."}
{"id": "2601.10738", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10738", "abs": "https://arxiv.org/abs/2601.10738", "authors": ["Percy Jardine"], "title": "CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems", "comment": null, "summary": "Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems."}
{"id": "2601.11195", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.11195", "abs": "https://arxiv.org/abs/2601.11195", "authors": ["Jiaming Huang", "Luca Neri"], "title": "Beyond Validity: SVAR Identification Through the Proxy Zoo", "comment": null, "summary": "This paper develops a framework for robust identification in SVARs when researchers face a zoo of proxy variables. Instead of imposing exact exogeneity, we introduce generalized ranking restrictions (GRR) that bound the relative correlation of each proxy with the target and non-target shocks through a continuous proxy-quality parameter. Combining GRR with standard sign and narrative restrictions, we characterize identified sets for structural impulse responses and show how to partially identify the proxy-quality parameter using the joint information contained in the proxy zoo. We further develop sensitivity and diagnostic tools that allow researchers to assess transparently how empirical conclusions depend on proxy exogeneity assumptions and the composition of the proxy zoo. A simulation study shows that proxies constructed from sign restrictions can induce biased proxy-SVAR estimates, while our approach delivers informative and robust identified sets. An application to U.S.\\ monetary policy illustrates the empirical relevance and computational tractability of the framework."}
{"id": "2601.11128", "categories": ["cs.SI", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11128", "abs": "https://arxiv.org/abs/2601.11128", "authors": ["Aldo Cerulli", "Lorenzo Cima", "Benedetta Tessa", "Serena Tardelli", "Stefano Cresci"], "title": "The Big Ban Theory: A Pre- and Post-Intervention Dataset of Online Content Moderation Actions", "comment": null, "summary": "Online platforms rely on moderation interventions to curb harmful behavior such hate speech, toxicity, and the spread of mis- and disinformation. Yet research on the effects and possible biases of such interventions faces multiple limitations. For example, existing works frequently focus on single or a few interventions, due to the absence of comprehensive datasets. As a result, researchers must typically collect the necessary data for each new study, which limits opportunities for systematic comparisons. To overcome these challenges, we introduce The Big Ban Theory (TBBT), a large dataset of moderation interventions. TBBT covers 25 interventions of varying type, severity, and scope, comprising in total over 339K users and nearly 39M posted messages. For each intervention, we provide standardized metadata and pseudonymized user activity collected three months before and after its enforcement, enabling consistent and comparable analyses of intervention effects. In addition, we provide a descriptive exploratory analysis of the dataset, along with several use cases of how it can support research on content moderation. With this dataset, we aim to support researchers studying the effects of moderation interventions and to promote more systematic, reproducible, and comparable research. TBBT is publicly available at: https://doi.org/10.5281/zenodo.18245670."}
{"id": "2601.10974", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2601.10974", "abs": "https://arxiv.org/abs/2601.10974", "authors": ["Shi Feng", "B. Brian Park", "Andrew Mondschein"], "title": "Analyzing Residential Speeding Using Connected Vehicle Data: A Case Study in Charlottesville, VA Area", "comment": null, "summary": "This study uses connected vehicle data to analyze speeding behavior on residential roads. A scalable pipeline processes trajectory data and supplements missing speed limits to generate summaries at OpenStreetMap's way ID level. The findings reveal a highly skewed distribution of both aggressive and reckless speeding. Based on a case study of Charlottesville, VA's connected vehicle data on residential roads, we found that 38% of segments had at least one instance of aggressive speeding, and 20% had at least one instance of reckless speeding. In addition, night time speeding is 27 times more prevalent than day time, and extreme violations on specific road segments highlight how severe the issue can be. Several segments rank among the top 10 for both aggressive and reckless speedings, indicating that there exist high-risk residential roads. These findings support the need for both spatial and behavioral interventions. The analysis provides a rich foundation for policy and planning, offering a valuable complement to traditional enforcement and planning tools. In conclusion, this framework sets the foundation for future applications in traffic safety analytics, demonstrating the growing potential of telematics data to inform safer, more livable communities."}
{"id": "2601.10970", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.10970", "abs": "https://arxiv.org/abs/2601.10970", "authors": ["Canwen Wang", "Angela Chen", "Catherine Bao", "Siwei Jin", "Yee Kit Chan", "Jessica R Mindel", "Sijia Xie", "Holly Swartz", "Tongshuang Wu", "Robert E Kraut", "Haiyi Zhu"], "title": "Modeling Multi-Party Interaction in Couples Therapy: A Multi-Agent Simulation Approach", "comment": null, "summary": "Couples therapy, or relationship counseling, helps partners resolve conflicts, improve satisfaction, and foster psychological growth. Traditional approaches to training couples therapists, such as textbooks and roleplay, often fail to capture the complexity and emotional nuance of real couple dynamics. We present a novel multimodal, multi-agent simulation system that models multi-party interactions in couples therapy. Informed by our systematic research, this system creates a low-stakes environment for trainee therapists to gain valuable practical experience dealing with the critical demand-withdraw communication cycle across six couple-interaction stages. In an evaluation study involving 21 US-based licensed therapists, participants blind to conditions identified the engineered agent behaviors (i.e., the stages and the demand-withdraw cycle) and rated overall realism and agent responses higher for the experimental system than the baseline. As the first known multi-agent framework for training couples therapists, our work builds the foundation for future research that fuses HCI technologies with couples therapy."}
{"id": "2601.10719", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10719", "abs": "https://arxiv.org/abs/2601.10719", "authors": ["Gerard Yeo", "Svetlana Churina", "Kokil Jaidka"], "title": "Do You Trust Me? Cognitive-Affective Signatures of Trustworthiness in Large Language Models", "comment": null, "summary": "Perceived trustworthiness underpins how users navigate online information, yet it remains unclear whether large language models (LLMs),increasingly embedded in search, recommendation, and conversational systems, represent this construct in psychologically coherent ways. We analyze how instruction-tuned LLMs (Llama 3.1 8B, Qwen 2.5 7B, Mistral 7B) encode perceived trustworthiness in web-like narratives using the PEACE-Reviews dataset annotated for cognitive appraisals, emotions, and behavioral intentions. Across models, systematic layer- and head-level activation differences distinguish high- from low-trust texts, revealing that trust cues are implicitly encoded during pretraining. Probing analyses show linearly de-codable trust signals and fine-tuning effects that refine rather than restructure these representations. Strongest associations emerge with appraisals of fairness, certainty, and accountability-self -- dimensions central to human trust formation online. These findings demonstrate that modern LLMs internalize psychologically grounded trust signals without explicit supervision, offering a representational foundation for designing credible, transparent, and trust-worthy AI systems in the web ecosystem. Code and appendix are available at: https://github.com/GerardYeo/TrustworthinessLLM."}
{"id": "2601.10744", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.10744", "abs": "https://arxiv.org/abs/2601.10744", "authors": ["Sen Wang", "Bangwei Liu", "Zhenkun Gao", "Lizhuang Ma", "Xuhong Wang", "Yuan Xie", "Xin Tan"], "title": "Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration", "comment": "Our dataset and code will be released at our \\href{https://wangsen99.github.io/papers/lmee/}{website}", "summary": "An ideal embodied agent should possess lifelong learning capabilities to handle long-horizon and complex tasks, enabling continuous operation in general environments. This not only requires the agent to accurately accomplish given tasks but also to leverage long-term episodic memory to optimize decision-making. However, existing mainstream one-shot embodied tasks primarily focus on task completion results, neglecting the crucial process of exploration and memory utilization. To address this, we propose Long-term Memory Embodied Exploration (LMEE), which aims to unify the agent's exploratory cognition and decision-making behaviors to promote lifelong learning.We further construct a corresponding dataset and benchmark, LMEE-Bench, incorporating multi-goal navigation and memory-based question answering to comprehensively evaluate both the process and outcome of embodied exploration. To enhance the agent's memory recall and proactive exploration capabilities, we propose MemoryExplorer, a novel method that fine-tunes a multimodal large language model through reinforcement learning to encourage active memory querying. By incorporating a multi-task reward function that includes action prediction, frontier selection, and question answering, our model achieves proactive exploration. Extensive experiments against state-of-the-art embodied exploration models demonstrate that our approach achieves significant advantages in long-horizon embodied tasks."}
{"id": "2601.11237", "categories": ["econ.EM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.11237", "abs": "https://arxiv.org/abs/2601.11237", "authors": ["Anthony Britto"], "title": "Likelihood-Based Ergodicity Transformations in Time Series Analysis", "comment": "19 pages, 7 figures, 5 tables", "summary": "Time series often exhibit non-ergodic behaviour that complicates forecasting and inference. This article proposes a likelihood-based approach for estimating ergodicity transformations that addresses such challenges. The method is broadly compatible with standard models, including Gaussian processes, ARMA, and GARCH. A detailed simulation study using geometric and arithmetic Brownian motion demonstrates the ability of the approach to recover known ergodicity transformations. A further case study on the large macroeconomic database FRED-QD shows that incorporating ergodicity transformations can provide meaningful improvements over conventional transformations or naive specifications in applied work."}
{"id": "2601.11140", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.11140", "abs": "https://arxiv.org/abs/2601.11140", "authors": ["Yuwei Chuai", "Manoel Horta Ribeiro", "Gabriele Lenzini", "Nicolas Pröllochs"], "title": "When \"Likers'' Go Private: Engagement With Reputationally Risky Content on X", "comment": null, "summary": "In June 2024, X/Twitter changed likes' visibility from public to private, offering a rare, platform-level opportunity to study how the visibility of engagement signals affects users' behavior. Here, we investigate whether hiding liker identities increases the number of likes received by high-reputational-risk content, content for which public endorsement may carry high social or reputational costs due to its topic (e.g., politics) or the account context in which it appears (e.g., partisan accounts). To this end, we conduct two complementary studies: 1) a Difference-in-Differences analysis of engagement with 154,122 posts by 1068 accounts before and after the policy change. 2) a within-subject survey experiment with 203 X users on participants' self-reported willingness to like different kinds of content. We find no detectable platform-level increase in likes for high-reputational-risk content (Study 1). This finding is robust for both between-group comparison of high- versus low-reputational-risk accounts and within-group comparison across engagement types (i.e., likes vs. reposts). Additionally, while participants in the survey experiment report modest increases in willingness to like high-reputational-risk content under private versus public visibility, these increases do not lead to significant changes in the group-level average likelihood of liking posts (Study 2). Taken together, our results suggest that hiding likes produces a limited behavioral response at the platform level. This may be caused by a gap between user intention and behavior, or by engagement driven by a narrow set of high-usage or automated accounts."}
{"id": "2601.10983", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.10983", "abs": "https://arxiv.org/abs/2601.10983", "authors": ["Zhen Xu", "Xin Guan", "Chenxi Shi", "Qinhao Chen", "Renzhe Yu"], "title": "Evaluating 21st-Century Competencies in Postsecondary Curricula with Large Language Models: Performance Benchmarking and Reasoning-Based Prompting Strategies", "comment": null, "summary": "The growing emphasis on 21st-century competencies in postsecondary education, intensified by the transformative impact of generative AI, underscores the need to evaluate how these competencies are embedded in curricula and how effectively academic programs align with evolving workforce and societal demands. Curricular Analytics, particularly recent generative AI-powered approaches, offer a promising data-driven pathway. However, analyzing 21st-century competencies requires pedagogical reasoning beyond surface-level information retrieval, and the capabilities of large language models in this context remain underexplored. In this study, we extend prior curricular analytics research by examining a broader range of curriculum documents, competency frameworks, and models. Using 7,600 manually annotated curriculum-competency alignment scores, we assess the informativeness of different curriculum sources, benchmark general-purpose LLMs for curriculum-to-competency mapping, and analyze error patterns. We further introduce a reasoning-based prompting strategy, Curricular CoT, to strengthen LLMs' pedagogical reasoning. Our results show that detailed instructional activity descriptions are the most informative type of curriculum document for competency analytics. Open-weight LLMs achieve accuracy comparable to proprietary models on coarse-grained tasks, demonstrating their scalability and cost-effectiveness for institutional use. However, no model reaches human-level precision in fine-grained pedagogical reasoning. Our proposed Curricular CoT yields modest improvements by reducing bias in instructional keyword inference and improving the detection of nuanced pedagogical evidence in long text. Together, these findings highlight the untapped potential of institutional curriculum documents and provide an empirical foundation for advancing AI-driven curricular analytics."}
{"id": "2601.10726", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10726", "abs": "https://arxiv.org/abs/2601.10726", "authors": ["Ross Chu", "Yuting Huang"], "title": "Building AI Agents to Improve Job Referral Requests to Strangers", "comment": null, "summary": "This paper develops AI agents that help job seekers write effective requests for job referrals in a professional online community. The basic workflow consists of an improver agent that rewrites the referral request and an evaluator agent that measures the quality of revisions using a model trained to predict the probability of receiving referrals from other users. Revisions suggested by the LLM (large language model) increase predicted success rates for weaker requests while reducing them for stronger requests. Enhancing the LLM with Retrieval-Augmented Generation (RAG) prevents edits that worsen stronger requests while it amplifies improvements for weaker requests. Overall, using LLM revisions with RAG increases the predicted success rate for weaker requests by 14\\% without degrading performance on stronger requests. Although improvements in model-predicted success do not guarantee more referrals in the real world, they provide low-cost signals for promising features before running higher-stakes experiments on real users."}
{"id": "2601.10768", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10768", "abs": "https://arxiv.org/abs/2601.10768", "authors": ["Nina Bočková", "Barbora Volná", "Mirko Dohnal"], "title": "Optimisation of complex product innovation processes based on trend models with three-valued logic", "comment": null, "summary": "This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph."}
{"id": "2601.11338", "categories": ["cs.SI", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.11338", "abs": "https://arxiv.org/abs/2601.11338", "authors": ["Francesca Arrigo", "Fabio Durastante"], "title": "Walk based Laplacians for Modeling Diffusion on Complex Networks", "comment": null, "summary": "We develop a novel framework for modeling diffusion on complex networks by constructing Laplacian-like operators based on walks around a graph. Our approach introduces a parametric family of walk-based Laplacians that naturally incorporate memory effects by excluding or downweighting backtracking trajectories, where walkers immediately revisit nodes. The framework includes: (i) walk-based Laplacians that count all traversals in the network; (ii) nonbacktracking variants that eliminate immediate reversals; and (iii) backtrack-downweighted variants that provide a continuous interpolation between these two regimes. We establish that these operators extend the definition of the standard Laplacian and also preserve some of its properties. We present efficient algorithms using Krylov subspace methods for computing them, ensuring applicability of our proposed framework to large networks. Extensive numerical experiments on real-world networks validate the modeling flexibility of our approach and demonstrate the computational efficiency of the proposed algorithms, including GPU acceleration."}
{"id": "2601.11065", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11065", "abs": "https://arxiv.org/abs/2601.11065", "authors": ["Rachmadita Andreswari", "Stephan A. Fahrenkrog-Petersen", "Jan Mendling"], "title": "Fairness in Healthcare Processes: A Quantitative Analysis of Decision Making in Triage", "comment": "conference", "summary": "Fairness in automated decision-making has become a critical concern, particularly in high-pressure healthcare scenarios such as emergency triage, where fast and equitable decisions are essential. Process mining is increasingly investigating fairness. There is a growing area focusing on fairness-aware algorithms. So far, we know less how these concepts perform on empirical healthcare data or how they cover aspects of justice theory. This study addresses this research problem and proposes a process mining approach to assess fairness in triage by linking real-life event logs with conceptual dimensions of justice. Using the MIMICEL event log (as derived from MIMIC-IV ED), we analyze time, re-do, deviation and decision as process outcomes, and evaluate the influence of age, gender, race, language and insurance using the Kruskal-Wallis, Chi-square and effect size measurements. These outcomes are mapped to justice dimensions to support the development of a conceptual framework. The results demonstrate which aspects of potential unfairness in high-acuity and sub-acute surface. In this way, this study contributes empirical insights that support further research in responsible, fairness-aware process mining in healthcare."}
{"id": "2601.10729", "categories": ["cs.AI", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.10729", "abs": "https://arxiv.org/abs/2601.10729", "authors": ["Xinyue Ma", "Heelim Hong", "Taegeon Um", "Jongseop Lee", "Seoyeong Choy", "Woo-Yeon Lee", "Myeongjae Jeon"], "title": "ORBITFLOW: SLO-Aware Long-Context LLM Serving with Fine-Grained KV Cache Reconfiguration", "comment": "Accepted at the 52nd International Conference on Very Large Data Bases (VLDB 2026). Xinyue Ma and Heelim Hong contributed equally (co-first authors)", "summary": "Serving long-context LLMs is challenging because request lengths and batch composition vary during token generation, causing the memory footprint to fluctuate significantly at runtime. Offloading KV caches to host memory limits effective memory usage, but existing static and predetermined offloading strategies cannot adapt to the rapidly shifting memory demands of long-context serving. This often leads to excessive CPU-to-GPU KV transfers that translate into latency spikes and frequent SLO violations. To address these challenges, we introduce ORBITFLOW, a fine-grained and adaptive KV cache management system that meets latency SLOs in long-context LLM serving. ORBITFLOW employs a lightweight ILP solver to decide which layers' KV caches to retain on the GPU for each request, within memory capacity constraints. It continuously refines KV placements based on runtime feedback when the active plan becomes suboptimal during token generation. Under heavy load, ORBITFLOW invokes a fallback mechanism to temporarily defer in-flight requests with large memory footprints, preserving overall SLO attainment. Our experiments demonstrate that ORBITFLOW improves SLO attainment for TPOT and TBT by up to 66% and 48%, respectively, while reducing the 95th percentile latency by 38% and achieving up to 3.3x higher throughput compared to existing offloading methods."}
{"id": "2601.10904", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10904", "abs": "https://arxiv.org/abs/2601.10904", "authors": ["François Chollet", "Mike Knoop", "Gregory Kamradt", "Bryan Landers"], "title": "ARC Prize 2025: Technical Report", "comment": null, "summary": "The ARC-AGI benchmark series serves as a critical measure of few-shot generalization on novel tasks, a core aspect of intelligence. The ARC Prize 2025 global competition targeted the newly released ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. The Kaggle competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the ARC-AGI-2 private evaluation set. Paper submissions nearly doubled year-over-year to 90 entries, reflecting the growing research interest in fluid intelligence and abstract reasoning. The defining theme of 2025 is the emergence of the refinement loop -- a per-task iterative program optimization loop guided by a feedback signal. Refinement loops come in a variety of forms, in particular evolutionary program synthesis approaches and application-layer refinements to commercial AI systems. Such refinement loops are also possible in weight space, as evidenced by zero-pretraining deep learning methods which are now achieving competitive performance with remarkably small networks (7M parameters). In parallel, four frontier AI labs (Anthropic, Google DeepMind, OpenAI, and xAI) reported ARC-AGI performance in public model cards in 2025, establishing ARC-AGI as an industry standard benchmark for AI reasoning. However, our analysis indicates that current frontier AI reasoning performance remains fundamentally constrained to knowledge coverage, giving rise to new forms of benchmark contamination. In this paper, we survey the top-performing methods, examine the role of refinement loops in AGI progress, discuss knowledge-dependent overfitting, and preview ARC-AGI-3, which introduces interactive reasoning challenges that require exploration, planning, memory, goal acquisition, and alignment capabilities."}
{"id": "2601.11507", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.11507", "abs": "https://arxiv.org/abs/2601.11507", "authors": ["Joseph Bak-Coleman", "Jevin West", "Cailin O'Connor", "Carl T. Bergstrom"], "title": "Industry Influence in High-Profile Social Media Research", "comment": "11 pages, 4 figures, preprint", "summary": "To what extent is social media research independent from industry influence? Leveraging openly available data, we show that half of the research published in top journals has disclosable ties to industry in the form of prior funding, collaboration, or employment. However, the majority of these ties go undisclosed in the published research. These trends do not arise from broad scientific engagement with industry, but rather from a select group of scientists who maintain long-lasting relationships with industry. Undisclosed ties to industry are common not just among authors, but among reviewers and academic editors during manuscript evaluation. Further, industry-tied research garners more attention within the academy, among policymakers, on social media, and in the news. Finally, we find evidence that industry ties are associated with a topical focus away from impacts of platform-scale features. Together, these findings suggest industry influence in social media research is extensive, impactful, and often opaque. Going forward there is a need to strengthen disclosure norms and implement policies to ensure the visibility of independent research, and the integrity of industry supported research."}
{"id": "2601.11169", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11169", "abs": "https://arxiv.org/abs/2601.11169", "authors": ["Francesco Semeraro", "Filip Bečanović", "Maja Trumić", "Kosta Jovanović", "Angelo Cangelosi"], "title": "How Do Technological Prototypes in the Food Industry Impact People's Perception? Insights from the MUSAE \"GROW, COOK, CODE\" Final Exhibition", "comment": null, "summary": "This work reports the results of the survey carried out during the MUSAE final exhibition to assess its impact on people's perception of aspects like trust in technology, environmental challenges, eating habits and potential increase of mental and physical health while interacting with the technological prototypes exposed during the exhibition. The results show that the exhibition positively increased people's awareness regarding these aspects."}
{"id": "2601.10738", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10738", "abs": "https://arxiv.org/abs/2601.10738", "authors": ["Percy Jardine"], "title": "CTHA: Constrained Temporal Hierarchical Architecture for Stable Multi-Agent LLM Systems", "comment": null, "summary": "Recently, multi-time-scale agent architectures have extended the ubiquitous single-loop paradigm by introducing temporal hierarchies with distinct cognitive layers. While yielding substantial performance gains, this diversification fundamentally compromises the coordination stability intrinsic to unified agent systems, which causes severe inter-layer conflicts, unbounded error propagation, and restricted scalability. To address these challenges, we propose Constrained Temporal Hierarchical Architecture (CTHA), a general framework that projects the inter-layer communication space onto structured manifolds to restore coordination stability, while incorporating principled arbitration mechanisms to ensure coherent decision-making. Specifically, CTHA enforces three key constraints: (1) Message Contract Constraints that formalize information flow between layers via typed summary, plan, and policy packets; (2) Authority Manifold Constraints that bound each layer's decision space according to its temporal scope; and (3) Arbiter Resolution Constraints that guarantee conflict-free composition of multi-layer decisions. Empirical experiments demonstrate that CTHA is effective for complex task execution at scale, offering 47% reduction in failure cascades, 2.3x improvement in sample efficiency, and superior scalability compared to unconstrained hierarchical baselines. We anticipate that CTHA, as a principled extension of temporal hierarchies, will contribute to a deeper understanding of multi-agent coordination and suggest promising directions for the evolution of robust autonomous systems."}
{"id": "2601.10922", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10922", "abs": "https://arxiv.org/abs/2601.10922", "authors": ["Yosub Shin", "Michael Buriek", "Boris Sobolev", "Pavel Bushuyeu", "Vikas Kumar", "Haoyang Xu", "Samuel Watson", "Igor Molybog"], "title": "What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge", "comment": null, "summary": "We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning."}
{"id": "2601.11178", "categories": ["cs.AI", "cs.CL", "cs.MM", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.11178", "abs": "https://arxiv.org/abs/2601.11178", "authors": ["Girish A. Koushik", "Helen Treharne", "Diptesh Kanojia"], "title": "TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech", "comment": "Under review at ICWSM 2026", "summary": "Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as \"black boxes\" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools."}
{"id": "2601.11202", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11202", "abs": "https://arxiv.org/abs/2601.11202", "authors": ["Emanuele Ratti"], "title": "Epistemic Control and the Normativity of Machine Learning-Based Science", "comment": null, "summary": "The past few years have witnessed an increasing use of machine learning (ML) systems in science. Paul Humphreys has argued that, because of specific characteristics of ML systems, human scientists are pushed out of the loop of science. In this chapter, I investigate to what extent this is true. First, I express these concerns in terms of what I call epistemic control. I identify two conditions for epistemic control, called tracking and tracing, drawing on works in philosophy of technology. With this new understanding of the problem, I then argue against Humphreys pessimistic view. Finally, I construct a more nuanced view of epistemic control in ML-based science."}
{"id": "2601.10744", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.10744", "abs": "https://arxiv.org/abs/2601.10744", "authors": ["Sen Wang", "Bangwei Liu", "Zhenkun Gao", "Lizhuang Ma", "Xuhong Wang", "Yuan Xie", "Xin Tan"], "title": "Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration", "comment": "Our dataset and code will be released at our \\href{https://wangsen99.github.io/papers/lmee/}{website}", "summary": "An ideal embodied agent should possess lifelong learning capabilities to handle long-horizon and complex tasks, enabling continuous operation in general environments. This not only requires the agent to accurately accomplish given tasks but also to leverage long-term episodic memory to optimize decision-making. However, existing mainstream one-shot embodied tasks primarily focus on task completion results, neglecting the crucial process of exploration and memory utilization. To address this, we propose Long-term Memory Embodied Exploration (LMEE), which aims to unify the agent's exploratory cognition and decision-making behaviors to promote lifelong learning.We further construct a corresponding dataset and benchmark, LMEE-Bench, incorporating multi-goal navigation and memory-based question answering to comprehensively evaluate both the process and outcome of embodied exploration. To enhance the agent's memory recall and proactive exploration capabilities, we propose MemoryExplorer, a novel method that fine-tunes a multimodal large language model through reinforcement learning to encourage active memory querying. By incorporating a multi-task reward function that includes action prediction, frontier selection, and question answering, our model achieves proactive exploration. Extensive experiments against state-of-the-art embodied exploration models demonstrate that our approach achieves significant advantages in long-horizon embodied tasks."}
{"id": "2601.11007", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11007", "abs": "https://arxiv.org/abs/2601.11007", "authors": ["Zhenhua Xu", "Dongsheng Chen", "Shuo Wang", "Jian Li", "Chengjie Wang", "Meng Han", "Yabiao Wang"], "title": "AdaMARP: An Adaptive Multi-Agent Interaction Framework for General Immersive Role-Playing", "comment": null, "summary": "LLM role-playing aims to portray arbitrary characters in interactive narratives, yet existing systems often suffer from limited immersion and adaptability. They typically under-model dynamic environmental information and assume largely static scenes and casts, offering insufficient support for multi-character orchestration, scene transitions, and on-the-fly character introduction. We propose an adaptive multi-agent role-playing framework, AdaMARP, featuring an immersive message format that interleaves [Thought], (Action), <Environment>, and Speech, together with an explicit Scene Manager that governs role-playing through discrete actions (init_scene, pick_speaker, switch_scene, add_role, end) accompanied by rationales. To train these capabilities, we construct AdaRPSet for the Actor Model and AdaSMSet for supervising orchestration decisions, and introduce AdaptiveBench for trajectory-level evaluation. Experiments across multiple backbones and model scales demonstrate consistent improvements: AdaRPSet enhances character consistency, environment grounding, and narrative coherence, with an 8B actor outperforming several commercial LLMs, while AdaSMSet enables smoother scene transitions and more natural role introductions, surpassing Claude Sonnet 4.5 using only a 14B LLM."}
{"id": "2601.11513", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11513", "abs": "https://arxiv.org/abs/2601.11513", "authors": ["Evan Dong", "Nikhil Garg", "Sarah Dean"], "title": "Capacity Constraints Make Admissions Processes Less Predictable", "comment": "This paper was accepted to the 2026 AAAI Conference on Artificial Intelligence AI for Social Impact Track", "summary": "Machine learning models are often used to make predictions about admissions process outcomes, such as for colleges or jobs. However, such decision processes differ substantially from the conventional machine learning paradigm. Because admissions decisions are capacity-constrained, whether a student is admitted depends on the other applicants who apply. We show how this dependence affects predictive performance even in otherwise ideal settings. Theoretically, we introduce two concepts that characterize the relationship between admission function properties, machine learning representation, and generalization to applicant pool distribution shifts: instability, which measures how many existing decisions can change when a single new applicant is introduced; and variability, which measures the number of unique students whose decisions can change. Empirically, we illustrate our theory on individual-level admissions data from the New York City high school matching system, showing that machine learning performance degrades as the applicant pool increasingly differs from the training data. Furthermore, there are larger performance drops for schools using decision rules that are more unstable and variable. Our work raises questions about the reliability of predicting individual admissions probabilities."}
{"id": "2601.10768", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10768", "abs": "https://arxiv.org/abs/2601.10768", "authors": ["Nina Bočková", "Barbora Volná", "Mirko Dohnal"], "title": "Optimisation of complex product innovation processes based on trend models with three-valued logic", "comment": null, "summary": "This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph."}
{"id": "2601.11012", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11012", "abs": "https://arxiv.org/abs/2601.11012", "authors": ["Jiahao Wang", "Shuangjia Zheng"], "title": "Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics", "comment": null, "summary": "The ability to engineer optimized protein variants has transformative potential for biotechnology and medicine. Prior sequence-based optimization methods struggle with the high-dimensional complexities due to the epistasis effect and the disregard for structural constraints. To address this, we propose HADES, a Bayesian optimization method utilizing Hamiltonian dynamics to efficiently sample from a structure-aware approximated posterior. Leveraging momentum and uncertainty in the simulated physical movements, HADES enables rapid transition of proposals toward promising areas. A position discretization procedure is introduced to propose discrete protein sequences from such a continuous state system. The posterior surrogate is powered by a two-stage encoder-decoder framework to determine the structure and function relationships between mutant neighbors, consequently learning a smoothed landscape to sample from. Extensive experiments demonstrate that our method outperforms state-of-the-art baselines in in-silico evaluations across most metrics. Remarkably, our approach offers a unique advantage by leveraging the mutual constraints between protein structure and sequence, facilitating the design of protein sequences with similar structures and optimized properties. The code and data are publicly available at https://github.com/GENTEL-lab/HADES."}
{"id": "2601.10852", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.10852", "abs": "https://arxiv.org/abs/2601.10852", "authors": ["Khondokar Fida Hasan", "William Hughes", "Adrita Rahman"], "title": "Gamifying Cyber Governance: A Virtual Escape Room to Transform Cybersecurity Policy Education", "comment": "10 pages", "summary": "Serious games are gaining popularity as effective teaching and learning tools, providing engaging, interactive, and practical experiences for students. Gamified learning experiences, such as virtual escape rooms, have emerged as powerful tools in bridging theory and practice, fostering deeper understanding and engagement among students. This paper presents the design, implementation, and evaluation of a virtual escape room tailored specifically for cybersecurity governance and policy education. Developed as a 3D immersive environment, the escape room simulates a virtual company scenario to facilitate risk-informed cyber policy development. It consists of three interactive zones, each offering distinct sets of scenario-based problems that target specific educational objectives. Through these zones, students analyze cybersecurity risks, match security frameworks, and draft appropriate policies, thereby developing critical thinking, decision-making skills, and practical cybersecurity competencies. The primary contribution of this work lies in its innovative integration of game-based learning and immersive technology to create robust, interactive learning materials that are also resilient to generative AI interventions, thereby maintaining academic integrity. Additionally, the escape room provides students with exposure to real-world cybersecurity scenarios in a virtual office environment that meets industry expectations. Results from a student survey indicated strong positive feedback, highlighting significant improvements in students engagement, practical understanding, and enthusiasm toward cybersecurity governance and policy concepts, underscoring the effectiveness and potential of gamification in cybersecurity education."}
{"id": "2601.11037", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11037", "abs": "https://arxiv.org/abs/2601.11037", "authors": ["Shiyu Liu", "Yongjing Yin", "Jianhao Yan", "Yunbo Tang", "Qinggang Zhang", "Bei Li", "Xin Chen", "Jingang Wang", "Xunliang Cai", "Jinsong Su"], "title": "BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search", "comment": "Code is available at https://github.com/Liushiyu-0709/BAPO-Reliable-Search", "summary": "RL-based agentic search enables LLMs to solve complex questions via dynamic planning and external search. While this approach significantly enhances accuracy with agent policies optimized via large-scale reinforcement learning, we identify a critical gap in reliability: these agents fail to recognize their reasoning boundaries and rarely admit ``I DON'T KNOW'' (IDK) even when evidence is insufficient or reasoning reaches its limit. The lack of reliability often leads to plausible but unreliable answers, introducing significant risks in many real-world scenarios. To this end, we propose Boundary-Aware Policy Optimization (BAPO), a novel RL framework designed to cultivate reliable boundary awareness without compromising accuracy. BAPO introduces two key components: (i) a group-based boundary-aware reward that encourages an IDK response only when the reasoning reaches its limit, and (ii) an adaptive reward modulator that strategically suspends this reward during early exploration, preventing the model from exploiting IDK as a shortcut. Extensive experiments on four benchmarks demonstrate that BAPO substantially enhances the overall reliability of agentic search."}
{"id": "2601.10904", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10904", "abs": "https://arxiv.org/abs/2601.10904", "authors": ["François Chollet", "Mike Knoop", "Gregory Kamradt", "Bryan Landers"], "title": "ARC Prize 2025: Technical Report", "comment": null, "summary": "The ARC-AGI benchmark series serves as a critical measure of few-shot generalization on novel tasks, a core aspect of intelligence. The ARC Prize 2025 global competition targeted the newly released ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. The Kaggle competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the ARC-AGI-2 private evaluation set. Paper submissions nearly doubled year-over-year to 90 entries, reflecting the growing research interest in fluid intelligence and abstract reasoning. The defining theme of 2025 is the emergence of the refinement loop -- a per-task iterative program optimization loop guided by a feedback signal. Refinement loops come in a variety of forms, in particular evolutionary program synthesis approaches and application-layer refinements to commercial AI systems. Such refinement loops are also possible in weight space, as evidenced by zero-pretraining deep learning methods which are now achieving competitive performance with remarkably small networks (7M parameters). In parallel, four frontier AI labs (Anthropic, Google DeepMind, OpenAI, and xAI) reported ARC-AGI performance in public model cards in 2025, establishing ARC-AGI as an industry standard benchmark for AI reasoning. However, our analysis indicates that current frontier AI reasoning performance remains fundamentally constrained to knowledge coverage, giving rise to new forms of benchmark contamination. In this paper, we survey the top-performing methods, examine the role of refinement loops in AGI progress, discuss knowledge-dependent overfitting, and preview ARC-AGI-3, which introduces interactive reasoning challenges that require exploration, planning, memory, goal acquisition, and alignment capabilities."}
{"id": "2601.11044", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11044", "abs": "https://arxiv.org/abs/2601.11044", "authors": ["Keyu Li", "Junhao Shi", "Yang Xiao", "Mohan Jiang", "Jie Sun", "Yunze Wu", "Shijie Xia", "Xiaojie Cai", "Tianze Xu", "Weiye Si", "Wenjie Li", "Dequan Wang", "Pengfei Liu"], "title": "AgencyBench: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts", "comment": null, "summary": "Large Language Models (LLMs) based autonomous agents demonstrate multifaceted capabilities to contribute substantially to economic production. However, existing benchmarks remain focused on single agentic capability, failing to capture long-horizon real-world scenarios. Moreover, the reliance on human-in-the-loop feedback for realistic tasks creates a scalability bottleneck, hindering automated rollout collection and evaluation. To bridge this gap, we introduce AgencyBench, a comprehensive benchmark derived from daily AI usage, evaluating 6 core agentic capabilities across 32 real-world scenarios, comprising 138 tasks with specific queries, deliverables, and rubrics. These scenarios require an average of 90 tool calls, 1 million tokens, and hours of execution time to resolve. To enable automated evaluation, we employ a user simulation agent to provide iterative feedback, and a Docker sandbox to conduct visual and functional rubric-based assessment. Experiments reveal that closed-source models significantly outperform open-source models (48.4% vs 32.1%). Further analysis reveals significant disparities across models in resource efficiency, feedback-driven self-correction, and specific tool-use preferences. Finally, we investigate the impact of agentic scaffolds, observing that proprietary models demonstrate superior performance within their native ecosystems (e.g., Claude-4.5-Opus via Claude-Agent-SDK), while open-source models exhibit distinct performance peaks, suggesting potential optimization for specific execution frameworks. AgencyBench serves as a critical testbed for next-generation agents, highlighting the necessity of co-optimizing model architecture with agentic frameworks. We believe this work sheds light on the future direction of autonomous agents, and we release the full benchmark and evaluation toolkit at https://github.com/GAIR-NLP/AgencyBench."}
{"id": "2601.10922", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10922", "abs": "https://arxiv.org/abs/2601.10922", "authors": ["Yosub Shin", "Michael Buriek", "Boris Sobolev", "Pavel Bushuyeu", "Vikas Kumar", "Haoyang Xu", "Samuel Watson", "Igor Molybog"], "title": "What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge", "comment": null, "summary": "We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning."}
{"id": "2601.11089", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11089", "abs": "https://arxiv.org/abs/2601.11089", "authors": ["Suhan Guo", "Jiahong Deng", "Furao Shen"], "title": "MiCA: A Mobility-Informed Causal Adapter for Lightweight Epidemic Forecasting", "comment": null, "summary": "Accurate forecasting of infectious disease dynamics is critical for public health planning and intervention. Human mobility plays a central role in shaping the spatial spread of epidemics, but mobility data are noisy, indirect, and difficult to integrate reliably with disease records. Meanwhile, epidemic case time series are typically short and reported at coarse temporal resolution. These conditions limit the effectiveness of parameter-heavy mobility-aware forecasters that rely on clean and abundant data. In this work, we propose the Mobility-Informed Causal Adapter (MiCA), a lightweight and architecture-agnostic module for epidemic forecasting. MiCA infers mobility relations through causal discovery and integrates them into temporal forecasting models via gated residual mixing. This design allows lightweight forecasters to selectively exploit mobility-derived spatial structure while remaining robust under noisy and data-limited conditions, without introducing heavy relational components such as graph neural networks or full attention. Extensive experiments on four real-world epidemic datasets, including COVID-19 incidence, COVID-19 mortality, influenza, and dengue, show that MiCA consistently improves lightweight temporal backbones, achieving an average relative error reduction of 7.5\\% across forecasting horizons. Moreover, MiCA attains performance competitive with SOTA spatio-temporal models while remaining lightweight."}
{"id": "2601.10970", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.10970", "abs": "https://arxiv.org/abs/2601.10970", "authors": ["Canwen Wang", "Angela Chen", "Catherine Bao", "Siwei Jin", "Yee Kit Chan", "Jessica R Mindel", "Sijia Xie", "Holly Swartz", "Tongshuang Wu", "Robert E Kraut", "Haiyi Zhu"], "title": "Modeling Multi-Party Interaction in Couples Therapy: A Multi-Agent Simulation Approach", "comment": null, "summary": "Couples therapy, or relationship counseling, helps partners resolve conflicts, improve satisfaction, and foster psychological growth. Traditional approaches to training couples therapists, such as textbooks and roleplay, often fail to capture the complexity and emotional nuance of real couple dynamics. We present a novel multimodal, multi-agent simulation system that models multi-party interactions in couples therapy. Informed by our systematic research, this system creates a low-stakes environment for trainee therapists to gain valuable practical experience dealing with the critical demand-withdraw communication cycle across six couple-interaction stages. In an evaluation study involving 21 US-based licensed therapists, participants blind to conditions identified the engineered agent behaviors (i.e., the stages and the demand-withdraw cycle) and rated overall realism and agent responses higher for the experimental system than the baseline. As the first known multi-agent framework for training couples therapists, our work builds the foundation for future research that fuses HCI technologies with couples therapy."}
{"id": "2601.11100", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11100", "abs": "https://arxiv.org/abs/2601.11100", "authors": ["Zhezheng Hao", "Hong Wang", "Jian Luo", "Jianqing Zhang", "Yuyan Zhou", "Qiang Lin", "Can Wang", "Hande Dong", "Jiawei Chen"], "title": "ReCreate: Reasoning and Creating Domain Agents Driven by Experience", "comment": null, "summary": "Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds."}
{"id": "2601.10983", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.10983", "abs": "https://arxiv.org/abs/2601.10983", "authors": ["Zhen Xu", "Xin Guan", "Chenxi Shi", "Qinhao Chen", "Renzhe Yu"], "title": "Evaluating 21st-Century Competencies in Postsecondary Curricula with Large Language Models: Performance Benchmarking and Reasoning-Based Prompting Strategies", "comment": null, "summary": "The growing emphasis on 21st-century competencies in postsecondary education, intensified by the transformative impact of generative AI, underscores the need to evaluate how these competencies are embedded in curricula and how effectively academic programs align with evolving workforce and societal demands. Curricular Analytics, particularly recent generative AI-powered approaches, offer a promising data-driven pathway. However, analyzing 21st-century competencies requires pedagogical reasoning beyond surface-level information retrieval, and the capabilities of large language models in this context remain underexplored. In this study, we extend prior curricular analytics research by examining a broader range of curriculum documents, competency frameworks, and models. Using 7,600 manually annotated curriculum-competency alignment scores, we assess the informativeness of different curriculum sources, benchmark general-purpose LLMs for curriculum-to-competency mapping, and analyze error patterns. We further introduce a reasoning-based prompting strategy, Curricular CoT, to strengthen LLMs' pedagogical reasoning. Our results show that detailed instructional activity descriptions are the most informative type of curriculum document for competency analytics. Open-weight LLMs achieve accuracy comparable to proprietary models on coarse-grained tasks, demonstrating their scalability and cost-effectiveness for institutional use. However, no model reaches human-level precision in fine-grained pedagogical reasoning. Our proposed Curricular CoT yields modest improvements by reducing bias in instructional keyword inference and improving the detection of nuanced pedagogical evidence in long text. Together, these findings highlight the untapped potential of institutional curriculum documents and provide an empirical foundation for advancing AI-driven curricular analytics."}
{"id": "2601.11147", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11147", "abs": "https://arxiv.org/abs/2601.11147", "authors": ["Zixu Wang", "Bingbing Xu", "Yige Yuan", "Huawei Shen", "Xueqi Cheng"], "title": "Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems", "comment": "17 pages, 4 figures, 3 tables", "summary": "Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \\textbf{SCALE}, which means \\underline{\\textbf{S}}elf prediction of the optimizer with few shot \\underline{\\textbf{CAL}}ibration for \\underline{\\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \\textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\\%."}
{"id": "2601.11007", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11007", "abs": "https://arxiv.org/abs/2601.11007", "authors": ["Zhenhua Xu", "Dongsheng Chen", "Shuo Wang", "Jian Li", "Chengjie Wang", "Meng Han", "Yabiao Wang"], "title": "AdaMARP: An Adaptive Multi-Agent Interaction Framework for General Immersive Role-Playing", "comment": null, "summary": "LLM role-playing aims to portray arbitrary characters in interactive narratives, yet existing systems often suffer from limited immersion and adaptability. They typically under-model dynamic environmental information and assume largely static scenes and casts, offering insufficient support for multi-character orchestration, scene transitions, and on-the-fly character introduction. We propose an adaptive multi-agent role-playing framework, AdaMARP, featuring an immersive message format that interleaves [Thought], (Action), <Environment>, and Speech, together with an explicit Scene Manager that governs role-playing through discrete actions (init_scene, pick_speaker, switch_scene, add_role, end) accompanied by rationales. To train these capabilities, we construct AdaRPSet for the Actor Model and AdaSMSet for supervising orchestration decisions, and introduce AdaptiveBench for trajectory-level evaluation. Experiments across multiple backbones and model scales demonstrate consistent improvements: AdaRPSet enhances character consistency, environment grounding, and narrative coherence, with an 8B actor outperforming several commercial LLMs, while AdaSMSet enables smoother scene transitions and more natural role introductions, surpassing Claude Sonnet 4.5 using only a 14B LLM."}
{"id": "2601.11178", "categories": ["cs.AI", "cs.CL", "cs.MM", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.11178", "abs": "https://arxiv.org/abs/2601.11178", "authors": ["Girish A. Koushik", "Helen Treharne", "Diptesh Kanojia"], "title": "TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech", "comment": "Under review at ICWSM 2026", "summary": "Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as \"black boxes\" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools."}
{"id": "2601.11012", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11012", "abs": "https://arxiv.org/abs/2601.11012", "authors": ["Jiahao Wang", "Shuangjia Zheng"], "title": "Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics", "comment": null, "summary": "The ability to engineer optimized protein variants has transformative potential for biotechnology and medicine. Prior sequence-based optimization methods struggle with the high-dimensional complexities due to the epistasis effect and the disregard for structural constraints. To address this, we propose HADES, a Bayesian optimization method utilizing Hamiltonian dynamics to efficiently sample from a structure-aware approximated posterior. Leveraging momentum and uncertainty in the simulated physical movements, HADES enables rapid transition of proposals toward promising areas. A position discretization procedure is introduced to propose discrete protein sequences from such a continuous state system. The posterior surrogate is powered by a two-stage encoder-decoder framework to determine the structure and function relationships between mutant neighbors, consequently learning a smoothed landscape to sample from. Extensive experiments demonstrate that our method outperforms state-of-the-art baselines in in-silico evaluations across most metrics. Remarkably, our approach offers a unique advantage by leveraging the mutual constraints between protein structure and sequence, facilitating the design of protein sequences with similar structures and optimized properties. The code and data are publicly available at https://github.com/GENTEL-lab/HADES."}
{"id": "2601.11189", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11189", "abs": "https://arxiv.org/abs/2601.11189", "authors": ["Sofiene Lassoued", "Asrat Gobachew", "Stefan Lier", "Andreas Schwung"], "title": "Policy-Based Deep Reinforcement Learning Hyperheuristics for Job-Shop Scheduling Problems", "comment": null, "summary": "This paper proposes a policy-based deep reinforcement learning hyper-heuristic framework for solving the Job Shop Scheduling Problem. The hyper-heuristic agent learns to switch scheduling rules based on the system state dynamically. We extend the hyper-heuristic framework with two key mechanisms. First, action prefiltering restricts decision-making to feasible low-level actions, enabling low-level heuristics to be evaluated independently of environmental constraints and providing an unbiased assessment. Second, a commitment mechanism regulates the frequency of heuristic switching. We investigate the impact of different commitment strategies, from step-wise switching to full-episode commitment, on both training behavior and makespan. Additionally, we compare two action selection strategies at the policy level: deterministic greedy selection and stochastic sampling. Computational experiments on standard JSSP benchmarks demonstrate that the proposed approach outperforms traditional heuristics, metaheuristics, and recent neural network-based scheduling methods"}
{"id": "2601.11037", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11037", "abs": "https://arxiv.org/abs/2601.11037", "authors": ["Shiyu Liu", "Yongjing Yin", "Jianhao Yan", "Yunbo Tang", "Qinggang Zhang", "Bei Li", "Xin Chen", "Jingang Wang", "Xunliang Cai", "Jinsong Su"], "title": "BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search", "comment": "Code is available at https://github.com/Liushiyu-0709/BAPO-Reliable-Search", "summary": "RL-based agentic search enables LLMs to solve complex questions via dynamic planning and external search. While this approach significantly enhances accuracy with agent policies optimized via large-scale reinforcement learning, we identify a critical gap in reliability: these agents fail to recognize their reasoning boundaries and rarely admit ``I DON'T KNOW'' (IDK) even when evidence is insufficient or reasoning reaches its limit. The lack of reliability often leads to plausible but unreliable answers, introducing significant risks in many real-world scenarios. To this end, we propose Boundary-Aware Policy Optimization (BAPO), a novel RL framework designed to cultivate reliable boundary awareness without compromising accuracy. BAPO introduces two key components: (i) a group-based boundary-aware reward that encourages an IDK response only when the reasoning reaches its limit, and (ii) an adaptive reward modulator that strategically suspends this reward during early exploration, preventing the model from exploiting IDK as a shortcut. Extensive experiments on four benchmarks demonstrate that BAPO substantially enhances the overall reliability of agentic search."}
{"id": "2601.11252", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11252", "abs": "https://arxiv.org/abs/2601.11252", "authors": ["Qianyue Wang", "Jinwu Hu", "Yufeng Wang", "Huanxiang Lin", "Bolin Chen", "Zhiquan Wen", "Yaofo Chen", "Mingkui Tan"], "title": "Beyond Model Scaling: Test-Time Intervention for Efficient Deep Reasoning", "comment": null, "summary": "Large Reasoning Models (LRMs) excel at multi-step reasoning but often suffer from inefficient reasoning processes like overthinking and overshoot, where excessive or misdirected reasoning increases computational cost and degrades performance. Existing efficient reasoning methods operate in a closed-loop manner, lacking mechanisms for external intervention to guide the reasoning process. To address this, we propose Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process. Our key insights are that transitional conjunctions serve as natural points for intervention, signaling phases of self-validation or exploration and using transitional words appropriately to prolong the reasoning enhances performance, while excessive use affects performance. Building on these insights, Think-with-Me pauses reasoning at these points for external feedback, adaptively extending or terminating reasoning to reduce redundancy while preserving accuracy. The feedback is generated via a multi-criteria evaluation (rationality and completeness) and comes from either human or LLM proxies. We train the target model using Group Relative Policy Optimization (GRPO) to adapt to this interactive mode. Experiments show that Think-with-Me achieves a superior balance between accuracy and reasoning length under limited context windows. On AIME24, Think-with-Me outperforms QwQ-32B by 7.19% in accuracy while reducing average reasoning length by 81% under an 8K window. The paradigm also benefits security and creative tasks."}
{"id": "2601.11044", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11044", "abs": "https://arxiv.org/abs/2601.11044", "authors": ["Keyu Li", "Junhao Shi", "Yang Xiao", "Mohan Jiang", "Jie Sun", "Yunze Wu", "Shijie Xia", "Xiaojie Cai", "Tianze Xu", "Weiye Si", "Wenjie Li", "Dequan Wang", "Pengfei Liu"], "title": "AgencyBench: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts", "comment": null, "summary": "Large Language Models (LLMs) based autonomous agents demonstrate multifaceted capabilities to contribute substantially to economic production. However, existing benchmarks remain focused on single agentic capability, failing to capture long-horizon real-world scenarios. Moreover, the reliance on human-in-the-loop feedback for realistic tasks creates a scalability bottleneck, hindering automated rollout collection and evaluation. To bridge this gap, we introduce AgencyBench, a comprehensive benchmark derived from daily AI usage, evaluating 6 core agentic capabilities across 32 real-world scenarios, comprising 138 tasks with specific queries, deliverables, and rubrics. These scenarios require an average of 90 tool calls, 1 million tokens, and hours of execution time to resolve. To enable automated evaluation, we employ a user simulation agent to provide iterative feedback, and a Docker sandbox to conduct visual and functional rubric-based assessment. Experiments reveal that closed-source models significantly outperform open-source models (48.4% vs 32.1%). Further analysis reveals significant disparities across models in resource efficiency, feedback-driven self-correction, and specific tool-use preferences. Finally, we investigate the impact of agentic scaffolds, observing that proprietary models demonstrate superior performance within their native ecosystems (e.g., Claude-4.5-Opus via Claude-Agent-SDK), while open-source models exhibit distinct performance peaks, suggesting potential optimization for specific execution frameworks. AgencyBench serves as a critical testbed for next-generation agents, highlighting the necessity of co-optimizing model architecture with agentic frameworks. We believe this work sheds light on the future direction of autonomous agents, and we release the full benchmark and evaluation toolkit at https://github.com/GAIR-NLP/AgencyBench."}
{"id": "2601.11286", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11286", "abs": "https://arxiv.org/abs/2601.11286", "authors": ["Weihong Qi", "Fan Huang", "Rasika Muralidharan", "Jisun An", "Haewoon Kwak"], "title": "XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making", "comment": null, "summary": "We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching."}
{"id": "2601.11065", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11065", "abs": "https://arxiv.org/abs/2601.11065", "authors": ["Rachmadita Andreswari", "Stephan A. Fahrenkrog-Petersen", "Jan Mendling"], "title": "Fairness in Healthcare Processes: A Quantitative Analysis of Decision Making in Triage", "comment": "conference", "summary": "Fairness in automated decision-making has become a critical concern, particularly in high-pressure healthcare scenarios such as emergency triage, where fast and equitable decisions are essential. Process mining is increasingly investigating fairness. There is a growing area focusing on fairness-aware algorithms. So far, we know less how these concepts perform on empirical healthcare data or how they cover aspects of justice theory. This study addresses this research problem and proposes a process mining approach to assess fairness in triage by linking real-life event logs with conceptual dimensions of justice. Using the MIMICEL event log (as derived from MIMIC-IV ED), we analyze time, re-do, deviation and decision as process outcomes, and evaluate the influence of age, gender, race, language and insurance using the Kruskal-Wallis, Chi-square and effect size measurements. These outcomes are mapped to justice dimensions to support the development of a conceptual framework. The results demonstrate which aspects of potential unfairness in high-acuity and sub-acute surface. In this way, this study contributes empirical insights that support further research in responsible, fairness-aware process mining in healthcare."}
{"id": "2601.11354", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11354", "abs": "https://arxiv.org/abs/2601.11354", "authors": ["Weiyi Wang", "Xinchi Chen", "Jingjing Gong", "Xuanjing Huang", "Xipeng Qiu"], "title": "AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems", "comment": null, "summary": "Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research."}
{"id": "2601.11089", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11089", "abs": "https://arxiv.org/abs/2601.11089", "authors": ["Suhan Guo", "Jiahong Deng", "Furao Shen"], "title": "MiCA: A Mobility-Informed Causal Adapter for Lightweight Epidemic Forecasting", "comment": null, "summary": "Accurate forecasting of infectious disease dynamics is critical for public health planning and intervention. Human mobility plays a central role in shaping the spatial spread of epidemics, but mobility data are noisy, indirect, and difficult to integrate reliably with disease records. Meanwhile, epidemic case time series are typically short and reported at coarse temporal resolution. These conditions limit the effectiveness of parameter-heavy mobility-aware forecasters that rely on clean and abundant data. In this work, we propose the Mobility-Informed Causal Adapter (MiCA), a lightweight and architecture-agnostic module for epidemic forecasting. MiCA infers mobility relations through causal discovery and integrates them into temporal forecasting models via gated residual mixing. This design allows lightweight forecasters to selectively exploit mobility-derived spatial structure while remaining robust under noisy and data-limited conditions, without introducing heavy relational components such as graph neural networks or full attention. Extensive experiments on four real-world epidemic datasets, including COVID-19 incidence, COVID-19 mortality, influenza, and dengue, show that MiCA consistently improves lightweight temporal backbones, achieving an average relative error reduction of 7.5\\% across forecasting horizons. Moreover, MiCA attains performance competitive with SOTA spatio-temporal models while remaining lightweight."}
{"id": "2601.11389", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11389", "abs": "https://arxiv.org/abs/2601.11389", "authors": ["Hedieh Haddad", "Thibault Falque", "Pierre Talbot", "Pascal Bouvry"], "title": "Hyperparameter Optimization of Constraint Programming Solvers", "comment": "28 pages, 3 figures. Submitted to Journal of Combinatorial Optimization. Special Issue: Recent applications, models and algorithms in Combinatorial Optimization", "summary": "The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.\n  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.\n  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types."}
{"id": "2601.11100", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11100", "abs": "https://arxiv.org/abs/2601.11100", "authors": ["Zhezheng Hao", "Hong Wang", "Jian Luo", "Jianqing Zhang", "Yuyan Zhou", "Qiang Lin", "Can Wang", "Hande Dong", "Jiawei Chen"], "title": "ReCreate: Reasoning and Creating Domain Agents Driven by Experience", "comment": null, "summary": "Large Language Model agents are reshaping the industrial landscape. However, most practical agents remain human-designed because tasks differ widely, making them labor-intensive to build. This situation poses a central question: can we automatically create and adapt domain agents in the wild? While several recent approaches have sought to automate agent creation, they typically treat agent generation as a black-box procedure and rely solely on final performance metrics to guide the process. Such strategies overlook critical evidence explaining why an agent succeeds or fails, and often require high computational costs. To address these limitations, we propose ReCreate, an experience-driven framework for the automatic creation of domain agents. ReCreate systematically leverages agent interaction histories, which provide rich concrete signals on both the causes of success or failure and the avenues for improvement. Specifically, we introduce an agent-as-optimizer paradigm that effectively learns from experience via three key components: (i) an experience storage and retrieval mechanism for on-demand inspection; (ii) a reasoning-creating synergy pipeline that maps execution experience into scaffold edits; and (iii) hierarchical updates that abstract instance-level details into reusable domain patterns. In experiments across diverse domains, ReCreate consistently outperforms human-designed agents and existing automated agent generation methods, even when starting from minimal seed scaffolds."}
{"id": "2601.11468", "categories": ["cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11468", "abs": "https://arxiv.org/abs/2601.11468", "authors": ["Alessandro Padella", "Massimiliano de Leoni", "Marlon Dumas"], "title": "Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs", "comment": "19 pages, 4 figure, TMIS journal submission", "summary": "Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions."}
{"id": "2601.11115", "categories": ["cs.SI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.11115", "abs": "https://arxiv.org/abs/2601.11115", "authors": ["Theofanis P. Raptis", "Chiara Boldrini", "Marco Conti", "Andrea Passarella"], "title": "Sparing User Time with a Socially-Aware Independent Metaverse Avatar", "comment": "Supported by PNNR projects SoBigDatait (IR0000013), FAIR (PE00000013), ICSC (CN00000013)", "summary": "The Metaverse is redefining digital interactions by merging physical, virtual, and social dimensions, yet its effects on social networking remain largely unexplored. This work examines the role of independent avatars (autonomous digital entities capable of managing social interactions on behalf of users), to optimize social time allocation and reshape Metaverse-based Online Social Networks. We propose a novel computational model that integrates a quantitative and realistic representation of user social life, grounded in evolutionary anthropology, with a framework for avatar-mediated interactions. Our model quantifies the effectiveness of a partial replacement of in-person interactions with independent avatar interactions. Additionally, it accounts for social conflicts and specific socialization constraints. We leverage our model to explore the benefits and trade-offs of an avatar-augmented social life in the Metaverse. Since the exact problem formulation leads to an NP-hard optimization problem when incorporating avatars into the social network, we tackle this challenge by introducing a heuristic solution. Through simulations, we compare avatar-mediated and non-avatar-mediated social networking, demonstrating the potential of independent avatars to enhance social connectivity and efficiency. Our findings provide a foundation for optimizing Metaverse-based social interactions, as well as useful insights for future digital social network design."}
{"id": "2601.11479", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11479", "abs": "https://arxiv.org/abs/2601.11479", "authors": ["Yohai Trabelsi", "Guojun Xiong", "Fentabil Getnet", "Stéphane Verguet", "Milind Tambe"], "title": "Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning", "comment": null, "summary": "Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning."}
{"id": "2601.11128", "categories": ["cs.SI", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11128", "abs": "https://arxiv.org/abs/2601.11128", "authors": ["Aldo Cerulli", "Lorenzo Cima", "Benedetta Tessa", "Serena Tardelli", "Stefano Cresci"], "title": "The Big Ban Theory: A Pre- and Post-Intervention Dataset of Online Content Moderation Actions", "comment": null, "summary": "Online platforms rely on moderation interventions to curb harmful behavior such hate speech, toxicity, and the spread of mis- and disinformation. Yet research on the effects and possible biases of such interventions faces multiple limitations. For example, existing works frequently focus on single or a few interventions, due to the absence of comprehensive datasets. As a result, researchers must typically collect the necessary data for each new study, which limits opportunities for systematic comparisons. To overcome these challenges, we introduce The Big Ban Theory (TBBT), a large dataset of moderation interventions. TBBT covers 25 interventions of varying type, severity, and scope, comprising in total over 339K users and nearly 39M posted messages. For each intervention, we provide standardized metadata and pseudonymized user activity collected three months before and after its enforcement, enabling consistent and comparable analyses of intervention effects. In addition, we provide a descriptive exploratory analysis of the dataset, along with several use cases of how it can support research on content moderation. With this dataset, we aim to support researchers studying the effects of moderation interventions and to promote more systematic, reproducible, and comparable research. TBBT is publicly available at: https://doi.org/10.5281/zenodo.18245670."}
{"id": "2601.11492", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11492", "abs": "https://arxiv.org/abs/2601.11492", "authors": ["Kaiwen Wang", "Kaili Zheng", "Rongrong Deng", "Qingmin Fan", "Milin Zhang", "Zongrui Li", "Xuesi Zhou", "Bo Han", "Liren Chen", "Chenyi Guo", "Ji Wu"], "title": "BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics", "comment": null, "summary": "Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports."}
{"id": "2601.11140", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.11140", "abs": "https://arxiv.org/abs/2601.11140", "authors": ["Yuwei Chuai", "Manoel Horta Ribeiro", "Gabriele Lenzini", "Nicolas Pröllochs"], "title": "When \"Likers'' Go Private: Engagement With Reputationally Risky Content on X", "comment": null, "summary": "In June 2024, X/Twitter changed likes' visibility from public to private, offering a rare, platform-level opportunity to study how the visibility of engagement signals affects users' behavior. Here, we investigate whether hiding liker identities increases the number of likes received by high-reputational-risk content, content for which public endorsement may carry high social or reputational costs due to its topic (e.g., politics) or the account context in which it appears (e.g., partisan accounts). To this end, we conduct two complementary studies: 1) a Difference-in-Differences analysis of engagement with 154,122 posts by 1068 accounts before and after the policy change. 2) a within-subject survey experiment with 203 X users on participants' self-reported willingness to like different kinds of content. We find no detectable platform-level increase in likes for high-reputational-risk content (Study 1). This finding is robust for both between-group comparison of high- versus low-reputational-risk accounts and within-group comparison across engagement types (i.e., likes vs. reposts). Additionally, while participants in the survey experiment report modest increases in willingness to like high-reputational-risk content under private versus public visibility, these increases do not lead to significant changes in the group-level average likelihood of liking posts (Study 2). Taken together, our results suggest that hiding likes produces a limited behavioral response at the platform level. This may be caused by a gap between user intention and behavior, or by engagement driven by a narrow set of high-usage or automated accounts."}
{"id": "2511.11689", "categories": ["cs.CY", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.11689", "abs": "https://arxiv.org/abs/2511.11689", "authors": ["Thomas D. Hull", "Lizhe Zhang", "Patricia A. Arean", "Matteo Malgaroli"], "title": "Generative AI Purpose-built for Social and Mental Health: A Real-World Pilot", "comment": null, "summary": "Generative artificial intelligence (GAI) chatbots built for mental health could deliver safe, personalized, and scalable mental health support. We evaluate a foundation model designed for mental health. Adults completed mental health measures while engaging with the chatbot between May 15, 2025 and September 15, 2025. Users completed an opt-in consent, demographic information, mental health symptoms, social connection, and self-identified goals. Measures were repeated every two weeks up to 6 weeks, and a final follow-up at 10 weeks. Analyses included effect sizes, and growth mixture models to identify participant groups and their characteristic engagement, severity, and demographic factors. Users demonstrated significant reductions in PHQ-9 and GAD-7 that were sustained at follow-up. Significant improvements in Hope, Behavioral Activation, Social Interaction, Loneliness, and Perceived Social Support were observed throughout and maintained at 10 week follow-up. Engagement was high and predicted outcomes. Working alliance was comparable to traditional care and predicted outcomes. Automated safety guardrails functioned as designed, with 76 sessions flagged for risk and all handled according to escalation policies. This single arm naturalistic observational study provides initial evidence that a GAI foundation model for mental health can deliver accessible, engaging, effective, and safe mental health support. These results lend support to findings from early randomized designs and offer promise for future study of mental health GAI in real world settings."}
{"id": "2601.11147", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11147", "abs": "https://arxiv.org/abs/2601.11147", "authors": ["Zixu Wang", "Bingbing Xu", "Yige Yuan", "Huawei Shen", "Xueqi Cheng"], "title": "Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems", "comment": "17 pages, 4 figures, 3 tables", "summary": "Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \\textbf{SCALE}, which means \\underline{\\textbf{S}}elf prediction of the optimizer with few shot \\underline{\\textbf{CAL}}ibration for \\underline{\\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \\textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\\%."}
{"id": "2601.11065", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11065", "abs": "https://arxiv.org/abs/2601.11065", "authors": ["Rachmadita Andreswari", "Stephan A. Fahrenkrog-Petersen", "Jan Mendling"], "title": "Fairness in Healthcare Processes: A Quantitative Analysis of Decision Making in Triage", "comment": "conference", "summary": "Fairness in automated decision-making has become a critical concern, particularly in high-pressure healthcare scenarios such as emergency triage, where fast and equitable decisions are essential. Process mining is increasingly investigating fairness. There is a growing area focusing on fairness-aware algorithms. So far, we know less how these concepts perform on empirical healthcare data or how they cover aspects of justice theory. This study addresses this research problem and proposes a process mining approach to assess fairness in triage by linking real-life event logs with conceptual dimensions of justice. Using the MIMICEL event log (as derived from MIMIC-IV ED), we analyze time, re-do, deviation and decision as process outcomes, and evaluate the influence of age, gender, race, language and insurance using the Kruskal-Wallis, Chi-square and effect size measurements. These outcomes are mapped to justice dimensions to support the development of a conceptual framework. The results demonstrate which aspects of potential unfairness in high-acuity and sub-acute surface. In this way, this study contributes empirical insights that support further research in responsible, fairness-aware process mining in healthcare."}
{"id": "2601.11169", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11169", "abs": "https://arxiv.org/abs/2601.11169", "authors": ["Francesco Semeraro", "Filip Bečanović", "Maja Trumić", "Kosta Jovanović", "Angelo Cangelosi"], "title": "How Do Technological Prototypes in the Food Industry Impact People's Perception? Insights from the MUSAE \"GROW, COOK, CODE\" Final Exhibition", "comment": null, "summary": "This work reports the results of the survey carried out during the MUSAE final exhibition to assess its impact on people's perception of aspects like trust in technology, environmental challenges, eating habits and potential increase of mental and physical health while interacting with the technological prototypes exposed during the exhibition. The results show that the exhibition positively increased people's awareness regarding these aspects."}
{"id": "2601.11202", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11202", "abs": "https://arxiv.org/abs/2601.11202", "authors": ["Emanuele Ratti"], "title": "Epistemic Control and the Normativity of Machine Learning-Based Science", "comment": null, "summary": "The past few years have witnessed an increasing use of machine learning (ML) systems in science. Paul Humphreys has argued that, because of specific characteristics of ML systems, human scientists are pushed out of the loop of science. In this chapter, I investigate to what extent this is true. First, I express these concerns in terms of what I call epistemic control. I identify two conditions for epistemic control, called tracking and tracing, drawing on works in philosophy of technology. With this new understanding of the problem, I then argue against Humphreys pessimistic view. Finally, I construct a more nuanced view of epistemic control in ML-based science."}
{"id": "2601.11178", "categories": ["cs.AI", "cs.CL", "cs.MM", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.11178", "abs": "https://arxiv.org/abs/2601.11178", "authors": ["Girish A. Koushik", "Helen Treharne", "Diptesh Kanojia"], "title": "TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech", "comment": "Under review at ICWSM 2026", "summary": "Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as \"black boxes\" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools."}
{"id": "2601.11189", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11189", "abs": "https://arxiv.org/abs/2601.11189", "authors": ["Sofiene Lassoued", "Asrat Gobachew", "Stefan Lier", "Andreas Schwung"], "title": "Policy-Based Deep Reinforcement Learning Hyperheuristics for Job-Shop Scheduling Problems", "comment": null, "summary": "This paper proposes a policy-based deep reinforcement learning hyper-heuristic framework for solving the Job Shop Scheduling Problem. The hyper-heuristic agent learns to switch scheduling rules based on the system state dynamically. We extend the hyper-heuristic framework with two key mechanisms. First, action prefiltering restricts decision-making to feasible low-level actions, enabling low-level heuristics to be evaluated independently of environmental constraints and providing an unbiased assessment. Second, a commitment mechanism regulates the frequency of heuristic switching. We investigate the impact of different commitment strategies, from step-wise switching to full-episode commitment, on both training behavior and makespan. Additionally, we compare two action selection strategies at the policy level: deterministic greedy selection and stochastic sampling. Computational experiments on standard JSSP benchmarks demonstrate that the proposed approach outperforms traditional heuristics, metaheuristics, and recent neural network-based scheduling methods"}
{"id": "2601.11202", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11202", "abs": "https://arxiv.org/abs/2601.11202", "authors": ["Emanuele Ratti"], "title": "Epistemic Control and the Normativity of Machine Learning-Based Science", "comment": null, "summary": "The past few years have witnessed an increasing use of machine learning (ML) systems in science. Paul Humphreys has argued that, because of specific characteristics of ML systems, human scientists are pushed out of the loop of science. In this chapter, I investigate to what extent this is true. First, I express these concerns in terms of what I call epistemic control. I identify two conditions for epistemic control, called tracking and tracing, drawing on works in philosophy of technology. With this new understanding of the problem, I then argue against Humphreys pessimistic view. Finally, I construct a more nuanced view of epistemic control in ML-based science."}
{"id": "2601.11252", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11252", "abs": "https://arxiv.org/abs/2601.11252", "authors": ["Qianyue Wang", "Jinwu Hu", "Yufeng Wang", "Huanxiang Lin", "Bolin Chen", "Zhiquan Wen", "Yaofo Chen", "Mingkui Tan"], "title": "Beyond Model Scaling: Test-Time Intervention for Efficient Deep Reasoning", "comment": null, "summary": "Large Reasoning Models (LRMs) excel at multi-step reasoning but often suffer from inefficient reasoning processes like overthinking and overshoot, where excessive or misdirected reasoning increases computational cost and degrades performance. Existing efficient reasoning methods operate in a closed-loop manner, lacking mechanisms for external intervention to guide the reasoning process. To address this, we propose Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process. Our key insights are that transitional conjunctions serve as natural points for intervention, signaling phases of self-validation or exploration and using transitional words appropriately to prolong the reasoning enhances performance, while excessive use affects performance. Building on these insights, Think-with-Me pauses reasoning at these points for external feedback, adaptively extending or terminating reasoning to reduce redundancy while preserving accuracy. The feedback is generated via a multi-criteria evaluation (rationality and completeness) and comes from either human or LLM proxies. We train the target model using Group Relative Policy Optimization (GRPO) to adapt to this interactive mode. Experiments show that Think-with-Me achieves a superior balance between accuracy and reasoning length under limited context windows. On AIME24, Think-with-Me outperforms QwQ-32B by 7.19% in accuracy while reducing average reasoning length by 81% under an 8K window. The paradigm also benefits security and creative tasks."}
{"id": "2601.11286", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11286", "abs": "https://arxiv.org/abs/2601.11286", "authors": ["Weihong Qi", "Fan Huang", "Rasika Muralidharan", "Jisun An", "Haewoon Kwak"], "title": "XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making", "comment": null, "summary": "We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching."}
{"id": "2601.11338", "categories": ["cs.SI", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.11338", "abs": "https://arxiv.org/abs/2601.11338", "authors": ["Francesca Arrigo", "Fabio Durastante"], "title": "Walk based Laplacians for Modeling Diffusion on Complex Networks", "comment": null, "summary": "We develop a novel framework for modeling diffusion on complex networks by constructing Laplacian-like operators based on walks around a graph. Our approach introduces a parametric family of walk-based Laplacians that naturally incorporate memory effects by excluding or downweighting backtracking trajectories, where walkers immediately revisit nodes. The framework includes: (i) walk-based Laplacians that count all traversals in the network; (ii) nonbacktracking variants that eliminate immediate reversals; and (iii) backtrack-downweighted variants that provide a continuous interpolation between these two regimes. We establish that these operators extend the definition of the standard Laplacian and also preserve some of its properties. We present efficient algorithms using Krylov subspace methods for computing them, ensuring applicability of our proposed framework to large networks. Extensive numerical experiments on real-world networks validate the modeling flexibility of our approach and demonstrate the computational efficiency of the proposed algorithms, including GPU acceleration."}
{"id": "2601.11354", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11354", "abs": "https://arxiv.org/abs/2601.11354", "authors": ["Weiyi Wang", "Xinchi Chen", "Jingjing Gong", "Xuanjing Huang", "Xipeng Qiu"], "title": "AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems", "comment": null, "summary": "Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluating agentic planning in Space Planning Problems (SPP), a family of high-stakes problems with heterogeneous objectives, strict physical constraints, and long-horizon decision-making. AstroReason-Bench integrates multiple scheduling regimes, including ground station communication and agile Earth observation, and provides a unified agent-oriented interaction protocol. Evaluating on a range of state-of-the-art open- and closed-source agentic LLM systems, we find that current agents substantially underperform specialized solvers, highlighting key limitations of generalist planning under realistic constraints. AstroReason-Bench offers a challenging and diagnostic testbed for future agentic research."}
{"id": "2601.11389", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11389", "abs": "https://arxiv.org/abs/2601.11389", "authors": ["Hedieh Haddad", "Thibault Falque", "Pierre Talbot", "Pascal Bouvry"], "title": "Hyperparameter Optimization of Constraint Programming Solvers", "comment": "28 pages, 3 figures. Submitted to Journal of Combinatorial Optimization. Special Issue: Recent applications, models and algorithms in Combinatorial Optimization", "summary": "The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.\n  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.\n  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types."}
{"id": "2601.11468", "categories": ["cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11468", "abs": "https://arxiv.org/abs/2601.11468", "authors": ["Alessandro Padella", "Massimiliano de Leoni", "Marlon Dumas"], "title": "Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs", "comment": "19 pages, 4 figure, TMIS journal submission", "summary": "Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions."}
{"id": "2601.11479", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11479", "abs": "https://arxiv.org/abs/2601.11479", "authors": ["Yohai Trabelsi", "Guojun Xiong", "Fentabil Getnet", "Stéphane Verguet", "Milind Tambe"], "title": "Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning", "comment": null, "summary": "Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning."}
{"id": "2601.11492", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11492", "abs": "https://arxiv.org/abs/2601.11492", "authors": ["Kaiwen Wang", "Kaili Zheng", "Rongrong Deng", "Qingmin Fan", "Milin Zhang", "Zongrui Li", "Xuesi Zhou", "Bo Han", "Liren Chen", "Chenyi Guo", "Ji Wu"], "title": "BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics", "comment": null, "summary": "Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports."}
{"id": "2601.11507", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.11507", "abs": "https://arxiv.org/abs/2601.11507", "authors": ["Joseph Bak-Coleman", "Jevin West", "Cailin O'Connor", "Carl T. Bergstrom"], "title": "Industry Influence in High-Profile Social Media Research", "comment": "11 pages, 4 figures, preprint", "summary": "To what extent is social media research independent from industry influence? Leveraging openly available data, we show that half of the research published in top journals has disclosable ties to industry in the form of prior funding, collaboration, or employment. However, the majority of these ties go undisclosed in the published research. These trends do not arise from broad scientific engagement with industry, but rather from a select group of scientists who maintain long-lasting relationships with industry. Undisclosed ties to industry are common not just among authors, but among reviewers and academic editors during manuscript evaluation. Further, industry-tied research garners more attention within the academy, among policymakers, on social media, and in the news. Finally, we find evidence that industry ties are associated with a topical focus away from impacts of platform-scale features. Together, these findings suggest industry influence in social media research is extensive, impactful, and often opaque. Going forward there is a need to strengthen disclosure norms and implement policies to ensure the visibility of independent research, and the integrity of industry supported research."}
{"id": "2601.11513", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11513", "abs": "https://arxiv.org/abs/2601.11513", "authors": ["Evan Dong", "Nikhil Garg", "Sarah Dean"], "title": "Capacity Constraints Make Admissions Processes Less Predictable", "comment": "This paper was accepted to the 2026 AAAI Conference on Artificial Intelligence AI for Social Impact Track", "summary": "Machine learning models are often used to make predictions about admissions process outcomes, such as for colleges or jobs. However, such decision processes differ substantially from the conventional machine learning paradigm. Because admissions decisions are capacity-constrained, whether a student is admitted depends on the other applicants who apply. We show how this dependence affects predictive performance even in otherwise ideal settings. Theoretically, we introduce two concepts that characterize the relationship between admission function properties, machine learning representation, and generalization to applicant pool distribution shifts: instability, which measures how many existing decisions can change when a single new applicant is introduced; and variability, which measures the number of unique students whose decisions can change. Empirically, we illustrate our theory on individual-level admissions data from the New York City high school matching system, showing that machine learning performance degrades as the applicant pool increasingly differs from the training data. Furthermore, there are larger performance drops for schools using decision rules that are more unstable and variable. Our work raises questions about the reliability of predicting individual admissions probabilities."}
