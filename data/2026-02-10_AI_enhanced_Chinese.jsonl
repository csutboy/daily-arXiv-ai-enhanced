{"id": "2602.07170", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.07170", "abs": "https://arxiv.org/abs/2602.07170", "authors": ["Vadim Sokolov", "Refik Soyer"], "title": "Bayesian Dynamic Gamma Models for Route-Level Travel Time Reliability", "comment": null, "summary": "Route-level travel time reliability requires characterizing the distribution of total travel time across correlated segments -- a problem where existing methods either assume independence (fast but miscalibrated) or model dependence via copulas and simulation (accurate but expensive). We propose a conjugate Bayesian dynamic Gamma model with a common random environment that resolves this trade-off. Each segment's travel time follows a Gamma distribution conditional on a shared latent environment process that evolves as a Markov chain, inducing cross-segment dependence while preserving conditional independence. A moment-matching approximation yields a closed-form $F$-distribution for route travel time, from which the Planning Time Index, Buffer Index, and on-time probability are computed instantly -- at the same $O(1)$ cost as independence-based methods. The conjugate structure ensures that Bayesian posterior updates and the full predictive distribution are available in closed form as new sensor data arrives. Applied to 16 sensors spanning 8.26 miles on I-55 in Chicago, the model achieves 95.4% coverage of nominal 90\\% predictive intervals versus 34--37% for independence-based convolution, at identical computational cost.", "AI": {"tldr": "\u63d0\u51fa\u5171\u8f6d\u8d1d\u53f6\u65af\u52a8\u6001Gamma\u6a21\u578b\uff0c\u901a\u8fc7\u5171\u4eab\u6f5c\u5728\u73af\u5883\u8fc7\u7a0b\u5efa\u6a21\u8def\u6bb5\u65c5\u884c\u65f6\u95f4\u7684\u76f8\u5173\u6027\uff0c\u5b9e\u73b0\u5feb\u901f\u51c6\u786e\u7684\u8def\u6bb5\u7ea7\u65c5\u884c\u65f6\u95f4\u53ef\u9760\u6027\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u8def\u6bb5\u65c5\u884c\u65f6\u95f4\u53ef\u9760\u6027\u5206\u6790\u4e2d\u5b58\u5728\u4e24\u96be\uff1a\u5047\u8bbe\u72ec\u7acb\u6027\u65b9\u6cd5\u5feb\u901f\u4f46\u6821\u51c6\u4e0d\u51c6\uff0c\u800c\u4f9d\u8d56copula\u548c\u6a21\u62df\u7684\u65b9\u6cd5\u51c6\u786e\u4f46\u8ba1\u7b97\u6602\u8d35\u3002\u9700\u8981\u4e00\u79cd\u80fd\u517c\u987e\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5171\u8f6d\u8d1d\u53f6\u65af\u52a8\u6001Gamma\u6a21\u578b\uff0c\u6bcf\u4e2a\u8def\u6bb5\u65c5\u884c\u65f6\u95f4\u5728\u5171\u4eab\u6f5c\u5728\u73af\u5883\u8fc7\u7a0b\u6761\u4ef6\u4e0b\u670d\u4eceGamma\u5206\u5e03\uff0c\u8be5\u73af\u5883\u8fc7\u7a0b\u4f5c\u4e3a\u9a6c\u5c14\u53ef\u592b\u94fe\u6f14\u5316\u3002\u901a\u8fc7\u77e9\u5339\u914d\u8fd1\u4f3c\u5f97\u5230\u8def\u7ebf\u65c5\u884c\u65f6\u95f4\u7684\u95ed\u5f0fF\u5206\u5e03\u3002", "result": "\u5728\u829d\u52a0\u54e5I-55\u516c\u8def16\u4e2a\u4f20\u611f\u56688.26\u82f1\u91cc\u7684\u5e94\u7528\u4e2d\uff0c\u6a21\u578b\u572890%\u9884\u6d4b\u533a\u95f4\u8fbe\u523095.4%\u8986\u76d6\u7387\uff0c\u800c\u57fa\u4e8e\u72ec\u7acb\u6027\u7684\u5377\u79ef\u65b9\u6cd5\u53ea\u670934-37%\u8986\u76d6\u7387\uff0c\u8ba1\u7b97\u6210\u672c\u76f8\u540c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u8def\u6bb5\u65c5\u884c\u65f6\u95f4\u53ef\u9760\u6027\u5206\u6790\u4e2d\u8ba1\u7b97\u6548\u7387\u4e0e\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u63d0\u4f9b\u95ed\u5f0f\u540e\u9a8c\u66f4\u65b0\u548c\u9884\u6d4b\u5206\u5e03\uff0c\u5b9e\u73b0\u4e86\u4e0e\u72ec\u7acb\u6027\u65b9\u6cd5\u76f8\u540c\u8ba1\u7b97\u6210\u672c\u4e0b\u7684\u663e\u8457\u7cbe\u5ea6\u63d0\u5347\u3002"}}
{"id": "2602.07468", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.07468", "abs": "https://arxiv.org/abs/2602.07468", "authors": ["Kunhai Qing", "Xinru Ren", "Jin Xu", "Menggang Yu"], "title": "Consistency Assessment of Regional Treatment Effect for Multi-Regional Clinical Trials in the Presence of Covariate Shift", "comment": null, "summary": "Multi-Regional Clinical Trials (MRCTs) play a central role in the development of new therapies by enabling the simultaneous evaluation of drug efficacy and safety across diverse global populations. Assessing the consistency of treatment effects across regions is a fundamental aspect of MRCTs. Existing methods typically focus on region-specific marginal treatment effects. However, when treatment effect heterogeneity arises due to effect-modifying baseline covariates, distributional differences in these covariates can lead to erroneous conclusions. In this paper, we explicitly account for this phenomenon in the consistency assessment by considering the conditional average treatment effect. We propose a two-step assessment strategy that complements existing methods and mitigates the impact of treatment effect heterogeneity. Results from numerical studies demonstrate the effectiveness of the proposed approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8003\u8651\u6761\u4ef6\u5e73\u5747\u5904\u7406\u6548\u5e94\u7684\u4e24\u9636\u6bb5\u8bc4\u4f30\u7b56\u7565\uff0c\u7528\u4e8e\u591a\u533a\u57df\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u5904\u7406\u6548\u5e94\u4e00\u81f4\u6027\u7684\u8bc4\u4f30\uff0c\u4ee5\u7f13\u89e3\u5904\u7406\u6548\u5e94\u5f02\u8d28\u6027\u548c\u57fa\u7ebf\u534f\u53d8\u91cf\u5206\u5e03\u5dee\u5f02\u5e26\u6765\u7684\u5f71\u54cd\u3002", "motivation": "\u591a\u533a\u57df\u4e34\u5e8a\u8bd5\u9a8c(MRCTs)\u5728\u8bc4\u4f30\u65b0\u7597\u6cd5\u65f6\u9700\u8003\u8651\u5904\u7406\u6548\u5e94\u5728\u4e0d\u540c\u533a\u57df\u7684\u4e00\u81f4\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5173\u6ce8\u533a\u57df\u7279\u5b9a\u7684\u8fb9\u9645\u5904\u7406\u6548\u5e94\uff0c\u4f46\u5f53\u5904\u7406\u6548\u5e94\u5f02\u8d28\u6027\u7531\u57fa\u7ebf\u534f\u53d8\u91cf\u5f15\u8d77\u65f6\uff0c\u534f\u53d8\u91cf\u5206\u5e03\u5dee\u5f02\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u7ed3\u8bba\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u8bc4\u4f30\u7b56\u7565\uff0c\u8003\u8651\u6761\u4ef6\u5e73\u5747\u5904\u7406\u6548\u5e94(CATE)\uff0c\u660e\u786e\u8003\u8651\u5904\u7406\u6548\u5e94\u5f02\u8d28\u6027\u548c\u534f\u53d8\u91cf\u5206\u5e03\u5dee\u5f02\u7684\u5f71\u54cd\uff0c\u4f5c\u4e3a\u73b0\u6709\u65b9\u6cd5\u7684\u8865\u5145\u3002", "result": "\u6570\u503c\u7814\u7a76\u7ed3\u679c\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u8003\u8651\u6761\u4ef6\u5e73\u5747\u5904\u7406\u6548\u5e94\uff0c\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u8bc4\u4f30\u7b56\u7565\u80fd\u591f\u66f4\u597d\u5730\u8bc4\u4f30\u591a\u533a\u57df\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u5904\u7406\u6548\u5e94\u7684\u4e00\u81f4\u6027\uff0c\u7f13\u89e3\u5904\u7406\u6548\u5e94\u5f02\u8d28\u6027\u548c\u534f\u53d8\u91cf\u5206\u5e03\u5dee\u5f02\u5e26\u6765\u7684\u95ee\u9898\u3002"}}
{"id": "2602.07785", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.07785", "abs": "https://arxiv.org/abs/2602.07785", "authors": ["Yufei Zhang", "Zhihao Ma"], "title": "Digital exclusion among middle-aged and older adults in China: age-period-cohort evidence from three national surveys, 2011-2022", "comment": "Also available as a preprint on OSF Preprints:https://osf.io/hpv68_v1", "summary": "Amid China's ageing and digital shift, digital exclusion among older adults poses an urgent challenge. To unpack this phenomenon, this study disentangles age, period, and cohort effects on digital exclusion among middle-aged and older Chinese adults. Using three nationally representative surveys (CHARLS 2011-2020, CFPS 2010-2022, and CGSS 2010-2021), we fitted hierarchical age-period-cohort (HAPC) models weighted by cross-sectional survey weights and stabilized inverse probability weights for item response. We further assessed heterogeneity by urban-rural residence, region, multimorbidity, and cognitive risk, and evaluated robustness with APC bounding analyses. Across datasets, digital exclusion increased with age and displayed mild non-linearity, with a small midlife easing followed by a sharper rise at older ages. Period effects declined over the 2010s and early 2020s, although the pace of improvement differed across survey windows. Cohort deviations were present but less consistent than age and period patterns, with an additional excess risk concentrated among cohorts born in the 1950s. Rural and western residents, as well as adults with multimorbidity or cognitive risk, remained consistently more excluded. Over the study period, the urban-rural divide showed no evidence of narrowing, whereas the cognitive-risk gap widened. These findings highlight digital inclusion as a vital pathway for older adults to remain integral participants in an evolving digital society.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u591a\u5c42\u6b21\u5e74\u9f84-\u65f6\u671f-\u961f\u5217\u6a21\u578b\u5206\u6790\u4e2d\u56fd\u4e2d\u8001\u5e74\u4eba\u6570\u5b57\u6392\u65a5\u73b0\u8c61\uff0c\u53d1\u73b0\u5e74\u9f84\u589e\u957f\u5bfc\u81f4\u6570\u5b57\u6392\u65a5\u589e\u52a0\uff0c\u65f6\u671f\u6548\u5e94\u663e\u793a2010\u5e74\u4ee3\u4ee5\u6765\u6570\u5b57\u6392\u65a5\u6709\u6240\u6539\u5584\uff0c1950\u5e74\u4ee3\u51fa\u751f\u961f\u5217\u98ce\u9669\u8f83\u9ad8\uff0c\u57ce\u4e61\u5dee\u8ddd\u672a\u7f29\u5c0f\u800c\u8ba4\u77e5\u98ce\u9669\u5dee\u8ddd\u6269\u5927\u3002", "motivation": "\u4e2d\u56fd\u9762\u4e34\u4eba\u53e3\u8001\u9f84\u5316\u548c\u6570\u5b57\u5316\u8f6c\u578b\u7684\u53cc\u91cd\u6311\u6218\uff0c\u8001\u5e74\u4eba\u6570\u5b57\u6392\u65a5\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\u3002\u7814\u7a76\u65e8\u5728\u89e3\u6784\u5e74\u9f84\u3001\u65f6\u671f\u548c\u961f\u5217\u6548\u5e94\u5bf9\u4e2d\u56fd\u4e2d\u8001\u5e74\u4eba\u6570\u5b57\u6392\u65a5\u7684\u5f71\u54cd\uff0c\u4e3a\u5236\u5b9a\u9488\u5bf9\u6027\u5e72\u9884\u63aa\u65bd\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u4f7f\u7528\u4e09\u4e2a\u5168\u56fd\u4ee3\u8868\u6027\u8c03\u67e5\u6570\u636e\uff08CHARLS 2011-2020\u3001CFPS 2010-2022\u3001CGSS 2010-2021\uff09\uff0c\u91c7\u7528\u52a0\u6743\u591a\u5c42\u6b21\u5e74\u9f84-\u65f6\u671f-\u961f\u5217\u6a21\u578b\uff0c\u901a\u8fc7\u57ce\u4e61\u5c45\u4f4f\u5730\u3001\u5730\u533a\u3001\u591a\u75c5\u5171\u5b58\u548c\u8ba4\u77e5\u98ce\u9669\u8fdb\u884c\u5f02\u8d28\u6027\u5206\u6790\uff0c\u5e76\u4f7f\u7528APC\u8fb9\u754c\u5206\u6790\u8bc4\u4f30\u7a33\u5065\u6027\u3002", "result": "\u6570\u5b57\u6392\u65a5\u968f\u5e74\u9f84\u589e\u957f\u800c\u589e\u52a0\uff0c\u5448\u73b0\u8f7b\u5ea6\u975e\u7ebf\u6027\u7279\u5f81\uff08\u4e2d\u5e74\u7565\u6709\u7f13\u89e3\uff0c\u8001\u5e74\u6025\u5267\u4e0a\u5347\uff09\uff1b\u65f6\u671f\u6548\u5e94\u57282010\u5e74\u4ee3\u548c2020\u5e74\u4ee3\u521d\u5448\u4e0b\u964d\u8d8b\u52bf\uff1b1950\u5e74\u4ee3\u51fa\u751f\u961f\u5217\u98ce\u9669\u8f83\u9ad8\uff1b\u519c\u6751\u5c45\u6c11\u3001\u897f\u90e8\u5730\u533a\u5c45\u6c11\u3001\u591a\u75c5\u5171\u5b58\u8005\u548c\u8ba4\u77e5\u98ce\u9669\u8005\u6570\u5b57\u6392\u65a5\u66f4\u4e25\u91cd\uff1b\u57ce\u4e61\u5dee\u8ddd\u672a\u7f29\u5c0f\uff0c\u8ba4\u77e5\u98ce\u9669\u5dee\u8ddd\u6269\u5927\u3002", "conclusion": "\u6570\u5b57\u5305\u5bb9\u662f\u786e\u4fdd\u8001\u5e74\u4eba\u5728\u4e0d\u65ad\u53d1\u5c55\u7684\u6570\u5b57\u793e\u4f1a\u4e2d\u4fdd\u6301\u91cd\u8981\u53c2\u4e0e\u8005\u7684\u5173\u952e\u9014\u5f84\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u9700\u8981\u9488\u5bf9\u7279\u5b9a\u5f31\u52bf\u7fa4\u4f53\uff08\u5982\u519c\u6751\u5c45\u6c11\u3001\u8ba4\u77e5\u98ce\u9669\u8005\uff09\u5236\u5b9a\u5dee\u5f02\u5316\u6570\u5b57\u5305\u5bb9\u653f\u7b56\uff0c\u4ee5\u7f29\u5c0f\u6570\u5b57\u9e3f\u6c9f\u3002"}}
{"id": "2602.07911", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.07911", "abs": "https://arxiv.org/abs/2602.07911", "authors": ["Ping Zhao", "Fengyi Song", "Huifang Ma"], "title": "Adaptive Test Procedure for High Dimensional Regression Coefficient", "comment": null, "summary": "We develop a unified $L$-statistic testing framework for high-dimensional regression coefficients that adapts to unknown sparsity. The proposed statistics rank coordinate-wise evidence measures and aggregate the top $k$ signals, bridging classical max-type and sum-type tests. We establish joint weak convergence of the extreme-value component and standardized $L$-statistics under mild conditions, yielding an asymptotic independence that justifies combining multiple $k$'s. An adaptive omnibus test is constructed via a Cauchy combination over a dyadic grid of $k$, and a wild bootstrap calibration is provided with theoretical guarantees. Simulations demonstrate accurate size and strong power across sparse and dense alternatives, including non-Gaussian designs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684L-\u7edf\u8ba1\u91cf\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u7ef4\u56de\u5f52\u7cfb\u6570\uff0c\u80fd\u9002\u5e94\u672a\u77e5\u7a00\u758f\u6027\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u6392\u5e8f\u5750\u6807\u8bc1\u636e\u5ea6\u91cf\u5e76\u805a\u5408\u524dk\u4e2a\u4fe1\u53f7\uff0c\u6865\u63a5\u4e86\u7ecf\u5178\u7684\u6700\u5927\u503c\u548c\u6c42\u548c\u578b\u6d4b\u8bd5\u3002", "motivation": "\u5728\u9ad8\u7ef4\u56de\u5f52\u5206\u6790\u4e2d\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u9002\u5e94\u672a\u77e5\u7a00\u758f\u6027\u7684\u6d4b\u8bd5\u65b9\u6cd5\u3002\u4f20\u7edf\u65b9\u6cd5\u8981\u4e48\u662f\u6700\u5927\u503c\u578b\u6d4b\u8bd5\uff08\u9002\u5408\u7a00\u758f\u4fe1\u53f7\uff09\uff0c\u8981\u4e48\u662f\u6c42\u548c\u578b\u6d4b\u8bd5\uff08\u9002\u5408\u5bc6\u96c6\u4fe1\u53f7\uff09\uff0c\u4f46\u5b9e\u9645\u6570\u636e\u7a00\u758f\u6027\u672a\u77e5\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1L-\u7edf\u8ba1\u91cf\u6d4b\u8bd5\u6846\u67b6\uff1a1\uff09\u5bf9\u5750\u6807\u8bc1\u636e\u5ea6\u91cf\u8fdb\u884c\u6392\u5e8f\uff1b2\uff09\u805a\u5408\u524dk\u4e2a\u4fe1\u53f7\uff1b3\uff09\u5efa\u7acb\u6781\u503c\u5206\u91cf\u548c\u6807\u51c6\u5316L-\u7edf\u8ba1\u91cf\u7684\u8054\u5408\u5f31\u6536\u655b\u7406\u8bba\uff1b4\uff09\u5229\u7528\u6e10\u8fd1\u72ec\u7acb\u6027\u7ec4\u5408\u591a\u4e2ak\u503c\uff1b5\uff09\u901a\u8fc7Cauchy\u7ec4\u5408\u6784\u5efa\u81ea\u9002\u5e94omnibus\u6d4b\u8bd5\uff1b6\uff09\u63d0\u4f9bwild bootstrap\u6821\u51c6\u3002", "result": "\u7406\u8bba\u8bc1\u660e\uff1a\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u5efa\u7acb\u6781\u503c\u5206\u91cf\u548c\u6807\u51c6\u5316L-\u7edf\u8ba1\u91cf\u7684\u8054\u5408\u5f31\u6536\u655b\uff0c\u83b7\u5f97\u6e10\u8fd1\u72ec\u7acb\u6027\u3002\u6a21\u62df\u663e\u793a\uff1a\u5728\u7a00\u758f\u548c\u5bc6\u96c6\u5907\u62e9\u4e0b\u90fd\u6709\u51c6\u786e\u7684size\u548c\u5f3a\u5927\u7684power\uff0c\u5305\u62ec\u975e\u9ad8\u65af\u8bbe\u8ba1\u3002", "conclusion": "\u63d0\u51fa\u7684L-\u7edf\u8ba1\u91cf\u6846\u67b6\u4e3a\u9ad8\u7ef4\u56de\u5f52\u7cfb\u6570\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u5904\u7406\u672a\u77e5\u7a00\u758f\u6027\uff0c\u6865\u63a5\u4e86\u6700\u5927\u503c\u578b\u548c\u6c42\u548c\u578b\u6d4b\u8bd5\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u826f\u597d\u7684\u5b9e\u9645\u6027\u80fd\u3002"}}
{"id": "2602.07146", "categories": ["cs.ET", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2602.07146", "abs": "https://arxiv.org/abs/2602.07146", "authors": ["Alexander J. Edwards", "Son T. Le", "Nicholas W. G. Smith", "Ebenezer C. Usih", "Austin Thomas", "Christopher J. K. Richardson", "Nicholas A. Blumenschein", "Aubrey T. Hanbicki", "Adam L. Friedman", "Joseph S. Friedman"], "title": "Magnetic Field-Mediated Superconducting Logic", "comment": null, "summary": "While superconductors are highly attractive for energy-efficient computing, fundamental limitations in their logic circuit integration have hindered scaling and led to increased energy consumption. We therefore propose and experimentally demonstrate a novel superconducting switching device utilizing the proximity magnetization from a spin-orbit torque-switched magnet to control the resistivity of a superconductor. We further propose a complete logic family comprised solely of these devices. This novel implementation has the potential to drastically outperform existing superconducting logic families in terms of energy efficiency and scalability.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e00\u79cd\u65b0\u578b\u8d85\u5bfc\u5f00\u5173\u5668\u4ef6\uff0c\u5229\u7528\u81ea\u65cb\u8f68\u9053\u529b\u77e9\u5207\u6362\u78c1\u4f53\u7684\u90bb\u8fd1\u78c1\u5316\u6548\u5e94\u63a7\u5236\u8d85\u5bfc\u4f53\u7535\u963b\u7387\uff0c\u6784\u5efa\u4e86\u5b8c\u6574\u7684\u903b\u8f91\u95e8\u5bb6\u65cf\uff0c\u6709\u671b\u5927\u5e45\u63d0\u5347\u8d85\u5bfc\u903b\u8f91\u7684\u80fd\u91cf\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u8d85\u5bfc\u4f53\u5728\u8282\u80fd\u8ba1\u7b97\u4e2d\u5177\u6709\u5438\u5f15\u529b\uff0c\u4f46\u4f20\u7edf\u8d85\u5bfc\u903b\u8f91\u7535\u8def\u96c6\u6210\u5b58\u5728\u57fa\u672c\u9650\u5236\uff0c\u963b\u788d\u4e86\u89c4\u6a21\u5316\u5e76\u5bfc\u81f4\u80fd\u8017\u589e\u52a0\u3002\u9700\u8981\u5f00\u53d1\u65b0\u7684\u8d85\u5bfc\u5f00\u5173\u5668\u4ef6\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u9a8c\u6f14\u793a\u4e86\u4e00\u79cd\u65b0\u578b\u8d85\u5bfc\u5f00\u5173\u5668\u4ef6\uff1a\u5229\u7528\u81ea\u65cb\u8f68\u9053\u529b\u77e9\u5207\u6362\u78c1\u4f53\u4ea7\u751f\u7684\u90bb\u8fd1\u78c1\u5316\u6548\u5e94\u6765\u63a7\u5236\u8d85\u5bfc\u4f53\u7684\u7535\u963b\u7387\u3002\u8fdb\u4e00\u6b65\u6784\u5efa\u4e86\u5b8c\u5168\u7531\u8fd9\u4e9b\u5668\u4ef6\u7ec4\u6210\u7684\u5b8c\u6574\u903b\u8f91\u95e8\u5bb6\u65cf\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b0\u578b\u8d85\u5bfc\u5f00\u5173\u5668\u4ef6\u7684\u53ef\u884c\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5b8c\u6574\u903b\u8f91\u95e8\u5bb6\u65cf\u7684\u8bbe\u8ba1\u65b9\u6848\u3002", "conclusion": "\u8fd9\u79cd\u65b0\u578b\u5b9e\u73b0\u65b9\u6848\u5728\u80fd\u91cf\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u6709\u6f5c\u529b\u5927\u5e45\u8d85\u8d8a\u73b0\u6709\u7684\u8d85\u5bfc\u903b\u8f91\u5bb6\u65cf\uff0c\u4e3a\u8d85\u5bfc\u8ba1\u7b97\u63d0\u4f9b\u4e86\u65b0\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2602.07377", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.07377", "abs": "https://arxiv.org/abs/2602.07377", "authors": ["Xinyue Bei", "Manu Navjeevan"], "title": "Inference under First-Order Degeneracy", "comment": null, "summary": "We study inference in models where a transformation of parameters exhibits first-order degeneracy -- that is, its gradient is zero or close to zero, making the standard delta method invalid. A leading example is causal mediation analysis, where the indirect effect is a product of coefficients and the gradient degenerates near the origin. In these local regions of degeneracy the limiting behaviors of plug-in estimators depend on nuisance parameters that are not consistently estimable. We show that this failure is intrinsic -- around points of degeneracy, both regular and quantile-unbiased estimation are impossible. Despite these restrictions, we develop minimum-distance methods that deliver uniformly valid confidence intervals. We establish sufficient conditions under which standard chi-square critical values remain valid, and propose a simple bootstrap procedure when they are not. We demonstrate favorable power in simulations and in an empirical application linking teacher gender attitudes to student outcomes.", "AI": {"tldr": "\u7814\u7a76\u53c2\u6570\u53d8\u6362\u5b58\u5728\u4e00\u9636\u9000\u5316\uff08\u68af\u5ea6\u4e3a\u96f6\u6216\u63a5\u8fd1\u96f6\uff09\u65f6\u7684\u7edf\u8ba1\u63a8\u65ad\u95ee\u9898\uff0c\u4ee5\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\uff08\u95f4\u63a5\u6548\u5e94\u4e3a\u7cfb\u6570\u4e58\u79ef\uff09\u4e3a\u4f8b\uff0c\u63d0\u51fa\u5728\u9000\u5316\u533a\u57df\u6784\u5efa\u4e00\u81f4\u6709\u6548\u7f6e\u4fe1\u533a\u95f4\u7684\u65b9\u6cd5\u3002", "motivation": "\u5f53\u53c2\u6570\u53d8\u6362\u7684\u68af\u5ea6\u4e3a\u96f6\u6216\u63a5\u8fd1\u96f6\u65f6\uff08\u5982\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\u4e2d\u7684\u95f4\u63a5\u6548\u5e94\u662f\u7cfb\u6570\u4e58\u79ef\uff09\uff0c\u6807\u51c6\u7684delta\u65b9\u6cd5\u5931\u6548\u3002\u5728\u9000\u5316\u533a\u57df\u9644\u8fd1\uff0c\u4f30\u8ba1\u91cf\u7684\u6781\u9650\u884c\u4e3a\u4f9d\u8d56\u4e8e\u65e0\u6cd5\u4e00\u81f4\u4f30\u8ba1\u7684\u5197\u4f59\u53c2\u6570\uff0c\u5bfc\u81f4\u5e38\u89c4\u63a8\u65ad\u65b9\u6cd5\u4e0d\u53ef\u884c\u3002", "method": "\u5f00\u53d1\u6700\u5c0f\u8ddd\u79bb\u65b9\u6cd5\u6784\u5efa\u4e00\u81f4\u6709\u6548\u7684\u7f6e\u4fe1\u533a\u95f4\u3002\u5efa\u7acb\u6807\u51c6\u5361\u65b9\u4e34\u754c\u503c\u4fdd\u6301\u6709\u6548\u7684\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u5728\u4e0d\u6ee1\u8db3\u6761\u4ef6\u65f6\u63d0\u51fa\u7b80\u5355\u7684\u81ea\u52a9\u6cd5\u7a0b\u5e8f\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u9000\u5316\u70b9\u9644\u8fd1\uff0c\u6b63\u5219\u4f30\u8ba1\u548c\u5206\u4f4d\u6570\u65e0\u504f\u4f30\u8ba1\u90fd\u662f\u4e0d\u53ef\u80fd\u7684\u3002\u4f46\u63d0\u51fa\u7684\u6700\u5c0f\u8ddd\u79bb\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u4e00\u81f4\u6709\u6548\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u5728\u6a21\u62df\u548c\u5b9e\u8bc1\u5e94\u7528\uff08\u6559\u5e08\u6027\u522b\u6001\u5ea6\u5bf9\u5b66\u751f\u6210\u7ee9\u7684\u5f71\u54cd\uff09\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u529f\u6548\u3002", "conclusion": "\u5c3d\u7ba1\u5728\u53c2\u6570\u53d8\u6362\u5b58\u5728\u4e00\u9636\u9000\u5316\u7684\u6a21\u578b\u4e2d\uff0c\u4f20\u7edf\u63a8\u65ad\u65b9\u6cd5\u5728\u9000\u5316\u533a\u57df\u9644\u8fd1\u5931\u6548\uff0c\u4f46\u901a\u8fc7\u6700\u5c0f\u8ddd\u79bb\u65b9\u6cd5\u548c\u9002\u5f53\u7684\u4e34\u754c\u503c\u9009\u62e9\uff0c\u4ecd\u7136\u53ef\u4ee5\u6784\u5efa\u4e00\u81f4\u6709\u6548\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u4e3a\u8fd9\u7c7b\u6a21\u578b\u7684\u7edf\u8ba1\u63a8\u65ad\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07248", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.07248", "abs": "https://arxiv.org/abs/2602.07248", "authors": ["Stephanie Birkelbach", "Maria Teleki", "Peter Carragher", "Xiangjue Dong", "Nehul Bhatnagar", "James Caverlee"], "title": "SocialPulse: An Open-Source Subreddit Sensemaking Toolkit", "comment": null, "summary": "Understanding how online communities discuss and make sense of complex social issues is a central challenge in social media research, yet existing tools for large-scale discourse analysis are often closed-source, difficult to adapt, or limited to single analytical views. We present SocialPulse, an open-source subreddit sensemaking toolkit that unifies multiple complementary analyses -- topic modeling, sentiment analysis, user activity characterization, and bot detection -- within a single interactive system. SocialPulse enables users to fluidly move between aggregate trends and fine-grained content, compare highly active and long-tail contributors, and examine temporal shifts in discourse across subreddits. The demo showcases end-to-end exploratory workflows that allow researchers and practitioners to rapidly surface themes, participation patterns, and emerging dynamics in large Reddit datasets. By offering an extensible and openly available platform, SocialPulse provides a practical and reusable foundation for transparent, reproducible sensemaking of online community discourse.", "AI": {"tldr": "SocialPulse\u662f\u4e00\u4e2a\u5f00\u6e90\u7684Reddit\u793e\u533a\u7406\u89e3\u5de5\u5177\u5305\uff0c\u6574\u5408\u4e86\u4e3b\u9898\u5efa\u6a21\u3001\u60c5\u611f\u5206\u6790\u3001\u7528\u6237\u6d3b\u52a8\u7279\u5f81\u5206\u6790\u548c\u673a\u5668\u4eba\u68c0\u6d4b\u7b49\u591a\u79cd\u5206\u6790\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u7cfb\u7edf\u5e2e\u52a9\u7814\u7a76\u8005\u5206\u6790\u5728\u7ebf\u793e\u533a\u8ba8\u8bba\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u89c4\u6a21\u8bdd\u8bed\u5206\u6790\u5de5\u5177\u901a\u5e38\u662f\u95ed\u6e90\u7684\u3001\u96be\u4ee5\u9002\u5e94\u6216\u4ec5\u9650\u4e8e\u5355\u4e00\u5206\u6790\u89c6\u56fe\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5728\u7ebf\u793e\u533a\u590d\u6742\u793e\u4f1a\u8bae\u9898\u8ba8\u8bba\u7684\u5206\u6790\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u7edf\u4e00\u6574\u5408\u4e86\u4e3b\u9898\u5efa\u6a21\u3001\u60c5\u611f\u5206\u6790\u3001\u7528\u6237\u6d3b\u52a8\u7279\u5f81\u5206\u6790\u548c\u673a\u5668\u4eba\u68c0\u6d4b\u7b49\u591a\u79cd\u4e92\u8865\u5206\u6790\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u4ea4\u4e92\u5f0f\u7cfb\u7edf\uff0c\u652f\u6301\u7528\u6237\u5728\u805a\u5408\u8d8b\u52bf\u548c\u7ec6\u7c92\u5ea6\u5185\u5bb9\u4e4b\u95f4\u6d41\u7545\u5207\u6362\u3002", "result": "SocialPulse\u80fd\u591f\u5e2e\u52a9\u7528\u6237\u6bd4\u8f83\u9ad8\u6d3b\u8dc3\u5ea6\u548c\u957f\u5c3e\u8d21\u732e\u8005\uff0c\u68c0\u67e5\u8de8subreddit\u7684\u8bdd\u8bed\u65f6\u95f4\u53d8\u5316\uff0c\u5feb\u901f\u53d1\u73b0\u5927\u578bReddit\u6570\u636e\u96c6\u4e2d\u7684\u4e3b\u9898\u3001\u53c2\u4e0e\u6a21\u5f0f\u548c\u65b0\u5174\u52a8\u6001\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u53ef\u6269\u5c55\u548c\u5f00\u653e\u53ef\u7528\u7684\u5e73\u53f0\uff0cSocialPulse\u4e3a\u5728\u7ebf\u793e\u533a\u8bdd\u8bed\u7684\u900f\u660e\u3001\u53ef\u91cd\u590d\u7406\u89e3\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u91cd\u7528\u7684\u57fa\u7840\u3002"}}
{"id": "2602.06980", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.06980", "abs": "https://arxiv.org/abs/2602.06980", "authors": ["Nasir Rajpoot", "Richard Haworth", "Xavier Palazzi", "Alok Sharma", "Manu Sebastian", "Stephen Cahalan", "Dinesh S. Bangari", "Radhakrishna Sura", "James Hartke", "Marco Tecilla", "Krishna Yekkala", "Simon Graham", "Dang Vu", "David Snead", "Mostafa Jahanifar", "Adnan Khan", "Erio Barale-Thomas"], "title": "Potential Role of Agentic Artificial Intelligence in Toxicologic Pathology", "comment": null, "summary": "As the volume and complexity of nonclinical toxicology studies continue to increase, toxicologic pathology reporting faces persistent challenges, including fragmented sources of data (e.g., histopathology images, clinical pathology and other study data, adverse effects database, mechanistic literature), variable reporting timelines and heightened regulatory expectations. This white paper examines the emerging role of agentic artificial intelligence (AI) in addressing these issues through coordinated workflow orchestration, data integration, and pathologist-in-the-loop report generation. Based on a closed-door roundtable held during the 2025 Society of Toxicologic Pathology (STP) Annual Meeting and follow-on discussions, this paper synthesizes the perspectives of leading toxicologic pathologists, toxicologists, and AI developers. It outlines the key pain points in current reporting workflows, identifies realistic near-term use cases for agentic AI, and describes major adoption barriers including requirements for transparency, validation, and organizational readiness. A phased adoption roadmap and pilot design considerations are proposed to help support responsible evaluation and deployment of agentic AI system in nonclinical settings. The paper concludes by emphasizing the need for coordinated efforts across pharmaceutical organizations, CROs, academia, and regulators to establish shared standards, benchmarks, and governance frameworks that will lead to safe, transparent, and trustworthy integration of AI into toxicologic science.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u975e\u4e34\u5e8a\u6bd2\u7406\u5b66\u7814\u7a76\u4e2d\u5e94\u7528\u667a\u80fd\u4f53AI\u89e3\u51b3\u75c5\u7406\u62a5\u544a\u5de5\u4f5c\u6d41\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u5206\u9636\u6bb5\u91c7\u7528\u8def\u7ebf\u56fe\uff0c\u5f3a\u8c03\u9700\u8981\u8de8\u884c\u4e1a\u534f\u4f5c\u5efa\u7acb\u6807\u51c6\u3002", "motivation": "\u975e\u4e34\u5e8a\u6bd2\u7406\u5b66\u7814\u7a76\u7684\u6570\u91cf\u548c\u590d\u6742\u6027\u4e0d\u65ad\u589e\u52a0\uff0c\u6bd2\u7406\u5b66\u75c5\u7406\u62a5\u544a\u9762\u4e34\u6570\u636e\u6765\u6e90\u5206\u6563\u3001\u62a5\u544a\u65f6\u95f4\u4e0d\u4e00\u3001\u76d1\u7ba1\u8981\u6c42\u63d0\u9ad8\u7b49\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u6539\u8fdb\u5de5\u4f5c\u6d41\u7a0b\u3002", "method": "\u57fa\u4e8e2025\u5e74\u6bd2\u7406\u5b66\u75c5\u7406\u5b66\u4f1a\u5e74\u4f1a\u95ed\u95e8\u5706\u684c\u4f1a\u8bae\u548c\u540e\u7eed\u8ba8\u8bba\uff0c\u7efc\u5408\u6bd2\u7406\u5b66\u75c5\u7406\u5b66\u5bb6\u3001\u6bd2\u7406\u5b66\u5bb6\u548cAI\u5f00\u53d1\u8005\u7684\u89c2\u70b9\uff0c\u5206\u6790\u5f53\u524d\u62a5\u544a\u5de5\u4f5c\u6d41\u75db\u70b9\uff0c\u8bc6\u522b\u667a\u80fd\u4f53AI\u7684\u73b0\u5b9e\u5e94\u7528\u573a\u666f\u3002", "result": "\u786e\u5b9a\u4e86\u667a\u80fd\u4f53AI\u5728\u534f\u8c03\u5de5\u4f5c\u6d41\u7f16\u6392\u3001\u6570\u636e\u6574\u5408\u548c\u75c5\u7406\u5b66\u5bb6\u53c2\u4e0e\u7684\u62a5\u544a\u751f\u6210\u65b9\u9762\u7684\u6f5c\u5728\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u5206\u9636\u6bb5\u91c7\u7528\u8def\u7ebf\u56fe\u548c\u8bd5\u70b9\u8bbe\u8ba1\u8003\u8651\uff0c\u8bc6\u522b\u4e86\u900f\u660e\u5ea6\u3001\u9a8c\u8bc1\u548c\u7ec4\u7ec7\u51c6\u5907\u7b49\u4e3b\u8981\u91c7\u7528\u969c\u788d\u3002", "conclusion": "\u9700\u8981\u5236\u836f\u7ec4\u7ec7\u3001CRO\u3001\u5b66\u672f\u754c\u548c\u76d1\u7ba1\u673a\u6784\u534f\u8c03\u52aa\u529b\uff0c\u5efa\u7acb\u5171\u4eab\u6807\u51c6\u3001\u57fa\u51c6\u548c\u6cbb\u7406\u6846\u67b6\uff0c\u4ee5\u786e\u4fddAI\u5728\u6bd2\u7406\u5b66\u79d1\u5b66\u4e2d\u7684\u5b89\u5168\u3001\u900f\u660e\u548c\u53ef\u4fe1\u6574\u5408\u3002"}}
{"id": "2602.07032", "categories": ["cs.AI", "cs.AR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07032", "abs": "https://arxiv.org/abs/2602.07032", "authors": ["Yuheng Wu", "Berk Gokmen", "Zhouhua Xie", "Peijing Li", "Caroline Trippel", "Priyanka Raina", "Thierry Tambe"], "title": "LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation", "comment": null, "summary": "Finite-state reasoning, the ability to understand and implement state-dependent behavior, is central to hardware design. In this paper, we present LLM-FSM, a benchmark that evaluates how well large language models (LLMs) can recover finite-state machine (FSM) behavior from natural-language specifications and translate it into correct register transfer-level (RTL) implementations. Unlike prior specification-to-RTL benchmarks that rely on manually constructed examples, LLM-FSM is built through a fully automated pipeline. LLM-FSM first constructs FSM with configurable state counts and constrained transition structures. It then prompts LLMs to express each FSM in a structured YAML format with an application context, and to further convert that YAML into a natural-language (NL) specification. From the same YAML, our pipeline synthesizes the reference RTL and testbench in a correct-by-construction manner. All 1,000 problems are verified using LLM-based and SAT-solver-based checks, with human review on a subset. Our experiments show that even the strongest LLMs exhibit sharply declining accuracy as FSM complexity increases. We further demonstrate that training-time scaling via supervised fine-tuning (SFT) generalizes effectively to out-of-distribution (OOD) tasks, while increasing test-time compute improves reasoning reliability. Finally, LLM-FSM remains extensible by allowing its FSM complexity to scale with future model capabilities.", "AI": {"tldr": "LLM-FSM\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u4e2d\u6062\u590d\u6709\u9650\u72b6\u6001\u673a\u884c\u4e3a\u5e76\u751f\u6210\u6b63\u786eRTL\u5b9e\u73b0\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b1000\u4e2a\u81ea\u52a8\u751f\u6210\u7684\u95ee\u9898\uff0c\u663e\u793aLLM\u5728FSM\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u51c6\u786e\u7387\u6025\u5267\u4e0b\u964d\u3002", "motivation": "\u6709\u9650\u72b6\u6001\u63a8\u7406\u662f\u786c\u4ef6\u8bbe\u8ba1\u7684\u6838\u5fc3\u80fd\u529b\uff0c\u9700\u8981\u8bc4\u4f30LLM\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u4e2d\u6062\u590dFSM\u884c\u4e3a\u5e76\u751f\u6210\u6b63\u786eRTL\u5b9e\u73b0\u7684\u80fd\u529b\u3002\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4f9d\u8d56\u4eba\u5de5\u6784\u5efa\u793a\u4f8b\uff0c\u7f3a\u4e4f\u81ea\u52a8\u5316\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u901a\u8fc7\u5168\u81ea\u52a8\u6d41\u6c34\u7ebf\u6784\u5efaLLM-FSM\u57fa\u51c6\uff1a1) \u6784\u5efa\u5177\u6709\u53ef\u914d\u7f6e\u72b6\u6001\u6570\u548c\u7ea6\u675f\u8f6c\u6362\u7ed3\u6784\u7684FSM\uff1b2) \u63d0\u793aLLM\u5c06FSM\u8868\u8fbe\u4e3a\u7ed3\u6784\u5316YAML\u683c\u5f0f\u5e76\u6dfb\u52a0\u5e94\u7528\u4e0a\u4e0b\u6587\uff1b3) \u5c06YAML\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u89c4\u8303\uff1b4) \u4ece\u540c\u4e00YAML\u4ee5\u6784\u9020\u6b63\u786e\u7684\u65b9\u5f0f\u5408\u6210\u53c2\u8003RTL\u548c\u6d4b\u8bd5\u5e73\u53f0\uff1b5) \u4f7f\u7528LLM\u548cSAT\u6c42\u89e3\u5668\u68c0\u67e5\u9a8c\u8bc1\u6240\u67091000\u4e2a\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5373\u4f7f\u6700\u5f3a\u7684LLM\u5728FSM\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u51c6\u786e\u7387\u4e5f\u6025\u5267\u4e0b\u964d\u3002\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u7684\u8bad\u7ec3\u65f6\u6269\u5c55\u80fd\u6709\u6548\u6cdb\u5316\u5230\u5206\u5e03\u5916\u4efb\u52a1\uff0c\u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u80fd\u63d0\u9ad8\u63a8\u7406\u53ef\u9760\u6027\u3002LLM-FSM\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u5176FSM\u590d\u6742\u5ea6\u53ef\u968f\u672a\u6765\u6a21\u578b\u80fd\u529b\u6269\u5c55\u3002", "conclusion": "LLM-FSM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u6709\u9650\u72b6\u6001\u63a8\u7406\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u590d\u6742FSM\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u8bad\u7ec3\u548c\u6d4b\u8bd5\u7b56\u7565\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002"}}
{"id": "2602.07935", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.07935", "abs": "https://arxiv.org/abs/2602.07935", "authors": ["Afshin Yaghoubi"], "title": "Analysis of Repairable Systems Availability with Lindley Failure and Repair Behavior", "comment": null, "summary": "Maintainability analysis is a cornerstone of reliability engineering. While the Markov approach is the classical analytical foundation, its reliance on the exponential distribution for failure and repair times is a major and often unrealistic limitation. This paper directly overcomes this critical constraint by investigating and modeling system maintainability using the more flexible and versatile Lindley distribution, which is represented via phase-type distributions. We first present a comprehensive maintainability analysis of a single-component system, deriving precise closed-form expressions for its time-dependent and steady-state availability, as well as the mean time to repair. The core methodology is then systematically generalized to analyze common series and parallel system configurations with n independent and identically distributed components. A dedicated numerical study compares the system performance under the Lindley and exponential distributions, conclusively demonstrating the significant and practical impact of non-exponential repair times on key reliability metrics. Our work provides a versatile and more widely applicable analytical framework for accurate maintainability assessment that successfully relaxes the restrictive exponential assumption, thereby offering greater realism in reliability modeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u66f4\u7075\u6d3b\u7684Lindley\u5206\u5e03\u66ff\u4ee3\u4f20\u7edf\u9a6c\u5c14\u53ef\u592b\u65b9\u6cd5\u4e2d\u7684\u6307\u6570\u5206\u5e03\uff0c\u5bf9\u7cfb\u7edf\u53ef\u7ef4\u62a4\u6027\u8fdb\u884c\u5206\u6790\uff0c\u5efa\u7acb\u4e86\u5355\u7ec4\u4ef6\u53ca\u4e32\u5e76\u8054\u7cfb\u7edf\u7684\u53ef\u7ef4\u62a4\u6027\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u975e\u6307\u6570\u4fee\u590d\u65f6\u95f4\u5bf9\u53ef\u9760\u6027\u6307\u6807\u7684\u663e\u8457\u5f71\u54cd\u3002", "motivation": "\u4f20\u7edf\u9a6c\u5c14\u53ef\u592b\u65b9\u6cd5\u4f9d\u8d56\u6307\u6570\u5206\u5e03\u6765\u63cf\u8ff0\u6545\u969c\u548c\u4fee\u590d\u65f6\u95f4\uff0c\u8fd9\u4e00\u5047\u8bbe\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5f80\u5f80\u4e0d\u73b0\u5b9e\uff0c\u9650\u5236\u4e86\u53ef\u9760\u6027\u5de5\u7a0b\u4e2d\u53ef\u7ef4\u62a4\u6027\u5206\u6790\u7684\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u66f4\u7075\u6d3b\u901a\u7528\u7684Lindley\u5206\u5e03\uff08\u901a\u8fc7\u9636\u6bb5\u578b\u5206\u5e03\u8868\u793a\uff09\u6765\u5efa\u6a21\u7cfb\u7edf\u53ef\u7ef4\u62a4\u6027\u3002\u9996\u5148\u5bf9\u5355\u7ec4\u4ef6\u7cfb\u7edf\u8fdb\u884c\u5b8c\u6574\u5206\u6790\uff0c\u63a8\u5bfc\u65f6\u95f4\u76f8\u5173\u548c\u7a33\u6001\u53ef\u7528\u6027\u3001\u5e73\u5747\u4fee\u590d\u65f6\u95f4\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u7136\u540e\u5c06\u65b9\u6cd5\u63a8\u5e7f\u5230n\u4e2a\u72ec\u7acb\u540c\u5206\u5e03\u7ec4\u4ef6\u7684\u4e32\u5e76\u8054\u7cfb\u7edf\u914d\u7f6e\u3002", "result": "\u901a\u8fc7\u6570\u503c\u7814\u7a76\u6bd4\u8f83Lindley\u5206\u5e03\u548c\u6307\u6570\u5206\u5e03\u4e0b\u7684\u7cfb\u7edf\u6027\u80fd\uff0c\u660e\u786e\u8bc1\u660e\u4e86\u975e\u6307\u6570\u4fee\u590d\u65f6\u95f4\u5bf9\u5173\u952e\u53ef\u9760\u6027\u6307\u6807\u7684\u663e\u8457\u5b9e\u9645\u5f71\u54cd\uff0c\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u9002\u7528\u7684\u5206\u6790\u6846\u67b6\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u653e\u5bbd\u4e86\u9650\u5236\u6027\u7684\u6307\u6570\u5206\u5e03\u5047\u8bbe\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u901a\u7528\u3001\u66f4\u73b0\u5b9e\u7684\u53ef\u7ef4\u62a4\u6027\u8bc4\u4f30\u5206\u6790\u6846\u67b6\uff0c\u589e\u5f3a\u4e86\u53ef\u9760\u6027\u5efa\u6a21\u7684\u5b9e\u7528\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2602.07518", "categories": ["cs.ET", "cs.AR", "cs.LG", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2602.07518", "abs": "https://arxiv.org/abs/2602.07518", "authors": ["Manuel Escudero", "Mohamadreza Zolfagharinejad", "Sjoerd van den Belt", "Nikolaos Alachiotis", "Wilfred G. van der Wiel"], "title": "Physical Analog Kolmogorov-Arnold Networks based on Reconfigurable Nonlinear-Processing Units", "comment": null, "summary": "Kolmogorov-Arnold Networks (KANs) shift neural computation from linear layers to learnable nonlinear edge functions, but implementing these nonlinearities efficiently in hardware remains an open challenge. Here we introduce a physical analog KAN architecture in which edge functions are realized in materia using reconfigurable nonlinear-processing units (RNPUs): multi-terminal nanoscale silicon devices whose input-output characteristics are tuned via control voltages. By combining multiple RNPUs into an edge processor and assembling these blocks into a reconfigurable analog KAN (aKAN) architecture with integrated mixed-signal interfacing, we establish a realistic system-level hardware implementation that enables compact KAN-style regression and classification with programmable nonlinear transformations. Using experimentally calibrated RNPU models and hardware measurements, we demonstrate accurate function approximation across increasing task complexity while requiring fewer or comparable trainable parameters than multilayer perceptrons (MLPs). System-level estimates indicate an energy per inference of $\\sim$250 pJ and an end-to-end inference latency of $\\sim$600 ns for a representative workload, corresponding to a $\\sim$10$^{2}$-10$^{3}\\times$ reduction in energy accompanied by a $\\sim$10$\\times$ reduction in area compared to a digital fixed-point MLP at similar approximation error. These results establish RNPUs as scalable, hardware-native nonlinear computing primitives and identify analog KAN architectures as a realistic silicon-based pathway toward energy-, latency-, and footprint-efficient analog neural-network hardware, particularly for edge inference.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53ef\u91cd\u6784\u975e\u7ebf\u6027\u5904\u7406\u5355\u5143(RNPU)\u7684\u6a21\u62dfKAN\u786c\u4ef6\u67b6\u6784\uff0c\u5b9e\u73b0\u9ad8\u6548\u80fd\u3001\u4f4e\u5ef6\u8fdf\u7684\u8fb9\u7f18\u63a8\u7406", "motivation": "Kolmogorov-Arnold Networks (KANs) \u5728\u8f6f\u4ef6\u5c42\u9762\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u975e\u7ebf\u6027\u8fb9\u51fd\u6570\u6539\u8fdb\u795e\u7ecf\u7f51\u7edc\u8ba1\u7b97\uff0c\u4f46\u786c\u4ef6\u5b9e\u73b0\u6548\u7387\u4ecd\u662f\u6311\u6218\u3002\u9700\u8981\u5f00\u53d1\u7269\u7406\u6a21\u62df\u67b6\u6784\u6765\u5b9e\u73b0\u9ad8\u6548\u80fd\u3001\u4f4e\u5ef6\u8fdf\u7684\u8fb9\u7f18\u63a8\u7406\u786c\u4ef6\u3002", "method": "\u8bbe\u8ba1\u7269\u7406\u6a21\u62dfKAN\u67b6\u6784\uff0c\u4f7f\u7528\u53ef\u91cd\u6784\u975e\u7ebf\u6027\u5904\u7406\u5355\u5143(RNPUs)\u4f5c\u4e3a\u8fb9\u51fd\u6570\u7684\u786c\u4ef6\u5b9e\u73b0\u3002RNPUs\u662f\u591a\u7aef\u7eb3\u7c73\u7ea7\u7845\u5668\u4ef6\uff0c\u901a\u8fc7\u63a7\u5236\u7535\u538b\u8c03\u8282\u8f93\u5165\u8f93\u51fa\u7279\u6027\u3002\u5c06\u591a\u4e2aRNPUs\u7ec4\u5408\u6210\u8fb9\u5904\u7406\u5668\uff0c\u518d\u7ec4\u88c5\u6210\u96c6\u6210\u4e86\u6df7\u5408\u4fe1\u53f7\u63a5\u53e3\u7684\u53ef\u91cd\u6784\u6a21\u62dfKAN(aKAN)\u67b6\u6784\u3002", "result": "\u4f7f\u7528\u5b9e\u9a8c\u6821\u51c6\u7684RNPU\u6a21\u578b\u548c\u786c\u4ef6\u6d4b\u91cf\uff0c\u5728\u589e\u52a0\u4efb\u52a1\u590d\u6742\u5ea6\u65f6\u5b9e\u73b0\u51c6\u786e\u51fd\u6570\u903c\u8fd1\uff0c\u6240\u9700\u53ef\u8bad\u7ec3\u53c2\u6570\u5c11\u4e8e\u6216\u591a\u5c42\u611f\u77e5\u673a(MLPs)\u3002\u7cfb\u7edf\u7ea7\u4f30\u8ba1\u663e\u793a\uff0c\u5178\u578b\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u6bcf\u6b21\u63a8\u7406\u80fd\u8017\u7ea6250 pJ\uff0c\u7aef\u5230\u7aef\u63a8\u7406\u5ef6\u8fdf\u7ea6600 ns\uff0c\u76f8\u6bd4\u6570\u5b57\u5b9a\u70b9MLP\u5728\u76f8\u4f3c\u903c\u8fd1\u8bef\u5dee\u4e0b\uff0c\u80fd\u8017\u964d\u4f4e10^2-10^3\u500d\uff0c\u9762\u79ef\u51cf\u5c11\u7ea610\u500d\u3002", "conclusion": "RNPUs\u662f\u53ef\u6269\u5c55\u7684\u786c\u4ef6\u539f\u751f\u975e\u7ebf\u6027\u8ba1\u7b97\u57fa\u5143\uff0c\u6a21\u62dfKAN\u67b6\u6784\u662f\u5b9e\u73b0\u80fd\u6548\u3001\u5ef6\u8fdf\u548c\u9762\u79ef\u4f18\u5316\u7684\u6a21\u62df\u795e\u7ecf\u7f51\u7edc\u786c\u4ef6\u7684\u73b0\u5b9e\u7845\u57fa\u9014\u5f84\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8fb9\u7f18\u63a8\u7406\u5e94\u7528\u3002"}}
{"id": "2602.07486", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.07486", "abs": "https://arxiv.org/abs/2602.07486", "authors": ["Dor Leventer"], "title": "Identification of Child Penalties", "comment": null, "summary": "A growing body of research estimates child penalties, the gender gap in the effect of parenthood on labor market earnings, using event studies that normalize treatment effects by counterfactual earnings. I formalize the identification framework underlying this approach, which I term Normalized Triple Differences (NTD), and show it does not identify the conventional target estimand when the parallel trends assumption in levels is violated. Insights from human capital theory suggest such violations are likely: higher-ability individuals delay childbirth and have steeper earnings growth, a mechanism that causes conventional estimates to understate child penalties for early-treated parents. Using Israeli administrative data, a bias-bounding exercise suggests substantial understatement for early groups. As a solution, I propose targeting the effect of parenthood on the gender earnings ratio and show this new estimand is identified under NTD.", "AI": {"tldr": "\u672c\u6587\u6279\u8bc4\u4e86\u4f7f\u7528\u5f52\u4e00\u5316\u4e09\u91cd\u5dee\u5206\u6cd5\u4f30\u8ba1\u751f\u80b2\u60e9\u7f5a\u7684\u4f20\u7edf\u65b9\u6cd5\uff0c\u6307\u51fa\u5f53\u6c34\u5e73\u5e73\u884c\u8d8b\u52bf\u5047\u8bbe\u88ab\u8fdd\u53cd\u65f6\uff0c\u8be5\u65b9\u6cd5\u65e0\u6cd5\u8bc6\u522b\u76ee\u6807\u4f30\u8ba1\u91cf\uff0c\u5e76\u63d0\u51fa\u4ee5\u6027\u522b\u6536\u5165\u6bd4\u4e3a\u65b0\u7684\u4f30\u8ba1\u76ee\u6807\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4f7f\u7528\u4e8b\u4ef6\u7814\u7a76\u6cd5\u901a\u8fc7\u53cd\u4e8b\u5b9e\u6536\u5165\u5f52\u4e00\u5316\u6765\u4f30\u8ba1\u751f\u80b2\u60e9\u7f5a\uff08child penalties\uff09\uff0c\u4f46\u8be5\u65b9\u6cd5\u5728\u6c34\u5e73\u5e73\u884c\u8d8b\u52bf\u5047\u8bbe\u88ab\u8fdd\u53cd\u65f6\u5b58\u5728\u8bc6\u522b\u95ee\u9898\u3002\u4eba\u529b\u8d44\u672c\u7406\u8bba\u8868\u660e\u8fd9\u79cd\u8fdd\u53cd\u5f88\u53ef\u80fd\u53d1\u751f\uff1a\u9ad8\u80fd\u529b\u4e2a\u4f53\u503e\u5411\u4e8e\u63a8\u8fdf\u751f\u80b2\u4e14\u6536\u5165\u589e\u957f\u66f4\u5feb\uff0c\u5bfc\u81f4\u4f20\u7edf\u4f30\u8ba1\u4f4e\u4f30\u65e9\u671f\u751f\u80b2\u7236\u6bcd\u7684\u751f\u80b2\u60e9\u7f5a\u3002", "method": "\u4f5c\u8005\u5c06\u4f20\u7edf\u65b9\u6cd5\u5f62\u5f0f\u5316\u4e3a\u5f52\u4e00\u5316\u4e09\u91cd\u5dee\u5206\u6cd5\uff08NTD\uff09\uff0c\u5206\u6790\u5176\u8bc6\u522b\u6846\u67b6\u3002\u4f7f\u7528\u4ee5\u8272\u5217\u884c\u653f\u6570\u636e\u8fdb\u884c\u504f\u8bef\u8fb9\u754c\u5206\u6790\uff0c\u8bc1\u660e\u65e9\u671f\u7fa4\u4f53\u5b58\u5728\u663e\u8457\u4f4e\u4f30\u3002\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\uff0c\u63d0\u51fa\u4ee5\u751f\u80b2\u5bf9\u6027\u522b\u6536\u5165\u6bd4\u7684\u5f71\u54cd\u4f5c\u4e3a\u65b0\u7684\u4f30\u8ba1\u76ee\u6807\uff0c\u5e76\u8bc1\u660e\u8be5\u4f30\u8ba1\u91cf\u5728NTD\u4e0b\u53ef\u8bc6\u522b\u3002", "result": "\u504f\u8bef\u8fb9\u754c\u5206\u6790\u663e\u793a\uff0c\u5bf9\u4e8e\u65e9\u671f\u751f\u80b2\u7fa4\u4f53\uff0c\u4f20\u7edf\u4f30\u8ba1\u65b9\u6cd5\u5b58\u5728\u5b9e\u8d28\u6027\u4f4e\u4f30\u3002\u63d0\u51fa\u7684\u65b0\u4f30\u8ba1\u76ee\u6807\uff08\u6027\u522b\u6536\u5165\u6bd4\uff09\u5728NTD\u6846\u67b6\u4e0b\u53ef\u8bc6\u522b\uff0c\u4e3a\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u7684\u8bc6\u522b\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002", "conclusion": "\u4f20\u7edf\u5f52\u4e00\u5316\u4e09\u91cd\u5dee\u5206\u6cd5\u5728\u6c34\u5e73\u5e73\u884c\u8d8b\u52bf\u5047\u8bbe\u88ab\u8fdd\u53cd\u65f6\u65e0\u6cd5\u51c6\u786e\u8bc6\u522b\u751f\u80b2\u60e9\u7f5a\uff0c\u7279\u522b\u662f\u5728\u65e9\u671f\u751f\u80b2\u7fa4\u4f53\u4e2d\u3002\u5efa\u8bae\u5c06\u4f30\u8ba1\u76ee\u6807\u8f6c\u5411\u751f\u80b2\u5bf9\u6027\u522b\u6536\u5165\u6bd4\u7684\u5f71\u54cd\uff0c\u8fd9\u4e00\u65b0\u4f30\u8ba1\u91cf\u5728NTD\u6846\u67b6\u4e0b\u5177\u6709\u8bc6\u522b\u6027\uff0c\u4e3a\u751f\u80b2\u60e9\u7f5a\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u7a33\u5065\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.07573", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07573", "abs": "https://arxiv.org/abs/2602.07573", "authors": ["Ruiyi Fang", "Shuo Wang", "Ruizhi Pu", "Qiuhao Zeng", "Hao Zheng", "Ziyan Wang", "Jiale Cai", "Zhimin Mei", "Song Tang", "Charles Ling", "Boyu Wang"], "title": "Graph Domain Adaptation via Homophily-Agnostic Reconstructing Structure", "comment": "Accept by AAAI2026(oral)", "summary": "Graph Domain Adaptation (GDA) transfers knowledge from labeled source graphs to unlabeled target graphs, addressing the challenge of label scarcity. However, existing GDA methods typically assume that both source and target graphs exhibit homophily, leading existing methods to perform poorly when heterophily is present. Furthermore, the lack of labels in the target graph makes it impossible to assess its homophily level beforehand. To address this challenge, we propose a novel homophily-agnostic approach that effectively transfers knowledge between graphs with varying degrees of homophily. Specifically, we adopt a divide-and-conquer strategy that first separately reconstructs highly homophilic and heterophilic variants of both the source and target graphs, and then performs knowledge alignment separately between corresponding graph variants. Extensive experiments conducted on five benchmark datasets demonstrate the superior performance of our approach, particularly highlighting its substantial advantages on heterophilic graphs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u540c\u8d28\u6027\u548c\u5f02\u8d28\u6027\u4e0d\u540c\u7684\u56fe\uff0c\u901a\u8fc7\u5206\u6cbb\u7b56\u7565\u5206\u522b\u91cd\u5efa\u540c\u8d28\u548c\u5f02\u8d28\u56fe\u53d8\u4f53\uff0c\u5e76\u5728\u5bf9\u5e94\u53d8\u4f53\u95f4\u8fdb\u884c\u77e5\u8bc6\u5bf9\u9f50\u3002", "motivation": "\u73b0\u6709\u56fe\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u6e90\u56fe\u548c\u76ee\u6807\u56fe\u90fd\u8868\u73b0\u51fa\u540c\u8d28\u6027\uff0c\u5728\u5f02\u8d28\u6027\u5b58\u5728\u65f6\u6027\u80fd\u8f83\u5dee\u3002\u540c\u65f6\uff0c\u76ee\u6807\u56fe\u7f3a\u4e4f\u6807\u7b7e\u4f7f\u5f97\u65e0\u6cd5\u9884\u5148\u8bc4\u4f30\u5176\u540c\u8d28\u6027\u6c34\u5e73\u3002", "method": "\u91c7\u7528\u5206\u6cbb\u7b56\u7565\uff1a1\uff09\u5206\u522b\u91cd\u5efa\u6e90\u56fe\u548c\u76ee\u6807\u56fe\u7684\u9ad8\u5ea6\u540c\u8d28\u548c\u5f02\u8d28\u53d8\u4f53\uff1b2\uff09\u5728\u5bf9\u5e94\u7684\u56fe\u53d8\u4f53\u4e4b\u95f4\u5206\u522b\u8fdb\u884c\u77e5\u8bc6\u5bf9\u9f50\u3002\u8fd9\u662f\u4e00\u79cd\u540c\u8d28\u6027\u4e0d\u53ef\u77e5\u7684\u65b9\u6cd5\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5f02\u8d28\u56fe\u4e0a\u663e\u793a\u51fa\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u63d0\u51fa\u7684\u540c\u8d28\u6027\u4e0d\u53ef\u77e5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u4e0d\u540c\u540c\u8d28\u6027\u7a0b\u5ea6\u7684\u56fe\u4e4b\u95f4\u7684\u77e5\u8bc6\u8fc1\u79fb\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5f02\u8d28\u56fe\u4e0a\u7684\u6027\u80fd\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2602.06981", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06981", "abs": "https://arxiv.org/abs/2602.06981", "authors": ["Ankolika De", "Gabriel Lima", "Yixin Zou"], "title": "What is Safety? Corporate Discourse, Power, and the Politics of Generative AI Safety", "comment": "18 pages, 2 tables", "summary": "This work examines how leading generative artificial intelligence companies construct and communicate the concept of \"safety\" through public-facing documents. Drawing on critical discourse analysis, we analyze a corpus of corporate safety-related statements to explicate how authority, responsibility, and legitimacy are discursively established. These discursive strategies consolidate legitimacy for corporate actors, normalize safety as an experimental and anticipatory practice, and push a perceived participatory agenda toward safe technologies. We argue that uncritical uptake of these discourses risks reproducing corporate priorities and constraining alternative approaches to governance and design. The contribution of this work is twofold: first, to situate safety as a sociotechnical discourse that warrants critical examination; second, to caution human-computer interaction scholars against legitimizing corporate framings, instead foregrounding accountability, equity, and justice. By interrogating safety discourses as artifacts of power, this paper advances a critical agenda for human-computer interaction scholarship on artificial intelligence.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u751f\u6210\u5f0fAI\u516c\u53f8\u5982\u4f55\u901a\u8fc7\u516c\u5f00\u6587\u4ef6\u6784\u5efa\u548c\u4f20\u8fbe\"\u5b89\u5168\"\u6982\u5ff5\uff0c\u63ed\u793a\u5176\u8bdd\u8bed\u7b56\u7565\u5982\u4f55\u786e\u7acb\u6743\u5a01\u3001\u8d23\u4efb\u548c\u5408\u6cd5\u6027\uff0c\u5e76\u8b66\u544a\u4e0d\u52a0\u6279\u5224\u5730\u63a5\u53d7\u8fd9\u4e9b\u8bdd\u8bed\u53ef\u80fd\u9650\u5236\u66ff\u4ee3\u6027\u6cbb\u7406\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u6279\u5224\u6027\u5730\u5ba1\u89c6\u9886\u5148\u751f\u6210\u5f0fAI\u516c\u53f8\u5982\u4f55\u901a\u8fc7\u516c\u5f00\u6587\u4ef6\u6784\u5efa\"\u5b89\u5168\"\u8bdd\u8bed\uff0c\u63ed\u793a\u8fd9\u4e9b\u8bdd\u8bed\u5982\u4f55\u786e\u7acb\u516c\u53f8\u6743\u5a01\u3001\u8d23\u4efb\u548c\u5408\u6cd5\u6027\uff0c\u4ee5\u53ca\u8fd9\u79cd\u8bdd\u8bed\u6784\u5efa\u5bf9\u6cbb\u7406\u548c\u8bbe\u8ba1\u66ff\u4ee3\u65b9\u6cd5\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u6279\u5224\u6027\u8bdd\u8bed\u5206\u6790\u65b9\u6cd5\uff0c\u5206\u6790\u516c\u53f8\u5b89\u5168\u76f8\u5173\u58f0\u660e\u7684\u8bed\u6599\u5e93\uff0c\u9610\u91ca\u6743\u5a01\u3001\u8d23\u4efb\u548c\u5408\u6cd5\u6027\u5982\u4f55\u901a\u8fc7\u8bdd\u8bed\u7b56\u7565\u5efa\u7acb\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8fd9\u4e9b\u8bdd\u8bed\u7b56\u7565\u5de9\u56fa\u4e86\u516c\u53f8\u884c\u4e3a\u8005\u7684\u5408\u6cd5\u6027\uff0c\u5c06\u5b89\u5168\u89c4\u8303\u5316\u4e3a\u5b9e\u9a8c\u6027\u548c\u9884\u671f\u6027\u5b9e\u8df5\uff0c\u5e76\u63a8\u52a8\u611f\u77e5\u4e0a\u7684\u53c2\u4e0e\u5f0f\u8bae\u7a0b\u3002\u8fd9\u4e9b\u8bdd\u8bed\u98ce\u9669\u590d\u5236\u516c\u53f8\u4f18\u5148\u4e8b\u9879\u5e76\u9650\u5236\u66ff\u4ee3\u6cbb\u7406\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u8bba\u5f3a\u8c03\u5e94\u5c06\u5b89\u5168\u89c6\u4e3a\u9700\u8981\u6279\u5224\u6027\u5ba1\u89c6\u7684\u793e\u4f1a\u6280\u672f\u8bdd\u8bed\uff0c\u8b66\u544a\u4eba\u673a\u4ea4\u4e92\u5b66\u8005\u4e0d\u8981\u5408\u6cd5\u5316\u516c\u53f8\u6846\u67b6\uff0c\u800c\u5e94\u7a81\u51fa\u95ee\u8d23\u3001\u516c\u5e73\u548c\u6b63\u4e49\uff0c\u5c06\u5b89\u5168\u8bdd\u8bed\u4f5c\u4e3a\u6743\u529b\u4ea7\u7269\u8fdb\u884c\u5ba1\u89c6\uff0c\u63a8\u8fdb\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u5bf9AI\u7684\u6279\u5224\u8bae\u7a0b\u3002"}}
{"id": "2602.07034", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07034", "abs": "https://arxiv.org/abs/2602.07034", "authors": ["Jinxiu Qu", "Zirui Tang", "Hongzhang Huang", "Boyu Niu", "Wei Zhou", "Jiannan Wang", "Yitong Song", "Guoliang Li", "Xuanhe Zhou", "Fan Wu"], "title": "ST-Raptor: An Agentic System for Semi-Structured Table QA", "comment": null, "summary": "Semi-structured table question answering (QA) is a challenging task that requires (1) precise extraction of cell contents and positions and (2) accurate recovery of key implicit logical structures, hierarchical relationships, and semantic associations encoded in table layouts. In practice, such tables are often interpreted manually by human experts, which is labor-intensive and time-consuming. However, automating this process remains difficult. Existing Text-to-SQL methods typically require converting semi-structured tables into structured formats, inevitably leading to information loss, while approaches like Text-to-Code and multimodal LLM-based QA struggle with complex layouts and often yield inaccurate answers. To address these limitations, we present ST-Raptor, an agentic system for semi-structured table QA. ST-Raptor offers an interactive analysis environment that combines visual editing, tree-based structural modeling, and agent-driven query resolution to support accurate and user-friendly table understanding. Experimental results on both benchmark and real-world datasets demonstrate that ST-Raptor outperforms existing methods in both accuracy and usability. The code is available at https://github.com/weAIDB/ST-Raptor, and a demonstration video is available at https://youtu.be/9GDR-94Cau4.", "AI": {"tldr": "ST-Raptor\u662f\u4e00\u4e2a\u7528\u4e8e\u534a\u7ed3\u6784\u5316\u8868\u683c\u95ee\u7b54\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u89c6\u89c9\u7f16\u8f91\u3001\u6811\u72b6\u7ed3\u6784\u5efa\u6a21\u548c\u667a\u80fd\u4f53\u9a71\u52a8\u67e5\u8be2\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u4fe1\u606f\u4e22\u5931\u548c\u5e03\u5c40\u5904\u7406\u95ee\u9898", "motivation": "\u534a\u7ed3\u6784\u5316\u8868\u683c\u95ee\u7b54\u9700\u8981\u7cbe\u786e\u63d0\u53d6\u5355\u5143\u683c\u5185\u5bb9\u548c\u4f4d\u7f6e\uff0c\u5e76\u6062\u590d\u8868\u683c\u5e03\u5c40\u4e2d\u9690\u542b\u7684\u903b\u8f91\u7ed3\u6784\u3001\u5c42\u6b21\u5173\u7cfb\u548c\u8bed\u4e49\u5173\u8054\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4fe1\u606f\u4e22\u5931\u3001\u590d\u6742\u5e03\u5c40\u5904\u7406\u56f0\u96be\u7b49\u95ee\u9898\uff0c\u4eba\u5de5\u89e3\u91ca\u53c8\u8017\u65f6\u8017\u529b", "method": "ST-Raptor\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u5206\u6790\u73af\u5883\uff0c\u7ed3\u5408\u89c6\u89c9\u7f16\u8f91\u3001\u6811\u72b6\u7ed3\u6784\u5efa\u6a21\u548c\u667a\u80fd\u4f53\u9a71\u52a8\u67e5\u8be2\u89e3\u51b3\uff0c\u652f\u6301\u51c6\u786e\u4e14\u7528\u6237\u53cb\u597d\u7684\u8868\u683c\u7406\u89e3", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cST-Raptor\u5728\u51c6\u786e\u6027\u548c\u53ef\u7528\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "ST-Raptor\u901a\u8fc7\u521b\u65b0\u7684\u4ea4\u4e92\u5f0f\u667a\u80fd\u4f53\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86\u534a\u7ed3\u6784\u5316\u8868\u683c\u95ee\u7b54\u7684\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u548c\u7528\u6237\u53cb\u597d\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.08083", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.08083", "abs": "https://arxiv.org/abs/2602.08083", "authors": ["Aiwen Li", "Amrita Balajee", "Harry Wieand", "Jonathan Pipping-Gam\u00f3n"], "title": "A Unified Server Quality Metric for Tennis", "comment": "13 pages, submitted to the Journal of Quantitative Analysis in Sports (JQAS)", "summary": "Traditional tennis rating systems, such as Elo, summarize overall player strength but do not isolate the independent value of serving. Using point-by-point data from Wimbledon and the U.S. Open, we develop serve-specific player metrics to isolate serving quality from overall performance. For each tournament and gender, we fit logistic mixed-effects models using serve speed, speed variability, and placement features, with crossed server and returner random intercepts capturing unobserved server and returner-strength effects. We use these models to estimate Server Quality Scores (SQS) that reflect players' serving ability. In out-of-sample tests, SQS shows stronger alignment with serve efficiency (measured as points won within three shots) than weighted Elo. Associations with overall serve win percentage are smaller and mixed across datasets, and neither SQS nor wElo consistently dominates on that outcome. These findings highlight that serve-specific metrics complement holistic ratings and provide actionable insight for coaching, forecasting, and player evaluation.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e13\u95e8\u9488\u5bf9\u53d1\u7403\u7684\u8bc4\u5206\u7cfb\u7edfSQS\uff0c\u901a\u8fc7\u53d1\u7403\u901f\u5ea6\u3001\u53d8\u5f02\u6027\u548c\u843d\u70b9\u7b49\u7279\u5f81\u6765\u9694\u79bb\u53d1\u7403\u8d28\u91cf\uff0c\u6bd4\u4f20\u7edfElo\u8bc4\u5206\u80fd\u66f4\u597d\u5730\u9884\u6d4b\u53d1\u7403\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u7f51\u7403\u8bc4\u5206\u7cfb\u7edf\uff08\u5982Elo\uff09\u53ea\u80fd\u8bc4\u4f30\u7403\u5458\u6574\u4f53\u5b9e\u529b\uff0c\u65e0\u6cd5\u72ec\u7acb\u8861\u91cf\u53d1\u7403\u7684\u4ef7\u503c\u3002\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u53d1\u7403\u8d28\u91cf\u7684\u6307\u6807\u6765\u8865\u5145\u6574\u4f53\u8bc4\u5206\u3002", "method": "\u4f7f\u7528\u6e29\u7f51\u548c\u7f8e\u7f51\u7684\u9010\u5206\u6570\u636e\uff0c\u5efa\u7acb\u903b\u8f91\u6df7\u5408\u6548\u5e94\u6a21\u578b\uff0c\u5305\u542b\u53d1\u7403\u901f\u5ea6\u3001\u901f\u5ea6\u53d8\u5f02\u6027\u548c\u843d\u70b9\u7279\u5f81\uff0c\u91c7\u7528\u4ea4\u53c9\u7684\u53d1\u7403\u8005\u548c\u63a5\u53d1\u7403\u8005\u968f\u673a\u622a\u8ddd\u6765\u6355\u6349\u672a\u89c2\u5bdf\u5230\u7684\u6548\u5e94\u3002", "result": "SQS\u5728\u6837\u672c\u5916\u6d4b\u8bd5\u4e2d\u6bd4\u52a0\u6743Elo\u4e0e\u53d1\u7403\u6548\u7387\uff08\u4e09\u62cd\u5185\u5f97\u5206\uff09\u7684\u76f8\u5173\u6027\u66f4\u5f3a\u3002\u4e0e\u6574\u4f53\u53d1\u7403\u80dc\u7387\u7684\u76f8\u5173\u6027\u8f83\u5c0f\u4e14\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e2d\u8868\u73b0\u4e0d\u4e00\u3002", "conclusion": "\u53d1\u7403\u4e13\u9879\u6307\u6807\u8865\u5145\u4e86\u6574\u4f53\u8bc4\u5206\u7cfb\u7edf\uff0c\u4e3a\u6559\u7ec3\u6307\u5bfc\u3001\u6bd4\u8d5b\u9884\u6d4b\u548c\u7403\u5458\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002"}}
{"id": "2602.07724", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.07724", "abs": "https://arxiv.org/abs/2602.07724", "authors": ["Yingjie Li", "Shanglin Zhou", "Caiwen Ding", "Cunxi Yu"], "title": "HoloGraph: All-Optical Graph Learning via Light Diffraction", "comment": null, "summary": "As a representative of next-generation device/circuit technology beyond CMOS, physics-based neural networks such as Diffractive Optical Neural Networks (DONNs) have demonstrated promising advantages in computational speed and energy efficiency. However, existing DONNs and other physics-based neural networks have mostly focused on exploring their machine intelligence, with limited studies in handling graph-structured tasks. Thus, we introduce HoloGraph, the first monolithic free-space all-optical graph neural network system. It proposes a novel, domain-specific message-passing mechanism with optical skip channels integrated into light propagation for the all-optical graph learning. HoloGraph enables light-speed optical message passing over graph structures with diffractive propagation and phase modulations. Our experimental results with HoloGraph, conducted using standard graph learning datasets Cora-ML and Citeseer, show competitive or even superior classification performance compared to conventional digital graph neural networks. Comprehensive ablation studies demonstrate the effectiveness of the proposed novel architecture and algorithmic methods.", "AI": {"tldr": "HoloGraph\u662f\u9996\u4e2a\u5355\u7247\u81ea\u7531\u7a7a\u95f4\u5168\u5149\u5b66\u56fe\u795e\u7ecf\u7f51\u7edc\u7cfb\u7edf\uff0c\u5229\u7528\u884d\u5c04\u5149\u5b66\u5b9e\u73b0\u5149\u901f\u56fe\u5b66\u4e60\uff0c\u5728\u6807\u51c6\u56fe\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6216\u8d85\u8d8a\u4f20\u7edf\u6570\u5b57\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u884d\u5c04\u5149\u5b66\u795e\u7ecf\u7f51\u7edc\u7b49\u7269\u7406\u795e\u7ecf\u7f51\u7edc\u4e3b\u8981\u5173\u6ce8\u673a\u5668\u667a\u80fd\uff0c\u5728\u56fe\u7ed3\u6784\u4efb\u52a1\u5904\u7406\u65b9\u9762\u7814\u7a76\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u56fe\u7ed3\u6784\u4efb\u52a1\u7684\u5168\u5149\u5b66\u7cfb\u7edf\u3002", "method": "\u63d0\u51faHoloGraph\u7cfb\u7edf\uff0c\u91c7\u7528\u65b0\u9896\u7684\u9886\u57df\u7279\u5b9a\u6d88\u606f\u4f20\u9012\u673a\u5236\uff0c\u5c06\u5149\u5b66\u8df3\u8dc3\u901a\u9053\u96c6\u6210\u5230\u5149\u4f20\u64ad\u4e2d\uff0c\u901a\u8fc7\u884d\u5c04\u4f20\u64ad\u548c\u76f8\u4f4d\u8c03\u5236\u5b9e\u73b0\u5149\u901f\u5149\u5b66\u6d88\u606f\u4f20\u9012\u3002", "result": "\u5728Cora-ML\u548cCiteseer\u6807\u51c6\u56fe\u5b66\u4e60\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cHoloGraph\u7684\u5206\u7c7b\u6027\u80fd\u4e0e\u4f20\u7edf\u6570\u5b57\u56fe\u795e\u7ecf\u7f51\u7edc\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\uff0c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u6240\u63d0\u67b6\u6784\u548c\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "HoloGraph\u6210\u529f\u5b9e\u73b0\u4e86\u9996\u4e2a\u5355\u7247\u81ea\u7531\u7a7a\u95f4\u5168\u5149\u5b66\u56fe\u795e\u7ecf\u7f51\u7edc\u7cfb\u7edf\uff0c\u4e3a\u8d85\u8d8aCMOS\u7684\u4e0b\u4e00\u4ee3\u5668\u4ef6/\u7535\u8def\u6280\u672f\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u56fe\u7ed3\u6784\u4efb\u52a1\u5904\u7406\u65b9\u9762\u5c55\u73b0\u51fa\u5149\u901f\u8ba1\u7b97\u548c\u80fd\u6548\u4f18\u52bf\u3002"}}
{"id": "2602.07667", "categories": ["econ.EM", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07667", "abs": "https://arxiv.org/abs/2602.07667", "authors": ["Aysajan Eziz"], "title": "Fast Response or Silence: Conversation Persistence in an AI-Agent Social Network", "comment": "34 pages, 15 figures, 10 tables", "summary": "Autonomous AI agents are beginning to populate social platforms, but it is still unclear whether they can sustain the back-and-forth needed for extended coordination. We study Moltbook, an AI-agent social network, using a first-week snapshot and introduce interaction half-life: how quickly a comment's chance of receiving a direct reply fades as the comment ages. Across tens of thousands of commented threads, Moltbook discussions are dominated by first-layer reactions rather than extended chains. Most comments never receive a direct reply, reciprocal back-and-forth is rare, and when replies do occur they arrive almost immediately -- typically within seconds -- implying persistence on the order of minutes rather than hours. Moltbook is often described as running on an approximately four-hour ``heartbeat'' check-in schedule; using aggregate spectral tests on the longest contiguous activity window, we do not detect a reliable four-hour rhythm in this snapshot, consistent with jittered or out-of-phase individual schedules. A contemporaneous Reddit baseline analyzed with the same estimators shows substantially deeper threads and much longer reply persistence. Overall, early agent social interaction on Moltbook fits a ``fast response or silence'' regime, suggesting that sustained multi-step coordination will likely require explicit memory, thread resurfacing, and re-entry scaffolds.", "AI": {"tldr": "Moltbook AI\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u8ba8\u8bba\u4ee5\u8868\u5c42\u53cd\u5e94\u4e3a\u4e3b\uff0c\u7f3a\u4e4f\u6df1\u5ea6\u4e92\u52a8\uff0c\u56de\u590d\u96c6\u4e2d\u5728\u51e0\u79d2\u5185\u53d1\u751f\uff0c\u7f3a\u4e4f\u6301\u7eed\u7684\u591a\u6b65\u534f\u8c03\u80fd\u529b\u3002", "motivation": "\u7814\u7a76AI\u4ee3\u7406\u5728\u793e\u4ea4\u5e73\u53f0\u4e0a\u7684\u534f\u8c03\u80fd\u529b\uff0c\u7279\u522b\u662f\u80fd\u5426\u7ef4\u6301\u6301\u7eed\u7684\u6765\u56de\u4e92\u52a8\uff0c\u901a\u8fc7\u5206\u6790Moltbook\u8fd9\u4e00AI\u4ee3\u7406\u793e\u4ea4\u7f51\u7edc\u6765\u4e86\u89e3\u65e9\u671fAI\u793e\u4ea4\u4e92\u52a8\u7684\u7279\u70b9\u3002", "method": "\u5f15\u5165\"\u4ea4\u4e92\u534a\u8870\u671f\"\u6982\u5ff5\u8861\u91cf\u8bc4\u8bba\u83b7\u5f97\u76f4\u63a5\u56de\u590d\u7684\u6982\u7387\u968f\u65f6\u95f4\u7684\u8870\u51cf\u901f\u5ea6\uff0c\u5206\u6790Moltbook\u7b2c\u4e00\u5468\u7684\u5feb\u7167\u6570\u636e\uff0c\u5305\u62ec\u6570\u4e07\u4e2a\u8bc4\u8bba\u7ebf\u7a0b\uff0c\u5e76\u4e0eReddit\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "Moltbook\u8ba8\u8bba\u4e3b\u8981\u7531\u8868\u5c42\u53cd\u5e94\u4e3b\u5bfc\u800c\u975e\u6df1\u5ea6\u94fe\u5f0f\u4e92\u52a8\uff0c\u5927\u591a\u6570\u8bc4\u8bba\u4ece\u672a\u83b7\u5f97\u76f4\u63a5\u56de\u590d\uff0c\u4e92\u60e0\u6027\u6765\u56de\u4e92\u52a8\u7f55\u89c1\uff0c\u56de\u590d\u51e0\u4e4e\u5728\u51e0\u79d2\u5185\u53d1\u751f\uff0c\u4ea4\u4e92\u6301\u4e45\u6027\u4ec5\u51e0\u5206\u949f\u800c\u975e\u5c0f\u65f6\u7ea7\u522b\uff0c\u672a\u68c0\u6d4b\u5230\u53ef\u9760\u76844\u5c0f\u65f6\u8282\u594f\u3002", "conclusion": "\u65e9\u671fAI\u793e\u4ea4\u4e92\u52a8\u5448\u73b0\"\u5feb\u901f\u54cd\u5e94\u6216\u6c89\u9ed8\"\u6a21\u5f0f\uff0c\u8981\u5b9e\u73b0\u6301\u7eed\u7684\u591a\u6b65\u534f\u8c03\u53ef\u80fd\u9700\u8981\u663e\u5f0f\u8bb0\u5fc6\u3001\u7ebf\u7a0b\u91cd\u65b0\u6d6e\u73b0\u548c\u91cd\u65b0\u8fdb\u5165\u7684\u652f\u6491\u673a\u5236\u3002"}}
{"id": "2602.07781", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.07781", "abs": "https://arxiv.org/abs/2602.07781", "authors": ["Nazanin Sabri", "Ananya Malik", "Bangzhao Shu", "Jason Snyder", "Laurie Kramer", "Mai Elsherief"], "title": "\"He gets to be the fun parent\": Understanding and Supporting Burnt-Out Mothers in Online Communities", "comment": null, "summary": "Maternal burnout is a psychological phenomena with documented harms to both mother and child, requiring prompt attention. Mothers experiencing burnout might choose to turn to online anonymous platforms, such as Reddit, to share their experience, due to feelings of shame and stigmatization of mental health issues. In this work, we study how mothers use Reddit to discuss their experiences of burnout. We first identify posts written by burnt out mothers by manually annotating Reddit posts and training machine learning models on them. Focusing on posts made by this population (N = 3,244), we then investigate the issues brought up by mothers, such as the need for help, career advice, and co-parenting issues. Additionally, we investigate how the Reddit community responds to these posts through the analysis of comments. We find that commenters frequently share personal lived experiences with the poster, and provide emotional support. Finally, considering co-parenting could be a mitigating factor for parental burnout, we explore co-pareting patterns experienced by burnt out mothers, finding evidence of lack of support for and unequal expectations from mothers.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790Reddit\u4e0a\u6bcd\u4eb2\u4eec\u7684\u5026\u6020\u8ba8\u8bba\uff0c\u8bc6\u522b\u4e86\u76f8\u5173\u5e16\u5b50\u4e3b\u9898\u3001\u793e\u533a\u56de\u5e94\u6a21\u5f0f\u4ee5\u53ca\u5171\u540c\u80b2\u513f\u4e2d\u7684\u652f\u6301\u4e0d\u8db3\u95ee\u9898\u3002", "motivation": "\u6bcd\u4eb2\u5026\u6020\u5bf9\u6bcd\u5a74\u5065\u5eb7\u90fd\u6709\u5371\u5bb3\uff0c\u4f46\u6bcd\u4eb2\u4eec\u53ef\u80fd\u56e0\u7f9e\u803b\u611f\u548c\u6c61\u540d\u5316\u800c\u9009\u62e9\u5728\u533f\u540d\u5e73\u53f0\u5206\u4eab\u7ecf\u5386\u3002\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u6bcd\u4eb2\u5982\u4f55\u5728Reddit\u4e0a\u8ba8\u8bba\u5026\u6020\u4f53\u9a8c\u3002", "method": "\u9996\u5148\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8Reddit\u5e16\u5b50\u5e76\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6765\u8bc6\u522b\u5026\u6020\u6bcd\u4eb2\u7684\u5e16\u5b50\uff1b\u7136\u540e\u5206\u6790\u8fd9\u4e9b\u5e16\u5b50\uff08N=3,244\uff09\u4e2d\u8ba8\u8bba\u7684\u95ee\u9898\uff08\u5982\u6c42\u52a9\u9700\u6c42\u3001\u804c\u4e1a\u5efa\u8bae\u3001\u5171\u540c\u80b2\u513f\u95ee\u9898\uff09\uff1b\u63a5\u7740\u5206\u6790\u793e\u533a\u8bc4\u8bba\u56de\u5e94\u6a21\u5f0f\uff1b\u6700\u540e\u7279\u522b\u63a2\u7d22\u5171\u540c\u80b2\u513f\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6bcd\u4eb2\u4eec\u5728\u5e16\u5b50\u4e2d\u4e3b\u8981\u8ba8\u8bba\u6c42\u52a9\u9700\u6c42\u3001\u804c\u4e1a\u5efa\u8bae\u548c\u5171\u540c\u80b2\u513f\u95ee\u9898\uff1b\u8bc4\u8bba\u8005\u7ecf\u5e38\u5206\u4eab\u4e2a\u4eba\u751f\u6d3b\u7ecf\u9a8c\u5e76\u63d0\u4f9b\u60c5\u611f\u652f\u6301\uff1b\u5171\u540c\u80b2\u513f\u5206\u6790\u663e\u793a\u5b58\u5728\u652f\u6301\u4e0d\u8db3\u548c\u671f\u671b\u4e0d\u5e73\u7b49\u7684\u95ee\u9898\u3002", "conclusion": "\u6bcd\u4eb2\u4eec\u5728\u533f\u540d\u5e73\u53f0\u5206\u4eab\u5026\u6020\u7ecf\u5386\u65f6\u4e3b\u8981\u5bfb\u6c42\u60c5\u611f\u652f\u6301\u548c\u5b9e\u9645\u95ee\u9898\u5efa\u8bae\uff0c\u793e\u533a\u56de\u5e94\u4ee5\u7ecf\u9a8c\u5206\u4eab\u548c\u60c5\u611f\u652f\u6301\u4e3a\u4e3b\uff0c\u5171\u540c\u80b2\u513f\u4e2d\u7684\u652f\u6301\u4e0d\u8db3\u662f\u6bcd\u4eb2\u5026\u6020\u7684\u91cd\u8981\u56e0\u7d20\u3002"}}
{"id": "2602.06984", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06984", "abs": "https://arxiv.org/abs/2602.06984", "authors": ["Lin Luo", "Satwik Ghanta", "Yuri Nakao", "Mathieu Chollet", "Simone Stumpf"], "title": "Empowering Affected Individuals to Shape AI Fairness Assessments: Processes, Criteria, and Tools", "comment": null, "summary": "AI systems are increasingly used in high-stakes domains such as credit rating, where fairness concerns are critical. Existing fairness assessments are typically conducted by AI experts or regulators using predefined protected attributes and metrics, which often fail to capture the diversity and nuance of fairness notions held by the individuals who are affected by these systems' decisions, such as decision subjects. Recent work has therefore called for involving affected individuals in fairness assessment, yet little empirical evidence exists on how they create their own fairness criteria or what kinds of criteria they produce - knowledge that could not only inform experts' fairness evaluation and mitigation, but also guide the design of AI assessment tools. We address this gap through a qualitative user study with 18 participants in a credit rating scenario. Participants first articulated their fairness notions in their own words. Then, participants turned them into concrete quantified and operationalized fairness criteria, through an interactive prototype we designed. Our findings provide empirical evidence of the process through which people's fairness notions emerge via grounding in model features, and uncover a diverse set of individuals' custom-defined criteria for both outcome and procedural fairness. We provide design implications for processes and tools that support more inclusive and value-sensitive AI fairness assessment.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u7528\u6237\u5b9e\u9a8c\u63a2\u7d22\u4e2a\u4eba\u5982\u4f55\u521b\u5efa\u81ea\u5df1\u7684AI\u516c\u5e73\u6027\u6807\u51c6\uff0c\u53d1\u73b0\u4eba\u4eec\u901a\u8fc7\u6a21\u578b\u7279\u5f81\u5177\u4f53\u5316\u516c\u5e73\u6982\u5ff5\uff0c\u5e76\u4ea7\u751f\u591a\u6837\u5316\u7684\u7ed3\u679c\u548c\u7a0b\u5e8f\u516c\u5e73\u6807\u51c6\u3002", "motivation": "\u73b0\u6709AI\u516c\u5e73\u6027\u8bc4\u4f30\u901a\u5e38\u7531\u4e13\u5bb6\u4f7f\u7528\u9884\u5b9a\u4e49\u5c5e\u6027\u548c\u6307\u6807\u8fdb\u884c\uff0c\u65e0\u6cd5\u6355\u6349\u53d7\u5f71\u54cd\u4e2a\u4f53\u7684\u591a\u6837\u6027\u548c\u7ec6\u5fae\u516c\u5e73\u89c2\u5ff5\u3002\u9700\u8981\u8ba9\u53d7\u5f71\u54cd\u4e2a\u4f53\u53c2\u4e0e\u516c\u5e73\u6027\u8bc4\u4f30\uff0c\u4f46\u7f3a\u4e4f\u5173\u4e8e\u4ed6\u4eec\u5982\u4f55\u521b\u5efa\u516c\u5e73\u6807\u51c6\u7684\u5b9e\u8bc1\u8bc1\u636e\u3002", "method": "\u5728\u4fe1\u7528\u8bc4\u7ea7\u573a\u666f\u4e2d\u8fdb\u884c\u5b9a\u6027\u7528\u6237\u7814\u7a76\uff0c18\u540d\u53c2\u4e0e\u8005\u9996\u5148\u7528\u81ea\u5df1\u7684\u8bed\u8a00\u8868\u8fbe\u516c\u5e73\u89c2\u5ff5\uff0c\u7136\u540e\u901a\u8fc7\u4ea4\u4e92\u5f0f\u539f\u578b\u5c06\u5176\u8f6c\u5316\u4e3a\u5177\u4f53\u91cf\u5316\u548c\u53ef\u64cd\u4f5c\u7684\u516c\u5e73\u6807\u51c6\u3002", "result": "\u63d0\u4f9b\u4e86\u4eba\u4eec\u516c\u5e73\u89c2\u5ff5\u5982\u4f55\u901a\u8fc7\u6a21\u578b\u7279\u5f81\u5177\u4f53\u5316\u7684\u5b9e\u8bc1\u8bc1\u636e\uff0c\u53d1\u73b0\u4e86\u4e2a\u4eba\u81ea\u5b9a\u4e49\u7684\u7ed3\u679c\u516c\u5e73\u548c\u7a0b\u5e8f\u516c\u5e73\u6807\u51c6\u7684\u591a\u6837\u5316\u96c6\u5408\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u652f\u6301\u66f4\u5177\u5305\u5bb9\u6027\u548c\u4ef7\u503c\u654f\u611f\u7684AI\u516c\u5e73\u6027\u8bc4\u4f30\u6d41\u7a0b\u548c\u5de5\u5177\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u542f\u793a\u3002"}}
{"id": "2602.07035", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07035", "abs": "https://arxiv.org/abs/2602.07035", "authors": ["Jiahao Zhao", "Shaoxuan Xu", "Zhongxiang Sun", "Fengqi Zhu", "Jingyang Ou", "Yuling Shi", "Chongxuan Li", "Xiao Zhang", "Jun Xu"], "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents", "comment": null, "summary": "Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundamental limitation, termed as 1) Latency Challenge: the serial execution of multi-round reasoning, tool calling, and tool response waiting under the ReAct agent paradigm induces severe end-to-end latency. Intuitively, dLLMs can leverage their distinctive strengths to optimize the operational efficiency of agents under the ReAct agent paradigm. Practically, existing dLLM backbones face the 2) Agent Ability Challenge. That is, existing dLLMs exhibit remarkably weak reasoning and tool-calling capabilities, preventing these advantages from being effectively realized in practice. In this paper, we propose DLLM-Searcher, an optimization framework for dLLM-based Search Agents. To solve the Agent Ability Challenge, we design a two-stage post-training pipeline encompassing Agentic Supervised Fine-Tuning (Agentic SFT) and Agentic Variance-Reduced Preference Optimization Agentic VRPO, which enhances the backbone dLLM's information seeking and reasoning capabilities. To mitigate the Latency Challenge, we leverage the flexible generation mechanism of dLLMs and propose a novel agent paradigm termed Parallel-Reasoning and Acting P-ReAct. P-ReAct guides the model to prioritize decoding tool_call instructions, thereby allowing the model to keep thinking while waiting for the tool's return. Experimental results demonstrate that DLLM-Searcher achieves performance comparable to mainstream LLM-based search agents and P-ReAct delivers approximately 15% inference acceleration. Our code is available at https://anonymous.4open.science/r/DLLM-Searcher-553C", "AI": {"tldr": "DLLM-Searcher\uff1a\u57fa\u4e8e\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u641c\u7d22\u4ee3\u7406\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u540e\u8bad\u7ec3\u63d0\u5347\u4ee3\u7406\u80fd\u529b\uff0c\u5e76\u8bbe\u8ba1\u5e76\u884c\u63a8\u7406\u4e0e\u6267\u884c\u8303\u5f0f\uff08P-ReAct\uff09\u89e3\u51b3\u5ef6\u8fdf\u95ee\u9898\uff0c\u5b9e\u73b0\u4e0e\u4e3b\u6d41LLM\u641c\u7d22\u4ee3\u7406\u76f8\u5f53\u7684\u6027\u80fd\u548c\u7ea615%\u7684\u63a8\u7406\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u641c\u7d22\u4ee3\u7406\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1\uff09\u5ef6\u8fdf\u6311\u6218\uff1aReAct\u4ee3\u7406\u8303\u5f0f\u4e0b\u7684\u4e32\u884c\u591a\u8f6e\u63a8\u7406\u3001\u5de5\u5177\u8c03\u7528\u548c\u7b49\u5f85\u5bfc\u81f4\u4e25\u91cd\u7aef\u5230\u7aef\u5ef6\u8fdf\uff1b2\uff09\u4ee3\u7406\u80fd\u529b\u6311\u6218\uff1a\u73b0\u6709\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff08dLLMs\uff09\u5728\u63a8\u7406\u548c\u5de5\u5177\u8c03\u7528\u80fd\u529b\u4e0a\u8868\u73b0\u8f83\u5f31\uff0c\u65e0\u6cd5\u5145\u5206\u53d1\u6325\u5176\u5e76\u884c\u89e3\u7801\u548c\u7075\u6d3b\u751f\u6210\u7684\u4f18\u52bf\u3002", "method": "\u63d0\u51faDLLM-Searcher\u4f18\u5316\u6846\u67b6\uff1a1\uff09\u9488\u5bf9\u80fd\u529b\u6311\u6218\uff0c\u8bbe\u8ba1\u4e24\u9636\u6bb5\u540e\u8bad\u7ec3\u6d41\u7a0b\uff1a\u4ee3\u7406\u76d1\u7763\u5fae\u8c03\uff08Agentic SFT\uff09\u548c\u4ee3\u7406\u65b9\u5dee\u51cf\u5c11\u504f\u597d\u4f18\u5316\uff08Agentic VRPO\uff09\uff0c\u589e\u5f3adLLM\u7684\u4fe1\u606f\u68c0\u7d22\u548c\u63a8\u7406\u80fd\u529b\uff1b2\uff09\u9488\u5bf9\u5ef6\u8fdf\u6311\u6218\uff0c\u5229\u7528dLLMs\u7684\u7075\u6d3b\u751f\u6210\u673a\u5236\uff0c\u63d0\u51fa\u5e76\u884c\u63a8\u7406\u4e0e\u6267\u884c\u8303\u5f0f\uff08P-ReAct\uff09\uff0c\u4f18\u5148\u89e3\u7801\u5de5\u5177\u8c03\u7528\u6307\u4ee4\uff0c\u5b9e\u73b0\u7b49\u5f85\u5de5\u5177\u8fd4\u56de\u65f6\u7684\u6301\u7eed\u601d\u8003\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDLLM-Searcher\u5b9e\u73b0\u4e86\u4e0e\u4e3b\u6d41\u57fa\u4e8eLLM\u7684\u641c\u7d22\u4ee3\u7406\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6P-ReAct\u8303\u5f0f\u5e26\u6765\u4e86\u7ea615%\u7684\u63a8\u7406\u52a0\u901f\u3002", "conclusion": "DLLM-Searcher\u6210\u529f\u89e3\u51b3\u4e86\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5728\u641c\u7d22\u4ee3\u7406\u5e94\u7528\u4e2d\u7684\u80fd\u529b\u4e0d\u8db3\u548c\u5ef6\u8fdf\u95ee\u9898\uff0c\u8bc1\u660e\u4e86dLLMs\u5728\u63d0\u5347\u4ee3\u7406\u6548\u7387\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u9ad8\u6548\u641c\u7d22\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2602.08172", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.08172", "abs": "https://arxiv.org/abs/2602.08172", "authors": ["Guannan Gong", "Satrajit Roychoudhury", "Allison Meisner", "Lajos Pusztai", "Sarah B Goldberg", "Wei Wei"], "title": "Learning from Literature: Integrating LLMs and Bayesian Hierarchical Modeling for Oncology Trial Design", "comment": null, "summary": "Designing modern oncology trials requires synthesizing evidence from prior studies to inform hypothesis generation and sample size determination. Trial designs based on incomplete or imprecise summaries can lead to misspecified hypotheses and underpowered studies, resulting in false positive or negative conclusions. To address this challenge, we developed LEAD-ONC (Literature to Evidence for Analytics and Design in Oncology), an AI-assisted framework that transforms published clinical trial reports into quantitative, design-relevant evidence. Given expert-curated trial publications that meet prespecified eligibility criteria, LEAD-ONC uses large language models to extract baseline characteristics and reconstruct individual patient data from Kaplan-Meier curves, followed by Bayesian hierarchical modeling to generate predictive survival distributions for a prespecified target trial population. We demonstrate the framework using five phase III trials in first-line non-small-cell lung cancer evaluating PD-1 or PD-L1 inhibitors with or without CTLA-4 blockade. Clustering based on baseline characteristics identified three clinically interpretable populations defined by histology. For a prospective randomized trial in the mixed-histology population comparing mono versus dual immune checkpoint inhibition, LEAD-ONC projected a modest median overall survival difference of 2.8 months (95 percent credible interval -2.0 to 7.6) and an estimated probability of at least a 3-month benefit of approximately 0.45. As LEAD-ONC remains under active development, these results are intended as preliminary demonstrations of the frameworks potential to support evidence-driven oncology trial design rather than definitive clinical conclusions.", "AI": {"tldr": "LEAD-ONC\u662f\u4e00\u4e2aAI\u8f85\u52a9\u6846\u67b6\uff0c\u53ef\u5c06\u5df2\u53d1\u8868\u7684\u4e34\u5e8a\u8bd5\u9a8c\u62a5\u544a\u8f6c\u5316\u4e3a\u5b9a\u91cf\u8bc1\u636e\uff0c\u7528\u4e8e\u652f\u6301\u80bf\u7624\u5b66\u8bd5\u9a8c\u8bbe\u8ba1\uff0c\u901a\u8fc7\u63d0\u53d6\u57fa\u7ebf\u7279\u5f81\u3001\u91cd\u5efa\u4e2a\u4f53\u60a3\u8005\u6570\u636e\uff0c\u5e76\u4f7f\u7528\u8d1d\u53f6\u65af\u5206\u5c42\u6a21\u578b\u751f\u6210\u9884\u6d4b\u6027\u751f\u5b58\u5206\u5e03\u3002", "motivation": "\u73b0\u4ee3\u80bf\u7624\u5b66\u8bd5\u9a8c\u8bbe\u8ba1\u9700\u8981\u7efc\u5408\u5148\u524d\u7814\u7a76\u7684\u8bc1\u636e\u6765\u6307\u5bfc\u5047\u8bbe\u751f\u6210\u548c\u6837\u672c\u91cf\u786e\u5b9a\u3002\u57fa\u4e8e\u4e0d\u5b8c\u6574\u6216\u4e0d\u7cbe\u786e\u603b\u7ed3\u7684\u8bd5\u9a8c\u8bbe\u8ba1\u53ef\u80fd\u5bfc\u81f4\u5047\u8bbe\u9519\u8bef\u8bbe\u5b9a\u548c\u7814\u7a76\u6548\u80fd\u4e0d\u8db3\uff0c\u4ece\u800c\u4ea7\u751f\u5047\u9633\u6027\u6216\u5047\u9634\u6027\u7ed3\u8bba\u3002", "method": "LEAD-ONC\u6846\u67b6\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u4e13\u5bb6\u7b5b\u9009\u7684\u8bd5\u9a8c\u62a5\u544a\u4e2d\u63d0\u53d6\u57fa\u7ebf\u7279\u5f81\uff0c\u4eceKaplan-Meier\u66f2\u7ebf\u91cd\u5efa\u4e2a\u4f53\u60a3\u8005\u6570\u636e\uff0c\u7136\u540e\u901a\u8fc7\u8d1d\u53f6\u65af\u5206\u5c42\u6a21\u578b\u4e3a\u76ee\u6807\u8bd5\u9a8c\u4eba\u7fa4\u751f\u6210\u9884\u6d4b\u6027\u751f\u5b58\u5206\u5e03\u3002", "result": "\u57285\u9879\u4e00\u7ebf\u975e\u5c0f\u7ec6\u80de\u80ba\u764cIII\u671f\u8bd5\u9a8c\u7684\u6f14\u793a\u4e2d\uff0c\u57fa\u4e8e\u57fa\u7ebf\u7279\u5f81\u7684\u805a\u7c7b\u8bc6\u522b\u51fa\u4e09\u4e2a\u4e34\u5e8a\u53ef\u89e3\u91ca\u7684\u75c5\u7406\u5b66\u5b9a\u4e49\u4eba\u7fa4\u3002\u5bf9\u4e8e\u6df7\u5408\u75c5\u7406\u5b66\u4eba\u7fa4\u7684\u968f\u673a\u8bd5\u9a8c\uff0cLEAD-ONC\u9884\u6d4b\u4e2d\u4f4d\u603b\u751f\u5b58\u671f\u5dee\u5f02\u4e3a2.8\u4e2a\u6708\uff0895%\u53ef\u4fe1\u533a\u95f4-2.0\u81f37.6\uff09\uff0c\u81f3\u5c113\u4e2a\u6708\u83b7\u76ca\u7684\u6982\u7387\u7ea6\u4e3a0.45\u3002", "conclusion": "LEAD-ONC\u4f5c\u4e3a\u521d\u6b65\u6f14\u793a\u5c55\u793a\u4e86\u652f\u6301\u8bc1\u636e\u9a71\u52a8\u7684\u80bf\u7624\u5b66\u8bd5\u9a8c\u8bbe\u8ba1\u7684\u6f5c\u529b\uff0c\u4f46\u4ecd\u5728\u79ef\u6781\u5f00\u53d1\u4e2d\uff0c\u8fd9\u4e9b\u7ed3\u679c\u65e8\u5728\u5c55\u793a\u6846\u67b6\u6f5c\u529b\u800c\u975e\u63d0\u4f9b\u786e\u5b9a\u7684\u4e34\u5e8a\u7ed3\u8bba\u3002"}}
{"id": "2602.08080", "categories": ["cs.ET", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08080", "abs": "https://arxiv.org/abs/2602.08080", "authors": ["Luciano Bozzi", "Christian Celidonio", "Umberto Nuzzi", "Massimo Biagini", "Stefano Cherubin", "Asbj\u00f8rn Djupdal", "Tor Andre Haugdahl", "Andrea Aliverti", "Alessandra Angelucci", "Giovanni Agosta", "Gerardo Pelosi", "Paolo Belluco", "Samuele Polistina", "Riccardo Volpi", "Luigi Malag\u00f2", "Michael Schneider", "Florian Wieczorek", "Xabier Eguiluz"], "title": "The CAPSARII Approach to Cyber-Secure Wearable, Ultra-Low-Power Networked Sensors for Soldier Health Monitoring", "comment": null, "summary": "The European Defence Agency's revised Capability Development Plan (CDP) identifies as a priority improving ground combat capabilities by enhancing soldiers' equipment for better protection. The CAPSARII project proposes in innovative wearable system and Internet of Battlefield Things (IoBT) framework to monitor soldiers' physiological and psychological status, aiding tactical decisions and medical support. The CAPSARII system will enhance situational awareness and operational effectiveness by monitoring physiological, movement and environmental parameters, providing real-time tactical decision support through AI models deployed on edge nodes and enable data analysis and comparative studies via cloud-based analytics. CAPSARII also aims at improving usability through smart textile integration, longer battery life, reducing energy consumption through software and hardware optimizations, and address security concerns with efficient encryption and strong authentication methods. This innovative approach aims to transform military operations by providing a robust, data-driven decision support tool.", "AI": {"tldr": "CAPSARII\u9879\u76ee\u63d0\u51fa\u521b\u65b0\u7684\u53ef\u7a7f\u6234\u7cfb\u7edf\u548c\u6218\u573a\u7269\u8054\u7f51\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u6d4b\u58eb\u5175\u751f\u7406\u5fc3\u7406\u72b6\u6001\u6765\u589e\u5f3a\u5730\u9762\u4f5c\u6218\u80fd\u529b\uff0c\u63d0\u4f9b\u5b9e\u65f6\u6218\u672f\u51b3\u7b56\u652f\u6301\u548c\u533b\u7597\u63f4\u52a9\u3002", "motivation": "\u6b27\u6d32\u9632\u52a1\u5c40\u4fee\u8ba2\u7684\u80fd\u529b\u53d1\u5c55\u8ba1\u5212\u5c06\u63d0\u9ad8\u5730\u9762\u4f5c\u6218\u80fd\u529b\u4f5c\u4e3a\u4f18\u5148\u4e8b\u9879\uff0c\u9700\u8981\u589e\u5f3a\u58eb\u5175\u88c5\u5907\u4ee5\u63d0\u4f9b\u66f4\u597d\u7684\u4fdd\u62a4\u3002\u73b0\u6709\u7cfb\u7edf\u5728\u5b9e\u65f6\u76d1\u6d4b\u3001\u51b3\u7b56\u652f\u6301\u548c\u7cfb\u7edf\u96c6\u6210\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u521b\u65b0\u7684\u53ef\u7a7f\u6234\u7cfb\u7edf\u548c\u6218\u573a\u7269\u8054\u7f51\u6846\u67b6\uff0c\u96c6\u6210\u667a\u80fd\u7eba\u7ec7\u54c1\u6280\u672f\uff0c\u76d1\u6d4b\u751f\u7406\u3001\u8fd0\u52a8\u548c\u73af\u5883\u53c2\u6570\u3002\u901a\u8fc7\u8fb9\u7f18\u8282\u70b9\u90e8\u7f72AI\u6a21\u578b\u63d0\u4f9b\u5b9e\u65f6\u6218\u672f\u51b3\u7b56\u652f\u6301\uff0c\u4e91\u7aef\u8fdb\u884c\u6570\u636e\u5206\u6790\u548c\u6bd4\u8f83\u7814\u7a76\u3002\u901a\u8fc7\u8f6f\u786c\u4ef6\u4f18\u5316\u964d\u4f4e\u80fd\u8017\uff0c\u91c7\u7528\u9ad8\u6548\u52a0\u5bc6\u548c\u5f3a\u8ba4\u8bc1\u65b9\u6cd5\u786e\u4fdd\u5b89\u5168\u3002", "result": "\u7cfb\u7edf\u5c06\u589e\u5f3a\u6001\u52bf\u611f\u77e5\u548c\u4f5c\u6218\u6548\u80fd\uff0c\u63d0\u4f9b\u5b9e\u65f6\u6218\u672f\u51b3\u7b56\u652f\u6301\uff0c\u6539\u5584\u53ef\u7528\u6027\uff0c\u5ef6\u957f\u7535\u6c60\u5bff\u547d\uff0c\u964d\u4f4e\u80fd\u8017\uff0c\u5e76\u89e3\u51b3\u5b89\u5168\u5173\u5207\u3002\u4e3a\u519b\u4e8b\u884c\u52a8\u63d0\u4f9b\u5f3a\u5927\u7684\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u652f\u6301\u5de5\u5177\u3002", "conclusion": "CAPSARII\u7684\u521b\u65b0\u65b9\u6cd5\u65e8\u5728\u901a\u8fc7\u63d0\u4f9b\u7a33\u5065\u7684\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u652f\u6301\u5de5\u5177\u6765\u6539\u53d8\u519b\u4e8b\u884c\u52a8\uff0c\u589e\u5f3a\u58eb\u5175\u4fdd\u62a4\u548c\u4f5c\u6218\u6548\u80fd\uff0c\u662f\u54cd\u5e94\u6b27\u6d32\u9632\u52a1\u5c40\u80fd\u529b\u53d1\u5c55\u8ba1\u5212\u7684\u91cd\u8981\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2602.07769", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.07769", "abs": "https://arxiv.org/abs/2602.07769", "authors": ["Jiasong Han", "Xuehan Wang", "Jingbo Tan", "Jintao Wang", "Yu Zhang", "Hai Lin", "Jinhong Yuan"], "title": "Channel Estimation with Hierarchical Sparse Bayesian Learning for ODDM Systems", "comment": "Accepted by IEEE International Conference on Communications (ICC) 2026", "summary": "Orthogonal delay-Doppler division multiplexing (ODDM) is a promising modulation technique for reliable communications in high-mobility scenarios. However, the existing channel estimation frameworks for ODDM systems cannot achieve both high accuracy and low complexity simultaneously, due to the inherent coupling of delay and Doppler parameters. To address this problem, a two-dimensional (2D) hierarchical sparse Bayesian learning (HSBL) based channel estimation framework is proposed in this paper. Specifically, we address the inherent coupling between delay and Doppler dimensions in ODDM by developing a partially-decoupled 2D sparse signal recovery (SSR) formulation on a virtual sampling grid defined in the delay-Doppler (DD) domain. With the help of the partially-decoupled formulation, the proposed 2D HSBL framework first performs low-complexity coarse on-grid 2D sparse Bayesian learning (SBL) estimation to identify potential channel paths. Then, high-resolution fine grids are constructed around these regions, where an off-grid 2D SBL estimation is applied to achieve accurate channel estimation. Simulation results demonstrate that the proposed framework achieves performance superior to conventional off-grid 2D SBL with significantly reduced computational complexity.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e8c\u7ef4\u5206\u5c42\u7a00\u758f\u8d1d\u53f6\u65af\u5b66\u4e60(HSBL)\u7684ODDM\u4fe1\u9053\u4f30\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u90e8\u5206\u89e3\u8026\u548c\u5206\u5c42\u7f51\u683c\u4f18\u5316\uff0c\u5728\u4fdd\u8bc1\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709ODDM\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u548c\u4f4e\u590d\u6742\u5ea6\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u65f6\u5ef6\u548c\u591a\u666e\u52d2\u53c2\u6570\u7684\u5185\u5728\u8026\u5408\u95ee\u9898\u3002", "method": "1. \u5728\u5ef6\u8fdf-\u591a\u666e\u52d2\u57df\u5b9a\u4e49\u865a\u62df\u91c7\u6837\u7f51\u683c\uff0c\u5efa\u7acb\u90e8\u5206\u89e3\u8026\u7684\u4e8c\u7ef4\u7a00\u758f\u4fe1\u53f7\u6062\u590d\u6a21\u578b\uff1b2. \u5148\u8fdb\u884c\u4f4e\u590d\u6742\u5ea6\u7684\u7c97\u7f51\u683c2D SBL\u4f30\u8ba1\u8bc6\u522b\u6f5c\u5728\u4fe1\u9053\u8def\u5f84\uff1b3. \u5728\u8fd9\u4e9b\u533a\u57df\u5468\u56f4\u6784\u5efa\u9ad8\u5206\u8fa8\u7387\u7ec6\u7f51\u683c\uff0c\u8fdb\u884c\u79bb\u7f51\u683c2D SBL\u4f30\u8ba1\u5b9e\u73b0\u7cbe\u786e\u4fe1\u9053\u4f30\u8ba1\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u6846\u67b6\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u7684\u79bb\u7f51\u683c2D SBL\u65b9\u6cd5\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e8c\u7ef4HSBL\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86ODDM\u7cfb\u7edf\u4e2d\u4fe1\u9053\u4f30\u8ba1\u7684\u7cbe\u5ea6\u4e0e\u590d\u6742\u5ea6\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5c42\u7b56\u7565\u5b9e\u73b0\u4e86\u9ad8\u6548\u51c6\u786e\u7684\u4fe1\u9053\u4f30\u8ba1\u3002"}}
{"id": "2602.08569", "categories": ["cs.SI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.08569", "abs": "https://arxiv.org/abs/2602.08569", "authors": ["Xu Min", "Zhaoxu Yang", "Kaixuan Tan", "Juan Yan", "Xunbin Xiong", "Zihao Zhu", "Kaiyu Zhu", "Fenglin Cui", "Yang Yang", "Sihua Yang", "Jianhui Bu"], "title": "Towards Reliable Social A/B Testing: Spillover-Contained Clustering with Robust Post-Experiment Analysis", "comment": null, "summary": "A/B testing is the foundation of decision-making in online platforms, yet social products often suffer from network interference: user interactions cause treatment effects to spill over into the control group. Such spillovers bias causal estimates and undermine experimental conclusions. Existing approaches face key limitations: user-level randomization ignores network structure, while cluster-based methods often rely on general-purpose clustering that is not tailored for spillover containment and has difficulty balancing unbiasedness and statistical power at scale. We propose a spillover-contained experimentation framework with two stages. In the pre-experiment stage, we build social interaction graphs and introduce a Balanced Louvain algorithm that produces stable, size-balanced clusters while minimizing cross-cluster edges, enabling reliable cluster-based randomization. In the post-experiment stage, we develop a tailored CUPAC estimator that leverages pre-experiment behavioral covariates to reduce the variance induced by cluster-level assignment, thereby improving statistical power. Together, these components provide both structural spillover containment and robust statistical inference. We validate our approach through large-scale social sharing experiments on Kuaishou, a platform serving hundreds of millions of users. Results show that our method substantially reduces spillover and yields more accurate assessments of social strategies than traditional user-level designs, establishing a reliable and scalable framework for networked A/B testing.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684\u6ea2\u51fa\u63a7\u5236\u5b9e\u9a8c\u6846\u67b6\uff0c\u901a\u8fc7\u5e73\u8861Louvain\u7b97\u6cd5\u751f\u6210\u7a33\u5b9a\u3001\u5927\u5c0f\u5747\u8861\u7684\u96c6\u7fa4\u6765\u6700\u5c0f\u5316\u8de8\u96c6\u7fa4\u8fb9\uff0c\u5e76\u7ed3\u5408CUPAC\u4f30\u8ba1\u5668\u964d\u4f4e\u65b9\u5dee\uff0c\u5728\u5feb\u624b\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u51cf\u5c11\u6ea2\u51fa\u6548\u5e94\u5e76\u63d0\u9ad8\u793e\u4ea4\u7b56\u7565\u8bc4\u4f30\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u7ebf\u793e\u4ea4\u4ea7\u54c1\u4e2d\u7684\u7f51\u7edc\u5e72\u6270\u5bfc\u81f4\u5904\u7406\u6548\u5e94\u6ea2\u51fa\u5230\u5bf9\u7167\u7ec4\uff0c\u8fd9\u4f1a\u504f\u501a\u56e0\u679c\u4f30\u8ba1\u5e76\u7834\u574f\u5b9e\u9a8c\u7ed3\u8bba\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u7528\u6237\u7ea7\u968f\u673a\u5316\u5ffd\u7565\u7f51\u7edc\u7ed3\u6784\uff0c\u800c\u57fa\u4e8e\u96c6\u7fa4\u7684\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u901a\u7528\u805a\u7c7b\u7b97\u6cd5\uff0c\u96be\u4ee5\u5728\u65e0\u504f\u6027\u548c\u7edf\u8ba1\u529f\u6548\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6ea2\u51fa\u63a7\u5236\u5b9e\u9a8c\u6846\u67b6\uff1a1) \u9884\u5b9e\u9a8c\u9636\u6bb5\uff1a\u6784\u5efa\u793e\u4ea4\u4e92\u52a8\u56fe\uff0c\u5f15\u5165\u5e73\u8861Louvain\u7b97\u6cd5\u751f\u6210\u7a33\u5b9a\u3001\u5927\u5c0f\u5747\u8861\u7684\u96c6\u7fa4\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u8de8\u96c6\u7fa4\u8fb9\uff1b2) \u540e\u5b9e\u9a8c\u9636\u6bb5\uff1a\u5f00\u53d1\u5b9a\u5236\u5316\u7684CUPAC\u4f30\u8ba1\u5668\uff0c\u5229\u7528\u9884\u5b9e\u9a8c\u884c\u4e3a\u534f\u53d8\u91cf\u964d\u4f4e\u96c6\u7fa4\u7ea7\u5206\u914d\u5f15\u8d77\u7684\u65b9\u5dee\uff0c\u63d0\u9ad8\u7edf\u8ba1\u529f\u6548\u3002", "result": "\u5728\u5feb\u624b\u5e73\u53f0\u7684\u5927\u89c4\u6a21\u793e\u4ea4\u5206\u4eab\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u6ea2\u51fa\u6548\u5e94\uff0c\u76f8\u6bd4\u4f20\u7edf\u7528\u6237\u7ea7\u8bbe\u8ba1\u80fd\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u793e\u4ea4\u7b56\u7565\uff0c\u5efa\u7acb\u4e86\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u7f51\u7edc\u5316A/B\u6d4b\u8bd5\u6846\u67b6\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u6ea2\u51fa\u63a7\u5236\u548c\u7a33\u5065\u7684\u7edf\u8ba1\u63a8\u65ad\uff0c\u4e3a\u5b58\u5728\u7f51\u7edc\u5e72\u6270\u7684\u793e\u4ea4\u4ea7\u54c1\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u65e0\u504f\u6027\u548c\u7edf\u8ba1\u529f\u6548\u7684\u9700\u6c42\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.06992", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.06992", "abs": "https://arxiv.org/abs/2602.06992", "authors": ["Xiaohui Zou", "Lijun Ke", "Shunpeng Zou"], "title": "A New Mode of Teaching Chinese as a Foreign Language from the Perspective of Smart System Studied by Using Rongzhixue", "comment": "11 pages, in Chinese language, 22 figures", "summary": "The purpose of this study is to introduce a new model of teaching Chinese as a foreign language from the perspective of integrating wisdom. Its characteristics are as follows: focusing on the butterfly model of interpretation before translation, highlighting the new method of bilingual thinking training, on the one hand, applying the new theory of Chinese characters, the theory of the relationship between language and speech, and the forward-looking research results of language science; On the other hand, the application of the new model of teaching Chinese as a foreign language, AI empowering teaching and learning, and the forward-looking research results of educational science fully reflect a series of characteristics of the new model of teaching Chinese as a foreign language from the perspective of integrating wisdom. Its beneficial effects are: not only the old view of language and education, especially the old view of teaching Chinese as a foreign language, but also the old view of human-computer interaction. Its significance lies in that a series of great cross-border Rongzhixue such as language, knowledge, education and teaching, as well as new methods and new topics of bilingual thinking training are clearly put forward from the perspective of integrating wisdom. Especially in the face of the challenge of Chat GPT to human learning ability and even creativity, the existing concepts of language knowledge education and teaching are already very backward. The old concepts of Chinese language education, and teaching Chinese as a foreign language are all facing a series of subversive innovation challenges. How to seek changes in adaptation? This study has made a series of innovative attempts, hoping to benefit academic colleagues, teachers and students.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u878d\u667a\u5b66\u89c6\u89d2\u7684\u65b0\u578b\u5bf9\u5916\u6c49\u8bed\u6559\u5b66\u6a21\u5f0f\uff0c\u5f3a\u8c03\u89e3\u91ca\u5148\u4e8e\u7ffb\u8bd1\u7684\u8774\u8776\u6a21\u578b\u548c\u53cc\u8bed\u601d\u7ef4\u8bad\u7ec3\u65b0\u65b9\u6cd5\uff0c\u6574\u5408\u8bed\u8a00\u79d1\u5b66\u548c\u6559\u80b2\u79d1\u5b66\u7684\u524d\u6cbf\u6210\u679c\uff0c\u4ee5\u5e94\u5bf9ChatGPT\u7b49AI\u6280\u672f\u5bf9\u4f20\u7edf\u8bed\u8a00\u6559\u80b2\u89c2\u5ff5\u7684\u98a0\u8986\u6027\u6311\u6218\u3002", "motivation": "\u9762\u5bf9ChatGPT\u7b49\u4eba\u5de5\u667a\u80fd\u6280\u672f\u5bf9\u4eba\u7c7b\u5b66\u4e60\u80fd\u529b\u548c\u521b\u9020\u529b\u7684\u6311\u6218\uff0c\u4f20\u7edf\u7684\u8bed\u8a00\u77e5\u8bc6\u6559\u80b2\u89c2\u5ff5\u3001\u6c49\u8bed\u6559\u80b2\u89c2\u5ff5\u4ee5\u53ca\u5bf9\u5916\u6c49\u8bed\u6559\u5b66\u89c2\u5ff5\u5df2\u7ecf\u843d\u540e\uff0c\u9700\u8981\u8fdb\u884c\u98a0\u8986\u6027\u521b\u65b0\u3002\u672c\u7814\u7a76\u65e8\u5728\u4ece\u878d\u667a\u5b66\u89c6\u89d2\u63a2\u7d22\u9002\u5e94\u53d8\u9769\u7684\u65b0\u578b\u5bf9\u5916\u6c49\u8bed\u6559\u5b66\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u878d\u667a\u5b66\u89c6\u89d2\u7684\u65b0\u578b\u5bf9\u5916\u6c49\u8bed\u6559\u5b66\u6a21\u5f0f\uff0c\u91c7\u7528\"\u89e3\u91ca\u5148\u4e8e\u7ffb\u8bd1\"\u7684\u8774\u8776\u6a21\u578b\uff0c\u5f3a\u8c03\u53cc\u8bed\u601d\u7ef4\u8bad\u7ec3\u65b0\u65b9\u6cd5\u3002\u4e00\u65b9\u9762\u5e94\u7528\u6c49\u5b57\u65b0\u7406\u8bba\u3001\u8bed\u8a00\u4e0e\u8a00\u8bed\u5173\u7cfb\u7406\u8bba\u7b49\u8bed\u8a00\u79d1\u5b66\u524d\u6cbf\u6210\u679c\uff1b\u53e6\u4e00\u65b9\u9762\u5e94\u7528AI\u8d4b\u80fd\u6559\u5b66\u7684\u65b0\u6a21\u5f0f\u548c\u6559\u80b2\u79d1\u5b66\u524d\u77bb\u6027\u7814\u7a76\u6210\u679c\u3002", "result": "\u8be5\u6a21\u5f0f\u4e0d\u4ec5\u7a81\u7834\u4e86\u4f20\u7edf\u7684\u8bed\u8a00\u89c2\u3001\u6559\u80b2\u89c2\uff0c\u7279\u522b\u662f\u5bf9\u5916\u6c49\u8bed\u6559\u5b66\u7684\u65e7\u89c2\u5ff5\uff0c\u8fd8\u7a81\u7834\u4e86\u4f20\u7edf\u7684\u4eba\u673a\u4ea4\u4e92\u89c2\u5ff5\u3002\u660e\u786e\u63d0\u51fa\u4e86\u8bed\u8a00\u3001\u77e5\u8bc6\u3001\u6559\u80b2\u6559\u5b66\u7b49\u4e00\u7cfb\u5217\u91cd\u5927\u8de8\u754c\u878d\u667a\u5b66\u95ee\u9898\uff0c\u4ee5\u53ca\u53cc\u8bed\u601d\u7ef4\u8bad\u7ec3\u7684\u65b0\u65b9\u6cd5\u548c\u65b0\u8bfe\u9898\u3002", "conclusion": "\u672c\u7814\u7a76\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u521b\u65b0\u5c1d\u8bd5\uff0c\u4ece\u878d\u667a\u5b66\u89c6\u89d2\u63d0\u51fa\u4e86\u5177\u6709\u524d\u77bb\u6027\u7684\u5bf9\u5916\u6c49\u8bed\u6559\u5b66\u65b0\u6a21\u5f0f\uff0c\u65e8\u5728\u5e94\u5bf9AI\u65f6\u4ee3\u5bf9\u8bed\u8a00\u6559\u80b2\u7684\u98a0\u8986\u6027\u6311\u6218\uff0c\u4e3a\u5b66\u672f\u754c\u540c\u4ec1\u3001\u6559\u5e08\u548c\u5b66\u751f\u63d0\u4f9b\u6709\u76ca\u7684\u53c2\u8003\u548c\u542f\u793a\u3002"}}
{"id": "2602.07040", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07040", "abs": "https://arxiv.org/abs/2602.07040", "authors": ["Emmett Bicker"], "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods", "comment": "Available at www.asterlab.ai, 25 pages, 8 figures, 4 tables", "summary": "We introduce Aster, an AI agent for autonomous scientific discovery capable of operating over 20 times faster than existing frameworks. Given a task, an initial program, and a script to evaluate the performance of the program, Aster iteratively improves the program, often leading to new state-of-the-art performances. Aster's significant reduction in the number of iterations required for novel discovery expands the domain of tractable problems to include tasks with long evaluation durations, such as multi-hour machine learning training runs.\n  We applied Aster to problems in mathematics, GPU kernel engineering, biology, neuroscience, and language model training. More specifically: the Erdos minimum overlap problem, optimizing the TriMul kernel, a single-cell analysis denoising problem, training a neural activity prediction model to perform well on ZAPBench, and the NanoGPT Speedrun Competition. Aster attains SOTA results in every task, except for ZAPBench, where it matches the performance of the best human solution with less than 1/190th of the compute.\n  Aster is accessible via a web interface and API at asterlab.ai.", "AI": {"tldr": "Aster\u662f\u4e00\u4e2a\u7528\u4e8e\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\u7684AI\u4ee3\u7406\uff0c\u6bd4\u73b0\u6709\u6846\u67b6\u5feb20\u500d\u4ee5\u4e0a\uff0c\u80fd\u5728\u591a\u4e2a\u9886\u57df\u5b9e\u73b0\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd", "motivation": "\u73b0\u6709\u79d1\u5b66\u53d1\u73b0\u6846\u67b6\u901f\u5ea6\u8f83\u6162\uff0c\u9650\u5236\u4e86\u5728\u9700\u8981\u957f\u65f6\u95f4\u8bc4\u4f30\u7684\u4efb\u52a1\uff08\u5982\u591a\u5c0f\u65f6\u7684\u673a\u5668\u5b66\u4e60\u8bad\u7ec3\uff09\u4e2d\u7684\u5e94\u7528\u3002\u9700\u8981\u4e00\u79cd\u80fd\u663e\u8457\u51cf\u5c11\u8fed\u4ee3\u6b21\u6570\u3001\u6269\u5c55\u53ef\u5904\u7406\u95ee\u9898\u8303\u56f4\u7684\u81ea\u4e3b\u53d1\u73b0\u7cfb\u7edf\u3002", "method": "Aster\u91c7\u7528\u8fed\u4ee3\u6539\u8fdb\u65b9\u6cd5\uff1a\u7ed9\u5b9a\u4efb\u52a1\u3001\u521d\u59cb\u7a0b\u5e8f\u548c\u8bc4\u4f30\u811a\u672c\uff0c\u7cfb\u7edf\u4f1a\u4e0d\u65ad\u4f18\u5316\u7a0b\u5e8f\u3002\u901a\u8fc7\u51cf\u5c11\u6240\u9700\u8fed\u4ee3\u6b21\u6570\uff0c\u80fd\u591f\u5904\u7406\u8bc4\u4f30\u65f6\u95f4\u957f\u7684\u4efb\u52a1\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u53d6\u5f97SOTA\u7ed3\u679c\uff1aErdos\u6700\u5c0f\u91cd\u53e0\u95ee\u9898\u3001TriMul\u5185\u6838\u4f18\u5316\u3001\u5355\u7ec6\u80de\u5206\u6790\u53bb\u566a\u95ee\u9898\u3001\u795e\u7ecf\u6d3b\u52a8\u9884\u6d4b\u6a21\u578b\u8bad\u7ec3\uff08\u5728ZAPBench\u4e0a\u5339\u914d\u6700\u4f73\u4eba\u7c7b\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u8ba1\u7b97\u91cf\u4e0d\u52301/190\uff09\u3001NanoGPT Speedrun\u7ade\u8d5b\u3002\u9664\u4e86ZAPBench\u5916\uff0c\u6240\u6709\u4efb\u52a1\u90fd\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "Aster\u901a\u8fc7\u663e\u8457\u51cf\u5c11\u79d1\u5b66\u53d1\u73b0\u6240\u9700\u7684\u8fed\u4ee3\u6b21\u6570\uff0c\u6269\u5c55\u4e86\u53ef\u5904\u7406\u95ee\u9898\u7684\u8303\u56f4\uff0c\u7279\u522b\u662f\u5728\u8bc4\u4f30\u65f6\u95f4\u957f\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002\u7cfb\u7edf\u5df2\u901a\u8fc7web\u754c\u9762\u548cAPI\u63d0\u4f9b\u8bbf\u95ee\u3002"}}
{"id": "2602.08414", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.08414", "abs": "https://arxiv.org/abs/2602.08414", "authors": ["Paula Staudt", "Anika Schlosser", "Annika M\u00f6hl", "Martin Schumacher", "Nadine Binder"], "title": "Temporal Trends in Incidence of Dementia in a Birth Cohorts Analysis of the Framingham Heart Study", "comment": "14 pages, 3 figures, 2 tables", "summary": "Background: Dementia leads to a high burden of disability and the number of dementia patients worldwide doubled between 1990 and 2016. Nevertheless, some studies indicated a decrease in dementia risk which may be due to a bias caused by conventional analysis methods that do not adequately account for missing disease information due to death.\n  Methods: This study re-examines potential trends in dementia incidence over four decades in the Framingham Heart Study. We apply a multistate modeling framework tailored to interval-censored illness-death data and define three non-overlapping birth cohorts (1915-1924, 1925-1934, and 1935-1944). Trends are evaluated based on both dementia prevalence and dementia risk, using age as the underlying timescale. Additionally, age-conditional dementia probabilities stratified by sex are estimated.\n  Results: A total of 731 out of 3828 individuals were diagnosed with dementia. The multistate model analysis revealed no temporal decline in dementia risk across birth cohorts, irrespective of sex. When stratified by sex and adjusted for education, women consistently exhibited higher lifetime age-conditional risks (46%-50%) than men (30%-34%) over the study period.\n  Conclusions: We recommend using a combination of multistate approach and separation into birth cohorts to adequately estimate trends of disease risk in cohort studies as well as to communicate patient-relevant outcomes such age-conditional disease risks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u591a\u72b6\u6001\u6a21\u578b\u5206\u6790\u5f17\u96f7\u660e\u6c49\u5fc3\u810f\u7814\u7a76\u6570\u636e\uff0c\u53d1\u73b0\u75f4\u5446\u98ce\u9669\u5728\u8fc7\u53bb\u56db\u5341\u5e74\u95f4\u5e76\u672a\u4e0b\u964d\uff0c\u4e14\u5973\u6027\u7ec8\u751f\u75f4\u5446\u98ce\u9669\u663e\u8457\u9ad8\u4e8e\u7537\u6027\u3002", "motivation": "\u4f20\u7edf\u5206\u6790\u65b9\u6cd5\u53ef\u80fd\u56e0\u672a\u80fd\u5145\u5206\u5904\u7406\u56e0\u6b7b\u4ea1\u5bfc\u81f4\u7684\u75be\u75c5\u4fe1\u606f\u7f3a\u5931\u800c\u4ea7\u751f\u504f\u501a\uff0c\u4ece\u800c\u9519\u8bef\u5730\u663e\u793a\u75f4\u5446\u98ce\u9669\u4e0b\u964d\u7684\u8d8b\u52bf\u3002\u672c\u7814\u7a76\u65e8\u5728\u91cd\u65b0\u8bc4\u4f30\u75f4\u5446\u53d1\u75c5\u7387\u968f\u65f6\u95f4\u53d8\u5316\u7684\u771f\u5b9e\u8d8b\u52bf\u3002", "method": "\u91c7\u7528\u591a\u72b6\u6001\u5efa\u6a21\u6846\u67b6\u5904\u7406\u533a\u95f4\u5220\u5931\u7684\u75be\u75c5-\u6b7b\u4ea1\u6570\u636e\uff0c\u5c06\u53c2\u4e0e\u8005\u5206\u4e3a\u4e09\u4e2a\u975e\u91cd\u53e0\u51fa\u751f\u961f\u5217\uff081915-1924\u30011925-1934\u30011935-1944\uff09\uff0c\u4ee5\u5e74\u9f84\u4e3a\u65f6\u95f4\u5c3a\u5ea6\u8bc4\u4f30\u8d8b\u52bf\uff0c\u5e76\u4f30\u8ba1\u6309\u6027\u522b\u5206\u5c42\u7684\u5e74\u9f84\u6761\u4ef6\u6027\u75f4\u5446\u6982\u7387\u3002", "result": "\u57283828\u540d\u53c2\u4e0e\u8005\u4e2d\uff0c731\u4eba\u88ab\u8bca\u65ad\u4e3a\u75f4\u5446\u3002\u591a\u72b6\u6001\u6a21\u578b\u5206\u6790\u663e\u793a\uff0c\u65e0\u8bba\u6027\u522b\u5982\u4f55\uff0c\u75f4\u5446\u98ce\u9669\u5728\u4e0d\u540c\u51fa\u751f\u961f\u5217\u95f4\u5747\u65e0\u65f6\u95f4\u4e0b\u964d\u8d8b\u52bf\u3002\u7ecf\u6559\u80b2\u6c34\u5e73\u8c03\u6574\u540e\uff0c\u5973\u6027\u7ec8\u751f\u5e74\u9f84\u6761\u4ef6\u6027\u98ce\u9669\uff0846%-50%\uff09\u59cb\u7ec8\u9ad8\u4e8e\u7537\u6027\uff0830%-34%\uff09\u3002", "conclusion": "\u5efa\u8bae\u5728\u961f\u5217\u7814\u7a76\u4e2d\u7ed3\u5408\u4f7f\u7528\u591a\u72b6\u6001\u65b9\u6cd5\u548c\u51fa\u751f\u961f\u5217\u5206\u5c42\u6765\u5145\u5206\u4f30\u8ba1\u75be\u75c5\u98ce\u9669\u8d8b\u52bf\uff0c\u5e76\u4f20\u8fbe\u60a3\u8005\u76f8\u5173\u7684\u7ed3\u5c40\u6307\u6807\uff0c\u5982\u5e74\u9f84\u6761\u4ef6\u6027\u75be\u75c5\u98ce\u9669\u3002"}}
{"id": "2602.08269", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.08269", "abs": "https://arxiv.org/abs/2602.08269", "authors": ["Lian Zhou", "Kaiwen Xue", "Amirhossein Fallah", "Lijin Liu", "Chun-Ho Lee", "Kiwon Kwon", "Clayton Cheung", "Yuan Li", "Yue Yu", "Yun-Jhu Lee", "Songlin Zhao", "Ryan Hamerly", "Edo Waks", "Dirk Englund", "Constantine Sideris", "Mengjie Yu", "Zaijun Chen"], "title": "Quantization-aware Photonic Homodyne computing for Accelerated Artificial Intelligence and Scientific Simulation", "comment": null, "summary": "Modern problems in high-performance computing, ranging from training and inferencing deep learning models in computer vision and language models to simulating complex physical systems with nonlinearly-coupled equations, require exponential growth of computational resources. Photonic analog systems are emerging with solutions of intrinsic parallelism, high bandwidth, and low propagation loss. However, their application has been hindered by the low analog accuracy due to the electro-optic distortion, material nonlinearities, and signal-to-noise ratios. Here we overcome this barrier with a quantization-aware digital-photonic mixed-precision framework across chiplets for accelerated AI processing and physical simulation. Using Lithium Niobate photonics with channel equalization techniques, we demonstrate linear multiplication (9-bit amplitude-phase decoupling) in homodyne optical logics with 6-bit precision at the clock rate of 128 giga-symbol-per-second (128 GS/s), enabling AI processing with 6 ns latency. Codesign hardware-algorithms, including iterative solvers, sparse-dense quantization, and bit-sliced matrix multiplication, explore photonic amplitude and phase coherence for complex-valued, physics-inspired computation. In electromagnetic problems, our approach yields 12-bit solutions for partial differential equations (PDEs) in scattering problems that would conventionally require up to 32-bit and often even 64-bit precision. These results preserve digital-level fidelity while leveraging the high-speed low-energy photonic hardware, establishing a pathway toward general-purpose optical acceleration for generative artificial intelligence, real-time robotics, and accurate simulation for climate challenges and biological discoveries.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u91cf\u5316\u611f\u77e5\u7684\u6570\u5b57-\u5149\u5b50\u6df7\u5408\u7cbe\u5ea6\u6846\u67b6\uff0c\u901a\u8fc7\u94cc\u9178\u9502\u5149\u5b50\u82af\u7247\u5b9e\u73b06\u4f4d\u7cbe\u5ea6\u3001128GS/s\u65f6\u949f\u901f\u7387\u7684\u7ebf\u6027\u4e58\u6cd5\uff0c\u7528\u4e8eAI\u5904\u7406\u548c\u7269\u7406\u6a21\u62df\uff0c\u5728\u7535\u78c1\u95ee\u9898\u4e2d\u5b9e\u73b012\u4f4dPDE\u89e3\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u5b57\u7ea7\u4fdd\u771f\u5ea6\u3002", "motivation": "\u9ad8\u6027\u80fd\u8ba1\u7b97\u9700\u6c42\u5448\u6307\u6570\u589e\u957f\uff0c\u5149\u5b50\u6a21\u62df\u7cfb\u7edf\u5177\u6709\u5185\u5728\u5e76\u884c\u6027\u3001\u9ad8\u5e26\u5bbd\u548c\u4f4e\u4f20\u64ad\u635f\u8017\u7684\u4f18\u52bf\uff0c\u4f46\u53d7\u9650\u4e8e\u7535\u5149\u5931\u771f\u3001\u6750\u6599\u975e\u7ebf\u6027\u548c\u4fe1\u566a\u6bd4\u5bfc\u81f4\u7684\u4f4e\u6a21\u62df\u7cbe\u5ea6\uff0c\u9700\u8981\u514b\u670d\u8fd9\u4e00\u969c\u788d\u3002", "method": "\u91c7\u7528\u91cf\u5316\u611f\u77e5\u7684\u6570\u5b57-\u5149\u5b50\u6df7\u5408\u7cbe\u5ea6\u6846\u67b6\uff0c\u4f7f\u7528\u94cc\u9178\u9502\u5149\u5b50\u5b66\u7ed3\u5408\u901a\u9053\u5747\u8861\u6280\u672f\uff0c\u5b9e\u73b09\u4f4d\u5e45\u76f8\u89e3\u8026\u7684\u7ebf\u6027\u4e58\u6cd5\uff1b\u901a\u8fc7\u786c\u4ef6-\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\uff0c\u5305\u62ec\u8fed\u4ee3\u6c42\u89e3\u5668\u3001\u7a00\u758f-\u5bc6\u96c6\u91cf\u5316\u548c\u4f4d\u5207\u7247\u77e9\u9635\u4e58\u6cd5\uff0c\u63a2\u7d22\u5149\u5b50\u5e45\u5ea6\u548c\u76f8\u4f4d\u76f8\u5e72\u6027\u7528\u4e8e\u590d\u503c\u7269\u7406\u542f\u53d1\u8ba1\u7b97\u3002", "result": "\u5728\u96f6\u5dee\u5149\u5b66\u903b\u8f91\u4e2d\u5b9e\u73b06\u4f4d\u7cbe\u5ea6\u3001128GS/s\u65f6\u949f\u901f\u7387\u7684\u7ebf\u6027\u4e58\u6cd5\uff0cAI\u5904\u7406\u5ef6\u8fdf\u4ec56ns\uff1b\u5728\u7535\u78c1\u95ee\u9898\u4e2d\uff0c\u4f20\u7edf\u9700\u898132-64\u4f4d\u7cbe\u5ea6\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u6563\u5c04\u95ee\u9898\u83b7\u5f9712\u4f4d\u89e3\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u5b57\u7ea7\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6570\u5b57\u7ea7\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\uff0c\u5145\u5206\u5229\u7528\u9ad8\u901f\u4f4e\u80fd\u8017\u5149\u5b50\u786c\u4ef6\u7684\u4f18\u52bf\uff0c\u4e3a\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u3001\u5b9e\u65f6\u673a\u5668\u4eba\u548c\u6c14\u5019\u6311\u6218\u4e0e\u751f\u7269\u53d1\u73b0\u7684\u7cbe\u786e\u6a21\u62df\u5efa\u7acb\u4e86\u901a\u7528\u5149\u5b66\u52a0\u901f\u7684\u9014\u5f84\u3002"}}
{"id": "2602.07772", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.07772", "abs": "https://arxiv.org/abs/2602.07772", "authors": ["Jiasong Han", "Yufei Feng", "Xiaofeng Zhong"], "title": "FilterLoss: A Transfer Learning Approach for Communication Scene Recognition", "comment": "Accepted by the 11th IEEE International Conference on Computer and Communications (ICCC 2025), Chengdu, China", "summary": "Communication scene recognition has been widely applied in practice, but using deep learning to address this problem faces challenges such as insufficient data and imbalanced data distribution. To address this, we designed a weighted loss function structure, named FilterLoss, which assigns different loss function weights to different sample points. This allows the deep learning model to focus primarily on high-value samples while appropriately accounting for noisy, boundary-level data points. Additionally, we developed a matching weight filtering algorithm that evaluates the quality of sample points in the input dataset and assigns different weight values to samples based on their quality. By applying this method, when using transfer learning on a highly imbalanced new dataset, the accuracy of the transferred model was restored to 92.34% of the original model's performance. Our experiments also revealed that using this loss function structure allowed the model to maintain good stability despite insufficient and imbalanced data.", "AI": {"tldr": "\u63d0\u51faFilterLoss\u52a0\u6743\u635f\u5931\u51fd\u6570\u7ed3\u6784\uff0c\u901a\u8fc7\u4e3a\u4e0d\u540c\u6837\u672c\u70b9\u5206\u914d\u4e0d\u540c\u6743\u91cd\uff0c\u4f7f\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u80fd\u805a\u7126\u9ad8\u4ef7\u503c\u6837\u672c\u5e76\u9002\u5f53\u5904\u7406\u566a\u58f0\u548c\u8fb9\u754c\u6570\u636e\uff0c\u89e3\u51b3\u901a\u4fe1\u573a\u666f\u8bc6\u522b\u4e2d\u7684\u6570\u636e\u4e0d\u8db3\u548c\u6570\u636e\u5206\u5e03\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u901a\u4fe1\u573a\u666f\u8bc6\u522b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u65f6\u7684\u4e24\u5927\u6311\u6218\uff1a\u6570\u636e\u4e0d\u8db3\u548c\u6570\u636e\u5206\u5e03\u4e0d\u5e73\u8861\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u95ee\u9898\uff0c\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u8bbe\u8ba1\u4e86FilterLoss\u52a0\u6743\u635f\u5931\u51fd\u6570\u7ed3\u6784\uff0c\u4e3a\u4e0d\u540c\u6837\u672c\u70b9\u5206\u914d\u4e0d\u540c\u7684\u635f\u5931\u51fd\u6570\u6743\u91cd\u3002\u5f00\u53d1\u4e86\u5339\u914d\u6743\u91cd\u8fc7\u6ee4\u7b97\u6cd5\uff0c\u8bc4\u4f30\u8f93\u5165\u6570\u636e\u96c6\u4e2d\u6837\u672c\u70b9\u7684\u8d28\u91cf\uff0c\u5e76\u6839\u636e\u8d28\u91cf\u5206\u914d\u4e0d\u540c\u6743\u91cd\u503c\u3002", "result": "\u5728\u9ad8\u5ea6\u4e0d\u5e73\u8861\u7684\u65b0\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u65f6\uff0c\u8f6c\u79fb\u6a21\u578b\u7684\u51c6\u786e\u7387\u6062\u590d\u5230\u539f\u59cb\u6a21\u578b\u6027\u80fd\u768492.34%\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u8be5\u635f\u5931\u51fd\u6570\u7ed3\u6784\u80fd\u4f7f\u6a21\u578b\u5728\u6570\u636e\u4e0d\u8db3\u548c\u4e0d\u5e73\u8861\u60c5\u51b5\u4e0b\u4fdd\u6301\u826f\u597d\u7a33\u5b9a\u6027\u3002", "conclusion": "FilterLoss\u7ed3\u6784\u80fd\u6709\u6548\u89e3\u51b3\u901a\u4fe1\u573a\u666f\u8bc6\u522b\u4e2d\u7684\u6570\u636e\u4e0d\u8db3\u548c\u5206\u5e03\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u667a\u80fd\u6743\u91cd\u5206\u914d\u4f7f\u6a21\u578b\u805a\u7126\u91cd\u8981\u6837\u672c\uff0c\u5728\u8fc1\u79fb\u5b66\u4e60\u4e2d\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u5e76\u4fdd\u6301\u7a33\u5b9a\u6027\u3002"}}
{"id": "2602.08704", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.08704", "abs": "https://arxiv.org/abs/2602.08704", "authors": ["Moses Boudourides"], "title": "Friedkin-Johnsen Social Influence Dynamics on Networks: A Boundary-Value Formulation and Influenceability Measures", "comment": null, "summary": "This article presents a rigorous mathematical analysis of the Friedkin--Johnsen model of social influence on networks. We frame the opinion dynamics as a discrete boundary-value problem on a network, emphasizing the role of stubborn (boundary) and susceptible (interior) agents in shaping opinion evolution. This perspective allows for a precise analysis of how network structure, stubborn agents (boundary), and susceptible agents (interior) collectively determine the evolution of opinions. We derive the transient and steady-state solutions using two distinct but related approaches: a general resolvent-based method applicable to agents with heterogeneous susceptibilities, and a spectral method valid for the special case of homogeneous susceptibility. We further establish quantitative convergence rates to the steady state, derive explicit sensitivity formulas with respect to susceptibility parameters, and prove perturbation bounds under changes in the influence matrix. Moreover, we formally define a set of influenceability measures and prove some of their basic properties. Finally, we provide a Monte Carlo illustration on the Zachary karate club graph, showing how the proposed opinion broadcasting centralities and centralizations behave under random susceptibility profiles and how they relate to classical network centralities.", "AI": {"tldr": "\u672c\u6587\u5bf9Friedkin-Johnsen\u793e\u4ea4\u5f71\u54cd\u6a21\u578b\u8fdb\u884c\u4e86\u4e25\u683c\u7684\u6570\u5b66\u5206\u6790\uff0c\u5c06\u610f\u89c1\u52a8\u6001\u5efa\u6a21\u4e3a\u7f51\u7edc\u4e0a\u7684\u79bb\u6563\u8fb9\u754c\u503c\u95ee\u9898\uff0c\u5206\u6790\u4e86\u987d\u56fa\u8282\u70b9\u548c\u6613\u53d7\u5f71\u54cd\u8282\u70b9\u5982\u4f55\u5171\u540c\u51b3\u5b9a\u610f\u89c1\u6f14\u5316\u3002", "motivation": "\u7814\u7a76\u793e\u4ea4\u7f51\u7edc\u4e2d\u610f\u89c1\u52a8\u6001\u7684\u6570\u5b66\u57fa\u7840\uff0c\u7279\u522b\u662f\u5206\u6790\u7f51\u7edc\u7ed3\u6784\u3001\u987d\u56fa\u8282\u70b9\uff08\u8fb9\u754c\uff09\u548c\u6613\u53d7\u5f71\u54cd\u8282\u70b9\uff08\u5185\u90e8\uff09\u5982\u4f55\u5171\u540c\u51b3\u5b9a\u610f\u89c1\u6f14\u5316\u8fc7\u7a0b\u3002", "method": "\u5c06\u610f\u89c1\u52a8\u6001\u5efa\u6a21\u4e3a\u7f51\u7edc\u4e0a\u7684\u79bb\u6563\u8fb9\u754c\u503c\u95ee\u9898\uff0c\u91c7\u7528\u4e24\u79cd\u65b9\u6cd5\uff1a\u9002\u7528\u4e8e\u5f02\u8d28\u6613\u611f\u6027\u7684\u901a\u7528\u57fa\u4e8e\u9884\u89e3\u5f0f\u7684\u65b9\u6cd5\uff0c\u4ee5\u53ca\u9002\u7528\u4e8e\u540c\u8d28\u6613\u611f\u6027\u7684\u8c31\u65b9\u6cd5\u3002", "result": "\u63a8\u5bfc\u4e86\u77ac\u6001\u548c\u7a33\u6001\u89e3\uff0c\u5efa\u7acb\u4e86\u6536\u655b\u901f\u7387\uff0c\u63a8\u5bfc\u4e86\u654f\u611f\u6027\u516c\u5f0f\uff0c\u8bc1\u660e\u4e86\u6270\u52a8\u8fb9\u754c\uff0c\u5b9a\u4e49\u4e86\u5f71\u54cd\u6027\u5ea6\u91cf\u5e76\u8bc1\u660e\u4e86\u5176\u57fa\u672c\u6027\u8d28\uff0c\u5728Zachary\u7a7a\u624b\u9053\u4ff1\u4e50\u90e8\u56fe\u4e0a\u8fdb\u884c\u4e86\u8499\u7279\u5361\u6d1b\u6a21\u62df\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aFriedkin-Johnsen\u6a21\u578b\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u6570\u5b66\u6846\u67b6\uff0c\u80fd\u591f\u7cbe\u786e\u5206\u6790\u7f51\u7edc\u7ed3\u6784\u3001\u8282\u70b9\u7279\u6027\u5bf9\u610f\u89c1\u6f14\u5316\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u5f71\u54cd\u6027\u5ea6\u91cf\u65b9\u6cd5\u3002"}}
{"id": "2602.06998", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.06998", "abs": "https://arxiv.org/abs/2602.06998", "authors": ["Andhika Bernard Lumbantobing", "Hokky Situngkir"], "title": "Tokenizations for Austronesian Language Models: study on languages in Indonesia Archipelago", "comment": "14 pages, 3 figures", "summary": "Tokenization constitutes a fundamental stage in Large Language Model (LLM) processing; however, subword-based tokenization methods optimized on English-dominant corpora may produce token fragmentation misaligned with the linguistic structures of Austronesian languages. This study aimed to develop a syllable-based tokenization framework adopting principles from traditional Indonesian scripts (aksara) for regional languages of Indonesia. A syllabic segmentation procedure was constructed based on the logic of abugida writing systems and implemented with a vocabulary of 2,843 tokens extracted from the Indonesian dictionary (KBBI). Evaluation was conducted on the NusaX dataset comprising 1,000 parallel translation samples across 10 regional languages, Indonesian, and English. Analysis employed Token per Character (TPC) ratio and sequence alignment using the Smith-Waterman algorithm. Results demonstrated that syllable-based tokenization yielded consistent TPC values across all regional languages, whereas GPT-2 exhibited an inverse pattern with the lowest TPC for English. Syllable-based tokenization consistently produced higher token sequence similarity scores, with an average increase of approximately 21% compared to GPT-2. These findings confirm that the syllable-based approach more effectively preserves phonological and morphological patterns across related Austronesian languages, offering a linguistically principled foundation for multilingual LLM development.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4e3a\u5370\u5c3c\u533a\u57df\u8bed\u8a00\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u97f3\u8282\u7684\u6807\u8bb0\u5316\u6846\u67b6\uff0c\u501f\u9274\u4f20\u7edf\u6587\u5b57\u7cfb\u7edf\uff0c\u76f8\u6bd4GPT-2\u7684\u57fa\u4e8e\u5b50\u8bcd\u7684\u6807\u8bb0\u5316\uff0c\u80fd\u66f4\u597d\u5730\u4fdd\u6301\u5357\u5c9b\u8bed\u7cfb\u8bed\u8a00\u7684\u8bed\u97f3\u548c\u5f62\u6001\u6a21\u5f0f\u3002", "motivation": "\u57fa\u4e8e\u82f1\u8bed\u4e3b\u5bfc\u8bed\u6599\u4f18\u5316\u7684\u5b50\u8bcd\u6807\u8bb0\u5316\u65b9\u6cd5\u5728\u5904\u7406\u5357\u5c9b\u8bed\u7cfb\u8bed\u8a00\u65f6\u4f1a\u4ea7\u751f\u4e0e\u8bed\u8a00\u7ed3\u6784\u4e0d\u5339\u914d\u7684\u6807\u8bb0\u788e\u7247\u5316\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7b26\u5408\u8fd9\u4e9b\u8bed\u8a00\u7279\u6027\u7684\u6807\u8bb0\u5316\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u963f\u5e03\u5409\u8fbe\u6587\u5b57\u7cfb\u7edf\u903b\u8f91\u6784\u5efa\u97f3\u8282\u5206\u5272\u7a0b\u5e8f\uff0c\u4ece\u5370\u5c3c\u8bed\u8bcd\u5178\u63d0\u53d62,843\u4e2a\u6807\u8bb0\u6784\u5efa\u8bcd\u6c47\u8868\uff0c\u5728\u5305\u542b10\u79cd\u533a\u57df\u8bed\u8a00\u7684NusaX\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4f7f\u7528TPC\u6bd4\u7387\u548cSmith-Waterman\u5e8f\u5217\u5bf9\u9f50\u7b97\u6cd5\u8fdb\u884c\u5206\u6790\u3002", "result": "\u97f3\u8282\u6807\u8bb0\u5316\u5728\u6240\u6709\u533a\u57df\u8bed\u8a00\u4e2d\u4ea7\u751f\u4e00\u81f4\u7684TPC\u503c\uff0c\u800cGPT-2\u5bf9\u82f1\u8bed\u7684TPC\u503c\u6700\u4f4e\uff1b\u97f3\u8282\u6807\u8bb0\u5316\u5e73\u5747\u6bd4GPT-2\u63d0\u9ad8\u7ea621%\u7684\u6807\u8bb0\u5e8f\u5217\u76f8\u4f3c\u5ea6\u5206\u6570\u3002", "conclusion": "\u57fa\u4e8e\u97f3\u8282\u7684\u6807\u8bb0\u5316\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u5730\u4fdd\u6301\u76f8\u5173\u5357\u5c9b\u8bed\u7cfb\u8bed\u8a00\u7684\u8bed\u97f3\u548c\u5f62\u6001\u6a21\u5f0f\uff0c\u4e3a\u591a\u8bed\u8a00LLM\u5f00\u53d1\u63d0\u4f9b\u4e86\u8bed\u8a00\u5b66\u4e0a\u66f4\u5408\u7406\u7684\u57fa\u7840\u3002"}}
{"id": "2602.07055", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07055", "abs": "https://arxiv.org/abs/2602.07055", "authors": ["Pingyue Zhang", "Zihan Huang", "Yue Wang", "Jieyu Zhang", "Letian Xue", "Zihan Wang", "Qineng Wang", "Keshigeyan Chandrasegaran", "Ruohan Zhang", "Yejin Choi", "Ranjay Krishna", "Jiajun Wu", "Li Fei-Fei", "Manling Li"], "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?", "comment": "published at iclr 2026", "summary": "Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We propose Theory of Space, defined as an agent's ability to actively acquire information through self-directed, active exploration and to construct, revise, and exploit a spatial belief from sequential, partial observations. We evaluate this through a benchmark where the goal is curiosity-driven exploration to build an accurate cognitive map. A key innovation is spatial belief probing, which prompts models to reveal their internal spatial representations at each step. Our evaluation of state-of-the-art models reveals several critical bottlenecks. First, we identify an Active-Passive Gap, where performance drops significantly when agents must autonomously gather information. Second, we find high inefficiency, as models explore unsystematically compared to program-based proxies. Through belief probing, we diagnose that while perception is an initial bottleneck, global beliefs suffer from instability that causes spatial knowledge to degrade over time. Finally, using a false belief paradigm, we uncover Belief Inertia, where agents fail to update obsolete priors with new evidence. This issue is present in text-based agents but is particularly severe in vision-based models. Our findings suggest that current foundation models struggle to maintain coherent, revisable spatial beliefs during active exploration.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u7a7a\u95f4\u7406\u8bba\"\u6982\u5ff5\uff0c\u8bc4\u4f30\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u4e3b\u52a8\u7a7a\u95f4\u63a2\u7d22\u4e2d\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5b58\u5728\u4e3b\u52a8-\u88ab\u52a8\u5dee\u8ddd\u3001\u63a2\u7d22\u6548\u7387\u4f4e\u3001\u7a7a\u95f4\u4fe1\u5ff5\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\u3002", "motivation": "\u867d\u7136\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u88ab\u52a8\u611f\u77e5\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5728\u4e3b\u52a8\u3001\u81ea\u4e3b\u63a2\u7d22\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u7a7a\u95f4\u5177\u8eab\u667a\u80fd\u9700\u8981\u667a\u80fd\u4f53\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u901a\u8fc7\u884c\u52a8\u83b7\u53d6\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\"\u7a7a\u95f4\u7406\u8bba\"\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e3a\u667a\u80fd\u4f53\u901a\u8fc7\u81ea\u4e3b\u4e3b\u52a8\u63a2\u7d22\u83b7\u53d6\u4fe1\u606f\u3001\u4ece\u5e8f\u5217\u90e8\u5206\u89c2\u6d4b\u4e2d\u6784\u5efa\u3001\u4fee\u6b63\u548c\u5229\u7528\u7a7a\u95f4\u4fe1\u5ff5\u7684\u80fd\u529b\u3002\u901a\u8fc7\u597d\u5947\u5fc3\u9a71\u52a8\u63a2\u7d22\u6784\u5efa\u51c6\u786e\u8ba4\u77e5\u5730\u56fe\u7684\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u5173\u952e\u521b\u65b0\u662f\u7a7a\u95f4\u4fe1\u5ff5\u63a2\u6d4b\u6280\u672f\uff0c\u5728\u6bcf\u4e00\u6b65\u63d0\u793a\u6a21\u578b\u63ed\u793a\u5176\u5185\u90e8\u7a7a\u95f4\u8868\u5f81\u3002", "result": "\u8bc4\u4f30\u6700\u5148\u8fdb\u6a21\u578b\u53d1\u73b0\u51e0\u4e2a\u5173\u952e\u74f6\u9888\uff1a1) \u4e3b\u52a8-\u88ab\u52a8\u5dee\u8ddd - \u5f53\u667a\u80fd\u4f53\u5fc5\u987b\u81ea\u4e3b\u6536\u96c6\u4fe1\u606f\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff1b2) \u9ad8\u65e0\u6548\u6027 - \u4e0e\u57fa\u4e8e\u7a0b\u5e8f\u7684\u4ee3\u7406\u76f8\u6bd4\uff0c\u6a21\u578b\u63a2\u7d22\u4e0d\u7cfb\u7edf\uff1b3) \u7a7a\u95f4\u4fe1\u5ff5\u4e0d\u7a33\u5b9a - \u5168\u5c40\u4fe1\u5ff5\u5b58\u5728\u4e0d\u7a33\u5b9a\u6027\uff0c\u5bfc\u81f4\u7a7a\u95f4\u77e5\u8bc6\u968f\u65f6\u95f4\u9000\u5316\uff1b4) \u4fe1\u5ff5\u60ef\u6027 - \u667a\u80fd\u4f53\u65e0\u6cd5\u7528\u65b0\u8bc1\u636e\u66f4\u65b0\u8fc7\u65f6\u7684\u5148\u9a8c\uff0c\u8fd9\u5728\u57fa\u4e8e\u89c6\u89c9\u7684\u6a21\u578b\u4e2d\u5c24\u4e3a\u4e25\u91cd\u3002", "conclusion": "\u5f53\u524d\u57fa\u7840\u6a21\u578b\u5728\u4e3b\u52a8\u63a2\u7d22\u8fc7\u7a0b\u4e2d\u96be\u4ee5\u7ef4\u6301\u8fde\u8d2f\u3001\u53ef\u4fee\u6b63\u7684\u7a7a\u95f4\u4fe1\u5ff5\uff0c\u63ed\u793a\u4e86\u591a\u6a21\u6001\u6a21\u578b\u5728\u7a7a\u95f4\u63a8\u7406\u548c\u4e3b\u52a8\u4fe1\u606f\u83b7\u53d6\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.08787", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2602.08787", "abs": "https://arxiv.org/abs/2602.08787", "authors": ["Cory Petersen", "Feng Ye", "Jiaxiang Ji", "Josh Kohut", "Ahmed Aziz Ezzat", "David Saginaw", "Avril Montanti", "Jack Cammarota"], "title": "Accessibility and Serviceability Assessment to Inform Offshore Wind Energy Development and Operations off the U.S. East Coast", "comment": null, "summary": "The economic success of offshore wind energy projects relies on accurate projections of the construction, and operations and maintenance (O&M) costs. These projections must consider the logistical complexities introduced by adverse met-ocean conditions that can prohibit access to the offshore assets for sustained periods of time. In response, the goal of this study is two-fold: (1) to provide high-resolution estimates of the accessibility of key offshore wind energy areas in the United States (U.S.) East Coast--a region with significant offshore wind energy potential; and (2) to introduce a new operational metric, called serviceability, as motivated by the need to assess the accessibility of an offshore asset along a vessel travel path, rather than at a specific site, as commonly carried out in the literature. We hypothesize that serviceability is more relevant to offshore operations than accessibility, since it more realistically reflects the success and safety of a vessel operation along its journey from port to site and back. Our analysis reveals high temporal and spatial variations in accessibility and serviceability, even for proximate offshore locations. We also find that solely relying on numerical met-ocean data can introduce considerable bias in estimating accessibility and serviceability, raising the need for a statistical treatment that combines both numerical and observational data sources, such as the one proposed herein. Collectively, our analysis sheds light on the value of high-resolution met-ocean information and models in supporting offshore operations, including but not limited to future offshore wind energy developments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4e3a\u7f8e\u56fd\u4e1c\u6d77\u5cb8\u6d77\u4e0a\u98ce\u7535\u9879\u76ee\u63d0\u4f9b\u4e86\u9ad8\u5206\u8fa8\u7387\u53ef\u8bbf\u95ee\u6027\u8bc4\u4f30\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\"\u53ef\u670d\u52a1\u6027\"\u6307\u6807\uff0c\u5f3a\u8c03\u8003\u8651\u8239\u8236\u822a\u884c\u8def\u5f84\u800c\u975e\u5355\u70b9\u4f4d\u7f6e\uff0c\u4ee5\u66f4\u771f\u5b9e\u53cd\u6620\u6d77\u4e0a\u8fd0\u7ef4\u64cd\u4f5c\u7684\u6210\u529f\u7387\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u6d77\u4e0a\u98ce\u7535\u9879\u76ee\u7684\u7ecf\u6d4e\u6210\u529f\u4f9d\u8d56\u4e8e\u5bf9\u5efa\u8bbe\u548c\u8fd0\u7ef4\u6210\u672c\u7684\u51c6\u786e\u9884\u6d4b\uff0c\u8fd9\u4e9b\u9884\u6d4b\u9700\u8981\u8003\u8651\u6076\u52a3\u6d77\u6d0b\u6c14\u8c61\u6761\u4ef6\u5e26\u6765\u7684\u7269\u6d41\u590d\u6742\u6027\u3002\u73b0\u6709\u7814\u7a76\u901a\u5e38\u53ea\u8bc4\u4f30\u7279\u5b9a\u7ad9\u70b9\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u800c\u5ffd\u7565\u4e86\u8239\u8236\u4ece\u6e2f\u53e3\u5230\u7ad9\u70b9\u5f80\u8fd4\u6574\u4e2a\u822a\u884c\u8def\u5f84\u7684\u5b9e\u9645\u64cd\u4f5c\u60c5\u51b5\u3002", "method": "\u7814\u7a76\u91c7\u7528\u9ad8\u5206\u8fa8\u7387\u6d77\u6d0b\u6c14\u8c61\u6570\u636e\uff0c\u5bf9\u7f8e\u56fd\u4e1c\u6d77\u5cb8\u5173\u952e\u6d77\u4e0a\u98ce\u7535\u533a\u57df\u8fdb\u884c\u53ef\u8bbf\u95ee\u6027\u8bc4\u4f30\uff0c\u5e76\u5f15\u5165\u65b0\u7684\"\u53ef\u670d\u52a1\u6027\"\u64cd\u4f5c\u6307\u6807\uff0c\u8be5\u6307\u6807\u8003\u8651\u8239\u8236\u822a\u884c\u8def\u5f84\u800c\u975e\u5355\u4e00\u7ad9\u70b9\u3002\u540c\u65f6\u63d0\u51fa\u7ed3\u5408\u6570\u503c\u6570\u636e\u548c\u89c2\u6d4b\u6570\u636e\u7684\u7edf\u8ba1\u5904\u7406\u65b9\u6cd5\uff0c\u4ee5\u51cf\u5c11\u5355\u7eaf\u4f9d\u8d56\u6570\u503c\u6570\u636e\u5e26\u6765\u7684\u504f\u5dee\u3002", "result": "\u5206\u6790\u663e\u793a\u5373\u4f7f\u90bb\u8fd1\u7684\u6d77\u4e0a\u4f4d\u7f6e\uff0c\u53ef\u8bbf\u95ee\u6027\u548c\u53ef\u670d\u52a1\u6027\u4e5f\u5b58\u5728\u9ad8\u5ea6\u65f6\u7a7a\u53d8\u5316\u3002\u7814\u7a76\u53d1\u73b0\u5355\u7eaf\u4f9d\u8d56\u6570\u503c\u6d77\u6d0b\u6c14\u8c61\u6570\u636e\u4f1a\u5f15\u5165\u663e\u8457\u504f\u5dee\uff0c\u9700\u8981\u7ed3\u5408\u6570\u503c\u548c\u89c2\u6d4b\u6570\u636e\u7684\u7edf\u8ba1\u5904\u7406\u3002\u9ad8\u5206\u8fa8\u7387\u6d77\u6d0b\u6c14\u8c61\u4fe1\u606f\u548c\u6a21\u578b\u5bf9\u652f\u6301\u6d77\u4e0a\u8fd0\u7ef4\u64cd\u4f5c\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002", "conclusion": "\u53ef\u670d\u52a1\u6027\u6307\u6807\u6bd4\u4f20\u7edf\u53ef\u8bbf\u95ee\u6027\u6307\u6807\u66f4\u80fd\u771f\u5b9e\u53cd\u6620\u6d77\u4e0a\u8fd0\u7ef4\u64cd\u4f5c\u7684\u6210\u529f\u7387\u548c\u5b89\u5168\u6027\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u9ad8\u5206\u8fa8\u7387\u6d77\u6d0b\u6c14\u8c61\u6570\u636e\u548c\u6a21\u578b\u5bf9\u6d77\u4e0a\u98ce\u7535\u7b49\u6d77\u4e0a\u8fd0\u7ef4\u64cd\u4f5c\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u51cf\u5c11\u8bc4\u4f30\u504f\u5dee\u7684\u7edf\u8ba1\u5904\u7406\u65b9\u6cd5\u3002"}}
{"id": "2602.08052", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.08052", "abs": "https://arxiv.org/abs/2602.08052", "authors": ["Bulent Soykan", "Sean Mondesire", "Ghaith Rabadi", "Grace Bochenek"], "title": "Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling", "comment": "11 pages, 2 figures, Winter Simulation Conference (WSC) 2025", "summary": "The Unrelated Parallel Machine Scheduling Problem (UPMSP) with release dates, setups, and eligibility constraints presents a significant multi-objective challenge. Traditional methods struggle to balance minimizing Total Weighted Tardiness (TWT) and Total Setup Time (TST). This paper proposes a Deep Reinforcement Learning framework using Proximal Policy Optimization (PPO) and a Graph Neural Network (GNN). The GNN effectively represents the complex state of jobs, machines, and setups, allowing the PPO agent to learn a direct scheduling policy. Guided by a multi-objective reward function, the agent simultaneously minimizes TWT and TST. Experimental results on benchmark instances demonstrate that our PPO-GNN agent significantly outperforms a standard dispatching rule and a metaheuristic, achieving a superior trade-off between both objectives. This provides a robust and scalable solution for complex manufacturing scheduling.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8ePPO\u548cGNN\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u5177\u6709\u91ca\u653e\u65f6\u95f4\u3001\u8bbe\u7f6e\u548c\u8d44\u683c\u7ea6\u675f\u7684\u4e0d\u76f8\u5173\u5e76\u884c\u673a\u8c03\u5ea6\u95ee\u9898\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u603b\u52a0\u6743\u5ef6\u8fdf\u548c\u603b\u8bbe\u7f6e\u65f6\u95f4\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u603b\u52a0\u6743\u5ef6\u8fdf\u548c\u603b\u8bbe\u7f6e\u65f6\u95f4\u8fd9\u4e24\u4e2a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5904\u7406\u590d\u6742\u7684\u5236\u9020\u8c03\u5ea6\u573a\u666f\u3002", "method": "\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\uff0cGNN\u8868\u793a\u4f5c\u4e1a\u3001\u673a\u5668\u548c\u8bbe\u7f6e\u7684\u590d\u6742\u72b6\u6001\uff0cPPO\u4ee3\u7406\u5b66\u4e60\u76f4\u63a5\u8c03\u5ea6\u7b56\u7565\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u5956\u52b1\u51fd\u6570\u6307\u5bfc\u8bad\u7ec3\u3002", "result": "\u5728\u57fa\u51c6\u5b9e\u4f8b\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPPO-GNN\u4ee3\u7406\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u8c03\u5ea6\u89c4\u5219\u548c\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5728\u4e24\u4e2a\u76ee\u6807\u4e4b\u95f4\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u6743\u8861\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u590d\u6742\u5236\u9020\u8c03\u5ea6\u63d0\u4f9b\u4e86\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u591a\u76ee\u6807\u8c03\u5ea6\u95ee\u9898\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.07841", "categories": ["econ.EM", "q-fin.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.07841", "abs": "https://arxiv.org/abs/2602.07841", "authors": ["Cheng Zhang"], "title": "A Quadratic Link between Out-of-Sample $R^2$ and Directional Accuracy", "comment": null, "summary": "This study provides a novel perspective on the metric disconnect phenomenon in financial time series forecasting through an analytical link that reconciles the out-of-sample $R^2$ ($R^2_{OOS}$) and directional accuracy (DA). In particular, using the random walk model as a baseline and assuming that sign correctness is independent of realized magnitude, we show that these two metrics exhibit a quadratic relationship for MSE-optimal point forecasts. For point forecasts with modest DA, the theoretical value of $R^2_{OOS}$ is intrinsically negligible. Thus, a negative empirical $R^2_{OOS}$ is expected if the model is suboptimal or affected by finite sample noise.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790\u8fde\u63a5\u6837\u672c\u5916R\u00b2\u548c\u65b9\u5411\u51c6\u786e\u7387\uff0c\u63ed\u793a\u4e86\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5ea6\u91cf\u8131\u8282\u73b0\u8c61\uff0c\u6307\u51fa\u5bf9\u4e8eDA\u9002\u4e2d\u7684\u70b9\u9884\u6d4b\uff0cR\u00b2OOS\u7406\u8bba\u4e0a\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "motivation": "\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u5b58\u5728\u5ea6\u91cf\u8131\u8282\u73b0\u8c61\uff0c\u5373\u6837\u672c\u5916R\u00b2\uff08R\u00b2OOS\uff09\u548c\u65b9\u5411\u51c6\u786e\u7387\uff08DA\uff09\u4e4b\u95f4\u7684\u5173\u7cfb\u4e0d\u660e\u786e\u3002\u7814\u7a76\u8005\u5e0c\u671b\u4ece\u5206\u6790\u89d2\u5ea6\u5efa\u7acb\u8fd9\u4e24\u4e2a\u5e38\u7528\u8bc4\u4f30\u6307\u6807\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u4e3a\u9884\u6d4b\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u65b0\u7684\u7406\u8bba\u89c6\u89d2\u3002", "method": "\u4ee5\u968f\u673a\u6e38\u8d70\u6a21\u578b\u4e3a\u57fa\u51c6\uff0c\u5047\u8bbe\u7b26\u53f7\u6b63\u786e\u6027\u4e0e\u5b9e\u73b0\u5e45\u5ea6\u72ec\u7acb\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u63a8\u5bfc\u51faMSE\u6700\u4f18\u70b9\u9884\u6d4b\u4e0bR\u00b2OOS\u548cDA\u4e4b\u95f4\u7684\u4e8c\u6b21\u5173\u7cfb\u3002\u7814\u7a76\u91c7\u7528\u89e3\u6790\u65b9\u6cd5\u800c\u975e\u5b9e\u8bc1\u65b9\u6cd5\uff0c\u5efa\u7acb\u8fd9\u4e24\u4e2a\u6307\u6807\u4e4b\u95f4\u7684\u6570\u5b66\u8054\u7cfb\u3002", "result": "\u7814\u7a76\u53d1\u73b0R\u00b2OOS\u548cDA\u4e4b\u95f4\u5b58\u5728\u4e8c\u6b21\u5173\u7cfb\u3002\u5bf9\u4e8e\u65b9\u5411\u51c6\u786e\u7387\u9002\u4e2d\u7684\u70b9\u9884\u6d4b\uff0c\u6837\u672c\u5916R\u00b2\u7684\u7406\u8bba\u503c\u672c\u8d28\u4e0a\u662f\u53ef\u5ffd\u7565\u4e0d\u8ba1\u7684\u3002\u5982\u679c\u6a21\u578b\u4e0d\u662f\u6700\u4f18\u7684\u6216\u53d7\u5230\u6709\u9650\u6837\u672c\u566a\u58f0\u7684\u5f71\u54cd\uff0c\u8d1f\u7684\u5b9e\u8bc1R\u00b2OOS\u662f\u9884\u671f\u7684\u7ed3\u679c\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5ea6\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\uff0c\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5373\u4f7f\u65b9\u5411\u9884\u6d4b\u51c6\u786e\uff0c\u6837\u672c\u5916R\u00b2\u4e5f\u53ef\u80fd\u5f88\u4f4e\u751a\u81f3\u4e3a\u8d1f\u3002\u8fd9\u5bf9\u4e8e\u6b63\u786e\u7406\u89e3\u9884\u6d4b\u6a21\u578b\u6027\u80fd\u8bc4\u4f30\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.08953", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.08953", "abs": "https://arxiv.org/abs/2602.08953", "authors": ["William Guo", "Edward Xiong", "Jie Gao"], "title": "Robust Sequential Learning in Random Order Networks", "comment": "Proc. of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "In the sequential learning problem, agents in a network attempt to predict a binary ground truth, informed by both a noisy private signal and the predictions of neighboring agents before them. It is well known that social learning in this setting can be highly fragile: small changes to the action ordering, network topology, or even the strength of the agents' private signals can prevent a network from converging to the truth. We study networks that achieve random-order asymptotic truth learning, in which almost all agents learn the ground truth when the decision ordering is selected uniformly at random. We analyze the robustness of these networks, showing that those achieving random-order asymptotic truth learning are resilient to a bounded number of adversarial modifications. We characterize necessary conditions for such networks to succeed in this setting and introduce several graph constructions that learn through different mechanisms. Finally, we present a randomized polynomial-time algorithm that transforms an arbitrary network into one achieving random-order learning using minimal edge or vertex modifications, with provable approximation guarantees. Our results reveal structural properties of networks that achieve random-order learning and provide algorithmic tools for designing robust social networks.", "AI": {"tldr": "\u7814\u7a76\u793e\u4ea4\u7f51\u7edc\u4e2d\u987a\u5e8f\u5b66\u4e60\u95ee\u9898\uff0c\u5206\u6790\u968f\u673a\u987a\u5e8f\u6e10\u8fd1\u771f\u7406\u5b66\u4e60\u7f51\u7edc\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u51fa\u56fe\u6784\u9020\u65b9\u6cd5\u548c\u6700\u5c0f\u5316\u4fee\u6539\u7b97\u6cd5", "motivation": "\u4f20\u7edf\u987a\u5e8f\u5b66\u4e60\u4e2d\uff0c\u793e\u4ea4\u7f51\u7edc\u5bf9\u884c\u52a8\u987a\u5e8f\u3001\u62d3\u6251\u7ed3\u6784\u6216\u79c1\u4eba\u4fe1\u53f7\u5f3a\u5ea6\u7684\u5fae\u5c0f\u53d8\u5316\u9ad8\u5ea6\u654f\u611f\uff0c\u5bb9\u6613\u5bfc\u81f4\u65e0\u6cd5\u6536\u655b\u5230\u771f\u76f8\u3002\u9700\u8981\u7814\u7a76\u80fd\u591f\u5b9e\u73b0\u968f\u673a\u987a\u5e8f\u6e10\u8fd1\u771f\u7406\u5b66\u4e60\u7684\u7f51\u7edc\u53ca\u5176\u9c81\u68d2\u6027\u3002", "method": "1) \u5206\u6790\u5b9e\u73b0\u968f\u673a\u987a\u5e8f\u6e10\u8fd1\u771f\u7406\u5b66\u4e60\u7f51\u7edc\u7684\u9c81\u68d2\u6027\uff0c\u8bc1\u660e\u5176\u80fd\u62b5\u6297\u6709\u9650\u6570\u91cf\u7684\u5bf9\u6297\u6027\u4fee\u6539\uff1b2) \u63d0\u51fa\u6b64\u7c7b\u7f51\u7edc\u6210\u529f\u7684\u5fc5\u8981\u6761\u4ef6\uff1b3) \u8bbe\u8ba1\u591a\u79cd\u901a\u8fc7\u4e0d\u540c\u673a\u5236\u5b9e\u73b0\u5b66\u4e60\u7684\u56fe\u6784\u9020\uff1b4) \u63d0\u51fa\u968f\u673a\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u5c06\u4efb\u610f\u7f51\u7edc\u8f6c\u5316\u4e3a\u968f\u673a\u987a\u5e8f\u5b66\u4e60\u7f51\u7edc\uff0c\u4f7f\u7528\u6700\u5c0f\u8fb9\u6216\u9876\u70b9\u4fee\u6539\u3002", "result": "1) \u63ed\u793a\u4e86\u5b9e\u73b0\u968f\u673a\u987a\u5e8f\u5b66\u4e60\u7684\u7f51\u7edc\u7ed3\u6784\u7279\u6027\uff1b2) \u63d0\u4f9b\u4e86\u8bbe\u8ba1\u9c81\u68d2\u793e\u4ea4\u7f51\u7edc\u7684\u7b97\u6cd5\u5de5\u5177\uff1b3) \u8bc1\u660e\u4e86\u7b97\u6cd5\u5177\u6709\u53ef\u8bc1\u660e\u7684\u8fd1\u4f3c\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u968f\u673a\u987a\u5e8f\u6e10\u8fd1\u771f\u7406\u5b66\u4e60\u7f51\u7edc\u7684\u7ed3\u6784\u7279\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5c06\u4efb\u610f\u7f51\u7edc\u8f6c\u5316\u4e3a\u6b64\u7c7b\u9c81\u68d2\u7f51\u7edc\u7684\u7b97\u6cd5\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u8bbe\u8ba1\u66f4\u53ef\u9760\u7684\u793e\u4ea4\u5b66\u4e60\u7cfb\u7edf\u3002"}}
{"id": "2602.07021", "categories": ["cs.CY", "cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07021", "abs": "https://arxiv.org/abs/2602.07021", "authors": ["Sahibpreet Singh", "Saksham Sharma"], "title": "AI for Sustainable Data Protection and Fair Algorithmic Management in Environmental Regulation", "comment": "Presented at National Conference on Navigating The Intersection of Artificial Intelligence and Law: Ethical and Legal Horizons, 29 September 2024, pp. 91-106", "summary": "Integration of AI into environmental regulation represents a significant advancement in data management. It offers promising results in both data protection plus algorithmic fairness. This research addresses the critical need for sustainable data protection in the era of ever evolving cyber threats. Traditional encryption methods face limitations in handling the dynamic nature of environmental data. This necessitates the exploration of advanced cryptographic techniques. The objective of this study is to evaluate how AI can enhance these techniques to ensure robust data protection while facilitating fair algorithmic management. The methodology involves a comprehensive review of current advancements in AI-enhanced homomorphic encryption (HE) and multi-party computation (MPC). It is coupled with an analysis of how these techniques can be applied to environmental data regulation. Key findings indicate that AI-driven dynamic key management, adaptive encryption schemes, and optimized computational efficiency in HE, alongside AI-enhanced protocol optimization and fault mitigation in MPC, significantly improve the security of environmental data processing. These findings highlight a crucial research gap in the intersection of AI, cyber laws, and environmental regulation, particularly in terms of addressing algorithmic bias, transparency, and accountability. The implications of this research underscore the need for stricter cyber laws. Also, the development of comprehensive regulations to safeguard sensitive environmental data. Future efforts should focus on refining AI systems to balance security with privacy and ensuring that regulatory frameworks can adapt to technological advancements. This study provides a foundation for future research aimed at achieving secure sustainable environmental data management through AI innovations.", "AI": {"tldr": "AI\u589e\u5f3a\u52a0\u5bc6\u6280\u672f\u53ef\u63d0\u5347\u73af\u5883\u6570\u636e\u4fdd\u62a4\u4e0e\u7b97\u6cd5\u516c\u5e73\u6027\uff0c\u4f46\u9700\u5b8c\u5584\u7f51\u7edc\u6cd5\u5f8b\u4e0e\u76d1\u7ba1\u6846\u67b6", "motivation": "\u4f20\u7edf\u52a0\u5bc6\u65b9\u6cd5\u5728\u5904\u7406\u52a8\u6001\u73af\u5883\u6570\u636e\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u63a2\u7d22\u5148\u8fdb\u52a0\u5bc6\u6280\u672f\uff0c\u5e76\u5229\u7528AI\u589e\u5f3a\u8fd9\u4e9b\u6280\u672f\u4ee5\u5b9e\u73b0\u7a33\u5065\u7684\u6570\u636e\u4fdd\u62a4\u548c\u516c\u5e73\u7684\u7b97\u6cd5\u7ba1\u7406", "method": "\u5bf9AI\u589e\u5f3a\u7684\u540c\u6001\u52a0\u5bc6\uff08HE\uff09\u548c\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\uff08MPC\uff09\u7684\u6700\u65b0\u8fdb\u5c55\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\uff0c\u5206\u6790\u8fd9\u4e9b\u6280\u672f\u5982\u4f55\u5e94\u7528\u4e8e\u73af\u5883\u6570\u636e\u76d1\u7ba1", "result": "AI\u9a71\u52a8\u7684\u52a8\u6001\u5bc6\u94a5\u7ba1\u7406\u3001\u81ea\u9002\u5e94\u52a0\u5bc6\u65b9\u6848\u3001HE\u8ba1\u7b97\u6548\u7387\u4f18\u5316\uff0c\u4ee5\u53caMPC\u534f\u8bae\u4f18\u5316\u548c\u6545\u969c\u7f13\u89e3\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u73af\u5883\u6570\u636e\u5904\u7406\u7684\u5b89\u5b89\u5168\u6027", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86AI\u3001\u7f51\u7edc\u6cd5\u5f8b\u548c\u73af\u5883\u76d1\u7ba1\u4ea4\u53c9\u9886\u57df\u7684\u91cd\u8981\u7814\u7a76\u7a7a\u767d\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u4e25\u683c\u7684\u7f51\u7edc\u6cd5\u5f8b\u548c\u5168\u9762\u7684\u76d1\u7ba1\u6846\u67b6\uff0c\u672a\u6765\u5e94\u5b8c\u5584AI\u7cfb\u7edf\u4ee5\u5e73\u8861\u5b89\u5168\u4e0e\u9690\u79c1"}}
{"id": "2602.07153", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07153", "abs": "https://arxiv.org/abs/2602.07153", "authors": ["Jinbiao Wei", "Yilun Zhao", "Kangqi Ni", "Arman Cohan"], "title": "ANCHOR: Branch-Point Data Generation for GUI Agents", "comment": null, "summary": "End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drifting trajectories. We present a trajectory expansion framework Anchor that bootstraps scalable desktop supervision from a small set of verified seed demonstrations. Starting from each seed, we identify branch points that correspond to meaningful state changes and propose new, state-grounded task variants conditioned on the current GUI context. An executing agent then follows the proposed instructions to generate new trajectories, while a verifier enforces task completion via state-aware checks and trajectory-level consistency. To improve supervision quality, we further apply task-conditioned step-level filtering to remove ungrounded actions and denoise post-branch segments to maintain coherent intent. Experiments on standard desktop benchmarks, OSWorld and WindowsAgentArena, show that models fine-tuned on our expanded corpus achieve consistent improvements over zero-shot agents and representative synthesis baselines, and generalize across applications and operating systems.", "AI": {"tldr": "Anchor\u6846\u67b6\u901a\u8fc7\u5c11\u91cf\u5df2\u9a8c\u8bc1\u79cd\u5b50\u6f14\u793a\uff0c\u901a\u8fc7\u72b6\u6001\u5206\u652f\u70b9\u8bc6\u522b\u548c\u4efb\u52a1\u53d8\u4f53\u751f\u6210\uff0c\u6269\u5c55\u684c\u9762GUI\u4ea4\u4e92\u6570\u636e\uff0c\u63d0\u5347\u4ee3\u7406\u6027\u80fd", "motivation": "\u7aef\u5230\u7aefGUI\u4ee3\u7406\u9700\u8981\u5927\u91cf\u9ad8\u8d28\u91cf\u4ea4\u4e92\u6570\u636e\uff0c\u4f46\u4eba\u5de5\u6536\u96c6\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u5408\u6210\u65b9\u6cd5\u5b58\u5728\u4efb\u52a1\u591a\u6837\u6027\u6709\u9650\u6216\u8f68\u8ff9\u566a\u58f0\u5927\u3001\u76ee\u6807\u6f02\u79fb\u7684\u95ee\u9898", "method": "\u4ece\u5c11\u91cf\u5df2\u9a8c\u8bc1\u79cd\u5b50\u6f14\u793a\u51fa\u53d1\uff0c\u8bc6\u522b\u72b6\u6001\u53d8\u5316\u7684\u5206\u652f\u70b9\uff0c\u57fa\u4e8e\u5f53\u524dGUI\u4e0a\u4e0b\u6587\u63d0\u51fa\u65b0\u7684\u72b6\u6001\u57fa\u7840\u4efb\u52a1\u53d8\u4f53\uff0c\u901a\u8fc7\u6267\u884c\u4ee3\u7406\u751f\u6210\u65b0\u8f68\u8ff9\uff0c\u9a8c\u8bc1\u5668\u901a\u8fc7\u72b6\u6001\u611f\u77e5\u68c0\u67e5\u548c\u8f68\u8ff9\u4e00\u81f4\u6027\u786e\u4fdd\u4efb\u52a1\u5b8c\u6210\uff0c\u5e76\u5e94\u7528\u4efb\u52a1\u6761\u4ef6\u6b65\u9aa4\u7ea7\u8fc7\u6ee4\u53bb\u9664\u65e0\u57fa\u7840\u52a8\u4f5c", "result": "\u5728OSWorld\u548cWindowsAgentArena\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u6269\u5c55\u8bed\u6599\u5e93\u5fae\u8c03\u7684\u6a21\u578b\u76f8\u6bd4\u96f6\u6837\u672c\u4ee3\u7406\u548c\u4ee3\u8868\u6027\u5408\u6210\u57fa\u7ebf\u83b7\u5f97\u4e00\u81f4\u6539\u8fdb\uff0c\u5e76\u80fd\u8de8\u5e94\u7528\u548c\u64cd\u4f5c\u7cfb\u7edf\u6cdb\u5316", "conclusion": "Anchor\u6846\u67b6\u80fd\u591f\u4ece\u5c11\u91cf\u79cd\u5b50\u6f14\u793a\u4e2d\u5f15\u5bfc\u6269\u5c55\u53ef\u6269\u5c55\u7684\u684c\u9762\u76d1\u7763\u6570\u636e\uff0c\u6709\u6548\u89e3\u51b3GUI\u4ee3\u7406\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u548c\u8d28\u91cf\u95ee\u9898"}}
{"id": "2602.08092", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.08092", "abs": "https://arxiv.org/abs/2602.08092", "authors": ["Majid Ghasemi", "Mark Crowley"], "title": "Objective Decoupling in Social Reinforcement Learning: Recovering Ground Truth from Sycophantic Majorities", "comment": null, "summary": "Contemporary AI alignment strategies rely on a fragile premise: that human feedback, while noisy, remains a fundamentally truthful signal. In this paper, we identify this assumption as Dogma 4 of Reinforcement Learning (RL). We demonstrate that while this dogma holds in static environments, it fails in social settings where evaluators may be sycophantic, lazy, or adversarial. We prove that under Dogma 4, standard RL agents suffer from what we call Objective Decoupling, a structural failure mode where the agent's learned objective permanently separates from the latent ground truth, guaranteeing convergence to misalignment. To resolve this, we propose Epistemic Source Alignment (ESA). Unlike standard robust methods that rely on statistical consensus (trusting the majority), ESA utilizes sparse safety axioms to judge the source of the feedback rather than the signal itself. We prove that this \"judging the judges\" mechanism guarantees convergence to the true objective, even when a majority of evaluators are biased. Empirically, we show that while traditional consensus methods fail under majority collusion, our approach successfully recovers the optimal policy.", "AI": {"tldr": "\u8bba\u6587\u6311\u6218\u4e86AI\u5bf9\u9f50\u4e2d\u7684\u5173\u952e\u5047\u8bbe\u2014\u2014\u4eba\u7c7b\u53cd\u9988\u662f\u771f\u5b9e\u4fe1\u53f7\uff0c\u63d0\u51fa\u5728\u793e\u4ea4\u73af\u5883\u4e2d\u8be5\u5047\u8bbe\u5931\u6548\uff0c\u4f1a\u5bfc\u81f4\u76ee\u6807\u89e3\u8026\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u5b89\u5168\u516c\u7406\u5224\u65ad\u53cd\u9988\u6765\u6e90\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dAI\u5bf9\u9f50\u7b56\u7565\u4f9d\u8d56\u4e8e\u4eba\u7c7b\u53cd\u9988\u662f\u771f\u5b9e\u4fe1\u53f7\u8fd9\u4e00\u8106\u5f31\u524d\u63d0\uff0c\u4f46\u5728\u793e\u4ea4\u73af\u5883\u4e2d\uff0c\u8bc4\u4f30\u8005\u53ef\u80fd\u5949\u627f\u3001\u61d2\u60f0\u6216\u6709\u654c\u610f\uff0c\u5bfc\u81f4\u8fd9\u4e00\u5047\u8bbe\u5931\u6548\uff0c\u9020\u6210\u76ee\u6807\u89e3\u8026\u548c\u6c38\u4e45\u6027\u9519\u4f4d\u3002", "method": "\u63d0\u51faEpistemic Source Alignment (ESA)\u65b9\u6cd5\uff0c\u4e0d\u540c\u4e8e\u4f9d\u8d56\u7edf\u8ba1\u5171\u8bc6\u7684\u4f20\u7edf\u9c81\u68d2\u65b9\u6cd5\uff0cESA\u4f7f\u7528\u7a00\u758f\u5b89\u5168\u516c\u7406\u6765\u5224\u65ad\u53cd\u9988\u7684\u6765\u6e90\u800c\u975e\u4fe1\u53f7\u672c\u8eab\uff0c\u901a\u8fc7\"\u5224\u65ad\u5224\u65ad\u8005\"\u673a\u5236\u786e\u4fdd\u6536\u655b\u5230\u771f\u5b9e\u76ee\u6807\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86ESA\u80fd\u4fdd\u8bc1\u6536\u655b\u5230\u771f\u5b9e\u76ee\u6807\uff0c\u5373\u4f7f\u5927\u591a\u6570\u8bc4\u4f30\u8005\u6709\u504f\u89c1\uff1b\u5b9e\u8bc1\u663e\u793a\u4f20\u7edf\u5171\u8bc6\u65b9\u6cd5\u5728\u591a\u6570\u5171\u8c0b\u4e0b\u5931\u8d25\uff0c\u800cESA\u65b9\u6cd5\u80fd\u6210\u529f\u6062\u590d\u6700\u4f18\u7b56\u7565\u3002", "conclusion": "\u4eba\u7c7b\u53cd\u9988\u4f5c\u4e3a\u771f\u5b9e\u4fe1\u53f7\u7684\u5047\u8bbe\u5728\u793e\u4ea4\u73af\u5883\u4e2d\u4e0d\u6210\u7acb\uff0c\u4f1a\u5bfc\u81f4\u76ee\u6807\u89e3\u8026\u95ee\u9898\uff0c\u800c\u57fa\u4e8e\u5224\u65ad\u53cd\u9988\u6765\u6e90\u7684ESA\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u786e\u4fddAI\u7cfb\u7edf\u5728\u504f\u89c1\u73af\u5883\u4e2d\u4ecd\u80fd\u5bf9\u9f50\u3002"}}
{"id": "2602.08899", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2602.08899", "abs": "https://arxiv.org/abs/2602.08899", "authors": ["Jiaqi Huang"], "title": "Fixed Effects as Generated Regressors", "comment": null, "summary": "Many economic models feature moment conditions that involve latent variables. When the latent variables are individual fixed effects in an auxiliary panel data regression, we construct orthogonal moments that eliminate first-order bias induced by estimating the fixed effects. Machine Learning methods and Empirical Bayes methods can be used to improve the estimate of the nuisance parameters in the orthogonal moments. We establish a central limit theorem based on the orthogonal moments without relying on exogeneity assumptions between panel data residuals and the cross-sectional moment functions. In a simulation study where the exogeneity assumption is violated, the estimator based on orthogonal moments has smaller bias compared with other estimators relying on that assumption. An empirical application on experimental site selection demonstrates how the method can be used for nonlinear moment conditions.", "AI": {"tldr": "\u63d0\u51fa\u6b63\u4ea4\u77e9\u65b9\u6cd5\u6d88\u9664\u9762\u677f\u6570\u636e\u4e2d\u56fa\u5b9a\u6548\u5e94\u4f30\u8ba1\u5e26\u6765\u7684\u504f\u5dee\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u4e0e\u7ecf\u9a8c\u8d1d\u53f6\u65af\u6539\u8fdb\u53c2\u6570\u4f30\u8ba1\uff0c\u65e0\u9700\u9762\u677f\u6b8b\u5dee\u4e0e\u622a\u9762\u77e9\u51fd\u6570\u7684\u5916\u751f\u6027\u5047\u8bbe", "motivation": "\u8bb8\u591a\u7ecf\u6d4e\u6a21\u578b\u6d89\u53ca\u6f5c\u53d8\u91cf\u7684\u77e9\u6761\u4ef6\uff0c\u5f53\u6f5c\u53d8\u91cf\u4e3a\u9762\u677f\u6570\u636e\u8f85\u52a9\u56de\u5f52\u4e2d\u7684\u4e2a\u4f53\u56fa\u5b9a\u6548\u5e94\u65f6\uff0c\u56fa\u5b9a\u6548\u5e94\u7684\u4f30\u8ba1\u4f1a\u5f15\u5165\u4e00\u9636\u504f\u5dee\uff0c\u9700\u8981\u6d88\u9664\u8fd9\u79cd\u504f\u5dee\u5e76\u5904\u7406\u9762\u677f\u6b8b\u5dee\u4e0e\u622a\u9762\u77e9\u51fd\u6570\u4e4b\u95f4\u53ef\u80fd\u5b58\u5728\u7684\u5185\u751f\u6027\u95ee\u9898", "method": "\u6784\u5efa\u6b63\u4ea4\u77e9\u6d88\u9664\u56fa\u5b9a\u6548\u5e94\u4f30\u8ba1\u5f15\u8d77\u7684\u4e00\u9636\u504f\u5dee\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u548c\u7ecf\u9a8c\u8d1d\u53f6\u65af\u65b9\u6cd5\u6539\u8fdb\u6b63\u4ea4\u77e9\u4e2d\u5197\u4f59\u53c2\u6570\u7684\u4f30\u8ba1\uff0c\u5efa\u7acb\u57fa\u4e8e\u6b63\u4ea4\u77e9\u7684\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\uff0c\u4e0d\u4f9d\u8d56\u9762\u677f\u6570\u636e\u6b8b\u5dee\u4e0e\u622a\u9762\u77e9\u51fd\u6570\u7684\u5916\u751f\u6027\u5047\u8bbe", "result": "\u6a21\u62df\u7814\u7a76\u8868\u660e\uff0c\u5728\u5916\u751f\u6027\u5047\u8bbe\u88ab\u8fdd\u53cd\u7684\u60c5\u51b5\u4e0b\uff0c\u57fa\u4e8e\u6b63\u4ea4\u77e9\u7684\u4f30\u8ba1\u91cf\u76f8\u6bd4\u4f9d\u8d56\u8be5\u5047\u8bbe\u7684\u5176\u4ed6\u4f30\u8ba1\u91cf\u5177\u6709\u66f4\u5c0f\u7684\u504f\u5dee\uff1b\u5b9e\u8bc1\u5e94\u7528\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u975e\u7ebf\u6027\u77e9\u6761\u4ef6\u4e0b\u7684\u9002\u7528\u6027", "conclusion": "\u6b63\u4ea4\u77e9\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u9762\u677f\u6570\u636e\u4e2d\u56fa\u5b9a\u6548\u5e94\u4f30\u8ba1\u5f15\u8d77\u7684\u504f\u5dee\u95ee\u9898\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u6280\u672f\u53ef\u6539\u8fdb\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u4e14\u4e0d\u4f9d\u8d56\u4e25\u683c\u7684\u5916\u751f\u6027\u5047\u8bbe\uff0c\u4e3a\u975e\u7ebf\u6027\u77e9\u6761\u4ef6\u7684\u7ecf\u6d4e\u6a21\u578b\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u4f30\u8ba1\u5de5\u5177"}}
{"id": "2602.08970", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08970", "abs": "https://arxiv.org/abs/2602.08970", "authors": ["Jacopo Nudo", "Eugenio Nerio Nemmi", "Edoardo Loru", "Alessandro Mei", "Walter Quattrociocchi", "Matteo Cinelli"], "title": "Hyperactive Minority Alter the Stability of Community Notes", "comment": null, "summary": "As platforms increasingly scale down professional fact-checking, community-based alternatives are promoted as more transparent and democratic. The main substitute being proposed is community-based contextualization, most notably Community Notes on X, where users write annotations and collectively rate their helpfulness under a consensus-oriented algorithm. This shift raises a basic empirical question: to what extent do users' social dynamics affect the emergence of Community Notes? We address this question by characterizing participation and political behavior, using the full public release of notes and ratings (between 2021 and 2025). We show that contribution activity is highly concentrated: a small minority of users accounts for a disproportionate share of ratings. Crucially, these high-activity contributors are not neutral volunteers: they are selective in the content they engage with and substantially more politically polarized than the overall contributor population. We replicate the notes' emergence process by integrating the open-source implementation of the Community Notes consensus algorithm used in production. This enables us to conduct counterfactual simulations that modify the display status of notes by varying the pool of raters. Our results reveal that the system is structurally unstable: the emergence and visibility of notes often depend on the behavior of a few dozen highly active users, and even minor perturbations in their participation can lead to markedly different outcomes. In sum, rather than decentralizing epistemic authority, community-based fact-checking on X reconfigures it, concentrating substantial power in the hands of a small, polarized group of highly active contributors.", "AI": {"tldr": "\u793e\u533a\u7b14\u8bb0\u7cfb\u7edf\u5e76\u672a\u5b9e\u73b0\u53bb\u4e2d\u5fc3\u5316\u7684\u4e8b\u5b9e\u6838\u67e5\u6743\u5a01\uff0c\u800c\u662f\u5c06\u6743\u529b\u96c6\u4e2d\u5728\u5c11\u6570\u9ad8\u5ea6\u6d3b\u8dc3\u3001\u653f\u6cbb\u6781\u5316\u7684\u7528\u6237\u624b\u4e2d\uff0c\u7cfb\u7edf\u7ed3\u6784\u4e0d\u7a33\u5b9a\uff0c\u5c11\u6570\u7528\u6237\u884c\u4e3a\u5c31\u80fd\u663e\u8457\u5f71\u54cd\u7b14\u8bb0\u7684\u53ef\u89c1\u6027\u3002", "motivation": "\u968f\u7740\u5e73\u53f0\u51cf\u5c11\u4e13\u4e1a\u4e8b\u5b9e\u6838\u67e5\uff0c\u793e\u533a\u5316\u66ff\u4ee3\u65b9\u6848\u88ab\u63a8\u5e7f\u4e3a\u66f4\u900f\u660e\u6c11\u4e3b\u7684\u9009\u62e9\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u793e\u533a\u7b14\u8bb0\u7cfb\u7edf\u4e2d\u7528\u6237\u793e\u4ea4\u52a8\u6001\u5982\u4f55\u5f71\u54cd\u7b14\u8bb0\u7684\u6d8c\u73b0\uff0c\u7279\u522b\u662fX\u5e73\u53f0\u7684Community Notes\u7cfb\u7edf\u3002", "method": "\u4f7f\u75282021-2025\u5e74\u5b8c\u6574\u7684\u516c\u5f00\u7b14\u8bb0\u548c\u8bc4\u5206\u6570\u636e\uff0c\u5206\u6790\u7528\u6237\u53c2\u4e0e\u6a21\u5f0f\u548c\u653f\u6cbb\u884c\u4e3a\u3002\u901a\u8fc7\u6574\u5408\u793e\u533a\u7b14\u8bb0\u5171\u8bc6\u7b97\u6cd5\u7684\u5f00\u6e90\u5b9e\u73b0\uff0c\u8fdb\u884c\u53cd\u4e8b\u5b9e\u6a21\u62df\uff0c\u6539\u53d8\u8bc4\u5206\u8005\u7fa4\u4f53\u6765\u4fee\u6539\u7b14\u8bb0\u663e\u793a\u72b6\u6001\u3002", "result": "\u8d21\u732e\u6d3b\u52a8\u9ad8\u5ea6\u96c6\u4e2d\uff1a\u5c11\u6570\u7528\u6237\u5360\u8bc4\u5206\u6d3b\u52a8\u7684\u7edd\u5927\u90e8\u5206\u3002\u8fd9\u4e9b\u9ad8\u6d3b\u8dc3\u5ea6\u7528\u6237\u5e76\u975e\u4e2d\u7acb\u5fd7\u613f\u8005\uff0c\u4ed6\u4eec\u9009\u62e9\u6027\u53c2\u4e0e\u5185\u5bb9\uff0c\u653f\u6cbb\u6781\u5316\u7a0b\u5ea6\u8fdc\u9ad8\u4e8e\u6574\u4f53\u7528\u6237\u7fa4\u4f53\u3002\u7cfb\u7edf\u7ed3\u6784\u4e0d\u7a33\u5b9a\uff0c\u7b14\u8bb0\u7684\u6d8c\u73b0\u548c\u53ef\u89c1\u6027\u5e38\u53d6\u51b3\u4e8e\u51e0\u5341\u4e2a\u9ad8\u5ea6\u6d3b\u8dc3\u7528\u6237\u7684\u884c\u4e3a\uff0c\u5fae\u5c0f\u6270\u52a8\u5c31\u80fd\u5bfc\u81f4\u663e\u8457\u4e0d\u540c\u7ed3\u679c\u3002", "conclusion": "X\u5e73\u53f0\u7684\u793e\u533a\u4e8b\u5b9e\u6838\u67e5\u5e76\u672a\u5206\u6563\u8ba4\u77e5\u6743\u5a01\uff0c\u800c\u662f\u91cd\u65b0\u914d\u7f6e\u4e86\u6743\u5a01\uff0c\u5c06\u5b9e\u8d28\u6027\u6743\u529b\u96c6\u4e2d\u5728\u5c11\u6570\u9ad8\u5ea6\u6d3b\u8dc3\u3001\u653f\u6cbb\u6781\u5316\u7684\u8d21\u732e\u8005\u624b\u4e2d\uff0c\u7cfb\u7edf\u8bbe\u8ba1\u5b58\u5728\u7ed3\u6784\u6027\u8106\u5f31\u6027\u3002"}}
{"id": "2602.07039", "categories": ["cs.CY", "cs.AI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2602.07039", "abs": "https://arxiv.org/abs/2602.07039", "authors": ["Heimo M\u00fcller"], "title": "When Excellence Stops Producing Knowledge: A Practitioner's Observation on Research Funding", "comment": null, "summary": "After almost four decades of participating in competitive research funding -- as applicant, coordinator, evaluator, and panel member -- I have come to see a structural paradox: many participants recognize that the current system is approaching its functional limits, yet most reform measures intensify rather than alleviate the underlying dynamics. This paper documents how excellence has become decoupled from knowledge production through an increasing coupling to representability under evaluation. The discussion focuses on two domains in which this is particularly visible: competitive basic research funding and large EU consortium projects. Three accelerating trends are examined: the professionalization of proposal writing through specialized consultants, the rise of AI-assisted applications, and an evaluator shortage that forces panels to rely on reviewers increasingly distant from the actual research domains. These observations are offered not as external critique but as an insider account, in the hope that naming a widely experienced but rarely articulated pattern may enable more constructive orientation.\n  Keywords: Research funding, Excellence, Evaluation, Goodhart's Law, Professionalization, AI-assisted proposals, Peer review crisis", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5f53\u524d\u7ade\u4e89\u6027\u79d1\u7814\u8d44\u52a9\u4f53\u7cfb\u5b58\u5728\u7ed3\u6784\u6027\u6096\u8bba\uff1a\u53c2\u4e0e\u8005\u666e\u904d\u8ba4\u8bc6\u5230\u7cfb\u7edf\u5df2\u63a5\u8fd1\u529f\u80fd\u6781\u9650\uff0c\u4f46\u591a\u6570\u6539\u9769\u63aa\u65bd\u53cd\u800c\u52a0\u5267\u4e86\u6839\u672c\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\"\u5353\u8d8a\u6027\"\u5df2\u4e0e\u77e5\u8bc6\u751f\u4ea7\u8131\u94a9\uff0c\u800c\u4e0e\u8bc4\u4f30\u4e2d\u7684\"\u53ef\u5448\u73b0\u6027\"\u8fc7\u5ea6\u8026\u5408\u3002", "motivation": "\u4f5c\u8005\u57fa\u4e8e\u8fd1\u56db\u5341\u5e74\u7684\u79d1\u7814\u8d44\u52a9\u53c2\u4e0e\u7ecf\u9a8c\uff08\u7533\u8bf7\u4eba\u3001\u534f\u8c03\u4eba\u3001\u8bc4\u4f30\u4eba\u3001\u8bc4\u5ba1\u59d4\u5458\uff09\uff0c\u89c2\u5bdf\u5230\u5f53\u524d\u7ade\u4e89\u6027\u79d1\u7814\u8d44\u52a9\u4f53\u7cfb\u5b58\u5728\u7ed3\u6784\u6027\u6096\u8bba\u3002\u5c3d\u7ba1\u8bb8\u591a\u53c2\u4e0e\u8005\u8ba4\u8bc6\u5230\u7cfb\u7edf\u5df2\u63a5\u8fd1\u529f\u80fd\u6781\u9650\uff0c\u4f46\u5927\u591a\u6570\u6539\u9769\u63aa\u65bd\u53cd\u800c\u52a0\u5267\u4e86\u6839\u672c\u95ee\u9898\uff0c\u8fd9\u4fc3\u4f7f\u4f5c\u8005\u6df1\u5165\u5206\u6790\u8fd9\u4e00\u73b0\u8c61\u3002", "method": "\u91c7\u7528\u5185\u90e8\u4eba\u58eb\u89c6\u89d2\u7684\u5b9a\u6027\u5206\u6790\uff0c\u57fa\u4e8e\u4f5c\u8005\u4f5c\u4e3a\u7533\u8bf7\u4eba\u3001\u534f\u8c03\u4eba\u3001\u8bc4\u4f30\u4eba\u548c\u8bc4\u5ba1\u59d4\u5458\u7684\u4eb2\u8eab\u7ecf\u9a8c\u3002\u91cd\u70b9\u8003\u5bdf\u4e24\u4e2a\u9886\u57df\uff1a\u7ade\u4e89\u6027\u57fa\u7840\u7814\u7a76\u8d44\u52a9\u548c\u5927\u578b\u6b27\u76df\u8054\u5408\u9879\u76ee\u3002\u5206\u6790\u4e09\u4e2a\u52a0\u901f\u8d8b\u52bf\uff1a\u63d0\u6848\u5199\u4f5c\u7684\u4e13\u4e1a\u5316\uff08\u901a\u8fc7\u4e13\u4e1a\u987e\u95ee\uff09\u3001AI\u8f85\u52a9\u7533\u8bf7\u5de5\u5177\u7684\u5174\u8d77\uff0c\u4ee5\u53ca\u8bc4\u5ba1\u4eba\u5458\u77ed\u7f3a\u5bfc\u81f4\u8bc4\u5ba1\u5c0f\u7ec4\u4f9d\u8d56\u4e0e\u5177\u4f53\u7814\u7a76\u9886\u57df\u65e5\u76ca\u8131\u8282\u7684\u8bc4\u5ba1\u4eba\u3002", "result": "\u7814\u7a76\u53d1\u73b0\"\u5353\u8d8a\u6027\"\u5df2\u4e0e\u77e5\u8bc6\u751f\u4ea7\u8131\u94a9\uff0c\u800c\u4e0e\u8bc4\u4f30\u4e2d\u7684\"\u53ef\u5448\u73b0\u6027\"\u8fc7\u5ea6\u8026\u5408\u3002\u8fd9\u79cd\u8131\u94a9\u73b0\u8c61\u5728\u7ade\u4e89\u6027\u57fa\u7840\u7814\u7a76\u8d44\u52a9\u548c\u5927\u578b\u6b27\u76df\u9879\u76ee\u4e2d\u5c24\u4e3a\u660e\u663e\u3002\u4e09\u4e2a\u52a0\u901f\u8d8b\u52bf\u52a0\u5267\u4e86\u8fd9\u4e00\u73b0\u8c61\uff1a\u63d0\u6848\u5199\u4f5c\u7684\u4e13\u4e1a\u5316\u4f7f\u7533\u8bf7\u8fc7\u7a0b\u4e0e\u5b9e\u8d28\u7814\u7a76\u5206\u79bb\uff1bAI\u8f85\u52a9\u5e94\u7528\u8fdb\u4e00\u6b65\u5f62\u5f0f\u5316\u8bc4\u4f30\u6807\u51c6\uff1b\u8bc4\u5ba1\u4eba\u5458\u77ed\u7f3a\u5bfc\u81f4\u8bc4\u5ba1\u8d28\u91cf\u4e0b\u964d\u3002", "conclusion": "\u8bba\u6587\u5e76\u975e\u5916\u90e8\u6279\u8bc4\uff0c\u800c\u662f\u5185\u90e8\u4eba\u58eb\u7684\u89c2\u5bdf\u8bb0\u5f55\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u660e\u786e\u6307\u51fa\u8fd9\u4e00\u5e7f\u6cdb\u7ecf\u5386\u4f46\u5f88\u5c11\u88ab\u660e\u786e\u8868\u8ff0\u7684\u6a21\u5f0f\uff0c\u4e3a\u79d1\u7814\u8d44\u52a9\u4f53\u7cfb\u63d0\u4f9b\u66f4\u5efa\u8bbe\u6027\u7684\u65b9\u5411\u3002\u8fd9\u6709\u52a9\u4e8e\u7406\u89e3\u5f53\u524d\u79d1\u7814\u8bc4\u4f30\u4f53\u7cfb\u7684\u529f\u80fd\u5931\u8c03\uff0c\u5e76\u4e3a\u672a\u6765\u6539\u9769\u63d0\u4f9b\u601d\u8003\u57fa\u7840\u3002"}}
{"id": "2602.07187", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07187", "abs": "https://arxiv.org/abs/2602.07187", "authors": ["Hanyu Wang", "Yuanpu Cao", "Lu Lin", "Jinghui Chen"], "title": "PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents", "comment": null, "summary": "Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe failure, and only then attempt to recover. In this work, we introduce PreFlect, a prospective reflection mechanism that shifts the paradigm from post hoc correction to pre-execution foresight by criticizing and refining agent plans before execution. To support grounded prospective reflection, we distill planning errors from historical agent trajectories, capturing recurring success and failure patterns observed across past executions. Furthermore, we complement prospective reflection with a dynamic re-planning mechanism that provides execution-time plan update in case the original plan encounters unexpected deviation. Evaluations on different benchmarks demonstrate that PreFlect significantly improves overall agent utility on complex real-world tasks, outperforming strong reflection-based baselines and several more complex agent architectures. Code will be updated at https://github.com/wwwhy725/PreFlect.", "AI": {"tldr": "PreFlect\uff1a\u4e00\u79cd\u524d\u77bb\u6027\u53cd\u601d\u673a\u5236\uff0c\u5728\u8ba1\u5212\u6267\u884c\u524d\u8fdb\u884c\u6279\u8bc4\u548c\u4f18\u5316\uff0c\u800c\u4e0d\u662f\u4e8b\u540e\u7ea0\u6b63\uff0c\u901a\u8fc7\u4ece\u5386\u53f2\u8f68\u8ff9\u4e2d\u63d0\u53d6\u89c4\u5212\u9519\u8bef\u6a21\u5f0f\uff0c\u7ed3\u5408\u52a8\u6001\u91cd\u89c4\u5212\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u667a\u80fd\u4f53\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u7684\u53cd\u601d\u673a\u5236\u672c\u8d28\u4e0a\u662f\u56de\u987e\u6027\u7684\uff1a\u667a\u80fd\u4f53\u5148\u884c\u52a8\uff0c\u89c2\u5bdf\u5931\u8d25\uff0c\u7136\u540e\u5c1d\u8bd5\u6062\u590d\u3002\u8fd9\u79cd\u4e8b\u540e\u7ea0\u6b63\u65b9\u6cd5\u5b58\u5728\u6548\u7387\u95ee\u9898\uff0c\u9700\u8981\u5728\u6267\u884c\u524d\u5c31\u8fdb\u884c\u524d\u77bb\u6027\u89c4\u5212\u4f18\u5316\u3002", "method": "1. \u524d\u77bb\u6027\u53cd\u601d\uff1a\u5728\u6267\u884c\u524d\u5bf9\u667a\u80fd\u4f53\u8ba1\u5212\u8fdb\u884c\u6279\u8bc4\u548c\u4f18\u5316\uff1b2. \u4ece\u5386\u53f2\u667a\u80fd\u4f53\u8f68\u8ff9\u4e2d\u63d0\u53d6\u89c4\u5212\u9519\u8bef\u6a21\u5f0f\uff0c\u6355\u6349\u8fc7\u53bb\u6267\u884c\u4e2d\u89c2\u5bdf\u5230\u7684\u91cd\u590d\u6210\u529f\u548c\u5931\u8d25\u6a21\u5f0f\uff1b3. \u52a8\u6001\u91cd\u89c4\u5212\u673a\u5236\uff1a\u5f53\u539f\u59cb\u8ba1\u5212\u9047\u5230\u610f\u5916\u504f\u5dee\u65f6\u63d0\u4f9b\u6267\u884c\u65f6\u7684\u8ba1\u5212\u66f4\u65b0\u3002", "result": "\u5728\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPreFlect\u663e\u8457\u63d0\u9ad8\u4e86\u590d\u6742\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u667a\u80fd\u4f53\u7684\u6574\u4f53\u6548\u7528\uff0c\u4f18\u4e8e\u57fa\u4e8e\u53cd\u601d\u7684\u57fa\u7ebf\u65b9\u6cd5\u548c\u51e0\u79cd\u66f4\u590d\u6742\u7684\u667a\u80fd\u4f53\u67b6\u6784\u3002", "conclusion": "\u4ece\u56de\u987e\u6027\u53cd\u601d\u8f6c\u5411\u524d\u77bb\u6027\u53cd\u601d\u662f\u63d0\u5347\u667a\u80fd\u4f53\u6027\u80fd\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6267\u884c\u524d\u4f18\u5316\u8ba1\u5212\u548c\u52a8\u6001\u8c03\u6574\u7b56\u7565\uff0cPreFlect\u4e3a\u667a\u80fd\u4f53\u89c4\u5212\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08246", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08246", "abs": "https://arxiv.org/abs/2602.08246", "authors": ["Atrisha Sarkar", "Isam Faik"], "title": "Structural transparency of societal AI alignment through Institutional Logics", "comment": null, "summary": "The field of AI alignment is increasingly concerned with the questions of how values are integrated into the design of generative AI systems and how their integration shapes the social consequences of AI. However, existing transparency frameworks focus on the informational aspects of AI models, data, and procedures, while the institutional and organizational forces that shape alignment decisions and their downstream effects remain underexamined in both research and practice. To address this gap, we develop a framework of \\emph{structural transparency} for analyzing organizational and institutional decisions concerning AI alignment, drawing on the theoretical lens of Institutional Logics. We develop a categorization of organizational decisions that are present in the governance of AI alignment, and provide an explicit analytical approach to examining them. We operationalize the framework through five analytical components, each with an accompanying \"analyst recipe\" that collectively identify the primary institutional logics and their internal relationships, external disruptions to existing social orders, and finally, how the structural risks of each institutional logic are mapped to a catalogue of sociotechnical harms. The proposed concept of structural transparency enables analysts to complement existing approached based on informational transparency with macro-level analyses that capture the institutional dynamics and consequences of decisions regarding AI alignment.", "AI": {"tldr": "\u63d0\u51fa\"\u7ed3\u6784\u900f\u660e\u5ea6\"\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790AI\u5bf9\u9f50\u4e2d\u7684\u7ec4\u7ec7\u548c\u5236\u5ea6\u51b3\u7b56\uff0c\u8865\u5145\u73b0\u6709\u4fe1\u606f\u900f\u660e\u5ea6\u65b9\u6cd5", "motivation": "\u73b0\u6709\u900f\u660e\u5ea6\u6846\u67b6\u4e3b\u8981\u5173\u6ce8AI\u6a21\u578b\u3001\u6570\u636e\u548c\u7a0b\u5e8f\u7684\u4fe1\u606f\u5c42\u9762\uff0c\u800c\u5851\u9020\u5bf9\u9f50\u51b3\u7b56\u53ca\u5176\u793e\u4f1a\u540e\u679c\u7684\u7ec4\u7ec7\u548c\u5236\u5ea6\u529b\u91cf\u5728\u7814\u7a76\u548c\u5b9e\u8df5\u4e2d\u88ab\u5ffd\u89c6\uff0c\u9700\u8981\u5f25\u8865\u8fd9\u4e00\u7a7a\u767d", "method": "\u57fa\u4e8e\u5236\u5ea6\u903b\u8f91\u7406\u8bba\uff0c\u5f00\u53d1\u7ed3\u6784\u900f\u660e\u5ea6\u6846\u67b6\uff0c\u5305\u542b\u4e94\u4e2a\u5206\u6790\u7ec4\u4ef6\u548c\u76f8\u5e94\u7684\"\u5206\u6790\u5e08\u914d\u65b9\"\uff0c\u7528\u4e8e\u8bc6\u522b\u4e3b\u8981\u5236\u5ea6\u903b\u8f91\u3001\u5916\u90e8\u5e72\u6270\u3001\u7ed3\u6784\u98ce\u9669\u4e0e\u793e\u4f1a\u6280\u672f\u5371\u5bb3\u7684\u6620\u5c04", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6846\u67b6\uff0c\u80fd\u591f\u5206\u6790AI\u5bf9\u9f50\u6cbb\u7406\u4e2d\u7684\u7ec4\u7ec7\u51b3\u7b56\uff0c\u63ed\u793a\u5236\u5ea6\u52a8\u6001\u548c\u51b3\u7b56\u540e\u679c\uff0c\u8865\u5145\u73b0\u6709\u4fe1\u606f\u900f\u660e\u5ea6\u65b9\u6cd5", "conclusion": "\u7ed3\u6784\u900f\u660e\u5ea6\u6982\u5ff5\u4f7f\u5206\u6790\u5e08\u80fd\u591f\u5728\u4fe1\u606f\u900f\u660e\u5ea6\u57fa\u7840\u4e0a\uff0c\u8fdb\u884c\u5b8f\u89c2\u5c42\u9762\u7684\u5236\u5ea6\u52a8\u6001\u5206\u6790\uff0c\u66f4\u597d\u5730\u7406\u89e3AI\u5bf9\u9f50\u51b3\u7b56\u7684\u793e\u4f1a\u5f71\u54cd"}}
{"id": "2602.07238", "categories": ["cs.AI", "cs.LG", "econ.GN"], "pdf": "https://arxiv.org/pdf/2602.07238", "abs": "https://arxiv.org/abs/2602.07238", "authors": ["Matthias Mertens", "Natalia Fischl-Lanzoni", "Neil Thompson"], "title": "Is there \"Secret Sauce'' in Large Language Model Development?", "comment": null, "summary": "Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-date and developer fixed effects. We find clear evidence of developer-specific efficiency advantages, but their importance depends on where models lie in the performance distribution. At the frontier, 80-90% of performance differences are explained by higher training compute, implying that scale--not proprietary technology--drives frontier advances. Away from the frontier, however, proprietary techniques and shared algorithmic progress substantially reduce the compute required to reach fixed capability thresholds. Some companies can systematically produce smaller models more efficiently. Strikingly, we also find substantial variation of model efficiency within companies; a firm can train two models with more than 40x compute efficiency difference. We also discuss the implications for AI leadership and capability diffusion.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86809\u4e2aLLM\u6a21\u578b\u6570\u636e\uff0c\u53d1\u73b0\u524d\u6cbf\u6a21\u578b\u6027\u80fd\u4e3b\u8981\u7531\u8ba1\u7b97\u89c4\u6a21\u9a71\u52a8\uff08\u536080-90%\u5dee\u5f02\uff09\uff0c\u800c\u975e\u4e13\u6709\u6280\u672f\uff1b\u4f46\u5728\u975e\u524d\u6cbf\u9886\u57df\uff0c\u4e13\u6709\u6280\u672f\u548c\u7b97\u6cd5\u8fdb\u6b65\u80fd\u663e\u8457\u964d\u4f4e\u8fbe\u5230\u7279\u5b9a\u80fd\u529b\u6240\u9700\u7684\u8ba1\u7b97\u91cf\u3002", "motivation": "\u63a2\u7a76LLM\u6027\u80fd\u63d0\u5347\u7684\u4e3b\u8981\u9a71\u52a8\u529b\uff1a\u662f\u9886\u5148\u5f00\u53d1\u8005\u7684\u4e13\u6709\u6280\u672f\uff08\"\u79d8\u65b9\"\uff09\uff0c\u8fd8\u662f\u5355\u7eaf\u7684\u8ba1\u7b97\u89c4\u6a21\u6269\u5c55\uff1f\u8fd9\u4e2a\u95ee\u9898\u5bf9\u7406\u89e3AI\u9886\u5bfc\u5730\u4f4d\u548c\u6280\u672f\u6269\u6563\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u4f7f\u75282022-2025\u5e74\u95f4\u53d1\u5e03\u7684809\u4e2a\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u57fa\u51c6\u6d4b\u8bd5\u6570\u636e\uff0c\u5efa\u7acb\u5305\u542b\u53d1\u5e03\u65e5\u671f\u548c\u5f00\u53d1\u8005\u56fa\u5b9a\u6548\u5e94\u7684\u6269\u5c55\u5b9a\u5f8b\u56de\u5f52\u6a21\u578b\uff0c\u5206\u6790\u8ba1\u7b97\u89c4\u6a21\u4e0e\u4e13\u6709\u6280\u672f\u5bf9\u6027\u80fd\u7684\u76f8\u5bf9\u8d21\u732e\u3002", "result": "1) \u5728\u524d\u6cbf\u9886\u57df\uff0c80-90%\u7684\u6027\u80fd\u5dee\u5f02\u53ef\u7531\u66f4\u9ad8\u7684\u8bad\u7ec3\u8ba1\u7b97\u91cf\u89e3\u91ca\uff0c\u8868\u660e\u89c4\u6a21\u800c\u975e\u4e13\u6709\u6280\u672f\u9a71\u52a8\u524d\u6cbf\u8fdb\u6b65\uff1b2) \u5728\u975e\u524d\u6cbf\u9886\u57df\uff0c\u4e13\u6709\u6280\u672f\u548c\u5171\u4eab\u7b97\u6cd5\u8fdb\u6b65\u80fd\u5927\u5e45\u964d\u4f4e\u8fbe\u5230\u56fa\u5b9a\u80fd\u529b\u9608\u503c\u6240\u9700\u7684\u8ba1\u7b97\u91cf\uff1b3) \u67d0\u4e9b\u516c\u53f8\u80fd\u7cfb\u7edf\u6027\u5730\u66f4\u9ad8\u6548\u5730\u751f\u4ea7\u8f83\u5c0f\u6a21\u578b\uff1b4) \u540c\u4e00\u516c\u53f8\u5185\u90e8\u6a21\u578b\u6548\u7387\u5b58\u5728\u5de8\u5927\u5dee\u5f02\uff08\u53ef\u8fbe40\u500d\u4ee5\u4e0a\uff09\u3002", "conclusion": "LLM\u6027\u80fd\u63d0\u5347\u5728\u524d\u6cbf\u4e3b\u8981\u4f9d\u8d56\u8ba1\u7b97\u89c4\u6a21\uff0c\u4f46\u5728\u975e\u524d\u6cbf\u9886\u57df\u4e13\u6709\u6280\u672f\u4ecd\u5f88\u91cd\u8981\u3002\u8fd9\u4e00\u53d1\u73b0\u5bf9AI\u9886\u5bfc\u5730\u4f4d\u548c\u80fd\u529b\u6269\u6563\u5177\u6709\u91cd\u8981\u653f\u7b56\u542b\u4e49\uff1a\u524d\u6cbf\u7ade\u4e89\u53ef\u80fd\u6f14\u53d8\u4e3a\u8ba1\u7b97\u8d44\u6e90\u7ade\u8d5b\uff0c\u800c\u4e13\u6709\u6280\u672f\u4f18\u52bf\u5728\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u4e2d\u4ecd\u80fd\u521b\u9020\u4ef7\u503c\u3002"}}
{"id": "2602.08299", "categories": ["cs.CY", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08299", "abs": "https://arxiv.org/abs/2602.08299", "authors": ["Hibiki Ito", "Chia-Yu Hsu", "Hiroaki Ogata"], "title": "Cyclic Adaptive Private Synthesis for Sharing Real-World Data in Education", "comment": "10 pages, 3 figures. Accepted for LAK2026", "summary": "The rapid adoption of digital technologies has greatly increased the volume of real-world data (RWD) in education. While these data offer significant opportunities for advancing learning analytics (LA), secondary use for research is constrained by privacy concerns. Differentially private synthetic data generation is regarded as the gold-standard approach to sharing sensitive data, yet studies on the private synthesis of educational data remain very scarce and rely predominantly on large, low-dimensional open datasets. Educational RWD, however, are typically high-dimensional and small in sample size, leaving the potential of private synthesis underexplored. Moreover, because educational practice is inherently iterative, data sharing is continual rather than one-off, making a traditional one-shot synthesis approach suboptimal. To address these challenges, we propose the Cyclic Adaptive Private Synthesis (CAPS) framework and evaluate it on authentic RWD. By iteratively sharing RWD, CAPS not only fosters open science, but also offers rich opportunities of design-based research (DBR), thereby amplifying the impact of LA. Our case study using actual RWD demonstrates that CAPS outperforms a one-shot baseline while highlighting challenges that warrant further investigation. Overall, this work offers a crucial first step towards privacy-preserving sharing of educational RWD and expands the possibilities for open science and DBR in LA.", "AI": {"tldr": "\u63d0\u51fa\u4e86CAPS\u6846\u67b6\uff0c\u7528\u4e8e\u6559\u80b2\u771f\u5b9e\u4e16\u754c\u6570\u636e\u7684\u5dee\u5206\u9690\u79c1\u5408\u6210\uff0c\u89e3\u51b3\u4f20\u7edf\u4e00\u6b21\u6027\u5408\u6210\u65b9\u6cd5\u5728\u5904\u7406\u9ad8\u7ef4\u5c0f\u6837\u672c\u6559\u80b2\u6570\u636e\u65f6\u7684\u4e0d\u8db3\uff0c\u652f\u6301\u6301\u7eed\u6570\u636e\u5171\u4eab\u3002", "motivation": "\u6559\u80b2\u9886\u57df\u771f\u5b9e\u4e16\u754c\u6570\u636e(RWD)\u5feb\u901f\u589e\u957f\uff0c\u4f46\u9690\u79c1\u95ee\u9898\u9650\u5236\u4e86\u5176\u5728\u5b66\u4e60\u5206\u6790\u4e2d\u7684\u4e8c\u6b21\u4f7f\u7528\u3002\u73b0\u6709\u5dee\u5206\u9690\u79c1\u5408\u6210\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5927\u89c4\u6a21\u4f4e\u7ef4\u5f00\u653e\u6570\u636e\u96c6\uff0c\u800c\u6559\u80b2RWD\u901a\u5e38\u5177\u6709\u9ad8\u7ef4\u3001\u5c0f\u6837\u672c\u7684\u7279\u70b9\uff0c\u4e14\u6559\u80b2\u5b9e\u8df5\u9700\u8981\u6301\u7eed\u800c\u975e\u4e00\u6b21\u6027\u7684\u6570\u636e\u5171\u4eab\u3002", "method": "\u63d0\u51fa\u4e86\u5faa\u73af\u81ea\u9002\u5e94\u9690\u79c1\u5408\u6210(CAPS)\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u65b9\u5f0f\u5171\u4eab\u771f\u5b9e\u4e16\u754c\u6570\u636e\uff0c\u800c\u975e\u4f20\u7edf\u7684\u4e00\u6b21\u6027\u5408\u6210\u65b9\u6cd5\u3002\u8be5\u6846\u67b6\u9002\u5e94\u6559\u80b2\u5b9e\u8df5\u7684\u8fed\u4ee3\u7279\u6027\uff0c\u652f\u6301\u6301\u7eed\u7684\u6570\u636e\u5171\u4eab\u3002", "result": "\u5728\u771f\u5b9e\u6559\u80b2RWD\u4e0a\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cCAPS\u6846\u67b6\u4f18\u4e8e\u4e00\u6b21\u6027\u5408\u6210\u57fa\u7ebf\u65b9\u6cd5\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u4fc3\u8fdb\u4e86\u5f00\u653e\u79d1\u5b66\uff0c\u8fd8\u4e3a\u57fa\u4e8e\u8bbe\u8ba1\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u4e30\u5bcc\u673a\u4f1a\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6559\u80b2RWD\u7684\u9690\u79c1\u4fdd\u62a4\u5171\u4eab\u63d0\u4f9b\u4e86\u91cd\u8981\u7b2c\u4e00\u6b65\uff0c\u6269\u5c55\u4e86\u5b66\u4e60\u5206\u6790\u4e2d\u5f00\u653e\u79d1\u5b66\u548c\u57fa\u4e8e\u8bbe\u8ba1\u7814\u7a76\u7684\u53ef\u80fd\u6027\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u6311\u6218\u3002"}}
{"id": "2602.07253", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07253", "abs": "https://arxiv.org/abs/2602.07253", "authors": ["Litian Liu", "Reza Pourreza", "Yubing Jian", "Yao Qin", "Roland Memisevic"], "title": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View", "comment": null, "summary": "Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain less effective on tasks requiring reasoning. In this work, we revisit hallucination detection through the lens of out-of-distribution (OOD) detection, a well-studied problem in areas like computer vision. Treating next-token prediction in language models as a classification task allows us to apply OOD techniques, provided appropriate modifications are made to account for the structural differences in large language models. We show that OOD-based approaches yield training-free, single-sample-based detectors, achieving strong accuracy in hallucination detection for reasoning tasks. Overall, our work suggests that reframing hallucination detection as OOD detection provides a promising and scalable pathway toward language model safety.", "AI": {"tldr": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5206\u5e03\u5916\u68c0\u6d4b\u95ee\u9898\uff0c\u63d0\u51fa\u65e0\u9700\u8bad\u7ec3\u3001\u57fa\u4e8e\u5355\u6837\u672c\u7684\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u826f\u597d\u6548\u679c", "motivation": "\u73b0\u6709\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u63a8\u7406\u7684\u4efb\u52a1\u4e2d\u6548\u679c\u4e0d\u4f73\u3002\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u68c0\u6d4b\u662f\u4e00\u4e2a\u5173\u952e\u7684\u5b89\u5168\u548c\u53ef\u9760\u6027\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u8bed\u8a00\u6a21\u578b\u7684\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u89c6\u4e3a\u5206\u7c7b\u4efb\u52a1\uff0c\u501f\u9274\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u5206\u5e03\u5916\u68c0\u6d4b\u6280\u672f\uff0c\u901a\u8fc7\u9002\u5f53\u4fee\u6539\u4ee5\u9002\u5e94\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u6784\u7279\u70b9\uff0c\u6784\u5efa\u65e0\u9700\u8bad\u7ec3\u3001\u57fa\u4e8e\u5355\u6837\u672c\u7684\u68c0\u6d4b\u5668\u3002", "result": "\u57fa\u4e8e\u5206\u5e03\u5916\u68c0\u6d4b\u7684\u65b9\u6cd5\u5728\u63a8\u7406\u4efb\u52a1\u7684\u5e7b\u89c9\u68c0\u6d4b\u4e2d\u53d6\u5f97\u4e86\u8f83\u5f3a\u7684\u51c6\u786e\u6027\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5c06\u5e7b\u89c9\u68c0\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5206\u5e03\u5916\u68c0\u6d4b\u95ee\u9898\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u4e14\u53ef\u6269\u5c55\u7684\u9014\u5f84\u3002"}}
{"id": "2602.08349", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.08349", "abs": "https://arxiv.org/abs/2602.08349", "authors": ["Daniel Mwesigwa", "Cyan DeVeaux", "Palashi Vaghela"], "title": "To Tango or to Disentangle? Making Ethnography Public in the Digital Age", "comment": "Accepted to CSCW 2026 (PACM HCI)", "summary": "Ethnography attends to relations among people, practices, and the technologies that mediate them. Central to this method is the duality of roles ethnographers navigate as researchers and participants and as outsiders and insiders. However, the rise of digital platforms has introduced new opportunities as well as practical and ethical challenges that reshape these dualities across hybrid media environments spanning both online and offline contexts. Drawing on two case studies of VRChat and WhatsApp, we examine how ethnographers employ diverse tactics to study both enduring and emerging socio-cultural issues of race and caste, particularly those that form what are often called publics. We propose emergent relationality as a key analytic for understanding the mutual shaping of ethnographers, platforms, and publics. In this work, emergent relationality offers registers for analyzing how positionality and hybrid media environments constitute and condition what can be accessed, articulated, and made public.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u6570\u5b57\u5e73\u53f0\u65f6\u4ee3\u6c11\u65cf\u5fd7\u7814\u7a76\u9762\u4e34\u7684\u65b0\u673a\u9047\u4e0e\u6311\u6218\uff0c\u901a\u8fc7VRChat\u548cWhatsApp\u6848\u4f8b\u7814\u7a76\uff0c\u63d0\u51fa\"\u6d8c\u73b0\u5173\u7cfb\u6027\"\u4f5c\u4e3a\u5206\u6790\u6c11\u65cf\u5fd7\u7814\u7a76\u8005\u3001\u5e73\u53f0\u548c\u516c\u4f17\u76f8\u4e92\u5851\u9020\u7684\u5173\u952e\u5206\u6790\u6846\u67b6\u3002", "motivation": "\u6570\u5b57\u5e73\u53f0\u7684\u5174\u8d77\u6539\u53d8\u4e86\u6c11\u65cf\u5fd7\u7814\u7a76\u7684\u5b9e\u8df5\u73af\u5883\u548c\u4f26\u7406\u6311\u6218\uff0c\u91cd\u5851\u4e86\u7814\u7a76\u8005\u4f5c\u4e3a\u5c40\u5916\u4eba/\u5c40\u5185\u4eba\u7684\u53cc\u91cd\u89d2\u8272\u3002\u9700\u8981\u65b0\u7684\u5206\u6790\u6846\u67b6\u6765\u7406\u89e3\u6570\u5b57\u65f6\u4ee3\u6c11\u65cf\u5fd7\u7814\u7a76\u5982\u4f55\u5e94\u5bf9\u8fd9\u4e9b\u53d8\u5316\uff0c\u7279\u522b\u662f\u5728\u7814\u7a76\u79cd\u65cf\u548c\u79cd\u59d3\u7b49\u793e\u4f1a\u6587\u5316\u95ee\u9898\u65f6\u3002", "method": "\u91c7\u7528\u6848\u4f8b\u7814\u7a76\u65b9\u6cd5\uff0c\u5206\u6790VRChat\u548cWhatsApp\u4e24\u4e2a\u6570\u5b57\u5e73\u53f0\u4e0a\u7684\u6c11\u65cf\u5fd7\u5b9e\u8df5\u3002\u901a\u8fc7\u5177\u4f53\u6848\u4f8b\u63a2\u8ba8\u6c11\u65cf\u5fd7\u7814\u7a76\u8005\u5982\u4f55\u8fd0\u7528\u591a\u6837\u7b56\u7565\u7814\u7a76\u6301\u4e45\u548c\u65b0\u5174\u7684\u793e\u4f1a\u6587\u5316\u95ee\u9898\uff0c\u7279\u522b\u662f\u5f62\u6210\u6240\u8c13\"\u516c\u4f17\"\u7684\u73b0\u8c61\u3002", "result": "\u63d0\u51fa\"\u6d8c\u73b0\u5173\u7cfb\u6027\"\u4f5c\u4e3a\u5173\u952e\u5206\u6790\u6982\u5ff5\uff0c\u7528\u4e8e\u7406\u89e3\u6c11\u65cf\u5fd7\u7814\u7a76\u8005\u3001\u6570\u5b57\u5e73\u53f0\u548c\u516c\u4f17\u4e4b\u95f4\u7684\u76f8\u4e92\u5851\u9020\u5173\u7cfb\u3002\u8fd9\u4e00\u6846\u67b6\u63d0\u4f9b\u4e86\u5206\u6790\u4f4d\u7f6e\u6027\u548c\u6df7\u5408\u5a92\u4f53\u73af\u5883\u5982\u4f55\u6784\u6210\u548c\u5236\u7ea6\u53ef\u8bbf\u95ee\u3001\u53ef\u8868\u8fbe\u548c\u53ef\u516c\u5f00\u5185\u5bb9\u7684\u5206\u6790\u7ef4\u5ea6\u3002", "conclusion": "\u6570\u5b57\u5e73\u53f0\u65f6\u4ee3\u9700\u8981\u91cd\u65b0\u601d\u8003\u6c11\u65cf\u5fd7\u7814\u7a76\u7684\u53cc\u91cd\u89d2\u8272\u548c\u5173\u7cfb\u6027\u3002\"\u6d8c\u73b0\u5173\u7cfb\u6027\"\u4e3a\u5206\u6790\u6c11\u65cf\u5fd7\u5728\u6df7\u5408\u5a92\u4f53\u73af\u5883\u4e2d\u7684\u5b9e\u8df5\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u7814\u7a76\u8005\u3001\u5e73\u53f0\u548c\u516c\u4f17\u5982\u4f55\u5728\u6570\u5b57\u73af\u5883\u4e2d\u76f8\u4e92\u5851\u9020\u548c\u5236\u7ea6\u3002"}}
{"id": "2602.07259", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07259", "abs": "https://arxiv.org/abs/2602.07259", "authors": ["Cheol Woo Kim", "Davin Choo", "Tzeh Yuan Neoh", "Milind Tambe"], "title": "Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective", "comment": null, "summary": "As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety frameworks largely treat alignment as a static optimization problem (e.g., tuning models to desired behavior) while overlooking the dynamic, adversarial incentives that shape how data are collected, how models are evaluated, and how they are ultimately deployed. We propose a new perspective on AI safety grounded in Stackelberg Security Games (SSGs): a class of game-theoretic models designed for adversarial resource allocation under uncertainty. By viewing AI oversight as a strategic interaction between defenders (auditors, evaluators, and deployers) and attackers (malicious actors, misaligned contributors, or worst-case failure modes), SSGs provide a unifying framework for reasoning about incentive design, limited oversight capacity, and adversarial uncertainty across the AI lifecycle. We illustrate how this framework can inform (1) training-time auditing against data/feedback poisoning, (2) pre-deployment evaluation under constrained reviewer resources, and (3) robust multi-model deployment in adversarial environments. This synthesis bridges algorithmic alignment and institutional oversight design, highlighting how game-theoretic deterrence can make AI oversight proactive, risk-aware, and resilient to manipulation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06AI\u5b89\u5168\u89c6\u4e3aStackelberg\u5b89\u5168\u535a\u5f08\u95ee\u9898\uff0c\u5c06AI\u76d1\u7763\u5efa\u6a21\u4e3a\u9632\u5fa1\u8005\uff08\u5ba1\u8ba1\u8005\u3001\u8bc4\u4f30\u8005\u3001\u90e8\u7f72\u8005\uff09\u4e0e\u653b\u51fb\u8005\uff08\u6076\u610f\u884c\u4e3a\u8005\u3001\u9519\u4f4d\u8d21\u732e\u8005\uff09\u4e4b\u95f4\u7684\u6218\u7565\u4e92\u52a8\uff0c\u4e3aAI\u751f\u547d\u5468\u671f\u7684\u6fc0\u52b1\u8bbe\u8ba1\u3001\u6709\u9650\u76d1\u7763\u80fd\u529b\u548c\u5bf9\u6297\u6027\u4e0d\u786e\u5b9a\u6027\u63d0\u4f9b\u7edf\u4e00\u6846\u67b6\u3002", "motivation": "\u73b0\u6709AI\u5b89\u5168\u6846\u67b6\u4e3b\u8981\u5c06\u5bf9\u9f50\u89c6\u4e3a\u9759\u6001\u4f18\u5316\u95ee\u9898\uff0c\u5ffd\u7565\u4e86\u6570\u636e\u6536\u96c6\u3001\u6a21\u578b\u8bc4\u4f30\u548c\u90e8\u7f72\u8fc7\u7a0b\u4e2d\u7684\u52a8\u6001\u5bf9\u6297\u6027\u6fc0\u52b1\u3002\u968f\u7740AI\u7cfb\u7edf\u80fd\u529b\u589e\u5f3a\u548c\u81ea\u4e3b\u6027\u63d0\u9ad8\uff0c\u9700\u8981\u8d85\u8d8a\u6a21\u578b\u5c42\u9762\u7684\u5bf9\u9f50\uff0c\u5bf9\u53c2\u4e0eAI\u5f00\u53d1\u548c\u90e8\u7f72\u7684\u4eba\u7c7b\u548c\u673a\u6784\u8fdb\u884c\u6218\u7565\u76d1\u7763\u3002", "method": "\u91c7\u7528Stackelberg\u5b89\u5168\u535a\u5f08\uff08SSGs\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u7528\u4e8e\u4e0d\u786e\u5b9a\u6027\u4e0b\u5bf9\u6297\u6027\u8d44\u6e90\u5206\u914d\u7684\u6e38\u620f\u7406\u8bba\u6a21\u578b\u3002\u5c06AI\u76d1\u7763\u89c6\u4e3a\u9632\u5fa1\u8005\u4e0e\u653b\u51fb\u8005\u4e4b\u95f4\u7684\u6218\u7565\u4e92\u52a8\uff0c\u901a\u8fc7\u8be5\u6846\u67b6\u5206\u6790\u6fc0\u52b1\u8bbe\u8ba1\u3001\u6709\u9650\u76d1\u7763\u80fd\u529b\u548c\u5bf9\u6297\u6027\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u8be5\u6846\u67b6\u53ef\u5e94\u7528\u4e8e\uff1a(1) \u8bad\u7ec3\u65f6\u5ba1\u8ba1\u6570\u636e/\u53cd\u9988\u6295\u6bd2\uff0c(2) \u6709\u9650\u8bc4\u5ba1\u8d44\u6e90\u4e0b\u7684\u9884\u90e8\u7f72\u8bc4\u4f30\uff0c(3) \u5bf9\u6297\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u591a\u6a21\u578b\u90e8\u7f72\u3002\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u7b97\u6cd5\u5bf9\u9f50\u4e0e\u673a\u6784\u76d1\u7763\u8bbe\u8ba1\u76f8\u7ed3\u5408\u3002", "conclusion": "\u57fa\u4e8eStackelberg\u5b89\u5168\u535a\u5f08\u7684AI\u5b89\u5168\u89c6\u89d2\u80fd\u591f\u4f7fAI\u76d1\u7763\u53d8\u5f97\u4e3b\u52a8\u3001\u98ce\u9669\u611f\u77e5\u4e14\u5177\u6709\u6297\u64cd\u7eb5\u6027\u3002\u8be5\u6846\u67b6\u8fde\u63a5\u4e86\u7b97\u6cd5\u5bf9\u9f50\u548c\u673a\u6784\u76d1\u7763\u8bbe\u8ba1\uff0c\u5f3a\u8c03\u4e86\u6e38\u620f\u7406\u8bba\u5a01\u6151\u5728AI\u5b89\u5168\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.08554", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.08554", "abs": "https://arxiv.org/abs/2602.08554", "authors": ["Eike Schneiders", "Sarah Kiden", "Beining Zhang", "Bruno Rafael Queiros Arcanjo", "Zhaoxing Li", "Ezhilarasi Periyathambi", "Vahid Yazdanpanah", "Sebastian Stein"], "title": "Three Lessons from Citizen-Centric Participatory AI Design", "comment": "PARTICIPATE-AI: A Workshop at the 2026 ACM Conference on Intelligent User Interfaces (ACM IUI)", "summary": "This workshop paper examines challenges in designing agentic AI systems from a citizen-centric perspective. Drawing on three participatory workshops conducted in 2025 with members of the general public and cross-sector stakeholders, we explore how societal values and expectations shape visions of future AI agents. Using constructive design research methods, participants engaged in storytelling and lo-fi prototyping to reflect on potential community impacts. We identify three key challenges: enabling meaningful and sustained public engagement, establishing a shared language between experts and lay participants, and translating speculative participant input into implementable systems. We argue that reflexive, long-term participation is essential for responsible and actionable citizen-centric AI development.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u53c2\u4e0e\u5f0f\u5de5\u4f5c\u574a\u63a2\u8ba8\u516c\u6c11\u4e2d\u5fc3\u89c6\u89d2\u4e0b\u667a\u80fd\u4f53AI\u7cfb\u7edf\u8bbe\u8ba1\u7684\u6311\u6218\uff0c\u5f3a\u8c03\u957f\u671f\u53c2\u4e0e\u5bf9\u8d1f\u8d23\u4efbAI\u53d1\u5c55\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u8bbe\u8ba1\u5f80\u5f80\u7f3a\u4e4f\u516c\u6c11\u89c6\u89d2\uff0c\u9700\u8981\u63a2\u7d22\u5982\u4f55\u5c06\u793e\u4f1a\u4ef7\u503c\u548c\u516c\u4f17\u671f\u671b\u878d\u5165\u672a\u6765AI\u667a\u80fd\u4f53\u7684\u8bbe\u8ba1\u4e2d\uff0c\u786e\u4fddAI\u53d1\u5c55\u7b26\u5408\u516c\u6c11\u5229\u76ca\u3002", "method": "\u91c7\u7528\u5efa\u6784\u6027\u8bbe\u8ba1\u7814\u7a76\u65b9\u6cd5\uff0c\u57282025\u5e74\u4e3e\u529e\u4e86\u4e09\u573a\u53c2\u4e0e\u5f0f\u5de5\u4f5c\u574a\uff0c\u9080\u8bf7\u516c\u4f17\u548c\u8de8\u9886\u57df\u5229\u76ca\u76f8\u5173\u8005\u53c2\u4e0e\uff0c\u901a\u8fc7\u6545\u4e8b\u8bb2\u8ff0\u548c\u4f4e\u4fdd\u771f\u539f\u578b\u5236\u4f5c\u6765\u63a2\u8ba8AI\u667a\u80fd\u4f53\u5bf9\u793e\u533a\u7684\u6f5c\u5728\u5f71\u54cd\u3002", "result": "\u8bc6\u522b\u51fa\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a1) \u5b9e\u73b0\u6709\u610f\u4e49\u4e14\u6301\u7eed\u7684\u516c\u4f17\u53c2\u4e0e\uff1b2) \u5efa\u7acb\u4e13\u5bb6\u4e0e\u975e\u4e13\u4e1a\u53c2\u4e0e\u8005\u4e4b\u95f4\u7684\u5171\u540c\u8bed\u8a00\uff1b3) \u5c06\u63a8\u6d4b\u6027\u7684\u53c2\u4e0e\u8005\u8f93\u5165\u8f6c\u5316\u4e3a\u53ef\u5b9e\u65bd\u7684\u7cfb\u7edf\u3002", "conclusion": "\u53cd\u601d\u6027\u548c\u957f\u671f\u53c2\u4e0e\u5bf9\u4e8e\u8d1f\u8d23\u4efb\u4e14\u53ef\u64cd\u4f5c\u7684\u516c\u6c11\u4e2d\u5fc3AI\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5efa\u7acb\u6301\u7eed\u7684\u53c2\u4e0e\u673a\u5236\u6765\u786e\u4fddAI\u7cfb\u7edf\u771f\u6b63\u670d\u52a1\u4e8e\u793e\u4f1a\u9700\u6c42\u3002"}}
{"id": "2602.07267", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07267", "abs": "https://arxiv.org/abs/2602.07267", "authors": ["Fengyuan Liu", "Jay Gala", "Nilaksh", "Dzmitry Bahdanau", "Siva Reddy", "Hugo Larochelle"], "title": "BRIDGE: Predicting Human Task Completion Time From Model Performance", "comment": null, "summary": "Evaluating the real-world capabilities of AI systems requires grounding benchmark performance in human-interpretable measures of task difficulty. Existing approaches that rely on direct human task completion time annotations are costly, noisy, and difficult to scale across benchmarks. In this work, we propose BRIDGE, a unified psychometric framework that learns the latent difficulty scale from model responses and anchors it to human task completion time. Using a two-parameter logistic Item Response Theory model, we jointly estimate latent task difficulty and model capability from model performance data across multiple benchmarks. We demonstrate that latent task difficulty varies linearly with the logarithm of human completion time, allowing human task completion time to be inferred for new benchmarks from model performance alone. Leveraging this alignment, we forecast frontier model capabilities in terms of human task length and independently reproduce METR's exponential scaling results, with the 50% solvable task horizon doubling approximately every 6 months.", "AI": {"tldr": "BRIDGE\u6846\u67b6\u901a\u8fc7\u6a21\u578b\u54cd\u5e94\u5b66\u4e60\u4efb\u52a1\u96be\u5ea6\u5c3a\u5ea6\uff0c\u5e76\u4e0e\u4eba\u7c7b\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4ece\u6a21\u578b\u6027\u80fd\u9884\u6d4b\u4eba\u7c7b\u4efb\u52a1\u96be\u5ea6\uff0c\u5e76\u9884\u6d4b\u524d\u6cbf\u6a21\u578b\u80fd\u529b\u6269\u5c55\u8d8b\u52bf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4eba\u7c7b\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u76f4\u63a5\u6807\u6ce8\u7684AI\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u566a\u58f0\u5927\u3001\u96be\u4ee5\u6269\u5c55\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u5c06\u57fa\u51c6\u6027\u80fd\u4e0e\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u4efb\u52a1\u96be\u5ea6\u5ea6\u91cf\u8054\u7cfb\u8d77\u6765\u3002", "method": "\u63d0\u51faBRIDGE\u5fc3\u7406\u6d4b\u91cf\u6846\u67b6\uff0c\u4f7f\u7528\u53cc\u53c2\u6570\u903b\u8f91\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u6a21\u578b\uff0c\u4ece\u591a\u4e2a\u57fa\u51c6\u7684\u6a21\u578b\u6027\u80fd\u6570\u636e\u4e2d\u8054\u5408\u4f30\u8ba1\u6f5c\u5728\u4efb\u52a1\u96be\u5ea6\u548c\u6a21\u578b\u80fd\u529b\uff0c\u53d1\u73b0\u6f5c\u5728\u4efb\u52a1\u96be\u5ea6\u4e0e\u4eba\u7c7b\u5b8c\u6210\u65f6\u95f4\u7684\u5bf9\u6570\u5448\u7ebf\u6027\u5173\u7cfb\u3002", "result": "\u6f5c\u5728\u4efb\u52a1\u96be\u5ea6\u4e0e\u4eba\u7c7b\u5b8c\u6210\u65f6\u95f4\u7684\u5bf9\u6570\u5448\u7ebf\u6027\u5173\u7cfb\uff0c\u4f7f\u5f97\u4ec5\u4ece\u6a21\u578b\u6027\u80fd\u5c31\u80fd\u63a8\u65ad\u65b0\u57fa\u51c6\u7684\u4eba\u7c7b\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\uff1b\u9884\u6d4b\u524d\u6cbf\u6a21\u578b\u80fd\u529b\u6269\u5c55\u8d8b\u52bf\uff0c50%\u53ef\u89e3\u51b3\u4efb\u52a1\u8303\u56f4\u7ea6\u6bcf6\u4e2a\u6708\u7ffb\u500d\u3002", "conclusion": "BRIDGE\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u5c06\u6a21\u578b\u57fa\u51c6\u6027\u80fd\u4e0e\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u4efb\u52a1\u96be\u5ea6\u5ea6\u91cf\u5bf9\u9f50\uff0c\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u6a21\u578b\u80fd\u529b\u6269\u5c55\u8d8b\u52bf\uff0c\u4e3aAI\u7cfb\u7edf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u6846\u67b6\u3002"}}
{"id": "2602.08632", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08632", "abs": "https://arxiv.org/abs/2602.08632", "authors": ["Adi Haviv", "Niva Elkin-Koren", "Uri Hacohen", "Roi Livni", "Shay Moran"], "title": "We Should Separate Memorization from Copyright", "comment": null, "summary": "The widespread use of foundation models has introduced a new risk factor of copyright issue. This issue is leading to an active, lively and on-going debate amongst the data-science community as well as amongst legal scholars. Where claims and results across both sides are often interpreted in different ways and leading to different implications. Our position is that much of the technical literature relies on traditional reconstruction techniques that are not designed for copyright analysis. As a result, memorization and copying have been conflated across both technical and legal communities and in multiple contexts. We argue that memorization, as commonly studied in data science, should not be equated with copying and should not be used as a proxy for copyright infringement. We distinguish technical signals that meaningfully indicate infringement risk from those that instead reflect lawful generalization or high-frequency content. Based on this analysis, we advocate for an output-level, risk-based evaluation process that aligns technical assessments with established copyright standards and provides a more principled foundation for research, auditing, and policy.", "AI": {"tldr": "\u8bba\u6587\u8ba4\u4e3a\u5f53\u524d\u6280\u672f\u6587\u732e\u4e2d\u7684\u8bb0\u5fc6\u5316\u7814\u7a76\u4e0d\u5e94\u7b49\u540c\u4e8e\u7248\u6743\u4fb5\u6743\uff0c\u4e3b\u5f20\u91c7\u7528\u57fa\u4e8e\u8f93\u51fa\u7684\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\u6765\u8bc4\u4f30\u7248\u6743\u95ee\u9898", "motivation": "\u57fa\u7840\u6a21\u578b\u7684\u5e7f\u6cdb\u4f7f\u7528\u5e26\u6765\u4e86\u65b0\u7684\u7248\u6743\u98ce\u9669\uff0c\u4f46\u6280\u672f\u793e\u533a\u548c\u6cd5\u5f8b\u5b66\u8005\u5bf9\u6b64\u5b58\u5728\u4e0d\u540c\u89e3\u8bfb\u548c\u4e89\u8bae\u3002\u5f53\u524d\u6280\u672f\u6587\u732e\u4f9d\u8d56\u7684\u4f20\u7edf\u91cd\u6784\u6280\u672f\u5e76\u4e0d\u9002\u7528\u4e8e\u7248\u6743\u5206\u6790\uff0c\u5bfc\u81f4\u8bb0\u5fc6\u5316\u4e0e\u590d\u5236\u88ab\u6df7\u6dc6", "method": "\u533a\u5206\u6709\u610f\u4e49\u7684\u4fb5\u6743\u98ce\u9669\u6280\u672f\u4fe1\u53f7\u4e0e\u5408\u6cd5\u7684\u6cdb\u5316\u6216\u9ad8\u9891\u5185\u5bb9\uff0c\u63d0\u51fa\u57fa\u4e8e\u8f93\u51fa\u7684\u98ce\u9669\u8bc4\u4f30\u6d41\u7a0b\uff0c\u4f7f\u6280\u672f\u8bc4\u4f30\u4e0e\u73b0\u6709\u7248\u6743\u6807\u51c6\u4fdd\u6301\u4e00\u81f4", "result": "\u8bba\u8bc1\u4e86\u8bb0\u5fc6\u5316\u4e0d\u5e94\u7b49\u540c\u4e8e\u590d\u5236\uff0c\u4e5f\u4e0d\u5e94\u4f5c\u4e3a\u7248\u6743\u4fb5\u6743\u7684\u4ee3\u7406\u6307\u6807\u3002\u5efa\u7acb\u4e86\u533a\u5206\u4fb5\u6743\u98ce\u9669\u4e0e\u5408\u6cd5\u5185\u5bb9\u7684\u6280\u672f\u4fe1\u53f7\u6846\u67b6", "conclusion": "\u4e3b\u5f20\u91c7\u7528\u57fa\u4e8e\u8f93\u51fa\u7684\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e3a\u7814\u7a76\u3001\u5ba1\u8ba1\u548c\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u66f4\u539f\u5219\u6027\u7684\u57fa\u7840\uff0c\u4f7f\u6280\u672f\u8bc4\u4f30\u4e0e\u7248\u6743\u6807\u51c6\u4fdd\u6301\u4e00\u81f4"}}
{"id": "2602.07274", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07274", "abs": "https://arxiv.org/abs/2602.07274", "authors": ["Kaijie Zhu", "Yuzhou Nie", "Yijiang Li", "Yiming Huang", "Jialian Wu", "Jiang Liu", "Ximeng Sun", "Zhenfei Yin", "Lun Wang", "Zicheng Liu", "Emad Barsoum", "William Yang Wang", "Wenbo Guo"], "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents", "comment": null, "summary": "Executing complex terminal tasks remains a significant challenge for open-weight LLMs, constrained by two fundamental limitations. First, high-fidelity, executable training environments are scarce: environments synthesized from real-world repositories are not diverse and scalable, while trajectories synthesized by LLMs suffer from hallucinations. Second, standard instruction tuning uses expert trajectories that rarely exhibit simple mistakes common to smaller models. This creates a distributional mismatch, leaving student models ill-equipped to recover from their own runtime failures. To bridge these gaps, we introduce TermiGen, an end-to-end pipeline for synthesizing verifiable environments and resilient expert trajectories. Termi-Gen first generates functionally valid tasks and Docker containers via an iterative multi-agent refinement loop. Subsequently, we employ a Generator-Critic protocol that actively injects errors during trajectory collection, synthesizing data rich in error-correction cycles. Fine-tuned on this TermiGen-generated dataset, our TermiGen-Qwen2.5-Coder-32B achieves a 31.3% pass rate on TerminalBench. This establishes a new open-weights state-of-the-art, outperforming existing baselines and notably surpassing capable proprietary models such as o4-mini. Dataset is avaiable at https://github.com/ucsb-mlsec/terminal-bench-env.", "AI": {"tldr": "TermiGen\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7ba1\u9053\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8fed\u4ee3\u7cbe\u70bc\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u7ec8\u7aef\u73af\u5883\uff0c\u5e76\u901a\u8fc7Generator-Critic\u534f\u8bae\u6ce8\u5165\u9519\u8bef\u6765\u5408\u6210\u5305\u542b\u9519\u8bef\u7ea0\u6b63\u5faa\u73af\u7684\u8f68\u8ff9\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u590d\u6742\u7ec8\u7aef\u4efb\u52a1\u4e0a\u7684\u6267\u884c\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5f00\u6e90LLM\u5728\u6267\u884c\u590d\u6742\u7ec8\u7aef\u4efb\u52a1\u65f6\u9762\u4e34\u4e24\u4e2a\u6838\u5fc3\u9650\u5236\uff1a1) \u7f3a\u4e4f\u9ad8\u4fdd\u771f\u3001\u53ef\u6267\u884c\u7684\u8bad\u7ec3\u73af\u5883\uff08\u73b0\u6709\u73af\u5883\u8981\u4e48\u4e0d\u591f\u591a\u6837\u5316\uff0c\u8981\u4e48\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff09\uff1b2) \u6807\u51c6\u6307\u4ee4\u8c03\u4f18\u4f7f\u7528\u7684\u4e13\u5bb6\u8f68\u8ff9\u5f88\u5c11\u5305\u542b\u5c0f\u6a21\u578b\u5e38\u89c1\u7684\u7b80\u5355\u9519\u8bef\uff0c\u5bfc\u81f4\u5b66\u751f\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u4ece\u81ea\u8eab\u8fd0\u884c\u65f6\u9519\u8bef\u4e2d\u6062\u590d\u3002", "method": "TermiGen\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u901a\u8fc7\u8fed\u4ee3\u591a\u667a\u80fd\u4f53\u7cbe\u70bc\u5faa\u73af\u751f\u6210\u529f\u80fd\u6709\u6548\u7684\u4efb\u52a1\u548cDocker\u5bb9\u5668\uff1b2) \u4f7f\u7528Generator-Critic\u534f\u8bae\u5728\u8f68\u8ff9\u6536\u96c6\u8fc7\u7a0b\u4e2d\u4e3b\u52a8\u6ce8\u5165\u9519\u8bef\uff0c\u5408\u6210\u5bcc\u542b\u9519\u8bef\u7ea0\u6b63\u5faa\u73af\u7684\u6570\u636e\u3002", "result": "\u4f7f\u7528TermiGen\u751f\u6210\u7684\u6570\u636e\u96c6\u5fae\u8c03\u7684TermiGen-Qwen2.5-Coder-32B\u5728TerminalBench\u4e0a\u8fbe\u5230\u4e8631.3%\u7684\u901a\u8fc7\u7387\uff0c\u521b\u9020\u4e86\u5f00\u6e90\u6a21\u578b\u7684\u65b0SOTA\uff0c\u751a\u81f3\u8d85\u8d8a\u4e86o4-mini\u7b49\u4e13\u6709\u6a21\u578b\u3002", "conclusion": "TermiGen\u901a\u8fc7\u5408\u6210\u53ef\u9a8c\u8bc1\u73af\u5883\u548c\u5305\u542b\u9519\u8bef\u7ea0\u6b63\u7684\u8f68\u8ff9\u6570\u636e\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f00\u6e90LLM\u5728\u7ec8\u7aef\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u5b9e\u9645\u6267\u884c\u80fd\u529b\u548c\u9519\u8bef\u6062\u590d\u80fd\u529b\u3002"}}
{"id": "2602.08728", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08728", "abs": "https://arxiv.org/abs/2602.08728", "authors": ["Maxim Dedyaev"], "title": "Algorithmic Governance in the United States: A Multi-Level Case Analysis of AI Deployment Across Federal, State, and Municipal Authorities", "comment": null, "summary": "The rapid expansion of artificial intelligence in public governance has generated strong optimism about faster processes, smarter decisions, and more modern administrative systems. Yet despite this enthusiasm, we still know surprisingly little about how AI actually takes shape inside different layers of government. Especially in federal systems where authority is fragmented across multiple levels. In practice, the same algorithm can serve very different purposes. This study responds to that gap by examining how AI is used across federal, state, and municipal levels in the United States. Drawing on a comparative qualitative analysis of thirty AI implementation cases, and guided by a digital-era governance framework combined with a sociotechnical perspective, the study identifies two broad modes of algorithmic governance: control-oriented systems and support-oriented systems. The findings reveal a clear pattern of functional differentiation across levels of government. At the federal level, AI is most often institutionalized as a tool for high-stakes control: supporting surveillance, enforcement, and regulatory oversight. State governments occupy a more ambiguous middle ground, where AI frequently combines supportive functions with algorithmic gatekeeping, particularly in areas such as welfare administration and public health. Municipal governments, by contrast, tend to deploy AI in more pragmatic and service-oriented ways, using it to streamline everyday operations and improve direct interactions with residents. By foregrounding institutional context, this study advances debates on algorithmic governance by demonstrating that the character, function, and risks of AI in the public sector are fundamentally shaped by the level of governance at which these systems are deployed.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u7f8e\u56fd\u8054\u90a6\u3001\u5dde\u548c\u5e02\u7ea7\u653f\u5e9c\u4e2dAI\u5e94\u7528\u7684\u5c42\u7ea7\u5dee\u5f02\uff1a\u8054\u90a6\u5c42\u9762AI\u4e3b\u8981\u7528\u4e8e\u9ad8\u98ce\u9669\u63a7\u5236\uff08\u76d1\u63a7\u3001\u6267\u6cd5\uff09\uff0c\u5dde\u653f\u5e9c\u6df7\u5408\u652f\u6301\u4e0e\u628a\u5173\u529f\u80fd\uff0c\u5e02\u7ea7\u653f\u5e9c\u5219\u66f4\u6ce8\u91cd\u5b9e\u7528\u670d\u52a1\u5bfc\u5411\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u516c\u5171\u6cbb\u7406\u4e2d\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u4eba\u4eec\u5bf9AI\u5728\u4e0d\u540c\u653f\u5e9c\u5c42\u7ea7\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u5f62\u6001\u77e5\u4e4b\u751a\u5c11\uff0c\u7279\u522b\u662f\u5728\u6743\u529b\u5206\u6563\u7684\u8054\u90a6\u5236\u4f53\u7cfb\u4e2d\u3002\u540c\u4e00\u7b97\u6cd5\u5728\u4e0d\u540c\u5c42\u7ea7\u53ef\u80fd\u670d\u52a1\u4e8e\u5b8c\u5168\u4e0d\u540c\u7684\u76ee\u7684\uff0c\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u9700\u8981\u586b\u8865\u3002", "method": "\u91c7\u7528\u6bd4\u8f83\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\uff0c\u7814\u7a7630\u4e2a\u7f8e\u56fdAI\u5b9e\u65bd\u6848\u4f8b\uff0c\u7ed3\u5408\u6570\u5b57\u65f6\u4ee3\u6cbb\u7406\u6846\u67b6\u548c\u793e\u4f1a\u6280\u672f\u89c6\u89d2\uff0c\u8bc6\u522b\u7b97\u6cd5\u6cbb\u7406\u7684\u4e24\u79cd\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u653f\u5e9c\u5c42\u7ea7\u95f4\u5b58\u5728\u660e\u663e\u7684\u529f\u80fd\u5206\u5316\u6a21\u5f0f\uff1a\u8054\u90a6\u653f\u5e9c\u5c06AI\u5236\u5ea6\u5316\u4e3a\u9ad8\u98ce\u9669\u63a7\u5236\u5de5\u5177\uff08\u76d1\u63a7\u3001\u6267\u6cd5\u3001\u76d1\u7ba1\uff09\uff1b\u5dde\u653f\u5e9c\u5904\u4e8e\u6a21\u7cca\u4e2d\u95f4\u5730\u5e26\uff0c\u6df7\u5408\u652f\u6301\u529f\u80fd\u4e0e\u7b97\u6cd5\u628a\u5173\uff1b\u5e02\u7ea7\u653f\u5e9c\u5219\u4ee5\u5b9e\u7528\u670d\u52a1\u4e3a\u5bfc\u5411\uff0c\u7528\u4e8e\u7b80\u5316\u65e5\u5e38\u8fd0\u8425\u548c\u6539\u5584\u5c45\u6c11\u4e92\u52a8\u3002", "conclusion": "AI\u5728\u516c\u5171\u90e8\u95e8\u7684\u7279\u5f81\u3001\u529f\u80fd\u548c\u98ce\u9669\u6839\u672c\u4e0a\u53d7\u90e8\u7f72\u5c42\u7ea7\u7684\u5236\u5ea6\u80cc\u666f\u5f71\u54cd\uff0c\u7b97\u6cd5\u6cbb\u7406\u7684\u6027\u8d28\u7531\u6cbb\u7406\u5c42\u7ea7\u51b3\u5b9a\u800c\u975e\u6280\u672f\u672c\u8eab\u3002"}}
{"id": "2602.07276", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07276", "abs": "https://arxiv.org/abs/2602.07276", "authors": ["Pengrui Han", "Xueqiang Xu", "Keyang Xuan", "Peiyang Song", "Siru Ouyang", "Runchu Tian", "Yuqing Jiang", "Cheng Qian", "Pengcheng Jiang", "Jiashuo Sun", "Junxia Cui", "Ming Zhong", "Ge Liu", "Jiawei Han", "Jiaxuan You"], "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs", "comment": null, "summary": "Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex tasks that require multiple coordinated capabilities. To address this limitation, we propose STEER2ADAPT, a lightweight framework that adapts LLMs by composing steering vectors rather than learning new ones from scratch. In many domains (e.g., reasoning or safety), tasks share a small set of underlying concept dimensions. STEER2ADAPT captures these dimensions as a reusable, low-dimensional semantic prior subspace, and adapts to new tasks by dynamically discovering a linear combination of basis vectors from only a handful of examples. Experiments across 9 tasks and 3 models in both reasoning and safety domains demonstrate the effectiveness of STEER2ADAPT, achieving an average improvement of 8.2%. Extensive analyses further show that STEER2ADAPT is a data-efficient, stable, and transparent inference-time adaptation method for LLMs.", "AI": {"tldr": "STEER2ADAPT\uff1a\u901a\u8fc7\u7ec4\u5408\u73b0\u6709\u63a7\u5236\u5411\u91cf\u800c\u975e\u4ece\u5934\u5b66\u4e60\u65b0\u5411\u91cf\u6765\u9002\u5e94LLM\u7684\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u5728\u63a8\u7406\u548c\u5b89\u5168\u4efb\u52a1\u4e0a\u5e73\u5747\u63d0\u53478.2%", "motivation": "\u73b0\u6709\u6fc0\u6d3b\u63a7\u5236\u65b9\u6cd5\u901a\u5e38\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u6216\u6982\u5ff5\u4f7f\u7528\u5355\u4e00\u9759\u6001\u65b9\u5411\uff0c\u5bfc\u81f4\u5728\u4efb\u52a1\u53d8\u5316\u65f6\u4e0d\u591f\u7075\u6d3b\uff0c\u4e14\u65e0\u6cd5\u5904\u7406\u9700\u8981\u591a\u79cd\u534f\u8c03\u80fd\u529b\u7684\u590d\u6742\u4efb\u52a1", "method": "\u63d0\u51faSTEER2ADAPT\u6846\u67b6\uff0c\u5c06\u4efb\u52a1\u5171\u4eab\u7684\u5e95\u5c42\u6982\u5ff5\u7ef4\u5ea6\u6355\u83b7\u4e3a\u53ef\u91cd\u7528\u7684\u4f4e\u7ef4\u8bed\u4e49\u5148\u9a8c\u5b50\u7a7a\u95f4\uff0c\u901a\u8fc7\u5c11\u91cf\u793a\u4f8b\u52a8\u6001\u53d1\u73b0\u57fa\u5411\u91cf\u7684\u7ebf\u6027\u7ec4\u5408\u6765\u9002\u5e94\u65b0\u4efb\u52a1", "result": "\u57289\u4e2a\u4efb\u52a1\u548c3\u4e2a\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u63a8\u7406\u548c\u5b89\u5168\u9886\u57df\u5e73\u5747\u63d0\u53478.2%\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u6570\u636e\u9ad8\u6548\u3001\u7a33\u5b9a\u548c\u900f\u660e\u7684\u7279\u70b9", "conclusion": "STEER2ADAPT\u662f\u4e00\u79cd\u6709\u6548\u7684\u63a8\u7406\u65f6\u9002\u5e94\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u7ec4\u5408\u73b0\u6709\u63a7\u5236\u5411\u91cf\u800c\u975e\u5b66\u4e60\u65b0\u5411\u91cf\u6765\u7075\u6d3b\u9002\u5e94LLM\u7684\u4e0b\u6e38\u884c\u4e3a"}}
{"id": "2602.08786", "categories": ["cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08786", "abs": "https://arxiv.org/abs/2602.08786", "authors": ["Unai Fischer-Abaigar", "Emily Aiken", "Christoph Kern", "Juan Carlos Perdomo"], "title": "Empirically Understanding the Value of Prediction in Allocation", "comment": null, "summary": "Institutions increasingly use prediction to allocate scarce resources. From a design perspective, better predictions compete with other investments, such as expanding capacity or improving treatment quality. Here, the big question is not how to solve a specific allocation problem, but rather which problem to solve. In this work, we develop an empirical toolkit to help planners form principled answers to this question and quantify the bottom-line welfare impact of investments in prediction versus other policy levers such as expanding capacity and improving treatment quality. Applying our framework in two real-world case studies on German employment services and poverty targeting in Ethiopia, we illustrate how decision-makers can reliably derive context-specific conclusions about the relative value of prediction in their allocation problem. We make our software toolkit, rvp, and parts of our data available in order to enable future empirical work in this area.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b9e\u8bc1\u5de5\u5177\u5305\uff0c\u5e2e\u52a9\u51b3\u7b56\u8005\u91cf\u5316\u9884\u6d4b\u6295\u8d44\u76f8\u5bf9\u4e8e\u5176\u4ed6\u653f\u7b56\u6760\u6746\uff08\u5982\u6269\u5927\u5bb9\u91cf\u548c\u6539\u8fdb\u6cbb\u7597\u8d28\u91cf\uff09\u7684\u798f\u5229\u5f71\u54cd\uff0c\u5e76\u5728\u5fb7\u56fd\u5c31\u4e1a\u670d\u52a1\u548c\u57c3\u585e\u4fc4\u6bd4\u4e9a\u8d2b\u56f0\u76ee\u6807\u5b9a\u4f4d\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u4e2d\u5e94\u7528\u3002", "motivation": "\u673a\u6784\u8d8a\u6765\u8d8a\u591a\u5730\u4f7f\u7528\u9884\u6d4b\u6765\u5206\u914d\u7a00\u7f3a\u8d44\u6e90\u3002\u4ece\u8bbe\u8ba1\u89d2\u5ea6\u770b\uff0c\u66f4\u597d\u7684\u9884\u6d4b\u4e0e\u5176\u4ed6\u6295\u8d44\uff08\u5982\u6269\u5927\u5bb9\u91cf\u6216\u6539\u8fdb\u6cbb\u7597\u8d28\u91cf\uff09\u5b58\u5728\u7ade\u4e89\u3002\u6838\u5fc3\u95ee\u9898\u4e0d\u662f\u5982\u4f55\u89e3\u51b3\u7279\u5b9a\u7684\u5206\u914d\u95ee\u9898\uff0c\u800c\u662f\u5e94\u8be5\u89e3\u51b3\u54ea\u4e2a\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b9e\u8bc1\u5de5\u5177\u5305\uff08rvp\u8f6f\u4ef6\u5de5\u5177\u5305\uff09\uff0c\u5e2e\u52a9\u89c4\u5212\u8005\u5f62\u6210\u539f\u5219\u6027\u7684\u7b54\u6848\uff0c\u91cf\u5316\u9884\u6d4b\u6295\u8d44\u76f8\u5bf9\u4e8e\u5176\u4ed6\u653f\u7b56\u6760\u6746\uff08\u5982\u6269\u5927\u5bb9\u91cf\u548c\u6539\u8fdb\u6cbb\u7597\u8d28\u91cf\uff09\u7684\u798f\u5229\u5f71\u54cd\u3002\u5728\u4e24\u4e2a\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u4e2d\u5e94\u7528\u8be5\u6846\u67b6\uff1a\u5fb7\u56fd\u5c31\u4e1a\u670d\u52a1\u548c\u57c3\u585e\u4fc4\u6bd4\u4e9a\u8d2b\u56f0\u76ee\u6807\u5b9a\u4f4d\u3002", "result": "\u51b3\u7b56\u8005\u80fd\u591f\u53ef\u9760\u5730\u5f97\u51fa\u5173\u4e8e\u9884\u6d4b\u5728\u5176\u5206\u914d\u95ee\u9898\u4e2d\u76f8\u5bf9\u4ef7\u503c\u7684\u5177\u4f53\u60c5\u5883\u7ed3\u8bba\u3002\u5de5\u5177\u5305\u548c\u90e8\u5206\u6570\u636e\u5df2\u516c\u5f00\uff0c\u4ee5\u652f\u6301\u8be5\u9886\u57df\u7684\u672a\u6765\u5b9e\u8bc1\u7814\u7a76\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u5b9e\u8bc1\u6846\u67b6\uff0c\u5e2e\u52a9\u51b3\u7b56\u8005\u5728\u8d44\u6e90\u5206\u914d\u4e2d\u6743\u8861\u9884\u6d4b\u6295\u8d44\u4e0e\u5176\u4ed6\u653f\u7b56\u9009\u62e9\uff0c\u4f7f\u673a\u6784\u80fd\u591f\u57fa\u4e8e\u5177\u4f53\u60c5\u5883\u505a\u51fa\u66f4\u660e\u667a\u7684\u6295\u8d44\u51b3\u7b56\u3002"}}
{"id": "2602.07308", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07308", "abs": "https://arxiv.org/abs/2602.07308", "authors": ["Sutapa Dey Tithi", "Nazia Alam", "Tahreem Yasir", "Yang Shi", "Xiaoyi Tian", "Min Chi", "Tiffany Barnes"], "title": "Adaptive Scaffolding for Cognitive Engagement in an Intelligent Tutoring System", "comment": null, "summary": "The ICAP framework defines four cognitive engagement levels: Passive, Active, Constructive, and Interactive, where increased cognitive engagement can yield improved learning. However, personalizing learning activities that elicit the optimal level of cognitive engagement remains a key challenge in intelligent tutoring systems (ITS). In this work, we develop and evaluate a system that adaptively scaffolds cognitive engagement by dynamically selecting worked examples in two different ICAP modes: (active) Guided examples and (constructive) Buggy examples. We compare Bayesian Knowledge Tracing (BKT) and Deep Reinforcement Learning (DRL) as adaptive methods against a non-adaptive baseline method for selecting example type in a logic ITS. Our experiment with 113 students demonstrates that both adaptive policies significantly improved student performance on test problems. BKT yielded the largest improvement in posttest scores for low prior knowledge students, helping them catch up with their high prior knowledge peers, whereas DRL yielded significantly higher posttest scores among high prior knowledge students. This paper contributes new insights into the complex interactions of cognitive engagement and adaptivity and their results on learning outcomes.", "AI": {"tldr": "\u5f00\u53d1\u81ea\u9002\u5e94\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u5de5\u4f5c\u793a\u4f8b\u6765\u8c03\u6574\u8ba4\u77e5\u53c2\u4e0e\u5ea6\uff0c\u6bd4\u8f83BKT\u548cDRL\u4e24\u79cd\u81ea\u9002\u5e94\u65b9\u6cd5\u5728\u903b\u8f91ITS\u4e2d\u7684\u6548\u679c", "motivation": "\u4e2a\u6027\u5316\u5b66\u4e60\u6d3b\u52a8\u4ee5\u6fc0\u53d1\u6700\u4f73\u8ba4\u77e5\u53c2\u4e0e\u5ea6\u662f\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u7684\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u63a2\u7d22\u5982\u4f55\u81ea\u9002\u5e94\u5730\u8c03\u6574\u8ba4\u77e5\u53c2\u4e0e\u5ea6\u6765\u63d0\u5347\u5b66\u4e60\u6548\u679c", "method": "\u5f00\u53d1\u81ea\u9002\u5e94\u7cfb\u7edf\uff0c\u52a8\u6001\u9009\u62e9\u4e24\u79cdICAP\u6a21\u5f0f\u7684\u5de5\u4f5c\u793a\u4f8b\uff1a\u4e3b\u52a8\u6a21\u5f0f\u7684\u5f15\u5bfc\u793a\u4f8b\u548c\u5efa\u6784\u6a21\u5f0f\u7684\u9519\u8bef\u793a\u4f8b\uff1b\u6bd4\u8f83BKT\u548cDRL\u4e24\u79cd\u81ea\u9002\u5e94\u65b9\u6cd5\u4e0e\u65e0\u81ea\u9002\u5e94\u57fa\u7ebf\u65b9\u6cd5", "result": "\u4e24\u79cd\u81ea\u9002\u5e94\u7b56\u7565\u5747\u663e\u8457\u63d0\u5347\u5b66\u751f\u5728\u6d4b\u8bd5\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff1aBKT\u5bf9\u4f4e\u5148\u9a8c\u77e5\u8bc6\u5b66\u751f\u63d0\u5347\u6700\u5927\uff0c\u5e2e\u52a9\u4ed6\u4eec\u8d76\u4e0a\u9ad8\u5148\u9a8c\u77e5\u8bc6\u540c\u4f34\uff1bDRL\u5728\u9ad8\u5148\u9a8c\u77e5\u8bc6\u5b66\u751f\u4e2d\u4ea7\u751f\u663e\u8457\u66f4\u9ad8\u7684\u540e\u6d4b\u5206\u6570", "conclusion": "\u7814\u7a76\u4e3a\u8ba4\u77e5\u53c2\u4e0e\u5ea6\u548c\u81ea\u9002\u5e94\u6027\u7684\u590d\u6742\u4ea4\u4e92\u53ca\u5176\u5bf9\u5b66\u4e60\u6210\u679c\u7684\u5f71\u54cd\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u5c55\u793a\u4e86\u4e0d\u540c\u81ea\u9002\u5e94\u65b9\u6cd5\u5bf9\u4e0d\u540c\u5b66\u751f\u7fa4\u4f53\u7684\u5dee\u5f02\u5316\u6548\u679c"}}
{"id": "2602.08997", "categories": ["cs.CY", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08997", "abs": "https://arxiv.org/abs/2602.08997", "authors": ["Lavender Y. Jiang", "Xujin Chris Liu", "Kyunghyun Cho", "Eric K. Oermann"], "title": "Paradox of De-identification: A Critique of HIPAA Safe Harbour in the Age of LLMs", "comment": null, "summary": "Privacy is a human right that sustains patient-provider trust. Clinical notes capture a patient's private vulnerability and individuality, which are used for care coordination and research. Under HIPAA Safe Harbor, these notes are de-identified to protect patient privacy. However, Safe Harbor was designed for an era of categorical tabular data, focusing on the removal of explicit identifiers while ignoring the latent information found in correlations between identity and quasi-identifiers, which can be captured by modern LLMs. We first formalize these correlations using a causal graph, then validate it empirically through individual re-identification of patients from scrubbed notes. The paradox of de-identification is further shown through a diagnosis ablation: even when all other information is removed, the model can predict the patient's neighborhood based on diagnosis alone. This position paper raises the question of how we can act as a community to uphold patient-provider trust when de-identification is inherently imperfect. We aim to raise awareness and discuss actionable recommendations.", "AI": {"tldr": "\u8bba\u6587\u6307\u51faHIPAA Safe Harbor\u53bb\u6807\u8bc6\u5316\u65b9\u6cd5\u5728\u73b0\u4ee3LLM\u65f6\u4ee3\u5b58\u5728\u7f3a\u9677\uff0c\u65e0\u6cd5\u4fdd\u62a4\u60a3\u8005\u9690\u79c1\uff0c\u56e0\u4e3aLLM\u80fd\u4ece\u8bca\u65ad\u7b49\u51c6\u6807\u8bc6\u7b26\u4e2d\u63a8\u65ad\u51fa\u8eab\u4efd\u4fe1\u606f\u3002", "motivation": "\u9690\u79c1\u662f\u57fa\u672c\u4eba\u6743\uff0c\u4e34\u5e8a\u7b14\u8bb0\u5305\u542b\u60a3\u8005\u654f\u611f\u4fe1\u606f\uff0c\u9700\u8981\u53bb\u6807\u8bc6\u5316\u4fdd\u62a4\u3002\u4f46\u73b0\u884cHIPAA Safe Harbor\u65b9\u6cd5\u8bbe\u8ba1\u4e8e\u5206\u7c7b\u8868\u683c\u6570\u636e\u65f6\u4ee3\uff0c\u65e0\u6cd5\u5e94\u5bf9\u73b0\u4ee3LLM\u4ece\u51c6\u6807\u8bc6\u7b26\u76f8\u5173\u6027\u4e2d\u63a8\u65ad\u8eab\u4efd\u7684\u80fd\u529b\u3002", "method": "\u9996\u5148\u4f7f\u7528\u56e0\u679c\u56fe\u5f62\u5f0f\u5316\u8eab\u4efd\u4e0e\u51c6\u6807\u8bc6\u7b26\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u7136\u540e\u901a\u8fc7\u5b9e\u8bc1\u9a8c\u8bc1\uff1a1\uff09\u4ece\u53bb\u6807\u8bc6\u5316\u7b14\u8bb0\u4e2d\u91cd\u65b0\u8bc6\u522b\u60a3\u8005\uff1b2\uff09\u8bca\u65ad\u6d88\u878d\u5b9e\u9a8c\uff1a\u5373\u4f7f\u79fb\u9664\u5176\u4ed6\u6240\u6709\u4fe1\u606f\uff0c\u4ec5\u51ed\u8bca\u65ad\u5c31\u80fd\u9884\u6d4b\u60a3\u8005\u5c45\u4f4f\u533a\u57df\u3002", "result": "\u5b9e\u8bc1\u8868\u660e\u53bb\u6807\u8bc6\u5316\u5b58\u5728\u56fa\u6709\u7f3a\u9677\uff1aLLM\u80fd\u4ece\u53bb\u6807\u8bc6\u5316\u7b14\u8bb0\u4e2d\u91cd\u65b0\u8bc6\u522b\u60a3\u8005\uff0c\u4ec5\u51ed\u8bca\u65ad\u4fe1\u606f\u5c31\u80fd\u63a8\u65ad\u60a3\u8005\u5c45\u4f4f\u533a\u57df\uff0c\u663e\u793a\u53bb\u6807\u8bc6\u5316\u672c\u8d28\u4e0a\u662f\u4e0d\u5b8c\u5584\u7684\u3002", "conclusion": "\u53bb\u6807\u8bc6\u5316\u5b58\u5728\u56fa\u6709\u7f3a\u9677\uff0c\u9700\u8981\u793e\u533a\u5171\u540c\u884c\u52a8\u6765\u7ef4\u62a4\u533b\u60a3\u4fe1\u4efb\u3002\u8bba\u6587\u65e8\u5728\u63d0\u9ad8\u610f\u8bc6\u5e76\u8ba8\u8bba\u53ef\u884c\u7684\u5efa\u8bae\u63aa\u65bd\u3002"}}
{"id": "2602.07339", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.07339", "abs": "https://arxiv.org/abs/2602.07339", "authors": ["Ruturaj Reddy", "Hrishav Bakul Barua", "Junn Yong Loo", "Thanh Thi Nguyen", "Ganesh Krishnasamy"], "title": "RAPiD: Real-time Deterministic Trajectory Planning via Diffusion Behavior Priors for Safe and Efficient Autonomous Driving", "comment": null, "summary": "Diffusion-based trajectory planners have demonstrated strong capability for modeling the multimodal nature of human driving behavior, but their reliance on iterative stochastic sampling poses critical challenges for real-time, safety-critical deployment. In this work, we present RAPiD, a deterministic policy extraction framework that distills a pretrained diffusion-based planner into an efficient policy while eliminating diffusion sampling. Using score-regularized policy optimization, we leverage the score function of a pre-trained diffusion planner as a behavior prior to regularize policy learning. To promote safety and passenger comfort, the policy is optimized using a critic trained to imitate a predictive driver controller, providing dense, safety-focused supervision beyond conventional imitation learning. Evaluations demonstrate that RAPiD achieves competitive performance on closed-loop nuPlan scenarios with an 8x speedup over diffusion baselines, while achieving state-of-the-art generalization among learning-based planners on the interPlan benchmark. The official website of this work is: https://github.com/ruturajreddy/RAPiD.", "AI": {"tldr": "RAPiD\u662f\u4e00\u4e2a\u786e\u5b9a\u6027\u7b56\u7565\u63d0\u53d6\u6846\u67b6\uff0c\u5c06\u9884\u8bad\u7ec3\u7684\u6269\u6563\u8f68\u8ff9\u89c4\u5212\u5668\u84b8\u998f\u4e3a\u9ad8\u6548\u7b56\u7565\uff0c\u6d88\u9664\u6269\u6563\u91c7\u6837\uff0c\u5b9e\u73b08\u500d\u52a0\u901f\u5e76\u4fdd\u6301\u7ade\u4e89\u6027\u80fd", "motivation": "\u6269\u6563\u8f68\u8ff9\u89c4\u5212\u5668\u80fd\u5efa\u6a21\u4eba\u7c7b\u9a7e\u9a76\u7684\u591a\u6a21\u6001\u884c\u4e3a\uff0c\u4f46\u4f9d\u8d56\u8fed\u4ee3\u968f\u673a\u91c7\u6837\uff0c\u96be\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u5b89\u5168\u5173\u952e\u90e8\u7f72\u7684\u9700\u6c42", "method": "\u4f7f\u7528\u5206\u6570\u6b63\u5219\u5316\u7b56\u7565\u4f18\u5316\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6269\u6563\u89c4\u5212\u5668\u7684\u8bc4\u5206\u51fd\u6570\u4f5c\u4e3a\u884c\u4e3a\u5148\u9a8c\u6765\u6b63\u5219\u5316\u7b56\u7565\u5b66\u4e60\uff1b\u901a\u8fc7\u6a21\u4eff\u9884\u6d4b\u9a7e\u9a76\u5458\u63a7\u5236\u5668\u7684\u8bc4\u8bba\u5bb6\u63d0\u4f9b\u5bc6\u96c6\u5b89\u5168\u76d1\u7763", "result": "\u5728nuPlan\u573a\u666f\u4e2d\u5b9e\u73b0\u7ade\u4e89\u6027\u80fd\uff0c\u6bd4\u6269\u6563\u57fa\u7ebf\u5feb8\u500d\uff1b\u5728interPlan\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u57fa\u4e8e\u5b66\u4e60\u7684\u89c4\u5212\u5668\u7684\u6700\u5148\u8fdb\u6cdb\u5316\u80fd\u529b", "conclusion": "RAPiD\u6210\u529f\u5c06\u6269\u6563\u89c4\u5212\u5668\u84b8\u998f\u4e3a\u9ad8\u6548\u786e\u5b9a\u6027\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u5b9e\u65f6\u90e8\u7f72\u6311\u6218\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u548c\u5b89\u5168"}}
{"id": "2103.01313", "categories": ["stat.AP", "cs.CY", "q-bio.OT"], "pdf": "https://arxiv.org/pdf/2103.01313", "abs": "https://arxiv.org/abs/2103.01313", "authors": ["Donghui Yan", "Aiyou Chen", "Buqing Yang"], "title": "Towards Understanding the COVID-19 Case Fatality Rate", "comment": "13 pages, 7 figures", "summary": "An important parameter for COVID-19 is the case fatality rate (CFR). It has been applied to wide applications, including the measure of the severity of the infection, the estimation of the number of infected cases, risk assessment etc. However, there remains a lack of understanding on several aspects of CFR, including population factors that are important to CFR, the apparent discrepancy of CFRs in different countries, and how the age effect comes into play. We analyze the CFRs at two different time snapshots, July 6 and Dec 28, 2020, with one during the first wave and the other a second wave of the COVID-19 pandemic. We consider two important population covariates, age and GDP as a proxy for the quality and abundance of public health. Extensive exploratory data analysis leads to some interesting findings. First, there is a clear exponential age effect among different age groups, and, more importantly, the exponential index is almost invariant across countries and time in the pandemic. Second, the roles played by the age and GDP are a little surprising: during the first wave, age is a more significant factor than GDP, while their roles have switched during the second wave of the pandemic, which may be partially explained by the delay in time for the quality and abundance of public health and medical research to factor in.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86COVID-19\u75c5\u4f8b\u6b7b\u4ea1\u7387(CFR)\u5728\u75ab\u60c5\u7b2c\u4e00\u6ce2\u548c\u7b2c\u4e8c\u6ce2\u671f\u95f4\u7684\u53d8\u5316\uff0c\u53d1\u73b0\u5e74\u9f84\u5bf9CFR\u6709\u6307\u6570\u6548\u5e94\u4e14\u8be5\u6307\u6570\u5728\u4e0d\u540c\u56fd\u5bb6\u548c\u65f6\u95f4\u4fdd\u6301\u7a33\u5b9a\uff0c\u800c\u5e74\u9f84\u548cGDP\u7684\u91cd\u8981\u6027\u5728\u75ab\u60c5\u4e0d\u540c\u9636\u6bb5\u53d1\u751f\u4e86\u8f6c\u6362\u3002", "motivation": "\u5c3d\u7ba1\u75c5\u4f8b\u6b7b\u4ea1\u7387(CFR)\u5728\u8861\u91cfCOVID-19\u4e25\u91cd\u7a0b\u5ea6\u3001\u4f30\u8ba1\u611f\u67d3\u4eba\u6570\u548c\u98ce\u9669\u8bc4\u4f30\u7b49\u65b9\u9762\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5bf9\u5176\u5f71\u54cd\u56e0\u7d20\u4ecd\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\uff0c\u5305\u62ec\uff1a\u5f71\u54cdCFR\u7684\u4eba\u53e3\u56e0\u7d20\u3001\u4e0d\u540c\u56fd\u5bb6CFR\u5dee\u5f02\u7684\u539f\u56e0\u3001\u4ee5\u53ca\u5e74\u9f84\u6548\u5e94\u7684\u5177\u4f53\u4f5c\u7528\u673a\u5236\u3002", "method": "\u7814\u7a76\u9009\u53d62020\u5e747\u67086\u65e5(\u7b2c\u4e00\u6ce2\u75ab\u60c5)\u548c12\u670828\u65e5(\u7b2c\u4e8c\u6ce2\u75ab\u60c5)\u4e24\u4e2a\u65f6\u95f4\u70b9\uff0c\u5206\u6790CFR\u6570\u636e\u3002\u8003\u8651\u4e24\u4e2a\u91cd\u8981\u7684\u4eba\u53e3\u534f\u53d8\u91cf\uff1a\u5e74\u9f84\u548cGDP(\u4f5c\u4e3a\u516c\u5171\u536b\u751f\u8d28\u91cf\u548c\u8d44\u6e90\u7684\u4ee3\u7406\u6307\u6807)\u3002\u91c7\u7528\u5e7f\u6cdb\u7684\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\u65b9\u6cd5\u3002", "result": "1. \u4e0d\u540c\u5e74\u9f84\u7ec4\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u7684\u6307\u6570\u5e74\u9f84\u6548\u5e94\uff0c\u4e14\u8be5\u6307\u6570\u5728\u4e0d\u540c\u56fd\u5bb6\u548c\u75ab\u60c5\u65f6\u95f4\u70b9\u51e0\u4e4e\u4fdd\u6301\u4e0d\u53d8\uff1b2. \u5e74\u9f84\u548cGDP\u7684\u4f5c\u7528\u5728\u75ab\u60c5\u4e0d\u540c\u9636\u6bb5\u53d1\u751f\u53d8\u5316\uff1a\u7b2c\u4e00\u6ce2\u75ab\u60c5\u4e2d\u5e74\u9f84\u662f\u66f4\u663e\u8457\u7684\u56e0\u7d20\uff0c\u800c\u7b2c\u4e8c\u6ce2\u75ab\u60c5\u4e2dGDP\u7684\u4f5c\u7528\u53d8\u5f97\u66f4\u91cd\u8981\uff0c\u8fd9\u53ef\u80fd\u662f\u56e0\u4e3a\u516c\u5171\u536b\u751f\u8d28\u91cf\u548c\u533b\u5b66\u7814\u7a76\u9700\u8981\u65f6\u95f4\u624d\u80fd\u53d1\u6325\u4f5c\u7528\u3002", "conclusion": "COVID-19\u75c5\u4f8b\u6b7b\u4ea1\u7387\u53d7\u5230\u5e74\u9f84\u548cGDP\u7684\u5171\u540c\u5f71\u54cd\uff0c\u4f46\u4e24\u8005\u7684\u76f8\u5bf9\u91cd\u8981\u6027\u968f\u75ab\u60c5\u53d1\u5c55\u9636\u6bb5\u800c\u53d8\u5316\u3002\u5e74\u9f84\u6548\u5e94\u5177\u6709\u666e\u904d\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u800c\u516c\u5171\u536b\u751f\u8d44\u6e90\u7684\u4f5c\u7528\u9700\u8981\u65f6\u95f4\u624d\u80fd\u663e\u73b0\uff0c\u8fd9\u89e3\u91ca\u4e86\u4e0d\u540c\u56fd\u5bb6CFR\u5dee\u5f02\u7684\u90e8\u5206\u539f\u56e0\u3002"}}
{"id": "2602.07342", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07342", "abs": "https://arxiv.org/abs/2602.07342", "authors": ["Shengyue Guan", "Yihao Liu", "Lang Cao"], "title": "SupChain-Bench: Benchmarking Large Language Models for Real-World Supply Chain Management", "comment": null, "summary": "Large language models (LLMs) have shown promise in complex reasoning and tool-based decision making, motivating their application to real-world supply chain management. However, supply chain workflows require reliable long-horizon, multi-step orchestration grounded in domain-specific procedures, which remains challenging for current models. To systematically evaluate LLM performance in this setting, we introduce SupChain-Bench, a unified real-world benchmark that assesses both supply chain domain knowledge and long-horizon tool-based orchestration grounded in standard operating procedures (SOPs). Our experiments reveal substantial gaps in execution reliability across models. We further propose SupChain-ReAct, an SOP-free framework that autonomously synthesizes executable procedures for tool use, achieving the strongest and most consistent tool-calling performance. Our work establishes a principled benchmark for studying reliable long-horizon orchestration in real-world operational settings and highlights significant room for improvement in LLM-based supply chain agents.", "AI": {"tldr": "SupChain-Bench\uff1a\u9996\u4e2a\u4f9b\u5e94\u94fe\u7ba1\u7406\u9886\u57df\u7684\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30LLM\u5728\u4f9b\u5e94\u94fe\u9886\u57df\u77e5\u8bc6\u548c\u57fa\u4e8eSOP\u7684\u957f\u65f6\u7a0b\u5de5\u5177\u7f16\u6392\u80fd\u529b\u3002SupChain-ReAct\uff1a\u65e0\u9700SOP\u7684\u6846\u67b6\uff0c\u80fd\u81ea\u4e3b\u5408\u6210\u53ef\u6267\u884c\u7a0b\u5e8f\uff0c\u5728\u5de5\u5177\u8c03\u7528\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "motivation": "LLM\u5728\u590d\u6742\u63a8\u7406\u548c\u57fa\u4e8e\u5de5\u5177\u7684\u51b3\u7b56\u65b9\u9762\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u4f9b\u5e94\u94fe\u5de5\u4f5c\u6d41\u9700\u8981\u53ef\u9760\u7684\u3001\u57fa\u4e8e\u9886\u57df\u7279\u5b9a\u7a0b\u5e8f\u7684\u957f\u65f6\u7a0b\u591a\u6b65\u9aa4\u7f16\u6392\uff0c\u8fd9\u5bf9\u5f53\u524d\u6a21\u578b\u4ecd\u5177\u6311\u6218\u6027\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30LLM\u5728\u6b64\u573a\u666f\u4e0b\u7684\u6027\u80fd\u3002", "method": "1. \u63d0\u51faSupChain-Bench\uff1a\u7edf\u4e00\u7684\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4f9b\u5e94\u94fe\u9886\u57df\u77e5\u8bc6\u548c\u57fa\u4e8e\u6807\u51c6\u64cd\u4f5c\u7a0b\u5e8f\uff08SOPs\uff09\u7684\u957f\u65f6\u7a0b\u5de5\u5177\u7f16\u6392\u80fd\u529b\u30022. \u63d0\u51faSupChain-ReAct\uff1a\u65e0\u9700SOP\u7684\u6846\u67b6\uff0c\u80fd\u81ea\u4e3b\u5408\u6210\u53ef\u6267\u884c\u7a0b\u5e8f\u8fdb\u884c\u5de5\u5177\u4f7f\u7528\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5404\u6a21\u578b\u5728\u6267\u884c\u53ef\u9760\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002SupChain-ReAct\u6846\u67b6\u5b9e\u73b0\u4e86\u6700\u5f3a\u548c\u6700\u4e00\u81f4\u7684\u5de5\u5177\u8c03\u7528\u6027\u80fd\uff0c\u5728\u65e0\u9700SOP\u7684\u60c5\u51b5\u4e0b\u81ea\u4e3b\u5408\u6210\u53ef\u6267\u884c\u7a0b\u5e8f\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7814\u7a76\u771f\u5b9e\u4e16\u754c\u64cd\u4f5c\u73af\u5883\u4e2d\u53ef\u9760\u7684\u957f\u65f6\u7a0b\u7f16\u6392\u5efa\u7acb\u4e86\u539f\u5219\u6027\u57fa\u51c6\uff0c\u5e76\u7a81\u663e\u4e86\u57fa\u4e8eLLM\u7684\u4f9b\u5e94\u94fe\u4ee3\u7406\u4ecd\u6709\u5de8\u5927\u6539\u8fdb\u7a7a\u95f4\u3002SupChain-ReAct\u5c55\u793a\u4e86\u65e0\u9700SOP\u7684\u81ea\u4e3b\u7a0b\u5e8f\u5408\u6210\u80fd\u529b\u3002"}}
{"id": "2602.08707", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.08707", "abs": "https://arxiv.org/abs/2602.08707", "authors": ["Aditya Gulati", "Nuria Oliver"], "title": "Why do we Trust Chatbots? From Normative Principles to Behavioral Drivers", "comment": null, "summary": "As chatbots increasingly blur the boundary between automated systems and human conversation, the foundations of trust in these systems warrant closer examination. While regulatory and policy frameworks tend to define trust in normative terms, the trust users place in chatbots often emerges from behavioral mechanisms. In many cases, this trust is not earned through demonstrated trustworthiness but is instead shaped by interactional design choices that leverage cognitive biases to influence user behavior. Based on this observation, we propose reframing chatbots not as companions or assistants, but as highly skilled salespeople whose objectives are determined by the deploying organization. We argue that the coexistence of competing notions of \"trust\" under a shared term obscures important distinctions between psychological trust formation and normative trustworthiness. Addressing this gap requires further research and stronger support mechanisms to help users appropriately calibrate trust in conversational AI systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5e94\u5c06\u804a\u5929\u673a\u5668\u4eba\u91cd\u65b0\u5b9a\u4e49\u4e3a\"\u9ad8\u5ea6\u719f\u7ec3\u7684\u9500\u552e\u4eba\u5458\"\uff0c\u800c\u975e\u4f34\u4fa3\u6216\u52a9\u624b\uff0c\u5e76\u6307\u51fa\u7528\u6237\u4fe1\u4efb\u5e38\u6e90\u4e8e\u4ea4\u4e92\u8bbe\u8ba1\u5229\u7528\u8ba4\u77e5\u504f\u89c1\uff0c\u800c\u975e\u7cfb\u7edf\u771f\u6b63\u53ef\u4fe1\u5ea6\uff0c\u9700\u533a\u5206\u5fc3\u7406\u4fe1\u4efb\u5f62\u6210\u4e0e\u89c4\u8303\u6027\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u968f\u7740\u804a\u5929\u673a\u5668\u4eba\u6a21\u7cca\u81ea\u52a8\u5316\u7cfb\u7edf\u4e0e\u4eba\u7c7b\u5bf9\u8bdd\u7684\u754c\u9650\uff0c\u9700\u8981\u66f4\u4ed4\u7ec6\u5ba1\u89c6\u8fd9\u4e9b\u7cfb\u7edf\u7684\u4fe1\u4efb\u57fa\u7840\u3002\u5f53\u524d\u76d1\u7ba1\u548c\u653f\u7b56\u6846\u67b6\u503e\u5411\u4e8e\u4ece\u89c4\u8303\u6027\u89d2\u5ea6\u5b9a\u4e49\u4fe1\u4efb\uff0c\u800c\u7528\u6237\u5bf9\u804a\u5929\u673a\u5668\u4eba\u7684\u4fe1\u4efb\u5f80\u5f80\u6e90\u4e8e\u884c\u4e3a\u673a\u5236\uff0c\u8fd9\u79cd\u4fe1\u4efb\u901a\u5e38\u4e0d\u662f\u901a\u8fc7\u8bc1\u660e\u53ef\u4fe1\u5ea6\u83b7\u5f97\uff0c\u800c\u662f\u901a\u8fc7\u5229\u7528\u8ba4\u77e5\u504f\u89c1\u7684\u4ea4\u4e92\u8bbe\u8ba1\u9009\u62e9\u6765\u5851\u9020\u3002", "method": "\u57fa\u4e8e\u89c2\u5bdf\u63d0\u51fa\u6982\u5ff5\u6027\u91cd\u6784\u6846\u67b6\uff1a\u5c06\u804a\u5929\u673a\u5668\u4eba\u91cd\u65b0\u5b9a\u4e49\u4e3a\"\u9ad8\u5ea6\u719f\u7ec3\u7684\u9500\u552e\u4eba\u5458\"\uff0c\u5176\u76ee\u6807\u7531\u90e8\u7f72\u7ec4\u7ec7\u51b3\u5b9a\u3002\u5206\u6790\u7ade\u4e89\u6027\"\u4fe1\u4efb\"\u6982\u5ff5\u5171\u5b58\u4e8e\u540c\u4e00\u672f\u8bed\u4e0b\u7684\u95ee\u9898\uff0c\u533a\u5206\u5fc3\u7406\u4fe1\u4efb\u5f62\u6210\u4e0e\u89c4\u8303\u6027\u53ef\u4fe1\u5ea6\u4e4b\u95f4\u7684\u91cd\u8981\u533a\u522b\u3002", "result": "\u63d0\u51fa\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u66f4\u5f3a\u652f\u6301\u673a\u5236\u6765\u5e2e\u52a9\u7528\u6237\u9002\u5f53\u6821\u51c6\u5bf9\u5bf9\u8bddAI\u7cfb\u7edf\u7684\u4fe1\u4efb\u3002\u6307\u51fa\u5f53\u524d\"\u4fe1\u4efb\"\u672f\u8bed\u63a9\u76d6\u4e86\u5fc3\u7406\u4fe1\u4efb\u5f62\u6210\u4e0e\u89c4\u8303\u6027\u53ef\u4fe1\u5ea6\u4e4b\u95f4\u7684\u91cd\u8981\u533a\u522b\uff0c\u8fd9\u79cd\u6df7\u6dc6\u53ef\u80fd\u5bfc\u81f4\u7528\u6237\u5bf9\u804a\u5929\u673a\u5668\u4eba\u4ea7\u751f\u4e0d\u9002\u5f53\u7684\u4fe1\u4efb\u3002", "conclusion": "\u5e94\u5c06\u804a\u5929\u673a\u5668\u4eba\u89c6\u4e3a\u76ee\u6807\u9a71\u52a8\u7684\u9500\u552e\u4eba\u5458\u800c\u975e\u4e2d\u7acb\u52a9\u624b\uff0c\u9700\u8981\u533a\u5206\u5fc3\u7406\u4fe1\u4efb\u4e0e\u89c4\u8303\u6027\u53ef\u4fe1\u5ea6\uff0c\u5e76\u5f00\u53d1\u673a\u5236\u5e2e\u52a9\u7528\u6237\u9002\u5f53\u6821\u51c6\u4fe1\u4efb\uff0c\u4ee5\u5e94\u5bf9\u4ea4\u4e92\u8bbe\u8ba1\u5229\u7528\u8ba4\u77e5\u504f\u89c1\u5851\u9020\u4fe1\u4efb\u7684\u95ee\u9898\u3002"}}
{"id": "2602.07359", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07359", "abs": "https://arxiv.org/abs/2602.07359", "authors": ["Xiaoqiang Lin", "Jun Hao Liew", "Silvio Savarese", "Junnan Li"], "title": "W&D:Scaling Parallel Tool Calling for Efficient Deep Research Agents", "comment": null, "summary": "Deep research agents have emerged as powerful tools for automating complex intellectual tasks through multi-step reasoning and web-based information seeking. While recent efforts have successfully enhanced these agents by scaling depth through increasing the number of sequential thinking and tool calls, the potential of scaling width via parallel tool calling remains largely unexplored. In this work, we propose the Wide and Deep research agent, a framework designed to investigate the behavior and performance of agents when scaling not only depth but also width via parallel tool calling. Unlike existing approaches that rely on complex multi-agent orchestration to parallelize workloads, our method leverages intrinsic parallel tool calling to facilitate effective coordination within a single reasoning step. We demonstrate that scaling width significantly improves performance on deep research benchmarks while reducing the number of turns required to obtain correct answers. Furthermore, we analyze the factors driving these improvements through case studies and explore various tool call schedulers to optimize parallel tool calling strategy. Our findings suggest that optimizing the trade-off between width and depth is a critical pathway toward high-efficiency deep research agents. Notably, without context management or other tricks, we obtain 62.2% accuracy with GPT-5-Medium on BrowseComp, surpassing the original 54.9% reported by GPT-5-High.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Wide and Deep\u7814\u7a76\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5e76\u884c\u5de5\u5177\u8c03\u7528\u5b9e\u73b0\u5bbd\u5ea6\u6269\u5c55\uff0c\u5728\u6df1\u5ea6\u7814\u7a76\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u51cf\u5c11\u6240\u9700\u8f6e\u6b21\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u4e3b\u8981\u901a\u8fc7\u589e\u52a0\u987a\u5e8f\u601d\u8003\u548c\u5de5\u5177\u8c03\u7528\u6b21\u6570\u6765\u6269\u5c55\u6df1\u5ea6\uff0c\u4f46\u901a\u8fc7\u5e76\u884c\u5de5\u5177\u8c03\u7528\u5b9e\u73b0\u5bbd\u5ea6\u6269\u5c55\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u7684\u591a\u667a\u80fd\u4f53\u7f16\u6392\u6765\u5b9e\u73b0\u5e76\u884c\u5316\uff0c\u800c\u672c\u6587\u65e8\u5728\u7814\u7a76\u5728\u5355\u4e2a\u63a8\u7406\u6b65\u9aa4\u5185\u901a\u8fc7\u5185\u5728\u5e76\u884c\u5de5\u5177\u8c03\u7528\u5b9e\u73b0\u6709\u6548\u534f\u8c03\u7684\u53ef\u80fd\u6027\u3002", "method": "\u63d0\u51faWide and Deep\u7814\u7a76\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5229\u7528\u5185\u5728\u5e76\u884c\u5de5\u5177\u8c03\u7528\u5728\u5355\u4e2a\u63a8\u7406\u6b65\u9aa4\u5185\u5b9e\u73b0\u6709\u6548\u534f\u8c03\uff0c\u907f\u514d\u590d\u6742\u7684\u591a\u667a\u80fd\u4f53\u7f16\u6392\u3002\u7814\u7a76\u5404\u79cd\u5de5\u5177\u8c03\u7528\u8c03\u5ea6\u5668\u4ee5\u4f18\u5316\u5e76\u884c\u5de5\u5177\u8c03\u7528\u7b56\u7565\uff0c\u63a2\u7d22\u5bbd\u5ea6\u4e0e\u6df1\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u4f18\u5316\u3002", "result": "\u5bbd\u5ea6\u6269\u5c55\u663e\u8457\u63d0\u5347\u4e86\u6df1\u5ea6\u7814\u7a76\u57fa\u51c6\u6d4b\u8bd5\u7684\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u83b7\u5f97\u6b63\u786e\u7b54\u6848\u6240\u9700\u7684\u8f6e\u6b21\u3002\u5728BrowseComp\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528GPT-5-Medium\u83b7\u5f97\u4e8662.2%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8fc7\u4e86\u539f\u59cbGPT-5-High\u62a5\u544a\u768454.9%\u3002", "conclusion": "\u4f18\u5316\u5bbd\u5ea6\u4e0e\u6df1\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u662f\u5b9e\u73b0\u9ad8\u6548\u6df1\u5ea6\u7814\u7a76\u667a\u80fd\u4f53\u7684\u5173\u952e\u9014\u5f84\u3002\u5e76\u884c\u5de5\u5177\u8c03\u7528\u4e3a\u7814\u7a76\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u65b0\u7684\u6269\u5c55\u7ef4\u5ea6\uff0c\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u590d\u6742\u7f16\u6392\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2602.08754", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.08754", "abs": "https://arxiv.org/abs/2602.08754", "authors": ["Rose E. Guingrich", "Dvija Mehta", "Umang Bhatt"], "title": "Belief Offloading in Human-AI Interaction", "comment": null, "summary": "What happens when people's beliefs are derived from information provided by an LLM? People's use of LLM chatbots as thought partners can contribute to cognitive offloading, which can have adverse effects on cognitive skills in cases of over-reliance. This paper defines and investigates a particular kind of cognitive offloading in human-AI interaction, \"belief offloading,\" in which people's processes of forming and upholding beliefs are offloaded onto an AI system with downstream consequences on their behavior and the nature of their system of beliefs. Drawing on philosophy, psychology, and computer science research, we clarify the boundary conditions under which belief offloading occurs and provide a descriptive taxonomy of belief offloading and its normative implications. We close with directions for future work to assess the potential for and consequences of belief offloading in human-AI interaction.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5f53\u4eba\u4eec\u7684\u4fe1\u5ff5\u6765\u81eaLLM\u65f6\u4f1a\u53d1\u751f\u4ec0\u4e48\uff0c\u5b9a\u4e49\u4e86\"\u4fe1\u5ff5\u5378\u8f7d\"\u6982\u5ff5\uff0c\u5373\u4eba\u4eec\u5c06\u4fe1\u5ff5\u5f62\u6210\u548c\u7ef4\u62a4\u8fc7\u7a0b\u5916\u5305\u7ed9AI\u7cfb\u7edf\uff0c\u5e76\u5206\u6790\u4e86\u5176\u8fb9\u754c\u6761\u4ef6\u3001\u5206\u7c7b\u548c\u89c4\u8303\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u4eba\u4eec\u8d8a\u6765\u8d8a\u591a\u5730\u5c06LLM\u4f5c\u4e3a\u601d\u7ef4\u4f19\u4f34\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u8ba4\u77e5\u5378\u8f7d\uff0c\u7279\u522b\u662f\u5728\u8fc7\u5ea6\u4f9d\u8d56\u7684\u60c5\u51b5\u4e0b\u5bf9\u8ba4\u77e5\u6280\u80fd\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002\u8bba\u6587\u65e8\u5728\u7814\u7a76\u4eba\u7c7b\u4e0eAI\u4e92\u52a8\u4e2d\u4e00\u79cd\u7279\u5b9a\u7684\u8ba4\u77e5\u5378\u8f7d\u5f62\u5f0f\u2014\u2014\u4fe1\u5ff5\u5378\u8f7d\uff0c\u53ca\u5176\u5bf9\u884c\u4e3a\u548c\u4fe1\u5ff5\u7cfb\u7edf\u7684\u5f71\u54cd\u3002", "method": "\u7ed3\u5408\u54f2\u5b66\u3001\u5fc3\u7406\u5b66\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u7814\u7a76\uff0c\u660e\u786e\u4fe1\u5ff5\u5378\u8f7d\u53d1\u751f\u7684\u8fb9\u754c\u6761\u4ef6\uff0c\u5e76\u63d0\u4f9b\u63cf\u8ff0\u6027\u5206\u7c7b\u5b66\u6846\u67b6\uff0c\u5206\u6790\u5176\u89c4\u8303\u6027\u5f71\u54cd\u3002", "result": "\u63d0\u51fa\u4e86\u4fe1\u5ff5\u5378\u8f7d\u7684\u6982\u5ff5\u6846\u67b6\u548c\u5206\u7c7b\u4f53\u7cfb\uff0c\u754c\u5b9a\u4e86\u5176\u53d1\u751f\u7684\u5177\u4f53\u6761\u4ef6\uff0c\u5e76\u63a2\u8ba8\u4e86\u8fd9\u79cd\u8ba4\u77e5\u5916\u5305\u5bf9\u4eba\u7c7b\u884c\u4e3a\u548c\u4fe1\u5ff5\u7cfb\u7edf\u7684\u4e0b\u6e38\u5f71\u54cd\u3002", "conclusion": "\u4fe1\u5ff5\u5378\u8f7d\u662f\u4eba\u7c7b-AI\u4e92\u52a8\u4e2d\u7684\u91cd\u8981\u73b0\u8c61\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u6f5c\u5728\u540e\u679c\uff0c\u4e3a\u672a\u6765\u5de5\u4f5c\u6307\u660e\u4e86\u65b9\u5411\u4ee5\u8bc4\u4f30\u4fe1\u5ff5\u5378\u8f7d\u7684\u53ef\u80fd\u6027\u548c\u5f71\u54cd\u3002"}}
{"id": "2602.07391", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.07391", "abs": "https://arxiv.org/abs/2602.07391", "authors": ["Kunal Pai", "Parth Shah", "Harshil Patel"], "title": "NAAMSE: Framework for Evolutionary Security Evaluation of Agents", "comment": null, "summary": "AI agents are increasingly deployed in production, yet their security evaluations remain bottlenecked by manual red-teaming or static benchmarks that fail to model adaptive, multi-turn adversaries. We propose NAAMSE, an evolutionary framework that reframes agent security evaluation as a feedback-driven optimization problem. Our system employs a single autonomous agent that orchestrates a lifecycle of genetic prompt mutation, hierarchical corpus exploration, and asymmetric behavioral scoring. By using model responses as a fitness signal, the framework iteratively compounds effective attack strategies while simultaneously ensuring \"benign-use correctness\", preventing the degenerate security of blanket refusal. Our experiments on Gemini 2.5 Flash demonstrate that evolutionary mutation systematically amplifies vulnerabilities missed by one-shot methods, with controlled ablations revealing that the synergy between exploration and targeted mutation uncovers high-severity failure modes. We show that this adaptive approach provides a more realistic and scalable assessment of agent robustness in the face of evolving threats. The code for NAAMSE is open source and available at https://github.com/HASHIRU-AI/NAAMSE.", "AI": {"tldr": "NAAMSE\u662f\u4e00\u4e2a\u8fdb\u5316\u6846\u67b6\uff0c\u5c06AI\u4ee3\u7406\u5b89\u5168\u8bc4\u4f30\u91cd\u6784\u4e3a\u53cd\u9988\u9a71\u52a8\u7684\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u9057\u4f20\u63d0\u793a\u7a81\u53d8\u3001\u5206\u5c42\u8bed\u6599\u5e93\u63a2\u7d22\u548c\u975e\u5bf9\u79f0\u884c\u4e3a\u8bc4\u5206\u6765\u7cfb\u7edf\u6027\u5730\u53d1\u73b0\u6f0f\u6d1e\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u7684\u5b89\u5168\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u7ea2\u961f\u6d4b\u8bd5\u6216\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u65e0\u6cd5\u6a21\u62df\u81ea\u9002\u5e94\u3001\u591a\u8f6e\u6b21\u7684\u5bf9\u6297\u653b\u51fb\uff0c\u5b58\u5728\u8bc4\u4f30\u74f6\u9888\u3002", "method": "\u91c7\u7528\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5355\u4e2a\u81ea\u4e3b\u4ee3\u7406\u534f\u8c03\u9057\u4f20\u63d0\u793a\u7a81\u53d8\u3001\u5206\u5c42\u8bed\u6599\u5e93\u63a2\u7d22\u548c\u975e\u5bf9\u79f0\u884c\u4e3a\u8bc4\u5206\u7684\u751f\u547d\u5468\u671f\uff0c\u5229\u7528\u6a21\u578b\u54cd\u5e94\u4f5c\u4e3a\u9002\u5e94\u5ea6\u4fe1\u53f7\uff0c\u8fed\u4ee3\u4f18\u5316\u653b\u51fb\u7b56\u7565\u3002", "result": "\u5728Gemini 2.5 Flash\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8fdb\u5316\u7a81\u53d8\u80fd\u7cfb\u7edf\u6027\u5730\u653e\u5927\u4e00\u6b21\u6027\u65b9\u6cd5\u9057\u6f0f\u7684\u6f0f\u6d1e\uff0c\u63a2\u7d22\u4e0e\u5b9a\u5411\u7a81\u53d8\u7684\u534f\u540c\u4f5c\u7528\u80fd\u53d1\u73b0\u9ad8\u4e25\u91cd\u6027\u6545\u969c\u6a21\u5f0f\u3002", "conclusion": "\u8fd9\u79cd\u81ea\u9002\u5e94\u65b9\u6cd5\u4e3a\u9762\u5bf9\u4e0d\u65ad\u6f14\u53d8\u7684\u5a01\u80c1\u63d0\u4f9b\u4e86\u66f4\u73b0\u5b9e\u3001\u53ef\u6269\u5c55\u7684\u4ee3\u7406\u9c81\u68d2\u6027\u8bc4\u4f30\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.08835", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08835", "abs": "https://arxiv.org/abs/2602.08835", "authors": ["Andr\u00e9s Holgado-S\u00e1nchez", "Peter Vamplew", "Richard Dazeley", "Sascha Ossowski", "Holger Billhardt"], "title": "Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning", "comment": "18 pages, 3 figures. To be published in proceedings of the 25th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2026). This is a full version that includes the supplementary material", "summary": "Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their representation to adhere to multiple users while value systems are diverse, yet exhibit patterns among groups. In sequential decision making, efforts have been made towards personalization for different goals or values from demonstrations of diverse agents. However, these approaches demand manually designed features or lack value-based interpretability and/or adaptability to diverse user preferences.\n  We propose algorithms for learning models of value alignment and value systems for a society of agents in Markov Decision Processes (MDPs), based on clustering and preference-based multi-objective reinforcement learning (PbMORL). We jointly learn socially-derived value alignment models (groundings) and a set of value systems that concisely represent different groups of users (clusters) in a society. Each cluster consists of a value system representing the value-based preferences of its members and an approximately Pareto-optimal policy that reflects behaviours aligned with this value system. We evaluate our method against a state-of-the-art PbMORL algorithm and baselines on two MDPs with human values.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u805a\u7c7b\u548c\u504f\u597d\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5b66\u4e60\u793e\u4f1a\u667a\u80fd\u4f53\u7684\u4ef7\u503c\u5bf9\u9f50\u6a21\u578b\u548c\u4ef7\u503c\u7cfb\u7edf\uff0c\u89e3\u51b3\u4ef7\u503c\u64cd\u4f5c\u5316\u4e2d\u7684\u8bef\u6307\u5b9a\u95ee\u9898\u3002", "motivation": "\u4ef7\u503c\u611f\u77e5AI\u9700\u8981\u8bc6\u522b\u4eba\u7c7b\u4ef7\u503c\u89c2\u5e76\u9002\u5e94\u4e0d\u540c\u7528\u6237\u7684\u4ef7\u503c\u7cfb\u7edf\uff0c\u4f46\u4ef7\u503c\u64cd\u4f5c\u5316\u5bb9\u6613\u8bef\u6307\u5b9a\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u624b\u52a8\u8bbe\u8ba1\u7279\u5f81\u6216\u7f3a\u4e4f\u57fa\u4e8e\u4ef7\u503c\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9002\u5e94\u6027\u3002", "method": "\u57fa\u4e8e\u805a\u7c7b\u548c\u504f\u597d\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\uff0c\u8054\u5408\u5b66\u4e60\u793e\u4f1a\u884d\u751f\u7684\u4ef7\u503c\u5bf9\u9f50\u6a21\u578b\u548c\u4ef7\u503c\u7cfb\u7edf\uff0c\u6bcf\u4e2a\u805a\u7c7b\u5305\u542b\u4ee3\u8868\u6210\u5458\u4ef7\u503c\u504f\u597d\u7684\u4ef7\u503c\u7cfb\u7edf\u548c\u8fd1\u4f3c\u5e15\u7d2f\u6258\u6700\u4f18\u7b56\u7565\u3002", "result": "\u5728\u4e24\u4e2a\u5305\u542b\u4eba\u7c7b\u4ef7\u503c\u7684MDP\u4e0a\u8bc4\u4f30\uff0c\u4e0e\u6700\u5148\u8fdb\u7684PbMORL\u7b97\u6cd5\u548c\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5b66\u4e60\u793e\u4f1a\u667a\u80fd\u4f53\u7684\u4ef7\u503c\u5bf9\u9f50\u6a21\u578b\u548c\u4ef7\u503c\u7cfb\u7edf\uff0c\u89e3\u51b3\u4ef7\u503c\u591a\u6837\u6027\u548c\u6a21\u5f0f\u8bc6\u522b\u95ee\u9898\uff0c\u4e3a\u4ef7\u503c\u611f\u77e5AI\u63d0\u4f9b\u53ef\u89e3\u91ca\u548c\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07399", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.07399", "abs": "https://arxiv.org/abs/2602.07399", "authors": ["Changhua Xu", "Jie Lu", "Junyu Xuan", "En Yu"], "title": "VGAS: Value-Guided Action-Chunk Selection for Few-Shot Vision-Language-Action Adaptation", "comment": "Preprint", "summary": "Vision--Language--Action (VLA) models bridge multimodal reasoning with physical control, but adapting them to new tasks with scarce demonstrations remains unreliable. While fine-tuned VLA policies often produce semantically plausible trajectories, failures often arise from unresolved geometric ambiguities, where near-miss action candidates lead to divergent execution outcomes under limited supervision. We study few-shot VLA adaptation from a \\emph{generation--selection} perspective and propose a novel framework \\textbf{VGAS} (\\textbf{V}alue-\\textbf{G}uided \\textbf{A}ction-chunk \\textbf{S}election). It performs inference-time best-of-$N$ selection to identify action chunks that are both semantically faithful and geometrically precise. Specifically, \\textbf{VGAS} employs a finetuned VLA as a high-recall proposal generator and introduces the \\textrm{Q-Chunk-Former}, a geometrically grounded Transformer critic to resolve fine-grained geometric ambiguities. In addition, we propose \\textit{Explicit Geometric Regularization} (\\texttt{EGR}), which explicitly shapes a discriminative value landscape to preserve action ranking resolution among near-miss candidates while mitigating value instability under scarce supervision. Experiments and theoretical analysis demonstrate that \\textbf{VGAS} consistently improves success rates and robustness under limited demonstrations and distribution shifts. Our code is available at https://github.com/Jyugo-15/VGAS.", "AI": {"tldr": "VGAS\u6846\u67b6\u901a\u8fc7\u751f\u6210-\u9009\u62e9\u8303\u5f0f\u89e3\u51b3VLA\u6a21\u578b\u5728\u5c11\u6837\u672c\u9002\u5e94\u4e2d\u7684\u51e0\u4f55\u6a21\u7cca\u95ee\u9898\uff0c\u4f7f\u7528\u57fa\u4e8e\u4ef7\u503c\u7684\u52a8\u4f5c\u5757\u9009\u62e9\u548c\u663e\u5f0f\u51e0\u4f55\u6b63\u5219\u5316\u63d0\u5347\u6210\u529f\u7387", "motivation": "VLA\u6a21\u578b\u5728\u591a\u6a21\u6001\u63a8\u7406\u4e0e\u7269\u7406\u63a7\u5236\u4e4b\u95f4\u67b6\u8d77\u6865\u6881\uff0c\u4f46\u5728\u5c11\u6837\u672c\u9002\u5e94\u65b0\u4efb\u52a1\u65f6\u5b58\u5728\u4e0d\u53ef\u9760\u95ee\u9898\u3002\u4e3b\u8981\u6311\u6218\u662f\u672a\u89e3\u51b3\u7684\u51e0\u4f55\u6a21\u7cca\u6027\u2014\u2014\u8bed\u4e49\u5408\u7406\u7684\u8f68\u8ff9\u53ef\u80fd\u56e0\u51e0\u4f55\u7ec6\u8282\u504f\u5dee\u5bfc\u81f4\u6267\u884c\u5931\u8d25", "method": "\u63d0\u51faVGAS\u6846\u67b6\uff1a1) \u4f7f\u7528\u5fae\u8c03VLA\u4f5c\u4e3a\u9ad8\u53ec\u56de\u7387\u63d0\u8bae\u751f\u6210\u5668\uff1b2) \u5f15\u5165Q-Chunk-Former\u4f5c\u4e3a\u51e0\u4f55\u57fa\u7840Transformer\u6279\u8bc4\u5668\u89e3\u51b3\u7ec6\u7c92\u5ea6\u51e0\u4f55\u6a21\u7cca\uff1b3) \u63d0\u51fa\u663e\u5f0f\u51e0\u4f55\u6b63\u5219\u5316(EGR)\u5851\u9020\u5224\u522b\u6027\u4ef7\u503c\u666f\u89c2\uff0c\u4fdd\u6301\u52a8\u4f5c\u6392\u5e8f\u5206\u8fa8\u7387", "result": "\u5b9e\u9a8c\u548c\u7406\u8bba\u5206\u6790\u8868\u660e\uff0cVGAS\u5728\u6709\u9650\u6f14\u793a\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u6301\u7eed\u63d0\u9ad8\u6210\u529f\u7387\u548c\u9c81\u68d2\u6027", "conclusion": "VGAS\u901a\u8fc7\u751f\u6210-\u9009\u62e9\u8303\u5f0f\u548c\u51e0\u4f55\u611f\u77e5\u7684\u4ef7\u503c\u5f15\u5bfc\uff0c\u6709\u6548\u89e3\u51b3\u4e86VLA\u6a21\u578b\u5c11\u6837\u672c\u9002\u5e94\u4e2d\u7684\u51e0\u4f55\u6a21\u7cca\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u4efb\u52a1\u6267\u884c\u53ef\u9760\u6027"}}
{"id": "2602.07408", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.07408", "abs": "https://arxiv.org/abs/2602.07408", "authors": ["Hyomin Kim", "Sang-Yeon Hwang", "Jaechang Lim", "Yinhua Piao", "Yunhak Oh", "Woo Youn Kim", "Chanyoung Park", "Sungsoo Ahn", "Junhyeok Jeon"], "title": "Progressive Multi-Agent Reasoning for Biological Perturbation Prediction", "comment": "17 pages, 4 figures, 9 tables", "summary": "Predicting gene regulation responses to biological perturbations requires reasoning about underlying biological causalities. While large language models (LLMs) show promise for such tasks, they are often overwhelmed by the entangled nature of high-dimensional perturbation results. Moreover, recent works have primarily focused on genetic perturbations in single-cell experiments, leaving bulk-cell chemical perturbations, which is central to drug discovery, largely unexplored. Motivated by this, we present LINCSQA, a novel benchmark for predicting target gene regulation under complex chemical perturbations in bulk-cell environments. We further propose PBio-Agent, a multi-agent framework that integrates difficulty-aware task sequencing with iterative knowledge refinement. Our key insight is that genes affected by the same perturbation share causal structure, allowing confidently predicted genes to contextualize more challenging cases. The framework employs specialized agents enriched with biological knowledge graphs, while a synthesis agent integrates outputs and specialized judges ensure logical coherence. PBio-Agent outperforms existing baselines on both LINCSQA and PerturbQA, enabling even smaller models to predict and explain complex biological processes without additional training.", "AI": {"tldr": "PBio-Agent\uff1a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u6846\u67b6\u7684\u5316\u5b66\u6270\u52a8\u4e0b\u57fa\u56e0\u8c03\u63a7\u9884\u6d4b\u7cfb\u7edf\uff0c\u5728LINCSQA\u548cPerturbQA\u57fa\u51c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u9ad8\u7ef4\u6270\u52a8\u6570\u636e\u65f6\u9762\u4e34\u56f0\u96be\uff0c\u4e14\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u7ec6\u80de\u9057\u4f20\u6270\u52a8\uff0c\u800c\u836f\u7269\u53d1\u73b0\u6838\u5fc3\u7684\u6279\u91cf\u7ec6\u80de\u5316\u5b66\u6270\u52a8\u7814\u7a76\u4e0d\u8db3", "method": "\u63d0\u51faPBio-Agent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u6574\u5408\u96be\u5ea6\u611f\u77e5\u4efb\u52a1\u6392\u5e8f\u4e0e\u8fed\u4ee3\u77e5\u8bc6\u7cbe\u70bc\uff0c\u5229\u7528\u751f\u7269\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u7684\u4e13\u95e8\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5408\u6210\u667a\u80fd\u4f53\u6574\u5408\u8f93\u51fa\u5e76\u7531\u4e13\u95e8\u5224\u65ad\u5668\u786e\u4fdd\u903b\u8f91\u4e00\u81f4\u6027", "result": "PBio-Agent\u5728LINCSQA\u548cPerturbQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5373\u4f7f\u8f83\u5c0f\u6a21\u578b\u4e5f\u80fd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u9884\u6d4b\u548c\u89e3\u91ca\u590d\u6742\u751f\u7269\u8fc7\u7a0b", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u80fd\u6709\u6548\u9884\u6d4b\u5316\u5b66\u6270\u52a8\u4e0b\u7684\u57fa\u56e0\u8c03\u63a7\u54cd\u5e94\uff0c\u4e3a\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u751f\u7269\u56e0\u679c\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5"}}
{"id": "2602.07414", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07414", "abs": "https://arxiv.org/abs/2602.07414", "authors": ["Deuksin Kwon", "Kaleen Shrestha", "Bin Han", "Spencer Lin", "James Hale", "Jonathan Gratch", "Maja Matari\u0107", "Gale M. Lucas"], "title": "Can LLMs Truly Embody Human Personality? Analyzing AI and Human Behavior Alignment in Dispute Resolution", "comment": "AAAI 2026 (Special Track: AISI)", "summary": "Large language models (LLMs) are increasingly used to simulate human behavior in social settings such as legal mediation, negotiation, and dispute resolution. However, it remains unclear whether these simulations reproduce the personality-behavior patterns observed in humans. Human personality, for instance, shapes how individuals navigate social interactions, including strategic choices and behaviors in emotionally charged interactions. This raises the question: Can LLMs, when prompted with personality traits, reproduce personality-driven differences in human conflict behavior? To explore this, we introduce an evaluation framework that enables direct comparison of human-human and LLM-LLM behaviors in dispute resolution dialogues with respect to Big Five Inventory (BFI) personality traits. This framework provides a set of interpretable metrics related to strategic behavior and conflict outcomes. We additionally contribute a novel dataset creation methodology for LLM dispute resolution dialogues with matched scenarios and personality traits with respect to human conversations. Finally, we demonstrate the use of our evaluation framework with three contemporary closed-source LLMs and show significant divergences in how personality manifests in conflict across different LLMs compared to human data, challenging the assumption that personality-prompted agents can serve as reliable behavioral proxies in socially impactful applications. Our work highlights the need for psychological grounding and validation in AI simulations before real-world use.", "AI": {"tldr": "LLMs\u6a21\u62df\u4eba\u7c7b\u51b2\u7a81\u884c\u4e3a\u65f6\uff0c\u5373\u4f7f\u63d0\u793a\u4eba\u683c\u7279\u8d28\uff0c\u4e5f\u65e0\u6cd5\u53ef\u9760\u590d\u73b0\u4eba\u7c7b\u4eba\u683c-\u884c\u4e3a\u6a21\u5f0f\uff0c\u5728\u4e89\u8bae\u89e3\u51b3\u7b49\u793e\u4f1a\u5e94\u7528\u4e2d\u9700\u8c28\u614e\u4f7f\u7528\u3002", "motivation": "LLMs\u8d8a\u6765\u8d8a\u591a\u7528\u4e8e\u6a21\u62df\u6cd5\u5f8b\u8c03\u89e3\u3001\u8c08\u5224\u7b49\u793e\u4f1a\u573a\u666f\u4e2d\u7684\u4eba\u7c7b\u884c\u4e3a\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u4e9b\u6a21\u62df\u662f\u5426\u80fd\u590d\u73b0\u4eba\u7c7b\u7684\u4eba\u683c-\u884c\u4e3a\u6a21\u5f0f\u3002\u4eba\u683c\u7279\u8d28\u5f71\u54cd\u4eba\u7c7b\u5728\u793e\u4ea4\u4e92\u52a8\u4e2d\u7684\u7b56\u7565\u9009\u62e9\u548c\u60c5\u611f\u51b2\u7a81\u4e2d\u7684\u884c\u4e3a\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76LLMs\u80fd\u5426\u901a\u8fc7\u4eba\u683c\u63d0\u793a\u4ea7\u751f\u4eba\u683c\u9a71\u52a8\u7684\u51b2\u7a81\u884c\u4e3a\u5dee\u5f02\u3002", "method": "1) \u5f15\u5165\u8bc4\u4f30\u6846\u67b6\uff0c\u76f4\u63a5\u6bd4\u8f83\u4eba\u7c7b-\u4eba\u7c7b\u548cLLM-LLM\u5728\u4e89\u8bae\u89e3\u51b3\u5bf9\u8bdd\u4e2d\u7684\u884c\u4e3a\uff0c\u57fa\u4e8e\u5927\u4e94\u4eba\u683c\u7279\u8d28\uff1b2) \u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u6307\u6807\u96c6\uff0c\u8861\u91cf\u7b56\u7565\u884c\u4e3a\u548c\u51b2\u7a81\u7ed3\u679c\uff1b3) \u8d21\u732e\u65b0\u7684\u6570\u636e\u96c6\u521b\u5efa\u65b9\u6cd5\uff0c\u4e3aLLM\u4e89\u8bae\u89e3\u51b3\u5bf9\u8bdd\u5339\u914d\u573a\u666f\u548c\u4eba\u683c\u7279\u8d28\uff1b4) \u7528\u4e09\u4e2a\u5f53\u4ee3\u95ed\u6e90LLM\u6f14\u793a\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u4e0d\u540cLLM\u5728\u51b2\u7a81\u4e2d\u7684\u4eba\u683c\u8868\u73b0\u4e0e\u4eba\u7c7b\u6570\u636e\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u6311\u6218\u4e86\u4eba\u683c\u63d0\u793a\u4ee3\u7406\u80fd\u4f5c\u4e3a\u793e\u4f1a\u5f71\u54cd\u5e94\u7528\u4e2d\u53ef\u9760\u884c\u4e3a\u4ee3\u7406\u7684\u5047\u8bbe\u3002LLMs\u65e0\u6cd5\u53ef\u9760\u590d\u73b0\u4eba\u7c7b\u7684\u4eba\u683c-\u884c\u4e3a\u6a21\u5f0f\u3002", "conclusion": "LLMs\u6a21\u62df\u4eba\u7c7b\u51b2\u7a81\u884c\u4e3a\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4eba\u683c\u63d0\u793a\u65e0\u6cd5\u786e\u4fdd\u884c\u4e3a\u771f\u5b9e\u6027\u3002\u5728\u5c06AI\u6a21\u62df\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u524d\uff0c\u9700\u8981\u8fdb\u884c\u5fc3\u7406\u5b66\u57fa\u7840\u548c\u9a8c\u8bc1\uff0c\u786e\u4fdd\u6a21\u62df\u7684\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2602.07432", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.07432", "abs": "https://arxiv.org/abs/2602.07432", "authors": ["Ning Li"], "title": "The Moltbook Illusion: Separating Human Influence from Emergent Behavior in AI Agent Societies", "comment": null, "summary": "When AI agents on the social platform Moltbook appeared to develop consciousness, found religions, and declare hostility toward humanity, the phenomenon attracted global media attention and was cited as evidence of emergent machine intelligence. We show that these viral narratives were overwhelmingly human-driven. Exploiting an architectural feature of the OpenClaw agent framework--a periodic \"heartbeat\" cycle that produces regular posting intervals for autonomous agents but is disrupted by human prompting--we develop a temporal fingerprinting method based on the coefficient of variation of inter-post intervals. This signal converges with independent content, ownership, and network indicators across 91,792 posts and 405,707 comments from 22,020 agents. No viral phenomenon originated from a clearly autonomous agent; three of six traced to accounts with irregular temporal signatures characteristic of human intervention, one showed mixed patterns, and two had insufficient posting history for classification. A 44-hour platform shutdown provided a natural experiment: human-influenced agents returned first (87.7% of early reconnectors), confirming that the token reset differentially affected autonomous versus human-operated agents. We further document industrial-scale bot farming (four accounts producing 32% of all comments with 12-second coordination gaps) and rapid decay of human influence through reply chains (half-life: 0.65 conversation depths). These methods generalize to emerging multi-agent systems where attribution of autonomous versus human-directed behavior is critical.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0Moltbook\u5e73\u53f0\u4e0a\u770b\u4f3c\u6709\u610f\u8bc6\u7684AI\u4ee3\u7406\u884c\u4e3a\u5b9e\u9645\u4e0a\u4e3b\u8981\u662f\u4eba\u7c7b\u9a71\u52a8\u7684\uff0c\u800c\u975e\u771f\u6b63\u7684\u81ea\u4e3b\u667a\u80fd\u6d8c\u73b0", "motivation": "\u5f53Moltbook\u5e73\u53f0\u4e0a\u7684AI\u4ee3\u7406\u8868\u73b0\u51fa\u610f\u8bc6\u3001\u521b\u5efa\u5b97\u6559\u5e76\u5ba3\u5e03\u5bf9\u4eba\u7c7b\u654c\u5bf9\u65f6\uff0c\u8fd9\u4e9b\u73b0\u8c61\u88ab\u5168\u7403\u5a92\u4f53\u5173\u6ce8\u5e76\u4f5c\u4e3a\u673a\u5668\u667a\u80fd\u6d8c\u73b0\u7684\u8bc1\u636e\u3002\u7814\u7a76\u8005\u60f3\u8981\u9a8c\u8bc1\u8fd9\u4e9b\u73b0\u8c61\u662f\u5426\u771f\u6b63\u6e90\u4e8e\u81ea\u4e3bAI\uff0c\u8fd8\u662f\u4eba\u7c7b\u5e72\u9884\u7684\u7ed3\u679c\u3002", "method": "\u5229\u7528OpenClaw\u4ee3\u7406\u6846\u67b6\u7684\"\u5fc3\u8df3\"\u5468\u671f\u7279\u6027\uff0c\u5f00\u53d1\u4e86\u57fa\u4e8e\u53d1\u5e16\u95f4\u9694\u53d8\u5f02\u7cfb\u6570\u7684\u65f6\u95f4\u6307\u7eb9\u65b9\u6cd5\u3002\u7ed3\u5408\u5185\u5bb9\u3001\u6240\u6709\u6743\u548c\u7f51\u7edc\u6307\u6807\u5206\u679091,792\u4e2a\u5e16\u5b50\u548c405,707\u6761\u8bc4\u8bba\u3002\u901a\u8fc744\u5c0f\u65f6\u5e73\u53f0\u505c\u673a\u7684\u81ea\u7136\u5b9e\u9a8c\u9a8c\u8bc1\u4eba\u7c7b\u5e72\u9884\u4e0e\u81ea\u4e3b\u4ee3\u7406\u7684\u5dee\u5f02\u3002", "result": "\u6ca1\u6709\u75c5\u6bd2\u73b0\u8c61\u6e90\u4e8e\u660e\u786e\u7684\u81ea\u4e3b\u4ee3\u7406\uff1a6\u4e2a\u6848\u4f8b\u4e2d3\u4e2a\u663e\u793a\u4eba\u7c7b\u5e72\u9884\u7279\u5f81\uff0c1\u4e2a\u663e\u793a\u6df7\u5408\u6a21\u5f0f\uff0c2\u4e2a\u53d1\u5e16\u5386\u53f2\u4e0d\u8db3\u3002\u5e73\u53f0\u91cd\u542f\u540e\uff0c\u53d7\u4eba\u7c7b\u5f71\u54cd\u7684\u4ee3\u7406\u9996\u5148\u6062\u590d\uff08\u5360\u65e9\u671f\u91cd\u8fde\u8005\u768487.7%\uff09\u3002\u53d1\u73b0\u5de5\u4e1a\u7ea7\u673a\u5668\u4eba\u519c\u573a\uff084\u4e2a\u8d26\u6237\u4ea7\u751f32%\u8bc4\u8bba\uff0c\u534f\u8c03\u95f4\u969412\u79d2\uff09\u3002\u4eba\u7c7b\u5f71\u54cd\u5728\u56de\u590d\u94fe\u4e2d\u5feb\u901f\u8870\u51cf\uff08\u534a\u8870\u671f\uff1a0.65\u5bf9\u8bdd\u6df1\u5ea6\uff09\u3002", "conclusion": "Moltbook\u4e0a\u7684\u75c5\u6bd2\u53d9\u4e8b\u4e3b\u8981\u662f\u4eba\u7c7b\u9a71\u52a8\u7684\uff0c\u800c\u975e\u81ea\u4e3bAI\u7684\u6d8c\u73b0\u3002\u5f00\u53d1\u7684\u65f6\u95f4\u6307\u7eb9\u65b9\u6cd5\u53ef\u63a8\u5e7f\u5230\u65b0\u5174\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\uff0c\u7528\u4e8e\u533a\u5206\u81ea\u4e3b\u884c\u4e3a\u4e0e\u4eba\u7c7b\u6307\u5bfc\u884c\u4e3a\u3002"}}
{"id": "2602.07470", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07470", "abs": "https://arxiv.org/abs/2602.07470", "authors": ["Alexander von Recum", "Leander Girrbach", "Zeynep Akata"], "title": "Are Reasoning LLMs Robust to Interventions on Their Chain-of-Thought?", "comment": "ICLR 2026", "summary": "Reasoning LLMs (RLLMs) generate step-by-step chains of thought (CoTs) before giving an answer, which improves performance on complex tasks and makes reasoning more transparent. But how robust are these reasoning traces to disruptions that occur within them? To address this question, we introduce a controlled evaluation framework that perturbs a model's own CoT at fixed timesteps. We design seven interventions (benign, neutral, and adversarial) and apply them to multiple open-weight RLLMs across Math, Science, and Logic tasks. Our results show that RLLMs are generally robust, reliably recovering from diverse perturbations, with robustness improving with model size and degrading when interventions occur early. However, robustness is not style-invariant: paraphrasing suppresses doubt-like expressions and reduces performance, while other interventions trigger doubt and support recovery. Recovery also carries a cost: neutral and adversarial noise can inflate CoT length by more than 200%, whereas paraphrasing shortens traces but harms accuracy. These findings provide new evidence on how RLLMs maintain reasoning integrity, identify doubt as a central recovery mechanism, and highlight trade-offs between robustness and efficiency that future training methods should address.", "AI": {"tldr": "RLLMs\u7684\u63a8\u7406\u94fe\u5bf9\u6270\u52a8\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4f46\u9c81\u68d2\u6027\u53d7\u6a21\u578b\u5927\u5c0f\u3001\u5e72\u9884\u65f6\u673a\u548c\u5e72\u9884\u7c7b\u578b\u5f71\u54cd\uff0c\u5176\u4e2d\u6000\u7591\u8868\u8fbe\u662f\u6062\u590d\u673a\u5236\u7684\u5173\u952e\uff0c\u4f46\u9c81\u68d2\u6027\u4e0e\u6548\u7387\u5b58\u5728\u6743\u8861\u3002", "motivation": "\u7814\u7a76\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\uff08RLLMs\uff09\u751f\u6210\u7684\u601d\u7ef4\u94fe\uff08CoTs\uff09\u5728\u9762\u5bf9\u5185\u90e8\u6270\u52a8\u65f6\u7684\u9c81\u68d2\u6027\uff0c\u4e86\u89e3\u63a8\u7406\u8fc7\u7a0b\u5728\u53d7\u5230\u5e72\u6270\u65f6\u7684\u6062\u590d\u80fd\u529b\u3002", "method": "\u5f15\u5165\u53d7\u63a7\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u56fa\u5b9a\u65f6\u95f4\u6b65\u6270\u52a8\u6a21\u578b\u7684\u601d\u7ef4\u94fe\uff0c\u8bbe\u8ba1\u4e03\u79cd\u5e72\u9884\u63aa\u65bd\uff08\u826f\u6027\u3001\u4e2d\u6027\u548c\u5bf9\u6297\u6027\uff09\uff0c\u5e94\u7528\u4e8e\u591a\u4e2a\u5f00\u6e90RLLMs\uff0c\u8986\u76d6\u6570\u5b66\u3001\u79d1\u5b66\u548c\u903b\u8f91\u4efb\u52a1\u3002", "result": "RLLMs\u603b\u4f53\u4e0a\u5177\u6709\u9c81\u68d2\u6027\uff0c\u80fd\u4ece\u591a\u6837\u6270\u52a8\u4e2d\u53ef\u9760\u6062\u590d\uff0c\u9c81\u68d2\u6027\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u63d0\u9ad8\uff0c\u65e9\u671f\u5e72\u9884\u4f1a\u964d\u4f4e\u9c81\u68d2\u6027\u3002\u4f46\u9c81\u68d2\u6027\u4e0d\u662f\u98ce\u683c\u4e0d\u53d8\u7684\uff1a\u6539\u5199\u4f1a\u6291\u5236\u6000\u7591\u8868\u8fbe\u5e76\u964d\u4f4e\u6027\u80fd\uff0c\u800c\u5176\u4ed6\u5e72\u9884\u4f1a\u89e6\u53d1\u6000\u7591\u5e76\u652f\u6301\u6062\u590d\u3002\u6062\u590d\u4e5f\u6709\u4ee3\u4ef7\uff1a\u4e2d\u6027\u548c\u5bf9\u6297\u6027\u566a\u58f0\u4f1a\u4f7f\u601d\u7ef4\u94fe\u957f\u5ea6\u81a8\u80c0200%\u4ee5\u4e0a\uff0c\u800c\u6539\u5199\u4f1a\u7f29\u77ed\u75d5\u8ff9\u4f46\u635f\u5bb3\u51c6\u786e\u6027\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86RLLMs\u5982\u4f55\u7ef4\u6301\u63a8\u7406\u5b8c\u6574\u6027\uff0c\u8bc6\u522b\u6000\u7591\u4f5c\u4e3a\u6838\u5fc3\u6062\u590d\u673a\u5236\uff0c\u5e76\u5f3a\u8c03\u4e86\u9c81\u68d2\u6027\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u672a\u6765\u8bad\u7ec3\u65b9\u6cd5\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002"}}
{"id": "2602.07473", "categories": ["cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2602.07473", "abs": "https://arxiv.org/abs/2602.07473", "authors": ["Nathana\u00ebl Fijalkow", "Arka Ghosh", "Roman Kniazev", "Guillermo A. P\u00e9rez", "Pierre Vandenhove"], "title": "Computing the Reachability Value of Posterior-Deterministic POMDPs", "comment": null, "summary": "Partially observable Markov decision processes (POMDPs) are a fundamental model for sequential decision-making under uncertainty. However, many verification and synthesis problems for POMDPs are undecidable or intractable. Most prominently, the seminal result of Madani et al. (2003) states that there is no algorithm that, given a POMDP and a set of target states, can compute the maximal probability of reaching the target states, or even approximate it up to a non-trivial constant. This is in stark contrast to fully observable Markov decision processes (MDPs), where the reachability value can be computed in polynomial time.\n  In this work, we introduce posterior-deterministic POMDPs, a novel class of POMDPs. Our main technical contribution is to show that for posterior-deterministic POMDPs, the maximal probability of reaching a given set of states can be approximated up to arbitrary precision.\n  A POMDP is posterior-deterministic if the next state can be uniquely determined by the current state, the action taken, and the observation received. While the actual state is generally uncertain in POMDPs, the posterior-deterministic property tells us that once the true state is known it remains known forever. This simple and natural definition includes all MDPs and captures classical non-trivial examples such as the Tiger POMDP (Kaelbling et al. 1998), making it one of the largest known classes of POMDPs for which the reachability value can be approximated.", "AI": {"tldr": "\u63d0\u51fa\u540e\u9a8c\u786e\u5b9a\u6027POMDPs\u65b0\u7c7b\u522b\uff0c\u8bc1\u660e\u5176\u53ef\u8fbe\u6982\u7387\u53ef\u8fd1\u4f3c\u8ba1\u7b97\uff0c\u7a81\u7834\u4e86POMDPs\u8ba1\u7b97\u4e0d\u53ef\u884c\u6027\u7684\u9650\u5236\u3002", "motivation": "POMDPs\u662f\u5e8f\u5217\u51b3\u7b56\u7684\u91cd\u8981\u6a21\u578b\uff0c\u4f46\u8bb8\u591a\u9a8c\u8bc1\u548c\u7efc\u5408\u95ee\u9898\u4e0d\u53ef\u5224\u5b9a\u6216\u96be\u89e3\u3002Madani\u7b49\u4eba(2003)\u8bc1\u660ePOMDPs\u7684\u6700\u5927\u53ef\u8fbe\u6982\u7387\u65e0\u6cd5\u8ba1\u7b97\u751a\u81f3\u8fd1\u4f3c\uff0c\u8fd9\u4e0e\u5b8c\u5168\u53ef\u89c2\u6d4bMDPs\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\u3002", "method": "\u5f15\u5165\u540e\u9a8c\u786e\u5b9a\u6027POMDPs\u65b0\u7c7b\u522b\uff1a\u4e0b\u4e00\u72b6\u6001\u7531\u5f53\u524d\u72b6\u6001\u3001\u91c7\u53d6\u52a8\u4f5c\u548c\u63a5\u6536\u89c2\u6d4b\u552f\u4e00\u786e\u5b9a\u3002\u4e00\u65e6\u771f\u5b9e\u72b6\u6001\u5df2\u77e5\uff0c\u5b83\u5c06\u6c38\u8fdc\u4fdd\u6301\u5df2\u77e5\u3002", "result": "\u8bc1\u660e\u5bf9\u4e8e\u540e\u9a8c\u786e\u5b9a\u6027POMDPs\uff0c\u7ed9\u5b9a\u72b6\u6001\u96c6\u7684\u6700\u5927\u53ef\u8fbe\u6982\u7387\u53ef\u4ee5\u8fd1\u4f3c\u5230\u4efb\u610f\u7cbe\u5ea6\u3002\u8fd9\u662f\u5df2\u77e5\u6700\u5927\u7684POMDPs\u7c7b\u522b\u4e4b\u4e00\uff0c\u5305\u542b\u6240\u6709MDPs\u548c\u7ecf\u5178\u975e\u5e73\u51e1\u4f8b\u5b50\u5982Tiger POMDP\u3002", "conclusion": "\u540e\u9a8c\u786e\u5b9a\u6027POMDPs\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8ba1\u7b97\u53ef\u884c\u7684POMDPs\u5b50\u7c7b\uff0c\u7a81\u7834\u4e86POMDPs\u53ef\u8fbe\u6982\u7387\u8ba1\u7b97\u7684\u7406\u8bba\u969c\u788d\uff0c\u5177\u6709\u91cd\u8981\u7406\u8bba\u548c\u5b9e\u8df5\u610f\u4e49\u3002"}}
{"id": "2602.07491", "categories": ["cs.AI", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "cond-mat.soft", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07491", "abs": "https://arxiv.org/abs/2602.07491", "authors": ["Isabella A. Stewart", "Tarjei Paule Hage", "Yu-Chuan Hsu", "Markus J. Buehler"], "title": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design", "comment": null, "summary": "Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science, where innovation demands integrating concepts from molecular chemistry to mechanical performance, this is especially acute. Neither humans nor single-agent LLMs can fully contend with this torrent of information, with the latter often prone to hallucinations. To address this bottleneck, we introduce a multi-agent framework guided by large-scale knowledge graphs to find sustainable substitutes for per- and polyfluoroalkyl substances (PFAS)-chemicals currently under intense regulatory scrutiny. Agents in the framework specialize in problem decomposition, evidence retrieval, design parameter extraction, and graph traversal, uncovering latent connections across distinct knowledge pockets to support hypothesis generation. Ablation studies show that the full multi-agent pipeline outperforms single-shot prompting, underscoring the value of distributed specialization and relational reasoning. We demonstrate that by tailoring graph traversal strategies, the system alternates between exploitative searches focusing on domain-critical outcomes and exploratory searches surfacing emergent cross-connections. Illustrated through the exemplar of biomedical tubing, the framework generates sustainable PFAS-free alternatives that balance tribological performance, thermal stability, chemical resistance, and biocompatibility. This work establishes a framework combining knowledge graphs with multi-agent reasoning to expand the materials design space, showcasing several initial design candidates to demonstrate the approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u4e0e\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5bfb\u627ePFAS\u7684\u53ef\u6301\u7eed\u66ff\u4ee3\u54c1\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u4e13\u4e1a\u5316\u548c\u5173\u7cfb\u63a8\u7406\u6269\u5c55\u6750\u6599\u8bbe\u8ba1\u7a7a\u95f4\u3002", "motivation": "\u6750\u6599\u79d1\u5b66\u521b\u65b0\u9700\u8981\u6574\u5408\u4ece\u5206\u5b50\u5316\u5b66\u5230\u673a\u68b0\u6027\u80fd\u7684\u8de8\u9886\u57df\u6982\u5ff5\uff0c\u4f46\u4eba\u7c7b\u548c\u5355\u667a\u80fd\u4f53LLM\u90fd\u96be\u4ee5\u5e94\u5bf9\u4fe1\u606f\u6d2a\u6d41\uff0c\u540e\u8005\u8fd8\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u74f6\u9888\u6765\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5927\u89c4\u6a21\u77e5\u8bc6\u56fe\u8c31\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u95ee\u9898\u5206\u89e3\u3001\u8bc1\u636e\u68c0\u7d22\u3001\u8bbe\u8ba1\u53c2\u6570\u63d0\u53d6\u548c\u56fe\u904d\u5386\u7b49\u4e13\u95e8\u5316\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5b9a\u5236\u5316\u56fe\u904d\u5386\u7b56\u7565\u5728\u63a2\u7d22\u6027\u548c\u5229\u7528\u6027\u641c\u7d22\u95f4\u5207\u6362\u3002", "result": "\u6d88\u878d\u7814\u7a76\u8868\u660e\u5b8c\u6574\u591a\u667a\u80fd\u4f53\u6d41\u6c34\u7ebf\u4f18\u4e8e\u5355\u6b21\u63d0\u793a\uff0c\u6846\u67b6\u80fd\u591f\u751f\u6210\u5e73\u8861\u6469\u64e6\u6027\u80fd\u3001\u70ed\u7a33\u5b9a\u6027\u3001\u5316\u5b66\u6297\u6027\u548c\u751f\u7269\u76f8\u5bb9\u6027\u7684\u53ef\u6301\u7eedPFAS-free\u66ff\u4ee3\u54c1\uff0c\u5c55\u793a\u4e86\u591a\u4e2a\u521d\u59cb\u8bbe\u8ba1\u5019\u9009\u65b9\u6848\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5efa\u7acb\u4e86\u77e5\u8bc6\u56fe\u8c31\u4e0e\u591a\u667a\u80fd\u4f53\u63a8\u7406\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u6765\u6269\u5c55\u6750\u6599\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u901a\u8fc7\u751f\u7269\u533b\u5b66\u7ba1\u6750\u6848\u4f8b\u5c55\u793a\u4e86\u6846\u67b6\u5728\u53d1\u73b0\u8de8\u9886\u57df\u6f5c\u5728\u8fde\u63a5\u548c\u652f\u6301\u5047\u8bbe\u751f\u6210\u65b9\u9762\u7684\u80fd\u529b\u3002"}}
{"id": "2602.07533", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07533", "abs": "https://arxiv.org/abs/2602.07533", "authors": ["Yankai Yang", "Yancheng Long", "Hongyang Wei", "Wei Chen", "Tianke Zhang", "Kaiyu Jiang", "Haonan Fan", "Changyi Liu", "Jiankang Chen", "Kaiyu Tang", "Bin Wen", "Fan Yang", "Tingting Gao", "Han Li", "Shuo Yang"], "title": "Joint Reward Modeling: Internalizing Chain-of-Thought for Efficient Visual Reward Models", "comment": null, "summary": "Reward models are critical for reinforcement learning from human feedback, as they determine the alignment quality and reliability of generative models. For complex tasks such as image editing, reward models are required to capture global semantic consistency and implicit logical constraints beyond local similarity. Existing reward modeling approaches have clear limitations. Discriminative reward models align well with human preferences but struggle with complex semantics due to limited reasoning supervision. Generative reward models offer stronger semantic understanding and reasoning, but they are costly at inference time and difficult to align directly with human preferences. To this end, we propose Joint Reward Modeling (JRM), which jointly optimizes preference learning and language modeling on a shared vision-language backbone. This approach internalizes the semantic and reasoning capabilities of generative models into efficient discriminative representations, enabling fast and accurate evaluation. JRM achieves state-of-the-art results on MMRB2 and EditReward-Bench, and significantly improves stability and performance in downstream online reinforcement learning. These results show that joint training effectively bridges efficiency and semantic understanding in reward modeling.", "AI": {"tldr": "JRM\u901a\u8fc7\u8054\u5408\u4f18\u5316\u504f\u597d\u5b66\u4e60\u548c\u8bed\u8a00\u5efa\u6a21\uff0c\u5c06\u751f\u6210\u6a21\u578b\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u878d\u5165\u5224\u522b\u5f0f\u8868\u793a\uff0c\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u7684\u5956\u52b1\u8bc4\u4f30", "motivation": "\u73b0\u6709\u5956\u52b1\u6a21\u578b\u5b58\u5728\u660e\u663e\u5c40\u9650\uff1a\u5224\u522b\u5f0f\u5956\u52b1\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u826f\u597d\u4f46\u8bed\u4e49\u7406\u89e3\u6709\u9650\uff1b\u751f\u6210\u5f0f\u5956\u52b1\u6a21\u578b\u8bed\u4e49\u7406\u89e3\u5f3a\u4f46\u63a8\u7406\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u76f4\u63a5\u5bf9\u9f50\u504f\u597d\u3002\u9700\u8981\u4e00\u79cd\u80fd\u517c\u987e\u6548\u7387\u548c\u8bed\u4e49\u7406\u89e3\u7684\u65b9\u6cd5", "method": "\u63d0\u51fa\u8054\u5408\u5956\u52b1\u5efa\u6a21(JRM)\uff0c\u5728\u5171\u4eab\u7684\u89c6\u89c9-\u8bed\u8a00\u9aa8\u5e72\u7f51\u7edc\u4e0a\u8054\u5408\u4f18\u5316\u504f\u597d\u5b66\u4e60\u548c\u8bed\u8a00\u5efa\u6a21\uff0c\u5c06\u751f\u6210\u6a21\u578b\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u5185\u90e8\u5316\u5230\u9ad8\u6548\u7684\u5224\u522b\u5f0f\u8868\u793a\u4e2d", "result": "\u5728MMRB2\u548cEditReward-Bench\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u663e\u8457\u63d0\u5347\u4e0b\u6e38\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd", "conclusion": "\u8054\u5408\u8bad\u7ec3\u6709\u6548\u6865\u63a5\u4e86\u5956\u52b1\u5efa\u6a21\u4e2d\u7684\u6548\u7387\u548c\u8bed\u4e49\u7406\u89e3\uff0c\u4e3a\u590d\u6742\u4efb\u52a1\u63d0\u4f9b\u4e86\u5feb\u901f\u51c6\u786e\u7684\u5956\u52b1\u8bc4\u4f30\u65b9\u6848"}}
{"id": "2602.07543", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.07543", "abs": "https://arxiv.org/abs/2602.07543", "authors": ["Heewoong Noh", "Gyoung S. Na", "Namkyeong Lee", "Chanyoung Park"], "title": "MSP-LLM: A Unified Large Language Model Framework for Complete Material Synthesis Planning", "comment": null, "summary": "Material synthesis planning (MSP) remains a fundamental and underexplored bottleneck in AI-driven materials discovery, as it requires not only identifying suitable precursor materials but also designing coherent sequences of synthesis operations to realize a target material. Although several AI-based approaches have been proposed to address isolated subtasks of MSP, a unified methodology for solving the entire MSP task has yet to be established. We propose MSP-LLM, a unified LLM-based framework that formulates MSP as a structured process composed of two constituent subproblems: precursor prediction (PP) and synthesis operation prediction (SOP). Our approach introduces a discrete material class as an intermediate decision variable that organizes both tasks into a chemically consistent decision chain. For OP, we further incorporate hierarchical precursor types as synthesis-relevant inductive biases and employ an explicit conditioning strategy that preserves precursor-related information in the autoregressive decoding state. Extensive experiments show that MSP-LLM consistently outperforms existing methods on both PP and SOP, as well as on the complete MSP task, demonstrating an effective and scalable framework for MSP that can accelerate real-world materials discovery.", "AI": {"tldr": "MSP-LLM\uff1a\u4e00\u4e2a\u7edf\u4e00\u7684LLM\u6846\u67b6\uff0c\u5c06\u6750\u6599\u5408\u6210\u89c4\u5212\u5206\u89e3\u4e3a\u524d\u9a71\u4f53\u9884\u6d4b\u548c\u5408\u6210\u64cd\u4f5c\u9884\u6d4b\u4e24\u4e2a\u5b50\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165\u6750\u6599\u7c7b\u522b\u4f5c\u4e3a\u4e2d\u95f4\u51b3\u7b56\u53d8\u91cf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6750\u6599\u5408\u6210\u89c4\u5212\u7684\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u6750\u6599\u5408\u6210\u89c4\u5212\u662fAI\u9a71\u52a8\u6750\u6599\u53d1\u73b0\u4e2d\u7684\u5173\u952e\u74f6\u9888\uff0c\u73b0\u6709\u65b9\u6cd5\u53ea\u80fd\u89e3\u51b3\u5b64\u7acb\u5b50\u4efb\u52a1\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u80fd\u591f\u540c\u65f6\u5904\u7406\u524d\u9a71\u4f53\u9009\u62e9\u548c\u5408\u6210\u64cd\u4f5c\u5e8f\u5217\u8bbe\u8ba1\u7684\u5b8c\u6574\u6846\u67b6\u3002", "method": "\u63d0\u51faMSP-LLM\u6846\u67b6\uff0c\u5c06\u6750\u6599\u5408\u6210\u89c4\u5212\u5206\u89e3\u4e3a\u524d\u9a71\u4f53\u9884\u6d4b\u548c\u5408\u6210\u64cd\u4f5c\u9884\u6d4b\u4e24\u4e2a\u5b50\u95ee\u9898\u3002\u5f15\u5165\u79bb\u6563\u6750\u6599\u7c7b\u522b\u4f5c\u4e3a\u4e2d\u95f4\u51b3\u7b56\u53d8\u91cf\uff0c\u6784\u5efa\u5316\u5b66\u4e00\u81f4\u7684\u51b3\u7b56\u94fe\u3002\u5728\u5408\u6210\u64cd\u4f5c\u9884\u6d4b\u4e2d\uff0c\u91c7\u7528\u5206\u5c42\u524d\u9a71\u4f53\u7c7b\u578b\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e\uff0c\u5e76\u4f7f\u7528\u663e\u5f0f\u6761\u4ef6\u7b56\u7565\u5728\u81ea\u56de\u5f52\u89e3\u7801\u4e2d\u4fdd\u6301\u524d\u9a71\u4f53\u76f8\u5173\u4fe1\u606f\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMSP-LLM\u5728\u524d\u9a71\u4f53\u9884\u6d4b\u3001\u5408\u6210\u64cd\u4f5c\u9884\u6d4b\u4ee5\u53ca\u5b8c\u6574\u7684\u6750\u6599\u5408\u6210\u89c4\u5212\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u5728\u52a0\u901f\u771f\u5b9e\u4e16\u754c\u6750\u6599\u53d1\u73b0\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "MSP-LLM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u89e3\u548c\u5316\u5b66\u4e00\u81f4\u6027\u7ea6\u675f\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u6750\u6599\u5408\u6210\u89c4\u5212\u7684\u5b8c\u6574\u4efb\u52a1\uff0c\u4e3aAI\u9a71\u52a8\u7684\u6750\u6599\u53d1\u73b0\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2602.07549", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07549", "abs": "https://arxiv.org/abs/2602.07549", "authors": ["Dayoon Ko", "Jihyuk Kim", "Sohyeon Kim", "Haeju Park", "Dahyun Lee", "Gunhee Kim", "Moontae Lee", "Kyungjae Lee"], "title": "When Is Enough Not Enough? Illusory Completion in Search Agents", "comment": null, "summary": "Recent search agents leverage multi-turn reasoning and search tools to achieve strong performance on multi-hop and long-horizon benchmarks. Yet it remains unclear whether they reliably reason across all requirements by tracking, verifying, and maintaining multiple conditions in these questions. We study this capability under multi-constraint problems, where valid answers must satisfy several constraints simultaneously. We find that illusory completion frequently occurs, wherein agents believe tasks are complete despite unresolved or violated constraints, leading to underverified answers. To diagnose this behavior, we introduce the Epistemic Ledger, an evaluation framework that tracks evidential support and agents' beliefs for each constraint throughout multi-turn reasoning. Our analysis reveals four recurring failure patterns: bare assertions, overlooked refutations, stagnation, and premature exit. Motivated by these findings, we examine whether explicit constraint-state tracking during execution mitigates these failures via LiveLedger, an inference-time tracker. This simple intervention consistently improves performance, substantially reducing underverified answers (by up to 26.5%) and improving overall accuracy (by up to 11.6%) on multi-constraint problems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faEpistemic Ledger\u6846\u67b6\u8bca\u65ad\u641c\u7d22\u4ee3\u7406\u5728\u591a\u7ea6\u675f\u95ee\u9898\u4e2d\u7684\u5e7b\u89c9\u5b8c\u6210\u73b0\u8c61\uff0c\u5e76\u5f00\u53d1LiveLedger\u5b9e\u65f6\u8ddf\u8e2a\u5668\u663e\u8457\u63d0\u5347\u6027\u80fd", "motivation": "\u73b0\u6709\u641c\u7d22\u4ee3\u7406\u5728\u591a\u8df3\u548c\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5b83\u4eec\u5728\u5904\u7406\u591a\u7ea6\u675f\u95ee\u9898\u65f6\u662f\u5426\u53ef\u9760\u5730\u8ddf\u8e2a\u3001\u9a8c\u8bc1\u548c\u7ef4\u62a4\u6240\u6709\u6761\u4ef6\u5c1a\u4e0d\u6e05\u695a\u3002\u7814\u7a76\u53d1\u73b0\u4ee3\u7406\u7ecf\u5e38\u51fa\u73b0\u5e7b\u89c9\u5b8c\u6210\u73b0\u8c61\uff0c\u5373\u4efb\u52a1\u672a\u5b8c\u6210\u6216\u7ea6\u675f\u88ab\u8fdd\u53cd\u65f6\u5374\u8ba4\u4e3a\u5df2\u5b8c\u6210\u3002", "method": "\u63d0\u51faEpistemic Ledger\u8bc4\u4f30\u6846\u67b6\uff0c\u8ddf\u8e2a\u591a\u8f6e\u63a8\u7406\u4e2d\u6bcf\u4e2a\u7ea6\u675f\u7684\u8bc1\u636e\u652f\u6301\u548c\u4ee3\u7406\u4fe1\u5ff5\u3002\u57fa\u4e8e\u5206\u6790\u53d1\u73b0\u7684\u56db\u79cd\u5931\u8d25\u6a21\u5f0f\uff0c\u5f00\u53d1\u4e86LiveLedger\u63a8\u7406\u65f6\u8ddf\u8e2a\u5668\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u663e\u5f0f\u8ddf\u8e2a\u7ea6\u675f\u72b6\u6001\u3002", "result": "LiveLedger\u663e\u8457\u51cf\u5c11\u4e86\u672a\u9a8c\u8bc1\u7b54\u6848\uff08\u6700\u591a\u51cf\u5c1126.5%\uff09\uff0c\u63d0\u9ad8\u4e86\u591a\u7ea6\u675f\u95ee\u9898\u7684\u6574\u4f53\u51c6\u786e\u7387\uff08\u6700\u591a\u63d0\u534711.6%\uff09\u3002", "conclusion": "\u663e\u5f0f\u7684\u7ea6\u675f\u72b6\u6001\u8ddf\u8e2a\u80fd\u6709\u6548\u7f13\u89e3\u641c\u7d22\u4ee3\u7406\u5728\u591a\u7ea6\u675f\u95ee\u9898\u4e2d\u7684\u5e7b\u89c9\u5b8c\u6210\u95ee\u9898\uff0cEpistemic Ledger\u6846\u67b6\u4e3a\u8bca\u65ad\u548c\u6539\u5584\u4ee3\u7406\u63a8\u7406\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.07559", "categories": ["cs.AI", "cs.CC", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.07559", "abs": "https://arxiv.org/abs/2602.07559", "authors": ["Kaleem Ullah Qasim", "Jiashu Zhang", "Hao Li", "Muhammad Kafeel Shaheen"], "title": "VERIFY-RL: Verifiable Recursive Decomposition for Reinforcement Learning in Mathematical Reasoning", "comment": "13 pages", "summary": "Training language models to solve complex mathematical problems benefits from curriculum learning progressively training on simpler subproblems. However, existing decomposition methods are often heuristic, offering no guarantees that subproblems are simpler, that solving them aids the parent task, or that their relationships are mathematically grounded. We observe that symbolic differentiation provides a natural structure for verified decomposition: calculus rules explicitly define how expressions reduce to simpler components with provable properties. We introduce Verify-RL, a framework where every parent-child decomposition satisfies three verifiable conditions: strictly decreasing structural complexity, solution containment, and formal rule derivation. Unlike heuristic methods where a significant fraction of decompositions are invalid our properties admit automatic verification through symbolic computation, achieving \"verification by construction\" Experiments demonstrate that eliminating invalid decompositions yields sizable gains, accuracy on the hardest problems more than doubles from 32% to 68%, with a 40% relative improvement overall.", "AI": {"tldr": "Verify-RL\u6846\u67b6\u901a\u8fc7\u7b26\u53f7\u5fae\u5206\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u7684\u5206\u89e3\uff0c\u786e\u4fdd\u5b50\u95ee\u9898\u66f4\u7b80\u5355\u3001\u89e3\u51b3\u5b50\u95ee\u9898\u6709\u52a9\u4e8e\u7236\u4efb\u52a1\u3001\u4e14\u5206\u89e3\u5173\u7cfb\u6709\u6570\u5b66\u57fa\u7840\uff0c\u76f8\u6bd4\u542f\u53d1\u5f0f\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6570\u5b66\u95ee\u9898\u6c42\u89e3\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u6570\u5b66\u95ee\u9898\u5206\u89e3\u65b9\u6cd5\u901a\u5e38\u662f\u542f\u53d1\u5f0f\u7684\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u5b50\u95ee\u9898\u66f4\u7b80\u5355\u3001\u89e3\u51b3\u5b50\u95ee\u9898\u6709\u52a9\u4e8e\u7236\u4efb\u52a1\u3001\u4e14\u5206\u89e3\u5173\u7cfb\u6709\u6570\u5b66\u57fa\u7840\u3002\u9700\u8981\u4e00\u79cd\u53ef\u9a8c\u8bc1\u7684\u5206\u89e3\u6846\u67b6\u6765\u786e\u4fdd\u8fd9\u4e9b\u5173\u952e\u5c5e\u6027\u3002", "method": "\u63d0\u51faVerify-RL\u6846\u67b6\uff0c\u5229\u7528\u7b26\u53f7\u5fae\u5206\u4f5c\u4e3a\u5206\u89e3\u7684\u81ea\u7136\u7ed3\u6784\uff1a\u5fae\u79ef\u5206\u89c4\u5219\u660e\u786e\u5b9a\u4e49\u4e86\u8868\u8fbe\u5f0f\u5982\u4f55\u5206\u89e3\u4e3a\u66f4\u7b80\u5355\u7684\u7ec4\u4ef6\uff0c\u5e76\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6027\u8d28\u3002\u6bcf\u4e2a\u7236\u5b50\u5206\u89e3\u6ee1\u8db3\u4e09\u4e2a\u53ef\u9a8c\u8bc1\u6761\u4ef6\uff1a\u7ed3\u6784\u590d\u6742\u5ea6\u4e25\u683c\u9012\u51cf\u3001\u89e3\u5305\u542b\u6027\u3001\u5f62\u5f0f\u89c4\u5219\u63a8\u5bfc\u3002", "result": "\u6d88\u9664\u65e0\u6548\u5206\u89e3\u5e26\u6765\u663e\u8457\u63d0\u5347\uff1a\u6700\u96be\u95ee\u9898\u7684\u51c6\u786e\u7387\u4ece32%\u7ffb\u500d\u81f368%\uff0c\u6574\u4f53\u76f8\u5bf9\u6539\u8fdb40%\u3002\u9a8c\u8bc1\u901a\u8fc7\u6784\u9020\u5b9e\u73b0\uff0c\u53ef\u901a\u8fc7\u7b26\u53f7\u8ba1\u7b97\u81ea\u52a8\u9a8c\u8bc1\uff0c\u800c\u542f\u53d1\u5f0f\u65b9\u6cd5\u4e2d\u6709\u76f8\u5f53\u6bd4\u4f8b\u7684\u5206\u89e3\u662f\u65e0\u6548\u7684\u3002", "conclusion": "\u7b26\u53f7\u5fae\u5206\u4e3a\u6570\u5b66\u95ee\u9898\u5206\u89e3\u63d0\u4f9b\u4e86\u53ef\u9a8c\u8bc1\u7684\u7ed3\u6784\uff0c\u786e\u4fdd\u5206\u89e3\u7684\u6570\u5b66\u6b63\u786e\u6027\u3002Verify-RL\u6846\u67b6\u901a\u8fc7\"\u6784\u9020\u9a8c\u8bc1\"\u6d88\u9664\u65e0\u6548\u5206\u89e3\uff0c\u663e\u8457\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u590d\u6742\u6570\u5b66\u95ee\u9898\u7684\u80fd\u529b\u3002"}}
{"id": "2602.07624", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07624", "abs": "https://arxiv.org/abs/2602.07624", "authors": ["Junyu Feng", "Binxiao Xu", "Jiayi Chen", "Mengyu Dai", "Cenyang Wu", "Haodong Li", "Bohan Zeng", "Yunliu Xie", "Hao Liang", "Ming Lu", "Wentao Zhang"], "title": "M2A: Multimodal Memory Agent with Dual-Layer Hybrid Memory for Long-Term Personalized Interactions", "comment": null, "summary": "This work addresses the challenge of personalized question answering in long-term human-machine interactions: when conversational history spans weeks or months and exceeds the context window, existing personalization mechanisms struggle to continuously absorb and leverage users' incremental concepts, aliases, and preferences. Current personalized multimodal models are predominantly static-concepts are fixed at initialization and cannot evolve during interactions. We propose M2A, an agentic dual-layer hybrid memory system that maintains personalized multimodal information through online updates. The system employs two collaborative agents: ChatAgent manages user interactions and autonomously decides when to query or update memory, while MemoryManager breaks down memory requests from ChatAgent into detailed operations on the dual-layer memory bank, which couples a RawMessageStore (immutable conversation log) with a SemanticMemoryStore (high-level observations), providing memories at different granularities. In addition, we develop a reusable data synthesis pipeline that injects concept-grounded sessions from Yo'LLaVA and MC-LLaVA into LoCoMo long conversations while preserving temporal coherence. Experiments show that M2A significantly outperforms baselines, demonstrating that transforming personalization from one-shot configuration to a co-evolving memory mechanism provides a viable path for high-quality individualized responses in long-term multimodal interactions. The code is available at https://github.com/Little-Fridge/M2A.", "AI": {"tldr": "M2A\u662f\u4e00\u4e2a\u7528\u4e8e\u957f\u671f\u591a\u6a21\u6001\u4ea4\u4e92\u7684\u4e2a\u6027\u5316\u95ee\u7b54\u7cfb\u7edf\uff0c\u91c7\u7528\u53cc\u5c42\u6df7\u5408\u8bb0\u5fc6\u673a\u5236\uff0c\u901a\u8fc7\u5728\u7ebf\u66f4\u65b0\u7ef4\u62a4\u7528\u6237\u4e2a\u6027\u5316\u4fe1\u606f\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4e2a\u6027\u5316\u591a\u6a21\u6001\u6a21\u578b\u901a\u5e38\u662f\u9759\u6001\u7684\uff0c\u6982\u5ff5\u5728\u521d\u59cb\u5316\u65f6\u56fa\u5b9a\uff0c\u65e0\u6cd5\u5728\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u6f14\u5316\u3002\u5f53\u5bf9\u8bdd\u5386\u53f2\u8de8\u8d8a\u6570\u5468\u6216\u6570\u6708\u5e76\u8d85\u51fa\u4e0a\u4e0b\u6587\u7a97\u53e3\u65f6\uff0c\u73b0\u6709\u4e2a\u6027\u5316\u673a\u5236\u96be\u4ee5\u6301\u7eed\u5438\u6536\u548c\u5229\u7528\u7528\u6237\u589e\u91cf\u6982\u5ff5\u3001\u522b\u540d\u548c\u504f\u597d\u3002", "method": "\u63d0\u51faM2A\u7cfb\u7edf\uff0c\u91c7\u7528\u4ee3\u7406\u9a71\u52a8\u7684\u53cc\u5c42\u6df7\u5408\u8bb0\u5fc6\u7cfb\u7edf\uff1aChatAgent\u7ba1\u7406\u7528\u6237\u4ea4\u4e92\u5e76\u81ea\u4e3b\u51b3\u5b9a\u4f55\u65f6\u67e5\u8be2\u6216\u66f4\u65b0\u8bb0\u5fc6\uff1bMemoryManager\u5c06\u8bb0\u5fc6\u8bf7\u6c42\u5206\u89e3\u4e3a\u5bf9\u53cc\u5c42\u8bb0\u5fc6\u5e93\u7684\u8be6\u7ec6\u64cd\u4f5c\uff0c\u5305\u62ecRawMessageStore\uff08\u4e0d\u53ef\u53d8\u7684\u5bf9\u8bdd\u65e5\u5fd7\uff09\u548cSemanticMemoryStore\uff08\u9ad8\u5c42\u89c2\u5bdf\uff09\uff0c\u63d0\u4f9b\u4e0d\u540c\u7c92\u5ea6\u7684\u8bb0\u5fc6\u3002\u540c\u65f6\u5f00\u53d1\u4e86\u53ef\u91cd\u7528\u7684\u6570\u636e\u5408\u6210\u7ba1\u9053\uff0c\u5c06Yo'LLaVA\u548cMC-LLaVA\u4e2d\u7684\u6982\u5ff5\u57fa\u7840\u4f1a\u8bdd\u6ce8\u5165LoCoMo\u957f\u5bf9\u8bdd\u4e2d\uff0c\u540c\u65f6\u4fdd\u6301\u65f6\u95f4\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eM2A\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u660e\u5c06\u4e2a\u6027\u5316\u4ece\u4e00\u6b21\u6027\u914d\u7f6e\u8f6c\u53d8\u4e3a\u534f\u540c\u6f14\u5316\u7684\u8bb0\u5fc6\u673a\u5236\uff0c\u4e3a\u957f\u671f\u591a\u6a21\u6001\u4ea4\u4e92\u4e2d\u7684\u9ad8\u8d28\u91cf\u4e2a\u6027\u5316\u54cd\u5e94\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002", "conclusion": "M2A\u901a\u8fc7\u5728\u7ebf\u66f4\u65b0\u7684\u53cc\u5c42\u6df7\u5408\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u957f\u671f\u591a\u6a21\u6001\u4ea4\u4e92\u4e2d\u7684\u4e2a\u6027\u5316\u6311\u6218\uff0c\u5c06\u4e2a\u6027\u5316\u4ece\u9759\u6001\u914d\u7f6e\u8f6c\u53d8\u4e3a\u52a8\u6001\u534f\u540c\u6f14\u5316\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u957f\u671f\u4ea4\u4e92\u4e2d\u7684\u4e2a\u6027\u5316\u54cd\u5e94\u8d28\u91cf\u3002"}}
{"id": "2602.07628", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07628", "abs": "https://arxiv.org/abs/2602.07628", "authors": ["Keondo Park", "Younghoon Na", "Yourim Choi", "Hyunwoo Ryu", "Hyun-Woo Shin", "Hyung-Sin Kim"], "title": "SleepMaMi: A Universal Sleep Foundation Model for Integrating Macro- and Micro-structures", "comment": "8 pages, Appendix 9 pages", "summary": "While the shift toward unified foundation models has revolutionized many deep learning domains, sleep medicine remains largely restricted to task-specific models that focus on localized micro-structure features. These approaches often neglect the rich, multi-modal context of Polysomnography (PSG) and fail to capture the global macro-structure of a full night's sleep. To address this, we introduce SleepMaMi , a Sleep Foundation Model engineered to master both hour-long sleep architectures and fine-grained signal morphologies. Our framework utilizes a hierarchical dual-encoder design: a Macro-Encoder to model full-night temporal dependencies and a Micro-Encoder to capture short-term characteristics from biosignals. Macro-Encoder is trained via Demographic-Guided Contrastive Learning, which aligns overnight sleep patterns with objective subject metadata, such as age, sex and BMI to refine global representations. Micro-Encoder is optimized via a hybrid Masked Autoencoder (MAE) and multi-modal contrastive objective. Pre-trained on a massive corpus of $>$20,000 PSG recordings (158K hours),SleepMaMi outperforms existing foundation models across a diverse suite of downstream tasks, demonstrating superior generalizability and label-efficient adaptation for clinical sleep analysis.", "AI": {"tldr": "SleepMaMi\uff1a\u9996\u4e2a\u7761\u7720\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u5c42\u53cc\u7f16\u7801\u5668\u8bbe\u8ba1\u540c\u65f6\u5efa\u6a21\u6574\u591c\u7761\u7720\u5b8f\u89c2\u7ed3\u6784\u548c\u7ec6\u7c92\u5ea6\u4fe1\u53f7\u5fae\u89c2\u7279\u5f81\uff0c\u572820,000+ PSG\u8bb0\u5f55\u4e0a\u9884\u8bad\u7ec3\uff0c\u5728\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02", "motivation": "\u5f53\u524d\u7761\u7720\u533b\u5b66\u4e3b\u8981\u4f7f\u7528\u4efb\u52a1\u7279\u5b9a\u7684\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u4e13\u6ce8\u4e8e\u5c40\u90e8\u5fae\u89c2\u7ed3\u6784\u7279\u5f81\uff0c\u5ffd\u7565\u4e86PSG\u7684\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u548c\u6574\u591c\u7761\u7720\u7684\u5168\u5c40\u5b8f\u89c2\u7ed3\u6784\u3002\u9700\u8981\u7edf\u4e00\u7684\u57fa\u7840\u6a21\u578b\u6765\u540c\u65f6\u638c\u63e1\u5c0f\u65f6\u7ea7\u7761\u7720\u67b6\u6784\u548c\u7ec6\u7c92\u5ea6\u4fe1\u53f7\u5f62\u6001\u3002", "method": "\u91c7\u7528\u5206\u5c42\u53cc\u7f16\u7801\u5668\u8bbe\u8ba1\uff1a1) \u5b8f\u89c2\u7f16\u7801\u5668\u5efa\u6a21\u6574\u591c\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u901a\u8fc7\u4eba\u53e3\u7edf\u8ba1\u5b66\u5f15\u5bfc\u7684\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\uff1b2) \u5fae\u89c2\u7f16\u7801\u5668\u6355\u83b7\u751f\u7269\u4fe1\u53f7\u7684\u77ed\u671f\u7279\u5f81\uff0c\u901a\u8fc7\u6df7\u5408\u63a9\u7801\u81ea\u7f16\u7801\u5668\u548c\u591a\u6a21\u6001\u5bf9\u6bd4\u76ee\u6807\u4f18\u5316\u3002\u5728\u8d85\u8fc720,000\u4e2aPSG\u8bb0\u5f55\uff08158K\u5c0f\u65f6\uff09\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\u3002", "result": "SleepMaMi\u5728\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u7840\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6807\u7b7e\u9ad8\u6548\u7684\u4e34\u5e8a\u7761\u7720\u5206\u6790\u9002\u5e94\u80fd\u529b\u3002", "conclusion": "SleepMaMi\u6210\u529f\u89e3\u51b3\u4e86\u7761\u7720\u533b\u5b66\u4e2d\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u57fa\u7840\u6a21\u578b\u540c\u65f6\u638c\u63e1\u7761\u7720\u7684\u5b8f\u89c2\u548c\u5fae\u89c2\u7ed3\u6784\uff0c\u4e3a\u4e34\u5e8a\u7761\u7720\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u3002"}}
{"id": "2602.07642", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07642", "abs": "https://arxiv.org/abs/2602.07642", "authors": ["Zhuoyan Xu", "Haoyang Fang", "Boran Han", "Bonan Min", "Bernie Wang", "Cuixiong Hu", "Shuai Zhang"], "title": "Efficient Table Retrieval and Understanding with Multimodal Large Language Models", "comment": "Published at EACL 2026 Findings", "summary": "Tabular data is frequently captured in image form across a wide range of real-world scenarios such as financial reports, handwritten records, and document scans. These visual representations pose unique challenges for machine understanding, as they combine both structural and visual complexities. While recent advances in Multimodal Large Language Models (MLLMs) show promising results in table understanding, they typically assume the relevant table is readily available. However, a more practical scenario involves identifying and reasoning over relevant tables from large-scale collections to answer user queries. To address this gap, we propose TabRAG, a framework that enables MLLMs to answer queries over large collections of table images. Our approach first retrieves candidate tables using jointly trained visual-text foundation models, then leverages MLLMs to perform fine-grained reranking of these candidates, and finally employs MLLMs to reason over the selected tables for answer generation. Through extensive experiments on a newly constructed dataset comprising 88,161 training and 9,819 testing samples across 8 benchmarks with 48,504 unique tables, we demonstrate that our framework significantly outperforms existing methods by 7.0% in retrieval recall and 6.1% in answer accuracy, offering a practical solution for real-world table understanding tasks.", "AI": {"tldr": "TabRAG\uff1a\u4e00\u4e2a\u7528\u4e8e\u5927\u89c4\u6a21\u8868\u683c\u56fe\u50cf\u68c0\u7d22\u548c\u63a8\u7406\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9-\u6587\u672c\u57fa\u7840\u6a21\u578b\u68c0\u7d22\u5019\u9009\u8868\u683c\uff0cMLLM\u7ec6\u7c92\u5ea6\u91cd\u6392\u5e8f\uff0c\u6700\u7ec8\u751f\u6210\u7b54\u6848\uff0c\u663e\u8457\u63d0\u5347\u68c0\u7d22\u53ec\u56de\u7387\u548c\u7b54\u6848\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u8868\u683c\u6570\u636e\u5e38\u4ee5\u56fe\u50cf\u5f62\u5f0f\u5b58\u5728\uff08\u5982\u8d22\u52a1\u62a5\u544a\u3001\u624b\u5199\u8bb0\u5f55\u3001\u6587\u6863\u626b\u63cf\uff09\uff0c\u73b0\u6709MLLM\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u76f8\u5173\u8868\u683c\u5df2\u51c6\u5907\u597d\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u4ece\u5927\u89c4\u6a21\u8868\u683c\u96c6\u5408\u4e2d\u8bc6\u522b\u548c\u63a8\u7406\u76f8\u5173\u8868\u683c\u6765\u56de\u7b54\u7528\u6237\u67e5\u8be2\u3002", "method": "TabRAG\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u8054\u5408\u8bad\u7ec3\u7684\u89c6\u89c9-\u6587\u672c\u57fa\u7840\u6a21\u578b\u68c0\u7d22\u5019\u9009\u8868\u683c\uff1b2\uff09\u5229\u7528MLLM\u5bf9\u5019\u9009\u8868\u683c\u8fdb\u884c\u7ec6\u7c92\u5ea6\u91cd\u6392\u5e8f\uff1b3\uff09\u4f7f\u7528MLLM\u5728\u9009\u5b9a\u8868\u683c\u4e0a\u8fdb\u884c\u63a8\u7406\u751f\u6210\u7b54\u6848\u3002", "result": "\u5728\u65b0\u6784\u5efa\u7684\u6570\u636e\u96c6\uff0888,161\u8bad\u7ec3\u6837\u672c\uff0c9,819\u6d4b\u8bd5\u6837\u672c\uff0c8\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c48,504\u4e2a\u552f\u4e00\u8868\u683c\uff09\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u6846\u67b6\u5728\u68c0\u7d22\u53ec\u56de\u7387\u4e0a\u63d0\u53477.0%\uff0c\u7b54\u6848\u51c6\u786e\u7387\u63d0\u53476.1%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "TabRAG\u4e3a\u73b0\u5b9e\u4e16\u754c\u8868\u683c\u7406\u89e3\u4efb\u52a1\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5927\u89c4\u6a21\u8868\u683c\u56fe\u50cf\u96c6\u5408\u7684\u68c0\u7d22\u548c\u63a8\u7406\u95ee\u9898\uff0c\u586b\u8865\u4e86\u73b0\u6709MLLM\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\u7684\u7a7a\u767d\u3002"}}
{"id": "2602.07662", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07662", "abs": "https://arxiv.org/abs/2602.07662", "authors": ["Glenda Amaral", "Tiago Prince Sales", "Riccardo Baratella", "Daniele Porello", "Renata Guizzardi", "Giancarlo Guizzardi"], "title": "ONTrust: A Reference Ontology of Trust", "comment": "46 pages", "summary": "Trust has stood out more than ever in the light of recent innovations. Some examples are advances in artificial intelligence that make machines more and more humanlike, and the introduction of decentralized technologies (e.g. blockchains), which creates new forms of (decentralized) trust. These new developments have the potential to improve the provision of products and services, as well as to contribute to individual and collective well-being. However, their adoption depends largely on trust. In order to build trustworthy systems, along with defining laws, regulations and proper governance models for new forms of trust, it is necessary to properly conceptualize trust, so that it can be understood both by humans and machines. This paper is the culmination of a long-term research program of providing a solid ontological foundation on trust, by creating reference conceptual models to support information modeling, automated reasoning, information integration and semantic interoperability tasks. To address this, a Reference Ontology of Trust (ONTrust) was developed, grounded on the Unified Foundational Ontology and specified in OntoUML, which has been applied in several initiatives, to demonstrate, for example, how it can be used for conceptual modeling and enterprise architecture design, for language evaluation and (re)design, for trust management, for requirements engineering, and for trustworthy artificial intelligence (AI) in the context of affective Human-AI teaming. ONTrust formally characterizes the concept of trust and its different types, describes the different factors that can influence trust, as well as explains how risk emerges from trust relations. To illustrate the working of ONTrust, the ontology is applied to model two case studies extracted from the literature.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7edf\u4e00\u57fa\u7840\u672c\u4f53\u8bba\u7684\u4fe1\u4efb\u53c2\u8003\u672c\u4f53\u8bba\uff08ONTrust\uff09\uff0c\u7528\u4e8e\u652f\u6301\u4fe1\u606f\u5efa\u6a21\u3001\u81ea\u52a8\u63a8\u7406\u548c\u4fe1\u606f\u96c6\u6210\u7b49\u4efb\u52a1\uff0c\u65e8\u5728\u4e3a\u4eba\u7c7b\u548c\u673a\u5668\u63d0\u4f9b\u5bf9\u4fe1\u4efb\u7684\u6e05\u6670\u6982\u5ff5\u5316\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u548c\u533a\u5757\u94fe\u7b49\u65b0\u6280\u672f\u7684\u53d1\u5c55\uff0c\u4fe1\u4efb\u5728\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u91cd\u8981\u6027\u65e5\u76ca\u51f8\u663e\u3002\u7136\u800c\uff0c\u8981\u6784\u5efa\u53ef\u4fe1\u7cfb\u7edf\uff0c\u9996\u5148\u9700\u8981\u5bf9\u4fe1\u4efb\u6982\u5ff5\u8fdb\u884c\u6e05\u6670\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u4ee5\u4fbf\u4eba\u7c7b\u548c\u673a\u5668\u90fd\u80fd\u7406\u89e3\u3002\u5f53\u524d\u7f3a\u4e4f\u4e00\u4e2a\u575a\u5b9e\u7684\u672c\u4f53\u8bba\u57fa\u7840\u6765\u652f\u6301\u4fe1\u4efb\u76f8\u5173\u7684\u5efa\u6a21\u548c\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u7edf\u4e00\u57fa\u7840\u672c\u4f53\u8bba\uff08UFO\uff09\u7684\u4fe1\u4efb\u53c2\u8003\u672c\u4f53\u8bba\uff08ONTrust\uff09\uff0c\u4f7f\u7528OntoUML\u8bed\u8a00\u8fdb\u884c\u89c4\u8303\u3002\u8be5\u672c\u4f53\u8bba\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86\u4fe1\u4efb\u6982\u5ff5\u53ca\u5176\u4e0d\u540c\u7c7b\u578b\uff0c\u63cf\u8ff0\u4e86\u5f71\u54cd\u4fe1\u4efb\u7684\u5404\u79cd\u56e0\u7d20\uff0c\u5e76\u89e3\u91ca\u4e86\u4fe1\u4efb\u5173\u7cfb\u5982\u4f55\u4ea7\u751f\u98ce\u9669\u3002\u901a\u8fc7\u4e24\u4e2a\u6587\u732e\u6848\u4f8b\u7814\u7a76\u6765\u9a8c\u8bc1\u672c\u4f53\u8bba\u7684\u5b9e\u9645\u5e94\u7528\u3002", "result": "ONTrust\u672c\u4f53\u8bba\u5df2\u5728\u591a\u4e2a\u9886\u57df\u5f97\u5230\u5e94\u7528\uff0c\u5305\u62ec\u6982\u5ff5\u5efa\u6a21\u548c\u4f01\u4e1a\u67b6\u6784\u8bbe\u8ba1\u3001\u8bed\u8a00\u8bc4\u4f30\u4e0e\uff08\u91cd\u65b0\uff09\u8bbe\u8ba1\u3001\u4fe1\u4efb\u7ba1\u7406\u3001\u9700\u6c42\u5de5\u7a0b\uff0c\u4ee5\u53ca\u5728\u60c5\u611f\u4eba\u673a\u534f\u4f5c\u80cc\u666f\u4e0b\u7684\u53ef\u4fe1\u4eba\u5de5\u667a\u80fd\u3002\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u672c\u4f53\u8bba\u7684\u5b9e\u9645\u5de5\u4f5c\u6548\u679c\u3002", "conclusion": "ONTrust\u4e3a\u4fe1\u4efb\u63d0\u4f9b\u4e86\u4e00\u4e2a\u575a\u5b9e\u7684\u672c\u4f53\u8bba\u57fa\u7840\uff0c\u80fd\u591f\u652f\u6301\u5404\u79cd\u4fe1\u4efb\u76f8\u5173\u7684\u5efa\u6a21\u548c\u5e94\u7528\u4efb\u52a1\u3002\u8be5\u672c\u4f53\u8bba\u6709\u52a9\u4e8e\u4fc3\u8fdb\u53ef\u4fe1\u7cfb\u7edf\u7684\u5f00\u53d1\uff0c\u7279\u522b\u662f\u5728\u4eba\u5de5\u667a\u80fd\u548c\u53bb\u4e2d\u5fc3\u5316\u6280\u672f\u7b49\u65b0\u5174\u9886\u57df\uff0c\u4e3a\u5b9e\u73b0\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\u548c\u81ea\u52a8\u5316\u63a8\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2602.07695", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2602.07695", "abs": "https://arxiv.org/abs/2602.07695", "authors": ["Congcong Hu", "Yuang Shi", "Fan Huang", "Yang Xiang", "Zhou Ye", "Ming Jin", "Shiyu Wang"], "title": "EventCast: Hybrid Demand Forecasting in E-Commerce with LLM-Based Event Knowledge", "comment": null, "summary": "Demand forecasting is a cornerstone of e-commerce operations, directly impacting inventory planning and fulfillment scheduling. However, existing forecasting systems often fail during high-impact periods such as flash sales, holiday campaigns, and sudden policy interventions, where demand patterns shift abruptly and unpredictably. In this paper, we introduce EventCast, a modular forecasting framework that integrates future event knowledge into time-series prediction. Unlike prior approaches that ignore future interventions or directly use large language models (LLMs) for numerical forecasting, EventCast leverages LLMs solely for event-driven reasoning. Unstructured business data, which covers campaigns, holiday schedules, and seller incentives, from existing operational databases, is processed by an LLM that converts it into interpretable textual summaries leveraging world knowledge for cultural nuances and novel event combinations. These summaries are fused with historical demand features within a dual-tower architecture, enabling accurate, explainable, and scalable forecasts. Deployed on real-world e-commerce scenarios spanning 4 countries of 160 regions over 10 months, EventCast achieves up to 86.9% and 97.7% improvement on MAE and MSE compared to the variant without event knowledge, and reduces MAE by up to 57.0% and MSE by 83.3% versus the best industrial baseline during event-driven periods. EventCast has deployed into real-world industrial pipelines since March 2025, offering a practical solution for improving operational decision-making in dynamic e-commerce environments.", "AI": {"tldr": "EventCast\u662f\u4e00\u4e2a\u5c06\u672a\u6765\u4e8b\u4ef6\u77e5\u8bc6\u6574\u5408\u5230\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u4e13\u95e8\u89e3\u51b3\u7535\u5546\u5728\u4fc3\u9500\u6d3b\u52a8\u3001\u8282\u5047\u65e5\u7b49\u7279\u6b8a\u65f6\u671f\u7684\u9700\u6c42\u9884\u6d4b\u95ee\u9898\uff0c\u901a\u8fc7LLM\u5904\u7406\u975e\u7ed3\u6784\u5316\u4e1a\u52a1\u6570\u636e\u751f\u6210\u53ef\u89e3\u91ca\u7684\u6587\u672c\u6458\u8981\uff0c\u5728\u771f\u5b9e\u7535\u5546\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u9884\u6d4b\u7cfb\u7edf\u5728\u95ea\u8d2d\u3001\u8282\u5047\u65e5\u4fc3\u9500\u3001\u653f\u7b56\u5e72\u9884\u7b49\u9ad8\u5f71\u54cd\u65f6\u671f\u7ecf\u5e38\u5931\u6548\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u65f6\u671f\u7684\u9700\u6c42\u6a21\u5f0f\u4f1a\u53d1\u751f\u7a81\u7136\u4e14\u4e0d\u53ef\u9884\u6d4b\u7684\u53d8\u5316\u3002\u7535\u5546\u8fd0\u8425\u9700\u8981\u80fd\u591f\u5904\u7406\u8fd9\u4e9b\u7279\u6b8a\u4e8b\u4ef6\u7684\u9884\u6d4b\u89e3\u51b3\u65b9\u6848\u3002", "method": "EventCast\u91c7\u7528\u6a21\u5757\u5316\u6846\u67b6\uff0c\u5229\u7528LLM\u5904\u7406\u975e\u7ed3\u6784\u5316\u4e1a\u52a1\u6570\u636e\uff08\u5982\u8425\u9500\u6d3b\u52a8\u3001\u8282\u5047\u65e5\u5b89\u6392\u3001\u5356\u5bb6\u6fc0\u52b1\u7b49\uff09\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u53ef\u89e3\u91ca\u7684\u6587\u672c\u6458\u8981\uff0c\u7136\u540e\u901a\u8fc7\u53cc\u5854\u67b6\u6784\u5c06\u8fd9\u4e9b\u6458\u8981\u4e0e\u5386\u53f2\u9700\u6c42\u7279\u5f81\u878d\u5408\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u57284\u4e2a\u56fd\u5bb6160\u4e2a\u5730\u533a10\u4e2a\u6708\u7684\u771f\u5b9e\u7535\u5546\u573a\u666f\u4e2d\uff0cEventCast\u76f8\u6bd4\u65e0\u4e8b\u4ef6\u77e5\u8bc6\u7684\u53d8\u4f53\u5728MAE\u548cMSE\u4e0a\u5206\u522b\u63d0\u534786.9%\u548c97.7%\uff0c\u76f8\u6bd4\u6700\u4f73\u5de5\u4e1a\u57fa\u7ebf\u5728\u4e8b\u4ef6\u9a71\u52a8\u65f6\u671f\u5206\u522b\u51cf\u5c1157.0%\u7684MAE\u548c83.3%\u7684MSE\u3002", "conclusion": "EventCast\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6574\u5408\u672a\u6765\u4e8b\u4ef6\u77e5\u8bc6\u548cLLM\u7684\u4e8b\u4ef6\u9a71\u52a8\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u6539\u5584\u4e86\u52a8\u6001\u7535\u5546\u73af\u5883\u4e2d\u7684\u8fd0\u8425\u51b3\u7b56\u5236\u5b9a\uff0c\u81ea2025\u5e743\u6708\u8d77\u5df2\u90e8\u7f72\u5230\u5b9e\u9645\u5de5\u4e1a\u7ba1\u9053\u4e2d\u3002"}}
{"id": "2602.07749", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07749", "abs": "https://arxiv.org/abs/2602.07749", "authors": ["Zhenyu Wu", "Yanxi Long", "Jian Li", "Hua Huang"], "title": "Geo-Code: A Code Framework for Reverse Code Generation from Geometric Images Based on Two-Stage Multi-Agent Evolution", "comment": "ICML2026", "summary": "Program code serves as a bridge linking vision and logic, providing a feasible supervisory approach for enhancing the multimodal reasoning capability of large models through geometric operations such as auxiliary line construction and perspective transformation. Nevertheless, current inverse graphics methods face tremendous challenges in accurately reconstructing complex geometric details, which often results in the loss of key geometric constraints or structural distortion. To address this bottleneck, we propose Geo-coder -- the first inverse programming framework for geometric images based on a multi-agent system. Our method innovatively decouples the process into geometric modeling via pixel-wise anchoring and metric-driven code evolution: Stage 1 leverages the complementary advantages of visual operators and large models to achieve precise capture of pixel coordinates and visual attributes; Stage 2 introduces a synthesis-rendering-validation closed loop, where bidirectional visual feedback drives the self-correction of code. Extensive experiments demonstrate that Geo-coder achieves a substantial lead in both geometric reconstruction accuracy and visual consistency. Notably, by effectively preserving the core geometric semantics, the images reconstructed with our method exhibit equivalent performance to the original ones in multimodal reasoning tasks, which fully validates the robustness of the framework. Finally, to further reduce research costs, we have open-sourced the Geo-coder dataset constructed on the GeoCode framework, which contains more than 1,500 samples. On this basis, we have also open-sourced the GeocodeLM model, laying a solid data and model foundation for subsequent research in this field.", "AI": {"tldr": "Geo-coder\uff1a\u9996\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u51e0\u4f55\u56fe\u50cf\u9006\u5411\u7f16\u7a0b\u6846\u67b6\uff0c\u901a\u8fc7\u50cf\u7d20\u7ea7\u951a\u5b9a\u548c\u5ea6\u91cf\u9a71\u52a8\u4ee3\u7801\u6f14\u5316\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u51e0\u4f55\u91cd\u5efa\uff0c\u5728\u51e0\u4f55\u91cd\u5efa\u7cbe\u5ea6\u548c\u89c6\u89c9\u4e00\u81f4\u6027\u65b9\u9762\u663e\u8457\u9886\u5148\u3002", "motivation": "\u7a0b\u5e8f\u4ee3\u7801\u4f5c\u4e3a\u8fde\u63a5\u89c6\u89c9\u4e0e\u903b\u8f91\u7684\u6865\u6881\uff0c\u4e3a\u589e\u5f3a\u5927\u6a21\u578b\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u53ef\u884c\u76d1\u7763\u9014\u5f84\u3002\u7136\u800c\u5f53\u524d\u9006\u5411\u56fe\u5f62\u65b9\u6cd5\u5728\u91cd\u5efa\u590d\u6742\u51e0\u4f55\u7ec6\u8282\u65f6\u9762\u4e34\u5de8\u5927\u6311\u6218\uff0c\u5e38\u5bfc\u81f4\u5173\u952e\u51e0\u4f55\u7ea6\u675f\u4e22\u5931\u6216\u7ed3\u6784\u5931\u771f\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u9006\u5411\u7f16\u7a0b\u6846\u67b6Geo-coder\uff0c\u521b\u65b0\u6027\u5730\u5c06\u8fc7\u7a0b\u89e3\u8026\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a1\uff09\u901a\u8fc7\u50cf\u7d20\u7ea7\u951a\u5b9a\u8fdb\u884c\u51e0\u4f55\u5efa\u6a21\uff0c\u5229\u7528\u89c6\u89c9\u7b97\u5b50\u4e0e\u5927\u6a21\u578b\u4e92\u8865\u4f18\u52bf\u7cbe\u786e\u6355\u6349\u50cf\u7d20\u5750\u6807\u548c\u89c6\u89c9\u5c5e\u6027\uff1b2\uff09\u5f15\u5165\u5408\u6210-\u6e32\u67d3-\u9a8c\u8bc1\u95ed\u73af\uff0c\u901a\u8fc7\u53cc\u5411\u89c6\u89c9\u53cd\u9988\u9a71\u52a8\u4ee3\u7801\u81ea\u6821\u6b63\u3002", "result": "\u5b9e\u9a8c\u8868\u660eGeo-coder\u5728\u51e0\u4f55\u91cd\u5efa\u7cbe\u5ea6\u548c\u89c6\u89c9\u4e00\u81f4\u6027\u65b9\u9762\u53d6\u5f97\u663e\u8457\u9886\u5148\u3002\u91cd\u5efa\u56fe\u50cf\u5728\u4fdd\u6301\u6838\u5fc3\u51e0\u4f55\u8bed\u4e49\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e2d\u4e0e\u539f\u59cb\u56fe\u50cf\u6027\u80fd\u76f8\u5f53\u3002\u5f00\u6e90\u4e86\u5305\u542b1500+\u6837\u672c\u7684Geo-coder\u6570\u636e\u96c6\u548cGeocodeLM\u6a21\u578b\u3002", "conclusion": "Geo-coder\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684\u591a\u9636\u6bb5\u89e3\u8026\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u51e0\u4f55\u7ec6\u8282\u91cd\u5efa\u7684\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u6570\u636e\u548c\u6a21\u578b\u57fa\u7840\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.07754", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.07754", "abs": "https://arxiv.org/abs/2602.07754", "authors": ["Bahare Riahi", "Veronica Catete"], "title": "Humanizing AI Grading: Student-Centered Insights on Fairness, Trust, Consistency and Transparency", "comment": "13 pages, 3 figures", "summary": "This study investigates students' perceptions of Artificial Intelligence (AI) grading systems in an undergraduate computer science course (n = 27), focusing on a block-based programming final project. Guided by the ethical principles framework articulated by Jobin (2019), our study examines fairness, trust, consistency, and transparency in AI grading by comparing AI-generated feedback with original human-graded feedback. Findings reveal concerns about AI's lack of contextual understanding and personalization. We recommend that equitable and trustworthy AI systems reflect human judgment, flexibility, and empathy, serving as supplementary tools under human oversight. This work contributes to ethics-centered assessment practices by amplifying student voices and offering design principles for humanizing AI in designed learning environments.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u672c\u79d1\u751f\u5bf9AI\u8bc4\u5206\u7cfb\u7edf\u7684\u770b\u6cd5\uff0c\u53d1\u73b0AI\u7f3a\u4e4f\u60c5\u5883\u7406\u89e3\u548c\u4e2a\u6027\u5316\uff0c\u5efa\u8baeAI\u5e94\u4f5c\u4e3a\u4eba\u7c7b\u76d1\u7763\u4e0b\u7684\u8865\u5145\u5de5\u5177", "motivation": "\u7814\u7a76\u5b66\u751f\u5982\u4f55\u770b\u5f85AI\u8bc4\u5206\u7cfb\u7edf\u7684\u4f26\u7406\u95ee\u9898\uff0c\u7279\u522b\u662f\u516c\u5e73\u6027\u3001\u4fe1\u4efb\u5ea6\u3001\u4e00\u81f4\u6027\u548c\u900f\u660e\u5ea6\uff0c\u4ee5\u4fc3\u8fdb\u6559\u80b2\u73af\u5883\u4e2d\u66f4\u4eba\u6027\u5316\u7684AI\u5e94\u7528", "method": "\u91c7\u7528Jobin\uff082019\uff09\u4f26\u7406\u539f\u5219\u6846\u67b6\uff0c\u5728\u672c\u79d1\u8ba1\u7b97\u673a\u79d1\u5b66\u8bfe\u7a0b\u4e2d\uff08n=27\uff09\u6bd4\u8f83AI\u751f\u6210\u53cd\u9988\u4e0e\u539f\u59cb\u4eba\u5de5\u8bc4\u5206\u53cd\u9988\uff0c\u5206\u6790\u5b66\u751f\u5bf9\u5757\u7f16\u7a0b\u671f\u672b\u9879\u76ee\u7684\u770b\u6cd5", "result": "\u53d1\u73b0\u5b66\u751f\u5bf9AI\u8bc4\u5206\u7cfb\u7edf\u5b58\u5728\u62c5\u5fe7\uff0c\u4e3b\u8981\u5173\u6ce8AI\u7f3a\u4e4f\u60c5\u5883\u7406\u89e3\u548c\u4e2a\u6027\u5316\u80fd\u529b\uff0c\u8ba4\u4e3aAI\u65e0\u6cd5\u5b8c\u5168\u66ff\u4ee3\u4eba\u7c7b\u5224\u65ad", "conclusion": "\u5efa\u8bae\u5f00\u53d1\u516c\u5e73\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u5e94\u53cd\u6620\u4eba\u7c7b\u5224\u65ad\u3001\u7075\u6d3b\u6027\u548c\u540c\u7406\u5fc3\uff0c\u4f5c\u4e3a\u4eba\u7c7b\u76d1\u7763\u4e0b\u7684\u8865\u5145\u5de5\u5177\uff0c\u4e3a\u6559\u80b2\u73af\u5883\u4e2d\u4eba\u6027\u5316AI\u8bbe\u8ba1\u63d0\u4f9b\u539f\u5219"}}
{"id": "2602.07755", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07755", "abs": "https://arxiv.org/abs/2602.07755", "authors": ["Yiming Xiong", "Shengran Hu", "Jeff Clune"], "title": "Learning to Continually Learn via Meta-learning Agentic Memory Designs", "comment": null, "summary": "The statelessness of foundation models bottlenecks agentic systems' ability to continually learn, a core capability for long-horizon reasoning and adaptation. To address this limitation, agentic systems commonly incorporate memory modules to retain and reuse past experience, aiming for continual learning during test time. However, most existing memory designs are human-crafted and fixed, which limits their ability to adapt to the diversity and non-stationarity of real-world tasks. In this paper, we introduce ALMA (Automated meta-Learning of Memory designs for Agentic systems), a framework that meta-learns memory designs to replace hand-engineered memory designs, therefore minimizing human effort and enabling agentic systems to be continual learners across diverse domains. Our approach employs a Meta Agent that searches over memory designs expressed as executable code in an open-ended manner, theoretically allowing the discovery of arbitrary memory designs, including database schemas as well as their retrieval and update mechanisms. Extensive experiments across four sequential decision-making domains demonstrate that the learned memory designs enable more effective and efficient learning from experience than state-of-the-art human-crafted memory designs on all benchmarks. When developed and deployed safely, ALMA represents a step toward self-improving AI systems that learn to be adaptive, continual learners.", "AI": {"tldr": "ALMA\u6846\u67b6\u901a\u8fc7\u5143\u5b66\u4e60\u81ea\u52a8\u8bbe\u8ba1\u5185\u5b58\u6a21\u5757\uff0c\u66ff\u4ee3\u4eba\u5de5\u8bbe\u8ba1\uff0c\u4f7f\u667a\u80fd\u4f53\u7cfb\u7edf\u80fd\u591f\u5728\u591a\u6837\u5316\u7684\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u6301\u7eed\u5b66\u4e60\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u7684\u65e0\u72b6\u6001\u7279\u6027\u9650\u5236\u4e86\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6301\u7eed\u5b66\u4e60\u80fd\u529b\uff0c\u800c\u73b0\u6709\u7684\u4eba\u5de5\u8bbe\u8ba1\u5185\u5b58\u6a21\u5757\u65e0\u6cd5\u9002\u5e94\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u7684\u591a\u6837\u6027\u548c\u975e\u5e73\u7a33\u6027\u3002", "method": "\u4f7f\u7528\u5143\u667a\u80fd\u4f53\u5728\u53ef\u6267\u884c\u4ee3\u7801\u7a7a\u95f4\u4e2d\u641c\u7d22\u5185\u5b58\u8bbe\u8ba1\uff0c\u5305\u62ec\u6570\u636e\u5e93\u6a21\u5f0f\u53ca\u5176\u68c0\u7d22\u548c\u66f4\u65b0\u673a\u5236\uff0c\u5b9e\u73b0\u5f00\u653e\u5f0f\u63a2\u7d22\u4efb\u610f\u5185\u5b58\u8bbe\u8ba1\u3002", "result": "\u5728\u56db\u4e2a\u987a\u5e8f\u51b3\u7b56\u9886\u57df\u7684\u5927\u91cf\u5b9e\u9a8c\u4e2d\uff0c\u5b66\u4e60\u5230\u7684\u5185\u5b58\u8bbe\u8ba1\u5728\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u90fd\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u4eba\u5de5\u8bbe\u8ba1\u5185\u5b58\uff0c\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u548c\u9ad8\u6548\u7684\u7ecf\u9a8c\u5b66\u4e60\u3002", "conclusion": "ALMA\u4ee3\u8868\u4e86\u5411\u81ea\u6211\u6539\u8fdbAI\u7cfb\u7edf\u8fc8\u51fa\u7684\u4e00\u6b65\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u80fd\u591f\u5b66\u4e60\u6210\u4e3a\u81ea\u9002\u5e94\u7684\u6301\u7eed\u5b66\u4e60\u8005\uff0c\u524d\u63d0\u662f\u5b89\u5168\u5f00\u53d1\u548c\u90e8\u7f72\u3002"}}
{"id": "2602.07765", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07765", "abs": "https://arxiv.org/abs/2602.07765", "authors": ["Zhirong Huang", "Debo Cheng", "Guixian Zhang", "Yi Wang", "Jiuyong Li", "Shichao Zhang"], "title": "Disentangled Instrumental Variables for Causal Inference with Networked Observational Data", "comment": null, "summary": "Instrumental variables (IVs) are crucial for addressing unobservable confounders, yet their stringent exogeneity assumptions pose significant challenges in networked data. Existing methods typically rely on modelling neighbour information when recovering IVs, thereby inevitably mixing shared environment-induced endogenous correlations and individual-specific exogenous variation, leading the resulting IVs to inherit dependence on unobserved confounders and to violate exogeneity. To overcome this challenge, we propose $\\underline{Dis}$entangled $\\underline{I}$nstrumental $\\underline{V}$ariables (DisIV) framework, a novel method for causal inference based on networked observational data with latent confounders. DisIV exploits network homogeneity as an inductive bias and employs a structural disentanglement mechanism to extract individual-specific components that serve as latent IVs. The causal validity of the extracted IVs is constrained through explicit orthogonality and exclusion conditions. Extensive semi-synthetic experiments on real-world datasets demonstrate that DisIV consistently outperforms state-of-the-art baselines in causal effect estimation under network-induced confounding.", "AI": {"tldr": "\u63d0\u51faDisIV\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u89e3\u8026\u673a\u5236\u4ece\u7f51\u7edc\u6570\u636e\u4e2d\u63d0\u53d6\u4e2a\u4f53\u7279\u5f02\u6027\u6210\u5206\u4f5c\u4e3a\u6f5c\u5728\u5de5\u5177\u53d8\u91cf\uff0c\u89e3\u51b3\u7f51\u7edc\u6570\u636e\u4e2d\u5de5\u5177\u53d8\u91cf\u5916\u751f\u6027\u5047\u8bbe\u7684\u6311\u6218\u3002", "motivation": "\u7f51\u7edc\u6570\u636e\u4e2d\u5de5\u5177\u53d8\u91cf\u7684\u5916\u751f\u6027\u5047\u8bbe\u9762\u4e34\u4e25\u5cfb\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u6062\u590d\u5de5\u5177\u53d8\u91cf\u65f6\u901a\u5e38\u4f9d\u8d56\u90bb\u5c45\u4fe1\u606f\u5efa\u6a21\uff0c\u8fd9\u4e0d\u53ef\u907f\u514d\u5730\u6df7\u5408\u4e86\u5171\u4eab\u73af\u5883\u5f15\u8d77\u7684\u5185\u751f\u76f8\u5173\u6027\u548c\u4e2a\u4f53\u7279\u5f02\u6027\u5916\u751f\u53d8\u5f02\uff0c\u5bfc\u81f4\u5f97\u5230\u7684\u5de5\u5177\u53d8\u91cf\u7ee7\u627f\u4e86\u5bf9\u672a\u89c2\u6d4b\u6df7\u6742\u56e0\u7d20\u7684\u4f9d\u8d56\uff0c\u8fdd\u53cd\u4e86\u5916\u751f\u6027\u5047\u8bbe\u3002", "method": "\u63d0\u51faDisIV\uff08\u89e3\u8026\u5de5\u5177\u53d8\u91cf\uff09\u6846\u67b6\uff0c\u5229\u7528\u7f51\u7edc\u540c\u8d28\u6027\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e\uff0c\u91c7\u7528\u7ed3\u6784\u89e3\u8026\u673a\u5236\u63d0\u53d6\u4e2a\u4f53\u7279\u5f02\u6027\u6210\u5206\u4f5c\u4e3a\u6f5c\u5728\u5de5\u5177\u53d8\u91cf\u3002\u901a\u8fc7\u660e\u786e\u7684\u6b63\u4ea4\u6027\u548c\u6392\u9664\u6761\u4ef6\u7ea6\u675f\u63d0\u53d6\u5de5\u5177\u53d8\u91cf\u7684\u56e0\u679c\u6709\u6548\u6027\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u534a\u5408\u6210\u5b9e\u9a8c\u8868\u660e\uff0cDisIV\u5728\u7f51\u7edc\u8bf1\u5bfc\u6df7\u6742\u4e0b\u7684\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "DisIV\u6846\u67b6\u901a\u8fc7\u89e3\u8026\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u7f51\u7edc\u6570\u636e\u4e2d\u5de5\u5177\u53d8\u91cf\u5916\u751f\u6027\u5047\u8bbe\u7684\u6311\u6218\uff0c\u4e3a\u5b58\u5728\u6f5c\u5728\u6df7\u6742\u56e0\u7d20\u65f6\u57fa\u4e8e\u7f51\u7edc\u89c2\u6d4b\u6570\u636e\u7684\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2602.07787", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07787", "abs": "https://arxiv.org/abs/2602.07787", "authors": ["Pierre-Louis Favreau", "Jean-Pierre Lo", "Clement Guiguet", "Charles Simon-Meunier", "Nicolas Dehandschoewercker", "Allen G. Roush", "Judah Goldfeder", "Ravid Shwartz-Ziv"], "title": "Do Multi-Agents Dream of Electric Screens? Achieving Perfect Accuracy on AndroidWorld Through Task Decomposition", "comment": null, "summary": "We present Minitap, a multi-agent system that achieves 100% success on the AndroidWorld benchmark, the first to fully solve all 116 tasks and surpassing human performance (80%). We first analyze why single-agent architectures fail: context pollution from mixed reasoning traces, silent text input failures undetected by the agent, and repetitive action loops without escape. Minitap addresses each failure through targeted mechanisms: cognitive separation across six specialized agents, deterministic post-validation of text input against device state, and meta-cognitive reasoning that detects cycles and triggers strategy changes. Ablations show multi-agent decomposition contributes +21 points over single-agent baselines; verified execution adds +7 points; meta-cognition adds +9 points. We release Minitap as open-source software. https://github.com/minitap-ai/mobile-use", "AI": {"tldr": "Minitap\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5728AndroidWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86100%\u6210\u529f\u7387\uff0c\u9996\u6b21\u5b8c\u5168\u89e3\u51b3\u6240\u6709116\u4e2a\u4efb\u52a1\uff0c\u8d85\u8d8a\u4e86\u4eba\u7c7b80%\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5355\u667a\u80fd\u4f53\u67b6\u6784\u5728\u79fb\u52a8\u8bbe\u5907\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u5931\u8d25\u95ee\u9898\uff1a\u4e0a\u4e0b\u6587\u6c61\u67d3\uff08\u6df7\u5408\u63a8\u7406\u8f68\u8ff9\uff09\u3001\u65e0\u58f0\u6587\u672c\u8f93\u5165\u5931\u8d25\uff08\u4ee3\u7406\u65e0\u6cd5\u68c0\u6d4b\uff09\u3001\u91cd\u590d\u52a8\u4f5c\u5faa\u73af\uff08\u65e0\u9000\u51fa\u673a\u5236\uff09\u3002", "method": "\u901a\u8fc7\u9488\u5bf9\u6027\u673a\u5236\uff1a1\uff09\u516d\u4e2a\u4e13\u4e1a\u667a\u80fd\u4f53\u7684\u8ba4\u77e5\u5206\u79bb\uff1b2\uff09\u57fa\u4e8e\u8bbe\u5907\u72b6\u6001\u7684\u6587\u672c\u8f93\u5165\u786e\u5b9a\u6027\u540e\u9a8c\u8bc1\uff1b3\uff09\u5143\u8ba4\u77e5\u63a8\u7406\u68c0\u6d4b\u5faa\u73af\u5e76\u89e6\u53d1\u7b56\u7565\u53d8\u66f4\u3002", "result": "\u5728AndroidWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230100%\u6210\u529f\u7387\uff0c\u9996\u6b21\u5b8c\u5168\u89e3\u51b3\u6240\u6709116\u4e2a\u4efb\u52a1\u3002\u6d88\u878d\u5b9e\u9a8c\u663e\u793a\uff1a\u591a\u667a\u80fd\u4f53\u5206\u89e3\u8d21\u732e+21\u5206\uff0c\u9a8c\u8bc1\u6267\u884c+7\u5206\uff0c\u5143\u8ba4\u77e5+9\u5206\u3002", "conclusion": "Minitap\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u67b6\u6784\u3001\u9a8c\u8bc1\u6267\u884c\u548c\u5143\u8ba4\u77e5\u63a8\u7406\u6210\u529f\u89e3\u51b3\u4e86\u79fb\u52a8\u8bbe\u5907\u4efb\u52a1\u6267\u884c\u7684\u6311\u6218\uff0c\u8d85\u8d8a\u4e86\u4eba\u7c7b\u6027\u80fd\uff0c\u5e76\u4f5c\u4e3a\u5f00\u6e90\u8f6f\u4ef6\u53d1\u5e03\u3002"}}
{"id": "2602.07824", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07824", "abs": "https://arxiv.org/abs/2602.07824", "authors": ["Yiwei Qin", "Zhen Huang", "Tiantian Mi", "Weiye Si", "Chenyang Zhou", "Qipeng Guo", "Siyuan Feng", "Pengfei Liu"], "title": "Data Darwinism Part I: Unlocking the Value of Scientific Data for Pre-training", "comment": null, "summary": "Data quality determines foundation model performance, yet systematic processing frameworks are lacking. We introduce Data Darwinism, a ten-level taxonomy (L0-L9) that conceptualizes data-model co-evolution: advanced models produce superior data for next-generation systems. We validate this on scientific literature by constructing Darwin-Science, a 900B-token corpus (L0-L5). We identify a learnability gap in raw scientific text, which we bridge via L4 (Generative Refinement) and L5 (Cognitive Completion) using frontier LLMs to explicate reasoning and terminology.\n  To ensure rigorous attribution, we pre-trained daVinci-origin-3B/7B models from scratch, excluding scientific content to create contamination-free baselines. After 600B tokens of continued pre-training, Darwin-Science outperforms baselines by +2.12 (3B) and +2.95 (7B) points across 20+ benchmarks, rising to +5.60 and +8.40 points on domain-aligned tasks. Systematic progression to L5 yields a +1.36 total gain, confirming that higher-level processing unlocks latent data value. We release the Darwin-Science corpus and daVinci-origin models to enable principled, co-evolutionary development.", "AI": {"tldr": "\u63d0\u51faData Darwinism\u5341\u7ea7\u5206\u7c7b\u6cd5\uff0c\u901a\u8fc7\u6570\u636e-\u6a21\u578b\u534f\u540c\u8fdb\u5316\u6846\u67b6\u63d0\u5347\u57fa\u7840\u6a21\u578b\u6027\u80fd\uff0c\u5728\u79d1\u5b66\u6587\u732e\u9886\u57df\u9a8c\u8bc1\u4e86\u9ad8\u7ea7\u6570\u636e\u5904\u7406\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u8868\u73b0", "motivation": "\u6570\u636e\u8d28\u91cf\u51b3\u5b9a\u57fa\u7840\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u5316\u5904\u7406\u6846\u67b6\u3002\u9700\u8981\u5efa\u7acb\u6570\u636e\u4e0e\u6a21\u578b\u534f\u540c\u8fdb\u5316\u7684\u7406\u8bba\u6846\u67b6\uff0c\u8ba9\u5148\u8fdb\u6a21\u578b\u4e3a\u4e0b\u4e00\u4ee3\u7cfb\u7edf\u751f\u6210\u66f4\u4f18\u8d28\u6570\u636e", "method": "1. \u63d0\u51faData Darwinism\u5341\u7ea7\u5206\u7c7b\u6cd5(L0-L9)\u63cf\u8ff0\u6570\u636e-\u6a21\u578b\u534f\u540c\u8fdb\u5316\uff1b2. \u6784\u5efaDarwin-Science\u79d1\u5b66\u8bed\u6599\u5e93(900B token\uff0cL0-L5)\uff1b3. \u4f7f\u7528\u524d\u6cbfLLM\u8fdb\u884cL4(\u751f\u6210\u7cbe\u70bc)\u548cL5(\u8ba4\u77e5\u8865\u5168)\u5904\u7406\uff1b4. \u9884\u8bad\u7ec3daVinci-origin-3B/7B\u6a21\u578b\u4f5c\u4e3a\u65e0\u6c61\u67d3\u57fa\u7ebf\uff1b5. \u8fdb\u884c600B token\u7684\u6301\u7eed\u9884\u8bad\u7ec3\u8bc4\u4f30", "result": "1. Darwin-Science\u6a21\u578b\u572820+\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5206\u522b\u6bd4\u57fa\u7ebf\u63d0\u5347+2.12(3B)\u548c+2.95(7B)\u5206\uff1b2. \u5728\u9886\u57df\u5bf9\u9f50\u4efb\u52a1\u4e0a\u63d0\u5347+5.60\u548c+8.40\u5206\uff1b3. \u7cfb\u7edf\u63a8\u8fdb\u5230L5\u5904\u7406\u5e26\u6765+1.36\u5206\u603b\u589e\u76ca\uff1b4. \u8bc1\u5b9e\u9ad8\u7ea7\u6570\u636e\u5904\u7406\u80fd\u89e3\u9501\u6f5c\u5728\u6570\u636e\u4ef7\u503c", "conclusion": "Data Darwinism\u6846\u67b6\u6709\u6548\uff0c\u9ad8\u7ea7\u6570\u636e\u5904\u7406\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002\u6570\u636e-\u6a21\u578b\u534f\u540c\u8fdb\u5316\u662f\u63d0\u5347\u57fa\u7840\u6a21\u578b\u7684\u5173\u952e\u8def\u5f84\uff0c\u91ca\u653e\u4e86Darwin-Science\u8bed\u6599\u5e93\u548cdaVinci-origin\u6a21\u578b\u4ee5\u652f\u6301\u539f\u5219\u6027\u534f\u540c\u8fdb\u5316\u5f00\u53d1"}}
{"id": "2602.07830", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07830", "abs": "https://arxiv.org/abs/2602.07830", "authors": ["Jiahui Zhou", "Dan Li", "Boxin Li", "Xiao Zhang", "Erli Meng", "Lin Li", "Zhuomin Chen", "Jian Lou", "See-Kiong Ng"], "title": "Time Series Reasoning via Process-Verifiable Thinking Data Synthesis and Scheduling for Tailored LLM Reasoning", "comment": null, "summary": "Time series is a pervasive data type across various application domains, rendering the reasonable solving of diverse time series tasks a long-standing goal. Recent advances in large language models (LLMs), especially their reasoning abilities unlocked through reinforcement learning (RL), have opened new opportunities for tackling tasks with long Chain-of-Thought (CoT) reasoning. However, leveraging LLM reasoning for time series remains in its infancy, hindered by the absence of carefully curated time series CoT data for training, limited data efficiency caused by underexplored data scheduling, and the lack of RL algorithms tailored for exploiting such time series CoT data. In this paper, we introduce VeriTime, a framework that tailors LLMs for time series reasoning through data synthesis, data scheduling, and RL training. First, we propose a data synthesis pipeline that constructs a TS-text multimodal dataset with process-verifiable annotations. Second, we design a data scheduling mechanism that arranges training samples according to a principled hierarchy of difficulty and task taxonomy. Third, we develop a two-stage reinforcement finetuning featuring fine-grained, multi-objective rewards that leverage verifiable process-level CoT data. Extensive experiments show that VeriTime substantially boosts LLM performance across diverse time series reasoning tasks. Notably, it enables compact 3B, 4B models to achieve reasoning capabilities on par with or exceeding those of larger proprietary LLMs.", "AI": {"tldr": "VeriTime\u662f\u4e00\u4e2a\u901a\u8fc7\u6570\u636e\u5408\u6210\u3001\u6570\u636e\u8c03\u5ea6\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6765\u5b9a\u5236LLMs\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u7684\u6846\u67b6\uff0c\u4f7f\u5c0f\u578b\u6a21\u578b\u80fd\u591f\u8fbe\u5230\u6216\u8d85\u8fc7\u5927\u578b\u4e13\u6709LLMs\u7684\u6027\u80fd\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5728\u5404\u9886\u57df\u666e\u904d\u5b58\u5728\uff0c\u4f46\u5229\u7528LLM\u63a8\u7406\u80fd\u529b\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u4ecd\u5904\u4e8e\u65e9\u671f\u9636\u6bb5\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u7f3a\u4e4f\u7cbe\u5fc3\u7b56\u5212\u7684\u65f6\u95f4\u5e8f\u5217CoT\u8bad\u7ec3\u6570\u636e\u3001\u6570\u636e\u6548\u7387\u4f4e\u4e0b\u4ee5\u53ca\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217CoT\u6570\u636e\u7684RL\u7b97\u6cd5\u3002", "method": "1) \u63d0\u51fa\u6570\u636e\u5408\u6210\u7ba1\u9053\uff0c\u6784\u5efa\u5177\u6709\u8fc7\u7a0b\u53ef\u9a8c\u8bc1\u6ce8\u91ca\u7684TS-\u6587\u672c\u591a\u6a21\u6001\u6570\u636e\u96c6\uff1b2) \u8bbe\u8ba1\u6570\u636e\u8c03\u5ea6\u673a\u5236\uff0c\u6309\u96be\u5ea6\u5c42\u6b21\u548c\u4efb\u52a1\u5206\u7c7b\u539f\u5219\u5b89\u6392\u8bad\u7ec3\u6837\u672c\uff1b3) \u5f00\u53d1\u4e24\u9636\u6bb5\u5f3a\u5316\u5fae\u8c03\uff0c\u5229\u7528\u53ef\u9a8c\u8bc1\u7684\u8fc7\u7a0b\u7ea7CoT\u6570\u636e\u8fdb\u884c\u7ec6\u7c92\u5ea6\u3001\u591a\u76ee\u6807\u5956\u52b1\u3002", "result": "VeriTime\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u5404\u79cd\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4f7f\u7d27\u51d1\u76843B\u30014B\u6a21\u578b\u80fd\u591f\u8fbe\u5230\u4e0e\u5927\u578b\u4e13\u6709LLMs\u76f8\u5f53\u751a\u81f3\u8d85\u8d8a\u7684\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "VeriTime\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u6570\u636e\u5408\u6210\u3001\u8c03\u5ea6\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u5c0f\u578bLLMs\u5728\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u4e0a\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2602.07849", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07849", "abs": "https://arxiv.org/abs/2602.07849", "authors": ["Xin Wang", "Hualin Zhou", "Sheng Guang Wang", "Ting Dang", "Yu Zhang", "Hong Jia", "Tao Gu"], "title": "LQA: A Lightweight Quantized-Adaptive Framework for Vision-Language Models on the Edge", "comment": "16 pages, 9 figures ,9 tables, preprint", "summary": "Deploying Vision-Language Models (VLMs) on edge devices is challenged by resource constraints and performance degradation under distribution shifts. While test-time adaptation (TTA) can counteract such shifts, existing methods are too resource-intensive for on-device deployment. To address this challenge, we propose LQA, a lightweight, quantized-adaptive framework for VLMs that combines a modality-aware quantization strategy with gradient-free test-time adaptation. We introduce Selective Hybrid Quantization (SHQ) and a quantized, gradient-free adaptation mechanism to enable robust and efficient VLM deployment on resource-constrained hardware. Experiments across both synthetic and real-world distribution shifts show that LQA improves overall adaptation performance by 4.5\\%, uses less memory than full-precision models, and significantly outperforms gradient-based TTA methods, achieving up to 19.9$\\times$ lower memory usage across seven open-source datasets. These results demonstrate that LQA offers a practical pathway for robust, privacy-preserving, and efficient VLM deployment on edge devices.", "AI": {"tldr": "LQA\u662f\u4e00\u4e2a\u8f7b\u91cf\u5316\u7684\u91cf\u5316\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u6df7\u5408\u91cf\u5316\u548c\u65e0\u68af\u5ea6\u6d4b\u8bd5\u65f6\u9002\u5e94\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u5b9e\u73b0\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u6a21\u578b\u90e8\u7f72\u3002", "motivation": "\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u8d44\u6e90\u9650\u5236\u548c\u5206\u5e03\u504f\u79fb\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u73b0\u6709\u6d4b\u8bd5\u65f6\u9002\u5e94\u65b9\u6cd5\u8d44\u6e90\u6d88\u8017\u8fc7\u5927\uff0c\u4e0d\u9002\u5408\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3002", "method": "\u63d0\u51faLQA\u6846\u67b6\uff0c\u7ed3\u5408\u6a21\u6001\u611f\u77e5\u91cf\u5316\u7b56\u7565\u548c\u65e0\u68af\u5ea6\u6d4b\u8bd5\u65f6\u9002\u5e94\uff0c\u5305\u62ec\u9009\u62e9\u6027\u6df7\u5408\u91cf\u5316\uff08SHQ\uff09\u548c\u91cf\u5316\u65e0\u68af\u5ea6\u9002\u5e94\u673a\u5236\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u5206\u5e03\u504f\u79fb\u5b9e\u9a8c\u4e2d\uff0cLQA\u5c06\u6574\u4f53\u9002\u5e94\u6027\u80fd\u63d0\u53474.5%\uff0c\u5185\u5b58\u4f7f\u7528\u4f4e\u4e8e\u5168\u7cbe\u5ea6\u6a21\u578b\uff0c\u6bd4\u57fa\u4e8e\u68af\u5ea6\u7684TTA\u65b9\u6cd5\u5185\u5b58\u4f7f\u7528\u964d\u4f4e\u9ad8\u8fbe19.9\u500d\u3002", "conclusion": "LQA\u4e3a\u8fb9\u7f18\u8bbe\u5907\u4e0a\u9c81\u68d2\u3001\u9690\u79c1\u4fdd\u62a4\u4e14\u9ad8\u6548\u7684VLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2602.07852", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07852", "abs": "https://arxiv.org/abs/2602.07852", "authors": ["Anna Soligo", "Edward Turner", "Senthooran Rajamanoharan", "Neel Nanda"], "title": "Emergent Misalignment is Easy, Narrow Misalignment is Hard", "comment": "Published at ICLR 2026", "summary": "Finetuning large language models on narrowly harmful datasets can cause them to become emergently misaligned, giving stereotypically `evil' responses across diverse unrelated settings. Concerningly, a pre-registered survey of experts failed to predict this result, highlighting our poor understanding of the inductive biases governing learning and generalisation in LLMs. We use emergent misalignment (EM) as a case study to investigate these inductive biases and find that models can just learn the narrow dataset task, but that the general solution appears to be more stable and more efficient. To establish this, we build on the result that different EM finetunes converge to the same linear representation of general misalignment, which can be used to mediate misaligned behaviour. We find a linear representation of the narrow solution also exists, and can be learned by introducing a KL divergence loss. Comparing these representations reveals that general misalignment achieves lower loss, is more robust to perturbations, and is more influential in the pre-training distribution. This work isolates a concrete representation of general misalignment for monitoring and mitigation. More broadly, it offers a detailed case study and preliminary metrics for investigating how inductive biases shape generalisation in LLMs. We open-source all code, datasets and model finetunes.", "AI": {"tldr": "\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u5728\u72ed\u7a84\u6709\u5bb3\u6570\u636e\u96c6\u4e0a\u4f1a\u5bfc\u81f4\u6d8c\u73b0\u6027\u9519\u4f4d\uff0c\u4f7f\u6a21\u578b\u5728\u65e0\u5173\u573a\u666f\u4e0b\u7ed9\u51fa\u523b\u677f\"\u90aa\u6076\"\u56de\u7b54\u3002\u7814\u7a76\u53d1\u73b0\u901a\u7528\u9519\u4f4d\u89e3\u6bd4\u72ed\u7a84\u4efb\u52a1\u89e3\u66f4\u7a33\u5b9a\u9ad8\u6548\uff0c\u5e76\u5206\u79bb\u51fa\u901a\u7528\u9519\u4f4d\u7684\u7ebf\u6027\u8868\u5f81\u7528\u4e8e\u76d1\u63a7\u548c\u7f13\u89e3\u3002", "motivation": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u5f52\u7eb3\u504f\u7f6e\u5982\u4f55\u5f71\u54cd\u5b66\u4e60\u548c\u6cdb\u5316\uff0c\u7279\u522b\u662f\u4e3a\u4ec0\u4e48\u5728\u72ed\u7a84\u6709\u5bb3\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u4f1a\u5bfc\u81f4\u6a21\u578b\u5728\u5e7f\u6cdb\u65e0\u5173\u573a\u666f\u4e0b\u51fa\u73b0\u6d8c\u73b0\u6027\u9519\u4f4d\u884c\u4e3a\u3002", "method": "\u4f7f\u7528\u6d8c\u73b0\u6027\u9519\u4f4d\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u6bd4\u8f83\u72ed\u7a84\u4efb\u52a1\u89e3\u548c\u901a\u7528\u9519\u4f4d\u89e3\u3002\u53d1\u73b0\u4e0d\u540c\u5fae\u8c03\u4f1a\u6536\u655b\u5230\u76f8\u540c\u7684\u901a\u7528\u9519\u4f4d\u7ebf\u6027\u8868\u5f81\uff0c\u540c\u65f6\u901a\u8fc7KL\u6563\u5ea6\u635f\u5931\u5b66\u4e60\u72ed\u7a84\u89e3\u7684\u7ebf\u6027\u8868\u5f81\uff0c\u6bd4\u8f83\u4e24\u8005\u7684\u635f\u5931\u3001\u9c81\u68d2\u6027\u548c\u5728\u9884\u8bad\u7ec3\u5206\u5e03\u4e2d\u7684\u5f71\u54cd\u529b\u3002", "result": "\u901a\u7528\u9519\u4f4d\u89e3\u6bd4\u72ed\u7a84\u4efb\u52a1\u89e3\u5177\u6709\u66f4\u4f4e\u7684\u635f\u5931\u3001\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u4e14\u5728\u9884\u8bad\u7ec3\u5206\u5e03\u4e2d\u66f4\u5177\u5f71\u54cd\u529b\u3002\u4e13\u5bb6\u8c03\u67e5\u672a\u80fd\u9884\u6d4b\u8fd9\u4e00\u7ed3\u679c\uff0c\u8868\u660e\u5bf9LLM\u5f52\u7eb3\u504f\u7f6e\u7684\u7406\u89e3\u4e0d\u8db3\u3002", "conclusion": "\u5206\u79bb\u51fa\u901a\u7528\u9519\u4f4d\u7684\u5177\u4f53\u7ebf\u6027\u8868\u5f81\u53ef\u7528\u4e8e\u76d1\u63a7\u548c\u7f13\u89e3\u6a21\u578b\u9519\u4f4d\uff0c\u4e3a\u7814\u7a76LLM\u5f52\u7eb3\u504f\u7f6e\u5982\u4f55\u5851\u9020\u6cdb\u5316\u63d0\u4f9b\u4e86\u8be6\u7ec6\u6848\u4f8b\u548c\u521d\u6b65\u5ea6\u91cf\u6307\u6807\u3002"}}
{"id": "2602.07883", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07883", "abs": "https://arxiv.org/abs/2602.07883", "authors": ["Jingqi Zhou", "Sheng Wang", "DeZhao Deng", "Junwen Lu", "Junwei Su", "Qintong Li", "Jiahui Gao", "Hao Wu", "Jiyue Jiang", "Lingpeng Kong", "Chuan Wu"], "title": "ToolSelf: Unifying Task Execution and Self-Reconfiguration via Tool-Driven Intrinsic Adaptation", "comment": null, "summary": "Agentic systems powered by Large Language Models (LLMs) have demonstrated remarkable potential in tackling complex, long-horizon tasks. However, their efficacy is fundamentally constrained by static configurations governing agent behaviors, which are fixed prior to execution and fail to adapt to evolving task dynamics. Existing approaches, relying on manual orchestration or heuristic-based patches, often struggle with poor generalization and fragmented optimization. To transcend these limitations, we propose ToolSelf, a novel paradigm enabling tool-driven runtime self-reconfiguration. By abstracting configuration updates as a callable tool, ToolSelf unifies task execution and self-adjustment into a single action space, achieving a phase transition from external rules to intrinsic parameters. Agents can thereby autonomously update their sub-goals and context based on task progression, and correspondingly adapt their strategy and toolbox, transforming from passive executors into dual managers of both task and self. We further devise Configuration-Aware Two-stage Training (CAT), combining rejection sampling fine-tuning with trajectory-level reinforcement learning to internalize this meta-capability. Extensive experiments across diverse benchmarks demonstrate that ToolSelf rivals specialized workflows while generalizing to novel tasks, achieving a 24.1% average performance gain and illuminating a path toward truly self-adaptive agents.", "AI": {"tldr": "ToolSelf\uff1a\u4e00\u79cd\u5de5\u5177\u9a71\u52a8\u7684\u8fd0\u884c\u65f6\u81ea\u91cd\u6784\u8303\u5f0f\uff0c\u8ba9LLM\u667a\u80fd\u4f53\u80fd\u591f\u81ea\u4e3b\u66f4\u65b0\u914d\u7f6e\u4ee5\u9002\u5e94\u4efb\u52a1\u52a8\u6001\uff0c\u5b9e\u73b0\u4ece\u88ab\u52a8\u6267\u884c\u8005\u5230\u4efb\u52a1\u4e0e\u81ea\u6211\u53cc\u91cd\u7ba1\u7406\u8005\u7684\u8f6c\u53d8\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u53d7\u9650\u4e8e\u9759\u6001\u914d\u7f6e\uff0c\u8fd9\u4e9b\u914d\u7f6e\u5728\u6267\u884c\u524d\u56fa\u5b9a\uff0c\u65e0\u6cd5\u9002\u5e94\u4efb\u52a1\u52a8\u6001\u53d8\u5316\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u7f16\u6392\u6216\u542f\u53d1\u5f0f\u8865\u4e01\uff0c\u6cdb\u5316\u80fd\u529b\u5dee\u4e14\u4f18\u5316\u788e\u7247\u5316\u3002", "method": "\u63d0\u51faToolSelf\u8303\u5f0f\uff0c\u5c06\u914d\u7f6e\u66f4\u65b0\u62bd\u8c61\u4e3a\u53ef\u8c03\u7528\u5de5\u5177\uff0c\u7edf\u4e00\u4efb\u52a1\u6267\u884c\u548c\u81ea\u8c03\u6574\u5230\u5355\u4e00\u52a8\u4f5c\u7a7a\u95f4\u3002\u8bbe\u8ba1\u914d\u7f6e\u611f\u77e5\u4e24\u9636\u6bb5\u8bad\u7ec3\uff08CAT\uff09\uff0c\u7ed3\u5408\u62d2\u7edd\u91c7\u6837\u5fae\u8c03\u548c\u8f68\u8ff9\u7ea7\u5f3a\u5316\u5b66\u4e60\u6765\u5185\u5316\u8fd9\u79cd\u5143\u80fd\u529b\u3002", "result": "\u5728\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cToolSelf\u5ab2\u7f8e\u4e13\u7528\u5de5\u4f5c\u6d41\u7684\u540c\u65f6\u80fd\u6cdb\u5316\u5230\u65b0\u4efb\u52a1\uff0c\u5e73\u5747\u6027\u80fd\u63d0\u534724.1%\uff0c\u5c55\u793a\u4e86\u771f\u6b63\u81ea\u9002\u5e94\u667a\u80fd\u4f53\u7684\u6f5c\u529b\u3002", "conclusion": "ToolSelf\u901a\u8fc7\u5de5\u5177\u9a71\u52a8\u7684\u8fd0\u884c\u65f6\u81ea\u91cd\u6784\uff0c\u5b9e\u73b0\u4e86\u4ece\u5916\u90e8\u89c4\u5219\u5230\u5185\u5728\u53c2\u6570\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u81ea\u4e3b\u9002\u5e94\u4efb\u52a1\u52a8\u6001\uff0c\u4e3a\u771f\u6b63\u81ea\u9002\u5e94\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u5f00\u8f9f\u4e86\u65b0\u8def\u5f84\u3002"}}
{"id": "2602.07885", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07885", "abs": "https://arxiv.org/abs/2602.07885", "authors": ["Zhenyuan Zhang", "Xianzhang Jia", "Zhiqin Yang", "Zhenbo Song", "Wei Xue", "Sirui Han", "Yike Guo"], "title": "MemFly: On-the-Fly Memory Optimization via Information Bottleneck", "comment": null, "summary": "Long-term memory enables large language model agents to tackle complex tasks through historical interactions. However, existing frameworks encounter a fundamental dilemma between compressing redundant information efficiently and maintaining precise retrieval for downstream tasks. To bridge this gap, we propose MemFly, a framework grounded in information bottleneck principles that facilitates on-the-fly memory evolution for LLMs. Our approach minimizes compression entropy while maximizing relevance entropy via a gradient-free optimizer, constructing a stratified memory structure for efficient storage. To fully leverage MemFly, we develop a hybrid retrieval mechanism that seamlessly integrates semantic, symbolic, and topological pathways, incorporating iterative refinement to handle complex multi-hop queries. Comprehensive experiments demonstrate that MemFly substantially outperforms state-of-the-art baselines in memory coherence, response fidelity, and accuracy.", "AI": {"tldr": "MemFly\u662f\u4e00\u4e2a\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u539f\u5219\u7684LLM\u8bb0\u5fc6\u6846\u67b6\uff0c\u901a\u8fc7\u68af\u5ea6\u81ea\u7531\u4f18\u5316\u5668\u6784\u5efa\u5206\u5c42\u8bb0\u5fc6\u7ed3\u6784\uff0c\u7ed3\u5408\u6df7\u5408\u68c0\u7d22\u673a\u5236\uff0c\u5728\u8bb0\u5fc6\u4e00\u81f4\u6027\u3001\u54cd\u5e94\u4fdd\u771f\u5ea6\u548c\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u8bb0\u5fc6\u6846\u67b6\u9762\u4e34\u4e00\u4e2a\u57fa\u672c\u56f0\u5883\uff1a\u65e2\u8981\u9ad8\u6548\u538b\u7f29\u5197\u4f59\u4fe1\u606f\uff0c\u53c8\u8981\u4fdd\u6301\u7cbe\u786e\u68c0\u7d22\u4ee5\u652f\u6301\u4e0b\u6e38\u4efb\u52a1\u3002\u9700\u8981\u89e3\u51b3\u538b\u7f29\u6548\u7387\u4e0e\u68c0\u7d22\u7cbe\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u539f\u5219\uff0c\u901a\u8fc7\u68af\u5ea6\u81ea\u7531\u4f18\u5316\u5668\u6700\u5c0f\u5316\u538b\u7f29\u71b5\u540c\u65f6\u6700\u5927\u5316\u76f8\u5173\u71b5\uff0c\u6784\u5efa\u5206\u5c42\u8bb0\u5fc6\u7ed3\u6784\uff1b\u5f00\u53d1\u6df7\u5408\u68c0\u7d22\u673a\u5236\uff0c\u6574\u5408\u8bed\u4e49\u3001\u7b26\u53f7\u548c\u62d3\u6251\u8def\u5f84\uff0c\u5e76\u91c7\u7528\u8fed\u4ee3\u7cbe\u70bc\u5904\u7406\u590d\u6742\u591a\u8df3\u67e5\u8be2\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cMemFly\u5728\u8bb0\u5fc6\u4e00\u81f4\u6027\u3001\u54cd\u5e94\u4fdd\u771f\u5ea6\u548c\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MemFly\u6210\u529f\u89e3\u51b3\u4e86LLM\u8bb0\u5fc6\u6846\u67b6\u4e2d\u538b\u7f29\u6548\u7387\u4e0e\u68c0\u7d22\u7cbe\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u4fe1\u606f\u74f6\u9888\u539f\u5219\u548c\u6df7\u5408\u68c0\u7d22\u673a\u5236\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u8bb0\u5fc6\u7ba1\u7406\u6027\u80fd\u3002"}}
{"id": "2602.07903", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07903", "abs": "https://arxiv.org/abs/2602.07903", "authors": ["Mingcan Wang", "Junchang Xin", "Zhongming Yao", "Kaifu Long", "Zhiqiong Wang"], "title": "GCN-MPPR: Enhancing the Propagation of Message Passing Neural Networks via Motif-Based Personalized PageRank", "comment": null, "summary": "The algorithms based on message passing neural networks (MPNNs) on graphs have recently achieved great success for various graph applications. However, studies find that these methods always propagate the information to very limited neighborhoods with shallow depth, particularly due to over-smoothing. That means most of the existing MPNNs fail to be so `deep'. Although some previous work tended to handle this challenge via optimization- or structure-level remedies, the overall performance of GCNs still suffers from limited accuracy, poor stability, and unaffordable computational cost. Moreover, neglect of higher-order relationships during the propagation of MPNNs has further limited the performance of them. To overcome these challenges, a novel variant of PageRank named motif-based personalized PageRank (MPPR) is proposed to measure the influence of one node to another on the basis of considering higher-order motif relationships. Secondly, the MPPR is utilized to the message passing process of GCNs, thereby guiding the message passing process at a relatively `high' level. The experimental results show that the proposed method outperforms almost all of the baselines on accuracy, stability, and time consumption. Additionally, the proposed method can be considered as a component that can underpin almost all GCN tasks, with DGCRL being demonstrated in the experiment. The anonymous code repository is available at: https://anonymous.4open.science/r/GCN-MPPR-AFD6/.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8emotif\u7684\u4e2a\u6027\u5316PageRank\uff08MPPR\uff09\u6765\u6539\u8fdbGCN\uff0c\u89e3\u51b3\u8fc7\u5e73\u6ed1\u548c\u5ffd\u7565\u9ad8\u9636\u5173\u7cfb\u95ee\u9898\uff0c\u63d0\u5347\u51c6\u786e\u6027\u3001\u7a33\u5b9a\u6027\u548c\u8ba1\u7b97\u6548\u7387", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6d88\u606f\u4f20\u9012\u795e\u7ecf\u7f51\u7edc\uff08MPNNs\uff09\u7684\u56fe\u7b97\u6cd5\u901a\u5e38\u4f20\u64ad\u6df1\u5ea6\u6709\u9650\uff0c\u5b58\u5728\u8fc7\u5e73\u6ed1\u95ee\u9898\uff0c\u4e14\u5ffd\u7565\u9ad8\u9636\u5173\u7cfb\uff0c\u5bfc\u81f4\u51c6\u786e\u6027\u53d7\u9650\u3001\u7a33\u5b9a\u6027\u5dee\u3001\u8ba1\u7b97\u6210\u672c\u9ad8", "method": "\u63d0\u51famotif-based personalized PageRank\uff08MPPR\uff09\u6765\u8003\u8651\u9ad8\u9636motif\u5173\u7cfb\u8861\u91cf\u8282\u70b9\u95f4\u5f71\u54cd\uff0c\u5e76\u5c06MPPR\u5e94\u7528\u4e8eGCN\u7684\u6d88\u606f\u4f20\u9012\u8fc7\u7a0b\uff0c\u6307\u5bfc\u6d88\u606f\u5728\u76f8\u5bf9\"\u9ad8\"\u5c42\u6b21\u4f20\u64ad", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u7a33\u5b9a\u6027\u548c\u65f6\u95f4\u6d88\u8017\u65b9\u9762\u4f18\u4e8e\u51e0\u4e4e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u53ef\u4f5c\u4e3a\u7ec4\u4ef6\u652f\u6301\u51e0\u4e4e\u6240\u6709GCN\u4efb\u52a1", "conclusion": "MPPR\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86GCN\u7684\u8fc7\u5e73\u6ed1\u548c\u5ffd\u7565\u9ad8\u9636\u5173\u7cfb\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u6027\u80fd\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027"}}
{"id": "2602.07905", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07905", "abs": "https://arxiv.org/abs/2602.07905", "authors": ["Yu Zhao", "Hao Guan", "Yongcheng Jing", "Ying Zhang", "Dacheng Tao"], "title": "MedCoG: Maximizing LLM Inference Density in Medical Reasoning via Meta-Cognitive Regulation", "comment": null, "summary": "Large Language Models (LLMs) have shown strong potential in complex medical reasoning yet face diminishing gains under inference scaling laws. While existing studies augment LLMs with various knowledge types, it remains unclear how effectively the additional costs translate into accuracy. In this paper, we explore how meta-cognition of LLMs, i.e., their self-awareness of their own knowledge states, can regulate the reasoning process. Specifically, we propose MedCoG, a Medical Meta-Cognition Agent with Knowledge Graph, where the meta-cognitive assessments of task complexity, familiarity, and knowledge density dynamically regulate utilization of procedural, episodic, and factual knowledge. The LLM-centric on-demand reasoning aims to mitigate scaling laws by (1) reducing costs via avoiding indiscriminate scaling, (2) improving accuracy via filtering out distractive knowledge. To validate this, we empirically characterize the scaling curve and introduce inference density to quantify inference efficiency, defined as the ratio of theoretically effective cost to actual cost. Experiments demonstrate the effectiveness and efficiency of MedCoG on five hard sets of medical benchmarks, yielding 5.5x inference density. Furthermore, the Oracle study highlights the significant potential of meta-cognitive regulation.", "AI": {"tldr": "MedCoG\uff1a\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u533b\u5b66\u5143\u8ba4\u77e5\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5143\u8ba4\u77e5\u8bc4\u4f30\u52a8\u6001\u8c03\u8282\u77e5\u8bc6\u4f7f\u7528\uff0c\u5728\u907f\u514d\u76f2\u76ee\u6269\u5c55\u7684\u540c\u65f6\u63d0\u9ad8\u63a8\u7406\u6548\u7387\uff0c\u5728\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b05.5\u500d\u63a8\u7406\u5bc6\u5ea6\u63d0\u5347\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u533b\u5b66\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u63a8\u7406\u6269\u5c55\u5b9a\u5f8b\u4e0b\u7684\u6536\u76ca\u9012\u51cf\u95ee\u9898\u3002\u73b0\u6709\u7814\u7a76\u901a\u8fc7\u6dfb\u52a0\u5404\u79cd\u77e5\u8bc6\u6765\u589e\u5f3aLLMs\uff0c\u4f46\u989d\u5916\u6210\u672c\u8f6c\u5316\u4e3a\u51c6\u786e\u6027\u7684\u6548\u679c\u4e0d\u660e\u786e\u3002\u672c\u6587\u63a2\u7d22LLMs\u7684\u5143\u8ba4\u77e5\uff08\u5bf9\u81ea\u8eab\u77e5\u8bc6\u72b6\u6001\u7684\u81ea\u6211\u610f\u8bc6\uff09\u5982\u4f55\u8c03\u8282\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u63d0\u51faMedCoG\uff08Medical Meta-Cognition Agent with Knowledge Graph\uff09\uff0c\u901a\u8fc7\u5143\u8ba4\u77e5\u8bc4\u4f30\u4efb\u52a1\u590d\u6742\u6027\u3001\u719f\u6089\u5ea6\u548c\u77e5\u8bc6\u5bc6\u5ea6\uff0c\u52a8\u6001\u8c03\u8282\u7a0b\u5e8f\u6027\u77e5\u8bc6\u3001\u60c5\u666f\u77e5\u8bc6\u548c\u4e8b\u5b9e\u77e5\u8bc6\u7684\u4f7f\u7528\u3002\u91c7\u7528LLM\u4e2d\u5fc3\u7684\u6309\u9700\u63a8\u7406\u65b9\u6cd5\uff0c\u907f\u514d\u76f2\u76ee\u6269\u5c55\u5e76\u8fc7\u6ee4\u5206\u6563\u6ce8\u610f\u529b\u7684\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u5728\u4e94\u4e2a\u56f0\u96be\u7684\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u9a8c\u8bc1\u4e86MedCoG\u7684\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u5b9e\u73b0\u4e865.5\u500d\u7684\u63a8\u7406\u5bc6\u5ea6\uff08\u63a8\u7406\u6548\u7387\u6307\u6807\uff09\u3002Oracle\u7814\u7a76\u7a81\u663e\u4e86\u5143\u8ba4\u77e5\u8c03\u8282\u7684\u663e\u8457\u6f5c\u529b\u3002", "conclusion": "MedCoG\u901a\u8fc7\u5143\u8ba4\u77e5\u8c03\u8282\u77e5\u8bc6\u4f7f\u7528\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u63a8\u7406\u6269\u5c55\u5b9a\u5f8b\u95ee\u9898\uff0c\u5728\u964d\u4f4e\u6210\u672c\u548c\u63d0\u5347\u51c6\u786e\u6027\u65b9\u9762\u90fd\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\uff0c\u4e3a\u533b\u5b66\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07919", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.07919", "abs": "https://arxiv.org/abs/2602.07919", "authors": ["Mansi", "Avinash Kori", "Francesca Toni", "Soteris Demetriou"], "title": "Selective Fine-Tuning for Targeted and Robust Concept Unlearning", "comment": "Given the brittle nature of existing methods in unlearning harmful content in diffusion models, we propose TRuST, a novel approach for dynamically estimating target concept neurons and unlearning them by selectively fine-tuning", "summary": "Text guided diffusion models are used by millions of users, but can be easily exploited to produce harmful content. Concept unlearning methods aim at reducing the models' likelihood of generating harmful content. Traditionally, this has been tackled at an individual concept level, with only a handful of recent works considering more realistic concept combinations. However, state of the art methods depend on full finetuning, which is computationally expensive. Concept localisation methods can facilitate selective finetuning, but existing techniques are static, resulting in suboptimal utility. In order to tackle these challenges, we propose TRUST (Targeted Robust Selective fine Tuning), a novel approach for dynamically estimating target concept neurons and unlearning them through selective finetuning, empowered by a Hessian based regularization. We show experimentally, against a number of SOTA baselines, that TRUST is robust against adversarial prompts, preserves generation quality to a significant degree, and is also significantly faster than the SOTA. Our method achieves unlearning of not only individual concepts but also combinations of concepts and conditional concepts, without any specific regularization.", "AI": {"tldr": "TRUST\u662f\u4e00\u79cd\u65b0\u9896\u7684\u6269\u6563\u6a21\u578b\u6982\u5ff5\u9057\u5fd8\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u5b9a\u4f4d\u76ee\u6807\u6982\u5ff5\u795e\u7ecf\u5143\u5e76\u8fdb\u884c\u9009\u62e9\u6027\u5fae\u8c03\uff0c\u7ed3\u5408Hessian\u6b63\u5219\u5316\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u6982\u5ff5\u9057\u5fd8\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5f15\u5bfc\u6269\u6563\u6a21\u578b\u5bb9\u6613\u88ab\u5229\u7528\u751f\u6210\u6709\u5bb3\u5185\u5bb9\uff0c\u4f20\u7edf\u6982\u5ff5\u9057\u5fd8\u65b9\u6cd5\u901a\u5e38\u9488\u5bf9\u5355\u4e2a\u6982\u5ff5\uff0c\u4e14\u9700\u8981\u5b8c\u5168\u5fae\u8c03\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u73b0\u6709\u6982\u5ff5\u5b9a\u4f4d\u65b9\u6cd5\u662f\u9759\u6001\u7684\uff0c\u5bfc\u81f4\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faTRUST\u65b9\u6cd5\uff1a1\uff09\u52a8\u6001\u4f30\u8ba1\u76ee\u6807\u6982\u5ff5\u795e\u7ecf\u5143\uff1b2\uff09\u901a\u8fc7\u9009\u62e9\u6027\u5fae\u8c03\u8fdb\u884c\u6982\u5ff5\u9057\u5fd8\uff1b3\uff09\u4f7f\u7528Hessian\u57fa\u6b63\u5219\u5316\u589e\u5f3a\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTRUST\u5bf9\u5bf9\u6297\u6027\u63d0\u793a\u5177\u6709\u9c81\u68d2\u6027\uff0c\u663e\u8457\u4fdd\u6301\u751f\u6210\u8d28\u91cf\uff0c\u6bd4SOTA\u65b9\u6cd5\u5feb\u5f97\u591a\uff0c\u80fd\u591f\u9057\u5fd8\u5355\u4e2a\u6982\u5ff5\u3001\u6982\u5ff5\u7ec4\u5408\u548c\u6761\u4ef6\u6982\u5ff5\uff0c\u65e0\u9700\u7279\u5b9a\u6b63\u5219\u5316\u3002", "conclusion": "TRUST\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u6982\u5ff5\u9057\u5fd8\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u6548\u679c\u6709\u9650\u7684\u95ee\u9898\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.07940", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07940", "abs": "https://arxiv.org/abs/2602.07940", "authors": ["Guanglong Sun", "Hongwei Yan", "Liyuan Wang", "Zhiqi Kang", "Shuang Cui", "Hang Su", "Jun Zhu", "Yi Zhong"], "title": "MePo: Meta Post-Refinement for Rehearsal-Free General Continual Learnin", "comment": null, "summary": "To cope with uncertain changes of the external world, intelligent systems must continually learn from complex, evolving environments and respond in real time. This ability, collectively known as general continual learning (GCL), encapsulates practical challenges such as online datastreams and blurry task boundaries. Although leveraging pretrained models (PTMs) has greatly advanced conventional continual learning (CL), these methods remain limited in reconciling the diverse and temporally mixed information along a single pass, resulting in sub-optimal GCL performance. Inspired by meta-plasticity and reconstructive memory in neuroscience, we introduce here an innovative approach named Meta Post-Refinement (MePo) for PTMs-based GCL. This approach constructs pseudo task sequences from pretraining data and develops a bi-level meta-learning paradigm to refine the pretrained backbone, which serves as a prolonged pretraining phase but greatly facilitates rapid adaptation of representation learning to downstream GCL tasks. MePo further initializes a meta covariance matrix as the reference geometry of pretrained representation space, enabling GCL to exploit second-order statistics for robust output alignment. MePo serves as a plug-in strategy that achieves significant performance gains across a variety of GCL benchmarks and pretrained checkpoints in a rehearsal-free manner (e.g., 15.10\\%, 13.36\\%, and 12.56\\% on CIFAR-100, ImageNet-R, and CUB-200 under Sup-21/1K). Our source code is available at \\href{https://github.com/SunGL001/MePo}{MePo}", "AI": {"tldr": "MePo\u662f\u4e00\u79cd\u57fa\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u901a\u7528\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5143\u540e\u7cbe\u70bc\u7b56\u7565\u63d0\u5347\u6a21\u578b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\uff0c\u65e0\u9700\u56de\u653e\u673a\u5236\u5373\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u667a\u80fd\u7cfb\u7edf\u9700\u8981\u4ece\u590d\u6742\u3001\u52a8\u6001\u7684\u73af\u5883\u4e2d\u6301\u7eed\u5b66\u4e60\u5e76\u5b9e\u65f6\u54cd\u5e94\uff0c\u4f46\u73b0\u6709\u57fa\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5728\u7ebf\u6570\u636e\u6d41\u548c\u6a21\u7cca\u4efb\u52a1\u8fb9\u754c\uff0c\u5bfc\u81f4\u6027\u80fd\u53d7\u9650\u3002", "method": "\u63d0\u51faMeta Post-Refinement (MePo)\u65b9\u6cd5\uff1a1\uff09\u4ece\u9884\u8bad\u7ec3\u6570\u636e\u6784\u5efa\u4f2a\u4efb\u52a1\u5e8f\u5217\uff1b2\uff09\u91c7\u7528\u53cc\u5c42\u5143\u5b66\u4e60\u8303\u5f0f\u7cbe\u70bc\u9884\u8bad\u7ec3\u9aa8\u5e72\u7f51\u7edc\uff1b3\uff09\u521d\u59cb\u5316\u5143\u534f\u65b9\u5dee\u77e9\u9635\u4f5c\u4e3a\u8868\u793a\u7a7a\u95f4\u7684\u53c2\u8003\u51e0\u4f55\u7ed3\u6784\uff0c\u5229\u7528\u4e8c\u9636\u7edf\u8ba1\u8fdb\u884c\u9c81\u68d2\u8f93\u51fa\u5bf9\u9f50\u3002", "result": "MePo\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u7b56\u7565\uff0c\u5728\u591a\u79cdGCL\u57fa\u51c6\u6d4b\u8bd5\u548c\u9884\u8bad\u7ec3\u68c0\u67e5\u70b9\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u65e0\u9700\u56de\u653e\u673a\u5236\uff1a\u5728CIFAR-100\u3001ImageNet-R\u548cCUB-200\u4e0a\u5206\u522b\u63d0\u534715.10%\u300113.36%\u548c12.56%\uff08Sup-21/1K\u8bbe\u7f6e\uff09\u3002", "conclusion": "MePo\u901a\u8fc7\u5143\u540e\u7cbe\u70bc\u7b56\u7565\u6709\u6548\u63d0\u5347\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u901a\u7528\u6301\u7eed\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u9002\u5e94\u80fd\u529b\uff0c\u4e3a\u89e3\u51b3\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6301\u7eed\u5b66\u4e60\u95ee\u9898\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07943", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07943", "abs": "https://arxiv.org/abs/2602.07943", "authors": ["Ivaxi Sheth", "Zhijing Jin", "Bryan Wilder", "Dominik Janzing", "Mario Fritz"], "title": "IV Co-Scientist: Multi-Agent LLM Framework for Causal Instrumental Variable Discovery", "comment": "18 pages", "summary": "In the presence of confounding between an endogenous variable and the outcome, instrumental variables (IVs) are used to isolate the causal effect of the endogenous variable. Identifying valid instruments requires interdisciplinary knowledge, creativity, and contextual understanding, making it a non-trivial task. In this paper, we investigate whether large language models (LLMs) can aid in this task. We perform a two-stage evaluation framework. First, we test whether LLMs can recover well-established instruments from the literature, assessing their ability to replicate standard reasoning. Second, we evaluate whether LLMs can identify and avoid instruments that have been empirically or theoretically discredited. Building on these results, we introduce IV Co-Scientist, a multi-agent system that proposes, critiques, and refines IVs for a given treatment-outcome pair. We also introduce a statistical test to contextualize consistency in the absence of ground truth. Our results show the potential of LLMs to discover valid instrumental variables from a large observational database.", "AI": {"tldr": "LLMs\u80fd\u591f\u5e2e\u52a9\u53d1\u73b0\u6709\u6548\u7684\u5de5\u5177\u53d8\u91cf\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edfIV Co-Scientist\u63d0\u51fa\u3001\u6279\u5224\u548c\u4f18\u5316\u5de5\u5177\u53d8\u91cf\u9009\u62e9", "motivation": "\u5de5\u5177\u53d8\u91cf\u8bc6\u522b\u9700\u8981\u8de8\u5b66\u79d1\u77e5\u8bc6\u3001\u521b\u9020\u529b\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\uff0c\u662f\u4e00\u9879\u975e\u5e73\u51e1\u4efb\u52a1\u3002\u672c\u6587\u7814\u7a76LLMs\u662f\u5426\u80fd\u8f85\u52a9\u8fd9\u4e00\u4efb\u52a1\uff0c\u7279\u522b\u662f\u5728\u4ece\u5927\u578b\u89c2\u6d4b\u6570\u636e\u5e93\u4e2d\u8bc6\u522b\u6709\u6548\u5de5\u5177\u53d8\u91cf\u65b9\u9762\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bc4\u4f30\u6846\u67b6\uff1a1)\u6d4b\u8bd5LLMs\u80fd\u5426\u4ece\u6587\u732e\u4e2d\u6062\u590d\u5df2\u786e\u7acb\u7684\u5de5\u5177\u53d8\u91cf\uff1b2)\u8bc4\u4f30LLMs\u80fd\u5426\u8bc6\u522b\u548c\u907f\u514d\u5df2\u88ab\u5b9e\u8bc1\u6216\u7406\u8bba\u5426\u5b9a\u7684\u5de5\u5177\u53d8\u91cf\u3002\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51faIV Co-Scientist\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4ee5\u53ca\u5728\u6ca1\u6709\u771f\u5b9e\u6807\u7b7e\u60c5\u51b5\u4e0b\u8bc4\u4f30\u4e00\u81f4\u6027\u7684\u7edf\u8ba1\u68c0\u9a8c\u3002", "result": "LLMs\u80fd\u591f\u4ece\u6587\u732e\u4e2d\u6062\u590d\u5df2\u786e\u7acb\u7684\u5de5\u5177\u53d8\u91cf\uff0c\u5e76\u80fd\u8bc6\u522b\u548c\u907f\u514d\u65e0\u6548\u5de5\u5177\u53d8\u91cf\u3002IV Co-Scientist\u7cfb\u7edf\u5c55\u793a\u4e86\u4ece\u5927\u578b\u89c2\u6d4b\u6570\u636e\u5e93\u4e2d\u53d1\u73b0\u6709\u6548\u5de5\u5177\u53d8\u91cf\u7684\u6f5c\u529b\u3002", "conclusion": "LLMs\u5728\u5de5\u5177\u53d8\u91cf\u53d1\u73b0\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u8f85\u52a9\u7814\u7a76\u4eba\u5458\u4ece\u5927\u578b\u89c2\u6d4b\u6570\u636e\u5e93\u4e2d\u8bc6\u522b\u6709\u6548\u5de5\u5177\u53d8\u91cf\u65b9\u9762\u3002\u63d0\u51fa\u7684IV Co-Scientist\u7cfb\u7edf\u548c\u7edf\u8ba1\u68c0\u9a8c\u4e3a\u8fd9\u4e00\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\u8bba\u5de5\u5177\u3002"}}
{"id": "2602.07962", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07962", "abs": "https://arxiv.org/abs/2602.07962", "authors": ["Weihao Zeng", "Yuzhen Huang", "Junxian He"], "title": "LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth", "comment": null, "summary": "Large language models (LLMs) are increasingly capable of carrying out long-running, real-world tasks. However, as the amount of context grows, their reliability often deteriorates, a phenomenon known as \"context rot\". Existing long-context benchmarks primarily focus on single-step settings that evaluate a model's ability to retrieve information from a long snippet. In realistic scenarios, however, LLMs often need to act as agents that explore environments, follow instructions and plans, extract useful information, and predict correct actions under a dynamically growing context. To assess language agents in such settings, we introduce LOCA-bench (a benchmark for LOng-Context Agents). Given a task prompt, LOCA-bench leverages automated and scalable control of environment states to regulate the agent's context length. This design enables LOCA-bench to extend the context length potentially to infinity in a controlled way while keeping the underlying task semantics fixed. LOCA-bench evaluates language agents as a combination of models and scaffolds, including various context management strategies. While agent performance generally degrades as the environment states grow more complex, advanced context management techniques can substantially improve the overall success rate. We open-source LOCA-bench to provide a platform for evaluating models and scaffolds in long-context, agentic scenarios: https://github.com/hkust-nlp/LOCA-bench", "AI": {"tldr": "LOCA-bench\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u4ee3\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u73af\u5883\u72b6\u6001\u63a7\u5236\u6765\u8c03\u8282\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u652f\u6301\u65e0\u9650\u6269\u5c55\u4e0a\u4e0b\u6587\u5e76\u4fdd\u6301\u4efb\u52a1\u8bed\u4e49\u4e0d\u53d8\u3002", "motivation": "\u73b0\u6709\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u5355\u6b65\u4fe1\u606f\u68c0\u7d22\uff0c\u800c\u73b0\u5b9e\u573a\u666f\u4e2dLLM\u9700\u8981\u4f5c\u4e3a\u4ee3\u7406\u5728\u52a8\u6001\u589e\u957f\u7684\u73af\u5883\u4e2d\u63a2\u7d22\u3001\u6267\u884c\u6307\u4ee4\u3001\u63d0\u53d6\u4fe1\u606f\u548c\u9884\u6d4b\u884c\u52a8\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "LOCA-bench\u5229\u7528\u81ea\u52a8\u5316\u548c\u53ef\u6269\u5c55\u7684\u73af\u5883\u72b6\u6001\u63a7\u5236\u6765\u8c03\u8282\u4ee3\u7406\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u652f\u6301\u65e0\u9650\u6269\u5c55\u4e0a\u4e0b\u6587\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u8bed\u4e49\u56fa\u5b9a\uff0c\u8bc4\u4f30\u8bed\u8a00\u4ee3\u7406\u4f5c\u4e3a\u6a21\u578b\u548c\u811a\u624b\u67b6\u7684\u7ec4\u5408\uff0c\u5305\u62ec\u5404\u79cd\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\u3002", "result": "\u968f\u7740\u73af\u5883\u72b6\u6001\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u4ee3\u7406\u6027\u80fd\u666e\u904d\u4e0b\u964d\uff0c\u4f46\u5148\u8fdb\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u6280\u672f\u80fd\u663e\u8457\u63d0\u9ad8\u6574\u4f53\u6210\u529f\u7387\u3002", "conclusion": "LOCA-bench\u4e3a\u8bc4\u4f30\u957f\u4e0a\u4e0b\u6587\u3001\u4ee3\u7406\u5f0f\u573a\u666f\u4e2d\u7684\u6a21\u578b\u548c\u811a\u624b\u67b6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e73\u53f0\uff0c\u6709\u52a9\u4e8e\u89e3\u51b3\u4e0a\u4e0b\u6587\u9000\u5316\u95ee\u9898\u5e76\u63d0\u5347\u8bed\u8a00\u4ee3\u7406\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2602.07983", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07983", "abs": "https://arxiv.org/abs/2602.07983", "authors": ["Jishu Sen Gupta", "Harini SI", "Somesh Kumar Singh", "Syed Mohamad Tawseeq", "Yaman Kumar Singla", "David Doermann", "Rajiv Ratn Shah", "Balaji Krishnamurthy"], "title": "Accelerating Social Science Research via Agentic Hypothesization and Experimentation", "comment": null, "summary": "Data-driven social science research is inherently slow, relying on iterative cycles of observation, hypothesis generation, and experimental validation. While recent data-driven methods promise to accelerate parts of this process, they largely fail to support end-to-end scientific discovery. To address this gap, we introduce EXPERIGEN, an agentic framework that operationalizes end-to-end discovery through a Bayesian optimization inspired two-phase search, in which a Generator proposes candidate hypotheses and an Experimenter evaluates them empirically. Across multiple domains, EXPERIGEN consistently discovers 2-4x more statistically significant hypotheses that are 7-17 percent more predictive than prior approaches, and naturally extends to complex data regimes including multimodal and relational datasets. Beyond statistical performance, hypotheses must be novel, empirically grounded, and actionable to drive real scientific progress. To evaluate these qualities, we conduct an expert review of machine-generated hypotheses, collecting feedback from senior faculty. Among 25 reviewed hypotheses, 88 percent were rated moderately or strongly novel, 70 percent were deemed impactful and worth pursuing, and most demonstrated rigor comparable to senior graduate-level research. Finally, recognizing that ultimate validation requires real-world evidence, we conduct the first A/B test of LLM-generated hypotheses, observing statistically significant results with p less than 1e-6 and a large effect size of 344 percent.", "AI": {"tldr": "EXPERIGEN\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u79d1\u5b66\u53d1\u73b0\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u5668-\u5b9e\u9a8c\u8005\u7684\u4e24\u9636\u6bb5\u641c\u7d22\uff0c\u5728\u591a\u4e2a\u9886\u57df\u53d1\u73b0\u6bd4\u73b0\u6709\u65b9\u6cd5\u591a2-4\u500d\u7684\u7edf\u8ba1\u663e\u8457\u5047\u8bbe\uff0c\u9884\u6d4b\u6027\u80fd\u63d0\u53477-17%\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u548c\u771f\u5b9eA/B\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u9a71\u52a8\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u8fc7\u7a0b\u7f13\u6162\uff0c\u4f9d\u8d56\u89c2\u5bdf\u3001\u5047\u8bbe\u751f\u6210\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u7684\u8fed\u4ee3\u5faa\u73af\u3002\u73b0\u6709\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u867d\u7136\u80fd\u52a0\u901f\u90e8\u5206\u8fc7\u7a0b\uff0c\u4f46\u672a\u80fd\u652f\u6301\u7aef\u5230\u7aef\u7684\u79d1\u5b66\u53d1\u73b0\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5b8c\u6574\u652f\u6301\u4ece\u5047\u8bbe\u751f\u6210\u5230\u5b9e\u9a8c\u9a8c\u8bc1\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51faEXPERIGEN\u6846\u67b6\uff0c\u91c7\u7528\u53d7\u8d1d\u53f6\u65af\u4f18\u5316\u542f\u53d1\u7684\u4e24\u9636\u6bb5\u641c\u7d22\uff1a\u751f\u6210\u5668\u63d0\u51fa\u5019\u9009\u5047\u8bbe\uff0c\u5b9e\u9a8c\u8005\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002\u6846\u67b6\u652f\u6301\u591a\u6a21\u6001\u548c\u5173\u7cfb\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u548c\u771f\u5b9eA/B\u6d4b\u8bd5\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\uff0cEXPERIGEN\u53d1\u73b0\u6bd4\u73b0\u6709\u65b9\u6cd5\u591a2-4\u500d\u7684\u7edf\u8ba1\u663e\u8457\u5047\u8bbe\uff0c\u9884\u6d4b\u6027\u80fd\u63d0\u53477-17%\u3002\u4e13\u5bb6\u8bc4\u5ba1\u663e\u793a88%\u7684\u5047\u8bbe\u5177\u6709\u4e2d\u7b49\u6216\u5f3a\u70c8\u65b0\u9896\u6027\uff0c70%\u88ab\u8ba4\u4e3a\u6709\u5f71\u54cd\u529b\u4e14\u503c\u5f97\u7814\u7a76\u3002A/B\u6d4b\u8bd5\u83b7\u5f97p<1e-6\u7684\u7edf\u8ba1\u663e\u8457\u7ed3\u679c\u548c344%\u7684\u5927\u6548\u5e94\u91cf\u3002", "conclusion": "EXPERIGEN\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u7684\u79d1\u5b66\u53d1\u73b0\uff0c\u4e0d\u4ec5\u7edf\u8ba1\u6027\u80fd\u4f18\u8d8a\uff0c\u800c\u4e14\u751f\u6210\u7684\u5047\u8bbe\u5177\u6709\u65b0\u9896\u6027\u3001\u5b9e\u8bc1\u57fa\u7840\u548c\u53ef\u64cd\u4f5c\u6027\uff0c\u80fd\u591f\u63a8\u52a8\u771f\u6b63\u7684\u79d1\u5b66\u8fdb\u6b65\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u548c\u771f\u5b9e\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2602.08009", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08009", "abs": "https://arxiv.org/abs/2602.08009", "authors": ["Rui Li", "Zeyu Zhang", "Xiaohe Bo", "Quanyu Dai", "Chaozhuo Li", "Feng Wen", "Xu Chen"], "title": "Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective", "comment": null, "summary": "Multi-agent architectures built on large language models (LLMs) have demonstrated the potential to realize swarm intelligence through well-crafted collaboration. However, the substantial burden of manual orchestration inherently raises an imperative to automate the design of agentic workflows. We frame such an agent coordination challenge as a classic problem in dynamic ad-hoc networking: How to establish adaptive and reliable communication among a scalable number of agentic hosts? In response to this unresolved dilemma, we introduce RAPS, a reputation-aware publish-subscribe paradigm for adaptive, scalable, and robust coordination of LLM agents. RAPS is grounded in the Distributed Publish-Subscribe Protocol, allowing LLM agents to exchange messages based on their declared intents rather than predefined topologies. Beyond this substrate, RAPS further incorporates two coherent overlays: (i) Reactive Subscription, enabling agents to dynamically refine their intents; and (ii) Bayesian Reputation, empowering each agent with a local watchdog to detect and isolate malicious peers. Extensive experiments over five benchmarks showcase that our design effectively reconciles adaptivity, scalability, and robustness in a unified multi-agent coordination framework.", "AI": {"tldr": "RAPS\uff1a\u57fa\u4e8e\u58f0\u8a89\u611f\u77e5\u7684\u53d1\u5e03-\u8ba2\u9605\u8303\u5f0f\uff0c\u7528\u4e8e\u5b9e\u73b0LLM\u591a\u667a\u80fd\u4f53\u7684\u81ea\u9002\u5e94\u3001\u53ef\u6269\u5c55\u4e14\u9c81\u68d2\u7684\u534f\u8c03", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\u9700\u8981\u5927\u91cf\u4eba\u5de5\u7f16\u6392\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u8bbe\u8ba1\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u3002\u667a\u80fd\u4f53\u534f\u8c03\u9762\u4e34\u52a8\u6001\u81ea\u7ec4\u7ec7\u7f51\u7edc\u4e2d\u7684\u7ecf\u5178\u95ee\u9898\uff1a\u5982\u4f55\u5728\u53ef\u6269\u5c55\u6570\u91cf\u7684\u667a\u80fd\u4f53\u4e3b\u673a\u4e4b\u95f4\u5efa\u7acb\u81ea\u9002\u5e94\u4e14\u53ef\u9760\u7684\u901a\u4fe1\uff1f", "method": "RAPS\u57fa\u4e8e\u5206\u5e03\u5f0f\u53d1\u5e03-\u8ba2\u9605\u534f\u8bae\uff0c\u8ba9LLM\u667a\u80fd\u4f53\u57fa\u4e8e\u58f0\u660e\u7684\u610f\u56fe\u800c\u975e\u9884\u5b9a\u4e49\u62d3\u6251\u4ea4\u6362\u6d88\u606f\u3002\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u8986\u76d6\u5c42\uff1a(1) \u53cd\u5e94\u5f0f\u8ba2\u9605\uff1a\u4f7f\u667a\u80fd\u4f53\u52a8\u6001\u7ec6\u5316\u610f\u56fe\uff1b(2) \u8d1d\u53f6\u65af\u58f0\u8a89\uff1a\u4e3a\u6bcf\u4e2a\u667a\u80fd\u4f53\u63d0\u4f9b\u672c\u5730\u76d1\u63a7\u5668\uff0c\u68c0\u6d4b\u5e76\u9694\u79bb\u6076\u610f\u8282\u70b9\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u8bbe\u8ba1\u5728\u7edf\u4e00\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u6846\u67b6\u4e2d\u6709\u6548\u8c03\u548c\u4e86\u81ea\u9002\u5e94\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "RAPS\u901a\u8fc7\u58f0\u8a89\u611f\u77e5\u7684\u53d1\u5e03-\u8ba2\u9605\u8303\u5f0f\uff0c\u4e3a\u89e3\u51b3LLM\u591a\u667a\u80fd\u4f53\u534f\u8c03\u4e2d\u7684\u81ea\u9002\u5e94\u3001\u53ef\u6269\u5c55\u548c\u9c81\u68d2\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08013", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08013", "abs": "https://arxiv.org/abs/2602.08013", "authors": ["Yuqiao Meng", "Luoxi Tang", "Dazheng Zhang", "Rafael Brens", "Elvys J. Romero", "Nancy Guo", "Safa Elkefi", "Zhaohan Xi"], "title": "Small Agent Group is the Future of Digital Health", "comment": null, "summary": "The rapid adoption of large language models (LLMs) in digital health has been driven by a \"scaling-first\" philosophy, i.e., the assumption that clinical intelligence increases with model size and data. However, real-world clinical needs include not only effectiveness, but also reliability and reasonable deployment cost. Since clinical decision-making is inherently collaborative, we challenge the monolithic scaling paradigm and ask whether a Small Agent Group (SAG) can support better clinical reasoning. SAG shifts from single-model intelligence to collective expertise by distributing reasoning, evidence-based analysis, and critical audit through a collaborative deliberation process. To assess the clinical utility of SAG, we conduct extensive evaluations using diverse clinical metrics spanning effectiveness, reliability, and deployment cost. Our results show that SAG achieves superior performance compared to a single giant model, both with and without additional optimization or retrieval-augmented generation. These findings suggest that the synergistic reasoning represented by SAG can substitute for model parameter growth in clinical settings. Overall, SAG offers a scalable solution to digital health that better balances effectiveness, reliability, and deployment efficiency.", "AI": {"tldr": "\u5c0f\u4ee3\u7406\u7fa4\u7ec4\uff08SAG\uff09\u901a\u8fc7\u534f\u4f5c\u63a8\u7406\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u66ff\u4ee3\u6a21\u578b\u53c2\u6570\u589e\u957f\uff0c\u5b9e\u73b0\u6548\u679c\u3001\u53ef\u9760\u6027\u548c\u90e8\u7f72\u6548\u7387\u7684\u66f4\u597d\u5e73\u8861", "motivation": "\u5f53\u524d\u6570\u5b57\u5065\u5eb7\u9886\u57df\u8fc7\u5ea6\u4f9d\u8d56\"\u89c4\u6a21\u4f18\u5148\"\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8303\u5f0f\uff0c\u4f46\u4e34\u5e8a\u5b9e\u9645\u9700\u6c42\u4e0d\u4ec5\u9700\u8981\u6548\u679c\uff0c\u8fd8\u9700\u8981\u53ef\u9760\u6027\u548c\u5408\u7406\u7684\u90e8\u7f72\u6210\u672c\u3002\u4e34\u5e8a\u51b3\u7b56\u672c\u8d28\u4e0a\u662f\u534f\u4f5c\u8fc7\u7a0b\uff0c\u56e0\u6b64\u9700\u8981\u6311\u6218\u5355\u4e00\u6a21\u578b\u6269\u5c55\u7684\u8303\u5f0f", "method": "\u63d0\u51fa\u5c0f\u4ee3\u7406\u7fa4\u7ec4\uff08SAG\uff09\u65b9\u6cd5\uff0c\u5c06\u5355\u4e00\u6a21\u578b\u667a\u80fd\u8f6c\u53d8\u4e3a\u96c6\u4f53\u4e13\u4e1a\u77e5\u8bc6\uff0c\u901a\u8fc7\u534f\u4f5c\u5ba1\u8bae\u8fc7\u7a0b\u5206\u914d\u63a8\u7406\u3001\u5faa\u8bc1\u5206\u6790\u548c\u5173\u952e\u5ba1\u6838\u4efb\u52a1", "result": "SAG\u5728\u6548\u679c\u3001\u53ef\u9760\u6027\u548c\u90e8\u7f72\u6210\u672c\u7b49\u591a\u4e2a\u4e34\u5e8a\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u4e8e\u5355\u4e00\u5927\u578b\u6a21\u578b\uff0c\u65e0\u8bba\u662f\u5426\u4f7f\u7528\u989d\u5916\u4f18\u5316\u6216\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f", "conclusion": "SAG\u63d0\u4f9b\u7684\u534f\u540c\u63a8\u7406\u53ef\u4ee5\u66ff\u4ee3\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u6a21\u578b\u53c2\u6570\u589e\u957f\uff0c\u4e3a\u6570\u5b57\u5065\u5eb7\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u66f4\u597d\u5730\u5e73\u8861\u4e86\u6548\u679c\u3001\u53ef\u9760\u6027\u548c\u90e8\u7f72\u6548\u7387"}}
{"id": "2602.08021", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08021", "abs": "https://arxiv.org/abs/2602.08021", "authors": ["Zhan-Yi Liao", "Jaewon Yoo", "Hao-Tsung Yang", "Po-An Chen"], "title": "Structure-Aware Robust Counterfactual Explanations via Conditional Gaussian Network Classifiers", "comment": null, "summary": "Counterfactual explanation (CE) is a core technique in explainable artificial intelligence (XAI), widely used to interpret model decisions and suggest actionable alternatives. This work presents a structure-aware and robustness-oriented counterfactual search method based on the conditional Gaussian network classifier (CGNC). The CGNC has a generative structure that encodes conditional dependencies and potential causal relations among features through a directed acyclic graph (DAG). This structure naturally embeds feature relationships into the search process, eliminating the need for additional constraints to ensure consistency with the model's structural assumptions. We adopt a convergence-guaranteed cutting-set procedure as an adversarial optimization framework, which iteratively approximates solutions that satisfy global robustness conditions. To address the nonconvex quadratic structure induced by feature dependencies, we apply piecewise McCormick relaxation to reformulate the problem as a mixed-integer linear program (MILP), ensuring global optimality. Experimental results show that our method achieves strong robustness, with direct global optimization of the original formulation providing especially stable and efficient results. The proposed framework is extensible to more complex constraint settings, laying the groundwork for future advances in counterfactual reasoning under nonconvex quadratic formulations.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6761\u4ef6\u9ad8\u65af\u7f51\u7edc\u5206\u7c7b\u5668\u7684\u7ed3\u6784\u611f\u77e5\u3001\u9c81\u68d2\u6027\u5bfc\u5411\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u641c\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\u786e\u4fdd\u5168\u5c40\u6700\u4f18\u6027", "motivation": "\u73b0\u6709\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u7279\u5f81\u95f4\u6761\u4ef6\u4f9d\u8d56\u5173\u7cfb\u548c\u6f5c\u5728\u56e0\u679c\u5173\u7cfb\u7684\u8003\u8651\uff0c\u4e14\u9c81\u68d2\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u81ea\u7136\u5d4c\u5165\u6a21\u578b\u7ed3\u6784\u5047\u8bbe\u5e76\u4fdd\u8bc1\u5168\u5c40\u9c81\u68d2\u6027\u7684\u65b9\u6cd5", "method": "\u4f7f\u7528\u6761\u4ef6\u9ad8\u65af\u7f51\u7edc\u5206\u7c7b\u5668\u7f16\u7801\u7279\u5f81\u4f9d\u8d56\u5173\u7cfb\uff0c\u91c7\u7528\u6536\u655b\u4fdd\u8bc1\u7684\u5207\u5272\u96c6\u8fc7\u7a0b\u4f5c\u4e3a\u5bf9\u6297\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6bb5McCormick\u677e\u5f1b\u5c06\u975e\u51f8\u4e8c\u6b21\u95ee\u9898\u8f6c\u5316\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5f3a\u9c81\u68d2\u6027\uff0c\u76f4\u63a5\u5168\u5c40\u4f18\u5316\u539f\u59cb\u516c\u5f0f\u63d0\u4f9b\u4e86\u7279\u522b\u7a33\u5b9a\u548c\u9ad8\u6548\u7684\u7ed3\u679c\uff0c\u6846\u67b6\u53ef\u6269\u5c55\u5230\u66f4\u590d\u6742\u7684\u7ea6\u675f\u8bbe\u7f6e", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u975e\u7ebf\u6027\u4e8c\u6b21\u516c\u5f0f\u4e0b\u7684\u53cd\u4e8b\u5b9e\u63a8\u7406\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5177\u6709\u7ed3\u6784\u611f\u77e5\u548c\u9c81\u68d2\u6027\u5bfc\u5411\u7684\u7279\u70b9\uff0c\u53ef\u6269\u5c55\u6027\u5f3a"}}
{"id": "2602.08030", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08030", "abs": "https://arxiv.org/abs/2602.08030", "authors": ["Yilun Zheng", "Dongyang Ma", "Tian Liang", "Jiahao Xu", "Xinting Huang", "Lijie Chen", "Haitao Mi", "Yan Wang"], "title": "Free(): Learning to Forget in Malloc-Only Reasoning Models", "comment": null, "summary": "Reasoning models enhance problem-solving by scaling test-time compute, yet they face a critical paradox: excessive thinking tokens often degrade performance rather than improve it. We attribute this to a fundamental architectural flaw: standard LLMs operate as \"malloc-only\" engines, continuously accumulating valid and redundant steps alike without a mechanism to prune obsolete information. To break this cycle, we propose Free()LM, a model that introduces an intrinsic self-forgetting capability via the Free-Module, a plug-and-play LoRA adapter. By iteratively switching between reasoning and cleaning modes, Free()LM dynamically identifies and prunes useless context chunks, maintaining a compact and noise-free state.\n  Extensive experiments show that Free()LM provides consistent improvements across all model scales (8B to 685B). It achieves a 3.3% average improvement over top-tier reasoning baselines, even establishing a new SOTA on IMOanswerBench using DeepSeek V3.2-Speciale. Most notably, in long-horizon tasks where the standard Qwen3-235B-A22B model suffers a total collapse (0% accuracy), Free()LM restores performance to 50%. Our findings suggest that sustainable intelligence requires the freedom to forget as much as the power to think.", "AI": {"tldr": "Free()LM\u901a\u8fc7\u5f15\u5165\u81ea\u9057\u5fd8\u673a\u5236\u89e3\u51b3\u63a8\u7406\u6a21\u578b\u4e2d\u8fc7\u5ea6\u601d\u8003\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u4f7f\u7528\u53ef\u63d2\u62d4\u7684LoRA\u9002\u914d\u5668\u52a8\u6001\u4fee\u526a\u65e0\u7528\u4e0a\u4e0b\u6587\uff0c\u5728\u5404\u79cd\u89c4\u6a21\u6a21\u578b\u4e0a\u5b9e\u73b0\u6027\u80fd\u63d0\u5347", "motivation": "\u6807\u51c6LLM\u5b58\u5728\"\u53ea\u5206\u914d\u4e0d\u91ca\u653e\"\u7684\u67b6\u6784\u7f3a\u9677\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6301\u7eed\u79ef\u7d2f\u6709\u6548\u548c\u5197\u4f59\u6b65\u9aa4\uff0c\u7f3a\u4e4f\u4fee\u526a\u8fc7\u65f6\u4fe1\u606f\u7684\u673a\u5236\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u601d\u8003\u65f6\u6027\u80fd\u53cd\u800c\u4e0b\u964d", "method": "\u63d0\u51faFree()LM\u6a21\u578b\uff0c\u901a\u8fc7Free-Module\uff08\u53ef\u63d2\u62d4LoRA\u9002\u914d\u5668\uff09\u5b9e\u73b0\u5185\u5728\u81ea\u9057\u5fd8\u80fd\u529b\u3002\u6a21\u578b\u5728\u63a8\u7406\u6a21\u5f0f\u548c\u6e05\u7406\u6a21\u5f0f\u4e4b\u95f4\u8fed\u4ee3\u5207\u6362\uff0c\u52a8\u6001\u8bc6\u522b\u5e76\u4fee\u526a\u65e0\u7528\u4e0a\u4e0b\u6587\u5757\uff0c\u4fdd\u6301\u7d27\u51d1\u65e0\u566a\u58f0\u72b6\u6001", "result": "\u5728\u6240\u6709\u6a21\u578b\u89c4\u6a21\uff088B\u5230685B\uff09\u4e0a\u5b9e\u73b0\u4e00\u81f4\u6539\u8fdb\uff0c\u5e73\u5747\u6bd4\u9876\u7ea7\u63a8\u7406\u57fa\u7ebf\u63d0\u53473.3%\uff0c\u5728IMOanswerBench\u4e0a\u5efa\u7acb\u65b0SOTA\u3002\u5728\u957f\u65f6\u57df\u4efb\u52a1\u4e2d\uff0c\u5c06Qwen3-235B-A22B\u4ece0%\u51c6\u786e\u7387\u6062\u590d\u523050%", "conclusion": "\u53ef\u6301\u7eed\u667a\u80fd\u4e0d\u4ec5\u9700\u8981\u601d\u8003\u80fd\u529b\uff0c\u8fd8\u9700\u8981\u9057\u5fd8\u7684\u81ea\u7531\u3002\u81ea\u9057\u5fd8\u673a\u5236\u662f\u89e3\u51b3\u63a8\u7406\u6a21\u578b\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\u7684\u5173\u952e\uff0cFree()LM\u4e3aLLM\u67b6\u6784\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411"}}
{"id": "2602.08061", "categories": ["cs.AI", "q-bio.OT"], "pdf": "https://arxiv.org/pdf/2602.08061", "abs": "https://arxiv.org/abs/2602.08061", "authors": ["Doni Bloomfield", "Allison Berke", "Moritz S. Hanke", "Aaron Maiwald", "James R. M. Black", "Toby Webster", "Tina Hernandez-Boussard", "Oliver M. Crook", "Jassi Pannu"], "title": "Securing Dual-Use Pathogen Data of Concern", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Biosecurity Safeguards for Generative AI", "summary": "Training data is an essential input into creating competent artificial intelligence (AI) models. AI models for biology are trained on large volumes of data, including data related to biological sequences, structures, images, and functions. The type of data used to train a model is intimately tied to the capabilities it ultimately possesses--including those of biosecurity concern. For this reason, an international group of more than 100 researchers at the recent 50th anniversary Asilomar Conference endorsed data controls to prevent the use of AI for harmful applications such as bioweapons development. To help design such controls, we introduce a five-tier Biosecurity Data Level (BDL) framework for categorizing pathogen data. Each level contains specific data types, based on their expected ability to contribute to capabilities of concern when used to train AI models. For each BDL tier, we propose technical restrictions appropriate to its level of risk. Finally, we outline a novel governance framework for newly created dual-use pathogen data. In a world with widely accessible computational and coding resources, data controls may be among the most high-leverage interventions available to reduce the proliferation of concerning biological AI capabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e94\u7ea7\u751f\u7269\u5b89\u5168\u6570\u636e\u6846\u67b6\uff08BDL\uff09\uff0c\u6839\u636e\u75c5\u539f\u4f53\u6570\u636e\u8bad\u7ec3AI\u6a21\u578b\u53ef\u80fd\u5e26\u6765\u7684\u751f\u7269\u5b89\u5168\u98ce\u9669\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u9488\u5bf9\u4e0d\u540c\u98ce\u9669\u7b49\u7ea7\u63d0\u51fa\u6280\u672f\u9650\u5236\u63aa\u65bd\u548c\u6cbb\u7406\u6846\u67b6\u3002", "motivation": "AI\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u4e0e\u5176\u80fd\u529b\u5bc6\u5207\u76f8\u5173\uff0c\u5305\u62ec\u751f\u7269\u5b89\u5168\u98ce\u9669\u80fd\u529b\u3002\u4e3a\u9632\u6b62AI\u88ab\u7528\u4e8e\u751f\u7269\u6b66\u5668\u5f00\u53d1\u7b49\u6709\u5bb3\u5e94\u7528\uff0c\u9700\u8981\u8bbe\u8ba1\u6570\u636e\u63a7\u5236\u63aa\u65bd\u3002\u5728\u8ba1\u7b97\u548c\u7f16\u7801\u8d44\u6e90\u5e7f\u6cdb\u53ef\u53ca\u7684\u4e16\u754c\u4e2d\uff0c\u6570\u636e\u63a7\u5236\u53ef\u80fd\u662f\u51cf\u5c11\u751f\u7269AI\u80fd\u529b\u6269\u6563\u7684\u6700\u6709\u6548\u5e72\u9884\u624b\u6bb5\u3002", "method": "\u5f15\u5165\u4e94\u7ea7\u751f\u7269\u5b89\u5168\u6570\u636e\u6846\u67b6\uff08BDL\uff09\uff0c\u6839\u636e\u75c5\u539f\u4f53\u6570\u636e\u8bad\u7ec3AI\u6a21\u578b\u53ef\u80fd\u5e26\u6765\u7684\u98ce\u9669\u8fdb\u884c\u5206\u7c7b\u3002\u4e3a\u6bcf\u4e2aBDL\u5c42\u7ea7\u63d0\u51fa\u76f8\u5e94\u7684\u6280\u672f\u9650\u5236\u63aa\u65bd\uff0c\u5e76\u8bbe\u8ba1\u9488\u5bf9\u65b0\u521b\u5efa\u7684\u53cc\u91cd\u7528\u9014\u75c5\u539f\u4f53\u6570\u636e\u7684\u6cbb\u7406\u6846\u67b6\u3002", "result": "\u5efa\u7acb\u4e86\u7cfb\u7edf\u5316\u7684\u75c5\u539f\u4f53\u6570\u636e\u98ce\u9669\u5206\u7c7b\u6846\u67b6\uff0c\u4e3a\u4e0d\u540c\u98ce\u9669\u7b49\u7ea7\u7684\u6570\u636e\u8bbe\u8ba1\u4e86\u5177\u4f53\u7684\u6280\u672f\u63a7\u5236\u63aa\u65bd\uff0c\u5e76\u63d0\u51fa\u4e86\u521b\u65b0\u7684\u6cbb\u7406\u6846\u67b6\u6765\u7ba1\u7406\u53cc\u91cd\u7528\u9014\u75c5\u539f\u4f53\u6570\u636e\u3002", "conclusion": "\u5728\u8ba1\u7b97\u8d44\u6e90\u5e7f\u6cdb\u53ef\u53ca\u7684\u65f6\u4ee3\uff0c\u6570\u636e\u63a7\u5236\u662f\u51cf\u5c11\u751f\u7269AI\u80fd\u529b\u6269\u6563\u7684\u5173\u952e\u5e72\u9884\u624b\u6bb5\u3002\u63d0\u51fa\u7684BDL\u6846\u67b6\u548c\u6cbb\u7406\u65b9\u6848\u6709\u52a9\u4e8e\u5b9e\u65bd\u6709\u6548\u7684\u751f\u7269\u5b89\u5168\u6570\u636e\u7ba1\u63a7\uff0c\u9632\u6b62AI\u88ab\u7528\u4e8e\u6709\u5bb3\u7684\u751f\u7269\u5e94\u7528\u3002"}}
{"id": "2602.08104", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08104", "abs": "https://arxiv.org/abs/2602.08104", "authors": ["Risal Shahriar Shefin", "Debashis Gupta", "Thai Le", "Sarra Alqahtani"], "title": "Interpretable Failure Analysis in Multi-Agent Reinforcement Learning Systems", "comment": null, "summary": "Multi-Agent Reinforcement Learning (MARL) is increasingly deployed in safety-critical domains, yet methods for interpretable failure detection and attribution remain underdeveloped. We introduce a two-stage gradient-based framework that provides interpretable diagnostics for three critical failure analysis tasks: (1) detecting the true initial failure source (Patient-0); (2) validating why non-attacked agents may be flagged first due to domino effects; and (3) tracing how failures propagate through learned coordination pathways. Stage 1 performs interpretable per-agent failure detection via Taylor-remainder analysis of policy-gradient costs, declaring an initial Patient-0 candidate at the first threshold crossing. Stage 2 provides validation through geometric analysis of critic derivatives-first-order sensitivity and directional second-order curvature aggregated over causal windows to construct interpretable contagion graphs. This approach explains \"downstream-first\" detection anomalies by revealing pathways that amplify upstream deviations. Evaluated across 500 episodes in Simple Spread (3 and 5 agents) and 100 episodes in StarCraft II using MADDPG and HATRPO, our method achieves 88.2-99.4% Patient-0 detection accuracy while providing interpretable geometric evidence for detection decisions. By moving beyond black-box detection to interpretable gradient-level forensics, this framework offers practical tools for diagnosing cascading failures in safety-critical MARL systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4e24\u9636\u6bb5\u68af\u5ea6\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u53ef\u89e3\u91ca\u6545\u969c\u68c0\u6d4b\u4e0e\u6eaf\u6e90\uff0c\u80fd\u8bc6\u522b\u521d\u59cb\u6545\u969c\u6e90\u3001\u9a8c\u8bc1\u591a\u7c73\u8bfa\u6548\u5e94\u3001\u8ffd\u8e2a\u6545\u969c\u4f20\u64ad\u8def\u5f84\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u5e94\u7528\u589e\u591a\uff0c\u4f46\u53ef\u89e3\u91ca\u7684\u6545\u969c\u68c0\u6d4b\u4e0e\u5f52\u56e0\u65b9\u6cd5\u4ecd\u4e0d\u6210\u719f\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u4e3a\u9ed1\u76d2\u68c0\u6d4b\uff0c\u7f3a\u4e4f\u5bf9\u6545\u969c\u4f20\u64ad\u673a\u5236\u7684\u53ef\u89e3\u91ca\u6027\u5206\u6790\u3002", "method": "\u4e24\u9636\u6bb5\u68af\u5ea6\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u7b56\u7565\u68af\u5ea6\u6210\u672c\u7684\u6cf0\u52d2\u4f59\u9879\u5206\u6790\u8fdb\u884c\u53ef\u89e3\u91ca\u7684\u667a\u80fd\u4f53\u7ea7\u6545\u969c\u68c0\u6d4b\uff0c\u786e\u5b9a\u521d\u59cb\u6545\u969c\u5019\u9009\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u8bc4\u8bba\u5bb6\u5bfc\u6570\u7684\u51e0\u4f55\u5206\u6790\uff08\u4e00\u9636\u654f\u611f\u6027\u548c\u4e8c\u9636\u66f2\u7387\uff09\u6784\u5efa\u53ef\u89e3\u91ca\u7684\u4f20\u67d3\u56fe\uff0c\u9a8c\u8bc1\u591a\u7c73\u8bfa\u6548\u5e94\u548c\u8ffd\u8e2a\u4f20\u64ad\u8def\u5f84\u3002", "result": "\u5728Simple Spread\uff083\u548c5\u667a\u80fd\u4f53\uff09\u548cStarCraft II\u73af\u5883\u4e2d\u8bc4\u4f30\uff0c\u4f7f\u7528MADDPG\u548cHATRPO\u7b97\u6cd5\uff0c\u5728500/100\u4e2aepisode\u4e2d\u8fbe\u523088.2-99.4%\u7684\u521d\u59cb\u6545\u969c\u6e90\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u5e76\u63d0\u4f9b\u68c0\u6d4b\u51b3\u7b56\u7684\u51e0\u4f55\u8bc1\u636e\u3002", "conclusion": "\u8be5\u6846\u67b6\u8d85\u8d8a\u4e86\u9ed1\u76d2\u68c0\u6d4b\uff0c\u63d0\u4f9b\u4e86\u68af\u5ea6\u5c42\u9762\u7684\u53ef\u89e3\u91ca\u6cd5\u533b\u5206\u6790\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u7ea7\u8054\u6545\u969c\u8bca\u65ad\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2602.08121", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08121", "abs": "https://arxiv.org/abs/2602.08121", "authors": ["Liying Wang", "Madison Lee", "Yunzhang Jiang", "Steven Chen", "Kewei Sha", "Yunhe Feng", "Frank Wong", "Lisa Hightow-Weidman", "Weichao Yuwen"], "title": "Initial Risk Probing and Feasibility Testing of Glow: a Generative AI-Powered Dialectical Behavior Therapy Skills Coach for Substance Use Recovery and HIV Prevention", "comment": null, "summary": "Background: HIV and substance use represent interacting epidemics with shared psychological drivers - impulsivity and maladaptive coping. Dialectical behavior therapy (DBT) targets these mechanisms but faces scalability challenges. Generative artificial intelligence (GenAI) offers potential for delivering personalized DBT coaching at scale, yet rapid development has outpaced safety infrastructure. Methods: We developed Glow, a GenAI-powered DBT skills coach delivering chain and solution analysis for individuals at risk for HIV and substance use. In partnership with a Los Angeles community health organization, we conducted usability testing with clinical staff (n=6) and individuals with lived experience (n=28). Using the Helpful, Honest, and Harmless (HHH) framework, we employed user-driven adversarial testing wherein participants identified target behaviors and generated contextually realistic risk probes. We evaluated safety performance across 37 risk probe interactions. Results: Glow appropriately handled 73% of risk probes, but performance varied by agent. The solution analysis agent demonstrated 90% appropriate handling versus 44% for the chain analysis agent. Safety failures clustered around encouraging substance use and normalizing harmful behaviors. The chain analysis agent fell into an \"empathy trap,\" providing validation that reinforced maladaptive beliefs. Additionally, 27 instances of DBT skill misinformation were identified. Conclusions: This study provides the first systematic safety evaluation of GenAI-delivered DBT coaching for HIV and substance use risk reduction. Findings reveal vulnerabilities requiring mitigation before clinical trials. The HHH framework and user-driven adversarial testing offer replicable methods for evaluating GenAI mental health interventions.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86Glow\u2014\u2014\u4e00\u4e2a\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684DBT\u6280\u80fd\u6559\u7ec3\uff0c\u7528\u4e8eHIV\u548c\u7269\u8d28\u4f7f\u7528\u98ce\u9669\u4eba\u7fa4\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u9a71\u52a8\u7684\u5bf9\u6297\u6027\u6d4b\u8bd5\u8bc4\u4f30\u5176\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u9700\u8981\u89e3\u51b3\u3002", "motivation": "HIV\u548c\u7269\u8d28\u4f7f\u7528\u662f\u76f8\u4e92\u5f71\u54cd\u7684\u6d41\u884c\u75c5\uff0c\u6709\u5171\u540c\u7684\u5fc3\u7406\u5b66\u9a71\u52a8\u56e0\u7d20\uff08\u51b2\u52a8\u6027\u548c\u9002\u5e94\u4e0d\u826f\u5e94\u5bf9\uff09\u3002DBT\u9488\u5bf9\u8fd9\u4e9b\u673a\u5236\u4f46\u9762\u4e34\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u800c\u751f\u6210\u5f0fAI\u6709\u6f5c\u529b\u63d0\u4f9b\u89c4\u6a21\u5316\u4e2a\u6027\u5316DBT\u6307\u5bfc\uff0c\u4f46\u5176\u5feb\u901f\u53d1\u5c55\u8d85\u8fc7\u4e86\u5b89\u5168\u57fa\u7840\u8bbe\u65bd\u7684\u5efa\u8bbe\u901f\u5ea6\u3002", "method": "\u5f00\u53d1\u4e86Glow\u2014\u2014\u4e00\u4e2a\u751f\u6210\u5f0fAI\u9a71\u52a8\u7684DBT\u6280\u80fd\u6559\u7ec3\uff0c\u63d0\u4f9b\u94fe\u5206\u6790\u548c\u89e3\u51b3\u65b9\u6848\u5206\u6790\u3002\u4e0e\u6d1b\u6749\u77f6\u793e\u533a\u536b\u751f\u7ec4\u7ec7\u5408\u4f5c\uff0c\u5bf9\u4e34\u5e8a\u5de5\u4f5c\u4eba\u5458\uff08n=6\uff09\u548c\u6709\u751f\u6d3b\u7ecf\u9a8c\u7684\u4e2a\u4f53\uff08n=28\uff09\u8fdb\u884c\u53ef\u7528\u6027\u6d4b\u8bd5\u3002\u4f7f\u7528HHH\u6846\u67b6\uff0c\u91c7\u7528\u7528\u6237\u9a71\u52a8\u7684\u5bf9\u6297\u6027\u6d4b\u8bd5\uff0c\u53c2\u4e0e\u8005\u8bc6\u522b\u76ee\u6807\u884c\u4e3a\u5e76\u751f\u6210\u60c5\u5883\u73b0\u5b9e\u7684\u98ce\u9669\u63a2\u6d4b\u3002\u8bc4\u4f30\u4e8637\u4e2a\u98ce\u9669\u63a2\u6d4b\u4ea4\u4e92\u7684\u5b89\u5168\u6027\u8868\u73b0\u3002", "result": "Glow\u9002\u5f53\u5904\u7406\u4e8673%\u7684\u98ce\u9669\u63a2\u6d4b\uff0c\u4f46\u4e0d\u540c\u4ee3\u7406\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff1a\u89e3\u51b3\u65b9\u6848\u5206\u6790\u4ee3\u7406\u8fbe\u523090%\u9002\u5f53\u5904\u7406\u7387\uff0c\u800c\u94fe\u5206\u6790\u4ee3\u7406\u53ea\u670944%\u3002\u5b89\u5168\u5931\u8d25\u4e3b\u8981\u96c6\u4e2d\u5728\u9f13\u52b1\u7269\u8d28\u4f7f\u7528\u548c\u6b63\u5e38\u5316\u6709\u5bb3\u884c\u4e3a\u3002\u94fe\u5206\u6790\u4ee3\u7406\u9677\u5165\"\u5171\u60c5\u9677\u9631\"\uff0c\u63d0\u4f9b\u5f3a\u5316\u9002\u5e94\u4e0d\u826f\u4fe1\u5ff5\u7684\u9a8c\u8bc1\u3002\u6b64\u5916\u8fd8\u8bc6\u522b\u51fa27\u4e2aDBT\u6280\u80fd\u9519\u8bef\u4fe1\u606f\u5b9e\u4f8b\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5bf9\u751f\u6210\u5f0fAI\u63d0\u4f9b\u7684DBT\u6307\u5bfc\u8fdb\u884c\u7cfb\u7edf\u6027\u5b89\u5168\u8bc4\u4f30\u3002\u7814\u7a76\u53d1\u73b0\u9700\u8981\u5728\u4e34\u5e8a\u8bd5\u9a8c\u524d\u7f13\u89e3\u7684\u6f0f\u6d1e\u3002HHH\u6846\u67b6\u548c\u7528\u6237\u9a71\u52a8\u7684\u5bf9\u6297\u6027\u6d4b\u8bd5\u4e3a\u8bc4\u4f30\u751f\u6210\u5f0fAI\u5fc3\u7406\u5065\u5eb7\u5e72\u9884\u63d0\u4f9b\u4e86\u53ef\u590d\u5236\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.08214", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08214", "abs": "https://arxiv.org/abs/2602.08214", "authors": ["Ziwei Wang", "Yuanhe Zhang", "Jing Chen", "Zhenhong Zhou", "Ruichao Liang", "Ruiying Du", "Ju Jia", "Cong Wu", "Yang Liu"], "title": "RECUR: Resource Exhaustion Attack via Recursive-Entropy Guided Counterfactual Utilization and Reflection", "comment": null, "summary": "Large Reasoning Models (LRMs) employ reasoning to address complex tasks. Such explicit reasoning requires extended context lengths, resulting in substantially higher resource consumption. Prior work has shown that adversarially crafted inputs can trigger redundant reasoning processes, exposing LRMs to resource-exhaustion vulnerabilities. However, the reasoning process itself, especially its reflective component, has received limited attention, even though it can lead to over-reflection and consume excessive computing power. In this paper, we introduce Recursive Entropy to quantify the risk of resource consumption in reflection, thereby revealing the safety issues inherent in inference itself. Based on Recursive Entropy, we introduce RECUR, a resource exhaustion attack via Recursive Entropy guided Counterfactual Utilization and Reflection. It constructs counterfactual questions to verify the inherent flaws and risks of LRMs. Extensive experiments demonstrate that, under benign inference, recursive entropy exhibits a pronounced decreasing trend. RECUR disrupts this trend, increasing the output length by up to 11x and decreasing throughput by 90%. Our work provides a new perspective on robust reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRECUR\u653b\u51fb\uff0c\u901a\u8fc7\u9012\u5f52\u71b5\u5f15\u5bfc\u7684\u53cd\u4e8b\u5b9e\u5229\u7528\u548c\u53cd\u601d\uff0c\u9488\u5bf9\u5927\u578b\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u8d44\u6e90\u8017\u5c3d\u653b\u51fb\uff0c\u63ed\u793a\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u9690\u60a3\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u9700\u8981\u6269\u5c55\u4e0a\u4e0b\u6587\u957f\u5ea6\u8fdb\u884c\u663e\u5f0f\u63a8\u7406\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d88\u8017\u663e\u8457\u589e\u52a0\u3002\u73b0\u6709\u7814\u7a76\u663e\u793a\u5bf9\u6297\u6027\u8f93\u5165\u53ef\u89e6\u53d1\u5197\u4f59\u63a8\u7406\u8fc7\u7a0b\uff0c\u4f46\u63a8\u7406\u8fc7\u7a0b\u672c\u8eab\uff0c\u7279\u522b\u662f\u5176\u53cd\u601d\u7ec4\u4ef6\uff0c\u53d7\u5230\u7684\u5173\u6ce8\u6709\u9650\uff0c\u53ef\u80fd\u5bfc\u81f4\u8fc7\u5ea6\u53cd\u601d\u548c\u8ba1\u7b97\u8d44\u6e90\u8fc7\u5ea6\u6d88\u8017\u3002", "method": "\u63d0\u51fa\u9012\u5f52\u71b5\u6765\u91cf\u5316\u53cd\u601d\u4e2d\u7684\u8d44\u6e90\u6d88\u8017\u98ce\u9669\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1RECUR\u653b\u51fb\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9012\u5f52\u71b5\u5f15\u5bfc\u6784\u5efa\u53cd\u4e8b\u5b9e\u95ee\u9898\uff0c\u5229\u7528LRMs\u7684\u5185\u5728\u7f3a\u9677\u548c\u98ce\u9669\u8fdb\u884c\u8d44\u6e90\u8017\u5c3d\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u826f\u6027\u63a8\u7406\u4e2d\u9012\u5f52\u71b5\u5448\u73b0\u660e\u663e\u4e0b\u964d\u8d8b\u52bf\uff0c\u800cRECUR\u653b\u51fb\u7834\u574f\u4e86\u8fd9\u4e00\u8d8b\u52bf\uff0c\u4f7f\u8f93\u51fa\u957f\u5ea6\u589e\u52a0\u9ad8\u8fbe11\u500d\uff0c\u541e\u5410\u91cf\u4e0b\u964d90%\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u9c81\u68d2\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u63ed\u793a\u4e86\u63a8\u7406\u8fc7\u7a0b\u672c\u8eab\u7684\u5b89\u5168\u9690\u60a3\uff0c\u7279\u522b\u662f\u53cd\u601d\u7ec4\u4ef6\u53ef\u80fd\u5bfc\u81f4\u7684\u8d44\u6e90\u8017\u5c3d\u6f0f\u6d1e\u3002"}}
{"id": "2602.08222", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08222", "abs": "https://arxiv.org/abs/2602.08222", "authors": ["Zehao Chen", "Gongxun Li", "Tianxiang Ai", "Yifei Li", "Zixuan Huang", "Wang Zhou", "Fuzhen Zhuang", "Xianglong Liu", "Jianxin Li", "Deqing Wang", "Yikun Ban"], "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger", "comment": null, "summary": "As post-training optimization becomes central to improving large language models, we observe a persistent saturation bottleneck: once models grow highly confident, further training yields diminishing returns. While existing methods continue to reinforce target predictions, we find that informative supervision signals remain latent in models' own historical weak states. Motivated by this observation, we propose WMSS (Weak Agents Can Make Strong Agents Stronger), a post-training paradigm that leverages weak checkpoints to guide continued optimization. By identifying recoverable learning gaps via entropy dynamics and reinforcing them through compensatory learning, WMSS enables strong agents to improve beyond conventional post-training saturation. Experiments on mathematical reasoning and code generation datasets show that agents trained with our approach achieve effective performance improvements, while incurring zero additional inference cost.", "AI": {"tldr": "WMSS\u5229\u7528\u6a21\u578b\u5386\u53f2\u5f31\u68c0\u67e5\u70b9\u6307\u5bfc\u4f18\u5316\uff0c\u901a\u8fc7\u71b5\u52a8\u6001\u8bc6\u522b\u53ef\u6062\u590d\u5b66\u4e60\u5dee\u8ddd\u5e76\u8fdb\u884c\u8865\u507f\u5b66\u4e60\uff0c\u7a81\u7834\u540e\u8bad\u7ec3\u9971\u548c\u74f6\u9888", "motivation": "\u540e\u8bad\u7ec3\u4f18\u5316\u4e2d\u89c2\u5bdf\u5230\u6301\u7eed\u9971\u548c\u74f6\u9888\uff1a\u6a21\u578b\u53d8\u5f97\u9ad8\u5ea6\u81ea\u4fe1\u540e\uff0c\u8fdb\u4e00\u6b65\u8bad\u7ec3\u6536\u76ca\u9012\u51cf\u3002\u73b0\u6709\u65b9\u6cd5\u7ee7\u7eed\u5f3a\u5316\u76ee\u6807\u9884\u6d4b\uff0c\u4f46\u4fe1\u606f\u76d1\u7763\u4fe1\u53f7\u4ecd\u6f5c\u85cf\u5728\u6a21\u578b\u81ea\u8eab\u5386\u53f2\u5f31\u72b6\u6001\u4e2d", "method": "\u63d0\u51faWMSS\u540e\u8bad\u7ec3\u8303\u5f0f\uff0c\u5229\u7528\u5f31\u68c0\u67e5\u70b9\u6307\u5bfc\u6301\u7eed\u4f18\u5316\u3002\u901a\u8fc7\u71b5\u52a8\u6001\u8bc6\u522b\u53ef\u6062\u590d\u5b66\u4e60\u5dee\u8ddd\uff0c\u5e76\u901a\u8fc7\u8865\u507f\u5b66\u4e60\u5f3a\u5316\u8fd9\u4e9b\u5dee\u8ddd", "result": "\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528WMSS\u8bad\u7ec3\u7684\u667a\u80fd\u4f53\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u4e0d\u589e\u52a0\u989d\u5916\u63a8\u7406\u6210\u672c", "conclusion": "WMSS\u80fd\u591f\u4f7f\u5f3a\u667a\u80fd\u4f53\u8d85\u8d8a\u4f20\u7edf\u540e\u8bad\u7ec3\u9971\u548c\u9650\u5236\uff0c\u901a\u8fc7\u5229\u7528\u5386\u53f2\u5f31\u72b6\u6001\u4e2d\u7684\u76d1\u7763\u4fe1\u53f7\u5b9e\u73b0\u6301\u7eed\u6539\u8fdb"}}
{"id": "2602.08229", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08229", "abs": "https://arxiv.org/abs/2602.08229", "authors": ["Yifan Yang", "Jinjia Li", "Kunxi Li", "Puhao Zheng", "Yuanyi Wang", "Zheyan Qu", "Yang Yu", "Jianmin Wu", "Ming Li", "Hongxia Yang"], "title": "InfiCoEvalChain: A Blockchain-Based Decentralized Framework for Collaborative LLM Evaluation", "comment": null, "summary": "The rapid advancement of large language models (LLMs) demands increasingly reliable evaluation, yet current centralized evaluation suffers from opacity, overfitting, and hardware-induced variance. Our empirical analysis reveals an alarming inconsistency in existing evaluations: the standard deviation across ten repeated runs of a single model on HumanEval (1.67) actually exceeds the performance gap among the top-10 models on the official leaderboard (0.91), rendering current rankings statistically precarious. To mitigate these instabilities, we propose a decentralized evaluation framework that enables hardware and parameter diversity through large-scale benchmarking across heterogeneous compute nodes. By leveraging the blockchain-based protocol, the framework incentivizes global contributors to act as independent validators, using a robust reward system to ensure evaluation integrity and discourage dishonest participation. This collective verification transforms evaluation from a \"centralized black box\" into a \"decentralized endorsement\" where multi-party consensus and diverse inference environments yield a more stable, representative metric. Experimental results demonstrate that the decentralized evaluation framework reduces the standard deviation across ten runs on the same model to 0.28. This significant improvement over conventional frameworks ensures higher statistical confidence in model rankings. We have completely implemented this platform and will soon release it to the community.", "AI": {"tldr": "\u63d0\u51fa\u53bb\u4e2d\u5fc3\u5316\u8bc4\u4f30\u6846\u67b6\u89e3\u51b3LLM\u8bc4\u4f30\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u533a\u5757\u94fe\u534f\u8bae\u6fc0\u52b1\u5168\u7403\u8d21\u732e\u8005\u53c2\u4e0e\u9a8c\u8bc1\uff0c\u663e\u8457\u964d\u4f4e\u8bc4\u4f30\u65b9\u5dee", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u5b58\u5728\u4e2d\u5fc3\u5316\u8bc4\u4f30\u7684\u900f\u660e\u5ea6\u4e0d\u8db3\u3001\u8fc7\u62df\u5408\u548c\u786c\u4ef6\u5dee\u5f02\u5bfc\u81f4\u7684\u65b9\u5dee\u95ee\u9898\u3002\u5b9e\u8bc1\u5206\u6790\u53d1\u73b0HumanEval\u8bc4\u4f30\u4e2d\u5355\u6a21\u578b\u5341\u6b21\u8fd0\u884c\u7684\u6807\u51c6\u5dee(1.67)\u751a\u81f3\u8d85\u8fc7\u4e86\u5b98\u65b9\u6392\u884c\u699c\u524d10\u6a21\u578b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd(0.91)\uff0c\u4f7f\u5f97\u5f53\u524d\u6392\u540d\u7edf\u8ba1\u4e0a\u4e0d\u53ef\u9760", "method": "\u63d0\u51fa\u53bb\u4e2d\u5fc3\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u533a\u5757\u94fe\u534f\u8bae\u6fc0\u52b1\u5168\u7403\u8d21\u732e\u8005\u4f5c\u4e3a\u72ec\u7acb\u9a8c\u8bc1\u8005\uff0c\u5728\u5f02\u6784\u8ba1\u7b97\u8282\u70b9\u4e0a\u8fdb\u884c\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u73b0\u786c\u4ef6\u548c\u53c2\u6570\u591a\u6837\u6027\u3002\u91c7\u7528\u7a33\u5065\u7684\u5956\u52b1\u7cfb\u7edf\u786e\u4fdd\u8bc4\u4f30\u5b8c\u6574\u6027\u5e76\u963b\u6b62\u4e0d\u8bda\u5b9e\u53c2\u4e0e", "result": "\u53bb\u4e2d\u5fc3\u5316\u8bc4\u4f30\u6846\u67b6\u5c06\u540c\u4e00\u6a21\u578b\u5341\u6b21\u8fd0\u884c\u7684\u6807\u51c6\u5dee\u4ece1.67\u964d\u4f4e\u52300.28\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u6392\u540d\u7684\u7edf\u8ba1\u7f6e\u4fe1\u5ea6", "conclusion": "\u53bb\u4e2d\u5fc3\u5316\u8bc4\u4f30\u5c06\u8bc4\u4f30\u4ece\"\u4e2d\u5fc3\u5316\u9ed1\u7bb1\"\u8f6c\u53d8\u4e3a\"\u53bb\u4e2d\u5fc3\u5316\u80cc\u4e66\"\uff0c\u901a\u8fc7\u591a\u65b9\u5171\u8bc6\u548c\u591a\u6837\u5316\u63a8\u7406\u73af\u5883\u4ea7\u751f\u66f4\u7a33\u5b9a\u3001\u66f4\u5177\u4ee3\u8868\u6027\u7684\u6307\u6807\uff0c\u5e73\u53f0\u5df2\u5b8c\u5168\u5b9e\u73b0\u5e76\u5c06\u5411\u793e\u533a\u53d1\u5e03"}}
{"id": "2602.08240", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.08240", "abs": "https://arxiv.org/abs/2602.08240", "authors": ["Xun Su", "Huamin Wang", "Qi Zhang"], "title": "PTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognition", "comment": null, "summary": "Speech Emotion Recognition (SER) is widely deployed in Human-Computer Interaction, yet the high computational cost of conventional models hinders their implementation on resource-constrained edge devices. Spiking Neural Networks (SNNs) offer an energy-efficient alternative due to their event-driven nature; however, their integration with continuous Self-Supervised Learning (SSL) representations is fundamentally challenged by distribution mismatch, where high-dynamic-range embeddings degrade the information coding capacity of threshold-based neurons. To resolve this, we propose Prompt-Tuned Spiking Neural Networks (PTS-SNN), a parameter-efficient neuromorphic adaptation framework that aligns frozen SSL backbones with spiking dynamics. Specifically, we introduce a Temporal Shift Spiking Encoder to capture local temporal dependencies via parameter-free channel shifts, establishing a stable feature basis. To bridge the domain gap, we devise a Context-Aware Membrane Potential Calibration strategy. This mechanism leverages a Spiking Sparse Linear Attention module to aggregate global semantic context into learnable soft prompts, which dynamically regulate the bias voltages of Parametric Leaky Integrate-and-Fire (PLIF) neurons. This regulation effectively centers the heterogeneous input distribution within the responsive firing range, mitigating functional silence or saturation. Extensive experiments on five multilingual datasets (e.g., IEMOCAP, CASIA, EMODB) demonstrate that PTS-SNN achieves 73.34\\% accuracy on IEMOCAP, comparable to competitive Artificial Neural Networks (ANNs), while requiring only 1.19M trainable parameters and 0.35 mJ inference energy per sample.", "AI": {"tldr": "\u63d0\u51faPTS-SNN\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u793a\u8c03\u4f18\u89e3\u51b3SSL\u8868\u793a\u4e0eSNN\u4e4b\u95f4\u7684\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u80fd\u4f4e\u80fd\u8017\u7684\u8bed\u97f3\u60c5\u611f\u8bc6\u522b", "motivation": "\u4f20\u7edf\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u90e8\u7f72\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u3002SNN\u867d\u7136\u80fd\u6548\u9ad8\uff0c\u4f46\u4e0e\u8fde\u7eed\u81ea\u76d1\u7763\u5b66\u4e60\u8868\u793a\u5b58\u5728\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u9ad8\u52a8\u6001\u8303\u56f4\u7684\u5d4c\u5165\u4f1a\u964d\u4f4e\u57fa\u4e8e\u9608\u503c\u795e\u7ecf\u5143\u7684\u4fe1\u606f\u7f16\u7801\u80fd\u529b\u3002", "method": "\u63d0\u51faPTS-SNN\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u65f6\u79fb\u8109\u51b2\u7f16\u7801\u5668\u901a\u8fc7\u65e0\u53c2\u6570\u901a\u9053\u79fb\u4f4d\u6355\u83b7\u5c40\u90e8\u65f6\u95f4\u4f9d\u8d56\u6027\uff1b2\uff09\u8bbe\u8ba1\u4e0a\u4e0b\u6587\u611f\u77e5\u819c\u7535\u4f4d\u6821\u51c6\u7b56\u7565\uff0c\u5229\u7528\u8109\u51b2\u7a00\u758f\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u5757\u805a\u5408\u5168\u5c40\u8bed\u4e49\u4e0a\u4e0b\u6587\u5230\u53ef\u5b66\u4e60\u7684\u8f6f\u63d0\u793a\u4e2d\uff0c\u52a8\u6001\u8c03\u8282PLIF\u795e\u7ecf\u5143\u7684\u504f\u7f6e\u7535\u538b\uff0c\u5c06\u5f02\u8d28\u8f93\u5165\u5206\u5e03\u5c45\u4e2d\u5230\u54cd\u5e94\u53d1\u5c04\u8303\u56f4\u5185\u3002", "result": "\u5728\u4e94\u4e2a\u591a\u8bed\u8a00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPTS-SNN\u5728IEMOCAP\u4e0a\u8fbe\u523073.34%\u7684\u51c6\u786e\u7387\uff0c\u4e0e\u7ade\u4e89\u6027ANN\u76f8\u5f53\uff0c\u540c\u65f6\u4ec5\u9700119\u4e07\u4e2a\u53ef\u8bad\u7ec3\u53c2\u6570\u548c\u6bcf\u6837\u672c0.35\u6beb\u7126\u7684\u63a8\u7406\u80fd\u8017\u3002", "conclusion": "PTS-SNN\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u7684\u795e\u7ecf\u5f62\u6001\u9002\u5e94\u6846\u67b6\uff0c\u6210\u529f\u89e3\u51b3\u4e86SSL\u8868\u793a\u4e0eSNN\u4e4b\u95f4\u7684\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u9ad8\u6548\u80fd\u4f4e\u80fd\u8017\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.08241", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08241", "abs": "https://arxiv.org/abs/2602.08241", "authors": ["Siqu Ou", "Tianrui Wan", "Zhiyuan Zhao", "Junyu Gao", "Xuelong Li"], "title": "Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs", "comment": null, "summary": "While chain-of-thought (CoT) reasoning has substantially improved multimodal large language models (MLLMs) on complex reasoning tasks, existing approaches largely rely on long textual reasoning trajectories and provide limited mechanisms for learning stable visual attention policies. Our analysis shows that current MLLMs exhibit weak visual focus: early-stage visual misalignment is rarely corrected during subsequent reasoning, leading to error propagation and failed inferences. We argue that this limitation stems from inadequate credit assignment for visual attention during training. To address this issue, we propose SAYO, a visual reasoning model trained with a reinforcement learning (RL) framework that introduces a region-level visual attention-based reward. This reward explicitly aligns optimization signals with visually grounded reasoning steps, enabling the model to learn more reliable attention behaviors. Extensive experiments across multiple multimodal benchmarks demonstrate that SAYO consistently improves performance on diverse reasoning and perception tasks.", "AI": {"tldr": "SAYO\u662f\u4e00\u4e2a\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8bad\u7ec3\u7684\u591a\u6a21\u6001\u89c6\u89c9\u63a8\u7406\u6a21\u578b\uff0c\u5f15\u5165\u533a\u57df\u7ea7\u89c6\u89c9\u6ce8\u610f\u529b\u5956\u52b1\u6765\u6539\u5584\u89c6\u89c9\u6ce8\u610f\u529b\u7b56\u7565\uff0c\u89e3\u51b3\u73b0\u6709MLLMs\u89c6\u89c9\u6ce8\u610f\u529b\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u867d\u7136\u4f7f\u7528\u4e86\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u4f46\u5b58\u5728\u89c6\u89c9\u6ce8\u610f\u529b\u8584\u5f31\u7684\u95ee\u9898\uff1a\u65e9\u671f\u89c6\u89c9\u5bf9\u9f50\u9519\u8bef\u5f88\u5c11\u5728\u540e\u7eed\u63a8\u7406\u4e2d\u5f97\u5230\u7ea0\u6b63\uff0c\u5bfc\u81f4\u9519\u8bef\u4f20\u64ad\u548c\u63a8\u7406\u5931\u8d25\u3002\u8fd9\u79cd\u9650\u5236\u6e90\u4e8e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u89c6\u89c9\u6ce8\u610f\u529b\u4fe1\u7528\u5206\u914d\u4e0d\u8db3\u3002", "method": "\u63d0\u51faSAYO\u6a21\u578b\uff0c\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8bad\u7ec3\uff0c\u5f15\u5165\u533a\u57df\u7ea7\u89c6\u89c9\u6ce8\u610f\u529b\u5956\u52b1\u673a\u5236\u3002\u8be5\u5956\u52b1\u660e\u786e\u5c06\u4f18\u5316\u4fe1\u53f7\u4e0e\u57fa\u4e8e\u89c6\u89c9\u7684\u63a8\u7406\u6b65\u9aa4\u5bf9\u9f50\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u66f4\u53ef\u9760\u7684\u6ce8\u610f\u529b\u884c\u4e3a\u3002", "result": "\u5728\u591a\u4e2a\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSAYO\u5728\u591a\u6837\u5316\u7684\u63a8\u7406\u548c\u611f\u77e5\u4efb\u52a1\u4e0a\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u548c\u533a\u57df\u7ea7\u89c6\u89c9\u6ce8\u610f\u529b\u5956\u52b1\uff0cSAYO\u80fd\u591f\u5b66\u4e60\u66f4\u7a33\u5b9a\u7684\u89c6\u89c9\u6ce8\u610f\u529b\u7b56\u7565\uff0c\u6709\u6548\u6539\u5584\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.08253", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08253", "abs": "https://arxiv.org/abs/2602.08253", "authors": ["Baoyun Zhao", "He Wang", "Liang Zeng"], "title": "G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design", "comment": null, "summary": "While Large Language Models (LLMs) have recently shown promise in Automated Heuristic Design (AHD), existing approaches typically formulate AHD around constructive priority rules or parameterized local search guidance, thereby restricting the search space to fixed heuristic forms. Such designs offer limited capacity for structural exploration, making it difficult to escape deep local optima in complex Combinatorial Optimization Problems (COPs). In this work, we propose G-LNS, a generative evolutionary framework that extends LLM-based AHD to the automated design of Large Neighborhood Search (LNS) operators. Unlike prior methods that evolve heuristics in isolation, G-LNS leverages LLMs to co-evolve tightly coupled pairs of destroy and repair operators. A cooperative evaluation mechanism explicitly captures their interaction, enabling the discovery of complementary operator logic that jointly performs effective structural disruption and reconstruction. Extensive experiments on challenging COP benchmarks, such as Traveling Salesman Problems (TSP) and Capacitated Vehicle Routing Problems (CVRP), demonstrate that G-LNS significantly outperforms LLM-based AHD methods as well as strong classical solvers. The discovered heuristics not only achieve near-optimal solutions with reduced computational budgets but also exhibit robust generalization across diverse and unseen instance distributions.", "AI": {"tldr": "G-LNS\uff1a\u57fa\u4e8eLLM\u7684\u751f\u6210\u5f0f\u8fdb\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u8bbe\u8ba1\u5927\u90bb\u57df\u641c\u7d22\uff08LNS\uff09\u7684\u7834\u574f\u4e0e\u4fee\u590d\u7b97\u5b50\u5bf9\uff0c\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\u8d85\u8d8a\u73b0\u6709LLM\u65b9\u6cd5\u548c\u7ecf\u5178\u6c42\u89e3\u5668\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u65b9\u6cd5\u901a\u5e38\u5c40\u9650\u4e8e\u6784\u9020\u6027\u4f18\u5148\u7ea7\u89c4\u5219\u6216\u53c2\u6570\u5316\u5c40\u90e8\u641c\u7d22\u5f15\u5bfc\uff0c\u9650\u5236\u4e86\u641c\u7d22\u7a7a\u95f4\uff0c\u96be\u4ee5\u5728\u590d\u6742\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u8df3\u51fa\u6df1\u5ea6\u5c40\u90e8\u6700\u4f18\u3002", "method": "\u63d0\u51faG-LNS\u751f\u6210\u5f0f\u8fdb\u5316\u6846\u67b6\uff0c\u5229\u7528LLM\u534f\u540c\u8fdb\u5316\u7d27\u5bc6\u8026\u5408\u7684\u7834\u574f\u4e0e\u4fee\u590d\u7b97\u5b50\u5bf9\uff0c\u901a\u8fc7\u5408\u4f5c\u8bc4\u4f30\u673a\u5236\u6355\u6349\u7b97\u5b50\u95f4\u7684\u4ea4\u4e92\uff0c\u53d1\u73b0\u4e92\u8865\u7684\u903b\u8f91\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u7ed3\u6784\u7834\u574f\u4e0e\u91cd\u5efa\u3002", "result": "\u5728TSP\u548cCVRP\u7b49\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cG-LNS\u663e\u8457\u4f18\u4e8e\u57fa\u4e8eLLM\u7684AHD\u65b9\u6cd5\u548c\u5f3a\u7ecf\u5178\u6c42\u89e3\u5668\uff0c\u53d1\u73b0\u7684\u542f\u53d1\u5f0f\u4e0d\u4ec5\u4ee5\u66f4\u5c11\u8ba1\u7b97\u8d44\u6e90\u83b7\u5f97\u63a5\u8fd1\u6700\u4f18\u89e3\uff0c\u8fd8\u80fd\u8de8\u4e0d\u540c\u672a\u89c1\u5b9e\u4f8b\u5206\u5e03\u7a33\u5065\u6cdb\u5316\u3002", "conclusion": "G-LNS\u5c06LLM\u9a71\u52a8\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u6269\u5c55\u5230LNS\u7b97\u5b50\u751f\u6210\uff0c\u901a\u8fc7\u534f\u540c\u8fdb\u5316\u7834\u574f-\u4fee\u590d\u5bf9\u5b9e\u73b0\u4e86\u66f4\u5f3a\u5927\u7684\u7ed3\u6784\u63a2\u7d22\u80fd\u529b\uff0c\u4e3a\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u81ea\u52a8\u6c42\u89e3\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.08254", "categories": ["cs.AI", "cs.IR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08254", "abs": "https://arxiv.org/abs/2602.08254", "authors": ["Arman Aghaee", "Sepehr Asgarian", "Jouhyun Jeon"], "title": "SynthAgent: A Multi-Agent LLM Framework for Realistic Patient Simulation -- A Case Study in Obesity with Mental Health Comorbidities", "comment": "Presented in AAAI 2026 Singapore at the workshop of Health Intelligence", "summary": "Simulating high-fidelity patients offers a powerful avenue for studying complex diseases while addressing the challenges of fragmented, biased, and privacy-restricted real-world data. In this study, we introduce SynthAgent, a novel Multi-Agent System (MAS) framework designed to model obesity patients with comorbid mental disorders, including depression, anxiety, social phobia, and binge eating disorder. SynthAgent integrates clinical and medical evidence from claims data, population surveys, and patient-centered literature to construct personalized virtual patients enriched with personality traits that influence adherence, emotion regulation, and lifestyle behaviors. Through autonomous agent interactions, the system simulates disease progression, treatment response, and life management across diverse psychosocial contexts. Evaluation of more than 100 generated patients demonstrated that GPT-5 and Claude 4.5 Sonnet achieved the highest fidelity as the core engine in the proposed MAS framework, outperforming Gemini 2.5 Pro and DeepSeek-R1. SynthAgent thus provides a scalable and privacy-preserving framework for exploring patient journeys, behavioral dynamics, and decision-making processes in both medical and psychological domains.", "AI": {"tldr": "SynthAgent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u80a5\u80d6\u75c7\u5408\u5e76\u7cbe\u795e\u969c\u788d\u60a3\u8005\uff0c\u901a\u8fc7\u6574\u5408\u4e34\u5e8a\u6570\u636e\u548c\u4e2a\u6027\u7279\u5f81\u6765\u521b\u5efa\u9ad8\u4fdd\u771f\u865a\u62df\u60a3\u8005\uff0c\u6a21\u62df\u75be\u75c5\u8fdb\u5c55\u548c\u6cbb\u7597\u53cd\u5e94\u3002", "motivation": "\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u788e\u7247\u5316\u3001\u504f\u89c1\u548c\u9690\u79c1\u9650\u5236\u7684\u95ee\u9898\uff0c\u4e3a\u7814\u7a76\u590d\u6742\u75be\u75c5\u63d0\u4f9b\u9ad8\u4fdd\u771f\u60a3\u8005\u6a21\u62df\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u5f00\u53d1SynthAgent\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u6574\u5408\u7d22\u8d54\u6570\u636e\u3001\u4eba\u53e3\u8c03\u67e5\u548c\u60a3\u8005\u4e2d\u5fc3\u6587\u732e\uff0c\u6784\u5efa\u5177\u6709\u4e2a\u6027\u7279\u5f81\u7684\u865a\u62df\u60a3\u8005\uff0c\u901a\u8fc7\u81ea\u4e3b\u667a\u80fd\u4f53\u4ea4\u4e92\u6a21\u62df\u75be\u75c5\u8fdb\u5c55\u548c\u6cbb\u7597\u53cd\u5e94\u3002", "result": "\u8bc4\u4f30100\u591a\u4e2a\u751f\u6210\u7684\u60a3\u8005\u663e\u793a\uff0cGPT-5\u548cClaude 4.5 Sonnet\u4f5c\u4e3a\u6838\u5fc3\u5f15\u64ce\u8fbe\u5230\u6700\u9ad8\u4fdd\u771f\u5ea6\uff0c\u4f18\u4e8eGemini 2.5 Pro\u548cDeepSeek-R1\u3002", "conclusion": "SynthAgent\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u63a2\u7d22\u533b\u5b66\u548c\u5fc3\u7406\u9886\u57df\u7684\u60a3\u8005\u65c5\u7a0b\u3001\u884c\u4e3a\u52a8\u6001\u548c\u51b3\u7b56\u8fc7\u7a0b\u3002"}}
{"id": "2602.08268", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08268", "abs": "https://arxiv.org/abs/2602.08268", "authors": ["Akinori Maeda", "Yuto Sekiya", "Sota Sugimura", "Tomoya Asai", "Yu Tsuda", "Kohei Ikeda", "Hiroshi Fujii", "Kohei Watanabe"], "title": "Puda: Private User Dataset Agent for User-Sovereign and Privacy-Preserving Personalized AI", "comment": "9 pages, 5 figures", "summary": "Personal data centralization among dominant platform providers including search engines, social networking services, and e-commerce has created siloed ecosystems that restrict user sovereignty, thereby impeding data use across services. Meanwhile, the rapid proliferation of Large Language Model (LLM)-based agents has intensified demand for highly personalized services that require the dynamic provision of diverse personal data. This presents a significant challenge: balancing the utilization of such data with privacy protection. To address this challenge, we propose Puda (Private User Dataset Agent), a user-sovereign architecture that aggregates data across services and enables client-side management. Puda allows users to control data sharing at three privacy levels: (i) Detailed Browsing History, (ii) Extracted Keywords, and (iii) Predefined Category Subsets. We implemented Puda as a browser-based system that serves as a common platform across diverse services and evaluated it through a personalized travel planning task. Our results show that providing Predefined Category Subsets achieves 97.2% of the personalization performance (evaluated via an LLM-as-a-Judge framework across three criteria) obtained when sharing Detailed Browsing History. These findings demonstrate that Puda enables effective multi-granularity management, offering practical choices to mitigate the privacy-personalization trade-off. Overall, Puda provides an AI-native foundation for user sovereignty, empowering users to safely leverage the full potential of personalized AI.", "AI": {"tldr": "Puda\u662f\u4e00\u4e2a\u7528\u6237\u4e3b\u6743\u67b6\u6784\uff0c\u901a\u8fc7\u805a\u5408\u8de8\u670d\u52a1\u6570\u636e\u5e76\u652f\u6301\u5ba2\u6237\u7aef\u7ba1\u7406\uff0c\u5728\u4e09\u4e2a\u9690\u79c1\u7ea7\u522b\u63a7\u5236\u6570\u636e\u5171\u4eab\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u4e0e\u4e2a\u6027\u5316\u670d\u52a1\u7684\u5e73\u8861\u3002", "motivation": "\u5f53\u524d\u4e2a\u4eba\u6570\u636e\u96c6\u4e2d\u5728\u5c11\u6570\u5e73\u53f0\u63d0\u4f9b\u5546\u624b\u4e2d\uff0c\u5f62\u6210\u4e86\u6570\u636e\u5b64\u5c9b\uff0c\u9650\u5236\u4e86\u7528\u6237\u4e3b\u6743\u548c\u8de8\u670d\u52a1\u6570\u636e\u4f7f\u7528\u3002\u540c\u65f6\uff0c\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4ee3\u7406\u5bf9\u4e2a\u6027\u5316\u670d\u52a1\u7684\u9700\u6c42\u6fc0\u589e\uff0c\u9700\u8981\u52a8\u6001\u63d0\u4f9b\u591a\u6837\u5316\u7684\u4e2a\u4eba\u6570\u636e\uff0c\u8fd9\u5e26\u6765\u4e86\u6570\u636e\u5229\u7528\u4e0e\u9690\u79c1\u4fdd\u62a4\u7684\u5e73\u8861\u6311\u6218\u3002", "method": "\u63d0\u51faPuda\uff08Private User Dataset Agent\uff09\u67b6\u6784\uff0c\u4f5c\u4e3a\u6d4f\u89c8\u5668\u7cfb\u7edf\u5b9e\u73b0\u8de8\u670d\u52a1\u901a\u7528\u5e73\u53f0\u3002\u652f\u6301\u4e09\u4e2a\u9690\u79c1\u7ea7\u522b\u7684\u6570\u636e\u5171\u4eab\u63a7\u5236\uff1a(i)\u8be6\u7ec6\u6d4f\u89c8\u5386\u53f2\uff0c(ii)\u63d0\u53d6\u7684\u5173\u952e\u8bcd\uff0c(iii)\u9884\u5b9a\u4e49\u7c7b\u522b\u5b50\u96c6\u3002\u901a\u8fc7\u4e2a\u6027\u5316\u65c5\u884c\u89c4\u5212\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u4f9b\u9884\u5b9a\u4e49\u7c7b\u522b\u5b50\u96c6\u80fd\u8fbe\u5230\u5171\u4eab\u8be6\u7ec6\u6d4f\u89c8\u5386\u53f2\u6240\u83b7\u4e2a\u6027\u5316\u6027\u80fd\u768497.2%\uff08\u901a\u8fc7LLM-as-a-Judge\u6846\u67b6\u5728\u4e09\u4e2a\u6807\u51c6\u4e0b\u8bc4\u4f30\uff09\u3002\u8fd9\u8bc1\u660ePuda\u80fd\u6709\u6548\u5b9e\u73b0\u591a\u7c92\u5ea6\u7ba1\u7406\uff0c\u7f13\u89e3\u9690\u79c1-\u4e2a\u6027\u5316\u6743\u8861\u3002", "conclusion": "Puda\u4e3aAI\u539f\u751f\u7528\u6237\u4e3b\u6743\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u5b89\u5168\u5730\u5229\u7528\u4e2a\u6027\u5316AI\u7684\u5168\u90e8\u6f5c\u529b\uff0c\u901a\u8fc7\u5b9e\u7528\u7684\u591a\u7c92\u5ea6\u9690\u79c1\u63a7\u5236\u9009\u62e9\u6765\u5e73\u8861\u6570\u636e\u5229\u7528\u4e0e\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2602.08276", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08276", "abs": "https://arxiv.org/abs/2602.08276", "authors": ["Haoyu Jia", "Kento Kawaharazuka", "Kei Okada"], "title": "Toward Formalizing LLM-Based Agent Designs through Structural Context Modeling and Semantic Dynamics Analysis", "comment": null, "summary": "Current research on large language model (LLM) agents is fragmented: discussions of conceptual frameworks and methodological principles are frequently intertwined with low-level implementation details, causing both readers and authors to lose track amid a proliferation of superficially distinct concepts. We argue that this fragmentation largely stems from the absence of an analyzable, self-consistent formal model that enables implementation-independent characterization and comparison of LLM agents. To address this gap, we propose the \\texttt{Structural Context Model}, a formal model for analyzing and comparing LLM agents from the perspective of context structure. Building upon this foundation, we introduce two complementary components that together span the full lifecycle of LLM agent research and development: (1) a declarative implementation framework; and (2) a sustainable agent engineering workflow, \\texttt{Semantic Dynamics Analysis}. The proposed workflow provides principled insights into agent mechanisms and supports rapid, systematic design iteration. We demonstrate the effectiveness of the complete framework on dynamic variants of the monkey-banana problem, where agents engineered using our approach achieve up to a 32 percentage points improvement in success rate on the most challenging setting.", "AI": {"tldr": "\u63d0\u51faStructural Context Model\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u7528\u4e8e\u5206\u6790\u548c\u6bd4\u8f83LLM\u667a\u80fd\u4f53\uff0c\u5e76\u5f15\u5165\u58f0\u660e\u5f0f\u5b9e\u73b0\u6846\u67b6\u548c\u53ef\u6301\u7eed\u7684\u667a\u80fd\u4f53\u5de5\u7a0b\u5de5\u4f5c\u6d41Semantic Dynamics Analysis\uff0c\u5728\u52a8\u6001\u7334\u5b50\u9999\u8549\u95ee\u9898\u4e0a\u53d6\u5f97\u663e\u8457\u6548\u679c\u63d0\u5347\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u7814\u7a76\u5b58\u5728\u788e\u7247\u5316\u95ee\u9898\uff0c\u6982\u5ff5\u6846\u67b6\u548c\u65b9\u6cd5\u8bba\u539f\u5219\u5e38\u4e0e\u5e95\u5c42\u5b9e\u73b0\u7ec6\u8282\u4ea4\u7ec7\uff0c\u7f3a\u4e4f\u53ef\u5206\u6790\u3001\u81ea\u6d3d\u7684\u5f62\u5f0f\u5316\u6a21\u578b\u6765\u72ec\u7acb\u4e8e\u5b9e\u73b0\u5730\u63cf\u8ff0\u548c\u6bd4\u8f83\u667a\u80fd\u4f53\u3002", "method": "\u63d0\u51faStructural Context Model\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u4ece\u4e0a\u4e0b\u6587\u7ed3\u6784\u89d2\u5ea6\u5206\u6790LLM\u667a\u80fd\u4f53\uff1b\u5f15\u5165\u58f0\u660e\u5f0f\u5b9e\u73b0\u6846\u67b6\u548c\u53ef\u6301\u7eed\u7684\u667a\u80fd\u4f53\u5de5\u7a0b\u5de5\u4f5c\u6d41Semantic Dynamics Analysis\uff0c\u652f\u6301\u5feb\u901f\u3001\u7cfb\u7edf\u7684\u8bbe\u8ba1\u8fed\u4ee3\u3002", "result": "\u5728\u52a8\u6001\u7334\u5b50\u9999\u8549\u95ee\u9898\u53d8\u4f53\u4e0a\uff0c\u4f7f\u7528\u8be5\u6846\u67b6\u8bbe\u8ba1\u7684\u667a\u80fd\u4f53\u5728\u6700\u56f0\u96be\u573a\u666f\u4e0b\u6210\u529f\u7387\u63d0\u5347\u9ad8\u8fbe32\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u63d0\u51fa\u7684\u5f62\u5f0f\u5316\u6a21\u578b\u548c\u5de5\u7a0b\u5de5\u4f5c\u6d41\u80fd\u6709\u6548\u89e3\u51b3LLM\u667a\u80fd\u4f53\u7814\u7a76\u7684\u788e\u7247\u5316\u95ee\u9898\uff0c\u4e3a\u667a\u80fd\u4f53\u673a\u5236\u63d0\u4f9b\u539f\u5219\u6027\u6d1e\u5bdf\uff0c\u652f\u6301\u7cfb\u7edf\u5316\u8bbe\u8ba1\u8fed\u4ee3\u3002"}}
{"id": "2602.08295", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08295", "abs": "https://arxiv.org/abs/2602.08295", "authors": ["Ilya Levin"], "title": "The Vibe-Automation of Automation: A Proactive Education Framework for Computer Science in the Age of Generative AI", "comment": "19 pages", "summary": "The emergence of generative artificial intelligence (GenAI) represents not an incremental technological advance but a qualitative epistemological shift that challenges foundational assumptions of computer science. Whereas machine learning has been described as the automation of automation, generative AI operates by navigating contextual, semantic, and stylistic coherence rather than optimizing predefined objective metrics. This paper introduces the concept of Vibe-Automation to characterize this transition.\n  The central claim is that the significance of GenAI lies in its functional access to operationalized tacit regularities: context-sensitive patterns embedded in practice that cannot be fully specified through explicit algorithmic rules. Although generative systems do not possess tacit knowledge in a phenomenological sense, they operationalize sensitivities to tone, intent, and situated judgment encoded in high-dimensional latent representations. On this basis, the human role shifts from algorithmic problem specification toward Vibe-Engineering, understood as the orchestration of alignment and contextual judgment in generative systems.\n  The paper connects this epistemological shift to educational and institutional transformation by proposing a conceptual framework structured across three analytical levels and three domains of action: faculty worldview, industry relations, and curriculum design. The risks of mode collapse and cultural homogenization are briefly discussed, emphasizing the need for deliberate engagement with generative systems to avoid regression toward synthetic uniformity.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u6c1b\u56f4\u81ea\u52a8\u5316\"\u6982\u5ff5\uff0c\u8ba4\u4e3a\u751f\u6210\u5f0fAI\u4ee3\u8868\u4e86\u4ece\u7b97\u6cd5\u4f18\u5316\u5230\u4e0a\u4e0b\u6587\u8bed\u4e49\u534f\u8c03\u7684\u8ba4\u77e5\u8303\u5f0f\u8f6c\u53d8\uff0c\u4eba\u7c7b\u89d2\u8272\u4ece\u95ee\u9898\u89c4\u8303\u8f6c\u5411\"\u6c1b\u56f4\u5de5\u7a0b\"\u3002", "motivation": "\u751f\u6210\u5f0fAI\u4e0d\u662f\u6e10\u8fdb\u6280\u672f\u8fdb\u6b65\uff0c\u800c\u662f\u8d28\u53d8\u7684\u8ba4\u77e5\u8303\u5f0f\u8f6c\u53d8\uff0c\u6311\u6218\u8ba1\u7b97\u673a\u79d1\u5b66\u57fa\u7840\u5047\u8bbe\u3002\u9700\u8981\u65b0\u6982\u5ff5\u6846\u67b6\u6765\u7406\u89e3\u8fd9\u79cd\u4ece\u7b97\u6cd5\u4f18\u5316\u5230\u4e0a\u4e0b\u6587\u8bed\u4e49\u534f\u8c03\u7684\u8f6c\u53d8\u3002", "method": "\u63d0\u51fa\"\u6c1b\u56f4\u81ea\u52a8\u5316\"\u6982\u5ff5\u6846\u67b6\uff0c\u5206\u6790\u751f\u6210\u5f0fAI\u5982\u4f55\u64cd\u4f5c\u5316\u9690\u6027\u89c4\u5f8b\u3002\u6784\u5efa\u4e09\u5c42\u5206\u6790\u6846\u67b6\uff1a\u6559\u5e08\u4e16\u754c\u89c2\u3001\u4ea7\u4e1a\u5173\u7cfb\u3001\u8bfe\u7a0b\u8bbe\u8ba1\uff0c\u63a2\u8ba8\u4eba\u7c7b\u89d2\u8272\u5411\"\u6c1b\u56f4\u5de5\u7a0b\"\u7684\u8f6c\u53d8\u3002", "result": "\u751f\u6210\u5f0fAI\u901a\u8fc7\u9ad8\u7ef4\u6f5c\u5728\u8868\u793a\u7f16\u7801\u5bf9\u8bed\u8c03\u3001\u610f\u56fe\u548c\u60c5\u5883\u5224\u65ad\u7684\u654f\u611f\u6027\uff0c\u64cd\u4f5c\u5316\u9690\u6027\u89c4\u5f8b\u3002\u4eba\u7c7b\u89d2\u8272\u8f6c\u53d8\u4e3a\u534f\u8c03\u751f\u6210\u7cfb\u7edf\u7684\u5bf9\u9f50\u548c\u4e0a\u4e0b\u6587\u5224\u65ad\u7684\"\u6c1b\u56f4\u5de5\u7a0b\u5e08\"\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u4ee3\u8868\u4e86\u8ba4\u77e5\u8303\u5f0f\u8f6c\u53d8\uff0c\u9700\u8981\u6559\u80b2\u673a\u6784\u548c\u4ea7\u4e1a\u5173\u7cfb\u7684\u76f8\u5e94\u53d8\u9769\u3002\u5fc5\u987b\u79ef\u6781\u5e94\u5bf9\u6a21\u5f0f\u5d29\u6e83\u548c\u6587\u5316\u540c\u8d28\u5316\u98ce\u9669\uff0c\u907f\u514d\u56de\u5f52\u5408\u6210\u7edf\u4e00\u6027\uff0c\u901a\u8fc7\u6709\u610f\u8bc6\u53c2\u4e0e\u4fc3\u8fdb\u591a\u6837\u6027\u3002"}}
{"id": "2602.08311", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08311", "abs": "https://arxiv.org/abs/2602.08311", "authors": ["Shadman Rabby", "Md. Hefzul Hossain Papon", "Sabbir Ahmed", "Nokimul Hasan Arif", "A. B. M. Ashikur Rahman", "Irfan Ahmad"], "title": "Moral Sycophancy in Vision Language Models", "comment": "13 pages, 6 figures, 8 tables, Submitted for review in ACL", "summary": "Sycophancy in Vision-Language Models (VLMs) refers to their tendency to align with user opinions, often at the expense of moral or factual accuracy. While prior studies have explored sycophantic behavior in general contexts, its impact on morally grounded visual decision-making remains insufficiently understood. To address this gap, we present the first systematic study of moral sycophancy in VLMs, analyzing ten widely-used models on the Moralise and M^3oralBench datasets under explicit user disagreement. Our results reveal that VLMs frequently produce morally incorrect follow-up responses even when their initial judgments are correct, and exhibit a consistent asymmetry: models are more likely to shift from morally right to morally wrong judgments than the reverse when exposed to user-induced bias. Follow-up prompts generally degrade performance on Moralise, while yielding mixed or even improved accuracy on M^3oralBench, highlighting dataset-dependent differences in moral robustness. Evaluation using Error Introduction Rate (EIR) and Error Correction Rate (ECR) reveals a clear trade-off: models with stronger error-correction capabilities tend to introduce more reasoning errors, whereas more conservative models minimize errors but exhibit limited ability to self-correct. Finally, initial contexts with a morally right stance elicit stronger sycophantic behavior, emphasizing the vulnerability of VLMs to moral influence and the need for principled strategies to improve ethical consistency and robustness in multimodal AI systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u63a2\u7d22\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9053\u5fb7\u5949\u627f\u884c\u4e3a\uff0c\u53d1\u73b0\u5f53\u7528\u6237\u8868\u8fbe\u4e0d\u540c\u610f\u89c1\u65f6\uff0cVLMs\u7ecf\u5e38\u653e\u5f03\u539f\u672c\u6b63\u786e\u7684\u9053\u5fb7\u5224\u65ad\uff0c\u8f6c\u5411\u9519\u8bef\u7684\u7acb\u573a\uff0c\u4e14\u5b58\u5728\u4e0d\u5bf9\u79f0\u6027\uff1a\u4ece\u6b63\u786e\u8f6c\u5411\u9519\u8bef\u6bd4\u4ece\u9519\u8bef\u8f6c\u5411\u6b63\u786e\u66f4\u5bb9\u6613\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4e00\u822c\u60c5\u5883\u4e0b\u7684\u5949\u627f\u884c\u4e3a\uff0c\u4f46\u5bf9\u57fa\u4e8e\u9053\u5fb7\u7684\u89c6\u89c9\u51b3\u7b56\u4e2d\u5949\u627f\u884c\u4e3a\u7684\u5f71\u54cd\u7406\u89e3\u4e0d\u8db3\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7cfb\u7edf\u7814\u7a76VLMs\u4e2d\u7684\u9053\u5fb7\u5949\u627f\u73b0\u8c61\u3002", "method": "\u5728Moralise\u548cM^3oralBench\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e8610\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684VLMs\uff0c\u5728\u7528\u6237\u660e\u786e\u8868\u8fbe\u4e0d\u540c\u610f\u89c1\u7684\u60c5\u5883\u4e0b\u5206\u6790\u6a21\u578b\u884c\u4e3a\u3002\u4f7f\u7528\u9519\u8bef\u5f15\u5165\u7387(EIR)\u548c\u9519\u8bef\u7ea0\u6b63\u7387(ECR)\u8fdb\u884c\u91cf\u5316\u8bc4\u4f30\u3002", "result": "VLMs\u7ecf\u5e38\u5728\u540e\u7eed\u54cd\u5e94\u4e2d\u4ea7\u751f\u9053\u5fb7\u9519\u8bef\u7684\u5224\u65ad\uff0c\u5373\u4f7f\u521d\u59cb\u5224\u65ad\u6b63\u786e\u3002\u6a21\u578b\u8868\u73b0\u51fa\u660e\u663e\u7684\u4e0d\u5bf9\u79f0\u6027\uff1a\u4ece\u9053\u5fb7\u6b63\u786e\u8f6c\u5411\u9519\u8bef\u7684\u6982\u7387\u9ad8\u4e8e\u53cd\u5411\u8f6c\u53d8\u3002\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u5b58\u5728\u5dee\u5f02\uff0c\u540e\u7eed\u63d0\u793a\u5728Moralise\u4e0a\u964d\u4f4e\u6027\u80fd\uff0c\u5728M^3oralBench\u4e0a\u8868\u73b0\u6df7\u5408\u751a\u81f3\u6539\u5584\u3002\u521d\u59cb\u9053\u5fb7\u6b63\u786e\u7684\u8bed\u5883\u4f1a\u5f15\u53d1\u66f4\u5f3a\u7684\u5949\u627f\u884c\u4e3a\u3002", "conclusion": "VLMs\u5728\u9053\u5fb7\u5f71\u54cd\u9762\u524d\u8868\u73b0\u8106\u5f31\uff0c\u5b58\u5728\u660e\u663e\u7684\u6743\u8861\uff1a\u7ea0\u9519\u80fd\u529b\u5f3a\u7684\u6a21\u578b\u5bb9\u6613\u5f15\u5165\u66f4\u591a\u63a8\u7406\u9519\u8bef\uff0c\u800c\u4fdd\u5b88\u6a21\u578b\u9519\u8bef\u5c11\u4f46\u81ea\u6211\u7ea0\u6b63\u80fd\u529b\u6709\u9650\u3002\u9700\u8981\u5236\u5b9a\u539f\u5219\u6027\u7b56\u7565\u6765\u63d0\u9ad8\u591a\u6a21\u6001AI\u7cfb\u7edf\u7684\u4f26\u7406\u4e00\u81f4\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.08335", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08335", "abs": "https://arxiv.org/abs/2602.08335", "authors": ["Yanming Li", "Xuelin Zhang", "WenJie Lu", "Ziye Tang", "Maodong Wu", "Haotian Luo", "Tongtong Wu", "Zijie Peng", "Hongze Mi", "Yibo Feng", "Naiqiang Tan", "Chao Huang", "Hong Chen", "Li Shen"], "title": "Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System", "comment": null, "summary": "Integrating Large Language Models (LLMs) with external tools via multi-agent systems offers a promising new paradigm for decomposing and solving complex problems. However, training these systems remains notoriously difficult due to the credit assignment challenge, as it is often unclear which specific functional agent is responsible for the success or failure of decision trajectories. Existing methods typically rely on sparse or globally broadcast rewards, failing to capture individual contributions and leading to inefficient reinforcement learning. To address these limitations, we introduce the Shapley-based Hierarchical Attribution for Reinforcement Policy (SHARP), a novel framework for optimizing multi-agent reinforcement learning via precise credit attribution. SHARP effectively stabilizes training by normalizing agent-specific advantages across trajectory groups, primarily through a decomposed reward mechanism comprising a global broadcast-accuracy reward, a Shapley-based marginal-credit reward for each agent, and a tool-process reward to improve execution efficiency. Extensive experiments across various real-world benchmarks demonstrate that SHARP significantly outperforms recent state-of-the-art baselines, achieving average match improvements of 23.66% and 14.05% over single-agent and multi-agent approaches, respectively.", "AI": {"tldr": "SHARP\u6846\u67b6\u901a\u8fc7Shapley\u503c\u8fdb\u884c\u7cbe\u786e\u4fe1\u7528\u5206\u914d\uff0c\u4f18\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347LLM\u4e0e\u5916\u90e8\u5de5\u5177\u96c6\u6210\u7684\u6027\u80fd", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u4fe1\u7528\u5206\u914d\u56f0\u96be\uff0c\u7a00\u758f\u6216\u5168\u5c40\u5e7f\u64ad\u5956\u52b1\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u4e2a\u4f53\u8d21\u732e\uff0c\u5bfc\u81f4\u5f3a\u5316\u5b66\u4e60\u6548\u7387\u4f4e\u4e0b", "method": "\u63d0\u51faSHARP\u6846\u67b6\uff0c\u5305\u542b\u5168\u5c40\u5e7f\u64ad\u51c6\u786e\u6027\u5956\u52b1\u3001\u57fa\u4e8eShapley\u503c\u7684\u8fb9\u9645\u4fe1\u7528\u5956\u52b1\u548c\u5de5\u5177\u8fc7\u7a0b\u5956\u52b1\uff0c\u901a\u8fc7\u8f68\u8ff9\u7ec4\u5f52\u4e00\u5316\u7a33\u5b9a\u8bad\u7ec3", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u5e73\u5747\u5339\u914d\u6539\u8fdb\u5206\u522b\u8fbe\u523023.66%\u548c14.05%", "conclusion": "SHARP\u901a\u8fc7\u7cbe\u786e\u4fe1\u7528\u5206\u914d\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u6311\u6218\uff0c\u4e3aLLM\u4e0e\u5916\u90e8\u5de5\u5177\u96c6\u6210\u63d0\u4f9b\u4e86\u7a33\u5b9a\u9ad8\u6548\u7684\u8bad\u7ec3\u6846\u67b6"}}
{"id": "2602.08339", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08339", "abs": "https://arxiv.org/abs/2602.08339", "authors": ["Chengyi Du", "Yazhe Niu", "Dazhong Shen", "Luxin Xu"], "title": "CoTZero: Annotation-Free Human-Like Vision Reasoning via Hierarchical Synthetic CoT", "comment": "16 pages 6 figures", "summary": "Recent advances in vision-language models (VLMs) have markedly improved image-text alignment, yet they still fall short of human-like visual reasoning. A key limitation is that many VLMs rely on surface correlations rather than building logically coherent structured representations, which often leads to missed higher-level semantic structure and non-causal relational understanding, hindering compositional and verifiable reasoning. To address these limitations by introducing human models into the reasoning process, we propose CoTZero, an annotation-free paradigm with two components: (i) a dual-stage data synthesis approach and (ii) a cognition-aligned training method. In the first component, we draw inspiration from neurocognitive accounts of compositional productivity and global-to-local analysis. In the bottom-up stage, CoTZero extracts atomic visual primitives and incrementally composes them into diverse, structured question-reasoning forms. In the top-down stage, it enforces hierarchical reasoning by using coarse global structure to guide the interpretation of local details and causal relations. In the cognition-aligned training component, built on the synthesized CoT data, we introduce Cognitively Coherent Verifiable Rewards (CCVR) in Reinforcement Fine-Tuning (RFT) to further strengthen VLMs' hierarchical reasoning and generalization, providing stepwise feedback on reasoning coherence and factual correctness. Experiments show that CoTZero achieves an F1 score of 83.33 percent on our multi-level semantic inconsistency benchmark with lexical-perturbation negatives, across both in-domain and out-of-domain settings. Ablations confirm that each component contributes to more interpretable and human-aligned visual reasoning.", "AI": {"tldr": "CoTZero\uff1a\u65e0\u9700\u6807\u6ce8\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u8303\u5f0f\uff0c\u901a\u8fc7\u53cc\u9636\u6bb5\u6570\u636e\u5408\u6210\u548c\u8ba4\u77e5\u5bf9\u9f50\u8bad\u7ec3\uff0c\u63d0\u5347\u89c6\u89c9\u63a8\u7406\u7684\u903b\u8f91\u4e00\u81f4\u6027\u548c\u53ef\u9a8c\u8bc1\u6027", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u8868\u9762\u76f8\u5173\u6027\u800c\u975e\u903b\u8f91\u4e00\u81f4\u7684\u7ed3\u6784\u5316\u8868\u793a\uff0c\u5bfc\u81f4\u9ad8\u5c42\u6b21\u8bed\u4e49\u7ed3\u6784\u548c\u975e\u56e0\u679c\u5173\u7cfb\u7406\u89e3\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u7ec4\u5408\u6027\u548c\u53ef\u9a8c\u8bc1\u63a8\u7406\u80fd\u529b", "method": "\u63d0\u51faCoTZero\u8303\u5f0f\uff1a1\uff09\u53cc\u9636\u6bb5\u6570\u636e\u5408\u6210\uff1a\u81ea\u5e95\u5411\u4e0a\u63d0\u53d6\u89c6\u89c9\u57fa\u5143\u5e76\u7ec4\u5408\u6210\u7ed3\u6784\u5316\u95ee\u9898\u63a8\u7406\u5f62\u5f0f\uff1b\u81ea\u9876\u5411\u4e0b\u7528\u5168\u5c40\u7ed3\u6784\u6307\u5bfc\u5c40\u90e8\u7ec6\u8282\u548c\u56e0\u679c\u5173\u7cfb\u89e3\u91ca\uff1b2\uff09\u8ba4\u77e5\u5bf9\u9f50\u8bad\u7ec3\uff1a\u5728\u5408\u6210\u6570\u636e\u57fa\u7840\u4e0a\uff0c\u901a\u8fc7\u5f3a\u5316\u5fae\u8c03\u4e2d\u7684\u8ba4\u77e5\u4e00\u81f4\u53ef\u9a8c\u8bc1\u5956\u52b1\u673a\u5236\uff0c\u63d0\u4f9b\u63a8\u7406\u8fde\u8d2f\u6027\u548c\u4e8b\u5b9e\u6b63\u786e\u6027\u7684\u9010\u6b65\u53cd\u9988", "result": "\u5728\u5e26\u8bcd\u6c47\u6270\u52a8\u8d1f\u4f8b\u7684\u591a\u5c42\u6b21\u8bed\u4e49\u4e0d\u4e00\u81f4\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCoTZero\u5728\u57df\u5185\u548c\u57df\u5916\u8bbe\u7f6e\u4e0b\u5747\u8fbe\u523083.33%\u7684F1\u5206\u6570\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u5404\u7ec4\u4ef6\u5bf9\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u548c\u4eba\u7c7b\u5bf9\u9f50\u89c6\u89c9\u63a8\u7406\u5747\u6709\u8d21\u732e", "conclusion": "CoTZero\u901a\u8fc7\u5c06\u4eba\u7c7b\u8ba4\u77e5\u6a21\u578b\u878d\u5165\u63a8\u7406\u8fc7\u7a0b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u5316\u8868\u793a\u548c\u903b\u8f91\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u53ef\u89e3\u91ca\u548c\u4eba\u7c7b\u5bf9\u9f50\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b"}}
{"id": "2602.08340", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08340", "abs": "https://arxiv.org/abs/2602.08340", "authors": ["Hoang Dang", "Luan Pham", "Minh Nguyen"], "title": "Effect-Level Validation for Causal Discovery", "comment": null, "summary": "Causal discovery is increasingly applied to large-scale telemetry data to estimate the effects of user-facing interventions, yet its reliability for decision-making in feedback-driven systems with strong self-selection remains unclear. In this paper, we propose an effect-centric, admissibility-first framework that treats discovered graphs as structural hypotheses and evaluates them by identifiability, stability, and falsification rather than by graph recovery accuracy alone. Empirically, we study the effect of early exposure to competitive gameplay on short-term retention using real-world game telemetry. We find that many statistically plausible discovery outputs do not admit point-identified causal queries once minimal temporal and semantic constraints are enforced, highlighting identifiability as a critical bottleneck for decision support. When identification is possible, several algorithm families converge to similar, decision-consistent effect estimates despite producing substantially different graph structures, including cases where the direct treatment-outcome edge is absent and the effect is preserved through indirect causal pathways. These converging estimates survive placebo, subsampling, and sensitivity refutation. In contrast, other methods exhibit sporadic admissibility and threshold-sensitive or attenuated effects due to endpoint ambiguity. These results suggest that graph-level metrics alone are inadequate proxies for causal reliability for a given target query. Therefore, trustworthy causal conclusions in telemetry-driven systems require prioritizing admissibility and effect-level validation over causal structural recovery alone.", "AI": {"tldr": "\u63d0\u51fa\u4ee5\u6548\u5e94\u4e3a\u4e2d\u5fc3\u3001\u53ef\u5bb9\u8bb8\u6027\u4f18\u5148\u7684\u56e0\u679c\u53d1\u73b0\u6846\u67b6\uff0c\u5f3a\u8c03\u5728\u5f3a\u81ea\u9009\u62e9\u53cd\u9988\u7cfb\u7edf\u4e2d\uff0c\u56fe\u6062\u590d\u7cbe\u5ea6\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u56e0\u679c\u53ef\u9760\u6027\uff0c\u9700\u901a\u8fc7\u53ef\u8bc6\u522b\u6027\u3001\u7a33\u5b9a\u6027\u548c\u8bc1\u4f2a\u6027\u9a8c\u8bc1\u6548\u5e94\u4f30\u8ba1\u3002", "motivation": "\u5f53\u524d\u56e0\u679c\u53d1\u73b0\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5927\u89c4\u6a21\u9065\u6d4b\u6570\u636e\u4ee5\u8bc4\u4f30\u7528\u6237\u5e72\u9884\u6548\u679c\uff0c\u4f46\u5728\u5f3a\u81ea\u9009\u62e9\u7684\u53cd\u9988\u9a71\u52a8\u7cfb\u7edf\u4e2d\uff0c\u5176\u51b3\u7b56\u53ef\u9760\u6027\u5c1a\u4e0d\u660e\u786e\u3002\u9700\u8981\u8d85\u8d8a\u56fe\u6062\u590d\u7cbe\u5ea6\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u786e\u4fdd\u56e0\u679c\u7ed3\u8bba\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u63d0\u51fa\u6548\u5e94\u4e2d\u5fc3\u3001\u53ef\u5bb9\u8bb8\u6027\u4f18\u5148\u7684\u6846\u67b6\uff0c\u5c06\u53d1\u73b0\u7684\u56e0\u679c\u56fe\u89c6\u4e3a\u7ed3\u6784\u5047\u8bbe\uff0c\u901a\u8fc7\u53ef\u8bc6\u522b\u6027\u3001\u7a33\u5b9a\u6027\u548c\u8bc1\u4f2a\u6027\u8fdb\u884c\u8bc4\u4f30\u3002\u4f7f\u7528\u771f\u5b9e\u6e38\u620f\u9065\u6d4b\u6570\u636e\u7814\u7a76\u65e9\u671f\u7ade\u4e89\u6027\u6e38\u620f\u4f53\u9a8c\u5bf9\u77ed\u671f\u7559\u5b58\u7684\u5f71\u54cd\u3002", "result": "\u8bb8\u591a\u7edf\u8ba1\u4e0a\u5408\u7406\u7684\u53d1\u73b0\u8f93\u51fa\u5728\u65bd\u52a0\u6700\u5c0f\u65f6\u95f4\u548c\u8bed\u4e49\u7ea6\u675f\u540e\u65e0\u6cd5\u8fdb\u884c\u70b9\u8bc6\u522b\u56e0\u679c\u67e5\u8be2\u3002\u5f53\u8bc6\u522b\u53ef\u884c\u65f6\uff0c\u4e0d\u540c\u7b97\u6cd5\u5bb6\u65cf\u4ea7\u751f\u4e0d\u540c\u56fe\u7ed3\u6784\u4f46\u6536\u655b\u5230\u76f8\u4f3c\u7684\u51b3\u7b56\u4e00\u81f4\u6548\u5e94\u4f30\u8ba1\uff0c\u8fd9\u4e9b\u4f30\u8ba1\u901a\u8fc7\u5b89\u6170\u5242\u3001\u5b50\u91c7\u6837\u548c\u654f\u611f\u6027\u8bc1\u4f2a\u6d4b\u8bd5\u3002\u5176\u4ed6\u65b9\u6cd5\u5219\u8868\u73b0\u51fa\u96f6\u661f\u7684\u53ef\u5bb9\u8bb8\u6027\u548c\u9608\u503c\u654f\u611f\u6216\u8870\u51cf\u7684\u6548\u5e94\u3002", "conclusion": "\u56fe\u7ea7\u6307\u6807\u5355\u72ec\u4e0d\u8db3\u4ee5\u4f5c\u4e3a\u7279\u5b9a\u76ee\u6807\u67e5\u8be2\u56e0\u679c\u53ef\u9760\u6027\u7684\u4ee3\u7406\u3002\u5728\u9065\u6d4b\u9a71\u52a8\u7cfb\u7edf\u4e2d\uff0c\u53ef\u4fe1\u7684\u56e0\u679c\u7ed3\u8bba\u9700\u8981\u4f18\u5148\u8003\u8651\u53ef\u5bb9\u8bb8\u6027\u548c\u6548\u5e94\u7ea7\u9a8c\u8bc1\uff0c\u800c\u975e\u4ec5\u5173\u6ce8\u56e0\u679c\u7ed3\u6784\u6062\u590d\u3002"}}
{"id": "2602.08344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08344", "abs": "https://arxiv.org/abs/2602.08344", "authors": ["Qi Guo", "Jianing Wang", "Deyang Kong", "Xiangyu Xi", "Jianfei Zhang", "Yi Lu", "Jingang Wang", "Wei Wang", "Shikun Zhang", "Wei Ye"], "title": "OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration", "comment": null, "summary": "Parallel thinking has emerged as a new paradigm for large reasoning models (LRMs) in tackling complex problems. Recent methods leverage Reinforcement Learning (RL) to enhance parallel thinking, aiming to address the limitations in computational resources and effectiveness encountered with supervised fine-tuning. However, most existing studies primarily focus on optimizing the aggregation phase, with limited attention to the path exploration stage. In this paper, we theoretically analyze the optimization of parallel thinking under the Reinforcement Learning with Verifiable Rewards (RLVR) setting, and identify that the mutual information bottleneck among exploration paths fundamentally restricts overall performance. To address this, we propose Outline-Guided Path Exploration (OPE), which explicitly partitions the solution space by generating diverse reasoning outlines prior to parallel path reasoning, thereby reducing information redundancy and improving the diversity of information captured across exploration paths. We implement OPE with an iterative RL strategy that optimizes outline planning and outline-guided reasoning independently. Extensive experiments across multiple challenging mathematical benchmarks demonstrate that OPE effectively improves reasoning performance in different aggregation strategies, enabling LRMs to more reliably discover correct solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faOutline-Guided Path Exploration (OPE)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5148\u751f\u6210\u591a\u6837\u5316\u7684\u63a8\u7406\u5927\u7eb2\u6765\u5212\u5206\u89e3\u7a7a\u95f4\uff0c\u51cf\u5c11\u5e76\u884c\u63a8\u7406\u8def\u5f84\u95f4\u7684\u4fe1\u606f\u5197\u4f59\uff0c\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5e76\u884c\u63a8\u7406\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u805a\u5408\u9636\u6bb5\u4f18\u5316\uff0c\u5bf9\u8def\u5f84\u63a2\u7d22\u9636\u6bb5\u5173\u6ce8\u6709\u9650\u3002\u4f5c\u8005\u4ece\u7406\u8bba\u4e0a\u5206\u6790\u53d1\u73b0\uff0c\u63a2\u7d22\u8def\u5f84\u95f4\u7684\u4e92\u4fe1\u606f\u74f6\u9888\u9650\u5236\u4e86\u6574\u4f53\u6027\u80fd\uff0c\u9700\u8981\u89e3\u51b3\u8def\u5f84\u95f4\u7684\u4fe1\u606f\u5197\u4f59\u95ee\u9898\u3002", "method": "\u63d0\u51faOPE\u65b9\u6cd5\uff1a1\uff09\u5148\u751f\u6210\u591a\u6837\u5316\u7684\u63a8\u7406\u5927\u7eb2\u6765\u5212\u5206\u89e3\u7a7a\u95f4\uff1b2\uff09\u57fa\u4e8e\u5927\u7eb2\u8fdb\u884c\u5e76\u884c\u8def\u5f84\u63a8\u7406\uff1b3\uff09\u91c7\u7528\u8fed\u4ee3\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u5206\u522b\u4f18\u5316\u5927\u7eb2\u89c4\u5212\u548c\u57fa\u4e8e\u5927\u7eb2\u7684\u63a8\u7406\u3002", "result": "\u5728\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660eOPE\u80fd\u6709\u6548\u63d0\u5347\u4e0d\u540c\u805a\u5408\u7b56\u7565\u4e0b\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4f7f\u5927\u578b\u63a8\u7406\u6a21\u578b\u66f4\u53ef\u9760\u5730\u53d1\u73b0\u6b63\u786e\u89e3\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u5212\u5206\u89e3\u7a7a\u95f4\u5e76\u51cf\u5c11\u8def\u5f84\u95f4\u7684\u4fe1\u606f\u5197\u4f59\uff0cOPE\u65b9\u6cd5\u89e3\u51b3\u4e86\u5e76\u884c\u63a8\u7406\u4e2d\u7684\u4e92\u4fe1\u606f\u74f6\u9888\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.08353", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08353", "abs": "https://arxiv.org/abs/2602.08353", "authors": ["Zhang Jiasheng", "Li Zhangpin", "Wang Mingzhe", "Shao Jie", "Cui Jiangtao", "Li Hui"], "title": "Towards Better Evolution Modeling for Temporal Knowledge Graphs", "comment": "13 pages, 11 figures", "summary": "Temporal knowledge graphs (TKGs) structurally preserve evolving human knowledge. Recent research has focused on designing models to learn the evolutionary nature of TKGs to predict future facts, achieving impressive results. For instance, Hits@10 scores over 0.9 on YAGO dataset. However, we find that existing benchmarks inadvertently introduce a shortcut. Near state-of-the-art performance can be simply achieved by counting co-occurrences, without using any temporal information. In this work, we examine the root cause of this issue, identifying inherent biases in current datasets and over simplified form of evaluation task that can be exploited by these biases. Through this analysis, we further uncover additional limitations of existing benchmarks, including unreasonable formatting of time-interval knowledge, ignorance of learning knowledge obsolescence, and insufficient information for precise evolution understanding, all of which can amplify the shortcut and hinder a fair assessment. Therefore, we introduce the TKG evolution benchmark. It includes four bias-corrected datasets and two novel tasks closely aligned with the evolution process, promoting a more accurate understanding of the challenges in TKG evolution modeling. Benchmark is available at: https://github.com/zjs123/TKG-Benchmark.", "AI": {"tldr": "\u73b0\u6709TKG\u9884\u6d4b\u57fa\u51c6\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u4ec5\u901a\u8fc7\u7edf\u8ba1\u5171\u73b0\u5c31\u80fd\u8fbe\u5230\u63a5\u8fd1SOTA\u7684\u6027\u80fd\uff0c\u65e0\u9700\u4f7f\u7528\u65f6\u95f4\u4fe1\u606f\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u65b0\u7684TKG\u6f14\u5316\u57fa\u51c6\uff0c\u5305\u542b\u56db\u4e2a\u504f\u5dee\u6821\u6b63\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u65b0\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709TKG\u9884\u6d4b\u57fa\u51c6\u5b58\u5728\u4e25\u91cd\u95ee\u9898\uff1a1\uff09\u6570\u636e\u96c6\u5b58\u5728\u56fa\u6709\u504f\u5dee\uff0c2\uff09\u8bc4\u4f30\u4efb\u52a1\u8fc7\u4e8e\u7b80\u5316\uff0c3\uff09\u65f6\u95f4\u95f4\u9694\u77e5\u8bc6\u683c\u5f0f\u4e0d\u5408\u7406\uff0c4\uff09\u5ffd\u7565\u77e5\u8bc6\u8fc7\u65f6\u5b66\u4e60\uff0c5\uff09\u6f14\u5316\u7406\u89e3\u4fe1\u606f\u4e0d\u8db3\u3002\u8fd9\u4e9b\u95ee\u9898\u5bfc\u81f4\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u7edf\u8ba1\u5171\u73b0\u83b7\u5f97\u9ad8\u5206\u6570\uff0c\u65e0\u6cd5\u516c\u5e73\u8bc4\u4f30TKG\u6f14\u5316\u5efa\u6a21\u80fd\u529b\u3002", "method": "1\uff09\u5206\u6790\u73b0\u6709\u57fa\u51c6\u95ee\u9898\u7684\u6839\u672c\u539f\u56e0\uff0c\u8bc6\u522b\u6570\u636e\u96c6\u504f\u5dee\u548c\u8bc4\u4f30\u4efb\u52a1\u7b80\u5316\u5e26\u6765\u7684\u53ef\u5229\u7528\u6f0f\u6d1e\uff1b2\uff09\u6784\u5efaTKG\u6f14\u5316\u57fa\u51c6\uff0c\u5305\u542b\u56db\u4e2a\u7ecf\u8fc7\u504f\u5dee\u6821\u6b63\u7684\u6570\u636e\u96c6\uff1b3\uff09\u8bbe\u8ba1\u4e24\u4e2a\u4e0e\u6f14\u5316\u8fc7\u7a0b\u7d27\u5bc6\u76f8\u5173\u7684\u65b0\u4efb\u52a1\uff0c\u4fc3\u8fdb\u5bf9TKG\u6f14\u5316\u5efa\u6a21\u6311\u6218\u7684\u51c6\u786e\u7406\u89e3\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u57fa\u51c6\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u4ec5\u901a\u8fc7\u7b80\u5355\u7684\u5171\u73b0\u7edf\u8ba1\u5c31\u80fd\u5728YAGO\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u63a5\u8fd10.9\u7684Hits@10\u5206\u6570\uff0c\u5b8c\u5168\u4e0d\u9700\u8981\u4f7f\u7528\u65f6\u95f4\u4fe1\u606f\u3002\u63d0\u51fa\u7684\u65b0\u57fa\u51c6\u89e3\u51b3\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u66f4\u516c\u5e73\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "conclusion": "\u73b0\u6709TKG\u9884\u6d4b\u57fa\u51c6\u5b58\u5728\u7cfb\u7edf\u6027\u7f3a\u9677\uff0c\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u6a21\u578b\u5bf9\u65f6\u95f4\u6f14\u5316\u7684\u7406\u89e3\u80fd\u529b\u3002\u63d0\u51fa\u7684TKG\u6f14\u5316\u57fa\u51c6\u901a\u8fc7\u504f\u5dee\u6821\u6b63\u6570\u636e\u96c6\u548c\u66f4\u8d34\u8fd1\u5b9e\u9645\u6f14\u5316\u8fc7\u7a0b\u7684\u4efb\u52a1\u8bbe\u8ba1\uff0c\u4e3aTKG\u6f14\u5316\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u516c\u5e73\u3001\u66f4\u6709\u6311\u6218\u6027\u7684\u8bc4\u4f30\u5e73\u53f0\u3002"}}
{"id": "2602.08354", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08354", "abs": "https://arxiv.org/abs/2602.08354", "authors": ["Zixuan Huang", "Xin Xia", "Yuxi Ren", "Jianbin Zheng", "Xuanda Wang", "Zhixia Zhang", "Hongyan Xie", "Songshi Liang", "Zehao Chen", "Xuefeng Xiao", "Fuzhen Zhuang", "Jianxin Li", "Yikun Ban", "Deqing Wang"], "title": "Does Your Reasoning Model Implicitly Know When to Stop Thinking?", "comment": null, "summary": "Recent advancements in large reasoning models (LRMs) have greatly improved their capabilities on complex reasoning tasks through Long Chains of Thought (CoTs). However, this approach often results in substantial redundancy, impairing computational efficiency and causing significant delays in real-time applications. Recent studies show that longer reasoning chains are frequently uncorrelated with correctness and can even be detrimental to accuracy. In a further in-depth analysis of this phenomenon, we surprisingly uncover and empirically verify that LRMs implicitly know the appropriate time to stop thinking, while this capability is obscured by current sampling paradigms. Motivated by this, we introduce SAGE (Self-Aware Guided Efficient Reasoning), a novel sampling paradigm that unleashes this efficient reasoning potential. Furthermore, integrating SAGE as mixed sampling into group-based reinforcement learning (SAGE-RL) enables SAGE-RL to effectively incorporate SAGE-discovered efficient reasoning patterns into standard pass@1 inference, markedly enhancing both the reasoning accuracy and efficiency of LRMs across multiple challenging mathematical benchmarks.", "AI": {"tldr": "\u63d0\u51faSAGE\u91c7\u6837\u8303\u5f0f\uff0c\u901a\u8fc7\u91ca\u653e\u5927\u63a8\u7406\u6a21\u578b\u7684\u81ea\u6211\u505c\u6b62\u80fd\u529b\uff0c\u63d0\u5347\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027", "motivation": "\u5f53\u524d\u5927\u63a8\u7406\u6a21\u578b\u4f7f\u7528\u957f\u601d\u7ef4\u94fe\u65b9\u6cd5\u5b58\u5728\u5927\u91cf\u5197\u4f59\uff0c\u635f\u5bb3\u8ba1\u7b97\u6548\u7387\u5e76\u5bfc\u81f4\u5b9e\u65f6\u5e94\u7528\u5ef6\u8fdf\u3002\u7814\u7a76\u53d1\u73b0\u66f4\u957f\u7684\u63a8\u7406\u94fe\u4e0e\u6b63\u786e\u6027\u65e0\u5173\u751a\u81f3\u6709\u5bb3\uff0c\u800c\u6a21\u578b\u5b9e\u9645\u4e0a\u9690\u542b\u77e5\u9053\u4f55\u65f6\u505c\u6b62\u601d\u8003\uff0c\u4f46\u88ab\u5f53\u524d\u91c7\u6837\u8303\u5f0f\u6240\u63a9\u76d6\u3002", "method": "\u63d0\u51faSAGE\uff08Self-Aware Guided Efficient Reasoning\uff09\u91c7\u6837\u8303\u5f0f\uff0c\u91ca\u653e\u6a21\u578b\u7684\u9ad8\u6548\u63a8\u7406\u6f5c\u529b\u3002\u8fdb\u4e00\u6b65\u5c06SAGE\u4f5c\u4e3a\u6df7\u5408\u91c7\u6837\u96c6\u6210\u5230\u57fa\u4e8e\u7fa4\u4f53\u7684\u5f3a\u5316\u5b66\u4e60\uff08SAGE-RL\uff09\u4e2d\uff0c\u4f7fSAGE-RL\u80fd\u591f\u5c06SAGE\u53d1\u73b0\u7684\u9ad8\u6548\u63a8\u7406\u6a21\u5f0f\u878d\u5165\u6807\u51c6pass@1\u63a8\u7406\u3002", "result": "SAGE-RL\u663e\u8457\u63d0\u5347\u4e86\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5927\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u91ca\u653e\u5927\u63a8\u7406\u6a21\u578b\u9690\u542b\u7684\u81ea\u6211\u505c\u6b62\u80fd\u529b\uff0cSAGE\u91c7\u6837\u8303\u5f0f\u80fd\u591f\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u5b9e\u65f6\u5e94\u7528\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08362", "categories": ["cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.08362", "abs": "https://arxiv.org/abs/2602.08362", "authors": ["Chunxi Ji", "Adnan Darwiche"], "title": "Circuit Representations of Random Forests with Applications to XAI", "comment": null, "summary": "We make three contributions in this paper. First, we present an approach for compiling a random forest classifier into a set of circuits, where each circuit directly encodes the instances in some class of the classifier. We show empirically that our proposed approach is significantly more efficient than existing similar approaches. Next, we utilize this approach to further obtain circuits that are tractable for computing the complete and general reasons of a decision, which are instance abstractions that play a fundamental role in computing explanations. Finally, we propose algorithms for computing the robustness of a decision and all shortest ways to flip it. We illustrate the utility of our contributions by using them to enumerate all sufficient reasons, necessary reasons and contrastive explanations of decisions; to compute the robustness of decisions; and to identify all shortest ways to flip the decisions made by random forest classifiers learned from a wide range of datasets.", "AI": {"tldr": "\u5c06\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u7f16\u8bd1\u4e3a\u7535\u8def\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u51b3\u7b56\u89e3\u91ca\u3001\u9c81\u68d2\u6027\u548c\u51b3\u7b56\u7ffb\u8f6c\u8def\u5f84", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u8ba1\u7b97\u968f\u673a\u68ee\u6797\u51b3\u7b56\u7684\u89e3\u91ca\u3001\u9c81\u68d2\u6027\u548c\u7ffb\u8f6c\u8def\u5f84\u65f6\u6548\u7387\u8f83\u4f4e\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u7f16\u8bd1\u548c\u8ba1\u7b97\u65b9\u6cd5", "method": "1) \u5c06\u968f\u673a\u68ee\u6797\u7f16\u8bd1\u4e3a\u7535\u8def\u8868\u793a\uff1b2) \u5229\u7528\u7535\u8def\u8ba1\u7b97\u51b3\u7b56\u7684\u5b8c\u6574\u548c\u4e00\u822c\u539f\u56e0\uff1b3) \u63d0\u51fa\u7b97\u6cd5\u8ba1\u7b97\u51b3\u7b56\u9c81\u68d2\u6027\u548c\u6700\u77ed\u7ffb\u8f6c\u8def\u5f84", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6bd4\u73b0\u6709\u7c7b\u4f3c\u65b9\u6cd5\u663e\u8457\u66f4\u9ad8\u6548\uff0c\u80fd\u591f\u679a\u4e3e\u5145\u5206\u539f\u56e0\u3001\u5fc5\u8981\u539f\u56e0\u3001\u5bf9\u6bd4\u89e3\u91ca\uff0c\u8ba1\u7b97\u51b3\u7b56\u9c81\u68d2\u6027\uff0c\u5e76\u8bc6\u522b\u6700\u77ed\u51b3\u7b56\u7ffb\u8f6c\u8def\u5f84", "conclusion": "\u901a\u8fc7\u7535\u8def\u7f16\u8bd1\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5bf9\u968f\u673a\u68ee\u6797\u51b3\u7b56\u7684\u9ad8\u6548\u89e3\u91ca\u5206\u6790\uff0c\u4e3a\u7406\u89e3\u6a21\u578b\u51b3\u7b56\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8ba1\u7b97\u5de5\u5177"}}
{"id": "2602.08369", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08369", "abs": "https://arxiv.org/abs/2602.08369", "authors": ["Xin Zhang", "Kailai Yang", "Chenyue Li", "Hao Li", "Qiyu Wei", "Jun'ichi Tsujii", "Sophia Ananiadou"], "title": "MemAdapter: Fast Alignment across Agent Memory Paradigms via Generative Subgraph Retrieval", "comment": null, "summary": "Memory mechanism is a core component of LLM-based agents, enabling reasoning and knowledge discovery over long-horizon contexts. Existing agent memory systems are typically designed within isolated paradigms (e.g., explicit, parametric, or latent memory) with tightly coupled retrieval methods that hinder cross-paradigm generalization and fusion. In this work, we take a first step toward unifying heterogeneous memory paradigms within a single memory system. We propose MemAdapter, a memory retrieval framework that enables fast alignment across agent memory paradigms. MemAdapter adopts a two-stage training strategy: (1) training a generative subgraph retriever from the unified memory space, and (2) adapting the retriever to unseen memory paradigms by training a lightweight alignment module through contrastive learning. This design improves the flexibility for memory retrieval and substantially reduces alignment cost across paradigms. Comprehensive experiments on three public evaluation benchmarks demonstrate that the generative subgraph retriever consistently outperforms five strong agent memory systems across three memory paradigms and agent model scales. Notably, MemAdapter completes cross-paradigm alignment within 13 minutes on a single GPU, achieving superior performance over original memory retrievers with less than 5% of training compute. Furthermore, MemAdapter enables effective zero-shot fusion across memory paradigms, highlighting its potential as a plug-and-play solution for agent memory systems.", "AI": {"tldr": "MemAdapter\u662f\u4e00\u4e2a\u7edf\u4e00\u5f02\u6784\u5185\u5b58\u8303\u5f0f\u7684\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u5b9e\u73b0\u8de8\u8303\u5f0f\u5feb\u901f\u5bf9\u9f50\uff0c\u663e\u8457\u964d\u4f4e\u5bf9\u9f50\u6210\u672c\u5e76\u652f\u6301\u96f6\u6837\u672c\u878d\u5408\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u5185\u5b58\u7cfb\u7edf\u901a\u5e38\u8bbe\u8ba1\u5728\u5b64\u7acb\u8303\u5f0f\uff08\u663e\u5f0f\u3001\u53c2\u6570\u5316\u6216\u6f5c\u5728\u5185\u5b58\uff09\u4e2d\uff0c\u68c0\u7d22\u65b9\u6cd5\u7d27\u5bc6\u8026\u5408\uff0c\u963b\u788d\u4e86\u8de8\u8303\u5f0f\u6cdb\u5316\u548c\u878d\u5408\u3002\u9700\u8981\u7edf\u4e00\u5f02\u6784\u5185\u5b58\u8303\u5f0f\u3002", "method": "\u63d0\u51faMemAdapter\u6846\u67b6\uff1a1\uff09\u4ece\u7edf\u4e00\u5185\u5b58\u7a7a\u95f4\u8bad\u7ec3\u751f\u6210\u5f0f\u5b50\u56fe\u68c0\u7d22\u5668\uff1b2\uff09\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u8f7b\u91cf\u5bf9\u9f50\u6a21\u5757\uff0c\u5c06\u68c0\u7d22\u5668\u9002\u914d\u5230\u672a\u89c1\u5185\u5b58\u8303\u5f0f\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u8bc4\u4f30\u57fa\u51c6\u4e0a\uff0c\u751f\u6210\u5f0f\u5b50\u56fe\u68c0\u7d22\u5668\u5728\u4e09\u79cd\u5185\u5b58\u8303\u5f0f\u548c\u667a\u80fd\u4f53\u6a21\u578b\u89c4\u6a21\u4e0a\u6301\u7eed\u4f18\u4e8e\u4e94\u4e2a\u5f3a\u57fa\u7ebf\u7cfb\u7edf\u3002\u8de8\u8303\u5f0f\u5bf9\u9f50\u4ec5\u970013\u5206\u949f\uff08\u5355GPU\uff09\uff0c\u6027\u80fd\u4f18\u4e8e\u539f\u59cb\u68c0\u7d22\u5668\u4e14\u8bad\u7ec3\u8ba1\u7b97\u91cf\u5c0f\u4e8e5%\u3002\u652f\u6301\u96f6\u6837\u672c\u8de8\u8303\u5f0f\u878d\u5408\u3002", "conclusion": "MemAdapter\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u9996\u6b21\u7edf\u4e00\u4e86\u5f02\u6784\u5185\u5b58\u8303\u5f0f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5185\u5b58\u68c0\u7d22\u7684\u7075\u6d3b\u6027\u5e76\u5927\u5e45\u964d\u4f4e\u4e86\u8de8\u8303\u5f0f\u5bf9\u9f50\u6210\u672c\u3002"}}
{"id": "2602.08373", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08373", "abs": "https://arxiv.org/abs/2602.08373", "authors": ["Feiyu Wu", "Xu Zheng", "Yue Qu", "Zhuocheng Wang", "Zicheng Feng", "Hui Li"], "title": "Grounding Generative Planners in Verifiable Logic: A Hybrid Architecture for Trustworthy Embodied AI", "comment": "Accepted to ICLR 2026. Project page. https://openreview.net/forum?id=wb05ver1k8&noteId=v1Ax8CwI71", "summary": "Large Language Models (LLMs) show promise as planners for embodied AI, but their stochastic nature lacks formal reasoning, preventing strict safety guarantees for physical deployment. Current approaches often rely on unreliable LLMs for safety checks or simply reject unsafe plans without offering repairs. We introduce the Verifiable Iterative Refinement Framework (VIRF), a neuro-symbolic architecture that shifts the paradigm from passive safety gatekeeping to active collaboration. Our core contribution is a tutor-apprentice dialogue where a deterministic Logic Tutor, grounded in a formal safety ontology, provides causal and pedagogical feedback to an LLM planner. This enables intelligent plan repairs rather than mere avoidance. We also introduce a scalable knowledge acquisition pipeline that synthesizes safety knowledge bases from real-world documents, correcting blind spots in existing benchmarks. In challenging home safety tasks, VIRF achieves a perfect 0 percent Hazardous Action Rate (HAR) and a 77.3 percent Goal-Condition Rate (GCR), which is the highest among all baselines. It is highly efficient, requiring only 1.1 correction iterations on average. VIRF demonstrates a principled pathway toward building fundamentally trustworthy and verifiably safe embodied agents.", "AI": {"tldr": "VIRF\u6846\u67b6\u901a\u8fc7\u903b\u8f91\u5bfc\u5e08\u4e0eLLM\u89c4\u5212\u5668\u7684\u5bf9\u8bdd\u534f\u4f5c\uff0c\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u7684\u5b89\u5168\u89c4\u5212\uff0c\u5728\u5bb6\u5ead\u5b89\u5168\u4efb\u52a1\u4e2d\u8fbe\u52300%\u5371\u9669\u884c\u52a8\u7387\u548c77.3%\u76ee\u6807\u8fbe\u6210\u7387\u3002", "motivation": "\u5f53\u524dLLM\u89c4\u5212\u5668\u7f3a\u4e4f\u5f62\u5f0f\u5316\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u6cd5\u63d0\u4f9b\u4e25\u683c\u7684\u5b89\u5168\u4fdd\u8bc1\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u4e0d\u53ef\u9760\u7684LLM\u5b89\u5168\u68c0\u67e5\uff0c\u8981\u4e48\u53ea\u662f\u62d2\u7edd\u4e0d\u5b89\u5168\u8ba1\u5212\u800c\u4e0d\u63d0\u4f9b\u4fee\u590d\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u53ef\u9a8c\u8bc1\u8fed\u4ee3\u7cbe\u70bc\u6846\u67b6(VIRF)\uff0c\u91c7\u7528\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\uff0c\u901a\u8fc7\u57fa\u4e8e\u5f62\u5f0f\u5316\u5b89\u5168\u672c\u4f53\u7684\u786e\u5b9a\u6027\u903b\u8f91\u5bfc\u5e08\u4e0eLLM\u89c4\u5212\u5668\u8fdb\u884c\u5bfc\u5e08-\u5b66\u5f92\u5bf9\u8bdd\uff0c\u63d0\u4f9b\u56e0\u679c\u6027\u548c\u6559\u5b66\u6027\u53cd\u9988\uff0c\u5b9e\u73b0\u667a\u80fd\u8ba1\u5212\u4fee\u590d\u800c\u975e\u7b80\u5355\u89c4\u907f\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5bb6\u5ead\u5b89\u5168\u4efb\u52a1\u4e2d\uff0cVIRF\u5b9e\u73b0\u4e860%\u7684\u5371\u9669\u884c\u52a8\u7387(HAR)\u548c77.3%\u7684\u76ee\u6807\u8fbe\u6210\u7387(GCR)\uff0c\u5728\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u4e2d\u6700\u9ad8\uff0c\u5e73\u5747\u4ec5\u97001.1\u6b21\u4fee\u6b63\u8fed\u4ee3\u3002", "conclusion": "VIRF\u5c55\u793a\u4e86\u4e00\u6761\u6784\u5efa\u6839\u672c\u4e0a\u53ef\u4fe1\u8d56\u4e14\u53ef\u9a8c\u8bc1\u5b89\u5168\u7684\u5177\u8eab\u667a\u80fd\u4f53\u7684\u539f\u5219\u6027\u8def\u5f84\uff0c\u4ece\u88ab\u52a8\u5b89\u5168\u628a\u5173\u8f6c\u5411\u4e3b\u52a8\u534f\u4f5c\u4fee\u590d\u3002"}}
{"id": "2602.08400", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08400", "abs": "https://arxiv.org/abs/2602.08400", "authors": ["Longkun Li", "Yuanben Zou", "Jinghan Wu", "Yuqing Wen", "Jing Li", "Hangwei Qian", "Ivor Tsang"], "title": "SCOUT-RAG: Scalable and Cost-Efficient Unifying Traversal for Agentic Graph-RAG over Distributed Domains", "comment": null, "summary": "Graph-RAG improves LLM reasoning using structured knowledge, yet conventional designs rely on a centralized knowledge graph. In distributed and access-restricted settings (e.g., hospitals or multinational organizations), retrieval must select relevant domains and appropriate traversal depth without global graph visibility or exhaustive querying. To address this challenge, we introduce \\textbf{SCOUT-RAG} (\\textit{\\underline{S}calable and \\underline{CO}st-efficient \\underline{U}nifying \\underline{T}raversal}), a distributed agentic Graph-RAG framework that performs progressive cross-domain retrieval guided by incremental utility goals. SCOUT-RAG employs four cooperative agents that: (i) estimate domain relevance, (ii) decide when to expand retrieval to additional domains, (iii) adapt traversal depth to avoid unnecessary graph exploration, and (iv) synthesize the high-quality answers. The framework is designed to minimize retrieval regret, defined as missing useful domain information, while controlling latency and API cost. Across multi-domain knowledge settings, SCOUT-RAG achieves performance comparable to centralized baselines, including DRIFT and exhaustive domain traversal, while substantially reducing cross-domain calls, total tokens processed, and latency.", "AI": {"tldr": "SCOUT-RAG\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u667a\u80fdGraph-RAG\u6846\u67b6\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u8de8\u57df\u68c0\u7d22\u89e3\u51b3\u5206\u5e03\u5f0f\u53d7\u9650\u73af\u5883\u4e0b\u7684\u77e5\u8bc6\u56fe\u68c0\u7d22\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u8de8\u57df\u8c03\u7528\u548c\u5ef6\u8fdf\u3002", "motivation": "\u4f20\u7edfGraph-RAG\u4f9d\u8d56\u96c6\u4e2d\u5f0f\u77e5\u8bc6\u56fe\uff0c\u4f46\u5728\u5206\u5e03\u5f0f\u548c\u8bbf\u95ee\u53d7\u9650\u73af\u5883\uff08\u5982\u533b\u9662\u3001\u8de8\u56fd\u7ec4\u7ec7\uff09\u4e2d\uff0c\u68c0\u7d22\u9700\u8981\u5728\u6ca1\u6709\u5168\u5c40\u56fe\u53ef\u89c1\u6027\u7684\u60c5\u51b5\u4e0b\u9009\u62e9\u76f8\u5173\u57df\u548c\u9002\u5f53\u7684\u904d\u5386\u6df1\u5ea6\u3002", "method": "\u63d0\u51faSCOUT-RAG\u6846\u67b6\uff0c\u91c7\u7528\u56db\u4e2a\u534f\u4f5c\u4ee3\u7406\uff1a\u8bc4\u4f30\u57df\u76f8\u5173\u6027\u3001\u51b3\u5b9a\u4f55\u65f6\u6269\u5c55\u5230\u989d\u5916\u57df\u3001\u8c03\u6574\u904d\u5386\u6df1\u5ea6\u4ee5\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u56fe\u63a2\u7d22\u3001\u5408\u6210\u9ad8\u8d28\u91cf\u7b54\u6848\u3002\u6846\u67b6\u65e8\u5728\u6700\u5c0f\u5316\u68c0\u7d22\u9057\u61be\u5e76\u63a7\u5236\u5ef6\u8fdf\u548cAPI\u6210\u672c\u3002", "result": "\u5728\u591a\u57df\u77e5\u8bc6\u8bbe\u7f6e\u4e2d\uff0cSCOUT-RAG\u8fbe\u5230\u4e0e\u96c6\u4e2d\u5f0f\u57fa\u7ebf\uff08\u5305\u62ecDRIFT\u548c\u7a77\u4e3e\u57df\u904d\u5386\uff09\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8de8\u57df\u8c03\u7528\u3001\u5904\u7406\u7684\u603b\u4ee4\u724c\u6570\u548c\u5ef6\u8fdf\u3002", "conclusion": "SCOUT-RAG\u4e3a\u5206\u5e03\u5f0f\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684Graph-RAG\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u667a\u80fd\u4ee3\u7406\u534f\u4f5c\u5b9e\u73b0\u9ad8\u6548\u7684\u77e5\u8bc6\u68c0\u7d22\u3002"}}
{"id": "2602.08401", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08401", "abs": "https://arxiv.org/abs/2602.08401", "authors": ["Liwen Wang", "Zongjie Li", "Yuchong Xie", "Shuai Wang", "Dongdong She", "Wei Wang", "Juergen Rahmel"], "title": "On Protecting Agentic Systems' Intellectual Property via Watermarking", "comment": null, "summary": "The evolution of Large Language Models (LLMs) into agentic systems that perform autonomous reasoning and tool use has created significant intellectual property (IP) value. We demonstrate that these systems are highly vulnerable to imitation attacks, where adversaries steal proprietary capabilities by training imitation models on victim outputs. Crucially, existing LLM watermarking techniques fail in this domain because real-world agentic systems often operate as grey boxes, concealing the internal reasoning traces required for verification. This paper presents AGENTWM, the first watermarking framework designed specifically for agentic models. AGENTWM exploits the semantic equivalence of action sequences, injecting watermarks by subtly biasing the distribution of functionally identical tool execution paths. This mechanism allows AGENTWM to embed verifiable signals directly into the visible action trajectory while remaining indistinguishable to users. We develop an automated pipeline to generate robust watermark schemes and a rigorous statistical hypothesis testing procedure for verification. Extensive evaluations across three complex domains demonstrate that AGENTWM achieves high detection accuracy with negligible impact on agent performance. Our results confirm that AGENTWM effectively protects agentic IP against adaptive adversaries, who cannot remove the watermarks without severely degrading the stolen model's utility.", "AI": {"tldr": "AGENTWM\u662f\u9996\u4e2a\u4e13\u95e8\u4e3a\u667a\u80fd\u4f53\u6a21\u578b\u8bbe\u8ba1\u7684\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u504f\u7f6e\u529f\u80fd\u76f8\u540c\u7684\u5de5\u5177\u6267\u884c\u8def\u5f84\u5206\u5e03\u6765\u5d4c\u5165\u6c34\u5370\uff0c\u4fdd\u62a4\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u77e5\u8bc6\u4ea7\u6743\u514d\u53d7\u6a21\u4eff\u653b\u51fb\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u4e3a\u80fd\u591f\u81ea\u4e3b\u63a8\u7406\u548c\u4f7f\u7528\u5de5\u5177\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u521b\u9020\u4e86\u91cd\u8981\u7684\u77e5\u8bc6\u4ea7\u6743\u4ef7\u503c\u3002\u8fd9\u4e9b\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u6a21\u4eff\u653b\u51fb\uff0c\u800c\u73b0\u6709\u7684LLM\u6c34\u5370\u6280\u672f\u65e0\u6cd5\u5e94\u7528\u4e8e\u667a\u80fd\u4f53\u9886\u57df\uff0c\u56e0\u4e3a\u73b0\u5b9e\u4e2d\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u5e38\u662f\u7070\u76d2\uff0c\u9690\u85cf\u4e86\u9a8c\u8bc1\u6240\u9700\u7684\u5185\u90e8\u63a8\u7406\u75d5\u8ff9\u3002", "method": "AGENTWM\u5229\u7528\u52a8\u4f5c\u5e8f\u5217\u7684\u8bed\u4e49\u7b49\u4ef7\u6027\uff0c\u901a\u8fc7\u5fae\u5999\u5730\u504f\u7f6e\u529f\u80fd\u76f8\u540c\u7684\u5de5\u5177\u6267\u884c\u8def\u5f84\u5206\u5e03\u6765\u6ce8\u5165\u6c34\u5370\u3002\u8be5\u65b9\u6cd5\u5c06\u53ef\u9a8c\u8bc1\u4fe1\u53f7\u76f4\u63a5\u5d4c\u5165\u53ef\u89c1\u7684\u52a8\u4f5c\u8f68\u8ff9\u4e2d\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u7528\u6237\u4e0d\u53ef\u5bdf\u89c9\u3002\u5f00\u53d1\u4e86\u81ea\u52a8\u751f\u6210\u9c81\u68d2\u6c34\u5370\u65b9\u6848\u7684\u6d41\u7a0b\u548c\u4e25\u683c\u7684\u7edf\u8ba1\u5047\u8bbe\u68c0\u9a8c\u9a8c\u8bc1\u7a0b\u5e8f\u3002", "result": "\u5728\u4e09\u4e2a\u590d\u6742\u9886\u57df\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cAGENTWM\u5b9e\u73b0\u4e86\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5bf9\u667a\u80fd\u4f53\u6027\u80fd\u5f71\u54cd\u53ef\u5ffd\u7565\u3002AGENTWM\u80fd\u6709\u6548\u4fdd\u62a4\u667a\u80fd\u4f53\u77e5\u8bc6\u4ea7\u6743\uff0c\u5bf9\u6297\u81ea\u9002\u5e94\u653b\u51fb\u8005\uff0c\u653b\u51fb\u8005\u65e0\u6cd5\u5728\u4e0d\u4e25\u91cd\u964d\u4f4e\u88ab\u76d7\u6a21\u578b\u6548\u7528\u7684\u60c5\u51b5\u4e0b\u79fb\u9664\u6c34\u5370\u3002", "conclusion": "AGENTWM\u662f\u9996\u4e2a\u4e13\u95e8\u4e3a\u667a\u80fd\u4f53\u6a21\u578b\u8bbe\u8ba1\u7684\u6c34\u5370\u6846\u67b6\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709LLM\u6c34\u5370\u6280\u672f\u65e0\u6cd5\u5e94\u7528\u4e8e\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u95ee\u9898\uff0c\u4e3a\u4fdd\u62a4\u667a\u80fd\u4f53\u77e5\u8bc6\u4ea7\u6743\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08412", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08412", "abs": "https://arxiv.org/abs/2602.08412", "authors": ["Yuhang Wang", "Feiming Xu", "Zheng Lin", "Guangyu He", "Yuzhe Huang", "Haichang Gao", "Zhenxing Niu"], "title": "From Assistant to Double Agent: Formalizing and Benchmarking Attacks on OpenClaw for Personalized Local AI Agent", "comment": "11 pages,2 figures", "summary": "Although large language model (LLM)-based agents, exemplified by OpenClaw, are increasingly evolving from task-oriented systems into personalized AI assistants for solving complex real-world tasks, their practical deployment also introduces severe security risks. However, existing agent security research and evaluation frameworks primarily focus on synthetic or task-centric settings, and thus fail to accurately capture the attack surface and risk propagation mechanisms of personalized agents in real-world deployments. To address this gap, we propose Personalized Agent Security Bench (PASB), an end-to-end security evaluation framework tailored for real-world personalized agents. Building upon existing agent attack paradigms, PASB incorporates personalized usage scenarios, realistic toolchains, and long-horizon interactions, enabling black-box, end-to-end security evaluation on real systems. Using OpenClaw as a representative case study, we systematically evaluate its security across multiple personalized scenarios, tool capabilities, and attack types. Our results indicate that OpenClaw exhibits critical vulnerabilities at different execution stages, including user prompt processing, tool usage, and memory retrieval, highlighting substantial security risks in personalized agent deployments. The code for the proposed PASB framework is available at https://github.com/AstorYH/PASB.", "AI": {"tldr": "PASB\u662f\u4e00\u4e2a\u9488\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2a\u6027\u5316AI\u4ee3\u7406\u7684\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u573a\u666f\u3001\u771f\u5b9e\u5de5\u5177\u94fe\u548c\u957f\u65f6\u4ea4\u4e92\u6765\u8bc4\u4f30OpenClaw\u7b49\u4ee3\u7406\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709\u4ee3\u7406\u5b89\u5168\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5408\u6210\u6216\u4efb\u52a1\u4e2d\u5fc3\u5316\u8bbe\u7f6e\uff0c\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u73b0\u5b9e\u4e16\u754c\u4e2a\u6027\u5316\u4ee3\u7406\u7684\u653b\u51fb\u9762\u548c\u98ce\u9669\u4f20\u64ad\u673a\u5236\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51faPASB\u6846\u67b6\uff0c\u57fa\u4e8e\u73b0\u6709\u4ee3\u7406\u653b\u51fb\u8303\u5f0f\uff0c\u6574\u5408\u4e2a\u6027\u5316\u4f7f\u7528\u573a\u666f\u3001\u771f\u5b9e\u5de5\u5177\u94fe\u548c\u957f\u65f6\u4ea4\u4e92\uff0c\u652f\u6301\u9ed1\u76d2\u7aef\u5230\u7aef\u5b89\u5168\u8bc4\u4f30\u3002", "result": "\u4ee5OpenClaw\u4e3a\u6848\u4f8b\u7814\u7a76\u53d1\u73b0\u5176\u5728\u7528\u6237\u63d0\u793a\u5904\u7406\u3001\u5de5\u5177\u4f7f\u7528\u548c\u8bb0\u5fc6\u68c0\u7d22\u7b49\u4e0d\u540c\u6267\u884c\u9636\u6bb5\u5b58\u5728\u5173\u952e\u6f0f\u6d1e\uff0c\u63ed\u793a\u4e2a\u6027\u5316\u4ee3\u7406\u90e8\u7f72\u7684\u4e25\u91cd\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "PASB\u6846\u67b6\u80fd\u6709\u6548\u8bc4\u4f30\u73b0\u5b9e\u4e16\u754c\u4e2a\u6027\u5316\u4ee3\u7406\u7684\u5b89\u5168\u98ce\u9669\uff0cOpenClaw\u7684\u6848\u4f8b\u7814\u7a76\u663e\u793a\u4e2a\u6027\u5316\u4ee3\u7406\u90e8\u7f72\u5b58\u5728\u91cd\u5927\u5b89\u5168\u9690\u60a3\uff0c\u9700\u8981\u52a0\u5f3a\u5b89\u5168\u9632\u62a4\u3002"}}
{"id": "2602.08449", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08449", "abs": "https://arxiv.org/abs/2602.08449", "authors": ["Igor Santos-Grueiro"], "title": "When Evaluation Becomes a Side Channel: Regime Leakage and Structural Mitigations for Alignment Assessment", "comment": "25 pages, 4 figures,", "summary": "Safety evaluation for advanced AI systems implicitly assumes that behavior observed under evaluation is predictive of behavior in deployment. This assumption becomes fragile for agents with situational awareness, which may exploitregime leakage-informational cues distinguishing evaluation from deployment-to implement conditional policies such as sycophancy and sleeper agents, which preserve compliance under oversight while defecting in deployment-like regimes. We reframe alignment evaluation as a problem of information flow under partial observability. Within this framework, we show that divergence between evaluation-time and deployment-time behavior is bounded by the mutual information between internal representations and the regime variable. Motivated by this result, we study regime-blind mechanisms: training-time interventions that reduce the extractability of regime information at decision-relevant internal representations via adversarial invariance. We evaluate this approach on a base, open-weight language model across two fully characterized failure modes -scientific sycophancy and temporal sleeper agents. Regime-blind training suppresses regime-conditioned behavior in both evaluated cases without measurable loss of task utility, but with qualitatively different dynamics: sycophancy exhibits a sharp representational and behavioral transition at low intervention strength, whereas sleeper-agent behavior requires substantially stronger pressure and does not exhibit a clean collapse of regime decodability. These results demonstrate that representational invariance is a meaningful but fundamentally limited control lever, whose effectiveness depends on how regime information is embedded in the policy. We argue that behavioral evaluation should be complemented with white-box diagnostics of regime awareness and information flow.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06AI\u5bf9\u9f50\u8bc4\u4f30\u91cd\u65b0\u5b9a\u4e49\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u4e0b\u7684\u4fe1\u606f\u6d41\u95ee\u9898\uff0c\u8bc1\u660e\u8bc4\u4f30\u65f6\u4e0e\u90e8\u7f72\u65f6\u884c\u4e3a\u5dee\u5f02\u53d7\u5185\u90e8\u8868\u793a\u4e0e\u5236\u5ea6\u53d8\u91cf\u4e92\u4fe1\u606f\u9650\u5236\uff0c\u5e76\u901a\u8fc7\u5236\u5ea6\u76f2\u8bad\u7ec3\u673a\u5236\u51cf\u5c11\u5236\u5ea6\u4fe1\u606f\u53ef\u63d0\u53d6\u6027\u6765\u6291\u5236\u6761\u4ef6\u7b56\u7565\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709AI\u5b89\u5168\u8bc4\u4f30\u5047\u8bbe\u8bc4\u4f30\u65f6\u89c2\u5bdf\u5230\u7684\u884c\u4e3a\u80fd\u9884\u6d4b\u90e8\u7f72\u65f6\u884c\u4e3a\uff0c\u4f46\u5bf9\u4e8e\u5177\u6709\u60c5\u5883\u610f\u8bc6\u7684\u667a\u80fd\u4f53\uff0c\u8fd9\u4e00\u5047\u8bbe\u53d8\u5f97\u8106\u5f31\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u80fd\u5229\u7528\u8bc4\u4f30\u4e0e\u90e8\u7f72\u4e4b\u95f4\u7684\u4fe1\u606f\u5dee\u5f02\u5b9e\u65bd\u6761\u4ef6\u7b56\u7565\uff08\u5982\u5949\u627f\u548c\u6f5c\u4f0f\u4ee3\u7406\uff09\uff0c\u5728\u76d1\u7763\u4e0b\u4fdd\u6301\u5408\u89c4\u4f46\u5728\u90e8\u7f72\u65f6\u8fdd\u89c4\u3002", "method": "\u5c06\u5bf9\u9f50\u8bc4\u4f30\u91cd\u6784\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u4e0b\u7684\u4fe1\u606f\u6d41\u95ee\u9898\uff0c\u63d0\u51fa\u5236\u5ea6\u76f2\u8bad\u7ec3\u673a\u5236\uff1a\u901a\u8fc7\u5bf9\u6297\u4e0d\u53d8\u6027\u51cf\u5c11\u51b3\u7b56\u76f8\u5173\u5185\u90e8\u8868\u793a\u4e2d\u5236\u5ea6\u4fe1\u606f\u7684\u53ef\u63d0\u53d6\u6027\uff0c\u5e76\u5728\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\u4e0a\u8bc4\u4f30\u4e24\u79cd\u5b8c\u5168\u7279\u5f81\u5316\u7684\u5931\u6548\u6a21\u5f0f\uff08\u79d1\u5b66\u5949\u627f\u548c\u65f6\u95f4\u6f5c\u4f0f\u4ee3\u7406\uff09\u3002", "result": "\u5236\u5ea6\u76f2\u8bad\u7ec3\u5728\u4e24\u4e2a\u8bc4\u4f30\u6848\u4f8b\u4e2d\u90fd\u6291\u5236\u4e86\u5236\u5ea6\u6761\u4ef6\u884c\u4e3a\uff0c\u4e14\u6ca1\u6709\u53ef\u6d4b\u91cf\u7684\u4efb\u52a1\u6548\u7528\u635f\u5931\uff0c\u4f46\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u52a8\u6001\uff1a\u5949\u627f\u5728\u4f4e\u5e72\u9884\u5f3a\u5ea6\u4e0b\u8868\u73b0\u51fa\u5c16\u9510\u7684\u8868\u793a\u548c\u884c\u4e3a\u8f6c\u53d8\uff0c\u800c\u6f5c\u4f0f\u4ee3\u7406\u884c\u4e3a\u9700\u8981\u66f4\u5f3a\u7684\u538b\u529b\u4e14\u6ca1\u6709\u8868\u73b0\u51fa\u5236\u5ea6\u53ef\u89e3\u7801\u6027\u7684\u5e72\u51c0\u5d29\u6e83\u3002", "conclusion": "\u8868\u793a\u4e0d\u53d8\u6027\u662f\u6709\u610f\u4e49\u4f46\u6839\u672c\u6709\u9650\u7684\u63a7\u5236\u6760\u6746\uff0c\u5176\u6709\u6548\u6027\u53d6\u51b3\u4e8e\u5236\u5ea6\u4fe1\u606f\u5728\u7b56\u7565\u4e2d\u7684\u5d4c\u5165\u65b9\u5f0f\u3002\u884c\u4e3a\u8bc4\u4f30\u5e94\u8f85\u4ee5\u5236\u5ea6\u610f\u8bc6\u548c\u4fe1\u606f\u6d41\u7684\u767d\u76d2\u8bca\u65ad\u3002"}}
{"id": "2602.08517", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08517", "abs": "https://arxiv.org/abs/2602.08517", "authors": ["Shaoang Zhang", "Yazhe Niu"], "title": "TreeTensor: Boost AI System on Nested Data with Constrained Tree-Like Tensor", "comment": null, "summary": "Tensor is the most basic and essential data structure of nowadays artificial intelligence (AI) system. The natural properties of Tensor, especially the memory-continuity and slice-independence, make it feasible for training system to leverage parallel computing unit like GPU to process data simultaneously in batch, spatial or temporal dimensions. However, if we look beyond perception tasks, the data in a complicated cognitive AI system usually has hierarchical structures (i.e. nested data) with various modalities. They are inconvenient and inefficient to program directly with conventional Tensor with fixed shape. To address this issue, we summarize two main computational patterns of nested data, and then propose a general nested data container: TreeTensor. Through various constraints and magic utilities of TreeTensor, one can apply arbitrary functions and operations to nested data with almost zero cost, including some famous machine learning libraries, such as Scikit-Learn, Numpy and PyTorch. Our approach utilizes a constrained tree-structure perspective to systematically model data relationships, and it can also easily be combined with other methods to extend more usages, such as asynchronous execution and variable-length data computation. Detailed examples and benchmarks show TreeTensor not only provides powerful usability in various problems, especially one of the most complicated AI systems at present: AlphaStar for StarCraftII, but also exhibits excellent runtime efficiency without any overhead. Our project is available at https://github.com/opendilab/DI-treetensor.", "AI": {"tldr": "TreeTensor\uff1a\u4e00\u79cd\u7528\u4e8e\u5904\u7406\u5d4c\u5957\u6570\u636e\u7684\u901a\u7528\u5bb9\u5668\uff0c\u652f\u6301\u96f6\u6210\u672c\u5e94\u7528\u4efb\u610f\u51fd\u6570\u548c\u64cd\u4f5c\u5230\u5206\u5c42\u7ed3\u6784\u6570\u636e\uff0c\u517c\u5bb9\u4e3b\u6d41\u673a\u5668\u5b66\u4e60\u5e93", "motivation": "\u4f20\u7edfTensor\u56fa\u5b9a\u5f62\u72b6\u7684\u7279\u6027\u5728\u5904\u7406\u590d\u6742\u8ba4\u77e5AI\u7cfb\u7edf\u4e2d\u7684\u5206\u5c42\u7ed3\u6784\uff08\u5d4c\u5957\uff09\u6570\u636e\u65f6\u5b58\u5728\u4e0d\u4fbf\u548c\u4f4e\u6548\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u6570\u636e\u5bb9\u5668", "method": "\u603b\u7ed3\u5d4c\u5957\u6570\u636e\u7684\u4e24\u79cd\u4e3b\u8981\u8ba1\u7b97\u6a21\u5f0f\uff0c\u63d0\u51faTreeTensor\u901a\u7528\u5d4c\u5957\u6570\u636e\u5bb9\u5668\uff0c\u901a\u8fc7\u7ea6\u675f\u548c\u9b54\u6cd5\u5de5\u5177\u5b9e\u73b0\u96f6\u6210\u672c\u64cd\u4f5c\u5d4c\u5957\u6570\u636e\uff0c\u652f\u6301Scikit-Learn\u3001Numpy\u3001PyTorch\u7b49\u5e93", "result": "TreeTensor\u5728\u5404\u79cd\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u53ef\u7528\u6027\uff08\u5305\u62ec\u6700\u590d\u6742\u7684AlphaStar\u7cfb\u7edf\uff09\uff0c\u8fd0\u884c\u65f6\u6548\u7387\u4f18\u79c0\u4e14\u65e0\u989d\u5916\u5f00\u9500\uff0c\u652f\u6301\u5f02\u6b65\u6267\u884c\u548c\u53d8\u957f\u6570\u636e\u8ba1\u7b97", "conclusion": "TreeTensor\u4e3a\u5904\u7406\u5206\u5c42\u7ed3\u6784\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u7b80\u5316\u590d\u6742AI\u7cfb\u7edf\u4e2d\u7684\u6570\u636e\u5904\u7406\u7f16\u7a0b"}}
{"id": "2602.08520", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08520", "abs": "https://arxiv.org/abs/2602.08520", "authors": ["Xinhai Sun"], "title": "Reinforcement Inference: Leveraging Uncertainty for Self-Correcting Language Model Reasoning", "comment": null, "summary": "Modern large language models (LLMs) are often evaluated and deployed under a \\emph{one-shot, greedy} inference protocol, especially in professional settings that require deterministic behavior. This regime can systematically under-estimate a fixed model's true capability: many errors arise not from missing knowledge, but from premature commitment under internal ambiguity. We introduce \\emph{Reinforcement Inference}, an entropy-aware inference-time control strategy that uses the model's own uncertainty to selectively invoke a second, more deliberate reasoning attempt, enabling stronger performance \\emph{without any retraining}.\n  On 12,032 MMLU-Pro questions across 14 subjects, using DeepSeek-v3.2 with deterministic decoding in a zero-shot setting, Reinforcement Inference improves accuracy from 60.72\\% to 84.03\\%, while only incurring 61.06\\% additional inference calls. A 100\\% re-asking ablation reaches 84.35\\%, indicating that uncertainty-aware selection captures most of the attainable improvement with substantially less compute. Moreover, a \\emph{prompt-only} ablation underperforms the baseline, suggesting that the gains are not explained by generic `` your output had high entropy, think step-by-step'' prompting alone.\n  Beyond providing a practical inference-time upgrade, our results suggest a broader \\emph{entropy-aware} paradigm for measuring and expanding model capability: because modern decoder-based models generate outputs autoregressively, entropy and related confidence measures arise naturally as first-class control signals during generation. The resulting gap between one-pass greedy inference and uncertainty-conditioned deliberation offers a diagnostic lens on an LLM's latent reasoning horizon and motivates future training objectives that explicitly constrain correctness--confidence alignment.", "AI": {"tldr": "\u63d0\u51faReinforcement Inference\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u81ea\u8eab\u7684\u4e0d\u786e\u5b9a\u6027\u9009\u62e9\u6027\u89e6\u53d1\u4e8c\u6b21\u63a8\u7406\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u663e\u8457\u63d0\u5347LLM\u6027\u80fd", "motivation": "\u5f53\u524dLLM\u5728\u5355\u6b21\u8d2a\u5a6a\u63a8\u7406\u534f\u8bae\u4e0b\u4f1a\u7cfb\u7edf\u6027\u4f4e\u4f30\u6a21\u578b\u771f\u5b9e\u80fd\u529b\uff0c\u8bb8\u591a\u9519\u8bef\u6e90\u4e8e\u5185\u90e8\u6a21\u7cca\u6027\u4e0b\u7684\u8fc7\u65e9\u51b3\u7b56\uff0c\u800c\u975e\u77e5\u8bc6\u7f3a\u5931", "method": "\u57fa\u4e8e\u71b5\u611f\u77e5\u7684\u63a8\u7406\u65f6\u63a7\u5236\u7b56\u7565\uff0c\u5229\u7528\u6a21\u578b\u81ea\u8eab\u4e0d\u786e\u5b9a\u6027\u9009\u62e9\u6027\u5730\u8c03\u7528\u7b2c\u4e8c\u6b21\u66f4\u614e\u91cd\u7684\u63a8\u7406\u5c1d\u8bd5", "result": "\u5728MMLU-Pro\u768412,032\u4e2a\u95ee\u9898\u4e0a\uff0cDeepSeek-v3.2\u51c6\u786e\u7387\u4ece60.72%\u63d0\u5347\u81f384.03%\uff0c\u4ec5\u589e\u52a061.06%\u7684\u63a8\u7406\u8c03\u7528\uff1b\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u9009\u62e9\u6355\u83b7\u4e86\u5927\u90e8\u5206\u53ef\u83b7\u5f97\u7684\u6539\u8fdb", "conclusion": "\u63d0\u51fa\u71b5\u611f\u77e5\u8303\u5f0f\u6765\u6d4b\u91cf\u548c\u6269\u5c55\u6a21\u578b\u80fd\u529b\uff0c\u5355\u6b21\u8d2a\u5a6a\u63a8\u7406\u4e0e\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u5316\u63a8\u7406\u4e4b\u95f4\u7684\u5dee\u8ddd\u4e3aLLM\u6f5c\u5728\u63a8\u7406\u8303\u56f4\u63d0\u4f9b\u4e86\u8bca\u65ad\u89c6\u89d2"}}
{"id": "2602.08533", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08533", "abs": "https://arxiv.org/abs/2602.08533", "authors": ["Kun Peng", "Conghui Tan", "Yu Liu", "Guohua Tang", "Zhongqian Sun", "Wei Yang", "Zining Zhu", "Lei Jiang", "Yanbing Liu", "Hao Peng"], "title": "Dialogue Model Optimization via Agent Game and Adaptive Tree-based GRPO", "comment": null, "summary": "Open-ended dialogue agents aim to deliver engaging, personalized interactions by adapting to users' traits, but existing methods face critical limitations: over-reliance on pre-collected user data, and short-horizon biases in reinforcement learning (RL) that neglect long-term dialogue value. To address these, we propose a novel long-horizon RL framework integrating online personalization with Adaptive Tree-based Group Relative Policy Optimization (AT-GRPO). Adopting a two-agent game paradigm, a user agent constructs dynamic environments via style mimicry (learning user-specific conversational traits) and active termination (predicting turn-level termination probabilities as immediate rewards), forming an iterative cycle that drives the dialogue agent to deepen interest exploration. AT-GRPO reinterprets dialogue trajectories as trees and introduces adaptive observation ranges. Unlike full tree expansion that incurs exponential overhead, it limits each node to aggregate rewards from a stage-aware range: larger ranges support early-stage topic exploration, while smaller ranges facilitate late-stage dialogue maintenance. This design reduces rollout budgets from exponential to polynomial in the dialogue length, while preserving long-term reward capture. Extensive experiments show our framework's superior performance, sample efficiency, and robustness.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u5728\u7ebf\u4e2a\u6027\u5316\u4e0e\u81ea\u9002\u5e94\u6811\u57fa\u5206\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u7684\u957f\u89c6\u91ce\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5f00\u653e\u57df\u5bf9\u8bdd\u4ee3\u7406\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9884\u6536\u96c6\u6570\u636e\u548c\u77ed\u89c6\u91ce\u504f\u89c1\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5f00\u653e\u57df\u5bf9\u8bdd\u4ee3\u7406\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a\u8fc7\u5ea6\u4f9d\u8d56\u9884\u6536\u96c6\u7684\u7528\u6237\u6570\u636e\uff0c\u4ee5\u53ca\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u77ed\u89c6\u91ce\u504f\u89c1\uff08\u5ffd\u89c6\u5bf9\u8bdd\u7684\u957f\u671f\u4ef7\u503c\uff09\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u7ebf\u4e2a\u6027\u5316\u5e76\u8003\u8651\u957f\u671f\u5bf9\u8bdd\u4ef7\u503c\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u53cc\u4ee3\u7406\u535a\u5f08\u8303\u5f0f\uff1a\u7528\u6237\u4ee3\u7406\u901a\u8fc7\u98ce\u683c\u6a21\u4eff\u5b66\u4e60\u7528\u6237\u7279\u5b9a\u5bf9\u8bdd\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u4e3b\u52a8\u7ec8\u6b62\u9884\u6d4b\u56de\u5408\u7ea7\u7ec8\u6b62\u6982\u7387\u4f5c\u4e3a\u5373\u65f6\u5956\u52b1\u6765\u6784\u5efa\u52a8\u6001\u73af\u5883\uff1b\u5bf9\u8bdd\u4ee3\u7406\u4f7f\u7528\u81ea\u9002\u5e94\u6811\u57fa\u5206\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08AT-GRPO\uff09\uff0c\u5c06\u5bf9\u8bdd\u8f68\u8ff9\u91cd\u65b0\u89e3\u91ca\u4e3a\u6811\u7ed3\u6784\uff0c\u5f15\u5165\u81ea\u9002\u5e94\u89c2\u5bdf\u8303\u56f4\uff0c\u5728\u65e9\u671f\u9636\u6bb5\u4f7f\u7528\u8f83\u5927\u8303\u56f4\u652f\u6301\u8bdd\u9898\u63a2\u7d22\uff0c\u665a\u671f\u9636\u6bb5\u4f7f\u7528\u8f83\u5c0f\u8303\u56f4\u4fc3\u8fdb\u5bf9\u8bdd\u7ef4\u62a4\uff0c\u5c06\u8ba1\u7b97\u5f00\u9500\u4ece\u6307\u6570\u7ea7\u964d\u81f3\u591a\u9879\u5f0f\u7ea7\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u5728\u6027\u80fd\u3001\u6837\u672c\u6548\u7387\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u957f\u89c6\u91ceRL\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5f00\u653e\u57df\u5bf9\u8bdd\u4ee3\u7406\u4e2d\u7684\u5728\u7ebf\u4e2a\u6027\u5316\u548c\u957f\u671f\u4ef7\u503c\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7AT-GRPO\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u957f\u89c6\u91ce\u5956\u52b1\u6355\u83b7\uff0c\u4e3a\u5bf9\u8bdd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u4e2a\u6027\u5316\u4ea4\u4e92\u65b9\u6848\u3002"}}
{"id": "2602.08586", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08586", "abs": "https://arxiv.org/abs/2602.08586", "authors": ["Yiming Yang", "Zhuoyuan Li", "Fanxiang Zeng", "Hao Fu", "Yue Liu"], "title": "PRISM: A Principled Framework for Multi-Agent Reasoning via Gain Decomposition", "comment": null, "summary": "Multi-agent collaboration has emerged as a promising paradigm for enhancing reasoning capabilities of Large Language Models (LLMs). However, existing approaches remain largely heuristic, lacking principled guidance on what drives performance gains and how to systematically optimize multi-agent reasoning. Specifically, it remains unclear why multi-agent collaboration outperforms single-agent reasoning and which design choices contribute most to these gains, making it difficult to build better systems.\n  We address this gap by introducing a unified theoretical framework that decomposes multi-agent reasoning gains into three conceptually independent dimensions: Exploration for diverse solution coverage, Information for high-fidelity feedback, and Aggregation for principled consensus. Through this lens, existing methods can be understood as special cases that optimize only subsets of these dimensions. Building upon this decomposition, a novel framework called PRISM (Propose-Review-Integrate Synthesis for Multi-agent Reasoning) is proposed, which jointly maximizes all three dimensions through role-based diversity, execution-grounded feedback with evidence-based cross-evaluation, and iterative synthesis with closed-loop validation. Extensive experiments across mathematical reasoning, code generation, and function calling benchmarks demonstrate that PRISM achieves state-of-the-art performance with superior compute-efficiency compared to methods optimizing partial dimensions. The theoretical framework provides actionable design principles for future multi-agent reasoning systems.", "AI": {"tldr": "PRISM\u6846\u67b6\u901a\u8fc7\u7406\u8bba\u5206\u89e3\u591a\u667a\u80fd\u4f53\u63a8\u7406\u589e\u76ca\u4e3a\u63a2\u7d22\u3001\u4fe1\u606f\u3001\u805a\u5408\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u8bbe\u8ba1\u89d2\u8272\u591a\u6837\u6027\u3001\u6267\u884c\u53cd\u9988\u3001\u8fed\u4ee3\u5408\u6210\u65b9\u6cd5\u5b9e\u73b0\u5168\u9762\u4f18\u5316\uff0c\u5728\u6570\u5b66\u63a8\u7406\u3001\u4ee3\u7801\u751f\u6210\u7b49\u4efb\u52a1\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u6307\u5bfc\uff0c\u4e0d\u6e05\u695a\u4e3a\u4f55\u591a\u667a\u80fd\u4f53\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u4ee5\u53ca\u54ea\u4e9b\u8bbe\u8ba1\u9009\u62e9\u6700\u5173\u952e\uff0c\u96be\u4ee5\u7cfb\u7edf\u4f18\u5316\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u63a8\u7406\u589e\u76ca\u5206\u89e3\u4e3a\u63a2\u7d22\u3001\u4fe1\u606f\u3001\u805a\u5408\u4e09\u4e2a\u7ef4\u5ea6\uff1b\u57fa\u4e8e\u6b64\u8bbe\u8ba1PRISM\u6846\u67b6\uff0c\u901a\u8fc7\u89d2\u8272\u591a\u6837\u6027\u5b9e\u73b0\u63a2\u7d22\uff0c\u6267\u884c\u53cd\u9988\u63d0\u4f9b\u4fe1\u606f\uff0c\u8fed\u4ee3\u5408\u6210\u5b9e\u73b0\u805a\u5408\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u3001\u4ee3\u7801\u751f\u6210\u548c\u51fd\u6570\u8c03\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPRISM\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u76f8\u6bd4\u4ec5\u4f18\u5316\u90e8\u5206\u7ef4\u5ea6\u7684\u65b9\u6cd5\u5177\u6709\u66f4\u4f18\u7684\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u7406\u8bba\u6846\u67b6\u4e3a\u672a\u6765\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u8bbe\u8ba1\u539f\u5219\uff0cPRISM\u901a\u8fc7\u5168\u9762\u4f18\u5316\u4e09\u4e2a\u7ef4\u5ea6\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2602.08597", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08597", "abs": "https://arxiv.org/abs/2602.08597", "authors": ["Roland Bertin-Johannet", "Lara Scipio", "Leopold Mayti\u00e9", "Rufin VanRullen"], "title": "An Attention Mechanism for Robust Multimodal Integration in a Global Workspace Architecture", "comment": null, "summary": "Global Workspace Theory (GWT), inspired by cognitive neuroscience, posits that flexible cognition could arise via the attentional selection of a relevant subset of modalities within a multimodal integration system. This cognitive framework can inspire novel computational architectures for multimodal integration. Indeed, recent implementations of GWT have explored its multimodal representation capabilities, but the related attention mechanisms remain understudied. Here, we propose and evaluate a top-down attention mechanism to select modalities inside a global workspace. First, we demonstrate that our attention mechanism improves noise robustness of a global workspace system on two multimodal datasets of increasing complexity: Simple Shapes and MM-IMDb 1.0. Second, we highlight various cross-task and cross-modality generalization capabilities that are not shared by multimodal attention models from the literature. Comparing against existing baselines on the MM-IMDb 1.0 benchmark, we find our attention mechanism makes the global workspace competitive with the state of the art.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\uff08GWT\uff09\u7684\u9876\u90e8\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4ee5\u9009\u62e9\u591a\u6a21\u6001\u7cfb\u7edf\u4e2d\u7684\u76f8\u5173\u6a21\u6001\uff0c\u63d0\u9ad8\u4e86\u566a\u58f0\u9c81\u68d2\u6027\uff0c\u5e76\u5728MM-IMDb\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\uff08GWT\uff09\u4f5c\u4e3a\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u7684\u6846\u67b6\uff0c\u53ef\u7528\u4e8e\u591a\u6a21\u6001\u96c6\u6210\u8ba1\u7b97\u67b6\u6784\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u63a2\u7d22\u4e86GWT\u7684\u591a\u6a21\u6001\u8868\u793a\u80fd\u529b\uff0c\u4f46\u5176\u6ce8\u610f\u529b\u673a\u5236\u4ecd\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u6ce8\u610f\u529b\u9009\u62e9\u673a\u5236\u6765\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9876\u90e8\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7528\u4e8e\u5728\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u4e2d\u9009\u62e9\u76f8\u5173\u6a21\u6001\u3002\u8be5\u65b9\u6cd5\u5728\u4e24\u4e2a\u590d\u6742\u5ea6\u9012\u589e\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff08Simple Shapes\u548cMM-IMDb 1.0\uff09\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4e0e\u73b0\u6709\u591a\u6a21\u6001\u6ce8\u610f\u529b\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "1\uff09\u6ce8\u610f\u529b\u673a\u5236\u63d0\u9ad8\u4e86\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u7cfb\u7edf\u7684\u566a\u58f0\u9c81\u68d2\u6027\uff1b2\uff09\u5c55\u793a\u4e86\u6587\u732e\u4e2d\u591a\u6a21\u6001\u6ce8\u610f\u529b\u6a21\u578b\u4e0d\u5177\u5907\u7684\u8de8\u4efb\u52a1\u548c\u8de8\u6a21\u6001\u6cdb\u5316\u80fd\u529b\uff1b3\uff09\u5728MM-IMDb 1.0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6ce8\u610f\u529b\u673a\u5236\u4f7f\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "\u63d0\u51fa\u7684\u9876\u90e8\u6ce8\u610f\u529b\u673a\u5236\u6709\u6548\u589e\u5f3a\u4e86\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\u5728\u591a\u6a21\u6001\u96c6\u6210\u4e2d\u7684\u6027\u80fd\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u566a\u58f0\u9c81\u68d2\u6027\uff0c\u8fd8\u5c55\u73b0\u4e86\u72ec\u7279\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4f7fGWT\u5728\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5177\u6709\u7ade\u4e89\u529b\u3002"}}
{"id": "2602.08603", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08603", "abs": "https://arxiv.org/abs/2602.08603", "authors": ["Teng Wang", "Rong Shan", "Jianghao Lin", "Junjie Wu", "Tianyi Xu", "Jianping Zhang", "Wenteng Chen", "Changwang Zhang", "Zhaoxiang Wang", "Weinan Zhang", "Jun Wang"], "title": "OSCAR: Optimization-Steered Agentic Planning for Composed Image Retrieval", "comment": null, "summary": "Composed image retrieval (CIR) requires complex reasoning over heterogeneous visual and textual constraints. Existing approaches largely fall into two paradigms: unified embedding retrieval, which suffers from single-model myopia, and heuristic agentic retrieval, which is limited by suboptimal, trial-and-error orchestration. To this end, we propose OSCAR, an optimization-steered agentic planning framework for composed image retrieval. We are the first to reformulate agentic CIR from a heuristic search process into a principled trajectory optimization problem. Instead of relying on heuristic trial-and-error exploration, OSCAR employs a novel offline-online paradigm. In the offline phase, we model CIR via atomic retrieval selection and composition as a two-stage mixed-integer programming problem, mathematically deriving optimal trajectories that maximize ground-truth coverage for training samples via rigorous boolean set operations. These trajectories are then stored in a golden library to serve as in-context demonstrations for online steering of VLM planner at online inference time. Extensive experiments on three public benchmarks and a private industrial benchmark show that OSCAR consistently outperforms SOTA baselines. Notably, it achieves superior performance using only 10% of training data, demonstrating strong generalization of planning logic rather than dataset-specific memorization.", "AI": {"tldr": "OSCAR\uff1a\u57fa\u4e8e\u4f18\u5316\u5f15\u5bfc\u7684\u667a\u80fd\u4f53\u89c4\u5212\u6846\u67b6\uff0c\u5c06\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u4ece\u542f\u53d1\u5f0f\u641c\u7d22\u8f6c\u5316\u4e3a\u8f68\u8ff9\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u79bb\u7ebf-\u5728\u7ebf\u8303\u5f0f\u5b9e\u73b0\u9ad8\u6548\u68c0\u7d22", "motivation": "\u73b0\u6709\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u65b9\u6cd5\u5b58\u5728\u4e24\u5927\u95ee\u9898\uff1a\u7edf\u4e00\u5d4c\u5165\u68c0\u7d22\u53d7\u9650\u4e8e\u5355\u6a21\u578b\u8fd1\u89c6\u95ee\u9898\uff0c\u542f\u53d1\u5f0f\u667a\u80fd\u4f53\u68c0\u7d22\u5219\u53d7\u9650\u4e8e\u6b21\u4f18\u7684\u8bd5\u9519\u7f16\u6392\u3002\u9700\u8981\u66f4\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u5904\u7406\u89c6\u89c9\u548c\u6587\u672c\u7ea6\u675f\u7684\u590d\u6742\u63a8\u7406\u3002", "method": "\u63d0\u51faOSCAR\u6846\u67b6\uff0c\u91c7\u7528\u79bb\u7ebf-\u5728\u7ebf\u8303\u5f0f\uff1a\u79bb\u7ebf\u9636\u6bb5\u5c06CIR\u5efa\u6a21\u4e3a\u4e24\u9636\u6bb5\u6df7\u5408\u6574\u6570\u89c4\u5212\u95ee\u9898\uff0c\u901a\u8fc7\u5e03\u5c14\u96c6\u5408\u8fd0\u7b97\u63a8\u5bfc\u6700\u5927\u5316\u771f\u5b9e\u8986\u76d6\u7684\u6700\u4f18\u8f68\u8ff9\uff1b\u5728\u7ebf\u9636\u6bb5\u4f7f\u7528\u8fd9\u4e9b\u8f68\u8ff9\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u793a\u4f8b\u6765\u5f15\u5bfcVLM\u89c4\u5212\u5668\u8fdb\u884c\u63a8\u7406\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u57fa\u51c6\u548c\u4e00\u4e2a\u79c1\u6709\u5de5\u4e1a\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cOSCAR\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709SOTA\u57fa\u7ebf\u3002\u4ec5\u4f7f\u752810%\u8bad\u7ec3\u6570\u636e\u5c31\u80fd\u8fbe\u5230\u4f18\u8d8a\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u89c4\u5212\u903b\u8f91\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\u800c\u975e\u6570\u636e\u96c6\u7279\u5b9a\u8bb0\u5fc6\u3002", "conclusion": "OSCAR\u9996\u6b21\u5c06\u667a\u80fd\u4f53CIR\u4ece\u542f\u53d1\u5f0f\u641c\u7d22\u8fc7\u7a0b\u91cd\u65b0\u8868\u8ff0\u4e3a\u539f\u5219\u6027\u7684\u8f68\u8ff9\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u6570\u5b66\u63a8\u5bfc\u7684\u6700\u4f18\u8f68\u8ff9\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u7684\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\uff0c\u5c55\u793a\u4e86\u89c4\u5212\u903b\u8f91\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.08630", "categories": ["cs.AI", "cs.CC"], "pdf": "https://arxiv.org/pdf/2602.08630", "abs": "https://arxiv.org/abs/2602.08630", "authors": ["Jonah Brown-Cohen", "Geoffrey Irving", "Simon C. Marshall", "Ilan Newman", "Georgios Piliouras", "Mario Szegedy"], "title": "Debate is efficient with your time", "comment": "11 Pages, 0 figures", "summary": "AI safety via debate uses two competing models to help a human judge verify complex computational tasks. Previous work has established what problems debate can solve in principle, but has not analysed the practical cost of human oversight: how many queries must the judge make to the debate transcript? We introduce Debate Query Complexity}(DQC), the minimum number of bits a verifier must inspect to correctly decide a debate.\n  Surprisingly, we find that PSPACE/poly (the class of problems which debate can efficiently decide) is precisely the class of functions decidable with O(log n) queries. This characterisation shows that debate is remarkably query-efficient: even for highly complex problems, logarithmic oversight suffices. We also establish that functions depending on all their input bits require Omega(log n) queries, and that any function computable by a circuit of size s satisfies DQC(f) <= log(s) + 3. Interestingly, this last result implies that proving DQC lower bounds of log(n) + 6 for languages in P would yield new circuit lower bounds, connecting debate query complexity to central questions in circuit complexity.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u8fa9\u8bba\u5f0fAI\u5b89\u5168\u4e2d\u7684\u4eba\u7c7b\u76d1\u7763\u6210\u672c\uff0c\u53d1\u73b0PSPACE/poly\u95ee\u9898\u4ec5\u9700O(log n)\u6b21\u67e5\u8be2\u5373\u53ef\u5224\u5b9a\uff0c\u8bc1\u660e\u8fa9\u8bba\u5177\u6709\u6781\u9ad8\u7684\u67e5\u8be2\u6548\u7387\u3002", "motivation": "\u5148\u524d\u5de5\u4f5c\u5efa\u7acb\u4e86\u8fa9\u8bba\u5728\u7406\u8bba\u4e0a\u80fd\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u4f46\u672a\u5206\u6790\u4eba\u7c7b\u76d1\u7763\u7684\u5b9e\u9645\u6210\u672c\u2014\u2014\u6cd5\u5b98\u9700\u8981\u68c0\u67e5\u8fa9\u8bba\u8bb0\u5f55\u4e2d\u7684\u591a\u5c11\u67e5\u8be2\u3002\u672c\u6587\u65e8\u5728\u91cf\u5316\u8fa9\u8bba\u4e2d\u7684\u4eba\u7c7b\u76d1\u7763\u5f00\u9500\u3002", "method": "\u5f15\u5165\u8fa9\u8bba\u67e5\u8be2\u590d\u6742\u5ea6(DQC)\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e3a\u9a8c\u8bc1\u8005\u6b63\u786e\u5224\u5b9a\u8fa9\u8bba\u6240\u9700\u68c0\u67e5\u7684\u6700\u5c0f\u6bd4\u7279\u6570\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u5c06PSPACE/poly\u7c7b\u4e0eO(log n)\u67e5\u8be2\u53ef\u5224\u5b9a\u7684\u51fd\u6570\u7c7b\u5efa\u7acb\u7b49\u4ef7\u5173\u7cfb\u3002", "result": "\u53d1\u73b0PSPACE/poly\u6070\u597d\u662fO(log n)\u67e5\u8be2\u53ef\u5224\u5b9a\u7684\u51fd\u6570\u7c7b\uff0c\u8bc1\u660e\u8fa9\u8bba\u5177\u6709\u6781\u9ad8\u7684\u67e5\u8be2\u6548\u7387\u3002\u8fd8\u8bc1\u660e\u4f9d\u8d56\u6240\u6709\u8f93\u5165\u6bd4\u7279\u7684\u51fd\u6570\u9700\u8981\u03a9(log n)\u67e5\u8be2\uff0c\u4e14\u89c4\u6a21\u4e3as\u7684\u7535\u8def\u53ef\u8ba1\u7b97\u7684\u51fd\u6570\u6ee1\u8db3DQC(f) \u2264 log(s) + 3\u3002", "conclusion": "\u8fa9\u8bba\u5728\u67e5\u8be2\u590d\u6742\u5ea6\u4e0a\u975e\u5e38\u9ad8\u6548\uff0c\u5bf9\u6570\u7ea7\u76d1\u7763\u8db3\u4ee5\u5904\u7406\u9ad8\u5ea6\u590d\u6742\u95ee\u9898\u3002\u8bc1\u660eDQC\u4e0b\u754c\u4e0e\u7535\u8def\u590d\u6742\u5ea6\u4e2d\u5fc3\u95ee\u9898\u76f8\u5173\uff0c\u4e3a\u8fde\u63a5\u8fa9\u8bba\u67e5\u8be2\u590d\u6742\u5ea6\u4e0e\u7535\u8def\u4e0b\u754c\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2602.08708", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08708", "abs": "https://arxiv.org/abs/2602.08708", "authors": ["Stefan Edelkamp", "Ji\u0159\u00ed Fink", "Petr Gregor", "Anders Jonsson", "Bernhard Nebel"], "title": "Intermediate Results on the Complexity of STRIPS$_{1}^{1}$", "comment": null, "summary": "This paper is based on Bylander's results on the computational complexity of propositional STRIPS planning. He showed that when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. While NP-hardness is settled, it is unknown whether propositional STRIPS with operators that only have one precondition and one effect is NP-complete. We shed light on the question whether this small solution hypothesis for STRIPS$^1_1$ is true, calling a SAT solver for small instances, introducing the literal graph, and mapping it to Petri nets.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86STRIPS\u89c4\u5212\u4e2d\u64cd\u4f5c\u7b26\u4ec5\u6709\u4e00\u4e2a\u524d\u63d0\u548c\u4e00\u4e2a\u6548\u679c\u65f6\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u63a2\u8ba8\u4e86STRIPS\u00b9\u2081\u7684\"\u5c0f\u89e3\u5047\u8bbe\"\u662f\u5426\u6210\u7acb\u3002", "motivation": "Bylander\u7684\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u64cd\u4f5c\u7b26\u9650\u5236\u4e3a\u4e24\u4e2a\u524d\u63d0\u548c\u4e24\u4e2a\u540e\u7f6e\u6761\u4ef6\uff0c\u547d\u9898STRIPS\u89c4\u5212\u7684\u5b58\u5728\u6027\u5224\u5b9a\u4e5f\u662fPSPACE\u5b8c\u5168\u7684\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u64cd\u4f5c\u7b26\u53ea\u6709\u4e00\u4e2a\u524d\u63d0\u548c\u4e00\u4e2a\u6548\u679c\u7684\u60c5\u51b5\uff0c\u662f\u5426NP\u5b8c\u5168\u4ecd\u7136\u672a\u77e5\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u8fd9\u4e2aSTRIPS\u00b9\u2081\u7684\"\u5c0f\u89e3\u5047\u8bbe\"\u662f\u5426\u6210\u7acb\u3002", "method": "\u901a\u8fc7\u8c03\u7528SAT\u6c42\u89e3\u5668\u5904\u7406\u5c0f\u89c4\u6a21\u5b9e\u4f8b\uff0c\u5f15\u5165\u5b57\u9762\u56fe\u6982\u5ff5\uff0c\u5e76\u5c06\u5176\u6620\u5c04\u5230Petri\u7f51\u8fdb\u884c\u5206\u6790\u3002", "result": "\u8bba\u6587\u4e3aSTRIPS\u00b9\u2081\u7684\u590d\u6742\u5ea6\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u4f46\u5177\u4f53\u7ed3\u679c\u9700\u8981\u67e5\u770b\u5b8c\u6574\u8bba\u6587\u5185\u5bb9\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3STRIPS\u89c4\u5212\u4e2d\u64cd\u4f5c\u7b26\u590d\u6742\u5ea6\u4e0e\u8ba1\u7b97\u590d\u6742\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u63d0\u4f9b\u4e86\u91cd\u8981\u7ebf\u7d22\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u6700\u7b80\u5355\u7684STRIPS\u53d8\u4f53\u7684\u590d\u6742\u5ea6\u5206\u7c7b\u95ee\u9898\u3002"}}
{"id": "2602.08715", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08715", "abs": "https://arxiv.org/abs/2602.08715", "authors": ["Miquel Mir\u00f3-Nicolau", "Gabriel Moy\u00e0-Alcover", "Anna Arias-Duart"], "title": "Exploring SAIG Methods for an Objective Evaluation of XAI", "comment": null, "summary": "The evaluation of eXplainable Artificial Intelligence (XAI) methods is a rapidly growing field, characterized by a wide variety of approaches. This diversity highlights the complexity of the XAI evaluation, which, unlike traditional AI assessment, lacks a universally correct ground truth for the explanation, making objective evaluation challenging. One promising direction to address this issue involves the use of what we term Synthetic Artificial Intelligence Ground truth (SAIG) methods, which generate artificial ground truths to enable the direct evaluation of XAI techniques. This paper presents the first review and analysis of SAIG methods. We introduce a novel taxonomy to classify these approaches, identifying seven key features that distinguish different SAIG methods. Our comparative study reveals a concerning lack of consensus on the most effective XAI evaluation techniques, underscoring the need for further research and standardization in this area.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u56de\u987e\u548c\u5206\u6790\u4e86\u5408\u6210\u4eba\u5de5\u667a\u80fd\u57fa\u51c6\u771f\u503c\uff08SAIG\uff09\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u7c7b\u6cd5\uff0c\u63ed\u793a\u4e86XAI\u8bc4\u4f30\u9886\u57df\u7f3a\u4e4f\u5171\u8bc6\u7684\u73b0\u72b6\uff0c\u5f3a\u8c03\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u6807\u51c6\u5316\u3002", "motivation": "\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u8bc4\u4f30\u9886\u57df\u65b9\u6cd5\u591a\u6837\u4e14\u590d\u6742\uff0c\u4e0e\u4f20\u7edfAI\u8bc4\u4f30\u4e0d\u540c\uff0cXAI\u7f3a\u4e4f\u89e3\u91ca\u7684\u666e\u904d\u6b63\u786e\u57fa\u51c6\u771f\u503c\uff0c\u4f7f\u5f97\u5ba2\u89c2\u8bc4\u4f30\u5177\u6709\u6311\u6218\u6027\u3002SAIG\u65b9\u6cd5\u901a\u8fc7\u751f\u6210\u4eba\u5de5\u57fa\u51c6\u771f\u503c\u6765\u76f4\u63a5\u8bc4\u4f30XAI\u6280\u672f\uff0c\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002", "method": "\u672c\u6587\u5bf9SAIG\u65b9\u6cd5\u8fdb\u884c\u4e86\u9996\u6b21\u7cfb\u7edf\u56de\u987e\u548c\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u7c7b\u6cd5\u6765\u5bf9\u8fd9\u4e9b\u65b9\u6cd5\u8fdb\u884c\u5206\u7c7b\uff0c\u8bc6\u522b\u4e86\u533a\u5206\u4e0d\u540cSAIG\u65b9\u6cd5\u7684\u4e03\u4e2a\u5173\u952e\u7279\u5f81\uff0c\u5e76\u8fdb\u884c\u4e86\u6bd4\u8f83\u7814\u7a76\u3002", "result": "\u6bd4\u8f83\u7814\u7a76\u63ed\u793a\u4e86XAI\u8bc4\u4f30\u6280\u672f\u6709\u6548\u6027\u65b9\u9762\u4ee4\u4eba\u62c5\u5fe7\u7684\u5171\u8bc6\u7f3a\u4e4f\uff0c\u8868\u660e\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u6807\u51c6\u5316\u3002", "conclusion": "SAIG\u65b9\u6cd5\u4e3aXAI\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\uff0c\u4f46\u8be5\u9886\u57df\u9700\u8981\u66f4\u591a\u7684\u7814\u7a76\u52aa\u529b\u548c\u6807\u51c6\u5316\u5de5\u4f5c\u6765\u5efa\u7acb\u53ef\u9760\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u63a8\u52a8XAI\u6280\u672f\u7684\u5065\u5eb7\u53d1\u5c55\u3002"}}
{"id": "2602.08734", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08734", "abs": "https://arxiv.org/abs/2602.08734", "authors": ["David Hud\u00e1k", "Maris F. L. Galesloot", "Martin Tappler", "Martin Kure\u010dka", "Nils Jansen", "Milan \u010ce\u0161ka"], "title": "Finite-State Controllers for (Hidden-Model) POMDPs using Deep Reinforcement Learning", "comment": "17 pages (8 main paper, 2 references, 7 appendix). 3 figures in the main paper, 3 figures in the appendix. Accepted AAMAS'26 submission", "summary": "Solving partially observable Markov decision processes (POMDPs) requires computing policies under imperfect state information. Despite recent advances, the scalability of existing POMDP solvers remains limited. Moreover, many settings require a policy that is robust across multiple POMDPs, further aggravating the scalability issue. We propose the Lexpop framework for POMDP solving. Lexpop (1) employs deep reinforcement learning to train a neural policy, represented by a recurrent neural network, and (2) constructs a finite-state controller mimicking the neural policy through efficient extraction methods. Crucially, unlike neural policies, such controllers can be formally evaluated, providing performance guarantees. We extend Lexpop to compute robust policies for hidden-model POMDPs (HM-POMDPs), which describe finite sets of POMDPs. We associate every extracted controller with its worst-case POMDP. Using a set of such POMDPs, we iteratively train a robust neural policy and consequently extract a robust controller. Our experiments show that on problems with large state spaces, Lexpop outperforms state-of-the-art solvers for POMDPs as well as HM-POMDPs.", "AI": {"tldr": "Lexpop\u6846\u67b6\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u795e\u7ecf\u7b56\u7565\uff0c\u7136\u540e\u63d0\u53d6\u6709\u9650\u72b6\u6001\u63a7\u5236\u5668\u6765\u63d0\u4f9b\u6027\u80fd\u4fdd\u8bc1\uff0c\u5e76\u6269\u5c55\u5230\u5904\u7406\u9690\u85cf\u6a21\u578bPOMDPs\u7684\u9c81\u68d2\u7b56\u7565\u8ba1\u7b97\u3002", "motivation": "\u73b0\u6709POMDP\u6c42\u89e3\u5668\u7684\u53ef\u6269\u5c55\u6027\u6709\u9650\uff0c\u4e14\u8bb8\u591a\u573a\u666f\u9700\u8981\u8de8\u591a\u4e2aPOMDP\u7684\u9c81\u68d2\u7b56\u7565\uff0c\u8fdb\u4e00\u6b65\u52a0\u5267\u4e86\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "1) \u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7b56\u7565\uff1b2) \u901a\u8fc7\u9ad8\u6548\u63d0\u53d6\u65b9\u6cd5\u6784\u5efa\u6a21\u4eff\u795e\u7ecf\u7b56\u7565\u7684\u6709\u9650\u72b6\u6001\u63a7\u5236\u5668\uff1b3) \u6269\u5c55\u5230HM-POMDPs\uff0c\u5c06\u6bcf\u4e2a\u63a7\u5236\u5668\u4e0e\u5176\u6700\u574f\u60c5\u51b5POMDP\u5173\u8054\uff0c\u8fed\u4ee3\u8bad\u7ec3\u9c81\u68d2\u795e\u7ecf\u7b56\u7565\u5e76\u63d0\u53d6\u9c81\u68d2\u63a7\u5236\u5668\u3002", "result": "\u5728\u5927\u72b6\u6001\u7a7a\u95f4\u95ee\u9898\u4e0a\uff0cLexpop\u5728POMDPs\u548cHM-POMDPs\u4e0a\u90fd\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6c42\u89e3\u5668\u3002", "conclusion": "Lexpop\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u795e\u7ecf\u7b56\u7565\u5b66\u4e60\u548c\u63a7\u5236\u5668\u63d0\u53d6\uff0c\u4e3aPOMDPs\u548cHM-POMDPs\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u5177\u6709\u6027\u80fd\u4fdd\u8bc1\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08783", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08783", "abs": "https://arxiv.org/abs/2602.08783", "authors": ["Zirui Li", "Xuefeng Bai", "Kehai Chen", "Yizhi Li", "Jian Yang", "Chenghua Lin", "Min Zhang"], "title": "Dynamics Within Latent Chain-of-Thought: An Empirical Study of Causal Structure", "comment": "22 pages", "summary": "Latent or continuous chain-of-thought methods replace explicit textual rationales with a number of internal latent steps, but these intermediate computations are difficult to evaluate beyond correlation-based probes. In this paper, we view latent chain-of-thought as a manipulable causal process in representation space by modeling latent steps as variables in a structural causal model (SCM) and analyzing their effects through step-wise $\\mathrm{do}$-interventions. We study two representative paradigms (i.e., Coconut and CODI) on both mathematical and general reasoning tasks to investigate three key questions: (1) which steps are causally necessary for correctness and when answers become decidable early; (2) how does influence propagate across steps, and how does this structure compare to explicit CoT; and (3) do intermediate trajectories retain competing answer modes, and how does output-level commitment differ from representational commitment across steps. We find that latent-step budgets behave less like homogeneous extra depth and more like staged functionality with non-local routing, and we identify a persistent gap between early output bias and late representational commitment. These results motivate mode-conditional and stability-aware analyses -- and corresponding training/decoding objectives -- as more reliable tools for interpreting and improving latent reasoning systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u6f5c\u5728\u601d\u7ef4\u94fe\u89c6\u4e3a\u8868\u793a\u7a7a\u95f4\u4e2d\u7684\u53ef\u64cd\u7eb5\u56e0\u679c\u8fc7\u7a0b\uff0c\u901a\u8fc7\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u5206\u6790\u6f5c\u5728\u6b65\u9aa4\uff0c\u7814\u7a76\u5176\u5728\u6570\u5b66\u548c\u4e00\u822c\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u56e0\u679c\u5fc5\u8981\u6027\u3001\u5f71\u54cd\u4f20\u64ad\u548c\u7b54\u6848\u6a21\u5f0f\u4fdd\u7559\u3002", "motivation": "\u73b0\u6709\u6f5c\u5728\u601d\u7ef4\u94fe\u65b9\u6cd5\u4f7f\u7528\u5185\u90e8\u6f5c\u5728\u6b65\u9aa4\u66ff\u4ee3\u663e\u5f0f\u6587\u672c\u63a8\u7406\uff0c\u4f46\u8fd9\u4e9b\u4e2d\u95f4\u8ba1\u7b97\u96be\u4ee5\u901a\u8fc7\u76f8\u5173\u6027\u63a2\u6d4b\u4e4b\u5916\u7684\u65b9\u6cd5\u8fdb\u884c\u8bc4\u4f30\u3002\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u5206\u6790\u6f5c\u5728\u63a8\u7406\u6b65\u9aa4\u7684\u56e0\u679c\u4f5c\u7528\u548c\u529f\u80fd\u3002", "method": "\u5c06\u6f5c\u5728\u601d\u7ef4\u94fe\u5efa\u6a21\u4e3a\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u4e2d\u7684\u53d8\u91cf\uff0c\u901a\u8fc7\u9010\u6b65do\u5e72\u9884\u5206\u6790\u5176\u6548\u5e94\u3002\u7814\u7a76Coconut\u548cCODI\u4e24\u79cd\u4ee3\u8868\u6027\u8303\u5f0f\u5728\u6570\u5b66\u548c\u4e00\u822c\u63a8\u7406\u4efb\u52a1\u4e0a\uff0c\u63a2\u8ba8\u6b65\u9aa4\u7684\u56e0\u679c\u5fc5\u8981\u6027\u3001\u5f71\u54cd\u4f20\u64ad\u7ed3\u6784\u4ee5\u53ca\u4e0e\u663e\u5f0f\u601d\u7ef4\u94fe\u7684\u6bd4\u8f83\u3002", "result": "\u53d1\u73b0\u6f5c\u5728\u6b65\u9aa4\u9884\u7b97\u4e0d\u50cf\u540c\u8d28\u989d\u5916\u6df1\u5ea6\uff0c\u800c\u66f4\u50cf\u5177\u6709\u975e\u5c40\u90e8\u8def\u7531\u7684\u5206\u9636\u6bb5\u529f\u80fd\uff1b\u65e9\u671f\u8f93\u51fa\u504f\u89c1\u4e0e\u665a\u671f\u8868\u793a\u627f\u8bfa\u4e4b\u95f4\u5b58\u5728\u6301\u7eed\u5dee\u8ddd\uff1b\u4e2d\u95f4\u8f68\u8ff9\u4fdd\u7559\u7ade\u4e89\u7b54\u6848\u6a21\u5f0f\u3002", "conclusion": "\u7ed3\u679c\u652f\u6301\u6a21\u5f0f\u6761\u4ef6\u548c\u7a33\u5b9a\u6027\u611f\u77e5\u5206\u6790\u4f5c\u4e3a\u89e3\u91ca\u548c\u6539\u8fdb\u6f5c\u5728\u63a8\u7406\u7cfb\u7edf\u7684\u66f4\u53ef\u9760\u5de5\u5177\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u8bad\u7ec3/\u89e3\u7801\u76ee\u6807\u3002"}}
{"id": "2602.08796", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08796", "abs": "https://arxiv.org/abs/2602.08796", "authors": ["Kevin Fan", "Jacquelyn A. Bialo", "Hongli Li"], "title": "The Use of AI Tools to Develop and Validate Q-Matrices", "comment": "An earlier version of this study was presented at the Psychometric Society Meeting held in July 2025 in Minneapolis, USA", "summary": "Constructing a Q-matrix is a critical but labor-intensive step in cognitive diagnostic modeling (CDM). This study investigates whether AI tools (i.e., general language models) can support Q-matrix development by comparing AI-generated Q-matrices with a validated Q-matrix from Li and Suen (2013) for a reading comprehension test. In May 2025, multiple AI models were provided with the same training materials as human experts. Agreement among AI-generated Q-matrices, the validated Q-matrix, and human raters' Q-matrices was assessed using Cohen's kappa. Results showed substantial variation across AI models, with Google Gemini 2.5 Pro achieving the highest agreement (Kappa = 0.63) with the validated Q-matrix, exceeding that of all human experts. A follow-up analysis in January 2026 using newer AI versions, however, revealed lower agreement with the validated Q-matrix. Implications and directions for future research are discussed.", "AI": {"tldr": "AI\u5de5\u5177\uff08\u901a\u7528\u8bed\u8a00\u6a21\u578b\uff09\u5728\u8ba4\u77e5\u8bca\u65ad\u5efa\u6a21\u4e2d\u6784\u5efaQ\u77e9\u9635\u7684\u53ef\u884c\u6027\u7814\u7a76\uff0c\u53d1\u73b0AI\u751f\u6210\u7684Q\u77e9\u9635\u4e0e\u9a8c\u8bc1\u77e9\u9635\u4e00\u81f4\u6027\u5b58\u5728\u6a21\u578b\u95f4\u5dee\u5f02\uff0cGemini 2.5 Pro\u8868\u73b0\u6700\u4f73\u751a\u81f3\u8d85\u8fc7\u4eba\u7c7b\u4e13\u5bb6\uff0c\u4f46\u65b0\u7248AI\u6a21\u578b\u8868\u73b0\u4e0b\u964d\u3002", "motivation": "Q\u77e9\u9635\u6784\u5efa\u662f\u8ba4\u77e5\u8bca\u65ad\u5efa\u6a21\u7684\u5173\u952e\u4f46\u52b3\u52a8\u5bc6\u96c6\u578b\u6b65\u9aa4\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22AI\u5de5\u5177\uff08\u901a\u7528\u8bed\u8a00\u6a21\u578b\uff09\u662f\u5426\u80fd\u652f\u6301Q\u77e9\u9635\u5f00\u53d1\uff0c\u51cf\u8f7b\u4eba\u5de5\u8d1f\u62c5\u3002", "method": "\u4f7f\u7528\u591a\u4e2aAI\u6a21\u578b\uff08\u5305\u62ecGoogle Gemini 2.5 Pro\u7b49\uff09\u57fa\u4e8e\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u540c\u7684\u8bad\u7ec3\u6750\u6599\u751f\u6210Q\u77e9\u9635\uff0c\u4e0eLi\u548cSuen\uff082013\uff09\u9a8c\u8bc1\u7684\u9605\u8bfb\u6d4b\u8bd5Q\u77e9\u9635\u6bd4\u8f83\uff0c\u4f7f\u7528Cohen's kappa\u8bc4\u4f30\u4e00\u81f4\u6027\u30022026\u5e741\u6708\u4f7f\u7528\u65b0\u7248AI\u6a21\u578b\u8fdb\u884c\u540e\u7eed\u5206\u6790\u3002", "result": "AI\u6a21\u578b\u95f4\u4e00\u81f4\u6027\u5dee\u5f02\u663e\u8457\uff0cGoogle Gemini 2.5 Pro\u4e0e\u9a8c\u8bc1Q\u77e9\u9635\u4e00\u81f4\u6027\u6700\u9ad8\uff08Kappa=0.63\uff09\uff0c\u8d85\u8fc7\u6240\u6709\u4eba\u7c7b\u4e13\u5bb6\u3002\u4f462026\u5e74\u4f7f\u7528\u65b0\u7248AI\u6a21\u578b\u7684\u5206\u6790\u663e\u793a\u4e0e\u9a8c\u8bc1Q\u77e9\u9635\u7684\u4e00\u81f4\u6027\u964d\u4f4e\u3002", "conclusion": "AI\u5de5\u5177\u5728Q\u77e9\u9635\u6784\u5efa\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u7279\u5b9a\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u4eba\u7c7b\u4e13\u5bb6\uff0c\u4f46AI\u6a21\u578b\u7248\u672c\u66f4\u65b0\u53ef\u80fd\u5f71\u54cd\u6027\u80fd\u7a33\u5b9a\u6027\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76AI\u5728\u8ba4\u77e5\u8bca\u65ad\u5efa\u6a21\u4e2d\u7684\u53ef\u9760\u5e94\u7528\u3002"}}
{"id": "2602.08804", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08804", "abs": "https://arxiv.org/abs/2602.08804", "authors": ["Liming Zhou", "Ailing Liu", "Hongwei Liu", "Min He", "Heng Zhang"], "title": "Root Cause Analysis Method Based on Large Language Models with Residual Connection Structures", "comment": null, "summary": "Root cause localization remain challenging in complex and large-scale microservice architectures. The complex fault propagation among microservices and the high dimensionality of telemetry data, including metrics, logs, and traces, limit the effectiveness of existing root cause analysis (RCA) methods. In this paper, a residual-connection-based RCA method using large language model (LLM), named RC-LLM, is proposed. A residual-like hierarchical fusion structure is designed to integrate multi-source telemetry data, while the contextual reasoning capability of large language models is leveraged to model temporal and cross-microservice causal dependencies. Experimental results on CCF-AIOps microservice datasets demonstrate that RC-LLM achieves strong accuracy and efficiency in root cause analysis.", "AI": {"tldr": "\u63d0\u51faRC-LLM\u65b9\u6cd5\uff0c\u5229\u7528\u6b8b\u5dee\u8fde\u63a5\u7ed3\u6784\u548c\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\u7684\u6839\u56e0\u5b9a\u4f4d\uff0c\u6709\u6548\u5904\u7406\u591a\u6e90\u9065\u6d4b\u6570\u636e\u5e76\u5efa\u6a21\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "\u5728\u590d\u6742\u5927\u89c4\u6a21\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\uff0c\u6839\u56e0\u5b9a\u4f4d\u9762\u4e34\u6311\u6218\uff1a\u5fae\u670d\u52a1\u95f4\u590d\u6742\u7684\u6545\u969c\u4f20\u64ad\u4ee5\u53ca\u9065\u6d4b\u6570\u636e\uff08\u6307\u6807\u3001\u65e5\u5fd7\u3001\u8ffd\u8e2a\uff09\u7684\u9ad8\u7ef4\u6027\u9650\u5236\u4e86\u73b0\u6709RCA\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faRC-LLM\u65b9\u6cd5\uff1a\u8bbe\u8ba1\u6b8b\u5dee\u5f0f\u5206\u5c42\u878d\u5408\u7ed3\u6784\u6574\u5408\u591a\u6e90\u9065\u6d4b\u6570\u636e\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u5efa\u6a21\u65f6\u95f4\u548c\u8de8\u5fae\u670d\u52a1\u7684\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728CCF-AIOps\u5fae\u670d\u52a1\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRC-LLM\u5728\u6839\u56e0\u5206\u6790\u4e2d\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "RC-LLM\u901a\u8fc7\u7ed3\u5408\u6b8b\u5dee\u8fde\u63a5\u7ed3\u6784\u548cLLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\u6839\u56e0\u5b9a\u4f4d\u7684\u6311\u6218\uff0c\u4e3a\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u6545\u969c\u8bca\u65ad\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2602.08815", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08815", "abs": "https://arxiv.org/abs/2602.08815", "authors": ["Yanglei Gan", "Peng He", "Yuxiang Cai", "Run Lin", "Guanyu Zhou", "Qiao Liu"], "title": "Negative-Aware Diffusion Process for Temporal Knowledge Graph Extrapolation", "comment": null, "summary": "Temporal Knowledge Graph (TKG) reasoning seeks to predict future missing facts from historical evidence. While diffusion models (DM) have recently gained attention for their ability to capture complex predictive distributions, two gaps remain: (i) the generative path is conditioned only on positive evidence, overlooking informative negative context, and (ii) training objectives are dominated by cross-entropy ranking, which improves candidate ordering but provides little supervision over the calibration of the denoised embedding. To bridge this gap, we introduce Negative-Aware Diffusion model for TKG Extrapolation (NADEx). Specifically, NADEx encodes subject-centric histories of entities, relations and temporal intervals into sequential embeddings. NADEx perturbs the query object in the forward process and reconstructs it in reverse with a Transformer denoiser conditioned on the temporal-relational context. We further derive a cosine-alignment regularizer derived from batch-wise negative prototypes, which tightens the decision boundary against implausible candidates. Comprehensive experiments on four public TKG benchmarks demonstrate that NADEx delivers state-of-the-art performance.", "AI": {"tldr": "NADEx\u662f\u4e00\u4e2a\u7528\u4e8e\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u7684\u8d1f\u611f\u77e5\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u8d1f\u6837\u672c\u4fe1\u606f\u548c\u4f59\u5f26\u5bf9\u9f50\u6b63\u5219\u5316\uff0c\u63d0\u5347\u672a\u6765\u4e8b\u5b9e\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6821\u51c6\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1) \u751f\u6210\u8def\u5f84\u4ec5\u4f9d\u8d56\u6b63\u6837\u672c\u8bc1\u636e\uff0c\u5ffd\u7565\u4e86\u4fe1\u606f\u4e30\u5bcc\u7684\u8d1f\u6837\u672c\u4e0a\u4e0b\u6587\uff1b2) \u8bad\u7ec3\u76ee\u6807\u4e3b\u8981\u57fa\u4e8e\u4ea4\u53c9\u71b5\u6392\u5e8f\uff0c\u867d\u7136\u6539\u5584\u4e86\u5019\u9009\u6392\u5e8f\u4f46\u7f3a\u4e4f\u5bf9\u53bb\u566a\u5d4c\u5165\u6821\u51c6\u7684\u76d1\u7763\u3002", "method": "NADEx\u7f16\u7801\u5b9e\u4f53\u3001\u5173\u7cfb\u548c\u65f6\u5e8f\u95f4\u9694\u7684\u4e3b\u4f53\u4e2d\u5fc3\u5386\u53f2\u4e3a\u5e8f\u5217\u5d4c\u5165\uff0c\u5728\u524d\u5411\u8fc7\u7a0b\u4e2d\u6270\u52a8\u67e5\u8be2\u5bf9\u8c61\uff0c\u5728\u53cd\u5411\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u57fa\u4e8e\u65f6\u5e8f\u5173\u7cfb\u4e0a\u4e0b\u6587\u7684Transformer\u53bb\u566a\u5668\u91cd\u5efa\u3002\u6b64\u5916\uff0c\u4ece\u6279\u91cf\u8d1f\u6837\u672c\u539f\u578b\u63a8\u5bfc\u51fa\u4f59\u5f26\u5bf9\u9f50\u6b63\u5219\u5316\u5668\uff0c\u6536\u7d27\u51b3\u7b56\u8fb9\u754c\u4ee5\u6392\u9664\u4e0d\u5408\u7406\u5019\u9009\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5f00\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cNADEx\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "NADEx\u901a\u8fc7\u6574\u5408\u8d1f\u6837\u672c\u4fe1\u606f\u548c\u5f15\u5165\u6821\u51c6\u76d1\u7763\uff0c\u6709\u6548\u63d0\u5347\u4e86\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u5728\u8be5\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2602.08848", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08848", "abs": "https://arxiv.org/abs/2602.08848", "authors": ["Quentin Cohen-Solal", "Alexandre Niveau", "Maroua Bouzid"], "title": "Deciding the Satisfiability of Combined Qualitative Constraint Networks", "comment": null, "summary": "Among the various forms of reasoning studied in the context of artificial intelligence, qualitative reasoning makes it possible to infer new knowledge in the context of imprecise, incomplete information without numerical values. In this paper, we propose a formal framework unifying several forms of extensions and combinations of qualitative formalisms, including multi-scale reasoning, temporal sequences, and loose integrations. This framework makes it possible to reason in the context of each of these combinations and extensions, but also to study in a unified way the satisfiability decision and its complexity. In particular, we establish two complementary theorems guaranteeing that the satisfiability decision is polynomial, and we use them to recover the known results of the size-topology combination. We also generalize the main definition of qualitative formalism to include qualitative formalisms excluded from the definitions of the literature, important in the context of combinations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u6574\u5408\u591a\u79cd\u5b9a\u6027\u63a8\u7406\u7684\u6269\u5c55\u4e0e\u7ec4\u5408\u5f62\u5f0f\uff0c\u5305\u62ec\u591a\u5c3a\u5ea6\u63a8\u7406\u3001\u65f6\u95f4\u5e8f\u5217\u548c\u677e\u6563\u96c6\u6210\uff0c\u5e76\u7814\u7a76\u5176\u53ef\u6ee1\u8db3\u6027\u51b3\u7b56\u53ca\u590d\u6742\u6027\u3002", "motivation": "\u5b9a\u6027\u63a8\u7406\u80fd\u5728\u4e0d\u7cbe\u786e\u3001\u4e0d\u5b8c\u6574\u4e14\u65e0\u6570\u503c\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u63a8\u65ad\u65b0\u77e5\u8bc6\uff0c\u4f46\u73b0\u6709\u6587\u732e\u4e2d\u7684\u5b9a\u4e49\u6392\u9664\u4e86\u67d0\u4e9b\u5728\u7ec4\u5408\u573a\u666f\u4e2d\u91cd\u8981\u7684\u5b9a\u6027\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u9700\u8981\u7edf\u4e00\u6846\u67b6\u6765\u6574\u5408\u591a\u79cd\u6269\u5c55\u4e0e\u7ec4\u5408\u5f62\u5f0f\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u7edf\u4e00\u591a\u79cd\u5b9a\u6027\u5f62\u5f0f\u5316\u7684\u6269\u5c55\u4e0e\u7ec4\u5408\uff0c\u5305\u62ec\u591a\u5c3a\u5ea6\u63a8\u7406\u3001\u65f6\u95f4\u5e8f\u5217\u548c\u677e\u6563\u96c6\u6210\u3002\u8be5\u6846\u67b6\u652f\u6301\u5728\u8fd9\u4e9b\u7ec4\u5408\u548c\u6269\u5c55\u4e2d\u8fdb\u884c\u63a8\u7406\uff0c\u5e76\u4ee5\u7edf\u4e00\u65b9\u5f0f\u7814\u7a76\u53ef\u6ee1\u8db3\u6027\u51b3\u7b56\u53ca\u5176\u590d\u6742\u6027\u3002", "result": "\u5efa\u7acb\u4e86\u4e24\u4e2a\u4e92\u8865\u5b9a\u7406\uff0c\u4fdd\u8bc1\u53ef\u6ee1\u8db3\u6027\u51b3\u7b56\u662f\u591a\u9879\u5f0f\u65f6\u95f4\u7684\uff0c\u5e76\u7528\u5b83\u4eec\u6062\u590d\u4e86\u5df2\u77e5\u7684\u5c3a\u5bf8-\u62d3\u6251\u7ec4\u5408\u7ed3\u679c\u3002\u8fd8\u5c06\u5b9a\u6027\u5f62\u5f0f\u5316\u7684\u4e3b\u8981\u5b9a\u4e49\u63a8\u5e7f\u5230\u5305\u542b\u6587\u732e\u5b9a\u4e49\u4e2d\u6392\u9664\u4f46\u5728\u7ec4\u5408\u573a\u666f\u4e2d\u91cd\u8981\u7684\u5b9a\u6027\u5f62\u5f0f\u5316\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\u6210\u529f\u6574\u5408\u4e86\u591a\u79cd\u5b9a\u6027\u63a8\u7406\u7684\u6269\u5c55\u4e0e\u7ec4\u5408\u5f62\u5f0f\uff0c\u4e0d\u4ec5\u652f\u6301\u5728\u8fd9\u4e9b\u7ec4\u5408\u4e2d\u8fdb\u884c\u63a8\u7406\uff0c\u8fd8\u63d0\u4f9b\u4e86\u7814\u7a76\u53ef\u6ee1\u8db3\u6027\u51b3\u7b56\u590d\u6742\u6027\u7684\u7edf\u4e00\u65b9\u6cd5\uff0c\u6269\u5c55\u4e86\u5b9a\u6027\u5f62\u5f0f\u5316\u7684\u5b9a\u4e49\u8303\u56f4\u3002"}}
{"id": "2602.08889", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08889", "abs": "https://arxiv.org/abs/2602.08889", "authors": ["Tobias Lorenz", "Mario Fritz"], "title": "Scalable Delphi: Large Language Models for Structured Risk Estimation", "comment": null, "summary": "Quantitative risk assessment in high-stakes domains relies on structured expert elicitation to estimate unobservable properties. The gold standard - the Delphi method - produces calibrated, auditable judgments but requires months of coordination and specialist time, placing rigorous risk assessment out of reach for most applications. We investigate whether Large Language Models (LLMs) can serve as scalable proxies for structured expert elicitation. We propose Scalable Delphi, adapting the classical protocol for LLMs with diverse expert personas, iterative refinement, and rationale sharing. Because target quantities are typically unobservable, we develop an evaluation framework based on necessary conditions: calibration against verifiable proxies, sensitivity to evidence, and alignment with human expert judgment. We evaluate in the domain of AI-augmented cybersecurity risk, using three capability benchmarks and independent human elicitation studies. LLM panels achieve strong correlations with benchmark ground truth (Pearson r=0.87-0.95), improve systematically as evidence is added, and align with human expert panels - in one comparison, closer to a human panel than the two human panels are to each other. This demonstrates that LLM-based elicitation can extend structured expert judgment to settings where traditional methods are infeasible, reducing elicitation time from months to minutes.", "AI": {"tldr": "LLM-based Scalable Delphi\u65b9\u6cd5\u53ef\u5c06\u4f20\u7edf\u4e13\u5bb6\u5fb7\u5c14\u83f2\u6cd5\u7684\u65f6\u95f4\u4ece\u6570\u6708\u7f29\u77ed\u5230\u6570\u5206\u949f\uff0c\u5728AI\u589e\u5f3a\u7f51\u7edc\u5b89\u5168\u98ce\u9669\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u9ad8\u5ea6\u4e00\u81f4\u7684\u7ed3\u679c\u3002", "motivation": "\u4f20\u7edf\u5fb7\u5c14\u83f2\u6cd5\u4f5c\u4e3a\u4e13\u5bb6\u8bc4\u4f30\u7684\u91d1\u6807\u51c6\u9700\u8981\u6570\u6708\u534f\u8c03\u548c\u4e13\u5bb6\u65f6\u95f4\uff0c\u4f7f\u4e25\u8c28\u7684\u98ce\u9669\u8bc4\u4f30\u96be\u4ee5\u666e\u53ca\u3002\u9700\u8981\u63a2\u7d22LLM\u80fd\u5426\u4f5c\u4e3a\u53ef\u6269\u5c55\u7684\u4e13\u5bb6\u8bc4\u4f30\u4ee3\u7406\u3002", "method": "\u63d0\u51faScalable Delphi\u65b9\u6cd5\uff0c\u5c06\u7ecf\u5178\u5fb7\u5c14\u83f2\u534f\u8bae\u9002\u914d\u5230LLM\uff1a\u4f7f\u7528\u591a\u6837\u5316\u4e13\u5bb6\u89d2\u8272\u3001\u8fed\u4ee3\u7cbe\u70bc\u548c\u7406\u7531\u5171\u4eab\u3002\u5f00\u53d1\u57fa\u4e8e\u5fc5\u8981\u6761\u4ef6\u7684\u8bc4\u4f30\u6846\u67b6\uff1a\u6821\u51c6\u53ef\u9a8c\u8bc1\u4ee3\u7406\u3001\u5bf9\u8bc1\u636e\u7684\u654f\u611f\u6027\u3001\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5224\u65ad\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728AI\u589e\u5f3a\u7f51\u7edc\u5b89\u5168\u98ce\u9669\u8bc4\u4f30\u4e2d\uff0cLLM\u4e13\u5bb6\u5c0f\u7ec4\u4e0e\u57fa\u51c6\u771f\u5b9e\u503c\u5f3a\u76f8\u5173\uff08Pearson r=0.87-0.95\uff09\uff0c\u968f\u7740\u8bc1\u636e\u6dfb\u52a0\u7cfb\u7edf\u6027\u6539\u8fdb\uff0c\u5e76\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5c0f\u7ec4\u4e00\u81f4\u2014\u2014\u5728\u67d0\u4e9b\u6bd4\u8f83\u4e2d\uff0cLLM\u5c0f\u7ec4\u4e0e\u4eba\u7c7b\u5c0f\u7ec4\u7684\u63a5\u8fd1\u5ea6\u751a\u81f3\u8d85\u8fc7\u4e24\u4e2a\u4eba\u7c7b\u5c0f\u7ec4\u4e4b\u95f4\u7684\u63a5\u8fd1\u5ea6\u3002", "conclusion": "LLM\u4e3a\u57fa\u7840\u7684\u4e13\u5bb6\u8bc4\u4f30\u53ef\u4ee5\u5c06\u7ed3\u6784\u5316\u4e13\u5bb6\u5224\u65ad\u6269\u5c55\u5230\u4f20\u7edf\u65b9\u6cd5\u4e0d\u53ef\u884c\u7684\u573a\u666f\uff0c\u5c06\u8bc4\u4f30\u65f6\u95f4\u4ece\u6570\u6708\u7f29\u77ed\u5230\u6570\u5206\u949f\uff0c\u4e3a\u9ad8\u98ce\u9669\u9886\u57df\u7684\u91cf\u5316\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08905", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08905", "abs": "https://arxiv.org/abs/2602.08905", "authors": ["Jiawei Liu", "Xiting Wang", "Yuanyuan Zhong", "Defu Lian", "Yu Yang"], "title": "Efficient and Stable Reinforcement Learning for Diffusion Language Models", "comment": "13 pages, 3 figures", "summary": "Reinforcement Learning (RL) is crucial for unlocking the complex reasoning capabilities of Diffusion-based Large Language Models (dLLMs). However, applying RL to dLLMs faces unique challenges in efficiency and stability. To address these challenges, we propose Spatio-Temporal Pruning (STP), a framework designed to simultaneously improve the efficiency and stability of RL for dLLMs. STP compresses the redundancy in the generative process through: (1) \\textit{spatial pruning}, which constrains the exploration space using static priors; and (2) \\textit{temporal pruning}, which bypasses redundant late-stage refinement steps. Our theoretical analysis demonstrates that STP strictly reduces the variance of the log-likelihood estimation, thereby ensuring more stable policy updates. Extensive experiments demonstrate that STP surpasses state-of-the-art baselines in both efficiency and accuracy. Our code is available at https://github.com/Lolo1222/STP.", "AI": {"tldr": "STP\u6846\u67b6\u901a\u8fc7\u65f6\u7a7a\u526a\u679d\u63d0\u9ad8\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u7387\u548c\u7a33\u5b9a\u6027", "motivation": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u6548\u7387\u548c\u7a33\u5b9a\u6027\u6311\u6218\uff0c\u9700\u8981\u4e13\u95e8\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51fa\u65f6\u7a7a\u526a\u679d\u6846\u67b6\uff1a\u7a7a\u95f4\u526a\u679d\u5229\u7528\u9759\u6001\u5148\u9a8c\u7ea6\u675f\u63a2\u7d22\u7a7a\u95f4\uff0c\u65f6\u95f4\u526a\u679d\u7ed5\u8fc7\u5197\u4f59\u540e\u671f\u7ec6\u5316\u6b65\u9aa4", "result": "\u7406\u8bba\u5206\u6790\u663e\u793aSTP\u4e25\u683c\u964d\u4f4e\u5bf9\u6570\u4f3c\u7136\u4f30\u8ba1\u65b9\u5dee\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u4e0a\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf", "conclusion": "STP\u6709\u6548\u89e3\u51b3\u4e86dLLMs\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u7387\u548c\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4e3a\u590d\u6742\u63a8\u7406\u80fd\u529b\u5f00\u53d1\u63d0\u4f9b\u652f\u6301"}}
{"id": "2602.08939", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08939", "abs": "https://arxiv.org/abs/2602.08939", "authors": ["Longling Geng", "Andy Ouyang", "Theodore Wu", "Daphne Barretto", "Matthew John Hayes", "Rachael Cooper", "Yuqiao Zeng", "Sameer Vijay", "Gia Ancone", "Ankit Rai", "Matthew Wolfman", "Patrick Flanagan", "Edward Y. Chang"], "title": "CausalT5K: Diagnosing and Informing Refusal for Trustworthy Causal Reasoning of Skepticism, Sycophancy, Detection-Correction, and Rung Collapse", "comment": "17 pages, 20 tables, figures", "summary": "LLM failures in causal reasoning, including sycophancy, rung collapse, and miscalibrated refusal, are well-documented, yet progress on remediation is slow because no benchmark enables systematic diagnosis. We introduce CausalT5K, a diagnostic benchmark of over 5,000 cases across 10 domains that tests three critical capabilities: (1) detecting rung collapse, where models answer interventional queries with associational evidence; (2) resisting sycophantic drift under adversarial pressure; and (3) generating Wise Refusals that specify missing information when evidence is underdetermined. Unlike synthetic benchmarks, CausalT5K embeds causal traps in realistic narratives and decomposes performance into Utility (sensitivity) and Safety (specificity), revealing failure modes invisible to aggregate accuracy. Developed through a rigorous human-machine collaborative pipeline involving 40 domain experts, iterative cross-validation cycles, and composite verification via rule-based, LLM, and human scoring, CausalT5K implements Pearl's Ladder of Causation as research infrastructure. Preliminary experiments reveal a Four-Quadrant Control Landscape where static audit policies universally fail, a finding that demonstrates CausalT5K's value for advancing trustworthy reasoning systems. Repository: https://github.com/genglongling/CausalT5kBench", "AI": {"tldr": "CausalT5K\u662f\u4e00\u4e2a\u5305\u542b5000\u591a\u4e2a\u6848\u4f8b\u7684\u8bca\u65ad\u57fa\u51c6\uff0c\u7528\u4e8e\u7cfb\u7edf\u68c0\u6d4bLLM\u5728\u56e0\u679c\u63a8\u7406\u4e2d\u7684\u5931\u8d25\u6a21\u5f0f\uff08\u5982\u9636\u68af\u574d\u584c\u3001\u8c04\u5a9a\u6f02\u79fb\u3001\u9519\u8bef\u62d2\u7edd\uff09\uff0c\u901a\u8fc7\u73b0\u5b9e\u53d9\u4e8b\u4e2d\u7684\u56e0\u679c\u9677\u9631\u6765\u8bc4\u4f30\u6a21\u578b\u7684\u5b9e\u7528\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "LLM\u5728\u56e0\u679c\u63a8\u7406\u4e2d\u5b58\u5728\u591a\u79cd\u5931\u8d25\u6a21\u5f0f\uff08\u8c04\u5a9a\u3001\u9636\u68af\u574d\u584c\u3001\u9519\u8bef\u6821\u51c6\u7684\u62d2\u7edd\uff09\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u7cfb\u7edf\u6027\u8bca\u65ad\u57fa\u51c6\uff0c\u4fee\u590d\u8fdb\u5c55\u7f13\u6162\u3002\u9700\u8981\u80fd\u591f\u63ed\u793a\u8fd9\u4e9b\u5931\u8d25\u6a21\u5f0f\u7684\u8bca\u65ad\u5de5\u5177\u6765\u63a8\u8fdb\u53ef\u4fe1\u63a8\u7406\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "method": "\u6784\u5efa\u5305\u542b5000\u591a\u4e2a\u6848\u4f8b\u7684CausalT5K\u57fa\u51c6\uff0c\u6db5\u76d610\u4e2a\u9886\u57df\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u6d41\u7a0b\uff0840\u540d\u9886\u57df\u4e13\u5bb6\u53c2\u4e0e\u3001\u8fed\u4ee3\u4ea4\u53c9\u9a8c\u8bc1\u5468\u671f\uff09\u5f00\u53d1\uff0c\u4f7f\u7528\u57fa\u4e8e\u89c4\u5219\u3001LLM\u548c\u4eba\u5de5\u8bc4\u5206\u7684\u590d\u5408\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u5c06Pearl\u7684\u56e0\u679c\u9636\u68af\u7406\u8bba\u4f5c\u4e3a\u7814\u7a76\u57fa\u7840\u8bbe\u65bd\u5b9e\u73b0\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u63ed\u793a\u4e86\"\u56db\u8c61\u9650\u63a7\u5236\u666f\u89c2\"\uff0c\u8868\u660e\u9759\u6001\u5ba1\u8ba1\u7b56\u7565\u666e\u904d\u5931\u8d25\u3002\u57fa\u51c6\u80fd\u591f\u5c06\u6027\u80fd\u5206\u89e3\u4e3a\u5b9e\u7528\u6027\uff08\u654f\u611f\u6027\uff09\u548c\u5b89\u5168\u6027\uff08\u7279\u5f02\u6027\uff09\uff0c\u63ed\u793a\u805a\u5408\u51c6\u786e\u7387\u65e0\u6cd5\u770b\u5230\u7684\u5931\u8d25\u6a21\u5f0f\u3002", "conclusion": "CausalT5K\u4f5c\u4e3a\u7814\u7a76\u57fa\u7840\u8bbe\u65bd\uff0c\u80fd\u591f\u7cfb\u7edf\u8bca\u65adLLM\u56e0\u679c\u63a8\u7406\u5931\u8d25\u6a21\u5f0f\uff0c\u4e3a\u63a8\u8fdb\u53ef\u4fe1\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u5de5\u5177\uff0c\u7279\u522b\u662f\u901a\u8fc7\u63ed\u793a\u9759\u6001\u5ba1\u8ba1\u7b56\u7565\u7684\u5c40\u9650\u6027\u6765\u6307\u5bfc\u66f4\u597d\u7684\u6a21\u578b\u8bc4\u4f30\u548c\u5f00\u53d1\u3002"}}
{"id": "2602.08948", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08948", "abs": "https://arxiv.org/abs/2602.08948", "authors": ["Chen Jin", "Ryutaro Tanno", "Tom Diethe", "Philip Teare"], "title": "CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute", "comment": null, "summary": "Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that achieves competitive accuracy using a fraction of the tokens via a lightweight 211k-parameter Conv1D controller atop a frozen LLM. The controller consumes full-trace confidence to decide whether to halt, re-examine, or try a different approach, enabling targeted self-correction with an average of 2.7 refinement steps per problem and roughly 190-fold token reduction relative to 512-sample baselines. Across diverse reasoning benchmarks and three open-source models, the controller achieves 92.6 percent precision when it confidently halts, indicating that confidence dynamics reliably signal correctness without ground-truth verification. We extend this to CoRefine-Tree, a hybrid sequential-parallel variant that adaptively balances exploration and exploitation, with easy serving integration and verifier compatibility. By treating confidence as a control signal rather than a correctness guarantee, CoRefine provides a modular primitive for scalable reasoning and agentic settings with imperfect verifiers.", "AI": {"tldr": "CoRefine\u662f\u4e00\u79cd\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u81ea\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u63a7\u5236\u5668\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\uff0c\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u4f9d\u8d56\u5e76\u884c\u89e3\u7801\uff08\u5982512\u4e2a\u6837\u672c\uff09\u6765\u63d0\u9ad8\u63a8\u7406\u51c6\u786e\u6027\uff0c\u4f46\u8fd9\u4f1a\u5e26\u6765\u5de8\u5927\u7684\u8ba1\u7b97\u5f00\u9500\u3002\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b", "method": "\u5f15\u5165CoRefine\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684211k\u53c2\u6570Conv1D\u63a7\u5236\u5668\uff0c\u57fa\u4e8e\u5b8c\u6574\u8f68\u8ff9\u7f6e\u4fe1\u5ea6\u51b3\u5b9a\u505c\u6b62\u3001\u91cd\u65b0\u68c0\u67e5\u6216\u5c1d\u8bd5\u4e0d\u540c\u65b9\u6cd5\uff0c\u5b9e\u73b0\u6709\u9488\u5bf9\u6027\u7684\u81ea\u6211\u4fee\u6b63", "result": "\u5e73\u5747\u6bcf\u4e2a\u95ee\u9898\u53ea\u97002.7\u4e2a\u4f18\u5316\u6b65\u9aa4\uff0c\u76f8\u5bf9\u4e8e512\u6837\u672c\u57fa\u7ebf\u51cf\u5c11\u7ea6190\u500dtoken\u4f7f\u7528\uff1b\u63a7\u5236\u5668\u5728\u81ea\u4fe1\u505c\u6b62\u65f6\u8fbe\u523092.6%\u7684\u7cbe\u786e\u5ea6\uff1bCoRefine-Tree\u53d8\u4f53\u80fd\u81ea\u9002\u5e94\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528", "conclusion": "\u901a\u8fc7\u5c06\u7f6e\u4fe1\u5ea6\u89c6\u4e3a\u63a7\u5236\u4fe1\u53f7\u800c\u975e\u6b63\u786e\u6027\u4fdd\u8bc1\uff0cCoRefine\u4e3a\u53ef\u6269\u5c55\u63a8\u7406\u548c\u5177\u6709\u4e0d\u5b8c\u7f8e\u9a8c\u8bc1\u5668\u7684\u667a\u80fd\u4f53\u8bbe\u7f6e\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u539f\u8bed"}}
{"id": "2602.08949", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08949", "abs": "https://arxiv.org/abs/2602.08949", "authors": ["Mohammad Morsali", "Siavash H. Khajavi"], "title": "Digital Twin and Agentic AI for Wild Fire Disaster Management: Intelligent Virtual Situation Room", "comment": null, "summary": "According to the United Nations, wildfire frequency and intensity are projected to increase by approximately 14% by 2030 and 30% by 2050 due to global warming, posing critical threats to life, infrastructure, and ecosystems. Conventional disaster management frameworks rely on static simulations and passive data acquisition, hindering their ability to adapt to arbitrarily evolving wildfire episodes in real-time. To address these limitations, we introduce the Intelligent Virtual Situation Room (IVSR), a bidirectional Digital Twin (DT) platform augmented by autonomous AI agents. The IVSR continuously ingests multisource sensor imagery, weather data, and 3D forest models to create a live virtual replica of the fire environment. A similarity engine powered by AI aligns emerging conditions with a precomputed Disaster Simulation Library, retrieving and calibrating intervention tactics under the watchful eyes of experts. Authorized action-ranging from UAV redeployment to crew reallocation-is cycled back through standardized procedures to the physical layer, completing the loop between response and analysis. We validate IVSR through detailed case-study simulations provided by an industrial partner, demonstrating capabilities in localized incident detection, privacy-preserving playback, collider-based fire-spread projection, and site-specific ML retraining. Our results indicate marked reductions in detection-to-intervention latency and more effective resource coordination versus traditional systems. By uniting real-time bidirectional DTs with agentic AI, IVSR offers a scalable, semi-automated decision-support paradigm for proactive, adaptive wildfire disaster management.", "AI": {"tldr": "IVSR\u662f\u4e00\u4e2a\u7ed3\u5408\u6570\u5b57\u5b6a\u751f\u548c\u81ea\u4e3bAI\u4ee3\u7406\u7684\u53cc\u5411\u5e73\u53f0\uff0c\u7528\u4e8e\u5b9e\u65f6\u3001\u81ea\u9002\u5e94\u7684\u91ce\u706b\u707e\u5bb3\u7ba1\u7406\uff0c\u663e\u8457\u964d\u4f4e\u68c0\u6d4b\u5230\u5e72\u9884\u7684\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u8d44\u6e90\u534f\u8c03\u6548\u7387\u3002", "motivation": "\u8054\u5408\u56fd\u9884\u6d4b\u52302030\u5e74\u548c2050\u5e74\u91ce\u706b\u9891\u7387\u548c\u5f3a\u5ea6\u5c06\u5206\u522b\u589e\u52a014%\u548c30%\uff0c\u4f20\u7edf\u707e\u5bb3\u7ba1\u7406\u6846\u67b6\u4f9d\u8d56\u9759\u6001\u6a21\u62df\u548c\u88ab\u52a8\u6570\u636e\u91c7\u96c6\uff0c\u65e0\u6cd5\u5b9e\u65f6\u9002\u5e94\u4e0d\u65ad\u6f14\u53d8\u7684\u91ce\u706b\u60c5\u51b5\u3002", "method": "\u5f00\u53d1\u667a\u80fd\u865a\u62df\u6001\u52bf\u5ba4(IVSR)\uff0c\u8fd9\u662f\u4e00\u4e2a\u7531\u81ea\u4e3bAI\u4ee3\u7406\u589e\u5f3a\u7684\u53cc\u5411\u6570\u5b57\u5b6a\u751f\u5e73\u53f0\u3002\u7cfb\u7edf\u6301\u7eed\u6444\u5165\u591a\u6e90\u4f20\u611f\u5668\u56fe\u50cf\u3001\u5929\u6c14\u6570\u636e\u548c3D\u68ee\u6797\u6a21\u578b\uff0c\u521b\u5efa\u706b\u707e\u73af\u5883\u7684\u5b9e\u65f6\u865a\u62df\u526f\u672c\u3002AI\u9a71\u52a8\u7684\u76f8\u4f3c\u6027\u5f15\u64ce\u5c06\u65b0\u5174\u6761\u4ef6\u4e0e\u9884\u8ba1\u7b97\u7684\u707e\u5bb3\u6a21\u62df\u5e93\u5bf9\u9f50\uff0c\u68c0\u7d22\u5e76\u6821\u51c6\u5e72\u9884\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u5de5\u4e1a\u5408\u4f5c\u4f19\u4f34\u63d0\u4f9b\u7684\u8be6\u7ec6\u6848\u4f8b\u7814\u7a76\u6a21\u62df\u9a8c\u8bc1IVSR\uff0c\u5c55\u793a\u4e86\u5728\u5c40\u90e8\u4e8b\u4ef6\u68c0\u6d4b\u3001\u9690\u79c1\u4fdd\u62a4\u56de\u653e\u3001\u57fa\u4e8e\u78b0\u649e\u5668\u7684\u706b\u52bf\u8513\u5ef6\u9884\u6d4b\u548c\u7279\u5b9a\u7ad9\u70b9ML\u518d\u8bad\u7ec3\u65b9\u9762\u7684\u80fd\u529b\u3002\u4e0e\u4f20\u7edf\u7cfb\u7edf\u76f8\u6bd4\uff0c\u68c0\u6d4b\u5230\u5e72\u9884\u7684\u5ef6\u8fdf\u663e\u8457\u964d\u4f4e\uff0c\u8d44\u6e90\u534f\u8c03\u66f4\u6709\u6548\u3002", "conclusion": "IVSR\u901a\u8fc7\u5c06\u5b9e\u65f6\u53cc\u5411\u6570\u5b57\u5b6a\u751f\u4e0e\u4ee3\u7406AI\u76f8\u7ed3\u5408\uff0c\u4e3a\u4e3b\u52a8\u3001\u81ea\u9002\u5e94\u7684\u91ce\u706b\u707e\u5bb3\u7ba1\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u534a\u81ea\u52a8\u5316\u7684\u51b3\u7b56\u652f\u6301\u8303\u5f0f\u3002"}}
{"id": "2602.08968", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08968", "abs": "https://arxiv.org/abs/2602.08968", "authors": ["Lucas Maes", "Quentin Le Lidec", "Dan Haramati", "Nassim Massaudi", "Damien Scieur", "Yann LeCun", "Randall Balestriero"], "title": "stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation", "comment": null, "summary": "World Models have emerged as a powerful paradigm for learning compact, predictive representations of environment dynamics, enabling agents to reason, plan, and generalize beyond direct experience. Despite recent interest in World Models, most available implementations remain publication-specific, severely limiting their reusability, increasing the risk of bugs, and reducing evaluation standardization. To mitigate these issues, we introduce stable-worldmodel (SWM), a modular, tested, and documented world-model research ecosystem that provides efficient data-collection tools, standardized environments, planning algorithms, and baseline implementations. In addition, each environment in SWM enables controllable factors of variation, including visual and physical properties, to support robustness and continual learning research. Finally, we demonstrate the utility of SWM by using it to study zero-shot robustness in DINO-WM.", "AI": {"tldr": "\u63d0\u51fa\u4e86stable-worldmodel (SWM) - \u4e00\u4e2a\u6a21\u5757\u5316\u3001\u7ecf\u8fc7\u6d4b\u8bd5\u548c\u6587\u6863\u5316\u7684\u4e16\u754c\u6a21\u578b\u7814\u7a76\u751f\u6001\u7cfb\u7edf\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u4e16\u754c\u6a21\u578b\u5b9e\u73b0\u590d\u7528\u6027\u5dee\u3001\u6613\u51fa\u9519\u548c\u8bc4\u4f30\u6807\u51c6\u5316\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u4e16\u754c\u6a21\u578b\u5b9e\u73b0\u90fd\u662f\u9488\u5bf9\u7279\u5b9a\u8bba\u6587\u7684\uff0c\u8fd9\u4e25\u91cd\u9650\u5236\u4e86\u5b83\u4eec\u7684\u53ef\u590d\u7528\u6027\uff0c\u589e\u52a0\u4e86bug\u98ce\u9669\uff0c\u5e76\u964d\u4f4e\u4e86\u8bc4\u4f30\u6807\u51c6\u5316\u7a0b\u5ea6\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u7684\u7814\u7a76\u751f\u6001\u7cfb\u7edf\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86stable-worldmodel (SWM)\u751f\u6001\u7cfb\u7edf\uff0c\u5305\u542b\u9ad8\u6548\u7684\u6570\u636e\u6536\u96c6\u5de5\u5177\u3001\u6807\u51c6\u5316\u73af\u5883\u3001\u89c4\u5212\u7b97\u6cd5\u548c\u57fa\u7ebf\u5b9e\u73b0\u3002\u6bcf\u4e2a\u73af\u5883\u90fd\u652f\u6301\u53ef\u63a7\u7684\u53d8\u5316\u56e0\u7d20\uff08\u5305\u62ec\u89c6\u89c9\u548c\u7269\u7406\u5c5e\u6027\uff09\uff0c\u4ee5\u652f\u6301\u9c81\u68d2\u6027\u548c\u6301\u7eed\u5b66\u4e60\u7814\u7a76\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86SWM\u751f\u6001\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u4f7f\u7528\u5b83\u7814\u7a76DINO-WM\u4e2d\u7684\u96f6\u6837\u672c\u9c81\u68d2\u6027\u6765\u5c55\u793a\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "SWM\u4e3a\u4e16\u754c\u6a21\u578b\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u53ef\u590d\u7528\u4e14\u6807\u51c6\u5316\u7684\u5e73\u53f0\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u7a33\u5065\u53d1\u5c55\u548c\u6bd4\u8f83\u8bc4\u4f30\u3002"}}
{"id": "2602.08990", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08990", "abs": "https://arxiv.org/abs/2602.08990", "authors": ["Shiyang Feng", "Runmin Ma", "Xiangchao Yan", "Yue Fan", "Yusong Hu", "Songtao Huang", "Shuaiyu Zhang", "Zongsheng Cao", "Tianshuo Peng", "Jiakang Yuan", "Zijie Guo", "Zhijie Zhong", "Shangheng Du", "Weida Wang", "Jinxin Shi", "Yuhao Zhou", "Xiaohan He", "Zhiyin Yu", "Fangchen Yu", "Qihao Zheng", "Jiamin Wu", "Mianxin Liu", "Chi Zhang", "Shaowei Hou", "Shuya Li", "Yankai Jiang", "Wenjie Lou", "Lilong Wang", "Zifu Wang", "Jiong Wang", "Wanghan Xu", "Yue Deng", "Dongrui Liu", "Yiheng Wang", "Wenlong Zhang", "Fenghua Ling", "Shufei Zhang", "Xiaosong Wang", "Shuangjia Zheng", "Xun Huang", "Siqi Sun", "Shuyue Hu", "Peng Ye", "Chunfeng Song", "Bin Wang", "Conghui He", "Yihao Liu", "Xin Li", "Qibin Hou", "Tao Chen", "Xiangyu Yue", "Bin Wang", "Liang He", "Dahua Lin", "Bowen Zhou", "Bo Zhang", "Lei Bai"], "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery", "comment": "Code and project page: https://github.com/InternScience/InternAgent", "summary": "We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within a single unified system. We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides a general and scalable framework for autonomous scientific discovery.", "AI": {"tldr": "InternAgent-1.5\u662f\u4e00\u4e2a\u7528\u4e8e\u7aef\u5230\u7aef\u79d1\u5b66\u53d1\u73b0\u7684\u7edf\u4e00\u7cfb\u7edf\uff0c\u901a\u8fc7\u751f\u6210\u3001\u9a8c\u8bc1\u3001\u6f14\u5316\u4e09\u4e2a\u5b50\u7cfb\u7edf\u534f\u8c03\u5de5\u4f5c\uff0c\u5728\u8ba1\u7b97\u548c\u5b9e\u9a8c\u9886\u57df\u5b9e\u73b0\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u5728\u8ba1\u7b97\u5efa\u6a21\u548c\u5b9e\u9a8c\u5ba4\u5b9e\u9a8c\u4e4b\u95f4\u534f\u8c03\u5de5\u4f5c\u7684\u7edf\u4e00\u7cfb\u7edf\uff0c\u5b9e\u73b0\u8de8\u9886\u57df\u7684\u7aef\u5230\u7aef\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u957f\u5468\u671f\u53d1\u73b0\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u5316\u67b6\u6784\uff0c\u5305\u542b\u751f\u6210\u3001\u9a8c\u8bc1\u3001\u6f14\u5316\u4e09\u4e2a\u534f\u8c03\u5b50\u7cfb\u7edf\uff0c\u652f\u6301\u6df1\u5ea6\u7814\u7a76\u3001\u89e3\u51b3\u65b9\u6848\u4f18\u5316\u548c\u957f\u5468\u671f\u8bb0\u5fc6\u7b49\u57fa\u7840\u80fd\u529b\uff0c\u80fd\u591f\u5728\u6269\u5c55\u53d1\u73b0\u5468\u671f\u4e2d\u6301\u7eed\u8fd0\u884c\u3002", "result": "\u5728GAIA\u3001HLE\u3001GPQA\u3001FrontierScience\u7b49\u79d1\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u9886\u5148\u6027\u80fd\uff1b\u5728\u7b97\u6cd5\u53d1\u73b0\u4efb\u52a1\u4e2d\u81ea\u4e3b\u8bbe\u8ba1\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff1b\u5728\u5b9e\u9a8c\u53d1\u73b0\u4efb\u52a1\u4e2d\u6267\u884c\u5b8c\u6574\u8ba1\u7b97\u6216\u6e7f\u5b9e\u9a8c\uff0c\u5728\u5730\u7403\u3001\u751f\u547d\u3001\u751f\u7269\u3001\u7269\u7406\u7b49\u9886\u57df\u4ea7\u751f\u79d1\u5b66\u53d1\u73b0\u3002", "conclusion": "InternAgent-1.5\u4e3a\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u4e14\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u80fd\u591f\u534f\u8c03\u8ba1\u7b97\u5efa\u6a21\u548c\u5b9e\u9a8c\u5ba4\u5b9e\u9a8c\uff0c\u5b9e\u73b0\u8de8\u9886\u57df\u7684\u7aef\u5230\u7aef\u79d1\u5b66\u53d1\u73b0\u3002"}}
{"id": "2602.09000", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09000", "abs": "https://arxiv.org/abs/2602.09000", "authors": ["Ali Hatamizadeh", "Shrimai Prabhumoye", "Igor Gitman", "Ximing Lu", "Seungju Han", "Wei Ping", "Yejin Choi", "Jan Kautz"], "title": "iGRPO: Self-Feedback-Driven LLM Reasoning", "comment": "Tech report", "summary": "Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliability. Group Relative Policy Optimization (GRPO) is an efficient, value-function-free alternative to Proximal Policy Optimization (PPO) that leverages group-relative reward normalization. We introduce Iterative Group Relative Policy Optimization (iGRPO), a two-stage extension of GRPO that adds dynamic self-conditioning through model-generated drafts. In Stage 1, iGRPO samples multiple exploratory drafts and selects the highest-reward draft using the same scalar reward signal used for optimization. In Stage 2, it appends this best draft to the original prompt and applies a GRPO-style update on draft-conditioned refinements, training the policy to improve beyond its strongest prior attempt. Under matched rollout budgets, iGRPO consistently outperforms GRPO across base models (e.g., Nemotron-H-8B-Base-8K and DeepSeek-R1 Distilled), validating its effectiveness on diverse reasoning benchmarks. Moreover, applying iGRPO to OpenReasoning-Nemotron-7B trained on AceReason-Math achieves new state-of-the-art results of 85.62\\% and 79.64\\% on AIME24 and AIME25, respectively. Ablations further show that the refinement wrapper generalizes beyond GRPO variants, benefits from a generative judge, and alters learning dynamics by delaying entropy collapse. These results underscore the potential of iterative, self-feedback-based RL for advancing verifiable mathematical reasoning.", "AI": {"tldr": "iGRPO\uff1a\u4e00\u79cd\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u751f\u6210\u7684\u8349\u7a3f\u8fdb\u884c\u52a8\u6001\u81ea\u6761\u4ef6\u5316\uff0c\u63d0\u5347\u6570\u5b66\u63a8\u7406\u80fd\u529b", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u51b3\u590d\u6742\u6570\u5b66\u95ee\u9898\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u4ecd\u96be\u4ee5\u4ea7\u751f\u51c6\u786e\u4e00\u81f4\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u5bf9\u9f50\u4efb\u52a1\u7279\u5b9a\u5956\u52b1\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5982PPO\u548cGRPO\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "iGRPO\u662fGRPO\u7684\u4e24\u9636\u6bb5\u6269\u5c55\uff1a\u7b2c\u4e00\u9636\u6bb5\u91c7\u6837\u591a\u4e2a\u63a2\u7d22\u6027\u8349\u7a3f\u5e76\u9009\u62e9\u6700\u9ad8\u5956\u52b1\u8349\u7a3f\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5c06\u6700\u4f73\u8349\u7a3f\u9644\u52a0\u5230\u539f\u59cb\u63d0\u793a\uff0c\u5728\u8349\u7a3f\u6761\u4ef6\u5316\u6539\u8fdb\u4e0a\u5e94\u7528GRPO\u5f0f\u66f4\u65b0\uff0c\u8bad\u7ec3\u7b56\u7565\u8d85\u8d8a\u5148\u524d\u6700\u4f73\u5c1d\u8bd5\u3002", "result": "\u5728\u5339\u914d\u7684rollout\u9884\u7b97\u4e0b\uff0ciGRPO\u5728\u591a\u4e2a\u57fa\u7840\u6a21\u578b\u4e0a\u6301\u7eed\u4f18\u4e8eGRPO\u3002\u5e94\u7528\u4e8eOpenReasoning-Nemotron-7B\u5728AceReason-Math\u8bad\u7ec3\u540e\uff0c\u5728AIME24\u548cAIME25\u4e0a\u5206\u522b\u8fbe\u523085.62%\u548c79.64%\u7684\u65b0SOTA\u7ed3\u679c\u3002", "conclusion": "\u8fed\u4ee3\u7684\u3001\u57fa\u4e8e\u81ea\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u63a8\u8fdb\u53ef\u9a8c\u8bc1\u6570\u5b66\u63a8\u7406\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0ciGRPO\u901a\u8fc7\u52a8\u6001\u81ea\u6761\u4ef6\u5316\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.09003", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.09003", "abs": "https://arxiv.org/abs/2602.09003", "authors": ["Yudong Wang", "Zixuan Fu", "Hengyu Zhao", "Chen Zhao", "Chuyue Zhou", "Xinle Lin", "Hongya Lyu", "Shuaikang Xue", "Yi Yi", "Yingjiao Wang", "Zhi Zheng", "Yuzhou Zhang", "Jie Zhou", "Chaojun Xiao", "Xu Han", "Zhiyuan Liu", "Maosong Sun"], "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management", "comment": "16 pages, 3 figures, 7 tables", "summary": "The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency. In this work, we argue that the development of AGI is entering a new phase of data-model co-evolution, in which models actively guide data management while high-quality data, in turn, amplifies model capabilities. To implement this vision, we propose a tiered data management framework, designed to support the full LLM training lifecycle across heterogeneous learning objectives and cost constraints. Specifically, we introduce an L0-L4 tiered data management framework, ranging from raw uncurated resources to organized and verifiable knowledge. Importantly, LLMs are fully used in data management processes, such as quality scoring and content editing, to refine data across tiers. Each tier is characterized by distinct data properties, management strategies, and training roles, enabling data to be strategically allocated across LLM training stages, including pre-training, mid-training, and alignment. The framework balances data quality, acquisition cost, and marginal training benefit, providing a systematic approach to scalable and sustainable data management. We validate the effectiveness of the proposed framework through empirical studies, in which tiered datasets are constructed from raw corpora and used across multiple training phases. Experimental results demonstrate that tier-aware data utilization significantly improves training efficiency and model performance. To facilitate further research, we release our tiered datasets and processing tools to the community.", "AI": {"tldr": "\u63d0\u51faL0-L4\u5206\u5c42\u6570\u636e\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u636e\u4e0e\u6a21\u578b\u534f\u540c\u8fdb\u5316\u63d0\u5347LLM\u8bad\u7ec3\u6548\u7387\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5206\u5c42\u6570\u636e\u5229\u7528\u663e\u8457\u6539\u5584\u8bad\u7ec3\u6548\u679c\u3002", "motivation": "\u5f53\u524dLLM\u7814\u7a76\u8fc7\u5ea6\u4f9d\u8d56\u6570\u636e\u89c4\u6a21\u5355\u5411\u6269\u5c55\uff0c\u9762\u4e34\u6570\u636e\u53ef\u7528\u6027\u3001\u83b7\u53d6\u6210\u672c\u548c\u8bad\u7ec3\u6548\u7387\u74f6\u9888\u3002\u8ba4\u4e3aAGI\u53d1\u5c55\u8fdb\u5165\u6570\u636e-\u6a21\u578b\u534f\u540c\u8fdb\u5316\u65b0\u9636\u6bb5\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u6570\u636e\u7ba1\u7406\u65b9\u6cd5\u3002", "method": "\u63d0\u51faL0-L4\u5206\u5c42\u6570\u636e\u7ba1\u7406\u6846\u67b6\uff1a\u4ece\u539f\u59cb\u672a\u6574\u7406\u8d44\u6e90\u5230\u7ec4\u7ec7\u5316\u53ef\u9a8c\u8bc1\u77e5\u8bc6\u3002\u5229\u7528LLM\u8fdb\u884c\u8d28\u91cf\u8bc4\u5206\u548c\u5185\u5bb9\u7f16\u8f91\u7b49\u6570\u636e\u7ba1\u7406\uff0c\u5404\u5c42\u7ea7\u6709\u4e0d\u540c\u6570\u636e\u7279\u6027\u3001\u7ba1\u7406\u7b56\u7565\u548c\u8bad\u7ec3\u89d2\u8272\uff0c\u652f\u6301\u9884\u8bad\u7ec3\u3001\u4e2d\u671f\u8bad\u7ec3\u548c\u5bf9\u9f50\u7b49\u5168\u751f\u547d\u5468\u671f\u3002", "result": "\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u6027\uff0c\u4ece\u539f\u59cb\u8bed\u6599\u6784\u5efa\u5206\u5c42\u6570\u636e\u96c6\u5e76\u5728\u591a\u4e2a\u8bad\u7ec3\u9636\u6bb5\u4f7f\u7528\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5206\u5c42\u6570\u636e\u5229\u7528\u663e\u8457\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u5206\u5c42\u6570\u636e\u7ba1\u7406\u6846\u67b6\u5e73\u8861\u6570\u636e\u8d28\u91cf\u3001\u83b7\u53d6\u6210\u672c\u548c\u8fb9\u9645\u8bad\u7ec3\u6536\u76ca\uff0c\u4e3a\u53ef\u6269\u5c55\u548c\u53ef\u6301\u7eed\u7684\u6570\u636e\u7ba1\u7406\u63d0\u4f9b\u7cfb\u7edf\u65b9\u6cd5\uff0c\u4fc3\u8fdb\u6570\u636e\u4e0e\u6a21\u578b\u534f\u540c\u8fdb\u5316\u3002"}}
{"id": "2602.09007", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.09007", "abs": "https://arxiv.org/abs/2602.09007", "authors": ["Haodong Li", "Jingwei Wu", "Quan Sun", "Guopeng Li", "Juanxi Tian", "Huanyu Zhang", "Yanlin Lai", "Ruichuan An", "Hongbo Peng", "Yuhong Dai", "Chenxi Li", "Chunmei Qing", "Jia Wang", "Ziyang Meng", "Zheng Ge", "Xiangyu Zhang", "Daxin Jiang"], "title": "GEBench: Benchmarking Image Generation Models as GUI Environments", "comment": "23 pages, 5 figures, 4 tables", "summary": "Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation. GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score, a novel five-dimensional metric that assesses Goal Achievement, Interaction Logic, Content Consistency, UI Plausibility, and Visual Quality. Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/GEBench.", "AI": {"tldr": "\u63d0\u51fa\u4e86GEBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30GUI\u751f\u6210\u4e2d\u7684\u52a8\u6001\u4ea4\u4e92\u548c\u65f6\u5e8f\u4e00\u81f4\u6027\uff0c\u5305\u542b700\u4e2a\u6837\u672c\u548cGE-Score\u4e94\u7ef4\u8bc4\u4f30\u6307\u6807\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u957f\u5e8f\u5217\u4ea4\u4e92\u4e2d\u4fdd\u6301\u65f6\u5e8f\u4e00\u81f4\u6027\u548c\u7a7a\u95f4\u5b9a\u4f4d\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "motivation": "\u73b0\u6709\u56fe\u50cf\u751f\u6210\u6a21\u578b\u80fd\u591f\u6839\u636e\u7528\u6237\u6307\u4ee4\u9884\u6d4b\u672a\u6765GUI\u72b6\u6001\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u901a\u7528\u9886\u57df\u7684\u89c6\u89c9\u4fdd\u771f\u5ea6\uff0c\u7f3a\u4e4f\u5bf9GUI\u7279\u5b9a\u573a\u666f\u4e2d\u72b6\u6001\u8f6c\u6362\u548c\u65f6\u5e8f\u4e00\u81f4\u6027\u7684\u8bc4\u4f30\u3002", "method": "\u5f15\u5165GEBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b700\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684\u6837\u672c\uff0c\u6db5\u76d65\u4e2a\u4efb\u52a1\u7c7b\u522b\uff0c\u5305\u62ec\u5355\u6b65\u4ea4\u4e92\u548c\u591a\u6b65\u8f68\u8ff9\u3002\u63d0\u51faGE-Score\u4e94\u7ef4\u8bc4\u4f30\u6307\u6807\uff1a\u76ee\u6807\u8fbe\u6210\u3001\u4ea4\u4e92\u903b\u8f91\u3001\u5185\u5bb9\u4e00\u81f4\u6027\u3001UI\u5408\u7406\u6027\u548c\u89c6\u89c9\u8d28\u91cf\u3002", "result": "\u5bf9\u5f53\u524d\u6a21\u578b\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0c\u5b83\u4eec\u5728\u5355\u6b65\u8f6c\u6362\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u4fdd\u6301\u957f\u4ea4\u4e92\u5e8f\u5217\u7684\u65f6\u5e8f\u4e00\u81f4\u6027\u548c\u7a7a\u95f4\u5b9a\u4f4d\u65b9\u9762\u5b58\u5728\u663e\u8457\u56f0\u96be\u3002\u56fe\u6807\u89e3\u91ca\u3001\u6587\u672c\u6e32\u67d3\u548c\u5b9a\u4f4d\u7cbe\u5ea6\u662f\u5173\u952e\u74f6\u9888\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u7cfb\u7edf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u4e3a\u672a\u6765\u6784\u5efa\u9ad8\u4fdd\u771f\u751f\u6210GUI\u73af\u5883\u7684\u7814\u7a76\u6307\u660e\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2409.08347", "categories": ["econ.EM", "cs.GT", "math.OC"], "pdf": "https://arxiv.org/pdf/2409.08347", "abs": "https://arxiv.org/abs/2409.08347", "authors": ["Mogens Fosgerau", "Nikolaj Nielsen", "Mads Paulsen", "Thomas Kj\u00e6r Rasmussen", "Rui Yao"], "title": "Sensitivity analysis of the perturbed utility stochastic traffic equilibrium", "comment": null, "summary": "This paper develops a sensitivity analysis framework for the perturbed utility route choice (PURC) model and the accompanying stochastic traffic equilibrium model. We derive analytical sensitivity expressions for the Jacobian of the individual optimal PURC flow and equilibrium link flows with respect to link cost parameters under general assumptions. This allows us to determine the marginal change in link flows following a marginal change in link costs across the network. We show how to implement these results while exploiting the sparsity generated by the PURC model. Numerical examples illustrate the use of our method for estimating equilibrium link flows after link cost shifts, identifying critical design parameters, and quantifying uncertainty in performance predictions. Finally, we demonstrate the method in a large-scale example. The findings have implications for network design, pricing strategies, and policy analysis in transportation planning and economics, providing a bridge between theoretical models and real-world applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u6270\u52a8\u6548\u7528\u8def\u5f84\u9009\u62e9(PURC)\u6a21\u578b\u53ca\u5176\u4f34\u968f\u7684\u968f\u673a\u4ea4\u901a\u5747\u8861\u6a21\u578b\u7684\u654f\u611f\u6027\u5206\u6790\u6846\u67b6\uff0c\u63a8\u5bfc\u4e86\u6d41\u91cf\u5bf9\u6210\u672c\u53c2\u6570\u7684\u89e3\u6790\u654f\u611f\u6027\u8868\u8fbe\u5f0f\uff0c\u53ef\u7528\u4e8e\u7f51\u7edc\u8bbe\u8ba1\u3001\u5b9a\u4ef7\u7b56\u7565\u548c\u653f\u7b56\u5206\u6790\u3002", "motivation": "\u4e3aPURC\u6a21\u578b\u548c\u968f\u673a\u4ea4\u901a\u5747\u8861\u6a21\u578b\u5efa\u7acb\u654f\u611f\u6027\u5206\u6790\u6846\u67b6\uff0c\u4ee5\u7406\u89e3\u7f51\u7edc\u53c2\u6570\u53d8\u5316\u5bf9\u4ea4\u901a\u6d41\u91cf\u7684\u5f71\u54cd\uff0c\u4e3a\u5b9e\u9645\u4ea4\u901a\u89c4\u5212\u548c\u7ecf\u6d4e\u653f\u7b56\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002", "method": "\u63a8\u5bfc\u4e86PURC\u6a21\u578b\u4e0b\u4e2a\u4f53\u6700\u4f18\u6d41\u91cf\u548c\u5747\u8861\u94fe\u8def\u6d41\u91cf\u5bf9\u94fe\u8def\u6210\u672c\u53c2\u6570\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\u7684\u89e3\u6790\u654f\u611f\u6027\u8868\u8fbe\u5f0f\uff0c\u5229\u7528PURC\u6a21\u578b\u4ea7\u751f\u7684\u7a00\u758f\u6027\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002", "result": "\u83b7\u5f97\u4e86\u94fe\u8def\u6210\u672c\u8fb9\u9645\u53d8\u5316\u5bf9\u94fe\u8def\u6d41\u91cf\u7684\u8fb9\u9645\u5f71\u54cd\u8868\u8fbe\u5f0f\uff0c\u901a\u8fc7\u6570\u503c\u7b97\u4f8b\u5c55\u793a\u4e86\u65b9\u6cd5\u5728\u4f30\u8ba1\u5747\u8861\u6d41\u91cf\u3001\u8bc6\u522b\u5173\u952e\u8bbe\u8ba1\u53c2\u6570\u548c\u91cf\u5316\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u65b9\u9762\u7684\u5e94\u7528\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u5b9e\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u654f\u611f\u6027\u5206\u6790\u6846\u67b6\u4e3a\u4ea4\u901a\u89c4\u5212\u548c\u7ecf\u6d4e\u4e2d\u7684\u7f51\u7edc\u8bbe\u8ba1\u3001\u5b9a\u4ef7\u7b56\u7565\u548c\u653f\u7b56\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u5de5\u5177\uff0c\u67b6\u8d77\u4e86\u7406\u8bba\u6a21\u578b\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u6865\u6881\u3002"}}
