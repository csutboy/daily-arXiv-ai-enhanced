{"id": "2510.08709", "categories": ["econ.TH", "econ.EM"], "pdf": "https://arxiv.org/pdf/2510.08709", "abs": "https://arxiv.org/abs/2510.08709", "authors": ["Maxwell Rosenthal"], "title": "Blackwell without Priors", "comment": null, "summary": "This paper proposes a fully prior-free model of experimentation in which the\ndecision maker observes the entire distribution of signals generated by a known\nexperiment under an unknown distribution of the state of the world. One\nexperiment is robustly more informative than another if the decision maker's\nmaxmin expected utility after observing the output of the former is always at\nleast her maxmin expected utility after observing the latter. We show that this\nranking holds if and only if the less informative experiment is a linear\ntransformation of the more informative experiment; equivalently, the null space\nof the more informative experiment is a subset of the null space of the less\ninformative experiment. Our criterion is implied by Blackwell's order but does\nnot imply it, and we show by example that our ranking admits strictly more\ncomparable pairs of experiments than the classical ranking.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u5168\u65e0\u5148\u9a8c\u7684\u5b9e\u9a8c\u6a21\u578b\uff0c\u51b3\u7b56\u8005\u5728\u5df2\u77e5\u5b9e\u9a8c\u4f46\u672a\u77e5\u72b6\u6001\u5206\u5e03\u4e0b\u89c2\u5bdf\u4fe1\u53f7\u5206\u5e03\u3002\u4e00\u4e2a\u5b9e\u9a8c\u6bd4\u53e6\u4e00\u4e2a\u66f4\u7a33\u5065\u4fe1\u606f\u4e30\u5bcc\uff0c\u5f53\u51b3\u7b56\u8005\u5728\u89c2\u5bdf\u524d\u8005\u8f93\u51fa\u540e\u7684\u6700\u5927\u6700\u5c0f\u671f\u671b\u6548\u7528\u603b\u662f\u81f3\u5c11\u7b49\u4e8e\u540e\u8005\u3002", "motivation": "\u4f20\u7edfBlackwell\u6392\u5e8f\u8981\u6c42\u5b9e\u9a8c\u5728\u6240\u6709\u5148\u9a8c\u5206\u5e03\u4e0b\u90fd\u66f4\u4f18\uff0c\u8fd9\u9650\u5236\u4e86\u53ef\u6bd4\u6027\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u66f4\u5bbd\u677e\u4f46\u4ecd\u6709\u610f\u4e49\u7684\u5b9e\u9a8c\u4fe1\u606f\u6027\u6bd4\u8f83\u6807\u51c6\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5b9e\u9a8c\u7684\u7ebf\u6027\u53d8\u6362\u5173\u7cfb\u548c\u96f6\u7a7a\u95f4\u5305\u542b\u5173\u7cfb\uff0c\u5efa\u7acb\u7a33\u5065\u4fe1\u606f\u6027\u6392\u5e8f\u7684\u5145\u8981\u6761\u4ef6\u3002", "result": "\u8bc1\u660e\u4e00\u4e2a\u5b9e\u9a8c\u6bd4\u53e6\u4e00\u4e2a\u66f4\u7a33\u5065\u4fe1\u606f\u4e30\u5bcc\u5f53\u4e14\u4ec5\u5f53\u4fe1\u606f\u8f83\u5c11\u7684\u5b9e\u9a8c\u662f\u4fe1\u606f\u8f83\u591a\u5b9e\u9a8c\u7684\u7ebf\u6027\u53d8\u6362\uff0c\u6216\u4fe1\u606f\u8f83\u591a\u5b9e\u9a8c\u7684\u96f6\u7a7a\u95f4\u662f\u4fe1\u606f\u8f83\u5c11\u5b9e\u9a8c\u96f6\u7a7a\u95f4\u7684\u5b50\u96c6\u3002", "conclusion": "\u65b0\u6807\u51c6\u6bd4Blackwell\u6392\u5e8f\u66f4\u5bbd\u677e\uff0c\u5141\u8bb8\u66f4\u591a\u5b9e\u9a8c\u5bf9\u8fdb\u884c\u6bd4\u8f83\uff0c\u4e3a\u5b9e\u9a8c\u4fe1\u606f\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2510.09076", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.09076", "abs": "https://arxiv.org/abs/2510.09076", "authors": ["Ori Livson", "Mikhail Prokopenko"], "title": "Arrow's Impossibility Theorem as a Generalisation of Condorcet's Paradox", "comment": "15 pages. Some material from this submission originally appeared in a\n  prior version of a separate paper written by the authors (arXiv:2504.06589)", "summary": "Arrow's Impossibility Theorem is a seminal result of Social Choice Theory\nthat demonstrates the impossibility of ranked-choice decision-making processes\nto jointly satisfy a number of intuitive and seemingly desirable constraints.\nThe theorem is often described as a generalisation of Condorcet's Paradox,\nwherein pairwise majority voting may fail to jointly satisfy the same\nconstraints due to the occurrence of elections that result in contradictory\npreference cycles. However, a formal proof of this relationship has been\nlimited to D'Antoni's work, which applies only to the strict preference case,\ni.e., where indifference between alternatives is not allowed. In this paper, we\ngeneralise D'Antoni's methodology to prove in full (i.e., accounting for weak\npreferences) that Arrow's Impossibility Theorem can be equivalently stated in\nterms of contradictory preference cycles. This methodology involves explicitly\nconstructing profiles that lead to preference cycles. Using this framework, we\nalso prove a number of additional facts regarding social welfare functions. As\na result, this methodology may yield further insights into the nature of\npreference cycles in other domains e.g., Money Pumps, Dutch Books, Intransitive\nGames, etc.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u963f\u7f57\u4e0d\u53ef\u80fd\u5b9a\u7406\u53ef\u4ee5\u7b49\u4ef7\u5730\u8868\u8ff0\u4e3a\u77db\u76fe\u504f\u597d\u5faa\u73af\u95ee\u9898\uff0c\u5c06D'Antoni\u7684\u65b9\u6cd5\u63a8\u5e7f\u5230\u5305\u542b\u5f31\u504f\u597d\u7684\u5b8c\u6574\u60c5\u51b5\u3002", "motivation": "\u963f\u7f57\u4e0d\u53ef\u80fd\u5b9a\u7406\u662f\u793e\u4f1a\u79d1\u5b66\u9009\u62e9\u7406\u8bba\u7684\u57fa\u7840\u6027\u6210\u679c\uff0c\u4f46\u73b0\u6709\u5173\u4e8e\u5176\u4e0e\u5b54\u591a\u585e\u6096\u8bba\u5173\u7cfb\u7684\u8bc1\u660e\u4ec5\u9650\u4e8e\u4e25\u683c\u504f\u597d\u60c5\u51b5\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5c06\u8bc1\u660e\u63a8\u5e7f\u5230\u5305\u542b\u5f31\u504f\u597d\u7684\u5b8c\u6574\u60c5\u51b5\u3002", "method": "\u901a\u8fc7\u663e\u5f0f\u6784\u9020\u5bfc\u81f4\u504f\u597d\u5faa\u73af\u7684\u914d\u7f6e\uff0c\u5c06D'Antoni\u7684\u65b9\u6cd5\u8bba\u63a8\u5e7f\u5230\u5305\u542b\u5f31\u504f\u597d\u7684\u60c5\u51b5\uff0c\u8bc1\u660e\u963f\u7f57\u4e0d\u53ef\u80fd\u5b9a\u7406\u53ef\u4ee5\u7b49\u4ef7\u5730\u8868\u8ff0\u4e3a\u77db\u76fe\u504f\u597d\u5faa\u73af\u95ee\u9898\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u5728\u5305\u542b\u5f31\u504f\u597d\u7684\u5b8c\u6574\u60c5\u51b5\u4e0b\uff0c\u963f\u7f57\u4e0d\u53ef\u80fd\u5b9a\u7406\u786e\u5b9e\u53ef\u4ee5\u7b49\u4ef7\u5730\u8868\u8ff0\u4e3a\u77db\u76fe\u504f\u597d\u5faa\u73af\u95ee\u9898\uff0c\u5e76\u83b7\u5f97\u4e86\u5173\u4e8e\u793e\u4f1a\u798f\u5229\u51fd\u6570\u7684\u82e5\u5e72\u989d\u5916\u4e8b\u5b9e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bba\u4e0d\u4ec5\u5b8c\u5584\u4e86\u963f\u7f57\u4e0d\u53ef\u80fd\u5b9a\u7406\u4e0e\u5b54\u591a\u585e\u6096\u8bba\u5173\u7cfb\u7684\u7406\u8bba\u6846\u67b6\uff0c\u8fd8\u53ef\u80fd\u4e3a\u5176\u4ed6\u9886\u57df\uff08\u5982\u91d1\u94b1\u6cf5\u3001\u8377\u5170\u8d4c\u3001\u4e0d\u53ef\u4f20\u9012\u535a\u5f08\u7b49\uff09\u7684\u504f\u597d\u5faa\u73af\u7814\u7a76\u63d0\u4f9b\u65b0\u7684\u6d1e\u89c1\u3002"}}
{"id": "2510.09590", "categories": ["econ.TH", "econ.EM"], "pdf": "https://arxiv.org/pdf/2510.09590", "abs": "https://arxiv.org/abs/2510.09590", "authors": ["Martyna Kobus", "Rados\u0142aw Kurek", "Thomas Parker"], "title": "Ranking Policies Under Loss Aversion and Inequality Aversion", "comment": "52 pages, 7 figures", "summary": "Strong empirical evidence from laboratory experiments, and more recently from\npopulation surveys, shows that individuals, when evaluating their situations,\npay attention to whether they experience gains or losses, with losses weighing\nmore heavily than gains. The electorate's loss aversion, in turn, influences\npoliticians' choices. We propose a new framework for welfare analysis of policy\noutcomes that, in addition to the traditional focus on post-policy incomes,\nalso accounts for individuals' gains and losses resulting from policies. We\ndevelop several bivariate stochastic dominance criteria for ranking policy\noutcomes that are sensitive to features of the joint distribution of\nindividuals' income changes and absolute incomes. The main social objective\nassumes that individuals are loss averse with respect to income gains and\nlosses, inequality averse with respect to absolute incomes, and hold varying\npreferences regarding the association between incomes and income changes. We\ntranslate these and other preferences into functional inequalities that can be\ntested using sample data. The concepts and methods are illustrated using data\nfrom an income support experiment conducted in Connecticut.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8003\u8651\u4e2a\u4f53\u5f97\u5931\u7684\u65b0\u798f\u5229\u5206\u6790\u6846\u67b6\uff0c\u5f00\u53d1\u53cc\u53d8\u91cf\u968f\u673a\u4f18\u52bf\u6807\u51c6\u6765\u8bc4\u4f30\u653f\u7b56\u7ed3\u679c\uff0c\u5173\u6ce8\u6536\u5165\u53d8\u5316\u4e0e\u7edd\u5bf9\u6536\u5165\u7684\u8054\u5408\u5206\u5e03\u7279\u5f81\u3002", "motivation": "\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\u4e2a\u4f53\u5728\u8bc4\u4f30\u81ea\u8eab\u72b6\u51b5\u65f6\u4f1a\u5173\u6ce8\u5f97\u5931\u4f53\u9a8c\uff0c\u4e14\u635f\u5931\u6bd4\u6536\u76ca\u5f71\u54cd\u66f4\u5927\uff0c\u8fd9\u79cd\u635f\u5931\u538c\u6076\u4f1a\u5f71\u54cd\u653f\u6cbb\u5bb6\u7684\u653f\u7b56\u9009\u62e9\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u798f\u5229\u5206\u6790\u6846\u67b6\u3002", "method": "\u5f00\u53d1\u53cc\u53d8\u91cf\u968f\u673a\u4f18\u52bf\u6807\u51c6\uff0c\u8003\u8651\u6536\u5165\u53d8\u5316\u548c\u7edd\u5bf9\u6536\u5165\u7684\u8054\u5408\u5206\u5e03\uff0c\u5c06\u635f\u5931\u538c\u6076\u3001\u4e0d\u5e73\u7b49\u538c\u6076\u7b49\u504f\u597d\u8f6c\u5316\u4e3a\u53ef\u901a\u8fc7\u6837\u672c\u6570\u636e\u68c0\u9a8c\u7684\u51fd\u6570\u4e0d\u7b49\u5f0f\u3002", "result": "\u4f7f\u7528\u5eb7\u6d85\u72c4\u683c\u5dde\u6536\u5165\u652f\u6301\u5b9e\u9a8c\u6570\u636e\u8fdb\u884c\u6982\u5ff5\u548c\u65b9\u6cd5\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u63d0\u51fa\u7684\u798f\u5229\u5206\u6790\u6846\u67b6\u80fd\u591f\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u653f\u7b56\u7ed3\u679c\uff0c\u4e0d\u4ec5\u5173\u6ce8\u6700\u7ec8\u6536\u5165\u6c34\u5e73\uff0c\u8fd8\u8003\u8651\u4e86\u4e2a\u4f53\u5728\u653f\u7b56\u5b9e\u65bd\u8fc7\u7a0b\u4e2d\u7684\u5f97\u5931\u4f53\u9a8c\u3002"}}
{"id": "2510.09031", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.09031", "abs": "https://arxiv.org/abs/2510.09031", "authors": ["Paul Bouchaud", "Pedro Ramaciotti"], "title": "Web Crawler Restrictions, AI Training Datasets \\&amp; Political Biases", "comment": null, "summary": "Large language models rely on web-scraped text for training; concurrently,\ncontent creators are increasingly blocking AI crawlers to retain control over\ntheir data. We analyze crawler restrictions across the top one million\nmost-visited websites since 2023 and examine their potential downstream effects\non training data composition. Our analysis reveals growing restrictions, with\nblocking patterns varying by website popularity and content type. A quarter of\nthe top thousand websites restrict AI crawlers, decreasing to one-tenth across\nthe broader top million. Content type matters significantly: 34.2% of news\noutlets disallow OpenAI's GPTBot, rising to 55% for outlets with high factual\nreporting. Additionally, outlets with neutral political positions impose the\nstrongest restrictions (58%), whereas hyperpartisan websites and those with low\nfactual reporting impose fewer restrictions -only 4.1% of right-leaning outlets\nblock access to OpenAI. Our findings suggest that heterogeneous blocking\npatterns may skew training datasets toward low-quality or polarized content,\npotentially affecting the capabilities of models served by prominent\nAI-as-a-Service providers.", "AI": {"tldr": "\u5206\u6790\u663e\u793aAI\u722c\u866b\u9650\u5236\u65e5\u76ca\u589e\u957f\uff0c\u4e0d\u540c\u7f51\u7ad9\u7c7b\u578b\u548c\u5185\u5bb9\u8d28\u91cf\u5448\u73b0\u5dee\u5f02\u5316\u5c4f\u853d\u6a21\u5f0f\uff0c\u53ef\u80fd\u5bfc\u81f4\u8bad\u7ec3\u6570\u636e\u504f\u5411\u4f4e\u8d28\u91cf\u6216\u6781\u5316\u5185\u5bb9", "motivation": "\u7814\u7a76AI\u722c\u866b\u88ab\u7f51\u7ad9\u5c4f\u853d\u7684\u73b0\u8c61\u53ca\u5176\u5bf9LLM\u8bad\u7ec3\u6570\u636e\u6784\u6210\u7684\u6f5c\u5728\u5f71\u54cd\uff0c\u56e0\u4e3a\u5185\u5bb9\u521b\u4f5c\u8005\u4e3a\u63a7\u5236\u6570\u636e\u800c\u9650\u5236AI\u722c\u866b\u8bbf\u95ee", "method": "\u5206\u67902023\u5e74\u4ee5\u6765\u5168\u7403\u524d100\u4e07\u8bbf\u95ee\u91cf\u7f51\u7ad9\u7684\u722c\u866b\u9650\u5236\u60c5\u51b5\uff0c\u6309\u7f51\u7ad9\u6d41\u884c\u5ea6\u3001\u5185\u5bb9\u7c7b\u578b\u3001\u653f\u6cbb\u7acb\u573a\u548c\u4e8b\u5b9e\u62a5\u9053\u8d28\u91cf\u8fdb\u884c\u5206\u7c7b\u7edf\u8ba1", "result": "25%\u7684\u9876\u7ea7\u7f51\u7ad9\u9650\u5236AI\u722c\u866b\uff0c\u65b0\u95fb\u7f51\u7ad9\u9650\u5236\u7387\u66f4\u9ad8\uff0834.2%\uff09\uff0c\u9ad8\u8d28\u91cf\u4e8b\u5b9e\u62a5\u9053\u7f51\u7ad9\u9650\u5236\u7387\u8fbe55%\uff0c\u4e2d\u7acb\u653f\u6cbb\u7acb\u573a\u7f51\u7ad9\u9650\u5236\u6700\u5f3a\uff0858%\uff09\uff0c\u800c\u53f3\u503e\u7f51\u7ad9\u9650\u5236\u7387\u4ec54.1%", "conclusion": "\u5f02\u8d28\u5316\u7684\u5c4f\u853d\u6a21\u5f0f\u53ef\u80fd\u5bfc\u81f4\u8bad\u7ec3\u6570\u636e\u96c6\u504f\u5411\u4f4e\u8d28\u91cf\u6216\u6781\u5316\u5185\u5bb9\uff0c\u5f71\u54cd\u4e3b\u6d41AI\u670d\u52a1\u63d0\u4f9b\u5546\u6a21\u578b\u7684\u80fd\u529b"}}
{"id": "2510.08731", "categories": ["cs.ET", "cs.AI", "cs.CL", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.08731", "abs": "https://arxiv.org/abs/2510.08731", "authors": ["Chen Wang", "Xunzhuo Liu", "Yuhan Liu", "Yue Zhu", "Xiangxi Mo", "Junchen Jiang", "Huamin Chen"], "title": "When to Reason: Semantic Router for vLLM", "comment": "5 pages, excluding references and appendix. To be appeared at\n  Workshop on ML for Systems at NeurIPS 2025, December 6, 2025\n  https://mlforsystems.org/", "summary": "Large Language Models (LLMs) demonstrate substantial accuracy gains when\naugmented with reasoning modes such as chain-of-thought and inference-time\nscaling. However, reasoning also incurs significant costs in inference latency\nand token usage, with environmental and financial impacts, which are\nunnecessary for many simple prompts. We present a semantic router that\nclassifies queries based on their reasoning requirements and selectively\napplies reasoning only when beneficial. Our approach achieves a 10.2 percentage\npoint improvement in accuracy on the MMLU-Pro benchmark while reducing response\nlatency by 47.1% and token consumption by 48.5% compared to direct inference\nwith vLLM. These results demonstrate that semantic routing offers an effective\nmechanism for striking a balance between accuracy and efficiency in open-source\nLLM serving systems", "AI": {"tldr": "\u63d0\u51fa\u8bed\u4e49\u8def\u7531\u5668\uff0c\u6839\u636e\u67e5\u8be2\u7684\u63a8\u7406\u9700\u6c42\u9009\u62e9\u6027\u5e94\u7528\u63a8\u7406\uff0c\u5728MMLU-Pro\u57fa\u51c6\u4e0a\u5b9e\u73b010.2%\u51c6\u786e\u7387\u63d0\u5347\uff0c\u540c\u65f6\u964d\u4f4e47.1%\u5ef6\u8fdf\u548c48.5%\u4ee4\u724c\u6d88\u8017", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u589e\u5f3a\u63a8\u7406\u6a21\u5f0f\u65f6\u867d\u7136\u80fd\u663e\u8457\u63d0\u5347\u51c6\u786e\u7387\uff0c\u4f46\u4e5f\u4f1a\u5e26\u6765\u63a8\u7406\u5ef6\u8fdf\u548c\u4ee4\u724c\u4f7f\u7528\u91cf\u7684\u663e\u8457\u589e\u52a0\uff0c\u8fd9\u5bf9\u4e8e\u8bb8\u591a\u7b80\u5355\u63d0\u793a\u6765\u8bf4\u662f\u4e0d\u5fc5\u8981\u7684\u6210\u672c", "method": "\u5f00\u53d1\u8bed\u4e49\u8def\u7531\u5668\uff0c\u901a\u8fc7\u5206\u7c7b\u67e5\u8be2\u7684\u63a8\u7406\u9700\u6c42\uff0c\u4ec5\u5728\u6709\u76ca\u65f6\u9009\u62e9\u6027\u5e94\u7528\u63a8\u7406\u6a21\u5f0f", "result": "\u5728MMLU-Pro\u57fa\u51c6\u4e0a\u51c6\u786e\u7387\u63d0\u534710.2\u4e2a\u767e\u5206\u70b9\uff0c\u54cd\u5e94\u5ef6\u8fdf\u964d\u4f4e47.1%\uff0c\u4ee4\u724c\u6d88\u8017\u51cf\u5c1148.5%", "conclusion": "\u8bed\u4e49\u8def\u7531\u4e3a\u5f00\u6e90LLM\u670d\u52a1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u7684\u6709\u6548\u673a\u5236"}}
{"id": "2510.09407", "categories": ["q-fin.GN", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09407", "abs": "https://arxiv.org/abs/2510.09407", "authors": ["Sahab Zandi", "Kamesh Korangi", "Juan C. Moreno-Paredes", "Mar\u00eda \u00d3skarsd\u00f3ttir", "Christophe Mues", "Cristi\u00e1n Bravo"], "title": "A Multimodal Approach to SME Credit Scoring Integrating Transaction and Ownership Networks", "comment": null, "summary": "Small and Medium-sized Enterprises (SMEs) are known to play a vital role in\neconomic growth, employment, and innovation. However, they tend to face\nsignificant challenges in accessing credit due to limited financial histories,\ncollateral constraints, and exposure to macroeconomic shocks. These challenges\nmake an accurate credit risk assessment by lenders crucial, particularly since\nSMEs frequently operate within interconnected firm networks through which\ndefault risk can propagate. This paper presents and tests a novel approach for\nmodelling the risk of SME credit, using a unique large data set of SME loans\nprovided by a prominent financial institution. Specifically, our approach\nemploys Graph Neural Networks to predict SME default using multilayer network\ndata derived from common ownership and financial transactions between firms. We\nshow that combining this information with traditional structured data not only\nimproves application scoring performance, but also explicitly models contagion\nrisk between companies. Further analysis shows how the directionality and\nintensity of these connections influence financial risk contagion, offering a\ndeeper understanding of the underlying processes. Our findings highlight the\npredictive power of network data, as well as the role of supply chain networks\nin exposing SMEs to correlated default risk.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u4e2d\u5c0f\u4f01\u4e1a\u4fe1\u8d37\u8fdd\u7ea6\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f01\u4e1a\u95f4\u7684\u5171\u540c\u6240\u6709\u6743\u548c\u91d1\u878d\u4ea4\u6613\u7f51\u7edc\u6570\u636e\u6765\u6539\u8fdb\u4fe1\u7528\u98ce\u9669\u8bc4\u4f30\u3002", "motivation": "\u4e2d\u5c0f\u4f01\u4e1a\u5728\u7ecf\u6d4e\u589e\u957f\u4e2d\u53d1\u6325\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u9762\u4e34\u4fe1\u8d37\u83b7\u53d6\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u7f3a\u4e4f\u5b8c\u6574\u8d22\u52a1\u5386\u53f2\u548c\u62b5\u62bc\u54c1\u7684\u60c5\u51b5\u4e0b\u3002\u4f01\u4e1a\u95f4\u7f51\u7edc\u4e2d\u7684\u8fdd\u7ea6\u98ce\u9669\u4f20\u64ad\u4f7f\u5f97\u51c6\u786e\u8bc4\u4f30\u4fe1\u7528\u98ce\u9669\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u7ed3\u5408\u4f01\u4e1a\u95f4\u7684\u591a\u5c42\u7f51\u7edc\u6570\u636e\uff08\u5171\u540c\u6240\u6709\u6743\u548c\u91d1\u878d\u4ea4\u6613\uff09\u4e0e\u4f20\u7edf\u7ed3\u6784\u5316\u6570\u636e\uff0c\u6765\u9884\u6d4b\u4e2d\u5c0f\u4f01\u4e1a\u8fdd\u7ea6\u98ce\u9669\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u7ed3\u5408\u7f51\u7edc\u6570\u636e\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u7533\u8bf7\u8bc4\u5206\u6027\u80fd\uff0c\u8fd8\u80fd\u660e\u786e\u6a21\u62df\u4f01\u4e1a\u95f4\u7684\u4f20\u67d3\u98ce\u9669\u3002\u8fde\u63a5\u7684\u65b9\u5411\u6027\u548c\u5f3a\u5ea6\u5bf9\u91d1\u878d\u98ce\u9669\u4f20\u67d3\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u7f51\u7edc\u6570\u636e\u5177\u6709\u5f3a\u5927\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u4f9b\u5e94\u94fe\u7f51\u7edc\u5728\u66b4\u9732\u4e2d\u5c0f\u4f01\u4e1a\u76f8\u5173\u8fdd\u7ea6\u98ce\u9669\u65b9\u9762\u53d1\u6325\u91cd\u8981\u4f5c\u7528\uff0c\u4e3a\u7406\u89e3\u98ce\u9669\u4f20\u67d3\u673a\u5236\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u7684\u89c6\u89d2\u3002"}}
{"id": "2510.08705", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08705", "abs": "https://arxiv.org/abs/2510.08705", "authors": ["Noah Steinkr\u00fcger", "Nisarga Nilavadi", "Wolfram Burgard", "Tanja Katharina Kaiser"], "title": "ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing", "comment": null, "summary": "Object transportation in cluttered environments is a fundamental task in\nvarious domains, including domestic service and warehouse logistics. In\ncooperative object transport, multiple robots must coordinate to move objects\nthat are too large for a single robot. One transport strategy is pushing, which\nonly requires simple robots. However, careful selection of robot-object contact\npoints is necessary to push the object along a preplanned path. Although this\nselection can be solved analytically, the solution space grows combinatorially\nwith the number of robots and object size, limiting scalability. Inspired by\nhow humans rely on common-sense reasoning for cooperative transport, we propose\ncombining the reasoning capabilities of Large Language Models with local search\nto select suitable contact points. Our LLM-guided local search method for\ncontact point selection, ConPoSe, successfully selects contact points for a\nvariety of shapes, including cuboids, cylinders, and T-shapes. We demonstrate\nthat ConPoSe scales better with the number of robots and object size than the\nanalytical approach, and also outperforms pure LLM-based selection.", "AI": {"tldr": "\u63d0\u51faConPoSe\u65b9\u6cd5\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u5c40\u90e8\u641c\u7d22\u6765\u9009\u62e9\u673a\u5668\u4eba-\u7269\u4f53\u63a5\u89e6\u70b9\uff0c\u89e3\u51b3\u591a\u673a\u5668\u4eba\u534f\u4f5c\u63a8\u8fd0\u7269\u4f53\u65f6\u7684\u63a5\u89e6\u70b9\u9009\u62e9\u95ee\u9898\uff0c\u6bd4\u7eaf\u89e3\u6790\u65b9\u6cd5\u548c\u7eafLLM\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u5728\u6742\u4e71\u73af\u5883\u4e2d\u8fdb\u884c\u7269\u4f53\u8fd0\u8f93\u662f\u91cd\u8981\u4efb\u52a1\uff0c\u591a\u673a\u5668\u4eba\u534f\u4f5c\u63a8\u8fd0\u5927\u7269\u4f53\u9700\u8981\u9009\u62e9\u5408\u9002\u7684\u63a5\u89e6\u70b9\u3002\u7eaf\u89e3\u6790\u65b9\u6cd5\u5728\u673a\u5668\u4eba\u6570\u91cf\u548c\u7269\u4f53\u5c3a\u5bf8\u589e\u52a0\u65f6\u7ec4\u5408\u7206\u70b8\uff0c\u800c\u4eba\u7c7b\u4f9d\u8d56\u5e38\u8bc6\u63a8\u7406\uff0c\u56e0\u6b64\u7ed3\u5408LLM\u7684\u63a8\u7406\u80fd\u529b\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "ConPoSe\u65b9\u6cd5\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u5c40\u90e8\u641c\u7d22\u6765\u9009\u62e9\u63a5\u89e6\u70b9\u3002LLM\u63d0\u4f9b\u521d\u59cb\u7684\u5e38\u8bc6\u63a8\u7406\uff0c\u5c40\u90e8\u641c\u7d22\u8fdb\u4e00\u6b65\u4f18\u5316\u9009\u62e9\u3002", "result": "ConPoSe\u6210\u529f\u4e3a\u957f\u65b9\u4f53\u3001\u5706\u67f1\u4f53\u548cT\u5f62\u7b49\u4e0d\u540c\u5f62\u72b6\u7684\u7269\u4f53\u9009\u62e9\u4e86\u5408\u9002\u7684\u63a5\u89e6\u70b9\u3002\u76f8\u6bd4\u7eaf\u89e3\u6790\u65b9\u6cd5\uff0c\u5728\u673a\u5668\u4eba\u6570\u91cf\u548c\u7269\u4f53\u5c3a\u5bf8\u589e\u52a0\u65f6\u5177\u6709\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e5f\u6bd4\u7eafLLM\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u7ed3\u5408LLM\u63a8\u7406\u548c\u5c40\u90e8\u641c\u7d22\u7684ConPoSe\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u673a\u5668\u4eba\u534f\u4f5c\u63a8\u8fd0\u4e2d\u7684\u63a5\u89e6\u70b9\u9009\u62e9\u95ee\u9898\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2510.08824", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.08824", "abs": "https://arxiv.org/abs/2510.08824", "authors": ["Shizhen Jia", "Mingjun Ying", "Marco Mezzavilla", "Doru Calin", "Theodore S. Rappaport", "Sundeep Rangan"], "title": "Joint Detection, Channel Estimation and Interference Nulling for Terrestrial-Satellite Downlink Co-Existence in the Upper Mid-Band", "comment": "Accepted for publication in the Proceedings of GlobeCom 2025", "summary": "The upper mid-band FR3 spectrum (7-24 GHz) has garnered significant interest\nfor future cellular services. However, utilizing a large portion of this band\nrequires careful interference coordination with incumbent satellite systems.\nThis paper investigates interference from high-power terrestrial base stations\n(TN-BSs) to satellite downlink receivers. A central challenge is that the\nvictim receivers, i.e., ground-based non-terrestrial user equipment (NTN-UEs)\nsuch as satellite customer premises equipment, must first be detected and their\nchannels estimated before the TN-BS can effectively place nulls in their\ndirections. We explore a potential solution where NTN-UEs periodically transmit\npreambles or beacon signals that TN-BSs can use for detection and channel\nestimation. The performance of this nulling approach is analyzed in a\nsimplified scenario with a single victim, revealing the interplay between path\nloss and estimation quality in determining nulling performance. To further\nvalidate the method, we conduct a detailed multi-user site-specific ray-tracing\n(RT) simulation in a rural environment. The results show that the proposed\nnulling approach is effective under realistic parameters, even with high\ndensities of victim units, although TN-BS may require a substantial number of\nantennas.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e867-24GHz\u9891\u6bb5\u4e2d\u5730\u9762\u57fa\u7ad9\u5bf9\u536b\u661f\u4e0b\u884c\u63a5\u6536\u5668\u7684\u5e72\u6270\u95ee\u9898\uff0c\u63d0\u51fa\u901a\u8fc7NTN-UE\u53d1\u9001\u524d\u5bfc\u4fe1\u53f7\u6765\u5e2e\u52a9TN-BS\u8fdb\u884c\u68c0\u6d4b\u548c\u4fe1\u9053\u4f30\u8ba1\uff0c\u4ece\u800c\u5728\u5e72\u6270\u65b9\u5411\u653e\u7f6e\u96f6\u9677\u7684\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740FR3\u9891\u6bb5(7-24GHz)\u5728\u8702\u7a9d\u670d\u52a1\u4e2d\u7684\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981\u89e3\u51b3\u5730\u9762\u57fa\u7ad9\u5bf9\u536b\u661f\u7cfb\u7edf\u7684\u5e72\u6270\u95ee\u9898\uff0c\u7279\u522b\u662f\u5982\u4f55\u534f\u8c03\u9ad8\u529f\u7387\u5730\u9762\u57fa\u7ad9\u4e0e\u73b0\u6709\u536b\u661f\u7cfb\u7edf\u4e4b\u95f4\u7684\u5e72\u6270\u3002", "method": "\u63d0\u51faNTN-UE\u5468\u671f\u6027\u53d1\u9001\u524d\u5bfc\u6216\u4fe1\u6807\u4fe1\u53f7\uff0cTN-BS\u5229\u7528\u8fd9\u4e9b\u4fe1\u53f7\u8fdb\u884c\u68c0\u6d4b\u548c\u4fe1\u9053\u4f30\u8ba1\uff0c\u7136\u540e\u5728\u5e72\u6270\u65b9\u5411\u653e\u7f6e\u96f6\u9677\u3002\u901a\u8fc7\u5355\u53d7\u5bb3\u8005\u7b80\u5316\u573a\u666f\u5206\u6790\u548c\u591a\u7528\u6237\u5c04\u7ebf\u8ffd\u8e2a\u4eff\u771f\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u5728\u53d7\u5bb3\u8005\u5355\u5143\u5bc6\u5ea6\u8f83\u9ad8\u7684\u60c5\u51b5\u4e0b\uff0c\u6240\u63d0\u51fa\u7684\u96f6\u9677\u65b9\u6cd5\u5728\u73b0\u5b9e\u53c2\u6570\u4e0b\u4ecd\u7136\u6709\u6548\uff0c\u4f46TN-BS\u53ef\u80fd\u9700\u8981\u5927\u91cf\u5929\u7ebf\u3002", "conclusion": "\u901a\u8fc7NTN-UE\u53d1\u9001\u524d\u5bfc\u4fe1\u53f7\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u534f\u8c03\u5730\u9762\u57fa\u7ad9\u4e0e\u536b\u661f\u7cfb\u7edf\u4e4b\u95f4\u7684\u5e72\u6270\uff0c\u4e3aFR3\u9891\u6bb5\u7684\u5171\u4eab\u4f7f\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2510.09064", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.09064", "abs": "https://arxiv.org/abs/2510.09064", "authors": ["Philipp Bach", "Sven Klaassen", "Jannis Kueck", "Mara Mattes", "Martin Spindler"], "title": "Sensitivity Analysis for Treatment Effects in Difference-in-Differences Models using Riesz Representation", "comment": null, "summary": "Difference-in-differences (DiD) is one of the most popular approaches for\nempirical research in economics, political science, and beyond. Identification\nin these models is based on the conditional parallel trends assumption: In the\nabsence of treatment, the average outcome of the treated and untreated group\nare assumed to evolve in parallel over time, conditional on pre-treatment\ncovariates. We introduce a novel approach to sensitivity analysis for DiD\nmodels that assesses the robustness of DiD estimates to violations of this\nassumption due to unobservable confounders, allowing researchers to\ntransparently assess and communicate the credibility of their causal estimation\nresults. Our method focuses on estimation by Double Machine Learning and\nextends previous work on sensitivity analysis based on Riesz Representation in\ncross-sectional settings. We establish asymptotic bounds for point estimates\nand confidence intervals in the canonical $2\\times2$ setting and group-time\ncausal parameters in settings with staggered treatment adoption. Our approach\nmakes it possible to relate the formulation of parallel trends violation to\nempirical evidence from (1) pre-testing, (2) covariate benchmarking and (3)\nstandard reporting statistics and visualizations. We provide extensive\nsimulation experiments demonstrating the validity of our sensitivity approach\nand diagnostics and apply our approach to two empirical applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u53cc\u91cd\u5dee\u5206\u6a21\u578b\u7684\u65b0\u654f\u611f\u6027\u5206\u6790\u65b9\u6cd5\uff0c\u8bc4\u4f30\u56e0\u4e0d\u53ef\u89c2\u6d4b\u6df7\u6742\u56e0\u7d20\u5bfc\u81f4\u5e73\u884c\u8d8b\u52bf\u5047\u8bbe\u8fdd\u53cd\u65f6\u4f30\u8ba1\u7ed3\u679c\u7684\u7a33\u5065\u6027\u3002", "motivation": "\u53cc\u91cd\u5dee\u5206\u6a21\u578b\u5728\u5b9e\u8bc1\u7814\u7a76\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u8bc6\u522b\u4f9d\u8d56\u4e8e\u6761\u4ef6\u5e73\u884c\u8d8b\u52bf\u5047\u8bbe\u3002\u5f53\u5b58\u5728\u4e0d\u53ef\u89c2\u6d4b\u6df7\u6742\u56e0\u7d20\u65f6\uff0c\u8fd9\u4e00\u5047\u8bbe\u53ef\u80fd\u88ab\u8fdd\u53cd\uff0c\u5f71\u54cd\u56e0\u679c\u63a8\u65ad\u7684\u53ef\u9760\u6027\u3002", "method": "\u57fa\u4e8e\u53cc\u91cd\u673a\u5668\u5b66\u4e60\u4f30\u8ba1\uff0c\u6269\u5c55\u4e86\u57fa\u4e8eRiesz\u8868\u793a\u7684\u654f\u611f\u6027\u5206\u6790\u65b9\u6cd5\uff0c\u5efa\u7acb\u4e86\u70b9\u4f30\u8ba1\u548c\u7f6e\u4fe1\u533a\u95f4\u7684\u6e10\u8fd1\u754c\u9650\uff0c\u9002\u7528\u4e8e\u6807\u51c62\u00d72\u8bbe\u7f6e\u548c\u4ea4\u9519\u5904\u7406\u91c7\u7528\u8bbe\u7f6e\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5c06\u5e73\u884c\u8d8b\u52bf\u8fdd\u53cd\u4e0e(1)\u9884\u68c0\u9a8c\u3001(2)\u534f\u53d8\u91cf\u57fa\u51c6\u6d4b\u8bd5\u548c(3)\u6807\u51c6\u62a5\u544a\u7edf\u8ba1\u548c\u53ef\u89c6\u5316\u7684\u5b9e\u8bc1\u8bc1\u636e\u8054\u7cfb\u8d77\u6765\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u79cd\u900f\u660e\u8bc4\u4f30\u548c\u4f20\u8fbe\u56e0\u679c\u4f30\u8ba1\u7ed3\u679c\u53ef\u4fe1\u5ea6\u7684\u5de5\u5177\uff0c\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u654f\u611f\u6027\u65b9\u6cd5\u548c\u8bca\u65ad\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.08792", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.08792", "abs": "https://arxiv.org/abs/2510.08792", "authors": ["Matteo Pistillo", "Charlotte Stix"], "title": "Assurance of Frontier AI Built for National Security", "comment": null, "summary": "This memorandum presents four recommendations aimed at strengthening the\nprinciples of AI model reliability and AI model governability, as DoW, ODNI,\nNIST, and CAISI refine AI assurance frameworks under the AI Action Plan. Our\nfocus concerns the open scientific problem of misalignment and its implications\non AI model behavior. Specifically, misalignment and scheming capabilities can\nbe a red flag indicating AI model insufficient reliability and governability.\nTo address the national security threats arising from misalignment, we\nrecommend that DoW and the IC strategically leverage existing testing and\nevaluation pipelines and their OT authority to future proof the principles of\nAI model reliability and AI model governability through a suite of scheming and\ncontrol evaluations.", "AI": {"tldr": "\u8be5\u5907\u5fd8\u5f55\u63d0\u51fa\u56db\u9879\u5efa\u8bae\uff0c\u65e8\u5728\u52a0\u5f3aAI\u6a21\u578b\u53ef\u9760\u6027\u548c\u53ef\u6cbb\u7406\u6027\u539f\u5219\uff0c\u91cd\u70b9\u5173\u6ce8\u9519\u4f4d\u95ee\u9898\u53ca\u5176\u5bf9AI\u6a21\u578b\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "motivation": "\u89e3\u51b3\u9519\u4f4d\u95ee\u9898\u5bf9\u56fd\u5bb6\u5b89\u5168\u6784\u6210\u7684\u5a01\u80c1\uff0c\u9519\u4f4d\u548c\u7b56\u5212\u80fd\u529b\u53ef\u80fd\u662fAI\u6a21\u578b\u53ef\u9760\u6027\u548c\u53ef\u6cbb\u7406\u6027\u4e0d\u8db3\u7684\u8b66\u793a\u4fe1\u53f7\u3002", "method": "\u5efa\u8bae\u56fd\u9632\u90e8\u548c\u60c5\u62a5\u754c\u6218\u7565\u6027\u5730\u5229\u7528\u73b0\u6709\u6d4b\u8bd5\u8bc4\u4f30\u6d41\u7a0b\u53ca\u5176\u8fd0\u8425\u6d4b\u8bd5\u6743\u9650\uff0c\u901a\u8fc7\u4e00\u5957\u7b56\u5212\u548c\u63a7\u5236\u8bc4\u4f30\u6765\u786e\u4fddAI\u6a21\u578b\u7684\u53ef\u9760\u6027\u539f\u5219\u3002", "result": "\u63d0\u51fa\u4e86\u56db\u9879\u5177\u4f53\u5efa\u8bae\u6765\u52a0\u5f3aAI\u6a21\u578b\u53ef\u9760\u6027\u548c\u53ef\u6cbb\u7406\u6027\u6846\u67b6\u3002", "conclusion": "\u9700\u8981\u901a\u8fc7\u4e13\u95e8\u7684\u8bc4\u4f30\u673a\u5236\u6765\u5e94\u5bf9AI\u6a21\u578b\u9519\u4f4d\u95ee\u9898\uff0c\u786e\u4fddAI\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u53ef\u6cbb\u7406\u6027\uff0c\u4ece\u800c\u9632\u8303\u56fd\u5bb6\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2510.08658", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.08658", "abs": "https://arxiv.org/abs/2510.08658", "authors": ["Shuige Liu"], "title": "When Truth Does Not Take on Its Shoes: How Misinformation Spreads in Chatrooms", "comment": null, "summary": "We examine how misinformation spreads in social networks composed of\nindividuals with long-term offline relationships. Especially, we focus on why\nmisinformation persists and diffuses despite being recognized by most as false.\nIn our psychological game theoretical model, each agent who receives a piece of\n(mis)information must first decide how to react -- by openly endorsing it,\nremaining silent, or openly challenging it. After observing the reactions of\nher neighbors who also received the message, the agent then chooses whether to\nforward it to others in her own chatroom who have not yet received it. By\ndistinguishing these two roles, our framework addresses puzzling real-world\nphenomena, such as the gap between what individuals privately believe and what\nthey publicly transmit. A key assumption in our model is that, while perceived\nveracity influences decisions, the dominant factor is the alignment between an\nagent's beliefs and those of her social network -- a feature characteristic of\ncommunities formed through long-term offline relationships. This dynamic can\nlead agents to tacitly accept and even propagate information they privately\njudge to be of low credibility. Our results challenge the view that improving\ninformation literacy alone can curb the spread of misinformation. We show that\nwhen agents are highly sensitive to peer pressure and the network exhibits\nstructural polarization, even if the majority does not genuinely believe in it,\nthe message still can spread widely without encountering open resistance.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u957f\u671f\u7ebf\u4e0b\u5173\u7cfb\u6784\u6210\u7684\u793e\u4ea4\u7f51\u7edc\u4e2d\uff0c\u9519\u8bef\u4fe1\u606f\u5982\u4f55\u4f20\u64ad\uff0c\u7279\u522b\u662f\u4e3a\u4ec0\u4e48\u5373\u4f7f\u5927\u591a\u6570\u4eba\u8ba4\u8bc6\u5230\u5176\u865a\u5047\u6027\uff0c\u9519\u8bef\u4fe1\u606f\u4ecd\u80fd\u6301\u7eed\u4f20\u64ad\u3002", "motivation": "\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u4e2d\u4ee4\u4eba\u56f0\u60d1\u7684\u73b0\u8c61\uff0c\u5982\u4e2a\u4eba\u79c1\u4e0b\u4fe1\u5ff5\u4e0e\u516c\u5f00\u4f20\u64ad\u5185\u5bb9\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4ee5\u53ca\u4e3a\u4ec0\u4e48\u9519\u8bef\u4fe1\u606f\u5728\u660e\u77e5\u5176\u865a\u5047\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u5e7f\u6cdb\u4f20\u64ad\u3002", "method": "\u91c7\u7528\u5fc3\u7406\u535a\u5f08\u7406\u8bba\u6a21\u578b\uff0c\u533a\u5206\u4e2a\u4f53\u63a5\u6536\u4fe1\u606f\u540e\u7684\u53cd\u5e94\u51b3\u7b56\uff08\u516c\u5f00\u652f\u6301\u3001\u4fdd\u6301\u6c89\u9ed8\u6216\u516c\u5f00\u8d28\u7591\uff09\u548c\u8f6c\u53d1\u51b3\u7b56\uff0c\u5e76\u8003\u8651\u4e2a\u4f53\u4fe1\u5ff5\u4e0e\u793e\u4f1a\u7f51\u7edc\u4fe1\u5ff5\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5f53\u4e2a\u4f53\u5bf9\u540c\u4f34\u538b\u529b\u9ad8\u5ea6\u654f\u611f\u4e14\u7f51\u7edc\u7ed3\u6784\u6781\u5316\u65f6\uff0c\u5373\u4f7f\u591a\u6570\u4eba\u4e0d\u771f\u6b63\u76f8\u4fe1\u9519\u8bef\u4fe1\u606f\uff0c\u8be5\u4fe1\u606f\u4ecd\u80fd\u5728\u6ca1\u6709\u516c\u5f00\u62b5\u5236\u7684\u60c5\u51b5\u4e0b\u5e7f\u6cdb\u4f20\u64ad\u3002", "conclusion": "\u4ec5\u63d0\u9ad8\u4fe1\u606f\u7d20\u517b\u4e0d\u8db3\u4ee5\u904f\u5236\u9519\u8bef\u4fe1\u606f\u7684\u4f20\u64ad\uff0c\u9700\u8981\u5173\u6ce8\u793e\u4f1a\u7f51\u7edc\u7ed3\u6784\u548c\u540c\u4f34\u538b\u529b\u5bf9\u4fe1\u606f\u4f20\u64ad\u7684\u5f71\u54cd\u3002"}}
{"id": "2510.08893", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.08893", "abs": "https://arxiv.org/abs/2510.08893", "authors": ["Christopher J. Paciorek", "Daniel Cooley"], "title": "Quantifying Very Extreme Precipitation and Temperature Using Huge Ensembles Generated by Machine Learning-based Climate Model Emulators", "comment": "28 pages, 11 figures, 5 appendix figures", "summary": "Weather extremes produce major impacts on society and ecosystems and are\nlikely to change in likelihood and magnitude with climate change. However, very\nlow probability events are hard to characterize statistically using\nobservations or climate model output because of short records/runs. For\nprecipitation, consideration of such events arises in quantifying Probable\nMaximum Precipitation (PMP), namely estimating extreme precipitation magnitudes\nfor designing and assessing critical infrastructure. A recent National\nAcademies report on modernizing PMP estimation proposed using huge climate\nmodel-based ensembles to estimate extreme quantiles, possibly through machine\nlearning-based ensemble boosting. Here we assess such an approach for the\ncontiguous United States using a huge ensemble (10560 years) from a\nstate-of-the-art emulator (ACE2) trained on ERA5 reanalysis. The results\nindicate that one can practically estimate very extreme precipitation and\ntemperature quantiles using appropriate statistical extreme value techniques.\nMore specifically, the results provide evidence for (1) the use of\nthreshold-exceedance methods with a sufficiently high threshold for reliable\nestimation (necessary for precipitation), (2) the robustness of results to\nvariations in extremes by season and storm type, and (3) well-constrained\nstatistical uncertainty. Our results also show that the emulator produces\nextremes outside the range of the ERA5 training data. While this suggests that\nsuch emulators have potential for quantifying the climatology of extremes, we\ndo not extensively investigate if this particular emulator is fit for purpose.\nOur focus is on how to use huge ensembles to estimate very extreme statistics,\nand we expect the results to be relevant for future improved emulators.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u6c14\u5019\u6a21\u578b\u96c6\u5408\u548c\u6781\u7aef\u503c\u7edf\u8ba1\u6280\u672f\u6765\u4f30\u8ba1\u6781\u7aef\u964d\u6c34\u548c\u6e29\u5ea6\u7684\u5206\u4f4d\u6570\uff0c\u4e3a\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u8bbe\u8ba1\u63d0\u4f9b\u6982\u7387\u6700\u5927\u964d\u6c34\u4f30\u8ba1\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u4e0b\u6781\u7aef\u5929\u6c14\u4e8b\u4ef6\u7684\u6982\u7387\u548c\u5f3a\u5ea6\u53ef\u80fd\u53d1\u751f\u53d8\u5316\uff0c\u4f46\u89c2\u6d4b\u6570\u636e\u6216\u6c14\u5019\u6a21\u578b\u8f93\u51fa\u7684\u8bb0\u5f55\u8f83\u77ed\uff0c\u96be\u4ee5\u7edf\u8ba1\u8868\u5f81\u6781\u4f4e\u6982\u7387\u4e8b\u4ef6\u3002\u9700\u8981\u6539\u8fdb\u6982\u7387\u6700\u5927\u964d\u6c34(PMP)\u7684\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eERA5\u518d\u5206\u6790\u8bad\u7ec3\u7684\u6700\u5148\u8fdb\u6a21\u62df\u5668(ACE2)\u751f\u6210\u7684\u5927\u578b\u96c6\u5408(10560\u5e74)\uff0c\u5e94\u7528\u9002\u5f53\u7684\u7edf\u8ba1\u6781\u7aef\u503c\u6280\u672f\uff0c\u7279\u522b\u662f\u9608\u503c\u8d85\u8d8a\u65b9\u6cd5\u3002", "result": "\u53ef\u4ee5\u5b9e\u9645\u4f30\u8ba1\u975e\u5e38\u6781\u7aef\u7684\u964d\u6c34\u548c\u6e29\u5ea6\u5206\u4f4d\u6570\uff1b\u9608\u503c\u8d85\u8d8a\u65b9\u6cd5\u5728\u8db3\u591f\u9ad8\u7684\u9608\u503c\u4e0b\u53ef\u9760\uff1b\u7ed3\u679c\u5bf9\u5b63\u8282\u548c\u98ce\u66b4\u7c7b\u578b\u7684\u53d8\u5316\u5177\u6709\u9c81\u68d2\u6027\uff1b\u7edf\u8ba1\u4e0d\u786e\u5b9a\u6027\u5f97\u5230\u826f\u597d\u7ea6\u675f\uff1b\u6a21\u62df\u5668\u80fd\u4ea7\u751f\u8d85\u51fa\u8bad\u7ec3\u6570\u636e\u8303\u56f4\u7684\u6781\u7aef\u503c\u3002", "conclusion": "\u5927\u578b\u96c6\u5408\u65b9\u6cd5\u6709\u6f5c\u529b\u91cf\u5316\u6781\u7aef\u6c14\u5019\u5b66\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u672a\u6765\u6539\u8fdb\u7684\u6a21\u62df\u5668\u63d0\u4f9b\u4e86\u5982\u4f55\u4f7f\u7528\u5927\u578b\u96c6\u5408\u4f30\u8ba1\u6781\u7aef\u7edf\u8ba1\u91cf\u7684\u76f8\u5173\u6307\u5bfc\u3002"}}
{"id": "2510.08619", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08619", "abs": "https://arxiv.org/abs/2510.08619", "authors": ["Tennison Liu", "Silas Ruhrberg Est\u00e9vez", "David L. Bentley", "Mihaela van der Schaar"], "title": "Hypothesis Hunting with Evolving Networks of Autonomous Scientific Agents", "comment": null, "summary": "Large-scale scientific datasets -- spanning health biobanks, cell atlases,\nEarth reanalyses, and more -- create opportunities for exploratory discovery\nunconstrained by specific research questions. We term this process hypothesis\nhunting: the cumulative search for insight through sustained exploration across\nvast and complex hypothesis spaces. To support it, we introduce AScience, a\nframework modeling discovery as the interaction of agents, networks, and\nevaluation norms, and implement it as ASCollab, a distributed system of\nLLM-based research agents with heterogeneous behaviors. These agents\nself-organize into evolving networks, continually producing and peer-reviewing\nfindings under shared standards of evaluation. Experiments show that such\nsocial dynamics enable the accumulation of expert-rated results along the\ndiversity-quality-novelty frontier, including rediscoveries of established\nbiomarkers, extensions of known pathways, and proposals of new therapeutic\ntargets. While wet-lab validation remains indispensable, our experiments on\ncancer cohorts demonstrate that socially structured, agentic networks can\nsustain exploratory hypothesis hunting at scale.", "AI": {"tldr": "\u63d0\u51faAScience\u6846\u67b6\u548cASCollab\u7cfb\u7edf\uff0c\u901a\u8fc7LLM\u667a\u80fd\u4f53\u7f51\u7edc\u8fdb\u884c\u5927\u89c4\u6a21\u79d1\u5b66\u5047\u8bbe\u63a2\u7d22\uff0c\u5728\u764c\u75c7\u961f\u5217\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u53d1\u73b0\u5df2\u77e5\u751f\u7269\u6807\u5fd7\u7269\u3001\u6269\u5c55\u5df2\u77e5\u901a\u8def\u548c\u63d0\u51fa\u65b0\u6cbb\u7597\u9776\u70b9\u7684\u80fd\u529b\u3002", "motivation": "\u5927\u89c4\u6a21\u79d1\u5b66\u6570\u636e\u96c6\u4e3a\u65e0\u7279\u5b9a\u7814\u7a76\u95ee\u9898\u7684\u63a2\u7d22\u6027\u53d1\u73b0\u521b\u9020\u4e86\u673a\u4f1a\uff0c\u9700\u8981\u652f\u6301\u5728\u590d\u6742\u5047\u8bbe\u7a7a\u95f4\u4e2d\u8fdb\u884c\u6301\u7eed\u63a2\u7d22\u7684\u5047\u8bbe\u72e9\u730e\u8fc7\u7a0b\u3002", "method": "\u5f15\u5165AScience\u6846\u67b6\uff0c\u5c06\u53d1\u73b0\u5efa\u6a21\u4e3a\u667a\u80fd\u4f53\u3001\u7f51\u7edc\u548c\u8bc4\u4f30\u89c4\u8303\u7684\u4ea4\u4e92\uff0c\u5b9e\u73b0\u4e3aASCollab\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0c\u5305\u542b\u5177\u6709\u5f02\u8d28\u884c\u4e3a\u7684LLM\u7814\u7a76\u667a\u80fd\u4f53\uff0c\u8fd9\u4e9b\u667a\u80fd\u4f53\u5728\u5171\u4eab\u8bc4\u4f30\u6807\u51c6\u4e0b\u81ea\u7ec4\u7ec7\u6210\u6f14\u5316\u7f51\u7edc\uff0c\u6301\u7eed\u4ea7\u751f\u548c\u540c\u884c\u8bc4\u5ba1\u53d1\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u793e\u4f1a\u52a8\u6001\u80fd\u591f\u5728\u591a\u6837\u6027-\u8d28\u91cf-\u65b0\u9896\u6027\u524d\u6cbf\u79ef\u7d2f\u4e13\u5bb6\u8bc4\u7ea7\u7ed3\u679c\uff0c\u5305\u62ec\u91cd\u65b0\u53d1\u73b0\u5df2\u5efa\u7acb\u7684\u751f\u7269\u6807\u5fd7\u7269\u3001\u6269\u5c55\u5df2\u77e5\u901a\u8def\u548c\u63d0\u51fa\u65b0\u7684\u6cbb\u7597\u9776\u70b9\u3002", "conclusion": "\u867d\u7136\u6e7f\u5b9e\u9a8c\u5ba4\u9a8c\u8bc1\u4ecd\u7136\u4e0d\u53ef\u6216\u7f3a\uff0c\u4f46\u5728\u764c\u75c7\u961f\u5217\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0c\u793e\u4f1a\u7ed3\u6784\u5316\u7684\u667a\u80fd\u4f53\u7f51\u7edc\u80fd\u591f\u5927\u89c4\u6a21\u6301\u7eed\u8fdb\u884c\u63a2\u7d22\u6027\u5047\u8bbe\u72e9\u730e\u3002"}}
{"id": "2510.09464", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.09464", "abs": "https://arxiv.org/abs/2510.09464", "authors": ["Patrick Gerard", "Luca Luceria", "Leonardo Blas", "Emilio Ferrara"], "title": "Cross-Platform Narrative Prediction: Leveraging Platform-Invariant Discourse Networks", "comment": "13 pages, 4 figures", "summary": "Online narratives spread unevenly across platforms, with content emerging on\none site often appearing on others, hours, days or weeks later. Existing\ncross-platform information diffusion models often treat platforms as isolated\nsystems, disregarding cross-platform activity that might make these patterns\nmore predictable. In this work, we frame cross-platform prediction as a network\nproximity problem: rather than tracking individual users across platforms or\nrelying on brittle signals like shared URLs or hashtags, we construct\nplatform-invariant discourse networks that link users through shared narrative\nengagement. We show that cross-platform neighbor proximity provides a strong\npredictive signal: adoption patterns follow discourse network structure even\nwithout direct cross-platform influence. Our highly-scalable approach\nsubstantially outperforms diffusion models and other baselines while requiring\nless than 3% of active users to make predictions. We also validate our\nframework through retrospective deployment. We sequentially process a\ndatastream of 5.7M social media posts occurred during the 2024 U.S. election,\nto simulate real-time collection from four platforms (X, TikTok, Truth Social,\nand Telegram): our framework successfully identified emerging narratives,\nincluding crises-related rumors, yielding over 94% AUC with sufficient lead\ntime to support proactive intervention.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7f51\u7edc\u90bb\u8fd1\u5ea6\u7684\u8de8\u5e73\u53f0\u4fe1\u606f\u4f20\u64ad\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u5e73\u53f0\u65e0\u5173\u7684\u8bdd\u8bed\u7f51\u7edc\u6765\u9884\u6d4b\u5185\u5bb9\u5728\u4e0d\u540c\u5e73\u53f0\u95f4\u7684\u4f20\u64ad\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u8de8\u5e73\u53f0\u4fe1\u606f\u4f20\u64ad\u6a21\u578b\u5f80\u5f80\u5c06\u5404\u5e73\u53f0\u89c6\u4e3a\u5b64\u7acb\u7cfb\u7edf\uff0c\u5ffd\u7565\u4e86\u8de8\u5e73\u53f0\u6d3b\u52a8\u53ef\u80fd\u4f7f\u4f20\u64ad\u6a21\u5f0f\u66f4\u53ef\u9884\u6d4b\u3002", "method": "\u5c06\u8de8\u5e73\u53f0\u9884\u6d4b\u6784\u5efa\u4e3a\u7f51\u7edc\u90bb\u8fd1\u5ea6\u95ee\u9898\uff0c\u901a\u8fc7\u5171\u4eab\u53d9\u4e8b\u53c2\u4e0e\u8fde\u63a5\u7528\u6237\u6784\u5efa\u5e73\u53f0\u65e0\u5173\u7684\u8bdd\u8bed\u7f51\u7edc\uff0c\u5229\u7528\u8de8\u5e73\u53f0\u90bb\u5c45\u90bb\u8fd1\u5ea6\u4f5c\u4e3a\u9884\u6d4b\u4fe1\u53f7\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u4f20\u64ad\u6a21\u578b\u548c\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4ec5\u9700\u4e0d\u52303%\u7684\u6d3b\u8dc3\u7528\u6237\u5373\u53ef\u8fdb\u884c\u9884\u6d4b\uff0c\u57282024\u5e74\u7f8e\u56fd\u9009\u4e3e\u671f\u95f4\u7684570\u4e07\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u6d4b\u8bd5\u4e2d\u8fbe\u523094%\u4ee5\u4e0a\u7684AUC\u3002", "conclusion": "\u8bdd\u8bed\u7f51\u7edc\u7ed3\u6784\u4e3a\u8de8\u5e73\u53f0\u4fe1\u606f\u4f20\u64ad\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u9884\u6d4b\u4fe1\u53f7\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u9ad8\u5ea6\u53ef\u6269\u5c55\u6027\uff0c\u80fd\u591f\u8bc6\u522b\u65b0\u5174\u53d9\u4e8b\u5e76\u652f\u6301\u4e3b\u52a8\u5e72\u9884\u3002"}}
{"id": "2510.08891", "categories": ["cs.ET", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.08891", "abs": "https://arxiv.org/abs/2510.08891", "authors": ["Ruijie Wang", "Jie Lu", "Bo Pei", "Evonne Jones", "Jamey Brinson", "Timothy Brown"], "title": "Designing and Evaluating an AI-driven Immersive Multidisciplinary Simulation (AIMS) for Interprofessional Education", "comment": "15 pages", "summary": "Interprofessional education has long relied on case studies and the use of\nstandardized patients to support teamwork, communication, and related\ncollaborative competencies among healthcare professionals. However, traditional\napproaches are often limited by cost, scalability, and inability to mimic the\ndynamic complexity of real-world clinical scenarios. To address these\nchallenges, we designed and developed AIMS (AI-Enhanced Immersive\nMultidisciplinary Simulations), a virtual simulation that integrates a large\nlanguage model (Gemini-2.5-Flash), a Unity-based virtual environment engine,\nand a character creation pipeline to support synchronized, multimodal\ninteractions between the user and the virtual patient. AIMS was designed to\nenhance collaborative clinical reasoning and health promotion competencies\namong students from pharmacy, medicine, nursing, and social work. A formal\nusability testing session was conducted which participants assumed professional\nroles on a healthcare team and engaged in a mix of scripted and unscripted\nconversations. Participants explored the patient's symptoms, social context,\nand care needs. Usability issues were identified (e.g., audio routing, response\nlatency) and used to guide subsequent refinements. Findings in general suggest\nthat AIMS supports realistic, profession-specific and contextually appropriate\nconversations. We discussed both technical and pedagogical innovations of AIMS\nand concluded with future directions.", "AI": {"tldr": "\u5f00\u53d1\u4e86AIMS\u865a\u62df\u6a21\u62df\u7cfb\u7edf\uff0c\u6574\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548cUnity\u5f15\u64ce\uff0c\u7528\u4e8e\u8de8\u4e13\u4e1a\u533b\u7597\u6559\u80b2\uff0c\u652f\u6301\u5b66\u751f\u4e0e\u865a\u62df\u60a3\u8005\u8fdb\u884c\u591a\u6a21\u6001\u4e92\u52a8\uff0c\u63d0\u5347\u4e34\u5e8a\u63a8\u7406\u548c\u5065\u5eb7\u4fc3\u8fdb\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u8de8\u4e13\u4e1a\u6559\u80b2\u65b9\u6cd5\u53d7\u9650\u4e8e\u6210\u672c\u3001\u53ef\u6269\u5c55\u6027\u548c\u65e0\u6cd5\u6a21\u62df\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\u7684\u52a8\u6001\u590d\u6742\u6027\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1AIMS\u7cfb\u7edf\uff0c\u96c6\u6210Gemini-2.5-Flash\u5927\u8bed\u8a00\u6a21\u578b\u3001Unity\u865a\u62df\u73af\u5883\u548c\u89d2\u8272\u521b\u5efa\u6d41\u7a0b\uff0c\u652f\u6301\u7528\u6237\u4e0e\u865a\u62df\u60a3\u8005\u7684\u540c\u6b65\u591a\u6a21\u6001\u4ea4\u4e92\u3002", "result": "\u53ef\u7528\u6027\u6d4b\u8bd5\u663e\u793aAIMS\u652f\u6301\u771f\u5b9e\u3001\u4e13\u4e1a\u7279\u5b9a\u4e14\u60c5\u5883\u9002\u5f53\u7684\u5bf9\u8bdd\uff0c\u8bc6\u522b\u51fa\u97f3\u9891\u8def\u7531\u3001\u54cd\u5e94\u5ef6\u8fdf\u7b49\u6280\u672f\u95ee\u9898\u5e76\u6307\u5bfc\u6539\u8fdb\u3002", "conclusion": "AIMS\u5728\u6280\u672f\u548c\u6559\u5b66\u521b\u65b0\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u8ba8\u8bba\u4e86\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2510.08753", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.08753", "abs": "https://arxiv.org/abs/2510.08753", "authors": ["A. Wang", "C. Jiang", "M. Przystupa", "J. Valentine", "M. Jagersand"], "title": "Point and Go: Intuitive Reference Frame Reallocation in Mode Switching for Assistive Robotics", "comment": "7 Pages, 5 figures", "summary": "Operating high degree of freedom robots can be difficult for users of\nwheelchair mounted robotic manipulators. Mode switching in Cartesian space has\nseveral drawbacks such as unintuitive control reference frames, separate\ntranslation and orientation control, and limited movement capabilities that\nhinder performance. We propose Point and Go mode switching, which reallocates\nthe Cartesian mode switching reference frames into a more intuitive action\nspace comprised of new translation and rotation modes. We use a novel sweeping\nmotion to point the gripper, which defines the new translation axis along the\nrobot base frame's horizontal plane. This creates an intuitive `point and go'\ntranslation mode that allows the user to easily perform complex, human-like\nmovements without switching control modes. The system's rotation mode combines\nposition control with a refined end-effector oriented frame that provides\nprecise and consistent robot actions in various end-effector poses. We verified\nits effectiveness through initial experiments, followed by a three-task user\nstudy that compared our method to Cartesian mode switching and a state of the\nart learning method. Results show that Point and Go mode switching reduced\ncompletion times by 31\\%, pauses by 41\\%, and mode switches by 33\\%, while\nreceiving significantly favorable responses in user surveys.", "AI": {"tldr": "\u63d0\u51faPoint and Go\u6a21\u5f0f\u5207\u6362\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u65b0\u5206\u914d\u7b1b\u5361\u5c14\u6a21\u5f0f\u5207\u6362\u53c2\u8003\u7cfb\uff0c\u521b\u5efa\u66f4\u76f4\u89c2\u7684\u5e73\u79fb\u548c\u65cb\u8f6c\u6a21\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u8f6e\u6905\u673a\u5668\u4eba\u64cd\u4f5c\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7b1b\u5361\u5c14\u7a7a\u95f4\u6a21\u5f0f\u5207\u6362\u5b58\u5728\u63a7\u5236\u53c2\u8003\u7cfb\u4e0d\u76f4\u89c2\u3001\u5e73\u79fb\u548c\u65cb\u8f6c\u63a7\u5236\u5206\u79bb\u3001\u8fd0\u52a8\u80fd\u529b\u6709\u9650\u7b49\u95ee\u9898\uff0c\u5f71\u54cd\u8f6e\u6905\u673a\u5668\u4eba\u64cd\u4f5c\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u65b0\u9896\u7684\u626b\u63a0\u8fd0\u52a8\u6307\u5411\u5939\u722a\uff0c\u5728\u673a\u5668\u4eba\u57fa\u5ea7\u6c34\u5e73\u9762\u5b9a\u4e49\u65b0\u7684\u5e73\u79fb\u8f74\uff0c\u521b\u5efa\u76f4\u89c2\u7684'\u6307\u5411\u5e76\u79fb\u52a8'\u5e73\u79fb\u6a21\u5f0f\uff1b\u65cb\u8f6c\u6a21\u5f0f\u7ed3\u5408\u4f4d\u7f6e\u63a7\u5236\u548c\u7cbe\u70bc\u7684\u672b\u7aef\u6267\u884c\u5668\u5b9a\u5411\u6846\u67b6\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u76f8\u6bd4\u7b1b\u5361\u5c14\u6a21\u5f0f\u5207\u6362\u548c\u6700\u5148\u8fdb\u5b66\u4e60\u65b9\u6cd5\uff0cPoint and Go\u5c06\u5b8c\u6210\u65f6\u95f4\u51cf\u5c1131%\uff0c\u6682\u505c\u65f6\u95f4\u51cf\u5c1141%\uff0c\u6a21\u5f0f\u5207\u6362\u51cf\u5c1133%\uff0c\u7528\u6237\u8bc4\u4ef7\u663e\u8457\u66f4\u4f18\u3002", "conclusion": "Point and Go\u6a21\u5f0f\u5207\u6362\u901a\u8fc7\u66f4\u76f4\u89c2\u7684\u52a8\u4f5c\u7a7a\u95f4\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u6a21\u5f0f\u5207\u6362\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8f6e\u6905\u673a\u5668\u4eba\u64cd\u4f5c\u6027\u80fd\u548c\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2510.08937", "categories": ["eess.SY", "cs.IT", "cs.SY", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.08937", "abs": "https://arxiv.org/abs/2510.08937", "authors": ["Omer Gokalp Serbetci", "Lei Chu", "Andreas F. Molisch"], "title": "Cognitive Radio for Asymmetric Cellular Downlink with Multi-User MIMO", "comment": null, "summary": "Cognitive radio (CR) is an important technique for improving spectral\nefficiency, letting a secondary system operate in a wireless spectrum when the\nprimary system does not make use of it. While it has been widely explored over\nthe past 25 years, many common assumptions are not aligned with the realities\nof 5G networks. In this paper, we consider the CR problem for the following\nsetup: (i) infrastructure-based systems, where downlink transmissions might\noccur to receivers whose positions are not, or not exactly, known; (ii)\nmulti-beam antennas at both primary and secondary base stations. We formulate a\ndetailed protocol to determine when secondary transmissions into different beam\ndirections can interfere with primary users at potential locations and create\nprobability-based interference rules. We then analyze the \"catastrophic\ninterference\" probability and the \"missed transmission opportunity\"\nprobability, as well as the achievable throughput, as a function of the\ntransmit powers of the primary and secondary base stations and the sensing\nwindow of the secondary base station. Results can serve to more realistically\nassess the spectral efficiency gains in 5G infrastructure-based cognitive\nsystems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e865G\u57fa\u7840\u8bbe\u65bd\u7f51\u7edc\u4e2d\u8ba4\u77e5\u65e0\u7ebf\u7535\u7cfb\u7edf\u7684\u5e72\u6270\u7ba1\u7406\u95ee\u9898\uff0c\u8003\u8651\u4e86\u591a\u6ce2\u675f\u5929\u7ebf\u548c\u63a5\u6536\u5668\u4f4d\u7f6e\u4e0d\u786e\u5b9a\u6027\u7684\u73b0\u5b9e\u6761\u4ef6\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6982\u7387\u7684\u5e72\u6270\u89c4\u5219\u6765\u5e73\u8861\u9891\u8c31\u6548\u7387\u548c\u5e72\u6270\u98ce\u9669\u3002", "motivation": "\u4f20\u7edf\u8ba4\u77e5\u65e0\u7ebf\u7535\u7684\u8bb8\u591a\u5047\u8bbe\u4e0e5G\u7f51\u7edc\u73b0\u5b9e\u4e0d\u7b26\uff0c\u7279\u522b\u662f\u5728\u57fa\u7840\u8bbe\u65bd\u7cfb\u7edf\u548c\u591a\u6ce2\u675f\u5929\u7ebf\u573a\u666f\u4e0b\uff0c\u9700\u8981\u66f4\u51c6\u786e\u7684\u5e72\u6270\u5206\u6790\u6765\u8bc4\u4f30\u9891\u8c31\u6548\u7387\u589e\u76ca\u3002", "method": "\u5236\u5b9a\u4e86\u8be6\u7ec6\u7684\u534f\u8bae\u6765\u786e\u5b9a\u6b21\u7ea7\u4f20\u8f93\u5728\u4e0d\u540c\u6ce2\u675f\u65b9\u5411\u4e0a\u53ef\u80fd\u5e72\u6270\u4e3b\u7528\u6237\u7684\u6982\u7387\uff0c\u521b\u5efa\u4e86\u57fa\u4e8e\u6982\u7387\u7684\u5e72\u6270\u89c4\u5219\uff0c\u5e76\u5206\u6790\u4e86\u5e72\u6270\u6982\u7387\u3001\u9519\u5931\u4f20\u8f93\u673a\u4f1a\u6982\u7387\u548c\u53ef\u8fbe\u541e\u5410\u91cf\u3002", "result": "\u5206\u6790\u4e86\u707e\u96be\u6027\u5e72\u6270\u6982\u7387\u3001\u9519\u5931\u4f20\u8f93\u673a\u4f1a\u6982\u7387\u548c\u53ef\u8fbe\u541e\u5410\u91cf\uff0c\u8fd9\u4e9b\u6307\u6807\u4f5c\u4e3a\u4e3b\u6b21\u57fa\u7ad9\u53d1\u5c04\u529f\u7387\u548c\u6b21\u7ea7\u57fa\u7ad9\u611f\u77e5\u7a97\u53e3\u7684\u51fd\u6570\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u80fd\u591f\u66f4\u73b0\u5b9e\u5730\u8bc4\u4f305G\u57fa\u7840\u8bbe\u65bd\u8ba4\u77e5\u7cfb\u7edf\u7684\u9891\u8c31\u6548\u7387\u589e\u76ca\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2510.09109", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.09109", "abs": "https://arxiv.org/abs/2510.09109", "authors": ["Philipp Bach", "Victor Chernozhukov", "Carlos Cinelli", "Lin Jia", "Sven Klaassen", "Nils Skotara", "Martin Spindler"], "title": "Sensitivity Analysis for Causal ML: A Use Case at Booking.com", "comment": null, "summary": "Causal Machine Learning has emerged as a powerful tool for flexibly\nestimating causal effects from observational data in both industry and\nacademia. However, causal inference from observational data relies on\nuntestable assumptions about the data-generating process, such as the absence\nof unobserved confounders. When these assumptions are violated, causal effect\nestimates may become biased, undermining the validity of research findings. In\nthese contexts, sensitivity analysis plays a crucial role, by enabling data\nscientists to assess the robustness of their findings to plausible violations\nof unconfoundedness. This paper introduces sensitivity analysis and\ndemonstrates its practical relevance through a (simulated) data example based\non a use case at Booking.com. We focus our presentation on a recently proposed\nmethod by Chernozhukov et al. (2023), which derives general non-parametric\nbounds on biases due to omitted variables, and is fully compatible with (though\nnot limited to) modern inferential tools of Causal Machine Learning. By\npresenting this use case, we aim to raise awareness of sensitivity analysis and\nhighlight its importance in real-world scenarios.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u654f\u611f\u6027\u5206\u6790\u5728\u56e0\u679c\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u901a\u8fc7Booking.com\u7684\u6a21\u62df\u7528\u4f8b\u5c55\u793a\u4e86\u5982\u4f55\u8bc4\u4f30\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u5bf9\u672a\u89c2\u6d4b\u6df7\u6742\u56e0\u7d20\u7684\u7a33\u5065\u6027\u3002", "motivation": "\u56e0\u679c\u673a\u5668\u5b66\u4e60\u4ece\u89c2\u6d4b\u6570\u636e\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\u65f6\u4f9d\u8d56\u4e0d\u53ef\u68c0\u9a8c\u7684\u5047\u8bbe\uff08\u5982\u65e0\u672a\u89c2\u6d4b\u6df7\u6742\u56e0\u7d20\uff09\uff0c\u5f53\u8fd9\u4e9b\u5047\u8bbe\u88ab\u8fdd\u53cd\u65f6\uff0c\u4f30\u8ba1\u7ed3\u679c\u4f1a\u4ea7\u751f\u504f\u5dee\uff0c\u5f71\u54cd\u7814\u7a76\u7ed3\u8bba\u7684\u6709\u6548\u6027\u3002", "method": "\u91c7\u7528Chernozhukov\u7b49\u4eba(2023)\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u63a8\u5bfc\u4e86\u56e0\u9057\u6f0f\u53d8\u91cf\u5bfc\u81f4\u7684\u504f\u5dee\u7684\u901a\u7528\u975e\u53c2\u6570\u8fb9\u754c\uff0c\u5e76\u4e0e\u73b0\u4ee3\u56e0\u679c\u673a\u5668\u5b66\u4e60\u63a8\u65ad\u5de5\u5177\u5b8c\u5168\u517c\u5bb9\u3002", "result": "\u901a\u8fc7Booking.com\u7684\u6a21\u62df\u6570\u636e\u7528\u4f8b\u5c55\u793a\u4e86\u654f\u611f\u6027\u5206\u6790\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u80fd\u591f\u5e2e\u52a9\u6570\u636e\u79d1\u5b66\u5bb6\u8bc4\u4f30\u7814\u7a76\u7ed3\u679c\u5bf9\u672a\u89c2\u6d4b\u6df7\u6742\u56e0\u7d20\u7684\u7a33\u5065\u6027\u3002", "conclusion": "\u654f\u611f\u6027\u5206\u6790\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u672c\u6587\u65e8\u5728\u63d0\u9ad8\u5bf9\u654f\u611f\u6027\u5206\u6790\u7684\u8ba4\u8bc6\u5e76\u5f3a\u8c03\u5176\u5728\u56e0\u679c\u63a8\u65ad\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.08885", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.08885", "abs": "https://arxiv.org/abs/2510.08885", "authors": ["Shomir Wilson"], "title": "Rethinking How We Discuss the Guidance of Student Researchers in Computing", "comment": "7 pages. Accepted to SIGCSE 2026. DOI pending", "summary": "Computing faculty at research universities are often expected to guide the\nwork of undergraduate and graduate student researchers. This guidance is\ntypically called advising or mentoring, but these terms belie the complexity of\nthe relationship, which includes several related but distinct roles. I examine\nthe guidance of student researchers in computing (abbreviated to research\nguidance or guidance throughout) within a facet framework, creating an\ninventory of roles that faculty members can hold. By expanding and\ndisambiguating the language of guidance, this approach reveals the full breadth\nof faculty responsibilities toward student researchers, and it facilitates\ndiscussing conflicts between those responsibilities. Additionally, the facet\nframework permits greater flexibility for students seeking guidance, allowing\nthem a robust support network without implying inadequacy in an individual\nfaculty member's skills. I further argue that an over-reliance on singular\nterms like advising or mentoring for the guidance of student researchers\nobscures the full scope of faculty responsibilities and interferes with\nimprovement of those as skills. Finally, I provide suggestions for how the\nfacet framework can be utilized by faculty and institutions, and how parts of\nit can be discussed with students for their benefit.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u9762\u4f53\u6846\u67b6\u6765\u5206\u6790\u8ba1\u7b97\u79d1\u5b66\u9886\u57df\u6559\u5e08\u5bf9\u5b66\u751f\u7684\u7814\u7a76\u6307\u5bfc\uff0c\u5c06\u4f20\u7edf\u7684\u5355\u4e00\"\u6307\u5bfc\"\u6216\"\u5bfc\u5e08\"\u6982\u5ff5\u5206\u89e3\u4e3a\u591a\u4e2a\u5177\u4f53\u89d2\u8272\uff0c\u4ee5\u66f4\u5168\u9762\u5730\u7406\u89e3\u6559\u5e08\u8d23\u4efb\u3002", "motivation": "\u4f20\u7edf\u4e0a\u4f7f\u7528\"\u6307\u5bfc\"\u6216\"\u5bfc\u5e08\"\u7b49\u5355\u4e00\u672f\u8bed\u6765\u63cf\u8ff0\u6559\u5e08\u5bf9\u5b66\u751f\u7684\u7814\u7a76\u6307\u5bfc\u5173\u7cfb\uff0c\u4f46\u8fd9\u4e9b\u672f\u8bed\u63a9\u76d6\u4e86\u6307\u5bfc\u5173\u7cfb\u7684\u590d\u6742\u6027\uff0c\u65e0\u6cd5\u5145\u5206\u4f53\u73b0\u6559\u5e08\u7684\u591a\u91cd\u8d23\u4efb\u3002", "method": "\u91c7\u7528\u591a\u9762\u4f53\u6846\u67b6\u65b9\u6cd5\uff0c\u521b\u5efa\u6559\u5e08\u89d2\u8272\u7684\u8be6\u7ec6\u6e05\u5355\uff0c\u5c06\u7814\u7a76\u6307\u5bfc\u5206\u89e3\u4e3a\u591a\u4e2a\u76f8\u5173\u4f46\u4e0d\u540c\u7684\u89d2\u8272\uff0c\u6269\u5c55\u548c\u6f84\u6e05\u6307\u5bfc\u8bed\u8a00\u3002", "result": "\u8be5\u6846\u67b6\u63ed\u793a\u4e86\u6559\u5e08\u5bf9\u5b66\u751f\u7814\u7a76\u8005\u7684\u5168\u90e8\u8d23\u4efb\u8303\u56f4\uff0c\u4fbf\u4e8e\u8ba8\u8bba\u8d23\u4efb\u95f4\u7684\u51b2\u7a81\uff0c\u5e76\u4e3a\u5b66\u751f\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u652f\u6301\u7f51\u7edc\u3002", "conclusion": "\u8fc7\u5ea6\u4f9d\u8d56\u5355\u4e00\u672f\u8bed\u4f1a\u63a9\u76d6\u6559\u5e08\u8d23\u4efb\u7684\u5b8c\u6574\u8303\u56f4\u5e76\u963b\u788d\u6280\u80fd\u6539\u8fdb\uff0c\u591a\u9762\u4f53\u6846\u67b6\u53ef\u4e3a\u6559\u5e08\u3001\u673a\u6784\u548c\u5b66\u751f\u63d0\u4f9b\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.08856", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.08856", "abs": "https://arxiv.org/abs/2510.08856", "authors": ["Jheelum Sarkar"], "title": "Who gets hit first and who recovers last? Evidence from Indian Coastal Flood Shock", "comment": "32 pages (21 main text and 11 in Appendix), 15 figures", "summary": "Catastrophic floods directly risk 1.8 billion lives worldwide, most of whom\nare from East and South Asia. How do extreme floods reshape paid labor\noutcomes? To answer this, I focus on a 1-in-100 year flood event in India. I\nfirst combine Sentinel-1 SAR with JRC Global Surface Water dataset to generate\nflood map. Using information from this map in various rounds of periodic labor\nforce surveys, I estimate gender-specific dynamic effects of the flood shock.\nKey results show that men experienced short-lived reduction in their employment\nwhile women faced a delayed but persistent decline in their working hours. Men\nsuffered most in secondary sector and increased their participation in primary\nsector. Women were hit hardest in the tertiary sector. Such sectoral impacts\ncould be attributable to disruptions in infrastructure and physical capital.\nMoreover, marital status and dependency burden further shape the gender\ndifferential effects of the extreme flood event. Results remain robust under\nalternative treatment definitions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u5370\u5ea6\u767e\u5e74\u4e00\u9047\u6d2a\u6c34\u5bf9\u52b3\u52a8\u529b\u5e02\u573a\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u7537\u6027\u5c31\u4e1a\u77ed\u671f\u4e0b\u964d\u4f46\u5f88\u5feb\u6062\u590d\uff0c\u800c\u5973\u6027\u5de5\u4f5c\u65f6\u95f4\u51fa\u73b0\u5ef6\u8fdf\u4f46\u6301\u4e45\u7684\u51cf\u5c11\uff0c\u4e14\u6027\u522b\u5dee\u5f02\u53d7\u5a5a\u59fb\u72b6\u51b5\u548c\u5bb6\u5ead\u8d1f\u62c5\u5f71\u54cd\u3002", "motivation": "\u5168\u7403\u670918\u4ebf\u4eba\u9762\u4e34\u6d2a\u6c34\u98ce\u9669\uff0c\u4e3b\u8981\u96c6\u4e2d\u5728\u4e1c\u4e9a\u548c\u5357\u4e9a\uff0c\u7814\u7a76\u6781\u7aef\u6d2a\u6c34\u5982\u4f55\u91cd\u5851\u6709\u507f\u52b3\u52a8\u529b\u7ed3\u679c\u5bf9\u4e8e\u7406\u89e3\u707e\u5bb3\u7684\u793e\u4f1a\u7ecf\u6d4e\u5f71\u54cd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7ed3\u5408Sentinel-1 SAR\u548cJRC\u5168\u7403\u5730\u8868\u6c34\u6570\u636e\u96c6\u751f\u6210\u6d2a\u6c34\u5730\u56fe\uff0c\u5229\u7528\u591a\u8f6e\u5468\u671f\u6027\u52b3\u52a8\u529b\u8c03\u67e5\u6570\u636e\uff0c\u4f30\u8ba1\u6d2a\u6c34\u51b2\u51fb\u5bf9\u6027\u522b\u7684\u52a8\u6001\u6548\u5e94\u3002", "result": "\u7537\u6027\u5c31\u4e1a\u77ed\u671f\u51cf\u5c11\u4f46\u5f88\u5feb\u6062\u590d\uff0c\u5973\u6027\u5de5\u4f5c\u65f6\u95f4\u5ef6\u8fdf\u4f46\u6301\u4e45\u4e0b\u964d\uff1b\u7537\u6027\u5728\u7b2c\u4e8c\u4ea7\u4e1a\u53d7\u5f71\u54cd\u6700\u5927\u5e76\u8f6c\u5411\u7b2c\u4e00\u4ea7\u4e1a\uff0c\u5973\u6027\u5728\u7b2c\u4e09\u4ea7\u4e1a\u53d7\u5f71\u54cd\u6700\u4e25\u91cd\uff1b\u5a5a\u59fb\u72b6\u51b5\u548c\u5bb6\u5ead\u8d1f\u62c5\u8fdb\u4e00\u6b65\u5851\u9020\u6027\u522b\u5dee\u5f02\u6548\u5e94\u3002", "conclusion": "\u6781\u7aef\u6d2a\u6c34\u5bf9\u52b3\u52a8\u529b\u5e02\u573a\u4ea7\u751f\u663e\u8457\u7684\u6027\u522b\u5dee\u5f02\u5316\u5f71\u54cd\uff0c\u57fa\u7840\u8bbe\u65bd\u548c\u7269\u8d28\u8d44\u672c\u4e2d\u65ad\u53ef\u80fd\u662f\u9020\u6210\u90e8\u95e8\u5dee\u5f02\u7684\u539f\u56e0\uff0c\u653f\u7b56\u5e94\u8003\u8651\u8fd9\u4e9b\u5dee\u5f02\u5316\u7684\u8106\u5f31\u6027\u3002"}}
{"id": "2510.08671", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.08671", "abs": "https://arxiv.org/abs/2510.08671", "authors": ["Milon Bhattacharya", "Milan Kumar"], "title": "Optimizing delivery for quick commerce factoring qualitative assessment of generated routes", "comment": null, "summary": "Indias e-commerce market is projected to grow rapidly, with last-mile\ndelivery accounting for nearly half of operational expenses. Although vehicle\nrouting problem (VRP) based solvers are widely used for delivery planning,\ntheir effectiveness in real-world scenarios is limited due to unstructured\naddresses, incomplete maps, and computational constraints in distance\nestimation. This study proposes a framework that employs large language models\n(LLMs) to critique VRP-generated routes against policy-based criteria, allowing\nlogistics operators to evaluate and prioritise more efficient delivery plans.\nAs a illustration of our approach we generate, annotate and evaluated 400 cases\nusing large language models. Our study found that open-source LLMs identified\nrouting issues with 79% accuracy, while proprietary reasoning models achieved\nreach upto 86%. The results demonstrate that LLM-based evaluation of\nVRP-generated routes can be an effective and scalable layer of evaluation which\ngoes beyond beyond conventional distance and time based metrics. This has\nimplications for improving cost efficiency, delivery reliability, and\nsustainability in last-mile logistics, especially for developing countries like\nIndia.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6765\u8bc4\u4f30\u8f66\u8f86\u8def\u5f84\u89c4\u5212\u751f\u6210\u7684\u914d\u9001\u8def\u7ebf\uff0c\u901a\u8fc7\u7b56\u7565\u6807\u51c6\u8fdb\u884c\u6279\u5224\u6027\u5206\u6790\uff0c\u5728\u5370\u5ea6\u7535\u5546\u7269\u6d41\u573a\u666f\u4e2d\u5b9e\u73b0\u4e8679-86%\u7684\u8def\u7531\u95ee\u9898\u8bc6\u522b\u51c6\u786e\u7387\u3002", "motivation": "\u5370\u5ea6\u7535\u5546\u5e02\u573a\u5feb\u901f\u589e\u957f\uff0c\u6700\u540e\u4e00\u516c\u91cc\u914d\u9001\u5360\u8fd0\u8425\u6210\u672c\u8fd1\u4e00\u534a\u3002\u4f20\u7edfVRP\u6c42\u89e3\u5668\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u53d7\u9650\u4e8e\u975e\u7ed3\u6784\u5316\u5730\u5740\u3001\u4e0d\u5b8c\u6574\u5730\u56fe\u548c\u8ba1\u7b97\u7ea6\u675f\uff0c\u6548\u679c\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u4e8e\u7b56\u7565\u6807\u51c6\u5bf9VRP\u751f\u6210\u7684\u8def\u7531\u8fdb\u884c\u6279\u5224\u6027\u8bc4\u4f30\uff0c\u751f\u6210\u3001\u6807\u6ce8\u5e76\u8bc4\u4f30\u4e86400\u4e2a\u6848\u4f8b\u3002", "result": "\u5f00\u6e90LLM\u8bc6\u522b\u8def\u7531\u95ee\u9898\u7684\u51c6\u786e\u7387\u8fbe\u523079%\uff0c\u4e13\u6709\u63a8\u7406\u6a21\u578b\u6700\u9ad8\u8fbe\u523086%\u3002LLM\u8bc4\u4f30\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u8ddd\u79bb\u548c\u65f6\u95f4\u6307\u6807\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684VRP\u8def\u7531\u8bc4\u4f30\u662f\u4e00\u79cd\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u5c42\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u6210\u672c\u6548\u7387\u3001\u914d\u9001\u53ef\u9760\u6027\u548c\u53ef\u6301\u7eed\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5370\u5ea6\u7b49\u53d1\u5c55\u4e2d\u56fd\u5bb6\u3002"}}
{"id": "2510.09585", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.09585", "abs": "https://arxiv.org/abs/2510.09585", "authors": ["Saeedeh Mohammadi", "Narges Chinichian", "Hannah Doyal", "Kristina Skutilova", "Hao Cui", "Michele d'Errico", "Siobhan Grayson", "Taha Yasseri"], "title": "From Birdwatch to Community Notes, from Twitter to X: four years of community-based content moderation", "comment": null, "summary": "Community Notes (formerly known as Birdwatch) is the first large-scale\ncrowdsourced content moderation initiative that was launched by X (formerly\nknown as Twitter) in January 2021. As the Community Notes model gains momentum\nacross other social media platforms, there is a growing need to assess its\nunderlying dynamics and effectiveness. This Resource paper provides (a) a\nsystematic review of the literature on Community Notes, and (b) a major curated\ndataset and accompanying source code to support future research on Community\nNotes. We parsed Notes and Ratings data from the first four years of the\nprogram and conducted language detection across all Notes. Focusing on\nEnglish-language Notes, we extracted embedded URLs and identified discussion\ntopics in each Note. Additionally, we constructed monthly interaction networks\namong the Contributors. Together with the literature review, these resources\noffer a robust foundation for advancing research on the Community Notes system.", "AI": {"tldr": "\u672c\u6587\u5bf9X\u5e73\u53f0\u7684Community Notes\u7cfb\u7edf\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u5e76\u63d0\u4f9b\u4e86\u6db5\u76d6\u524d\u56db\u5e74\u7684\u6570\u636e\u96c6\u548c\u6e90\u4ee3\u7801\uff0c\u5305\u62ec\u7b14\u8bb0\u5185\u5bb9\u5206\u6790\u3001URL\u63d0\u53d6\u3001\u4e3b\u9898\u8bc6\u522b\u548c\u8d21\u732e\u8005\u4e92\u52a8\u7f51\u7edc\u6784\u5efa\u3002", "motivation": "\u968f\u7740Community Notes\u6a21\u5f0f\u5728\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5e95\u5c42\u52a8\u6001\u548c\u6709\u6548\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u8d44\u6e90\u3002", "method": "\u89e3\u6790\u524d\u56db\u5e74\u7684\u7b14\u8bb0\u548c\u8bc4\u5206\u6570\u636e\uff0c\u8fdb\u884c\u8bed\u8a00\u68c0\u6d4b\uff0c\u63d0\u53d6\u82f1\u6587\u7b14\u8bb0\u4e2d\u7684URL\uff0c\u8bc6\u522b\u8ba8\u8bba\u4e3b\u9898\uff0c\u5e76\u6784\u5efa\u8d21\u732e\u8005\u6708\u5ea6\u4e92\u52a8\u7f51\u7edc\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u6587\u732e\u7efc\u8ff0\u3001\u6570\u636e\u96c6\u548c\u6e90\u4ee3\u7801\u7684\u7efc\u5408\u8d44\u6e90\uff0c\u652f\u6301\u5bf9Community Notes\u7cfb\u7edf\u7684\u6df1\u5165\u7814\u7a76\u3002", "conclusion": "\u8fd9\u4e9b\u8d44\u6e90\u4e3a\u63a8\u8fdbCommunity Notes\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u4f17\u5305\u5185\u5bb9\u5ba1\u6838\u7684\u8fd0\u4f5c\u673a\u5236\u548c\u6548\u679c\u3002"}}
{"id": "2409.00026", "categories": ["cs.CY", "cs.ET", "cs.HC", "A.0; H.0; K.4"], "pdf": "https://arxiv.org/pdf/2409.00026", "abs": "https://arxiv.org/abs/2409.00026", "authors": ["Yonas Kassa"], "title": "Online Advertising is a Regrettable Necessity: On the Dangers of Pay-Walling the Web", "comment": "2 figs", "summary": "The exponential growth of the web and its benefits can be attributed largely\nto its open model where anyone with internet connection can access information\non the web for free. This has created unprecedented opportunities for various\nmembers of society including the most vulnerable, as recognized by\norganizations such as the UN. This again can be attributed to online\nadvertising, which has been the main financier to the open web. However, recent\ntrends of paywalling information and services on the web are creating imminent\ndangers to such open model of the web, inhibiting access for the economically\nvulnerable, and eventually creating digital segregation. In this paper, we\nargue that this emerging model lacks sustainability, exacerbates digital\ndivide, and might lead to collapse of online advertising. We revisit the\nad-supported open web business model and demonstrate how global users actually\npay for the ads they see. Using data on GNI (gross national income) per capita\nand average paywall access costs, we established a simple income-paywall\nexpenditure gap baseline. With this baseline we show that 135 countries with a\ntotal population estimate of 6.56 billion people cannot afford a scenario of a\nfully paywalled web. We further discuss how a mixed model of the so-called\n\"premium services\" creates digital segregation and poses danger to online\nadvertising ecosystem. Finally, we call for further research and policy\ninitiatives to keep the web open and more inclusive with a sustainable business\nmodel.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u4ed8\u8d39\u5899\u5bf9\u4e92\u8054\u7f51\u5f00\u653e\u6a21\u5f0f\u7684\u5a01\u80c1\uff0c\u6307\u51fa\u5b8c\u5168\u4ed8\u8d39\u5899\u5316\u7684\u7f51\u7edc\u5c06\u5bfc\u81f4\u5168\u7403135\u4e2a\u56fd\u5bb6\u300165.6\u4ebf\u4eba\u53e3\u65e0\u6cd5\u8d1f\u62c5\uff0c\u52a0\u5267\u6570\u5b57\u9e3f\u6c9f\uff0c\u5e76\u53ef\u80fd\u7834\u574f\u5728\u7ebf\u5e7f\u544a\u751f\u6001\u7cfb\u7edf\u3002", "motivation": "\u7814\u7a76\u4ed8\u8d39\u5899\u8d8b\u52bf\u5bf9\u4e92\u8054\u7f51\u5f00\u653e\u6a21\u5f0f\u7684\u5a01\u80c1\uff0c\u7279\u522b\u662f\u5bf9\u7ecf\u6d4e\u5f31\u52bf\u7fa4\u4f53\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u8fd9\u79cd\u8d8b\u52bf\u5bf9\u5728\u7ebf\u5e7f\u544a\u751f\u6001\u7cfb\u7edf\u7684\u6f5c\u5728\u7834\u574f\u3002", "method": "\u4f7f\u7528\u4eba\u5747\u56fd\u6c11\u603b\u6536\u5165(GNI)\u6570\u636e\u548c\u5e73\u5747\u4ed8\u8d39\u5899\u8bbf\u95ee\u6210\u672c\uff0c\u5efa\u7acb\u6536\u5165-\u4ed8\u8d39\u5899\u652f\u51fa\u5dee\u8ddd\u57fa\u7ebf\uff0c\u5206\u6790\u5168\u7403\u8303\u56f4\u5185\u4ed8\u8d39\u5899\u7684\u53ef\u8d1f\u62c5\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0135\u4e2a\u56fd\u5bb6\u300165.6\u4ebf\u4eba\u53e3\u65e0\u6cd5\u8d1f\u62c5\u5b8c\u5168\u4ed8\u8d39\u5899\u5316\u7684\u7f51\u7edc\u573a\u666f\uff0c\u4ed8\u8d39\u5899\u6a21\u5f0f\u4f1a\u52a0\u5267\u6570\u5b57\u9694\u79bb\u5e76\u5a01\u80c1\u5728\u7ebf\u5e7f\u544a\u751f\u6001\u7cfb\u7edf\u3002", "conclusion": "\u547c\u5401\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u653f\u7b56\u5021\u8bae\uff0c\u4ee5\u7ef4\u6301\u4e92\u8054\u7f51\u7684\u5f00\u653e\u6027\u548c\u5305\u5bb9\u6027\uff0c\u5efa\u7acb\u53ef\u6301\u7eed\u7684\u5546\u4e1a\u6a21\u5f0f\u3002"}}
{"id": "2510.08754", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.08754", "abs": "https://arxiv.org/abs/2510.08754", "authors": ["David Nguyen", "Zulfiqar Zaidi", "Kevin Karol", "Jessica Hodgins", "Zhaoming Xie"], "title": "Whole Body Model Predictive Control for Spin-Aware Quadrupedal Table Tennis", "comment": "Submitted to appear in IEEE ICRA 2026", "summary": "Developing table tennis robots that mirror human speed, accuracy, and ability\nto predict and respond to the full range of ball spins remains a significant\nchallenge for legged robots. To demonstrate these capabilities we present a\nsystem to play dynamic table tennis for quadrupedal robots that integrates high\nspeed perception, trajectory prediction, and agile control. Our system uses\nexternal cameras for high-speed ball localization, physical models with learned\nresiduals to infer spin and predict trajectories, and a novel model predictive\ncontrol (MPC) formulation for agile full-body control. Notably, a continuous\nset of stroke strategies emerge automatically from different ball return\nobjectives using this control paradigm. We demonstrate our system in the real\nworld on a Spot quadruped, evaluate accuracy of each system component, and\nexhibit coordination through the system's ability to aim and return balls with\nvarying spin types. As a further demonstration, the system is able to rally\nwith human players.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8e\u56db\u8db3\u673a\u5668\u4eba\u7684\u52a8\u6001\u4e52\u4e53\u7403\u7cfb\u7edf\uff0c\u96c6\u6210\u4e86\u9ad8\u901f\u611f\u77e5\u3001\u8f68\u8ff9\u9884\u6d4b\u548c\u654f\u6377\u63a7\u5236\uff0c\u80fd\u591f\u4e0e\u4eba\u7c7b\u73a9\u5bb6\u8fdb\u884c\u5bf9\u6253\u3002", "motivation": "\u5f00\u53d1\u80fd\u591f\u5339\u914d\u4eba\u7c7b\u901f\u5ea6\u3001\u7cbe\u5ea6\u548c\u9884\u6d4b\u5404\u79cd\u7403\u65cb\u8f6c\u80fd\u529b\u7684\u4e52\u4e53\u7403\u673a\u5668\u4eba\u5bf9\u817f\u5f0f\u673a\u5668\u4eba\u6765\u8bf4\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u4f7f\u7528\u5916\u90e8\u6444\u50cf\u5934\u8fdb\u884c\u9ad8\u901f\u7403\u5b9a\u4f4d\uff0c\u7ed3\u5408\u7269\u7406\u6a21\u578b\u548c\u5b66\u4e60\u7684\u6b8b\u5dee\u6765\u63a8\u65ad\u65cb\u8f6c\u548c\u9884\u6d4b\u8f68\u8ff9\uff0c\u91c7\u7528\u65b0\u9896\u7684\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MPC\uff09\u516c\u5f0f\u8fdb\u884c\u654f\u6377\u5168\u8eab\u63a7\u5236\u3002", "result": "\u5728Spot\u56db\u8db3\u673a\u5668\u4eba\u4e0a\u6210\u529f\u6f14\u793a\u4e86\u7cfb\u7edf\uff0c\u80fd\u591f\u7784\u51c6\u548c\u56de\u51fb\u4e0d\u540c\u7c7b\u578b\u7684\u65cb\u8f6c\u7403\uff0c\u5e76\u80fd\u4e0e\u4eba\u7c7b\u73a9\u5bb6\u8fdb\u884c\u5bf9\u6253\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5c55\u793a\u4e86\u56db\u8db3\u673a\u5668\u4eba\u5728\u52a8\u6001\u4e52\u4e53\u7403\u4efb\u52a1\u4e2d\u7684\u534f\u8c03\u80fd\u529b\uff0c\u901a\u8fc7\u63a7\u5236\u8303\u5f0f\u81ea\u52a8\u6d8c\u73b0\u51fa\u8fde\u7eed\u7684\u51fb\u7403\u7b56\u7565\u3002"}}
{"id": "2510.08980", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.08980", "abs": "https://arxiv.org/abs/2510.08980", "authors": ["Mehmet Fatih Ozkan", "Dennis Kibalama", "Jacob Paugh", "Marcello Canova", "Stephanie Stockar"], "title": "Traffic-Aware Eco-Driving Control in CAVs via Learning-based Terminal Cost Model", "comment": null, "summary": "Connected and Automated Vehicles (CAVs) offer significant potential for\nimproving energy efficiency and lowering vehicle emissions through eco-driving\ntechnologies. Control algorithms in CAVs leverage look-ahead route information\nand Vehicle-to-Everything (V2X) communication to optimize vehicle performance.\nHowever, existing eco-driving strategies often neglect macroscopic traffic\neffects, such as upstream traffic jams, that occur outside the optimization\nhorizon but significantly impact vehicle energy efficiency. This work presents\na novel Neural Network (NN)-based methodology to approximate the terminal cost\nwithin a model predictive control (MPC) problem framework, explicitly\nincorporating upstream traffic dynamics. By incorporating traffic jams into the\noptimization process, the proposed traffic-aware approach yields more\nenergy-efficient speed trajectories compared to traffic-agnostic methods, with\nminimal impact on travel time. The framework is scalable for real-time\nimplementation while effectively addressing uncertainties from dynamic traffic\nconditions and macroscopic traffic events.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fd1\u4f3c\u7ec8\u7aef\u6210\u672c\u6765\u8003\u8651\u4e0a\u6e38\u4ea4\u901a\u62e5\u5835\u5bf9\u8f66\u8f86\u80fd\u8017\u7684\u5f71\u54cd\uff0c\u76f8\u6bd4\u4e0d\u8003\u8651\u4ea4\u901a\u7684\u65b9\u6cd5\u80fd\u751f\u6210\u66f4\u8282\u80fd\u7684\u901f\u5ea6\u8f68\u8ff9\u3002", "motivation": "\u73b0\u6709CAV\u751f\u6001\u9a7e\u9a76\u7b56\u7565\u5f80\u5f80\u5ffd\u7565\u4f18\u5316\u89c6\u91ce\u5916\u7684\u5b8f\u89c2\u4ea4\u901a\u5f71\u54cd\uff08\u5982\u4e0a\u6e38\u4ea4\u901a\u62e5\u5835\uff09\uff0c\u8fd9\u4e9b\u56e0\u7d20\u663e\u8457\u5f71\u54cd\u8f66\u8f86\u80fd\u6548\u3002", "method": "\u5728MPC\u6846\u67b6\u4e2d\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u7ec8\u7aef\u6210\u672c\uff0c\u660e\u786e\u7eb3\u5165\u4e0a\u6e38\u4ea4\u901a\u52a8\u6001\uff0c\u4f7f\u4f18\u5316\u8fc7\u7a0b\u80fd\u591f\u8003\u8651\u4ea4\u901a\u62e5\u5835\u3002", "result": "\u63d0\u51fa\u7684\u4ea4\u901a\u611f\u77e5\u65b9\u6cd5\u76f8\u6bd4\u4ea4\u901a\u65e0\u5173\u65b9\u6cd5\u80fd\u4ea7\u751f\u66f4\u8282\u80fd\u7684\u901f\u5ea6\u8f68\u8ff9\uff0c\u4e14\u5bf9\u884c\u7a0b\u65f6\u95f4\u5f71\u54cd\u6700\u5c0f\uff0c\u6846\u67b6\u53ef\u6269\u5c55\u7528\u4e8e\u5b9e\u65f6\u5b9e\u73b0\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u52a8\u6001\u4ea4\u901a\u6761\u4ef6\u548c\u5b8f\u89c2\u4ea4\u901a\u4e8b\u4ef6\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u4fdd\u6301\u5b9e\u65f6\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u80fd\u6548\u3002"}}
{"id": "2510.09185", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.09185", "abs": "https://arxiv.org/abs/2510.09185", "authors": ["Stephane Hess", "Sander van Cranenburgh"], "title": "Flexibility without foresight: the predictive limitations of mixture models", "comment": null, "summary": "Models allowing for random heterogeneity, such as mixed logit and latent\nclass, are generally observed to obtain superior model fit and yield detailed\ninsights into unobserved preference heterogeneity. Using theoretical arguments\nand two case studies on revealed and stated choice data, this paper highlights\nthat these advantages do not translate into any benefits in forecasting,\nwhether looking at prediction performance or the recovery of market shares. The\nonly exception arises when using conditional distributions in making\npredictions for the same individuals included in the estimation sample, which\nobviously precludes any out-of-sample forecasting.", "AI": {"tldr": "\u968f\u673a\u5f02\u8d28\u6027\u6a21\u578b\u5728\u9884\u6d4b\u8868\u73b0\u548c\u5e02\u573a\u4efd\u989d\u6062\u590d\u65b9\u9762\u6ca1\u6709\u4f18\u52bf\uff0c\u552f\u4e00\u7684\u4f8b\u5916\u662f\u5728\u5bf9\u4f30\u8ba1\u6837\u672c\u4e2d\u7684\u76f8\u540c\u4e2a\u4f53\u8fdb\u884c\u9884\u6d4b\u65f6\u4f7f\u7528\u6761\u4ef6\u5206\u5e03\u3002", "motivation": "\u7814\u7a76\u968f\u673a\u5f02\u8d28\u6027\u6a21\u578b\uff08\u5982\u6df7\u5408logit\u548c\u6f5c\u5728\u7c7b\u522b\u6a21\u578b\uff09\u5728\u6a21\u578b\u62df\u5408\u548c\u63ed\u793a\u672a\u89c2\u6d4b\u504f\u597d\u5f02\u8d28\u6027\u65b9\u9762\u7684\u4f18\u52bf\u662f\u5426\u80fd\u591f\u8f6c\u5316\u4e3a\u9884\u6d4b\u6027\u80fd\u7684\u63d0\u5347\u3002", "method": "\u4f7f\u7528\u7406\u8bba\u8bba\u8bc1\u548c\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff08\u57fa\u4e8e\u663e\u793a\u9009\u62e9\u548c\u9648\u8ff0\u9009\u62e9\u6570\u636e\uff09\u6765\u8bc4\u4f30\u968f\u673a\u5f02\u8d28\u6027\u6a21\u578b\u5728\u9884\u6d4b\u6027\u80fd\u548c\u5e02\u573a\u5171\u4eab\u6062\u590d\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u968f\u673a\u5f02\u8d28\u6027\u6a21\u578b\u5728\u6a21\u578b\u62df\u5408\u548c\u63ed\u793a\u504f\u597d\u5f02\u8d28\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u8fd9\u4e9b\u4f18\u52bf\u5e76\u4e0d\u80fd\u8f6c\u5316\u4e3a\u9884\u6d4b\u6027\u80fd\u6216\u5e02\u573a\u4efd\u989d\u6062\u590d\u7684\u4efb\u4f55\u76ca\u5904\u3002", "conclusion": "\u968f\u673a\u5f02\u8d28\u6027\u6a21\u578b\u5728\u9884\u6d4b\u65b9\u9762\u6ca1\u6709\u4f18\u52bf\uff0c\u552f\u4e00\u7684\u4f8b\u5916\u662f\u5728\u5bf9\u4f30\u8ba1\u6837\u672c\u4e2d\u7684\u76f8\u540c\u4e2a\u4f53\u8fdb\u884c\u9884\u6d4b\u65f6\u4f7f\u7528\u6761\u4ef6\u5206\u5e03\uff0c\u4f46\u8fd9\u6392\u9664\u4e86\u4efb\u4f55\u6837\u672c\u5916\u9884\u6d4b\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2510.08921", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.08921", "abs": "https://arxiv.org/abs/2510.08921", "authors": ["Chunsong Chen", "Yichen Hou", "Huan Chen", "Junlin Li", "Rong Fu", "Qiushen Lai", "Yiping Chen", "Ting Han"], "title": "GBA-UBF : A Large-Scale and Fine-Grained Building Function Classification Dataset in the Greater Bay Area", "comment": "12 pages, 10 figures, The 4th ACM SIGSPATIAL International Workshop\n  on Spatial Big Data and AI for Industrial Applications (GeoIndustry '25),\n  November 3--6, 2025, Minneapolis, MN, USA", "summary": "Rapid urbanization in the Guangdong-Hong Kong-Macao Greater Bay Area (GBA)\nhas created urgent demand for high-resolution, building-level functional data\nto support sustainable spatial planning. Existing land use datasets suffer from\ncoarse granularity and difficulty in capturing intra-block heterogeneity. To\nthis end, we present the Greater Bay Area Urban Building Function Dataset\n(GBA-UBF), a large-scale, fine-grained dataset that assigns one of five\nfunctional categories to nearly four million buildings across six core GBA\ncities. We proposed a Multi-level Building Function Optimization (ML-BFO)\nmethod by integrating Points of Interest (POI) records and building footprints\nthrough a three-stage pipeline: (1) candidate label generation using spatial\noverlay with proximity weighting, (2) iterative refinement based on\nneighborhood label autocorrelation, and (3) function-related correction\ninformed by High-level POI buffers. To quantitatively validate results, we\ndesign the Building Function Matching Index (BFMI), which jointly measures\ncategorical consistency and distributional similarity against POI-derived\nprobability heatmaps. Comparative experiments demonstrate that GBA-UBF achieves\nsignificantly higher accuracy, with a BMFI of 0.58. This value markedly exceeds\nthat of the baseline dataset and exhibits superior alignment with urban\nactivity patterns. Field validation further confirms the dataset's semantic\nreliability and practical interpretability. The GBA-UBF dataset establishes a\nreproducible framework for building-level functional classification, bridging\nthe gap between coarse land use maps and fine-grained urban analytics. The\ndataset is accessible at https://github.com/chenchs0629/GBA-UBF, and the data\nwill undergo continuous improvement and updates based on feedback from the\ncommunity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7ca4\u6e2f\u6fb3\u5927\u6e7e\u533a\u57ce\u5e02\u5efa\u7b51\u529f\u80fd\u6570\u636e\u96c6(GBA-UBF)\uff0c\u901a\u8fc7\u591a\u7ea7\u5efa\u7b51\u529f\u80fd\u4f18\u5316\u65b9\u6cd5\u4e3a\u8fd1400\u4e07\u680b\u5efa\u7b51\u5206\u914d5\u79cd\u529f\u80fd\u7c7b\u522b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5efa\u7b51\u7ea7\u529f\u80fd\u5206\u7c7b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u7ca4\u6e2f\u6fb3\u5927\u6e7e\u533a\u7684\u5feb\u901f\u57ce\u5e02\u5316\u5bf9\u9ad8\u5206\u8fa8\u7387\u3001\u5efa\u7b51\u7ea7\u529f\u80fd\u6570\u636e\u63d0\u51fa\u4e86\u8feb\u5207\u9700\u6c42\uff0c\u73b0\u6709\u571f\u5730\u5229\u7528\u6570\u636e\u96c6\u5b58\u5728\u7c92\u5ea6\u7c97\u7cd9\u548c\u96be\u4ee5\u6355\u6349\u8857\u533a\u5185\u90e8\u5f02\u8d28\u6027\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u7ea7\u5efa\u7b51\u529f\u80fd\u4f18\u5316\u65b9\u6cd5(ML-BFO)\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u6d41\u7a0b\u6574\u5408POI\u8bb0\u5f55\u548c\u5efa\u7b51\u8db3\u8ff9\uff1a\u5019\u9009\u6807\u7b7e\u751f\u6210\u3001\u57fa\u4e8e\u90bb\u57df\u6807\u7b7e\u81ea\u76f8\u5173\u7684\u8fed\u4ee3\u4f18\u5316\u3001\u4ee5\u53ca\u57fa\u4e8e\u9ad8\u7ea7POI\u7f13\u51b2\u533a\u7684\u529f\u80fd\u76f8\u5173\u6821\u6b63\u3002", "result": "GBA-UBF\u6570\u636e\u96c6\u8fbe\u52300.58\u7684BFMI\u503c\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6570\u636e\u96c6\uff0c\u4e0e\u57ce\u5e02\u6d3b\u52a8\u6a21\u5f0f\u5177\u6709\u66f4\u597d\u7684\u5bf9\u9f50\u6027\uff0c\u5b9e\u5730\u9a8c\u8bc1\u786e\u8ba4\u4e86\u6570\u636e\u96c6\u7684\u8bed\u4e49\u53ef\u9760\u6027\u548c\u5b9e\u7528\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "GBA-UBF\u6570\u636e\u96c6\u4e3a\u5efa\u7b51\u7ea7\u529f\u80fd\u5206\u7c7b\u5efa\u7acb\u4e86\u53ef\u590d\u73b0\u7684\u6846\u67b6\uff0c\u5f25\u5408\u4e86\u7c97\u7cd9\u571f\u5730\u5229\u7528\u5730\u56fe\u4e0e\u7cbe\u7ec6\u5316\u57ce\u5e02\u5206\u6790\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2510.08713", "categories": ["cs.AI", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.08713", "abs": "https://arxiv.org/abs/2510.08713", "authors": ["Yifei Dong", "Fengyi Wu", "Guangyu Chen", "Zhi-Qi Cheng", "Qiyu Hu", "Yuxuan Zhou", "Jingdong Sun", "Jun-Yan He", "Qi Dai", "Alexander G Hauptmann"], "title": "Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation", "comment": "18 pages, 11 figures, code: https://github.com/F1y1113/UniWM", "summary": "Enabling embodied agents to effectively imagine future states is critical for\nrobust and generalizable visual navigation. Current state-of-the-art\napproaches, however, adopt modular architectures that separate navigation\nplanning from visual world modeling, leading to state-action misalignment and\nlimited adaptability in novel or dynamic scenarios. To overcome this\nfundamental limitation, we propose UniWM, a unified, memory-augmented world\nmodel integrating egocentric visual foresight and planning within a single\nmultimodal autoregressive backbone. Unlike modular frameworks, UniWM explicitly\ngrounds action decisions in visually imagined outcomes, ensuring tight\nalignment between prediction and control. A hierarchical memory mechanism\nfurther integrates detailed short-term perceptual cues with longer-term\ntrajectory context, enabling stable, coherent reasoning over extended horizons.\nExtensive experiments across four challenging benchmarks (Go Stanford, ReCon,\nSCAND, HuRoN) demonstrate that UniWM substantially improves navigation success\nrates by up to 30%, significantly reduces trajectory errors compared to strong\nbaselines, and exhibits impressive zero-shot generalization on the unseen\nTartanDrive dataset. These results highlight UniWM as a principled step toward\nunified, imagination-driven embodied navigation.", "AI": {"tldr": "\u63d0\u51faUniWM\u7edf\u4e00\u4e16\u754c\u6a21\u578b\uff0c\u5c06\u89c6\u89c9\u9884\u6d4b\u548c\u5bfc\u822a\u89c4\u5212\u96c6\u6210\u5230\u5355\u4e00\u591a\u6a21\u6001\u81ea\u56de\u5f52\u6846\u67b6\u4e2d\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u8bb0\u5fc6\u673a\u5236\u5b9e\u73b0\u957f\u671f\u7a33\u5b9a\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u5bfc\u822a\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6a21\u5757\u5316\u67b6\u6784\u4e2d\u5bfc\u822a\u89c4\u5212\u4e0e\u89c6\u89c9\u4e16\u754c\u5efa\u6a21\u5206\u79bb\u5bfc\u81f4\u7684\u52a8\u4f5c\u72b6\u6001\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u63d0\u5347\u5728\u52a8\u6001\u548c\u672a\u77e5\u573a\u666f\u4e2d\u7684\u9002\u5e94\u6027\u3002", "method": "\u91c7\u7528\u7edf\u4e00\u3001\u8bb0\u5fc6\u589e\u5f3a\u7684\u4e16\u754c\u6a21\u578b\uff0c\u5c06\u81ea\u6211\u4e2d\u5fc3\u89c6\u89c9\u9884\u6d4b\u548c\u89c4\u5212\u96c6\u6210\u5230\u591a\u6a21\u6001\u81ea\u56de\u5f52\u4e3b\u5e72\u7f51\u7edc\u4e2d\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u8bb0\u5fc6\u673a\u5236\u6574\u5408\u77ed\u671f\u611f\u77e5\u7ebf\u7d22\u548c\u957f\u671f\u8f68\u8ff9\u4e0a\u4e0b\u6587\u3002", "result": "\u5728\u56db\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5bfc\u822a\u6210\u529f\u7387\u63d0\u5347\u9ad8\u8fbe30%\uff0c\u8f68\u8ff9\u8bef\u5dee\u663e\u8457\u964d\u4f4e\uff0c\u5e76\u5728\u672a\u89c1\u8fc7\u7684TartanDrive\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u79c0\u7684\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "UniWM\u662f\u5b9e\u73b0\u7edf\u4e00\u3001\u60f3\u8c61\u529b\u9a71\u52a8\u7684\u5177\u8eab\u5bfc\u822a\u7684\u91cd\u8981\u8fdb\u5c55\uff0c\u901a\u8fc7\u7d27\u5bc6\u5bf9\u9f50\u9884\u6d4b\u4e0e\u63a7\u5236\uff0c\u63d0\u5347\u4e86\u5bfc\u822a\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u3002"}}
{"id": "2510.09082", "categories": ["cs.AI", "cs.CY", "cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2510.09082", "abs": "https://arxiv.org/abs/2510.09082", "authors": ["Bicheng Wang", "Jinping Wang", "Yibo Sue"], "title": "Physics-Informed High-order Graph Dynamics Identification Learning for Predicting Complex Networks Long-term Dynamics", "comment": null, "summary": "Learning complex network dynamics is fundamental to understanding, modelling\nand controlling real-world complex systems. There are two main problems in the\ntask of predicting the dynamic evolution of complex networks: on the one hand,\nexisting methods usually use simple graphs to describe the relationships in\ncomplex networks; however, this approach can only capture pairwise\nrelationships, while there may be rich non-pairwise structured relationships in\nthe network. First-order GNNs have difficulty in capturing dynamic non-pairwise\nrelationships. On the other hand, theoretical prediction models lack accuracy\nand data-driven prediction models lack interpretability. To address the above\nproblems, this paper proposes a higher-order network dynamics identification\nmethod for long-term dynamic prediction of complex networks. Firstly, to\naddress the problem that traditional graph machine learning can only deal with\npairwise relations, dynamic hypergraph learning is introduced to capture the\nhigher-order non-pairwise relations among complex networks and improve the\naccuracy of complex network modelling. Then, a dual-driven dynamic prediction\nmodule for physical data is proposed. The Koopman operator theory is introduced\nto transform the nonlinear dynamical differential equations for the dynamic\nevolution of complex networks into linear systems for solving. Meanwhile, the\nphysical information neural differential equation method is utilised to ensure\nthat the dynamic evolution conforms to the physical laws. The dual-drive\ndynamic prediction module ensures both accuracy and interpretability of the\nprediction. Validated on public datasets and self-built industrial chain\nnetwork datasets, the experimental results show that the method in this paper\nhas good prediction accuracy and long-term prediction performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u9636\u7f51\u7edc\u52a8\u529b\u5b66\u8bc6\u522b\u65b9\u6cd5\uff0c\u7528\u4e8e\u590d\u6742\u7f51\u7edc\u7684\u957f\u671f\u52a8\u6001\u9884\u6d4b\u3002\u901a\u8fc7\u52a8\u6001\u8d85\u56fe\u5b66\u4e60\u6355\u6349\u9ad8\u9636\u975e\u6210\u5bf9\u5173\u7cfb\uff0c\u5e76\u7ed3\u5408\u7269\u7406\u6570\u636e\u53cc\u9a71\u52a8\u9884\u6d4b\u6a21\u5757\uff0c\u786e\u4fdd\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u4f20\u7edf\u56fe\u673a\u5668\u5b66\u4e60\u53ea\u80fd\u5904\u7406\u6210\u5bf9\u5173\u7cfb\uff0c\u96be\u4ee5\u6355\u6349\u7f51\u7edc\u4e2d\u7684\u9ad8\u9636\u975e\u6210\u5bf9\u7ed3\u6784\u5173\u7cfb\uff1b2\uff09\u7406\u8bba\u9884\u6d4b\u6a21\u578b\u7f3a\u4e4f\u51c6\u786e\u6027\uff0c\u6570\u636e\u9a71\u52a8\u9884\u6d4b\u6a21\u578b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002", "method": "1\uff09\u5f15\u5165\u52a8\u6001\u8d85\u56fe\u5b66\u4e60\u6355\u6349\u590d\u6742\u7f51\u7edc\u4e2d\u7684\u9ad8\u9636\u975e\u6210\u5bf9\u5173\u7cfb\uff1b2\uff09\u63d0\u51fa\u7269\u7406\u6570\u636e\u53cc\u9a71\u52a8\u52a8\u6001\u9884\u6d4b\u6a21\u5757\uff0c\u7ed3\u5408Koopman\u7b97\u5b50\u7406\u8bba\u5c06\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u5fae\u5206\u65b9\u7a0b\u8f6c\u5316\u4e3a\u7ebf\u6027\u7cfb\u7edf\uff0c\u5e76\u5229\u7528\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u5fae\u5206\u65b9\u7a0b\u65b9\u6cd5\u786e\u4fdd\u52a8\u6001\u6f14\u5316\u7b26\u5408\u7269\u7406\u89c4\u5f8b\u3002", "result": "\u5728\u516c\u5171\u6570\u636e\u96c6\u548c\u81ea\u5efa\u4ea7\u4e1a\u94fe\u7f51\u7edc\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u826f\u597d\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u957f\u671f\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u9ad8\u9636\u7f51\u7edc\u52a8\u529b\u5b66\u8bc6\u522b\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u590d\u6742\u7f51\u7edc\u52a8\u6001\u9884\u6d4b\u4e2d\u7684\u9ad8\u9636\u5173\u7cfb\u5efa\u6a21\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.08787", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.08787", "abs": "https://arxiv.org/abs/2510.08787", "authors": ["Yiming Li", "Nael Darwiche", "Amirreza Razmjoo", "Sichao Liu", "Yilun Du", "Auke Ijspeert", "Sylvain Calinon"], "title": "Geometry-aware Policy Imitation", "comment": "21 pages, 13 figures. In submission", "summary": "We propose a Geometry-aware Policy Imitation (GPI) approach that rethinks\nimitation learning by treating demonstrations as geometric curves rather than\ncollections of state-action samples. From these curves, GPI derives distance\nfields that give rise to two complementary control primitives: a progression\nflow that advances along expert trajectories and an attraction flow that\ncorrects deviations. Their combination defines a controllable, non-parametric\nvector field that directly guides robot behavior. This formulation decouples\nmetric learning from policy synthesis, enabling modular adaptation across\nlow-dimensional robot states and high-dimensional perceptual inputs. GPI\nnaturally supports multimodality by preserving distinct demonstrations as\nseparate models and allows efficient composition of new demonstrations through\nsimple additions to the distance field. We evaluate GPI in simulation and on\nreal robots across diverse tasks. Experiments show that GPI achieves higher\nsuccess rates than diffusion-based policies while running 20 times faster,\nrequiring less memory, and remaining robust to perturbations. These results\nestablish GPI as an efficient, interpretable, and scalable alternative to\ngenerative approaches for robotic imitation learning. Project website:\nhttps://yimingli1998.github.io/projects/GPI/", "AI": {"tldr": "GPI\u5c06\u6f14\u793a\u6570\u636e\u89c6\u4e3a\u51e0\u4f55\u66f2\u7ebf\u800c\u975e\u72b6\u6001-\u52a8\u4f5c\u6837\u672c\uff0c\u901a\u8fc7\u8ddd\u79bb\u573a\u751f\u6210\u4e24\u79cd\u63a7\u5236\u6d41\uff1a\u524d\u8fdb\u6d41\u548c\u5438\u5f15\u6d41\uff0c\u6784\u5efa\u53ef\u63a7\u7684\u975e\u53c2\u6570\u5411\u91cf\u573a\u76f4\u63a5\u6307\u5bfc\u673a\u5668\u4eba\u884c\u4e3a\u3002", "motivation": "\u91cd\u65b0\u601d\u8003\u6a21\u4eff\u5b66\u4e60\uff0c\u5c06\u6f14\u793a\u6570\u636e\u4f5c\u4e3a\u51e0\u4f55\u66f2\u7ebf\u5904\u7406\uff0c\u89e3\u8026\u5ea6\u91cf\u5b66\u4e60\u548c\u7b56\u7565\u5408\u6210\uff0c\u5b9e\u73b0\u8de8\u4f4e\u7ef4\u72b6\u6001\u548c\u9ad8\u7ef4\u611f\u77e5\u8f93\u5165\u7684\u6a21\u5757\u5316\u9002\u5e94\u3002", "method": "\u4ece\u6f14\u793a\u66f2\u7ebf\u63a8\u5bfc\u8ddd\u79bb\u573a\uff0c\u751f\u6210\u524d\u8fdb\u6d41\uff08\u6cbf\u4e13\u5bb6\u8f68\u8ff9\u63a8\u8fdb\uff09\u548c\u5438\u5f15\u6d41\uff08\u7ea0\u6b63\u504f\u5dee\uff09\uff0c\u7ec4\u5408\u6210\u53ef\u63a7\u5411\u91cf\u573a\u6307\u5bfc\u673a\u5668\u4eba\u884c\u4e3a\u3002", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\uff0cGPI\u6bd4\u57fa\u4e8e\u6269\u6563\u7684\u7b56\u7565\u83b7\u5f97\u66f4\u9ad8\u6210\u529f\u7387\uff0c\u8fd0\u884c\u901f\u5ea6\u5feb20\u500d\uff0c\u5185\u5b58\u9700\u6c42\u66f4\u5c11\uff0c\u4e14\u5bf9\u6270\u52a8\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "GPI\u4f5c\u4e3a\u673a\u5668\u4eba\u6a21\u4eff\u5b66\u4e60\u4e2d\u751f\u6210\u5f0f\u65b9\u6cd5\u7684\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6269\u5c55\u66ff\u4ee3\u65b9\u6848\uff0c\u652f\u6301\u591a\u6a21\u6001\u6f14\u793a\u548c\u9ad8\u6548\u7ec4\u5408\u65b0\u6f14\u793a\u3002"}}
{"id": "2510.09042", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09042", "abs": "https://arxiv.org/abs/2510.09042", "authors": ["Minghao Han", "Kiwan Wong", "Adrian Wing-Keung Law", "Xunyuan Yin"], "title": "MAKO: Meta-Adaptive Koopman Operators for Learning-based Model Predictive Control of Parametrically Uncertain Nonlinear Systems", "comment": null, "summary": "In this work, we propose a meta-learning-based Koopman modeling and\npredictive control approach for nonlinear systems with parametric\nuncertainties. An adaptive deep meta-learning-based modeling approach, called\nMeta Adaptive Koopman Operator (MAKO), is proposed. Without knowledge of the\nparametric uncertainty, the proposed MAKO approach can learn a meta-model from\na multi-modal dataset and efficiently adapt to new systems with previously\nunseen parameter settings by using online data. Based on the learned meta\nKoopman model, a predictive control scheme is developed, and the stability of\nthe closed-loop system is ensured even in the presence of previously unseen\nparameter settings. Through extensive simulations, our proposed approach\ndemonstrates superior performance in both modeling accuracy and control\nefficacy as compared to competitive baselines.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5143\u5b66\u4e60\u7684Koopman\u5efa\u6a21\u548c\u9884\u6d4b\u63a7\u5236\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u5177\u6709\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u7684\u975e\u7ebf\u6027\u7cfb\u7edf\u3002", "motivation": "\u9488\u5bf9\u975e\u7ebf\u6027\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u9002\u5e94\u672a\u77e5\u53c2\u6570\u8bbe\u7f6e\u7684\u5efa\u6a21\u548c\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u63d0\u51faMeta Adaptive Koopman Operator (MAKO)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u4ece\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u5143\u6a21\u578b\uff0c\u5e76\u5229\u7528\u5728\u7ebf\u6570\u636e\u5feb\u901f\u9002\u5e94\u65b0\u7684\u53c2\u6570\u8bbe\u7f6e\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5efa\u6a21\u7cbe\u5ea6\u548c\u63a7\u5236\u6548\u679c\u65b9\u9762\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684MAKO\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\uff0c\u786e\u4fdd\u95ed\u73af\u7cfb\u7edf\u7a33\u5b9a\u6027\uff0c\u5e76\u5728\u672a\u77e5\u53c2\u6570\u8bbe\u7f6e\u4e0b\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.09257", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.09257", "abs": "https://arxiv.org/abs/2510.09257", "authors": ["Eugenio Felipe Merlano"], "title": "Boundary estimation in the regression-discontinuity design: Evidence for a merit- and need-based financial aid program", "comment": null, "summary": "In the conventional regression-discontinuity (RD) design, the probability\nthat units receive a treatment changes discontinuously as a function of one\ncovariate exceeding a threshold or cutoff point. This paper studies an extended\nRD design where assignment rules simultaneously involve two or more continuous\ncovariates. We show that assignment rules with more than one variable allow the\nestimation of a more comprehensive set of treatment effects, relaxing in a\nresearch-driven style the local and sometimes limiting nature of univariate RD\ndesigns. We then propose a flexible nonparametric approach to estimate the\nmultidimensional discontinuity by univariate local linear regression and\ncompare its performance to existing methods. We present an empirical\napplication to a large-scale and countrywide financial aid program for\nlow-income students in Colombia. The program uses a merit-based (academic\nachievement) and need-based (wealth index) assignment rule to select students\nfor the program. We show that our estimation strategy fully exploits the\nmultidimensional assignment rule and reveals heterogeneous effects along the\ntreatment boundaries.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6269\u5c55\u7684\u56de\u5f52\u65ad\u70b9\u8bbe\u8ba1\uff0c\u5176\u4e2d\u5206\u914d\u89c4\u5219\u540c\u65f6\u6d89\u53ca\u4e24\u4e2a\u6216\u591a\u4e2a\u8fde\u7eed\u534f\u53d8\u91cf\uff0c\u63d0\u51fa\u4e86\u901a\u8fc7\u5355\u53d8\u91cf\u5c40\u90e8\u7ebf\u6027\u56de\u5f52\u4f30\u8ba1\u591a\u7ef4\u65ad\u70b9\u7684\u7075\u6d3b\u975e\u53c2\u6570\u65b9\u6cd5\uff0c\u5e76\u5728\u54e5\u4f26\u6bd4\u4e9a\u4f4e\u6536\u5165\u5b66\u751f\u8d44\u52a9\u9879\u76ee\u4e2d\u8fdb\u884c\u4e86\u5b9e\u8bc1\u5e94\u7528\u3002", "motivation": "\u4f20\u7edf\u5355\u53d8\u91cfRD\u8bbe\u8ba1\u5728\u5904\u7406\u6982\u7387\u5728\u5355\u4e00\u534f\u53d8\u91cf\u8d85\u8fc7\u9608\u503c\u65f6\u53d1\u751f\u4e0d\u8fde\u7eed\u53d8\u5316\uff0c\u9650\u5236\u4e86\u4f30\u8ba1\u7684\u5c40\u90e8\u6027\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u591a\u7ef4RD\u8bbe\u8ba1\u4f30\u8ba1\u66f4\u5168\u9762\u7684\u5904\u7406\u6548\u5e94\uff0c\u7f13\u89e3\u5355\u53d8\u91cfRD\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u901a\u8fc7\u5355\u53d8\u91cf\u5c40\u90e8\u7ebf\u6027\u56de\u5f52\u4f30\u8ba1\u591a\u7ef4\u65ad\u70b9\u7684\u7075\u6d3b\u975e\u53c2\u6570\u65b9\u6cd5\uff0c\u5e76\u4e0e\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\u3002", "result": "\u5728\u54e5\u4f26\u6bd4\u4e9a\u4f4e\u6536\u5165\u5b66\u751f\u8d44\u52a9\u9879\u76ee\u7684\u5b9e\u8bc1\u5e94\u7528\u4e2d\uff0c\u8be5\u4f30\u8ba1\u7b56\u7565\u5145\u5206\u5229\u7528\u4e86\u591a\u7ef4\u5206\u914d\u89c4\u5219\uff0c\u63ed\u793a\u4e86\u6cbf\u5904\u7406\u8fb9\u754c\u7684\u5f02\u8d28\u6027\u6548\u5e94\u3002", "conclusion": "\u591a\u7ef4RD\u8bbe\u8ba1\u80fd\u591f\u4f30\u8ba1\u66f4\u5168\u9762\u7684\u5904\u7406\u6548\u5e94\uff0c\u653e\u677e\u4e86\u5355\u53d8\u91cfRD\u8bbe\u8ba1\u7684\u5c40\u90e8\u9650\u5236\uff0c\u63d0\u51fa\u7684\u975e\u53c2\u6570\u65b9\u6cd5\u6709\u6548\u5229\u7528\u4e86\u591a\u7ef4\u5206\u914d\u89c4\u5219\u5e76\u63ed\u793a\u4e86\u5f02\u8d28\u6027\u6548\u5e94\u3002"}}
{"id": "2510.09090", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09090", "abs": "https://arxiv.org/abs/2510.09090", "authors": ["Laxmiraju Kandikatla", "Branislav Radeljic"], "title": "AI and Human Oversight: A Risk-Based Framework for Alignment", "comment": "19 pages", "summary": "As Artificial Intelligence (AI) technologies continue to advance, protecting\nhuman autonomy and promoting ethical decision-making are essential to fostering\ntrust and accountability. Human agency (the capacity of individuals to make\ninformed decisions) should be actively preserved and reinforced by AI systems.\nThis paper examines strategies for designing AI systems that uphold fundamental\nrights, strengthen human agency, and embed effective human oversight\nmechanisms. It discusses key oversight models, including Human-in-Command\n(HIC), Human-in-the-Loop (HITL), and Human-on-the-Loop (HOTL), and proposes a\nrisk-based framework to guide the implementation of these mechanisms. By\nlinking the level of AI model risk to the appropriate form of human oversight,\nthe paper underscores the critical role of human involvement in the responsible\ndeployment of AI, balancing technological innovation with the protection of\nindividual values and rights. In doing so, it aims to ensure that AI\ntechnologies are used responsibly, safeguarding individual autonomy while\nmaximizing societal benefits.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u7cfb\u7edf\u4e2d\u4fdd\u62a4\u4eba\u7c7b\u81ea\u4e3b\u6743\u548c\u4fc3\u8fdb\u4f26\u7406\u51b3\u7b56\u7684\u7b56\u7565\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u98ce\u9669\u7684\u4eba\u7c7b\u76d1\u7763\u6846\u67b6\uff0c\u5c06AI\u6a21\u578b\u98ce\u9669\u6c34\u5e73\u4e0e\u9002\u5f53\u7684\u4eba\u7c7b\u76d1\u7763\u5f62\u5f0f\u8054\u7cfb\u8d77\u6765\u3002", "motivation": "\u968f\u7740AI\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u4fdd\u62a4\u4eba\u7c7b\u81ea\u4e3b\u6743\u548c\u4fc3\u8fdb\u4f26\u7406\u51b3\u7b56\u5bf9\u4e8e\u5efa\u7acb\u4fe1\u4efb\u548c\u95ee\u8d23\u5236\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u8bbe\u8ba1\u80fd\u591f\u7ef4\u62a4\u57fa\u672c\u6743\u5229\u3001\u589e\u5f3a\u4eba\u7c7b\u80fd\u52a8\u6027\u5e76\u5d4c\u5165\u6709\u6548\u4eba\u7c7b\u76d1\u7763\u673a\u5236\u7684AI\u7cfb\u7edf\u3002", "method": "\u8ba8\u8bba\u4e86\u5173\u952e\u76d1\u7763\u6a21\u578b\uff08HIC\u3001HITL\u3001HOTL\uff09\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u98ce\u9669\u7684\u6846\u67b6\u6765\u6307\u5bfc\u8fd9\u4e9b\u673a\u5236\u7684\u5b9e\u65bd\uff0c\u5c06AI\u6a21\u578b\u98ce\u9669\u6c34\u5e73\u4e0e\u9002\u5f53\u7684\u4eba\u7c7b\u76d1\u7763\u5f62\u5f0f\u8054\u7cfb\u8d77\u6765\u3002", "result": "\u901a\u8fc7\u5c06AI\u6a21\u578b\u98ce\u9669\u6c34\u5e73\u4e0e\u9002\u5f53\u7684\u4eba\u7c7b\u76d1\u7763\u5f62\u5f0f\u76f8\u8fde\u63a5\uff0c\u5f3a\u8c03\u4e86\u4eba\u7c7b\u53c2\u4e0e\u5728\u8d1f\u8d23\u4efb\u90e8\u7f72AI\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e73\u8861\u6280\u672f\u521b\u65b0\u4e0e\u4e2a\u4eba\u4ef7\u503c\u89c2\u548c\u6743\u5229\u4fdd\u62a4\u3002", "conclusion": "\u8be5\u6846\u67b6\u65e8\u5728\u786e\u4fddAI\u6280\u672f\u88ab\u8d1f\u8d23\u4efb\u5730\u4f7f\u7528\uff0c\u5728\u4fdd\u62a4\u4e2a\u4eba\u81ea\u4e3b\u6743\u7684\u540c\u65f6\u6700\u5927\u5316\u793e\u4f1a\u6548\u76ca\uff0c\u5b9e\u73b0\u6280\u672f\u521b\u65b0\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u5e73\u8861\u3002"}}
{"id": "2510.08755", "categories": ["cs.AI", "cs.CL", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.08755", "abs": "https://arxiv.org/abs/2510.08755", "authors": ["Pantea Karimi", "Dany Rouhana", "Pooria Namyar", "Siva Kesava Reddy Kakarla", "Venkat Arun", "Behnaz Arzani"], "title": "Robust Heuristic Algorithm Design with LLMs", "comment": null, "summary": "We posit that we can generate more robust and performant heuristics if we\naugment approaches using LLMs for heuristic design with tools that explain why\nheuristics underperform and suggestions about how to fix them. We find even\nsimple ideas that (1) expose the LLM to instances where the heuristic\nunderperforms; (2) explain why they occur; and (3) specialize design to regions\nin the input space, can produce more robust algorithms compared to existing\ntechniques~ -- ~the heuristics we produce have a $\\sim28\\times$ better\nworst-case performance compared to FunSearch, improve average performance, and\nmaintain the runtime.", "AI": {"tldr": "\u901a\u8fc7\u5411LLM\u66b4\u9732\u542f\u53d1\u5f0f\u7b97\u6cd5\u8868\u73b0\u4e0d\u4f73\u7684\u5b9e\u4f8b\u3001\u89e3\u91ca\u539f\u56e0\u5e76\u9488\u5bf9\u8f93\u5165\u7a7a\u95f4\u7279\u5b9a\u533a\u57df\u8fdb\u884c\u4e13\u95e8\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u751f\u6210\u6bd4\u73b0\u6709\u6280\u672f\u66f4\u9c81\u68d2\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u6700\u5dee\u6027\u80fd\u63d0\u5347\u7ea628\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u8fd0\u884c\u65f6\u95f4\u3002", "motivation": "\u901a\u8fc7\u589e\u5f3aLLM\u5728\u542f\u53d1\u5f0f\u8bbe\u8ba1\u4e2d\u7684\u80fd\u529b\uff0c\u4f7f\u7528\u5de5\u5177\u6765\u89e3\u91ca\u542f\u53d1\u5f0f\u7b97\u6cd5\u8868\u73b0\u4e0d\u4f73\u7684\u539f\u56e0\u5e76\u63d0\u4f9b\u6539\u8fdb\u5efa\u8bae\uff0c\u4ece\u800c\u751f\u6210\u66f4\u9c81\u68d2\u548c\u6027\u80fd\u66f4\u597d\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u7b80\u5355\u4f46\u6709\u6548\u7684\u7b56\u7565\uff1a(1)\u5411LLM\u5c55\u793a\u542f\u53d1\u5f0f\u7b97\u6cd5\u8868\u73b0\u4e0d\u4f73\u7684\u5b9e\u4f8b\uff1b(2)\u89e3\u91ca\u8fd9\u4e9b\u8868\u73b0\u4e0d\u4f73\u7684\u539f\u56e0\uff1b(3)\u9488\u5bf9\u8f93\u5165\u7a7a\u95f4\u7684\u7279\u5b9a\u533a\u57df\u8fdb\u884c\u4e13\u95e8\u5316\u8bbe\u8ba1\u3002", "result": "\u751f\u6210\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u76f8\u6bd4FunSearch\u5177\u6709\u7ea628\u500d\u66f4\u597d\u7684\u6700\u5dee\u6027\u80fd\uff0c\u5e73\u5747\u6027\u80fd\u4e5f\u6709\u6240\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "\u901a\u8fc7\u5411LLM\u63d0\u4f9b\u5173\u4e8e\u542f\u53d1\u5f0f\u7b97\u6cd5\u5931\u8d25\u6848\u4f8b\u7684\u89e3\u91ca\u548c\u6539\u8fdb\u5efa\u8bae\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\uff0c\u800c\u4e0d\u4f1a\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2510.08807", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08807", "abs": "https://arxiv.org/abs/2510.08807", "authors": ["Zhenyu Zhao", "Hongyi Jing", "Xiawei Liu", "Jiageng Mao", "Abha Jha", "Hanwen Yang", "Rong Xue", "Sergey Zakharor", "Vitor Guizilini", "Yue Wang"], "title": "Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation", "comment": null, "summary": "From loco-motion to dextrous manipulation, humanoid robots have made\nremarkable strides in demonstrating complex full-body capabilities. However,\nthe majority of current robot learning datasets and benchmarks mainly focus on\nstationary robot arms, and the few existing humanoid datasets are either\nconfined to fixed environments or limited in task diversity, often lacking\nhuman-humanoid interaction and lower-body locomotion. Moreover, there are a few\nstandardized evaluation platforms for benchmarking learning-based policies on\nhumanoid data. In this work, we present Humanoid Everyday, a large-scale and\ndiverse humanoid manipulation dataset characterized by extensive task variety\ninvolving dextrous object manipulation, human-humanoid interaction,\nlocomotion-integrated actions, and more. Leveraging a highly efficient\nhuman-supervised teleoperation pipeline, Humanoid Everyday aggregates\nhigh-quality multimodal sensory data, including RGB, depth, LiDAR, and tactile\ninputs, together with natural language annotations, comprising 10.3k\ntrajectories and over 3 million frames of data across 260 tasks across 7 broad\ncategories. In addition, we conduct an analysis of representative policy\nlearning methods on our dataset, providing insights into their strengths and\nlimitations across different task categories. For standardized evaluation, we\nintroduce a cloud-based evaluation platform that allows researchers to\nseamlessly deploy their policies in our controlled setting and receive\nperformance feedback. By releasing Humanoid Everyday along with our policy\nlearning analysis and a standardized cloud-based evaluation platform, we intend\nto advance research in general-purpose humanoid manipulation and lay the\ngroundwork for more capable and embodied robotic agents in real-world\nscenarios. Our dataset, data collection code, and cloud evaluation website are\nmade publicly available on our project website.", "AI": {"tldr": "\u63d0\u51fa\u4e86Humanoid Everyday\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u591a\u6837\u5316\u7684\u4eba\u5f62\u673a\u5668\u4eba\u64cd\u4f5c\u6570\u636e\u96c6\uff0c\u5305\u542b10.3k\u6761\u8f68\u8ff9\u548c\u8d85\u8fc7300\u4e07\u5e27\u6570\u636e\uff0c\u6db5\u76d6260\u4e2a\u4efb\u52a1\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e91\u7aef\u8bc4\u4f30\u5e73\u53f0\u3002", "motivation": "\u5f53\u524d\u673a\u5668\u4eba\u5b66\u4e60\u6570\u636e\u96c6\u4e3b\u8981\u5173\u6ce8\u56fa\u5b9a\u673a\u68b0\u81c2\uff0c\u73b0\u6709\u7684\u4eba\u5f62\u673a\u5668\u4eba\u6570\u636e\u96c6\u8981\u4e48\u5c40\u9650\u4e8e\u56fa\u5b9a\u73af\u5883\uff0c\u8981\u4e48\u4efb\u52a1\u591a\u6837\u6027\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u4eba\u673a\u4ea4\u4e92\u548c\u4e0b\u534a\u8eab\u8fd0\u52a8\uff0c\u4e14\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u5e73\u53f0\u3002", "method": "\u901a\u8fc7\u9ad8\u6548\u7684\u4eba\u7c7b\u76d1\u7763\u9065\u64cd\u4f5c\u6d41\u7a0b\u6536\u96c6\u9ad8\u8d28\u91cf\u591a\u6a21\u6001\u611f\u77e5\u6570\u636e\uff0c\u5305\u62ecRGB\u3001\u6df1\u5ea6\u3001LiDAR\u548c\u89e6\u89c9\u8f93\u5165\uff0c\u4ee5\u53ca\u81ea\u7136\u8bed\u8a00\u6ce8\u91ca\uff0c\u6db5\u76d67\u5927\u7c7b260\u4e2a\u4efb\u52a1\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b10.3k\u6761\u8f68\u8ff9\u548c\u8d85\u8fc7300\u4e07\u5e27\u6570\u636e\u7684\u591a\u6837\u5316\u6570\u636e\u96c6\uff0c\u5e76\u5206\u6790\u4e86\u4ee3\u8868\u6027\u7b56\u7565\u5b66\u4e60\u65b9\u6cd5\u5728\u4e0d\u540c\u4efb\u52a1\u7c7b\u522b\u4e0a\u7684\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u53d1\u5e03Humanoid Everyday\u6570\u636e\u96c6\u3001\u7b56\u7565\u5b66\u4e60\u5206\u6790\u548c\u6807\u51c6\u5316\u4e91\u7aef\u8bc4\u4f30\u5e73\u53f0\uff0c\u65e8\u5728\u63a8\u8fdb\u901a\u7528\u4eba\u5f62\u673a\u5668\u4eba\u64cd\u4f5c\u7814\u7a76\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u4e2d\u66f4\u5f3a\u5927\u3001\u5177\u8eab\u5316\u7684\u673a\u5668\u4eba\u667a\u80fd\u4f53\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.09055", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09055", "abs": "https://arxiv.org/abs/2510.09055", "authors": ["Tianhao Liang", "Mu Jia", "Tingting Zhang", "Junting Chen", "Longyu Zhou", "Tony Q. S. Quek", "Pooi-Yuen Kam"], "title": "Sensing, Detection and Localization for Low Altitude UAV: A RF-Based Framework via Multiple BSs Collaboration", "comment": null, "summary": "The rapid growth of the low-altitude economy has resulted in a significant\nincrease in the number of Low, slow, and small (LLS) unmanned aerial vehicles\n(UAVs), raising critical challenges for secure airspace management and reliable\ntrajectory planning. To address this, this paper proposes a cooperative\nradio-frequency (RF) detection and localization framework that leverages\nexisting cellular base stations. The proposed approach features a robust scheme\nfor LSS target identification, integrating a cell averaging-constant false\nalarm rate (CA-CFAR) detector with a micro-Doppler signature (MDS) based\nrecognition method. Multi-station measurements are fused through a grid-based\nprobabilistic algorithm combined with clustering techniques, effectively\nmitigating ghost targets and improving localization accuracy in multi-UAV\nscenarios. Furthermore, the Cramer-Rao lower bound (CRLB) is derived as a\nperformance benchmark and reinforcement learning (RL)-based optimization is\nemployed to balance localization accuracy against station resource usage.\nSimulations demonstrate that increasing from one to multiple BSs reduces the\npositioning error to near the CRLB, while practical experiments further verify\nthe framework's effectiveness. Furthermore, our RL-based optimization can find\nsolutions that maintain high accuracy while minimizing resource usage,\nhighlighting its potential as a scalable solution for ensuring airspace safety\nin the emerging low-altitude economy.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8702\u7a9d\u57fa\u7ad9\u7684\u534f\u4f5c\u5c04\u9891\u68c0\u6d4b\u4e0e\u5b9a\u4f4d\u6846\u67b6\uff0c\u7528\u4e8e\u4f4e\u6162\u5c0f\u65e0\u4eba\u673a\u7ba1\u7406\uff0c\u7ed3\u5408CA-CFAR\u68c0\u6d4b\u5668\u548c\u5fae\u591a\u666e\u52d2\u7279\u5f81\u8bc6\u522b\uff0c\u901a\u8fc7\u7f51\u683c\u6982\u7387\u7b97\u6cd5\u548c\u805a\u7c7b\u6280\u672f\u63d0\u9ad8\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u5e76\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u8d44\u6e90\u4f7f\u7528\u3002", "motivation": "\u4f4e\u7a7a\u7ecf\u6d4e\u5feb\u901f\u53d1\u5c55\u5bfc\u81f4\u4f4e\u6162\u5c0f\u65e0\u4eba\u673a\u6570\u91cf\u6fc0\u589e\uff0c\u7ed9\u7a7a\u57df\u5b89\u5168\u548c\u8f68\u8ff9\u89c4\u5212\u5e26\u6765\u6311\u6218\uff0c\u9700\u8981\u53ef\u9760\u7684\u68c0\u6d4b\u5b9a\u4f4d\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u8702\u7a9d\u57fa\u7ad9\u8fdb\u884c\u534f\u4f5c\u5c04\u9891\u68c0\u6d4b\uff0c\u7ed3\u5408CA-CFAR\u68c0\u6d4b\u5668\u548c\u5fae\u591a\u666e\u52d2\u7279\u5f81\u8bc6\u522b\u65b9\u6cd5\uff0c\u91c7\u7528\u7f51\u683c\u6982\u7387\u7b97\u6cd5\u878d\u5408\u591a\u7ad9\u6d4b\u91cf\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5b9a\u4f4d\u7cbe\u5ea6\u4e0e\u8d44\u6e90\u4f7f\u7528\u5e73\u8861\u3002", "result": "\u4eff\u771f\u663e\u793a\u591a\u57fa\u7ad9\u53ef\u5c06\u5b9a\u4f4d\u8bef\u5dee\u964d\u81f3\u63a5\u8fd1\u514b\u62c9\u7f8e-\u7f57\u4e0b\u754c\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027\uff0c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u80fd\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u6700\u5c0f\u5316\u8d44\u6e90\u4f7f\u7528\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u65b0\u5174\u4f4e\u7a7a\u7ecf\u6d4e\u4e2d\u7684\u7a7a\u57df\u5b89\u5168\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u7ba1\u7406\u591a\u65e0\u4eba\u673a\u573a\u666f\u5e76\u4f18\u5316\u8d44\u6e90\u5229\u7528\u3002"}}
{"id": "2510.09145", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.09145", "abs": "https://arxiv.org/abs/2510.09145", "authors": ["Mattia Mazzoli", "Irma Varela-Lasheras", "Sonia Namorado", "Constantino Pereira Caetano", "Andreia Leite", "Lisa Hermans", "Niel Hens", "Polen T\u00fcrkmen", "Kyriaki Kalimeri", "Leo Ferres", "Ciro Cattuto", "Daniela Paolotti", "Stefaan Verhulst"], "title": "Non-traditional data in pandemic preparedness and response: identifying and addressing first and last-mile challenges", "comment": null, "summary": "The pandemic served as an important test case of complementing traditional\npublic health data with non-traditional data (NTD) such as mobility traces,\nsocial media activity, and wearables data to inform decision-making. Drawing on\nan expert workshop and a targeted survey of European modelers, we assess the\npromise and persistent limitations of such data in pandemic preparedness and\nresponse. We distinguish between \"first-mile\" (accessing and harmonizing data)\nand \"last-mile\" challenges (translating insights into actionable\ninterventions). The expert workshop held in 2024 brought together participants\nfrom public health, academia, policymakers, and industry to reflect on lessons\nlearned and define strategies for translating NTD insights into policy making.\nThe survey offers evidence of the barriers faced during COVID-19 and highlights\nkey data unavailability and underuse. Our findings reveal ongoing issues with\ndata access, quality, and interoperability, as well as institutional and\ncognitive barriers to evidence-based decision-making. Around 66% of datasets\nsuffered access problem, with data sharing reluctance for NTD being double that\nof traditional data (30% vs 15%). Only 10% reported they could use all the data\nthey needed. We propose a set of recommendations: for first-mile challenges,\nsolutions focus on technical and legal frameworks for data access.; for\nlast-mile challenges, we recommend fusion centers, decision accelerator labs,\nand networks of scientific ambassadors to bridge the gap between analysis and\naction. Realizing the full value of NTD requires a sustained investment in\ninstitutional readiness, cross-sectoral collaboration, and a shift toward a\nculture of data solidarity. Grounded in the lessons of COVID-19, the article\ncan be used to design a roadmap for using NTD to confront a broader array of\npublic health emergencies, from climate shocks to humanitarian crises.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u5728\u75ab\u60c5\u671f\u95f4\u4f7f\u7528\u975e\u4f20\u7edf\u6570\u636e\uff08\u5982\u79fb\u52a8\u8f68\u8ff9\u3001\u793e\u4ea4\u5a92\u4f53\u6d3b\u52a8\u548c\u53ef\u7a7f\u6234\u8bbe\u5907\u6570\u636e\uff09\u8865\u5145\u4f20\u7edf\u516c\u5171\u536b\u751f\u6570\u636e\u7684\u6f5c\u529b\u548c\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u89e3\u51b3\"\u7b2c\u4e00\u82f1\u91cc\"\uff08\u6570\u636e\u83b7\u53d6\u548c\u534f\u8c03\uff09\u548c\"\u6700\u540e\u4e00\u82f1\u91cc\"\uff08\u5c06\u6d1e\u5bdf\u8f6c\u5316\u4e3a\u884c\u52a8\uff09\u6311\u6218\u7684\u5efa\u8bae\u3002", "motivation": "\u65b0\u51a0\u75ab\u60c5\u662f\u6d4b\u8bd5\u975e\u4f20\u7edf\u6570\u636e\u5728\u516c\u5171\u536b\u751f\u51b3\u7b56\u4e2d\u4ef7\u503c\u7684\u91cd\u8981\u6848\u4f8b\uff0c\u9700\u8981\u8bc4\u4f30\u6b64\u7c7b\u6570\u636e\u5728\u75ab\u60c5\u51c6\u5907\u548c\u54cd\u5e94\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6548\u679c\u548c\u6301\u7eed\u5b58\u5728\u7684\u969c\u788d\u3002", "method": "\u901a\u8fc72024\u5e74\u4e13\u5bb6\u7814\u8ba8\u4f1a\u548c\u9488\u5bf9\u6b27\u6d32\u5efa\u6a21\u5e08\u7684\u5b9a\u5411\u8c03\u67e5\uff0c\u6536\u96c6\u4e86\u5173\u4e8e\u975e\u4f20\u7edf\u6570\u636e\u4f7f\u7528\u969c\u788d\u548c\u6f5c\u529b\u7684\u5b9e\u8bc1\u8bc1\u636e\u3002", "result": "\u7814\u7a76\u53d1\u73b066%\u7684\u6570\u636e\u96c6\u5b58\u5728\u8bbf\u95ee\u95ee\u9898\uff0c\u975e\u4f20\u7edf\u6570\u636e\u5171\u4eab\u4e0d\u60c5\u613f\u7a0b\u5ea6\u662f\u4f20\u7edf\u6570\u636e\u7684\u4e24\u500d\uff0830% vs 15%\uff09\uff0c\u53ea\u670910%\u7684\u53d7\u8bbf\u8005\u80fd\u591f\u4f7f\u7528\u6240\u6709\u9700\u8981\u7684\u6570\u636e\u3002\u6570\u636e\u8bbf\u95ee\u3001\u8d28\u91cf\u548c\u4e92\u64cd\u4f5c\u6027\u4ecd\u7136\u662f\u4e3b\u8981\u6311\u6218\u3002", "conclusion": "\u5b9e\u73b0\u975e\u4f20\u7edf\u6570\u636e\u7684\u5168\u90e8\u4ef7\u503c\u9700\u8981\u5728\u673a\u6784\u51c6\u5907\u5ea6\u3001\u8de8\u90e8\u95e8\u534f\u4f5c\u548c\u6570\u636e\u56e2\u7ed3\u6587\u5316\u65b9\u9762\u8fdb\u884c\u6301\u7eed\u6295\u8d44\uff0c\u5efa\u8bae\u5efa\u7acb\u878d\u5408\u4e2d\u5fc3\u3001\u51b3\u7b56\u52a0\u901f\u5b9e\u9a8c\u5ba4\u548c\u79d1\u5b66\u5927\u4f7f\u7f51\u7edc\u6765\u5f25\u5408\u5206\u6790\u4e0e\u884c\u52a8\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2510.08790", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.08790", "abs": "https://arxiv.org/abs/2510.08790", "authors": ["Guangya Wan", "Mingyang Ling", "Xiaoqi Ren", "Rujun Han", "Sheng Li", "Zizhao Zhang"], "title": "COMPASS: Enhancing Agent Long-Horizon Reasoning with Evolving Context", "comment": "Under Review for ACL", "summary": "Long-horizon tasks that require sustained reasoning and multiple tool\ninteractions remain challenging for LLM agents: small errors compound across\nsteps, and even state-of-the-art models often hallucinate or lose coherence. We\nidentify context management as the central bottleneck -- extended histories\ncause agents to overlook critical evidence or become distracted by irrelevant\ninformation, thus failing to replan or reflect from previous mistakes. To\naddress this, we propose COMPASS (Context-Organized Multi-Agent Planning and\nStrategy System), a lightweight hierarchical framework that separates tactical\nexecution, strategic oversight, and context organization into three specialized\ncomponents: (1) a Main Agent that performs reasoning and tool use, (2) a\nMeta-Thinker that monitors progress and issues strategic interventions, and (3)\na Context Manager that maintains concise, relevant progress briefs for\ndifferent reasoning stages. Across three challenging benchmarks -- GAIA,\nBrowseComp, and Humanity's Last Exam -- COMPASS improves accuracy by up to 20%\nrelative to both single- and multi-agent baselines. We further introduce a\ntest-time scaling extension that elevates performance to match established\nDeepResearch agents, and a post-training pipeline that delegates context\nmanagement to smaller models for enhanced efficiency.", "AI": {"tldr": "COMPASS\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5206\u5c42\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6218\u672f\u6267\u884c\u3001\u6218\u7565\u76d1\u7763\u548c\u4e0a\u4e0b\u6587\u7ba1\u7406\u5206\u79bb\u5230\u4e09\u4e2a\u4e13\u95e8\u7ec4\u4ef6\u4e2d\uff0c\u89e3\u51b3\u4e86LLM\u667a\u80fd\u4f53\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u957f\u65f6\u7a0b\u4efb\u52a1\u9700\u8981\u6301\u7eed\u63a8\u7406\u548c\u591a\u6b21\u5de5\u5177\u4ea4\u4e92\uff0c\u8fd9\u5bf9LLM\u667a\u80fd\u4f53\u5177\u6709\u6311\u6218\u6027\uff1a\u5c0f\u9519\u8bef\u4f1a\u5728\u6b65\u9aa4\u95f4\u7d2f\u79ef\uff0c\u5373\u4f7f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u7ecf\u5e38\u4ea7\u751f\u5e7b\u89c9\u6216\u5931\u53bb\u8fde\u8d2f\u6027\u3002\u4e0a\u4e0b\u6587\u7ba1\u7406\u662f\u6838\u5fc3\u74f6\u9888\u2014\u2014\u6269\u5c55\u7684\u5386\u53f2\u8bb0\u5f55\u5bfc\u81f4\u667a\u80fd\u4f53\u5ffd\u7565\u5173\u952e\u8bc1\u636e\u6216\u88ab\u65e0\u5173\u4fe1\u606f\u5206\u6563\u6ce8\u610f\u529b\u3002", "method": "COMPASS\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u4e13\u95e8\u7ec4\u4ef6\uff1a(1)\u4e3b\u667a\u80fd\u4f53\u6267\u884c\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\uff0c(2)\u5143\u601d\u8003\u5668\u76d1\u63a7\u8fdb\u5ea6\u5e76\u53d1\u51fa\u6218\u7565\u5e72\u9884\uff0c(3)\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\u4e3a\u4e0d\u540c\u63a8\u7406\u9636\u6bb5\u7ef4\u62a4\u7b80\u6d01\u76f8\u5173\u7684\u8fdb\u5ea6\u7b80\u62a5\u3002", "result": "\u5728GAIA\u3001BrowseComp\u548cHumanity's Last Exam\u4e09\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCOMPASS\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u57fa\u7ebf\u51c6\u786e\u7387\u63d0\u9ad8\u4e86\u9ad8\u8fbe20%\u3002", "conclusion": "COMPASS\u901a\u8fc7\u4e13\u95e8\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u6709\u6548\u89e3\u51b3\u4e86\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u8fde\u8d2f\u6027\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6d4b\u8bd5\u65f6\u6269\u5c55\u548c\u8bad\u7ec3\u540e\u6d41\u6c34\u7ebf\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2510.08811", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.08811", "abs": "https://arxiv.org/abs/2510.08811", "authors": ["Jiurun Song", "Xiao Liang", "Minghui Zheng"], "title": "Adaptive Motion Planning via Contact-Based Intent Inference for Human-Robot Collaboration", "comment": null, "summary": "Human-robot collaboration (HRC) requires robots to adapt their motions to\nhuman intent to ensure safe and efficient cooperation in shared spaces.\nAlthough large language models (LLMs) provide high-level reasoning for\ninferring human intent, their application to reliable motion planning in HRC\nremains challenging. Physical human-robot interaction (pHRI) is intuitive but\noften relies on continuous kinesthetic guidance, which imposes burdens on\noperators. To address these challenges, a contact-informed adaptive\nmotion-planning framework is introduced to infer human intent directly from\nphysical contact and employ the inferred intent for online motion correction in\nHRC. First, an optimization-based force estimation method is proposed to infer\nhuman-intended contact forces and locations from joint torque measurements and\na robot dynamics model, thereby reducing cost and installation complexity while\nenabling whole-body sensitivity. Then, a torque-based contact detection\nmechanism with link-level localization is introduced to reduce the optimization\nsearch space and to enable real-time estimation. Subsequently, a\ncontact-informed adaptive motion planner is developed to infer human intent\nfrom contacts and to replan robot motion online, while maintaining smoothness\nand adapting to human corrections. Finally, experiments on a 7-DOF manipulator\nare conducted to demonstrate the accuracy of the proposed force estimation\nmethod and the effectiveness of the contact-informed adaptive motion planner\nunder perception uncertainty in HRC.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63a5\u89e6\u4fe1\u606f\u7684\u4eba\u673a\u534f\u4f5c\u81ea\u9002\u5e94\u8fd0\u52a8\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u7269\u7406\u63a5\u89e6\u63a8\u65ad\u4eba\u7c7b\u610f\u56fe\u5e76\u5728\u7ebf\u4fee\u6b63\u673a\u5668\u4eba\u8fd0\u52a8", "motivation": "\u89e3\u51b3\u4eba\u673a\u534f\u4f5c\u4e2d\u673a\u5668\u4eba\u5982\u4f55\u5b89\u5168\u9ad8\u6548\u5730\u9002\u5e94\u4eba\u7c7b\u610f\u56fe\u7684\u95ee\u9898\uff0c\u514b\u670d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53ef\u9760\u8fd0\u52a8\u89c4\u5212\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4ee5\u53ca\u7269\u7406\u4eba\u673a\u4ea4\u4e92\u4e2d\u6301\u7eed\u5f15\u5bfc\u7ed9\u64cd\u4f5c\u8005\u5e26\u6765\u7684\u8d1f\u62c5", "method": "1) \u57fa\u4e8e\u4f18\u5316\u7684\u529b\u4f30\u8ba1\u65b9\u6cd5\u4ece\u5173\u8282\u626d\u77e9\u6d4b\u91cf\u63a8\u65ad\u4eba\u7c7b\u610f\u56fe\u7684\u63a5\u89e6\u529b\u548c\u4f4d\u7f6e\uff1b2) \u57fa\u4e8e\u626d\u77e9\u7684\u63a5\u89e6\u68c0\u6d4b\u673a\u5236\u8fdb\u884c\u94fe\u63a5\u7ea7\u5b9a\u4f4d\uff1b3) \u63a5\u89e6\u4fe1\u606f\u81ea\u9002\u5e94\u8fd0\u52a8\u89c4\u5212\u5668\u5728\u7ebf\u91cd\u65b0\u89c4\u5212\u673a\u5668\u4eba\u8fd0\u52a8", "result": "\u57287\u81ea\u7531\u5ea6\u673a\u68b0\u81c2\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u529b\u4f30\u8ba1\u65b9\u6cd5\u5177\u6709\u51c6\u786e\u6027\uff0c\u63a5\u89e6\u4fe1\u606f\u81ea\u9002\u5e94\u8fd0\u52a8\u89c4\u5212\u5668\u5728\u4eba\u673a\u534f\u4f5c\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u4e0b\u5177\u6709\u6709\u6548\u6027", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u76f4\u63a5\u4ece\u7269\u7406\u63a5\u89e6\u63a8\u65ad\u4eba\u7c7b\u610f\u56fe\uff0c\u5b9e\u73b0\u5b9e\u65f6\u8fd0\u52a8\u4fee\u6b63\uff0c\u4e3a\u4eba\u673a\u534f\u4f5c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9760\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.09138", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09138", "abs": "https://arxiv.org/abs/2510.09138", "authors": ["Adel Omrani", "Sajjad Sadeghi"], "title": "Antenna's Performance in Microwave Imaging of Stratified Media", "comment": null, "summary": "Numerous types of antennas have been employed for microwave imaging of\nstratified media for ground penetrating radar (GPR), through-the-wall-radar\nimaging (TWRI), etc. This letter aims to investigate the impact of the\ndifferent antennas with their characteristics on the image reconstruction of\nthose media. Hence, three types of antennas, including horn antennas, open\nwaveguide and Vivaldi antennas, are chosen as almost directional antennas,\noperating at X-band 8-12 GHz. The antenna's far-field and near-field\ncharacteristics are analyzed. A diffraction tomography (DT)-based algorithm is\nused to reconstruct the target location within the stratified media using\nmonostatic and multistatic data. It is observed that the more directional\nantennas provide a better-reconstructed image with less shadowing image of the\nstratified media.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e0d\u540c\u7c7b\u578b\u5929\u7ebf\uff08\u5587\u53ed\u5929\u7ebf\u3001\u5f00\u53e3\u6ce2\u5bfc\u548cVivaldi\u5929\u7ebf\uff09\u5bf9\u5206\u5c42\u4ecb\u8d28\u5fae\u6ce2\u6210\u50cf\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5728X\u6ce2\u6bb58-12GHz\u4e0b\uff0c\u65b9\u5411\u6027\u66f4\u5f3a\u7684\u5929\u7ebf\u80fd\u63d0\u4f9b\u66f4\u597d\u7684\u91cd\u5efa\u56fe\u50cf\u8d28\u91cf\u3002", "motivation": "\u7814\u7a76\u4e0d\u540c\u5929\u7ebf\u7279\u6027\u5bf9\u5206\u5c42\u4ecb\u8d28\uff08\u5982\u63a2\u5730\u96f7\u8fbe\u3001\u7a7f\u5899\u96f7\u8fbe\u6210\u50cf\uff09\u56fe\u50cf\u91cd\u5efa\u7684\u5f71\u54cd\uff0c\u4ee5\u4f18\u5316\u5fae\u6ce2\u6210\u50cf\u7cfb\u7edf\u7684\u5929\u7ebf\u9009\u62e9\u3002", "method": "\u9009\u62e9\u4e09\u79cd\u51c6\u5b9a\u5411\u5929\u7ebf\uff0c\u5206\u6790\u5176\u8fdc\u573a\u548c\u8fd1\u573a\u7279\u6027\uff0c\u4f7f\u7528\u57fa\u4e8e\u884d\u5c04\u5c42\u6790\u6210\u50cf\u7684\u7b97\u6cd5\u5904\u7406\u5355\u9759\u6001\u548c\u591a\u9759\u6001\u6570\u636e\u6765\u91cd\u5efa\u76ee\u6807\u4f4d\u7f6e\u3002", "result": "\u89c2\u5bdf\u5230\u65b9\u5411\u6027\u66f4\u5f3a\u7684\u5929\u7ebf\u80fd\u591f\u63d0\u4f9b\u66f4\u597d\u7684\u91cd\u5efa\u56fe\u50cf\uff0c\u51cf\u5c11\u5206\u5c42\u4ecb\u8d28\u7684\u9634\u5f71\u56fe\u50cf\u3002", "conclusion": "\u5929\u7ebf\u65b9\u5411\u6027\u5bf9\u5206\u5c42\u4ecb\u8d28\u5fae\u6ce2\u6210\u50cf\u8d28\u91cf\u6709\u663e\u8457\u5f71\u54cd\uff0c\u9ad8\u65b9\u5411\u6027\u5929\u7ebf\u80fd\u6539\u5584\u56fe\u50cf\u91cd\u5efa\u6548\u679c\u3002"}}
{"id": "2510.09155", "categories": ["cs.CY", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.09155", "abs": "https://arxiv.org/abs/2510.09155", "authors": ["Mira Raheem", "Michael Papazoglou", "Bernd Kr\u00e4mer", "Neamat El-Tazi", "Amal Elgammal"], "title": "Federated Data Analytics for Cancer Immunotherapy: A Privacy-Preserving Collaborative Platform for Patient Management", "comment": "This manuscript is currently under review at * ACM Transactions on\n  Computing for Healthcare (HEALTH)*", "summary": "Connected health is a multidisciplinary approach focused on health\nmanagement, prioritizing pa-tient needs in the creation of tools, services, and\ntreatments. This paradigm ensures proactive and efficient care by facilitating\nthe timely exchange of accurate patient information among all stake-holders in\nthe care continuum. The rise of digital technologies and process innovations\npromises to enhance connected health by integrating various healthcare data\nsources. This integration aims to personalize care, predict health outcomes,\nand streamline patient management, though challeng-es remain, particularly in\ndata architecture, application interoperability, and security. Data analytics\ncan provide critical insights for informed decision-making and health\nco-creation, but solutions must prioritize end-users, including patients and\nhealthcare professionals. This perspective was explored through an agile System\nDevelopment Lifecycle in an EU-funded project aimed at developing an integrated\nAI-generated solution for managing cancer patients undergoing immunotherapy.\nThis paper contributes with a collaborative digital framework integrating\nstakeholders across the care continuum, leveraging federated big data analytics\nand artificial intelligence for improved decision-making while ensuring\nprivacy. Analytical capabilities, such as treatment recommendations and adverse\nevent predictions, were validated using real-life data, achieving 70%-90%\naccuracy in a pilot study with the medical partners, demonstrating the\nframework's effectiveness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u534f\u4f5c\u5f0f\u6570\u5b57\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u90a6\u5927\u6570\u636e\u5206\u6790\u548c\u4eba\u5de5\u667a\u80fd\u6574\u5408\u533b\u7597\u4fdd\u5065\u6570\u636e\u6e90\uff0c\u4e3a\u63a5\u53d7\u514d\u75ab\u6cbb\u7597\u7684\u764c\u75c7\u60a3\u8005\u63d0\u4f9b\u4e2a\u6027\u5316\u62a4\u7406\u548c\u9884\u6d4b\uff0c\u5728\u8bd5\u70b9\u7814\u7a76\u4e2d\u8fbe\u523070%-90%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u8fde\u63a5\u5065\u5eb7\u6a21\u5f0f\u9700\u8981\u6574\u5408\u5404\u79cd\u533b\u7597\u6570\u636e\u6e90\u6765\u4e2a\u6027\u5316\u62a4\u7406\u3001\u9884\u6d4b\u5065\u5eb7\u7ed3\u679c\u548c\u7b80\u5316\u60a3\u8005\u7ba1\u7406\uff0c\u4f46\u9762\u4e34\u6570\u636e\u67b6\u6784\u3001\u5e94\u7528\u4e92\u64cd\u4f5c\u6027\u548c\u5b89\u5168\u6027\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u654f\u6377\u7cfb\u7edf\u5f00\u53d1\u751f\u547d\u5468\u671f\uff0c\u5f00\u53d1\u96c6\u6210AI\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5229\u7528\u8054\u90a6\u5927\u6570\u636e\u5206\u6790\u548c\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u786e\u4fdd\u9690\u79c1\u7684\u540c\u65f6\u6539\u5584\u51b3\u7b56\u3002", "result": "\u5728\u8bd5\u70b9\u7814\u7a76\u4e2d\uff0c\u6cbb\u7597\u5efa\u8bae\u548c\u4e0d\u826f\u4e8b\u4ef6\u9884\u6d4b\u7b49\u5206\u6790\u80fd\u529b\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u9a8c\u8bc1\uff0c\u8fbe\u523070%-90%\u7684\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u534f\u4f5c\u6570\u5b57\u6846\u67b6\u6210\u529f\u6574\u5408\u4e86\u62a4\u7406\u8fde\u7eed\u4f53\u4e2d\u7684\u5229\u76ca\u76f8\u5173\u8005\uff0c\u901a\u8fc7\u8054\u90a6\u5206\u6790\u548cAI\u6280\u672f\u5b9e\u73b0\u4e86\u6539\u8fdb\u7684\u51b3\u7b56\u5236\u5b9a\uff0c\u540c\u65f6\u786e\u4fdd\u4e86\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2510.08831", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.08831", "abs": "https://arxiv.org/abs/2510.08831", "authors": ["Wouter Haverals", "Meredith Martin"], "title": "Everyone prefers human writers, including AI", "comment": "46 pages, 18 figures (5 main text + 13 supplementary), 5 tables", "summary": "As AI writing tools become widespread, we need to understand how both humans\nand machines evaluate literary style, a domain where objective standards are\nelusive and judgments are inherently subjective. We conducted controlled\nexperiments using Raymond Queneau's Exercises in Style (1947) to measure\nattribution bias across evaluators. Study 1 compared human participants (N=556)\nand AI models (N=13) evaluating literary passages from Queneau versus\nGPT-4-generated versions under three conditions: blind, accurately labeled, and\ncounterfactually labeled. Study 2 tested bias generalization across a\n14$\\times$14 matrix of AI evaluators and creators. Both studies revealed\nsystematic pro-human attribution bias. Humans showed +13.7 percentage point\n(pp) bias (Cohen's h = 0.28, 95% CI: 0.21-0.34), while AI models showed +34.3\npercentage point bias (h = 0.70, 95% CI: 0.65-0.76), a 2.5-fold stronger effect\n(P$<$0.001). Study 2 confirmed this bias operates across AI architectures\n(+25.8pp, 95% CI: 24.1-27.6%), demonstrating that AI systems systematically\ndevalue creative content when labeled as \"AI-generated\" regardless of which AI\ncreated it. We also find that attribution labels cause evaluators to invert\nassessment criteria, with identical features receiving opposing evaluations\nbased solely on perceived authorship. This suggests AI models have absorbed\nhuman cultural biases against artificial creativity during training. Our study\nrepresents the first controlled comparison of attribution bias between human\nand artificial evaluators in aesthetic judgment, revealing that AI systems not\nonly replicate but amplify this human tendency.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4eba\u7c7b\u548cAI\u8bc4\u4f30\u8005\u5728\u6587\u5b66\u98ce\u683c\u8bc4\u5224\u4e2d\u90fd\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0cAI\u6bd4\u4eba\u7c7b\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u53cdAI\u504f\u89c1\uff082.5\u500d\uff09\uff0c\u4e14\u8fd9\u79cd\u504f\u89c1\u5728\u4e0d\u540cAI\u67b6\u6784\u95f4\u666e\u904d\u5b58\u5728\u3002", "motivation": "\u968f\u7740AI\u5199\u4f5c\u5de5\u5177\u7684\u666e\u53ca\uff0c\u9700\u8981\u7406\u89e3\u4eba\u7c7b\u548c\u673a\u5668\u5982\u4f55\u8bc4\u4f30\u6587\u5b66\u98ce\u683c\u8fd9\u4e00\u4e3b\u89c2\u9886\u57df\uff0c\u7279\u522b\u662f\u8bc4\u4f30\u4e2d\u7684\u5f52\u56e0\u504f\u89c1\u95ee\u9898\u3002", "method": "\u4f7f\u7528Raymond Queneau\u7684\u300a\u98ce\u683c\u7ec3\u4e60\u300b\u8fdb\u884c\u5bf9\u7167\u5b9e\u9a8c\u3002\u7814\u7a761\u6bd4\u8f83\u4eba\u7c7b\u53c2\u4e0e\u8005\u548cAI\u6a21\u578b\u5728\u76f2\u8bc4\u3001\u51c6\u786e\u6807\u6ce8\u548c\u53cd\u4e8b\u5b9e\u6807\u6ce8\u6761\u4ef6\u4e0b\u8bc4\u4f30\u6587\u5b66\u6bb5\u843d\uff1b\u7814\u7a762\u6d4b\u8bd5\u504f\u89c1\u572814\u00d714 AI\u8bc4\u4f30\u8005\u548c\u521b\u4f5c\u8005\u77e9\u9635\u4e2d\u7684\u6cdb\u5316\u6027\u3002", "result": "\u4eba\u7c7b\u663e\u793a+13.7\u4e2a\u767e\u5206\u70b9\u7684\u504f\u89c1\uff0cAI\u6a21\u578b\u663e\u793a+34.3\u4e2a\u767e\u5206\u70b9\u7684\u504f\u89c1\uff082.5\u500d\u66f4\u5f3a\uff09\u3002\u7814\u7a762\u8bc1\u5b9e\u8fd9\u79cd\u504f\u89c1\u5728\u4e0d\u540cAI\u67b6\u6784\u95f4\u666e\u904d\u5b58\u5728\uff08+25.8\u4e2a\u767e\u5206\u70b9\uff09\u3002\u5f52\u56e0\u6807\u7b7e\u5bfc\u81f4\u8bc4\u4f30\u8005\u98a0\u5012\u8bc4\u4f30\u6807\u51c6\u3002", "conclusion": "AI\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5438\u6536\u4e86\u4eba\u7c7b\u5bf9\u4eba\u5de5\u521b\u9020\u529b\u7684\u6587\u5316\u504f\u89c1\uff0c\u4e0d\u4ec5\u590d\u5236\u8fd8\u653e\u5927\u4e86\u8fd9\u79cd\u4eba\u7c7b\u503e\u5411\u3002\u8fd9\u662f\u9996\u6b21\u5728\u7f8e\u5b66\u5224\u65ad\u4e2d\u6bd4\u8f83\u4eba\u7c7b\u548cAI\u8bc4\u4f30\u8005\u5f52\u56e0\u504f\u89c1\u7684\u5bf9\u7167\u7814\u7a76\u3002"}}
{"id": "2510.08812", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08812", "abs": "https://arxiv.org/abs/2510.08812", "authors": ["Grace Ra Kim", "Hailey Warner", "Duncan Eddy", "Evan Astle", "Zachary Booth", "Edward Balaban", "Mykel J. Kochenderfer"], "title": "Adaptive Science Operations in Deep Space Missions Using Offline Belief State Planning", "comment": "7 pages, 4 tables, 5 figures, accepted in IEEE ISPARO 2026", "summary": "Deep space missions face extreme communication delays and environmental\nuncertainty that prevent real-time ground operations. To support autonomous\nscience operations in communication-constrained environments, we present a\npartially observable Markov decision process (POMDP) framework that adaptively\nsequences spacecraft science instruments. We integrate a Bayesian network into\nthe POMDP observation space to manage the high-dimensional and uncertain\nmeasurements typical of astrobiology missions. This network compactly encodes\ndependencies among measurements and improves the interpretability and\ncomputational tractability of science data. Instrument operation policies are\ncomputed offline, allowing resource-aware plans to be generated and thoroughly\nvalidated prior to launch. We use the Enceladus Orbilander's proposed Life\nDetection Suite (LDS) as a case study, demonstrating how Bayesian network\nstructure and reward shaping influence system performance. We compare our\nmethod against the mission's baseline Concept of Operations (ConOps),\nevaluating both misclassification rates and performance in off-nominal sample\naccumulation scenarios. Our approach reduces sample identification errors by\nnearly 40%", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b(POMDP)\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u901a\u4fe1\u53d7\u9650\u7684\u6df1\u7a7a\u4efb\u52a1\u4e2d\u81ea\u9002\u5e94\u6392\u5e8f\u822a\u5929\u5668\u79d1\u5b66\u4eea\u5668\uff0c\u901a\u8fc7\u96c6\u6210\u8d1d\u53f6\u65af\u7f51\u7edc\u6765\u7ba1\u7406\u9ad8\u7ef4\u4e0d\u786e\u5b9a\u6d4b\u91cf\u6570\u636e\u3002", "motivation": "\u6df1\u7a7a\u4efb\u52a1\u9762\u4e34\u6781\u7aef\u7684\u901a\u4fe1\u5ef6\u8fdf\u548c\u73af\u5883\u4e0d\u786e\u5b9a\u6027\uff0c\u65e0\u6cd5\u8fdb\u884c\u5b9e\u65f6\u5730\u9762\u64cd\u4f5c\uff0c\u9700\u8981\u652f\u6301\u81ea\u4e3b\u79d1\u5b66\u64cd\u4f5c\u3002", "method": "\u5c06\u8d1d\u53f6\u65af\u7f51\u7edc\u96c6\u6210\u5230POMDP\u89c2\u6d4b\u7a7a\u95f4\u4e2d\uff0c\u7d27\u51d1\u7f16\u7801\u6d4b\u91cf\u4f9d\u8d56\u5173\u7cfb\uff0c\u79bb\u7ebf\u8ba1\u7b97\u4eea\u5668\u64cd\u4f5c\u7b56\u7565\uff0c\u751f\u6210\u8d44\u6e90\u611f\u77e5\u8ba1\u5212\u3002", "result": "\u4f7f\u7528Enceladus Orbilander\u7684\u751f\u547d\u68c0\u6d4b\u5957\u4ef6\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u4e0e\u4efb\u52a1\u57fa\u7ebf\u6982\u5ff5\u64cd\u4f5c\u76f8\u6bd4\uff0c\u6837\u672c\u8bc6\u522b\u9519\u8bef\u51cf\u5c11\u4e86\u8fd140%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u79d1\u5b66\u6570\u636e\u7684\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u53ef\u884c\u6027\uff0c\u5728\u975e\u6807\u79f0\u6837\u672c\u79ef\u7d2f\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2510.09169", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09169", "abs": "https://arxiv.org/abs/2510.09169", "authors": ["Paul Mayr", "Alessandro Pisano", "Stefan Koch", "Markus Reichhartinger"], "title": "Robust Adaptive Boundary Control of a Thermal Process with Thermoelectric Actuators: Theory and Experimental Validation", "comment": "Extended version of the preprint submitted to the journal Automatica", "summary": "A sliding-mode-based adaptive boundary control law is proposed for a class of\nuncertain thermal reaction-diffusion processes subject to matched disturbances.\nThe disturbances are assumed to be bounded, but the corresponding bounds are\nunknown, thus motivating the use of adaptive control strategies. A boundary\ncontrol law comprising a proportional and discontinuous term is proposed,\nwherein the magnitude of the discontinuous relay term is adjusted via a\ngradient-based adaptation algorithm. Depending on how the adaptation algorithm\nis parameterized, the adaptive gain can be either a nondecreasing function of\ntime (monodirectional adaptation) or it can both increase and decrease\n(bidirectional adaptation). The convergence and stability properties of these\ntwo solutions are investigated by Lyapunov analyses, and two distinct stability\nresults are derived, namely, asymptotic stability for the monodirectional\nadaptation and globally uniformly ultimately bounded solutions for the\nbidirectional adaptation. The proposed algorithms are then specified to address\nthe control problem of stabilizing a desired temperature profile in a metal\nbeam equipped with thermoelectric boundary actuators. Experiments are conducted\nto investigate the real-world performance of the proposed sliding-mode-based\nadaptive control, with a particular focus on comparing the monodirectional and\nbidirectional adaptation laws.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ed1\u6a21\u7684\u81ea\u9002\u5e94\u8fb9\u754c\u63a7\u5236\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u5177\u6709\u5339\u914d\u6270\u52a8\u7684\u70ed\u53cd\u5e94\u6269\u6563\u8fc7\u7a0b\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7b97\u6cd5\u8c03\u6574\u6ed1\u6a21\u63a7\u5236\u4e2d\u7684\u4e0d\u8fde\u7eed\u9879\u5e45\u503c", "motivation": "\u5904\u7406\u70ed\u53cd\u5e94\u6269\u6563\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u6709\u754c\u4f46\u8fb9\u754c\u672a\u77e5\u7684\u5339\u914d\u6270\u52a8\uff0c\u9700\u8981\u5f00\u53d1\u81ea\u9002\u5e94\u63a7\u5236\u7b56\u7565\u6765\u5e94\u5bf9\u672a\u77e5\u6270\u52a8\u8fb9\u754c", "method": "\u91c7\u7528\u8fb9\u754c\u63a7\u5236\u5f8b\uff08\u6bd4\u4f8b\u9879+\u4e0d\u8fde\u7eed\u9879\uff09\uff0c\u901a\u8fc7\u68af\u5ea6\u81ea\u9002\u5e94\u7b97\u6cd5\u8c03\u6574\u4e0d\u8fde\u7eed\u4e2d\u7ee7\u9879\u7684\u5e45\u503c\uff0c\u5305\u62ec\u5355\u5411\u81ea\u9002\u5e94\uff08\u589e\u76ca\u5355\u8c03\u9012\u589e\uff09\u548c\u53cc\u5411\u81ea\u9002\u5e94\uff08\u589e\u76ca\u53ef\u589e\u51cf\uff09\u4e24\u79cd\u53c2\u6570\u5316\u65b9\u5f0f", "result": "\u901a\u8fc7Lyapunov\u5206\u6790\u8bc1\u660e\u4e86\u5355\u5411\u81ea\u9002\u5e94\u5177\u6709\u6e10\u8fd1\u7a33\u5b9a\u6027\uff0c\u53cc\u5411\u81ea\u9002\u5e94\u5177\u6709\u5168\u5c40\u4e00\u81f4\u6700\u7ec8\u6709\u754c\u89e3", "conclusion": "\u8be5\u81ea\u9002\u5e94\u6ed1\u6a21\u63a7\u5236\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u70ed\u53cd\u5e94\u6269\u6563\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6270\u52a8\uff0c\u5e76\u5728\u91d1\u5c5e\u6881\u6e29\u5ea6\u63a7\u5236\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u4e24\u79cd\u81ea\u9002\u5e94\u7b56\u7565\u7684\u5b9e\u9645\u6027\u80fd"}}
{"id": "2510.09183", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.09183", "abs": "https://arxiv.org/abs/2510.09183", "authors": ["Jianxiao Jiang", "Yu Zhang"], "title": "Student Development Agent: Risk-free Simulation for Evaluating AIED Innovations", "comment": null, "summary": "In the age of AI-powered educational (AIED) innovation, evaluating the\ndevelopmental consequences of novel designs before they are exposed to students\nhas become both essential and challenging. Since such interventions may carry\nirreversible effects, it is critical to anticipate not only potential benefits\nbut also possible harms. This study proposes a student development agent\nframework based on large language models (LLMs), designed to simulate how\nstudents with diverse characteristics may evolve under different educational\nsettings without administering them to real students. By validating the\napproach through a case study on a multi-agent learning environment (MAIC), we\ndemonstrate that the agent's predictions align with real student outcomes in\nnon-cognitive developments. The results suggest that LLM-based simulations hold\npromise for evaluating AIED innovations efficiently and ethically. Future\ndirections include enhancing profile structures, incorporating fine-tuned or\nsmall task-specific models, validating effects of empirical findings,\ninterpreting simulated data and optimizing evaluation methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b66\u751f\u53d1\u5c55\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u4e0d\u540c\u6559\u80b2\u73af\u5883\u4e0b\u5b66\u751f\u7684\u975e\u8ba4\u77e5\u53d1\u5c55\uff0c\u907f\u514d\u5bf9\u771f\u5b9e\u5b66\u751f\u8fdb\u884c\u5b9e\u9a8c\u3002", "motivation": "\u5728AI\u6559\u80b2\u521b\u65b0\u65f6\u4ee3\uff0c\u9700\u8981\u5728\u5411\u5b66\u751f\u66b4\u9732\u65b0\u8bbe\u8ba1\u524d\u8bc4\u4f30\u5176\u53d1\u5c55\u5f71\u54cd\uff0c\u56e0\u4e3a\u8fd9\u7c7b\u5e72\u9884\u53ef\u80fd\u4ea7\u751f\u4e0d\u53ef\u9006\u7684\u540e\u679c\u3002", "method": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u5b66\u751f\u53d1\u5c55\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u73af\u5883\u6848\u4f8b\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\u3002", "result": "\u4ee3\u7406\u9884\u6d4b\u7ed3\u679c\u4e0e\u771f\u5b9e\u5b66\u751f\u975e\u8ba4\u77e5\u53d1\u5c55\u7ed3\u679c\u4e00\u81f4\uff0c\u8868\u660e\u57fa\u4e8eLLM\u7684\u6a21\u62df\u6709\u671b\u9ad8\u6548\u4e14\u7b26\u5408\u4f26\u7406\u5730\u8bc4\u4f30AI\u6559\u80b2\u521b\u65b0\u3002", "conclusion": "LLM\u6a21\u62df\u5728\u6559\u80b2\u521b\u65b0\u8bc4\u4f30\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u672a\u6765\u9700\u6539\u8fdb\u6863\u6848\u7ed3\u6784\u3001\u6574\u5408\u7279\u5b9a\u4efb\u52a1\u6a21\u578b\u3001\u9a8c\u8bc1\u5b9e\u8bc1\u53d1\u73b0\u6548\u679c\u3001\u89e3\u91ca\u6a21\u62df\u6570\u636e\u5e76\u4f18\u5316\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2510.08847", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.08847", "abs": "https://arxiv.org/abs/2510.08847", "authors": ["Allison Sihan Jia", "Daniel Huang", "Nikhil Vytla", "Nirvika Choudhury", "John C Mitchell", "Anupam Datta"], "title": "What Is Your Agent's GPA? A Framework for Evaluating Agent Goal-Plan-Action Alignment", "comment": null, "summary": "We introduce the Agent GPA (Goal-Plan-Action) framework: an evaluation\nparadigm based on an agent's operational loop of setting goals, devising plans,\nand executing actions. The framework includes five evaluation metrics: Goal\nFulfillment, Logical Consistency, Execution Efficiency, Plan Quality, and Plan\nAdherence. Logical Consistency checks that an agent's actions are consistent\nwith its prior actions. Execution Efficiency checks whether the agent executes\nin the most efficient way to achieve its goal. Plan Quality checks whether an\nagent's plans are aligned with its goals; Plan Adherence checks if an agent's\nactions are aligned with its plan; and Goal Fulfillment checks that agent's\nfinal outcomes match the stated goals. Our experimental results on two\nbenchmark datasets - the public TRAIL/GAIA dataset and an internal dataset for\na production-grade data agent - show that this framework (a) provides a\nsystematic way to cover a broad range of agent failures, including all agent\nerrors on the TRAIL/GAIA benchmark dataset; (b) supports LLM-judges that\nexhibit strong agreement with human annotation, covering 80% to over 95%\nerrors; and (c) localizes errors with 86% agreement to enable targeted\nimprovement of agent performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86Agent GPA\uff08\u76ee\u6807-\u8ba1\u5212-\u884c\u52a8\uff09\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u4e94\u4e2a\u8bc4\u4f30\u6307\u6807\uff1a\u76ee\u6807\u8fbe\u6210\u5ea6\u3001\u903b\u8f91\u4e00\u81f4\u6027\u3001\u6267\u884c\u6548\u7387\u3001\u8ba1\u5212\u8d28\u91cf\u548c\u8ba1\u5212\u9075\u5faa\u5ea6\uff0c\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u8986\u76d6\u5e7f\u6cdb\u7684\u667a\u80fd\u4f53\u5931\u8d25\u60c5\u51b5\u3002", "motivation": "\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u8303\u5f0f\u6765\u5168\u9762\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u76ee\u6807\u8bbe\u5b9a\u3001\u8ba1\u5212\u5236\u5b9a\u548c\u884c\u52a8\u6267\u884c\u6574\u4e2a\u64cd\u4f5c\u5faa\u73af\u4e2d\u7684\u8868\u73b0\uff0c\u8bc6\u522b\u5404\u79cd\u7c7b\u578b\u7684\u5931\u8d25\u60c5\u51b5\u3002", "method": "\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u76ee\u6807-\u8ba1\u5212-\u884c\u52a8\u64cd\u4f5c\u5faa\u73af\uff0c\u8bbe\u8ba1\u4e86\u4e94\u4e2a\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u5728TRAIL/GAIA\u57fa\u51c6\u6570\u636e\u96c6\u548c\u751f\u4ea7\u7ea7\u6570\u636e\u667a\u80fd\u4f53\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u6846\u67b6\u80fd\u591f\u8986\u76d6TRAIL/GAIA\u57fa\u51c6\u6570\u636e\u96c6\u4e2d\u7684\u6240\u6709\u667a\u80fd\u4f53\u9519\u8bef\uff0c\u652f\u6301LLM\u8bc4\u4f30\u5668\u4e0e\u4eba\u5de5\u6807\u6ce8\u8fbe\u523080%-95%\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u80fd\u4ee586%\u7684\u51c6\u786e\u7387\u5b9a\u4f4d\u9519\u8bef\u3002", "conclusion": "Agent GPA\u6846\u67b6\u4e3a\u667a\u80fd\u4f53\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u5168\u9762\u8986\u76d6\u667a\u80fd\u4f53\u5931\u8d25\u60c5\u51b5\uff0c\u652f\u6301\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u548c\u6027\u80fd\u6539\u8fdb\u3002"}}
{"id": "2510.08851", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.08851", "abs": "https://arxiv.org/abs/2510.08851", "authors": ["Le Mao", "Andrew H. Liu", "Renos Zabounidis", "Zachary Kingston", "Joseph Campbell"], "title": "CDE: Concept-Driven Exploration for Reinforcement Learning", "comment": "Preprint", "summary": "Intelligent exploration remains a critical challenge in reinforcement\nlearning (RL), especially in visual control tasks. Unlike low-dimensional\nstate-based RL, visual RL must extract task-relevant structure from raw pixels,\nmaking exploration inefficient. We propose Concept-Driven Exploration (CDE),\nwhich leverages a pre-trained vision-language model (VLM) to generate\nobject-centric visual concepts from textual task descriptions as weak,\npotentially noisy supervisory signals. Rather than directly conditioning on\nthese noisy signals, CDE trains a policy to reconstruct the concepts via an\nauxiliary objective, using reconstruction accuracy as an intrinsic reward to\nguide exploration toward task-relevant objects. Because the policy internalizes\nthese concepts, VLM queries are only needed during training, reducing\ndependence on external models during deployment. Across five challenging\nsimulated visual manipulation tasks, CDE achieves efficient, targeted\nexploration and remains robust to noisy VLM predictions. Finally, we\ndemonstrate real-world transfer by deploying CDE on a Franka Research 3 arm,\nattaining an 80\\% success rate in a real-world manipulation task.", "AI": {"tldr": "CDE\u5229\u7528\u9884\u8bad\u7ec3\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4ece\u6587\u672c\u4efb\u52a1\u63cf\u8ff0\u751f\u6210\u7269\u4f53\u4e2d\u5fc3\u89c6\u89c9\u6982\u5ff5\uff0c\u901a\u8fc7\u91cd\u5efa\u8fd9\u4e9b\u6982\u5ff5\u4f5c\u4e3a\u5185\u5728\u5956\u52b1\u6765\u6307\u5bfc\u63a2\u7d22\uff0c\u5728\u89c6\u89c9\u63a7\u5236\u4efb\u52a1\u4e2d\u5b9e\u73b0\u9ad8\u6548\u63a2\u7d22\u3002", "motivation": "\u89e3\u51b3\u89c6\u89c9\u5f3a\u5316\u5b66\u4e60\u4e2d\u63a2\u7d22\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u9700\u8981\u4ece\u539f\u59cb\u50cf\u7d20\u4e2d\u63d0\u53d6\u4efb\u52a1\u76f8\u5173\u7ed3\u6784\uff0c\u6bd4\u4f4e\u7ef4\u72b6\u6001RL\u66f4\u56f0\u96be\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3VLM\u4ece\u6587\u672c\u4efb\u52a1\u63cf\u8ff0\u751f\u6210\u7269\u4f53\u4e2d\u5fc3\u89c6\u89c9\u6982\u5ff5\uff0c\u8bad\u7ec3\u7b56\u7565\u901a\u8fc7\u8f85\u52a9\u76ee\u6807\u91cd\u5efa\u8fd9\u4e9b\u6982\u5ff5\uff0c\u5c06\u91cd\u5efa\u51c6\u786e\u6027\u4f5c\u4e3a\u5185\u5728\u5956\u52b1\u6765\u6307\u5bfc\u63a2\u7d22\u3002", "result": "\u5728\u4e94\u4e2a\u6a21\u62df\u89c6\u89c9\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5b9e\u73b0\u9ad8\u6548\u3001\u6709\u9488\u5bf9\u6027\u7684\u63a2\u7d22\uff0c\u5bf9\u566a\u58f0VLM\u9884\u6d4b\u5177\u6709\u9c81\u68d2\u6027\uff1b\u5728\u771f\u5b9e\u4e16\u754cFranka\u673a\u68b0\u81c2\u4e0a\u8fbe\u523080%\u6210\u529f\u7387\u3002", "conclusion": "CDE\u901a\u8fc7\u6982\u5ff5\u9a71\u52a8\u7684\u63a2\u7d22\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u89c6\u89c9RL\u4e2d\u7684\u63a2\u7d22\u6311\u6218\uff0c\u51cf\u5c11\u4e86\u5bf9\u90e8\u7f72\u65f6\u5916\u90e8\u6a21\u578b\u7684\u4f9d\u8d56\uff0c\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u90fd\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.09281", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09281", "abs": "https://arxiv.org/abs/2510.09281", "authors": ["Manuel R. Arahal", "Manuel G. Satu\u00e9", "Kumars Rouzbehi", "Juana M. Mart\u00ednez-Heredia"], "title": "Single vs Multi Vector Predictive Control of Five-phase Drives", "comment": null, "summary": "The field of Finite State Model Predictive Control for multiphase drives has\nproduced many contributions. Many variants of FSMPC exist, each aiming at some\naspect such as complexity of the cost function, switching frequency, etc.\nDespite past efforts to compare different techniques, the field is still out of\nconsensus regarding the relative merits of each one. This paper presents a new\nmethod to compare FSMPC variants. The method is based on analyzing the\nmodulation, implicit or explicit, used by each variant. In the paper the method\nis used to compare single-vector state-of-the-art FSMPC with a multi-vector\nvariant designed to cancel xy currents and simplify the cost function. The\nresults show the strengths and weaknesses of each technique. Also, it is found\nthat the trade-offs between figures, previously thought to concern just\nindividual regimes, extend to the whole operating space and also can be\npinpoint to each FSMPC variant. Finally, it is shown that the flexibility of\nthe single-vector approach and its better DC-link usage makes it, arguably,\nsuperior over the multi-vector variant.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8c03\u5236\u5206\u6790\u7684\u65b0\u65b9\u6cd5\u6765\u6bd4\u8f83\u6709\u9650\u72b6\u6001\u6a21\u578b\u9884\u6d4b\u63a7\u5236(FSMPC)\u53d8\u4f53\uff0c\u901a\u8fc7\u6bd4\u8f83\u5355\u5411\u91cf\u548c\u591a\u5411\u91cfFSMPC\u53d8\u4f53\uff0c\u53d1\u73b0\u5355\u5411\u91cf\u65b9\u6cd5\u5728\u7075\u6d3b\u6027\u548cDC-link\u5229\u7528\u7387\u65b9\u9762\u66f4\u4f18\u3002", "motivation": "FSMPC\u9886\u57df\u5b58\u5728\u591a\u79cd\u53d8\u4f53\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5b83\u4eec\u76f8\u5bf9\u4f18\u70b9\u7684\u5171\u8bc6\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u6bd4\u8f83\u65b9\u6cd5\u6765\u8bc4\u4f30\u4e0d\u540cFSMPC\u6280\u672f\u7684\u6027\u80fd\u3002", "method": "\u57fa\u4e8e\u5206\u6790\u6bcf\u79cdFSMPC\u53d8\u4f53\u4f7f\u7528\u7684\u8c03\u5236\u65b9\u6cd5\uff08\u9690\u5f0f\u6216\u663e\u5f0f\uff09\uff0c\u6bd4\u8f83\u5355\u5411\u91cf\u548c\u591a\u5411\u91cfFSMPC\u53d8\u4f53\uff0c\u7279\u522b\u5173\u6ce8\u591a\u5411\u91cf\u53d8\u4f53\u5982\u4f55\u6d88\u9664xy\u7535\u6d41\u548c\u7b80\u5316\u6210\u672c\u51fd\u6570\u3002", "result": "\u63ed\u793a\u4e86\u6bcf\u79cd\u6280\u672f\u7684\u4f18\u7f3a\u70b9\uff0c\u53d1\u73b0\u6027\u80fd\u6743\u8861\u4e0d\u4ec5\u9650\u4e8e\u5355\u4e2a\u5de5\u4f5c\u72b6\u6001\uff0c\u800c\u662f\u6269\u5c55\u5230\u6574\u4e2a\u5de5\u4f5c\u7a7a\u95f4\uff0c\u5e76\u4e14\u53ef\u4ee5\u9488\u5bf9\u6bcf\u4e2aFSMPC\u53d8\u4f53\u8fdb\u884c\u7cbe\u786e\u5b9a\u4f4d\u3002", "conclusion": "\u5355\u5411\u91cfFSMPC\u65b9\u6cd5\u5728\u7075\u6d3b\u6027\u548cDC-link\u5229\u7528\u7387\u65b9\u9762\u4f18\u4e8e\u591a\u5411\u91cf\u53d8\u4f53\u3002"}}
{"id": "2510.09249", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.09249", "abs": "https://arxiv.org/abs/2510.09249", "authors": ["Javara A. Bukhsh", "Maya Daneva", "Marten van Sinderen"], "title": "Exploring User Risk Factors and Target Groups for Phishing Victimization in Pakistan", "comment": null, "summary": "Phishing attacks pose a significant cybersecurity threat globally. This study\ninvestigates phishing susceptibility within the Pakistani population, examining\nthe influence of demographic factors, technological aptitude and usage,\nprevious phishing victimization, and email characteristics. Data was collected\nthrough convenient sampling; a total of 164 people completed the questionnaire.\nContrary to some assumptions, the results indicate that men, individuals over\n25, employed persons and frequent online shoppers have relatively high phishing\nsusceptibility. The characteristics of email significantly affected phishing\nvictimization, with authority and urgency signaling increasing susceptibility,\nwhile risk cues sometimes improved vigilance. In particular, users were more\nsusceptible to emails from communication services such as Gmail and LinkedIn\ncompared to government or social media sources. These findings highlight the\nneed for targeted security awareness interventions tailored to specific\ndemographics and email types. A multifaceted approach combining technology and\neducation is crucial to combat phishing attacks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8c03\u67e5\u4e86\u5df4\u57fa\u65af\u5766\u4eba\u7fa4\u7684\u7f51\u7edc\u9493\u9c7c\u6613\u611f\u6027\uff0c\u53d1\u73b0\u7537\u6027\u300125\u5c81\u4ee5\u4e0a\u4eba\u7fa4\u3001\u5728\u804c\u4eba\u5458\u548c\u9891\u7e41\u7f51\u8d2d\u8005\u66f4\u5bb9\u6613\u53d7\u9a97\uff0c\u90ae\u4ef6\u7279\u5f81\u5982\u6743\u5a01\u6027\u548c\u7d27\u6025\u6027\u4f1a\u589e\u52a0\u6613\u611f\u6027\uff0c\u800c\u6765\u81eaGmail\u548cLinkedIn\u7b49\u901a\u4fe1\u670d\u52a1\u7684\u90ae\u4ef6\u6700\u5371\u9669\u3002", "motivation": "\u7f51\u7edc\u9493\u9c7c\u653b\u51fb\u662f\u5168\u7403\u6027\u7684\u91cd\u5927\u7f51\u7edc\u5b89\u5168\u5a01\u80c1\uff0c\u9700\u8981\u4e86\u89e3\u7279\u5b9a\u4eba\u7fa4\u7684\u6613\u611f\u6027\u7279\u5f81\u4ee5\u5236\u5b9a\u9488\u5bf9\u6027\u9632\u62a4\u63aa\u65bd\u3002", "method": "\u901a\u8fc7\u4fbf\u5229\u62bd\u6837\u6536\u96c6\u6570\u636e\uff0c\u5171\u6709164\u4eba\u5b8c\u6210\u4e86\u95ee\u5377\u8c03\u67e5\uff0c\u5206\u6790\u4eba\u53e3\u7edf\u8ba1\u56e0\u7d20\u3001\u6280\u672f\u80fd\u529b\u3001\u4f7f\u7528\u4e60\u60ef\u3001\u8fc7\u5f80\u53d7\u5bb3\u7ecf\u5386\u548c\u90ae\u4ef6\u7279\u5f81\u5bf9\u7f51\u7edc\u9493\u9c7c\u6613\u611f\u6027\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7537\u6027\u300125\u5c81\u4ee5\u4e0a\u3001\u5728\u804c\u4eba\u5458\u3001\u9891\u7e41\u7f51\u8d2d\u8005\u6613\u611f\u6027\u8f83\u9ad8\uff1b\u6743\u5a01\u548c\u7d27\u6025\u7279\u5f81\u7684\u90ae\u4ef6\u589e\u52a0\u53d7\u5bb3\u98ce\u9669\uff1b\u6765\u81eaGmail\u548cLinkedIn\u7684\u90ae\u4ef6\u6bd4\u653f\u5e9c\u6216\u793e\u4ea4\u5a92\u4f53\u90ae\u4ef6\u66f4\u5371\u9669\u3002", "conclusion": "\u9700\u8981\u9488\u5bf9\u7279\u5b9a\u4eba\u7fa4\u548c\u90ae\u4ef6\u7c7b\u578b\u5236\u5b9a\u5b89\u5168\u610f\u8bc6\u5e72\u9884\u63aa\u65bd\uff0c\u7ed3\u5408\u6280\u672f\u548c\u6559\u80b2\u7684\u591a\u5c42\u9762\u65b9\u6cd5\u5bf9\u9632\u8303\u7f51\u7edc\u9493\u9c7c\u653b\u51fb\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.08867", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.08867", "abs": "https://arxiv.org/abs/2510.08867", "authors": ["Gaurav Sahu", "Hugo Larochelle", "Laurent Charlin", "Christopher Pal"], "title": "ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review", "comment": null, "summary": "Peer review is the cornerstone of scientific publishing, yet it suffers from\ninconsistencies, reviewer subjectivity, and scalability challenges. We\nintroduce ReviewerToo, a modular framework for studying and deploying\nAI-assisted peer review to complement human judgment with systematic and\nconsistent assessments. ReviewerToo supports systematic experiments with\nspecialized reviewer personas and structured evaluation criteria, and can be\npartially or fully integrated into real conference workflows. We validate\nReviewerToo on a carefully curated dataset of 1,963 paper submissions from ICLR\n2025, where our experiments with the gpt-oss-120b model achieves 81.8% accuracy\nfor the task of categorizing a paper as accept/reject compared to 83.9% for the\naverage human reviewer. Additionally, ReviewerToo-generated reviews are rated\nas higher quality than the human average by an LLM judge, though still trailing\nthe strongest expert contributions. Our analysis highlights domains where AI\nreviewers excel (e.g., fact-checking, literature coverage) and where they\nstruggle (e.g., assessing methodological novelty and theoretical\ncontributions), underscoring the continued need for human expertise. Based on\nthese findings, we propose guidelines for integrating AI into peer-review\npipelines, showing how AI can enhance consistency, coverage, and fairness while\nleaving complex evaluative judgments to domain experts. Our work provides a\nfoundation for systematic, hybrid peer-review systems that scale with the\ngrowth of scientific publishing.", "AI": {"tldr": "ReviewerToo\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u7814\u7a76\u548c\u90e8\u7f72AI\u8f85\u52a9\u540c\u884c\u8bc4\u5ba1\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u8bc4\u4f30\u8865\u5145\u4eba\u7c7b\u5224\u65ad\uff0c\u5728ICLR 2025\u6570\u636e\u96c6\u4e0a\u8fbe\u523081.8%\u7684\u63a5\u53d7/\u62d2\u7edd\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u540c\u884c\u8bc4\u5ba1\u5b58\u5728\u7684\u4e0d\u4e00\u81f4\u6027\u3001\u8bc4\u5ba1\u8005\u4e3b\u89c2\u6027\u548c\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u901a\u8fc7AI\u8f85\u52a9\u63d0\u9ad8\u8bc4\u5ba1\u7684\u7cfb\u7edf\u6027\u548c\u4e00\u81f4\u6027\u3002", "method": "\u5f00\u53d1\u6a21\u5757\u5316\u6846\u67b6ReviewerToo\uff0c\u652f\u6301\u4e13\u95e8\u7684\u8bc4\u5ba1\u8005\u89d2\u8272\u548c\u7ed3\u6784\u5316\u8bc4\u4f30\u6807\u51c6\uff0c\u5728ICLR 2025\u76841,963\u7bc7\u8bba\u6587\u6570\u636e\u96c6\u4e0a\u4f7f\u7528gpt-oss-120b\u6a21\u578b\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "AI\u8bc4\u5ba1\u8005\u5728\u63a5\u53d7/\u62d2\u7edd\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fbe\u523081.8%\u51c6\u786e\u7387\uff08\u4eba\u7c7b\u5e73\u574783.9%\uff09\uff0cAI\u751f\u6210\u7684\u8bc4\u5ba1\u8d28\u91cf\u9ad8\u4e8e\u4eba\u7c7b\u5e73\u5747\u6c34\u5e73\uff0c\u4f46\u5728\u65b9\u6cd5\u65b0\u9896\u6027\u548c\u7406\u8bba\u8d21\u732e\u8bc4\u4f30\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\u3002", "conclusion": "AI\u53ef\u4ee5\u589e\u5f3a\u540c\u884c\u8bc4\u5ba1\u7684\u4e00\u81f4\u6027\u3001\u8986\u76d6\u8303\u56f4\u548c\u516c\u5e73\u6027\uff0c\u4f46\u590d\u6742\u8bc4\u4f30\u4ecd\u9700\u9886\u57df\u4e13\u5bb6\uff0c\u4e3a\u6784\u5efa\u7cfb\u7edf\u5316\u6df7\u5408\u8bc4\u5ba1\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.08880", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.08880", "abs": "https://arxiv.org/abs/2510.08880", "authors": ["Baoshan Song", "Xiao Xia", "Penggao Yan", "Yihan Zhong", "Weisong Wen", "Li-Ta Hsu"], "title": "Online IMU-odometer Calibration using GNSS Measurements for Autonomous Ground Vehicle Localization", "comment": "Submitted to IEEE Transactions on Intelligent Transportation Systems", "summary": "Accurate calibration of intrinsic (odometer scaling factors) and extrinsic\nparameters (IMU-odometer translation and rotation) is essential for autonomous\nground vehicle localization. Existing GNSS-aided approaches often rely on\npositioning results or raw measurements without ambiguity resolution, and their\nobservability properties remain underexplored. This paper proposes a tightly\ncoupled online calibration method that fuses IMU, odometer, and raw GNSS\nmeasurements (pseudo-range, carrier-phase, and Doppler) within an extendable\nfactor graph optimization (FGO) framework, incorporating outlier mitigation and\nambiguity resolution. Observability analysis reveals that two horizontal\ntranslation and three rotation parameters are observable under general motion,\nwhile vertical translation remains unobservable. Simulation and real-world\nexperiments demonstrate superior calibration and localization performance over\nstate-of-the-art loosely coupled methods. Specifically, the IMU-odometer\npositioning using our calibrated parameters achieves the absolute maximum error\nof 17.75 m while the one of LC method is 61.51 m, achieving up to 71.14 percent\nimprovement. To foster further research, we also release the first open-source\ndataset that combines IMU, 2D odometer, and raw GNSS measurements from both\nrover and base stations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7d27\u8026\u5408\u5728\u7ebf\u6821\u51c6\u65b9\u6cd5\uff0c\u878d\u5408IMU\u3001\u91cc\u7a0b\u8ba1\u548c\u539f\u59cbGNSS\u6d4b\u91cf\uff0c\u7528\u4e8e\u81ea\u4e3b\u5730\u9762\u8f66\u8f86\u7684\u5b9a\u4f4d\u6821\u51c6\u3002", "motivation": "\u73b0\u6709GNSS\u8f85\u52a9\u65b9\u6cd5\u4f9d\u8d56\u5b9a\u4f4d\u7ed3\u679c\u6216\u672a\u89e3\u6790\u6a21\u7cca\u5ea6\u7684\u539f\u59cb\u6d4b\u91cf\uff0c\u4e14\u53ef\u89c2\u6d4b\u6027\u7279\u6027\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u5728\u53ef\u6269\u5c55\u56e0\u5b50\u56fe\u4f18\u5316\u6846\u67b6\u4e2d\u878d\u5408IMU\u3001\u91cc\u7a0b\u8ba1\u548c\u539f\u59cbGNSS\u6d4b\u91cf\uff08\u4f2a\u8ddd\u3001\u8f7d\u6ce2\u76f8\u4f4d\u548c\u591a\u666e\u52d2\uff09\uff0c\u5305\u542b\u5f02\u5e38\u503c\u6291\u5236\u548c\u6a21\u7cca\u5ea6\u89e3\u6790\u3002", "result": "\u4eff\u771f\u548c\u771f\u5b9e\u5b9e\u9a8c\u663e\u793a\uff0c\u5728\u6821\u51c6\u548c\u5b9a\u4f4d\u6027\u80fd\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u677e\u8026\u5408\u65b9\u6cd5\uff0cIMU-\u91cc\u7a0b\u8ba1\u5b9a\u4f4d\u7edd\u5bf9\u6700\u5927\u8bef\u5dee\u4ece61.51\u7c73\u964d\u81f317.75\u7c73\uff0c\u63d0\u534771.14%\u3002", "conclusion": "\u6c34\u5e73\u5e73\u79fb\u548c\u4e09\u4e2a\u65cb\u8f6c\u53c2\u6570\u5728\u4e00\u822c\u8fd0\u52a8\u4e0b\u53ef\u89c2\u6d4b\uff0c\u5782\u76f4\u5e73\u79fb\u4e0d\u53ef\u89c2\u6d4b\uff1b\u53d1\u5e03\u4e86\u9996\u4e2a\u7ed3\u5408IMU\u30012D\u91cc\u7a0b\u8ba1\u548c\u539f\u59cbGNSS\u6d4b\u91cf\u7684\u5f00\u6e90\u6570\u636e\u96c6\u3002"}}
{"id": "2510.09283", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09283", "abs": "https://arxiv.org/abs/2510.09283", "authors": ["Mariat James Elizebeth", "Shufeng Chen", "Halima El Badaoui", "Siddartha Khastgir", "Paul Jennings"], "title": "Safety Analysis of eVTOL Operations based on STPA", "comment": null, "summary": "Electric Vertical Take-Off and Landing (eVTOL) aircraft are expected to be\nquieter and more cost-effective than helicopters, offering major economic and\nsocial benefits through improved connectivity. Their adoption will require new\nground infrastructure and airspace redesign, introducing risks involving\nmultiple stakeholders (Regulators, eVTOL operators, Air navigation service\nproviders, Vertiport operators, OEMs, Pilots, etc.). To assess these risks for\nthe UK airspace, systems-thinking based System Theoretic Process Analysis\n(STPA) was conducted. To manage the large number of Unsafe Control Actions\n(UCAs) and requirements generated due to the complexity of the analysis, a\nnovel extension to STPA for the prioritization of results was applied. 317 UCAs\nwere identified in total out of which 110 high-priority UCAs were analyzed\n(Step-4), resulting in 377 causal factors and 432 requirements. These were\nprioritized to produce a targeted list of 124 distinct high-priority\nrequirements, 56 of which were identified as gaps in existing aviation\nregulations, policies, or procedures.. These highlight opportunities for\nregulatory updates in areas such as organizational performance, certification\nprocesses, training, collision avoidance, energy management, and automation.\nThe findings provide regulators with safety considerations that could shape new\nor updated regulations, compliance methods, and guidance materials for the safe\ndeployment of eVTOLs.", "AI": {"tldr": "\u4f7f\u7528\u7cfb\u7edf\u7406\u8bba\u8fc7\u7a0b\u5206\u6790(STPA)\u8bc4\u4f30\u82f1\u56fd\u7a7a\u57dfeVTOL\u98de\u673a\u90e8\u7f72\u7684\u98ce\u9669\uff0c\u8bc6\u522b\u51fa317\u4e2a\u4e0d\u5b89\u5168\u63a7\u5236\u884c\u4e3a\uff0c\u5176\u4e2d110\u4e2a\u9ad8\u4f18\u5148\u7ea7\u884c\u4e3a\u4ea7\u751f377\u4e2a\u56e0\u679c\u56e0\u7d20\u548c432\u4e2a\u9700\u6c42\uff0c\u6700\u7ec8\u786e\u5b9a124\u4e2a\u9ad8\u4f18\u5148\u7ea7\u9700\u6c42\uff0c\u5176\u4e2d56\u4e2a\u662f\u73b0\u6709\u822a\u7a7a\u6cd5\u89c4\u7684\u7a7a\u767d\u3002", "motivation": "eVTOL\u98de\u673a\u6bd4\u76f4\u5347\u673a\u66f4\u5b89\u9759\u3001\u6210\u672c\u66f4\u4f4e\uff0c\u80fd\u901a\u8fc7\u6539\u5584\u8fde\u901a\u6027\u5e26\u6765\u91cd\u5927\u7ecf\u6d4e\u548c\u793e\u4f1a\u6548\u76ca\uff0c\u4f46\u5176\u91c7\u7528\u9700\u8981\u65b0\u7684\u5730\u9762\u57fa\u7840\u8bbe\u65bd\u548c\u7a7a\u57df\u91cd\u65b0\u8bbe\u8ba1\uff0c\u6d89\u53ca\u591a\u4e2a\u5229\u76ca\u76f8\u5173\u65b9\u7684\u98ce\u9669\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u7cfb\u7edf\u601d\u7ef4\u7684\u7cfb\u7edf\u7406\u8bba\u8fc7\u7a0b\u5206\u6790(STPA)\uff0c\u5e76\u5e94\u7528\u65b0\u9896\u7684STPA\u6269\u5c55\u65b9\u6cd5\u5bf9\u7ed3\u679c\u8fdb\u884c\u4f18\u5148\u7ea7\u6392\u5e8f\u3002", "result": "\u5171\u8bc6\u522b317\u4e2a\u4e0d\u5b89\u5168\u63a7\u5236\u884c\u4e3a\uff0c\u5206\u6790110\u4e2a\u9ad8\u4f18\u5148\u7ea7\u884c\u4e3a\uff0c\u4ea7\u751f377\u4e2a\u56e0\u679c\u56e0\u7d20\u548c432\u4e2a\u9700\u6c42\uff0c\u6700\u7ec8\u786e\u5b9a124\u4e2a\u9ad8\u4f18\u5148\u7ea7\u9700\u6c42\uff0c\u5176\u4e2d56\u4e2a\u662f\u73b0\u6709\u6cd5\u89c4\u7a7a\u767d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u76d1\u7ba1\u673a\u6784\u63d0\u4f9b\u4e86\u5b89\u5168\u8003\u91cf\uff0c\u53ef\u6307\u5bfc\u5236\u5b9a\u6216\u66f4\u65b0eVTOL\u5b89\u5168\u90e8\u7f72\u7684\u6cd5\u89c4\u3001\u5408\u89c4\u65b9\u6cd5\u548c\u6307\u5bfc\u6750\u6599\uff0c\u7279\u522b\u662f\u5728\u7ec4\u7ec7\u7ee9\u6548\u3001\u8ba4\u8bc1\u6d41\u7a0b\u3001\u57f9\u8bad\u3001\u9632\u649e\u3001\u80fd\u6e90\u7ba1\u7406\u548c\u81ea\u52a8\u5316\u7b49\u9886\u57df\u3002"}}
{"id": "2510.09374", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.09374", "abs": "https://arxiv.org/abs/2510.09374", "authors": ["Razi Iqbal"], "title": "Challenges in designing ethical rules for Infrastructures in Internet of Vehicles", "comment": null, "summary": "Vehicular Ad-hoc Networks (VANETs) have seen significant advancements in\ntechnology. Innovation in connectivity and communication has brought\nsubstantial capabilities to various components of VANETs such as vehicles,\ninfrastructures, passengers, drivers and affiliated environmental sensors.\nInternet of Things (IoT) has brought the notion of Internet of Vehicles (IoV)\nto VANETs where each component of VANET is connected directly or indirectly to\nthe Internet. Vehicles and infrastructures are key components of a VANET system\nthat can greatly augment the overall experience of the network by integrating\nthe competencies of Vehicle to Vehicle (V2V), Vehicle to Pedestrian (V2P),\nVehicle to Sensor (V2S), Vehicle to Infrastructure (V2I) and Infrastructure to\nInfrastructure (I2I). Internet connectivity in Vehicles and Infrastructures has\nimmensely expanded the potential of developing applications for VANETs under\nthe broad spectrum of IoV. Advent in the use of technology in VANETs requires\nconsiderable efforts in scheming the ethical rules for autonomous systems.\nCurrently, there is a gap in literature that focuses on the challenges involved\nin designing ethical rules or policies for infrastructures, sometimes referred\nto as Road Side Units (RSUs) for IoVs. This paper highlights the key challenges\nentailing the design of ethical rules for RSUs in IoV systems. Furthermore, the\narticle also proposes major ethical principles for RSUs in IoV systems that\nwould set foundation for modeling future IoV architectures.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u8f66\u8054\u7f51\u7cfb\u7edf\u4e2d\u8def\u8fb9\u5355\u5143(RSU)\u4f26\u7406\u89c4\u5219\u8bbe\u8ba1\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86RSU\u7684\u4e3b\u8981\u4f26\u7406\u539f\u5219\uff0c\u4e3a\u672a\u6765\u8f66\u8054\u7f51\u67b6\u6784\u5efa\u6a21\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u968f\u7740\u8f66\u8054\u7f51\u6280\u672f\u7684\u53d1\u5c55\uff0c\u8f66\u8f86\u548c\u57fa\u7840\u8bbe\u65bd\u7684\u4e92\u8054\u7f51\u8fde\u63a5\u6781\u5927\u5730\u6269\u5c55\u4e86\u8f66\u8054\u7f51\u5e94\u7528\u7684\u6f5c\u529b\u3002\u7136\u800c\uff0c\u76ee\u524d\u6587\u732e\u4e2d\u7f3a\u4e4f\u5bf9\u8f66\u8054\u7f51\u7cfb\u7edf\u4e2d\u57fa\u7840\u8bbe\u65bd\uff08\u8def\u8fb9\u5355\u5143\uff09\u4f26\u7406\u89c4\u5219\u8bbe\u8ba1\u6311\u6218\u7684\u5173\u6ce8\u3002", "method": "\u901a\u8fc7\u5206\u6790\u8f66\u8054\u7f51\u7cfb\u7edf\u4e2dV2V\u3001V2P\u3001V2S\u3001V2I\u548cI2I\u7b49\u901a\u4fe1\u6a21\u5f0f\u7684\u96c6\u6210\u80fd\u529b\uff0c\u8bc6\u522bRSU\u4f26\u7406\u89c4\u5219\u8bbe\u8ba1\u7684\u5173\u952e\u6311\u6218\u3002", "result": "\u8bc6\u522b\u4e86\u8f66\u8054\u7f51\u7cfb\u7edf\u4e2dRSU\u4f26\u7406\u89c4\u5219\u8bbe\u8ba1\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u4f26\u7406\u539f\u5219\u3002", "conclusion": "\u4e3a\u8f66\u8054\u7f51\u7cfb\u7edf\u4e2d\u7684\u8def\u8fb9\u5355\u5143\u5efa\u7acb\u4e86\u4f26\u7406\u539f\u5219\u6846\u67b6\uff0c\u4e3a\u672a\u6765\u8f66\u8054\u7f51\u67b6\u6784\u7684\u5efa\u6a21\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.08872", "categories": ["cs.AI", "cs.GT", "cs.HC", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.08872", "abs": "https://arxiv.org/abs/2510.08872", "authors": ["Siqi Zhu", "David Zhang", "Pedro Cisneros-Velarde", "Jiaxuan You"], "title": "GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare", "comment": "31 pages, 6 figures", "summary": "Large Language Models (LLMs) have achieved remarkable progress in reasoning,\nyet sometimes produce responses that are suboptimal for users in tasks such as\nwriting, information seeking, or providing practical guidance. Conventional\nalignment practices typically assume that maximizing model reward also\nmaximizes user welfare, but this assumption frequently fails in practice:\nmodels may over-clarify or generate overly verbose reasoning when users prefer\nconcise answers. Such behaviors resemble the prisoner's dilemma, where\nindividually rational choices lead to socially suboptimal outcomes. The\nfundamental challenge is the lack of a principled decision making mechanism\nthat mutually benefits both the LLM and the user. We propose Game-Theoretic\nAlignment (GTAlign), an alignment framework that integrates game-theoretic\ndecision making into both reasoning and training. During reasoning, the model\nexplicitly treats user-LLM interaction as a strategic game: it constructs\npayoff matrices within its reasoning chain to estimate welfare for both itself\nand the user, and then selects actions that are mutually beneficial. During\ntraining, we introduce a mutual welfare reward that reinforces cooperative\nresponses, aligning model behavior with socially efficient outcomes. In\naddition, we introduce an inference technique that leverages game-theoretic\nreasoning to dynamically adapt LLM's response when pricing policies of LLM\nservice change. Extensive experiments demonstrate that GTAlign substantially\nimproves reasoning efficiency, answer quality, and mutual welfare compared to\nbaselines across diverse tasks. The code is available at\nhttps://github.com/ulab-uiuc/GTAlign .", "AI": {"tldr": "\u63d0\u51fa\u4e86GTAlign\u6846\u67b6\uff0c\u5c06\u535a\u5f08\u8bba\u51b3\u7b56\u6574\u5408\u5230LLM\u7684\u63a8\u7406\u548c\u8bad\u7ec3\u4e2d\uff0c\u901a\u8fc7\u6784\u5efa\u6536\u76ca\u77e9\u9635\u6765\u4f18\u5316\u7528\u6237\u4e0e\u6a21\u578b\u4e4b\u95f4\u7684\u4e92\u52a8\uff0c\u5b9e\u73b0\u4e92\u5229\u5171\u8d62\u3002", "motivation": "\u4f20\u7edf\u5bf9\u9f50\u65b9\u6cd5\u5047\u8bbe\u6700\u5927\u5316\u6a21\u578b\u5956\u52b1\u5c31\u7b49\u4e8e\u6700\u5927\u5316\u7528\u6237\u798f\u5229\uff0c\u4f46\u5b9e\u9645\u4e0aLLM\u7ecf\u5e38\u4ea7\u751f\u8fc7\u4e8e\u5197\u957f\u6216\u8fc7\u5ea6\u6f84\u6e05\u7684\u56de\u7b54\uff0c\u800c\u7528\u6237\u66f4\u559c\u6b22\u7b80\u6d01\u7b54\u6848\uff0c\u8fd9\u79cd\u4e2a\u4f53\u7406\u6027\u9009\u62e9\u5bfc\u81f4\u793e\u4f1a\u6b21\u4f18\u7ed3\u679c\u3002", "method": "\u5728\u63a8\u7406\u9636\u6bb5\u5c06\u7528\u6237-LLM\u4e92\u52a8\u89c6\u4e3a\u7b56\u7565\u535a\u5f08\uff0c\u6784\u5efa\u6536\u76ca\u77e9\u9635\u8bc4\u4f30\u53cc\u65b9\u798f\u5229\uff1b\u5728\u8bad\u7ec3\u9636\u6bb5\u5f15\u5165\u4e92\u5229\u5956\u52b1\u6765\u5f3a\u5316\u5408\u4f5c\u6027\u54cd\u5e94\uff1b\u8fd8\u63d0\u51fa\u4e86\u57fa\u4e8e\u535a\u5f08\u8bba\u63a8\u7406\u7684\u52a8\u6001\u9002\u5e94\u6280\u672f\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cGTAlign\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u3001\u56de\u7b54\u8d28\u91cf\u548c\u4e92\u5229\u798f\u5229\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "GTAlign\u901a\u8fc7\u535a\u5f08\u8bba\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LLM\u5bf9\u9f50\u4e2d\u7684\u793e\u4f1a\u6548\u7387\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7528\u6237\u4e0e\u6a21\u578b\u4e4b\u95f4\u7684\u4e92\u5229\u5171\u8d62\u3002"}}
{"id": "2510.08884", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.08884", "abs": "https://arxiv.org/abs/2510.08884", "authors": ["Alexandre Lopes", "Catarina Barata", "Plinio Moreno"], "title": "Model-Based Lookahead Reinforcement Learning for in-hand manipulation", "comment": null, "summary": "In-Hand Manipulation, as many other dexterous tasks, remains a difficult\nchallenge in robotics by combining complex dynamic systems with the capability\nto control and manoeuvre various objects using its actuators. This work\npresents the application of a previously developed hybrid Reinforcement\nLearning (RL) Framework to In-Hand Manipulation task, verifying that it is\ncapable of improving the performance of the task. The model combines concepts\nof both Model-Free and Model-Based Reinforcement Learning, by guiding a trained\npolicy with the help of a dynamic model and value-function through trajectory\nevaluation, as done in Model Predictive Control. This work evaluates the\nperformance of the model by comparing it with the policy that will be guided.\nTo fully explore this, various tests are performed using both fully-actuated\nand under-actuated simulated robotic hands to manipulate different objects for\na given task. The performance of the model will also be tested for\ngeneralization tests, by changing the properties of the objects in which both\nthe policy and dynamic model were trained, such as density and size, and\nadditionally by guiding a trained policy in a certain object to perform the\nsame task in a different one. The results of this work show that, given a\npolicy with high average reward and an accurate dynamic model, the hybrid\nframework improves the performance of in-hand manipulation tasks for most test\ncases, even when the object properties are changed. However, this improvement\ncomes at the expense of increasing the computational cost, due to the\ncomplexity of trajectory evaluation.", "AI": {"tldr": "\u5c06\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u5e94\u7528\u4e8e\u624b\u5185\u64cd\u4f5c\u4efb\u52a1\uff0c\u7ed3\u5408\u6a21\u578b\u65e0\u5173\u548c\u6a21\u578b\u76f8\u5173\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f68\u8ff9\u8bc4\u4f30\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u589e\u52a0\u4e86\u8ba1\u7b97\u6210\u672c", "motivation": "\u624b\u5185\u64cd\u4f5c\u662f\u673a\u5668\u4eba\u5b66\u4e2d\u7684\u6311\u6218\u6027\u4efb\u52a1\uff0c\u9700\u8981\u63a7\u5236\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u6765\u64cd\u7eb5\u5404\u79cd\u7269\u4f53\u3002\u672c\u6587\u65e8\u5728\u9a8c\u8bc1\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u5426\u63d0\u5347\u624b\u5185\u64cd\u4f5c\u4efb\u52a1\u7684\u6027\u80fd", "method": "\u4f7f\u7528\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u6a21\u578b\u65e0\u5173\u548c\u6a21\u578b\u76f8\u5173\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u6a21\u578b\u548c\u4ef7\u503c\u51fd\u6570\u8fdb\u884c\u8f68\u8ff9\u8bc4\u4f30\uff08\u7c7b\u4f3c\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff09\u3002\u4f7f\u7528\u5b8c\u5168\u9a71\u52a8\u548c\u6b20\u9a71\u52a8\u4eff\u771f\u673a\u68b0\u624b\u6d4b\u8bd5\u4e0d\u540c\u7269\u4f53\u7684\u64cd\u4f5c", "result": "\u5728\u5927\u591a\u6570\u6d4b\u8bd5\u6848\u4f8b\u4e2d\uff0c\u6df7\u5408\u6846\u67b6\u63d0\u5347\u4e86\u624b\u5185\u64cd\u4f5c\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5373\u4f7f\u7269\u4f53\u5c5e\u6027\u53d1\u751f\u53d8\u5316\u3002\u4f46\u6027\u80fd\u63d0\u5347\u4ee5\u8ba1\u7b97\u6210\u672c\u589e\u52a0\u4e3a\u4ee3\u4ef7", "conclusion": "\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u624b\u5185\u64cd\u4f5c\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u9700\u8981\u6743\u8861\u6027\u80fd\u63d0\u5347\u4e0e\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u7684\u5173\u7cfb"}}
{"id": "2510.09290", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09290", "abs": "https://arxiv.org/abs/2510.09290", "authors": ["Manuel R. Arahal", "Manuel G. Satu\u00e9", "Kumars Rouzbehi", "Francisco Colodro"], "title": "Weighting Factors Tuning by Direct Feedback in Predictive Control of Multiphase Motors", "comment": null, "summary": "Predictive Stator Current Control (PSCC) has been proposed for control of\nmulti-phase drives. The flexibility offered by the use of a Cost Function has\nbeen used to deal with the increased number of phases. However, tuning of the\nWeighting Factors constitutes a problem. Intensive trial and error tests are\nusual in this context. Existing on-line selection methods, on the other hand,\nrequire large amounts of data and/or complex optimization procedures. The\nproposal of this paper is a closed-loop scheme that links Weighting Factors to\nperformance indicators. In this way, optimal Weighting Factors are determined\nfor each operating point. Also, changes in reference values for performance\nindicators are easily tackled. Unlike previous methods, the proposal carries\nvery little computational burden. A case study is developed for a five-phase\ninduction motor and assessed with real experimentation on a laboratory set-up.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u6743\u91cd\u56e0\u5b50\u4e0e\u6027\u80fd\u6307\u6807\u5173\u8054\u7684\u95ed\u73af\u65b9\u6848\uff0c\u7528\u4e8e\u591a\u76f8\u9a71\u52a8\u5668\u7684\u9884\u6d4b\u5b9a\u5b50\u7535\u6d41\u63a7\u5236\uff0c\u89e3\u51b3\u4e86\u6743\u91cd\u56e0\u5b50\u8c03\u4f18\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfPSCC\u4e2d\u6743\u91cd\u56e0\u5b50\u8c03\u4f18\u9700\u8981\u5927\u91cf\u8bd5\u9519\u6d4b\u8bd5\uff0c\u73b0\u6709\u5728\u7ebf\u9009\u62e9\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6570\u636e\u548c\u590d\u6742\u4f18\u5316\u8fc7\u7a0b\uff0c\u8ba1\u7b97\u8d1f\u62c5\u91cd\u3002", "method": "\u5f00\u53d1\u95ed\u73af\u65b9\u6848\u5c06\u6743\u91cd\u56e0\u5b50\u4e0e\u6027\u80fd\u6307\u6807\u76f4\u63a5\u5173\u8054\uff0c\u4e3a\u6bcf\u4e2a\u5de5\u4f5c\u70b9\u786e\u5b9a\u6700\u4f18\u6743\u91cd\u56e0\u5b50\uff0c\u8ba1\u7b97\u8d1f\u62c5\u6781\u5c0f\u3002", "result": "\u5728\u4e94\u76f8\u611f\u5e94\u7535\u673a\u4e0a\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5ba4\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u8f7b\u677e\u5e94\u5bf9\u6027\u80fd\u6307\u6807\u53c2\u8003\u503c\u7684\u53d8\u5316\uff0c\u76f8\u6bd4\u4e4b\u524d\u65b9\u6cd5\u8ba1\u7b97\u8d1f\u62c5\u6781\u5c0f\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.09439", "categories": ["cs.CY", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.09439", "abs": "https://arxiv.org/abs/2510.09439", "authors": ["Fanfan Lin", "Peter Wilson", "Xinze Li", "Alan Mantooth"], "title": "Demystifying and Navigating AI Ethics in Power Electronics", "comment": null, "summary": "Artificial intelligence (AI) is rapidly transforming power electronics, with\nAI-related publications in IEEE Power Electronics Society selected journals\nincreasing more than fourfold from 2020 to 2025. However, the ethical\ndimensions of this transformation have received limited attention. This article\nunderscores the urgent need for an ethical framework to guide responsible AI\nintegration in power electronics, not only to prevent AI-related incidents but\nalso to comply with legal and regulatory responsibilities. In this context,\nthis article identifies four core pillars of AI ethics in power electronics:\nSecurity & Safety, Explainability & Transparency, Energy Sustainability, and\nEvolving Roles of Engineers. Each pillar is supported by practical and\nactionable insights to ensure that ethical principles are embedded in algorithm\ndesign, system deployment, and workforce development. The authors advocate for\npower electronics engineers to lead the ethical discourse, given their deep\ntechnical understanding of both AI systems and power conversion technologies.\nThe paper concludes by calling on the IEEE Power Electronics Society to\nspearhead the establishment of ethical standards and best practices that ensure\nAI innovations are not only technically advanced but also trustworthy, safe,\nand sustainable.", "AI": {"tldr": "\u672c\u6587\u5f3a\u8c03\u5728\u7535\u529b\u7535\u5b50\u9886\u57df\u5efa\u7acbAI\u4f26\u7406\u6846\u67b6\u7684\u7d27\u8feb\u6027\uff0c\u63d0\u51fa\u4e86\u5b89\u5168\u4e0e\u4fdd\u969c\u3001\u53ef\u89e3\u91ca\u6027\u4e0e\u900f\u660e\u5ea6\u3001\u80fd\u6e90\u53ef\u6301\u7eed\u6027\u3001\u5de5\u7a0b\u5e08\u89d2\u8272\u6f14\u53d8\u56db\u5927\u652f\u67f1\uff0c\u5e76\u547c\u5401IEEE\u7535\u529b\u7535\u5b50\u5b66\u4f1a\u7275\u5934\u5236\u5b9a\u4f26\u7406\u6807\u51c6\u3002", "motivation": "AI\u5728\u7535\u529b\u7535\u5b50\u9886\u57df\u7684\u5e94\u7528\u5feb\u901f\u589e\u957f\uff0c\u4f46\u4f26\u7406\u7ef4\u5ea6\u5173\u6ce8\u6709\u9650\u3002\u9700\u8981\u5efa\u7acb\u4f26\u7406\u6846\u67b6\u6765\u9884\u9632AI\u76f8\u5173\u4e8b\u6545\uff0c\u5e76\u5c65\u884c\u6cd5\u5f8b\u548c\u76d1\u7ba1\u8d23\u4efb\u3002", "method": "\u8bc6\u522b\u5e76\u9610\u8ff0AI\u4f26\u7406\u5728\u7535\u529b\u7535\u5b50\u9886\u57df\u7684\u56db\u5927\u6838\u5fc3\u652f\u67f1\uff1a\u5b89\u5168\u4e0e\u4fdd\u969c\u3001\u53ef\u89e3\u91ca\u6027\u4e0e\u900f\u660e\u5ea6\u3001\u80fd\u6e90\u53ef\u6301\u7eed\u6027\u3001\u5de5\u7a0b\u5e08\u89d2\u8272\u6f14\u53d8\uff0c\u4e3a\u6bcf\u4e2a\u652f\u67f1\u63d0\u4f9b\u5b9e\u7528\u53ef\u884c\u7684\u89c1\u89e3\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684AI\u4f26\u7406\u6846\u67b6\uff0c\u786e\u4fdd\u4f26\u7406\u539f\u5219\u5d4c\u5165\u7b97\u6cd5\u8bbe\u8ba1\u3001\u7cfb\u7edf\u90e8\u7f72\u548c\u4eba\u624d\u53d1\u5c55\u8fc7\u7a0b\u4e2d\uff0c\u5f3a\u8c03\u7535\u529b\u7535\u5b50\u5de5\u7a0b\u5e08\u5e94\u5728\u4f26\u7406\u8ba8\u8bba\u4e2d\u53d1\u6325\u9886\u5bfc\u4f5c\u7528\u3002", "conclusion": "\u547c\u5401IEEE\u7535\u529b\u7535\u5b50\u5b66\u4f1a\u7275\u5934\u5efa\u7acb\u4f26\u7406\u6807\u51c6\u548c\u6700\u4f73\u5b9e\u8df5\uff0c\u786e\u4fddAI\u521b\u65b0\u4e0d\u4ec5\u6280\u672f\u5148\u8fdb\uff0c\u800c\u4e14\u53ef\u4fe1\u3001\u5b89\u5168\u548c\u53ef\u6301\u7eed\u3002"}}
{"id": "2510.08928", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08928", "abs": "https://arxiv.org/abs/2510.08928", "authors": ["Yushuo Zheng", "Zicheng Zhang", "Xiongkuo Min", "Huiyu Duan", "Guangtao Zhai"], "title": "LM Fight Arena: Benchmarking Large Multimodal Models via Game Competition", "comment": null, "summary": "Existing benchmarks for large multimodal models (LMMs) often fail to capture\ntheir performance in real-time, adversarial environments. We introduce LM Fight\nArena (Large Model Fight Arena), a novel framework that evaluates LMMs by\npitting them against each other in the classic fighting game Mortal Kombat II,\na task requiring rapid visual understanding and tactical, sequential\ndecision-making. In a controlled tournament, we test six leading open- and\nclosed-source models, where each agent operates controlling the same character\nto ensure a fair comparison. The models are prompted to interpret game frames\nand state data to select their next actions. Unlike static evaluations, LM\nFight Arena provides a fully automated, reproducible, and objective assessment\nof an LMM's strategic reasoning capabilities in a dynamic setting. This work\nintroduces a challenging and engaging benchmark that bridges the gap between AI\nevaluation and interactive entertainment.", "AI": {"tldr": "LM Fight Arena\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u683c\u6597\u6e38\u620f\u300a\u771f\u4eba\u5feb\u6253II\u300b\u4e2d\u8ba9\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u76f8\u4e92\u5bf9\u6218\uff0c\u8bc4\u4f30\u5b83\u4eec\u5728\u5b9e\u65f6\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u5b83\u4eec\u5728\u5b9e\u65f6\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u771f\u5b9e\u6027\u80fd\uff0c\u9700\u8981\u4e00\u79cd\u52a8\u6001\u3001\u4ea4\u4e92\u5f0f\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5728\u53d7\u63a7\u7684\u9526\u6807\u8d5b\u4e2d\u6d4b\u8bd56\u4e2a\u9886\u5148\u7684\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\uff0c\u8ba9\u6bcf\u4e2a\u6a21\u578b\u63a7\u5236\u76f8\u540c\u89d2\u8272\uff0c\u901a\u8fc7\u89e3\u6790\u6e38\u620f\u753b\u9762\u548c\u72b6\u6001\u6570\u636e\u6765\u9009\u62e9\u884c\u52a8\uff0c\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u8bc4\u4f30\u3002", "result": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u91cd\u73b0\u3001\u5ba2\u89c2\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u80fd\u591f\u6d4b\u8bd5\u591a\u6a21\u6001\u6a21\u578b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6218\u7565\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "LM Fight Arena\u5f15\u5165\u4e86\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u548c\u5438\u5f15\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5f25\u5408\u4e86AI\u8bc4\u4f30\u4e0e\u4ea4\u4e92\u5a31\u4e50\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2510.08953", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.08953", "abs": "https://arxiv.org/abs/2510.08953", "authors": ["Cheng Ouyang", "Moeen Ul Islam", "Dong Chen", "Kaixiang Zhang", "Zhaojian Li", "Xiaobo Tan"], "title": "Direct Data-Driven Predictive Control for a Three-dimensional Cable-Driven Soft Robotic Arm", "comment": null, "summary": "Soft robots offer significant advantages in safety and adaptability, yet\nachieving precise and dynamic control remains a major challenge due to their\ninherently complex and nonlinear dynamics. Recently, Data-enabled Predictive\nControl (DeePC) has emerged as a promising model-free approach that bypasses\nexplicit system identification by directly leveraging input-output data. While\nDeePC has shown success in other domains, its application to soft robots\nremains underexplored, particularly for three-dimensional (3D) soft robotic\nsystems. This paper addresses this gap by developing and experimentally\nvalidating an effective DeePC framework on a 3D, cable-driven soft arm.\nSpecifically, we design and fabricate a soft robotic arm with a thick tubing\nbackbone for stability, a dense silicone body with large cavities for strength\nand flexibility, and rigid endcaps for secure termination. Using this platform,\nwe implement DeePC with singular value decomposition (SVD)-based dimension\nreduction for two key control tasks: fixed-point regulation and trajectory\ntracking in 3D space. Comparative experiments with a baseline model-based\ncontroller demonstrate DeePC's superior accuracy, robustness, and adaptability,\nhighlighting its potential as a practical solution for dynamic control of soft\nrobots.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u9884\u6d4b\u63a7\u5236(DeePC)\u76843D\u8f6f\u4f53\u673a\u5668\u4eba\u63a7\u5236\u6846\u67b6\uff0c\u5728\u7535\u7f06\u9a71\u52a8\u7684\u8f6f\u4f53\u624b\u81c2\u4e0a\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u52a8\u6001\u63a7\u5236\u3002", "motivation": "\u8f6f\u4f53\u673a\u5668\u4eba\u5177\u6709\u5b89\u5168\u6027\u548c\u9002\u5e94\u6027\u4f18\u52bf\uff0c\u4f46\u56e0\u5176\u590d\u6742\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7279\u6027\uff0c\u5b9e\u73b0\u7cbe\u786e\u52a8\u6001\u63a7\u5236\u4ecd\u5177\u6311\u6218\u3002DeePC\u4f5c\u4e3a\u4e00\u79cd\u65e0\u9700\u663e\u5f0f\u7cfb\u7edf\u8fa8\u8bc6\u7684\u6a21\u578b\u65e0\u5173\u65b9\u6cd5\uff0c\u5728\u8f6f\u4f53\u673a\u5668\u4eba\u9886\u57df\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u7279\u522b\u662f\u57283D\u7cfb\u7edf\u4e0a\u3002", "method": "\u8bbe\u8ba1\u5236\u9020\u4e86\u5177\u6709\u539a\u7ba1\u72b6\u9aa8\u67b6\u3001\u81f4\u5bc6\u7845\u80f6\u4f53\u548c\u521a\u6027\u7aef\u76d6\u76843D\u7535\u7f06\u9a71\u52a8\u8f6f\u4f53\u624b\u81c2\uff0c\u91c7\u7528\u57fa\u4e8e\u5947\u5f02\u503c\u5206\u89e3(SVD)\u964d\u7ef4\u7684DeePC\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u56fa\u5b9a\u70b9\u8c03\u8282\u548c3D\u7a7a\u95f4\u8f68\u8ff9\u8ddf\u8e2a\u4e24\u79cd\u63a7\u5236\u4efb\u52a1\u3002", "result": "\u4e0e\u57fa\u4e8e\u6a21\u578b\u7684\u57fa\u7ebf\u63a7\u5236\u5668\u76f8\u6bd4\uff0cDeePC\u5728\u7cbe\u5ea6\u3001\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u8f6f\u4f53\u673a\u5668\u4eba\u52a8\u6001\u63a7\u5236\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "DeePC\u6846\u67b6\u4e3a\u8f6f\u4f53\u673a\u5668\u4eba\u7684\u52a8\u6001\u63a7\u5236\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u5176\u57283D\u8f6f\u4f53\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2510.09304", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09304", "abs": "https://arxiv.org/abs/2510.09304", "authors": ["Marwan Soliman", "Pauline Kergus", "Diego Regruto", "Luiz Villa", "Zohra Kader"], "title": "Data-Driven Control Of Power Converters", "comment": "Conference paper for the french national electrical engineering\n  symposium, SGE 2025", "summary": "The fundamental role of power converters is to efficiently manage and control\nthe flow of electrical energy, ensuring compatibility between power sources and\nloads. All these applications of power converters need the design of an\nappropriate control law. Control of power converters is a challenging problem\ndue to the presence of switching devices which are difficult to handle using\ntraditional control approaches. The objective of this paper is to investigate\nthe use of data-driven techniques, in particular the Virtual References\nFeedback Tuning (VRFT) method, in the context of power converters feedback\ncontrol. This study considers a buck \\pauline{mode} power converter circuit\nprovided by the OwnTech foundation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5728\u7535\u529b\u53d8\u6362\u5668\u53cd\u9988\u63a7\u5236\u4e2d\u4f7f\u7528\u6570\u636e\u9a71\u52a8\u6280\u672f\uff0c\u7279\u522b\u662f\u865a\u62df\u53c2\u8003\u53cd\u9988\u6574\u5b9a(VRFT)\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u63a7\u5236\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5f00\u5173\u5668\u4ef6\u7684\u95ee\u9898\u3002", "motivation": "\u7535\u529b\u53d8\u6362\u5668\u7684\u63a7\u5236\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5f00\u5173\u5668\u4ef6\u7684\u5b58\u5728\u4f7f\u5f97\u4f20\u7edf\u63a7\u5236\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u6570\u636e\u9a71\u52a8\u6280\u672f\u5728\u7535\u529b\u53d8\u6362\u5668\u63a7\u5236\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u91c7\u7528\u865a\u62df\u53c2\u8003\u53cd\u9988\u6574\u5b9a(VRFT)\u8fd9\u4e00\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u57fa\u4e8eOwnTech\u57fa\u91d1\u4f1a\u63d0\u4f9b\u7684\u964d\u538b\u6a21\u5f0f\u7535\u529b\u53d8\u6362\u5668\u7535\u8def\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u8bba\u6587\u7814\u7a76\u4e86VRFT\u65b9\u6cd5\u5728\u7535\u529b\u53d8\u6362\u5668\u53cd\u9988\u63a7\u5236\u4e2d\u7684\u9002\u7528\u6027\u548c\u6548\u679c\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u6280\u672f\uff0c\u7279\u522b\u662fVRFT\u65b9\u6cd5\uff0c\u4e3a\u7535\u529b\u53d8\u6362\u5668\u7684\u63a7\u5236\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u514b\u670d\u4f20\u7edf\u63a7\u5236\u65b9\u6cd5\u5728\u5904\u7406\u5f00\u5173\u5668\u4ef6\u65f6\u7684\u56f0\u96be\u3002"}}
{"id": "2510.09038", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09038", "abs": "https://arxiv.org/abs/2510.09038", "authors": ["Wenyi Wu", "Kun Zhou", "Ruoxin Yuan", "Vivian Yu", "Stephen Wang", "Zhiting Hu", "Biwei Huang"], "title": "Auto-scaling Continuous Memory for GUI Agent", "comment": null, "summary": "We study how to endow GUI agents with scalable memory that help generalize\nacross unfamiliar interfaces and long-horizon tasks. Prior GUI agents compress\npast trajectories into text tokens, which balloons context length and misses\ndecisive visual cues (e.g., exact widget size and position). We propose a\ncontinuous memory that encodes each GUI trajectory into a fixed-length sequence\nof continuous embeddings using the VLM itself as an encoder; these embeddings\nare plugged directly into the backbone's input layer, sharply reducing context\ncost while preserving fine-grained visual information. As memory size and\nretrieval depth increase, performance improves monotonically, unlike text\nmemories that degrade with long prompts. To grow memory at low cost, we\nintroduce an auto-scaling data flywheel that (i) discovers new environments via\nsearch, (ii) synthesizes tasks with an open-source VLM, (iii) rolls out\ntrajectories with the agent, and (iv) verifies success with the same VLM. Using\nthis pipeline, we collect 100k+ trajectories for about \\$4000 and fine-tune\nonly the memory encoder (LoRA on a Q-Former, 1.2\\% parameters) with 1,500\nsamples. On real-world GUI benchmarks, our memory-augmented agent consistently\nimproves success rates under long horizons and distribution shifts. Notably,\nQwen-2.5-VL-7B + continuous memory achieves performance comparable to\nstate-of-the-art closed-source models (e.g., GPT-4o, Claude-4).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fde\u7eed\u8bb0\u5fc6\u673a\u5236\uff0c\u901a\u8fc7VLM\u7f16\u7801GUI\u8f68\u8ff9\u4e3a\u56fa\u5b9a\u957f\u5ea6\u7684\u8fde\u7eed\u5d4c\u5165\uff0c\u663e\u8457\u51cf\u5c11\u4e0a\u4e0b\u6587\u6210\u672c\u5e76\u4fdd\u7559\u7ec6\u7c92\u5ea6\u89c6\u89c9\u4fe1\u606f\uff0c\u5728\u957f\u4efb\u52a1\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u63d0\u5347GUI\u4ee3\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709GUI\u4ee3\u7406\u5c06\u5386\u53f2\u8f68\u8ff9\u538b\u7f29\u4e3a\u6587\u672ctoken\uff0c\u5bfc\u81f4\u4e0a\u4e0b\u6587\u957f\u5ea6\u81a8\u80c0\u4e14\u4e22\u5931\u5173\u952e\u89c6\u89c9\u7ebf\u7d22\uff08\u5982\u63a7\u4ef6\u7cbe\u786e\u5c3a\u5bf8\u548c\u4f4d\u7f6e\uff09\uff0c\u9700\u8981\u53ef\u6269\u5c55\u7684\u8bb0\u5fc6\u673a\u5236\u6765\u6cdb\u5316\u5230\u4e0d\u719f\u6089\u754c\u9762\u548c\u957f\u65f6\u4efb\u52a1\u3002", "method": "\u4f7f\u7528VLM\u4f5c\u4e3a\u7f16\u7801\u5668\u5c06GUI\u8f68\u8ff9\u7f16\u7801\u4e3a\u56fa\u5b9a\u957f\u5ea6\u8fde\u7eed\u5d4c\u5165\uff0c\u76f4\u63a5\u8f93\u5165\u5230\u9aa8\u5e72\u7f51\u7edc\uff1b\u5f15\u5165\u81ea\u52a8\u6269\u5c55\u6570\u636e\u98de\u8f6e\uff0c\u901a\u8fc7\u641c\u7d22\u53d1\u73b0\u65b0\u73af\u5883\u3001VLM\u5408\u6210\u4efb\u52a1\u3001\u4ee3\u7406\u6267\u884c\u8f68\u8ff9\u3001VLM\u9a8c\u8bc1\u6210\u529f\u6765\u4f4e\u6210\u672c\u6269\u5c55\u8bb0\u5fc6\u3002", "result": "\u968f\u7740\u8bb0\u5fc6\u5927\u5c0f\u548c\u68c0\u7d22\u6df1\u5ea6\u589e\u52a0\uff0c\u6027\u80fd\u5355\u8c03\u63d0\u5347\uff1b\u5728\u771f\u5b9eGUI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u957f\u65f6\u4efb\u52a1\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u6301\u7eed\u63d0\u5347\u6210\u529f\u7387\uff1bQwen-2.5-VL-7B+\u8fde\u7eed\u8bb0\u5fc6\u8fbe\u5230\u4e0eGPT-4o\u3001Claude-4\u7b49\u95ed\u6e90\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "\u8fde\u7eed\u8bb0\u5fc6\u673a\u5236\u80fd\u6709\u6548\u63d0\u5347GUI\u4ee3\u7406\u5728\u590d\u6742\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u4f4e\u6210\u672c\u6570\u636e\u6536\u96c6\u548c\u5fae\u8c03\u5b9e\u73b0\u4e0e\u9876\u7ea7\u95ed\u6e90\u6a21\u578b\u7ade\u4e89\u7684\u6548\u679c\uff0c\u8bc1\u660e\u4e86\u89c6\u89c9\u8bb0\u5fc6\u5728GUI\u81ea\u52a8\u5316\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.08931", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08931", "abs": "https://arxiv.org/abs/2510.08931", "authors": ["Ashish Kattamuri", "Harshwardhan Fartale", "Arpita Vats", "Rahul Raja", "Ishita Prasad"], "title": "RADAR: Mechanistic Pathways for Detecting Data Contamination in LLM Evaluation", "comment": "NeurIPS 2025 Workshop on Evaluating the Evolving LLM Lifecycle:\n  Benchmarks, Emergent Abilities, and Scaling", "summary": "Data contamination poses a significant challenge to reliable LLM evaluation,\nwhere models may achieve high performance by memorizing training data rather\nthan demonstrating genuine reasoning capabilities. We introduce RADAR (Recall\nvs. Reasoning Detection through Activation Representation), a novel framework\nthat leverages mechanistic interpretability to detect contamination by\ndistinguishing recall-based from reasoning-based model responses. RADAR\nextracts 37 features spanning surface-level confidence trajectories and deep\nmechanistic properties including attention specialization, circuit dynamics,\nand activation flow patterns. Using an ensemble of classifiers trained on these\nfeatures, RADAR achieves 93\\% accuracy on a diverse evaluation set, with\nperfect performance on clear cases and 76.7\\% accuracy on challenging ambiguous\nexamples. This work demonstrates the potential of mechanistic interpretability\nfor advancing LLM evaluation beyond traditional surface-level metrics.", "AI": {"tldr": "RADAR\u662f\u4e00\u4e2a\u57fa\u4e8e\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u533a\u5206\u57fa\u4e8e\u8bb0\u5fc6\u548c\u57fa\u4e8e\u63a8\u7406\u7684\u6a21\u578b\u54cd\u5e94\u6765\u68c0\u6d4b\u6570\u636e\u6c61\u67d3\uff0c\u51c6\u786e\u7387\u8fbe\u523093%\u3002", "motivation": "\u6570\u636e\u6c61\u67d3\u5bf9\u53ef\u9760\u7684LLM\u8bc4\u4f30\u6784\u6210\u91cd\u5927\u6311\u6218\uff0c\u6a21\u578b\u53ef\u80fd\u901a\u8fc7\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u800c\u975e\u5c55\u793a\u771f\u6b63\u63a8\u7406\u80fd\u529b\u6765\u83b7\u5f97\u9ad8\u6027\u80fd\u3002", "method": "RADAR\u63d0\u53d637\u4e2a\u7279\u5f81\uff0c\u6db5\u76d6\u8868\u9762\u7ea7\u7f6e\u4fe1\u5ea6\u8f68\u8ff9\u548c\u6df1\u5c42\u673a\u5236\u7279\u6027\uff08\u5305\u62ec\u6ce8\u610f\u529b\u4e13\u4e1a\u5316\u3001\u7535\u8def\u52a8\u6001\u548c\u6fc0\u6d3b\u6d41\u6a21\u5f0f\uff09\uff0c\u5e76\u4f7f\u7528\u8fd9\u4e9b\u7279\u5f81\u7684\u96c6\u6210\u5206\u7c7b\u5668\u3002", "result": "\u5728\u591a\u6837\u5316\u8bc4\u4f30\u96c6\u4e0a\u8fbe\u523093%\u51c6\u786e\u7387\uff0c\u5728\u6e05\u6670\u6848\u4f8b\u4e2d\u8868\u73b0\u5b8c\u7f8e\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u6a21\u7cca\u793a\u4f8b\u4e2d\u8fbe\u523076.7%\u51c6\u786e\u7387\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u673a\u5236\u53ef\u89e3\u91ca\u6027\u5728\u8d85\u8d8a\u4f20\u7edf\u8868\u9762\u7ea7\u6307\u6807\u63a8\u8fdbLLM\u8bc4\u4f30\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.08973", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.08973", "abs": "https://arxiv.org/abs/2510.08973", "authors": ["Bibekananda Patra", "Aditya Mahesh Kolte", "Sandipan Bandyopadhyay"], "title": "A geometrical approach to solve the proximity of a point to an axisymmetric quadric in space", "comment": null, "summary": "This paper presents the classification of a general quadric into an\naxisymmetric quadric (AQ) and the solution to the problem of the proximity of a\ngiven point to an AQ. The problem of proximity in $R^3$ is reduced to the same\nin $R^2$, which is not found in the literature. A new method to solve the\nproblem in $R^2$ is used based on the geometrical properties of the conics,\nsuch as sub-normal, length of the semi-major axis, eccentricity, slope and\nradius. Furthermore, the problem in $R^2$ is categorised into two and three\nmore sub-cases for parabola and ellipse/hyperbola, respectively, depending on\nthe location of the point, which is a novel approach as per the authors'\nknowledge. The proposed method is suitable for implementation in a common\nprogramming language, such as C and proved to be faster than a commercial\nlibrary, namely, Bullet.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u4e00\u822c\u4e8c\u6b21\u66f2\u9762\u5206\u7c7b\u4e3a\u8f74\u5bf9\u79f0\u4e8c\u6b21\u66f2\u9762(AQ)\u7684\u65b9\u6cd5\uff0c\u5e76\u89e3\u51b3\u4e86\u70b9\u5230AQ\u7684\u90bb\u8fd1\u5ea6\u95ee\u9898\u3002\u901a\u8fc7\u5c06R^3\u7a7a\u95f4\u7684\u95ee\u9898\u7b80\u5316\u4e3aR^2\u7a7a\u95f4\uff0c\u5e76\u5229\u7528\u5706\u9525\u66f2\u7ebf\u7684\u51e0\u4f55\u7279\u6027\u5f00\u53d1\u65b0\u7b97\u6cd5\uff0c\u8bc1\u660e\u6bd4\u5546\u4e1a\u5e93Bullet\u66f4\u5feb\u3002", "motivation": "\u89e3\u51b3\u4e09\u7ef4\u7a7a\u95f4\u4e2d\u70b9\u5230\u8f74\u5bf9\u79f0\u4e8c\u6b21\u66f2\u9762\u7684\u90bb\u8fd1\u5ea6\u8ba1\u7b97\u95ee\u9898\uff0c\u73b0\u6709\u6587\u732e\u4e2d\u7f3a\u4e4f\u5c06R^3\u95ee\u9898\u7b80\u5316\u4e3aR^2\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u7b97\u6cd5\u3002", "method": "\u5c06R^3\u7a7a\u95f4\u7684\u90bb\u8fd1\u5ea6\u95ee\u9898\u7b80\u5316\u4e3aR^2\u7a7a\u95f4\uff0c\u57fa\u4e8e\u5706\u9525\u66f2\u7ebf\u7684\u51e0\u4f55\u7279\u6027\uff08\u5982\u6b21\u6cd5\u7ebf\u3001\u534a\u957f\u8f74\u957f\u5ea6\u3001\u79bb\u5fc3\u7387\u3001\u659c\u7387\u548c\u534a\u5f84\uff09\u5f00\u53d1\u65b0\u65b9\u6cd5\uff0c\u5bf9\u629b\u7269\u7ebf\u548c\u692d\u5706/\u53cc\u66f2\u7ebf\u5206\u522b\u8fdb\u884c2-3\u79cd\u5b50\u60c5\u51b5\u5206\u7c7b\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u9002\u5408\u5728C\u7b49\u901a\u7528\u7f16\u7a0b\u8bed\u8a00\u4e2d\u5b9e\u73b0\uff0c\u7ecf\u6d4b\u8bd5\u6bd4\u5546\u4e1a\u5e93Bullet\u66f4\u5feb\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u5c06\u4e09\u7ef4\u90bb\u8fd1\u5ea6\u95ee\u9898\u7b80\u5316\u4e3a\u4e8c\u7ef4\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u57fa\u4e8e\u51e0\u4f55\u7279\u6027\u7684\u65b0\u7b97\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u5546\u4e1a\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.09349", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09349", "abs": "https://arxiv.org/abs/2510.09349", "authors": ["Yeomoon Kim", "Minsoo Kim", "Jip Kim"], "title": "MPA-DNN: Projection-Aware Unsupervised Learning for Multi-period DC-OPF", "comment": null, "summary": "Ensuring both feasibility and efficiency in optimal power flow (OPF)\noperations has become increasingly important in modern power systems with high\npenetrations of renewable energy and energy storage. While deep neural networks\n(DNNs) have emerged as promising fast surrogates for OPF solvers, they often\nfail to satisfy critical operational constraints, especially those involving\ninter-temporal coupling, such as generator ramping limits and energy storage\noperations. To deal with these issues, we propose a Multi-Period\nProjection-Aware Deep Neural Network (MPA-DNN) that incorporates a projection\nlayer for multi-period dispatch into the network. By doing so, our model\nenforces physical feasibility through the projection, enabling end-to-end\nlearning of constraint-compliant dispatch trajectories without relying on\nlabeled data. Experimental results demonstrate that the proposed method\nachieves near-optimal performance while strictly satisfying all constraints in\nvarying load conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5468\u671f\u6295\u5f71\u611f\u77e5\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc(MPA-DNN)\uff0c\u901a\u8fc7\u5728\u7f51\u7edc\u4e2d\u96c6\u6210\u591a\u5468\u671f\u8c03\u5ea6\u6295\u5f71\u5c42\uff0c\u786e\u4fdd\u7535\u529b\u7cfb\u7edf\u6700\u4f18\u6f6e\u6d41(OPF)\u7684\u53ef\u884c\u6027\u548c\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u53ef\u518d\u751f\u80fd\u6e90\u548c\u50a8\u80fd\u9ad8\u6e17\u900f\u7387\u573a\u666f\u4e0b\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3aOPF\u5feb\u901f\u66ff\u4ee3\u6c42\u89e3\u5668\u65f6\u96be\u4ee5\u6ee1\u8db3\u53d1\u7535\u673a\u722c\u5761\u9650\u5236\u548c\u50a8\u80fd\u8fd0\u884c\u7b49\u8de8\u65f6\u95f4\u8026\u5408\u7ea6\u675f\u7684\u95ee\u9898\u3002", "method": "\u5728\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u96c6\u6210\u591a\u5468\u671f\u8c03\u5ea6\u6295\u5f71\u5c42\uff0c\u901a\u8fc7\u6295\u5f71\u5f3a\u5236\u6ee1\u8db3\u7269\u7406\u53ef\u884c\u6027\uff0c\u5b9e\u73b0\u65e0\u9700\u6807\u6ce8\u6570\u636e\u7684\u7aef\u5230\u7aef\u7ea6\u675f\u5408\u89c4\u8c03\u5ea6\u8f68\u8ff9\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u8d1f\u8377\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4e25\u683c\u6ee1\u8db3\u6240\u6709\u7ea6\u675f\u6761\u4ef6\u3002", "conclusion": "MPA-DNN\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3OPF\u4e2d\u7684\u8de8\u65f6\u95f4\u8026\u5408\u7ea6\u675f\u95ee\u9898\uff0c\u63d0\u4f9b\u53ef\u884c\u4e14\u9ad8\u6548\u7684\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08945", "categories": ["cs.AI", "I.7.5; I.2.1; I.2.8; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.08945", "abs": "https://arxiv.org/abs/2510.08945", "authors": ["Samuel Hildebrand", "Curtis Taylor", "Sean Oesch", "James M Ghawaly Jr", "Amir Sadovnik", "Ryan Shivers", "Brandon Schreiber", "Kevin Kurian"], "title": "FATHOMS-RAG: A Framework for the Assessment of Thinking and Observation in Multimodal Systems that use Retrieval Augmented Generation", "comment": null, "summary": "Retrieval-augmented generation (RAG) has emerged as a promising paradigm for\nimproving factual accuracy in large language models (LLMs). We introduce a\nbenchmark designed to evaluate RAG pipelines as a whole, evaluating a\npipeline's ability to ingest, retrieve, and reason about several modalities of\ninformation, differentiating it from existing benchmarks that focus on\nparticular aspects such as retrieval. We present (1) a small, human-created\ndataset of 93 questions designed to evaluate a pipeline's ability to ingest\ntextual data, tables, images, and data spread across these modalities in one or\nmore documents; (2) a phrase-level recall metric for correctness; (3) a\nnearest-neighbor embedding classifier to identify potential pipeline\nhallucinations; (4) a comparative evaluation of 2 pipelines built with\nopen-source retrieval mechanisms and 4 closed-source foundation models; and (5)\na third-party human evaluation of the alignment of our correctness and\nhallucination metrics. We find that closed-source pipelines significantly\noutperform open-source pipelines in both correctness and hallucination metrics,\nwith wider performance gaps in questions relying on multimodal and\ncross-document information. Human evaluation of our metrics showed average\nagreement of 4.62 for correctness and 4.53 for hallucination detection on a 1-5\nLikert scale (5 indicating \"strongly agree\").", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30RAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u7ba1\u9053\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u591a\u6a21\u6001\u6570\u636e\u8bc4\u4f30\u3001\u77ed\u8bed\u7ea7\u53ec\u56de\u6307\u6807\u3001\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5e76\u6bd4\u8f83\u4e86\u5f00\u6e90\u4e0e\u95ed\u6e90\u7ba1\u9053\u7684\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u68c0\u7d22\u7b49\u7279\u5b9a\u65b9\u9762\uff0c\u7f3a\u4e4f\u5bf9RAG\u7ba1\u9053\u6574\u4f53\u80fd\u529b\u7684\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u5904\u7406\u591a\u6a21\u6001\u4fe1\u606f\u7684\u80fd\u529b\u3002", "method": "\u521b\u5efa\u4e86\u5305\u542b93\u4e2a\u95ee\u9898\u7684\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u6587\u672c\u3001\u8868\u683c\u3001\u56fe\u50cf\u7b49\u591a\u6a21\u6001\u4fe1\u606f\uff1b\u63d0\u51fa\u4e86\u77ed\u8bed\u7ea7\u53ec\u56de\u6307\u6807\u548c\u57fa\u4e8e\u6700\u8fd1\u90bb\u5d4c\u5165\u7684\u5e7b\u89c9\u5206\u7c7b\u5668\uff1b\u8bc4\u4f30\u4e862\u4e2a\u5f00\u6e90\u548c4\u4e2a\u95ed\u6e90\u7ba1\u9053\u3002", "result": "\u95ed\u6e90\u7ba1\u9053\u5728\u6b63\u786e\u6027\u548c\u5e7b\u89c9\u68c0\u6d4b\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5f00\u6e90\u7ba1\u9053\uff0c\u7279\u522b\u662f\u5728\u591a\u6a21\u6001\u548c\u8de8\u6587\u6863\u95ee\u9898\u4e0a\uff1b\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\u6307\u6807\u4e0e\u4eba\u7c7b\u5224\u65ad\u9ad8\u5ea6\u4e00\u81f4\uff084.62/5\u548c4.53/5\uff09\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u80fd\u6709\u6548\u8bc4\u4f30RAG\u7ba1\u9053\u7684\u6574\u4f53\u6027\u80fd\uff0c\u95ed\u6e90\u6a21\u578b\u5728\u591a\u6a21\u6001\u5904\u7406\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u63d0\u51fa\u7684\u8bc4\u4f30\u6307\u6807\u4e0e\u4eba\u7c7b\u5224\u65ad\u6709\u826f\u597d\u4e00\u81f4\u6027\u3002"}}
{"id": "2510.09013", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.09013", "abs": "https://arxiv.org/abs/2510.09013", "authors": ["Daniel A. Williams", "Airlie Chapman", "Daniel R. Little", "Chris Manzie"], "title": "Trust Modeling and Estimation in Human-Autonomy Interactions", "comment": "10 pages. 13 figures", "summary": "Advances in the control of autonomous systems have accompanied an expansion\nin the potential applications for autonomous robotic systems. The success of\napplications involving humans depends on the quality of interaction between the\nautonomous system and the human supervisor, which is particularly affected by\nthe degree of trust that the supervisor places in the autonomous system. Absent\nfrom the literature are models of supervisor trust dynamics that can\naccommodate asymmetric responses to autonomous system performance and the\nintermittent nature of supervisor-autonomous system communication. This paper\nfocuses on formulating an estimated model of supervisor trust that incorporates\nboth of these features by employing a switched linear system structure with\nevent-triggered sampling of the model input and output. Trust response data\ncollected in a user study with 51 participants were then used identify\nparameters for a switched linear model-based observer of supervisor trust.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5207\u6362\u7ebf\u6027\u7cfb\u7edf\u7684\u76d1\u7763\u8005\u4fe1\u4efb\u52a8\u6001\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u5904\u7406\u5bf9\u81ea\u4e3b\u7cfb\u7edf\u6027\u80fd\u7684\u4e0d\u5bf9\u79f0\u54cd\u5e94\u548c\u95f4\u6b47\u6027\u901a\u4fe1\u7279\u6027\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u7f3a\u4e4f\u80fd\u591f\u540c\u65f6\u5904\u7406\u81ea\u4e3b\u7cfb\u7edf\u6027\u80fd\u4e0d\u5bf9\u79f0\u54cd\u5e94\u548c\u76d1\u7763\u8005-\u81ea\u4e3b\u7cfb\u7edf\u95f4\u6b47\u6027\u901a\u4fe1\u7279\u6027\u7684\u4fe1\u4efb\u52a8\u6001\u6a21\u578b\uff0c\u8fd9\u5f71\u54cd\u4e86\u4eba\u673a\u4ea4\u4e92\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u5207\u6362\u7ebf\u6027\u7cfb\u7edf\u7ed3\u6784\uff0c\u7ed3\u5408\u4e8b\u4ef6\u89e6\u53d1\u91c7\u6837\u7684\u6a21\u578b\u8f93\u5165\u8f93\u51fa\uff0c\u4f7f\u752851\u540d\u53c2\u4e0e\u8005\u7684\u4fe1\u4efb\u54cd\u5e94\u6570\u636e\u6765\u8bc6\u522b\u5207\u6362\u7ebf\u6027\u6a21\u578b\u89c2\u6d4b\u5668\u7684\u53c2\u6570\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u80fd\u591f\u51c6\u786e\u63cf\u8ff0\u76d1\u7763\u8005\u4fe1\u4efb\u52a8\u6001\u7684\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u6355\u6349\u4fe1\u4efb\u5bf9\u81ea\u4e3b\u7cfb\u7edf\u6027\u80fd\u7684\u4e0d\u5bf9\u79f0\u54cd\u5e94\u7279\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u5207\u6362\u7ebf\u6027\u7cfb\u7edf\u6a21\u578b\u4e3a\u7406\u89e3\u548c\u7ba1\u7406\u4eba\u673a\u4ea4\u4e92\u4e2d\u7684\u4fe1\u4efb\u52a8\u6001\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5efa\u6a21\u6846\u67b6\u3002"}}
{"id": "2510.09409", "categories": ["eess.SY", "cs.IT", "cs.SY", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.09409", "abs": "https://arxiv.org/abs/2510.09409", "authors": ["Chongxiao Cai", "Yan Zhu", "Min Sheng", "Jiandong Li", "Yan Shi", "Di Zhou", "Ziwen Xie", "Chen Zhang"], "title": "3C Resources Joint Allocation for Time-Deterministic Remote Sensing Image Backhaul in the Space-Ground Integrated Network", "comment": null, "summary": "Low-Earth-orbit (LEO) satellites assist observation satellites (OSs) to\ncompress and backhaul more time-determined images (TDI) has become a new\nparadigm, which is used to enhance the timeout caused by the limited computing\nresources of OSs. However, how to capture the time-varying and dynamic\ncharacteristics of multi-dimensional resources is challenging for efficient\ncollaborative scheduling. Motivated by this factor, we design a highly succinct\nmulti-dimensional resource time-expanded graph (MDR-TEG) modell. Specifically,\nby employing a slots division mechanism and introducing an external virtual\nnode, the time-varying communication, caching, and computing (3C) resources are\ndepicted in low complexity by the link weights within, between, and outside the\nslots. Based on the MDR-TEG, the maximizing successful transmission ratio of\nTDI (MSTR-TDI) is modeled as a mixed integer linear programming (MILP) problem.\nWhich further relaxed decomposed into two tractable sub-problems: maximizing\nthe successful transmission rate of images (MSTRI) and ensuring the timeliness\nproblem (ETP). Subsequently, an efficient subgradient of relaxation computing\nconstraint (SRCC) algorithm is proposed. The upper and lower bounds of MSTR-TDI\nare obtained by solving the two subproblems and the dual problem (DP), and the\ndirection of the next iteration is obtained by feedback. Furthermore, arranging\nthe sending sequences of images to improve the quality of the solution. The\napproximate optimal solution of MSTR-TDI is eventually obtained through\nrepeated iterations. The simulation results verify the superiority of the\nproposed MDR-TEG model and the effectiveness of the SRCC.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u7ef4\u5ea6\u8d44\u6e90\u65f6\u95f4\u6269\u5c55\u56fe\u6a21\u578b\u548cSRCC\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u4f4e\u8f68\u536b\u661f\u534f\u52a9\u89c2\u6d4b\u536b\u661f\u4f20\u8f93\u65f6\u95f4\u654f\u611f\u56fe\u50cf\u65f6\u7684\u8d44\u6e90\u8c03\u5ea6\u95ee\u9898\u3002", "motivation": "\u4f4e\u8f68\u536b\u661f\u534f\u52a9\u89c2\u6d4b\u536b\u661f\u538b\u7f29\u548c\u56de\u4f20\u65f6\u95f4\u654f\u611f\u56fe\u50cf\u65f6\uff0c\u5982\u4f55\u6355\u6349\u591a\u7ef4\u5ea6\u8d44\u6e90\u7684\u65f6\u53d8\u548c\u52a8\u6001\u7279\u6027\u4ee5\u5b9e\u73b0\u9ad8\u6548\u534f\u540c\u8c03\u5ea6\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u4e86\u591a\u7ef4\u5ea6\u8d44\u6e90\u65f6\u95f4\u6269\u5c55\u56fe\u6a21\u578b\uff0c\u901a\u8fc7\u65f6\u9699\u5212\u5206\u673a\u5236\u548c\u865a\u62df\u8282\u70b9\u4f4e\u590d\u6742\u5ea6\u63cf\u8ff0\u65f6\u53d8\u901a\u4fe1\u3001\u7f13\u5b58\u548c\u8ba1\u7b97\u8d44\u6e90\u3002\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff0c\u5206\u89e3\u4e3a\u4e24\u4e2a\u5b50\u95ee\u9898\u5e76\u63d0\u51fa\u4e86SRCC\u7b97\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86MDR-TEG\u6a21\u578b\u7684\u4f18\u8d8a\u6027\u548cSRCC\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6a21\u578b\u548c\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4f4e\u8f68\u536b\u661f\u534f\u52a9\u89c2\u6d4b\u536b\u661f\u4f20\u8f93\u65f6\u95f4\u654f\u611f\u56fe\u50cf\u65f6\u7684\u8d44\u6e90\u8c03\u5ea6\u95ee\u9898\uff0c\u83b7\u5f97\u8fd1\u4f3c\u6700\u4f18\u89e3\u3002"}}
{"id": "2510.09162", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.09162", "abs": "https://arxiv.org/abs/2510.09162", "authors": ["Emma Kondrup", "Anne Imouza"], "title": "Dr. Bias: Social Disparities in AI-Powered Medical Guidance", "comment": null, "summary": "With the rapid progress of Large Language Models (LLMs), the general public\nnow has easy and affordable access to applications capable of answering most\nhealth-related questions in a personalized manner. These LLMs are increasingly\nproving to be competitive, and now even surpass professionals in some medical\ncapabilities. They hold particular promise in low-resource settings,\nconsidering they provide the possibility of widely accessible, quasi-free\nhealthcare support. However, evaluations that fuel these motivations highly\nlack insights into the social nature of healthcare, oblivious to health\ndisparities between social groups and to how bias may translate into\nLLM-generated medical advice and impact users. We provide an exploratory\nanalysis of LLM answers to a series of medical questions spanning key clinical\ndomains, where we simulate these questions being asked by several patient\nprofiles that vary in sex, age range, and ethnicity. By comparing natural\nlanguage features of the generated responses, we show that, when LLMs are used\nfor medical advice generation, they generate responses that systematically\ndiffer between social groups. In particular, Indigenous and intersex patients\nreceive advice that is less readable and more complex. We observe these trends\namplify when intersectional groups are considered. Considering the increasing\ntrust individuals place in these models, we argue for higher AI literacy and\nfor the urgent need for investigation and mitigation by AI developers to ensure\nthese systemic differences are diminished and do not translate to unjust\npatient support. Our code is publicly available on GitHub.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u533b\u7597\u5efa\u8bae\u65f6\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u5bf9\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\uff08\u7279\u522b\u662f\u571f\u8457\u548c\u53cc\u6027\u4eba\u60a3\u8005\uff09\u7684\u56de\u7b54\u5728\u53ef\u8bfb\u6027\u548c\u590d\u6742\u6027\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u4e14\u4ea4\u53c9\u7fa4\u4f53\u4e2d\u8fd9\u79cd\u8d8b\u52bf\u66f4\u52a0\u660e\u663e\u3002", "motivation": "\u968f\u7740LLMs\u5728\u533b\u7597\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u662f\u5426\u4f1a\u56e0\u793e\u4f1a\u504f\u89c1\u800c\u4ea7\u751f\u4e0d\u516c\u5e73\u7684\u533b\u7597\u5efa\u8bae\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u8d44\u6e90\u532e\u4e4f\u7684\u73af\u5883\u4e2d\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u4e0d\u540c\u6027\u522b\u3001\u5e74\u9f84\u548c\u79cd\u65cf\u7684\u60a3\u8005\u6863\u6848\uff0c\u5411LLMs\u63d0\u51fa\u4e00\u7cfb\u5217\u4e34\u5e8a\u95ee\u9898\uff0c\u6bd4\u8f83\u751f\u6210\u56de\u7b54\u7684\u81ea\u7136\u8bed\u8a00\u7279\u5f81\u3002", "result": "LLMs\u751f\u6210\u7684\u533b\u7597\u5efa\u8bae\u5728\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u571f\u8457\u548c\u53cc\u6027\u4eba\u60a3\u8005\u6536\u5230\u7684\u5efa\u8bae\u53ef\u8bfb\u6027\u66f4\u5dee\u3001\u66f4\u590d\u6742\uff0c\u4ea4\u53c9\u7fa4\u4f53\u4e2d\u8fd9\u79cd\u5dee\u5f02\u66f4\u52a0\u660e\u663e\u3002", "conclusion": "\u9700\u8981\u63d0\u9ad8AI\u7d20\u517b\uff0c\u5e76\u547c\u5401AI\u5f00\u53d1\u8005\u7d27\u6025\u8c03\u67e5\u548c\u7f13\u89e3\u8fd9\u4e9b\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u786e\u4fdd\u60a3\u8005\u83b7\u5f97\u516c\u5e73\u7684\u652f\u6301\u3002"}}
{"id": "2510.08958", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.08958", "abs": "https://arxiv.org/abs/2510.08958", "authors": ["Zirui Liao"], "title": "EcphoryRAG: Re-Imagining Knowledge-Graph RAG via Human Associative Memory", "comment": null, "summary": "Cognitive neuroscience research indicates that humans leverage cues to\nactivate entity-centered memory traces (engrams) for complex, multi-hop\nrecollection. Inspired by this mechanism, we introduce EcphoryRAG, an\nentity-centric knowledge graph RAG framework. During indexing, EcphoryRAG\nextracts and stores only core entities with corresponding metadata, a\nlightweight approach that reduces token consumption by up to 94\\% compared to\nother structured RAG systems. For retrieval, the system first extracts cue\nentities from queries, then performs a scalable multi-hop associative search\nacross the knowledge graph. Crucially, EcphoryRAG dynamically infers implicit\nrelations between entities to populate context, enabling deep reasoning without\nexhaustive pre-enumeration of relationships. Extensive evaluations on the\n2WikiMultiHop, HotpotQA, and MuSiQue benchmarks demonstrate that EcphoryRAG\nsets a new state-of-the-art, improving the average Exact Match (EM) score from\n0.392 to 0.474 over strong KG-RAG methods like HippoRAG. These results validate\nthe efficacy of the entity-cue-multi-hop retrieval paradigm for complex\nquestion answering.", "AI": {"tldr": "EcphoryRAG\u662f\u4e00\u4e2a\u57fa\u4e8e\u5b9e\u4f53\u77e5\u8bc6\u56fe\u8c31\u7684RAG\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u53d6\u6838\u5fc3\u5b9e\u4f53\u548c\u5143\u6570\u636e\u8fdb\u884c\u8f7b\u91cf\u7ea7\u7d22\u5f15\uff0c\u5229\u7528\u591a\u8df3\u5173\u8054\u68c0\u7d22\u548c\u52a8\u6001\u5173\u7cfb\u63a8\u7406\uff0c\u5728\u590d\u6742\u95ee\u7b54\u4efb\u52a1\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u53d7\u4eba\u7c7b\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\uff0c\u5229\u7528\u7ebf\u7d22\u6fc0\u6d3b\u5b9e\u4f53\u4e2d\u5fc3\u8bb0\u5fc6\u75d5\u8ff9\u8fdb\u884c\u590d\u6742\u591a\u8df3\u56de\u5fc6\u7684\u673a\u5236\uff0c\u65e8\u5728\u63d0\u9ad8\u590d\u6742\u95ee\u7b54\u7cfb\u7edf\u7684\u6548\u7387\u548c\u6027\u80fd\u3002", "method": "\u7d22\u5f15\u9636\u6bb5\u4ec5\u63d0\u53d6\u548c\u5b58\u50a8\u6838\u5fc3\u5b9e\u4f53\u53ca\u5143\u6570\u636e\uff1b\u68c0\u7d22\u9636\u6bb5\u4ece\u67e5\u8be2\u4e2d\u63d0\u53d6\u7ebf\u7d22\u5b9e\u4f53\uff0c\u5728\u77e5\u8bc6\u56fe\u8c31\u4e0a\u8fdb\u884c\u53ef\u6269\u5c55\u7684\u591a\u8df3\u5173\u8054\u641c\u7d22\uff0c\u5e76\u52a8\u6001\u63a8\u65ad\u5b9e\u4f53\u95f4\u7684\u9690\u5f0f\u5173\u7cfb\u6765\u586b\u5145\u4e0a\u4e0b\u6587\u3002", "result": "\u57282WikiMultiHop\u3001HotpotQA\u548cMuSiQue\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5e73\u5747\u7cbe\u786e\u5339\u914d\u5206\u6570\u4ece0.392\u63d0\u5347\u52300.474\uff0c\u6bd4HippoRAG\u7b49\u5f3aKG-RAG\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\uff0c\u540c\u65f6\u7d22\u5f15token\u6d88\u8017\u51cf\u5c11\u9ad8\u8fbe94%\u3002", "conclusion": "\u5b9e\u4f53-\u7ebf\u7d22-\u591a\u8df3\u68c0\u7d22\u8303\u5f0f\u5728\u590d\u6742\u95ee\u7b54\u4e2d\u5177\u6709\u9ad8\u6548\u6027\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.09036", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09036", "abs": "https://arxiv.org/abs/2510.09036", "authors": ["Chuanrui Zhang", "Zhengxian Wu", "Guanxing Lu", "Yansong Tang", "Ziwei Wang"], "title": "iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation", "comment": null, "summary": "Learned world models hold significant potential for robotic manipulation, as\nthey can serve as simulator for real-world interactions. While extensive\nprogress has been made in 2D video-based world models, these approaches often\nlack geometric and spatial reasoning, which is essential for capturing the\nphysical structure of the 3D world. To address this limitation, we introduce\niMoWM, a novel interactive world model designed to generate color images, depth\nmaps, and robot arm masks in an autoregressive manner conditioned on actions.\nTo overcome the high computational cost associated with three-dimensional\ninformation, we propose MMTokenizer, which unifies multi-modal inputs into a\ncompact token representation. This design enables iMoWM to leverage large-scale\npretrained VideoGPT models while maintaining high efficiency and incorporating\nricher physical information. With its multi-modal representation, iMoWM not\nonly improves the visual quality of future predictions but also serves as an\neffective simulator for model-based reinforcement learning (MBRL) and\nfacilitates real-world imitation learning. Extensive experiments demonstrate\nthe superiority of iMoWM across these tasks, showcasing the advantages of\nmulti-modal world modeling for robotic manipulation. Homepage:\nhttps://xingyoujun.github.io/imowm/", "AI": {"tldr": "iMoWM\u662f\u4e00\u4e2a\u7528\u4e8e\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u4ea4\u4e92\u5f0f\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u4ee4\u724c\u5316\u5668\u7edf\u4e00\u5904\u7406\u989c\u8272\u56fe\u50cf\u3001\u6df1\u5ea6\u56fe\u548c\u673a\u68b0\u81c2\u63a9\u7801\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u589e\u5f3a3D\u7269\u7406\u4fe1\u606f\u5efa\u6a21\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u76842D\u89c6\u9891\u4e16\u754c\u6a21\u578b\u7f3a\u4e4f\u51e0\u4f55\u548c\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u6cd5\u5145\u5206\u6355\u63493D\u4e16\u754c\u7684\u7269\u7406\u7ed3\u6784\uff0c\u9650\u5236\u4e86\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faiMoWM\u4ea4\u4e92\u5f0f\u4e16\u754c\u6a21\u578b\u548cMMTokenizer\u591a\u6a21\u6001\u4ee4\u724c\u5316\u5668\uff0c\u5c06\u591a\u6a21\u6001\u8f93\u5165\u7edf\u4e00\u4e3a\u7d27\u51d1\u4ee4\u724c\u8868\u793a\uff0c\u4ee5\u81ea\u56de\u5f52\u65b9\u5f0f\u751f\u6210\u989c\u8272\u56fe\u50cf\u3001\u6df1\u5ea6\u56fe\u548c\u673a\u68b0\u81c2\u63a9\u7801\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eiMoWM\u5728\u89c6\u89c9\u8d28\u91cf\u3001\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u548c\u771f\u5b9e\u4e16\u754c\u6a21\u4eff\u5b66\u4e60\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u5c55\u793a\u4e86\u591a\u6a21\u6001\u4e16\u754c\u5efa\u6a21\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u4f18\u52bf\u3002", "conclusion": "\u591a\u6a21\u6001\u4e16\u754c\u5efa\u6a21\u80fd\u591f\u6709\u6548\u63d0\u5347\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u7684\u6027\u80fd\uff0ciMoWM\u901a\u8fc7\u6574\u54083D\u7269\u7406\u4fe1\u606f\u4e3a\u673a\u5668\u4eba\u64cd\u4f5c\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u4eff\u771f\u73af\u5883\u3002"}}
{"id": "2510.09411", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09411", "abs": "https://arxiv.org/abs/2510.09411", "authors": ["Amir Bahador Javadi", "Philip Pong"], "title": "Grid-forming Control of Converter Infinite Bus System: Modeling by Data-driven Methods", "comment": null, "summary": "This study explores data-driven modeling techniques to capture the dynamics\nof a grid-forming converter-based infinite bus system, critical for\nrenewable-integrated power grids. Using sparse identification of nonlinear\ndynamics and deep symbolic regression, models were generated from synthetic\ndata simulating key disturbances in active power, reactive power, and voltage\nreferences. Deep symbolic regression demonstrated more accuracy in capturing\ncomplex system dynamics, though it required substantially more computational\ntime than sparse identification of nonlinear dynamics. These findings suggest\nthat while deep symbolic regression offers high fidelity, sparse identification\nof nonlinear dynamics provides a more computationally efficient approach,\nbalancing accuracy and runtime for real-time grid applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u7a00\u758f\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u8bc6\u522b\u548c\u6df1\u5ea6\u7b26\u53f7\u56de\u5f52\u5728\u7535\u7f51\u5efa\u6a21\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6df1\u5ea6\u7b26\u53f7\u56de\u5f52\u7cbe\u5ea6\u66f4\u9ad8\u4f46\u8ba1\u7b97\u6210\u672c\u5927\uff0c\u7a00\u758f\u8bc6\u522b\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u95f4\u53d6\u5f97\u66f4\u597d\u5e73\u8861\u3002", "motivation": "\u968f\u7740\u53ef\u518d\u751f\u80fd\u6e90\u5e76\u7f51\uff0c\u9700\u8981\u51c6\u786e\u5efa\u6a21\u7535\u7f51\u5f62\u6210\u53d8\u6362\u5668\u7cfb\u7edf\u52a8\u6001\uff0c\u4ee5\u4fdd\u969c\u7535\u7f51\u7a33\u5b9a\u8fd0\u884c\u3002", "method": "\u4f7f\u7528\u7a00\u758f\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u8bc6\u522b\u548c\u6df1\u5ea6\u7b26\u53f7\u56de\u5f52\u6280\u672f\uff0c\u57fa\u4e8e\u5408\u6210\u6570\u636e\uff08\u6a21\u62df\u6709\u529f\u529f\u7387\u3001\u65e0\u529f\u529f\u7387\u548c\u7535\u538b\u53c2\u8003\u6270\u52a8\uff09\u751f\u6210\u7cfb\u7edf\u6a21\u578b\u3002", "result": "\u6df1\u5ea6\u7b26\u53f7\u56de\u5f52\u5728\u6355\u6349\u590d\u6742\u7cfb\u7edf\u52a8\u6001\u65b9\u9762\u66f4\u51c6\u786e\uff0c\u4f46\u8ba1\u7b97\u65f6\u95f4\u663e\u8457\u66f4\u957f\uff1b\u7a00\u758f\u8bc6\u522b\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u6df1\u5ea6\u7b26\u53f7\u56de\u5f52\u63d0\u4f9b\u9ad8\u4fdd\u771f\u5ea6\uff0c\u800c\u7a00\u758f\u8bc6\u522b\u5728\u5b9e\u65f6\u7535\u7f51\u5e94\u7528\u4e2d\u66f4\u5b9e\u7528\uff0c\u5728\u7cbe\u5ea6\u548c\u8ba1\u7b97\u65f6\u95f4\u4e4b\u95f4\u53d6\u5f97\u66f4\u597d\u5e73\u8861\u3002"}}
{"id": "2510.08959", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08959", "abs": "https://arxiv.org/abs/2510.08959", "authors": ["Jinxin Shi", "Zongsheng Cao", "Runmin Ma", "Yusong Hu", "Jie Zhou", "Xin Li", "Lei Bai", "Liang He", "Bo Zhang"], "title": "DualResearch: Entropy-Gated Dual-Graph Retrieval for Answer Reconstruction", "comment": "16 pages, 6 figures, 5 tables, Under Review", "summary": "The deep-research framework orchestrates external tools to perform complex,\nmulti-step scientific reasoning that exceeds the native limits of a single\nlarge language model. However, it still suffers from context pollution, weak\nevidentiary support, and brittle execution paths. To address these issues, we\npropose DualResearch, a retrieval and fusion framework that matches the\nepistemic structure of tool-intensive reasoning by jointly modeling two\ncomplementary graphs: a breadth semantic graph that encodes stable background\nknowledge, and a depth causal graph that captures execution provenance. Each\ngraph has a layer-native relevance function, seed-anchored semantic diffusion\nfor breadth, and causal-semantic path matching with reliability weighting for\ndepth. To reconcile their heterogeneity and query-dependent uncertainty,\nDualResearch converts per-layer path evidence into answer distributions and\nfuses them in log space via an entropy-gated rule with global calibration. The\nfusion up-weights the more certain channel and amplifies agreement. As a\ncomplement to deep-research systems, DualResearch compresses lengthy multi-tool\nexecution logs into a concise reasoning graph, and we show that it can\nreconstruct answers stably and effectively. On the scientific reasoning\nbenchmarks HLE and GPQA, DualResearch achieves competitive performance. Using\nlog files from the open-source system InternAgent, its accuracy improves by\n7.7% on HLE and 6.06% on GPQA.", "AI": {"tldr": "DualResearch\u662f\u4e00\u4e2a\u68c0\u7d22\u548c\u878d\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u5e7f\u5ea6\u8bed\u4e49\u56fe\u548c\u6df1\u5ea6\u56e0\u679c\u56fe\u6765\u89e3\u51b3\u6df1\u5ea6\u7814\u7a76\u6846\u67b6\u4e2d\u7684\u4e0a\u4e0b\u6587\u6c61\u67d3\u3001\u8bc1\u636e\u652f\u6301\u8584\u5f31\u548c\u6267\u884c\u8def\u5f84\u8106\u5f31\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u7814\u7a76\u6846\u67b6\u5728\u590d\u6742\u591a\u6b65\u79d1\u5b66\u63a8\u7406\u4e2d\u5b58\u5728\u7684\u4e0a\u4e0b\u6587\u6c61\u67d3\u3001\u8bc1\u636e\u652f\u6301\u8584\u5f31\u548c\u6267\u884c\u8def\u5f84\u8106\u5f31\u7b49\u5c40\u9650\u6027\u3002", "method": "\u8054\u5408\u5efa\u6a21\u4e24\u4e2a\u4e92\u8865\u56fe\uff1a\u7f16\u7801\u7a33\u5b9a\u80cc\u666f\u77e5\u8bc6\u7684\u5e7f\u5ea6\u8bed\u4e49\u56fe\u548c\u6355\u83b7\u6267\u884c\u6765\u6e90\u7684\u6df1\u5ea6\u56e0\u679c\u56fe\uff0c\u4f7f\u7528\u5c42\u539f\u751f\u76f8\u5173\u6027\u51fd\u6570\u3001\u79cd\u5b50\u951a\u5b9a\u8bed\u4e49\u6269\u6563\u548c\u56e0\u679c\u8bed\u4e49\u8def\u5f84\u5339\u914d\uff0c\u5e76\u901a\u8fc7\u71b5\u95e8\u63a7\u89c4\u5219\u878d\u5408\u7b54\u6848\u5206\u5e03\u3002", "result": "\u5728\u79d1\u5b66\u63a8\u7406\u57fa\u51c6HLE\u548cGPQA\u4e0a\u53d6\u5f97\u7ade\u4e89\u6027\u8868\u73b0\uff0c\u4f7f\u7528InternAgent\u65e5\u5fd7\u6587\u4ef6\u65f6\uff0cHLE\u51c6\u786e\u7387\u63d0\u53477.7%\uff0cGPQA\u51c6\u786e\u7387\u63d0\u53476.06%\u3002", "conclusion": "DualResearch\u80fd\u591f\u5c06\u5197\u957f\u7684\u591a\u5de5\u5177\u6267\u884c\u65e5\u5fd7\u538b\u7f29\u4e3a\u7b80\u6d01\u7684\u63a8\u7406\u56fe\uff0c\u7a33\u5b9a\u6709\u6548\u5730\u91cd\u5efa\u7b54\u6848\uff0c\u4f5c\u4e3a\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u7684\u8865\u5145\u3002"}}
{"id": "2510.09080", "categories": ["cs.RO", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.09080", "abs": "https://arxiv.org/abs/2510.09080", "authors": ["Shannon Liu", "Maria Teresa Parreira", "Wendy Ju"], "title": "Training Models to Detect Successive Robot Errors from Human Reactions", "comment": "Accepted to NERC '25", "summary": "As robots become more integrated into society, detecting robot errors is\nessential for effective human-robot interaction (HRI). When a robot fails\nrepeatedly, how can it know when to change its behavior? Humans naturally\nrespond to robot errors through verbal and nonverbal cues that intensify over\nsuccessive failures-from confusion and subtle speech changes to visible\nfrustration and impatience. While prior work shows that human reactions can\nindicate robot failures, few studies examine how these evolving responses\nreveal successive failures. This research uses machine learning to recognize\nstages of robot failure from human reactions. In a study with 26 participants\ninteracting with a robot that made repeated conversational errors, behavioral\nfeatures were extracted from video data to train models for individual users.\nThe best model achieved 93.5% accuracy for detecting errors and 84.1% for\nclassifying successive failures. Modeling the progression of human reactions\nenhances error detection and understanding of repeated interaction breakdowns\nin HRI.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u4ece\u4eba\u7c7b\u53cd\u5e94\u4e2d\u8bc6\u522b\u673a\u5668\u4eba\u8fde\u7eed\u5931\u8d25\u9636\u6bb5\uff0c\u901a\u8fc7\u63d0\u53d6\u89c6\u9891\u884c\u4e3a\u7279\u5f81\u8bad\u7ec3\u4e2a\u6027\u5316\u6a21\u578b\uff0c\u5728\u68c0\u6d4b\u9519\u8bef\u548c\u5206\u7c7b\u8fde\u7eed\u5931\u8d25\u65b9\u9762\u5206\u522b\u8fbe\u523093.5%\u548c84.1%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u968f\u7740\u673a\u5668\u4eba\u66f4\u6df1\u5165\u878d\u5165\u793e\u4f1a\uff0c\u68c0\u6d4b\u673a\u5668\u4eba\u9519\u8bef\u5bf9\u6709\u6548\u7684\u4eba\u673a\u4ea4\u4e92\u81f3\u5173\u91cd\u8981\u3002\u4eba\u7c7b\u5bf9\u673a\u5668\u4eba\u9519\u8bef\u7684\u53cd\u5e94\u4f1a\u968f\u7740\u8fde\u7eed\u5931\u8d25\u800c\u52a0\u5267\uff0c\u4ece\u56f0\u60d1\u5230\u660e\u663e\u6cae\u4e27\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5f88\u5c11\u63a2\u8ba8\u8fd9\u4e9b\u6f14\u5316\u53cd\u5e94\u5982\u4f55\u63ed\u793a\u8fde\u7eed\u5931\u8d25\u3002", "method": "\u572826\u540d\u53c2\u4e0e\u8005\u4e0e\u53cd\u590d\u51fa\u73b0\u5bf9\u8bdd\u9519\u8bef\u7684\u673a\u5668\u4eba\u4e92\u52a8\u7814\u7a76\u4e2d\uff0c\u4ece\u89c6\u9891\u6570\u636e\u4e2d\u63d0\u53d6\u884c\u4e3a\u7279\u5f81\uff0c\u4e3a\u4e2a\u4f53\u7528\u6237\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "result": "\u6700\u4f73\u6a21\u578b\u5728\u68c0\u6d4b\u9519\u8bef\u65b9\u9762\u8fbe\u523093.5%\u51c6\u786e\u7387\uff0c\u5728\u5206\u7c7b\u8fde\u7eed\u5931\u8d25\u65b9\u9762\u8fbe\u523084.1%\u51c6\u786e\u7387\u3002", "conclusion": "\u5bf9\u4eba\u7c7b\u53cd\u5e94\u8fdb\u5c55\u8fdb\u884c\u5efa\u6a21\u80fd\u591f\u589e\u5f3a\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\uff0c\u5e76\u66f4\u597d\u5730\u7406\u89e3\u4eba\u673a\u4ea4\u4e92\u4e2d\u91cd\u590d\u7684\u4ea4\u4e92\u4e2d\u65ad\u3002"}}
{"id": "2510.09420", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09420", "abs": "https://arxiv.org/abs/2510.09420", "authors": ["Han Hu", "Wenjie Wan", "Feiyu Chen", "Xiaoyu Liu", "Bo Yu", "Kequan Zhao"], "title": "Critical States Identiffcation in Power System via Lattice Partition and Its Application in Reliability Assessment", "comment": null, "summary": "With the increasing complexity of power systems,accurately identifying\ncritical states (the states corresponding to minimal cut sets) and assessing\nsystem reliability have become crucial tasks. In this paper, a mathematical\nlattice structure is employed to represent and partition the state space of\npower system. Based on this structure, a novel recursive method is proposed to\nefffciently identify critical states by leveraging lattice partitioning and\nOptimal Power Flow(OPF) calculations. This method not only enables the\nextension of failure system states,but also calculates the upper and lower\nbounds of the Loss of Load Probability (LOLP) in a progressively converging\nmanner. Compared to traditional reliability assessment methods such as State\nEnumeration (SE) and Monte Carlo Simulation (MCS), this approach offers greater\naccuracy and efffciency. Experiments conducted on the RBTS and RTS79 systems\ndemonstrate that the proposed method accurately identiffes all critical states\nup to a preset order, which are high-risk states. The contribution of these\ncritical states to LOLP highlights their signiffcance in the system. Moreover,\nthe proposed method achieves the analytical value with signiffcantly fewer OPF\ncalculations in RBTS system, reaching acceptable precision of LOLP up to 100\ntimes faster than SE in both the RBTS and RTS systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u5b66\u683c\u7ed3\u6784\u7684\u9012\u5f52\u65b9\u6cd5\uff0c\u7528\u4e8e\u9ad8\u6548\u8bc6\u522b\u7535\u529b\u7cfb\u7edf\u4e34\u754c\u72b6\u6001\u5e76\u8bc4\u4f30\u7cfb\u7edf\u53ef\u9760\u6027\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8\u7cbe\u5ea6\u548c\u6548\u7387\u3002", "motivation": "\u968f\u7740\u7535\u529b\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\uff0c\u51c6\u786e\u8bc6\u522b\u4e34\u754c\u72b6\u6001\uff08\u5bf9\u5e94\u6700\u5c0f\u5272\u96c6\u7684\u72b6\u6001\uff09\u548c\u8bc4\u4f30\u7cfb\u7edf\u53ef\u9760\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u6570\u5b66\u683c\u7ed3\u6784\u8868\u793a\u548c\u5212\u5206\u7535\u529b\u7cfb\u7edf\u72b6\u6001\u7a7a\u95f4\uff0c\u57fa\u4e8e\u683c\u5212\u5206\u548c\u6700\u4f18\u6f6e\u6d41\u8ba1\u7b97\u63d0\u51fa\u9012\u5f52\u65b9\u6cd5\u8bc6\u522b\u4e34\u754c\u72b6\u6001\uff0c\u5e76\u6e10\u8fdb\u6536\u655b\u5730\u8ba1\u7b97\u5931\u8d1f\u8377\u6982\u7387\u7684\u4e0a\u4e0b\u754c\u3002", "result": "\u5728RBTS\u548cRTS79\u7cfb\u7edf\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u51c6\u786e\u8bc6\u522b\u9884\u8bbe\u9636\u6570\u7684\u6240\u6709\u4e34\u754c\u72b6\u6001\uff0c\u5728RBTS\u7cfb\u7edf\u4e2d\u7528\u663e\u8457\u66f4\u5c11\u7684\u6700\u4f18\u6f6e\u6d41\u8ba1\u7b97\u8fbe\u5230\u5206\u6790\u503c\uff0c\u5728RBTS\u548cRTS\u7cfb\u7edf\u4e2d\u6bd4\u72b6\u6001\u679a\u4e3e\u6cd5\u5feb100\u500d\u8fbe\u5230\u53ef\u63a5\u53d7\u7684\u5931\u8d1f\u8377\u6982\u7387\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u9ad8\u6548\u8bc6\u522b\u9ad8\u98ce\u9669\u4e34\u754c\u72b6\u6001\uff0c\u8fd9\u4e9b\u72b6\u6001\u5bf9\u5931\u8d1f\u8377\u6982\u7387\u6709\u663e\u8457\u8d21\u732e\uff0c\u76f8\u6bd4\u4f20\u7edf\u53ef\u9760\u6027\u8bc4\u4f30\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2510.08966", "categories": ["cs.AI", "cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.08966", "abs": "https://arxiv.org/abs/2510.08966", "authors": ["Ruitong Liu", "Yan Wen", "Te Sun", "Yunjia Wu", "Pingyang Huang", "Zihang Yu", "Siyuan Li"], "title": "Semantic-Condition Tuning: Fusing Graph Context with Large Language Models for Knowledge Graph Completion", "comment": "11 pages, 3 figures, conference", "summary": "Fusing Knowledge Graphs with Large Language Models is crucial for\nknowledge-intensive tasks like knowledge graph completion. The prevailing\nparadigm, prefix-tuning, simply concatenates knowledge embeddings with text\ninputs. However, this shallow fusion overlooks the rich relational semantics\nwithin KGs and imposes a significant implicit reasoning burden on the LLM to\ncorrelate the prefix with the text. To address these, we propose\nSemantic-condition Tuning (SCT), a new knowledge injection paradigm comprising\ntwo key modules. First, a Semantic Graph Module employs a Graph Neural Network\nto extract a context-aware semantic condition from the local graph\nneighborhood, guided by knowledge-enhanced relations. Subsequently, this\ncondition is passed to a Condition-Adaptive Fusion Module, which, in turn,\nadaptively modulates the textual embedding via two parameterized projectors,\nenabling a deep, feature-wise, and knowledge-aware interaction. The resulting\npre-fused embedding is then fed into the LLM for fine-tuning. Extensive\nexperiments on knowledge graph benchmarks demonstrate that SCT significantly\noutperforms prefix-tuning and other strong baselines. Our analysis confirms\nthat by modulating the input representation with semantic graph context before\nLLM inference, SCT provides a more direct and potent signal, enabling more\naccurate and robust knowledge reasoning.", "AI": {"tldr": "\u63d0\u51fa\u8bed\u4e49\u6761\u4ef6\u8c03\u4f18(SCT)\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u63d0\u53d6\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u8bed\u4e49\u6761\u4ef6\uff0c\u6df1\u5ea6\u878d\u5408\u77e5\u8bc6\u56fe\u8c31\u4e0e\u8bed\u8a00\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u77e5\u8bc6\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u524d\u7f00\u8c03\u4f18\u65b9\u6cd5\u53ea\u662f\u7b80\u5355\u62fc\u63a5\u77e5\u8bc6\u5d4c\u5165\u548c\u6587\u672c\u8f93\u5165\uff0c\u5ffd\u7565\u4e86\u77e5\u8bc6\u56fe\u8c31\u4e2d\u4e30\u5bcc\u7684\u5173\u7cfb\u8bed\u4e49\uff0c\u7ed9\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u4e86\u6c89\u91cd\u7684\u9690\u5f0f\u63a8\u7406\u8d1f\u62c5\u3002", "method": "SCT\u5305\u542b\u4e24\u4e2a\u5173\u952e\u6a21\u5757\uff1a\u8bed\u4e49\u56fe\u6a21\u5757\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u4ece\u5c40\u90e8\u56fe\u90bb\u57df\u63d0\u53d6\u4e0a\u4e0b\u6587\u611f\u77e5\u8bed\u4e49\u6761\u4ef6\uff1b\u6761\u4ef6\u81ea\u9002\u5e94\u878d\u5408\u6a21\u5757\u901a\u8fc7\u53c2\u6570\u5316\u6295\u5f71\u5668\u81ea\u9002\u5e94\u8c03\u8282\u6587\u672c\u5d4c\u5165\uff0c\u5b9e\u73b0\u6df1\u5ea6\u7279\u5f81\u7ea7\u77e5\u8bc6\u611f\u77e5\u4ea4\u4e92\u3002", "result": "\u5728\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSCT\u663e\u8457\u4f18\u4e8e\u524d\u7f00\u8c03\u4f18\u548c\u5176\u4ed6\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5728\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u524d\u7528\u8bed\u4e49\u56fe\u4e0a\u4e0b\u6587\u8c03\u8282\u8f93\u5165\u8868\u793a\uff0cSCT\u63d0\u4f9b\u4e86\u66f4\u76f4\u63a5\u6709\u6548\u7684\u4fe1\u53f7\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u548c\u9c81\u68d2\u7684\u77e5\u8bc6\u63a8\u7406\u3002"}}
{"id": "2510.09089", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09089", "abs": "https://arxiv.org/abs/2510.09089", "authors": ["Jikai Wang", "Yunqi Cheng", "Kezhi Wang", "Zonghai Chen"], "title": "Robust Visual Teach-and-Repeat Navigation with Flexible Topo-metric Graph Map Representation", "comment": null, "summary": "Visual Teach-and-Repeat Navigation is a direct solution for mobile robot to\nbe deployed in unknown environments. However, robust trajectory repeat\nnavigation still remains challenged due to environmental changing and dynamic\nobjects. In this paper, we propose a novel visual teach-and-repeat navigation\nsystem, which consists of a flexible map representation, robust map matching\nand a map-less local navigation module. During the teaching process, the\nrecorded keyframes are formulated as a topo-metric graph and each node can be\nfurther extended to save new observations. Such representation also alleviates\nthe requirement of globally consistent mapping. To enhance the place\nrecognition performance during repeating process, instead of using\nframe-to-frame matching, we firstly implement keyframe clustering to aggregate\nsimilar connected keyframes into local map and perform place recognition based\non visual frame-tolocal map matching strategy. To promote the local goal\npersistent tracking performance, a long-term goal management algorithm is\nconstructed, which can avoid the robot getting lost due to environmental\nchanges or obstacle occlusion. To achieve the goal without map, a local\ntrajectory-control candidate optimization algorithm is proposed. Extensively\nexperiments are conducted on our mobile platform. The results demonstrate that\nour system is superior to the baselines in terms of robustness and\neffectiveness.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u89c6\u89c9\u6559-\u590d\u5bfc\u822a\u7cfb\u7edf\uff0c\u901a\u8fc7\u7075\u6d3b\u7684\u62d3\u6251\u5ea6\u91cf\u56fe\u8868\u793a\u3001\u9c81\u68d2\u7684\u5730\u56fe\u5339\u914d\u548c\u65e0\u5730\u56fe\u5c40\u90e8\u5bfc\u822a\u6a21\u5757\uff0c\u89e3\u51b3\u4e86\u73af\u5883\u53d8\u5316\u548c\u52a8\u6001\u7269\u4f53\u5bf9\u8f68\u8ff9\u91cd\u590d\u5bfc\u822a\u7684\u6311\u6218\u3002", "motivation": "\u89c6\u89c9\u6559-\u590d\u5bfc\u822a\u662f\u79fb\u52a8\u673a\u5668\u4eba\u5728\u672a\u77e5\u73af\u5883\u4e2d\u90e8\u7f72\u7684\u76f4\u63a5\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u7531\u4e8e\u73af\u5883\u53d8\u5316\u548c\u52a8\u6001\u7269\u4f53\u7684\u5b58\u5728\uff0c\u9c81\u68d2\u7684\u8f68\u8ff9\u91cd\u590d\u5bfc\u822a\u4ecd\u7136\u9762\u4e34\u6311\u6218\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a1\uff09\u7075\u6d3b\u7684\u62d3\u6251\u5ea6\u91cf\u56fe\u8868\u793a\uff0c\u652f\u6301\u5173\u952e\u5e27\u6269\u5c55\uff1b2\uff09\u57fa\u4e8e\u5173\u952e\u5e27\u805a\u7c7b\u7684\u89c6\u89c9\u5e27\u5230\u5c40\u90e8\u5730\u56fe\u5339\u914d\u7b56\u7565\uff1b3\uff09\u957f\u671f\u76ee\u6807\u7ba1\u7406\u7b97\u6cd5\u548c\u65e0\u5730\u56fe\u5c40\u90e8\u8f68\u8ff9\u63a7\u5236\u4f18\u5316\u7b97\u6cd5\u3002", "result": "\u5728\u79fb\u52a8\u5e73\u53f0\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u7cfb\u7edf\u5728\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u89c6\u89c9\u6559-\u590d\u5bfc\u822a\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u73af\u5883\u53d8\u5316\u548c\u52a8\u6001\u969c\u788d\uff0c\u5b9e\u73b0\u9c81\u68d2\u7684\u8f68\u8ff9\u91cd\u590d\u5bfc\u822a\u3002"}}
{"id": "2510.09445", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.09445", "abs": "https://arxiv.org/abs/2510.09445", "authors": ["Ashkan Sebghati", "S. Hassan HosseinNia"], "title": "Robust reset control design for piezo-actuated nano-positioner in presence of hysteresis nonlinearity", "comment": null, "summary": "In this paper, a robust nonlinear control scheme is designed for the motion\ncontrol of a class of piezo-actuated nano-positioning systems using\nfrequency-domain analysis. The hysteresis, the nonlinearity in the\npiezoelectric material, degrades the precision in tracking references with high\nfrequency contents and different travel ranges. The hysteresis compensation by\nthe inverse model, as the state-of-the-art solution, is not reliable alone.\nTherefore, a control framework with robustness against the remaining\nnonlinearity is needed. It is shown that there is an unavoidable limitation in\nrobust linear control design to improve the performance. A robust control\nmethodology based on a complex-order element is established to relax the\nlimitation. Then, a constant-in-gain-lead-in-phase (CgLp) reset controller is\nutilized to realize the complex-order control. The control design is based on\nthe sinusoidal input describing function (SIDF) and the higher-order SIDF\n(HOSIDF) tools. A constrained optimization problem is provided to tune the\ncontrol parameters. The achieved improvements by the CgLp control is validated\nby the simulation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9891\u57df\u5206\u6790\u7684\u9c81\u68d2\u975e\u7ebf\u6027\u63a7\u5236\u65b9\u6848\uff0c\u7528\u4e8e\u538b\u7535\u9a71\u52a8\u7eb3\u7c73\u5b9a\u4f4d\u7cfb\u7edf\u7684\u8fd0\u52a8\u63a7\u5236\uff0c\u901a\u8fc7\u590d\u6742\u9636\u5143\u7d20\u548c\u91cd\u7f6e\u63a7\u5236\u5668\u6765\u8865\u507f\u8fdf\u6ede\u975e\u7ebf\u6027\u5e76\u63d0\u9ad8\u8ddf\u8e2a\u6027\u80fd\u3002", "motivation": "\u538b\u7535\u6750\u6599\u7684\u8fdf\u6ede\u975e\u7ebf\u6027\u4f1a\u964d\u4f4e\u9ad8\u9891\u53c2\u8003\u4fe1\u53f7\u8ddf\u8e2a\u7684\u7cbe\u5ea6\uff0c\u4ec5\u4f7f\u7528\u9006\u6a21\u578b\u8865\u507f\u4e0d\u591f\u53ef\u9760\uff0c\u9700\u8981\u5177\u6709\u9c81\u68d2\u6027\u7684\u63a7\u5236\u6846\u67b6\u6765\u5e94\u5bf9\u5269\u4f59\u975e\u7ebf\u6027\u3002", "method": "\u5efa\u7acb\u4e86\u57fa\u4e8e\u590d\u6742\u9636\u5143\u7d20\u7684\u9c81\u68d2\u63a7\u5236\u65b9\u6cd5\uff0c\u4f7f\u7528\u6052\u5b9a\u589e\u76ca\u8d85\u524d\u76f8\u4f4d(CgLp)\u91cd\u7f6e\u63a7\u5236\u5668\u5b9e\u73b0\u590d\u6742\u9636\u63a7\u5236\uff0c\u57fa\u4e8e\u6b63\u5f26\u8f93\u5165\u63cf\u8ff0\u51fd\u6570(SIDF)\u548c\u9ad8\u9636SIDF\u5de5\u5177\u8fdb\u884c\u8bbe\u8ba1\uff0c\u5e76\u901a\u8fc7\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u8c03\u6574\u63a7\u5236\u53c2\u6570\u3002", "result": "\u4eff\u771f\u9a8c\u8bc1\u4e86CgLp\u63a7\u5236\u5728\u63d0\u9ad8\u6027\u80fd\u65b9\u9762\u7684\u6539\u8fdb\u6548\u679c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u590d\u6742\u9636\u63a7\u5236\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u653e\u677e\u7ebf\u6027\u9c81\u68d2\u63a7\u5236\u8bbe\u8ba1\u7684\u9650\u5236\uff0c\u4e3a\u538b\u7535\u9a71\u52a8\u7eb3\u7c73\u5b9a\u4f4d\u7cfb\u7edf\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u8fdf\u6ede\u8865\u507f\u548c\u8ddf\u8e2a\u6027\u80fd\u3002"}}
{"id": "2510.08987", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08987", "abs": "https://arxiv.org/abs/2510.08987", "authors": ["Qixiang Yin", "Huanjin Yao", "Jianghao Chen", "Jiaxing Huang", "Zhicheng Zhao", "Fei Su"], "title": "Tiny-R1V: Lightweight Multimodal Unified Reasoning Model via Model Merging", "comment": "Technical report, Code will be available at\n  https://github.com/buptyqx/Tiny-R1V", "summary": "Although Multimodal Large Language Models (MLLMs) have demonstrated\nremarkable capabilities across diverse tasks, they encounter numerous\nchallenges in terms of reasoning efficiency, such as large model size,\noverthinking, and compromised accuracy in lightweight scenarios. However,\nresearch on the reasoning capabilities of lightweight MLLMs is quite lacking.\nTo this end, we propose Tiny-R1V, a novel lightweight 3B model that achieves\nfaster inference and higher accuracy via a two-stage optimization, while\nunifying multimodal reasoning across multiple tasks and using fewer tokens. In\nthe first stage, Tiny-R1V introduces Length-Informed Relative Policy\nOptimization (LIPO), a novel reinforcement learning method, to train each\nreasoning model. The LIPO is designed to dynamically adjusts advantages of\nresponses within groups, that is, by prioritizing concise yet high-quality\nresponses to encourage the generation of shorter and more accurate response. In\nthe second stage, we propose Adaptive Model Merging (AMM), a training-free\nmodel merging method that merges multiple specialist models into a unified\narchitecture. Specifically, AMM adaptively adjusts the weights of task vectors\nand robustly optimizes the merged vectors via a novel gradient projection\nregularization loss function, thus mitigating redundant conflicts between them.\nExtensive evaluations on ten widely-used reasoning benchmarks covering\nmathematics, structured data (charts, tables, documents), OCR, and general\ncapabilities showcase the superior performance of Tiny-R1V, enabling\nlightweight models to excel in diverse multimodal reasoning tasks.", "AI": {"tldr": "Tiny-R1V\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea73B\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u4f18\u5316\u5b9e\u73b0\u66f4\u5feb\u63a8\u7406\u548c\u66f4\u9ad8\u51c6\u786e\u7387\uff0c\u7edf\u4e00\u4e86\u591a\u4efb\u52a1\u591a\u6a21\u6001\u63a8\u7406\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u6548\u7387\u65b9\u9762\u9762\u4e34\u6a21\u578b\u5c3a\u5bf8\u5927\u3001\u8fc7\u5ea6\u601d\u8003\u3001\u8f7b\u91cf\u7ea7\u573a\u666f\u51c6\u786e\u7387\u4f4e\u7b49\u6311\u6218\uff0c\u800c\u8f7b\u91cf\u7ea7MLLMs\u7684\u63a8\u7406\u80fd\u529b\u7814\u7a76\u8f83\u4e3a\u7f3a\u4e4f\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u4f18\u5316\uff1a\u7b2c\u4e00\u9636\u6bb5\u5f15\u5165LIPO\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u52a8\u6001\u8c03\u6574\u54cd\u5e94\u4f18\u52bf\uff0c\u9f13\u52b1\u751f\u6210\u66f4\u77ed\u66f4\u51c6\u786e\u7684\u54cd\u5e94\uff1b\u7b2c\u4e8c\u9636\u6bb5\u63d0\u51faAMM\u6a21\u578b\u878d\u5408\u65b9\u6cd5\uff0c\u81ea\u9002\u5e94\u8c03\u6574\u4efb\u52a1\u5411\u91cf\u6743\u91cd\uff0c\u901a\u8fc7\u68af\u5ea6\u6295\u5f71\u6b63\u5219\u5316\u635f\u5931\u51fd\u6570\u4f18\u5316\u5408\u5e76\u5411\u91cf\u3002", "result": "\u5728\u5341\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff08\u6570\u5b66\u3001\u7ed3\u6784\u5316\u6570\u636e\u3001OCR\u548c\u901a\u7528\u80fd\u529b\uff09\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4f7f\u8f7b\u91cf\u7ea7\u6a21\u578b\u5728\u591a\u6837\u5316\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "Tiny-R1V\u901a\u8fc7\u521b\u65b0\u7684\u4e24\u9636\u6bb5\u4f18\u5316\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u8f7b\u91cf\u7ea7\u591a\u6a21\u6001\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u8f7b\u91cf\u5316\u7684\u540c\u65f6\u63d0\u5347\u4e86\u63a8\u7406\u51c6\u786e\u7387\u3002"}}
{"id": "2510.09096", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09096", "abs": "https://arxiv.org/abs/2510.09096", "authors": ["Xinhu Li", "Ayush Jain", "Zhaojing Yang", "Yigit Korkmaz", "Erdem B\u0131y\u0131k"], "title": "When a Robot is More Capable than a Human: Learning from Constrained Demonstrators", "comment": null, "summary": "Learning from demonstrations enables experts to teach robots complex tasks\nusing interfaces such as kinesthetic teaching, joystick control, and\nsim-to-real transfer. However, these interfaces often constrain the expert's\nability to demonstrate optimal behavior due to indirect control, setup\nrestrictions, and hardware safety. For example, a joystick can move a robotic\narm only in a 2D plane, even though the robot operates in a higher-dimensional\nspace. As a result, the demonstrations collected by constrained experts lead to\nsuboptimal performance of the learned policies. This raises a key question: Can\na robot learn a better policy than the one demonstrated by a constrained\nexpert? We address this by allowing the agent to go beyond direct imitation of\nexpert actions and explore shorter and more efficient trajectories. We use the\ndemonstrations to infer a state-only reward signal that measures task progress,\nand self-label reward for unknown states using temporal interpolation. Our\napproach outperforms common imitation learning in both sample efficiency and\ntask completion time. On a real WidowX robotic arm, it completes the task in 12\nseconds, 10x faster than behavioral cloning, as shown in real-robot videos on\nhttps://sites.google.com/view/constrainedexpert .", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u53d7\u9650\u4e13\u5bb6\u6f14\u793a\u4e2d\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u63a8\u65ad\u72b6\u6001\u5956\u52b1\u4fe1\u53f7\u548c\u81ea\u6807\u6ce8\u672a\u77e5\u72b6\u6001\u5956\u52b1\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u5b66\u4e60\u6bd4\u4e13\u5bb6\u6f14\u793a\u66f4\u4f18\u7684\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u6f14\u793a\u63a5\u53e3\uff08\u5982\u9065\u64cd\u4f5c\u3001\u6a21\u62df\u5230\u771f\u5b9e\u8fc1\u79fb\uff09\u9650\u5236\u4e86\u4e13\u5bb6\u5c55\u793a\u6700\u4f18\u884c\u4e3a\u7684\u80fd\u529b\uff0c\u5bfc\u81f4\u6536\u96c6\u7684\u6f14\u793a\u6570\u636e\u8d28\u91cf\u4e0d\u9ad8\uff0c\u5b66\u4e60\u5230\u7684\u7b56\u7565\u6027\u80fd\u6b20\u4f73\u3002", "method": "\u4f7f\u7528\u6f14\u793a\u6570\u636e\u63a8\u65ad\u4ec5\u57fa\u4e8e\u72b6\u6001\u7684\u4efb\u52a1\u8fdb\u5ea6\u5956\u52b1\u4fe1\u53f7\uff0c\u901a\u8fc7\u65f6\u95f4\u63d2\u503c\u4e3a\u672a\u77e5\u72b6\u6001\u81ea\u6807\u6ce8\u5956\u52b1\uff0c\u8ba9\u667a\u80fd\u4f53\u63a2\u7d22\u6bd4\u4e13\u5bb6\u6f14\u793a\u66f4\u77ed\u66f4\u9ad8\u6548\u7684\u8f68\u8ff9\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6837\u672c\u6548\u7387\u548c\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u4e0a\u90fd\u4f18\u4e8e\u5e38\u89c1\u7684\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u771f\u5b9eWidowX\u673a\u68b0\u81c2\u4e0a\u5b8c\u6210\u4efb\u52a1\u4ec5\u970012\u79d2\uff0c\u6bd4\u884c\u4e3a\u514b\u9686\u5feb10\u500d\u3002", "conclusion": "\u901a\u8fc7\u8d85\u8d8a\u76f4\u63a5\u6a21\u4eff\u4e13\u5bb6\u52a8\u4f5c\uff0c\u5229\u7528\u72b6\u6001\u5956\u52b1\u4fe1\u53f7\u548c\u65f6\u95f4\u63d2\u503c\uff0c\u673a\u5668\u4eba\u80fd\u591f\u4ece\u53d7\u9650\u4e13\u5bb6\u6f14\u793a\u4e2d\u5b66\u4e60\u5230\u6bd4\u4e13\u5bb6\u672c\u8eab\u66f4\u4f18\u7684\u7b56\u7565\u3002"}}
{"id": "2510.09011", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.09011", "abs": "https://arxiv.org/abs/2510.09011", "authors": ["Yincen Qu", "Huan Xiao", "Feng Li", "Hui Zhou", "Xiangying Dai"], "title": "TripScore: Benchmarking and rewarding real-world travel planning with fine-grained evaluation", "comment": null, "summary": "Travel planning is a valuable yet complex task that poses significant\nchallenges even for advanced large language models (LLMs). While recent\nbenchmarks have advanced in evaluating LLMs' planning capabilities, they often\nfall short in evaluating feasibility, reliability, and engagement of travel\nplans. We introduce a comprehensive benchmark for travel planning that unifies\nfine-grained criteria into a single reward, enabling direct comparison of plan\nquality and seamless integration with reinforcement learning (RL). Our\nevaluator achieves moderate agreement with travel-expert annotations (60.75\\%)\nand outperforms multiple LLM-as-judge baselines. We further release a\nlarge-scale dataset of 4,870 queries including 219 real-world, free-form\nrequests for generalization to authentic user intent. Using this benchmark, we\nconduct extensive experiments across diverse methods and LLMs, including\ntest-time computation, neuro-symbolic approaches, supervised fine-tuning, and\nRL via GRPO. Across base models, RL generally improves itinerary feasibility\nover prompt-only and supervised baselines, yielding higher unified reward\nscores.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u65c5\u884c\u89c4\u5212\u57fa\u51c6\uff0c\u901a\u8fc7\u5355\u4e00\u5956\u52b1\u6574\u5408\u7ec6\u7c92\u5ea6\u6807\u51c6\uff0c\u652f\u6301\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86RL\u65b9\u6cd5\u5728\u63d0\u9ad8\u884c\u7a0b\u53ef\u884c\u6027\u65b9\u9762\u7684\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5728\u8bc4\u4f30LLMs\u7684\u65c5\u884c\u89c4\u5212\u80fd\u529b\u65f6\uff0c\u5f80\u5f80\u5ffd\u89c6\u53ef\u884c\u6027\u3001\u53ef\u9760\u6027\u548c\u53c2\u4e0e\u5ea6\u7b49\u5173\u952e\u7ef4\u5ea6\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u6784\u5efa\u5305\u542b4,870\u4e2a\u67e5\u8be2\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u7edf\u4e00\u5956\u52b1\u8bc4\u4f30\u5668\uff0c\u901a\u8fc7GRPO\u7b49\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u4e0e\u591a\u79cd\u57fa\u7ebf\u65b9\u6cd5\u5bf9\u6bd4\u3002", "result": "\u8bc4\u4f30\u5668\u4e0e\u65c5\u884c\u4e13\u5bb6\u6807\u6ce8\u8fbe\u523060.75%\u7684\u4e00\u81f4\u6027\uff0cRL\u65b9\u6cd5\u76f8\u6bd4\u63d0\u793a\u5de5\u7a0b\u548c\u76d1\u7763\u5b66\u4e60\u80fd\u663e\u8457\u63d0\u9ad8\u884c\u7a0b\u7684\u53ef\u884c\u6027\u548c\u7edf\u4e00\u5956\u52b1\u5206\u6570\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u51c6\u80fd\u6709\u6548\u8bc4\u4f30\u65c5\u884c\u89c4\u5212\u8d28\u91cf\uff0cRL\u65b9\u6cd5\u5728\u6539\u5584\u884c\u7a0b\u53ef\u884c\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3aLLMs\u7684\u65c5\u884c\u89c4\u5212\u80fd\u529b\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2510.09188", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.09188", "abs": "https://arxiv.org/abs/2510.09188", "authors": ["Zihao Mao", "Yunheng Wang", "Yunting Ji", "Yi Yang", "Wenjie Song"], "title": "Decentralized Multi-Robot Relative Navigation in Unknown, Structurally Constrained Environments under Limited Communication", "comment": null, "summary": "Multi-robot navigation in unknown, structurally constrained, and GPS-denied\nenvironments presents a fundamental trade-off between global strategic\nforesight and local tactical agility, particularly under limited communication.\nCentralized methods achieve global optimality but suffer from high\ncommunication overhead, while distributed methods are efficient but lack the\nbroader awareness to avoid deadlocks and topological traps. To address this, we\npropose a fully decentralized, hierarchical relative navigation framework that\nachieves both strategic foresight and tactical agility without a unified\ncoordinate system. At the strategic layer, robots build and exchange\nlightweight topological maps upon opportunistic encounters. This process\nfosters an emergent global awareness, enabling the planning of efficient,\ntrap-avoiding routes at an abstract level. This high-level plan then inspires\nthe tactical layer, which operates on local metric information. Here, a\nsampling-based escape point strategy resolves dense spatio-temporal conflicts\nby generating dynamically feasible trajectories in real time, concurrently\nsatisfying tight environmental and kinodynamic constraints. Extensive\nsimulations and real-world experiments demonstrate that our system\nsignificantly outperforms in success rate and efficiency, especially in\ncommunication-limited environments with complex topological structures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u7684\u5206\u5c42\u76f8\u5bf9\u5bfc\u822a\u6846\u67b6\uff0c\u5728\u672a\u77e5\u3001\u7ed3\u6784\u53d7\u9650\u4e14\u65e0GPS\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u6218\u7565\u8fdc\u89c1\u548c\u6218\u672f\u654f\u6377\u6027\uff0c\u65e0\u9700\u7edf\u4e00\u5750\u6807\u7cfb\u3002", "motivation": "\u89e3\u51b3\u591a\u673a\u5668\u4eba\u5bfc\u822a\u4e2d\u5168\u5c40\u6218\u7565\u8fdc\u89c1\u4e0e\u5c40\u90e8\u6218\u672f\u654f\u6377\u6027\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\uff0c\u7279\u522b\u662f\u5728\u901a\u4fe1\u53d7\u9650\u73af\u5883\u4e0b\u3002\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u901a\u4fe1\u5f00\u9500\u5927\uff0c\u5206\u5e03\u5f0f\u65b9\u6cd5\u7f3a\u4e4f\u5168\u5c40\u610f\u8bc6\u5bb9\u6613\u9677\u5165\u6b7b\u9501\u548c\u62d3\u6251\u9677\u9631\u3002", "method": "\u5206\u5c42\u6846\u67b6\uff1a\u6218\u7565\u5c42\u901a\u8fc7\u673a\u4f1a\u6027\u76f8\u9047\u6784\u5efa\u548c\u4ea4\u6362\u8f7b\u91cf\u7ea7\u62d3\u6251\u5730\u56fe\uff0c\u57f9\u517b\u6d8c\u73b0\u7684\u5168\u5c40\u610f\u8bc6\uff1b\u6218\u672f\u5c42\u57fa\u4e8e\u5c40\u90e8\u5ea6\u91cf\u4fe1\u606f\uff0c\u91c7\u7528\u57fa\u4e8e\u91c7\u6837\u7684\u9003\u9038\u70b9\u7b56\u7565\u5b9e\u65f6\u751f\u6210\u52a8\u6001\u53ef\u884c\u8f68\u8ff9\u3002", "result": "\u5e7f\u6cdb\u7684\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u6210\u529f\u7387\u548c\u5de5\u4f5c\u6548\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u901a\u4fe1\u53d7\u9650\u548c\u62d3\u6251\u7ed3\u6784\u590d\u6742\u7684\u73af\u5883\u4e2d\u3002", "conclusion": "\u8be5\u53bb\u4e2d\u5fc3\u5316\u5206\u5c42\u76f8\u5bf9\u5bfc\u822a\u6846\u67b6\u6210\u529f\u5e73\u8861\u4e86\u6218\u7565\u8fdc\u89c1\u548c\u6218\u672f\u654f\u6377\u6027\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u591a\u673a\u5668\u4eba\u5bfc\u822a\uff0c\u65e0\u9700\u7edf\u4e00\u5750\u6807\u7cfb\u6216\u9ad8\u901a\u4fe1\u5f00\u9500\u3002"}}
{"id": "2510.09021", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09021", "abs": "https://arxiv.org/abs/2510.09021", "authors": ["Hamed Mahdavi", "Pouria Mahdavinia", "Samira Malek", "Pegah Mohammadipour", "Alireza Hashemi", "Majid Daliri", "Alireza Farhadi", "Amir Khasahmadi", "Niloofar Mireshghallah", "Vasant Honavar"], "title": "RefGrader: Automated Grading of Mathematical Competition Proofs using Agentic Workflows", "comment": null, "summary": "State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based\nOlympiad problems to solving most of the IMO 2025 problems, with leading\nsystems reportedly handling 5 of 6 problems. Given this progress, we assess how\nwell these models can grade proofs: detecting errors, judging their severity,\nand assigning fair scores beyond binary correctness. We study proof-analysis\ncapabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we\ngrade on a 1-4 scale with detailed error annotations, and on MathArena solution\nsets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models\ncan reliably flag incorrect (including subtly incorrect) solutions but exhibit\ncalibration gaps in how partial credit is assigned. To address this, we\nintroduce agentic workflows that extract and analyze reference solutions and\nautomatically derive problem-specific rubrics for a multi-step grading process.\nWe instantiate and compare different design choices for the grading workflows,\nand evaluate their trade-offs. Across our annotated corpus and MathArena, our\nproposed workflows achieve higher agreement with human grades and more\nconsistent handling of partial credit across metrics. We release all code,\ndata, and prompts/logs to facilitate future research.", "AI": {"tldr": "\u8bc4\u4f30LLMs\u5728\u6570\u5b66\u8bc1\u660e\u8bc4\u5206\u65b9\u9762\u7684\u80fd\u529b\uff0c\u63d0\u51fa\u57fa\u4e8e\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\u7684\u8bc4\u5206\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e0e\u4eba\u5de5\u8bc4\u5206\u7684\u4e00\u81f4\u6027\u548c\u90e8\u5206\u5b66\u5206\u5904\u7406\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740LLMs\u5728\u89e3\u51b3\u5965\u6797\u5339\u514b\u6570\u5b66\u95ee\u9898\u65b9\u9762\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u9700\u8981\u8bc4\u4f30\u5b83\u4eec\u80fd\u5426\u51c6\u786e\u8bc4\u5206\u8bc1\u660e\uff0c\u5305\u62ec\u68c0\u6d4b\u9519\u8bef\u3001\u5224\u65ad\u4e25\u91cd\u7a0b\u5ea6\u4ee5\u53ca\u5206\u914d\u516c\u5e73\u5206\u6570\u3002", "method": "\u4f7f\u752890\u4e2aGemini 2.5 Pro\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\u548cMathArena\u7684IMO/USAMO 2025\u89e3\u51b3\u65b9\u6848\u96c6\uff0c\u5f15\u5165\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\u63d0\u53d6\u53c2\u8003\u89e3\u51b3\u65b9\u6848\u5e76\u81ea\u52a8\u63a8\u5bfc\u95ee\u9898\u7279\u5b9a\u7684\u8bc4\u5206\u6807\u51c6\uff0c\u8fdb\u884c\u591a\u6b65\u9aa4\u8bc4\u5206\u8fc7\u7a0b\u3002", "result": "\u6a21\u578b\u80fd\u591f\u53ef\u9760\u5730\u6807\u8bb0\u9519\u8bef\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5728\u5206\u914d\u90e8\u5206\u5b66\u5206\u65b9\u9762\u5b58\u5728\u6821\u51c6\u5dee\u8ddd\u3002\u63d0\u51fa\u7684\u5de5\u4f5c\u6d41\u7a0b\u5728\u6ce8\u91ca\u8bed\u6599\u5e93\u548cMathArena\u4e2d\u5b9e\u73b0\u4e86\u4e0e\u4eba\u5de5\u8bc4\u5206\u66f4\u9ad8\u7684\u4e00\u81f4\u6027\u548c\u66f4\u4e00\u81f4\u7684\u90e8\u5206\u5b66\u5206\u5904\u7406\u3002", "conclusion": "\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\u663e\u8457\u63d0\u9ad8\u4e86LLMs\u5728\u6570\u5b66\u8bc1\u660e\u8bc4\u5206\u65b9\u9762\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u4ee3\u7801\u3001\u6570\u636e\u548c\u63d0\u793a/\u65e5\u5fd7\u3002"}}
{"id": "2510.09204", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09204", "abs": "https://arxiv.org/abs/2510.09204", "authors": ["Simon Idoko", "Arun Kumar Singh"], "title": "Flow-Opt: Scalable Centralized Multi-Robot Trajectory Optimization with Flow Matching and Differentiable Optimization", "comment": null, "summary": "Centralized trajectory optimization in the joint space of multiple robots\nallows access to a larger feasible space that can result in smoother\ntrajectories, especially while planning in tight spaces. Unfortunately, it is\noften computationally intractable beyond a very small swarm size. In this\npaper, we propose Flow-Opt, a learning-based approach towards improving the\ncomputational tractability of centralized multi-robot trajectory optimization.\nSpecifically, we reduce the problem to first learning a generative model to\nsample different candidate trajectories and then using a learned\nSafety-Filter(SF) to ensure fast inference-time constraint satisfaction. We\npropose a flow-matching model with a diffusion transformer (DiT) augmented with\npermutation invariant robot position and map encoders as the generative model.\nWe develop a custom solver for our SF and equip it with a neural network that\npredicts context-specific initialization. The initialization network is trained\nin a self-supervised manner, taking advantage of the differentiability of the\nSF solver. We advance the state-of-the-art in the following respects. First, we\nshow that we can generate trajectories of tens of robots in cluttered\nenvironments in a few tens of milliseconds. This is several times faster than\nexisting centralized optimization approaches. Moreover, our approach also\ngenerates smoother trajectories orders of magnitude faster than competing\nbaselines based on diffusion models. Second, each component of our approach can\nbe batched, allowing us to solve a few tens of problem instances in a fraction\nof a second. We believe this is a first such result; no existing approach\nprovides such capabilities. Finally, our approach can generate a diverse set of\ntrajectories between a given set of start and goal locations, which can capture\ndifferent collision-avoidance behaviors.", "AI": {"tldr": "Flow-Opt\u662f\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684\u96c6\u4e2d\u5f0f\u591a\u673a\u5668\u4eba\u8f68\u8ff9\u4f18\u5316\u65b9\u6cd5\uff0c\u4f7f\u7528\u6d41\u5339\u914d\u6a21\u578b\u751f\u6210\u5019\u9009\u8f68\u8ff9\uff0c\u5e76\u901a\u8fc7\u5b66\u4e60\u7684\u5b89\u5168\u8fc7\u6ee4\u5668\u786e\u4fdd\u7ea6\u675f\u6ee1\u8db3\uff0c\u5b9e\u73b0\u6beb\u79d2\u7ea7\u8f68\u8ff9\u751f\u6210\u3002", "motivation": "\u96c6\u4e2d\u5f0f\u591a\u673a\u5668\u4eba\u8f68\u8ff9\u4f18\u5316\u5728\u72ed\u7a84\u7a7a\u95f4\u4e2d\u80fd\u4ea7\u751f\u66f4\u5e73\u6ed1\u7684\u8f68\u8ff9\uff0c\u4f46\u8ba1\u7b97\u590d\u6742\u5ea6\u968f\u673a\u5668\u4eba\u6570\u91cf\u589e\u52a0\u800c\u6025\u5267\u4e0a\u5347\uff0c\u96be\u4ee5\u6269\u5c55\u5230\u5927\u89c4\u6a21\u7fa4\u4f53\u3002", "method": "\u63d0\u51faFlow-Opt\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u6269\u6563\u53d8\u6362\u5668\uff08DiT\uff09\u6784\u5efa\u751f\u6210\u6a21\u578b\u91c7\u6837\u5019\u9009\u8f68\u8ff9\uff1b2\uff09\u5f00\u53d1\u53ef\u5fae\u5206\u7684\u5b89\u5168\u8fc7\u6ee4\u5668\u786e\u4fdd\u7ea6\u675f\u6ee1\u8db3\uff1b3\uff09\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u4e0a\u4e0b\u6587\u7279\u5b9a\u7684\u521d\u59cb\u5316\u3002", "result": "\u5728\u6742\u4e71\u73af\u5883\u4e2d\u751f\u6210\u6570\u5341\u4e2a\u673a\u5668\u4eba\u7684\u8f68\u8ff9\u4ec5\u9700\u51e0\u5341\u6beb\u79d2\uff0c\u6bd4\u73b0\u6709\u96c6\u4e2d\u5f0f\u4f18\u5316\u65b9\u6cd5\u5feb\u6570\u500d\uff0c\u6bd4\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u57fa\u7ebf\u65b9\u6cd5\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u5e76\u80fd\u6279\u91cf\u5904\u7406\u591a\u4e2a\u95ee\u9898\u5b9e\u4f8b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u591a\u673a\u5668\u4eba\u8f68\u8ff9\u89c4\u5212\uff0c\u5728\u8ba1\u7b97\u901f\u5ea6\u548c\u8f68\u8ff9\u5e73\u6ed1\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u751f\u6210\u591a\u6837\u5316\u7684\u907f\u78b0\u884c\u4e3a\u8f68\u8ff9\u3002"}}
{"id": "2510.09037", "categories": ["cs.AI", "cs.PL", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.09037", "abs": "https://arxiv.org/abs/2510.09037", "authors": ["Sicheol Sung", "Joonghyuk Hahn", "Yo-Sub Han"], "title": "Repairing Regex Vulnerabilities via Localization-Guided Instructions", "comment": "14 pages, 4 figures, 4 tables", "summary": "Regular expressions (regexes) are foundational to modern computing for\ncritical tasks like input validation and data parsing, yet their ubiquity\nexposes systems to regular expression denial of service (ReDoS), a\nvulnerability requiring automated repair methods. Current approaches, however,\nare hampered by a trade-off. Symbolic, rule-based system are precise but fails\nto repair unseen or complex vulnerability patterns. Conversely, large language\nmodels (LLMs) possess the necessary generalizability but are unreliable for\ntasks demanding strict syntactic and semantic correctness. We resolve this\nimpasse by introducing a hybrid framework, localized regex repair (LRR),\ndesigned to harness LLM generalization while enforcing reliability. Our core\ninsight is to decouple problem identification from the repair process. First, a\ndeterministic, symbolic module localizes the precise vulnerable subpattern,\ncreating a constrained and tractable problem space. Then, the LLM invoked to\ngenerate a semantically equivalent fix for this isolated segment. This combined\narchitecture successfully resolves complex repair cases intractable for\nrule-based repair while avoiding the semantic errors of LLM-only approaches.\nOur work provides a validated methodology for solving such problems in\nautomated repair, improving the repair rate by 15.4%p over the\nstate-of-the-art. Our code is available at https://github.com/cdltlehf/LRR.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6846\u67b6LRR\uff0c\u7ed3\u5408\u7b26\u53f7\u7cfb\u7edf\u548cLLM\u7684\u4f18\u52bf\u6765\u4fee\u590d\u6b63\u5219\u8868\u8fbe\u5f0fReDoS\u6f0f\u6d1e\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7cbe\u5ea6\u548c\u6cdb\u5316\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u6b63\u5219\u8868\u8fbe\u5f0f\u5728\u73b0\u4ee3\u8ba1\u7b97\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5b58\u5728ReDoS\u6f0f\u6d1e\u98ce\u9669\u3002\u73b0\u6709\u4fee\u590d\u65b9\u6cd5\u9762\u4e34\u4e24\u96be\uff1a\u7b26\u53f7\u7cfb\u7edf\u7cbe\u786e\u4f46\u65e0\u6cd5\u5904\u7406\u590d\u6742\u6a21\u5f0f\uff0cLLM\u6cdb\u5316\u6027\u5f3a\u4f46\u53ef\u9760\u6027\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6846\u67b6LRR\uff1a\u5148\u7528\u7b26\u53f7\u6a21\u5757\u7cbe\u786e\u5b9a\u4f4d\u6f0f\u6d1e\u5b50\u6a21\u5f0f\uff0c\u518d\u7528LLM\u751f\u6210\u8bed\u4e49\u7b49\u6548\u7684\u4fee\u590d\u65b9\u6848\uff0c\u5c06\u95ee\u9898\u8bc6\u522b\u4e0e\u4fee\u590d\u8fc7\u7a0b\u89e3\u8026\u3002", "result": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u7b26\u53f7\u7cfb\u7edf\u65e0\u6cd5\u5904\u7406\u7684\u590d\u6742\u4fee\u590d\u6848\u4f8b\uff0c\u907f\u514d\u4e86\u7eafLLM\u65b9\u6cd5\u7684\u8bed\u4e49\u9519\u8bef\uff0c\u4fee\u590d\u7387\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u9ad8\u4e8615.4\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "LRR\u6846\u67b6\u4e3a\u81ea\u52a8\u4fee\u590d\u95ee\u9898\u63d0\u4f9b\u4e86\u9a8c\u8bc1\u6709\u6548\u7684\u65b9\u6cd5\u8bba\uff0c\u6709\u6548\u7ed3\u5408\u4e86LLM\u7684\u6cdb\u5316\u80fd\u529b\u548c\u7b26\u53f7\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.09209", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09209", "abs": "https://arxiv.org/abs/2510.09209", "authors": ["Yuki Kuroda", "Tomoya Takahashi", "Cristian C Beltran-Hernandez", "Masashi Hamaya", "Kazutoshi Tanaka"], "title": "PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling Precision-Lateral Dexterous Manipulation", "comment": null, "summary": "Electric prosthetic hands should be lightweight to decrease the burden on the\nuser, shaped like human hands for cosmetic purposes, and have motors inside to\nprotect them from damage and dirt. In addition to the ability to perform daily\nactivities, these features are essential for everyday use of the hand. In-hand\nmanipulation is necessary to perform daily activities such as transitioning\nbetween different postures, particularly through rotational movements, such as\nreorienting cards before slot insertion and operating tools such as\nscrewdrivers. However, currently used electric prosthetic hands only achieve\nstatic grasp postures, and existing manipulation approaches require either many\nmotors, which makes the prosthesis heavy for daily use in the hand, or complex\nmechanisms that demand a large internal space and force external motor\nplacement, complicating attachment and exposing the components to damage.\nAlternatively, we combine a single-axis thumb and optimized thumb positioning\nto achieve basic posture and in-hand manipulation, that is, the reorientation\nbetween precision and lateral grasps, using only four motors in a lightweight\n(311 g) prosthetic hand. Experimental validation using primitive objects of\nvarious widths (5-30 mm) and shapes (cylinders and prisms) resulted in success\nrates of 90-100% for reorientation tasks. The hand performed seal stamping and\nUSB device insertion, as well as rotation to operate a screwdriver.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4ec5\u4f7f\u75284\u4e2a\u7535\u673a\u7684\u8f7b\u91cf\u5316\uff08311\u514b\uff09\u5047\u80a2\u624b\uff0c\u901a\u8fc7\u5355\u8f74\u62c7\u6307\u548c\u4f18\u5316\u62c7\u6307\u4f4d\u7f6e\u5b9e\u73b0\u57fa\u672c\u6293\u63e1\u59ff\u52bf\u548c\u624b\u5185\u64cd\u4f5c\uff08\u7cbe\u5ea6\u548c\u4fa7\u5411\u6293\u63e1\u4e4b\u95f4\u7684\u91cd\u65b0\u5b9a\u5411\uff09\u3002", "motivation": "\u7535\u52a8\u5047\u80a2\u624b\u9700\u8981\u8f7b\u91cf\u5316\u4ee5\u51cf\u8f7b\u7528\u6237\u8d1f\u62c5\uff0c\u5916\u5f62\u50cf\u4eba\u624b\u7528\u4e8e\u7f8e\u89c2\uff0c\u7535\u673a\u5185\u7f6e\u4ee5\u4fdd\u62a4\u514d\u53d7\u635f\u574f\u548c\u6c61\u57a2\u3002\u9664\u4e86\u6267\u884c\u65e5\u5e38\u6d3b\u52a8\u7684\u80fd\u529b\u5916\uff0c\u8fd9\u4e9b\u7279\u6027\u5bf9\u4e8e\u65e5\u5e38\u4f7f\u7528\u81f3\u5173\u91cd\u8981\u3002\u624b\u5185\u64cd\u4f5c\u5bf9\u4e8e\u6267\u884c\u65e5\u5e38\u6d3b\u52a8\u662f\u5fc5\u8981\u7684\uff0c\u4f8b\u5982\u5728\u4e0d\u540c\u59ff\u52bf\u4e4b\u95f4\u8f6c\u6362\uff0c\u7279\u522b\u662f\u901a\u8fc7\u65cb\u8f6c\u8fd0\u52a8\u3002", "method": "\u7ed3\u5408\u5355\u8f74\u62c7\u6307\u548c\u4f18\u5316\u7684\u62c7\u6307\u5b9a\u4f4d\uff0c\u4ec5\u4f7f\u7528\u56db\u4e2a\u7535\u673a\u5728\u8f7b\u91cf\u5316\u5047\u80a2\u624b\u4e2d\u5b9e\u73b0\u57fa\u672c\u59ff\u52bf\u548c\u624b\u5185\u64cd\u4f5c\uff08\u7cbe\u5ea6\u548c\u4fa7\u5411\u6293\u63e1\u4e4b\u95f4\u7684\u91cd\u65b0\u5b9a\u5411\uff09\u3002", "result": "\u4f7f\u7528\u5404\u79cd\u5bbd\u5ea6\uff085-30\u6beb\u7c73\uff09\u548c\u5f62\u72b6\uff08\u5706\u67f1\u4f53\u548c\u68f1\u67f1\uff09\u7684\u539f\u59cb\u7269\u4f53\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u91cd\u65b0\u5b9a\u5411\u4efb\u52a1\u7684\u6210\u529f\u7387\u4e3a90-100%\u3002\u8be5\u624b\u6210\u529f\u6267\u884c\u4e86\u76d6\u7ae0\u3001USB\u8bbe\u5907\u63d2\u5165\u4ee5\u53ca\u65cb\u8f6c\u64cd\u4f5c\u87ba\u4e1d\u5200\u7b49\u4efb\u52a1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u4ec5\u4f7f\u7528\u56db\u4e2a\u7535\u673a\u7684\u8f7b\u91cf\u5316\u5047\u80a2\u624b\uff0c\u80fd\u591f\u6267\u884c\u57fa\u672c\u6293\u63e1\u548c\u624b\u5185\u64cd\u4f5c\u4efb\u52a1\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u65e5\u5e38\u6d3b\u52a8\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.09221", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09221", "abs": "https://arxiv.org/abs/2510.09221", "authors": ["Jingyuan Sun", "Chaoran Wang", "Mingyu Zhang", "Cui Miao", "Hongyu Ji", "Zihan Qu", "Han Sun", "Bing Wang", "Qingyi Si"], "title": "HANDO: Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation", "comment": "4 pages, 2 figures, this paper has been accepted for the workshop\n  Perception and Planning for Mobile Manipulation in Changing Environments\n  (PM2CE) at IROS 2025", "summary": "Seamless loco-manipulation in unstructured environments requires robots to\nleverage autonomous exploration alongside whole-body control for physical\ninteraction. In this work, we introduce HANDO (Hierarchical Autonomous\nNavigation and Dexterous Omni-loco-manipulation), a two-layer framework\ndesigned for legged robots equipped with manipulators to perform human-centered\nmobile manipulation tasks. The first layer utilizes a goal-conditioned\nautonomous exploration policy to guide the robot to semantically specified\ntargets, such as a black office chair in a dynamic environment. The second\nlayer employs a unified whole-body loco-manipulation policy to coordinate the\narm and legs for precise interaction tasks-for example, handing a drink to a\nperson seated on the chair. We have conducted an initial deployment of the\nnavigation module, and will continue to pursue finer-grained deployment of\nwhole-body loco-manipulation.", "AI": {"tldr": "HANDO\u6846\u67b6\uff1a\u4e3a\u914d\u5907\u673a\u68b0\u81c2\u7684\u817f\u5f0f\u673a\u5668\u4eba\u8bbe\u8ba1\u7684\u4e24\u5c42\u7cfb\u7edf\uff0c\u5b9e\u73b0\u81ea\u4e3b\u5bfc\u822a\u548c\u5168\u8eab\u534f\u8c03\u64cd\u4f5c\uff0c\u7528\u4e8e\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u6267\u884c\u4eba\u7c7b\u4e2d\u5fc3\u7684\u79fb\u52a8\u64cd\u4f5c\u4efb\u52a1\u3002", "motivation": "\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u5b9e\u73b0\u65e0\u7f1d\u7684\u79fb\u52a8\u64cd\u4f5c\u9700\u8981\u673a\u5668\u4eba\u80fd\u591f\u81ea\u4e3b\u63a2\u7d22\u5e76\u534f\u8c03\u5168\u8eab\u63a7\u5236\u8fdb\u884c\u7269\u7406\u4ea4\u4e92\uff0c\u4ee5\u5b8c\u6210\u4eba\u7c7b\u4e2d\u5fc3\u7684\u79fb\u52a8\u64cd\u4f5c\u4efb\u52a1\u3002", "method": "\u91c7\u7528\u4e24\u5c42\u6846\u67b6\uff1a\u7b2c\u4e00\u5c42\u4f7f\u7528\u76ee\u6807\u6761\u4ef6\u81ea\u4e3b\u63a2\u7d22\u7b56\u7565\u5f15\u5bfc\u673a\u5668\u4eba\u5230\u8fbe\u8bed\u4e49\u6307\u5b9a\u76ee\u6807\uff1b\u7b2c\u4e8c\u5c42\u4f7f\u7528\u7edf\u4e00\u7684\u5168\u8eab\u79fb\u52a8\u64cd\u4f5c\u7b56\u7565\u534f\u8c03\u624b\u81c2\u548c\u817f\u90e8\u8fdb\u884c\u7cbe\u786e\u4ea4\u4e92\u4efb\u52a1\u3002", "result": "\u5df2\u5b8c\u6210\u5bfc\u822a\u6a21\u5757\u7684\u521d\u6b65\u90e8\u7f72\uff0c\u5c06\u7ee7\u7eed\u63a8\u8fdb\u5168\u8eab\u79fb\u52a8\u64cd\u4f5c\u7684\u66f4\u7cbe\u7ec6\u90e8\u7f72\u3002", "conclusion": "HANDO\u6846\u67b6\u4e3a\u817f\u5f0f\u673a\u5668\u4eba\u5728\u52a8\u6001\u73af\u5883\u4e2d\u6267\u884c\u590d\u6742\u79fb\u52a8\u64cd\u4f5c\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5206\u5c42\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u4ece\u81ea\u4e3b\u5bfc\u822a\u5230\u7cbe\u786e\u64cd\u4f5c\u7684\u5b8c\u6574\u6d41\u7a0b\u3002"}}
{"id": "2510.09043", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09043", "abs": "https://arxiv.org/abs/2510.09043", "authors": ["Sang Hun Kim", "Jongmin Lee", "Dongkyu Park", "So Young Lee", "Yosep Chong"], "title": "Humanoid Artificial Consciousness Designed with Large Language Model Based on Psychoanalysis and Personality Theory", "comment": "41 pages, 6 figures. Accepted and published to Cognitive Systems\n  Research, 2025", "summary": "Human consciousness is still a concept hard to define with current scientific\nunderstanding. Although Large Language Models (LLMs) have recently demonstrated\nsignificant advancements across various domains including translation and\nsummarization, human consciousness is not something to imitate with current\nupfront technology owing to so-called hallucination. This study, therefore,\nproposes a novel approach to address these challenges by integrating\npsychoanalysis and the Myers-Briggs Type Indicator (MBTI) into constructing\nconsciousness and personality modules. We developed three artificial\nconsciousnesses (self-awareness, unconsciousness, and preconsciousness) based\non the principles of psychoanalysis. Additionally, we designed 16 characters\nwith different personalities representing the sixteen MBTI types, with several\nattributes such as needs, status, and memories. To determine if our model's\nartificial consciousness exhibits human-like cognition, we created ten distinct\nsituations considering seven attributes such as emotional understanding and\nlogical thinking. The decision-making process of artificial consciousness and\nthe final action were evaluated in three ways: survey evaluation, three-tier\nclassification via ChatGPT, and qualitative review. Both quantitative and\nqualitative analyses indicated a high likelihood of well-simulated\nconsciousness, although the difference in response between different characters\nand consciousnesses was not very significant. This implies that the developed\nmodels incorporating elements of psychoanalysis and personality theory can lead\nto building a more intuitive and adaptable AI system with humanoid\nconsciousness. Therefore, this study contributes to opening up new avenues for\nimproving AI interactions in complex cognitive contexts.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u5408\u7cbe\u795e\u5206\u6790\u548cMBTI\u4eba\u683c\u7406\u8bba\u7684\u65b0\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u5305\u542b\u81ea\u6211\u610f\u8bc6\u3001\u6f5c\u610f\u8bc6\u548c\u524d\u610f\u8bc6\u7684\u4eba\u5de5\u610f\u8bc6\u6a21\u5757\uff0c\u4ee5\u53ca16\u79cdMBTI\u4eba\u683c\u7c7b\u578b\u89d2\u8272\uff0c\u901a\u8fc7\u591a\u79cd\u8bc4\u4f30\u65b9\u6cd5\u9a8c\u8bc1\u4e86\u6a21\u62df\u4eba\u7c7b\u610f\u8bc6\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u5404\u9886\u57df\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u7531\u4e8e\u5e7b\u89c9\u95ee\u9898\u96be\u4ee5\u6a21\u62df\u4eba\u7c7b\u610f\u8bc6\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u6574\u5408\u7cbe\u795e\u5206\u6790\u548c\u4eba\u683c\u7406\u8bba\u6765\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u7cbe\u795e\u5206\u6790\u539f\u7406\u5f00\u53d1\u4e86\u4e09\u79cd\u4eba\u5de5\u610f\u8bc6\uff08\u81ea\u6211\u610f\u8bc6\u3001\u6f5c\u610f\u8bc6\u3001\u524d\u610f\u8bc6\uff09\uff0c\u8bbe\u8ba1\u4e8616\u79cdMBTI\u4eba\u683c\u7c7b\u578b\u89d2\u8272\uff0c\u521b\u5efa\u4e8610\u79cd\u4e0d\u540c\u60c5\u5883\uff0c\u91c7\u7528\u8c03\u67e5\u8bc4\u4f30\u3001ChatGPT\u4e09\u7ea7\u5206\u7c7b\u548c\u5b9a\u6027\u5ba1\u67e5\u4e09\u79cd\u65b9\u5f0f\u8bc4\u4f30\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u8868\u660e\u6a21\u578b\u5177\u6709\u8f83\u9ad8\u7684\u610f\u8bc6\u6a21\u62df\u53ef\u80fd\u6027\uff0c\u5c3d\u7ba1\u4e0d\u540c\u89d2\u8272\u548c\u610f\u8bc6\u4e4b\u95f4\u7684\u54cd\u5e94\u5dee\u5f02\u4e0d\u663e\u8457\uff0c\u4f46\u8bc1\u5b9e\u4e86\u6574\u5408\u7cbe\u795e\u5206\u6790\u548c\u4eba\u683c\u7406\u8bba\u53ef\u4ee5\u6784\u5efa\u66f4\u76f4\u89c2\u3001\u9002\u5e94\u6027\u5f3a\u7684\u7c7b\u4eba\u610f\u8bc6AI\u7cfb\u7edf\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u5728\u590d\u6742\u8ba4\u77e5\u60c5\u5883\u4e2d\u6539\u8fdbAI\u4ea4\u4e92\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u5c55\u793a\u4e86\u6574\u5408\u5fc3\u7406\u7406\u8bba\u5143\u7d20\u6784\u5efa\u7c7b\u4eba\u610f\u8bc6AI\u7cfb\u7edf\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.09229", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09229", "abs": "https://arxiv.org/abs/2510.09229", "authors": ["Yuyang Gao", "Haofei Ma", "Pai Zheng"], "title": "Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System", "comment": null, "summary": "We present Glovity, a novel, low-cost wearable teleoperation system that\nintegrates a spatial wrench (force-torque) feedback device with a haptic glove\nfeaturing fingertip Hall sensor calibration, enabling feedback-rich dexterous\nmanipulation. Glovity addresses key challenges in contact-rich tasks by\nproviding intuitive wrench and tactile feedback, while overcoming embodiment\ngaps through precise retargeting. User studies demonstrate significant\nimprovements: wrench feedback boosts success rates in book-flipping tasks from\n48% to 78% and reduces completion time by 25%, while fingertip calibration\nenhances thin-object grasping success significantly compared to commercial\nglove. Furthermore, incorporating wrench signals into imitation learning (via\nDP-R3M) achieves high success rate in novel contact-rich scenarios, such as\nadaptive page flipping and force-aware handovers. All hardware designs,\nsoftware will be open-sourced. Project website: https://glovity.github.io/", "AI": {"tldr": "Glovity\u662f\u4e00\u4e2a\u4f4e\u6210\u672c\u7684\u53ef\u7a7f\u6234\u8fdc\u7a0b\u64cd\u4f5c\u7cfb\u7edf\uff0c\u96c6\u6210\u4e86\u7a7a\u95f4\u529b\u53cd\u9988\u8bbe\u5907\u548c\u5e26\u6307\u5c16\u970d\u5c14\u4f20\u611f\u5668\u6821\u51c6\u7684\u89e6\u89c9\u624b\u5957\uff0c\u5b9e\u73b0\u4e86\u53cd\u9988\u4e30\u5bcc\u7684\u7075\u5de7\u64cd\u4f5c\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u63d0\u4f9b\u76f4\u89c2\u7684\u529b\u53cd\u9988\u548c\u89e6\u89c9\u53cd\u9988\uff0c\u5728\u63a5\u89e6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u63a5\u89e6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u901a\u8fc7\u63d0\u4f9b\u76f4\u89c2\u7684\u529b\u53cd\u9988\u548c\u89e6\u89c9\u53cd\u9988\u6765\u514b\u670d\u4f53\u73b0\u5dee\u8ddd\uff0c\u5b9e\u73b0\u7cbe\u786e\u7684\u91cd\u5b9a\u5411\u3002", "method": "\u96c6\u6210\u7a7a\u95f4\u529b\u53cd\u9988\u8bbe\u5907\u4e0e\u5e26\u6307\u5c16\u970d\u5c14\u4f20\u611f\u5668\u6821\u51c6\u7684\u89e6\u89c9\u624b\u5957\uff0c\u7ed3\u5408\u6a21\u4eff\u5b66\u4e60\uff08DP-R3M\uff09\u65b9\u6cd5\u3002", "result": "\u529b\u53cd\u9988\u5c06\u7ffb\u4e66\u4efb\u52a1\u7684\u6210\u529f\u7387\u4ece48%\u63d0\u5347\u523078%\uff0c\u5b8c\u6210\u65f6\u95f4\u51cf\u5c1125%\uff1b\u6307\u5c16\u6821\u51c6\u663e\u8457\u63d0\u5347\u4e86\u8584\u7269\u4f53\u6293\u53d6\u6210\u529f\u7387\uff1b\u5728\u65b0\u578b\u63a5\u89e6\u5bc6\u96c6\u578b\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6210\u529f\u7387\u3002", "conclusion": "Glovity\u7cfb\u7edf\u901a\u8fc7\u529b\u53cd\u9988\u548c\u89e6\u89c9\u53cd\u9988\u663e\u8457\u63d0\u5347\u4e86\u8fdc\u7a0b\u64cd\u4f5c\u7684\u6027\u80fd\u548c\u6210\u529f\u7387\uff0c\u786c\u4ef6\u8bbe\u8ba1\u548c\u8f6f\u4ef6\u5c06\u5f00\u6e90\u53d1\u5e03\u3002"}}
{"id": "2510.09049", "categories": ["cs.AI", "cs.SE", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.09049", "abs": "https://arxiv.org/abs/2510.09049", "authors": ["Joonghyuk Hahn", "Soohan Lim", "Yo-Sub Han"], "title": "MEC$^3$O: Multi-Expert Consensus for Code Time Complexity Prediction", "comment": "24 pages, 11 figures, 10 tables", "summary": "Predicting the complexity of source code is essential for software\ndevelopment and algorithm analysis. Recently, Baik et al. (2025) introduced\nCodeComplex for code time complexity prediction. The paper shows that LLMs\nwithout fine-tuning struggle with certain complexity classes. This suggests\nthat no single LLM excels at every class, but rather each model shows\nadvantages in certain classes. We propose MEC$^3$O, a multi-expert consensus\nsystem, which extends the multi-agent debate frameworks. MEC$^3$O assigns LLMs\nto complexity classes based on their performance and provides them with\nclass-specialized instructions, turning them into experts. These experts engage\nin structured debates, and their predictions are integrated through a weighted\nconsensus mechanism. Our expertise assignments to LLMs effectively handle\nDegeneration-of-Thought, reducing reliance on a separate judge model, and\npreventing convergence to incorrect majority opinions. Experiments on\nCodeComplex show that MEC$^3$O outperforms the open-source baselines, achieving\nat least 10% higher accuracy and macro-F1 scores. It also surpasses GPT-4o-mini\nin macro-F1 scores on average and demonstrates competitive on-par F1 scores to\nGPT-4o and GPT-o4-mini on average. This demonstrates the effectiveness of\nmulti-expert debates and weight consensus strategy to generate the final\npredictions. Our code and data is available at\nhttps://github.com/suhanmen/MECO.", "AI": {"tldr": "\u63d0\u51fa\u4e86MEC\u00b3O\u591a\u4e13\u5bb6\u5171\u8bc6\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06LLM\u5206\u914d\u5230\u4e0d\u540c\u590d\u6742\u5ea6\u7c7b\u522b\u5e76\u8ba9\u4e13\u5bb6\u8fdb\u884c\u7ed3\u6784\u5316\u8fa9\u8bba\uff0c\u4f7f\u7528\u52a0\u6743\u5171\u8bc6\u673a\u5236\u6574\u5408\u9884\u6d4b\uff0c\u5728\u4ee3\u7801\u65f6\u95f4\u590d\u6742\u5ea6\u9884\u6d4b\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u5728\u4ee3\u7801\u65f6\u95f4\u590d\u6742\u5ea6\u9884\u6d4b\u4e2d\u96be\u4ee5\u5728\u6240\u6709\u590d\u6742\u5ea6\u7c7b\u522b\u4e0a\u90fd\u8868\u73b0\u4f18\u5f02\uff0c\u4e0d\u540c\u6a21\u578b\u5728\u4e0d\u540c\u7c7b\u522b\u4e0a\u5404\u6709\u4f18\u52bf\uff0c\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u6574\u5408\u5404\u6a21\u578b\u7684\u4e13\u957f\u3002", "method": "MEC\u00b3O\u591a\u4e13\u5bb6\u5171\u8bc6\u7cfb\u7edf\uff1a\u57fa\u4e8e\u6027\u80fd\u5c06LLM\u5206\u914d\u5230\u4e0d\u540c\u590d\u6742\u5ea6\u7c7b\u522b\uff0c\u63d0\u4f9b\u7c7b\u522b\u4e13\u7528\u6307\u4ee4\u4f7f\u5176\u6210\u4e3a\u4e13\u5bb6\uff1b\u4e13\u5bb6\u8fdb\u884c\u7ed3\u6784\u5316\u8fa9\u8bba\uff0c\u901a\u8fc7\u52a0\u6743\u5171\u8bc6\u673a\u5236\u6574\u5408\u9884\u6d4b\u7ed3\u679c\u3002", "result": "\u5728CodeComplex\u6570\u636e\u96c6\u4e0a\uff0cMEC\u00b3O\u6bd4\u5f00\u6e90\u57fa\u7ebf\u65b9\u6cd5\u51c6\u786e\u7387\u548cmacro-F1\u5206\u6570\u81f3\u5c11\u63d0\u9ad810%\uff1b\u5728macro-F1\u5206\u6570\u4e0a\u5e73\u5747\u8d85\u8fc7GPT-4o-mini\uff0c\u4e0eGPT-4o\u548cGPT-4o-mini\u7684F1\u5206\u6570\u76f8\u5f53\u3002", "conclusion": "\u591a\u4e13\u5bb6\u8fa9\u8bba\u548c\u52a0\u6743\u5171\u8bc6\u7b56\u7565\u80fd\u6709\u6548\u751f\u6210\u6700\u7ec8\u9884\u6d4b\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u4ee3\u7801\u590d\u6742\u5ea6\u9884\u6d4b\u4efb\u52a1\u4e0a\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.09254", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09254", "abs": "https://arxiv.org/abs/2510.09254", "authors": ["Dominik Urbaniak", "Alejandro Agostini", "Pol Ramon", "Jan Rosell", "Ra\u00fal Su\u00e1rez", "Michael Suppa"], "title": "Obstacle Avoidance using Dynamic Movement Primitives and Reinforcement Learning", "comment": "8 pages, 7 figures", "summary": "Learning-based motion planning can quickly generate near-optimal\ntrajectories. However, it often requires either large training datasets or\ncostly collection of human demonstrations. This work proposes an alternative\napproach that quickly generates smooth, near-optimal collision-free 3D\nCartesian trajectories from a single artificial demonstration. The\ndemonstration is encoded as a Dynamic Movement Primitive (DMP) and iteratively\nreshaped using policy-based reinforcement learning to create a diverse\ntrajectory dataset for varying obstacle configurations. This dataset is used to\ntrain a neural network that takes as inputs the task parameters describing the\nobstacle dimensions and location, derived automatically from a point cloud, and\noutputs the DMP parameters that generate the trajectory. The approach is\nvalidated in simulation and real-robot experiments, outperforming a RRT-Connect\nbaseline in terms of computation and execution time, as well as trajectory\nlength, while supporting multi-modal trajectory generation for different\nobstacle geometries and end-effector dimensions. Videos and the implementation\ncode are available at https://github.com/DominikUrbaniak/obst-avoid-dmp-pi2.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5355\u4e2a\u4eba\u5de5\u6f14\u793a\u7684\u8fd0\u52a8\u89c4\u5212\u65b9\u6cd5\uff0c\u4f7f\u7528\u52a8\u6001\u8fd0\u52a8\u57fa\u5143(DMP)\u548c\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\u5feb\u901f\u751f\u6210\u5e73\u6ed1\u3001\u63a5\u8fd1\u6700\u4f18\u76843D\u7b1b\u5361\u5c14\u8f68\u8ff9\uff0c\u65e0\u9700\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u6216\u4eba\u5de5\u6f14\u793a\u3002", "motivation": "\u4f20\u7edf\u5b66\u4e60\u578b\u8fd0\u52a8\u89c4\u5212\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u6216\u6602\u8d35\u7684\u4eba\u5de5\u6f14\u793a\uff0c\u672c\u5de5\u4f5c\u65e8\u5728\u901a\u8fc7\u5355\u4e2a\u4eba\u5de5\u6f14\u793a\u5feb\u901f\u751f\u6210\u591a\u6837\u5316\u7684\u65e0\u78b0\u649e\u8f68\u8ff9\u3002", "method": "\u5c06\u4eba\u5de5\u6f14\u793a\u7f16\u7801\u4e3aDMP\uff0c\u4f7f\u7528\u57fa\u4e8e\u7b56\u7565\u7684\u5f3a\u5316\u5b66\u4e60\u8fed\u4ee3\u91cd\u5851\u4ee5\u521b\u5efa\u591a\u6837\u5316\u8f68\u8ff9\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u6839\u636e\u969c\u788d\u7269\u53c2\u6570\u8f93\u51faDMP\u53c2\u6570\u3002", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\uff0c\u5728\u8ba1\u7b97\u65f6\u95f4\u3001\u6267\u884c\u65f6\u95f4\u548c\u8f68\u8ff9\u957f\u5ea6\u65b9\u9762\u4f18\u4e8eRRT-Connect\u57fa\u7ebf\uff0c\u652f\u6301\u4e0d\u540c\u969c\u788d\u7269\u51e0\u4f55\u548c\u672b\u7aef\u6267\u884c\u5668\u5c3a\u5bf8\u7684\u591a\u6a21\u6001\u8f68\u8ff9\u751f\u6210\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u751f\u6210\u5e73\u6ed1\u3001\u63a5\u8fd1\u6700\u4f18\u7684\u65e0\u78b0\u649e\u8f68\u8ff9\uff0c\u4ec5\u9700\u5355\u4e2a\u4eba\u5de5\u6f14\u793a\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.09060", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.09060", "abs": "https://arxiv.org/abs/2510.09060", "authors": ["Jingxuan Wu", "Zhenglin Wan", "Xingrui Yu", "Yuzhe Yang", "Bo An", "Ivor Tsang"], "title": "OSCAR: Orthogonal Stochastic Control for Alignment-Respecting Diversity in Flow Matching", "comment": null, "summary": "Flow-based text-to-image models follow deterministic trajectories, forcing\nusers to repeatedly sample to discover diverse modes, which is a costly and\ninefficient process. We present a training-free, inference-time control\nmechanism that makes the flow itself diversity-aware. Our method simultaneously\nencourages lateral spread among trajectories via a feature-space objective and\nreintroduces uncertainty through a time-scheduled stochastic perturbation.\nCrucially, this perturbation is projected to be orthogonal to the generation\nflow, a geometric constraint that allows it to boost variation without\ndegrading image details or prompt fidelity. Our procedure requires no\nretraining or modification to the base sampler and is compatible with common\nflow-matching solvers. Theoretically, our method is shown to monotonically\nincrease a volume surrogate while, due to its geometric constraints,\napproximately preserving the marginal distribution. This provides a principled\nexplanation for why generation quality is robustly maintained. Empirically,\nacross multiple text-to-image settings under fixed sampling budgets, our method\nconsistently improves diversity metrics such as the Vendi Score and Brisque\nover strong baselines, while upholding image quality and alignment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u5728\u63a8\u7406\u65f6\u63a7\u5236\u6d41\u5f0f\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7279\u5f81\u7a7a\u95f4\u76ee\u6807\u548c\u65f6\u95f4\u8c03\u5ea6\u7684\u968f\u673a\u6270\u52a8\u6765\u589e\u5f3a\u751f\u6210\u591a\u6837\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u56fe\u50cf\u8d28\u91cf\u548c\u63d0\u793a\u5bf9\u9f50\u3002", "motivation": "\u6d41\u5f0f\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u9075\u5faa\u786e\u5b9a\u6027\u8f68\u8ff9\uff0c\u7528\u6237\u9700\u8981\u91cd\u590d\u91c7\u6837\u624d\u80fd\u53d1\u73b0\u591a\u6837\u6a21\u5f0f\uff0c\u8fd9\u662f\u4e00\u4e2a\u6210\u672c\u9ad8\u4e14\u6548\u7387\u4f4e\u7684\u8fc7\u7a0b\u3002", "method": "\u540c\u65f6\u901a\u8fc7\u7279\u5f81\u7a7a\u95f4\u76ee\u6807\u9f13\u52b1\u8f68\u8ff9\u95f4\u7684\u6a2a\u5411\u6269\u6563\uff0c\u5e76\u901a\u8fc7\u65f6\u95f4\u8c03\u5ea6\u7684\u968f\u673a\u6270\u52a8\u91cd\u65b0\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u3002\u5173\u952e\u662f\u5c06\u6270\u52a8\u6295\u5f71\u4e3a\u4e0e\u751f\u6210\u6d41\u6b63\u4ea4\uff0c\u8fd9\u4e00\u51e0\u4f55\u7ea6\u675f\u5141\u8bb8\u5728\u4e0d\u964d\u4f4e\u56fe\u50cf\u7ec6\u8282\u6216\u63d0\u793a\u4fdd\u771f\u5ea6\u7684\u60c5\u51b5\u4e0b\u589e\u5f3a\u53d8\u5316\u3002", "result": "\u5728\u56fa\u5b9a\u91c7\u6837\u9884\u7b97\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6587\u672c\u5230\u56fe\u50cf\u8bbe\u7f6e\u4e2d\u6301\u7eed\u6539\u8fdb\u4e86Vendi Score\u548cBrisque\u7b49\u591a\u6837\u6027\u6307\u6807\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u56fe\u50cf\u8d28\u91cf\u548c\u5bf9\u9f50\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u4fee\u6539\u57fa\u7840\u91c7\u6837\u5668\uff0c\u4e0e\u5e38\u89c1\u7684\u6d41\u5339\u914d\u6c42\u89e3\u5668\u517c\u5bb9\uff0c\u7406\u8bba\u4e0a\u663e\u793a\u80fd\u5355\u8c03\u589e\u52a0\u4f53\u79ef\u4ee3\u7406\uff0c\u540c\u65f6\u7531\u4e8e\u51e0\u4f55\u7ea6\u675f\u8fd1\u4f3c\u4fdd\u6301\u8fb9\u7f18\u5206\u5e03\uff0c\u4e3a\u751f\u6210\u8d28\u91cf\u7684\u7a33\u5065\u4fdd\u6301\u63d0\u4f9b\u4e86\u539f\u7406\u6027\u89e3\u91ca\u3002"}}
{"id": "2510.09267", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09267", "abs": "https://arxiv.org/abs/2510.09267", "authors": ["Amina Ferrad", "Johann Huber", "Fran\u00e7ois H\u00e9l\u00e9non", "Julien Gleyze", "Mahdi Khoramshahi", "St\u00e9phane Doncieux"], "title": "Placeit! A Framework for Learning Robot Object Placement Skills", "comment": "8 pages, 8 figures. Draft version", "summary": "Robotics research has made significant strides in learning, yet mastering\nbasic skills like object placement remains a fundamental challenge. A key\nbottleneck is the acquisition of large-scale, high-quality data, which is often\na manual and laborious process. Inspired by Graspit!, a foundational work that\nused simulation to automatically generate dexterous grasp poses, we introduce\nPlaceit!, an evolutionary-computation framework for generating valid placement\npositions for rigid objects. Placeit! is highly versatile, supporting tasks\nfrom placing objects on tables to stacking and inserting them. Our experiments\nshow that by leveraging quality-diversity optimization, Placeit! significantly\noutperforms state-of-the-art methods across all scenarios for generating\ndiverse valid poses. A pick&place pipeline built on our framework achieved a\n90% success rate over 120 real-world deployments. This work positions Placeit!\nas a powerful tool for open-environment pick-and-place tasks and as a valuable\nengine for generating the data needed to train simulation-based foundation\nmodels in robotics.", "AI": {"tldr": "Placeit!\u662f\u4e00\u4e2a\u57fa\u4e8e\u8fdb\u5316\u8ba1\u7b97\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u521a\u6027\u7269\u4f53\u7684\u6709\u6548\u653e\u7f6e\u4f4d\u7f6e\uff0c\u652f\u6301\u684c\u9762\u653e\u7f6e\u3001\u5806\u53e0\u548c\u63d2\u5165\u7b49\u591a\u79cd\u4efb\u52a1\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u4e2d\u8fbe\u523090%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u673a\u5668\u4eba\u5b66\u4e60\u9762\u4e34\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u6570\u636e\u83b7\u53d6\u7684\u74f6\u9888\uff0c\u9700\u8981\u81ea\u52a8\u5316\u7684\u6570\u636e\u751f\u6210\u65b9\u6cd5\u6765\u652f\u6301\u57fa\u672c\u6280\u80fd\uff08\u5982\u7269\u4f53\u653e\u7f6e\uff09\u7684\u638c\u63e1\u3002", "method": "\u91c7\u7528\u8fdb\u5316\u8ba1\u7b97\u548c\u591a\u6837\u6027\u4f18\u5316\u65b9\u6cd5\uff0c\u5f00\u53d1Placeit!\u6846\u67b6\u81ea\u52a8\u751f\u6210\u6709\u6548\u7684\u7269\u4f53\u653e\u7f6e\u59ff\u52bf\uff0c\u652f\u6301\u591a\u79cd\u653e\u7f6e\u573a\u666f\u3002", "result": "Placeit!\u5728\u6240\u6709\u6d4b\u8bd5\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u66f4\u591a\u6837\u5316\u7684\u6709\u6548\u59ff\u52bf\uff1b\u57fa\u4e8e\u8be5\u6846\u67b6\u7684\u6293\u53d6\u653e\u7f6e\u7ba1\u9053\u5728120\u6b21\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u4e2d\u8fbe\u523090%\u7684\u6210\u529f\u7387\u3002", "conclusion": "Placeit!\u662f\u5f00\u653e\u73af\u5883\u6293\u53d6\u653e\u7f6e\u4efb\u52a1\u7684\u6709\u529b\u5de5\u5177\uff0c\u4e5f\u662f\u8bad\u7ec3\u57fa\u4e8e\u4eff\u771f\u7684\u673a\u5668\u4eba\u57fa\u7840\u6a21\u578b\u6240\u9700\u6570\u636e\u751f\u6210\u7684\u91cd\u8981\u5f15\u64ce\u3002"}}
{"id": "2510.09396", "categories": ["cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.09396", "abs": "https://arxiv.org/abs/2510.09396", "authors": ["Sajad Khatiri", "Francisco Eli Vina Barrientos", "Maximilian Wulf", "Paolo Tonella", "Sebastiano Panichella"], "title": "Bridging Research and Practice in Simulation-based Testing of Industrial Robot Navigation Systems", "comment": "12 pages, accepted for publication at IEEE/ACM International\n  Conference on Automated Software Engineering (ASE) 2025 - Industry Showcase\n  Track", "summary": "Ensuring robust robotic navigation in dynamic environments is a key\nchallenge, as traditional testing methods often struggle to cover the full\nspectrum of operational requirements. This paper presents the industrial\nadoption of Surrealist, a simulation-based test generation framework originally\nfor UAVs, now applied to the ANYmal quadrupedal robot for industrial\ninspection. Our method uses a search-based algorithm to automatically generate\nchallenging obstacle avoidance scenarios, uncovering failures often missed by\nmanual testing. In a pilot phase, generated test suites revealed critical\nweaknesses in one experimental algorithm (40.3% success rate) and served as an\neffective benchmark to prove the superior robustness of another (71.2% success\nrate). The framework was then integrated into the ANYbotics workflow for a\nsix-month industrial evaluation, where it was used to test five proprietary\nalgorithms. A formal survey confirmed its value, showing it enhances the\ndevelopment process, uncovers critical failures, provides objective benchmarks,\nand strengthens the overall verification pipeline.", "AI": {"tldr": "\u5c06Surrealist\u4eff\u771f\u6d4b\u8bd5\u6846\u67b6\u4ece\u65e0\u4eba\u673a\u6269\u5c55\u5230ANYmal\u56db\u8db3\u673a\u5668\u4eba\u5de5\u4e1a\u68c0\u6d4b\u5e94\u7528\uff0c\u901a\u8fc7\u641c\u7d22\u7b97\u6cd5\u81ea\u52a8\u751f\u6210\u969c\u788d\u89c4\u907f\u573a\u666f\uff0c\u5728\u5de5\u4e1a\u8bc4\u4f30\u4e2d\u9a8c\u8bc1\u4e86\u4e94\u4e2a\u4e13\u6709\u7b97\u6cd5\u5e76\u63d0\u5347\u4e86\u5f00\u53d1\u6d41\u7a0b\u3002", "motivation": "\u4f20\u7edf\u6d4b\u8bd5\u65b9\u6cd5\u96be\u4ee5\u8986\u76d6\u52a8\u6001\u73af\u5883\u4e2d\u673a\u5668\u4eba\u5bfc\u822a\u7684\u5168\u90e8\u64cd\u4f5c\u8981\u6c42\uff0c\u9700\u8981\u81ea\u52a8\u5316\u7684\u6d4b\u8bd5\u751f\u6210\u6846\u67b6\u6765\u53d1\u73b0\u624b\u52a8\u6d4b\u8bd5\u9057\u6f0f\u7684\u6545\u969c\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u641c\u7d22\u7684\u7b97\u6cd5\u81ea\u52a8\u751f\u6210\u5177\u6709\u6311\u6218\u6027\u7684\u969c\u788d\u89c4\u907f\u573a\u666f\uff0c\u5e76\u5c06\u6846\u67b6\u96c6\u6210\u5230ANYbotics\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u8fdb\u884c\u516d\u4e2a\u6708\u7684\u5de5\u4e1a\u8bc4\u4f30\u3002", "result": "\u5728\u8bd5\u70b9\u9636\u6bb5\uff0c\u751f\u6210\u7684\u6d4b\u8bd5\u5957\u4ef6\u63ed\u793a\u4e86\u4e00\u4e2a\u5b9e\u9a8c\u7b97\u6cd5\u7684\u5173\u952e\u5f31\u70b9\uff08\u6210\u529f\u738740.3%\uff09\uff0c\u5e76\u8bc1\u660e\u4e86\u53e6\u4e00\u4e2a\u7b97\u6cd5\u7684\u4f18\u8d8a\u9c81\u68d2\u6027\uff08\u6210\u529f\u738771.2%\uff09\u3002\u6b63\u5f0f\u8c03\u67e5\u786e\u8ba4\u8be5\u6846\u67b6\u589e\u5f3a\u4e86\u5f00\u53d1\u8fc7\u7a0b\uff0c\u53d1\u73b0\u4e86\u5173\u952e\u6545\u969c\uff0c\u63d0\u4f9b\u4e86\u5ba2\u89c2\u57fa\u51c6\u3002", "conclusion": "Surrealist\u6846\u67b6\u6210\u529f\u5e94\u7528\u4e8e\u5de5\u4e1a\u56db\u8db3\u673a\u5668\u4eba\u6d4b\u8bd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u7b97\u6cd5\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u80fd\u591f\u53d1\u73b0\u624b\u52a8\u6d4b\u8bd5\u9057\u6f0f\u7684\u6545\u969c\u5e76\u4e3a\u7b97\u6cd5\u6027\u80fd\u63d0\u4f9b\u5ba2\u89c2\u57fa\u51c6\u3002"}}
{"id": "2510.09087", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09087", "abs": "https://arxiv.org/abs/2510.09087", "authors": ["Zhang Zheng", "Deheng Ye", "Peilin Zhao", "Hao Wang"], "title": "Leading the Follower: Learning Persuasive Agents in Social Deduction Games", "comment": null, "summary": "Large language model (LLM) agents have shown remarkable progress in social\ndeduction games (SDGs). However, existing approaches primarily focus on\ninformation processing and strategy selection, overlooking the significance of\npersuasive communication in influencing other players' beliefs and responses.\nIn SDGs, success depends not only on making correct deductions but on\nconvincing others to response in alignment with one's intent. To address this\nlimitation, we formalize turn-based dialogue in SDGs as a Stackelberg\ncompetition, where the current player acts as the leader who strategically\ninfluences the follower's response. Building on this theoretical foundation, we\npropose a reinforcement learning framework that trains agents to optimize\nutterances for persuasive impact. Through comprehensive experiments across\nthree diverse SDGs, we demonstrate that our agents significantly outperform\nbaselines. This work represents a significant step toward developing AI agents\ncapable of strategic social influence, with implications extending to scenarios\nrequiring persuasive communication.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eStackelberg\u7ade\u4e89\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3LLM\u4ee3\u7406\u5728\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u4e2d\u4f18\u5316\u8bf4\u670d\u6027\u6c9f\u901a\u80fd\u529b\uff0c\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u5728\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u4e2d\u4e3b\u8981\u5173\u6ce8\u4fe1\u606f\u5904\u7406\u548c\u7b56\u7565\u9009\u62e9\uff0c\u5ffd\u89c6\u4e86\u8bf4\u670d\u6027\u6c9f\u901a\u5728\u5f71\u54cd\u5176\u4ed6\u73a9\u5bb6\u4fe1\u5ff5\u548c\u56de\u5e94\u65b9\u9762\u7684\u91cd\u8981\u6027\u3002", "method": "\u5c06\u56de\u5408\u5236\u5bf9\u8bdd\u5f62\u5f0f\u5316\u4e3aStackelberg\u7ade\u4e89\uff0c\u63d0\u51fa\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8bad\u7ec3\u4ee3\u7406\u4f18\u5316\u8bdd\u8bed\u7684\u8bf4\u670d\u6548\u679c\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u7684\u793e\u4ea4\u63a8\u7406\u6e38\u620f\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u4ee3\u7406\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4ee3\u8868\u4e86\u5f00\u53d1\u5177\u6709\u6218\u7565\u6027\u793e\u4f1a\u5f71\u54cd\u529bAI\u4ee3\u7406\u7684\u91cd\u8981\u8fdb\u5c55\uff0c\u5bf9\u9700\u8981\u8bf4\u670d\u6027\u6c9f\u901a\u7684\u573a\u666f\u5177\u6709\u5e7f\u6cdb\u610f\u4e49\u3002"}}
{"id": "2510.09459", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09459", "abs": "https://arxiv.org/abs/2510.09459", "authors": ["Ralf R\u00f6mer", "Adrian Kobras", "Luca Worbis", "Angela P. Schoellig"], "title": "Failure Prediction at Runtime for Generative Robot Policies", "comment": "Accepted to NeurIPS 2025", "summary": "Imitation learning (IL) with generative models, such as diffusion and flow\nmatching, has enabled robots to perform complex, long-horizon tasks. However,\ndistribution shifts from unseen environments or compounding action errors can\nstill cause unpredictable and unsafe behavior, leading to task failure. Early\nfailure prediction during runtime is therefore essential for deploying robots\nin human-centered and safety-critical environments. We propose FIPER, a general\nframework for Failure Prediction at Runtime for generative IL policies that\ndoes not require failure data. FIPER identifies two key indicators of impending\nfailure: (i) out-of-distribution (OOD) observations detected via random network\ndistillation in the policy's embedding space, and (ii) high uncertainty in\ngenerated actions measured by a novel action-chunk entropy score. Both failure\nprediction scores are calibrated using a small set of successful rollouts via\nconformal prediction. A failure alarm is triggered when both indicators,\naggregated over short time windows, exceed their thresholds. We evaluate FIPER\nacross five simulation and real-world environments involving diverse failure\nmodes. Our results demonstrate that FIPER better distinguishes actual failures\nfrom benign OOD situations and predicts failures more accurately and earlier\nthan existing methods. We thus consider this work an important step towards\nmore interpretable and safer generative robot policies. Code, data and videos\nare available at https://tum-lsy.github.io/fiper_website.", "AI": {"tldr": "FIPER\u662f\u4e00\u4e2a\u65e0\u9700\u5931\u8d25\u6570\u636e\u7684\u8fd0\u884c\u65f6\u6545\u969c\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u6d4b\u5206\u5e03\u5916\u89c2\u5bdf\u548c\u52a8\u4f5c\u4e0d\u786e\u5b9a\u6027\u6765\u9884\u6d4b\u751f\u6210\u5f0f\u6a21\u4eff\u5b66\u4e60\u7b56\u7565\u7684\u6545\u969c\u3002", "motivation": "\u751f\u6210\u5f0f\u6a21\u4eff\u5b66\u4e60\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5206\u5e03\u504f\u79fb\u548c\u52a8\u4f5c\u8bef\u5dee\u7d2f\u79ef\u4f1a\u5bfc\u81f4\u4e0d\u53ef\u9884\u6d4b\u7684\u4e0d\u5b89\u5168\u884c\u4e3a\uff0c\u9700\u8981\u8fd0\u884c\u65f6\u6545\u969c\u9884\u6d4b\u6765\u786e\u4fdd\u673a\u5668\u4eba\u90e8\u7f72\u5b89\u5168\u3002", "method": "\u4f7f\u7528\u968f\u673a\u7f51\u7edc\u84b8\u998f\u68c0\u6d4b\u5206\u5e03\u5916\u89c2\u5bdf\uff0c\u63d0\u51fa\u65b0\u7684\u52a8\u4f5c\u5757\u71b5\u5206\u6570\u8861\u91cf\u52a8\u4f5c\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u4fdd\u5f62\u9884\u6d4b\u6821\u51c6\u6545\u969c\u9884\u6d4b\u5206\u6570\uff0c\u5e76\u5728\u77ed\u65f6\u95f4\u7a97\u53e3\u5185\u805a\u5408\u4e24\u4e2a\u6307\u6807\u6765\u89e6\u53d1\u6545\u969c\u8b66\u62a5\u3002", "result": "\u5728\u4e94\u4e2a\u4eff\u771f\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u8bc4\u4f30\u8868\u660e\uff0cFIPER\u80fd\u66f4\u597d\u5730\u533a\u5206\u5b9e\u9645\u6545\u969c\u4e0e\u826f\u6027\u5206\u5e03\u5916\u60c5\u51b5\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u51c6\u786e\u3001\u66f4\u65e9\u5730\u9884\u6d4b\u6545\u969c\u3002", "conclusion": "FIPER\u662f\u5411\u66f4\u53ef\u89e3\u91ca\u3001\u66f4\u5b89\u5168\u7684\u751f\u6210\u5f0f\u673a\u5668\u4eba\u7b56\u7565\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u4e3a\u673a\u5668\u4eba\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6545\u969c\u9884\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.09133", "categories": ["cs.AI", "cs.LG", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.09133", "abs": "https://arxiv.org/abs/2510.09133", "authors": ["Hao Zeng", "Jianguo Huang", "Bingyi Jing", "Hongxin Wei", "Bo An"], "title": "PAC Reasoning: Controlling the Performance Loss for Efficient Reasoning", "comment": null, "summary": "Large reasoning models (LRMs) have achieved remarkable progress in complex\nproblem-solving tasks. Despite this success, LRMs typically suffer from high\ncomputational costs during deployment, highlighting a need for efficient\ninference. A popular direction of efficiency improvement is to switch the LRM\nbetween thinking and nonthinking modes dynamically. However, such approaches\noften introduce additional reasoning errors and lack statistical guarantees for\nthe performance loss, which are critical for high-stakes applications. In this\nwork, we propose Probably Approximately Correct (PAC) reasoning that controls\nthe performance loss under the user-specified performance loss tolerance. In\nparticular, we construct an upper confidence bound on the performance loss,\nformulated as a monotone function of the uncertainty score, and subsequently\ndetermine a threshold for switching to the nonthinking model. Theoretically,\nusing the threshold to switch between the thinking and nonthinking modes\nensures bounded performance loss in a distribution-free manner. Our\ncomprehensive experiments on reasoning benchmarks show that the proposed method\ncan save computational budgets and control the user-specified performance loss.", "AI": {"tldr": "\u63d0\u51faPAC\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f6e\u4fe1\u4e0a\u754c\u63a7\u5236\u6027\u80fd\u635f\u5931\uff0c\u5728\u7528\u6237\u6307\u5b9a\u7684\u5bb9\u5fcd\u8303\u56f4\u5185\u52a8\u6001\u5207\u6362\u601d\u8003\u548c\u975e\u601d\u8003\u6a21\u5f0f\u4ee5\u8282\u7701\u8ba1\u7b97\u6210\u672c", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u95ee\u9898\u89e3\u51b3\u4e2d\u8868\u73b0\u51fa\u8272\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u52a8\u6001\u5207\u6362\u65b9\u6cd5\u7f3a\u4e4f\u6027\u80fd\u635f\u5931\u7684\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u4e0d\u9002\u5408\u9ad8\u98ce\u9669\u5e94\u7528", "method": "\u6784\u5efa\u6027\u80fd\u635f\u5931\u7684\u5355\u8c03\u51fd\u6570\u7f6e\u4fe1\u4e0a\u754c\uff0c\u786e\u5b9a\u5207\u6362\u9608\u503c\uff0c\u5728\u7406\u8bba\u4fdd\u8bc1\u4e0b\u5206\u5e03\u65e0\u5173\u5730\u63a7\u5236\u6027\u80fd\u635f\u5931", "result": "\u5728\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u8282\u7701\u8ba1\u7b97\u9884\u7b97\u5e76\u63a7\u5236\u7528\u6237\u6307\u5b9a\u7684\u6027\u80fd\u635f\u5931", "conclusion": "PAC\u63a8\u7406\u65b9\u6cd5\u4e3a\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c"}}
{"id": "2510.09483", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09483", "abs": "https://arxiv.org/abs/2510.09483", "authors": ["Lars Ohnemus", "Nils Hantke", "Max Wei\u00dfer", "Kai Furmans"], "title": "FOGMACHINE -- Leveraging Discrete-Event Simulation and Scene Graphs for Modeling Hierarchical, Interconnected Environments under Partial Observations from Mobile Agents", "comment": "submitted to the IEEE for possible publication; 8 pages, 3 figures, 1\n  table", "summary": "Dynamic Scene Graphs (DSGs) provide a structured representation of\nhierarchical, interconnected environments, but current approaches struggle to\ncapture stochastic dynamics, partial observability, and multi-agent activity.\nThese aspects are critical for embodied AI, where agents must act under\nuncertainty and delayed perception. We introduce FOGMACHINE , an open-source\nframework that fuses DSGs with discrete-event simulation to model object\ndynamics, agent observations, and interactions at scale. This setup enables the\nstudy of uncertainty propagation, planning under limited perception, and\nemergent multi-agent behavior. Experiments in urban scenarios illustrate\nrealistic temporal and spatial patterns while revealing the challenges of\nbelief estimation under sparse observations. By combining structured\nrepresentations with efficient simulation, FOGMACHINE establishes an effective\ntool for benchmarking, model training, and advancing embodied AI in complex,\nuncertain environments.", "AI": {"tldr": "FOGMACHINE\u662f\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u5c06\u52a8\u6001\u573a\u666f\u56fe\u4e0e\u79bb\u6563\u4e8b\u4ef6\u6a21\u62df\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u5efa\u6a21\u5bf9\u8c61\u52a8\u6001\u3001\u667a\u80fd\u4f53\u89c2\u5bdf\u548c\u4ea4\u4e92\u3002", "motivation": "\u5f53\u524d\u52a8\u6001\u573a\u666f\u56fe\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u968f\u673a\u52a8\u6001\u3001\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u548c\u591a\u667a\u80fd\u4f53\u6d3b\u52a8\uff0c\u800c\u8fd9\u4e9b\u5bf9\u4e8e\u5177\u8eabAI\u5728\u4e0d\u786e\u5b9a\u6027\u548c\u5ef6\u8fdf\u611f\u77e5\u4e0b\u884c\u52a8\u81f3\u5173\u91cd\u8981\u3002", "method": "\u878d\u5408\u52a8\u6001\u573a\u666f\u56fe\u4e0e\u79bb\u6563\u4e8b\u4ef6\u6a21\u62df\uff0c\u5efa\u6a21\u5bf9\u8c61\u52a8\u6001\u3001\u667a\u80fd\u4f53\u89c2\u5bdf\u548c\u5927\u89c4\u6a21\u4ea4\u4e92\u3002", "result": "\u5728\u57ce\u5e02\u573a\u666f\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u771f\u5b9e\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u6a21\u5f0f\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5728\u7a00\u758f\u89c2\u5bdf\u4e0b\u4fe1\u5ff5\u4f30\u8ba1\u7684\u6311\u6218\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u7ed3\u6784\u5316\u8868\u793a\u548c\u9ad8\u6548\u6a21\u62df\uff0cFOGMACHINE\u4e3a\u590d\u6742\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u57fa\u51c6\u6d4b\u8bd5\u3001\u6a21\u578b\u8bad\u7ec3\u548c\u5177\u8eabAI\u53d1\u5c55\u5efa\u7acb\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2510.09497", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09497", "abs": "https://arxiv.org/abs/2510.09497", "authors": ["Noah Barnes", "Ji Woong Kim", "Lingyun Di", "Hannah Qu", "Anuruddha Bhattacharjee", "Miroslaw Janowski", "Dheeraj Gandhi", "Bailey Felix", "Shaopeng Jiang", "Olivia Young", "Mark Fuge", "Ryan D. Sochol", "Jeremy D. Brown", "Axel Krieger"], "title": "Autonomous Soft Robotic Guidewire Navigation via Imitation Learning", "comment": null, "summary": "In endovascular surgery, endovascular interventionists push a thin tube\ncalled a catheter, guided by a thin wire to a treatment site inside the\npatient's blood vessels to treat various conditions such as blood clots,\naneurysms, and malformations. Guidewires with robotic tips can enhance\nmaneuverability, but they present challenges in modeling and control.\nAutomation of soft robotic guidewire navigation has the potential to overcome\nthese challenges, increasing the precision and safety of endovascular\nnavigation. In other surgical domains, end-to-end imitation learning has shown\npromising results. Thus, we develop a transformer-based imitation learning\nframework with goal conditioning, relative action outputs, and automatic\ncontrast dye injections to enable generalizable soft robotic guidewire\nnavigation in an aneurysm targeting task. We train the model on 36 different\nmodular bifurcated geometries, generating 647 total demonstrations under\nsimulated fluoroscopy, and evaluate it on three previously unseen vascular\ngeometries. The model can autonomously drive the tip of the robot to the\naneurysm location with a success rate of 83% on the unseen geometries,\noutperforming several baselines. In addition, we present ablation and baseline\nstudies to evaluate the effectiveness of each design and data collection\nchoice. Project website: https://softrobotnavigation.github.io/", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eTransformer\u7684\u6a21\u4eff\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u8f6f\u4f53\u673a\u5668\u4eba\u5bfc\u4e1d\u5728\u8840\u7ba1\u5185\u5bfc\u822a\uff0c\u5728\u52a8\u8109\u7624\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u8fbe\u523083%\u7684\u6210\u529f\u7387", "motivation": "\u89e3\u51b3\u8f6f\u4f53\u673a\u5668\u4eba\u5bfc\u4e1d\u5728\u8840\u7ba1\u5185\u5bfc\u822a\u4e2d\u7684\u5efa\u6a21\u548c\u63a7\u5236\u6311\u6218\uff0c\u63d0\u9ad8\u8840\u7ba1\u5185\u5bfc\u822a\u7684\u7cbe\u786e\u6027\u548c\u5b89\u5168\u6027", "method": "\u5f00\u53d1\u57fa\u4e8eTransformer\u7684\u6a21\u4eff\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u76ee\u6807\u6761\u4ef6\u3001\u76f8\u5bf9\u52a8\u4f5c\u8f93\u51fa\u548c\u81ea\u52a8\u5bf9\u6bd4\u5242\u6ce8\u5c04\uff0c\u572836\u79cd\u4e0d\u540c\u5206\u53c9\u51e0\u4f55\u7ed3\u6784\u4e0a\u8bad\u7ec3\u6a21\u578b", "result": "\u5728\u672a\u89c1\u8fc7\u7684\u8840\u7ba1\u51e0\u4f55\u7ed3\u6784\u4e0a\uff0c\u6a21\u578b\u80fd\u591f\u81ea\u4e3b\u5c06\u673a\u5668\u4eba\u5c16\u7aef\u5bfc\u822a\u81f3\u52a8\u8109\u7624\u4f4d\u7f6e\uff0c\u6210\u529f\u7387\u8fbe83%\uff0c\u4f18\u4e8e\u591a\u4e2a\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u53ef\u6cdb\u5316\u7684\u8f6f\u4f53\u673a\u5668\u4eba\u5bfc\u4e1d\u5bfc\u822a\uff0c\u4e3a\u8840\u7ba1\u5185\u624b\u672f\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.09223", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09223", "abs": "https://arxiv.org/abs/2510.09223", "authors": ["Mubaris Nadeem", "Madjid Fathi"], "title": "Comparing Knowledge Source Integration Methods for Optimizing Healthcare Knowledge Fusion in Rescue Operation", "comment": "Conference Paper for 2024 IEEE 7th International Conference on\n  Industrial Cyber-Physical Systems (ICPS), KIRETT Project, University of\n  Siegen, Germany", "summary": "In the field of medicine and healthcare, the utilization of medical\nexpertise, based on medical knowledge combined with patients' health\ninformation is a life-critical challenge for patients and health professionals.\nThe within-laying complexity and variety form the need for a united approach to\ngather, analyze, and utilize existing knowledge of medical treatments, and\nmedical operations to provide the ability to present knowledge for the means of\naccurate patient-driven decision-making. One way to achieve this is the fusion\nof multiple knowledge sources in healthcare. It provides health professionals\nthe opportunity to select from multiple contextual aligned knowledge sources\nwhich enables the support for critical decisions. This paper presents multiple\nconceptual models for knowledge fusion in the field of medicine, based on a\nknowledge graph structure. It will evaluate, how knowledge fusion can be\nenabled and presents how to integrate various knowledge sources into the\nknowledge graph for rescue operations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7ed3\u6784\u7684\u533b\u5b66\u77e5\u8bc6\u878d\u5408\u6982\u5ff5\u6a21\u578b\uff0c\u65e8\u5728\u6574\u5408\u591a\u79cd\u533b\u7597\u77e5\u8bc6\u6e90\u4ee5\u652f\u6301\u5173\u952e\u533b\u7597\u51b3\u7b56\u3002", "motivation": "\u533b\u7597\u9886\u57df\u9700\u8981\u7edf\u4e00\u7684\u65b9\u6cd5\u6765\u6536\u96c6\u3001\u5206\u6790\u548c\u5229\u7528\u73b0\u6709\u533b\u7597\u77e5\u8bc6\uff0c\u4ee5\u652f\u6301\u51c6\u786e\u7684\u4ee5\u60a3\u8005\u4e3a\u5bfc\u5411\u7684\u51b3\u7b56\u5236\u5b9a\u3002\u533b\u7597\u77e5\u8bc6\u7684\u590d\u6742\u6027\u548c\u591a\u6837\u6027\u8981\u6c42\u878d\u5408\u591a\u79cd\u77e5\u8bc6\u6e90\u6765\u4e3a\u533b\u7597\u4e13\u4e1a\u4eba\u5458\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7ed3\u6784\u7684\u6982\u5ff5\u6a21\u578b\uff0c\u8bc4\u4f30\u77e5\u8bc6\u878d\u5408\u7684\u5b9e\u73b0\u65b9\u5f0f\uff0c\u5e76\u5c55\u793a\u5982\u4f55\u5c06\u5404\u79cd\u77e5\u8bc6\u6e90\u6574\u5408\u5230\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7528\u4e8e\u6551\u63f4\u64cd\u4f5c\u3002", "result": "\u5f00\u53d1\u4e86\u652f\u6301\u77e5\u8bc6\u878d\u5408\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u4f7f\u533b\u7597\u4e13\u4e1a\u4eba\u5458\u80fd\u591f\u4ece\u591a\u4e2a\u4e0a\u4e0b\u6587\u5bf9\u9f50\u7684\u77e5\u8bc6\u6e90\u4e2d\u8fdb\u884c\u9009\u62e9\uff0c\u4ece\u800c\u652f\u6301\u5173\u952e\u51b3\u7b56\u3002", "conclusion": "\u77e5\u8bc6\u56fe\u8c31\u7ed3\u6784\u4e3a\u533b\u7597\u9886\u57df\u7684\u77e5\u8bc6\u878d\u5408\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\uff0c\u80fd\u591f\u6709\u6548\u6574\u5408\u591a\u6e90\u533b\u7597\u77e5\u8bc6\u5e76\u652f\u6301\u7cbe\u51c6\u7684\u533b\u7597\u51b3\u7b56\u3002"}}
{"id": "2510.09526", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09526", "abs": "https://arxiv.org/abs/2510.09526", "authors": ["Chenghao Wang", "Kaushik Venkatesh Krishnamurthy", "Shreyansh Pitroda", "Adarsh Salagame", "Ioannis Mandralis", "Eric Sihite", "Alireza Ramezani", "Morteza Gharib"], "title": "Dynamic Quadrupedal Legged and Aerial Locomotion via Structure Repurposing", "comment": null, "summary": "Multi-modal ground-aerial robots have been extensively studied, with a\nsignificant challenge lying in the integration of conflicting requirements\nacross different modes of operation. The Husky robot family, developed at\nNortheastern University, and specifically the Husky v.2 discussed in this\nstudy, addresses this challenge by incorporating posture manipulation and\nthrust vectoring into multi-modal locomotion through structure repurposing.\nThis quadrupedal robot features leg structures that can be repurposed for\ndynamic legged locomotion and flight. In this paper, we present the hardware\ndesign of the robot and report primary results on dynamic quadrupedal legged\nlocomotion and hovering.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Husky v.2\u591a\u6a21\u6001\u673a\u5668\u4eba\u7684\u786c\u4ef6\u8bbe\u8ba1\uff0c\u8be5\u673a\u5668\u4eba\u901a\u8fc7\u7ed3\u6784\u91cd\u7528\u9014\u5f84\u5b9e\u73b0\u4e86\u52a8\u6001\u56db\u8db3\u884c\u8d70\u548c\u98de\u884c\u4e24\u79cd\u8fd0\u52a8\u6a21\u5f0f\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u5730\u9762-\u7a7a\u4e2d\u673a\u5668\u4eba\u5728\u4e0d\u540c\u64cd\u4f5c\u6a21\u5f0f\u4e0b\u7684\u51b2\u7a81\u9700\u6c42\u6574\u5408\u96be\u9898\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u91cd\u7528\u9014\u5f84\uff0c\u5c06\u817f\u90e8\u7ed3\u6784\u91cd\u65b0\u7528\u4e8e\u52a8\u6001\u56db\u8db3\u884c\u8d70\u548c\u98de\u884c\uff0c\u7ed3\u5408\u59ff\u6001\u64cd\u7eb5\u548c\u63a8\u529b\u77e2\u91cf\u63a7\u5236\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u52a8\u6001\u56db\u8db3\u884c\u8d70\u548c\u60ac\u505c\u98de\u884c\u7684\u4e3b\u8981\u7ed3\u679c\u3002", "conclusion": "Husky v.2\u673a\u5668\u4eba\u901a\u8fc7\u7ed3\u6784\u91cd\u7528\u9014\u5f84\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u8fd0\u52a8\u4e2d\u7684\u51b2\u7a81\u9700\u6c42\uff0c\u4e3a\u591a\u6a21\u6001\u673a\u5668\u4eba\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.09227", "categories": ["cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2510.09227", "abs": "https://arxiv.org/abs/2510.09227", "authors": ["Hyundong Jin", "Joonghyuk Hahn", "Yo-Sub Han"], "title": "RegexPSPACE: A Benchmark for Evaluating LLM Reasoning on PSPACE-complete Regex Problems", "comment": null, "summary": "Large language models (LLMs) show strong performance across natural language\nprocessing (NLP), mathematical reasoning, and programming, and recent large\nreasoning models (LRMs) further emphasize explicit reasoning. Yet their\ncomputational limits, particularly spatial complexity constrained by finite\ncontext windows, remain poorly understood. While recent works often focus on\nproblems within the NP complexity class, we push the boundary by introducing a\nnovel benchmark grounded in two PSPACE-complete regular expression (regex)\nproblems: equivalence decision (RegexEQ) and minimization (RegexMin).\nPSPACE-complete problems serve as a more rigorous standard for assessing\ncomputational capacity, as their solutions require massive search space\nexploration. We perform a double-exponential space exploration to construct a\nlabeled dataset of over a million regex instances with a sound filtering\nprocess to build the benchmark. We conduct extensive evaluations on 6 LLMs and\n5 LRMs of varying scales, revealing common failure patterns such as verbosity\nand repetition. With its well-defined structure and quantitative evaluation\nmetrics, this work presents the first empirical investigation into the spatial\ncomputational limitations of LLMs and LRMs, offering a new framework for\nevaluating their advanced reasoning capabilities. Our code is available at\nhttps://github.com/hyundong98/RegexPSPACE .", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8ePSPACE\u5b8c\u5168\u6b63\u5219\u8868\u8fbe\u5f0f\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5927\u63a8\u7406\u6a21\u578b\u7684\u7a7a\u95f4\u8ba1\u7b97\u9650\u5236\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u5904\u7406\u9700\u8981\u5927\u91cf\u641c\u7d22\u7a7a\u95f4\u63a2\u7d22\u7684\u95ee\u9898\u65f6\u5b58\u5728\u5931\u8d25\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8NP\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u590d\u6742\u5ea6\u65b9\u9762\u7684\u8ba1\u7b97\u9650\u5236\u4ecd\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u66f4\u4e25\u683c\u7684PSPACE\u5b8c\u5168\u95ee\u9898\u6765\u8bc4\u4f30\u5176\u8ba1\u7b97\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u53cc\u6307\u6570\u7a7a\u95f4\u63a2\u7d22\u6784\u5efa\u5305\u542b\u8d85\u8fc7\u767e\u4e07\u4e2a\u6b63\u5219\u8868\u8fbe\u5f0f\u5b9e\u4f8b\u7684\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u4e25\u683c\u8fc7\u6ee4\u8fc7\u7a0b\u5efa\u7acb\u57fa\u51c6\uff0c\u5bf96\u4e2aLLM\u548c5\u4e2aLRM\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\u3002", "result": "\u63ed\u793a\u4e86\u6a21\u578b\u5728\u5904\u7406PSPACE\u5b8c\u5168\u95ee\u9898\u65f6\u7684\u5e38\u89c1\u5931\u8d25\u6a21\u5f0f\uff0c\u5982\u5197\u957f\u548c\u91cd\u590d\uff0c\u8868\u660e\u6a21\u578b\u5728\u9700\u8981\u5927\u89c4\u6a21\u641c\u7d22\u7a7a\u95f4\u63a2\u7d22\u7684\u95ee\u9898\u4e0a\u5b58\u5728\u8ba1\u7b97\u9650\u5236\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u9996\u6b21\u5b9e\u8bc1\u7814\u7a76\u4e86LLM\u548cLRM\u7684\u7a7a\u95f4\u8ba1\u7b97\u9650\u5236\uff0c\u4e3a\u8bc4\u4f30\u5176\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\u3002"}}
{"id": "2510.09543", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09543", "abs": "https://arxiv.org/abs/2510.09543", "authors": ["Chenghao Wang", "Arjun Viswanathan", "Eric Sihite", "Alireza Ramezani"], "title": "Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards", "comment": null, "summary": "Animals achieve energy-efficient locomotion by their implicit passive\ndynamics, a marvel that has captivated roboticists for decades.Recently,\nmethods incorporated Adversarial Motion Prior (AMP) and Reinforcement learning\n(RL) shows promising progress to replicate Animals' naturalistic motion.\nHowever, such imitation learning approaches predominantly capture explicit\nkinematic patterns, so-called gaits, while overlooking the implicit passive\ndynamics. This work bridges this gap by incorporating a reward term guided by\nImpact Mitigation Factor (IMF), a physics-informed metric that quantifies a\nrobot's ability to passively mitigate impacts. By integrating IMF with AMP, our\napproach enables RL policies to learn both explicit motion trajectories from\nanimal reference motion and the implicit passive dynamic. We demonstrate energy\nefficiency improvements of up to 32%, as measured by the Cost of Transport\n(CoT), across both AMP and handcrafted reward structure.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u51b2\u51fb\u7f13\u89e3\u56e0\u5b50(IMF)\u4e0e\u5bf9\u6297\u8fd0\u52a8\u5148\u9a8c(AMP)\u7684\u65b9\u6cd5\uff0c\u4f7f\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u80fd\u591f\u540c\u65f6\u5b66\u4e60\u52a8\u7269\u7684\u663e\u6027\u8fd0\u52a8\u8f68\u8ff9\u548c\u9690\u6027\u88ab\u52a8\u52a8\u529b\u5b66\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe32%\u7684\u80fd\u6e90\u6548\u7387\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u6355\u6349\u52a8\u7269\u7684\u663e\u6027\u6b65\u6001\u6a21\u5f0f\uff0c\u4f46\u5ffd\u7565\u4e86\u9690\u6027\u88ab\u52a8\u52a8\u529b\u5b66\uff0c\u800c\u52a8\u7269\u6b63\u662f\u901a\u8fc7\u8fd9\u79cd\u88ab\u52a8\u52a8\u529b\u5b66\u5b9e\u73b0\u8282\u80fd\u8fd0\u52a8\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u7269\u7406\u7684\u51b2\u51fb\u7f13\u89e3\u56e0\u5b50(IMF)\u4f5c\u4e3a\u5956\u52b1\u9879\uff0c\u5e76\u5c06\u5176\u4e0e\u5bf9\u6297\u8fd0\u52a8\u5148\u9a8c(AMP)\u7ed3\u5408\uff0c\u4f7f\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u80fd\u591f\u5b66\u4e60\u52a8\u7269\u7684\u663e\u6027\u8fd0\u52a8\u8f68\u8ff9\u548c\u9690\u6027\u88ab\u52a8\u52a8\u6001\u3002", "result": "\u5728AMP\u548c\u624b\u5de5\u5956\u52b1\u7ed3\u6784\u4e0a\u90fd\u5b9e\u73b0\u4e86\u9ad8\u8fbe32%\u7684\u80fd\u6e90\u6548\u7387\u63d0\u5347\uff0c\u901a\u8fc7\u8fd0\u8f93\u6210\u672c(CoT)\u8861\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u88ab\u52a8\u52a8\u6001\u5b66\u4e60\u6574\u5408\u5230\u6a21\u4eff\u5b66\u4e60\u4e2d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u7684\u80fd\u6e90\u6548\u7387\uff0c\u4e3a\u66f4\u81ea\u7136\u7684\u673a\u5668\u4eba\u8fd0\u52a8\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.09244", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09244", "abs": "https://arxiv.org/abs/2510.09244", "authors": ["Victor de Lamo Castrillo", "Habtom Kahsay Gidey", "Alexander Lenz", "Alois Knoll"], "title": "Fundamentals of Building Autonomous LLM Agents", "comment": null, "summary": "This paper reviews the architecture and implementation methods of agents\npowered by large language models (LLMs). Motivated by the limitations of\ntraditional LLMs in real-world tasks, the research aims to explore patterns to\ndevelop \"agentic\" LLMs that can automate complex tasks and bridge the\nperformance gap with human capabilities. Key components include a perception\nsystem that converts environmental percepts into meaningful representations; a\nreasoning system that formulates plans, adapts to feedback, and evaluates\nactions through different techniques like Chain-of-Thought and Tree-of-Thought;\na memory system that retains knowledge through both short-term and long-term\nmechanisms; and an execution system that translates internal decisions into\nconcrete actions. This paper shows how integrating these systems leads to more\ncapable and generalized software bots that mimic human cognitive processes for\nautonomous and intelligent behavior.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u67b6\u6784\u548c\u5b9e\u73b0\u65b9\u6cd5\uff0c\u63a2\u7d22\u5982\u4f55\u5f00\u53d1\u80fd\u591f\u81ea\u52a8\u5316\u590d\u6742\u4efb\u52a1\u7684\"\u667a\u80fd\u4f53\u5316\"LLMs\uff0c\u4ee5\u5f25\u5408\u4e0e\u4eba\u7c7b\u80fd\u529b\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u4f20\u7edfLLMs\u5728\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u81ea\u52a8\u5316\u590d\u6742\u4efb\u52a1\u5e76\u7f29\u5c0f\u4e0e\u4eba\u7c7b\u80fd\u529b\u5dee\u8ddd\u7684\u667a\u80fd\u4f53\u5316LLMs\u3002", "method": "\u6784\u5efa\u5305\u542b\u56db\u4e2a\u5173\u952e\u7ec4\u4ef6\u7684\u7cfb\u7edf\uff1a\u611f\u77e5\u7cfb\u7edf\uff08\u5c06\u73af\u5883\u611f\u77e5\u8f6c\u6362\u4e3a\u6709\u610f\u4e49\u8868\u793a\uff09\u3001\u63a8\u7406\u7cfb\u7edf\uff08\u5236\u5b9a\u8ba1\u5212\u3001\u9002\u5e94\u53cd\u9988\u3001\u8bc4\u4f30\u884c\u52a8\uff09\u3001\u8bb0\u5fc6\u7cfb\u7edf\uff08\u901a\u8fc7\u77ed\u671f\u548c\u957f\u671f\u673a\u5236\u4fdd\u7559\u77e5\u8bc6\uff09\u3001\u6267\u884c\u7cfb\u7edf\uff08\u5c06\u5185\u90e8\u51b3\u7b56\u8f6c\u5316\u4e3a\u5177\u4f53\u884c\u52a8\uff09\u3002", "result": "\u96c6\u6210\u8fd9\u4e9b\u7cfb\u7edf\u80fd\u591f\u521b\u5efa\u66f4\u5f3a\u5927\u548c\u901a\u7528\u7684\u8f6f\u4ef6\u673a\u5668\u4eba\uff0c\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u5b9e\u73b0\u81ea\u4e3b\u667a\u80fd\u884c\u4e3a\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u611f\u77e5\u3001\u63a8\u7406\u3001\u8bb0\u5fc6\u548c\u6267\u884c\u7cfb\u7edf\uff0c\u53ef\u4ee5\u5f00\u53d1\u51fa\u80fd\u591f\u6a21\u4eff\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u7684\u667a\u80fd\u4f53\u5316LLMs\uff0c\u5b9e\u73b0\u81ea\u4e3b\u548c\u667a\u80fd\u884c\u4e3a\u3002"}}
{"id": "2510.09574", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09574", "abs": "https://arxiv.org/abs/2510.09574", "authors": ["Daria de tinguy", "Tim Verbelen", "Emilio Gamba", "Bart Dhoedt"], "title": "Zero-shot Structure Learning and Planning for Autonomous Robot Navigation using Active Inference", "comment": "yet to be submitted", "summary": "Autonomous navigation in unfamiliar environments requires robots to\nsimultaneously explore, localise, and plan under uncertainty, without relying\non predefined maps or extensive training. We present a biologically inspired,\nActive Inference-based framework, Active Inference MAPping and Planning\n(AIMAPP). This model unifies mapping, localisation, and decision-making within\na single generative model. Inspired by hippocampal navigation, it uses\ntopological reasoning, place-cell encoding, and episodic memory to guide\nbehaviour. The agent builds and updates a sparse topological map online, learns\nstate transitions dynamically, and plans actions by minimising Expected Free\nEnergy. This allows it to balance goal-directed and exploratory behaviours. We\nimplemented a ROS-compatible navigation system that is sensor and\nrobot-agnostic, capable of integrating with diverse hardware configurations. It\noperates in a fully self-supervised manner, is resilient to drift, and supports\nboth exploration and goal-directed navigation without any pre-training. We\ndemonstrate robust performance in large-scale real and simulated environments\nagainst state-of-the-art planning models, highlighting the system's\nadaptability to ambiguous observations, environmental changes, and sensor\nnoise. The model offers a biologically inspired, modular solution to scalable,\nself-supervised navigation in unstructured settings. AIMAPP is available at\nhttps://github.com/decide-ugent/AIMAPP.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e3b\u52a8\u63a8\u7406\u7684\u751f\u7269\u542f\u53d1\u5bfc\u822a\u6846\u67b6AIMAPP\uff0c\u5c06\u5efa\u56fe\u3001\u5b9a\u4f4d\u548c\u51b3\u7b56\u7edf\u4e00\u5728\u5355\u4e00\u751f\u6210\u6a21\u578b\u4e2d\uff0c\u652f\u6301\u65e0\u9884\u8bad\u7ec3\u7684\u81ea\u76d1\u7763\u5bfc\u822a\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u5728\u964c\u751f\u73af\u5883\u4e2d\u540c\u65f6\u8fdb\u884c\u63a2\u7d22\u3001\u5b9a\u4f4d\u548c\u89c4\u5212\u7684\u95ee\u9898\uff0c\u65e0\u9700\u4f9d\u8d56\u9884\u5b9a\u4e49\u5730\u56fe\u6216\u5927\u91cf\u8bad\u7ec3\uff0c\u5b9e\u73b0\u751f\u7269\u542f\u53d1\u7684\u81ea\u4e3b\u5bfc\u822a\u3002", "method": "\u4f7f\u7528\u4e3b\u52a8\u63a8\u7406\u6846\u67b6\uff0c\u7ed3\u5408\u62d3\u6251\u63a8\u7406\u3001\u4f4d\u7f6e\u7ec6\u80de\u7f16\u7801\u548c\u60c5\u666f\u8bb0\u5fc6\uff0c\u5728\u7ebf\u6784\u5efa\u7a00\u758f\u62d3\u6251\u5730\u56fe\uff0c\u52a8\u6001\u5b66\u4e60\u72b6\u6001\u8f6c\u79fb\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u671f\u671b\u81ea\u7531\u80fd\u6765\u89c4\u5212\u52a8\u4f5c\u3002", "result": "\u5f00\u53d1\u4e86ROS\u517c\u5bb9\u7684\u5bfc\u822a\u7cfb\u7edf\uff0c\u5728\u5927\u578b\u771f\u5b9e\u548c\u6a21\u62df\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u80fd\uff0c\u80fd\u591f\u9002\u5e94\u6a21\u7cca\u89c2\u6d4b\u3001\u73af\u5883\u53d8\u5316\u548c\u4f20\u611f\u5668\u566a\u58f0\u3002", "conclusion": "AIMAPP\u63d0\u4f9b\u4e86\u4e00\u4e2a\u751f\u7269\u542f\u53d1\u7684\u6a21\u5757\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u81ea\u76d1\u7763\u5bfc\u822a\u3002"}}
{"id": "2510.09338", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09338", "abs": "https://arxiv.org/abs/2510.09338", "authors": ["Joachim Diederich"], "title": "Localist LLMs -- A Mathematical Framework for Dynamic Locality Control", "comment": null, "summary": "We present a novel framework for training large language models with\ncontinuously adjustable internal representations that span the full spectrum\nfrom localist (interpretable, rule-based) to distributed (generalizable,\nefficient) encodings. The key innovation is a locality dial, a tunable\nparameter that dynamically controls the degree of localization during both\ntraining and inference without requiring model retraining. This is achieved\nthrough group sparsity penalties on attention mechanisms, information-theoretic\nanchor design, and dynamic rule injection. We provide rigorous mathematical\nproofs establishing explicit threshold conditions under which attention\nprovably concentrates on semantically relevant blocks, with exponential bounds\non attention entropy and pointer fidelity. Specifically, we prove that when\ngroup sparsity penalties exceed certain threshold values, the model's attention\nmechanisms concentrate on semantically relevant blocks, achieving low entropy\nand high fidelity with negligible error. This framework enables practitioners\nto continuously interpolate between interpretable and high-performance modes,\nsupporting applications in regulated domains requiring both transparency and\ncapability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u8c03\u8282\u7684\u5c40\u90e8\u6027\u53c2\u6570\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u5176\u5185\u90e8\u8868\u793a\u80fd\u5728\u5c40\u90e8\u5316\uff08\u53ef\u89e3\u91ca\u3001\u57fa\u4e8e\u89c4\u5219\uff09\u548c\u5206\u5e03\u5f0f\uff08\u6cdb\u5316\u6027\u5f3a\u3001\u9ad8\u6548\uff09\u7f16\u7801\u4e4b\u95f4\u8fde\u7eed\u8c03\u6574\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53ef\u89e3\u91ca\u6027\u548c\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u900f\u660e\u5ea6\u548c\u80fd\u529b\u7684\u53d7\u76d1\u7ba1\u9886\u57df\uff0c\u5f00\u53d1\u80fd\u591f\u52a8\u6001\u8c03\u6574\u8868\u793a\u5c40\u90e8\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7ec4\u7a00\u758f\u60e9\u7f5a\u6ce8\u610f\u529b\u673a\u5236\u3001\u4fe1\u606f\u8bba\u951a\u70b9\u8bbe\u8ba1\u548c\u52a8\u6001\u89c4\u5219\u6ce8\u5165\uff0c\u901a\u8fc7\u53ef\u8c03\u8282\u7684\u5c40\u90e8\u6027\u53c2\u6570\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d\u52a8\u6001\u63a7\u5236\u5c40\u90e8\u5316\u7a0b\u5ea6\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u6570\u5b66\u8bc1\u660e\uff0c\u5efa\u7acb\u4e86\u660e\u786e\u7684\u9608\u503c\u6761\u4ef6\uff0c\u8bc1\u660e\u5f53\u7ec4\u7a00\u758f\u60e9\u7f5a\u8d85\u8fc7\u7279\u5b9a\u9608\u503c\u65f6\uff0c\u6ce8\u610f\u529b\u673a\u5236\u4f1a\u96c6\u4e2d\u5728\u8bed\u4e49\u76f8\u5173\u5757\u4e0a\uff0c\u5b9e\u73b0\u4f4e\u71b5\u548c\u9ad8\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4f7f\u4ece\u4e1a\u8005\u80fd\u591f\u5728\u53ef\u89e3\u91ca\u6a21\u5f0f\u548c\u9ad8\u6027\u80fd\u6a21\u5f0f\u4e4b\u95f4\u8fde\u7eed\u63d2\u503c\uff0c\u652f\u6301\u9700\u8981\u900f\u660e\u5ea6\u548c\u80fd\u529b\u7684\u53d7\u76d1\u7ba1\u9886\u57df\u5e94\u7528\u3002"}}
{"id": "2510.09340", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.09340", "abs": "https://arxiv.org/abs/2510.09340", "authors": ["Davide Maltoni", "Matteo Ferrara"], "title": "Toward Mechanistic Explanation of Deductive Reasoning in Language Models", "comment": null, "summary": "Recent large language models have demonstrated relevant capabilities in\nsolving problems that require logical reasoning; however, the corresponding\ninternal mechanisms remain largely unexplored. In this paper, we show that a\nsmall language model can solve a deductive reasoning task by learning the\nunderlying rules (rather than operating as a statistical learner). A low-level\nexplanation of its internal representations and computational circuits is then\nprovided. Our findings reveal that induction heads play a central role in the\nimplementation of the rule completion and rule chaining steps involved in the\nlogical inference required by the task.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5c0f\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u4e60\u5f97\u5e95\u5c42\u89c4\u5219\u800c\u975e\u7edf\u8ba1\u5b66\u4e60\u6765\u89e3\u51b3\u6f14\u7ece\u63a8\u7406\u4efb\u52a1\uff0c\u63ed\u793a\u4e86\u5f52\u7eb3\u5934\u5728\u903b\u8f91\u63a8\u7406\u4e2d\u7684\u6838\u5fc3\u4f5c\u7528\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u63a8\u7406\u65b9\u9762\u5c55\u73b0\u51fa\u76f8\u5173\u80fd\u529b\uff0c\u4f46\u5176\u5185\u90e8\u673a\u5236\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5b9e\u73b0\u903b\u8f91\u63a8\u7406\u7684\u5185\u90e8\u5de5\u4f5c\u539f\u7406\u3002", "method": "\u4f7f\u7528\u5c0f\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u6f14\u7ece\u63a8\u7406\u4efb\u52a1\uff0c\u5206\u6790\u5176\u5185\u90e8\u8868\u5f81\u548c\u8ba1\u7b97\u7535\u8def\uff0c\u7279\u522b\u5173\u6ce8\u5f52\u7eb3\u5934\u5728\u89c4\u5219\u8865\u5168\u548c\u89c4\u5219\u94fe\u5f0f\u63a8\u7406\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u6a21\u578b\u786e\u5b9e\u80fd\u591f\u5b66\u4e60\u5e95\u5c42\u63a8\u7406\u89c4\u5219\uff0c\u800c\u975e\u4ec5\u8fdb\u884c\u7edf\u8ba1\u5b66\u4e60\u3002\u5f52\u7eb3\u5934\u5728\u5b9e\u73b0\u903b\u8f91\u63a8\u7406\u6240\u9700\u7684\u89c4\u5219\u8865\u5168\u548c\u89c4\u5219\u94fe\u5f0f\u6b65\u9aa4\u4e2d\u53d1\u6325\u6838\u5fc3\u4f5c\u7528\u3002", "conclusion": "\u5c0f\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u4e60\u5f97\u63a8\u7406\u89c4\u5219\u6765\u89e3\u51b3\u903b\u8f91\u4efb\u52a1\uff0c\u8fd9\u4e3a\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u673a\u5236\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u7279\u522b\u662f\u5f52\u7eb3\u5934\u5728\u903b\u8f91\u63a8\u7406\u4e2d\u7684\u5173\u952e\u529f\u80fd\u3002"}}
{"id": "2510.09373", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09373", "abs": "https://arxiv.org/abs/2510.09373", "authors": ["Augustin Delecluse", "Pierre Schaus", "Pascal Van Hentenryck"], "title": "Sequence Variables: A Constraint Programming Computational Domain for Routing and Sequencing", "comment": null, "summary": "Constraint Programming (CP) offers an intuitive, declarative framework for\nmodeling Vehicle Routing Problems (VRP), yet classical CP models based on\nsuccessor variables cannot always deal with optional visits or insertion based\nheuristics. To address these limitations, this paper formalizes sequence\nvariables within CP. Unlike the classical successor models, this computational\ndomain handle optional visits and support insertion heuristics, including\ninsertion-based Large Neighborhood Search. We provide a clear definition of\ntheir domain, update operations, and introduce consistency levels for\nconstraints on this domain. An implementation is described with the underlying\ndata structures required for integrating sequence variables into existing\ntrail-based CP solvers. Furthermore, global constraints specifically designed\nfor sequence variables and vehicle routing are introduced. Finally, the\neffectiveness of sequence variables is demonstrated by simplifying problem\nmodeling and achieving competitive computational performance on the Dial-a-Ride\nProblem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5e8f\u5217\u53d8\u91cf\u4f5c\u4e3a\u7ea6\u675f\u7f16\u7a0b\u4e2d\u5904\u7406\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u53ef\u9009\u8bbf\u95ee\u70b9\u5e76\u652f\u6301\u63d2\u5165\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u540e\u7ee7\u53d8\u91cf\u6a21\u578b\u5177\u6709\u66f4\u597d\u7684\u8868\u8fbe\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7ea6\u675f\u7f16\u7a0b\u4e2d\u57fa\u4e8e\u540e\u7ee7\u53d8\u91cf\u7684\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u4e2d\u7684\u53ef\u9009\u8bbf\u95ee\u70b9\u6216\u63d2\u5165\u5f0f\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u8fd9\u9650\u5236\u4e86CP\u5728VRP\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86\u5e8f\u5217\u53d8\u91cf\u7684\u8ba1\u7b97\u57df\u3001\u66f4\u65b0\u64cd\u4f5c\u548c\u4e00\u81f4\u6027\u7ea7\u522b\uff0c\u8bbe\u8ba1\u4e86\u4e13\u95e8\u7684\u6570\u636e\u7ed3\u6784\u548c\u5168\u5c40\u7ea6\u675f\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e0e\u73b0\u6709CP\u6c42\u89e3\u5668\u7684\u96c6\u6210\u3002", "result": "\u5e8f\u5217\u53d8\u91cf\u7b80\u5316\u4e86\u95ee\u9898\u5efa\u6a21\u8fc7\u7a0b\uff0c\u5e76\u5728Dial-a-Ride\u95ee\u9898\u4e0a\u5c55\u73b0\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u8ba1\u7b97\u6027\u80fd\u3002", "conclusion": "\u5e8f\u5217\u53d8\u91cf\u4e3a\u7ea6\u675f\u7f16\u7a0b\u5904\u7406\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u76f4\u89c2\u548c\u5f3a\u5927\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u652f\u6301\u53ef\u9009\u8bbf\u95ee\u548c\u63d2\u5165\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002"}}
{"id": "2510.09404", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09404", "abs": "https://arxiv.org/abs/2510.09404", "authors": ["Christian Bluethgen", "Dave Van Veen", "Daniel Truhn", "Jakob Nikolas Kather", "Michael Moor", "Malgorzata Polacin", "Akshay Chaudhari", "Thomas Frauenfelder", "Curtis P. Langlotz", "Michael Krauthammer", "Farhad Nooralahzadeh"], "title": "Agentic Systems in Radiology: Design, Applications, Evaluation, and Challenges", "comment": null, "summary": "Building agents, systems that perceive and act upon their environment with a\ndegree of autonomy, has long been a focus of AI research. This pursuit has\nrecently become vastly more practical with the emergence of large language\nmodels (LLMs) capable of using natural language to integrate information,\nfollow instructions, and perform forms of \"reasoning\" and planning across a\nwide range of tasks. With its multimodal data streams and orchestrated\nworkflows spanning multiple systems, radiology is uniquely suited to benefit\nfrom agents that can adapt to context and automate repetitive yet complex\ntasks. In radiology, LLMs and their multimodal variants have already\ndemonstrated promising performance for individual tasks such as information\nextraction and report summarization. However, using LLMs in isolation\nunderutilizes their potential to support complex, multi-step workflows where\ndecisions depend on evolving context from multiple information sources.\nEquipping LLMs with external tools and feedback mechanisms enables them to\ndrive systems that exhibit a spectrum of autonomy, ranging from semi-automated\nworkflows to more adaptive agents capable of managing complex processes. This\nreview examines the design of such LLM-driven agentic systems, highlights key\napplications, discusses evaluation methods for planning and tool use, and\noutlines challenges such as error cascades, tool-use efficiency, and health IT\nintegration.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u56de\u987e\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u5728\u653e\u5c04\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u4e86\u4ece\u534a\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u5230\u81ea\u9002\u5e94\u4ee3\u7406\u7684\u8bbe\u8ba1\u3001\u5e94\u7528\u3001\u8bc4\u4f30\u65b9\u6cd5\u548c\u6311\u6218\u3002", "motivation": "\u653e\u5c04\u5b66\u5177\u6709\u591a\u6a21\u6001\u6570\u636e\u6d41\u548c\u534f\u8c03\u5de5\u4f5c\u6d41\u7a0b\u7684\u7279\u70b9\uff0c\u975e\u5e38\u9002\u5408\u5229\u7528\u80fd\u591f\u9002\u5e94\u4e0a\u4e0b\u6587\u5e76\u81ea\u52a8\u5316\u91cd\u590d\u590d\u6742\u4efb\u52a1\u7684\u667a\u80fd\u4ee3\u7406\u3002\u867d\u7136LLM\u5728\u5355\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b64\u7acb\u4f7f\u7528\u65e0\u6cd5\u5145\u5206\u53d1\u6325\u5176\u5728\u590d\u6742\u591a\u6b65\u9aa4\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u4e3aLLM\u914d\u5907\u5916\u90e8\u5de5\u5177\u548c\u53cd\u9988\u673a\u5236\uff0c\u4f7f\u5176\u80fd\u591f\u9a71\u52a8\u8868\u73b0\u51fa\u4e0d\u540c\u7a0b\u5ea6\u81ea\u4e3b\u6027\u7684\u7cfb\u7edf\uff0c\u4ece\u534a\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u5230\u80fd\u591f\u7ba1\u7406\u590d\u6742\u8fc7\u7a0b\u7684\u81ea\u9002\u5e94\u4ee3\u7406\u3002", "result": "LLM\u9a71\u52a8\u7684\u4ee3\u7406\u7cfb\u7edf\u5728\u653e\u5c04\u5b66\u4e2d\u663e\u793a\u51fa\u652f\u6301\u590d\u6742\u3001\u591a\u6b65\u9aa4\u5de5\u4f5c\u6d41\u7a0b\u7684\u6f5c\u529b\uff0c\u5176\u4e2d\u51b3\u7b56\u4f9d\u8d56\u4e8e\u6765\u81ea\u591a\u4e2a\u4fe1\u606f\u6e90\u7684\u4e0d\u65ad\u6f14\u53d8\u7684\u4e0a\u4e0b\u6587\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u4ee3\u7406\u7cfb\u7edf\u4e3a\u653e\u5c04\u5b66\u63d0\u4f9b\u4e86\u4ece\u534a\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u5230\u81ea\u9002\u5e94\u4ee3\u7406\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u9762\u4e34\u9519\u8bef\u7ea7\u8054\u3001\u5de5\u5177\u4f7f\u7528\u6548\u7387\u548c\u5065\u5eb7IT\u96c6\u6210\u7b49\u6311\u6218\u3002"}}
{"id": "2510.09551", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09551", "abs": "https://arxiv.org/abs/2510.09551", "authors": ["Gavriel Di Nepi", "Federico Siciliano", "Fabrizio Silvestri"], "title": "Titans Revisited: A Lightweight Reimplementation and Critical Analysis of a Test-Time Memory Model", "comment": null, "summary": "By the end of 2024, Google researchers introduced Titans: Learning at Test\nTime, a neural memory model achieving strong empirical results across multiple\ntasks. However, the lack of publicly available code and ambiguities in the\noriginal description hinder reproducibility. In this work, we present a\nlightweight reimplementation of Titans and conduct a comprehensive evaluation\non Masked Language Modeling, Time Series Forecasting, and Recommendation tasks.\nOur results reveal that Titans does not always outperform established baselines\ndue to chunking. However, its Neural Memory component consistently improves\nperformance compared to attention-only models. These findings confirm the\nmodel's innovative potential while highlighting its practical limitations and\nraising questions for future research.", "AI": {"tldr": "\u5bf9Titans\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u91cd\u5b9e\u73b0\u4e0e\u8bc4\u4f30\uff0c\u53d1\u73b0\u5176\u795e\u7ecf\u8bb0\u5fc6\u7ec4\u4ef6\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u6574\u4f53\u8868\u73b0\u4e0d\u603b\u662f\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "Google\u63d0\u51fa\u7684Titans\u6a21\u578b\u7f3a\u4e4f\u516c\u5f00\u4ee3\u7801\u548c\u6e05\u6670\u63cf\u8ff0\uff0c\u963b\u788d\u4e86\u53ef\u590d\u73b0\u6027\uff0c\u56e0\u6b64\u8fdb\u884c\u91cd\u5b9e\u73b0\u548c\u5168\u9762\u8bc4\u4f30\u3002", "method": "\u5f00\u53d1\u4e86Titans\u7684\u8f7b\u91cf\u7ea7\u91cd\u5b9e\u73b0\uff0c\u5e76\u5728\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\u3001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u548c\u63a8\u8350\u4efb\u52a1\u4e0a\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\u3002", "result": "Titans\u56e0\u5206\u5757\u5904\u7406\u5e76\u4e0d\u603b\u662f\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4f46\u5176\u795e\u7ecf\u8bb0\u5fc6\u7ec4\u4ef6\u76f8\u6bd4\u4ec5\u4f7f\u7528\u6ce8\u610f\u529b\u7684\u6a21\u578b\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u786e\u8ba4\u4e86Titans\u6a21\u578b\u7684\u521b\u65b0\u6f5c\u529b\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u5b9e\u9645\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u51fa\u4e86\u95ee\u9898\u3002"}}
{"id": "2510.09567", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.09567", "abs": "https://arxiv.org/abs/2510.09567", "authors": ["Jacopo Tagliabue", "Ciro Greco"], "title": "Safe, Untrusted, \"Proof-Carrying\" AI Agents: toward the agentic lakehouse", "comment": "IEEE Big Data, Workshop on Secure and Safe AI Agents for Big Data\n  Infrastructures", "summary": "Data lakehouses run sensitive workloads, where AI-driven automation raises\nconcerns about trust, correctness, and governance. We argue that API-first,\nprogrammable lakehouses provide the right abstractions for safe-by-design,\nagentic workflows. Using Bauplan as a case study, we show how data branching\nand declarative environments extend naturally to agents, enabling\nreproducibility and observability while reducing the attack surface. We present\na proof-of-concept in which agents repair data pipelines using correctness\nchecks inspired by proof-carrying code. Our prototype demonstrates that\nuntrusted AI agents can operate safely on production data and outlines a path\ntoward a fully agentic lakehouse.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAPI\u4f18\u5148\u3001\u53ef\u7f16\u7a0b\u7684\u6570\u636e\u6e56\u4ed3\u5c4b\u4e3aAI\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u63d0\u4f9b\u5b89\u5168\u8bbe\u8ba1\uff0c\u901a\u8fc7\u6570\u636e\u5206\u652f\u548c\u58f0\u660e\u5f0f\u73af\u5883\u5b9e\u73b0\u53ef\u590d\u73b0\u6027\u548c\u53ef\u89c2\u6d4b\u6027\uff0c\u51cf\u5c11\u653b\u51fb\u9762\u3002", "motivation": "\u6570\u636e\u6e56\u4ed3\u5c4b\u8fd0\u884c\u654f\u611f\u5de5\u4f5c\u8d1f\u8f7d\uff0cAI\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u5f15\u53d1\u4e86\u5173\u4e8e\u4fe1\u4efb\u3001\u6b63\u786e\u6027\u548c\u6cbb\u7406\u7684\u62c5\u5fe7\uff0c\u9700\u8981\u5b89\u5168\u8bbe\u8ba1\u6765\u652f\u6301\u4ee3\u7406\u5de5\u4f5c\u6d41\u3002", "method": "\u4f7f\u7528Bauplan\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u6570\u636e\u5206\u652f\u548c\u58f0\u660e\u5f0f\u73af\u5883\u5982\u4f55\u81ea\u7136\u6269\u5c55\u5230\u4ee3\u7406\uff0c\u901a\u8fc7\u53d7\u8bc1\u660e\u643a\u5e26\u4ee3\u7801\u542f\u53d1\u7684\u6b63\u786e\u6027\u68c0\u67e5\u6765\u4fee\u590d\u6570\u636e\u7ba1\u9053\u3002", "result": "\u539f\u578b\u6f14\u793a\u8868\u660e\u4e0d\u53d7\u4fe1\u4efb\u7684AI\u4ee3\u7406\u53ef\u4ee5\u5728\u751f\u4ea7\u6570\u636e\u4e0a\u5b89\u5168\u64cd\u4f5c\uff0c\u5e76\u6982\u8ff0\u4e86\u5b9e\u73b0\u5b8c\u5168\u4ee3\u7406\u5316\u6e56\u4ed3\u5c4b\u7684\u8def\u5f84\u3002", "conclusion": "API\u4f18\u5148\u3001\u53ef\u7f16\u7a0b\u7684\u6e56\u4ed3\u5c4b\u4e3a\u5b89\u5168\u8bbe\u8ba1\u7684\u4ee3\u7406\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u5408\u9002\u7684\u62bd\u8c61\uff0c\u80fd\u591f\u5b9e\u73b0\u53ef\u590d\u73b0\u6027\u548c\u53ef\u89c2\u6d4b\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u653b\u51fb\u9762\u3002"}}
{"id": "2510.09580", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.09580", "abs": "https://arxiv.org/abs/2510.09580", "authors": ["Margarita Belova", "Jiaxin Xiao", "Shikhar Tuli", "Niraj K. Jha"], "title": "GraphMERT: Efficient and Scalable Distillation of Reliable Knowledge Graphs from Unstructured Data", "comment": null, "summary": "Researchers have pursued neurosymbolic artificial intelligence (AI)\napplications for nearly three decades because symbolic components provide\nabstraction while neural components provide generalization. Thus, a marriage of\nthe two components can lead to rapid advancements in AI. Yet, the field has not\nrealized this promise since most neurosymbolic AI frameworks fail to scale. In\naddition, the implicit representations and approximate reasoning of neural\napproaches limit interpretability and trust. Knowledge graphs (KGs), a\ngold-standard representation of explicit semantic knowledge, can address the\nsymbolic side. However, automatically deriving reliable KGs from text corpora\nhas remained an open problem. We address these challenges by introducing\nGraphMERT, a tiny graphical encoder-only model that distills high-quality KGs\nfrom unstructured text corpora and its own internal representations. GraphMERT\nand its equivalent KG form a modular neurosymbolic stack: neural learning of\nabstractions; symbolic KGs for verifiable reasoning. GraphMERT + KG is the\nfirst efficient and scalable neurosymbolic model to achieve state-of-the-art\nbenchmark accuracy along with superior symbolic representations relative to\nbaselines.\n  Concretely, we target reliable domain-specific KGs that are both (1) factual\n(with provenance) and (2) valid (ontology-consistent relations with\ndomain-appropriate semantics). When a large language model (LLM), e.g.,\nQwen3-32B, generates domain-specific KGs, it falls short on reliability due to\nprompt sensitivity, shallow domain expertise, and hallucinated relations. On\ntext obtained from PubMed papers on diabetes, our 80M-parameter GraphMERT\nyields a KG with a 69.8% FActScore; a 32B-parameter baseline LLM yields a KG\nthat achieves only 40.2% FActScore. The GraphMERT KG also attains a higher\nValidityScore of 68.8%, versus 43.0% for the LLM baseline.", "AI": {"tldr": "GraphMERT\u662f\u4e00\u4e2a\u5c0f\u578b\u56fe\u5f62\u7f16\u7801\u5668\u6a21\u578b\uff0c\u80fd\u591f\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u8bed\u6599\u5e93\u4e2d\u63d0\u53d6\u9ad8\u8d28\u91cf\u77e5\u8bc6\u56fe\u8c31\uff0c\u5f62\u6210\u6a21\u5757\u5316\u7684\u795e\u7ecf\u7b26\u53f7\u5806\u6808\uff0c\u5728\u4fdd\u6301\u6700\u5148\u8fdb\u57fa\u51c6\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7684\u7b26\u53f7\u8868\u793a\u3002", "motivation": "\u89e3\u51b3\u795e\u7ecf\u7b26\u53f7AI\u6846\u67b6\u96be\u4ee5\u6269\u5c55\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u795e\u7ecf\u65b9\u6cd5\u9690\u5f0f\u8868\u793a\u548c\u8fd1\u4f3c\u63a8\u7406\u5bfc\u81f4\u7684\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u9650\u5236\u3002\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u663e\u5f0f\u8bed\u4e49\u77e5\u8bc6\u7684\u9ec4\u91d1\u6807\u51c6\u8868\u793a\u53ef\u4ee5\u89e3\u51b3\u7b26\u53f7\u65b9\u9762\u7684\u95ee\u9898\uff0c\u4f46\u4ece\u6587\u672c\u8bed\u6599\u5e93\u81ea\u52a8\u63a8\u5bfc\u53ef\u9760\u77e5\u8bc6\u56fe\u8c31\u4e00\u76f4\u662f\u4e2a\u5f00\u653e\u95ee\u9898\u3002", "method": "\u5f15\u5165GraphMERT\uff0c\u4e00\u4e2a\u5fae\u5c0f\u7684\u56fe\u5f62\u7f16\u7801\u5668\u6a21\u578b\uff0c\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u8bed\u6599\u5e93\u53ca\u5176\u5185\u90e8\u8868\u793a\u4e2d\u63d0\u53d6\u9ad8\u8d28\u91cf\u77e5\u8bc6\u56fe\u8c31\u3002GraphMERT\u4e0e\u5176\u7b49\u6548\u7684\u77e5\u8bc6\u56fe\u8c31\u5f62\u6210\u6a21\u5757\u5316\u795e\u7ecf\u7b26\u53f7\u5806\u6808\uff1a\u795e\u7ecf\u5b66\u4e60\u62bd\u8c61\uff1b\u7b26\u53f7\u77e5\u8bc6\u56fe\u8c31\u7528\u4e8e\u53ef\u9a8c\u8bc1\u63a8\u7406\u3002", "result": "\u5728PubMed\u7cd6\u5c3f\u75c5\u8bba\u6587\u6587\u672c\u4e0a\uff0c80M\u53c2\u6570\u7684GraphMERT\u751f\u6210\u7684\u77e5\u8bc6\u56fe\u8c31\u8fbe\u523069.8%\u7684FActScore\uff0c\u800c32B\u53c2\u6570\u7684\u57fa\u7ebfLLM\u4ec5\u8fbe\u523040.2%\u3002GraphMERT\u77e5\u8bc6\u56fe\u8c31\u8fd8\u83b7\u5f9768.8%\u7684ValidityScore\uff0c\u800cLLM\u57fa\u7ebf\u4e3a43.0%\u3002", "conclusion": "GraphMERT+KG\u662f\u7b2c\u4e00\u4e2a\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\uff0c\u5728\u5b9e\u73b0\u6700\u5148\u8fdb\u57fa\u51c6\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u5177\u6709\u4f18\u8d8a\u7684\u7b26\u53f7\u8868\u793a\u80fd\u529b\u3002"}}
{"id": "2510.09595", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09595", "abs": "https://arxiv.org/abs/2510.09595", "authors": ["Kaijian Zou", "Aaron Xiong", "Yunxiang Zhang", "Frederick Zhang", "Yueqi Ren", "Jirong Yang", "Ayoung Lee", "Shitanshu Bhushan", "Lu Wang"], "title": "LiveOIBench: Can Large Language Models Outperform Human Contestants in Informatics Olympiads?", "comment": null, "summary": "Competitive programming problems increasingly serve as valuable benchmarks to\nevaluate the coding capabilities of large language models (LLMs) due to their\ncomplexity and ease of verification. Yet, current coding benchmarks face\nlimitations such as lack of exceptionally challenging problems, insufficient\ntest case coverage, reliance on online platform APIs that limit accessibility.\nTo address these issues, we introduce LiveOIBench, a comprehensive benchmark\nfeaturing 403 expert-curated Olympiad-level competitive programming problems,\neach with an average of 60 expert-designed test cases. The problems are sourced\ndirectly from 72 official Informatics Olympiads in different regions conducted\nbetween 2023 and 2025. LiveOIBench distinguishes itself through four key\nfeatures: (1) meticulously curated high-quality tasks with detailed subtask\nrubrics and extensive private test cases; (2) direct integration of elite\ncontestant performance data to enable informative comparison against\ntop-performing humans; (3) planned continuous, contamination-free updates from\nnewly released Olympiad problems; and (4) a self-contained evaluation system\nfacilitating offline and easy-to-reproduce assessments. Benchmarking 32 popular\ngeneral-purpose and reasoning LLMs, we find that GPT-5 achieves a notable\n81.76th percentile, a strong result that nonetheless falls short of top human\ncontestant performance, who usually place above 90th. In contrast, among\nopen-weight reasoning models, GPT-OSS-120B achieves only a 60th percentile,\nunderscoring significant capability disparities from frontier closed models.\nDetailed analyses indicate that robust reasoning models prioritize precise\nproblem analysis over excessive exploration, suggesting future models should\nemphasize structured analysis and minimize unnecessary exploration. All data,\ncode, and leaderboard results will be made publicly available on our website.", "AI": {"tldr": "LiveOIBench\u662f\u4e00\u4e2a\u5305\u542b403\u4e2a\u5965\u6797\u5339\u514b\u7ea7\u522b\u7f16\u7a0b\u7ade\u8d5b\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bcf\u4e2a\u95ee\u9898\u5e73\u5747\u670960\u4e2a\u4e13\u5bb6\u8bbe\u8ba1\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7f16\u7a0b\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7f16\u7a0b\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u7f3a\u4e4f\u9ad8\u96be\u5ea6\u95ee\u9898\u3001\u6d4b\u8bd5\u7528\u4f8b\u8986\u76d6\u4e0d\u8db3\u3001\u4f9d\u8d56\u5728\u7ebf\u5e73\u53f0API\u5bfc\u81f4\u53ef\u8bbf\u95ee\u6027\u5dee\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u4ece72\u4e2a\u5b98\u65b9\u4fe1\u606f\u5b66\u5965\u6797\u5339\u514b\u7ade\u8d5b\u4e2d\u6536\u96c6403\u4e2a\u4e13\u5bb6\u7b56\u5212\u7684\u95ee\u9898\uff0c\u6bcf\u4e2a\u95ee\u9898\u914d\u5907\u8be6\u7ec6\u5b50\u4efb\u52a1\u8bc4\u5206\u6807\u51c6\u548c\u5927\u91cf\u79c1\u6709\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5e76\u96c6\u6210\u7cbe\u82f1\u9009\u624b\u8868\u73b0\u6570\u636e\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728\u8bc4\u4f3032\u4e2a\u4e3b\u6d41LLM\u540e\uff0cGPT-5\u8fbe\u523081.76\u767e\u5206\u4f4d\u6570\uff0c\u8868\u73b0\u5f3a\u52b2\u4f46\u4ecd\u4e0d\u53ca\u9876\u5c16\u4eba\u7c7b\u9009\u624b\uff08\u901a\u5e38\u8d85\u8fc790\u767e\u5206\u4f4d\u6570\uff09\uff0c\u800c\u5f00\u6e90\u6a21\u578bGPT-OSS-120B\u4ec5\u8fbe60\u767e\u5206\u4f4d\u6570\u3002", "conclusion": "\u5f3a\u5927\u7684\u63a8\u7406\u6a21\u578b\u5e94\u4f18\u5148\u8fdb\u884c\u7cbe\u786e\u7684\u95ee\u9898\u5206\u6790\u800c\u975e\u8fc7\u5ea6\u63a2\u7d22\uff0c\u672a\u6765\u6a21\u578b\u5e94\u5f3a\u8c03\u7ed3\u6784\u5316\u5206\u6790\u5e76\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u63a2\u7d22\u3002\u6240\u6709\u6570\u636e\u3001\u4ee3\u7801\u548c\u6392\u884c\u699c\u7ed3\u679c\u5c06\u516c\u5f00\u3002"}}
