{"id": "2511.03931", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.03931", "abs": "https://arxiv.org/abs/2511.03931", "authors": ["Iman Adibnazari", "Harsh Sharma", "Myungsun Park", "Jacobo Cervera-Torralba", "Boris Kramer", "Michael T. Tolley"], "title": "Dynamic Shape Control of Soft Robots Enabled by Data-Driven Model Reduction", "comment": "20 Pages, 8 Figures", "summary": "Soft robots have shown immense promise in settings where they can leverage\ndynamic control of their entire bodies. However, effective dynamic shape\ncontrol requires a controller that accounts for the robot's high-dimensional\ndynamics--a challenge exacerbated by a lack of general-purpose tools for\nmodeling soft robots amenably for control. In this work, we conduct a\ncomparative study of data-driven model reduction techniques for generating\nlinear models amendable to dynamic shape control. We focus on three\nmethods--the eigensystem realization algorithm, dynamic mode decomposition with\ncontrol, and the Lagrangian operator inference (LOpInf) method. Using each\nclass of model, we explored their efficacy in model predictive control policies\nfor the dynamic shape control of a simulated eel-inspired soft robot in three\nexperiments: 1) tracking simulated reference trajectories guaranteed to be\nfeasible, 2) tracking reference trajectories generated from a biological model\nof eel kinematics, and 3) tracking reference trajectories generated by a\nreduced-scale physical analog. In all experiments, the LOpInf-based policies\ngenerated lower tracking errors than policies based on other models.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4e09\u79cd\u6570\u636e\u9a71\u52a8\u6a21\u578b\u964d\u9636\u6280\u672f\uff08ERA\u3001DMDc\u548cLOpInf\uff09\u5728\u8f6f\u4f53\u673a\u5668\u4eba\u52a8\u6001\u5f62\u72b6\u63a7\u5236\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u57fa\u4e8eLOpInf\u65b9\u6cd5\u7684\u63a7\u5236\u5668\u5728\u6240\u6709\u5b9e\u9a8c\u4e2d\u90fd\u80fd\u4ea7\u751f\u6700\u4f4e\u7684\u8ddf\u8e2a\u8bef\u5dee\u3002", "motivation": "\u8f6f\u4f53\u673a\u5668\u4eba\u9700\u8981\u80fd\u591f\u5904\u7406\u9ad8\u7ef4\u52a8\u6001\u7684\u63a7\u5236\u5668\uff0c\u4f46\u7f3a\u4e4f\u9002\u7528\u4e8e\u63a7\u5236\u7684\u901a\u7528\u5efa\u6a21\u5de5\u5177\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u6570\u636e\u9a71\u52a8\u7684\u6a21\u578b\u964d\u9636\u65b9\u6cd5\u6765\u751f\u6210\u9002\u5408\u52a8\u6001\u5f62\u72b6\u63a7\u5236\u7684\u7ebf\u6027\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u4e09\u79cd\u6570\u636e\u9a71\u52a8\u6a21\u578b\u964d\u9636\u6280\u672f\uff08\u7279\u5f81\u7cfb\u7edf\u5b9e\u73b0\u7b97\u6cd5\u3001\u5e26\u63a7\u5236\u7684\u52a8\u6001\u6a21\u6001\u5206\u89e3\u548c\u62c9\u683c\u6717\u65e5\u7b97\u5b50\u63a8\u65ad\u65b9\u6cd5\uff09\u751f\u6210\u7ebf\u6027\u6a21\u578b\uff0c\u5e76\u5728\u6a21\u62df\u7684\u9cd7\u9c7c\u542f\u53d1\u7684\u8f6f\u4f53\u673a\u5668\u4eba\u4e0a\u8fdb\u884c\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5b9e\u9a8c\u3002", "result": "\u5728\u6240\u6709\u4e09\u4e2a\u5b9e\u9a8c\u4e2d\uff08\u8ddf\u8e2a\u4fdd\u8bc1\u53ef\u884c\u7684\u6a21\u62df\u53c2\u8003\u8f68\u8ff9\u3001\u8ddf\u8e2a\u57fa\u4e8e\u9cd7\u9c7c\u8fd0\u52a8\u5b66\u751f\u7269\u6a21\u578b\u751f\u6210\u7684\u53c2\u8003\u8f68\u8ff9\u3001\u8ddf\u8e2a\u7531\u7f29\u5c0f\u7269\u7406\u6a21\u62df\u5668\u751f\u6210\u7684\u53c2\u8003\u8f68\u8ff9\uff09\uff0c\u57fa\u4e8eLOpInf\u65b9\u6cd5\u7684\u63a7\u5236\u7b56\u7565\u4ea7\u751f\u7684\u8ddf\u8e2a\u8bef\u5dee\u5747\u4f4e\u4e8e\u57fa\u4e8e\u5176\u4ed6\u6a21\u578b\u7684\u7b56\u7565\u3002", "conclusion": "LOpInf\u65b9\u6cd5\u5728\u8f6f\u4f53\u673a\u5668\u4eba\u52a8\u6001\u5f62\u72b6\u63a7\u5236\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4e3a\u8f6f\u4f53\u673a\u5668\u4eba\u7684\u9ad8\u7ef4\u52a8\u6001\u63a7\u5236\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6a21\u578b\u964d\u9636\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.03996", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.03996", "abs": "https://arxiv.org/abs/2511.03996", "authors": ["Yushi Wang", "Changsheng Luo", "Penghui Chen", "Jianran Liu", "Weijian Sun", "Tong Guo", "Kechang Yang", "Biao Hu", "Yangang Zhang", "Mingguo Zhao"], "title": "Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots", "comment": "Project page: https://humanoid-kick.github.io", "summary": "Humanoid soccer poses a representative challenge for embodied intelligence,\nrequiring robots to operate within a tightly coupled perception-action loop.\nHowever, existing systems typically rely on decoupled modules, resulting in\ndelayed responses and incoherent behaviors in dynamic environments, while\nreal-world perceptual limitations further exacerbate these issues. In this\nwork, we present a unified reinforcement learning-based controller that enables\nhumanoid robots to acquire reactive soccer skills through the direct\nintegration of visual perception and motion control. Our approach extends\nAdversarial Motion Priors to perceptual settings in real-world dynamic\nenvironments, bridging motion imitation and visually grounded dynamic control.\nWe introduce an encoder-decoder architecture combined with a virtual perception\nsystem that models real-world visual characteristics, allowing the policy to\nrecover privileged states from imperfect observations and establish active\ncoordination between perception and action. The resulting controller\ndemonstrates strong reactivity, consistently executing coherent and robust\nsoccer behaviors across various scenarios, including real RoboCup matches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7edf\u4e00\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u89c6\u89c9\u611f\u77e5\u4e0e\u8fd0\u52a8\u63a7\u5236\u7684\u76f4\u63a5\u96c6\u6210\uff0c\u4f7f\u4eba\u5f62\u673a\u5668\u4eba\u83b7\u5f97\u53cd\u5e94\u5f0f\u8db3\u7403\u6280\u80fd\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u901a\u5e38\u4f9d\u8d56\u89e3\u8026\u6a21\u5757\uff0c\u5bfc\u81f4\u52a8\u6001\u73af\u5883\u4e2d\u54cd\u5e94\u5ef6\u8fdf\u548c\u884c\u4e3a\u4e0d\u8fde\u8d2f\uff0c\u800c\u73b0\u5b9e\u4e16\u754c\u7684\u611f\u77e5\u9650\u5236\u8fdb\u4e00\u6b65\u52a0\u5267\u4e86\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u6269\u5c55Adversarial Motion Priors\u5230\u73b0\u5b9e\u52a8\u6001\u73af\u5883\u7684\u611f\u77e5\u8bbe\u7f6e\uff0c\u7ed3\u5408\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u548c\u865a\u62df\u611f\u77e5\u7cfb\u7edf\uff0c\u4ece\u6709\u7f3a\u9677\u7684\u89c2\u5bdf\u4e2d\u6062\u590d\u7279\u6743\u72b6\u6001\uff0c\u5efa\u7acb\u611f\u77e5\u4e0e\u52a8\u4f5c\u7684\u4e3b\u52a8\u534f\u8c03\u3002", "result": "\u63a7\u5236\u5668\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u53cd\u5e94\u80fd\u529b\uff0c\u5728\u5404\u79cd\u573a\u666f\uff08\u5305\u62ec\u771f\u5b9eRoboCup\u6bd4\u8d5b\uff09\u4e2d\u6301\u7eed\u6267\u884c\u8fde\u8d2f\u4e14\u7a33\u5065\u7684\u8db3\u7403\u884c\u4e3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u89c6\u89c9\u611f\u77e5\u4e0e\u8fd0\u52a8\u63a7\u5236\u7684\u7edf\u4e00\uff0c\u4e3a\u4eba\u5f62\u673a\u5668\u4eba\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u53cd\u5e94\u5f0f\u884c\u4e3a\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.04009", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04009", "abs": "https://arxiv.org/abs/2511.04009", "authors": ["Chenzui Li", "Yiming Chen", "Xi Wu", "Giacinto Barresi", "Fei Chen"], "title": "Integrating Ergonomics and Manipulability for Upper Limb Postural Optimization in Bimanual Human-Robot Collaboration", "comment": "7 pages, 7 figures, IROS 2025 accepted", "summary": "This paper introduces an upper limb postural optimization method for\nenhancing physical ergonomics and force manipulability during bimanual\nhuman-robot co-carrying tasks. Existing research typically emphasizes human\nsafety or manipulative efficiency, whereas our proposed method uniquely\nintegrates both aspects to strengthen collaboration across diverse conditions\n(e.g., different grasping postures of humans, and different shapes of objects).\nSpecifically, the joint angles of a simplified human skeleton model are\noptimized by minimizing the cost function to prioritize safety and manipulative\ncapability. To guide humans towards the optimized posture, the reference\nend-effector poses of the robot are generated through a transformation module.\nA bimanual model predictive impedance controller (MPIC) is proposed for our\nhuman-like robot, CURI, to recalibrate the end effector poses through planned\ntrajectories. The proposed method has been validated through various subjects\nand objects during human-human collaboration (HHC) and human-robot\ncollaboration (HRC). The experimental results demonstrate significant\nimprovement in muscle conditions by comparing the activation of target muscles\nbefore and after optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4e0a\u80a2\u59ff\u6001\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347\u53cc\u4eba/\u4eba\u673a\u534f\u540c\u642c\u8fd0\u4efb\u52a1\u4e2d\u7684\u7269\u7406\u5de5\u6548\u5b66\u548c\u529b\u64cd\u7eb5\u80fd\u529b\uff0c\u901a\u8fc7\u4f18\u5316\u5173\u8282\u89d2\u5ea6\u548c\u673a\u5668\u4eba\u672b\u7aef\u6267\u884c\u5668\u59ff\u6001\u6765\u540c\u65f6\u4fdd\u969c\u5b89\u5168\u6027\u548c\u64cd\u4f5c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u901a\u5e38\u53ea\u5173\u6ce8\u4eba\u7c7b\u5b89\u5168\u6216\u64cd\u4f5c\u6548\u7387\uff0c\u800c\u8be5\u65b9\u6cd5\u72ec\u7279\u5730\u5c06\u8fd9\u4e24\u4e2a\u65b9\u9762\u6574\u5408\uff0c\u4ee5\u52a0\u5f3a\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u534f\u4f5c\u80fd\u529b\uff08\u5982\u4e0d\u540c\u7684\u4eba\u7c7b\u6293\u63e1\u59ff\u52bf\u548c\u7269\u4f53\u5f62\u72b6\uff09\u3002", "method": "\u901a\u8fc7\u6700\u5c0f\u5316\u4ee3\u4ef7\u51fd\u6570\u4f18\u5316\u7b80\u5316\u4eba\u4f53\u9aa8\u9abc\u6a21\u578b\u7684\u5173\u8282\u89d2\u5ea6\uff0c\u4f18\u5148\u8003\u8651\u5b89\u5168\u6027\u548c\u64cd\u7eb5\u80fd\u529b\uff1b\u901a\u8fc7\u53d8\u6362\u6a21\u5757\u751f\u6210\u673a\u5668\u4eba\u672b\u7aef\u6267\u884c\u5668\u7684\u53c2\u8003\u59ff\u6001\uff1b\u63d0\u51fa\u53cc\u6a21\u578b\u9884\u6d4b\u963b\u6297\u63a7\u5236\u5668\uff08MPIC\uff09\u6765\u91cd\u65b0\u6821\u51c6\u672b\u7aef\u6267\u884c\u5668\u59ff\u6001\u3002", "result": "\u5728\u4eba\u7c7b-\u4eba\u7c7b\u534f\u4f5c\uff08HHC\uff09\u548c\u4eba\u7c7b-\u673a\u5668\u4eba\u534f\u4f5c\uff08HRC\uff09\u4e2d\u901a\u8fc7\u591a\u4e2a\u53d7\u8bd5\u8005\u548c\u7269\u4f53\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u76ee\u6807\u808c\u8089\u6fc0\u6d3b\u72b6\u6001\u5728\u4f18\u5316\u524d\u540e\u6709\u663e\u8457\u6539\u5584\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u6539\u5584\u4e86\u808c\u8089\u72b6\u51b5\uff0c\u8bc1\u660e\u4e86\u5728\u53cc\u4eba/\u4eba\u673a\u534f\u540c\u642c\u8fd0\u4efb\u52a1\u4e2d\u540c\u65f6\u4f18\u5316\u5b89\u5168\u6027\u548c\u64cd\u4f5c\u6548\u7387\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.04042", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04042", "abs": "https://arxiv.org/abs/2511.04042", "authors": ["Kailun Ji", "Xiaoyu Hu", "Xinyu Zhang", "Jun Chen"], "title": "An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster Search and Rescue", "comment": null, "summary": "Large-scale disaster Search And Rescue (SAR) operations are persistently\nchallenged by complex terrain and disrupted communications. While Unmanned\nAerial Vehicle (UAV) swarms offer a promising solution for tasks like wide-area\nsearch and supply delivery, yet their effective coordination places a\nsignificant cognitive burden on human operators. The core human-machine\ncollaboration bottleneck lies in the ``intention-to-action gap'', which is an\nerror-prone process of translating a high-level rescue objective into a\nlow-level swarm command under high intensity and pressure. To bridge this gap,\nthis study proposes a novel LLM-CRF system that leverages Large Language Models\n(LLMs) to model and augment human-swarm teaming cognition. The proposed\nframework initially captures the operator's intention through natural and\nmulti-modal interactions with the device via voice or graphical annotations. It\nthen employs the LLM as a cognitive engine to perform intention comprehension,\nhierarchical task decomposition, and mission planning for the UAV swarm. This\nclosed-loop framework enables the swarm to act as a proactive partner,\nproviding active feedback in real-time while reducing the need for manual\nmonitoring and control, which considerably advances the efficacy of the SAR\ntask. We evaluate the proposed framework in a simulated SAR scenario.\nExperimental results demonstrate that, compared to traditional order and\ncommand-based interfaces, the proposed LLM-driven approach reduced task\ncompletion time by approximately $64.2\\%$ and improved task success rate by\n$7\\%$. It also leads to a considerable reduction in subjective cognitive\nworkload, with NASA-TLX scores dropping by $42.9\\%$. This work establishes the\npotential of LLMs to create more intuitive and effective human-swarm\ncollaborations in high-stakes scenarios.", "AI": {"tldr": "\u63d0\u51faLLM-CRF\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u4eba\u673a\u534f\u4f5c\u8ba4\u77e5\uff0c\u901a\u8fc7\u81ea\u7136\u4ea4\u4e92\u6355\u6349\u64cd\u4f5c\u5458\u610f\u56fe\uff0c\u81ea\u52a8\u5206\u89e3\u4efb\u52a1\u89c4\u5212\u65e0\u4eba\u673a\u7fa4\u884c\u52a8\uff0c\u663e\u8457\u63d0\u5347\u641c\u6551\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u707e\u96be\u641c\u6551\u4e2d\u4eba\u673a\u534f\u4f5c\u7684\"\u610f\u56fe\u5230\u884c\u52a8\u5dee\u8ddd\"\u95ee\u9898\uff0c\u4f20\u7edf\u65e0\u4eba\u673a\u7fa4\u534f\u8c03\u7ed9\u64cd\u4f5c\u5458\u5e26\u6765\u5de8\u5927\u8ba4\u77e5\u8d1f\u62c5\uff0c\u9700\u8981\u66f4\u76f4\u89c2\u9ad8\u6548\u7684\u4eba\u673a\u4ea4\u4e92\u65b9\u5f0f\u3002", "method": "\u6784\u5efaLLM-CRF\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u97f3\u6216\u56fe\u5f62\u6807\u6ce8\u591a\u6a21\u6001\u4ea4\u4e92\u6355\u6349\u64cd\u4f5c\u5458\u610f\u56fe\uff0c\u4f7f\u7528LLM\u4f5c\u4e3a\u8ba4\u77e5\u5f15\u64ce\u8fdb\u884c\u610f\u56fe\u7406\u89e3\u3001\u5206\u5c42\u4efb\u52a1\u5206\u89e3\u548c\u4efb\u52a1\u89c4\u5212\uff0c\u5f62\u6210\u95ed\u73af\u53cd\u9988\u7cfb\u7edf\u3002", "result": "\u5728\u6a21\u62df\u641c\u6551\u573a\u666f\u4e2d\uff0c\u76f8\u6bd4\u4f20\u7edf\u547d\u4ee4\u63a5\u53e3\uff0c\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u51cf\u5c1164.2%\uff0c\u4efb\u52a1\u6210\u529f\u7387\u63d0\u9ad87%\uff0cNASA-TLX\u8ba4\u77e5\u8d1f\u8377\u8bc4\u5206\u4e0b\u964d42.9%\u3002", "conclusion": "LLM\u80fd\u591f\u521b\u5efa\u66f4\u76f4\u89c2\u6709\u6548\u7684\u4eba\u673a\u534f\u4f5c\u7cfb\u7edf\uff0c\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u663e\u8457\u63d0\u5347\u641c\u6551\u4efb\u52a1\u6548\u80fd\u3002"}}
{"id": "2511.03859", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03859", "abs": "https://arxiv.org/abs/2511.03859", "authors": ["Tammy Mackenzie", "Sukriti Punj", "Natalie Perez", "Sreyoshi Bhaduri", "Branislav Radeljic"], "title": "Levers of Power in the Field of AI", "comment": "18 pages, research submission", "summary": "This paper examines how decision makers in academia, government, business,\nand civil society navigate questions of power in implementations of artificial\nintelligence. The study explores how individuals experience and exercise levers\nof power, which are presented as social mechanisms that shape institutional\nresponses to technological change. The study reports on the responses of\npersonalized questionnaires designed to gather insight on a decision maker's\ninstitutional purview, based on an institutional governance framework developed\nfrom the work of Neo-institutionalists. Findings present the anonymized, real\nresponses and circumstances of respondents in the form of twelve fictional\npersonas of high-level decision makers from North America and Europe. These\npersonas illustrate how personal agency, organizational logics, and\ninstitutional infrastructures may intersect in the governance of AI. The\ndecision makers' responses to the questionnaires then inform a discussion of\nthe field-level personal power of decision makers, methods of fostering\ninstitutional stability in times of change, and methods of influencing\ninstitutional change in the field of AI. The final section of the discussion\npresents a table of the dynamics of the levers of power in the field of AI for\nchange makers and five testable hypotheses for institutional and social\nmovement researchers. In summary, this study provides insight on the means for\npolicymakers within institutions and their counterparts in civil society to\npersonally engage with AI governance.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u95ee\u5377\u8c03\u67e5\u5206\u6790\u51b3\u7b56\u8005\u5728AI\u5b9e\u65bd\u4e2d\u5982\u4f55\u8fd0\u7528\u6743\u529b\u6760\u6746\uff0c\u521b\u5efa\u4e8612\u4e2a\u865a\u6784\u4eba\u7269\u89d2\u8272\u6765\u5c55\u793a\u4e2a\u4eba\u80fd\u52a8\u6027\u3001\u7ec4\u7ec7\u903b\u8f91\u548c\u5236\u5ea6\u57fa\u7840\u8bbe\u65bd\u5728AI\u6cbb\u7406\u4e2d\u7684\u4ea4\u96c6\u3002", "motivation": "\u63a2\u8ba8\u5b66\u672f\u754c\u3001\u653f\u5e9c\u3001\u4f01\u4e1a\u548c\u516c\u6c11\u793e\u4f1a\u7684\u51b3\u7b56\u8005\u5982\u4f55\u5728\u4eba\u5de5\u667a\u80fd\u5b9e\u65bd\u8fc7\u7a0b\u4e2d\u5904\u7406\u6743\u529b\u95ee\u9898\uff0c\u4e86\u89e3\u4ed6\u4eec\u5982\u4f55\u4f53\u9a8c\u548c\u8fd0\u7528\u6743\u529b\u6760\u6746\u6765\u5851\u9020\u5bf9\u6280\u672f\u53d8\u9769\u7684\u5236\u5ea6\u54cd\u5e94\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u65b0\u5236\u5ea6\u4e3b\u4e49\u7406\u8bba\u5f00\u53d1\u7684\u5236\u5ea6\u6cbb\u7406\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e2a\u6027\u5316\u95ee\u5377\u6536\u96c6\u51b3\u7b56\u8005\u7684\u5236\u5ea6\u7ba1\u8f96\u8303\u56f4\u89c1\u89e3\uff0c\u5e76\u5c06\u53d7\u8bbf\u8005\u7684\u533f\u540d\u771f\u5b9e\u56de\u5e94\u8f6c\u5316\u4e3a12\u4e2a\u865a\u6784\u7684\u9ad8\u5c42\u51b3\u7b56\u8005\u4eba\u7269\u89d2\u8272\u3002", "result": "\u5c55\u793a\u4e86\u5317\u7f8e\u548c\u6b27\u6d32\u51b3\u7b56\u8005\u768412\u4e2a\u865a\u6784\u4eba\u7269\u89d2\u8272\uff0c\u63ed\u793a\u4e86\u4e2a\u4eba\u80fd\u52a8\u6027\u3001\u7ec4\u7ec7\u903b\u8f91\u548c\u5236\u5ea6\u57fa\u7840\u8bbe\u65bd\u5728AI\u6cbb\u7406\u4e2d\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u6743\u529b\u6760\u6746\u52a8\u6001\u8868\u548c\u4e94\u4e2a\u53ef\u68c0\u9a8c\u5047\u8bbe\u3002", "conclusion": "\u4e3a\u5236\u5ea6\u5185\u7684\u653f\u7b56\u5236\u5b9a\u8005\u548c\u516c\u6c11\u793e\u4f1a\u4e2d\u7684\u540c\u884c\u63d0\u4f9b\u4e86\u4e2a\u4eba\u53c2\u4e0eAI\u6cbb\u7406\u7684\u65b9\u6cd5\u89c1\u89e3\uff0c\u5305\u62ec\u4fc3\u8fdb\u5236\u5ea6\u7a33\u5b9a\u548c\u5f71\u54cd\u5236\u5ea6\u53d8\u9769\u7684\u7b56\u7565\u3002"}}
{"id": "2511.04299", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.04299", "abs": "https://arxiv.org/abs/2511.04299", "authors": ["Elliot Beck", "Franziska Eckert", "Linus K\u00fchne", "Helge Liebert", "Rina Rosenblatt-Wisch"], "title": "Measuring economic outlook in the news timely and efficiently", "comment": null, "summary": "We introduce a novel indicator that combines machine learning and large\nlanguage models with traditional statistical methods to track sentiment\nregarding the economic outlook in Swiss news. The indicator is interpretable\nand timely, and it significantly improves the accuracy of GDP growth forecasts.\nOur approach is resource-efficient, modular, and offers a way of benefitting\nfrom state-of-the-art large language models even if data are proprietary and\ncannot be stored or analyzed on external infrastructure - a restriction faced\nby many central banks and public institutions.", "AI": {"tldr": "\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u4f20\u7edf\u7edf\u8ba1\u65b9\u6cd5\uff0c\u5f00\u53d1\u53ef\u89e3\u91ca\u3001\u53ca\u65f6\u7684\u7ecf\u6d4e\u60c5\u7eea\u6307\u6807\uff0c\u663e\u8457\u63d0\u5347GDP\u589e\u957f\u9884\u6d4b\u51c6\u786e\u6027", "motivation": "\u4e3a\u592e\u884c\u548c\u516c\u5171\u673a\u6784\u63d0\u4f9b\u8d44\u6e90\u9ad8\u6548\u3001\u6a21\u5757\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u5176\u80fd\u5728\u6570\u636e\u4fdd\u5bc6\u9650\u5236\u4e0b\u5229\u7528\u5148\u8fdb\u8bed\u8a00\u6a21\u578b\u5206\u6790\u7ecf\u6d4e\u60c5\u7eea", "method": "\u5c06\u673a\u5668\u5b66\u4e60\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u4f20\u7edf\u7edf\u8ba1\u65b9\u6cd5\u76f8\u7ed3\u5408\uff0c\u6784\u5efa\u53ef\u89e3\u91ca\u7684\u7ecf\u6d4e\u60c5\u7eea\u8ffd\u8e2a\u6307\u6807", "result": "\u8be5\u6307\u6807\u663e\u8457\u63d0\u9ad8\u4e86GDP\u589e\u957f\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u4e14\u5177\u6709\u65f6\u6548\u6027\u548c\u53ef\u89e3\u91ca\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u53d7\u6570\u636e\u4fdd\u5bc6\u9650\u5236\u7684\u673a\u6784\u63d0\u4f9b\u4e86\u5229\u7528\u5148\u8fdb\u8bed\u8a00\u6a21\u578b\u7684\u6709\u6548\u9014\u5f84\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u5b9e\u73b0\u4e86\u7ecf\u6d4e\u60c5\u7eea\u5206\u6790\u7684\u6280\u672f\u7a81\u7834"}}
{"id": "2511.04127", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2511.04127", "abs": "https://arxiv.org/abs/2511.04127", "authors": ["Xiaojun Song", "Jichao Yuan"], "title": "Specification tests for regression models with measurement errors", "comment": null, "summary": "In this paper, we propose new specification tests for regression models with\nmeasurement errors in the explanatory variables. Inspired by the integrated\nconditional moment (ICM) approach, we use a deconvoluted residual-marked\nempirical process and construct ICM-type test statistics based on it. The issue\nof measurement errors is addressed by applying a deconvolution kernel estimator\nin constructing the residuals. We demonstrate that employing an orthogonal\nprojection onto the tangent space of nuisance parameters not only eliminates\nthe parameter estimation effect but also facilitates the simulation of critical\nvalues via a computationally simple multiplier bootstrap procedure. It is the\nfirst time a multiplier bootstrap has been proposed in the literature of\nspecification testing with measurement errors. We also develop specification\ntests and the multiplier bootstrap procedure when the measurement error\ndistribution is unknown. The finite-sample performance of the proposed tests\nfor both known and unknown measurement error distributions is evaluated through\nMonte Carlo simulations, which demonstrate their efficacy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9488\u5bf9\u542b\u6d4b\u91cf\u8bef\u5dee\u56de\u5f52\u6a21\u578b\u7684\u65b0\u89c4\u8303\u68c0\u9a8c\u65b9\u6cd5\uff0c\u57fa\u4e8e\u53bb\u5377\u79ef\u6b8b\u5dee\u6807\u8bb0\u7ecf\u9a8c\u8fc7\u7a0b\u548cICM\u65b9\u6cd5\uff0c\u9996\u6b21\u5728\u6d4b\u91cf\u8bef\u5dee\u89c4\u8303\u68c0\u9a8c\u4e2d\u5f15\u5165\u4e58\u6570bootstrap\uff0c\u5e76\u5904\u7406\u4e86\u5df2\u77e5\u548c\u672a\u77e5\u6d4b\u91cf\u8bef\u5dee\u5206\u5e03\u7684\u60c5\u51b5\u3002", "motivation": "\u5728\u56de\u5f52\u6a21\u578b\u4e2d\uff0c\u89e3\u91ca\u53d8\u91cf\u7684\u6d4b\u91cf\u8bef\u5dee\u4f1a\u5f71\u54cd\u6a21\u578b\u89c4\u8303\u68c0\u9a8c\u7684\u6709\u6548\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u6d4b\u91cf\u8bef\u5dee\u5b58\u5728\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u68c0\u9a8c\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u53bb\u5377\u79ef\u6838\u4f30\u8ba1\u5668\u6784\u5efa\u6b8b\u5dee\uff0c\u57fa\u4e8e\u53bb\u5377\u79ef\u6b8b\u5dee\u6807\u8bb0\u7ecf\u9a8c\u8fc7\u7a0b\u6784\u9020ICM\u578b\u68c0\u9a8c\u7edf\u8ba1\u91cf\uff0c\u901a\u8fc7\u6b63\u4ea4\u6295\u5f71\u6d88\u9664\u53c2\u6570\u4f30\u8ba1\u6548\u5e94\uff0c\u91c7\u7528\u4e58\u6570bootstrap\u6a21\u62df\u4e34\u754c\u503c\u3002", "result": "\u8499\u7279\u5361\u6d1b\u6a21\u62df\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u68c0\u9a8c\u65b9\u6cd5\u5728\u6709\u9650\u6837\u672c\u4e0b\u5bf9\u5df2\u77e5\u548c\u672a\u77e5\u6d4b\u91cf\u8bef\u5dee\u5206\u5e03\u90fd\u5177\u6709\u826f\u597d\u6027\u80fd\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u9002\u7528\u4e8e\u542b\u6d4b\u91cf\u8bef\u5dee\u56de\u5f52\u6a21\u578b\u7684\u89c4\u8303\u68c0\u9a8c\u6846\u67b6\uff0c\u9996\u6b21\u5f15\u5165\u4e58\u6570bootstrap\uff0c\u4e3a\u6d4b\u91cf\u8bef\u5dee\u4e0b\u7684\u6a21\u578b\u68c0\u9a8c\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2511.03813", "categories": ["econ.TH", "econ.EM"], "pdf": "https://arxiv.org/pdf/2511.03813", "abs": "https://arxiv.org/abs/2511.03813", "authors": ["Kaushil Patel"], "title": "Price-Based Attention and Welfare", "comment": null, "summary": "To choose between two discrete goods, a consumer pays attention to only those\nwith prices below a threshold. From these, she chooses her most preferred good.\nWe assume consumers in a population have the same preference but may have\ndifferent thresholds. Similar models of bounded rationality have been studied\nin the empirical marketing literature. We fully characterize the model, and\nusing observational choice data alone, we identify the welfare implications of\na price change. The behavioral content of our model overlaps with an important\nclass of random utility models, but the welfare implications are meaningfully\ndifferent. The distribution of equivalent variation under our model first-order\nstochastically dominates that under the random utility model.", "AI": {"tldr": "\u6d88\u8d39\u8005\u5728\u79bb\u6563\u5546\u54c1\u9009\u62e9\u4e2d\u53ea\u5173\u6ce8\u4ef7\u683c\u4f4e\u4e8e\u9608\u503c\u7684\u5546\u54c1\uff0c\u7136\u540e\u4ece\u4e2d\u9009\u62e9\u6700\u504f\u597d\u7684\u5546\u54c1\u3002\u6a21\u578b\u5047\u8bbe\u6d88\u8d39\u8005\u6709\u76f8\u540c\u504f\u597d\u4f46\u4e0d\u540c\u9608\u503c\uff0c\u80fd\u591f\u4ec5\u901a\u8fc7\u89c2\u5bdf\u6570\u636e\u8bc6\u522b\u4ef7\u683c\u53d8\u5316\u7684\u798f\u5229\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u6709\u9650\u7406\u6027\u6d88\u8d39\u8005\u5728\u79bb\u6563\u5546\u54c1\u9009\u62e9\u4e2d\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u7279\u522b\u662f\u4ef7\u683c\u9608\u503c\u5bf9\u9009\u62e9\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u8fd9\u79cd\u9009\u62e9\u884c\u4e3a\u4e0e\u968f\u673a\u6548\u7528\u6a21\u578b\u5728\u798f\u5229\u5206\u6790\u4e0a\u7684\u5dee\u5f02\u3002", "method": "\u6784\u5efa\u6d88\u8d39\u8005\u9009\u62e9\u6a21\u578b\uff0c\u5047\u8bbe\u6d88\u8d39\u8005\u53ea\u8003\u8651\u4ef7\u683c\u4f4e\u4e8e\u4e2a\u4eba\u9608\u503c\u7684\u5546\u54c1\uff0c\u7136\u540e\u4ece\u4e2d\u9009\u62e9\u6700\u504f\u597d\u7684\u5546\u54c1\u3002\u4f7f\u7528\u89c2\u5bdf\u6027\u9009\u62e9\u6570\u636e\u6765\u8bc6\u522b\u4ef7\u683c\u53d8\u5316\u7684\u798f\u5229\u5f71\u54cd\u3002", "result": "\u8be5\u6a21\u578b\u7684\u884c\u4e3a\u5185\u5bb9\u4e0e\u91cd\u8981\u7684\u4e00\u7c7b\u968f\u673a\u6548\u7528\u6a21\u578b\u6709\u91cd\u53e0\uff0c\u4f46\u798f\u5229\u542b\u4e49\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u5728\u8be5\u6a21\u578b\u4e0b\u7684\u7b49\u4ef7\u53d8\u5dee\u5206\u5e03\u4e00\u9636\u968f\u673a\u5360\u4f18\u4e8e\u968f\u673a\u6548\u7528\u6a21\u578b\u4e0b\u7684\u5206\u5e03\u3002", "conclusion": "\u4ef7\u683c\u9608\u503c\u6a21\u578b\u63d0\u4f9b\u4e86\u4e0e\u968f\u673a\u6548\u7528\u6a21\u578b\u4e0d\u540c\u7684\u798f\u5229\u5206\u6790\u89c6\u89d2\uff0c\u8868\u660e\u8003\u8651\u6d88\u8d39\u8005\u6709\u9650\u7406\u6027\u7279\u5f81\u5bf9\u798f\u5229\u8bc4\u4f30\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2511.03734", "categories": ["eess.SY", "cs.SY", "math.DS", "93B30, 15A18, 93C10, 37M25"], "pdf": "https://arxiv.org/pdf/2511.03734", "abs": "https://arxiv.org/abs/2511.03734", "authors": ["Philipp Schmitz", "Lea Bold", "Friedrich M. Philipp", "Mario Rosenfelder", "Peter Eberhard", "Henrik Ebel", "Karl Worthmann"], "title": "On excitation of control-affine systems and its use for data-driven Koopman approximants", "comment": null, "summary": "The Koopman operator and extended dynamic mode decomposition (EDMD) as a\ndata-driven technique for its approximation have attracted considerable\nattention as a key tool for modeling, analysis, and control of complex\ndynamical systems. However, extensions towards control-affine systems resulting\nin bilinear surrogate models are prone to demanding data requirements rendering\ntheir applicability intricate. In this paper, we propose a framework for\ndata-fitting of control-affine mappings to increase the robustness margin in\nthe associated system identification problem and, thus, to provide more\nreliable bilinear EDMD schemes. In particular, guidelines for input selection\nbased on subspace angles are deduced such that a desired threshold with respect\nto the minimal singular value is ensured. Moreover, we derive necessary and\nsufficient conditions of optimality for maximizing the minimal singular value.\nFurther, we demonstrate the usefulness of the proposed approach using bilinear\nEDMD with control for non-holonomic robots.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u63a7\u5236\u4eff\u5c04\u7cfb\u7edf\u7684\u6570\u636e\u62df\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u5b50\u7a7a\u95f4\u89d2\u5ea6\u7684\u8f93\u5165\u9009\u62e9\u6765\u63d0\u9ad8\u7cfb\u7edf\u8fa8\u8bc6\u7684\u9c81\u68d2\u6027\uff0c\u4ece\u800c\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u53cc\u7ebf\u6027EDMD\u65b9\u6848\u3002", "motivation": "\u63a7\u5236\u4eff\u5c04\u7cfb\u7edf\u7684Koopman\u7b97\u5b50\u548cEDMD\u65b9\u6cd5\u5728\u5efa\u6a21\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u65f6\u9762\u4e34\u6570\u636e\u9700\u6c42\u9ad8\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u5176\u5e94\u7528\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5b50\u7a7a\u95f4\u89d2\u5ea6\u7684\u8f93\u5165\u9009\u62e9\u6846\u67b6\uff0c\u786e\u4fdd\u6700\u5c0f\u5947\u5f02\u503c\u8fbe\u5230\u671f\u671b\u9608\u503c\uff0c\u5e76\u63a8\u5bfc\u4e86\u6700\u5927\u5316\u6700\u5c0f\u5947\u5f02\u503c\u7684\u6700\u4f18\u6027\u6761\u4ef6\u3002", "result": "\u901a\u8fc7\u975e\u5b8c\u6574\u673a\u5668\u4eba\u7684\u53cc\u7ebf\u6027EDMD\u63a7\u5236\u5e94\u7528\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u63a7\u5236\u4eff\u5c04\u7cfb\u7edf\u8fa8\u8bc6\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u53cc\u7ebf\u6027EDMD\u65b9\u6848\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u5b9e\u73b0\u9014\u5f84\u3002"}}
{"id": "2511.03747", "categories": ["cs.ET", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03747", "abs": "https://arxiv.org/abs/2511.03747", "authors": ["Ali Safa", "Farida Mohsen", "Zainab Ali", "Bo Wang", "Amine Bermak"], "title": "OpenMENA: An Open-Source Memristor Interfacing and Compute Board for Neuromorphic Edge-AI Applications", "comment": null, "summary": "Memristive crossbars enable in-memory multiply-accumulate and local\nplasticity learning, offering a path to energy-efficient edge AI. To this end,\nwe present Open-MENA (Open Memristor-in-Memory Accelerator), which, to our\nknowledge, is the first fully open memristor interfacing system integrating (i)\na reproducible hardware interface for memristor crossbars with mixed-signal\nread-program-verify loops; (ii) a firmware-software stack with high-level APIs\nfor inference and on-device learning; and (iii) a Voltage-Incremental\nProportional-Integral (VIPI) method to program pre-trained weights into analog\nconductances, followed by chip-in-the-loop fine-tuning to mitigate device\nnon-idealities. OpenMENA is validated on digit recognition, demonstrating the\nflow from weight transfer to on-device adaptation, and on a real-world robot\nobstacle-avoidance task, where the memristor-based model learns to map\nlocalization inputs to motor commands. OpenMENA is released as open source to\ndemocratize memristor-enabled edge-AI research.", "AI": {"tldr": "OpenMENA\u662f\u9996\u4e2a\u5b8c\u5168\u5f00\u6e90\u7684\u5fc6\u963b\u5668\u5185\u5b58\u8ba1\u7b97\u52a0\u901f\u5668\u7cfb\u7edf\uff0c\u96c6\u6210\u4e86\u786c\u4ef6\u63a5\u53e3\u3001\u56fa\u4ef6\u8f6f\u4ef6\u6808\u548cVIPI\u6743\u91cd\u7f16\u7a0b\u65b9\u6cd5\uff0c\u652f\u6301\u63a8\u7406\u548c\u7247\u4e0a\u5b66\u4e60\uff0c\u5e76\u5728\u6570\u5b57\u8bc6\u522b\u548c\u673a\u5668\u4eba\u907f\u969c\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5fc6\u963b\u5668\u4ea4\u53c9\u9635\u5217\u80fd\u591f\u5b9e\u73b0\u5185\u5b58\u5185\u4e58\u7d2f\u52a0\u548c\u5c40\u90e8\u53ef\u5851\u6027\u5b66\u4e60\uff0c\u4e3a\u80fd\u6548\u8fb9\u7f18AI\u63d0\u4f9b\u4e86\u4e00\u6761\u8def\u5f84\u3002\u4f46\u7f3a\u4e4f\u5f00\u6e90\u3001\u53ef\u590d\u73b0\u7684\u5fc6\u963b\u5668\u63a5\u53e3\u7cfb\u7edf\u963b\u788d\u4e86\u76f8\u5173\u7814\u7a76\u7684\u53d1\u5c55\u3002", "method": "\u5f00\u53d1\u4e86OpenMENA\u7cfb\u7edf\uff0c\u5305\u542b\uff1a(i)\u53ef\u590d\u73b0\u7684\u5fc6\u963b\u5668\u4ea4\u53c9\u9635\u5217\u786c\u4ef6\u63a5\u53e3\uff0c\u652f\u6301\u6df7\u5408\u4fe1\u53f7\u8bfb-\u7f16\u7a0b-\u9a8c\u8bc1\u5faa\u73af\uff1b(ii)\u5177\u6709\u9ad8\u7ea7API\u7684\u56fa\u4ef6-\u8f6f\u4ef6\u6808\uff0c\u652f\u6301\u63a8\u7406\u548c\u7247\u4e0a\u5b66\u4e60\uff1b(iii)VIPI\u65b9\u6cd5\u5c06\u9884\u8bad\u7ec3\u6743\u91cd\u7f16\u7a0b\u5230\u6a21\u62df\u7535\u5bfc\u4e2d\uff0c\u5e76\u901a\u8fc7\u82af\u7247\u5728\u73af\u5fae\u8c03\u6765\u7f13\u89e3\u5668\u4ef6\u975e\u7406\u60f3\u6027\u3002", "result": "\u5728\u6570\u5b57\u8bc6\u522b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u4ece\u6743\u91cd\u8fc1\u79fb\u5230\u7247\u4e0a\u9002\u5e94\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u907f\u969c\u4efb\u52a1\u4e2d\uff0c\u5fc6\u963b\u5668\u6a21\u578b\u6210\u529f\u5b66\u4e60\u5c06\u5b9a\u4f4d\u8f93\u5165\u6620\u5c04\u5230\u7535\u673a\u547d\u4ee4\u3002", "conclusion": "OpenMENA\u4f5c\u4e3a\u5f00\u6e90\u7cfb\u7edf\u53d1\u5e03\uff0c\u65e8\u5728\u6c11\u4e3b\u5316\u5fc6\u963b\u5668\u4f7f\u80fd\u7684\u8fb9\u7f18AI\u7814\u7a76\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u786c\u4ef6-\u8f6f\u4ef6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.03773", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03773", "abs": "https://arxiv.org/abs/2511.03773", "authors": ["Zhaorun Chen", "Zhuokai Zhao", "Kai Zhang", "Bo Liu", "Qi Qi", "Yifan Wu", "Tarun Kalluri", "Sara Cao", "Yuanhao Xiong", "Haibo Tong", "Huaxiu Yao", "Hengduo Li", "Jiacheng Zhu", "Xian Li", "Dawn Song", "Bo Li", "Jason Weston", "Dat Huynh"], "title": "Scaling Agent Learning via Experience Synthesis", "comment": null, "summary": "While reinforcement learning (RL) can empower large language model (LLM)\nagents by enabling self-improvement through interaction, its practical adoption\nremains challenging due to costly rollouts, limited task diversity, unreliable\nreward signals, and infrastructure complexity, all of which obstruct the\ncollection of scalable experience data. To address these challenges, we\nintroduce DreamGym, the first unified framework designed to synthesize diverse\nexperiences with scalability in mind to enable effective online RL training for\nautonomous agents. Rather than relying on expensive real-environment rollouts,\nDreamGym distills environment dynamics into a reasoning-based experience model\nthat derives consistent state transitions and feedback signals through\nstep-by-step reasoning, enabling scalable agent rollout collection for RL. To\nimprove the stability and quality of transitions, DreamGym leverages an\nexperience replay buffer initialized with offline real-world data and\ncontinuously enriched with fresh interactions to actively support agent\ntraining. To improve knowledge acquisition, DreamGym adaptively generates new\ntasks that challenge the current agent policy, enabling more effective online\ncurriculum learning. Experiments across diverse environments and agent\nbackbones demonstrate that DreamGym substantially improves RL training, both in\nfully synthetic settings and in sim-to-real transfer scenarios. On non-RL-ready\ntasks like WebArena, DreamGym outperforms all baselines by over 30%. And in\nRL-ready but costly settings, it matches GRPO and PPO performance using only\nsynthetic interactions. When transferring a policy trained purely on synthetic\nexperiences to real-environment RL, DreamGym yields significant additional\nperformance gains while requiring far fewer real-world interactions, providing\na scalable warm-start strategy for general-purpose RL.", "AI": {"tldr": "DreamGym\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u63a8\u7406\u7684\u7ecf\u9a8c\u6a21\u578b\u5408\u6210\u591a\u6837\u5316\u7ecf\u9a8c\u6570\u636e\uff0c\u89e3\u51b3RL\u8bad\u7ec3\u4e2d\u6210\u672c\u9ad8\u3001\u4efb\u52a1\u591a\u6837\u6027\u6709\u9650\u3001\u5956\u52b1\u4fe1\u53f7\u4e0d\u53ef\u9760\u7b49\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u81ea\u4e3b\u4ee3\u7406\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e2d\u5b9e\u9645\u5e94\u7528\u7684\u6311\u6218\uff0c\u5305\u62ec\u6602\u8d35\u7684\u73af\u5883\u4ea4\u4e92\u3001\u6709\u9650\u7684\u4efb\u52a1\u591a\u6837\u6027\u3001\u4e0d\u53ef\u9760\u7684\u5956\u52b1\u4fe1\u53f7\u548c\u57fa\u7840\u8bbe\u65bd\u590d\u6742\u6027\uff0c\u8fd9\u4e9b\u56e0\u7d20\u963b\u788d\u4e86\u53ef\u6269\u5c55\u7ecf\u9a8c\u6570\u636e\u7684\u6536\u96c6\u3002", "method": "\u5c06\u73af\u5883\u52a8\u6001\u63d0\u70bc\u4e3a\u57fa\u4e8e\u63a8\u7406\u7684\u7ecf\u9a8c\u6a21\u578b\uff0c\u901a\u8fc7\u9010\u6b65\u63a8\u7406\u63a8\u5bfc\u4e00\u81f4\u7684\u72b6\u6001\u8f6c\u6362\u548c\u53cd\u9988\u4fe1\u53f7\uff1b\u5229\u7528\u7ecf\u9a8c\u56de\u653e\u7f13\u51b2\u533a\u521d\u59cb\u5316\u79bb\u7ebf\u771f\u5b9e\u4e16\u754c\u6570\u636e\u5e76\u6301\u7eed\u4e30\u5bcc\uff1b\u81ea\u9002\u5e94\u751f\u6210\u6311\u6218\u5f53\u524d\u4ee3\u7406\u7b56\u7565\u7684\u65b0\u4efb\u52a1\u3002", "result": "\u5728\u591a\u6837\u5316\u73af\u5883\u548c\u4ee3\u7406\u9aa8\u5e72\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDreamGym\u663e\u8457\u6539\u5584\u4e86RL\u8bad\u7ec3\u3002\u5728WebArena\u7b49\u975eRL\u5c31\u7eea\u4efb\u52a1\u4e0a\uff0c\u6027\u80fd\u8d85\u8fc7\u6240\u6709\u57fa\u7ebf30%\u4ee5\u4e0a\uff1b\u5728RL\u5c31\u7eea\u4f46\u6210\u672c\u9ad8\u7684\u8bbe\u7f6e\u4e2d\uff0c\u4ec5\u4f7f\u7528\u5408\u6210\u4ea4\u4e92\u5c31\u80fd\u5339\u914dGRPO\u548cPPO\u6027\u80fd\uff1b\u5728\u7eaf\u5408\u6210\u7ecf\u9a8c\u8bad\u7ec3\u7684\u7b56\u7565\u8f6c\u79fb\u5230\u771f\u5b9e\u73af\u5883RL\u65f6\uff0c\u83b7\u5f97\u663e\u8457\u989d\u5916\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u9700\u8981\u66f4\u5c11\u7684\u771f\u5b9e\u4e16\u754c\u4ea4\u4e92\u3002", "conclusion": "DreamGym\u4e3a\u901a\u7528\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u70ed\u542f\u52a8\u7b56\u7565\uff0c\u901a\u8fc7\u5408\u6210\u7ecf\u9a8c\u6570\u636e\u6709\u6548\u89e3\u51b3\u4e86RL\u8bad\u7ec3\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5728\u591a\u79cd\u573a\u666f\u4e0b\u90fd\u53d6\u5f97\u4e86\u4f18\u5f02\u8868\u73b0\u3002"}}
{"id": "2511.04090", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04090", "abs": "https://arxiv.org/abs/2511.04090", "authors": ["Brigitte A. Mora-Reyes", "Jennifer A. Drewyor", "Abel A. Reyes-Angulo"], "title": "Advancing Equitable AI: Evaluating Cultural Expressiveness in LLMs for Latin American Contexts", "comment": null, "summary": "Artificial intelligence (AI) systems often reflect biases from economically\nadvanced regions, marginalizing contexts in economically developing regions\nlike Latin America due to imbalanced datasets. This paper examines AI\nrepresentations of diverse Latin American contexts, revealing disparities\nbetween data from economically advanced and developing regions. We highlight\nhow the dominance of English over Spanish, Portuguese, and indigenous languages\nsuch as Quechua and Nahuatl perpetuates biases, framing Latin American\nperspectives through a Western lens. To address this, we introduce a culturally\naware dataset rooted in Latin American history and socio-political contexts,\nchallenging Eurocentric models. We evaluate six language models on questions\ntesting cultural context awareness, using a novel Cultural Expressiveness\nmetric, statistical tests, and linguistic analyses. Our findings show that some\nmodels better capture Latin American perspectives, while others exhibit\nsignificant sentiment misalignment (p < 0.001). Fine-tuning Mistral-7B with our\ndataset improves its cultural expressiveness by 42.9%, advancing equitable AI\ndevelopment. We advocate for equitable AI by prioritizing datasets that reflect\nLatin American history, indigenous knowledge, and diverse languages, while\nemphasizing community-centered approaches to amplify marginalized voices.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86AI\u7cfb\u7edf\u4e2d\u5bf9\u62c9\u4e01\u7f8e\u6d32\u7684\u6587\u5316\u504f\u89c1\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u62c9\u4e01\u7f8e\u6d32\u5386\u53f2\u6587\u5316\u80cc\u666f\u7684\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5fae\u8c03\u6a21\u578b\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6587\u5316\u8868\u8fbe\u80fd\u529b\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u4e3b\u8981\u53cd\u6620\u7ecf\u6d4e\u53d1\u8fbe\u5730\u533a\u7684\u504f\u89c1\uff0c\u8fb9\u7f18\u5316\u4e86\u62c9\u4e01\u7f8e\u6d32\u7b49\u53d1\u5c55\u4e2d\u5730\u533a\u7684\u8bed\u5883\uff0c\u7279\u522b\u662f\u82f1\u8bed\u4e3b\u5bfc\u5730\u4f4d\u538b\u5236\u4e86\u897f\u73ed\u7259\u8bed\u3001\u8461\u8404\u7259\u8bed\u548c\u571f\u8457\u8bed\u8a00\uff0c\u5bfc\u81f4\u62c9\u4e01\u7f8e\u6d32\u89c6\u89d2\u88ab\u897f\u65b9\u6846\u67b6\u626d\u66f2\u3002", "method": "\u521b\u5efa\u4e86\u57fa\u4e8e\u62c9\u4e01\u7f8e\u6d32\u5386\u53f2\u548c\u793e\u4f1a\u653f\u6cbb\u80cc\u666f\u7684\u6587\u5316\u611f\u77e5\u6570\u636e\u96c6\uff1b\u8bc4\u4f30\u4e86\u516d\u4e2a\u8bed\u8a00\u6a21\u578b\u7684\u6587\u5316\u8bed\u5883\u7406\u89e3\u80fd\u529b\uff1b\u4f7f\u7528\u6587\u5316\u8868\u8fbe\u6027\u6307\u6807\u3001\u7edf\u8ba1\u68c0\u9a8c\u548c\u8bed\u8a00\u5206\u6790\uff1b\u5bf9Mistral-7B\u6a21\u578b\u8fdb\u884c\u4e86\u5fae\u8c03\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u67d0\u4e9b\u6a21\u578b\u80fd\u66f4\u597d\u5730\u6355\u6349\u62c9\u4e01\u7f8e\u6d32\u89c6\u89d2\uff0c\u800c\u5176\u4ed6\u6a21\u578b\u5b58\u5728\u663e\u8457\u60c5\u611f\u504f\u5dee(p < 0.001)\uff1b\u5fae\u8c03\u540e\u7684Mistral-7B\u6587\u5316\u8868\u8fbe\u6027\u63d0\u5347\u4e8642.9%\u3002", "conclusion": "\u5021\u5bfc\u901a\u8fc7\u4f18\u5148\u8003\u8651\u53cd\u6620\u62c9\u4e01\u7f8e\u6d32\u5386\u53f2\u3001\u571f\u8457\u77e5\u8bc6\u548c\u591a\u6837\u8bed\u8a00\u7684\u6570\u636e\u96c6\u6765\u4fc3\u8fdbAI\u516c\u5e73\u53d1\u5c55\uff0c\u5f3a\u8c03\u4ee5\u793e\u533a\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\u6765\u653e\u5927\u8fb9\u7f18\u5316\u58f0\u97f3\u3002"}}
{"id": "2511.03750", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.03750", "abs": "https://arxiv.org/abs/2511.03750", "authors": ["Heidi A. Hanson", "Joemy Ramsay", "Josh Grant", "Maggie Davis", "Janet O. Agbaje", "Dakotah Maguire", "Jeremy Logan", "Marissa Taddie", "Chad Melton", "Midgie MacFarland", "James VanDerslice"], "title": "Centralized Health and Exposomic Resource (C-HER): Analytic and AI-Ready Data for External Exposomic Research", "comment": null, "summary": "The Centralized Health and Exposomic Resource (C-HER) project has identified,\nprofiled, spatially indexed, and stored over 30 external exposomic datasets.\nThe resulting analytic and AI-ready data (AAIRD) provides a significant\nopportunity to develop an integrated picture of the exposome for health\nresearch. The exposome is a conceptual framework designed to guide the study of\nthe complex environmental and genetic factors that together shape human health.\nFew composite measures of the exposome exist due to the high dimensionality of\nexposure data, multimodal data sources, and varying spatiotemporal scales. We\ndevelop a data engineering solution that overcomes the challenges of\nspatio-temporal linkage in this field. We provide examples of how environmental\ndata can be combined to characterize a region, model air pollution, or provide\nindicators for cancer research. The development of AAIRD will allow future\nstudies to use ML and deep learning methods to generate spatial and contextual\nexposure data for disease prediction.", "AI": {"tldr": "C-HER\u9879\u76ee\u5f00\u53d1\u4e86\u6570\u636e\u5de5\u7a0b\u89e3\u51b3\u65b9\u6848\uff0c\u6574\u5408\u4e8630\u591a\u4e2a\u5916\u90e8\u66b4\u9732\u7ec4\u6570\u636e\u96c6\uff0c\u521b\u5efa\u4e86\u5206\u6790\u548cAI\u5c31\u7eea\u6570\u636e(AAIRD)\uff0c\u4ee5\u514b\u670d\u66b4\u9732\u7ec4\u7814\u7a76\u4e2d\u65f6\u7a7a\u5173\u8054\u7684\u6311\u6218\u3002", "motivation": "\u66b4\u9732\u7ec4\u662f\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\uff0c\u7528\u4e8e\u7814\u7a76\u590d\u6742\u73af\u5883\u548c\u9057\u4f20\u56e0\u7d20\u5982\u4f55\u5171\u540c\u5f71\u54cd\u4eba\u7c7b\u5065\u5eb7\u3002\u7531\u4e8e\u66b4\u9732\u6570\u636e\u7684\u9ad8\u7ef4\u5ea6\u3001\u591a\u6a21\u6001\u6570\u636e\u6e90\u548c\u4e0d\u540c\u65f6\u7a7a\u5c3a\u5ea6\uff0c\u73b0\u6709\u7684\u66b4\u9732\u7ec4\u7efc\u5408\u6d4b\u91cf\u65b9\u6cd5\u5f88\u5c11\u3002", "method": "\u5f00\u53d1\u6570\u636e\u5de5\u7a0b\u89e3\u51b3\u65b9\u6848\uff0c\u5bf930\u591a\u4e2a\u5916\u90e8\u66b4\u9732\u7ec4\u6570\u636e\u96c6\u8fdb\u884c\u8bc6\u522b\u3001\u5206\u6790\u3001\u7a7a\u95f4\u7d22\u5f15\u548c\u5b58\u50a8\uff0c\u521b\u5efaAAIRD\u3002", "result": "\u6210\u529f\u6574\u5408\u4e86\u73af\u5883\u6570\u636e\uff0c\u53ef\u7528\u4e8e\u533a\u57df\u7279\u5f81\u63cf\u8ff0\u3001\u7a7a\u6c14\u6c61\u67d3\u5efa\u6a21\u548c\u764c\u75c7\u7814\u7a76\u6307\u6807\u3002AAIRD\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86ML\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u751f\u6210\u7a7a\u95f4\u548c\u4e0a\u4e0b\u6587\u66b4\u9732\u6570\u636e\u7684\u57fa\u7840\u3002", "conclusion": "AAIRD\u7684\u5f00\u53d1\u5c06\u4f7f\u672a\u6765\u7814\u7a76\u80fd\u591f\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u751f\u6210\u7a7a\u95f4\u548c\u4e0a\u4e0b\u6587\u66b4\u9732\u6570\u636e\uff0c\u7528\u4e8e\u75be\u75c5\u9884\u6d4b\u3002"}}
{"id": "2511.04052", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04052", "abs": "https://arxiv.org/abs/2511.04052", "authors": ["Kyongsik Yun", "David Bayard", "Gerik Kubiak", "Austin Owens", "Andrew Johnson", "Ryan Johnson", "Dan Scharf", "Thomas Lu"], "title": "Enhancing Fault-Tolerant Space Computing: Guidance Navigation and Control (GNC) and Landing Vision System (LVS) Implementations on Next-Gen Multi-Core Processors", "comment": null, "summary": "Future planetary exploration missions demand high-performance, fault-tolerant\ncomputing to enable autonomous Guidance, Navigation, and Control (GNC) and\nLander Vision System (LVS) operations during Entry, Descent, and Landing (EDL).\nThis paper evaluates the deployment of GNC and LVS algorithms on\nnext-generation multi-core processors--HPSC, Snapdragon VOXL2, and AMD Xilinx\nVersal--demonstrating up to 15x speedup for LVS image processing and over 250x\nspeedup for Guidance for Fuel-Optimal Large Divert (GFOLD) trajectory\noptimization compared to legacy spaceflight hardware. To ensure computational\nreliability, we present ARBITER (Asynchronous Redundant Behavior Inspection for\nTrusted Execution and Recovery), a Multi-Core Voting (MV) mechanism that\nperforms real-time fault detection and correction across redundant cores.\nARBITER is validated in both static optimization tasks (GFOLD) and dynamic\nclosed-loop control (Attitude Control System). A fault injection study further\nidentifies the gradient computation stage in GFOLD as the most sensitive to\nbit-level errors, motivating selective protection strategies and vector-based\noutput arbitration. This work establishes a scalable and energy-efficient\narchitecture for future missions, including Mars Sample Return, Enceladus\nOrbilander, and Ceres Sample Return, where onboard autonomy, low latency, and\nfault resilience are critical.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u4e0b\u4e00\u4ee3\u591a\u6838\u5904\u7406\u5668\u5728\u884c\u661f\u63a2\u7d22\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5c55\u793a\u4e86LVS\u56fe\u50cf\u5904\u740615\u500d\u52a0\u901f\u548cGFOLD\u8f68\u8ff9\u4f18\u5316250\u500d\u52a0\u901f\uff0c\u5e76\u63d0\u51fa\u4e86ARBITER\u6545\u969c\u68c0\u6d4b\u673a\u5236\u786e\u4fdd\u8ba1\u7b97\u53ef\u9760\u6027\u3002", "motivation": "\u672a\u6765\u884c\u661f\u63a2\u7d22\u4efb\u52a1\u9700\u8981\u9ad8\u6027\u80fd\u3001\u5bb9\u9519\u7684\u8ba1\u7b97\u80fd\u529b\u6765\u5b9e\u73b0\u81ea\u4e3b\u7684\u5236\u5bfc\u5bfc\u822a\u63a7\u5236\u548c\u7740\u9646\u89c6\u89c9\u7cfb\u7edf\u64cd\u4f5c\uff0c\u7279\u522b\u662f\u5728\u8fdb\u5165\u3001\u4e0b\u964d\u548c\u7740\u9646\u9636\u6bb5\u3002", "method": "\u5728HPSC\u3001Snapdragon VOXL2\u548cAMD Xilinx Versal\u7b49\u591a\u6838\u5904\u7406\u5668\u4e0a\u90e8\u7f72GNC\u548cLVS\u7b97\u6cd5\uff0c\u5e76\u5f00\u53d1ARBITER\u591a\u6838\u6295\u7968\u673a\u5236\u8fdb\u884c\u5b9e\u65f6\u6545\u969c\u68c0\u6d4b\u548c\u6821\u6b63\u3002", "result": "LVS\u56fe\u50cf\u5904\u7406\u83b7\u5f9715\u500d\u52a0\u901f\uff0cGFOLD\u8f68\u8ff9\u4f18\u5316\u83b7\u5f97\u8d85\u8fc7250\u500d\u52a0\u901f\uff1b\u6545\u969c\u6ce8\u5165\u7814\u7a76\u53d1\u73b0GFOLD\u4e2d\u7684\u68af\u5ea6\u8ba1\u7b97\u9636\u6bb5\u5bf9\u4f4d\u7ea7\u9519\u8bef\u6700\u654f\u611f\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5305\u62ec\u706b\u661f\u6837\u672c\u8fd4\u56de\u3001\u571f\u536b\u4e8c\u8f68\u9053\u7740\u9646\u5668\u548c\u8c37\u795e\u661f\u6837\u672c\u8fd4\u56de\u5728\u5185\u7684\u672a\u6765\u4efb\u52a1\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u4e14\u8282\u80fd\u7684\u67b6\u6784\uff0c\u5176\u4e2d\u673a\u8f7d\u81ea\u4e3b\u6027\u3001\u4f4e\u5ef6\u8fdf\u548c\u5bb9\u9519\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.04024", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.04024", "abs": "https://arxiv.org/abs/2511.04024", "authors": ["Marina Buzzi", "Barbara Leporini", "Angelica Lo Duca"], "title": "The Benefits of Data Storytelling in Accessible Teaching", "comment": null, "summary": "Accessible teaching has been extensively investigated in computer science,\nyet its integration into other disciplines, such as data literacy, remains\nlimited. This paper examines the potential of data storytelling, defined as the\nintegration of data, visualizations, and narrative, as a possible strategy for\nmaking complex information accessible to diverse learners in compliance with\nTitle II of the Americans with Disabilities Act (ADA). We propose six design\nprinciples, derived from Title II's core obligations, to guide educators in\napplying data storytelling within inclusive learning environments. A simulated\nscenario shows the operationalization of these principles, illustrating how\nnarrative-driven data presentation can enhance comprehension, engagement, and\nequitable access across different educational contexts.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u6570\u636e\u53d9\u4e8b\u4f5c\u4e3a\u5b9e\u73b0\u65e0\u969c\u788d\u6559\u5b66\u7684\u4e00\u79cd\u7b56\u7565\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7d20\u517b\u6559\u80b2\u4e2d\u5e94\u7528\uff0c\u4ee5\u7b26\u5408ADA\u6cd5\u6848\u8981\u6c42\u3002", "motivation": "\u8ba1\u7b97\u673a\u79d1\u5b66\u9886\u57df\u5df2\u5e7f\u6cdb\u7814\u7a76\u65e0\u969c\u788d\u6559\u5b66\uff0c\u4f46\u5728\u5176\u4ed6\u5b66\u79d1\u5982\u6570\u636e\u7d20\u517b\u4e2d\u7684\u6574\u5408\u4ecd\u7136\u6709\u9650\uff0c\u9700\u8981\u63a2\u7d22\u65b0\u7684\u7b56\u7565\u6765\u4f7f\u590d\u6742\u4fe1\u606f\u5bf9\u591a\u6837\u5316\u5b66\u4e60\u8005\u66f4\u6613\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8eADA\u6cd5\u6848\u6838\u5fc3\u4e49\u52a1\u7684\u516d\u4e2a\u8bbe\u8ba1\u539f\u5219\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u573a\u666f\u5c55\u793a\u4e86\u8fd9\u4e9b\u539f\u5219\u5728\u5305\u5bb9\u6027\u5b66\u4e60\u73af\u5883\u4e2d\u7684\u5177\u4f53\u5e94\u7528\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u53d9\u4e8b\u9a71\u52a8\u7684\u6570\u636e\u5448\u73b0\u65b9\u5f0f\u80fd\u591f\u589e\u5f3a\u7406\u89e3\u529b\u3001\u53c2\u4e0e\u5ea6\uff0c\u5e76\u5728\u4e0d\u540c\u6559\u80b2\u73af\u5883\u4e2d\u5b9e\u73b0\u66f4\u516c\u5e73\u7684\u8bbf\u95ee\u3002", "conclusion": "\u6570\u636e\u53d9\u4e8b\u662f\u4e00\u79cd\u6709\u6548\u7684\u7b56\u7565\uff0c\u53ef\u4ee5\u5e2e\u52a9\u6559\u80b2\u5de5\u4f5c\u8005\u521b\u5efa\u66f4\u5305\u5bb9\u7684\u5b66\u4e60\u73af\u5883\uff0c\u4f7f\u590d\u6742\u6570\u636e\u5bf9\u591a\u6837\u5316\u5b66\u4e60\u8005\u66f4\u52a0\u53ef\u8bbf\u95ee\u3002"}}
{"id": "2511.04348", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.04348", "abs": "https://arxiv.org/abs/2511.04348", "authors": ["Domenico delli Gatti", "Filippo Gusella", "Giorgio Ricchiuti"], "title": "Regime Changes and Real-Financial Cycles: Searching Minsky's Hypothesis in a Nonlinear Setting", "comment": null, "summary": "This paper investigates Minsky's cycles by extending the paper of stockhammer\net al. (2019) with a nonlinear model to capture possible local real-financial\nendogenous cycles. We trace nonlinear regime changes and check the presence of\nMinsky cycles from the 1970s to 2020 for the USA, France, Germany, Canada,\nAustralia, and the UK, linking the GDP with corporate debt, interest rate, and\nhousehold debt. When considering corporate debt, the results reveal\nreal-financial endogenous cycles in all countries, except Australia, and across\nall countries when interest rates are included. We find evidence for an\ninteraction mechanism between household debt and GDP only for the USA and the\nUK. These findings underscore the importance of nonlinear regime transitions in\nempirically assessing Minsky's theory.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u975e\u7ebf\u6027\u6a21\u578b\u6269\u5c55Stockhammer\u7b49\u4eba\u7684\u5de5\u4f5c\uff0c\u68c0\u9a8c\u4e861970-2020\u5e74\u95f4\u7f8e\u56fd\u3001\u6cd5\u56fd\u3001\u5fb7\u56fd\u3001\u52a0\u62ff\u5927\u3001\u6fb3\u5927\u5229\u4e9a\u548c\u82f1\u56fd\u7684\u660e\u65af\u57fa\u5468\u671f\uff0c\u53d1\u73b0\u9664\u6fb3\u5927\u5229\u4e9a\u5916\u6240\u6709\u56fd\u5bb6\u90fd\u5b58\u5728\u4f01\u4e1a\u503a\u52a1\u76f8\u5173\u7684\u771f\u5b9e-\u91d1\u878d\u5185\u751f\u5468\u671f\uff0c\u4ee5\u53ca\u5229\u7387\u76f8\u5173\u7684\u8de8\u56fd\u5468\u671f\uff0c\u800c\u5bb6\u5ead\u503a\u52a1\u4e0eGDP\u7684\u4e92\u52a8\u673a\u5236\u4ec5\u5728\u7f8e\u56fd\u548c\u82f1\u56fd\u663e\u8457\u3002", "motivation": "\u6269\u5c55Stockhammer\u7b49\u4eba(2019)\u7684\u7ebf\u6027\u6a21\u578b\uff0c\u91c7\u7528\u975e\u7ebf\u6027\u6a21\u578b\u6765\u6355\u6349\u53ef\u80fd\u7684\u5c40\u90e8\u771f\u5b9e-\u91d1\u878d\u5185\u751f\u5468\u671f\uff0c\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u660e\u65af\u57fa\u7406\u8bba\u3002", "method": "\u4f7f\u7528\u975e\u7ebf\u6027\u6a21\u578b\u8ffd\u8e2a\u975e\u7ebf\u6027\u5236\u5ea6\u53d8\u5316\uff0c\u68c0\u9a8c1970-2020\u5e74\u95f4\u516d\u4e2a\u56fd\u5bb6GDP\u4e0e\u4f01\u4e1a\u503a\u52a1\u3001\u5229\u7387\u548c\u5bb6\u5ead\u503a\u52a1\u4e4b\u95f4\u7684\u660e\u65af\u57fa\u5468\u671f\u5173\u7cfb\u3002", "result": "\u8003\u8651\u4f01\u4e1a\u503a\u52a1\u65f6\uff0c\u9664\u6fb3\u5927\u5229\u4e9a\u5916\u7684\u6240\u6709\u56fd\u5bb6\u90fd\u5b58\u5728\u771f\u5b9e-\u91d1\u878d\u5185\u751f\u5468\u671f\uff1b\u8003\u8651\u5229\u7387\u65f6\uff0c\u6240\u6709\u56fd\u5bb6\u90fd\u5b58\u5728\u5468\u671f\uff1b\u5bb6\u5ead\u503a\u52a1\u4e0eGDP\u7684\u4e92\u52a8\u673a\u5236\u4ec5\u5728\u7f8e\u56fd\u548c\u82f1\u56fd\u663e\u8457\u3002", "conclusion": "\u975e\u7ebf\u6027\u5236\u5ea6\u8f6c\u53d8\u5728\u5b9e\u8bc1\u8bc4\u4f30\u660e\u65af\u57fa\u7406\u8bba\u4e2d\u5177\u6709\u91cd\u8981\u6027\uff0c\u4e0d\u540c\u56fd\u5bb6\u5728\u4e0d\u540c\u503a\u52a1\u7c7b\u578b\u4e0b\u7684\u5468\u671f\u6027\u8868\u73b0\u5b58\u5728\u5dee\u5f02\u3002"}}
{"id": "2511.03917", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.03917", "abs": "https://arxiv.org/abs/2511.03917", "authors": ["Raul A. Barreto", "Angus Flavel"], "title": "Cross-pollination dynamics of web-based social media: An application of insect-mediated pollen transfer", "comment": "Angus Flavel and Raul Barreto are the CEO and CFO of both Flavel REM\n  Pty Ltd and Share Social Pty Ltd. The latter company is the sole proprietor\n  of the share app. This paper is the result of research conducted by Flavel\n  REM Pty Ltd under contract by Share Social Pty Ltd as part of its Australian\n  AusIndustry Research and Development Tax Incentive (RDTI) reporting\n  obligations", "summary": "We propose a model of cross-pollination among online social media (OSM)\nwebsites, where the dynamics of user interactions mimic insect-mediated pollen\ntransfer by pollinators. A pollinator acts as a vehicle enabling users to visit\nmultiple social media sites- akin to visiting different plants in the same\nfield- within a single browsing session. This approach frames geitonogamy in\nself-incompatible plant species as analogous to the distribution of web traffic\nacross the social media landscape. A theoretical pollinator, allowing users to\nchoose among social media sites multiple times per trip, drives uneven\nincreases in web traffic across platforms, disproportionately benefiting the\nlargest social networks while providing tangible competitive advantages to\nsmaller OSMs. This heterogeneous landscape fosters monopolistic competition\namong niche platforms, incentivizing smaller sites to promote cross-pollination\ndespite the larger relative gains to their bigger competitors. Our findings\nunderscore the broader value of cross-platform user engagement, highlighting\nhow cross-pollination dynamics can intensify network effects and bolster\ninterconnectivity. Cross pollination via new pass-through apps facilitates the\nmovement of attention, deepening and distributing engagement across multiple\ndestinations. As pass-through apps gain traction, their disproportionate impact\non traffic to social media platforms will incentivize social media platforms,\nlarge and small, to embrace cross-pollination dynamics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7ebf\u793e\u4ea4\u5a92\u4f53\u95f4\u7684\u4ea4\u53c9\u6388\u7c89\u6a21\u578b\uff0c\u5c06\u7528\u6237\u8de8\u5e73\u53f0\u4e92\u52a8\u6bd4\u4f5c\u6606\u866b\u6388\u7c89\u8fc7\u7a0b\uff0c\u5206\u6790\u4e86\u8fd9\u79cd\u52a8\u6001\u5982\u4f55\u5f71\u54cd\u4e0d\u540c\u89c4\u6a21\u793e\u4ea4\u5e73\u53f0\u7684\u6d41\u91cf\u5206\u5e03\u548c\u7ade\u4e89\u683c\u5c40\u3002", "motivation": "\u7814\u7a76\u5728\u7ebf\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u95f4\u7684\u7528\u6237\u6d41\u52a8\u52a8\u6001\uff0c\u7406\u89e3\u4ea4\u53c9\u5e73\u53f0\u4e92\u52a8\u5982\u4f55\u5f71\u54cd\u7f51\u7edc\u6548\u5e94\u548c\u5e73\u53f0\u7ade\u4e89\uff0c\u7279\u522b\u662f\u5206\u6790\u8fd9\u79cd\u4ea4\u53c9\u6388\u7c89\u73b0\u8c61\u5bf9\u4e0d\u540c\u89c4\u6a21\u5e73\u53f0\u7684\u5f71\u54cd\u3002", "method": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7406\u8bba\u6a21\u578b\uff0c\u5c06\u7528\u6237\u8de8\u5e73\u53f0\u8bbf\u95ee\u6bd4\u4f5c\u6606\u866b\u6388\u7c89\u8fc7\u7a0b\uff0c\u5176\u4e2d'\u6388\u7c89\u8005'\uff08\u7528\u6237\uff09\u5728\u4e00\u6b21\u6d4f\u89c8\u4f1a\u8bdd\u4e2d\u8bbf\u95ee\u591a\u4e2a\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\uff0c\u7c7b\u4f3c\u4e8e\u6606\u866b\u5728\u4e0d\u540c\u690d\u7269\u95f4\u4f20\u9012\u82b1\u7c89\u3002", "result": "\u4ea4\u53c9\u6388\u7c89\u52a8\u6001\u5bfc\u81f4\u7f51\u7edc\u6d41\u91cf\u5728\u5e73\u53f0\u95f4\u4e0d\u5747\u5300\u589e\u957f\uff0c\u5927\u578b\u793e\u4ea4\u7f51\u7edc\u83b7\u5f97\u4e0d\u6210\u6bd4\u4f8b\u7684\u6536\u76ca\uff0c\u4f46\u5c0f\u578b\u5e73\u53f0\u4e5f\u80fd\u83b7\u5f97\u5b9e\u8d28\u6027\u7ade\u4e89\u4f18\u52bf\uff0c\u4fc3\u8fdb\u4e86\u5784\u65ad\u7ade\u4e89\u683c\u5c40\u7684\u5f62\u6210\u3002", "conclusion": "\u8de8\u5e73\u53f0\u7528\u6237\u53c2\u4e0e\u5177\u6709\u5e7f\u6cdb\u4ef7\u503c\uff0c\u4ea4\u53c9\u6388\u7c89\u52a8\u6001\u80fd\u591f\u5f3a\u5316\u7f51\u7edc\u6548\u5e94\u5e76\u589e\u5f3a\u4e92\u8054\u6027\uff0c\u968f\u7740\u4e2d\u8f6c\u5e94\u7528\u7684\u666e\u53ca\uff0c\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u65e0\u8bba\u5927\u5c0f\u90fd\u5c06\u53d7\u76ca\u4e8e\u62e5\u62b1\u8fd9\u79cd\u4ea4\u53c9\u6388\u7c89\u52a8\u6001\u3002"}}
{"id": "2511.03737", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03737", "abs": "https://arxiv.org/abs/2511.03737", "authors": ["D\u00e1niel Istv\u00e1n N\u00e9meth", "K\u00e1lm\u00e1n Tornai"], "title": "Hybrid ILM-NILM Smart Plug System", "comment": "13 pages, 9 figures. This is the original version of a manuscript\n  currently under review at the International Journal of Electrical Power &\n  Energy Systems", "summary": "Electrical load classification is generally divided into intrusive and\nnon-intrusive approaches, both having their limitations and advantages. With\nthe non-intrusive approach, controlling appliances is not possible, but the\ninstallation cost of a single measurement device is cheap. In comparison,\nintrusive, smart plug-based solutions offer individual appliance control, but\nthe installation cost is much higher. There have been very few approaches\naiming to combine these methods. In this paper we show that extending a smart\nplug-based solution to multiple loads per plug can reduce control granularity\nin favor of lowering the system's installation costs. Connecting various loads\nto a Smart Plug through an extension cord is seldom considered in the\nliterature, even though it is common in households. This scenario is also\nhandled by the hybrid load classification solution presented in this paper.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u8d1f\u8f7d\u5206\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u667a\u80fd\u63d2\u5ea7\u8fde\u63a5\u591a\u4e2a\u8d1f\u8f7d\u6765\u964d\u4f4e\u5b89\u88c5\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e00\u5b9a\u7684\u63a7\u5236\u7c92\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u4fb5\u5165\u5f0f\u548c\u975e\u4fb5\u5165\u5f0f\u8d1f\u8f7d\u5206\u7c7b\u65b9\u6cd5\u5404\u6709\u4f18\u7f3a\u70b9\uff0c\u5f88\u5c11\u6709\u7814\u7a76\u5c06\u4e24\u8005\u7ed3\u5408\u3002\u667a\u80fd\u63d2\u5ea7\u65b9\u6848\u867d\u7136\u80fd\u63a7\u5236\u5355\u4e2a\u8bbe\u5907\u4f46\u6210\u672c\u9ad8\uff0c\u800c\u975e\u4fb5\u5165\u5f0f\u65b9\u6cd5\u6210\u672c\u4f4e\u4f46\u65e0\u6cd5\u63a7\u5236\u8bbe\u5907\u3002", "method": "\u6269\u5c55\u667a\u80fd\u63d2\u5ea7\u65b9\u6848\uff0c\u8ba9\u4e00\u4e2a\u667a\u80fd\u63d2\u5ea7\u901a\u8fc7\u5ef6\u957f\u7ebf\u8fde\u63a5\u591a\u4e2a\u8d1f\u8f7d\uff0c\u5f62\u6210\u6df7\u5408\u8d1f\u8f7d\u5206\u7c7b\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u964d\u4f4e\u7cfb\u7edf\u5b89\u88c5\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e00\u5b9a\u7684\u8bbe\u5907\u63a7\u5236\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u5bb6\u5ead\u4e2d\u5e38\u89c1\u7684\u4e00\u4e2a\u63d2\u5ea7\u8fde\u63a5\u591a\u4e2a\u8bbe\u5907\u7684\u60c5\u51b5\u3002", "conclusion": "\u901a\u8fc7\u6df7\u5408\u8d1f\u8f7d\u5206\u7c7b\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u63a7\u5236\u7c92\u5ea6\u548c\u5b89\u88c5\u6210\u672c\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u4e3a\u667a\u80fd\u5bb6\u5c45\u8d1f\u8f7d\u7ba1\u7406\u63d0\u4f9b\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.04136", "categories": ["cs.ET", "physics.app-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.04136", "abs": "https://arxiv.org/abs/2511.04136", "authors": ["Neil Na", "Chih-Hao Cheng", "Shou-Chen Hsu", "Che-Fu Liang", "Chung-Chih Lin", "Nathaniel Y. Na", "Andrew I. Shieh", "Erik Chen", "Haisheng Rong", "Richard A. Soref"], "title": "Implementation of transformer-based LLMs with large-scale optoelectronic neurons on a CMOS image sensor platform", "comment": null, "summary": "The recent rapid deployment of datacenter infrastructures for performing\nlarge language models (LLMs) and related artificial intelligence (AI)\napplications in the clouds is predicted to incur an exponentially growing\nenergy consumption in the near-term future. In this paper, we propose and\nanalyze the implementation of the transformer model, which is the cornerstone\nof the modern LLMs, with novel large-scale optoelectronic neurons (OENs)\nconstructed over the commercially available complementary\nmetal-oxide-semiconductor (CMOS) image sensor (CIS) platform. With all of the\nrequired optoelectronic devices and electronic circuits integrated in a chiplet\nonly about 2 cm by 3 cm in size, 175 billon parameters in the case of GPT-3 are\nshown to perform inference at an unprecedented speed of 12.6 POPS using only a\n40 nm CMOS process node, along with a high power efficiency of 74 TOPS/W and a\nhigh area efficiency of 19 TOPS/mm2, both surpassing the related digital\nelectronics by roughly two orders of magnitude. The influence of the\nquantization formats and the hardware induced errors are numerically\ninvestigated, and are shown to have a minimal impact. Our study presents a new\nyet practical path toward analog neural processing units (NPUs) to complement\nexisting digital processing units.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eCMOS\u56fe\u50cf\u4f20\u611f\u5668\u5e73\u53f0\u7684\u5927\u89c4\u6a21\u5149\u7535\u795e\u7ecf\u5143\u5b9e\u73b0Transformer\u6a21\u578b\uff0c\u572840nm\u5de5\u827a\u4e0b\u5b9e\u73b0GPT-3\u7ea7\u522b\u6a21\u578b\u63a8\u7406\uff0c\u6027\u80fd\u6bd4\u6570\u5b57\u7535\u5b50\u5668\u4ef6\u63d0\u5347\u7ea6\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u8fd0\u884c\u5927\u8bed\u8a00\u6a21\u578b\u548c\u76f8\u5173AI\u5e94\u7528\u5bfc\u81f4\u80fd\u6e90\u6d88\u8017\u6307\u6570\u7ea7\u589e\u957f\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u786c\u4ef6\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5728\u5546\u7528CMOS\u56fe\u50cf\u4f20\u611f\u5668\u5e73\u53f0\u4e0a\u6784\u5efa\u65b0\u578b\u5927\u89c4\u6a21\u5149\u7535\u795e\u7ecf\u5143\uff0c\u96c6\u6210\u6240\u6709\u5fc5\u9700\u7684\u5149\u7535\u5668\u4ef6\u548c\u7535\u5b50\u7535\u8def\u5230\u7ea62cm\u00d73cm\u7684\u82af\u7247\u4e2d\u3002", "result": "\u572840nm CMOS\u5de5\u827a\u4e0b\uff0cGPT-3\u76841750\u4ebf\u53c2\u6570\u6a21\u578b\u63a8\u7406\u901f\u5ea6\u8fbe\u523012.6 POPS\uff0c\u529f\u7387\u6548\u738774 TOPS/W\uff0c\u9762\u79ef\u6548\u738719 TOPS/mm\u00b2\uff0c\u5747\u6bd4\u6570\u5b57\u7535\u5b50\u5668\u4ef6\u63d0\u5347\u7ea6\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002\u91cf\u5316\u683c\u5f0f\u548c\u786c\u4ef6\u8bef\u5dee\u5f71\u54cd\u6781\u5c0f\u3002", "conclusion": "\u4e3a\u6a21\u62df\u795e\u7ecf\u5904\u7406\u5355\u5143\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u65b0\u8def\u5f84\uff0c\u53ef\u4f5c\u4e3a\u73b0\u6709\u6570\u5b57\u5904\u7406\u5355\u5143\u7684\u8865\u5145\u3002"}}
{"id": "2511.03825", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03825", "abs": "https://arxiv.org/abs/2511.03825", "authors": ["Ahmed Mostafa", "Raisul Arefin Nahid", "Samuel Mulder"], "title": "How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis", "comment": "Publication Notice. This paper was published in the BAR 2025 Workshop\n  (with NDSS 2025) and is for research and educational use. Copyright\n  \\c{opyright} 2025 Internet Society. All rights reserved. Personal/classroom\n  reproduction is permitted with this notice and full paper citation. All other\n  uses, including commercial, require prior written permission from the\n  Internet Society", "summary": "Tokenization is fundamental in assembly code analysis, impacting intrinsic\ncharacteristics like vocabulary size, semantic coverage, and extrinsic\nperformance in downstream tasks. Despite its significance, tokenization in the\ncontext of assembly code remains an underexplored area. This study aims to\naddress this gap by evaluating the intrinsic properties of Natural Language\nProcessing (NLP) tokenization models and parameter choices, such as vocabulary\nsize. We explore preprocessing customization options and pre-tokenization rules\ntailored to the unique characteristics of assembly code. Additionally, we\nassess their impact on downstream tasks like function signature prediction -- a\ncritical problem in binary code analysis.\n  To this end, we conduct a thorough study on various tokenization models,\nsystematically analyzing their efficiency in encoding assembly instructions and\ncapturing semantic nuances. Through intrinsic evaluations, we compare\ntokenizers based on tokenization efficiency, vocabulary compression, and\nrepresentational fidelity for assembly code. Using state-of-the-art pre-trained\nmodels such as the decoder-only Large Language Model (LLM) Llama 3.2, the\nencoder-only transformer BERT, and the encoder-decoder model BART, we evaluate\nthe effectiveness of these tokenizers across multiple performance metrics.\nPreliminary findings indicate that tokenizer choice significantly influences\ndownstream performance, with intrinsic metrics providing partial but incomplete\npredictability of extrinsic evaluation outcomes. These results reveal complex\ntrade-offs between intrinsic tokenizer properties and their utility in\npractical assembly code tasks. Ultimately, this study provides valuable\ninsights into optimizing tokenization models for low-level code analysis,\ncontributing to the robustness and scalability of Natural Language Model\n(NLM)-based binary analysis workflows.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86NLP\u5206\u8bcd\u6a21\u578b\u5728\u6c47\u7f16\u4ee3\u7801\u5206\u6790\u4e2d\u7684\u5185\u5728\u7279\u6027\uff0c\u5305\u62ec\u8bcd\u6c47\u91cf\u5927\u5c0f\u3001\u8bed\u4e49\u8986\u76d6\u7b49\uff0c\u5e76\u7814\u7a76\u4e86\u5176\u5bf9\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u51fd\u6570\u7b7e\u540d\u9884\u6d4b\uff09\u7684\u5f71\u54cd\u3002", "motivation": "\u6c47\u7f16\u4ee3\u7801\u5206\u6790\u4e2d\u7684\u5206\u8bcd\u6280\u672f\u7814\u7a76\u4e0d\u8db3\uff0c\u4f46\u5176\u5bf9\u8bcd\u6c47\u91cf\u5927\u5c0f\u3001\u8bed\u4e49\u8986\u76d6\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528\u591a\u79cd\u5206\u8bcd\u6a21\u578b\uff08\u5982Llama 3.2\u3001BERT\u3001BART\uff09\uff0c\u901a\u8fc7\u5185\u5728\u8bc4\u4f30\u6bd4\u8f83\u5206\u8bcd\u6548\u7387\u3001\u8bcd\u6c47\u538b\u7f29\u548c\u8868\u793a\u4fdd\u771f\u5ea6\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u6548\u679c\u3002", "result": "\u5206\u8bcd\u5668\u9009\u62e9\u663e\u8457\u5f71\u54cd\u4e0b\u6e38\u6027\u80fd\uff0c\u5185\u5728\u6307\u6807\u53ea\u80fd\u90e8\u5206\u9884\u6d4b\u5916\u5728\u8bc4\u4f30\u7ed3\u679c\uff0c\u63ed\u793a\u4e86\u5185\u5728\u7279\u6027\u4e0e\u5b9e\u9645\u6548\u7528\u4e4b\u95f4\u7684\u590d\u6742\u6743\u8861\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u4f18\u5316\u4f4e\u5c42\u4ee3\u7801\u5206\u6790\u7684\u5206\u8bcd\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u6a21\u578b\u7684\u4e8c\u8fdb\u5236\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\u7684\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.04453", "categories": ["cs.SI", "cs.SE", "H.5.3; K.6.3; D.2.9"], "pdf": "https://arxiv.org/pdf/2511.04453", "abs": "https://arxiv.org/abs/2511.04453", "authors": ["Obada Kraishan"], "title": "Launch-Day Diffusion: Tracking Hacker News Impact on GitHub Stars for AI Tools", "comment": "7 pages, 3 figures. Reproducible demonstration system with public\n  code available at https://github.com/obadaKraishan/Launch-Day-Diffusion", "summary": "Social news platforms have become key launch outlets for open-source\nprojects, especially Hacker News (HN), though quantifying their immediate\nimpact remains challenging. This paper presents a reproducible demonstration\nsystem that tracks how HN exposure translates into GitHub star growth for AI\nand LLM tools. Built entirely on public APIs, our pipeline analyzes 138\nrepository launches from 2024-2025 and reveals substantial launch effects:\nrepositories gain an average of 121 stars within 24 hours, 189 stars within 48\nhours, and 289 stars within a week of HN exposure. Through machine learning\nmodels (Elastic Net) and non-linear approaches (Gradient Boosting), we identify\nkey predictors of viral growth. Posting timing appears as key factor--launching\nat optimal hours can mean hundreds of additional stars--while the \"Show HN\" tag\nshows no statistical advantage after controlling for other factors. The\ndemonstration completes in under five minutes on standard hardware,\nautomatically collecting data, training models, and generating visualizations\nthrough single-file scripts. This makes our findings immediately reproducible\nand the framework easily be extended to other platforms, providing both\nresearchers and developers with actionable insights into launch dynamics.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u7cfb\u7edf\uff0c\u8ffd\u8e2aHacker News\u66dd\u5149\u5982\u4f55\u8f6c\u5316\u4e3aGitHub\u661f\u6807\u589e\u957f\uff0c\u53d1\u73b0HN\u53d1\u5e03\u53ef\u4e3aAI/LLM\u5de5\u5177\u5e26\u6765\u663e\u8457\u589e\u957f\uff1a24\u5c0f\u65f6\u5185\u5e73\u5747121\u661f\uff0c48\u5c0f\u65f6\u5185189\u661f\uff0c\u4e00\u5468\u5185289\u661f\u3002", "motivation": "\u91cf\u5316\u793e\u4ea4\u65b0\u95fb\u5e73\u53f0\uff08\u7279\u522b\u662fHacker News\uff09\u5bf9\u5f00\u6e90\u9879\u76ee\u7684\u5373\u65f6\u5f71\u54cd\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u53ef\u590d\u73b0\u7684\u65b9\u6cd5\u6765\u8ffd\u8e2a\u66dd\u5149\u5230GitHub\u661f\u6807\u589e\u957f\u7684\u5173\u7cfb\u3002", "method": "\u57fa\u4e8e\u516c\u5171API\u6784\u5efa\u5206\u6790\u7ba1\u9053\uff0c\u5206\u6790138\u4e2a2024-2025\u5e74\u4ed3\u5e93\u53d1\u5e03\u6570\u636e\uff0c\u4f7f\u7528\u5f39\u6027\u7f51\u7edc\u548c\u68af\u5ea6\u63d0\u5347\u7b49\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bc6\u522b\u5173\u952e\u9884\u6d4b\u56e0\u5b50\u3002", "result": "\u53d1\u5e03\u65f6\u673a\u662f\u5173\u952e\u56e0\u7d20\uff0c\u5728\u6700\u4f73\u65f6\u95f4\u53d1\u5e03\u53ef\u5e26\u6765\u6570\u767e\u989d\u5916\u661f\u6807\uff1b\"Show HN\"\u6807\u7b7e\u5728\u63a7\u5236\u5176\u4ed6\u56e0\u7d20\u540e\u65e0\u7edf\u8ba1\u4f18\u52bf\uff1b\u7cfb\u7edf\u53ef\u57285\u5206\u949f\u5185\u5b8c\u6210\u5206\u6790\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u590d\u73b0\u4e14\u6613\u4e8e\u6269\u5c55\u5230\u5176\u4ed6\u5e73\u53f0\uff0c\u4e3a\u7814\u7a76\u8005\u548c\u5f00\u53d1\u8005\u63d0\u4f9b\u5173\u4e8e\u53d1\u5e03\u52a8\u6001\u7684\u53ef\u64cd\u4f5c\u89c1\u89e3\u3002"}}
{"id": "2511.04065", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.04065", "abs": "https://arxiv.org/abs/2511.04065", "authors": ["Mohsen Sadatsafavi", "Gavin Pereira", "Wenjia Chen"], "title": "Transportability of Prognostic Markers: Rethinking Common Practices through a Sufficient-Component-Cause Perspective", "comment": "15 pages, 2 tables, 2 figures, 1 appendix", "summary": "Transportability, the ability to maintain performance across populations, is\na desirable property of of markers of clinical outcomes. However, empirical\nfindings indicate that markers often exhibit varying performances across\npopulations. For prognostic markers whose results are used to quantify of the\nrisk of an outcome, oftentimes a form of updating is required when the marker\nis transported to populations with different disease prevalences. Here, we\nrevisit transportability of prognostic markers through the lens of the\nfoundational framework of sufficient component causes (SCC). We argue that\ntransporting a marker \"as is\" implicitly assumes predictive values are\ntransportable, whereas conventional prevalence-adjustment shifts the locus of\ntransportability to accuracy metrics (sensitivity and specificity). Using a\nminimalist SCC framework that decomposes risk prediction into its causal\nconstituents, we show that both approaches rely on strong assumptions about the\nstability of cause distributions across populations. A SCC framework instead\ninvites making transparent assumptions about how different causes vary across\npopulations, leading to different transportation methods. For example, in the\nabsence of any external information other than disease prevalence, a\ncause-neutral perspective can assume all causes are responsible for change in\nprevalence, leading to a new form of marker transportation. Numerical\nexperiments demonstrate that different transportability assumptions lead to\nvarying degrees of information loss, depending on how population differ from\neach other in the distribution of causes. A SCC perspective challenges common\nassumptions and practices for marker transportability, and proposes\ntransportation algorithms that reflect our knowledge or assumptions about how\ncauses vary across populations.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5145\u5206\u6210\u5206\u539f\u56e0\u6846\u67b6\u91cd\u65b0\u5ba1\u89c6\u9884\u540e\u6807\u5fd7\u7269\u7684\u53ef\u79fb\u690d\u6027\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u7684\u53ef\u79fb\u690d\u6027\u5047\u8bbe\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u75c5\u56e0\u5206\u5e03\u53d8\u5316\u7684\u65b0\u8fd0\u8f93\u65b9\u6cd5\u3002", "motivation": "\u9884\u540e\u6807\u5fd7\u7269\u5728\u4e0d\u540c\u4eba\u7fa4\u4e2d\u6027\u80fd\u5b58\u5728\u5dee\u5f02\uff0c\u4f20\u7edf\u8fd0\u8f93\u65b9\u6cd5\uff08\u76f4\u63a5\u4f7f\u7528\u6216\u60a3\u75c5\u7387\u8c03\u6574\uff09\u90fd\u4f9d\u8d56\u5f3a\u5047\u8bbe\uff0c\u9700\u8981\u66f4\u900f\u660e\u7684\u53ef\u79fb\u690d\u6027\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u5145\u5206\u6210\u5206\u539f\u56e0(SCC)\u6846\u67b6\u5206\u89e3\u98ce\u9669\u9884\u6d4b\u7684\u56e0\u679c\u6210\u5206\uff0c\u5206\u6790\u4e0d\u540c\u8fd0\u8f93\u65b9\u6cd5\u5bf9\u75c5\u56e0\u5206\u5e03\u7a33\u5b9a\u6027\u7684\u5047\u8bbe\uff0c\u63d0\u51fa\u57fa\u4e8e\u75c5\u56e0\u53d8\u5316\u5047\u8bbe\u7684\u65b0\u8fd0\u8f93\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0d\u540c\u7684\u53ef\u79fb\u690d\u6027\u5047\u8bbe\u4f1a\u5bfc\u81f4\u4e0d\u540c\u7a0b\u5ea6\u7684\u4fe1\u606f\u635f\u5931\uff0c\u53d6\u51b3\u4e8e\u4eba\u7fa4\u95f4\u75c5\u56e0\u5206\u5e03\u7684\u5dee\u5f02\u7a0b\u5ea6\u3002", "conclusion": "SCC\u89c6\u89d2\u6311\u6218\u4e86\u6807\u5fd7\u7269\u53ef\u79fb\u690d\u6027\u7684\u5e38\u89c1\u5047\u8bbe\u548c\u5b9e\u8df5\uff0c\u63d0\u51fa\u4e86\u53cd\u6620\u75c5\u56e0\u5206\u5e03\u53d8\u5316\u77e5\u8bc6\u548c\u5047\u8bbe\u7684\u8fd0\u8f93\u7b97\u6cd5\u3002"}}
{"id": "2511.04109", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04109", "abs": "https://arxiv.org/abs/2511.04109", "authors": ["Yanbo Pang", "Qingkai Li", "Mingguo Zhao"], "title": "CBMC-V3: A CNS-inspired Control Framework Towards Manipulation Agility with SNN", "comment": null, "summary": "As robotic arm applications extend beyond industrial settings into\nhealthcare, service, and daily life, existing control algorithms struggle to\nachieve the agile manipulation required for complex environments with dynamic\ntrajectories, unpredictable interactions, and diverse objects. This paper\npresents a biomimetic control framework based on Spiking Neural Networks (SNN),\ninspired by the human Central Nervous System (CNS), to achieve agile control in\nsuch environments. The proposed framework features five control modules\n(cerebral cortex, cerebellum, thalamus, brainstem, spinal cord), three\nhierarchical control levels (first-order, second-order, third-order), and two\ninformation pathways (ascending, descending). Each module is fully implemented\nusing SNN. The spinal cord module uses spike encoding and Leaky\nIntegrate-and-Fire (LIF) neurons for feedback control. The brainstem module\nemploys a network of LIF and non-spiking LIF neurons to dynamically adjust\nspinal cord parameters via reinforcement learning. The thalamus module\nsimilarly adjusts the cerebellum's torque outputs. The cerebellum module uses a\nrecurrent SNN to learn the robotic arm's dynamics through regression, providing\nfeedforward gravity compensation torques. The framework is validated both in\nsimulation and on real-world robotic arm platform under various loads and\ntrajectories. Results demonstrate that our method outperforms the\nindustrial-grade position control in manipulation agility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7684\u4eff\u751f\u63a7\u5236\u6846\u67b6\uff0c\u6a21\u4eff\u4eba\u7c7b\u4e2d\u67a2\u795e\u7ecf\u7cfb\u7edf\uff0c\u7528\u4e8e\u673a\u5668\u81c2\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u654f\u6377\u63a7\u5236\u3002", "motivation": "\u968f\u7740\u673a\u5668\u81c2\u5e94\u7528\u6269\u5c55\u5230\u533b\u7597\u3001\u670d\u52a1\u548c\u65e5\u5e38\u751f\u6d3b\u9886\u57df\uff0c\u73b0\u6709\u63a7\u5236\u7b97\u6cd5\u96be\u4ee5\u5728\u5177\u6709\u52a8\u6001\u8f68\u8ff9\u3001\u4e0d\u53ef\u9884\u6d4b\u4ea4\u4e92\u548c\u591a\u6837\u5316\u5bf9\u8c61\u7684\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u654f\u6377\u64cd\u4f5c\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b\u4e94\u4e2a\u63a7\u5236\u6a21\u5757\uff08\u5927\u8111\u76ae\u5c42\u3001\u5c0f\u8111\u3001\u4e18\u8111\u3001\u8111\u5e72\u3001\u810a\u9ad3\uff09\u3001\u4e09\u4e2a\u63a7\u5236\u5c42\u7ea7\u548c\u4e24\u6761\u4fe1\u606f\u901a\u8def\u7684\u4eff\u751f\u63a7\u5236\u6846\u67b6\uff0c\u6240\u6709\u6a21\u5757\u5747\u4f7f\u7528\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u3002", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u81c2\u5e73\u53f0\u4e0a\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u64cd\u4f5c\u654f\u6377\u6027\u65b9\u9762\u4f18\u4e8e\u5de5\u4e1a\u7ea7\u4f4d\u7f6e\u63a7\u5236\u3002", "conclusion": "\u57fa\u4e8e\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7684\u4eff\u751f\u63a7\u5236\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u673a\u5668\u81c2\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u63a7\u5236\u6027\u80fd\uff0c\u5b9e\u73b0\u66f4\u654f\u6377\u7684\u64cd\u4f5c\u3002"}}
{"id": "2511.04105", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.04105", "abs": "https://arxiv.org/abs/2511.04105", "authors": ["Michael Heron", "Pauline Belford", "Klara Aune"], "title": "The Psychogeography of Imaginary Places", "comment": null, "summary": "Psychogeography -- the study of how environments shape emotion and behaviour\n-- has long concerned itself with the emotional resonance of the physical,\noften through the idea of the derive through the city. Its philosophical core,\nhowever, is primarily concerned with identifying affective relationships\nbetween the personal and the environmental, and this does not require the\nconstraint of concrete.\n  This paper extends psychogeographical practice into the realm of the\nimaginary, proposing a psychogeography of virtual and fictive spaces. Drawing\non literary, Situationist, and contemporary psychogeographical traditions, we\nexamine how the derive might operate within the elastic spatiality and\ntemporalities of video game worlds. We argue that digital environments, being\nwholly constructed, invite new forms of meaning-making and self-reflection.\nThrough this reframing, games become both laboratory and landscape for a\nrevitalised psychogeography: one attuned not only to the spirits of streets and\ncities, but also to the ghosts that haunt code, pixels, and play.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u5fc3\u7406\u5730\u7406\u5b66\u5b9e\u8df5\u5230\u865a\u62df\u548c\u865a\u6784\u7a7a\u95f4\u9886\u57df\uff0c\u63a2\u8ba8\u4e86\u5982\u4f55\u5728\u89c6\u9891\u6e38\u620f\u4e16\u754c\u7684\u5f39\u6027\u7a7a\u95f4\u548c\u65f6\u95f4\u6027\u4e2d\u8fdb\u884c\u6f2b\u6e38\uff0c\u8ba4\u4e3a\u6570\u5b57\u73af\u5883\u4e3a\u610f\u4e49\u521b\u9020\u548c\u81ea\u6211\u53cd\u601d\u63d0\u4f9b\u4e86\u65b0\u5f62\u5f0f\u3002", "motivation": "\u4f20\u7edf\u5fc3\u7406\u5730\u7406\u5b66\u4e3b\u8981\u5173\u6ce8\u7269\u7406\u73af\u5883\u5bf9\u60c5\u611f\u548c\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u5176\u54f2\u5b66\u6838\u5fc3\u5173\u6ce8\u4e2a\u4eba\u4e0e\u73af\u5883\u4e4b\u95f4\u7684\u60c5\u611f\u5173\u7cfb\uff0c\u8fd9\u4e0d\u9700\u8981\u5c40\u9650\u4e8e\u5177\u4f53\u7269\u7406\u7a7a\u95f4\u3002\u56e0\u6b64\u5e0c\u671b\u5c06\u5fc3\u7406\u5730\u7406\u5b66\u6269\u5c55\u5230\u865a\u62df\u548c\u865a\u6784\u7a7a\u95f4\u3002", "method": "\u501f\u9274\u6587\u5b66\u3001\u60c5\u5883\u4e3b\u4e49\u548c\u5f53\u4ee3\u5fc3\u7406\u5730\u7406\u5b66\u4f20\u7edf\uff0c\u5206\u6790\u89c6\u9891\u6e38\u620f\u4e16\u754c\u4e2d\u7684\u5f39\u6027\u7a7a\u95f4\u6027\u548c\u65f6\u95f4\u6027\uff0c\u63a2\u8ba8\u6570\u5b57\u73af\u5883\u4e2d\u7684\u6f2b\u6e38\u5b9e\u8df5\u3002", "result": "\u6570\u5b57\u73af\u5883\u4f5c\u4e3a\u5b8c\u5168\u6784\u5efa\u7684\u7a7a\u95f4\uff0c\u4e3a\u610f\u4e49\u521b\u9020\u548c\u81ea\u6211\u53cd\u601d\u63d0\u4f9b\u4e86\u65b0\u5f62\u5f0f\uff0c\u6e38\u620f\u6210\u4e3a\u5fc3\u7406\u5730\u7406\u5b66\u7684\u5b9e\u9a8c\u5ba4\u548c\u666f\u89c2\u3002", "conclusion": "\u901a\u8fc7\u8fd9\u79cd\u91cd\u6784\uff0c\u6e38\u620f\u4e0d\u4ec5\u6210\u4e3a\u8857\u9053\u548c\u57ce\u5e02\u7cbe\u795e\u7684\u5b9e\u9a8c\u5ba4\uff0c\u4e5f\u6210\u4e3a\u4ee3\u7801\u3001\u50cf\u7d20\u548c\u6e38\u620f\u4e2d\u5e7d\u7075\u7684\u5fc3\u7406\u5730\u7406\u5b66\u666f\u89c2\uff0c\u4e3a\u5fc3\u7406\u5730\u7406\u5b66\u6ce8\u5165\u4e86\u65b0\u7684\u6d3b\u529b\u3002"}}
{"id": "2511.04142", "categories": ["econ.TH", "91B14, 91B03, 91B68"], "pdf": "https://arxiv.org/pdf/2511.04142", "abs": "https://arxiv.org/abs/2511.04142", "authors": ["Sai Praneeth Donthu", "Souvik Roy", "Soumyarup Sadhukhan", "Gogulapati Sreedurga"], "title": "A characterization of strategy-proof probabilistic assignment rules", "comment": "27 pages", "summary": "We study the classical probabilistic assignment problem, where finitely many\nindivisible objects are to be probabilistically or proportionally assigned\namong an equal number of agents. Each agent has an initial deterministic\nendowment and a strict preference over the objects. While the deterministic\nversion of this problem is well understood, most notably through the\ncharacterization of the Top Trading Cycles (TTC) rule by Ma (1994), much less\nis known in the probabilistic setting. Motivated by practical considerations,\nwe introduce a weakened incentive requirement, namely\nSD-top-strategy-proofness, which precludes only those manipulations that\nincrease the probability of an agent's top-ranked object.\n  Our first main result shows that, on any free pair at the top (FPT) domain\n(Sen, 2011), the TTC rule is the unique probabilistic assignment rule\nsatisfying SD-Pareto efficiency, SD-individual rationality, and\nSD-top-strategy-proofness. We further show that this characterization remains\nvalid when Pareto efficiency is replaced by the weaker notion of SD-pair\nefficiency, provided the domain satisfies the slightly stronger free triple at\nthe top (FTT) condition (Sen, 2011). Finally, we extend these results to the ex\npost notions of efficiency and individual rationality.\n  Together, our findings generalize the classical deterministic results of Ma\n(1994) and Ekici (2024) along three dimensions: extending them from\ndeterministic to probabilistic settings, from full strategy-proofness to\ntop-strategy-proofness, and from the unrestricted domain to the more general\nFPT and FTT domains.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u6982\u7387\u5206\u914d\u95ee\u9898\uff0c\u5728\u81ea\u7531\u5bf9\u9876(FPT)\u548c\u81ea\u7531\u4e09\u9876(FTT)\u57df\u4e0a\uff0c\u8bc1\u660e\u4e86TTC\u89c4\u5219\u662f\u552f\u4e00\u6ee1\u8db3SD-\u5e15\u7d2f\u6258\u6548\u7387\u3001SD-\u4e2a\u4f53\u7406\u6027\u548cSD-\u9876\u7b56\u7565\u8bc1\u660e\u6027\u7684\u6982\u7387\u5206\u914d\u89c4\u5219\u3002", "motivation": "\u786e\u5b9a\u6027\u5206\u914d\u95ee\u9898\u5df2\u6709\u6df1\u5165\u7814\u7a76\uff0c\u4f46\u6982\u7387\u8bbe\u7f6e\u4e0b\u7684\u7814\u7a76\u8f83\u5c11\u3002\u53d7\u5b9e\u9645\u8003\u8651\u9a71\u52a8\uff0c\u5f15\u5165\u5f31\u5316\u7684\u6fc0\u52b1\u8981\u6c42SD-\u9876\u7b56\u7565\u8bc1\u660e\u6027\uff0c\u53ea\u963b\u6b62\u90a3\u4e9b\u589e\u52a0\u4ee3\u7406\u4eba\u9996\u9009\u5bf9\u8c61\u6982\u7387\u7684\u64cd\u7eb5\u3002", "method": "\u5728FPT\u548cFTT\u57df\u4e0a\u5206\u6790TTC\u89c4\u5219\u7684\u6027\u8d28\uff0c\u4f7f\u7528SD-\u5e15\u7d2f\u6258\u6548\u7387\u3001SD-\u4e2a\u4f53\u7406\u6027\u548cSD-\u9876\u7b56\u7565\u8bc1\u660e\u6027\u7b49\u6982\u5ff5\uff0c\u5e76\u4e0e\u786e\u5b9a\u6027\u7ed3\u679c\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728FPT\u57df\u4e0a\uff0cTTC\u89c4\u5219\u662f\u552f\u4e00\u6ee1\u8db3SD-\u5e15\u7d2f\u6258\u6548\u7387\u3001SD-\u4e2a\u4f53\u7406\u6027\u548cSD-\u9876\u7b56\u7565\u8bc1\u660e\u6027\u7684\u6982\u7387\u5206\u914d\u89c4\u5219\u3002\u5728FTT\u57df\u4e0a\uff0c\u5373\u4f7f\u5c06\u5e15\u7d2f\u6258\u6548\u7387\u5f31\u5316\u4e3aSD-\u5bf9\u6548\u7387\uff0c\u8be5\u7279\u5f81\u4ecd\u7136\u6210\u7acb\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4ece\u4e09\u4e2a\u7ef4\u5ea6\u63a8\u5e7f\u4e86\u7ecf\u5178\u7684\u786e\u5b9a\u6027\u7ed3\u679c\uff1a\u4ece\u786e\u5b9a\u6027\u6269\u5c55\u5230\u6982\u7387\u8bbe\u7f6e\uff0c\u4ece\u5b8c\u5168\u7b56\u7565\u8bc1\u660e\u6027\u6269\u5c55\u5230\u9876\u7b56\u7565\u8bc1\u660e\u6027\uff0c\u4ece\u65e0\u9650\u5236\u57df\u6269\u5c55\u5230\u66f4\u4e00\u822c\u7684FPT\u548cFTT\u57df\u3002"}}
{"id": "2511.03740", "categories": ["eess.SY", "cs.MA", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03740", "abs": "https://arxiv.org/abs/2511.03740", "authors": ["Xinyi Wang", "Devansh R. Agrawal", "Dimitra Panagou"], "title": "Kalman-Bucy Filtering with Randomized Sensing: Fundamental Limits and Sensor Network Design for Field Estimation", "comment": null, "summary": "Stability analysis of the Kalman filter under randomly lost measurements has\nbeen widely studied. We revisit this problem in a general continuous-time\nframework, where both the measurement matrix and noise covariance evolve as\nrandom processes, capturing variability in sensing locations. Within this\nsetting, we derive a closed-form upper bound on the expected estimation\ncovariance for continuous-time Kalman filtering. We then apply this framework\nto spatiotemporal field estimation, where the field is modeled as a Gaussian\nprocess observed by randomly located, noisy sensors. Using clarity, introduced\nin our earlier work as a rescaled form of the differential entropy of a random\nvariable, we establish a grid-independent lower bound on the spatially averaged\nexpected clarity. This result exposes fundamental performance limits through a\ncomposite sensing parameter that jointly captures the effects of the number of\nsensors, noise level, and measurement frequency. Simulations confirm that the\nproposed bound is tight for the discrete-time Kalman filter, approaching it as\nthe measurement rate decreases, while avoiding the recursive computations\nrequired in the discrete-time formulation. Most importantly, the derived limits\nprovide principled and efficient guidelines for sensor network design problem\nprior to deployment.", "AI": {"tldr": "\u672c\u6587\u5728\u8fde\u7eed\u65f6\u95f4\u6846\u67b6\u4e0b\u7814\u7a76\u4e86\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5728\u968f\u673a\u4e22\u5931\u6d4b\u91cf\u60c5\u51b5\u4e0b\u7684\u7a33\u5b9a\u6027\uff0c\u63a8\u5bfc\u4e86\u4f30\u8ba1\u534f\u65b9\u5dee\u7684\u95ed\u5f0f\u4e0a\u754c\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u65f6\u7a7a\u573a\u4f30\u8ba1\uff0c\u5efa\u7acb\u4e86\u4e0e\u7f51\u683c\u65e0\u5173\u7684\u6e05\u6670\u5ea6\u4e0b\u754c\uff0c\u4e3a\u4f20\u611f\u5668\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u6307\u5bfc\u3002", "motivation": "\u7814\u7a76\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5728\u968f\u673a\u4e22\u5931\u6d4b\u91cf\u548c\u53d8\u5316\u4f20\u611f\u4f4d\u7f6e\u4e0b\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u65e8\u5728\u4e3a\u4f20\u611f\u5668\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u5728\u8fde\u7eed\u65f6\u95f4\u6846\u67b6\u4e0b\uff0c\u8003\u8651\u6d4b\u91cf\u77e9\u9635\u548c\u566a\u58f0\u534f\u65b9\u5dee\u4f5c\u4e3a\u968f\u673a\u8fc7\u7a0b\uff0c\u63a8\u5bfc\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u7684\u671f\u671b\u4f30\u8ba1\u534f\u65b9\u5dee\u95ed\u5f0f\u4e0a\u754c\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u5efa\u6a21\u7684\u65f6\u7a7a\u573a\u4f30\u8ba1\u3002", "result": "\u5efa\u7acb\u4e86\u7a7a\u95f4\u5e73\u5747\u671f\u671b\u6e05\u6670\u5ea6\u7684\u7f51\u683c\u65e0\u5173\u4e0b\u754c\uff0c\u63ed\u793a\u4e86\u901a\u8fc7\u590d\u5408\u4f20\u611f\u53c2\u6570\u6355\u83b7\u4f20\u611f\u5668\u6570\u91cf\u3001\u566a\u58f0\u6c34\u5e73\u548c\u6d4b\u91cf\u9891\u7387\u5f71\u54cd\u7684\u57fa\u672c\u6027\u80fd\u9650\u5236\uff0c\u4eff\u771f\u9a8c\u8bc1\u4e86\u8be5\u754c\u9650\u5bf9\u79bb\u6563\u65f6\u95f4\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u7684\u7d27\u81f4\u6027\u3002", "conclusion": "\u6240\u63a8\u5bfc\u7684\u6027\u80fd\u754c\u9650\u4e3a\u4f20\u611f\u5668\u7f51\u7edc\u90e8\u7f72\u524d\u7684\u8bbe\u8ba1\u95ee\u9898\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u548c\u9ad8\u6548\u7684\u6307\u5bfc\uff0c\u907f\u514d\u4e86\u79bb\u6563\u65f6\u95f4\u516c\u5f0f\u6240\u9700\u7684\u9012\u5f52\u8ba1\u7b97\u3002"}}
{"id": "2511.03845", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03845", "abs": "https://arxiv.org/abs/2511.03845", "authors": ["Tianning Dong", "Luyi Ma", "Varun Vasudevan", "Jason Cho", "Sushant Kumar", "Kannan Achan"], "title": "To See or To Read: User Behavior Reasoning in Multimodal LLMs", "comment": "Accepted by the 39th Conference on Neural Information Processing\n  Systems (NeurIPS 2025) Workshop: Efficient Reasoning", "summary": "Multimodal Large Language Models (MLLMs) are reshaping how modern agentic\nsystems reason over sequential user-behavior data. However, whether textual or\nimage representations of user behavior data are more effective for maximizing\nMLLM performance remains underexplored. We present \\texttt{BehaviorLens}, a\nsystematic benchmarking framework for assessing modality trade-offs in\nuser-behavior reasoning across six MLLMs by representing transaction data as\n(1) a text paragraph, (2) a scatter plot, and (3) a flowchart. Using a\nreal-world purchase-sequence dataset, we find that when data is represented as\nimages, MLLMs next-purchase prediction accuracy is improved by 87.5% compared\nwith an equivalent textual representation without any additional computational\ncost.", "AI": {"tldr": "BehaviorLens\u6846\u67b6\u7cfb\u7edf\u8bc4\u4f30\u4e86\u7528\u6237\u884c\u4e3a\u6570\u636e\u5728\u6587\u672c\u548c\u56fe\u50cf\u8868\u793a\u4e0b\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u56fe\u50cf\u8868\u793a\u80fd\u5c06\u4e0b\u4e00\u4e2a\u8d2d\u4e70\u9884\u6d4b\u51c6\u786e\u7387\u63d0\u534787.5%\u3002", "motivation": "\u63a2\u7d22\u6587\u672c\u548c\u56fe\u50cf\u4e24\u79cd\u7528\u6237\u884c\u4e3a\u6570\u636e\u8868\u793a\u65b9\u5f0f\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u4ee5\u786e\u5b9a\u54ea\u79cd\u8868\u793a\u65b9\u5f0f\u80fd\u6700\u5927\u5316\u6a21\u578b\u8868\u73b0\u3002", "method": "\u5f00\u53d1BehaviorLens\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u5728\u516d\u4e2aMLLM\u4e0a\u8bc4\u4f30\u4e09\u79cd\u6570\u636e\u8868\u793a\u65b9\u5f0f\uff1a\u6587\u672c\u6bb5\u843d\u3001\u6563\u70b9\u56fe\u548c\u6d41\u7a0b\u56fe\uff0c\u4f7f\u7528\u771f\u5b9e\u8d2d\u4e70\u5e8f\u5217\u6570\u636e\u96c6\u3002", "result": "\u5f53\u6570\u636e\u8868\u793a\u4e3a\u56fe\u50cf\u65f6\uff0cMLLM\u7684\u4e0b\u4e00\u4e2a\u8d2d\u4e70\u9884\u6d4b\u51c6\u786e\u7387\u6bd4\u7b49\u6548\u6587\u672c\u8868\u793a\u63d0\u9ad8\u4e8687.5%\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u56fe\u50cf\u8868\u793a\u5728\u7528\u6237\u884c\u4e3a\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u6587\u672c\u8868\u793a\uff0c\u4e3a\u4f18\u5316MLLM\u6027\u80fd\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2511.04616", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.04616", "abs": "https://arxiv.org/abs/2511.04616", "authors": ["Elvis Agbenyega", "Cody Quick"], "title": "Nonparametric Safety Stock Dimensioning: A Data-Driven Approach for Supply Chains of Hardware OEMs", "comment": "17 pages, 3 figures, 3 tables. To appear in INFORMs journal", "summary": "Resilient supply chains are critical, especially for Original Equipment\nManufacturers (OEMs) that power today's digital economy. Safety Stock\ndimensioning-the computation of the appropriate safety stock quantity-is one of\nseveral mechanisms to ensure supply chain resiliency, as it protects the supply\nchain against demand and supply uncertainties. Unfortunately, the major\napproaches to dimensioning safety stock heavily assume that demand is normally\ndistributed and ignore future demand variability, limiting their applicability\nin manufacturing contexts where demand is non-normal, intermittent, and highly\nskewed. In this paper, we propose a data-driven approach that relaxes the\nassumption of normality, enabling the demand distribution of each inventory\nitem to be analytically determined using Kernel Density Estimation. Also, we\nextended the analysis from historical demand variability to forecasted demand\nvariability. We evaluated the proposed approach against a normal distribution\nmodel in a near-world inventory replenishment simulation. Afterwards, we used a\nlinear optimization model to determine the optimal safety stock configuration.\nThe results from the simulation and linear optimization models showed that the\ndata-driven approach outperformed traditional approaches. In particular, the\ndata-driven approach achieved the desired service levels at lower safety stock\nlevels than the conventional approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u6838\u5bc6\u5ea6\u4f30\u8ba1\u786e\u5b9a\u9700\u6c42\u5206\u5e03\uff0c\u5e76\u8003\u8651\u9884\u6d4b\u9700\u6c42\u53d8\u5f02\u6027\uff0c\u5728\u5e93\u5b58\u8865\u8d27\u6a21\u62df\u4e2d\u4f18\u4e8e\u4f20\u7edf\u6b63\u6001\u5206\u5e03\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5b89\u5168\u5e93\u5b58\u8ba1\u7b97\u65b9\u6cd5\u5047\u8bbe\u9700\u6c42\u670d\u4ece\u6b63\u6001\u5206\u5e03\u4e14\u5ffd\u7565\u672a\u6765\u9700\u6c42\u53d8\u5f02\u6027\uff0c\u5728\u5236\u9020\u4e1a\u4e2d\u9700\u6c42\u901a\u5e38\u662f\u975e\u6b63\u6001\u3001\u95f4\u6b47\u6027\u548c\u9ad8\u5ea6\u504f\u659c\u7684\uff0c\u9650\u5236\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u9002\u7528\u6027\u3002", "method": "\u4f7f\u7528\u6838\u5bc6\u5ea6\u4f30\u8ba1\u786e\u5b9a\u6bcf\u4e2a\u5e93\u5b58\u9879\u76ee\u7684\u9700\u6c42\u5206\u5e03\uff0c\u5c06\u5206\u6790\u4ece\u5386\u53f2\u9700\u6c42\u53d8\u5f02\u6027\u6269\u5c55\u5230\u9884\u6d4b\u9700\u6c42\u53d8\u5f02\u6027\uff0c\u901a\u8fc7\u7ebf\u6027\u4f18\u5316\u6a21\u578b\u786e\u5b9a\u6700\u4f18\u5b89\u5168\u5e93\u5b58\u914d\u7f6e\u3002", "result": "\u5728\u8fd1\u771f\u5b9e\u4e16\u754c\u7684\u5e93\u5b58\u8865\u8d27\u6a21\u62df\u4e2d\uff0c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4ee5\u66f4\u4f4e\u7684\u5b89\u5168\u5e93\u5b58\u6c34\u5e73\u5b9e\u73b0\u4e86\u671f\u671b\u7684\u670d\u52a1\u6c34\u5e73\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u80fd\u591f\u653e\u677e\u6b63\u6001\u6027\u5047\u8bbe\uff0c\u66f4\u51c6\u786e\u5730\u5904\u7406\u975e\u6b63\u6001\u9700\u6c42\u5206\u5e03\uff0c\u5728\u4fdd\u6301\u670d\u52a1\u6c34\u5e73\u7684\u540c\u540b\u964d\u4f4e\u5b89\u5168\u5e93\u5b58\u6c34\u5e73\u3002"}}
{"id": "2511.04131", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04131", "abs": "https://arxiv.org/abs/2511.04131", "authors": ["Yitang Li", "Zhengyi Luo", "Tonghe Zhang", "Cunxi Dai", "Anssi Kanervisto", "Andrea Tirinzoni", "Haoyang Weng", "Kris Kitani", "Mateusz Guzek", "Ahmed Touati", "Alessandro Lazaric", "Matteo Pirotta", "Guanya Shi"], "title": "BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning", "comment": null, "summary": "Building Behavioral Foundation Models (BFMs) for humanoid robots has the\npotential to unify diverse control tasks under a single, promptable generalist\npolicy. However, existing approaches are either exclusively deployed on\nsimulated humanoid characters, or specialized to specific tasks such as\ntracking. We propose BFM-Zero, a framework that learns an effective shared\nlatent representation that embeds motions, goals, and rewards into a common\nspace, enabling a single policy to be prompted for multiple downstream tasks\nwithout retraining. This well-structured latent space in BFM-Zero enables\nversatile and robust whole-body skills on a Unitree G1 humanoid in the real\nworld, via diverse inference methods, including zero-shot motion tracking, goal\nreaching, and reward optimization, and few-shot optimization-based adaptation.\nUnlike prior on-policy reinforcement learning (RL) frameworks, BFM-Zero builds\nupon recent advancements in unsupervised RL and Forward-Backward (FB) models,\nwhich offer an objective-centric, explainable, and smooth latent representation\nof whole-body motions. We further extend BFM-Zero with critical reward shaping,\ndomain randomization, and history-dependent asymmetric learning to bridge the\nsim-to-real gap. Those key design choices are quantitatively ablated in\nsimulation. A first-of-its-kind model, BFM-Zero establishes a step toward\nscalable, promptable behavioral foundation models for whole-body humanoid\ncontrol.", "AI": {"tldr": "BFM-Zero\u662f\u4e00\u4e2a\u7528\u4e8e\u4eba\u5f62\u673a\u5668\u4eba\u7684\u884c\u4e3a\u57fa\u7840\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u6f5c\u5728\u8868\u793a\u7edf\u4e00\u591a\u79cd\u63a7\u5236\u4efb\u52a1\uff0c\u652f\u6301\u96f6\u6837\u672c\u8fd0\u52a8\u8ddf\u8e2a\u3001\u76ee\u6807\u5230\u8fbe\u548c\u5956\u52b1\u4f18\u5316\uff0c\u4ee5\u53ca\u5c11\u6837\u672c\u4f18\u5316\u9002\u5e94\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4ec5\u90e8\u7f72\u5728\u6a21\u62df\u4eba\u5f62\u89d2\u8272\u4e0a\uff0c\u8981\u4e48\u4e13\u95e8\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\uff08\u5982\u8ddf\u8e2a\uff09\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u591a\u4efb\u52a1\u63a7\u5236\u7b56\u7565\u3002", "method": "\u57fa\u4e8e\u65e0\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u548c\u524d\u5411-\u540e\u5411\u6a21\u578b\uff0c\u6784\u5efa\u5171\u4eab\u6f5c\u5728\u8868\u793a\u7a7a\u95f4\uff0c\u5d4c\u5165\u8fd0\u52a8\u3001\u76ee\u6807\u548c\u5956\u52b1\uff0c\u7ed3\u5408\u5173\u952e\u5956\u52b1\u5851\u9020\u3001\u9886\u57df\u968f\u673a\u5316\u548c\u5386\u53f2\u4f9d\u8d56\u975e\u5bf9\u79f0\u5b66\u4e60\u6765\u5f25\u5408\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7684Unitree G1\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u4e86\u591a\u529f\u80fd\u548c\u9c81\u68d2\u7684\u5168\u8eab\u4f53\u6280\u80fd\uff0c\u901a\u8fc7\u5b9a\u91cf\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\u7684\u6709\u6548\u6027\u3002", "conclusion": "BFM-Zero\u4e3a\u5168\u8eab\u4f53\u4eba\u5f62\u63a7\u5236\u7684\u53ef\u6269\u5c55\u3001\u53ef\u63d0\u793a\u884c\u4e3a\u57fa\u7840\u6a21\u578b\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2511.04588", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.04588", "abs": "https://arxiv.org/abs/2511.04588", "authors": ["Soham De", "Lodewijk Gelauff", "Ashish Goel", "Smitha Milli", "Ariel Procaccia", "Alice Siu"], "title": "Question the Questions: Auditing Representation in Online Deliberative Processes", "comment": null, "summary": "A central feature of many deliberative processes, such as citizens'\nassemblies and deliberative polls, is the opportunity for participants to\nengage directly with experts. While participants are typically invited to\npropose questions for expert panels, only a limited number can be selected due\nto time constraints. This raises the challenge of how to choose a small set of\nquestions that best represent the interests of all participants. We introduce\nan auditing framework for measuring the level of representation provided by a\nslate of questions, based on the social choice concept known as justified\nrepresentation (JR). We present the first algorithms for auditing JR in the\ngeneral utility setting, with our most efficient algorithm achieving a runtime\nof $O(mn\\log n)$, where $n$ is the number of participants and $m$ is the number\nof proposed questions. We apply our auditing methods to historical\ndeliberations, comparing the representativeness of (a) the actual questions\nposed to the expert panel (chosen by a moderator), (b) participants' questions\nchosen via integer linear programming, (c) summary questions generated by large\nlanguage models (LLMs). Our results highlight both the promise and current\nlimitations of LLMs in supporting deliberative processes. By integrating our\nmethods into an online deliberation platform that has been used for over\nhundreds of deliberations across more than 50 countries, we make it easy for\npractitioners to audit and improve representation in future deliberations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5408\u7406\u4ee3\u8868(JR)\u6982\u5ff5\u7684\u5ba1\u8ba1\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e13\u5bb6\u95ee\u7b54\u73af\u8282\u4e2d\u95ee\u9898\u9009\u62e9\u7684\u4ee3\u8868\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u5ba1\u8ba1\u7b97\u6cd5\u3002", "motivation": "\u5728\u516c\u6c11\u5927\u4f1a\u7b49\u5ba1\u8bae\u8fc7\u7a0b\u4e2d\uff0c\u53c2\u4e0e\u8005\u53ea\u80fd\u5411\u4e13\u5bb6\u63d0\u51fa\u6709\u9650\u6570\u91cf\u7684\u95ee\u9898\uff0c\u9700\u8981\u786e\u4fdd\u6240\u9009\u95ee\u9898\u80fd\u591f\u5145\u5206\u4ee3\u8868\u6240\u6709\u53c2\u4e0e\u8005\u7684\u5229\u76ca\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5408\u7406\u4ee3\u8868(JR)\u6982\u5ff5\u7684\u5ba1\u8ba1\u6846\u67b6\uff0c\u5f00\u53d1O(mn log n)\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u5ba1\u8ba1\u7b97\u6cd5\uff0c\u6bd4\u8f83\u4e86\u4e3b\u6301\u4eba\u9009\u62e9\u3001\u6574\u6570\u7ebf\u6027\u89c4\u5212\u9009\u62e9\u548cLLM\u751f\u6210\u95ee\u9898\u4e09\u79cd\u65b9\u6cd5\u3002", "result": "\u5e94\u7528\u5ba1\u8ba1\u65b9\u6cd5\u5206\u6790\u5386\u53f2\u5ba1\u8bae\u6570\u636e\uff0c\u63ed\u793a\u4e86LLM\u5728\u652f\u6301\u5ba1\u8bae\u8fc7\u7a0b\u4e2d\u7684\u6f5c\u529b\u548c\u5f53\u524d\u5c40\u9650\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06\u5ba1\u8ba1\u65b9\u6cd5\u96c6\u6210\u5230\u5728\u7ebf\u5ba1\u8bae\u5e73\u53f0\uff0c\u4f7f\u5b9e\u8df5\u8005\u80fd\u591f\u8f7b\u677e\u5ba1\u8ba1\u548c\u6539\u8fdb\u672a\u6765\u5ba1\u8bae\u4e2d\u7684\u4ee3\u8868\u6027\u3002"}}
{"id": "2511.04449", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.04449", "abs": "https://arxiv.org/abs/2511.04449", "authors": ["David Lagziel", "Ehud Lehrer", "Tao Wang"], "title": "Comparison of Oracles: Part II", "comment": null, "summary": "This paper studies incomplete-information games in which an information\nprovider, an oracle, publicly discloses information to the players. One oracle\nis said to dominate another if, in every game, it can replicate the equilibrium\noutcomes induced by the latter. The companion Part I characterizes dominance\nunder deterministic signaling and under stochastic signaling with a unique\ncommon knowledge component. The present paper extends the analysis to general\nenvironments and provides a characterization of equivalence (mutual dominance)\namong oracles. To this end, we develop a theory of information loops, thereby\nextending the seminal work of Blackwell (1951) to strategic environments and\nAumann (1976)'s theory of common knowledge.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e0d\u5b8c\u5168\u4fe1\u606f\u535a\u5f08\u4e2d\u4fe1\u606f\u63d0\u4f9b\u8005\uff08\u9884\u8a00\u673a\uff09\u5411\u73a9\u5bb6\u516c\u5f00\u62ab\u9732\u4fe1\u606f\u7684\u60c5\u51b5\u3002\u4e00\u4e2a\u9884\u8a00\u673a\u652f\u914d\u53e6\u4e00\u4e2a\u9884\u8a00\u673a\u610f\u5473\u7740\u5728\u6240\u6709\u535a\u5f08\u4e2d\uff0c\u524d\u8005\u53ef\u4ee5\u590d\u5236\u540e\u8005\u8bf1\u5bfc\u7684\u5747\u8861\u7ed3\u679c\u3002\u672c\u6587\u6269\u5c55\u4e86Part I\u7684\u5206\u6790\uff0c\u5728\u4e00\u822c\u73af\u5883\u4e0b\u63d0\u4f9b\u4e86\u9884\u8a00\u673a\u7b49\u4ef7\u6027\uff08\u76f8\u4e92\u652f\u914d\uff09\u7684\u8868\u5f81\u3002", "motivation": "\u6269\u5c55\u4e0d\u5b8c\u5168\u4fe1\u606f\u535a\u5f08\u4e2d\u4fe1\u606f\u63d0\u4f9b\u8005\u652f\u914d\u5173\u7cfb\u7684\u5206\u6790\u5230\u4e00\u822c\u73af\u5883\uff0c\u5efa\u7acb\u9884\u8a00\u673a\u7b49\u4ef7\u6027\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06Blackwell\u548cAumann\u7684\u7ecf\u5178\u5de5\u4f5c\u6269\u5c55\u5230\u6218\u7565\u73af\u5883\u4e2d\u3002", "method": "\u53d1\u5c55\u4e86\u4fe1\u606f\u5faa\u73af\u7406\u8bba\uff0c\u6269\u5c55Blackwell(1951)\u548cAumann(1976)\u7684\u7ecf\u5178\u7406\u8bba\u5230\u6218\u7565\u73af\u5883\uff0c\u5728\u4e00\u822c\u73af\u5883\u4e0b\u8868\u5f81\u9884\u8a00\u673a\u7684\u7b49\u4ef7\u5173\u7cfb\u3002", "result": "\u63d0\u4f9b\u4e86\u9884\u8a00\u673a\u7b49\u4ef7\u6027\uff08\u76f8\u4e92\u652f\u914d\uff09\u7684\u5b8c\u6574\u8868\u5f81\uff0c\u5efa\u7acb\u4e86\u4fe1\u606f\u5faa\u73af\u7406\u8bba\u5728\u6218\u7565\u73af\u5883\u4e2d\u7684\u5e94\u7528\u6846\u67b6\u3002", "conclusion": "\u901a\u8fc7\u53d1\u5c55\u4fe1\u606f\u5faa\u73af\u7406\u8bba\uff0c\u6210\u529f\u5c06Blackwell\u548cAumann\u7684\u7ecf\u5178\u4fe1\u606f\u7406\u8bba\u6269\u5c55\u5230\u6218\u7565\u73af\u5883\uff0c\u4e3a\u4e0d\u5b8c\u5168\u4fe1\u606f\u535a\u5f08\u4e2d\u4fe1\u606f\u63d0\u4f9b\u8005\u7684\u7b49\u4ef7\u5173\u7cfb\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.03741", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03741", "abs": "https://arxiv.org/abs/2511.03741", "authors": ["Xiachong Lin", "Arian Prabowo", "Imran Razzak", "Hao Xue", "Matthew Amos", "Sam Behrens", "Flora D. Salim"], "title": "Electric Vehicle Charging Load Modeling: A Survey, Trends, Challenges and Opportunities", "comment": "14 pages, 7 figures", "summary": "The evolution of electric vehicles (EVs) is reshaping the automotive\nindustry, advocating for more sustainable transportation practices. Accurately\npredicting EV charging behavior is essential for effective infrastructure\nplanning and optimization. However, the charging load of EVs is significantly\ninfluenced by uncertainties and randomness, posing challenges for accurate\nestimation. Furthermore, existing literature reviews lack a systematic analysis\nof modeling approaches focused on information fusion. This paper\ncomprehensively reviews EV charging load models from the past five years. We\ncategorize state-of-the-art modeling methods into statistical, simulated, and\ndata-driven approaches, examining the advantages and drawbacks of each.\nAdditionally, we analyze the three bottom-up level operations of information\nfusion in existing models. We conclude by discussing the challenges and\nopportunities in the field, offering guidance for future research endeavors to\nadvance our understanding and explore practical research directions.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u8fc7\u53bb\u4e94\u5e74\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u8d1f\u8377\u6a21\u578b\uff0c\u5c06\u5efa\u6a21\u65b9\u6cd5\u5206\u4e3a\u7edf\u8ba1\u3001\u4eff\u771f\u548c\u6570\u636e\u9a71\u52a8\u4e09\u7c7b\uff0c\u5206\u6790\u4e86\u4fe1\u606f\u878d\u5408\u7684\u4e09\u4e2a\u5e95\u5c42\u64cd\u4f5c\uff0c\u5e76\u8ba8\u8bba\u4e86\u8be5\u9886\u57df\u7684\u6311\u6218\u4e0e\u673a\u9047\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u884c\u4e3a\u9884\u6d4b\u5bf9\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u548c\u4f18\u5316\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5145\u7535\u8d1f\u8377\u53d7\u4e0d\u786e\u5b9a\u6027\u548c\u968f\u673a\u6027\u5f71\u54cd\uff0c\u73b0\u6709\u6587\u732e\u7f3a\u4e4f\u5bf9\u4fe1\u606f\u878d\u5408\u5efa\u6a21\u65b9\u6cd5\u7684\u7cfb\u7edf\u5206\u6790\u3002", "method": "\u5bf9\u8fc7\u53bb\u4e94\u5e74EV\u5145\u7535\u8d1f\u8377\u6a21\u578b\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\uff0c\u5c06\u5efa\u6a21\u65b9\u6cd5\u5206\u4e3a\u7edf\u8ba1\u65b9\u6cd5\u3001\u4eff\u771f\u65b9\u6cd5\u548c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u4e09\u7c7b\uff0c\u5e76\u5206\u6790\u4fe1\u606f\u878d\u5408\u5728\u73b0\u6709\u6a21\u578b\u4e2d\u7684\u4e09\u4e2a\u5e95\u5c42\u64cd\u4f5c\u3002", "result": "\u7cfb\u7edf\u68b3\u7406\u4e86\u5404\u7c7b\u5efa\u6a21\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u8bc6\u522b\u4e86\u4fe1\u606f\u878d\u5408\u5728EV\u5145\u7535\u8d1f\u8377\u5efa\u6a21\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e3a\u7406\u89e3\u4e0d\u540c\u5efa\u6a21\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6846\u67b6\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u8be5\u9886\u57df\u9762\u4e34\u7684\u6311\u6218\u548c\u673a\u9047\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6307\u5bfc\u65b9\u5411\uff0c\u63a8\u52a8\u5bf9\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u884c\u4e3a\u7684\u6df1\u5165\u7406\u89e3\u548c\u5b9e\u9645\u7814\u7a76\u65b9\u5411\u63a2\u7d22\u3002"}}
{"id": "2511.03878", "categories": ["cs.AI", "cs.IR", "cs.LG", "cs.MA", "I.2.7; I.2.0"], "pdf": "https://arxiv.org/pdf/2511.03878", "abs": "https://arxiv.org/abs/2511.03878", "authors": ["Suraj Prasai", "Mengnan Du", "Ying Zhang", "Fan Yang"], "title": "KnowThyself: An Agentic Assistant for LLM Interpretability", "comment": "5 pages, 1 figure, Accepted for publication at the Demonstration\n  Track of the 40th AAAI Conference on Artificial Intelligence (AAAI 26)", "summary": "We develop KnowThyself, an agentic assistant that advances large language\nmodel (LLM) interpretability. Existing tools provide useful insights but remain\nfragmented and code-intensive. KnowThyself consolidates these capabilities into\na chat-based interface, where users can upload models, pose natural language\nquestions, and obtain interactive visualizations with guided explanations. At\nits core, an orchestrator LLM first reformulates user queries, an agent router\nfurther directs them to specialized modules, and the outputs are finally\ncontextualized into coherent explanations. This design lowers technical\nbarriers and provides an extensible platform for LLM inspection. By embedding\nthe whole process into a conversational workflow, KnowThyself offers a robust\nfoundation for accessible LLM interpretability.", "AI": {"tldr": "KnowThyself\u662f\u4e00\u4e2a\u57fa\u4e8e\u804a\u5929\u7684LLM\u53ef\u89e3\u91ca\u6027\u5de5\u5177\uff0c\u901a\u8fc7\u6574\u5408\u73b0\u6709\u788e\u7247\u5316\u529f\u80fd\uff0c\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u548c\u53ef\u89c6\u5316\u89e3\u91ca\uff0c\u964d\u4f4e\u6280\u672f\u95e8\u69db\u3002", "motivation": "\u73b0\u6709LLM\u53ef\u89e3\u91ca\u6027\u5de5\u5177\u529f\u80fd\u5206\u6563\u4e14\u9700\u8981\u7f16\u7a0b\uff0c\u6280\u672f\u95e8\u69db\u9ad8\uff0c\u9700\u8981\u7edf\u4e00\u7684\u6613\u7528\u5e73\u53f0\u3002", "method": "\u4f7f\u7528\u7f16\u6392\u5668LLM\u91cd\u65b0\u8868\u8ff0\u7528\u6237\u67e5\u8be2\uff0c\u901a\u8fc7\u4ee3\u7406\u8def\u7531\u5668\u5206\u53d1\u5230\u4e13\u95e8\u6a21\u5757\uff0c\u6700\u540e\u5c06\u8f93\u51fa\u6574\u5408\u4e3a\u8fde\u8d2f\u89e3\u91ca\u3002", "result": "\u5f00\u53d1\u4e86\u53ef\u6269\u5c55\u7684LLM\u68c0\u67e5\u5e73\u53f0\uff0c\u5d4c\u5165\u5bf9\u8bdd\u5f0f\u5de5\u4f5c\u6d41\u7a0b\uff0c\u63d0\u4f9b\u5f3a\u5927\u7684\u53ef\u8bbf\u95ee\u6027\u57fa\u7840\u3002", "conclusion": "KnowThyself\u901a\u8fc7\u6574\u5408\u788e\u7247\u5316\u5de5\u5177\u548c\u964d\u4f4e\u6280\u672f\u95e8\u69db\uff0c\u4e3aLLM\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u57fa\u7840\u5e73\u53f0\u3002"}}
{"id": "2511.04619", "categories": ["stat.AP", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04619", "abs": "https://arxiv.org/abs/2511.04619", "authors": ["Natalia Glazman", "Jyoti Mangal", "Pedro Borges", "Sebastien Ourselin", "M. Jorge Cardoso"], "title": "Dynamic causal discovery in Alzheimer's disease through latent pseudotime modelling", "comment": "Accepted to the NeurIPS 2025 Workshop on CauScien: Uncovering\n  Causality in Science", "summary": "The application of causal discovery to diseases like Alzheimer's (AD) is\nlimited by the static graph assumptions of most methods; such models cannot\naccount for an evolving pathophysiology, modulated by a latent disease\npseudotime. We propose to apply an existing latent variable model to real-world\nAD data, inferring a pseudotime that orders patients along a data-driven\ndisease trajectory independent of chronological age, then learning how causal\nrelationships evolve. Pseudotime outperformed age in predicting diagnosis (AUC\n0.82 vs 0.59). Incorporating minimal, disease-agnostic background knowledge\nsubstantially improved graph accuracy and orientation. Our framework reveals\ndynamic interactions between novel (NfL, GFAP) and established AD markers,\nenabling practical causal discovery despite violated assumptions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6f5c\u5728\u53d8\u91cf\u6a21\u578b\u7684\u52a8\u6001\u56e0\u679c\u53d1\u73b0\u6846\u67b6\uff0c\u7528\u4e8e\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7814\u7a76\uff0c\u901a\u8fc7\u63a8\u65ad\u75be\u75c5\u4f2a\u65f6\u95f4\u8f68\u8ff9\u6765\u5b66\u4e60\u56e0\u679c\u5173\u7cfb\u7684\u6f14\u5316\u3002", "motivation": "\u4f20\u7edf\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5047\u8bbe\u9759\u6001\u56fe\u7ed3\u6784\uff0c\u65e0\u6cd5\u6355\u6349\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7b49\u75be\u75c5\u4e2d\u968f\u6f5c\u5728\u75be\u75c5\u8fdb\u5c55\u800c\u6f14\u53d8\u7684\u75c5\u7406\u751f\u7406\u5b66\u8fc7\u7a0b\u3002", "method": "\u5e94\u7528\u73b0\u6709\u6f5c\u5728\u53d8\u91cf\u6a21\u578b\u63a8\u65ad\u75be\u75c5\u4f2a\u65f6\u95f4\uff0c\u72ec\u7acb\u4e8e\u5b9e\u9645\u5e74\u9f84\u5bf9\u60a3\u8005\u8fdb\u884c\u6392\u5e8f\uff0c\u7136\u540e\u5b66\u4e60\u56e0\u679c\u5173\u7cfb\u7684\u52a8\u6001\u6f14\u5316\uff0c\u5e76\u6574\u5408\u6700\u5c0f\u5316\u7684\u75be\u75c5\u65e0\u5173\u80cc\u666f\u77e5\u8bc6\u3002", "result": "\u4f2a\u65f6\u95f4\u5728\u9884\u6d4b\u8bca\u65ad\u65b9\u9762\u4f18\u4e8e\u5b9e\u9645\u5e74\u9f84\uff08AUC 0.82 vs 0.59\uff09\uff0c\u6574\u5408\u80cc\u666f\u77e5\u8bc6\u663e\u8457\u63d0\u9ad8\u4e86\u56fe\u7ed3\u6784\u7684\u51c6\u786e\u6027\u548c\u65b9\u5411\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u63ed\u793a\u4e86\u65b0\u578b\u548c\u5df2\u786e\u7acb\u7684AD\u6807\u5fd7\u7269\u4e4b\u95f4\u7684\u52a8\u6001\u76f8\u4e92\u4f5c\u7528\uff0c\u5373\u4f7f\u5728\u5047\u8bbe\u88ab\u8fdd\u53cd\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u5b9e\u7528\u7684\u56e0\u679c\u53d1\u73b0\u3002"}}
{"id": "2511.04180", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04180", "abs": "https://arxiv.org/abs/2511.04180", "authors": ["Yizhen Yin", "Dapeng Feng", "Hongbo Chen", "Yuhua Qi"], "title": "PUL-SLAM: Path-Uncertainty Co-Optimization with Lightweight Stagnation Detection for Efficient Robotic Exploration", "comment": null, "summary": "Existing Active SLAM methodologies face issues such as slow exploration speed\nand suboptimal paths. To address these limitations, we propose a hybrid\nframework combining a Path-Uncertainty Co-Optimization Deep Reinforcement\nLearning framework and a Lightweight Stagnation Detection mechanism. The\nPath-Uncertainty Co-Optimization framework jointly optimizes travel distance\nand map uncertainty through a dual-objective reward function, balancing\nexploration and exploitation. The Lightweight Stagnation Detection reduces\nredundant exploration through Lidar Static Anomaly Detection and Map Update\nStagnation Detection, terminating episodes on low expansion rates. Experimental\nresults show that compared with the frontier-based method and RRT method, our\napproach shortens exploration time by up to 65% and reduces path distance by up\nto 42%, significantly improving exploration efficiency in complex environments\nwhile maintaining reliable map completeness. Ablation studies confirm that the\ncollaborative mechanism accelerates training convergence. Empirical validation\non a physical robotic platform demonstrates the algorithm's practical\napplicability and its successful transferability from simulation to real-world\nenvironments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8def\u5f84-\u4e0d\u786e\u5b9a\u6027\u534f\u540c\u4f18\u5316\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u548c\u8f7b\u91cf\u7ea7\u505c\u6ede\u68c0\u6d4b\u673a\u5236\u7684\u6df7\u5408\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e3b\u52a8SLAM\u7684\u63a2\u7d22\u6548\u7387\u548c\u8def\u5f84\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u4e3b\u52a8SLAM\u65b9\u6cd5\u5b58\u5728\u63a2\u7d22\u901f\u5ea6\u6162\u548c\u8def\u5f84\u6b21\u4f18\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u4f18\u5316\u8def\u5f84\u8ddd\u79bb\u548c\u5730\u56fe\u4e0d\u786e\u5b9a\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u8def\u5f84-\u4e0d\u786e\u5b9a\u6027\u534f\u540c\u4f18\u5316\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u76ee\u6807\u5956\u52b1\u51fd\u6570\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff1b\u7ed3\u5408\u8f7b\u91cf\u7ea7\u505c\u6ede\u68c0\u6d4b\u673a\u5236\uff0c\u901a\u8fc7\u6fc0\u5149\u96f7\u8fbe\u9759\u6001\u5f02\u5e38\u68c0\u6d4b\u548c\u5730\u56fe\u66f4\u65b0\u505c\u6ede\u68c0\u6d4b\u51cf\u5c11\u5197\u4f59\u63a2\u7d22\u3002", "result": "\u76f8\u6bd4\u524d\u6cbf\u65b9\u6cd5\u548cRRT\u65b9\u6cd5\uff0c\u63a2\u7d22\u65f6\u95f4\u7f29\u77ed65%\uff0c\u8def\u5f84\u8ddd\u79bb\u51cf\u5c1142%\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347\u63a2\u7d22\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u9760\u7684\u5730\u56fe\u5b8c\u6574\u6027\u3002", "conclusion": "\u8be5\u6df7\u5408\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u4e3b\u52a8SLAM\u7684\u63a2\u7d22\u6548\u7387\u548c\u8def\u5f84\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u4eff\u771f\u5230\u5b9e\u7269\u7684\u9a8c\u8bc1\u8bc1\u660e\u4e86\u7b97\u6cd5\u7684\u5b9e\u7528\u6027\u548c\u53ef\u8fc1\u79fb\u6027\u3002"}}
{"id": "2511.03742", "categories": ["eess.SY", "cs.SE", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03742", "abs": "https://arxiv.org/abs/2511.03742", "authors": ["Angelos Alexopoulos", "Agorakis Bompotas", "Nikitas Rigas Kalogeropoulos", "Panagiotis Kechagias", "Athanasios P. Kalogeras", "Christos Alexakos"], "title": "A Model-Based Approach to Automated Digital Twin Generation in Manufacturing", "comment": "Accepted for presentation to 10th South-East Europe Design\n  Automation, Computer Engineering, Computer Networks and Social Media\n  Conference (SEEDA-CECNSM 2025)", "summary": "Modern manufacturing demands high flexibility and reconfigurability to adapt\nto dynamic production needs. Model-based Engineering (MBE) supports rapid\nproduction line design, but final reconfiguration requires simulations and\nvalidation. Digital Twins (DTs) streamline this process by enabling real-time\nmonitoring, simulation, and reconfiguration. This paper presents a novel\nplatform that automates DT generation and deployment using AutomationML-based\nfactory plans. The platform closes the loop with a GAI-powered simulation\nscenario generator and automatic physical line reconfiguration, enhancing\nefficiency and adaptability in manufacturing.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u81ea\u52a8\u5316\u6570\u5b57\u5b6a\u751f\u751f\u6210\u548c\u90e8\u7f72\u5e73\u53f0\uff0c\u4f7f\u7528AutomationML\u5de5\u5382\u89c4\u5212\uff0c\u7ed3\u5408GAI\u9a71\u52a8\u7684\u4eff\u771f\u573a\u666f\u751f\u6210\u548c\u81ea\u52a8\u7269\u7406\u4ea7\u7ebf\u91cd\u914d\u7f6e\uff0c\u63d0\u5347\u5236\u9020\u6548\u7387\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u73b0\u4ee3\u5236\u9020\u9700\u8981\u9ad8\u7075\u6d3b\u6027\u548c\u53ef\u91cd\u6784\u6027\u6765\u9002\u5e94\u52a8\u6001\u751f\u4ea7\u9700\u6c42\uff0c\u57fa\u4e8e\u6a21\u578b\u7684\u5de5\u7a0b\u652f\u6301\u5feb\u901f\u4ea7\u7ebf\u8bbe\u8ba1\uff0c\u4f46\u6700\u7ec8\u91cd\u914d\u7f6e\u9700\u8981\u4eff\u771f\u548c\u9a8c\u8bc1\u3002", "method": "\u5f00\u53d1\u4e00\u4e2a\u81ea\u52a8\u5316\u6570\u5b57\u5b6a\u751f\u751f\u6210\u548c\u90e8\u7f72\u5e73\u53f0\uff0c\u57fa\u4e8eAutomationML\u5de5\u5382\u89c4\u5212\uff0c\u4f7f\u7528GAI\u9a71\u52a8\u7684\u4eff\u771f\u573a\u666f\u751f\u6210\u5668\uff0c\u5b9e\u73b0\u81ea\u52a8\u7269\u7406\u4ea7\u7ebf\u91cd\u914d\u7f6e\u3002", "result": "\u8be5\u5e73\u53f0\u901a\u8fc7\u5b9e\u65f6\u76d1\u63a7\u3001\u4eff\u771f\u548c\u91cd\u914d\u7f6e\u7b80\u5316\u4e86\u5236\u9020\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u9002\u5e94\u6027\u3002", "conclusion": "\u8be5\u5e73\u53f0\u6210\u529f\u5b9e\u73b0\u4e86\u6570\u5b57\u5b6a\u751f\u7684\u81ea\u52a8\u5316\u751f\u6210\u548c\u90e8\u7f72\uff0c\u4e3a\u73b0\u4ee3\u5236\u9020\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u91cd\u914d\u7f6e\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.03948", "categories": ["cs.AI", "cs.HC", "I.2.6; K.3.1"], "pdf": "https://arxiv.org/pdf/2511.03948", "abs": "https://arxiv.org/abs/2511.03948", "authors": ["Kevin Hong", "Kia Karbasi", "Gregory Pottie"], "title": "Extracting Causal Relations in Deep Knowledge Tracing", "comment": "Accepted for publication in the Proceedings of the 18th International\n  Conference on Educational Data Mining, 6 pages, 1 figure", "summary": "A longstanding goal in computational educational research is to develop\nexplainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which\nleverages a Recurrent Neural Network (RNN) to predict student knowledge and\nperformance on exercises, has been proposed as a major advancement over\ntraditional KT methods. Several studies suggest that its performance gains stem\nfrom its ability to model bidirectional relationships between different\nknowledge components (KCs) within a course, enabling the inference of a\nstudent's understanding of one KC from their performance on others. In this\npaper, we challenge this prevailing explanation and demonstrate that DKT's\nstrength lies in its implicit ability to model prerequisite relationships as a\ncausal structure, rather than bidirectional relationships. By pruning exercise\nrelation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal\nsubsets of the Assistments dataset, we show that DKT's predictive capabilities\nalign strongly with these causal structures. Furthermore, we propose an\nalternative method for extracting exercise relation DAGs using DKT's learned\nrepresentations and provide empirical evidence supporting our claim. Our\nfindings suggest that DKT's effectiveness is largely driven by its capacity to\napproximate causal dependencies between KCs rather than simple relational\nmappings.", "AI": {"tldr": "\u672c\u6587\u6311\u6218\u4e86\u5173\u4e8e\u6df1\u5ea6\u77e5\u8bc6\u8ffd\u8e2a(DKT)\u6027\u80fd\u63d0\u5347\u6e90\u4e8e\u53cc\u5411\u5173\u7cfb\u5efa\u6a21\u7684\u4f20\u7edf\u89e3\u91ca\uff0c\u63d0\u51faDKT\u7684\u771f\u6b63\u4f18\u52bf\u5728\u4e8e\u5176\u9690\u5f0f\u5efa\u6a21\u5148\u51b3\u6761\u4ef6\u56e0\u679c\u7ed3\u6784\u7684\u80fd\u529b\u3002", "motivation": "\u957f\u671f\u4ee5\u6765\uff0c\u8ba1\u7b97\u6559\u80b2\u7814\u7a76\u7684\u76ee\u6807\u662f\u5f00\u53d1\u53ef\u89e3\u91ca\u7684\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u3002DKT\u4f5c\u4e3a\u4f20\u7edfKT\u65b9\u6cd5\u7684\u91cd\u5927\u8fdb\u6b65\uff0c\u5176\u6027\u80fd\u63d0\u5347\u539f\u56e0\u5b58\u5728\u4e89\u8bae\uff0c\u9700\u8981\u6f84\u6e05\u5176\u771f\u6b63\u7684\u5de5\u4f5c\u539f\u7406\u3002", "method": "\u901a\u8fc7\u5c06\u7ec3\u4e60\u5173\u7cfb\u56fe\u4fee\u526a\u4e3a\u6709\u5411\u65e0\u73af\u56fe(DAG)\uff0c\u5728Assistments\u6570\u636e\u96c6\u7684\u56e0\u679c\u5b50\u96c6\u4e0a\u8bad\u7ec3DKT\uff0c\u5e76\u4f7f\u7528DKT\u5b66\u4e60\u8868\u793a\u63d0\u53d6\u7ec3\u4e60\u5173\u7cfbDAG\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDKT\u7684\u9884\u6d4b\u80fd\u529b\u4e0e\u56e0\u679c\u7ed3\u6784\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5176\u5b66\u4e60\u8868\u793a\u53ef\u7528\u4e8e\u6709\u6548\u63d0\u53d6\u7ec3\u4e60\u5173\u7cfbDAG\uff0c\u652f\u6301DKT\u901a\u8fc7\u8fd1\u4f3cKC\u95f4\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u800c\u975e\u7b80\u5355\u5173\u7cfb\u6620\u5c04\u53d1\u6325\u4f5c\u7528\u7684\u8bba\u70b9\u3002", "conclusion": "DKT\u7684\u6709\u6548\u6027\u4e3b\u8981\u6e90\u4e8e\u5176\u8fd1\u4f3c\u77e5\u8bc6\u7ec4\u4ef6\u95f4\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u7684\u80fd\u529b\uff0c\u800c\u975e\u4f20\u7edf\u8ba4\u4e3a\u7684\u53cc\u5411\u5173\u7cfb\u5efa\u6a21\uff0c\u8fd9\u4e3a\u7406\u89e3DKT\u5de5\u4f5c\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2511.04199", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04199", "abs": "https://arxiv.org/abs/2511.04199", "authors": ["Shenglin Wang", "Mingtong Dai", "Jingxuan Su", "Lingbo Liu", "Chunjie Chen", "Xinyu Wu", "Liang Lin"], "title": "GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments", "comment": null, "summary": "Robotic grasping is a fundamental capability for autonomous manipulation, yet\nremains highly challenging in cluttered environments where occlusion, poor\nperception quality, and inconsistent 3D reconstructions often lead to unstable\nor failed grasps. Conventional pipelines have widely relied on RGB-D cameras to\nprovide geometric information, which fail on transparent or glossy objects and\ndegrade at close range. We present GraspView, an RGB-only robotic grasping\npipeline that achieves accurate manipulation in cluttered environments without\ndepth sensors. Our framework integrates three key components: (i) global\nperception scene reconstruction, which provides locally consistent, up-to-scale\ngeometry from a single RGB view and fuses multi-view projections into a\ncoherent global 3D scene; (ii) a render-and-score active perception strategy,\nwhich dynamically selects next-best-views to reveal occluded regions; and (iii)\nan online metric alignment module that calibrates VGGT predictions against\nrobot kinematics to ensure physical scale consistency. Building on these\ntailor-designed modules, GraspView performs best-view global grasping, fusing\nmulti-view reconstructions and leveraging GraspNet for robust execution.\nExperiments on diverse tabletop objects demonstrate that GraspView\nsignificantly outperforms both RGB-D and single-view RGB baselines, especially\nunder heavy occlusion, near-field sensing, and with transparent objects. These\nresults highlight GraspView as a practical and versatile alternative to RGB-D\npipelines, enabling reliable grasping in unstructured real-world environments.", "AI": {"tldr": "GraspView\u662f\u4e00\u4e2a\u4ec5\u4f7f\u7528RGB\u76f8\u673a\u7684\u673a\u5668\u4eba\u6293\u53d6\u7cfb\u7edf\uff0c\u5728\u6742\u4e71\u73af\u5883\u4e2d\u65e0\u9700\u6df1\u5ea6\u4f20\u611f\u5668\u5373\u53ef\u5b9e\u73b0\u7cbe\u786e\u64cd\u4f5c\uff0c\u7279\u522b\u5728\u906e\u6321\u3001\u900f\u660e\u7269\u4f53\u548c\u8fd1\u8ddd\u79bb\u611f\u77e5\u7b49\u6311\u6218\u6027\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8eRGB-D\u76f8\u673a\u7684\u6293\u53d6\u7cfb\u7edf\u5728\u900f\u660e/\u53cd\u5149\u7269\u4f53\u4e0a\u4f1a\u5931\u6548\uff0c\u4e14\u5728\u8fd1\u8ddd\u79bb\u611f\u77e5\u65f6\u6027\u80fd\u4e0b\u964d\u3002\u9700\u8981\u5f00\u53d1\u4ec5\u4f7f\u7528RGB\u76f8\u673a\u7684\u53ef\u9760\u6293\u53d6\u65b9\u6848\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u96c6\u6210\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u5168\u5c40\u611f\u77e5\u573a\u666f\u91cd\u5efa\uff08\u4ece\u5355RGB\u89c6\u56fe\u751f\u6210\u5c40\u90e8\u4e00\u81f4\u51e0\u4f55\uff09\u3001\u6e32\u67d3\u8bc4\u5206\u4e3b\u52a8\u611f\u77e5\u7b56\u7565\uff08\u52a8\u6001\u9009\u62e9\u6700\u4f73\u89c6\u89d2\u63ed\u793a\u906e\u6321\u533a\u57df\uff09\u3001\u5728\u7ebf\u5ea6\u91cf\u5bf9\u9f50\u6a21\u5757\uff08\u6821\u51c6\u6293\u53d6\u9884\u6d4b\u4e0e\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\uff09\u3002", "result": "\u5728\u591a\u6837\u5316\u684c\u9762\u7269\u4f53\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGraspView\u663e\u8457\u4f18\u4e8eRGB-D\u548c\u5355\u89c6\u56feRGB\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u4e25\u91cd\u906e\u6321\u3001\u8fd1\u8ddd\u79bb\u611f\u77e5\u548c\u900f\u660e\u7269\u4f53\u573a\u666f\u4e2d\u3002", "conclusion": "GraspView\u4f5c\u4e3aRGB-D\u7ba1\u9053\u7684\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u975e\u7ed3\u6784\u5316\u771f\u5b9e\u73af\u5883\u4e2d\u5b9e\u73b0\u53ef\u9760\u7684\u6293\u53d6\u64cd\u4f5c\u3002"}}
{"id": "2511.03743", "categories": ["eess.SY", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SP", "68T05 (Learning and adaptive systems) 93C95 (Neural networks in\n  control theory)", "I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2511.03743", "abs": "https://arxiv.org/abs/2511.03743", "authors": ["Marios Impraimakis"], "title": "A convolutional neural network deep learning method for model class selection", "comment": "31 pages, 16 figures, published in Earthquake Engineering &\n  Structural Dynamics", "summary": "The response-only model class selection capability of a novel deep\nconvolutional neural network method is examined herein in a simple, yet\neffective, manner. Specifically, the responses from a unique degree of freedom\nalong with their class information train and validate a one-dimensional\nconvolutional neural network. In doing so, the network selects the model class\nof new and unlabeled signals without the need of the system input information,\nor full system identification. An optional physics-based algorithm enhancement\nis also examined using the Kalman filter to fuse the system response signals\nusing the kinematics constraints of the acceleration and displacement data.\nImportantly, the method is shown to select the model class in slight signal\nvariations attributed to the damping behavior or hysteresis behavior on both\nlinear and nonlinear dynamic systems, as well as on a 3D building finite\nelement model, providing a powerful tool for structural health monitoring\napplications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e00\u7ef4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6a21\u578b\u7c7b\u522b\u9009\u62e9\u65b9\u6cd5\uff0c\u4ec5\u4f7f\u7528\u7cfb\u7edf\u54cd\u5e94\u4fe1\u53f7\u5373\u53ef\u8bc6\u522b\u52a8\u6001\u7cfb\u7edf\u7684\u6a21\u578b\u7c7b\u522b\uff0c\u65e0\u9700\u8f93\u5165\u4fe1\u606f\u6216\u5b8c\u6574\u7cfb\u7edf\u8fa8\u8bc6\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u7c7b\u522b\u9009\u62e9\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u7cfb\u7edf\u8f93\u5165\u4fe1\u606f\u6216\u5b8c\u6574\u7cfb\u7edf\u8fa8\u8bc6\uff0c\u9650\u5236\u4e86\u5728\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\u3002", "method": "\u4f7f\u7528\u5355\u81ea\u7531\u5ea6\u54cd\u5e94\u4fe1\u53f7\u53ca\u5176\u7c7b\u522b\u4fe1\u606f\u8bad\u7ec3\u4e00\u7ef4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u53ef\u9009\u5730\u4f7f\u7528\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u878d\u5408\u52a0\u901f\u5ea6\u548c\u4f4d\u79fb\u6570\u636e\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u52a8\u6001\u7cfb\u7edf\u4ee5\u53ca3D\u5efa\u7b51\u6709\u9650\u5143\u6a21\u578b\u4e2d\uff0c\u51c6\u786e\u8bc6\u522b\u7531\u963b\u5c3c\u884c\u4e3a\u6216\u8fdf\u6ede\u884c\u4e3a\u5f15\u8d77\u7684\u8f7b\u5fae\u4fe1\u53f7\u53d8\u5316\u5bf9\u5e94\u7684\u6a21\u578b\u7c7b\u522b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u80fd\u591f\u5728\u4ec5\u4f7f\u7528\u54cd\u5e94\u4fe1\u53f7\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u9009\u62e9\u6a21\u578b\u7c7b\u522b\u3002"}}
{"id": "2511.03980", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03980", "abs": "https://arxiv.org/abs/2511.03980", "authors": ["Bram Bult\u00e9", "Ayla Rigouts Terryn"], "title": "LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing", "comment": "Preprint under review at Computational Linguistics. Accepted with\n  minor revisions (10/10/2025); second round", "summary": "Large Language Models (LLMs) are rapidly being adopted by users across the\nglobe, who interact with them in a diverse range of languages. At the same\ntime, there are well-documented imbalances in the training data and\noptimisation objectives of this technology, raising doubts as to whether LLMs\ncan represent the cultural diversity of their broad user base. In this study,\nwe look at LLMs and cultural values and examine how prompt language and\ncultural framing influence model responses and their alignment with human\nvalues in different countries. We probe 10 LLMs with 63 items from the Hofstede\nValues Survey Module and World Values Survey, translated into 11 languages, and\nformulated as prompts with and without different explicit cultural\nperspectives. Our study confirms that both prompt language and cultural\nperspective produce variation in LLM outputs, but with an important caveat:\nWhile targeted prompting can, to a certain extent, steer LLM responses in the\ndirection of the predominant values of the corresponding countries, it does not\novercome the models' systematic bias toward the values associated with a\nrestricted set of countries in our dataset: the Netherlands, Germany, the US,\nand Japan. All tested models, regardless of their origin, exhibit remarkably\nsimilar patterns: They produce fairly neutral responses on most topics, with\nselective progressive stances on issues such as social tolerance. Alignment\nwith cultural values of human respondents is improved more with an explicit\ncultural perspective than with a targeted prompt language. Unexpectedly,\ncombining both approaches is no more effective than cultural framing with an\nEnglish prompt. These findings reveal that LLMs occupy an uncomfortable middle\nground: They are responsive enough to changes in prompts to produce variation,\nbut too firmly anchored to specific cultural defaults to adequately represent\ncultural diversity.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5982\u4f55\u56de\u5e94\u4e0d\u540c\u6587\u5316\u548c\u8bed\u8a00\u63d0\u793a\uff0c\u53d1\u73b0\u867d\u7136\u63d0\u793a\u8bed\u8a00\u548c\u6587\u5316\u6846\u67b6\u80fd\u5f71\u54cd\u6a21\u578b\u8f93\u51fa\uff0c\u4f46LLMs\u4ecd\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u503e\u5411\u4e8e\u8377\u5170\u3001\u5fb7\u56fd\u3001\u7f8e\u56fd\u548c\u65e5\u672c\u7684\u4ef7\u503c\u89c2\u3002", "motivation": "\u968f\u7740LLMs\u5728\u5168\u7403\u8303\u56f4\u5185\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u8bad\u7ec3\u6570\u636e\u548c\u4f18\u5316\u76ee\u6807\u5b58\u5728\u4e0d\u5e73\u8861\uff0c\u5f15\u53d1\u4e86\u5bf9LLMs\u662f\u5426\u80fd\u4ee3\u8868\u5176\u5e7f\u6cdb\u7528\u6237\u7fa4\u6587\u5316\u591a\u6837\u6027\u7684\u8d28\u7591\u3002", "method": "\u4f7f\u7528\u6765\u81ea\u970d\u592b\u65af\u6cf0\u5fb7\u4ef7\u503c\u89c2\u8c03\u67e5\u6a21\u5757\u548c\u4e16\u754c\u4ef7\u503c\u89c2\u8c03\u67e5\u768463\u4e2a\u9879\u76ee\uff0c\u7ffb\u8bd1\u621011\u79cd\u8bed\u8a00\uff0c\u4ee5\u5e26\u6709\u548c\u4e0d\u5e26\u6709\u660e\u786e\u6587\u5316\u89c6\u89d2\u7684\u63d0\u793a\u5f62\u5f0f\u6d4b\u8bd510\u4e2aLLMs\u3002", "result": "\u63d0\u793a\u8bed\u8a00\u548c\u6587\u5316\u89c6\u89d2\u90fd\u4f1a\u5bfc\u81f4LLM\u8f93\u51fa\u53d8\u5316\uff0c\u4f46\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u504f\u5411\u7279\u5b9a\u56fd\u5bb6\u7684\u4ef7\u503c\u89c2\u3002\u660e\u786e\u6587\u5316\u89c6\u89d2\u6bd4\u9488\u5bf9\u6027\u63d0\u793a\u8bed\u8a00\u66f4\u80fd\u6539\u5584\u4e0e\u4eba\u7c7b\u53d7\u8bbf\u8005\u6587\u5316\u4ef7\u503c\u89c2\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "LLMs\u5904\u4e8e\u4e00\u4e2a\u5c34\u5c2c\u7684\u4e2d\u95f4\u5730\u5e26\uff1a\u5b83\u4eec\u5bf9\u63d0\u793a\u53d8\u5316\u8db3\u591f\u654f\u611f\u4ee5\u4ea7\u751f\u53d8\u5316\uff0c\u4f46\u53c8\u8fc7\u4e8e\u56fa\u5b88\u7279\u5b9a\u6587\u5316\u9ed8\u8ba4\u503c\uff0c\u65e0\u6cd5\u5145\u5206\u4ee3\u8868\u6587\u5316\u591a\u6837\u6027\u3002"}}
{"id": "2511.04249", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04249", "abs": "https://arxiv.org/abs/2511.04249", "authors": ["Marco Iannotta", "Yuxuan Yang", "Johannes A. Stork", "Erik Schaffernicht", "Todor Stoyanov"], "title": "Can Context Bridge the Reality Gap? Sim-to-Real Transfer of Context-Aware Policies", "comment": null, "summary": "Sim-to-real transfer remains a major challenge in reinforcement learning (RL)\nfor robotics, as policies trained in simulation often fail to generalize to the\nreal world due to discrepancies in environment dynamics. Domain Randomization\n(DR) mitigates this issue by exposing the policy to a wide range of randomized\ndynamics during training, yet leading to a reduction in performance. While\nstandard approaches typically train policies agnostic to these variations, we\ninvestigate whether sim-to-real transfer can be improved by conditioning the\npolicy on an estimate of the dynamics parameters -- referred to as context. To\nthis end, we integrate a context estimation module into a DR-based RL framework\nand systematically compare SOTA supervision strategies. We evaluate the\nresulting context-aware policies in both a canonical control benchmark and a\nreal-world pushing task using a Franka Emika Panda robot. Results show that\ncontext-aware policies outperform the context-agnostic baseline across all\nsettings, although the best supervision strategy depends on the task.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5728\u57fa\u4e8e\u57df\u968f\u673a\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e2d\u96c6\u6210\u4e0a\u4e0b\u6587\u4f30\u8ba1\u6a21\u5757\uff0c\u901a\u8fc7\u8ba9\u7b56\u7565\u611f\u77e5\u73af\u5883\u52a8\u6001\u53c2\u6570\u6765\u6539\u8fdb\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u8fc1\u79fb\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u5728\u673a\u5668\u4eba\u9886\u57df\u4e2d\u7684\u6a21\u62df\u5230\u73b0\u5b9e\u8fc1\u79fb\u95ee\u9898\uff0c\u4f20\u7edf\u57df\u968f\u673a\u5316\u65b9\u6cd5\u867d\u7136\u80fd\u63d0\u9ad8\u6cdb\u5316\u6027\u4f46\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u56e0\u6b64\u7814\u7a76\u662f\u5426\u901a\u8fc7\u8ba9\u7b56\u7565\u611f\u77e5\u52a8\u6001\u53c2\u6570\u4e0a\u4e0b\u6587\u53ef\u4ee5\u6539\u8fdb\u8fc1\u79fb\u6548\u679c\u3002", "method": "\u5728\u57fa\u4e8e\u57df\u968f\u673a\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e2d\u96c6\u6210\u4e0a\u4e0b\u6587\u4f30\u8ba1\u6a21\u5757\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4e86\u6700\u5148\u8fdb\u7684\u76d1\u7763\u7b56\u7565\uff0c\u8ba9\u7b56\u7565\u80fd\u591f\u57fa\u4e8e\u4f30\u8ba1\u7684\u52a8\u6001\u53c2\u6570\u8fdb\u884c\u51b3\u7b56\u3002", "result": "\u5728\u6807\u51c6\u63a7\u5236\u57fa\u51c6\u548c\u771f\u5b9e\u4e16\u754cFranka Emika Panda\u673a\u5668\u4eba\u63a8\u52a8\u4efb\u52a1\u4e2d\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u4e0a\u4e0b\u6587\u611f\u77e5\u7b56\u7565\u5728\u6240\u6709\u8bbe\u7f6e\u4e2d\u90fd\u4f18\u4e8e\u4e0a\u4e0b\u6587\u65e0\u5173\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4f46\u6700\u4f73\u76d1\u7763\u7b56\u7565\u53d6\u51b3\u4e8e\u5177\u4f53\u4efb\u52a1\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u611f\u77e5\u7b56\u7565\u80fd\u591f\u6709\u6548\u6539\u8fdb\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u8fc1\u79fb\u6027\u80fd\uff0c\u4f46\u9700\u8981\u6839\u636e\u5177\u4f53\u4efb\u52a1\u9009\u62e9\u9002\u5f53\u7684\u76d1\u7763\u7b56\u7565\u3002"}}
{"id": "2511.03744", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03744", "abs": "https://arxiv.org/abs/2511.03744", "authors": ["Navid Mojahed", "Mahdis Rabbani", "Shima Nazari"], "title": "Predictive Compensation in Finite-Horizon LQ Games under Gauss-Markov Deviations", "comment": "10 pages, 4 Figures, Preprint submitted to Control Engineering\n  Practice (Elsevier)", "summary": "This paper presents a predictive compensation framework for finite-horizon\ndiscrete-time linear quadratic dynamic games in the presence of Gauss-Markov\ndeviations from feedback Nash strategies. One player experiences correlated\nstochastic deviations, modeled via a first-order autoregressive process, while\nthe other compensates using a predictive strategy that anticipates the effect\nof future correlation. Closed-form recursions for mean and covariance\npropagation are derived, and the resulting performance improvement is analyzed\nthrough the sensitivity of expected cost.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9884\u6d4b\u8865\u507f\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u5b58\u5728\u9ad8\u65af-\u9a6c\u5c14\u53ef\u592b\u504f\u5dee\u7684\u6709\u9650\u65f6\u57df\u79bb\u6563\u65f6\u95f4\u7ebf\u6027\u4e8c\u6b21\u52a8\u6001\u535a\u5f08\uff0c\u5176\u4e2d\u4e00\u4e2a\u73a9\u5bb6\u7ecf\u5386\u76f8\u5173\u968f\u673a\u504f\u5dee\uff0c\u53e6\u4e00\u4e2a\u73a9\u5bb6\u4f7f\u7528\u9884\u6d4b\u7b56\u7565\u8fdb\u884c\u8865\u507f\u3002", "motivation": "\u5728\u52a8\u6001\u535a\u5f08\u4e2d\uff0c\u73a9\u5bb6\u53ef\u80fd\u504f\u79bb\u53cd\u9988\u7eb3\u4ec0\u7b56\u7565\uff0c\u8fd9\u4e9b\u504f\u5dee\u53ef\u80fd\u5177\u6709\u76f8\u5173\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u5145\u5206\u8003\u8651\u672a\u6765\u76f8\u5173\u6027\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u80fd\u591f\u9884\u6d4b\u5e76\u8865\u507f\u8fd9\u79cd\u76f8\u5173\u504f\u5dee\u7684\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u4e00\u9636\u81ea\u56de\u5f52\u8fc7\u7a0b\u5bf9\u76f8\u5173\u968f\u673a\u504f\u5dee\u5efa\u6a21\uff0c\u5f00\u53d1\u9884\u6d4b\u8865\u507f\u7b56\u7565\u6765\u9884\u671f\u672a\u6765\u76f8\u5173\u6027\u7684\u5f71\u54cd\uff0c\u63a8\u5bfc\u5747\u503c\u548c\u534f\u65b9\u5dee\u4f20\u64ad\u7684\u95ed\u5f0f\u9012\u63a8\u516c\u5f0f\u3002", "result": "\u83b7\u5f97\u4e86\u5747\u503c\u548c\u534f\u65b9\u5dee\u4f20\u64ad\u7684\u95ed\u5f0f\u9012\u63a8\u516c\u5f0f\uff0c\u901a\u8fc7\u671f\u671b\u6210\u672c\u654f\u611f\u6027\u5206\u6790\u4e86\u6027\u80fd\u6539\u8fdb\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u9884\u6d4b\u8865\u507f\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u52a8\u6001\u535a\u5f08\u4e2d\u7684\u76f8\u5173\u968f\u673a\u504f\u5dee\uff0c\u901a\u8fc7\u9884\u6d4b\u672a\u6765\u76f8\u5173\u6027\u5b9e\u73b0\u4e86\u6027\u80fd\u6539\u8fdb\u3002"}}
{"id": "2511.03985", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03985", "abs": "https://arxiv.org/abs/2511.03985", "authors": ["Zhuowen Yuan", "Tao Liu", "Yang Yang", "Yang Wang", "Feng Qi", "Kaushik Rangadurai", "Bo Li", "Shuang Yang"], "title": "ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning Engineering", "comment": null, "summary": "Recent LLM-based agents have demonstrated strong capabilities in automated ML\nengineering. However, they heavily rely on repeated full training runs to\nevaluate candidate solutions, resulting in significant computational overhead,\nlimited scalability to large search spaces, and slow iteration cycles. To\naddress these challenges, we introduce ArchPilot, a multi-agent system that\nintegrates architecture generation, proxy-based evaluation, and adaptive search\ninto a unified framework. ArchPilot consists of three specialized agents: an\norchestration agent that coordinates the search process using a Monte Carlo\nTree Search (MCTS)-inspired novel algorithm with a restart mechanism and\nmanages memory of previous candidates; a generation agent that iteratively\ngenerates, improves, and debugs candidate architectures; and an evaluation\nagent that executes proxy training runs, generates and optimizes proxy\nfunctions, and aggregates the proxy scores into a fidelity-aware performance\nmetric. This multi-agent collaboration allows ArchPilot to prioritize\nhigh-potential candidates with minimal reliance on expensive full training\nruns, facilitating efficient ML engineering under limited budgets. Experiments\non MLE-Bench demonstrate that ArchPilot outperforms SOTA baselines such as AIDE\nand ML-Master, validating the effectiveness of our multi-agent system.", "AI": {"tldr": "ArchPilot\u662f\u4e00\u4e2a\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u96c6\u6210\u67b6\u6784\u751f\u6210\u3001\u57fa\u4e8e\u4ee3\u7406\u7684\u8bc4\u4f30\u548c\u81ea\u9002\u5e94\u641c\u7d22\u6765\u89e3\u51b3LLM\u4ee3\u7406\u5728ML\u5de5\u7a0b\u4e2d\u4f9d\u8d56\u91cd\u590d\u5b8c\u6574\u8bad\u7ec3\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u5728\u81ea\u52a8\u5316ML\u5de5\u7a0b\u4e2d\u4e25\u91cd\u4f9d\u8d56\u91cd\u590d\u7684\u5b8c\u6574\u8bad\u7ec3\u6765\u8bc4\u4f30\u5019\u9009\u65b9\u6848\uff0c\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u641c\u7d22\u7a7a\u95f4\u6269\u5c55\u6027\u5dee\u548c\u8fed\u4ee3\u5468\u671f\u6162\u3002", "method": "ArchPilot\u5305\u542b\u4e09\u4e2a\u4e13\u4e1a\u4ee3\u7406\uff1a\u534f\u8c03\u641c\u7d22\u8fc7\u7a0b\u7684\u7f16\u6392\u4ee3\u7406\u3001\u8fed\u4ee3\u751f\u6210\u6539\u8fdb\u67b6\u6784\u7684\u751f\u6210\u4ee3\u7406\u3001\u6267\u884c\u4ee3\u7406\u8bad\u7ec3\u548c\u4f18\u5316\u4ee3\u7406\u51fd\u6570\u7684\u8bc4\u4f30\u4ee3\u7406\uff0c\u91c7\u7528MCTS\u542f\u53d1\u7b97\u6cd5\u548c\u91cd\u542f\u673a\u5236\u3002", "result": "\u5728MLE-Bench\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cArchPilot\u8d85\u8d8a\u4e86AIDE\u548cML-Master\u7b49SOTA\u57fa\u7ebf\uff0c\u9a8c\u8bc1\u4e86\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002", "conclusion": "ArchPilot\u901a\u8fc7\u591a\u4ee3\u7406\u534f\u4f5c\uff0c\u5728\u6709\u9650\u9884\u7b97\u4e0b\u4f18\u5148\u8003\u8651\u9ad8\u6f5c\u529b\u5019\u9009\u65b9\u6848\uff0c\u6700\u5c0f\u5316\u5bf9\u6602\u8d35\u5b8c\u6574\u8bad\u7ec3\u7684\u4f9d\u8d56\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684ML\u5de5\u7a0b\u3002"}}
{"id": "2511.04251", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04251", "abs": "https://arxiv.org/abs/2511.04251", "authors": ["Jinfeng Liang", "Haocheng Guo", "Ximin Lyu"], "title": "Design and Control of a Coaxial Dual-rotor Reconfigurable Tailsitter UAV Based on Swashplateless Mechanism", "comment": "8 pages 12 figures", "summary": "The tailsitter vertical takeoff and landing (VTOL) UAV is widely used due to\nits lower dead weight, which eliminates the actuators and mechanisms for\ntilting. However, the tailsitter UAV is susceptible to wind disturbances in\nmulti-rotor mode, as it exposes a large frontal fuselage area. To address this\nissue, our tailsitter UAV features a reconfigurable wing design, allowing wings\nto retract in multi-rotor mode and extend in fixed- wing mode. Considering\npower efficiency, we design a coaxial heterogeneous dual-rotor configuration,\nwhich significantly re- duces the total power consumption. To reduce structural\nweight and simplify structural complexity, we employ a swashplateless mechanism\nwith an improved design to control pitch and roll in multi-rotor mode. We\noptimize the structure of the swashplateless mechanism by adding flapping\nhinges, which reduces vibration during cyclic acceleration and deceleration.\nFinally, we perform comprehensive transition flight tests to validate stable\nflight performance across the entire flight envelope of the tailsitter UAV.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u91cd\u6784\u673a\u7ffc\u7684\u5c3e\u5750\u5f0f\u5782\u76f4\u8d77\u964d\u65e0\u4eba\u673a\uff0c\u91c7\u7528\u540c\u8f74\u5f02\u6784\u53cc\u65cb\u7ffc\u914d\u7f6e\u548c\u65e0\u659c\u76d8\u673a\u6784\uff0c\u901a\u8fc7\u4f18\u5316\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u5728\u60ac\u505c\u548c\u56fa\u5b9a\u7ffc\u6a21\u5f0f\u4e0b\u7684\u9ad8\u6548\u7a33\u5b9a\u98de\u884c\u3002", "motivation": "\u4f20\u7edf\u5c3e\u5750\u5f0f\u65e0\u4eba\u673a\u5728\u591a\u65cb\u7ffc\u6a21\u5f0f\u4e0b\u7531\u4e8e\u66b4\u9732\u8f83\u5927\u673a\u8eab\u9762\u79ef\u800c\u5bb9\u6613\u53d7\u5230\u98ce\u6270\uff0c\u9700\u8981\u89e3\u51b3\u5176\u6297\u98ce\u6027\u548c\u529f\u7387\u6548\u7387\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u53ef\u4f38\u7f29\u673a\u7ffc\u7ed3\u6784\uff0c\u91c7\u7528\u540c\u8f74\u5f02\u6784\u53cc\u65cb\u7ffc\u914d\u7f6e\u964d\u4f4e\u529f\u8017\uff0c\u4f7f\u7528\u6539\u8fdb\u7684\u65e0\u659c\u76d8\u673a\u6784\u63a7\u5236\u4fef\u4ef0\u548c\u6eda\u8f6c\uff0c\u5e76\u6dfb\u52a0\u6325\u821e\u94f0\u94fe\u4f18\u5316\u7ed3\u6784\u51cf\u5c11\u632f\u52a8\u3002", "result": "\u901a\u8fc7\u5168\u9762\u7684\u8fc7\u6e21\u98de\u884c\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u65e0\u4eba\u673a\u5728\u6574\u4e2a\u98de\u884c\u5305\u7ebf\u5185\u7684\u7a33\u5b9a\u98de\u884c\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u53ef\u91cd\u6784\u673a\u7ffc\u5c3e\u5750\u5f0f\u65e0\u4eba\u673a\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u98ce\u6270\u95ee\u9898\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u529f\u7387\u6548\u7387\u548c\u7ed3\u6784\u7b80\u5316\uff0c\u5177\u6709\u826f\u597d\u7684\u98de\u884c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2511.03745", "categories": ["eess.SY", "cs.CE", "cs.SY", "65L06, 37B10, 68W30, 70E60, 770E15, 70-10", "G.1.3; G.1.7; G.1.10; I.6.3; J.2; J.6"], "pdf": "https://arxiv.org/pdf/2511.03745", "abs": "https://arxiv.org/abs/2511.03745", "authors": ["Osama A. Marzouk"], "title": "InvSim algorithm for pre-computing airplane flight controls in limited-range autonomous missions, and demonstration via double-roll maneuver of Mirage III fighters", "comment": "47 pages, 20 figures, 10 tables, published journal article,\n  peer-reviewed, open access", "summary": "In this work, we start with a generic mathematical framework for the\nequations of motion (EOM) in flight mechanics with six degrees of freedom\n(6-DOF) for a general (not necessarily symmetric) fixed-wing aircraft. This\nmathematical framework incorporates (1) body axes (fixed in the airplane at its\ncenter of gravity), (2) inertial axes (fixed in the earth/ground at the\ntake-off point), wind axes (aligned with the flight path/course), (3) spherical\nflight path angles (azimuth angle measured clockwise from the geographic north,\nand elevation angle measured above the horizon plane), and (4) spherical flight\nangles (angle of attack and sideslip angle). We then manipulate these equations\nof motion to derive a customized version suitable for inverse simulation flight\nmechanics, where a target flight trajectory is specified while a set of\ncorresponding necessary flight controls to achieve that maneuver are predicted.\nWe then present a numerical procedure for integrating the developed inverse\nsimulation (InvSim) system in time; utilizing (1) symbolic mathematics, (2)\nexplicit fourth-order Runge-Kutta (RK4) numerical integration technique, and\n(3) expressions based on the finite difference method (FDM); such that the four\nnecessary control variables (engine thrust force, ailerons' deflection angle,\nelevators' deflection angle, and rudder's deflection angle) are computed as\ndiscrete values over the entire maneuver time, and these calculated control\nvalues enable the airplane to achieve the desired flight trajectory, which is\nspecified by three inertial Cartesian coordinates of the airplane, in addition\nto the Euler's roll angle. We finally demonstrate the proposed numerical\nprocedure of flight mechanics inverse simulation (InvSim).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e6\u81ea\u7531\u5ea6\u56fa\u5b9a\u7ffc\u98de\u673a\u9006\u4eff\u771f\u7684\u6570\u5b66\u6846\u67b6\u548c\u6570\u503c\u65b9\u6cd5\uff0c\u901a\u8fc7\u6307\u5b9a\u76ee\u6807\u98de\u884c\u8f68\u8ff9\u6765\u9884\u6d4b\u6240\u9700\u7684\u98de\u884c\u63a7\u5236\u8f93\u5165\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u901a\u7528\u7684\u6570\u5b66\u6846\u67b6\u6765\u5904\u7406\u975e\u5bf9\u79f0\u56fa\u5b9a\u7ffc\u98de\u673a\u76846\u81ea\u7531\u5ea6\u8fd0\u52a8\u65b9\u7a0b\uff0c\u5e76\u4e13\u95e8\u9488\u5bf9\u9006\u4eff\u771f\u95ee\u9898\u5b9a\u5236\uff0c\u5176\u4e2d\u76ee\u6807\u98de\u884c\u8f68\u8ff9\u5df2\u77e5\u800c\u9700\u8981\u9884\u6d4b\u63a7\u5236\u8f93\u5165\u3002", "method": "\u5efa\u7acb\u5305\u542b\u4f53\u8f74\u3001\u60ef\u6027\u8f74\u3001\u98ce\u8f74\u548c\u7403\u5f62\u98de\u884c\u89d2\u5ea6\u7684\u6570\u5b66\u6846\u67b6\uff0c\u7136\u540e\u63a8\u5bfc\u9006\u4eff\u771f\u65b9\u7a0b\uff0c\u4f7f\u7528\u7b26\u53f7\u6570\u5b66\u3001\u56db\u9636\u9f99\u683c-\u5e93\u5854\u6cd5\u548c\u6709\u9650\u5dee\u5206\u6cd5\u8fdb\u884c\u6570\u503c\u79ef\u5206\uff0c\u8ba1\u7b97\u53d1\u52a8\u673a\u63a8\u529b\u3001\u526f\u7ffc\u3001\u5347\u964d\u8235\u548c\u65b9\u5411\u8235\u7684\u504f\u8f6c\u89d2\u5ea6\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6570\u503c\u7a0b\u5e8f\uff0c\u80fd\u591f\u8ba1\u7b97\u5728\u6574\u4e2a\u673a\u52a8\u65f6\u95f4\u5185\u4f5c\u4e3a\u79bb\u6563\u503c\u7684\u56db\u4e2a\u5fc5\u8981\u63a7\u5236\u53d8\u91cf\uff0c\u4f7f\u98de\u673a\u80fd\u591f\u5b9e\u73b0\u7531\u4e09\u4e2a\u60ef\u6027\u7b1b\u5361\u5c14\u5750\u6807\u548c\u6b27\u62c9\u6eda\u8f6c\u89d2\u6307\u5b9a\u7684\u671f\u671b\u98de\u884c\u8f68\u8ff9\u3002", "conclusion": "\u63d0\u51fa\u7684\u98de\u884c\u529b\u5b66\u9006\u4eff\u771f\u6570\u503c\u7a0b\u5e8f\u80fd\u591f\u6709\u6548\u9884\u6d4b\u5b9e\u73b0\u7279\u5b9a\u98de\u884c\u8f68\u8ff9\u6240\u9700\u7684\u63a7\u5236\u8f93\u5165\uff0c\u4e3a\u98de\u884c\u63a7\u5236\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2511.04032", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04032", "abs": "https://arxiv.org/abs/2511.04032", "authors": ["Divya Pathak", "Harshit Kumar", "Anuska Roy", "Felix George", "Mudit Verma", "Pratibha Moogi"], "title": "Detecting Silent Failures in Multi-Agentic AI Trajectories", "comment": null, "summary": "Multi-Agentic AI systems, powered by large language models (LLMs), are\ninherently non-deterministic and prone to silent failures such as drift,\ncycles, and missing details in outputs, which are difficult to detect. We\nintroduce the task of anomaly detection in agentic trajectories to identify\nthese failures and present a dataset curation pipeline that captures user\nbehavior, agent non-determinism, and LLM variation. Using this pipeline, we\ncurate and label two benchmark datasets comprising \\textbf{4,275 and 894}\ntrajectories from Multi-Agentic AI systems. Benchmarking anomaly detection\nmethods on these datasets, we show that supervised (XGBoost) and\nsemi-supervised (SVDD) approaches perform comparably, achieving accuracies up\nto 98% and 96%, respectively. This work provides the first systematic study of\nanomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks,\nand insights to guide future research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u4e2d\u5f02\u5e38\u68c0\u6d4b\u7684\u4efb\u52a1\uff0c\u521b\u5efa\u4e86\u4e24\u4e2a\u5305\u542b4,275\u548c894\u6761\u8f68\u8ff9\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5c55\u793a\u4e86\u76d1\u7763\u548c\u534a\u76d1\u7763\u65b9\u6cd5\u80fd\u8fbe\u523098%\u548c96%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u5177\u6709\u975e\u786e\u5b9a\u6027\uff0c\u5bb9\u6613\u53d1\u751f\u6f02\u79fb\u3001\u5faa\u73af\u548c\u8f93\u51fa\u7ec6\u8282\u7f3a\u5931\u7b49\u96be\u4ee5\u68c0\u6d4b\u7684\u9759\u9ed8\u6545\u969c\u3002", "method": "\u5f00\u53d1\u4e86\u6570\u636e\u6536\u96c6\u6d41\u7a0b\u6765\u6355\u6349\u7528\u6237\u884c\u4e3a\u3001\u667a\u80fd\u4f53\u975e\u786e\u5b9a\u6027\u548cLLM\u53d8\u5316\uff0c\u5e76\u521b\u5efa\u4e86\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76d1\u7763\u65b9\u6cd5(XGBoost)\u548c\u534a\u76d1\u7763\u65b9\u6cd5(SVDD)\u5206\u522b\u8fbe\u523098%\u548c96%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u7cfb\u7edf\u7814\u7a76\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u4e2d\u5f02\u5e38\u68c0\u6d4b\u7684\u5de5\u4f5c\uff0c\u63d0\u4f9b\u4e86\u6570\u636e\u96c6\u3001\u57fa\u51c6\u548c\u89c1\u89e3\u6765\u6307\u5bfc\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2511.04320", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04320", "abs": "https://arxiv.org/abs/2511.04320", "authors": ["Kuankuan Sima", "Longbin Tang", "Haozhe Ma", "Lin Zhao"], "title": "MacroNav: Multi-Task Context Representation Learning Enables Efficient Navigation in Unknown Environments", "comment": null, "summary": "Autonomous navigation in unknown environments requires compact yet expressive\nspatial understanding under partial observability to support high-level\ndecision making. Existing approaches struggle to balance rich contextual\nrepresentation with navigation efficiency. We present MacroNav, a\nlearning-based navigation framework featuring two key components: (1) a\nlightweight context encoder trained via multi-task self-supervised learning to\ncapture multi-scale, navigation-centric spatial representations; and (2) a\nreinforcement learning policy that seamlessly integrates these representations\nwith graph-based reasoning for efficient action selection. Extensive\nexperiments demonstrate the context encoder's efficient and robust\nenvironmental understanding. Real-world deployments further validate MacroNav's\neffectiveness, yielding significant gains over state-of-the-art navigation\nmethods in both Success Rate (SR) and Success weighted by Path Length (SPL),\nwhile maintaining low computational cost. Code will be released upon\nacceptance.", "AI": {"tldr": "MacroNav\u662f\u4e00\u4e2a\u57fa\u4e8e\u5b66\u4e60\u7684\u5bfc\u822a\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u4e0a\u4e0b\u6587\u7f16\u7801\u5668\u548c\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u5728\u672a\u77e5\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u5bfc\u822a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6210\u529f\u7387\u548c\u8def\u5f84\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u8868\u793a\u548c\u5bfc\u822a\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u81ea\u4e3b\u5bfc\u822a\u9700\u8981\u5728\u4e0d\u5b8c\u5168\u89c2\u6d4b\u4e0b\u5b9e\u73b0\u7d27\u51d1\u800c\u8868\u8fbe\u529b\u5f3a\u7684\u7a7a\u95f4\u7406\u89e3\u3002", "method": "\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a(1) \u901a\u8fc7\u591a\u4efb\u52a1\u81ea\u76d1\u7763\u5b66\u4e60\u8bad\u7ec3\u7684\u8f7b\u91cf\u7ea7\u4e0a\u4e0b\u6587\u7f16\u7801\u5668\uff0c\u6355\u6349\u591a\u5c3a\u5ea6\u5bfc\u822a\u4e2d\u5fc3\u7a7a\u95f4\u8868\u793a\uff1b(2) \u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u5c06\u8fd9\u4e9b\u8868\u793a\u4e0e\u57fa\u4e8e\u56fe\u7684\u63a8\u7406\u65e0\u7f1d\u96c6\u6210\u4ee5\u8fdb\u884c\u9ad8\u6548\u52a8\u4f5c\u9009\u62e9\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e0a\u4e0b\u6587\u7f16\u7801\u5668\u5177\u6709\u9ad8\u6548\u548c\u9c81\u68d2\u7684\u73af\u5883\u7406\u89e3\u80fd\u529b\u3002\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u9a8c\u8bc1\u4e86MacroNav\u7684\u6709\u6548\u6027\uff0c\u5728\u6210\u529f\u7387\u548c\u8def\u5f84\u957f\u5ea6\u52a0\u6743\u6210\u529f\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5bfc\u822a\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "MacroNav\u6846\u67b6\u5728\u672a\u77e5\u73af\u5883\u5bfc\u822a\u4e2d\u5b9e\u73b0\u4e86\u4e0a\u4e0b\u6587\u8868\u793a\u4e0e\u5bfc\u822a\u6548\u7387\u7684\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u81ea\u4e3b\u5bfc\u822a\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.03746", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03746", "abs": "https://arxiv.org/abs/2511.03746", "authors": ["Guang An Ooi", "Otavio Bertozzi", "Mohd Asim Aftab", "Charalambos Konstantinou", "Shehab Ahmed"], "title": "A Dynamic Recurrent Adjacency Memory Network for Mixed-Generation Power System Stability Forecasting", "comment": "Submitted to IEEE Transactions on Power Systems", "summary": "Modern power systems with high penetration of inverter-based resources\nexhibit complex dynamic behaviors that challenge the scalability and\ngeneralizability of traditional stability assessment methods. This paper\npresents a dynamic recurrent adjacency memory network (DRAMN) that combines\nphysics-informed analysis with deep learning for real-time power system\nstability forecasting. The framework employs sliding-window dynamic mode\ndecomposition to construct time-varying, multi-layer adjacency matrices from\nphasor measurement unit and sensor data to capture system dynamics such as\nmodal participation factors, coupling strengths, phase relationships, and\nspectral energy distributions. As opposed to processing spatial and temporal\ndependencies separately, DRAMN integrates graph convolution operations directly\nwithin recurrent gating mechanisms, enabling simultaneous modeling of evolving\ndynamics and temporal dependencies. Extensive validations on modified IEEE\n9-bus, 39-bus, and a multi-terminal HVDC network demonstrate high performance,\nachieving 99.85\\%, 99.90\\%, and 99.69\\% average accuracies, respectively,\nsurpassing all tested benchmarks, including classical machine learning\nalgorithms and recent graph-based models. The framework identifies optimal\ncombinations of measurements that reduce feature dimensionality by 82\\% without\nperformance degradation. Correlation analysis between dominant measurements for\nsmall-signal and transient stability events validates generalizability across\ndifferent stability phenomena. DRAMN achieves state-of-the-art accuracy while\nproviding enhanced interpretability for power system operators, making it\nsuitable for real-time deployment in modern control centers.", "AI": {"tldr": "\u63d0\u51fa\u52a8\u6001\u5faa\u73af\u90bb\u63a5\u8bb0\u5fc6\u7f51\u7edc(DRAMN)\uff0c\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u5206\u6790\u548c\u6df1\u5ea6\u5b66\u4e60\uff0c\u7528\u4e8e\u5b9e\u65f6\u7535\u529b\u7cfb\u7edf\u7a33\u5b9a\u6027\u9884\u6d4b\uff0c\u5728\u591a\u4e2a\u6d4b\u8bd5\u7cfb\u7edf\u4e2d\u8fbe\u523099%\u4ee5\u4e0a\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u4ee3\u7535\u529b\u7cfb\u7edf\u4e2d\u9006\u53d8\u5668\u8d44\u6e90\u7684\u9ad8\u6e17\u900f\u7387\u5e26\u6765\u4e86\u590d\u6742\u7684\u52a8\u6001\u884c\u4e3a\uff0c\u4f20\u7edf\u7a33\u5b9a\u6027\u8bc4\u4f30\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u6027\u65b9\u9762\u9762\u4e34\u6311\u6218\u3002", "method": "\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u52a8\u6001\u6a21\u5f0f\u5206\u89e3\u6784\u5efa\u65f6\u53d8\u591a\u5c42\u90bb\u63a5\u77e9\u9635\uff0c\u5c06\u56fe\u5377\u79ef\u64cd\u4f5c\u76f4\u63a5\u96c6\u6210\u5230\u5faa\u73af\u95e8\u63a7\u673a\u5236\u4e2d\uff0c\u540c\u65f6\u5efa\u6a21\u6f14\u5316\u52a8\u6001\u548c\u65f6\u95f4\u4f9d\u8d56\u6027\u3002", "result": "\u5728\u6539\u8fdb\u7684IEEE 9\u603b\u7ebf\u300139\u603b\u7ebf\u548c\u591a\u7aefHVDC\u7f51\u7edc\u4e0a\u9a8c\u8bc1\uff0c\u5206\u522b\u8fbe\u523099.85%\u300199.90%\u548c99.69%\u7684\u5e73\u5747\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u6240\u6709\u57fa\u51c6\u6a21\u578b\u3002\u7279\u5f81\u7ef4\u5ea6\u51cf\u5c1182%\u4e14\u6027\u80fd\u65e0\u635f\u5931\u3002", "conclusion": "DRAMN\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4e3a\u7535\u529b\u7cfb\u7edf\u64cd\u4f5c\u5458\u63d0\u4f9b\u4e86\u589e\u5f3a\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u9002\u5408\u5728\u73b0\u4ee3\u63a7\u5236\u4e2d\u5fc3\u5b9e\u65f6\u90e8\u7f72\u3002"}}
{"id": "2511.04053", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04053", "abs": "https://arxiv.org/abs/2511.04053", "authors": ["Hirohane Takagi", "Gouki Minegishi", "Shota Kizawa", "Issey Sukeda", "Hitomi Yanaka"], "title": "Interpreting Multi-Attribute Confounding through Numerical Attributes in Large Language Models", "comment": "Accepted to IJCNLP-AACL 2025 (Main). Code available at\n  https://github.com/htkg/num_attrs", "summary": "Although behavioral studies have documented numerical reasoning errors in\nlarge language models (LLMs), the underlying representational mechanisms remain\nunclear. We hypothesize that numerical attributes occupy shared latent\nsubspaces and investigate two questions:(1) How do LLMs internally integrate\nmultiple numerical attributes of a single entity? (2)How does irrelevant\nnumerical context perturb these representations and their downstream outputs?\nTo address these questions, we combine linear probing with partial correlation\nanalysis and prompt-based vulnerability tests across models of varying sizes.\nOur results show that LLMs encode real-world numerical correlations but tend to\nsystematically amplify them. Moreover, irrelevant context induces consistent\nshifts in magnitude representations, with downstream effects that vary by model\nsize. These findings reveal a vulnerability in LLM decision-making and lay the\ngroundwork for fairer, representation-aware control under multi-attribute\nentanglement.", "AI": {"tldr": "LLMs\u5728\u6570\u503c\u63a8\u7406\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u9519\u8bef\uff0c\u7814\u7a76\u53d1\u73b0\u5b83\u4eec\u4f1a\u653e\u5927\u771f\u5b9e\u4e16\u754c\u6570\u503c\u76f8\u5173\u6027\uff0c\u4e14\u65e0\u5173\u4e0a\u4e0b\u6587\u4f1a\u5e72\u6270\u6570\u503c\u8868\u793a\uff0c\u8fd9\u79cd\u5f71\u54cd\u968f\u6a21\u578b\u89c4\u6a21\u53d8\u5316\u3002", "motivation": "\u5c3d\u7ba1\u884c\u4e3a\u7814\u7a76\u5df2\u8bb0\u5f55LLMs\u7684\u6570\u503c\u63a8\u7406\u9519\u8bef\uff0c\u4f46\u5176\u5e95\u5c42\u8868\u5f81\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLMs\u5982\u4f55\u6574\u5408\u5b9e\u4f53\u591a\u4e2a\u6570\u503c\u5c5e\u6027\uff0c\u4ee5\u53ca\u65e0\u5173\u6570\u503c\u4e0a\u4e0b\u6587\u5982\u4f55\u5e72\u6270\u8fd9\u4e9b\u8868\u793a\u3002", "method": "\u7ed3\u5408\u7ebf\u6027\u63a2\u6d4b\u4e0e\u504f\u76f8\u5173\u5206\u6790\uff0c\u4ee5\u53ca\u57fa\u4e8e\u63d0\u793a\u7684\u8106\u5f31\u6027\u6d4b\u8bd5\uff0c\u5728\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "LLMs\u7f16\u7801\u4e86\u771f\u5b9e\u4e16\u754c\u7684\u6570\u503c\u76f8\u5173\u6027\u4f46\u4f1a\u7cfb\u7edf\u6027\u653e\u5927\u5b83\u4eec\uff1b\u65e0\u5173\u4e0a\u4e0b\u6587\u4f1a\u5bfc\u81f4\u6570\u503c\u8868\u793a\u7684\u4e00\u81f4\u504f\u79fb\uff0c\u4e0b\u6e38\u5f71\u54cd\u968f\u6a21\u578b\u89c4\u6a21\u800c\u5f02\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u63ed\u793a\u4e86LLM\u51b3\u7b56\u4e2d\u7684\u8106\u5f31\u6027\uff0c\u4e3a\u5728\u591a\u5c5e\u6027\u7ea0\u7f20\u4e0b\u5b9e\u73b0\u66f4\u516c\u5e73\u3001\u8868\u5f81\u611f\u77e5\u7684\u63a7\u5236\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.04357", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04357", "abs": "https://arxiv.org/abs/2511.04357", "authors": ["Ma\u00eblic Neau", "Zoe Falomir", "Paulo E. Santos", "Anne-Gwenn Bosser", "C\u00e9dric Buche"], "title": "GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies", "comment": null, "summary": "Deploying autonomous robots that can learn new skills from demonstrations is\nan important challenge of modern robotics. Existing solutions often apply\nend-to-end imitation learning with Vision-Language Action (VLA) models or\nsymbolic approaches with Action Model Learning (AML). On the one hand, current\nVLA models are limited by the lack of high-level symbolic planning, which\nhinders their abilities in long-horizon tasks. On the other hand, symbolic\napproaches in AML lack generalization and scalability perspectives. In this\npaper we present a new neuro-symbolic approach, GraSP-VLA, a framework that\nuses a Continuous Scene Graph representation to generate a symbolic\nrepresentation of human demonstrations. This representation is used to generate\nnew planning domains during inference and serves as an orchestrator for\nlow-level VLA policies, scaling up the number of actions that can be reproduced\nin a row. Our results show that GraSP-VLA is effective for modeling symbolic\nrepresentations on the task of automatic planning domain generation from\nobservations. In addition, results on real-world experiments show the potential\nof our Continuous Scene Graph representation to orchestrate low-level VLA\npolicies in long-horizon tasks.", "AI": {"tldr": "GraSP-VLA\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u4f7f\u7528\u8fde\u7eed\u573a\u666f\u56fe\u8868\u793a\u6765\u751f\u6210\u4eba\u7c7b\u6f14\u793a\u7684\u7b26\u53f7\u8868\u793a\uff0c\u7528\u4e8e\u63a8\u7406\u65f6\u751f\u6210\u65b0\u7684\u89c4\u5212\u57df\uff0c\u5e76\u4f5c\u4e3a\u4f4e\u7ea7VLA\u7b56\u7565\u7684\u534f\u8c03\u5668\uff0c\u63d0\u9ad8\u8fde\u7eed\u6267\u884c\u52a8\u4f5c\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u4e2d\uff0c\u7aef\u5230\u7aef\u6a21\u4eff\u5b66\u4e60\u7684VLA\u6a21\u578b\u7f3a\u4e4f\u9ad8\u7ea7\u7b26\u53f7\u89c4\u5212\u80fd\u529b\uff0c\u96be\u4ee5\u5904\u7406\u957f\u671f\u4efb\u52a1\uff1b\u800c\u7b26\u53f7\u65b9\u6cd5\u7684AML\u7f3a\u4e4f\u6cdb\u5316\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002\u9700\u8981\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u8fde\u7eed\u573a\u666f\u56fe\u8868\u793a\u751f\u6210\u4eba\u7c7b\u6f14\u793a\u7684\u7b26\u53f7\u8868\u793a\uff0c\u5728\u63a8\u7406\u65f6\u751f\u6210\u65b0\u7684\u89c4\u5212\u57df\uff0c\u5e76\u4f5c\u4e3a\u4f4e\u7ea7VLA\u7b56\u7565\u7684\u534f\u8c03\u5668\u3002", "result": "GraSP-VLA\u5728\u81ea\u52a8\u89c4\u5212\u57df\u751f\u6210\u4efb\u52a1\u4e2d\u6709\u6548\u5efa\u6a21\u7b26\u53f7\u8868\u793a\uff0c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u663e\u793a\u8fde\u7eed\u573a\u666f\u56fe\u8868\u793a\u5728\u534f\u8c03\u957f\u671f\u4efb\u52a1\u4e2d\u7684\u4f4e\u7ea7VLA\u7b56\u7565\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002", "conclusion": "GraSP-VLA\u6846\u67b6\u6210\u529f\u7ed3\u5408\u4e86\u795e\u7ecf\u548c\u7b26\u53f7\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u957f\u671f\u4efb\u52a1\u5e76\u63d0\u9ad8\u52a8\u4f5c\u5e8f\u5217\u7684\u6269\u5c55\u6027\u3002"}}
{"id": "2511.03754", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03754", "abs": "https://arxiv.org/abs/2511.03754", "authors": ["Haoran Zhao", "Neema Nassir", "Andres Fielbaum"], "title": "Analytical modelling of a stop-less modular bus service with an application to charging strategies comparison", "comment": null, "summary": "Buses are a vital component of metropolitan public transport, yet\nconventional bus services often struggle with inefficiencies including extended\ndwelling time, which increases in-vehicle travel time for non-alighting\npassengers. A stop-less autonomous modular (SLAM) bus service has emerged as a\nsolution, enabling dynamic capacity to reduce dwelling time. Meanwhile, the\nelectrification of buses is advancing as a strategy to mitigate greenhouse gas\nemissions and reduces operators' costs, but introduces new operational\nconstraints due to charging requirements. This study develops analytical\noptimization models for SLAM bus service that integrates vehicle-to-vehicle\n(V2V) charging technology. By comparing the optimal designs and their\nfeasibility across non-charging case and charging strategies, we identify a\nsequence of operational stages as ridership grows: from idle capacity under low\ndemand, to full small buses, full large buses, and a proposed frequency-capped\nregime where only bus capacity expands. Under the mobile charging strategy,\nthis progression further includes an energy-limited regime, in which frequency\ndeclines, and ultimately infeasibility under high demand. These findings enable\noperators to deliver more efficient services.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u96c6\u6210V2V\u5145\u7535\u6280\u672f\u7684\u65e0\u505c\u9760\u81ea\u4e3b\u6a21\u5757\u5316(SLAM)\u516c\u4ea4\u670d\u52a1\u7684\u5206\u6790\u4f18\u5316\u6a21\u578b\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u5145\u7535\u7b56\u7565\u4e0b\u7684\u6700\u4f18\u8bbe\u8ba1\u548c\u53ef\u884c\u6027\u3002", "motivation": "\u4f20\u7edf\u516c\u4ea4\u670d\u52a1\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\uff0c\u7279\u522b\u662f\u505c\u9760\u65f6\u95f4\u8fc7\u957f\u589e\u52a0\u4e86\u975e\u4e0b\u8f66\u4e58\u5ba2\u7684\u4e58\u8f66\u65f6\u95f4\u3002\u540c\u65f6\uff0c\u516c\u4ea4\u7535\u52a8\u5316\u867d\u7136\u80fd\u51cf\u5c11\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u548c\u8fd0\u8425\u6210\u672c\uff0c\u4f46\u5145\u7535\u9700\u6c42\u5e26\u6765\u4e86\u65b0\u7684\u8fd0\u8425\u7ea6\u675f\u3002", "method": "\u5f00\u53d1\u4e86\u96c6\u6210\u8f66\u8f86\u5230\u8f66\u8f86(V2V)\u5145\u7535\u6280\u672f\u7684SLAM\u516c\u4ea4\u670d\u52a1\u5206\u6790\u4f18\u5316\u6a21\u578b\uff0c\u6bd4\u8f83\u4e86\u65e0\u5145\u7535\u60c5\u51b5\u548c\u4e0d\u540c\u5145\u7535\u7b56\u7565\u4e0b\u7684\u6700\u4f18\u8bbe\u8ba1\u3002", "result": "\u968f\u7740\u5ba2\u6d41\u589e\u957f\uff0c\u8fd0\u8425\u9636\u6bb5\u4f9d\u6b21\u4e3a\uff1a\u4f4e\u9700\u6c42\u4e0b\u7684\u95f2\u7f6e\u5bb9\u91cf\u3001\u5168\u5c0f\u578b\u516c\u4ea4\u8f66\u3001\u5168\u5927\u578b\u516c\u4ea4\u8f66\uff0c\u4ee5\u53ca\u63d0\u51fa\u7684\u9891\u7387\u4e0a\u9650\u673a\u5236\uff08\u4ec5\u6269\u5927\u516c\u4ea4\u8f66\u5bb9\u91cf\uff09\u3002\u5728\u79fb\u52a8\u5145\u7535\u7b56\u7565\u4e0b\uff0c\u8fd8\u5305\u62ec\u80fd\u6e90\u53d7\u9650\u673a\u5236\uff08\u9891\u7387\u4e0b\u964d\uff09\u548c\u6700\u7ec8\u5728\u9ad8\u9700\u6c42\u4e0b\u7684\u4e0d\u53ef\u884c\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4f7f\u8fd0\u8425\u5546\u80fd\u591f\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u670d\u52a1\uff0c\u4e3aSLAM\u516c\u4ea4\u670d\u52a1\u7684\u8fd0\u8425\u89c4\u5212\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2511.04076", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04076", "abs": "https://arxiv.org/abs/2511.04076", "authors": ["Hao Li", "Haotian Chen", "Ruoyuan Gong", "Juanjuan Wang", "Hao Jiang"], "title": "Agentmandering: A Game-Theoretic Framework for Fair Redistricting via Large Language Model Agents", "comment": "Accepted by AAAI AISI 2026", "summary": "Redistricting plays a central role in shaping how votes are translated into\npolitical power. While existing computational methods primarily aim to generate\nlarge ensembles of legally valid districting plans, they often neglect the\nstrategic dynamics involved in the selection process. This oversight creates\nopportunities for partisan actors to cherry-pick maps that, while technically\ncompliant, are politically advantageous. Simply satisfying formal constraints\ndoes not ensure fairness when the selection process itself can be manipulated.\nWe propose \\textbf{Agentmandering}, a framework that reimagines redistricting\nas a turn-based negotiation between two agents representing opposing political\ninterests. Drawing inspiration from game-theoretic ideas, particularly the\n\\textit{Choose-and-Freeze} protocol, our method embeds strategic interaction\ninto the redistricting process via large language model (LLM) agents. Agents\nalternate between selecting and freezing districts from a small set of\ncandidate maps, gradually partitioning the state through constrained and\ninterpretable choices. Evaluation on post-2020 U.S. Census data across all\nstates shows that Agentmandering significantly reduces partisan bias and\nunfairness, while achieving 2 to 3 orders of magnitude lower variance than\nstandard baselines. These results demonstrate both fairness and stability,\nespecially in swing-state scenarios. Our code is available at\nhttps://github.com/Lihaogx/AgentMandering.", "AI": {"tldr": "\u63d0\u51fa\u4e86Agentmandering\u6846\u67b6\uff0c\u5c06\u9009\u533a\u91cd\u5212\u91cd\u65b0\u6784\u60f3\u4e3a\u4e24\u4e2a\u4ee3\u8868\u5bf9\u7acb\u653f\u6cbb\u5229\u76ca\u7684\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u56de\u5408\u5236\u8c08\u5224\uff0c\u901a\u8fc7LLM\u667a\u80fd\u4f53\u5c06\u6218\u7565\u4e92\u52a8\u5d4c\u5165\u5230\u9009\u533a\u91cd\u5212\u8fc7\u7a0b\u4e2d\uff0c\u663e\u8457\u51cf\u5c11\u515a\u6d3e\u504f\u89c1\u548c\u4e0d\u516c\u5e73\u6027\u3002", "motivation": "\u73b0\u6709\u8ba1\u7b97\u65b9\u6cd5\u4e3b\u8981\u751f\u6210\u5927\u91cf\u5408\u6cd5\u9009\u533a\u91cd\u5212\u65b9\u6848\uff0c\u4f46\u5ffd\u89c6\u4e86\u9009\u62e9\u8fc7\u7a0b\u4e2d\u7684\u6218\u7565\u52a8\u6001\uff0c\u8fd9\u4e3a\u515a\u6d3e\u884c\u4e3a\u8005\u6311\u9009\u6280\u672f\u4e0a\u5408\u89c4\u4f46\u653f\u6cbb\u4e0a\u6709\u5229\u7684\u5730\u56fe\u521b\u9020\u4e86\u673a\u4f1a\u3002\u4ec5\u4ec5\u6ee1\u8db3\u5f62\u5f0f\u7ea6\u675f\u65e0\u6cd5\u786e\u4fdd\u516c\u5e73\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u535a\u5f08\u8bba\u601d\u60f3\u7684\u56de\u5408\u5236\u8c08\u5224\u6846\u67b6\uff0c\u4e24\u4e2aLLM\u667a\u80fd\u4f53\u4ee3\u8868\u5bf9\u7acb\u653f\u6cbb\u5229\u76ca\uff0c\u8f6e\u6d41\u4ece\u5c11\u91cf\u5019\u9009\u5730\u56fe\u4e2d\u9009\u62e9\u548c\u51bb\u7ed3\u9009\u533a\uff0c\u901a\u8fc7\u53d7\u7ea6\u675f\u4e14\u53ef\u89e3\u91ca\u7684\u9009\u62e9\u9010\u6b65\u5212\u5206\u5dde\u3002", "result": "\u57282020\u5e74\u7f8e\u56fd\u4eba\u53e3\u666e\u67e5\u6570\u636e\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cAgentmandering\u663e\u8457\u51cf\u5c11\u4e86\u515a\u6d3e\u504f\u89c1\u548c\u4e0d\u516c\u5e73\u6027\uff0c\u65b9\u5dee\u6bd4\u6807\u51c6\u57fa\u7ebf\u4f4e2-3\u4e2a\u6570\u91cf\u7ea7\uff0c\u5728\u6447\u6446\u5dde\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u516c\u5e73\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "Agentmandering\u6846\u67b6\u901a\u8fc7\u5c06\u6218\u7565\u4e92\u52a8\u5d4c\u5165\u9009\u533a\u91cd\u5212\u8fc7\u7a0b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9009\u62e9\u8fc7\u7a0b\u4e2d\u7684\u64cd\u7eb5\u95ee\u9898\uff0c\u4e3a\u516c\u5e73\u7684\u9009\u533a\u91cd\u5212\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2511.04375", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04375", "abs": "https://arxiv.org/abs/2511.04375", "authors": ["Anna M\u00e9sz\u00e1ros", "Javier Alonso-Mora", "Jens Kober"], "title": "Studying the Effect of Explicit Interaction Representations on Learning Scene-level Distributions of Human Trajectories", "comment": null, "summary": "Effectively capturing the joint distribution of all agents in a scene is\nrelevant for predicting the true evolution of the scene and in turn providing\nmore accurate information to the decision processes of autonomous vehicles.\nWhile new models have been developed for this purpose in recent years, it\nremains unclear how to best represent the joint distributions particularly from\nthe perspective of the interactions between agents. Thus far there is no clear\nconsensus on how best to represent interactions between agents; whether they\nshould be learned implicitly from data by neural networks, or explicitly\nmodeled using the spatial and temporal relations that are more grounded in\nhuman decision-making. This paper aims to study various means of describing\ninteractions within the same network structure and their effect on the final\nlearned joint distributions. Our findings show that more often than not, simply\nallowing a network to establish interactive connections between agents based on\ndata has a detrimental effect on performance. Instead, having well defined\ninteractions (such as which agent of an agent pair passes first at an\nintersection) can often bring about a clear boost in performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e2d\uff0c\u5982\u4f55\u6700\u4f73\u5730\u8868\u793a\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u4ea4\u4e92\u5173\u7cfb\u4ee5\u6355\u6349\u5176\u8054\u5408\u5206\u5e03\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8ba9\u7f51\u7edc\u57fa\u4e8e\u6570\u636e\u9690\u5f0f\u5b66\u4e60\u4ea4\u4e92\u8fde\u63a5\u901a\u5e38\u5bf9\u6027\u80fd\u6709\u5bb3\uff0c\u800c\u660e\u786e\u5b9a\u4e49\u7684\u4ea4\u4e92\uff08\u5982\u786e\u5b9a\u54ea\u4e2a\u667a\u80fd\u4f53\u5728\u4ea4\u53c9\u53e3\u4f18\u5148\u901a\u8fc7\uff09\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u6709\u6548\u6355\u6349\u573a\u666f\u4e2d\u6240\u6709\u667a\u80fd\u4f53\u7684\u8054\u5408\u5206\u5e03\u5bf9\u4e8e\u9884\u6d4b\u573a\u666f\u7684\u771f\u5b9e\u6f14\u53d8\u548c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u51b3\u7b56\u63d0\u4f9b\u66f4\u51c6\u786e\u4fe1\u606f\u81f3\u5173\u91cd\u8981\u3002\u76ee\u524d\u5bf9\u4e8e\u5982\u4f55\u6700\u4f73\u8868\u793a\u667a\u80fd\u4f53\u95f4\u4ea4\u4e92\u5c1a\u65e0\u5171\u8bc6\u2014\u2014\u662f\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u9690\u5f0f\u5b66\u4e60\uff0c\u8fd8\u662f\u4f7f\u7528\u66f4\u8d34\u8fd1\u4eba\u7c7b\u51b3\u7b56\u7684\u65f6\u7a7a\u5173\u7cfb\u8fdb\u884c\u663e\u5f0f\u5efa\u6a21\u3002", "method": "\u5728\u540c\u4e00\u7f51\u7edc\u7ed3\u6784\u4e2d\u7814\u7a76\u4e0d\u540c\u4ea4\u4e92\u63cf\u8ff0\u65b9\u5f0f\u53ca\u5176\u5bf9\u6700\u7ec8\u5b66\u4e60\u5230\u7684\u8054\u5408\u5206\u5e03\u7684\u5f71\u54cd\u3002\u6bd4\u8f83\u4e86\u9690\u5f0f\u5b66\u4e60\u4ea4\u4e92\u8fde\u63a5\u548c\u660e\u786e\u5b9a\u4e49\u4ea4\u4e92\uff08\u5982\u786e\u5b9a\u4ea4\u53c9\u53e3\u4f18\u5148\u901a\u8fc7\u6743\uff09\u4e24\u79cd\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u8ba9\u7f51\u7edc\u57fa\u4e8e\u6570\u636e\u9690\u5f0f\u5efa\u7acb\u667a\u80fd\u4f53\u95f4\u4ea4\u4e92\u8fde\u63a5\u901a\u5e38\u5bf9\u6027\u80fd\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002\u76f8\u53cd\uff0c\u5177\u6709\u660e\u786e\u5b9a\u4e49\u7684\u4ea4\u4e92\uff08\u5982\u786e\u5b9a\u667a\u80fd\u4f53\u5bf9\u4e2d\u54ea\u4e2a\u4f18\u5148\u901a\u8fc7\u4ea4\u53c9\u53e3\uff09\u5f80\u5f80\u80fd\u5e26\u6765\u660e\u663e\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u660e\u786e\u5b9a\u4e49\u7684\u4ea4\u4e92\u5efa\u6a21\u65b9\u6cd5\u4f18\u4e8e\u9690\u5f0f\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u7684\u8054\u5408\u5206\u5e03\u9884\u6d4b\u4e2d\u80fd\u5e26\u6765\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2511.03903", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03903", "abs": "https://arxiv.org/abs/2511.03903", "authors": ["Niloufar Yousefi", "John W. Simpson-Porco"], "title": "Removing Time-Scale Separation in Feedback-Based Optimization via Estimators", "comment": null, "summary": "Feedback-based optimization (FBO) provides a simple control framework for\nregulating a stable dynamical system to the solution of a constrained\noptimization problem in the presence of exogenous disturbances, and does so\nwithout full knowledge of the plant dynamics. However, closed-loop stability\nrequires the controller to operate on a sufficiently slower timescale than the\nplant, significantly constraining achievable closed-loop performance. Motivated\nby this trade-off, we propose an estimator-based modification of FBO which\nleverages dynamic plant model information to eliminate the time-scale\nseparation requirement of traditional FBO. Under this design, the convergence\nrate of the closed-loop system is limited only by the dominant eigenvalue of\nthe open-loop system. We extend the approach to the case of design based on\nonly an approximate plant model when the original system is singularly\nperturbed. The results are illustrated via an application to fast power system\nfrequency control using inverter-based resources.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f30\u8ba1\u5668\u7684\u53cd\u9988\u4f18\u5316\u65b9\u6cd5\u6539\u8fdb\uff0c\u901a\u8fc7\u5229\u7528\u52a8\u6001\u7cfb\u7edf\u6a21\u578b\u4fe1\u606f\u6d88\u9664\u4f20\u7edf\u53cd\u9988\u4f18\u5316\u4e2d\u7684\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb\u8981\u6c42\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u95ed\u73af\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u53cd\u9988\u4f18\u5316\u9700\u8981\u63a7\u5236\u5668\u6bd4\u88ab\u63a7\u7cfb\u7edf\u8fd0\u884c\u5728\u66f4\u6162\u7684\u65f6\u95f4\u5c3a\u5ea6\u4e0a\uff0c\u8fd9\u4e25\u91cd\u9650\u5236\u4e86\u95ed\u73af\u6027\u80fd\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u6743\u8861\u95ee\u9898\uff0c\u9700\u8981\u6d88\u9664\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb\u7684\u8981\u6c42\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4f30\u8ba1\u5668\u7684\u53cd\u9988\u4f18\u5316\u6539\u8fdb\u65b9\u6cd5\uff0c\u5229\u7528\u52a8\u6001\u7cfb\u7edf\u6a21\u578b\u4fe1\u606f\u6765\u8bbe\u8ba1\u63a7\u5236\u5668\uff0c\u4e0d\u518d\u9700\u8981\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb\u3002", "result": "\u65b0\u65b9\u6cd5\u4f7f\u95ed\u73af\u7cfb\u7edf\u7684\u6536\u655b\u901f\u7387\u4ec5\u53d7\u9650\u4e8e\u5f00\u73af\u7cfb\u7edf\u7684\u4e3b\u5bfc\u7279\u5f81\u503c\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u8fd8\u53ef\u6269\u5c55\u5230\u57fa\u4e8e\u8fd1\u4f3c\u6a21\u578b\u7684\u8bbe\u8ba1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u4f30\u8ba1\u5668\u7684\u53cd\u9988\u4f18\u5316\u65b9\u6cd5\u6210\u529f\u6d88\u9664\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u65f6\u95f4\u5c3a\u5ea6\u9650\u5236\uff0c\u5728\u7535\u529b\u7cfb\u7edf\u9891\u7387\u63a7\u5236\u7b49\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.04093", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04093", "abs": "https://arxiv.org/abs/2511.04093", "authors": ["Yuanning Cui", "Zequn Sun", "Wei Hu", "Zhangjie Fu"], "title": "KGFR: A Foundation Retriever for Generalized Knowledge Graph Question Answering", "comment": null, "summary": "Large language models (LLMs) excel at reasoning but struggle with\nknowledge-intensive questions due to limited context and parametric knowledge.\nHowever, existing methods that rely on finetuned LLMs or GNN retrievers are\nlimited by dataset-specific tuning and scalability on large or unseen graphs.\nWe propose the LLM-KGFR collaborative framework, where an LLM works with a\nstructured retriever, the Knowledge Graph Foundation Retriever (KGFR). KGFR\nencodes relations using LLM-generated descriptions and initializes entities\nbased on their roles in the question, enabling zero-shot generalization to\nunseen KGs. To handle large graphs efficiently, it employs Asymmetric\nProgressive Propagation (APP)- a stepwise expansion that selectively limits\nhigh-degree nodes while retaining informative paths. Through node-, edge-, and\npath-level interfaces, the LLM iteratively requests candidate answers,\nsupporting facts, and reasoning paths, forming a controllable reasoning loop.\nExperiments demonstrate that LLM-KGFR achieves strong performance while\nmaintaining scalability and generalization, providing a practical solution for\nKG-augmented reasoning.", "AI": {"tldr": "LLM-KGFR\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u77e5\u8bc6\u56fe\u8c31\u57fa\u7840\u68c0\u7d22\u5668\uff0c\u89e3\u51b3LLM\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u95ee\u9898\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u96f6\u6837\u672c\u6cdb\u5316\u548c\u5927\u89c4\u6a21\u56fe\u8c31\u7684\u9ad8\u6548\u5904\u7406\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5fae\u8c03LLM\u6216GNN\u68c0\u7d22\u5668\u7684\u65b9\u6cd5\u5b58\u5728\u6570\u636e\u96c6\u7279\u5b9a\u8c03\u4f18\u548c\u53ef\u6269\u5c55\u6027\u9650\u5236\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u5927\u89c4\u6a21\u6216\u672a\u89c1\u8fc7\u7684\u77e5\u8bc6\u56fe\u8c31\u3002", "method": "\u63d0\u51faLLM-KGFR\u534f\u4f5c\u6846\u67b6\uff0c\u5229\u7528LLM\u751f\u6210\u5173\u7cfb\u63cf\u8ff0\u7f16\u7801\uff0c\u57fa\u4e8e\u95ee\u9898\u89d2\u8272\u521d\u59cb\u5316\u5b9e\u4f53\uff0c\u91c7\u7528\u975e\u5bf9\u79f0\u6e10\u8fdb\u4f20\u64ad\u7b56\u7565\u9ad8\u6548\u5904\u7406\u5927\u56fe\uff0c\u901a\u8fc7\u8282\u70b9\u3001\u8fb9\u548c\u8def\u5f84\u7ea7\u63a5\u53e3\u5b9e\u73b0\u53ef\u63a7\u63a8\u7406\u5faa\u73af\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLLM-KGFR\u5728\u4fdd\u6301\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5f3a\u52b2\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.04381", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04381", "abs": "https://arxiv.org/abs/2511.04381", "authors": ["Dexin wang", "Faliang Chang", "Chunsheng Liu"], "title": "ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation", "comment": null, "summary": "Efficiently leveraging simulation to acquire advanced manipulation skills is\nboth challenging and highly significant. We introduce \\textit{ForeRobo}, a\ngenerative robotic agent that utilizes generative simulations to autonomously\nacquire manipulation skills driven by envisioned goal states. Instead of\ndirectly learning low-level policies, we advocate integrating generative\nparadigms with classical control. Our approach equips a robotic agent with a\nself-guided \\textit{propose-generate-learn-actuate} cycle. The agent first\nproposes the skills to be acquired and constructs the corresponding simulation\nenvironments; it then configures objects into appropriate arrangements to\ngenerate skill-consistent goal states (\\textit{ForeGen}). Subsequently, the\nvirtually infinite data produced by ForeGen are used to train the proposed\nstate generation model (\\textit{ForeFormer}), which establishes point-wise\ncorrespondences by predicting the 3D goal position of every point in the\ncurrent state, based on the scene state and task instructions. Finally,\nclassical control algorithms are employed to drive the robot in real-world\nenvironments to execute actions based on the envisioned goal states. Compared\nwith end-to-end policy learning methods, ForeFormer offers superior\ninterpretability and execution efficiency. We train and benchmark ForeFormer\nacross a variety of rigid-body and articulated-object manipulation tasks, and\nobserve an average improvement of 56.32\\% over the state-of-the-art state\ngeneration models, demonstrating strong generality across different\nmanipulation patterns. Moreover, in real-world evaluations involving more than\n20 robotic tasks, ForeRobo achieves zero-shot sim-to-real transfer and exhibits\nremarkable generalization capabilities, attaining an average success rate of\n79.28\\%.", "AI": {"tldr": "ForeRobo\u662f\u4e00\u4e2a\u751f\u6210\u5f0f\u673a\u5668\u4eba\u4ee3\u7406\uff0c\u901a\u8fc7\u751f\u6210\u6a21\u62df\u81ea\u4e3b\u83b7\u53d6\u64cd\u4f5c\u6280\u80fd\uff0c\u7ed3\u5408\u751f\u6210\u8303\u5f0f\u4e0e\u7ecf\u5178\u63a7\u5236\uff0c\u5b9e\u73b0\u96f6\u6837\u672c\u6a21\u62df\u5230\u771f\u5b9e\u73af\u5883\u7684\u8fc1\u79fb\u3002", "motivation": "\u9ad8\u6548\u5229\u7528\u6a21\u62df\u83b7\u53d6\u9ad8\u7ea7\u64cd\u4f5c\u6280\u80fd\u5177\u6709\u6311\u6218\u6027\u4f46\u610f\u4e49\u91cd\u5927\uff0c\u73b0\u6709\u7aef\u5230\u7aef\u7b56\u7565\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u6267\u884c\u6548\u7387\u3002", "method": "\u91c7\u7528\u81ea\u5f15\u5bfc\u7684\"\u63d0\u8bae-\u751f\u6210-\u5b66\u4e60-\u6267\u884c\"\u5faa\u73af\uff1a\u63d0\u8bae\u6280\u80fd\u5e76\u6784\u5efa\u6a21\u62df\u73af\u5883\uff0c\u751f\u6210\u6280\u80fd\u4e00\u81f4\u7684\u76ee\u6807\u72b6\u6001(ForeGen)\uff0c\u8bad\u7ec3\u72b6\u6001\u751f\u6210\u6a21\u578b(ForeFormer)\u9884\u6d4b3D\u76ee\u6807\u4f4d\u7f6e\uff0c\u6700\u540e\u4f7f\u7528\u7ecf\u5178\u63a7\u5236\u7b97\u6cd5\u9a71\u52a8\u771f\u5b9e\u673a\u5668\u4eba\u3002", "result": "\u5728\u591a\u79cd\u521a\u4f53\u548c\u5173\u8282\u7269\u4f53\u64cd\u4f5c\u4efb\u52a1\u4e2d\uff0cForeFormer\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u72b6\u6001\u751f\u6210\u6a21\u578b\u5e73\u5747\u63d0\u534756.32%\uff0c\u572820\u591a\u4e2a\u771f\u5b9e\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u5b9e\u73b079.28%\u7684\u5e73\u5747\u6210\u529f\u7387\u3002", "conclusion": "ForeRobo\u5c55\u793a\u4e86\u751f\u6210\u6a21\u62df\u4e0e\u7ecf\u5178\u63a7\u5236\u7ed3\u5408\u7684\u6709\u6548\u6027\uff0c\u5177\u6709\u4f18\u8d8a\u7684\u53ef\u89e3\u91ca\u6027\u3001\u6267\u884c\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u6210\u529f\u5b9e\u73b0\u96f6\u6837\u672c\u6a21\u62df\u5230\u771f\u5b9e\u73af\u5883\u7684\u8fc1\u79fb\u3002"}}
{"id": "2511.03969", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.03969", "abs": "https://arxiv.org/abs/2511.03969", "authors": ["Hangyu Teng"], "title": "A Co-simulation Framework for Quadrotor Control System Design using ROS 2 and MATLAB/Simulink", "comment": null, "summary": "Co-simulation is a critical approach for the design and analysis of complex\ncyber-physical systems. It will enhance development efficiency and reduce\ncosts. This paper presents a co-simulation framework integrating ROS 2 and\nMATLAB/Simulink for quadrotor unmanned aerial vehicle (UAV) control system\ndesign and verification. First, a six-degree-of-freedom nonlinear dynamic model\nof the quadrotor is derived accurately that based on Newton-Euler equations.\nSecond, within the proposed framework, a hierarchical control architecture was\ndesigned and implemented: LQR controller for attitude control to achieve\noptimal regulation performance, and PID controller for position control to\nensure robustness and practical applicability. Third, elaborated the\narchitecture of the framework, including the implementation details of the\ncross-platform data exchange mechanism. Simulation results demonstrate the\neffectiveness of the framework, highlighting its capability to provide an\nefficient and standardized solution for rapid prototyping and\nSoftware-in-the-Loop (SIL) validation of UAV control algorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210ROS 2\u548cMATLAB/Simulink\u7684\u534f\u540c\u4eff\u771f\u6846\u67b6\uff0c\u7528\u4e8e\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u63a7\u5236\u7cfb\u7edf\u8bbe\u8ba1\u548c\u9a8c\u8bc1\uff0c\u5305\u542b\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u6a21\u578b\u3001\u5206\u5c42\u63a7\u5236\u67b6\u6784\u548c\u8de8\u5e73\u53f0\u6570\u636e\u4ea4\u6362\u673a\u5236\u3002", "motivation": "\u534f\u540c\u4eff\u771f\u662f\u590d\u6742\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u8bbe\u8ba1\u548c\u5206\u6790\u7684\u5173\u952e\u65b9\u6cd5\uff0c\u80fd\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u5e76\u964d\u4f4e\u6210\u672c\u3002", "method": "1. \u57fa\u4e8e\u725b\u987f-\u6b27\u62c9\u65b9\u7a0b\u63a8\u5bfc\u56db\u65cb\u7ffc\u516d\u81ea\u7531\u5ea6\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u6a21\u578b\uff1b2. \u8bbe\u8ba1\u5206\u5c42\u63a7\u5236\u67b6\u6784\uff1aLQR\u63a7\u5236\u5668\u7528\u4e8e\u59ff\u6001\u63a7\u5236\uff0cPID\u63a7\u5236\u5668\u7528\u4e8e\u4f4d\u7f6e\u63a7\u5236\uff1b3. \u5b9e\u73b0\u8de8\u5e73\u53f0\u6570\u636e\u4ea4\u6362\u673a\u5236\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u4e3a\u65e0\u4eba\u673a\u63a7\u5236\u7b97\u6cd5\u63d0\u4f9b\u9ad8\u6548\u7684\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u548c\u8f6f\u4ef6\u5728\u73af\u9a8c\u8bc1\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u65e0\u4eba\u673a\u63a7\u5236\u7b97\u6cd5\u7684\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u548c\u8f6f\u4ef6\u5728\u73af\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u6807\u51c6\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.04133", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04133", "abs": "https://arxiv.org/abs/2511.04133", "authors": ["Miguel E. Andres", "Vadim Fedorov", "Rida Sadek", "Enric Spagnolo-Arrizabalaga", "Nadescha Trudel"], "title": "Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing Platforms", "comment": null, "summary": "Voice AI agents are rapidly transitioning to production deployments, yet\nsystematic methods for ensuring testing reliability remain underdeveloped.\nOrganizations cannot objectively assess whether their testing approaches\n(internal tools or external platforms) actually work, creating a critical\nmeasurement gap as voice AI scales to billions of daily interactions.\n  We present the first systematic framework for evaluating voice AI testing\nquality through human-centered benchmarking. Our methodology addresses the\nfundamental dual challenge of testing platforms: generating realistic test\nconversations (simulation quality) and accurately evaluating agent responses\n(evaluation quality). The framework combines established psychometric\ntechniques (pairwise comparisons yielding Elo ratings, bootstrap confidence\nintervals, and permutation tests) with rigorous statistical validation to\nprovide reproducible metrics applicable to any testing approach.\n  To validate the framework and demonstrate its utility, we conducted\ncomprehensive empirical evaluation of three leading commercial platforms\nfocused on Voice AI Testing using 21,600 human judgments across 45 simulations\nand ground truth validation on 60 conversations. Results reveal statistically\nsignificant performance differences with the proposed framework, with the\ntop-performing platform, Evalion, achieving 0.92 evaluation quality measured as\nf1-score versus 0.73 for others, and 0.61 simulation quality using a league\nbased scoring system (including ties) vs 0.43 for other platforms.\n  This framework enables researchers and organizations to empirically validate\nthe testing capabilities of any platform, providing essential measurement\nfoundations for confident voice AI deployment at scale. Supporting materials\nare made available to facilitate reproducibility and adoption.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u7cfb\u7edf\u6846\u67b6\u6765\u8bc4\u4f30\u8bed\u97f3AI\u6d4b\u8bd5\u8d28\u91cf\uff0c\u901a\u8fc7\u4eba\u7c7b\u4e2d\u5fc3\u5316\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u6d4b\u8bd5\u5e73\u53f0\u751f\u6210\u771f\u5b9e\u5bf9\u8bdd\u548c\u51c6\u786e\u8bc4\u4f30\u54cd\u5e94\u7684\u53cc\u91cd\u6311\u6218\u3002", "motivation": "\u968f\u7740\u8bed\u97f3AI\u4ee3\u7406\u5feb\u901f\u90e8\u7f72\u5230\u751f\u4ea7\u73af\u5883\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u6d4b\u8bd5\u53ef\u9760\u6027\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u7ec4\u7ec7\u65e0\u6cd5\u5ba2\u89c2\u8bc4\u4f30\u6d4b\u8bd5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8fd9\u5728\u5927\u89c4\u6a21\u90e8\u7f72\u65f6\u9020\u6210\u4e86\u5173\u952e\u7684\u6d4b\u91cf\u5dee\u8ddd\u3002", "method": "\u7ed3\u5408\u5fc3\u7406\u6d4b\u91cf\u6280\u672f\uff08\u6210\u5bf9\u6bd4\u8f83\u4ea7\u751fElo\u8bc4\u5206\u3001\u81ea\u52a9\u7f6e\u4fe1\u533a\u95f4\u548c\u7f6e\u6362\u68c0\u9a8c\uff09\u4e0e\u4e25\u683c\u7edf\u8ba1\u9a8c\u8bc1\uff0c\u63d0\u4f9b\u53ef\u590d\u73b0\u7684\u6307\u6807\uff0c\u9002\u7528\u4e8e\u4efb\u4f55\u6d4b\u8bd5\u65b9\u6cd5\u3002", "result": "\u5bf9\u4e09\u4e2a\u9886\u5148\u5546\u4e1a\u5e73\u53f0\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aEvalion\u5e73\u53f0\u8868\u73b0\u6700\u4f73\uff0c\u8bc4\u4f30\u8d28\u91cfF1\u5206\u6570\u8fbe0.92\uff0c\u6a21\u62df\u8d28\u91cf\u8fbe0.61\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u5e73\u53f0\u3002", "conclusion": "\u8be5\u6846\u67b6\u4f7f\u7814\u7a76\u4eba\u5458\u548c\u7ec4\u7ec7\u80fd\u591f\u5b9e\u8bc1\u9a8c\u8bc1\u4efb\u4f55\u5e73\u53f0\u7684\u6d4b\u8bd5\u80fd\u529b\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u97f3AI\u90e8\u7f72\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u6d4b\u91cf\u57fa\u7840\u3002"}}
{"id": "2511.04421", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04421", "abs": "https://arxiv.org/abs/2511.04421", "authors": ["Yueyang Weng", "Xiaopeng Zhang", "Yongjin Mu", "Yingcong Zhu", "Yanjie Li", "Qi Liu"], "title": "Temporal Action Selection for Action Chunking", "comment": null, "summary": "Action chunking is a widely adopted approach in Learning from Demonstration\n(LfD). By modeling multi-step action chunks rather than single-step actions,\naction chunking significantly enhances modeling capabilities for human expert\npolicies. However, the reduced decision frequency restricts the utilization of\nrecent observations, degrading reactivity - particularly evident in the\ninadequate adaptation to sensor noise and dynamic environmental changes.\nExisting efforts to address this issue have primarily resorted to trading off\nreactivity against decision consistency, without achieving both. To address\nthis limitation, we propose a novel algorithm, Temporal Action Selector (TAS),\nwhich caches predicted action chunks from multiple timesteps and dynamically\nselects the optimal action through a lightweight selector network. TAS achieves\nbalanced optimization across three critical dimensions: reactivity, decision\nconsistency, and motion coherence. Experiments across multiple tasks with\ndiverse base policies show that TAS significantly improves success rates -\nyielding an absolute gain of up to 73.3%. Furthermore, integrating TAS as a\nbase policy with residual reinforcement learning (RL) substantially enhances\ntraining efficiency and elevates the performance plateau. Experiments in both\nsimulation and physical robots confirm the method's efficacy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTAS\u7684\u65b0\u7b97\u6cd5\uff0c\u901a\u8fc7\u7f13\u5b58\u591a\u4e2a\u65f6\u95f4\u6b65\u7684\u9884\u6d4b\u52a8\u4f5c\u5757\u5e76\u4f7f\u7528\u8f7b\u91cf\u7ea7\u9009\u62e9\u5668\u7f51\u7edc\u52a8\u6001\u9009\u62e9\u6700\u4f18\u52a8\u4f5c\uff0c\u89e3\u51b3\u4e86\u52a8\u4f5c\u5206\u5757\u65b9\u6cd5\u5728\u53cd\u5e94\u6027\u3001\u51b3\u7b56\u4e00\u81f4\u6027\u548c\u8fd0\u52a8\u8fde\u8d2f\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u52a8\u4f5c\u5206\u5757\u65b9\u6cd5\u867d\u7136\u589e\u5f3a\u4e86\u5efa\u6a21\u80fd\u529b\uff0c\u4f46\u964d\u4f4e\u4e86\u51b3\u7b56\u9891\u7387\uff0c\u9650\u5236\u4e86\u8fd1\u671f\u89c2\u5bdf\u7684\u5229\u7528\uff0c\u5bfc\u81f4\u53cd\u5e94\u6027\u4e0b\u964d\uff0c\u7279\u522b\u662f\u5728\u9002\u5e94\u4f20\u611f\u5668\u566a\u58f0\u548c\u52a8\u6001\u73af\u5883\u53d8\u5316\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u5b9e\u73b0\u53cd\u5e94\u6027\u548c\u51b3\u7b56\u4e00\u81f4\u6027\u3002", "method": "TAS\u7b97\u6cd5\u7f13\u5b58\u591a\u4e2a\u65f6\u95f4\u6b65\u9884\u6d4b\u7684\u52a8\u4f5c\u5757\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u9009\u62e9\u5668\u7f51\u7edc\u52a8\u6001\u9009\u62e9\u6700\u4f18\u52a8\u4f5c\u3002\u8be5\u65b9\u6cd5\u53ef\u4e0e\u6b8b\u5dee\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u4f7f\u7528\u3002", "result": "\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u4e0d\u540c\u57fa\u7840\u7b56\u7565\u7684\u5b9e\u9a8c\u4e2d\uff0cTAS\u663e\u8457\u63d0\u9ad8\u4e86\u6210\u529f\u7387\uff0c\u7edd\u5bf9\u589e\u76ca\u9ad8\u8fbe73.3%\u3002\u4e0e\u6b8b\u5dee\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u540e\uff0c\u8bad\u7ec3\u6548\u7387\u5927\u5e45\u63d0\u5347\uff0c\u6027\u80fd\u4e0a\u9650\u4e5f\u5f97\u5230\u63d0\u9ad8\u3002\u4eff\u771f\u548c\u7269\u7406\u673a\u5668\u4eba\u5b9e\u9a8c\u5747\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "TAS\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u52a8\u4f5c\u5206\u5757\u65b9\u6cd5\u5728\u53cd\u5e94\u6027\u3001\u51b3\u7b56\u4e00\u81f4\u6027\u548c\u8fd0\u52a8\u8fde\u8d2f\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b66\u4e60\u6548\u679c\u548c\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2511.04054", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.04054", "abs": "https://arxiv.org/abs/2511.04054", "authors": ["Sheikh A. Tahmid", "Gennaro Notomista"], "title": "Necessary and Sufficient Conditions for the Optimization-Based Concurrent Execution of Learned Robotic Tasks", "comment": "currently in review", "summary": "In this work, we consider the problem of executing multiple tasks encoded by\nvalue functions, each learned through Reinforcement Learning, using an\noptimization-based framework. Prior works develop such a framework, but left\nunanswered a fundamental question of when learned value functions can be\nconcurrently executed. The main contribution of this work is to present\ntheorems which provide necessary and sufficient conditions to concurrently\nexecute sets of learned tasks within subsets of the state space, using a\npreviously proposed min-norm controller. These theorems provide insight into\nwhen learned control tasks are possible to be made concurrently executable,\nwhen they might already inherently be concurrently executable and when it is\nnot possible at all to make a set of learned tasks concurrently executable\nusing the previously proposed methods. Additional contributions of this work\ninclude extending the optimization-based framework to execute multiple tasks\nencoded by value functions to also account for value functions trained with a\ndiscount factor, making the overall framework more compatible with standard RL\npractices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5173\u4e8e\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u4ef7\u503c\u51fd\u6570\u5e76\u53d1\u6267\u884c\u7684\u7406\u8bba\u6761\u4ef6\uff0c\u6269\u5c55\u4e86\u57fa\u4e8e\u4f18\u5316\u7684\u591a\u4efb\u52a1\u6267\u884c\u6846\u67b6\u3002", "motivation": "\u5148\u524d\u7684\u5de5\u4f5c\u5f00\u53d1\u4e86\u57fa\u4e8e\u4f18\u5316\u7684\u591a\u4efb\u52a1\u6267\u884c\u6846\u67b6\uff0c\u4f46\u672a\u56de\u7b54\u4f55\u65f6\u53ef\u4ee5\u5e76\u53d1\u6267\u884c\u5b66\u4e60\u5230\u7684\u4ef7\u503c\u51fd\u6570\u8fd9\u4e00\u57fa\u672c\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5148\u524d\u63d0\u51fa\u7684\u6700\u5c0f\u8303\u6570\u63a7\u5236\u5668\uff0c\u63d0\u51fa\u4e86\u5728\u72b6\u6001\u7a7a\u95f4\u5b50\u96c6\u4e2d\u5e76\u53d1\u6267\u884c\u5b66\u4e60\u4efb\u52a1\u96c6\u7684\u5fc5\u8981\u548c\u5145\u5206\u6761\u4ef6\u5b9a\u7406\u3002", "result": "\u5b9a\u7406\u63ed\u793a\u4e86\u4f55\u65f6\u53ef\u4ee5\u4f7f\u5b66\u4e60\u5230\u7684\u63a7\u5236\u4efb\u52a1\u5e76\u53d1\u6267\u884c\u3001\u4f55\u65f6\u5b83\u4eec\u5df2\u7ecf\u56fa\u6709\u5730\u53ef\u5e76\u53d1\u6267\u884c\uff0c\u4ee5\u53ca\u4f55\u65f6\u65e0\u6cd5\u4f7f\u7528\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u5e76\u53d1\u6267\u884c\u3002", "conclusion": "\u6269\u5c55\u4e86\u57fa\u4e8e\u4f18\u5316\u7684\u6846\u67b6\u4ee5\u5904\u7406\u5e26\u6298\u6263\u56e0\u5b50\u7684\u4ef7\u503c\u51fd\u6570\uff0c\u4f7f\u6574\u4f53\u6846\u67b6\u66f4\u7b26\u5408\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u5b9e\u8df5\u3002"}}
{"id": "2511.04177", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04177", "abs": "https://arxiv.org/abs/2511.04177", "authors": ["Claire Yang", "Maya Cakmak", "Max Kleiman-Weiner"], "title": "When Empowerment Disempowers", "comment": null, "summary": "Empowerment, a measure of an agent's ability to control its environment, has\nbeen proposed as a universal goal-agnostic objective for motivating assistive\nbehavior in AI agents. While multi-human settings like homes and hospitals are\npromising for AI assistance, prior work on empowerment-based assistance assumes\nthat the agent assists one human in isolation. We introduce an open source\nmulti-human gridworld test suite Disempower-Grid. Using Disempower-Grid, we\nempirically show that assistive RL agents optimizing for one human's\nempowerment can significantly reduce another human's environmental influence\nand rewards - a phenomenon we formalize as disempowerment. We characterize when\ndisempowerment occurs in these environments and show that joint empowerment\nmitigates disempowerment at the cost of the user's reward. Our work reveals a\nbroader challenge for the AI alignment community: goal-agnostic objectives that\nseem aligned in single-agent settings can become misaligned in multi-agent\ncontexts.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.04555", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04555", "abs": "https://arxiv.org/abs/2511.04555", "authors": ["Tao Lin", "Yilei Zhong", "Yuxin Du", "Jingjing Zhang", "Jiting Liu", "Yinxinyu Chen", "Encheng Gu", "Ziyan Liu", "Hongyi Cai", "Yanwen Zou", "Lixing Zou", "Zhaoye Zhou", "Gen Li", "Bo Zhao"], "title": "Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment", "comment": "Github: https://github.com/MINT-SJTU/Evo-1", "summary": "Vision-Language-Action (VLA) models have emerged as a powerful framework that\nunifies perception, language, and control, enabling robots to perform diverse\ntasks through multimodal understanding. However, current VLA models typically\ncontain massive parameters and rely heavily on large-scale robot data\npretraining, leading to high computational costs during training, as well as\nlimited deployability for real-time inference. Moreover, most training\nparadigms often degrade the perceptual representations of the vision-language\nbackbone, resulting in overfitting and poor generalization to downstream tasks.\nIn this work, we present Evo-1, a lightweight VLA model that reduces\ncomputation and improves deployment efficiency, while maintaining strong\nperformance without pretraining on robot data. Evo-1 builds on a native\nmultimodal Vision-Language model (VLM), incorporating a novel cross-modulated\ndiffusion transformer along with an optimized integration module, together\nforming an effective architecture. We further introduce a two-stage training\nparadigm that progressively aligns action with perception, preserving the\nrepresentations of the VLM. Notably, with only 0.77 billion parameters, Evo-1\nachieves state-of-the-art results on the Meta-World and RoboTwin suite,\nsurpassing the previous best models by 12.4% and 6.9%, respectively, and also\nattains a competitive result of 94.8% on LIBERO. In real-world evaluations,\nEvo-1 attains a 78% success rate with high inference frequency and low memory\noverhead, outperforming all baseline methods. We release code, data, and model\nweights to facilitate future research on lightweight and efficient VLA models.", "AI": {"tldr": "Evo-1\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u8de8\u8c03\u5236\u6269\u6563\u53d8\u6362\u5668\u548c\u4f18\u5316\u7684\u96c6\u6210\u6a21\u5757\uff0c\u5728\u4ec50.77B\u53c2\u6570\u4e0b\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u65e0\u9700\u673a\u5668\u4eba\u6570\u636e\u9884\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u90e8\u7f72\u6548\u7387\u3002", "motivation": "\u5f53\u524dVLA\u6a21\u578b\u53c2\u6570\u91cf\u5927\u3001\u4f9d\u8d56\u5927\u89c4\u6a21\u673a\u5668\u4eba\u6570\u636e\u9884\u8bad\u7ec3\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u5b9e\u65f6\u63a8\u7406\u90e8\u7f72\u56f0\u96be\uff0c\u4e14\u8bad\u7ec3\u8303\u5f0f\u4f1a\u635f\u5bb3\u89c6\u89c9-\u8bed\u8a00\u9aa8\u5e72\u7f51\u7edc\u7684\u611f\u77e5\u8868\u793a\uff0c\u5bfc\u81f4\u8fc7\u62df\u5408\u548c\u6cdb\u5316\u80fd\u529b\u5dee\u3002", "method": "\u57fa\u4e8e\u539f\u751f\u591a\u6a21\u6001\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff0c\u5f15\u5165\u8de8\u8c03\u5236\u6269\u6563\u53d8\u6362\u5668\u548c\u4f18\u5316\u96c6\u6210\u6a21\u5757\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\u9010\u6b65\u5bf9\u9f50\u52a8\u4f5c\u4e0e\u611f\u77e5\uff0c\u4fdd\u7559VLM\u8868\u793a\u3002", "result": "\u5728Meta-World\u548cRoboTwin\u5957\u4ef6\u4e0a\u5206\u522b\u8d85\u8d8a\u4e4b\u524d\u6700\u4f73\u6a21\u578b12.4%\u548c6.9%\uff0c\u5728LIBERO\u4e0a\u8fbe\u523094.8%\u7684\u7ade\u4e89\u6027\u7ed3\u679c\uff0c\u771f\u5b9e\u4e16\u754c\u8bc4\u4f30\u4e2d\u8fbe\u523078%\u6210\u529f\u7387\uff0c\u5177\u6709\u9ad8\u63a8\u7406\u9891\u7387\u548c\u4f4e\u5185\u5b58\u5f00\u9500\u3002", "conclusion": "Evo-1\u8bc1\u660e\u4e86\u8f7b\u91cf\u7ea7VLA\u6a21\u578b\u7684\u53ef\u884c\u6027\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u90e8\u7f72\u6548\u7387\uff0c\u4e3a\u8f7b\u91cf\u9ad8\u6548VLA\u6a21\u578b\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2511.04246", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.04246", "abs": "https://arxiv.org/abs/2511.04246", "authors": ["Sander De Witte", "Tom Lefebvre", "Thomas Neve", "Andras Retzler", "Guillaume Crevecoeur"], "title": "Differential Flatness of Quasi-Static Slider-Pusher Models with Applications in Control", "comment": null, "summary": "This paper investigates the dynamic properties of planar slider-pusher\nsystems as a motion primitive in manipulation tasks. To that end, we construct\na differential kinematic model deriving from the limit surface approach under\nthe quasi-static assumption and with negligible contact friction. The\nquasi-static model applies to generic slider shapes and circular pusher\ngeometries, enabling a differential kinematic representation of the system.\nFrom this model, we analyze differential flatness - a property advantageous for\ncontrol synthesis and planning - and find that slider-pusher systems with\npolygon sliders and circular pushers exhibit flatness with the centre of mass\nas a flat output. Leveraging this property, we propose two control strategies\nfor trajectory tracking: a cascaded quasi-static feedback strategy and a\ndynamic feedback linearization approach. We validate these strategies through\nclosed-loop simulations incorporating perturbed models and input noise, as well\nas experimental results using a physical setup with a finger-like pusher and\nvision-based state detection. The real-world experiments confirm the\napplicability of the simulation gains, highlighting the potential of the\nproposed methods for", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e73\u9762\u6ed1\u5757-\u63a8\u52a8\u5668\u7cfb\u7edf\u4f5c\u4e3a\u64cd\u4f5c\u4efb\u52a1\u4e2d\u8fd0\u52a8\u57fa\u5143\u7684\u52a8\u6001\u7279\u6027\uff0c\u5efa\u7acb\u4e86\u57fa\u4e8e\u6781\u9650\u8868\u9762\u65b9\u6cd5\u7684\u5fae\u5206\u8fd0\u52a8\u5b66\u6a21\u578b\uff0c\u5206\u6790\u4e86\u7cfb\u7edf\u7684\u5fae\u5206\u5e73\u5766\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u8f68\u8ff9\u8ddf\u8e2a\u63a7\u5236\u7b56\u7565\u3002", "motivation": "\u7814\u7a76\u5e73\u9762\u6ed1\u5757-\u63a8\u52a8\u5668\u7cfb\u7edf\u7684\u52a8\u6001\u7279\u6027\uff0c\u5c06\u5176\u4f5c\u4e3a\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u8fd0\u52a8\u57fa\u5143\uff0c\u63a2\u7d22\u5176\u5fae\u5206\u5e73\u5766\u6027\u4ee5\u7b80\u5316\u63a7\u5236\u7efc\u5408\u548c\u89c4\u5212\u3002", "method": "\u6784\u5efa\u4e86\u57fa\u4e8e\u6781\u9650\u8868\u9762\u65b9\u6cd5\u7684\u5fae\u5206\u8fd0\u52a8\u5b66\u6a21\u578b\uff0c\u5206\u6790\u4e86\u591a\u8fb9\u5f62\u6ed1\u5757\u548c\u5706\u5f62\u63a8\u52a8\u5668\u7cfb\u7edf\u7684\u5fae\u5206\u5e73\u5766\u6027\uff0c\u63d0\u51fa\u4e86\u7ea7\u8054\u51c6\u9759\u6001\u53cd\u9988\u7b56\u7565\u548c\u52a8\u6001\u53cd\u9988\u7ebf\u6027\u5316\u65b9\u6cd5\u4e24\u79cd\u63a7\u5236\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u5305\u542b\u6270\u52a8\u6a21\u578b\u548c\u8f93\u5165\u566a\u58f0\u7684\u95ed\u73af\u4eff\u771f\u4ee5\u53ca\u7269\u7406\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u63a7\u5236\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u4eff\u771f\u589e\u76ca\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\u5177\u6709\u9002\u7528\u6027\u3002", "conclusion": "\u5e73\u9762\u6ed1\u5757-\u63a8\u52a8\u5668\u7cfb\u7edf\u5177\u6709\u5fae\u5206\u5e73\u5766\u6027\uff0c\u6240\u63d0\u51fa\u7684\u63a7\u5236\u7b56\u7565\u5728\u5b9e\u9645\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.04220", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04220", "abs": "https://arxiv.org/abs/2511.04220", "authors": ["Alan Seroul", "Th\u00e9o Fagnoni", "In\u00e8s Adnani", "Dana O. Mohamed", "Phillip Kingston"], "title": "Opus: A Quantitative Framework for Workflow Evaluation", "comment": null, "summary": "This paper introduces the Opus Workflow Evaluation Framework, a\nprobabilistic-normative formulation for quantifying Workflow quality and\nefficiency. It integrates notions of correctness, reliability, and cost into a\ncoherent mathematical model that enables direct comparison, scoring, and\noptimization of Workflows. The framework combines the Opus Workflow Reward, a\nprobabilistic function estimating expected performance through success\nlikelihood, resource usage, and output gain, with the Opus Workflow Normative\nPenalties, a set of measurable functions capturing structural and informational\nquality across Cohesion, Coupling, Observability, and Information Hygiene. It\nsupports automated Workflow assessment, ranking, and optimization within modern\nautomation systems such as Opus and can be integrated into Reinforcement\nLearning loops to guide Workflow discovery and refinement. In this paper, we\nintroduce the Opus Workflow Reward model that formalizes Workflow success as a\nprobabilistic expectation over costs and outcomes. We define measurable Opus\nWorkflow Normative Penalties capturing structural, semantic, and signal-related\nproperties of Workflows. Finally, we propose a unified optimization formulation\nfor identifying and ranking optimal Workflows under joint Reward-Penalty\ntrade-offs.", "AI": {"tldr": "Opus\u5de5\u4f5c\u6d41\u8bc4\u4f30\u6846\u67b6\uff1a\u4e00\u4e2a\u6982\u7387-\u89c4\u8303\u5316\u7684\u6570\u5b66\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u5de5\u4f5c\u6d41\u8d28\u91cf\u548c\u6548\u7387\uff0c\u7ed3\u5408\u6b63\u786e\u6027\u3001\u53ef\u9760\u6027\u548c\u6210\u672c\uff0c\u652f\u6301\u81ea\u52a8\u5316\u8bc4\u4f30\u3001\u6392\u540d\u548c\u4f18\u5316\u3002", "motivation": "\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u91cf\u5316\u5de5\u4f5c\u6d41\u8d28\u91cf\uff0c\u652f\u6301\u76f4\u63a5\u6bd4\u8f83\u3001\u8bc4\u5206\u548c\u4f18\u5316\u5de5\u4f5c\u6d41\uff0c\u7279\u522b\u662f\u5728\u73b0\u4ee3\u81ea\u52a8\u5316\u7cfb\u7edf\u4e2d\u3002", "method": "\u7ed3\u5408Opus\u5de5\u4f5c\u6d41\u5956\u52b1\uff08\u6982\u7387\u51fd\u6570\u4f30\u8ba1\u9884\u671f\u6027\u80fd\uff09\u548cOpus\u5de5\u4f5c\u6d41\u89c4\u8303\u60e9\u7f5a\uff08\u6d4b\u91cf\u7ed3\u6784\u4fe1\u606f\u8d28\u91cf\uff09\uff0c\u5f62\u6210\u7edf\u4e00\u7684\u6570\u5b66\u6a21\u578b\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u652f\u6301\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u8bc4\u4f30\u3001\u6392\u540d\u548c\u4f18\u5316\u7684\u6846\u67b6\uff0c\u53ef\u96c6\u6210\u5230\u5f3a\u5316\u5b66\u4e60\u5faa\u73af\u4e2d\u6307\u5bfc\u5de5\u4f5c\u6d41\u53d1\u73b0\u548c\u6539\u8fdb\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5de5\u4f5c\u6d41\u8d28\u91cf\u8bc4\u4f30\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6570\u5b66\u57fa\u7840\uff0c\u652f\u6301\u5728\u73b0\u4ee3\u81ea\u52a8\u5316\u7cfb\u7edf\u4e2d\u8fdb\u884c\u6709\u6548\u7684\u5de5\u4f5c\u6d41\u7ba1\u7406\u3002"}}
{"id": "2511.04664", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04664", "abs": "https://arxiv.org/abs/2511.04664", "authors": ["Phat Nguyen", "Erfan Aasi", "Shiva Sreeram", "Guy Rosman", "Andrew Silva", "Sertac Karaman", "Daniela Rus"], "title": "SAFe-Copilot: Unified Shared Autonomy Framework", "comment": null, "summary": "Autonomous driving systems remain brittle in rare, ambiguous, and\nout-of-distribution scenarios, where human driver succeed through contextual\nreasoning. Shared autonomy has emerged as a promising approach to mitigate such\nfailures by incorporating human input when autonomy is uncertain. However, most\nexisting methods restrict arbitration to low-level trajectories, which\nrepresent only geometric paths and therefore fail to preserve the underlying\ndriving intent. We propose a unified shared autonomy framework that integrates\nhuman input and autonomous planners at a higher level of abstraction. Our\nmethod leverages Vision Language Models (VLMs) to infer driver intent from\nmulti-modal cues -- such as driver actions and environmental context -- and to\nsynthesize coherent strategies that mediate between human and autonomous\ncontrol. We first study the framework in a mock-human setting, where it\nachieves perfect recall alongside high accuracy and precision. A human-subject\nsurvey further shows strong alignment, with participants agreeing with\narbitration outcomes in 92% of cases. Finally, evaluation on the Bench2Drive\nbenchmark demonstrates a substantial reduction in collision rate and\nimprovement in overall performance compared to pure autonomy. Arbitration at\nthe level of semantic, language-based representations emerges as a design\nprinciple for shared autonomy, enabling systems to exercise common-sense\nreasoning and maintain continuity with human intent.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5171\u4eab\u81ea\u52a8\u9a7e\u9a76\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u5c42\u9762\u7684\u4ef2\u88c1\u6765\u6574\u5408\u4eba\u7c7b\u8f93\u5165\u548c\u81ea\u4e3b\u89c4\u5212\uff0c\u5728\u6a21\u7cca\u548c\u7f55\u89c1\u573a\u666f\u4e2d\u6539\u5584\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u7f55\u89c1\u3001\u6a21\u7cca\u548c\u5206\u5e03\u5916\u573a\u666f\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u800c\u4eba\u7c7b\u9a7e\u9a76\u5458\u80fd\u901a\u8fc7\u4e0a\u4e0b\u6587\u63a8\u7406\u6210\u529f\u5e94\u5bf9\u3002\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u4e8e\u4f4e\u5c42\u8f68\u8ff9\u4ef2\u88c1\uff0c\u65e0\u6cd5\u4fdd\u6301\u9a7e\u9a76\u610f\u56fe\u3002", "method": "\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4ece\u591a\u6a21\u6001\u7ebf\u7d22\uff08\u5982\u9a7e\u9a76\u5458\u52a8\u4f5c\u548c\u73af\u5883\u4e0a\u4e0b\u6587\uff09\u63a8\u65ad\u9a7e\u9a76\u610f\u56fe\uff0c\u5728\u8bed\u4e49\u5c42\u9762\u8fdb\u884c\u4eba\u7c7b\u4e0e\u81ea\u4e3b\u63a7\u5236\u4e4b\u95f4\u7684\u7b56\u7565\u5408\u6210\u4e0e\u4ef2\u88c1\u3002", "result": "\u5728\u6a21\u62df\u4eba\u7c7b\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u5b8c\u7f8e\u53ec\u56de\u7387\u548c\u9ad8\u7cbe\u5ea6\uff1b\u4eba\u7c7b\u4e3b\u4f53\u8c03\u67e5\u663e\u793a92%\u7684\u53c2\u4e0e\u8005\u540c\u610f\u4ef2\u88c1\u7ed3\u679c\uff1b\u5728Bench2Drive\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u964d\u4f4e\u78b0\u649e\u7387\u5e76\u63d0\u5347\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "\u57fa\u4e8e\u8bed\u4e49\u3001\u8bed\u8a00\u8868\u793a\u7684\u4ef2\u88c1\u662f\u5171\u4eab\u81ea\u52a8\u9a7e\u9a76\u7684\u5173\u952e\u8bbe\u8ba1\u539f\u5219\uff0c\u4f7f\u7cfb\u7edf\u80fd\u591f\u8fd0\u7528\u5e38\u8bc6\u63a8\u7406\u5e76\u4fdd\u6301\u4e0e\u4eba\u7c7b\u610f\u56fe\u7684\u8fde\u7eed\u6027\u3002"}}
{"id": "2511.04293", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.04293", "abs": "https://arxiv.org/abs/2511.04293", "authors": ["Jovana Kova\u010devi\u0107", "Felix Langner", "Erfan Tajalli-Ardekani", "Marvin Dorn", "Simon Waczowicz", "Ralf Mikut", "J\u00f6rg Matthes", "H\u00fcseyin K. \u00c7akmak", "Veit Hagenmeyer"], "title": "ComEMS4Build: Comfort-Oriented Energy Management System for Residential Buildings using Hydrogen for Seasonal Storage", "comment": "30 pages, 14 figures, Submitted to Applied Energy Journal", "summary": "Integrating flexible loads and storage systems into the residential sector\ncontributes to the alignment of volatile renewable generation with demand.\nBesides batteries serving as a short-term storage solution, residential\nbuildings can benefit from a Hydrogen (H2) storage system, allowing seasonal\nshifting of renewable energy. However, as the initial costs of H2 systems are\nhigh, coupling a Fuel Cell (FC) with a Heat Pump (HP) can contribute to the\nsize reduction of the H2 system. The present study develops a Comfort-Oriented\nEnergy Management System for Residential Buildings (ComEMS4Build) comprising\nPhotovoltaics (PV), Battery Energy Storage System (BESS), and H2 storage, where\nFC and HP are envisioned as complementary technologies. The fuzzy-logic-based\nComEMS4Build is designed and evaluated over a period of 12 weeks in winter for\na family household building in Germany using a semi-synthetic modeling\napproach. The Rule-Based Control (RBC), which serves as a lower benchmark, is a\nscheduler designed to require minimal inputs for operation. The Model\nPredictive Control (MPC) is intended as a cost-optimal benchmark with an ideal\nforecast. The results show that ComEMS4Build, similar to MPC, does not violate\nthe thermal comfort of occupants in 10 out of 12 weeks, while RBC has a\nslightly higher median discomfort of 0.68 Kh. The ComEMS4Build increases the\nweekly electricity costs by 12.06 EUR compared to MPC, while RBC increases the\nweekly costs by 30.14 EUR. The ComEMS4Build improves the Hybrid Energy Storage\nSystem (HESS) utilization and energy exchange with the main grid compared to\nthe RBC. However, when it comes to the FC operation, the RBC has an advantage,\nas it reduces the toggling counts by 3.48% and working hours by 7.59% compared\nto MPC...", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u9762\u5411\u8212\u9002\u5ea6\u7684\u4f4f\u5b85\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u7cfb\u7edf(ComEMS4Build)\uff0c\u8be5\u7cfb\u7edf\u6574\u5408\u5149\u4f0f\u3001\u7535\u6c60\u50a8\u80fd\u548c\u6c22\u50a8\u80fd\uff0c\u901a\u8fc7\u6a21\u7cca\u903b\u8f91\u63a7\u5236\u5b9e\u73b0\u70ed\u8212\u9002\u4e0e\u6210\u672c\u6548\u76ca\u7684\u5e73\u8861\u3002", "motivation": "\u5c06\u67d4\u6027\u8d1f\u8377\u548c\u50a8\u80fd\u7cfb\u7edf\u6574\u5408\u5230\u4f4f\u5b85\u9886\u57df\u6709\u52a9\u4e8e\u534f\u8c03\u6ce2\u52a8\u6027\u53ef\u518d\u751f\u80fd\u6e90\u53d1\u7535\u4e0e\u9700\u6c42\u3002\u6c22\u50a8\u80fd\u7cfb\u7edf\u53ef\u5b9e\u73b0\u5b63\u8282\u6027\u80fd\u91cf\u8f6c\u79fb\uff0c\u4f46\u521d\u59cb\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u667a\u80fd\u7ba1\u7406\u7cfb\u7edf\u6765\u4f18\u5316\u7cfb\u7edf\u89c4\u6a21\u548c\u4f7f\u7528\u6548\u7387\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u7684ComEMS4Build\u7cfb\u7edf\uff0c\u5305\u542b\u5149\u4f0f\u3001\u7535\u6c60\u50a8\u80fd\u548c\u6c22\u50a8\u80fd\uff0c\u5176\u4e2d\u71c3\u6599\u7535\u6c60\u548c\u70ed\u6cf5\u4f5c\u4e3a\u4e92\u8865\u6280\u672f\u3002\u91c7\u7528\u534a\u5408\u6210\u5efa\u6a21\u65b9\u6cd5\u5728\u5fb7\u56fd\u4e00\u4e2a\u5bb6\u5ead\u4f4f\u5b85\u4e2d\u8fdb\u884c12\u5468\u51ac\u5b63\u8bc4\u4f30\uff0c\u5e76\u4e0e\u57fa\u4e8e\u89c4\u5219\u7684\u63a7\u5236(RBC)\u548c\u6a21\u578b\u9884\u6d4b\u63a7\u5236(MPC)\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "ComEMS4Build\u572812\u5468\u4e2d\u670910\u5468\u672a\u8fdd\u53cd\u5c45\u4f4f\u8005\u70ed\u8212\u9002\uff0c\u8868\u73b0\u4e0eMPC\u76f8\u4f3c\uff0c\u800cRBC\u7684\u4e2d\u4f4d\u4e0d\u9002\u611f\u4e3a0.68 Kh\u3002ComEMS4Build\u6bcf\u5468\u7535\u8d39\u6bd4MPC\u589e\u52a012.06\u6b27\u5143\uff0c\u800cRBC\u589e\u52a030.14\u6b27\u5143\u3002ComEMS4Build\u63d0\u9ad8\u4e86\u6df7\u5408\u50a8\u80fd\u7cfb\u7edf\u5229\u7528\u7387\u548c\u4e0e\u4e3b\u7535\u7f51\u7684\u80fd\u91cf\u4ea4\u6362\u6548\u7387\u3002", "conclusion": "ComEMS4Build\u5728\u4fdd\u6301\u70ed\u8212\u9002\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5408\u7406\u7684\u6210\u672c\u63a7\u5236\uff0c\u76f8\u6bd4\u4f20\u7edfRBC\u65b9\u6cd5\u5728\u7cfb\u7edf\u5229\u7528\u7387\u548c\u6210\u672c\u6548\u76ca\u65b9\u9762\u6709\u663e\u8457\u6539\u8fdb\uff0c\u4f46\u5728\u71c3\u6599\u7535\u6c60\u64cd\u4f5c\u65b9\u9762RBC\u5177\u6709\u51cf\u5c11\u5207\u6362\u6b21\u6570\u548c\u5de5\u4f5c\u65f6\u95f4\u7684\u4f18\u52bf\u3002"}}
{"id": "2511.04235", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.04235", "abs": "https://arxiv.org/abs/2511.04235", "authors": ["Zhengru Fang", "Yu Guo", "Jingjing Wang", "Yuang Zhang", "Haonan An", "Yinhai Wang", "Yuguang Fang"], "title": "Shared Spatial Memory Through Predictive Coding", "comment": "We have prepared the open-source code and video demonstration pages:\n  1. Code: github.com/fangzr/SSM-PC 2. Demo: fangzr.github.io/SSM-PC/index.html", "summary": "Sharing and reconstructing a consistent spatial memory is a critical\nchallenge in multi-agent systems, where partial observability and limited\nbandwidth often lead to catastrophic failures in coordination. We introduce a\nmulti-agent predictive coding framework that formulate coordination as the\nminimization of mutual uncertainty among agents. Instantiated as an information\nbottleneck objective, it prompts agents to learn not only who and what to\ncommunicate but also when. At the foundation of this framework lies a\ngrid-cell-like metric as internal spatial coding for self-localization,\nemerging spontaneously from self-supervised motion prediction. Building upon\nthis internal spatial code, agents gradually develop a bandwidth-efficient\ncommunication mechanism and specialized neural populations that encode\npartners' locations: an artificial analogue of hippocampal social place cells\n(SPCs). These social representations are further enacted by a hierarchical\nreinforcement learning policy that actively explores to reduce joint\nuncertainty. On the Memory-Maze benchmark, our approach shows exceptional\nresilience to bandwidth constraints: success degrades gracefully from 73.5% to\n64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast\nbaseline collapses from 67.6% to 28.6%. Our findings establish a theoretically\nprincipled and biologically plausible basis for how complex social\nrepresentations emerge from a unified predictive drive, leading to social\ncollective intelligence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u9884\u6d4b\u7f16\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u667a\u80fd\u4f53\u95f4\u7684\u76f8\u4e92\u4e0d\u786e\u5b9a\u6027\u6765\u534f\u8c03\u884c\u52a8\uff0c\u5728\u5e26\u5bbd\u53d7\u9650\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u7a7a\u95f4\u8bb0\u5fc6\u5171\u4eab\u548c\u534f\u8c03\u3002", "motivation": "\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\uff0c\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u548c\u6709\u9650\u5e26\u5bbd\u5e38\u5e38\u5bfc\u81f4\u534f\u8c03\u5931\u8d25\uff0c\u9700\u8981\u89e3\u51b3\u4e00\u81f4\u7a7a\u95f4\u8bb0\u5fc6\u5171\u4eab\u7684\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u76ee\u6807\u7684\u591a\u667a\u80fd\u4f53\u9884\u6d4b\u7f16\u7801\u6846\u67b6\uff0c\u5305\u62ec\u81ea\u76d1\u7763\u8fd0\u52a8\u9884\u6d4b\u4ea7\u751f\u7684\u7f51\u683c\u7ec6\u80de\u72b6\u7a7a\u95f4\u7f16\u7801\u3001\u5e26\u5bbd\u9ad8\u6548\u901a\u4fe1\u673a\u5236\u3001\u7c7b\u4f3c\u6d77\u9a6c\u4f53\u793e\u4ea4\u4f4d\u7f6e\u7ec6\u80de\u7684\u795e\u7ecf\u7fa4\u4f53\uff0c\u4ee5\u53ca\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5728Memory-Maze\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u65b9\u6cd5\u5728\u5e26\u5bbd\u4ece128\u4f4d/\u6b65\u964d\u81f34\u4f4d/\u6b65\u65f6\uff0c\u6210\u529f\u7387\u4ece73.5%\u4f18\u96c5\u4e0b\u964d\u81f364.4%\uff0c\u800c\u5168\u5e7f\u64ad\u57fa\u7ebf\u4ece67.6%\u5d29\u6e83\u81f328.6%\u3002", "conclusion": "\u4e3a\u590d\u6742\u793e\u4ea4\u8868\u5f81\u5982\u4f55\u4ece\u7edf\u4e00\u7684\u9884\u6d4b\u9a71\u52a8\u4e2d\u6d8c\u73b0\u5efa\u7acb\u4e86\u7406\u8bba\u539f\u5219\u548c\u751f\u7269\u5b66\u4e0a\u5408\u7406\u7684\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\u793e\u4ea4\u96c6\u4f53\u667a\u80fd\u3002"}}
{"id": "2511.04665", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04665", "abs": "https://arxiv.org/abs/2511.04665", "authors": ["Kaifeng Zhang", "Shuo Sha", "Hanxiao Jiang", "Matthew Loper", "Hyunjong Song", "Guangyan Cai", "Zhuo Xu", "Xiaochen Hu", "Changxi Zheng", "Yunzhu Li"], "title": "Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions", "comment": "Website: https://real2sim-eval.github.io/", "summary": "Robotic manipulation policies are advancing rapidly, but their direct\nevaluation in the real world remains costly, time-consuming, and difficult to\nreproduce, particularly for tasks involving deformable objects. Simulation\nprovides a scalable and systematic alternative, yet existing simulators often\nfail to capture the coupled visual and physical complexity of soft-body\ninteractions. We present a real-to-sim policy evaluation framework that\nconstructs soft-body digital twins from real-world videos and renders robots,\nobjects, and environments with photorealistic fidelity using 3D Gaussian\nSplatting. We validate our approach on representative deformable manipulation\ntasks, including plush toy packing, rope routing, and T-block pushing,\ndemonstrating that simulated rollouts correlate strongly with real-world\nexecution performance and reveal key behavioral patterns of learned policies.\nOur results suggest that combining physics-informed reconstruction with\nhigh-quality rendering enables reproducible, scalable, and accurate evaluation\nof robotic manipulation policies. Website: https://real2sim-eval.github.io/", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u89c6\u9891\u6784\u5efa\u8f6f\u4f53\u6570\u5b57\u5b6a\u751f\u7684\u771f\u5b9e\u5230\u4eff\u771f\u7b56\u7565\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u75283D\u9ad8\u65af\u6cfc\u6e85\u5b9e\u73b0\u903c\u771f\u6e32\u67d3\uff0c\u7528\u4e8e\u8bc4\u4f30\u673a\u5668\u4eba\u64cd\u4f5c\u7b56\u7565\u3002", "motivation": "\u771f\u5b9e\u4e16\u754c\u4e2d\u76f4\u63a5\u8bc4\u4f30\u673a\u5668\u4eba\u64cd\u4f5c\u7b56\u7565\u6210\u672c\u9ad8\u3001\u8017\u65f6\u957f\u4e14\u96be\u4ee5\u590d\u73b0\uff0c\u7279\u522b\u662f\u6d89\u53ca\u53ef\u53d8\u5f62\u7269\u4f53\u7684\u4efb\u52a1\u3002\u73b0\u6709\u6a21\u62df\u5668\u96be\u4ee5\u6355\u6349\u8f6f\u4f53\u4ea4\u4e92\u7684\u89c6\u89c9\u548c\u7269\u7406\u590d\u6742\u6027\u3002", "method": "\u4ece\u771f\u5b9e\u4e16\u754c\u89c6\u9891\u6784\u5efa\u8f6f\u4f53\u6570\u5b57\u5b6a\u751f\uff0c\u4f7f\u75283D\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\u6e32\u67d3\u673a\u5668\u4eba\u3001\u7269\u4f53\u548c\u73af\u5883\uff0c\u5b9e\u73b0\u7167\u7247\u7ea7\u771f\u5b9e\u611f\u3002", "result": "\u5728\u4ee3\u8868\u6027\u53ef\u53d8\u5f62\u64cd\u4f5c\u4efb\u52a1\uff08\u6bdb\u7ed2\u73a9\u5177\u6253\u5305\u3001\u7ef3\u5b50\u5e03\u7ebf\u3001T\u5f62\u5757\u63a8\u52a8\uff09\u4e0a\u9a8c\u8bc1\uff0c\u6a21\u62df\u8fd0\u884c\u4e0e\u73b0\u5b9e\u6267\u884c\u6027\u80fd\u9ad8\u5ea6\u76f8\u5173\uff0c\u5e76\u80fd\u63ed\u793a\u5b66\u4e60\u7b56\u7565\u7684\u5173\u952e\u884c\u4e3a\u6a21\u5f0f\u3002", "conclusion": "\u5c06\u7269\u7406\u4fe1\u606f\u91cd\u5efa\u4e0e\u9ad8\u8d28\u91cf\u6e32\u67d3\u76f8\u7ed3\u5408\uff0c\u80fd\u591f\u5b9e\u73b0\u53ef\u91cd\u590d\u3001\u53ef\u6269\u5c55\u4e14\u51c6\u786e\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u7b56\u7565\u8bc4\u4f30\u3002"}}
{"id": "2511.04330", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.04330", "abs": "https://arxiv.org/abs/2511.04330", "authors": ["Christian Portilla", "Arviandy G Aribowo", "Ramachandran Anantharaman", "C\u00e9sar A G\u00f3mez-P\u00e9rez", "Leyla \u00d6zkan"], "title": "Data-Driven Modeling of Photosynthesis Regulation Under Oscillating Light Condition - Part I: In-Silico Exploration", "comment": "10 pages, 14 figures", "summary": "This paper explores the application of data-driven system identification\ntechniques in the frequency domain to obtain simplified, control-oriented\nmodels of photosynthesis regulation under oscillating light conditions.\nIn-silico datasets are generated using simulations of the physics-based Basic\nDREAM Model (BDM) Funete et al.[2024], with light intensity signals --\ncomprising DC (static) and AC (modulated) components as input and chlorophyll\nfluorescence (ChlF) as output. Using these data, the Best Linear Approximation\n(BLA) method is employed to estimate second-order linear time-invariant (LTI)\ntransfer function models across different operating conditions defined by DC\nlevels and modulation frequencies of light intensity. Building on these local\nmodels, a Linear Parameter-Varying (LPV) representation is constructed, in\nwhich the scheduling parameter is defined by the DC values of the light\nintensity, providing a compact state-space representation of the system\ndynamics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5e94\u7528\u9891\u57df\u6570\u636e\u9a71\u52a8\u7cfb\u7edf\u8fa8\u8bc6\u6280\u672f\uff0c\u5728\u632f\u8361\u5149\u7167\u6761\u4ef6\u4e0b\u5efa\u7acb\u7b80\u5316\u7684\u5149\u5408\u4f5c\u7528\u8c03\u63a7\u63a7\u5236\u5bfc\u5411\u6a21\u578b\uff0c\u901a\u8fc7Basic DREAM Model\u751f\u6210\u4eff\u771f\u6570\u636e\uff0c\u4f7f\u7528BLA\u65b9\u6cd5\u4f30\u8ba1\u4e8c\u9636LTI\u4f20\u9012\u51fd\u6570\u6a21\u578b\uff0c\u5e76\u6784\u5efa\u57fa\u4e8e\u5149\u7167\u5f3a\u5ea6DC\u503c\u7684LPV\u8868\u793a\u3002", "motivation": "\u63a2\u7d22\u5728\u632f\u8361\u5149\u7167\u6761\u4ef6\u4e0b\u5149\u5408\u4f5c\u7528\u8c03\u63a7\u7684\u7b80\u5316\u63a7\u5236\u5bfc\u5411\u6a21\u578b\uff0c\u4e3a\u5149\u5408\u4f5c\u7528\u7cfb\u7edf\u7684\u63a7\u5236\u5e94\u7528\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u4f7f\u7528Basic DREAM Model\u751f\u6210\u4eff\u771f\u6570\u636e\uff0c\u4ee5\u5149\u7167\u5f3a\u5ea6\u4fe1\u53f7\uff08\u5305\u542bDC\u548cAC\u5206\u91cf\uff09\u4e3a\u8f93\u5165\uff0c\u53f6\u7eff\u7d20\u8367\u5149\u4e3a\u8f93\u51fa\uff0c\u5e94\u7528BLA\u65b9\u6cd5\u4f30\u8ba1\u4e8c\u9636LTI\u4f20\u9012\u51fd\u6570\u6a21\u578b\uff0c\u5e76\u6784\u5efa\u57fa\u4e8e\u5149\u7167\u5f3a\u5ea6DC\u503c\u7684LPV\u72b6\u6001\u7a7a\u95f4\u8868\u793a\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86\u5728\u4e0d\u540c\u64cd\u4f5c\u6761\u4ef6\u4e0b\uff08\u7531\u5149\u7167\u5f3a\u5ea6\u7684DC\u6c34\u5e73\u548c\u8c03\u5236\u9891\u7387\u5b9a\u4e49\uff09\u7684\u5c40\u90e8\u7ebf\u6027\u6a21\u578b\uff0c\u5e76\u6784\u5efa\u4e86\u7edf\u4e00\u7684LPV\u7cfb\u7edf\u8868\u793a\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u7684\u9891\u57df\u7cfb\u7edf\u8fa8\u8bc6\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u83b7\u5f97\u5149\u5408\u4f5c\u7528\u8c03\u63a7\u7684\u7b80\u5316\u63a7\u5236\u5bfc\u5411\u6a21\u578b\uff0cLPV\u8868\u793a\u63d0\u4f9b\u4e86\u7cfb\u7edf\u52a8\u529b\u5b66\u7684\u7d27\u51d1\u72b6\u6001\u7a7a\u95f4\u63cf\u8ff0\u3002"}}
{"id": "2511.04285", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04285", "abs": "https://arxiv.org/abs/2511.04285", "authors": ["Zeng Zhiyuan", "Jiashuo Liu", "Zhangyue Yin", "Ge Zhang", "Wenhao Huang", "Xipeng Qiu"], "title": "RLoop: An Self-Improving Framework for Reinforcement Learning with Iterative Policy Initialization", "comment": null, "summary": "While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for\ntraining large reasoning models, its training dynamics harbor a critical\nchallenge: RL overfitting, where models gain training rewards but lose\ngeneralization. Our analysis reveals this is driven by policy\nover-specialization and catastrophic forgetting of diverse solutions generated\nduring training. Standard optimization discards this valuable inter-step policy\ndiversity. To address this, we introduce RLoop, a self-improving framework\nbuilt on iterative policy initialization. RLoop transforms the standard\ntraining process into a virtuous cycle: it first uses RL to explore the\nsolution space from a given policy, then filters the successful trajectories to\ncreate an expert dataset. This dataset is used via Rejection-sampling\nFine-Tuning (RFT) to refine the initial policy, creating a superior starting\npoint for the next iteration. This loop of exploration and exploitation via\niterative re-initialization effectively converts transient policy variations\ninto robust performance gains. Our experiments show RLoop mitigates forgetting\nand substantially improves generalization, boosting average accuracy by 9% and\npass@32 by over 15% compared to vanilla RL.", "AI": {"tldr": "RLoop\u662f\u4e00\u4e2a\u81ea\u6539\u8fdb\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u7b56\u7565\u521d\u59cb\u5316\u89e3\u51b3RL\u8bad\u7ec3\u4e2d\u7684\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5c06\u63a2\u7d22\u548c\u5229\u7528\u8f6c\u5316\u4e3a\u7a33\u5065\u6027\u80fd\u63d0\u5347", "motivation": "RLVR\u8bad\u7ec3\u4e2d\u5b58\u5728RL\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u6a21\u578b\u83b7\u5f97\u8bad\u7ec3\u5956\u52b1\u4f46\u5931\u53bb\u6cdb\u5316\u80fd\u529b\uff0c\u8fd9\u7531\u7b56\u7565\u8fc7\u4e13\u4e1a\u5316\u548c\u707e\u96be\u6027\u9057\u5fd8\u9a71\u52a8", "method": "RLoop\u901a\u8fc7\u8fed\u4ee3\u7b56\u7565\u521d\u59cb\u5316\u6784\u5efa\uff1a\u5148\u7528RL\u4ece\u7ed9\u5b9a\u7b56\u7565\u63a2\u7d22\u89e3\u7a7a\u95f4\uff0c\u8fc7\u6ee4\u6210\u529f\u8f68\u8ff9\u521b\u5efa\u4e13\u5bb6\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u5fae\u8c03\u6765\u7cbe\u70bc\u521d\u59cb\u7b56\u7565\uff0c\u4e3a\u4e0b\u4e00\u6b21\u8fed\u4ee3\u521b\u5efa\u66f4\u597d\u7684\u8d77\u70b9", "result": "RLoop\u663e\u8457\u6539\u5584\u6cdb\u5316\u80fd\u529b\uff0c\u5e73\u5747\u51c6\u786e\u7387\u63d0\u53479%\uff0cpass@32\u63d0\u5347\u8d85\u8fc715%", "conclusion": "RLoop\u901a\u8fc7\u5c06\u77ac\u6001\u7b56\u7565\u53d8\u5316\u8f6c\u5316\u4e3a\u7a33\u5065\u6027\u80fd\u589e\u76ca\uff0c\u6709\u6548\u7f13\u89e3\u9057\u5fd8\u5e76\u63d0\u5347\u6cdb\u5316"}}
{"id": "2511.04671", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04671", "abs": "https://arxiv.org/abs/2511.04671", "authors": ["Maximus A. Pace", "Prithwish Dan", "Chuanruo Ning", "Atiksh Bhardwaj", "Audrey Du", "Edward W. Duan", "Wei-Chiu Ma", "Kushal Kedia"], "title": "X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations", "comment": null, "summary": "Human videos can be recorded quickly and at scale, making them an appealing\nsource of training data for robot learning. However, humans and robots differ\nfundamentally in embodiment, resulting in mismatched action execution. Direct\nkinematic retargeting of human hand motion can therefore produce actions that\nare physically infeasible for robots. Despite these low-level differences,\nhuman demonstrations provide valuable motion cues about how to manipulate and\ninteract with objects. Our key idea is to exploit the forward diffusion\nprocess: as noise is added to actions, low-level execution differences fade\nwhile high-level task guidance is preserved. We present X-Diffusion, a\nprincipled framework for training diffusion policies that maximally leverages\nhuman data without learning dynamically infeasible motions. X-Diffusion first\ntrains a classifier to predict whether a noisy action is executed by a human or\nrobot. Then, a human action is incorporated into policy training only after\nadding sufficient noise such that the classifier cannot discern its embodiment.\nActions consistent with robot execution supervise fine-grained denoising at low\nnoise levels, while mismatched human actions provide only coarse guidance at\nhigher noise levels. Our experiments show that naive co-training under\nexecution mismatches degrades policy performance, while X-Diffusion\nconsistently improves it. Across five manipulation tasks, X-Diffusion achieves\na 16% higher average success rate than the best baseline. The project website\nis available at https://portal-cornell.github.io/X-Diffusion/.", "AI": {"tldr": "X-Diffusion\u662f\u4e00\u4e2a\u5229\u7528\u4eba\u7c7b\u89c6\u9891\u8bad\u7ec3\u673a\u5668\u4eba\u7b56\u7565\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6269\u6563\u8fc7\u7a0b\u5904\u7406\u52a8\u4f5c\u6267\u884c\u5dee\u5f02\uff0c\u5728\u4fdd\u6301\u9ad8\u5c42\u4efb\u52a1\u6307\u5bfc\u7684\u540c\u65f6\u907f\u514d\u5b66\u4e60\u4e0d\u53ef\u884c\u7684\u673a\u5668\u4eba\u52a8\u4f5c\u3002", "motivation": "\u4eba\u7c7b\u89c6\u9891\u6570\u636e\u4e30\u5bcc\u6613\u5f97\uff0c\u4f46\u4eba\u7c7b\u548c\u673a\u5668\u4eba\u7684\u52a8\u4f5c\u6267\u884c\u5b58\u5728\u6839\u672c\u5dee\u5f02\uff0c\u76f4\u63a5\u8fd0\u52a8\u91cd\u5b9a\u5411\u4f1a\u4ea7\u751f\u7269\u7406\u4e0a\u4e0d\u53ef\u884c\u7684\u52a8\u4f5c\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u65e2\u80fd\u5229\u7528\u4eba\u7c7b\u6570\u636e\u7684\u6709\u4ef7\u503c\u8fd0\u52a8\u7ebf\u7d22\uff0c\u53c8\u907f\u514d\u5b66\u4e60\u4e0d\u53ef\u884c\u7684\u4f4e\u5c42\u52a8\u4f5c\u3002", "method": "X-Diffusion\u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u5668\u9884\u6d4b\u566a\u58f0\u52a8\u4f5c\u662f\u7531\u4eba\u7c7b\u8fd8\u662f\u673a\u5668\u4eba\u6267\u884c\uff0c\u7136\u540e\u5728\u7b56\u7565\u8bad\u7ec3\u4e2d\u53ea\u4f7f\u7528\u6dfb\u52a0\u8db3\u591f\u566a\u58f0\u7684\u4eba\u7c7b\u52a8\u4f5c\uff08\u6b64\u65f6\u5206\u7c7b\u5668\u65e0\u6cd5\u533a\u5206\u6267\u884c\u4e3b\u4f53\uff09\u3002\u4e0e\u673a\u5668\u4eba\u6267\u884c\u4e00\u81f4\u7684\u52a8\u4f5c\u5728\u4f4e\u566a\u58f0\u6c34\u5e73\u4e0b\u76d1\u7763\u7cbe\u7ec6\u53bb\u566a\uff0c\u4e0d\u5339\u914d\u7684\u4eba\u7c7b\u52a8\u4f5c\u4ec5\u5728\u9ad8\u566a\u58f0\u6c34\u5e73\u4e0b\u63d0\u4f9b\u7c97\u7565\u6307\u5bfc\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u52a8\u4f5c\u6267\u884c\u4e0d\u5339\u914d\u7684\u60c5\u51b5\u4e0b\uff0c\u7b80\u5355\u7684\u5171\u540c\u8bad\u7ec3\u4f1a\u964d\u4f4e\u7b56\u7565\u6027\u80fd\uff0c\u800cX-Diffusion\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002\u5728\u4e94\u4e2a\u64cd\u4f5c\u4efb\u52a1\u4e2d\uff0cX-Diffusion\u6bd4\u6700\u4f73\u57fa\u7ebf\u5b9e\u73b0\u4e8616%\u7684\u5e73\u5747\u6210\u529f\u7387\u63d0\u5347\u3002", "conclusion": "X-Diffusion\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u6846\u67b6\uff0c\u80fd\u591f\u6700\u5927\u5316\u5229\u7528\u4eba\u7c7b\u6570\u636e\u8bad\u7ec3\u6269\u6563\u7b56\u7565\uff0c\u540c\u65f6\u907f\u514d\u5b66\u4e60\u52a8\u6001\u4e0d\u53ef\u884c\u7684\u52a8\u4f5c\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4eba\u7c7b-\u673a\u5668\u4eba\u52a8\u4f5c\u6267\u884c\u5dee\u5f02\u7684\u95ee\u9898\u3002"}}
{"id": "2511.04370", "categories": ["eess.SY", "cs.FL", "cs.SE", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.04370", "abs": "https://arxiv.org/abs/2511.04370", "authors": ["Dennis Hendriks", "Michel Reniers", "Wan Fokkink", "Wytse Oortwijn"], "title": "Overview and Performance Evaluation of Supervisory Controller Synthesis with Eclipse ESCET v4.0", "comment": null, "summary": "Supervisory controllers control cyber-physical systems to ensure their\ncorrect and safe operation. Synthesis-based engineering (SBE) is an approach to\nlargely automate their design and implementation. SBE combines model-based\nengineering with computer-aided design, allowing engineers to focus on 'what'\nthe system should do (the requirements) rather than 'how' it should do it\n(design and implementation). In the Eclipse Supervisory Control Engineering\nToolkit (ESCET) open-source project, a community of users, researchers, and\ntool vendors jointly develop a toolkit to support the entire SBE process,\nparticularly through the CIF modeling language and tools. In this paper, we\nfirst provide a description of CIF's symbolic supervisory controller synthesis\nalgorithm, and thereby include aspects that are often omitted in the\nliterature, but are of great practical relevance, such as the prevention of\nruntime errors, handling different types of requirements, and supporting input\nvariables (to connect to external inputs). Secondly, we introduce and describe\nCIF's benchmark models, a collection of 23 freely available industrial and\nacademic models of various sizes and complexities. Thirdly, we describe recent\nimprovements between ESCET versions v0.8 (December 2022) and v4.0 (June 2024)\nthat affect synthesis performance, evaluate them on our benchmark models, and\nshow the current practical synthesis performance of CIF. Fourthly, we briefly\nlook at multi-level synthesis, a non-monolithic synthesis approach, evaluate\nits gains, and show that while it can help to further improve synthesis\nperformance, further performance improvements are still needed to synthesize\ncomplex models.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86ESCET\u5f00\u6e90\u9879\u76ee\u4e2dCIF\u5efa\u6a21\u8bed\u8a00\u7684\u7b26\u53f7\u5316\u76d1\u7763\u63a7\u5236\u5668\u7efc\u5408\u7b97\u6cd5\uff0c\u5305\u62ec\u9632\u6b62\u8fd0\u884c\u65f6\u9519\u8bef\u3001\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u9700\u6c42\u548c\u8f93\u5165\u53d8\u91cf\u7b49\u5b9e\u7528\u65b9\u9762\uff0c\u5e76\u63d0\u51fa\u4e86\u5305\u542b23\u4e2a\u5de5\u4e1a\u4e0e\u5b66\u672f\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u8bc4\u4f30\u4e86\u4ecev0.8\u5230v4.0\u7248\u672c\u7684\u6027\u80fd\u6539\u8fdb\u3002", "motivation": "\u76d1\u7763\u63a7\u5236\u5668\u786e\u4fdd\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u7684\u6b63\u786e\u5b89\u5168\u8fd0\u884c\uff0c\u7efc\u5408\u5316\u5de5\u7a0b\u65b9\u6cd5\u65e8\u5728\u81ea\u52a8\u5316\u8bbe\u8ba1\u548c\u5b9e\u73b0\u8fc7\u7a0b\uff0c\u8ba9\u5de5\u7a0b\u5e08\u4e13\u6ce8\u4e8e\u7cfb\u7edf\u9700\u6c42\u800c\u975e\u5b9e\u73b0\u7ec6\u8282\u3002", "method": "\u4f7f\u7528CIF\u5efa\u6a21\u8bed\u8a00\u7684\u7b26\u53f7\u5316\u76d1\u7763\u63a7\u5236\u5668\u7efc\u5408\u7b97\u6cd5\uff0c\u5305\u542b\u9632\u6b62\u8fd0\u884c\u65f6\u9519\u8bef\u3001\u5904\u7406\u4e0d\u540c\u9700\u6c42\u7c7b\u578b\u548c\u652f\u6301\u8f93\u5165\u53d8\u91cf\u7b49\u5b9e\u7528\u7279\u6027\uff1b\u91c7\u7528\u591a\u7ea7\u7efc\u5408\u65b9\u6cd5\u8fdb\u884c\u975e\u6574\u4f53\u5316\u7efc\u5408\uff1b\u5efa\u7acb23\u4e2a\u57fa\u51c6\u6a21\u578b\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\u3002", "result": "ESCET\u4ecev0.8\u5230v4.0\u7248\u672c\u5728\u7efc\u5408\u6027\u80fd\u4e0a\u6709\u663e\u8457\u6539\u8fdb\uff0c\u591a\u7ea7\u7efc\u5408\u65b9\u6cd5\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u5bf9\u4e8e\u590d\u6742\u6a21\u578b\u7684\u7efc\u5408\u4ecd\u9700\u66f4\u591a\u6027\u80fd\u4f18\u5316\u3002", "conclusion": "CIF\u7684\u7efc\u5408\u7b97\u6cd5\u5728\u5b9e\u7528\u6027\u548c\u6027\u80fd\u65b9\u9762\u90fd\u6709\u91cd\u8981\u8fdb\u5c55\uff0c\u591a\u7ea7\u7efc\u5408\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6027\u80fd\u63d0\u5347\u6f5c\u529b\uff0c\u4f46\u5904\u7406\u590d\u6742\u6a21\u578b\u65f6\u4ecd\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u7efc\u5408\u6027\u80fd\u3002"}}
{"id": "2511.04307", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04307", "abs": "https://arxiv.org/abs/2511.04307", "authors": ["Jian Mu", "Chaoyun Zhang", "Chiming Ni", "Lu Wang", "Bo Qiao", "Kartik Mathur", "Qianhui Wu", "Yuhang Xie", "Xiaojun Ma", "Mengyu Zhou", "Si Qin", "Liqun Li", "Yu Kang", "Minghua Ma", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang"], "title": "GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents", "comment": null, "summary": "We introduce GUI-360$^\\circ$, a large-scale, comprehensive dataset and\nbenchmark suite designed to advance computer-using agents (CUAs). CUAs present\nunique challenges and is constrained by three persistent gaps: a scarcity of\nreal-world CUA tasks, the lack of automated collection-and-annotation pipelines\nfor multi-modal trajectories, and the absence of a unified benchmark that\njointly evaluates GUI grounding, screen parsing, and action prediction.\n  GUI-360$^\\circ$ addresses these gaps with an LLM-augmented, largely automated\npipeline for query sourcing, environment-template construction, task\ninstantiation, batched execution, and LLM-driven quality filtering. The\nreleased corpus contains over 1.2M executed action steps across thousands of\ntrajectories in popular Windows office applications, and includes\nfull-resolution screenshots, accessibility metadata when available,\ninstantiated goals, intermediate reasoning traces, and both successful and\nfailed action trajectories. The dataset supports three canonical tasks, GUI\ngrounding, screen parsing, and action prediction, and a hybrid GUI+API action\nspace that reflects modern agent designs. Benchmarking state-of-the-art\nvision--language models on GUI-360$^\\circ$ reveals substantial out-of-the-box\nshortcomings in grounding and action prediction; supervised fine-tuning and\nreinforcement learning yield significant gains but do not close the gap to\nhuman-level reliability. We release GUI-360$^\\circ$ and accompanying code to\nfacilitate reproducible research and accelerate progress on robust desktop\nCUAs.\n  The full dataset has been made public on\nhttps://huggingface.co/datasets/vyokky/GUI-360.", "AI": {"tldr": "GUI-360\u00b0\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u57fa\u51c6\u5957\u4ef6\uff0c\u7528\u4e8e\u63a8\u8fdb\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\uff08CUAs\uff09\u7684\u7814\u7a76\uff0c\u5305\u542b120\u4e07+\u6267\u884c\u52a8\u4f5c\u6b65\u9aa4\uff0c\u652f\u6301GUI\u5b9a\u4f4d\u3001\u5c4f\u5e55\u89e3\u6790\u548c\u52a8\u4f5c\u9884\u6d4b\u4e09\u4e2a\u6838\u5fc3\u4efb\u52a1\u3002", "motivation": "\u89e3\u51b3\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7814\u7a76\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u771f\u5b9e\u4e16\u754cCUA\u4efb\u52a1\u7a00\u7f3a\u3001\u7f3a\u4e4f\u591a\u6a21\u6001\u8f68\u8ff9\u7684\u81ea\u52a8\u6536\u96c6\u548c\u6807\u6ce8\u6d41\u7a0b\u3001\u4ee5\u53ca\u7f3a\u5c11\u7edf\u4e00\u8bc4\u4f30GUI\u5b9a\u4f4d\u3001\u5c4f\u5e55\u89e3\u6790\u548c\u52a8\u4f5c\u9884\u6d4b\u7684\u57fa\u51c6\u3002", "method": "\u4f7f\u7528LLM\u589e\u5f3a\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\uff0c\u5305\u62ec\u67e5\u8be2\u6765\u6e90\u3001\u73af\u5883\u6a21\u677f\u6784\u5efa\u3001\u4efb\u52a1\u5b9e\u4f8b\u5316\u3001\u6279\u91cf\u6267\u884c\u548cLLM\u9a71\u52a8\u7684\u8d28\u91cf\u8fc7\u6ee4\uff0c\u5728Windows\u529e\u516c\u5e94\u7528\u4e2d\u6536\u96c6\u6570\u5343\u6761\u8f68\u8ff9\u6570\u636e\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u73b0\u6709\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728GUI\u5b9a\u4f4d\u548c\u52a8\u4f5c\u9884\u6d4b\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u5e26\u6765\u663e\u8457\u6539\u8fdb\u4f46\u4ecd\u672a\u8fbe\u5230\u4eba\u7c7b\u53ef\u9760\u6027\u6c34\u5e73\u3002", "conclusion": "GUI-360\u00b0\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5df2\u516c\u5f00\u53d1\u5e03\uff0c\u65e8\u5728\u4fc3\u8fdb\u53ef\u91cd\u590d\u7814\u7a76\u5e76\u52a0\u901f\u7a33\u5065\u684c\u9762CUAs\u7684\u8fdb\u5c55\u3002"}}
{"id": "2511.04679", "categories": ["cs.RO", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.04679", "abs": "https://arxiv.org/abs/2511.04679", "authors": ["Qingzhou Lu", "Yao Feng", "Baiyu Shi", "Michael Piseno", "Zhenan Bao", "C. Karen Liu"], "title": "GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction", "comment": "Home page: https://gentle-humanoid.axell.top", "summary": "Humanoid robots are expected to operate in human-centered environments where\nsafe and natural physical interaction is essential. However, most recent\nreinforcement learning (RL) policies emphasize rigid tracking and suppress\nexternal forces. Existing impedance-augmented approaches are typically\nrestricted to base or end-effector control and focus on resisting extreme\nforces rather than enabling compliance. We introduce GentleHumanoid, a\nframework that integrates impedance control into a whole-body motion tracking\npolicy to achieve upper-body compliance. At its core is a unified spring-based\nformulation that models both resistive contacts (restoring forces when pressing\nagainst surfaces) and guiding contacts (pushes or pulls sampled from human\nmotion data). This formulation ensures kinematically consistent forces across\nthe shoulder, elbow, and wrist, while exposing the policy to diverse\ninteraction scenarios. Safety is further supported through task-adjustable\nforce thresholds. We evaluate our approach in both simulation and on the\nUnitree G1 humanoid across tasks requiring different levels of compliance,\nincluding gentle hugging, sit-to-stand assistance, and safe object\nmanipulation. Compared to baselines, our policy consistently reduces peak\ncontact forces while maintaining task success, resulting in smoother and more\nnatural interactions. These results highlight a step toward humanoid robots\nthat can safely and effectively collaborate with humans and handle objects in\nreal-world environments.", "AI": {"tldr": "GentleHumanoid\u6846\u67b6\u5c06\u963b\u6297\u63a7\u5236\u96c6\u6210\u5230\u5168\u8eab\u8fd0\u52a8\u8ddf\u8e2a\u7b56\u7565\u4e2d\uff0c\u5b9e\u73b0\u4e0a\u534a\u8eab\u67d4\u987a\u6027\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u5f39\u7c27\u6a21\u578b\u5904\u7406\u963b\u529b\u548c\u5f15\u5bfc\u63a5\u89e6\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6210\u529f\u7387\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u63a5\u89e6\u529b\u3002", "motivation": "\u4eba\u5f62\u673a\u5668\u4eba\u9700\u8981\u5728\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u73af\u5883\u4e2d\u5b89\u5168\u81ea\u7136\u5730\u7269\u7406\u4ea4\u4e92\uff0c\u4f46\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u8fc7\u4e8e\u5f3a\u8c03\u521a\u6027\u8ddf\u8e2a\u800c\u6291\u5236\u5916\u529b\uff0c\u73b0\u6709\u963b\u6297\u63a7\u5236\u65b9\u6cd5\u5c40\u9650\u4e8e\u57fa\u5ea7\u6216\u672b\u7aef\u63a7\u5236\u4e14\u4e3b\u8981\u5173\u6ce8\u62b5\u6297\u6781\u7aef\u529b\u800c\u975e\u5b9e\u73b0\u67d4\u987a\u6027\u3002", "method": "\u63d0\u51faGentleHumanoid\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u7edf\u4e00\u7684\u5f39\u7c27\u6a21\u578b\uff0c\u540c\u65f6\u5efa\u6a21\u963b\u529b\u63a5\u89e6\uff08\u6309\u538b\u8868\u9762\u65f6\u7684\u6062\u590d\u529b\uff09\u548c\u5f15\u5bfc\u63a5\u89e6\uff08\u4ece\u4eba\u7c7b\u8fd0\u52a8\u6570\u636e\u91c7\u6837\u7684\u63a8\u62c9\u52a8\u4f5c\uff09\uff0c\u786e\u4fdd\u80a9\u3001\u8098\u3001\u8155\u7684\u52a8\u529b\u5b66\u4e00\u81f4\u6027\u529b\uff0c\u5e76\u901a\u8fc7\u4efb\u52a1\u53ef\u8c03\u529b\u9608\u503c\u4fdd\u8bc1\u5b89\u5168\u3002", "result": "\u5728\u4eff\u771f\u548cUnitree G1\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u8bc4\u4f30\uff0c\u5728\u9700\u8981\u4e0d\u540c\u67d4\u987a\u6027\u6c34\u5e73\u7684\u4efb\u52a1\u4e2d\uff08\u8f7b\u67d4\u62e5\u62b1\u3001\u5750\u7ad9\u8f85\u52a9\u3001\u5b89\u5168\u7269\u4f53\u64cd\u4f5c\uff09\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8be5\u7b56\u7565\u5728\u4fdd\u6301\u4efb\u52a1\u6210\u529f\u7387\u7684\u540c\u65f6\u6301\u7eed\u964d\u4f4e\u5cf0\u503c\u63a5\u89e6\u529b\uff0c\u5b9e\u73b0\u66f4\u5e73\u6ed1\u81ea\u7136\u7684\u4ea4\u4e92\u3002", "conclusion": "\u8be5\u7814\u7a76\u5411\u80fd\u591f\u5b89\u5168\u6709\u6548\u4e0e\u4eba\u7c7b\u534f\u4f5c\u5e76\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u5904\u7406\u7269\u4f53\u7684\u4eba\u5f62\u673a\u5668\u4eba\u8fc8\u51fa\u4e86\u4e00\u6b65\uff0c\u5c55\u793a\u4e86\u67d4\u987a\u4ea4\u4e92\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.04437", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.04437", "abs": "https://arxiv.org/abs/2511.04437", "authors": ["Patrik Val\u00e1bek", "Michaela Horv\u00e1thov\u00e1", "Martin Klau\u010do"], "title": "Deep Koopman Economic Model Predictive Control of a Pasteurisation Unit", "comment": null, "summary": "This paper presents a deep Koopman-based Economic Model Predictive Control\n(EMPC) for efficient operation of a laboratory-scale pasteurization unit (PU).\nThe method uses Koopman operator theory to transform the complex, nonlinear\nsystem dynamics into a linear representation, enabling the application of\nconvex optimization while representing the complex PU accurately. The deep\nKoopman model utilizes neural networks to learn the linear dynamics from\nexperimental data, achieving a 45% improvement in open-loop prediction accuracy\nover conventional N4SID subspace identification. Both analyzed models were\nemployed in the EMPC formulation that includes interpretable economic costs,\nsuch as energy consumption, material losses due to inadequate pasteurization,\nand actuator wear. The feasibility of EMPC is ensured using slack variables.\nThe deep Koopman EMPC and N4SID EMPC are numerically validated on a nonlinear\nmodel of multivariable PU under external disturbance. The disturbances include\nfeed pump fail-to-close scenario and the introduction of a cold batch to be\npastuerized. These results demonstrate that the deep Koopmand EMPC achieves a\n32% reduction in total economic cost compared to the N4SID baseline. This\nimprovement is mainly due to the reductions in material losses and energy\nconsumption. Furthermore, the steady-state operation via Koopman-based EMPC\nrequires 10.2% less electrical energy. The results highlight the practical\nadvantages of integrating deep Koopman representations with economic\noptimization to achieve resource-efficient control of thermal-intensive plants.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6Koopman\u7684\u7ecf\u6d4e\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9e\u9a8c\u5ba4\u89c4\u6a21\u5df4\u6c0f\u6740\u83cc\u5355\u5143\u7684\u9ad8\u6548\u8fd0\u884c\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5b9e\u73b0\u4e8645%\u7684\u5f00\u73af\u9884\u6d4b\u7cbe\u5ea6\u63d0\u5347\u548c32%\u7684\u603b\u7ecf\u6d4e\u6210\u672c\u964d\u4f4e\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u590d\u6742\u975e\u7ebf\u6027\u7cfb\u7edf\u5728\u63a7\u5236\u4f18\u5316\u4e2d\u7684\u8ba1\u7b97\u56f0\u96be\uff0c\u540c\u65f6\u51c6\u786e\u8868\u793a\u5df4\u6c0f\u6740\u83cc\u5355\u5143\u7684\u590d\u6742\u52a8\u6001\uff0c\u9700\u8981\u5c06\u975e\u7ebf\u6027\u7cfb\u7edf\u8f6c\u6362\u4e3a\u7ebf\u6027\u8868\u793a\u4ee5\u5e94\u7528\u51f8\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528Koopman\u7b97\u5b50\u7406\u8bba\u5c06\u975e\u7ebf\u6027\u7cfb\u7edf\u52a8\u6001\u8f6c\u6362\u4e3a\u7ebf\u6027\u8868\u793a\uff0c\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u4ece\u5b9e\u9a8c\u6570\u636e\u4e2d\u5b66\u4e60\u7ebf\u6027\u52a8\u6001\uff0c\u5e76\u5728EMPC\u6846\u67b6\u4e2d\u5305\u542b\u53ef\u89e3\u91ca\u7684\u7ecf\u6d4e\u6210\u672c\uff08\u80fd\u8017\u3001\u6750\u6599\u635f\u5931\u3001\u6267\u884c\u5668\u78e8\u635f\uff09\u3002", "result": "\u6df1\u5ea6Koopman EMPC\u76f8\u6bd4\u4f20\u7edfN4SID\u65b9\u6cd5\u5b9e\u73b0\u4e8645%\u7684\u5f00\u73af\u9884\u6d4b\u7cbe\u5ea6\u63d0\u5347\uff0c32%\u7684\u603b\u7ecf\u6d4e\u6210\u672c\u964d\u4f4e\uff0c\u4ee5\u53ca10.2%\u7684\u7a33\u6001\u8fd0\u884c\u7535\u80fd\u51cf\u5c11\u3002", "conclusion": "\u5c06\u6df1\u5ea6Koopman\u8868\u793a\u4e0e\u7ecf\u6d4e\u4f18\u5316\u76f8\u7ed3\u5408\uff0c\u53ef\u4ee5\u5b9e\u73b0\u70ed\u5bc6\u96c6\u578b\u5de5\u5382\u7684\u8d44\u6e90\u9ad8\u6548\u63a7\u5236\uff0c\u5177\u6709\u663e\u8457\u7684\u5b9e\u8df5\u4f18\u52bf\u3002"}}
{"id": "2511.04312", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04312", "abs": "https://arxiv.org/abs/2511.04312", "authors": ["Jacob Lysn\u00e6s-Larsen", "Marte Eggen", "Inga Str\u00fcmke"], "title": "Probing the Probes: Methods and Metrics for Concept Alignment", "comment": "29 pages, 17 figures", "summary": "In explainable AI, Concept Activation Vectors (CAVs) are typically obtained\nby training linear classifier probes to detect human-understandable concepts as\ndirections in the activation space of deep neural networks. It is widely\nassumed that a high probe accuracy indicates a CAV faithfully representing its\ntarget concept. However, we show that the probe's classification accuracy alone\nis an unreliable measure of concept alignment, i.e., the degree to which a CAV\ncaptures the intended concept. In fact, we argue that probes are more likely to\ncapture spurious correlations than they are to represent only the intended\nconcept. As part of our analysis, we demonstrate that deliberately misaligned\nprobes constructed to exploit spurious correlations, achieve an accuracy close\nto that of standard probes. To address this severe problem, we introduce a\nnovel concept localization method based on spatial linear attribution, and\nprovide a comprehensive comparison of it to existing feature visualization\ntechniques for detecting and mitigating concept misalignment. We further\npropose three classes of metrics for quantitatively assessing concept\nalignment: hard accuracy, segmentation scores, and augmentation robustness. Our\nanalysis shows that probes with translation invariance and spatial alignment\nconsistently increase concept alignment. These findings highlight the need for\nalignment-based evaluation metrics rather than probe accuracy, and the\nimportance of tailoring probes to both the model architecture and the nature of\nthe target concept.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5728\u53ef\u89e3\u91caAI\u4e2d\uff0c\u4ec5\u51ed\u6982\u5ff5\u6fc0\u6d3b\u5411\u91cf(CAV)\u63a2\u6d4b\u5668\u7684\u5206\u7c7b\u7cbe\u5ea6\u4e0d\u80fd\u53ef\u9760\u8861\u91cf\u6982\u5ff5\u5bf9\u9f50\u5ea6\uff0c\u63a2\u6d4b\u5668\u66f4\u53ef\u80fd\u6355\u6349\u865a\u5047\u76f8\u5173\u6027\u800c\u975e\u76ee\u6807\u6982\u5ff5\u3002\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u7a7a\u95f4\u7ebf\u6027\u5f52\u56e0\u7684\u65b0\u6982\u5ff5\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e09\u7c7b\u91cf\u5316\u8bc4\u4f30\u6982\u5ff5\u5bf9\u9f50\u7684\u6307\u6807\u3002", "motivation": "\u5f53\u524dCAV\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u63a2\u6d4b\u5668\u5206\u7c7b\u7cbe\u5ea6\u6765\u8bc4\u4f30\u6982\u5ff5\u8868\u793a\u8d28\u91cf\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u8fd9\u79cd\u8bc4\u4f30\u4e0d\u53ef\u9760\uff0c\u63a2\u6d4b\u5668\u5bb9\u6613\u6355\u6349\u865a\u5047\u76f8\u5173\u6027\u800c\u975e\u771f\u6b63\u6982\u5ff5\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u6982\u5ff5\u5bf9\u9f50\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7a7a\u95f4\u7ebf\u6027\u5f52\u56e0\u7684\u6982\u5ff5\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u4e0e\u73b0\u6709\u7279\u5f81\u53ef\u89c6\u5316\u6280\u672f\u5bf9\u6bd4\uff1b\u5f15\u5165\u4e09\u7c7b\u6982\u5ff5\u5bf9\u9f50\u8bc4\u4f30\u6307\u6807\uff1a\u786c\u7cbe\u5ea6\u3001\u5206\u5272\u5206\u6570\u548c\u589e\u5f3a\u9c81\u68d2\u6027\uff1b\u6784\u5efa\u6545\u610f\u9519\u4f4d\u63a2\u6d4b\u5668\u9a8c\u8bc1\u95ee\u9898\u3002", "result": "\u6545\u610f\u9519\u4f4d\u7684\u63a2\u6d4b\u5668\u4e5f\u80fd\u8fbe\u5230\u63a5\u8fd1\u6807\u51c6\u63a2\u6d4b\u5668\u7684\u7cbe\u5ea6\uff0c\u8bc1\u660e\u4ec5\u9760\u7cbe\u5ea6\u4e0d\u53ef\u9760\uff1b\u5177\u6709\u5e73\u79fb\u4e0d\u53d8\u6027\u548c\u7a7a\u95f4\u5bf9\u9f50\u7684\u63a2\u6d4b\u5668\u80fd\u63d0\u9ad8\u6982\u5ff5\u5bf9\u9f50\u5ea6\uff1b\u65b0\u63d0\u51fa\u7684\u8bc4\u4f30\u6307\u6807\u80fd\u66f4\u51c6\u786e\u8861\u91cf\u6982\u5ff5\u5bf9\u9f50\u3002", "conclusion": "\u9700\u8981\u57fa\u4e8e\u5bf9\u9f50\u5ea6\u7684\u8bc4\u4f30\u6307\u6807\u800c\u975e\u63a2\u6d4b\u5668\u7cbe\u5ea6\uff0c\u63a2\u6d4b\u5668\u8bbe\u8ba1\u5e94\u8003\u8651\u6a21\u578b\u67b6\u6784\u548c\u76ee\u6807\u6982\u5ff5\u7279\u6027\uff0c\u7a7a\u95f4\u5bf9\u9f50\u548c\u5e73\u79fb\u4e0d\u53d8\u6027\u5bf9\u6982\u5ff5\u5bf9\u9f50\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.04451", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.04451", "abs": "https://arxiv.org/abs/2511.04451", "authors": ["Patrik Val\u00e1bek", "Marek Wadinger", "Michal Kvasnica", "Martin Klau\u010do"], "title": "Deep Dictionary-Free Method for Identifying Linear Model of Nonlinear System with Input Delay", "comment": null, "summary": "Nonlinear dynamical systems with input delays pose significant challenges for\nprediction, estimation, and control due to their inherent complexity and the\nimpact of delays on system behavior. Traditional linear control techniques\noften fail in these contexts, necessitating innovative approaches. This paper\nintroduces a novel approach to approximate the Koopman operator using an\nLSTM-enhanced Deep Koopman model, enabling linear representations of nonlinear\nsystems with time delays. By incorporating Long Short-Term Memory (LSTM)\nlayers, the proposed framework captures historical dependencies and efficiently\nencodes time-delayed system dynamics into a latent space. Unlike traditional\nextended Dynamic Mode Decomposition (eDMD) approaches that rely on predefined\ndictionaries, the LSTM-enhanced Deep Koopman model is dictionary-free, which\nmitigates the problems with the underlying dynamics being known and\nincorporated into the dictionary. Quantitative comparisons with extended eDMD\non a simulated system demonstrate highly significant performance gains in\nprediction accuracy in cases where the true nonlinear dynamics are unknown and\nachieve comparable results to eDMD with known dynamics of a system.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLSTM\u589e\u5f3a\u7684\u6df1\u5ea6Koopman\u6a21\u578b\uff0c\u7528\u4e8e\u8fd1\u4f3c\u5177\u6709\u8f93\u5165\u5ef6\u8fdf\u7684\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u7684Koopman\u7b97\u5b50\uff0c\u5b9e\u73b0\u7ebf\u6027\u8868\u793a\u5e76\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u5177\u6709\u8f93\u5165\u5ef6\u8fdf\u7684\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u5728\u9884\u6d4b\u3001\u4f30\u8ba1\u548c\u63a7\u5236\u65b9\u9762\u5b58\u5728\u663e\u8457\u6311\u6218\uff0c\u4f20\u7edf\u7ebf\u6027\u63a7\u5236\u6280\u672f\u5f80\u5f80\u5931\u6548\uff0c\u9700\u8981\u521b\u65b0\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528LSTM\u589e\u5f3a\u7684\u6df1\u5ea6Koopman\u6a21\u578b\uff0c\u901a\u8fc7LSTM\u5c42\u6355\u6349\u5386\u53f2\u4f9d\u8d56\u5173\u7cfb\uff0c\u5c06\u65f6\u6ede\u7cfb\u7edf\u52a8\u6001\u9ad8\u6548\u7f16\u7801\u5230\u6f5c\u5728\u7a7a\u95f4\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u5b57\u5178\u3002", "result": "\u5728\u6a21\u62df\u7cfb\u7edf\u4e0a\u4e0e\u6269\u5c55eDMD\u8fdb\u884c\u5b9a\u91cf\u6bd4\u8f83\uff0c\u5f53\u771f\u5b9e\u975e\u7ebf\u6027\u52a8\u6001\u672a\u77e5\u65f6\uff0c\u9884\u6d4b\u7cbe\u5ea6\u6709\u663e\u8457\u63d0\u5347\uff1b\u5728\u5df2\u77e5\u7cfb\u7edf\u52a8\u6001\u65f6\uff0c\u7ed3\u679c\u4e0eeDMD\u76f8\u5f53\u3002", "conclusion": "LSTM\u589e\u5f3a\u7684\u6df1\u5ea6Koopman\u6a21\u578b\u4e3a\u5904\u7406\u5177\u6709\u8f93\u5165\u5ef6\u8fdf\u7684\u975e\u7ebf\u6027\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5b57\u5178\u65e0\u5173\u65b9\u6cd5\uff0c\u5728\u672a\u77e5\u52a8\u6001\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.04316", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04316", "abs": "https://arxiv.org/abs/2511.04316", "authors": ["Tim Beyer", "Jonas Dornbusch", "Jakob Steimle", "Moritz Ladenburger", "Leo Schwinn", "Stephan G\u00fcnnemann"], "title": "AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research", "comment": null, "summary": "The rapid expansion of research on Large Language Model (LLM) safety and\nrobustness has produced a fragmented and oftentimes buggy ecosystem of\nimplementations, datasets, and evaluation methods. This fragmentation makes\nreproducibility and comparability across studies challenging, hindering\nmeaningful progress. To address these issues, we introduce AdversariaLLM, a\ntoolbox for conducting LLM jailbreak robustness research. Its design centers on\nreproducibility, correctness, and extensibility. The framework implements\ntwelve adversarial attack algorithms, integrates seven benchmark datasets\nspanning harmfulness, over-refusal, and utility evaluation, and provides access\nto a wide range of open-weight LLMs via Hugging Face. The implementation\nincludes advanced features for comparability and reproducibility such as\ncompute-resource tracking, deterministic results, and distributional evaluation\ntechniques. \\name also integrates judging through the companion package\nJudgeZoo, which can also be used independently. Together, these components aim\nto establish a robust foundation for transparent, comparable, and reproducible\nresearch in LLM safety.", "AI": {"tldr": "AdversariaLLM\u662f\u4e00\u4e2a\u7528\u4e8eLLM\u8d8a\u72f1\u9c81\u68d2\u6027\u7814\u7a76\u7684\u5de5\u5177\u7bb1\uff0c\u65e8\u5728\u89e3\u51b3\u5f53\u524dLLM\u5b89\u5168\u7814\u7a76\u751f\u6001\u7cfb\u7edf\u788e\u7247\u5316\u3001\u96be\u4ee5\u590d\u73b0\u548c\u6bd4\u8f83\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524dLLM\u5b89\u5168\u548c\u9c81\u68d2\u6027\u7814\u7a76\u751f\u6001\u7cfb\u7edf\u788e\u7247\u5316\u4e25\u91cd\uff0c\u5b58\u5728\u5927\u91cfbuggy\u5b9e\u73b0\u3001\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5bfc\u81f4\u7814\u7a76\u96be\u4ee5\u590d\u73b0\u548c\u6bd4\u8f83\uff0c\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u5b9e\u8d28\u6027\u8fdb\u5c55\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4ee5\u53ef\u590d\u73b0\u6027\u3001\u6b63\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u4e3a\u6838\u5fc3\u7684\u5de5\u5177\u7bb1\uff0c\u5b9e\u73b0\u4e8612\u79cd\u5bf9\u6297\u653b\u51fb\u7b97\u6cd5\uff0c\u96c6\u6210\u4e867\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08\u6db5\u76d6\u5371\u5bb3\u6027\u3001\u8fc7\u5ea6\u62d2\u7edd\u548c\u5b9e\u7528\u6027\u8bc4\u4f30\uff09\uff0c\u5e76\u901a\u8fc7Hugging Face\u63d0\u4f9b\u5bf9\u591a\u79cd\u5f00\u6e90LLM\u7684\u8bbf\u95ee\u3002", "result": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u7528\u4e8e\u53ef\u6bd4\u6027\u548c\u53ef\u590d\u73b0\u6027\u7684\u9ad8\u7ea7\u529f\u80fd\uff0c\u5305\u62ec\u8ba1\u7b97\u8d44\u6e90\u8ddf\u8e2a\u3001\u786e\u5b9a\u6027\u7ed3\u679c\u548c\u5206\u5e03\u8bc4\u4f30\u6280\u672f\uff0c\u5e76\u4e0eJudgeZoo\u96c6\u6210\u8fdb\u884c\u8bc4\u5224\u3002", "conclusion": "AdversariaLLM\u65e8\u5728\u4e3aLLM\u5b89\u5168\u7814\u7a76\u5efa\u7acb\u900f\u660e\u3001\u53ef\u6bd4\u548c\u53ef\u590d\u73b0\u7684\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2511.04461", "categories": ["eess.SY", "cs.CE", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.04461", "abs": "https://arxiv.org/abs/2511.04461", "authors": ["Giorgio Palma", "Andrea Serani", "Matteo Diez"], "title": "Data-driven uncertainty-aware seakeeping prediction of the Delft 372 catamaran using ensemble Hankel dynamic mode decomposition", "comment": null, "summary": "In this study, we present and validate an ensemble-based Hankel Dynamic Mode\nDecomposition with control (HDMDc) for uncertainty-aware seakeeping predictions\nof a high-speed catamaran, namely the Delft 372 model. Experimental\nmeasurements (time histories) of wave elevation at the longitudinal center of\ngravity, heave, pitch, notional flight-deck velocity, notional bridge\nacceleration, and total resistance were collected from irregular wave basin\ntests on a 1:33.3 scale replica of the Delft 372 model under sea state 5\nconditions at Fr = 0.425, and organized into training, validation, and test\nsets. The HDMDc algorithm constructs an equation-free linear reduced-order\nmodel of the seakeeping vessel by augmenting states and inputs with their\ntime-lagged copies to capture nonlinear and memory effects. Two ensembling\nstrategies, namely Bayesian HDMDc (BHDMDc), which samples hyperparameters\nconsidered stochastic variables with prior distribution to produce posterior\nmean forecasts with confidence intervals, and Frequentist HDMDc (FHDMDc), which\naggregates multiple model obtained over data subsets, are compared in providing\nseakeeping prediction and uncertainty quantification. The FHDMDc approach is\nfound to improve the accuracy of the predictions compared to the deterministic\ncounterpart, also providing robust uncertainty estimation; whereas the\napplication of BHDMDc to the present test case is not found beneficial in\ncomparison to the deterministic model. FHDMDc-derived probability density\nfunctions for the motions closely match both experimental data and URANS\nresults, demonstrating reliable and computationally efficient seakeeping\nprediction for design and operational support.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u57fa\u4e8e\u96c6\u6210\u5b66\u4e60\u7684Hankel\u52a8\u6001\u6a21\u6001\u5206\u89e3\u63a7\u5236\u65b9\u6cd5(HDMDc)\uff0c\u7528\u4e8e\u9ad8\u901f\u53cc\u4f53\u8239\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8010\u6ce2\u6027\u9884\u6d4b\u3002\u901a\u8fc7\u5bf9\u6bd4\u8d1d\u53f6\u65afHDMDc\u548c\u9891\u7387\u4e3b\u4e49HDMDc\u4e24\u79cd\u96c6\u6210\u7b56\u7565\uff0c\u53d1\u73b0FHDMDc\u65b9\u6cd5\u5728\u9884\u6d4b\u7cbe\u5ea6\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u9ad8\u6548\u8010\u6ce2\u6027\u9884\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u652f\u6301\u8239\u8236\u8bbe\u8ba1\u548c\u8fd0\u8425\u51b3\u7b56\u3002\u4f20\u7edf\u786e\u5b9a\u6027\u6a21\u578b\u65e0\u6cd5\u63d0\u4f9b\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u4fe1\u606f\uff0c\u800c\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528HDMDc\u7b97\u6cd5\u6784\u5efa\u65e0\u65b9\u7a0b\u7ebf\u6027\u964d\u9636\u6a21\u578b\uff0c\u901a\u8fc7\u72b6\u6001\u548c\u8f93\u5165\u7684\u65f6\u6ede\u526f\u672c\u6765\u6355\u6349\u975e\u7ebf\u6027\u548c\u8bb0\u5fc6\u6548\u5e94\u3002\u6bd4\u8f83\u4e24\u79cd\u96c6\u6210\u7b56\u7565\uff1a\u8d1d\u53f6\u65afHDMDc\uff08\u91c7\u6837\u8d85\u53c2\u6570\uff09\u548c\u9891\u7387\u4e3b\u4e49HDMDc\uff08\u6570\u636e\u5b50\u96c6\u805a\u5408\uff09\u3002", "result": "FHDMDc\u65b9\u6cd5\u76f8\u6bd4\u786e\u5b9a\u6027\u6a21\u578b\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002FHDMDc\u5bfc\u51fa\u7684\u8fd0\u52a8\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u4e0e\u5b9e\u9a8c\u6570\u636e\u548cURANS\u7ed3\u679c\u9ad8\u5ea6\u5339\u914d\u3002\u800cBHDMDc\u5728\u5f53\u524d\u6d4b\u8bd5\u6848\u4f8b\u4e2d\u76f8\u6bd4\u786e\u5b9a\u6027\u6a21\u578b\u6ca1\u6709\u660e\u663e\u4f18\u52bf\u3002", "conclusion": "FHDMDc\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u53ef\u9760\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u8010\u6ce2\u6027\u9884\u6d4b\uff0c\u9002\u7528\u4e8e\u8239\u8236\u8bbe\u8ba1\u548c\u8fd0\u8425\u652f\u6301\uff0c\u5176\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\u4e3a\u51b3\u7b56\u63d0\u4f9b\u4e86\u91cd\u8981\u4fe1\u606f\u3002"}}
{"id": "2511.04328", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04328", "abs": "https://arxiv.org/abs/2511.04328", "authors": ["Jiahao Zhao", "Luxin Xu", "Minghuan Tan", "Lichao Zhang", "Ahmadreza Argha", "Hamid Alinejad-Rokny", "Min Yang"], "title": "RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation", "comment": "To appear in BIBM2025", "summary": "Numerous medical systems powered by Large Language Models (LLMs) have\nachieved remarkable progress in diverse healthcare tasks. However, research on\ntheir medication safety remains limited due to the lack of real world datasets,\nconstrained by privacy and accessibility issues. Moreover, evaluation of LLMs\nin realistic clinical consultation settings, particularly regarding medication\nsafety, is still underexplored. To address these gaps, we propose a framework\nthat simulates and evaluates clinical consultations to systematically assess\nthe medication safety capabilities of LLMs. Within this framework, we generate\ninquiry diagnosis dialogues with embedded medication risks and construct a\ndedicated medication safety database, RxRisk DB, containing 6,725\ncontraindications, 28,781 drug interactions, and 14,906 indication-drug pairs.\nA two-stage filtering strategy ensures clinical realism and professional\nquality, resulting in the benchmark RxSafeBench with 2,443 high-quality\nconsultation scenarios. We evaluate leading open-source and proprietary LLMs\nusing structured multiple choice questions that test their ability to recommend\nsafe medications under simulated patient contexts. Results show that current\nLLMs struggle to integrate contraindication and interaction knowledge,\nespecially when risks are implied rather than explicit. Our findings highlight\nkey challenges in ensuring medication safety in LLM-based systems and provide\ninsights into improving reliability through better prompting and task-specific\ntuning. RxSafeBench offers the first comprehensive benchmark for evaluating\nmedication safety in LLMs, advancing safer and more trustworthy AI-driven\nclinical decision support.", "AI": {"tldr": "\u63d0\u51fa\u4e86RxSafeBench\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u4e34\u5e8a\u54a8\u8be2\u8bc4\u4f30LLMs\u7684\u836f\u7269\u5b89\u5168\u6027\u80fd\u529b\uff0c\u5305\u542b6,725\u79cd\u7981\u5fcc\u75c7\u300128,781\u79cd\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u548c14,906\u4e2a\u9002\u5e94\u75c7-\u836f\u7269\u5bf9\uff0c\u6784\u5efa\u4e862,443\u4e2a\u9ad8\u8d28\u91cf\u54a8\u8be2\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLMs\u7684\u533b\u7597\u7cfb\u7edf\u5728\u836f\u7269\u5b89\u5168\u6027\u65b9\u9762\u7684\u7814\u7a76\u6709\u9650\uff0c\u7f3a\u4e4f\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff0c\u4e14\u5728\u771f\u5b9e\u4e34\u5e8a\u54a8\u8be2\u73af\u5883\u4e0b\u7684\u8bc4\u4f30\u4e0d\u8db3\u3002", "method": "\u6784\u5efaRxRisk DB\u836f\u7269\u5b89\u5168\u6570\u636e\u5e93\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8fc7\u6ee4\u7b56\u7565\u786e\u4fdd\u4e34\u5e8a\u771f\u5b9e\u6027\u548c\u4e13\u4e1a\u8d28\u91cf\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u591a\u9009\u9898\u8bc4\u4f30LLMs\u5728\u6a21\u62df\u60a3\u8005\u60c5\u5883\u4e0b\u63a8\u8350\u5b89\u5168\u836f\u7269\u7684\u80fd\u529b\u3002", "result": "\u5f53\u524dLLMs\u5728\u6574\u5408\u7981\u5fcc\u75c7\u548c\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u77e5\u8bc6\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u7279\u522b\u662f\u5f53\u98ce\u9669\u662f\u9690\u542b\u800c\u975e\u660e\u786e\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "RxSafeBench\u63d0\u4f9b\u4e86\u9996\u4e2a\u8bc4\u4f30LLMs\u836f\u7269\u5b89\u5168\u6027\u7684\u7efc\u5408\u57fa\u51c6\uff0c\u4e3a\u6539\u8fdbAI\u9a71\u52a8\u7684\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2511.04470", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.04470", "abs": "https://arxiv.org/abs/2511.04470", "authors": ["Amin Hashemi-Zadeh", "Nima Tashakor", "Sandun Hettiarachchi", "Stefan Goetz"], "title": "AI-Driven Phase-Shifted Carrier Optimization for Cascaded Bridge Converters, Modular Multilevel Converters, and Reconfigurable Batteries", "comment": "10 pages, 11 figures", "summary": "Phase-shifted carrier pulse-width modulation (PSC-PWM) is a widely adopted\nscheduling algorithm in cascaded bridge converters, modular multilevel\nconverters, and reconfigurable batteries. However, non-uniformed pulse widths\nfor the modules with fixed phase shift angles lead to significant ripple\ncurrent and output-voltage distortion. Voltage uniformity instead would require\noptimization of the phase shifts of the individual carriers. However, the\ncomputational burden for such optimization is beyond the capabilities of any\nsimple embedded controller. This paper proposes a neural network that emulates\nthe behavior of an instantaneous optimizer with significantly reduced\ncomputational burden. The proposed method has the advantages of stable\nperformance in predicting the optimum phase-shift angles under balanced battery\nmodules with non-identical modulation indices without requiring extensive\nlookup tables, slow numerical optimization, or complex controller tuning. With\nonly one (re)training session for any specified number of modules, the proposed\nmethod is readily adaptable to different system sizes. Furthermore, the\nproposed framework also includes a simple scaling strategy that allows a neural\nnetwork trained for fewer modules to be reused for larger systems by grouping\nmodules and adjusting their phase shifts. The scaling strategy eliminates the\nneed for retraining. Large-scale assessment, simulations, and experiments\ndemonstrate that, on average, the proposed approach can reduce the current\nripple and the weighted total harmonic distortion by up to 50 % in real time\nand is 100 to 500 thousand times faster than a conventional optimizer (e.g.,\ngenetic algorithms), making it the only solution for an online application.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u66ff\u4ee3\u4f20\u7edf\u4f18\u5316\u5668\uff0c\u7528\u4e8e\u4f18\u5316\u7ea7\u8054\u6865\u5f0f\u53d8\u6362\u5668\u4e2d\u7684\u76f8\u79fb\u89d2\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u8d1f\u62c5\uff0c\u5b9e\u73b0\u5b9e\u65f6\u7535\u6d41\u7eb9\u6ce2\u548c\u8c10\u6ce2\u5931\u771f\u51cf\u5c11\u3002", "motivation": "\u4f20\u7edf\u76f8\u79fb\u8f7d\u6ce2PWM\u5728\u6a21\u5757\u8c03\u5236\u6307\u6570\u4e0d\u540c\u65f6\u4f1a\u4ea7\u751f\u975e\u5747\u5300\u8109\u51b2\u5bbd\u5ea6\uff0c\u5bfc\u81f4\u663e\u8457\u7684\u7535\u6d41\u7eb9\u6ce2\u548c\u8f93\u51fa\u7535\u538b\u5931\u771f\uff0c\u800c\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u8ba1\u7b97\u8d1f\u62c5\u8fc7\u91cd\uff0c\u65e0\u6cd5\u5728\u5d4c\u5165\u5f0f\u63a7\u5236\u5668\u4e2d\u5b9e\u65f6\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u6a21\u62df\u77ac\u65f6\u4f18\u5316\u5668\u884c\u4e3a\uff0c\u901a\u8fc7\u4e00\u6b21\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u4e0d\u540c\u7cfb\u7edf\u89c4\u6a21\uff0c\u5e76\u5305\u542b\u7b80\u5355\u7684\u7f29\u653e\u7b56\u7565\uff0c\u5141\u8bb8\u5c06\u8bad\u7ec3\u597d\u7684\u7f51\u7edc\u590d\u7528\u4e8e\u66f4\u5927\u7cfb\u7edf\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "result": "\u5e73\u5747\u53ef\u51cf\u5c1150%\u7684\u7535\u6d41\u7eb9\u6ce2\u548c\u52a0\u6743\u603b\u8c10\u6ce2\u5931\u771f\uff0c\u6bd4\u4f20\u7edf\u4f18\u5316\u5668\uff08\u5982\u9057\u4f20\u7b97\u6cd5\uff09\u5feb10\u4e07\u523050\u4e07\u500d\uff0c\u9002\u5408\u5728\u7ebf\u5e94\u7528\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7ea7\u8054\u6865\u5f0f\u53d8\u6362\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u5b9e\u65f6\u7684\u76f8\u79fb\u89d2\u4f18\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u8ba1\u7b97\u8d1f\u62c5\u8fc7\u91cd\u7684\u95ee\u9898\u3002"}}
{"id": "2511.04341", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04341", "abs": "https://arxiv.org/abs/2511.04341", "authors": ["Nick Oh", "Fernand Gobet"], "title": "Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for Language Model Reasoning", "comment": "To-be presented at the Workshop on the Foundations of Reasoning in\n  Language Models at NeurIPS 2025 (non-archival)", "summary": "Test-time reasoning architectures such as those following the Generate-Verify\nparadigm -- where a model iteratively refines or verifies its own generated\noutputs -- prioritise generation and verification but exclude the monitoring\nprocesses that determine when and how reasoning should begin. This omission may\ncontribute to the prefix dominance trap, in which models commit early to\nsuboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy\nloss. We address this architectural gap by formalising Flavell's and Nelson and\nNarens' metacognitive theories into computational specifications, proposing the\nMonitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify\nparadigm by adding explicit monitoring that captures metacognitive experiences\n(from difficulty assessments to confidence judgements) before generation begins\nand refines future monitoring through verification feedback. Though we present\nno empirical validation, this work provides the first systematic computational\ntranslation of foundational metacognitive theories, offering a principled\nvocabulary for understanding reasoning system failures and suggesting specific\narchitectural interventions for future test-time reasoning designs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Monitor-Generate-Verify\uff08MGV\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5728Generate-Verify\u8303\u5f0f\u524d\u6dfb\u52a0\u663e\u5f0f\u76d1\u63a7\u673a\u5236\u6765\u89e3\u51b3\u524d\u7f00\u4e3b\u5bfc\u9677\u9631\u95ee\u9898\uff0c\u5c06\u5143\u8ba4\u77e5\u7406\u8bba\u8f6c\u5316\u4e3a\u8ba1\u7b97\u89c4\u8303\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u63a8\u7406\u67b6\u6784\u7f3a\u4e4f\u76d1\u63a7\u8fc7\u7a0b\uff0c\u5bfc\u81f4\u6a21\u578b\u8fc7\u65e9\u627f\u8bfa\u6b21\u4f18\u63a8\u7406\u8def\u5f84\u800c\u96be\u4ee5\u6062\u590d\uff08\u524d\u7f00\u4e3b\u5bfc\u9677\u9631\uff09\uff0c\u9020\u6210\u7ea620%\u7684\u51c6\u786e\u7387\u635f\u5931\u3002", "method": "\u5c06Flavell\u4ee5\u53caNelson\u548cNarens\u7684\u5143\u8ba4\u77e5\u7406\u8bba\u5f62\u5f0f\u5316\u4e3a\u8ba1\u7b97\u89c4\u8303\uff0c\u63d0\u51faMGV\u6846\u67b6\uff0c\u5728\u751f\u6210\u524d\u6dfb\u52a0\u663e\u5f0f\u76d1\u63a7\u673a\u5236\uff0c\u901a\u8fc7\u9a8c\u8bc1\u53cd\u9988\u6539\u8fdb\u672a\u6765\u76d1\u63a7\u3002", "result": "\u867d\u7136\u672a\u63d0\u4f9b\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u4f46\u8fd9\u662f\u9996\u6b21\u7cfb\u7edf\u5730\u5c06\u57fa\u7840\u5143\u8ba4\u77e5\u7406\u8bba\u8f6c\u5316\u4e3a\u8ba1\u7b97\u89c4\u8303\uff0c\u4e3a\u7406\u89e3\u63a8\u7406\u7cfb\u7edf\u5931\u8d25\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u8bcd\u6c47\u3002", "conclusion": "MGV\u6846\u67b6\u4e3a\u672a\u6765\u6d4b\u8bd5\u65f6\u63a8\u7406\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u67b6\u6784\u5e72\u9884\u5efa\u8bae\uff0c\u901a\u8fc7\u6574\u5408\u5143\u8ba4\u77e5\u76d1\u63a7\u6765\u6539\u5584\u63a8\u7406\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2511.04531", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.04531", "abs": "https://arxiv.org/abs/2511.04531", "authors": ["Arkadeep Saha", "Pieter van Goor", "Antonio Franchi", "Ravi Banavar"], "title": "Synchronous Observer Design for Landmark-Inertial SLAM with Almost-Global Convergence", "comment": "13 pages, 3 figures, This work has been submitted to IFAC World\n  Congress 2026 for possible publication", "summary": "Landmark Inertial Simultaneous Localisation and Mapping (LI-SLAM) is the\nproblem of estimating the locations of landmarks in the environment and the\nrobot's pose relative to those landmarks using landmark position measurements\nand measurements from Inertial Measurement Unit (IMU). This paper proposes a\nnonlinear observer for LI-SLAM posed in continuous time and analyses the\nobserver in a base space that encodes all the observable states of LI-SLAM. The\nlocal exponential stability and almost-global asymptotic stability of the error\ndynamics in base space is established in the proof section and validated using\nsimulations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5730\u6807\u60ef\u6027SLAM\u7684\u975e\u7ebf\u6027\u89c2\u6d4b\u5668\uff0c\u5728\u8fde\u7eed\u65f6\u95f4\u6846\u67b6\u4e0b\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u8bef\u5dee\u52a8\u529b\u5b66\u5728\u57fa\u7a7a\u95f4\u4e2d\u7684\u5c40\u90e8\u6307\u6570\u7a33\u5b9a\u6027\u548c\u51e0\u4e4e\u5168\u5c40\u6e10\u8fd1\u7a33\u5b9a\u6027\u3002", "motivation": "\u89e3\u51b3\u5730\u6807\u60ef\u6027\u540c\u65f6\u5b9a\u4f4d\u4e0e\u5efa\u56fe\u95ee\u9898\uff0c\u901a\u8fc7\u5730\u6807\u4f4d\u7f6e\u6d4b\u91cf\u548cIMU\u6d4b\u91cf\u6765\u4f30\u8ba1\u5730\u6807\u4f4d\u7f6e\u548c\u673a\u5668\u4eba\u76f8\u5bf9\u4e8e\u8fd9\u4e9b\u5730\u6807\u7684\u59ff\u6001\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5728\u8fde\u7eed\u65f6\u95f4\u4e2d\u8868\u8ff0\u7684\u975e\u7ebf\u6027\u89c2\u6d4b\u5668\uff0c\u5e76\u5728\u7f16\u7801\u6240\u6709\u53ef\u89c2\u6d4b\u72b6\u6001\u7684\u57fa\u7a7a\u95f4\u4e2d\u5206\u6790\u8be5\u89c2\u6d4b\u5668\u3002", "result": "\u5728\u8bc1\u660e\u90e8\u5206\u5efa\u7acb\u4e86\u8bef\u5dee\u52a8\u529b\u5b66\u5728\u57fa\u7a7a\u95f4\u4e2d\u7684\u5c40\u90e8\u6307\u6570\u7a33\u5b9a\u6027\u548c\u51e0\u4e4e\u5168\u5c40\u6e10\u8fd1\u7a33\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u6027\u8d28\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u975e\u7ebf\u6027\u89c2\u6d4b\u5668\u80fd\u591f\u6709\u6548\u89e3\u51b3LI-SLAM\u95ee\u9898\uff0c\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u7a33\u5b9a\u6027\u6027\u80fd\u3002"}}
{"id": "2511.04393", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04393", "abs": "https://arxiv.org/abs/2511.04393", "authors": ["Chanwoo Park", "Ziyang Chen", "Asuman Ozdaglar", "Kaiqing Zhang"], "title": "Post-Training LLMs as Better Decision-Making Agents: A Regret-Minimization Approach", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed as \"agents\" for\ndecision-making (DM) in interactive and dynamic environments. Yet, since they\nwere not originally designed for DM, recent studies show that LLMs can struggle\neven in basic online DM problems, failing to achieve low regret or an effective\nexploration-exploitation tradeoff. To address this, we introduce Iterative\nRegret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure\nthat repeatedly distills low-regret decision trajectories back into the base\nmodel. At each iteration, the model rolls out multiple decision trajectories,\nselects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior\nmethods that (a) distill action sequences from known DM algorithms or (b) rely\non manually crafted chain-of-thought templates, our approach leverages the\nregret metric to elicit the model's own DM ability and reasoning rationales.\nThis reliance on model-generated reasoning avoids rigid output engineering and\nprovides more flexible, natural-language training signals. Empirical results\nshow that Iterative RMFT improves LLMs' DM performance across diverse models -\nfrom Transformers with numerical input/output, to open-weight LLMs, and\nadvanced closed-weight models like GPT-4o mini. Its flexibility in output and\nreasoning formats enables generalization across tasks with varying horizons,\naction spaces, reward processes, and natural-language contexts. Finally, we\nprovide theoretical insight showing that a single-layer Transformer under this\nparadigm can act as a no-regret learner in a simplified setting. Overall,\nIterative RMFT offers a principled and general post-training framework for\nenhancing LLMs' decision-making capabilities.", "AI": {"tldr": "\u63d0\u51faIterative RMFT\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u84b8\u998f\u4f4e\u540e\u6094\u51b3\u7b56\u8f68\u8ff9\u6765\u589e\u5f3aLLMs\u7684\u51b3\u7b56\u80fd\u529b\uff0c\u65e0\u9700\u4f9d\u8d56\u5df2\u77e5\u7b97\u6cd5\u6216\u4eba\u5de5\u6a21\u677f\u3002", "motivation": "LLMs\u5728\u4ea4\u4e92\u5f0f\u52a8\u6001\u73af\u5883\u4e2d\u4f5c\u4e3a\u51b3\u7b56\u4ee3\u7406\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u96be\u4ee5\u5b9e\u73b0\u4f4e\u540e\u6094\u6216\u6709\u6548\u7684\u63a2\u7d22-\u5229\u7528\u6743\u8861\uff0c\u9700\u8981\u4e13\u95e8\u7684\u51b3\u7b56\u80fd\u529b\u589e\u5f3a\u65b9\u6cd5\u3002", "method": "\u8fed\u4ee3\u540e\u6094\u6700\u5c0f\u5316\u5fae\u8c03\uff1a\u6a21\u578b\u751f\u6210\u591a\u4e2a\u51b3\u7b56\u8f68\u8ff9\uff0c\u9009\u62e9k\u4e2a\u6700\u4f4e\u540e\u6094\u7684\u8f68\u8ff9\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u8f68\u8ff9\u8fdb\u884c\u81ea\u5fae\u8c03\uff0c\u5229\u7528\u540e\u6094\u6307\u6807\u6fc0\u53d1\u6a21\u578b\u81ea\u8eab\u7684\u51b3\u7b56\u80fd\u529b\u548c\u63a8\u7406\u903b\u8f91\u3002", "result": "Iterative RMFT\u663e\u8457\u63d0\u5347\u4e86\u591a\u79cdLLMs\u7684\u51b3\u7b56\u6027\u80fd\uff0c\u5305\u62ecTransformer\u3001\u5f00\u6e90LLMs\u548cGPT-4o mini\u7b49\u95ed\u6e90\u6a21\u578b\uff0c\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Iterative RMFT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u4e14\u901a\u7528\u7684\u540e\u8bad\u7ec3\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u589e\u5f3aLLMs\u7684\u51b3\u7b56\u80fd\u529b\uff0c\u7406\u8bba\u5206\u6790\u8868\u660e\u5355\u5c42Transformer\u5728\u6b64\u8303\u5f0f\u4e0b\u53ef\u5b9e\u73b0\u65e0\u540e\u6094\u5b66\u4e60\u3002"}}
{"id": "2511.04626", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.04626", "abs": "https://arxiv.org/abs/2511.04626", "authors": ["Zihao Song", "Shirantha Welikala", "Panos J. Antsaklis", "Hai Lin"], "title": "Funnel-Based Online Recovery Control for Nonlinear Systems With Unknown Dynamics", "comment": "13 pages, 14 figures", "summary": "In this paper, we focus on recovery control of nonlinear systems from attacks\nor failures. The main challenges of this problem lie in (1) learning the\nunknown dynamics caused by attacks or failures with formal guarantees, and (2)\nfinding the invariant set of states to formally ensure the state deviations\nallowed from the nominal trajectory. To solve this problem, we propose to apply\nthe Recurrent Equilibrium Networks (RENs) to learn the unknown dynamics using\nthe data from the real-time system states. The input-output property of this\nREN model is guaranteed by incremental integral quadratic constraints (IQCs).\nThen, we propose a funnel-based control method to achieve system recovery from\nthe deviated states. In particular, a sufficient condition for nominal\ntrajectory stabilization is derived together with the invariant funnels along\nthe nominal trajectory. Eventually, the effectiveness of our proposed control\nmethod is illustrated by a simulation example of a DC microgrid control\napplication.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5faa\u73af\u5747\u8861\u7f51\u7edc\u548c\u6f0f\u6597\u63a7\u5236\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u975e\u7ebf\u6027\u7cfb\u7edf\u5728\u906d\u53d7\u653b\u51fb\u6216\u6545\u969c\u540e\u7684\u6062\u590d\u63a7\u5236\uff0c\u901a\u8fc7\u6570\u636e\u5b66\u4e60\u672a\u77e5\u52a8\u6001\u5e76\u4fdd\u8bc1\u72b6\u6001\u8f68\u8ff9\u7684\u7a33\u5b9a\u6027\u3002", "motivation": "\u89e3\u51b3\u975e\u7ebf\u6027\u7cfb\u7edf\u5728\u653b\u51fb\u6216\u6545\u969c\u540e\u7684\u6062\u590d\u63a7\u5236\u95ee\u9898\uff0c\u4e3b\u8981\u6311\u6218\u5305\u62ec\u5b66\u4e60\u672a\u77e5\u52a8\u6001\u5e76\u63d0\u4f9b\u5f62\u5f0f\u5316\u4fdd\u8bc1\uff0c\u4ee5\u53ca\u627e\u5230\u786e\u4fdd\u72b6\u6001\u504f\u79bb\u5141\u8bb8\u8303\u56f4\u7684\u7a33\u5b9a\u96c6\u3002", "method": "\u4f7f\u7528\u5faa\u73af\u5747\u8861\u7f51\u7edc\u4ece\u5b9e\u65f6\u7cfb\u7edf\u72b6\u6001\u6570\u636e\u4e2d\u5b66\u4e60\u672a\u77e5\u52a8\u6001\uff0c\u901a\u8fc7\u589e\u91cf\u79ef\u5206\u4e8c\u6b21\u7ea6\u675f\u4fdd\u8bc1\u6a21\u578b\u7279\u6027\uff1b\u63d0\u51fa\u57fa\u4e8e\u6f0f\u6597\u7684\u63a7\u5236\u65b9\u6cd5\u5b9e\u73b0\u7cfb\u7edf\u6062\u590d\uff0c\u63a8\u5bfc\u540d\u4e49\u8f68\u8ff9\u7a33\u5b9a\u7684\u5145\u5206\u6761\u4ef6\u548c\u6cbf\u8f68\u8ff9\u7684\u4e0d\u53d8\u6f0f\u6597\u3002", "result": "\u5728\u76f4\u6d41\u5fae\u7535\u7f51\u63a7\u5236\u5e94\u7528\u7684\u4eff\u771f\u793a\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u6240\u63d0\u63a7\u5236\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u975e\u7ebf\u6027\u7cfb\u7edf\u5728\u653b\u51fb\u6216\u6545\u969c\u540e\u7684\u6062\u590d\u63a7\u5236\u95ee\u9898\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u4fdd\u8bc1\u786e\u4fdd\u7cfb\u7edf\u72b6\u6001\u7684\u7a33\u5b9a\u6062\u590d\u3002"}}
{"id": "2511.04439", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04439", "abs": "https://arxiv.org/abs/2511.04439", "authors": ["Anisha Garg", "Ganesh Venkatesh"], "title": "The Peril of Preference: Why GRPO fails on Ordinal Rewards", "comment": null, "summary": "Group-relative Policy Optimization's (GRPO) simplicity makes it highly\ndesirable for adapting LLMs to become experts at specific tasks. But this\nsimplicity also makes it ill-specified as we seek to enhance RL training with\nricher, non-binary feedback. When using ordinal rewards to give partial credit,\nGRPO's simplicity starts to hurt, as its group-average baseline often assigns a\npositive advantage to failed trajectories and reinforces incorrect behavior.\n  We introduce Correctness Relative Policy Optimization (CoRPO), a new\nformulation that solves this flaw. CoRPO uses an adaptive baseline that\nenforces a minimum quality threshold, ensuring failed solutions are never\npositively reinforced. Once the policy consistently meets this threshold, the\nbaseline automatically transitions to a relative preference mode, pushing the\nmodel to find optimal solutions rather than just \"acceptable\" ones. We\nempirically validate CoRPO on a code verification task, where it demonstrates\nmore stable convergence and better out-of-domain generalization.\n  This work represents a critical step in our broader research program to\nenable LLMs to learn genuinely new capabilities through reinforcement learning.\nWe achieve this by enabling LLMs to learn from rich, multi-dimensional feedback\n- progressing from binary to ordinal rewards in this work, and onward to\ndenser, per-step supervision.", "AI": {"tldr": "CoRPO\u89e3\u51b3\u4e86GRPO\u5728\u4f7f\u7528\u5e8f\u6570\u5956\u52b1\u65f6\u5bf9\u5931\u8d25\u8f68\u8ff9\u9519\u8bef\u5f3a\u5316\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u57fa\u7ebf\u786e\u4fdd\u5931\u8d25\u89e3\u51b3\u65b9\u6848\u4e0d\u88ab\u6b63\u5411\u5f3a\u5316\uff0c\u5e76\u5728\u8fbe\u5230\u8d28\u91cf\u9608\u503c\u540e\u5207\u6362\u5230\u76f8\u5bf9\u504f\u597d\u6a21\u5f0f\u4ee5\u5bfb\u627e\u6700\u4f18\u89e3\u3002", "motivation": "GRPO\u7684\u7b80\u5355\u6027\u4f7f\u5176\u5728\u9002\u5e94LLM\u5230\u7279\u5b9a\u4efb\u52a1\u65f6\u5f88\u6709\u5438\u5f15\u529b\uff0c\u4f46\u4f7f\u7528\u5e8f\u6570\u5956\u52b1\u63d0\u4f9b\u90e8\u5206\u4fe1\u7528\u65f6\uff0c\u5176\u7ec4\u5e73\u5747\u57fa\u7ebf\u7ecf\u5e38\u5bf9\u5931\u8d25\u8f68\u8ff9\u5206\u914d\u6b63\u4f18\u52bf\u5e76\u5f3a\u5316\u9519\u8bef\u884c\u4e3a\u3002", "method": "\u63d0\u51faCorrectness Relative Policy Optimization (CoRPO)\uff0c\u4f7f\u7528\u81ea\u9002\u5e94\u57fa\u7ebf\u5f3a\u5236\u6267\u884c\u6700\u4f4e\u8d28\u91cf\u9608\u503c\uff0c\u786e\u4fdd\u5931\u8d25\u89e3\u51b3\u65b9\u6848\u6c38\u8fdc\u4e0d\u4f1a\u88ab\u6b63\u5411\u5f3a\u5316\u3002\u5f53\u7b56\u7565\u6301\u7eed\u6ee1\u8db3\u6b64\u9608\u503c\u540e\uff0c\u57fa\u7ebf\u81ea\u52a8\u8fc7\u6e21\u5230\u76f8\u5bf9\u504f\u597d\u6a21\u5f0f\u3002", "result": "\u5728\u4ee3\u7801\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u7ecf\u9a8c\u9a8c\u8bc1\uff0cCoRPO\u8868\u73b0\u51fa\u66f4\u7a33\u5b9a\u7684\u6536\u655b\u6027\u548c\u66f4\u597d\u7684\u57df\u5916\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u662f\u5728LLM\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b66\u4e60\u771f\u6b63\u65b0\u80fd\u529b\u7684\u7814\u7a76\u8ba1\u5212\u4e2d\u7684\u5173\u952e\u4e00\u6b65\uff0c\u901a\u8fc7\u4f7fLLM\u80fd\u591f\u4ece\u4e30\u5bcc\u7684\u591a\u7ef4\u53cd\u9988\u4e2d\u5b66\u4e60\uff0c\u4ece\u4e8c\u5143\u5956\u52b1\u8fdb\u5c55\u5230\u5e8f\u6570\u5956\u52b1\uff0c\u5e76\u8fdb\u4e00\u6b65\u5411\u66f4\u5bc6\u96c6\u7684\u6bcf\u6b65\u76d1\u7763\u53d1\u5c55\u3002"}}
{"id": "2511.04644", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.04644", "abs": "https://arxiv.org/abs/2511.04644", "authors": ["Stephen Ampleman", "Himanshu Sharma", "Sayak Mukherjee", "Sonja Glavaski"], "title": "Control Affine Hybrid Power Plant Subsystem Modeling for Supervisory Control Design", "comment": "7 pages, 3 figures", "summary": "Hybrid power plants (HPPs) combine multiple power generators\n(conventional/variable) and energy storage capabilities to support generation\ninadequacy and grid demands. This paper introduces a modeling and control\ndesign framework for hybrid power plants (HPPs) consisting of a wind farm,\nsolar plant, and battery storage. Specifically, this work adapts established\nmodeling paradigms for wind farms, solar plants and battery models into a\ncontrol affine form suitable for control design at the supervisory level. In\nthe case of wind and battery models, generator torque and cell current control\nlaws are developed using nonlinear control and control barrier function\ntechniques to track a command from a supervisory control law while maintaining\nsafe and stable operation. The utility of this modeling and control framework\nis illustrated through a test case using a utility demand signal for tracking,\ntime varying wind and irradiance data, and a rule-based supervisory control\nlaw.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6df7\u5408\u53d1\u7535\u5382\uff08HPP\uff09\u7684\u5efa\u6a21\u4e0e\u63a7\u5236\u6846\u67b6\uff0c\u7ed3\u5408\u98ce\u7535\u573a\u3001\u592a\u9633\u80fd\u7535\u7ad9\u548c\u7535\u6c60\u50a8\u80fd\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u63a7\u5236\u548c\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u6280\u672f\u5b9e\u73b0\u5b89\u5168\u7a33\u5b9a\u7684\u8fd0\u884c\u3002", "motivation": "\u6df7\u5408\u53d1\u7535\u5382\u7ed3\u5408\u591a\u79cd\u53d1\u7535\u673a\u7ec4\u548c\u50a8\u80fd\u80fd\u529b\u6765\u652f\u6301\u53d1\u7535\u4e0d\u8db3\u548c\u7535\u7f51\u9700\u6c42\uff0c\u9700\u8981\u7edf\u4e00\u7684\u5efa\u6a21\u548c\u63a7\u5236\u6846\u67b6\u6765\u534f\u8c03\u4e0d\u540c\u7ec4\u4ef6\u3002", "method": "\u5c06\u98ce\u7535\u573a\u3001\u592a\u9633\u80fd\u7535\u7ad9\u548c\u7535\u6c60\u6a21\u578b\u9002\u914d\u4e3a\u63a7\u5236\u4eff\u5c04\u5f62\u5f0f\uff0c\u5f00\u53d1\u53d1\u7535\u673a\u626d\u77e9\u548c\u7535\u6c60\u7535\u6d41\u63a7\u5236\u5f8b\uff0c\u4f7f\u7528\u975e\u7ebf\u6027\u63a7\u5236\u548c\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u6280\u672f\u8ddf\u8e2a\u4e0a\u7ea7\u63a7\u5236\u6307\u4ee4\u3002", "result": "\u901a\u8fc7\u6d4b\u8bd5\u6848\u4f8b\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u5b9e\u7528\u6027\uff0c\u5305\u62ec\u8ddf\u8e2a\u7535\u7f51\u9700\u6c42\u4fe1\u53f7\u3001\u5904\u7406\u65f6\u53d8\u98ce\u529b\u548c\u8f90\u7167\u5ea6\u6570\u636e\uff0c\u4ee5\u53ca\u57fa\u4e8e\u89c4\u5219\u7684\u4e0a\u7ea7\u63a7\u5236\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5efa\u6a21\u4e0e\u63a7\u5236\u6846\u67b6\u80fd\u591f\u6709\u6548\u534f\u8c03\u6df7\u5408\u53d1\u7535\u5382\u4e2d\u5404\u7ec4\u4ef6\uff0c\u786e\u4fdd\u5b89\u5168\u7a33\u5b9a\u8fd0\u884c\u5e76\u6ee1\u8db3\u7535\u7f51\u9700\u6c42\u3002"}}
{"id": "2511.04464", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04464", "abs": "https://arxiv.org/abs/2511.04464", "authors": ["Carnot Braun", "Rafael O. Jarczewski", "Gabriel U. Talasso", "Leandro A. Villas", "Allan M. de Souza"], "title": "Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context", "comment": null, "summary": "Traditional vehicle routing systems efficiently optimize singular metrics\nlike time or distance, and when considering multiple metrics, they need more\nprocesses to optimize . However, they lack the capability to interpret and\nintegrate the complex, semantic, and dynamic contexts of human drivers, such as\nmulti-step tasks, situational constraints, or urgent needs. This paper\nintroduces and evaluates PAVe (Personalized Agentic Vehicular Routing), a\nhybrid agentic assistant designed to augment classical pathfinding algorithms\nwith contextual reasoning. Our approach employs a Large Language Model (LLM)\nagent that operates on a candidate set of routes generated by a multi-objective\n(time, CO2) Dijkstra algorithm. The agent evaluates these options against\nuser-provided tasks, preferences, and avoidance rules by leveraging a\npre-processed geospatial cache of urban Points of Interest (POIs). In a\nbenchmark of realistic urban scenarios, PAVe successfully used complex user\nintent into appropriate route modifications, achieving over 88% accuracy in its\ninitial route selections with a local model. We conclude that combining\nclassical routing algorithms with an LLM-based semantic reasoning layer is a\nrobust and effective approach for creating personalized, adaptive, and scalable\nsolutions for urban mobility optimization.", "AI": {"tldr": "PAVe\u7cfb\u7edf\u7ed3\u5408\u4f20\u7edf\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\u4e0eLLM\u8bed\u4e49\u63a8\u7406\uff0c\u901a\u8fc7\u591a\u76ee\u6807Dijkstra\u7b97\u6cd5\u751f\u6210\u5019\u9009\u8def\u7ebf\uff0c\u518d\u7531LLM\u4ee3\u7406\u6839\u636e\u7528\u6237\u4efb\u52a1\u3001\u504f\u597d\u548c\u89c4\u907f\u89c4\u5219\u8fdb\u884c\u4e0a\u4e0b\u6587\u8bc4\u4f30\uff0c\u5b9e\u73b0\u4e2a\u6027\u5316\u8f66\u8f86\u8def\u5f84\u89c4\u5212\u3002", "motivation": "\u4f20\u7edf\u8f66\u8f86\u8def\u5f84\u7cfb\u7edf\u53ea\u80fd\u4f18\u5316\u5355\u4e00\u6307\u6807\uff0c\u65e0\u6cd5\u7406\u89e3\u4eba\u7c7b\u9a7e\u9a76\u5458\u7684\u590d\u6742\u8bed\u4e49\u4e0a\u4e0b\u6587\uff08\u5982\u591a\u6b65\u9aa4\u4efb\u52a1\u3001\u60c5\u5883\u7ea6\u675f\u3001\u7d27\u6025\u9700\u6c42\uff09\uff0c\u9700\u8981\u80fd\u591f\u96c6\u6210\u8bed\u4e49\u63a8\u7406\u7684\u667a\u80fd\u8def\u7531\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u591a\u76ee\u6807\uff08\u65f6\u95f4\u3001CO2\uff09Dijkstra\u7b97\u6cd5\u751f\u6210\u5019\u9009\u8def\u7ebf\uff0c\u7136\u540e\u901a\u8fc7LLM\u4ee3\u7406\u7ed3\u5408\u9884\u5904\u7406\u7684\u5730\u7406\u7a7a\u95f4POI\u7f13\u5b58\uff0c\u6839\u636e\u7528\u6237\u63d0\u4f9b\u7684\u4efb\u52a1\u3001\u504f\u597d\u548c\u89c4\u907f\u89c4\u5219\u8bc4\u4f30\u8def\u7ebf\u9009\u9879\u3002", "result": "\u5728\u771f\u5b9e\u57ce\u5e02\u573a\u666f\u6d4b\u8bd5\u4e2d\uff0cPAVe\u6210\u529f\u5c06\u590d\u6742\u7528\u6237\u610f\u56fe\u8f6c\u5316\u4e3a\u9002\u5f53\u7684\u8def\u7ebf\u4fee\u6539\uff0c\u4f7f\u7528\u672c\u5730\u6a21\u578b\u65f6\u521d\u59cb\u8def\u7ebf\u9009\u62e9\u51c6\u786e\u7387\u8d85\u8fc788%\u3002", "conclusion": "\u5c06\u7ecf\u5178\u8def\u7531\u7b97\u6cd5\u4e0e\u57fa\u4e8eLLM\u7684\u8bed\u4e49\u63a8\u7406\u5c42\u76f8\u7ed3\u5408\uff0c\u662f\u521b\u5efa\u4e2a\u6027\u5316\u3001\u81ea\u9002\u5e94\u548c\u53ef\u6269\u5c55\u57ce\u5e02\u79fb\u52a8\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u7684\u7a33\u5065\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2511.04481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04481", "abs": "https://arxiv.org/abs/2511.04481", "authors": ["Lars Krupp", "Daniel Gei\u00dfler", "Vishal Banwari", "Paul Lukowicz", "Jakob Karolus"], "title": "Promoting Sustainable Web Agents: Benchmarking and Estimating Energy Consumption through Empirical and Theoretical Analysis", "comment": "Accepted by AAAI 2026 AISI", "summary": "Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful\nagentic systems pushing the boundaries of Large Language Models (LLM). They can\nautonomously interact with the internet at the user's behest, such as\nnavigating websites, filling search masks, and comparing price lists. Though\nweb agent research is thriving, induced sustainability issues remain largely\nunexplored. To highlight the urgency of this issue, we provide an initial\nexploration of the energy and $CO_2$ cost associated with web agents from both\na theoretical -via estimation- and an empirical perspective -by benchmarking.\nOur results show how different philosophies in web agent creation can severely\nimpact the associated expended energy, and that more energy consumed does not\nnecessarily equate to better results. We highlight a lack of transparency\nregarding disclosing model parameters and processes used for some web agents as\na limiting factor when estimating energy consumption. Our work contributes\ntowards a change in thinking of how we evaluate web agents, advocating for\ndedicated metrics measuring energy consumption in benchmarks.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u63a2\u7d22\u4e86\u7f51\u7edc\u4ee3\u7406\u7684\u80fd\u6e90\u6d88\u8017\u548c\u78b3\u6392\u653e\u95ee\u9898\uff0c\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790\u63ed\u793a\u4e86\u4e0d\u540c\u8bbe\u8ba1\u7406\u5ff5\u5bf9\u80fd\u8017\u7684\u663e\u8457\u5f71\u54cd\uff0c\u5e76\u6307\u51fa\u80fd\u8017\u4e0e\u6027\u80fd\u4e0d\u4e00\u5b9a\u6210\u6b63\u6bd4\u3002", "motivation": "\u5c3d\u7ba1\u7f51\u7edc\u4ee3\u7406\u7814\u7a76\u84ec\u52c3\u53d1\u5c55\uff0c\u4f46\u5176\u5f15\u53d1\u7684\u53ef\u6301\u7eed\u6027\u95ee\u9898\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u7f51\u7edc\u4ee3\u7406\u7684\u80fd\u6e90\u548c\u78b3\u6392\u653e\u6210\u672c\uff0c\u5f3a\u8c03\u8fd9\u4e00\u95ee\u9898\u7684\u7d27\u8feb\u6027\u3002", "method": "\u91c7\u7528\u7406\u8bba\u4f30\u8ba1\u548c\u5b9e\u8bc1\u57fa\u51c6\u6d4b\u8bd5\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u4ece\u7406\u8bba\u548c\u5b9e\u8df5\u4e24\u4e2a\u89d2\u5ea6\u5206\u6790\u7f51\u7edc\u4ee3\u7406\u7684\u80fd\u6e90\u6d88\u8017\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4e0d\u540c\u7f51\u7edc\u4ee3\u7406\u8bbe\u8ba1\u7406\u5ff5\u4f1a\u4e25\u91cd\u5f71\u54cd\u80fd\u8017\uff0c\u4e14\u66f4\u9ad8\u80fd\u8017\u4e0d\u4e00\u5b9a\u5e26\u6765\u66f4\u597d\u7ed3\u679c\u3002\u540c\u65f6\u53d1\u73b0\u6a21\u578b\u53c2\u6570\u548c\u8fc7\u7a0b\u62ab\u9732\u4e0d\u900f\u660e\u9650\u5236\u4e86\u80fd\u8017\u4f30\u7b97\u3002", "conclusion": "\u547c\u5401\u6539\u53d8\u7f51\u7edc\u4ee3\u7406\u8bc4\u4f30\u65b9\u5f0f\uff0c\u5efa\u8bae\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u52a0\u5165\u4e13\u95e8\u7684\u80fd\u8017\u6307\u6807\uff0c\u63a8\u52a8\u66f4\u53ef\u6301\u7eed\u7684\u7f51\u7edc\u4ee3\u7406\u53d1\u5c55\u3002"}}
{"id": "2511.04500", "categories": ["cs.AI", "cs.CL", "cs.GT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04500", "abs": "https://arxiv.org/abs/2511.04500", "authors": ["Andrea Cera Palatsi", "Samuel Martin-Gutierrez", "Ana S. Cardenal", "Max Pellert"], "title": "Large language models replicate and predict human cooperation across experiments in game theory", "comment": null, "summary": "Large language models (LLMs) are increasingly used both to make decisions in\ndomains such as health, education and law, and to simulate human behavior. Yet\nhow closely LLMs mirror actual human decision-making remains poorly understood.\nThis gap is critical: misalignment could produce harmful outcomes in practical\napplications, while failure to replicate human behavior renders LLMs\nineffective for social simulations. Here, we address this gap by developing a\ndigital twin of game-theoretic experiments and introducing a systematic\nprompting and probing framework for machine-behavioral evaluation. Testing\nthree open-source models (Llama, Mistral and Qwen), we find that Llama\nreproduces human cooperation patterns with high fidelity, capturing human\ndeviations from rational choice theory, while Qwen aligns closely with Nash\nequilibrium predictions. Notably, we achieved population-level behavioral\nreplication without persona-based prompting, simplifying the simulation\nprocess. Extending beyond the original human-tested games, we generate and\npreregister testable hypotheses for novel game configurations outside the\noriginal parameter grid. Our findings demonstrate that appropriately calibrated\nLLMs can replicate aggregate human behavioral patterns and enable systematic\nexploration of unexplored experimental spaces, offering a complementary\napproach to traditional research in the social and behavioral sciences that\ngenerates new empirical predictions about human social decision-making.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540cLLM\u5728\u535a\u5f08\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u4eba\u7c7b\u51b3\u7b56\u6a21\u5f0f\uff1aLlama\u80fd\u9ad8\u4fdd\u771f\u590d\u5236\u4eba\u7c7b\u5408\u4f5c\u884c\u4e3a\uff0c\u6355\u6349\u4eba\u7c7b\u504f\u79bb\u7406\u6027\u9009\u62e9\u7406\u8bba\u7684\u6a21\u5f0f\uff1bQwen\u5219\u66f4\u63a5\u8fd1\u7eb3\u4ec0\u5747\u8861\u9884\u6d4b\u3002\u65e0\u9700\u4eba\u7269\u8bbe\u5b9a\u63d0\u793a\u5373\u53ef\u5b9e\u73b0\u7fa4\u4f53\u884c\u4e3a\u590d\u5236\uff0c\u7b80\u5316\u4e86\u6a21\u62df\u8fc7\u7a0b\u3002", "motivation": "\u7406\u89e3LLM\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u80fd\u6a21\u62df\u4eba\u7c7b\u51b3\u7b56\u884c\u4e3a\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u5982\u679cLLM\u4e0e\u4eba\u7c7b\u51b3\u7b56\u4e0d\u4e00\u81f4\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u80fd\u5bfc\u81f4\u6709\u5bb3\u7ed3\u679c\uff0c\u800c\u5728\u793e\u4f1a\u6a21\u62df\u4e2d\u65e0\u6cd5\u590d\u5236\u4eba\u7c7b\u884c\u4e3a\u5219\u4f1a\u4f7fLLM\u5931\u6548\u3002", "method": "\u5f00\u53d1\u535a\u5f08\u5b9e\u9a8c\u7684\u6570\u5b57\u5b6a\u751f\u6a21\u578b\uff0c\u5f15\u5165\u7cfb\u7edf\u7684\u63d0\u793a\u548c\u63a2\u6d4b\u6846\u67b6\u8fdb\u884c\u673a\u5668\u884c\u4e3a\u8bc4\u4f30\uff0c\u6d4b\u8bd5\u4e09\u4e2a\u5f00\u6e90\u6a21\u578b\uff08Llama\u3001Mistral\u548cQwen\uff09\u3002", "result": "Llama\u80fd\u9ad8\u4fdd\u771f\u590d\u5236\u4eba\u7c7b\u5408\u4f5c\u6a21\u5f0f\uff0c\u6355\u6349\u4eba\u7c7b\u504f\u79bb\u7406\u6027\u9009\u62e9\u7406\u8bba\u7684\u884c\u4e3a\uff1bQwen\u4e0e\u7eb3\u4ec0\u5747\u8861\u9884\u6d4b\u9ad8\u5ea6\u4e00\u81f4\uff1b\u65e0\u9700\u4eba\u7269\u8bbe\u5b9a\u63d0\u793a\u5373\u53ef\u5b9e\u73b0\u7fa4\u4f53\u884c\u4e3a\u590d\u5236\u3002", "conclusion": "\u9002\u5f53\u6821\u51c6\u7684LLM\u53ef\u4ee5\u590d\u5236\u7fa4\u4f53\u4eba\u7c7b\u884c\u4e3a\u6a21\u5f0f\uff0c\u5e76\u80fd\u7cfb\u7edf\u63a2\u7d22\u672a\u7ecf\u9a8c\u8bc1\u7684\u5b9e\u9a8c\u7a7a\u95f4\uff0c\u4e3a\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u8865\u5145\u65b9\u6cd5\uff0c\u751f\u6210\u5173\u4e8e\u4eba\u7c7b\u793e\u4ea4\u51b3\u7b56\u7684\u65b0\u5b9e\u8bc1\u9884\u6d4b\u3002"}}
{"id": "2511.04556", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.04556", "abs": "https://arxiv.org/abs/2511.04556", "authors": ["Zihang Ding", "Kun Zhang"], "title": "Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse Sensing Approach", "comment": "32 pages (including supplementary information), 11 figures (and 7\n  figures in supplementary). Submitted to Nature Water. Partially presented at\n  HydroML 2025 Symposium, Minnesota Water Resources Conference 2025, and will\n  be presented at AGU Fall Meeting 2025", "summary": "Urban surface water flooding, triggered by intense rainfall overwhelming\ndrainage systems, is increasingly frequent and widespread. While flood\nprediction and monitoring in high spatial-temporal resolution are desired,\npractical constraints in time, budget, and technology hinder its full\nimplementation. How to monitor urban drainage networks and predict flow\nconditions under constrained resource is a major challenge. This study presents\na data-driven sparse sensing (DSS) framework, integrated with EPA-SWMM, to\noptimize sensor placement and reconstruct peak flowrates in a stormwater\nsystem, using the Woodland Avenue catchment in Duluth, Minnesota, as a case\nstudy. We utilized a SWMM model to generate a training dataset of peak flowrate\nprofiles across the stormwater network. Furthermore, we applied DSS -\nleveraging singular value decomposition for dimensionality reduction and QR\nfactorization for sensor allocation - to identify the optimal monitoring nodes\nbased on the simulated training dataset. We then validated the\nrepresentativeness of these identified monitoring nodes by comparing the\nDSS-reconstructed peak flowrate profiles with those obtained from SWMM. Three\noptimally placed sensors among 77 nodes achieved satisfactory reconstruction\nperformance with Nash-Sutcliffe Efficiency (NSE) values of 0.92-0.95 (25th to\n75th percentiles). In addition, the model showed good robustness to uncertainty\nin measurements. Its robustness to sensor failures is location-dependent and\nimproves with the number of sensors deployed. The framework balances\ncomputational efficiency and physical interpretability, enabling high-accuracy\nflow reconstruction with minimal sensors. This DSS framework can be further\nintegrated with predictive models to realize flood early warning and real-time\ncontrol under limited sensing and monitoring resource.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u636e\u9a71\u52a8\u7684\u7a00\u758f\u611f\u77e5\u6846\u67b6\uff0c\u7ed3\u5408EPA-SWMM\u6a21\u578b\uff0c\u901a\u8fc7\u4f18\u5316\u4f20\u611f\u5668\u5e03\u5c40\u6765\u91cd\u5efa\u57ce\u5e02\u6392\u6c34\u7cfb\u7edf\u7684\u5cf0\u503c\u6d41\u91cf\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u6d2a\u6c34\u76d1\u6d4b\u3002", "motivation": "\u57ce\u5e02\u5730\u8868\u6c34\u6d2a\u6c34\u65e5\u76ca\u9891\u7e41\uff0c\u4f46\u9ad8\u65f6\u7a7a\u5206\u8fa8\u7387\u7684\u6d2a\u6c34\u9884\u6d4b\u548c\u76d1\u6d4b\u53d7\u5230\u65f6\u95f4\u3001\u9884\u7b97\u548c\u6280\u672f\u9650\u5236\u3002\u5982\u4f55\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u76d1\u6d4b\u57ce\u5e02\u6392\u6c34\u7f51\u7edc\u5e76\u9884\u6d4b\u6d41\u91cf\u72b6\u51b5\u662f\u4e3b\u8981\u6311\u6218\u3002", "method": "\u4f7f\u7528SWMM\u6a21\u578b\u751f\u6210\u5cf0\u503c\u6d41\u91cf\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5e94\u7528\u6570\u636e\u9a71\u52a8\u7a00\u758f\u611f\u77e5\u6846\u67b6\uff08\u5305\u62ec\u5947\u5f02\u503c\u5206\u89e3\u964d\u7ef4\u548cQR\u5206\u89e3\u4f20\u611f\u5668\u5206\u914d\uff09\u6765\u8bc6\u522b\u6700\u4f18\u76d1\u6d4b\u8282\u70b9\uff0c\u5e76\u9a8c\u8bc1\u91cd\u5efa\u6027\u80fd\u3002", "result": "\u572877\u4e2a\u8282\u70b9\u4e2d\u4ec5\u97003\u4e2a\u4f18\u5316\u5e03\u7f6e\u7684\u4f20\u611f\u5668\uff0c\u5c31\u80fd\u5b9e\u73b0\u6ee1\u610f\u7684\u91cd\u5efa\u6027\u80fd\uff08NSE\u503c0.92-0.95\uff09\uff0c\u6a21\u578b\u5bf9\u6d4b\u91cf\u4e0d\u786e\u5b9a\u6027\u5177\u6709\u826f\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u5e73\u8861\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u7269\u7406\u53ef\u89e3\u91ca\u6027\uff0c\u80fd\u591f\u4ee5\u6700\u5c11\u7684\u4f20\u611f\u5668\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u6d41\u91cf\u91cd\u5efa\uff0c\u53ef\u8fdb\u4e00\u6b65\u4e0e\u9884\u6d4b\u6a21\u578b\u96c6\u6210\uff0c\u5728\u6709\u9650\u4f20\u611f\u8d44\u6e90\u4e0b\u5b9e\u73b0\u6d2a\u6c34\u65e9\u671f\u9884\u8b66\u548c\u5b9e\u65f6\u63a7\u5236\u3002"}}
{"id": "2511.04583", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04583", "abs": "https://arxiv.org/abs/2511.04583", "authors": ["Atsuyuki Miyai", "Mashiro Toyooka", "Takashi Otonari", "Zaiying Zhao", "Kiyoharu Aizawa"], "title": "Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper", "comment": "Issues, comments, and questions are all welcome in\n  https://github.com/Agent4Science-UTokyo/Jr.AI-Scientist", "summary": "Understanding the current capabilities and risks of AI Scientist systems is\nessential for ensuring trustworthy and sustainable AI-driven scientific\nprogress while preserving the integrity of the academic ecosystem. To this end,\nwe develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system\nthat mimics the core research workflow of a novice student researcher: Given\nthe baseline paper from the human mentor, it analyzes its limitations,\nformulates novel hypotheses for improvement, validates them through rigorous\nexperimentation, and writes a paper with the results. Unlike previous\napproaches that assume full automation or operate on small-scale code, Jr. AI\nScientist follows a well-defined research workflow and leverages modern coding\nagents to handle complex, multi-file implementations, leading to scientifically\nvaluable contributions. For evaluation, we conducted automated assessments\nusing AI Reviewers, author-led evaluations, and submissions to Agents4Science,\na venue dedicated to AI-driven scientific contributions. The findings\ndemonstrate that Jr. AI Scientist generates papers receiving higher review\nscores than existing fully automated systems. Nevertheless, we identify\nimportant limitations from both the author evaluation and the Agents4Science\nreviews, indicating the potential risks of directly applying current AI\nScientist systems and key challenges for future research. Finally, we\ncomprehensively report various risks identified during development. We hope\nthese insights will deepen understanding of current progress and risks in AI\nScientist development.", "AI": {"tldr": "\u5f00\u53d1\u4e86Jr. AI Scientist\u7cfb\u7edf\uff0c\u8fd9\u662f\u4e00\u4e2a\u6a21\u62df\u65b0\u624b\u7814\u7a76\u4eba\u5458\u5de5\u4f5c\u6d41\u7a0b\u7684\u81ea\u4e3bAI\u79d1\u5b66\u5bb6\u7cfb\u7edf\uff0c\u80fd\u591f\u5206\u6790\u8bba\u6587\u5c40\u9650\u6027\u3001\u63d0\u51fa\u5047\u8bbe\u3001\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u5e76\u64b0\u5199\u8bba\u6587\u3002", "motivation": "\u7406\u89e3AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u7684\u5f53\u524d\u80fd\u529b\u548c\u98ce\u9669\u5bf9\u4e8e\u786e\u4fdd\u53ef\u4fe1\u8d56\u548c\u53ef\u6301\u7eed\u7684AI\u9a71\u52a8\u79d1\u5b66\u8fdb\u6b65\u81f3\u5173\u91cd\u8981\uff0c\u540c\u65f6\u4fdd\u62a4\u5b66\u672f\u751f\u6001\u7cfb\u7edf\u7684\u5b8c\u6574\u6027\u3002", "method": "Jr. AI Scientist\u9075\u5faa\u660e\u786e\u7684\u7814\u7a76\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5229\u7528\u73b0\u4ee3\u7f16\u7801\u4ee3\u7406\u5904\u7406\u590d\u6742\u7684\u591a\u6587\u4ef6\u5b9e\u73b0\uff0c\u901a\u8fc7AI\u8bc4\u5ba1\u5458\u3001\u4f5c\u8005\u4e3b\u5bfc\u8bc4\u4f30\u548c\u5411Agents4Science\u6295\u7a3f\u8fdb\u884c\u81ea\u52a8\u5316\u8bc4\u4f30\u3002", "result": "Jr. AI Scientist\u751f\u6210\u7684\u8bba\u6587\u83b7\u5f97\u7684\u8bc4\u5ba1\u5206\u6570\u9ad8\u4e8e\u73b0\u6709\u5168\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u4f46\u4f5c\u8005\u8bc4\u4f30\u548cAgents4Science\u8bc4\u5ba1\u90fd\u53d1\u73b0\u4e86\u91cd\u8981\u5c40\u9650\u6027\u3002", "conclusion": "\u5f53\u524dAI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u5b58\u5728\u76f4\u63a5\u5e94\u7528\u7684\u98ce\u9669\u548c\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u62a5\u544a\u4e86\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u8bc6\u522b\u7684\u5404\u79cd\u98ce\u9669\u4ee5\u52a0\u6df1\u5bf9AI\u79d1\u5b66\u5bb6\u53d1\u5c55\u73b0\u72b6\u548c\u98ce\u9669\u7684\u7406\u89e3\u3002"}}
{"id": "2511.04584", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.04584", "abs": "https://arxiv.org/abs/2511.04584", "authors": ["Daniel Gomm", "Cornelius Wolff", "Madelon Hulsebos"], "title": "Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis", "comment": "Accepted to the AI for Tabular Data workshop at EurIPS 2025", "summary": "Natural language interfaces to tabular data must handle ambiguities inherent\nto queries. Instead of treating ambiguity as a deficiency, we reframe it as a\nfeature of cooperative interaction, where the responsibility of query\nspecification is shared among the user and the system. We develop a principled\nframework distinguishing cooperative queries, i.e., queries that yield a\nresolvable interpretation, from uncooperative queries that cannot be resolved.\nApplying the framework to evaluations for tabular question answering and\nanalysis, we analyze the queries in 15 popular datasets, and observe an\nuncontrolled mixing of query types neither adequate for evaluating a system's\nexecution accuracy nor for evaluating interpretation capabilities. Our\nframework and analysis of queries shifts the perspective from fixing ambiguity\nto embracing cooperation in resolving queries. This reflection enables more\ninformed design and evaluation for natural language interfaces for tabular\ndata, for which we outline implications and directions for future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u7684\u6b67\u4e49\u91cd\u65b0\u5b9a\u4e49\u4e3a\u534f\u4f5c\u4ea4\u4e92\u7684\u7279\u5f81\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u533a\u5206\u53ef\u534f\u4f5c\u67e5\u8be2\u4e0e\u4e0d\u53ef\u534f\u4f5c\u67e5\u8be2\u7684\u6846\u67b6\uff0c\u5206\u6790\u4e8615\u4e2a\u6d41\u884c\u6570\u636e\u96c6\u4e2d\u7684\u67e5\u8be2\u7c7b\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u66f4\u660e\u667a\u7684\u8868\u683c\u6570\u636e\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u8bbe\u8ba1\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u7684\u6b67\u4e49\u89c6\u4e3a\u7f3a\u9677\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u5e94\u8be5\u5c06\u5176\u91cd\u65b0\u5b9a\u4e49\u4e3a\u534f\u4f5c\u4ea4\u4e92\u7684\u7279\u5f81\uff0c\u8ba9\u7528\u6237\u548c\u7cfb\u7edf\u5171\u540c\u627f\u62c5\u67e5\u8be2\u89c4\u8303\u7684\u8d23\u4efb\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u6846\u67b6\u6765\u533a\u5206\u53ef\u534f\u4f5c\u67e5\u8be2\uff08\u53ef\u89e3\u6790\u89e3\u91ca\uff09\u548c\u4e0d\u53ef\u534f\u4f5c\u67e5\u8be2\uff08\u65e0\u6cd5\u89e3\u6790\uff09\uff0c\u5e76\u5c06\u8be5\u6846\u67b6\u5e94\u7528\u4e8e15\u4e2a\u6d41\u884c\u6570\u636e\u96c6\u7684\u8868\u683c\u95ee\u7b54\u548c\u5206\u6790\u8bc4\u4f30\u4e2d\u3002", "result": "\u5206\u6790\u53d1\u73b0\u8fd9\u4e9b\u6570\u636e\u96c6\u4e2d\u7684\u67e5\u8be2\u7c7b\u578b\u6df7\u5408\u63a7\u5236\u4e0d\u5f53\uff0c\u65e2\u4e0d\u9002\u5408\u8bc4\u4f30\u7cfb\u7edf\u6267\u884c\u51c6\u786e\u6027\uff0c\u4e5f\u4e0d\u9002\u5408\u8bc4\u4f30\u89e3\u91ca\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u548c\u5206\u6790\u5c06\u89c6\u89d2\u4ece\u4fee\u590d\u6b67\u4e49\u8f6c\u5411\u5728\u89e3\u6790\u67e5\u8be2\u4e2d\u62e5\u62b1\u534f\u4f5c\uff0c\u4e3a\u8868\u683c\u6570\u636e\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u7684\u8bbe\u8ba1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u660e\u667a\u7684\u65b9\u6cd5\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.04646", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04646", "abs": "https://arxiv.org/abs/2511.04646", "authors": ["Narjes Nourzad", "Hanqing Yang", "Shiyu Chen", "Carlee Joe-Wong"], "title": "DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration", "comment": null, "summary": "Cooperative multi-agent planning requires agents to make joint decisions with\npartial information and limited communication. Coordination at the trajectory\nlevel often fails, as small deviations in timing or movement cascade into\nconflicts. Symbolic planning mitigates this challenge by raising the level of\nabstraction and providing a minimal vocabulary of actions that enable\nsynchronization and collective progress. We present DR. WELL, a decentralized\nneurosymbolic framework for cooperative multi-agent planning. Cooperation\nunfolds through a two-phase negotiation protocol: agents first propose\ncandidate roles with reasoning and then commit to a joint allocation under\nconsensus and environment constraints. After commitment, each agent\nindependently generates and executes a symbolic plan for its role without\nrevealing detailed trajectories. Plans are grounded in execution outcomes via a\nshared world model that encodes the current state and is updated as agents act.\nBy reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids\nbrittle step-level alignment and enables higher-level operations that are\nreusable, synchronizable, and interpretable. Experiments on cooperative\nblock-push tasks show that agents adapt across episodes, with the dynamic world\nmodel capturing reusable patterns and improving task completion rates and\nefficiency. Experiments on cooperative block-push tasks show that our dynamic\nworld model improves task completion and efficiency through negotiation and\nself-refinement, trading a time overhead for evolving, more efficient\ncollaboration strategies.", "AI": {"tldr": "DR. WELL\u662f\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7528\u4e8e\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u89c4\u5212\u3002\u901a\u8fc7\u4e24\u9636\u6bb5\u534f\u5546\u534f\u8bae\uff08\u63d0\u51fa\u5019\u9009\u89d2\u8272\u548c\u627f\u8bfa\u8054\u5408\u5206\u914d\uff09\uff0c\u667a\u80fd\u4f53\u5728\u7b26\u53f7\u5c42\u9762\u800c\u975e\u8f68\u8ff9\u5c42\u9762\u8fdb\u884c\u534f\u8c03\uff0c\u907f\u514d\u4e86\u8106\u5f31\u7684\u6b65\u7ea7\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4e86\u53ef\u91cd\u7528\u3001\u53ef\u540c\u6b65\u548c\u53ef\u89e3\u91ca\u7684\u9ad8\u5c42\u64cd\u4f5c\u3002", "motivation": "\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u89c4\u5212\u4e2d\uff0c\u667a\u80fd\u4f53\u9700\u8981\u5728\u90e8\u5206\u4fe1\u606f\u548c\u6709\u9650\u901a\u4fe1\u4e0b\u505a\u51fa\u8054\u5408\u51b3\u7b56\u3002\u8f68\u8ff9\u5c42\u9762\u7684\u534f\u8c03\u7ecf\u5e38\u5931\u8d25\uff0c\u56e0\u4e3a\u65f6\u95f4\u6216\u8fd0\u52a8\u7684\u5c0f\u504f\u5dee\u4f1a\u7ea7\u8054\u6210\u51b2\u7a81\u3002\u7b26\u53f7\u89c4\u5212\u901a\u8fc7\u63d0\u9ad8\u62bd\u8c61\u7ea7\u522b\u548c\u63d0\u4f9b\u6700\u5c0f\u52a8\u4f5c\u8bcd\u6c47\u6765\u7f13\u89e3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u534f\u5546\u534f\u8bae\uff1a\u667a\u80fd\u4f53\u9996\u5148\u63d0\u51fa\u5e26\u63a8\u7406\u7684\u5019\u9009\u89d2\u8272\uff0c\u7136\u540e\u5728\u5171\u8bc6\u548c\u73af\u5883\u7ea6\u675f\u4e0b\u627f\u8bfa\u8054\u5408\u5206\u914d\u3002\u627f\u8bfa\u540e\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u72ec\u7acb\u751f\u6210\u5e76\u6267\u884c\u5176\u89d2\u8272\u7684\u7b26\u53f7\u8ba1\u5212\uff0c\u4e0d\u900f\u9732\u8be6\u7ec6\u8f68\u8ff9\u3002\u8ba1\u5212\u901a\u8fc7\u5171\u4eab\u4e16\u754c\u6a21\u578b\u5728\u6267\u884c\u7ed3\u679c\u4e2d\u843d\u5730\uff0c\u8be5\u6a21\u578b\u7f16\u7801\u5f53\u524d\u72b6\u6001\u5e76\u968f\u667a\u80fd\u4f53\u884c\u52a8\u66f4\u65b0\u3002", "result": "\u5728\u534f\u4f5c\u63a8\u5757\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u667a\u80fd\u4f53\u80fd\u591f\u8de8\u60c5\u666f\u9002\u5e94\uff0c\u52a8\u6001\u4e16\u754c\u6a21\u578b\u6355\u83b7\u53ef\u91cd\u7528\u6a21\u5f0f\uff0c\u63d0\u9ad8\u4e86\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u6548\u7387\u3002\u901a\u8fc7\u534f\u5546\u548c\u81ea\u6211\u7cbe\u70bc\uff0c\u52a8\u6001\u4e16\u754c\u6a21\u578b\u4ee5\u65f6\u95f4\u5f00\u9500\u4e3a\u4ee3\u4ef7\uff0c\u5b9e\u73b0\u4e86\u6f14\u5316\u4e14\u66f4\u9ad8\u6548\u7684\u534f\u4f5c\u7b56\u7565\u3002", "conclusion": "\u901a\u8fc7\u7b26\u53f7\u89c4\u5212\u800c\u975e\u539f\u59cb\u8f68\u8ff9\u8fdb\u884c\u63a8\u7406\uff0cDR. WELL\u907f\u514d\u4e86\u8106\u5f31\u7684\u6b65\u7ea7\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4e86\u53ef\u91cd\u7528\u3001\u53ef\u540c\u6b65\u548c\u53ef\u89e3\u91ca\u7684\u9ad8\u5c42\u64cd\u4f5c\uff0c\u63d0\u9ad8\u4e86\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u6548\u7387\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2511.04662", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04662", "abs": "https://arxiv.org/abs/2511.04662", "authors": ["Yu Feng", "Nathaniel Weir", "Kaj Bostrom", "Sam Bayless", "Darion Cassel", "Sapana Chaudhary", "Benjamin Kiesl-Reiter", "Huzefa Rangwala"], "title": "VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks", "comment": null, "summary": "LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but\nthey cannot reliably verify their own logic. Even when they reach correct\nanswers, the underlying reasoning may be flawed, undermining trust in\nhigh-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a\nneuro-symbolic method that extracts and verifies formal logical arguments from\nCoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order\nlogic and identifies premises that ground the argument in source context,\ncommonsense knowledge, or prior reasoning steps. The symbolic representation\nenables automated solvers to verify logical validity while the NL premises\nallow humans and systems to identify ungrounded or fallacious reasoning steps.\nExperiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT\neffectively identifies flawed reasoning, and serves as a strong predictor of\nfinal answer correctness. We also leverage VeriCoT's verification signal for\n(1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on\nVeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct\npreference optimization (DPO) using verification-based pairwise rewards,\nfurther improving reasoning validity and accuracy.", "AI": {"tldr": "VeriCoT\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u4eceCoT\u63a8\u7406\u4e2d\u63d0\u53d6\u5e76\u9a8c\u8bc1\u5f62\u5f0f\u903b\u8f91\u8bba\u8bc1\uff0c\u901a\u8fc7\u4e00\u9636\u903b\u8f91\u5f62\u5f0f\u5316\u63a8\u7406\u6b65\u9aa4\uff0c\u4f7f\u7528\u81ea\u52a8\u6c42\u89e3\u5668\u9a8c\u8bc1\u903b\u8f91\u6709\u6548\u6027\uff0c\u63d0\u9ad8LLM\u63a8\u7406\u7684\u53ef\u4fe1\u5ea6\u3002", "motivation": "LLMs\u901a\u8fc7\u601d\u7ef4\u94fe\u53ef\u4ee5\u8fdb\u884c\u591a\u6b65\u63a8\u7406\uff0c\u4f46\u65e0\u6cd5\u53ef\u9760\u9a8c\u8bc1\u81ea\u8eab\u903b\u8f91\u3002\u5373\u4f7f\u5f97\u51fa\u6b63\u786e\u7b54\u6848\uff0c\u5e95\u5c42\u63a8\u7406\u53ef\u80fd\u5b58\u5728\u7f3a\u9677\uff0c\u8fd9\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u524a\u5f31\u4e86\u53ef\u4fe1\u5ea6\u3002", "method": "VeriCoT\u5c06\u6bcf\u4e2aCoT\u63a8\u7406\u6b65\u9aa4\u5f62\u5f0f\u5316\u4e3a\u4e00\u9636\u903b\u8f91\uff0c\u8bc6\u522b\u57fa\u4e8e\u6e90\u4e0a\u4e0b\u6587\u3001\u5e38\u8bc6\u77e5\u8bc6\u6216\u5148\u524d\u63a8\u7406\u6b65\u9aa4\u7684\u524d\u63d0\u3002\u7b26\u53f7\u8868\u793a\u652f\u6301\u81ea\u52a8\u6c42\u89e3\u5668\u9a8c\u8bc1\u903b\u8f91\u6709\u6548\u6027\uff0c\u81ea\u7136\u8bed\u8a00\u524d\u63d0\u4fbf\u4e8e\u8bc6\u522b\u672a\u63a5\u5730\u6216\u8c2c\u8bef\u63a8\u7406\u6b65\u9aa4\u3002", "result": "\u5728ProofWriter\u3001LegalBench\u548cBioASQ\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVeriCoT\u80fd\u6709\u6548\u8bc6\u522b\u6709\u7f3a\u9677\u7684\u63a8\u7406\uff0c\u5e76\u4f5c\u4e3a\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\u7684\u5f3a\u9884\u6d4b\u6307\u6807\u3002\u5229\u7528\u9a8c\u8bc1\u4fe1\u53f7\u8fdb\u884c\u63a8\u7406\u65f6\u81ea\u6211\u53cd\u601d\u3001\u76d1\u7763\u5fae\u8c03\u548c\u504f\u597d\u5fae\u8c03\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u63a8\u7406\u6709\u6548\u6027\u548c\u51c6\u786e\u6027\u3002", "conclusion": "VeriCoT\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86LLM\u63a8\u7406\u7684\u53ef\u9a8c\u8bc1\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u4e3a\u9ad8\u98ce\u9669\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u63a8\u7406\u9a8c\u8bc1\u673a\u5236\u3002"}}
