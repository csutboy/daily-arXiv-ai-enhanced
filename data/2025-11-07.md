<div id=toc></div>

# Table of Contents

- [econ.EM](#econ.EM) [Total: 1]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.RO](#cs.RO) [Total: 21]
- [cs.AI](#cs.AI) [Total: 32]
- [cs.CY](#cs.CY) [Total: 3]
- [econ.GN](#econ.GN) [Total: 2]
- [stat.AP](#stat.AP) [Total: 4]
- [cs.ET](#cs.ET) [Total: 2]
- [econ.TH](#econ.TH) [Total: 4]
- [eess.SY](#eess.SY) [Total: 24]


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [1] [Specification tests for regression models with measurement errors](https://arxiv.org/abs/2511.04127)
*Xiaojun Song,Jichao Yuan*

Main category: econ.EM

TL;DR: 提出了针对含测量误差回归模型的新规范检验方法，基于去卷积残差标记经验过程和ICM方法，首次在测量误差规范检验中引入乘数bootstrap，并处理了已知和未知测量误差分布的情况。


<details>
  <summary>Details</summary>
Motivation: 在回归模型中，解释变量的测量误差会影响模型规范检验的有效性，现有方法在测量误差存在时表现不佳，需要开发新的检验方法。

Method: 使用去卷积核估计器构建残差，基于去卷积残差标记经验过程构造ICM型检验统计量，通过正交投影消除参数估计效应，采用乘数bootstrap模拟临界值。

Result: 蒙特卡洛模拟显示，所提出的检验方法在有限样本下对已知和未知测量误差分布都具有良好性能。

Conclusion: 成功开发了适用于含测量误差回归模型的规范检验框架，首次引入乘数bootstrap，为测量误差下的模型检验提供了有效工具。

Abstract: In this paper, we propose new specification tests for regression models with
measurement errors in the explanatory variables. Inspired by the integrated
conditional moment (ICM) approach, we use a deconvoluted residual-marked
empirical process and construct ICM-type test statistics based on it. The issue
of measurement errors is addressed by applying a deconvolution kernel estimator
in constructing the residuals. We demonstrate that employing an orthogonal
projection onto the tangent space of nuisance parameters not only eliminates
the parameter estimation effect but also facilitates the simulation of critical
values via a computationally simple multiplier bootstrap procedure. It is the
first time a multiplier bootstrap has been proposed in the literature of
specification testing with measurement errors. We also develop specification
tests and the multiplier bootstrap procedure when the measurement error
distribution is unknown. The finite-sample performance of the proposed tests
for both known and unknown measurement error distributions is evaluated through
Monte Carlo simulations, which demonstrate their efficacy.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [2] [Advancing Equitable AI: Evaluating Cultural Expressiveness in LLMs for Latin American Contexts](https://arxiv.org/abs/2511.04090)
*Brigitte A. Mora-Reyes,Jennifer A. Drewyor,Abel A. Reyes-Angulo*

Main category: cs.SI

TL;DR: 本文研究了AI系统中对拉丁美洲的文化偏见问题，提出了一个基于拉丁美洲历史文化背景的数据集，并通过实验证明微调模型可以显著提升文化表达能力。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统主要反映经济发达地区的偏见，边缘化了拉丁美洲等发展中地区的语境，特别是英语主导地位压制了西班牙语、葡萄牙语和土著语言，导致拉丁美洲视角被西方框架扭曲。

Method: 创建了基于拉丁美洲历史和社会政治背景的文化感知数据集；评估了六个语言模型的文化语境理解能力；使用文化表达性指标、统计检验和语言分析；对Mistral-7B模型进行了微调。

Result: 研究发现某些模型能更好地捕捉拉丁美洲视角，而其他模型存在显著情感偏差(p < 0.001)；微调后的Mistral-7B文化表达性提升了42.9%。

Conclusion: 倡导通过优先考虑反映拉丁美洲历史、土著知识和多样语言的数据集来促进AI公平发展，强调以社区为中心的方法来放大边缘化声音。

Abstract: Artificial intelligence (AI) systems often reflect biases from economically
advanced regions, marginalizing contexts in economically developing regions
like Latin America due to imbalanced datasets. This paper examines AI
representations of diverse Latin American contexts, revealing disparities
between data from economically advanced and developing regions. We highlight
how the dominance of English over Spanish, Portuguese, and indigenous languages
such as Quechua and Nahuatl perpetuates biases, framing Latin American
perspectives through a Western lens. To address this, we introduce a culturally
aware dataset rooted in Latin American history and socio-political contexts,
challenging Eurocentric models. We evaluate six language models on questions
testing cultural context awareness, using a novel Cultural Expressiveness
metric, statistical tests, and linguistic analyses. Our findings show that some
models better capture Latin American perspectives, while others exhibit
significant sentiment misalignment (p < 0.001). Fine-tuning Mistral-7B with our
dataset improves its cultural expressiveness by 42.9%, advancing equitable AI
development. We advocate for equitable AI by prioritizing datasets that reflect
Latin American history, indigenous knowledge, and diverse languages, while
emphasizing community-centered approaches to amplify marginalized voices.

</details>


### [3] [Launch-Day Diffusion: Tracking Hacker News Impact on GitHub Stars for AI Tools](https://arxiv.org/abs/2511.04453)
*Obada Kraishan*

Main category: cs.SI

TL;DR: 该研究构建了一个可复现的系统，追踪Hacker News曝光如何转化为GitHub星标增长，发现HN发布可为AI/LLM工具带来显著增长：24小时内平均121星，48小时内189星，一周内289星。


<details>
  <summary>Details</summary>
Motivation: 量化社交新闻平台（特别是Hacker News）对开源项目的即时影响具有挑战性，需要可复现的方法来追踪曝光到GitHub星标增长的关系。

Method: 基于公共API构建分析管道，分析138个2024-2025年仓库发布数据，使用弹性网络和梯度提升等机器学习模型识别关键预测因子。

Result: 发布时机是关键因素，在最佳时间发布可带来数百额外星标；"Show HN"标签在控制其他因素后无统计优势；系统可在5分钟内完成分析。

Conclusion: 该框架可复现且易于扩展到其他平台，为研究者和开发者提供关于发布动态的可操作见解。

Abstract: Social news platforms have become key launch outlets for open-source
projects, especially Hacker News (HN), though quantifying their immediate
impact remains challenging. This paper presents a reproducible demonstration
system that tracks how HN exposure translates into GitHub star growth for AI
and LLM tools. Built entirely on public APIs, our pipeline analyzes 138
repository launches from 2024-2025 and reveals substantial launch effects:
repositories gain an average of 121 stars within 24 hours, 189 stars within 48
hours, and 289 stars within a week of HN exposure. Through machine learning
models (Elastic Net) and non-linear approaches (Gradient Boosting), we identify
key predictors of viral growth. Posting timing appears as key factor--launching
at optimal hours can mean hundreds of additional stars--while the "Show HN" tag
shows no statistical advantage after controlling for other factors. The
demonstration completes in under five minutes on standard hardware,
automatically collecting data, training models, and generating visualizations
through single-file scripts. This makes our findings immediately reproducible
and the framework easily be extended to other platforms, providing both
researchers and developers with actionable insights into launch dynamics.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [4] [Dynamic Shape Control of Soft Robots Enabled by Data-Driven Model Reduction](https://arxiv.org/abs/2511.03931)
*Iman Adibnazari,Harsh Sharma,Myungsun Park,Jacobo Cervera-Torralba,Boris Kramer,Michael T. Tolley*

Main category: cs.RO

TL;DR: 本文比较了三种数据驱动模型降阶技术（ERA、DMDc和LOpInf）在软体机器人动态形状控制中的应用，发现基于LOpInf方法的控制器在所有实验中都能产生最低的跟踪误差。


<details>
  <summary>Details</summary>
Motivation: 软体机器人需要能够处理高维动态的控制器，但缺乏适用于控制的通用建模工具，因此需要研究数据驱动的模型降阶方法来生成适合动态形状控制的线性模型。

Method: 使用三种数据驱动模型降阶技术（特征系统实现算法、带控制的动态模态分解和拉格朗日算子推断方法）生成线性模型，并在模拟的鳗鱼启发的软体机器人上进行模型预测控制实验。

Result: 在所有三个实验中（跟踪保证可行的模拟参考轨迹、跟踪基于鳗鱼运动学生物模型生成的参考轨迹、跟踪由缩小物理模拟器生成的参考轨迹），基于LOpInf方法的控制策略产生的跟踪误差均低于基于其他模型的策略。

Conclusion: LOpInf方法在软体机器人动态形状控制中表现最佳，为软体机器人的高维动态控制提供了一种有效的模型降阶解决方案。

Abstract: Soft robots have shown immense promise in settings where they can leverage
dynamic control of their entire bodies. However, effective dynamic shape
control requires a controller that accounts for the robot's high-dimensional
dynamics--a challenge exacerbated by a lack of general-purpose tools for
modeling soft robots amenably for control. In this work, we conduct a
comparative study of data-driven model reduction techniques for generating
linear models amendable to dynamic shape control. We focus on three
methods--the eigensystem realization algorithm, dynamic mode decomposition with
control, and the Lagrangian operator inference (LOpInf) method. Using each
class of model, we explored their efficacy in model predictive control policies
for the dynamic shape control of a simulated eel-inspired soft robot in three
experiments: 1) tracking simulated reference trajectories guaranteed to be
feasible, 2) tracking reference trajectories generated from a biological model
of eel kinematics, and 3) tracking reference trajectories generated by a
reduced-scale physical analog. In all experiments, the LOpInf-based policies
generated lower tracking errors than policies based on other models.

</details>


### [5] [Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots](https://arxiv.org/abs/2511.03996)
*Yushi Wang,Changsheng Luo,Penghui Chen,Jianran Liu,Weijian Sun,Tong Guo,Kechang Yang,Biao Hu,Yangang Zhang,Mingguo Zhao*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的统一控制器，通过视觉感知与运动控制的直接集成，使人形机器人获得反应式足球技能。


<details>
  <summary>Details</summary>
Motivation: 现有系统通常依赖解耦模块，导致动态环境中响应延迟和行为不连贯，而现实世界的感知限制进一步加剧了这些问题。

Method: 扩展Adversarial Motion Priors到现实动态环境的感知设置，结合编码器-解码器架构和虚拟感知系统，从有缺陷的观察中恢复特权状态，建立感知与动作的主动协调。

Result: 控制器表现出强大的反应能力，在各种场景（包括真实RoboCup比赛）中持续执行连贯且稳健的足球行为。

Conclusion: 该方法成功实现了视觉感知与运动控制的统一，为人形机器人在动态环境中的反应式行为控制提供了有效解决方案。

Abstract: Humanoid soccer poses a representative challenge for embodied intelligence,
requiring robots to operate within a tightly coupled perception-action loop.
However, existing systems typically rely on decoupled modules, resulting in
delayed responses and incoherent behaviors in dynamic environments, while
real-world perceptual limitations further exacerbate these issues. In this
work, we present a unified reinforcement learning-based controller that enables
humanoid robots to acquire reactive soccer skills through the direct
integration of visual perception and motion control. Our approach extends
Adversarial Motion Priors to perceptual settings in real-world dynamic
environments, bridging motion imitation and visually grounded dynamic control.
We introduce an encoder-decoder architecture combined with a virtual perception
system that models real-world visual characteristics, allowing the policy to
recover privileged states from imperfect observations and establish active
coordination between perception and action. The resulting controller
demonstrates strong reactivity, consistently executing coherent and robust
soccer behaviors across various scenarios, including real RoboCup matches.

</details>


### [6] [Integrating Ergonomics and Manipulability for Upper Limb Postural Optimization in Bimanual Human-Robot Collaboration](https://arxiv.org/abs/2511.04009)
*Chenzui Li,Yiming Chen,Xi Wu,Giacinto Barresi,Fei Chen*

Main category: cs.RO

TL;DR: 提出一种上肢姿态优化方法，用于提升双人/人机协同搬运任务中的物理工效学和力操纵能力，通过优化关节角度和机器人末端执行器姿态来同时保障安全性和操作效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常只关注人类安全或操作效率，而该方法独特地将这两个方面整合，以加强在不同条件下的协作能力（如不同的人类抓握姿势和物体形状）。

Method: 通过最小化代价函数优化简化人体骨骼模型的关节角度，优先考虑安全性和操纵能力；通过变换模块生成机器人末端执行器的参考姿态；提出双模型预测阻抗控制器（MPIC）来重新校准末端执行器姿态。

Result: 在人类-人类协作（HHC）和人类-机器人协作（HRC）中通过多个受试者和物体进行了验证，实验结果显示目标肌肉激活状态在优化前后有显著改善。

Conclusion: 该方法显著改善了肌肉状况，证明了在双人/人机协同搬运任务中同时优化安全性和操作效率的有效性。

Abstract: This paper introduces an upper limb postural optimization method for
enhancing physical ergonomics and force manipulability during bimanual
human-robot co-carrying tasks. Existing research typically emphasizes human
safety or manipulative efficiency, whereas our proposed method uniquely
integrates both aspects to strengthen collaboration across diverse conditions
(e.g., different grasping postures of humans, and different shapes of objects).
Specifically, the joint angles of a simplified human skeleton model are
optimized by minimizing the cost function to prioritize safety and manipulative
capability. To guide humans towards the optimized posture, the reference
end-effector poses of the robot are generated through a transformation module.
A bimanual model predictive impedance controller (MPIC) is proposed for our
human-like robot, CURI, to recalibrate the end effector poses through planned
trajectories. The proposed method has been validated through various subjects
and objects during human-human collaboration (HHC) and human-robot
collaboration (HRC). The experimental results demonstrate significant
improvement in muscle conditions by comparing the activation of target muscles
before and after optimization.

</details>


### [7] [An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster Search and Rescue](https://arxiv.org/abs/2511.04042)
*Kailun Ji,Xiaoyu Hu,Xinyu Zhang,Jun Chen*

Main category: cs.RO

TL;DR: 提出LLM-CRF系统，利用大语言模型增强人机协作认知，通过自然交互捕捉操作员意图，自动分解任务规划无人机群行动，显著提升搜救效率。


<details>
  <summary>Details</summary>
Motivation: 解决大规模灾难搜救中人机协作的"意图到行动差距"问题，传统无人机群协调给操作员带来巨大认知负担，需要更直观高效的人机交互方式。

Method: 构建LLM-CRF框架，通过语音或图形标注多模态交互捕捉操作员意图，使用LLM作为认知引擎进行意图理解、分层任务分解和任务规划，形成闭环反馈系统。

Result: 在模拟搜救场景中，相比传统命令接口，任务完成时间减少64.2%，任务成功率提高7%，NASA-TLX认知负荷评分下降42.9%。

Conclusion: LLM能够创建更直观有效的人机协作系统，在高风险场景中具有巨大潜力，显著提升搜救任务效能。

Abstract: Large-scale disaster Search And Rescue (SAR) operations are persistently
challenged by complex terrain and disrupted communications. While Unmanned
Aerial Vehicle (UAV) swarms offer a promising solution for tasks like wide-area
search and supply delivery, yet their effective coordination places a
significant cognitive burden on human operators. The core human-machine
collaboration bottleneck lies in the ``intention-to-action gap'', which is an
error-prone process of translating a high-level rescue objective into a
low-level swarm command under high intensity and pressure. To bridge this gap,
this study proposes a novel LLM-CRF system that leverages Large Language Models
(LLMs) to model and augment human-swarm teaming cognition. The proposed
framework initially captures the operator's intention through natural and
multi-modal interactions with the device via voice or graphical annotations. It
then employs the LLM as a cognitive engine to perform intention comprehension,
hierarchical task decomposition, and mission planning for the UAV swarm. This
closed-loop framework enables the swarm to act as a proactive partner,
providing active feedback in real-time while reducing the need for manual
monitoring and control, which considerably advances the efficacy of the SAR
task. We evaluate the proposed framework in a simulated SAR scenario.
Experimental results demonstrate that, compared to traditional order and
command-based interfaces, the proposed LLM-driven approach reduced task
completion time by approximately $64.2\%$ and improved task success rate by
$7\%$. It also leads to a considerable reduction in subjective cognitive
workload, with NASA-TLX scores dropping by $42.9\%$. This work establishes the
potential of LLMs to create more intuitive and effective human-swarm
collaborations in high-stakes scenarios.

</details>


### [8] [Enhancing Fault-Tolerant Space Computing: Guidance Navigation and Control (GNC) and Landing Vision System (LVS) Implementations on Next-Gen Multi-Core Processors](https://arxiv.org/abs/2511.04052)
*Kyongsik Yun,David Bayard,Gerik Kubiak,Austin Owens,Andrew Johnson,Ryan Johnson,Dan Scharf,Thomas Lu*

Main category: cs.RO

TL;DR: 本文评估了下一代多核处理器在行星探索任务中的性能表现，展示了LVS图像处理15倍加速和GFOLD轨迹优化250倍加速，并提出了ARBITER故障检测机制确保计算可靠性。


<details>
  <summary>Details</summary>
Motivation: 未来行星探索任务需要高性能、容错的计算能力来实现自主的制导导航控制和着陆视觉系统操作，特别是在进入、下降和着陆阶段。

Method: 在HPSC、Snapdragon VOXL2和AMD Xilinx Versal等多核处理器上部署GNC和LVS算法，并开发ARBITER多核投票机制进行实时故障检测和校正。

Result: LVS图像处理获得15倍加速，GFOLD轨迹优化获得超过250倍加速；故障注入研究发现GFOLD中的梯度计算阶段对位级错误最敏感。

Conclusion: 这项工作为包括火星样本返回、土卫二轨道着陆器和谷神星样本返回在内的未来任务建立了可扩展且节能的架构，其中机载自主性、低延迟和容错能力至关重要。

Abstract: Future planetary exploration missions demand high-performance, fault-tolerant
computing to enable autonomous Guidance, Navigation, and Control (GNC) and
Lander Vision System (LVS) operations during Entry, Descent, and Landing (EDL).
This paper evaluates the deployment of GNC and LVS algorithms on
next-generation multi-core processors--HPSC, Snapdragon VOXL2, and AMD Xilinx
Versal--demonstrating up to 15x speedup for LVS image processing and over 250x
speedup for Guidance for Fuel-Optimal Large Divert (GFOLD) trajectory
optimization compared to legacy spaceflight hardware. To ensure computational
reliability, we present ARBITER (Asynchronous Redundant Behavior Inspection for
Trusted Execution and Recovery), a Multi-Core Voting (MV) mechanism that
performs real-time fault detection and correction across redundant cores.
ARBITER is validated in both static optimization tasks (GFOLD) and dynamic
closed-loop control (Attitude Control System). A fault injection study further
identifies the gradient computation stage in GFOLD as the most sensitive to
bit-level errors, motivating selective protection strategies and vector-based
output arbitration. This work establishes a scalable and energy-efficient
architecture for future missions, including Mars Sample Return, Enceladus
Orbilander, and Ceres Sample Return, where onboard autonomy, low latency, and
fault resilience are critical.

</details>


### [9] [CBMC-V3: A CNS-inspired Control Framework Towards Manipulation Agility with SNN](https://arxiv.org/abs/2511.04109)
*Yanbo Pang,Qingkai Li,Mingguo Zhao*

Main category: cs.RO

TL;DR: 提出了一种基于脉冲神经网络的仿生控制框架，模仿人类中枢神经系统，用于机器臂在复杂环境中的敏捷控制。


<details>
  <summary>Details</summary>
Motivation: 随着机器臂应用扩展到医疗、服务和日常生活领域，现有控制算法难以在具有动态轨迹、不可预测交互和多样化对象的复杂环境中实现敏捷操作。

Method: 构建了包含五个控制模块（大脑皮层、小脑、丘脑、脑干、脊髓）、三个控制层级和两条信息通路的仿生控制框架，所有模块均使用脉冲神经网络实现。

Result: 在仿真和真实机器臂平台上验证，结果表明该方法在操作敏捷性方面优于工业级位置控制。

Conclusion: 基于脉冲神经网络的仿生控制框架能够有效提升机器臂在复杂环境中的控制性能，实现更敏捷的操作。

Abstract: As robotic arm applications extend beyond industrial settings into
healthcare, service, and daily life, existing control algorithms struggle to
achieve the agile manipulation required for complex environments with dynamic
trajectories, unpredictable interactions, and diverse objects. This paper
presents a biomimetic control framework based on Spiking Neural Networks (SNN),
inspired by the human Central Nervous System (CNS), to achieve agile control in
such environments. The proposed framework features five control modules
(cerebral cortex, cerebellum, thalamus, brainstem, spinal cord), three
hierarchical control levels (first-order, second-order, third-order), and two
information pathways (ascending, descending). Each module is fully implemented
using SNN. The spinal cord module uses spike encoding and Leaky
Integrate-and-Fire (LIF) neurons for feedback control. The brainstem module
employs a network of LIF and non-spiking LIF neurons to dynamically adjust
spinal cord parameters via reinforcement learning. The thalamus module
similarly adjusts the cerebellum's torque outputs. The cerebellum module uses a
recurrent SNN to learn the robotic arm's dynamics through regression, providing
feedforward gravity compensation torques. The framework is validated both in
simulation and on real-world robotic arm platform under various loads and
trajectories. Results demonstrate that our method outperforms the
industrial-grade position control in manipulation agility.

</details>


### [10] [BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning](https://arxiv.org/abs/2511.04131)
*Yitang Li,Zhengyi Luo,Tonghe Zhang,Cunxi Dai,Anssi Kanervisto,Andrea Tirinzoni,Haoyang Weng,Kris Kitani,Mateusz Guzek,Ahmed Touati,Alessandro Lazaric,Matteo Pirotta,Guanya Shi*

Main category: cs.RO

TL;DR: BFM-Zero是一个用于人形机器人的行为基础模型框架，通过共享潜在表示统一多种控制任务，支持零样本运动跟踪、目标到达和奖励优化，以及少样本优化适应。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么仅部署在模拟人形角色上，要么专门针对特定任务（如跟踪），缺乏统一的多任务控制策略。

Method: 基于无监督强化学习和前向-后向模型，构建共享潜在表示空间，嵌入运动、目标和奖励，结合关键奖励塑造、领域随机化和历史依赖非对称学习来弥合模拟到现实的差距。

Result: 在真实世界的Unitree G1人形机器人上实现了多功能和鲁棒的全身体技能，通过定量消融实验验证了关键设计选择的有效性。

Conclusion: BFM-Zero为全身体人形控制的可扩展、可提示行为基础模型迈出了重要一步。

Abstract: Building Behavioral Foundation Models (BFMs) for humanoid robots has the
potential to unify diverse control tasks under a single, promptable generalist
policy. However, existing approaches are either exclusively deployed on
simulated humanoid characters, or specialized to specific tasks such as
tracking. We propose BFM-Zero, a framework that learns an effective shared
latent representation that embeds motions, goals, and rewards into a common
space, enabling a single policy to be prompted for multiple downstream tasks
without retraining. This well-structured latent space in BFM-Zero enables
versatile and robust whole-body skills on a Unitree G1 humanoid in the real
world, via diverse inference methods, including zero-shot motion tracking, goal
reaching, and reward optimization, and few-shot optimization-based adaptation.
Unlike prior on-policy reinforcement learning (RL) frameworks, BFM-Zero builds
upon recent advancements in unsupervised RL and Forward-Backward (FB) models,
which offer an objective-centric, explainable, and smooth latent representation
of whole-body motions. We further extend BFM-Zero with critical reward shaping,
domain randomization, and history-dependent asymmetric learning to bridge the
sim-to-real gap. Those key design choices are quantitatively ablated in
simulation. A first-of-its-kind model, BFM-Zero establishes a step toward
scalable, promptable behavioral foundation models for whole-body humanoid
control.

</details>


### [11] [PUL-SLAM: Path-Uncertainty Co-Optimization with Lightweight Stagnation Detection for Efficient Robotic Exploration](https://arxiv.org/abs/2511.04180)
*Yizhen Yin,Dapeng Feng,Hongbo Chen,Yuhua Qi*

Main category: cs.RO

TL;DR: 提出了一种结合路径-不确定性协同优化深度强化学习和轻量级停滞检测机制的混合框架，显著提升了主动SLAM的探索效率和路径质量。


<details>
  <summary>Details</summary>
Motivation: 现有主动SLAM方法存在探索速度慢和路径次优的问题，需要一种能够同时优化路径距离和地图不确定性的解决方案。

Method: 采用路径-不确定性协同优化深度强化学习框架，通过双目标奖励函数平衡探索与利用；结合轻量级停滞检测机制，通过激光雷达静态异常检测和地图更新停滞检测减少冗余探索。

Result: 相比前沿方法和RRT方法，探索时间缩短65%，路径距离减少42%，在复杂环境中显著提升探索效率，同时保持可靠的地图完整性。

Conclusion: 该混合框架有效解决了主动SLAM的探索效率和路径优化问题，通过仿真到实物的验证证明了算法的实用性和可迁移性。

Abstract: Existing Active SLAM methodologies face issues such as slow exploration speed
and suboptimal paths. To address these limitations, we propose a hybrid
framework combining a Path-Uncertainty Co-Optimization Deep Reinforcement
Learning framework and a Lightweight Stagnation Detection mechanism. The
Path-Uncertainty Co-Optimization framework jointly optimizes travel distance
and map uncertainty through a dual-objective reward function, balancing
exploration and exploitation. The Lightweight Stagnation Detection reduces
redundant exploration through Lidar Static Anomaly Detection and Map Update
Stagnation Detection, terminating episodes on low expansion rates. Experimental
results show that compared with the frontier-based method and RRT method, our
approach shortens exploration time by up to 65% and reduces path distance by up
to 42%, significantly improving exploration efficiency in complex environments
while maintaining reliable map completeness. Ablation studies confirm that the
collaborative mechanism accelerates training convergence. Empirical validation
on a physical robotic platform demonstrates the algorithm's practical
applicability and its successful transferability from simulation to real-world
environments.

</details>


### [12] [GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments](https://arxiv.org/abs/2511.04199)
*Shenglin Wang,Mingtong Dai,Jingxuan Su,Lingbo Liu,Chunjie Chen,Xinyu Wu,Liang Lin*

Main category: cs.RO

TL;DR: GraspView是一个仅使用RGB相机的机器人抓取系统，在杂乱环境中无需深度传感器即可实现精确操作，特别在遮挡、透明物体和近距离感知等挑战性场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统基于RGB-D相机的抓取系统在透明/反光物体上会失效，且在近距离感知时性能下降。需要开发仅使用RGB相机的可靠抓取方案来克服这些限制。

Method: 集成三个关键组件：全局感知场景重建（从单RGB视图生成局部一致几何）、渲染评分主动感知策略（动态选择最佳视角揭示遮挡区域）、在线度量对齐模块（校准抓取预测与机器人运动学）。

Result: 在多样化桌面物体上的实验表明，GraspView显著优于RGB-D和单视图RGB基线方法，特别是在严重遮挡、近距离感知和透明物体场景中。

Conclusion: GraspView作为RGB-D管道的实用替代方案，能够在非结构化真实环境中实现可靠的抓取操作。

Abstract: Robotic grasping is a fundamental capability for autonomous manipulation, yet
remains highly challenging in cluttered environments where occlusion, poor
perception quality, and inconsistent 3D reconstructions often lead to unstable
or failed grasps. Conventional pipelines have widely relied on RGB-D cameras to
provide geometric information, which fail on transparent or glossy objects and
degrade at close range. We present GraspView, an RGB-only robotic grasping
pipeline that achieves accurate manipulation in cluttered environments without
depth sensors. Our framework integrates three key components: (i) global
perception scene reconstruction, which provides locally consistent, up-to-scale
geometry from a single RGB view and fuses multi-view projections into a
coherent global 3D scene; (ii) a render-and-score active perception strategy,
which dynamically selects next-best-views to reveal occluded regions; and (iii)
an online metric alignment module that calibrates VGGT predictions against
robot kinematics to ensure physical scale consistency. Building on these
tailor-designed modules, GraspView performs best-view global grasping, fusing
multi-view reconstructions and leveraging GraspNet for robust execution.
Experiments on diverse tabletop objects demonstrate that GraspView
significantly outperforms both RGB-D and single-view RGB baselines, especially
under heavy occlusion, near-field sensing, and with transparent objects. These
results highlight GraspView as a practical and versatile alternative to RGB-D
pipelines, enabling reliable grasping in unstructured real-world environments.

</details>


### [13] [Can Context Bridge the Reality Gap? Sim-to-Real Transfer of Context-Aware Policies](https://arxiv.org/abs/2511.04249)
*Marco Iannotta,Yuxuan Yang,Johannes A. Stork,Erik Schaffernicht,Todor Stoyanov*

Main category: cs.RO

TL;DR: 该论文提出在基于域随机化的强化学习框架中集成上下文估计模块，通过让策略感知环境动态参数来改进模拟到现实的迁移性能。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在机器人领域中的模拟到现实迁移问题，传统域随机化方法虽然能提高泛化性但会降低性能，因此研究是否通过让策略感知动态参数上下文可以改进迁移效果。

Method: 在基于域随机化的强化学习框架中集成上下文估计模块，系统比较了最先进的监督策略，让策略能够基于估计的动态参数进行决策。

Result: 在标准控制基准和真实世界Franka Emika Panda机器人推动任务中的评估显示，上下文感知策略在所有设置中都优于上下文无关的基线方法，但最佳监督策略取决于具体任务。

Conclusion: 上下文感知策略能够有效改进模拟到现实的迁移性能，但需要根据具体任务选择适当的监督策略。

Abstract: Sim-to-real transfer remains a major challenge in reinforcement learning (RL)
for robotics, as policies trained in simulation often fail to generalize to the
real world due to discrepancies in environment dynamics. Domain Randomization
(DR) mitigates this issue by exposing the policy to a wide range of randomized
dynamics during training, yet leading to a reduction in performance. While
standard approaches typically train policies agnostic to these variations, we
investigate whether sim-to-real transfer can be improved by conditioning the
policy on an estimate of the dynamics parameters -- referred to as context. To
this end, we integrate a context estimation module into a DR-based RL framework
and systematically compare SOTA supervision strategies. We evaluate the
resulting context-aware policies in both a canonical control benchmark and a
real-world pushing task using a Franka Emika Panda robot. Results show that
context-aware policies outperform the context-agnostic baseline across all
settings, although the best supervision strategy depends on the task.

</details>


### [14] [Design and Control of a Coaxial Dual-rotor Reconfigurable Tailsitter UAV Based on Swashplateless Mechanism](https://arxiv.org/abs/2511.04251)
*Jinfeng Liang,Haocheng Guo,Ximin Lyu*

Main category: cs.RO

TL;DR: 本文提出了一种可重构机翼的尾坐式垂直起降无人机，采用同轴异构双旋翼配置和无斜盘机构，通过优化设计实现了在悬停和固定翼模式下的高效稳定飞行。


<details>
  <summary>Details</summary>
Motivation: 传统尾坐式无人机在多旋翼模式下由于暴露较大机身面积而容易受到风扰，需要解决其抗风性和功率效率问题。

Method: 设计可伸缩机翼结构，采用同轴异构双旋翼配置降低功耗，使用改进的无斜盘机构控制俯仰和滚转，并添加挥舞铰链优化结构减少振动。

Result: 通过全面的过渡飞行测试验证了无人机在整个飞行包线内的稳定飞行性能。

Conclusion: 所提出的可重构机翼尾坐式无人机设计有效解决了风扰问题，同时实现了功率效率和结构简化，具有良好的飞行稳定性。

Abstract: The tailsitter vertical takeoff and landing (VTOL) UAV is widely used due to
its lower dead weight, which eliminates the actuators and mechanisms for
tilting. However, the tailsitter UAV is susceptible to wind disturbances in
multi-rotor mode, as it exposes a large frontal fuselage area. To address this
issue, our tailsitter UAV features a reconfigurable wing design, allowing wings
to retract in multi-rotor mode and extend in fixed- wing mode. Considering
power efficiency, we design a coaxial heterogeneous dual-rotor configuration,
which significantly re- duces the total power consumption. To reduce structural
weight and simplify structural complexity, we employ a swashplateless mechanism
with an improved design to control pitch and roll in multi-rotor mode. We
optimize the structure of the swashplateless mechanism by adding flapping
hinges, which reduces vibration during cyclic acceleration and deceleration.
Finally, we perform comprehensive transition flight tests to validate stable
flight performance across the entire flight envelope of the tailsitter UAV.

</details>


### [15] [MacroNav: Multi-Task Context Representation Learning Enables Efficient Navigation in Unknown Environments](https://arxiv.org/abs/2511.04320)
*Kuankuan Sima,Longbin Tang,Haozhe Ma,Lin Zhao*

Main category: cs.RO

TL;DR: MacroNav是一个基于学习的导航框架，通过轻量级上下文编码器和强化学习策略，在未知环境中实现高效导航，显著提升了成功率和路径效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在丰富的上下文表示和导航效率之间取得平衡，自主导航需要在不完全观测下实现紧凑而表达力强的空间理解。

Method: 包含两个关键组件：(1) 通过多任务自监督学习训练的轻量级上下文编码器，捕捉多尺度导航中心空间表示；(2) 强化学习策略，将这些表示与基于图的推理无缝集成以进行高效动作选择。

Result: 实验证明上下文编码器具有高效和鲁棒的环境理解能力。真实世界部署验证了MacroNav的有效性，在成功率和路径长度加权成功率方面显著优于现有导航方法，同时保持低计算成本。

Conclusion: MacroNav框架在未知环境导航中实现了上下文表示与导航效率的良好平衡，为自主导航提供了有效的解决方案。

Abstract: Autonomous navigation in unknown environments requires compact yet expressive
spatial understanding under partial observability to support high-level
decision making. Existing approaches struggle to balance rich contextual
representation with navigation efficiency. We present MacroNav, a
learning-based navigation framework featuring two key components: (1) a
lightweight context encoder trained via multi-task self-supervised learning to
capture multi-scale, navigation-centric spatial representations; and (2) a
reinforcement learning policy that seamlessly integrates these representations
with graph-based reasoning for efficient action selection. Extensive
experiments demonstrate the context encoder's efficient and robust
environmental understanding. Real-world deployments further validate MacroNav's
effectiveness, yielding significant gains over state-of-the-art navigation
methods in both Success Rate (SR) and Success weighted by Path Length (SPL),
while maintaining low computational cost. Code will be released upon
acceptance.

</details>


### [16] [GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies](https://arxiv.org/abs/2511.04357)
*Maëlic Neau,Zoe Falomir,Paulo E. Santos,Anne-Gwenn Bosser,Cédric Buche*

Main category: cs.RO

TL;DR: GraSP-VLA是一个神经符号方法，使用连续场景图表示来生成人类演示的符号表示，用于推理时生成新的规划域，并作为低级VLA策略的协调器，提高连续执行动作的能力。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案中，端到端模仿学习的VLA模型缺乏高级符号规划能力，难以处理长期任务；而符号方法的AML缺乏泛化性和可扩展性。需要结合两者优势的新方法。

Method: 使用连续场景图表示生成人类演示的符号表示，在推理时生成新的规划域，并作为低级VLA策略的协调器。

Result: GraSP-VLA在自动规划域生成任务中有效建模符号表示，真实世界实验显示连续场景图表示在协调长期任务中的低级VLA策略方面具有潜力。

Conclusion: GraSP-VLA框架成功结合了神经和符号方法的优势，能够有效处理长期任务并提高动作序列的扩展性。

Abstract: Deploying autonomous robots that can learn new skills from demonstrations is
an important challenge of modern robotics. Existing solutions often apply
end-to-end imitation learning with Vision-Language Action (VLA) models or
symbolic approaches with Action Model Learning (AML). On the one hand, current
VLA models are limited by the lack of high-level symbolic planning, which
hinders their abilities in long-horizon tasks. On the other hand, symbolic
approaches in AML lack generalization and scalability perspectives. In this
paper we present a new neuro-symbolic approach, GraSP-VLA, a framework that
uses a Continuous Scene Graph representation to generate a symbolic
representation of human demonstrations. This representation is used to generate
new planning domains during inference and serves as an orchestrator for
low-level VLA policies, scaling up the number of actions that can be reproduced
in a row. Our results show that GraSP-VLA is effective for modeling symbolic
representations on the task of automatic planning domain generation from
observations. In addition, results on real-world experiments show the potential
of our Continuous Scene Graph representation to orchestrate low-level VLA
policies in long-horizon tasks.

</details>


### [17] [Studying the Effect of Explicit Interaction Representations on Learning Scene-level Distributions of Human Trajectories](https://arxiv.org/abs/2511.04375)
*Anna Mészáros,Javier Alonso-Mora,Jens Kober*

Main category: cs.RO

TL;DR: 本文研究了在自动驾驶场景中，如何最佳地表示智能体之间的交互关系以捕捉其联合分布。研究发现，让网络基于数据隐式学习交互连接通常对性能有害，而明确定义的交互（如确定哪个智能体在交叉口优先通过）能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 有效捕捉场景中所有智能体的联合分布对于预测场景的真实演变和为自动驾驶决策提供更准确信息至关重要。目前对于如何最佳表示智能体间交互尚无共识——是通过神经网络隐式学习，还是使用更贴近人类决策的时空关系进行显式建模。

Method: 在同一网络结构中研究不同交互描述方式及其对最终学习到的联合分布的影响。比较了隐式学习交互连接和明确定义交互（如确定交叉口优先通过权）两种方法。

Result: 研究发现，让网络基于数据隐式建立智能体间交互连接通常对性能产生负面影响。相反，具有明确定义的交互（如确定智能体对中哪个优先通过交叉口）往往能带来明显的性能提升。

Conclusion: 明确定义的交互建模方法优于隐式学习的方法，在自动驾驶场景的联合分布预测中能带来更好的性能表现。

Abstract: Effectively capturing the joint distribution of all agents in a scene is
relevant for predicting the true evolution of the scene and in turn providing
more accurate information to the decision processes of autonomous vehicles.
While new models have been developed for this purpose in recent years, it
remains unclear how to best represent the joint distributions particularly from
the perspective of the interactions between agents. Thus far there is no clear
consensus on how best to represent interactions between agents; whether they
should be learned implicitly from data by neural networks, or explicitly
modeled using the spatial and temporal relations that are more grounded in
human decision-making. This paper aims to study various means of describing
interactions within the same network structure and their effect on the final
learned joint distributions. Our findings show that more often than not, simply
allowing a network to establish interactive connections between agents based on
data has a detrimental effect on performance. Instead, having well defined
interactions (such as which agent of an agent pair passes first at an
intersection) can often bring about a clear boost in performance.

</details>


### [18] [ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation](https://arxiv.org/abs/2511.04381)
*Dexin wang,Faliang Chang,Chunsheng Liu*

Main category: cs.RO

TL;DR: ForeRobo是一个生成式机器人代理，通过生成模拟自主获取操作技能，结合生成范式与经典控制，实现零样本模拟到真实环境的迁移。


<details>
  <summary>Details</summary>
Motivation: 高效利用模拟获取高级操作技能具有挑战性但意义重大，现有端到端策略学习方法缺乏可解释性和执行效率。

Method: 采用自引导的"提议-生成-学习-执行"循环：提议技能并构建模拟环境，生成技能一致的目标状态(ForeGen)，训练状态生成模型(ForeFormer)预测3D目标位置，最后使用经典控制算法驱动真实机器人。

Result: 在多种刚体和关节物体操作任务中，ForeFormer相比最先进的状态生成模型平均提升56.32%，在20多个真实机器人任务中实现79.28%的平均成功率。

Conclusion: ForeRobo展示了生成模拟与经典控制结合的有效性，具有优越的可解释性、执行效率和泛化能力，成功实现零样本模拟到真实环境的迁移。

Abstract: Efficiently leveraging simulation to acquire advanced manipulation skills is
both challenging and highly significant. We introduce \textit{ForeRobo}, a
generative robotic agent that utilizes generative simulations to autonomously
acquire manipulation skills driven by envisioned goal states. Instead of
directly learning low-level policies, we advocate integrating generative
paradigms with classical control. Our approach equips a robotic agent with a
self-guided \textit{propose-generate-learn-actuate} cycle. The agent first
proposes the skills to be acquired and constructs the corresponding simulation
environments; it then configures objects into appropriate arrangements to
generate skill-consistent goal states (\textit{ForeGen}). Subsequently, the
virtually infinite data produced by ForeGen are used to train the proposed
state generation model (\textit{ForeFormer}), which establishes point-wise
correspondences by predicting the 3D goal position of every point in the
current state, based on the scene state and task instructions. Finally,
classical control algorithms are employed to drive the robot in real-world
environments to execute actions based on the envisioned goal states. Compared
with end-to-end policy learning methods, ForeFormer offers superior
interpretability and execution efficiency. We train and benchmark ForeFormer
across a variety of rigid-body and articulated-object manipulation tasks, and
observe an average improvement of 56.32\% over the state-of-the-art state
generation models, demonstrating strong generality across different
manipulation patterns. Moreover, in real-world evaluations involving more than
20 robotic tasks, ForeRobo achieves zero-shot sim-to-real transfer and exhibits
remarkable generalization capabilities, attaining an average success rate of
79.28\%.

</details>


### [19] [Temporal Action Selection for Action Chunking](https://arxiv.org/abs/2511.04421)
*Yueyang Weng,Xiaopeng Zhang,Yongjin Mu,Yingcong Zhu,Yanjie Li,Qi Liu*

Main category: cs.RO

TL;DR: 提出了一种名为TAS的新算法，通过缓存多个时间步的预测动作块并使用轻量级选择器网络动态选择最优动作，解决了动作分块方法在反应性、决策一致性和运动连贯性之间的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 动作分块方法虽然增强了建模能力，但降低了决策频率，限制了近期观察的利用，导致反应性下降，特别是在适应传感器噪声和动态环境变化方面表现不足。现有方法无法同时实现反应性和决策一致性。

Method: TAS算法缓存多个时间步预测的动作块，通过轻量级选择器网络动态选择最优动作。该方法可与残差强化学习结合使用。

Result: 在多个任务和不同基础策略的实验中，TAS显著提高了成功率，绝对增益高达73.3%。与残差强化学习结合后，训练效率大幅提升，性能上限也得到提高。仿真和物理机器人实验均验证了方法的有效性。

Conclusion: TAS算法成功解决了动作分块方法在反应性、决策一致性和运动连贯性之间的平衡问题，显著提升了学习效果和训练效率。

Abstract: Action chunking is a widely adopted approach in Learning from Demonstration
(LfD). By modeling multi-step action chunks rather than single-step actions,
action chunking significantly enhances modeling capabilities for human expert
policies. However, the reduced decision frequency restricts the utilization of
recent observations, degrading reactivity - particularly evident in the
inadequate adaptation to sensor noise and dynamic environmental changes.
Existing efforts to address this issue have primarily resorted to trading off
reactivity against decision consistency, without achieving both. To address
this limitation, we propose a novel algorithm, Temporal Action Selector (TAS),
which caches predicted action chunks from multiple timesteps and dynamically
selects the optimal action through a lightweight selector network. TAS achieves
balanced optimization across three critical dimensions: reactivity, decision
consistency, and motion coherence. Experiments across multiple tasks with
diverse base policies show that TAS significantly improves success rates -
yielding an absolute gain of up to 73.3%. Furthermore, integrating TAS as a
base policy with residual reinforcement learning (RL) substantially enhances
training efficiency and elevates the performance plateau. Experiments in both
simulation and physical robots confirm the method's efficacy.

</details>


### [20] [Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment](https://arxiv.org/abs/2511.04555)
*Tao Lin,Yilei Zhong,Yuxin Du,Jingjing Zhang,Jiting Liu,Yinxinyu Chen,Encheng Gu,Ziyan Liu,Hongyi Cai,Yanwen Zou,Lixing Zou,Zhaoye Zhou,Gen Li,Bo Zhao*

Main category: cs.RO

TL;DR: Evo-1是一个轻量级的视觉-语言-动作模型，通过新颖的跨调制扩散变换器和优化的集成模块，在仅0.77B参数下实现了最先进的性能，无需机器人数据预训练，显著提升了部署效率。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型参数量大、依赖大规模机器人数据预训练，导致计算成本高、实时推理部署困难，且训练范式会损害视觉-语言骨干网络的感知表示，导致过拟合和泛化能力差。

Method: 基于原生多模态视觉-语言模型，引入跨调制扩散变换器和优化集成模块，采用两阶段训练范式逐步对齐动作与感知，保留VLM表示。

Result: 在Meta-World和RoboTwin套件上分别超越之前最佳模型12.4%和6.9%，在LIBERO上达到94.8%的竞争性结果，真实世界评估中达到78%成功率，具有高推理频率和低内存开销。

Conclusion: Evo-1证明了轻量级VLA模型的可行性，在保持高性能的同时显著提升了部署效率，为轻量高效VLA模型研究提供了新方向。

Abstract: Vision-Language-Action (VLA) models have emerged as a powerful framework that
unifies perception, language, and control, enabling robots to perform diverse
tasks through multimodal understanding. However, current VLA models typically
contain massive parameters and rely heavily on large-scale robot data
pretraining, leading to high computational costs during training, as well as
limited deployability for real-time inference. Moreover, most training
paradigms often degrade the perceptual representations of the vision-language
backbone, resulting in overfitting and poor generalization to downstream tasks.
In this work, we present Evo-1, a lightweight VLA model that reduces
computation and improves deployment efficiency, while maintaining strong
performance without pretraining on robot data. Evo-1 builds on a native
multimodal Vision-Language model (VLM), incorporating a novel cross-modulated
diffusion transformer along with an optimized integration module, together
forming an effective architecture. We further introduce a two-stage training
paradigm that progressively aligns action with perception, preserving the
representations of the VLM. Notably, with only 0.77 billion parameters, Evo-1
achieves state-of-the-art results on the Meta-World and RoboTwin suite,
surpassing the previous best models by 12.4% and 6.9%, respectively, and also
attains a competitive result of 94.8% on LIBERO. In real-world evaluations,
Evo-1 attains a 78% success rate with high inference frequency and low memory
overhead, outperforming all baseline methods. We release code, data, and model
weights to facilitate future research on lightweight and efficient VLA models.

</details>


### [21] [SAFe-Copilot: Unified Shared Autonomy Framework](https://arxiv.org/abs/2511.04664)
*Phat Nguyen,Erfan Aasi,Shiva Sreeram,Guy Rosman,Andrew Silva,Sertac Karaman,Daniela Rus*

Main category: cs.RO

TL;DR: 提出了一种基于视觉语言模型的共享自动驾驶框架，通过语义层面的仲裁来整合人类输入和自主规划，在模糊和罕见场景中改善系统性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在罕见、模糊和分布外场景中表现脆弱，而人类驾驶员能通过上下文推理成功应对。现有方法局限于低层轨迹仲裁，无法保持驾驶意图。

Method: 利用视觉语言模型从多模态线索（如驾驶员动作和环境上下文）推断驾驶意图，在语义层面进行人类与自主控制之间的策略合成与仲裁。

Result: 在模拟人类设置中实现完美召回率和高精度；人类主体调查显示92%的参与者同意仲裁结果；在Bench2Drive基准测试中显著降低碰撞率并提升整体性能。

Conclusion: 基于语义、语言表示的仲裁是共享自动驾驶的关键设计原则，使系统能够运用常识推理并保持与人类意图的连续性。

Abstract: Autonomous driving systems remain brittle in rare, ambiguous, and
out-of-distribution scenarios, where human driver succeed through contextual
reasoning. Shared autonomy has emerged as a promising approach to mitigate such
failures by incorporating human input when autonomy is uncertain. However, most
existing methods restrict arbitration to low-level trajectories, which
represent only geometric paths and therefore fail to preserve the underlying
driving intent. We propose a unified shared autonomy framework that integrates
human input and autonomous planners at a higher level of abstraction. Our
method leverages Vision Language Models (VLMs) to infer driver intent from
multi-modal cues -- such as driver actions and environmental context -- and to
synthesize coherent strategies that mediate between human and autonomous
control. We first study the framework in a mock-human setting, where it
achieves perfect recall alongside high accuracy and precision. A human-subject
survey further shows strong alignment, with participants agreeing with
arbitration outcomes in 92% of cases. Finally, evaluation on the Bench2Drive
benchmark demonstrates a substantial reduction in collision rate and
improvement in overall performance compared to pure autonomy. Arbitration at
the level of semantic, language-based representations emerges as a design
principle for shared autonomy, enabling systems to exercise common-sense
reasoning and maintain continuity with human intent.

</details>


### [22] [Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions](https://arxiv.org/abs/2511.04665)
*Kaifeng Zhang,Shuo Sha,Hanxiao Jiang,Matthew Loper,Hyunjong Song,Guangyan Cai,Zhuo Xu,Xiaochen Hu,Changxi Zheng,Yunzhu Li*

Main category: cs.RO

TL;DR: 提出了一个基于真实世界视频构建软体数字孪生的真实到仿真策略评估框架，使用3D高斯泼溅实现逼真渲染，用于评估机器人操作策略。


<details>
  <summary>Details</summary>
Motivation: 真实世界中直接评估机器人操作策略成本高、耗时长且难以复现，特别是涉及可变形物体的任务。现有模拟器难以捕捉软体交互的视觉和物理复杂性。

Method: 从真实世界视频构建软体数字孪生，使用3D高斯泼溅技术渲染机器人、物体和环境，实现照片级真实感。

Result: 在代表性可变形操作任务（毛绒玩具打包、绳子布线、T形块推动）上验证，模拟运行与现实执行性能高度相关，并能揭示学习策略的关键行为模式。

Conclusion: 将物理信息重建与高质量渲染相结合，能够实现可重复、可扩展且准确的机器人操作策略评估。

Abstract: Robotic manipulation policies are advancing rapidly, but their direct
evaluation in the real world remains costly, time-consuming, and difficult to
reproduce, particularly for tasks involving deformable objects. Simulation
provides a scalable and systematic alternative, yet existing simulators often
fail to capture the coupled visual and physical complexity of soft-body
interactions. We present a real-to-sim policy evaluation framework that
constructs soft-body digital twins from real-world videos and renders robots,
objects, and environments with photorealistic fidelity using 3D Gaussian
Splatting. We validate our approach on representative deformable manipulation
tasks, including plush toy packing, rope routing, and T-block pushing,
demonstrating that simulated rollouts correlate strongly with real-world
execution performance and reveal key behavioral patterns of learned policies.
Our results suggest that combining physics-informed reconstruction with
high-quality rendering enables reproducible, scalable, and accurate evaluation
of robotic manipulation policies. Website: https://real2sim-eval.github.io/

</details>


### [23] [X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations](https://arxiv.org/abs/2511.04671)
*Maximus A. Pace,Prithwish Dan,Chuanruo Ning,Atiksh Bhardwaj,Audrey Du,Edward W. Duan,Wei-Chiu Ma,Kushal Kedia*

Main category: cs.RO

TL;DR: X-Diffusion是一个利用人类视频训练机器人策略的框架，通过扩散过程处理动作执行差异，在保持高层任务指导的同时避免学习不可行的机器人动作。


<details>
  <summary>Details</summary>
Motivation: 人类视频数据丰富易得，但人类和机器人的动作执行存在根本差异，直接运动重定向会产生物理上不可行的动作。需要一种方法既能利用人类数据的有价值运动线索，又避免学习不可行的低层动作。

Method: X-Diffusion训练一个分类器预测噪声动作是由人类还是机器人执行，然后在策略训练中只使用添加足够噪声的人类动作（此时分类器无法区分执行主体）。与机器人执行一致的动作在低噪声水平下监督精细去噪，不匹配的人类动作仅在高噪声水平下提供粗略指导。

Result: 实验表明，在动作执行不匹配的情况下，简单的共同训练会降低策略性能，而X-Diffusion能持续提升性能。在五个操作任务中，X-Diffusion比最佳基线实现了16%的平均成功率提升。

Conclusion: X-Diffusion提供了一个原则性框架，能够最大化利用人类数据训练扩散策略，同时避免学习动态不可行的动作，有效解决了人类-机器人动作执行差异的问题。

Abstract: Human videos can be recorded quickly and at scale, making them an appealing
source of training data for robot learning. However, humans and robots differ
fundamentally in embodiment, resulting in mismatched action execution. Direct
kinematic retargeting of human hand motion can therefore produce actions that
are physically infeasible for robots. Despite these low-level differences,
human demonstrations provide valuable motion cues about how to manipulate and
interact with objects. Our key idea is to exploit the forward diffusion
process: as noise is added to actions, low-level execution differences fade
while high-level task guidance is preserved. We present X-Diffusion, a
principled framework for training diffusion policies that maximally leverages
human data without learning dynamically infeasible motions. X-Diffusion first
trains a classifier to predict whether a noisy action is executed by a human or
robot. Then, a human action is incorporated into policy training only after
adding sufficient noise such that the classifier cannot discern its embodiment.
Actions consistent with robot execution supervise fine-grained denoising at low
noise levels, while mismatched human actions provide only coarse guidance at
higher noise levels. Our experiments show that naive co-training under
execution mismatches degrades policy performance, while X-Diffusion
consistently improves it. Across five manipulation tasks, X-Diffusion achieves
a 16% higher average success rate than the best baseline. The project website
is available at https://portal-cornell.github.io/X-Diffusion/.

</details>


### [24] [GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction](https://arxiv.org/abs/2511.04679)
*Qingzhou Lu,Yao Feng,Baiyu Shi,Michael Piseno,Zhenan Bao,C. Karen Liu*

Main category: cs.RO

TL;DR: GentleHumanoid框架将阻抗控制集成到全身运动跟踪策略中，实现上半身柔顺性，通过统一的弹簧模型处理阻力和引导接触，在保持任务成功率的同时显著降低接触力。


<details>
  <summary>Details</summary>
Motivation: 人形机器人需要在以人为中心的环境中安全自然地物理交互，但现有强化学习策略过于强调刚性跟踪而抑制外力，现有阻抗控制方法局限于基座或末端控制且主要关注抵抗极端力而非实现柔顺性。

Method: 提出GentleHumanoid框架，核心是统一的弹簧模型，同时建模阻力接触（按压表面时的恢复力）和引导接触（从人类运动数据采样的推拉动作），确保肩、肘、腕的动力学一致性力，并通过任务可调力阈值保证安全。

Result: 在仿真和Unitree G1人形机器人上评估，在需要不同柔顺性水平的任务中（轻柔拥抱、坐站辅助、安全物体操作），相比基线方法，该策略在保持任务成功率的同时持续降低峰值接触力，实现更平滑自然的交互。

Conclusion: 该研究向能够安全有效与人类协作并在真实环境中处理物体的人形机器人迈出了一步，展示了柔顺交互的重要性。

Abstract: Humanoid robots are expected to operate in human-centered environments where
safe and natural physical interaction is essential. However, most recent
reinforcement learning (RL) policies emphasize rigid tracking and suppress
external forces. Existing impedance-augmented approaches are typically
restricted to base or end-effector control and focus on resisting extreme
forces rather than enabling compliance. We introduce GentleHumanoid, a
framework that integrates impedance control into a whole-body motion tracking
policy to achieve upper-body compliance. At its core is a unified spring-based
formulation that models both resistive contacts (restoring forces when pressing
against surfaces) and guiding contacts (pushes or pulls sampled from human
motion data). This formulation ensures kinematically consistent forces across
the shoulder, elbow, and wrist, while exposing the policy to diverse
interaction scenarios. Safety is further supported through task-adjustable
force thresholds. We evaluate our approach in both simulation and on the
Unitree G1 humanoid across tasks requiring different levels of compliance,
including gentle hugging, sit-to-stand assistance, and safe object
manipulation. Compared to baselines, our policy consistently reduces peak
contact forces while maintaining task success, resulting in smoother and more
natural interactions. These results highlight a step toward humanoid robots
that can safely and effectively collaborate with humans and handle objects in
real-world environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [25] [Scaling Agent Learning via Experience Synthesis](https://arxiv.org/abs/2511.03773)
*Zhaorun Chen,Zhuokai Zhao,Kai Zhang,Bo Liu,Qi Qi,Yifan Wu,Tarun Kalluri,Sara Cao,Yuanhao Xiong,Haibo Tong,Huaxiu Yao,Hengduo Li,Jiacheng Zhu,Xian Li,Dawn Song,Bo Li,Jason Weston,Dat Huynh*

Main category: cs.AI

TL;DR: DreamGym是一个统一的框架，通过基于推理的经验模型合成多样化经验数据，解决RL训练中成本高、任务多样性有限、奖励信号不可靠等问题，显著提升自主代理的在线强化学习训练效果。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在大语言模型代理中实际应用的挑战，包括昂贵的环境交互、有限的任务多样性、不可靠的奖励信号和基础设施复杂性，这些因素阻碍了可扩展经验数据的收集。

Method: 将环境动态提炼为基于推理的经验模型，通过逐步推理推导一致的状态转换和反馈信号；利用经验回放缓冲区初始化离线真实世界数据并持续丰富；自适应生成挑战当前代理策略的新任务。

Result: 在多样化环境和代理骨干上的实验表明，DreamGym显著改善了RL训练。在WebArena等非RL就绪任务上，性能超过所有基线30%以上；在RL就绪但成本高的设置中，仅使用合成交互就能匹配GRPO和PPO性能；在纯合成经验训练的策略转移到真实环境RL时，获得显著额外性能提升，同时需要更少的真实世界交互。

Conclusion: DreamGym为通用强化学习提供了一个可扩展的热启动策略，通过合成经验数据有效解决了RL训练中的可扩展性问题，在多种场景下都取得了优异表现。

Abstract: While reinforcement learning (RL) can empower large language model (LLM)
agents by enabling self-improvement through interaction, its practical adoption
remains challenging due to costly rollouts, limited task diversity, unreliable
reward signals, and infrastructure complexity, all of which obstruct the
collection of scalable experience data. To address these challenges, we
introduce DreamGym, the first unified framework designed to synthesize diverse
experiences with scalability in mind to enable effective online RL training for
autonomous agents. Rather than relying on expensive real-environment rollouts,
DreamGym distills environment dynamics into a reasoning-based experience model
that derives consistent state transitions and feedback signals through
step-by-step reasoning, enabling scalable agent rollout collection for RL. To
improve the stability and quality of transitions, DreamGym leverages an
experience replay buffer initialized with offline real-world data and
continuously enriched with fresh interactions to actively support agent
training. To improve knowledge acquisition, DreamGym adaptively generates new
tasks that challenge the current agent policy, enabling more effective online
curriculum learning. Experiments across diverse environments and agent
backbones demonstrate that DreamGym substantially improves RL training, both in
fully synthetic settings and in sim-to-real transfer scenarios. On non-RL-ready
tasks like WebArena, DreamGym outperforms all baselines by over 30%. And in
RL-ready but costly settings, it matches GRPO and PPO performance using only
synthetic interactions. When transferring a policy trained purely on synthetic
experiences to real-environment RL, DreamGym yields significant additional
performance gains while requiring far fewer real-world interactions, providing
a scalable warm-start strategy for general-purpose RL.

</details>


### [26] [How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis](https://arxiv.org/abs/2511.03825)
*Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder*

Main category: cs.AI

TL;DR: 本文评估了NLP分词模型在汇编代码分析中的内在特性，包括词汇量大小、语义覆盖等，并研究了其对下游任务（如函数签名预测）的影响。


<details>
  <summary>Details</summary>
Motivation: 汇编代码分析中的分词技术研究不足，但其对词汇量大小、语义覆盖和下游任务性能有重要影响，需要系统评估。

Method: 使用多种分词模型（如Llama 3.2、BERT、BART），通过内在评估比较分词效率、词汇压缩和表示保真度，并在下游任务中验证效果。

Result: 分词器选择显著影响下游性能，内在指标只能部分预测外在评估结果，揭示了内在特性与实际效用之间的复杂权衡。

Conclusion: 本研究为优化低层代码分析的分词模型提供了宝贵见解，有助于提升基于自然语言模型的二进制分析工作流程的鲁棒性和可扩展性。

Abstract: Tokenization is fundamental in assembly code analysis, impacting intrinsic
characteristics like vocabulary size, semantic coverage, and extrinsic
performance in downstream tasks. Despite its significance, tokenization in the
context of assembly code remains an underexplored area. This study aims to
address this gap by evaluating the intrinsic properties of Natural Language
Processing (NLP) tokenization models and parameter choices, such as vocabulary
size. We explore preprocessing customization options and pre-tokenization rules
tailored to the unique characteristics of assembly code. Additionally, we
assess their impact on downstream tasks like function signature prediction -- a
critical problem in binary code analysis.
  To this end, we conduct a thorough study on various tokenization models,
systematically analyzing their efficiency in encoding assembly instructions and
capturing semantic nuances. Through intrinsic evaluations, we compare
tokenizers based on tokenization efficiency, vocabulary compression, and
representational fidelity for assembly code. Using state-of-the-art pre-trained
models such as the decoder-only Large Language Model (LLM) Llama 3.2, the
encoder-only transformer BERT, and the encoder-decoder model BART, we evaluate
the effectiveness of these tokenizers across multiple performance metrics.
Preliminary findings indicate that tokenizer choice significantly influences
downstream performance, with intrinsic metrics providing partial but incomplete
predictability of extrinsic evaluation outcomes. These results reveal complex
trade-offs between intrinsic tokenizer properties and their utility in
practical assembly code tasks. Ultimately, this study provides valuable
insights into optimizing tokenization models for low-level code analysis,
contributing to the robustness and scalability of Natural Language Model
(NLM)-based binary analysis workflows.

</details>


### [27] [To See or To Read: User Behavior Reasoning in Multimodal LLMs](https://arxiv.org/abs/2511.03845)
*Tianning Dong,Luyi Ma,Varun Vasudevan,Jason Cho,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: BehaviorLens框架系统评估了用户行为数据在文本和图像表示下对多模态大语言模型性能的影响，发现图像表示能将下一个购买预测准确率提升87.5%。


<details>
  <summary>Details</summary>
Motivation: 探索文本和图像两种用户行为数据表示方式对多模态大语言模型性能的影响，以确定哪种表示方式能最大化模型表现。

Method: 开发BehaviorLens基准测试框架，在六个MLLM上评估三种数据表示方式：文本段落、散点图和流程图，使用真实购买序列数据集。

Result: 当数据表示为图像时，MLLM的下一个购买预测准确率比等效文本表示提高了87.5%，且无需额外计算成本。

Conclusion: 图像表示在用户行为推理任务中显著优于文本表示，为优化MLLM性能提供了重要指导。

Abstract: Multimodal Large Language Models (MLLMs) are reshaping how modern agentic
systems reason over sequential user-behavior data. However, whether textual or
image representations of user behavior data are more effective for maximizing
MLLM performance remains underexplored. We present \texttt{BehaviorLens}, a
systematic benchmarking framework for assessing modality trade-offs in
user-behavior reasoning across six MLLMs by representing transaction data as
(1) a text paragraph, (2) a scatter plot, and (3) a flowchart. Using a
real-world purchase-sequence dataset, we find that when data is represented as
images, MLLMs next-purchase prediction accuracy is improved by 87.5% compared
with an equivalent textual representation without any additional computational
cost.

</details>


### [28] [Question the Questions: Auditing Representation in Online Deliberative Processes](https://arxiv.org/abs/2511.04588)
*Soham De,Lodewijk Gelauff,Ashish Goel,Smitha Milli,Ariel Procaccia,Alice Siu*

Main category: cs.AI

TL;DR: 提出了一个基于合理代表(JR)概念的审计框架，用于评估专家问答环节中问题选择的代表性，并开发了高效的审计算法。


<details>
  <summary>Details</summary>
Motivation: 在公民大会等审议过程中，参与者只能向专家提出有限数量的问题，需要确保所选问题能够充分代表所有参与者的利益。

Method: 引入基于合理代表(JR)概念的审计框架，开发O(mn log n)时间复杂度的审计算法，比较了主持人选择、整数线性规划选择和LLM生成问题三种方法。

Result: 应用审计方法分析历史审议数据，揭示了LLM在支持审议过程中的潜力和当前局限性。

Conclusion: 通过将审计方法集成到在线审议平台，使实践者能够轻松审计和改进未来审议中的代表性。

Abstract: A central feature of many deliberative processes, such as citizens'
assemblies and deliberative polls, is the opportunity for participants to
engage directly with experts. While participants are typically invited to
propose questions for expert panels, only a limited number can be selected due
to time constraints. This raises the challenge of how to choose a small set of
questions that best represent the interests of all participants. We introduce
an auditing framework for measuring the level of representation provided by a
slate of questions, based on the social choice concept known as justified
representation (JR). We present the first algorithms for auditing JR in the
general utility setting, with our most efficient algorithm achieving a runtime
of $O(mn\log n)$, where $n$ is the number of participants and $m$ is the number
of proposed questions. We apply our auditing methods to historical
deliberations, comparing the representativeness of (a) the actual questions
posed to the expert panel (chosen by a moderator), (b) participants' questions
chosen via integer linear programming, (c) summary questions generated by large
language models (LLMs). Our results highlight both the promise and current
limitations of LLMs in supporting deliberative processes. By integrating our
methods into an online deliberation platform that has been used for over
hundreds of deliberations across more than 50 countries, we make it easy for
practitioners to audit and improve representation in future deliberations.

</details>


### [29] [KnowThyself: An Agentic Assistant for LLM Interpretability](https://arxiv.org/abs/2511.03878)
*Suraj Prasai,Mengnan Du,Ying Zhang,Fan Yang*

Main category: cs.AI

TL;DR: KnowThyself是一个基于聊天的LLM可解释性工具，通过整合现有碎片化功能，提供自然语言交互和可视化解释，降低技术门槛。


<details>
  <summary>Details</summary>
Motivation: 现有LLM可解释性工具功能分散且需要编程，技术门槛高，需要统一的易用平台。

Method: 使用编排器LLM重新表述用户查询，通过代理路由器分发到专门模块，最后将输出整合为连贯解释。

Result: 开发了可扩展的LLM检查平台，嵌入对话式工作流程，提供强大的可访问性基础。

Conclusion: KnowThyself通过整合碎片化工具和降低技术门槛，为LLM可解释性提供了稳健的基础平台。

Abstract: We develop KnowThyself, an agentic assistant that advances large language
model (LLM) interpretability. Existing tools provide useful insights but remain
fragmented and code-intensive. KnowThyself consolidates these capabilities into
a chat-based interface, where users can upload models, pose natural language
questions, and obtain interactive visualizations with guided explanations. At
its core, an orchestrator LLM first reformulates user queries, an agent router
further directs them to specialized modules, and the outputs are finally
contextualized into coherent explanations. This design lowers technical
barriers and provides an extensible platform for LLM inspection. By embedding
the whole process into a conversational workflow, KnowThyself offers a robust
foundation for accessible LLM interpretability.

</details>


### [30] [Extracting Causal Relations in Deep Knowledge Tracing](https://arxiv.org/abs/2511.03948)
*Kevin Hong,Kia Karbasi,Gregory Pottie*

Main category: cs.AI

TL;DR: 本文挑战了关于深度知识追踪(DKT)性能提升源于双向关系建模的传统解释，提出DKT的真正优势在于其隐式建模先决条件因果结构的能力。


<details>
  <summary>Details</summary>
Motivation: 长期以来，计算教育研究的目标是开发可解释的知识追踪模型。DKT作为传统KT方法的重大进步，其性能提升原因存在争议，需要澄清其真正的工作原理。

Method: 通过将练习关系图修剪为有向无环图(DAG)，在Assistments数据集的因果子集上训练DKT，并使用DKT学习表示提取练习关系DAG的替代方法。

Result: 实验表明DKT的预测能力与因果结构高度一致，其学习表示可用于有效提取练习关系DAG，支持DKT通过近似KC间因果依赖关系而非简单关系映射发挥作用的论点。

Conclusion: DKT的有效性主要源于其近似知识组件间因果依赖关系的能力，而非传统认为的双向关系建模，这为理解DKT工作机制提供了新视角。

Abstract: A longstanding goal in computational educational research is to develop
explainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which
leverages a Recurrent Neural Network (RNN) to predict student knowledge and
performance on exercises, has been proposed as a major advancement over
traditional KT methods. Several studies suggest that its performance gains stem
from its ability to model bidirectional relationships between different
knowledge components (KCs) within a course, enabling the inference of a
student's understanding of one KC from their performance on others. In this
paper, we challenge this prevailing explanation and demonstrate that DKT's
strength lies in its implicit ability to model prerequisite relationships as a
causal structure, rather than bidirectional relationships. By pruning exercise
relation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal
subsets of the Assistments dataset, we show that DKT's predictive capabilities
align strongly with these causal structures. Furthermore, we propose an
alternative method for extracting exercise relation DAGs using DKT's learned
representations and provide empirical evidence supporting our claim. Our
findings suggest that DKT's effectiveness is largely driven by its capacity to
approximate causal dependencies between KCs rather than simple relational
mappings.

</details>


### [31] [LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing](https://arxiv.org/abs/2511.03980)
*Bram Bulté,Ayla Rigouts Terryn*

Main category: cs.AI

TL;DR: 本研究探讨了大型语言模型（LLMs）如何回应不同文化和语言提示，发现虽然提示语言和文化框架能影响模型输出，但LLMs仍存在系统性偏见，倾向于荷兰、德国、美国和日本的价值观。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在全球范围内被广泛使用，但训练数据和优化目标存在不平衡，引发了对LLMs是否能代表其广泛用户群文化多样性的质疑。

Method: 使用来自霍夫斯泰德价值观调查模块和世界价值观调查的63个项目，翻译成11种语言，以带有和不带有明确文化视角的提示形式测试10个LLMs。

Result: 提示语言和文化视角都会导致LLM输出变化，但模型存在系统性偏见，偏向特定国家的价值观。明确文化视角比针对性提示语言更能改善与人类受访者文化价值观的一致性。

Conclusion: LLMs处于一个尴尬的中间地带：它们对提示变化足够敏感以产生变化，但又过于固守特定文化默认值，无法充分代表文化多样性。

Abstract: Large Language Models (LLMs) are rapidly being adopted by users across the
globe, who interact with them in a diverse range of languages. At the same
time, there are well-documented imbalances in the training data and
optimisation objectives of this technology, raising doubts as to whether LLMs
can represent the cultural diversity of their broad user base. In this study,
we look at LLMs and cultural values and examine how prompt language and
cultural framing influence model responses and their alignment with human
values in different countries. We probe 10 LLMs with 63 items from the Hofstede
Values Survey Module and World Values Survey, translated into 11 languages, and
formulated as prompts with and without different explicit cultural
perspectives. Our study confirms that both prompt language and cultural
perspective produce variation in LLM outputs, but with an important caveat:
While targeted prompting can, to a certain extent, steer LLM responses in the
direction of the predominant values of the corresponding countries, it does not
overcome the models' systematic bias toward the values associated with a
restricted set of countries in our dataset: the Netherlands, Germany, the US,
and Japan. All tested models, regardless of their origin, exhibit remarkably
similar patterns: They produce fairly neutral responses on most topics, with
selective progressive stances on issues such as social tolerance. Alignment
with cultural values of human respondents is improved more with an explicit
cultural perspective than with a targeted prompt language. Unexpectedly,
combining both approaches is no more effective than cultural framing with an
English prompt. These findings reveal that LLMs occupy an uncomfortable middle
ground: They are responsive enough to changes in prompts to produce variation,
but too firmly anchored to specific cultural defaults to adequately represent
cultural diversity.

</details>


### [32] [ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning Engineering](https://arxiv.org/abs/2511.03985)
*Zhuowen Yuan,Tao Liu,Yang Yang,Yang Wang,Feng Qi,Kaushik Rangadurai,Bo Li,Shuang Yang*

Main category: cs.AI

TL;DR: ArchPilot是一个多代理系统，通过集成架构生成、基于代理的评估和自适应搜索来解决LLM代理在ML工程中依赖重复完整训练的高计算成本问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在自动化ML工程中严重依赖重复的完整训练来评估候选方案，导致计算开销大、搜索空间扩展性差和迭代周期慢。

Method: ArchPilot包含三个专业代理：协调搜索过程的编排代理、迭代生成改进架构的生成代理、执行代理训练和优化代理函数的评估代理，采用MCTS启发算法和重启机制。

Result: 在MLE-Bench上的实验表明，ArchPilot超越了AIDE和ML-Master等SOTA基线，验证了多代理系统的有效性。

Conclusion: ArchPilot通过多代理协作，在有限预算下优先考虑高潜力候选方案，最小化对昂贵完整训练的依赖，实现了高效的ML工程。

Abstract: Recent LLM-based agents have demonstrated strong capabilities in automated ML
engineering. However, they heavily rely on repeated full training runs to
evaluate candidate solutions, resulting in significant computational overhead,
limited scalability to large search spaces, and slow iteration cycles. To
address these challenges, we introduce ArchPilot, a multi-agent system that
integrates architecture generation, proxy-based evaluation, and adaptive search
into a unified framework. ArchPilot consists of three specialized agents: an
orchestration agent that coordinates the search process using a Monte Carlo
Tree Search (MCTS)-inspired novel algorithm with a restart mechanism and
manages memory of previous candidates; a generation agent that iteratively
generates, improves, and debugs candidate architectures; and an evaluation
agent that executes proxy training runs, generates and optimizes proxy
functions, and aggregates the proxy scores into a fidelity-aware performance
metric. This multi-agent collaboration allows ArchPilot to prioritize
high-potential candidates with minimal reliance on expensive full training
runs, facilitating efficient ML engineering under limited budgets. Experiments
on MLE-Bench demonstrate that ArchPilot outperforms SOTA baselines such as AIDE
and ML-Master, validating the effectiveness of our multi-agent system.

</details>


### [33] [Detecting Silent Failures in Multi-Agentic AI Trajectories](https://arxiv.org/abs/2511.04032)
*Divya Pathak,Harshit Kumar,Anuska Roy,Felix George,Mudit Verma,Pratibha Moogi*

Main category: cs.AI

TL;DR: 提出了多智能体AI系统中异常检测的任务，创建了两个包含4,275和894条轨迹的数据集，并展示了监督和半监督方法能达到98%和96%的准确率。


<details>
  <summary>Details</summary>
Motivation: 多智能体AI系统具有非确定性，容易发生漂移、循环和输出细节缺失等难以检测的静默故障。

Method: 开发了数据收集流程来捕捉用户行为、智能体非确定性和LLM变化，并创建了两个基准数据集。

Result: 在基准测试中，监督方法(XGBoost)和半监督方法(SVDD)分别达到98%和96%的准确率。

Conclusion: 这是首个系统研究多智能体AI系统中异常检测的工作，提供了数据集、基准和见解来指导未来研究。

Abstract: Multi-Agentic AI systems, powered by large language models (LLMs), are
inherently non-deterministic and prone to silent failures such as drift,
cycles, and missing details in outputs, which are difficult to detect. We
introduce the task of anomaly detection in agentic trajectories to identify
these failures and present a dataset curation pipeline that captures user
behavior, agent non-determinism, and LLM variation. Using this pipeline, we
curate and label two benchmark datasets comprising \textbf{4,275 and 894}
trajectories from Multi-Agentic AI systems. Benchmarking anomaly detection
methods on these datasets, we show that supervised (XGBoost) and
semi-supervised (SVDD) approaches perform comparably, achieving accuracies up
to 98% and 96%, respectively. This work provides the first systematic study of
anomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks,
and insights to guide future research.

</details>


### [34] [Interpreting Multi-Attribute Confounding through Numerical Attributes in Large Language Models](https://arxiv.org/abs/2511.04053)
*Hirohane Takagi,Gouki Minegishi,Shota Kizawa,Issey Sukeda,Hitomi Yanaka*

Main category: cs.AI

TL;DR: LLMs在数值推理中存在系统性错误，研究发现它们会放大真实世界数值相关性，且无关上下文会干扰数值表示，这种影响随模型规模变化。


<details>
  <summary>Details</summary>
Motivation: 尽管行为研究已记录LLMs的数值推理错误，但其底层表征机制尚不明确。研究旨在探索LLMs如何整合实体多个数值属性，以及无关数值上下文如何干扰这些表示。

Method: 结合线性探测与偏相关分析，以及基于提示的脆弱性测试，在不同规模的模型上进行实验。

Result: LLMs编码了真实世界的数值相关性但会系统性放大它们；无关上下文会导致数值表示的一致偏移，下游影响随模型规模而异。

Conclusion: 这些发现揭示了LLM决策中的脆弱性，为在多属性纠缠下实现更公平、表征感知的控制奠定了基础。

Abstract: Although behavioral studies have documented numerical reasoning errors in
large language models (LLMs), the underlying representational mechanisms remain
unclear. We hypothesize that numerical attributes occupy shared latent
subspaces and investigate two questions:(1) How do LLMs internally integrate
multiple numerical attributes of a single entity? (2)How does irrelevant
numerical context perturb these representations and their downstream outputs?
To address these questions, we combine linear probing with partial correlation
analysis and prompt-based vulnerability tests across models of varying sizes.
Our results show that LLMs encode real-world numerical correlations but tend to
systematically amplify them. Moreover, irrelevant context induces consistent
shifts in magnitude representations, with downstream effects that vary by model
size. These findings reveal a vulnerability in LLM decision-making and lay the
groundwork for fairer, representation-aware control under multi-attribute
entanglement.

</details>


### [35] [Agentmandering: A Game-Theoretic Framework for Fair Redistricting via Large Language Model Agents](https://arxiv.org/abs/2511.04076)
*Hao Li,Haotian Chen,Ruoyuan Gong,Juanjuan Wang,Hao Jiang*

Main category: cs.AI

TL;DR: 提出了Agentmandering框架，将选区重划重新构想为两个代表对立政治利益的智能体之间的回合制谈判，通过LLM智能体将战略互动嵌入到选区重划过程中，显著减少党派偏见和不公平性。


<details>
  <summary>Details</summary>
Motivation: 现有计算方法主要生成大量合法选区重划方案，但忽视了选择过程中的战略动态，这为党派行为者挑选技术上合规但政治上有利的地图创造了机会。仅仅满足形式约束无法确保公平性。

Method: 采用基于博弈论思想的回合制谈判框架，两个LLM智能体代表对立政治利益，轮流从少量候选地图中选择和冻结选区，通过受约束且可解释的选择逐步划分州。

Result: 在2020年美国人口普查数据上的评估显示，Agentmandering显著减少了党派偏见和不公平性，方差比标准基线低2-3个数量级，在摇摆州场景中表现出公平性和稳定性。

Conclusion: Agentmandering框架通过将战略互动嵌入选区重划过程，有效解决了选择过程中的操纵问题，为公平的选区重划提供了新方法。

Abstract: Redistricting plays a central role in shaping how votes are translated into
political power. While existing computational methods primarily aim to generate
large ensembles of legally valid districting plans, they often neglect the
strategic dynamics involved in the selection process. This oversight creates
opportunities for partisan actors to cherry-pick maps that, while technically
compliant, are politically advantageous. Simply satisfying formal constraints
does not ensure fairness when the selection process itself can be manipulated.
We propose \textbf{Agentmandering}, a framework that reimagines redistricting
as a turn-based negotiation between two agents representing opposing political
interests. Drawing inspiration from game-theoretic ideas, particularly the
\textit{Choose-and-Freeze} protocol, our method embeds strategic interaction
into the redistricting process via large language model (LLM) agents. Agents
alternate between selecting and freezing districts from a small set of
candidate maps, gradually partitioning the state through constrained and
interpretable choices. Evaluation on post-2020 U.S. Census data across all
states shows that Agentmandering significantly reduces partisan bias and
unfairness, while achieving 2 to 3 orders of magnitude lower variance than
standard baselines. These results demonstrate both fairness and stability,
especially in swing-state scenarios. Our code is available at
https://github.com/Lihaogx/AgentMandering.

</details>


### [36] [KGFR: A Foundation Retriever for Generalized Knowledge Graph Question Answering](https://arxiv.org/abs/2511.04093)
*Yuanning Cui,Zequn Sun,Wei Hu,Zhangjie Fu*

Main category: cs.AI

TL;DR: LLM-KGFR框架通过结合大语言模型与知识图谱基础检索器，解决LLM在知识密集型问题上的局限性，实现零样本泛化和大规模图谱的高效处理。


<details>
  <summary>Details</summary>
Motivation: 现有基于微调LLM或GNN检索器的方法存在数据集特定调优和可扩展性限制，无法有效处理大规模或未见过的知识图谱。

Method: 提出LLM-KGFR协作框架，利用LLM生成关系描述编码，基于问题角色初始化实体，采用非对称渐进传播策略高效处理大图，通过节点、边和路径级接口实现可控推理循环。

Result: 实验表明LLM-KGFR在保持可扩展性和泛化能力的同时实现了强劲性能。

Conclusion: 该框架为知识图谱增强推理提供了实用解决方案，平衡了性能、可扩展性和泛化能力。

Abstract: Large language models (LLMs) excel at reasoning but struggle with
knowledge-intensive questions due to limited context and parametric knowledge.
However, existing methods that rely on finetuned LLMs or GNN retrievers are
limited by dataset-specific tuning and scalability on large or unseen graphs.
We propose the LLM-KGFR collaborative framework, where an LLM works with a
structured retriever, the Knowledge Graph Foundation Retriever (KGFR). KGFR
encodes relations using LLM-generated descriptions and initializes entities
based on their roles in the question, enabling zero-shot generalization to
unseen KGs. To handle large graphs efficiently, it employs Asymmetric
Progressive Propagation (APP)- a stepwise expansion that selectively limits
high-degree nodes while retaining informative paths. Through node-, edge-, and
path-level interfaces, the LLM iteratively requests candidate answers,
supporting facts, and reasoning paths, forming a controllable reasoning loop.
Experiments demonstrate that LLM-KGFR achieves strong performance while
maintaining scalability and generalization, providing a practical solution for
KG-augmented reasoning.

</details>


### [37] [Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing Platforms](https://arxiv.org/abs/2511.04133)
*Miguel E. Andres,Vadim Fedorov,Rida Sadek,Enric Spagnolo-Arrizabalaga,Nadescha Trudel*

Main category: cs.AI

TL;DR: 提出了首个系统框架来评估语音AI测试质量，通过人类中心化基准测试方法，解决了测试平台生成真实对话和准确评估响应的双重挑战。


<details>
  <summary>Details</summary>
Motivation: 随着语音AI代理快速部署到生产环境，缺乏系统性的测试可靠性验证方法，组织无法客观评估测试方法的有效性，这在大规模部署时造成了关键的测量差距。

Method: 结合心理测量技术（成对比较产生Elo评分、自助置信区间和置换检验）与严格统计验证，提供可复现的指标，适用于任何测试方法。

Result: 对三个领先商业平台进行了全面实证评估，结果显示Evalion平台表现最佳，评估质量F1分数达0.92，模拟质量达0.61，显著优于其他平台。

Conclusion: 该框架使研究人员和组织能够实证验证任何平台的测试能力，为大规模语音AI部署提供了必要的测量基础。

Abstract: Voice AI agents are rapidly transitioning to production deployments, yet
systematic methods for ensuring testing reliability remain underdeveloped.
Organizations cannot objectively assess whether their testing approaches
(internal tools or external platforms) actually work, creating a critical
measurement gap as voice AI scales to billions of daily interactions.
  We present the first systematic framework for evaluating voice AI testing
quality through human-centered benchmarking. Our methodology addresses the
fundamental dual challenge of testing platforms: generating realistic test
conversations (simulation quality) and accurately evaluating agent responses
(evaluation quality). The framework combines established psychometric
techniques (pairwise comparisons yielding Elo ratings, bootstrap confidence
intervals, and permutation tests) with rigorous statistical validation to
provide reproducible metrics applicable to any testing approach.
  To validate the framework and demonstrate its utility, we conducted
comprehensive empirical evaluation of three leading commercial platforms
focused on Voice AI Testing using 21,600 human judgments across 45 simulations
and ground truth validation on 60 conversations. Results reveal statistically
significant performance differences with the proposed framework, with the
top-performing platform, Evalion, achieving 0.92 evaluation quality measured as
f1-score versus 0.73 for others, and 0.61 simulation quality using a league
based scoring system (including ties) vs 0.43 for other platforms.
  This framework enables researchers and organizations to empirically validate
the testing capabilities of any platform, providing essential measurement
foundations for confident voice AI deployment at scale. Supporting materials
are made available to facilitate reproducibility and adoption.

</details>


### [38] [When Empowerment Disempowers](https://arxiv.org/abs/2511.04177)
*Claire Yang,Maya Cakmak,Max Kleiman-Weiner*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Empowerment, a measure of an agent's ability to control its environment, has
been proposed as a universal goal-agnostic objective for motivating assistive
behavior in AI agents. While multi-human settings like homes and hospitals are
promising for AI assistance, prior work on empowerment-based assistance assumes
that the agent assists one human in isolation. We introduce an open source
multi-human gridworld test suite Disempower-Grid. Using Disempower-Grid, we
empirically show that assistive RL agents optimizing for one human's
empowerment can significantly reduce another human's environmental influence
and rewards - a phenomenon we formalize as disempowerment. We characterize when
disempowerment occurs in these environments and show that joint empowerment
mitigates disempowerment at the cost of the user's reward. Our work reveals a
broader challenge for the AI alignment community: goal-agnostic objectives that
seem aligned in single-agent settings can become misaligned in multi-agent
contexts.

</details>


### [39] [Opus: A Quantitative Framework for Workflow Evaluation](https://arxiv.org/abs/2511.04220)
*Alan Seroul,Théo Fagnoni,Inès Adnani,Dana O. Mohamed,Phillip Kingston*

Main category: cs.AI

TL;DR: Opus工作流评估框架：一个概率-规范化的数学框架，用于量化工作流质量和效率，结合正确性、可靠性和成本，支持自动化评估、排名和优化。


<details>
  <summary>Details</summary>
Motivation: 需要一种系统性的方法来量化工作流质量，支持直接比较、评分和优化工作流，特别是在现代自动化系统中。

Method: 结合Opus工作流奖励（概率函数估计预期性能）和Opus工作流规范惩罚（测量结构信息质量），形成统一的数学模型。

Result: 提出了一个支持自动化工作流评估、排名和优化的框架，可集成到强化学习循环中指导工作流发现和改进。

Conclusion: 该框架为工作流质量评估和优化提供了统一的数学基础，支持在现代自动化系统中进行有效的工作流管理。

Abstract: This paper introduces the Opus Workflow Evaluation Framework, a
probabilistic-normative formulation for quantifying Workflow quality and
efficiency. It integrates notions of correctness, reliability, and cost into a
coherent mathematical model that enables direct comparison, scoring, and
optimization of Workflows. The framework combines the Opus Workflow Reward, a
probabilistic function estimating expected performance through success
likelihood, resource usage, and output gain, with the Opus Workflow Normative
Penalties, a set of measurable functions capturing structural and informational
quality across Cohesion, Coupling, Observability, and Information Hygiene. It
supports automated Workflow assessment, ranking, and optimization within modern
automation systems such as Opus and can be integrated into Reinforcement
Learning loops to guide Workflow discovery and refinement. In this paper, we
introduce the Opus Workflow Reward model that formalizes Workflow success as a
probabilistic expectation over costs and outcomes. We define measurable Opus
Workflow Normative Penalties capturing structural, semantic, and signal-related
properties of Workflows. Finally, we propose a unified optimization formulation
for identifying and ranking optimal Workflows under joint Reward-Penalty
trade-offs.

</details>


### [40] [Shared Spatial Memory Through Predictive Coding](https://arxiv.org/abs/2511.04235)
*Zhengru Fang,Yu Guo,Jingjing Wang,Yuang Zhang,Haonan An,Yinhai Wang,Yuguang Fang*

Main category: cs.AI

TL;DR: 提出了一种多智能体预测编码框架，通过最小化智能体间的相互不确定性来协调行动，在带宽受限条件下实现了高效的空间记忆共享和协调。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，部分可观测性和有限带宽常常导致协调失败，需要解决一致空间记忆共享的挑战。

Method: 基于信息瓶颈目标的多智能体预测编码框架，包括自监督运动预测产生的网格细胞状空间编码、带宽高效通信机制、类似海马体社交位置细胞的神经群体，以及分层强化学习策略。

Result: 在Memory-Maze基准测试中，方法在带宽从128位/步降至4位/步时，成功率从73.5%优雅下降至64.4%，而全广播基线从67.6%崩溃至28.6%。

Conclusion: 为复杂社交表征如何从统一的预测驱动中涌现建立了理论原则和生物学上合理的基础，实现了社交集体智能。

Abstract: Sharing and reconstructing a consistent spatial memory is a critical
challenge in multi-agent systems, where partial observability and limited
bandwidth often lead to catastrophic failures in coordination. We introduce a
multi-agent predictive coding framework that formulate coordination as the
minimization of mutual uncertainty among agents. Instantiated as an information
bottleneck objective, it prompts agents to learn not only who and what to
communicate but also when. At the foundation of this framework lies a
grid-cell-like metric as internal spatial coding for self-localization,
emerging spontaneously from self-supervised motion prediction. Building upon
this internal spatial code, agents gradually develop a bandwidth-efficient
communication mechanism and specialized neural populations that encode
partners' locations: an artificial analogue of hippocampal social place cells
(SPCs). These social representations are further enacted by a hierarchical
reinforcement learning policy that actively explores to reduce joint
uncertainty. On the Memory-Maze benchmark, our approach shows exceptional
resilience to bandwidth constraints: success degrades gracefully from 73.5% to
64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast
baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically
principled and biologically plausible basis for how complex social
representations emerge from a unified predictive drive, leading to social
collective intelligence.

</details>


### [41] [RLoop: An Self-Improving Framework for Reinforcement Learning with Iterative Policy Initialization](https://arxiv.org/abs/2511.04285)
*Zeng Zhiyuan,Jiashuo Liu,Zhangyue Yin,Ge Zhang,Wenhao Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: RLoop是一个自改进框架，通过迭代策略初始化解决RL训练中的过拟合问题，将探索和利用转化为稳健性能提升


<details>
  <summary>Details</summary>
Motivation: RLVR训练中存在RL过拟合问题，模型获得训练奖励但失去泛化能力，这由策略过专业化和灾难性遗忘驱动

Method: RLoop通过迭代策略初始化构建：先用RL从给定策略探索解空间，过滤成功轨迹创建专家数据集，通过拒绝采样微调来精炼初始策略，为下一次迭代创建更好的起点

Result: RLoop显著改善泛化能力，平均准确率提升9%，pass@32提升超过15%

Conclusion: RLoop通过将瞬态策略变化转化为稳健性能增益，有效缓解遗忘并提升泛化

Abstract: While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for
training large reasoning models, its training dynamics harbor a critical
challenge: RL overfitting, where models gain training rewards but lose
generalization. Our analysis reveals this is driven by policy
over-specialization and catastrophic forgetting of diverse solutions generated
during training. Standard optimization discards this valuable inter-step policy
diversity. To address this, we introduce RLoop, a self-improving framework
built on iterative policy initialization. RLoop transforms the standard
training process into a virtuous cycle: it first uses RL to explore the
solution space from a given policy, then filters the successful trajectories to
create an expert dataset. This dataset is used via Rejection-sampling
Fine-Tuning (RFT) to refine the initial policy, creating a superior starting
point for the next iteration. This loop of exploration and exploitation via
iterative re-initialization effectively converts transient policy variations
into robust performance gains. Our experiments show RLoop mitigates forgetting
and substantially improves generalization, boosting average accuracy by 9% and
pass@32 by over 15% compared to vanilla RL.

</details>


### [42] [GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents](https://arxiv.org/abs/2511.04307)
*Jian Mu,Chaoyun Zhang,Chiming Ni,Lu Wang,Bo Qiao,Kartik Mathur,Qianhui Wu,Yuhang Xie,Xiaojun Ma,Mengyu Zhou,Si Qin,Liqun Li,Yu Kang,Minghua Ma,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.AI

TL;DR: GUI-360°是一个大规模数据集和基准套件，用于推进计算机使用代理（CUAs）的研究，包含120万+执行动作步骤，支持GUI定位、屏幕解析和动作预测三个核心任务。


<details>
  <summary>Details</summary>
Motivation: 解决计算机使用代理研究中的三个关键问题：真实世界CUA任务稀缺、缺乏多模态轨迹的自动收集和标注流程、以及缺少统一评估GUI定位、屏幕解析和动作预测的基准。

Method: 使用LLM增强的自动化流程，包括查询来源、环境模板构建、任务实例化、批量执行和LLM驱动的质量过滤，在Windows办公应用中收集数千条轨迹数据。

Result: 基准测试显示现有视觉-语言模型在GUI定位和动作预测方面存在显著不足，监督微调和强化学习带来显著改进但仍未达到人类可靠性水平。

Conclusion: GUI-360°数据集和代码已公开发布，旨在促进可重复研究并加速稳健桌面CUAs的进展。

Abstract: We introduce GUI-360$^\circ$, a large-scale, comprehensive dataset and
benchmark suite designed to advance computer-using agents (CUAs). CUAs present
unique challenges and is constrained by three persistent gaps: a scarcity of
real-world CUA tasks, the lack of automated collection-and-annotation pipelines
for multi-modal trajectories, and the absence of a unified benchmark that
jointly evaluates GUI grounding, screen parsing, and action prediction.
  GUI-360$^\circ$ addresses these gaps with an LLM-augmented, largely automated
pipeline for query sourcing, environment-template construction, task
instantiation, batched execution, and LLM-driven quality filtering. The
released corpus contains over 1.2M executed action steps across thousands of
trajectories in popular Windows office applications, and includes
full-resolution screenshots, accessibility metadata when available,
instantiated goals, intermediate reasoning traces, and both successful and
failed action trajectories. The dataset supports three canonical tasks, GUI
grounding, screen parsing, and action prediction, and a hybrid GUI+API action
space that reflects modern agent designs. Benchmarking state-of-the-art
vision--language models on GUI-360$^\circ$ reveals substantial out-of-the-box
shortcomings in grounding and action prediction; supervised fine-tuning and
reinforcement learning yield significant gains but do not close the gap to
human-level reliability. We release GUI-360$^\circ$ and accompanying code to
facilitate reproducible research and accelerate progress on robust desktop
CUAs.
  The full dataset has been made public on
https://huggingface.co/datasets/vyokky/GUI-360.

</details>


### [43] [Probing the Probes: Methods and Metrics for Concept Alignment](https://arxiv.org/abs/2511.04312)
*Jacob Lysnæs-Larsen,Marte Eggen,Inga Strümke*

Main category: cs.AI

TL;DR: 本文指出在可解释AI中，仅凭概念激活向量(CAV)探测器的分类精度不能可靠衡量概念对齐度，探测器更可能捕捉虚假相关性而非目标概念。作者提出基于空间线性归因的新概念定位方法，并引入三类量化评估概念对齐的指标。


<details>
  <summary>Details</summary>
Motivation: 当前CAV方法仅依赖探测器分类精度来评估概念表示质量，但研究发现这种评估不可靠，探测器容易捕捉虚假相关性而非真正概念，需要更可靠的概念对齐评估方法。

Method: 提出基于空间线性归因的概念定位方法，与现有特征可视化技术对比；引入三类概念对齐评估指标：硬精度、分割分数和增强鲁棒性；构建故意错位探测器验证问题。

Result: 故意错位的探测器也能达到接近标准探测器的精度，证明仅靠精度不可靠；具有平移不变性和空间对齐的探测器能提高概念对齐度；新提出的评估指标能更准确衡量概念对齐。

Conclusion: 需要基于对齐度的评估指标而非探测器精度，探测器设计应考虑模型架构和目标概念特性，空间对齐和平移不变性对概念对齐至关重要。

Abstract: In explainable AI, Concept Activation Vectors (CAVs) are typically obtained
by training linear classifier probes to detect human-understandable concepts as
directions in the activation space of deep neural networks. It is widely
assumed that a high probe accuracy indicates a CAV faithfully representing its
target concept. However, we show that the probe's classification accuracy alone
is an unreliable measure of concept alignment, i.e., the degree to which a CAV
captures the intended concept. In fact, we argue that probes are more likely to
capture spurious correlations than they are to represent only the intended
concept. As part of our analysis, we demonstrate that deliberately misaligned
probes constructed to exploit spurious correlations, achieve an accuracy close
to that of standard probes. To address this severe problem, we introduce a
novel concept localization method based on spatial linear attribution, and
provide a comprehensive comparison of it to existing feature visualization
techniques for detecting and mitigating concept misalignment. We further
propose three classes of metrics for quantitatively assessing concept
alignment: hard accuracy, segmentation scores, and augmentation robustness. Our
analysis shows that probes with translation invariance and spatial alignment
consistently increase concept alignment. These findings highlight the need for
alignment-based evaluation metrics rather than probe accuracy, and the
importance of tailoring probes to both the model architecture and the nature of
the target concept.

</details>


### [44] [AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research](https://arxiv.org/abs/2511.04316)
*Tim Beyer,Jonas Dornbusch,Jakob Steimle,Moritz Ladenburger,Leo Schwinn,Stephan Günnemann*

Main category: cs.AI

TL;DR: AdversariaLLM是一个用于LLM越狱鲁棒性研究的工具箱，旨在解决当前LLM安全研究生态系统碎片化、难以复现和比较的问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM安全和鲁棒性研究生态系统碎片化严重，存在大量buggy实现、数据集和评估方法，导致研究难以复现和比较，阻碍了该领域的实质性进展。

Method: 设计了一个以可复现性、正确性和可扩展性为核心的工具箱，实现了12种对抗攻击算法，集成了7个基准数据集（涵盖危害性、过度拒绝和实用性评估），并通过Hugging Face提供对多种开源LLM的访问。

Result: 该框架提供了用于可比性和可复现性的高级功能，包括计算资源跟踪、确定性结果和分布评估技术，并与JudgeZoo集成进行评判。

Conclusion: AdversariaLLM旨在为LLM安全研究建立透明、可比和可复现的坚实基础。

Abstract: The rapid expansion of research on Large Language Model (LLM) safety and
robustness has produced a fragmented and oftentimes buggy ecosystem of
implementations, datasets, and evaluation methods. This fragmentation makes
reproducibility and comparability across studies challenging, hindering
meaningful progress. To address these issues, we introduce AdversariaLLM, a
toolbox for conducting LLM jailbreak robustness research. Its design centers on
reproducibility, correctness, and extensibility. The framework implements
twelve adversarial attack algorithms, integrates seven benchmark datasets
spanning harmfulness, over-refusal, and utility evaluation, and provides access
to a wide range of open-weight LLMs via Hugging Face. The implementation
includes advanced features for comparability and reproducibility such as
compute-resource tracking, deterministic results, and distributional evaluation
techniques. \name also integrates judging through the companion package
JudgeZoo, which can also be used independently. Together, these components aim
to establish a robust foundation for transparent, comparable, and reproducible
research in LLM safety.

</details>


### [45] [RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation](https://arxiv.org/abs/2511.04328)
*Jiahao Zhao,Luxin Xu,Minghuan Tan,Lichao Zhang,Ahmadreza Argha,Hamid Alinejad-Rokny,Min Yang*

Main category: cs.AI

TL;DR: 提出了RxSafeBench框架，通过模拟临床咨询评估LLMs的药物安全性能力，包含6,725种禁忌症、28,781种药物相互作用和14,906个适应症-药物对，构建了2,443个高质量咨询场景的基准测试。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLMs的医疗系统在药物安全性方面的研究有限，缺乏真实世界数据集，且在真实临床咨询环境下的评估不足。

Method: 构建RxRisk DB药物安全数据库，采用两阶段过滤策略确保临床真实性和专业质量，通过结构化多选题评估LLMs在模拟患者情境下推荐安全药物的能力。

Result: 当前LLMs在整合禁忌症和药物相互作用知识方面存在困难，特别是当风险是隐含而非明确时表现不佳。

Conclusion: RxSafeBench提供了首个评估LLMs药物安全性的综合基准，为改进AI驱动的临床决策支持系统的可靠性提供了见解。

Abstract: Numerous medical systems powered by Large Language Models (LLMs) have
achieved remarkable progress in diverse healthcare tasks. However, research on
their medication safety remains limited due to the lack of real world datasets,
constrained by privacy and accessibility issues. Moreover, evaluation of LLMs
in realistic clinical consultation settings, particularly regarding medication
safety, is still underexplored. To address these gaps, we propose a framework
that simulates and evaluates clinical consultations to systematically assess
the medication safety capabilities of LLMs. Within this framework, we generate
inquiry diagnosis dialogues with embedded medication risks and construct a
dedicated medication safety database, RxRisk DB, containing 6,725
contraindications, 28,781 drug interactions, and 14,906 indication-drug pairs.
A two-stage filtering strategy ensures clinical realism and professional
quality, resulting in the benchmark RxSafeBench with 2,443 high-quality
consultation scenarios. We evaluate leading open-source and proprietary LLMs
using structured multiple choice questions that test their ability to recommend
safe medications under simulated patient contexts. Results show that current
LLMs struggle to integrate contraindication and interaction knowledge,
especially when risks are implied rather than explicit. Our findings highlight
key challenges in ensuring medication safety in LLM-based systems and provide
insights into improving reliability through better prompting and task-specific
tuning. RxSafeBench offers the first comprehensive benchmark for evaluating
medication safety in LLMs, advancing safer and more trustworthy AI-driven
clinical decision support.

</details>


### [46] [Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for Language Model Reasoning](https://arxiv.org/abs/2511.04341)
*Nick Oh,Fernand Gobet*

Main category: cs.AI

TL;DR: 论文提出了Monitor-Generate-Verify（MGV）框架，通过在Generate-Verify范式前添加显式监控机制来解决前缀主导陷阱问题，将元认知理论转化为计算规范。


<details>
  <summary>Details</summary>
Motivation: 现有测试时推理架构缺乏监控过程，导致模型过早承诺次优推理路径而难以恢复（前缀主导陷阱），造成约20%的准确率损失。

Method: 将Flavell以及Nelson和Narens的元认知理论形式化为计算规范，提出MGV框架，在生成前添加显式监控机制，通过验证反馈改进未来监控。

Result: 虽然未提供实证验证，但这是首次系统地将基础元认知理论转化为计算规范，为理解推理系统失败提供了原则性词汇。

Conclusion: MGV框架为未来测试时推理设计提供了具体的架构干预建议，通过整合元认知监控来改善推理系统的性能。

Abstract: Test-time reasoning architectures such as those following the Generate-Verify
paradigm -- where a model iteratively refines or verifies its own generated
outputs -- prioritise generation and verification but exclude the monitoring
processes that determine when and how reasoning should begin. This omission may
contribute to the prefix dominance trap, in which models commit early to
suboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy
loss. We address this architectural gap by formalising Flavell's and Nelson and
Narens' metacognitive theories into computational specifications, proposing the
Monitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify
paradigm by adding explicit monitoring that captures metacognitive experiences
(from difficulty assessments to confidence judgements) before generation begins
and refines future monitoring through verification feedback. Though we present
no empirical validation, this work provides the first systematic computational
translation of foundational metacognitive theories, offering a principled
vocabulary for understanding reasoning system failures and suggesting specific
architectural interventions for future test-time reasoning designs.

</details>


### [47] [Post-Training LLMs as Better Decision-Making Agents: A Regret-Minimization Approach](https://arxiv.org/abs/2511.04393)
*Chanwoo Park,Ziyang Chen,Asuman Ozdaglar,Kaiqing Zhang*

Main category: cs.AI

TL;DR: 提出Iterative RMFT方法，通过迭代蒸馏低后悔决策轨迹来增强LLMs的决策能力，无需依赖已知算法或人工模板。


<details>
  <summary>Details</summary>
Motivation: LLMs在交互式动态环境中作为决策代理时表现不佳，难以实现低后悔或有效的探索-利用权衡，需要专门的决策能力增强方法。

Method: 迭代后悔最小化微调：模型生成多个决策轨迹，选择k个最低后悔的轨迹，并基于这些轨迹进行自微调，利用后悔指标激发模型自身的决策能力和推理逻辑。

Result: Iterative RMFT显著提升了多种LLMs的决策性能，包括Transformer、开源LLMs和GPT-4o mini等闭源模型，在多样化任务中展现出良好的泛化能力。

Conclusion: Iterative RMFT提供了一个原则性且通用的后训练框架，能够有效增强LLMs的决策能力，理论分析表明单层Transformer在此范式下可实现无后悔学习。

Abstract: Large language models (LLMs) are increasingly deployed as "agents" for
decision-making (DM) in interactive and dynamic environments. Yet, since they
were not originally designed for DM, recent studies show that LLMs can struggle
even in basic online DM problems, failing to achieve low regret or an effective
exploration-exploitation tradeoff. To address this, we introduce Iterative
Regret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure
that repeatedly distills low-regret decision trajectories back into the base
model. At each iteration, the model rolls out multiple decision trajectories,
selects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior
methods that (a) distill action sequences from known DM algorithms or (b) rely
on manually crafted chain-of-thought templates, our approach leverages the
regret metric to elicit the model's own DM ability and reasoning rationales.
This reliance on model-generated reasoning avoids rigid output engineering and
provides more flexible, natural-language training signals. Empirical results
show that Iterative RMFT improves LLMs' DM performance across diverse models -
from Transformers with numerical input/output, to open-weight LLMs, and
advanced closed-weight models like GPT-4o mini. Its flexibility in output and
reasoning formats enables generalization across tasks with varying horizons,
action spaces, reward processes, and natural-language contexts. Finally, we
provide theoretical insight showing that a single-layer Transformer under this
paradigm can act as a no-regret learner in a simplified setting. Overall,
Iterative RMFT offers a principled and general post-training framework for
enhancing LLMs' decision-making capabilities.

</details>


### [48] [The Peril of Preference: Why GRPO fails on Ordinal Rewards](https://arxiv.org/abs/2511.04439)
*Anisha Garg,Ganesh Venkatesh*

Main category: cs.AI

TL;DR: CoRPO解决了GRPO在使用序数奖励时对失败轨迹错误强化的问题，通过自适应基线确保失败解决方案不被正向强化，并在达到质量阈值后切换到相对偏好模式以寻找最优解。


<details>
  <summary>Details</summary>
Motivation: GRPO的简单性使其在适应LLM到特定任务时很有吸引力，但使用序数奖励提供部分信用时，其组平均基线经常对失败轨迹分配正优势并强化错误行为。

Method: 提出Correctness Relative Policy Optimization (CoRPO)，使用自适应基线强制执行最低质量阈值，确保失败解决方案永远不会被正向强化。当策略持续满足此阈值后，基线自动过渡到相对偏好模式。

Result: 在代码验证任务上经验验证，CoRPO表现出更稳定的收敛性和更好的域外泛化能力。

Conclusion: 这项工作是在LLM通过强化学习学习真正新能力的研究计划中的关键一步，通过使LLM能够从丰富的多维反馈中学习，从二元奖励进展到序数奖励，并进一步向更密集的每步监督发展。

Abstract: Group-relative Policy Optimization's (GRPO) simplicity makes it highly
desirable for adapting LLMs to become experts at specific tasks. But this
simplicity also makes it ill-specified as we seek to enhance RL training with
richer, non-binary feedback. When using ordinal rewards to give partial credit,
GRPO's simplicity starts to hurt, as its group-average baseline often assigns a
positive advantage to failed trajectories and reinforces incorrect behavior.
  We introduce Correctness Relative Policy Optimization (CoRPO), a new
formulation that solves this flaw. CoRPO uses an adaptive baseline that
enforces a minimum quality threshold, ensuring failed solutions are never
positively reinforced. Once the policy consistently meets this threshold, the
baseline automatically transitions to a relative preference mode, pushing the
model to find optimal solutions rather than just "acceptable" ones. We
empirically validate CoRPO on a code verification task, where it demonstrates
more stable convergence and better out-of-domain generalization.
  This work represents a critical step in our broader research program to
enable LLMs to learn genuinely new capabilities through reinforcement learning.
We achieve this by enabling LLMs to learn from rich, multi-dimensional feedback
- progressing from binary to ordinal rewards in this work, and onward to
denser, per-step supervision.

</details>


### [49] [Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context](https://arxiv.org/abs/2511.04464)
*Carnot Braun,Rafael O. Jarczewski,Gabriel U. Talasso,Leandro A. Villas,Allan M. de Souza*

Main category: cs.AI

TL;DR: PAVe系统结合传统路径规划算法与LLM语义推理，通过多目标Dijkstra算法生成候选路线，再由LLM代理根据用户任务、偏好和规避规则进行上下文评估，实现个性化车辆路径规划。


<details>
  <summary>Details</summary>
Motivation: 传统车辆路径系统只能优化单一指标，无法理解人类驾驶员的复杂语义上下文（如多步骤任务、情境约束、紧急需求），需要能够集成语义推理的智能路由系统。

Method: 使用多目标（时间、CO2）Dijkstra算法生成候选路线，然后通过LLM代理结合预处理的地理空间POI缓存，根据用户提供的任务、偏好和规避规则评估路线选项。

Result: 在真实城市场景测试中，PAVe成功将复杂用户意图转化为适当的路线修改，使用本地模型时初始路线选择准确率超过88%。

Conclusion: 将经典路由算法与基于LLM的语义推理层相结合，是创建个性化、自适应和可扩展城市移动优化解决方案的稳健有效方法。

Abstract: Traditional vehicle routing systems efficiently optimize singular metrics
like time or distance, and when considering multiple metrics, they need more
processes to optimize . However, they lack the capability to interpret and
integrate the complex, semantic, and dynamic contexts of human drivers, such as
multi-step tasks, situational constraints, or urgent needs. This paper
introduces and evaluates PAVe (Personalized Agentic Vehicular Routing), a
hybrid agentic assistant designed to augment classical pathfinding algorithms
with contextual reasoning. Our approach employs a Large Language Model (LLM)
agent that operates on a candidate set of routes generated by a multi-objective
(time, CO2) Dijkstra algorithm. The agent evaluates these options against
user-provided tasks, preferences, and avoidance rules by leveraging a
pre-processed geospatial cache of urban Points of Interest (POIs). In a
benchmark of realistic urban scenarios, PAVe successfully used complex user
intent into appropriate route modifications, achieving over 88% accuracy in its
initial route selections with a local model. We conclude that combining
classical routing algorithms with an LLM-based semantic reasoning layer is a
robust and effective approach for creating personalized, adaptive, and scalable
solutions for urban mobility optimization.

</details>


### [50] [Promoting Sustainable Web Agents: Benchmarking and Estimating Energy Consumption through Empirical and Theoretical Analysis](https://arxiv.org/abs/2511.04481)
*Lars Krupp,Daniel Geißler,Vishal Banwari,Paul Lukowicz,Jakob Karolus*

Main category: cs.AI

TL;DR: 本文首次探索了网络代理的能源消耗和碳排放问题，通过理论和实证分析揭示了不同设计理念对能耗的显著影响，并指出能耗与性能不一定成正比。


<details>
  <summary>Details</summary>
Motivation: 尽管网络代理研究蓬勃发展，但其引发的可持续性问题仍未被充分探索。本文旨在揭示网络代理的能源和碳排放成本，强调这一问题的紧迫性。

Method: 采用理论估计和实证基准测试相结合的方法，从理论和实践两个角度分析网络代理的能源消耗。

Result: 结果显示不同网络代理设计理念会严重影响能耗，且更高能耗不一定带来更好结果。同时发现模型参数和过程披露不透明限制了能耗估算。

Conclusion: 呼吁改变网络代理评估方式，建议在基准测试中加入专门的能耗指标，推动更可持续的网络代理发展。

Abstract: Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful
agentic systems pushing the boundaries of Large Language Models (LLM). They can
autonomously interact with the internet at the user's behest, such as
navigating websites, filling search masks, and comparing price lists. Though
web agent research is thriving, induced sustainability issues remain largely
unexplored. To highlight the urgency of this issue, we provide an initial
exploration of the energy and $CO_2$ cost associated with web agents from both
a theoretical -via estimation- and an empirical perspective -by benchmarking.
Our results show how different philosophies in web agent creation can severely
impact the associated expended energy, and that more energy consumed does not
necessarily equate to better results. We highlight a lack of transparency
regarding disclosing model parameters and processes used for some web agents as
a limiting factor when estimating energy consumption. Our work contributes
towards a change in thinking of how we evaluate web agents, advocating for
dedicated metrics measuring energy consumption in benchmarks.

</details>


### [51] [Large language models replicate and predict human cooperation across experiments in game theory](https://arxiv.org/abs/2511.04500)
*Andrea Cera Palatsi,Samuel Martin-Gutierrez,Ana S. Cardenal,Max Pellert*

Main category: cs.AI

TL;DR: 研究发现不同LLM在博弈实验中表现出不同的人类决策模式：Llama能高保真复制人类合作行为，捕捉人类偏离理性选择理论的模式；Qwen则更接近纳什均衡预测。无需人物设定提示即可实现群体行为复制，简化了模拟过程。


<details>
  <summary>Details</summary>
Motivation: 理解LLM在多大程度上能模拟人类决策行为至关重要，因为如果LLM与人类决策不一致，在实际应用中可能导致有害结果，而在社会模拟中无法复制人类行为则会使LLM失效。

Method: 开发博弈实验的数字孪生模型，引入系统的提示和探测框架进行机器行为评估，测试三个开源模型（Llama、Mistral和Qwen）。

Result: Llama能高保真复制人类合作模式，捕捉人类偏离理性选择理论的行为；Qwen与纳什均衡预测高度一致；无需人物设定提示即可实现群体行为复制。

Conclusion: 适当校准的LLM可以复制群体人类行为模式，并能系统探索未经验证的实验空间，为社会科学研究提供补充方法，生成关于人类社交决策的新实证预测。

Abstract: Large language models (LLMs) are increasingly used both to make decisions in
domains such as health, education and law, and to simulate human behavior. Yet
how closely LLMs mirror actual human decision-making remains poorly understood.
This gap is critical: misalignment could produce harmful outcomes in practical
applications, while failure to replicate human behavior renders LLMs
ineffective for social simulations. Here, we address this gap by developing a
digital twin of game-theoretic experiments and introducing a systematic
prompting and probing framework for machine-behavioral evaluation. Testing
three open-source models (Llama, Mistral and Qwen), we find that Llama
reproduces human cooperation patterns with high fidelity, capturing human
deviations from rational choice theory, while Qwen aligns closely with Nash
equilibrium predictions. Notably, we achieved population-level behavioral
replication without persona-based prompting, simplifying the simulation
process. Extending beyond the original human-tested games, we generate and
preregister testable hypotheses for novel game configurations outside the
original parameter grid. Our findings demonstrate that appropriately calibrated
LLMs can replicate aggregate human behavioral patterns and enable systematic
exploration of unexplored experimental spaces, offering a complementary
approach to traditional research in the social and behavioral sciences that
generates new empirical predictions about human social decision-making.

</details>


### [52] [Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse Sensing Approach](https://arxiv.org/abs/2511.04556)
*Zihang Ding,Kun Zhang*

Main category: cs.AI

TL;DR: 提出了一个数据驱动的稀疏感知框架，结合EPA-SWMM模型，通过优化传感器布局来重建城市排水系统的峰值流量，在资源受限条件下实现高精度洪水监测。


<details>
  <summary>Details</summary>
Motivation: 城市地表水洪水日益频繁，但高时空分辨率的洪水预测和监测受到时间、预算和技术限制。如何在资源受限条件下监测城市排水网络并预测流量状况是主要挑战。

Method: 使用SWMM模型生成峰值流量训练数据集，应用数据驱动稀疏感知框架（包括奇异值分解降维和QR分解传感器分配）来识别最优监测节点，并验证重建性能。

Result: 在77个节点中仅需3个优化布置的传感器，就能实现满意的重建性能（NSE值0.92-0.95），模型对测量不确定性具有良好的鲁棒性。

Conclusion: 该框架平衡了计算效率和物理可解释性，能够以最少的传感器实现高精度流量重建，可进一步与预测模型集成，在有限传感资源下实现洪水早期预警和实时控制。

Abstract: Urban surface water flooding, triggered by intense rainfall overwhelming
drainage systems, is increasingly frequent and widespread. While flood
prediction and monitoring in high spatial-temporal resolution are desired,
practical constraints in time, budget, and technology hinder its full
implementation. How to monitor urban drainage networks and predict flow
conditions under constrained resource is a major challenge. This study presents
a data-driven sparse sensing (DSS) framework, integrated with EPA-SWMM, to
optimize sensor placement and reconstruct peak flowrates in a stormwater
system, using the Woodland Avenue catchment in Duluth, Minnesota, as a case
study. We utilized a SWMM model to generate a training dataset of peak flowrate
profiles across the stormwater network. Furthermore, we applied DSS -
leveraging singular value decomposition for dimensionality reduction and QR
factorization for sensor allocation - to identify the optimal monitoring nodes
based on the simulated training dataset. We then validated the
representativeness of these identified monitoring nodes by comparing the
DSS-reconstructed peak flowrate profiles with those obtained from SWMM. Three
optimally placed sensors among 77 nodes achieved satisfactory reconstruction
performance with Nash-Sutcliffe Efficiency (NSE) values of 0.92-0.95 (25th to
75th percentiles). In addition, the model showed good robustness to uncertainty
in measurements. Its robustness to sensor failures is location-dependent and
improves with the number of sensors deployed. The framework balances
computational efficiency and physical interpretability, enabling high-accuracy
flow reconstruction with minimal sensors. This DSS framework can be further
integrated with predictive models to realize flood early warning and real-time
control under limited sensing and monitoring resource.

</details>


### [53] [Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper](https://arxiv.org/abs/2511.04583)
*Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa*

Main category: cs.AI

TL;DR: 开发了Jr. AI Scientist系统，这是一个模拟新手研究人员工作流程的自主AI科学家系统，能够分析论文局限性、提出假设、进行实验验证并撰写论文。


<details>
  <summary>Details</summary>
Motivation: 理解AI科学家系统的当前能力和风险对于确保可信赖和可持续的AI驱动科学进步至关重要，同时保护学术生态系统的完整性。

Method: Jr. AI Scientist遵循明确的研究工作流程，利用现代编码代理处理复杂的多文件实现，通过AI评审员、作者主导评估和向Agents4Science投稿进行自动化评估。

Result: Jr. AI Scientist生成的论文获得的评审分数高于现有全自动化系统，但作者评估和Agents4Science评审都发现了重要局限性。

Conclusion: 当前AI科学家系统存在直接应用的风险和关键挑战，需要进一步研究，报告了开发过程中识别的各种风险以加深对AI科学家发展现状和风险的理解。

Abstract: Understanding the current capabilities and risks of AI Scientist systems is
essential for ensuring trustworthy and sustainable AI-driven scientific
progress while preserving the integrity of the academic ecosystem. To this end,
we develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system
that mimics the core research workflow of a novice student researcher: Given
the baseline paper from the human mentor, it analyzes its limitations,
formulates novel hypotheses for improvement, validates them through rigorous
experimentation, and writes a paper with the results. Unlike previous
approaches that assume full automation or operate on small-scale code, Jr. AI
Scientist follows a well-defined research workflow and leverages modern coding
agents to handle complex, multi-file implementations, leading to scientifically
valuable contributions. For evaluation, we conducted automated assessments
using AI Reviewers, author-led evaluations, and submissions to Agents4Science,
a venue dedicated to AI-driven scientific contributions. The findings
demonstrate that Jr. AI Scientist generates papers receiving higher review
scores than existing fully automated systems. Nevertheless, we identify
important limitations from both the author evaluation and the Agents4Science
reviews, indicating the potential risks of directly applying current AI
Scientist systems and key challenges for future research. Finally, we
comprehensively report various risks identified during development. We hope
these insights will deepen understanding of current progress and risks in AI
Scientist development.

</details>


### [54] [Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis](https://arxiv.org/abs/2511.04584)
*Daniel Gomm,Cornelius Wolff,Madelon Hulsebos*

Main category: cs.AI

TL;DR: 该论文提出将自然语言查询中的歧义重新定义为协作交互的特征，开发了一个区分可协作查询与不可协作查询的框架，分析了15个流行数据集中的查询类型，并提出了更明智的表格数据自然语言接口设计和评估方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法将自然语言查询中的歧义视为缺陷，但作者认为应该将其重新定义为协作交互的特征，让用户和系统共同承担查询规范的责任。

Method: 开发了一个原则性框架来区分可协作查询（可解析解释）和不可协作查询（无法解析），并将该框架应用于15个流行数据集的表格问答和分析评估中。

Result: 分析发现这些数据集中的查询类型混合控制不当，既不适合评估系统执行准确性，也不适合评估解释能力。

Conclusion: 该框架和分析将视角从修复歧义转向在解析查询中拥抱协作，为表格数据自然语言接口的设计和评估提供了更明智的方法和未来研究方向。

Abstract: Natural language interfaces to tabular data must handle ambiguities inherent
to queries. Instead of treating ambiguity as a deficiency, we reframe it as a
feature of cooperative interaction, where the responsibility of query
specification is shared among the user and the system. We develop a principled
framework distinguishing cooperative queries, i.e., queries that yield a
resolvable interpretation, from uncooperative queries that cannot be resolved.
Applying the framework to evaluations for tabular question answering and
analysis, we analyze the queries in 15 popular datasets, and observe an
uncontrolled mixing of query types neither adequate for evaluating a system's
execution accuracy nor for evaluating interpretation capabilities. Our
framework and analysis of queries shifts the perspective from fixing ambiguity
to embracing cooperation in resolving queries. This reflection enables more
informed design and evaluation for natural language interfaces for tabular
data, for which we outline implications and directions for future research.

</details>


### [55] [DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration](https://arxiv.org/abs/2511.04646)
*Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong*

Main category: cs.AI

TL;DR: DR. WELL是一个去中心化的神经符号框架，用于协作多智能体规划。通过两阶段协商协议（提出候选角色和承诺联合分配），智能体在符号层面而非轨迹层面进行协调，避免了脆弱的步级对齐，实现了可重用、可同步和可解释的高层操作。


<details>
  <summary>Details</summary>
Motivation: 协作多智能体规划中，智能体需要在部分信息和有限通信下做出联合决策。轨迹层面的协调经常失败，因为时间或运动的小偏差会级联成冲突。符号规划通过提高抽象级别和提供最小动作词汇来缓解这一挑战。

Method: 采用两阶段协商协议：智能体首先提出带推理的候选角色，然后在共识和环境约束下承诺联合分配。承诺后，每个智能体独立生成并执行其角色的符号计划，不透露详细轨迹。计划通过共享世界模型在执行结果中落地，该模型编码当前状态并随智能体行动更新。

Result: 在协作推块任务上的实验表明，智能体能够跨情景适应，动态世界模型捕获可重用模式，提高了任务完成率和效率。通过协商和自我精炼，动态世界模型以时间开销为代价，实现了演化且更高效的协作策略。

Conclusion: 通过符号规划而非原始轨迹进行推理，DR. WELL避免了脆弱的步级对齐，实现了可重用、可同步和可解释的高层操作，提高了多智能体协作的效率和适应性。

Abstract: Cooperative multi-agent planning requires agents to make joint decisions with
partial information and limited communication. Coordination at the trajectory
level often fails, as small deviations in timing or movement cascade into
conflicts. Symbolic planning mitigates this challenge by raising the level of
abstraction and providing a minimal vocabulary of actions that enable
synchronization and collective progress. We present DR. WELL, a decentralized
neurosymbolic framework for cooperative multi-agent planning. Cooperation
unfolds through a two-phase negotiation protocol: agents first propose
candidate roles with reasoning and then commit to a joint allocation under
consensus and environment constraints. After commitment, each agent
independently generates and executes a symbolic plan for its role without
revealing detailed trajectories. Plans are grounded in execution outcomes via a
shared world model that encodes the current state and is updated as agents act.
By reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids
brittle step-level alignment and enables higher-level operations that are
reusable, synchronizable, and interpretable. Experiments on cooperative
block-push tasks show that agents adapt across episodes, with the dynamic world
model capturing reusable patterns and improving task completion rates and
efficiency. Experiments on cooperative block-push tasks show that our dynamic
world model improves task completion and efficiency through negotiation and
self-refinement, trading a time overhead for evolving, more efficient
collaboration strategies.

</details>


### [56] [VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks](https://arxiv.org/abs/2511.04662)
*Yu Feng,Nathaniel Weir,Kaj Bostrom,Sam Bayless,Darion Cassel,Sapana Chaudhary,Benjamin Kiesl-Reiter,Huzefa Rangwala*

Main category: cs.AI

TL;DR: VeriCoT是一个神经符号方法，从CoT推理中提取并验证形式逻辑论证，通过一阶逻辑形式化推理步骤，使用自动求解器验证逻辑有效性，提高LLM推理的可信度。


<details>
  <summary>Details</summary>
Motivation: LLMs通过思维链可以进行多步推理，但无法可靠验证自身逻辑。即使得出正确答案，底层推理可能存在缺陷，这在高风险场景中削弱了可信度。

Method: VeriCoT将每个CoT推理步骤形式化为一阶逻辑，识别基于源上下文、常识知识或先前推理步骤的前提。符号表示支持自动求解器验证逻辑有效性，自然语言前提便于识别未接地或谬误推理步骤。

Result: 在ProofWriter、LegalBench和BioASQ数据集上的实验表明，VeriCoT能有效识别有缺陷的推理，并作为最终答案正确性的强预测指标。利用验证信号进行推理时自我反思、监督微调和偏好微调，进一步提高了推理有效性和准确性。

Conclusion: VeriCoT通过神经符号方法显著提升了LLM推理的可验证性和可信度，为高风险应用提供了可靠的推理验证机制。

Abstract: LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but
they cannot reliably verify their own logic. Even when they reach correct
answers, the underlying reasoning may be flawed, undermining trust in
high-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a
neuro-symbolic method that extracts and verifies formal logical arguments from
CoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order
logic and identifies premises that ground the argument in source context,
commonsense knowledge, or prior reasoning steps. The symbolic representation
enables automated solvers to verify logical validity while the NL premises
allow humans and systems to identify ungrounded or fallacious reasoning steps.
Experiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT
effectively identifies flawed reasoning, and serves as a strong predictor of
final answer correctness. We also leverage VeriCoT's verification signal for
(1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on
VeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct
preference optimization (DPO) using verification-based pairwise rewards,
further improving reasoning validity and accuracy.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [57] [Levers of Power in the Field of AI](https://arxiv.org/abs/2511.03859)
*Tammy Mackenzie,Sukriti Punj,Natalie Perez,Sreyoshi Bhaduri,Branislav Radeljic*

Main category: cs.CY

TL;DR: 本研究通过问卷调查分析决策者在AI实施中如何运用权力杠杆，创建了12个虚构人物角色来展示个人能动性、组织逻辑和制度基础设施在AI治理中的交集。


<details>
  <summary>Details</summary>
Motivation: 探讨学术界、政府、企业和公民社会的决策者如何在人工智能实施过程中处理权力问题，了解他们如何体验和运用权力杠杆来塑造对技术变革的制度响应。

Method: 使用基于新制度主义理论开发的制度治理框架，设计个性化问卷收集决策者的制度管辖范围见解，并将受访者的匿名真实回应转化为12个虚构的高层决策者人物角色。

Result: 展示了北美和欧洲决策者的12个虚构人物角色，揭示了个人能动性、组织逻辑和制度基础设施在AI治理中的相互作用，并提出了权力杠杆动态表和五个可检验假设。

Conclusion: 为制度内的政策制定者和公民社会中的同行提供了个人参与AI治理的方法见解，包括促进制度稳定和影响制度变革的策略。

Abstract: This paper examines how decision makers in academia, government, business,
and civil society navigate questions of power in implementations of artificial
intelligence. The study explores how individuals experience and exercise levers
of power, which are presented as social mechanisms that shape institutional
responses to technological change. The study reports on the responses of
personalized questionnaires designed to gather insight on a decision maker's
institutional purview, based on an institutional governance framework developed
from the work of Neo-institutionalists. Findings present the anonymized, real
responses and circumstances of respondents in the form of twelve fictional
personas of high-level decision makers from North America and Europe. These
personas illustrate how personal agency, organizational logics, and
institutional infrastructures may intersect in the governance of AI. The
decision makers' responses to the questionnaires then inform a discussion of
the field-level personal power of decision makers, methods of fostering
institutional stability in times of change, and methods of influencing
institutional change in the field of AI. The final section of the discussion
presents a table of the dynamics of the levers of power in the field of AI for
change makers and five testable hypotheses for institutional and social
movement researchers. In summary, this study provides insight on the means for
policymakers within institutions and their counterparts in civil society to
personally engage with AI governance.

</details>


### [58] [The Benefits of Data Storytelling in Accessible Teaching](https://arxiv.org/abs/2511.04024)
*Marina Buzzi,Barbara Leporini,Angelica Lo Duca*

Main category: cs.CY

TL;DR: 本文探讨了数据叙事作为实现无障碍教学的一种策略，特别是在数据素养教育中应用，以符合ADA法案要求。


<details>
  <summary>Details</summary>
Motivation: 计算机科学领域已广泛研究无障碍教学，但在其他学科如数据素养中的整合仍然有限，需要探索新的策略来使复杂信息对多样化学习者更易理解。

Method: 提出了基于ADA法案核心义务的六个设计原则，并通过模拟场景展示了这些原则在包容性学习环境中的具体应用。

Result: 研究表明，叙事驱动的数据呈现方式能够增强理解力、参与度，并在不同教育环境中实现更公平的访问。

Conclusion: 数据叙事是一种有效的策略，可以帮助教育工作者创建更包容的学习环境，使复杂数据对多样化学习者更加可访问。

Abstract: Accessible teaching has been extensively investigated in computer science,
yet its integration into other disciplines, such as data literacy, remains
limited. This paper examines the potential of data storytelling, defined as the
integration of data, visualizations, and narrative, as a possible strategy for
making complex information accessible to diverse learners in compliance with
Title II of the Americans with Disabilities Act (ADA). We propose six design
principles, derived from Title II's core obligations, to guide educators in
applying data storytelling within inclusive learning environments. A simulated
scenario shows the operationalization of these principles, illustrating how
narrative-driven data presentation can enhance comprehension, engagement, and
equitable access across different educational contexts.

</details>


### [59] [The Psychogeography of Imaginary Places](https://arxiv.org/abs/2511.04105)
*Michael Heron,Pauline Belford,Klara Aune*

Main category: cs.CY

TL;DR: 本文扩展了心理地理学实践到虚拟和虚构空间领域，探讨了如何在视频游戏世界的弹性空间和时间性中进行漫游，认为数字环境为意义创造和自我反思提供了新形式。


<details>
  <summary>Details</summary>
Motivation: 传统心理地理学主要关注物理环境对情感和行为的影响，但作者认为其哲学核心关注个人与环境之间的情感关系，这不需要局限于具体物理空间。因此希望将心理地理学扩展到虚拟和虚构空间。

Method: 借鉴文学、情境主义和当代心理地理学传统，分析视频游戏世界中的弹性空间性和时间性，探讨数字环境中的漫游实践。

Result: 数字环境作为完全构建的空间，为意义创造和自我反思提供了新形式，游戏成为心理地理学的实验室和景观。

Conclusion: 通过这种重构，游戏不仅成为街道和城市精神的实验室，也成为代码、像素和游戏中幽灵的心理地理学景观，为心理地理学注入了新的活力。

Abstract: Psychogeography -- the study of how environments shape emotion and behaviour
-- has long concerned itself with the emotional resonance of the physical,
often through the idea of the derive through the city. Its philosophical core,
however, is primarily concerned with identifying affective relationships
between the personal and the environmental, and this does not require the
constraint of concrete.
  This paper extends psychogeographical practice into the realm of the
imaginary, proposing a psychogeography of virtual and fictive spaces. Drawing
on literary, Situationist, and contemporary psychogeographical traditions, we
examine how the derive might operate within the elastic spatiality and
temporalities of video game worlds. We argue that digital environments, being
wholly constructed, invite new forms of meaning-making and self-reflection.
Through this reframing, games become both laboratory and landscape for a
revitalised psychogeography: one attuned not only to the spirits of streets and
cities, but also to the ghosts that haunt code, pixels, and play.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [60] [Measuring economic outlook in the news timely and efficiently](https://arxiv.org/abs/2511.04299)
*Elliot Beck,Franziska Eckert,Linus Kühne,Helge Liebert,Rina Rosenblatt-Wisch*

Main category: econ.GN

TL;DR: 结合机器学习和大型语言模型与传统统计方法，开发可解释、及时的经济情绪指标，显著提升GDP增长预测准确性


<details>
  <summary>Details</summary>
Motivation: 为央行和公共机构提供资源高效、模块化的解决方案，使其能在数据保密限制下利用先进语言模型分析经济情绪

Method: 将机器学习、大型语言模型与传统统计方法相结合，构建可解释的经济情绪追踪指标

Result: 该指标显著提高了GDP增长预测的准确性，且具有时效性和可解释性

Conclusion: 该方法为受数据保密限制的机构提供了利用先进语言模型的有效途径，在资源受限环境下实现了经济情绪分析的技术突破

Abstract: We introduce a novel indicator that combines machine learning and large
language models with traditional statistical methods to track sentiment
regarding the economic outlook in Swiss news. The indicator is interpretable
and timely, and it significantly improves the accuracy of GDP growth forecasts.
Our approach is resource-efficient, modular, and offers a way of benefitting
from state-of-the-art large language models even if data are proprietary and
cannot be stored or analyzed on external infrastructure - a restriction faced
by many central banks and public institutions.

</details>


### [61] [Regime Changes and Real-Financial Cycles: Searching Minsky's Hypothesis in a Nonlinear Setting](https://arxiv.org/abs/2511.04348)
*Domenico delli Gatti,Filippo Gusella,Giorgio Ricchiuti*

Main category: econ.GN

TL;DR: 该研究通过非线性模型扩展Stockhammer等人的工作，检验了1970-2020年间美国、法国、德国、加拿大、澳大利亚和英国的明斯基周期，发现除澳大利亚外所有国家都存在企业债务相关的真实-金融内生周期，以及利率相关的跨国周期，而家庭债务与GDP的互动机制仅在美国和英国显著。


<details>
  <summary>Details</summary>
Motivation: 扩展Stockhammer等人(2019)的线性模型，采用非线性模型来捕捉可能的局部真实-金融内生周期，更准确地评估明斯基理论。

Method: 使用非线性模型追踪非线性制度变化，检验1970-2020年间六个国家GDP与企业债务、利率和家庭债务之间的明斯基周期关系。

Result: 考虑企业债务时，除澳大利亚外的所有国家都存在真实-金融内生周期；考虑利率时，所有国家都存在周期；家庭债务与GDP的互动机制仅在美国和英国显著。

Conclusion: 非线性制度转变在实证评估明斯基理论中具有重要性，不同国家在不同债务类型下的周期性表现存在差异。

Abstract: This paper investigates Minsky's cycles by extending the paper of stockhammer
et al. (2019) with a nonlinear model to capture possible local real-financial
endogenous cycles. We trace nonlinear regime changes and check the presence of
Minsky cycles from the 1970s to 2020 for the USA, France, Germany, Canada,
Australia, and the UK, linking the GDP with corporate debt, interest rate, and
household debt. When considering corporate debt, the results reveal
real-financial endogenous cycles in all countries, except Australia, and across
all countries when interest rates are included. We find evidence for an
interaction mechanism between household debt and GDP only for the USA and the
UK. These findings underscore the importance of nonlinear regime transitions in
empirically assessing Minsky's theory.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [62] [Centralized Health and Exposomic Resource (C-HER): Analytic and AI-Ready Data for External Exposomic Research](https://arxiv.org/abs/2511.03750)
*Heidi A. Hanson,Joemy Ramsay,Josh Grant,Maggie Davis,Janet O. Agbaje,Dakotah Maguire,Jeremy Logan,Marissa Taddie,Chad Melton,Midgie MacFarland,James VanDerslice*

Main category: stat.AP

TL;DR: C-HER项目开发了数据工程解决方案，整合了30多个外部暴露组数据集，创建了分析和AI就绪数据(AAIRD)，以克服暴露组研究中时空关联的挑战。


<details>
  <summary>Details</summary>
Motivation: 暴露组是一个概念框架，用于研究复杂环境和遗传因素如何共同影响人类健康。由于暴露数据的高维度、多模态数据源和不同时空尺度，现有的暴露组综合测量方法很少。

Method: 开发数据工程解决方案，对30多个外部暴露组数据集进行识别、分析、空间索引和存储，创建AAIRD。

Result: 成功整合了环境数据，可用于区域特征描述、空气污染建模和癌症研究指标。AAIRD为未来研究提供了ML和深度学习方法生成空间和上下文暴露数据的基础。

Conclusion: AAIRD的开发将使未来研究能够使用机器学习和深度学习方法生成空间和上下文暴露数据，用于疾病预测。

Abstract: The Centralized Health and Exposomic Resource (C-HER) project has identified,
profiled, spatially indexed, and stored over 30 external exposomic datasets.
The resulting analytic and AI-ready data (AAIRD) provides a significant
opportunity to develop an integrated picture of the exposome for health
research. The exposome is a conceptual framework designed to guide the study of
the complex environmental and genetic factors that together shape human health.
Few composite measures of the exposome exist due to the high dimensionality of
exposure data, multimodal data sources, and varying spatiotemporal scales. We
develop a data engineering solution that overcomes the challenges of
spatio-temporal linkage in this field. We provide examples of how environmental
data can be combined to characterize a region, model air pollution, or provide
indicators for cancer research. The development of AAIRD will allow future
studies to use ML and deep learning methods to generate spatial and contextual
exposure data for disease prediction.

</details>


### [63] [Transportability of Prognostic Markers: Rethinking Common Practices through a Sufficient-Component-Cause Perspective](https://arxiv.org/abs/2511.04065)
*Mohsen Sadatsafavi,Gavin Pereira,Wenjia Chen*

Main category: stat.AP

TL;DR: 本文通过充分成分原因框架重新审视预后标志物的可移植性，挑战了传统的可移植性假设，提出了基于病因分布变化的新运输方法。


<details>
  <summary>Details</summary>
Motivation: 预后标志物在不同人群中性能存在差异，传统运输方法（直接使用或患病率调整）都依赖强假设，需要更透明的可移植性框架。

Method: 使用充分成分原因(SCC)框架分解风险预测的因果成分，分析不同运输方法对病因分布稳定性的假设，提出基于病因变化假设的新运输算法。

Result: 数值实验表明，不同的可移植性假设会导致不同程度的信息损失，取决于人群间病因分布的差异程度。

Conclusion: SCC视角挑战了标志物可移植性的常见假设和实践，提出了反映病因分布变化知识和假设的运输算法。

Abstract: Transportability, the ability to maintain performance across populations, is
a desirable property of of markers of clinical outcomes. However, empirical
findings indicate that markers often exhibit varying performances across
populations. For prognostic markers whose results are used to quantify of the
risk of an outcome, oftentimes a form of updating is required when the marker
is transported to populations with different disease prevalences. Here, we
revisit transportability of prognostic markers through the lens of the
foundational framework of sufficient component causes (SCC). We argue that
transporting a marker "as is" implicitly assumes predictive values are
transportable, whereas conventional prevalence-adjustment shifts the locus of
transportability to accuracy metrics (sensitivity and specificity). Using a
minimalist SCC framework that decomposes risk prediction into its causal
constituents, we show that both approaches rely on strong assumptions about the
stability of cause distributions across populations. A SCC framework instead
invites making transparent assumptions about how different causes vary across
populations, leading to different transportation methods. For example, in the
absence of any external information other than disease prevalence, a
cause-neutral perspective can assume all causes are responsible for change in
prevalence, leading to a new form of marker transportation. Numerical
experiments demonstrate that different transportability assumptions lead to
varying degrees of information loss, depending on how population differ from
each other in the distribution of causes. A SCC perspective challenges common
assumptions and practices for marker transportability, and proposes
transportation algorithms that reflect our knowledge or assumptions about how
causes vary across populations.

</details>


### [64] [Nonparametric Safety Stock Dimensioning: A Data-Driven Approach for Supply Chains of Hardware OEMs](https://arxiv.org/abs/2511.04616)
*Elvis Agbenyega,Cody Quick*

Main category: stat.AP

TL;DR: 提出一种数据驱动的方法，使用核密度估计确定需求分布，并考虑预测需求变异性，在库存补货模拟中优于传统正态分布方法。


<details>
  <summary>Details</summary>
Motivation: 传统安全库存计算方法假设需求服从正态分布且忽略未来需求变异性，在制造业中需求通常是非正态、间歇性和高度偏斜的，限制了这些方法的适用性。

Method: 使用核密度估计确定每个库存项目的需求分布，将分析从历史需求变异性扩展到预测需求变异性，通过线性优化模型确定最优安全库存配置。

Result: 在近真实世界的库存补货模拟中，数据驱动方法优于传统方法，以更低的安全库存水平实现了期望的服务水平。

Conclusion: 数据驱动方法能够放松正态性假设，更准确地处理非正态需求分布，在保持服务水平的同吋降低安全库存水平。

Abstract: Resilient supply chains are critical, especially for Original Equipment
Manufacturers (OEMs) that power today's digital economy. Safety Stock
dimensioning-the computation of the appropriate safety stock quantity-is one of
several mechanisms to ensure supply chain resiliency, as it protects the supply
chain against demand and supply uncertainties. Unfortunately, the major
approaches to dimensioning safety stock heavily assume that demand is normally
distributed and ignore future demand variability, limiting their applicability
in manufacturing contexts where demand is non-normal, intermittent, and highly
skewed. In this paper, we propose a data-driven approach that relaxes the
assumption of normality, enabling the demand distribution of each inventory
item to be analytically determined using Kernel Density Estimation. Also, we
extended the analysis from historical demand variability to forecasted demand
variability. We evaluated the proposed approach against a normal distribution
model in a near-world inventory replenishment simulation. Afterwards, we used a
linear optimization model to determine the optimal safety stock configuration.
The results from the simulation and linear optimization models showed that the
data-driven approach outperformed traditional approaches. In particular, the
data-driven approach achieved the desired service levels at lower safety stock
levels than the conventional approaches.

</details>


### [65] [Dynamic causal discovery in Alzheimer's disease through latent pseudotime modelling](https://arxiv.org/abs/2511.04619)
*Natalia Glazman,Jyoti Mangal,Pedro Borges,Sebastien Ourselin,M. Jorge Cardoso*

Main category: stat.AP

TL;DR: 提出了一种结合潜在变量模型的动态因果发现框架，用于阿尔茨海默病研究，通过推断疾病伪时间轨迹来学习因果关系的演化。


<details>
  <summary>Details</summary>
Motivation: 传统因果发现方法假设静态图结构，无法捕捉阿尔茨海默病等疾病中随潜在疾病进展而演变的病理生理学过程。

Method: 应用现有潜在变量模型推断疾病伪时间，独立于实际年龄对患者进行排序，然后学习因果关系的动态演化，并整合最小化的疾病无关背景知识。

Result: 伪时间在预测诊断方面优于实际年龄（AUC 0.82 vs 0.59），整合背景知识显著提高了图结构的准确性和方向性。

Conclusion: 该框架揭示了新型和已确立的AD标志物之间的动态相互作用，即使在假设被违反的情况下也能实现实用的因果发现。

Abstract: The application of causal discovery to diseases like Alzheimer's (AD) is
limited by the static graph assumptions of most methods; such models cannot
account for an evolving pathophysiology, modulated by a latent disease
pseudotime. We propose to apply an existing latent variable model to real-world
AD data, inferring a pseudotime that orders patients along a data-driven
disease trajectory independent of chronological age, then learning how causal
relationships evolve. Pseudotime outperformed age in predicting diagnosis (AUC
0.82 vs 0.59). Incorporating minimal, disease-agnostic background knowledge
substantially improved graph accuracy and orientation. Our framework reveals
dynamic interactions between novel (NfL, GFAP) and established AD markers,
enabling practical causal discovery despite violated assumptions.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [66] [OpenMENA: An Open-Source Memristor Interfacing and Compute Board for Neuromorphic Edge-AI Applications](https://arxiv.org/abs/2511.03747)
*Ali Safa,Farida Mohsen,Zainab Ali,Bo Wang,Amine Bermak*

Main category: cs.ET

TL;DR: OpenMENA是首个完全开源的忆阻器内存计算加速器系统，集成了硬件接口、固件软件栈和VIPI权重编程方法，支持推理和片上学习，并在数字识别和机器人避障任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 忆阻器交叉阵列能够实现内存内乘累加和局部可塑性学习，为能效边缘AI提供了一条路径。但缺乏开源、可复现的忆阻器接口系统阻碍了相关研究的发展。

Method: 开发了OpenMENA系统，包含：(i)可复现的忆阻器交叉阵列硬件接口，支持混合信号读-编程-验证循环；(ii)具有高级API的固件-软件栈，支持推理和片上学习；(iii)VIPI方法将预训练权重编程到模拟电导中，并通过芯片在环微调来缓解器件非理想性。

Result: 在数字识别任务中验证了从权重迁移到片上适应的完整流程，在真实世界机器人避障任务中，忆阻器模型成功学习将定位输入映射到电机命令。

Conclusion: OpenMENA作为开源系统发布，旨在民主化忆阻器使能的边缘AI研究，为社区提供了完整的硬件-软件解决方案。

Abstract: Memristive crossbars enable in-memory multiply-accumulate and local
plasticity learning, offering a path to energy-efficient edge AI. To this end,
we present Open-MENA (Open Memristor-in-Memory Accelerator), which, to our
knowledge, is the first fully open memristor interfacing system integrating (i)
a reproducible hardware interface for memristor crossbars with mixed-signal
read-program-verify loops; (ii) a firmware-software stack with high-level APIs
for inference and on-device learning; and (iii) a Voltage-Incremental
Proportional-Integral (VIPI) method to program pre-trained weights into analog
conductances, followed by chip-in-the-loop fine-tuning to mitigate device
non-idealities. OpenMENA is validated on digit recognition, demonstrating the
flow from weight transfer to on-device adaptation, and on a real-world robot
obstacle-avoidance task, where the memristor-based model learns to map
localization inputs to motor commands. OpenMENA is released as open source to
democratize memristor-enabled edge-AI research.

</details>


### [67] [Implementation of transformer-based LLMs with large-scale optoelectronic neurons on a CMOS image sensor platform](https://arxiv.org/abs/2511.04136)
*Neil Na,Chih-Hao Cheng,Shou-Chen Hsu,Che-Fu Liang,Chung-Chih Lin,Nathaniel Y. Na,Andrew I. Shieh,Erik Chen,Haisheng Rong,Richard A. Soref*

Main category: cs.ET

TL;DR: 提出基于CMOS图像传感器平台的大规模光电神经元实现Transformer模型，在40nm工艺下实现GPT-3级别模型推理，性能比数字电子器件提升约两个数量级。


<details>
  <summary>Details</summary>
Motivation: 数据中心运行大语言模型和相关AI应用导致能源消耗指数级增长，需要更高效的硬件解决方案。

Method: 在商用CMOS图像传感器平台上构建新型大规模光电神经元，集成所有必需的光电器件和电子电路到约2cm×3cm的芯片中。

Result: 在40nm CMOS工艺下，GPT-3的1750亿参数模型推理速度达到12.6 POPS，功率效率74 TOPS/W，面积效率19 TOPS/mm²，均比数字电子器件提升约两个数量级。量化格式和硬件误差影响极小。

Conclusion: 为模拟神经处理单元提供了一条实用新路径，可作为现有数字处理单元的补充。

Abstract: The recent rapid deployment of datacenter infrastructures for performing
large language models (LLMs) and related artificial intelligence (AI)
applications in the clouds is predicted to incur an exponentially growing
energy consumption in the near-term future. In this paper, we propose and
analyze the implementation of the transformer model, which is the cornerstone
of the modern LLMs, with novel large-scale optoelectronic neurons (OENs)
constructed over the commercially available complementary
metal-oxide-semiconductor (CMOS) image sensor (CIS) platform. With all of the
required optoelectronic devices and electronic circuits integrated in a chiplet
only about 2 cm by 3 cm in size, 175 billon parameters in the case of GPT-3 are
shown to perform inference at an unprecedented speed of 12.6 POPS using only a
40 nm CMOS process node, along with a high power efficiency of 74 TOPS/W and a
high area efficiency of 19 TOPS/mm2, both surpassing the related digital
electronics by roughly two orders of magnitude. The influence of the
quantization formats and the hardware induced errors are numerically
investigated, and are shown to have a minimal impact. Our study presents a new
yet practical path toward analog neural processing units (NPUs) to complement
existing digital processing units.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [68] [Price-Based Attention and Welfare](https://arxiv.org/abs/2511.03813)
*Kaushil Patel*

Main category: econ.TH

TL;DR: 消费者在离散商品选择中只关注价格低于阈值的商品，然后从中选择最偏好的商品。模型假设消费者有相同偏好但不同阈值，能够仅通过观察数据识别价格变化的福利影响。


<details>
  <summary>Details</summary>
Motivation: 研究有限理性消费者在离散商品选择中的行为模式，特别是价格阈值对选择的影响，以及这种选择行为与随机效用模型在福利分析上的差异。

Method: 构建消费者选择模型，假设消费者只考虑价格低于个人阈值的商品，然后从中选择最偏好的商品。使用观察性选择数据来识别价格变化的福利影响。

Result: 该模型的行为内容与重要的一类随机效用模型有重叠，但福利含义存在显著差异。在该模型下的等价变差分布一阶随机占优于随机效用模型下的分布。

Conclusion: 价格阈值模型提供了与随机效用模型不同的福利分析视角，表明考虑消费者有限理性特征对福利评估有重要影响。

Abstract: To choose between two discrete goods, a consumer pays attention to only those
with prices below a threshold. From these, she chooses her most preferred good.
We assume consumers in a population have the same preference but may have
different thresholds. Similar models of bounded rationality have been studied
in the empirical marketing literature. We fully characterize the model, and
using observational choice data alone, we identify the welfare implications of
a price change. The behavioral content of our model overlaps with an important
class of random utility models, but the welfare implications are meaningfully
different. The distribution of equivalent variation under our model first-order
stochastically dominates that under the random utility model.

</details>


### [69] [Cross-pollination dynamics of web-based social media: An application of insect-mediated pollen transfer](https://arxiv.org/abs/2511.03917)
*Raul A. Barreto,Angus Flavel*

Main category: econ.TH

TL;DR: 该论文提出了一种在线社交媒体间的交叉授粉模型，将用户跨平台互动比作昆虫授粉过程，分析了这种动态如何影响不同规模社交平台的流量分布和竞争格局。


<details>
  <summary>Details</summary>
Motivation: 研究在线社交媒体平台间的用户流动动态，理解交叉平台互动如何影响网络效应和平台竞争，特别是分析这种交叉授粉现象对不同规模平台的影响。

Method: 建立了一个理论模型，将用户跨平台访问比作昆虫授粉过程，其中'授粉者'（用户）在一次浏览会话中访问多个社交媒体平台，类似于昆虫在不同植物间传递花粉。

Result: 交叉授粉动态导致网络流量在平台间不均匀增长，大型社交网络获得不成比例的收益，但小型平台也能获得实质性竞争优势，促进了垄断竞争格局的形成。

Conclusion: 跨平台用户参与具有广泛价值，交叉授粉动态能够强化网络效应并增强互联性，随着中转应用的普及，社交媒体平台无论大小都将受益于拥抱这种交叉授粉动态。

Abstract: We propose a model of cross-pollination among online social media (OSM)
websites, where the dynamics of user interactions mimic insect-mediated pollen
transfer by pollinators. A pollinator acts as a vehicle enabling users to visit
multiple social media sites- akin to visiting different plants in the same
field- within a single browsing session. This approach frames geitonogamy in
self-incompatible plant species as analogous to the distribution of web traffic
across the social media landscape. A theoretical pollinator, allowing users to
choose among social media sites multiple times per trip, drives uneven
increases in web traffic across platforms, disproportionately benefiting the
largest social networks while providing tangible competitive advantages to
smaller OSMs. This heterogeneous landscape fosters monopolistic competition
among niche platforms, incentivizing smaller sites to promote cross-pollination
despite the larger relative gains to their bigger competitors. Our findings
underscore the broader value of cross-platform user engagement, highlighting
how cross-pollination dynamics can intensify network effects and bolster
interconnectivity. Cross pollination via new pass-through apps facilitates the
movement of attention, deepening and distributing engagement across multiple
destinations. As pass-through apps gain traction, their disproportionate impact
on traffic to social media platforms will incentivize social media platforms,
large and small, to embrace cross-pollination dynamics.

</details>


### [70] [A characterization of strategy-proof probabilistic assignment rules](https://arxiv.org/abs/2511.04142)
*Sai Praneeth Donthu,Souvik Roy,Soumyarup Sadhukhan,Gogulapati Sreedurga*

Main category: econ.TH

TL;DR: 本文研究概率分配问题，在自由对顶(FPT)和自由三顶(FTT)域上，证明了TTC规则是唯一满足SD-帕累托效率、SD-个体理性和SD-顶策略证明性的概率分配规则。


<details>
  <summary>Details</summary>
Motivation: 确定性分配问题已有深入研究，但概率设置下的研究较少。受实际考虑驱动，引入弱化的激励要求SD-顶策略证明性，只阻止那些增加代理人首选对象概率的操纵。

Method: 在FPT和FTT域上分析TTC规则的性质，使用SD-帕累托效率、SD-个体理性和SD-顶策略证明性等概念，并与确定性结果进行比较。

Result: 在FPT域上，TTC规则是唯一满足SD-帕累托效率、SD-个体理性和SD-顶策略证明性的概率分配规则。在FTT域上，即使将帕累托效率弱化为SD-对效率，该特征仍然成立。

Conclusion: 研究结果从三个维度推广了经典的确定性结果：从确定性扩展到概率设置，从完全策略证明性扩展到顶策略证明性，从无限制域扩展到更一般的FPT和FTT域。

Abstract: We study the classical probabilistic assignment problem, where finitely many
indivisible objects are to be probabilistically or proportionally assigned
among an equal number of agents. Each agent has an initial deterministic
endowment and a strict preference over the objects. While the deterministic
version of this problem is well understood, most notably through the
characterization of the Top Trading Cycles (TTC) rule by Ma (1994), much less
is known in the probabilistic setting. Motivated by practical considerations,
we introduce a weakened incentive requirement, namely
SD-top-strategy-proofness, which precludes only those manipulations that
increase the probability of an agent's top-ranked object.
  Our first main result shows that, on any free pair at the top (FPT) domain
(Sen, 2011), the TTC rule is the unique probabilistic assignment rule
satisfying SD-Pareto efficiency, SD-individual rationality, and
SD-top-strategy-proofness. We further show that this characterization remains
valid when Pareto efficiency is replaced by the weaker notion of SD-pair
efficiency, provided the domain satisfies the slightly stronger free triple at
the top (FTT) condition (Sen, 2011). Finally, we extend these results to the ex
post notions of efficiency and individual rationality.
  Together, our findings generalize the classical deterministic results of Ma
(1994) and Ekici (2024) along three dimensions: extending them from
deterministic to probabilistic settings, from full strategy-proofness to
top-strategy-proofness, and from the unrestricted domain to the more general
FPT and FTT domains.

</details>


### [71] [Comparison of Oracles: Part II](https://arxiv.org/abs/2511.04449)
*David Lagziel,Ehud Lehrer,Tao Wang*

Main category: econ.TH

TL;DR: 本文研究不完全信息博弈中信息提供者（预言机）向玩家公开披露信息的情况。一个预言机支配另一个预言机意味着在所有博弈中，前者可以复制后者诱导的均衡结果。本文扩展了Part I的分析，在一般环境下提供了预言机等价性（相互支配）的表征。


<details>
  <summary>Details</summary>
Motivation: 扩展不完全信息博弈中信息提供者支配关系的分析到一般环境，建立预言机等价性的理论框架，将Blackwell和Aumann的经典工作扩展到战略环境中。

Method: 发展了信息循环理论，扩展Blackwell(1951)和Aumann(1976)的经典理论到战略环境，在一般环境下表征预言机的等价关系。

Result: 提供了预言机等价性（相互支配）的完整表征，建立了信息循环理论在战略环境中的应用框架。

Conclusion: 通过发展信息循环理论，成功将Blackwell和Aumann的经典信息理论扩展到战略环境，为不完全信息博弈中信息提供者的等价关系提供了理论基础。

Abstract: This paper studies incomplete-information games in which an information
provider, an oracle, publicly discloses information to the players. One oracle
is said to dominate another if, in every game, it can replicate the equilibrium
outcomes induced by the latter. The companion Part I characterizes dominance
under deterministic signaling and under stochastic signaling with a unique
common knowledge component. The present paper extends the analysis to general
environments and provides a characterization of equivalence (mutual dominance)
among oracles. To this end, we develop a theory of information loops, thereby
extending the seminal work of Blackwell (1951) to strategic environments and
Aumann (1976)'s theory of common knowledge.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [72] [On excitation of control-affine systems and its use for data-driven Koopman approximants](https://arxiv.org/abs/2511.03734)
*Philipp Schmitz,Lea Bold,Friedrich M. Philipp,Mario Rosenfelder,Peter Eberhard,Henrik Ebel,Karl Worthmann*

Main category: eess.SY

TL;DR: 本文提出了一种用于控制仿射系统的数据拟合框架，通过基于子空间角度的输入选择来提高系统辨识的鲁棒性，从而提供更可靠的双线性EDMD方案。


<details>
  <summary>Details</summary>
Motivation: 控制仿射系统的Koopman算子和EDMD方法在建模复杂动力系统时面临数据需求高的问题，导致其应用困难。

Method: 提出了基于子空间角度的输入选择框架，确保最小奇异值达到期望阈值，并推导了最大化最小奇异值的最优性条件。

Result: 通过非完整机器人的双线性EDMD控制应用验证了所提方法的有效性。

Conclusion: 该框架提高了控制仿射系统辨识的鲁棒性，为双线性EDMD方案提供了更可靠的实现途径。

Abstract: The Koopman operator and extended dynamic mode decomposition (EDMD) as a
data-driven technique for its approximation have attracted considerable
attention as a key tool for modeling, analysis, and control of complex
dynamical systems. However, extensions towards control-affine systems resulting
in bilinear surrogate models are prone to demanding data requirements rendering
their applicability intricate. In this paper, we propose a framework for
data-fitting of control-affine mappings to increase the robustness margin in
the associated system identification problem and, thus, to provide more
reliable bilinear EDMD schemes. In particular, guidelines for input selection
based on subspace angles are deduced such that a desired threshold with respect
to the minimal singular value is ensured. Moreover, we derive necessary and
sufficient conditions of optimality for maximizing the minimal singular value.
Further, we demonstrate the usefulness of the proposed approach using bilinear
EDMD with control for non-holonomic robots.

</details>


### [73] [Hybrid ILM-NILM Smart Plug System](https://arxiv.org/abs/2511.03737)
*Dániel István Németh,Kálmán Tornai*

Main category: eess.SY

TL;DR: 提出一种混合负载分类方法，通过智能插座连接多个负载来降低安装成本，同时保持一定的控制粒度。


<details>
  <summary>Details</summary>
Motivation: 现有的侵入式和非侵入式负载分类方法各有优缺点，很少有研究将两者结合。智能插座方案虽然能控制单个设备但成本高，而非侵入式方法成本低但无法控制设备。

Method: 扩展智能插座方案，让一个智能插座通过延长线连接多个负载，形成混合负载分类解决方案。

Result: 该方法能够降低系统安装成本，同时保持一定的设备控制能力，解决了家庭中常见的一个插座连接多个设备的情况。

Conclusion: 通过混合负载分类方法，可以在控制粒度和安装成本之间取得平衡，为智能家居负载管理提供更实用的解决方案。

Abstract: Electrical load classification is generally divided into intrusive and
non-intrusive approaches, both having their limitations and advantages. With
the non-intrusive approach, controlling appliances is not possible, but the
installation cost of a single measurement device is cheap. In comparison,
intrusive, smart plug-based solutions offer individual appliance control, but
the installation cost is much higher. There have been very few approaches
aiming to combine these methods. In this paper we show that extending a smart
plug-based solution to multiple loads per plug can reduce control granularity
in favor of lowering the system's installation costs. Connecting various loads
to a Smart Plug through an extension cord is seldom considered in the
literature, even though it is common in households. This scenario is also
handled by the hybrid load classification solution presented in this paper.

</details>


### [74] [Kalman-Bucy Filtering with Randomized Sensing: Fundamental Limits and Sensor Network Design for Field Estimation](https://arxiv.org/abs/2511.03740)
*Xinyi Wang,Devansh R. Agrawal,Dimitra Panagou*

Main category: eess.SY

TL;DR: 本文在连续时间框架下研究了卡尔曼滤波器在随机丢失测量情况下的稳定性，推导了估计协方差的闭式上界，并将其应用于时空场估计，建立了与网格无关的清晰度下界，为传感器网络设计提供了高效指导。


<details>
  <summary>Details</summary>
Motivation: 研究卡尔曼滤波器在随机丢失测量和变化传感位置下的稳定性问题，旨在为传感器网络设计提供理论依据。

Method: 在连续时间框架下，考虑测量矩阵和噪声协方差作为随机过程，推导卡尔曼滤波器的期望估计协方差闭式上界，并将其应用于高斯过程建模的时空场估计。

Result: 建立了空间平均期望清晰度的网格无关下界，揭示了通过复合传感参数捕获传感器数量、噪声水平和测量频率影响的基本性能限制，仿真验证了该界限对离散时间卡尔曼滤波器的紧致性。

Conclusion: 所推导的性能界限为传感器网络部署前的设计问题提供了原则性和高效的指导，避免了离散时间公式所需的递归计算。

Abstract: Stability analysis of the Kalman filter under randomly lost measurements has
been widely studied. We revisit this problem in a general continuous-time
framework, where both the measurement matrix and noise covariance evolve as
random processes, capturing variability in sensing locations. Within this
setting, we derive a closed-form upper bound on the expected estimation
covariance for continuous-time Kalman filtering. We then apply this framework
to spatiotemporal field estimation, where the field is modeled as a Gaussian
process observed by randomly located, noisy sensors. Using clarity, introduced
in our earlier work as a rescaled form of the differential entropy of a random
variable, we establish a grid-independent lower bound on the spatially averaged
expected clarity. This result exposes fundamental performance limits through a
composite sensing parameter that jointly captures the effects of the number of
sensors, noise level, and measurement frequency. Simulations confirm that the
proposed bound is tight for the discrete-time Kalman filter, approaching it as
the measurement rate decreases, while avoiding the recursive computations
required in the discrete-time formulation. Most importantly, the derived limits
provide principled and efficient guidelines for sensor network design problem
prior to deployment.

</details>


### [75] [Electric Vehicle Charging Load Modeling: A Survey, Trends, Challenges and Opportunities](https://arxiv.org/abs/2511.03741)
*Xiachong Lin,Arian Prabowo,Imran Razzak,Hao Xue,Matthew Amos,Sam Behrens,Flora D. Salim*

Main category: eess.SY

TL;DR: 本文系统综述了过去五年电动汽车充电负荷模型，将建模方法分为统计、仿真和数据驱动三类，分析了信息融合的三个底层操作，并讨论了该领域的挑战与机遇。


<details>
  <summary>Details</summary>
Motivation: 电动汽车充电行为预测对基础设施规划和优化至关重要，但充电负荷受不确定性和随机性影响，现有文献缺乏对信息融合建模方法的系统分析。

Method: 对过去五年EV充电负荷模型进行全面综述，将建模方法分为统计方法、仿真方法和数据驱动方法三类，并分析信息融合在现有模型中的三个底层操作。

Result: 系统梳理了各类建模方法的优缺点，识别了信息融合在EV充电负荷建模中的关键作用，为理解不同建模方法提供了框架。

Conclusion: 讨论了该领域面临的挑战和机遇，为未来研究提供了指导方向，推动对电动汽车充电行为的深入理解和实际研究方向探索。

Abstract: The evolution of electric vehicles (EVs) is reshaping the automotive
industry, advocating for more sustainable transportation practices. Accurately
predicting EV charging behavior is essential for effective infrastructure
planning and optimization. However, the charging load of EVs is significantly
influenced by uncertainties and randomness, posing challenges for accurate
estimation. Furthermore, existing literature reviews lack a systematic analysis
of modeling approaches focused on information fusion. This paper
comprehensively reviews EV charging load models from the past five years. We
categorize state-of-the-art modeling methods into statistical, simulated, and
data-driven approaches, examining the advantages and drawbacks of each.
Additionally, we analyze the three bottom-up level operations of information
fusion in existing models. We conclude by discussing the challenges and
opportunities in the field, offering guidance for future research endeavors to
advance our understanding and explore practical research directions.

</details>


### [76] [A Model-Based Approach to Automated Digital Twin Generation in Manufacturing](https://arxiv.org/abs/2511.03742)
*Angelos Alexopoulos,Agorakis Bompotas,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Athanasios P. Kalogeras,Christos Alexakos*

Main category: eess.SY

TL;DR: 提出一个自动化数字孪生生成和部署平台，使用AutomationML工厂规划，结合GAI驱动的仿真场景生成和自动物理产线重配置，提升制造效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 现代制造需要高灵活性和可重构性来适应动态生产需求，基于模型的工程支持快速产线设计，但最终重配置需要仿真和验证。

Method: 开发一个自动化数字孪生生成和部署平台，基于AutomationML工厂规划，使用GAI驱动的仿真场景生成器，实现自动物理产线重配置。

Result: 该平台通过实时监控、仿真和重配置简化了制造过程，提高了效率和适应性。

Conclusion: 该平台成功实现了数字孪生的自动化生成和部署，为现代制造提供了高效、灵活的重配置解决方案。

Abstract: Modern manufacturing demands high flexibility and reconfigurability to adapt
to dynamic production needs. Model-based Engineering (MBE) supports rapid
production line design, but final reconfiguration requires simulations and
validation. Digital Twins (DTs) streamline this process by enabling real-time
monitoring, simulation, and reconfiguration. This paper presents a novel
platform that automates DT generation and deployment using AutomationML-based
factory plans. The platform closes the loop with a GAI-powered simulation
scenario generator and automatic physical line reconfiguration, enhancing
efficiency and adaptability in manufacturing.

</details>


### [77] [A convolutional neural network deep learning method for model class selection](https://arxiv.org/abs/2511.03743)
*Marios Impraimakis*

Main category: eess.SY

TL;DR: 提出了一种基于一维卷积神经网络的模型类别选择方法，仅使用系统响应信号即可识别动态系统的模型类别，无需输入信息或完整系统辨识。


<details>
  <summary>Details</summary>
Motivation: 传统模型类别选择方法通常需要系统输入信息或完整系统辨识，限制了在结构健康监测等实际应用中的使用。

Method: 使用单自由度响应信号及其类别信息训练一维卷积神经网络，并可选地使用卡尔曼滤波器融合加速度和位移数据。

Result: 该方法能够在线性和非线性动态系统以及3D建筑有限元模型中，准确识别由阻尼行为或迟滞行为引起的轻微信号变化对应的模型类别。

Conclusion: 该方法为结构健康监测应用提供了一个强大的工具，能够在仅使用响应信号的情况下有效选择模型类别。

Abstract: The response-only model class selection capability of a novel deep
convolutional neural network method is examined herein in a simple, yet
effective, manner. Specifically, the responses from a unique degree of freedom
along with their class information train and validate a one-dimensional
convolutional neural network. In doing so, the network selects the model class
of new and unlabeled signals without the need of the system input information,
or full system identification. An optional physics-based algorithm enhancement
is also examined using the Kalman filter to fuse the system response signals
using the kinematics constraints of the acceleration and displacement data.
Importantly, the method is shown to select the model class in slight signal
variations attributed to the damping behavior or hysteresis behavior on both
linear and nonlinear dynamic systems, as well as on a 3D building finite
element model, providing a powerful tool for structural health monitoring
applications.

</details>


### [78] [Predictive Compensation in Finite-Horizon LQ Games under Gauss-Markov Deviations](https://arxiv.org/abs/2511.03744)
*Navid Mojahed,Mahdis Rabbani,Shima Nazari*

Main category: eess.SY

TL;DR: 提出了一个预测补偿框架，用于处理存在高斯-马尔可夫偏差的有限时域离散时间线性二次动态博弈，其中一个玩家经历相关随机偏差，另一个玩家使用预测策略进行补偿。


<details>
  <summary>Details</summary>
Motivation: 在动态博弈中，玩家可能偏离反馈纳什策略，这些偏差可能具有相关性。现有方法未充分考虑未来相关性的影响，因此需要开发能够预测并补偿这种相关偏差的框架。

Method: 使用一阶自回归过程对相关随机偏差建模，开发预测补偿策略来预期未来相关性的影响，推导均值和协方差传播的闭式递推公式。

Result: 获得了均值和协方差传播的闭式递推公式，通过期望成本敏感性分析了性能改进效果。

Conclusion: 提出的预测补偿框架能够有效处理动态博弈中的相关随机偏差，通过预测未来相关性实现了性能改进。

Abstract: This paper presents a predictive compensation framework for finite-horizon
discrete-time linear quadratic dynamic games in the presence of Gauss-Markov
deviations from feedback Nash strategies. One player experiences correlated
stochastic deviations, modeled via a first-order autoregressive process, while
the other compensates using a predictive strategy that anticipates the effect
of future correlation. Closed-form recursions for mean and covariance
propagation are derived, and the resulting performance improvement is analyzed
through the sensitivity of expected cost.

</details>


### [79] [InvSim algorithm for pre-computing airplane flight controls in limited-range autonomous missions, and demonstration via double-roll maneuver of Mirage III fighters](https://arxiv.org/abs/2511.03745)
*Osama A. Marzouk*

Main category: eess.SY

TL;DR: 本文提出了一个用于6自由度固定翼飞机逆仿真的数学框架和数值方法，通过指定目标飞行轨迹来预测所需的飞行控制输入。


<details>
  <summary>Details</summary>
Motivation: 开发一个通用的数学框架来处理非对称固定翼飞机的6自由度运动方程，并专门针对逆仿真问题定制，其中目标飞行轨迹已知而需要预测控制输入。

Method: 建立包含体轴、惯性轴、风轴和球形飞行角度的数学框架，然后推导逆仿真方程，使用符号数学、四阶龙格-库塔法和有限差分法进行数值积分，计算发动机推力、副翼、升降舵和方向舵的偏转角度。

Result: 开发了一个数值程序，能够计算在整个机动时间内作为离散值的四个必要控制变量，使飞机能够实现由三个惯性笛卡尔坐标和欧拉滚转角指定的期望飞行轨迹。

Conclusion: 提出的飞行力学逆仿真数值程序能够有效预测实现特定飞行轨迹所需的控制输入，为飞行控制系统设计提供了实用工具。

Abstract: In this work, we start with a generic mathematical framework for the
equations of motion (EOM) in flight mechanics with six degrees of freedom
(6-DOF) for a general (not necessarily symmetric) fixed-wing aircraft. This
mathematical framework incorporates (1) body axes (fixed in the airplane at its
center of gravity), (2) inertial axes (fixed in the earth/ground at the
take-off point), wind axes (aligned with the flight path/course), (3) spherical
flight path angles (azimuth angle measured clockwise from the geographic north,
and elevation angle measured above the horizon plane), and (4) spherical flight
angles (angle of attack and sideslip angle). We then manipulate these equations
of motion to derive a customized version suitable for inverse simulation flight
mechanics, where a target flight trajectory is specified while a set of
corresponding necessary flight controls to achieve that maneuver are predicted.
We then present a numerical procedure for integrating the developed inverse
simulation (InvSim) system in time; utilizing (1) symbolic mathematics, (2)
explicit fourth-order Runge-Kutta (RK4) numerical integration technique, and
(3) expressions based on the finite difference method (FDM); such that the four
necessary control variables (engine thrust force, ailerons' deflection angle,
elevators' deflection angle, and rudder's deflection angle) are computed as
discrete values over the entire maneuver time, and these calculated control
values enable the airplane to achieve the desired flight trajectory, which is
specified by three inertial Cartesian coordinates of the airplane, in addition
to the Euler's roll angle. We finally demonstrate the proposed numerical
procedure of flight mechanics inverse simulation (InvSim).

</details>


### [80] [A Dynamic Recurrent Adjacency Memory Network for Mixed-Generation Power System Stability Forecasting](https://arxiv.org/abs/2511.03746)
*Guang An Ooi,Otavio Bertozzi,Mohd Asim Aftab,Charalambos Konstantinou,Shehab Ahmed*

Main category: eess.SY

TL;DR: 提出动态循环邻接记忆网络(DRAMN)，结合物理信息分析和深度学习，用于实时电力系统稳定性预测，在多个测试系统中达到99%以上的准确率。


<details>
  <summary>Details</summary>
Motivation: 现代电力系统中逆变器资源的高渗透率带来了复杂的动态行为，传统稳定性评估方法在可扩展性和泛化性方面面临挑战。

Method: 使用滑动窗口动态模式分解构建时变多层邻接矩阵，将图卷积操作直接集成到循环门控机制中，同时建模演化动态和时间依赖性。

Result: 在改进的IEEE 9总线、39总线和多端HVDC网络上验证，分别达到99.85%、99.90%和99.69%的平均准确率，优于所有基准模型。特征维度减少82%且性能无损失。

Conclusion: DRAMN实现了最先进的准确性，同时为电力系统操作员提供了增强的可解释性，适合在现代控制中心实时部署。

Abstract: Modern power systems with high penetration of inverter-based resources
exhibit complex dynamic behaviors that challenge the scalability and
generalizability of traditional stability assessment methods. This paper
presents a dynamic recurrent adjacency memory network (DRAMN) that combines
physics-informed analysis with deep learning for real-time power system
stability forecasting. The framework employs sliding-window dynamic mode
decomposition to construct time-varying, multi-layer adjacency matrices from
phasor measurement unit and sensor data to capture system dynamics such as
modal participation factors, coupling strengths, phase relationships, and
spectral energy distributions. As opposed to processing spatial and temporal
dependencies separately, DRAMN integrates graph convolution operations directly
within recurrent gating mechanisms, enabling simultaneous modeling of evolving
dynamics and temporal dependencies. Extensive validations on modified IEEE
9-bus, 39-bus, and a multi-terminal HVDC network demonstrate high performance,
achieving 99.85\%, 99.90\%, and 99.69\% average accuracies, respectively,
surpassing all tested benchmarks, including classical machine learning
algorithms and recent graph-based models. The framework identifies optimal
combinations of measurements that reduce feature dimensionality by 82\% without
performance degradation. Correlation analysis between dominant measurements for
small-signal and transient stability events validates generalizability across
different stability phenomena. DRAMN achieves state-of-the-art accuracy while
providing enhanced interpretability for power system operators, making it
suitable for real-time deployment in modern control centers.

</details>


### [81] [Analytical modelling of a stop-less modular bus service with an application to charging strategies comparison](https://arxiv.org/abs/2511.03754)
*Haoran Zhao,Neema Nassir,Andres Fielbaum*

Main category: eess.SY

TL;DR: 该研究开发了集成V2V充电技术的无停靠自主模块化(SLAM)公交服务的分析优化模型，分析了不同充电策略下的最优设计和可行性。


<details>
  <summary>Details</summary>
Motivation: 传统公交服务存在效率低下问题，特别是停靠时间过长增加了非下车乘客的乘车时间。同时，公交电动化虽然能减少温室气体排放和运营成本，但充电需求带来了新的运营约束。

Method: 开发了集成车辆到车辆(V2V)充电技术的SLAM公交服务分析优化模型，比较了无充电情况和不同充电策略下的最优设计。

Result: 随着客流增长，运营阶段依次为：低需求下的闲置容量、全小型公交车、全大型公交车，以及提出的频率上限机制（仅扩大公交车容量）。在移动充电策略下，还包括能源受限机制（频率下降）和最终在高需求下的不可行性。

Conclusion: 这些发现使运营商能够提供更高效的服务，为SLAM公交服务的运营规划提供了理论指导。

Abstract: Buses are a vital component of metropolitan public transport, yet
conventional bus services often struggle with inefficiencies including extended
dwelling time, which increases in-vehicle travel time for non-alighting
passengers. A stop-less autonomous modular (SLAM) bus service has emerged as a
solution, enabling dynamic capacity to reduce dwelling time. Meanwhile, the
electrification of buses is advancing as a strategy to mitigate greenhouse gas
emissions and reduces operators' costs, but introduces new operational
constraints due to charging requirements. This study develops analytical
optimization models for SLAM bus service that integrates vehicle-to-vehicle
(V2V) charging technology. By comparing the optimal designs and their
feasibility across non-charging case and charging strategies, we identify a
sequence of operational stages as ridership grows: from idle capacity under low
demand, to full small buses, full large buses, and a proposed frequency-capped
regime where only bus capacity expands. Under the mobile charging strategy,
this progression further includes an energy-limited regime, in which frequency
declines, and ultimately infeasibility under high demand. These findings enable
operators to deliver more efficient services.

</details>


### [82] [Removing Time-Scale Separation in Feedback-Based Optimization via Estimators](https://arxiv.org/abs/2511.03903)
*Niloufar Yousefi,John W. Simpson-Porco*

Main category: eess.SY

TL;DR: 提出了一种基于估计器的反馈优化方法改进，通过利用动态系统模型信息消除传统反馈优化中的时间尺度分离要求，从而显著提高闭环系统性能。


<details>
  <summary>Details</summary>
Motivation: 传统反馈优化需要控制器比被控系统运行在更慢的时间尺度上，这严重限制了闭环性能。为了解决这个权衡问题，需要消除时间尺度分离的要求。

Method: 提出基于估计器的反馈优化改进方法，利用动态系统模型信息来设计控制器，不再需要时间尺度分离。

Result: 新方法使闭环系统的收敛速率仅受限于开环系统的主导特征值，显著提高了性能。该方法还可扩展到基于近似模型的设计。

Conclusion: 所提出的基于估计器的反馈优化方法成功消除了传统方法的时间尺度限制，在电力系统频率控制等应用中展现出优越性能。

Abstract: Feedback-based optimization (FBO) provides a simple control framework for
regulating a stable dynamical system to the solution of a constrained
optimization problem in the presence of exogenous disturbances, and does so
without full knowledge of the plant dynamics. However, closed-loop stability
requires the controller to operate on a sufficiently slower timescale than the
plant, significantly constraining achievable closed-loop performance. Motivated
by this trade-off, we propose an estimator-based modification of FBO which
leverages dynamic plant model information to eliminate the time-scale
separation requirement of traditional FBO. Under this design, the convergence
rate of the closed-loop system is limited only by the dominant eigenvalue of
the open-loop system. We extend the approach to the case of design based on
only an approximate plant model when the original system is singularly
perturbed. The results are illustrated via an application to fast power system
frequency control using inverter-based resources.

</details>


### [83] [A Co-simulation Framework for Quadrotor Control System Design using ROS 2 and MATLAB/Simulink](https://arxiv.org/abs/2511.03969)
*Hangyu Teng*

Main category: eess.SY

TL;DR: 提出了一个集成ROS 2和MATLAB/Simulink的协同仿真框架，用于四旋翼无人机控制系统设计和验证，包含非线性动力学模型、分层控制架构和跨平台数据交换机制。


<details>
  <summary>Details</summary>
Motivation: 协同仿真是复杂信息物理系统设计和分析的关键方法，能提高开发效率并降低成本。

Method: 1. 基于牛顿-欧拉方程推导四旋翼六自由度非线性动力学模型；2. 设计分层控制架构：LQR控制器用于姿态控制，PID控制器用于位置控制；3. 实现跨平台数据交换机制。

Result: 仿真结果验证了框架的有效性，能够为无人机控制算法提供高效的快速原型设计和软件在环验证解决方案。

Conclusion: 该框架为无人机控制算法的快速原型设计和软件在环验证提供了高效、标准化的解决方案。

Abstract: Co-simulation is a critical approach for the design and analysis of complex
cyber-physical systems. It will enhance development efficiency and reduce
costs. This paper presents a co-simulation framework integrating ROS 2 and
MATLAB/Simulink for quadrotor unmanned aerial vehicle (UAV) control system
design and verification. First, a six-degree-of-freedom nonlinear dynamic model
of the quadrotor is derived accurately that based on Newton-Euler equations.
Second, within the proposed framework, a hierarchical control architecture was
designed and implemented: LQR controller for attitude control to achieve
optimal regulation performance, and PID controller for position control to
ensure robustness and practical applicability. Third, elaborated the
architecture of the framework, including the implementation details of the
cross-platform data exchange mechanism. Simulation results demonstrate the
effectiveness of the framework, highlighting its capability to provide an
efficient and standardized solution for rapid prototyping and
Software-in-the-Loop (SIL) validation of UAV control algorithms.

</details>


### [84] [Necessary and Sufficient Conditions for the Optimization-Based Concurrent Execution of Learned Robotic Tasks](https://arxiv.org/abs/2511.04054)
*Sheikh A. Tahmid,Gennaro Notomista*

Main category: eess.SY

TL;DR: 本文提出了关于多任务强化学习价值函数并发执行的理论条件，扩展了基于优化的多任务执行框架。


<details>
  <summary>Details</summary>
Motivation: 先前的工作开发了基于优化的多任务执行框架，但未回答何时可以并发执行学习到的价值函数这一基本问题。

Method: 使用先前提出的最小范数控制器，提出了在状态空间子集中并发执行学习任务集的必要和充分条件定理。

Result: 定理揭示了何时可以使学习到的控制任务并发执行、何时它们已经固有地可并发执行，以及何时无法使用现有方法实现并发执行。

Conclusion: 扩展了基于优化的框架以处理带折扣因子的价值函数，使整体框架更符合标准强化学习实践。

Abstract: In this work, we consider the problem of executing multiple tasks encoded by
value functions, each learned through Reinforcement Learning, using an
optimization-based framework. Prior works develop such a framework, but left
unanswered a fundamental question of when learned value functions can be
concurrently executed. The main contribution of this work is to present
theorems which provide necessary and sufficient conditions to concurrently
execute sets of learned tasks within subsets of the state space, using a
previously proposed min-norm controller. These theorems provide insight into
when learned control tasks are possible to be made concurrently executable,
when they might already inherently be concurrently executable and when it is
not possible at all to make a set of learned tasks concurrently executable
using the previously proposed methods. Additional contributions of this work
include extending the optimization-based framework to execute multiple tasks
encoded by value functions to also account for value functions trained with a
discount factor, making the overall framework more compatible with standard RL
practices.

</details>


### [85] [Differential Flatness of Quasi-Static Slider-Pusher Models with Applications in Control](https://arxiv.org/abs/2511.04246)
*Sander De Witte,Tom Lefebvre,Thomas Neve,Andras Retzler,Guillaume Crevecoeur*

Main category: eess.SY

TL;DR: 本文研究了平面滑块-推动器系统作为操作任务中运动基元的动态特性，建立了基于极限表面方法的微分运动学模型，分析了系统的微分平坦性，并提出了两种轨迹跟踪控制策略。


<details>
  <summary>Details</summary>
Motivation: 研究平面滑块-推动器系统的动态特性，将其作为操作任务中的运动基元，探索其微分平坦性以简化控制综合和规划。

Method: 构建了基于极限表面方法的微分运动学模型，分析了多边形滑块和圆形推动器系统的微分平坦性，提出了级联准静态反馈策略和动态反馈线性化方法两种控制策略。

Result: 通过包含扰动模型和输入噪声的闭环仿真以及物理实验验证了所提控制策略的有效性，实验结果表明仿真增益在实际系统中具有适用性。

Conclusion: 平面滑块-推动器系统具有微分平坦性，所提出的控制策略在实际操作任务中具有应用潜力。

Abstract: This paper investigates the dynamic properties of planar slider-pusher
systems as a motion primitive in manipulation tasks. To that end, we construct
a differential kinematic model deriving from the limit surface approach under
the quasi-static assumption and with negligible contact friction. The
quasi-static model applies to generic slider shapes and circular pusher
geometries, enabling a differential kinematic representation of the system.
From this model, we analyze differential flatness - a property advantageous for
control synthesis and planning - and find that slider-pusher systems with
polygon sliders and circular pushers exhibit flatness with the centre of mass
as a flat output. Leveraging this property, we propose two control strategies
for trajectory tracking: a cascaded quasi-static feedback strategy and a
dynamic feedback linearization approach. We validate these strategies through
closed-loop simulations incorporating perturbed models and input noise, as well
as experimental results using a physical setup with a finger-like pusher and
vision-based state detection. The real-world experiments confirm the
applicability of the simulation gains, highlighting the potential of the
proposed methods for

</details>


### [86] [ComEMS4Build: Comfort-Oriented Energy Management System for Residential Buildings using Hydrogen for Seasonal Storage](https://arxiv.org/abs/2511.04293)
*Jovana Kovačević,Felix Langner,Erfan Tajalli-Ardekani,Marvin Dorn,Simon Waczowicz,Ralf Mikut,Jörg Matthes,Hüseyin K. Çakmak,Veit Hagenmeyer*

Main category: eess.SY

TL;DR: 本研究开发了一种面向舒适度的住宅建筑能源管理系统(ComEMS4Build)，该系统整合光伏、电池储能和氢储能，通过模糊逻辑控制实现热舒适与成本效益的平衡。


<details>
  <summary>Details</summary>
Motivation: 将柔性负荷和储能系统整合到住宅领域有助于协调波动性可再生能源发电与需求。氢储能系统可实现季节性能量转移，但初始成本高，因此需要开发智能管理系统来优化系统规模和使用效率。

Method: 开发基于模糊逻辑的ComEMS4Build系统，包含光伏、电池储能和氢储能，其中燃料电池和热泵作为互补技术。采用半合成建模方法在德国一个家庭住宅中进行12周冬季评估，并与基于规则的控制(RBC)和模型预测控制(MPC)进行对比。

Result: ComEMS4Build在12周中有10周未违反居住者热舒适，表现与MPC相似，而RBC的中位不适感为0.68 Kh。ComEMS4Build每周电费比MPC增加12.06欧元，而RBC增加30.14欧元。ComEMS4Build提高了混合储能系统利用率和与主电网的能量交换效率。

Conclusion: ComEMS4Build在保持热舒适的同时实现了合理的成本控制，相比传统RBC方法在系统利用率和成本效益方面有显著改进，但在燃料电池操作方面RBC具有减少切换次数和工作时间的优势。

Abstract: Integrating flexible loads and storage systems into the residential sector
contributes to the alignment of volatile renewable generation with demand.
Besides batteries serving as a short-term storage solution, residential
buildings can benefit from a Hydrogen (H2) storage system, allowing seasonal
shifting of renewable energy. However, as the initial costs of H2 systems are
high, coupling a Fuel Cell (FC) with a Heat Pump (HP) can contribute to the
size reduction of the H2 system. The present study develops a Comfort-Oriented
Energy Management System for Residential Buildings (ComEMS4Build) comprising
Photovoltaics (PV), Battery Energy Storage System (BESS), and H2 storage, where
FC and HP are envisioned as complementary technologies. The fuzzy-logic-based
ComEMS4Build is designed and evaluated over a period of 12 weeks in winter for
a family household building in Germany using a semi-synthetic modeling
approach. The Rule-Based Control (RBC), which serves as a lower benchmark, is a
scheduler designed to require minimal inputs for operation. The Model
Predictive Control (MPC) is intended as a cost-optimal benchmark with an ideal
forecast. The results show that ComEMS4Build, similar to MPC, does not violate
the thermal comfort of occupants in 10 out of 12 weeks, while RBC has a
slightly higher median discomfort of 0.68 Kh. The ComEMS4Build increases the
weekly electricity costs by 12.06 EUR compared to MPC, while RBC increases the
weekly costs by 30.14 EUR. The ComEMS4Build improves the Hybrid Energy Storage
System (HESS) utilization and energy exchange with the main grid compared to
the RBC. However, when it comes to the FC operation, the RBC has an advantage,
as it reduces the toggling counts by 3.48% and working hours by 7.59% compared
to MPC...

</details>


### [87] [Data-Driven Modeling of Photosynthesis Regulation Under Oscillating Light Condition - Part I: In-Silico Exploration](https://arxiv.org/abs/2511.04330)
*Christian Portilla,Arviandy G Aribowo,Ramachandran Anantharaman,César A Gómez-Pérez,Leyla Özkan*

Main category: eess.SY

TL;DR: 该论文应用频域数据驱动系统辨识技术，在振荡光照条件下建立简化的光合作用调控控制导向模型，通过Basic DREAM Model生成仿真数据，使用BLA方法估计二阶LTI传递函数模型，并构建基于光照强度DC值的LPV表示。


<details>
  <summary>Details</summary>
Motivation: 探索在振荡光照条件下光合作用调控的简化控制导向模型，为光合作用系统的控制应用提供理论基础。

Method: 使用Basic DREAM Model生成仿真数据，以光照强度信号（包含DC和AC分量）为输入，叶绿素荧光为输出，应用BLA方法估计二阶LTI传递函数模型，并构建基于光照强度DC值的LPV状态空间表示。

Result: 成功建立了在不同操作条件下（由光照强度的DC水平和调制频率定义）的局部线性模型，并构建了统一的LPV系统表示。

Conclusion: 数据驱动的频域系统辨识方法能够有效获得光合作用调控的简化控制导向模型，LPV表示提供了系统动力学的紧凑状态空间描述。

Abstract: This paper explores the application of data-driven system identification
techniques in the frequency domain to obtain simplified, control-oriented
models of photosynthesis regulation under oscillating light conditions.
In-silico datasets are generated using simulations of the physics-based Basic
DREAM Model (BDM) Funete et al.[2024], with light intensity signals --
comprising DC (static) and AC (modulated) components as input and chlorophyll
fluorescence (ChlF) as output. Using these data, the Best Linear Approximation
(BLA) method is employed to estimate second-order linear time-invariant (LTI)
transfer function models across different operating conditions defined by DC
levels and modulation frequencies of light intensity. Building on these local
models, a Linear Parameter-Varying (LPV) representation is constructed, in
which the scheduling parameter is defined by the DC values of the light
intensity, providing a compact state-space representation of the system
dynamics.

</details>


### [88] [Overview and Performance Evaluation of Supervisory Controller Synthesis with Eclipse ESCET v4.0](https://arxiv.org/abs/2511.04370)
*Dennis Hendriks,Michel Reniers,Wan Fokkink,Wytse Oortwijn*

Main category: eess.SY

TL;DR: 本文介绍了ESCET开源项目中CIF建模语言的符号化监督控制器综合算法，包括防止运行时错误、处理不同类型需求和输入变量等实用方面，并提出了包含23个工业与学术模型的基准测试集，评估了从v0.8到v4.0版本的性能改进。


<details>
  <summary>Details</summary>
Motivation: 监督控制器确保信息物理系统的正确安全运行，综合化工程方法旨在自动化设计和实现过程，让工程师专注于系统需求而非实现细节。

Method: 使用CIF建模语言的符号化监督控制器综合算法，包含防止运行时错误、处理不同需求类型和支持输入变量等实用特性；采用多级综合方法进行非整体化综合；建立23个基准模型进行性能评估。

Result: ESCET从v0.8到v4.0版本在综合性能上有显著改进，多级综合方法能进一步提升性能，但对于复杂模型的综合仍需更多性能优化。

Conclusion: CIF的综合算法在实用性和性能方面都有重要进展，多级综合方法提供了性能提升潜力，但处理复杂模型时仍需进一步优化综合性能。

Abstract: Supervisory controllers control cyber-physical systems to ensure their
correct and safe operation. Synthesis-based engineering (SBE) is an approach to
largely automate their design and implementation. SBE combines model-based
engineering with computer-aided design, allowing engineers to focus on 'what'
the system should do (the requirements) rather than 'how' it should do it
(design and implementation). In the Eclipse Supervisory Control Engineering
Toolkit (ESCET) open-source project, a community of users, researchers, and
tool vendors jointly develop a toolkit to support the entire SBE process,
particularly through the CIF modeling language and tools. In this paper, we
first provide a description of CIF's symbolic supervisory controller synthesis
algorithm, and thereby include aspects that are often omitted in the
literature, but are of great practical relevance, such as the prevention of
runtime errors, handling different types of requirements, and supporting input
variables (to connect to external inputs). Secondly, we introduce and describe
CIF's benchmark models, a collection of 23 freely available industrial and
academic models of various sizes and complexities. Thirdly, we describe recent
improvements between ESCET versions v0.8 (December 2022) and v4.0 (June 2024)
that affect synthesis performance, evaluate them on our benchmark models, and
show the current practical synthesis performance of CIF. Fourthly, we briefly
look at multi-level synthesis, a non-monolithic synthesis approach, evaluate
its gains, and show that while it can help to further improve synthesis
performance, further performance improvements are still needed to synthesize
complex models.

</details>


### [89] [Deep Koopman Economic Model Predictive Control of a Pasteurisation Unit](https://arxiv.org/abs/2511.04437)
*Patrik Valábek,Michaela Horváthová,Martin Klaučo*

Main category: eess.SY

TL;DR: 提出了一种基于深度Koopman的经济模型预测控制方法，用于实验室规模巴氏杀菌单元的高效运行，相比传统方法实现了45%的开环预测精度提升和32%的总经济成本降低。


<details>
  <summary>Details</summary>
Motivation: 为了解决复杂非线性系统在控制优化中的计算困难，同时准确表示巴氏杀菌单元的复杂动态，需要将非线性系统转换为线性表示以应用凸优化方法。

Method: 使用Koopman算子理论将非线性系统动态转换为线性表示，利用神经网络从实验数据中学习线性动态，并在EMPC框架中包含可解释的经济成本（能耗、材料损失、执行器磨损）。

Result: 深度Koopman EMPC相比传统N4SID方法实现了45%的开环预测精度提升，32%的总经济成本降低，以及10.2%的稳态运行电能减少。

Conclusion: 将深度Koopman表示与经济优化相结合，可以实现热密集型工厂的资源高效控制，具有显著的实践优势。

Abstract: This paper presents a deep Koopman-based Economic Model Predictive Control
(EMPC) for efficient operation of a laboratory-scale pasteurization unit (PU).
The method uses Koopman operator theory to transform the complex, nonlinear
system dynamics into a linear representation, enabling the application of
convex optimization while representing the complex PU accurately. The deep
Koopman model utilizes neural networks to learn the linear dynamics from
experimental data, achieving a 45% improvement in open-loop prediction accuracy
over conventional N4SID subspace identification. Both analyzed models were
employed in the EMPC formulation that includes interpretable economic costs,
such as energy consumption, material losses due to inadequate pasteurization,
and actuator wear. The feasibility of EMPC is ensured using slack variables.
The deep Koopman EMPC and N4SID EMPC are numerically validated on a nonlinear
model of multivariable PU under external disturbance. The disturbances include
feed pump fail-to-close scenario and the introduction of a cold batch to be
pastuerized. These results demonstrate that the deep Koopmand EMPC achieves a
32% reduction in total economic cost compared to the N4SID baseline. This
improvement is mainly due to the reductions in material losses and energy
consumption. Furthermore, the steady-state operation via Koopman-based EMPC
requires 10.2% less electrical energy. The results highlight the practical
advantages of integrating deep Koopman representations with economic
optimization to achieve resource-efficient control of thermal-intensive plants.

</details>


### [90] [Deep Dictionary-Free Method for Identifying Linear Model of Nonlinear System with Input Delay](https://arxiv.org/abs/2511.04451)
*Patrik Valábek,Marek Wadinger,Michal Kvasnica,Martin Klaučo*

Main category: eess.SY

TL;DR: 提出了一种基于LSTM增强的深度Koopman模型，用于近似具有输入延迟的非线性动力系统的Koopman算子，实现线性表示并提高预测精度。


<details>
  <summary>Details</summary>
Motivation: 具有输入延迟的非线性动力系统在预测、估计和控制方面存在显著挑战，传统线性控制技术往往失效，需要创新方法。

Method: 使用LSTM增强的深度Koopman模型，通过LSTM层捕捉历史依赖关系，将时滞系统动态高效编码到潜在空间，无需预定义字典。

Result: 在模拟系统上与扩展eDMD进行定量比较，当真实非线性动态未知时，预测精度有显著提升；在已知系统动态时，结果与eDMD相当。

Conclusion: LSTM增强的深度Koopman模型为处理具有输入延迟的非线性系统提供了一种有效的字典无关方法，在未知动态情况下表现优异。

Abstract: Nonlinear dynamical systems with input delays pose significant challenges for
prediction, estimation, and control due to their inherent complexity and the
impact of delays on system behavior. Traditional linear control techniques
often fail in these contexts, necessitating innovative approaches. This paper
introduces a novel approach to approximate the Koopman operator using an
LSTM-enhanced Deep Koopman model, enabling linear representations of nonlinear
systems with time delays. By incorporating Long Short-Term Memory (LSTM)
layers, the proposed framework captures historical dependencies and efficiently
encodes time-delayed system dynamics into a latent space. Unlike traditional
extended Dynamic Mode Decomposition (eDMD) approaches that rely on predefined
dictionaries, the LSTM-enhanced Deep Koopman model is dictionary-free, which
mitigates the problems with the underlying dynamics being known and
incorporated into the dictionary. Quantitative comparisons with extended eDMD
on a simulated system demonstrate highly significant performance gains in
prediction accuracy in cases where the true nonlinear dynamics are unknown and
achieve comparable results to eDMD with known dynamics of a system.

</details>


### [91] [Data-driven uncertainty-aware seakeeping prediction of the Delft 372 catamaran using ensemble Hankel dynamic mode decomposition](https://arxiv.org/abs/2511.04461)
*Giorgio Palma,Andrea Serani,Matteo Diez*

Main category: eess.SY

TL;DR: 本研究提出并验证了一种基于集成学习的Hankel动态模态分解控制方法(HDMDc)，用于高速双体船的不确定性感知耐波性预测。通过对比贝叶斯HDMDc和频率主义HDMDc两种集成策略，发现FHDMDc方法在预测精度和不确定性量化方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够提供不确定性量化的高效耐波性预测方法，以支持船舶设计和运营决策。传统确定性模型无法提供预测的不确定性信息，而集成学习方法可以解决这一问题。

Method: 使用HDMDc算法构建无方程线性降阶模型，通过状态和输入的时滞副本来捕捉非线性和记忆效应。比较两种集成策略：贝叶斯HDMDc（采样超参数）和频率主义HDMDc（数据子集聚合）。

Result: FHDMDc方法相比确定性模型提高了预测精度，并提供了稳健的不确定性估计。FHDMDc导出的运动概率密度函数与实验数据和URANS结果高度匹配。而BHDMDc在当前测试案例中相比确定性模型没有明显优势。

Conclusion: FHDMDc方法能够提供可靠且计算高效的耐波性预测，适用于船舶设计和运营支持，其不确定性量化能力为决策提供了重要信息。

Abstract: In this study, we present and validate an ensemble-based Hankel Dynamic Mode
Decomposition with control (HDMDc) for uncertainty-aware seakeeping predictions
of a high-speed catamaran, namely the Delft 372 model. Experimental
measurements (time histories) of wave elevation at the longitudinal center of
gravity, heave, pitch, notional flight-deck velocity, notional bridge
acceleration, and total resistance were collected from irregular wave basin
tests on a 1:33.3 scale replica of the Delft 372 model under sea state 5
conditions at Fr = 0.425, and organized into training, validation, and test
sets. The HDMDc algorithm constructs an equation-free linear reduced-order
model of the seakeeping vessel by augmenting states and inputs with their
time-lagged copies to capture nonlinear and memory effects. Two ensembling
strategies, namely Bayesian HDMDc (BHDMDc), which samples hyperparameters
considered stochastic variables with prior distribution to produce posterior
mean forecasts with confidence intervals, and Frequentist HDMDc (FHDMDc), which
aggregates multiple model obtained over data subsets, are compared in providing
seakeeping prediction and uncertainty quantification. The FHDMDc approach is
found to improve the accuracy of the predictions compared to the deterministic
counterpart, also providing robust uncertainty estimation; whereas the
application of BHDMDc to the present test case is not found beneficial in
comparison to the deterministic model. FHDMDc-derived probability density
functions for the motions closely match both experimental data and URANS
results, demonstrating reliable and computationally efficient seakeeping
prediction for design and operational support.

</details>


### [92] [AI-Driven Phase-Shifted Carrier Optimization for Cascaded Bridge Converters, Modular Multilevel Converters, and Reconfigurable Batteries](https://arxiv.org/abs/2511.04470)
*Amin Hashemi-Zadeh,Nima Tashakor,Sandun Hettiarachchi,Stefan Goetz*

Main category: eess.SY

TL;DR: 提出一种神经网络方法替代传统优化器，用于优化级联桥式变换器中的相移角，显著降低计算负担，实现实时电流纹波和谐波失真减少。


<details>
  <summary>Details</summary>
Motivation: 传统相移载波PWM在模块调制指数不同时会产生非均匀脉冲宽度，导致显著的电流纹波和输出电压失真，而传统优化方法计算负担过重，无法在嵌入式控制器中实时应用。

Method: 使用神经网络模拟瞬时优化器行为，通过一次训练即可适应不同系统规模，并包含简单的缩放策略，允许将训练好的网络复用于更大系统而无需重新训练。

Result: 平均可减少50%的电流纹波和加权总谐波失真，比传统优化器（如遗传算法）快10万到50万倍，适合在线应用。

Conclusion: 该方法为级联桥式变换器提供了一种高效、实时的相移角优化解决方案，解决了传统优化方法计算负担过重的问题。

Abstract: Phase-shifted carrier pulse-width modulation (PSC-PWM) is a widely adopted
scheduling algorithm in cascaded bridge converters, modular multilevel
converters, and reconfigurable batteries. However, non-uniformed pulse widths
for the modules with fixed phase shift angles lead to significant ripple
current and output-voltage distortion. Voltage uniformity instead would require
optimization of the phase shifts of the individual carriers. However, the
computational burden for such optimization is beyond the capabilities of any
simple embedded controller. This paper proposes a neural network that emulates
the behavior of an instantaneous optimizer with significantly reduced
computational burden. The proposed method has the advantages of stable
performance in predicting the optimum phase-shift angles under balanced battery
modules with non-identical modulation indices without requiring extensive
lookup tables, slow numerical optimization, or complex controller tuning. With
only one (re)training session for any specified number of modules, the proposed
method is readily adaptable to different system sizes. Furthermore, the
proposed framework also includes a simple scaling strategy that allows a neural
network trained for fewer modules to be reused for larger systems by grouping
modules and adjusting their phase shifts. The scaling strategy eliminates the
need for retraining. Large-scale assessment, simulations, and experiments
demonstrate that, on average, the proposed approach can reduce the current
ripple and the weighted total harmonic distortion by up to 50 % in real time
and is 100 to 500 thousand times faster than a conventional optimizer (e.g.,
genetic algorithms), making it the only solution for an online application.

</details>


### [93] [Synchronous Observer Design for Landmark-Inertial SLAM with Almost-Global Convergence](https://arxiv.org/abs/2511.04531)
*Arkadeep Saha,Pieter van Goor,Antonio Franchi,Ravi Banavar*

Main category: eess.SY

TL;DR: 提出了一种用于地标惯性SLAM的非线性观测器，在连续时间框架下分析，证明了误差动力学在基空间中的局部指数稳定性和几乎全局渐近稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决地标惯性同时定位与建图问题，通过地标位置测量和IMU测量来估计地标位置和机器人相对于这些地标的姿态。

Method: 设计了一个在连续时间中表述的非线性观测器，并在编码所有可观测状态的基空间中分析该观测器。

Result: 在证明部分建立了误差动力学在基空间中的局部指数稳定性和几乎全局渐近稳定性，并通过仿真验证了这些性质。

Conclusion: 所提出的非线性观测器能够有效解决LI-SLAM问题，具有理论保证的稳定性性能。

Abstract: Landmark Inertial Simultaneous Localisation and Mapping (LI-SLAM) is the
problem of estimating the locations of landmarks in the environment and the
robot's pose relative to those landmarks using landmark position measurements
and measurements from Inertial Measurement Unit (IMU). This paper proposes a
nonlinear observer for LI-SLAM posed in continuous time and analyses the
observer in a base space that encodes all the observable states of LI-SLAM. The
local exponential stability and almost-global asymptotic stability of the error
dynamics in base space is established in the proof section and validated using
simulations.

</details>


### [94] [Funnel-Based Online Recovery Control for Nonlinear Systems With Unknown Dynamics](https://arxiv.org/abs/2511.04626)
*Zihao Song,Shirantha Welikala,Panos J. Antsaklis,Hai Lin*

Main category: eess.SY

TL;DR: 提出一种基于循环均衡网络和漏斗控制的方法，用于非线性系统在遭受攻击或故障后的恢复控制，通过数据学习未知动态并保证状态轨迹的稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决非线性系统在攻击或故障后的恢复控制问题，主要挑战包括学习未知动态并提供形式化保证，以及找到确保状态偏离允许范围的稳定集。

Method: 使用循环均衡网络从实时系统状态数据中学习未知动态，通过增量积分二次约束保证模型特性；提出基于漏斗的控制方法实现系统恢复，推导名义轨迹稳定的充分条件和沿轨迹的不变漏斗。

Result: 在直流微电网控制应用的仿真示例中验证了所提控制方法的有效性。

Conclusion: 该方法能够有效处理非线性系统在攻击或故障后的恢复控制问题，通过形式化保证确保系统状态的稳定恢复。

Abstract: In this paper, we focus on recovery control of nonlinear systems from attacks
or failures. The main challenges of this problem lie in (1) learning the
unknown dynamics caused by attacks or failures with formal guarantees, and (2)
finding the invariant set of states to formally ensure the state deviations
allowed from the nominal trajectory. To solve this problem, we propose to apply
the Recurrent Equilibrium Networks (RENs) to learn the unknown dynamics using
the data from the real-time system states. The input-output property of this
REN model is guaranteed by incremental integral quadratic constraints (IQCs).
Then, we propose a funnel-based control method to achieve system recovery from
the deviated states. In particular, a sufficient condition for nominal
trajectory stabilization is derived together with the invariant funnels along
the nominal trajectory. Eventually, the effectiveness of our proposed control
method is illustrated by a simulation example of a DC microgrid control
application.

</details>


### [95] [Control Affine Hybrid Power Plant Subsystem Modeling for Supervisory Control Design](https://arxiv.org/abs/2511.04644)
*Stephen Ampleman,Himanshu Sharma,Sayak Mukherjee,Sonja Glavaski*

Main category: eess.SY

TL;DR: 本文提出了一个混合发电厂（HPP）的建模与控制框架，结合风电场、太阳能电站和电池储能，通过非线性控制和控制屏障函数技术实现安全稳定的运行。


<details>
  <summary>Details</summary>
Motivation: 混合发电厂结合多种发电机组和储能能力来支持发电不足和电网需求，需要统一的建模和控制框架来协调不同组件。

Method: 将风电场、太阳能电站和电池模型适配为控制仿射形式，开发发电机扭矩和电池电流控制律，使用非线性控制和控制屏障函数技术跟踪上级控制指令。

Result: 通过测试案例验证了该框架的实用性，包括跟踪电网需求信号、处理时变风力和辐照度数据，以及基于规则的上级控制。

Conclusion: 所提出的建模与控制框架能够有效协调混合发电厂中各组件，确保安全稳定运行并满足电网需求。

Abstract: Hybrid power plants (HPPs) combine multiple power generators
(conventional/variable) and energy storage capabilities to support generation
inadequacy and grid demands. This paper introduces a modeling and control
design framework for hybrid power plants (HPPs) consisting of a wind farm,
solar plant, and battery storage. Specifically, this work adapts established
modeling paradigms for wind farms, solar plants and battery models into a
control affine form suitable for control design at the supervisory level. In
the case of wind and battery models, generator torque and cell current control
laws are developed using nonlinear control and control barrier function
techniques to track a command from a supervisory control law while maintaining
safe and stable operation. The utility of this modeling and control framework
is illustrated through a test case using a utility demand signal for tracking,
time varying wind and irradiance data, and a rule-based supervisory control
law.

</details>
