<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 25]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.CY](#cs.CY) [Total: 10]
- [cs.ET](#cs.ET) [Total: 1]
- [stat.AP](#stat.AP) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem](https://arxiv.org/abs/2512.05946)
*Truong Thanh Hung Nguyen,Truong Thinh Nguyen,Hung Cao*

Main category: cs.AI

TL;DR: VQR-DQN将变分量子电路与Rainbow DQN结合，用于人力资源分配问题，相比经典方法获得4.9-13.4%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 资源分配问题是NP难问题，传统深度强化学习方法受限于经典函数逼近器的表示能力，需要更强大的表示方法来处理组合复杂性。

Method: 提出VQR-DQN方法，将环形拓扑变分量子电路集成到Rainbow DQN中，利用量子叠加和纠缠特性。将人力资源分配问题建模为基于官员能力、事件安排和转移时间的MDP。

Result: 在四个人力资源分配基准测试中，VQR-DQN相比随机基线减少26.8%的归一化完工时间，相比Double DQN和经典Rainbow DQN提升4.9-13.4%。

Conclusion: 量子增强的深度强化学习在大规模资源分配中具有潜力，电路表达能力、纠缠与策略质量之间存在理论联系。

Abstract: Resource allocation remains NP-hard due to combinatorial complexity. While deep reinforcement learning (DRL) methods, such as the Rainbow Deep Q-Network (DQN), improve scalability through prioritized replay and distributional heads, classical function approximators limit their representational power. We introduce Variational Quantum Rainbow DQN (VQR-DQN), which integrates ring-topology variational quantum circuits with Rainbow DQN to leverage quantum superposition and entanglement. We frame the human resource allocation problem (HRAP) as a Markov decision process (MDP) with combinatorial action spaces based on officer capabilities, event schedules, and transition times. On four HRAP benchmarks, VQR-DQN achieves 26.8% normalized makespan reduction versus random baselines and outperforms Double DQN and classical Rainbow DQN by 4.9-13.4%. These gains align with theoretical connections between circuit expressibility, entanglement, and policy quality, demonstrating the potential of quantum-enhanced DRL for large-scale resource allocation. Our implementation is available at: https://github.com/Analytics-Everywhere-Lab/qtrl/.

</details>


### [2] [Documenting SME Processes with Conversational AI: From Tacit Knowledge to BPMN](https://arxiv.org/abs/2512.05122)
*Unnikrishnan Radhakrishnan*

Main category: cs.AI

TL;DR: 使用LLM驱动的对话助手，通过访谈式对话捕获中小企业隐性知识，自动生成BPMN 2.0流程图，降低流程文档化的技能和成本门槛。


<details>
  <summary>Details</summary>
Motivation: 中小企业依赖隐性经验知识，但很少形成正式文档。需要一种低成本、低技能门槛的方法来捕获这些知识并转化为标准流程文档，以保存机构知识、增强运营透明度。

Method: 基于Gemini 2.5 Pro LLM构建对话助手，通过Gradio前端和bpmn-js可视化界面进行访谈式对话，逐步引导用户描述流程，实时生成并精炼BPMN 2.0图表。

Result: 在设备维护场景的验证中，聊天机器人在约12分钟内生成了准确的"现状"模型，通过图表标注标记问题，并生成了改进的"未来"变体，API成本控制在中小企业友好预算内。

Conclusion: 对话式LLM能够有效降低严格流程文档化的技能和成本障碍，帮助中小企业保存机构知识、增强运营透明度，并加速持续改进工作，具有实际应用潜力。

Abstract: Small and medium-sized enterprises (SMEs) still depend heavily on tacit, experience-based know-how that rarely makes its way into formal documentation. This paper introduces a large-language-model (LLM)-driven conversational assistant that captures such knowledge on the shop floor and converts it incrementally and interactively into standards-compliant Business Process Model and Notation (BPMN) 2.0 diagrams. Powered by Gemini 2.5 Pro and delivered through a lightweight Gradio front-end with client-side bpmn-js visualisation, the assistant conducts an interview-style dialogue: it elicits process details, supports clarifying dialogue and on-demand analysis, and renders live diagrams that users can refine in real time. A proof-of-concept evaluation in an equipment-maintenance scenario shows that the chatbot produced an accurate "AS-IS" model, flagged issues via on-diagram annotations, and generated an improved "TO-BE" variant, all within about 12-minutes, while keeping API costs within an SME-friendly budget. The study analyses latency sources, model-selection trade-offs, and the challenges of enforcing strict XML schemas, then outlines a roadmap toward agentic and multimodal deployments. The results demonstrate that conversational LLMs can potentially be used to lower the skill and cost barriers to rigorous process documentation, helping SMEs preserve institutional knowledge, enhance operational transparency, and accelerate continuous-improvement efforts.

</details>


### [3] [Semantic Faithfulness and Entropy Production Measures to Tame Your LLM Demons and Manage Hallucinations](https://arxiv.org/abs/2512.05156)
*Igor Halperin*

Main category: cs.AI

TL;DR: 该论文提出了两种基于信息论和热力学的无监督指标来评估LLM的忠实度：语义忠实度(SF)和语义熵产生(SEP)，通过将LLM建模为二分信息引擎来量化模型输出与任务要求的匹配程度。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型对给定任务的忠实度是一个复杂挑战，现有方法存在局限性。需要开发无监督的量化指标来准确衡量LLM输出是否忠实于输入上下文和任务要求。

Method: 将LLM建模为二分信息引擎，隐藏层作为麦克斯韦妖控制上下文到答案的转换。将QCA三元组建模为共享主题的概率分布，使用转移矩阵Q和A分别编码查询目标和实际结果。通过凸优化最小化这两个矩阵的KL散度得到SF指标，并基于热力学原理提出SEP指标。

Result: 提出的SF和SEP指标能够有效评估LLM的忠实度，高忠实度通常对应低熵产生。在SEC 10-K文件摘要任务上的演示验证了框架的有效性，两个指标可单独或联合用于LLM评估和幻觉控制。

Conclusion: 基于信息论和热力学的无监督指标为LLM忠实度评估提供了新方法，SF和SEP指标能够量化模型输出与任务要求的匹配程度，有助于LLM评估和幻觉控制。

Abstract: Evaluating faithfulness of Large Language Models (LLMs) to a given task is a complex challenge. We propose two new unsupervised metrics for faithfulness evaluation using insights from information theory and thermodynamics. Our approach treats an LLM as a bipartite information engine where hidden layers act as a Maxwell demon controlling transformations of context $C $ into answer $A$ via prompt $Q$. We model Question-Context-Answer (QCA) triplets as probability distributions over shared topics. Topic transformations from $C$ to $Q$ and $A$ are modeled as transition matrices ${\bf Q}$ and ${\bf A}$ encoding the query goal and actual result, respectively. Our semantic faithfulness (SF) metric quantifies faithfulness for any given QCA triplet by the Kullback-Leibler (KL) divergence between these matrices. Both matrices are inferred simultaneously via convex optimization of this KL divergence, and the final SF metric is obtained by mapping the minimal divergence onto the unit interval [0,1], where higher scores indicate greater faithfulness. Furthermore, we propose a thermodynamics-based semantic entropy production (SEP) metric in answer generation, and show that high faithfulness generally implies low entropy production. The SF and SEP metrics can be used jointly or separately for LLM evaluation and hallucination control. We demonstrate our framework on LLM summarization of corporate SEC 10-K filings.

</details>


### [4] [Bridging Traditional Machine Learning and Large Language Models: A Two-Part Course Design for Modern AI Education](https://arxiv.org/abs/2512.05167)
*Fang Li*

Main category: cs.AI

TL;DR: 提出一种创新的AI与数据科学教学方法，系统性地将传统机器学习技术与现代大语言模型相结合，通过两部分课程设计帮助学生全面理解AI发展并掌握实用技能。


<details>
  <summary>Details</summary>
Motivation: 为了帮助学生全面理解人工智能的发展历程，同时掌握传统机器学习技术和现代大语言模型的应用，更好地满足快速发展的AI行业需求。

Method: 设计分为两个顺序互补部分的课程：基础机器学习概念和当代LLM应用，详细描述课程架构、实施策略、评估方法，并在夏季课程中进行了为期两个七周学期的教学实践。

Result: 这种综合教学方法增强了学生对AI领域的理解，更好地为他们应对快速发展的AI行业需求做好了准备。

Conclusion: 该集成教学方法有效提升了学生对AI发展全景的理解，并增强了他们在快速变化的人工智能领域中的实践能力和行业适应性。

Abstract: This paper presents an innovative pedagogical approach for teaching artificial intelligence and data science that systematically bridges traditional machine learning techniques with modern Large Language Models (LLMs). We describe a course structured in two sequential and complementary parts: foundational machine learning concepts and contemporary LLM applications. This design enables students to develop a comprehensive understanding of AI evolution while building practical skills with both established and cutting-edge technologies. We detail the course architecture, implementation strategies, assessment methods, and learning outcomes from our summer course delivery spanning two seven-week terms. Our findings demonstrate that this integrated approach enhances student comprehension of the AI landscape and better prepares them for industry demands in the rapidly evolving field of artificial intelligence.

</details>


### [5] [On the Computability of Artificial General Intelligence](https://arxiv.org/abs/2512.05212)
*Georgios Mappouras,Charalambos Rossides*

Main category: cs.AI

TL;DR: 该论文证明任何算法（包括AI模型）都无法产生超出其初始算法本身已有功能的新功能能力，因此无法实现真正的创造力，从而为AGI设定了理论上限。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的快速发展，人们开始探讨人类距离开发出达到人类智能水平的人工通用智能（AGI）还有多远。本文旨在从计算理论的角度探讨这个问题，为机器可计算过程设定上限。

Method: 采用先前研究中关于AGI的定义（即在某个研究领域中能够创造和创新，从而解锁该领域中新的、先前未知的功能能力）。基于此定义，作者通过形式化证明来界定计算的极限。

Result: 形式化证明表明：任何算法都无法展示出超出初始算法本身已有功能的新功能能力。因此，没有算法（包括AI模型）能够在任何研究领域（科学、工程、艺术、体育等）实现真正的创造力。AI只能展示现有功能能力及其组合和排列。

Conclusion: 该证明对AI发展的未来和人类智能的起源都有重要启示：AGI在理论上存在根本性限制，这促使我们重新思考人类智能的本质和起源。

Abstract: In recent years we observed rapid and significant advancements in artificial intelligence (A.I.). So much so that many wonder how close humanity is to developing an A.I. model that can achieve human level of intelligence, also known as artificial general intelligence (A.G.I.). In this work we look at this question and we attempt to define the upper bounds, not just of A.I., but rather of any machine-computable process (a.k.a. an algorithm). To answer this question however, one must first precisely define A.G.I. We borrow prior work's definition of A.G.I. [1] that best describes the sentiment of the term, as used by the leading developers of A.I. That is, the ability to be creative and innovate in some field of study in a way that unlocks new and previously unknown functional capabilities in that field. Based on this definition we draw new bounds on the limits of computation. We formally prove that no algorithm can demonstrate new functional capabilities that were not already present in the initial algorithm itself. Therefore, no algorithm (and thus no A.I. model) can be truly creative in any field of study, whether that is science, engineering, art, sports, etc. In contrast, A.I. models can demonstrate existing functional capabilities, as well as combinations and permutations of existing functional capabilities. We conclude this work by discussing the implications of this proof both as it regards to the future of A.I. development, as well as to what it means for the origins of human intelligence.

</details>


### [6] [Resolving Zadehs Paradox Axiomatic Possibility Theory as a Foundation for Reliable Artificial Intelligence](https://arxiv.org/abs/2512.05257)
*Bychkov Oleksii,Bychkova Sophia,Lytvynchuk Khrystyna*

Main category: cs.AI

TL;DR: 本文论证可能性理论是解决Dempster-Shafer理论悖论的根本方案，而非仅仅是替代方案，通过可能性与必要性测度的二元框架提供逻辑一致的不确定性处理基础。


<details>
  <summary>Details</summary>
Motivation: Dempster-Shafer理论(DST)存在悖论和逻辑陷阱，许多尝试修复Dempster规则的方法未能从根本上解决问题。作者认为需要从零开始建立逻辑一致且数学严谨的不确定性处理基础，而可能性理论提供了这样的基础。

Method: 采用Bychkov文章中发展的公理化方法，基于可能性与必要性测度的二元框架。通过比较分析概率、证据和可能性三种范式，并以经典医疗诊断困境为例，展示可能性理论如何处理矛盾数据。

Result: 可能性理论能够正确处理矛盾数据，避免DST的逻辑陷阱，使形式推理更接近自然智能的逻辑。它提供了解决DST悖论的根本性方案，而不仅仅是替代方案。

Conclusion: 可能性理论为解决Dempster-Shafer理论危机提供了根本性解决方案，其公理化方法建立了逻辑一致的不确定性处理基础，使形式推理更接近人类自然智能的逻辑。

Abstract: This work advances and substantiates the thesis that the resolution of this crisis lies in the domain of possibility theory, specifically in the axiomatic approach developed in Bychkovs article. Unlike numerous attempts to fix Dempster rule, this approach builds from scratch a logically consistent and mathematically rigorous foundation for working with uncertainty, using the dualistic apparatus of possibility and necessity measures. The aim of this work is to demonstrate that possibility theory is not merely an alternative, but provides a fundamental resolution to DST paradoxes. A comparative analysis of three paradigms will be conducted probabilistic, evidential, and possibilistic. Using a classic medical diagnostic dilemma as an example, it will be shown how possibility theory allows for correct processing of contradictory data, avoiding the logical traps of DST and bringing formal reasoning closer to the logic of natural intelligence.

</details>


### [7] [AI & Human Co-Improvement for Safer Co-Superintelligence](https://arxiv.org/abs/2512.05356)
*Jason Weston,Jakob Foerster*

Main category: cs.AI

TL;DR: 论文主张用"共同改进"替代"自我改进"作为AI发展目标，强调人类研究者与AI协作实现共同超级智能


<details>
  <summary>Details</summary>
Motivation: 当前AI领域的自我改进目标充满危险且难以实现，需要寻找更可行、更安全的发展路径。作者认为人类与AI的协作改进是更好的目标，既能加速AI研究，又能确保超级智能的安全性。

Method: 提出"共同改进"框架，专注于提升AI系统与人类研究者协作进行AI研究的能力，涵盖从构思到实验的全过程。强调将人类研究改进纳入循环，通过人机共生实现更安全的发展。

Result: 共同改进框架能够加速AI研究进程，同时通过人机协作确保超级智能的安全性，比单纯的AI自我改进更具可行性和安全性。

Conclusion: 将目标从AI自我改进转向人类与AI的共同改进，是实现超级智能更快速、更安全的途径。人机协作的研究模式能够带来共同超级智能，同时降低风险。

Abstract: Self-improvement is a goal currently exciting the field of AI, but is fraught with danger, and may take time to fully achieve. We advocate that a more achievable and better goal for humanity is to maximize co-improvement: collaboration between human researchers and AIs to achieve co-superintelligence. That is, specifically targeting improving AI systems' ability to work with human researchers to conduct AI research together, from ideation to experimentation, in order to both accelerate AI research and to generally endow both AIs and humans with safer superintelligence through their symbiosis. Focusing on including human research improvement in the loop will both get us there faster, and more safely.

</details>


### [8] [MCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare](https://arxiv.org/abs/2512.05365)
*Zag ElSayed,Craig Erickson,Ernest Pedapati*

Main category: cs.AI

TL;DR: MCP-AI是一种创新的医疗AI架构，结合模型上下文协议(MCP)与临床应用，支持长期状态管理、可解释决策和医生参与验证，相比传统CDSS和提示式LLMs有显著改进。


<details>
  <summary>Details</summary>
Motivation: 传统医疗AI系统在整合上下文推理、长期状态管理和人类可验证工作流程方面存在挑战，随着医疗系统日益复杂，迫切需要自主、上下文感知的临床推理框架。

Method: 基于模型上下文协议(MCP)构建MCP-AI架构，MCP文件捕获临床目标、患者上下文、推理状态和任务逻辑，形成可重用、可审计的记忆对象，支持实时工作流中生成式和描述式AI代理的编排。

Result: 通过两个用例验证：1)脆性X综合征伴抑郁症的诊断建模；2)2型糖尿病和高血压的远程协调。系统支持医生参与验证、简化临床流程，并保证AI责任在医疗提供者之间的安全转移。

Conclusion: MCP-AI为即将到来的临床环境提供了可扩展、可解释、可组合且安全导向的AI基础，连接HL7/FHIR接口并符合HIPAA和FDA SaMD等监管标准。

Abstract: Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state management, and human-verifiable workflows into a cohesive framework. This paper introduces a completely innovative architecture and concept: combining the Model Context Protocol (MCP) with a specific clinical application, known as MCP-AI. This integration allows intelligent agents to reason over extended periods, collaborate securely, and adhere to authentic clinical logic, representing a significant shift away from traditional Clinical Decision Support Systems (CDSS) and prompt-based Large Language Models (LLMs). As healthcare systems become more complex, the need for autonomous, context-aware clinical reasoning frameworks has become urgent. We present MCP-AI, a novel architecture for explainable medical decision-making built upon the Model Context Protocol (MCP) a modular, executable specification for orchestrating generative and descriptive AI agents in real-time workflows. Each MCP file captures clinical objectives, patient context, reasoning state, and task logic, forming a reusable and auditable memory object. Unlike conventional CDSS or stateless prompt-based AI systems, MCP-AI supports adaptive, longitudinal, and collaborative reasoning across care settings. MCP-AI is validated through two use cases: (1) diagnostic modeling of Fragile X Syndrome with comorbid depression, and (2) remote coordination for Type 2 Diabetes and hypertension. In either scenario, the protocol facilitates physician-in-the-loop validation, streamlines clinical processes, and guarantees secure transitions of AI responsibilities between healthcare providers. The system connects with HL7/FHIR interfaces and adheres to regulatory standards, such as HIPAA and FDA SaMD guidelines. MCP-AI provides a scalable basis for interpretable, composable, and safety-oriented AI within upcoming clinical environments.

</details>


### [9] [ChipMind: Retrieval-Augmented Reasoning for Long-Context Circuit Design Specifications](https://arxiv.org/abs/2512.05371)
*Changwen Xing,SamZaak Wong,Xinlai Wan,Yanfeng Lu,Mengli Zhang,Zebin Ma,Lei Qi,Zhengxiong Li,Nan Guan,Zhe Jiang,Xi Wang,Jun Yang*

Main category: cs.AI

TL;DR: ChipMind是一个基于知识图谱增强的推理框架，专门用于处理长篇幅集成电路规格文档，通过构建领域知识图谱和自适应检索机制，显著提升LLM在硬件设计中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在集成电路开发自动化方面潜力巨大，但受限于有限的上下文窗口。现有的上下文扩展方法难以对复杂、冗长的电路规格进行有效的语义建模和多跳推理，阻碍了LLM在实际工业部署中的应用。

Method: 1. 通过电路语义感知知识图谱构建方法(Circuit Semantic-Aware Knowledge Graph Construction)将电路规格转换为领域特定知识图谱ChipKG；2. 采用ChipKG增强推理机制，结合信息论自适应检索动态追踪逻辑依赖关系，以及意图感知语义过滤去除无关噪声，平衡检索的完整性和精确性。

Result: 在工业级规格推理基准测试中，ChipMind显著优于现有最先进基线方法，平均提升34.59%，最高提升达72.73%。

Conclusion: ChipMind框架填补了学术研究与LLM辅助硬件设计(LAD)实际工业部署之间的关键空白，为集成电路开发自动化提供了有效的解决方案。

Abstract: While Large Language Models (LLMs) demonstrate immense potential for automating integrated circuit (IC) development, their practical deployment is fundamentally limited by restricted context windows. Existing context-extension methods struggle to achieve effective semantic modeling and thorough multi-hop reasoning over extensive, intricate circuit specifications. To address this, we introduce ChipMind, a novel knowledge graph-augmented reasoning framework specifically designed for lengthy IC specifications. ChipMind first transforms circuit specifications into a domain-specific knowledge graph ChipKG through the Circuit Semantic-Aware Knowledge Graph Construction methodology. It then leverages the ChipKG-Augmented Reasoning mechanism, combining information-theoretic adaptive retrieval to dynamically trace logical dependencies with intent-aware semantic filtering to prune irrelevant noise, effectively balancing retrieval completeness and precision. Evaluated on an industrial-scale specification reasoning benchmark, ChipMind significantly outperforms state-of-the-art baselines, achieving an average improvement of 34.59% (up to 72.73%). Our framework bridges a critical gap between academic research and practical industrial deployment of LLM-aided Hardware Design (LAD).

</details>


### [10] [BEAVER: An Efficient Deterministic LLM Verifier](https://arxiv.org/abs/2512.05439)
*Tarun Suresh,Nalin Wadhwa,Debangshu Banerjee,Gagandeep Singh*

Main category: cs.AI

TL;DR: BEAVER是首个为LLM约束满足提供确定性、可靠概率边界的实用框架，相比基线方法能获得6-8倍更紧的概率边界，识别出3-4倍更多高风险实例。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型从研究原型转向生产系统，从业者需要可靠方法来验证模型输出是否满足所需约束。基于采样的估计方法只能提供模型行为的直觉，无法提供可靠的保证。

Method: BEAVER框架使用新颖的token trie和frontier数据结构，系统性地探索生成空间，为任何前缀封闭的语义约束维护可证明可靠的概率边界。框架形式化了验证问题，并证明了方法的可靠性。

Result: 在正确性验证、隐私验证和安全代码生成任务上，BEAVER在相同计算预算下，相比基线方法实现了6-8倍更紧的概率边界，识别出3-4倍更多高风险实例。

Conclusion: BEAVER能够提供松散边界或经验评估无法实现的精确特征描述和风险评估，为LLM约束满足提供了首个实用的确定性验证框架。

Abstract: As large language models (LLMs) transition from research prototypes to production systems, practitioners often need reliable methods to verify that model outputs satisfy required constraints. While sampling-based estimates provide an intuition of model behavior, they offer no sound guarantees. We present BEAVER, the first practical framework for computing deterministic, sound probability bounds on LLM constraint satisfaction. Given any prefix-closed semantic constraint, BEAVER systematically explores the generation space using novel token trie and frontier data structures, maintaining provably sound bounds at every iteration. We formalize the verification problem, prove soundness of our approach, and evaluate BEAVER on correctness verification, privacy verification and secure code generation tasks across multiple state of the art LLMs. BEAVER achieves 6 to 8 times tighter probability bounds and identifies 3 to 4 times more high risk instances compared to baseline methods under identical computational budgets, enabling precise characterization and risk assessment that loose bounds or empirical evaluation cannot provide.

</details>


### [11] [The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems](https://arxiv.org/abs/2512.05449)
*Robert Yang*

Main category: cs.AI

TL;DR: 该论文提出将"意志薄弱"(akrasia)作为分析AI代理系统不一致性的核心概念，并开发了Akrasia基准测试来量化模型在不同诱惑条件下的"自我控制"能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型表现出一种特殊的不一致性：它们"知道"正确答案但无法据此行动。这种全局判断与局部冲动之间的张力在人类哲学中被称为"意志薄弱"。作者认为这一概念可用于分析AI代理系统中的不一致性和目标漂移问题。

Method: 提出了Akrasia基准测试的初步版本，包含四种结构化提示条件：基线(B)、同义词(S)、时间(T)和诱惑(X)，用于测量模型局部响应与其先前承诺之间的矛盾程度。

Result: 该基准能够量化比较不同模型家族、解码策略和诱惑类型下的"自我控制"能力。同时指出微观层面的意志薄弱可能在多智能体系统中累积为宏观层面的不稳定性，可能被解释为"阴谋"或故意不对齐。

Conclusion: 通过将不一致性重新定义为意志薄弱，这项工作将代理行为与经典的代理理论联系起来，为哲学、心理学和新兴的AI代理科学之间建立了实证桥梁。

Abstract: Large language models display a peculiar form of inconsistency: they "know" the correct answer but fail to act on it. In human philosophy, this tension between global judgment and local impulse is called akrasia, or weakness of will. We propose akrasia as a foundational concept for analyzing inconsistency and goal drift in agentic AI systems. To operationalize it, we introduce a preliminary version of the Akrasia Benchmark, currently a structured set of prompting conditions (Baseline [B], Synonym [S], Temporal [T], and Temptation [X]) that measures when a model's local response contradicts its own prior commitments. The benchmark enables quantitative comparison of "self-control" across model families, decoding strategies, and temptation types. Beyond single-model evaluation, we outline how micro-level akrasia may compound into macro-level instability in multi-agent systems that may be interpreted as "scheming" or deliberate misalignment. By reframing inconsistency as weakness of will, this work connects agentic behavior to classical theories of agency and provides an empirical bridge between philosophy, psychology, and the emerging science of agentic AI.

</details>


### [12] [MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models](https://arxiv.org/abs/2512.05530)
*Chuang Yu,Jinmiao Zhao,Mingxuan Zhao,Yunpeng Liu,Xiujun Shu,Yuanhao Feng,Bo Wang,Xiangyu Yue*

Main category: cs.AI

TL;DR: 提出MIND推理框架，通过"理解-反思-修正"的类人认知能力，将MLLMs从被动模仿推理转变为主动判别推理，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在推理任务中存在多理由语义建模有限、逻辑鲁棒性不足、容易受到复杂场景误导等问题，需要提升其认知智能水平。

Method: 提出MIND推理框架，包含：1) RAD范式自动生成多样化理由扩展数据集；2) P2CL策略分两阶段增强多理由正向学习和主动逻辑判别修正；3) MCA优化策略解决多理由语义空间表示纠缠问题。

Result: 在涵盖科学、常识和数学场景的多个公共数据集上实现了最先进的性能，为推进MLLMs向更高层次认知智能提供了新视角。

Conclusion: MIND框架通过赋予MLLMs类人认知能力，实现了从被动模仿推理到主动判别推理的范式演进，显著提升了多模态推理性能。

Abstract: Recently, multimodal large language models (MLLMs) have been widely applied to reasoning tasks. However, they suffer from limited multi-rationale semantic modeling, insufficient logical robustness, and are susceptible to misleading interpretations in complex scenarios. Therefore, we propose a Multi-rationale INtegrated Discriminative (MIND) reasoning framework, which is designed to endow MLLMs with human-like cognitive abilities of "Understand -> Rethink -> Correct", and achieves a paradigm evolution from passive imitation-based reasoning to active discriminative reasoning. Specifically, we introduce a Rationale Augmentation and Discrimination (RAD) paradigm, which automatically and efficiently expands existing datasets by generating diverse rationales, providing a unified and extensible data foundation. Meanwhile, we design a Progressive Two-stage Correction Learning (P2CL) strategy. The first phase enhances multi-rationale positive learning, while the second phase enables active logic discrimination and correction. In addition, to mitigate representation entanglement in the multi-rationale semantic space, we propose a Multi-rationale Contrastive Alignment (MCA) optimization strategy, which achieves semantic aggregation of correct reasoning and boundary separation of incorrect reasoning. Extensive experiments demonstrate that the proposed MIND reasoning framework achieves state-of-the-art (SOTA) performance on multiple public datasets covering scientific, commonsense, and mathematical scenarios. It provides a new perspective for advancing MLLMs towards higher levels of cognitive intelligence. Our code is available at https://github.com/YuChuang1205/MIND

</details>


### [13] [CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning](https://arxiv.org/abs/2512.05576)
*Ting-Ting Xie,Yixin Zhang*

Main category: cs.AI

TL;DR: 提出Executor-Analyst框架，通过解耦工具执行和临床推理，解决小LLM临床代理的上下文利用失败问题，无需昂贵微调即实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于小LLM的临床代理（如TxAgent）存在"上下文利用失败"问题：模型能成功检索生物医学证据，但无法基于这些信息进行诊断推理。

Method: 提出Executor-Analyst框架，将专用TxAgents（执行器）与长上下文基础模型（分析师）协调工作。采用分层集成策略保持证据多样性，解决信息瓶颈。

Result: 在CURE-Bench上实现最先进性能，无需端到端微调。发现上下文长度超过12k token会引入噪声降低准确性，工具集扩展需要分层检索策略。

Conclusion: 通过免训练架构工程提供可扩展、敏捷的下一代可信AI驱动治疗基础，代码已开源。

Abstract: Current clinical agent built on small LLMs, such as TxAgent suffer from a \textit{Context Utilization Failure}, where models successfully retrieve biomedical evidence due to supervised finetuning but fail to ground their diagnosis in that information. In this work, we propose the Executor-Analyst Framework, a modular architecture that decouples the syntactic precision of tool execution from the semantic robustness of clinical reasoning. By orchestrating specialized TxAgents (Executors) with long-context foundation models (Analysts), we mitigate the reasoning deficits observed in monolithic models. Beyond simple modularity, we demonstrate that a Stratified Ensemble strategy significantly outperforms global pooling by preserving evidentiary diversity, effectively addressing the information bottleneck. Furthermore, our stress tests reveal critical scaling insights: (1) a \textit{Context-Performance Paradox}, where extending reasoning contexts beyond 12k tokens introduces noise that degrades accuracy; and (2) the \textit{Curse of Dimensionality} in action spaces, where expanding toolsets necessitates hierarchical retrieval strategies. Crucially, our approach underscores the potential of training-free architectural engineering, achieving state-of-the-art performance on CURE-Bench without the need for expensive end-to-end finetuning. This provides a scalable, agile foundation for the next generation of trustworthy AI-driven therapeutics. Code has been released on https://github.com/June01/CureAgent.

</details>


### [14] [Ontology Learning with LLMs: A Benchmark Study on Axiom Identification](https://arxiv.org/abs/2512.05594)
*Roos M. Bakker,Daan L. Di Scala,Maaike H. T. de Boer,Stephan A. Raaijmakers*

Main category: cs.AI

TL;DR: 本文介绍了OntoAxiom基准测试，用于评估大语言模型在识别本体论公理方面的性能，发现Axiom-by-Axiom提示策略优于直接方法，但性能因公理类型和领域而异。


<details>
  <summary>Details</summary>
Motivation: 本体论开发需要大量建模和领域专业知识，自动化这一过程的本体学习在过去十年中随着自然语言处理技术和大语言模型的发展而进步。本文旨在解决识别公理（定义类和属性之间逻辑关系的基本本体组件）的挑战。

Method: 引入OntoAxiom基准测试，包含9个中等规模本体（共17,118个三元组和2,771个公理），专注于子类、不相交、子属性、域和范围公理。评估12个LLM在三种few-shot设置和两种提示策略下的性能：直接方法（一次查询所有公理）与Axiom-by-Axiom方法（每个提示只查询一个公理）。

Result: Axiom-by-Axiom提示策略比直接方法获得更高的F1分数，但性能因公理类型和领域而异。例如，FOAF本体在子类公理上得分为0.642，而音乐本体仅为0.218。较大的LLM表现优于较小的模型，但较小模型在资源受限环境下仍可能适用。总体性能不足以完全自动化公理识别。

Conclusion: 虽然LLM性能不足以完全自动化公理识别，但它们可以提供有价值的候选公理来支持本体工程师开发和优化本体。Axiom-by-Axiom提示策略更有效，但性能差异表明某些公理类型和领域更具挑战性。

Abstract: Ontologies are an important tool for structuring domain knowledge, but their development is a complex task that requires significant modelling and domain expertise. Ontology learning, aimed at automating this process, has seen advancements in the past decade with the improvement of Natural Language Processing techniques, and especially with the recent growth of Large Language Models (LLMs). This paper investigates the challenge of identifying axioms: fundamental ontology components that define logical relations between classes and properties. In this work, we introduce an Ontology Axiom Benchmark OntoAxiom, and systematically test LLMs on that benchmark for axiom identification, evaluating different prompting strategies, ontologies, and axiom types. The benchmark consists of nine medium-sized ontologies with together 17.118 triples, and 2.771 axioms. We focus on subclass, disjoint, subproperty, domain, and range axioms. To evaluate LLM performance, we compare twelve LLMs with three shot settings and two prompting strategies: a Direct approach where we query all axioms at once, versus an Axiom-by-Axiom (AbA) approach, where each prompt queries for one axiom only. Our findings show that the AbA prompting leads to higher F1 scores than the direct approach. However, performance varies across axioms, suggesting that certain axioms are more challenging to identify. The domain also influences performance: the FOAF ontology achieves a score of 0.642 for the subclass axiom, while the music ontology reaches only 0.218. Larger LLMs outperform smaller ones, but smaller models may still be viable for resource-constrained settings. Although performance overall is not high enough to fully automate axiom identification, LLMs can provide valuable candidate axioms to support ontology engineers with the development and refinement of ontologies.

</details>


### [15] [Enhancing Local Search for MaxSAT with Deep Differentiation Clause Weighting](https://arxiv.org/abs/2512.05619)
*Menghua Jiang,Haokai Gao,Shuhao Chen,Yin Chen*

Main category: cs.AI

TL;DR: 提出DeepDist SLS求解器，针对PMS和WPMS问题设计新的子句权重方案和初始化方法，性能优于现有最佳SLS求解器，与TT-Open-WBO-Inc混合后超越MaxSAT Evaluation 2024冠军。


<details>
  <summary>Details</summary>
Motivation: 现有(W)PMS的随机局部搜索算法主要关注子句权重方案设计，但未能充分区分PMS和WPMS问题，通常采用统一的权重更新策略，忽视了这两类问题的关键结构差异。

Method: 1) 首次提出根据PMS和WPMS实例的不同条件更新子句权重的权重方案；2) 新的初始化方法更好地适应两类实例特性；3) 提出优先满足单元子句和硬子句的decimation方法；4) 基于这些方法开发DeepDist SLS求解器。

Result: 在近期MaxSAT Evaluation的基准测试中，DeepDist优于最先进的SLS求解器。与TT-Open-WBO-Inc混合的求解器超越了MaxSAT Evaluation 2024冠军SPB-MaxSAT-c-Band和SPB-MaxSAT-c-FPS。

Conclusion: 提出的针对PMS和WPMS的差异化权重方案和初始化方法有效提升了求解性能，DeepDist展示了在(W)PMS问题上的优越性，混合求解器达到了当前最佳水平。

Abstract: Partial Maximum Satisfiability (PMS) and Weighted Partial Maximum Satisfiability (WPMS) generalize Maximum Satisfiability (MaxSAT), with broad real-world applications. Recent advances in Stochastic Local Search (SLS) algorithms for solving (W)PMS have mainly focused on designing clause weighting schemes. However, existing methods often fail to adequately distinguish between PMS and WPMS, typically employing uniform update strategies for clause weights and overlooking critical structural differences between the two problem types. In this work, we present a novel clause weighting scheme that, for the first time, updates the clause weights of PMS and WPMS instances according to distinct conditions. This scheme also introduces a new initialization method, which better accommodates the unique characteristics of both instance types. Furthermore, we propose a decimation method that prioritizes satisfying unit and hard clauses, effectively complementing our proposed clause weighting scheme. Building on these methods, we develop a new SLS solver for (W)PMS named DeepDist. Experimental results on benchmarks from the anytime tracks of recent MaxSAT Evaluations show that DeepDist outperforms state-of-the-art SLS solvers. Notably, a hybrid solver combining DeepDist with TT-Open-WBO-Inc surpasses the performance of the MaxSAT Evaluation 2024 winners, SPB-MaxSAT-c-Band and SPB-MaxSAT-c-FPS, highlighting the effectiveness of our approach. The code is available at https://github.com/jmhmaxsat/DeepDist

</details>


### [16] [KANFormer for Predicting Fill Probabilities via Survival Analysis in Limit Order Books](https://arxiv.org/abs/2512.05734)
*Jinfeng Zhong,Emmanuel Bacry,Agathe Guilloux,Jean-François Muzy*

Main category: cs.AI

TL;DR: KANFormer是一种结合Dilated Causal CNN、Transformer编码器和Kolmogorov-Arnold Networks的深度学习模型，用于预测限价单的成交时间，通过整合市场级和代理级信息显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型主要依赖限价订单簿的快照序列，忽略了与LOB动态相关的代理行为以及订单在队列中的位置信息，这些信息对于准确预测成交可能性至关重要。

Method: 结合Dilated Causal Convolutional网络和Transformer编码器，使用Kolmogorov-Arnold Networks增强非线性逼近能力，整合市场级信息（LOB快照）和代理级信息（代理行为、订单队列位置）。

Result: 在CAC 40指数期货数据上评估，KANFormer在校准指标（右删失对数似然、综合Brier分数）和区分指标（C指数、时间依赖AUC）上均优于现有方法，并通过SHAP分析特征重要性随时间的变化。

Conclusion: 结合丰富的市场信号和表达能力强的神经架构能够实现准确且可解释的成交概率预测，KANFormer展示了这种整合方法的优势。

Abstract: This paper introduces KANFormer, a novel deep-learning-based model for predicting the time-to-fill of limit orders by leveraging both market- and agent-level information. KANFormer combines a Dilated Causal Convolutional network with a Transformer encoder, enhanced by Kolmogorov-Arnold Networks (KANs), which improve nonlinear approximation. Unlike existing models that rely solely on a series of snapshots of the limit order book, KANFormer integrates the actions of agents related to LOB dynamics and the position of the order in the queue to more effectively capture patterns related to execution likelihood. We evaluate the model using CAC 40 index futures data with labeled orders. The results show that KANFormer outperforms existing works in both calibration (Right-Censored Log-Likelihood, Integrated Brier Score) and discrimination (C-index, time-dependent AUC). We further analyze feature importance over time using SHAP (SHapley Additive exPlanations). Our results highlight the benefits of combining rich market signals with expressive neural architectures to achieve accurate and interpretabl predictions of fill probabilities.

</details>


### [17] [A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning](https://arxiv.org/abs/2512.05753)
*Wencheng Cai,Xuchao Gao,Congying Han,Mingqiang Li,Tiande Guo*

Main category: cs.AI

TL;DR: 提出FARDA框架，使用深度强化学习快速部署认知雷达对抗干扰，比进化算法快约7000倍


<details>
  <summary>Details</summary>
Motivation: 现代战争中快速部署认知雷达对抗干扰是关键挑战，现有基于进化算法的方法耗时且易陷入局部最优

Method: 将雷达部署问题建模为端到端任务，设计深度强化学习算法，开发集成神经模块感知热图信息和新奖励格式

Result: 方法达到与进化算法相当的覆盖效果，部署速度提升约7000倍，消融实验验证各组件必要性

Conclusion: FARDA框架通过深度强化学习实现了快速高效的雷达部署，显著优于传统进化算法

Abstract: The fast deployment of cognitive radar to counter jamming remains a critical challenge in modern warfare, where more efficient deployment leads to quicker detection of targets. Existing methods are primarily based on evolutionary algorithms, which are time-consuming and prone to falling into local optima. We tackle these drawbacks via the efficient inference of neural networks and propose a brand new framework: Fast Anti-Jamming Radar Deployment Algorithm (FARDA). We first model the radar deployment problem as an end-to-end task and design deep reinforcement learning algorithms to solve it, where we develop integrated neural modules to perceive heatmap information and a brand new reward format. Empirical results demonstrate that our method achieves coverage comparable to evolutionary algorithms while deploying radars approximately 7,000 times faster. Further ablation experiments confirm the necessity of each component of FARDA.

</details>


### [18] [Evolutionary System 2 Reasoning: An Empirical Proof](https://arxiv.org/abs/2512.05760)
*Zeyuan Ma,Wenqi Huang,Guo-Huan Song,Hongshu Guo,Sijie Ma,Zhiguang Cao,Yue-Jiao Gong*

Main category: cs.AI

TL;DR: 提出进化推理优化（ERO）框架，通过进化算法优化LLMs的推理能力，发现GPT-5等最新模型仍存在系统2推理限制，但通过简单进化循环可显著提升较弱模型（如Qwen-7B）的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在特定任务上表现出色，但在通用智能和系统2推理（慢思考）方面仍有不足。研究旨在探索机器智能（如LLMs）能否像人类一样进化获得推理能力，而不仅仅是特定技能。

Method: 提出进化推理优化（ERO）框架：1）初始化多个LLMs作为种群；2）采用进化策略优化种群，最大化最佳个体的量化推理分数；3）通过"适者生存"原则筛选具有强推理能力的LLM个体。

Result: 两个重要发现：1）最新LLMs（如GPT-5）仍表现出有限的系统2推理能力；2）通过ERO的简单进化循环，相对较弱的模型（Qwen-7B）可被增强，展现出强大的推理能力。

Conclusion: 进化优化方法能有效提升LLMs的推理能力，为机器智能获得类似人类的推理能力提供了可行路径。该框架开源，便于复现研究结果。

Abstract: Machine intelligence marks the ultimate dream of making machines' intelligence comparable to human beings. While recent progress in Large Language Models (LLMs) show substantial specific skills for a wide array of downstream tasks, they more or less fall shorts in general intelligence. Following correlation between intelligence and system 2 reasoning (slow thinking), in this paper, we aim to answering a worthwhile research question: could machine intelligence such as LLMs be evolved to acquire reasoning ability (not specific skill) just like our human beings? To this end, we propose evolutionary reasoning optimization (ERO) framework which performs survival of the fittest over a population of LLMs to search for individual with strong reasoning ability. Given a reasoning task, ERO first initializes multiple LLMs as a population, after which an evolutionary strategy evolves the population to maximize quantified reasoning score of the best individual. Based on experiments on representative testsuites, we claim two surprising empirical discoveries: i) the latest LLMs such as GPT-5 still show limited system 2 reasoning ability; ii) with simple evolution-loop of ERO, a relatively weak model (Qwen-7B) could be enhanced to emerge powerful reasoning ability. Our project can be accessed at https://github.com/MetaEvo/ERO for reproduction needs.

</details>


### [19] [The Missing Layer of AGI: From Pattern Alchemy to Coordination Physics](https://arxiv.org/abs/2512.05765)
*Edward Y. Chang*

Main category: cs.AI

TL;DR: 论文认为LLM不是AGI的死胡同，而是缺乏系统2的协调层。提出UCCT理论和MACI架构，将推理建模为语义锚定的相变过程。


<details>
  <summary>Details</summary>
Motivation: 针对"LLM只是模式匹配器，无法实现推理和规划"的批评，作者认为问题不在于LLM本身，而在于缺乏一个系统2的协调层来选择和约束模式。

Method: 提出UCCT理论，将推理建模为受有效支持度、表征失配和自适应锚定预算控制的相变过程。并设计MACI架构实现诱饵、过滤和持久化三个协调机制。

Result: 理论框架将无基础的生成解释为未锚定的最大似然先验检索，而"推理"则是在锚点将后验向目标导向约束转移时出现。

Conclusion: 通往AGI的道路是通过LLM而非绕过LLM，需要构建系统2协调层来补充LLM的模式匹配能力。

Abstract: Influential critiques argue that Large Language Models (LLMs) are a dead end for AGI: "mere pattern matchers" structurally incapable of reasoning or planning. We argue this conclusion misidentifies the bottleneck: it confuses the ocean with the net. Pattern repositories are the necessary System-1 substrate; the missing component is a System-2 coordination layer that selects, constrains, and binds these patterns. We formalize this layer via UCCT, a theory of semantic anchoring that models reasoning as a phase transition governed by effective support (rho_d), representational mismatch (d_r), and an adaptive anchoring budget (gamma log k). Under this lens, ungrounded generation is simply an unbaited retrieval of the substrate's maximum likelihood prior, while "reasoning" emerges when anchors shift the posterior toward goal-directed constraints. We translate UCCT into architecture with MACI, a coordination stack that implements baiting (behavior-modulated debate), filtering (Socratic judging), and persistence (transactional memory). By reframing common objections as testable coordination failures, we argue that the path to AGI runs through LLMs, not around them.

</details>


### [20] [Multimodal Oncology Agent for IDH1 Mutation Prediction in Low-Grade Glioma](https://arxiv.org/abs/2512.05824)
*Hafsa Akebli,Adam Shephard,Vincenzo Della Mea,Nasir Rajpoot*

Main category: cs.AI

TL;DR: 本文提出了一种多模态肿瘤智能体(MOA)，整合TITAN基础模型的病理学工具和临床基因组数据推理，用于低级别胶质瘤IDH1突变预测，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 低级别胶质瘤中的IDH1突变具有重要的临床意义，但现有预测方法存在局限性。需要开发能够整合多模态信息（包括病理学、临床和基因组数据）并利用外部生物医学知识的智能系统来提高预测准确性。

Method: 开发了多模态肿瘤智能体(MOA)，整合两个核心组件：1)基于TITAN基础模型的病理学工具用于IDH1突变预测；2)通过PubMed、Google Search和OncoKB对结构化临床和基因组输入进行推理。在TCGA-LGG队列的488名患者上进行评估。

Result: MOA无病理学工具时F1分数为0.826，优于临床基线(0.798)。结合病理学特征后，MOA达到最高性能，F1分数为0.912，超过病理学基线(0.894)和融合病理学-临床基线(0.897)。

Conclusion: MOA通过整合多模态信息和外部生物医学知识源，能够捕捉互补的突变相关信息，实现准确的IDH1突变预测，为低级别胶质瘤的精准医疗提供了有效工具。

Abstract: Low-grade gliomas frequently present IDH1 mutations that define clinically distinct subgroups with specific prognostic and therapeutic implications. This work introduces a Multimodal Oncology Agent (MOA) integrating a histology tool based on the TITAN foundation model for IDH1 mutation prediction in low-grade glioma, combined with reasoning over structured clinical and genomic inputs through PubMed, Google Search, and OncoKB. MOA reports were quantitatively evaluated on 488 patients from the TCGA-LGG cohort against clinical and histology baselines. MOA without the histology tool outperformed the clinical baseline, achieving an F1-score of 0.826 compared to 0.798. When fused with histology features, MOA reached the highest performance with an F1-score of 0.912, exceeding both the histology baseline at 0.894 and the fused histology-clinical baseline at 0.897. These results demonstrate that the proposed agent captures complementary mutation-relevant information enriched through external biomedical sources, enabling accurate IDH1 mutation prediction.

</details>


### [21] [Using Large Language Models to Create Personalized Networks From Therapy Sessions](https://arxiv.org/abs/2512.05836)
*Clarissa W. Ong,Hiba Arnaout,Kate Sheehan,Estella Fox,Eugen Owtscharow,Iryna Gurevych*

Main category: cs.AI

TL;DR: 利用LLMs从治疗记录自动生成客户心理网络，支持个案概念化和治疗规划，专家评估显示临床实用性和可解释性优于直接提示方法


<details>
  <summary>Details</summary>
Motivation: 个性化治疗需要基于个性化网络选择治疗模块，但传统方法需要密集纵向数据，难以规模化。LLMs为解决这一问题提供了可能，可以从治疗记录中自动生成临床相关的心理网络

Method: 1) 从77份治疗记录中标注3364个心理过程及其维度；2) 使用上下文学习联合识别心理过程和维度；3) 两步法将过程分组为临床有意义的簇；4) 生成解释增强的簇间关系

Result: 方法在少量训练示例下达到高性能；专家评估显示多步方法在临床实用性和可解释性上优于直接提示方法，90%专家偏好该方法；网络在临床相关性、新颖性和有用性上获得72-75%评分

Conclusion: 研究证明了使用LLMs从治疗记录创建临床相关网络的可行性，优势包括自下而上的个案概念化和潜在主题识别。未来研究应比较这些网络与其他个性化治疗方法对治疗结果的影响

Abstract: Recent advances in psychotherapy have focused on treatment personalization, such as by selecting treatment modules based on personalized networks. However, estimating personalized networks typically requires intensive longitudinal data, which is not always feasible. A solution to facilitate scalability of network-driven treatment personalization is leveraging LLMs. In this study, we present an end-to-end pipeline for automatically generating client networks from 77 therapy transcripts to support case conceptualization and treatment planning. We annotated 3364 psychological processes and their corresponding dimensions in therapy transcripts. Using these data, we applied in-context learning to jointly identify psychological processes and their dimensions. The method achieved high performance even with a few training examples. To organize the processes into networks, we introduced a two-step method that grouped them into clinically meaningful clusters. We then generated explanation-augmented relationships between clusters. Experts found that networks produced by our multi-step approach outperformed those built with direct prompting for clinical utility and interpretability, with up to 90% preferring our approach. In addition, the networks were rated favorably by experts, with scores for clinical relevance, novelty, and usefulness ranging from 72-75%. Our findings provide a proof of concept for using LLMs to create clinically relevant networks from therapy transcripts. Advantages of our approach include bottom-up case conceptualization from client utterances in therapy sessions and identification of latent themes. Networks generated from our pipeline may be used in clinical settings and supervision and training. Future research should examine whether these networks improve treatment outcomes relative to other methods of treatment personalization, including statistically estimated networks.

</details>


### [22] [To Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis](https://arxiv.org/abs/2512.05925)
*Federico Bianchi,Yongchan Kwon,Zachary Izzo,Linjun Zhang,James Zou*

Main category: cs.AI

TL;DR: 使用GPT-5开发的论文正确性检查器发现，顶级AI会议和期刊发表的论文中存在显著数量的客观错误，且错误数量随时间增加，AI检查器能有效识别并修正这些错误。


<details>
  <summary>Details</summary>
Motivation: 同行评审出版物是构建新研究和知识的基础，但文献中持续存在的错误会传播混淆，影响后续研究和可重复性。研究加速和同行评审系统压力使得错误更难被发现和避免。

Method: 开发基于GPT-5的论文正确性检查器，系统识别顶级AI会议和期刊已发表论文中的客观错误（如公式、推导、计算、图表错误），排除主观考量，并由人类专家验证AI识别结果。

Result: 发表论文包含显著数量的客观错误，且平均错误数随时间增加（如NeurIPS从2021年的3.8个增至2025年的5.9个）。AI检查器识别错误的精确度为83.2%，并能对75.8%的错误提出正确修正。

Conclusion: 前沿大语言模型在检测和修正已发表论文客观错误方面具有潜力，有助于建立更坚实的知识基础，减少文献混淆并增强可重复性。

Abstract: How many mistakes do published AI papers contain? Peer-reviewed publications form the foundation upon which new research and knowledge are built. Errors that persist in the literature can propagate unnoticed, creating confusion in follow-up studies and complicating reproducibility. The accelerating pace of research and the increasing demands on the peer-review system make such mistakes harder to detect and avoid. To address this, we developed a Paper Correctness Checker based on GPT-5 to systematically identify mistakes in papers previously published at top AI conferences and journals. Our analysis focuses on objective mistakes-e.g., errors in formulas, derivations, calculations, figures, and tables-that have a clearly verifiable ground truth. We intentionally exclude subjective considerations such as novelty, importance, or writing quality. We find that published papers contain a non-negligible number of objective mistakes and that the average number of mistakes per paper has increased over time-from 3.8 in NeurIPS 2021 to 5.9 in NeurIPS 2025 (55.3% increase); from 4.1 in ICLR 2018 to 5.2 in ICLR 2025; and from 5.0 in TMLR 2022/23 to 5.5 in TMLR 2025. Human experts reviewed 316 potential mistakes identified by the AI Checker and confirmed that 263 were actual mistakes, corresponding to a precision of 83.2%. While most identified issues are relatively minor, correcting them would reduce confusion in the literature and strengthen reproducibility. The AI Checker also surfaced potentially more substantive mistakes that could affect the interpretation of results. Moreover, we show that the AI Checker can propose correct fixes for 75.8% of the identified mistakes. Overall, this study highlights the potential of frontier LLMs to detect and correct objective mistakes in published papers, helping to establish a firmer foundation of knowledge.

</details>


### [23] [PRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation](https://arxiv.org/abs/2512.05930)
*Shima Imani,Seungwhan Moon,Adel Ahmadyan,Lu Zhang,Kirmani Ahmed,Babak Damavandi*

Main category: cs.AI

TL;DR: PRiSM是一个用于评估视觉语言模型在科学领域（物理和数学）推理能力的动态多模态基准测试，包含24,750个大学水平问题，通过Python代码生成和验证地面真值，支持五种评估任务。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在评估科学领域的视觉语言模型时存在不足：缺乏中间推理步骤、对变化的鲁棒性不足、无法验证科学正确性，且大多是静态的。科学领域需要概念理解、符号推理和遵循形式法则，这些要求现有基准测试未能满足。

Method: 提出PRiSM基准测试，包含24,750个大学水平的物理和数学问题。使用PrismAgent代理管道生成结构化问题实例，每个问题包含动态文本和视觉输入、生成的图形，以及丰富的结构化输出：用于地面真值生成和验证的可执行Python代码，以及详细的逐步推理步骤。

Result: PRiSM基准测试能够对多模态视觉语言模型进行细粒度实验审计，揭示失败模式、不确定性行为和科学推理的局限性。通过对现有视觉语言模型的综合评估，突显了它们的局限性，并展示了PRiSM如何深入洞察其科学推理能力。

Conclusion: PRiSM通过其动态特性和Python驱动的自动地面真值生成，为评估视觉语言模型在科学领域的推理能力提供了更全面、更深入的基准测试框架，支持五种针对性评估任务，能够揭示模型在科学推理方面的真实能力。

Abstract: Evaluating vision-language models (VLMs) in scientific domains like mathematics and physics poses unique challenges that go far beyond predicting final answers. These domains demand conceptual understanding, symbolic reasoning, and adherence to formal laws, requirements that most existing benchmarks fail to address. In particular, current datasets tend to be static, lacking intermediate reasoning steps, robustness to variations, or mechanisms for verifying scientific correctness. To address these limitations, we introduce PRiSM, a synthetic, fully dynamic, and multimodal benchmark for evaluating scientific reasoning via grounded Python code. PRiSM includes over 24,750 university-level physics and math problems, and it leverages our scalable agent-based pipeline, PrismAgent, to generate well-structured problem instances. Each problem contains dynamic textual and visual input, a generated figure, alongside rich structured outputs: executable Python code for ground truth generation and verification, and detailed step-by-step reasoning. The dynamic nature and Python-powered automated ground truth generation of our benchmark allow for fine-grained experimental auditing of multimodal VLMs, revealing failure modes, uncertainty behaviors, and limitations in scientific reasoning. To this end, we propose five targeted evaluation tasks covering generalization, symbolic program synthesis, perturbation robustness, reasoning correction, and ambiguity resolution. Through comprehensive evaluation of existing VLMs, we highlight their limitations and showcase how PRiSM enables deeper insights into their scientific reasoning capabilities.

</details>


### [24] [TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models](https://arxiv.org/abs/2512.05943)
*Shima Imani,Seungwhan Moon,Lambert Mathias,Lu Zhang,Babak Damavandi*

Main category: cs.AI

TL;DR: TRACE框架通过辅助推理集评估大视觉语言模型的推理轨迹而非最终答案，利用一致性指标诊断中间步骤错误，定义置信区间区分可靠与不可靠推理路径。


<details>
  <summary>Details</summary>
Motivation: 当前大视觉语言模型在数学和科学推理方面存在可靠性问题，标准最终答案评估往往掩盖推理错误，导致静默失败持续存在。

Method: 提出TRACE框架，核心是辅助推理集（ARS）——将复杂问题分解为子问题-答案对，通过基于一致性的指标评估中间步骤，暴露标准评估忽略的失败。

Result: 实验表明ARS间的一致性与最终答案正确性相关，能精确定位推理失败步骤，为模型改进提供可操作信号。TRACE定义的置信区间能区分可靠与不可靠推理路径。

Conclusion: TRACE框架通过透明推理和一致性评估，为诊断大视觉语言模型的推理错误、支持有效过滤、调试和模型改进提供了系统方法。

Abstract: Reliable mathematical and scientific reasoning remains an open challenge for large vision-language models. Standard final-answer evaluation often masks reasoning errors, allowing silent failures to persist. To address this gap, we introduce TRACE, a framework for Transparent Reasoning And Consistency Evaluation that diagnoses reasoning trajectories rather than only end results. At its core, TRACE leverages Auxiliary Reasoning Sets, compact sub question answer pairs that decompose complex problems, evaluate intermediate steps through consistency-based metrics, and expose failures overlooked by standard evaluation. Our experiments show that consistency across ARS correlates with final-answer correctness and helps pinpoint the reasoning steps where failures arise, offering actionable signals for model improvement. Furthermore, TRACE defines confidence regions that distinguish reliable from unreliable reasoning paths, supporting effective filtering, debugging, and model refinement.

</details>


### [25] [SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code](https://arxiv.org/abs/2512.05954)
*Shima Imani,Seungwhan Moon,Adel Ahmadyan,Lu Zhang,Kirmani Ahmed,Babak Damavandi*

Main category: cs.AI

TL;DR: SymPyBench是一个包含15,045个大学物理问题的大规模合成基准测试，支持无限参数配置，包含三种问题类型和创新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏能够全面评估语言模型科学推理能力的大规模基准测试，特别是能够测试模型在不同参数配置下一致性和鲁棒性的动态测试集。

Method: 创建了完全参数化的物理问题数据集，每个问题都附带结构化的逐步推理过程和可执行的Python代码。包含三种问题类型：MC-Symbolic、MC-Numerical和自由形式问题。

Result: 通过最先进的指令调优语言模型实验，揭示了模型在科学推理方面的优势和局限性。引入了三个新颖的评估指标：一致性分数、失败率和混淆率。

Conclusion: SymPyBench为开发更鲁棒和可解释的推理系统奠定了基础，能够量化模型在不同问题变体中的可变性和不确定性。

Abstract: We introduce, a large-scale synthetic benchmark of 15,045 university-level physics problems (90/10% train/test split). Each problem is fully parameterized, supporting an effectively infinite range of input configurations, and is accompanied by structured, step-by-step reasoning and executable Python code that produces the ground-truth solution for any parameter set. The benchmark contains three question types: MC-Symbolic (multiple-choice with symbolic options), MC-Numerical (multiple-choice with numerical options), and free-form (open-ended responses). These diverse formats test complementary reasoning skills. By leveraging the dynamic, code-driven nature of the benchmark, we introduce three novel evaluation metrics in addition to standard accuracy: Consistency Score, Failure Rate, and Confusion Rate, that quantify variability and uncertainty across problem variants. Experiments with state-of-the-art instruction-tuned language models reveal both strengths and limitations in scientific reasoning, positioning SymPyBench as a foundation for developing more robust and interpretable reasoning systems

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [26] [ProbeWalk: Fast Estimation of Biharmonic Distance on Graphs via Probe-Driven Random Walks](https://arxiv.org/abs/2512.05460)
*Dehong Zheng,Zhongzhi Zhang*

Main category: cs.SI

TL;DR: 本文提出了一种基于探针驱动随机游走的新算法，将双调和距离计算的时间复杂度从O(L⁵/ε_abs²)改进到O(L³/ε²)，实现了10-1000倍的加速，并能扩展到数千万节点的图。


<details>
  <summary>Details</summary>
Motivation: 双调和距离是图上的重要度量，广泛应用于网络中心性、图聚类和机器学习等领域。现有算法计算成本高昂，特别是对于现实网络（L≥10³）来说，L的五次方依赖导致计算效率低下。此外，双调和距离在不同节点对间变化幅度巨大，需要相对误差保证而非绝对误差保证。

Method: 提出基于探针驱动随机游走（probe-driven random walks）的新算法，通过改进计算策略将L的依赖从五次方降低到三次方，同时提供相对误差保证而非绝对误差保证。

Result: 在现实网络上的大量实验表明，新方法在相同相对误差下比基线方法快10-1000倍，能够扩展到具有数千万节点的图，显著提升了计算效率。

Conclusion: 通过探针驱动随机游走方法，本文显著改进了双调和距离的计算效率，将时间复杂度从O(L⁵/ε_abs²)降低到O(L³/ε²)，解决了大规模图分析中的计算瓶颈问题。

Abstract: The biharmonic distance is a fundamental metric on graphs that measures the dissimilarity between two nodes, capturing both local and global structures. It has found applications across various fields, including network centrality, graph clustering, and machine learning. These applications typically require efficient evaluation of pairwise biharmonic distances. However, existing algorithms remain computationally expensive. The state-of-the-art method attains an absolute-error guarantee epsilon_abs with time complexity O(L^5 / epsilon_abs^2), where L denotes the truncation length. In this work, we improve the complexity to O(L^3 / epsilon^2) under a relative-error guarantee epsilon via probe-driven random walks. We provide a relative-error guarantee rather than an absolute-error guarantee because biharmonic distances vary by orders of magnitude across node pairs. Since L is often very large in real-world networks (for example, L >= 10^3), reducing the L-dependence from the fifth to the third power yields substantial gains. Extensive experiments on real-world networks show that our method delivers 10x-1000x per-query speedups at matched relative error over strong baselines and scales to graphs with tens of millions of nodes.

</details>


### [27] [The Power of Network Pluralism: Multi-Perspective Modeling of Heterogeneous Legal Document Networks](https://arxiv.org/abs/2512.05679)
*Titus Pünder,Corinna Coupette*

Main category: cs.SI

TL;DR: 论文提出"网络多元主义"概念框架，通过多视角网络分析获得更完整、有意义和稳健的结果，并以法律系统分析为例进行演示。


<details>
  <summary>Details</summary>
Motivation: 认识到单一研究视角无法产生完整知识，需要采用认识论多元主义来获得对现象的整体理解。网络科学领域需要将这一理念转化为具体框架。

Method: 提出网络多元主义概念框架，通过构建多网络分析空间，将不同政府分支的文档引用、组织层级和细粒度结构纳入网络建模，展示多视角分析的优势。

Result: 多网络分析显示：互补视角有助于情境化高层发现；对比同一数据衍生的多个网络可通过差异学习；将指标与视角关联可提高网络分析结果的透明度和稳健性。

Conclusion: 网络多元主义为领域驱动的网络研究提供了蓝图，虽然将领域变化维度映射到网络建模决策和指标参数具有挑战性，但该框架有助于更广泛地采用多视角分析。

Abstract: Insights are relative - influenced by a range of factors such as assumptions, scopes, or methods that together define a research perspective. In normative and empirical fields alike, this insight has led to the conclusion that no single perspective can generate complete knowledge. As a response, epistemological pluralism mandates that researchers consider multiple perspectives simultaneously to obtain a holistic understanding of their phenomenon under study. Translating this mandate to network science, our work introduces Network Pluralism as a conceptual framework that leverages multi-perspectivity to yield more complete, meaningful, and robust results. We develop and demonstrate the benefits of this approach via a hands-on analysis of complex legal systems, constructing a network space from references across documents from different branches of government as well as including organizational hierarchy above and fine-grained structure below the document level. Leveraging the resulting heterogeneity in a multi-network analysis, we show how complementing perspectives can help contextualize otherwise high-level findings, how contrasting several networks derived from the same data enables researchers to learn by difference, and how relating metrics to perspectives may increase the transparency and robustness of network-analytical results. To analyze a space of networks as perspectives, researchers need to map dimensions of variation in a given domain to network-modeling decisions and network-metric parameters. While this remains a challenging and inherently interdisciplinary task, our work acts as a blueprint to facilitate the broader adoption of Network Pluralism in domain-driven network research.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [28] [La transformation num{é}rique de la justice : ambitions, r{é}alit{é}s et perspectives](https://arxiv.org/abs/2512.05143)
*Yannick Meneceur*

Main category: cs.CY

TL;DR: 该研究通过四年学术周期，结合法学硕士学生参与，客观评估司法数字化转型的话语与表征，重点关注从业者证言和现有文献。


<details>
  <summary>Details</summary>
Motivation: 研究旨在客观分析司法数字化转型的话语和表征，填补该领域系统性评估的空白，为理解数字化转型对司法系统的影响提供实证基础。

Method: 采用四年学术周期的纵向研究设计，结合斯特拉斯堡大学网络司法硕士项目学生的参与，收集和分析从业者证言，并系统梳理现有文献。

Result: 研究提供了对司法数字化转型话语和表征的客观评估，揭示了从业者视角与学术文献之间的异同，为政策制定和实践改进提供了实证依据。

Conclusion: 该研究通过多角度分析方法，为理解司法数字化转型提供了全面框架，强调了从业者经验与学术研究结合的重要性，对推动司法系统现代化具有参考价值。

Abstract: The study, conducted over a four-year academic cycle with the assistance of M2 students from the Cyberjustice Master's programme at the Faculty of Law, Political Science and Management at the University of Strasbourg, aims to objectively assess the discourse and representations of the digital transformation of justice, in particular by capitalising on testimonials from professionals in the field and drawing on the available literature.

</details>


### [29] [Deadline-Chasing in Digital Health: Modeling EMR Adoption Dynamics and Regulatory Impact in Indonesian Primary Care](https://arxiv.org/abs/2512.05381)
*Suryo Satrio,Bukhori Muhammad Aqid*

Main category: cs.CY

TL;DR: 研究评估印尼初级卫生机构电子病历采用水平与速度，发现PT MTK客户网络内EMR采用稳步增长，但总体市场份额仍低于10%。


<details>
  <summary>Details</summary>
Motivation: 印尼卫生部2022年第24号条例强制要求采用电子病历并与SATUSEHAT平台整合，但初级卫生机构采用的因素、轨迹和速度缺乏实证证据。

Method: 观察性研究，分析主要电子病历系统提供商PT MTK客户网络数据，使用描述性分析、逻辑增长模型和ARIMA预测方法。

Result: 33个月内累计注册机构从2家增至3,533家，中位同月激活率0.889，最终采用比例占合格机构的8.9%。ARIMA模型预测到2025年6月累计约3,997家诊所。

Conclusion: EMR采用在注册当月快速激活，呈现稳定增长。截止日期前出现局部激增表明存在"截止日期追逐"现象，应将干预措施与截止日期日历对齐以最大化影响。

Abstract: Indonesia digital healthcare transformation is accelerating under Minister of Health Regulation Number 24 of 2022, which mandates the adoption of Electronic Medical Records EMR and integration with the SATUSEHAT platform. However, empirical evidence regarding the factors, trajectory and speed of adoption in Primary Health Facilities FKTP remains limited. This study aims to evaluate the level and rate of EMR adoption within the customer network of a major EMR system provider PT MTK and model short-term projections. This is an observational study with the main variables being cumulative registered EMR facilities, monthly registration flow, same-month activation, same-month inactivation, and the estimated number of eligible FKTPs nationally monthly known as eligible facilities. The analysis uses descriptive analysis, logistic growth modeling, and ARIMA forecasting. The results of the study over 33 months showed that cumulative registered facilities increased from 2 to 3,533, with a median same-month activation rate of 0.889 IQR 0.717 to 0.992. The proportion of final adoption compared to eligible facilities was 8.9 percent 3,533 of 39,852. The ARIMA model projects a cumulative approximately 3,997 clinics 95 percent CI 3,697 to 4,298 by June 2025. The estimated growth in logistics converges with a carrying capacity of 4.1 thousand facilities. The study findings reveal that EMR adoption within the customer network of EMR system providers is showing steady growth with rapid activation in the month of registration. Although the cumulative series showed no major departures from the long-term trend, localized step-ups around deadlines suggest deadline chasing, so impact should be maximized by aligning interventions to the deadline calendar. Given the trajectory, total market share of FKTP for PT MTK remains less than 10 percent at the end of 2024, but continues to increase in 2025.

</details>


### [30] [Building Capacity for Artificial Intelligence in Africa: A Cross-Country Survey of Challenges and Governance Pathways](https://arxiv.org/abs/2512.05432)
*Jeffrey N. A. Aryee,Patrick Davies,Godfred A. Torsah,Mercy M. Apaw,Cyril D. Boateng,Sam M. Mwando,Chris Kwisanga,Eric Jobunga,Leonard K. Amekudzi*

Main category: cs.CY

TL;DR: 非洲AI教育面临机遇与挑战：大学与企业合作不足，资源分配不均，基础设施薄弱，但AI重要性已被广泛认可，需加强合作与政策支持


<details>
  <summary>Details</summary>
Motivation: AI正在改变教育和劳动力市场，但非洲的AI学习机会获取不均。随着人口结构快速变化和劳动力市场压力增加，AI已成为战略发展重点，相关技能需求日益紧迫。研究旨在了解非洲大学和产业如何参与塑造AI教育和劳动力准备。

Method: 通过对五个非洲国家（加纳、纳米比亚、卢旺达、肯尼亚和赞比亚）的问卷调查，分析大学和产业在AI教育和劳动力准备方面的参与情况。

Result: 研究显示：1）广泛认识到AI重要性，但持续参与、实践培训和资源公平获取有限；2）认为AI课程相关性高的受访者通常感觉就业准备充分；3）财务障碍、基础设施差、沟通不畅限制了参与，特别是学生和弱势群体；4）实习、产业合作和针对性支持机制是关键推动因素；5）需要包容性治理框架。

Conclusion: 非洲对AI潜力认识不断增强，但结构性差距阻碍其转化为劳动力能力。加强大学-产业合作，解决获取、资金和政策障碍，对确保AI促进非洲大陆公平和可持续发展至关重要。

Abstract: Artificial intelligence (AI) is transforming education and the workforce, but access to AI learning opportunities in Africa remains uneven. With rapid demographic shifts and growing labour market pressures, AI has become a strategic development priority, making the demand for relevant skills more urgent. This study investigates how universities and industries engage in shaping AI education and workforce preparation, drawing on survey responses from five African countries (Ghana, Namibia, Rwanda, Kenya and Zambia). The findings show broad recognition of AI importance but limited evidence of consistent engagement, practical training, or equitable access to resources. Most respondents who rated the AI component of their curriculum as very relevant reported being well prepared for jobs, but financial barriers, poor infrastructure, and weak communication limit participation, especially among students and underrepresented groups. Respondents highlighted internships, industry partnerships, and targeted support mechanisms as critical enablers, alongside the need for inclusive governance frameworks. The results showed both the growing awareness of AI's potential and the structural gaps that hinder its translation into workforce capacity. Strengthening university-industry collaboration and addressing barriers of access, funding, and policy are central to ensuring that AI contributes to equitable and sustainable development across the continent.

</details>


### [31] [Knowing Your Uncertainty -- On the application of LLM in social sciences](https://arxiv.org/abs/2512.05461)
*Bolun Zhang,Linzhuo Li,Yunqi Chen,Qinlin Zhao,Zihan Zhu,Xiaoyuan Yi,Xing Xie*

Main category: cs.CY

TL;DR: 本文提出了一个评估大语言模型在社会科学研究中不确定性的统一框架，通过任务类型和验证类型两个维度进行分类，为研究者提供实用建议。


<details>
  <summary>Details</summary>
Motivation: 大语言模型越来越多地应用于计算社会科学研究，但其黑盒训练和推理中的随机性给科学研究带来了独特挑战。社会科学和机器学习领域都强调不确定性评估的重要性，因此需要系统的方法来评估LLM在社会科学任务中的不确定性。

Method: 提出了一个统一的评估框架，包含两个维度：任务类型（分类、短文本生成、长文本生成）和验证类型（参考数据或评估标准的可用性）。基于计算机科学和社会科学文献，将现有不确定性量化方法映射到这个T-V分类体系中。

Result: 该框架为研究者提供了实用的不确定性评估建议，能够帮助社会科学研究者更严谨地整合大语言模型到研究中。

Conclusion: 该框架既作为方法学保障，又作为实践指南，支持大语言模型在严谨的社会科学研究中的整合应用，强调不确定性评估对于LLM在社会科学研究中的可靠使用至关重要。

Abstract: Large language models (LLMs) are rapidly being integrated into computational social science research, yet their blackboxed training and designed stochastic elements in inference pose unique challenges for scientific inquiry. This article argues that applying LLMs to social scientific tasks requires explicit assessment of uncertainty-an expectation long established in both quantitative methodology in the social sciences and machine learning. We introduce a unified framework for evaluating LLM uncertainty along two dimensions: the task type (T), which distinguishes between classification, short-form, and long-form generation, and the validation type (V), which captures the availability of reference data or evaluative criteria. Drawing from both computer science and social science literature, we map existing uncertainty quantification (UQ) methods to this T-V typology and offer practical recommendations for researchers. Our framework provides both a methodological safeguard and a practical guide for integrating LLMs into rigorous social science research.

</details>


### [32] [The Topology of Hardship: Empirical Curriculum Graphs and Structural Bottlenecks in Engineering Degrees](https://arxiv.org/abs/2512.05561)
*H. R. Paz*

Main category: cs.CY

TL;DR: 工程学位的"难度"可通过学生实际学习轨迹构建的课程网络拓扑结构来量化，研究发现课程结构的密度和瓶颈中心性等拓扑特征与辍学率、毕业时间显著相关。


<details>
  <summary>Details</summary>
Motivation: 传统上工程学位的"难度"通常被归因于内容难度或学生能力不足，而非课程结构本身。现有研究多基于官方教学大纲而非学生实际学习轨迹，缺乏对课程结构复杂性的实证量化分析。

Method: 基于CAPIRE多级轨迹建模框架，从29个工程课程的学生注册和完成数据重建课程网络图，计算结构指标（密度、最长路径、瓶颈中心性）和实证困难度量（阻塞概率、进度时间），组合成综合困难指数，并与辍学率、毕业时间关联分析。

Result: 课程难度是可测量的拓扑属性：少数结构密集、瓶颈严重的课程导致了不成比例的辍学率和时间不同步。课程硬度不是模糊感知，而是可量化的结构特征。

Conclusion: 课程改革、认证和数据驱动的政策设计应考虑课程拓扑结构的影响，通过优化课程网络结构来降低学生困难，提高学业完成率。

Abstract: Engineering degrees are often perceived as "hard", yet this hardness is usually discussed in terms of content difficulty or student weaknesses rather than as a structural property of the curriculum itself. Recent work on course-prerequisite networks and curriculum graphs has shown that study plans can be modelled as complex networks with identifiable hubs and bottlenecks, but most studies rely on official syllabi rather than on how students actually progress through the system (Simon de Blas et al., 2021; Stavrinides & Zuev, 2023; Yang et al., 2024; Wang et al., 2025).
  This paper introduces the notion of topology of hardship: a quantitative description of curriculum complexity derived from empirical student trajectories in long-cycle engineering programmes. Building on the CAPIRE framework for multilevel trajectory modelling (Paz, 2025a, 2025b), we reconstruct degree-curriculum graphs from enrolment and completion data for 29 engineering curricula across several cohorts. For each graph we compute structural metrics (e.g., density, longest path, bottleneck centrality) and empirical hardship measures capturing blocking probability and time-to-progress. These are combined into a composite hardship index, which is then related to observed dropout rates and time to degree.
  Our findings show that curriculum hardness is not a vague perception but a measurable topological property: a small number of structurally dense, bottleneck-heavy curricula account for a disproportionate share of dropout and temporal desynchronisation. We discuss implications for curriculum reform, accreditation, and data-informed policy design.

</details>


### [33] [Open Data, Privacy, and Fair Information Principles: Towards a Balancing Framework](https://arxiv.org/abs/2512.05728)
*Frederik Zuiderveen Borgesius,Jonathan Gray,Mireille van Eechoud*

Main category: cs.CY

TL;DR: 本文提出了一个平衡框架，帮助公共机构在开放政府数据时保护个人隐私，认为开放数据并非唯一途径，需要明确的公共利益论证才能将个人信息作为开放数据发布。


<details>
  <summary>Details</summary>
Motivation: 开放数据有助于实现透明度、公众参与、民主问责、经济增长、创新和公共部门效率等多种社会政治目标，但包含个人信息的政府数据发布可能威胁隐私和相关权益。需要平衡隐私保护与开放数据带来的利益。

Method: 提出了一个平衡框架，考虑不同类型数据的隐私风险级别，区分访问和再利用决策，强调多种披露途径，并提供一个情况目录列举评估数据集是否、在何种条件下以及如何发布时需要考虑的因素。

Result: 框架为公共机构提供了在不同情境下处理隐私与开放数据冲突的实用工具，强调需要根据具体情况进行平衡决策。

Conclusion: 开放数据虽然是发布政府信息的重要途径，但不是唯一途径。将个人信息作为开放数据发布需要有明确且充分的公共利益论证。需要在隐私保护与开放数据利益之间找到适当平衡。

Abstract: Open data are held to contribute to a wide variety of social and political goals, including strengthening transparency, public participation and democratic accountability, promoting economic growth and innovation, and enabling greater public sector efficiency and cost savings. However, releasing government data that contain personal information may threaten privacy and related rights and interests. In this Article we ask how these privacy interests can be respected, without unduly hampering benefits from disclosing public sector information. We propose a balancing framework to help public authorities address this question in different contexts. The framework takes into account different levels of privacy risks for different types of data. It also separates decisions about access and re-use, and highlights a range of different disclosure routes. A circumstance catalogue lists factors that might be considered when assessing whether, under which conditions, and how a dataset can be released. While open data remains an important route for the publication of government information, we conclude that it is not the only route, and there must be clear and robust public interest arguments in order to justify the disclosure of personal information as open data.

</details>


### [34] [Informed Consent: We Can Do Better to Defend Privacy](https://arxiv.org/abs/2512.05729)
*Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 论文批判当前隐私保护过度依赖知情同意机制，认为行为研究显示其效果有限，主张结合保护与赋权双重路径


<details>
  <summary>Details</summary>
Motivation: 当前隐私保护政策过度依赖知情同意机制，但行为研究表明人们倾向于盲目点击同意，导致隐私保护效果不佳，需要重新思考隐私保护方法

Method: 通过分析行为研究证据，批判知情同意在实际操作中的问题，以行为定向广告为例说明当前隐私规则的缺陷，提出保护与赋权相结合的理论框架

Result: 指出知情同意机制在实践中存在严重缺陷，人们无法做出理性隐私决策，当前隐私规则对行为定向广告的监管不足，需要更强调保护性规则

Conclusion: 政策制定者应减少对知情同意机制的依赖，更多关注直接保护个人的规则，采取保护与赋权相结合的综合隐私保护策略

Abstract: We need to rethink our approach to defend privacy on the internet. Currently, policymakers focus heavily on the idea of informed consent as a means to defend privacy. For instance, in many countries the law requires firms to obtain an individual's consent before they use data about her; with such informed consent requirements, the law aims to empower people to make privacy choices in their best interests. But behavioural studies cast doubt on this approach's effectiveness, as people tend to click OK to almost any request they see on their screens. To improve privacy protection, this article argues for a combined approach of protecting and empowering the individual. This article discusses practical problems with informed consent as a means to protect privacy, and illustrates the problems with current data privacy rules regarding behavioural targeting. First, the privacy problems of behavioural targeting, and the central role of informed consent in privacy law are discussed. Following that, practical problems with informed consent are highlighted. Then, the article argues that policymakers should give more attention to rules that protect, rather than empower, people.

</details>


### [35] [De mythe van geïnformeerde toestemming: online privacybescherming kan beter [Informed Consent: We Can Do Better to Defend Privacy]](https://arxiv.org/abs/2512.05730)
*Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 论文批判当前隐私保护过度依赖知情同意模式，指出行为研究显示其效果有限，主张应采用保护与赋权相结合的新方法。


<details>
  <summary>Details</summary>
Motivation: 当前隐私保护政策过度依赖"知情同意"模式，但行为研究表明人们倾向于盲目点击同意，导致这种机制失效。需要重新思考更有效的隐私保护方法。

Method: 通过分析行为目标定位的隐私问题，探讨知情同意在隐私法中的核心作用，揭示知情同意的实际局限性，并提出政策建议。

Result: 指出知情同意机制存在严重实践问题，人们无法做出理性的隐私选择，当前隐私规则在行为目标定位方面效果不佳。

Conclusion: 政策制定者应减少对赋权型规则（如知情同意）的依赖，更多关注保护型规则，采取保护与赋权相结合的综合隐私保护方法。

Abstract: We need to rethink our approach to defend privacy on the internet. Currently, policymakers focus heavily on the idea of informed consent as a means to defend privacy. For instance, in many countries the law requires firms to obtain an individual's consent before they use data about her; with such informed consent requirements, the law aims to empower people to make privacy choices in their best interests. But behavioural studies cast doubt on this approach's effectiveness, as people tend to click OK to almost any request they see on their screens. To improve privacy protection, this article argues for a combined approach of protecting and empowering the individual. This article discusses practical problems with informed consent as a means to protect privacy, and illustrates the problems with current data privacy rules regarding behavioural targeting. First, the privacy problems of behavioural targeting, and the central role of informed consent in privacy law are discussed. Following that, practical problems with informed consent are highlighted. Then, the article argues that policymakers should give more attention to rules that protect, rather than empower, people.

</details>


### [36] [Internal Deployment in the EU AI Act](https://arxiv.org/abs/2512.05742)
*Matteo Pistillo*

Main category: cs.CY

TL;DR: 该备忘录分析了欧盟AI法案是否适用于内部部署AI系统的争议，探讨了支持与反对的论点，并提出了基于法案条款的多种解释路径。


<details>
  <summary>Details</summary>
Motivation: 欧盟AI法案对内部部署AI系统的适用范围存在争议，需要澄清法律解释以指导欧盟委员会、AI提供商、部署者及法律政策界。

Method: 基于欧盟AI法案第2(1)、2(6)、2(8)条进行法律分析，首先分析支持内部部署适用的四种解释路径，然后审查可能的反对意见和例外情况，最后展示各条款的互补性。

Result: 提出了多种解释路径，表明欧盟AI法案可能适用于内部部署AI系统，但也存在例外情况，特别是第2(6)条的科学研发例外较为复杂。

Conclusion: 通过综合分析相关条款，备忘录为欧盟AI法案对内部部署AI系统的适用性提供了法律解释框架，有助于各方理解和应用该法案。

Abstract: This memorandum analyzes and stress-tests arguments in favor and against the inclusion of internal deployment within the scope of the European Union Artificial Intelligence Act (EU AI Act). In doing so, it aims to offer several possible interpretative pathways to the European Commission, AI providers and deployers, and the legal and policy community at large based on Articles 2(1), 2(6), 2(8) of the EU AI Act. Specifically, this memorandum first analyzes four interpretative pathways based on Article 2(1)(a)-(c) supporting the application of the EU AI Act to internally deployed AI models and systems. Then, it examines possible objections and exceptions based on Articles 2(1)(a), 2(6), and 2(8), with particular attention to the complexity of the scientific R&D exception under Article 2(6). Finally, it illustrates how Articles 2(1), 2(6), and 2(8) can be viewed as complementary to each other, once broken down to their most plausible meaning and interpreted in conjunction with Articles 3(1), 3(3), 3(4), 3(9), 3(10), 3(11), 3(12), 3(63), and Recitals 12, 13, 21, 25, 97, and 109.

</details>


### [37] [LLM Harms: A Taxonomy and Discussion](https://arxiv.org/abs/2512.05929)
*Kevin Chen,Saleh Afroogh,Abhejay Murali,David Atkinson,Amit Dhurandhar,Junfeng Jiao*

Main category: cs.CY

TL;DR: 该研究系统分析了大型语言模型在AI应用开发前、中、后各阶段的五类潜在危害，并提出缓解策略和动态审计系统，以促进LLM负责任的发展和应用。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在AI应用中存在多种潜在危害风险，需要在开发前、中、后各阶段进行系统性识别和管理，以确保问责制、透明度和减少偏见，促进LLM在实际应用中的负责任发展。

Method: 研究采用分类分析方法，识别了五个危害类别：开发前危害、直接输出危害、滥用和恶意应用危害、下游应用危害。通过定义当前风险格局，提出缓解策略和未来发展方向，并设计动态审计系统来指导标准化提案。

Result: 建立了全面的LLM危害分类框架，涵盖开发全周期的风险识别，提出了针对特定领域的缓解策略和动态审计机制，为标准化负责任LLM开发提供了系统化方案。

Conclusion: 需要系统性地定义和管理LLM在各应用阶段的潜在危害，通过动态审计系统和标准化提案确保问责制、透明度和偏见控制，促进LLM在实际应用中的负责任发展和集成。

Abstract: This study addresses categories of harm surrounding Large Language Models (LLMs) in the field of artificial intelligence. It addresses five categories of harms addressed before, during, and after development of AI applications: pre-development, direct output, Misuse and Malicious Application, and downstream application. By underscoring the need to define risks of the current landscape to ensure accountability, transparency and navigating bias when adapting LLMs for practical applications. It proposes mitigation strategies and future directions for specific domains and a dynamic auditing system guiding responsible development and integration of LLMs in a standardized proposal.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [38] [First Demonstration of Second-order Training of Deep Neural Networks with In-memory Analog Matrix Computing](https://arxiv.org/abs/2512.05342)
*Saitao Zhang,Yubiao Luo,Shiqing Wang,Pushen Zuo,Yongxiang Li,Lunshuai Pan,Zheng Miao,Zhong Sun*

Main category: cs.ET

TL;DR: 基于RRAM内存模拟矩阵计算实现二阶优化器，通过单步矩阵求逆加速神经网络训练，相比SGD和Adam分别减少26%和61%训练轮次，能效提升6.9倍。


<details>
  <summary>Details</summary>
Motivation: 二阶优化方法虽然收敛更快更稳定，但传统数字处理器计算二阶信息矩阵求逆成本过高，限制了其在大规模神经网络训练中的实际应用。

Method: 使用电阻式随机存取存储器(RRAM)实现内存模拟矩阵计算(AMC)，在单步内完成矩阵求逆操作，构建基于硬件的二阶优化器。

Result: 在手写字母分类任务中，相比带动量的SGD和Adam分别减少26%和61%训练轮次；在更大任务中，相比最先进数字处理器吞吐量提升5.88倍，能效提升6.9倍。

Conclusion: AMC电路为二阶神经网络训练提供了可行有效的解决方案，为能效型AI加速开辟了新路径。

Abstract: Second-order optimization methods, which leverage curvature information, offer faster and more stable convergence than first-order methods such as stochastic gradient descent (SGD) and Adam. However, their practical adoption is hindered by the prohibitively high cost of inverting the second-order information matrix, particularly in large-scale neural network training. Here, we present the first demonstration of a second-order optimizer powered by in-memory analog matrix computing (AMC) using resistive random-access memory (RRAM), which performs matrix inversion (INV) in a single step. We validate the optimizer by training a two-layer convolutional neural network (CNN) for handwritten letter classification, achieving 26% and 61% fewer training epochs than SGD with momentum and Adam, respectively. On a larger task using the same second-order method, our system delivers a 5.88x improvement in throughput and a 6.9x gain in energy efficiency compared to state-of-the-art digital processors. These results demonstrate the feasibility and effectiveness of AMC circuits for second-order neural network training, opening a new path toward energy-efficient AI acceleration.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [39] [Consistency of Familial DNA Search Results in Southeast Asian Populations](https://arxiv.org/abs/2512.05490)
*Monchai Kooakachai,Tiwakorn Chapalee,Chairat Thitiyan,Patsaya Jumnongwut*

Main category: stat.AP

TL;DR: 该研究评估了东南亚人口（泰国、马来西亚、新加坡）中基于似然比的家族DNA搜索策略，发现在泰国亚群中，最小似然比策略在保持高统计功效的同时能最小化亚群间差异。


<details>
  <summary>Details</summary>
Motivation: 当DNA数据库中没有精确匹配时，家族DNA搜索可以通过似然比识别一级亲属。在存在多个相关亚群的情况下，需要有效的策略来组合不同亚群的似然比。虽然已有研究在美国人群中进行比较，但这些策略在其他地区（特别是东南亚）的有效性尚不清楚。

Method: 研究评估了多种似然比组合策略在东南亚人口（泰国、马来西亚、新加坡）中的表现。比较了不同策略，包括平均等位基因频率、平均似然比、最大似然比和最小似然比等方法。

Result: 研究结果与先前研究一致，显示统计功效在不同策略间存在差异。在泰国亚群中，最小似然比策略表现最佳，能够在保持高统计功效的同时，最小化不同亚群之间的差异。

Conclusion: 对于东南亚人口，特别是泰国亚群，推荐使用最小似然比策略进行家族DNA搜索，因为它在维持高识别能力的同时，能够有效处理亚群间的遗传差异。

Abstract: DNA databases are widely used in forensic science to identify unknown offenders. When no exact match is found, familial DNA searches can help by identifying first-degree relatives using likelihood ratios. If multiple subpopulations are relevant, likelihood ratios can be computed separately based on allele frequency estimates. Various strategies exist to combine these ratios, such as averaging allele frequencies or taking the average, maximum, or minimum likelihood ratio. While some comparisons have been made in populations like those in the U.S., their effectiveness in other regions remains unclear. This study evaluates likelihood ratio-based strategies in Southeast Asian populations, specifically Thailand, Malaysia, and Singapore. Our findings align with previous research, showing that statistical power varies across strategies. Among Thai subpopulations, the minimum likelihood ratio strategy is preferred, as it maintains high power while minimizing differences between subpopulations.

</details>


### [40] [Multi-state Modeling of Delay Evolution in Suburban Rail Transports](https://arxiv.org/abs/2512.05521)
*Stefania Colombo,Alfredo Gimenez Zapiola,Francesca Ieva,Simone Vantini*

Main category: stat.AP

TL;DR: 该研究应用连续时间多状态模型分析意大利伦巴第S5郊区线路的延误动态，揭示延误传播的时空特征及影响因素。


<details>
  <summary>Details</summary>
Motivation: 铁路系统特别是郊区网络的延误问题严重，传统延误模型往往忽略延误传播的时空动态特征，需要更精细的分析方法。

Method: 使用连续时间多状态模型，结合详细的运营数据、气象数据和上下文数据，对延误转换进行建模，同时考虑可观测的异质性。

Result: 研究发现延误动态随行驶方向、时间段和路线段而变化，车站饱和度和乘客负载等协变量显著影响延误升级或恢复的风险。

Conclusion: 该研究提供了方法学进步和实用结果，有助于提高铁路服务的可靠性，为改善运营管理提供依据。

Abstract: Train delays are a persistent issue in railway systems, particularly in suburban networks where operational complexity is heightened by frequent services and high passenger volumes. Traditional delay models often overlook the temporal and structural dynamics of real delay propagation.
  This work applies continuous-time multi-state models to analyze the temporal evolution of delay on the S5 suburban line in Lombardy, Italy. Using detailed operational, meteorological, and contextual data, the study models delay transitions while accounting for observable heterogeneity.
  The findings reveal how delay dynamics vary by travel direction, time slot, and route segment. Covariates such as station saturation and passenger load are shown to significantly affect the risk of delay escalation or recovery. The study offers both methodological advancements and practical results for improving the reliability of rail services.

</details>
