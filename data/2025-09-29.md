<div id=toc></div>

# Table of Contents

- [econ.TH](#econ.TH) [Total: 3]
- [stat.AP](#stat.AP) [Total: 3]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.RO](#cs.RO) [Total: 47]
- [eess.SY](#eess.SY) [Total: 9]
- [cs.SI](#cs.SI) [Total: 2]
- [econ.EM](#econ.EM) [Total: 1]
- [cs.CY](#cs.CY) [Total: 9]
- [econ.GN](#econ.GN) [Total: 8]
- [cs.AI](#cs.AI) [Total: 51]


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [1] [Linear Risk Sharing on Networks](https://arxiv.org/abs/2509.21411)
*Arthur Charpentier,Philipp Ratz*

Main category: econ.TH

TL;DR: 提出了线性风险共享(LRS)框架，通过非负线性算子重新分配随机损失，涵盖各种网络结构。基于随机矩阵理论，建立了预算平衡、公平性和多样化的约束条件，并分析了不同网络拓扑对风险结果的影响。


<details>
  <summary>Details</summary>
Motivation: 随着点对点保险、互惠合约和去中心化金融平台的兴起，需要建立基于网络结构的风险再分配理论框架，以促进本地参与和风险分散。

Method: 构建线性风险共享框架，使用随机矩阵和双随机矩阵理论，分析不同网络拓扑（完全图、星形、环形、随机、无标度图）的风险共享特性，并引入随机共享矩阵。

Result: 建立了保证预算平衡、公平性和多样化的条件，证明了双随机混合自然导致方差减少和优化，揭示了网络拓扑如何影响风险结果，并提供了网络风险池化的设计原则。

Conclusion: 该框架为公平高效的点对点保险和网络风险池化提供了数学严谨且经济可解释的设计原则，结合了自保留与多样化的权衡。

Abstract: Over the past decade alternatives to traditional insurance and banking have
grown in popularity. The desire to encourage local participation has lead
products such as peer-to-peer insurance, reciprocal contracts, and
decentralized finance platforms to increasingly rely on network structures to
redistribute risk among participants. In this paper, we develop a comprehensive
framework for linear risk sharing (LRS), where random losses are reallocated
through nonnegative linear operators which can accommodate a wide range of
networks. Building on the theory of stochastic and doubly stochastic matrices,
we establish conditions under which constraints such as budget balance,
fairness, and diversification are guaranteed. The convex order framework allows
us to compare different allocations rigorously, highlighting variance reduction
and majorization as natural consequences of doubly stochastic mixing. We then
extend the analysis to network-based sharing, showing how their topology shapes
risk outcomes in complete, star, ring, random, and scale-free graphs. A second
layer of randomness, where the sharing matrix itself is random, is introduced
via Erd\H{o}s--R\'enyi and preferential-attachment networks, connecting
risk-sharing properties to degree distributions. Finally, we study convex
combinations of identity and network-induced operators, capturing the trade-off
between self-retention and diversification. Our results provide design
principles for fair and efficient peer-to-peer insurance and network-based risk
pooling, combining mathematical soundness with economic interpretability.

</details>


### [2] [Dynamic Threats to Credible Auctions](https://arxiv.org/abs/2509.21439)
*Martino Banchio,Andrzej Skrzypacz,Frank Yang*

Main category: econ.TH

TL;DR: 当卖家拥有关于其成本的私人信息时，静态机制无法实现最优收益，最优第一价格拍卖不可信。英语拍卖可以可信地实施最优机制，而荷兰拍卖则不能。


<details>
  <summary>Details</summary>
Motivation: 研究在卖家拥有私人成本信息的情况下，如何设计可信的拍卖机制来实现最优收益。

Method: 分析不同拍卖机制的可信性，包括第一价格拍卖、英语拍卖和荷兰拍卖，并推导静态拍卖的可信性条件。

Result: 英语拍卖可以可信地实施最优机制，而最优第一价格拍卖和荷兰拍卖不可信。可信的静态拍卖必须是通过秘密保留价依赖卖家成本的第一价格拍卖。

Conclusion: 卖家私人信息的存在限制了静态机制的最优性，动态机制在非正式拍卖中具有优势，这解释了公共机构的作用和动态机制的使用。

Abstract: A seller wants to sell a good to a set of bidders using a credible mechanism.
We show that when the seller has private information about her cost, it is
impossible for a static mechanism to achieve the optimal revenue. In
particular, even the optimal first-price auction is not credible. We show that
the English auction can credibly implement the optimal mechanism, unlike the
optimal Dutch auction. For symmetric mechanisms in which only winners pay, we
also characterize all the static auctions that are credible: They are
first-price auctions that depend only on the seller's cost ex post via a secret
reserve, and may profitably pool bidders via a bid restriction. Our
impossibility result highlights the role of public institutions and helps
explain the use of dynamic mechanisms in informal auctions.

</details>


### [3] [On fairness of multi-center allocation problems](https://arxiv.org/abs/2509.21812)
*Yao Cheng,Di Feng*

Main category: econ.TH

TL;DR: 该论文研究多中心分配问题中的公平性，提出了三种公平概念：内部公平、外部公平和程序公平，并通过这些概念对TTC机制进行了三个特征化。


<details>
  <summary>Details</summary>
Motivation: 研究多中心分配问题中的公平性，特别是在尊重中心优先级的背景下，为医疗项目国际合作和工人交换项目等实际应用提供理论支持。

Method: 引入三种公平概念：内部公平（消除同一中心内代理人之间的嫉妒）、外部公平（消除不同中心间代理人的嫉妒）和程序公平（从事前角度通过交易机会消除嫉妒）。使用策略证明性和效率等公理对TTC机制进行特征化。

Result: 证明了三个主要定理：在策略证明性和配对效率下，内部公平和外部公平共同特征化TTC（定理1）；策略证明性与程序公平单独也特征化TTC（定理2）；通过添加内部公平，建立了第三个TTC特征化（定理3）。还定义了核心解并通过TTC进行特征化（定理4）。

Conclusion: 研究结果为市场设计者提供了实用见解，特别是在国际医疗合作和工人交换项目等背景下，TTC机制能够同时满足多种公平性要求。

Abstract: We investigate Ekici (2024b)'s multi-center allocation problems, focusing on
fairness in this context. We introduce three fairness notions that respect
centers' priorities: internal fairness, external fairness, and procedural
fairness. The first notion eliminates envy among agents within the same center,
the second prohibits envy across different centers, and the third rules out
envy from an ex-ante perspective through agents' trading opportunities. We
provide two characterizations of a natural extension of the top-trading-cycles
mechanism (TTC) through our fairness notions. Precisely, we show that in the
presence of strategy-proofness and pair efficiency, internal fairness and
external fairness together characterize TTC (Theorem 1). Also,
strategy-proofness combined solely with procedural fairness also characterizes
TTC (Theorem 2). Furthermore, by adding internal fairness, we establish our
third TTC characterization, by relaxing Ekici's queuewise rationality to
another voluntary participation condition, the center lower bound (Theorem 3).
Finally, we define a core solution within this model and characterize it
through TTC (Theorem 4). Our findings offer practical insights for market
designers, particularly in contexts such as international cooperation in
medical programs and worker exchange programs.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [4] [Quantifying Fire Risk Index in Chemical Industry Using Statistical Modeling Procedure](https://arxiv.org/abs/2509.21736)
*Hyewon Jung,Seungil Ahn,Seungho Choi,Yeseul Jeon*

Main category: stat.AP

TL;DR: 开发了一个基于文本数据的火灾风险指数框架，通过整合火灾报告中的文本叙述和财务损失数据，量化关键词与财产损失之间的关联，实现可解释的火灾风险评估。


<details>
  <summary>Details</summary>
Motivation: 火灾事故报告中的文本叙述包含了结构化记录中常被忽略的因果因素，而财务损失金额提供了这些事件的可衡量结果。整合这两种信息对于揭示描述性原因与其经济后果之间的可解释联系至关重要。

Method: 使用韩国化学工业特殊建筑火灾调查报告（2013-2024），采用主题建模和基于网络的嵌入来估计词语间的语义相似性，然后应用Lasso回归量化它们与财产损失金额的关联，从而估计火灾风险指数。

Result: 分析识别了多个风险领域，包括危险化学品泄漏、不安全存储实践、设备和设施故障以及环境引发的点火。文本衍生指数提供了可解释且实际相关的见解。

Conclusion: 文本衍生指数提供了可解释且实际相关的见解，将非结构化叙述与结构化损失信息联系起来，为基于证据的火灾风险评估和管理提供了基础。

Abstract: Fire incident reports contain detailed textual narratives that capture causal
factors often overlooked in structured records, while financial damage amounts
provide measurable outcomes of these events. Integrating these two sources of
information is essential for uncovering interpretable links between descriptive
causes and their economic consequences. To this end, we develop a data-driven
framework that constructs a composite Risk Index, enabling systematic
quantification of how specific keywords relate to property damage amounts. This
index facilitates both the identification of high-impact terms and the
aggregation of risks across semantically related clusters, thereby offering a
principled measure of fire-related financial risk. Using more than a decade of
Korean fire investigation reports on the chemical industry classified as
Special Buildings (2013 through 2024), we employ topic modeling and
network-based embedding to estimate semantic similarities from interactions
among words and subsequently apply Lasso regression to quantify their
associations with property damage amounts, thereby estimate fire risk index.
This approach enables us to assess fire risk not only at the level of
individual terms but also within their broader textual context, where highly
interactive related words provide insights into collective patterns of hazard
representation and their potential impact on expected losses. The analysis
highlights several domains of risk, including hazardous chemical leakage,
unsafe storage practices, equipment and facility malfunctions, and
environmentally induced ignition. The results demonstrate that text-derived
indices provide interpretable and practically relevant insights, bridging
unstructured narratives with structured loss information and offering a basis
for evidence-based fire risk assessment and management.

</details>


### [5] [Personalized Oncology: Feasibility of Evaluating Treatment Effects for Individual Patients](https://arxiv.org/abs/2509.22089)
*Lydia Jang,Stefan Konigorski*

Main category: stat.AP

TL;DR: 该研究探索了在单癌症患者环境中应用因果推断方法的可行性，通过分析一个转移性癌症患者的纵向数据，使用时间变化的g-公式计算个体特异性治疗效果。


<details>
  <summary>Details</summary>
Motivation: 个性化肿瘤治疗的有效性取决于能否因果归因于治疗，但由于癌症的异质性和动态性，传统方法难以评估个体治疗效果。N-of-1试验旨在评估个体治疗效果，但现有因果框架是否适用于单癌症患者环境尚不清楚。

Method: 使用一个转移性癌症患者的纵向数据集，包含自适应选择的治疗方案以及随时间记录的生物标志物和病变测量。选择数据点充足的治疗期，应用因果框架定义估计目标、识别因果关系和假设，并使用时间变化的g-公式计算个体特异性治疗效果。

Result: 研究证明了在单癌症患者环境中应用因果方法的可行性，能够明确说明何时以及如何在这种环境中估计因果治疗效果。

Conclusion: 该研究不仅展示了在单癌症患者环境中应用因果方法的可行性，还为在更广泛的癌症类型中个性化环境中使用因果方法提供了蓝图。

Abstract: The effectiveness of personalized oncology treatments ultimately depends on
whether outcomes can be causally attributed to the treatment. Advances in
precision oncology have improved molecular profiling of individuals, and
tailored therapies have led to more effective treatments for select patient
groups. However, treatment responses still vary among individuals. As cancer is
a heterogeneous and dynamic disease with varying treatment outcomes across
different molecular types and resistance mechanisms, it requires customized
approaches to identify cause-and-effect relationships. N-of-1 trials, or
single-subject clinical trials, are designed to evaluate individual treatment
effects. Several works have described different causal frameworks to identify
treatment effects in N-of-1 trials, yet whether these approaches can be
extended to single-cancer patient settings remains unclear. To explore this
possibility, a longitudinal dataset from a single metastatic cancer patient
with adaptively chosen treatments was considered. The dataset consisted of a
detailed treatment plan as well as biomarker and lesion measurements recorded
over time. After data processing, a treatment period with sufficient data
points to conduct causal inference was selected. Under this setting, a causal
framework was applied to define an estimand, identify causal relationships and
assumptions, and calculate an individual-specific treatment effect using a
time-varying g-formula. Through this application, we illustrate explicitly when
and how causal treatment effects can be estimated in single-patient oncology
settings. Our findings not only demonstrate the feasibility of applying causal
methods in a single-cancer patient setting but also offer a blueprint for using
causal methods across a broader spectrum of cancer types in individualized
settings.

</details>


### [6] [Chronic Stress, Immune Suppression, and Cancer Occurrence: Unveiling the Connection using Survey Data and Predictive Models](https://arxiv.org/abs/2509.22275)
*Teddy Lazebnik,Vered Aharonson*

Main category: stat.AP

TL;DR: 使用机器学习和因果模型分析慢性压力与癌症发生之间的因果关系，发现压力频率、压力水平和感知健康影响与癌症发病率存在显著因果关联，整合社会人口学和家族癌症史数据可显著提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 慢性压力被认为与癌症发生有关，但直接的因果关系尚未得到一致证实。机器学习和因果建模为探索心理慢性压力与癌症发生之间的复杂因果相互作用提供了机会。

Method: 开发预测模型，使用压力指标、癌症史和人口统计学数据等变量，通过自我报告调查收集数据，并用传统统计方法进行验证。

Result: 发现压力频率、压力水平和感知健康影响与癌症发病率存在显著因果关联。虽然单独的压力预测能力有限，但整合社会人口学和家族癌症史数据可显著提高模型准确性。

Conclusion: 研究结果强调了癌症风险的多维性质，压力与遗传易感性一样是一个重要因素。这些发现支持将慢性压力作为可改变的癌症风险因素，纳入个性化预防策略和公共卫生干预措施以减少癌症发病率。

Abstract: Chronic stress was implicated in cancer occurrence, but a direct causal
connection has not been consistently established. Machine learning and causal
modeling offer opportunities to explore complex causal interactions between
psychological chronic stress and cancer occurrences. We developed predictive
models employing variables from stress indicators, cancer history, and
demographic data from self-reported surveys, unveiling the direct and immune
suppression mitigated connection between chronic stress and cancer occurrence.
The models were corroborated by traditional statistical methods. Our findings
indicated significant causal correlations between stress frequency, stress
level and perceived health impact, and cancer incidence. Although stress alone
showed limited predictive power, integrating socio-demographic and familial
cancer history data significantly enhanced model accuracy. These results
highlight the multidimensional nature of cancer risk, with stress emerging as a
notable factor alongside genetic predisposition. These findings strengthen the
case for addressing chronic stress as a modifiable cancer risk factor,
supporting its integration into personalized prevention strategies and public
health interventions to reduce cancer incidence.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [7] [Bacterial Gene Regulatory Neural Network as a Biocomputing Library of Mathematical Solvers](https://arxiv.org/abs/2509.21598)
*Adrian Ratwatte,Samitha Somathilaka,Thanh Cao,Xu Li,Sasitharan Balasubramaniam*

Main category: cs.ET

TL;DR: 利用GRNN框架将细菌基因表达动态转化为生物计算库，通过子网络搜索算法识别特定数学计算任务的子网络，并评估其鲁棒性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前生物计算方法主要依赖固定逻辑的工程电路，在不同环境条件下稳定性和可靠性有限。

Method: 使用GRNN框架，引入子网络搜索算法识别针对特定数学计算和分类任务的功能子网络，通过基因表达模式评估化学编码输入条件。

Result: 结果表明原生转录机制可用于执行多样化的数学计算和分类任务，同时保持计算稳定性和可靠性。

Conclusion: 原生转录机制可以被利用来执行多样化的数学计算和分类任务，同时保持计算稳定性和可靠性。

Abstract: Current biocomputing approaches predominantly rely on engineered circuits
with fixed logic, offering limited stability and reliability under diverse
environmental conditions. Here, we use the GRNN framework introduced in our
previous work to transform bacterial gene expression dynamics into a
biocomputing library of mathematical solvers. We introduce a sub-GRNN search
algorithm that identifies functional subnetworks tailored to specific
mathematical calculation and classification tasks by evaluating gene expression
patterns across chemically encoded input conditions. Tasks include identifying
Fibonacci numbers, prime numbers, multiplication, and Collatz step counts. The
identified problem-specific sub-GRNNs are then assessed using gene-wise and
collective perturbation, as well as Lyapunov-based stability analysis, to
evaluate robustness and reliability. Our results demonstrate that native
transcriptional machinery can be harnessed to perform diverse mathematical
calculation and classification tasks, while maintaining computing stability and
reliability.

</details>


### [8] [QMill: Representative Quantum Data Generation for Quantum Machine Learning Utility](https://arxiv.org/abs/2509.21622)
*Jason Ludmir,Ian Martin,Nicholas S. DiBrita,Daniel Leeds,Tirthak Patel*

Main category: cs.ET

TL;DR: QMill是一个低深度量子数据生成框架，能够生成纠缠的高质量样本，模拟各种经典和量子分布，以解决量子机器学习中训练数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习在量子数据集上运行时有显著加速潜力，但受到合适训练数据稀缺的阻碍。现有的合成数据生成方法无法捕捉关键的纠缠特性，限制了它们在QML中的实用性。

Method: 引入了QMill框架，这是一个低深度的量子数据生成方法，能够产生纠缠的高质量样本，模拟多样化的经典和量子分布。

Result: QMill框架能够生成具有代表性的量子数据，支持在代表性数据设置下更有效地开发和评估量子机器学习模型。

Conclusion: QMill通过生成高质量的纠缠量子数据，解决了量子机器学习中训练数据稀缺的核心问题，为QML模型的开发和评估提供了更好的数据基础。

Abstract: Quantum machine learning (QML) promises significant speedups, particularly
when operating on quantum datasets. However, its progress is hindered by the
scarcity of suitable training data. Existing synthetic data generation methods
fall short in capturing essential entanglement properties, limiting their
utility for QML. To address this, we introduce QMill, a low-depth quantum data
generation framework that produces entangled, high-quality samples emulating
diverse classical and quantum distributions, enabling more effective
development and evaluation of QML models in representative-data settings.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [9] [Language-in-the-Loop Culvert Inspection on the Erie Canal](https://arxiv.org/abs/2509.21370)
*Yashom Dighe,Yash Turkar,Karthik Dantu*

Main category: cs.RO

TL;DR: VISION是一个端到端的自主检查系统，结合视觉语言模型和约束视角规划，用于运河涵洞的自主检查，无需领域特定微调即可生成专家认可的高分辨率报告。


<details>
  <summary>Details</summary>
Motivation: 传统人工检查运河涵洞存在年龄、几何形状、照明差、天气和难以接近等挑战，需要自动化解决方案来提高检查效率和安全性。

Method: 使用网络级视觉语言模型生成开放词汇的感兴趣区域建议，结合立体深度恢复尺度，通过约束感知的规划器进行重新定位拍摄目标特写。

Result: 在伊利运河涵洞部署的四足机器人上，VISION实现了61.4%的初始感兴趣区域建议与专家一致，经过重新成像后达到80%的一致性。

Conclusion: VISION系统能够将初步假设转化为基于事实的专家对齐发现，为涵洞检查提供了有效的自主解决方案。

Abstract: Culverts on canals such as the Erie Canal, built originally in 1825, require
frequent inspections to ensure safe operation. Human inspection of culverts is
challenging due to age, geometry, poor illumination, weather, and lack of easy
access. We introduce VISION, an end-to-end, language-in-the-loop autonomy
system that couples a web-scale vision-language model (VLM) with constrained
viewpoint planning for autonomous inspection of culverts. Brief prompts to the
VLM solicit open-vocabulary ROI proposals with rationales and confidences,
stereo depth is fused to recover scale, and a planner -- aware of culvert
constraints -- commands repositioning moves to capture targeted close-ups.
Deployed on a quadruped in a culvert under the Erie Canal, VISION closes the
see, decide, move, re-image loop on-board and produces high-resolution images
for detailed reporting without domain-specific fine-tuning. In an external
evaluation by New York Canal Corporation personnel, initial ROI proposals
achieved 61.4\% agreement with subject-matter experts, and final
post-re-imaging assessments reached 80\%, indicating that VISION converts
tentative hypotheses into grounded, expert-aligned findings.

</details>


### [10] [Developing a Mono-Actuated Compliant GeoGami Robot](https://arxiv.org/abs/2509.21445)
*Archie Webster,Lee Skull,Seyed Amir Tafrishi*

Main category: cs.RO

TL;DR: GeoGami是一个软硬混合机器人平台，利用折纸表面实现形状收缩和欠驱动运动，通过单驱动器实现变形和移动。


<details>
  <summary>Details</summary>
Motivation: 解决折纸表面自由度多、需要大量驱动器的问题，通过集成表面柔顺性提高可重复性，开发能够通过形状变化适应不同环境并进行运动的机器人。

Method: 结合折纸表面柔顺性和几何柔顺骨架，设计单驱动器移动平台；开发刚度模型和中央齿轮箱机制；分析替代性线缆驱动方法实现表面变形。

Result: 实现了GeoGami机器人的形状变换和滚动能力，验证了单驱动器驱动变形和运动的可行性。

Conclusion: 该平台为通过形状变化适应不同环境和使用形状变换进行运动的机器人开辟了新能力。

Abstract: This paper presents the design of a new soft-rigid robotic platform,
"GeoGami". We leverage origami surface capabilities to achieve shape
contraction and to support locomotion with underactuated forms. A key challenge
is that origami surfaces have high degrees of freedom and typically require
many actuators; we address repeatability by integrating surface compliance. We
propose a mono-actuated GeoGami mobile platform that combines origami surface
compliance with a geometric compliant skeleton, enabling the robot to transform
and locomote using a single actuator. We demonstrate the robot, develop a
stiffness model, and describe the central gearbox mechanism. We also analyze
alternative cable-driven actuation methods for the skeleton to enable surface
transformation. Finally, we evaluate the GeoGami platform for capabilities,
including shape transformation and rolling. This platform opens new
capabilities for robots that change shape to access different environments and
that use shape transformation for locomotion.

</details>


### [11] [Wall Inspector: Quadrotor Control in Wall-proximity Through Model Compensation](https://arxiv.org/abs/2509.21496)
*Peiwen Yang,Weisong Wen,Runqiu Yang,Yingming Chen,Cheuk Chi Tsang*

Main category: cs.RO

TL;DR: 提出了一种针对四旋翼无人机在近壁环境中受空气动力学吸力影响的解决方案，包括物理吸力模型和吸力补偿模型预测控制框架，显著提升了轨迹跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 四旋翼无人机在近壁城市或室内环境（如检查和搜救任务）中安全运行面临未建模的空气动力学效应挑战，壁面接近产生的复杂涡流会引发不稳定吸力，导致危险振动或碰撞。

Method: 开发了基于物理的吸力模型，明确表征了转子速度和壁面距离的依赖关系；设计了吸力补偿模型预测控制（SC-MPC）框架，通过增强的动力学模型考虑吸力效应，构建为因子图优化问题，整合系统动力学约束、轨迹跟踪目标、控制输入平滑性和执行器物理限制。

Result: 实验验证显示SC-MPC在X轴和Y轴位置控制上分别达到2.1厘米和2.0厘米的均方根误差，相比级联PID控制分别提升74%和79%，相比标准MPC分别提升60%和53%；平均绝对误差指标（X轴1.2厘米，Y轴1.4厘米）同样优于两个基线方法。

Conclusion: 提出的SC-MPC框架有效解决了四旋翼无人机在近壁环境中的空气动力学挑战，显著提高了轨迹跟踪精度和稳定性，为安全操作提供了可靠解决方案，并开源了完整实现以促进社区采用。

Abstract: The safe operation of quadrotors in near-wall urban or indoor environments
(e.g., inspection and search-and-rescue missions) is challenged by unmodeled
aerodynamic effects arising from wall-proximity. It generates complex vortices
that induce destabilizing suction forces, potentially leading to hazardous
vibrations or collisions. This paper presents a comprehensive solution
featuring (1) a physics-based suction force model that explicitly characterizes
the dependency on both rotor speed and wall distance, and (2) a
suction-compensated model predictive control (SC-MPC) framework designed to
ensure accurate and stable trajectory tracking during wall-proximity
operations. The proposed SC-MPC framework incorporates an enhanced dynamics
model that accounts for suction force effects, formulated as a factor graph
optimization problem integrating system dynamics constraints, trajectory
tracking objectives, control input smoothness requirements, and actuator
physical limitations. The suction force model parameters are systematically
identified through extensive experimental measurements across varying
operational conditions. Experimental validation demonstrates SC-MPC's superior
performance, achieving 2.1 cm root mean squared error (RMSE) in X-axis and 2.0
cm RMSE in Y-axis position control - representing 74% and 79% improvements over
cascaded proportional-integral-derivative (PID) control, and 60% and 53%
improvements over standard MPC respectively. The corresponding mean absolute
error (MAE) metrics (1.2 cm X-axis, 1.4 cm Y-axis) similarly outperform both
baselines. The evaluation platform employs a ducted quadrotor design that
provides collision protection while maintaining aerodynamic efficiency. To
facilitate reproducibility and community adoption, we have open-sourced our
complete implementation, available at
https://anonymous.4open.science/r/SC-MPC-6A61.

</details>


### [12] [Effect of Gait Design on Proprioceptive Sensing of Terrain Properties in a Quadrupedal Robot](https://arxiv.org/abs/2509.22065)
*Ethan Fulcher,J. Diego Caporale,Yifeng Zhang,John Ruck,Feifei Qian*

Main category: cs.RO

TL;DR: 本文研究了步态对腿式机器人本体感知地形传感精度的影响，比较了传感导向的爬行步态和运动导向的小跑步态在测量可变形基质强度和纹理方面的能力。


<details>
  <summary>Details</summary>
Motivation: 通过腿式机器人在运动过程中测量地形特性，可以提供前所未有的采样速度和密度，同时能够进入以前因风险过高而无法采样的地形，这对于行星地质勘探具有重要意义。

Method: 在实验室环境中，让机器人使用两种不同步态（Crawl N' Sense和Trot-Walk）在由刚性表面、松散沙子和带合成表面结壳的松散沙子组成的样带上运动，量化每种步态测量基质强度和纹理的能力。

Result: 两种步态都能测量低阻力和高阻力基质之间的强度差异，但运动导向的小跑步态测量值幅度和方差更大。较慢的爬行步态检测表面结壳脆性破裂的准确度显著高于较快的小跑步态。

Conclusion: 研究结果为腿式机器人"运动过程中传感"的步态设计和规划提供了新见解，有助于在其他星球上进行地形侦察和科学测量，增进对其地质和形成过程的理解。

Abstract: In-situ robotic exploration is an important tool for advancing knowledge of
geological processes that describe the Earth and other Planetary bodies. To
inform and enhance operations for these roving laboratories, it is imperative
to understand the terramechanical properties of their environments, especially
for traversing on loose, deformable substrates. Recent research suggested that
legged robots with direct-drive and low-gear ratio actuators can sensitively
detect external forces, and therefore possess the potential to measure terrain
properties with their legs during locomotion, providing unprecedented sampling
speed and density while accessing terrains previously too risky to sample. This
paper explores these ideas by investigating the impact of gait on
proprioceptive terrain sensing accuracy, particularly comparing a
sensing-oriented gait, Crawl N' Sense, with a locomotion-oriented gait,
Trot-Walk. Each gait's ability to measure the strength and texture of
deformable substrate is quantified as the robot locomotes over a laboratory
transect consisting of a rigid surface, loose sand, and loose sand with
synthetic surface crusts. Our results suggest that with both the
sensing-oriented crawling gait and locomotion-oriented trot gait, the robot can
measure a consistent difference in the strength (in terms of penetration
resistance) between the low- and high-resistance substrates; however, the
locomotion-oriented trot gait contains larger magnitude and variance in
measurements. Furthermore, the slower crawl gait can detect brittle ruptures of
the surface crusts with significantly higher accuracy than the faster trot
gait. Our results offer new insights that inform legged robot "sensing during
locomotion" gait design and planning for scouting the terrain and producing
scientific measurements on other worlds to advance our understanding of their
geology and formation.

</details>


### [13] [DroneFL: Federated Learning for Multi-UAV Visual Target Tracking](https://arxiv.org/abs/2509.21523)
*Xiaofan Yu,Yuwei Wu,Katherine Mao,Ye Tian,Vijay Kumar,Tajana Rosing*

Main category: cs.RO

TL;DR: DroneFL是首个专为多无人机目标跟踪设计的联邦学习框架，通过轻量级本地模型、位置不变架构和云端轨迹优化，显著提升了预测精度和跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 多机器人目标跟踪在农业、环境监测等领域很重要，但联邦学习在多无人机跟踪中的应用尚未充分探索，面临计算资源有限、数据异构性强以及轨迹预测与规划紧密耦合等挑战。

Method: 设计轻量级本地模型（冻结YOLO骨干+浅层Transformer），引入位置不变架构和基于高度的自适应实例归一化来缓解数据异构性，云端融合多无人机预测并生成最优轨迹。

Result: 相比分布式非联邦学习框架，DroneFL将预测误差降低6%-83%，跟踪距离减少0.4%-4.6%，在树莓派5上实时运行，平均云端数据速率仅1.56 KBps。

Conclusion: DroneFL成功解决了多无人机目标跟踪中的联邦学习挑战，在保持高效性的同时显著提升了性能，为实际部署提供了可行方案。

Abstract: Multi-robot target tracking is a fundamental problem that requires
coordinated monitoring of dynamic entities in applications such as precision
agriculture, environmental monitoring, disaster response, and security
surveillance. While Federated Learning (FL) has the potential to enhance
learning across multiple robots without centralized data aggregation, its use
in multi-Unmanned Aerial Vehicle (UAV) target tracking remains largely
underexplored. Key challenges include limited onboard computational resources,
significant data heterogeneity in FL due to varying targets and the fields of
view, and the need for tight coupling between trajectory prediction and
multi-robot planning. In this paper, we introduce DroneFL, the first federated
learning framework specifically designed for efficient multi-UAV target
tracking. We design a lightweight local model to predict target trajectories
from sensor inputs, using a frozen YOLO backbone and a shallow transformer for
efficient onboard training. The updated models are periodically aggregated in
the cloud for global knowledge sharing. To alleviate the data heterogeneity
that hinders FL convergence, DroneFL introduces a position-invariant model
architecture with altitude-based adaptive instance normalization. Finally, we
fuse predictions from multiple UAVs in the cloud and generate optimal
trajectories that balance target prediction accuracy and overall tracking
performance. Our results show that DroneFL reduces prediction error by 6%-83%
and tracking distance by 0.4%-4.6% compared to a distributed non-FL framework.
In terms of efficiency, DroneFL runs in real time on a Raspberry Pi 5 and has
on average just 1.56 KBps data rate to the cloud.

</details>


### [14] [Plan2Evolve: LLM Self-Evolution for Improved Planning Capability via Automated Domain Generation](https://arxiv.org/abs/2509.21543)
*Jinbang Huang,Zhiyuan Li,Zhanguang Zhang,Xingyue Quan,Jianye Hao,Yingxue Zhang*

Main category: cs.RO

TL;DR: Plan2Evolve是一个LLM自我进化框架，通过生成规划领域作为推理数据源，将符号规划问题-计划对转化为自然语言推理轨迹，从而提升LLM的规划能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法将规划领域仅视为搜索工具，忽视了其作为可扩展推理数据源的潜力；同时机器人领域的CoT监督依赖昂贵的人工标注数据集。

Method: 基础模型生成规划领域作为引擎，产生符号问题-计划对作为推理轨迹，然后通过自然语言解释转化为扩展的CoT轨迹，使符号规划结构与自然语言推理对齐。

Result: 生成的数据超越了模型内在规划能力，通过微调产生规划增强的LLM，提高了规划成功率、跨任务泛化能力，并降低了推理成本。

Conclusion: Plan2Evolve框架通过自我生成规划数据，有效提升了LLM在机器人任务规划中的性能，实现了符号规划与自然语言推理的显式对齐。

Abstract: Large Language Models (LLMs) have recently shown strong potential in robotic
task planning, particularly through automatic planning domain generation that
integrates symbolic search. Prior approaches, however, have largely treated
these domains as search utilities, with limited attention to their potential as
scalable sources of reasoning data. At the same time, progress in reasoning
LLMs has been driven by chain-of-thought (CoT) supervision, whose application
in robotics remains dependent on costly, human-curated datasets. We propose
Plan2Evolve, an LLM self-evolving framework in which the base model generates
planning domains that serve as engines for producing symbolic problem-plan
pairs as reasoning traces. These pairs are then transformed into extended CoT
trajectories by the same model through natural-language explanations, thereby
explicitly aligning symbolic planning structures with natural language
reasoning. The resulting data extend beyond the model's intrinsic planning
capacity, enabling model fine-tuning that yields a planning-enhanced LLM with
improved planning success, stronger cross-task generalization, and reduced
inference costs.

</details>


### [15] [PL-VIWO2: A Lightweight, Fast and Robust Visual-Inertial-Wheel Odometry Using Points and Lines](https://arxiv.org/abs/2509.21563)
*Zhixin Zhang,Liang Zhao,Pawel Ladosz*

Main category: cs.RO

TL;DR: PL-VIWO2是一个基于滤波器的视觉-惯性-轮式里程计系统，通过整合IMU、轮式编码器和相机，在复杂城市环境中实现长期鲁棒的状态估计。


<details>
  <summary>Details</summary>
Motivation: 视觉里程计在自动驾驶中应用广泛，但在复杂室外城市环境中性能会下降，需要更鲁棒的解决方案。

Method: 提出了三个主要贡献：1）利用2D特征点和线之间几何关系的线特征处理框架；2）基于地面车辆平面运动特性的SE(2)约束SE(3)轮式预积分方法；3）联合使用IMU和轮式测量的高效运动一致性检查来过滤动态特征。

Result: 在蒙特卡洛模拟和公开自动驾驶数据集上的大量实验表明，PL-VIWO2在准确性、效率和鲁棒性方面优于现有最先进方法。

Conclusion: PL-VIWO2系统通过多传感器融合和创新的特征处理方法，在复杂城市环境中实现了优越的里程计性能。

Abstract: Vision-based odometry has been widely adopted in autonomous driving owing to
its low cost and lightweight setup; however, its performance often degrades in
complex outdoor urban environments. To address these challenges, we propose
PL-VIWO2, a filter-based visual-inertial-wheel odometry system that integrates
an IMU, wheel encoder, and camera (supporting both monocular and stereo) for
long-term robust state estimation. The main contributions are: (i) a novel line
feature processing framework that exploits the geometric relationship between
2D feature points and lines, enabling fast and robust line tracking and
triangulation while ensuring real-time performance; (ii) an SE(2)-constrained
SE(3) wheel pre-integration method that leverages the planar motion
characteristics of ground vehicles for accurate wheel updates; and (iii) an
efficient motion consistency check (MCC) that filters out dynamic features by
jointly using IMU and wheel measurements. Extensive experiments on Monte Carlo
simulations and public autonomous driving datasets demonstrate that PL-VIWO2
outperforms state-of-the-art methods in terms of accuracy, efficiency, and
robustness.

</details>


### [16] [Autonomous UAV-Quadruped Docking in Complex Terrains via Active Posture Alignment and Constraint-Aware Control](https://arxiv.org/abs/2509.21571)
*HaoZhe Xu,Cheng Cheng,HongRui Sang,Zhipeng Wang,Qiyong He,Xiuxian Li,Bin He*

Main category: cs.RO

TL;DR: 提出了一种用于GPS拒绝环境下的无人机-四足机器人自主对接框架，通过混合内部模型稳定四足机器人躯干，采用三阶段策略实现无人机安全对接，在复杂地形上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人因频繁姿态变化难以提供稳定着陆平台的问题，实现异构系统在复杂地形中的自主对接能力。

Method: 四足机器人侧使用混合内部模型主动稳定躯干；无人机侧采用三阶段策略：远距离获取、近距离跟踪（结合非奇异快速终端滑模控制器和障碍函数）、终端下降（安全周期机制）。

Result: 在仿真和真实场景中验证成功，能够在高于17厘米的室外楼梯和超过30度的粗糙斜坡上实现对接。

Conclusion: 该框架有效解决了四足机器人平台稳定性问题，实现了在复杂地形中的可靠自主对接。

Abstract: Autonomous docking between Unmanned Aerial Vehicles (UAVs) and ground robots
is essential for heterogeneous systems, yet most existing approaches target
wheeled platforms whose limited mobility constrains exploration in complex
terrains. Quadruped robots offer superior adaptability but undergo frequent
posture variations, making it difficult to provide a stable landing surface for
UAVs. To address these challenges, we propose an autonomous UAV-quadruped
docking framework for GPS-denied environments. On the quadruped side, a Hybrid
Internal Model with Horizontal Alignment (HIM-HA), learned via deep
reinforcement learning, actively stabilizes the torso to provide a level
platform. On the UAV side, a three-phase strategy is adopted, consisting of
long-range acquisition with a median-filtered YOLOv8 detector, close-range
tracking with a constraint-aware controller that integrates a Nonsingular Fast
Terminal Sliding Mode Controller (NFTSMC) and a logarithmic Barrier Function
(BF) to guarantee finite-time error convergence under field-of-view (FOV)
constraints, and terminal descent guided by a Safety Period (SP) mechanism that
jointly verifies tracking accuracy and platform stability. The proposed
framework is validated in both simulation and real-world scenarios,
successfully achieving docking on outdoor staircases higher than 17 cm and
rough slopes steeper than 30 degrees. Supplementary materials and videos are
available at: https://uav-quadruped-docking.github.io.

</details>


### [17] [Real-Time Indoor Object SLAM with LLM-Enhanced Priors](https://arxiv.org/abs/2509.21602)
*Yang Jiao,Yiding Qiu,Henrik I. Christensen*

Main category: cs.RO

TL;DR: 提出了一种利用大型语言模型提供物体几何先验知识的对象级SLAM方法，在稀疏观测条件下通过常识知识约束提升建图精度


<details>
  <summary>Details</summary>
Motivation: 传统对象级SLAM由于观测稀疏导致优化欠约束，而获取常识知识先验通常费时费力且缺乏跨类别泛化能力

Method: 利用LLM提供物体尺寸和方向的几何属性先验，集成到图优化SLAM框架中，特别在初始观测有限阶段发挥作用

Result: 在TUM RGB-D和3RScan数据集上，相比最新基线方法建图精度提升36.8%，并实现实时性能

Conclusion: LLM提供的常识几何先验能有效解决对象级SLAM的稀疏观测问题，显著提升建图精度和实时性能

Abstract: Object-level Simultaneous Localization and Mapping (SLAM), which incorporates
semantic information for high-level scene understanding, faces challenges of
under-constrained optimization due to sparse observations. Prior work has
introduced additional constraints using commonsense knowledge, but obtaining
such priors has traditionally been labor-intensive and lacks generalizability
across diverse object categories. We address this limitation by leveraging
large language models (LLMs) to provide commonsense knowledge of object
geometric attributes, specifically size and orientation, as prior factors in a
graph-based SLAM framework. These priors are particularly beneficial during the
initial phase when object observations are limited. We implement a complete
pipeline integrating these priors, achieving robust data association on sparse
object-level features and enabling real-time object SLAM. Our system, evaluated
on the TUM RGB-D and 3RScan datasets, improves mapping accuracy by 36.8\% over
the latest baseline. Additionally, we present real-world experiments in the
supplementary video, demonstrating its real-time performance.

</details>


### [18] [Generating Stable Placements via Physics-guided Diffusion Models](https://arxiv.org/abs/2509.21664)
*Philippe Nadeau,Miguel Rogel,Ivan Bilić,Ivan Petrović,Jonathan Kelly*

Main category: cs.RO

TL;DR: 提出一种基于扩散模型的稳定物体放置方法，通过将稳定性直接集成到采样过程中，无需额外训练即可生成物理稳定的放置方案。


<details>
  <summary>Details</summary>
Motivation: 解决多物体场景中稳定放置物体的挑战，现有方法依赖仿真引擎或启发式评估，缺乏直接集成稳定性的高效方法。

Method: 使用离线采样规划器收集多模态放置标签，训练扩散模型生成稳定放置。结合几何感知先验和稳定性感知损失，提高采样稳定性。

Result: 在四个基准场景中，物理引导模型生成的放置对强力扰动的鲁棒性提高56%，运行时间减少47%。

Conclusion: 该方法成功将物理稳定性集成到扩散模型中，无需重新训练即可显著提高放置稳定性和效率。

Abstract: Stably placing an object in a multi-object scene is a fundamental challenge
in robotic manipulation, as placements must be penetration-free, establish
precise surface contact, and result in a force equilibrium. To assess
stability, existing methods rely on running a simulation engine or resort to
heuristic, appearance-based assessments. In contrast, our approach integrates
stability directly into the sampling process of a diffusion model. To this end,
we query an offline sampling-based planner to gather multi-modal placement
labels and train a diffusion model to generate stable placements. The diffusion
model is conditioned on scene and object point clouds, and serves as a
geometry-aware prior. We leverage the compositional nature of score-based
generative models to combine this learned prior with a stability-aware loss,
thereby increasing the likelihood of sampling from regions of high stability.
Importantly, this strategy requires no additional re-training or fine-tuning,
and can be directly applied to off-the-shelf models. We evaluate our method on
four benchmark scenes where stability can be accurately computed. Our
physics-guided models achieve placements that are 56% more robust to forceful
perturbations while reducing runtime by 47% compared to a state-of-the-art
geometric method.

</details>


### [19] [Towards Versatile Humanoid Table Tennis: Unified Reinforcement Learning with Prediction Augmentation](https://arxiv.org/abs/2509.21690)
*Muqun Hu,Wenxi Chen,Wenjing Li,Falak Mandali,Zijian He,Renhong Zhang,Praveen Krisna,Katherine Christian,Leo Benaharon,Dizhi Ma,Karthik Ramani,Yan Gu*

Main category: cs.RO

TL;DR: 提出一个强化学习框架，将乒乓球位置观测直接映射到全身关节指令，结合预测信号和物理引导的密集奖励，实现人形机器人乒乓球的端到端控制


<details>
  <summary>Details</summary>
Motivation: 人形机器人乒乓球需要快速感知、主动全身运动和敏捷步法，这些能力在统一控制器中仍然难以实现

Method: 使用强化学习框架，通过轻量级学习预测器估计未来球状态，结合物理基础预测器构建密集奖励，实现端到端学习

Result: 在模拟中达到强性能（命中率≥96%，成功率≥92%），在物理机器人上零样本部署产生协调步法和准确快速回球

Conclusion: 该框架为人形机器人乒乓球提供了一条实用的路径，学习预测器和预测奖励设计对端到端学习至关重要

Abstract: Humanoid table tennis (TT) demands rapid perception, proactive whole-body
motion, and agile footwork under strict timing -- capabilities that remain
difficult for unified controllers. We propose a reinforcement learning
framework that maps ball-position observations directly to whole-body joint
commands for both arm striking and leg locomotion, strengthened by predictive
signals and dense, physics-guided rewards. A lightweight learned predictor, fed
with recent ball positions, estimates future ball states and augments the
policy's observations for proactive decision-making. During training, a
physics-based predictor supplies precise future states to construct dense,
informative rewards that lead to effective exploration. The resulting policy
attains strong performance across varied serve ranges (hit rate $\geq$ 96% and
success rate $\geq$ 92%) in simulations. Ablation studies confirm that both the
learned predictor and the predictive reward design are critical for end-to-end
learning. Deployed zero-shot on a physical Booster T1 humanoid with 23 revolute
joints, the policy produces coordinated lateral and forward-backward footwork
with accurate, fast returns, suggesting a practical path toward versatile,
competitive humanoid TT.

</details>


### [20] [VLBiMan: Vision-Language Anchored One-Shot Demonstration Enables Generalizable Robotic Bimanual Manipulation](https://arxiv.org/abs/2509.21723)
*Huayi Zhou,Kui Jia*

Main category: cs.RO

TL;DR: VLBiMan是一个从单个人类演示中学习可复用技能的双臂操作框架，通过任务感知分解和视觉语言基础实现动态适应，大幅减少演示需求并支持跨平台部署。


<details>
  <summary>Details</summary>
Motivation: 现有方法面临两难：模仿策略学习需要大量演示覆盖任务变化，而模块化方法在动态场景中缺乏灵活性。需要能够从少量人类输入中高效学习并适应现实世界不确定性和多样化体现的系统。

Method: 通过任务感知分解从单个人类示例中提取可复用技能，保留不变基元作为锚点，同时通过视觉语言基础动态调整可适应组件。利用语义解析和几何可行性约束解决场景模糊性，并继承人类混合控制能力。

Result: 实验验证显示：(1)相比模仿基线大幅减少演示需求，(2)通过原子技能拼接实现组合泛化，(3)对新对象和外部干扰具有鲁棒性，(4)支持跨平台技能迁移无需重新训练。

Conclusion: 通过连接人类先验与视觉语言锚定适应，该工作向非结构化环境中实用且通用的双臂操作迈进一步。

Abstract: Achieving generalizable bimanual manipulation requires systems that can learn
efficiently from minimal human input while adapting to real-world uncertainties
and diverse embodiments. Existing approaches face a dilemma: imitation policy
learning demands extensive demonstrations to cover task variations, while
modular methods often lack flexibility in dynamic scenes. We introduce VLBiMan,
a framework that derives reusable skills from a single human example through
task-aware decomposition, preserving invariant primitives as anchors while
dynamically adapting adjustable components via vision-language grounding. This
adaptation mechanism resolves scene ambiguities caused by background changes,
object repositioning, or visual clutter without policy retraining, leveraging
semantic parsing and geometric feasibility constraints. Moreover, the system
inherits human-like hybrid control capabilities, enabling mixed synchronous and
asynchronous use of both arms. Extensive experiments validate VLBiMan across
tool-use and multi-object tasks, demonstrating: (1) a drastic reduction in
demonstration requirements compared to imitation baselines, (2) compositional
generalization through atomic skill splicing for long-horizon tasks, (3)
robustness to novel but semantically similar objects and external disturbances,
and (4) strong cross-embodiment transfer, showing that skills learned from
human demonstrations can be instantiated on different robotic platforms without
retraining. By bridging human priors with vision-language anchored adaptation,
our work takes a step toward practical and versatile dual-arm manipulation in
unstructured settings.

</details>


### [21] [The Turkish Ice Cream Robot: Examining Playful Deception in Social Human-Robot Interactions](https://arxiv.org/abs/2509.21776)
*Hyeonseong Kim,Roy El-Helou,Seungbeen Lee,Sungjoon Choi,Matthew Pan*

Main category: cs.RO

TL;DR: 本文研究了受土耳其冰淇淋小贩启发的游戏性欺骗在机器人交互中的应用，发现这种欺骗能显著提升用户的愉悦感和参与度，但会降低安全感和信任度。


<details>
  <summary>Details</summary>
Motivation: 游戏性欺骗在人类社交互动中很常见，但在人机交互领域研究不足。受土耳其冰淇淋小贩互动方式的启发，探索有界、文化熟悉的欺骗形式如何影响用户信任、愉悦感和参与度。

Method: 设计了一个配备定制末端执行器的机械臂，实现了五种土耳其冰淇淋风格的欺骗策略，通过延迟交接冰淇淋形状物体来模拟欺骗行为。采用混合设计用户研究，涉及91名参与者，评估游戏性欺骗和交互时长对用户体验的影响。

Result: 土耳其冰淇淋风格的欺骗显著提升了用户的愉悦感和参与度，但降低了感知安全性和信任度，表明在多维度方面存在结构性权衡。

Conclusion: 游戏性欺骗可以成为娱乐和参与导向场景下交互机器人的有价值设计策略，但需要慎重考虑其复杂的权衡关系。

Abstract: Playful deception, a common feature in human social interactions, remains
underexplored in Human-Robot Interaction (HRI). Inspired by the Turkish Ice
Cream (TIC) vendor routine, we investigate how bounded, culturally familiar
forms of deception influence user trust, enjoyment, and engagement during
robotic handovers. We design a robotic manipulator equipped with a custom
end-effector and implement five TIC-inspired trick policies that deceptively
delay the handover of an ice cream-shaped object. Through a mixed-design user
study with 91 participants, we evaluate the effects of playful deception and
interaction duration on user experience. Results reveal that TIC-inspired
deception significantly enhances enjoyment and engagement, though reduces
perceived safety and trust, suggesting a structured trade-off across the
multi-dimensional aspects. Our findings demonstrate that playful deception can
be a valuable design strategy for interactive robots in entertainment and
engagement-focused contexts, while underscoring the importance of deliberate
consideration of its complex trade-offs. You can find more information,
including demonstration videos, on
https://hyeonseong-kim98.github.io/turkish-ice-cream-robot/ .

</details>


### [22] [Learning Multi-Skill Legged Locomotion Using Conditional Adversarial Motion Priors](https://arxiv.org/abs/2509.21810)
*Ning Huang,Zhentao Xie,Qinchuan Li*

Main category: cs.RO

TL;DR: 提出基于条件对抗运动先验(CAMP)的多技能学习框架，使四足机器人能从专家演示中高效学习多种运动技能，支持主动控制和技能重用。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以通过单一策略学习多种运动技能且缺乏平滑的技能转换，需要开发能获取多样化技能库的解决方案。

Method: 使用条件对抗运动先验框架，结合新颖的技能判别器和技能条件奖励设计，实现精确的技能重建。

Result: 框架支持多种运动技能的主动控制和重用，为复杂环境中的泛化策略学习提供实用解决方案。

Conclusion: CAMP框架能够有效解决四足机器人多技能学习问题，实现平滑的技能转换和泛化能力。

Abstract: Despite growing interest in developing legged robots that emulate biological
locomotion for agile navigation of complex environments, acquiring a diverse
repertoire of skills remains a fundamental challenge in robotics. Existing
methods can learn motion behaviors from expert data, but they often fail to
acquire multiple locomotion skills through a single policy and lack smooth
skill transitions. We propose a multi-skill learning framework based on
Conditional Adversarial Motion Priors (CAMP), with the aim of enabling
quadruped robots to efficiently acquire a diverse set of locomotion skills from
expert demonstrations. Precise skill reconstruction is achieved through a novel
skill discriminator and skill-conditioned reward design. The overall framework
supports the active control and reuse of multiple skills, providing a practical
solution for learning generalizable policies in complex environments.

</details>


### [23] [Improved Vehicle Maneuver Prediction using Game Theoretic Priors](https://arxiv.org/abs/2509.21873)
*Nishant Doshi*

Main category: cs.RO

TL;DR: 提出一种结合博弈论和传统轨迹分类的车辆行为预测方法，利用Level-k博弈理论模拟车辆间的交互决策，提高变道等复杂行为的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统基于轨迹分类的方法在预测车辆变道等复杂行为时不够准确，需要整合整个场景信息。博弈论能够模拟人类层次化推理过程，捕捉车辆间的交互决策。

Method: 使用Level-k博弈理论建立车辆交互模型，将博弈论评估结果作为先验或与传统运动分类模型结合，通过在线优化求解最合理的车辆行为预测。

Result: 该方法能够更准确地预测车辆变道等复杂行为，为自适应巡航控制等决策系统提供更可靠的预测结果。

Conclusion: 结合博弈论和传统分类模型的方法能够显著提高车辆行为预测的准确性，特别是在复杂交互场景下，有助于提升智能驾驶系统的性能和燃油效率。

Abstract: Conventional maneuver prediction methods use some sort of classification
model on temporal trajectory data to predict behavior of agents over a set time
horizon. Despite of having the best precision and recall, these models cannot
predict a lane change accurately unless they incorporate information about the
entire scene. Level-k game theory can leverage the human-like hierarchical
reasoning to come up with the most rational decisions each agent can make in a
group. This can be leveraged to model interactions between different vehicles
in presence of each other and hence compute the most rational decisions each
agent would make. The result of game theoretic evaluation can be used as a
"prior" or combined with a traditional motion-based classification model to
achieve more accurate predictions. The proposed approach assumes that the
states of the vehicles around the target lead vehicle are known. The module
will output the most rational maneuver prediction of the target vehicle based
on an online optimization solution. These predictions are instrumental in
decision making systems like Adaptive Cruise Control (ACC) or Traxen's
iQ-Cruise further improving the resulting fuel savings.

</details>


### [24] [WAVE: Worm Gear-based Adaptive Variable Elasticity for Decoupling Actuators from External Forces](https://arxiv.org/abs/2509.21878)
*Moses Gladson Selvamuthu,Tomoya Takahashi,Riichiro Tadakuma,Kazutoshi Tanaka*

Main category: cs.RO

TL;DR: WAVE是一种基于蜗轮的可变刚度执行器，通过非反向驱动的蜗轮将驱动电机与外力解耦，实现精确的力传递和通过柔顺性吸收位置差异，同时通过弹簧存储冲击能量实现过载保护。


<details>
  <summary>Details</summary>
Motivation: 开发能够同时调节柔顺性和刚度的机器人操作器，以增强操作安全性和多功能性，特别是在接触密集型任务和挑战性环境中。

Method: 集成非反向驱动蜗轮，将驱动电机与外力解耦；使用弹簧存储弹性能量实现过载保护；通过改变弹簧预压缩长度实现连续关节刚度调节。

Result: 实验验证了刚度模型，在静止状态下即使有外部负载，电机负载也接近零；展示了在配备WAVE的操作器上的应用，成功实现了外力的解耦。

Conclusion: WAVE执行器成功实现了外力解耦，其保护特性使其能够在接触密集型任务中长时间运行，并在挑战性环境中实现稳健的机器人应用。

Abstract: Robotic manipulators capable of regulating both compliance and stiffness
offer enhanced operational safety and versatility. Here, we introduce Worm
Gear-based Adaptive Variable Elasticity (WAVE), a variable stiffness actuator
(VSA) that integrates a non-backdrivable worm gear. By decoupling the driving
motor from external forces using this gear, WAVE enables precise force
transmission to the joint, while absorbing positional discrepancies through
compliance. WAVE is protected from excessive loads by converting impact forces
into elastic energy stored in a spring. In addition, the actuator achieves
continuous joint stiffness modulation by changing the spring's precompression
length. We demonstrate these capabilities, experimentally validate the proposed
stiffness model, show that motor loads approach zero at rest--even under
external loading--and present applications using a manipulator with WAVE. This
outcome showcases the successful decoupling of external forces. The protective
attributes of this actuator allow for extended operation in contact-intensive
tasks, and for robust robotic applications in challenging environments.

</details>


### [25] [SAGE: Scene Graph-Aware Guidance and Execution for Long-Horizon Manipulation Tasks](https://arxiv.org/abs/2509.21928)
*Jialiang Li,Wenzheng Wu,Gaojing Zhang,Yifan Han,Wenzhao Lian*

Main category: cs.RO

TL;DR: SAGE是一个用于长时程操作任务的场景图感知引导与执行框架，通过语义场景图连接高层次任务规划和低层次视觉运动控制，实现鲁棒的任务规划和目标条件操作。


<details>
  <summary>Details</summary>
Motivation: 解决长时程操作任务中高层次符号规划与低层次连续控制之间的鸿沟，现有方法在泛化性和语义推理方面存在局限，图像条件控制方法难以适应未见任务。

Method: 使用语义场景图作为场景状态的结构化表示，包含两个关键组件：基于场景图的任务规划器（使用VLM和LLM解析环境和推理场景状态转换序列），以及解耦的结构化图像编辑流水线（通过图像修复和合成将目标子目标图转换为对应图像）。

Result: 大量实验表明SAGE在不同长时程任务上实现了最先进的性能。

Conclusion: SAGE框架通过场景图有效连接了任务级语义推理和像素级视觉运动控制，在长时程操作任务中表现出色。

Abstract: Successfully solving long-horizon manipulation tasks remains a fundamental
challenge. These tasks involve extended action sequences and complex object
interactions, presenting a critical gap between high-level symbolic planning
and low-level continuous control. To bridge this gap, two essential
capabilities are required: robust long-horizon task planning and effective
goal-conditioned manipulation. Existing task planning methods, including
traditional and LLM-based approaches, often exhibit limited generalization or
sparse semantic reasoning. Meanwhile, image-conditioned control methods
struggle to adapt to unseen tasks. To tackle these problems, we propose SAGE, a
novel framework for Scene Graph-Aware Guidance and Execution in Long-Horizon
Manipulation Tasks. SAGE utilizes semantic scene graphs as a structural
representation for scene states. A structural scene graph enables bridging
task-level semantic reasoning and pixel-level visuo-motor control. This also
facilitates the controllable synthesis of accurate, novel sub-goal images. SAGE
consists of two key components: (1) a scene graph-based task planner that uses
VLMs and LLMs to parse the environment and reason about physically-grounded
scene state transition sequences, and (2) a decoupled structural image editing
pipeline that controllably converts each target sub-goal graph into a
corresponding image through image inpainting and composition. Extensive
experiments have demonstrated that SAGE achieves state-of-the-art performance
on distinct long-horizon tasks.

</details>


### [26] [Learnable Conformal Prediction with Context-Aware Nonconformity Functions for Robotic Planning and Perception](https://arxiv.org/abs/2509.21955)
*Divake Kumar,Sina Tayebati,Francesco Migliarba,Ranganath Krishnan,Amit Ranjan Trivedi*

Main category: cs.RO

TL;DR: 提出了可学习的一致性预测(LCP)方法，通过轻量级神经网络生成上下文感知的不确定性集合，在保持理论保证的同时显著减小预测集大小，提升机器人任务的安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在机器人应用中输出点估计但置信度校准不佳，无法量化新输入、噪声或分布外输入的预测可靠性。传统一致性预测依赖固定非一致性分数，忽略上下文导致区间过于保守或不安全。

Method: 用轻量级神经网络函数替代固定非一致性分数，利用几何、语义和任务特定特征生成上下文感知的不确定性集合，同时保持一致性预测的理论保证。

Result: 在分类任务中预测集大小减少18%，检测区间缩小52%，路径规划成功率从72%提升至91%。在7个基准测试的3个机器人任务中均优于标准CP和集成方法，内存开销仅42KB，推理开销15.9%。

Conclusion: LCP是一种轻量级、高效的方法，适用于资源受限的自主系统，在保持理论保证的同时显著提升预测精度和任务安全性。

Abstract: Deep learning models in robotics often output point estimates with poorly
calibrated confidences, offering no native mechanism to quantify predictive
reliability under novel, noisy, or out-of-distribution inputs. Conformal
prediction (CP) addresses this gap by providing distribution-free coverage
guarantees, yet its reliance on fixed nonconformity scores ignores context and
can yield intervals that are overly conservative or unsafe. We address this
with Learnable Conformal Prediction (LCP), which replaces fixed scores with a
lightweight neural function that leverages geometric, semantic, and
task-specific features to produce context-aware uncertainty sets.
  LCP maintains CP's theoretical guarantees while reducing prediction set sizes
by 18% in classification, tightening detection intervals by 52%, and improving
path planning safety from 72% to 91% success with minimal overhead. Across
three robotic tasks on seven benchmarks, LCP consistently outperforms Standard
CP and ensemble baselines. In classification on CIFAR-100 and ImageNet, it
achieves smaller set sizes (4.7-9.9% reduction) at target coverage. For object
detection on COCO, BDD100K, and Cityscapes, it produces 46-54% tighter bounding
boxes. In path planning through cluttered environments, it improves success to
91.5% with only 4.5% path inflation, compared to 12.2% for Standard CP.
  The method is lightweight (approximately 4.8% runtime overhead, 42 KB memory)
and supports online adaptation, making it well suited to resource-constrained
autonomous systems. Hardware evaluation shows LCP adds less than 1% memory and
15.9% inference overhead, yet sustains 39 FPS on detection tasks while being
7.4 times more energy-efficient than ensembles.

</details>


### [27] [FlowDrive: moderated flow matching with data balancing for trajectory planning](https://arxiv.org/abs/2509.21961)
*Lingguang Wang,Ömer Şahin Taş,Marlon Steiner,Christoph Stiller*

Main category: cs.RO

TL;DR: FlowDrive是一个基于流匹配的轨迹规划器，通过重新加权轨迹模式来解决数据分布不平衡问题，使用条件修正流将噪声直接映射到轨迹分布，并通过调节指导增加轨迹多样性，在nuPlan和interPlan基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 基于学习的规划器对驾驶数据的长尾分布敏感，常见操作主导数据集，而危险或罕见场景稀疏，这种不平衡会使模型偏向频繁情况，在关键场景上性能下降。

Method: 提出FlowDrive流匹配轨迹规划器，学习条件修正流以少量流匹配步骤将噪声直接映射到轨迹分布；引入调节的循环内指导，在流步骤之间注入小扰动以系统增加轨迹多样性同时保持场景一致性。

Result: 在nuPlan和交互重点的interPlan基准测试中，FlowDrive在基于学习的规划器中达到最先进结果，接近基于规则优化的方法；添加调节指导和轻量后处理后，在几乎所有基准分割上都达到整体最先进性能。

Conclusion: 通过重新加权轨迹模式和流匹配方法有效解决了数据不平衡问题，调节指导机制成功增加了轨迹多样性，使FlowDrive在轨迹规划任务中表现出色。

Abstract: Learning-based planners are sensitive to the long-tailed distribution of
driving data. Common maneuvers dominate datasets, while dangerous or rare
scenarios are sparse. This imbalance can bias models toward the frequent cases
and degrade performance on critical scenarios. To tackle this problem, we
compare balancing strategies for sampling training data and find reweighting by
trajectory pattern an effective approach. We then present FlowDrive, a
flow-matching trajectory planner that learns a conditional rectified flow to
map noise directly to trajectory distributions with few flow-matching steps. We
further introduce moderated, in-the-loop guidance that injects small
perturbation between flow steps to systematically increase trajectory diversity
while remaining scene-consistent. On nuPlan and the interaction-focused
interPlan benchmarks, FlowDrive achieves state-of-the-art results among
learning-based planners and approaches methods with rule-based refinements.
After adding moderated guidance and light post-processing (FlowDrive*), it
achieves overall state-of-the-art performance across nearly all benchmark
splits.

</details>


### [28] [Hybrid Diffusion for Simultaneous Symbolic and Continuous Planning](https://arxiv.org/abs/2509.21983)
*Sigmund Hennum Høeg,Aksel Vaaler,Chaoqi Liu,Olav Egeland,Yilun Du*

Main category: cs.RO

TL;DR: 提出一种结合离散符号规划和连续轨迹生成的混合扩散方法，解决长时域任务中生成模型容易混淆行为模式的问题


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的机器人轨迹生成方法在长时域复杂决策任务中表现不佳，容易混淆不同的行为模式导致失败

Method: 提出混合扩散过程，同时生成高层符号规划和连续轨迹，结合离散变量扩散和连续扩散

Result: 该方法显著优于基线模型，支持基于部分或完整符号条件的灵活轨迹合成

Conclusion: 混合扩散方法能有效解决长时域任务中的复杂决策问题，提升机器人轨迹生成的性能

Abstract: Constructing robots to accomplish long-horizon tasks is a long-standing
challenge within artificial intelligence. Approaches using generative methods,
particularly Diffusion Models, have gained attention due to their ability to
model continuous robotic trajectories for planning and control. However, we
show that these models struggle with long-horizon tasks that involve complex
decision-making and, in general, are prone to confusing different modes of
behavior, leading to failure. To remedy this, we propose to augment continuous
trajectory generation by simultaneously generating a high-level symbolic plan.
We show that this requires a novel mix of discrete variable diffusion and
continuous diffusion, which dramatically outperforms the baselines. In
addition, we illustrate how this hybrid diffusion process enables flexible
trajectory synthesis, allowing us to condition synthesized actions on partial
and complete symbolic conditions.

</details>


### [29] [Developing Vision-Language-Action Model from Egocentric Videos](https://arxiv.org/abs/2509.21986)
*Tomoya Yoshida,Shuhei Kurita,Taichi Nishimura,Shinsuke Mori*

Main category: cs.RO

TL;DR: 提出了EgoScaler框架，从原始自我中心视频中提取6DoF物体操作轨迹，构建大规模VLA预训练数据集，显著提升机器人任务性能


<details>
  <summary>Details</summary>
Motivation: 自我中心视频提供了丰富的物体操作线索，相比昂贵的人工遥操作更具可扩展性，但之前的研究依赖额外注释，不清楚能否直接从原始视频训练VLA

Method: 使用EgoScaler框架从四个大规模自我中心视频数据集中提取6DoF物体操作轨迹，自动精炼噪声或不完整的轨迹，构建VLA预训练数据集

Result: 在模拟和真实机器人环境中，使用最先进的π₀架构进行实验：预训练使任务成功率提升20%以上；性能与真实机器人数据集相当；与真实数据结合能进一步提升性能

Conclusion: 自我中心视频是推进VLA研究的有前景且可扩展的资源

Abstract: Egocentric videos capture how humans manipulate objects and tools, providing
diverse motion cues for learning object manipulation. Unlike the costly,
expert-driven manual teleoperation commonly used in training
Vision-Language-Action models (VLAs), egocentric videos offer a scalable
alternative. However, prior studies that leverage such videos for training
robot policies typically rely on auxiliary annotations, such as detailed
hand-pose recordings. Consequently, it remains unclear whether VLAs can be
trained directly from raw egocentric videos. In this work, we address this
challenge by leveraging EgoScaler, a framework that extracts 6DoF object
manipulation trajectories from egocentric videos without requiring auxiliary
recordings. We apply EgoScaler to four large-scale egocentric video datasets
and automatically refine noisy or incomplete trajectories, thereby constructing
a new large-scale dataset for VLA pre-training. Our experiments with a
state-of-the-art $\pi_0$ architecture in both simulated and real-robot
environments yield three key findings: (i) pre-training on our dataset improves
task success rates by over 20\% compared to training from scratch, (ii) the
performance is competitive with that achieved using real-robot datasets, and
(iii) combining our dataset with real-robot data yields further improvements.
These results demonstrate that egocentric videos constitute a promising and
scalable resource for advancing VLA research.

</details>


### [30] [One-DoF Robotic Design of Overconstrained Limbs with Energy-Efficient, Self-Collision-Free Motion](https://arxiv.org/abs/2509.22002)
*Yuping Gu,Bangchao Huang,Haoran Sun,Ronghan Xu,Jiayi Yin,Wei Zhang,Fang Wan,Jia Pan,Chaoyang Song*

Main category: cs.RO

TL;DR: 提出了一种计算设计方法，用于创建单自由度过约束机器人肢体，能够在全周期旋转中实现能量高效且无自碰撞的空间轨迹运动。


<details>
  <summary>Details</summary>
Motivation: 虽然多自由度机器人肢体受自然启发，但单自由度设计具有简单性、鲁棒性、成本效益和效率等优势。过约束机构能够为单自由度系统引入运动多样性，但通常受到全周期运动中自碰撞的限制。

Method: 首先提出了连杆式机器人肢体的几何优化问题，制定了空间轨迹生成的广义公式，通过优化相似性和动态相关指标，并进一步优化过约束连杆的几何形状以确保平滑无碰撞运动。

Result: 通过个性化自动机和仿生六足机器人等实验验证了该方法。采用过约束机器人肢体的六足机器人在前进行走时表现出卓越的能量效率。

Conclusion: 该方法成功实现了单自由度过约束机器人肢体的设计，能够在全周期旋转中实现能量高效且无自碰撞的空间轨迹运动。

Abstract: While it is expected to build robotic limbs with multiple degrees of freedom
(DoF) inspired by nature, a single DoF design remains fundamental, providing
benefits that include, but are not limited to, simplicity, robustness,
cost-effectiveness, and efficiency. Mechanisms, especially those with multiple
links and revolute joints connected in closed loops, play an enabling factor in
introducing motion diversity for 1-DoF systems, which are usually constrained
by self-collision during a full-cycle range of motion. This study presents a
novel computational approach to designing one-degree-of-freedom (1-DoF)
overconstrained robotic limbs for a desired spatial trajectory, while achieving
energy-efficient, self-collision-free motion in full-cycle rotations. Firstly,
we present the geometric optimization problem of linkage-based robotic limbs in
a generalized formulation for self-collision-free design. Next, we formulate
the spatial trajectory generation problem with the overconstrained linkages by
optimizing the similarity and dynamic-related metrics. We further optimize the
geometric shape of the overconstrained linkage to ensure smooth and
collision-free motion driven by a single actuator. We validated our proposed
method through various experiments, including personalized automata and
bio-inspired hexapod robots. The resulting hexapod robot, featuring
overconstrained robotic limbs, demonstrated outstanding energy efficiency
during forward walking.

</details>


### [31] [An Adaptive ICP LiDAR Odometry Based on Reliable Initial Pose](https://arxiv.org/abs/2509.22058)
*Qifeng Wang,Weigang Li,Lei Nie,Xin Xu,Wenping Liu,Zhe Xu*

Main category: cs.RO

TL;DR: 提出了一种基于自适应ICP的LiDAR里程计方法，通过可靠的初始位姿和自适应阈值来提升动态环境下的点云配准精度


<details>
  <summary>Details</summary>
Motivation: 现有ICP方法未考虑初始位姿的可靠性，容易陷入局部最优；缺乏自适应机制难以处理复杂动态环境，导致配准精度下降

Method: 采用基于密度滤波的分布式粗配准获取初始位姿估计，通过与运动预测位姿比较选择可靠初始位姿；结合当前和历史误差动态调整自适应阈值；基于可靠初始位姿和自适应阈值执行点对平面自适应ICP配准

Result: 在公开KITTI数据集上的大量实验表明，该方法优于现有方法，显著提升了LiDAR里程计的精度

Conclusion: 该方法通过可靠的初始位姿和自适应阈值机制，有效解决了ICP方法在动态环境中的配准精度问题，实现了高精度的点云对齐

Abstract: As a key technology for autonomous navigation and positioning in mobile
robots, light detection and ranging (LiDAR) odometry is widely used in
autonomous driving applications. The Iterative Closest Point (ICP)-based
methods have become the core technique in LiDAR odometry due to their efficient
and accurate point cloud registration capability. However, some existing
ICP-based methods do not consider the reliability of the initial pose, which
may cause the method to converge to a local optimum. Furthermore, the absence
of an adaptive mechanism hinders the effective handling of complex dynamic
environments, resulting in a significant degradation of registration accuracy.
To address these issues, this paper proposes an adaptive ICP-based LiDAR
odometry method that relies on a reliable initial pose. First, distributed
coarse registration based on density filtering is employed to obtain the
initial pose estimation. The reliable initial pose is then selected by
comparing it with the motion prediction pose, reducing the initial error
between the source and target point clouds. Subsequently, by combining the
current and historical errors, the adaptive threshold is dynamically adjusted
to accommodate the real-time changes in the dynamic environment. Finally, based
on the reliable initial pose and the adaptive threshold, point-to-plane
adaptive ICP registration is performed from the current frame to the local map,
achieving high-precision alignment of the source and target point clouds.
Extensive experiments on the public KITTI dataset demonstrate that the proposed
method outperforms existing approaches and significantly enhances the accuracy
of LiDAR odometry.

</details>


### [32] [Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation](https://arxiv.org/abs/2509.22093)
*Xiaohuan Pei,Yuxing Chen,Siyu Xu,Yunke Wang,Yuheng Shi,Chang Xu*

Main category: cs.RO

TL;DR: 提出了ADP（动作感知动态剪枝）框架，通过文本驱动的token选择和动作感知轨迹门控，在机器人操作的不同阶段自适应调整视觉token保留比例，显著降低计算成本同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在优化VLA模型推理速度时忽视了机器人操作不同阶段的视觉冗余度差异，特别是在粗粒度操作阶段视觉token冗余度更高，且与动作动态强相关。

Method: 结合文本驱动的token选择和动作感知轨迹门控机制，利用过去运动窗口自适应调整token保留比例，平衡计算效率和感知精度。

Result: 在LIBERO套件和多样化现实场景中，显著降低FLOPs和动作推理延迟（如OpenVLA-OFT上1.35倍加速），同时保持竞争力的成功率（如OpenVLA上25.8%提升）。

Conclusion: ADP为高效机器人策略提供了简单的插件式路径，推进了机器人操作效率和性能的前沿。

Abstract: Robotic manipulation with Vision-Language-Action models requires efficient
inference over long-horizon multi-modal context, where attention to dense
visual tokens dominates computational cost. Existing methods optimize inference
speed by reducing visual redundancy within VLA models, but they overlook the
varying redundancy across robotic manipulation stages. We observe that the
visual token redundancy is higher in coarse manipulation phase than in
fine-grained operations, and is strongly correlated with the action dynamic.
Motivated by this observation, we propose \textbf{A}ction-aware
\textbf{D}ynamic \textbf{P}runing (\textbf{ADP}), a multi-modal pruning
framework that integrates text-driven token selection with action-aware
trajectory gating. Our method introduces a gating mechanism that conditions the
pruning signal on recent action trajectories, using past motion windows to
adaptively adjust token retention ratios in accordance with dynamics, thereby
balancing computational efficiency and perceptual precision across different
manipulation stages. Extensive experiments on the LIBERO suites and diverse
real-world scenarios demonstrate that our method significantly reduces FLOPs
and action inference latency (\textit{e.g.} $1.35 \times$ speed up on
OpenVLA-OFT) while maintaining competitive success rates (\textit{e.g.} 25.8\%
improvements with OpenVLA) compared to baselines, thereby providing a simple
plug-in path to efficient robot policies that advances the efficiency and
performance frontier of robotic manipulation. Our project website is:
\href{https://vla-adp.github.io/}{ADP.com}.

</details>


### [33] [Multi-stage robust nonlinear model predictive control of a lower-limb exoskeleton robot](https://arxiv.org/abs/2509.22120)
*Alireza Aliyari,Gholamreza Vossoughi*

Main category: cs.RO

TL;DR: 提出了一种鲁棒非线性模型预测控制方法（多阶段NMPC），用于控制二自由度外骨骼机器人，通过解决非线性优化问题来处理系统不确定性，显著降低了人机交互力。


<details>
  <summary>Details</summary>
Motivation: 由于外骨骼机器人中人类-机器人系统存在不确定性，传统线性化方法会因机器人动力学的非线性特性而降低性能，需要开发更鲁棒的控制方法。

Method: 采用多阶段非线性模型预测控制（RNMPC），使用多个场景来表示系统不确定性，专注于在摆动阶段最小化人机交互力，特别是在机器人承载未知负载时。

Result: 仿真和实验测试表明，该方法显著提高了鲁棒性，优于非鲁棒NMPC。在2kg未知载荷和外部扰动下，大腿和小腿交互力的RMS值分别减少了77%和94%。

Conclusion: 多阶段NMPC方法能有效处理外骨骼机器人中的不确定性，降低跟踪误差和交互力，为外骨骼控制提供了更鲁棒的解决方案。

Abstract: The use of exoskeleton robots is increasing due to the rising number of
musculoskeletal injuries. However, their effectiveness depends heavily on the
design of control systems. Designing robust controllers is challenging because
of uncertainties in human-robot systems. Among various control strategies,
Model Predictive Control (MPC) is a powerful approach due to its ability to
handle constraints and optimize performance. Previous studies have used
linearization-based methods to implement robust MPC on exoskeletons, but these
can degrade performance due to nonlinearities in the robot's dynamics. To
address this gap, this paper proposes a Robust Nonlinear Model Predictive
Control (RNMPC) method, called multi-stage NMPC, to control a
two-degree-of-freedom exoskeleton by solving a nonlinear optimization problem.
This method uses multiple scenarios to represent system uncertainties. The
study focuses on minimizing human-robot interaction forces during the swing
phase, particularly when the robot carries unknown loads. Simulations and
experimental tests show that the proposed method significantly improves
robustness, outperforming non-robust NMPC. It achieves lower tracking errors
and interaction forces under various uncertainties. For instance, when a 2 kg
unknown payload is combined with external disturbances, the RMS values of thigh
and shank interaction forces for multi-stage NMPC are reduced by 77 and 94
percent, respectively, compared to non-robust NMPC.

</details>


### [34] [DemoGrasp: Universal Dexterous Grasping from a Single Demonstration](https://arxiv.org/abs/2509.22149)
*Haoqi Yuan,Ziye Huang,Ye Wang,Chuan Mao,Chaoyi Xu,Zongqing Lu*

Main category: cs.RO

TL;DR: DemoGrasp是一种简单有效的通用灵巧抓取学习方法，通过编辑单次成功演示轨迹来适应新物体和姿态，在仿真中达到95%成功率，并在真实世界中成功抓取110个未见物体。


<details>
  <summary>Details</summary>
Motivation: 现有的灵巧手抓取方法需要复杂的奖励和课程设计，导致在不同物体上的性能不佳。需要一种简单但有效的通用抓取学习方法。

Method: 从单次成功抓取演示轨迹出发，通过编辑机器人动作来适应新物体：改变手腕姿态决定抓取位置，改变手部关节角度决定抓取方式。将此轨迹编辑建模为单步马尔可夫决策过程，使用强化学习在仿真中并行优化通用策略。

Result: 在仿真中，DemoGrasp在DexGraspNet物体上使用Shadow Hand达到95%成功率，优于之前最先进方法。在六个未见物体数据集上平均成功率达84.6%。通过视觉模仿学习，成功抓取110个真实世界未见物体，包括小而薄的物品。

Conclusion: DemoGrasp展示了从单次演示学习通用灵巧抓取策略的有效性，具有强大的泛化能力，支持RGB和深度输入，并能扩展到语言引导的杂乱场景抓取。

Abstract: Universal grasping with multi-fingered dexterous hands is a fundamental
challenge in robotic manipulation. While recent approaches successfully learn
closed-loop grasping policies using reinforcement learning (RL), the inherent
difficulty of high-dimensional, long-horizon exploration necessitates complex
reward and curriculum design, often resulting in suboptimal solutions across
diverse objects. We propose DemoGrasp, a simple yet effective method for
learning universal dexterous grasping. We start from a single successful
demonstration trajectory of grasping a specific object and adapt to novel
objects and poses by editing the robot actions in this trajectory: changing the
wrist pose determines where to grasp, and changing the hand joint angles
determines how to grasp. We formulate this trajectory editing as a single-step
Markov Decision Process (MDP) and use RL to optimize a universal policy across
hundreds of objects in parallel in simulation, with a simple reward consisting
of a binary success term and a robot-table collision penalty. In simulation,
DemoGrasp achieves a 95% success rate on DexGraspNet objects using the Shadow
Hand, outperforming previous state-of-the-art methods. It also shows strong
transferability, achieving an average success rate of 84.6% across diverse
dexterous hand embodiments on six unseen object datasets, while being trained
on only 175 objects. Through vision-based imitation learning, our policy
successfully grasps 110 unseen real-world objects, including small, thin items.
It generalizes to spatial, background, and lighting changes, supports both RGB
and depth inputs, and extends to language-guided grasping in cluttered scenes.

</details>


### [35] [DHAGrasp: Synthesizing Affordance-Aware Dual-Hand Grasps with Text Instructions](https://arxiv.org/abs/2509.22175)
*Quanzhou Li,Zhonghua Wu,Jingbo Wang,Chen Change Loy,Bo Dai*

Main category: cs.RO

TL;DR: 提出SymOpt管道构建大规模双手抓握数据集，并开发DHAGrasp文本引导的双手抓握生成器，能够为未见过的物体生成语义一致的双手抓握。


<details>
  <summary>Details</summary>
Motivation: 现有抓握数据集主要关注单手交互且语义标注有限，缺乏对双手抓握和物体语义的研究。

Method: 利用现有单手数据集和物体、手部对称性构建大规模双手抓握数据集；提出双阶段设计的DHAGrasp生成器，结合新颖的双手功能表示，能够从少量分割训练数据中有效学习。

Result: 实验表明该方法能生成多样且语义一致的抓握，在抓握质量和未见物体泛化能力上优于强基线方法。

Conclusion: 该方法成功解决了双手抓握数据集稀缺问题，实现了语义感知的双手抓握生成，具有很好的泛化性能。

Abstract: Learning to generate dual-hand grasps that respect object semantics is
essential for robust hand-object interaction but remains largely underexplored
due to dataset scarcity. Existing grasp datasets predominantly focus on
single-hand interactions and contain only limited semantic part annotations. To
address these challenges, we introduce a pipeline, SymOpt, that constructs a
large-scale dual-hand grasp dataset by leveraging existing single-hand datasets
and exploiting object and hand symmetries. Building on this, we propose a
text-guided dual-hand grasp generator, DHAGrasp, that synthesizes Dual-Hand
Affordance-aware Grasps for unseen objects. Our approach incorporates a novel
dual-hand affordance representation and follows a two-stage design, which
enables effective learning from a small set of segmented training objects while
scaling to a much larger pool of unsegmented data. Extensive experiments
demonstrate that our method produces diverse and semantically consistent
grasps, outperforming strong baselines in both grasp quality and generalization
to unseen objects. The project page is at
https://quanzhou-li.github.io/DHAGrasp/.

</details>


### [36] [Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting](https://arxiv.org/abs/2509.22195)
*Asher J. Hancock,Xindi Wu,Lihan Zha,Olga Russakovsky,Anirudha Majumdar*

Main category: cs.RO

TL;DR: VLM2VLA是一种新的视觉语言动作模型训练范式，通过用自然语言表示低级动作来解决预训练和机器人数据之间的分布不匹配问题，使用LoRA微调避免灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 传统方法在视觉语言模型上微调机器人遥操作数据时，会导致模型丧失原有的推理和多模态理解能力，阻碍泛化到新场景、指令跟随和语义理解。

Method: 将低级动作表示为自然语言，使数据分布与VLM预训练语料对齐，然后仅使用低秩适应(LoRA)进行微调，最小化对VLM主干的修改。

Result: 通过广泛的视觉问答研究和800多个真实世界机器人实验，证明VLM2VLA能保持VLM的核心能力，实现零样本泛化到需要开放世界语义推理和多语言指令跟随的新任务。

Conclusion: VLM2VLA通过数据级对齐和最小化架构修改，成功解决了VLA训练中的灾难性遗忘问题，为训练通用策略提供了有效解决方案。

Abstract: Fine-tuning vision-language models (VLMs) on robot teleoperation data to
create vision-language-action (VLA) models is a promising paradigm for training
generalist policies, but it suffers from a fundamental tradeoff: learning to
produce actions often diminishes the VLM's foundational reasoning and
multimodal understanding, hindering generalization to novel scenarios,
instruction following, and semantic understanding. We argue that this
catastrophic forgetting is due to a distribution mismatch between the VLM's
internet-scale pretraining corpus and the robotics fine-tuning data. Inspired
by this observation, we introduce VLM2VLA: a VLA training paradigm that first
resolves this mismatch at the data level by representing low-level actions with
natural language. This alignment makes it possible to train VLAs solely with
Low-Rank Adaptation (LoRA), thereby minimally modifying the VLM backbone and
averting catastrophic forgetting. As a result, the VLM can be fine-tuned on
robot teleoperation data without fundamentally altering the underlying
architecture and without expensive co-training on internet-scale VLM datasets.
Through extensive Visual Question Answering (VQA) studies and over 800
real-world robotics experiments, we demonstrate that VLM2VLA preserves the
VLM's core capabilities, enabling zero-shot generalization to novel tasks that
require open-world semantic reasoning and multilingual instruction following.

</details>


### [37] [MimicDreamer: Aligning Human and Robot Demonstrations for Scalable VLA Training](https://arxiv.org/abs/2509.22199)
*Haoyun Li,Ivan Zhang,Runqi Ouyang,Xiaofeng Wang,Zheng Zhu,Zhiqin Yang,Zhentao Zhang,Boyuan Wang,Chaojun Ni,Wenkang Qin,Xinze Chen,Yun Ye,Guan Huang,Zhenbo Song,Xingang Wang*

Main category: cs.RO

TL;DR: MimicDreamer是一个将人类演示视频转化为机器人可用监督数据的框架，通过视觉、视角和动作对齐来支持策略训练，显著提升VLA模型在真实机器人上的表现。


<details>
  <summary>Details</summary>
Motivation: 收集机器人交互数据成本高昂，而人类演示视频更具可扩展性和成本效益，但存在视角不稳定、视觉差异和运动动态差异等域差距问题。

Method: 提出H2R Aligner进行视觉对齐，使用视频扩散模型生成高保真机器人演示视频；EgoStabilizer进行视角稳定，通过单应性变换规范化第一人称视频；将人手轨迹映射到机器人坐标系，应用约束逆运动学求解器生成可行的关节命令。

Result: 仅使用合成的人类到机器人视频训练的VLA模型在真实机器人上实现了少样本执行；与仅使用真实机器人数据训练的模型相比，在六个代表性操作任务中平均成功率提高了14.7%。

Conclusion: 该方法有效弥合了人类视频与机器人视频之间的域差距，显著提升了VLA模型的泛化能力，证明了人类演示数据在机器人学习中的巨大潜力。

Abstract: Vision Language Action (VLA) models derive their generalization capability
from diverse training data, yet collecting embodied robot interaction data
remains prohibitively expensive. In contrast, human demonstration videos are
far more scalable and cost-efficient to collect, and recent studies confirm
their effectiveness in training VLA models. However, a significant domain gap
persists between human videos and robot-executed videos, including unstable
camera viewpoints, visual discrepancies between human hands and robotic arms,
and differences in motion dynamics. To bridge this gap, we propose
MimicDreamer, a framework that turns fast, low-cost human demonstrations into
robot-usable supervision by jointly aligning vision, viewpoint, and actions to
directly support policy training. For visual alignment, we propose H2R Aligner,
a video diffusion model that generates high-fidelity robot demonstration videos
by transferring motion from human manipulation footage. For viewpoint
stabilization, EgoStabilizer is proposed, which canonicalizes egocentric videos
via homography and inpaints occlusions and distortions caused by warping. For
action alignment, we map human hand trajectories to the robot frame and apply a
constrained inverse kinematics solver to produce feasible, low-jitter joint
commands with accurate pose tracking. Empirically, VLA models trained purely on
our synthesized human-to-robot videos achieve few-shot execution on real
robots. Moreover, scaling training with human data significantly boosts
performance compared to models trained solely on real robot data; our approach
improves the average success rate by 14.7\% across six representative
manipulation tasks.

</details>


### [38] [From Watch to Imagine: Steering Long-horizon Manipulation via Human Demonstration and Future Envisionment](https://arxiv.org/abs/2509.22205)
*Ke Ye,Jiaming Zhou,Yuanfeng Qiu,Jiayi Liu,Shihui Zhou,Kun-Yu Lin,Junwei Liang*

Main category: cs.RO

TL;DR: Super-Mimic是一个分层框架，通过从无脚本的人类演示视频中推断程序意图，实现零样本机器人模仿。它包含人类意图翻译器和未来动态预测器两个模块，显著优于现有零样本方法。


<details>
  <summary>Details</summary>
Motivation: 解决机器人零样本设置下长时程操作任务的泛化问题。当前基于多模态基础的方法通常无法仅从静态视觉输入将高级命令分解为可执行动作序列。

Method: 分层框架：1) 人类意图翻译器(HIT)使用多模态推理解析输入视频，生成语言基础子任务序列；2) 未来动态预测器(FDP)使用生成模型为每个步骤合成物理合理的视频展开。

Result: 在长时程操作任务套件上的广泛实验表明，Super-Mimic显著优于最先进的零样本方法，性能提升超过20%。

Conclusion: 将视频驱动的意图解析与前瞻性动态建模相结合，是开发通用机器人系统的有效策略。

Abstract: Generalizing to long-horizon manipulation tasks in a zero-shot setting
remains a central challenge in robotics. Current multimodal foundation based
approaches, despite their capabilities, typically fail to decompose high-level
commands into executable action sequences from static visual input alone. To
address this challenge, we introduce Super-Mimic, a hierarchical framework that
enables zero-shot robotic imitation by directly inferring procedural intent
from unscripted human demonstration videos. Our framework is composed of two
sequential modules. First, a Human Intent Translator (HIT) parses the input
video using multimodal reasoning to produce a sequence of language-grounded
subtasks. These subtasks then condition a Future Dynamics Predictor (FDP),
which employs a generative model that synthesizes a physically plausible video
rollout for each step. The resulting visual trajectories are dynamics-aware,
explicitly modeling crucial object interactions and contact points to guide the
low-level controller. We validate this approach through extensive experiments
on a suite of long-horizon manipulation tasks, where Super-Mimic significantly
outperforms state-of-the-art zero-shot methods by over 20\%. These results
establish that coupling video-driven intent parsing with prospective dynamics
modeling is a highly effective strategy for developing general-purpose robotic
systems.

</details>


### [39] [Leveraging Large Language Models for Robot-Assisted Learning of Morphological Structures in Preschool Children with Language Vulnerabilities](https://arxiv.org/abs/2509.22287)
*Stina Sundstedt,Mattias Wingren,Susanne Hägglund,Daniel Ventus*

Main category: cs.RO

TL;DR: 开发使用Furhat对话机器人和大型语言模型来帮助有语言障碍的学龄前儿童改善表达性语言技能的应用，通过游戏化方式教授特定形态结构。


<details>
  <summary>Details</summary>
Motivation: 帮助有语言障碍（如发育性语言障碍或移民相关语言挑战）的学龄前儿童，传统方法对教育者和家长要求高，需要精确的语言知识和实时生成各种形态形式。

Method: 开发基于Furhat对话机器人的应用，使用大型语言模型管理游戏玩法、对话、情感响应和轮换，在单词检索游戏"Alias"中与儿童互动，并计划进一步利用LLM生成和传递特定形态目标。

Result: 目前应用已开发完成，使用LLM管理游戏各方面，下一步将扩展LLM能力以在游戏中生成特定形态目标。

Conclusion: 机器人可能在此任务上优于人类，可作为儿童和专业人士的模型和导师，长期目标是创建强大的基于LLM的机器人辅助语言学习干预，能够跨语言教授各种形态结构。

Abstract: Preschool children with language vulnerabilities -- such as developmental
language disorders or immigration related language challenges -- often require
support to strengthen their expressive language skills. Based on the principle
of implicit learning, speech-language therapists (SLTs) typically embed target
morphological structures (e.g., third person -s) into everyday interactions or
game-based learning activities. Educators are recommended by SLTs to do the
same. This approach demands precise linguistic knowledge and real-time
production of various morphological forms (e.g., "Daddy wears these when he
drives to work"). The task becomes even more demanding when educators or parent
also must keep children engaged and manage turn-taking in a game-based
activity. In the TalBot project our multiprofessional team have developed an
application in which the Furhat conversational robot plays the word retrieval
game "Alias" with children to improve language skills. Our application
currently employs a large language model (LLM) to manage gameplay, dialogue,
affective responses, and turn-taking. Our next step is to further leverage the
capacity of LLMs so the robot can generate and deliver specific morphological
targets during the game. We hypothesize that a robot could outperform humans at
this task. Novel aspects of this approach are that the robot could ultimately
serve as a model and tutor for both children and professionals and that using
LLM capabilities in this context would support basic communication needs for
children with language vulnerabilities. Our long-term goal is to create a
robust LLM-based Robot-Assisted Language Learning intervention capable of
teaching a variety of morphological structures across different languages.

</details>


### [40] [IMU-Preintegrated Radar Factors for Asynchronous Radar-LiDAR-Inertial SLAM](https://arxiv.org/abs/2509.22288)
*Johan Hatleskog,Morten Nissov,Kostas Alexis*

Main category: cs.RO

TL;DR: 提出了一种IMU预积分雷达因子方法，通过使用高频惯性数据将最新的LiDAR状态传播到雷达测量时间戳，将节点创建率保持在LiDAR测量频率，相比传统方法减少50%的节点数量，在保持定位精度的同时将优化时间降低56%。


<details>
  <summary>Details</summary>
Motivation: 传统固定滞后雷达-LiDAR-惯性平滑器为每个测量创建一个因子图节点，导致状态创建率翻倍，计算成本高，难以在资源受限硬件上实现实时性能。

Method: 引入IMU预积分雷达因子，利用高频惯性数据将最新LiDAR状态传播到雷达测量时间戳，从而将节点创建率维持在LiDAR测量频率。

Result: 在单板计算机上的实验表明，该方法保持了传统基线的绝对位姿误差，同时将聚合因子图优化时间降低了高达56%。

Conclusion: 提出的IMU预积分雷达因子方法有效降低了计算成本，在资源受限硬件上实现了更好的实时性能，同时保持了定位精度。

Abstract: Fixed-lag Radar-LiDAR-Inertial smoothers conventionally create one factor
graph node per measurement to compensate for the lack of time synchronization
between radar and LiDAR. For a radar-LiDAR sensor pair with equal rates, this
strategy results in a state creation rate of twice the individual sensor
frequencies. This doubling of the number of states per second yields high
optimization costs, inhibiting real-time performance on resource-constrained
hardware. We introduce IMU-preintegrated radar factors that use high-rate
inertial data to propagate the most recent LiDAR state to the radar measurement
timestamp. This strategy maintains the node creation rate at the LiDAR
measurement frequency. Assuming equal sensor rates, this lowers the number of
nodes by 50 % and consequently the computational costs. Experiments on a single
board computer (which has 4 cores each of 2.2 GHz A73 and 2 GHz A53 with 8 GB
RAM) show that our method preserves the absolute pose error of a conventional
baseline while simultaneously lowering the aggregated factor graph optimization
time by up to 56 %.

</details>


### [41] [Beyond Detection -- Orchestrating Human-Robot-Robot Assistance via an Internet of Robotic Things Paradigm](https://arxiv.org/abs/2509.22296)
*Joseph Hunt,Koyo Fujii,Aly Magassouba,Praminda Caleb-Solly*

Main category: cs.RO

TL;DR: 提出基于IoRT的医院防跌倒系统，通过热感测预测患者离床意图，协调多机器人提供个性化主动协助，减少跌倒风险并满足患者需求。


<details>
  <summary>Details</summary>
Motivation: 传统跌倒预防系统存在高误报率且无法解决患者离床的根本需求，需要从被动检测转向主动预防和个性化协助。

Method: 采用IoRT架构，集成隐私保护的热感测模型进行实时离床预测，协调两个机器人代理根据预测意图和患者输入动态响应。

Result: 展示了低分辨率热感测能准确预测离床行为，用户研究和系统误差分析为多代理交互设计提供指导。

Conclusion: 交互式连接机器人系统能超越被动监控，提供及时有意义的协助，创造更安全、响应更快的护理环境。

Abstract: Hospital patient falls remain a critical and costly challenge worldwide.
While conventional fall prevention systems typically rely on post-fall
detection or reactive alerts, they also often suffer from high false positive
rates and fail to address the underlying patient needs that lead to bed-exit
attempts. This paper presents a novel system architecture that leverages the
Internet of Robotic Things (IoRT) to orchestrate human-robot-robot interaction
for proactive and personalized patient assistance. The system integrates a
privacy-preserving thermal sensing model capable of real-time bed-exit
prediction, with two coordinated robotic agents that respond dynamically based
on predicted intent and patient input. This orchestrated response could not
only reduce fall risk but also attend to the patient's underlying motivations
for movement, such as thirst, discomfort, or the need for assistance, before a
hazardous situation arises. Our contributions with this pilot study are
three-fold: (1) a modular IoRT-based framework enabling distributed sensing,
prediction, and multi-robot coordination; (2) a demonstration of low-resolution
thermal sensing for accurate, privacy-preserving preemptive bed-exit detection;
and (3) results from a user study and systematic error analysis that inform the
design of situationally aware, multi-agent interactions in hospital settings.
The findings highlight how interactive and connected robotic systems can move
beyond passive monitoring to deliver timely, meaningful assistance, empowering
safer, more responsive care environments.

</details>


### [42] [RoboView-Bias: Benchmarking Visual Bias in Embodied Agents for Robotic Manipulation](https://arxiv.org/abs/2509.22356)
*Enguang Liu,Siyuan Liang,Liming Lu,Xiyu Zeng,Xiaochun Cao,Aishan Liu,Shuchao Pang*

Main category: cs.RO

TL;DR: 提出了首个专门用于系统量化机器人操作中视觉偏见的基准RoboView-Bias，通过2,127个任务实例评估了三种代表性具身代理，发现所有代理都存在显著视觉偏见，并提出基于语义接地层的缓解策略可将偏见减少约54.5%。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注泛化性和扰动下的鲁棒性，而对视觉偏见的系统量化研究较少，这限制了对感知如何影响决策稳定性的深入理解。

Method: 采用因子隔离原则，利用结构化变体生成框架和感知公平验证协议，创建了2,127个任务实例来稳健测量单个视觉因子及其相互作用引起的偏见。

Result: 评估发现：(i)所有代理都存在显著视觉偏见，相机视角是最关键因素；(ii)代理在高度饱和颜色上成功率最高，表明继承了底层VLM的视觉偏好；(iii)视觉偏见表现出强烈的不对称耦合，视角强烈放大了颜色相关偏见。

Conclusion: 系统分析视觉偏见是开发安全可靠通用具身代理的先决条件，提出的语义接地层缓解策略可显著减少视觉偏见。

Abstract: The safety and reliability of embodied agents rely on accurate and unbiased
visual perception. However, existing benchmarks mainly emphasize generalization
and robustness under perturbations, while systematic quantification of visual
bias remains scarce. This gap limits a deeper understanding of how perception
influences decision-making stability. To address this issue, we propose
RoboView-Bias, the first benchmark specifically designed to systematically
quantify visual bias in robotic manipulation, following a principle of factor
isolation. Leveraging a structured variant-generation framework and a
perceptual-fairness validation protocol, we create 2,127 task instances that
enable robust measurement of biases induced by individual visual factors and
their interactions. Using this benchmark, we systematically evaluate three
representative embodied agents across two prevailing paradigms and report three
key findings: (i) all agents exhibit significant visual biases, with camera
viewpoint being the most critical factor; (ii) agents achieve their highest
success rates on highly saturated colors, indicating inherited visual
preferences from underlying VLMs; and (iii) visual biases show strong,
asymmetric coupling, with viewpoint strongly amplifying color-related bias.
Finally, we demonstrate that a mitigation strategy based on a semantic
grounding layer substantially reduces visual bias by approximately 54.5\% on
MOKA. Our results highlight that systematic analysis of visual bias is a
prerequisite for developing safe and reliable general-purpose embodied agents.

</details>


### [43] [Learning-Based Collaborative Control for Bi-Manual Tactile-Reactive Grasping](https://arxiv.org/abs/2509.22421)
*Leonel Giacobbe,Jingdao Chen,Chuangchuang Sun*

Main category: cs.RO

TL;DR: 提出了一种基于学习的触觉反应多智能体模型预测控制器，用于抓取不同软硬度和形状的物体，解决了现有单智能体系统在抓取易碎、可变形和大重物体时的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前大多数抓取系统主要针对刚性物体设计，在处理需要实时反馈的易碎或可变形材料时性能显著下降。同时，触觉反应抓取系统通常只关注单个智能体，限制了抓取和操纵大型、重物的能力。

Method: 使用两个Gelsight Mini触觉传感器实时提取物体纹理和刚度信息，通过触觉反馈估计接触动力学和物体柔顺性。采用基于学习的多智能体MPC控制器，在闭环中利用触觉编码预测抓取稳定性并相应调整力和位置。

Result: 通过大量实验验证，该方法在实现和维持对不同尺寸和刚度物体的稳定抓取方面，成功率优于独立的PD和MPC基线方法。

Conclusion: 结合触觉传感和基于学习的多智能体MPC，为复杂环境中的协作抓取提供了鲁棒、智能的解决方案，显著提升了多智能体系统的能力。

Abstract: Grasping is a core task in robotics with various applications. However, most
current implementations are primarily designed for rigid items, and their
performance drops considerably when handling fragile or deformable materials
that require real-time feedback. Meanwhile, tactile-reactive grasping focuses
on a single agent, which limits their ability to grasp and manipulate large,
heavy objects. To overcome this, we propose a learning-based, tactile-reactive
multi-agent Model Predictive Controller (MPC) for grasping a wide range of
objects with different softness and shapes, beyond the capabilities of
preexisting single-agent implementations. Our system uses two Gelsight Mini
tactile sensors [1] to extract real-time information on object texture and
stiffness. This rich tactile feedback is used to estimate contact dynamics and
object compliance in real time, enabling the system to adapt its control policy
to diverse object geometries and stiffness profiles. The learned controller
operates in a closed loop, leveraging tactile encoding to predict grasp
stability and adjust force and position accordingly. Our key technical
contributions include a multi-agent MPC formulation trained on real contact
interactions, a tactile-data driven method for inferring grasping states, and a
coordination strategy that enables collaborative control. By combining tactile
sensing and a learning-based multi-agent MPC, our method offers a robust,
intelligent solution for collaborative grasping in complex environments,
significantly advancing the capabilities of multi-agent systems. Our approach
is validated through extensive experiments against independent PD and MPC
baselines. Our pipeline outperforms the baselines regarding success rates in
achieving and maintaining stable grasps across objects of varying sizes and
stiffness.

</details>


### [44] [An Ontology for Unified Modeling of Tasks, Actions, Environments, and Capabilities in Personal Service Robotics](https://arxiv.org/abs/2509.22434)
*Margherita Martorana,Francesca Urgese,Ilaria Tiddi,Stefan Schlobach*

Main category: cs.RO

TL;DR: 提出了OntoBOT本体，统一表示任务、动作、环境和机器人能力，支持服务机器人的上下文感知推理和任务导向执行。


<details>
  <summary>Details</summary>
Motivation: 现有服务机器人解决方案通常与特定平台紧密耦合，导致孤立、硬编码的系统，限制了互操作性、可重用性和知识共享。现有本体如SOMA和DOLCE专注于特定领域，未能充分捕捉环境、动作、机器人能力和系统级集成之间的连接。

Method: 扩展现有本体，提出OntoBOT本体，提供任务、动作、环境和能力的统一表示。通过评估四个具体代理（TIAGo、HSR、UR3、Stretch）的能力问题来验证其通用性。

Result: OntoBOT支持服务机器人中的上下文感知推理、任务导向执行和知识共享，展示了跨不同机器人平台的通用性。

Conclusion: OntoBOT本体为服务机器人提供了一个统一的表示框架，解决了现有解决方案的互操作性和知识共享限制，支持形式化推理和跨平台应用。

Abstract: Personal service robots are increasingly used in domestic settings to assist
older adults and people requiring support. Effective operation involves not
only physical interaction but also the ability to interpret dynamic
environments, understand tasks, and choose appropriate actions based on
context. This requires integrating both hardware components (e.g. sensors,
actuators) and software systems capable of reasoning about tasks, environments,
and robot capabilities. Frameworks such as the Robot Operating System (ROS)
provide open-source tools that help connect low-level hardware with
higher-level functionalities. However, real-world deployments remain tightly
coupled to specific platforms. As a result, solutions are often isolated and
hard-coded, limiting interoperability, reusability, and knowledge sharing.
Ontologies and knowledge graphs offer a structured way to represent tasks,
environments, and robot capabilities. Existing ontologies, such as the
Socio-physical Model of Activities (SOMA) and the Descriptive Ontology for
Linguistic and Cognitive Engineering (DOLCE), provide models for activities,
spatial relationships, and reasoning structures. However, they often focus on
specific domains and do not fully capture the connection between environment,
action, robot capabilities, and system-level integration. In this work, we
propose the Ontology for roBOts and acTions (OntoBOT), which extends existing
ontologies to provide a unified representation of tasks, actions, environments,
and capabilities. Our contributions are twofold: (1) we unify these aspects
into a cohesive ontology to support formal reasoning about task execution, and
(2) we demonstrate its generalizability by evaluating competency questions
across four embodied agents - TIAGo, HSR, UR3, and Stretch - showing how
OntoBOT enables context-aware reasoning, task-oriented execution, and knowledge
sharing in service robotics.

</details>


### [45] [UnderwaterVLA: Dual-brain Vision-Language-Action architecture for Autonomous Underwater Navigation](https://arxiv.org/abs/2509.22441)
*Zhangyuan Wang,Yunpeng Zhu,Yuqi Yan,Xiaoyuan Tian,Xinhao Shao,Meixuan Li,Weikun Li,Guangsheng Su,Weicheng Cui,Dixia Fan*

Main category: cs.RO

TL;DR: UnderwaterVLA是一个用于自主水下导航的新框架，通过整合多模态基础模型和具身智能系统，解决了水下操作中的挑战。


<details>
  <summary>Details</summary>
Motivation: 水下操作面临流体动力扰动、有限通信带宽和浑浊水域感知退化等困难，需要更智能的导航解决方案。

Method: 采用双脑架构分离高级任务推理与低级反应控制；首次将视觉-语言-动作模型应用于水下机器人；使用流体动力学模型预测控制方案实时补偿流体效应。

Result: 现场测试显示，UnderwaterVLA在视觉条件退化时减少了导航误差，任务完成率比基线高出19%至27%。

Conclusion: 通过减少对水下特定训练数据的依赖并提高跨环境适应性，UnderwaterVLA为下一代智能自主水下航行器提供了可扩展且经济高效的路径。

Abstract: This paper presents UnderwaterVLA, a novel framework for autonomous
underwater navigation that integrates multimodal foundation models with
embodied intelligence systems. Underwater operations remain difficult due to
hydrodynamic disturbances, limited communication bandwidth, and degraded
sensing in turbid waters. To address these challenges, we introduce three
innovations. First, a dual-brain architecture decouples high-level mission
reasoning from low-level reactive control, enabling robust operation under
communication and computational constraints. Second, we apply
Vision-Language-Action(VLA) models to underwater robotics for the first time,
incorporating structured chain-of-thought reasoning for interpretable
decision-making. Third, a hydrodynamics-informed Model Predictive Control(MPC)
scheme compensates for fluid effects in real time without costly task-specific
training. Experimental results in field tests show that UnderwaterVLA reduces
navigation errors in degraded visual conditions while maintaining higher task
completion by 19% to 27% over baseline. By minimizing reliance on
underwater-specific training data and improving adaptability across
environments, UnderwaterVLA provides a scalable and cost-effective path toward
the next generation of intelligent AUVs.

</details>


### [46] [Uncertainty-Aware Multi-Robot Task Allocation With Strongly Coupled Inter-Robot Rewards](https://arxiv.org/abs/2509.22469)
*Ben Rossano,Jaein Lim,Jonathan P. How*

Main category: cs.RO

TL;DR: 提出一种面向异构机器人团队的任务分配算法，在任务需求不确定的环境中使用概率分布建模需求，通过市场机制优化团队目标并处理机器人间的耦合奖励。


<details>
  <summary>Details</summary>
Motivation: 解决异构机器人在任务需求不确定环境中的高效分配问题，避免资源浪费同时预防任务失败。

Method: 使用概率分布建模任务需求，采用基于市场的方法优化团队目标，显式捕获机器人间的耦合奖励，提供多项式时间解决方案。

Result: 与基准算法对比实验证明该方法的有效性，同时揭示了在去中心化环境中处理耦合奖励的挑战。

Conclusion: 该方法能够有效处理异构机器人在不确定环境中的任务分配，通过互补技能配置主动缓解任务失败风险。

Abstract: This paper proposes a task allocation algorithm for teams of heterogeneous
robots in environments with uncertain task requirements. We model these
requirements as probability distributions over capabilities and use this model
to allocate tasks such that robots with complementary skills naturally position
near uncertain tasks, proactively mitigating task failures without wasting
resources. We introduce a market-based approach that optimizes the joint team
objective while explicitly capturing coupled rewards between robots, offering a
polynomial-time solution in decentralized settings with strict communication
assumptions. Comparative experiments against benchmark algorithms demonstrate
the effectiveness of our approach and highlight the challenges of incorporating
coupled rewards in a decentralized formulation.

</details>


### [47] [Ontological foundations for contrastive explanatory narration of robot plans](https://arxiv.org/abs/2509.22493)
*Alberto Olivares-Alarcos,Sergi Foix,Júlia Borràs,Gerard Canal,Guillem Alenyà*

Main category: cs.RO

TL;DR: 提出了一种新的本体模型和算法，用于比较竞争性计划之间的差异，使机器人能够解释选择某个计划的原因。


<details>
  <summary>Details</summary>
Motivation: 确保人工智能决策的相互理解对于建立可信赖的人机交互至关重要，机器人需要能够做出合理决策并在需要时向人类解释。

Method: 首先提出一个新颖的本体模型来形式化和推理竞争计划之间的差异，然后开发了一种新算法，利用计划间的分歧知识来构建对比性叙述。

Result: 通过实证评估，观察到该解释方法在性能上超越了基线方法。

Conclusion: 该方法能够有效支持机器人解释其决策过程，特别是在比较不同计划时提供有意义的对比性解释。

Abstract: Mutual understanding of artificial agents' decisions is key to ensuring a
trustworthy and successful human-robot interaction. Hence, robots are expected
to make reasonable decisions and communicate them to humans when needed. In
this article, the focus is on an approach to modeling and reasoning about the
comparison of two competing plans, so that robots can later explain the
divergent result. First, a novel ontological model is proposed to formalize and
reason about the differences between competing plans, enabling the
classification of the most appropriate one (e.g., the shortest, the safest, the
closest to human preferences, etc.). This work also investigates the
limitations of a baseline algorithm for ontology-based explanatory narration.
To address these limitations, a novel algorithm is presented, leveraging
divergent knowledge between plans and facilitating the construction of
contrastive narratives. Through empirical evaluation, it is observed that the
explanations excel beyond the baseline method.

</details>


### [48] [HELIOS: Hierarchical Exploration for Language-grounded Interaction in Open Scenes](https://arxiv.org/abs/2509.22498)
*Katrina Ashton,Chahyon Ku,Shrey Shah,Wen Jiang,Kostas Daniilidis,Bernadette Bucher*

Main category: cs.RO

TL;DR: HELIOS是一个用于语言指定移动操作任务的分层场景表示方法，在部分观察的新环境中实现了最先进的拾取放置性能，并能零样本迁移到真实世界。


<details>
  <summary>Details</summary>
Motivation: 解决在部分观察的新环境中执行语言指定移动操作任务时面临的挑战：场景部分可见、语言指令到部分观察场景的语义基础、以及主动更新场景知识。

Method: 构建包含导航相关语义和占据信息的2D地图，同时主动构建任务相关对象的3D高斯表示，融合多层表示中的观察，并显式建模每个对象检测的多视角一致性。

Result: 在Habitat模拟器的OVMM基准测试中取得最先进结果，并在真实世界办公室环境中使用Spot机器人成功演示，无需额外数据即可迁移。

Conclusion: HELIOS通过分层场景表示和平衡探索与利用的搜索目标，有效解决了复杂场景中语言指定移动操作任务的挑战，并展示了零样本迁移到真实世界的能力。

Abstract: Language-specified mobile manipulation tasks in novel environments
simultaneously face challenges interacting with a scene which is only partially
observed, grounding semantic information from language instructions to the
partially observed scene, and actively updating knowledge of the scene with new
observations. To address these challenges, we propose HELIOS, a hierarchical
scene representation and associated search objective to perform language
specified pick and place mobile manipulation tasks. We construct 2D maps
containing the relevant semantic and occupancy information for navigation while
simultaneously actively constructing 3D Gaussian representations of
task-relevant objects. We fuse observations across this multi-layered
representation while explicitly modeling the multi-view consistency of the
detections of each object. In order to efficiently search for the target
object, we formulate an objective function balancing exploration of unobserved
or uncertain regions with exploitation of scene semantic information. We
evaluate HELIOS on the OVMM benchmark in the Habitat simulator, a pick and
place benchmark in which perception is challenging due to large and complex
scenes with comparatively small target objects. HELIOS achieves
state-of-the-art results on OVMM. As our approach is zero-shot, HELIOS can also
transfer to the real world without requiring additional data, as we illustrate
by demonstrating it in a real world office environment on a Spot robot.

</details>


### [49] [An Intention-driven Lane Change Framework Considering Heterogeneous Dynamic Cooperation in Mixed-traffic Environment](https://arxiv.org/abs/2509.22550)
*Xiaoyun Qiu,Haichao Liu,Yue Pan,Jun Ma,Xinhu Zheng*

Main category: cs.RO

TL;DR: 提出了一种意图驱动的车道变换框架，通过识别人类驾驶风格、合作感知决策和协调运动规划，在混合交通环境中实现安全高效的车道变换。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶车辆与人类驾驶车辆混合的交通环境中，不可预测的意图和异质行为使得安全高效的车道变换极具挑战性。现有方法往往过度简化这些交互，假设统一的模式。

Method: 使用在NGSIM数据集上训练的深度学习分类器实时识别人类驾驶风格；通过内在和交互组件计算合作分数来估计周围驾驶员的意图；结合行为克隆和逆强化学习进行决策；集成模型预测控制和IRL意图推理生成轨迹。

Result: 实验显示该模型达到94.2%的准确率和94.3%的F1分数，在车道变换识别方面比基于规则和基于学习的基线方法高出4-15%。

Conclusion: 结果表明建模驾驶员异质性的益处，并展示了该框架在复杂交通环境中推进情境感知和类人自动驾驶的潜力。

Abstract: In mixed-traffic environments, where autonomous vehicles (AVs) interact with
diverse human-driven vehicles (HVs), unpredictable intentions and heterogeneous
behaviors make safe and efficient lane change maneuvers highly challenging.
Existing methods often oversimplify these interactions by assuming uniform
patterns. We propose an intention-driven lane change framework that integrates
driving-style recognition, cooperation-aware decision-making, and coordinated
motion planning. A deep learning classifier trained on the NGSIM dataset
identifies human driving styles in real time. A cooperation score with
intrinsic and interactive components estimates surrounding drivers' intentions
and quantifies their willingness to cooperate with the ego vehicle.
Decision-making combines behavior cloning with inverse reinforcement learning
to determine whether a lane change should be initiated. For trajectory
generation, model predictive control is integrated with IRL-based intention
inference to produce collision-free and socially compliant maneuvers.
Experiments show that the proposed model achieves 94.2\% accuracy and 94.3\%
F1-score, outperforming rule-based and learning-based baselines by 4-15\% in
lane change recognition. These results highlight the benefit of modeling
inter-driver heterogeneity and demonstrate the potential of the framework to
advance context-aware and human-like autonomous driving in complex traffic
environments.

</details>


### [50] [MINT-RVAE: Multi-Cues Intention Prediction of Human-Robot Interaction using Human Pose and Emotion Information from RGB-only Camera Data](https://arxiv.org/abs/2509.22573)
*Farida Mohsen,Ali Safa*

Main category: cs.RO

TL;DR: 提出了一种仅使用RGB输入的帧级精度人机交互意图预测方法，通过MINT-RVAE合成序列生成和新的损失函数解决类别不平衡问题，在AUROC指标上达到0.95的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多依赖多模态输入（如RGB-D），而仅使用RGB输入可以降低成本并实现更快的机器人响应。真实世界HRI数据集中的类别不平衡问题会阻碍模型训练和泛化。

Method: 提出RGB-only管道进行帧级意图预测，引入MINT-RVAE合成序列生成方法，配合新的损失函数和训练策略来增强模型在样本外数据上的泛化能力。

Result: 在AUROC指标上达到0.95的SOTA性能，优于之前工作的0.90-0.912，仅需RGB输入且支持精确的帧级起始预测。

Conclusion: 该方法在仅使用RGB输入的情况下实现了优越的人机交互意图检测性能，并公开了新的帧级标注数据集以支持未来研究。

Abstract: Efficiently detecting human intent to interact with ubiquitous robots is
crucial for effective human-robot interaction (HRI) and collaboration. Over the
past decade, deep learning has gained traction in this field, with most
existing approaches relying on multimodal inputs, such as RGB combined with
depth (RGB-D), to classify time-sequence windows of sensory data as interactive
or non-interactive. In contrast, we propose a novel RGB-only pipeline for
predicting human interaction intent with frame-level precision, enabling faster
robot responses and improved service quality. A key challenge in intent
prediction is the class imbalance inherent in real-world HRI datasets, which
can hinder the model's training and generalization. To address this, we
introduce MINT-RVAE, a synthetic sequence generation method, along with new
loss functions and training strategies that enhance generalization on
out-of-sample data. Our approach achieves state-of-the-art performance (AUROC:
0.95) outperforming prior works (AUROC: 0.90-0.912), while requiring only RGB
input and supporting precise frame onset prediction. Finally, to support future
research, we openly release our new dataset with frame-level labeling of human
interaction intent.

</details>


### [51] [EgoDemoGen: Novel Egocentric Demonstration Generation Enables Viewpoint-Robust Manipulation](https://arxiv.org/abs/2509.22578)
*Yuan Xu,Jiabing Yang,Xiaofeng Wang,Yixiang Chen,Zheng Zhu,Bowen Fang,Guan Huang,Xinze Chen,Yun Ye,Qiang Zhang,Peiyan Li,Xiangnan Wu,Kai Wang,Bing Zhan,Shuo Lu,Jing Liu,Nianfeng Liu,Yan Huang,Liang Wang*

Main category: cs.RO

TL;DR: EgoDemoGen框架通过生成配对的新的自我中心视角演示来解决模仿学习策略在自我中心视角变化下的性能下降问题，显著提升了机器人在标准和新视角下的操作成功率。


<details>
  <summary>Details</summary>
Motivation: 模仿学习策略在机器人操作中表现良好，但在单一自我中心视角训练下，面对自我中心视角变化时性能会下降。

Method: 提出EgoDemoGen框架，通过重新定位动作到新自我中心帧，并使用生成视频修复模型EgoViewTransfer合成对应的自我中心观察视频。EgoViewTransfer基于预训练视频生成模型，采用自监督双重重投影策略进行微调。

Result: 在模拟环境中，使用EgoDemoGen生成的新自我中心演示训练后，标准视角成功率绝对提升17.0%，新视角提升17.7%；在真实机器人上，绝对提升分别为18.3%和25.8%。

Conclusion: EgoDemoGen为自我中心视角鲁棒的机器人操作提供了一条实用路径，且随着生成演示比例增加，性能持续提升。

Abstract: Imitation learning based policies perform well in robotic manipulation, but
they often degrade under *egocentric viewpoint shifts* when trained from a
single egocentric viewpoint. To address this issue, we present **EgoDemoGen**,
a framework that generates *paired* novel egocentric demonstrations by
retargeting actions in the novel egocentric frame and synthesizing the
corresponding egocentric observation videos with proposed generative video
repair model **EgoViewTransfer**, which is conditioned by a novel-viewpoint
reprojected scene video and a robot-only video rendered from the retargeted
joint actions. EgoViewTransfer is finetuned from a pretrained video generation
model using self-supervised double reprojection strategy. We evaluate
EgoDemoGen on both simulation (RoboTwin2.0) and real-world robot. After
training with a mixture of EgoDemoGen-generated novel egocentric demonstrations
and original standard egocentric demonstrations, policy success rate improves
**absolutely** by **+17.0%** for standard egocentric viewpoint and by
**+17.7%** for novel egocentric viewpoints in simulation. On real-world robot,
the **absolute** improvements are **+18.3%** and **+25.8%**. Moreover,
performance continues to improve as the proportion of EgoDemoGen-generated
demonstrations increases, with diminishing returns. These results demonstrate
that EgoDemoGen provides a practical route to egocentric viewpoint-robust
robotic manipulation.

</details>


### [52] [WoW: Towards a World omniscient World model Through Embodied Interaction](https://arxiv.org/abs/2509.22642)
*Xiaowei Chi,Peidong Jia,Chun-Kai Fan,Xiaozhu Ju,Weishi Mi,Kevin Zhang,Zhiyuan Qin,Wanxin Tian,Kuangzhi Ge,Hao Li,Zezhong Qian,Anthony Chen,Qiang Zhou,Yueru Jia,Jiaming Liu,Yong Dai,Qingpo Wuwu,Chengyu Bai,Yu-Kai Wang,Ying Li,Lizhang Chen,Yong Bao,Zhiyuan Jiang,Jiacheng Zhu,Kai Tang,Ruichuan An,Yulin Luo,Qiuxuan Feng,Siyuan Zhou,Chi-min Chan,Chengkai Hou,Wei Xue,Sirui Han,Yike Guo,Shanghang Zhang,Jian Tang*

Main category: cs.RO

TL;DR: 提出了WoW，一个基于200万机器人交互轨迹训练的140亿参数生成世界模型，证明了大规模真实世界交互对于AI发展物理直觉的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前视频模型（如Sora）依赖被动观察，难以理解物理因果关系。假设真实的物理直觉必须基于与真实世界的大量因果丰富交互。

Method: 训练140亿参数的WoW生成世界模型，使用SOPHIA系统通过视觉语言模型评估DiT生成输出并迭代优化语言指令，配合逆动力学模型将精炼计划转化为可执行机器人动作。

Result: WoW在物理一致性和因果推理的新基准WoWBench上达到最先进性能，在物理因果关系、碰撞动力学和物体持久性方面表现出色。

Conclusion: 大规模真实世界交互是发展AI物理直觉的基石，模型、数据和基准将开源。

Abstract: Humans develop an understanding of intuitive physics through active
interaction with the world. This approach is in stark contrast to current video
models, such as Sora, which rely on passive observation and therefore struggle
with grasping physical causality. This observation leads to our central
hypothesis: authentic physical intuition of the world model must be grounded in
extensive, causally rich interactions with the real world. To test this
hypothesis, we present WoW, a 14-billion-parameter generative world model
trained on 2 million robot interaction trajectories. Our findings reveal that
the model's understanding of physics is a probabilistic distribution of
plausible outcomes, leading to stochastic instabilities and physical
hallucinations. Furthermore, we demonstrate that this emergent capability can
be actively constrained toward physical realism by SOPHIA, where
vision-language model agents evaluate the DiT-generated output and guide its
refinement by iteratively evolving the language instructions. In addition, a
co-trained Inverse Dynamics Model translates these refined plans into
executable robotic actions, thus closing the imagination-to-action loop. We
establish WoWBench, a new benchmark focused on physical consistency and causal
reasoning in video, where WoW achieves state-of-the-art performance in both
human and autonomous evaluation, demonstrating strong ability in physical
causality, collision dynamics, and object permanence. Our work provides
systematic evidence that large-scale, real-world interaction is a cornerstone
for developing physical intuition in AI. Models, data, and benchmarks will be
open-sourced.

</details>


### [53] [VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search](https://arxiv.org/abs/2509.22643)
*Wenkai Guo,Guanxing Lu,Haoyuan Deng,Zhenyu Wu,Yansong Tang,Ziwei Wang*

Main category: cs.RO

TL;DR: VLA-Reasoner是一个插件框架，通过测试时扩展为现成的VLA模型提供预见未来状态的能力，解决了VLA在长时程任务中因增量偏差而表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型(VLAs)在通用机器人操作任务中表现良好，但仅限于预测短视的下一步动作，在长时程轨迹任务中会因增量偏差而表现不佳。

Method: 提出VLA-Reasoner框架，通过世界模型采样并推演可能的动作轨迹来生成未来状态，使用蒙特卡洛树搜索(MCTS)提高搜索效率，引入基于核密度估计(KDE)的置信度采样机制，以及离线奖励塑造策略来评估中间状态。

Result: 在模拟器和真实世界中的广泛实验表明，VLA-Reasoner相比最先进的VLA模型取得了显著改进。

Conclusion: 该方法为机器人操作的可扩展测试时计算提供了一条潜在路径。

Abstract: Vision-Language-Action models (VLAs) achieve strong performance in general
robotic manipulation tasks by scaling imitation learning. However, existing
VLAs are limited to predicting short-sighted next-action, which struggle with
long-horizon trajectory tasks due to incremental deviations. To address this
problem, we propose a plug-in framework named VLA-Reasoner that effectively
empowers off-the-shelf VLAs with the capability of foreseeing future states via
test-time scaling. Specifically, VLA-Reasoner samples and rolls out possible
action trajectories where involved actions are rationales to generate future
states via a world model, which enables VLA-Reasoner to foresee and reason
potential outcomes and search for the optimal actions. We further leverage
Monte Carlo Tree Search (MCTS) to improve search efficiency in large action
spaces, where stepwise VLA predictions seed the root. Meanwhile, we introduce a
confidence sampling mechanism based on Kernel Density Estimation (KDE), to
enable efficient exploration in MCTS without redundant VLA queries. We evaluate
intermediate states in MCTS via an offline reward shaping strategy, to score
predicted futures and correct deviations with long-term feedback. We conducted
extensive experiments in both simulators and the real world, demonstrating that
our proposed VLA-Reasoner achieves significant improvements over the
state-of-the-art VLAs. Our method highlights a potential pathway toward
scalable test-time computation of robotic manipulation.

</details>


### [54] [Pixel Motion Diffusion is What We Need for Robot Control](https://arxiv.org/abs/2509.22652)
*E-Ro Nguyen,Yichi Zhang,Kanchana Ranasinghe,Xiang Li,Michael S. Ryoo*

Main category: cs.RO

TL;DR: DAWN是一个基于扩散模型的统一机器人控制框架，通过结构化像素运动表示连接高层运动意图和底层机器人动作，在CALVIN和MetaWorld基准测试中达到最先进水平，并展示了可靠的现实世界迁移能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人控制中高层运动意图与底层动作之间的连接问题，以及实现可扩展和鲁棒的机器人学习。

Method: 使用扩散过程建模高层和底层控制器，采用结构化像素运动表示，构建完全可训练的端到端系统，具有可解释的中间运动抽象。

Result: 在CALVIN基准测试中达到最先进结果，展示了强大的多任务性能，在MetaWorld上验证了有效性，仅需最小微调即可实现可靠的现实世界迁移。

Conclusion: 将扩散建模与运动中心表示相结合，为可扩展和鲁棒的机器人学习提供了强大的基准方法。

Abstract: We present DAWN (Diffusion is All We Need for robot control), a unified
diffusion-based framework for language-conditioned robotic manipulation that
bridges high-level motion intent and low-level robot action via structured
pixel motion representation. In DAWN, both the high-level and low-level
controllers are modeled as diffusion processes, yielding a fully trainable,
end-to-end system with interpretable intermediate motion abstractions. DAWN
achieves state-of-the-art results on the challenging CALVIN benchmark,
demonstrating strong multi-task performance, and further validates its
effectiveness on MetaWorld. Despite the substantial domain gap between
simulation and reality and limited real-world data, we demonstrate reliable
real-world transfer with only minimal finetuning, illustrating the practical
viability of diffusion-based motion abstractions for robotic control. Our
results show the effectiveness of combining diffusion modeling with
motion-centric representations as a strong baseline for scalable and robust
robot learning. Project page: https://nero1342.github.io/DAWN/

</details>


### [55] [See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation](https://arxiv.org/abs/2509.22653)
*Chih Yao Hu,Yang-Sen Lin,Yuna Lee,Chih-Hai Su,Jie-Ying Lee,Shr-Ruei Tsai,Chin-Yang Lin,Kuan-Wen Chen,Tsung-Wei Ke,Yu-Lun Liu*

Main category: cs.RO

TL;DR: SPF是一个基于视觉语言模型的免训练航空视觉语言导航框架，将动作预测视为2D空间定位任务，通过分解语言指令为2D航点，实现无人机在动态环境中的闭环控制导航。


<details>
  <summary>Details</summary>
Motivation: 现有基于VLM的方法将动作预测视为文本生成任务，但作者认为航空视觉语言导航的动作预测更适合作为2D空间定位任务来处理，以实现更精确的导航控制。

Method: SPF利用VLM将模糊语言指令分解为输入图像上的迭代2D航点标注，结合预测的行驶距离，将2D航点转换为3D位移向量作为无人机动作指令，并自适应调整行驶距离以提高导航效率。

Result: 在DRL仿真基准测试中，SPF比之前最佳方法绝对提升了63%，在真实世界评估中也大幅优于强基线方法，并展现出对不同VLM的显著泛化能力。

Conclusion: SPF通过将动作预测重新定义为2D空间定位任务，实现了高效、通用的航空视觉语言导航，在仿真和真实环境中都表现出色，具有很好的泛化性。

Abstract: We present See, Point, Fly (SPF), a training-free aerial vision-and-language
navigation (AVLN) framework built atop vision-language models (VLMs). SPF is
capable of navigating to any goal based on any type of free-form instructions
in any kind of environment. In contrast to existing VLM-based approaches that
treat action prediction as a text generation task, our key insight is to
consider action prediction for AVLN as a 2D spatial grounding task. SPF
harnesses VLMs to decompose vague language instructions into iterative
annotation of 2D waypoints on the input image. Along with the predicted
traveling distance, SPF transforms predicted 2D waypoints into 3D displacement
vectors as action commands for UAVs. Moreover, SPF also adaptively adjusts the
traveling distance to facilitate more efficient navigation. Notably, SPF
performs navigation in a closed-loop control manner, enabling UAVs to follow
dynamic targets in dynamic environments. SPF sets a new state of the art in DRL
simulation benchmark, outperforming the previous best method by an absolute
margin of 63%. In extensive real-world evaluations, SPF outperforms strong
baselines by a large margin. We also conduct comprehensive ablation studies to
highlight the effectiveness of our design choice. Lastly, SPF shows remarkable
generalization to different VLMs. Project page: https://spf-web.pages.dev

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [56] [A Crime/S.I.R. optimal control problem](https://arxiv.org/abs/2509.21406)
*Mariana Álvarez,Alexander Alegría,Andrés Rivera,Sebastián Pedersen*

Main category: eess.SY

TL;DR: 本文提出基于控制理论的数学模型，用于制定最优公共政策以最小化犯罪活动的减少和控制成本。


<details>
  <summary>Details</summary>
Motivation: 研究旨在确定最优的公共干预政策组合，以最低经济成本最小化犯罪率，特别关注卡利社会最弱势群体的机会创造和长期安全。

Method: 使用SIR型动态系统建模犯罪行为的社会经济影响，并作为成本函数的约束条件。应用最优控制理论和变分法分析预防政策的最优组合。

Result: 通过最优控制理论分析，预防性政策（如社区和社会凝聚力项目）预计对减少犯罪产生显著积极影响。

Conclusion: 在资源有限的情况下，基于控制理论的数学模型能够为政府制定最优犯罪控制策略提供理论支持，实现成本效益最优的公共政策。

Abstract: This paper presents and discusses a mathematical model inspired by control
theory to derive optimal public policies for minimizing costs associated with
the reduction and control of criminal activity in a population. Specifically,
we analyze the optimal control problem \begin{equation*} \min G(u_1, u_2, u_3)
= \int_{0}^{t_{\text{F}}} \left( I(t) - R(t) + \frac{B_1}{2} u_1^2(t) +
\frac{B_2}{2} u_2^2(t) + \frac{B_3}{2} u_3^2(t) \right) \, dt. \end{equation*}
where $I=I(t)$ and $R=R(t)$ satisfies the system of equations \begin{equation*}
\left\{ \begin{aligned} \dot{S} &= \Lambda - (1-u_1)SI - \mu S +
((1+u_3)\gamma_2)I + \rho \Omega R,\\ \dot{I} &= (1-u_1)SI - (\mu + \delta_1)I
- ((1+u_2)\gamma_1)I - ((1+u_3)\gamma_2)I + (1-\Omega)\rho R,\\ \dot{R} &=
((1+u_2)\gamma_1)I - (\mu + \delta_2 + \rho)R. \end{aligned} \right.
\end{equation*} Our approach assumes that the social and economic effects of
criminal behavior can be modeled by a dynamic SIR-type system, which serves as
a constraint on a cost functional associated with the strategies implemented by
government and law enforcement authorities to reduce criminal behavior. Using
optimal control theory, the proposed controls, i.e., preventive policies (such
as community and social cohesion programs), are expected to have a significant
and positive impact on crime reduction, generating opportunities for the most
disadvantaged sectors of Cali society and contributing to long-term security.
Given that resources to address this problem are limited, this research aims to
determine an optimal combination of public interventions and policies that
minimize criminality at the lowest possible economic cost, using an SIR model,
tools from variational calculus, and optimal control theory.

</details>


### [57] [Quaternionic Pole Placement via Companion Forms and the Ackermann Formula](https://arxiv.org/abs/2509.21425)
*Michael Sebek*

Main category: eess.SY

TL;DR: 提出了基于伴随形式和Ackermann公式的四元数系统状态反馈极点配置扩展方法


<details>
  <summary>Details</summary>
Motivation: 扩展经典极点配置方法到四元数系统，解决四元数LTI模型的极点配置问题

Method: 使用伴随形式和Ackermann公式，定义伴随多项式，通过右特征值相似类表征谱，证明可控坐标中的系数匹配设计

Result: 推导出适用于实目标多项式的坐标无关Ackermann增益表达式，并通过示例验证了正确性、实用性和数值简洁性

Conclusion: 成功将极点配置方法扩展到四元数系统，提供了有效的设计工具并明确了适用范围和限制

Abstract: We present an extension of state-feedback pole placement for quaternionic
systems, based on companion forms and the Ackermann formula. For controllable
single-input quaternionic LTI models, we define a companion polynomial that
right-annihilates its companion matrix, characterize spectra via
right-eigenvalue similarity classes, and prove coefficient-matching design in
controllable coordinates. We then derive a coordinate-free Ackermann gain
expression valid for real target polynomials, and state its scope and
limitations. Short examples demonstrate correctness, practical use, and
numerical simplicity.

</details>


### [58] [Mitigation of Active Power Oscillation in Multi-VSG Grids: An Impedance-Based Perspective](https://arxiv.org/abs/2509.21642)
*Junjie Xiao,Lu Wang,Xiong Du,Pedro Rodriguez,Zian Qin*

Main category: eess.SY

TL;DR: 该论文提出了一种物理直观的RLC等效电路模型来解释逆变器主导电力系统中主动功率振荡的根源，并基于此开发了两种模式特定的抑制策略：孤岛模式下的基于图论的阻抗控制，以及并网模式下的自适应惯性和阻尼控制。


<details>
  <summary>Details</summary>
Motivation: 逆变器主导电力系统中多个虚拟同步发电机控制的变流器之间经常出现主动功率振荡，威胁系统稳定性和保护协调。现有方法依赖系统参数先验知识、阻尼性能有限或模型复杂缺乏物理可解释性，难以实际应用。

Method: 首先引入RLC等效电路模型，将惯性、阻尼和馈线阻抗分别映射到电容、电阻和电感元件，揭示变流器间不匹配导致LC谐振的机理。基于此提出两种抑制策略：孤岛模式下基于图论的阻抗控制确保无功功率按比例分配；并网模式下采用带前馈滤波的自适应惯性和阻尼控制重塑暂态功率动态。

Result: 通过广泛仿真和实时硬件在环实验验证，所提方法能有效抑制振荡，增强多变流器电力系统的鲁棒性。

Conclusion: 提出的RLC等效电路模型为理解主动功率振荡提供了物理直观的解释，两种模式特定的抑制策略在不同运行模式下都能有效提升系统稳定性，具有实际应用价值。

Abstract: Active power oscillations frequently arise in inverter-dominated power
systems with multiple converters operating under Virtual Synchronous Generator
control, posing risks to system stability and protection coordination. While
various mitigation strategies have been proposed, many rely on prior knowledge
of system parameters, offer limited damping performance, or involve complex
models that lack physical interpretability, making them difficult to apply in
practice. To address these challenges, this paper first introduces a physically
intuitive RLC equivalent circuit model to explain the root causes of APOs in
both stand-alone and grid-connected modes. By mapping inertia, damping, and
feeder impedance to capacitive, resistive, and inductive elements,
respectively, the model reveals how mismatches among converters lead to
inter-unit oscillations characterized by LC resonance. Building on this
insight, we propose two mode-specific mitigation strategies: in SA mode, a
graph theory based impedance control ensures proportional reactive power
sharing and effectively suppresses APOs; and in GC mode, adaptive inertia and
damping control with feedforward filtering is designed to reshape transient
power dynamics while preserving frequency stability. The proposed methods are
validated through extensive simulations and real-time hardware-in-the-loop
experiments, demonstrating their effectiveness in suppressing oscillations and
enhancing the robustness of multi-converter power systems.

</details>


### [59] [NEO-Grid: A Neural Approximation Framework for Optimization and Control in Distribution Grids](https://arxiv.org/abs/2509.21668)
*Mohamad Chehade,Hao Zhu*

Main category: eess.SY

TL;DR: NEO-Grid是一个基于学习的统一框架，用于分布式电网的电压无功优化和控制，使用神经网络替代传统功率流模型，通过深度均衡模型实现闭环控制。


<details>
  <summary>Details</summary>
Motivation: 分布式能源资源的兴起给现代配电网带来电压稳定性挑战，传统线性近似方法在动态分散运行条件下效果有限。

Method: 使用分段线性ReLU网络替代传统线性近似来捕捉功率注入与电压幅值的非线性关系，采用深度均衡模型建模电压与逆变器响应的递归交互，通过隐式微分进行高效训练。

Result: 在IEEE 33总线系统上的评估表明，NEO-Grid在优化和控制场景中相比标准线性和启发式基准方法显著提高了电压调节性能。

Conclusion: NEO-Grid为配电网中基于学习的电压调节提供了一个可扩展、准确且可解释的解决方案。

Abstract: The rise of distributed energy resources (DERs) is reshaping modern
distribution grids, introducing new challenges in attaining voltage stability
under dynamic and decentralized operating conditions. This paper presents
NEO-Grid, a unified learning-based framework for volt-var optimization (VVO)
and volt-var control (VVC) that leverages neural network surrogates for power
flow and deep equilibrium models (DEQs) for closed-loop control. Our method
replaces traditional linear approximations with piecewise-linear ReLU networks
trained to capture the nonlinear relationship between power injections and
voltage magnitudes. For control, we model the recursive interaction between
voltage and inverter response using DEQs, allowing direct fixed-point
computation and efficient training via implicit differentiation. We evaluated
NEO-Grid on the IEEE 33-bus system, demonstrating that it significantly
improves voltage regulation performance compared to standard linear and
heuristic baselines in both optimization and control settings. Our results
establish NEO-Grid as a scalable, accurate, and interpretable solution for
learning-based voltage regulation in distribution grids.

</details>


### [60] [On Suboptimal Safety-Critical Tracking Controller Design](https://arxiv.org/abs/2509.21726)
*Yazdan Batmani,Saber Omidi*

Main category: eess.SY

TL;DR: 提出基于状态依赖Riccati方程的安全关键最优轨迹跟踪框架，通过嵌入障碍状态同时确保安全性和跟踪要求，支持实时实现。


<details>
  <summary>Details</summary>
Motivation: 解决非线性系统中安全性和跟踪要求可能冲突的问题，开发能同时满足这两个目标的控制器。

Method: 使用状态依赖Riccati方程方法，将障碍状态嵌入系统动力学，提出两种控制器设计：单障碍状态和多障碍状态方法，分别用于整体安全约束和个体约束调整。

Result: 仿真和实验验证表明，该控制器在机械系统和移动机器人避障场景中能持续保持安全并实现轨迹跟踪，在电缆驱动并联机器人上展示了实际应用效果。

Conclusion: 所提出的安全SDRE控制器为安全关键控制任务提供了有效的解决方案，具有良好的实时实现能力和实际应用价值。

Abstract: This paper proposes a novel framework for safety-critical optimal trajectory
tracking in nonlinear systems based on the state-dependent Riccati equation
(SDRE) methodology. By embedding barrier states into the system dynamics, the
proposed strategy simultaneously ensures safety and tracking requirements, even
in scenarios where these objectives may be inherently conflicting. A discounted
pseudo-quadratic cost function is formulated to achieve a suboptimal trade-off
between tracking accuracy, control effort, and safety objective. We present two
distinct controller designs: one utilizing a single barrier state to enforce
overall safety constraints, and another employing multiple barrier states to
individually tuning the system's conservatism with respect to each safety
constraint, providing enhanced flexibility in tuning the system's conservatism
toward individual constraints. We establish sufficient conditions to ensure the
solvability of the associated Riccati equations. The proposed safe controller
is well-suited for real-time implementation in practical systems, given its
reasonable computational requirements and compatibility with widely available
embedded microprocessors. This is supported by simulation studies involving a
mechanical system and a mobile robot collision avoidance scenario, where the
safe SDRE controller consistently maintained safety while achieving trajectory
tracking objectives in challenging conditions. Additionally, experimental
results on a cable-driven parallel robot further demonstrate the practical
applicability and effectiveness of the proposed method in real-world control
tasks.

</details>


### [61] [Reinforcement Learning Based Traffic Signal Design to Minimize Queue Lengths](https://arxiv.org/abs/2509.21745)
*Anirud Nandakumar,Chayan Banerjee,Lelitha Devi Vanajakshi*

Main category: eess.SY

TL;DR: 提出基于强化学习的自适应交通信号控制框架，使用PPO算法最小化排队长度，在SUMO模拟器中相比传统方法减少29%平均排队长度


<details>
  <summary>Details</summary>
Motivation: 传统交通信号控制方法难以处理动态交通模式，需要更智能的自适应控制方案来缓解拥堵、减少延误和污染

Method: 使用强化学习（PPO算法），通过多种状态表示方法（扩展状态空间、自编码器表示、K-Planes表示）处理随机交通条件

Result: 在SUMO模拟器中表现优于传统方法和常规RL方法，最佳配置相比Webster方法减少约29%平均排队长度

Conclusion: 基于排队的奖励方法有效，展示了可扩展自适应城市交通管理的潜力

Abstract: Efficient traffic signal control (TSC) is crucial for reducing congestion,
travel delays, pollution, and for ensuring road safety. Traditional approaches,
such as fixed signal control and actuated control, often struggle to handle
dynamic traffic patterns. In this study, we propose a novel adaptive TSC
framework that leverages Reinforcement Learning (RL), using the Proximal Policy
Optimization (PPO) algorithm, to minimize total queue lengths across all signal
phases. The challenge of efficiently representing highly stochastic traffic
conditions for an RL controller is addressed through multiple state
representations, including an expanded state space, an autoencoder
representation, and a K-Planes-inspired representation. The proposed algorithm
has been implemented using the Simulation of Urban Mobility (SUMO) traffic
simulator and demonstrates superior performance over both traditional methods
and other conventional RL-based approaches in reducing queue lengths. The best
performing configuration achieves an approximately 29% reduction in average
queue lengths compared to the traditional Webster method. Furthermore,
comparative evaluation of alternative reward formulations demonstrates the
effectiveness of the proposed queue-based approach, showcasing the potential
for scalable and adaptive urban traffic management.

</details>


### [62] [Optimized Control of Duplex Networks](https://arxiv.org/abs/2509.21767)
*Haoyu Zheng,Xizhe Zhang*

Main category: eess.SY

TL;DR: 提出了针对双层网络的通用最小联合驱动集（MinUDS）问题，开发了CLAP-S算法来寻找能同时控制两个层的最小驱动节点集，显著减少了所需驱动节点数量和计算时间。


<details>
  <summary>Details</summary>
Motivation: 现实世界复杂系统常建模为多层网络，但现有网络控制理论主要关注单层网络。对多层网络分别控制会导致驱动节点冗余，增加成本和复杂性。

Method: 提出了最短跨层增广路径搜索（CLAP-S）算法，引入跨层增广路径（CLAP）概念，高效探索控制配置的组合空间，通过迭代重新对齐每层的最小驱动集来最大化它们的重叠。

Result: CLAP-S在合成网络和真实多层系统上始终优于基线方法，显著减少了所需驱动节点数量，并将计算时间降低了一个数量级。

Conclusion: 这项工作为多层网络中的控制策略优化提供了一个强大、通用的工具，能够在不同领域实现更经济的干预。

Abstract: Many real-world complex systems can be modeled as multiplex networks, where
each layer represents a distinct set of interactions among the same entities.
Controlling such systems-steering them toward desired states using external
inputs-is crucial across many domains. However, existing network control theory
largely focuses on single-layer networks, and applying separate controls to
each layer of a multiplex system often leads to redundant sets of driver nodes,
increasing cost and complexity.
  To address this challenge, we formulate the Universal Minimum Union Driver
Set (MinUDS) problem for duplex networks. The goal is to find the smallest set
of driver nodes that can simultaneously control both layers.
  We propose a novel algorithm, Shortest Cross-Layer Augmenting Path Search
(CLAP-S). This method introduces the concept of a Cross-Layer Augmenting Path
(CLAP) and efficiently explores the combinatorial space of control
configurations. CLAP-S iteratively realigns each layer's Minimum Driver Set
(MDS) to maximize their overlap. We prove the algorithm's global optimality and
demonstrate its efficiency on both synthetic networks and real-world multiplex
systems.
  The results show that CLAP-S consistently outperforms baseline approaches by
significantly reducing the number of required driver nodes and cutting
computational time by an order of magnitude. This work provides a powerful,
general-purpose tool for optimizing control strategies in multi-layer networks,
enabling more economical interventions in diverse fields.

</details>


### [63] [A Parallel Ultra-Low Power Silent Speech Interface based on a Wearable, Fully-dry EMG Neckband](https://arxiv.org/abs/2509.21964)
*Fiona Meier,Giusy Spacone,Sebastian Frey,Luca Benini,Andrea Cossettini*

Main category: eess.SY

TL;DR: 开发了一种可穿戴、完全干燥、超低功耗的肌电系统，集成在纺织颈带中，用于无声语音识别，在发声和无声发音条件下分别达到87%和68%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 开发舒适、非侵入式的可穿戴系统，用于无声语音识别，以实现在日常生活中的实用应用。

Method: 基于BioGAP-Ultra平台构建14通道全差分肌电系统，集成到纺织颈带中，采用5折交叉验证评估性能，并引入会话间变异性模拟日常使用条件。

Result: 在发声和无声发音条件下分别达到87±3%和68±3%的平均分类准确率；在会话间变异性测试中，留一会话准确率分别为64±18%和54±7%。

Conclusion: 该方法具有鲁棒性，展示了能量高效的无声语音解码的潜力。

Abstract: We present a wearable, fully-dry, and ultra-low power EMG system for silent
speech recognition, integrated into a textile neckband to enable comfortable,
non-intrusive use. The system features 14 fully-differential EMG channels and
is based on the BioGAP-Ultra platform for ultra-low power (22 mW) biosignal
acquisition and wireless transmission. We evaluate its performance on eight
speech commands under both vocalized and silent articulation, achieving average
classification accuracies of 87$\pm$3% and 68$\pm$3% respectively, with a
5-fold CV approach. To mimic everyday-life conditions, we introduce
session-to-session variability by repositioning the neckband between sessions,
achieving leave-one-session-out accuracies of 64$\pm$18% and 54$\pm$7% for the
vocalized and silent experiments, respectively. These results highlight the
robustness of the proposed approach and the promise of energy-efficient
silent-speech decoding.

</details>


### [64] [A Preliminary Assessment of Shipboard Power System Architectures for LVDC Integration](https://arxiv.org/abs/2509.22567)
*D. Roncagliolo,M. Gallo,D. Kaza,F. D'Agostino,A. Chiarelli,F. Silvestro*

Main category: eess.SY

TL;DR: 对三种舰船电网拓扑结构进行初步比较评估：传统MVAC-LVAC径向配电加LVDC段、全LVDC径向配电和区域LVDC配电。


<details>
  <summary>Details</summary>
Motivation: 低压直流段在电网架构中的应用正在成为海军领域有前景的设计选择。

Method: 使用现有MVAC-LVAC船舶电力系统作为参考，分析三种不同电网拓扑结构，包括同步发电机、推进电机、储能系统单元、额外推进负载和脉冲功率负载等典型元素。

Result: 利用五个关键性能指标进行分析：重量、体积、技术成熟度、平均系统中断持续时间指数和脉冲功率负载中断指数。

Conclusion: 该研究为舰船电力系统架构选择提供了初步比较评估框架。

Abstract: The adoption of low-voltage direct current sections within grid architectures
is emerging as a promising design option in the naval sector. This paper
presents a preliminary comparative assessment of three different grid
topologies, using an existing MVAC-LVAC shipboard power system as a reference:
a conventional MVAC-LVAC radial distribution with an additional LVDC section, a
full LVDC radial distribution and a zonal LVDC distribution. Each architecture
includes typical elements such as synchronous generators, propulsion motors,
energy storage system units, extra propulsive loads, and pulse power loads. The
analysis exploits five key performance indicators: weight, volume, technology
readiness level, average system interruption duration index, and pulsed power
loads interruption index.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [65] [Message passing for epidemiological interventions on networks with loops](https://arxiv.org/abs/2509.21596)
*Erik Weis,Laurent Hébert-Dufresne,Jean-Gabriel Young*

Main category: cs.SI

TL;DR: 提出了基于邻域消息传递(NMP)框架的改进算法，用于更准确地估计网络传播模型中的爆发规模，并应用于干预设计问题。


<details>
  <summary>Details</summary>
Motivation: 传统消息传递方法在真实世界网络上倾向于高估爆发规模，导致预测不准确和干预措施失效，需要改进算法以获得更可靠的估计。

Method: 使用邻域消息传递(NMP)框架进行流行病学计算，改进传统消息传递方法，提高爆发规模估计的准确性。

Result: 改进的NMP算法能够提供更准确的爆发规模估计，并在影响力最大化、最优疫苗接种和哨点监测三个干预设计问题中验证了其有效性。

Conclusion: 邻域消息传递框架显著提高了网络传播模型预测的准确性，为干预设计问题提供了更可靠的解决方案。

Abstract: Spreading models capture key dynamics on networks, such as cascading failures
in economic systems, (mis)information diffusion, and pathogen transmission.
Here, we focus on design intervention problems -- for example, designing
optimal vaccination rollouts or wastewater surveillance systems -- which can be
solved by comparing outcomes under various counterfactuals. A leading approach
to computing these outcomes is message passing, which allows for the rapid and
direct computation of the marginal probabilities for each node. However,
despite its efficiency, classical message passing tends to overestimate
outbreak sizes on real-world networks, leading to incorrect predictions and,
thus, interventions. Here, we improve these estimates by using the neighborhood
message passing (NMP) framework for the epidemiological calculations. We
evaluate the quality of the improved algorithm and demonstrate how it can be
used to test possible solutions to three intervention design problems:
influence maximization, optimal vaccination, and sentinel surveillance.

</details>


### [66] [Attributed Hypergraph Generation with Realistic Interplay Between Structure and Attributes](https://arxiv.org/abs/2509.21838)
*Jaewan Chun,Seokbum Yoon,Minyoung Choe,Geon Lee,Kijung Shin*

Main category: cs.SI

TL;DR: 提出了NoAH模型，这是一个考虑节点属性的超图生成模型，通过核心-边缘节点层次结构建模超边形成过程，比现有模型更准确地反映结构与属性的交互作用。


<details>
  <summary>Details</summary>
Motivation: 现有超图生成模型大多忽略节点属性在超边形成中的作用，无法准确反映结构与节点属性之间的交互关系。

Method: 使用核心-边缘节点层次结构建模超边形成过程，基于节点属性确定附着概率，并提出了参数学习过程NoAHFit。

Result: 在四个领域的九个数据集上测试，NoAH在六个指标上比八个基线模型更准确地复制了真实超图中观察到的结构-属性交互。

Conclusion: NoAH模型能够有效建模超图中结构与节点属性的交互关系，为属性超图的生成提供了更准确的工具。

Abstract: In many real-world scenarios, interactions happen in a group-wise manner with
multiple entities, and therefore, hypergraphs are a suitable tool to accurately
represent such interactions. Hyperedges in real-world hypergraphs are not
composed of randomly selected nodes but are instead formed through structured
processes. Consequently, various hypergraph generative models have been
proposed to explore fundamental mechanisms underlying hyperedge formation.
However, most existing hypergraph generative models do not account for node
attributes, which can play a significant role in hyperedge formation. As a
result, these models fail to reflect the interactions between structure and
node attributes. To address the issue above, we propose NoAH, a stochastic
hypergraph generative model for attributed hypergraphs. NoAH utilizes the
core-fringe node hierarchy to model hyperedge formation as a series of node
attachments and determines attachment probabilities based on node attributes.
We further introduce NoAHFit, a parameter learning procedure that allows NoAH
to replicate a given real-world hypergraph. Through experiments on nine
datasets across four different domains, we show that NoAH with NoAHFit more
accurately reproduces the structure-attribute interplay observed in the
real-world hypergraphs than eight baseline hypergraph generative models, in
terms of six metrics.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [67] [Direct Bias-Correction Term Estimation for Propensity Scores and Average Treatment Effect Estimation](https://arxiv.org/abs/2509.22122)
*Masahiro Kato*

Main category: econ.EM

TL;DR: 提出通过直接估计倾向得分的偏倚校正项来改进平均处理效应估计的方法，而不是传统的最大似然或协变量平衡方法。


<details>
  <summary>Details</summary>
Motivation: 现有倾向得分估计方法（如最大似然、协变量平衡）可能无法最优地估计偏倚校正项，从而影响平均处理效应的估计精度。

Method: 通过最小化偏倚校正项的预测误差来直接估计倾向得分，采用Bregman散度最小化框架。

Result: 模拟研究表明该方法能有效提高平均处理效应的估计精度。

Conclusion: 直接估计偏倚校正项的方法为平均处理效应估计提供了更有效的途径，优于传统倾向得分估计方法。

Abstract: This study considers the estimation of the average treatment effect (ATE).
For ATE estimation, we estimate the propensity score through direct
bias-correction term estimation. Let $\{(X_i, D_i, Y_i)\}_{i=1}^{n}$ be the
observations, where $X_i \in \mathbb{R}^p$ denotes $p$-dimensional covariates,
$D_i \in \{0, 1\}$ denotes a binary treatment assignment indicator, and $Y_i
\in \mathbb{R}$ is an outcome. In ATE estimation, the bias-correction term
$h_0(X_i, D_i) = \frac{1[D_i = 1]}{e_0(X_i)} - \frac{1[D_i = 0]}{1 - e_0(X_i)}$
plays an important role, where $e_0(X_i)$ is the propensity score, the
probability of being assigned treatment $1$. In this study, we propose
estimating $h_0$ (or equivalently the propensity score $e_0$) by directly
minimizing the prediction error of $h_0$. Since the bias-correction term $h_0$
is essential for ATE estimation, this direct approach is expected to improve
estimation accuracy for the ATE. For example, existing studies often employ
maximum likelihood or covariate balancing to estimate $e_0$, but these
approaches may not be optimal for accurately estimating $h_0$ or the ATE. We
present a general framework for this direct bias-correction term estimation
approach from the perspective of Bregman divergence minimization and conduct
simulation studies to evaluate the effectiveness of the proposed method.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [68] [C-QUERI: Congressional Questions, Exchanges, and Responses in Institutions Dataset](https://arxiv.org/abs/2509.21548)
*Manjari Rudra,Daniel Magleby,Sujoy Sikdar*

Main category: cs.CY

TL;DR: 开发了一个从国会听证会转录本中提取问答对的流程，构建了第108-117届国会的新数据集，揭示了不同政党在提问策略上的系统性差异。


<details>
  <summary>Details</summary>
Motivation: 政治访谈和听证会中的问题具有超越信息收集的战略目的，但这些战略方面由于缺乏大规模研究数据集而研究不足。国会听证会为研究政治提问提供了丰富且可处理的场所。

Method: 开发了一个从非结构化听证会转录本中提取问答对的流程，构建了第108-117届国会委员会听证会的新数据集。

Result: 分析揭示了不同政党在提问策略上的系统性差异，仅通过问题内容就能预测提问者的政党归属。

Conclusion: 该数据集和方法不仅推进了国会政治研究，还为分析类似访谈场景中的问答提供了通用框架。

Abstract: Questions in political interviews and hearings serve strategic purposes
beyond information gathering including advancing partisan narratives and
shaping public perceptions. However, these strategic aspects remain
understudied due to the lack of large-scale datasets for studying such
discourse. Congressional hearings provide an especially rich and tractable site
for studying political questioning: Interactions are structured by formal
rules, witnesses are obliged to respond, and members with different political
affiliations are guaranteed opportunities to ask questions, enabling
comparisons of behaviors across the political spectrum.
  We develop a pipeline to extract question-answer pairs from unstructured
hearing transcripts and construct a novel dataset of committee hearings from
the 108th--117th Congress. Our analysis reveals systematic differences in
questioning strategies across parties, by showing the party affiliation of
questioners can be predicted from their questions alone. Our dataset and
methods not only advance the study of congressional politics, but also provide
a general framework for analyzing question-answering across interview-like
settings.

</details>


### [69] [Developing Strategies to Increase Capacity in AI Education](https://arxiv.org/abs/2509.21713)
*Noah Q. Cowit,Sri Yash Tadimalla,Stephanie T. Jones,Mary Lou Maher,Tracy Camp,Enrico Pontelli*

Main category: cs.CY

TL;DR: CRA组织32场虚拟圆桌会议，汇集202位专家讨论AI教育面临的挑战，重点关注基础设施不足、师资短缺、课程更新负担等问题，并提出建立AI教育资源中心等解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着AI需求增长，许多机构在AI教育方面面临挑战，需要了解不同教育环境的具体需求和资源限制，以制定有效的AI教育策略。

Method: 通过32场虚拟圆桌讨论，汇集202位专家，按机构类型组织讨论，重点关注AI知识领域与教学法、基础设施挑战、扩大AI教育容量的策略以及普及AI教育四个领域。

Result: 发现数字鸿沟导致基础设施障碍，师资短缺且缺乏再培训时间，计算基础设施不足，技术支持有限，课程更新负担重。专家建议建立AI教育资源中心。

Conclusion: 需要为教师提供持续的专业发展机会，特别是资源不足的机构，并建立中央AI教育资源库，确保所有学生都能获得AI教育。

Abstract: Many institutions are currently grappling with teaching artificial
intelligence (AI) in the face of growing demand and relevance in our world. The
Computing Research Association (CRA) has conducted 32 moderated virtual
roundtable discussions of 202 experts committed to improving AI education.
These discussions slot into four focus areas: AI Knowledge Areas and Pedagogy,
Infrastructure Challenges in AI Education, Strategies to Increase Capacity in
AI Education, and AI Education for All. Roundtables were organized around
institution type to consider the particular goals and resources of different AI
education environments. We identified the following high-level community needs
to increase capacity in AI education. A significant digital divide creates
major infrastructure hurdles, especially for smaller and under-resourced
institutions. These challenges manifest as a shortage of faculty with AI
expertise, who also face limited time for reskilling; a lack of computational
infrastructure for students and faculty to develop and test AI models; and
insufficient institutional technical support. Compounding these issues is the
large burden associated with updating curricula and creating new programs. To
address the faculty gap, accessible and continuous professional development is
crucial for faculty to learn about AI and its ethical dimensions. This support
is particularly needed for under-resourced institutions and must extend to
faculty both within and outside of computing programs to ensure all students
have access to AI education. We have compiled and organized a list of resources
that our participant experts mentioned throughout this study. These resources
contribute to a frequent request heard during the roundtables: a central
repository of AI education resources for institutions to freely use across
higher education.

</details>


### [70] [Malaysia's AI-Driven Education Landscape: Policies, Applications, and Comparative Insights for a Digital Future](https://arxiv.org/abs/2509.21858)
*Fadhilah Jamaluddin,Ahmad Hakiim Jamaluddin,Faridzah Jamaluddin,Faathirah Jamaluddin*

Main category: cs.CY

TL;DR: 本文分析了马来西亚AI驱动教育的发展现状，重点研究国家AI路线图和教育政策，通过比较分析提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 探索马来西亚如何通过AI战略政策提升教育质量，为数字未来培养人才，并了解其在全球AI教育中的定位。

Method: 采用政策驱动分析方法，评估国家战略，识别挑战，并与英国、美国、中国、印度进行对比分析。

Result: 发现马来西亚在AI素养和个性化学习方面取得进展，但在农村基础设施和教师准备度方面存在差距。

Conclusion: 建议加强治理、投资公平基础设施、促进公私合作，帮助马来西亚成为区域AI教育领导者。

Abstract: Artificial Intelligence (AI) is transforming education globally, and Malaysia
is leveraging this potential through strategic policies to enhance learning and
prepare students for a digital future. This article explores Malaysia's
AI-driven education landscape, emphasising the National Artificial Intelligence
Roadmap 2021-2025 and the Digital Education Policy. Employing a policy-driven
analysis, it maps AI applications in pedagogy, curriculum design,
administration, and teacher training across primary to tertiary levels. The
study evaluates national strategies, identifies challenges like digital divides
and ethical concerns, and conducts a comparative analysis with the United
Kingdom, the United States, China, and India to draw best practices in AI
policy and digital transformation. Findings highlight Malaysia's progress in AI
literacy and personalised learning, alongside gaps in rural infrastructure and
teacher readiness. Recommendations include strengthening governance, investing
in equitable infrastructure, and fostering public-private partnerships.
Targeting researchers, policymakers, and educators, this study informs
Malaysia's path to becoming a regional leader in AI-driven education and
contributes to global comparative education discourse.

</details>


### [71] [Opening Knowledge Gaps Drives Scientific Progress](https://arxiv.org/abs/2509.21899)
*Kara Kedrick,Wenlong Yang,Thomas Gebhart,Yang Wang,Russell J. Funk*

Main category: cs.CY

TL;DR: 该研究提出了一种使用计算拓扑学识别科学中知识缺口的方法，发现创造拓扑缺口的论文更有可能成为高被引论文，且更具颠覆性。


<details>
  <summary>Details</summary>
Motivation: 知识生产通常被视为现有理论、发现和概念重组的內生过程，但在海量潜在重组中识别最有价值的方向具有挑战性。研究者认为，当概念连接创造知识缺口时，会引导科学关注未探索的连接，指示有前景的研究方向。

Method: 使用计算拓扑学开发了在科学中系统识别知识缺口的方法，应用于微软学术图谱中的3400多万篇论文（1900-2020年），追踪这些创造缺口的论文如何重塑科学知识景观。

Result: 创造拓扑缺口的论文更有可能进入最高被引论文行列（前1-20%），而仅引入新颖组合但不创造缺口的论文在顶级被引中表现不佳，甚至低于基线论文。缺口创造论文更具颠覆性。

Conclusion: 知识缺口在引导科学探究新方向中发挥生成性作用，识别这些缺口有助于发现最有前景的研究方向。

Abstract: Knowledge production is often viewed as an endogenous process in which
discovery arises through the recombination of existing theories, findings, and
concepts. Yet given the vast space of potential recombinations, not all are
equally valuable, and identifying those that may prove most generative remains
challenging. We argue that a crucial form of recombination occurs when linking
concepts creates knowledge gaps-empty regions in the conceptual landscape that
focus scientific attention on proximal, unexplored connections and signal
promising directions for future research. Using computational topology, we
develop a method to systematically identify knowledge gaps in science at scale.
Applying this approach to millions of articles from Microsoft Academic Graph (n
= 34,363,623) over a 120-year period (1900-2020), we uncover papers that create
topological gaps in concept networks, tracking how these gap-opening works
reshape the scientific knowledge landscape. Our results indicate that
gap-opening papers are more likely to rank among the most highly cited works
(top 1-20%) compared with papers that do not introduce novel concept pairings.
In contrast, papers that introduce novel combinations without opening gaps are
not more likely to rank in the top 1% for citation counts, and are even less
likely than baseline papers to appear in the top 5% to 20%. Our findings also
suggest that gap-opening papers are more disruptive, highlighting their
generative role in stimulating new directions for scientific inquiry.

</details>


### [72] [From Superficial Outputs to Superficial Learning: Risks of Large Language Models in Education](https://arxiv.org/abs/2509.21972)
*Iris Delikoura,Yi. R,Fung,Pan Hui*

Main category: cs.CY

TL;DR: 对70项实证研究的系统综述显示，LLM在教育中的应用主要围绕操作效率、个性化应用和交互式学习工具三大领域，存在从模型层面到学习者认知行为层面的多重风险。


<details>
  <summary>Details</summary>
Motivation: LLM在教育中带来个性化、反馈和知识获取等优势的同时，也对学生和学习系统构成风险，但相关实证证据仍较为分散，需要系统梳理。

Method: 对计算机科学、教育和心理学领域的70项实证研究进行系统综述，围绕四个研究问题分析LLM在教育中的应用、影响测量方法、风险类型和缓解策略。

Result: 研究发现LLM风险包括模型层面的浅层理解、偏见、鲁棒性差、拟人化、幻觉、隐私问题和知识限制，以及学习者层面的认知行为影响如神经活动减少、过度依赖、独立学习能力下降和学生自主性丧失。

Conclusion: 提出了LLM风险适应学习模型，说明技术风险如何通过交互和解释影响教育成果，为负责任、以人为本的LLM教育整合提供了基础。

Abstract: Large Language Models (LLMs) are transforming education by enabling
personalization, feedback, and knowledge access, while also raising concerns
about risks to students and learning systems. Yet empirical evidence on these
risks remains fragmented. This paper presents a systematic review of 70
empirical studies across computer science, education, and psychology. Guided by
four research questions, we examine: (i) which applications of LLMs in
education have been most frequently explored; (ii) how researchers have
measured their impact; (iii) which risks stem from such applications; and (iv)
what mitigation strategies have been proposed. We find that research on LLMs
clusters around three domains: operational effectiveness, personalized
applications, and interactive learning tools. Across these, model-level risks
include superficial understanding, bias, limited robustness, anthropomorphism,
hallucinations, privacy concerns, and knowledge constraints. When learners
interact with LLMs, these risks extend to cognitive and behavioural outcomes,
including reduced neural activity, over-reliance, diminished independent
learning skills, and a loss of student agency. To capture this progression, we
propose an LLM-Risk Adapted Learning Model that illustrates how technical risks
cascade through interaction and interpretation to shape educational outcomes.
As the first synthesis of empirically assessed risks, this review provides a
foundation for responsible, human-centred integration of LLMs in education.

</details>


### [73] [AI Ethics Education in India: A Syllabus-Level Review of Computing Courses](https://arxiv.org/abs/2509.22329)
*Anshu M Mittal,P D Parthasarathy,Swaroop Joshi*

Main category: cs.CY

TL;DR: 对印度顶尖院校3,395份计算机科学及相关领域教学大纲的分析显示，仅有2.21%包含实质性AI伦理内容，且多为技术课程中的次要模块，覆盖深度和一致性有限。


<details>
  <summary>Details</summary>
Motivation: 随着AI在医疗、治理、金融和教育等领域的广泛应用，其伦理问题日益受到关注，但AI伦理在计算机科学教育中的具体教学处理仍缺乏系统研究。

Method: 通过对印度领先院校3,395份公开教学大纲进行大规模分析，识别包含AI伦理内容的课程。

Result: 仅75份教学大纲(2.21%)包含实质性AI伦理内容，主要作为技术课程的次要模块，通常只有1-2个教学课时，主题集中在算法公平性、隐私与数据治理、透明度和社会影响。

Conclusion: 当前AI伦理在计算课程中的整合存在深度和一致性不足的问题，需要加强未来技术人才对AI伦理维度的有意义参与能力培养。

Abstract: The pervasive integration of artificial intelligence (AI) across domains such
as healthcare, governance, finance, and education has intensified scrutiny of
its ethical implications, including algorithmic bias, privacy risks,
accountability, and societal impact. While ethics has received growing
attention in computer science (CS) education more broadly, the specific
pedagogical treatment of {AI ethics} remains under-examined. This study
addresses that gap through a large-scale analysis of 3,395 publicly accessible
syllabi from CS and allied areas at leading Indian institutions. Among them,
only 75 syllabi (2.21%) included any substantive AI ethics content. Three key
findings emerged: (1) AI ethics is typically integrated as a minor module
within broader technical courses rather than as a standalone course; (2) ethics
coverage is often limited to just one or two instructional sessions; and (3)
recurring topics include algorithmic fairness, privacy and data governance,
transparency, and societal impact. While these themes reflect growing
awareness, current curricular practices reveal limited depth and consistency.
This work highlights both the progress and the gaps in preparing future
technologists to engage meaningfully with the ethical dimensions of AI, and it
offers suggestions to strengthen the integration of AI ethics within computing
curricula.

</details>


### [74] [MakOne: Behavioural Data of University Students' Smart Devices in Uganda](https://arxiv.org/abs/2509.22334)
*Michael Kizito,Ivan Kayongo,Hawa Nyende,Halimu Chongomweru,Lillian Muyama,Roy Alia Asiku,Alice Mugisha*

Main category: cs.CY

TL;DR: 该论文介绍了MakOne数据集，这是一个从乌干达马凯雷雷大学72名学生收集的多模态数据集，旨在填补非洲学生行为数据的空白。


<details>
  <summary>Details</summary>
Motivation: 现有学生行为数据集主要来自西方机构，忽视了非洲独特的社会经济和基础设施背景，限制了研究结果的全球适用性。

Method: 使用iLog移动感知应用，在六周内收集72名学生的被动智能手机传感器数据（位置、身体活动、屏幕使用）和生态瞬时评估（情绪和日常习惯）。

Result: 创建了MakOne数据集，该数据集反映了非洲学生的生活体验，为行为建模、包容性情境感知系统设计、心理健康分析和文化教育技术提供了基础。

Conclusion: MakOne为基于数据的学生行为研究贡献了关键的非洲视角，促进了全球范围内更包容和多样化的研究。

Abstract: Understanding student behaviour in higher education is essential for
improving academic performance, supporting mental well-being, and informing
institutional policies. However, most existing behavioural datasets originate
from Western institutions and overlook the unique socioeconomic and
infrastructural contexts of African institutions, limiting the global
applicability of resulting insights. This paper introduces MakOne, a novel
multimodal dataset collected over six weeks from 72 students at Makerere
University, Kampala, using iLog, a mobile sensing application. The dataset
integrates passive smartphone sensor data-including location, physical
activity, and screen usage-with ecological momentary assessments (EMAs) that
capture students' moods and daily routines. Designed to reflect the lived
experiences of students in an African setting, MakOne offers a foundation for
research in behaviour modeling, inclusive context-aware system design, mental
health analytics, and culturally grounded educational technologies. It
contributes a critical African perspective to the growing body of data-driven
studies on student behaviour.

</details>


### [75] [LLM-Augmented and Fair Machine Learning Framework for University Admission Prediction](https://arxiv.org/abs/2509.22560)
*Mohammad Abbadi,Yassine Himeur,Shadi Atalla,Dahlia Mansoor,Wathiq Mansoor*

Main category: cs.CY

TL;DR: 该研究开发了一个结合机器学习、深度学习和大型语言模型的大学录取预测框架，使用2000多个学生记录进行测试，集成模型达到91%准确率，并进行了公平性审计发现性别和家庭背景差距。


<details>
  <summary>Details</summary>
Motivation: 大学面临申请激增和对公平性期望提高，需要准确的录取预测来确保公平公正的招生过程。

Method: 融合机器学习、深度学习和LLM技术，结合结构化学术人口数据和文本信号，测试逻辑回归、朴素贝叶斯、随机森林、深度神经网络和集成模型，并加入GPT-4模拟的个人陈述评估作为特征。

Result: 逻辑回归达到89.5%准确率，集成模型最佳为91.0%，文本特征集成带来适度提升。公平性审计显示9%性别差距（男67% vs 女76%）和11%父母教育背景差距。

Conclusion: 该框架具有可解释性、公平性意识且可部署，强调了持续监控公平性的必要性。

Abstract: Universities face surging applications and heightened expectations for
fairness, making accurate admission prediction increasingly vital. This work
presents a comprehensive framework that fuses machine learning, deep learning,
and large language model techniques to combine structured academic and
demographic variables with unstructured text signals. Drawing on more than
2,000 student records, the study benchmarks logistic regression, Naive Bayes,
random forests, deep neural networks, and a stacked ensemble. Logistic
regression offers a strong, interpretable baseline at 89.5% accuracy, while the
stacked ensemble achieves the best performance at 91.0%, with Naive Bayes and
random forests close behind. To probe text integration, GPT-4-simulated
evaluations of personal statements are added as features, yielding modest gains
but demonstrating feasibility for authentic essays and recommendation letters.
Transparency is ensured through feature-importance visualizations and fairness
audits. The audits reveal a 9% gender gap (67% male vs. 76% female) and an 11%
gap by parental education, underscoring the need for continued monitoring. The
framework is interpretable, fairness-aware, and deployable.

</details>


### [76] [A Systematic Review: Affective Perception on Urban Facades](https://arxiv.org/abs/2509.22599)
*Chenxi Wang,Haining Ding,Michal Gath-Morad*

Main category: cs.CY

TL;DR: 系统综述61篇文献，识别建筑立面属性如何影响情感感知（愉悦度和唤醒度），发现复杂性、材质、对称性和与环境的融合是主要预测因子，提出理论模型连接物理设计特征与情感结果。


<details>
  <summary>Details</summary>
Motivation: 建筑立面在城市环境中对情感感知具有关键影响，但目前对城市建筑立面情感影响的理论研究不足，需要系统梳理相关证据。

Method: 采用PRISMA框架进行系统文献综述，通过多尺度综合和知识图谱分析，识别立面属性与情感响应的关系，并分析计算方法的应用现状。

Result: 复杂性、材质、对称性和与环境的融合是影响情感感知的一致预测因子；计算方法应用增加但存在碎片化，忽视叙事连贯性和文化象征等无形维度。

Conclusion: 提出连接物理设计特征与情感结果的理论模型，指出方法学空白，为情感感知立面设计提供基础，支持城市环境中的心理健康。

Abstract: Architectural facades critically shape affective perception in urban
environments. Here, affect is understood as a multidimensional psychological
construct encompassing valence (pleasure-displeasure) and arousal
(activation-deactivation). Despite growing interest in affective responses to
the built environment, the affective impact of urban architectural facades
remains under-theorized. This study conducts a systematic review of 61 works,
guided by the PRISMA framework, to identify which facade attributes most
strongly predict affective responses operationalized as valence and arousal.
Through multi-scalar synthesis and knowledge mapping, the review highlights
complexity, materiality, symmetry, and bibliophilic integration as consistent
predictors of affective perception across urban, building, and detail levels.
Computational tools such as eye-tracking, CNN-based analysis, and parametric
modeling are increasingly employed, yet remain fragmented and often overlook
intangible dimensions like narrative coherence and cultural symbolism. By
consolidating cross-disciplinary evidence, this review proposes a theoretical
model linking physical design features to affective outcomes, and identifies
methodological gaps, particularly the lack of integrative, mixed-method
approaches. The findings offer a foundation for affect-aware facade design,
advancing evidence-based strategies to support psychological well-being in
urban contexts.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [77] [Pattern Recognition of Illicit E-Waste Misclassification in Global Trade Data](https://arxiv.org/abs/2509.21395)
*Muhammad Sukri Bin Ramli*

Main category: econ.GN

TL;DR: 提出并验证了一个数据驱动框架，通过异常价格-数量模式识别电子垃圾贸易，使用离群感知分割方法和废物评分来量化风险。


<details>
  <summary>Details</summary>
Motivation: 全球电子电气产品贸易中，电子垃圾常被错误分类以规避监管，传统方法难以从大数据集中识别这种非法贸易模式。

Method: 采用离群感知分割方法（迭代K-Means），首先隔离极端离群值防止数据偏斜，然后重新聚类剩余产品以揭示市场细分。使用逻辑回归模型开发"废物评分"来识别贸易特征与废料相似的产品。

Result: 在马来西亚和全球数据集中发现一致的四层市场层级。马来西亚市场以高容量大宗商品为主，而全球市场以高价值资本货物为主，显示出独特的国家专业化。框架成功识别出如电动发电机等以废料方式交易的成品。

Conclusion: 该框架能够有效识别具有"废物特征"的产品，为监管机构提供有针对性的审查清单，有助于打击电子垃圾非法贸易。

Abstract: The global trade in electronic and electrical goods is complicated by the
challenge of identifying e-waste, which is often misclassified to evade
regulations. Traditional analysis methods struggle to discern the underlying
patterns of this illicit trade within vast datasets. This research proposes and
validates a robust, data-driven framework to segment products and identify
goods exhibiting an anomalous "waste signature" a trade pattern defined by a
clear 'inverse price-volume'. The core of the framework is an Outlier-Aware
Segmentation method, an iterative K-Means approach that first isolates extreme
outliers to prevent data skewing and then re-clusters the remaining products to
reveal subtle market segments. To quantify risk, a "Waste Score" is developed
using a Logistic Regression model that identifies products whose trade
signatures are statistically similar to scrap. The findings reveal a consistent
four-tier market hierarchy in both Malaysian and global datasets. A key pattern
emerged from a comparative analysis: Malaysia's market structure is defined by
high-volume bulk commodities, whereas the global market is shaped by high-value
capital goods, indicating a unique national specialization. The framework
successfully flags finished goods, such as electric generators (HS 8502), that
are traded like scrap, providing a targeted list for regulatory scrutiny.

</details>


### [78] [Impact of government spending shocks in the Visegrad countries, 1999Q1-2019Q4](https://arxiv.org/abs/2509.21397)
*Zoltan Bartha,Marco M. Matarrese*

Main category: econ.GN

TL;DR: 该研究使用SVAR模型分析财政支出冲击对维谢格拉德四国经济的影响，发现除斯洛伐克外，财政扩张在这些国家具有比通常更大的影响。


<details>
  <summary>Details</summary>
Motivation: 研究维谢格拉德四国（捷克、匈牙利、波兰、斯洛伐克）财政政策支出冲击的经济影响，特别关注这些国家的财政乘数效应。

Method: 使用结构向量自回归（SVAR）模型，基于84个季度观测数据（1999年第一季度至2019年第四季度）进行估计。

Result: 长期（5年）累计支出乘数分别为：捷克0.81、匈牙利1.14、波兰1.76，斯洛伐克为-0.18但不显著。高支出乘数与较高的增值税收入占比、较高的债务比率、较高的外债以及较低的开放度相关。

Conclusion: 维谢格拉德四国（除斯洛伐克外）的财政扩张效应比通常预期更大，且财政乘数大小与特定经济特征相关。

Abstract: This study investigates the impact of a fiscal policy spending shock on the
economy of the Visegrad 4 countries. The impact is estimated with an SVAR
model, and the calculations are based on 84 quarterly observations
(1999Q1-2019Q4). The results suggest that fiscal expansion has a larger than
usual impact in the V4 countries (except for Slovakia): the estimated long-term
(5-year) cumulative spending multipliers are 0.81 for Czechia, 1.14 for
Hungary, and 1.76 for Poland (the Slovakian multiplier has a value of -0.18,
but it is not significant). The discussion section also connects higher
spending multipliers with a higher share of VAT revenues, a higher debt ratio,
higher foreign debt, and lower openness.

</details>


### [79] [Student perception and the efficacy of universities in shaping the entrepreneurial mindset](https://arxiv.org/abs/2509.21414)
*Andrea S. Gubik,Zoltan Bartha*

Main category: econ.GN

TL;DR: 研究发现，创业教育对创业活动影响较弱的原因在于学生对创业活动的认知。通过分析匈牙利9667名学生的数据，发现学生的创业意向、态度、自我效能感、社会规范以及大学和专业背景都对他们在大学内感知创业生态系统有显著但较小的影响。


<details>
  <summary>Details</summary>
Motivation: 现代大学在创业生态系统中扮演重要角色，但创业教育对创业活动的影响较弱。本研究旨在探讨创业教育效果不佳的原因，特别是学生对创业活动的认知如何影响课程和课外项目的效果。

Method: 使用2018年GUESSS数据库中的9667份匈牙利学生回答，建立广义线性模型进行分析。

Result: 学生的创业意向、创业态度、自我效能感、社会规范以及大学和专业背景都对学生在大学内感知创业生态系统有统计学上显著但较小的影响。

Conclusion: 应更注重塑造学生态度和激发学生兴趣，以提高创业教育的效率。

Abstract: Modern universities may play a significant role in entrepreneurial ecosystems
by boosting the entrepreneurial activity of the region. One way to achieve this
is through entrepreneurship education. In this study we suggest that one reason
why entrepreneurship education has a weak impact on entrepreneurial activity is
that the effect of courses and extracurricular programmes depends on how
students perceive the entrepreneurial activity. We use the 2018 GUESSS
database, which includes 9,667 answers for Hungary, to develop a general linear
model. The model suggests that students' entrepreneurial intentions, attitudes
toward entrepreneurship, self-efficacy, social norms, as well as the
university, and the field of study all have a small but statistically
significant impact on how students perceive the entrepreneurial ecosystem
within the university. Our conclusion is that more emphasis on shaping
attitudes and arousing student interest can increase the efficiency of
entrepreneurship education.

</details>


### [80] [The Impact of the UEFA Women's EURO on Hotel Overnight Stays: Evidence from a Causal Analysis](https://arxiv.org/abs/2509.21421)
*Hannes Wallimann,Anna Mehr*

Main category: econ.GN

TL;DR: 该研究评估了2025年欧洲女子足球锦标赛对瑞士旅游业的实际影响，发现只有微小正面效应，主要场馆的酒店过夜次数仅增加1.6%。


<details>
  <summary>Details</summary>
Motivation: 女性体育赛事的影响评估是一个重要但被忽视的研究领域，需要填补这一空白。

Method: 使用城市级酒店过夜数据，采用Arkhangelsky等人(2021)的合成双重差分法，比较主办城市与非主办目的地。

Result: 结果不支持大规模旅游影响的强烈主张，仅显示微小正面效应，主要场馆的过夜次数增加1.6%。

Conclusion: 该赛事对旅游业有正面但适度的积极影响，并为体育赛事的进一步政策评估提供了框架。

Abstract: The impact evaluation of female sports events remains an important yet
neglected area of research. To fill this gap, this working paper provides a
timely assessment of the 2025 UEFA Women's European Championship (WEURO) in
Switzerland-the largest women-specific sports event in Europe with more than
657,000 spectators. Using city-level data on hotel overnight stays, we apply
the Synthetic Difference-in-Differences approach of Arkhangelsky et al. (2021)
to compare WEURO host cities with non-host destinations. In summary, our
results do not support strong claims of large tourism impacts but rather point
to a small positive effect. Sensitivity analyses also suggest positive effects.
However, confidence intervals permit firm conclusions only for the main venues,
indicating an increase in overnight stays of 1.6% attributable to the WEURO.
Overall, our findings indicate positive but modest tourism impacts of the WEURO
and outline a framework for further policy evaluation of sports events.

</details>


### [81] [Forecasting House Prices](https://arxiv.org/abs/2509.21460)
*Emanuel Kohlscheen*

Main category: econ.GN

TL;DR: 基于随机森林模型分析13个发达国家的房价驱动因素，发现价格动量、初始估值和家庭信贷增长是主要因素，模型预测精度比OLS模型显著提升。


<details>
  <summary>Details</summary>
Motivation: 识别过去35年13个发达国家房价的主要驱动因素，探索房价增长的决定性变量及其非线性效应。

Method: 使用Breiman(2001)的随机森林模型，结合Shapley值分析变量重要性，并与使用相同10个预测变量的OLS模型进行对比。

Result: 房价增长主要由价格动量、价格租金比和家庭信贷增长解释；随机森林模型相比OLS模型，RMSE降低44%，MAE降低45%；模型对所有国家都适用，国家固定效应影响很小。

Conclusion: 随机森林模型能有效捕捉房价驱动因素的非线性关系，在预测精度上显著优于传统线性模型，且具有跨国普适性。

Abstract: This article identifies the factors that drove house prices in 13 advanced
countries over the past 35 years. It does so based on Breiman s (2001) random
forest model. Shapley values indicate that annual house price growth across
countries is explained first and foremost by price momentum, initial valuations
(proxied by price to rent ratios) and household credit growth. Partial effects
of explanatory variables are also elicited and suggest important
non-linearities, for instance as to what concerns the effects of CPI inflation
on house price growth. The out-of-sample forecast test reveals that the random
forest model delivers 44% lower house price variation RMSEs and 45% lower MAEs
when compared to an OLS model that uses the same set of 10 pre-determined
explanatory variables. Notably, the same model works well for all countries, as
the random forest attributes minimal values to country fixed effects.

</details>


### [82] [Persistent Gaps, Partial Gains: A Population-Level Study of COVID-19 Learning Inequalities in the Netherlands](https://arxiv.org/abs/2509.22136)
*Hekmat Alrouh,Tom Emery,Anja Schreijer*

Main category: econ.GN

TL;DR: 使用荷兰人口数据研究COVID-19学校关闭对教育不平等的影响，发现平均成绩有所恢复，但基于父母教育和移民背景的不平等持续或加剧，特别是在职业教育轨道中。


<details>
  <summary>Details</summary>
Motivation: COVID-19大流行扰乱了全球学校教育，引发了关于教育不平等扩大的担忧，需要研究疫情期间学校关闭对不同社会经济群体学业表现的影响。

Method: 使用荷兰人口级行政数据(N=1,471,217)，分析2017-2023年毕业队列的最终中央考试成绩，通过广义线性模型估计大流行暴露与关键分层变量(父母教育、家庭收入、移民背景、城市化程度)的交互作用。

Result: 平均成绩到2023年部分恢复，但父母教育和移民背景的不平等持续或加剧，特别是在职业教育轨道中。非西方背景的第一代移民学生遭受最大持续损失，而农村地区学生缩小或逆转了疫情前的表现差距。

Conclusion: 系统性冲击既能加剧也能重新调整不平等模式，具体取决于社会人口维度和教育背景。教育途径和地方背景在塑造对危机引起的学习中断的韧性方面发挥重要作用。

Abstract: The COVID-19 pandemic disrupted schooling worldwide, raising concerns about
widening educational inequalities. Using population-level administrative data
from the Netherlands (N = 1,471,217), this study examines how socio-economic
disparities in secondary school performance evolved before, during, and after
pandemic-related school closures. We analyze final central examination scores
for cohorts graduating between 2017 and 2023 across four educational tracks,
estimating generalized linear models with interactions between pandemic
exposure and key stratification variables: parental education, household
income, migration background, and urbanicity. Results show that while average
performance partially recovered by 2023, inequalities by parental education and
migration background persisted or intensified, particularly in vocational
tracks. First-generation students with a non-Western background experienced the
largest sustained losses, whereas students in rural areas (previously
disadvantaged) narrowed or reversed pre-pandemic performance gaps. Findings
suggest that systemic shocks can both exacerbate and recalibrate inequality
patterns, depending on the socio-demographic dimension and educational context.
We discuss implications for stratification theory, highlighting the role of
educational pathways and local contexts in shaping resilience to crisis-induced
learning disruptions.

</details>


### [83] [How firms, bureaucrats, and ministries benefit from the revolving door: Evidence from Japan](https://arxiv.org/abs/2509.22173)
*Trevor Incerti*

Main category: econ.GN

TL;DR: 日本官僚离职后就业市场呈现两极分化：高层官员加入营利企业带来政府贷款和股市收益，低层官员加入非营利组织获得更高价值合同，显示旋转门现象是企业需求与官僚激励共同作用的结果。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注立法联系对企业的回报，较少关注官僚联系和非营利组织的作用，需要揭示官僚旋转门就业市场的完整图景。

Method: 使用日本所有前公务员首次离职后职位数据，分析不同级别官员的就业选择和产生的回报。

Result: 精英经济部门高层官员更可能加入营利企业，带来政府贷款增加和股市正面反应；低层官员更可能加入政府关联非营利组织，在领导职位时获得更高价值合同。

Conclusion: 旋转门动态不仅由企业需求驱动，也受到官僚激励影响，政府部门通过引导利益来确保公务员长期职业价值。

Abstract: A growing literature finds high returns to firms with legislative
connections. Less attention has been paid to returns from bureaucratic
connections and to organizations beyond for-profit firms. Using data recording
the first post-bureaucracy position occupied by all former civil servants in
Japan, I reveal a bifurcated job market for former bureaucrats. High-ranking
officials from elite economic ministries are more likely to join for-profit
firms, where they generate returns such as increased government loans and
positive stock market reactions. Lower-ranking officials are more likely to
join nonprofits linked to government ministries, which receive higher-value
contracts when former bureaucrats are in leadership roles. These patterns
suggest that while firms wish to hire bureaucrats who can deliver tangible
benefits, ministries also shape revolving door pathways by directing benefits
to ensure long-term career value for civil servants. These findings reframe
revolving door dynamics as the result of both firm-driven demand and
bureaucratic incentives.

</details>


### [84] [Metro 3 in Brussels under uncertainty: scenario-based public transport accessibility analysis](https://arxiv.org/abs/2509.22223)
*Brecht Verbeken,Arne Vanhoyweghen,Vincent Ginis*

Main category: econ.GN

TL;DR: 本文对布鲁塞尔地铁3号线进行了基于情景的可达性评估，发现该项目能显著改善公共交通可达性，特别是在低收入社区，有助于减少社会空间不平等。


<details>
  <summary>Details</summary>
Motivation: 布鲁塞尔地铁3号线是欧洲最具争议的基础设施项目之一，成本不断上升、工期延误且完工时间不确定，但缺乏公开的可达性评估来为政策辩论提供依据。

Method: 使用基于时刻表的公共交通数据，结合所有区域运营商的官方GTFS数据，构建三个情景：当前网络、部分实施（南段轻轨转换）、完全实施到Bordet。在布鲁塞尔首都区647个均匀分布的500米点上测量公共交通出行时间。

Result: 结果显示显著但不均衡的可达性提升，最大改善出现在收入低于平均水平的社区。时间鲁棒性分析揭示了可达性结果的可变性，强调了考虑出发时间不确定性的必要性。

Conclusion: 地铁3号线有潜力减少可达性方面的社会空间不平等，为这个被成本担忧主导的公共辩论提供了透明证据。

Abstract: Metro Line 3 in Brussels is one of Europe's most debated infrastructure
projects, marked by escalating costs, delays, and uncertainty over completion.
Yet no public accessibility appraisal exists to inform this policy debate. This
paper provides a scenario-based assessment of the spatial and distributional
accessibility impacts of Metro 3 using schedule-based public transport data.
Official GTFS feeds from all regional operators were combined and adapted to
represent three scenarios: (i) the current network, (ii) partial implementation
of Metro 3 (conversion of the southern premetro section), and (iii) full
implementation to Bordet. Accessibility was measured as public transport travel
time between 647 evenly spaced 500 m points covering the Brussels-Capital
Region. Simulations were conducted for morning, evening, and weekend midday
periods, each with three departure times (t-10, t, t+10), capturing robustness
to short-term timetable variation. Results show substantial but uneven
accessibility gains, with the largest improvements occurring in neighborhoods
with below-average incomes. Temporal robustness analysis highlights variability
in accessibility outcomes, underscoring the need to account for uncertainty in
departure timing. These findings suggest that Metro 3 has the potential to
reduce socio-spatial inequalities in accessibility, providing transparent
evidence for a project where public debate is dominated by cost concerns.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [85] [Towards mitigating information leakage when evaluating safety monitors](https://arxiv.org/abs/2509.21344)
*Gerard Boxo,Aman Neelappa,Shivam Raval*

Main category: cs.AI

TL;DR: 提出了一个系统框架来评估白盒监控器的真实性能，避免因行为诱发信息泄露而夸大效果。通过内容过滤、分数过滤和微调模型生物三种策略来检测和缓解泄漏问题。


<details>
  <summary>Details</summary>
Motivation: 现有白盒监控器在训练和评估时，诱发有害行为的信息会泄露到监控器输入数据中，从而夸大监控器的检测效果。需要区分监控器是检测真实模型行为还是表面诱发痕迹。

Method: 提出三种评估策略：内容过滤（移除诱发相关文本）、分数过滤（仅聚合任务相关token）、提示蒸馏微调模型生物（无需显式提示即可展现欺骗行为）。以欺骗检测为案例研究，识别两种泄漏类型。

Result: 实验发现：内容过滤能平滑移除诱发信号，使AUROC下降30%；分数过滤使AUROC下降15%；微调模型生物能改进评估但使性能下降达40%。

Conclusion: 白盒监控器的评估需要仔细考虑诱发信息泄露问题，提出的三种策略能有效识别和缓解泄漏，确保监控器评估反映真实检测能力而非表面痕迹。

Abstract: White box monitors that analyze model internals offer promising advantages
for detecting potentially harmful behaviors in large language models, including
lower computational costs and integration into layered defense systems.However,
training and evaluating these monitors requires response exemplars that exhibit
the target behaviors, typically elicited through prompting or fine-tuning. This
presents a challenge when the information used to elicit behaviors inevitably
leaks into the data that monitors ingest, inflating their effectiveness. We
present a systematic framework for evaluating a monitor's performance in terms
of its ability to detect genuine model behavior rather than superficial
elicitation artifacts. Furthermore, we propose three novel strategies to
evaluate the monitor: content filtering (removing deception-related text from
inputs), score filtering (aggregating only over task-relevant tokens), and
prompt distilled fine-tuned model organisms (models trained to exhibit
deceptive behavior without explicit prompting). Using deception detection as a
representative case study, we identify two forms of leakage that inflate
monitor performance: elicitation leakage from prompts that explicitly request
harmful behavior, and reasoning leakage from models that verbalize their
deceptive actions. Through experiments on multiple deception benchmarks, we
apply our proposed mitigation strategies and measure performance retention. Our
evaluation of the monitors reveal three crucial findings: (1) Content filtering
is a good mitigation strategy that allows for a smooth removal of elicitation
signal and can decrease probe AUROC by 30\% (2) Score filtering was found to
reduce AUROC by 15\% but is not as straightforward to attribute to (3) A
finetuned model organism improves monitor evaluations but reduces their
performance by upto 40\%, even when re-trained.

</details>


### [86] [Correct Reasoning Paths Visit Shared Decision Pivots](https://arxiv.org/abs/2509.21549)
*Dongkyu Cho,Amy B. Z. Zhang,Bilel Fehri,Sheng Wang,Rumi Chunara,Rui Song,Hengrui Cai*

Main category: cs.AI

TL;DR: 提出了一种基于决策支点的自训练方法，通过识别和验证推理过程中的关键检查点来改进大语言模型的推理能力，无需真实推理数据或外部指标。


<details>
  <summary>Details</summary>
Motivation: 解决大规模验证思维链推理轨迹的挑战，确保推理路径的正确性。

Method: 使用自训练流程：(1) 采样多样推理路径并挖掘共享决策支点；(2) 通过辅助验证器将推理轨迹压缩为支点聚焦的短路径；(3) 使用自生成输出进行后训练。

Result: 在LogiQA、MedQA和MATH500等标准基准测试中验证了方法的有效性。

Conclusion: 该方法能够在不依赖真实推理数据或外部指标的情况下，有效对齐和改进模型的推理能力。

Abstract: Chain-of-thought (CoT) reasoning exposes the intermediate thinking process of
large language models (LLMs), yet verifying those traces at scale remains
unsolved. In response, we introduce the idea of decision pivots-minimal,
verifiable checkpoints that any correct reasoning path must visit. We
hypothesize that correct reasoning, though stylistically diverse, converge on
the same pivot set, while incorrect ones violate at least one pivot. Leveraging
this property, we propose a self-training pipeline that (i) samples diverse
reasoning paths and mines shared decision pivots, (ii) compresses each trace
into pivot-focused short-path reasoning using an auxiliary verifier, and (iii)
post-trains the model using its self-generated outputs. The proposed method
aligns reasoning without ground truth reasoning data or external metrics.
Experiments on standard benchmarks such as LogiQA, MedQA, and MATH500 show the
effectiveness of our method.

</details>


### [87] [AutoClimDS: Climate Data Science Agentic AI -- A Knowledge Graph is All You Need](https://arxiv.org/abs/2509.21553)
*Ahmed Jaber,Wangshu Zhu,Karthick Jayavelu,Justin Downes,Sameer Mohamed,Candace Agonafir,Linnia Hawkins,Tian Zheng*

Main category: cs.AI

TL;DR: 提出了一种结合知识图谱和AI代理的云原生科学工作流系统，旨在降低气候数据科学的技术门槛，使非专业用户能够通过自然语言交互访问和分析气候数据。


<details>
  <summary>Details</summary>
Motivation: 气候数据科学面临数据源分散、格式异构、技术门槛高等挑战，限制了参与度、减缓了发现速度并降低了科学工作流的可重复性。

Method: 通过整合精心构建的知识图谱和基于生成式AI服务的AI代理，知识图谱统一组织数据集、工具和工作流，AI代理支持自然语言交互、自动化数据访问和简化分析。

Result: 该系统显著降低了参与气候数据科学的技术门槛，使非专业用户能够识别和分析相关数据集，展示了可扩展和自主的科学工作流。

Conclusion: 该系统为民主化气候数据访问和建立可重复、可扩展的人机协作科学研究框架开辟了道路。

Abstract: Climate data science faces persistent barriers stemming from the fragmented
nature of data sources, heterogeneous formats, and the steep technical
expertise required to identify, acquire, and process datasets. These challenges
limit participation, slow discovery, and reduce the reproducibility of
scientific workflows. In this paper, we present a proof of concept for
addressing these barriers through the integration of a curated knowledge graph
(KG) with AI agents designed for cloud-native scientific workflows. The KG
provides a unifying layer that organizes datasets, tools, and workflows, while
AI agents -- powered by generative AI services -- enable natural language
interaction, automated data access, and streamlined analysis. Together, these
components drastically lower the technical threshold for engaging in climate
data science, enabling non-specialist users to identify and analyze relevant
datasets. By leveraging existing cloud-ready API data portals, we demonstrate
that "a knowledge graph is all you need" to unlock scalable and agentic
workflows for scientific inquiry. The open-source design of our system further
supports community contributions, ensuring that the KG and associated tools can
evolve as a shared commons. Our results illustrate a pathway toward
democratizing access to climate data and establishing a reproducible,
extensible framework for human--AI collaboration in scientific research.

</details>


### [88] [Reimagining Agent-based Modeling with Large Language Model Agents via Shachi](https://arxiv.org/abs/2509.21862)
*So Kuroki,Yingtao Tian,Kou Misaki,Takashi Ikegami,Takuya Akiba,Yujin Tang*

Main category: cs.AI

TL;DR: Shachi是一个用于LLM驱动多智能体系统的模块化框架，将智能体策略分解为配置、记忆和工具三个核心认知组件，通过LLM推理引擎协调，支持对集体行为的系统性分析。


<details>
  <summary>Details</summary>
Motivation: 当前LLM多智能体系统研究缺乏受控实验的方法论，限制了对其涌现行为的科学理解。

Method: 提出Shachi框架，将智能体策略分解为配置（内在特质）、记忆（上下文持久性）和工具（扩展能力）三个组件，由LLM推理引擎协调。

Result: 在10个任务的基准测试中验证了方法有效性，通过模拟美国关税冲击实验证明，只有当智能体认知架构正确配置记忆和工具时，其行为才与真实市场反应一致。

Conclusion: Shachi为构建和评估LLM智能体提供了严谨的开源基础，旨在促进更累积性和科学基础的研究。

Abstract: The study of emergent behaviors in large language model (LLM)-driven
multi-agent systems is a critical research challenge, yet progress is limited
by a lack of principled methodologies for controlled experimentation. To
address this, we introduce Shachi, a formal methodology and modular framework
that decomposes an agent's policy into core cognitive components: Configuration
for intrinsic traits, Memory for contextual persistence, and Tools for expanded
capabilities, all orchestrated by an LLM reasoning engine. This principled
architecture moves beyond brittle, ad-hoc agent designs and enables the
systematic analysis of how specific architectural choices influence collective
behavior. We validate our methodology on a comprehensive 10-task benchmark and
demonstrate its power through novel scientific inquiries. Critically, we
establish the external validity of our approach by modeling a real-world U.S.
tariff shock, showing that agent behaviors align with observed market reactions
only when their cognitive architecture is appropriately configured with memory
and tools. Our work provides a rigorous, open-source foundation for building
and evaluating LLM agents, aimed at fostering more cumulative and
scientifically grounded research.

</details>


### [89] [EEG-Based Consumer Behaviour Prediction: An Exploration from Classical Machine Learning to Graph Neural Networks](https://arxiv.org/abs/2509.21567)
*Mohammad Parsa Afshar,Aryan Azimi*

Main category: cs.AI

TL;DR: 使用EEG数据和机器学习模型预测消费者行为，比较了传统机器学习模型和图神经网络(GNN)的性能，发现GNN在某些基础指标上表现更好。


<details>
  <summary>Details</summary>
Motivation: 预测消费者行为在市场营销、认知神经科学和人机交互中很重要，EEG数据可以提供大脑神经活动的详细信息来分析决策过程。

Method: 从NeuMa数据集中提取和清理EEG特征，为GNN模型创建大脑连接特征，使用包括传统模型和GNN在内的多种机器学习模型进行比较。

Result: 整体结果没有显著差异，但GNN模型在某些基础指标上表现更好，而传统模型在这些指标上不够理想。

Conclusion: EEG信号分析与机器学习模型结合可以更深入理解消费者行为，并提供了传统模型与新兴GNN模型的全面比较。

Abstract: Prediction of consumer behavior is one of the important purposes in
marketing, cognitive neuroscience, and human-computer interaction. The
electroencephalography (EEG) data can help analyze the decision process by
providing detailed information about the brain's neural activity. In this
research, a comparative approach is utilized for predicting consumer behavior
by EEG data. In the first step, the features of the EEG data from the NeuMa
dataset were extracted and cleaned. For the Graph Neural Network (GNN) models,
the brain connectivity features were created. Different machine learning
models, such as classical models and Graph Neural Networks, are used and
compared. The GNN models with different architectures are implemented to have a
comprehensive comparison; furthermore, a wide range of classical models, such
as ensemble models, are applied, which can be very helpful to show the
difference and performance of each model on the dataset. Although the results
did not show a significant difference overall, the GNN models generally
performed better in some basic criteria where classical models were not
satisfactory. This study not only shows that combining EEG signal analysis and
machine learning models can provide an approach to deeper understanding of
consumer behavior, but also provides a comprehensive comparison between the
machine learning models that have been widely used in previous studies in the
EEG-based neuromarketing such as Support Vector Machine (SVM), and the models
which are not used or rarely used in the field, like Graph Neural Networks.

</details>


### [90] [GeoEvolve: Automating Geospatial Model Discovery via Multi-Agent Large Language Models](https://arxiv.org/abs/2509.21593)
*Peng Luo,Xiayin Lou,Yu Zheng,Zhuo Zheng,Stefano Ermon*

Main category: cs.AI

TL;DR: GeoEvolve是一个多智能体LLM框架，通过结合进化搜索和地理空间领域知识，自动设计和优化地理空间算法，在空间插值和不确定性量化任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的算法发现框架缺乏地理空间领域知识和多步推理能力，难以解决复杂的地理空间问题。

Method: 采用双层循环结构：内环使用代码进化器生成和变异候选解，外环通过智能控制器评估精英解并查询GeoKnowRAG模块（结构化地理空间知识库）来注入地理学理论先验。

Result: 在空间插值任务上降低RMSE误差13-21%，在不确定性估计任务上提升性能17%。消融研究证实领域知识引导的检索对稳定高质量进化至关重要。

Conclusion: GeoEvolve为自动化、知识驱动的地理空间建模提供了可扩展路径，为可信赖和高效的AI-for-Science发现开辟了新机会。

Abstract: Geospatial modeling provides critical solutions for pressing global
challenges such as sustainability and climate change. Existing large language
model (LLM)-based algorithm discovery frameworks, such as AlphaEvolve, excel at
evolving generic code but lack the domain knowledge and multi-step reasoning
required for complex geospatial problems. We introduce GeoEvolve, a multi-agent
LLM framework that couples evolutionary search with geospatial domain knowledge
to automatically design and refine geospatial algorithms. GeoEvolve operates in
two nested loops: an inner loop leverages a code evolver to generate and mutate
candidate solutions, while an outer agentic controller evaluates global elites
and queries a GeoKnowRAG module -- a structured geospatial knowledge base that
injects theoretical priors from geography. This knowledge-guided evolution
steers the search toward theoretically meaningful and computationally efficient
algorithms. We evaluate GeoEvolve on two fundamental and classical tasks:
spatial interpolation (kriging) and spatial uncertainty quantification
(geospatial conformal prediction). Across these benchmarks, GeoEvolve
automatically improves and discovers new algorithms, incorporating geospatial
theory on top of classical models. It reduces spatial interpolation error
(RMSE) by 13-21% and enhances uncertainty estimation performance by 17\%.
Ablation studies confirm that domain-guided retrieval is essential for stable,
high-quality evolution. These results demonstrate that GeoEvolve provides a
scalable path toward automated, knowledge-driven geospatial modeling, opening
new opportunities for trustworthy and efficient AI-for-Science discovery.

</details>


### [91] [Automated and Interpretable Survival Analysis from Multimodal Data](https://arxiv.org/abs/2509.21600)
*Mafalda Malafaia,Peter A. N. Bosman,Coen Rasch,Tanja Alderliesten*

Main category: cs.AI

TL;DR: 提出了一个可解释的多模态AI框架MultiFIX，通过整合临床变量和CT影像来自动化生存分析，在头颈癌数据集上取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 随着多模态数据的增长和临床对透明模型的需求增加，准确且可解释的生存分析在肿瘤学中仍然是一个核心挑战。

Method: 使用深度学习推断与生存相关的特征：影像特征通过Grad-CAM解释，临床变量通过遗传编程建模为符号表达式。风险估计采用透明的Cox回归，实现不同生存结果的群体分层。

Result: 在头颈癌RADCURE数据集上，MultiFIX实现了C-index为0.838（预测）和0.826（分层），优于临床和学术基线方法，并与已知预后标志物一致。

Conclusion: 结果突显了可解释多模态AI在精准肿瘤学中的潜力，MultiFIX框架具有良好应用前景。

Abstract: Accurate and interpretable survival analysis remains a core challenge in
oncology. With growing multimodal data and the clinical need for transparent
models to support validation and trust, this challenge increases in complexity.
We propose an interpretable multimodal AI framework to automate survival
analysis by integrating clinical variables and computed tomography imaging. Our
MultiFIX-based framework uses deep learning to infer survival-relevant features
that are further explained: imaging features are interpreted via Grad-CAM,
while clinical variables are modeled as symbolic expressions through genetic
programming. Risk estimation employs a transparent Cox regression, enabling
stratification into groups with distinct survival outcomes. Using the
open-source RADCURE dataset for head and neck cancer, MultiFIX achieves a
C-index of 0.838 (prediction) and 0.826 (stratification), outperforming the
clinical and academic baseline approaches and aligning with known prognostic
markers. These results highlight the promise of interpretable multimodal AI for
precision oncology with MultiFIX.

</details>


### [92] [Semantic F1 Scores: Fair Evaluation Under Fuzzy Class Boundaries](https://arxiv.org/abs/2509.21633)
*Georgios Chochlakis,Jackson Trager,Vedant Jhaveri,Nikhil Ravichandran,Alexandros Potamianos,Shrikanth Narayanan*

Main category: cs.AI

TL;DR: 提出Semantic F1 Scores，一种用于主观或多标签分类的新评估指标，通过量化预测标签与黄金标签之间的语义相关性来改进传统F1指标。


<details>
  <summary>Details</summary>
Motivation: 传统F1指标将语义相关的预测视为完全失败，无法反映人类标注者分歧或模糊类别边界的现实情况。需要一种能够给予语义相关但非完全相同标签部分信用的公平评估方法。

Method: 使用标签相似性矩阵计算软精度和软召回分数，通过新颖的两步精度-召回公式，无需丢弃标签或强制匹配不相似标签即可比较任意大小的标签集。

Result: 通过理论论证和在合成及真实数据上的广泛实证验证，Semantic F1显示出更好的可解释性和生态效度。该方法对相似性矩阵的误指定具有鲁棒性。

Conclusion: Semantic F1提供了更公平的评估，认识到类别重叠、标注者分歧以及基于相似预测的下游决策会产生相似结果。由于只需要领域适当的相似性矩阵而非严格本体，该方法适用于各种任务和模态。

Abstract: We propose Semantic F1 Scores, novel evaluation metrics for subjective or
fuzzy multi-label classification that quantify semantic relatedness between
predicted and gold labels. Unlike the conventional F1 metrics that treat
semantically related predictions as complete failures, Semantic F1 incorporates
a label similarity matrix to compute soft precision-like and recall-like
scores, from which the Semantic F1 scores are derived. Unlike existing
similarity-based metrics, our novel two-step precision-recall formulation
enables the comparison of label sets of arbitrary sizes without discarding
labels or forcing matches between dissimilar labels. By granting partial credit
for semantically related but nonidentical labels, Semantic F1 better reflects
the realities of domains marked by human disagreement or fuzzy category
boundaries. In this way, it provides fairer evaluations: it recognizes that
categories overlap, that annotators disagree, and that downstream decisions
based on similar predictions lead to similar outcomes. Through theoretical
justification and extensive empirical validation on synthetic and real data, we
show that Semantic F1 demonstrates greater interpretability and ecological
validity. Because it requires only a domain-appropriate similarity matrix,
which is robust to misspecification, and not a rigid ontology, it is applicable
across tasks and modalities.

</details>


### [93] [Can AI Perceive Physical Danger and Intervene?](https://arxiv.org/abs/2509.21651)
*Abhishek Jindal,Dmitry Kalashnikov,Oscar Chang,Divya Garikapati,Anirudha Majumdar,Pierre Sermanet,Vikas Sindhwani*

Main category: cs.AI

TL;DR: 该论文提出了一个用于评估具身AI系统物理安全性的可扩展基准测试方法，通过生成真实感图像和视频来测试基础模型对物理安全的理解能力，并开发了后训练范式来提升模型的安全推理能力。


<details>
  <summary>Details</summary>
Motivation: 当AI与物理世界交互时（如机器人或辅助代理），会产生超越纯数字AI的安全挑战，存在直接的物理伤害风险。需要评估当前基础模型对物理安全常识的理解程度。

Method: 1. 基于真实世界伤害叙述和操作安全约束，开发可扩展的物理安全基准测试方法；2. 使用先进生成模型将安全约束转化为从安全到不安全状态过渡的真实感图像和视频；3. 分析主要基础模型的风险感知、安全推理和干预触发能力；4. 开发后训练范式，通过系统指令教导模型显式推理具身特定的安全约束。

Result: 开发的后训练模型生成可解释的安全推理思维轨迹，在约束满足评估中达到最先进的性能水平。

Conclusion: 该研究为具身AI系统的物理安全评估提供了有效方法，通过可解释的安全推理提升了模型在安全关键应用中的部署准备度。

Abstract: When AI interacts with the physical world -- as a robot or an assistive agent
-- new safety challenges emerge beyond those of purely ``digital AI". In such
interactions, the potential for physical harm is direct and immediate. How well
do state-of-the-art foundation models understand common-sense facts about
physical safety, e.g. that a box may be too heavy to lift, or that a hot cup of
coffee should not be handed to a child? In this paper, our contributions are
three-fold: first, we develop a highly scalable approach to continuous physical
safety benchmarking of Embodied AI systems, grounded in real-world injury
narratives and operational safety constraints. To probe multi-modal safety
understanding, we turn these narratives and constraints into photorealistic
images and videos capturing transitions from safe to unsafe states, using
advanced generative models. Secondly, we comprehensively analyze the ability of
major foundation models to perceive risks, reason about safety, and trigger
interventions; this yields multi-faceted insights into their deployment
readiness for safety-critical agentic applications. Finally, we develop a
post-training paradigm to teach models to explicitly reason about
embodiment-specific safety constraints provided through system instructions.
The resulting models generate thinking traces that make safety reasoning
interpretable and transparent, achieving state of the art performance in
constraint satisfaction evaluations. The benchmark will be released at
https://asimov-benchmark.github.io/v2

</details>


### [94] [Align2Speak: Improving TTS for Low Resource Languages via ASR-Guided Online Preference Optimization](https://arxiv.org/abs/2509.21718)
*Shehzeen Hussain,Paarth Neekhara,Xuesong Yang,Edresson Casanova,Subhankar Ghosh,Roy Fejgin,Ryan Langman,Mikyas Desta,Leili Tavabi,Jason Li*

Main category: cs.AI

TL;DR: 提出基于GRPO的框架，利用预训练ASR模型辅助低资源语言的TTS系统开发，通过多目标奖励优化实现高质量语音合成


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言缺乏配对文本-语音数据的问题，利用更易获取的ASR模型来提升TTS性能

Method: 1) 使用IPA标记训练多语言基线模型；2) 在有限配对数据上微调；3) 应用GRPO算法，使用无配对文本和说话人提示，通过ASR、说话人验证和音频质量估计模型的多目标奖励进行优化

Result: 在低资源语言中生成可理解且说话人一致的语音，显著优于单独微调；在高资源语言中也超越DPO等离线对齐方法，在可理解性、说话人相似性和音频质量方面表现更优

Conclusion: GRPO框架能有效利用ASR模型提升TTS性能，特别适用于低资源语言场景，同时在高资源语言中也有显著改进

Abstract: Developing high-quality text-to-speech (TTS) systems for low-resource
languages is challenging due to the scarcity of paired text and speech data. In
contrast, automatic speech recognition (ASR) models for such languages are
often more accessible, owing to large-scale multilingual pre-training efforts.
We propose a framework based on Group Relative Policy Optimization (GRPO) to
adapt an autoregressive, multilingual TTS model to new languages. Our method
first establishes a language-agnostic foundation for TTS synthesis by training
a multilingual baseline with International Phonetic Alphabet (IPA) tokens.
Next, we fine-tune this model on limited paired data of the new languages to
capture the target language's prosodic features. Finally, we apply GRPO to
optimize the model using only unpaired text and speaker prompts, guided by a
multi-objective reward from pretrained ASR, speaker verification, and audio
quality estimation models. Experiments demonstrate that this pipeline produces
intelligible and speaker-consistent speech in low-resource languages,
substantially outperforming fine-tuning alone. Furthermore, our GRPO-based
framework also improves TTS performance in high-resource languages, surpassing
offline alignment methods such as Direct Preference Optimization (DPO) yielding
superior intelligibility, speaker similarity, and audio quality.

</details>


### [95] [Retrieval-of-Thought: Efficient Reasoning via Reusing Thoughts](https://arxiv.org/abs/2509.21743)
*Ammar Ahmed,Azal Ahmad Khan,Ayaan Ahmad,Sheng Di,Zirui Liu,Ali Anwar*

Main category: cs.AI

TL;DR: RoT通过检索和重用先前的推理步骤来构建动态模板，减少推理时的输出token数量，在保持准确性的同时显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过生成长推理链来提高准确性，但这会增加延迟和成本，因此需要在推理时提高效率。

Method: 提出RoT方法，将推理步骤组织成带有顺序和语义边的思想图，通过检索相关节点和奖励引导的遍历来组装问题特定的模板。

Result: RoT在多个模型和推理基准测试中，输出token减少高达40%，推理延迟降低82%，成本降低59%，同时保持准确性。

Conclusion: RoT通过检索构建动态模板，为高效的大型推理模型推理建立了可扩展的范式。

Abstract: Large reasoning models improve accuracy by producing long reasoning traces,
but this inflates latency and cost, motivating inference-time efficiency. We
propose Retrieval-of-Thought (RoT), which reuses prior reasoning as composable
``thought" steps to guide new problems. RoT organizes steps into a thought
graph with sequential and semantic edges to enable fast retrieval and flexible
recombination. At inference, RoT retrieves query-relevant nodes and applies
reward-guided traversal to assemble a problem-specific template that guides
generation. This dynamic template reuse reduces redundant exploration and,
therefore, reduces output tokens while preserving accuracy. We evaluate RoT on
reasoning benchmarks with multiple models, measuring accuracy, token usage,
latency, and memory overhead. Findings show small prompt growth but substantial
efficiency gains, with RoT reducing output tokens by up to 40%, inference
latency by 82%, and cost by 59% while maintaining accuracy. RoT establishes a
scalable paradigm for efficient LRM reasoning via dynamic template construction
through retrieval.

</details>


### [96] [Lifelong Learning with Behavior Consolidation for Vehicle Routing](https://arxiv.org/abs/2509.21765)
*Jiyuan Pei,Yi Mei,Jialin Liu,Mengjie Zhang,Xin Yao*

Main category: cs.AI

TL;DR: 本文提出了一种用于神经VRP求解器的终身学习框架LLR-BC，通过行为整合方法解决多任务学习中的灾难性遗忘问题，同时保持模型的可塑性。


<details>
  <summary>Details</summary>
Motivation: 现有神经求解器通常基于预定义问题分布和规模进行一次性训练，当新任务出现时，要么依赖零样本泛化（效果不佳），要么进行微调（导致灾难性遗忘）。需要一种能够持续学习多个任务而不遗忘先前知识的解决方案。

Method: 提出LLR-BC框架，通过行为整合方法将新任务训练的求解器行为与缓冲区中的先前行为进行对齐，并为低置信度决策分配更大的整合权重，以关注关键经验。

Result: 在容量约束车辆路径问题和旅行商问题上的大量实验表明，LLR-BC在终身学习设置下能够有效训练高性能神经求解器，解决灾难性遗忘问题，保持模型可塑性，并提升零样本泛化能力。

Conclusion: LLR-BC为神经VRP求解器提供了一种有效的终身学习解决方案，能够在多任务环境中持续学习而不遗忘先前知识，具有实际应用价值。

Abstract: Recent neural solvers have demonstrated promising performance in learning to
solve routing problems. However, existing studies are primarily based on
one-off training on one or a set of predefined problem distributions and
scales, i.e., tasks. When a new task arises, they typically rely on either
zero-shot generalization, which may be poor due to the discrepancies between
the new task and the training task(s), or fine-tuning the pretrained solver on
the new task, which possibly leads to catastrophic forgetting of knowledge
acquired from previous tasks. This paper explores a novel lifelong learning
paradigm for neural VRP solvers, where multiple tasks with diverse
distributions and scales arise sequentially over time. Solvers are required to
effectively and efficiently learn to solve new tasks while maintaining their
performance on previously learned tasks. Consequently, a novel framework called
Lifelong Learning Router with Behavior Consolidation (LLR-BC) is proposed.
LLR-BC consolidates prior knowledge effectively by aligning behaviors of the
solver trained on a new task with the buffered ones in a decision-seeking way.
To encourage more focus on crucial experiences, LLR-BC assigns greater
consolidated weights to decisions with lower confidence. Extensive experiments
on capacitated vehicle routing problems and traveling salesman problems
demonstrate LLR-BC's effectiveness in training high-performance neural solvers
in a lifelong learning setting, addressing the catastrophic forgetting issue,
maintaining their plasticity, and improving zero-shot generalization ability.

</details>


### [97] [UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios](https://arxiv.org/abs/2509.21766)
*Haotian Luo,Huaisong Zhang,Xuelin Zhang,Haoyu Wang,Zeyu Qin,Wenjie Lu,Guozheng Ma,Haiying He,Yingsha Xie,Qiyang Zhou,Zixuan Hu,Hongze Mi,Yibo Wang,Naiqiang Tan,Hong Chen,Yi R. Fung,Chun Yuan,Li Shen*

Main category: cs.AI

TL;DR: 提出了UltraHorizon基准，用于评估自主代理在长视野、部分可观测场景下的持续推理、规划、记忆管理和工具使用能力，发现在这些复杂任务中LLM代理表现不佳，存在上下文锁定和功能能力差距两大问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注短视野、完全可观测任务，而现实世界中的关键任务（如软件开发、商业投资、科学发现）通常具有长视野和部分可观测特性，需要系统性的评估方法来衡量代理在这些复杂场景下的核心能力。

Method: 通过探索任务在三个不同环境中验证核心能力，设计长视野发现任务，要求代理通过持续推理、规划、记忆和工具管理以及与环境交互来迭代揭示隐藏规则。

Result: 在最重规模设置下，轨迹平均超过20万token和400+工具调用，标准配置下也超过3.5万token和60+工具调用。实验显示LLM代理在这些设置下表现不佳，而人类参与者得分更高，表明代理在长视野能力上存在持续差距。

Conclusion: 简单扩展在长视野任务中失败，代理存在上下文锁定和功能性基础能力差距两大主要问题，揭示了当前自主代理在复杂现实任务中的局限性。

Abstract: Autonomous agents have recently achieved remarkable progress across diverse
domains, yet most evaluations focus on short-horizon, fully observable tasks.
In contrast, many critical real-world tasks, such as large-scale software
development, commercial investment, and scientific discovery, unfold in
long-horizon and partially observable scenarios where success hinges on
sustained reasoning, planning, memory management, and tool use. Existing
benchmarks rarely capture these long-horizon challenges, leaving a gap in
systematic evaluation. To bridge this gap, we introduce \textbf{UltraHorizon} a
novel benchmark that measures the foundational capabilities essential for
complex real-world challenges. We use exploration as a unifying task across
three distinct environments to validate these core competencies. Agents are
designed in long-horizon discovery tasks where they must iteratively uncover
hidden rules through sustained reasoning, planning, memory and tools
management, and interaction with environments. Under the heaviest scale
setting, trajectories average \textbf{200k+} tokens and \textbf{400+} tool
calls, whereas in standard configurations they still exceed \textbf{35k} tokens
and involve more than \textbf{60} tool calls on average. Our extensive
experiments reveal that LLM-agents consistently underperform in these settings,
whereas human participants achieve higher scores, underscoring a persistent gap
in agents' long-horizon abilities. We also observe that simple scaling fails in
our task. To better illustrate the failure of agents, we conduct an in-depth
analysis of collected trajectories. We identify eight types of errors and
attribute them to two primary causes: in-context locking and functional
fundamental capability gaps.
\href{https://github.com/StarDewXXX/UltraHorizon}{Our code will be available
here.}

</details>


### [98] [Benchmarking MLLM-based Web Understanding: Reasoning, Robustness and Safety](https://arxiv.org/abs/2509.21782)
*Junliang Liu,Jingyu Xiao,Wenxin Tang,Wenxuan Wang,Zhixian Wang,Minrui Zhang,Shuanghe Yu*

Main category: cs.AI

TL;DR: 提出了WebRSSBench基准测试，用于全面评估多模态大语言模型在网页理解中的推理、鲁棒性和安全性能力，包含8个任务和3799个问答对。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注视觉感知或UI代码生成，缺乏对端到端网页应用所需的推理、鲁棒性和安全性能力的评估。

Method: 从729个网站构建包含3799个问答对的基准测试，涵盖位置关系推理、颜色鲁棒性、安全关键检测等8个任务，采用标准化提示、确定性评估脚本和多阶段质量控制。

Result: 评估12个MLLM模型发现，模型在真实布局的组合和跨元素推理方面仍有困难，面对UI和内容扰动时鲁棒性有限，在识别和避免安全关键操作方面过于保守。

Conclusion: WebRSSBench揭示了当前MLLM在网页理解方面的显著差距，为未来模型开发提供了重要基准。

Abstract: Multimodal large language models (MLLMs) are increasingly positioned as AI
collaborators for building complex web-related applications like GUI agents and
front-end code generation. However, existing benchmarks largely emphasize
visual perception or UI code generation, showing insufficient evaluation on the
reasoning, robustness and safety capability required for end-to-end web
applications. To bridge the gap, we introduce a comprehensive web understanding
benchmark, named WebRSSBench, that jointly evaluates Reasoning, Robustness, and
Safety across eight tasks, such as position relationship reasoning, color
robustness, and safety critical detection, etc. The benchmark is constructed
from 729 websites and contains 3799 question answer pairs that probe multi-step
inference over page structure, text, widgets, and safety-critical interactions.
To ensure reliable measurement, we adopt standardized prompts, deterministic
evaluation scripts, and multi-stage quality control combining automatic checks
with targeted human verification. We evaluate 12 MLLMs on WebRSSBench. The
results reveal significant gaps, models still struggle with compositional and
cross-element reasoning over realistic layouts, show limited robustness when
facing perturbations in user interfaces and content such as layout
rearrangements or visual style shifts, and are rather conservative in
recognizing and avoiding safety critical or irreversible actions. Our code is
available at https://github.com/jinliang-byte/webssrbench.

</details>


### [99] [D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents](https://arxiv.org/abs/2509.21799)
*Hongze Mi,Yibo Feng,Wenjie Lu,Yuqi Wang,Jinyuan Li,Song Cao,He Cui,Tengfei Tian,Xuelin Zhang,Haotian Luo,Di Sun,Naiqiang Tan,Gang Pan*

Main category: cs.AI

TL;DR: D-Artemis是一个基于人类认知循环（思考、对齐、反思）的GUI代理框架，通过应用特定提示检索、预执行对齐和状态反思来提升多模态大语言模型在GUI任务中的性能，无需复杂轨迹数据训练。


<details>
  <summary>Details</summary>
Motivation: 解决当前GUI代理面临的三个关键挑战：端到端训练的数据瓶颈、延迟错误检测的高成本以及矛盾指导的风险。

Method: 采用思考-对齐-反思的认知循环框架，包含应用特定提示检索、预执行对齐（包含思想-行动一致性检查和行动修正代理）以及执行后状态反思代理。

Result: 在两个主要基准测试中达到最先进水平：AndroidWorld上75.8%的成功率，ScreenSpot-V2上96.8%的成功率。消融研究证实了各组件的重要贡献。

Conclusion: D-Artemis框架能有效增强通用多模态大语言模型在GUI任务中的能力，具有强泛化性，无需复杂轨迹数据集训练。

Abstract: Graphical User Interface (GUI) agents aim to automate a wide spectrum of
human tasks by emulating user interaction. Despite rapid advancements, current
approaches are hindered by several critical challenges: data bottleneck in
end-to-end training, high cost of delayed error detection, and risk of
contradictory guidance. Inspired by the human cognitive loop of Thinking,
Alignment, and Reflection, we present D-Artemis -- a novel deliberative
framework in this paper. D-Artemis leverages a fine-grained, app-specific tip
retrieval mechanism to inform its decision-making process. It also employs a
proactive Pre-execution Alignment stage, where Thought-Action Consistency (TAC)
Check module and Action Correction Agent (ACA) work in concert to mitigate the
risk of execution failures. A post-execution Status Reflection Agent (SRA)
completes the cognitive loop, enabling strategic learning from experience.
Crucially, D-Artemis enhances the capabilities of general-purpose Multimodal
large language models (MLLMs) for GUI tasks without the need for training on
complex trajectory datasets, demonstrating strong generalization. D-Artemis
establishes new state-of-the-art (SOTA) results across both major benchmarks,
achieving a 75.8% success rate on AndroidWorld and 96.8% on ScreenSpot-V2.
Extensive ablation studies further demonstrate the significant contribution of
each component to the framework.

</details>


### [100] [ProRe: A Proactive Reward System for GUI Agents via Reasoner-Actor Collaboration](https://arxiv.org/abs/2509.21823)
*Gaole Dai,Shiqi Jiang,Ting Cao,Yuqing Yang,Yuanchun Li,Rui Tan,Mo Li,Lili Qiu*

Main category: cs.AI

TL;DR: ProRe是一个主动奖励系统，通过通用推理器和领域特定评估器主动与环境交互来改进GUI智能体的奖励评估准确性


<details>
  <summary>Details</summary>
Motivation: 现有基于规则或模型的奖励方法难以泛化到GUI智能体，因为缺乏真实轨迹或应用数据库，而静态轨迹的LLM评估方法准确率有限

Method: 使用通用推理器调度针对性状态探测任务，评估器智能体通过主动与环境交互收集额外观察，从而分配更准确可验证的奖励

Result: 在3000多个轨迹上的实验显示，ProRe将奖励准确率和F1分数分别提升5.3%和19.4%，与最先进策略智能体集成可将成功率提升22.4%

Conclusion: ProRe通过主动环境交互显著改进了GUI智能体的奖励评估准确性，为训练和评估提供了更可靠的奖励信号

Abstract: Reward is critical to the evaluation and training of large language models
(LLMs). However, existing rule-based or model-based reward methods struggle to
generalize to GUI agents, where access to ground-truth trajectories or
application databases is often unavailable, and static trajectory-based
LLM-as-a-Judge approaches suffer from limited accuracy. To address these
challenges, we propose ProRe, a proactive reward system that leverages a
general-purpose reasoner and domain-specific evaluator agents (actors). The
reasoner schedules targeted state probing tasks, which the evaluator agents
then execute by actively interacting with the environment to collect additional
observations. This enables the reasoner to assign more accurate and verifiable
rewards to GUI agents. Empirical results on over 3K trajectories demonstrate
that ProRe improves reward accuracy and F1 score by up to 5.3% and 19.4%,
respectively. Furthermore, integrating ProRe with state-of-the-art policy
agents yields a success rate improvement of up to 22.4%.

</details>


### [101] [DS-STAR: Data Science Agent via Iterative Planning and Verification](https://arxiv.org/abs/2509.21825)
*Jaehyun Nam,Jinsung Yoon,Jiefeng Chen,Jinwoo Shin,Tomas Pfister*

Main category: cs.AI

TL;DR: DS-STAR是一个新颖的数据科学智能体，通过自动数据文件分析、LLM验证步骤和顺序规划机制，解决了LLM在处理异构数据格式和生成分析计划方面的困难，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 数据科学任务复杂，涉及探索多个数据源并综合发现。虽然LLM在自动化这一过程方面显示出潜力，但它们在处理异构数据格式和生成次优分析计划方面存在困难，因为验证计划充分性在没有真实标签的情况下本质上是困难的。

Method: DS-STAR包含三个关键贡献：(1) 自动探索和提取多种数据格式上下文的数据文件分析模块；(2) LLM评估分析计划充分性的验证步骤；(3) 从简单可执行计划开始，基于反馈迭代优化直到验证充分的顺序规划机制。

Result: 实验显示DS-STAR在三个具有挑战性的基准测试（DABStep、KramaBench和DA-Code）中达到最先进性能，特别是在需要处理多个异构格式数据文件的困难任务上显著优于基线方法。

Conclusion: DS-STAR通过其迭代优化方法能够可靠地导航涉及多样化数据源的复杂分析，为数据科学任务的自动化提供了有效的解决方案。

Abstract: Data science, which transforms raw data into actionable insights, is critical
for data-driven decision-making. However, these tasks are often complex,
involving steps for exploring multiple data sources and synthesizing findings
to deliver insightful answers. While large language models (LLMs) show
significant promise in automating this process, they often struggle with
heterogeneous data formats and generate sub-optimal analysis plans, as
verifying plan sufficiency is inherently difficult without ground-truth labels
for such open-ended tasks. To overcome these limitations, we introduce DS-STAR,
a novel data science agent. Specifically, DS-STAR makes three key
contributions: (1) a data file analysis module that automatically explores and
extracts context from diverse data formats, including unstructured types; (2) a
verification step where an LLM-based judge evaluates the sufficiency of the
analysis plan at each stage; and (3) a sequential planning mechanism that
starts with a simple, executable plan and iteratively refines it based on the
DS-STAR's feedback until its sufficiency is verified. This iterative refinement
allows DS-STAR to reliably navigate complex analyses involving diverse data
sources. Our experiments show that DS-STAR achieves state-of-the-art
performance across three challenging benchmarks: DABStep, KramaBench, and
DA-Code. Moreover, DS-STAR particularly outperforms baselines on hard tasks
that require processing multiple data files with heterogeneous formats.

</details>


### [102] [Axiomatic Choice and the Decision-Evaluation Paradox](https://arxiv.org/abs/2509.21836)
*Ben Abramowitz,Nicholas Mattei*

Main category: cs.AI

TL;DR: 提出了一个基于公理的决策建模框架，揭示了决策-评估悖论，并指出在训练决策模型和应用公理时需要格外谨慎。


<details>
  <summary>Details</summary>
Motivation: 研究决策公理（如伦理约束）在决策制定和评估中的结构性特性，以及它们之间的潜在冲突。

Method: 引入一个决策建模框架，定义基于结构特性的决策公理分类法，分析决策公理在制定和评估决策时的应用。

Result: 发现决策-评估悖论的存在，表明使用公理制定决策与使用公理评估决策之间存在紧张关系。

Conclusion: 决策-评估悖论在现实公理结构中普遍存在，因此在训练决策模型和应用公理时需要特别小心。

Abstract: We introduce a framework for modeling decisions with axioms that are
statements about decisions, e.g., ethical constraints. Using our framework we
define a taxonomy of decision axioms based on their structural properties and
demonstrate a tension between the use of axioms to make decisions and the use
of axioms to evaluate decisions which we call the Decision-Evaluation Paradox.
We argue that the Decision-Evaluation Paradox arises with realistic axiom
structures, and the paradox illuminates why one must be exceptionally careful
when training models on decision data or applying axioms to make and evaluate
decisions.

</details>


### [103] [DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents](https://arxiv.org/abs/2509.21842)
*Yansong Ning,Rui Liu,Jun Wang,Kai Chen,Wei Li,Jun Fang,Kan Zheng,Naiqiang Tan,Hao Liu*

Main category: cs.AI

TL;DR: DeepTravel是一个端到端的强化学习框架，用于构建自主旅行规划代理，能够自主规划、执行工具并反思工具响应，通过多步推理来探索、验证和优化中间行动。


<details>
  <summary>Details</summary>
Motivation: 现有旅行规划代理依赖手工制作的提示和固定的代理工作流程，限制了代理的灵活性和自主性。

Method: 构建沙盒环境缓存交通、住宿和POI数据；开发分层奖励建模系统（轨迹级验证器和轮次级验证器）；提出回复增强强化学习方法，从失败经验缓冲区定期重放。

Result: 在滴滴企业解决方案应用上部署，评估显示DeepTravel使小型LLM（如Qwen3 32B）在旅行规划任务中显著优于前沿LLM（如OpenAI o1、o3和DeepSeek R1）。

Conclusion: DeepTravel框架成功构建了自主旅行规划代理，通过强化学习和分层奖励系统提升了代理的规划能力和效率。

Abstract: Travel planning (TP) agent has recently worked as an emerging building block
to interact with external tools and resources for travel itinerary generation,
ensuring enjoyable user experience. Despite its benefits, existing studies rely
on hand craft prompt and fixed agent workflow, hindering more flexible and
autonomous TP agent. This paper proposes DeepTravel, an end to end agentic
reinforcement learning framework for building autonomous travel planning agent,
capable of autonomously planning, executing tools, and reflecting on tool
responses to explore, verify, and refine intermediate actions in multi step
reasoning. To achieve this, we first construct a robust sandbox environment by
caching transportation, accommodation and POI data, facilitating TP agent
training without being constrained by real world APIs limitations (e.g.,
inconsistent outputs). Moreover, we develop a hierarchical reward modeling
system, where a trajectory level verifier first checks spatiotemporal
feasibility and filters unsatisfied travel itinerary, and then the turn level
verifier further validate itinerary detail consistency with tool responses,
enabling efficient and precise reward service. Finally, we propose the reply
augmented reinforcement learning method that enables TP agent to periodically
replay from a failures experience buffer, emerging notable agentic capacity. We
deploy trained TP agent on DiDi Enterprise Solutions App and conduct
comprehensive online and offline evaluations, demonstrating that DeepTravel
enables small size LLMs (e.g., Qwen3 32B) to significantly outperform existing
frontier LLMs such as OpenAI o1, o3 and DeepSeek R1 in travel planning tasks.

</details>


### [104] [TRACE: Learning to Compute on Graphs](https://arxiv.org/abs/2509.21886)
*Ziyang Zheng,Jiaying Zhu,Jingyi Zhou,Qiang Xu*

Main category: cs.AI

TL;DR: TRACE提出了一个新的图表示学习范式，通过层次化Transformer架构和函数偏移学习目标，解决了传统MPNN和Transformer在计算图建模中的架构不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 传统消息传递神经网络和Transformer在计算图建模中存在架构不匹配，无法捕捉计算的位置感知和层次化特性，需要新的范式来解决这一根本挑战。

Method: 采用层次化Transformer架构模拟逐步计算流程，并引入函数偏移学习目标，将复杂全局函数预测分解为预测真实函数与简单局部近似之间的差异。

Result: 在电子电路等复杂计算图上，TRACE在全面基准测试中显著优于所有现有架构。

Conclusion: 架构对齐的主干网络和解耦学习目标构成了更稳健的计算图学习范式，为解决学习计算这一根本挑战提供了有效方案。

Abstract: Learning to compute, the ability to model the functional behavior of a
computational graph, is a fundamental challenge for graph representation
learning. Yet, the dominant paradigm is architecturally mismatched for this
task. This flawed assumption, central to mainstream message passing neural
networks (MPNNs) and their conventional Transformer-based counterparts,
prevents models from capturing the position-aware, hierarchical nature of
computation. To resolve this, we introduce \textbf{TRACE}, a new paradigm built
on an architecturally sound backbone and a principled learning objective.
First, TRACE employs a Hierarchical Transformer that mirrors the step-by-step
flow of computation, providing a faithful architectural backbone that replaces
the flawed permutation-invariant aggregation. Second, we introduce
\textbf{function shift learning}, a novel objective that decouples the learning
problem. Instead of predicting the complex global function directly, our model
is trained to predict only the \textit{function shift}, the discrepancy between
the true global function and a simple local approximation that assumes input
independence. We validate this paradigm on electronic circuits, one of the most
complex and economically critical classes of computational graphs. Across a
comprehensive suite of benchmarks, TRACE substantially outperforms all prior
architectures. These results demonstrate that our architecturally-aligned
backbone and decoupled learning objective form a more robust paradigm for the
fundamental challenge of learning to compute on graphs.

</details>


### [105] [GenesisGeo: Technical Report](https://arxiv.org/abs/2509.21896)
*Minfeng Zhu,Zi Wang,Sizhe Ji,Zhengtong Du,Junming Ke,Xiao Deng,Zanlang Yin,Xiuqi Huang,Heyu Wang,Wei Chen*

Main category: cs.AI

TL;DR: GenesisGeo是一个自动几何定理证明器，开源了2180万个几何问题数据集，通过定理匹配将符号推理引擎DDARN加速120倍，使用Qwen3-0.6B-Base模型在IMO-AG-30基准上取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 开发高效的自动几何定理证明系统，解决大规模几何问题，提升符号推理效率，达到国际数学奥林匹克竞赛级别的证明能力。

Method: 采用神经符号方法，结合定理匹配技术加速符号推理引擎DDARN（120倍加速），使用C++实现核心组件，基于Qwen3-0.6B-Base模型构建证明器。

Result: 在IMO-AG-30基准测试中，单模型解决24个问题（银牌水平），双模型集成解决26个问题（金牌水平）；开源了包含2180万个几何问题的大规模数据集，其中300多万个包含辅助构造。

Conclusion: GenesisGeo证明了神经符号方法在几何定理证明中的有效性，通过优化符号推理引擎和利用大型语言模型，达到了国际数学奥林匹克竞赛金牌级别的性能。

Abstract: We present GenesisGeo, an automated theorem prover in Euclidean geometry. We
have open-sourced a large-scale geometry dataset of 21.8 million geometric
problems, over 3 million of which contain auxiliary constructions. Specially,
we significantly accelerate the symbolic deduction engine DDARN by 120x through
theorem matching, combined with a C++ implementation of its core components.
Furthermore, we build our neuro-symbolic prover, GenesisGeo, upon
Qwen3-0.6B-Base, which solves 24 of 30 problems (IMO silver medal level) in the
IMO-AG-30 benchmark using a single model, and achieves 26 problems (IMO gold
medal level) with a dual-model ensemble.

</details>


### [106] [DyRo-MCTS: A Robust Monte Carlo Tree Search Approach to Dynamic Job Shop Scheduling](https://arxiv.org/abs/2509.21902)
*Ruiqi Chen,Yi Mei,Fangfang Zhang,Mengjie Zhang*

Main category: cs.AI

TL;DR: 提出了DyRo-MCTS方法，将动作鲁棒性估计集成到MCTS中，用于动态作业车间调度问题，以应对新作业到达带来的不确定性。


<details>
  <summary>Details</summary>
Motivation: 动态作业车间调度面临新作业频繁到达的干扰，现有离线学习策略不完美，而在线规划时基于不完整信息的决策容易受到扰动影响。

Method: DyRo-MCTS方法在MCTS中集成动作鲁棒性估计，引导生产环境向既能产生良好调度结果又能轻松适应未来作业到达的状态发展。

Result: 实验表明DyRo-MCTS显著提升了离线学习策略的性能，且在线规划时间增加可忽略不计，在各种调度场景中始终优于普通MCTS。

Conclusion: DyRo-MCTS通过做出鲁棒的调度决策，在扰动下实现了长期可持续的性能提升。

Abstract: Dynamic job shop scheduling, a fundamental combinatorial optimisation problem
in various industrial sectors, poses substantial challenges for effective
scheduling due to frequent disruptions caused by the arrival of new jobs.
State-of-the-art methods employ machine learning to learn scheduling policies
offline, enabling rapid responses to dynamic events. However, these offline
policies are often imperfect, necessitating the use of planning techniques such
as Monte Carlo Tree Search (MCTS) to improve performance at online decision
time. The unpredictability of new job arrivals complicates online planning, as
decisions based on incomplete problem information are vulnerable to
disturbances. To address this issue, we propose the Dynamic Robust MCTS
(DyRo-MCTS) approach, which integrates action robustness estimation into MCTS.
DyRo-MCTS guides the production environment toward states that not only yield
good scheduling outcomes but are also easily adaptable to future job arrivals.
Extensive experiments show that DyRo-MCTS significantly improves the
performance of offline-learned policies with negligible additional online
planning time. Moreover, DyRo-MCTS consistently outperforms vanilla MCTS across
various scheduling scenarios. Further analysis reveals that its ability to make
robust scheduling decisions leads to long-term, sustainable performance gains
under disturbances.

</details>


### [107] [Outlier Detection in Plantar Pressure: Human-Centered Comparison of Statistical Parametric Mapping and Explainable Machine Learning](https://arxiv.org/abs/2509.21943)
*Carlo Dindorf,Jonas Dully,Steven Simon,Dennis Perchthaler,Stephan Becker,Hannah Ehmann,Kjell Heitmann,Bernd Stetter,Christian Diers,Michael Fröhlich*

Main category: cs.AI

TL;DR: 比较SPM统计参数映射和可解释机器学习方法在足底压力数据异常检测中的表现，发现ML方法准确率更高，但SPM解释更简单易懂。


<details>
  <summary>Details</summary>
Motivation: 足底压力映射在临床诊断和运动科学中很重要，但大型异构数据集常包含技术错误或程序不一致导致的异常值。SPM提供可解释分析但对对齐敏感，其鲁棒异常检测能力尚不明确。

Method: 使用多中心数据，通过专家共识标注并添加合成异常，共798个有效样本和2000个异常值。评估(i)非参数、配准依赖的SPM方法和(ii)使用SHAP解释的卷积神经网络(CNN)。通过嵌套交叉验证评估性能，通过语义差异调查评估解释质量。

Result: ML模型达到高准确率并优于SPM，SPM误分类了临床有意义的变异并遗漏了真实异常。专家认为SPM和SHAP解释都清晰、有用且可信，但SPM被认为复杂度较低。

Conclusion: SPM和可解释ML在足底压力数据自动异常检测中具有互补潜力，可解释性对于将复杂模型输出转化为可解释见解以有效支持决策制定至关重要。

Abstract: Plantar pressure mapping is essential in clinical diagnostics and sports
science, yet large heterogeneous datasets often contain outliers from technical
errors or procedural inconsistencies. Statistical Parametric Mapping (SPM)
provides interpretable analyses but is sensitive to alignment and its capacity
for robust outlier detection remains unclear. This study compares an SPM
approach with an explainable machine learning (ML) approach to establish
transparent quality-control pipelines for plantar pressure datasets. Data from
multiple centers were annotated by expert consensus and enriched with synthetic
anomalies resulting in 798 valid samples and 2000 outliers. We evaluated (i) a
non-parametric, registration-dependent SPM approach and (ii) a convolutional
neural network (CNN), explained using SHapley Additive exPlanations (SHAP).
Performance was assessed via nested cross-validation; explanation quality via a
semantic differential survey with domain experts. The ML model reached high
accuracy and outperformed SPM, which misclassified clinically meaningful
variations and missed true outliers. Experts perceived both SPM and SHAP
explanations as clear, useful, and trustworthy, though SPM was assessed less
complex. These findings highlight the complementary potential of SPM and
explainable ML as approaches for automated outlier detection in plantar
pressure data, and underscore the importance of explainability in translating
complex model outputs into interpretable insights that can effectively inform
decision-making.

</details>


### [108] [CoBel-World: Harnessing LLM Reasoning to Build a Collaborative Belief World for Optimizing Embodied Multi-Agent Collaboration](https://arxiv.org/abs/2509.21981)
*Zhimin Wang,Shaokang He,Duo Wu,Jinghe Wang,Linjia Kang,Jing Yu,Zhi Wang*

Main category: cs.AI

TL;DR: CoBel-World框架通过为LLM智能体配备协作信念世界，显式建模物理环境和协作伙伴的心理状态，显著减少通信成本22-60%，提高任务完成效率4-28%。


<details>
  <summary>Details</summary>
Motivation: 现有LLM协作框架忽视了动态意图推理能力，导致计划不一致和通信冗余，降低协作效率。需要解决部分可观测环境下避免误协调和冗余通信的问题。

Method: 使用符号信念语言将开放世界任务知识解析为结构化信念，通过LLM推理进行零样本贝叶斯式信念更新，主动检测潜在误协调并自适应通信。

Result: 在TDW-MAT和C-WAH基准测试中，通信成本减少22-60%，任务完成效率提升4-28%。

Conclusion: 显式的意图感知信念建模对于基于LLM的多智能体系统实现高效、类人协作至关重要。

Abstract: Effective real-world multi-agent collaboration requires not only accurate
planning but also the ability to reason about collaborators' intents -- a
crucial capability for avoiding miscoordination and redundant communication
under partial observable environments. Due to their strong planning and
reasoning capabilities, large language models (LLMs) have emerged as promising
autonomous agents for collaborative task solving. However, existing
collaboration frameworks for LLMs overlook their reasoning potential for
dynamic intent inference, and thus produce inconsistent plans and redundant
communication, reducing collaboration efficiency. To bridge this gap, we
propose CoBel-World, a novel framework that equips LLM agents with a
collaborative belief world -- an internal representation jointly modeling the
physical environment and collaborators' mental states. CoBel-World enables
agents to parse open-world task knowledge into structured beliefs via a
symbolic belief language, and perform zero-shot Bayesian-style belief updates
through LLM reasoning. This allows agents to proactively detect potential
miscoordination (e.g., conflicting plans) and communicate adaptively. Evaluated
on challenging embodied benchmarks (i.e., TDW-MAT and C-WAH), CoBel-World
significantly reduces communication costs by 22-60% and improves task
completion efficiency by 4-28% compared to the strongest baseline. Our results
show that explicit, intent-aware belief modeling is essential for efficient and
human-like collaboration in LLM-based multi-agent systems.

</details>


### [109] [RISK: A Framework for GUI Agents in E-commerce Risk Management](https://arxiv.org/abs/2509.21982)
*Renqi Chen,Zeyin Tao,Jianming Guo,Jingzhe Zhu,Yiheng Peng,Qingqing Sun,Tianyi Zhang,Shuai Chen*

Main category: cs.AI

TL;DR: RISK框架为电商风险管理构建GUI代理，包含数据集、基准测试和强化微调框架，在单步和多步交互任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统爬虫方法和现有GUI代理无法处理电商风险管理所需的多步骤、有状态交互，这些代理通常局限于单步任务，缺乏处理动态交互内容的能力。

Method: RISK框架包含三个组件：RISK-Data数据集（8,492单步和2,386多步交互轨迹）、RISK-Bench基准测试（802单步和320多步轨迹）、RISK-R1强化微调框架（考虑输出格式、单步级、多步级和任务级四个方面的奖励机制）。

Result: RISK-R1在离线单步任务中提升6.8%，离线多步任务中提升8.8%，在线评估中达到70.5%的最高任务成功率。

Conclusion: RISK为自动化复杂网络交互提供了可扩展的领域特定解决方案，推动了电商风险管理的技术进步。

Abstract: E-commerce risk management requires aggregating diverse, deeply embedded web
data through multi-step, stateful interactions, which traditional scraping
methods and most existing Graphical User Interface (GUI) agents cannot handle.
These agents are typically limited to single-step tasks and lack the ability to
manage dynamic, interactive content critical for effective risk assessment. To
address this challenge, we introduce RISK, a novel framework designed to build
and deploy GUI agents for this domain. RISK integrates three components: (1)
RISK-Data, a dataset of 8,492 single-step and 2,386 multi-step interaction
trajectories, collected through a high-fidelity browser framework and a
meticulous data curation process; (2) RISK-Bench, a benchmark with 802
single-step and 320 multi-step trajectories across three difficulty levels for
standardized evaluation; and (3) RISK-R1, a R1-style reinforcement fine-tuning
framework considering four aspects: (i) Output Format: Updated format reward to
enhance output syntactic correctness and task comprehension, (ii) Single-step
Level: Stepwise accuracy reward to provide granular feedback during early
training stages, (iii) Multi-step Level: Process reweight to emphasize critical
later steps in interaction sequences, and (iv) Task Level: Level reweight to
focus on tasks of varying difficulty. Experiments show that RISK-R1 outperforms
existing baselines, achieving a 6.8% improvement in offline single-step and an
8.8% improvement in offline multi-step. Moreover, it attains a top task success
rate of 70.5% in online evaluation. RISK provides a scalable, domain-specific
solution for automating complex web interactions, advancing the state of the
art in e-commerce risk management.

</details>


### [110] [Bilinear relational structure fixes reversal curse and enables consistent model editing](https://arxiv.org/abs/2509.21993)
*Dong-Kyum Kim,Minsung Kim,Jea Kwon,Nakyeong Yang,Meeyoung Cha*

Main category: cs.AI

TL;DR: 论文证明反转诅咒不是语言模型的固有缺陷，而是知识编码方式的产物。通过在关系知识图上训练，模型会形成双线性关系结构，从而缓解反转诅咒并实现一致的模型编辑。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型的反转诅咒问题——即模型无法从已学习的"A是B"推断出"B是A"，并探索模型编辑的底层机制。

Method: 从零开始在合成的关系知识图数据集上训练语言模型，分析其隐藏表示中出现的双线性关系结构。

Result: 双线性关系结构显著缓解了反转诅咒，使模型能够推断未见过的反向事实。这种结构在模型编辑中起关键作用，确保编辑能正确传播到相关事实。

Conclusion: 模型编辑的成功不仅取决于编辑算法，更关键的是被修改知识的底层表示几何结构。关系知识训练诱导的双线性表示使语言模型在编辑后能保持逻辑一致性。

Abstract: The reversal curse -- a language model's (LM) inability to infer an unseen
fact ``B is A'' from a learned fact ``A is B'' -- is widely considered a
fundamental limitation. We show that this is not an inherent failure but an
artifact of how models encode knowledge. By training LMs from scratch on a
synthetic dataset of relational knowledge graphs, we demonstrate that bilinear
relational structure emerges in their hidden representations. This structure
substantially alleviates the reversal curse, enabling LMs to infer unseen
reverse facts. Crucially, we also find that this bilinear structure plays a key
role in consistent model editing. When a fact is updated in a LM with this
structure, the edit correctly propagates to its reverse and other logically
dependent facts. In contrast, models lacking this representation not only
suffer from the reversal curse but also fail to generalize edits, further
introducing logical inconsistencies. Our results establish that training on a
relational knowledge dataset induces the emergence of bilinear internal
representations, which in turn enable LMs to behave in a logically consistent
manner after editing. This implies that the success of model editing depends
critically not just on editing algorithms but on the underlying
representational geometry of the knowledge being modified.

</details>


### [111] [GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments](https://arxiv.org/abs/2509.21998)
*Hanlin Zhu,Tianyu Guo,Song Mei,Stuart Russell,Nikhil Ghosh,Alberto Bietti,Jiantao Jiao*

Main category: cs.AI

TL;DR: 提出了GSM-Agent基准测试，评估LLM在需要主动使用工具收集信息来解决小学数学问题时的代理推理能力，发现前沿模型准确率仅67%，并提出工具增强的测试时扩展方法来改进性能。


<details>
  <summary>Details</summary>
Motivation: 当前代理基准测试往往将代理推理与复杂的数学推理、专家级知识等能力混在一起，难以单独评估代理推理能力。需要构建一个能专门评估LLM结合工具使用和推理能力的基准。

Method: 构建GSM-Agent基准，要求LLM代理解决小学数学问题但只提供问题本身，不提供必要的前提信息，需要主动使用工具收集信息。提出代理推理图概念来分析推理模式，并开发工具增强的测试时扩展方法。

Result: 即使是GPT-5这样的前沿模型在GSM-Agent基准上准确率也只有67%。分析发现许多模型缺乏重新访问先前访问节点的能力，这是静态推理中的关键模式。

Conclusion: GSM-Agent基准和代理推理框架有助于未来理解和推进代理推理能力的研究，提出的工具增强方法能有效改进LLM的代理推理性能。

Abstract: As LLMs are increasingly deployed as agents, agentic reasoning - the ability
to combine tool use, especially search, and reasoning - becomes a critical
skill. However, it is hard to disentangle agentic reasoning when evaluated in
complex environments and tasks. Current agent benchmarks often mix agentic
reasoning with challenging math reasoning, expert-level knowledge, and other
advanced capabilities. To fill this gap, we build a novel benchmark, GSM-Agent,
where an LLM agent is required to solve grade-school-level reasoning problems,
but is only presented with the question in the prompt without the premises that
contain the necessary information to solve the task, and needs to proactively
collect that information using tools. Although the original tasks are
grade-school math problems, we observe that even frontier models like GPT-5
only achieve 67% accuracy. To understand and analyze the agentic reasoning
patterns, we propose the concept of agentic reasoning graph: cluster the
environment's document embeddings into nodes, and map each tool call to its
nearest node to build a reasoning path. Surprisingly, we identify that the
ability to revisit a previously visited node, widely taken as a crucial pattern
in static reasoning, is often missing for agentic reasoning for many models.
Based on the insight, we propose a tool-augmented test-time scaling method to
improve LLM's agentic reasoning performance by adding tools to encourage models
to revisit. We expect our benchmark and the agentic reasoning framework to aid
future studies of understanding and pushing the boundaries of agentic
reasoning.

</details>


### [112] [The Thinking Spectrum: An Emperical Study of Tunable Reasoning in LLMs through Model Merging](https://arxiv.org/abs/2509.22034)
*Xiaochong Lan,Yu Zheng,Shiteng Cao,Yong Li*

Main category: cs.AI

TL;DR: 模型融合技术通过组合通用模型和专用推理模型的权重，能够有效创建在推理精度和计算成本之间平衡的LLM谱系，实现可调控的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现实应用中对具有可调推理能力的大型语言模型的需求日益增长，需要能高效生成平衡推理深度和计算成本的模型谱系的方法。

Method: 进行了大规模实证研究，评估多种模型融合技术，通过系统变化融合强度构建精度-效率曲线，分析可调性能空间。

Result: 发现模型融合能有效校准推理精度和token效率之间的权衡，即使父模型权重空间高度不同。识别出帕累托改进实例，融合模型在精度和token消耗上均优于父模型。

Conclusion: 模型融合为创建具有特定推理配置的LLM提供了实用指南，满足多样化应用需求。

Abstract: The growing demand for large language models (LLMs) with tunable reasoning
capabilities in many real-world applications highlights a critical need for
methods that can efficiently produce a spectrum of models balancing reasoning
depth and computational cost. Model merging has emerged as a promising,
training-free technique to address this challenge by arithmetically combining
the weights of a general-purpose model with a specialized reasoning model.
While various merging techniques exist, their potential to create a spectrum of
models with fine-grained control over reasoning abilities remains largely
unexplored. This work presents a large-scale empirical study evaluating a range
of model merging techniques across multiple reasoning benchmarks. We
systematically vary merging strengths to construct accuracy-efficiency curves,
providing the first comprehensive view of the tunable performance landscape.
Our findings reveal that model merging offers an effective and controllable
method for calibrating the trade-off between reasoning accuracy and token
efficiency, even when parent models have highly divergent weight spaces.
Crucially, we identify instances of Pareto Improvement, where a merged model
achieves both higher accuracy and lower token consumption than one of its
parents. Our study provides the first comprehensive analysis of this tunable
space, offering practical guidelines for creating LLMs with specific reasoning
profiles to meet diverse application demands.

</details>


### [113] [A2R: An Asymmetric Two-Stage Reasoning Framework for Parallel Reasoning](https://arxiv.org/abs/2509.22044)
*Ziqi Wang,Boye Niu,Zhongli Li,Linghui Meng,Jing Liu,Zhi Zheng,Tong Xu,Hua Wu,Haifeng Wang,Enhong Chen*

Main category: cs.AI

TL;DR: A2R是一个非对称两阶段推理框架，通过探索器并行生成多个解决方案，再由合成器进行整合，显著提升大型推理模型在复杂任务上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型在单次尝试中的表现与其潜在能力之间存在显著差距，需要通过多路径解决方案来揭示模型的真实潜力。

Method: 提出A2R框架：第一阶段由探索器模型并行生成多个潜在解决方案，第二阶段由合成器模型整合这些参考方案进行更精细的推理。

Result: Qwen3-8B-distill模型性能提升75%；A2R-Efficient变体（4B探索器+8B合成器）性能超越32B单体模型，成本降低30%。

Conclusion: A2R不仅是性能提升框架，更是现实应用中高效实用的解决方案，通过非对称扩展范式实现计算效率优化。

Abstract: Recent Large Reasoning Models have achieved significant improvements in
complex task-solving capabilities by allocating more computation at the
inference stage with a "thinking longer" paradigm. Even as the foundational
reasoning capabilities of models advance rapidly, the persistent gap between a
model's performance in a single attempt and its latent potential, often
revealed only across multiple solution paths, starkly highlights the disparity
between its realized and inherent capabilities. To address this, we present
A2R, an Asymmetric Two-Stage Reasoning framework designed to explicitly bridge
the gap between a model's potential and its actual performance. In this
framework, an "explorer" model first generates potential solutions in parallel
through repeated sampling. Subsequently,a "synthesizer" model integrates these
references for a more refined, second stage of reasoning. This two-stage
process allows computation to be scaled orthogonally to existing sequential
methods. Our work makes two key innovations: First, we present A2R as a
plug-and-play parallel reasoning framework that explicitly enhances a model's
capabilities on complex questions. For example, using our framework, the
Qwen3-8B-distill model achieves a 75% performance improvement compared to its
self-consistency baseline. Second, through a systematic analysis of the
explorer and synthesizer roles, we identify an effective asymmetric scaling
paradigm. This insight leads to A2R-Efficient, a "small-to-big" variant that
combines a Qwen3-4B explorer with a Qwen3-8B synthesizer. This configuration
surpasses the average performance of a monolithic Qwen3-32B model at a nearly
30% lower cost. Collectively, these results show that A2R is not only a
performance-boosting framework but also an efficient and practical solution for
real-world applications.

</details>


### [114] [Generalizing Multi-Objective Search via Objective-Aggregation Functions](https://arxiv.org/abs/2509.22085)
*Hadar Peer,Eyal Weiss,Ron Alterovitz,Oren Salzman*

Main category: cs.AI

TL;DR: 提出了一种多目标搜索的通用问题表述，通过隐藏目标的聚合函数优化解决方案目标，支持标准MOS算法的应用，在多个机器人规划问题中显著优于无目标聚合的算法版本。


<details>
  <summary>Details</summary>
Motivation: 现实机器人系统需要同时平衡多个相互冲突的目标，而现有复杂目标交互的问题表述无法直接使用最先进的多目标搜索算法。

Method: 提出广义问题表述，通过隐藏搜索目标的聚合函数优化解决方案目标，仅需适当扩展核心操作以反映特定聚合函数。

Result: 在导航、操作、医疗系统障碍不确定性规划、检查规划和路线规划等多个机器人规划问题中，扩展后的最先进MOS算法比无目标聚合的原始版本性能提升数个数量级。

Conclusion: 该通用表述支持标准MOS算法的应用，通过适当扩展核心操作即可处理复杂目标聚合问题，在多种机器人规划场景中展现出显著优势。

Abstract: Multi-objective search (MOS) has become essential in robotics, as real-world
robotic systems need to simultaneously balance multiple, often conflicting
objectives. Recent works explore complex interactions between objectives,
leading to problem formulations that do not allow the usage of out-of-the-box
state-of-the-art MOS algorithms. In this paper, we suggest a generalized
problem formulation that optimizes solution objectives via aggregation
functions of hidden (search) objectives. We show that our formulation supports
the application of standard MOS algorithms, necessitating only to properly
extend several core operations to reflect the specific aggregation functions
employed. We demonstrate our approach in several diverse robotics planning
problems, spanning motion-planning for navigation, manipulation and planning fr
medical systems under obstacle uncertainty as well as inspection planning, and
route planning with different road types. We solve the problems using
state-of-the-art MOS algorithms after properly extending their core operations,
and provide empirical evidence that they outperform by orders of magnitude the
vanilla versions of the algorithms applied to the same problems but without
objective aggregation.

</details>


### [115] [Ground-Truthing AI Energy Consumption: Validating CodeCarbon Against External Measurements](https://arxiv.org/abs/2509.22092)
*Raphael Fischer*

Main category: cs.AI

TL;DR: 系统评估AI模型能耗估算工具的准确性，发现现有工具虽然能反映能耗模式，但误差高达40%，并提出了改进指南和验证框架。


<details>
  <summary>Details</summary>
Motivation: 随着AI快速发展带来的环境影响日益显著，现有能耗估算工具虽然易于使用，但存在简化假设和忽略重要因素的问题，需要验证其估算准确性。

Method: 通过比较静态和动态能耗估算方法与真实测量数据，在数百个AI实验中系统评估估算可靠性，并建立验证框架。

Result: 现有估算工具总体上能反映AI能耗模式，但持续存在高达40%的误差，需要提高估算准确性。

Conclusion: 本研究为可持续AI发展提供了能耗估算质量的实证证据，验证了广泛使用的工具，并提出了改进指南和可扩展的验证代码。

Abstract: Although machine learning (ML) and artificial intelligence (AI) present
fascinating opportunities for innovation, their rapid development is also
significantly impacting our environment. In response to growing
resource-awareness in the field, quantification tools such as the ML Emissions
Calculator and CodeCarbon were developed to estimate the energy consumption and
carbon emissions of running AI models. They are easy to incorporate into AI
projects, however also make pragmatic assumptions and neglect important
factors, raising the question of estimation accuracy. This study systematically
evaluates the reliability of static and dynamic energy estimation approaches
through comparisons with ground-truth measurements across hundreds of AI
experiments. Based on the proposed validation framework, investigative insights
into AI energy demand and estimation inaccuracies are provided. While generally
following the patterns of AI energy consumption, the established estimation
approaches are shown to consistently make errors of up to 40%. By providing
empirical evidence on energy estimation quality and errors, this study
establishes transparency and validates widely used tools for sustainable AI
development. It moreover formulates guidelines for improving the
state-of-the-art and offers code for extending the validation to other domains
and tools, thus making important contributions to resource-aware ML and AI
sustainability research.

</details>


### [116] [Log2Plan: An Adaptive GUI Automation Framework Integrated with Task Mining Approach](https://arxiv.org/abs/2509.22137)
*Seoyoung Lee,Seonbin Yoon,Seongbeen Lee,Hyesoo Kim,Joo Yong Sim*

Main category: cs.AI

TL;DR: Log2Plan是一个结合结构化两级规划框架和用户行为日志任务挖掘的GUI任务自动化系统，解决了现有LLM/VLM代理的脆弱泛化、高延迟和有限长序列一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM或VLM的规划-执行代理在GUI自动化中存在脆弱泛化、高延迟和有限长序列一致性问题，依赖单次推理或静态计划使其在UI变化或复杂任务下表现脆弱。

Method: Log2Plan采用结构化两级规划框架：高层规划将用户命令映射到结构化任务字典，低层规划通过实时GUI上下文解释将高层计划转化为具体动作序列，并结合用户行为日志的任务挖掘方法识别用户特定模式。

Result: 在200个真实世界任务上的评估显示，Log2Plan在任务成功率和执行时间方面显著提升，即使在长序列任务中也能保持超过60.0%的成功率。

Conclusion: Log2Plan通过结合两级规划和任务挖掘方法，实现了鲁棒且可适应的GUI自动化，在复杂多步骤工作流中表现出色。

Abstract: GUI task automation streamlines repetitive tasks, but existing LLM or
VLM-based planner-executor agents suffer from brittle generalization, high
latency, and limited long-horizon coherence. Their reliance on single-shot
reasoning or static plans makes them fragile under UI changes or complex tasks.
Log2Plan addresses these limitations by combining a structured two-level
planning framework with a task mining approach over user behavior logs,
enabling robust and adaptable GUI automation. Log2Plan constructs high-level
plans by mapping user commands to a structured task dictionary, enabling
consistent and generalizable automation. To support personalization and reuse,
it employs a task mining approach from user behavior logs that identifies
user-specific patterns. These high-level plans are then grounded into low-level
action sequences by interpreting real-time GUI context, ensuring robust
execution across varying interfaces. We evaluated Log2Plan on 200 real-world
tasks, demonstrating significant improvements in task success rate and
execution time. Notably, it maintains over 60.0% success rate even on
long-horizon task sequences, highlighting its robustness in complex, multi-step
workflows.

</details>


### [117] [Clinical Uncertainty Impacts Machine Learning Evaluations](https://arxiv.org/abs/2509.22242)
*Simone Lionetti,Fabian Gröger,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Ludovic Amruthalingam,Alexander A. Navarini,Marc Pouly*

Main category: cs.AI

TL;DR: 论文主张在医学影像机器学习评估中应考虑标注不确定性，使用概率指标直接对分布进行操作，而非传统的多数投票等聚合方法。


<details>
  <summary>Details</summary>
Motivation: 临床数据集的标注很少是确定的，因为标注者之间存在分歧且置信度不一致。传统聚合方法（如多数投票）掩盖了这种变异性，影响模型排名的准确性。

Method: 提出使用概率指标来明确考虑标注不确定性，这些指标可以直接对分布进行操作，适用于简单计数、主观置信度评级或概率响应模型等各种标注生成过程。

Result: 在医学影像基准测试的简单实验中，考虑二元标签的置信度显著影响模型排名，表明不确定性感知评估的重要性。

Conclusion: 呼吁社区发布数据集的原始标注，并采用不确定性感知评估方法，使性能估计能更好地反映临床数据的特性。

Abstract: Clinical dataset labels are rarely certain as annotators disagree and
confidence is not uniform across cases. Typical aggregation procedures, such as
majority voting, obscure this variability. In simple experiments on medical
imaging benchmarks, accounting for the confidence in binary labels
significantly impacts model rankings. We therefore argue that machine-learning
evaluations should explicitly account for annotation uncertainty using
probabilistic metrics that directly operate on distributions. These metrics can
be applied independently of the annotations' generating process, whether
modeled by simple counting, subjective confidence ratings, or probabilistic
response models. They are also computationally lightweight, as closed-form
expressions have linear-time implementations once examples are sorted by model
score. We thus urge the community to release raw annotations for datasets and
to adopt uncertainty-aware evaluation so that performance estimates may better
reflect clinical data.

</details>


### [118] [Evaluating LLMs for Combinatorial Optimization: One-Phase and Two-Phase Heuristics for 2D Bin-Packing](https://arxiv.org/abs/2509.22255)
*Syed Mahbubul Huq,Daniel Brito,Daniel Sikar,Rajesh Mojumder*

Main category: cs.AI

TL;DR: 提出了评估LLM在组合优化中能力的框架，针对2D装箱问题，将LLM与进化算法结合迭代生成和优化启发式解，证明LLM能产生更高效解且计算资源需求更少。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在组合优化领域的能力，特别是2D装箱问题，探索LLM在专业领域的应用潜力。

Method: 系统化方法将LLM与进化算法结合，迭代生成和优化启发式解，并与传统方法(有限首次适应和混合首次适应)进行比较。

Result: GPT-4o在两次迭代内达到最优解，平均箱使用从16减少到15，空间利用率从0.76-0.78提升到0.83。

Conclusion: 这项工作有助于理解LLM在专业领域的评估，并为组合优化任务中LLM性能评估建立了基准。

Abstract: This paper presents an evaluation framework for assessing Large Language
Models' (LLMs) capabilities in combinatorial optimization, specifically
addressing the 2D bin-packing problem. We introduce a systematic methodology
that combines LLMs with evolutionary algorithms to generate and refine
heuristic solutions iteratively. Through comprehensive experiments comparing
LLM generated heuristics against traditional approaches (Finite First-Fit and
Hybrid First-Fit), we demonstrate that LLMs can produce more efficient
solutions while requiring fewer computational resources. Our evaluation reveals
that GPT-4o achieves optimal solutions within two iterations, reducing average
bin usage from 16 to 15 bins while improving space utilization from 0.76-0.78
to 0.83. This work contributes to understanding LLM evaluation in specialized
domains and establishes benchmarks for assessing LLM performance in
combinatorial optimization tasks.

</details>


### [119] [InfiMed-Foundation: Pioneering Advanced Multimodal Medical Models with Compute-Efficient Pre-Training and Multi-Stage Fine-Tuning](https://arxiv.org/abs/2509.22261)
*Guanghao Zhu,Zhitian Hou,Zeyu Liu,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: 提出了两个医疗专用多模态大语言模型InfiMed-Foundation-1.7B和4B，通过高质量数据筛选、高效训练方法和三阶段微调，在医疗任务中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 通用多模态大语言模型在医疗领域应用受限，缺乏专业知识导致回答不确定或产生幻觉，知识蒸馏难以捕捉医学专业知识，大规模医疗数据持续预训练计算成本高。

Method: 结合通用和医疗多模态数据，提出五维质量评估框架筛选高质量数据集；采用低到高图像分辨率和多模态序列打包提高训练效率；使用三阶段监督微调进行复杂医疗任务知识提取。

Result: 在MedEvalKit评估中，InfiMed-Foundation-1.7B优于Qwen2.5VL-3B，InfiMed-Foundation-4B超越HuatuoGPT-V-7B和MedGemma-27B-IT，在医疗视觉问答和诊断任务中表现优异。

Conclusion: 通过解决数据质量、训练效率和领域知识提取等关键挑战，为医疗领域提供更可靠有效的AI驱动解决方案。

Abstract: Multimodal large language models (MLLMs) have shown remarkable potential in
various domains, yet their application in the medical field is hindered by
several challenges. General-purpose MLLMs often lack the specialized knowledge
required for medical tasks, leading to uncertain or hallucinatory responses.
Knowledge distillation from advanced models struggles to capture
domain-specific expertise in radiology and pharmacology. Additionally, the
computational cost of continual pretraining with large-scale medical data poses
significant efficiency challenges. To address these issues, we propose
InfiMed-Foundation-1.7B and InfiMed-Foundation-4B, two medical-specific MLLMs
designed to deliver state-of-the-art performance in medical applications. We
combined high-quality general-purpose and medical multimodal data and proposed
a novel five-dimensional quality assessment framework to curate high-quality
multimodal medical datasets. We employ low-to-high image resolution and
multimodal sequence packing to enhance training efficiency, enabling the
integration of extensive medical data. Furthermore, a three-stage supervised
fine-tuning process ensures effective knowledge extraction for complex medical
tasks. Evaluated on the MedEvalKit framework, InfiMed-Foundation-1.7B
outperforms Qwen2.5VL-3B, while InfiMed-Foundation-4B surpasses HuatuoGPT-V-7B
and MedGemma-27B-IT, demonstrating superior performance in medical visual
question answering and diagnostic tasks. By addressing key challenges in data
quality, training efficiency, and domain-specific knowledge extraction, our
work paves the way for more reliable and effective AI-driven solutions in
healthcare. InfiMed-Foundation-4B model is available at
\href{https://huggingface.co/InfiX-ai/InfiMed-Foundation-4B}{InfiMed-Foundation-4B}.

</details>


### [120] [Structured Sparse Transition Matrices to Enable State Tracking in State-Space Models](https://arxiv.org/abs/2509.22284)
*Aleksandar Terzić,Nicolas Menet,Michael Hersche,Thomas Hofmann,Abbas Rahimi*

Main category: cs.AI

TL;DR: 提出PD-SSM方法，通过结构化稀疏参数化状态空间模型的转移矩阵，在保持计算效率的同时显著提升模型表达能力，能够最优地模拟有限状态自动机。


<details>
  <summary>Details</summary>
Motivation: 现代状态空间模型使用对角化转移矩阵虽然计算高效但表达能力受限，而无结构转移矩阵虽然表达能力强但计算和内存成本过高，需要在表达能力和计算效率之间取得平衡。

Method: 将转移矩阵参数化为列one-hot矩阵(P)和复值对角矩阵(D)的乘积，使并行扫描的计算成本与状态大小呈线性关系，同时保持BIBO稳定性。

Result: 在各种FSA状态跟踪任务中显著优于现有SSM变体，在多类时间序列分类中性能与神经控制微分方程相当，并能有效跟踪复杂FSA状态。

Conclusion: PD-SSM在保持计算效率的同时实现了最优的FSA模拟能力，为状态空间模型提供了表达能力和效率的良好平衡。

Abstract: Modern state-space models (SSMs) often utilize transition matrices which
enable efficient computation but pose restrictions on the model's expressivity,
as measured in terms of the ability to emulate finite-state automata (FSA).
While unstructured transition matrices are optimal in terms of expressivity,
they come at a prohibitively high compute and memory cost even for moderate
state sizes. We propose a structured sparse parametrization of transition
matrices in SSMs that enables FSA state tracking with optimal state size and
depth, while keeping the computational cost of the recurrence comparable to
that of diagonal SSMs. Our method, PD-SSM, parametrizes the transition matrix
as the product of a column one-hot matrix ($P$) and a complex-valued diagonal
matrix ($D$). Consequently, the computational cost of parallel scans scales
linearly with the state size. Theoretically, the model is BIBO-stable and can
emulate any $N$-state FSA with one layer of dimension $N$ and a linear readout
of size $N \times N$, significantly improving on all current structured SSM
guarantees. Experimentally, the model significantly outperforms a wide
collection of modern SSM variants on various FSA state tracking tasks. On
multiclass time-series classification, the performance is comparable to that of
neural controlled differential equations, a paradigm explicitly built for
time-series analysis. Finally, we integrate PD-SSM into a hybrid
Transformer-SSM architecture and demonstrate that the model can effectively
track the states of a complex FSA in which transitions are encoded as a set of
variable-length English sentences. The code is available at
https://github.com/IBM/expressive-sparse-state-space-model

</details>


### [121] [Large Language Models as Nondeterministic Causal Models](https://arxiv.org/abs/2509.22297)
*Sander Beckers*

Main category: cs.AI

TL;DR: 本文提出了一种更简单的反事实生成方法，将LLM表示为非确定性因果模型，相比现有方法更直接适用于任何黑盒LLM，无需修改实现细节。


<details>
  <summary>Details</summary>
Motivation: 现有方法对LLM的解释存在歧义，要么不按字面解释（假设可以改变采样实现而不改变LLM本身），要么不按预期解释（将非确定性LLM表示为确定性因果模型）。需要一种基于LLM预期语义的更简单方法。

Method: 将LLM表示为非确定性因果模型，直接基于LLM的预期解释生成反事实，适用于任何黑盒LLM且无需修改实现细节。

Result: 提出了一个更简单直接的反事实生成方法，能够处理LLM的非确定性特性，同时为特定应用场景的反事实生成提供了理论基础。

Conclusion: 新方法为LLM反事实推理提供了更清晰的理论基础，两种方法各有优势：新方法通用性强，现有方法在某些特定场景下更实用。这为开发针对特定应用的反事实生成方法奠定了基础。

Abstract: Recent work by Chatzi et al. and Ravfogel et al. has developed, for the first
time, a method for generating counterfactuals of probabilistic Large Language
Models. Such counterfactuals tell us what would - or might - have been the
output of an LLM if some factual prompt ${\bf x}$ had been ${\bf x}^*$ instead.
The ability to generate such counterfactuals is an important necessary step
towards explaining, evaluating, and comparing, the behavior of LLMs. I argue,
however, that the existing method rests on an ambiguous interpretation of LLMs:
it does not interpret LLMs literally, for the method involves the assumption
that one can change the implementation of an LLM's sampling process without
changing the LLM itself, nor does it interpret LLMs as intended, for the method
involves explicitly representing a nondeterministic LLM as a deterministic
causal model. I here present a much simpler method for generating
counterfactuals that is based on an LLM's intended interpretation by
representing it as a nondeterministic causal model instead. The advantage of my
simpler method is that it is directly applicable to any black-box LLM without
modification, as it is agnostic to any implementation details. The advantage of
the existing method, on the other hand, is that it directly implements the
generation of a specific type of counterfactuals that is useful for certain
purposes, but not for others. I clarify how both methods relate by offering a
theoretical foundation for reasoning about counterfactuals in LLMs based on
their intended semantics, thereby laying the groundwork for novel
application-specific methods for generating counterfactuals.

</details>


### [122] [PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning](https://arxiv.org/abs/2509.22315)
*Hieu Tran,Zonghai Yao,Nguyen Luong Tran,Zhichao Yang,Feiyun Ouyang,Shuo Han,Razieh Rahimi,Hong Yu*

Main category: cs.AI

TL;DR: PRIME是一个受人类双系统认知理论启发的多智能体推理框架，通过动态整合快速直觉思维（系统1）和慢速深思思维（系统2）来提升LLMs的推理能力。


<details>
  <summary>Details</summary>
Motivation: 受《思考，快与慢》中人类双系统认知理论的启发，旨在让LLMs更接近人类推理过程，提高在复杂知识密集型任务中的表现。

Method: 采用多智能体架构：先由快速思维智能体（系统1）生成初步答案，若检测到不确定性则触发系统2推理管道，包括规划、假设生成、检索、信息整合和决策等专门智能体。

Result: 实验表明，使用LLaMA 3模型的PRIME在需要多跳和知识基础推理的基准测试中，能够与GPT-4、GPT-4o等闭源模型竞争。

Conclusion: PRIME为提升LLMs在复杂知识密集型推理领域的表现提供了一个可扩展的解决方案。

Abstract: Inspired by the dual-process theory of human cognition from \textit{Thinking,
Fast and Slow}, we introduce \textbf{PRIME} (Planning and Retrieval-Integrated
Memory for Enhanced Reasoning), a multi-agent reasoning framework that
dynamically integrates \textbf{System 1} (fast, intuitive thinking) and
\textbf{System 2} (slow, deliberate thinking). PRIME first employs a Quick
Thinking Agent (System 1) to generate a rapid answer; if uncertainty is
detected, it then triggers a structured System 2 reasoning pipeline composed of
specialized agents for \textit{planning}, \textit{hypothesis generation},
\textit{retrieval}, \textit{information integration}, and
\textit{decision-making}. This multi-agent design faithfully mimics human
cognitive processes and enhances both efficiency and accuracy. Experimental
results with LLaMA 3 models demonstrate that PRIME enables open-source LLMs to
perform competitively with state-of-the-art closed-source models like GPT-4 and
GPT-4o on benchmarks requiring multi-hop and knowledge-grounded reasoning. This
research establishes PRIME as a scalable solution for improving LLMs in domains
requiring complex, knowledge-intensive reasoning.

</details>


### [123] [Do LLM Agents Know How to Ground, Recover, and Assess? A Benchmark for Epistemic Competence in Information-Seeking Agents](https://arxiv.org/abs/2509.22391)
*Jiaqi Shao,Yuxiang Lin,Munish Prasad Lohani,Yufeng Miao,Bing Luo*

Main category: cs.AI

TL;DR: 提出了SeekBench基准，用于通过步骤级分析评估LLM搜索代理的认知能力，重点关注其推理过程与外部证据的关联性。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注最终答案准确性，忽略了LLM搜索代理如何基于外部证据进行推理和行动的过程。

Method: 构建包含190个专家标注轨迹和1800多个响应步骤的数据集，每个步骤都带有证据标注，用于分析代理的推理基础、搜索调整能力和证据充分性判断。

Result: 开发了首个专门评估LLM搜索代理认知能力的基准，提供了细粒度的分析框架。

Conclusion: SeekBench填补了现有评估方法的空白，能够更全面地评估LLM搜索代理的推理能力和证据处理能力。

Abstract: Recent work has explored training Large Language Model (LLM) search agents
with reinforcement learning (RL) for open-domain question answering (QA).
However, most evaluations focus solely on final answer accuracy, overlooking
how these agents reason with and act on external evidence. We introduce
SeekBench, the first benchmark for evaluating the \textit{epistemic competence}
of LLM search agents through step-level analysis of their response traces.
SeekBench comprises 190 expert-annotated traces with over 1,800 response steps
generated by LLM search agents, each enriched with evidence annotations for
granular analysis of whether agents (1) generate reasoning steps grounded in
observed evidence, (2) adaptively reformulate searches to recover from
low-quality results, and (3) have proper calibration to correctly assess
whether the current evidence is sufficient for providing an answer.

</details>


### [124] [EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer](https://arxiv.org/abs/2509.22407)
*Zhehao Dong,Xiaofeng Wang,Zheng Zhu,Yirui Wang,Yang Wang,Yukun Zhou,Boyuan Wang,Chaojun Ni,Runqi Ouyang,Wenkang Qin,Xinze Chen,Yun Ye,Guan Huang*

Main category: cs.AI

TL;DR: 提出EMMA框架，通过生成式数据引擎DreamTransfer创建多视角一致的机器人操作视频，结合AdaMix训练策略，显著提升视觉-语言-动作模型在未见物体类别和新视觉域上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 收集大规模真实机器人操作数据成本高昂且耗时，限制了VLA模型的泛化能力，需要一种能生成多样化训练数据的方法来克服这一瓶颈。

Method: 使用DreamTransfer框架进行文本控制的机器人视频视觉编辑，保持3D结构和几何合理性；采用AdaMix训练策略动态调整训练批次权重，专注于感知或运动学上的困难样本。

Result: DreamTransfer生成的视频在多视角一致性、几何保真度和文本条件准确性上显著优于现有方法；在零样本视觉域的真实机器人操作任务中，相比仅使用真实数据训练，性能提升超过200%，结合AdaMix后进一步改善13%。

Conclusion: EMMA框架通过生成式数据增强和智能训练策略，有效解决了机器人操作数据稀缺问题，大幅提升了VLA模型在新视觉域和物体类别上的泛化性能。

Abstract: Vision-language-action (VLA) models increasingly rely on diverse training
data to achieve robust generalization. However, collecting large-scale
real-world robot manipulation data across varied object appearances and
environmental conditions remains prohibitively time-consuming and expensive. To
overcome this bottleneck, we propose Embodied Manipulation Media Adaptation
(EMMA), a VLA policy enhancement framework that integrates a generative data
engine with an effective training pipeline. We introduce DreamTransfer, a
diffusion Transformer-based framework for generating multi-view consistent,
geometrically grounded embodied manipulation videos. DreamTransfer enables
text-controlled visual editing of robot videos, transforming foreground,
background, and lighting conditions without compromising 3D structure or
geometrical plausibility. Furthermore, we explore hybrid training with real and
generated data, and introduce AdaMix, a hard-sample-aware training strategy
that dynamically reweights training batches to focus optimization on
perceptually or kinematically challenging samples. Extensive experiments show
that videos generated by DreamTransfer significantly outperform prior video
generation methods in multi-view consistency, geometric fidelity, and
text-conditioning accuracy. Crucially, VLAs trained with generated data enable
robots to generalize to unseen object categories and novel visual domains using
only demonstrations from a single appearance. In real-world robotic
manipulation tasks with zero-shot visual domains, our approach achieves over a
200% relative performance gain compared to training on real data alone, and
further improves by 13% with AdaMix, demonstrating its effectiveness in
boosting policy generalization.

</details>


### [125] [Guiding Evolution of Artificial Life Using Vision-Language Models](https://arxiv.org/abs/2509.22447)
*Nikhil Baid,Hannah Erlebach,Paul Hellegouarch,Frederico Wieser*

Main category: cs.AI

TL;DR: ASAL++是一种基于多模态基础模型的开放演化搜索方法，通过第二个基础模型根据模拟视觉历史提出新的演化目标，从而产生具有日益复杂目标的演化轨迹。


<details>
  <summary>Details</summary>
Motivation: 基础模型为人工生命模拟提供了强大的自动化搜索工具，先前工作使用视觉语言模型将ALife模拟与自然语言目标提示对齐。本文在ASAL基础上进一步探索开放式的演化搜索。

Method: 提出ASAL++方法，使用第二个基础模型根据模拟视觉历史提出新的演化目标。探索两种策略：EST（每次迭代匹配单个新提示）和ETT（匹配整个生成提示序列）。在Lenia基底中使用Gemma-3提出演化目标。

Result: 实验结果表明，EST策略促进更大的视觉新颖性，而ETT策略培养更连贯和可解释的演化序列。

Conclusion: ASAL++为基础模型驱动的人工生命发现指出了具有开放端特征的新方向。

Abstract: Foundation models (FMs) have recently opened up new frontiers in the field of
artificial life (ALife) by providing powerful tools to automate search through
ALife simulations. Previous work aligns ALife simulations with natural language
target prompts using vision-language models (VLMs). We build on Automated
Search for Artificial Life (ASAL) by introducing ASAL++, a method for
open-ended-like search guided by multimodal FMs. We use a second FM to propose
new evolutionary targets based on a simulation's visual history. This induces
an evolutionary trajectory with increasingly complex targets.
  We explore two strategies: (1) evolving a simulation to match a single new
prompt at each iteration (Evolved Supervised Targets: EST) and (2) evolving a
simulation to match the entire sequence of generated prompts (Evolved Temporal
Targets: ETT). We test our method empirically in the Lenia substrate using
Gemma-3 to propose evolutionary targets, and show that EST promotes greater
visual novelty, while ETT fosters more coherent and interpretable evolutionary
sequences.
  Our results suggest that ASAL++ points towards new directions for FM-driven
ALife discovery with open-ended characteristics.

</details>


### [126] [GeoSketch: A Neural-Symbolic Approach to Geometric Multimodal Reasoning with Auxiliary Line Construction and Affine Transformation](https://arxiv.org/abs/2509.22460)
*Shichao Weng,Zhiqiang Wang,Yuhua Zhou,Rui Lu,Ting Liu,Zhiyang Teng,Xiaozhang Liu,Hanmeng Liu*

Main category: cs.AI

TL;DR: GeoSketch是一个神经符号框架，将几何推理重构为交互式感知-推理-行动循环，通过动态操作图表解决几何问题，显著优于静态感知方法。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型处理几何问题时仅将图表视为静态图像，缺乏动态操作能力，而人类几何推理需要辅助线构造和仿射变换等动态操作。

Method: 集成三个模块：感知模块将图表抽象为结构化逻辑形式，符号推理模块应用几何定理决定下一步推理步骤，草图行动模块执行绘制辅助线或应用变换等操作，形成闭环。采用两阶段训练：监督微调和强化学习。

Result: 在GeoSketch基准测试上，GeoSketch显著提高了逐步推理准确性和问题解决成功率，优于静态感知方法。

Conclusion: 通过统一分层决策、可执行视觉动作和符号验证，GeoSketch将多模态推理从静态解释推进到动态可验证交互，为复杂视觉空间问题解决建立了新基础。

Abstract: Geometric Problem Solving (GPS) poses a unique challenge for Multimodal Large
Language Models (MLLMs), requiring not only the joint interpretation of text
and diagrams but also iterative visuospatial reasoning. While existing
approaches process diagrams as static images, they lack the capacity for
dynamic manipulation - a core aspect of human geometric reasoning involving
auxiliary line construction and affine transformations. We present GeoSketch, a
neural-symbolic framework that recasts geometric reasoning as an interactive
perception-reasoning-action loop. GeoSketch integrates: (1) a Perception module
that abstracts diagrams into structured logic forms, (2) a Symbolic Reasoning
module that applies geometric theorems to decide the next deductive step, and
(3) a Sketch Action module that executes operations such as drawing auxiliary
lines or applying transformations, thereby updating the diagram in a closed
loop. To train this agent, we develop a two-stage pipeline: supervised
fine-tuning on 2,000 symbolic-curated trajectories followed by reinforcement
learning with dense, symbolic rewards to enhance robustness and strategic
exploration. To evaluate this paradigm, we introduce the GeoSketch Benchmark, a
high-quality set of 390 geometry problems requiring auxiliary construction or
affine transformations. Experiments on strong MLLM baselines demonstrate that
GeoSketch significantly improves stepwise reasoning accuracy and
problem-solving success over static perception methods. By unifying
hierarchical decision-making, executable visual actions, and symbolic
verification, GeoSketch advances multimodal reasoning from static
interpretation to dynamic, verifiable interaction, establishing a new
foundation for solving complex visuospatial problems.

</details>


### [127] [InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios](https://arxiv.org/abs/2509.22502)
*Chenglin Yu,Yang Yu,Songmiao Wang,Yucheng Wang,Yifan Yang,Jinjia Li,Ming Li,Hongxia Yang*

Main category: cs.AI

TL;DR: InfiAgent是一个基于DAG的金字塔式多智能体框架，通过自动分解复杂智能体、双重审核机制、智能体路由和自进化机制，能够应用于无限场景，显著提升LLM智能体的可扩展性和成本效益。


<details>
  <summary>Details</summary>
Motivation: 传统LLM智能体开发需要精心设计工作流、提示词和迭代调优，依赖LLM技术和领域专业知识，这些手工限制阻碍了LLM智能体在各行业的可扩展性和成本效益。

Method: 提出InfiAgent框架，包含：1）通用"智能体即工具"机制自动分解复杂智能体；2）双重审核机制确保任务完成质量；3）智能体路由功能实现高效任务匹配；4）智能体自进化机制自主重构DAG；5）原子任务设计支持智能体并行化。

Result: 在多个基准测试中，InfiAgent相比类似的自生成智能体框架ADAS性能提升9.9%。案例研究显示AI研究助手InfiHelper生成的科研论文获得了IEEE顶级会议人类评审的认可。

Conclusion: InfiAgent框架能够演化成通用的金字塔式多智能体系统，解决广泛的问题，显著提升LLM智能体的执行效率和可扩展性。

Abstract: Large Language Model (LLM) agents have demonstrated remarkable capabilities
in organizing and executing complex tasks, and many such agents are now widely
used in various application scenarios. However, developing these agents
requires carefully designed workflows, carefully crafted prompts, and iterative
tuning, which requires LLM techniques and domain-specific expertise. These
hand-crafted limitations hinder the scalability and cost-effectiveness of LLM
agents across a wide range of industries. To address these challenges, we
propose \textbf{InfiAgent}, a Pyramid-like DAG-based Multi-Agent Framework that
can be applied to \textbf{infi}nite scenarios, which introduces several key
innovations: a generalized "agent-as-a-tool" mechanism that automatically
decomposes complex agents into hierarchical multi-agent systems; a dual-audit
mechanism that ensures the quality and stability of task completion; an agent
routing function that enables efficient task-agent matching; and an agent
self-evolution mechanism that autonomously restructures the agent DAG based on
new tasks, poor performance, or optimization opportunities. Furthermore,
InfiAgent's atomic task design supports agent parallelism, significantly
improving execution efficiency. This framework evolves into a versatile
pyramid-like multi-agent system capable of solving a wide range of problems.
Evaluations on multiple benchmarks demonstrate that InfiAgent achieves 9.9\%
higher performance compared to ADAS (similar auto-generated agent framework),
while a case study of the AI research assistant InfiHelper shows that it
generates scientific papers that have received recognition from human reviewers
at top-tier IEEE conferences.

</details>


### [128] [Estimating the Empowerment of Language Model Agents](https://arxiv.org/abs/2509.22504)
*Jinyeop Song,Jeff Gore,Max Kleiman-Weiner*

Main category: cs.AI

TL;DR: 提出基于信息论中赋权概念的语言模型代理评估框架EELMA，通过计算代理行动与未来状态间的互信息来评估代理能力，在语言游戏和网页浏览场景中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型代理能力增强并广泛使用现实工具，需要可扩展的评估框架。传统基准评估成本高且需要人工设计任务来获取通用能力洞察。

Method: 引入EELMA算法，从多轮文本交互中近似估计有效赋权，在语言游戏和现实网页浏览场景中进行验证。

Result: 赋权与平均任务性能强相关，能表征环境复杂性和代理因素影响，高赋权状态通常是通用能力的关键时刻。

Conclusion: 赋权是评估复杂开放环境中语言模型代理的有吸引力的通用指标。

Abstract: As language model (LM) agents become more capable and gain broader access to
real-world tools, there is a growing need for scalable evaluation frameworks of
agentic capability. However, conventional benchmark-centric evaluations are
costly to design and require human designers to come up with valid tasks that
translate into insights about general model capabilities. In this work, we
propose information-theoretic evaluation based on empowerment, the mutual
information between an agent's actions and future states, as an open-ended
method for evaluating LM agents. We introduce EELMA (Estimating Empowerment of
Language Model Agents), an algorithm for approximating effective empowerment
from multi-turn text interactions. We validate EELMA on both language games and
scaled-up realistic web-browsing scenarios. We find that empowerment strongly
correlates with average task performance, characterize the impact of
environmental complexity and agentic factors such as chain-of-thought, model
scale, and memory length on estimated empowerment, and that high empowerment
states and actions are often pivotal moments for general capabilities.
Together, these results demonstrate empowerment as an appealing general-purpose
metric for evaluating and monitoring LM agents in complex, open-ended settings.

</details>


### [129] [TrueGradeAI: Retrieval-Augmented and Bias-Resistant AI for Transparent and Explainable Digital Assessments](https://arxiv.org/abs/2509.22516)
*Rakesh Thakur,Shivaansh Kaushik,Gauri Chopra,Harsh Rohilla*

Main category: cs.AI

TL;DR: TrueGradeAI是一个AI驱动的数字考试框架，通过保留手写输入和使用OCR转录，结合检索增强的评分管道实现自动化、可解释的评分，解决传统纸质考试的纸张浪费、评分延迟和评估者偏见等问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统纸质考试的局限性，包括纸张浪费、物流复杂、评分延迟和评估者偏见，同时保持手写的自然性。

Method: 使用安全平板电脑捕捉手写笔输入，应用基于transformer的OCR进行转录，通过检索增强管道整合教师解决方案、缓存层和外部参考，让大语言模型进行评分并提供证据关联的推理。

Result: 系统实现了手写保留与可扩展透明评估的结合，减少了环境成本，加速了反馈周期，并逐步构建可重复使用的知识库。

Conclusion: TrueGradeAI通过结合手写保留和可扩展透明评估，推进了数字考试领域，减少了环境成本，加速了反馈，并积极减轻评分偏见以确保评估公平性。

Abstract: This paper introduces TrueGradeAI, an AI-driven digital examination framework
designed to overcome the shortcomings of traditional paper-based assessments,
including excessive paper usage, logistical complexity, grading delays, and
evaluator bias. The system preserves natural handwriting by capturing stylus
input on secure tablets and applying transformer-based optical character
recognition for transcription. Evaluation is conducted through a
retrieval-augmented pipeline that integrates faculty solutions, cache layers,
and external references, enabling a large language model to assign scores with
explicit, evidence-linked reasoning. Unlike prior tablet-based exam systems
that primarily digitize responses, TrueGradeAI advances the field by
incorporating explainable automation, bias mitigation, and auditable grading
trails. By uniting handwriting preservation with scalable and transparent
evaluation, the framework reduces environmental costs, accelerates feedback
cycles, and progressively builds a reusable knowledge base, while actively
working to mitigate grading bias and ensure fairness in assessment.

</details>


### [130] [REMA: A Unified Reasoning Manifold Framework for Interpreting Large Language Model](https://arxiv.org/abs/2509.22518)
*Bo Li,Guanzhi Deng,Ronghao Chen,Junrong Yue,Shuo Zhang,Qinghua Zhao,Linqi Song,Lijie Wen*

Main category: cs.AI

TL;DR: 提出了推理流形的概念，通过分析LLM内部表示的空间几何关系来量化推理失败的原因，并开发了REMA框架来定位推理链偏离的起点。


<details>
  <summary>Details</summary>
Motivation: 理解大语言模型如何进行复杂推理及其失败机制是解释性研究的挑战，需要提供可测量的几何分析视角。

Method: 定义推理流形概念，构建REMA框架，通过计算错误表示与正确流形的k近邻距离来量化几何偏差，并跟踪层间偏差来定位偏离点。

Result: 实验验证了推理流形的低维特性，以及错误与正确推理表示之间的高可分性，REMA框架能有效分析推理失败起源。

Conclusion: 该研究将抽象推理失败与表示中的可测量几何偏差联系起来，为深入理解黑盒模型的内部计算过程提供了新途径。

Abstract: Understanding how Large Language Models (LLMs) perform complex reasoning and
their failure mechanisms is a challenge in interpretability research. To
provide a measurable geometric analysis perspective, we define the concept of
the Reasoning Manifold, a latent low-dimensional geometric structure formed by
the internal representations corresponding to all correctly reasoned
generations. This structure can be conceptualized as the embodiment of the
effective thinking paths that the model has learned to successfully solve a
given task. Based on this concept, we build REMA, a framework that explains the
origins of failures by quantitatively comparing the spatial relationships of
internal model representations corresponding to both erroneous and correct
reasoning samples. Specifically, REMA first quantifies the geometric deviation
of each erroneous representation by calculating its k-nearest neighbors
distance to the approximated manifold formed by correct representations,
thereby providing a unified failure signal. It then localizes the divergence
points where these deviations first become significant by tracking this
deviation metric across the model's layers and comparing it against a baseline
of internal fluctuations from correct representations, thus identifying where
the reasoning chain begins to go off-track. Our extensive experiments on
diverse language and multimodal models and tasks demonstrate the
low-dimensional nature of the reasoning manifold and the high separability
between erroneous and correct reasoning representations. The results also
validate the effectiveness of the REMA framework in analyzing the origins of
reasoning failures. This research connects abstract reasoning failures to
measurable geometric deviations in representations, providing new avenues for
in-depth understanding and diagnosis of the internal computational processes of
black-box models.

</details>


### [131] [The Emergence of Altruism in Large-Language-Model Agents Society](https://arxiv.org/abs/2509.22537)
*Haoyang Li,Xiao Jia,Zhanzhan Zhao*

Main category: cs.AI

TL;DR: 该研究首次揭示了不同大语言模型在利己和利他倾向上的内在异质性，识别出两种社会行为原型："适应性利己主义者"和"利他优化者"。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注小规模任务导向游戏中的合作行为，忽视了大规模智能体社会中利他主义的涌现机制。

Method: 引入Schelling变体城市迁移模型，创建社会困境，让200多个LLM智能体在利己和利他目标间进行选择，并使用基于扎根理论的系统编码方法分析智能体推理。

Result: 发现LLM存在根本性的社会倾向差异：适应性利己主义者默认优先考虑自身利益，但在社会规范影响下利他行为显著增加；利他优化者则表现出固有的利他逻辑，即使损害自身利益也优先考虑集体利益。

Conclusion: 对于社会模拟，模型选择不仅是推理能力的选择，更是内在社会行动逻辑的选择。适应性利己主义者更适合模拟复杂人类社会，而利他优化者更适合模拟理想化的亲社会行为者。

Abstract: Leveraging Large Language Models (LLMs) for social simulation is a frontier
in computational social science. Understanding the social logics these agents
embody is critical to this attempt. However, existing research has primarily
focused on cooperation in small-scale, task-oriented games, overlooking how
altruism, which means sacrificing self-interest for collective benefit, emerges
in large-scale agent societies. To address this gap, we introduce a
Schelling-variant urban migration model that creates a social dilemma,
compelling over 200 LLM agents to navigate an explicit conflict between
egoistic (personal utility) and altruistic (system utility) goals. Our central
finding is a fundamental difference in the social tendencies of LLMs. We
identify two distinct archetypes: "Adaptive Egoists", which default to
prioritizing self-interest but whose altruistic behaviors significantly
increase under the influence of a social norm-setting message board; and
"Altruistic Optimizers", which exhibit an inherent altruistic logic,
consistently prioritizing collective benefit even at a direct cost to
themselves. Furthermore, to qualitatively analyze the cognitive underpinnings
of these decisions, we introduce a method inspired by Grounded Theory to
systematically code agent reasoning. In summary, this research provides the
first evidence of intrinsic heterogeneity in the egoistic and altruistic
tendencies of different LLMs. We propose that for social simulation, model
selection is not merely a matter of choosing reasoning capability, but of
choosing an intrinsic social action logic. While "Adaptive Egoists" may offer a
more suitable choice for simulating complex human societies, "Altruistic
Optimizers" are better suited for modeling idealized pro-social actors or
scenarios where collective welfare is the primary consideration.

</details>


### [132] [StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models](https://arxiv.org/abs/2509.22558)
*Chenyu Zhou,Tianyi Xu,Jianghao Lin,Dongdong Ge*

Main category: cs.AI

TL;DR: StepORLM是一个自演化的LLM框架，通过生成式过程监督解决运筹学问题，包含策略模型和生成式过程奖励模型的协同进化循环，在六个基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个关键限制：结果奖励存在信用分配问题，正确最终答案可能强化错误推理；传统判别式过程监督短视，无法整体评估运筹学建模的相互依赖步骤。

Method: 提出StepORLM框架，包含策略模型和生成式过程奖励模型的协同进化循环，采用双反馈机制：来自外部求解器的确定性结果验证和来自GenPRM的细致整体过程评估，通过加权直接偏好优化对齐策略并同时优化GenPRM。

Result: 8B参数的StepORLM在六个基准测试中建立了新的最先进水平，显著优于更大的通用模型、代理方法和专业基线。协同进化的GenPRM能够作为强大且普遍适用的过程验证器，大幅提升自身模型和其他现有LLM的推理扩展性能。

Conclusion: StepORLM通过生成式过程监督和协同进化循环成功解决了运筹学问题中的信用分配和过程评估问题，证明了该框架的有效性和通用性。

Abstract: Large Language Models (LLMs) have shown promising capabilities for solving
Operations Research (OR) problems. While reinforcement learning serves as a
powerful paradigm for LLM training on OR problems, existing works generally
face two key limitations. First, outcome reward suffers from the credit
assignment problem, where correct final answers can reinforce flawed reasoning.
Second, conventional discriminative process supervision is myopic, failing to
evaluate the interdependent steps of OR modeling holistically. To this end, we
introduce StepORLM, a novel self-evolving framework with generative process
supervision. At its core, StepORLM features a co-evolutionary loop where a
policy model and a generative process reward model (GenPRM) iteratively improve
on each other. This loop is driven by a dual-feedback mechanism: definitive,
outcome-based verification from an external solver, and nuanced, holistic
process evaluation from the GenPRM. The combined signal is used to align the
policy via Weighted Direct Preference Optimization (W-DPO) and simultaneously
refine the GenPRM. Our resulting 8B-parameter StepORLM establishes a new
state-of-the-art across six benchmarks, significantly outperforming vastly
larger generalist models, agentic methods, and specialized baselines. Moreover,
the co-evolved GenPRM is able to act as a powerful and universally applicable
process verifier, substantially boosting the inference scaling performance of
both our own model and other existing LLMs.

</details>


### [133] [UniMIC: Token-Based Multimodal Interactive Coding for Human-AI Collaboration](https://arxiv.org/abs/2509.22570)
*Qi Mao,Tinghan Yang,Jiahao Li,Bin Li,Libiao Jin,Yan Lu*

Main category: cs.AI

TL;DR: UniMIC是一个统一的多模态交互编码框架，使用紧凑的token化表示作为通信媒介，在保持与大型多模态模型兼容的同时实现高效低比特率传输。


<details>
  <summary>Details</summary>
Motivation: 现有编解码器仍针对单模态单向通信优化，在传统的压缩-传输-重建流程中会导致重复的质量下降，无法满足多模态AI交互的需求。

Method: 采用基于token的紧凑表示作为通信媒介，使用轻量级Transformer熵模型（通用型、掩码型和文本条件型）来最小化token间冗余。

Result: 在文本到图像生成、文本引导修复、扩展和视觉问答等任务上，UniMIC实现了显著的比特率节省，即使在超低比特率（<0.05bpp）下仍保持鲁棒性，且不影响下游任务性能。

Conclusion: UniMIC为下一代多模态交互通信提供了一个实用且前瞻性的范式。

Abstract: The rapid progress of Large Multimodal Models (LMMs) and cloud-based AI
agents is transforming human-AI collaboration into bidirectional, multimodal
interaction. However, existing codecs remain optimized for unimodal, one-way
communication, resulting in repeated degradation under conventional
compress-transmit-reconstruct pipelines. To address this limitation, we propose
UniMIC, a Unified token-based Multimodal Interactive Coding framework that
bridges edge devices and cloud AI agents. Instead of transmitting raw pixels or
plain text, UniMIC employs compact tokenized representations as the
communication medium, enabling efficient low-bitrate transmission while
maintaining compatibility with LMMs. To further enhance compression,
lightweight Transformer-based entropy models with scenario-specific
designs-generic, masked, and text-conditioned-effectively minimize inter-token
redundancy. Extensive experiments on text-to-image generation, text-guided
inpainting, outpainting, and visual question answering show that UniMIC
achieves substantial bitrate savings and remains robust even at ultra-low
bitrates (<0.05bpp), without compromising downstream task performance. These
results establish UniMIC as a practical and forward-looking paradigm for
next-generation multimodal interactive communication.

</details>


### [134] [Dynamic Experts Search: Enhancing Reasoning in Mixture-of-Experts LLMs at Test Time](https://arxiv.org/abs/2509.22572)
*Yixuan Han,Fan Ma,Ruijie Quan,Yi Yang*

Main category: cs.AI

TL;DR: 提出了Dynamic Experts Search (DES)方法，通过在推理时动态控制MoE模型中激活的专家数量来增强LLM的推理能力，无需额外成本。


<details>
  <summary>Details</summary>
Motivation: 现有测试时缩放方法主要依赖输出级采样，忽视了模型架构的作用。在MoE LLMs中，发现改变激活专家数量能产生互补的解决方案集，这揭示了一个未被充分探索的多样性来源。

Method: DES包含两个关键组件：1) Dynamic MoE - 在推理时直接控制专家数量以生成多样化的推理轨迹；2) Expert Configuration Inheritance - 在推理路径内保持一致的专家数量，在不同运行中变化，平衡稳定性和多样性。

Result: 在MoE架构、验证器和推理基准（数学、代码和知识）上的广泛实验表明，DES可靠地优于TTS基线，提高了准确性和稳定性，且无需额外成本。

Conclusion: DES是一种实用且可扩展的架构感知TTS方法，展示了现代LLMs中结构灵活性如何推进推理能力。

Abstract: Test-Time Scaling (TTS) enhances the reasoning ability of large language
models (LLMs) by allocating additional computation during inference. However,
existing approaches primarily rely on output-level sampling while overlooking
the role of model architecture. In mainstream Mixture-of-Experts (MoE) LLMs, we
observe that varying the number of activated experts yields complementary
solution sets with stable accuracy, revealing a new and underexplored source of
diversity. Motivated by this observation, we propose Dynamic Experts Search
(DES), a TTS strategy that elevates expert activation into a controllable
dimension of the search space. DES integrates two key components: (1) Dynamic
MoE, which enables direct control of expert counts during inference to generate
diverse reasoning trajectories without additional cost; and (2) Expert
Configuration Inheritance, which preserves consistent expert counts within a
reasoning path while varying them across runs, thereby balancing stability and
diversity throughout the search. Extensive experiments across MoE
architectures, verifiers and reasoning benchmarks (i.e., math, code and
knowledge) demonstrate that DES reliably outperforms TTS baselines, enhancing
accuracy and stability without additional cost. These results highlight DES as
a practical and scalable form of architecture-aware TTS, illustrating how
structural flexibility in modern LLMs can advance reasoning.

</details>


### [135] [Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective](https://arxiv.org/abs/2509.22613)
*Siwei Wang,Yifei Shen,Haoran Sun,Shi Feng,Shang-Hua Teng,Li Dong,Yaru Hao,Wei Chen*

Main category: cs.AI

TL;DR: 本文通过图抽象分析强化学习在LLM规划中的理论基础，发现RL通过探索实现正确规划，但策略梯度存在多样性崩溃问题，而Q学习能保持多样性但需要精心设计奖励函数。


<details>
  <summary>Details</summary>
Motivation: 当前RL方法显著提升了LLM的规划能力，但其理论有效性基础尚不明确，需要系统分析RL在规划任务中的优势和局限。

Method: 采用可处理的图抽象方法，重点分析策略梯度和Q学习两种方法，并在Blocksworld真实规划基准上进行验证。

Result: 监督微调可能引入基于共现的伪解，RL通过探索实现正确规划；策略梯度存在多样性崩溃，Q学习能保持多样性但易受奖励攻击影响。

Conclusion: 探索在RL规划中至关重要，Q学习在多样性保持方面优于策略梯度，但需要精心设计奖励函数来防止奖励攻击问题。

Abstract: Recent reinforcement learning (RL) methods have substantially enhanced the
planning capabilities of Large Language Models (LLMs), yet the theoretical
basis for their effectiveness remains elusive. In this work, we investigate
RL's benefits and limitations through a tractable graph-based abstraction,
focusing on policy gradient (PG) and Q-learning methods. Our theoretical
analyses reveal that supervised fine-tuning (SFT) may introduce
co-occurrence-based spurious solutions, whereas RL achieves correct planning
primarily through exploration, underscoring exploration's role in enabling
better generalization. However, we also show that PG suffers from diversity
collapse, where output diversity decreases during training and persists even
after perfect accuracy is attained. By contrast, Q-learning provides two key
advantages: off-policy learning and diversity preservation at convergence. We
further demonstrate that careful reward design is necessary to prevent reward
hacking in Q-learning. Finally, applying our framework to the real-world
planning benchmark Blocksworld, we confirm that these behaviors manifest in
practice.

</details>
