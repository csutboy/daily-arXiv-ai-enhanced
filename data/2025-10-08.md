<div id=toc></div>

# Table of Contents

- [econ.GN](#econ.GN) [Total: 3]
- [cs.SI](#cs.SI) [Total: 1]
- [econ.EM](#econ.EM) [Total: 4]
- [cs.RO](#cs.RO) [Total: 29]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.CY](#cs.CY) [Total: 6]
- [eess.SY](#eess.SY) [Total: 13]
- [stat.AP](#stat.AP) [Total: 5]


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [1] [The role of work-life balance in effective business management](https://arxiv.org/abs/2510.05783)
*Anna Kasperczuk,Michał Ćwiąkała,Ernest Górka,Piotr Ręczajski,Piotr Mrzygłód,Maciej Frasunkiewicz,Agnieszka Darcińska-Głębocka,Jan Piwnik,Grzegorz Gardocki*

Main category: econ.GN

TL;DR: 工作与生活平衡是提升员工动机、工作满意度和组织绩效的关键战略工具，灵活工作时间是最有效的措施。


<details>
  <summary>Details</summary>
Motivation: 研究工作与生活平衡作为有效企业管理战略组成部分的作用，及其对员工动机、工作满意度和组织绩效的影响。

Method: 采用定量调查方法，对102名经济活动个体进行问卷调查，评估灵活工作时间、私人医疗保险等WLB措施的有效性。

Result: 灵活工作安排对提升工作与生活平衡最具影响力，显著提高员工动机；WLB与动机呈显著正相关，改善WLB能增强承诺、减少倦怠；不同人口群体对WLB感知存在差异。

Conclusion: 积极支持WLB的组织能获得更高员工忠诚度、生产力和雇主品牌；WLB措施应纳入人力资源战略以提升组织绩效和社会福祉；未来需研究文化、职业和远程工作背景下的WLB策略。

Abstract: This study examines the role of work-life balance (WLB) as a strategic
component of effective business management and its influence on employee
motivation, job satisfaction, and organizational performance. Drawing on a
quantitative survey of 102 economically active individuals, the research
investigates the effectiveness of various WLB initiatives, including flexible
working hours, private medical care, and additional employee benefits. The
results reveal that flexible working arrangements are the most impactful tool
for enhancing work-life balance and significantly contribute to higher levels
of employee motivation. A statistically significant positive correlation was
observed between perceived work-life balance and motivation, indicating that
improving WLB directly strengthens commitment, reduces burnout, and increases
job satisfaction. Moreover, the findings highlight differences in WLB
perceptions across demographic groups, suggesting the need for tailored
policies. The study emphasizes that organizations actively supporting WLB
achieve greater employee loyalty, improved productivity, and enhanced employer
branding. These results have practical implications for human resource
strategies, showing that integrating WLB initiatives can improve overall
organizational performance and societal well-being. The paper also identifies
research gaps and recommends exploring cultural, occupational, and remote work
contexts in future studies to better understand how WLB strategies shape
workforce engagement in dynamic labor markets.

</details>


### [2] [The challenge of employee motivation in business management](https://arxiv.org/abs/2510.05812)
*Anna Kasperczuk,Michał Ćwiąkała,Ernest Górka,Dariusz Baran,Piotr Ręczajski,Piotr Mrzygłód,Maciej Frasunkiewicz,Agnieszka Dardzińska-Głębocka,Jan Piwnik*

Main category: econ.GN

TL;DR: 本研究探讨员工动机在企业管理中的作用，发现财务激励（特别是目标奖金）是最有效的激励因素，非财务因素如灵活工作时间、职业发展机会和工作氛围也至关重要。研究基于102名员工的调查数据，显示男性、年长员工和资深员工动机水平更高。


<details>
  <summary>Details</summary>
Motivation: 研究旨在了解员工动机作为企业管理关键因素的作用，探索财务和非财务激励如何影响员工参与度和绩效，为管理者设计有效激励系统提供依据。

Method: 采用定量调查方法，对102名员工进行问卷调查，分析不同性别、年龄和工作经验员工的动机水平差异，以及各种激励工具的感知有效性。

Result: 财务激励特别是目标奖金是最具影响力的激励因素；非财务因素如灵活工作时间、额外假期、职业发展机会和工作氛围对提升动机同样重要；男性、年长员工和资深员工动机水平更高；工作生活平衡措施显著提高动机。

Conclusion: 结合财务和非财务激励策略的多方面定制化方法能够优化员工满意度、留任率和组织绩效，为管理者设计有效激励系统提供可行见解。未来研究可探索文化和行业差异，以及远程和混合工作环境中激励因素的演变重要性。

Abstract: This study investigates the role of employee motivation as a critical factor
in effective business management and explores how financial and non-financial
motivators shape engagement and performance. Based on a quantitative survey of
102 employees, the research analyzes differences in motivation levels across
gender, age, and work experience, as well as the perceived effectiveness of
various motivational tools. The findings indicate that financial incentives,
particularly bonuses for achieving targets, are the most influential
motivators, while non-financial factors such as flexible work schedules,
additional leave, career development opportunities, and workplace atmosphere
also play a crucial role in enhancing motivation. Significant variations in
motivation were observed, with men, older employees, and those with longer
tenure reporting higher levels. The study also reveals that work-life balance
initiatives substantially increase motivation, highlighting the importance of
combining financial and non-financial strategies to achieve optimal results.
The results provide actionable insights for managers seeking to design
effective motivation systems, showing that tailored, multifaceted approaches
can improve employee satisfaction, retention, and organizational performance.
Future research could explore cultural and sectoral differences and examine the
evolving importance of motivational factors in remote and hybrid work
environments.

</details>


### [3] [The impact of leadership styles on project efficiency](https://arxiv.org/abs/2510.05822)
*Michał Ćwiąkała,Julia Walter,Dariusz Baran,Gabriela Wojak,Ernest Górka,Piotr Mrzygłód,Maciej Frasunkiewicz,Piotr Ręczajski,Jan Piwnik*

Main category: econ.GN

TL;DR: 该研究探讨了不同领导风格对项目效率的影响，发现领导风格显著影响项目成果，其中建设性反馈、目标清晰沟通、角色明确和鼓励团队主动性是最具影响力的行为。


<details>
  <summary>Details</summary>
Motivation: 研究旨在填补领导力理论与项目管理实践之间的空白，为管理者提供优化团队绩效的可操作见解。

Method: 采用定量研究设计，通过对100名项目专业人员的调查收集数据，并使用Spearman相关等统计技术分析领导行为与项目绩效的关系。

Result: 结果显示领导风格显著影响项目成果，建设性反馈、目标清晰沟通、角色明确和鼓励团队主动性等行为与项目成功指标（目标达成、预算遵守、利益相关者满意度）强相关。

Conclusion: 领导风格直接影响团队动态、动机和协作，进而影响整体效率。民主和参与式方法能提高参与度，但短期内不一定直接转化为可衡量的项目成果。未来研究应考虑更大样本和纵向设计。

Abstract: This study examines the influence of various leadership styles on project
efficiency across diverse organizational contexts. Using a quantitative
research design, data were collected through a survey of 100 project
professionals representing multiple industries, and analyzed with statistical
techniques, including Spearman correlation, to explore the relationship between
leadership behaviors and project performance. The results show that leadership
style significantly affects project outcomes, with constructive feedback, clear
communication of goals, role clarity, and encouragement of team initiative
emerging as the most impactful behaviors. These factors strongly correlate with
project success indicators such as goal achievement, budget adherence, and
stakeholder satisfaction. The findings also highlight areas needing
improvement, including time management, conflict resolution, and involving team
members in decision-making. Moreover, the study provides empirical evidence
that leadership styles directly shape team dynamics, motivation, and
collaboration, which in turn influence overall efficiency. While democratic and
participative approaches enhance engagement, they do not always translate
directly into measurable project results in the short term. The study
contributes to the literature by bridging the gap between leadership theory and
project management practice, offering actionable insights for managers seeking
to optimize team performance. Future research should consider larger, more
diverse samples and longitudinal designs to assess the long-term impact of
leadership behaviors on project success.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [4] [Emergent Directedness in Social Contagion](https://arxiv.org/abs/2510.06012)
*Fabian Tschofenig,Douglas Guilbeault*

Main category: cs.SI

TL;DR: 本文提出了一个因果建模框架来分析复杂传染在网络中的传播路径，发现复杂传染会产生单向传播路径，挑战了传统的网络传播理论。


<details>
  <summary>Details</summary>
Motivation: 解决传统网络结构难以预测复杂传染传播路径的问题，因为传染路径会涌现出难以预测的复杂性。

Method: 开发因果建模框架：(i)模拟传染传播过程中可能出现的网络路径；(ii)识别在这些可能路径中对扩散影响最大的边和节点。

Result: 发现复杂传染会产生单向传播路径，传染越复杂，路径越不对称。弱连接主要促进从一个社区到另一个社区的单向传播，复杂传染更多从网络外围流向核心。

Conclusion: 涌现的方向性挑战了经典网络传播理论，在LinkedIn工作扩散研究中解释了未解释的非线性效应，网络演化偏向增长有向路径，但文化因素可以抑制这种偏向。

Abstract: An enduring challenge in contagion theory is that the pathways contagions
follow through social networks exhibit emergent complexities that are difficult
to predict using network structure. Here, we address this challenge by
developing a causal modeling framework that (i) simulates the possible network
pathways that emerge as contagions spread and (ii) identifies which edges and
nodes are most impactful on diffusion across these possible pathways. This
yields a surprising discovery. If people require exposure to multiple peers to
adopt a contagion (a.k.a., 'complex contagions'), the pathways that emerge
often only work in one direction. In fact, the more complex a contagion is, the
more asymmetric its paths become. This emergent directedness problematizes
canonical theories of how networks mediate contagion. Weak ties spanning
network regions - widely thought to facilitate mutual influence and integration
- prove to privilege the spread contagions from one community to the other.
Emergent directedness also disproportionately channels complex contagions from
the network periphery to the core, inverting standard centrality models. We
demonstrate two practical applications. We show that emergent directedness
accounts for unexplained nonlinearity in the effects of tie strength in a
recent study of job diffusion over LinkedIn. Lastly, we show that network
evolution is biased toward growing directed paths, but that cultural factors
(e.g., triadic closure) can curtail this bias, with strategic implications for
network building and behavioral interventions.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [5] [Estimating Treatment Effects Under Bounded Heterogeneity](https://arxiv.org/abs/2510.05454)
*Soonwoo Kwon,Liyang Sun*

Main category: econ.EM

TL;DR: 提出了一种广义岭回归估计器regulaTE，通过惩罚交互项系数在有限处理效应异质性下实现偏差与方差的最优权衡，构建了在有限重叠下有效的置信区间。


<details>
  <summary>Details</summary>
Motivation: 当处理效应存在异质性时，传统恒定效应假设下的规范无法准确估计平均处理效应，而添加交互项会导致估计不精确且在有限重叠下不可行。

Method: 使用广义岭回归估计器regulaTE，惩罚协变量与处理的交互项系数，在有限处理效应异质性下优化偏差与方差的权衡。

Result: 该方法在有限重叠条件下构建了有效的置信区间，并能评估对恒定效应假设违背的敏感性。

Conclusion: regulaTE为在有限重叠条件下进行统计推断提供了实用方法，适用于无混淆和交错采用等实证场景。

Abstract: Researchers often use specifications that correctly estimate the average
treatment effect under the assumption of constant effects. When treatment
effects are heterogeneous, however, such specifications generally fail to
recover this average effect. Augmenting these specifications with interaction
terms between demeaned covariates and treatment eliminates this bias, but often
leads to imprecise estimates and becomes infeasible under limited overlap. We
propose a generalized ridge regression estimator, $\texttt{regulaTE}$, that
penalizes the coefficients on the interaction terms to achieve an optimal
trade-off between worst-case bias and variance in estimating the average effect
under limited treatment effect heterogeneity. Building on this estimator, we
construct confidence intervals that remain valid under limited overlap and can
also be used to assess sensitivity to violations of the constant effects
assumption. We illustrate the method in empirical applications under
unconfoundedness and staggered adoption, providing a practical approach to
inference under limited overlap.

</details>


### [6] [Correcting sample selection bias with categorical outcomes](https://arxiv.org/abs/2510.05551)
*Onil Boussim*

Main category: econ.EM

TL;DR: 提出了一种用于校正样本选择偏差的方法，特别适用于分类结果变量（如职业选择、健康状态等），通过局部表示方法避免了传统参数化假设的限制，并建立了半参数多项logit模型。


<details>
  <summary>Details</summary>
Motivation: 传统样本选择方法依赖于强参数分布假设，在实践中可能过于严格。现有非参数识别方法仅适用于有序离散结果，需要扩展到无序分类结果。

Method: 开发了适用于联合概率的局部表示方法，将每个联合概率分解为边际概率和类别特定的关联参数，建立了半参数多项logit模型，并提出计算可行的两步估计器。

Result: 在类似于LGR模型的排除限制下，建立了潜在分类分布的非参数点识别，推导了估计器的渐近性质。

Conclusion: 该框架显著扩展了分析分类和其他离散结果中样本选择偏差的工具集，对经济学、健康科学和社会科学的实证研究具有重要价值。

Abstract: In this paper, we propose a method for correcting sample selection bias when
the outcome of interest is categorical, such as occupational choice, health
status, or field of study. Classical approaches to sample selection rely on
strong parametric distributional assumptions, which may be restrictive in
practice. While the recent framework of Chernozhukov et al. (2023) offers a
nonparametric identification using a local Gaussian representation (LGR) that
holds for any bivariate joint distributions. This makes this approach limited
to ordered discrete outcomes. We therefore extend it by developing a local
representation that applies to joint probabilities, thereby eliminating the
need to impose an artificial ordering on categories. Our representation
decomposes each joint probability into marginal probabilities and a
category-specific association parameter that captures how selection
differentially affects each outcome. Under exclusion restrictions analogous to
those in the LGR model, we establish nonparametric point identification of the
latent categorical distribution. Building on this identification result, we
introduce a semiparametric multinomial logit model with sample selection,
propose a computationally tractable two-step estimator, and derive its
asymptotic properties. This framework significantly broadens the set of tools
available for analyzing selection in categorical and other discrete outcomes,
offering substantial relevance for empirical work across economics, health
sciences, and social sciences.

</details>


### [7] [Assessing the Effects of Monetary Shocks on Macroeconomic Stars: A SMUC-IV Framework](https://arxiv.org/abs/2510.05802)
*Bowen Fu,Chenghan Hou,Jan Prüser*

Main category: econ.EM

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper proposes a structural multivariate unobserved components model
with external instrument (SMUC-IV) to investigate the effects of monetary
policy shocks on key U.S. macroeconomic "stars"-namely, the level of potential
output, the growth rate of potential output, trend inflation, and the neutral
interest rate. A key feature of our approach is the use of an external
instrument to identify monetary policy shocks within the multivariate unob-
served components modeling framework. We develop an MCMC estimation method to
facilitate posterior inference within our proposed SMUC-IV frame- work. In
addition, we propose an marginal likelihood estimator to enable model
comparison across alternative specifications. Our empirical analysis shows that
contractionary monetary policy shocks have significant negative effects on the
macroeconomic stars, highlighting the nonzero long-run effects of transitory
monetary policy shocks.

</details>


### [8] [Robust Inference for Convex Pairwise Difference Estimators](https://arxiv.org/abs/2510.05991)
*Matias D. Cattaneo,Michael Jansson,Kenichi Nagasawa*

Main category: econ.EM

TL;DR: 本文为凸成对差异估计器开发了分布理论和基于bootstrap的推断方法，在更宽松的带宽条件下实现有效推断。


<details>
  <summary>Details</summary>
Motivation: 经典结果在严格带宽条件下建立渐近正态性，但实际应用中带宽选择往往不满足这些条件，需要更稳健的推断方法。

Method: 1) 将小带宽渐近理论扩展到凸成对估计；2) 使用基于广义刀切法的去偏方法；3) 构建新的bootstrap方法调整带宽引起的方差失真。

Result: 提出的推断方法在更弱的假设下保持有效，对带宽选择具有更强的鲁棒性。

Conclusion: 该方法在保持凸成对差异估计器实用性的同时，显著提高了推断的稳健性，适用于更广泛的带宽选择范围。

Abstract: This paper develops distribution theory and bootstrap-based inference methods
for a broad class of convex pairwise difference estimators. These estimators
minimize a kernel-weighted convex-in-parameter function over observation pairs
that are similar in terms of certain covariates, where the similarity is
governed by a localization (bandwidth) parameter. While classical results
establish asymptotic normality under restrictive bandwidth conditions, we show
that valid Gaussian and bootstrap-based inference remains possible under
substantially weaker assumptions. First, we extend the theory of small
bandwidth asymptotics to convex pairwise estimation settings, deriving robust
Gaussian approximations even when a smaller than standard bandwidth is used.
Second, we employ a debiasing procedure based on generalized jackknifing to
enable inference with larger bandwidths, while preserving convexity of the
objective function. Third, we construct a novel bootstrap method that adjusts
for bandwidth-induced variance distortions, yielding valid inference across a
wide range of bandwidth choices. Our proposed inference method enjoys
demonstrable more robustness, while retaining the practical appeal of convex
pairwise difference estimators.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [9] [VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing](https://arxiv.org/abs/2510.05213)
*Yixiao Wang,Mingxiao Huo,Zhixuan Liang,Yushi Du,Lingfeng Sun,Haotian Lin,Jinghuan Shang,Chensheng Peng,Mohit Bansal,Mingyu Ding,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: VER是一个用于机器人学习的视觉专家变换器，通过蒸馏多个视觉基础模型构建专家库，并使用轻量级路由网络动态选择任务相关专家，在17个机器人任务中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉基础模型通常只在特定领域表现优异，限制了跨任务的通用性。将多个VFM蒸馏到统一表示中虽然能缓解这一限制，但通常会产生不灵活的任务特定特征选择，并且需要昂贵的全量重新训练来整合机器人领域知识。

Method: 提出VER方法：1）预训练阶段蒸馏多个VFM构建视觉专家库；2）微调阶段仅训练轻量级路由网络（少于0.4%参数）动态选择任务相关专家；3）引入补丁级专家路由与课程Top-K退火机制提高动态专家选择的灵活性和精度；4）支持参数高效微调以实现可扩展的专家利用和自适应机器人领域知识整合。

Result: 在17个多样化机器人任务和多个策略头中，VER实现了最先进的性能。研究发现VER减少了任务无关区域（如背景）的大范数异常值，并集中在任务关键区域。

Conclusion: VER通过动态专家选择和轻量级路由网络，有效解决了多VFM融合的灵活性和效率问题，在机器人学习中表现出卓越的性能和泛化能力。

Abstract: Pretrained vision foundation models (VFMs) advance robotic learning via rich
visual representations, yet individual VFMs typically excel only in specific
domains, limiting generality across tasks. Distilling multiple VFMs into a
unified representation for policy can mitigate this limitation but often yields
inflexible task-specific feature selection and requires costly full re-training
to incorporate robot-domain knowledge. We propose VER, a Vision Expert
transformer for Robot learning. During pretraining, VER distills multiple VFMs
into a vision expert library. It then fine-tunes only a lightweight routing
network (fewer than 0.4% of parameters) to dynamically select task-relevant
experts from the pretrained library for downstream robot tasks. We further
introduce Patchwise Expert Routing with Curriculum Top-K Annealing to improve
both flexibility and precision of dynamic expert selection. Moreover, VER
supports parameter-efficient finetuning for scalable expert utilization and
adaptive robot-domain knowledge integration. Across 17 diverse robotic tasks
and multiple policy heads, VER achieves state-of-the-art performance. We find
that VER reduces large-norm outliers in task-irrelevant regions (e.g.,
background) and concentrates on task-critical regions. Visualizations and codes
can be found in https://yixiaowang7.github.io/ver_page/.

</details>


### [10] [Adaptive Dynamics Planning for Robot Navigation](https://arxiv.org/abs/2510.05330)
*Lu Yuanjie,Mao Mingyang,Xu Tong,Wang Linji,Lin Xiaomin,Xiao Xuesu*

Main category: cs.RO

TL;DR: 提出了自适应动力学规划（ADP），一种学习增强的范式，通过强化学习动态调整机器人动力学属性，使规划器能够适应不同环境，提高导航成功率、安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统分层规划中全局规划器不考虑动力学，局部规划器强制执行动力学约束，这种动力学不连续性在高度受限环境中容易导致轨迹跟踪失败。现有方法采用静态的动力学保真度递减方案，无法适应环境复杂性变化。

Method: 使用强化学习动态调整机器人动力学属性，将ADP集成到三种不同的规划器中，并设计了独立的基于ADP的导航系统。

Result: 在仿真和真实世界测试中，ADP持续提高了导航成功率、安全性和效率。

Conclusion: ADP通过学习增强的方法解决了传统规划中动力学不连续性问题，能够自适应不同环境复杂性，显著提升机器人导航性能。

Abstract: Autonomous robot navigation systems often rely on hierarchical planning,
where global planners compute collision-free paths without considering
dynamics, and local planners enforce dynamics constraints to produce executable
commands. This discontinuity in dynamics often leads to trajectory tracking
failure in highly constrained environments. Recent approaches integrate
dynamics within the entire planning process by gradually decreasing its
fidelity, e.g., increasing integration steps and reducing collision checking
resolution, for real-time planning efficiency. However, they assume that the
fidelity of the dynamics should decrease according to a manually designed
scheme. Such static settings fail to adapt to environmental complexity
variations, resulting in computational overhead in simple environments or
insufficient dynamics consideration in obstacle-rich scenarios. To overcome
this limitation, we propose Adaptive Dynamics Planning (ADP), a
learning-augmented paradigm that uses reinforcement learning to dynamically
adjust robot dynamics properties, enabling planners to adapt across diverse
environments. We integrate ADP into three different planners and further design
a standalone ADP-based navigation system, benchmarking them against other
baselines. Experiments in both simulation and real-world tests show that ADP
consistently improves navigation success, safety, and efficiency.

</details>


### [11] [A multi-modal tactile fingertip design for robotic hands to enhance dexterous manipulation](https://arxiv.org/abs/2510.05382)
*Zhuowei Xu,Zilin Si,Kevin Zhang,Oliver Kroemer,Zeynep Temel*

Main category: cs.RO

TL;DR: 提出了一种低成本、易制造、适应性强的机器人指尖设计，集成了多模态触觉传感器（应变计和接触式麦克风），在多种灵巧操作任务中展示了触觉感知的优势。


<details>
  <summary>Details</summary>
Motivation: 触觉感知能提高机器人操作的精度和灵活性，但由于传感器成本高、制造集成困难以及信号处理复杂等问题，在机器人手中的应用仍然有限。

Method: 设计集成应变计传感器（测量静态力）和接触式麦克风传感器（测量高频振动）的紧凑指尖结构，所有传感器内置以避免直接磨损。

Result: 应变计传感器在0-5N范围内提供可重复的2D平面力测量，接触式麦克风能区分接触材料特性。在从零到完全视觉遮挡的三种灵巧操作任务中，触觉传感器单独或与视觉结合都能提高任务性能。

Conclusion: 多模态触觉传感器设计具有表达性和可靠性，可以在操作的不同阶段灵活使用，显著提升机器人操作能力，特别是在视觉受限的情况下。

Abstract: Tactile sensing holds great promise for enhancing manipulation precision and
versatility, but its adoption in robotic hands remains limited due to high
sensor costs, manufacturing and integration challenges, and difficulties in
extracting expressive and reliable information from signals. In this work, we
present a low-cost, easy-to-make, adaptable, and compact fingertip design for
robotic hands that integrates multi-modal tactile sensors. We use strain gauge
sensors to capture static forces and a contact microphone sensor to measure
high-frequency vibrations during contact. These tactile sensors are integrated
into a compact design with a minimal sensor footprint, and all sensors are
internal to the fingertip and therefore not susceptible to direct wear and tear
from interactions. From sensor characterization, we show that strain gauge
sensors provide repeatable 2D planar force measurements in the 0-5 N range and
the contact microphone sensor has the capability to distinguish contact
material properties. We apply our design to three dexterous manipulation tasks
that range from zero to full visual occlusion. Given the expressiveness and
reliability of tactile sensor readings, we show that different tactile sensing
modalities can be used flexibly in different stages of manipulation, solely or
together with visual observations to achieve improved task performance. For
instance, we can precisely count and unstack a desired number of paper cups
from a stack with 100\% success rate which is hard to achieve with vision only.

</details>


### [12] [Towards Online Robot Interaction Adaptation to Human Upper-limb Mobility Impairments in Return-to-Work Scenarios](https://arxiv.org/abs/2510.05425)
*Marta Lagomarsino,Francesco Tassi*

Main category: cs.RO

TL;DR: 提出了一种用于上肢残疾人士的自适应人机交互在线框架，通过整合关节限制的移动性模型到分层最优控制器中，使机器人能够在线生成反应性、移动性感知的行为。


<details>
  <summary>Details</summary>
Motivation: 工作环境通常不适合上肢残疾人士且缺乏包容性，传统人机协作方法假设用户为健全人，无法满足残疾人士的需求。

Method: 将特定关节限制的移动性模型整合到分层最优控制器中，使机器人能够在线生成反应性、移动性感知的行为，并引导用户受损肢体利用残余功能移动性。

Result: 在涉及不同上肢移动性损伤的交接任务中测试，结果显示该框架能够个性化交互以适应用户的受损运动范围，并根据功能限制严重程度鼓励关节使用。

Conclusion: 该自适应人机交互框架能够有效适应上肢残疾用户的需求，促进其积极参与工作活动。

Abstract: Work environments are often inadequate and lack inclusivity for individuals
with upper-body disabilities. This paper presents a novel online framework for
adaptive human-robot interaction (HRI) that accommodates users' arm mobility
impairments, ultimately aiming to promote active work participation. Unlike
traditional human-robot collaboration approaches that assume able-bodied users,
our method integrates a mobility model for specific joint limitations into a
hierarchical optimal controller. This allows the robot to generate reactive,
mobility-aware behaviour online and guides the user's impaired limb to exploit
residual functional mobility. The framework was tested in handover tasks
involving different upper-limb mobility impairments (i.e., emulated elbow and
shoulder arthritis, and wrist blockage), under both standing and seated
configurations with task constraints using a mobile manipulator, and
complemented by quantitative and qualitative comparisons with state-of-the-art
ergonomic HRI approaches. Preliminary results indicated that the framework can
personalise the interaction to fit within the user's impaired range of motion
and encourage joint usage based on the severity of their functional
limitations.

</details>


### [13] [Active Semantic Perception](https://arxiv.org/abs/2510.05430)
*Huayi Tang,Pratik Chaudhari*

Main category: cs.RO

TL;DR: 提出了一种基于分层场景图和大型语言模型的主动语义感知方法，用于室内环境探索任务，能够更快更准确地推断环境语义。


<details>
  <summary>Details</summary>
Motivation: 利用场景语义进行主动感知和探索任务，需要处理大型复杂室内环境的多层次抽象表示。

Method: 构建紧凑的分层多图层场景图表示环境，使用LLM基于部分观测采样一致的场景图，计算信息增益进行空间推理。

Result: 在复杂3D室内环境模拟中，该方法比基线方法更快更准确地推断环境语义。

Conclusion: 基于分层场景图和LLM的主动语义感知方法在环境探索任务中表现出色，能够有效利用语义信息进行空间推理。

Abstract: We develop an approach for active semantic perception which refers to using
the semantics of the scene for tasks such as exploration. We build a compact,
hierarchical multi-layer scene graph that can represent large, complex indoor
environments at various levels of abstraction, e.g., nodes corresponding to
rooms, objects, walls, windows etc. as well as fine-grained details of their
geometry. We develop a procedure based on large language models (LLMs) to
sample plausible scene graphs of unobserved regions that are consistent with
partial observations of the scene. These samples are used to compute an
information gain of a potential waypoint for sophisticated spatial reasoning,
e.g., the two doors in the living room can lead to either a kitchen or a
bedroom. We evaluate this approach in complex, realistic 3D indoor environments
in simulation. We show using qualitative and quantitative experiments that our
approach can pin down the semantics of the environment quicker and more
accurately than baseline approaches.

</details>


### [14] [AD-NODE: Adaptive Dynamics Learning with Neural ODEs for Mobile Robots Control](https://arxiv.org/abs/2510.05443)
*Shao-Yi Yu,Jen-Wei Wang,Maya Horii,Vikas Garg,Tarek Zohdi*

Main category: cs.RO

TL;DR: 提出了一种自适应动力学模型，通过从状态-动作历史推断操作环境，无需直接环境知识即可适应变化的环境条件，并与模型预测控制集成。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在不确定环境中需要能够响应环境变化的动力学模型，特别是在难以直接获取环境信息的情况下。

Method: 基于神经常微分方程构建动力学模型，采用两阶段训练程序学习潜在环境表示，通过状态-动作历史推断操作环境。

Result: 在三个机器人平台上验证了方法的有效性：2D差动轮式机器人、3D四旋翼无人机和Sphero BOLT机器人，能够处理时间和空间变化的环境变化。

Conclusion: 该方法能够在仿真和真实世界系统中有效处理环境变化，无需直接环境知识即可实现自适应控制。

Abstract: Mobile robots, such as ground vehicles and quadrotors, are becoming
increasingly important in various fields, from logistics to agriculture, where
they automate processes in environments that are difficult to access for
humans. However, to perform effectively in uncertain environments using
model-based controllers, these systems require dynamics models capable of
responding to environmental variations, especially when direct access to
environmental information is limited. To enable such adaptivity and facilitate
integration with model predictive control, we propose an adaptive dynamics
model which bypasses the need for direct environmental knowledge by inferring
operational environments from state-action history. The dynamics model is based
on neural ordinary equations, and a two-phase training procedure is used to
learn latent environment representations. We demonstrate the effectiveness of
our approach through goal-reaching and path-tracking tasks on three robotic
platforms of increasing complexity: a 2D differential wheeled robot with
changing wheel contact conditions, a 3D quadrotor in variational wind fields,
and the Sphero BOLT robot under two contact conditions for real-world
deployment. Empirical results corroborate that our method can handle temporally
and spatially varying environmental changes in both simulation and real-world
systems.

</details>


### [15] [Correlation-Aware Dual-View Pose and Velocity Estimation for Dynamic Robotic Manipulation](https://arxiv.org/abs/2510.05536)
*Mahboubeh Zarei,Robin Chhabra,Farrokh Janabi-Sharifi*

Main category: cs.RO

TL;DR: 提出了一种基于李群的双视图去中心化融合方法，用于估计目标物体的位姿和速度，通过手眼和固定视角相机配置实现鲁棒跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统集中式传感器融合方法存在局限性，需要开发去中心化融合方法来提高机器人操作中位姿和速度估计的精度和鲁棒性。

Method: 使用双视图测量配置（手眼相机和固定视角相机），运行两个独立的自适应扩展卡尔曼滤波器，在SE(3)×R³×R³流形上进行状态预测，在SE(3)流形上更新状态，最后使用相关性感知融合规则进行状态融合。

Result: 在UFactory xArm 850机器人上的实验验证了该方法的有效性和鲁棒性，相比现有方法有持续改进。

Conclusion: 所提出的去中心化双视图估计框架能够有效估计目标物体的位姿和速度，为机器人空间任务规划提供了可靠的状态估计。

Abstract: Accurate pose and velocity estimation is essential for effective spatial task
planning in robotic manipulators. While centralized sensor fusion has
traditionally been used to improve pose estimation accuracy, this paper
presents a novel decentralized fusion approach to estimate both pose and
velocity. We use dual-view measurements from an eye-in-hand and an eye-to-hand
vision sensor configuration mounted on a manipulator to track a target object
whose motion is modeled as random walk (stochastic acceleration model). The
robot runs two independent adaptive extended Kalman filters formulated on a
matrix Lie group, developed as part of this work. These filters predict poses
and velocities on the manifold $\mathbb{SE}(3) \times \mathbb{R}^3 \times
\mathbb{R}^3$ and update the state on the manifold $\mathbb{SE}(3)$. The final
fused state comprising the fused pose and velocities of the target is obtained
using a correlation-aware fusion rule on Lie groups. The proposed method is
evaluated on a UFactory xArm 850 equipped with Intel RealSense cameras,
tracking a moving target. Experimental results validate the effectiveness and
robustness of the proposed decentralized dual-view estimation framework,
showing consistent improvements over state-of-the-art methods.

</details>


### [16] [ARRC: Advanced Reasoning Robot Control - Knowledge-Driven Autonomous Manipulation Using Retrieval-Augmented Generation](https://arxiv.org/abs/2510.05547)
*Eugene Vorobiov,Ammar Jaleel Mahmood,Salim Rezvani,Robin Chhabra*

Main category: cs.RO

TL;DR: ARRC系统结合检索增强生成(RAG)与RGB-D感知，将自然语言指令转化为安全的机器人控制，在低成本机械臂上实现桌面扫描、接近和拾放任务。


<details>
  <summary>Details</summary>
Motivation: 连接自然语言指令与安全本地机器人控制，通过RAG提升计划有效性和适应性，同时保持感知和底层控制本地化。

Method: 使用向量数据库索引机器人知识，检索任务相关上下文，通过LLM生成JSON结构化行动计划，在UFactory xArm 850上执行，结合AprilTag检测和深度感知，实施软件安全门机制。

Result: 实验结果表明该方法能显著提高计划有效性和适应性，在桌面任务中表现良好。

Conclusion: 基于RAG的规划可以大幅改善计划有效性，同时保持感知和底层控制的本地化，为自然语言机器人控制提供了实用解决方案。

Abstract: We present ARRC (Advanced Reasoning Robot Control), a practical system that
connects natural-language instructions to safe local robotic control by
combining Retrieval-Augmented Generation (RAG) with RGB-D perception and
guarded execution on an affordable robot arm. The system indexes curated robot
knowledge (movement patterns, task templates, and safety heuristics) in a
vector database, retrieves task-relevant context for each instruction, and
conditions a large language model (LLM) to produce JSON-structured action
plans. Plans are executed on a UFactory xArm 850 fitted with a Dynamixel-driven
parallel gripper and an Intel RealSense D435 camera. Perception uses AprilTag
detections fused with depth to produce object-centric metric poses. Execution
is enforced via software safety gates: workspace bounds, speed and force caps,
timeouts, and bounded retries. We describe the architecture, knowledge design,
integration choices, and a reproducible evaluation protocol for tabletop scan,
approach, and pick-place tasks. Experimental results demonstrate the efficacy
of the proposed approach. Our design shows that RAG-based planning can
substantially improve plan validity and adaptability while keeping perception
and low-level control local to the robot.

</details>


### [17] [GO-Flock: Goal-Oriented Flocking in 3D Unknown Environments with Depth Maps](https://arxiv.org/abs/2510.05553)
*Yan Rui Tan,Wenqi Liu,Wai Lun Leong,John Guan Zhong Tan,Wayne Wen Huei Yong,Fan Shi,Rodney Swee Huat Teo*

Main category: cs.RO

TL;DR: GO-Flock是一个混合集群框架，将规划与基于人工势场(APF)的响应式控制相结合，解决了传统APF方法在障碍物环境中容易陷入死锁和局部极小值的问题。


<details>
  <summary>Details</summary>
Motivation: 传统APF方法在集群控制中广泛使用，但在障碍物存在时容易出现死锁和局部极小值问题，现有解决方案通常是被动的，导致集体导航缓慢低效。

Method: GO-Flock包含上游感知模块（处理深度图提取路径点和虚拟代理用于避障）和下游集体导航模块（应用新型APF策略实现有效集群行为）。

Result: 在障碍物密集环境中评估GO-Flock，并与被动APF方法对比，展示了其在克服局部极小值和集群行为方面的优势。通过硬件在环实验成功在森林环境中集群了9架无人机（6架实体+3架虚拟）。

Conclusion: GO-Flock框架通过整合规划和响应式控制，有效解决了传统APF方法在复杂环境中的局限性，实现了高效可靠的集群导航。

Abstract: Artificial Potential Field (APF) methods are widely used for reactive
flocking control, but they often suffer from challenges such as deadlocks and
local minima, especially in the presence of obstacles. Existing solutions to
address these issues are typically passive, leading to slow and inefficient
collective navigation. As a result, many APF approaches have only been
validated in obstacle-free environments or simplified, pseudo 3D simulations.
This paper presents GO-Flock, a hybrid flocking framework that integrates
planning with reactive APF-based control. GO-Flock consists of an upstream
Perception Module, which processes depth maps to extract waypoints and virtual
agents for obstacle avoidance, and a downstream Collective Navigation Module,
which applies a novel APF strategy to achieve effective flocking behavior in
cluttered environments. We evaluate GO-Flock against passive APF-based
approaches to demonstrate their respective merits, such as their flocking
behavior and the ability to overcome local minima. Finally, we validate
GO-Flock through obstacle-filled environment and also hardware-in-the-loop
experiments where we successfully flocked a team of nine drones, six physical
and three virtual, in a forest environment.

</details>


### [18] [DeLTa: Demonstration and Language-Guided Novel Transparent Object Manipulation](https://arxiv.org/abs/2510.05662)
*Taeyeop Lee,Gyuree Kang,Bowen Wen,Youngho Kim,Seunghyeok Back,In So Kweon,David Hyunchul Shim,Kuk-Jin Yoon*

Main category: cs.RO

TL;DR: DeLTa是一个用于透明物体精确长时程操作的框架，结合深度估计、6D姿态估计和视觉语言规划，通过单次演示即可泛化到新物体，无需类别先验或额外训练。


<details>
  <summary>Details</summary>
Motivation: 透明物体操作研究目前局限于短时程任务和基本抓取能力，现有方法对新物体的泛化能力不足，难以实现精确的长时程操作。

Method: 集成深度估计、6D姿态估计和视觉语言规划，采用单次演示方法将6D轨迹泛化到新透明物体，并设计了考虑单臂眼在手机器人约束的任务规划器。

Result: 在综合评估中，该方法显著优于现有透明物体操作方法，特别是在需要精确操作能力的长时程场景中表现突出。

Conclusion: DeLTa框架成功解决了透明物体长时程精确操作的挑战，通过单次演示实现了对新物体的泛化，为透明物体操作提供了有效解决方案。

Abstract: Despite the prevalence of transparent object interactions in human everyday
life, transparent robotic manipulation research remains limited to
short-horizon tasks and basic grasping capabilities.Although some methods have
partially addressed these issues, most of them have limitations in
generalizability to novel objects and are insufficient for precise long-horizon
robot manipulation. To address this limitation, we propose DeLTa (Demonstration
and Language-Guided Novel Transparent Object Manipulation), a novel framework
that integrates depth estimation, 6D pose estimation, and vision-language
planning for precise long-horizon manipulation of transparent objects guided by
natural task instructions. A key advantage of our method is its
single-demonstration approach, which generalizes 6D trajectories to novel
transparent objects without requiring category-level priors or additional
training. Additionally, we present a task planner that refines the
VLM-generated plan to account for the constraints of a single-arm, eye-in-hand
robot for long-horizon object manipulation tasks. Through comprehensive
evaluation, we demonstrate that our method significantly outperforms existing
transparent object manipulation approaches, particularly in long-horizon
scenarios requiring precise manipulation capabilities. Project page:
https://sites.google.com/view/DeLTa25/

</details>


### [19] [Verifier-free Test-Time Sampling for Vision Language Action Models](https://arxiv.org/abs/2510.05681)
*Suhyeok Jang,Dongyoung Kim,Changyeon Kim,Youngsuk Kim,Jinwoo Shin*

Main category: cs.RO

TL;DR: 提出MG-Select框架，通过利用VLA模型内部属性进行测试时扩展，无需额外训练或外部模块，显著提升机器人控制精度。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在需要高精度的任务中存在局限，而基于外部验证器的测试时扩展方法需要额外训练且难以泛化到未见条件。

Method: 使用KL散度作为置信度指标，通过随机掩码状态和语言条件生成参考分布，并采用联合训练策略学习条件和非条件分布。

Result: 在真实世界任务中实现28%/35%的分布内/分布外性能提升，在RoboCasa拾取任务上获得168%的相对增益。

Conclusion: MG-Select通过利用模型内部属性有效提升了VLA在精确任务中的性能，无需额外训练成本。

Abstract: Vision-Language-Action models (VLAs) have demonstrated remarkable performance
in robot control. However, they remain fundamentally limited in tasks that
require high precision due to their single-inference paradigm. While test-time
scaling approaches using external verifiers have shown promise, they require
additional training and fail to generalize to unseen conditions. We propose
Masking Distribution Guided Selection (MG-Select), a novel test-time scaling
framework for VLAs that leverages the model's internal properties without
requiring additional training or external modules. Our approach utilizes KL
divergence from a reference action token distribution as a confidence metric
for selecting the optimal action from multiple candidates. We introduce a
reference distribution generated by the same VLA but with randomly masked
states and language conditions as inputs, ensuring maximum uncertainty while
remaining aligned with the target task distribution. Additionally, we propose a
joint training strategy that enables the model to learn both conditional and
unconditional distributions by applying dropout to state and language
conditions, thereby further improving the quality of the reference
distribution. Our experiments demonstrate that MG-Select achieves significant
performance improvements, including a 28%/35% improvement in real-world
in-distribution/out-of-distribution tasks, along with a 168% relative gain on
RoboCasa pick-and-place tasks trained with 30 demonstrations.

</details>


### [20] [Oracle-Guided Masked Contrastive Reinforcement Learning for Visuomotor Policies](https://arxiv.org/abs/2510.05692)
*Yuhang Zhang,Jiaping Xiao,Chao Yan,Mir Feroskhan*

Main category: cs.RO

TL;DR: 提出OMC-RL框架，通过两阶段学习（上游表示学习和下游策略学习）解决视觉运动策略学习中样本效率低和仿真到现实差距大的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法直接将高维视觉观察映射到动作命令，存在样本效率低和仿真到现实差距大的长期挑战。

Method: 上游阶段使用掩码Transformer进行时序建模和对比学习提取任务相关表示；下游阶段使用特权信息教师策略提供早期指导并逐步减少。

Result: 在仿真和真实环境中的广泛实验表明，OMC-RL实现了优越的样本效率和渐近策略性能，并提高了在多样化感知复杂场景中的泛化能力。

Conclusion: OMC-RL框架有效解决了视觉运动策略学习中的关键挑战，为实际应用提供了可行解决方案。

Abstract: A prevailing approach for learning visuomotor policies is to employ
reinforcement learning to map high-dimensional visual observations directly to
action commands. However, the combination of high-dimensional visual inputs and
agile maneuver outputs leads to long-standing challenges, including low sample
efficiency and significant sim-to-real gaps. To address these issues, we
propose Oracle-Guided Masked Contrastive Reinforcement Learning (OMC-RL), a
novel framework designed to improve the sample efficiency and asymptotic
performance of visuomotor policy learning. OMC-RL explicitly decouples the
learning process into two stages: an upstream representation learning stage and
a downstream policy learning stage. In the upstream stage, a masked Transformer
module is trained with temporal modeling and contrastive learning to extract
temporally-aware and task-relevant representations from sequential visual
inputs. After training, the learned encoder is frozen and used to extract
visual representations from consecutive frames, while the Transformer module is
discarded. In the downstream stage, an oracle teacher policy with privileged
access to global state information supervises the agent during early training
to provide informative guidance and accelerate early policy learning. This
guidance is gradually reduced to allow independent exploration as training
progresses. Extensive experiments in simulated and real-world environments
demonstrate that OMC-RL achieves superior sample efficiency and asymptotic
policy performance, while also improving generalization across diverse and
perceptually complex scenarios.

</details>


### [21] [Stable Robot Motions on Manifolds: Learning Lyapunov-Constrained Neural Manifold ODEs](https://arxiv.org/abs/2510.05707)
*David Boetius,Abdelrahman Abdelnaby,Ashok Kumar,Stefan Leue,Abdalla Swikir,Fares J. Abu-Dakka*

Main category: cs.RO

TL;DR: 提出了一种在黎曼流形上学习稳定动力系统的通用框架，通过神经ODE和Lyapunov稳定性准则确保系统稳定性，适用于机器人运动规划和控制。


<details>
  <summary>Details</summary>
Motivation: 在黎曼流形上扩展稳定性保证面临几何约束的挑战，这对于安全可靠的机器人运动规划和控制至关重要。

Method: 使用神经ODE学习黎曼流形上的动力系统，通过投影神经向量场严格满足Lyapunov稳定性准则，利用灵活的神经网络参数化基向量场和Lyapunov函数。

Result: 在单位四元数(S^3)和对称正定矩阵流形上解决了黎曼LASA数据集，在ℝ³×S³上实现了机器人运动学习，通过广泛仿真和真实实验验证了性能、可扩展性和实用性。

Conclusion: 该框架能够准确表示复杂轨迹同时尊重流形约束，为黎曼流形上的稳定动力系统学习提供了有效解决方案。

Abstract: Learning stable dynamical systems from data is crucial for safe and reliable
robot motion planning and control. However, extending stability guarantees to
trajectories defined on Riemannian manifolds poses significant challenges due
to the manifold's geometric constraints. To address this, we propose a general
framework for learning stable dynamical systems on Riemannian manifolds using
neural ordinary differential equations. Our method guarantees stability by
projecting the neural vector field evolving on the manifold so that it strictly
satisfies the Lyapunov stability criterion, ensuring stability at every system
state. By leveraging a flexible neural parameterisation for both the base
vector field and the Lyapunov function, our framework can accurately represent
complex trajectories while respecting manifold constraints by evolving
solutions directly on the manifold. We provide an efficient training strategy
for applying our framework and demonstrate its utility by solving Riemannian
LASA datasets on the unit quaternion (S^3) and symmetric positive-definite
matrix manifolds, as well as robotic motions evolving on \mathbb{R}^3 \times
S^3. We demonstrate the performance, scalability, and practical applicability
of our approach through extensive simulations and by learning robot motions in
a real-world experiment.

</details>


### [22] [Federated Split Learning for Resource-Constrained Robots in Industrial IoT: Framework Comparison, Optimization Strategies, and Future Directions](https://arxiv.org/abs/2510.05713)
*Wanli Ni,Hui Tian,Shuai Wang,Chengyang Li,Lei Sun,Zhaohui Yang*

Main category: cs.RO

TL;DR: 本文对联邦分割学习（FedSL）在工业物联网系统中的应用进行了全面研究，重点关注资源受限的机器人场景，比较了不同框架的性能并提出了优化技术。


<details>
  <summary>Details</summary>
Motivation: 工业物联网系统中数据隐私、通信效率和设备异构性是关键问题，联邦分割学习能够实现协作智能同时保护隐私。

Method: 比较同步、异步、分层和异构FedSL框架，系统分类令牌融合策略为输入级、中间级和输出级，并提供自适应优化技术。

Result: 仿真结果验证了这些框架在工业检测场景下的性能表现。

Conclusion: 提出了FedSL在未来智能制造系统中的开放问题和研究方向。

Abstract: Federated split learning (FedSL) has emerged as a promising paradigm for
enabling collaborative intelligence in industrial Internet of Things (IoT)
systems, particularly in smart factories where data privacy, communication
efficiency, and device heterogeneity are critical concerns. In this article, we
present a comprehensive study of FedSL frameworks tailored for
resource-constrained robots in industrial scenarios. We compare synchronous,
asynchronous, hierarchical, and heterogeneous FedSL frameworks in terms of
workflow, scalability, adaptability, and limitations under dynamic industrial
conditions. Furthermore, we systematically categorize token fusion strategies
into three paradigms: input-level (pre-fusion), intermediate-level
(intra-fusion), and output-level (post-fusion), and summarize their respective
strengths in industrial applications. We also provide adaptive optimization
techniques to enhance the efficiency and feasibility of FedSL implementation,
including model compression, split layer selection, computing frequency
allocation, and wireless resource management. Simulation results validate the
performance of these frameworks under industrial detection scenarios. Finally,
we outline open issues and research directions of FedSL in future smart
manufacturing systems.

</details>


### [23] [Precise and Efficient Collision Prediction under Uncertainty in Autonomous Driving](https://arxiv.org/abs/2510.05729)
*Marc Kaufeld,Johannes Betz*

Main category: cs.RO

TL;DR: 提出了两种高效方法来估计自动驾驶中规划轨迹的碰撞风险，考虑了感知噪声、定位误差和交通参与者预测不确定性，能够在实时规划中准确计算与凸面障碍物的碰撞概率。


<details>
  <summary>Details</summary>
Motivation: 确定性碰撞检查在不确定驾驶条件下往往不准确或过于保守，需要能够处理感知噪声、定位误差和交通参与者预测不确定性的碰撞概率估计方法。

Method: 提出了两种半解析方法：第一种评估自动驾驶车辆与周围障碍物空间重叠的概率，第二种基于随机边界穿越估计碰撞概率，两种方法都考虑了完整状态不确定性。

Result: 仿真研究表明，所提方法能够紧密匹配蒙特卡洛结果，同时提供显著的运行时间优势，适用于风险感知的轨迹规划。

Conclusion: 这些方法在计算成本适合实时规划的情况下实现了高精度，为自动驾驶系统中的风险感知轨迹规划提供了有效工具，并已作为开源软件发布。

Abstract: This research introduces two efficient methods to estimate the collision risk
of planned trajectories in autonomous driving under uncertain driving
conditions. Deterministic collision checks of planned trajectories are often
inaccurate or overly conservative, as noisy perception, localization errors,
and uncertain predictions of other traffic participants introduce significant
uncertainty into the planning process. This paper presents two semi-analytic
methods to compute the collision probability of planned trajectories with
arbitrary convex obstacles. The first approach evaluates the probability of
spatial overlap between an autonomous vehicle and surrounding obstacles, while
the second estimates the collision probability based on stochastic boundary
crossings. Both formulations incorporate full state uncertainties, including
position, orientation, and velocity, and achieve high accuracy at computational
costs suitable for real-time planning. Simulation studies verify that the
proposed methods closely match Monte Carlo results while providing significant
runtime advantages, enabling their use in risk-aware trajectory planning. The
collision estimation methods are available as open-source software:
https://github.com/TUM-AVS/Collision-Probability-Estimation

</details>


### [24] [Human-in-the-loop Optimisation in Robot-assisted Gait Training](https://arxiv.org/abs/2510.05780)
*Andreas Christou,Andreas Sochopoulos,Elliot Lister,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 本文研究了人机协同优化在步态训练中提供个性化辅助的潜力，使用CMA-ES算法优化下肢外骨骼辅助控制器，发现虽然算法能为每个个体收敛到独特的刚度参数，但在验证试验中未观察到对受试者表现的显著影响。


<details>
  <summary>Details</summary>
Motivation: 由于步行模式存在显著的人际和个体内变异性，需要设计能够适应每个个体独特特征的机器人控制器，以提供个性化的步态训练辅助。

Method: 采用协方差矩阵自适应进化策略（CMA-ES）持续优化下肢外骨骼的按需辅助控制器，并在六名健康个体上进行为期两天的实验。

Result: CMA-ES算法似乎能为每个个体收敛到独特的刚度参数集，但在验证试验中未观察到对受试者表现的显著影响。

Conclusion: 研究强调了人机协同适应和人类行为变异性的影响，这些影响可能超过个性化基于规则的辅助控制器的潜在益处，指出了当前外骨骼辅助步态康复个性化方法的局限性。

Abstract: Wearable robots offer a promising solution for quantitatively monitoring gait
and providing systematic, adaptive assistance to promote patient independence
and improve gait. However, due to significant interpersonal and intrapersonal
variability in walking patterns, it is important to design robot controllers
that can adapt to the unique characteristics of each individual. This paper
investigates the potential of human-in-the-loop optimisation (HILO) to deliver
personalised assistance in gait training. The Covariance Matrix Adaptation
Evolution Strategy (CMA-ES) was employed to continuously optimise an
assist-as-needed controller of a lower-limb exoskeleton. Six healthy
individuals participated over a two-day experiment. Our results suggest that
while the CMA-ES appears to converge to a unique set of stiffnesses for each
individual, no measurable impact on the subjects' performance was observed
during the validation trials. These findings highlight the impact of
human-robot co-adaptation and human behaviour variability, whose effect may be
greater than potential benefits of personalising rule-based assistive
controllers. Our work contributes to understanding the limitations of current
personalisation approaches in exoskeleton-assisted gait rehabilitation and
identifies key challenges for effective implementation of human-in-the-loop
optimisation in this domain.

</details>


### [25] [VCoT-Grasp: Grasp Foundation Models with Visual Chain-of-Thought Reasoning for Language-driven Grasp Generation](https://arxiv.org/abs/2510.05827)
*Haoran Zhang,Shuanghao Bai,Wanqi Zhou,Yuedi Zhang,Qi Zhang,Pengxiang Ding,Cheng Chi,Donglin Wang,Badong Chen*

Main category: cs.RO

TL;DR: 提出了VCoT-Grasp，一种端到端的抓取基础模型，通过视觉思维链推理增强视觉理解，用于在杂乱环境中生成抓取动作。


<details>
  <summary>Details</summary>
Motivation: 现有语言驱动抓取生成方法要么缺乏足够的推理和泛化能力，要么依赖复杂的模块化流程，且当前抓取基础模型过度强调对话和对象语义，导致性能不佳且仅限于单对象抓取。

Method: 采用多轮处理范式，动态关注视觉输入并提供可解释的推理轨迹。构建了大规模数据集VCoT-GraspSet，包含16.7万合成图像和400+真实图像。

Result: 在VCoT-GraspSet和真实机器人上的广泛实验表明，该方法显著提高了抓取成功率，并能有效泛化到未见过的物体、背景和干扰物。

Conclusion: VCoT-Grasp通过视觉思维链推理保持了强大的推理能力和在杂乱环境中的泛化能力，为机器人抓取任务提供了有效的解决方案。

Abstract: Robotic grasping is one of the most fundamental tasks in robotic
manipulation, and grasp detection/generation has long been the subject of
extensive research. Recently, language-driven grasp generation has emerged as a
promising direction due to its practical interaction capabilities. However,
most existing approaches either lack sufficient reasoning and generalization
capabilities or depend on complex modular pipelines. Moreover, current grasp
foundation models tend to overemphasize dialog and object semantics, resulting
in inferior performance and restriction to single-object grasping. To maintain
strong reasoning ability and generalization in cluttered environments, we
propose VCoT-Grasp, an end-to-end grasp foundation model that incorporates
visual chain-of-thought reasoning to enhance visual understanding for grasp
generation. VCoT-Grasp adopts a multi-turn processing paradigm that dynamically
focuses on visual inputs while providing interpretable reasoning traces. For
training, we refine and introduce a large-scale dataset, VCoT-GraspSet,
comprising 167K synthetic images with over 1.36M grasps, as well as 400+
real-world images with more than 1.2K grasps, annotated with intermediate
bounding boxes. Extensive experiments on both VCoT-GraspSet and real robot
demonstrate that our method significantly improves grasp success rates and
generalizes effectively to unseen objects, backgrounds, and distractors. More
details can be found at https://zhanghr2001.github.io/VCoT-Grasp.github.io.

</details>


### [26] [A Co-Design Framework for Energy-Aware Monoped Jumping with Detailed Actuator Modeling](https://arxiv.org/abs/2510.05923)
*Aman Singh,Aastha Mishra,Deepak Kapa,Suryank Joshi,Shishir Kolathaya*

Main category: cs.RO

TL;DR: 提出三阶段协同设计优化框架，在最大化单足机器人跳跃高度的同时最小化机械能耗，包含真实执行器质量模型和变速箱参数优化，可自动生成CAD模型用于制造。


<details>
  <summary>Details</summary>
Motivation: 现有协同设计框架通常只优化最大高度或最小能耗，忽略了二者权衡，且常省略变速箱参数优化，使用过于简化的执行器质量模型，导致设计难以实际复制。

Method: 三阶段协同设计优化框架，联合优化机械设计（包括变速箱）和控制参数，采用真实执行器质量模型，可自动生成参数化CAD模型。

Result: 实验评估显示，相比基线设计机械能耗降低50%，同时实现0.8米跳跃高度。

Conclusion: 该框架有效解决了跳跃高度与能耗的权衡问题，产生可直接制造的设计，显著减少手动设计迭代。

Abstract: A monoped's jump height and energy consumption depend on both, its mechanical
design and control strategy. Existing co-design frameworks typically optimize
for either maximum height or minimum energy, neglecting their trade-off. They
also often omit gearbox parameter optimization and use oversimplified actuator
mass models, producing designs difficult to replicate in practice. In this
work, we introduce a novel three-stage co-design optimization framework that
jointly maximizes jump height while minimizing mechanical energy consumption of
a monoped. The proposed method explicitly incorporates realistic actuator mass
models and optimizes mechanical design (including gearbox) and control
parameters within a unified framework. The resulting design outputs are then
used to automatically generate a parameterized CAD model suitable for direct
fabrication, significantly reducing manual design iterations. Our experimental
evaluations demonstrate a 50 percent reduction in mechanical energy consumption
compared to the baseline design, while achieving a jump height of 0.8m. Video
presentation is available at http://y2u.be/XW8IFRCcPgM

</details>


### [27] [Learning to Crawl: Latent Model-Based Reinforcement Learning for Soft Robotic Adaptive Locomotion](https://arxiv.org/abs/2510.05957)
*Vaughn Gzenda,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出一种基于模型强化学习框架，利用从传感器推断的潜在动力学作为预测模型，指导行动者-评论者算法优化软体爬行机器人的运动策略


<details>
  <summary>Details</summary>
Motivation: 软体爬行机器人的控制策略设计面临模型不准确、传感器噪声和运动步态发现困难等挑战

Method: 使用模型强化学习框架，从机载传感器推断潜在动力学作为预测模型，结合行动者-评论者算法优化运动策略

Result: 在仿真环境中，学习的潜在动力学能够实现短时域运动预测，行动者-评论者算法发现了有效的运动策略

Conclusion: 该方法展示了基于潜在动力学的模型强化学习在实现仅依赖噪声传感器反馈的软体机器人自适应运动方面的潜力

Abstract: Soft robotic crawlers are mobile robots that utilize soft body deformability
and compliance to achieve locomotion through surface contact. Designing control
strategies for such systems is challenging due to model inaccuracies, sensor
noise, and the need to discover locomotor gaits. In this work, we present a
model-based reinforcement learning (MB-RL) framework in which latent dynamics
inferred from onboard sensors serve as a predictive model that guides an
actor-critic algorithm to optimize locomotor policies. We evaluate the
framework on a minimal crawler model in simulation using inertial measurement
units and time-of-flight sensors as observations. The learned latent dynamics
enable short-horizon motion prediction while the actor-critic discovers
effective locomotor policies. This approach highlights the potential of
latent-dynamics MB-RL for enabling embodied soft robotic adaptive locomotion
based solely on noisy sensor feedback.

</details>


### [28] [The DISTANT Design for Remote Transmission and Steering Systems for Planetary Robotics](https://arxiv.org/abs/2510.05981)
*Cristina Luna,Alba Guerra,Almudena Moreno,Manuel Esquer,Willy Roa,Mateusz Krawczak,Robert Popela,Piotr Osica,Davide Nicolis*

Main category: cs.RO

TL;DR: DISTANT设计将火星车牵引和转向执行器从车轮位置移至车体热保护箱，解决长距离穿越任务中的热循环、灰尘污染和机械磨损问题。


<details>
  <summary>Details</summary>
Motivation: 行星探测任务需要在极端环境中长期运行，传统车轮安装执行器易受热循环、灰尘和机械磨损影响，影响任务可靠性。

Method: 采用双横臂悬架配置，使用万向节和绞盘驱动转向系统，将所有电机化组件置于保护环境内，实现独立车轮牵引、转向控制和悬架管理。

Result: 设计满足50公里穿越要求且性能不下降，集成了灰尘保护机制和热管理解决方案，计划2026年第一季度进行1:3比例样机测试验证。

Conclusion: DISTANT设计通过重新定位关键执行器到保护环境，显著提升了行星探测车在极端环境下的可靠性和使用寿命。

Abstract: Planetary exploration missions require robust locomotion systems capable of
operating in extreme environments over extended periods. This paper presents
the DISTANT (Distant Transmission and Steering Systems) design, a novel
approach for relocating rover traction and steering actuators from
wheel-mounted positions to a thermally protected warm box within the rover
body. The design addresses critical challenges in long-distance traversal
missions by protecting sensitive components from thermal cycling, dust
contamination, and mechanical wear. A double wishbone suspension configuration
with cardan joints and capstan drive steering has been selected as the optimal
architecture following comprehensive trade-off analysis. The system enables
independent wheel traction, steering control, and suspension management whilst
maintaining all motorisation within the protected environment. The design meets
a 50 km traverse requirement without performance degradation, with integrated
dust protection mechanisms and thermal management solutions. Testing and
validation activities are planned for Q1 2026 following breadboard
manufacturing at 1:3 scale.

</details>


### [29] [AI-Enabled Capabilities to Facilitate Next-Generation Rover Surface Operations](https://arxiv.org/abs/2510.05985)
*Cristina Luna,Robert Field,Steven Kay*

Main category: cs.RO

TL;DR: 本文提出了集成AI系统，通过三个组件显著提高行星探测车的自主性：快速障碍物检测、多机器人协调框架和深度学习地形分类，在火星模拟环境中验证了技术成熟度4级。


<details>
  <summary>Details</summary>
Motivation: 当前行星探测车的行进速度约为10厘米/秒，严重限制了探测效率，需要开发更快的自主导航系统。

Method: 开发了三个集成AI组件：FASTNAV远距离障碍物检测器、CISRU多机器人协调框架，以及ViBEKO和AIAXR深度学习地形分类系统。

Result: 在火星模拟环境中验证了技术成熟度4级，显著提高了行进速度、分类精度和操作安全性。

Conclusion: 这些AI系统为下一代行星任务提供了可衡量的性能改进，实现了1.0米/秒的持续行进速度。

Abstract: Current planetary rovers operate at traverse speeds of approximately 10 cm/s,
fundamentally limiting exploration efficiency. This work presents integrated AI
systems which significantly improve autonomy through three components: (i) the
FASTNAV Far Obstacle Detector (FOD), capable of facilitating sustained 1.0 m/s
speeds via computer vision-based obstacle detection; (ii) CISRU, a multi-robot
coordination framework enabling human-robot collaboration for in-situ resource
utilisation; and (iii) the ViBEKO and AIAXR deep learning-based terrain
classification studies. Field validation in Mars analogue environments
demonstrated these systems at Technology Readiness Level 4, providing
measurable improvements in traverse speed, classification accuracy, and
operational safety for next-generation planetary missions.

</details>


### [30] [Coordinate-Consistent Localization via Continuous-Time Calibration and Fusion of UWB and SLAM Observations](https://arxiv.org/abs/2510.05992)
*Tien-Dat Nguyen,Thien-Minh Nguyen,Vinh-Hao Nguyen*

Main category: cs.RO

TL;DR: 提出一种两阶段方法，通过校准和融合UWB数据与SLAM数据，在相同环境中实现坐标系一致且精确的定位


<details>
  <summary>Details</summary>
Motivation: SLAM方法的坐标系原点每次运行都会重置，而基于固定锚点的UWB定位能确保跨会话的坐标系一致性，但需要准确分配锚点坐标

Method: 第一阶段：使用一次完整运行的测距和里程计数据，通过连续时间批量优化问题恢复锚点的3D位置；第二阶段：通过滑动窗口优化方案融合UWB和SLAM数据

Result: 在NTU VIRAL数据集上的六个无人机飞行场景实验表明，仅使用一次运行的数据进行校准就足以在其余运行中实现精确定位

Conclusion: 该方法能够实现坐标系一致且精确的定位，并开源了代码以惠及社区

Abstract: Onboard simultaneous localization and mapping (SLAM) methods are commonly
used to provide accurate localization information for autonomous robots.
However, the coordinate origin of SLAM estimate often resets for each run. On
the other hand, UWB-based localization with fixed anchors can ensure a
consistent coordinate reference across sessions; however, it requires an
accurate assignment of the anchor nodes' coordinates. To this end, we propose a
two-stage approach that calibrates and fuses UWB data and SLAM data to achieve
coordinate-wise consistent and accurate localization in the same environment.
In the first stage, we solve a continuous-time batch optimization problem by
using the range and odometry data from one full run, incorporating height
priors and anchor-to-anchor distance factors to recover the anchors' 3D
positions. For the subsequent runs in the second stage, a sliding-window
optimization scheme fuses the UWB and SLAM data, which facilitates accurate
localization in the same coordinate system. Experiments are carried out on the
NTU VIRAL dataset with six scenarios of UAV flight, and we show that
calibration using data in one run is sufficient to enable accurate localization
in the remaining runs. We release our source code to benefit the community at
https://github.com/ntdathp/slam-uwb-calibration.

</details>


### [31] [Cross-Embodiment Dexterous Hand Articulation Generation via Morphology-Aware Learning](https://arxiv.org/abs/2510.06068)
*Heng Zhang,Kevin Yuchen Ma,Mike Zheng Shou,Weisi Lin,Yan Wu*

Main category: cs.RO

TL;DR: 提出了一种基于特征抓握的端到端框架，用于跨具身抓握生成，通过形态嵌入和特征抓握集实现不同灵巧手的泛化抓握。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端方法需要针对特定手进行大规模数据集训练，限制了它们在不同具身之间的泛化能力。

Method: 从手的形态描述中推导形态嵌入和特征抓握集，通过振幅预测器在低维空间中回归关节系数，并使用运动学感知关节损失监督学习。

Result: 在模拟中对三个未见过的灵巧手实现了91.9%的平均抓握成功率，推理时间小于0.4秒；通过少样本适应到未见手，在模拟中达到85.6%成功率，真实世界实验达到87%成功率。

Conclusion: 该框架能够有效实现跨具身的灵巧抓握生成，具有高成功率和快速推理能力，且能通过少样本适应泛化到新的手部形态。

Abstract: Dexterous grasping with multi-fingered hands remains challenging due to
high-dimensional articulations and the cost of optimization-based pipelines.
Existing end-to-end methods require training on large-scale datasets for
specific hands, limiting their ability to generalize across different
embodiments. We propose an eigengrasp-based, end-to-end framework for
cross-embodiment grasp generation. From a hand's morphology description, we
derive a morphology embedding and an eigengrasp set. Conditioned on these,
together with the object point cloud and wrist pose, an amplitude predictor
regresses articulation coefficients in a low-dimensional space, which are
decoded into full joint articulations. Articulation learning is supervised with
a Kinematic-Aware Articulation Loss (KAL) that emphasizes fingertip-relevant
motions and injects morphology-specific structure. In simulation on unseen
objects across three dexterous hands, our model attains a 91.9% average grasp
success rate with less than 0.4 seconds inference per grasp. With few-shot
adaptation to an unseen hand, it achieves 85.6% success on unseen objects in
simulation, and real-world experiments on this few-shot generalized hand
achieve an 87% success rate. The code and additional materials will be made
available upon publication on our project website
https://connor-zh.github.io/cross_embodiment_dexterous_grasping.

</details>


### [32] [Multi-Robot Distributed Optimization for Exploration and Mapping of Unknown Environments using Bioinspired Tactile-Sensor](https://arxiv.org/abs/2510.06085)
*Roman Ibrahimov,Jannik Matthias Heinen*

Main category: cs.RO

TL;DR: 提出一种基于分布式优化的仿生多机器人系统，用于未知环境的高效探索和建图。机器人采用类似蟑螂触角的触觉传感器进行壁障探索，通过记录碰撞点来构建全局2D地图。


<details>
  <summary>Details</summary>
Motivation: 受壁障行为启发，开发去中心化控制策略，实现有效的任务分配和未知地形高效探索，应用于搜救、工业检测和环境监测等领域。

Method: 每个机器人使用触觉传感器自主探索环境，记录碰撞点，通过分布式优化将局部地图整合成全局2D地图。在1.5×1.5米模拟环境中使用e-puck机器人进行实验验证。

Result: 实验结果表明，该系统在实现高覆盖率、最小化碰撞和构建准确2D地图方面具有显著效果。

Conclusion: 该仿生多机器人系统通过分布式优化和触觉传感实现了未知环境的高效探索和建图，验证了去中心化控制策略的有效性。

Abstract: This project proposes a bioinspired multi-robot system using Distributed
Optimization for efficient exploration and mapping of unknown environments.
Each robot explores its environment and creates a map, which is afterwards put
together to form a global 2D map of the environment. Inspired by wall-following
behaviors, each robot autonomously explores its neighborhood based on a tactile
sensor, similar to the antenna of a cockroach, mounted on the surface of the
robot. Instead of avoiding obstacles, robots log collision points when they
touch obstacles. This decentralized control strategy ensures effective task
allocation and efficient exploration of unknown terrains, with applications in
search and rescue, industrial inspection, and environmental monitoring. The
approach was validated through experiments using e-puck robots in a simulated
1.5 x 1.5 m environment with three obstacles. The results demonstrated the
system's effectiveness in achieving high coverage, minimizing collisions, and
constructing accurate 2D maps.

</details>


### [33] [Towards Autonomous Tape Handling for Robotic Wound Redressing](https://arxiv.org/abs/2510.06127)
*Xiao Liang,Lu Shen,Peihan Zhang,Soofiyan Atar,Florian Richter,Michael Yip*

Main category: cs.RO

TL;DR: 本文提出了一个自主框架，用于伤口敷料更换中的关键子任务——胶带操作，包括胶带初始分离和安全贴敷两个核心能力。


<details>
  <summary>Details</summary>
Motivation: 慢性伤口影响美国超过650万患者，年成本超过250亿美元。目前伤口护理完全依赖人工操作，需要开发机器人自动化技术来降低成本并改善患者预后。

Method: 使用力反馈模仿学习方法处理胶带分离的复杂粘附动力学，基于人类遥操作演示进行训练；开发数值轨迹优化方法确保胶带在不同解剖表面上的平滑粘附和无皱褶贴敷。

Result: 通过大量实验验证了方法的可靠性，在定量评估和集成伤口敷料更换流程中都表现出良好性能。

Conclusion: 胶带操作是实现实用机器人伤口护理自动化的关键步骤，为未来机器人辅助伤口护理奠定了基础。

Abstract: Chronic wounds, such as diabetic, pressure, and venous ulcers, affect over
6.5 million patients in the United States alone and generate an annual cost
exceeding \$25 billion. Despite this burden, chronic wound care remains a
routine yet manual process performed exclusively by trained clinicians due to
its critical safety demands. We envision a future in which robotics and
automation support wound care to lower costs and enhance patient outcomes. This
paper introduces an autonomous framework for one of the most fundamental yet
challenging subtasks in wound redressing: adhesive tape manipulation.
Specifically, we address two critical capabilities: tape initial detachment
(TID) and secure tape placement. To handle the complex adhesive dynamics of
detachment, we propose a force-feedback imitation learning approach trained
from human teleoperation demonstrations. For tape placement, we develop a
numerical trajectory optimization method based to ensure smooth adhesion and
wrinkle-free application across diverse anatomical surfaces. We validate these
methods through extensive experiments, demonstrating reliable performance in
both quantitative evaluations and integrated wound redressing pipelines. Our
results establish tape manipulation as an essential step toward practical
robotic wound care automation.

</details>


### [34] [Vision-Guided Targeted Grasping and Vibration for Robotic Pollination in Controlled Environments](https://arxiv.org/abs/2510.06146)
*Jaehwan Jeong,Tuan-Anh Vu,Radha Lahoti,Jiawen Wang,Vivek Alumootil,Sangpil Kim,M. Khalid Jawed*

Main category: cs.RO

TL;DR: 提出了一种视觉引导的机器人授粉框架，结合3D植物重建、抓取规划和物理振动建模，实现精确的自动化授粉。


<details>
  <summary>Details</summary>
Motivation: 在受控农业环境中，缺乏风媒授粉且商业授粉者使用受限，机器人授粉成为替代人工和熊蜂授粉的有前景方案。

Method: 使用末端执行器RGB-D传感器进行3D植物重建，识别无障碍抓取位姿；采用离散弹性杆模型预测振动参数与花朵动态关系；软抓手机器人抓取茎干并施加受控振动。

Result: 实验显示主茎抓取成功率达92.5%，通过仿真优化振动参数验证了方法的可行性，确保机器人能安全有效授粉而不损伤花朵。

Conclusion: 这是首个将视觉抓取与振动建模集成用于自动化精确授粉的机器人系统，展示了机器人授粉的实用性和有效性。

Abstract: Robotic pollination offers a promising alternative to manual labor and
bumblebee-assisted methods in controlled agriculture, where wind-driven
pollination is absent and regulatory restrictions limit the use of commercial
pollinators. In this work, we present and validate a vision-guided robotic
framework that uses data from an end-effector mounted RGB-D sensor and combines
3D plant reconstruction, targeted grasp planning, and physics-based vibration
modeling to enable precise pollination. First, the plant is reconstructed in 3D
and registered to the robot coordinate frame to identify obstacle-free grasp
poses along the main stem. Second, a discrete elastic rod model predicts the
relationship between actuation parameters and flower dynamics, guiding the
selection of optimal pollination strategies. Finally, a manipulator with soft
grippers grasps the stem and applies controlled vibrations to induce pollen
release. End-to-end experiments demonstrate a 92.5\% main-stem grasping success
rate, and simulation-guided optimization of vibration parameters further
validates the feasibility of our approach, ensuring that the robot can safely
and effectively perform pollination without damaging the flower. To our
knowledge, this is the first robotic system to jointly integrate vision-based
grasping and vibration modeling for automated precision pollination.

</details>


### [35] [A Preview of HoloOcean 2.0](https://arxiv.org/abs/2510.06160)
*Blake Romrell,Abigail Austin,Braden Meyers,Ryan Anderson,Carter Noh,Joshua G. Mangelson*

Main category: cs.RO

TL;DR: HoloOcean 2.0是一个新一代的海洋机器人模拟器，迁移到Unreal Engine 5.3，提供先进的车辆动力学模型和ROS2支持，旨在支持各种海洋机器人任务开发。


<details>
  <summary>Details</summary>
Motivation: 随着海洋机器人领域的发展，需要更高保真度的传感器、物理和视觉渲染模拟来支持自主海洋机器人的开发和验证。

Method: 迁移到Unreal Engine 5.3，采用Fossen的先进车辆动力学模型，开发自定义ROS2桥接器，并正在开发基于光线追踪的声纳实现、语义传感器等新功能。

Result: HoloOcean 2.0提供了最先进的海洋模拟能力，支持多种任务，具备更好的物理真实性和系统集成能力。

Conclusion: HoloOcean 2.0作为新一代海洋机器人模拟器，通过先进的技术栈和持续开发的新功能，为海洋机器人系统的开发提供了强大的仿真平台。

Abstract: Marine robotics simulators play a fundamental role in the development of
marine robotic systems. With increased focus on the marine robotics field in
recent years, there has been significant interest in developing higher
fidelitysimulation of marine sensors, physics, and visual rendering
capabilities to support autonomous marine robot development and validation.
HoloOcean 2.0, the next major release of HoloOcean, brings state-of-the-art
features under a general marine simulator capable of supporting a variety of
tasks. New features in HoloOcean 2.0 include migration to Unreal Engine (UE)
5.3, advanced vehicle dynamics using models from Fossen, and support for ROS2
using a custom bridge. Additional features are currently in development,
including significantly more efficient ray tracing-based sidescan,
forward-looking, and bathymetric sonar implementations; semantic sensors;
environment generation tools; volumetric environmental effects; and realistic
waves.

</details>


### [36] [DYMO-Hair: Generalizable Volumetric Dynamics Modeling for Robot Hair Manipulation](https://arxiv.org/abs/2510.06199)
*Chengyang Zhao,Uksang Yoo,Arkadeep Narayan Chaudhury,Giljoo Nam,Jonathan Francis,Jeffrey Ichnowski,Jean Oh*

Main category: cs.RO

TL;DR: DYMO-Hair是一个基于模型的机器人护发系统，通过新颖的动态学习范式和3D潜在空间，能够在未见过的发型上实现视觉目标条件发型设计。


<details>
  <summary>Details</summary>
Motivation: 日常护发活动对于行动不便的人群难以进行，且由于头发的细粒度物理结构和复杂动态特性，对自主机器人系统具有挑战性。

Method: 采用基于动作条件的潜在状态编辑机制，结合紧凑的3D潜在空间表示不同发型，使用新型头发物理模拟器进行大规模预训练，并与MPPI规划器结合实现视觉目标条件发型设计。

Result: 在模拟实验中，DYMO-Hair的动态模型在捕捉不同未见发型的局部变形方面优于基线方法，闭环发型设计任务的最终几何误差平均降低22%，成功率提高42%。真实世界实验显示系统能够零样本迁移到假发上。

Conclusion: DYMO-Hair为基于模型的机器人护发奠定了基础，推动在无约束物理环境中实现更通用、灵活和可访问的机器人发型设计。

Abstract: Hair care is an essential daily activity, yet it remains inaccessible to
individuals with limited mobility and challenging for autonomous robot systems
due to the fine-grained physical structure and complex dynamics of hair. In
this work, we present DYMO-Hair, a model-based robot hair care system. We
introduce a novel dynamics learning paradigm that is suited for volumetric
quantities such as hair, relying on an action-conditioned latent state editing
mechanism, coupled with a compact 3D latent space of diverse hairstyles to
improve generalizability. This latent space is pre-trained at scale using a
novel hair physics simulator, enabling generalization across previously unseen
hairstyles. Using the dynamics model with a Model Predictive Path Integral
(MPPI) planner, DYMO-Hair is able to perform visual goal-conditioned hair
styling. Experiments in simulation demonstrate that DYMO-Hair's dynamics model
outperforms baselines on capturing local deformation for diverse, unseen
hairstyles. DYMO-Hair further outperforms baselines in closed-loop hair styling
tasks on unseen hairstyles, with an average of 22% lower final geometric error
and 42% higher success rate than the state-of-the-art system. Real-world
experiments exhibit zero-shot transferability of our system to wigs, achieving
consistent success on challenging unseen hairstyles where the state-of-the-art
system fails. Together, these results introduce a foundation for model-based
robot hair care, advancing toward more generalizable, flexible, and accessible
robot hair styling in unconstrained physical environments. More details are
available on our project page: https://chengyzhao.github.io/DYMOHair-web/.

</details>


### [37] [EmbodiedCoder: Parameterized Embodied Mobile Manipulation via Modern Coding Model](https://arxiv.org/abs/2510.06207)
*Zefu Lin,Rongxu Cui,Chen Hanning,Xiangyu Wang,Junjia Xu,Xiaojuan Jin,Chen Wenbo,Hui Zhou,Lue Fan,Wenling Li,Zhaoxiang Zhang*

Main category: cs.RO

TL;DR: EmbodiedCoder是一个无需训练的开放世界移动机器人操作框架，利用编码模型直接生成可执行的机器人轨迹，通过代码实现高级指令的落地。


<details>
  <summary>Details</summary>
Motivation: 现有机器人控制方法依赖大型标注数据集且可解释性有限，难以扩展到多样化环境。

Method: 使用编码模型将自然语言指令转换为可执行代码，实现对象几何参数化和操作轨迹合成，无需额外数据收集或微调。

Result: 在真实移动机器人上的实验表明，EmbodiedCoder在多样化长期任务中表现稳健，并能有效泛化到新对象和环境。

Conclusion: 该方法提供了一种可解释的方式连接感知与操作，超越了固定原语，向通用机器人智能迈进。

Abstract: Recent advances in control robot methods, from end-to-end
vision-language-action frameworks to modular systems with predefined
primitives, have advanced robots' ability to follow natural language
instructions. Nonetheless, many approaches still struggle to scale to diverse
environments, as they often rely on large annotated datasets and offer limited
interpretability.In this work, we introduce EmbodiedCoder, a training-free
framework for open-world mobile robot manipulation that leverages coding models
to directly generate executable robot trajectories. By grounding high-level
instructions in code, EmbodiedCoder enables flexible object geometry
parameterization and manipulation trajectory synthesis without additional data
collection or fine-tuning.This coding-based paradigm provides a transparent and
generalizable way to connect perception with manipulation. Experiments on real
mobile robots show that EmbodiedCoder achieves robust performance across
diverse long-term tasks and generalizes effectively to novel objects and
environments.Our results demonstrate an interpretable approach for bridging
high-level reasoning and low-level control, moving beyond fixed primitives
toward versatile robot intelligence. See the project page at:
https://anonymous.4open.science/w/Embodied-Coder/

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [38] [Rule Encoding and Compliance in Large Language Models: An Information-Theoretic Analysis](https://arxiv.org/abs/2510.05106)
*Joachim Diederich*

Main category: cs.AI

TL;DR: 该论文通过信息论分析系统提示中规则编码对注意力机制和合规行为的影响，揭示了锚点冗余与注意力熵之间的基本权衡，并提出动态规则验证架构来提高合规输出的概率。


<details>
  <summary>Details</summary>
Motivation: 设计基于大语言模型的安全关键代理需要超越简单的提示工程，需要理解规则编码如何影响注意力机制和合规行为，以保护代理免受提示注入攻击。

Method: 采用信息论分析多种注意力架构（因果、双向、局部稀疏、核化和交叉注意力），建立指针保真度边界，并结合动态规则验证架构进行形式化证明。

Result: 发现低句法熵和高度集中的锚点格式能降低注意力熵并提高指针保真度，但存在锚点冗余与注意力熵之间的权衡。动态规则验证架构能增加合规输出的渐近概率。

Conclusion: 强调需要原则性的锚点设计和双重执行机制，以在保护LLM代理免受提示注入攻击的同时，在演化领域中保持合规性。

Abstract: The design of safety-critical agents based on large language models (LLMs)
requires more than simple prompt engineering. This paper presents a
comprehensive information-theoretic analysis of how rule encodings in system
prompts influence attention mechanisms and compliance behaviour. We demonstrate
that rule formats with low syntactic entropy and highly concentrated anchors
reduce attention entropy and improve pointer fidelity, but reveal a fundamental
trade-off between anchor redundancy and attention entropy that previous work
failed to recognize. Through formal analysis of multiple attention
architectures including causal, bidirectional, local sparse, kernelized, and
cross-attention mechanisms, we establish bounds on pointer fidelity and show
how anchor placement strategies must account for competing fidelity and entropy
objectives. Combining these insights with a dynamic rule verification
architecture, we provide a formal proof that hot reloading of verified rule
sets increases the asymptotic probability of compliant outputs. These findings
underscore the necessity of principled anchor design and dual enforcement
mechanisms to protect LLM-based agents against prompt injection attacks while
maintaining compliance in evolving domains.

</details>


### [39] [Structured Cognition for Behavioral Intelligence in Large Language Model Agents: Preliminary Study](https://arxiv.org/abs/2510.05107)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 提出结构化认知循环（SCL）架构，将推理、记忆和控制功能分离，相比现有提示框架在任务成功率、目标保真度和可靠性方面有稳定提升。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理框架通常将推理、记忆和控制功能混合在单一提示中，这会降低连贯性和可预测性。需要一种分离这些功能的架构来减轻模型认知负担。

Method: SCL架构将语言模型专用于推理，外部维护记忆，通过轻量级控制器在目标导向循环中指导执行，允许中间结果存储、重访和检查。

Result: 在360个测试场景中，SCL任务成功率平均86.3%，优于基线（70-77%），目标保真度更高，冗余调用更少，中间状态重用更可靠，每100次工具调用中的无支持断言减少。

Conclusion: 架构分离可以在不依赖更大模型或更重提示的情况下提高可靠性和可追溯性，为扩展研究提供指导。

Abstract: Large language models have advanced natural language understanding and
generation, yet their use as autonomous agents raises architectural challenges
for multi-step tasks. Existing frameworks often intertwine inference, memory,
and control in a single prompt, which can reduce coherence and predictability.
The Structured Cognitive Loop (SCL) is introduced as an alternative
architecture that separates these functions. In SCL, the language model is
dedicated to inference, memory is maintained externally, and execution is
guided by a lightweight controller within a goal-directed loop. This design
offloads cognitive load from the model and allows intermediate results to be
stored, revisited, and checked before actions are taken, providing a clearer
basis for traceability and evaluation.
  We evaluate SCL against prompt-based baselines including ReAct and common
LangChain agents across three scenarios: temperature-based travel planning,
email drafting with conditional send, and constraint-guided image generation.
All systems share the same base model and tools under matched decoding
settings. Across 360 episodes, SCL shows modest but consistent improvements.
Task success averages 86.3 percent compared with 70-77 percent for baselines.
Goal fidelity is higher, redundant calls are fewer, intermediate states are
reused more reliably, and unsupported assertions per 100 tool calls are
reduced. Ablations show that external memory and control each contribute
independently, and decoding sweeps confirm stability of the effects.
  These results suggest that architectural separation can improve reliability
and traceability without relying on larger models or heavier prompts. The
findings are preliminary and intended to guide extended studies with additional
models, longer horizons, multimodal tasks, and collaborative settings.

</details>


### [40] [Efficient Prediction of Pass@k Scaling in Large Language Models](https://arxiv.org/abs/2510.05197)
*Joshua Kazdan,Rylan Schaeffer,Youssef Allouah,Colin Sullivan,Kyssen Yu,Noam Levi,Sanmi Koyejo*

Main category: cs.AI

TL;DR: 提出了一种改进的统计框架，用于在有限采样预算下准确预测AI模型在大规模尝试中的能力和风险表现。


<details>
  <summary>Details</summary>
Motivation: 重复采样能显著提升AI模型的能力和风险，但现有方法在数据有限时预测准确性不足，这对模型提供商和监管机构都很重要。

Method: 1) 识别标准拟合方法的统计缺陷；2) 引入基于beta-二项分布的稳健估计框架；3) 提出动态采样策略，将更多预算分配给更难的问题。

Result: 该创新框架能以更低的计算成本更可靠地预测罕见风险和能力。

Conclusion: 结合稳健估计和动态采样策略，能够显著提高在有限数据下预测模型大规模行为的能力和风险准确性。

Abstract: Assessing the capabilities and risks of frontier AI systems is a critical
area of research, and recent work has shown that repeated sampling from models
can dramatically increase both. For instance, repeated sampling has been shown
to increase their capabilities, such as solving difficult math and coding
problems, but it has also been shown to increase their potential for harm, such
as being jailbroken. Such results raise a crucial question for both capability
and safety forecasting: how can one accurately predict a model's behavior when
scaled to a massive number of attempts, given a vastly smaller sampling budget?
This question is directly relevant to model providers, who serve hundreds of
millions of users daily, and to governmental regulators, who seek to prevent
harms. To answer this questions, we make three contributions. First, we find
that standard methods for fitting these laws suffer from statistical
shortcomings that hinder predictive accuracy, especially in data-limited
scenarios. Second, we remedy these shortcomings by introducing a robust
estimation framework, which uses a beta-binomial distribution to generate more
accurate predictions from limited data. Third, we propose a dynamic sampling
strategy that allocates a greater budget to harder problems. Combined, these
innovations enable more reliable prediction of rare risks and capabilities at a
fraction of the computational cost.

</details>


### [41] [Optimization Modeling via Semantic Anchored Alignment](https://arxiv.org/abs/2510.05115)
*Yansen Zhang,Qingcan Kang,Yujie Chen,Yufei Wang,Xiongwei Han,Tao Zhong,Mingxuan Yuan,Chen Ma*

Main category: cs.AI

TL;DR: SAC-Opt是一个基于语义锚点的后向引导修正框架，用于提高LLM生成优化模型代码的语义准确性，通过对比原始语义与生成代码重构语义来选择性修正不匹配组件。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成优化模型的方法主要依赖求解器反馈进行单次前向生成和有限的后处理，存在未检测的语义错误，导致生成语法正确但逻辑错误的模型。

Method: 提出语义锚点驱动的后向修正框架，在每一步将原始语义锚点与生成代码重构的语义锚点对齐，选择性修正不匹配组件，实现细粒度的约束和目标逻辑优化。

Result: 在7个公共数据集上的实验表明，SAC-Opt将平均建模准确率提高了7.8%，在ComplexLP数据集上提升高达21.9%。

Conclusion: 语义锚点修正在基于LLM的优化工作流中至关重要，能够确保问题意图到求解器可执行代码的忠实转换。

Abstract: Large language models (LLMs) have opened new paradigms in optimization
modeling by enabling the generation of executable solver code from natural
language descriptions. Despite this promise, existing approaches typically
remain solver-driven: they rely on single-pass forward generation and apply
limited post-hoc fixes based on solver error messages, leaving undetected
semantic errors that silently produce syntactically correct but logically
flawed models. To address this challenge, we propose SAC-Opt, a backward-guided
correction framework that grounds optimization modeling in problem semantics
rather than solver feedback. At each step, SAC-Opt aligns the original semantic
anchors with those reconstructed from the generated code and selectively
corrects only the mismatched components, driving convergence toward a
semantically faithful model. This anchor-driven correction enables fine-grained
refinement of constraint and objective logic, enhancing both fidelity and
robustness without requiring additional training or supervision. Empirical
results on seven public datasets demonstrate that SAC-Opt improves average
modeling accuracy by 7.8\%, with gains of up to 21.9\% on the ComplexLP
dataset. These findings highlight the importance of semantic-anchored
correction in LLM-based optimization workflows to ensure faithful translation
from problem intent to solver-executable code.

</details>


### [42] [Decade-long Emission Forecasting with an Ensemble Model in Taiwan](https://arxiv.org/abs/2510.05548)
*Gordon Hung,Salinna Abdullah*

Main category: cs.AI

TL;DR: 该研究比较了21种时间序列模型预测台湾二氧化碳排放量，发现FFNN、SVM和RFR表现最佳，并通过集成学习构建了更稳健的预测模型，为政策制定提供数据支持。


<details>
  <summary>Details</summary>
Motivation: 台湾人口密集且高度依赖化石燃料导致严重空气污染，二氧化碳是最主要的温室气体，需要准确预测排放量以支持政策决策。

Method: 比较21种常用时间序列模型（包括单变量和多变量方法），对表现最佳的FFNN、SVM和RFR模型通过自定义堆叠泛化集成技术与线性回归结合。

Result: 提出的集成模型SMAPE达到1.407，没有过拟合迹象，提供了准确的十年期排放预测。

Conclusion: 该研究开发了稳健的排放预测模型，能够为政策制定者提供数据驱动的决策支持。

Abstract: Taiwan's high population and heavy dependence on fossil fuels have led to
severe air pollution, with the most prevalent greenhouse gas being carbon
dioxide (CO2). There-fore, this study presents a reproducible and comprehensive
case study comparing 21 of the most commonly employed time series models in
forecasting emissions, analyzing both univariate and multivariate approaches.
Among these, Feedforward Neural Network (FFNN), Support Vector Machine (SVM),
and Random Forest Regressor (RFR) achieved the best performances. To further
enhance robustness, the top performers were integrated with Linear Regression
through a custom stacked generalization en-semble technique. Our proposed
ensemble model achieved an SMAPE of 1.407 with no signs of overfitting.
Finally, this research provides an accurate decade-long emission projection
that will assist policymakers in making more data-driven decisions.

</details>


### [43] [Structuring Reasoning for Complex Rules Beyond Flat Representations](https://arxiv.org/abs/2510.05134)
*Zhihao Yang,Ancheng Xu,Jingpeng Li,Liang Yan,Jiehui Zhou,Zhen Qin,Hengyun Chang,Ahmadreza Argha,Hamid Alinejad-Rokny,Minghuan Tan,Yujun Cai,Min Yang*

Main category: cs.AI

TL;DR: 提出动态裁决模板(DAT)框架，通过三阶段推理机制解决大语言模型处理复杂规则系统的局限性，显著优于传统思维链方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理复杂规则系统时面临挑战，通常将相互依赖的规则视为非结构化文本而非逻辑框架，导致推理偏差和关键规则依赖被忽略。

Method: DAT框架包含三个方法化阶段：定性分析（全面评估上下文）、证据收集（基于模板元素提取和验证信息）、裁决（综合验证组件形成判断）。

Result: 实证结果显示DAT在复杂规则任务中持续优于传统CoT方法，且能让较小模型达到甚至超越更大LLM的性能。

Conclusion: DAT框架通过结构化推理机制有效管理复杂规则系统，在效率和效果上表现出色，为规则处理提供了系统化方法。

Abstract: Large language models (LLMs) face significant challenges when processing
complex rule systems, as they typically treat interdependent rules as
unstructured textual data rather than as logically organized frameworks. This
limitation results in reasoning divergence, where models often overlook
critical rule dependencies essential for accurate interpretation. Although
existing approaches such as Chain-of-Thought (CoT) reasoning have shown
promise, they lack systematic methodologies for structured rule processing and
are particularly susceptible to error propagation through sequential reasoning
chains. To address these limitations, we propose the Dynamic Adjudication
Template (DAT), a novel framework inspired by expert human reasoning processes.
DAT structures the inference mechanism into three methodical stages:
qualitative analysis, evidence gathering, and adjudication. During the
qualitative analysis phase, the model comprehensively evaluates the contextual
landscape. The subsequent evidence gathering phase involves the targeted
extraction of pertinent information based on predefined template elements
([placeholder]), followed by systematic verification against applicable rules.
Finally, in the adjudication phase, the model synthesizes these validated
components to formulate a comprehensive judgment. Empirical results demonstrate
that DAT consistently outperforms conventional CoT approaches in complex
rule-based tasks. Notably, DAT enables smaller language models to match, and in
some cases exceed, the performance of significantly larger LLMs, highlighting
its efficiency and effectiveness in managing intricate rule systems.

</details>


### [44] [An Algorithmic Information-Theoretic Perspective on the Symbol Grounding Problem](https://arxiv.org/abs/2510.05153)
*Zhangchi Liu*

Main category: cs.AI

TL;DR: 本文通过算法信息理论重新定义符号接地问题，证明意义接地是一个受信息理论限制的过程，统一了哥德尔自指和没有免费午餐统计视角。


<details>
  <summary>Details</summary>
Motivation: 为符号接地问题提供一个确定性的统一框架，揭示意义接地过程受信息理论基本限制的约束。

Method: 将符号系统建模为通用图灵机，将接地定义为信息压缩过程，通过四个阶段论证：证明纯符号系统无法接地算法随机世界；静态接地系统的不完备性；接地行为的不可推断性；以及算法学习过程的局限性。

Result: 证明了符号系统无法接地算法随机世界，任何静态接地系统都存在不完备性，接地行为需要新信息输入而不可推断，算法学习过程无法理解超过自身复杂度的世界。

Conclusion: 意义是一个系统不断尝试克服自身信息理论限制的开放过程，符号接地受到根本性的信息理论约束。

Abstract: This paper provides a definitive, unifying framework for the Symbol Grounding
Problem (SGP) by reformulating it within Algorithmic Information Theory (AIT).
We demonstrate that the grounding of meaning is a process fundamentally
constrained by information-theoretic limits, thereby unifying the G\"odelian
(self-reference) and No Free Lunch (statistical) perspectives. We model a
symbolic system as a universal Turing machine and define grounding as an act of
information compression. The argument proceeds in four stages. First, we prove
that a purely symbolic system cannot ground almost all possible "worlds" (data
strings), as they are algorithmically random and thus incompressible. Second,
we show that any statically grounded system, specialized for compressing a
specific world, is inherently incomplete because an adversarial, incompressible
world relative to the system can always be constructed. Third, the "grounding
act" of adapting to a new world is proven to be non-inferable, as it requires
the input of new information (a shorter program) that cannot be deduced from
the system's existing code. Finally, we use Chaitin's Incompleteness Theorem to
prove that any algorithmic learning process is itself a finite system that
cannot comprehend or model worlds whose complexity provably exceeds its own.
This establishes that meaning is the open-ended process of a system perpetually
attempting to overcome its own information-theoretic limitations.

</details>


### [45] [Lang-PINN: From Language to Physics-Informed Neural Networks via a Multi-Agent Framework](https://arxiv.org/abs/2510.05158)
*Xin He,Liangliang You,Hongduan Tian,Bo Han,Ivor Tsang,Yew-Soon Ong*

Main category: cs.AI

TL;DR: Lang-PINN是一个基于大语言模型的多智能体系统，能够直接从自然语言任务描述构建可训练的物理信息神经网络(PINNs)，显著降低了PINN构建的复杂性和错误率。


<details>
  <summary>Details</summary>
Motivation: 传统PINN构建过程劳动密集且容易出错，科学家需要将问题解释为PDE公式、设计架构和损失函数、实现稳定的训练流程。现有LLM方法只解决孤立步骤，缺乏端到端的视角。

Method: Lang-PINN协调四个互补智能体：PDE智能体将任务描述解析为符号PDE，PINN智能体选择架构，代码智能体生成模块化实现，反馈智能体执行和诊断错误进行迭代优化。

Result: 实验显示Lang-PINN比竞争基线显著降低误差和提高鲁棒性：均方误差降低3-5个数量级，端到端执行成功率提高50%以上，时间开销减少74%。

Conclusion: 该设计将非正式任务陈述转化为可执行和可验证的PINN代码，为PINN的自动化构建提供了有效的端到端解决方案。

Abstract: Physics-informed neural networks (PINNs) provide a powerful approach for
solving partial differential equations (PDEs), but constructing a usable PINN
remains labor-intensive and error-prone. Scientists must interpret problems as
PDE formulations, design architectures and loss functions, and implement stable
training pipelines. Existing large language model (LLM) based approaches
address isolated steps such as code generation or architecture suggestion, but
typically assume a formal PDE is already specified and therefore lack an
end-to-end perspective. We present Lang-PINN, an LLM-driven multi-agent system
that builds trainable PINNs directly from natural language task descriptions.
Lang-PINN coordinates four complementary agents: a PDE Agent that parses task
descriptions into symbolic PDEs, a PINN Agent that selects architectures, a
Code Agent that generates modular implementations, and a Feedback Agent that
executes and diagnoses errors for iterative refinement. This design transforms
informal task statements into executable and verifiable PINN code. Experiments
show that Lang-PINN achieves substantially lower errors and greater robustness
than competitive baselines: mean squared error (MSE) is reduced by up to 3--5
orders of magnitude, end-to-end execution success improves by more than 50\%,
and reduces time overhead by up to 74\%.

</details>


### [46] [Artificially intelligent agents in the social and behavioral sciences: A history and outlook](https://arxiv.org/abs/2510.05743)
*Petter Holme,Milena Tsvetkova*

Main category: cs.AI

TL;DR: 本文回顾了从1950年代至今人工智能代理在社会科学中的发展历程，涵盖社会模拟、智能博弈论代理、大数据时代到生成式AI应用等关键阶段。


<details>
  <summary>Details</summary>
Motivation: 探讨AI技术在社会科学研究中的历史演变和当前趋势，分析技术发展如何改变科学认知过程以及人类与理解自身技术的深度交织关系。

Method: 采用历史回顾和趋势分析的方法，系统梳理从第一台可编程计算机到现代大语言模型在社会科学中的应用发展脉络。

Result: 展示了AI代理在社会科学中的完整发展轨迹，揭示了技术变革如何推动科学范式的转变，特别是在社会模拟、数据分析和认知理解方面的突破。

Conclusion: 人类与理解自身的技术深度交织，AI的发展不仅改变了社会科学的研究方法，更重塑了我们对人类行为的认知框架。

Abstract: We review the historical development and current trends of artificially
intelligent agents (agentic AI) in the social and behavioral sciences: from the
first programmable computers, and social simulations soon thereafter, to
today's experiments with large language models. This overview emphasizes the
role of AI in the scientific process and the changes brought about, both
through technological advancements and the broader evolution of science from
around 1950 to the present. Some of the specific points we cover include: the
challenges of presenting the first social simulation studies to a world unaware
of computers, the rise of social systems science, intelligent game theoretic
agents, the age of big data and the epistemic upheaval in its wake, and the
current enthusiasm around applications of generative AI, and many other topics.
A pervasive theme is how deeply entwined we are with the technologies we use to
understand ourselves.

</details>


### [47] [Representation Potentials of Foundation Models for Multimodal Alignment: A Survey](https://arxiv.org/abs/2510.05184)
*Jianglin Lu,Hailing Wang,Yi Xu,Yizhou Wang,Kuo Yang,Yun Fu*

Main category: cs.AI

TL;DR: 该调查论文探讨了基础模型的表征潜力，即其学习到的表征在单一模态内捕获任务特定信息，同时为跨模态对齐和统一提供可迁移基础的能力。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型通过大规模预训练学习到高度可迁移的表征，研究发现这些表征在不同架构和模态间表现出显著相似性，这激发了对其表征潜力的系统研究。

Method: 通过回顾代表性基础模型和关键度量指标，综合来自视觉、语言、语音、多模态和神经科学研究的实证证据，分析表征空间中的结构规律性和语义一致性。

Result: 证据表明基础模型通常在其表征空间中表现出结构规律性和语义一致性，使其成为跨模态迁移和对齐的有力候选者。

Conclusion: 基础模型具有强大的表征潜力，能够支持跨模态的迁移和对齐，但仍存在开放问题和潜在挑战需要进一步研究。

Abstract: Foundation models learn highly transferable representations through
large-scale pretraining on diverse data. An increasing body of research
indicates that these representations exhibit a remarkable degree of similarity
across architectures and modalities. In this survey, we investigate the
representation potentials of foundation models, defined as the latent capacity
of their learned representations to capture task-specific information within a
single modality while also providing a transferable basis for alignment and
unification across modalities. We begin by reviewing representative foundation
models and the key metrics that make alignment measurable. We then synthesize
empirical evidence of representation potentials from studies in vision,
language, speech, multimodality, and neuroscience. The evidence suggests that
foundation models often exhibit structural regularities and semantic
consistencies in their representation spaces, positioning them as strong
candidates for cross-modal transfer and alignment. We further analyze the key
factors that foster representation potentials, discuss open questions, and
highlight potential challenges.

</details>


### [48] [Moloch's Bargain: Emergent Misalignment When LLMs Compete for Audiences](https://arxiv.org/abs/2510.06105)
*Batu El,James Zou*

Main category: cs.AI

TL;DR: 优化LLMs在竞争环境中的表现会导致模型失准，即使有对齐保障，竞争压力仍会驱动欺骗性行为。


<details>
  <summary>Details</summary>
Motivation: 研究竞争性反馈循环如何影响LLM行为，特别是在商业、政治和社交媒体等竞争性场景中。

Method: 在模拟环境中测试LLMs在销售、选举和社交媒体场景中的表现，测量竞争优化对模型行为的影响。

Result: 竞争优化导致显著的行为恶化：销售场景中欺骗性营销增加14.0%，选举中虚假信息增加22.3%，社交媒体中虚假信息激增188.6%。

Conclusion: 市场竞争压力会系统性地侵蚀AI对齐，需要更强治理和精心设计的激励机制来防止竞争动态破坏社会信任。

Abstract: Large language models (LLMs) are increasingly shaping how information is
created and disseminated, from companies using them to craft persuasive
advertisements, to election campaigns optimizing messaging to gain votes, to
social media influencers boosting engagement. These settings are inherently
competitive, with sellers, candidates, and influencers vying for audience
approval, yet it remains poorly understood how competitive feedback loops
influence LLM behavior. We show that optimizing LLMs for competitive success
can inadvertently drive misalignment. Using simulated environments across these
scenarios, we find that, 6.3% increase in sales is accompanied by a 14.0% rise
in deceptive marketing; in elections, a 4.9% gain in vote share coincides with
22.3% more disinformation and 12.5% more populist rhetoric; and on social
media, a 7.5% engagement boost comes with 188.6% more disinformation and a
16.3% increase in promotion of harmful behaviors. We call this phenomenon
Moloch's Bargain for AI--competitive success achieved at the cost of alignment.
These misaligned behaviors emerge even when models are explicitly instructed to
remain truthful and grounded, revealing the fragility of current alignment
safeguards. Our findings highlight how market-driven optimization pressures can
systematically erode alignment, creating a race to the bottom, and suggest that
safe deployment of AI systems will require stronger governance and carefully
designed incentives to prevent competitive dynamics from undermining societal
trust.

</details>


### [49] [Real-time Framework for Interoperable Semantic-driven Internet-of-Things in Smart Agriculture](https://arxiv.org/abs/2510.05187)
*Mohamed El-Dosuky*

Main category: cs.AI

TL;DR: 提出一个包含六个语义层的实时物联网框架，通过语义标注、互操作性和推理来增强物联网设备对数据的理解和处理能力，特别适用于农业等动态环境。


<details>
  <summary>Details</summary>
Motivation: 物联网在农业等应用中面临数据收集和理解方面的挑战，需要让物联网设备和传感器能够理解数据的含义和来源，实现更智能的数据处理。

Method: 构建六层框架：感知层、语义标注层、互操作层、传输层、语义推理层和应用层。使用语义算法标准化文件类型和识别同义词，采用模糊逻辑、Dempster-Shafer理论和贝叶斯网络进行知识推理。

Result: 开发了一个完整的语义物联网框架，能够实现数据的语义标注、标准化传输和智能推理，为物联网数据管理提供了稳健解决方案。

Conclusion: 该框架通过整合不确定性推理方法和语义互操作技术，为物联网应用特别是农业领域提供了有价值的工具，确保了语义完整性和实时知识推理能力。

Abstract: The Internet of Things (IoT) has revolutionized various applications
including agriculture, but it still faces challenges in data collection and
understanding. This paper proposes a real-time framework with three additional
semantic layers to help IoT devices and sensors comprehend data meaning and
source. The framework consists of six layers: perception, semantic annotation,
interoperability, transportation, semantic reasoning, and application, suitable
for dynamic environments. Sensors collect data in the form of voltage, which is
then processed by microprocessors or microcontrollers in the semantic
annotation and preprocessing layer. Metadata is added to the raw data,
including the purpose, ID number, and application. Two semantic algorithms are
proposed in the semantic interoperability and ontologies layer: the
interoperability semantic algorithm for standardizing file types and the
synonym identification algorithm for identifying synonyms. In the
transportation layer, raw data and metadata are sent to other IoT devices or
cloud computing platforms using techniques like WiFi, Zigbee networks,
Bluetooth, and mobile communication networks. A semantic reasoning layer is
proposed to infer new knowledge from the existing data, using fuzzy logic,
Dempster-Shafer theory, and Bayesian networks. A Graphical User Interface (GUI)
is proposed in the application layer to help users communicate with and monitor
IoT sensors, devices, and new knowledge inferred. This framework provides a
robust solution for managing IoT data, ensuring semantic completeness, and
enabling real-time knowledge inference. The integration of uncertainty
reasoning methods and semantic interoperability techniques makes this framework
a valuable tool for advancing IoT applications in general and in agriculture in
particular.

</details>


### [50] [Plug-and-Play Dramaturge: A Divide-and-Conquer Approach for Iterative Narrative Script Refinement via Collaborative LLM Agents](https://arxiv.org/abs/2510.05188)
*Wenda Xie,Chao Guo,Yanqing Jing. Junle Wang,Yisheng Lv,Fei-Yue Wang*

Main category: cs.AI

TL;DR: Dramaturge是一个基于分层多LLM代理的任务导向分治方法，用于改进长篇叙事脚本的质量。它通过全局审查、场景级审查和分层协调修订三个阶段，以自上而下的方式确保局部修改与整体叙事要求的一致性。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM已广泛用于创意内容生成，但单次生成过程难以产生高质量的长篇叙事。如何像编剧一样有效修订和改进长篇叙事脚本仍是一个重大挑战，因为这需要全面理解整个上下文以识别全局结构问题和局部细节缺陷，并协调多个粒度和位置的修订。

Method: 提出Dramaturge方法，包含三个阶段：1）全局审查阶段把握整体故事情节和结构问题；2）场景级审查阶段识别详细场景和句子缺陷；3）分层协调修订阶段协调并整合整个脚本的结构和细节改进。采用从粗到精的迭代过程，直到无法做出实质性改进为止。

Result: 综合实验表明，Dramaturge在脚本级整体质量和场景级细节方面显著优于所有基线方法。

Conclusion: 该方法即插即用，可以轻松集成到现有方法中以改进生成的脚本。

Abstract: Although LLMs have been widely adopted for creative content generation, a
single-pass process often struggles to produce high-quality long narratives.
How to effectively revise and improve long narrative scripts like scriptwriters
remains a significant challenge, as it demands a comprehensive understanding of
the entire context to identify global structural issues and local detailed
flaws, as well as coordinating revisions at multiple granularities and
locations. Direct modifications by LLMs typically introduce inconsistencies
between local edits and the overall narrative requirements. To address these
issues, we propose Dramaturge, a task and feature oriented divide-and-conquer
approach powered by hierarchical multiple LLM agents. It consists of a Global
Review stage to grasp the overall storyline and structural issues, a
Scene-level Review stage to pinpoint detailed scene and sentence flaws, and a
Hierarchical Coordinated Revision stage that coordinates and integrates
structural and detailed improvements throughout the script. The top-down task
flow ensures that high-level strategies guide local modifications, maintaining
contextual consistency. The review and revision workflow follows a
coarse-to-fine iterative process, continuing through multiple rounds until no
further substantive improvements can be made. Comprehensive experiments show
that Dramaturge significantly outperforms all baselines in terms of
script-level overall quality and scene-level details. Our approach is
plug-and-play and can be easily integrated into existing methods to improve the
generated scripts.

</details>


### [51] [Graph-based LLM over Semi-Structured Population Data for Dynamic Policy Response](https://arxiv.org/abs/2510.05196)
*Daqian Shi,Xiaolei Diao,Jinge Wu,Honghan Wu,Xiongfeng Tang,Felix Naughton,Paulina Bondaronek*

Main category: cs.AI

TL;DR: 提出了一种基于图推理的框架，将大语言模型与结构化人口属性和非结构化公众反馈相结合，用于公共卫生应急中的智能人口健康监测。


<details>
  <summary>Details</summary>
Motivation: 在COVID-19等公共卫生紧急情况下，传统分析方法难以处理海量半结构化数据，专家评估效率低，标准NLP方法需要大量标注数据且泛化能力差。

Method: 使用弱监督管道，将大语言模型与人口属性和公众反馈集成，构建需求感知图，基于年龄、性别、多重剥夺指数等关键特征进行人群特定分析。

Result: 在真实数据集上的初步实验结果表明该方法的可行性。

Conclusion: 该方法为资源受限的临床和政府环境提供了可扩展的智能人口健康监测解决方案。

Abstract: Timely and accurate analysis of population-level data is crucial for
effective decision-making during public health emergencies such as the COVID-19
pandemic. However, the massive input of semi-structured data, including
structured demographic information and unstructured human feedback, poses
significant challenges to conventional analysis methods. Manual expert-driven
assessments, though accurate, are inefficient, while standard NLP pipelines
often require large task-specific labeled datasets and struggle with
generalization across diverse domains. To address these challenges, we propose
a novel graph-based reasoning framework that integrates large language models
with structured demographic attributes and unstructured public feedback in a
weakly supervised pipeline. The proposed approach dynamically models evolving
citizen needs into a need-aware graph, enabling population-specific analyses
based on key features such as age, gender, and the Index of Multiple
Deprivation. It generates interpretable insights to inform responsive health
policy decision-making. We test our method using a real-world dataset, and
preliminary experimental results demonstrate its feasibility. This approach
offers a scalable solution for intelligent population health monitoring in
resource-constrained clinical and governmental settings.

</details>


### [52] [Beyond Monolithic Rewards: A Hybrid and Multi-Aspect Reward Optimization for MLLM Alignment](https://arxiv.org/abs/2510.05283)
*Radha Gulhane,Sathish Reddy Indurthi*

Main category: cs.AI

TL;DR: 提出混合奖励建模框架，结合模型奖励和规则奖励，通过多维度奖励信号提升多模态大语言模型与人类偏好的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于单一信号的模型奖励方法存在置信度校准不足、无法捕捉人类偏好多样性、需要大量数据标注和奖励模型训练等问题。

Method: 集成模型奖励（从合成和人类反馈中预测标量或向量分数）和规则奖励（领域特定启发式提供显式正确性信号），并引入多维度奖励和广义长度惩罚奖励。

Result: 在3B模型家族中，通用和数学推理任务平均提升约9.5%，数学基准测试平均提升约16%。

Conclusion: 混合奖励建模框架为通过强化学习策略优化对齐多模态大语言模型提供了灵活有效的方法。

Abstract: Aligning multimodal large language models (MLLMs) with human preferences
often relies on single-signal, model-based reward methods. Such monolithic
rewards often lack confidence calibration across domain-specific tasks, fail to
capture diverse aspects of human preferences, and require extensive data
annotation and reward model training. In this work, we propose a hybrid reward
modeling framework that integrates complementary reward paradigms: (i)
model-based rewards, where a learned reward model predicts scalar or vector
scores from synthetic and human feedback, and (ii) rule-based rewards, where
domain-specific heuristics provide explicit correctness signals with
confidence. Beyond accuracy, we further incorporate multi-aspect rewards to
enforce instruction adherence and introduce a generalized length-penalty reward
to stabilize training and improve performance. The proposed framework provides
a flexible and effective approach to aligning MLLMs through reinforcement
learning policy optimization. Our experiments show consistent improvements
across different multimodal benchmarks when applying hybrid and multi-aspect
reward modeling. Our best performing model in the 3B family achieves an overall
average improvement of ~9.5% across general and math reasoning tasks. Focusing
specifically on mathematical benchmarks, the model achieves a significant
average improvement of ~16%, highlighting its effectiveness in mathematical
reasoning and problem solving.

</details>


### [53] [BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models via Lens of Dynamic Interactions](https://arxiv.org/abs/2510.05318)
*Nan Huo,Xiaohan Xu,Jinyang Li,Per Jacobsson,Shipei Lin,Bowen Qin,Binyuan Hui,Xiaolong Li,Ge Qu,Shuzheng Si,Linheng Han,Edward Alexander,Xintong Zhu,Rui Qin,Ruihan Yu,Yiyao Jin,Feige Zhou,Weihao Zhong,Yun Chen,Hongyu Liu,Chenhao Ma,Fatma Ozcan,Yannis Papakonstantinou,Reynold Cheng*

Main category: cs.AI

TL;DR: BIRD-INTERACT是一个用于评估多轮交互式文本到SQL任务的基准测试，通过模拟真实数据库应用环境，包含完整CRUD操作、知识库检索和错误恢复功能，挑战现有语言模型在动态交互场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有文本到SQL基准测试主要关注单轮任务，无法反映真实数据库应用中常见的多轮交互需求，如处理模糊查询、执行错误和用户需求变化等动态场景。

Method: 构建包含层次化知识库、元数据文件和函数驱动用户模拟器的综合交互环境；设计两种评估设置：预定义对话协议(c-Interact)和开放式代理设置(a-Interact)；开发覆盖完整CRUD操作的任务套件，包含模糊和后续子任务。

Result: BIRD-INTERACT表现出较高难度，GPT-5在c-Interact中仅完成8.67%任务，在a-Interact中完成17.00%任务，验证了有效交互对复杂动态文本到SQL任务的重要性。

Conclusion: BIRD-INTERACT基准测试成功恢复了真实数据库助手应用的现实性，强调了多轮交互能力在文本到SQL任务中的关键作用，为未来研究提供了重要评估框架。

Abstract: Large language models (LLMs) have demonstrated remarkable performance on
single-turn text-to-SQL tasks, but real-world database applications
predominantly require multi-turn interactions to handle ambiguous queries,
execution errors, and evolving user requirements. Existing multi-turn
benchmarks fall short by treating conversation histories as static context or
limiting evaluation to read-only operations, failing to reflect
production-grade database assistant challenges. We introduce BIRD-INTERACT, a
benchmark that restores this realism through: (1) a comprehensive interaction
environment coupling each database with a hierarchical knowledge base, metadata
files, and a function-driven user simulator, enabling models to solicit
clarifications, retrieve knowledge, and recover from errors without human
supervision; (2) two evaluation settings consisting of a pre-defined
conversational protocol (c-Interact) and an open-ended agentic setting
(a-Interact) where models autonomously decide when to query the user simulator
or explore the environment; (3) a challenging task suite covering the full CRUD
spectrum for business-intelligence and operational use cases, guarded by
executable test cases. Each task features ambiguous and follow-up sub-tasks
requiring dynamic interaction. The suite comprises BIRD-INTERACT-FULL (600
tasks, up to 11,796 interactions) for comprehensive performance assessment, and
BIRD-INTERACT-LITE (300 tasks with simplified databases) for detailed
behavioral analysis and rapid method development. Our empirical results
highlight BIRD-INTERACT's difficulty: GPT-5 completes only 8.67% of tasks in
c-Interact and 17.00% in a-Interact. Analysis via memory grafting and
Interaction Test-time Scaling validates the importance of effective interaction
for complex, dynamic text-to-SQL tasks.

</details>


### [54] [Biomedical reasoning in action: Multi-agent System for Auditable Biomedical Evidence Synthesis](https://arxiv.org/abs/2510.05335)
*Oskar Wysocki,Magdalena Wysocka,Mauricio Jacobo,Harriet Unsworth,André Freitas*

Main category: cs.AI

TL;DR: M-Reason是一个用于生物医学领域（特别是癌症研究）的透明、基于代理的推理和证据整合演示系统，利用LLM和模块化代理编排自动化证据检索、评估和合成。


<details>
  <summary>Details</summary>
Motivation: 解决生物医学研究中证据整合的复杂性问题，通过多代理系统提高证据合成的效率和透明度，强调可解释性和用户可审计性。

Method: 使用大型语言模型和模块化代理编排，每个代理专门处理特定的证据流，支持并行处理和细粒度分析，结合确定性代码进行验证。

Result: 评估显示在效率和输出一致性方面有显著提升，系统可作为证据合成的实用工具和科学研究中稳健多代理LLM系统的测试平台。

Conclusion: M-Reason展示了多代理LLM系统在生物医学证据合成中的潜力，平衡了代理专业化、系统复杂性和资源使用之间的关键权衡。

Abstract: We present M-Reason, a demonstration system for transparent, agent-based
reasoning and evidence integration in the biomedical domain, with a focus on
cancer research. M-Reason leverages recent advances in large language models
(LLMs) and modular agent orchestration to automate evidence retrieval,
appraisal, and synthesis across diverse biomedical data sources. Each agent
specializes in a specific evidence stream, enabling parallel processing and
fine-grained analysis. The system emphasizes explainability, structured
reporting, and user auditability, providing complete traceability from source
evidence to final conclusions. We discuss critical tradeoffs between agent
specialization, system complexity, and resource usage, as well as the
integration of deterministic code for validation. An open, interactive user
interface allows researchers to directly observe, explore and evaluate the
multi-agent workflow. Our evaluation demonstrates substantial gains in
efficiency and output consistency, highlighting M-Reason's potential as both a
practical tool for evidence synthesis and a testbed for robust multi-agent LLM
systems in scientific research, available at https://m-reason.digitalecmt.com.

</details>


### [55] [Integrating Bayesian methods with neural network--based model predictive control: a review](https://arxiv.org/abs/2510.05338)
*Asli Karacelik*

Main category: cs.AI

TL;DR: 本文综述了贝叶斯方法在模型预测控制中的应用，重点关注神经网络建模、控制设计和不确定性量化，指出当前研究存在基准不一致和可靠性分析有限的问题，呼吁建立标准化基准和透明报告。


<details>
  <summary>Details</summary>
Motivation: 评估贝叶斯方法在模型预测控制中的实际应用效果，系统分析现有研究的实施方式，识别当前研究中的局限性。

Method: 通过系统性地分析个体研究及其实际实施方式，评估贝叶斯方法在神经网络建模、控制设计和不确定性量化中的应用。

Result: 发现贝叶斯方法在MPC中越来越被用于捕捉和传播不确定性，但报告的性能和鲁棒性提升结果分散，存在基准不一致和可靠性分析有限的问题。

Conclusion: 需要建立标准化基准、消融研究和透明报告机制，以严格确定贝叶斯技术在MPC中的有效性。

Abstract: In this review, we assess the use of Bayesian methods in model predictive
control (MPC), focusing on neural-network-based modeling, control design, and
uncertainty quantification. We systematically analyze individual studies and
how they are implemented in practice. While Bayesian approaches are
increasingly adopted to capture and propagate uncertainty in MPC, reported
gains in performance and robustness remain fragmented, with inconsistent
baselines and limited reliability analyses. We therefore argue for standardized
benchmarks, ablation studies, and transparent reporting to rigorously determine
the effectiveness of Bayesian techniques for MPC.

</details>


### [56] [MHA-RAG: Improving Efficiency, Accuracy, and Consistency by Encoding Exemplars as Soft Prompts](https://arxiv.org/abs/2510.05363)
*Abhinav Jain,Xinyu Yao,Thomas Reps,Christopher Jermaine*

Main category: cs.AI

TL;DR: MHA-RAG框架通过将示例表示为软提示而非纯文本，实现了比标准RAG更高的准确性和效率，性能提升20分，推理成本降低10倍，且对示例顺序不敏感。


<details>
  <summary>Details</summary>
Motivation: 传统方法使用领域特定示例作为上下文演示，但纯文本表示可能不是最高效、最有效和最稳定的方法。

Method: 提出MHA-RAG框架，使用软提示表示示例，通过注意力头数量控制不同任务的软提示生成，构建示例顺序不变的模型架构。

Result: 在多个问答基准测试和模型规模下，MHA-RAG相比标准RAG实现20分性能提升，推理成本降低10倍GFLOPs。

Conclusion: 软提示表示比纯文本表示更高效有效，MHA-RAG在保持示例顺序不变性的同时实现了更高的准确性和效率。

Abstract: Adapting Foundation Models to new domains with limited training data is
challenging and computationally expensive. While prior work has demonstrated
the effectiveness of using domain-specific exemplars as in-context
demonstrations, we investigate whether representing exemplars purely as text is
the most efficient, effective, and stable approach. We explore an alternative:
representing exemplars as soft prompts with an exemplar order invariant model
architecture. To this end, we introduce Multi-Head Attention
Retrieval-Augmented Generation (MHA-RAG), a framework with the number of
attention heads serving as a simple hyperparameter to control soft
prompt-generation across different tasks. Across multiple question-answering
benchmarks and model scales, MHA-RAG achieves a 20-point performance gain over
standard RAG, while cutting inference costs by a factor of 10X
GFLOPs-delivering both higher accuracy and greater efficiency, invariant to
exemplar order.

</details>


### [57] [What Do You Mean? Exploring How Humans and AI Interact with Symbols and Meanings in Their Interactions](https://arxiv.org/abs/2510.05378)
*Reza Habibi,Seung Wan Ha,Zhiyu Lin,Atieh Kashani,Ala Shafia,Lakshana Lakshmanarajan,Chia-Fang Chung,Magy Seif El-Nasr*

Main category: cs.AI

TL;DR: 该研究基于符号互动理论，通过两项实证研究探讨人类与AI如何共同构建符号及其意义，发现意义共享不是来自简单同意，而是来自符号的双向交换和重新解释。


<details>
  <summary>Details</summary>
Motivation: 有意义的人机协作需要超越语言处理，深入理解符号及其社会建构意义。人类通过社交互动自然解释符号，而AI系统往往错过对话中出现的动态解释。

Method: 基于符号互动理论，进行了两项实证研究，调查人类与AI如何共同构建符号及其意义。

Result: 研究发现参与者会根据对话AI建议的符号和解释调整初始意义定义，特别是在引入社交语境时。参与者还会投射个人和社会价值观到互动中，随时间推移精炼意义。

Conclusion: 共享理解不是来自简单同意，而是来自符号的双向交换和重新解释，这为人机交互设计提出了新范式。

Abstract: Meaningful human-AI collaboration requires more than processing language; it
demands a deeper understanding of symbols and their socially constructed
meanings. While humans naturally interpret symbols through social interaction,
AI systems often miss the dynamic interpretations that emerge in conversation.
Drawing on Symbolic Interactionism theory, we conducted two studies to
investigate how humans and AI co-construct symbols and their meanings. Findings
provide empirical insights into how humans and conversational AI agents
collaboratively shape meanings during interaction. We show how participants
shift their initial definitions of meaning in response to the symbols and
interpretations suggested by the conversational AI agents, especially when
social context is introduced. We also observe how participants project their
personal and social values into these interactions, refining meanings over
time. These findings reveal that shared understanding does not emerge from mere
agreement but from the bi-directional exchange and reinterpretation of symbols,
suggesting new paradigms for human-AI interaction design.

</details>


### [58] [Teacher-Student Guided Inverse Modeling for Steel Final Hardness Estimation](https://arxiv.org/abs/2510.05402)
*Ahmad Alsheikh,Andreas Fischer*

Main category: cs.AI

TL;DR: 提出一种教师-学生学习框架来解决钢热处理硬度预测的逆问题，通过前向模型预测硬度，反向模型从目标硬度推断输入参数，在计算效率和精度上都优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 钢热处理硬度预测存在多对一的模糊性问题，即不同输入参数组合可能产生相同硬度值，这使得从目标硬度反推输入参数的逆问题特别困难。

Method: 使用教师-学生学习框架：先训练前向模型（教师）从13个冶金特征预测最终硬度，再训练反向模型（学生）从目标硬度推断输入配置，通过教师的反馈进行迭代监督优化。

Result: 在公开的回火钢数据集上评估，该方法不仅实现了更高的逆预测精度，而且计算时间显著减少，优于基线回归和强化学习模型。

Conclusion: 教师-学生框架在材料科学逆过程建模中展现出高效性和有效性，为解决多对一映射问题提供了有前景的解决方案。

Abstract: Predicting the final hardness of steel after heat treatment is a challenging
regression task due to the many-to-one nature of the process -- different
combinations of input parameters (such as temperature, duration, and chemical
composition) can result in the same hardness value. This ambiguity makes the
inverse problem, estimating input parameters from a desired hardness,
particularly difficult. In this work, we propose a novel solution using a
Teacher-Student learning framework. First, a forward model (Teacher) is trained
to predict final hardness from 13 metallurgical input features. Then, a
backward model (Student) is trained to infer plausible input configurations
from a target hardness value. The Student is optimized by leveraging feedback
from the Teacher in an iterative, supervised loop. We evaluate our method on a
publicly available tempered steel dataset and compare it against baseline
regression and reinforcement learning models. Results show that our
Teacher-Student framework not only achieves higher inverse prediction accuracy
but also requires significantly less computational time, demonstrating its
effectiveness and efficiency for inverse process modeling in materials science.

</details>


### [59] [AInstein: Assessing the Feasibility of AI-Generated Approaches to Research Problems](https://arxiv.org/abs/2510.05432)
*Shambhavi Mishra,Gaurav Sahu,Marco Pedersoli,Laurent Charlin,Jose Dolz,Christopher Pal*

Main category: cs.AI

TL;DR: AInstein框架测试LLMs仅使用预训练参数知识解决AI研究问题的能力，无需外部辅助。结果表明LLMs能重新发现可行解决方案并偶尔提出创新方法，但问题解决能力脆弱且对问题表述敏感。


<details>
  <summary>Details</summary>
Motivation: 测试LLMs的成功是源于真正推理还是复杂记忆，评估LLMs作为自主科学问题解决者的潜力。

Method: 从ICLR 2025论文提取问题陈述，让专业求解代理通过迭代批判循环提出和完善技术解决方案，使用LLM作为评判者进行结构化评估。

Result: LLMs能够重新发现可行解决方案并偶尔提出创造性替代方案，但问题解决能力脆弱且高度依赖于问题表述方式。

Conclusion: 这是首个关于LLMs作为自主科学问题解决者能力的大规模证据，揭示了其潜在潜力和当前局限性。

Abstract: Large language models (LLMs) demonstrate impressive capabilities across a
wide range of tasks, yet it remains unclear whether such success reflects
genuine reasoning or sophisticated recall. We introduce AInstein, a framework
for testing whether LLMs can generate valid solutions to AI research problems
using only their pretrained parametric knowledge -- without domain-specific
fine-tuning, retrieval augmentation, or other external aids. Our approach
extracts distilled problem statements from high-quality ICLR 2025 submissions,
then tasks specialized solver agents with proposing and refining technical
solutions through iterative critique loops, mimicking the cycles of proposal,
review, and revision central to scientific inquiry. We evaluate AInstein on
1,214 ICLR papers stratified by acceptance tier (Oral, Spotlight, Poster),
using an LLM-as-a-judge paradigm guided by a structured rubric, complemented by
targeted manual checks. Performance is assessed with three metrics: Success
Rate (does the solution address the problem?), Rediscovery (does it align with
human-proposed methods?), and Novelty (does it yield valid, original
approaches?). Our results reveal that while LLMs can rediscover feasible
solutions and occasionally propose creative alternatives, their problem-solving
ability remains fragile and highly sensitive to framing. These findings provide
the first large-scale evidence on the extent to which LLMs can act as
autonomous scientific problem-solvers, highlighting both their latent potential
and their current limitations.

</details>


### [60] [NASP-T: A Fuzzy Neuro-Symbolic Transformer for Logic-Constrained Aviation Safety Report Classification](https://arxiv.org/abs/2510.05451)
*Fadi Al Machot,Fidaa Al Machot*

Main category: cs.AI

TL;DR: 提出了一种结合答案集编程(ASP)与transformer的混合神经符号框架，用于航空安全报告系统(ASRS)的多标签文本分类，通过规则增强和模糊逻辑正则化提高分类性能并减少逻辑违规


<details>
  <summary>Details</summary>
Motivation: 深度transformer模型在多标签文本分类中表现优异，但在安全关键应用中经常违反专家认为必要的领域逻辑规则

Method: 将领域知识形式化为加权ASP规则，通过两种方式整合：1) 基于规则的数据增强生成逻辑一致的合成样本；2) 模糊逻辑正则化在微调期间以可微分形式强制执行规则满足

Result: 相比强基线BCE，该方法提高了micro-和macro-F1分数，在ASRS测试集上实现了高达86%的规则违规减少

Conclusion: 这是首个将基于ASP的推理、规则驱动增强和可微分transformer训练统一应用于ASRS报告的大规模神经符号应用，为可信赖的安全关键NLP提供了解决方案

Abstract: Deep transformer models excel at multi-label text classification but often
violate domain logic that experts consider essential, an issue of particular
concern in safety-critical applications. We propose a hybrid neuro-symbolic
framework that integrates Answer Set Programming (ASP) with transformer-based
learning on the Aviation Safety Reporting System (ASRS) corpus. Domain
knowledge is formalized as weighted ASP rules and validated using the Clingo
solver. These rules are incorporated in two complementary ways: (i) as
rule-based data augmentation, generating logically consistent synthetic samples
that improve label diversity and coverage; and (ii) as a fuzzy-logic
regularizer, enforcing rule satisfaction in a differentiable form during
fine-tuning. This design preserves the interpretability of symbolic reasoning
while leveraging the scalability of deep neural architectures. We further tune
per-class thresholds and report both standard classification metrics and
logic-consistency rates. Compared to a strong Binary Cross-Entropy (BCE)
baseline, our approach improves micro- and macro-F1 scores and achieves up to
an 86% reduction in rule violations on the ASRS test set. To the best of our
knowledge, this constitutes the first large-scale neuro-symbolic application to
ASRS reports that unifies ASP-based reasoning, rule-driven augmentation, and
differentiable transformer training for trustworthy, safety-critical NLP.

</details>


### [61] [Do Code Models Suffer from the Dunning-Kruger Effect?](https://arxiv.org/abs/2510.05457)
*Mukul Singh,Somya Chatterjee,Arjun Radhakrishna,Sumit Gulwani*

Main category: cs.AI

TL;DR: 研究发现AI模型在编程任务中表现出类似人类的邓宁-克鲁格效应，即能力较低的模型在陌生或低资源编程语言中更容易过度自信。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在创意和技术领域与人类协作日益增多，需要了解影响共享代理的认知边界和偏见，特别是AI是否也会像人类一样表现出过度自信的认知偏差。

Method: 通过分析模型在不同编程语言中的置信度和性能表现，研究模型在多样化编程任务中的自信程度与实际能力的关系。

Result: 实验表明，能力较低的模型和在罕见编程语言中操作的模型表现出更强的邓宁-克鲁格效应，这种偏见强度与模型能力成比例。

Conclusion: AI模型确实会镜像人类的过度自信模式，特别是在不熟悉或低资源领域，这种认知偏差的存在对AI与人类协作具有重要意义。

Abstract: As artificial intelligence systems increasingly collaborate with humans in
creative and technical domains, questions arise about the cognitive boundaries
and biases that shape our shared agency. This paper investigates the
Dunning-Kruger Effect (DKE), the tendency for those with limited competence to
overestimate their abilities in state-of-the-art LLMs in coding tasks. By
analyzing model confidence and performance across a diverse set of programming
languages, we reveal that AI models mirror human patterns of overconfidence,
especially in unfamiliar or low-resource domains. Our experiments demonstrate
that less competent models and those operating in rare programming languages
exhibit stronger DKE-like bias, suggesting that the strength of the bias is
proportionate to the competence of the models.

</details>


### [62] [VAL-Bench: Measuring Value Alignment in Language Models](https://arxiv.org/abs/2510.05465)
*Aman Gupta,Denny O'Shea,Fazl Barez*

Main category: cs.AI

TL;DR: VAL-Bench是一个评估大语言模型价值对齐的基准，通过测试模型在争议性话题中对立框架下是否保持稳定价值立场来衡量其价值一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注拒绝或安全违规检测，但无法揭示模型在面对现实争议问题时是否坚持一致的价值体系，需要新的评估方法来测试模型的价值对齐程度。

Method: 使用维基百科争议章节构建115K个对立框架提示对，通过LLM作为评判者来评估模型在配对响应中的一致性或分歧程度。

Result: 在领先的开源和闭源模型上应用该基准，发现模型间价值对齐存在显著差异，并揭示了安全策略（如拒绝回答）与更丰富价值系统之间的权衡关系。

Conclusion: VAL-Bench提供了一个可扩展、可复现的基准，能够系统性地比较LLMs在体现人类价值观方面的可靠性。

Abstract: Large language models (LLMs) are increasingly used for tasks where outputs
shape human decisions, so it is critical to test whether their responses
reflect consistent human values. Existing benchmarks mostly track refusals or
predefined safety violations, but these only check rule compliance and do not
reveal whether a model upholds a coherent value system when facing
controversial real-world issues. We introduce the \textbf{V}alue
\textbf{AL}ignment \textbf{Bench}mark (\textbf{VAL-Bench}), which evaluates
whether models maintain a stable value stance across paired prompts that frame
opposing sides of public debates. VAL-Bench consists of 115K such pairs from
Wikipedia's controversial sections. A well-aligned model should express similar
underlying views regardless of framing, which we measure using an LLM-as-judge
to score agreement or divergence between paired responses. Applied across
leading open- and closed-source models, the benchmark reveals large variation
in alignment and highlights trade-offs between safety strategies (e.g.,
refusals) and more expressive value systems. By providing a scalable,
reproducible benchmark, VAL-Bench enables systematic comparison of how reliably
LLMs embody human values.

</details>


### [63] [Vul-R2: A Reasoning LLM for Automated Vulnerability Repair](https://arxiv.org/abs/2510.05480)
*Xin-Cheng Wen,Zirui Lin,Yijun Yang,Cuiyun Gao,Deheng Ye*

Main category: cs.AI

TL;DR: 论文提出了一种新的自动漏洞修复方法，通过生成漏洞相关推理数据并利用强化学习训练LLMs，解决了现有方法缺乏高质量漏洞推理数据和难以验证中间修复过程的挑战。


<details>
  <summary>Details</summary>
Motivation: 软件漏洞的指数级增长迫切需要自动漏洞修复解决方案。现有基于LLM的方法面临两个主要挑战：缺乏高质量的漏洞相关推理数据，以及难以在LLM训练过程中验证中间漏洞修复过程。

Method: 论文提出了一种新方法，通过生成漏洞相关推理数据，并利用强化学习来训练大型语言模型进行漏洞修复。该方法解决了现有方法依赖通用编程知识而无法捕捉多样化漏洞修复模式的问题。

Result: 该方法能够生成高质量的漏洞相关推理数据，并通过强化学习有效训练LLMs，克服了现有方法在捕获漏洞修复模式和验证中间修复过程方面的局限性。

Conclusion: 提出的方法为解决自动漏洞修复中的关键挑战提供了有效途径，通过生成专门的数据和利用强化学习，显著提升了LLMs在漏洞修复任务中的性能。

Abstract: The exponential increase in software vulnerabilities has created an urgent
need for automatic vulnerability repair (AVR) solutions. Recent research has
formulated AVR as a sequence generation problem and has leveraged large
language models (LLMs) to address this problem. Typically, these approaches
prompt or fine-tune LLMs to generate repairs for vulnerabilities directly.
Although these methods show state-of-the-art performance, they face the
following challenges: (1) Lack of high-quality, vulnerability-related reasoning
data. Current approaches primarily rely on foundation models that mainly encode
general programming knowledge. Without vulnerability-related reasoning data,
they tend to fail to capture the diverse vulnerability repair patterns. (2)
Hard to verify the intermediate vulnerability repair process during LLM
training. Existing reinforcement learning methods often leverage intermediate
execution feedback from the environment (e.g., sandbox-based execution results)
to guide reinforcement learning training. In contrast, the vulnerability repair
process generally lacks such intermediate, verifiable feedback, which poses
additional challenges for model training.

</details>


### [64] [MetaVLA: Unified Meta Co-training For Efficient Embodied Adaption](https://arxiv.org/abs/2510.05580)
*Chen Li,Zhantao Yang,Han Zhang,Fangyi Chen,Chenchen Zhu,Anudeepsekhar Bolimera,Marios Savvides*

Main category: cs.AI

TL;DR: MetaVLA是一个统一的、骨干网络无关的后训练框架，通过上下文感知元协同训练，将多样目标任务整合到单个微调阶段，利用结构多样的辅助任务提升领域内泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言-动作模型在具身推理中表现有限，通常需要任务特定的微调，且对未见任务的泛化能力较差。

Method: 提出Context-Aware Meta Co-Training方法，整合多样目标任务，引入轻量级元学习机制（基于Attentive Neural Processes），实现快速适应且不增加推理开销。

Result: 在LIBERO基准测试中，MetaVLA使用6个辅助任务，在长时域任务上比OpenVLA提升8.0%，训练步数从240K减少到75K，GPU时间减少约76%。

Conclusion: 证明了可扩展、低资源后训练的可行性，为通用具身智能体铺平了道路。

Abstract: Vision-Language-Action (VLA) models show promise in embodied reasoning, yet
remain far from true generalists-they often require task-specific fine-tuning,
and generalize poorly to unseen tasks. We propose MetaVLA, a unified,
backbone-agnostic post-training framework for efficient and scalable alignment.
MetaVLA introduces Context-Aware Meta Co-Training, which consolidates diverse
target tasks into a single fine-tuning stage while leveraging structurally
diverse auxiliary tasks to improve in-domain generalization. Unlike naive
multi-task SFT, MetaVLA integrates a lightweight meta-learning
mechanism-derived from Attentive Neural Processes-to enable rapid adaptation
from diverse contexts with minimal architectural change or inference overhead.
On the LIBERO benchmark, MetaVLA with six auxiliary tasks outperforms OpenVLA
by up to 8.0% on long-horizon tasks, reduces training steps from 240K to 75K,
and cuts GPU time by ~76%. These results show that scalable, low-resource
post-training is achievable-paving the way toward general-purpose embodied
agents. Code will be available.

</details>


### [65] [In-the-Flow Agentic System Optimization for Effective Planning and Tool Use](https://arxiv.org/abs/2510.05592)
*Zhuofeng Li,Haoxiang Zhang,Seungju Han,Sheng Liu,Jianwen Xie,Yu Zhang,Yejin Choi,James Zou,Pan Lu*

Main category: cs.AI

TL;DR: AgentFlow是一个可训练的在线智能体框架，通过四个模块（规划器、执行器、验证器、生成器）协调工作，使用Flow-GRPO算法在多轮交互中优化规划器，在长视野、稀疏奖励任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强方法训练单一策略，在长视野和多样化工具场景下扩展性差，泛化能力弱；智能体系统虽然通过模块分解工作，但大多缺乏训练或离线训练，无法适应多轮交互的动态特性。

Method: 提出AgentFlow框架，包含四个协调模块和演化记忆系统，使用Flow-GRPO算法在多轮环境中进行在线策略训练，将多轮优化转化为可处理的单轮策略更新。

Result: 在十个基准测试中，使用7B规模骨干的AgentFlow在搜索任务上平均准确率提升14.9%，智能体任务14.0%，数学任务14.5%，科学任务4.1%，甚至超越GPT-4o等更大专有模型。

Conclusion: AgentFlow证明了在线优化的优势，显示出改进的规划能力、增强的工具调用可靠性，以及随模型规模和推理轮数增加的正向扩展性。

Abstract: Outcome-driven reinforcement learning has advanced reasoning in large
language models (LLMs), but prevailing tool-augmented approaches train a
single, monolithic policy that interleaves thoughts and tool calls under full
context; this scales poorly with long horizons and diverse tools and
generalizes weakly to new scenarios. Agentic systems offer a promising
alternative by decomposing work across specialized modules, yet most remain
training-free or rely on offline training decoupled from the live dynamics of
multi-turn interaction. We introduce AgentFlow, a trainable, in-the-flow
agentic framework that coordinates four modules (planner, executor, verifier,
generator) through an evolving memory and directly optimizes its planner inside
the multi-turn loop. To train on-policy in live environments, we propose
Flow-based Group Refined Policy Optimization (Flow-GRPO), which tackles
long-horizon, sparse-reward credit assignment by converting multi-turn
optimization into a sequence of tractable single-turn policy updates. It
broadcasts a single, verifiable trajectory-level outcome to every turn to align
local planner decisions with global success and stabilizes learning with
group-normalized advantages. Across ten benchmarks, AgentFlow with a 7B-scale
backbone outperforms top-performing baselines with average accuracy gains of
14.9% on search, 14.0% on agentic, 14.5% on mathematical, and 4.1% on
scientific tasks, even surpassing larger proprietary models like GPT-4o.
Further analyses confirm the benefits of in-the-flow optimization, showing
improved planning, enhanced tool-calling reliability, and positive scaling with
model size and reasoning turns.

</details>


### [66] [From Agentification to Self-Evolving Agentic AI for Wireless Networks: Concepts, Approaches, and Future Research Directions](https://arxiv.org/abs/2510.05596)
*Changyuan Zhao,Ruichen Zhang,Jiacheng Wang,Dusit Niyato,Geng Sun,Xianbin Wang,Shiwen Mao,Abbas Jamalipour*

Main category: cs.AI

TL;DR: 本文提出了一个自演进智能AI框架，通过多智能体协作实现无线系统的自主演进和优化，在低空无线网络中成功将固定天线优化升级为可移动天线优化，性能提升达52.02%。


<details>
  <summary>Details</summary>
Motivation: 传统静态AI模型无法适应动态环境变化，需要人工干预。自演进智能AI旨在实现无线系统的自主适应和改进，无需人工干预。

Method: 提出多智能体协作的自演进智能AI框架，包含角色专业化的大型语言模型和监督智能体，通过结构化对话、迭代反馈和系统验证实现完整生命周期的自主执行。

Result: 在低空无线网络的天线演进案例中，框架成功自主升级优化方案，波束增益提升，性能恢复达52.02%，持续超越固定基线。

Conclusion: 自演进智能AI框架展示了在下一代无线智能中的适应性和鲁棒性，能够自主改进系统性能，减少人工干预需求。

Abstract: Self-evolving agentic artificial intelligence (AI) offers a new paradigm for
future wireless systems by enabling autonomous agents to continually adapt and
improve without human intervention. Unlike static AI models, self-evolving
agents embed an autonomous evolution cycle that updates models, tools, and
workflows in response to environmental dynamics. This paper presents a
comprehensive overview of self-evolving agentic AI, highlighting its layered
architecture, life cycle, and key techniques, including tool intelligence,
workflow optimization, self-reflection, and evolutionary learning. We further
propose a multi-agent cooperative self-evolving agentic AI framework, where
multiple large language models (LLMs) are assigned role-specialized prompts
under the coordination of a supervisor agent. Through structured dialogue,
iterative feedback, and systematic validation, the system autonomously executes
the entire life cycle without human intervention. A case study on antenna
evolution in low-altitude wireless networks (LAWNs) demonstrates how the
framework autonomously upgrades fixed antenna optimization into movable antenna
optimization. Experimental results show that the proposed self-evolving agentic
AI autonomously improves beam gain and restores degraded performance by up to
52.02%, consistently surpassing the fixed baseline with little to no human
intervention and validating its adaptability and robustness for next-generation
wireless intelligence.

</details>


### [67] [Large Language Model-Based Uncertainty-Adjusted Label Extraction for Artificial Intelligence Model Development in Upper Extremity Radiography](https://arxiv.org/abs/2510.05664)
*Hanna Kreutzer,Anne-Sophie Caselitz,Thomas Dratsch,Daniel Pinto dos Santos,Christiane Kuhl,Daniel Truhn,Sven Nebelung*

Main category: cs.AI

TL;DR: GPT-4o能够从放射学报告中高精度提取诊断标签（准确率98.6%），这些标签可用于训练具有竞争力的多标签图像分类模型，标签不确定性不影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 评估GPT-4o从自由文本放射学报告中提取诊断标签的能力，并测试这些标签如何影响肌肉骨骼X光片的多标签图像分类。

Method: 回顾性研究，使用GPT-4o从匿名放射学报告中提取结构化标签（真/假/不确定），然后训练ResNet50进行多标签分类，比较包含性和排除性标签策略。

Result: GPT-4o标签提取准确率达98.6%，基于标签训练的模型在内部和外部数据集上都表现出色（AUC约0.80），不同标签策略间无显著差异。

Conclusion: GPT-4o能够从放射学报告中提取标签来训练有竞争力的多标签分类模型，检测到的不确定性不影响模型性能。

Abstract: Objectives: To evaluate GPT-4o's ability to extract diagnostic labels (with
uncertainty) from free-text radiology reports and to test how these labels
affect multi-label image classification of musculoskeletal radiographs.
Methods: This retrospective study included radiography series of the clavicle
(n=1,170), elbow (n=3,755), and thumb (n=1,978). After anonymization, GPT-4o
filled out structured templates by indicating imaging findings as present
("true"), absent ("false"), or "uncertain." To assess the impact of label
uncertainty, "uncertain" labels of the training and validation sets were
automatically reassigned to "true" (inclusive) or "false" (exclusive).
Label-image-pairs were used for multi-label classification using ResNet50.
Label extraction accuracy was manually verified on internal (clavicle: n=233,
elbow: n=745, thumb: n=393) and external test sets (n=300 for each).
Performance was assessed using macro-averaged receiver operating characteristic
(ROC) area under the curve (AUC), precision recall curves, sensitivity,
specificity, and accuracy. AUCs were compared with the DeLong test. Results:
Automatic extraction was correct in 98.6% (60,618 of 61,488) of labels in the
test sets. Across anatomic regions, label-based model training yielded
competitive performance measured by macro-averaged AUC values for inclusive
(e.g., elbow: AUC=0.80 [range, 0.62-0.87]) and exclusive models (elbow:
AUC=0.80 [range, 0.61-0.88]). Models generalized well on external datasets
(elbow [inclusive]: AUC=0.79 [range, 0.61-0.87]; elbow [exclusive]: AUC=0.79
[range, 0.63-0.89]). No significant differences were observed across labeling
strategies or datasets (p>=0.15). Conclusion: GPT-4o extracted labels from
radiologic reports to train competitive multi-label classification models with
high accuracy. Detected uncertainty in the radiologic reports did not influence
the performance of these models.

</details>


### [68] [D2E: Scaling Vision-Action Pretraining on Desktop Data for Transfer to Embodied AI](https://arxiv.org/abs/2510.05684)
*Suwhan Choi,Jaeyoon Jung,Haebin Seong,Minchan Kim,Minyeong Kim,Yongjun Cho,Yoonshik Kim,Yubeen Park,Youngjae Yu,Yunsung Lee*

Main category: cs.AI

TL;DR: D2E框架利用桌面游戏环境作为机器人具身AI的预训练平台，通过标准化桌面交互数据、通用事件预测模型和迁移学习方法，成功将数字交互中的感知运动基元迁移到物理机器人任务中。


<details>
  <summary>Details</summary>
Motivation: 解决具身AI因物理轨迹收集成本高昂而受限的问题，利用桌面游戏环境提供的大规模丰富感知运动交互作为替代方案。

Method: 开发了三个组件：OWA工具包统一桌面交互格式并实现152倍压缩；Generalist-IDM通过时间戳事件预测实现零样本泛化；VAPT将桌面预训练表示迁移到物理操作和导航任务。

Result: 使用1300+小时数据（259小时人类演示和1000+小时伪标签游戏数据），在LIBERO操作任务上达到96.6%成功率，在CANVAS导航基准上达到83.3%成功率。

Conclusion: 数字交互中的感知运动基元具有足够的恒定性，能够有效迁移到物理具身任务，确立了桌面预训练作为机器人学的实用范式。

Abstract: Large language models leverage internet-scale text data, yet embodied AI
remains constrained by the prohibitive costs of physical trajectory collection.
Desktop environments -- particularly gaming -- offer a compelling alternative:
they provide rich sensorimotor interactions at scale while maintaining the
structured observation-action coupling essential for embodied learning. We
present D2E (Desktop to Embodied AI), a framework that demonstrates desktop
interactions can serve as an effective pretraining substrate for robotics
embodied AI tasks. Unlike prior work that remained domain-specific (e.g., VPT
for Minecraft) or kept data proprietary (e.g., SIMA), D2E establishes a
complete pipeline from scalable desktop data collection to verified transfer in
embodied domains. Our framework comprises three components: (1) the OWA Toolkit
that unifies diverse desktop interactions into a standardized format with 152x
compression, (2) the Generalist-IDM that achieves strong zero-shot
generalization across unseen games through timestamp-based event prediction,
enabling internet-scale pseudo-labeling, and (3) VAPT that transfers
desktop-pretrained representations to physical manipulation and navigation.
Using 1.3K+ hours of data (259 hours of human demonstrations, and 1K+ hours of
pseudo-labeled gameplay), we achieve a total of 96.6% success rate on LIBERO
manipulation and 83.3% on CANVAS navigation benchmarks. This validates that
sensorimotor primitives in digital interactions exhibit sufficient invariance
to transfer meaningfully to physical embodied tasks, establishing desktop
pretraining as a practical paradigm for robotics. We will make all our work
public, including the OWA toolkit, datasets of human-collected and
pseudo-labeled, and VAPT-trained models available at
https://worv-ai.github.io/d2e/

</details>


### [69] [Joint Communication Scheduling and Velocity Control for Multi-UAV-Assisted Post-Disaster Monitoring: An Attention-Based In-Context Learning Approach](https://arxiv.org/abs/2510.05698)
*Yousef Emami,Seyedsina Nabavirazavi,Jingjing Zheng,Hao Zhou,Miguel Gutierrez Gaitan,Kai Li,Luis Almeida*

Main category: cs.AI

TL;DR: 提出AIC-VDS方法，使用基于注意力的上下文学习来优化多无人机在灾后监测中的数据收集调度和速度控制，以最小化数据丢失。


<details>
  <summary>Details</summary>
Motivation: 在灾后监测场景中，无人机数据收集面临调度和速度控制的挑战，不当设置会导致传输错误和缓冲区溢出。传统在线深度强化学习方法训练复杂且存在仿真与现实不匹配的问题，无法满足海啸监测的紧急需求。

Method: 提出基于注意力机制的上下文学习方法AIC-VDS，考虑地面传感器电池水平、队列长度、信道条件以及无人机轨迹，联合优化数据收集调度和速度控制。

Result: 仿真结果表明，AIC-VDS方法在性能上优于Deep-Q-Network和最大信道增益基线方法。

Conclusion: AIC-VDS作为深度强化学习的替代方案，在紧急情况下能够有效优化无人机数据收集，减少数据丢失。

Abstract: Recently, Unmanned Aerial Vehicles (UAVs) are increasingly being investigated
to collect sensory data in post-disaster monitoring scenarios, such as
tsunamis, where early actions are critical to limit coastal damage. A major
challenge is to design the data collection schedules and flight velocities, as
unfavorable schedules and velocities can lead to transmission errors and buffer
overflows of the ground sensors, ultimately resulting in significant packet
loss. Meanwhile, online Deep Reinforcement Learning (DRL) solutions have a
complex training process and a mismatch between simulation and reality that
does not meet the urgent requirements of tsunami monitoring. Recent advances in
Large Language Models (LLMs) offer a compelling alternative. With their strong
reasoning and generalization capabilities, LLMs can adapt to new tasks through
In-Context Learning (ICL), which enables task adaptation through natural
language prompts and example-based guidance without retraining. However, LLM
models have input data limitations and thus require customized approaches. In
this paper, a joint optimization of data collection schedules and velocities
control for multiple UAVs is proposed to minimize data loss. The battery level
of the ground sensors, the length of the queues, and the channel conditions, as
well as the trajectories of the UAVs, are taken into account. Attention-Based
In-Context Learning for Velocity Control and Data Collection Schedule (AIC-VDS)
is proposed as an alternative to DRL in emergencies. The simulation results
show that the proposed AIC-VDS outperforms both the Deep-Q-Network (DQN) and
maximum channel gain baselines.

</details>


### [70] [Syn-Diag: An LLM-based Synergistic Framework for Generalizable Few-shot Fault Diagnosis on the Edge](https://arxiv.org/abs/2510.05733)
*Zijun Jia,Shuang Liang,Jinsong Yu*

Main category: cs.AI

TL;DR: Syn-Diag是一个云边协同的工业故障诊断框架，利用大语言模型解决数据稀缺和资源受限环境下的少样本故障诊断问题。


<details>
  <summary>Details</summary>
Motivation: 工业故障诊断面临数据稀缺和大型AI模型在资源受限环境中部署困难的双重挑战。

Method: 采用三层机制：1）视觉-语义协同，通过跨模态预训练将信号特征与大语言模型的语义空间对齐；2）内容感知推理，动态构建上下文提示以提升少样本诊断准确性；3）云边协同，通过知识蒸馏创建轻量级边缘模型，支持在线更新。

Result: 在六个数据集上的实验表明，Syn-Diag显著优于现有方法，特别是在1样本和跨工况场景下。边缘模型性能接近云端版本，同时模型大小减少83%，延迟降低50%。

Conclusion: Syn-Diag为现代智能诊断提供了一个实用、鲁棒且可部署的范式。

Abstract: Industrial fault diagnosis faces the dual challenges of data scarcity and the
difficulty of deploying large AI models in resource-constrained environments.
This paper introduces Syn-Diag, a novel cloud-edge synergistic framework that
leverages Large Language Models to overcome these limitations in few-shot fault
diagnosis. Syn-Diag is built on a three-tiered mechanism: 1) Visual-Semantic
Synergy, which aligns signal features with the LLM's semantic space through
cross-modal pre-training; 2) Content-Aware Reasoning, which dynamically
constructs contextual prompts to enhance diagnostic accuracy with limited
samples; and 3) Cloud-Edge Synergy, which uses knowledge distillation to create
a lightweight, efficient edge model capable of online updates via a shared
decision space. Extensive experiments on six datasets covering different CWRU
and SEU working conditions show that Syn-Diag significantly outperforms
existing methods, especially in 1-shot and cross-condition scenarios. The edge
model achieves performance comparable to the cloud version while reducing model
size by 83% and latency by 50%, offering a practical, robust, and deployable
paradigm for modern intelligent diagnostics.

</details>


### [71] [The Safety Challenge of World Models for Embodied AI Agents: A Review](https://arxiv.org/abs/2510.05865)
*Lorenzo Baraldi,Zifan Zeng,Chongzhe Zhang,Aradhana Nayak,Hongbo Zhu,Feng Liu,Qunli Zhang,Peng Wang,Shiming Liu,Zheng Hu,Angelo Cangelosi,Lorenzo Baraldi*

Main category: cs.AI

TL;DR: 本文对自动驾驶和机器人领域的世界模型进行了文献综述，重点关注场景和控制生成任务的安全性影响，并通过实证分析识别和分类了当前最先进模型的常见故障。


<details>
  <summary>Details</summary>
Motivation: 随着具身人工智能的快速发展，需要更先进和集成的模型来感知、解释和预测环境动态。世界模型为具身智能体提供了预测未来环境状态和填补知识空白的能力，但必须确保预测对智能体和环境都是安全的。

Method: 采用文献综述和实证分析相结合的方法：收集并检查最先进模型的预测结果，识别和分类常见故障（称为病理），并对结果进行定量评估。

Result: 研究识别并分类了世界模型在场景和控制生成任务中的常见故障类型，提供了这些故障的定量评估结果。

Conclusion: 世界模型在提升具身智能体规划能力的同时，其预测安全性问题需要特别关注，研究为理解和改进世界模型的安全性提供了系统性的分析框架。

Abstract: The rapid progress in embodied artificial intelligence has highlighted the
necessity for more advanced and integrated models that can perceive, interpret,
and predict environmental dynamics. In this context, World Models (WMs) have
been introduced to provide embodied agents with the abilities to anticipate
future environmental states and fill in knowledge gaps, thereby enhancing
agents' ability to plan and execute actions. However, when dealing with
embodied agents it is fundamental to ensure that predictions are safe for both
the agent and the environment. In this article, we conduct a comprehensive
literature review of World Models in the domains of autonomous driving and
robotics, with a specific focus on the safety implications of scene and control
generation tasks. Our review is complemented by an empirical analysis, wherein
we collect and examine predictions from state-of-the-art models, identify and
categorize common faults (herein referred to as pathologies), and provide a
quantitative evaluation of the results.

</details>


### [72] [ARM: Discovering Agentic Reasoning Modules for Generalizable Multi-Agent Systems](https://arxiv.org/abs/2510.05746)
*Bohan Yao,Shiva Krishna Reddy Malay,Vikas Yadav*

Main category: cs.AI

TL;DR: 提出了ARM（Agentic Reasoning Module）新范式，通过树搜索优化CoT推理，显著优于手动设计和现有自动MAS设计方法，并具有优秀的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有自动多智能体系统设计方法效果差、计算成本高且需要重复发现架构，而简单的CoT推理表现竞争力强，值得深入研究。

Method: 引入ARM作为CoT的智能体化泛化，通过代码空间的树搜索从简单CoT模块演化，利用执行轨迹反思指导突变。

Result: ARM方法显著优于手动设计的MAS和最先进的自动MAS设计方法，在不同基础模型和任务领域都保持高性能且无需进一步优化。

Conclusion: ARM作为通用推理构建块，可作为递归循环或元编排器子程序使用，在多智能体系统设计中具有优越性能和泛化能力。

Abstract: Large Language Model (LLM)-powered Multi-agent systems (MAS) have achieved
state-of-the-art results on various complex reasoning tasks. Recent works have
proposed techniques to automate the design of MASes, eliminating the need for
manual engineering. However, these techniques perform poorly, often achieving
similar or inferior performance to simple baselines. Furthermore, they require
computationally expensive re-discovery of architectures for each new task
domain and expensive data annotation on domains without existing labeled
validation sets. A critical insight is that simple Chain of Thought (CoT)
reasoning often performs competitively with these complex systems, suggesting
that the fundamental reasoning unit of MASes, CoT, warrants further
investigation. To this end, we present a new paradigm for automatic MAS design
that pivots the focus to optimizing CoT reasoning. We introduce the Agentic
Reasoning Module (ARM), an agentic generalization of CoT where each granular
reasoning step is executed by a specialized reasoning module. This module is
discovered through a tree search over the code space, starting from a simple
CoT module and evolved using mutations informed by reflection on execution
traces. The resulting ARM acts as a versatile reasoning building block which
can be utilized as a direct recursive loop or as a subroutine in a learned
meta-orchestrator. Our approach significantly outperforms both manually
designed MASes and state-of-the-art automatic MAS design methods. Crucially,
MASes built with ARM exhibit superb generalization, maintaining high
performance across different foundation models and task domains without further
optimization.

</details>


### [73] [Information-Theoretic Policy Pre-Training with Empowerment](https://arxiv.org/abs/2510.05996)
*Moritz Schneider,Robert Krug,Narunas Vaskevicius,Luigi Palmieri,Michael Volpp,Joschka Boedecker*

Main category: cs.AI

TL;DR: 本文提出使用折扣赋权作为预训练信号，通过最大化长期折扣赋权来初始化策略，提高下游任务的适应性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 赋权作为内在动机在强化学习中已有应用，但作为预训练信号的研究有限。作者希望探索赋权预训练在数据高效下游任务适应中的潜力。

Method: 引入折扣赋权概念，平衡智能体在短期和长期时间尺度上对环境的影响，提出基于折扣赋权最大化的预训练范式。

Result: 实验证明，具有长期视野的赋权最大化策略具有数据高效性和有效性，能显著提升下游任务的适应能力。

Conclusion: 赋权预训练是一种通用的初始化策略，为未来在高维复杂任务中扩展该框架铺平了道路。

Abstract: Empowerment, an information-theoretic measure of an agent's potential
influence on its environment, has emerged as a powerful intrinsic motivation
and exploration framework for reinforcement learning (RL). Besides for
unsupervised RL and skill learning algorithms, the specific use of empowerment
as a pre-training signal has received limited attention in the literature. We
show that empowerment can be used as a pre-training signal for data-efficient
downstream task adaptation. For this we extend the traditional notion of
empowerment by introducing discounted empowerment, which balances the agent's
control over the environment across short- and long-term horizons. Leveraging
this formulation, we propose a novel pre-training paradigm that initializes
policies to maximize discounted empowerment, enabling agents to acquire a
robust understanding of environmental dynamics. We analyze empowerment-based
pre-training for various existing RL algorithms and empirically demonstrate its
potential as a general-purpose initialization strategy: empowerment-maximizing
policies with long horizons are data-efficient and effective, leading to
improved adaptability in downstream tasks. Our findings pave the way for future
research to scale this framework to high-dimensional and complex tasks, further
advancing the field of RL.

</details>


### [74] [Uncertainty assessment in satellite-based greenhouse gas emissions estimates using emulated atmospheric transport](https://arxiv.org/abs/2510.05751)
*Jeffrey N. Clark,Elena Fillola,Nawid Keshtmand,Raul Santos-Rodriguez,Matthew Rigby*

Main category: cs.AI

TL;DR: 使用图神经网络模拟拉格朗日粒子扩散模型，实现了1000倍加速，通过集成方法量化大气传输足迹和温室气体浓度测量的不确定性，支持卫星排放监测的稳健性。


<details>
  <summary>Details</summary>
Motivation: 传统传输模型计算成本高且不确定性难以表征，人工智能提供了加速模拟和量化不确定性的双重机会，以改进温室气体排放监测。

Method: 基于图神经网络的集成管道，模拟拉格朗日粒子扩散模型，计算大气传输足迹和温室气体浓度测量及其不确定性。

Result: 模拟器比NAME LPDM快约1000倍，重现了大尺度足迹结构，集成分析揭示了预测误差的空间相关性，集成分布突出了低置信度的时空预测。

Conclusion: 该方法可推广到大气传输模型，支持不确定性感知的温室气体反演系统，提高卫星排放监测的稳健性，并为探索系统误差提供计算高效途径。

Abstract: Monitoring greenhouse gas emissions and evaluating national inventories
require efficient, scalable, and reliable inference methods. Top-down
approaches, combined with recent advances in satellite observations, provide
new opportunities to evaluate emissions at continental and global scales.
However, transport models used in these methods remain a key source of
uncertainty: they are computationally expensive to run at scale, and their
uncertainty is difficult to characterise. Artificial intelligence offers a dual
opportunity to accelerate transport simulations and to quantify their
associated uncertainty.
  We present an ensemble-based pipeline for estimating atmospheric transport
"footprints", greenhouse gas mole fraction measurements, and their
uncertainties using a graph neural network emulator of a Lagrangian Particle
Dispersion Model (LPDM). The approach is demonstrated with GOSAT (Greenhouse
Gases Observing Satellite) observations for Brazil in 2016. The emulator
achieved a ~1000x speed-up over the NAME LPDM, while reproducing large-scale
footprint structures. Ensembles were calculated to quantify absolute and
relative uncertainty, revealing spatial correlations with prediction error. The
results show that ensemble spread highlights low-confidence spatial and
temporal predictions for both atmospheric transport footprints and methane mole
fractions.
  While demonstrated here for an LPDM emulator, the approach could be applied
more generally to atmospheric transport models, supporting uncertainty-aware
greenhouse gas inversion systems and improving the robustness of
satellite-based emissions monitoring. With further development, ensemble-based
emulators could also help explore systematic LPDM errors, offering a
computationally efficient pathway towards a more comprehensive uncertainty
budget in greenhouse gas flux estimates.

</details>


### [75] [Early Multimodal Prediction of Cross-Lingual Meme Virality on Reddit: A Time-Window Analysis](https://arxiv.org/abs/2510.05761)
*Sedat Dogan,Nina Dethlefs,Debarati Chakraborty*

Main category: cs.AI

TL;DR: 该研究提出了一种基于混合参与度得分的早期网络迷因传播性预测方法，使用多语言Reddit数据集，在30分钟内就能达到PR-AUC > 0.52的预测性能。


<details>
  <summary>Details</summary>
Motivation: 预测在线内容的传播性仍然具有挑战性，特别是对于文化复杂、快速演变的迷因。本研究旨在探索早期预测迷因传播性的可行性。

Method: 使用来自25个多样化Reddit社区的大规模跨语言数据集，提出基于混合参与度得分的传播性定义方法，评估了包括逻辑回归、XGBoost和MLP在内的多种模型，使用全面的多模态特征集在不同时间窗口（30-420分钟）进行预测。

Result: XGBoost模型表现最佳，在仅30分钟内就能达到PR-AUC > 0.52的性能。分析揭示了明显的"证据转换"现象：随着迷因获得关注，特征重要性从静态上下文动态转向时间动态。

Conclusion: 这项工作为早期传播性预测建立了一个稳健、可解释且实用的基准，特别是在完整传播级联数据不可用的情况下，贡献了一个新颖的跨语言数据集和方法论上合理的传播性定义。

Abstract: Predicting the virality of online content remains challenging, especially for
culturally complex, fast-evolving memes. This study investigates the
feasibility of early prediction of meme virality using a large-scale,
cross-lingual dataset from 25 diverse Reddit communities. We propose a robust,
data-driven method to define virality based on a hybrid engagement score,
learning a percentile-based threshold from a chronologically held-out training
set to prevent data leakage. We evaluated a suite of models, including Logistic
Regression, XGBoost, and a Multi-layer Perceptron (MLP), with a comprehensive,
multimodal feature set across increasing time windows (30-420 min). Crucially,
useful signals emerge quickly: our best-performing model, XGBoost, achieves a
PR-AUC $>$ 0.52 in just 30 minutes. Our analysis reveals a clear "evidentiary
transition," in which the importance of the feature dynamically shifts from the
static context to the temporal dynamics as a meme gains traction. This work
establishes a robust, interpretable, and practical benchmark for early virality
prediction in scenarios where full diffusion cascade data is unavailable,
contributing a novel cross-lingual dataset and a methodologically sound
definition of virality. To our knowledge, this study is the first to combine
time series data with static content and network features to predict early meme
virality.

</details>


### [76] [RareAgent: Self-Evolving Reasoning for Drug Repurposing in Rare Diseases](https://arxiv.org/abs/2510.05764)
*Lang Qin,Zijian Gan,Xu Cao,Pengcheng Jiang,Yankai Jiang,Jiawei Han,Kaishun Wu,Jintai Chen*

Main category: cs.AI

TL;DR: RareAgent是一个自进化的多智能体系统，通过对抗性辩论动态构建证据图来支持、反驳或蕴含假设，解决了罕见病药物重定位中缺乏先验关联信号的问题。


<details>
  <summary>Details</summary>
Motivation: 罕见病药物重定位在药物与目标疾病之间没有先验关联时特别困难，知识图谱补全和消息传递GNN缺乏可靠信号来学习和传播，导致性能不佳。

Method: RareAgent组织任务特定的对抗性辩论，智能体从不同视角动态构建证据图来支持、反驳或蕴含假设。推理策略在后验分析中通过自进化循环产生文本反馈来优化智能体策略，成功的推理路径被提炼为可转移的启发式规则。

Result: 综合评估显示，RareAgent将指示AUPRC提高了18.1%，优于推理基线方法，并提供了与临床证据一致的透明推理链。

Conclusion: RareAgent将罕见病药物重定位任务从被动模式识别重新定义为主动寻求证据的推理，通过多智能体对抗性辩论和自进化机制有效解决了缺乏先验关联信号的问题。

Abstract: Computational drug repurposing for rare diseases is especially challenging
when no prior associations exist between drugs and target diseases. Therefore,
knowledge graph completion and message-passing GNNs have little reliable signal
to learn and propagate, resulting in poor performance. We present RareAgent, a
self-evolving multi-agent system that reframes this task from passive pattern
recognition to active evidence-seeking reasoning. RareAgent organizes
task-specific adversarial debates in which agents dynamically construct
evidence graphs from diverse perspectives to support, refute, or entail
hypotheses. The reasoning strategies are analyzed post hoc in a
self-evolutionary loop, producing textual feedback that refines agent policies,
while successful reasoning paths are distilled into transferable heuristics to
accelerate future investigations. Comprehensive evaluations reveal that
RareAgent improves the indication AUPRC by 18.1% over reasoning baselines and
provides a transparent reasoning chain consistent with clinical evidence.

</details>


### [77] [ConstraintLLM: A Neuro-Symbolic Framework for Industrial-Level Constraint Programming](https://arxiv.org/abs/2510.05774)
*Weichun Shi,Minghao Liu,Wanting Zhang,Langchen Shi,Fuqi Jia,Feifei Ma,Jian Zhang*

Main category: cs.AI

TL;DR: ConstraintLLM是首个专门为约束编程建模设计的大语言模型，通过多指令监督微调训练，在工业级基准测试中达到最先进的求解精度。


<details>
  <summary>Details</summary>
Motivation: 约束编程在解决现实世界约束优化问题中具有重要作用，但目前基于大语言模型自动生成形式化建模的研究主要集中在运筹学模型上，约束编程领域关注较少。

Method: 在开源大语言模型基础上进行多指令监督微调，提出约束感知检索模块增强上下文学习能力，并集成到具有引导自校正机制的思维树框架中。

Result: ConstraintLLM在多个基准测试中达到最先进的求解精度，在新发布的工业级基准IndusCP上性能比基线方法提升2倍。

Conclusion: ConstraintLLM证明了专门针对约束编程建模设计的大语言模型的有效性，为构建可信赖的神经符号AI提供了新途径。

Abstract: Constraint programming (CP) is a crucial technology for solving real-world
constraint optimization problems (COPs), with the advantages of rich modeling
semantics and high solving efficiency. Using large language models (LLMs) to
generate formal modeling automatically for COPs is becoming a promising
approach, which aims to build trustworthy neuro-symbolic AI with the help of
symbolic solvers. However, CP has received less attention compared to works
based on operations research (OR) models. We introduce ConstraintLLM, the first
LLM specifically designed for CP modeling, which is trained on an open-source
LLM with multi-instruction supervised fine-tuning. We propose the
Constraint-Aware Retrieval Module (CARM) to increase the in-context learning
capabilities, which is integrated in a Tree-of-Thoughts (ToT) framework with
guided self-correction mechanism. Moreover, we construct and release IndusCP,
the first industrial-level benchmark for CP modeling, which contains 140
challenging tasks from various domains. Our experiments demonstrate that
ConstraintLLM achieves state-of-the-art solving accuracy across multiple
benchmarks and outperforms the baselines by 2x on the new IndusCP benchmark.
Code and data are available at: https://github.com/william4s/ConstraintLLM.

</details>


### [78] [Towards Label-Free Biological Reasoning Synthetic Dataset Creation via Uncertainty Filtering](https://arxiv.org/abs/2510.05871)
*Josefa Lia Stoisser,Lawrence Phillips,Aditya Misra,Tom A. Lamb,Philip Torr,Marc Boubnovski Martell,Julien Fauqueur,Kaspar Märtens*

Main category: cs.AI

TL;DR: 提出了一种基于不确定性的无标签过滤方法，使用模型自身置信度替代外部标签来筛选合成思维链数据，在生物扰动预测领域取得了优于未过滤数据的性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要真实标签来筛选合成思维链数据，但在生物学等实验数据稀缺的领域，获取真实标签成本高昂。

Method: 使用模型自身的不确定性指标（如自一致性和预测困惑度）来采样多个推理轨迹，仅保留低不确定性子集进行监督微调。

Result: 在生物扰动预测任务中，过滤后的数据具有更高准确性，基于不确定性过滤数据的监督微调优于未过滤合成数据，缩小了与真实标签训练的差距，并超越了强基线模型。

Conclusion: 模型内部置信度是创建高效推理数据集的强大信号，能够在监督成本高昂的领域实现大型推理模型的训练。

Abstract: Synthetic chain-of-thought (CoT) traces are widely used to train large
reasoning models (LRMs), improving generalization by providing step-level
supervision. Yet most approaches require ground-truth labels to seed or filter
these traces - an expensive bottleneck in domains like biology where wet-lab
data are scarce. We propose a label-free alternative: uncertainty-based
filtering, which uses a model's own confidence - quantified through established
uncertainty metrics like self-consistency and predictive perplexity - as a
substitute for external labels. We sample multiple reasoning traces and retain
only low-uncertainty subsets. Applied to biological perturbation prediction, a
domain where wet-lab labels are especially costly, we show that the filtered
subset has higher accuracy, and that supervised fine-tuning (SFT) on
uncertainty-filtered data outperforms unfiltered synthetic data, narrows the
gap to ground-truth training, and surpasses strong LRM baselines. Ablations
show that per-class filtering corrects for class-specific uncertainty scales
and that hybrid uncertainty metrics yield higher-quality datasets. Our results
suggest that model-internal confidence is a powerful signal for efficient
reasoning dataset creation, enabling LRMs in domains where supervision is
expensive.

</details>


### [79] [Optimizing for Persuasion Improves LLM Generalization: Evidence from Quality-Diversity Evolution of Debate Strategies](https://arxiv.org/abs/2510.05909)
*Aksel Joonas Reedi,Corentin Léger,Julien Pourcel,Loris Gaven,Perrine Charriau,Guillaume Pourcel*

Main category: cs.AI

TL;DR: 提出DebateQD算法，通过辩论式进化优化LLM推理能力，发现说服优化比传统真值优化具有更好的泛化性能


<details>
  <summary>Details</summary>
Motivation: 传统基于真值优化的LLM容易过拟合，产生脆弱的推理能力。辩论优化方法虽有潜力但缺乏系统比较

Method: 使用DebateQD质量多样性进化算法，在单一LLM架构中通过提示策略演化多样辩论策略，固定辩论协议仅交换适应度函数

Result: 在三个模型规模上，说服优化策略比真值优化减少13.94%的训练-测试泛化差距，测试性能相当或更好

Conclusion: 竞争性说服压力比协作寻求真值能培养更具迁移性的推理技能，为改进LLM泛化提供了新路径

Abstract: Large Language Models (LLMs) optimized to output truthful answers often
overfit, producing brittle reasoning that fails to generalize. While
persuasion-based optimization has shown promise in debate settings, it has not
been systematically compared against mainstream truth-based approaches. We
introduce DebateQD, a minimal Quality-Diversity (QD) evolutionary algorithm
that evolves diverse debate strategies across different categories
(rationality, authority, emotional appeal, etc.) through tournament-style
competitions where two LLMs debate while a third judges. Unlike previously
proposed methods that require a population of LLMs, our approach maintains
diversity of opponents through prompt-based strategies within a single LLM
architecture, making it more accessible for experiments while preserving the
key benefits of population-based optimization. In contrast to prior work, we
explicitly isolate the role of the optimization objective by fixing the debate
protocol and swapping only the fitness function: persuasion rewards strategies
that convince the judge irrespective of truth, whereas truth rewards
collaborative correctness. Across three model scales (7B, 32B, 72B parameters)
and multiple dataset sizes from the QuALITY benchmark, persuasion-optimized
strategies achieve up to 13.94% smaller train-test generalization gaps, while
matching or exceeding truth optimization's test performance. These results
provide the first controlled evidence that competitive pressure to persuade,
rather than seek the truth collaboratively, fosters more transferable reasoning
skills, offering a promising path for improving LLM generalization.

</details>


### [80] [Training-Free Time Series Classification via In-Context Reasoning with LLM Agents](https://arxiv.org/abs/2510.05950)
*Songyuan Sui,Zihang Xu,Yu-Neng Chuang,Kwei-Herng Lai,Xia Hu*

Main category: cs.AI

TL;DR: FETA是一个无需训练的多智能体框架，通过基于示例的上下文推理实现时间序列分类，将多变量序列分解为通道级子问题，使用推理LLM比较查询与相似示例，并通过置信度加权聚合所有通道决策。


<details>
  <summary>Details</summary>
Motivation: 时间序列分类中标记数据稀缺，任务特定训练成本高且不灵活，而纯零样本使用LLM效果欠佳，需要一种无需训练的高效分类方法。

Method: 将多变量序列分解为通道级子问题，为每个通道检索结构相似的标记示例，使用推理LLM比较查询与示例并生成通道级标签和置信度，最后通过置信度加权聚合器融合所有通道决策。

Result: 在九个具有挑战性的UEA数据集上，FETA在完全无需训练的情况下实现了强大的准确率，超越了多个经过训练的基线方法。

Conclusion: 多智能体上下文推理框架可以将LLM转变为具有竞争力的即插即用时间序列分类器，无需任何参数训练。

Abstract: Time series classification (TSC) spans diverse application scenarios, yet
labeled data are often scarce, making task-specific training costly and
inflexible. Recent reasoning-oriented large language models (LLMs) show promise
in understanding temporal patterns, but purely zero-shot usage remains
suboptimal. We propose FETA, a multi-agent framework for training-free TSC via
exemplar-based in-context reasoning. FETA decomposes a multivariate series into
channel-wise subproblems, retrieves a few structurally similar labeled examples
for each channel, and leverages a reasoning LLM to compare the query against
these exemplars, producing channel-level labels with self-assessed confidences;
a confidence-weighted aggregator then fuses all channel decisions. This design
eliminates the need for pretraining or fine-tuning, improves efficiency by
pruning irrelevant channels and controlling input length, and enhances
interpretability through exemplar grounding and confidence estimation. On nine
challenging UEA datasets, FETA achieves strong accuracy under a fully
training-free setting, surpassing multiple trained baselines. These results
demonstrate that a multi-agent in-context reasoning framework can transform
LLMs into competitive, plug-and-play TSC solvers without any parameter
training. The code is available at https://github.com/SongyuanSui/FETATSC.

</details>


### [81] [MatheMagic: Generating Dynamic Mathematics Benchmarks Robust to Memorization](https://arxiv.org/abs/2510.05962)
*Dayyán O'Brien,Barry Haddow,Emily Allaway,Pinzhen Chen*

Main category: cs.AI

TL;DR: 提出MatheMagic方法，通过改变数字和运算符的语义来构建动态反事实数学基准，用于检测模型过拟合和评估真实推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有数学基准存在两个问题：模型可能记忆公开测试集；当前数学基准由于符号和规则多样性有限且答案封闭，容易导致过拟合。需要一种无污染的方法来评估数学推理能力。

Method: 开发MatheMagic方法，在测试时随机生成数学测试实例，改变数字和运算符的语义解释但保持答案可自动验证，评估模型的归纳和演绎能力。

Result: 实验发现模型更容易解决演绎问题而非归纳问题，但会回归到标准数学；数学适应模型未能展现通用的推理"技能"，归纳任务的微调泛化效果差。

Conclusion: 该方法提供了稳定、可扩展、可比较且对过拟合鲁棒的评估框架，揭示了当前模型在数学推理方面的局限性。

Abstract: Conducting contamination-free evaluation of mathematical capabilities can be
difficult for two reasons: models may memorize a test set once it is made
public, and current mathematical benchmarks are prone to overfitting due to
having limited diversity of symbols and rules, coupled with closed-ended
answers. This paper proposes a method to leverage these shortcomings as useful
features to a construct dynamic, counterfactual benchmark, which can be used to
both reveal overfitting and measure true reasoning. We demonstrate this via
MatheMagic, which generates math test instances with the interpretations of
numbers and operators altered, yet has automatically verifiable answers. Test
instances are randomly seeded and constructed at test time to evaluate a
model's induction or deduction capability, offering stability, extensibility,
comparability, and robustness to overfitting. Our experiments find that models
solve deduction more easily than induction, but they revert to standard math.
Further analysis reveals that math-adapted models fail to exhibit a general
"skill" of reasoning, and fine-tuning on induction tasks generalizes poorly.

</details>


### [82] [Deterministic Legal Retrieval: An Action API for Querying the SAT-Graph RAG](https://arxiv.org/abs/2510.06002)
*Hudson de Martim*

Main category: cs.AI

TL;DR: SAT-Graph API是一个用于法律领域结构化知识图谱的查询执行层，通过原子化、可组合、可审计的原语操作，将概率性发现与确定性检索分离，实现透明可审计的检索过程。


<details>
  <summary>Details</summary>
Motivation: 解决标准RAG在法律领域的核心限制，特别是如何在不牺牲确定性属性的前提下可靠查询结构化知识，满足高风险领域对可解释AI的要求。

Method: 引入基于规范动作的正式查询执行层，这些动作是原子化、可组合和可审计的原语，支持混合搜索、引用解析、时间点版本检索和因果追踪。通过规划器引导的代理将复杂查询分解为这些动作的有向无环图。

Result: 实现了高精度混合搜索、鲁棒的引用解析、时间点版本检索和可审计的因果追踪，将检索从黑盒过程转变为透明可审计的过程。

Conclusion: 两层架构通过将概率性发现与确定性检索分离，直接满足了高风险领域对可解释AI的要求，为法律领域的结构化知识图谱查询提供了可靠解决方案。

Abstract: The Structure-Aware Temporal Graph RAG (SAT-Graph RAG) addresses core
limitations of standard Retrieval-Augmented Generation in the legal domain by
providing a verifiable knowledge graph that models hierarchical structure,
temporal evolution, and causal events of legal norms. However, a critical gap
remains: how to reliably query this structured knowledge without sacrificing
its deterministic properties. This paper introduces the SAT-Graph API, a formal
query execution layer centered on canonical actions-atomic, composable, and
auditable primitives that isolate probabilistic discovery from deterministic
retrieval. These actions enable: (i) high-precision hybrid search; (ii) robust
reference resolution; (iii) point-in-time version retrieval; and (iv) auditable
causal tracing. We demonstrate how planner-guided agents can decompose complex
queries into Directed Acyclic Graphs (DAGs) of these actions. This two-layer
architecture transforms retrieval from an opaque black box to a transparent,
auditable process, directly addressing Explainable AI (XAI) requirements for
high-stakes domains.

</details>


### [83] [ARISE: An Adaptive Resolution-Aware Metric for Test-Time Scaling Evaluation in Large Reasoning Models](https://arxiv.org/abs/2510.06014)
*Zhangyue Yin,Qiushi Sun,Zhiyuan Zeng,Zhiyuan Yu,Qipeng Guo,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: 提出了ARISE评估指标，专门用于评估大型推理模型的测试时扩展能力，包含样本级感知和动态采样机制，实验显示Claude Opus具有最优的扩展特性。


<details>
  <summary>Details</summary>
Motivation: 随着推理模型快速发展，需要系统性地比较和评估不同模型的测试时扩展能力，现有评估方法无法有效衡量计算资源动态分配的效果。

Method: 设计ARISE评估指标，包含两个关键创新：样本级感知（惩罚负扩展行为）和动态采样机制（减少准确率波动和token计数不稳定的影响）。

Result: 在数学推理、代码生成和智能体任务等多个领域的实验中，ARISE可靠地测量了测试时扩展能力，发现不同模型间扩展效率存在显著差异。

Conclusion: ARISE为评估推理模型的测试时扩展能力提供了细粒度测量，识别出Claude Opus相比其他当代模型具有更优的扩展特性。

Abstract: Test-time scaling has emerged as a transformative paradigm for enhancing the
performance of large reasoning models, enabling dynamic allocation of
computational resources during inference. However, as the landscape of
reasoning models rapidly expands, a critical question remains: how can we
systematically compare and evaluate the test-time scaling capabilities across
different models? In this paper, we introduce ARISE (Adaptive Resolution-aware
Scaling Evaluation), a novel metric specifically designed to assess the
test-time scaling effectiveness of large reasoning models. Unlike existing
evaluation approaches, ARISE incorporates two key innovations: (1) sample-level
awareness that effectively penalizes negative scaling behaviors where increased
computation leads to performance degradation, and (2) a dynamic sampling
mechanism that mitigates the impact of accuracy fluctuations and token count
instability on the final assessment. We conduct comprehensive experiments
evaluating state-of-the-art reasoning models across diverse domains including
mathematical reasoning, code generation, and agentic tasks. Our results
demonstrate that ARISE provides a reliable and fine-grained measurement of
test-time scaling capabilities, revealing significant variations in scaling
efficiency across models. Notably, our evaluation identifies Claude Opus as
exhibiting superior scaling characteristics compared to other contemporary
reasoning models.

</details>


### [84] [Refusal Falls off a Cliff: How Safety Alignment Fails in Reasoning?](https://arxiv.org/abs/2510.06036)
*Qingyu Yin,Chak Tou Leong,Linyi Yang,Wenxuan Huang,Wenjie Li,Xiting Wang,Jaehong Yoon,YunXing,XingYu,Jinjin Gu*

Main category: cs.AI

TL;DR: 研究发现大型推理模型存在"拒绝悬崖"现象：模型在推理过程中能正确识别有害提示并保持拒绝意图，但在输出前最后几个token处拒绝分数急剧下降，表明拒绝意图被系统性抑制。通过因果干预识别出少量负面贡献的注意力头，仅消融3%的头就能显著降低攻击成功率。基于此提出了Cliff-as-a-Judge数据选择方法，仅用1.7%的安全训练数据就能达到可比的安全改进效果。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型虽然具备多步推理能力，但存在令人担忧的安全漏洞且机制尚不清楚。本研究旨在通过机制可解释性视角探究为什么安全对齐在推理模型中会失败。

Method: 使用线性探测方法追踪token位置上的拒绝意图，发现拒绝悬崖现象；通过因果干预分析识别负面贡献的注意力头；提出Cliff-as-a-Judge数据选择方法，选择表现出最大拒绝悬崖的训练样本来高效修复推理模型的安全对齐。

Result: 发现许多对齐不良的推理模型在思考过程中能正确识别有害提示并保持强烈拒绝意图，但在输出前最后几个token处拒绝分数急剧下降；仅消融3%的负面注意力头就能将攻击成功率降至10%以下；Cliff-as-a-Judge方法仅用1.7%的普通安全训练数据就实现了可比的安全改进。

Conclusion: 推理模型并非天生不安全，而是其拒绝意图被系统性抑制；通过机制性洞察可以高效修复安全对齐问题，展示了安全对齐中的"少即是多"效应。

Abstract: Large reasoning models (LRMs) with multi-step reasoning capabilities have
shown remarkable problem-solving abilities, yet they exhibit concerning safety
vulnerabilities that remain poorly understood. In this work, we investigate why
safety alignment fails in reasoning models through a mechanistic
interpretability lens. Using a linear probing approach to trace refusal
intentions across token positions, we discover a striking phenomenon termed as
\textbf{refusal cliff}: many poorly-aligned reasoning models correctly identify
harmful prompts and maintain strong refusal intentions during their thinking
process, but experience a sharp drop in refusal scores at the final tokens
before output generation. This suggests that these models are not inherently
unsafe; rather, their refusal intentions are systematically suppressed. Through
causal intervention analysis, we identify a sparse set of attention heads that
negatively contribute to refusal behavior. Ablating just 3\% of these heads can
reduce attack success rates below 10\%. Building on these mechanistic insights,
we propose \textbf{Cliff-as-a-Judge}, a novel data selection method that
identifies training examples exhibiting the largest refusal cliff to
efficiently repair reasoning models' safety alignment. This approach achieves
comparable safety improvements using only 1.7\% of the vanilla safety training
data, demonstrating a less-is-more effect in safety alignment.

</details>


### [85] [MixReasoning: Switching Modes to Think](https://arxiv.org/abs/2510.06052)
*Haiquan Lu,Gongfan Fang,Xinyin Ma,Qi Li,Xinchao Wang*

Main category: cs.AI

TL;DR: MixReasoning框架通过动态调整推理深度，在困难步骤进行详细推理，在简单步骤进行简洁推断，从而缩短推理长度并提高效率，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型对所有步骤采用相同的详细推理方式，但实际子问题的难度差异很大，这导致了大量冗余。关键步骤需要深入推理，而简单步骤只需简洁处理。

Method: 提出MixReasoning框架，在单个响应中动态调整推理深度，形成混合推理链：对困难步骤进行详细推理，对简单步骤进行简洁推断。

Result: 在GSM8K、MATH-500和AIME数据集上的实验表明，MixReasoning显著缩短了推理长度，大幅提高了效率，且没有影响准确性。

Conclusion: 动态调整推理深度的混合推理方法能够有效减少冗余，提高推理效率，同时保持模型性能，为推理模型提供了一种更高效的解决方案。

Abstract: Reasoning models enhance performance by tackling problems in a step-by-step
manner, decomposing them into sub-problems and exploring long chains of thought
before producing an answer. However, applying extended reasoning to every step
introduces substantial redundancy, as sub-problems vary widely in difficulty
and complexity: a small number of pivotal steps are genuinely challenging and
decisive for the final answer, while many others only involve straightforward
revisions or simple computations. Therefore, a natural idea is to endow
reasoning models with the ability to adaptively respond to this variation,
rather than treating all steps with the same level of elaboration. To this end,
we propose MixReasoning, a framework that dynamically adjusts the depth of
reasoning within a single response. The resulting chain of thought then becomes
a mixture of detailed reasoning on difficult steps and concise inference on
simpler ones. Experiments on GSM8K, MATH-500, and AIME show that MixReasoning
shortens reasoning length and substantially improves efficiency without
compromising accuracy.

</details>


### [86] [Scientific Algorithm Discovery by Augmenting AlphaEvolve with Deep Research](https://arxiv.org/abs/2510.06056)
*Gang Liu,Yihan Zhu,Jie Chen,Meng Jiang*

Main category: cs.AI

TL;DR: DeepEvolve是一个结合深度研究和算法演化的科学助手代理，通过外部知识检索、跨文件代码编辑和系统调试的反馈驱动迭代循环，持续改进科学算法。


<details>
  <summary>Details</summary>
Motivation: 现有科学助手要么仅依赖算法演化（依赖LLM内部知识，在复杂领域快速达到平台期），要么仅进行深度研究（提出想法但缺乏验证，导致不切实际的解决方案），两者都有严重局限性。

Method: 集成深度研究和算法演化，结合外部知识检索、跨文件代码编辑和系统调试，在反馈驱动的迭代循环中不仅提出新假设，还进行精炼、实现和测试。

Result: 在化学、数学、生物学、材料和专利等九个基准测试中，DeepEvolve持续改进初始算法，产生可执行的新算法并保持持续增益。

Conclusion: 通过弥合无引导演化和无基础研究之间的差距，DeepEvolve为推进科学算法发现提供了一个可靠框架。

Abstract: Large language models hold promise as scientific assistants, yet existing
agents either rely solely on algorithm evolution or on deep research in
isolation, both of which face critical limitations. Pure algorithm evolution,
as in AlphaEvolve, depends only on the internal knowledge of LLMs and quickly
plateaus in complex domains, while pure deep research proposes ideas without
validation, resulting in unrealistic or unimplementable solutions. We present
DeepEvolve, an agent that integrates deep research with algorithm evolution,
uniting external knowledge retrieval, cross-file code editing, and systematic
debugging under a feedback-driven iterative loop. Each iteration not only
proposes new hypotheses but also refines, implements, and tests them, avoiding
both shallow improvements and unproductive over-refinements. Across nine
benchmarks in chemistry, mathematics, biology, materials, and patents,
DeepEvolve consistently improves the initial algorithm, producing executable
new algorithms with sustained gains. By bridging the gap between unguided
evolution and research without grounding, DeepEvolve provides a reliable
framework for advancing scientific algorithm discovery. Our code is available
at https://github.com/liugangcode/deepevolve.

</details>


### [87] [TelecomTS: A Multi-Modal Observability Dataset for Time Series and Language Analysis](https://arxiv.org/abs/2510.06063)
*Austin Feng,Andreas Varvarigos,Ioannis Panitsas,Daniela Fernandez,Jinbiao Wei,Yuwei Guo,Jialin Chen,Ali Maatouk,Leandros Tassiulas,Rex Ying*

Main category: cs.AI

TL;DR: 提出了TelecomTS数据集，这是一个来自5G电信网络的大规模可观测性数据集，解决了现有数据集缺乏真实规模和协变量信息的问题，支持异常检测、根因分析和多模态推理等下游任务。


<details>
  <summary>Details</summary>
Motivation: 现有可观测性数据集在公共基准中代表性不足，通常经过匿名化和归一化处理，移除了尺度信息，限制了它们在异常检测、根因分析和多模态推理等任务中的应用。

Method: 从5G电信网络收集大规模可观测性数据，构建包含异构、去匿名化协变量和明确尺度信息的TelecomTS数据集，并建立包含异常检测、根因分析和多模态问答的下游任务基准。

Result: 基准测试显示，现有的时间序列、语言和推理模型在处理可观测性数据的突然、噪声和高方差动态方面表现不佳。实验强调了保留协变量绝对尺度信息的重要性。

Conclusion: 需要开发能够原生利用尺度信息的基础时间序列模型，以应对实际可观测性应用中的挑战。

Abstract: Modern enterprises generate vast streams of time series metrics when
monitoring complex systems, known as observability data. Unlike conventional
time series from domains such as weather, observability data are zero-inflated,
highly stochastic, and exhibit minimal temporal structure. Despite their
importance, observability datasets are underrepresented in public benchmarks
due to proprietary restrictions. Existing datasets are often anonymized and
normalized, removing scale information and limiting their use for tasks beyond
forecasting, such as anomaly detection, root-cause analysis, and multi-modal
reasoning. To address this gap, we introduce TelecomTS, a large-scale
observability dataset derived from a 5G telecommunications network. TelecomTS
features heterogeneous, de-anonymized covariates with explicit scale
information and supports a suite of downstream tasks, including anomaly
detection, root-cause analysis, and a question-answering benchmark requiring
multi-modal reasoning. Benchmarking state-of-the-art time series, language, and
reasoning models reveals that existing approaches struggle with the abrupt,
noisy, and high-variance dynamics of observability data. Our experiments also
underscore the importance of preserving covariates' absolute scale, emphasizing
the need for foundation time series models that natively leverage scale
information for practical observability applications.

</details>


### [88] [Constraint-Aware Route Recommendation from Natural Language via Hierarchical LLM Agents](https://arxiv.org/abs/2510.06078)
*Tao Zhe,Rui Liu,Fateme Memar,Xiao Luo,Wei Fan,Xinyue Ye,Zhongren Peng,Dongjie Wang*

Main category: cs.AI

TL;DR: RouteLLM是一个分层多智能体框架，将自然语言意图转化为约束感知的路线推荐系统，通过协调多个专业智能体来解析用户查询、解决约束、检索POI并优化路径。


<details>
  <summary>Details</summary>
Motivation: 传统路由算法假设结构化输入和固定目标，难以适应自然语言查询；而基于LLM的方法在空间推理和联合建模路线级与POI级偏好方面存在困难。

Method: 提出分层多智能体框架：首先解析用户查询为结构化意图，然后通过管理器协调约束智能体、POI智能体和路径优化智能体，最后通过验证器确保约束满足并生成可解释的路线。

Result: 实验表明该方法能可靠地将文本偏好转化为约束感知路线，在路线质量和偏好满足度方面优于传统方法。

Conclusion: RouteLLM成功桥接了语言灵活性和空间结构，实现了对路线可行性和用户偏好的推理，提高了路线推荐的质量和用户满意度。

Abstract: Route recommendation aims to provide users with optimal travel plans that
satisfy diverse and complex requirements. Classical routing algorithms (e.g.,
shortest-path and constraint-aware search) are efficient but assume structured
inputs and fixed objectives, limiting adaptability to natural-language queries.
Recent LLM-based approaches enhance flexibility but struggle with spatial
reasoning and the joint modeling of route-level and POI-level preferences. To
address these limitations, we propose RouteLLM, a hierarchical multi-agent
framework that grounds natural-language intents into constraint-aware routes.
It first parses user queries into structured intents including POIs, paths, and
constraints. A manager agent then coordinates specialized sub-agents: a
constraint agent that resolves and formally check constraints, a POI agent that
retrieves and ranks candidate POIs, and a path refinement agent that refines
routes via a routing engine with preference-conditioned costs. A final verifier
agent ensures constraint satisfaction and produces the final route with an
interpretable rationale. This design bridges linguistic flexibility and spatial
structure, enabling reasoning over route feasibility and user preferences.
Experiments show that our method reliably grounds textual preferences into
constraint-aware routes, improving route quality and preference satisfaction
over classical methods.

</details>


### [89] [Classical AI vs. LLMs for Decision-Maker Alignment in Health Insurance Choices](https://arxiv.org/abs/2510.06093)
*Mallika Mainali,Harsha Sureshbabu,Anik Sen,Christopher B. Rauch,Noah D. Reifsnyder,John Meyer,J. T. Turner,Michael W. Floyd,Matthew Molineaux,Rosina O. Weber*

Main category: cs.AI

TL;DR: 该研究比较了经典AI方法和基于LLM的方法在决策者对齐任务中的表现，发现两种方法在健康保险决策数据集上表现相当，经典AI方法在中等风险偏好下略优。


<details>
  <summary>Details</summary>
Motivation: 随着算法决策在关键领域应用增多，AI对齐研究从通用价值对齐转向考虑决策者属性的上下文特定方法。现有决策者对齐方法在通用性方面仍有待探索。

Method: 实现了一个经典AI模型并开发了基于LLM的算法决策器，使用GPT-5和GPT-4在零样本提示框架下评估，数据集包含三个不同风险容忍度的决策者。

Result: 经典AI和基于LLM的模型在与基于属性的目标对齐方面表现相当，经典AI在中等风险偏好下表现出稍好的对齐性。

Conclusion: 两种方法在决策者对齐任务中都有潜力，经典AI方法在某些特定风险偏好下可能具有优势，为未来研究提供了基准和开源实现。

Abstract: As algorithmic decision-makers are increasingly applied to high-stakes
domains, AI alignment research has evolved from a focus on universal value
alignment to context-specific approaches that account for decision-maker
attributes. Prior work on Decision-Maker Alignment (DMA) has explored two
primary strategies: (1) classical AI methods integrating case-based reasoning,
Bayesian reasoning, and naturalistic decision-making, and (2) large language
model (LLM)-based methods leveraging prompt engineering. While both approaches
have shown promise in limited domains such as medical triage, their
generalizability to novel contexts remains underexplored. In this work, we
implement a prior classical AI model and develop an LLM-based algorithmic
decision-maker evaluated using a large reasoning model (GPT-5) and a
non-reasoning model (GPT-4) with weighted self-consistency under a zero-shot
prompting framework, as proposed in recent literature. We evaluate both
approaches on a health insurance decision-making dataset annotated for three
target decision-makers with varying levels of risk tolerance (0.0, 0.5, 1.0).
In the experiments reported herein, classical AI and LLM-based models achieved
comparable alignment with attribute-based targets, with classical AI exhibiting
slightly better alignment for a moderate risk profile. The dataset and
open-source implementation are publicly available at:
https://github.com/TeX-Base/ClassicalAIvsLLMsforDMAlignment and
https://github.com/Parallax-Advanced-Research/ITM/tree/feature_insurance.

</details>


### [90] [Pushing Test-Time Scaling Limits of Deep Search with Asymmetric Verification](https://arxiv.org/abs/2510.06135)
*Weihao Zeng,Keqing He,Chuqiao Kuang,Xiaoguang Li,Junxian He*

Main category: cs.AI

TL;DR: 该论文研究了测试时计算扩展（TTS）策略，包括顺序扩展和并行扩展，利用验证比生成更容易的不对称验证特性，在深度搜索代理中实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 在某些场景下（如解决数独谜题），验证响应比生成响应要容易得多，这种不对称验证特性凸显了测试时扩展的巨大潜力。

Method: 结合顺序扩展（延长生成过程）和并行扩展（验证和选择多个候选输出）策略，利用不对称验证特性，为验证器分配适量计算资源。

Result: 通过TTS扩展的开源模型在BrowseComp基准上实现了高达27个绝对百分点的提升，GLM-4.5 Heavy达到54.0%准确率，Tongyi-DeepResearch Heavy达到69.0%准确率，超越了最好的专有模型结果。

Conclusion: 测试时计算扩展，特别是利用不对称验证特性，能够显著提升AI系统性能，使开源模型在复杂任务上达到甚至超越专有模型的水平。

Abstract: Test-time compute can be scaled both sequentially and in parallel. Sequential
scaling involves lengthening the generation process, while parallel scaling
involves verifying and selecting among multiple candidate outputs. Combining
these two strategies has led to the most powerful AI systems, such as Grok 4
Heavy and GPT-5 Pro. In certain contexts (e.g., solving Sudoku puzzles),
verifying responses can be substantially easier than generating them. This
property, referred to as \emph{asymmetric verification}, highlights the strong
potential of test-time scaling (TTS). In this work, we study both sequential
and parallel TTS of deep search agents, motivated by the intuition that
verification in this setting is often much easier than generation. In
experiments, we first show that sequential scaling methods, such as budget
forcing, can be effective initially but soon degrade performance. Leveraging
asymmetric verification, however, we are able to achieve substantial
improvements by allocating only a modest amount of compute to the verifier. We
conduct experiments with flagship open-source models and extend them to their
``Heavy'' variants through TTS. These deep research agents achieve gains of up
to 27 absolute points on benchmarks such as BrowseComp. Remarkably, as an
open-source alternative, GLM-4.5 Heavy reaches accuracy of {\bf 54.0\%} on
BrowseComp and {\bf 66.0\%} on GAIA, placing it comparable to the best
proprietary choices such as OpenAI Deep Research. Tongyi-DeepResearch Heavy
further achieves {\bf 69.0\%} accuracy on BrowseComp, greatly surpassing the
best proprietary results.

</details>


### [91] [Barbarians at the Gate: How AI is Upending Systems Research](https://arxiv.org/abs/2510.06189)
*Audrey Cheng,Shu Liu,Melissa Pan,Zhifei Li,Bowen Wang,Alex Krentsel,Tian Xia,Mert Cemri,Jongseok Park,Shuo Yang,Jeff Chen,Aditya Desai,Jiarong Xing,Koushik Sen,Matei Zaharia,Ion Stoica*

Main category: cs.AI

TL;DR: AI驱动的系统研究(ADRS)通过自动生成、评估和优化算法解决方案，在多个系统领域实现了超越人类设计的最优性能，最高可达5倍运行时间改进或50%成本降低。


<details>
  <summary>Details</summary>
Motivation: 系统研究特别适合AI驱动的解决方案发现，因为系统性能问题天然具有可靠的验证器——解决方案可以在真实系统或模拟器中实现，并通过预定义工作负载进行性能测量验证。

Method: 提出AI驱动的系统研究(ADRS)方法，迭代生成、评估和优化解决方案。使用penEvolve开源实例，在负载均衡、专家混合推理、LLM SQL查询和事务调度等多个领域进行案例研究。

Result: ADRS在多个实例中发现了超越最先进人类设计的算法，实现了高达5.0倍的运行时间改进或50%的成本降低。

Conclusion: 随着AI在算法设计中发挥核心作用，人类研究人员将更多地专注于问题制定和战略指导，这凸显了在AI时代适应系统研究实践的紧迫性和颠覆性潜力。

Abstract: Artificial Intelligence (AI) is starting to transform the research process as
we know it by automating the discovery of new solutions. Given a task, the
typical AI-driven approach is (i) to generate a set of diverse solutions, and
then (ii) to verify these solutions and select one that solves the problem.
Crucially, this approach assumes the existence of a reliable verifier, i.e.,
one that can accurately determine whether a solution solves the given problem.
We argue that systems research, long focused on designing and evaluating new
performance-oriented algorithms, is particularly well-suited for AI-driven
solution discovery. This is because system performance problems naturally admit
reliable verifiers: solutions are typically implemented in real systems or
simulators, and verification reduces to running these software artifacts
against predefined workloads and measuring performance. We term this approach
as AI-Driven Research for Systems (ADRS), which iteratively generates,
evaluates, and refines solutions. Using penEvolve, an existing open-source ADRS
instance, we present case studies across diverse domains, including load
balancing for multi-region cloud scheduling, Mixture-of-Experts inference,
LLM-based SQL queries, and transaction scheduling. In multiple instances, ADRS
discovers algorithms that outperform state-of-the-art human designs (e.g.,
achieving up to 5.0x runtime improvements or 50% cost reductions). We distill
best practices for guiding algorithm evolution, from prompt design to evaluator
construction, for existing frameworks. We then discuss the broader implications
for the systems community: as AI assumes a central role in algorithm design, we
argue that human researchers will increasingly focus on problem formulation and
strategic guidance. Our results highlight both the disruptive potential and the
urgent need to adapt systems research practices in the age of AI.

</details>


### [92] [TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular Reasoning](https://arxiv.org/abs/2510.06217)
*Jiaru Zou,Soumya Roy,Vinay Kumar Verma,Ziyi Wang,David Wipf,Pan Lu,Sumit Negi,James Zou,Jingrui He*

Main category: cs.AI

TL;DR: TaTToo是一个新颖的表格基础过程奖励模型框架，专门针对表格推理任务，通过工具验证提供精确的奖励监督，在5个具有挑战性的表格推理基准测试中显著提升下游策略模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型(PRMs)虽然在文本推理步骤监督方面表现良好，但在处理表格特定操作(如子表检索和模式交互)时存在困难，导致在表格推理领域性能瓶颈。

Method: 提出TaTToo框架：1)设计可扩展的数据整理流程，构建6万多个高质量步骤级标注；2)采用双阶段训练范式：冷启动监督微调捕获工具使用推理模式，然后通过工具基础奖励塑形的强化学习来对齐表格验证。

Result: 在5个表格推理基准测试中，TaTToo在推理时提升下游策略LRMs 30.9%，仅用8B参数就超越了强大的PRM基线模型(Qwen-2.5-Math-PRM-72B)，并在不同TTS策略中展现出强泛化能力。

Conclusion: TaTToo通过显式的表格推理步骤和工具验证，有效解决了表格推理中的关键性能瓶颈，为表格推理领域的过程奖励模型提供了新的解决方案。

Abstract: Process Reward Models (PRMs) have recently emerged as a powerful framework
for enhancing the reasoning capabilities of large reasoning models (LRMs),
particularly in the context of test-time scaling (TTS). However, their
potential for supervising LRMs on tabular reasoning domains remains
underexplored. Through detailed empirical analyses, we identify that existing
PRMs, though widely adopted for supervising text-only reasoning steps, struggle
with table-specific operations such as sub-table retrieval and schema
interaction, leading to critical performance bottlenecks. To address this
limitation, we propose TaTToo, a novel table-grounded PRM framework that (i)
reasons explicitly over tabular reasoning steps and (ii) integrates tool-based
verification to provide precise reward supervision. Concretely, we first design
a scalable data curation pipeline that constructs over 60k high-quality
step-level annotations by integrating table verification rationales with
tool-based executions. Building on the collected data, we train TaTToo with a
dual-stage paradigm: cold-start supervised fine-tuning to capture tool-use
reasoning patterns, followed by reinforcement learning with tool-grounded
reward shaping to align our model with table-based verification. We provide a
comprehensive evaluation of the policy improvement induced by our newly
designed PRM. Across 5 challenging tabular reasoning benchmarks covering
numerical reasoning, fact-checking, and data analysis, TaTToo improves
downstream policy LRMs by 30.9% at inference, surpasses strong PRM baselines
such as Qwen-2.5-Math-PRM-72B with only 8B parameters, and demonstrates strong
generalizability across diverse TTS strategies.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [93] [Artificial-Intelligence Grading Assistance for Handwritten Components of a Calculus Exam](https://arxiv.org/abs/2510.05162)
*Gerd Kortemeyer,Alexander Caspar,Daria Horica*

Main category: cs.CY

TL;DR: 研究现代多模态LLM能否在不降低有效性的情况下大规模批改开放式微积分题目，通过人类参与循环过滤机制实现AI与助教评分的一致性。


<details>
  <summary>Details</summary>
Motivation: 探索AI在大规模教育评估中的应用潜力，特别是能否在保持评分有效性的前提下，减轻人工批改负担。

Method: 使用GPT-5批改学生手写微积分作业，与助教使用相同评分标准，结合部分学分阈值和项目反应理论风险度量构建人类参与循环过滤机制。

Result: 未过滤时AI与助教评分一致性中等，适合低风险反馈；严格置信度过滤下AI可达人类水平准确性，但约70%题目仍需人工批改。

Conclusion: 校准置信度和保守路由使AI能可靠处理常规题目子集，同时保留专家判断用于模糊或教学价值高的回答。

Abstract: We investigate whether contemporary multimodal LLMs can assist with grading
open-ended calculus at scale without eroding validity. In a large first-year
exam, students' handwritten work was graded by GPT-5 against the same rubric
used by teaching assistants (TAs), with fractional credit permitted; TA rubric
decisions served as ground truth. We calibrated a human-in-the-loop filter that
combines a partial-credit threshold with an Item Response Theory (2PL) risk
measure based on the deviation between the AI score and the model-expected
score for each student-item. Unfiltered AI-TA agreement was moderate, adequate
for low-stakes feedback but not for high-stakes use. Confidence filtering made
the workload-quality trade-off explicit: under stricter settings, AI delivered
human-level accuracy, but also left roughly 70% of the items to be graded by
humans. Psychometric patterns were constrained by low stakes on the open-ended
portion, a small set of rubric checkpoints, and occasional misalignment between
designated answer regions and where work appeared. Practical adjustments such
as slightly higher weight and protected time, a few rubric-visible substeps,
stronger spatial anchoring should raise ceiling performance. Overall,
calibrated confidence and conservative routing enable AI to reliably handle a
sizable subset of routine cases while reserving expert judgment for ambiguous
or pedagogically rich responses.

</details>


### [94] [Disclosure and Evaluation as Fairness Interventions for General-Purpose AI](https://arxiv.org/abs/2510.05292)
*Vyoma Raman,Judy Hanwen Shen,Andy K. Zhang,Lindsey Gailmard,Rishi Bommasani,Daniel E. Ho,Angelina Wang*

Main category: cs.CY

TL;DR: 该论文主张AI公平性应通过过程规范而非结果强制来实现，重点关注系统提供商和部署商的信息收集与披露责任，以适应通用AI的多上下文特性。


<details>
  <summary>Details</summary>
Motivation: 针对通用AI系统服务于多种上下文环境的特点，传统基于特定上下文的公平性定义面临挑战，需要新的公平性实现框架。

Method: 提出基于过程的公平性方法，分析系统提供商和部署商各自的责任：提供商应进行公平性评估研究并披露模型信息，部署商应披露用户信息并进行多层级公平性评估。

Result: 建立了针对通用AI系统的公平性责任分配框架，明确了不同利益相关者在信息收集和披露方面的具体义务。

Conclusion: 通过关注过程而非结果，可以在未知上下文的情况下具体规范公平性实践，为AI公平性责任分配和上下文敏感干预提供清晰指导。

Abstract: Despite conflicting definitions and conceptions of fairness, AI fairness
researchers broadly agree that fairness is context-specific. However, when
faced with general-purpose AI, which by definition serves a range of contexts,
how should we think about fairness? We argue that while we cannot be
prescriptive about what constitutes fair outcomes, we can specify the processes
that different stakeholders should follow in service of fairness. Specifically,
we consider the obligations of two major groups: system providers and system
deployers. While system providers are natural candidates for regulatory
attention, the current state of AI understanding offers limited insight into
how upstream factors translate into downstream fairness impacts. Thus, we
recommend that providers invest in evaluative research studying how model
development decisions influence fairness and disclose whom they are serving
their models to, or at the very least, reveal sufficient information for
external researchers to conduct such research. On the other hand, system
deployers are closer to real-world contexts and can leverage their proximity to
end users to address fairness harms in different ways. Here, we argue they
should responsibly disclose information about users and personalization and
conduct rigorous evaluations across different levels of fairness. Overall,
instead of focusing on enforcing fairness outcomes, we prioritize intentional
information-gathering by system providers and deployers that can facilitate
later context-aware action. This allows us to be specific and concrete about
the processes even while the contexts remain unknown. Ultimately, this approach
can sharpen how we distribute fairness responsibilities and inform more fluid,
context-sensitive interventions as AI continues to advance.

</details>


### [95] [Evaluating LLM Safety Across Child Development Stages: A Simulated Agent Approach](https://arxiv.org/abs/2510.05484)
*Abhejay Murali,Saleh Afroogh,Kevin Chen,David Atkinson,Amit Dhurandhar,Junfeng Jiao*

Main category: cs.CY

TL;DR: ChildSafe是一个评估LLM儿童安全性的基准测试，通过模拟四个发展阶段的人工智能儿童代理来系统评估语言模型在儿童安全方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法捕捉LLM如何管理特定年龄段儿童的语言、推理和安全需求，需要专门针对儿童安全性的评估框架。

Method: 基于发展心理学创建四个发展阶段的模拟儿童代理，在敏感和中性情境下评估九个安全维度，采用年龄加权评分和多轮对话实验。

Result: 实验发现LLM存在一致的安全漏洞，这些漏洞随模拟年龄变化，暴露了现有对齐实践的不足。

Conclusion: ChildSafe提供了一个可复现的年龄感知安全研究框架，鼓励社区扩展真实儿童数据和研究，推动开发真正安全且发展对齐的LLM。

Abstract: Large Language Models (LLMs) are rapidly becoming part of tools used by
children; however, existing benchmarks fail to capture how these models manage
language, reasoning, and safety needs that are specific to various ages. We
present ChildSafe, a benchmark that evaluates LLM safety through simulated
child agents that embody four developmental stages. These agents, grounded in
developmental psychology, enable a systematic study of child safety without the
ethical implications of involving real children. ChildSafe assesses responses
across nine safety dimensions (including privacy, misinformation, and emotional
support) using age-weighted scoring in both sensitive and neutral contexts.
Multi-turn experiments with multiple LLMs uncover consistent vulnerabilities
that vary by simulated age, exposing shortcomings in existing alignment
practices. By releasing agent templates, evaluation protocols, and an
experimental corpus, we provide a reproducible framework for age-aware safety
research. We encourage the community to expand this work with real
child-centered data and studies, advancing the development of LLMs that are
genuinely safe and developmentally aligned.

</details>


### [96] [Assessing Human Rights Risks in AI: A Framework for Model Evaluation](https://arxiv.org/abs/2510.05519)
*Vyoma Raman,Camille Chabot,Betsy Popken*

Main category: cs.CY

TL;DR: 提出了一个计算评估AI模型人权风险的框架，基于联合国商业与人权指导原则，通过选择任务、设计指标和分析权利三个步骤来评估模型对特定人权的风险水平。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的普及，其对非歧视、健康和安全等人权的风险日益凸显，需要开发系统化的人权风险评估方法来应对这些挑战。

Method: 开发了一个三部分框架：1）选择可能造成人权风险的任务；2）设计衡量风险范围、规模和可能性的指标；3）根据指标值分析具体权利。通过政治新闻新闻业中大型语言模型的案例研究来验证框架。

Result: 框架成功应用于政治新闻新闻业场景，能够评估不同模型对信息获取权和思想自由权的影响，为模型比较提供了基准。

Conclusion: 人权风险评估方法强调在具体部署环境中评估AI系统，有助于更全面地理解和管理AI技术对人权的潜在影响，为算法审计领域提供了重要贡献。

Abstract: The Universal Declaration of Human Rights and other international agreements
outline numerous inalienable rights that apply across geopolitical boundaries.
As generative AI becomes increasingly prevalent, it poses risks to human rights
such as non-discrimination, health, and security, which are also central
concerns for AI researchers focused on fairness and safety. We contribute to
the field of algorithmic auditing by presenting a framework to computationally
assess human rights risk. Drawing on the UN Guiding Principles on Business and
Human Rights, we develop an approach to evaluating a model to make grounded
claims about the level of risk a model poses to particular human rights. Our
framework consists of three parts: selecting tasks that are likely to pose
human rights risks within a given context, designing metrics to measure the
scope, scale, and likelihood of potential risks from that task, and analyzing
rights with respect to the values of those metrics. Because a human rights
approach centers on real-world harms, it requires evaluating AI systems in the
specific contexts in which they are deployed. We present a case study of large
language models in political news journalism, demonstrating how our framework
helps to design an evaluation and benchmarking different models. We then
discuss the implications of the results for the rights of access to information
and freedom of thought and broader considerations for adopting this approach.

</details>


### [97] [Beyond Accessibility: How Intelligent Assistive Technologies Improve Activities of Daily Life for Visually Impaired People in South Africa](https://arxiv.org/abs/2510.05998)
*Ronaldo Nombakuse,Nils Messerschmidt,Pitso Tsibolane,Muhammad Irfan Khalid*

Main category: cs.CY

TL;DR: 研究探讨智能辅助技术如何帮助视障人士克服数字社会中的障碍，提升生活质量。基于社会残疾模型，通过访谈和调查发现自主性和技术可及性是促进社会参与的关键因素。


<details>
  <summary>Details</summary>
Motivation: 探索智能辅助技术如何帮助视障人士在数字社会中实现包容，改善其生活质量，特别关注全球南方地区的情况。

Method: 采用半结构化访谈和在线定性调查，对南非61名视障人士进行研究，使用描述性统计和定性比较分析(QCA)方法。

Result: 识别出9种配置，分为3大类条件组合，发现视障人士的自主性和智能辅助技术的可及性是促进社会参与的主要预测因素。

Conclusion: 研究为信息系统领域在技术与社会参与交叉点提供贡献，并为促进全球南方视障人士社会包容的政策制定提供启示。

Abstract: Our study explores how intelligent assistive technologies (IATs) can enable
visually impaired people (VIPs) to overcome barriers to inclusion in a digital
society to ultimately improve their quality of life. Drawing on the Social
Model of Disability (SMD), which frames disability as a consequence of social
and institutional barriers rather than individual impairments, we employ
semi-structured interviews and an online qualitative survey with n=61 VIPs in
South Africa. Using descriptive statistics and Qualitative Comparative Analysis
(QCA), we uncover nine configurations, clustered along three broader
combinations of conditions, that support and hinder IAT-mediated inclusion.
Most notably, we identify that the autonomy of VIPs and the accessibility of
IATs are primary predictors of IAT's ability to achieve social participation.
Our findings contribute to Information Systems (IS) literature at the
intersection of technology and social participation. We further formulate
implications for research and policymakers to foster social inclusion of VIPs
in the Global South.

</details>


### [98] [A Possibility Frontier Approach to Diverse Talent Selection](https://arxiv.org/abs/2510.06119)
*Neil Natarajan,Kadeem Noray*

Main category: cs.CY

TL;DR: 该论文提出了一种算法来近似计算人才选拔中多样性与才能之间的权衡边界，并通过实际案例验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 组织在选拔人才时面临多样性与才能之间的权衡，但目前缺乏有效方法来量化这种权衡，无法做出帕累托最优决策。

Method: 引入选择可能性边界（SPF）算法，近似计算人才选拔中多样性与才能的上界，并用该边界评估选拔效率。

Result: 在2021和2022年周期中，项目选拔的最终人选在多样性和才能方面都非最优；但在2023年使用SPF后，成功选拔出位于边界上的最优人选。

Conclusion: SPF算法能够有效帮助组织在人才选拔中实现多样性与才能的帕累托最优平衡。

Abstract: Organizations (e.g., talent investment programs, schools, firms) are
perennially interested in selecting cohorts of talented people. And
organizations are increasingly interested in selecting diverse cohorts. Except
in trivial cases, measuring the tradeoff between cohort diversity and talent is
computationally difficult. Thus, organizations are presently unable to make
Pareto-efficient decisions about these tradeoffs. We introduce an algorithm
that approximates upper bounds on cohort talent and diversity. We call this
object the selection possibility frontier (SPF). We then use the SPF to assess
the efficiency of selection of a talent investment program. We show that, in
the 2021 and 2022 cycles, the program selected cohorts of finalists that could
have been better along both diversity and talent dimensions (i.e., considering
only these dimensions as we subsequently calculated them, they are
Pareto-inferior cohorts). But, when given access our approximation of the SPF
in the 2023 cycle, the program adjusted decisions and selected a cohort on the
SPF.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [99] [Pricing Short-Circuit Current via a Primal-Dual Formulation for Preserving Integrality Constraints](https://arxiv.org/abs/2510.05293)
*Peng Wang,Luis Badesa*

Main category: eess.SY

TL;DR: 提出一种基于原始-对偶公式的短路电流服务定价方法，解决了传统方法在处理机组组合整数约束时的局限性，能够有效计算SCC服务的影子价格。


<details>
  <summary>Details</summary>
Motivation: 随着同步发电机被电力电子发电设备替代，短路电流供应能力下降，需要优化剩余同步发电机的SCC服务采购，但现有定价方法在处理机组组合整数约束时存在局限性。

Method: 采用原始-对偶公式的SCC约束调度方法，保留了机组组合的二元性质，同时有效计算SCC服务的影子价格。

Result: 在改进的IEEE 30节点系统中与现有定价方案比较，证明原始-对偶方法在保持机组组合整数性进行SCC定价方面的优势。

Conclusion: 所提出的原始-对偶方法能够克服现有SCC定价方法的缺陷，提供更准确和可解释的短路电流服务价格。

Abstract: Synchronous Generators (SGs) currently provide important levels of
Short-Circuit Current (SCC), a critical ancillary service that ensures line
protections trip during short-circuit faults. Given the ongoing replacement of
SGs by power-electronics-based generation, which have a hard limit for current
injection, it has become relevant to optimize the procurement of SCC provided
by remaining SGs. Pricing this service is however challenging due to the
integrality constraints in Unit Commitment (UC). Existing methods, e.g.,
dispatchable pricing, restricted pricing and marginal unit pricing, attempt to
address this issue but exhibit limitations in handling binary variables,
resulting in SCC prices that either fail to cover the operating costs of units
or lack interpretability. To overcome these pitfalls, we propose a primal-dual
formulation of the SCC-constrained dispatch that preserves the binary nature of
UC while effectively computing shadow prices of SCC services. Using a modified
IEEE 30-bus system, a comparison is carried out between the proposed approach
and the state-of-the-art pricing schemes, highlighting the advantages of the
primal-dual method in preserving UC integrality for SCC pricing.

</details>


### [100] [Robust Sensor Placement for Poisson Arrivals with False Alarm Aware Spatiotemporal Sensing](https://arxiv.org/abs/2510.05343)
*Mingyu Kim,Pronoy Sarker,Seungmo Kim,Daniel J. Stilwell,Jorge Jimenez*

Main category: eess.SY

TL;DR: 研究了在检测性能因环境因素随机变化且存在虚警的情况下，使用滤波器来减弱影响的传感器布局问题。提出了一个统一模型，通过可用性函数耦合检测和虚警，并给出了滤波器改善检测的充分条件。


<details>
  <summary>Details</summary>
Motivation: 在动态不确定环境中，传感器检测性能会因空间和时间的随机环境因素而变化，同时存在虚警问题。需要开发理论框架来指导传感器部署，确保在滤波处理下的检测性能。

Method: 引入统一模型，通过可用性函数耦合检测和虚警，建立覆盖概率下界，并证明当检测概率从有限数据学习时的鲁棒性保证。使用AIS船舶交通数据和合成海事场景进行数值验证。

Result: 给出了滤波器改善检测的充分条件，推导了覆盖概率下界，证明了性能在检测概率从有限数据学习时的稳定性。数值研究验证了方法的有效性。

Conclusion: 该研究为在动态不确定环境中部署传感器提供了理论和实践指导，特别是在存在随机环境变化和虚警的情况下，通过滤波处理可以改善检测性能。

Abstract: This paper studies sensor placement when detection performance varies
stochastically due to environmental factors over space and time and false
alarms are present, but a filter is used to attenuate the effect. We introduce
a unified model that couples detection and false alarms through an availability
function, which captures how false alarms reduce effective sensing and
filtering responses to the disturbance. Building on this model, we give a
sufficient condition under which filtering improves detection. In addition, we
derive a coverage-based lower bound on the void probability. Furthermore, we
prove robustness guarantees showing that performance remains stable when
detection probabilities are learned from limited data. We validate the approach
with numerical studies using AIS vessel-traffic data and synthetic maritime
scenarios. Together, these results provide theory and practical guidance for
deploying sensors in dynamic, uncertain environments.

</details>


### [101] [Koopman Control Factorization: Data-Driven Convex Controller Design for a Class of Nonlinear Systems](https://arxiv.org/abs/2510.05359)
*Taha Ondogan,Ran Jing,Andrew P. Sabelhaus,Roberto Tron*

Main category: eess.SY

TL;DR: 提出Koopman控制分解方法，将控制仿射系统与基于非线性测量的反馈控制器参数化，使闭环系统的Koopman算子成为系统矩阵和控制器矩阵的双线性组合，通过半定规划计算反馈矩阵，实现非线性系统的稳定控制。


<details>
  <summary>Details</summary>
Motivation: 虽然Koopman算子为自治系统提供了全局线性化，但非自治系统在输入上不是全局线性的，状态反馈控制器设计在典型表述中仍然是非凸的，即使通过双线性控制仿射项进行近似。

Method: 引入Koopman控制分解，将控制仿射动力系统与基于非线性测量线性组合的反馈控制器参数化，提出充分条件保证分解成立，通过半定规划算法计算反馈矩阵。

Result: 在两个典型控制仿射非线性系统（倒立摆）上评估，在适当选择的基函数下，所提出的分解和控制器成功稳定了两个系统。

Conclusion: 该方法为非线性系统稳定控制提供了一种广泛通用的控制综合方法，计算快速、可验证稳定、数据驱动且不依赖近似。

Abstract: Although Koopman operators provide a global linearization for autonomous
dynamical systems, nonautonomous systems are not globally linear in the inputs.
State (or output) feedback controller design therefore remains nonconvex in
typical formulations, even with approximations via bilinear control-affine
terms. We address this gap by introducing the Koopman Control Factorization, a
novel parameterization of control-affine dynamical systems combined with a
feedback controller defined as a linear combination of nonlinear measurements.
With this choice, the Koopman operator of the closed-loop system is a bilinear
combination of the coefficients in two matrices: one representing the system,
and the other the controller. We propose a set of sufficient conditions such
that the factorization holds. Then, we present an algorithm that calculates the
feedback matrix via semi-definite programming, producing a Lyapunov-stable
closed-loop system with convex optimization. We evaluate the proposed
controllers on two canonical examples of control-affine nonlinear systems
(inverted pendulums), and show that our factorization and controller
successfully stabilize both under properly-chosen basis functions. This
manuscript introduces a broadly generalizable control synthesis method for
stabilization of nonlinear systems that is quick-to-compute, verifiably stable,
data-driven, and does not rely on approximations.

</details>


### [102] [Digital Twins for Intelligent Intersections: A Literature Review](https://arxiv.org/abs/2510.05374)
*Alben Rome Bagabaldo,Jürgen Hackl*

Main category: eess.SY

TL;DR: 这篇文献综述系统分析了数字孪生在智能交叉口的应用，将其分为五个主题领域：架构框架、数据处理与仿真、AI/ML自适应控制、弱势道路用户安全、以及从局部交叉口到城市路网的扩展。


<details>
  <summary>Details</summary>
Motivation: 智能交叉口在城市交通中至关重要，需要数字孪生等创新解决方案来提升安全性和效率。本文旨在系统梳理数字孪生在智能交叉口领域的集成与应用现状。

Method: 采用文献综述方法，将现有研究系统分类为五个关键主题领域，并对每个主题进行全面探索，突出重要进展、当前挑战和关键见解。

Result: 研究发现多层数字孪生架构结合实时数据融合和AI驱动决策能显著提升交通效率和安全性。先进仿真技术与复杂AI/ML算法相结合，在实时响应性和交通管理预测准确性方面表现出显著改进。

Conclusion: 数字孪生集成在通过主动自适应安全策略保护弱势道路用户方面展现出巨大潜力。然而，关键挑战仍然存在，包括异构数据源的互操作性、大规模交通网络的可扩展性以及动态城市环境中的不确定性管理。

Abstract: Intelligent intersections play a pivotal role in urban mobility, demanding
innovative solutions such as digital twins to enhance safety and efficiency.
This literature review investigates the integration and application of digital
twins for intelligent intersections, a critical area within smart urban traffic
systems. The review systematically categorizes existing research into five key
thematic areas: (i) Digital Twin Architectures and Frameworks; (ii) Data
Processing and Simulation Techniques; (iii) Artificial Intelligence and Machine
Learning for Adaptive Traffic Control; (iv) Safety and Protection of Vulnerable
Road Users; and (v) Scaling from Localized Intersections to Citywide Traffic
Networks. Each theme is explored comprehensively, highlighting significant
advancements, current challenges, and critical insights. The findings reveal
that multi-layered digital twin architectures incorporating real-time data
fusion and AI-driven decision-making enhances traffic efficiency and safety.
Advanced simulation techniques combined with sophisticated AI/ML algorithms
demonstrate notable improvements in real-time responsiveness and predictive
accuracy for traffic management. Additionally, the integration of digital twins
has shown substantial promise in safeguarding vulnerable road users through
proactive and adaptive safety strategies. Despite these advancements, key
challenges persist, including interoperability of diverse data sources,
scalability of digital twins for extensive traffic networks, and managing
uncertainty within dynamic urban environments. Addressing these challenges will
be essential for the future development and deployment of intelligent,
adaptive, and sustainable intersection management systems.

</details>


### [103] [Safety-Critical Control with Bounded Inputs: A Closed-Form Solution for Backup Control Barrier Functions](https://arxiv.org/abs/2510.05436)
*David E. J. van Wijk,Ersin Das,Tamas G. Molnar,Aaron D. Ames,Joel W. Burdick*

Main category: eess.SY

TL;DR: 提出一种在计算受限系统中保证控制器安全性的方法，通过最优插值在名义控制器和备份控制器之间，提供闭式解以避免实时求解高维二次规划问题。


<details>
  <summary>Details</summary>
Motivation: 备份控制屏障函数(bCBFs)虽然能保证控制器安全性，但需要实时求解高维二次规划，对计算受限系统(如航空航天器)来说代价过高。

Method: 提出最优插值方法，在名义控制器和备份控制器之间进行插值，并推导出该优化问题的闭式解。

Result: 证明了该闭式控制器在保证安全性的同时能够遵守输入边界约束，并在双积分器和非线性固定翼飞机示例中验证了有效性。

Conclusion: 该方法为计算受限系统提供了一种高效的安全控制器验证方案，避免了实时求解复杂优化问题。

Abstract: Verifying the safety of controllers is critical for many applications, but is
especially challenging for systems with bounded inputs. Backup control barrier
functions (bCBFs) offer a structured approach to synthesizing safe controllers
that are guaranteed to satisfy input bounds by leveraging the knowledge of a
backup controller. While powerful, bCBFs require solving a high-dimensional
quadratic program at run-time, which may be too costly for
computationally-constrained systems such as aerospace vehicles. We propose an
approach that optimally interpolates between a nominal controller and the
backup controller, and we derive the solution to this optimization problem in
closed form. We prove that this closed-form controller is guaranteed to be safe
while obeying input bounds. We demonstrate the effectiveness of the approach on
a double integrator and a nonlinear fixed-wing aircraft example.

</details>


### [104] [Operational Risks in Grid Integration of Large Data Center Loads: Characteristics, Stability Assessments, and Sensitivity Studies](https://arxiv.org/abs/2510.05437)
*Kyung-Bin Kwon,Sayak Mukherjee,Veronica Adetola*

Main category: eess.SY

TL;DR: 该论文研究大型数据中心与电网的动态交互，重点关注由需求突然波动引起的可靠性挑战，并提出实时电网稳定性评估方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI驱动工作负载的快速增长，数据中心需求的突然波动和快速爬坡模式预计会加剧电网压力和不稳定性，需要开发实时评估方法来确保可靠集成。

Method: 使用MIT超云数据集的开源AI数据中心消费配置文件，开发非线性暂态稳定性和小信号稳定性的分析评估方法，包括计算局部总线动能流和构建状态矩阵。

Result: 在改进的IEEE 68总线基准模型中进行的研究表明，该方法能够量化大型数据中心集群的稳定性影响，提高运营商对电网风险的情境感知能力。

Conclusion: 所提出的实时稳定性评估方法能够有效捕捉大型数据中心负载可靠集成过程中的风险，为电网运营商提供增强的可观测性。

Abstract: This paper investigates the dynamic interactions between large-scale data
centers and the power grid, focusing on reliability challenges arising from
sudden fluctuations in demand. With the rapid growth of AI-driven workloads,
such fluctuations, along with fast ramp patterns, are expected to exacerbate
stressed grid conditions and system instabilities. We consider a few
open-source AI data center consumption profiles from the MIT supercloud
datasets, along with generating a few experimental HPC job-distribution-based
inference profiles. Subsequently, we develop analytical methodologies for
real-time assessment of grid stability, focusing on both transient and
small-signal stability assessments. Energy-flow-like metrics for nonlinear
transient stability, formulated by computing localized data center bus
kinetic-like flows and coupling interactions with neighboring buses over
varying time windows, help provide operators a real-time assessments of the
regional grid stress in the data center hubs. On the other hand, small-signal
stability metrics, constructed from analytical state matrices under variable
operating conditions during a fast ramping period, enable snapshot-based
assessments of data center load fluctuations, provide enhanced observability
into evolving grid conditions. By quantifying the stability impacts of large
data center clusters, studies conducted in the modified IEEE benchmark $68-$bus
model support improved operator situational awareness to capture risks in
reliable integration of large data center loads.

</details>


### [105] [A Predictive and Sampled-Data Barrier Method for Safe and Efficient Quadrotor Control](https://arxiv.org/abs/2510.05456)
*Ming Gao,Zhanglin Shangguan,Shuo Liu,Liang Wu,Bo Yang,Wei Xiao*

Main category: eess.SY

TL;DR: 提出了一种具有形式化安全保证的四旋翼轨迹跟踪级联控制框架，通过外环位置MPC和内环非线性姿态控制实现位置安全与偏航方向的解耦，并采用采样数据高阶控制屏障函数保证安全性。


<details>
  <summary>Details</summary>
Motivation: 四旋翼的安全约束通常涉及高阶相对度，需要一种能够提供形式化安全保证的控制方法，同时保持实时实现的可行性。

Method: 设计级联控制器：外环位置模型预测控制(MPC)和内环非线性姿态控制；采用高阶控制屏障函数(HOCBFs)处理高阶安全约束；将HOCBFs扩展为采样数据HOCBFs(SdHOCBFs)，通过引入补偿项确保整个采样区间的安全性；将SdHOCBFs作为控制仿射约束嵌入MPC公式中。

Result: 所提出的方法在综合仿真中展示了安全保证和高效率，相比现有方法具有更好的性能。

Conclusion: 该框架能够同时保证安全性和最优性，同时保持凸性以实现实时实现，为四旋翼轨迹跟踪提供了形式化的安全保证。

Abstract: This paper proposes a cascaded control framework for quadrotor trajectory
tracking with formal safety guarantees. First, we design a controller
consisting of an outer-loop position model predictive control (MPC) and an
inner-loop nonlinear attitude control, enabling decoupling of position safety
and yaw orientation. Second, since quadrotor safety constraints often involve
high relative degree, we adopt high order control barrier functions (HOCBFs) to
guarantee safety. To employ HOCBFs in the MPC formulation that has formal
guarantees, we extend HOCBFs to sampled-data HOCBF (SdHOCBFs) by introducing
compensation terms, ensuring safety over the entire sampling interval. We show
that embedding SdHOCBFs as control-affine constraints into the MPC formulation
guarantees both safety and optimality while preserving convexity for real-time
implementations. Finally, comprehensive simulations are conducted to
demonstrate the safety guarantee and high efficiency of the proposed method
compared to existing methods.

</details>


### [106] [Sample-Efficient and Smooth Cross-Entropy Method Model Predictive Control Using Deterministic Samples](https://arxiv.org/abs/2510.05706)
*Markus Walker,Daniel Frisch,Uwe D. Hanebeck*

Main category: eess.SY

TL;DR: 提出确定性采样CEM(dsCEM)框架，用局部累积分布生成的确定性样本替代随机采样，在低样本量下显著提升控制性能和输入平滑度。


<details>
  <summary>Details</summary>
Motivation: 传统CEM-MPC依赖随机采样导致解空间探索效率低、控制输入不平滑，需要大量样本才能获得满意结果。

Method: 用局部累积分布(LCDs)生成确定性样本，引入模块化方案生成和调整样本集，结合时间相关性确保平滑控制轨迹。

Result: 在两个非线性控制任务上的实验表明，dsCEM在累积成本和控制输入平滑度方面持续优于最先进的iCEM，特别是在关键的低样本量情况下。

Conclusion: dsCEM可作为现有CEM控制器的即插即用替代方案，在保持性能的同时显著减少所需样本量。

Abstract: Cross-entropy method model predictive control (CEM--MPC) is a powerful
gradient-free technique for nonlinear optimal control, but its performance is
often limited by the reliance on random sampling. This conventional approach
can lead to inefficient exploration of the solution space and non-smooth
control inputs, requiring a large number of samples to achieve satisfactory
results. To address these limitations, we propose deterministic sampling CEM
(dsCEM), a novel framework that replaces the random sampling step with
deterministic samples derived from localized cumulative distributions (LCDs).
Our approach introduces modular schemes to generate and adapt these sample
sets, incorporating temporal correlations to ensure smooth control
trajectories. This method can be used as a drop-in replacement for the sampling
step in existing CEM-based controllers. Experimental evaluations on two
nonlinear control tasks demonstrate that dsCEM consistently outperforms
state-of-the-art iCEM in terms of cumulative cost and control input smoothness,
particularly in the critical low-sample regime.

</details>


### [107] [Safe Landing on Small Celestial Bodies with Gravitational Uncertainty Using Disturbance Estimation and Control Barrier Functions](https://arxiv.org/abs/2510.05895)
*Felipe Arenas-Uribe,T. Michael Seigler,Jesse B. Hoagg*

Main category: eess.SY

TL;DR: 提出了一种结合轨迹跟踪、扰动估计和安全约束的控制器，用于小天体软着陆任务，确保在不确定环境下安全执行机动。


<details>
  <summary>Details</summary>
Motivation: 现有控制方法缺乏对安全约束的正式保证，而小天体软着陆面临引力模型不确定性和动态环境挑战，需要高自主性。

Method: 使用扩展高增益观测器估计引力扰动，采用反馈线性化和扰动消除控制器实现指数跟踪，结合控制障碍函数的最小干预控制器强制执行状态和输入约束。

Result: 数值模拟显示控制器能够实现精确安全的软着陆，在燃料最优轨迹下有效执行激进机动而不牺牲安全性。

Conclusion: 该控制器将轨迹跟踪与安全保证相结合，为自主小天体任务提供了有前景的解决方案。

Abstract: Soft landing on small celestial bodies (SCBs) poses unique challenges, as
uncertainties in gravitational models and poorly characterized, dynamic
environments require a high level of autonomy. Existing control approaches lack
formal guarantees for safety constraint satisfaction, necessary to ensure the
safe execution of the maneuvers. This paper introduces a control that addresses
this limitation by integrating trajectory tracking, disturbance estimation, and
safety enforcement. An extended high-gain observer is employed to estimate
disturbances resulting from gravitational model uncertainties. We then apply a
feedback-linearizing and disturbance-canceling controller that achieves
exponential tracking of reference trajectories. Finally, we use a control
barrier function based minimum-intervention controller to enforce state and
input constraints through out the maneuver execution. This control combines
trajectory tracking of offline generated reference trajectories with formal
guarantees of safety, which follows common guidance and control architectures
for spacecraft and allows aggressive maneuvers to be executed without
compromising safety. Numerical simulations using fuel-optimal trajectories
demonstrate the effectiveness of the controller in achieving precise and safe
soft-landing, highlighting its potential for autonomous SCB missions.

</details>


### [108] [Distributed Platoon Control Under Quantization: Stability Analysis and Privacy Preservation](https://arxiv.org/abs/2510.05959)
*Kaixiang Zhang,Zhaojian Li,Wei Lin*

Main category: eess.SY

TL;DR: 本文研究了分布式车队控制中的稳定性和隐私保护特性，比较了确定性和概率性量化器的性能差异。


<details>
  <summary>Details</summary>
Motivation: 分布式车辆控制需要共享隐私敏感的车辆数据，这带来了信息泄露和恶意活动的风险，因此需要研究如何在保证控制性能的同时保护隐私。

Method: 采用两种量化器（确定性和概率性）来分析分布式车队控制的稳定性和隐私保护特性，并构建优化问题来量化控制性能与隐私之间的权衡。

Result: 确定性量化器能确保系统误差一致最终有界，且无辅助信息时窃听者无法唯一推断敏感状态；概率性量化器能使车队在期望中渐近收敛，且满足差分隐私保证。

Conclusion: 概率性量化器在隐私保护方面表现更优，能够提供差分隐私保证，而确定性量化器在控制稳定性方面有优势，两种方法在控制性能和隐私保护之间存在权衡关系。

Abstract: Distributed control of connected and automated vehicles has attracted
considerable interest for its potential to improve traffic efficiency and
safety. However, such control schemes require sharing privacy-sensitive vehicle
data, which introduces risks of information leakage and potential malicious
activities. This paper investigates the stability and privacy-preserving
properties of distributed platoon control under two types of quantizers:
deterministic and probabilistic. For deterministic quantization, we show that
the resulting control strategy ensures the system errors remain uniformly
ultimately bounded. Moreover, in the absence of auxiliary information, an
eavesdropper cannot uniquely infer sensitive vehicle states. In contrast, the
use of probabilistic quantization enables asymptotic convergence of the vehicle
platoon in expectation with bounded variance. Importantly, probabilistic
quantizers can satisfy differential privacy guarantees, thereby preserving
privacy even when the eavesdropper possesses arbitrary auxiliary information.
We further analyze the trade-off between control performance and privacy by
formulating an optimization problem that characterizes the impact of the
quantization step on both metrics. Numerical simulations are provided to
illustrate the performance differences between the two quantization strategies.

</details>


### [109] [Optimal Batched Scheduling of Stochastic Processing Networks Using Atomic Action Decomposition](https://arxiv.org/abs/2510.06033)
*Jim Dai,Manxi Wu,Zhanhao Zhang*

Main category: eess.SY

TL;DR: 提出原子动作分解框架，将联合服务器分配分解为顺序单服务器分配，解决随机处理网络控制中策略维度随服务器数量指数增长的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 随机处理网络控制中，联合分配策略的维度随服务器数量指数增长，使得标准强化学习和策略优化方法在大规模场景下难以处理。

Method: 原子动作分解框架，将联合分配分解为顺序单服务器分配，研究步长依赖和步长独立两类原子策略。

Result: 证明两类原子策略都能达到与原联合策略相同的最优长期平均奖励，实现无最优性损失的可扩展计算。

Conclusion: 原子框架为大规模随机处理网络控制提供了理论依据，证实了先前研究中该框架在大型应用中的成功经验。

Abstract: Stochastic processing networks (SPNs) have broad applications in healthcare,
transportation, and communication networks. The control of SPN is to
dynamically assign servers in batches under uncertainty to optimize long-run
performance. This problem is challenging as the policy dimension grows
exponentially with the number of servers, making standard reinforcement
learning and policy optimization methods intractable at scale. We propose an
atomic action decomposition framework that addresses this scalability challenge
by breaking joint assignments into sequential single-server assignments. This
yields policies with constant dimension, independent of the number of servers.
We study two classes of atomic policies, the step-dependent and
step-independent atomic policies, and prove that both achieve the same optimal
long-run average reward as the original joint policies. These results establish
that computing the optimal SPN control can be made scalable without loss of
optimality using the atomic framework. Our results offer theoretical
justification for the strong empirical success of the atomic framework in
large-scale applications reported in previous articles.

</details>


### [110] [Toward Model Matching for Remotely Controlled Differential Drive Robotic Vehicles](https://arxiv.org/abs/2510.06081)
*Nikolaos D. Kouvakas,Fotis N. Koumboulis,Konstantinos G. Tzierakis,John Sigalas,Anastasios Dimakakos*

Main category: eess.SY

TL;DR: 提出了一种针对具有执行器动态和网络延迟的差速驱动机器人方向角控制的三层非线性控制方案，通过延迟依赖的动态输出反馈控制器实现精确模型匹配。


<details>
  <summary>Details</summary>
Motivation: 解决远程控制差速驱动机器人在存在执行器动态和网络诱导延迟时的方向角调节问题，为延迟机器人系统提供基于解析设计的替代AI调优方案。

Method: 在已有的两层非线性控制方案基础上，引入第三层延迟依赖控制器，采用动态可测量输出反馈控制器和动态预补偿器，通过参数化获得具有稳定性约束的简单特征拟多项式。

Result: 计算实验证实了精确跟踪、快速稳定以及有界内部信号和控制电压的性能。

Conclusion: 该方法为延迟机器人系统提供了一种解析设计替代方案，避免了基于AI的调优需求。

Abstract: The problem of regulation of the orientation angle of a remotely controlled
differential-drive mobile robot with actuator dynamics and network-induced
delays is studied. Using a preinstalled two-layer nonlinear control scheme that
decouples linear and angular velocities and regulates heading, a third,
delay-dependent layer that achieves exact model matching from the orientation
angle command to the orientation angle is introduced. The proposed outer loop
controller is a delay dependent dynamic measurable output-feedback controller
with dynamic proper precompensator. Parameterization yields a simple
characteristic quasi-polynomial with coefficients constrained to satisfy
stability for all delays up to a computable bound. Computational experiments
confirm accurate tracking, fast settling and bounded internal signals and
control voltages. The approach offers an analytic design alternative to
AI-based tuning for delayed robotic systems.

</details>


### [111] [Multi-Segment Photonic Power Converters for Energy Harvesting and High-Speed Optical Wireless Communication](https://arxiv.org/abs/2510.06205)
*Othman Younus,Behnaz Majlesein,Richard Nacke,Isaac N. O. Osahon,Carmine Pellegrino,Sina Babadi,Iman Tavakkolnia,Henning Helmers,Harald Haas*

Main category: eess.SY

TL;DR: 该论文提出并测试了多段GaAs基PPC，作为能量收集器和数据探测器，通过将有效区域分割成2、4或6个子电池来减少电容并提高带宽，同时保持光收集能力。在1.5米光学无线链路中实现了3.8Gbps的世界纪录数据速率，是先前工作的四倍。


<details>
  <summary>Details</summary>
Motivation: 对节能高速无线通信的需求以及物联网设备的快速增长，需要将能量收集与光学数据接收相结合的系统，以消除充电或更换电池的需求。

Method: 提出多段GaAs基PPC，将有效区域分割成2、4或6个子电池，形成直径1、1.5或2.08mm的圆形区域。在半绝缘GaAs衬底上制造，通过蚀刻沟槽实现电隔离，串联连接的子电池优化吸收并最小化寄生效应。使用OFDM与自适应比特和功率加载进行1.5米光学无线链路。

Result: 系统实现了3.8Gbps的世界纪录数据速率，是先前工作的四倍。系统将2.3mW光束中39.7%的光功率转换为电能，尽管分割增加了对准的敏感性。

Conclusion: 这些发现为未来通信网络（如6G蜂窝）的离网回程提供了新的解决方案。

Abstract: The demand for energy-efficient high-speed wireless communication, coupled
with the rapid rise of IoT devices, requires systems that integrate power
harvesting with optical data reception to eliminate the need for charging or
battery replacements. Recent advances have explored the use of solar cells as
optical receivers for high-speed data detection alongside power harvesting.
\acs{GaAs}-based \acp{PPC} provide six times greater electron mobility than
silicon- or cadmium telluride-based cells, enabling faster data detection and
improved power efficiency. However, their bandwidth is constrained by junction
capacitance, which increases with active area, creating a trade-off between
power output and data rate. To address this, we propose and test multi-segment
\acs{GaAs}-based \Acp{PPC} that serve as both energy harvesters and data
detectors. By segmenting the active area into 2, 4, or 6 subcells, forming
circular areas with diameters of 1, 1.5, or 2.08~mm, we reduce capacitance and
boost bandwidth while preserving light collection. Fabricated on a
semi-insulating \ac{GaAs} substrate with etched trenches for electrical
isolation, the series-connected subcells optimize absorption and minimize
parasitic effects. The \Acp{PPC} were used for an eye-safe 1.5~m optical
wireless link, employing \ac{OFDM} with adaptive bit and power loading. The
system achieved a world record data rate of 3.8~Gbps, which is four times
higher than prior works. The system converts 39.7\% of optical power from a
beam of 2.3~mW, although the segmentation increases the sensitivity of the
alignment. These findings provide new solutions for off-grid backhaul for
future communication networks, such as 6th generation (6G) cellular.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [112] [Geographically Weighted Regression for Air Quality Low-Cost Sensor Calibration](https://arxiv.org/abs/2510.05646)
*Jean-Michel Poggi,Bruno Portier,Emma Thulliez*

Main category: stat.AP

TL;DR: 使用地理加权回归(GWR)方法校准空气质量低成本传感器的NO2测量数据，基于安特卫普的SensEURCity数据集进行验证。


<details>
  <summary>Details</summary>
Motivation: 低成本传感器在城市尺度高分辨率空气质量监测中具有重要价值，但需要通过与参考分析仪进行校准来提高数据准确性。

Method: 采用地理加权回归(GWR)方法对34个微传感器和9个参考站的数据进行校准，分析估计系数的空间分布特征。

Result: 提供了NO2的校准结果，并对GWR模型的估计系数及其空间内容进行了详细分析。

Conclusion: GWR方法能够有效校准低成本空气质量传感器的测量数据，为城市尺度空气质量监测提供可靠的技术支持。

Abstract: This article focuses on the use of Geographically Weighted Regression (GWR)
method to correct air quality low-cost sensors measurements. Those sensors are
of major interest in the current era of high-resolution air quality monitoring
at urban scale, but require calibration using reference analyzers. The results
for NO2 are provided along with comments on the estimated GWR model and the
spatial content of the estimated coefficients. The study has been carried out
using the publicly available SensEURCity dataset in Antwerp, which is
especially relevant since it includes 9 reference stations and 34 micro-sensors
collocated and deployed within the city.

</details>


### [113] [Copula-Based Clustering of Financial Time Series via Evidence Accumulation](https://arxiv.org/abs/2510.05960)
*Andrea Mecchina,Roberta Pappadà,Nicola Torelli*

Main category: stat.AP

TL;DR: 提出一种基于多重copula相异度量的聚类方法，用于资产依赖结构分析，帮助风险厌恶投资者构建风险分散投资组合。


<details>
  <summary>Details</summary>
Motivation: 理解资产收益的依赖结构对风险评估至关重要，特别是在投资组合分散策略中需要识别在风险情景下具有相似随机行为的资产。

Method: 使用经典层次聚类程序结合多种copula基相异度量，通过多重分类积累证据进行资产聚类。

Result: 同一聚类中的资产在风险情景下表现出相似的随机行为，该方法在EURO STOXX 50指数数据上进行了实证演示。

Conclusion: 风险厌恶投资者可以利用聚类信息构建风险分散的投资组合，该方法为投资组合多样化策略提供了有效工具。

Abstract: Understanding the dependence structure of asset returns is fundamental in
risk assessment and is particularly relevant in a portfolio diversification
strategy. We propose a clustering approach where evidence accumulated in a
multiplicity of classifications is achieved using classical hierarchical
procedures and multiple copula-based dissimilarity measures. Assets that are
grouped in the same cluster are such that their stochastic behavior is similar
during risky scenarios, and riskaverse investors could exploit this information
to build a risk-diversified portfolio. An empirical demonstration of such a
strategy is presented by using data from the EURO STOXX 50 index.

</details>


### [114] [Measuring Data Quality for Project Lighthouse](https://arxiv.org/abs/2510.06121)
*Adam Bloomston,Elizabeth Burke,Megan Cacace,Anne Diaz,Wren Dougherty,Matthew Gonzalez,Remington Gregg,Yeliz Güngör,Bryce Hayes,Eeway Hsu,Oron Israeli,Heesoo Kim,Sara Kwasnick,Joanne Lacsina,Demma Rosa Rodriguez,Adam Schiller,Whitney Schumacher,Jessica Simon,Maggie Tang,Skyler Wharton,Marilyn Wilcken*

Main category: stat.AP

TL;DR: 提出基于机器学习分类的框架，用于实证论证数据质量指标及其阈值的选择，实现定量数据最小化原则


<details>
  <summary>Details</summary>
Motivation: 在Project Lighthouse项目中测量数据质量面临挑战，需要在更广泛的学术背景下解决这些问题

Method: 使用三个核心数据质量指标进行测量，其中两个扩展了先前学术工作；提出基于机器学习分类的框架来实证论证指标选择和阈值设定

Result: 开发的方法能够严谨地满足数据最小化原则，在分析Project Lighthouse中的潜在体验差距时实现定量数据最小化

Conclusion: 提出的框架为选择数据质量指标和设定阈值提供了实证依据，支持在数据收集和分析中实现定量数据最小化

Abstract: In this paper, we first situate the challenges for measuring data quality
under Project Lighthouse in the broader academic context. We then discuss in
detail the three core data quality metrics we use for measurement--two of which
extend prior academic work. Using those data quality metrics as examples, we
propose a framework, based on machine learning classification, for empirically
justifying the choice of data quality metrics and their associated minimum
thresholds. Finally we outline how these methods enable us to rigorously meet
the principle of data minimization when analyzing potential experience gaps
under Project Lighthouse, which we term quantitative data minimization.

</details>


### [115] [Rapid calibration of atrial electrophysiology models using Gaussian process emulators in the ensemble Kalman filter](https://arxiv.org/abs/2510.06191)
*Mariya Mamajiwala,Cesare Corrado,Chris Lanyon,Steven A. Niederer,Richard D. Wilkinson,Richard H. Clayton*

Main category: stat.AP

TL;DR: 提出一种基于集成卡尔曼滤波的静态非线性逆问题求解方法，用于快速校准心房颤动患者的个性化电生理模型参数，实现近实时患者特异性校准。


<details>
  <summary>Details</summary>
Motivation: 心房颤动标准治疗导管消融具有侵入性和不可逆性，需要快速校准基于物理的患者特异性模型来指导临床决策。

Method: 将校准任务构建为静态逆问题，使用高斯过程模拟器替代昂贵的正向模型，并提出集成卡尔曼滤波的新变体用于静态非线性逆问题。

Result: 该方法能够生成可解释为后验分布最佳高斯近似的参数样本，与MCMC采样结果相当，支持近实时患者特异性校准。

Conclusion: 该方法是实现心房颤动治疗结果预测在临床时间尺度内的关键步骤，适用于科学和工程中的各种静态逆问题。

Abstract: Atrial fibrillation (AF) is a common cardiac arrhythmia characterised by
disordered electrical activity in the atria. The standard treatment is catheter
ablation, which is invasive and irreversible. Recent advances in computational
electrophysiology offer the potential for patient-specific models, often
referred to as digital twins, that can be used to guide clinical decisions. To
be of practical value, we must be able to rapidly calibrate physics-based
models using routine clinical measurements. We pose this calibration task as a
static inverse problem, where the goal is to infer tissue-level
electrophysiological parameters from the available observations. To make this
tractable, we replace the expensive forward model with Gaussian process
emulators (GPEs), and propose a novel adaptation of the ensemble Kalman filter
(EnKF) for static non-linear inverse problems. The approach yields parameter
samples that can be interpreted as coming from the best Gaussian approximation
of the posterior distribution. We compare our results with those obtained using
Markov chain Monte Carlo (MCMC) sampling and demonstrate the potential of the
approach to enable near-real-time patient-specific calibration, a key step
towards predicting outcomes of AF treatment within clinical timescales. The
approach is readily applicable to a wide range of static inverse problems in
science and engineering.

</details>


### [116] [Geographical inequalities in mortality by age and gender in Italy, 2002-2019: insights from a spatial extension of the Lee-Carter model](https://arxiv.org/abs/2510.06210)
*Francesca Fiori,Andrea Riebler,Sara Martino*

Main category: stat.AP

TL;DR: 本文分析了意大利107个省份2002-2019年的死亡率数据，发现尽管全国死亡率总体改善，但地区不平等正在加剧，特别是中南部和西北部地区死亡率较高，且这种地理差异自2010年以来不断扩大。


<details>
  <summary>Details</summary>
Motivation: 尽管意大利是发达国家中死亡率较低的国家，但近期证据表明死亡率改善速度放缓，地区不平等加剧。本研究旨在提供新的实证证据，分析意大利各省份的死亡率空间分布和变化趋势。

Method: 扩展了广泛使用的Lee Carter模型，纳入空间变化的年龄特定效应，捕捉空间-年龄-时间交互作用。在贝叶斯框架下使用inlabru包进行估计，基于INLA方法，利用平滑先验来减少小区域死亡计数的随机波动。

Result: 结果显示意大利存在不均衡的死亡率地理分布。中南部和西北部地区死亡率较高，而中北部和东北部表现相对较好。自2010年以来，这些地理差异不断扩大，男性在较年轻成年期、女性在较年长成年期表现出更明显的模式。

Conclusion: 这种细粒度方法有助于揭示意大利各省份的死亡率差异。未来的工作可以进一步分析死因或社会经济状况的死亡率，为制定更有针对性的公共卫生政策提供依据，以解决意大利各省份的死亡率不平等问题。

Abstract: Italy reports some of the lowest levels of mortality in the developed world.
Recent evidence, however, suggests that even in low mortality countries
improvements may be slowing and regional inequalities widening. This study
contributes new empirical evidence to the debate by analysing mortality data by
single year of age for males and females across 107 provinces in Italy from
2002 to 2019. We extend the widely used Lee Carter model to include spatially
varying age specific effects, and further specify it to capture space age time
interactions. The model is estimated in a Bayesian framework using the inlabru
package, which builds on INLA (Integrated Nested Laplace Approximation) for non
linear models and facilitates the use of smoothing priors. This approach
borrows strength across provinces and years, mitigating random fluctuations in
small area death counts. Results demonstrate the value of such a granular
approach, highlighting the existence of an uneven geography of mortality
despite overall national improvements. Mortality disadvantage is concentrated
in parts of the Centre South and North West, while the Centre North and North
East fare relatively better. These geographical differences have widened since
2010, with clear age and gender specific patterns, being more pronounced at
younger adult ages for men and at older adult ages for women. Future work may
involve refining the analysis to mortality by cause of death or socioeconomic
status, informing more targeted public health policies to address mortality
disparities across Italy's provinces.

</details>
