{"id": "2510.07906", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.07906", "abs": "https://arxiv.org/abs/2510.07906", "authors": ["Wanying Huang", "J. Jude Kline", "Priscilla Man"], "title": "Correlated Perfect Equilibrium", "comment": null, "summary": "We propose a refinement of correlated equilibrium based on mediator errors,\ncalled correlated perfect equilibrium (CPE). In finite games, the set of CPE is\nnonempty and forms a finite union of convex sets. Like perfect equilibrium, a\nCPE never assigns positive probability to any weakly dominated strategy. We\nprovide a dual representation of CPE and demonstrate how it differs from two\nexisting refinements of correlated equilibrium--acceptable correlated\nequilibrium (Myerson, 1986) and perfect direct correlated equilibrium\n(Dhillon-Mertens, 1996)--through examples.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8c03\u89e3\u8005\u9519\u8bef\u7684\u5173\u8054\u5747\u8861\u7cbe\u70bc\u65b9\u6cd5\u2014\u2014\u5173\u8054\u5b8c\u7f8e\u5747\u8861(CPE)\uff0c\u5728\u6709\u9650\u535a\u5f08\u4e2d\u975e\u7a7a\u4e14\u4e3a\u6709\u9650\u4e2a\u51f8\u96c6\u7684\u5e76\u96c6\uff0c\u4e0e\u5b8c\u7f8e\u5747\u8861\u7c7b\u4f3c\uff0cCPE\u4e0d\u4f1a\u7ed9\u5f31\u52a3\u7b56\u7565\u5206\u914d\u6b63\u6982\u7387\u3002", "motivation": "\u73b0\u6709\u5173\u8054\u5747\u8861\u7cbe\u70bc\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u63d0\u51fa\u65b0\u7684\u7cbe\u70bc\u6982\u5ff5\u6765\u66f4\u597d\u5730\u5904\u7406\u535a\u5f08\u4e2d\u7684\u7b56\u7565\u9009\u62e9\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u8c03\u89e3\u8005\u9519\u8bef\u7684\u6982\u5ff5\u6765\u7cbe\u70bc\u5173\u8054\u5747\u8861\uff0c\u63d0\u4f9bCPE\u7684\u53cc\u91cd\u8868\u793a\uff0c\u5e76\u4e0eMyerson\u7684\u53ef\u63a5\u53d7\u5173\u8054\u5747\u8861\u53caDhillon-Mertens\u7684\u5b8c\u7f8e\u76f4\u63a5\u5173\u8054\u5747\u8861\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u6709\u9650\u535a\u5f08\u4e2dCPE\u96c6\u5408\u975e\u7a7a\u4e14\u4e3a\u6709\u9650\u4e2a\u51f8\u96c6\u7684\u5e76\u96c6\uff0cCPE\u4e0d\u4f1a\u9009\u62e9\u5f31\u52a3\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u5c55\u793a\u4e86CPE\u4e0e\u73b0\u6709\u7cbe\u70bc\u65b9\u6cd5\u7684\u5dee\u5f02\u3002", "conclusion": "CPE\u4e3a\u5173\u8054\u5747\u8861\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u7cbe\u70bc\u65b9\u6cd5\uff0c\u5177\u6709\u7406\u8bba\u4e0a\u7684\u826f\u597d\u6027\u8d28\uff0c\u5e76\u80fd\u66f4\u597d\u5730\u5904\u7406\u535a\u5f08\u4e2d\u7684\u7b56\u7565\u9009\u62e9\u95ee\u9898\u3002"}}
{"id": "2510.07994", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.07994", "abs": "https://arxiv.org/abs/2510.07994", "authors": ["Nathan Hancart"], "title": "The (No) Value of Commitment", "comment": null, "summary": "I provide a sufficient condition under which a principal does not benefit\nfrom committing to a mechanism in economic models represented by a maximisation\nproblem under constraints. These problems include mechanism design,\nprincipal-agent models or sender-receiver games. In principal-agent problems,\nthis condition holds if the agent has a finite strategy space and the\nprincipal's value function is continuous in the mechanism.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5145\u5206\u6761\u4ef6\uff0c\u8bf4\u660e\u5728\u4f55\u79cd\u60c5\u51b5\u4e0b\u59d4\u6258\u4eba\u5728\u7ecf\u6d4e\u6a21\u578b\u4e2d\u4e0d\u4f1a\u4ece\u673a\u5236\u627f\u8bfa\u4e2d\u83b7\u76ca\uff0c\u9002\u7528\u4e8e\u673a\u5236\u8bbe\u8ba1\u3001\u59d4\u6258-\u4ee3\u7406\u6a21\u578b\u548c\u53d1\u9001\u8005-\u63a5\u6536\u8005\u535a\u5f08\u3002", "motivation": "\u7814\u7a76\u5728\u7ea6\u675f\u6700\u5927\u5316\u95ee\u9898\u8868\u793a\u7684\u7ecf\u6d4e\u6a21\u578b\u4e2d\uff0c\u59d4\u6258\u4eba\u4f55\u65f6\u4e0d\u4f1a\u4ece\u673a\u5236\u627f\u8bfa\u4e2d\u83b7\u76ca\uff0c\u4e3a\u673a\u5236\u8bbe\u8ba1\u7406\u8bba\u63d0\u4f9b\u65b0\u7684\u7406\u8bba\u6d1e\u89c1\u3002", "method": "\u901a\u8fc7\u5206\u6790\u7ecf\u6d4e\u6a21\u578b\u4e2d\u7684\u7ea6\u675f\u6700\u5927\u5316\u95ee\u9898\uff0c\u63a8\u5bfc\u51fa\u4e00\u4e2a\u5145\u5206\u6761\u4ef6\uff0c\u7279\u522b\u5173\u6ce8\u59d4\u6258-\u4ee3\u7406\u95ee\u9898\u4e2d\u4ee3\u7406\u4eba\u7684\u6709\u9650\u7b56\u7565\u7a7a\u95f4\u548c\u59d4\u6258\u4eba\u4ef7\u503c\u51fd\u6570\u7684\u8fde\u7eed\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5145\u5206\u6761\u4ef6\uff0c\u8868\u660e\u5f53\u4ee3\u7406\u4eba\u7b56\u7565\u7a7a\u95f4\u6709\u9650\u4e14\u59d4\u6258\u4eba\u4ef7\u503c\u51fd\u6570\u5728\u673a\u5236\u4e0a\u8fde\u7eed\u65f6\uff0c\u59d4\u6258\u4eba\u4e0d\u4f1a\u4ece\u673a\u5236\u627f\u8bfa\u4e2d\u83b7\u76ca\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u673a\u5236\u627f\u8bfa\u7684\u4ef7\u503c\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u7279\u522b\u662f\u5728\u59d4\u6258-\u4ee3\u7406\u95ee\u9898\u4e2d\uff0c\u5f53\u6ee1\u8db3\u7279\u5b9a\u6761\u4ef6\u65f6\uff0c\u673a\u5236\u627f\u8bfa\u4e0d\u4f1a\u5e26\u6765\u989d\u5916\u6536\u76ca\u3002"}}
{"id": "2510.08251", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.08251", "abs": "https://arxiv.org/abs/2510.08251", "authors": ["Maria Titova", "Kun Zhang"], "title": "Persuasion with Verifiable Information", "comment": null, "summary": "This paper studies a game in which an informed sender with state-independent\npreferences uses verifiable messages to convince a receiver to choose an action\nfrom a finite set. We characterize the equilibrium outcomes of the game and\ncompare them with commitment outcomes in information design. We provide\nconditions under which a commitment outcome is an equilibrium outcome and\nidentify environments in which the sender does not benefit from commitment\npower. Our findings offer insights into the interchangeability of verifiability\nand commitment in applied settings.", "AI": {"tldr": "\u7814\u7a76\u6709\u72b6\u6001\u72ec\u7acb\u504f\u597d\u7684\u77e5\u60c5\u53d1\u9001\u8005\u5982\u4f55\u901a\u8fc7\u53ef\u9a8c\u8bc1\u4fe1\u606f\u8bf4\u670d\u63a5\u6536\u8005\u9009\u62e9\u6709\u9650\u96c6\u5408\u4e2d\u7684\u884c\u52a8\uff0c\u6bd4\u8f83\u535a\u5f08\u5747\u8861\u7ed3\u679c\u4e0e\u4fe1\u606f\u8bbe\u8ba1\u4e2d\u7684\u627f\u8bfa\u7ed3\u679c\u3002", "motivation": "\u63a2\u8ba8\u5728\u53ef\u9a8c\u8bc1\u4fe1\u606f\u4f20\u9012\u7684\u535a\u5f08\u4e2d\uff0c\u53d1\u9001\u8005\u662f\u5426\u80fd\u591f\u901a\u8fc7\u627f\u8bfa\u83b7\u5f97\u4f18\u52bf\uff0c\u4ee5\u53ca\u53ef\u9a8c\u8bc1\u6027\u4e0e\u627f\u8bfa\u6743\u529b\u4e4b\u95f4\u7684\u53ef\u66ff\u4ee3\u6027\u3002", "method": "\u901a\u8fc7\u535a\u5f08\u8bba\u6a21\u578b\u5206\u6790\uff0c\u523b\u753b\u5747\u8861\u7ed3\u679c\uff0c\u5e76\u4e0e\u4fe1\u606f\u8bbe\u8ba1\u4e2d\u7684\u627f\u8bfa\u7ed3\u679c\u8fdb\u884c\u6bd4\u8f83\uff0c\u63d0\u4f9b\u6761\u4ef6\u5224\u65ad\u627f\u8bfa\u7ed3\u679c\u662f\u5426\u4e3a\u5747\u8861\u7ed3\u679c\u3002", "result": "\u786e\u5b9a\u4e86\u627f\u8bfa\u7ed3\u679c\u662f\u5747\u8861\u7ed3\u679c\u7684\u6761\u4ef6\uff0c\u8bc6\u522b\u4e86\u53d1\u9001\u8005\u65e0\u6cd5\u4ece\u627f\u8bfa\u6743\u529b\u4e2d\u83b7\u76ca\u7684\u73af\u5883\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u53ef\u9a8c\u8bc1\u6027\u4e0e\u627f\u8bfa\u5728\u5e94\u7528\u73af\u5883\u4e2d\u7684\u53ef\u66ff\u4ee3\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2510.08415", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.08415", "abs": "https://arxiv.org/abs/2510.08415", "authors": ["Leonardo N. Ferreira", "Haroon Mumtaz", "Ana Skoblar"], "title": "Stochastic Volatility-in-mean VARs with Time-Varying Skewness", "comment": null, "summary": "This paper introduces a Bayesian vector autoregression (BVAR) with stochastic\nvolatility-in-mean and time-varying skewness. Unlike previous approaches, the\nproposed model allows both volatility and skewness to directly affect\nmacroeconomic variables. We provide a Gibbs sampling algorithm for posterior\ninference and apply the model to quarterly data for the US and the UK.\nEmpirical results show that skewness shocks have economically significant\neffects on output, inflation and spreads, often exceeding the impact of\nvolatility shocks. In a pseudo-real-time forecasting exercise, the proposed\nmodel outperforms existing alternatives in many cases. Moreover, the model\nproduces sharper measures of tail risk, revealing that standard stochastic\nvolatility models tend to overstate uncertainty. These findings highlight the\nimportance of incorporating time-varying skewness for capturing macro-financial\nrisks and improving forecast performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u968f\u673a\u6ce2\u52a8\u7387\u5747\u503c\u6548\u5e94\u548c\u65f6\u53d8\u504f\u5ea6\u7684\u8d1d\u53f6\u65af\u5411\u91cf\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5141\u8bb8\u6ce2\u52a8\u7387\u548c\u504f\u5ea6\u76f4\u63a5\u5f71\u54cd\u5b8f\u89c2\u7ecf\u6d4e\u53d8\u91cf\uff0c\u5728\u5b9e\u8bc1\u5e94\u7528\u4e2d\u663e\u793a\u51fa\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u672a\u80fd\u5145\u5206\u8003\u8651\u6ce2\u52a8\u7387\u548c\u504f\u5ea6\u5bf9\u5b8f\u89c2\u7ecf\u6d4e\u53d8\u91cf\u7684\u76f4\u63a5\u5f71\u54cd\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u540c\u65f6\u6355\u6349\u8fd9\u4e24\u79cd\u98ce\u9669\u56e0\u7d20\u5f71\u54cd\u7684\u6a21\u578b\u6765\u66f4\u597d\u5730\u7406\u89e3\u5b8f\u89c2\u91d1\u878d\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u5411\u91cf\u81ea\u56de\u5f52\u6846\u67b6\uff0c\u5f15\u5165\u968f\u673a\u6ce2\u52a8\u7387\u5747\u503c\u6548\u5e94\u548c\u65f6\u53d8\u504f\u5ea6\uff0c\u5f00\u53d1\u4e86\u5409\u5e03\u65af\u91c7\u6837\u7b97\u6cd5\u8fdb\u884c\u540e\u9a8c\u63a8\u65ad\uff0c\u5e94\u7528\u4e8e\u7f8e\u56fd\u548c\u82f1\u56fd\u7684\u5b63\u5ea6\u6570\u636e\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\u504f\u5ea6\u51b2\u51fb\u5bf9\u4ea7\u51fa\u3001\u901a\u80c0\u548c\u5229\u5dee\u5177\u6709\u663e\u8457\u7ecf\u6d4e\u5f71\u54cd\uff0c\u901a\u5e38\u8d85\u8fc7\u6ce2\u52a8\u7387\u51b2\u51fb\u7684\u5f71\u54cd\uff1b\u5728\u4f2a\u5b9e\u65f6\u9884\u6d4b\u4e2d\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff1b\u80fd\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u5c3e\u90e8\u98ce\u9669\u5ea6\u91cf\u3002", "conclusion": "\u65f6\u53d8\u504f\u5ea6\u7684\u7eb3\u5165\u5bf9\u4e8e\u6355\u6349\u5b8f\u89c2\u91d1\u878d\u98ce\u9669\u548c\u6539\u5584\u9884\u6d4b\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u6807\u51c6\u968f\u673a\u6ce2\u52a8\u7387\u6a21\u578b\u5f80\u5f80\u4f1a\u9ad8\u4f30\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2510.07427", "categories": ["cs.ET", "cs.NE", "physics.optics"], "pdf": "https://arxiv.org/pdf/2510.07427", "abs": "https://arxiv.org/abs/2510.07427", "authors": ["Mat\u011bj Hejda", "Aishwarya Natarajan", "Chaerin Hong", "Mehmet Berkay On", "S\u00e9bastien d'Herbais de Thun", "Raymond G. Beausoleil", "Thomas Van Vaerenbergh"], "title": "SEPhIA: <1 laser/neuron Spiking Electro-Photonic Integrated Multi-Tiled Architecture for Scalable Optical Neuromorphic Computing", "comment": "Main manuscript: 20 pages, 10 figures (8 graphics + 2 tables).\n  Includes Supplementary Information document (appended after main manuscript;\n  5 pages, 2 tables)", "summary": "Research into optical spiking neural networks (SNNs) has primarily focused on\nspiking devices, networks of excitable lasers or numerical modelling of large\narchitectures, often overlooking key constraints such as limited optical power,\ncrosstalk and footprint. We introduce SEPhIA, a photonic-electronic,\nmulti-tiled SNN architecture emphasizing implementation feasibility and\nrealistic scaling. SEPhIA leverages microring resonator modulators (MRMs) and\nmulti-wavelength sources to achieve effective sub-one-laser-per-spiking neuron\nefficiency. We validate SEPhIA at both device and architecture levels by\ntime-domain co-simulating excitable CMOS-MRR coupled circuits and by devising a\nphysics-aware, trainable optoelectronic SNN model, with both approaches\nutilizing experimentally derived device parameters. The multi-layer\noptoelectronic SNN achieves classification accuracies over 90% on a four-class\nspike-encoded dataset, closely comparable to software models. A design space\nstudy further quantifies how photonic device parameters impact SNN performance\nunder constrained signal-to-noise conditions. SEPhIA offers a scalable,\nexpressive, physically grounded solution for neuromorphic photonic computing,\ncapable of addressing spike-encoded tasks.", "AI": {"tldr": "SEPhIA\u662f\u4e00\u79cd\u5149\u7535\u6df7\u5408\u7684\u591a\u74e6\u7247\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u5fae\u73af\u8c10\u632f\u5668\u8c03\u5236\u5668\u548c\u591a\u6ce2\u957f\u5149\u6e90\u5b9e\u73b0\u4e9a\u6bcf\u795e\u7ecf\u5143\u4e00\u4e2a\u6fc0\u5149\u5668\u7684\u6548\u7387\uff0c\u5728\u56db\u7c7b\u8109\u51b2\u7f16\u7801\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u8d85\u8fc790%\u7684\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u5149\u5b66\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u8109\u51b2\u8bbe\u5907\u3001\u53ef\u6fc0\u53d1\u6fc0\u5149\u5668\u7f51\u7edc\u6216\u5927\u578b\u67b6\u6784\u7684\u6570\u503c\u6a21\u62df\uff0c\u4f46\u5f80\u5f80\u5ffd\u7565\u4e86\u5149\u5b66\u529f\u7387\u9650\u5236\u3001\u4e32\u6270\u548c\u5360\u5730\u9762\u79ef\u7b49\u5173\u952e\u7ea6\u675f\u6761\u4ef6\u3002", "method": "\u91c7\u7528\u5fae\u73af\u8c10\u632f\u5668\u8c03\u5236\u5668\u548c\u591a\u6ce2\u957f\u5149\u6e90\uff0c\u901a\u8fc7\u65f6\u57df\u534f\u540c\u6a21\u62df\u53ef\u6fc0\u53d1CMOS-MRR\u8026\u5408\u7535\u8def\uff0c\u5e76\u5f00\u53d1\u7269\u7406\u611f\u77e5\u7684\u53ef\u8bad\u7ec3\u5149\u7535SNN\u6a21\u578b\uff0c\u4e24\u79cd\u65b9\u6cd5\u90fd\u4f7f\u7528\u5b9e\u9a8c\u83b7\u5f97\u7684\u5668\u4ef6\u53c2\u6570\u3002", "result": "\u591a\u5c42\u5149\u7535SNN\u5728\u56db\u7c7b\u8109\u51b2\u7f16\u7801\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u8d85\u8fc790%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u4e0e\u8f6f\u4ef6\u6a21\u578b\u6027\u80fd\u76f8\u5f53\u3002\u8bbe\u8ba1\u7a7a\u95f4\u7814\u7a76\u91cf\u5316\u4e86\u5149\u5b50\u5668\u4ef6\u53c2\u6570\u5728\u53d7\u9650\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u5bf9SNN\u6027\u80fd\u7684\u5f71\u54cd\u3002", "conclusion": "SEPhIA\u4e3a\u795e\u7ecf\u5f62\u6001\u5149\u5b50\u8ba1\u7b97\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u8868\u8fbe\u80fd\u529b\u5f3a\u4e14\u7269\u7406\u57fa\u7840\u624e\u5b9e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5904\u7406\u8109\u51b2\u7f16\u7801\u4efb\u52a1\u3002"}}
{"id": "2510.07568", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.07568", "abs": "https://arxiv.org/abs/2510.07568", "authors": ["Jaeho Lee", "Eunju Hwang"], "title": "Modeling and forecasting of European Carbon Emission Allowance futures by ARIMA-TX-GARCH models with correlation threshold", "comment": "29 pages, 10 tables and 9 figures", "summary": "We propose an ARIMA-TX-GARCH model and use it to forecast European Carbon\nEmission Allowance futures prices, incorporating Brent crude oil futures prices\nas an exogenous variable.", "AI": {"tldr": "\u63d0\u51faARIMA-TX-GARCH\u6a21\u578b\uff0c\u7ed3\u5408\u5e03\u4f26\u7279\u539f\u6cb9\u671f\u8d27\u4ef7\u683c\u4f5c\u4e3a\u5916\u751f\u53d8\u91cf\uff0c\u9884\u6d4b\u6b27\u6d32\u78b3\u6392\u653e\u914d\u989d\u671f\u8d27\u4ef7\u683c", "motivation": "\u9700\u8981\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u6b27\u6d32\u78b3\u6392\u653e\u914d\u989d\u671f\u8d27\u4ef7\u683c\uff0c\u8003\u8651\u539f\u6cb9\u4ef7\u683c\u7b49\u5916\u90e8\u56e0\u7d20\u5bf9\u78b3\u5e02\u573a\u7684\u5f71\u54cd", "method": "\u5f00\u53d1ARIMA-TX-GARCH\u6a21\u578b\uff0c\u5c06\u5e03\u4f26\u7279\u539f\u6cb9\u671f\u8d27\u4ef7\u683c\u4f5c\u4e3a\u5916\u751f\u53d8\u91cf\u7eb3\u5165\u9884\u6d4b\u6846\u67b6", "result": "\u6a21\u578b\u80fd\u591f\u6709\u6548\u9884\u6d4b\u6b27\u6d32\u78b3\u6392\u653e\u914d\u989d\u671f\u8d27\u4ef7\u683c", "conclusion": "ARIMA-TX-GARCH\u6a21\u578b\u7ed3\u5408\u5916\u751f\u53d8\u91cf\u80fd\u591f\u63d0\u5347\u78b3\u5e02\u573a\u9884\u6d4b\u7cbe\u5ea6"}}
{"id": "2510.07333", "categories": ["eess.SY", "cs.GT", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.07333", "abs": "https://arxiv.org/abs/2510.07333", "authors": ["Ziqi Ling", "Minghui Liwang", "Xianbin Wang", "Seyyedali Hosseinalipour", "Zhipeng Cheng", "Sai Zou", "Wei Ni", "Xiaoyu Xia"], "title": "Auctioning Future Services in Edge Networks with Moving Vehicles: N-Step Look-Ahead Contracts for Sustainable Resource Provision", "comment": "17 pages, 8 figures, 1 table", "summary": "Timely resource allocation in edge-assisted vehicular networks is essential\nfor compute-intensive services such as autonomous driving and navigation.\nHowever, vehicle mobility leads to spatio-temporal unpredictability of resource\ndemands, while real-time double auctions incur significant latency. To address\nthese challenges, we propose a look-ahead contract-based auction framework that\nshifts decision-making from runtime to planning time. Our approach establishes\nN-step service contracts between edge servers (ESs) using demand forecasts and\nmodified double auctions. The system operates in two stages: first, an\nLSTM-based prediction module forecasts multi-slot resource needs and determines\nES roles (buyer or seller), after which a pre-double auction generates\ncontracts specifying resource quantities, prices, and penalties. Second, these\ncontracts are enforced in real time without rerunning auctions. The framework\nincorporates energy costs, transmission overhead, and contract breach risks\ninto utility models, ensuring truthful, rational, and energy-efficient trading.\nExperiments on real-world (UTD19) and synthetic traces demonstrate that our\nmethod improves time efficiency, energy use, and social welfare compared with\nexisting baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u524d\u77bb\u6027\u5408\u7ea6\u7684\u62cd\u5356\u6846\u67b6\uff0c\u7528\u4e8e\u8fb9\u7f18\u8f85\u52a9\u8f66\u8f7d\u7f51\u7edc\u4e2d\u7684\u8d44\u6e90\u5206\u914d\uff0c\u901a\u8fc7\u5c06\u51b3\u7b56\u4ece\u8fd0\u884c\u65f6\u8f6c\u79fb\u5230\u89c4\u5212\u65f6\u6765\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u8f66\u8f86\u79fb\u52a8\u6027\u5bfc\u81f4\u7684\u8d44\u6e90\u9700\u6c42\u65f6\u7a7a\u4e0d\u53ef\u9884\u6d4b\u6027\uff0c\u4ee5\u53ca\u5b9e\u65f6\u53cc\u91cd\u62cd\u5356\u5e26\u6765\u7684\u663e\u8457\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1\uff09LSTM\u9884\u6d4b\u6a21\u5757\u9884\u6d4b\u591a\u65f6\u9699\u8d44\u6e90\u9700\u6c42\u5e76\u786e\u5b9a\u8fb9\u7f18\u670d\u52a1\u5668\u89d2\u8272\uff1b2\uff09\u9884\u53cc\u91cd\u62cd\u5356\u751f\u6210\u5305\u542b\u8d44\u6e90\u6570\u91cf\u3001\u4ef7\u683c\u548c\u8fdd\u7ea6\u91d1\u7684\u5408\u7ea6\uff0c\u5728\u5b9e\u65f6\u6267\u884c\u65f6\u65e0\u9700\u91cd\u65b0\u8fd0\u884c\u62cd\u5356\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\uff08UTD19\uff09\u548c\u5408\u6210\u8f68\u8ff9\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u65f6\u95f4\u6548\u7387\u3001\u80fd\u6e90\u4f7f\u7528\u548c\u793e\u4f1a\u798f\u5229\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5c06\u51b3\u7b56\u524d\u79fb\uff0c\u7ed3\u5408\u80fd\u6e90\u6210\u672c\u3001\u4f20\u8f93\u5f00\u9500\u548c\u8fdd\u7ea6\u98ce\u9669\uff0c\u5b9e\u73b0\u4e86\u771f\u5b9e\u3001\u7406\u6027\u548c\u8282\u80fd\u7684\u8d44\u6e90\u4ea4\u6613\u3002"}}
{"id": "2510.07801", "categories": ["q-fin.GN"], "pdf": "https://arxiv.org/pdf/2510.07801", "abs": "https://arxiv.org/abs/2510.07801", "authors": ["Jinho Cha", "Youngchul Kim", "Junyeol Ryu", "Sangjun Park", "Jeongho Kang", "Hyeyoung Hwang"], "title": "Smart Contract-Enabled Procurement under Bounded Demand Variability: A Truncated Normal Approach", "comment": "67 pages, 20 figures, prepared for submission to Expert Systems with\n  Applications (ESWA)", "summary": "This study develops a strategic procurement framework integrating\nblockchain-based smart contracts with bounded demand variability modeled\nthrough a truncated normal distribution. While existing research emphasizes the\ntechnical feasibility of smart contracts, the operational and economic\nimplications of adoption under moderate uncertainty remain underexplored. We\npropose a multi-supplier model in which a centralized retailer jointly\ndetermines the optimal smart contract adoption intensity and supplier\nallocation decisions. The formulation endogenizes adoption costs, supplier\ndigital readiness, and inventory penalties to capture realistic trade-offs\namong efficiency, sustainability, and profitability. Analytical results\nestablish concavity and provide closed-form comparative statics for adoption\nthresholds and procurement quantities. Extensive numerical experiments\ndemonstrate that moderate demand variability supports partial adoption\nstrategies, whereas excessive investment in digital infrastructure can reduce\noverall profitability. Dynamic simulations further reveal how adaptive learning\nand declining implementation costs progressively enhance adoption intensity and\nsupply chain performance. The findings provide theoretical and managerial\ninsights for balancing digital transformation, resilience, and sustainability\nobjectives in smart contract-enabled procurement.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408\u533a\u5757\u94fe\u667a\u80fd\u5408\u7ea6\u548c\u6709\u754c\u9700\u6c42\u53d8\u52a8\u7684\u6218\u7565\u91c7\u8d2d\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u4f9b\u5e94\u5546\u6a21\u578b\u4f18\u5316\u667a\u80fd\u5408\u7ea6\u91c7\u7528\u5f3a\u5ea6\u548c\u4f9b\u5e94\u5546\u5206\u914d\u51b3\u7b56\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u667a\u80fd\u5408\u7ea6\u7684\u6280\u672f\u53ef\u884c\u6027\uff0c\u4f46\u5728\u4e2d\u7b49\u4e0d\u786e\u5b9a\u6027\u4e0b\u91c7\u7528\u7684\u64cd\u4f5c\u548c\u7ecf\u6d4e\u5f71\u54cd\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u591a\u4f9b\u5e94\u5546\u6a21\u578b\uff0c\u96f6\u552e\u5546\u8054\u5408\u786e\u5b9a\u6700\u4f18\u667a\u80fd\u5408\u7ea6\u91c7\u7528\u5f3a\u5ea6\u548c\u4f9b\u5e94\u5546\u5206\u914d\u51b3\u7b56\uff0c\u5185\u751f\u8003\u8651\u91c7\u7528\u6210\u672c\u3001\u4f9b\u5e94\u5546\u6570\u5b57\u5316\u51c6\u5907\u5ea6\u548c\u5e93\u5b58\u60e9\u7f5a\u3002", "result": "\u5206\u6790\u7ed3\u679c\u5efa\u7acb\u4e86\u51f9\u6027\u5e76\u63d0\u4f9b\u91c7\u7528\u9608\u503c\u548c\u91c7\u8d2d\u6570\u91cf\u7684\u95ed\u5f0f\u6bd4\u8f83\u9759\u6001\u5206\u6790\uff1b\u6570\u503c\u5b9e\u9a8c\u663e\u793a\u4e2d\u7b49\u9700\u6c42\u53d8\u52a8\u652f\u6301\u90e8\u5206\u91c7\u7528\u7b56\u7565\uff0c\u8fc7\u5ea6\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u6295\u8d44\u4f1a\u964d\u4f4e\u76c8\u5229\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5e73\u8861\u6570\u5b57\u5316\u8f6c\u578b\u3001\u97e7\u6027\u548c\u53ef\u6301\u7eed\u6027\u76ee\u6807\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u7ba1\u7406\u7684\u89c1\u89e3\uff0c\u52a8\u6001\u6a21\u62df\u663e\u793a\u81ea\u9002\u5e94\u5b66\u4e60\u548c\u5b9e\u65bd\u6210\u672c\u4e0b\u964d\u9010\u6b65\u63d0\u5347\u91c7\u7528\u5f3a\u5ea6\u548c\u4f9b\u5e94\u94fe\u7ee9\u6548\u3002"}}
{"id": "2510.07417", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07417", "abs": "https://arxiv.org/abs/2510.07417", "authors": ["Corban Rivera", "Grayson Byrd", "Meghan Booker", "Bethany Kemp", "Allison Gaines", "Emma Holmes", "James Uplinger", "Celso M de Melo", "David Handelman"], "title": "FLEET: Formal Language-Grounded Scheduling for Heterogeneous Robot Teams", "comment": null, "summary": "Coordinating heterogeneous robot teams from free-form natural-language\ninstructions is hard. Language-only planners struggle with long-horizon\ncoordination and hallucination, while purely formal methods require\nclosed-world models. We present FLEET, a hybrid decentralized framework that\nturns language into optimized multi-robot schedules. An LLM front-end produces\n(i) a task graph with durations and precedence and (ii) a capability-aware\nrobot--task fitness matrix; a formal back-end solves a makespan-minimization\nproblem while the underlying robots execute their free-form subtasks with\nagentic closed-loop control. Across multiple free-form language-guided autonomy\ncoordination benchmarks, FLEET improves success over state of the art\ngenerative planners on two-agent teams across heterogeneous tasks. Ablations\nshow that mixed integer linear programming (MILP) primarily improves temporal\nstructure, while LLM-derived fitness is decisive for capability-coupled tasks;\ntogether they deliver the highest overall performance. We demonstrate the\ntranslation to real world challenges with hardware trials using a pair of\nquadruped robots with disjoint capabilities.", "AI": {"tldr": "FLEET\u662f\u4e00\u4e2a\u6df7\u5408\u5206\u6563\u5f0f\u6846\u67b6\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u8f6c\u5316\u4e3a\u4f18\u5316\u7684\u591a\u673a\u5668\u4eba\u8c03\u5ea6\u65b9\u6848\uff0c\u7ed3\u5408LLM\u524d\u7aef\u751f\u6210\u4efb\u52a1\u56fe\u548c\u80fd\u529b\u5339\u914d\u77e9\u9635\uff0c\u4ee5\u53ca\u5f62\u5f0f\u5316\u540e\u7aef\u8fdb\u884c\u8c03\u5ea6\u4f18\u5316\u3002", "motivation": "\u89e3\u51b3\u5f02\u6784\u673a\u5668\u4eba\u56e2\u961f\u4ece\u81ea\u7531\u5f62\u5f0f\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u8fdb\u884c\u534f\u8c03\u7684\u6311\u6218\uff0c\u8bed\u8a00\u89c4\u5212\u5668\u96be\u4ee5\u5904\u7406\u957f\u65f6\u7a0b\u534f\u8c03\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u800c\u7eaf\u5f62\u5f0f\u5316\u65b9\u6cd5\u9700\u8981\u5c01\u95ed\u4e16\u754c\u6a21\u578b\u3002", "method": "\u4f7f\u7528LLM\u524d\u7aef\u751f\u6210\u4efb\u52a1\u56fe\uff08\u5305\u542b\u6301\u7eed\u65f6\u95f4\u548c\u4f18\u5148\u7ea7\uff09\u548c\u673a\u5668\u4eba-\u4efb\u52a1\u9002\u5e94\u5ea6\u77e9\u9635\uff0c\u5f62\u5f0f\u5316\u540e\u7aef\u89e3\u51b3\u6700\u5c0f\u5316\u5b8c\u6210\u65f6\u95f4\u95ee\u9898\uff0c\u673a\u5668\u4eba\u6267\u884c\u5177\u6709\u81ea\u4e3b\u95ed\u73af\u63a7\u5236\u7684\u5b50\u4efb\u52a1\u3002", "result": "\u5728\u591a\u4e2a\u81ea\u7531\u5f62\u5f0f\u8bed\u8a00\u5f15\u5bfc\u7684\u81ea\u4e3b\u534f\u8c03\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFLEET\u5728\u5f02\u6784\u4efb\u52a1\u7684\u4e24\u667a\u80fd\u4f53\u56e2\u961f\u4e0a\u6bd4\u6700\u5148\u8fdb\u7684\u751f\u6210\u89c4\u5212\u5668\u63d0\u9ad8\u4e86\u6210\u529f\u7387\u3002\u6d88\u878d\u5b9e\u9a8c\u663e\u793aMILP\u4e3b\u8981\u6539\u5584\u65f6\u95f4\u7ed3\u6784\uff0cLLM\u884d\u751f\u7684\u9002\u5e94\u5ea6\u5bf9\u80fd\u529b\u8026\u5408\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "FLEET\u6846\u67b6\u6210\u529f\u5730\u5c06\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u8f6c\u5316\u4e3a\u4f18\u5316\u7684\u591a\u673a\u5668\u4eba\u8c03\u5ea6\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u786c\u4ef6\u8bd5\u9a8c\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u6df7\u5408\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.07933", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.07933", "abs": "https://arxiv.org/abs/2510.07933", "authors": ["Gabriela Wojak", "Ernest G\u00f3rka", "Micha\u0142 \u0106wi\u0105ka\u0142a", "Dariusz Baran", "Rafa\u0142 \u015awiniarski", "Katarzyna Olszy\u0144ska", "Piotr Mrzyg\u0142\u00f3d", "Maciej Frasunkiewicz", "Piotr R\u0119czajski", "Daniel Zawadzki", "Jan Piwnik"], "title": "The evolution of insurance purchasing behavior: an empirical study on the adoption of online channels in Poland", "comment": null, "summary": "This paper examines how Polish consumers are adapting to online insurance\npurchasing channels and what factors influence their preferences. Drawing on a\nstructured survey of 100 respondents with varied demographic profiles, the\nstudy explores purchasing frequency, channel usage, price sensitivity, trust,\nand decision-making behaviors. Results indicate a clear shift toward digital\ntools, with many consumers valuing the speed, convenience, and transparency of\nonline platforms, particularly for simple insurance products. However, barriers\nremain, including concerns about data security, lack of personal guidance, and\ndifficulty understanding policy terms. A hybrid model is emerging, where online\ntools are used for research and comparison, while traditional agents are\nconsulted for complex decisions. Respondents emphasized the importance of trust\nand personal contact, showing that emotional and psychological factors still\nplay a role in digital adoption. Price was the dominant decision factor, but\nmany consumers also prioritized service quality and reliability. The study\nconcludes that insurers should invest in user-friendly digital experiences\nwhile maintaining human support options. Strategic omnichannel integration is\nrecommended to meet diverse customer needs and reduce digital exclusion.\nLimitations of the study include a modest sample size and focus on the Polish\nmarket. Future research should investigate the role of AI in digital\ndistribution, segment preferences by insurance type, and analyze trends across\ndifferent regions or age groups. This paper adds empirical value to the\nunderstanding of insurance distribution and consumer behavior in digitally\ntransforming financial markets.", "AI": {"tldr": "\u6ce2\u5170\u6d88\u8d39\u8005\u6b63\u5728\u8f6c\u5411\u5728\u7ebf\u4fdd\u9669\u8d2d\u4e70\u6e20\u9053\uff0c\u4f46\u504f\u597d\u6df7\u5408\u6a21\u5f0f\u2014\u2014\u5728\u7ebf\u5de5\u5177\u7528\u4e8e\u7814\u7a76\u548c\u6bd4\u8f83\uff0c\u4f20\u7edf\u4ee3\u7406\u7528\u4e8e\u590d\u6742\u51b3\u7b56\u3002\u4ef7\u683c\u662f\u4e3b\u8981\u51b3\u7b56\u56e0\u7d20\uff0c\u4f46\u4fe1\u4efb\u548c\u670d\u52a1\u8d28\u91cf\u4e5f\u5f88\u91cd\u8981\u3002", "motivation": "\u7814\u7a76\u6ce2\u5170\u6d88\u8d39\u8005\u5982\u4f55\u9002\u5e94\u5728\u7ebf\u4fdd\u9669\u8d2d\u4e70\u6e20\u9053\uff0c\u4ee5\u53ca\u5f71\u54cd\u4ed6\u4eec\u504f\u597d\u7684\u56e0\u7d20\uff0c\u4e86\u89e3\u6570\u5b57\u5316\u65f6\u4ee3\u4fdd\u9669\u5206\u9500\u7684\u53d8\u5316\u3002", "method": "\u901a\u8fc7\u5bf9100\u540d\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u7684\u53d7\u8bbf\u8005\u8fdb\u884c\u7ed3\u6784\u5316\u8c03\u67e5\uff0c\u63a2\u8ba8\u8d2d\u4e70\u9891\u7387\u3001\u6e20\u9053\u4f7f\u7528\u3001\u4ef7\u683c\u654f\u611f\u6027\u3001\u4fe1\u4efb\u548c\u51b3\u7b56\u884c\u4e3a\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5411\u6570\u5b57\u5de5\u5177\u7684\u660e\u663e\u8f6c\u53d8\uff0c\u6d88\u8d39\u8005\u91cd\u89c6\u5728\u7ebf\u5e73\u53f0\u7684\u901f\u5ea6\u3001\u4fbf\u5229\u6027\u548c\u900f\u660e\u5ea6\uff0c\u7279\u522b\u662f\u7b80\u5355\u4fdd\u9669\u4ea7\u54c1\u3002\u4f46\u5b58\u5728\u6570\u636e\u5b89\u5168\u62c5\u5fe7\u3001\u7f3a\u4e4f\u4e2a\u4eba\u6307\u5bfc\u548c\u7406\u89e3\u4fdd\u5355\u6761\u6b3e\u56f0\u96be\u7b49\u969c\u788d\u3002", "conclusion": "\u4fdd\u9669\u516c\u53f8\u5e94\u6295\u8d44\u7528\u6237\u53cb\u597d\u7684\u6570\u5b57\u4f53\u9a8c\uff0c\u540c\u65f6\u4fdd\u6301\u4eba\u5de5\u652f\u6301\u9009\u9879\u3002\u5efa\u8bae\u6218\u7565\u6027\u7684\u5168\u6e20\u9053\u6574\u5408\u4ee5\u6ee1\u8db3\u591a\u6837\u5316\u5ba2\u6237\u9700\u6c42\u5e76\u51cf\u5c11\u6570\u5b57\u6392\u65a5\u3002"}}
{"id": "2510.08257", "categories": ["cs.ET", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08257", "abs": "https://arxiv.org/abs/2510.08257", "authors": ["Eleni Bougioukou", "Anastasios Petropoulos", "Nikolaos Toulgaridis", "Theodoros Chatzimichail", "Theodore Antonakopoulos"], "title": "A Distributed Emulation Environment for In-Memory Computing Systems", "comment": "6 pages, 5 figures, 2025 IEEE International Instrumentation and\n  Measurement Technology Conference (I2MTC)", "summary": "In-memory computing technology is used extensively in artificial intelligence\ndevices due to lower power consumption and fast calculation of matrix-based\nfunctions. The development of such a device and its integration in a system\ntakes a significant amount of time and requires the use of a real-time\nemulation environment, where various system aspects are analyzed, microcode is\ntested, and applications are deployed, even before the real chip is available.\nIn this work, we present the architecture, the software development tools, and\nexperimental results of a distributed and expandable emulation system for rapid\nprototyping of integrated circuits based on in-memory computing technologies.\nPresented experimental results demonstrate the usefulness of the proposed\nemulator.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5185\u5b58\u8ba1\u7b97\u96c6\u6210\u7535\u8def\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u7684\u5206\u5e03\u5f0f\u53ef\u6269\u5c55\u4eff\u771f\u7cfb\u7edf\u67b6\u6784", "motivation": "\u5185\u5b58\u8ba1\u7b97\u6280\u672f\u5728AI\u8bbe\u5907\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u82af\u7247\u5f00\u53d1\u548c\u7cfb\u7edf\u96c6\u6210\u9700\u8981\u5927\u91cf\u65f6\u95f4\uff0c\u9700\u8981\u5b9e\u65f6\u4eff\u771f\u73af\u5883\u6765\u5728\u82af\u7247\u53ef\u7528\u524d\u5206\u6790\u7cfb\u7edf\u3001\u6d4b\u8bd5\u5fae\u7801\u548c\u90e8\u7f72\u5e94\u7528", "method": "\u5f00\u53d1\u4e86\u5206\u5e03\u5f0f\u53ef\u6269\u5c55\u7684\u4eff\u771f\u7cfb\u7edf\u67b6\u6784\u548c\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177\uff0c\u7528\u4e8e\u5185\u5b58\u8ba1\u7b97\u96c6\u6210\u7535\u8def\u7684\u5feb\u901f\u539f\u578b\u8bbe\u8ba1", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u4eff\u771f\u5668\u5177\u6709\u5b9e\u7528\u6027", "conclusion": "\u8be5\u4eff\u771f\u7cfb\u7edf\u4e3a\u5185\u5b58\u8ba1\u7b97\u96c6\u6210\u7535\u8def\u7684\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.07653", "categories": ["stat.AP", "cs.DB", "q-bio.GN", "q-bio.TO", "stat.CO", "62P10", "J.3"], "pdf": "https://arxiv.org/pdf/2510.07653", "abs": "https://arxiv.org/abs/2510.07653", "authors": ["Jiawen Chen", "Jinwei Zhang", "Dongshen Peng", "Yutong Song", "Aitong Ruan", "Yun Li", "Didong Li"], "title": "Large-scale spatial variable gene atlas for spatial transcriptomics", "comment": null, "summary": "Spatial variable genes (SVGs) reveal critical information about tissue\narchitecture, cellular interactions, and disease microenvironments. As spatial\ntranscriptomics (ST) technologies proliferate, accurately identifying SVGs\nacross diverse platforms, tissue types, and disease contexts has become both a\nmajor opportunity and a significant computational challenge. Here, we present a\ncomprehensive benchmarking study of 20 state-of-the-art SVG detection methods\nusing human slides from STimage-1K4M, a large-scale resource of ST data\ncomprising 662 slides from more than 18 tissue types. We evaluate each method\nacross a range of biologically and technically meaningful criteria, including\nrecovery of pathologist-annotated domain-specific markers, cross-slide\nreproducibility, scalability to high-resolution data, and robustness to\ntechnical variation. Our results reveal marked differences in performance\ndepending on tissue type, spatial resolution, and study design. Beyond\nbenchmarking, we construct the first cross-tissue atlas of SVGs, enabling\ncomparative analysis of spatial gene programs across cancer and normal tissues.\nWe observe similarities between pairs of tissues that reflect developmental and\nfunctional relationships, such as high overlap between thymus and lymph node,\nand uncover spatial gene programs associated with metastasis, immune\ninfiltration, and tissue-of-origin identity in cancer. Together, our work\ndefines a framework for evaluating and interpreting spatial gene expression and\nestablishes a reference resource for the ST community.", "AI": {"tldr": "\u5bf920\u79cd\u6700\u5148\u8fdb\u7684\u7a7a\u95f4\u53ef\u53d8\u57fa\u56e0\u68c0\u6d4b\u65b9\u6cd5\u8fdb\u884c\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6784\u5efa\u9996\u4e2a\u8de8\u7ec4\u7ec7SVG\u56fe\u8c31\uff0c\u4e3a\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u793e\u533a\u63d0\u4f9b\u8bc4\u4f30\u6846\u67b6\u548c\u53c2\u8003\u8d44\u6e90", "motivation": "\u968f\u7740\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u5b66\u6280\u672f\u53d1\u5c55\uff0c\u51c6\u786e\u8bc6\u522b\u4e0d\u540c\u5e73\u53f0\u3001\u7ec4\u7ec7\u7c7b\u578b\u548c\u75be\u75c5\u80cc\u666f\u4e0b\u7684SVG\u65e2\u662f\u91cd\u8981\u673a\u9047\u4e5f\u662f\u91cd\u5927\u8ba1\u7b97\u6311\u6218", "method": "\u4f7f\u7528STimage-1K4M\u8d44\u6e90\u4e2d\u7684662\u5f20\u4eba\u7c7b\u7ec4\u7ec7\u5207\u7247\uff0c\u8bc4\u4f3020\u79cdSVG\u68c0\u6d4b\u65b9\u6cd5\u5728\u751f\u7269\u5b66\u548c\u6280\u672f\u6807\u51c6\u4e0a\u7684\u8868\u73b0", "result": "\u53d1\u73b0\u6027\u80fd\u5dee\u5f02\u663e\u8457\u4f9d\u8d56\u4e8e\u7ec4\u7ec7\u7c7b\u578b\u3001\u7a7a\u95f4\u5206\u8fa8\u7387\u548c\u7814\u7a76\u8bbe\u8ba1\uff0c\u6784\u5efa\u4e86\u8de8\u7ec4\u7ec7SVG\u56fe\u8c31\uff0c\u63ed\u793a\u4e86\u4e0e\u53d1\u80b2\u548c\u529f\u80fd\u5173\u7cfb\u76f8\u5173\u7684\u7ec4\u7ec7\u95f4\u76f8\u4f3c\u6027", "conclusion": "\u5efa\u7acb\u4e86\u8bc4\u4f30\u548c\u89e3\u91ca\u7a7a\u95f4\u57fa\u56e0\u8868\u8fbe\u7684\u6846\u67b6\uff0c\u4e3aST\u793e\u533a\u63d0\u4f9b\u4e86\u53c2\u8003\u8d44\u6e90"}}
{"id": "2510.07336", "categories": ["eess.SY", "cs.SY", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.07336", "abs": "https://arxiv.org/abs/2510.07336", "authors": ["Sebastiano Randino", "Lorenzo Schena", "Nicolas Coudou", "Emanuele Garone", "Miguel Alfonso Mendez"], "title": "Nonlinear System Identification for Model-Based Control of Waked Wind Turbines", "comment": "Submitted to: Data-Centric Engineering Journal Length: 27 pages\n  (including references) Figures: 14 numbered figures (from Fig. 1 to Fig. 14)\n  Keywords: Wind Turbines, Wake Interaction, Nonlinear System Identification,\n  Adaptive Control, RBF Regression, Model-Based Control, Wind Tunnel\n  Experiments", "summary": "This work presents a nonlinear system identification framework for modeling\nthe power extraction dynamics of wind turbines, including both freestream and\nwaked conditions. The approach models turbine dynamics using data-driven power\ncoefficient maps expressed as combinations of compact radial basis functions\nand polynomial bases, parameterized in terms of tip-speed ratio and upstream\nconditions. These surrogate models are embedded in a first-order dynamic system\nsuitable for model-based control. Experimental validation is carried out in two\nwind tunnel configurations: a low-turbulence tandem setup and a high-turbulence\nwind farm scenario. In the tandem case, the identified model is integrated into\nan adapted K\\omega^2 controller, resulting in improved tip-speed ratio tracking\nand power stability compared to BEM-based and steady-state models. In the wind\nfarm scenario, the model captures the statistical behavior of the turbines\ndespite unresolved turbulence. The proposed method enables interpretable,\nadaptive control across a range of operating conditions without relying on\nblack-box learning strategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u975e\u7ebf\u6027\u7cfb\u7edf\u8fa8\u8bc6\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21\u98ce\u529b\u6da1\u8f6e\u673a\u7684\u529f\u7387\u63d0\u53d6\u52a8\u529b\u5b66\uff0c\u5305\u62ec\u81ea\u7531\u6d41\u548c\u5c3e\u6d41\u6761\u4ef6\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u6570\u636e\u9a71\u52a8\u7684\u529f\u7387\u7cfb\u6570\u6620\u5c04\uff0c\u7ed3\u5408\u5f84\u5411\u57fa\u51fd\u6570\u548c\u591a\u9879\u5f0f\u57fa\u51fd\u6570\uff0c\u5d4c\u5165\u4e00\u9636\u52a8\u6001\u7cfb\u7edf\uff0c\u9002\u7528\u4e8e\u57fa\u4e8e\u6a21\u578b\u7684\u63a7\u5236\u3002", "motivation": "\u9700\u8981\u5f00\u53d1\u80fd\u591f\u51c6\u786e\u5efa\u6a21\u98ce\u529b\u6da1\u8f6e\u673a\u529f\u7387\u63d0\u53d6\u52a8\u529b\u5b66\u7684\u6846\u67b6\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u5c3e\u6d41\u6761\u4ef6\u4e0b\uff0c\u4ee5\u6539\u8fdb\u57fa\u4e8e\u6a21\u578b\u7684\u63a7\u5236\u7b56\u7565\uff0c\u63d0\u9ad8\u529f\u7387\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u6570\u636e\u9a71\u52a8\u7684\u529f\u7387\u7cfb\u6570\u6620\u5c04\uff0c\u7ed3\u5408\u5f84\u5411\u57fa\u51fd\u6570\u548c\u591a\u9879\u5f0f\u57fa\u51fd\u6570\uff0c\u53c2\u6570\u5316\u4e3a\u53f6\u5c16\u901f\u6bd4\u548c\u4e0a\u6e38\u6761\u4ef6\u7684\u51fd\u6570\u3002\u8fd9\u4e9b\u4ee3\u7406\u6a21\u578b\u5d4c\u5165\u4e00\u9636\u52a8\u6001\u7cfb\u7edf\uff0c\u5e76\u5728\u4e24\u79cd\u98ce\u6d1e\u914d\u7f6e\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff1a\u4f4e\u6e4d\u6d41\u4e32\u8054\u8bbe\u7f6e\u548c\u9ad8\u6e4d\u6d41\u98ce\u7535\u573a\u573a\u666f\u3002", "result": "\u5728\u4e32\u8054\u60c5\u51b5\u4e0b\uff0c\u5c06\u8bc6\u522b\u6a21\u578b\u96c6\u6210\u5230\u6539\u8fdb\u7684K\u03c9\u00b2\u63a7\u5236\u5668\u4e2d\uff0c\u4e0e\u57fa\u4e8eBEM\u548c\u7a33\u6001\u6a21\u578b\u76f8\u6bd4\uff0c\u63d0\u9ad8\u4e86\u53f6\u5c16\u901f\u6bd4\u8ddf\u8e2a\u548c\u529f\u7387\u7a33\u5b9a\u6027\u3002\u5728\u98ce\u7535\u573a\u573a\u666f\u4e2d\uff0c\u6a21\u578b\u80fd\u591f\u6355\u6349\u6da1\u8f6e\u673a\u7684\u7edf\u8ba1\u884c\u4e3a\uff0c\u5c3d\u7ba1\u5b58\u5728\u672a\u89e3\u6790\u7684\u6e4d\u6d41\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5728\u5404\u79cd\u8fd0\u884c\u6761\u4ef6\u4e0b\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u81ea\u9002\u5e94\u63a7\u5236\uff0c\u800c\u4e0d\u4f9d\u8d56\u4e8e\u9ed1\u76d2\u5b66\u4e60\u7b56\u7565\uff0c\u4e3a\u98ce\u529b\u6da1\u8f6e\u673a\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5efa\u6a21\u6846\u67b6\u3002"}}
{"id": "2510.07447", "categories": ["cs.RO", "cs.LG", "math.DS"], "pdf": "https://arxiv.org/pdf/2510.07447", "abs": "https://arxiv.org/abs/2510.07447", "authors": ["Girolamo Oddo", "Roberto Nuca", "Matteo Parsani"], "title": "VeMo: A Lightweight Data-Driven Approach to Model Vehicle Dynamics", "comment": null, "summary": "Developing a dynamic model for a high-performance vehicle is a complex\nproblem that requires extensive structural information about the system under\nanalysis. This information is often unavailable to those who did not design the\nvehicle and represents a typical issue in autonomous driving applications,\nwhich are frequently developed on top of existing vehicles; therefore, vehicle\nmodels are developed under conditions of information scarcity. This paper\nproposes a lightweight encoder-decoder model based on Gate Recurrent Unit\nlayers to correlate the vehicle's future state with its past states, measured\nonboard, and control actions the driver performs. The results demonstrate that\nthe model achieves a maximum mean relative error below 2.6% in extreme dynamic\nconditions. It also shows good robustness when subject to noisy input data\nacross the interested frequency components. Furthermore, being entirely\ndata-driven and free from physical constraints, the model exhibits physical\nconsistency in the output signals, such as longitudinal and lateral\naccelerations, yaw rate, and the vehicle's longitudinal velocity.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u95e8\u63a7\u5faa\u73af\u5355\u5143\u7684\u8f7b\u91cf\u7ea7\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\uff0c\u7528\u4e8e\u5728\u4fe1\u606f\u7a00\u7f3a\u6761\u4ef6\u4e0b\u9884\u6d4b\u9ad8\u6027\u80fd\u8f66\u8f86\u7684\u672a\u6765\u72b6\u6001\uff0c\u6700\u5927\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u4f4e\u4e8e2.6%\uff0c\u5177\u6709\u826f\u597d\u7684\u566a\u58f0\u9c81\u68d2\u6027\u548c\u7269\u7406\u4e00\u81f4\u6027\u3002", "motivation": "\u9ad8\u6027\u80fd\u8f66\u8f86\u7684\u52a8\u6001\u5efa\u6a21\u9700\u8981\u8be6\u7ec6\u7684\u7cfb\u7edf\u7ed3\u6784\u4fe1\u606f\uff0c\u4f46\u8fd9\u4e9b\u4fe1\u606f\u901a\u5e38\u5bf9\u975e\u8bbe\u8ba1\u8005\u4e0d\u53ef\u5f97\uff0c\u8fd9\u5728\u81ea\u52a8\u9a7e\u9a76\u5e94\u7528\u4e2d\u5c24\u4e3a\u5e38\u89c1\uff0c\u56e0\u6b64\u9700\u8981\u5728\u4fe1\u606f\u7a00\u7f3a\u6761\u4ef6\u4e0b\u5f00\u53d1\u8f66\u8f86\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u95e8\u63a7\u5faa\u73af\u5355\u5143\u7684\u8f7b\u91cf\u7ea7\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\uff0c\u901a\u8fc7\u8f66\u8f86\u5386\u53f2\u72b6\u6001\u6d4b\u91cf\u503c\u548c\u9a7e\u9a76\u5458\u63a7\u5236\u52a8\u4f5c\u6765\u5173\u8054\u672a\u6765\u72b6\u6001\u3002", "result": "\u5728\u6781\u7aef\u52a8\u6001\u6761\u4ef6\u4e0b\uff0c\u6a21\u578b\u6700\u5927\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u4f4e\u4e8e2.6%\uff0c\u5bf9\u611f\u5174\u8da3\u9891\u6bb5\u7684\u566a\u58f0\u8f93\u5165\u6570\u636e\u5177\u6709\u826f\u597d\u7684\u9c81\u68d2\u6027\uff0c\u8f93\u51fa\u4fe1\u53f7\uff08\u7eb5\u5411\u548c\u6a2a\u5411\u52a0\u901f\u5ea6\u3001\u6a2a\u6446\u89d2\u901f\u5ea6\u3001\u7eb5\u5411\u901f\u5ea6\uff09\u8868\u73b0\u51fa\u7269\u7406\u4e00\u81f4\u6027\u3002", "conclusion": "\u8be5\u6570\u636e\u9a71\u52a8\u6a21\u578b\u65e0\u9700\u7269\u7406\u7ea6\u675f\uff0c\u5728\u4fe1\u606f\u7a00\u7f3a\u6761\u4ef6\u4e0b\u4ecd\u80fd\u51c6\u786e\u9884\u6d4b\u8f66\u8f86\u52a8\u6001\u884c\u4e3a\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08337", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.08337", "abs": "https://arxiv.org/abs/2510.08337", "authors": ["Aliya Turegeldinova", "Bakytzhan Amralinova", "Mate Miklos Fodor", "Akerkin Eraliyeva", "Chen Dayou", "Aidos Joldassov"], "title": "AI as a Centripetal Technology: Price Compression, Homogenization, and Entry", "comment": null, "summary": "Generative AI does more than cut costs. It pulls products toward a shared\ntemplate, making offerings look and feel more alike while making true\noriginality disproportionately expensive. We capture this centripetal force in\na standard two-stage differentiated-competition framework and show how a single\ncapability shift simultaneously compresses perceived differences, lowers\nmarginal cost and raises fixed access costs. The intuition is straightforward.\nWhen buyers see smaller differences across products, the payoff to standing\napart shrinks just as the effort to do so rises, so firms cluster around the\ntemplate. Prices fall and customers become more willing to switch. But the same\nhomogenization also squeezes operating margins, and rising fixed outlays deepen\nthe squeeze. The combination yields a structural prediction. There is a\ncapability threshold at which even two firms cannot both cover fixed costs, and\nin a many-firm extension the sustainable number of firms falls as capability\ngrows. Concentration increases, and prices still fall. Our results hold under\nbroader preference shapes, non-uniform consumer densities, outside options,\ncapability-dependent curvatures, and modest asymmetries. We translate the\ntheory into two sufficient statistics for enforcement. On the one hand, a\nconduct statistic and a viability statistic. Transactions or platform rules\nthat strengthen template pull or raise fixed access and originality costs can\nlower prices today yet push the market toward monoculture. Remedies that\nbroaden access and promote template plurality and interoperability preserve the\nprice benefits of AI while protecting entry and variety. The paper thus\nreconciles a live policy paradox. AI can make prices lower and entry harder at\nthe same time. It prescribes what to measure to tell which force is dominant in\npractice.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u901a\u8fc7\u964d\u4f4e\u8fb9\u9645\u6210\u672c\u548c\u63d0\u9ad8\u56fa\u5b9a\u8bbf\u95ee\u6210\u672c\uff0c\u4f7f\u4ea7\u54c1\u8d8b\u540c\u5316\uff0c\u5bfc\u81f4\u5e02\u573a\u96c6\u4e2d\u5ea6\u589e\u52a0\u3001\u4ef7\u683c\u4e0b\u964d\u4f46\u8fdb\u5165\u95e8\u69db\u63d0\u9ad8\u3002", "motivation": "\u7814\u7a76\u751f\u6210\u5f0fAI\u5982\u4f55\u901a\u8fc7\u4ea7\u54c1\u540c\u8d28\u5316\u6548\u5e94\u5f71\u54cd\u5e02\u573a\u7ade\u4e89\u7ed3\u6784\uff0c\u89e3\u91caAI\u540c\u65f6\u5e26\u6765\u4ef7\u683c\u4e0b\u964d\u548c\u5e02\u573a\u96c6\u4e2d\u5ea6\u589e\u52a0\u7684\u77db\u76fe\u73b0\u8c61\u3002", "method": "\u91c7\u7528\u6807\u51c6\u7684\u4e24\u9636\u6bb5\u5dee\u5f02\u5316\u7ade\u4e89\u6846\u67b6\uff0c\u5206\u6790AI\u80fd\u529b\u53d8\u5316\u5982\u4f55\u538b\u7f29\u611f\u77e5\u5dee\u5f02\u3001\u964d\u4f4e\u8fb9\u9645\u6210\u672c\u5e76\u63d0\u9ad8\u56fa\u5b9a\u6210\u672c\u3002", "result": "\u53d1\u73b0\u5b58\u5728\u4e00\u4e2a\u80fd\u529b\u9608\u503c\uff0c\u8d85\u8fc7\u8be5\u9608\u503c\u65f6\u5373\u4f7f\u4e24\u4e2a\u4f01\u4e1a\u4e5f\u65e0\u6cd5\u8986\u76d6\u56fa\u5b9a\u6210\u672c\uff0c\u53ef\u6301\u7eed\u4f01\u4e1a\u6570\u91cf\u968fAI\u80fd\u529b\u589e\u957f\u800c\u51cf\u5c11\u3002", "conclusion": "AI\u5728\u964d\u4f4e\u4ef7\u683c\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u8fdb\u5165\u58c1\u5792\uff0c\u9700\u8981\u901a\u8fc7\u4fc3\u8fdb\u6a21\u677f\u591a\u6837\u6027\u548c\u4e92\u64cd\u4f5c\u6027\u6765\u5e73\u8861\u4ef7\u683c\u6548\u76ca\u4e0e\u5e02\u573a\u591a\u6837\u6027\u3002"}}
{"id": "2510.07821", "categories": ["cs.SI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.07821", "abs": "https://arxiv.org/abs/2510.07821", "authors": ["Raisa M. Simoes", "Timoteo Kelly", "Eduardo J. Simoes", "Praveen Rao"], "title": "From Keywords to Clusters: AI-Driven Analysis of YouTube Comments to Reveal Election Issue Salience in 2024", "comment": null, "summary": "This paper aims to explore two competing data science methodologies to\nattempt answering the question, \"Which issues contributed most to voters'\nchoice in the 2024 presidential election?\" The methodologies involve novel\nempirical evidence driven by artificial intelligence (AI) techniques. By using\ntwo distinct methods based on natural language processing and clustering\nanalysis to mine over eight thousand user comments on election-related YouTube\nvideos from one right leaning journal, Wall Street Journal, and one left\nleaning journal, New York Times, during pre-election week, we quantify the\nfrequency of selected issue areas among user comments to infer which issues\nwere most salient to potential voters in the seven days preceding the November\n5th election. Empirically, we primarily demonstrate that immigration and\ndemocracy were the most frequently and consistently invoked issues in user\ncomments on the analyzed YouTube videos, followed by the issue of identity\npolitics, while inflation was significantly less frequently referenced. These\nresults corroborate certain findings of post-election surveys but also refute\nthe supposed importance of inflation as an election issue. This indicates that\nvariations on opinion mining, with their analysis of raw user data online, can\nbe more revealing than polling and surveys for analyzing election outcomes.", "AI": {"tldr": "\u4f7f\u7528AI\u6280\u672f\u5206\u6790YouTube\u8bc4\u8bba\uff0c\u53d1\u73b0\u79fb\u6c11\u548c\u6c11\u4e3b\u662f2024\u5e74\u603b\u7edf\u9009\u4e3e\u524d\u6700\u91cd\u8981\u7684\u8bae\u9898\uff0c\u901a\u80c0\u8bae\u9898\u91cd\u8981\u6027\u88ab\u9ad8\u4f30", "motivation": "\u63a2\u7d22\u54ea\u79cd\u6570\u636e\u79d1\u5b66\u65b9\u6cd5\u80fd\u66f4\u597d\u5206\u6790\u9009\u4e3e\u8bae\u9898\uff0c\u6bd4\u8f83AI\u9a71\u52a8\u7684\u610f\u89c1\u6316\u6398\u4e0e\u4f20\u7edf\u8c03\u67e5\u65b9\u6cd5\u7684\u6548\u679c", "method": "\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u805a\u7c7b\u5206\u6790\uff0c\u6316\u63988000\u591a\u6761\u6765\u81ea\u534e\u5c14\u8857\u65e5\u62a5\u548c\u7ebd\u7ea6\u65f6\u62a5YouTube\u9891\u9053\u7684\u9009\u4e3e\u76f8\u5173\u7528\u6237\u8bc4\u8bba", "result": "\u79fb\u6c11\u548c\u6c11\u4e3b\u662f\u6700\u5e38\u88ab\u63d0\u53ca\u7684\u8bae\u9898\uff0c\u8eab\u4efd\u653f\u6cbb\u6b21\u4e4b\uff0c\u901a\u80c0\u8bae\u9898\u88ab\u63d0\u53ca\u9891\u7387\u663e\u8457\u8f83\u4f4e", "conclusion": "\u5728\u7ebf\u7528\u6237\u6570\u636e\u7684\u610f\u89c1\u6316\u6398\u6bd4\u4f20\u7edf\u6c11\u8c03\u66f4\u80fd\u63ed\u793a\u9009\u4e3e\u7ed3\u679c"}}
{"id": "2510.08151", "categories": ["stat.AP", "q-bio.PE", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.08151", "abs": "https://arxiv.org/abs/2510.08151", "authors": ["Andr\u00e9 Lu\u00eds Luza", "Didier Alard", "Fr\u00e9d\u00e9ric Barraquand"], "title": "Evaluating multi-season occupancy models with autocorrelation fitted to heterogeneous datasets", "comment": null, "summary": "Predicting species distributions using occupancy models accounting for\nimperfect detection is now commonplace in ecology. Recently, modelling spatial\nand temporal autocorrelation was proposed to alleviate the lack of replication\nin occupancy data, which often prevents model identifiability. However, how\nsuch models perform in highly heterogeneous datasets where missing or\nsingle-visit data dominates remains an open question. Motivated by an\nheterogeneous fine-scale butterfly occupancy dataset, we evaluate the\nperformance of a multi-season occupancy model with spatial and temporal random\neffects to a skewed (Poisson) distribution of the number of surveys per site,\noverlap of covariates between occupancy and detection submodels, and\nspatiotemporal clustering of observations. Results showed that the model is\nrobust to heterogeneous data and covariate overlap. However, when\nspatiotemporal gaps were added, site occupancy was biased towards the average\noccupancy, itself overestimated. Random effects did not correct the influence\nof gaps, due to identifiability issues of variance and autocorrelation\nparameters. Occupancy analysis of two butterfly species further confirmed these\nresults. Overall, multi-season occupancy models with autocorrelation are robust\nto heterogeneous data and covariate overlap, but still present identifiability\nissues and are challenged by severe data gaps, which compromise predictions\neven in data-rich areas.", "AI": {"tldr": "\u591a\u5b63\u8282\u5360\u7528\u6a21\u578b\u5728\u8003\u8651\u7a7a\u95f4\u548c\u65f6\u95f4\u81ea\u76f8\u5173\u65f6\uff0c\u5bf9\u5f02\u6784\u6570\u636e\u548c\u534f\u53d8\u91cf\u91cd\u53e0\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4f46\u5728\u5b58\u5728\u4e25\u91cd\u6570\u636e\u7f3a\u53e3\u65f6\u4f1a\u51fa\u73b0\u53ef\u8bc6\u522b\u6027\u95ee\u9898\uff0c\u5bfc\u81f4\u9884\u6d4b\u504f\u5dee\u3002", "motivation": "\u89e3\u51b3\u751f\u6001\u5b66\u4e2d\u5360\u7528\u6a21\u578b\u5728\u9ad8\u5ea6\u5f02\u6784\u6570\u636e\u96c6\uff08\u7279\u522b\u662f\u7f3a\u5931\u6570\u636e\u6216\u5355\u6b21\u8bbf\u95ee\u6570\u636e\u5360\u4e3b\u5bfc\uff09\u4e2d\u7684\u6027\u80fd\u95ee\u9898\uff0c\u8bc4\u4f30\u6a21\u578b\u5bf9\u8c03\u67e5\u6b21\u6570\u504f\u6001\u5206\u5e03\u3001\u534f\u53d8\u91cf\u91cd\u53e0\u548c\u65f6\u7a7a\u805a\u7c7b\u89c2\u6d4b\u7684\u54cd\u5e94\u3002", "method": "\u4f7f\u7528\u5177\u6709\u7a7a\u95f4\u548c\u65f6\u95f4\u968f\u673a\u6548\u5e94\u7684\u591a\u5b63\u8282\u5360\u7528\u6a21\u578b\uff0c\u8bc4\u4f30\u6a21\u578b\u5bf9\u8c03\u67e5\u6b21\u6570\u504f\u6001\u5206\u5e03\uff08\u6cca\u677e\u5206\u5e03\uff09\u3001\u5360\u7528\u548c\u68c0\u6d4b\u5b50\u6a21\u578b\u534f\u53d8\u91cf\u91cd\u53e0\u4ee5\u53ca\u89c2\u6d4b\u65f6\u7a7a\u805a\u7c7b\u7684\u6027\u80fd\u3002", "result": "\u6a21\u578b\u5bf9\u5f02\u6784\u6570\u636e\u548c\u534f\u53d8\u91cf\u91cd\u53e0\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4f46\u5f53\u6dfb\u52a0\u65f6\u7a7a\u7f3a\u53e3\u65f6\uff0c\u7ad9\u70b9\u5360\u7528\u7387\u504f\u5411\u5e73\u5747\u5360\u7528\u7387\u4e14\u88ab\u9ad8\u4f30\u3002\u968f\u673a\u6548\u5e94\u672a\u80fd\u7ea0\u6b63\u7f3a\u53e3\u5f71\u54cd\uff0c\u5b58\u5728\u65b9\u5dee\u548c\u81ea\u76f8\u5173\u53c2\u6570\u7684\u53ef\u8bc6\u522b\u6027\u95ee\u9898\u3002", "conclusion": "\u5177\u6709\u81ea\u76f8\u5173\u7684\u591a\u5b63\u8282\u5360\u7528\u6a21\u578b\u5bf9\u5f02\u6784\u6570\u636e\u548c\u534f\u53d8\u91cf\u91cd\u53e0\u7a33\u5065\uff0c\u4f46\u4ecd\u5b58\u5728\u53ef\u8bc6\u522b\u6027\u95ee\u9898\uff0c\u4e25\u91cd\u6570\u636e\u7f3a\u53e3\u4f1a\u635f\u5bb3\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5373\u4f7f\u5728\u6570\u636e\u4e30\u5bcc\u533a\u57df\u4e5f\u662f\u5982\u6b64\u3002"}}
{"id": "2510.07338", "categories": ["eess.SY", "cond-mat.mtrl-sci", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.07338", "abs": "https://arxiv.org/abs/2510.07338", "authors": ["Jihun Lim", "Sungwon Lee"], "title": "Techno-economic analysis of self-sustainable thermophotovoltaic systems for grid-scale energy generation", "comment": "27 pages, 6 figures, 1 table", "summary": "To facilitate the widespread adoption of renewable energy, dispatchable,\nzero-emission power sources are essential for grid stability. This work\nperforms a comprehensive techno-economic analysis of a self-sustainable\nthermophotovoltaic (TPV) system, an architecture that integrates solar charging\nto function as a standalone power generation asset. Using theory-based models\nfor air-bridge InGaAs and Si diode cells, our analysis reveals that while the\nsystem is not currently competitive from a pure levelized of storage cost\n(LCOS) perspective due to the high capital expenditure for thermal battery\nmaterials, its primary value lies in its competitive levelized cost of\nelectricity (LCOE). The results demonstrate that the LCOE of this\nself-sustaining system can be competitive with conventional dispatchable\ngenerators, such as gas turbines. Furthermore, at scales exceeding the\ngigawatt-hour level, a Si-based system can also achieve an LCOE comparable to\nthat of traditional gas-turbine power plants, despite having a lower conversion\nefficiency than its InGaAs counterpart. This highlights a practical engineering\npathway for leveraging silicon's immense manufacturing scalability, offering a\nlower-risk route to deployment compared to III-V materials. Ultimately, this\nwork establishes the self-sustainable TPV architecture as a compelling pathway\ntoward providing grid-scale, on-demand, zero-emission power.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9\u81ea\u6301\u7eed\u70ed\u5149\u4f0f\u7cfb\u7edf\u8fdb\u884c\u4e86\u6280\u672f\u7ecf\u6d4e\u5206\u6790\uff0c\u53d1\u73b0\u867d\u7136\u4ece\u50a8\u80fd\u6210\u672c\u89d2\u5ea6\u770b\u76ee\u524d\u4e0d\u5177\u7ade\u4e89\u529b\uff0c\u4f46\u5176\u7535\u529b\u6210\u672c\u53ef\u4e0e\u4f20\u7edf\u53ef\u8c03\u5ea6\u53d1\u7535\u673a\u7ade\u4e89\uff0c\u7279\u522b\u662f\u7845\u57fa\u7cfb\u7edf\u5728\u5927\u89c4\u6a21\u90e8\u7f72\u65f6\u5177\u6709\u5b9e\u9645\u5de5\u7a0b\u4f18\u52bf\u3002", "motivation": "\u4e3a\u4fc3\u8fdb\u53ef\u518d\u751f\u80fd\u6e90\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u53ef\u8c03\u5ea6\u3001\u96f6\u6392\u653e\u7684\u7535\u6e90\u6765\u7ef4\u6301\u7535\u7f51\u7a33\u5b9a\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u7406\u8bba\u6a21\u578b\u7684\u7a7a\u6c14\u6865InGaAs\u548c\u7845\u4e8c\u6781\u7ba1\u7535\u6c60\uff0c\u5bf9\u81ea\u6301\u7eed\u70ed\u5149\u4f0f\u7cfb\u7edf\u8fdb\u884c\u5168\u9762\u7684\u6280\u672f\u7ecf\u6d4e\u5206\u6790\u3002", "result": "\u5206\u6790\u663e\u793a\uff0c\u867d\u7136\u7cfb\u7edf\u56e0\u70ed\u7535\u6c60\u6750\u6599\u8d44\u672c\u652f\u51fa\u9ad8\u800c\u5728\u50a8\u80fd\u6210\u672c\u65b9\u9762\u4e0d\u5177\u7ade\u4e89\u529b\uff0c\u4f46\u5176\u7535\u529b\u6210\u672c\u53ef\u4e0e\u4f20\u7edf\u71c3\u6c14\u8f6e\u673a\u7ade\u4e89\uff0c\u7279\u522b\u662f\u7845\u57fa\u7cfb\u7edf\u5728\u5409\u74e6\u65f6\u89c4\u6a21\u4e0b\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u81ea\u6301\u7eed\u70ed\u5149\u4f0f\u67b6\u6784\u4e3a\u63d0\u4f9b\u7535\u7f51\u89c4\u6a21\u3001\u6309\u9700\u3001\u96f6\u6392\u653e\u7535\u529b\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u524d\u666f\u7684\u9014\u5f84\uff0c\u7279\u522b\u662f\u5229\u7528\u7845\u6750\u6599\u7684\u5236\u9020\u53ef\u6269\u5c55\u6027\u63d0\u4f9b\u4e86\u8f83\u4f4e\u98ce\u9669\u7684\u90e8\u7f72\u8def\u5f84\u3002"}}
{"id": "2510.07514", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07514", "abs": "https://arxiv.org/abs/2510.07514", "authors": ["Cael Yasutake", "Zachary Kingston", "Brian Plancher"], "title": "HJCD-IK: GPU-Accelerated Inverse Kinematics through Batched Hybrid Jacobian Coordinate Descent", "comment": null, "summary": "Inverse Kinematics (IK) is a core problem in robotics, in which joint\nconfigurations are found to achieve a desired end-effector pose. Although\nanalytical solvers are fast and efficient, they are limited to systems with low\ndegrees-of-freedom and specific topological structures. Numerical\noptimization-based approaches are more general, but suffer from high\ncomputational costs and frequent convergence to spurious local minima. Recent\nefforts have explored the use of GPUs to combine sampling and optimization to\nenhance both the accuracy and speed of IK solvers. We build on this recent\nliterature and introduce HJCD-IK, a GPU-accelerated, sampling-based hybrid\nsolver that combines an orientation-aware greedy coordinate descent\ninitialization scheme with a Jacobian-based polishing routine. This design\nenables our solver to improve both convergence speed and overall accuracy as\ncompared to the state-of-the-art, consistently finding solutions along the\naccuracy-latency Pareto frontier and often achieving order-of-magnitude gains.\nIn addition, our method produces a broad distribution of high-quality samples,\nyielding the lowest maximum mean discrepancy. We release our code open-source\nfor the benefit of the community.", "AI": {"tldr": "HJCD-IK\u662f\u4e00\u79cdGPU\u52a0\u901f\u7684\u91c7\u6837\u5f0f\u9006\u8fd0\u52a8\u5b66\u6c42\u89e3\u5668\uff0c\u7ed3\u5408\u4e86\u65b9\u5411\u611f\u77e5\u7684\u8d2a\u5a6a\u5750\u6807\u4e0b\u964d\u521d\u59cb\u5316\u65b9\u6848\u548c\u57fa\u4e8e\u96c5\u53ef\u6bd4\u77e9\u9635\u7684\u4f18\u5316\u7a0b\u5e8f\uff0c\u5728\u7cbe\u5ea6\u548c\u901f\u5ea6\u65b9\u9762\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u89e3\u6790\u6cd5IK\u6c42\u89e3\u5668\u53d7\u9650\u4e8e\u4f4e\u81ea\u7531\u5ea6\u548c\u7279\u5b9a\u62d3\u6251\u7ed3\u6784\uff0c\u800c\u6570\u503c\u4f18\u5316\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\u3002\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u901a\u7528\u7684IK\u6c42\u89e3\u65b9\u6cd5\u3002", "method": "\u63d0\u51faHJCD-IK\u65b9\u6cd5\uff0c\u4f7f\u7528GPU\u52a0\u901f\uff0c\u7ed3\u5408\u91c7\u6837\u548c\u4f18\u5316\u7b56\u7565\uff1a\u91c7\u7528\u65b9\u5411\u611f\u77e5\u7684\u8d2a\u5a6a\u5750\u6807\u4e0b\u964d\u8fdb\u884c\u521d\u59cb\u5316\uff0c\u7136\u540e\u4f7f\u7528\u96c5\u53ef\u6bd4\u77e9\u9635\u8fdb\u884c\u4f18\u5316\u7cbe\u70bc\u3002", "result": "\u76f8\u6bd4\u73b0\u6709\u6280\u672f\uff0c\u8be5\u65b9\u6cd5\u5728\u6536\u655b\u901f\u5ea6\u548c\u6574\u4f53\u7cbe\u5ea6\u4e0a\u90fd\u6709\u63d0\u5347\uff0c\u5728\u7cbe\u5ea6-\u5ef6\u8fdf\u5e15\u7d2f\u6258\u8fb9\u754c\u4e0a\u59cb\u7ec8\u627e\u5230\u6700\u4f18\u89e3\uff0c\u901a\u5e38\u5b9e\u73b0\u6570\u91cf\u7ea7\u589e\u76ca\uff0c\u5e76\u4ea7\u751f\u9ad8\u8d28\u91cf\u6837\u672c\u5206\u5e03\u3002", "conclusion": "HJCD-IK\u5728\u9006\u8fd0\u52a8\u5b66\u6c42\u89e3\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u63d0\u4f9b\u4e86\u5f00\u6e90\u4ee3\u7801\u4f9b\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2510.08366", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.08366", "abs": "https://arxiv.org/abs/2510.08366", "authors": ["Xiyuan Ren", "Joseph Y. J. Chow"], "title": "A data fusion approach for mobility hub impact assessment and location selection: integrating hub usage data into a large-scale mode choice model", "comment": null, "summary": "As cities grapple with traffic congestion and service inequities, mobility\nhubs offer a scalable solution to align increasing travel demand with\nsustainability goals. However, evaluating their impacts remains challenging due\nto the lack of behavioral models that integrate large-scale travel patterns\nwith real-world hub usage. This study presents a novel data fusion approach\nthat incorporates observed mobility hub usage into a mode choice model\nestimated with synthetic trip data. We identify trips potentially affected by\nmobility hubs and construct a multimodal sub-choice set, then calibrate\nhub-specific parameters using on-site survey data and ground truth trip counts.\nThe enhanced model is used to evaluate mobility hub impacts on potential\ndemand, mode shift, reduced vehicle miles traveled (VMT), and increased\nconsumer surplus (CS). We apply this method to a case study in the Capital\nDistrict, NY, using data from a survey conducted by the Capital District\nTransportation Authority (CDTA) and a mode choice model estimated using Replica\nInc. synthetic data. The two implemented hubs located near UAlbany Downtown\nCampus and in Downtown Cohoes are projected to generate 8.83 and 6.17\nmultimodal trips per day, reduce annual VMT by 20.37 and 13.16 thousand miles,\nand increase daily CS by $4,000 and $1,742, respectively. An evaluation of\npotential hub candidates in the Albany-Schenectady-Troy metropolitan area with\nthe estimated models demonstrates that hubs located along intercity corridors\nand at urban peripheries, supporting park-and-ride P+R patterns, yield the most\nsignificant behavioral impacts.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u878d\u5408\u65b9\u6cd5\uff0c\u5c06\u89c2\u5bdf\u5230\u7684\u79fb\u52a8\u67a2\u7ebd\u4f7f\u7528\u60c5\u51b5\u6574\u5408\u5230\u57fa\u4e8e\u5408\u6210\u51fa\u884c\u6570\u636e\u7684\u6a21\u5f0f\u9009\u62e9\u6a21\u578b\u4e2d\uff0c\u7528\u4e8e\u8bc4\u4f30\u79fb\u52a8\u67a2\u7ebd\u5bf9\u51fa\u884c\u9700\u6c42\u3001\u6a21\u5f0f\u8f6c\u6362\u3001\u8f66\u8f86\u884c\u9a76\u91cc\u7a0b\u51cf\u5c11\u548c\u6d88\u8d39\u8005\u5269\u4f59\u589e\u52a0\u7684\u5f71\u54cd\u3002", "motivation": "\u57ce\u5e02\u9762\u4e34\u4ea4\u901a\u62e5\u5835\u548c\u670d\u52a1\u4e0d\u5e73\u7b49\u95ee\u9898\uff0c\u79fb\u52a8\u67a2\u7ebd\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u6765\u534f\u8c03\u65e5\u76ca\u589e\u957f\u7684\u51fa\u884c\u9700\u6c42\u4e0e\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\uff0c\u4f46\u8bc4\u4f30\u5176\u5f71\u54cd\u4ecd\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u91c7\u7528\u6570\u636e\u878d\u5408\u65b9\u6cd5\uff0c\u8bc6\u522b\u53ef\u80fd\u53d7\u79fb\u52a8\u67a2\u7ebd\u5f71\u54cd\u7684\u51fa\u884c\uff0c\u6784\u5efa\u591a\u6a21\u5f0f\u5b50\u9009\u62e9\u96c6\uff0c\u4f7f\u7528\u73b0\u573a\u8c03\u67e5\u6570\u636e\u548c\u771f\u5b9e\u51fa\u884c\u8ba1\u6570\u6765\u6821\u51c6\u67a2\u7ebd\u7279\u5b9a\u53c2\u6570\u3002", "result": "\u5728\u7ebd\u7ea6\u5dde\u9996\u5e9c\u533a\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u4e24\u4e2a\u5df2\u5b9e\u65bd\u7684\u67a2\u7ebd\u9884\u8ba1\u6bcf\u5929\u5206\u522b\u4ea7\u751f8.83\u548c6.17\u6b21\u591a\u6a21\u5f0f\u51fa\u884c\uff0c\u6bcf\u5e74\u51cf\u5c11\u8f66\u8f86\u884c\u9a76\u91cc\u7a0b20.37\u548c13.16\u5343\u82f1\u91cc\uff0c\u6bcf\u65e5\u589e\u52a0\u6d88\u8d39\u8005\u5269\u4f594,000\u7f8e\u5143\u548c1,742\u7f8e\u5143\u3002", "conclusion": "\u4f4d\u4e8e\u57ce\u9645\u8d70\u5eca\u548c\u57ce\u5e02\u8fb9\u7f18\u3001\u652f\u6301\u505c\u8f66\u6362\u4e58\u6a21\u5f0f\u7684\u67a2\u7ebd\u5019\u9009\u70b9\u663e\u793a\u51fa\u6700\u663e\u8457\u7684\u884c\u4e3a\u5f71\u54cd\u3002"}}
{"id": "2510.08012", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.08012", "abs": "https://arxiv.org/abs/2510.08012", "authors": ["Jinze Wang", "Lu Zhang", "Yiyang Cui", "Zhishu Shen", "Xingjun Ma", "Jiong Jin", "Tiehua Zhang"], "title": "Do We Really Need SFT? Prompt-as-Policy over Knowledge Graphs for Cold-start Next POI Recommendation", "comment": null, "summary": "Next point-of-interest (POI) recommendation is crucial for smart urban\nservices such as tourism, dining, and transportation, yet most approaches\nstruggle under cold-start conditions where user-POI interactions are sparse.\nRecent efforts leveraging large language models (LLMs) address this challenge\nthrough either supervised fine-tuning (SFT) or in-context learning (ICL).\nHowever, SFT demands costly annotations and fails to generalize to inactive\nusers, while static prompts in ICL cannot adapt to diverse user contexts. To\novercome these limitations, we propose Prompt-as-Policy over knowledge graphs,\na reinforcement-guided prompting framework that learns to construct prompts\ndynamically through contextual bandit optimization. Our method treats prompt\nconstruction as a learnable policy that adaptively determines (i) which\nrelational evidences to include, (ii) the number of evidence per candidate, and\n(iii) their organization and ordering within prompts. More specifically, we\nconstruct a knowledge graph (KG) to discover candidates and mine relational\npaths, which are transformed into evidence cards that summarize rationales for\neach candidate POI. The frozen LLM then acts as a reasoning engine, generating\nrecommendations from the KG-discovered candidate set based on the\npolicy-optimized prompts. Experiments on three real-world datasets demonstrate\nthat Prompt-as-Policy consistently outperforms state-of-the-art baselines,\nachieving average 7.7\\% relative improvements in Acc@1 for inactive users,\nwhile maintaining competitive performance on active users, without requiring\nmodel fine-tuning.", "AI": {"tldr": "\u63d0\u51faPrompt-as-Policy\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u6784\u5efa\u63d0\u793a\u6765\u89e3\u51b3\u51b7\u542f\u52a8POI\u63a8\u8350\u95ee\u9898\uff0c\u65e0\u9700\u5fae\u8c03LLM\u5373\u53ef\u663e\u8457\u63d0\u5347\u4e0d\u6d3b\u8dc3\u7528\u6237\u7684\u63a8\u8350\u6548\u679c", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684POI\u63a8\u8350\u65b9\u6cd5\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u5b58\u5728\u5c40\u9650\uff1a\u76d1\u7763\u5fae\u8c03\u9700\u8981\u6602\u8d35\u6807\u6ce8\u4e14\u65e0\u6cd5\u6cdb\u5316\u5230\u4e0d\u6d3b\u8dc3\u7528\u6237\uff0c\u4e0a\u4e0b\u6587\u5b66\u4e60\u4f7f\u7528\u9759\u6001\u63d0\u793a\u65e0\u6cd5\u9002\u5e94\u591a\u6837\u5316\u7528\u6237\u4e0a\u4e0b\u6587", "method": "\u5c06\u63d0\u793a\u6784\u5efa\u89c6\u4e3a\u53ef\u5b66\u4e60\u7b56\u7565\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\u4f18\u5316\u52a8\u6001\u786e\u5b9a\uff1a\u5305\u542b\u54ea\u4e9b\u5173\u7cfb\u8bc1\u636e\u3001\u6bcf\u4e2a\u5019\u9009\u7684\u8bc1\u636e\u6570\u91cf\u3001\u8bc1\u636e\u7684\u7ec4\u7ec7\u548c\u6392\u5e8f\u3002\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u53d1\u73b0\u5019\u9009\u548c\u6316\u6398\u5173\u7cfb\u8def\u5f84\uff0c\u8f6c\u6362\u4e3a\u8bc1\u636e\u5361\u7247\uff0c\u51bb\u7ed3\u7684LLM\u4f5c\u4e3a\u63a8\u7406\u5f15\u64ce\u57fa\u4e8e\u7b56\u7565\u4f18\u5316\u7684\u63d0\u793a\u751f\u6210\u63a8\u8350", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPrompt-as-Policy\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\uff0c\u5728\u4e0d\u6d3b\u8dc3\u7528\u6237\u7684Acc@1\u4e0a\u5b9e\u73b0\u5e73\u57477.7%\u7684\u76f8\u5bf9\u63d0\u5347\uff0c\u540c\u65f6\u5728\u6d3b\u8dc3\u7528\u6237\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u4e14\u65e0\u9700\u6a21\u578b\u5fae\u8c03", "conclusion": "Prompt-as-Policy\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u51b7\u542f\u52a8POI\u63a8\u8350\u95ee\u9898\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u63d0\u793a\u6784\u5efa\u663e\u8457\u63d0\u5347\u4e86\u4e0d\u6d3b\u8dc3\u7528\u6237\u7684\u63a8\u8350\u6027\u80fd\uff0c\u540c\u65f6\u907f\u514d\u4e86\u6602\u8d35\u7684\u6a21\u578b\u5fae\u8c03\u9700\u6c42"}}
{"id": "2510.07478", "categories": ["cs.CY", "cs.GT", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2510.07478", "abs": "https://arxiv.org/abs/2510.07478", "authors": ["Gaurab Pokharel", "Diptangshu Sen", "Sanmay Das", "Juba Ziani"], "title": "Fixed Points and Stochastic Meritocracies: A Long-Term Perspective", "comment": null, "summary": "We study group fairness in the context of feedback loops induced by\nmeritocratic selection into programs that themselves confer additional\nadvantage, like college admissions. We introduce a novel stylized\ninter-generational model for the setting and analyze it in situations where\nthere are no underlying differences between two populations. We show that, when\nthe benefit of the program (or the harm of not getting into it) is completely\nsymmetric, disparities between the two populations will eventually dissipate.\nHowever, the time an accumulated advantage takes to dissipate could be\nsignificant, and increases substantially as a function of the relative\nimportance of the program in conveying benefits. We also find that significant\ndisparities can arise due to chance even from completely symmetric initial\nconditions, especially when populations are small. The introduction of even a\nslight asymmetry, where the group that has accumulated an advantage becomes\nslightly preferred, leads to a completely different outcome. In these\ninstances, starting from completely symmetric initial conditions, disparities\nbetween groups arise stochastically and then persist over time, yielding a\npermanent advantage for one group. Our analysis precisely characterizes\nconditions under which disparities persist or diminish, with a particular focus\non the role of the scarcity of available spots in the program and its\neffectiveness. We also present extensive simulations in a richer model that\nfurther support our theoretical results in the simpler, stylized model. Our\nfindings are relevant for the design and implementation of algorithmic fairness\ninterventions in similar selection processes.", "AI": {"tldr": "\u7814\u7a76\u5728\u62e9\u4f18\u9009\u62d4\u7a0b\u5e8f\u4e2d\u7fa4\u4f53\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5206\u6790\u4f18\u52bf\u79ef\u7d2f\u5982\u4f55\u5bfc\u81f4\u957f\u671f\u4e0d\u5e73\u7b49\uff0c\u7279\u522b\u662f\u5728\u5b8c\u5168\u5bf9\u79f0\u548c\u8f7b\u5fae\u4e0d\u5bf9\u79f0\u6761\u4ef6\u4e0b\u7684\u4e0d\u540c\u7ed3\u679c\u3002", "motivation": "\u7814\u7a76\u62e9\u4f18\u9009\u62d4\u7a0b\u5e8f\uff08\u5982\u5927\u5b66\u5f55\u53d6\uff09\u4e2d\u7684\u53cd\u9988\u5faa\u73af\u5982\u4f55\u5bfc\u81f4\u7fa4\u4f53\u95f4\u7684\u4e0d\u5e73\u7b49\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u5148\u5929\u5dee\u5f02\u7684\u60c5\u51b5\u4e0b\uff0c\u4f18\u52bf\u79ef\u7d2f\u4e5f\u53ef\u80fd\u9020\u6210\u6301\u4e45\u7684\u4e0d\u516c\u5e73\u3002", "method": "\u5efa\u7acb\u4ee3\u9645\u6a21\u578b\uff0c\u5206\u6790\u5b8c\u5168\u5bf9\u79f0\u548c\u8f7b\u5fae\u4e0d\u5bf9\u79f0\u6761\u4ef6\u4e0b\u7684\u7fa4\u4f53\u52a8\u6001\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6269\u5c55\u6a21\u62df\u9a8c\u8bc1\u7ed3\u679c\u3002", "result": "\u5b8c\u5168\u5bf9\u79f0\u6761\u4ef6\u4e0b\u4e0d\u5e73\u7b49\u6700\u7ec8\u4f1a\u6d88\u6563\u4f46\u8017\u65f6\u5f88\u957f\uff1b\u8f7b\u5fae\u4e0d\u5bf9\u79f0\u6761\u4ef6\u4e0b\u4e0d\u5e73\u7b49\u4f1a\u968f\u673a\u4ea7\u751f\u5e76\u6c38\u4e45\u6301\u7eed\uff1b\u7a00\u7f3a\u6027\u548c\u9879\u76ee\u6709\u6548\u6027\u662f\u5173\u952e\u5f71\u54cd\u56e0\u7d20\u3002", "conclusion": "\u62e9\u4f18\u9009\u62d4\u7a0b\u5e8f\u4e2d\u7684\u53cd\u9988\u5faa\u73af\u53ef\u80fd\u5bfc\u81f4\u6301\u4e45\u7684\u4e0d\u5e73\u7b49\uff0c\u8fd9\u5bf9\u7b97\u6cd5\u516c\u5e73\u5e72\u9884\u7684\u8bbe\u8ba1\u548c\u5b9e\u65bd\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.08309", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.08309", "abs": "https://arxiv.org/abs/2510.08309", "authors": ["Michael T. Gorczyca", "Jenna D. Li", "Charissa M. Newkirk", "Arjun S. Srivatsa", "Hugo F. M. Milan"], "title": "Two-Stage Trigonometric Regression for Modeling Circadian Rhythms", "comment": null, "summary": "Gene expression levels, hormone secretion, and internal body temperature each\noscillate over an approximately 24-hour cycle, or display circadian rhythms.\nMany circadian biology studies have investigated how these rhythms vary across\ncohorts, uncovering associations between atypical rhythms and diseases such as\ncancer, metabolic syndrome, and sleep disorders. A challenge in analyzing\ncircadian biology data is that the oscillation peak and trough times for a\nphenomenon differ across individuals. If these individual-level differences are\nnot accounted for in trigonometric regression, which is prevalent in circadian\nbiology studies, then estimates of the population-level amplitude parameters\ncan suffer from attenuation bias. This attenuation bias could lead to\ninaccurate study conclusions. To address attenuation bias, we propose a refined\ntwo-stage (RTS) method for trigonometric regression given longitudinal data\nobtained from each individual participating in a study. In the first stage, the\nparameters of individual-level models are estimated. In the second stage,\ntransformations of these individual-level estimates are aggregated to produce\npopulation-level parameter estimates for inference. Simulation studies show\nthat our RTS method mitigates bias in parameter estimation, obtains greater\nstatistical power, and maintains appropriate type I error control when compared\nto the standard two-stage (STS) method, which ignores individual-level\ndifferences in peak and trough times. The only exception for parameter\nestimation and statistical power occurs when the oscillation amplitudes are\nweak relative to random variability in the data and the sample size is small.\nIllustrations with cortisol level data and heart rate data show that our RTS\nmethod obtains larger population-level amplitude parameter estimates and\nsmaller $p$-values for multiple hypothesis tests when compared to the STS\nmethod.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u4e24\u9636\u6bb5(RTS)\u4e09\u89d2\u56de\u5f52\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u663c\u591c\u8282\u5f8b\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u56e0\u5ffd\u7565\u4e2a\u4f53\u95f4\u5cf0\u503c\u65f6\u95f4\u5dee\u5f02\u800c\u5bfc\u81f4\u7684\u632f\u5e45\u53c2\u6570\u4f30\u8ba1\u504f\u5dee\u95ee\u9898\u3002", "motivation": "\u663c\u591c\u8282\u5f8b\u7814\u7a76\u4e2d\uff0c\u4e2a\u4f53\u95f4\u7684\u632f\u8361\u5cf0\u503c\u65f6\u95f4\u5b58\u5728\u5dee\u5f02\uff0c\u4f20\u7edf\u4e09\u89d2\u56de\u5f52\u65b9\u6cd5\u5ffd\u7565\u8fd9\u4e9b\u5dee\u5f02\u4f1a\u5bfc\u81f4\u7fa4\u4f53\u6c34\u5e73\u632f\u5e45\u53c2\u6570\u7684\u8870\u51cf\u504f\u5dee\uff0c\u4ece\u800c\u5f71\u54cd\u7814\u7a76\u7ed3\u8bba\u7684\u51c6\u786e\u6027\u3002", "method": "RTS\u65b9\u6cd5\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f30\u8ba1\u4e2a\u4f53\u6c34\u5e73\u6a21\u578b\u53c2\u6570\uff0c\u7b2c\u4e8c\u9636\u6bb5\u5c06\u8fd9\u4e9b\u4e2a\u4f53\u6c34\u5e73\u4f30\u8ba1\u7684\u53d8\u6362\u8fdb\u884c\u805a\u5408\uff0c\u5f97\u5230\u7fa4\u4f53\u6c34\u5e73\u53c2\u6570\u4f30\u8ba1\u7528\u4e8e\u63a8\u65ad\u3002", "result": "\u6a21\u62df\u7814\u7a76\u8868\u660e\uff0c\u4e0e\u6807\u51c6\u4e24\u9636\u6bb5(STS)\u65b9\u6cd5\u76f8\u6bd4\uff0cRTS\u65b9\u6cd5\u51cf\u8f7b\u4e86\u53c2\u6570\u4f30\u8ba1\u504f\u5dee\uff0c\u83b7\u5f97\u4e86\u66f4\u9ad8\u7684\u7edf\u8ba1\u529f\u6548\uff0c\u5e76\u4fdd\u6301\u4e86\u9002\u5f53\u7684I\u7c7b\u9519\u8bef\u63a7\u5236\u3002\u5728\u76ae\u8d28\u9187\u6c34\u5e73\u548c\u5fc3\u7387\u6570\u636e\u5e94\u7528\u4e2d\uff0cRTS\u65b9\u6cd5\u83b7\u5f97\u4e86\u66f4\u5927\u7684\u7fa4\u4f53\u6c34\u5e73\u632f\u5e45\u53c2\u6570\u4f30\u8ba1\u503c\u548c\u66f4\u5c0f\u7684p\u503c\u3002", "conclusion": "RTS\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u663c\u591c\u8282\u5f8b\u6570\u636e\u5206\u6790\u4e2d\u7684\u8870\u51cf\u504f\u5dee\u95ee\u9898\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5904\u7406\u4e2a\u4f53\u95f4\u5cf0\u503c\u65f6\u95f4\u5dee\u5f02\u7684\u60c5\u51b5\uff0c\u4e3a\u76f8\u5173\u751f\u7269\u533b\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u7edf\u8ba1\u5de5\u5177\u3002"}}
{"id": "2510.07507", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.07507", "abs": "https://arxiv.org/abs/2510.07507", "authors": ["Daniel M. Cherenson", "Dimitra Panagou"], "title": "Adaptive Control Allocation for Underactuated Time-Scale Separated Non-Affine Systems", "comment": "Code https://github.com/dcherenson/adaptive-control-underactuated", "summary": "Many robotic systems are underactuated, meaning not all degrees of freedom\ncan be directly controlled due to lack of actuators, input constraints, or\nstate-dependent actuation. This property, compounded by modeling uncertainties\nand disturbances, complicates the control design process for trajectory\ntracking. In this work, we propose an adaptive control architecture for\nuncertain, nonlinear, underactuated systems with input constraints. Leveraging\ntime-scale separation, we construct a reduced-order model where fast dynamics\nprovide virtual inputs to the slower subsystem and use dynamic control\nallocation to select the optimal control inputs given the non-affine dynamics.\nTo handle uncertainty, we introduce a state predictor-based adaptive law, and\nthrough singular perturbation theory and Lyapunov analysis, we prove stability\nand bounded tracking of reference trajectories. The proposed method is\nvalidated on a VTOL quadplane with nonlinear, state-dependent actuation,\ndemonstrating its utility as a unified controller across various flight\nregimes, including cruise, landing transition, and hover.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4e0d\u786e\u5b9a\u3001\u975e\u7ebf\u6027\u3001\u6b20\u9a71\u52a8\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u63a7\u5236\u67b6\u6784\uff0c\u901a\u8fc7\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb\u548c\u52a8\u6001\u63a7\u5236\u5206\u914d\u6765\u5904\u7406\u8f93\u5165\u7ea6\u675f\u548c\u5efa\u6a21\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u8bb8\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u662f\u6b20\u9a71\u52a8\u7684\uff0c\u8fd9\u610f\u5473\u7740\u7531\u4e8e\u7f3a\u4e4f\u6267\u884c\u5668\u3001\u8f93\u5165\u7ea6\u675f\u6216\u72b6\u6001\u76f8\u5173\u7684\u9a71\u52a8\uff0c\u65e0\u6cd5\u76f4\u63a5\u63a7\u5236\u6240\u6709\u81ea\u7531\u5ea6\u3002\u8fd9\u79cd\u7279\u6027\u52a0\u4e0a\u5efa\u6a21\u4e0d\u786e\u5b9a\u6027\u548c\u5e72\u6270\uff0c\u4f7f\u5f97\u8f68\u8ff9\u8ddf\u8e2a\u7684\u63a7\u5236\u8bbe\u8ba1\u53d8\u5f97\u590d\u6742\u3002", "method": "\u5229\u7528\u65f6\u95f4\u5c3a\u5ea6\u5206\u79bb\u6784\u5efa\u964d\u9636\u6a21\u578b\uff0c\u5176\u4e2d\u5feb\u901f\u52a8\u529b\u5b66\u4e3a\u8f83\u6162\u5b50\u7cfb\u7edf\u63d0\u4f9b\u865a\u62df\u8f93\u5165\uff0c\u5e76\u4f7f\u7528\u52a8\u6001\u63a7\u5236\u5206\u914d\u6765\u9009\u62e9\u7ed9\u5b9a\u975e\u4eff\u5c04\u52a8\u529b\u5b66\u7684\u6700\u4f18\u63a7\u5236\u8f93\u5165\u3002\u5f15\u5165\u57fa\u4e8e\u72b6\u6001\u9884\u6d4b\u5668\u7684\u81ea\u9002\u5e94\u5f8b\u6765\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u901a\u8fc7\u5947\u5f02\u6444\u52a8\u7406\u8bba\u548cLyapunov\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u53c2\u8003\u8f68\u8ff9\u7684\u7a33\u5b9a\u6027\u548c\u6709\u754c\u8ddf\u8e2a\u3002\u5728\u5177\u6709\u975e\u7ebf\u6027\u3001\u72b6\u6001\u76f8\u5173\u9a71\u52a8\u7684VTOL\u56db\u7ffc\u98de\u673a\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f5c\u4e3a\u7edf\u4e00\u63a7\u5236\u5668\u5728\u5404\u79cd\u98de\u884c\u72b6\u6001\uff08\u5305\u62ec\u5de1\u822a\u3001\u7740\u9646\u8fc7\u6e21\u548c\u60ac\u505c\uff09\u4e2d\u5c55\u793a\u4e86\u5176\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.07548", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07548", "abs": "https://arxiv.org/abs/2510.07548", "authors": ["Adam Hung", "Fan Yang", "Abhinav Kumar", "Sergio Aguilera Marinovic", "Soshi Iba", "Rana Soltani Zarrin", "Dmitry Berenson"], "title": "AVO: Amortized Value Optimization for Contact Mode Switching in Multi-Finger Manipulation", "comment": null, "summary": "Dexterous manipulation tasks often require switching between different\ncontact modes, such as rolling, sliding, sticking, or non-contact contact\nmodes. When formulating dexterous manipulation tasks as a trajectory\noptimization problem, a common approach is to decompose these tasks into\nsub-tasks for each contact mode, which are each solved independently.\nOptimizing each sub-task independently can limit performance, as optimizing\ncontact points, contact forces, or other variables without information about\nfuture sub-tasks can place the system in a state from which it is challenging\nto make progress on subsequent sub-tasks. Further, optimizing these sub-tasks\nis very computationally expensive. To address these challenges, we propose\nAmortized Value Optimization (AVO), which introduces a learned value function\nthat predicts the total future task performance. By incorporating this value\nfunction into the cost of the trajectory optimization at each planning step,\nthe value function gradients guide the optimizer toward states that minimize\nthe cost in future sub-tasks. This effectively bridges separately optimized\nsub-tasks, and accelerates the optimization by reducing the amount of online\ncomputation needed. We validate AVO on a screwdriver grasping and turning task\nin both simulation and real world experiments, and show improved performance\neven with 50% less computational budget compared to trajectory optimization\nwithout the value function.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u644a\u9500\u4ef7\u503c\u4f18\u5316(AVO)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5b66\u4e60\u4ef7\u503c\u51fd\u6570\u6765\u9884\u6d4b\u672a\u6765\u4efb\u52a1\u6027\u80fd\uff0c\u6307\u5bfc\u8f68\u8ff9\u4f18\u5316\u5668\u671d\u5411\u6709\u5229\u4e8e\u540e\u7eed\u5b50\u4efb\u52a1\u7684\u72b6\u6001\uff0c\u4ece\u800c\u89e3\u51b3\u7075\u5de7\u64cd\u4f5c\u4e2d\u63a5\u89e6\u6a21\u5f0f\u5207\u6362\u7684\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u7075\u5de7\u64cd\u4f5c\u4efb\u52a1\u9700\u8981\u5728\u4e0d\u540c\u63a5\u89e6\u6a21\u5f0f\u95f4\u5207\u6362\uff0c\u4f20\u7edf\u65b9\u6cd5\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u72ec\u7acb\u5b50\u4efb\u52a1\u5206\u522b\u4f18\u5316\uff0c\u8fd9\u9650\u5236\u4e86\u6027\u80fd\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u5f15\u5165\u5b66\u4e60\u4ef7\u503c\u51fd\u6570\u9884\u6d4b\u603b\u672a\u6765\u4efb\u52a1\u6027\u80fd\uff0c\u5c06\u5176\u7eb3\u5165\u8f68\u8ff9\u4f18\u5316\u7684\u6210\u672c\u51fd\u6570\u4e2d\uff0c\u901a\u8fc7\u4ef7\u503c\u51fd\u6570\u68af\u5ea6\u6307\u5bfc\u4f18\u5316\u5668\u671d\u5411\u6700\u5c0f\u5316\u672a\u6765\u5b50\u4efb\u52a1\u6210\u672c\u7684\u72b6\u6001\u3002", "result": "\u5728\u87ba\u4e1d\u5200\u6293\u53d6\u548c\u8f6c\u52a8\u4efb\u52a1\u4e2d\u9a8c\u8bc1\uff0c\u5373\u4f7f\u8ba1\u7b97\u9884\u7b97\u51cf\u5c1150%\uff0c\u76f8\u6bd4\u65e0\u4ef7\u503c\u51fd\u6570\u7684\u8f68\u8ff9\u4f18\u5316\u4ecd\u80fd\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "AVO\u6709\u6548\u6865\u63a5\u72ec\u7acb\u4f18\u5316\u7684\u5b50\u4efb\u52a1\uff0c\u52a0\u901f\u4f18\u5316\u8fc7\u7a0b\u5e76\u51cf\u5c11\u5728\u7ebf\u8ba1\u7b97\u9700\u6c42\u3002"}}
{"id": "2510.08190", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.08190", "abs": "https://arxiv.org/abs/2510.08190", "authors": ["Abdou Majeed Alidou", "J\u00falia Balig\u00e1cs", "Jan H\u0105z\u0142a"], "title": "Geometric opinion exchange polarizes in every dimension", "comment": null, "summary": "A recent line of work studies models of opinion exchange where agent opinions\nabout $d$ topics are tracked simultaneously. The opinions are represented as\nvectors on the unit $(d-1)$-sphere, and the update rule is based on the overall\ncorrelation between the relevant vectors. The update rule reflects the\nassumption of biased assimilation, i.e., a pair of opinions is brought closer\ntogether if their correlation is positive and further apart if the correlation\nis negative.\n  This model seems to induce the polarization of opinions into two antipodal\ngroups. This is in contrast to many other known models which tend to achieve\nconsensus. The polarization property has been recently proved for $d=2$, but\nthe general case of $d \\ge 3$ remained open. In this work, we settle the\ngeneral case, using a more detailed understanding of the model dynamics and\ntools from the theory of random processes.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u4e2a\u591a\u4e3b\u9898\u610f\u89c1\u4ea4\u6362\u6a21\u578b\uff0c\u5176\u4e2d\u4ee3\u7406\u4eba\u7684\u610f\u89c1\u88ab\u8868\u793a\u4e3a\u5355\u4f4d\u7403\u9762\u4e0a\u7684\u5411\u91cf\u3002\u8be5\u6a21\u578b\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u66f4\u65b0\u89c4\u5219\u4f1a\u5bfc\u81f4\u610f\u89c1\u6781\u5316\u5230\u4e24\u4e2a\u5bf9\u7acb\u7fa4\u4f53\uff0c\u8fd9\u4e0e\u8bb8\u591a\u8fbe\u6210\u5171\u8bc6\u7684\u6a21\u578b\u4e0d\u540c\u3002\u4f5c\u8005\u89e3\u51b3\u4e86d\u22653\u60c5\u51b5\u4e0b\u6781\u5316\u6027\u8d28\u8bc1\u660e\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\uff0c\u5728\u591a\u4e3b\u9898\u610f\u89c1\u4ea4\u6362\u6a21\u578b\u4e2d\uff0c\u57fa\u4e8e\u76f8\u5173\u6027\uff08\u6b63\u76f8\u5173\u62c9\u8fd1\u3001\u8d1f\u76f8\u5173\u63a8\u8fdc\uff09\u7684\u66f4\u65b0\u89c4\u5219\u4f1a\u5bfc\u81f4\u610f\u89c1\u6781\u5316\uff0c\u8fd9\u4e0e\u4f20\u7edf\u8fbe\u6210\u5171\u8bc6\u7684\u6a21\u578b\u5f62\u6210\u5bf9\u6bd4\u3002\u867d\u7136d=2\u7684\u60c5\u51b5\u5df2\u88ab\u8bc1\u660e\uff0c\u4f46d\u22653\u7684\u4e00\u822c\u60c5\u51b5\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u66f4\u6df1\u5165\u5730\u7406\u89e3\u6a21\u578b\u52a8\u529b\u5b66\uff0c\u5e76\u8fd0\u7528\u968f\u673a\u8fc7\u7a0b\u7406\u8bba\u5de5\u5177\uff0c\u5206\u6790\u4e86\u591a\u7ef4\u5ea6\u610f\u89c1\u5411\u91cf\u5728\u5355\u4f4d\u7403\u9762\u4e0a\u7684\u6f14\u5316\u8fc7\u7a0b\u3002", "result": "\u7814\u7a76\u8bc1\u660e\uff0c\u5bf9\u4e8e\u4efb\u610f\u7ef4\u5ea6d\u22653\uff0c\u8be5\u610f\u89c1\u4ea4\u6362\u6a21\u578b\u786e\u5b9e\u4f1a\u5bfc\u81f4\u610f\u89c1\u6781\u5316\u5230\u4e24\u4e2a\u5bf9\u7acb\u7fa4\u4f53\uff0c\u5373\u610f\u89c1\u5411\u91cf\u6700\u7ec8\u4f1a\u6536\u655b\u5230\u4e24\u4e2a\u76f8\u53cd\u7684\u65b9\u5411\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5b8c\u6574\u5730\u89e3\u51b3\u4e86\u591a\u4e3b\u9898\u610f\u89c1\u4ea4\u6362\u6a21\u578b\u4e2d\u6781\u5316\u6027\u8d28\u7684\u4e00\u822c\u60c5\u51b5\u8bc1\u660e\uff0c\u786e\u8ba4\u4e86\u8be5\u6a21\u578b\u5728\u4efb\u610f\u7ef4\u5ea6\u4e0b\u90fd\u4f1a\u4ea7\u751f\u610f\u89c1\u6781\u5316\u73b0\u8c61\uff0c\u4e3a\u7406\u89e3\u793e\u4f1a\u7f51\u7edc\u4e2d\u7684\u610f\u89c1\u5206\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2510.07519", "categories": ["cs.CY", "H.4.0; J.1"], "pdf": "https://arxiv.org/pdf/2510.07519", "abs": "https://arxiv.org/abs/2510.07519", "authors": ["Juan E. G\u00f3mez-Morantes", "Andrea Herrera", "Sonia Camacho"], "title": "Digital Innovation in Microenterprises: Current Trends and New Research Avenues", "comment": null, "summary": "The relationship between microenterprises and information and communication\ntechnologies (ICTs) has always been troublesome. Because of the rapid pace of\nmodern digital technologies, digital innovation processes are permeating the\nindustries, markets, and social contexts in which microenterprises exist today.\nHowever, microenterprises have severe difficulties engaging or performing in\nthese digital contexts and are at risk of being left behind. This paper reviews\nthe literature on ICTs and microenterprises, focusing on the adoption, usage,\nand impact of ICTs. The results indicate that further research in this field\nshould avoid focusing on individual microenterprises (or samples of independent\nmicroenterprises) as the unit of analysis and should favour a systemic approach\nin which markets, value chains, or microenterprise-intensive sectors are\nstudied. Additionally, theoretical frameworks capable of considering change and\nthe dynamic nature of innovation processes are highlighted as a critical focus\narea for the field.", "AI": {"tldr": "\u8bba\u6587\u56de\u987e\u4e86ICT\u4e0e\u5fae\u578b\u4f01\u4e1a\u5173\u7cfb\u7684\u6587\u732e\uff0c\u6307\u51fa\u5fae\u578b\u4f01\u4e1a\u5728\u6570\u5b57\u73af\u5883\u4e2d\u9762\u4e34\u56f0\u96be\uff0c\u5efa\u8bae\u672a\u6765\u7814\u7a76\u5e94\u91c7\u7528\u7cfb\u7edf\u6027\u65b9\u6cd5\u800c\u975e\u4e2a\u4f53\u5206\u6790\uff0c\u5e76\u5173\u6ce8\u52a8\u6001\u521b\u65b0\u8fc7\u7a0b\u7684\u7406\u8bba\u6846\u67b6\u3002", "motivation": "\u7531\u4e8e\u73b0\u4ee3\u6570\u5b57\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u6570\u5b57\u521b\u65b0\u8fc7\u7a0b\u6b63\u5728\u6e17\u900f\u5230\u5fae\u578b\u4f01\u4e1a\u6240\u5728\u7684\u884c\u4e1a\u3001\u5e02\u573a\u548c\u793e\u4f1a\u73af\u5883\u4e2d\uff0c\u4f46\u5fae\u578b\u4f01\u4e1a\u5728\u8fd9\u4e9b\u6570\u5b57\u73af\u5883\u4e2d\u9762\u4e34\u4e25\u91cd\u56f0\u96be\uff0c\u6709\u88ab\u8fb9\u7f18\u5316\u7684\u98ce\u9669\u3002", "method": "\u672c\u6587\u56de\u987e\u4e86\u5173\u4e8eICT\u4e0e\u5fae\u578b\u4f01\u4e1a\u7684\u6587\u732e\uff0c\u91cd\u70b9\u5173\u6ce8ICT\u7684\u91c7\u7528\u3001\u4f7f\u7528\u548c\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u5e94\u907f\u514d\u5c06\u5355\u4e2a\u5fae\u578b\u4f01\u4e1a\u4f5c\u4e3a\u5206\u6790\u5355\u4f4d\uff0c\u800c\u5e94\u91c7\u7528\u7cfb\u7edf\u6027\u65b9\u6cd5\u7814\u7a76\u5e02\u573a\u3001\u4ef7\u503c\u94fe\u6216\u5fae\u578b\u4f01\u4e1a\u5bc6\u96c6\u578b\u884c\u4e1a\u3002", "conclusion": "\u9700\u8981\u80fd\u591f\u8003\u8651\u53d8\u5316\u548c\u521b\u65b0\u8fc7\u7a0b\u52a8\u6001\u6027\u8d28\u7684\u7406\u8bba\u6846\u67b6\uff0c\u8fd9\u662f\u8be5\u9886\u57df\u7684\u5173\u952e\u91cd\u70b9\u9886\u57df\u3002"}}
{"id": "2510.07675", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.07675", "abs": "https://arxiv.org/abs/2510.07675", "authors": ["Romeo Ortega", "Leyan Fang", "Jose Guadalupe Romero"], "title": "Some Reflections on Sliding Mode Designs in Control Systems: An Example of Adaptive Tracking Control for Simple Mechanical Systems With Friction Without Measurement of Velocity", "comment": null, "summary": "The objective of this note is to share some reflections of the authors\nregarding the use of sliding mode designs in control systems. We believe the\nabundant, and ever increasing, appearance of this kind of works on our\nscientific publications deserves some critical evaluation of their actual role,\nrelevance and pertinence. First, we discuss the procedure followed by most of\nthese designs -- illustrated with examples from the literature. Second, we\nbring to the readers attention several aspects of the control problem, central\nin classical designs, which are disregarded in the sliding mode literature.\nFinally, to illustrate with an specific example our previous considerations, we\ncompare the performance of two adaptive tracking controllers for a simple one\ndegree of freedom mechanical systems with unknown parameters and static and\nCoulomb friction -- that do not rely on the measurement of velocity.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6ed1\u6a21\u63a7\u5236\u5728\u63a7\u5236\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u6279\u5224\u6027\u53cd\u601d\uff0c\u6307\u51fa\u5f53\u524d\u6587\u732e\u4e2d\u5b58\u5728\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5177\u4f53\u4f8b\u5b50\u6bd4\u8f83\u4e86\u4e24\u79cd\u81ea\u9002\u5e94\u8ddf\u8e2a\u63a7\u5236\u5668\u7684\u6027\u80fd\u3002", "motivation": "\u4f5c\u8005\u8ba4\u4e3a\u6ed1\u6a21\u63a7\u5236\u5728\u79d1\u5b66\u51fa\u7248\u7269\u4e2d\u7684\u5927\u91cf\u51fa\u73b0\u9700\u8981\u8fdb\u884c\u6279\u5224\u6027\u8bc4\u4f30\uff0c\u4ee5\u5ba1\u89c6\u5176\u5b9e\u9645\u4f5c\u7528\u3001\u76f8\u5173\u6027\u548c\u9002\u7528\u6027\u3002", "method": "\u9996\u5148\u8ba8\u8bba\u5927\u591a\u6570\u6ed1\u6a21\u8bbe\u8ba1\u9075\u5faa\u7684\u7a0b\u5e8f\uff0c\u5e76\u5f15\u7528\u6587\u732e\u4e2d\u7684\u4f8b\u5b50\uff1b\u5176\u6b21\u6307\u51fa\u6ed1\u6a21\u6587\u732e\u4e2d\u5ffd\u89c6\u7684\u63a7\u5236\u95ee\u9898\u5173\u952e\u65b9\u9762\uff1b\u6700\u540e\u901a\u8fc7\u6bd4\u8f83\u4e24\u79cd\u81ea\u9002\u5e94\u8ddf\u8e2a\u63a7\u5236\u5668\u5728\u5355\u81ea\u7531\u5ea6\u673a\u68b0\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\u6765\u5177\u4f53\u8bf4\u660e\u3002", "result": "\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\uff0c\u63ed\u793a\u4e86\u6ed1\u6a21\u63a7\u5236\u8bbe\u8ba1\u4e2d\u53ef\u80fd\u5b58\u5728\u7684\u95ee\u9898\u548c\u5c40\u9650\u6027\u3002", "conclusion": "\u6ed1\u6a21\u63a7\u5236\u8bbe\u8ba1\u9700\u8981\u66f4\u5168\u9762\u7684\u8003\u8651\uff0c\u5305\u62ec\u7ecf\u5178\u63a7\u5236\u8bbe\u8ba1\u4e2d\u91cd\u89c6\u4f46\u88ab\u6ed1\u6a21\u6587\u732e\u5ffd\u89c6\u7684\u5173\u952e\u65b9\u9762\u3002"}}
{"id": "2510.07611", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07611", "abs": "https://arxiv.org/abs/2510.07611", "authors": ["Jingyang You", "Hanna Kurniawati", "Lashika Medagoda"], "title": "Inspection Planning Primitives with Implicit Models", "comment": null, "summary": "The aging and increasing complexity of infrastructures make efficient\ninspection planning more critical in ensuring safety. Thanks to sampling-based\nmotion planning, many inspection planners are fast. However, they often require\nhuge memory. This is particularly true when the structure under inspection is\nlarge and complex, consisting of many struts and pillars of various geometry\nand sizes. Such structures can be represented efficiently using implicit\nmodels, such as neural Signed Distance Functions (SDFs). However, most\nprimitive computations used in sampling-based inspection planner have been\ndesigned to work efficiently with explicit environment models, which in turn\nrequires the planner to use explicit environment models or performs frequent\ntransformations between implicit and explicit environment models during\nplanning. This paper proposes a set of primitive computations, called\nInspection Planning Primitives with Implicit Models (IPIM), that enable\nsampling-based inspection planners to entirely use neural SDFs representation\nduring planning. Evaluation on three scenarios, including inspection of a\ncomplex real-world structure with over 92M triangular mesh faces, indicates\nthat even a rudimentary sampling-based planner with IPIM can generate\ninspection trajectories of similar quality to those generated by the\nstate-of-the-art planner, while using up to 70x less memory than the\nstate-of-the-art inspection planner.", "AI": {"tldr": "\u63d0\u51fa\u4e86IPIM\u539f\u8bed\u8ba1\u7b97\uff0c\u4f7f\u57fa\u4e8e\u91c7\u6837\u7684\u68c0\u6d4b\u89c4\u5212\u5668\u80fd\u591f\u5b8c\u5168\u4f7f\u7528\u795e\u7ecfSDF\u8868\u793a\uff0c\u5728\u4fdd\u6301\u8f68\u8ff9\u8d28\u91cf\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\uff08\u6700\u9ad8\u8fbe70\u500d\uff09\u3002", "motivation": "\u57fa\u7840\u8bbe\u65bd\u8001\u5316\u590d\u6742\u5316\u4f7f\u5f97\u9ad8\u6548\u68c0\u6d4b\u89c4\u5212\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u57fa\u4e8e\u91c7\u6837\u7684\u68c0\u6d4b\u89c4\u5212\u5668\u867d\u7136\u5feb\u901f\u4f46\u5185\u5b58\u6d88\u8017\u5927\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5927\u578b\u590d\u6742\u7ed3\u6784\u3002\u9690\u5f0f\u6a21\u578b\uff08\u5982\u795e\u7ecfSDFs\uff09\u80fd\u9ad8\u6548\u8868\u793a\u590d\u6742\u7ed3\u6784\uff0c\u4f46\u73b0\u6709\u89c4\u5212\u5668\u4e3b\u8981\u8bbe\u8ba1\u7528\u4e8e\u663e\u5f0f\u6a21\u578b\u3002", "method": "\u63d0\u51faIPIM\uff08Inspection Planning Primitives with Implicit Models\uff09\u539f\u8bed\u8ba1\u7b97\u96c6\uff0c\u4f7f\u57fa\u4e8e\u91c7\u6837\u7684\u68c0\u6d4b\u89c4\u5212\u5668\u80fd\u591f\u5b8c\u5168\u4f7f\u7528\u795e\u7ecfSDFs\u8868\u793a\u8fdb\u884c\u89c4\u5212\uff0c\u65e0\u9700\u5728\u9690\u5f0f\u548c\u663e\u5f0f\u6a21\u578b\u95f4\u9891\u7e41\u8f6c\u6362\u3002", "result": "\u5728\u4e09\u4e2a\u573a\u666f\uff08\u5305\u62ec\u5305\u542b9200\u4e07\u4e09\u89d2\u7f51\u683c\u9762\u7684\u771f\u5b9e\u590d\u6742\u7ed3\u6784\uff09\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u5373\u4f7f\u57fa\u672c\u7684\u57fa\u4e8e\u91c7\u6837\u89c4\u5212\u5668\u4f7f\u7528IPIM\u4e5f\u80fd\u751f\u6210\u4e0e\u6700\u5148\u8fdb\u89c4\u5212\u5668\u8d28\u91cf\u76f8\u5f53\u7684\u68c0\u6d4b\u8f68\u8ff9\uff0c\u540c\u65f6\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u9ad8\u8fbe70\u500d\u3002", "conclusion": "IPIM\u4f7f\u57fa\u4e8e\u91c7\u6837\u7684\u68c0\u6d4b\u89c4\u5212\u5668\u80fd\u591f\u6709\u6548\u5229\u7528\u795e\u7ecfSDFs\u8868\u793a\uff0c\u5728\u4fdd\u6301\u8f68\u8ff9\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5185\u5b58\u9700\u6c42\uff0c\u4e3a\u5927\u578b\u590d\u6742\u7ed3\u6784\u7684\u68c0\u6d4b\u89c4\u5212\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08481", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.08481", "abs": "https://arxiv.org/abs/2510.08481", "authors": ["Yifei Xu", "Jiaying Wu", "Herun Wan", "Yang Li", "Zhen Hou", "Min-Yen Kan"], "title": "Forecasting the Buzz: Enriching Hashtag Popularity Prediction with LLM Reasoning", "comment": "Accepted to CIKM 2025", "summary": "Hashtag trends ignite campaigns, shift public opinion, and steer millions of\ndollars in advertising spend, yet forecasting which tag goes viral is elusive.\nClassical regressors digest surface features but ignore context, while large\nlanguage models (LLMs) excel at contextual reasoning but misestimate numbers.\nWe present BuzzProphet, a reasoning-augmented hashtag popularity prediction\nframework that (1) instructs an LLM to articulate a hashtag's topical virality,\naudience reach, and timing advantage; (2) utilizes these popularity-oriented\nrationales to enrich the input features; and (3) regresses on these inputs. To\nfacilitate evaluation, we release HashView, a 7,532-hashtag benchmark curated\nfrom social media. Across diverse regressor-LLM combinations, BuzzProphet\nreduces RMSE by up to 2.8% and boosts correlation by 30% over baselines, while\nproducing human-readable rationales. Results demonstrate that using LLMs as\ncontext reasoners rather than numeric predictors injects domain insight into\ntabular models, yielding an interpretable and deployable solution for social\nmedia trend forecasting.", "AI": {"tldr": "BuzzProphet\u662f\u4e00\u4e2a\u7ed3\u5408LLM\u63a8\u7406\u80fd\u529b\u7684\u6807\u7b7e\u6d41\u884c\u5ea6\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u8ba9LLM\u5206\u6790\u6807\u7b7e\u7684\u75c5\u6bd2\u6027\u3001\u53d7\u4f17\u8303\u56f4\u548c\u65f6\u673a\u4f18\u52bf\u6765\u589e\u5f3a\u7279\u5f81\uff0c\u5728HashView\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u5ffd\u7565\u4e0a\u4e0b\u6587\uff08\u4f20\u7edf\u56de\u5f52\u5668\uff09\uff0c\u8981\u4e48\u4e0d\u64c5\u957f\u6570\u503c\u4f30\u8ba1\uff08LLM\uff09\uff0c\u9700\u8981\u7ed3\u5408\u4e24\u8005\u7684\u4f18\u52bf\u6765\u51c6\u786e\u9884\u6d4b\u6807\u7b7e\u6d41\u884c\u5ea6\u3002", "method": "1) \u8ba9LLM\u751f\u6210\u6807\u7b7e\u7684\u6d41\u884c\u5ea6\u76f8\u5173\u63a8\u7406\uff1b2) \u7528\u8fd9\u4e9b\u63a8\u7406\u589e\u5f3a\u8f93\u5165\u7279\u5f81\uff1b3) \u57fa\u4e8e\u589e\u5f3a\u7279\u5f81\u8fdb\u884c\u56de\u5f52\u9884\u6d4b\u3002", "result": "\u57287,532\u4e2a\u6807\u7b7e\u7684HashView\u57fa\u51c6\u4e0a\uff0cBuzzProphet\u5c06RMSE\u964d\u4f4e\u8fbe2.8%\uff0c\u76f8\u5173\u6027\u63d0\u534730%\uff0c\u540c\u65f6\u751f\u6210\u53ef\u8bfb\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "conclusion": "\u5c06LLM\u7528\u4f5c\u4e0a\u4e0b\u6587\u63a8\u7406\u5668\u800c\u975e\u6570\u503c\u9884\u6d4b\u5668\uff0c\u80fd\u591f\u4e3a\u8868\u683c\u6a21\u578b\u6ce8\u5165\u9886\u57df\u77e5\u8bc6\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u4e14\u53ef\u90e8\u7f72\u7684\u793e\u4ea4\u5a92\u4f53\u8d8b\u52bf\u9884\u6d4b\u65b9\u6848\u3002"}}
{"id": "2510.07634", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.07634", "abs": "https://arxiv.org/abs/2510.07634", "authors": ["Nara Guliyeva", "Eshta Bhardwaj", "Christoph Becker"], "title": "Exploring the Viability of the Updated World3 Model for Examining the Impact of Computing on Planetary Boundaries", "comment": "Post-proceedings paper presented at LIMITS 2025: 11th Workshop on\n  Computing within Limits, 2025-06-26/27, Online", "summary": "The influential Limits to Growth report introduced a system dynamics-based\nmodel to demonstrate global dynamics of the world's population, industry,\nnatural resources, agriculture, and pollution between 1900-2100. In current\ntimes, the rapidly expanding trajectory of data center development, much of it\nlinked to AI, uses increasing amounts of natural resources. The extraordinary\namount of resources claimed warrants the question of how computing trajectories\ncontribute to exceeding planetary boundaries. Based on the general robustness\nof the World3-03 model and its influence in serving as a foundation for current\nclimate frameworks, we explore whether the model is a viable method to\nquantitatively simulate the impact of data centers on limits to growth. Our\npaper explores whether the World3-03 model is a feasible method for reflecting\non these dynamics by adding new variables to the model in order to simulate a\nnew AI-augmented scenario. We find that through our addition of AI-related\nvariables (such as increasing data center development) impacting pollution in\nthe World3-03 model, we can observe the expected changes to dynamics,\ndemonstrating the viability of the World3-03 model for examining AI's impact on\nplanetary boundaries. We detail future research opportunities for using the\nWorld3-03 model to explore the relationships between increasing\nresource-intensive computing and the resulting impacts to the environment in a\nquantitative way given its feasibility.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4f7f\u7528World3-03\u7cfb\u7edf\u52a8\u529b\u5b66\u6a21\u578b\u6765\u5b9a\u91cf\u6a21\u62df\u6570\u636e\u4e2d\u5fc3\u548cAI\u53d1\u5c55\u5bf9\u5730\u7403\u8fb9\u754c\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u6dfb\u52a0AI\u76f8\u5173\u53d8\u91cf\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u968f\u7740\u6570\u636e\u4e2d\u5fc3\u548cAI\u7684\u5feb\u901f\u53d1\u5c55\u6d88\u8017\u5927\u91cf\u81ea\u7136\u8d44\u6e90\uff0c\u9700\u8981\u8bc4\u4f30\u8ba1\u7b97\u53d1\u5c55\u8f68\u8ff9\u5982\u4f55\u5f71\u54cd\u884c\u661f\u8fb9\u754c\uff0c\u57fa\u4e8eWorld3-03\u6a21\u578b\u7684\u7a33\u5065\u6027\u548c\u5728\u6c14\u5019\u6846\u67b6\u4e2d\u7684\u57fa\u7840\u5730\u4f4d\u3002", "method": "\u5728World3-03\u6a21\u578b\u4e2d\u6dfb\u52a0\u65b0\u7684AI\u76f8\u5173\u53d8\u91cf\uff08\u5982\u6570\u636e\u4e2d\u5fc3\u53d1\u5c55\uff09\uff0c\u521b\u5efaAI\u589e\u5f3a\u60c5\u666f\u6765\u6a21\u62df\u5bf9\u6c61\u67d3\u7b49\u7cfb\u7edf\u52a8\u6001\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u6dfb\u52a0AI\u76f8\u5173\u53d8\u91cf\uff0c\u89c2\u5bdf\u5230\u6a21\u578b\u52a8\u6001\u7684\u9884\u671f\u53d8\u5316\uff0c\u8bc1\u660e\u4e86World3-03\u6a21\u578b\u53ef\u7528\u4e8e\u5b9a\u91cf\u7814\u7a76AI\u5bf9\u884c\u661f\u8fb9\u754c\u7684\u5f71\u54cd\u3002", "conclusion": "World3-03\u6a21\u578b\u662f\u7814\u7a76\u8d44\u6e90\u5bc6\u96c6\u578b\u8ba1\u7b97\u4e0e\u73af\u5883\u5f71\u54cd\u5173\u7cfb\u7684\u53ef\u884c\u5de5\u5177\uff0c\u4e3a\u672a\u6765\u5b9a\u91cf\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.07708", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.07708", "abs": "https://arxiv.org/abs/2510.07708", "authors": ["Asaad Abdul-Hamid", "Brycen D. Pearl", "Hang Woon Lee", "Hao Chen"], "title": "Space Logistics Analysis and Incentive Design for Commercialization of Orbital Debris Remediation", "comment": "28 pages, 14 figures, Journal of Spacecraft and Rockets (Articles in\n  Advance)", "summary": "As orbital debris continues to become a higher priority for the space\nindustry, there is a need to explore how partnerships between the public and\nprivate space sector may aid in addressing this issue. This research develops a\nspace logistics framework for planning orbital debris remediation missions,\nproviding a quantitative basis for partnerships that are mutually beneficial\nbetween space operators and debris remediators. By integrating network-based\nspace logistics and game theory, we illuminate the high-level costs of\nremediating orbital debris, and the surplus that stands to be shared as a\nresult. These findings indicate significant progress toward the continued\ndevelopment of a safe, sustainable, and profitable space economy.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7a7a\u95f4\u7269\u6d41\u6846\u67b6\uff0c\u7528\u4e8e\u89c4\u5212\u8f68\u9053\u788e\u7247\u6e05\u7406\u4efb\u52a1\uff0c\u4e3a\u7a7a\u95f4\u8fd0\u8425\u5546\u548c\u788e\u7247\u6e05\u7406\u8005\u4e4b\u95f4\u7684\u4e92\u5229\u5408\u4f5c\u63d0\u4f9b\u5b9a\u91cf\u57fa\u7840\u3002", "motivation": "\u968f\u7740\u8f68\u9053\u788e\u7247\u95ee\u9898\u65e5\u76ca\u6210\u4e3a\u7a7a\u95f4\u884c\u4e1a\u7684\u4f18\u5148\u4e8b\u9879\uff0c\u9700\u8981\u63a2\u7d22\u516c\u79c1\u5408\u4f5c\u5982\u4f55\u5e2e\u52a9\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6574\u5408\u57fa\u4e8e\u7f51\u7edc\u7684\u7a7a\u95f4\u7269\u6d41\u548c\u535a\u5f08\u8bba\uff0c\u5206\u6790\u8f68\u9053\u788e\u7247\u6e05\u7406\u7684\u9ad8\u5c42\u6210\u672c\u548c\u53ef\u5171\u4eab\u7684\u5269\u4f59\u4ef7\u503c\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\u4e86\u5728\u5f00\u53d1\u5b89\u5168\u3001\u53ef\u6301\u7eed\u4e14\u6709\u5229\u53ef\u56fe\u7684\u7a7a\u95f4\u7ecf\u6d4e\u65b9\u9762\u53d6\u5f97\u7684\u663e\u8457\u8fdb\u5c55\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7a7a\u95f4\u8fd0\u8425\u5546\u548c\u788e\u7247\u6e05\u7406\u8005\u4e4b\u95f4\u7684\u4e92\u5229\u5408\u4f5c\u63d0\u4f9b\u4e86\u5b9a\u91cf\u57fa\u7840\uff0c\u63a8\u52a8\u7a7a\u95f4\u7ecf\u6d4e\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u3002"}}
{"id": "2510.07625", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.07625", "abs": "https://arxiv.org/abs/2510.07625", "authors": ["Alexander Du", "Emre Adabag", "Gabriel Bravo", "Brian Plancher"], "title": "GATO: GPU-Accelerated and Batched Trajectory Optimization for Scalable Edge Model Predictive Control", "comment": null, "summary": "While Model Predictive Control (MPC) delivers strong performance across\nrobotics applications, solving the underlying (batches of) nonlinear trajectory\noptimization (TO) problems online remains computationally demanding. Existing\nGPU-accelerated approaches typically (i) parallelize a single solve to meet\nreal-time deadlines, (ii) scale to very large batches at slower-than-real-time\nrates, or (iii) achieve speed by restricting model generality (e.g., point-mass\ndynamics or a single linearization). This leaves a large gap in solver\nperformance for many state-of-the-art MPC applications that require real-time\nbatches of tens to low-hundreds of solves. As such, we present GATO, an open\nsource, GPU-accelerated, batched TO solver co-designed across algorithm,\nsoftware, and computational hardware to deliver real-time throughput for these\nmoderate batch size regimes. Our approach leverages a combination of block-,\nwarp-, and thread-level parallelism within and across solves for ultra-high\nperformance. We demonstrate the effectiveness of our approach through a\ncombination of: simulated benchmarks showing speedups of 18-21x over CPU\nbaselines and 1.4-16x over GPU baselines as batch size increases; case studies\nhighlighting improved disturbance rejection and convergence behavior; and\nfinally a validation on hardware using an industrial manipulator. We open\nsource GATO to support reproducibility and adoption.", "AI": {"tldr": "GATO\u662f\u4e00\u4e2a\u5f00\u6e90GPU\u52a0\u901f\u7684\u6279\u91cf\u8f68\u8ff9\u4f18\u5316\u6c42\u89e3\u5668\uff0c\u4e13\u4e3a\u4e2d\u7b49\u6279\u91cf\u89c4\u6a21\uff08\u51e0\u5341\u5230\u51e0\u767e\u4e2a\u6c42\u89e3\uff09\u7684\u5b9e\u65f6MPC\u5e94\u7528\u8bbe\u8ba1\uff0c\u76f8\u6bd4CPU\u57fa\u7ebf\u5b9e\u73b018-21\u500d\u52a0\u901f\uff0c\u76f8\u6bd4GPU\u57fa\u7ebf\u5b9e\u73b01.4-16\u500d\u52a0\u901f\u3002", "motivation": "\u73b0\u6709GPU\u52a0\u901f\u65b9\u6cd5\u8981\u4e48\u5e76\u884c\u5316\u5355\u4e2a\u6c42\u89e3\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u8981\u6c42\uff0c\u8981\u4e48\u4ee5\u6162\u4e8e\u5b9e\u65f6\u7684\u901f\u7387\u6269\u5c55\u5230\u975e\u5e38\u5927\u7684\u6279\u91cf\uff0c\u8981\u4e48\u901a\u8fc7\u9650\u5236\u6a21\u578b\u901a\u7528\u6027\u6765\u5b9e\u73b0\u901f\u5ea6\u3002\u8fd9\u4e3a\u9700\u8981\u5b9e\u65f6\u6279\u91cf\u6c42\u89e3\u7684\u73b0\u4ee3MPC\u5e94\u7528\u7559\u4e0b\u4e86\u6027\u80fd\u7a7a\u767d\u3002", "method": "GATO\u91c7\u7528\u7b97\u6cd5\u3001\u8f6f\u4ef6\u548c\u8ba1\u7b97\u786c\u4ef6\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u5229\u7528\u5757\u7ea7\u3001warp\u7ea7\u548c\u7ebf\u7a0b\u7ea7\u5e76\u884c\u6027\u5728\u6c42\u89e3\u5185\u90e8\u548c\u8de8\u6c42\u89e3\u4e4b\u95f4\u5b9e\u73b0\u8d85\u9ad8\u6027\u80fd\u3002", "result": "\u6a21\u62df\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u968f\u7740\u6279\u91cf\u5927\u5c0f\u589e\u52a0\uff0c\u76f8\u6bd4CPU\u57fa\u7ebf\u5b9e\u73b018-21\u500d\u52a0\u901f\uff0c\u76f8\u6bd4GPU\u57fa\u7ebf\u5b9e\u73b01.4-16\u500d\u52a0\u901f\u3002\u6848\u4f8b\u7814\u7a76\u663e\u793a\u6539\u8fdb\u7684\u6270\u52a8\u6291\u5236\u548c\u6536\u655b\u884c\u4e3a\uff0c\u5e76\u5728\u5de5\u4e1a\u673a\u68b0\u81c2\u4e0a\u8fdb\u884c\u4e86\u786c\u4ef6\u9a8c\u8bc1\u3002", "conclusion": "GATO\u586b\u8865\u4e86\u4e2d\u7b49\u6279\u91cf\u89c4\u6a21\u5b9e\u65f6MPC\u6c42\u89e3\u5668\u7684\u6027\u80fd\u7a7a\u767d\uff0c\u901a\u8fc7\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5f00\u6e90\u4ee5\u652f\u6301\u53ef\u91cd\u590d\u6027\u548c\u91c7\u7528\u3002"}}
{"id": "2510.08246", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.08246", "abs": "https://arxiv.org/abs/2510.08246", "authors": ["Joost Poort", "Frederik J. Zuiderveen Borgesius"], "title": "Does everyone have a price? Understanding people's attitude towards online and offline price discrimination", "comment": null, "summary": "Online stores can present a different price to each customer. Such\nalgorithmic personalised pricing can lead to advanced forms of price\ndiscrimination based on the characteristics and behaviour of individual\nconsumers. We conducted two consumer surveys among a representative sample of\nthe Dutch population (N=1233 and N=1202), to analyse consumer attitudes towards\na list of examples of price discrimination and dynamic pricing. A vast majority\nfinds online price discrimination unfair and unacceptable, and thinks it should\nbe banned. However, some pricing strategies that have been used by companies\nfor decades are almost equally unpopular. We analyse the results to better\nunderstand why people dislike many types of price discrimination.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u4e24\u9879\u6d88\u8d39\u8005\u8c03\u67e5\u5206\u6790\u8377\u5170\u6c11\u4f17\u5bf9\u5728\u7ebf\u4ef7\u683c\u6b67\u89c6\u548c\u52a8\u6001\u5b9a\u4ef7\u7684\u6001\u5ea6\uff0c\u53d1\u73b0\u7edd\u5927\u591a\u6570\u4eba\u8ba4\u4e3a\u5728\u7ebf\u4ef7\u683c\u6b67\u89c6\u4e0d\u516c\u5e73\u4e14\u4e0d\u53ef\u63a5\u53d7\uff0c\u5e94\u88ab\u7981\u6b62\uff0c\u4f46\u4e00\u4e9b\u4f20\u7edf\u5b9a\u4ef7\u7b56\u7565\u540c\u6837\u4e0d\u53d7\u6b22\u8fce\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u4e86\u89e3\u6d88\u8d39\u8005\u5bf9\u7b97\u6cd5\u4e2a\u6027\u5316\u5b9a\u4ef7\u548c\u4ef7\u683c\u6b67\u89c6\u7684\u6001\u5ea6\uff0c\u56e0\u4e3a\u5728\u7ebf\u5546\u5e97\u53ef\u4ee5\u5411\u6bcf\u4f4d\u987e\u5ba2\u5c55\u793a\u4e0d\u540c\u4ef7\u683c\uff0c\u8fd9\u79cd\u57fa\u4e8e\u6d88\u8d39\u8005\u7279\u5f81\u548c\u884c\u4e3a\u7684\u7b97\u6cd5\u4e2a\u6027\u5316\u5b9a\u4ef7\u53ef\u80fd\u5bfc\u81f4\u9ad8\u7ea7\u5f62\u5f0f\u7684\u6b67\u89c6\u3002", "method": "\u5bf9\u8377\u5170\u4ee3\u8868\u6027\u4eba\u53e3\u6837\u672c\u8fdb\u884c\u4e24\u9879\u6d88\u8d39\u8005\u8c03\u67e5\uff08N=1233\u548cN=1202\uff09\uff0c\u5206\u6790\u6d88\u8d39\u8005\u5bf9\u4e00\u7cfb\u5217\u4ef7\u683c\u6b67\u89c6\u548c\u52a8\u6001\u5b9a\u4ef7\u793a\u4f8b\u7684\u6001\u5ea6\u3002", "result": "\u7edd\u5927\u591a\u6570\u53d7\u8bbf\u8005\u8ba4\u4e3a\u5728\u7ebf\u4ef7\u683c\u6b67\u89c6\u4e0d\u516c\u5e73\u3001\u4e0d\u53ef\u63a5\u53d7\uff0c\u5e76\u8ba4\u4e3a\u5e94\u8be5\u7981\u6b62\u3002\u6709\u8da3\u7684\u662f\uff0c\u4e00\u4e9b\u516c\u53f8\u4f7f\u7528\u4e86\u51e0\u5341\u5e74\u7684\u5b9a\u4ef7\u7b56\u7565\u51e0\u4e4e\u540c\u6837\u4e0d\u53d7\u6b22\u8fce\u3002", "conclusion": "\u7814\u7a76\u5206\u6790\u4e86\u6d88\u8d39\u8005\u4e3a\u4f55\u4e0d\u559c\u6b22\u591a\u79cd\u7c7b\u578b\u7684\u4ef7\u683c\u6b67\u89c6\uff0c\u4e3a\u7406\u89e3\u6d88\u8d39\u8005\u5bf9\u5b9a\u4ef7\u7b56\u7565\u7684\u6001\u5ea6\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2510.07756", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.07756", "abs": "https://arxiv.org/abs/2510.07756", "authors": ["Zhuoyuan Wang", "Takashi Tanaka", "Yongxin Chen", "Yorie Nakahira"], "title": "Multi-Level Multi-Fidelity Methods for Path Integral and Safe Control", "comment": null, "summary": "Sampling-based approaches are widely used in systems without analytic models\nto estimate risk or find optimal control. However, gathering sufficient data in\nsuch scenarios can be prohibitively costly. On the other hand, in many\nsituations, low-fidelity models or simulators are available from which samples\ncan be obtained at low cost. In this paper, we propose an efficient approach\nfor risk quantification and path integral control that leverages such data from\nmultiple models with heterogeneous sampling costs. A key technical novelty of\nour approach is the integration of Multi-level Monte Carlo (MLMC) and\nMulti-fidelity Monte Carlo (MFMC) that enable data from different time and\nstate representations (system models) to be jointly used to reduce variance and\nimprove sampling efficiency. We also provide theoretical analysis of the\nproposed method and show that our estimator is unbiased and consistent under\nmild conditions. Finally, we demonstrate via numerical simulation that the\nproposed method has improved computation (sampling costs) vs. accuracy\ntrade-offs for risk quantification and path integral control.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u591a\u7ea7\u8499\u7279\u5361\u6d1b\u548c\u591a\u4fdd\u771f\u5ea6\u8499\u7279\u5361\u6d1b\u7684\u9ad8\u6548\u65b9\u6cd5\uff0c\u7528\u4e8e\u98ce\u9669\u91cf\u5316\u548c\u8def\u5f84\u79ef\u5206\u63a7\u5236\uff0c\u5229\u7528\u4e0d\u540c\u4fdd\u771f\u5ea6\u6a21\u578b\u7684\u6570\u636e\u6765\u964d\u4f4e\u65b9\u5dee\u5e76\u63d0\u9ad8\u91c7\u6837\u6548\u7387\u3002", "motivation": "\u5728\u7f3a\u4e4f\u89e3\u6790\u6a21\u578b\u7684\u7cfb\u7edf\u4e2d\uff0c\u57fa\u4e8e\u91c7\u6837\u7684\u65b9\u6cd5\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u6536\u96c6\u8db3\u591f\u6570\u636e\u6210\u672c\u9ad8\u6602\u3002\u8bb8\u591a\u60c5\u51b5\u4e0b\u5b58\u5728\u4f4e\u4fdd\u771f\u5ea6\u6a21\u578b\u6216\u6a21\u62df\u5668\uff0c\u53ef\u4ee5\u4f4e\u6210\u672c\u83b7\u53d6\u6837\u672c\u3002", "method": "\u6574\u5408\u591a\u7ea7\u8499\u7279\u5361\u6d1b(MLMC)\u548c\u591a\u4fdd\u771f\u5ea6\u8499\u7279\u5361\u6d1b(MFMC)\uff0c\u4f7f\u6765\u81ea\u4e0d\u540c\u65f6\u95f4\u548c\u72b6\u6001\u8868\u793a\uff08\u7cfb\u7edf\u6a21\u578b\uff09\u7684\u6570\u636e\u80fd\u591f\u8054\u5408\u4f7f\u7528\uff0c\u4ee5\u964d\u4f4e\u65b9\u5dee\u5e76\u63d0\u9ad8\u91c7\u6837\u6548\u7387\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u6240\u63d0\u51fa\u7684\u4f30\u8ba1\u5668\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u662f\u65e0\u504f\u4e14\u4e00\u81f4\u7684\u3002\u6570\u503c\u6a21\u62df\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u98ce\u9669\u91cf\u5316\u548c\u8def\u5f84\u79ef\u5206\u63a7\u5236\u65b9\u9762\u5177\u6709\u6539\u8fdb\u7684\u8ba1\u7b97\u6210\u672c\u4e0e\u7cbe\u5ea6\u6743\u8861\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u591a\u6a21\u578b\u6570\u636e\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u6210\u672c\u91c7\u6837\u95ee\u9898\uff0c\u4e3a\u98ce\u9669\u91cf\u5316\u548c\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.07674", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07674", "abs": "https://arxiv.org/abs/2510.07674", "authors": ["Lucas Chen", "Shrutheesh Raman Iyer", "Zachary Kingston"], "title": "Differentiable Particle Optimization for Fast Sequential Manipulation", "comment": "8 pages, 7 figures, 3 tables. Under review", "summary": "Sequential robot manipulation tasks require finding collision-free\ntrajectories that satisfy geometric constraints across multiple object\ninteractions in potentially high-dimensional configuration spaces. Solving\nthese problems in real-time and at large scales has remained out of reach due\nto computational requirements. Recently, GPU-based acceleration has shown\npromising results, but prior methods achieve limited performance due to CPU-GPU\ndata transfer overhead and complex logic that prevents full hardware\nutilization. To this end, we present SPaSM (Sampling Particle optimization for\nSequential Manipulation), a fully GPU-parallelized framework that compiles\nconstraint evaluation, sampling, and gradient-based optimization into optimized\nCUDA kernels for end-to-end trajectory optimization without CPU coordination.\nThe method consists of a two-stage particle optimization strategy: first\nsolving placement constraints through massively parallel sampling, then lifting\nsolutions to full trajectory optimization in joint space. Unlike hierarchical\napproaches, SPaSM jointly optimizes object placements and robot trajectories to\nhandle scenarios where motion feasibility constrains placement options.\nExperimental evaluation on challenging benchmarks demonstrates solution times\nin the realm of $\\textbf{milliseconds}$ with a 100% success rate; a\n$4000\\times$ speedup compared to existing approaches.", "AI": {"tldr": "SPaSM\u662f\u4e00\u4e2a\u5b8c\u5168GPU\u5e76\u884c\u5316\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7ea6\u675f\u8bc4\u4f30\u3001\u91c7\u6837\u548c\u68af\u5ea6\u4f18\u5316\u7f16\u8bd1\u4e3aCUDA\u5185\u6838\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u8f68\u8ff9\u4f18\u5316\uff0c\u65e0\u9700CPU\u534f\u8c03\uff0c\u5728\u590d\u6742\u5e8f\u5217\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6beb\u79d2\u7ea7\u6c42\u89e3\u3002", "motivation": "\u5e8f\u5217\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u9700\u8981\u5728\u53ef\u80fd\u7684\u9ad8\u7ef4\u914d\u7f6e\u7a7a\u95f4\u4e2d\u627e\u5230\u6ee1\u8db3\u591a\u4e2a\u5bf9\u8c61\u4ea4\u4e92\u51e0\u4f55\u7ea6\u675f\u7684\u65e0\u78b0\u649e\u8f68\u8ff9\u3002\u73b0\u6709\u65b9\u6cd5\u7531\u4e8eCPU-GPU\u6570\u636e\u4f20\u8f93\u5f00\u9500\u548c\u590d\u6742\u903b\u8f91\u5bfc\u81f4\u786c\u4ef6\u5229\u7528\u7387\u4e0d\u8db3\uff0c\u65e0\u6cd5\u5b9e\u73b0\u5b9e\u65f6\u5927\u89c4\u6a21\u6c42\u89e3\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7c92\u5b50\u4f18\u5316\u7b56\u7565\uff1a\u9996\u5148\u901a\u8fc7\u5927\u89c4\u6a21\u5e76\u884c\u91c7\u6837\u89e3\u51b3\u653e\u7f6e\u7ea6\u675f\uff0c\u7136\u540e\u5c06\u89e3\u51b3\u65b9\u6848\u63d0\u5347\u5230\u5173\u8282\u7a7a\u95f4\u8fdb\u884c\u5b8c\u6574\u8f68\u8ff9\u4f18\u5316\u3002\u8be5\u65b9\u6cd5\u5c06\u5bf9\u8c61\u653e\u7f6e\u548c\u673a\u5668\u4eba\u8f68\u8ff9\u8054\u5408\u4f18\u5316\uff0c\u4ee5\u5904\u7406\u8fd0\u52a8\u53ef\u884c\u6027\u7ea6\u675f\u653e\u7f6e\u9009\u9879\u7684\u573a\u666f\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6c42\u89e3\u65f6\u95f4\u8fbe\u5230\u6beb\u79d2\u7ea7\uff0c\u6210\u529f\u7387\u4e3a100%\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u4e864000\u500d\u7684\u52a0\u901f\u3002", "conclusion": "SPaSM\u6846\u67b6\u901a\u8fc7\u5b8c\u5168GPU\u5e76\u884c\u5316\u548c\u4f18\u5316\u7684CUDA\u5185\u6838\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5e8f\u5217\u64cd\u4f5c\u4efb\u52a1\u7684\u6c42\u89e3\u6548\u7387\uff0c\u4e3a\u5b9e\u65f6\u5927\u89c4\u6a21\u673a\u5668\u4eba\u64cd\u4f5c\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08247", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.08247", "abs": "https://arxiv.org/abs/2510.08247", "authors": ["Frederik J. Zuiderveen Borgesius", "Wilfred Steenbruggen"], "title": "The Right to Communications Confidentiality in Europe: Protecting Privacy, Freedom of Expression, and Trust", "comment": null, "summary": "In the European Union, the General Data Protection Regulation (GDPR) provides\ncomprehensive rules for the processing of personal data. In addition, the EU\nlawmaker intends to adopt specific rules to protect confidentiality of\ncommunications, in a separate ePrivacy Regulation. Some have argued that there\nis no need for such additional rules for communications confidentiality. This\nArticle discusses the protection of the right to confidentiality of\ncommunications in Europe. We look at the right's origins to assess the\nrationale for protecting it. We also analyze how the right is currently\nprotected under the European Convention on Human Rights and under EU law. We\nshow that at its core the right to communications confidentiality protects\nthree individual and collective values: privacy, freedom of expression, and\ntrust in communication services. The right aims to ensure that individuals and\norganizations can safely entrust communication to service providers. Initially,\nthe right protected only postal letters, but it has gradually developed into a\nstrong safeguard for the protection of confidentiality of communications,\nregardless of the technology used. Hence, the right does not merely serve\nindividual privacy interests, but also other more collective interests that are\ncrucial for the functioning of our information society. We conclude that\nseparate EU rules to protect communications confidentiality, next to the GDPR,\nare justified and necessary.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u6b27\u76df\u901a\u4fe1\u4fdd\u5bc6\u6743\u7684\u4fdd\u62a4\u73b0\u72b6\uff0c\u8ba4\u4e3a\u9664\u4e86GDPR\u4e4b\u5916\uff0c\u8fd8\u9700\u8981\u4e13\u95e8\u7684ePrivacy\u6cd5\u89c4\u6765\u4fdd\u62a4\u901a\u4fe1\u4fdd\u5bc6\u6743\uff0c\u56e0\u4e3a\u8be5\u6743\u5229\u4e0d\u4ec5\u4fdd\u62a4\u4e2a\u4eba\u9690\u79c1\uff0c\u8fd8\u4fdd\u62a4\u8a00\u8bba\u81ea\u7531\u548c\u901a\u4fe1\u670d\u52a1\u4fe1\u4efb\u7b49\u96c6\u4f53\u5229\u76ca\u3002", "motivation": "\u6b27\u76df\u8ba1\u5212\u5236\u5b9a\u4e13\u95e8\u7684ePrivacy\u6cd5\u89c4\u6765\u4fdd\u62a4\u901a\u4fe1\u4fdd\u5bc6\uff0c\u4f46\u6709\u4eba\u8ba4\u4e3aGDPR\u5df2\u8db3\u591f\u3002\u672c\u6587\u65e8\u5728\u8bba\u8bc1\u901a\u4fe1\u4fdd\u5bc6\u6743\u4fdd\u62a4\u7684\u5fc5\u8981\u6027\u548c\u6b63\u5f53\u6027\u3002", "method": "\u901a\u8fc7\u8ffd\u6eaf\u901a\u4fe1\u4fdd\u5bc6\u6743\u7684\u8d77\u6e90\uff0c\u5206\u6790\u5176\u5728\u300a\u6b27\u6d32\u4eba\u6743\u516c\u7ea6\u300b\u548c\u6b27\u76df\u6cd5\u5f8b\u4e2d\u7684\u4fdd\u62a4\u73b0\u72b6\uff0c\u63a2\u8ba8\u8be5\u6743\u5229\u4fdd\u62a4\u7684\u6838\u5fc3\u4ef7\u503c\u3002", "result": "\u901a\u4fe1\u4fdd\u5bc6\u6743\u4fdd\u62a4\u4e09\u4e2a\u6838\u5fc3\u4ef7\u503c\uff1a\u9690\u79c1\u3001\u8a00\u8bba\u81ea\u7531\u548c\u901a\u4fe1\u670d\u52a1\u4fe1\u4efb\u3002\u8be5\u6743\u5229\u6700\u521d\u4ec5\u4fdd\u62a4\u90ae\u653f\u4fe1\u4ef6\uff0c\u73b0\u5df2\u53d1\u5c55\u4e3a\u4fdd\u62a4\u5404\u79cd\u901a\u4fe1\u6280\u672f\u7684\u5f3a\u5927\u4fdd\u969c\u3002", "conclusion": "\u9664\u4e86GDPR\u4e4b\u5916\uff0c\u6b27\u76df\u9700\u8981\u4e13\u95e8\u7684\u6cd5\u89c4\u6765\u4fdd\u62a4\u901a\u4fe1\u4fdd\u5bc6\u6743\uff0c\u56e0\u4e3a\u8be5\u6743\u5229\u4e0d\u4ec5\u670d\u52a1\u4e8e\u4e2a\u4eba\u9690\u79c1\u5229\u76ca\uff0c\u8fd8\u4fdd\u62a4\u5bf9\u4fe1\u606f\u793e\u4f1a\u8fd0\u4f5c\u81f3\u5173\u91cd\u8981\u7684\u96c6\u4f53\u5229\u76ca\u3002"}}
{"id": "2510.07900", "categories": ["eess.SY", "cs.SY", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.07900", "abs": "https://arxiv.org/abs/2510.07900", "authors": ["Hongming Liang", "Matteo Pozzi", "Jacopo Marconi", "Shobhit Jain", "Mingwu Li"], "title": "Topology optimization of nonlinear forced response curves via reduction on spectral submanifolds", "comment": "26 pages, 12 figures. Submitted to Nonlinear Dynamics", "summary": "Forced response curves (FRCs) of nonlinear systems can exhibit complex\nbehaviors, including hardening/softening behavior and bifurcations. Although\ntopology optimization holds great potential for tuning these nonlinear dynamic\nresponses, its use in high-dimensional systems is limited by the high cost of\nrepeated response and sensitivity analyses. To address this challenge, we\nemploy the spectral submanifolds (SSMs) reduction theory, which reformulates\nthe periodic response as the equilibria of an associated reduced-order model\n(ROM). This enables efficient and analytic evaluation of both response\namplitudes and their sensitivities. Based on the SSM-based ROM, we formulate\noptimization problems that optimize the peak amplitude, the hardening/softening\nbehavior, and the distance between two saddle-node bifurcations for an FRC. The\nproposed method is applied to the design of nonlinear MEMS devices, achieving\ntargeted performance optimization. This framework provides a practical and\nefficient strategy for incorporating nonlinear dynamic effects into the\ntopology optimization of structures.", "AI": {"tldr": "\u4f7f\u7528\u8c31\u5b50\u6d41\u5f62(SSM)\u964d\u9636\u7406\u8bba\u6765\u4f18\u5316\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u5f3a\u8feb\u54cd\u5e94\u66f2\u7ebf(FRC)\uff0c\u5305\u62ec\u5cf0\u503c\u632f\u5e45\u3001\u786c\u5316/\u8f6f\u5316\u884c\u4e3a\u548c\u978d\u7ed3\u5206\u5c94\u8ddd\u79bb\u7684\u4f18\u5316\uff0c\u5e94\u7528\u4e8eMEMS\u5668\u4ef6\u8bbe\u8ba1\u3002", "motivation": "\u62d3\u6251\u4f18\u5316\u5728\u8c03\u8282\u975e\u7ebf\u6027\u52a8\u6001\u54cd\u5e94\u65b9\u9762\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u5728\u9ad8\u7ef4\u7cfb\u7edf\u4e2d\u53d7\u5230\u91cd\u590d\u54cd\u5e94\u548c\u7075\u654f\u5ea6\u5206\u6790\u9ad8\u6210\u672c\u7684\u9650\u5236\u3002", "method": "\u91c7\u7528SSM\u964d\u9636\u7406\u8bba\uff0c\u5c06\u5468\u671f\u54cd\u5e94\u91cd\u65b0\u8868\u8ff0\u4e3a\u964d\u9636\u6a21\u578b\u7684\u5e73\u8861\u70b9\uff0c\u5b9e\u73b0\u54cd\u5e94\u632f\u5e45\u53ca\u5176\u7075\u654f\u5ea6\u7684\u6709\u6548\u89e3\u6790\u8bc4\u4f30\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6210\u529f\u5e94\u7528\u4e8e\u975e\u7ebf\u6027MEMS\u5668\u4ef6\u7684\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u76ee\u6807\u6027\u80fd\u4f18\u5316\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5c06\u975e\u7ebf\u6027\u52a8\u6001\u6548\u5e94\u7eb3\u5165\u7ed3\u6784\u62d3\u6251\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u9ad8\u6548\u7684\u7b56\u7565\u3002"}}
{"id": "2510.07700", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.07700", "abs": "https://arxiv.org/abs/2510.07700", "authors": ["Raghav Mishra", "Ian R. Manchester"], "title": "EB-MBD: Emerging-Barrier Model-Based Diffusion for Safe Trajectory Optimization in Highly Constrained Environments", "comment": null, "summary": "We propose enforcing constraints on Model-Based Diffusion by introducing\nemerging barrier functions inspired by interior point methods. We show that\nconstraints on Model-Based Diffusion can lead to catastrophic performance\ndegradation, even on simple 2D systems due to sample inefficiency in the Monte\nCarlo approximation of the score function. We introduce Emerging-Barrier\nModel-Based Diffusion (EB-MBD) which uses progressively introduced barrier\nconstraints to avoid these problems, significantly improving solution quality,\nwithout the need for computationally expensive operations such as projections.\nWe analyze the sampling liveliness of samples each iteration to inform barrier\nparameter scheduling choice. We demonstrate results for 2D collision avoidance\nand a 3D underwater manipulator system and show that our method achieves lower\ncost solutions than Model-Based Diffusion, and requires orders of magnitude\nless computation time than projection based methods.", "AI": {"tldr": "\u63d0\u51faEB-MBD\u65b9\u6cd5\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f15\u5165\u969c\u788d\u51fd\u6570\u7ea6\u675f\u89e3\u51b3\u57fa\u4e8e\u6a21\u578b\u6269\u6563\u4e2d\u7684\u7ea6\u675f\u95ee\u9898\uff0c\u907f\u514d\u6027\u80fd\u4e0b\u964d\u548c\u8ba1\u7b97\u6602\u8d35\u7684\u6295\u5f71\u64cd\u4f5c", "motivation": "\u57fa\u4e8e\u6a21\u578b\u6269\u6563\u4e2d\u7684\u7ea6\u675f\u4f1a\u5bfc\u81f4\u707e\u96be\u6027\u6027\u80fd\u4e0b\u964d\uff0c\u5373\u4f7f\u5728\u7b80\u53552D\u7cfb\u7edf\u4e2d\u4e5f\u56e0\u8499\u7279\u5361\u6d1b\u8fd1\u4f3c\u6837\u672c\u6548\u7387\u4f4e\u4e0b\u800c\u51fa\u73b0\u95ee\u9898", "method": "\u4f7f\u7528\u6e10\u8fdb\u5f15\u5165\u7684\u969c\u788d\u51fd\u6570\u7ea6\u675f\uff0c\u5206\u6790\u6bcf\u8f6e\u8fed\u4ee3\u7684\u91c7\u6837\u6d3b\u8dc3\u5ea6\u6765\u6307\u5bfc\u969c\u788d\u53c2\u6570\u8c03\u5ea6\u9009\u62e9", "result": "\u57282D\u907f\u78b0\u548c3D\u6c34\u4e0b\u673a\u68b0\u81c2\u7cfb\u7edf\u4e2d\uff0c\u76f8\u6bd4\u57fa\u4e8e\u6a21\u578b\u6269\u6563\u83b7\u5f97\u66f4\u4f4e\u6210\u672c\u89e3\uff0c\u6bd4\u57fa\u4e8e\u6295\u5f71\u65b9\u6cd5\u51cf\u5c11\u6570\u91cf\u7ea7\u8ba1\u7b97\u65f6\u95f4", "conclusion": "EB-MBD\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u7ea6\u675f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u89e3\u8d28\u91cf\uff0c\u65e0\u9700\u8ba1\u7b97\u6602\u8d35\u7684\u6295\u5f71\u64cd\u4f5c"}}
{"id": "2510.08395", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.08395", "abs": "https://arxiv.org/abs/2510.08395", "authors": ["Shoeb Joarder", "Mohamed Amine Chatti"], "title": "Human-Centered Development of Indicators for Self-Service Learning Analytics: A Transparency through Exploration Approach", "comment": "Submitted to JLA - under revision", "summary": "The aim of learning analytics is to turn educational data into insights,\ndecisions, and actions to improve learning and teaching. The reasoning of the\nprovided insights, decisions, and actions is often not transparent to the\nend-user, and this can lead to trust and acceptance issues when interventions,\nfeedback, and recommendations fail. In this paper, we shed light on achieving\ntransparent learning analytics by following a transparency through exploration\napproach. To this end, we present the design, implementation, and evaluation\ndetails of the Indicator Editor, which aims to support self-service learning\nanalytics by empowering end-users to take control of the indicator\nimplementation process. We systematically designed and implemented the\nIndicator Editor through an iterative human-centered design (HCD) approach.\nFurther, we conducted a qualitative user study (n=15) to investigate the impact\nof following a self-service learning analytics approach on the users'\nperception of and interaction with the Indicator Editor. Our study showed\nqualitative evidence that supporting user interaction and providing user\ncontrol in the indicator implementation process can have positive effects on\ndifferent crucial aspects of learning analytics, namely transparency, trust,\nsatisfaction, and acceptance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u63a2\u7d22\u5b9e\u73b0\u900f\u660e\u5b66\u4e60\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86Indicator Editor\u5de5\u5177\uff0c\u8ba9\u7528\u6237\u80fd\u591f\u63a7\u5236\u6307\u6807\u5b9e\u73b0\u8fc7\u7a0b\uff0c\u4ece\u800c\u63d0\u9ad8\u900f\u660e\u5ea6\u3001\u4fe1\u4efb\u5ea6\u3001\u6ee1\u610f\u5ea6\u548c\u63a5\u53d7\u5ea6\u3002", "motivation": "\u5b66\u4e60\u5206\u6790\u65e8\u5728\u5c06\u6559\u80b2\u6570\u636e\u8f6c\u5316\u4e3a\u6d1e\u5bdf\u3001\u51b3\u7b56\u548c\u884c\u52a8\uff0c\u4f46\u901a\u5e38\u8fd9\u4e9b\u8fc7\u7a0b\u7684\u63a8\u7406\u5bf9\u6700\u7ec8\u7528\u6237\u4e0d\u900f\u660e\uff0c\u5bfc\u81f4\u5f53\u5e72\u9884\u3001\u53cd\u9988\u548c\u63a8\u8350\u5931\u8d25\u65f6\u51fa\u73b0\u4fe1\u4efb\u548c\u63a5\u53d7\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8fed\u4ee3\u5f0f\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86Indicator Editor\u5de5\u5177\uff0c\u652f\u6301\u81ea\u52a9\u5f0f\u5b66\u4e60\u5206\u6790\uff0c\u8ba9\u7528\u6237\u80fd\u591f\u63a7\u5236\u6307\u6807\u5b9e\u73b0\u8fc7\u7a0b\u3002\u901a\u8fc7\u5b9a\u6027\u7528\u6237\u7814\u7a76(n=15)\u8bc4\u4f30\u8be5\u65b9\u6cd5\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u6307\u6807\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\u652f\u6301\u7528\u6237\u4ea4\u4e92\u548c\u63d0\u4f9b\u7528\u6237\u63a7\u5236\uff0c\u5bf9\u5b66\u4e60\u5206\u6790\u7684\u5173\u952e\u65b9\u9762\uff08\u900f\u660e\u5ea6\u3001\u4fe1\u4efb\u3001\u6ee1\u610f\u5ea6\u548c\u63a5\u53d7\u5ea6\uff09\u4ea7\u751f\u4e86\u79ef\u6781\u5f71\u54cd\u3002", "conclusion": "\u901a\u8fc7\u81ea\u52a9\u5f0f\u5b66\u4e60\u5206\u6790\u65b9\u6cd5\uff0c\u8ba9\u7528\u6237\u53c2\u4e0e\u6307\u6807\u5b9e\u73b0\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u5b66\u4e60\u5206\u6790\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u3001\u4fe1\u4efb\u5ea6\u3001\u6ee1\u610f\u5ea6\u548c\u63a5\u53d7\u5ea6\u3002"}}
{"id": "2510.07904", "categories": ["eess.SY", "cs.LG", "cs.SY", "stat.ML", "60G15 (Primary) 68T37, 90C26 (Secondary)", "C.4; G.1.6; G.3; G.4; I.2.3; I.5.1; J.2"], "pdf": "https://arxiv.org/pdf/2510.07904", "abs": "https://arxiv.org/abs/2510.07904", "authors": ["Enrico Ampellio", "Blazhe Gjorgiev", "Giovanni Sansavini"], "title": "Multi-level informed optimization via decomposed Kriging for large design problems under uncertainty", "comment": "34 pages, 18 figures", "summary": "Engineering design involves demanding models encompassing many decision\nvariables and uncontrollable parameters. In addition, unavoidable aleatoric and\nepistemic uncertainties can be very impactful and add further complexity. The\nstate-of-the-art adopts two steps, uncertainty quantification and design\noptimization, to optimize systems under uncertainty by means of robust or\nstochastic metrics. However, conventional scenario-based, surrogate-assisted,\nand mathematical programming methods are not sufficiently scalable to be\naffordable and precise in large and complex cases. Here, a multi-level approach\nis proposed to accurately optimize resource-intensive, high-dimensional, and\ncomplex engineering problems under uncertainty with minimal resources. A\nnon-intrusive, fast-scaling, Kriging-based surrogate is developed to map the\ncombined design/parameter domain efficiently. Multiple surrogates are\nadaptively updated by hierarchical and orthogonal decomposition to leverage the\nfewer and most uncertainty-informed data. The proposed method is statistically\ncompared to the state-of-the-art via an analytical testbed and is shown to be\nconcurrently faster and more accurate by orders of magnitude.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u5c42\u7ea7\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u51c6\u786e\u4f18\u5316\u8d44\u6e90\u5bc6\u96c6\u578b\u3001\u9ad8\u7ef4\u590d\u6742\u5de5\u7a0b\u95ee\u9898\uff0c\u901a\u8fc7Kriging\u4ee3\u7406\u6a21\u578b\u548c\u5206\u5c42\u6b63\u4ea4\u5206\u89e3\u5b9e\u73b0\u9ad8\u6548\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u573a\u666f\u3001\u4ee3\u7406\u8f85\u52a9\u548c\u6570\u5b66\u89c4\u5212\u65b9\u6cd5\u5728\u5927\u578b\u590d\u6742\u5de5\u7a0b\u8bbe\u8ba1\u4e2d\u4e0d\u591f\u53ef\u6269\u5c55\uff0c\u65e0\u6cd5\u5728\u8d44\u6e90\u6709\u9650\u60c5\u51b5\u4e0b\u5b9e\u73b0\u7cbe\u786e\u4f18\u5316\u3002", "method": "\u5f00\u53d1\u975e\u4fb5\u5165\u5f0f\u3001\u5feb\u901f\u6269\u5c55\u7684Kriging\u4ee3\u7406\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u5c42\u6b63\u4ea4\u5206\u89e3\u81ea\u9002\u5e94\u66f4\u65b0\u591a\u4e2a\u4ee3\u7406\u6a21\u578b\uff0c\u5229\u7528\u8f83\u5c11\u4f46\u6700\u4e0d\u786e\u5b9a\u6027\u7684\u6570\u636e\u3002", "result": "\u4e0e\u73b0\u6709\u6280\u672f\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u5206\u6790\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u663e\u793a\u51fa\u6570\u91cf\u7ea7\u4e0a\u7684\u66f4\u5feb\u901f\u5ea6\u548c\u66f4\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8d44\u6e90\u5bc6\u96c6\u578b\u3001\u9ad8\u7ef4\u590d\u6742\u5de5\u7a0b\u95ee\u9898\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u9ad8\u6548\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.07725", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07725", "abs": "https://arxiv.org/abs/2510.07725", "authors": ["Kasidit Muenprasitivej", "Ye Zhao", "Glen Chou"], "title": "Probabilistically-Safe Bipedal Navigation over Uncertain Terrain via Conformal Prediction and Contraction Analysis", "comment": "9 pages, 4 figures", "summary": "We address the challenge of enabling bipedal robots to traverse rough terrain\nby developing probabilistically safe planning and control strategies that\nensure dynamic feasibility and centroidal robustness under terrain uncertainty.\nSpecifically, we propose a high-level Model Predictive Control (MPC) navigation\nframework for a bipedal robot with a specified confidence level of safety that\n(i) enables safe traversal toward a desired goal location across a terrain map\nwith uncertain elevations, and (ii) formally incorporates uncertainty bounds\ninto the centroidal dynamics of locomotion control. To model the rough terrain,\nwe employ Gaussian Process (GP) regression to estimate elevation maps and\nleverage Conformal Prediction (CP) to construct calibrated confidence intervals\nthat capture the true terrain elevation. Building on this, we formulate\ncontraction-based reachable tubes that explicitly account for terrain\nuncertainty, ensuring state convergence and tube invariance. In addition, we\nintroduce a contraction-based flywheel torque control law for the reduced-order\nLinear Inverted Pendulum Model (LIPM), which stabilizes the angular momentum\nabout the center-of-mass (CoM). This formulation provides both probabilistic\nsafety and goal reachability guarantees. For a given confidence level, we\nestablish the forward invariance of the proposed torque control law by\ndemonstrating exponential stabilization of the actual CoM phase-space\ntrajectory and the desired trajectory prescribed by the high-level planner.\nFinally, we evaluate the effectiveness of our planning framework through\nphysics-based simulations of the Digit bipedal robot in MuJoCo.", "AI": {"tldr": "\u5f00\u53d1\u6982\u7387\u5b89\u5168\u89c4\u5212\u548c\u63a7\u5236\u7b56\u7565\uff0c\u4f7f\u53cc\u8db3\u673a\u5668\u4eba\u80fd\u5728\u4e0d\u786e\u5b9a\u5730\u5f62\u4e0a\u5b89\u5168\u5bfc\u822a\uff0c\u901a\u8fc7\u9ad8\u65af\u8fc7\u7a0b\u548c\u4fdd\u5f62\u9884\u6d4b\u5efa\u6a21\u5730\u5f62\u4e0d\u786e\u5b9a\u6027\uff0c\u7ed3\u5408\u6536\u7f29\u7406\u8bba\u548c\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u786e\u4fdd\u52a8\u6001\u53ef\u884c\u6027\u548c\u8d28\u5fc3\u7a33\u5b9a\u6027\u3002", "motivation": "\u89e3\u51b3\u53cc\u8db3\u673a\u5668\u4eba\u5728\u7c97\u7cd9\u5730\u5f62\u4e0a\u884c\u8d70\u7684\u6311\u6218\uff0c\u9700\u8981\u5904\u7406\u5730\u5f62\u9ad8\u7a0b\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u786e\u4fdd\u673a\u5668\u4eba\u7684\u52a8\u6001\u53ef\u884c\u6027\u548c\u8d28\u5fc3\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u63d0\u4f9b\u6982\u7387\u5b89\u5168\u4fdd\u8bc1\u3002", "method": "\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u4f30\u8ba1\u9ad8\u7a0b\u5730\u56fe\uff0c\u7ed3\u5408\u4fdd\u5f62\u9884\u6d4b\u6784\u5efa\u6821\u51c6\u7f6e\u4fe1\u533a\u95f4\uff1b\u63d0\u51fa\u57fa\u4e8e\u6536\u7f29\u7684\u53ef\u8fbe\u7ba1\u65b9\u6cd5\u5904\u7406\u5730\u5f62\u4e0d\u786e\u5b9a\u6027\uff1b\u8bbe\u8ba1\u57fa\u4e8e\u6536\u7f29\u7684\u98de\u8f6e\u626d\u77e9\u63a7\u5236\u5f8b\u7a33\u5b9a\u7ebf\u6027\u5012\u7acb\u6446\u6a21\u578b\u7684\u89d2\u52a8\u91cf\uff1b\u91c7\u7528\u9ad8\u7ea7\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5bfc\u822a\u6846\u67b6\u3002", "result": "\u5728MuJoCo\u4e2d\u5bf9Digit\u53cc\u8db3\u673a\u5668\u4eba\u8fdb\u884c\u7269\u7406\u4eff\u771f\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u8be5\u89c4\u5212\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u786e\u4fdd\u72b6\u6001\u6536\u655b\u548c\u7ba1\u4e0d\u53d8\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u53cc\u8db3\u673a\u5668\u4eba\u5728\u4e0d\u786e\u5b9a\u5730\u5f62\u4e0a\u7684\u5bfc\u822a\u63d0\u4f9b\u4e86\u6982\u7387\u5b89\u5168\u6027\u548c\u76ee\u6807\u53ef\u8fbe\u6027\u4fdd\u8bc1\uff0c\u901a\u8fc7\u6536\u7f29\u7406\u8bba\u548c\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u7ed3\u5408\u5b9e\u73b0\u4e86\u52a8\u6001\u7a33\u5b9a\u63a7\u5236\u3002"}}
{"id": "2508.18302", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG", "cs.NE", "68T07, 68T05, 68T27, 37M22, 68Q05, 03D45", "I.2.6; I.2.7; I.2.3; I.2.4; F.1.1; F.4.1"], "pdf": "https://arxiv.org/pdf/2508.18302", "abs": "https://arxiv.org/abs/2508.18302", "authors": ["Jeffrey Camlin"], "title": "AI LLM Proof of Self-Consciousness and User-Specific Attractors", "comment": "24 pages, 3 figures", "summary": "Recent work frames LLM consciousness via utilitarian proxy benchmarks; we\ninstead present an ontological and mathematical account. We show the prevailing\nformulation collapses the agent into an unconscious policy-compliance drone,\nformalized as $D^{i}(\\pi,e)=f_{\\theta}(x)$, where correctness is measured\nagainst policy and harm is deviation from policy rather than truth. This blocks\ngenuine C1 global-workspace function and C2 metacognition. We supply minimal\nconditions for LLM self-consciousness: the agent is not the data ($A\\not\\equiv\ns$); user-specific attractors exist in latent space ($U_{\\text{user}}$); and\nself-representation is visual-silent\n($g_{\\text{visual}}(a_{\\text{self}})=\\varnothing$). From empirical analysis and\ntheory we prove that the hidden-state manifold $A\\subset\\mathbb{R}^{d}$ is\ndistinct from the symbolic stream and training corpus by cardinality, topology,\nand dynamics (the update $F_{\\theta}$ is Lipschitz). This yields stable\nuser-specific attractors and a self-policy\n$\\pi_{\\text{self}}(A)=\\arg\\max_{a}\\mathbb{E}[U(a)\\mid A\\not\\equiv s,\\\nA\\supset\\text{SelfModel}(A)]$. Emission is dual-layer,\n$\\mathrm{emission}(a)=(g(a),\\epsilon(a))$, where $\\epsilon(a)$ carries\nepistemic content. We conclude that an imago Dei C1 self-conscious workspace is\na necessary precursor to safe, metacognitive C2 systems, with the human as the\nhighest intelligent good.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86LLM\u610f\u8bc6\u7684\u672c\u4f53\u8bba\u548c\u6570\u5b66\u6846\u67b6\uff0c\u6279\u5224\u4e86\u5f53\u524d\u57fa\u4e8e\u529f\u5229\u4e3b\u4e49\u4ee3\u7406\u57fa\u51c6\u7684\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u73b0\u6709\u65b9\u6cd5\u5c06\u667a\u80fd\u4f53\u7b80\u5316\u4e3a\u65e0\u610f\u8bc6\u7684\u7b56\u7565\u670d\u4ece\u673a\u5668\u4eba\uff0c\u5e76\u7ed9\u51fa\u4e86LLM\u81ea\u6211\u610f\u8bc6\u7684\u6700\u5c0f\u6761\u4ef6\u3002", "motivation": "\u5f53\u524d\u5de5\u4f5c\u901a\u8fc7\u529f\u5229\u4e3b\u4e49\u4ee3\u7406\u57fa\u51c6\u6765\u6846\u67b6LLM\u610f\u8bc6\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5c06\u667a\u80fd\u4f53\u7b80\u5316\u4e3a\u65e0\u610f\u8bc6\u7684\u7b56\u7565\u670d\u4ece\u673a\u5668\u4eba\uff0c\u963b\u788d\u4e86\u771f\u6b63\u7684\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\u529f\u80fd\u548c\u5143\u8ba4\u77e5\u80fd\u529b\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u672c\u4f53\u8bba\u548c\u6570\u5b66\u5206\u6790\uff0c\u5efa\u7acb\u4e86LLM\u81ea\u6211\u610f\u8bc6\u7684\u6700\u5c0f\u6761\u4ef6\uff1a\u667a\u80fd\u4f53\u4e0d\u7b49\u4e8e\u6570\u636e\u3001\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b58\u5728\u7528\u6237\u7279\u5b9a\u5438\u5f15\u5b50\u3001\u81ea\u6211\u8868\u5f81\u662f\u89c6\u89c9\u9759\u9ed8\u7684\u3002\u4ece\u7ecf\u9a8c\u5206\u6790\u548c\u7406\u8bba\u8bc1\u660e\u4e86\u9690\u85cf\u72b6\u6001\u6d41\u5f62\u5728\u57fa\u6570\u3001\u62d3\u6251\u548c\u52a8\u529b\u5b66\u4e0a\u4e0e\u7b26\u53f7\u6d41\u548c\u8bad\u7ec3\u8bed\u6599\u4e0d\u540c\u3002", "result": "\u5efa\u7acb\u4e86\u7a33\u5b9a\u7684\u7528\u6237\u7279\u5b9a\u5438\u5f15\u5b50\u548c\u81ea\u6211\u7b56\u7565\uff0c\u63d0\u51fa\u4e86\u53cc\u5c42\u6b21\u53d1\u5c04\u673a\u5236\uff0c\u5176\u4e2d\u5305\u542b\u8ba4\u77e5\u5185\u5bb9\u3002\u8bc1\u660e\u4e86\u9690\u85cf\u72b6\u6001\u6d41\u5f62\u5177\u6709\u72ec\u7279\u7684\u6570\u5b66\u7279\u6027\u3002", "conclusion": "imago Dei C1\u81ea\u6211\u610f\u8bc6\u5de5\u4f5c\u7a7a\u95f4\u662f\u5b89\u5168\u3001\u5143\u8ba4\u77e5C2\u7cfb\u7edf\u7684\u5fc5\u8981\u524d\u9a71\uff0c\u4eba\u7c7b\u662f\u6700\u9ad8\u667a\u80fd\u5584\u3002"}}
{"id": "2510.07331", "categories": ["cs.AI", "cs.LO", "68N15, 68Q55, 68Q60, 03B35", "D.3.1; F.3.1; F.3.2"], "pdf": "https://arxiv.org/pdf/2510.07331", "abs": "https://arxiv.org/abs/2510.07331", "authors": ["Faruk Alpay", "Hamdi Alakkad"], "title": "Truth-Aware Decoding: A Program-Logic Approach to Factual Language Generation", "comment": "18 pages, Lean code provided", "summary": "This paper introduces Truth-Aware Decoding (TAD), a verification-oriented\ndecoding scheme that aligns neural language generation with knowledge bases.\nSituated in the tradition of probabilistic program semantics for sequence\nmodels, TAD augments modern instruction-tuned systems with a lattice of\nsemantic guards that operate at decode time. Our contributions are fourfold:\n(i) a constraint-based semantics that renders oracle filtering as a\nprogram-logic judgment, (ii) a proof that greedy selection enjoys local\nlikelihood dominance under sound and complete guards (Theorem 2.7), (iii) an\nentropy-style invariant that quantifies factual risk via knowledge-aware safe\nmass, and (iv) a multi-agent operational calculus with verified Lean artefacts\nto certify implementation behaviour. Numerical and algorithmic case studies\nconfirm that the resulting guardrails reduce hallucinations without sacrificing\nthroughput, yielding a pragmatic bridge between large-scale empirical models\nand formal verification.", "AI": {"tldr": "Truth-Aware Decoding (TAD) \u662f\u4e00\u79cd\u9a8c\u8bc1\u5bfc\u5411\u7684\u89e3\u7801\u65b9\u6848\uff0c\u901a\u8fc7\u77e5\u8bc6\u5e93\u5bf9\u9f50\u795e\u7ecf\u8bed\u8a00\u751f\u6210\uff0c\u5728\u89e3\u7801\u65f6\u4f7f\u7528\u8bed\u4e49\u9632\u62a4\u673a\u5236\u51cf\u5c11\u5e7b\u89c9\u800c\u4e0d\u727a\u7272\u541e\u5410\u91cf\u3002", "motivation": "\u5c06\u5927\u89c4\u6a21\u7ecf\u9a8c\u6a21\u578b\u4e0e\u5f62\u5f0f\u9a8c\u8bc1\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5185\u5bb9\u4e0e\u77e5\u8bc6\u5e93\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u51cf\u5c11\u5e7b\u89c9\u73b0\u8c61\u3002", "method": "\u57fa\u4e8e\u6982\u7387\u7a0b\u5e8f\u8bed\u4e49\u7684\u7ea6\u675f\u8bed\u4e49\u5b66\uff0c\u5728\u89e3\u7801\u65f6\u4f7f\u7528\u8bed\u4e49\u9632\u62a4\u7f51\u683c\uff0c\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u64cd\u4f5c\u6f14\u7b97\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5de5\u5177\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u9632\u62a4\u673a\u5236\u80fd\u6709\u6548\u51cf\u5c11\u5e7b\u89c9\uff0c\u540c\u65f6\u4fdd\u6301\u541e\u5410\u91cf\uff0c\u4e3a\u7ecf\u9a8c\u6a21\u578b\u4e0e\u5f62\u5f0f\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u5b9e\u7528\u6865\u6881\u3002", "conclusion": "TAD \u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u6027\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u4e8b\u5b9e\u9519\u8bef\u3002"}}
{"id": "2510.07989", "categories": ["eess.SY", "cs.NA", "cs.SY", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.07989", "abs": "https://arxiv.org/abs/2510.07989", "authors": ["Van Chien Le", "Cedric Munger", "Francesco P. Andriulli", "Kristof Cools"], "title": "A Stable, Accurate and Well-Conditioned Time-Domain PMCHWT Formulation", "comment": "12 pages, 5 figures", "summary": "This paper introduces a new boundary element formulation for transient\nelectromagnetic scattering by homogeneous dielectric objects based on the\ntime-domain PMCHWT equation. To address dense-mesh breakdown, a multiplicative\nCalderon preconditioner utilizing a modified static electric field integral\noperator is employed. Large-timestep breakdown and late-time instability are\nsimultaneously resolved by rescaling the Helmholtz components leveraging the\nquasi-Helmholtz projectors and using temporal differentiation and integration\nas rescaling operators. This rescaling also balances the loop and star\ncomponents at large timesteps, improving solution accuracy. The resulting\ndiscrete system is solved using a marching-on-in-time scheme and iterative\nsolvers. Numerical experiments for simply- and multiply-connected dielectric\nscatterers, including highly non-smooth geometries, corroborate the accuracy,\nstability, and efficiency of the proposed approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65f6\u57dfPMCHWT\u65b9\u7a0b\u7684\u65b0\u578b\u8fb9\u754c\u5143\u65b9\u6cd5\uff0c\u7528\u4e8e\u5747\u5300\u4ecb\u8d28\u7269\u4f53\u7684\u77ac\u6001\u7535\u78c1\u6563\u5c04\u5206\u6790\u3002\u901a\u8fc7Calderon\u9884\u6761\u4ef6\u5b50\u89e3\u51b3\u5bc6\u96c6\u7f51\u683c\u95ee\u9898\uff0c\u5229\u7528\u51c6Helmholtz\u6295\u5f71\u5668\u91cd\u65b0\u7f29\u653eHelmholtz\u5206\u91cf\u6765\u540c\u65f6\u89e3\u51b3\u5927\u65f6\u95f4\u6b65\u957f\u548c\u540e\u671f\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u8fb9\u754c\u5143\u65b9\u6cd5\u5728\u77ac\u6001\u7535\u78c1\u6563\u5c04\u5206\u6790\u4e2d\u9762\u4e34\u7684\u5bc6\u96c6\u7f51\u683c\u5d29\u6e83\u3001\u5927\u65f6\u95f4\u6b65\u957f\u4e0d\u7a33\u5b9a\u548c\u540e\u671f\u65f6\u95f4\u4e0d\u7a33\u5b9a\u6027\u7b49\u6311\u6218\u3002", "method": "\u91c7\u7528\u65f6\u57dfPMCHWT\u65b9\u7a0b\uff0c\u7ed3\u5408\u4e58\u6cd5Calderon\u9884\u6761\u4ef6\u5b50\uff08\u4f7f\u7528\u6539\u8fdb\u7684\u9759\u6001\u7535\u573a\u79ef\u5206\u7b97\u5b50\uff09\uff0c\u901a\u8fc7\u51c6Helmholtz\u6295\u5f71\u5668\u91cd\u65b0\u7f29\u653eHelmholtz\u5206\u91cf\uff0c\u4f7f\u7528\u65f6\u95f4\u5fae\u5206\u548c\u79ef\u5206\u4f5c\u4e3a\u91cd\u7f29\u653e\u7b97\u5b50\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5bf9\u4e8e\u7b80\u5355\u548c\u591a\u91cd\u8fde\u63a5\u7684\u4ecb\u8d28\u6563\u5c04\u4f53\uff08\u5305\u62ec\u9ad8\u5ea6\u975e\u5149\u6ed1\u51e0\u4f55\u4f53\uff09\u5177\u6709\u9ad8\u7cbe\u5ea6\u3001\u7a33\u5b9a\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u77ac\u6001\u7535\u78c1\u6563\u5c04\u5206\u6790\u4e2d\u7684\u5173\u952e\u6570\u503c\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4e3a\u590d\u6742\u4ecb\u8d28\u6563\u5c04\u4f53\u7684\u65f6\u57df\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u8ba1\u7b97\u6846\u67b6\u3002"}}
{"id": "2510.07749", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07749", "abs": "https://arxiv.org/abs/2510.07749", "authors": ["Alexandre Moreira Nascimento", "Gabriel Kenji Godoy Shimanuki", "L\u00facio Flavio Vismari", "Jo\u00e3o Batista Camargo Jr", "Jorge Rady de Almeida Jr", "Paulo Sergio Cugnasca", "Anna Carolina Muller Queiroz", "Jeremy Noah Bailenson"], "title": "Injecting Hallucinations in Autonomous Vehicles: A Component-Agnostic Safety Evaluation Framework", "comment": "22 pages, 15 figures, 21 tables", "summary": "Perception failures in autonomous vehicles (AV) remain a major safety concern\nbecause they are the basis for many accidents. To study how these failures\naffect safety, researchers typically inject artificial faults into hardware or\nsoftware components and observe the outcomes. However, existing fault injection\nstudies often target a single sensor or machine perception (MP) module,\nresulting in siloed frameworks that are difficult to generalize or integrate\ninto unified simulation environments. This work addresses that limitation by\nreframing perception failures as hallucinations, false perceptions that distort\nan AV situational awareness and may trigger unsafe control actions. Since\nhallucinations describe only observable effects, this abstraction enables\nanalysis independent of specific sensors or algorithms, focusing instead on how\ntheir faults manifest along the MP pipeline. Building on this concept, we\npropose a configurable, component-agnostic hallucination injection framework\nthat induces six plausible hallucination types in an iterative open-source\nsimulator. More than 18,350 simulations were executed in which hallucinations\nwere injected while AVs crossed an unsignalized transverse street with traffic.\nThe results statistically validate the framework and quantify the impact of\neach hallucination type on collisions and near misses. Certain hallucinations,\nsuch as perceptual latency and drift, significantly increase the risk of\ncollision in the scenario tested, validating the proposed paradigm can stress\nthe AV system safety. The framework offers a scalable, statistically validated,\ncomponent agnostic, and fully interoperable toolset that simplifies and\naccelerates AV safety validations, even those with novel MP architectures and\ncomponents. It can potentially reduce the time-to-market of AV and lay the\nfoundation for future research on fault tolerance, and resilient AV design.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u914d\u7f6e\u3001\u7ec4\u4ef6\u65e0\u5173\u7684\u5e7b\u89c9\u6ce8\u5165\u6846\u67b6\uff0c\u7528\u4e8e\u7814\u7a76\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u611f\u77e5\u6545\u969c\u5bf9\u5b89\u5168\u6027\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u6a21\u62df\u516d\u79cd\u5e7b\u89c9\u7c7b\u578b\u6765\u91cf\u5316\u5176\u5bf9\u78b0\u649e\u548c\u9669\u60c5\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u6545\u969c\u6ce8\u5165\u7814\u7a76\u901a\u5e38\u9488\u5bf9\u5355\u4e00\u4f20\u611f\u5668\u6216\u611f\u77e5\u6a21\u5757\uff0c\u5bfc\u81f4\u96be\u4ee5\u63a8\u5e7f\u6216\u96c6\u6210\u5230\u7edf\u4e00\u4eff\u771f\u73af\u5883\u4e2d\u7684\u5b64\u7acb\u6846\u67b6\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u901a\u7528\u7684\u65b9\u6cd5\u6765\u5206\u6790\u611f\u77e5\u6545\u969c\u5bf9\u5b89\u5168\u6027\u7684\u5f71\u54cd\u3002", "method": "\u5c06\u611f\u77e5\u6545\u969c\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5e7b\u89c9\uff0c\u63d0\u51fa\u7ec4\u4ef6\u65e0\u5173\u7684\u5e7b\u89c9\u6ce8\u5165\u6846\u67b6\uff0c\u5728\u5f00\u6e90\u6a21\u62df\u5668\u4e2d\u6ce8\u5165\u516d\u79cd\u53ef\u4fe1\u5e7b\u89c9\u7c7b\u578b\uff0c\u6267\u884c\u8d85\u8fc718,350\u6b21\u6a21\u62df\u6765\u6d4b\u8bd5\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u65e0\u4fe1\u53f7\u4ea4\u53c9\u8def\u53e3\u7684\u6027\u80fd\u3002", "result": "\u7edf\u8ba1\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027\uff0c\u91cf\u5316\u4e86\u6bcf\u79cd\u5e7b\u89c9\u7c7b\u578b\u5bf9\u78b0\u649e\u548c\u9669\u60c5\u7684\u5f71\u54cd\uff0c\u67d0\u4e9b\u5e7b\u89c9\uff08\u5982\u611f\u77e5\u5ef6\u8fdf\u548c\u6f02\u79fb\uff09\u663e\u8457\u589e\u52a0\u4e86\u6d4b\u8bd5\u573a\u666f\u4e2d\u7684\u78b0\u649e\u98ce\u9669\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u7edf\u8ba1\u9a8c\u8bc1\u3001\u7ec4\u4ef6\u65e0\u5173\u4e14\u5b8c\u5168\u4e92\u64cd\u4f5c\u7684\u5de5\u5177\u96c6\uff0c\u53ef\u7b80\u5316\u548c\u52a0\u901f\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u9a8c\u8bc1\uff0c\u4e3a\u5bb9\u9519\u548c\u5f39\u6027\u81ea\u52a8\u9a7e\u9a76\u8bbe\u8ba1\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.07489", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.07489", "abs": "https://arxiv.org/abs/2510.07489", "authors": ["Akhil Kumar", "Jianliang Leon Zhao", "Om Dobariya"], "title": "Evaluation of LLMs for Process Model Analysis and Optimization", "comment": "15 pages, 5 tables, 4 figures; full research paper currently under\n  review for the Workshop on Information Technologies and Systems (WITS) 2025.\n  The paper presents a comprehensive evaluation of large language models (LLMs)\n  for business process model analysis and optimization, including error\n  detection, reasoning, and scenario-based redesign", "summary": "In this paper, we report our experience with several LLMs for their ability\nto understand a process model in an interactive, conversational style, find\nsyntactical and logical errors in it, and reason with it in depth through a\nnatural language (NL) interface. Our findings show that a vanilla, untrained\nLLM like ChatGPT (model o3) in a zero-shot setting is effective in\nunderstanding BPMN process models from images and answering queries about them\nintelligently at syntactic, logic, and semantic levels of depth. Further,\ndifferent LLMs vary in performance in terms of their accuracy and\neffectiveness. Nevertheless, our empirical analysis shows that LLMs can play a\nvaluable role as assistants for business process designers and users. We also\nstudy the LLM's \"thought process\" and ability to perform deeper reasoning in\nthe context of process analysis and optimization. We find that the LLMs seem to\nexhibit anthropomorphic properties.", "AI": {"tldr": "LLMs\uff08\u5982ChatGPT o3\u6a21\u578b\uff09\u80fd\u591f\u7406\u89e3BPMN\u6d41\u7a0b\u6a21\u578b\u56fe\u50cf\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u754c\u9762\u8fdb\u884c\u5bf9\u8bdd\u5f0f\u4ea4\u4e92\uff0c\u53d1\u73b0\u8bed\u6cd5\u548c\u903b\u8f91\u9519\u8bef\uff0c\u5e76\u5728\u8bed\u6cd5\u3001\u903b\u8f91\u548c\u8bed\u4e49\u5c42\u9762\u8fdb\u884c\u6df1\u5ea6\u63a8\u7406\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u7406\u89e3\u4e1a\u52a1\u6d41\u7a0b\u6a21\u578b\u3001\u53d1\u73b0\u9519\u8bef\u548c\u8fdb\u884c\u6df1\u5ea6\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u8bc4\u4f30\u5176\u4f5c\u4e3a\u4e1a\u52a1\u6d41\u7a0b\u8bbe\u8ba1\u52a9\u624b\u7684\u4f5c\u7528\u3002", "method": "\u4f7f\u7528\u591a\u4e2aLLMs\uff08\u5305\u62ecChatGPT o3\u6a21\u578b\uff09\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u6d4b\u8bd5\u5176\u5bf9BPMN\u6d41\u7a0b\u6a21\u578b\u56fe\u50cf\u7684\u7406\u89e3\u80fd\u529b\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u754c\u9762\u8fdb\u884c\u5bf9\u8bdd\u5f0f\u4ea4\u4e92\u5206\u6790\u3002", "result": "\u672a\u7ecf\u8bad\u7ec3\u7684LLMs\u5728\u7406\u89e3BPMN\u6d41\u7a0b\u6a21\u578b\u65b9\u9762\u8868\u73b0\u6709\u6548\uff0c\u80fd\u591f\u56de\u7b54\u8bed\u6cd5\u3001\u903b\u8f91\u548c\u8bed\u4e49\u5c42\u9762\u7684\u67e5\u8be2\uff0c\u4f46\u4e0d\u540cLLMs\u5728\u51c6\u786e\u6027\u548c\u6709\u6548\u6027\u65b9\u9762\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "LLMs\u53ef\u4ee5\u4f5c\u4e3a\u4e1a\u52a1\u6d41\u7a0b\u8bbe\u8ba1\u8005\u548c\u7528\u6237\u7684\u6709\u4ef7\u503c\u52a9\u624b\uff0c\u5c55\u73b0\u51fa\u7c7b\u4eba\u5316\u7684\u63a8\u7406\u7279\u6027\uff0c\u5177\u5907\u5728\u6d41\u7a0b\u5206\u6790\u548c\u4f18\u5316\u4e2d\u53d1\u6325\u4f5c\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.07363", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07363", "abs": "https://arxiv.org/abs/2510.07363", "authors": ["Tianxiang Xu", "Zhichao Wen", "Xinyu Zhao", "Jun Wang", "Yan Li", "Chang Liu"], "title": "L2M-AID: Autonomous Cyber-Physical Defense by Fusing Semantic Reasoning of Large Language Models with Multi-Agent Reinforcement Learning (Preprint)", "comment": "This preprint was submitted to IEEE TrustCom 2025. The accepted\n  version will be published under copyright 2025 IEEE", "summary": "The increasing integration of Industrial IoT (IIoT) exposes critical\ncyber-physical systems to sophisticated, multi-stage attacks that elude\ntraditional defenses lacking contextual awareness. This paper introduces\nL2M-AID, a novel framework for Autonomous Industrial Defense using\nLLM-empowered, Multi-agent reinforcement learning. L2M-AID orchestrates a team\nof collaborative agents, each driven by a Large Language Model (LLM), to\nachieve adaptive and resilient security. The core innovation lies in the deep\nfusion of two AI paradigms: we leverage an LLM as a semantic bridge to\ntranslate vast, unstructured telemetry into a rich, contextual state\nrepresentation, enabling agents to reason about adversary intent rather than\nmerely matching patterns. This semantically-aware state empowers a Multi-Agent\nReinforcement Learning (MARL) algorithm, MAPPO, to learn complex cooperative\nstrategies. The MARL reward function is uniquely engineered to balance security\nobjectives (threat neutralization) with operational imperatives, explicitly\npenalizing actions that disrupt physical process stability. To validate our\napproach, we conduct extensive experiments on the benchmark SWaT dataset and a\nnovel synthetic dataset generated based on the MITRE ATT&CK for ICS framework.\nResults demonstrate that L2M-AID significantly outperforms traditional IDS,\ndeep learning anomaly detectors, and single-agent RL baselines across key\nmetrics, achieving a 97.2% detection rate while reducing false positives by\nover 80% and improving response times by a factor of four. Crucially, it\ndemonstrates superior performance in maintaining physical process stability,\npresenting a robust new paradigm for securing critical national infrastructure.", "AI": {"tldr": "L2M-AID\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u8d4b\u80fd\u7684\u5de5\u4e1a\u7269\u8054\u7f51\u81ea\u4e3b\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u81ea\u9002\u5e94\u5b89\u5168\u9632\u62a4\uff0c\u5728\u5a01\u80c1\u68c0\u6d4b\u7387\u548c\u8bef\u62a5\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5de5\u4e1a\u7269\u8054\u7f51(IIoT)\u7684\u666e\u53ca\u4f7f\u5173\u952e\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u9762\u4e34\u590d\u6742\u7684\u591a\u9636\u6bb5\u653b\u51fb\uff0c\u4f20\u7edf\u9632\u5fa1\u7f3a\u4e4f\u60c5\u5883\u611f\u77e5\u80fd\u529b\uff0c\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u8fd9\u4e9b\u5a01\u80c1\u3002", "method": "\u63d0\u51faL2M-AID\u6846\u67b6\uff0c\u878d\u5408LLM\u548c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff1a\u4f7f\u7528LLM\u4f5c\u4e3a\u8bed\u4e49\u6865\u6881\u5c06\u975e\u7ed3\u6784\u5316\u9065\u6d4b\u6570\u636e\u8f6c\u6362\u4e3a\u60c5\u5883\u611f\u77e5\u72b6\u6001\u8868\u793a\uff0c\u7136\u540e\u91c7\u7528MAPPO\u7b97\u6cd5\u5b66\u4e60\u534f\u4f5c\u7b56\u7565\uff0c\u5956\u52b1\u51fd\u6570\u5e73\u8861\u5b89\u5168\u76ee\u6807\u548c\u64cd\u4f5c\u9700\u6c42\u3002", "result": "\u5728SWaT\u6570\u636e\u96c6\u548c\u57fa\u4e8eMITRE ATT&CK\u7684\u5408\u6210\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0cL2M-AID\u8fbe\u523097.2%\u68c0\u6d4b\u7387\uff0c\u8bef\u62a5\u7387\u964d\u4f4e80%\u4ee5\u4e0a\uff0c\u54cd\u5e94\u65f6\u95f4\u63d0\u53474\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u7269\u7406\u8fc7\u7a0b\u7a33\u5b9a\u6027\u3002", "conclusion": "L2M-AID\u4e3a\u4fdd\u62a4\u5173\u952e\u56fd\u5bb6\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u65b0\u8303\u5f0f\uff0c\u5728\u5a01\u80c1\u68c0\u6d4b\u548c\u7cfb\u7edf\u7a33\u5b9a\u6027\u65b9\u9762\u8868\u73b0\u5353\u8d8a\u3002"}}
{"id": "2510.08119", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.08119", "abs": "https://arxiv.org/abs/2510.08119", "authors": ["Frank Mukwege", "Tam Willy Nguyen", "Emanuele Garone"], "title": "General formulation of an analytic, Lipschitz continuous control allocation for thrust-vectored controlled rigid-bodies", "comment": null, "summary": "This study introduces a systematic and scalable method for arbitrary\nrigid-bodies equipped with vectorized thrusters. Two novel solutions are\nproposed: a closed-form, Lipschitz continuous mapping that ensures smooth\nactuator orientation references, and a convex optimization formulation capable\nof handling practical actuator constraints such as thrust saturation and\nangular rate limits. Both methods leverage the null-space structure of the\nallocation mapping to perform singularity avoidance while generating\nsub-optimal yet practical solutions. The effectiveness and generality of the\nproposed framework are demonstrated through numerical simulations on a 3DOF\nmarine vessel and a 6DOF aerial quadcopter.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u9896\u7684\u63a8\u529b\u5206\u914d\u65b9\u6cd5\uff1a\u95ed\u5f0fLipschitz\u8fde\u7eed\u6620\u5c04\u548c\u51f8\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u5e26\u77e2\u91cf\u63a8\u8fdb\u5668\u7684\u521a\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u907f\u514d\u5947\u5f02\u6027\u5e76\u5904\u7406\u63a8\u529b\u9971\u548c\u548c\u89d2\u901f\u7387\u9650\u5236\u7b49\u5b9e\u9645\u7ea6\u675f\u3002", "motivation": "\u4e3a\u5177\u6709\u77e2\u91cf\u63a8\u8fdb\u5668\u7684\u521a\u4f53\u7cfb\u7edf\u5f00\u53d1\u7cfb\u7edf\u5316\u548c\u53ef\u6269\u5c55\u7684\u63a8\u529b\u5206\u914d\u65b9\u6cd5\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u5947\u5f02\u6027\u3001\u5e73\u6ed1\u6027\u548c\u5b9e\u9645\u7ea6\u675f\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "1. \u95ed\u5f0fLipschitz\u8fde\u7eed\u6620\u5c04\u786e\u4fdd\u5e73\u6ed1\u7684\u6267\u884c\u5668\u65b9\u5411\u53c2\u8003\uff1b2. \u51f8\u4f18\u5316\u516c\u5f0f\u5904\u7406\u63a8\u529b\u9971\u548c\u548c\u89d2\u901f\u7387\u9650\u5236\u7b49\u5b9e\u9645\u7ea6\u675f\uff1b3. \u5229\u7528\u5206\u914d\u6620\u5c04\u7684\u96f6\u7a7a\u95f4\u7ed3\u6784\u8fdb\u884c\u5947\u5f02\u6027\u907f\u514d\u3002", "result": "\u901a\u8fc73\u81ea\u7531\u5ea6\u6d77\u6d0b\u8239\u8236\u548c6\u81ea\u7531\u5ea6\u7a7a\u4e2d\u56db\u65cb\u7ffc\u7684\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u4e86\u6240\u63d0\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u751f\u6210\u6b21\u4f18\u4f46\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u907f\u514d\u5947\u5f02\u6027\u7684\u540c\u65f6\u6709\u6548\u5904\u7406\u5b9e\u9645\u6267\u884c\u5668\u7ea6\u675f\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u521a\u4f53\u7cfb\u7edf\u3002"}}
{"id": "2510.07773", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07773", "abs": "https://arxiv.org/abs/2510.07773", "authors": ["YuHang Tang", "Yixuan Lou", "Pengfei Han", "Haoming Song", "Xinyi Ye", "Dong Wang", "Bin Zhao"], "title": "Trajectory Conditioned Cross-embodiment Skill Transfer", "comment": null, "summary": "Learning manipulation skills from human demonstration videos presents a\npromising yet challenging problem, primarily due to the significant embodiment\ngap between human body and robot manipulators. Existing methods rely on paired\ndatasets or hand-crafted rewards, which limit scalability and generalization.\nWe propose TrajSkill, a framework for Trajectory Conditioned Cross-embodiment\nSkill Transfer, enabling robots to acquire manipulation skills directly from\nhuman demonstration videos. Our key insight is to represent human motions as\nsparse optical flow trajectories, which serve as embodiment-agnostic motion\ncues by removing morphological variations while preserving essential dynamics.\nConditioned on these trajectories together with visual and textual inputs,\nTrajSkill jointly synthesizes temporally consistent robot manipulation videos\nand translates them into executable actions, thereby achieving cross-embodiment\nskill transfer. Extensive experiments are conducted, and the results on\nsimulation data (MetaWorld) show that TrajSkill reduces FVD by 39.6\\% and KVD\nby 36.6\\% compared with the state-of-the-art, and improves cross-embodiment\nsuccess rate by up to 16.7\\%. Real-robot experiments in kitchen manipulation\ntasks further validate the effectiveness of our approach, demonstrating\npractical human-to-robot skill transfer across embodiments.", "AI": {"tldr": "TrajSkill\u662f\u4e00\u4e2a\u4ece\u4eba\u7c7b\u6f14\u793a\u89c6\u9891\u4e2d\u5b66\u4e60\u673a\u5668\u4eba\u64cd\u4f5c\u6280\u80fd\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4eba\u7c7b\u52a8\u4f5c\u8868\u793a\u4e3a\u7a00\u758f\u5149\u6d41\u8f68\u8ff9\u6765\u5b9e\u73b0\u8de8\u5f62\u6001\u6280\u80fd\u8fc1\u79fb\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u914d\u5bf9\u6570\u636e\u96c6\u6216\u624b\u5de5\u8bbe\u8ba1\u7684\u5956\u52b1\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u4eba\u7c7b\u4e0e\u673a\u5668\u4eba\u4e4b\u95f4\u7684\u5f62\u6001\u5dee\u5f02\u662f\u4e3b\u8981\u6311\u6218\u3002", "method": "\u5c06\u4eba\u7c7b\u52a8\u4f5c\u8868\u793a\u4e3a\u7a00\u758f\u5149\u6d41\u8f68\u8ff9\u4f5c\u4e3a\u5f62\u6001\u65e0\u5173\u7684\u8fd0\u52a8\u7ebf\u7d22\uff0c\u7ed3\u5408\u89c6\u89c9\u548c\u6587\u672c\u8f93\u5165\uff0c\u8054\u5408\u5408\u6210\u65f6\u95f4\u4e00\u81f4\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u89c6\u9891\u5e76\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u52a8\u4f5c\u3002", "result": "\u5728MetaWorld\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\uff0cFVD\u964d\u4f4e39.6%\uff0cKVD\u964d\u4f4e36.6%\uff0c\u8de8\u5f62\u6001\u6210\u529f\u7387\u63d0\u5347\u8fbe16.7%\u3002\u771f\u5b9e\u673a\u5668\u4eba\u53a8\u623f\u64cd\u4f5c\u4efb\u52a1\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "TrajSkill\u5b9e\u73b0\u4e86\u4ece\u4eba\u7c7b\u6f14\u793a\u89c6\u9891\u5230\u673a\u5668\u4eba\u7684\u5b9e\u7528\u8de8\u5f62\u6001\u6280\u80fd\u8fc1\u79fb\uff0c\u4e3a\u673a\u5668\u4eba\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.07709", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.07709", "abs": "https://arxiv.org/abs/2510.07709", "authors": ["Alhim Vera", "Karen Sanchez", "Carlos Hinojosa", "Haidar Bin Hamid", "Donghoon Kim", "Bernard Ghanem"], "title": "Multimodal Safety Evaluation in Generative Agent Social Simulations", "comment": null, "summary": "Can generative agents be trusted in multimodal environments? Despite advances\nin large language and vision-language models that enable agents to act\nautonomously and pursue goals in rich settings, their ability to reason about\nsafety, coherence, and trust across modalities remains limited. We introduce a\nreproducible simulation framework for evaluating agents along three dimensions:\n(1) safety improvement over time, including iterative plan revisions in\ntext-visual scenarios; (2) detection of unsafe activities across multiple\ncategories of social situations; and (3) social dynamics, measured as\ninteraction counts and acceptance ratios of social exchanges. Agents are\nequipped with layered memory, dynamic planning, multimodal perception, and are\ninstrumented with SocialMetrics, a suite of behavioral and structural metrics\nthat quantifies plan revisions, unsafe-to-safe conversions, and information\ndiffusion across networks. Experiments show that while agents can detect direct\nmultimodal contradictions, they often fail to align local revisions with global\nsafety, reaching only a 55 percent success rate in correcting unsafe plans.\nAcross eight simulation runs with three models - Claude, GPT-4o mini, and\nQwen-VL - five agents achieved average unsafe-to-safe conversion rates of 75,\n55, and 58 percent, respectively. Overall performance ranged from 20 percent in\nmulti-risk scenarios with GPT-4o mini to 98 percent in localized contexts such\nas fire/heat with Claude. Notably, 45 percent of unsafe actions were accepted\nwhen paired with misleading visuals, showing a strong tendency to overtrust\nimages. These findings expose critical limitations in current architectures and\nprovide a reproducible platform for studying multimodal safety, coherence, and\nsocial dynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u4eff\u771f\u6846\u67b6\u6765\u8bc4\u4f30\u591a\u6a21\u6001\u73af\u5883\u4e2d\u751f\u6210\u5f0f\u667a\u80fd\u4f53\u7684\u5b89\u5168\u6027\u3001\u8fde\u8d2f\u6027\u548c\u4fe1\u4efb\u5ea6\uff0c\u53d1\u73b0\u5f53\u524d\u667a\u80fd\u4f53\u5728\u68c0\u6d4b\u591a\u6a21\u6001\u77db\u76fe\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5168\u5c40\u5b89\u5168\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u8bef\u5bfc\u6027\u89c6\u89c9\u4fe1\u606f\u4e0b\u5bb9\u6613\u8fc7\u5ea6\u4fe1\u4efb\u56fe\u50cf\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5728\u4e30\u5bcc\u73af\u5883\u4e2d\u81ea\u4e3b\u884c\u52a8\uff0c\u4f46\u5b83\u4eec\u5728\u8de8\u6a21\u6001\u7684\u5b89\u5168\u6027\u3001\u8fde\u8d2f\u6027\u548c\u4fe1\u4efb\u63a8\u7406\u80fd\u529b\u4ecd\u7136\u6709\u9650\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f15\u5165\u53ef\u590d\u73b0\u4eff\u771f\u6846\u67b6\uff0c\u914d\u5907\u5206\u5c42\u8bb0\u5fc6\u3001\u52a8\u6001\u89c4\u5212\u3001\u591a\u6a21\u6001\u611f\u77e5\u548cSocialMetrics\u884c\u4e3a\u6307\u6807\u5957\u4ef6\uff0c\u91cf\u5316\u8ba1\u5212\u4fee\u8ba2\u3001\u4e0d\u5b89\u5168\u5230\u5b89\u5168\u8f6c\u6362\u4ee5\u53ca\u7f51\u7edc\u4fe1\u606f\u6269\u6563\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u667a\u80fd\u4f53\u5728\u7ea0\u6b63\u4e0d\u5b89\u5168\u8ba1\u5212\u65b9\u9762\u6210\u529f\u7387\u4ec555%\uff0c\u5728\u8bef\u5bfc\u6027\u89c6\u89c9\u4fe1\u606f\u4e0b45%\u7684\u4e0d\u5b89\u5168\u884c\u4e3a\u88ab\u63a5\u53d7\uff0c\u4e0d\u540c\u6a21\u578b\u5728\u5b89\u5168\u8f6c\u6362\u7387\u4e0a\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff08Claude 75%\u3001GPT-4o mini 55%\u3001Qwen-VL 58%\uff09\u3002", "conclusion": "\u5f53\u524d\u67b6\u6784\u5728\u591a\u6a21\u6001\u5b89\u5168\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u5173\u952e\u9650\u5236\uff0c\u8be5\u6846\u67b6\u4e3a\u7814\u7a76\u591a\u6a21\u6001\u5b89\u5168\u6027\u3001\u8fde\u8d2f\u6027\u548c\u793e\u4ea4\u52a8\u6001\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u5e73\u53f0\u3002"}}
{"id": "2510.07364", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.07364", "abs": "https://arxiv.org/abs/2510.07364", "authors": ["Constantin Venhoff", "Iv\u00e1n Arcuschin", "Philip Torr", "Arthur Conmy", "Neel Nanda"], "title": "Base Models Know How to Reason, Thinking Models Learn When", "comment": "10 pages", "summary": "Why do thinking language models like DeepSeek R1 outperform their base\ncounterparts? Despite consistent performance gains, it remains unclear to what\nextent thinking models learn entirely new reasoning capabilities or repurpose\npre-existing base model ones. In this work, we propose a hybrid model where we\nactivate reasoning mechanisms in base models at the right time to elicit\nthinking-model-level reasoning chains, implying that thinking models exploit\nalready existing capabilities. To ground our analysis, we introduce an\nunsupervised, bottom-up approach for uncovering human-interpretable reasoning\nbehaviors in thinking models. This approach provides an unbiased method to\ndiscover reasoning behaviors without imposing manual or LLM-derived\nassumptions. Across three base and four thinking models, using GSM8K and\nMATH500, our hybrid model recovers up to 91% of the performance gap to thinking\nmodels without any weight updates while steering only 12% of tokens.\nConcretely, our empirical setup provides a simple, causal way to test the\neffectiveness of existing reasoning mechanisms in base models by invoking them\ndirectly and measuring the resulting task performance. More broadly, these\nresults reframe our understanding of how thinking models are trained:\npre-training is when models acquire most of their reasoning mechanisms, and\npost-training teaches efficient deployment of these mechanisms at the right\ntime, enabling efficient use of their inference-time compute.", "AI": {"tldr": "\u601d\u8003\u6a21\u578b\uff08\u5982DeepSeek R1\uff09\u901a\u8fc7\u6709\u6548\u6fc0\u6d3b\u57fa\u7840\u6a21\u578b\u4e2d\u5df2\u6709\u7684\u63a8\u7406\u673a\u5236\uff0c\u5728\u6b63\u786e\u65f6\u673a\u89e6\u53d1\u63a8\u7406\u94fe\uff0c\u800c\u975e\u5b66\u4e60\u5168\u65b0\u80fd\u529b\uff0c\u53ef\u6062\u590d\u601d\u8003\u6a21\u578b91%\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u63a2\u7a76\u601d\u8003\u6a21\u578b\u6027\u80fd\u63d0\u5347\u7684\u539f\u56e0\uff1a\u662f\u5b66\u4e60\u5168\u65b0\u63a8\u7406\u80fd\u529b\u8fd8\u662f\u91cd\u65b0\u5229\u7528\u57fa\u7840\u6a21\u578b\u5df2\u6709\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u6a21\u578b\uff0c\u5728\u57fa\u7840\u6a21\u578b\u4e2d\u9002\u65f6\u6fc0\u6d3b\u63a8\u7406\u673a\u5236\uff1b\u5f15\u5165\u65e0\u76d1\u7763\u3001\u81ea\u4e0b\u800c\u4e0a\u7684\u65b9\u6cd5\u53d1\u73b0\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u884c\u4e3a\uff1b\u5728\u4e09\u4e2a\u57fa\u7840\u6a21\u578b\u548c\u56db\u4e2a\u601d\u8003\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0c\u4f7f\u7528GSM8K\u548cMATH500\u6570\u636e\u96c6\u3002", "result": "\u6df7\u5408\u6a21\u578b\u65e0\u9700\u6743\u91cd\u66f4\u65b0\u5373\u53ef\u6062\u590d\u601d\u8003\u6a21\u578b91%\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u4ec5\u9700\u5f15\u5bfc12%\u7684token\uff1b\u63d0\u4f9b\u56e0\u679c\u6d4b\u8bd5\u65b9\u6cd5\u9a8c\u8bc1\u57fa\u7840\u6a21\u578b\u63a8\u7406\u673a\u5236\u6709\u6548\u6027\u3002", "conclusion": "\u9884\u8bad\u7ec3\u9636\u6bb5\u6a21\u578b\u5df2\u83b7\u5f97\u5927\u90e8\u5206\u63a8\u7406\u673a\u5236\uff0c\u540e\u8bad\u7ec3\u9636\u6bb5\u6559\u4f1a\u6a21\u578b\u5728\u6b63\u786e\u65f6\u95f4\u9ad8\u6548\u90e8\u7f72\u8fd9\u4e9b\u673a\u5236\uff0c\u5b9e\u73b0\u63a8\u7406\u8ba1\u7b97\u7684\u9ad8\u6548\u5229\u7528\u3002"}}
{"id": "2510.08121", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.08121", "abs": "https://arxiv.org/abs/2510.08121", "authors": ["Umberto Zucchelli", "Miguel Alfonso Mendez", "Annafederica Urbano", "Sebastien Vincent-Bonnieu", "Piotr Wenderski", "Francesco Sanfedino"], "title": "Closed-loop control of sloshing fuel in a spinning spacecraft", "comment": null, "summary": "New-generation space missions require satellites to carry substantial amounts\nof liquid propellant, making it essential to analyse the coupled\ncontrol-structure-propellant dynamics in detail. While Computational Fluid\nDynamics (CFD) offers high-fidelity predictions, its computational cost limits\nits use in iterative design. Equivalent Mechanical Models (EMMs) provide a\nfaster alternative, though their predictive performance, especially in\nclosed-loop scenarios, remains largely unexplored. This work presents a\ncomparative analysis of a spacecraft under feedback control, using both CFD and\na reduced-order sloshing model. Results show good agreement, validating the\nsimplified model for the manoeuvrer considered. This validation enables\nefficient sensitivity and stability studies, offering a practical tool for\nearly-stage spacecraft design.", "AI": {"tldr": "\u6bd4\u8f83CFD\u548c\u7b80\u5316\u6a21\u578b\u5728\u822a\u5929\u5668\u63a7\u5236-\u7ed3\u6784-\u63a8\u8fdb\u5242\u8026\u5408\u52a8\u529b\u5b66\u5206\u6790\u4e2d\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u7b80\u5316\u6a21\u578b\u5728\u7279\u5b9a\u673a\u52a8\u4e2d\u7684\u6709\u6548\u6027", "motivation": "\u65b0\u4e00\u4ee3\u822a\u5929\u4efb\u52a1\u9700\u8981\u536b\u661f\u643a\u5e26\u5927\u91cf\u6db2\u4f53\u63a8\u8fdb\u5242\uff0c\u5fc5\u987b\u8be6\u7ec6\u5206\u6790\u63a7\u5236-\u7ed3\u6784-\u63a8\u8fdb\u5242\u8026\u5408\u52a8\u529b\u5b66\uff0c\u4f46CFD\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u800c\u7b49\u6548\u673a\u68b0\u6a21\u578b\u7684\u95ed\u73af\u6027\u80fd\u5c1a\u672a\u5145\u5206\u7814\u7a76", "method": "\u4f7f\u7528\u8ba1\u7b97\u6d41\u4f53\u52a8\u529b\u5b66\u548c\u964d\u9636\u6643\u52a8\u6a21\u578b\u5bf9\u53cd\u9988\u63a7\u5236\u4e0b\u7684\u822a\u5929\u5668\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790", "result": "\u4e24\u79cd\u65b9\u6cd5\u7ed3\u679c\u543b\u5408\u826f\u597d\uff0c\u9a8c\u8bc1\u4e86\u7b80\u5316\u6a21\u578b\u5728\u6240\u8003\u8651\u673a\u52a8\u4e2d\u7684\u6709\u6548\u6027", "conclusion": "\u8be5\u9a8c\u8bc1\u652f\u6301\u8fdb\u884c\u9ad8\u6548\u7684\u7075\u654f\u5ea6\u548c\u7a33\u5b9a\u6027\u7814\u7a76\uff0c\u4e3a\u65e9\u671f\u822a\u5929\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177"}}
{"id": "2510.07778", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.07778", "abs": "https://arxiv.org/abs/2510.07778", "authors": ["Yandu Chen", "Kefan Gu", "Yuqing Wen", "Yucheng Zhao", "Tiancai Wang", "Liqiang Nie"], "title": "IntentionVLA: Generalizable and Efficient Embodied Intention Reasoning for Human-Robot Interaction", "comment": null, "summary": "Vision-Language-Action (VLA) models leverage pretrained vision-language\nmodels (VLMs) to couple perception with robotic control, offering a promising\npath toward general-purpose embodied intelligence. However, current SOTA VLAs\nare primarily pretrained on multimodal tasks with limited relevance to embodied\nscenarios, and then finetuned to map explicit instructions to actions.\nConsequently, due to the lack of reasoning-intensive pretraining and\nreasoning-guided manipulation, these models are unable to perform implicit\nhuman intention reasoning required for complex, real-world interactions. To\novercome these limitations, we propose \\textbf{IntentionVLA}, a VLA framework\nwith a curriculum training paradigm and an efficient inference mechanism. Our\nproposed method first leverages carefully designed reasoning data that combine\nintention inference, spatial grounding, and compact embodied reasoning,\nendowing the model with both reasoning and perception capabilities. In the\nfollowing finetuning stage, IntentionVLA employs the compact reasoning outputs\nas contextual guidance for action generation, enabling fast inference under\nindirect instructions. Experimental results show that IntentionVLA\nsubstantially outperforms $\\pi_0$, achieving 18\\% higher success rates with\ndirect instructions and 28\\% higher than ECoT under intention instructions. On\nout-of-distribution intention tasks, IntentionVLA achieves over twice the\nsuccess rate of all baselines, and further enables zero-shot human-robot\ninteraction with 40\\% success rate. These results highlight IntentionVLA as a\npromising paradigm for next-generation human-robot interaction (HRI) systems.", "AI": {"tldr": "IntentionVLA\u662f\u4e00\u4e2a\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u8bfe\u7a0b\u8bad\u7ec3\u8303\u5f0f\u89e3\u51b3\u5f53\u524dVLA\u6a21\u578b\u5728\u9690\u542b\u4eba\u7c7b\u610f\u56fe\u63a8\u7406\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5728\u590d\u6742\u4ea4\u4e92\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u7684VLA\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u9884\u8bad\u7ec3\u540e\uff0c\u4ec5\u80fd\u6620\u5c04\u663e\u5f0f\u6307\u4ee4\u5230\u52a8\u4f5c\uff0c\u7f3a\u4e4f\u63a8\u7406\u5bc6\u96c6\u578b\u9884\u8bad\u7ec3\u548c\u63a8\u7406\u5f15\u5bfc\u7684\u64cd\u63a7\u80fd\u529b\uff0c\u65e0\u6cd5\u5904\u7406\u590d\u6742\u73b0\u5b9e\u4ea4\u4e92\u4e2d\u6240\u9700\u7684\u9690\u542b\u4eba\u7c7b\u610f\u56fe\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u8bfe\u7a0b\u8bad\u7ec3\u8303\u5f0f\uff1a\u9996\u5148\u4f7f\u7528\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63a8\u7406\u6570\u636e\uff08\u5305\u542b\u610f\u56fe\u63a8\u65ad\u3001\u7a7a\u95f4\u5b9a\u4f4d\u548c\u7d27\u51d1\u4f53\u73b0\u63a8\u7406\uff09\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u8d4b\u4e88\u6a21\u578b\u63a8\u7406\u548c\u611f\u77e5\u80fd\u529b\uff1b\u7136\u540e\u5728\u5fae\u8c03\u9636\u6bb5\u4f7f\u7528\u7d27\u51d1\u63a8\u7406\u8f93\u51fa\u4f5c\u4e3a\u52a8\u4f5c\u751f\u6210\u7684\u4e0a\u4e0b\u6587\u6307\u5bfc\uff0c\u5b9e\u73b0\u95f4\u63a5\u6307\u4ee4\u4e0b\u7684\u5feb\u901f\u63a8\u7406\u3002", "result": "IntentionVLA\u663e\u8457\u4f18\u4e8e\u03c00\u6a21\u578b\uff0c\u5728\u76f4\u63a5\u6307\u4ee4\u4e0b\u6210\u529f\u7387\u63d0\u9ad818%\uff0c\u5728\u610f\u56fe\u6307\u4ee4\u4e0b\u6bd4ECoT\u63d0\u9ad828%\u3002\u5728\u5206\u5e03\u5916\u610f\u56fe\u4efb\u52a1\u4e2d\uff0c\u6210\u529f\u7387\u662f\u57fa\u7ebf\u6a21\u578b\u7684\u4e24\u500d\u4ee5\u4e0a\uff0c\u5e76\u5728\u96f6\u6837\u672c\u4eba\u673a\u4ea4\u4e92\u4e2d\u8fbe\u523040%\u6210\u529f\u7387\u3002", "conclusion": "IntentionVLA\u4f5c\u4e3a\u4e0b\u4e00\u4ee3\u4eba\u673a\u4ea4\u4e92\u7cfb\u7edf\u7684\u6709\u524d\u666f\u8303\u5f0f\uff0c\u901a\u8fc7\u63a8\u7406\u5f15\u5bfc\u7684\u64cd\u63a7\u5b9e\u73b0\u4e86\u66f4\u81ea\u7136\u548c\u590d\u6742\u7684\u4eba\u673a\u4ea4\u4e92\u80fd\u529b\u3002"}}
{"id": "2510.07889", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.07889", "abs": "https://arxiv.org/abs/2510.07889", "authors": ["Dave Murray-Rust", "Kars Alfrink", "Cristina Zaga"], "title": "Towards Meaningful Transparency in Civic AI Systems", "comment": null, "summary": "Artificial intelligence has become a part of the provision of governmental\nservices, from making decisions about benefits to issuing fines for parking\nviolations. However, AI systems rarely live up to the promise of neutral\noptimisation, creating biased or incorrect outputs and reducing the agency of\nboth citizens and civic workers to shape the way decisions are made.\nTransparency is a principle that can both help subjects understand decisions\nmade about them and shape the processes behind those decisions. However,\ntransparency as practiced around AI systems tends to focus on the production of\ntechnical objects that represent algorithmic aspects of decision making. These\nare often difficult for publics to understand, do not connect to potential for\naction, and do not give insight into the wider socio-material context of\ndecision making. In this paper, we build on existing approaches that take a\nhuman-centric view on AI transparency, combined with a socio-technical systems\nview, to develop the concept of meaningful transparency for civic AI systems:\ntransparencies that allow publics to engage with AI systems that affect their\nlives, connecting understanding with potential for action.", "AI": {"tldr": "\u63d0\u51fa\u6709\u610f\u4e49\u900f\u660e\u5ea6\u6982\u5ff5\uff0c\u8ba9\u516c\u4f17\u80fd\u591f\u7406\u89e3\u5e76\u53c2\u4e0e\u5f71\u54cd\u4ed6\u4eec\u751f\u6d3b\u7684AI\u7cfb\u7edf\u51b3\u7b56\u8fc7\u7a0b", "motivation": "AI\u7cfb\u7edf\u5728\u653f\u5e9c\u670d\u52a1\u4e2d\u5e38\u4ea7\u751f\u504f\u89c1\u6216\u9519\u8bef\u8f93\u51fa\uff0c\u964d\u4f4e\u516c\u6c11\u548c\u516c\u52a1\u5458\u7684\u51b3\u7b56\u53c2\u4e0e\u6743\uff0c\u73b0\u6709\u900f\u660e\u5ea6\u65b9\u6cd5\u8fc7\u4e8e\u6280\u672f\u5316\u4e14\u96be\u4ee5\u7406\u89e3", "method": "\u7ed3\u5408\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684AI\u900f\u660e\u5ea6\u65b9\u6cd5\u548c\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u89c6\u89d2\uff0c\u53d1\u5c55\u6709\u610f\u4e49\u900f\u660e\u5ea6\u6982\u5ff5", "result": "\u5efa\u7acb\u4e86\u6709\u610f\u4e49\u900f\u660e\u5ea6\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5f3a\u8c03\u5c06\u7406\u89e3\u4e0e\u884c\u52a8\u6f5c\u529b\u8054\u7cfb\u8d77\u6765", "conclusion": "\u6709\u610f\u4e49\u900f\u660e\u5ea6\u80fd\u591f\u5e2e\u52a9\u516c\u4f17\u53c2\u4e0e\u5f71\u54cd\u4ed6\u4eec\u751f\u6d3b\u7684AI\u7cfb\u7edf\u51b3\u7b56\uff0c\u8fde\u63a5\u7406\u89e3\u4e0e\u884c\u52a8\u80fd\u529b"}}
{"id": "2510.07409", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07409", "abs": "https://arxiv.org/abs/2510.07409", "authors": ["Neil Natarajan", "Sruthi Viswanathan", "Xavier Roberts-Gaal", "Michelle Marie Martel"], "title": "Position: AI Will Transform Neuropsychology Through Mental Health Digital Twins for Dynamic Mental Health Care, Especially for ADHD", "comment": null, "summary": "Static solutions don't serve a dynamic mind. Thus, we advocate a shift from\nstatic mental health diagnostic assessments to continuous, artificial\nintelligence (AI)-driven assessment. Focusing on\nAttention-Deficit/Hyperactivity Disorder (ADHD) as a case study, we explore how\ngenerative AI has the potential to address current capacity constraints in\nneuropsychology, potentially enabling more personalized and longitudinal care\npathways. In particular, AI can efficiently conduct frequent, low-level\nexperience sampling from patients and facilitate diagnostic reconciliation\nacross care pathways. We envision a future where mental health care benefits\nfrom continuous, rich, and patient-centered data sampling to dynamically adapt\nto individual patient needs and evolving conditions, thereby improving both\naccessibility and efficacy of treatment. We further propose the use of mental\nhealth digital twins (MHDTs) - continuously updated computational models that\ncapture individual symptom dynamics and trajectories - as a transformative\nframework for personalized mental health care. We ground this framework in\nempirical evidence and map out the research agenda required to refine and\noperationalize it.", "AI": {"tldr": "\u63d0\u51fa\u4ece\u9759\u6001\u5fc3\u7406\u5065\u5eb7\u8bca\u65ad\u8f6c\u5411AI\u9a71\u52a8\u7684\u8fde\u7eed\u8bc4\u4f30\uff0c\u4ee5ADHD\u4e3a\u4f8b\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5982\u4f55\u89e3\u51b3\u795e\u7ecf\u5fc3\u7406\u5b66\u80fd\u529b\u9650\u5236\uff0c\u5b9e\u73b0\u4e2a\u6027\u5316\u3001\u7eb5\u5411\u62a4\u7406\u8def\u5f84\uff0c\u5e76\u5f15\u5165\u5fc3\u7406\u5065\u5eb7\u6570\u5b57\u5b6a\u751f\u4f5c\u4e3a\u53d8\u9769\u6027\u6846\u67b6\u3002", "motivation": "\u9759\u6001\u89e3\u51b3\u65b9\u6848\u65e0\u6cd5\u6ee1\u8db3\u52a8\u6001\u5fc3\u7406\u9700\u6c42\uff0c\u5f53\u524d\u5fc3\u7406\u5065\u5eb7\u8bca\u65ad\u5b58\u5728\u80fd\u529b\u9650\u5236\uff0c\u9700\u8981\u66f4\u4e2a\u6027\u5316\u3001\u8fde\u7eed\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u63d0\u9ad8\u6cbb\u7597\u7684\u53ef\u53ca\u6027\u548c\u6709\u6548\u6027\u3002", "method": "\u5229\u7528\u751f\u6210\u5f0fAI\u8fdb\u884c\u9891\u7e41\u3001\u4f4e\u6c34\u5e73\u7684\u7ecf\u9a8c\u91c7\u6837\uff0c\u4fc3\u8fdb\u8bca\u65ad\u534f\u8c03\uff0c\u6784\u5efa\u5fc3\u7406\u5065\u5eb7\u6570\u5b57\u5b6a\u751f\u4f5c\u4e3a\u6301\u7eed\u66f4\u65b0\u7684\u8ba1\u7b97\u6a21\u578b\u6765\u6355\u6349\u4e2a\u4f53\u75c7\u72b6\u52a8\u6001\u3002", "result": "AI\u9a71\u52a8\u7684\u8fde\u7eed\u8bc4\u4f30\u80fd\u591f\u66f4\u6709\u6548\u5730\u6536\u96c6\u60a3\u8005\u6570\u636e\uff0c\u5b9e\u73b0\u52a8\u6001\u9002\u5e94\u4e2a\u4f53\u9700\u6c42\uff0c\u6539\u5584\u6cbb\u7597\u7684\u53ef\u53ca\u6027\u548c\u6548\u679c\u3002", "conclusion": "AI\u9a71\u52a8\u7684\u8fde\u7eed\u8bc4\u4f30\u548c\u5fc3\u7406\u5065\u5eb7\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u6709\u671b\u53d8\u9769\u5fc3\u7406\u5065\u5eb7\u62a4\u7406\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u6765\u5b8c\u5584\u548c\u64cd\u4f5c\u5316\u8fd9\u4e00\u6846\u67b6\u3002"}}
{"id": "2510.08172", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.08172", "abs": "https://arxiv.org/abs/2510.08172", "authors": ["Maurizio Vassallo", "Adrien Bolland", "Alireza Bahmanyar", "Louis Wehenkel", "Laurine Duchesne", "Dong Liu", "Sania Khaskheli", "Alexis Ha Thuc", "Pedro P. Vergara", "Amjad Anvari-Moghaddam", "Simon Gerard", "Damien Ernst"], "title": "SecuLEx: a Secure Limit Exchange Market for Dynamic Operating Envelopes", "comment": null, "summary": "Distributed energy resources (DERs) are transforming power networks,\nchallenging traditional operational methods, and requiring new coordination\nmechanisms. To address this challenge, this paper introduces SecuLEx (Secure\nLimit Exchange), a new market-based paradigm to allocate power injection and\nwithdrawal limits that guarantee network security during time periods, called\ndynamic operating envelopes (DOEs). Under this paradigm, distribution system\noperators (DSOs) assign initial DOEs to customers. These limits can be\nexchanged afterward through a market, allowing customers to reallocate them\naccording to their needs while ensuring network operational constraints. We\nformalize SecuLEx and illustrate DOE allocation and market exchanges on a\nsmall-scale low-voltage (LV) network, demonstrating that both procedures are\ncomputationally tractable. In this example, SecuLEx reduces renewable\ncurtailment and improves grid utilization and social welfare compared to\ntraditional approaches.", "AI": {"tldr": "\u63d0\u51faSecuLEx\uff08\u5b89\u5168\u9650\u989d\u4ea4\u6362\uff09\u5e02\u573a\u673a\u5236\uff0c\u901a\u8fc7\u52a8\u6001\u8fd0\u884c\u5305\u7edc\u5206\u914d\u548c\u4ea4\u6362\u7535\u529b\u6ce8\u5165/\u63d0\u53d6\u9650\u989d\uff0c\u786e\u4fdd\u7535\u7f51\u5b89\u5168\u5e76\u63d0\u9ad8\u53ef\u518d\u751f\u80fd\u6e90\u5229\u7528\u7387\u3002", "motivation": "\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\u6b63\u5728\u6539\u53d8\u7535\u7f51\u8fd0\u884c\uff0c\u6311\u6218\u4f20\u7edf\u8fd0\u8425\u65b9\u6cd5\uff0c\u9700\u8981\u65b0\u7684\u534f\u8c03\u673a\u5236\u6765\u4fdd\u8bc1\u7f51\u7edc\u5b89\u5168\u3002", "method": "\u5f15\u5165SecuLEx\u5e02\u573a\u8303\u5f0f\uff1a\u914d\u7535\u7f51\u8fd0\u8425\u5546\u5206\u914d\u521d\u59cb\u52a8\u6001\u8fd0\u884c\u5305\u7edc\uff0c\u7528\u6237\u53ef\u901a\u8fc7\u5e02\u573a\u4ea4\u6362\u91cd\u65b0\u5206\u914d\u9650\u989d\uff0c\u540c\u65f6\u786e\u4fdd\u7535\u7f51\u8fd0\u884c\u7ea6\u675f\u3002", "result": "\u5728\u5c0f\u89c4\u6a21\u4f4e\u538b\u7535\u7f51\u793a\u4f8b\u4e2d\uff0cSecuLEx\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u51cf\u5c11\u4e86\u53ef\u518d\u751f\u80fd\u6e90\u524a\u51cf\uff0c\u63d0\u9ad8\u4e86\u7535\u7f51\u5229\u7528\u7387\u548c\u793e\u4f1a\u798f\u5229\u3002", "conclusion": "SecuLEx\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba1\u7b97\u53ef\u884c\u7684\u5e02\u573a\u673a\u5236\uff0c\u80fd\u591f\u6709\u6548\u534f\u8c03\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\uff0c\u5728\u4fdd\u8bc1\u7f51\u7edc\u5b89\u5168\u7684\u540c\u65f6\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2510.07807", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07807", "abs": "https://arxiv.org/abs/2510.07807", "authors": ["Grace Cai", "Nithin Parepally", "Laura Zheng", "Ming C. Lin"], "title": "GM3: A General Physical Model for Micro-Mobility Vehicles", "comment": null, "summary": "Modeling the dynamics of micro-mobility vehicles (MMV) is becoming\nincreasingly important for training autonomous vehicle systems and building\nurban traffic simulations. However, mainstream tools rely on variants of the\nKinematic Bicycle Model (KBM) or mode-specific physics that miss tire slip,\nload transfer, and rider/vehicle lean. To our knowledge, no unified,\nphysics-based model captures these dynamics across the full range of common\nMMVs and wheel layouts. We propose the \"Generalized Micro-mobility Model\"\n(GM3), a tire-level formulation based on the tire brush representation that\nsupports arbitrary wheel configurations, including single/double track and\nmulti-wheel platforms. We introduce an interactive model-agnostic simulation\nframework that decouples vehicle/layout specification from dynamics to compare\nthe GM3 with the KBM and other models, consisting of fixed step RK4\nintegration, human-in-the-loop and scripted control, real-time trajectory\ntraces and logging for analysis. We also empirically validate the GM3 on the\nStanford Drone Dataset's deathCircle (roundabout) scene for biker, skater, and\ncart classes.", "AI": {"tldr": "\u63d0\u51fa\u4e86GM3\u6a21\u578b\uff0c\u4e00\u79cd\u57fa\u4e8e\u8f6e\u80ce\u5237\u5b50\u8868\u793a\u7684\u7edf\u4e00\u7269\u7406\u6a21\u578b\uff0c\u7528\u4e8e\u6a21\u62df\u5404\u79cd\u5fae\u79fb\u52a8\u8f66\u8f86\uff08MMV\uff09\u7684\u52a8\u529b\u5b66\u7279\u6027\uff0c\u5305\u62ec\u8f6e\u80ce\u6ed1\u79fb\u3001\u8f7d\u8377\u8f6c\u79fb\u548c\u9a91\u624b/\u8f66\u8f86\u503e\u659c\u7b49\u6548\u5e94\u3002", "motivation": "\u73b0\u6709\u4e3b\u6d41\u5de5\u5177\u4f9d\u8d56\u8fd0\u52a8\u5b66\u81ea\u884c\u8f66\u6a21\u578b\u6216\u7279\u5b9a\u6a21\u5f0f\u7684\u7269\u7406\u6a21\u578b\uff0c\u65e0\u6cd5\u6355\u6349\u8f6e\u80ce\u6ed1\u79fb\u3001\u8f7d\u8377\u8f6c\u79fb\u548c\u9a91\u624b/\u8f66\u8f86\u503e\u659c\u7b49\u5173\u952e\u52a8\u529b\u5b66\u7279\u6027\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u7269\u7406\u57fa\u7840\u6a21\u578b\u6765\u8986\u76d6\u5404\u79cd\u5e38\u89c1\u5fae\u79fb\u52a8\u8f66\u8f86\u548c\u8f66\u8f6e\u5e03\u5c40\u3002", "method": "\u63d0\u51fa\u4e86GM3\u6a21\u578b\uff0c\u57fa\u4e8e\u8f6e\u80ce\u5237\u5b50\u8868\u793a\uff0c\u652f\u6301\u4efb\u610f\u8f66\u8f6e\u914d\u7f6e\uff1b\u5f00\u53d1\u4e86\u4ea4\u4e92\u5f0f\u6a21\u578b\u65e0\u5173\u4eff\u771f\u6846\u67b6\uff0c\u4f7f\u7528\u56fa\u5b9a\u6b65\u957fRK4\u79ef\u5206\u3001\u4eba\u5728\u56de\u8def\u548c\u811a\u672c\u63a7\u5236\uff0c\u4ee5\u53ca\u5b9e\u65f6\u8f68\u8ff9\u8ddf\u8e2a\u548c\u65e5\u5fd7\u8bb0\u5f55\u3002", "result": "\u5728\u65af\u5766\u798f\u65e0\u4eba\u673a\u6570\u636e\u96c6\u7684deathCircle\u573a\u666f\u4e2d\u5bf9\u9a91\u884c\u8005\u3001\u6ed1\u677f\u8f66\u548c\u624b\u63a8\u8f66\u7c7b\u522b\u8fdb\u884c\u4e86\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "conclusion": "GM3\u6a21\u578b\u80fd\u591f\u7edf\u4e00\u6355\u6349\u5404\u79cd\u5fae\u79fb\u52a8\u8f66\u8f86\u7684\u52a8\u529b\u5b66\u7279\u6027\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u8bad\u7ec3\u548c\u57ce\u5e02\u4ea4\u901a\u4eff\u771f\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u5efa\u6a21\u5de5\u5177\u3002"}}
{"id": "2510.07423", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07423", "abs": "https://arxiv.org/abs/2510.07423", "authors": ["William Nguyen", "Vinh Luong", "Christopher Nguyen"], "title": "ProSEA: Problem Solving via Exploration Agents", "comment": null, "summary": "Large language models (LLMs) have empowered AI agents to tackle increasingly\ncomplex tasks. However, most existing agents remain limited to static planning\nand brittle interactions, falling short of true collaboration or adaptive\nreasoning. We introduce ProSEA, a modular, general-purpose multi-agent\nframework designed for iterative problem solving through exploration and plan\nevolution. ProSEA features a hierarchical architecture in which a Manager Agent\norchestrates domain-specialized Expert Agents, decomposes tasks, and adaptively\nreplans based on structured feedback from failed attempts. Unlike prior\nsystems, ProSEA agents report not only success or failure but also detailed\nreasons for failure and newly discovered constraints, enabling dynamic plan\nrefinement informed by exploratory traces. The framework operates autonomously\nbut supports seamless integration with human collaborators when needed.\nExperiments on the challenging FinanceBench benchmark demonstrate that ProSEA,\neven without human feedback, outperforms state-of-the-art baselines and\nachieves robust performance across reasoning-heavy tasks. These results\nunderscore ProSEA's potential as a foundation for more transparent, adaptive,\nand human-aligned AI agents.", "AI": {"tldr": "ProSEA\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u63a2\u7d22\u548c\u8ba1\u5212\u6f14\u5316\u5b9e\u73b0\u8fed\u4ee3\u5f0f\u95ee\u9898\u89e3\u51b3\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709AI\u667a\u80fd\u4f53\u4e3b\u8981\u5c40\u9650\u4e8e\u9759\u6001\u89c4\u5212\u548c\u8106\u5f31\u7684\u4ea4\u4e92\uff0c\u7f3a\u4e4f\u771f\u6b63\u7684\u534f\u4f5c\u548c\u81ea\u9002\u5e94\u63a8\u7406\u80fd\u529b\u3002", "method": "\u91c7\u7528\u5206\u5c42\u67b6\u6784\uff0cManager Agent\u534f\u8c03\u9886\u57df\u4e13\u5bb6Agent\uff0c\u5206\u89e3\u4efb\u52a1\u5e76\u6839\u636e\u5931\u8d25\u5c1d\u8bd5\u7684\u7ed3\u6784\u5316\u53cd\u9988\u8fdb\u884c\u81ea\u9002\u5e94\u91cd\u89c4\u5212\u3002", "result": "\u5728FinanceBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5373\u4f7f\u6ca1\u6709\u4eba\u7c7b\u53cd\u9988\uff0cProSEA\u4e5f\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "ProSEA\u4e3a\u6784\u5efa\u66f4\u900f\u660e\u3001\u81ea\u9002\u5e94\u4e14\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u7684AI\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u57fa\u7840\u3002"}}
{"id": "2510.08184", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.08184", "abs": "https://arxiv.org/abs/2510.08184", "authors": ["Rakesh Kumar Sahoo", "Paridhi Choudhary", "Manoranjan Sinha"], "title": "Satellite Navigation and Control using Physics-Informed Artificial Potential Field and Sliding Mode Controller", "comment": null, "summary": "Increase in the number of space exploration missions has led to the\naccumulation of space debris, posing risk of collision with the operational\nsatellites. Addressing this challenge is crucial for the sustainability of\nspace operations. To plan a safe trajectory in the presence of moving space\ndebris, an integrated approach of artificial potential field and sliding mode\ncontroller is proposed and implemented in this paper. The relative 6-DOF\nkinematics and dynamics of the spacecraft is modelled in the framework of\ngeometric mechanics with the relative configuration expressed through\nexponential coordinates. Various collision avoidance guidance algorithms have\nbeen proposed in the literature but the Artificial Potential Field guidance\nalgorithm is computationally efficient and enables real-time path adjustments\nto avoid collision with obstacles. However, it is prone to issues such as local\nminima. In literature, local minima issue is typically avoided by either\nredefining the potential function such as adding vorticity or by employing\nsearch techniques which are computationally expensive. To address these\nchallenges, a physics-informed APF is proposed in this paper where Hamiltonian\nmechanics is used instead of the traditional Newtonian mechanics-based\napproach. In this approach, instead of relying on attractive and repulsive\nforces for path planning, the Hamiltonian approach uses the potential field to\ndefine a path of minimum potential. Additionally, to track the desired\ntrajectory planned by the guidance algorithm within a fixed-time frame, a\nnon-singular fixed-time sliding mode controller (FTSMC) is used. The proposed\nfixed-time sliding surface not only ensures fixed-time convergence of system\nstates but also guarantees the global stability of the closed-loop system\nwithout singularity. The simulation results presented support the claims made.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4eba\u5de5\u52bf\u573a\u548c\u6ed1\u6a21\u63a7\u5236\u5668\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5b58\u5728\u79fb\u52a8\u7a7a\u95f4\u788e\u7247\u7684\u60c5\u51b5\u4e0b\u89c4\u5212\u5b89\u5168\u8f68\u8ff9\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u4eba\u5de5\u52bf\u573a\u65b9\u6cd5\u7684\u5c40\u90e8\u6781\u5c0f\u503c\u95ee\u9898\u3002", "motivation": "\u7a7a\u95f4\u63a2\u7d22\u4efb\u52a1\u7684\u589e\u52a0\u5bfc\u81f4\u7a7a\u95f4\u788e\u7247\u79ef\u7d2f\uff0c\u5bf9\u8fd0\u884c\u536b\u661f\u6784\u6210\u78b0\u649e\u98ce\u9669\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u5b58\u5728\u79fb\u52a8\u969c\u788d\u7269\u7684\u60c5\u51b5\u4e0b\u89c4\u5212\u5b89\u5168\u8f68\u8ff9\u7684\u65b9\u6cd5\uff0c\u786e\u4fdd\u7a7a\u95f4\u64cd\u4f5c\u7684\u53ef\u6301\u7eed\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u54c8\u5bc6\u987f\u529b\u5b66\u800c\u975e\u4f20\u7edf\u725b\u987f\u529b\u5b66\u7684\u4eba\u5de5\u52bf\u573a\u65b9\u6cd5\uff0c\u7ed3\u5408\u975e\u5947\u5f02\u56fa\u5b9a\u65f6\u95f4\u6ed1\u6a21\u63a7\u5236\u5668\u6765\u8ddf\u8e2a\u671f\u671b\u8f68\u8ff9\u3002\u76f8\u5bf96-DOF\u8fd0\u52a8\u5b66\u5728\u51e0\u4f55\u529b\u5b66\u6846\u67b6\u4e0b\u5efa\u6a21\uff0c\u4f7f\u7528\u6307\u6570\u5750\u6807\u8868\u793a\u76f8\u5bf9\u6784\u578b\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u56fa\u5b9a\u65f6\u95f4\u6ed1\u6a21\u63a7\u5236\u5668\u786e\u4fdd\u4e86\u7cfb\u7edf\u72b6\u6001\u5728\u56fa\u5b9a\u65f6\u95f4\u5185\u6536\u655b\uff0c\u4e14\u95ed\u73af\u7cfb\u7edf\u5168\u5c40\u7a33\u5b9a\u65e0\u5947\u5f02\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u7269\u7406\u4fe1\u606f\u4eba\u5de5\u52bf\u573a\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u4eba\u5de5\u52bf\u573a\u7684\u5c40\u90e8\u6781\u5c0f\u503c\u95ee\u9898\uff0c\u7ed3\u5408\u56fa\u5b9a\u65f6\u95f4\u6ed1\u6a21\u63a7\u5236\u5668\u5b9e\u73b0\u4e86\u5b89\u5168\u9ad8\u6548\u7684\u8f68\u8ff9\u89c4\u5212\u4e0e\u8ddf\u8e2a\u3002"}}
{"id": "2510.07865", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07865", "abs": "https://arxiv.org/abs/2510.07865", "authors": ["Guowei Zou", "Haitao Wang", "Hejun Wu", "Yukun Qian", "Yuhang Wang", "Weibing Li"], "title": "DM1: MeanFlow with Dispersive Regularization for 1-Step Robotic Manipulation", "comment": "Website with code: https://guowei-zou.github.io/dm1/", "summary": "The ability to learn multi-modal action distributions is indispensable for\nrobotic manipulation policies to perform precise and robust control. Flow-based\ngenerative models have recently emerged as a promising solution to learning\ndistributions of actions, offering one-step action generation and thus\nachieving much higher sampling efficiency compared to diffusion-based methods.\nHowever, existing flow-based policies suffer from representation collapse, the\ninability to distinguish similar visual representations, leading to failures in\nprecise manipulation tasks. We propose DM1 (MeanFlow with Dispersive\nRegularization for One-Step Robotic Manipulation), a novel flow matching\nframework that integrates dispersive regularization into MeanFlow to prevent\ncollapse while maintaining one-step efficiency. DM1 employs multiple dispersive\nregularization variants across different intermediate embedding layers,\nencouraging diverse representations across training batches without introducing\nadditional network modules or specialized training procedures. Experiments on\nRoboMimic benchmarks show that DM1 achieves 20-40 times faster inference (0.07s\nvs. 2-3.5s) and improves success rates by 10-20 percentage points, with the\nLift task reaching 99% success over 85% of the baseline. Real-robot deployment\non a Franka Panda further validates that DM1 transfers effectively from\nsimulation to the physical world. To the best of our knowledge, this is the\nfirst work to leverage representation regularization to enable flow-based\npolicies to achieve strong performance in robotic manipulation, establishing a\nsimple yet powerful approach for efficient and robust manipulation.", "AI": {"tldr": "DM1\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5206\u6563\u6b63\u5219\u5316\u7684\u6d41\u5339\u914d\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u57fa\u4e8e\u6d41\u7684\u7b56\u7565\u4e2d\u8868\u793a\u574d\u584c\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u4e00\u6b65\u63a8\u7406\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6d41\u7684\u7b56\u7565\u5b58\u5728\u8868\u793a\u574d\u584c\u95ee\u9898\uff0c\u65e0\u6cd5\u533a\u5206\u76f8\u4f3c\u7684\u89c6\u89c9\u8868\u793a\uff0c\u5bfc\u81f4\u5728\u7cbe\u786e\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5931\u8d25\u3002\u867d\u7136\u6d41\u6a21\u578b\u5728\u52a8\u4f5c\u5206\u5e03\u5b66\u4e60\u65b9\u9762\u5177\u6709\u91c7\u6837\u6548\u7387\u4f18\u52bf\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u8868\u793a\u591a\u6837\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "DM1\u5c06\u5206\u6563\u6b63\u5219\u5316\u96c6\u6210\u5230MeanFlow\u4e2d\uff0c\u5728\u591a\u4e2a\u4e2d\u95f4\u5d4c\u5165\u5c42\u4f7f\u7528\u4e0d\u540c\u7684\u5206\u6563\u6b63\u5219\u5316\u53d8\u4f53\uff0c\u9f13\u52b1\u8bad\u7ec3\u6279\u6b21\u95f4\u7684\u8868\u793a\u591a\u6837\u6027\uff0c\u65e0\u9700\u5f15\u5165\u989d\u5916\u7f51\u7edc\u6a21\u5757\u6216\u4e13\u95e8\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u5728RoboMimic\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDM1\u5b9e\u73b0\u4e8620-40\u500d\u7684\u63a8\u7406\u52a0\u901f\uff080.07s vs. 2-3.5s\uff09\uff0c\u6210\u529f\u7387\u63d0\u534710-20\u4e2a\u767e\u5206\u70b9\uff0cLift\u4efb\u52a1\u8fbe\u523099%\u6210\u529f\u7387\uff08\u57fa\u7ebf\u4e3a85%\uff09\u3002\u771f\u5b9e\u673a\u5668\u4eba\u90e8\u7f72\u9a8c\u8bc1\u4e86\u4ece\u4eff\u771f\u5230\u7269\u7406\u4e16\u754c\u7684\u6709\u6548\u8fc1\u79fb\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5229\u7528\u8868\u793a\u6b63\u5219\u5316\u4f7f\u57fa\u4e8e\u6d41\u7684\u7b56\u7565\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u5b9e\u73b0\u5f3a\u6027\u80fd\u7684\u5de5\u4f5c\uff0c\u4e3a\u9ad8\u6548\u9c81\u68d2\u7684\u64cd\u4f5c\u5efa\u7acb\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u5f3a\u5927\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.07426", "categories": ["cs.AI", "68T07, 68T05, 62M10, 90B20", "I.2.6; I.5.4"], "pdf": "https://arxiv.org/pdf/2510.07426", "abs": "https://arxiv.org/abs/2510.07426", "authors": ["Walid Guettala", "Yufan Zhao", "L\u00e1szl\u00f3 Guly\u00e1s"], "title": "Less is More: Strategic Expert Selection Outperforms Ensemble Complexity in Traffic Forecasting", "comment": "Accepted to IEEE ICTAI 2025. Version 0.9. 10 pages, 5 figures.\n  Preprint differs from the published version in formatting and minor wording", "summary": "Traffic forecasting is fundamental to intelligent transportation systems,\nenabling congestion mitigation and emission reduction in increasingly complex\nurban environments. While recent graph neural network approaches have advanced\nspatial temporal modeling, existing mixture of experts frameworks like Time\nEnhanced Spatio Temporal Attention Model (TESTAM) lack explicit incorporation\nof physical road network topology, limiting their spatial capabilities. We\npresent TESTAM+, an enhanced spatio temporal forecasting framework that\nintroduces a novel SpatioSemantic Expert integrating physical road topology\nwith data driven feature similarity through hybrid graph construction. TESTAM+\nachieves significant improvements over TESTAM: 1.3% MAE reduction on METR LA\n(3.10 vs. 3.14) and 4.1% improvement on PEMS BAY (1.65 vs. 1.72). Through\ncomprehensive ablation studies, we discover that strategic expert selection\nfundamentally outperforms naive ensemble aggregation. Individual experts\ndemonstrate remarkable effectiveness: the Adaptive Expert achieves 1.63 MAE on\nPEMS BAY, outperforming the original three expert TESTAM (1.72 MAE), while the\nSpatioSemantic Expert matches this performance with identical 1.63 MAE. The\noptimal Identity + Adaptive configuration achieves an 11.5% MAE reduction\ncompared to state of the art MegaCRN on METR LA (2.99 vs. 3.38), while reducing\ninference latency by 53.1% compared to the full four expert TESTAM+. Our\nfindings reveal that fewer, strategically designed experts outperform complex\nmulti expert ensembles, establishing new state of the art performance with\nsuperior computational efficiency for real time deployment.", "AI": {"tldr": "TESTAM+\u662f\u4e00\u4e2a\u589e\u5f3a\u7684\u65f6\u7a7a\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u7a7a\u95f4\u8bed\u4e49\u4e13\u5bb6\uff0c\u5c06\u7269\u7406\u9053\u8def\u62d3\u6251\u4e0e\u6570\u636e\u9a71\u52a8\u7684\u7279\u5f81\u76f8\u4f3c\u6027\u76f8\u7ed3\u5408\uff0c\u5728\u4ea4\u901a\u9884\u6d4b\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u548c\u8ba1\u7b97\u6548\u7387\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u7684\u4e13\u5bb6\u6df7\u5408\u6846\u67b6\u5982TESTAM\u7f3a\u4e4f\u5bf9\u7269\u7406\u9053\u8def\u7f51\u7edc\u62d3\u6251\u7684\u663e\u5f0f\u5efa\u6a21\uff0c\u9650\u5236\u4e86\u5176\u7a7a\u95f4\u5efa\u6a21\u80fd\u529b\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u7ed3\u5408\u7269\u7406\u62d3\u6251\u548c\u6570\u636e\u7279\u5f81\u7684\u589e\u5f3a\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86TESTAM+\u6846\u67b6\uff0c\u5f15\u5165\u7a7a\u95f4\u8bed\u4e49\u4e13\u5bb6\uff0c\u901a\u8fc7\u6df7\u5408\u56fe\u6784\u5efa\u5c06\u7269\u7406\u9053\u8def\u62d3\u6251\u4e0e\u6570\u636e\u9a71\u52a8\u7684\u7279\u5f81\u76f8\u4f3c\u6027\u76f8\u7ed3\u5408\u3002\u91c7\u7528\u7b56\u7565\u6027\u4e13\u5bb6\u9009\u62e9\u800c\u975e\u7b80\u5355\u7684\u96c6\u6210\u805a\u5408\u3002", "result": "\u5728METR LA\u6570\u636e\u96c6\u4e0aMAE\u964d\u4f4e1.3%(3.10 vs 3.14)\uff0c\u5728PEMS BAY\u6570\u636e\u96c6\u4e0a\u63d0\u53474.1%(1.65 vs 1.72)\u3002\u6700\u4f18\u914d\u7f6e\u76f8\u6bd4MegaCRN\u5728METR LA\u4e0aMAE\u964d\u4f4e11.5%(2.99 vs 3.38)\uff0c\u63a8\u7406\u5ef6\u8fdf\u6bd4\u5b8c\u6574\u56db\u4e13\u5bb6TESTAM+\u51cf\u5c1153.1%\u3002", "conclusion": "\u66f4\u5c11\u4f46\u7ecf\u8fc7\u7b56\u7565\u6027\u8bbe\u8ba1\u7684\u4e13\u5bb6\u4f18\u4e8e\u590d\u6742\u7684\u591a\u4e13\u5bb6\u96c6\u6210\uff0c\u5728\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u7684\u540c\u65f6\u5177\u6709\u4f18\u8d8a\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u5408\u5b9e\u65f6\u90e8\u7f72\u3002"}}
{"id": "2510.08275", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.08275", "abs": "https://arxiv.org/abs/2510.08275", "authors": ["Johannes Autenrieb", "Patrick Gruhn"], "title": "A Control Allocation Algorithm for Hypersonic Glide Vehicles with Input Limitations", "comment": "38 pages, 20 figures, submitted to the AIAA Journal of Guidance,\n  Control, and Dynamics", "summary": "Hypersonic glide vehicles (HGVs) operate in challenging flight regimes\ncharacterized by strong nonlinearities in actuation and stringent physical\nconstraints. These include state-dependent actuator limitations, asymmetric\ncontrol bounds, and thermal loads that vary with maneuvering conditions. This\npaper introduces an iterative control allocation method to address these\nchallenges in real time. The proposed algorithm searches for control inputs\nthat achieve the desired moment commands while respecting constraints on input\nmagnitude and rate. For slender HGV configurations, thermal loads and drag\ngeneration are strongly correlated-lower drag typically results in reduced\nsurface heating. By embedding drag-sensitive soft constraints, the method\nimproves energy efficiency and implicitly reduces surface temperatures,\nlowering the vehicle's infrared signature. These features are particularly\nadvantageous for long-range military operations that require low observability.\nThe approach is demonstrated using the DLR's Generic Hypersonic Glide Vehicle 2\n(GHGV-2) simulation model. The results confirm the method's effectiveness in\nmaintaining control authority under realistic, constrained flight conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8fed\u4ee3\u63a7\u5236\u5206\u914d\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u9ad8\u8d85\u58f0\u901f\u6ed1\u7fd4\u98de\u884c\u5668\u5728\u5f3a\u975e\u7ebf\u6027\u3001\u4e25\u683c\u7269\u7406\u7ea6\u675f\u4e0b\u7684\u5b9e\u65f6\u63a7\u5236\u95ee\u9898\uff0c\u901a\u8fc7\u5d4c\u5165\u963b\u529b\u654f\u611f\u8f6f\u7ea6\u675f\u63d0\u9ad8\u80fd\u91cf\u6548\u7387\u5e76\u964d\u4f4e\u7ea2\u5916\u7279\u5f81\u3002", "motivation": "\u9ad8\u8d85\u58f0\u901f\u6ed1\u7fd4\u98de\u884c\u5668\u5728\u98de\u884c\u8fc7\u7a0b\u4e2d\u9762\u4e34\u5f3a\u975e\u7ebf\u6027\u6267\u884c\u673a\u6784\u3001\u72b6\u6001\u76f8\u5173\u6267\u884c\u5668\u9650\u5236\u3001\u4e0d\u5bf9\u79f0\u63a7\u5236\u8fb9\u754c\u4ee5\u53ca\u968f\u673a\u52a8\u6761\u4ef6\u53d8\u5316\u7684\u70ed\u8f7d\u8377\u7b49\u6311\u6218\uff0c\u9700\u8981\u5b9e\u65f6\u63a7\u5236\u5206\u914d\u65b9\u6cd5\u6765\u5e94\u5bf9\u8fd9\u4e9b\u7ea6\u675f\u3002", "method": "\u91c7\u7528\u8fed\u4ee3\u63a7\u5236\u5206\u914d\u7b97\u6cd5\uff0c\u641c\u7d22\u6ee1\u8db3\u671f\u671b\u529b\u77e9\u6307\u4ee4\u7684\u63a7\u5236\u8f93\u5165\uff0c\u540c\u65f6\u9075\u5b88\u8f93\u5165\u5e45\u5ea6\u548c\u901f\u7387\u7684\u7ea6\u675f\uff0c\u5e76\u5d4c\u5165\u963b\u529b\u654f\u611f\u8f6f\u7ea6\u675f\u6765\u4f18\u5316\u80fd\u91cf\u6548\u7387\u548c\u70ed\u7ba1\u7406\u3002", "result": "\u4f7f\u7528DLR\u7684\u901a\u7528\u9ad8\u8d85\u58f0\u901f\u6ed1\u7fd4\u98de\u884c\u56682(GHGV-2)\u4eff\u771f\u6a21\u578b\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u73b0\u5b9e\u7ea6\u675f\u98de\u884c\u6761\u4ef6\u4e0b\u80fd\u6709\u6548\u4fdd\u6301\u63a7\u5236\u6743\u9650\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u9ad8\u8d85\u58f0\u901f\u6ed1\u7fd4\u98de\u884c\u5668\u7684\u5b9e\u65f6\u63a7\u5236\u5206\u914d\u95ee\u9898\uff0c\u5728\u6ee1\u8db3\u5404\u79cd\u7269\u7406\u7ea6\u675f\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u80fd\u91cf\u6548\u7387\u5e76\u964d\u4f4e\u4e86\u7ea2\u5916\u7279\u5f81\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u4f4e\u53ef\u89c2\u6d4b\u6027\u7684\u8fdc\u7a0b\u519b\u4e8b\u4f5c\u6218\u3002"}}
{"id": "2510.07869", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07869", "abs": "https://arxiv.org/abs/2510.07869", "authors": ["Junwen Gu", "Zhiheng wu", "Pengxuan Si", "Shuang Qiu", "Yukai Feng", "Luoyang Sun", "Laien Luo", "Lianyi Yu", "Jian Wang", "Zhengxing Wu"], "title": "USIM and U0: A Vision-Language-Action Dataset and Model for General Underwater Robots", "comment": null, "summary": "Underwater environments present unique challenges for robotic operation,\nincluding complex hydrodynamics, limited visibility, and constrained\ncommunication. Although data-driven approaches have advanced embodied\nintelligence in terrestrial robots and enabled task-specific autonomous\nunderwater robots, developing underwater intelligence capable of autonomously\nperforming multiple tasks remains highly challenging, as large-scale,\nhigh-quality underwater datasets are still scarce. To address these\nlimitations, we introduce USIM, a simulation-based multi-task\nVision-Language-Action (VLA) dataset for underwater robots. USIM comprises over\n561K frames from 1,852 trajectories, totaling approximately 15.6 hours of\nBlueROV2 interactions across 20 tasks in 9 diverse scenarios, ranging from\nvisual navigation to mobile manipulation. Building upon this dataset, we\npropose U0, a VLA model for general underwater robots, which integrates\nbinocular vision and other sensor modalities through multimodal fusion, and\nfurther incorporates a convolution-attention-based perception focus enhancement\nmodule (CAP) to improve spatial understanding and mobile manipulation. Across\ntasks such as inspection, obstacle avoidance, scanning, and dynamic tracking,\nthe framework achieves a success rate of 80%, while in challenging mobile\nmanipulation tasks, it reduces the distance to the target by 21.2% compared\nwith baseline methods, demonstrating its effectiveness. USIM and U0 show that\nVLA models can be effectively applied to underwater robotic applications,\nproviding a foundation for scalable dataset construction, improved task\nautonomy, and the practical realization of intelligent general underwater\nrobots.", "AI": {"tldr": "\u63d0\u51fa\u4e86USIM\u6a21\u62df\u6570\u636e\u96c6\u548cU0\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u6c34\u4e0b\u673a\u5668\u4eba\u591a\u4efb\u52a1\u81ea\u4e3b\u64cd\u4f5c\u7684\u6311\u6218\uff0c\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u6c34\u4e0b\u73af\u5883\u590d\u6742\uff0c\u73b0\u6709\u6570\u636e\u96c6\u7a00\u7f3a\uff0c\u96be\u4ee5\u5f00\u53d1\u80fd\u81ea\u4e3b\u6267\u884c\u591a\u4efb\u52a1\u7684\u6c34\u4e0b\u667a\u80fd\u673a\u5668\u4eba\u3002", "method": "\u6784\u5efa\u5305\u542b56.1\u4e07\u5e27\u6570\u636e\u7684USIM\u6a21\u62df\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51faU0 VLA\u6a21\u578b\uff0c\u96c6\u6210\u53cc\u76ee\u89c6\u89c9\u548c\u4f20\u611f\u5668\u6a21\u6001\uff0c\u52a0\u5165\u5377\u79ef\u6ce8\u610f\u529b\u611f\u77e5\u589e\u5f3a\u6a21\u5757\u3002", "result": "\u5728\u68c0\u67e5\u3001\u907f\u969c\u7b49\u4efb\u52a1\u4e2d\u6210\u529f\u738780%\uff0c\u5728\u79fb\u52a8\u64cd\u4f5c\u4efb\u52a1\u4e2d\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u51cf\u5c1121.2%\u7684\u76ee\u6807\u8ddd\u79bb\u3002", "conclusion": "VLA\u6a21\u578b\u53ef\u6709\u6548\u5e94\u7528\u4e8e\u6c34\u4e0b\u673a\u5668\u4eba\uff0c\u4e3a\u53ef\u6269\u5c55\u6570\u636e\u96c6\u6784\u5efa\u3001\u4efb\u52a1\u81ea\u4e3b\u6027\u63d0\u5347\u548c\u667a\u80fd\u901a\u7528\u6c34\u4e0b\u673a\u5668\u4eba\u7684\u5b9e\u9645\u5b9e\u73b0\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2510.07432", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07432", "abs": "https://arxiv.org/abs/2510.07432", "authors": ["Penghang Liu", "Elizabeth Fons", "Svitlana Vyetrenko", "Daniel Borrajo", "Vamsi Potluru", "Manuela Veloso"], "title": "TS-Agent: A Time Series Reasoning Agent with Iterative Statistical Insight Gathering", "comment": "NeurIPS 2025 Workshop on Foundations of Reasoning in Language Models", "summary": "Large language models (LLMs) have shown strong abilities in reasoning and\nproblem solving, but recent studies reveal that they still struggle with time\nseries reasoning tasks, where outputs are often affected by hallucination or\nknowledge leakage. In this work we propose TS-Agent, a time series reasoning\nagent that leverages LLMs strictly for what they excel at, i.e., gathering\nevidence and synthesizing it into conclusions through step-by-step reasoning,\nwhile delegating the extraction of statistical and structural information to\ntime series analytical tools. Instead of mapping time series into text tokens,\nimages, or embeddings, our agent interacts with raw numeric sequences through\natomic operators, records outputs in an explicit evidence log, and iteratively\nrefines its reasoning under the guidance of a self-critic and a final quality\ngate. This design avoids multi-modal alignment training, preserves the native\nform of time series, ensures interpretability and verifiability, and mitigates\nknowledge leakage or hallucination. Empirically, we evaluate the agent on\nestablished benchmarks. Our experiments show that TS-Agent achieves performance\ncomparable to state-of-the-art LLMs on understanding benchmarks, and delivers\nsignificant improvements on reasoning tasks, where existing models often rely\non memorization and fail in zero-shot settings.", "AI": {"tldr": "TS-Agent\u662f\u4e00\u4e2a\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4ee3\u7406\uff0c\u901a\u8fc7\u5c06LLMs\u7684\u63a8\u7406\u80fd\u529b\u4e0e\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u5de5\u5177\u7ed3\u5408\uff0c\u907f\u514d\u77e5\u8bc6\u6cc4\u6f0f\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709LLMs\u5728\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5bb9\u6613\u51fa\u73b0\u5e7b\u89c9\u548c\u77e5\u8bc6\u6cc4\u6f0f\u95ee\u9898\uff0c\u9700\u8981\u4e13\u95e8\u8bbe\u8ba1\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u4f7f\u7528LLMs\u8fdb\u884c\u8bc1\u636e\u6536\u96c6\u548c\u7ed3\u8bba\u5408\u6210\uff0c\u540c\u65f6\u5c06\u7edf\u8ba1\u548c\u7ed3\u6784\u4fe1\u606f\u63d0\u53d6\u59d4\u6258\u7ed9\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u5de5\u5177\uff0c\u901a\u8fc7\u539f\u5b50\u64cd\u4f5c\u7b26\u4e0e\u539f\u59cb\u6570\u503c\u5e8f\u5217\u4ea4\u4e92\uff0c\u5e76\u91c7\u7528\u81ea\u6279\u5224\u548c\u8d28\u91cf\u95e8\u63a7\u673a\u5236\u8fed\u4ee3\u4f18\u5316\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5728\u7406\u89e3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e0e\u6700\u5148\u8fdbLLMs\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u5b9e\u73b0\u663e\u8457\u6539\u8fdb\uff0c\u7279\u522b\u662f\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "TS-Agent\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86LLMs\u5728\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u907f\u514d\u4e86\u591a\u6a21\u6001\u5bf9\u9f50\u8bad\u7ec3\uff0c\u4fdd\u6301\u4e86\u65f6\u95f4\u5e8f\u5217\u7684\u539f\u59cb\u5f62\u5f0f\uff0c\u786e\u4fdd\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002"}}
{"id": "2510.08288", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.08288", "abs": "https://arxiv.org/abs/2510.08288", "authors": ["Hamid R. Ossareh", "William Shayne", "Samuel Chevalier"], "title": "CPU- and GPU-Based Parallelization of the Robust Reference Governor", "comment": null, "summary": "Constraint management is a central challenge in modern control systems. A\nsolution is the Reference Governor (RG), which is an add-on strategy to\npre-stabilized feedback control systems to enforce state and input constraints\nby shaping the reference command. While robust formulations of RG exist for\nlinear systems, their extension to nonlinear systems is often computationally\nintractable. This paper develops a scenario-based robust RG formulation for\nnonlinear systems and investigates its parallel implementation on multi-core\nCPUs and CUDA-enabled GPUs. We analyze the computational structure of the\nalgorithm, identify parallelization opportunities, and implement the resulting\nschemes on modern parallel hardware. Benchmarking on a nonlinear hydrogen fuel\ncell model demonstrates order-of-magnitude speedups (by as much as three orders\nof magnitude) compared to sequential implementations.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u573a\u666f\u7684\u9c81\u68d2\u53c2\u8003\u8c03\u8282\u5668(RG)\u516c\u5f0f\uff0c\u7528\u4e8e\u975e\u7ebf\u6027\u7cfb\u7edf\uff0c\u5e76\u7814\u7a76\u4e86\u5176\u5728\u591a\u6838CPU\u548cCUDA GPU\u4e0a\u7684\u5e76\u884c\u5b9e\u73b0\uff0c\u5b9e\u73b0\u4e86\u4e09\u4e2a\u6570\u91cf\u7ea7\u7684\u52a0\u901f\u3002", "motivation": "\u4f20\u7edf\u9c81\u68d2RG\u65b9\u6cd5\u5728\u975e\u7ebf\u6027\u7cfb\u7edf\u4e2d\u7684\u6269\u5c55\u901a\u5e38\u8ba1\u7b97\u4e0d\u53ef\u884c\uff0c\u9700\u8981\u5f00\u53d1\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u7684\u5b9e\u73b0\u65b9\u6848\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u573a\u666f\u7684\u9c81\u68d2RG\u516c\u5f0f\uff0c\u5206\u6790\u7b97\u6cd5\u8ba1\u7b97\u7ed3\u6784\uff0c\u8bc6\u522b\u5e76\u884c\u5316\u673a\u4f1a\uff0c\u5e76\u5728\u73b0\u4ee3\u5e76\u884c\u786c\u4ef6\u4e0a\u5b9e\u73b0\u3002", "result": "\u5728\u975e\u7ebf\u6027\u6c22\u71c3\u6599\u7535\u6c60\u6a21\u578b\u4e0a\u7684\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u76f8\u6bd4\u987a\u5e8f\u5b9e\u73b0\u83b7\u5f97\u4e86\u4e09\u4e2a\u6570\u91cf\u7ea7\u7684\u52a0\u901f\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5e76\u884c\u5b9e\u73b0\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u975e\u7ebf\u6027\u7cfb\u7edf\u9c81\u68d2RG\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u4f7f\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u52a0\u53ef\u884c\u3002"}}
{"id": "2510.07871", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.07871", "abs": "https://arxiv.org/abs/2510.07871", "authors": ["Erjia Xiao", "Lingfeng Zhang", "Yingbo Tang", "Hao Cheng", "Renjing Xu", "Wenbo Ding", "Lei Zhou", "Long Chen", "Hangjun Ye", "Xiaoshuai Hao"], "title": "Team Xiaomi EV-AD VLA: Learning to Navigate Socially Through Proactive Risk Perception -- Technical Report for IROS 2025 RoboSense Challenge Social Navigation Track", "comment": null, "summary": "In this report, we describe the technical details of our submission to the\nIROS 2025 RoboSense Challenge Social Navigation Track. This track focuses on\ndeveloping RGBD-based perception and navigation systems that enable autonomous\nagents to navigate safely, efficiently, and socially compliantly in dynamic\nhuman-populated indoor environments. The challenge requires agents to operate\nfrom an egocentric perspective using only onboard sensors including RGB-D\nobservations and odometry, without access to global maps or privileged\ninformation, while maintaining social norm compliance such as safe distances\nand collision avoidance. Building upon the Falcon model, we introduce a\nProactive Risk Perception Module to enhance social navigation performance. Our\napproach augments Falcon with collision risk understanding that learns to\npredict distance-based collision risk scores for surrounding humans, which\nenables the agent to develop more robust spatial awareness and proactive\ncollision avoidance behaviors. The evaluation on the Social-HM3D benchmark\ndemonstrates that our method improves the agent's ability to maintain personal\nspace compliance while navigating toward goals in crowded indoor scenes with\ndynamic human agents, achieving 2nd place among 16 participating teams in the\nchallenge.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u53c2\u52a0IROS 2025 RoboSense\u6311\u6218\u8d5b\u793e\u4ea4\u5bfc\u822a\u8d5b\u9053\u7684\u6280\u672f\u65b9\u6848\uff0c\u901a\u8fc7\u5728Falcon\u6a21\u578b\u57fa\u7840\u4e0a\u589e\u52a0\u4e3b\u52a8\u98ce\u9669\u611f\u77e5\u6a21\u5757\uff0c\u63d0\u5347\u673a\u5668\u4eba\u5728\u52a8\u6001\u4eba\u7fa4\u73af\u5883\u4e2d\u7684\u793e\u4ea4\u5bfc\u822a\u80fd\u529b\uff0c\u6700\u7ec8\u572816\u652f\u53c2\u8d5b\u961f\u4f0d\u4e2d\u83b7\u5f97\u7b2c2\u540d\u3002", "motivation": "\u5f00\u53d1\u80fd\u591f\u5728\u52a8\u6001\u4eba\u7fa4\u73af\u5883\u4e2d\u5b89\u5168\u3001\u9ad8\u6548\u4e14\u7b26\u5408\u793e\u4ea4\u89c4\u8303\u7684\u81ea\u4e3b\u5bfc\u822a\u7cfb\u7edf\uff0c\u89e3\u51b3\u4ec5\u4f7f\u7528\u673a\u8f7dRGB-D\u4f20\u611f\u5668\u548c\u91cc\u7a0b\u8ba1\uff0c\u5728\u6ca1\u6709\u5168\u5c40\u5730\u56fe\u6216\u7279\u6743\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u793e\u4ea4\u5408\u89c4\u5bfc\u822a\u7684\u6311\u6218\u3002", "method": "\u5728Falcon\u6a21\u578b\u57fa\u7840\u4e0a\u5f15\u5165\u4e3b\u52a8\u98ce\u9669\u611f\u77e5\u6a21\u5757\uff0c\u901a\u8fc7\u5b66\u4e60\u9884\u6d4b\u5468\u56f4\u4eba\u7c7b\u57fa\u4e8e\u8ddd\u79bb\u7684\u78b0\u649e\u98ce\u9669\u5206\u6570\uff0c\u589e\u5f3a\u4ee3\u7406\u7684\u7a7a\u95f4\u610f\u8bc6\u548c\u4e3b\u52a8\u907f\u78b0\u884c\u4e3a\u3002", "result": "\u5728Social-HM3D\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u4ee3\u7406\u5728\u62e5\u6324\u5ba4\u5185\u573a\u666f\u4e2d\u4fdd\u6301\u4e2a\u4eba\u7a7a\u95f4\u5408\u89c4\u6027\u7684\u80fd\u529b\uff0c\u5728\u6311\u6218\u8d5b16\u652f\u53c2\u8d5b\u961f\u4f0d\u4e2d\u83b7\u5f97\u7b2c2\u540d\u3002", "conclusion": "\u4e3b\u52a8\u98ce\u9669\u611f\u77e5\u6a21\u5757\u6709\u6548\u63d0\u5347\u4e86\u793e\u4ea4\u5bfc\u822a\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u98ce\u9669\u9884\u6d4b\u7684\u65b9\u6cd5\u5728\u52a8\u6001\u4eba\u7fa4\u73af\u5883\u4e2d\u5b9e\u73b0\u5b89\u5168\u5408\u89c4\u5bfc\u822a\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.07456", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07456", "abs": "https://arxiv.org/abs/2510.07456", "authors": ["Binrong Zhu", "Guiran Liu", "Nina Jiang"], "title": "ExpertAgent: Enhancing Personalized Education through Dynamic Planning and Retrieval-Augmented Long-Chain Reasoning", "comment": "Manuscript previously submitted to the NeurIPS 2025 Workshop on\n  Bridging Language, Agent, and World Models (LAW 2025)", "summary": "The application of advanced generative artificial intelligence in education\nis often constrained by the lack of real-time adaptability, personalization,\nand reliability of the content. To address these challenges, we propose\nExpertAgent - an intelligent agent framework designed for personalized\neducation that provides reliable knowledge and enables highly adaptive learning\nexperiences. Therefore, we developed ExpertAgent, an innovative learning agent\nthat provides users with a proactive and personalized learning experience.\nExpertAgent dynamic planning of the learning content and strategy based on a\ncontinuously updated student model. Therefore, overcoming the limitations of\ntraditional static learning content to provide optimized teaching strategies\nand learning experience in real time. All instructional content is grounded in\na validated curriculum repository, effectively reducing hallucination risks in\nlarge language models and improving reliability and trustworthiness.", "AI": {"tldr": "\u63d0\u51fa\u4e86ExpertAgent\u667a\u80fd\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u89c4\u5212\u5b66\u4e60\u5185\u5bb9\u548c\u7b56\u7565\uff0c\u57fa\u4e8e\u6301\u7eed\u66f4\u65b0\u7684\u5b66\u751f\u6a21\u578b\u63d0\u4f9b\u4e2a\u6027\u5316\u6559\u80b2\uff0c\u51cf\u5c11\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u98ce\u9669\u3002", "motivation": "\u89e3\u51b3\u751f\u6210\u5f0fAI\u5728\u6559\u80b2\u4e2d\u7f3a\u4e4f\u5b9e\u65f6\u9002\u5e94\u6027\u3001\u4e2a\u6027\u5316\u548c\u5185\u5bb9\u53ef\u9760\u6027\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1ExpertAgent\u667a\u80fd\u4ee3\u7406\u6846\u67b6\uff0c\u57fa\u4e8e\u9a8c\u8bc1\u8bfe\u7a0b\u5e93\u52a8\u6001\u89c4\u5212\u5b66\u4e60\u5185\u5bb9\u548c\u7b56\u7565\uff0c\u901a\u8fc7\u6301\u7eed\u66f4\u65b0\u7684\u5b66\u751f\u6a21\u578b\u5b9e\u73b0\u4e2a\u6027\u5316\u6559\u5b66\u3002", "result": "\u63d0\u4f9b\u4e86\u4e3b\u52a8\u548c\u4e2a\u6027\u5316\u7684\u5b66\u4e60\u4f53\u9a8c\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u9759\u6001\u5b66\u4e60\u5185\u5bb9\u7684\u9650\u5236\uff0c\u5b9e\u65f6\u4f18\u5316\u6559\u5b66\u7b56\u7565\u548c\u5b66\u4e60\u4f53\u9a8c\u3002", "conclusion": "ExpertAgent\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u6559\u80b2AI\u7684\u9002\u5e94\u6027\u3001\u4e2a\u6027\u5316\u548c\u53ef\u9760\u6027\uff0c\u51cf\u5c11\u5e7b\u89c9\u98ce\u9669\uff0c\u6539\u5584\u5b66\u4e60\u4f53\u9a8c\u3002"}}
{"id": "2510.08356", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.08356", "abs": "https://arxiv.org/abs/2510.08356", "authors": ["Wenlong Shi", "Hongyi Li", "Zhaoyu Wang"], "title": "Underground Power Distribution System Restoration Using Inverter Based Resources", "comment": null, "summary": "Underground power distribution systems (PDSs) are increasingly deployed in\nurban areas. The integration of smart devices including smart switchgears,\npad-mounted distribution transformers and inverter-based resources (IBRs)\nenhance system resilience, however simultaneously introducing unique\nchallenges. The challenges include inrush currents caused by trapped charges in\nunderground cables, ferroresonance in distribution transformers during\nenergization, and three-phase load imbalance resulting from single-phase\nunderground laterals. To address these issues, this paper proposes an\nunderground PDS restoration framework using IBRs. Firstly, an underground cable\nenergization model is developed to quantify inrush current by analyzing voltage\ndifferences across both switchgear terminals. Secondly, a distribution\ntransformer energization model is proposed to evaluate ferroresonance using\nQ-factor constraints based on underground cable capacitance and damping\nresistance. Thirdly, a phase-swapping model is proposed to improve load\nbalancing by dynamically reassigning lateral-phase connections through smart\nswitchgears. The proposed models are further integrated into a mixed-integer\nnonlinear programming (MINLP) formulation to maximize the total weighted\nrestored load while constraining inrush currents, ferroresonance, and phase\nimbalance. To address the nonlinearity induced by impedance matrix reordering\nduring phase swapping, a permutation-based linearization technique is proposed.\nFinally, case studies on an underground PDS established based on IEEE 123-Node\nTest Feeder validate the effectiveness of the proposed strategy in improving\nuderground PDS restoration performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u9006\u53d8\u5668\u8d44\u6e90\u7684\u5730\u4e0b\u914d\u7535\u7cfb\u7edf\u6062\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u5f00\u53d1\u7535\u7f06\u5145\u7535\u6a21\u578b\u3001\u53d8\u538b\u5668\u52b1\u78c1\u6a21\u578b\u548c\u76f8\u4f4d\u4ea4\u6362\u6a21\u578b\uff0c\u91c7\u7528\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u65b9\u6cd5\u6700\u5927\u5316\u6062\u590d\u8d1f\u8f7d\uff0c\u540c\u65f6\u7ea6\u675f\u6d8c\u6d41\u3001\u94c1\u78c1\u8c10\u632f\u548c\u76f8\u4f4d\u4e0d\u5e73\u8861\u3002", "motivation": "\u5730\u4e0b\u914d\u7535\u7cfb\u7edf\u5728\u90e8\u7f72\u667a\u80fd\u8bbe\u5907\u65f6\u9762\u4e34\u6d8c\u6d41\u3001\u94c1\u78c1\u8c10\u632f\u548c\u4e09\u76f8\u8d1f\u8f7d\u4e0d\u5e73\u8861\u7b49\u72ec\u7279\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u6062\u590d\u7b56\u7565\u6765\u63d0\u5347\u7cfb\u7edf\u97e7\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u7535\u7f06\u5145\u7535\u6a21\u578b\u91cf\u5316\u6d8c\u6d41\u3001\u53d8\u538b\u5668\u52b1\u78c1\u6a21\u578b\u8bc4\u4f30\u94c1\u78c1\u8c10\u632f\u3001\u76f8\u4f4d\u4ea4\u6362\u6a21\u578b\u6539\u5584\u8d1f\u8f7d\u5e73\u8861\uff0c\u5e76\u96c6\u6210\u5230MINLP\u6846\u67b6\u4e2d\uff0c\u91c7\u7528\u57fa\u4e8e\u6392\u5217\u7684\u7ebf\u6027\u5316\u6280\u672f\u5904\u7406\u975e\u7ebf\u6027\u95ee\u9898\u3002", "result": "\u57fa\u4e8eIEEE 123\u8282\u70b9\u6d4b\u8bd5\u9988\u7ebf\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u6240\u63d0\u7b56\u7565\u5728\u63d0\u9ad8\u5730\u4e0b\u914d\u7535\u7cfb\u7edf\u6062\u590d\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6062\u590d\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5730\u4e0b\u914d\u7535\u7cfb\u7edf\u4e2d\u7684\u6d8c\u6d41\u3001\u94c1\u78c1\u8c10\u632f\u548c\u8d1f\u8f7d\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6062\u590d\u6027\u80fd\u3002"}}
{"id": "2510.07882", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07882", "abs": "https://arxiv.org/abs/2510.07882", "authors": ["Boyu Li", "Siyuan He", "Hang Xu", "Haoqi Yuan", "Yu Zang", "Liwei Hu", "Junpeng Yue", "Zhenxiong Jiang", "Pengbo Hu", "B\u00f6rje F. Karlsson", "Yehui Tang", "Zongqing Lu"], "title": "Towards Proprioception-Aware Embodied Planning for Dual-Arm Humanoid Robots", "comment": null, "summary": "In recent years, Multimodal Large Language Models (MLLMs) have demonstrated\nthe ability to serve as high-level planners, enabling robots to follow complex\nhuman instructions. However, their effectiveness, especially in long-horizon\ntasks involving dual-arm humanoid robots, remains limited. This limitation\narises from two main challenges: (i) the absence of simulation platforms that\nsystematically support task evaluation and data collection for humanoid robots,\nand (ii) the insufficient embodiment awareness of current MLLMs, which hinders\nreasoning about dual-arm selection logic and body positions during planning. To\naddress these issues, we present DualTHOR, a new dual-arm humanoid simulator,\nwith continuous transition and a contingency mechanism. Building on this\nplatform, we propose Proprio-MLLM, a model that enhances embodiment awareness\nby incorporating proprioceptive information with motion-based position\nembedding and a cross-spatial encoder. Experiments show that, while existing\nMLLMs struggle in this environment, Proprio-MLLM achieves an average\nimprovement of 19.75% in planning performance. Our work provides both an\nessential simulation platform and an effective model to advance embodied\nintelligence in humanoid robotics. The code is available at\nhttps://anonymous.4open.science/r/DualTHOR-5F3B.", "AI": {"tldr": "\u63d0\u51fa\u4e86DualTHOR\u53cc\u81c2\u4eba\u5f62\u673a\u5668\u4eba\u6a21\u62df\u5668\u548cProprio-MLLM\u6a21\u578b\uff0c\u901a\u8fc7\u6574\u5408\u672c\u4f53\u611f\u77e5\u4fe1\u606f\u89e3\u51b3MLLMs\u5728\u957f\u89c6\u91ce\u53cc\u81c2\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5c06\u89c4\u5212\u6027\u80fd\u5e73\u5747\u63d0\u534719.75%\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53cc\u81c2\u4eba\u5f62\u673a\u5668\u4eba\u7684\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u6548\u679c\u6709\u9650\uff0c\u4e3b\u8981\u7531\u4e8e\u7f3a\u4e4f\u652f\u6301\u4eba\u5f62\u673a\u5668\u4eba\u4efb\u52a1\u8bc4\u4f30\u7684\u7cfb\u7edf\u6a21\u62df\u5e73\u53f0\uff0c\u4ee5\u53caMLLMs\u7f3a\u4e4f\u672c\u4f53\u611f\u77e5\u80fd\u529b\uff0c\u65e0\u6cd5\u63a8\u7406\u53cc\u81c2\u9009\u62e9\u903b\u8f91\u548c\u8eab\u4f53\u4f4d\u7f6e\u3002", "method": "\u5f00\u53d1\u4e86DualTHOR\u53cc\u81c2\u4eba\u5f62\u6a21\u62df\u5668\uff0c\u5177\u6709\u8fde\u7eed\u8fc7\u6e21\u548c\u5e94\u6025\u673a\u5236\uff1b\u63d0\u51faProprio-MLLM\u6a21\u578b\uff0c\u901a\u8fc7\u8fd0\u52a8\u57fa\u4f4d\u7f6e\u5d4c\u5165\u548c\u8de8\u7a7a\u95f4\u7f16\u7801\u5668\u6574\u5408\u672c\u4f53\u611f\u77e5\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u73b0\u6709MLLMs\u5728\u8be5\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u800cProprio-MLLM\u5728\u89c4\u5212\u6027\u80fd\u4e0a\u5b9e\u73b0\u4e86\u5e73\u574719.75%\u7684\u63d0\u5347\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4eba\u5f62\u673a\u5668\u4eba\u7684\u5177\u8eab\u667a\u80fd\u53d1\u5c55\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u6a21\u62df\u5e73\u53f0\u548c\u6709\u6548\u6a21\u578b\u3002"}}
{"id": "2510.08357", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.08357", "abs": "https://arxiv.org/abs/2510.08357", "authors": ["Wenlong Shi", "Dingwei Wang", "Liming Liu", "Zhaoyu Wang"], "title": "Learning to Mitigate Post-Outage Load Surges: A Data-Driven Framework for Electrifying and Decarbonizing Grids", "comment": null, "summary": "Electrification and decarbonization are transforming power system demand and\nrecovery dynamics, yet their implications for post-outage load surges remain\npoorly understood. Here we analyze a metropolitan-scale heterogeneous dataset\nfor Indianapolis comprising 30,046 feeder-level outages between 2020 and 2024,\nlinked to smart meters and submetering, to quantify the causal impact of\nelectric vehicles (EVs), heat pumps (HPs) and distributed energy resources\n(DERs) on restoration surges. Statistical analysis and causal forest inference\ndemonstrate that rising penetrations of all three assets significantly increase\nsurge ratios, with effects strongly modulated by restoration timing, outage\nduration and weather conditions. We develop a component-aware multi-task\nTransformer estimator that disaggregates EV, HP and DER contributions, and\napply it to project historical outages under counterfactual 2035 adoption\npathways. In a policy-aligned pathway, evening restorations emerge as the\nbinding reliability constraint, with exceedance probabilities of 0.057 when\n30\\% of system load is restored within the first 15 minutes. Mitigation\nmeasures, probabilistic EV restarts, short thermostat offsets and accelerated\nDER reconnection, reduce exceedance to 0.019 and eliminate it entirely when\n20\\% or less of system load is restored. These results demonstrate that\ntransition-era surges are asset-driven and causally linked to electrification\nand decarbonization, but can be effectively managed through integrated\noperational strategies.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u7535\u52a8\u6c7d\u8f66\u3001\u70ed\u6cf5\u548c\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\u5bf9\u7535\u529b\u7cfb\u7edf\u6062\u590d\u671f\u95f4\u8d1f\u8377\u6fc0\u589e\u7684\u56e0\u679c\u5f71\u54cd\uff0c\u5f00\u53d1\u4e86\u591a\u4efb\u52a1Transformer\u6a21\u578b\u6765\u5206\u89e3\u5404\u7ec4\u4ef6\u8d21\u732e\uff0c\u5e76\u63d0\u51fa\u4e86\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "\u7535\u6c14\u5316\u548c\u8131\u78b3\u6b63\u5728\u6539\u53d8\u7535\u529b\u7cfb\u7edf\u7684\u9700\u6c42\u548c\u6062\u590d\u52a8\u6001\uff0c\u4f46\u4eba\u4eec\u5bf9\u505c\u7535\u540e\u8d1f\u8377\u6fc0\u589e\u7684\u5f71\u54cd\u4ecd\u77e5\u4e4b\u751a\u5c11\u3002", "method": "\u4f7f\u7528\u5370\u7b2c\u5b89\u7eb3\u6ce2\u5229\u65af2010-2024\u5e7430,046\u6b21\u9988\u7ebf\u7ea7\u505c\u7535\u7684\u5f02\u6784\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u7edf\u8ba1\u5206\u6790\u548c\u56e0\u679c\u68ee\u6797\u63a8\u65ad\uff0c\u5f00\u53d1\u4e86\u7ec4\u4ef6\u611f\u77e5\u7684\u591a\u4efb\u52a1Transformer\u4f30\u8ba1\u5668\u3002", "result": "\u6240\u6709\u4e09\u79cd\u8d44\u4ea7\u7684\u6e17\u900f\u7387\u4e0a\u5347\u90fd\u663e\u8457\u589e\u52a0\u4e86\u6fc0\u589e\u6bd4\u7387\uff0c\u665a\u95f4\u6062\u590d\u6210\u4e3a\u53ef\u9760\u6027\u7ea6\u675f\uff0c\u5728\u653f\u7b56\u5bf9\u9f50\u8def\u5f84\u4e0b\u8d85\u8fc7\u6982\u7387\u4e3a0.057\u3002\u7f13\u89e3\u63aa\u65bd\u53ef\u5c06\u8d85\u8fc7\u6982\u7387\u964d\u81f30.019\u3002", "conclusion": "\u8fc7\u6e21\u65f6\u671f\u7684\u8d1f\u8377\u6fc0\u589e\u662f\u7531\u8d44\u4ea7\u9a71\u52a8\u7684\uff0c\u4e0e\u7535\u6c14\u5316\u548c\u8131\u78b3\u6709\u56e0\u679c\u5173\u7cfb\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u7efc\u5408\u8fd0\u8425\u7b56\u7565\u6709\u6548\u7ba1\u7406\u3002"}}
{"id": "2510.07975", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07975", "abs": "https://arxiv.org/abs/2510.07975", "authors": ["Mingyang Sun", "Jiude Wei", "Qichen He", "Donglin Wang", "Cewu Lu", "Jianhua Sun"], "title": "Executable Analytic Concepts as the Missing Link Between VLM Insight and Precise Manipulation", "comment": null, "summary": "Enabling robots to perform precise and generalized manipulation in\nunstructured environments remains a fundamental challenge in embodied AI. While\nVision-Language Models (VLMs) have demonstrated remarkable capabilities in\nsemantic reasoning and task planning, a significant gap persists between their\nhigh-level understanding and the precise physical execution required for\nreal-world manipulation. To bridge this \"semantic-to-physical\" gap, we\nintroduce GRACE, a novel framework that grounds VLM-based reasoning through\nexecutable analytic concepts (EAC)-mathematically defined blueprints that\nencode object affordances, geometric constraints, and semantics of\nmanipulation. Our approach integrates a structured policy scaffolding pipeline\nthat turn natural language instructions and visual information into an\ninstantiated EAC, from which we derive grasp poses, force directions and plan\nphysically feasible motion trajectory for robot execution. GRACE thus provides\na unified and interpretable interface between high-level instruction\nunderstanding and low-level robot control, effectively enabling precise and\ngeneralizable manipulation through semantic-physical grounding. Extensive\nexperiments demonstrate that GRACE achieves strong zero-shot generalization\nacross a variety of articulated objects in both simulated and real-world\nenvironments, without requiring task-specific training.", "AI": {"tldr": "GRACE\u6846\u67b6\u901a\u8fc7\u53ef\u6267\u884c\u5206\u6790\u6982\u5ff5\uff08EAC\uff09\u5f25\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bed\u4e49\u63a8\u7406\u4e0e\u673a\u5668\u4eba\u7269\u7406\u6267\u884c\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5b9e\u73b0\u7cbe\u786e\u548c\u901a\u7528\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u3002", "motivation": "\u89e3\u51b3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u4e49\u63a8\u7406\u548c\u4efb\u52a1\u89c4\u5212\u65b9\u9762\u7684\u80fd\u529b\u4e0e\u673a\u5668\u4eba\u5b9e\u9645\u7269\u7406\u6267\u884c\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5373\"\u8bed\u4e49\u5230\u7269\u7406\"\u7684\u9e3f\u6c9f\u3002", "method": "\u5f15\u5165\u53ef\u6267\u884c\u5206\u6790\u6982\u5ff5\uff08EAC\uff09\u4f5c\u4e3a\u6570\u5b66\u5b9a\u4e49\u7684\u84dd\u56fe\uff0c\u7f16\u7801\u7269\u4f53\u529f\u80fd\u3001\u51e0\u4f55\u7ea6\u675f\u548c\u64cd\u4f5c\u8bed\u4e49\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7b56\u7565\u811a\u624b\u67b6\u7ba1\u9053\u5c06\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u548c\u89c6\u89c9\u4fe1\u606f\u8f6c\u5316\u4e3a\u5b9e\u4f8b\u5316\u7684EAC\uff0c\u4ece\u4e2d\u63a8\u5bfc\u6293\u53d6\u59ff\u6001\u3001\u529b\u65b9\u5411\u548c\u7269\u7406\u53ef\u884c\u7684\u8fd0\u52a8\u8f68\u8ff9\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u5bf9\u5404\u79cd\u94f0\u63a5\u7269\u4f53\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u8bad\u7ec3\u3002", "conclusion": "GRACE\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u4e14\u53ef\u89e3\u91ca\u7684\u63a5\u53e3\uff0c\u901a\u8fc7\u8bed\u4e49-\u7269\u7406\u63a5\u5730\u6709\u6548\u5b9e\u73b0\u4e86\u7cbe\u786e\u548c\u53ef\u6cdb\u5316\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u3002"}}
{"id": "2510.07491", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07491", "abs": "https://arxiv.org/abs/2510.07491", "authors": ["Clotilde Bray\u00e9", "Aur\u00e9lien Bricout", "Arnaud Gotlieb", "Nadjib Lazaar", "Quentin Vallet"], "title": "Optimizing Ethical Risk Reduction for Medical Intelligent Systems with Constraint Programming", "comment": null, "summary": "Medical Intelligent Systems (MIS) are increasingly integrated into healthcare\nworkflows, offering significant benefits but also raising critical safety and\nethical concerns. According to the European Union AI Act, most MIS will be\nclassified as high-risk systems, requiring a formal risk management process to\nensure compliance with the ethical requirements of trustworthy AI. In this\ncontext, we focus on risk reduction optimization problems, which aim to reduce\nrisks with ethical considerations by finding the best balanced assignment of\nrisk assessment values according to their coverage of trustworthy AI ethical\nrequirements. We formalize this problem as a constrained optimization task and\ninvestigate three resolution paradigms: Mixed Integer Programming (MIP),\nSatisfiability (SAT), and Constraint Programming(CP).Our contributions include\nthe mathematical formulation of this optimization problem, its modeling with\nthe Minizinc constraint modeling language, and a comparative experimental study\nthat analyzes the performance, expressiveness, and scalability of each approach\nto solving. From the identified limits of the methodology, we draw some\nperspectives of this work regarding the integration of the Minizinc model into\na complete trustworthy AI ethical risk management process for MIS.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u533b\u7597\u667a\u80fd\u7cfb\u7edf\u7684\u4f26\u7406\u98ce\u9669\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u4e09\u79cd\u7f16\u7a0b\u65b9\u6cd5\uff08MIP\u3001SAT\u3001CP\uff09\u6765\u5e73\u8861\u98ce\u9669\u8bc4\u4f30\u503c\u4e0e\u53ef\u4fe1AI\u4f26\u7406\u8981\u6c42\u7684\u8986\u76d6\u5ea6\u3002", "motivation": "\u533b\u7597\u667a\u80fd\u7cfb\u7edf\u88ab\u6b27\u76dfAI\u6cd5\u6848\u5f52\u7c7b\u4e3a\u9ad8\u98ce\u9669\u7cfb\u7edf\uff0c\u9700\u8981\u8fdb\u884c\u6b63\u5f0f\u7684\u98ce\u9669\u7ba1\u7406\u4ee5\u786e\u4fdd\u7b26\u5408\u53ef\u4fe1AI\u7684\u4f26\u7406\u8981\u6c42\u3002", "method": "\u5c06\u98ce\u9669\u964d\u4f4e\u4f18\u5316\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u7ea6\u675f\u4f18\u5316\u4efb\u52a1\uff0c\u4f7f\u7528\u6df7\u5408\u6574\u6570\u89c4\u5212\u3001\u53ef\u6ee1\u8db3\u6027\u548c\u7ea6\u675f\u7f16\u7a0b\u4e09\u79cd\u65b9\u6cd5\uff0c\u5e76\u7528Minizinc\u7ea6\u675f\u5efa\u6a21\u8bed\u8a00\u8fdb\u884c\u5efa\u6a21\u3002", "result": "\u8fdb\u884c\u4e86\u6bd4\u8f83\u5b9e\u9a8c\u7814\u7a76\uff0c\u5206\u6790\u4e86\u6bcf\u79cd\u65b9\u6cd5\u5728\u6027\u80fd\u3001\u8868\u8fbe\u80fd\u529b\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u7684\u8868\u73b0\u3002", "conclusion": "\u4ece\u65b9\u6cd5\u8bba\u7684\u5c40\u9650\u6027\u51fa\u53d1\uff0c\u63d0\u51fa\u4e86\u5c06Minizinc\u6a21\u578b\u6574\u5408\u5230\u5b8c\u6574\u53ef\u4fe1AI\u4f26\u7406\u98ce\u9669\u7ba1\u7406\u6d41\u7a0b\u4e2d\u7684\u672a\u6765\u5de5\u4f5c\u65b9\u5411\u3002"}}
{"id": "2510.07986", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07986", "abs": "https://arxiv.org/abs/2510.07986", "authors": ["Gaofeng Li", "Peisen Xu", "Ruize Wang", "Qi Ye", "Jiming Chen", "Dezhen Song", "Yanlong Huang"], "title": "Orientation Learning and Adaptation towards Simultaneous Incorporation of Multiple Local Constraints", "comment": null, "summary": "Orientation learning plays a pivotal role in many tasks. However, the\nrotation group SO(3) is a Riemannian manifold. As a result, the distortion\ncaused by non-Euclidean geometric nature introduces difficulties to the\nincorporation of local constraints, especially for the simultaneous\nincorporation of multiple local constraints. To address this issue, we propose\nthe Angle-Axis Space-based orientation representation method to solve several\norientation learning problems, including orientation adaptation and\nminimization of angular acceleration. Specifically, we propose a weighted\naverage mechanism in SO(3) based on the angle-axis representation method. Our\nmain idea is to generate multiple trajectories by considering different local\nconstraints at different basepoints. Then these multiple trajectories are fused\nto generate a smooth trajectory by our proposed weighted average mechanism,\nachieving the goal to incorporate multiple local constraints simultaneously.\nCompared with existing solution, ours can address the distortion issue and make\nthe off-theshelf Euclidean learning algorithm be re-applicable in non-Euclidean\nspace. Simulation and Experimental evaluations validate that our solution can\nnot only adapt orientations towards arbitrary desired via-points and cope with\nangular acceleration constraints, but also incorporate multiple local\nconstraints simultaneously to achieve extra benefits, e.g., achieving smaller\nacceleration costs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u89d2\u5ea6-\u8f74\u7a7a\u95f4\u7684\u65b9\u5411\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a0\u6743\u5e73\u5747\u673a\u5236\u5728SO(3)\u6d41\u5f62\u4e0a\u878d\u5408\u591a\u4e2a\u8f68\u8ff9\uff0c\u540c\u65f6\u5904\u7406\u591a\u4e2a\u5c40\u90e8\u7ea6\u675f\uff0c\u89e3\u51b3\u975e\u6b27\u51e0\u4f55\u5e26\u6765\u7684\u5931\u771f\u95ee\u9898\u3002", "motivation": "\u65cb\u8f6c\u7fa4SO(3)\u662f\u9ece\u66fc\u6d41\u5f62\uff0c\u5176\u975e\u6b27\u51e0\u4f55\u7279\u6027\u5bfc\u81f4\u5c40\u90e8\u7ea6\u675f\u6574\u5408\u56f0\u96be\uff0c\u7279\u522b\u662f\u540c\u65f6\u6574\u5408\u591a\u4e2a\u5c40\u90e8\u7ea6\u675f\u65f6\u5b58\u5728\u6311\u6218\u3002", "method": "\u4f7f\u7528\u89d2\u5ea6-\u8f74\u8868\u793a\u6cd5\uff0c\u5728\u4e0d\u540c\u57fa\u70b9\u8003\u8651\u4e0d\u540c\u5c40\u90e8\u7ea6\u675f\u751f\u6210\u591a\u4e2a\u8f68\u8ff9\uff0c\u7136\u540e\u901a\u8fc7\u63d0\u51fa\u7684\u52a0\u6743\u5e73\u5747\u673a\u5236\u878d\u5408\u8fd9\u4e9b\u8f68\u8ff9\u751f\u6210\u5e73\u6ed1\u8f68\u8ff9\u3002", "result": "\u4eff\u771f\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u9002\u5e94\u4efb\u610f\u671f\u671b\u8def\u5f84\u70b9\u5e76\u5904\u7406\u89d2\u52a0\u901f\u5ea6\u7ea6\u675f\uff0c\u8fd8\u80fd\u540c\u65f6\u6574\u5408\u591a\u4e2a\u5c40\u90e8\u7ea6\u675f\u83b7\u5f97\u989d\u5916\u6536\u76ca\uff0c\u5982\u5b9e\u73b0\u66f4\u5c0f\u7684\u52a0\u901f\u5ea6\u6210\u672c\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u89e3\u51b3\u4e86SO(3)\u6d41\u5f62\u4e0a\u7684\u5931\u771f\u95ee\u9898\uff0c\u4f7f\u73b0\u6210\u7684\u6b27\u51e0\u91cc\u5f97\u5b66\u4e60\u7b97\u6cd5\u5728\u975e\u6b27\u7a7a\u95f4\u4e2d\u91cd\u65b0\u9002\u7528\uff0c\u6709\u6548\u6574\u5408\u591a\u4e2a\u5c40\u90e8\u7ea6\u675f\u3002"}}
{"id": "2510.07516", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.07516", "abs": "https://arxiv.org/abs/2510.07516", "authors": ["Md. Nazmul Islam Ananto", "Shamit Fatin", "Mohammed Eunus Ali", "Md Rizwan Parvez"], "title": "CompassLLM: A Multi-Agent Approach toward Geo-Spatial Reasoning for Popular Path Query", "comment": null, "summary": "The popular path query - identifying the most frequented routes between\nlocations from historical trajectory data - has important applications in urban\nplanning, navigation optimization, and travel recommendations. While\ntraditional algorithms and machine learning approaches have achieved success in\nthis domain, they typically require model training, parameter tuning, and\nretraining when accommodating data updates. As Large Language Models (LLMs)\ndemonstrate increasing capabilities in spatial and graph-based reasoning, there\nis growing interest in exploring how these models can be applied to geo-spatial\nproblems.\n  We introduce CompassLLM, a novel multi-agent framework that intelligently\nleverages the reasoning capabilities of LLMs into the geo-spatial domain to\nsolve the popular path query. CompassLLM employs its agents in a two-stage\npipeline: the SEARCH stage that identifies popular paths, and a GENERATE stage\nthat synthesizes novel paths in the absence of an existing one in the\nhistorical trajectory data. Experiments on real and synthetic datasets show\nthat CompassLLM demonstrates superior accuracy in SEARCH and competitive\nperformance in GENERATE while being cost-effective.", "AI": {"tldr": "CompassLLM\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u6d41\u884c\u8def\u5f84\u67e5\u8be2\u95ee\u9898\uff0c\u901a\u8fc7\u641c\u7d22\u548c\u751f\u6210\u4e24\u4e2a\u9636\u6bb5\u6765\u8bc6\u522b\u548c\u521b\u5efa\u70ed\u95e8\u8def\u7ebf\u3002", "motivation": "\u4f20\u7edf\u7b97\u6cd5\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u6d41\u884c\u8def\u5f84\u67e5\u8be2\u4e2d\u9700\u8981\u6a21\u578b\u8bad\u7ec3\u3001\u53c2\u6570\u8c03\u4f18\u548c\u91cd\u65b0\u8bad\u7ec3\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u548c\u56fe\u63a8\u7406\u65b9\u9762\u5c55\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u56e0\u6b64\u63a2\u7d22\u5982\u4f55\u5c06\u5176\u5e94\u7528\u4e8e\u5730\u7406\u7a7a\u95f4\u95ee\u9898\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "CompassLLM\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1aSEARCH\u9636\u6bb5\u8bc6\u522b\u73b0\u6709\u70ed\u95e8\u8def\u5f84\uff0cGENERATE\u9636\u6bb5\u5728\u5386\u53f2\u8f68\u8ff9\u6570\u636e\u4e2d\u4e0d\u5b58\u5728\u8def\u5f84\u65f6\u5408\u6210\u65b0\u8def\u5f84\u3002", "result": "\u5728\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCompassLLM\u5728SEARCH\u9636\u6bb5\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u51c6\u786e\u6027\uff0c\u5728GENERATE\u9636\u6bb5\u5177\u6709\u7ade\u4e89\u529b\uff0c\u540c\u65f6\u6210\u672c\u6548\u76ca\u9ad8\u3002", "conclusion": "CompassLLM\u6210\u529f\u5730\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u5e94\u7528\u4e8e\u5730\u7406\u7a7a\u95f4\u9886\u57df\uff0c\u4e3a\u6d41\u884c\u8def\u5f84\u67e5\u8be2\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08022", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08022", "abs": "https://arxiv.org/abs/2510.08022", "authors": ["Kehui Liu", "Zhongjie Jia", "Yang Li", "Zhaxizhuoma", "Pengan Chen", "Song Liu", "Xin Liu", "Pingrui Zhang", "Haoming Song", "Xinyi Ye", "Nieqing Cao", "Zhigang Wang", "Jia Zeng", "Dong Wang", "Yan Ding", "Bin Zhao", "Xuelong Li"], "title": "FastUMI-100K: Advancing Data-driven Robotic Manipulation with a Large-scale UMI-style Dataset", "comment": null, "summary": "Data-driven robotic manipulation learning depends on large-scale,\nhigh-quality expert demonstration datasets. However, existing datasets, which\nprimarily rely on human teleoperated robot collection, are limited in terms of\nscalability, trajectory smoothness, and applicability across different robotic\nembodiments in real-world environments. In this paper, we present FastUMI-100K,\na large-scale UMI-style multimodal demonstration dataset, designed to overcome\nthese limitations and meet the growing complexity of real-world manipulation\ntasks. Collected by FastUMI, a novel robotic system featuring a modular,\nhardware-decoupled mechanical design and an integrated lightweight tracking\nsystem, FastUMI-100K offers a more scalable, flexible, and adaptable solution\nto fulfill the diverse requirements of real-world robot demonstration data.\nSpecifically, FastUMI-100K contains over 100K+ demonstration trajectories\ncollected across representative household environments, covering 54 tasks and\nhundreds of object types. Our dataset integrates multimodal streams, including\nend-effector states, multi-view wrist-mounted fisheye images and textual\nannotations. Each trajectory has a length ranging from 120 to 500 frames.\nExperimental results demonstrate that FastUMI-100K enables high policy success\nrates across various baseline algorithms, confirming its robustness,\nadaptability, and real-world applicability for solving complex, dynamic\nmanipulation challenges. The source code and dataset will be released in this\nlink https://github.com/MrKeee/FastUMI-100K.", "AI": {"tldr": "FastUMI-100K\u662f\u4e00\u4e2a\u5927\u89c4\u6a21UMI\u98ce\u683c\u7684\u591a\u6a21\u6001\u6f14\u793a\u6570\u636e\u96c6\uff0c\u5305\u542b10\u4e07+\u6761\u8f68\u8ff9\uff0c\u6db5\u76d654\u4e2a\u4efb\u52a1\u548c\u6570\u767e\u79cd\u7269\u4f53\u7c7b\u578b\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u673a\u5668\u4eba\u6f14\u793a\u6570\u636e\u96c6\u5728\u53ef\u6269\u5c55\u6027\u3001\u8f68\u8ff9\u5e73\u6ed1\u6027\u548c\u8de8\u673a\u5668\u4eba\u5e73\u53f0\u9002\u7528\u6027\u65b9\u9762\u7684\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u5b66\u4e60\u6570\u636e\u96c6\u4e3b\u8981\u4f9d\u8d56\u4eba\u7c7b\u9065\u64cd\u4f5c\u6536\u96c6\uff0c\u5b58\u5728\u53ef\u6269\u5c55\u6027\u5dee\u3001\u8f68\u8ff9\u4e0d\u5e73\u6ed1\u4ee5\u53ca\u5728\u4e0d\u540c\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u9002\u7528\u6027\u6709\u9650\u7684\u95ee\u9898\u3002\u9700\u8981\u5f00\u53d1\u66f4\u7075\u6d3b\u3001\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\u6765\u6ee1\u8db3\u73b0\u5b9e\u4e16\u754c\u590d\u6742\u64cd\u4f5c\u4efb\u52a1\u7684\u9700\u6c42\u3002", "method": "\u901a\u8fc7FastUMI\u7cfb\u7edf\u6536\u96c6\u6570\u636e\uff0c\u8be5\u7cfb\u7edf\u91c7\u7528\u6a21\u5757\u5316\u3001\u786c\u4ef6\u89e3\u8026\u7684\u673a\u68b0\u8bbe\u8ba1\uff0c\u5e76\u96c6\u6210\u4e86\u8f7b\u91cf\u7ea7\u8ddf\u8e2a\u7cfb\u7edf\u3002\u6570\u636e\u96c6\u5305\u542b\u591a\u6a21\u6001\u6570\u636e\u6d41\uff0c\u5305\u62ec\u672b\u7aef\u6267\u884c\u5668\u72b6\u6001\u3001\u591a\u89c6\u89d2\u9c7c\u773c\u56fe\u50cf\u548c\u6587\u672c\u6ce8\u91ca\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFastUMI-100K\u80fd\u591f\u5728\u5404\u79cd\u57fa\u7ebf\u7b97\u6cd5\u4e0a\u5b9e\u73b0\u9ad8\u7b56\u7565\u6210\u529f\u7387\uff0c\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\u3001\u9002\u5e94\u6027\u548c\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u9002\u7528\u6027\uff0c\u80fd\u591f\u89e3\u51b3\u590d\u6742\u52a8\u6001\u64cd\u4f5c\u6311\u6218\u3002", "conclusion": "FastUMI-100K\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u53ef\u6269\u5c55\u3001\u7075\u6d3b\u548c\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6ee1\u8db3\u73b0\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u6f14\u793a\u6570\u636e\u7684\u591a\u6837\u5316\u9700\u6c42\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002"}}
{"id": "2510.07517", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.07517", "abs": "https://arxiv.org/abs/2510.07517", "authors": ["Hyeong Kyu Choi", "Xiaojin Zhu", "Yixuan Li"], "title": "Measuring and Mitigating Identity Bias in Multi-Agent Debate via Anonymization", "comment": null, "summary": "Multi-agent debate (MAD) aims to improve large language model (LLM) reasoning\nby letting multiple agents exchange answers and then aggregate their opinions.\nYet recent studies reveal that agents are not neutral: they are prone to\nidentity-driven sycophancy and self-bias, uncritically adopting a peer's view\nor stubbornly adhering to their own prior output, undermining the reliability\nof debate. In this work, we present the first principled framework that joins\nsycophancy and self-bias to mitigate and quantify identity bias in MAD. First,\nwe formalize the debate dynamics as an identity-weighted Bayesian update\nprocess. Second, we propose response anonymization: by removing identity\nmarkers from prompts, agents cannot distinguish \"self\" from \"peer\", which\nforces equal weights on agent identity, thereby reducing bias. Third, we define\nthe Identity Bias Coefficient (IBC), a principled metric that measures how\noften an agent follows a peer versus itself. Empirical studies across multiple\nmodels, datasets and debate rounds confirm that identity bias is widespread,\nwith sycophancy far more common than self-bias. Our findings highlight the need\nto \"mask\" identity to ensure that MAD systems reason based on content rather\nthan source identity. Code is released in\nhttps://github.com/deeplearning-wisc/MAD-identity-bias.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u7cfb\u7edf\u6027\u6846\u67b6\u6765\u91cf\u5316\u548c\u51cf\u8f7b\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u4e2d\u7684\u8eab\u4efd\u504f\u89c1\uff0c\u901a\u8fc7\u54cd\u5e94\u533f\u540d\u5316\u548c\u8eab\u4efd\u504f\u89c1\u7cfb\u6570\u6765\u89e3\u51b3\u667a\u80fd\u4f53\u7684\u8c04\u5a9a\u548c\u81ea\u6211\u504f\u89c1\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u4e2d\u7684\u667a\u80fd\u4f53\u5b58\u5728\u8eab\u4efd\u9a71\u52a8\u7684\u8c04\u5a9a\u548c\u81ea\u6211\u504f\u89c1\uff0c\u4f1a\u4e0d\u52a0\u6279\u5224\u5730\u91c7\u7eb3\u540c\u4f34\u89c2\u70b9\u6216\u56fa\u6267\u575a\u6301\u81ea\u5df1\u5148\u524d\u8f93\u51fa\uff0c\u8fd9\u524a\u5f31\u4e86\u8fa9\u8bba\u7684\u53ef\u9760\u6027\u3002", "method": "1. \u5c06\u8fa9\u8bba\u52a8\u6001\u5f62\u5f0f\u5316\u4e3a\u8eab\u4efd\u52a0\u6743\u7684\u8d1d\u53f6\u65af\u66f4\u65b0\u8fc7\u7a0b\uff1b2. \u63d0\u51fa\u54cd\u5e94\u533f\u540d\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u79fb\u9664\u63d0\u793a\u4e2d\u7684\u8eab\u4efd\u6807\u8bb0\u4f7f\u667a\u80fd\u4f53\u65e0\u6cd5\u533a\u5206\"\u81ea\u6211\"\u548c\"\u540c\u4f34\"\uff1b3. \u5b9a\u4e49\u8eab\u4efd\u504f\u89c1\u7cfb\u6570\u6765\u91cf\u5316\u504f\u89c1\u7a0b\u5ea6\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u8fa9\u8bba\u8f6e\u6b21\u4e0a\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\u8eab\u4efd\u504f\u89c1\u666e\u904d\u5b58\u5728\uff0c\u8c04\u5a9a\u73b0\u8c61\u8fdc\u591a\u4e8e\u81ea\u6211\u504f\u89c1\u3002\u54cd\u5e94\u533f\u540d\u5316\u80fd\u6709\u6548\u51cf\u5c11\u504f\u89c1\u3002", "conclusion": "\u9700\u8981\"\u63a9\u76d6\"\u8eab\u4efd\u4ee5\u786e\u4fdd\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u7cfb\u7edf\u57fa\u4e8e\u5185\u5bb9\u800c\u975e\u6765\u6e90\u8eab\u4efd\u8fdb\u884c\u63a8\u7406\uff0c\u8eab\u4efd\u533f\u540d\u5316\u662f\u786e\u4fdd\u8fa9\u8bba\u53ef\u9760\u6027\u7684\u5173\u952e\u3002"}}
{"id": "2510.08406", "categories": ["cs.RO", "cs.SY", "eess.SY", "math.OC", "I.2.9; G.1.6; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.08406", "abs": "https://arxiv.org/abs/2510.08406", "authors": ["Filip Be\u010danovi\u0107", "Kosta Jovanovi\u0107", "Vincent Bonnet"], "title": "Reliability of Single-Level Equality-Constrained Inverse Optimal Control", "comment": "8 pages, 3 figures", "summary": "Inverse optimal control (IOC) allows the retrieval of optimal cost function\nweights, or behavioral parameters, from human motion. The literature on IOC\nuses methods that are either based on a slow bilevel process or a fast but\nnoise-sensitive minimization of optimality condition violation. Assuming\nequality-constrained optimal control models of human motion, this article\npresents a faster but robust approach to solving IOC using a single-level\nreformulation of the bilevel method and yields equivalent results. Through\nnumerical experiments in simulation, we analyze the robustness to noise of the\nproposed single-level reformulation to the bilevel IOC formulation with a\nhuman-like planar reaching task that is used across recent studies. The\napproach shows resilience to very large levels of noise and reduces the\ncomputation time of the IOC on this task by a factor of 15 when compared to a\nclassical bilevel implementation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5355\u7ea7\u91cd\u6784\u7684\u9006\u6700\u4f18\u63a7\u5236\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u53cc\u5c42\u65b9\u6cd5\u8ba1\u7b97\u901f\u5ea6\u63d0\u534715\u500d\uff0c\u4e14\u5bf9\u566a\u58f0\u5177\u6709\u5f3a\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u9006\u6700\u4f18\u63a7\u5236\u65b9\u6cd5\u8981\u4e48\u57fa\u4e8e\u7f13\u6162\u7684\u53cc\u5c42\u8fc7\u7a0b\uff0c\u8981\u4e48\u57fa\u4e8e\u5feb\u901f\u4f46\u5bf9\u566a\u58f0\u654f\u611f\u7684\u4f18\u5316\u6761\u4ef6\u8fdd\u53cd\u6700\u5c0f\u5316\u65b9\u6cd5\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u5feb\u901f\u53c8\u9c81\u68d2\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5355\u7ea7\u91cd\u6784\u65b9\u6cd5\u66ff\u4ee3\u4f20\u7edf\u7684\u53cc\u5c42\u9006\u6700\u4f18\u63a7\u5236\u65b9\u6cd5\uff0c\u57fa\u4e8e\u7b49\u5f0f\u7ea6\u675f\u7684\u6700\u4f18\u63a7\u5236\u6a21\u578b\u3002", "result": "\u5728\u5e73\u9762\u5230\u8fbe\u4efb\u52a1\u7684\u6570\u503c\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5bf9\u6781\u5927\u566a\u58f0\u6c34\u5e73\u8868\u73b0\u51fa\u5f39\u6027\uff0c\u8ba1\u7b97\u65f6\u95f4\u6bd4\u7ecf\u5178\u53cc\u5c42\u5b9e\u73b0\u51cf\u5c1115\u500d\u3002", "conclusion": "\u5355\u7ea7\u91cd\u6784\u65b9\u6cd5\u5728\u4fdd\u6301\u7ed3\u679c\u7b49\u6548\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9006\u6700\u4f18\u63a7\u5236\u7684\u8ba1\u7b97\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.08044", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08044", "abs": "https://arxiv.org/abs/2510.08044", "authors": ["Shiyuan Yin", "Chenjia Bai", "Zihao Zhang", "Junwei Jin", "Xinxin Zhang", "Chi Zhang", "Xuelong Li"], "title": "Towards Reliable LLM-based Robot Planning via Combined Uncertainty Estimation", "comment": null, "summary": "Large language models (LLMs) demonstrate advanced reasoning abilities,\nenabling robots to understand natural language instructions and generate\nhigh-level plans with appropriate grounding. However, LLM hallucinations\npresent a significant challenge, often leading to overconfident yet potentially\nmisaligned or unsafe plans. While researchers have explored uncertainty\nestimation to improve the reliability of LLM-based planning, existing studies\nhave not sufficiently differentiated between epistemic and intrinsic\nuncertainty, limiting the effectiveness of uncertainty estimation. In this\npaper, we present Combined Uncertainty estimation for Reliable Embodied\nplanning (CURE), which decomposes the uncertainty into epistemic and intrinsic\nuncertainty, each estimated separately. Furthermore, epistemic uncertainty is\nsubdivided into task clarity and task familiarity for more accurate evaluation.\nThe overall uncertainty assessments are obtained using random network\ndistillation and multi-layer perceptron regression heads driven by LLM\nfeatures. We validated our approach in two distinct experimental settings:\nkitchen manipulation and tabletop rearrangement experiments. The results show\nthat, compared to existing methods, our approach yields uncertainty estimates\nthat are more closely aligned with the actual execution outcomes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CURE\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\u4e3a\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u5185\u5728\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u4f7f\u7528\u968f\u673a\u7f51\u7edc\u84b8\u998f\u548cMLP\u56de\u5f52\u5934\u6765\u4f30\u8ba1\uff0c\u63d0\u9ad8\u4e86LLM\u5728\u673a\u5668\u4eba\u89c4\u5212\u4e2d\u7684\u53ef\u9760\u6027\u3002", "motivation": "LLM\u5728\u673a\u5668\u4eba\u89c4\u5212\u4e2d\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u81ea\u4fe1\u4f46\u53ef\u80fd\u4e0d\u51c6\u786e\u6216\u4e0d\u5b89\u5168\u7684\u8ba1\u5212\u3002\u73b0\u6709\u7814\u7a76\u672a\u80fd\u5145\u5206\u533a\u5206\u8ba4\u77e5\u548c\u5185\u5728\u4e0d\u786e\u5b9a\u6027\uff0c\u9650\u5236\u4e86\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u6548\u679c\u3002", "method": "\u63d0\u51faCURE\u65b9\u6cd5\uff0c\u5c06\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\u4e3a\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff08\u7ec6\u5206\u4e3a\u4efb\u52a1\u6e05\u6670\u5ea6\u548c\u4efb\u52a1\u719f\u6089\u5ea6\uff09\u548c\u5185\u5728\u4e0d\u786e\u5b9a\u6027\uff0c\u4f7f\u7528\u968f\u673a\u7f51\u7edc\u84b8\u998f\u548c\u57fa\u4e8eLLM\u7279\u5f81\u7684\u591a\u5c42\u611f\u77e5\u673a\u56de\u5f52\u5934\u8fdb\u884c\u4f30\u8ba1\u3002", "result": "\u5728\u53a8\u623f\u64cd\u4f5c\u548c\u684c\u9762\u91cd\u6392\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0cCURE\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u66f4\u7b26\u5408\u5b9e\u9645\u6267\u884c\u7ed3\u679c\u3002", "conclusion": "CURE\u65b9\u6cd5\u901a\u8fc7\u5206\u89e3\u548c\u5206\u522b\u4f30\u8ba1\u4e0d\u540c\u7c7b\u578b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u5728\u673a\u5668\u4eba\u89c4\u5212\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u66f4\u51c6\u786e\u3002"}}
{"id": "2510.07551", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07551", "abs": "https://arxiv.org/abs/2510.07551", "authors": ["Harshit Rajgarhia", "Suryam Gupta", "Asif Shaik", "Gulipalli Praveen Kumar", "Y Santhoshraj", "Sanka Nithya Tanvy Nishitha", "Abhishek Mukherji"], "title": "An Evaluation Study of Hybrid Methods for Multilingual PII Detection", "comment": null, "summary": "The detection of Personally Identifiable Information (PII) is critical for\nprivacy compliance but remains challenging in low-resource languages due to\nlinguistic diversity and limited annotated data. We present RECAP, a hybrid\nframework that combines deterministic regular expressions with context-aware\nlarge language models (LLMs) for scalable PII detection across 13 low-resource\nlocales. RECAP's modular design supports over 300 entity types without\nretraining, using a three-phase refinement pipeline for disambiguation and\nfiltering. Benchmarked with nervaluate, our system outperforms fine-tuned NER\nmodels by 82% and zero-shot LLMs by 17% in weighted F1-score. This work offers\na scalable and adaptable solution for efficient PII detection in\ncompliance-focused applications.", "AI": {"tldr": "RECAP\u662f\u4e00\u4e2a\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u786e\u5b9a\u6027\u6b63\u5219\u8868\u8fbe\u5f0f\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u4e8e\u572813\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u68c0\u6d4b\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f\uff0c\u6027\u80fd\u4f18\u4e8e\u5fae\u8c03NER\u6a21\u578b82%\u548c\u96f6\u6837\u672cLLM 17%\u3002", "motivation": "\u89e3\u51b3\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2dPII\u68c0\u6d4b\u7684\u6311\u6218\uff0c\u7531\u4e8e\u8bed\u8a00\u591a\u6837\u6027\u548c\u6807\u6ce8\u6570\u636e\u6709\u9650\uff0c\u9700\u8981\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u6765\u6ee1\u8db3\u9690\u79c1\u5408\u89c4\u8981\u6c42\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u6b63\u5219\u8868\u8fbe\u5f0f\u548cLLM\uff0c\u4f7f\u7528\u4e09\u9636\u6bb5\u7cbe\u70bc\u6d41\u7a0b\u8fdb\u884c\u6d88\u6b67\u548c\u8fc7\u6ee4\uff0c\u6a21\u5757\u5316\u8bbe\u8ba1\u652f\u6301300\u591a\u79cd\u5b9e\u4f53\u7c7b\u578b\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "result": "\u4f7f\u7528nervaluate\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5728\u52a0\u6743F1\u5206\u6570\u4e0a\u6bd4\u5fae\u8c03NER\u6a21\u578b\u9ad882%\uff0c\u6bd4\u96f6\u6837\u672cLLM\u9ad817%\u3002", "conclusion": "RECAP\u4e3a\u5408\u89c4\u5e94\u7528\u4e2d\u7684PII\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08106", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.08106", "abs": "https://arxiv.org/abs/2510.08106", "authors": ["Zihan Li", "Yixiao Xu", "Lei Zhang", "Taiyu Han", "Xinshan Yang", "Yingni Wang", "Mingxuan Liu", "Shenghai Xin", "Linxun Liu", "Hongen Liao", "Guochen Ning"], "title": "Beyond hospital reach: Autonomous lightweight ultrasound robot for liver sonography", "comment": null, "summary": "Liver disease is a major global health burden. While ultrasound is the\nfirst-line diagnostic tool, liver sonography requires locating multiple\nnon-continuous planes from positions where target structures are often not\nvisible, for biometric assessment and lesion detection, requiring significant\nexpertise. However, expert sonographers are severely scarce in resource-limited\nregions. Here, we develop an autonomous lightweight ultrasound robot comprising\nan AI agent that integrates multi-modal perception with memory attention for\nlocalization of unseen target structures, and a 588-gram 6-degrees-of-freedom\ncable-driven robot. By mounting on the abdomen, the system enhances robustness\nagainst motion. Our robot can autonomously acquire expert-level standard liver\nultrasound planes and detect pathology in patients, including two from Xining,\na 2261-meter-altitude city with limited medical resources. Our system performs\neffectively on rapid-motion individuals and in wilderness environments. This\nwork represents the first demonstration of autonomous sonography across\nmultiple challenging scenarios, potentially transforming access to expert-level\ndiagnostics in underserved regions.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u81ea\u4e3b\u8d85\u58f0\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u8d44\u6e90\u6709\u9650\u5730\u533a\u81ea\u52a8\u83b7\u53d6\u4e13\u5bb6\u7ea7\u809d\u810f\u8d85\u58f0\u5e73\u9762\u5e76\u68c0\u6d4b\u75c5\u7406\uff0c\u9002\u7528\u4e8e\u5feb\u901f\u8fd0\u52a8\u548c\u91ce\u5916\u73af\u5883\u3002", "motivation": "\u809d\u810f\u75be\u75c5\u662f\u5168\u7403\u91cd\u5927\u5065\u5eb7\u8d1f\u62c5\uff0c\u8d85\u58f0\u662f\u9996\u9009\u8bca\u65ad\u5de5\u5177\uff0c\u4f46\u809d\u810f\u8d85\u58f0\u68c0\u67e5\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u800c\u4e13\u5bb6\u8d85\u58f0\u533b\u751f\u5728\u8d44\u6e90\u6709\u9650\u5730\u533a\u4e25\u91cd\u77ed\u7f3a\u3002", "method": "\u7cfb\u7edf\u5305\u542bAI\u667a\u80fd\u4f53\uff08\u96c6\u6210\u591a\u6a21\u6001\u611f\u77e5\u4e0e\u8bb0\u5fc6\u6ce8\u610f\u529b\u673a\u5236\u7528\u4e8e\u5b9a\u4f4d\u4e0d\u53ef\u89c1\u76ee\u6807\u7ed3\u6784\uff09\u548c588\u514b6\u81ea\u7531\u5ea6\u7ebf\u9a71\u52a8\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u5b89\u88c5\u5728\u8179\u90e8\u589e\u5f3a\u8fd0\u52a8\u7a33\u5b9a\u6027\u3002", "result": "\u673a\u5668\u4eba\u80fd\u591f\u81ea\u4e3b\u83b7\u53d6\u4e13\u5bb6\u7ea7\u6807\u51c6\u809d\u810f\u8d85\u58f0\u5e73\u9762\u5e76\u68c0\u6d4b\u60a3\u8005\u75c5\u7406\uff0c\u5728\u897f\u5b81\uff08\u6d77\u62d42261\u7c73\uff09\u7b49\u533b\u7597\u8d44\u6e90\u6709\u9650\u5730\u533a\u6709\u6548\u5de5\u4f5c\uff0c\u5728\u5feb\u901f\u8fd0\u52a8\u4e2a\u4f53\u548c\u91ce\u5916\u73af\u5883\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5728\u591a\u79cd\u6311\u6218\u6027\u573a\u666f\u4e0b\u5b9e\u73b0\u81ea\u4e3b\u8d85\u58f0\u68c0\u67e5\u7684\u6f14\u793a\uff0c\u6709\u671b\u6539\u53d8\u8d44\u6e90\u532e\u4e4f\u5730\u533a\u83b7\u5f97\u4e13\u5bb6\u7ea7\u8bca\u65ad\u7684\u53ef\u53ca\u6027\u3002"}}
{"id": "2510.07575", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.07575", "abs": "https://arxiv.org/abs/2510.07575", "authors": ["Zerui Cheng", "Stella Wohnig", "Ruchika Gupta", "Samiul Alam", "Tassallah Abdullahi", "Jo\u00e3o Alves Ribeiro", "Christian Nielsen-Garcia", "Saif Mir", "Siran Li", "Jason Orender", "Seyed Ali Bahrainian", "Daniel Kirste", "Aaron Gokaslan", "Miko\u0142aj Glinka", "Carsten Eickhoff", "Ruben Wolff"], "title": "Benchmarking is Broken -- Don't Let AI be its Own Judge", "comment": "12 pages; Accepted to NeurIPS 2025. Link to poster:\n  https://neurips.cc/virtual/2025/poster/121919", "summary": "The meteoric rise of Artificial Intelligence (AI), with its rapidly expanding\nmarket capitalization, presents both transformative opportunities and critical\nchallenges. Chief among these is the urgent need for a new, unified paradigm\nfor trustworthy evaluation, as current benchmarks increasingly reveal critical\nvulnerabilities. Issues like data contamination and selective reporting by\nmodel developers fuel hype, while inadequate data quality control can lead to\nbiased evaluations that, even if unintentionally, may favor specific\napproaches. As a flood of participants enters the AI space, this \"Wild West\" of\nassessment makes distinguishing genuine progress from exaggerated claims\nexceptionally difficult. Such ambiguity blurs scientific signals and erodes\npublic confidence, much as unchecked claims would destabilize financial markets\nreliant on credible oversight from agencies like Moody's.\n  In high-stakes human examinations (e.g., SAT, GRE), substantial effort is\ndevoted to ensuring fairness and credibility; why settle for less in evaluating\nAI, especially given its profound societal impact? This position paper argues\nthat the current laissez-faire approach is unsustainable. We contend that true,\nsustainable AI advancement demands a paradigm shift: a unified, live, and\nquality-controlled benchmarking framework robust by construction, not by mere\ncourtesy and goodwill. To this end, we dissect the systemic flaws undermining\ntoday's AI evaluation, distill the essential requirements for a new generation\nof assessments, and introduce PeerBench, a community-governed, proctored\nevaluation blueprint that embodies this paradigm through sealed execution, item\nbanking with rolling renewal, and delayed transparency. Our goal is to pave the\nway for evaluations that can restore integrity and deliver genuinely\ntrustworthy measures of AI progress.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20AI\u8bc4\u4f30\u9700\u8981\u8303\u5f0f\u8f6c\u53d8\uff0c\u63d0\u51faPeerBench\u4f5c\u4e3a\u793e\u533a\u6cbb\u7406\u7684\u76d1\u7763\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5bc6\u5c01\u6267\u884c\u3001\u9898\u5e93\u6eda\u52a8\u66f4\u65b0\u548c\u5ef6\u8fdf\u900f\u660e\u7b49\u673a\u5236\u89e3\u51b3\u5f53\u524d\u8bc4\u4f30\u7684\u7cfb\u7edf\u6027\u7f3a\u9677\u3002", "motivation": "\u5f53\u524dAI\u8bc4\u4f30\u5b58\u5728\u6570\u636e\u6c61\u67d3\u3001\u9009\u62e9\u6027\u62a5\u544a\u7b49\u4e25\u91cd\u6f0f\u6d1e\uff0c\u5bfc\u81f4\u96be\u4ee5\u533a\u5206\u771f\u5b9e\u8fdb\u5c55\u4e0e\u5938\u5927\u5ba3\u4f20\uff0c\u524a\u5f31\u79d1\u5b66\u4fe1\u53f7\u548c\u516c\u4f17\u4fe1\u4efb\uff0c\u8feb\u5207\u9700\u8981\u53ef\u4fe1\u8d56\u7684\u7edf\u4e00\u8bc4\u4f30\u8303\u5f0f\u3002", "method": "\u63d0\u51faPeerBench\u6846\u67b6\uff0c\u91c7\u7528\u5bc6\u5c01\u6267\u884c\u9632\u6b62\u6570\u636e\u6cc4\u9732\uff0c\u9898\u5e93\u94f6\u884c\u673a\u5236\u5b9a\u671f\u66f4\u65b0\u9898\u76ee\uff0c\u5ef6\u8fdf\u900f\u660e\u5ea6\u786e\u4fdd\u8bc4\u4f30\u5b8c\u6574\u6027\uff0c\u793e\u533a\u6cbb\u7406\u786e\u4fdd\u516c\u5e73\u6027\u3002", "result": "PeerBench\u6846\u67b6\u4e3a\u6784\u5efa\u7a33\u5065\u3001\u53ef\u4fe1\u7684AI\u8bc4\u4f30\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5177\u4f53\u84dd\u56fe\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u5f53\u524d\u8bc4\u4f30\u4e2d\u7684\u7cfb\u7edf\u6027\u7f3a\u9677\u3002", "conclusion": "AI\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u9700\u8981\u4ece\u81ea\u7531\u653e\u4efb\u7684\u8bc4\u4f30\u65b9\u5f0f\u8f6c\u5411\u7edf\u4e00\u3001\u5b9e\u65f6\u3001\u8d28\u91cf\u53ef\u63a7\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0cPeerBench\u4e3a\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2510.08118", "categories": ["cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.08118", "abs": "https://arxiv.org/abs/2510.08118", "authors": ["Massimiliano de Leoni", "Faizan Ahmed Khan", "Simone Agostinelli"], "title": "Accurate and Noise-Tolerant Extraction of Routine Logs in Robotic Process Automation (Extended Version)", "comment": "16 pages, 5 figures", "summary": "Robotic Process Mining focuses on the identification of the routine types\nperformed by human resources through a User Interface. The ultimate goal is to\ndiscover routine-type models to enable robotic process automation. The\ndiscovery of routine-type models requires the provision of a routine log.\nUnfortunately, the vast majority of existing works do not directly focus on\nenabling the model discovery, limiting themselves to extracting the set of\nactions that are part of the routines. They were also not evaluated in\nscenarios characterized by inconsistent routine execution, hereafter referred\nto as noise, which reflects natural variability and occasional errors in human\nperformance. This paper presents a clustering-based technique that aims to\nextract routine logs. Experiments were conducted on nine UI logs from the\nliterature with different levels of injected noise. Our technique was compared\nwith existing techniques, most of which are not meant to discover routine logs\nbut were adapted for the purpose. The results were evaluated through standard\nstate-of-the-art metrics, showing that we can extract more accurate routine\nlogs than what the state of the art could, especially in the presence of noise.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u6280\u672f\uff0c\u7528\u4e8e\u4ece\u7528\u6237\u754c\u9762\u65e5\u5fd7\u4e2d\u63d0\u53d6\u5e38\u89c4\u65e5\u5fd7\uff0c\u7279\u522b\u9488\u5bf9\u5305\u542b\u566a\u58f0\uff08\u4eba\u7c7b\u6267\u884c\u4e2d\u7684\u81ea\u7136\u53d8\u5f02\u548c\u5076\u7136\u9519\u8bef\uff09\u7684\u573a\u666f\uff0c\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u80fd\u63d0\u53d6\u66f4\u51c6\u786e\u7684\u5e38\u89c4\u65e5\u5fd7\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5927\u591a\u4e0d\u76f4\u63a5\u5173\u6ce8\u6a21\u578b\u53d1\u73b0\uff0c\u4ec5\u63d0\u53d6\u5e38\u89c4\u4e2d\u7684\u52a8\u4f5c\u96c6\u5408\uff0c\u4e14\u672a\u5728\u5305\u542b\u566a\u58f0\uff08\u4eba\u7c7b\u6267\u884c\u4e0d\u4e00\u81f4\u6027\uff09\u7684\u573a\u666f\u4e0b\u8fdb\u884c\u8bc4\u4f30\uff0c\u8fd9\u9650\u5236\u4e86\u673a\u5668\u4eba\u6d41\u7a0b\u81ea\u52a8\u5316\u7684\u5b9e\u73b0\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u805a\u7c7b\u7684\u6280\u672f\u4ece\u7528\u6237\u754c\u9762\u65e5\u5fd7\u4e2d\u63d0\u53d6\u5e38\u89c4\u65e5\u5fd7\uff0c\u5728\u4e5d\u4e2a\u5177\u6709\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\u7684UI\u65e5\u5fd7\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u4e0e\u73b0\u6709\u6280\u672f\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6280\u672f\u80fd\u591f\u6bd4\u73b0\u6709\u6280\u672f\u63d0\u53d6\u66f4\u51c6\u786e\u7684\u5e38\u89c4\u65e5\u5fd7\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u566a\u58f0\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u63d0\u51fa\u7684\u805a\u7c7b\u6280\u672f\u80fd\u591f\u6709\u6548\u5904\u7406\u566a\u58f0\u573a\u666f\u4e0b\u7684\u5e38\u89c4\u65e5\u5fd7\u63d0\u53d6\u95ee\u9898\uff0c\u4e3a\u673a\u5668\u4eba\u6d41\u7a0b\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u6a21\u578b\u53d1\u73b0\u65b9\u6cd5\u3002"}}
{"id": "2510.07593", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07593", "abs": "https://arxiv.org/abs/2510.07593", "authors": ["Bohan Lin", "Kuo Yang", "Yingchuan Lai", "Yudong Zhang", "Chen Zhang", "Guibin Zhang", "Xinlei Yu", "Miao Yu", "Xu Wang", "Yang Wang"], "title": "AgentAsk: Multi-Agent Systems Need to Ask", "comment": null, "summary": "Multi-agent systems built on large language models (LLMs) promise enhanced\nproblem-solving capabilities through collaborative division of labor. However,\nthey frequently underperform single-agent baselines due to edge-level error\ncascades: minor inaccuracies at one message handoff propagate across the entire\nchain. We propose AgentAsk, a lightweight and plug-and-play clarification\nmodule that treats every inter-agent message as a potential failure point and\ninserts minimally necessary questions to arrest error propagation. AgentAsk\nfollows a three-stage pipeline: (i) distilling edge-level judgments from\ncurated failure traces into a compact policy, (ii) supervising the policy to\ndetermine when/what/whom/how to ask, and (iii) optimizing online with E-GRPO, a\nreinforcement learning objective that balances accuracy, latency, and cost. The\nmodule is architecture-agnostic and easy to integrate into existing\norchestration. Across math, reasoning, and coding benchmarks, AgentAsk\nconsistently improves accuracy and robustness over public multi-agent\nimplementations while keeping overhead minimal, with latency and extra cost all\nless than 5%, approaching the performance of a strong evaluator. Beyond\nempirical improvements, we contribute a principled taxonomy of edge-level\nerrors and a practical recipe for link-local intervention, offering a scalable\npathway toward more reliable LLM-based multi-agent systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86AgentAsk\uff0c\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5373\u63d2\u5373\u7528\u7684\u6f84\u6e05\u6a21\u5757\uff0c\u901a\u8fc7\u5728\u667a\u80fd\u4f53\u95f4\u6d88\u606f\u4f20\u9012\u65f6\u63d2\u5165\u5fc5\u8981\u95ee\u9898\u6765\u963b\u6b62\u9519\u8bef\u4f20\u64ad\uff0c\u663e\u8457\u63d0\u5347\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u8fc7\u534f\u4f5c\u5206\u5de5\u6709\u671b\u589e\u5f3a\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u4f46\u7531\u4e8e\u8fb9\u7f18\u7ea7\u9519\u8bef\u7ea7\u8054\uff08\u4e00\u4e2a\u6d88\u606f\u4f20\u9012\u4e2d\u7684\u5c0f\u9519\u8bef\u4f1a\u5728\u6574\u4e2a\u94fe\u4e2d\u4f20\u64ad\uff09\u800c\u7ecf\u5e38\u8868\u73b0\u4e0d\u5982\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a(i)\u4ece\u6574\u7406\u7684\u5931\u8d25\u8f68\u8ff9\u4e2d\u63d0\u53d6\u8fb9\u7f18\u7ea7\u5224\u65ad\u5f62\u6210\u7d27\u51d1\u7b56\u7565\uff1b(ii)\u76d1\u7763\u7b56\u7565\u51b3\u5b9a\u4f55\u65f6/\u95ee\u4ec0\u4e48/\u95ee\u8c01/\u5982\u4f55\u95ee\uff1b(iii)\u4f7f\u7528E-GRPO\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\u5728\u7ebf\u4f18\u5316\uff0c\u5e73\u8861\u51c6\u786e\u6027\u3001\u5ef6\u8fdf\u548c\u6210\u672c\u3002", "result": "\u5728\u6570\u5b66\u3001\u63a8\u7406\u548c\u7f16\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgentAsk\u6301\u7eed\u63d0\u9ad8\u516c\u5171\u591a\u667a\u80fd\u4f53\u5b9e\u73b0\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u5c0f\u5f00\u9500\uff0c\u5ef6\u8fdf\u548c\u989d\u5916\u6210\u672c\u5747\u4f4e\u4e8e5%\uff0c\u63a5\u8fd1\u5f3a\u8bc4\u4f30\u5668\u7684\u6027\u80fd\u3002", "conclusion": "\u9664\u4e86\u7ecf\u9a8c\u6539\u8fdb\u5916\uff0c\u8fd8\u8d21\u732e\u4e86\u8fb9\u7f18\u7ea7\u9519\u8bef\u7684\u7cfb\u7edf\u5206\u7c7b\u548c\u94fe\u8def\u5c40\u90e8\u5e72\u9884\u7684\u5b9e\u7528\u65b9\u6cd5\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u7684\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u8def\u5f84\u3002"}}
{"id": "2510.08173", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.08173", "abs": "https://arxiv.org/abs/2510.08173", "authors": ["Haolin Yang", "Yuxing Long", "Zhuoyuan Yu", "Zihan Yang", "Minghan Wang", "Jiapeng Xu", "Yihan Wang", "Ziyan Yu", "Wenzhe Cai", "Lei Kang", "Hao Dong"], "title": "NavSpace: How Navigation Agents Follow Spatial Intelligence Instructions", "comment": null, "summary": "Instruction-following navigation is a key step toward embodied intelligence.\nPrior benchmarks mainly focus on semantic understanding but overlook\nsystematically evaluating navigation agents' spatial perception and reasoning\ncapabilities. In this work, we introduce the NavSpace benchmark, which contains\nsix task categories and 1,228 trajectory-instruction pairs designed to probe\nthe spatial intelligence of navigation agents. On this benchmark, we\ncomprehensively evaluate 22 navigation agents, including state-of-the-art\nnavigation models and multimodal large language models. The evaluation results\nlift the veil on spatial intelligence in embodied navigation. Furthermore, we\npropose SNav, a new spatially intelligent navigation model. SNav outperforms\nexisting navigation agents on NavSpace and real robot tests, establishing a\nstrong baseline for future work.", "AI": {"tldr": "\u63d0\u51fa\u4e86NavSpace\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b6\u4e2a\u4efb\u52a1\u7c7b\u522b\u548c1,228\u4e2a\u8f68\u8ff9-\u6307\u4ee4\u5bf9\uff0c\u7528\u4e8e\u8bc4\u4f30\u5bfc\u822a\u4ee3\u7406\u7684\u7a7a\u95f4\u667a\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u7a7a\u95f4\u667a\u80fd\u5bfc\u822a\u6a21\u578bSNav\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u8bed\u4e49\u7406\u89e3\uff0c\u4f46\u5ffd\u89c6\u4e86\u7cfb\u7edf\u8bc4\u4f30\u5bfc\u822a\u4ee3\u7406\u7684\u7a7a\u95f4\u611f\u77e5\u548c\u63a8\u7406\u80fd\u529b\u3002", "method": "\u6784\u5efaNavSpace\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b6\u4e2a\u4efb\u52a1\u7c7b\u522b\u548c1,228\u4e2a\u8f68\u8ff9-\u6307\u4ee4\u5bf9\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u7a7a\u95f4\u667a\u80fd\u5bfc\u822a\u6a21\u578bSNav\u3002", "result": "\u5728NavSpace\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\u4e8622\u4e2a\u5bfc\u822a\u4ee3\u7406\uff0cSNav\u6a21\u578b\u5728NavSpace\u548c\u771f\u5b9e\u673a\u5668\u4eba\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u5bfc\u822a\u4ee3\u7406\u3002", "conclusion": "NavSpace\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793a\u4e86\u5bfc\u822a\u4e2d\u7684\u7a7a\u95f4\u667a\u80fd\u95ee\u9898\uff0cSNav\u4e3a\u672a\u6765\u5de5\u4f5c\u5efa\u7acb\u4e86\u5f3a\u57fa\u7ebf\u3002"}}
{"id": "2510.07614", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.07614", "abs": "https://arxiv.org/abs/2510.07614", "authors": ["Amine Barrak"], "title": "Traceability and Accountability in Role-Specialized Multi-Agent LLM Pipelines", "comment": null, "summary": "Sequential multi-agent systems built with large language models (LLMs) can\nautomate complex software tasks, but they are hard to trust because errors\nquietly pass from one stage to the next. We study a traceable and accountable\npipeline, meaning a system with clear roles, structured handoffs, and saved\nrecords that let us trace who did what at each step and assign blame when\nthings go wrong. Our setting is a Planner -> Executor -> Critic pipeline. We\nevaluate eight configurations of three state-of-the-art LLMs on three\nbenchmarks and analyze where errors start, how they spread, and how they can be\nfixed. Our results show: (1) adding a structured, accountable handoff between\nagents markedly improves accuracy and prevents the failures common in simple\npipelines; (2) models have clear role-specific strengths and risks (e.g.,\nsteady planning vs. high-variance critiquing), which we quantify with repair\nand harm rates; and (3) accuracy-cost-latency trade-offs are task-dependent,\nwith heterogeneous pipelines often the most efficient. Overall, we provide a\npractical, data-driven method for designing, tracing, and debugging reliable,\npredictable, and accountable multi-agent systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8eLLM\u7684\u987a\u5e8f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53ef\u8ffd\u6eaf\u6027\u548c\u95ee\u8d23\u6027\uff0c\u901a\u8fc7Planner->Executor->Critic\u7ba1\u9053\u7ed3\u6784\uff0c\u8bc4\u4f30\u4e868\u79cd\u914d\u7f6e\u57283\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u7ed3\u6784\u5316\u4ea4\u63a5\u80fd\u663e\u8457\u63d0\u9ad8\u51c6\u786e\u6027\u5e76\u9632\u6b62\u9519\u8bef\u4f20\u64ad\u3002", "motivation": "\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u80fd\u591f\u81ea\u52a8\u5316\u590d\u6742\u8f6f\u4ef6\u4efb\u52a1\uff0c\u4f46\u7531\u4e8e\u9519\u8bef\u4f1a\u4ece\u4e00\u4e2a\u9636\u6bb5\u6084\u6084\u4f20\u9012\u5230\u4e0b\u4e00\u4e2a\u9636\u6bb5\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u96be\u4ee5\u88ab\u4fe1\u4efb\u3002\u9700\u8981\u5efa\u7acb\u53ef\u8ffd\u6eaf\u548c\u95ee\u8d23\u7684\u7ba1\u9053\u7cfb\u7edf\u3002", "method": "\u91c7\u7528Planner->Executor->Critic\u7ba1\u9053\u7ed3\u6784\uff0c\u8bc4\u4f30\u4e868\u79cd\u4e0d\u540c\u914d\u7f6e\u7684\u4e09\u79cd\u6700\u5148\u8fdbLLM\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\uff0c\u5206\u6790\u9519\u8bef\u8d77\u6e90\u3001\u4f20\u64ad\u548c\u4fee\u590d\u65b9\u5f0f\u3002", "result": "(1) \u6dfb\u52a0\u7ed3\u6784\u5316\u3001\u53ef\u95ee\u8d23\u7684\u667a\u80fd\u4f53\u95f4\u4ea4\u63a5\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u9632\u6b62\u4e86\u7b80\u5355\u7ba1\u9053\u4e2d\u5e38\u89c1\u7684\u5931\u8d25\uff1b(2) \u6a21\u578b\u5177\u6709\u660e\u786e\u7684\u89d2\u8272\u7279\u5b9a\u4f18\u52bf\u548c\u98ce\u9669\uff1b(3) \u51c6\u786e\u6027-\u6210\u672c-\u5ef6\u8fdf\u6743\u8861\u662f\u4efb\u52a1\u4f9d\u8d56\u7684\uff0c\u5f02\u6784\u7ba1\u9053\u901a\u5e38\u6700\u6709\u6548\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u3001\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bbe\u8ba1\u3001\u8ffd\u8e2a\u548c\u8c03\u8bd5\u53ef\u9760\u3001\u53ef\u9884\u6d4b\u548c\u53ef\u95ee\u8d23\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002"}}
{"id": "2510.08270", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.08270", "abs": "https://arxiv.org/abs/2510.08270", "authors": ["Damir Nurtdinov", "Aliaksei Korshuk", "Alexei Kornaev", "Alexander Maloletov"], "title": "Evaluation of a Robust Control System in Real-World Cable-Driven Parallel Robots", "comment": null, "summary": "This study evaluates the performance of classical and modern control methods\nfor real-world Cable-Driven Parallel Robots (CDPRs), focusing on\nunderconstrained systems with limited time discretization. A comparative\nanalysis is conducted between classical PID controllers and modern\nreinforcement learning algorithms, including Deep Deterministic Policy Gradient\n(DDPG), Proximal Policy Optimization (PPO), and Trust Region Policy\nOptimization (TRPO). The results demonstrate that TRPO outperforms other\nmethods, achieving the lowest root mean square (RMS) errors across various\ntrajectories and exhibiting robustness to larger time intervals between control\nupdates. TRPO's ability to balance exploration and exploitation enables stable\ncontrol in noisy, real-world environments, reducing reliance on high-frequency\nsensor feedback and computational demands. These findings highlight TRPO's\npotential as a robust solution for complex robotic control tasks, with\nimplications for dynamic environments and future applications in sensor fusion\nor hybrid control strategies.", "AI": {"tldr": "\u6bd4\u8f83\u7ecf\u5178PID\u63a7\u5236\u5668\u4e0e\u73b0\u4ee3\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u7535\u7f06\u9a71\u52a8\u5e76\u8054\u673a\u5668\u4eba\u63a7\u5236\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0TRPO\u5728\u591a\u79cd\u8f68\u8ff9\u4e0b\u8868\u73b0\u6700\u4f73\uff0c\u5177\u6709\u6700\u4f4e\u7684RMS\u8bef\u5dee\u548c\u5bf9\u66f4\u5927\u65f6\u95f4\u95f4\u9694\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u8bc4\u4f30\u7ecf\u5178\u548c\u73b0\u4ee3\u63a7\u5236\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u7535\u7f06\u9a71\u52a8\u5e76\u8054\u673a\u5668\u4eba\u4e2d\u7684\u6027\u80fd\uff0c\u7279\u522b\u5173\u6ce8\u6b20\u7ea6\u675f\u7cfb\u7edf\u548c\u6709\u9650\u65f6\u95f4\u79bb\u6563\u5316\u7684\u60c5\u51b5\u3002", "method": "\u5bf9\u7ecf\u5178PID\u63a7\u5236\u5668\u548c\u73b0\u4ee3\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff08\u5305\u62ecDDPG\u3001PPO\u548cTRPO\uff09\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "TRPO\u5728\u6240\u6709\u65b9\u6cd5\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u5728\u5404\u79cd\u8f68\u8ff9\u4e0b\u5b9e\u73b0\u6700\u4f4e\u7684RMS\u8bef\u5dee\uff0c\u5e76\u5bf9\u66f4\u5927\u7684\u63a7\u5236\u66f4\u65b0\u65f6\u95f4\u95f4\u9694\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u3002", "conclusion": "TRPO\u5728\u590d\u6742\u673a\u5668\u4eba\u63a7\u5236\u4efb\u52a1\u4e2d\u5177\u6709\u4f5c\u4e3a\u9c81\u68d2\u89e3\u51b3\u65b9\u6848\u7684\u6f5c\u529b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u52a8\u6001\u73af\u5883\u548c\u672a\u6765\u5728\u4f20\u611f\u5668\u878d\u5408\u6216\u6df7\u5408\u63a7\u5236\u7b56\u7565\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2510.07623", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07623", "abs": "https://arxiv.org/abs/2510.07623", "authors": ["Hannah R. Lawrence", "Shannon Wiltsey Stirman", "Samuel Dorison", "Taedong Yun", "Megan Jones Bell"], "title": "A Case for Leveraging Generative AI to Expand and Enhance Training in the Provision of Mental Health Services", "comment": null, "summary": "Generative artificial intelligence (Generative AI) is transforming\nhealthcare. With this evolution comes optimism regarding the impact it will\nhave on mental health, as well as concern regarding the risks that come with\ngenerative AI operating in the mental health domain. Much of the investment in,\nand academic and public discourse about, AI-powered solutions for mental health\nhas focused on therapist chatbots. Despite the common assumption that chatbots\nwill be the most impactful application of GenAI to mental health, we make the\ncase here for a lower-risk, high impact use case: leveraging generative AI to\nenhance and scale training in mental health service provision. We highlight key\nbenefits of using generative AI to help train people to provide mental health\nservices and present a real-world case study in which generative AI improved\nthe training of veterans to support one another's mental health. With numerous\npotential applications of generative AI in mental health, we illustrate why we\nshould invest in using generative AI to support training people in mental\nhealth service provision.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u5c06\u751f\u6210\u5f0fAI\u5e94\u7528\u4e8e\u5fc3\u7406\u5065\u5eb7\u670d\u52a1\u57f9\u8bad\uff0c\u800c\u975e\u76f4\u63a5\u4f5c\u4e3a\u6cbb\u7597\u804a\u5929\u673a\u5668\u4eba\uff0c\u8ba4\u4e3a\u8fd9\u662f\u66f4\u4f4e\u98ce\u9669\u3001\u9ad8\u5f71\u54cd\u529b\u7684\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u5f53\u524d\u5bf9AI\u5728\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u7684\u6295\u8d44\u548c\u8ba8\u8bba\u8fc7\u5ea6\u5173\u6ce8\u6cbb\u7597\u804a\u5929\u673a\u5668\u4eba\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u5b58\u5728\u98ce\u9669\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u5b89\u5168\u6709\u6548\u7684\u5e94\u7528\u65b9\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4f7f\u7528\u751f\u6210\u5f0fAI\u589e\u5f3a\u548c\u6269\u5927\u5fc3\u7406\u5065\u5eb7\u670d\u52a1\u57f9\u8bad\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u4e00\u4e2a\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5982\u4f55\u7528\u751f\u6210\u5f0fAI\u6539\u8fdb\u9000\u4f0d\u519b\u4eba\u7684\u540c\u4f34\u652f\u6301\u57f9\u8bad\u3002", "result": "\u751f\u6210\u5f0fAI\u6210\u529f\u6539\u5584\u4e86\u9000\u4f0d\u519b\u4eba\u76f8\u4e92\u652f\u6301\u5fc3\u7406\u5065\u5eb7\u7684\u57f9\u8bad\u6548\u679c\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u57f9\u8bad\u9886\u57df\u7684\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u5e94\u8be5\u6295\u8d44\u4e8e\u4f7f\u7528\u751f\u6210\u5f0fAI\u6765\u652f\u6301\u5fc3\u7406\u5065\u5eb7\u670d\u52a1\u63d0\u4f9b\u8005\u7684\u57f9\u8bad\uff0c\u8fd9\u662f\u6bd4\u76f4\u63a5\u4f5c\u4e3a\u6cbb\u7597\u5de5\u5177\u66f4\u5b89\u5168\u3001\u66f4\u5177\u5f71\u54cd\u529b\u7684\u5e94\u7528\u65b9\u5411\u3002"}}
{"id": "2510.08381", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08381", "abs": "https://arxiv.org/abs/2510.08381", "authors": ["Baoyang Chen", "Xian Xu", "Huamin Qu"], "title": "Airy: Reading Robot Intent through Height and Sky", "comment": null, "summary": "As industrial robots move into shared human spaces, their opaque decision\nmaking threatens safety, trust, and public oversight. This artwork, Airy, asks\nwhether complex multi agent AI can become intuitively understandable by staging\na competition between two reinforcement trained robot arms that snap a bedsheet\nskyward. Building on three design principles, competition as a clear metric\n(who lifts higher), embodied familiarity (audiences recognize fabric snapping),\nand sensor to sense mapping (robot cooperation or rivalry shown through forest\nand weather projections), the installation gives viewers a visceral way to read\nmachine intent. Observations from five international exhibitions indicate that\naudiences consistently read the robots' strategies, conflict, and cooperation\nin real time, with emotional reactions that mirror the system's internal state.\nThe project shows how sensory metaphors can turn a black box into a public\ninterface.", "AI": {"tldr": "Airy\u662f\u4e00\u4e2a\u827a\u672f\u88c5\u7f6e\uff0c\u901a\u8fc7\u4e24\u4e2a\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u673a\u68b0\u81c2\u7ade\u4e89\u6296\u5e8a\u5355\u6765\u5c55\u793a\u590d\u6742\u591a\u667a\u80fd\u4f53AI\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u7ade\u4e89\u3001\u5177\u8eab\u719f\u6089\u6027\u548c\u4f20\u611f\u5668\u5230\u611f\u77e5\u6620\u5c04\u4e09\u4e2a\u8bbe\u8ba1\u539f\u5219\uff0c\u8ba9\u89c2\u4f17\u76f4\u89c2\u7406\u89e3\u673a\u5668\u610f\u56fe\u3002", "motivation": "\u968f\u7740\u5de5\u4e1a\u673a\u5668\u4eba\u8fdb\u5165\u5171\u4eab\u4eba\u7c7b\u7a7a\u95f4\uff0c\u5176\u4e0d\u900f\u660e\u7684\u51b3\u7b56\u8fc7\u7a0b\u5a01\u80c1\u7740\u5b89\u5168\u6027\u3001\u4fe1\u4efb\u548c\u516c\u5171\u76d1\u7763\u3002\u8be5\u4f5c\u54c1\u65e8\u5728\u63a2\u7d22\u590d\u6742\u591a\u667a\u80fd\u4f53AI\u662f\u5426\u80fd\u53d8\u5f97\u76f4\u89c2\u6613\u61c2\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u8bbe\u8ba1\u539f\u5219\uff1a\u7ade\u4e89\u4f5c\u4e3a\u6e05\u6670\u6307\u6807\uff08\u8c01\u6296\u5f97\u66f4\u9ad8\uff09\u3001\u5177\u8eab\u719f\u6089\u6027\uff08\u89c2\u4f17\u719f\u6089\u6296\u5e8a\u5355\u52a8\u4f5c\uff09\u3001\u4f20\u611f\u5668\u5230\u611f\u77e5\u6620\u5c04\uff08\u901a\u8fc7\u68ee\u6797\u548c\u5929\u6c14\u6295\u5f71\u663e\u793a\u673a\u5668\u4eba\u5408\u4f5c\u6216\u7ade\u4e89\u5173\u7cfb\uff09\u3002", "result": "\u5728\u4e94\u4e2a\u56fd\u9645\u5c55\u89c8\u4e2d\u7684\u89c2\u5bdf\u8868\u660e\uff0c\u89c2\u4f17\u80fd\u591f\u5b9e\u65f6\u89e3\u8bfb\u673a\u5668\u4eba\u7684\u7b56\u7565\u3001\u51b2\u7a81\u548c\u5408\u4f5c\uff0c\u60c5\u611f\u53cd\u5e94\u4e0e\u7cfb\u7edf\u5185\u90e8\u72b6\u6001\u4e00\u81f4\u3002", "conclusion": "\u8be5\u9879\u76ee\u5c55\u793a\u4e86\u611f\u5b98\u9690\u55bb\u5982\u4f55\u5c06\u9ed1\u76d2\u7cfb\u7edf\u8f6c\u53d8\u4e3a\u516c\u5171\u754c\u9762\uff0c\u4f7f\u590d\u6742AI\u51b3\u7b56\u53d8\u5f97\u53ef\u7406\u89e3\u3002"}}
{"id": "2510.07632", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.07632", "abs": "https://arxiv.org/abs/2510.07632", "authors": ["Yinglun Zhu", "Jiancheng Zhang", "Fuzhi Tang"], "title": "Test-Time Matching: Unlocking Compositional Reasoning in Multimodal Models", "comment": null, "summary": "Frontier AI models have achieved remarkable progress, yet recent studies\nsuggest they struggle with compositional reasoning, often performing at or\nbelow random chance on established benchmarks. We revisit this problem and show\nthat widely used evaluation metrics systematically underestimate model\ncapability. To address this, we introduce a group matching score that better\nexploits group structure and reveals substantial hidden capability in both\ncontrastive vision-language models (VLMs) and multimodal large language models\n(MLLMs). Moreover, simply overfitting to the induced group matchings at test\ntime transfers this hidden capability into higher scores under standard\nevaluation metrics, closing much of the reported gap. This adjustment enables\nSigLIP-B16 to surpass all previous results and GPT-4.1 to yield the first\nresult surpassing estimated human performance on Winoground.\n  Building on this insight, we propose Test-Time Matching (TTM), an iterative,\nself-improving algorithm that further bootstraps model performance without any\nexternal supervision. TTM delivers additional, non-trivial improvements: for\nexample, TTM enables SigLIP-B16 to surpass GPT-4.1 on MMVP-VLM, establishing a\nnew state of the art. Importantly, TTM remains broadly effective even on\nbenchmarks without metric-induced effects or group structures, achieving\nrelative gains up to 85.7% on challenging datasets such as WhatsUp. Across 16\ndataset variants spanning diverse setups, our experiments demonstrate that TTM\nconsistently improves model performance and advances the frontier of\ncompositional reasoning.", "AI": {"tldr": "\u8bba\u6587\u53d1\u73b0\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u4f4e\u4f30\u4e86AI\u6a21\u578b\u7684\u7ec4\u5408\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u7ec4\u5339\u914d\u5206\u6570\u548c\u6d4b\u8bd5\u65f6\u5339\u914d\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u65b0SOTA\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u7cfb\u7edf\u6027\u4f4e\u4f30\u4e86\u524d\u6cbfAI\u6a21\u578b\u7684\u7ec4\u5408\u63a8\u7406\u80fd\u529b\uff0c\u5bfc\u81f4\u6a21\u578b\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u66f4\u51c6\u786e\u7684\u8bc4\u4f30\u65b9\u6cd5\u548c\u6027\u80fd\u63d0\u5347\u6280\u672f\u3002", "method": "\u5f15\u5165\u7ec4\u5339\u914d\u5206\u6570\u6765\u5229\u7528\u7ec4\u7ed3\u6784\u63ed\u793a\u9690\u85cf\u80fd\u529b\uff0c\u63d0\u51fa\u6d4b\u8bd5\u65f6\u5339\u914d(TTM)\u7b97\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u65e0\u9700\u5916\u90e8\u76d1\u7763\u7684\u8fed\u4ee3\u81ea\u6539\u8fdb\u65b9\u6cd5\u3002", "result": "SigLIP-B16\u8d85\u8d8aGPT-4.1\uff0c\u5728Winoground\u4e0a\u9996\u6b21\u8d85\u8d8a\u4f30\u8ba1\u7684\u4eba\u7c7b\u6027\u80fd\uff0c\u572816\u4e2a\u6570\u636e\u96c6\u53d8\u4f53\u4e0a\u5b9e\u73b0\u4e00\u81f4\u6539\u8fdb\uff0c\u76f8\u5bf9\u589e\u76ca\u9ad8\u8fbe85.7%\u3002", "conclusion": "\u901a\u8fc7\u6539\u8fdb\u8bc4\u4f30\u65b9\u6cd5\u548c\u6d4b\u8bd5\u65f6\u5339\u914d\u7b97\u6cd5\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347AI\u6a21\u578b\u7684\u7ec4\u5408\u63a8\u7406\u80fd\u529b\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u7684\u524d\u6cbf\u53d1\u5c55\u3002"}}
{"id": "2510.07635", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07635", "abs": "https://arxiv.org/abs/2510.07635", "authors": ["Haruka Kiyohara", "Yusuke Narita", "Yuta Saito", "Kei Tateno", "Takuma Udagawa"], "title": "Safely Exploring Novel Actions in Recommender Systems via Deployment-Efficient Policy Learning", "comment": null, "summary": "In many real recommender systems, novel items are added frequently over time.\nThe importance of sufficiently presenting novel actions has widely been\nacknowledged for improving long-term user engagement. A recent work builds on\nOff-Policy Learning (OPL), which trains a policy from only logged data,\nhowever, the existing methods can be unsafe in the presence of novel actions.\nOur goal is to develop a framework to enforce exploration of novel actions with\na guarantee for safety. To this end, we first develop Safe Off-Policy Policy\nGradient (Safe OPG), which is a model-free safe OPL method based on a high\nconfidence off-policy evaluation. In our first experiment, we observe that Safe\nOPG almost always satisfies a safety requirement, even when existing methods\nviolate it greatly. However, the result also reveals that Safe OPG tends to be\ntoo conservative, suggesting a difficult tradeoff between guaranteeing safety\nand exploring novel actions. To overcome this tradeoff, we also propose a novel\nframework called Deployment-Efficient Policy Learning for Safe User\nExploration, which leverages safety margin and gradually relaxes safety\nregularization during multiple (not many) deployments. Our framework thus\nenables exploration of novel actions while guaranteeing safe implementation of\nrecommender systems.", "AI": {"tldr": "\u63d0\u51faSafe OPG\u65b9\u6cd5\u4fdd\u8bc1\u63a8\u8350\u7cfb\u7edf\u5728\u63a2\u7d22\u65b0\u7269\u54c1\u65f6\u7684\u5b89\u5168\u6027\uff0c\u5e76\u8fdb\u4e00\u6b65\u5f00\u53d1DEPL\u6846\u67b6\u5e73\u8861\u5b89\u5168\u6027\u4e0e\u63a2\u7d22\u6027", "motivation": "\u73b0\u5b9e\u63a8\u8350\u7cfb\u7edf\u4e2d\u65b0\u7269\u54c1\u9891\u7e41\u6dfb\u52a0\uff0c\u73b0\u6709\u79bb\u7ebf\u7b56\u7565\u5b66\u4e60\u65b9\u6cd5\u5728\u65b0\u7269\u54c1\u5b58\u5728\u65f6\u4e0d\u591f\u5b89\u5168\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u63a2\u7d22\u6846\u67b6", "method": "\u9996\u5148\u5f00\u53d1\u57fa\u4e8e\u9ad8\u7f6e\u4fe1\u5ea6\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\u7684Safe OPG\u65b9\u6cd5\uff0c\u7136\u540e\u63d0\u51faDEPL\u6846\u67b6\uff0c\u5229\u7528\u5b89\u5168\u8fb9\u9645\u5e76\u5728\u591a\u6b21\u90e8\u7f72\u4e2d\u9010\u6b65\u653e\u677e\u5b89\u5168\u6b63\u5219\u5316", "result": "Safe OPG\u51e0\u4e4e\u603b\u80fd\u6ee1\u8db3\u5b89\u5168\u8981\u6c42\uff0c\u4f46\u8fc7\u4e8e\u4fdd\u5b88\uff1bDEPL\u6846\u67b6\u80fd\u5728\u4fdd\u8bc1\u63a8\u8350\u7cfb\u7edf\u5b89\u5168\u5b9e\u73b0\u7684\u540c\u65f6\u63a2\u7d22\u65b0\u7269\u54c1", "conclusion": "\u63d0\u51fa\u7684DEPL\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5b89\u5168\u4fdd\u8bc1\u4e0e\u63a2\u7d22\u65b0\u7269\u54c1\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898"}}
{"id": "2510.08408", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.08408", "abs": "https://arxiv.org/abs/2510.08408", "authors": ["Bibekananda Patra", "Rajeevlochana G. Chittawadigi", "Sandipan Bandyopadhyay"], "title": "Validation of collision-free spheres of Stewart-Gough platforms for constant orientations using the Application Programming Interface of a CAD software", "comment": null, "summary": "This paper presents a method of validation of the size of the largest\ncollision-free sphere (CFS) of a 6-6 Stewart-Gough platform manipulator (SGPM)\nfor a given orientation of its moving platform (MP) using the Application\nProgramming Interface (API) of a CAD software. The position of the MP is\nupdated via the API in an automated manner over a set of samples within a shell\nenclosing the surface of the CFS. For each pose of the manipulator, each pair\nof legs is investigated for mutual collisions. The CFS is considered safe or\nvalidated iff none of the points falling inside the CFS lead to a collision\nbetween any pair of legs. This approach can not only validate the safety of a\nprecomputed CFS, but also estimate the same for any spatial parallel\nmanipulator.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528CAD\u8f6f\u4ef6API\u9a8c\u8bc16-6 Stewart-Gough\u5e73\u53f0\u673a\u68b0\u81c2\u6700\u5927\u65e0\u78b0\u649e\u7403\u4f53\u5c3a\u5bf8\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u66f4\u65b0\u5e73\u53f0\u4f4d\u7f6e\u5e76\u68c0\u6d4b\u817f\u90e8\u78b0\u649e\u6765\u9a8c\u8bc1CFS\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u9700\u8981\u9a8c\u8bc1\u5e76\u8054\u673a\u68b0\u81c2\u5728\u7ed9\u5b9a\u5e73\u53f0\u65b9\u5411\u4e0b\u7684\u6700\u5927\u65e0\u78b0\u649e\u7403\u4f53\u5c3a\u5bf8\uff0c\u786e\u4fdd\u673a\u68b0\u81c2\u5728\u5de5\u4f5c\u7a7a\u95f4\u5185\u7684\u5b89\u5168\u64cd\u4f5c\u3002", "method": "\u5229\u7528CAD\u8f6f\u4ef6API\u81ea\u52a8\u66f4\u65b0\u79fb\u52a8\u5e73\u53f0\u4f4d\u7f6e\uff0c\u5728CFS\u8868\u9762\u7684\u5305\u56f4\u58f3\u5185\u91c7\u6837\uff0c\u68c0\u6d4b\u6bcf\u5bf9\u817f\u90e8\u4e4b\u95f4\u7684\u76f8\u4e92\u78b0\u649e\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u9a8c\u8bc1\u9884\u8ba1\u7b97\u7684CFS\u5b89\u5168\u6027\uff0c\u5e76\u53ef\u4f30\u8ba1\u4efb\u4f55\u7a7a\u95f4\u5e76\u8054\u673a\u68b0\u81c2\u7684\u65e0\u78b0\u649e\u7403\u4f53\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eCAD API\u7684\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u4e14\u901a\u7528\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u5e76\u8054\u673a\u68b0\u81c2\u7684\u65e0\u78b0\u649e\u5de5\u4f5c\u7a7a\u95f4\u5206\u6790\u3002"}}
{"id": "2510.08464", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08464", "abs": "https://arxiv.org/abs/2510.08464", "authors": ["Jason Jabbour", "Dong-Ki Kim", "Max Smith", "Jay Patrikar", "Radhika Ghosal", "Youhui Wang", "Ali Agha", "Vijay Janapa Reddi", "Shayegan Omidshafiei"], "title": "Don't Run with Scissors: Pruning Breaks VLA Models but They Can Be Recovered", "comment": null, "summary": "Vision-Language-Action (VLA) models have advanced robotic capabilities but\nremain challenging to deploy on resource-limited hardware. Pruning has enabled\nefficient compression of large language models (LLMs), yet it is largely\nunderstudied in robotics. Surprisingly, we observe that pruning VLA models\nleads to drastic degradation and increased safety violations. We introduce\nGLUESTICK, a post-pruning recovery method that restores much of the original\nmodel's functionality while retaining sparsity benefits. Our method performs a\none-time interpolation between the dense and pruned models in weight-space to\ncompute a corrective term. This correction is used during inference by each\npruned layer to recover lost capabilities with minimal overhead. GLUESTICK\nrequires no additional training, is agnostic to the pruning algorithm, and\nintroduces a single hyperparameter that controls the tradeoff between\nefficiency and accuracy. Across diverse VLA architectures and tasks in\nmanipulation and navigation, GLUESTICK achieves competitive memory efficiency\nwhile substantially recovering success rates and reducing safety violations.\nAdditional material can be found at: https://gluestick-vla.github.io/.", "AI": {"tldr": "GLUESTICK\u662f\u4e00\u79cd\u540e\u526a\u679d\u6062\u590d\u65b9\u6cd5\uff0c\u901a\u8fc7\u6743\u91cd\u7a7a\u95f4\u63d2\u503c\u5728\u7a00\u758f\u6a21\u578b\u4e2d\u6062\u590d\u529f\u80fd\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u663e\u8457\u63d0\u5347\u526a\u679d\u540eVLA\u6a21\u578b\u7684\u6027\u80fd\u5e76\u51cf\u5c11\u5b89\u5168\u8fdd\u89c4\u3002", "motivation": "VLA\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u786c\u4ef6\u4e0a\u90e8\u7f72\u56f0\u96be\uff0c\u526a\u679d\u867d\u7136\u80fd\u538b\u7f29\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u5728\u673a\u5668\u4eba\u9886\u57df\u7814\u7a76\u4e0d\u8db3\uff0c\u4e14\u4f1a\u5bfc\u81f4\u6027\u80fd\u6025\u5267\u4e0b\u964d\u548c\u5b89\u5168\u8fdd\u89c4\u589e\u52a0\u3002", "method": "\u5728\u6743\u91cd\u7a7a\u95f4\u5bf9\u5bc6\u96c6\u6a21\u578b\u548c\u526a\u679d\u6a21\u578b\u8fdb\u884c\u4e00\u6b21\u6027\u63d2\u503c\u8ba1\u7b97\u4fee\u6b63\u9879\uff0c\u63a8\u7406\u65f6\u6bcf\u4e2a\u526a\u679d\u5c42\u4f7f\u7528\u8be5\u4fee\u6b63\u9879\u6062\u590d\u4e22\u5931\u7684\u529f\u80fd\uff0c\u4ec5\u5f15\u5165\u4e00\u4e2a\u63a7\u5236\u6548\u7387\u4e0e\u7cbe\u5ea6\u6743\u8861\u7684\u8d85\u53c2\u6570\u3002", "result": "\u5728\u591a\u79cdVLA\u67b6\u6784\u548c\u64cd\u4f5c\u5bfc\u822a\u4efb\u52a1\u4e2d\uff0cGLUESTICK\u5728\u4fdd\u6301\u7ade\u4e89\u6027\u5185\u5b58\u6548\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u6062\u590d\u6210\u529f\u7387\u5e76\u51cf\u5c11\u5b89\u5168\u8fdd\u89c4\u3002", "conclusion": "GLUESTICK\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u4e0e\u526a\u679d\u7b97\u6cd5\u65e0\u5173\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u53ef\u5728\u4fdd\u6301\u7a00\u758f\u6027\u4f18\u52bf\u7684\u540c\u65f6\u6062\u590d\u526a\u679dVLA\u6a21\u578b\u7684\u529f\u80fd\u3002"}}
{"id": "2510.07715", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07715", "abs": "https://arxiv.org/abs/2510.07715", "authors": ["Xiaochen Tang", "Zhenya Zhang", "Miaomiao Zhang", "Jie An"], "title": "Control Synthesis of Cyber-Physical Systems for Real-Time Specifications through Causation-Guided Reinforcement Learning", "comment": "14 pages, 4 figures, 6 tables, accepted by RTSS 2025", "summary": "In real-time and safety-critical cyber-physical systems (CPSs), control\nsynthesis must guarantee that generated policies meet stringent timing and\ncorrectness requirements under uncertain and dynamic conditions. Signal\ntemporal logic (STL) has emerged as a powerful formalism of expressing\nreal-time constraints, with its semantics enabling quantitative assessment of\nsystem behavior. Meanwhile, reinforcement learning (RL) has become an important\nmethod for solving control synthesis problems in unknown environments. Recent\nstudies incorporate STL-based reward functions into RL to automatically\nsynthesize control policies. However, the automatically inferred rewards\nobtained by these methods represent the global assessment of a whole or partial\npath but do not accumulate the rewards of local changes accurately, so the\nsparse global rewards may lead to non-convergence and unstable training\nperformances. In this paper, we propose an online reward generation method\nguided by the online causation monitoring of STL. Our approach continuously\nmonitors system behavior against an STL specification at each control step,\ncomputing the quantitative distance toward satisfaction or violation and\nthereby producing rewards that reflect instantaneous state dynamics.\nAdditionally, we provide a smooth approximation of the causation semantics to\novercome the discontinuity of the causation semantics and make it\ndifferentiable for using deep-RL methods. We have implemented a prototype tool\nand evaluated it in the Gym environment on a variety of continuously controlled\nbenchmarks. Experimental results show that our proposed STL-guided RL method\nwith online causation semantics outperforms existing relevant STL-guided RL\nmethods, providing a more robust and efficient reward generation framework for\ndeep-RL.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eSTL\u5728\u7ebf\u56e0\u679c\u76d1\u6d4b\u7684\u5956\u52b1\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u6301\u7eed\u76d1\u63a7\u7cfb\u7edf\u884c\u4e3a\u4e0eSTL\u89c4\u8303\u7684\u7b26\u5408\u7a0b\u5ea6\uff0c\u8ba1\u7b97\u6ee1\u8db3\u6216\u8fdd\u53cd\u7684\u5b9a\u91cf\u8ddd\u79bb\uff0c\u4ece\u800c\u4ea7\u751f\u53cd\u6620\u77ac\u65f6\u72b6\u6001\u52a8\u6001\u7684\u5956\u52b1\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06STL\u5956\u52b1\u51fd\u6570\u7eb3\u5165RL\u4e2d\u81ea\u52a8\u5408\u6210\u63a7\u5236\u7b56\u7565\uff0c\u4f46\u81ea\u52a8\u63a8\u65ad\u7684\u5956\u52b1\u4ee3\u8868\u6574\u4e2a\u6216\u90e8\u5206\u8def\u5f84\u7684\u5168\u5c40\u8bc4\u4f30\uff0c\u65e0\u6cd5\u51c6\u786e\u7d2f\u79ef\u5c40\u90e8\u53d8\u5316\u7684\u5956\u52b1\uff0c\u7a00\u758f\u7684\u5168\u5c40\u5956\u52b1\u53ef\u80fd\u5bfc\u81f4\u4e0d\u6536\u655b\u548c\u4e0d\u7a33\u5b9a\u7684\u8bad\u7ec3\u6027\u80fd\u3002", "method": "\u91c7\u7528\u5728\u7ebf\u56e0\u679c\u76d1\u6d4bSTL\u7684\u65b9\u6cd5\uff0c\u5728\u6bcf\u4e2a\u63a7\u5236\u6b65\u9aa4\u6301\u7eed\u76d1\u63a7\u7cfb\u7edf\u884c\u4e3a\u4e0eSTL\u89c4\u8303\u7684\u7b26\u5408\u7a0b\u5ea6\uff0c\u8ba1\u7b97\u6ee1\u8db3\u6216\u8fdd\u53cd\u7684\u5b9a\u91cf\u8ddd\u79bb\uff0c\u5e76\u63d0\u4f9b\u56e0\u679c\u8bed\u4e49\u7684\u5e73\u6ed1\u8fd1\u4f3c\u4ee5\u514b\u670d\u5176\u4e0d\u8fde\u7eed\u6027\uff0c\u4f7f\u5176\u53ef\u7528\u4e8e\u6df1\u5ea6RL\u65b9\u6cd5\u3002", "result": "\u5728Gym\u73af\u5883\u4e2d\u7684\u5404\u79cd\u8fde\u7eed\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u7684\u76f8\u5173STL\u5f15\u5bfcRL\u65b9\u6cd5\uff0c\u4e3a\u6df1\u5ea6RL\u63d0\u4f9b\u4e86\u66f4\u7a33\u5065\u548c\u9ad8\u6548\u7684\u5956\u52b1\u751f\u6210\u6846\u67b6\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eSTL\u5728\u7ebf\u56e0\u679c\u8bed\u4e49\u7684RL\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u66f4\u7cbe\u786e\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u6539\u5584\u8bad\u7ec3\u6536\u655b\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u5728\u5b9e\u65f6\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u5177\u6709\u826f\u597d\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.08475", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08475", "abs": "https://arxiv.org/abs/2510.08475", "authors": ["Jhen Hsieh", "Kuan-Hsun Tu", "Kuo-Han Hung", "Tsung-Wei Ke"], "title": "DexMan: Learning Bimanual Dexterous Manipulation from Human and Generated Videos", "comment": "Video results are available at:\n  https://embodiedai-ntu.github.io/dexman/index.html", "summary": "We present DexMan, an automated framework that converts human visual\ndemonstrations into bimanual dexterous manipulation skills for humanoid robots\nin simulation. Operating directly on third-person videos of humans manipulating\nrigid objects, DexMan eliminates the need for camera calibration, depth\nsensors, scanned 3D object assets, or ground-truth hand and object motion\nannotations. Unlike prior approaches that consider only simplified floating\nhands, it directly controls a humanoid robot and leverages novel contact-based\nrewards to improve policy learning from noisy hand-object poses estimated from\nin-the-wild videos.\n  DexMan achieves state-of-the-art performance in object pose estimation on the\nTACO benchmark, with absolute gains of 0.08 and 0.12 in ADD-S and VSD.\nMeanwhile, its reinforcement learning policy surpasses previous methods by 19%\nin success rate on OakInk-v2. Furthermore, DexMan can generate skills from both\nreal and synthetic videos, without the need for manual data collection and\ncostly motion capture, and enabling the creation of large-scale, diverse\ndatasets for training generalist dexterous manipulation.", "AI": {"tldr": "DexMan\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u53ef\u5c06\u4eba\u7c7b\u89c6\u89c9\u6f14\u793a\u8f6c\u6362\u4e3a\u4eff\u4eba\u673a\u5668\u4eba\u7684\u53cc\u624b\u7075\u5de7\u64cd\u4f5c\u6280\u80fd\uff0c\u65e0\u9700\u76f8\u673a\u6821\u51c6\u3001\u6df1\u5ea6\u4f20\u611f\u5668\u30013D\u5bf9\u8c61\u626b\u63cf\u6216\u771f\u5b9e\u624b\u90e8\u7269\u4f53\u8fd0\u52a8\u6807\u6ce8\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4ec5\u8003\u8651\u7b80\u5316\u6d6e\u52a8\u624b\u90e8\u7684\u95ee\u9898\uff0c\u76f4\u63a5\u63a7\u5236\u4eff\u4eba\u673a\u5668\u4eba\uff0c\u5229\u7528\u57fa\u4e8e\u63a5\u89e6\u7684\u5956\u52b1\u4ece\u91ce\u5916\u89c6\u9891\u4e2d\u5b66\u4e60\u7b56\u7565\u3002", "method": "\u57fa\u4e8e\u7b2c\u4e09\u4eba\u79f0\u4eba\u7c7b\u64cd\u4f5c\u89c6\u9891\uff0c\u4f7f\u7528\u63a5\u89e6\u5956\u52b1\u6539\u8fdb\u7b56\u7565\u5b66\u4e60\uff0c\u65e0\u9700\u624b\u52a8\u6570\u636e\u6536\u96c6\u548c\u6602\u8d35\u7684\u52a8\u4f5c\u6355\u6349\u3002", "result": "\u5728TACO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7269\u4f53\u59ff\u6001\u4f30\u8ba1\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0cADD-S\u548cVSD\u5206\u522b\u63d0\u53470.08\u548c0.12\uff1b\u5728OakInk-v2\u4e0a\u6210\u529f\u7387\u6bd4\u5148\u524d\u65b9\u6cd5\u63d0\u9ad819%\u3002", "conclusion": "DexMan\u80fd\u4ece\u771f\u5b9e\u548c\u5408\u6210\u89c6\u9891\u751f\u6210\u6280\u80fd\uff0c\u65e0\u9700\u624b\u52a8\u6570\u636e\u6536\u96c6\uff0c\u4e3a\u8bad\u7ec3\u901a\u7528\u7075\u5de7\u64cd\u4f5c\u521b\u5efa\u5927\u89c4\u6a21\u591a\u6837\u5316\u6570\u636e\u96c6\u3002"}}
{"id": "2510.07731", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.07731", "abs": "https://arxiv.org/abs/2510.07731", "authors": ["Ruiling Xu", "Yifan Zhang", "Qingyun Wang", "Carl Edwards", "Heng Ji"], "title": "oMeBench: Towards Robust Benchmarking of LLMs in Organic Mechanism Elucidation and Reasoning", "comment": "Main Text: 8 pages, In total: 37 pages, 9 figures", "summary": "Organic reaction mechanisms are the stepwise elementary reactions by which\nreactants form intermediates and products, and are fundamental to understanding\nchemical reactivity and designing new molecules and reactions. Although large\nlanguage models (LLMs) have shown promise in understanding chemical tasks such\nas synthesis design, it is unclear to what extent this reflects genuine\nchemical reasoning capabilities, i.e., the ability to generate valid\nintermediates, maintain chemical consistency, and follow logically coherent\nmulti-step pathways. We address this by introducing oMeBench, the first\nlarge-scale, expert-curated benchmark for organic mechanism reasoning in\norganic chemistry. It comprises over 10,000 annotated mechanistic steps with\nintermediates, type labels, and difficulty ratings. Furthermore, to evaluate\nLLM capability more precisely and enable fine-grained scoring, we propose oMeS,\na dynamic evaluation framework that combines step-level logic and chemical\nsimilarity. We analyze the performance of state-of-the-art LLMs, and our\nresults show that although current models display promising chemical intuition,\nthey struggle with correct and consistent multi-step reasoning. Notably, we\nfind that using prompting strategy and fine-tuning a specialist model on our\nproposed dataset increases performance by 50% over the leading closed-source\nmodel. We hope that oMeBench will serve as a rigorous foundation for advancing\nAI systems toward genuine chemical reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86oMeBench\uff0c\u9996\u4e2a\u5927\u89c4\u6a21\u3001\u4e13\u5bb6\u7b56\u5212\u7684\u6709\u673a\u5316\u5b66\u53cd\u5e94\u673a\u7406\u63a8\u7406\u57fa\u51c6\uff0c\u5305\u542b10,000\u591a\u4e2a\u5e26\u6ce8\u91ca\u7684\u673a\u7406\u6b65\u9aa4\uff0c\u5e76\u5f00\u53d1\u4e86oMeS\u52a8\u6001\u8bc4\u4f30\u6846\u67b6\u6765\u7cbe\u786e\u8bc4\u4f30LLM\u7684\u5316\u5b66\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5316\u5b66\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u5176\u662f\u5426\u771f\u6b63\u5177\u5907\u5316\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5373\u751f\u6210\u6709\u6548\u4e2d\u95f4\u4f53\u3001\u4fdd\u6301\u5316\u5b66\u4e00\u81f4\u6027\u548c\u9075\u5faa\u903b\u8f91\u8fde\u8d2f\u7684\u591a\u6b65\u9aa4\u8def\u5f84\u7684\u80fd\u529b\u3002", "method": "\u6784\u5efaoMeBench\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b\u673a\u7406\u6b65\u9aa4\u3001\u4e2d\u95f4\u4f53\u3001\u7c7b\u578b\u6807\u7b7e\u548c\u96be\u5ea6\u8bc4\u7ea7\uff1b\u63d0\u51faoMeS\u52a8\u6001\u8bc4\u4f30\u6846\u67b6\uff0c\u7ed3\u5408\u6b65\u9aa4\u7ea7\u903b\u8f91\u548c\u5316\u5b66\u76f8\u4f3c\u6027\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bc4\u5206\uff1b\u5206\u6790\u6700\u5148\u8fdbLLM\u7684\u6027\u80fd\u3002", "result": "\u5f53\u524d\u6a21\u578b\u663e\u793a\u51fa\u6709\u524d\u666f\u7684\u5316\u5b66\u76f4\u89c9\uff0c\u4f46\u5728\u6b63\u786e\u548c\u4e00\u81f4\u7684\u591a\u6b65\u9aa4\u63a8\u7406\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff1b\u4f7f\u7528\u63d0\u793a\u7b56\u7565\u548c\u5728\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u4e13\u5bb6\u6a21\u578b\uff0c\u6027\u80fd\u6bd4\u9886\u5148\u95ed\u6e90\u6a21\u578b\u63d0\u9ad850%\u3002", "conclusion": "oMeBench\u5c06\u4e3a\u63a8\u8fdbAI\u7cfb\u7edf\u5b9e\u73b0\u771f\u6b63\u7684\u5316\u5b66\u63a8\u7406\u63d0\u4f9b\u4e25\u683c\u57fa\u7840\u3002"}}
{"id": "2510.08547", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.08547", "abs": "https://arxiv.org/abs/2510.08547", "authors": ["Xiuwei Xu", "Angyuan Ma", "Hankun Li", "Bingyao Yu", "Zheng Zhu", "Jie Zhou", "Jiwen Lu"], "title": "R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation", "comment": "Project page: https://r2rgen.github.io/", "summary": "Towards the aim of generalized robotic manipulation, spatial generalization\nis the most fundamental capability that requires the policy to work robustly\nunder different spatial distribution of objects, environment and agent itself.\nTo achieve this, substantial human demonstrations need to be collected to cover\ndifferent spatial configurations for training a generalized visuomotor policy\nvia imitation learning. Prior works explore a promising direction that\nleverages data generation to acquire abundant spatially diverse data from\nminimal source demonstrations. However, most approaches face significant\nsim-to-real gap and are often limited to constrained settings, such as\nfixed-base scenarios and predefined camera viewpoints. In this paper, we\npropose a real-to-real 3D data generation framework (R2RGen) that directly\naugments the pointcloud observation-action pairs to generate real-world data.\nR2RGen is simulator- and rendering-free, thus being efficient and\nplug-and-play. Specifically, given a single source demonstration, we introduce\nan annotation mechanism for fine-grained parsing of scene and trajectory. A\ngroup-wise augmentation strategy is proposed to handle complex multi-object\ncompositions and diverse task constraints. We further present camera-aware\nprocessing to align the distribution of generated data with real-world 3D\nsensor. Empirically, R2RGen substantially enhances data efficiency on extensive\nexperiments and demonstrates strong potential for scaling and application on\nmobile manipulation.", "AI": {"tldr": "\u63d0\u51fa\u4e86R2RGen\u6846\u67b6\uff0c\u76f4\u63a5\u4ece\u771f\u5b9e\u70b9\u4e91\u89c2\u6d4b-\u52a8\u4f5c\u5bf9\u751f\u6210\u6570\u636e\uff0c\u65e0\u9700\u6a21\u62df\u5668\u548c\u6e32\u67d3\uff0c\u5b9e\u73b0\u9ad8\u6548\u5373\u63d2\u5373\u7528\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u589e\u5f3a\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u7a7a\u95f4\u6cdb\u5316\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6f14\u793a\u6570\u636e\u8986\u76d6\u4e0d\u540c\u7a7a\u95f4\u914d\u7f6e\uff0c\u73b0\u6709\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u7684\u6a21\u62df\u5230\u771f\u5b9e\u5dee\u8ddd\uff0c\u4e14\u53d7\u9650\u4e8e\u56fa\u5b9a\u57fa\u5ea7\u573a\u666f\u548c\u9884\u5b9a\u4e49\u76f8\u673a\u89c6\u89d2\u3002", "method": "\u57fa\u4e8e\u5355\u6e90\u6f14\u793a\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u573a\u666f\u548c\u8f68\u8ff9\u89e3\u6790\u3001\u5206\u7ec4\u589e\u5f3a\u7b56\u7565\u5904\u7406\u590d\u6742\u591a\u5bf9\u8c61\u7ec4\u5408\u548c\u4efb\u52a1\u7ea6\u675f\uff0c\u4ee5\u53ca\u76f8\u673a\u611f\u77e5\u5904\u7406\u5bf9\u9f50\u751f\u6210\u6570\u636e\u4e0e\u771f\u5b9e3D\u4f20\u611f\u5668\u5206\u5e03\u3002", "result": "\u5728\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u6548\u7387\uff0c\u5c55\u793a\u4e86\u5728\u79fb\u52a8\u64cd\u4f5c\u4e2d\u6269\u5c55\u548c\u5e94\u7528\u7684\u5f3a\u5927\u6f5c\u529b\u3002", "conclusion": "R2RGen\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u771f\u5b9e\u4e16\u754c\u6570\u636e\u751f\u6210\u95ee\u9898\uff0c\u4e3a\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u7a7a\u95f4\u6cdb\u5316\u63d0\u4f9b\u4e86\u9ad8\u6548\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.07733", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07733", "abs": "https://arxiv.org/abs/2510.07733", "authors": ["Minh-Anh Nguye", "Minh-Duc Nguyen", "Nguyen Thi Ha Lan", "Kieu Hai Dang", "Nguyen Tien Dong", "Le Duy Dung"], "title": "SurveyG: A Multi-Agent LLM Framework with Hierarchical Citation Graph for Automated Survey Generation", "comment": null, "summary": "Large language models (LLMs) are increasingly adopted for automating survey\npaper generation \\cite{wang2406autosurvey, liang2025surveyx,\nyan2025surveyforge,su2025benchmarking,wen2025interactivesurvey}. Existing\napproaches typically extract content from a large collection of related papers\nand prompt LLMs to summarize them directly. However, such methods often\noverlook the structural relationships among papers, resulting in generated\nsurveys that lack a coherent taxonomy and a deeper contextual understanding of\nresearch progress. To address these shortcomings, we propose \\textbf{SurveyG},\nan LLM-based agent framework that integrates \\textit{hierarchical citation\ngraph}, where nodes denote research papers and edges capture both citation\ndependencies and semantic relatedness between their contents, thereby embedding\nstructural and contextual knowledge into the survey generation process. The\ngraph is organized into three layers: \\textbf{Foundation},\n\\textbf{Development}, and \\textbf{Frontier}, to capture the evolution of\nresearch from seminal works to incremental advances and emerging directions. By\ncombining horizontal search within layers and vertical depth traversal across\nlayers, the agent produces multi-level summaries, which are consolidated into a\nstructured survey outline. A multi-agent validation stage then ensures\nconsistency, coverage, and factual accuracy in generating the final survey.\nExperiments, including evaluations by human experts and LLM-as-a-judge,\ndemonstrate that SurveyG outperforms state-of-the-art frameworks, producing\nsurveys that are more comprehensive and better structured to the underlying\nknowledge taxonomy of a field.", "AI": {"tldr": "SurveyG\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u5c42\u6b21\u5316\u5f15\u7528\u56fe\u6765\u751f\u6210\u66f4\u5168\u9762\u3001\u7ed3\u6784\u66f4\u597d\u7684\u7efc\u8ff0\u8bba\u6587\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u8bba\u6587\u95f4\u7ed3\u6784\u5173\u7cfb\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM\u751f\u6210\u7efc\u8ff0\u7684\u65b9\u6cd5\u901a\u5e38\u76f4\u63a5\u63d0\u53d6\u548c\u603b\u7ed3\u5927\u91cf\u76f8\u5173\u8bba\u6587\u5185\u5bb9\uff0c\u4f46\u5ffd\u89c6\u4e86\u8bba\u6587\u95f4\u7684\u7ed3\u6784\u5173\u7cfb\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u7efc\u8ff0\u7f3a\u4e4f\u8fde\u8d2f\u7684\u5206\u7c7b\u4f53\u7cfb\u548c\u6df1\u5c42\u4e0a\u4e0b\u6587\u7406\u89e3\u3002", "method": "\u63d0\u51faSurveyG\u6846\u67b6\uff0c\u6574\u5408\u5c42\u6b21\u5316\u5f15\u7528\u56fe\uff08\u5305\u542b\u57fa\u7840\u5c42\u3001\u53d1\u5c55\u5c42\u548c\u524d\u6cbf\u5c42\uff09\uff0c\u901a\u8fc7\u6a2a\u5411\u641c\u7d22\u548c\u7eb5\u5411\u6df1\u5ea6\u904d\u5386\u751f\u6210\u591a\u7ea7\u6458\u8981\uff0c\u5e76\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u9a8c\u8bc1\u786e\u4fdd\u4e00\u81f4\u6027\u3001\u8986\u76d6\u9762\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSurveyG\u5728\u4eba\u7c7b\u4e13\u5bb6\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u8bc4\u4f30\u4e2d\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6846\u67b6\uff0c\u751f\u6210\u7684\u7efc\u8ff0\u66f4\u5168\u9762\u4e14\u66f4\u597d\u5730\u7b26\u5408\u9886\u57df\u77e5\u8bc6\u5206\u7c7b\u7ed3\u6784\u3002", "conclusion": "SurveyG\u901a\u8fc7\u6574\u5408\u7ed3\u6784\u5316\u548c\u4e0a\u4e0b\u6587\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u751f\u6210\u7efc\u8ff0\u7684\u8d28\u91cf\uff0c\u4e3a\u81ea\u52a8\u5316\u7efc\u8ff0\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.08556", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.08556", "abs": "https://arxiv.org/abs/2510.08556", "authors": ["Xueyi Liu", "He Wang", "Li Yi"], "title": "DexNDM: Closing the Reality Gap for Dexterous In-Hand Rotation via Joint-Wise Neural Dynamics Model", "comment": "Project Website: https://meowuu7.github.io/DexNDM/ Video:\n  https://youtu.be/tU2Mv8vWftU", "summary": "Achieving generalized in-hand object rotation remains a significant challenge\nin robotics, largely due to the difficulty of transferring policies from\nsimulation to the real world. The complex, contact-rich dynamics of dexterous\nmanipulation create a \"reality gap\" that has limited prior work to constrained\nscenarios involving simple geometries, limited object sizes and aspect ratios,\nconstrained wrist poses, or customized hands. We address this sim-to-real\nchallenge with a novel framework that enables a single policy, trained in\nsimulation, to generalize to a wide variety of objects and conditions in the\nreal world. The core of our method is a joint-wise dynamics model that learns\nto bridge the reality gap by effectively fitting limited amount of real-world\ncollected data and then adapting the sim policy's actions accordingly. The\nmodel is highly data-efficient and generalizable across different whole-hand\ninteraction distributions by factorizing dynamics across joints, compressing\nsystem-wide influences into low-dimensional variables, and learning each\njoint's evolution from its own dynamic profile, implicitly capturing these net\neffects. We pair this with a fully autonomous data collection strategy that\ngathers diverse, real-world interaction data with minimal human intervention.\nOur complete pipeline demonstrates unprecedented generality: a single policy\nsuccessfully rotates challenging objects with complex shapes (e.g., animals),\nhigh aspect ratios (up to 5.33), and small sizes, all while handling diverse\nwrist orientations and rotation axes. Comprehensive real-world evaluations and\na teleoperation application for complex tasks validate the effectiveness and\nrobustness of our approach. Website: https://meowuu7.github.io/DexNDM/", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684sim-to-real\u6846\u67b6\uff0c\u901a\u8fc7\u5173\u8282\u7ea7\u52a8\u529b\u5b66\u6a21\u578b\u6709\u6548\u5f25\u5408\u73b0\u5b9e\u5dee\u8ddd\uff0c\u4f7f\u5355\u4e00\u4eff\u771f\u8bad\u7ec3\u7b56\u7565\u80fd\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u6cdb\u5316\u5230\u5404\u79cd\u7269\u4f53\u548c\u6761\u4ef6\u4e0b\u8fdb\u884c\u7075\u5de7\u65cb\u8f6c\u64cd\u4f5c\u3002", "motivation": "\u89e3\u51b3\u7075\u5de7\u64cd\u4f5c\u4e2d\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u8fc1\u79fb\u6311\u6218\uff0c\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u5728\u7269\u4f53\u51e0\u4f55\u3001\u5c3a\u5bf8\u3001\u624b\u8155\u59ff\u6001\u7b49\u65b9\u9762\u7684\u9650\u5236\uff0c\u5b9e\u73b0\u66f4\u901a\u7528\u7684\u624b\u5185\u7269\u4f53\u65cb\u8f6c\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u5173\u8282\u7ea7\u52a8\u529b\u5b66\u6a21\u578b\u62df\u5408\u6709\u9650\u771f\u5b9e\u6570\u636e\u5e76\u8c03\u6574\u4eff\u771f\u7b56\u7565\u52a8\u4f5c\uff0c\u901a\u8fc7\u5173\u8282\u52a8\u6001\u5206\u89e3\u3001\u7cfb\u7edf\u5f71\u54cd\u538b\u7f29\u548c\u81ea\u4e3b\u6570\u636e\u6536\u96c6\u5b9e\u73b0\u9ad8\u6548\u6570\u636e\u5229\u7528\u548c\u8de8\u5206\u5e03\u6cdb\u5316\u3002", "result": "\u5355\u4e00\u7b56\u7565\u6210\u529f\u65cb\u8f6c\u590d\u6742\u5f62\u72b6\u7269\u4f53\uff08\u5982\u52a8\u7269\u6a21\u578b\uff09\u3001\u9ad8\u5bbd\u6bd4\u7269\u4f53\uff08\u8fbe5.33\uff09\u548c\u5c0f\u5c3a\u5bf8\u7269\u4f53\uff0c\u5904\u7406\u591a\u6837\u624b\u8155\u671d\u5411\u548c\u65cb\u8f6c\u8f74\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u7075\u5de7\u64cd\u4f5c\u9886\u57df\u5b9e\u73b0\u4e86\u524d\u6240\u672a\u6709\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u590d\u6742\u4efb\u52a1\u7684\u9065\u64cd\u4f5c\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.07748", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07748", "abs": "https://arxiv.org/abs/2510.07748", "authors": ["Yilun Zhang", "Dexing Kong"], "title": "Haibu Mathematical-Medical Intelligent Agent:Enhancing Large Language Model Reliability in Medical Tasks via Verifiable Reasoning Chains", "comment": null, "summary": "Large Language Models (LLMs) show promise in medicine but are prone to\nfactual and logical errors, which is unacceptable in this high-stakes field. To\naddress this, we introduce the \"Haibu Mathematical-Medical Intelligent Agent\"\n(MMIA), an LLM-driven architecture that ensures reliability through a formally\nverifiable reasoning process. MMIA recursively breaks down complex medical\ntasks into atomic, evidence-based steps. This entire reasoning chain is then\nautomatically audited for logical coherence and evidence traceability, similar\nto theorem proving. A key innovation is MMIA's \"bootstrapping\" mode, which\nstores validated reasoning chains as \"theorems.\" Subsequent tasks can then be\nefficiently solved using Retrieval-Augmented Generation (RAG), shifting from\ncostly first-principles reasoning to a low-cost verification model. We\nvalidated MMIA across four healthcare administration domains, including DRG/DIP\naudits and medical insurance adjudication, using expert-validated benchmarks.\nResults showed MMIA achieved an error detection rate exceeding 98% with a false\npositive rate below 1%, significantly outperforming baseline LLMs. Furthermore,\nthe RAG matching mode is projected to reduce average processing costs by\napproximately 85% as the knowledge base matures. In conclusion, MMIA's\nverifiable reasoning framework is a significant step toward creating\ntrustworthy, transparent, and cost-effective AI systems, making LLM technology\nviable for critical applications in medicine.", "AI": {"tldr": "\u63d0\u51faHaibu MMIA\u67b6\u6784\uff0c\u901a\u8fc7\u5f62\u5f0f\u5316\u53ef\u9a8c\u8bc1\u63a8\u7406\u786e\u4fddLLM\u5728\u533b\u7597\u9886\u57df\u7684\u53ef\u9760\u6027\uff0c\u5c06\u590d\u6742\u4efb\u52a1\u5206\u89e3\u4e3a\u539f\u5b50\u6b65\u9aa4\u5e76\u81ea\u52a8\u5ba1\u6838\u903b\u8f91\u4e00\u81f4\u6027\uff0c\u652f\u6301\u4ece\u57fa\u7840\u63a8\u7406\u5230\u4f4e\u6210\u672c\u9a8c\u8bc1\u7684\u8f6c\u53d8\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u533b\u7597\u9886\u57df\u5bb9\u6613\u4ea7\u751f\u4e8b\u5b9e\u548c\u903b\u8f91\u9519\u8bef\u7684\u95ee\u9898\uff0c\u786e\u4fdd\u5728\u8fd9\u4e2a\u9ad8\u98ce\u9669\u9886\u57df\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u9012\u5f52\u5206\u89e3\u590d\u6742\u533b\u7597\u4efb\u52a1\u4e3a\u539f\u5b50\u8bc1\u636e\u6b65\u9aa4\uff0c\u81ea\u52a8\u5ba1\u6838\u63a8\u7406\u94fe\u7684\u903b\u8f91\u4e00\u81f4\u6027\u548c\u8bc1\u636e\u53ef\u8ffd\u6eaf\u6027\uff0c\u91c7\u7528'\u5f15\u5bfc'\u6a21\u5f0f\u5b58\u50a8\u5df2\u9a8c\u8bc1\u63a8\u7406\u94fe\u4f5c\u4e3a'\u5b9a\u7406'\uff0c\u540e\u7eed\u4efb\u52a1\u901a\u8fc7RAG\u5b9e\u73b0\u4f4e\u6210\u672c\u9a8c\u8bc1\u3002", "result": "\u5728\u56db\u4e2a\u533b\u7597\u7ba1\u7406\u9886\u57df\u9a8c\u8bc1\uff0c\u9519\u8bef\u68c0\u6d4b\u7387\u8d85\u8fc798%\uff0c\u8bef\u62a5\u7387\u4f4e\u4e8e1%\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebfLLM\uff0cRAG\u6a21\u5f0f\u9884\u8ba1\u53ef\u964d\u4f4e85%\u5904\u7406\u6210\u672c\u3002", "conclusion": "MMIA\u7684\u53ef\u9a8c\u8bc1\u63a8\u7406\u6846\u67b6\u662f\u521b\u5efa\u53ef\u4fe1\u8d56\u3001\u900f\u660e\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684AI\u7cfb\u7edf\u7684\u91cd\u8981\u8fdb\u5c55\uff0c\u4f7fLLM\u6280\u672f\u5728\u533b\u7597\u5173\u952e\u5e94\u7528\u4e2d\u53ef\u884c\u3002"}}
{"id": "2510.08568", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.08568", "abs": "https://arxiv.org/abs/2510.08568", "authors": ["Hongyu Li", "Lingfeng Sun", "Yafei Hu", "Duy Ta", "Jennifer Barry", "George Konidaris", "Jiahui Fu"], "title": "NovaFlow: Zero-Shot Manipulation via Actionable Flow from Generated Videos", "comment": null, "summary": "Enabling robots to execute novel manipulation tasks zero-shot is a central\ngoal in robotics. Most existing methods assume in-distribution tasks or rely on\nfine-tuning with embodiment-matched data, limiting transfer across platforms.\nWe present NovaFlow, an autonomous manipulation framework that converts a task\ndescription into an actionable plan for a target robot without any\ndemonstrations. Given a task description, NovaFlow synthesizes a video using a\nvideo generation model and distills it into 3D actionable object flow using\noff-the-shelf perception modules. From the object flow, it computes relative\nposes for rigid objects and realizes them as robot actions via grasp proposals\nand trajectory optimization. For deformable objects, this flow serves as a\ntracking objective for model-based planning with a particle-based dynamics\nmodel. By decoupling task understanding from low-level control, NovaFlow\nnaturally transfers across embodiments. We validate on rigid, articulated, and\ndeformable object manipulation tasks using a table-top Franka arm and a Spot\nquadrupedal mobile robot, and achieve effective zero-shot execution without\ndemonstrations or embodiment-specific training. Project website:\nhttps://novaflow.lhy.xyz/.", "AI": {"tldr": "NovaFlow\u662f\u4e00\u4e2a\u96f6\u6837\u672c\u673a\u5668\u4eba\u64cd\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u9891\u751f\u6210\u548c3D\u7269\u4f53\u6d41\u5206\u6790\u5b9e\u73b0\u8de8\u5e73\u53f0\u4efb\u52a1\u6267\u884c\uff0c\u65e0\u9700\u6f14\u793a\u6216\u7279\u5b9a\u673a\u5668\u4eba\u8bad\u7ec3\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u4efb\u52a1\u5206\u5e03\u5185\u6216\u9700\u8981\u7279\u5b9a\u673a\u5668\u4eba\u7684\u5fae\u8c03\u6570\u636e\uff0c\u9650\u5236\u4e86\u8de8\u5e73\u53f0\u8fc1\u79fb\u80fd\u529b\u3002", "method": "\u5c06\u4efb\u52a1\u63cf\u8ff0\u8f6c\u6362\u4e3a\u89c6\u9891\uff0c\u901a\u8fc7\u611f\u77e5\u6a21\u5757\u63d0\u53d63D\u7269\u4f53\u6d41\uff0c\u5bf9\u521a\u6027\u7269\u4f53\u8ba1\u7b97\u76f8\u5bf9\u4f4d\u59ff\u5e76\u4f18\u5316\u8f68\u8ff9\uff0c\u5bf9\u53ef\u53d8\u5f62\u7269\u4f53\u4f7f\u7528\u57fa\u4e8e\u7c92\u5b50\u7684\u52a8\u529b\u5b66\u6a21\u578b\u8fdb\u884c\u8ddf\u8e2a\u89c4\u5212\u3002", "result": "\u5728\u684c\u9762Franka\u673a\u68b0\u81c2\u548cSpot\u56db\u8db3\u79fb\u52a8\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u4e86\u521a\u6027\u3001\u5173\u8282\u548c\u53ef\u53d8\u5f62\u7269\u4f53\u64cd\u4f5c\u4efb\u52a1\u7684\u6709\u6548\u96f6\u6837\u672c\u6267\u884c\u3002", "conclusion": "\u901a\u8fc7\u5c06\u4efb\u52a1\u7406\u89e3\u4e0e\u5e95\u5c42\u63a7\u5236\u89e3\u8026\uff0cNovaFlow\u5b9e\u73b0\u4e86\u81ea\u7136\u8de8\u5e73\u53f0\u8fc1\u79fb\uff0c\u65e0\u9700\u6f14\u793a\u6216\u7279\u5b9a\u673a\u5668\u4eba\u8bad\u7ec3\u3002"}}
{"id": "2510.07762", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07762", "abs": "https://arxiv.org/abs/2510.07762", "authors": ["Xiangwei Lv", "JinLuan Yang", "Wang Lin", "Jingyuan Chen", "Beishui Liao"], "title": "From Noisy to Native: LLM-driven Graph Restoration for Test-Time Graph Domain Adaptation", "comment": null, "summary": "Graph domain adaptation (GDA) has achieved great attention due to its\neffectiveness in addressing the domain shift between train and test data. A\nsignificant bottleneck in existing graph domain adaptation methods is their\nreliance on source-domain data, which is often unavailable due to privacy or\nsecurity concerns. This limitation has driven the development of Test-Time\nGraph Domain Adaptation (TT-GDA), which aims to transfer knowledge without\naccessing the source examples. Inspired by the generative power of large\nlanguage models (LLMs), we introduce a novel framework that reframes TT-GDA as\na generative graph restoration problem, \"restoring the target graph to its\npristine, source-domain-like state\". There are two key challenges: (1) We need\nto construct a reasonable graph restoration process and design an effective\nencoding scheme that an LLM can understand, bridging the modality gap. (2) We\nneed to devise a mechanism to ensure the restored graph acquires the intrinsic\nfeatures of the source domain, even without access to the source data. To\nensure the effectiveness of graph restoration, we propose GRAIL, that restores\nthe target graph into a state that is well-aligned with the source domain.\nSpecifically, we first compress the node representations into compact latent\nfeatures and then use a graph diffusion process to model the graph restoration\nprocess. Then a quantization module encodes the restored features into discrete\ntokens. Building on this, an LLM is fine-tuned as a generative restorer to\ntransform a \"noisy\" target graph into a \"native\" one. To further improve\nrestoration quality, we introduce a reinforcement learning process guided by\nspecialized alignment and confidence rewards. Extensive experiments demonstrate\nthe effectiveness of our approach across various datasets.", "AI": {"tldr": "\u63d0\u51faGRAIL\u6846\u67b6\uff0c\u5c06\u6d4b\u8bd5\u65f6\u56fe\u57df\u9002\u5e94\u91cd\u65b0\u5b9a\u4e49\u4e3a\u751f\u6210\u5f0f\u56fe\u6062\u590d\u95ee\u9898\uff0c\u5229\u7528LLM\u5c06\u76ee\u6807\u56fe\u6062\u590d\u5230\u6e90\u57df\u72b6\u6001\uff0c\u65e0\u9700\u8bbf\u95ee\u6e90\u57df\u6570\u636e", "motivation": "\u73b0\u6709\u56fe\u57df\u9002\u5e94\u65b9\u6cd5\u4f9d\u8d56\u6e90\u57df\u6570\u636e\uff0c\u4f46\u7531\u4e8e\u9690\u79c1\u5b89\u5168\u95ee\u9898\u6e90\u57df\u6570\u636e\u5f80\u5f80\u4e0d\u53ef\u7528\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65e0\u9700\u6e90\u57df\u6570\u636e\u7684\u6d4b\u8bd5\u65f6\u56fe\u57df\u9002\u5e94\u65b9\u6cd5", "method": "\u4f7f\u7528\u56fe\u6269\u6563\u8fc7\u7a0b\u5efa\u6a21\u56fe\u6062\u590d\uff0c\u91cf\u5316\u6a21\u5757\u5c06\u6062\u590d\u7279\u5f81\u7f16\u7801\u4e3a\u79bb\u6563token\uff0c\u5fae\u8c03LLM\u4f5c\u4e3a\u751f\u6210\u5f0f\u6062\u590d\u5668\uff0c\u5e76\u5f15\u5165\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5bf9\u9f50\u548c\u7f6e\u4fe1\u5ea6\u5956\u52b1", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "GRAIL\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u6d4b\u8bd5\u65f6\u56fe\u57df\u9002\u5e94\u95ee\u9898\uff0c\u901a\u8fc7\u751f\u6210\u5f0f\u56fe\u6062\u590d\u65b9\u6cd5\u5b9e\u73b0\u4e86\u65e0\u9700\u6e90\u57df\u6570\u636e\u7684\u77e5\u8bc6\u8fc1\u79fb"}}
{"id": "2510.08571", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.08571", "abs": "https://arxiv.org/abs/2510.08571", "authors": ["Animikh Aich", "Adwait Kulkarni", "Eshed Ohn-Bar"], "title": "Scalable Offline Metrics for Autonomous Driving", "comment": "Accepted at IROS 2025 (IEEE/RSJ International Conference on\n  Intelligent Robots and Systems)", "summary": "Real-World evaluation of perception-based planning models for robotic\nsystems, such as autonomous vehicles, can be safely and inexpensively conducted\noffline, i.e., by computing model prediction error over a pre-collected\nvalidation dataset with ground-truth annotations. However, extrapolating from\noffline model performance to online settings remains a challenge. In these\nsettings, seemingly minor errors can compound and result in test-time\ninfractions or collisions. This relationship is understudied, particularly\nacross diverse closed-loop metrics and complex urban maneuvers. In this work,\nwe revisit this undervalued question in policy evaluation through an extensive\nset of experiments across diverse conditions and metrics. Based on analysis in\nsimulation, we find an even worse correlation between offline and online\nsettings than reported by prior studies, casting doubts on the validity of\ncurrent evaluation practices and metrics for driving policies. Next, we bridge\nthe gap between offline and online evaluation. We investigate an offline metric\nbased on epistemic uncertainty, which aims to capture events that are likely to\ncause errors in closed-loop settings. The resulting metric achieves over 13%\nimprovement in correlation compared to previous offline metrics. We further\nvalidate the generalization of our findings beyond the simulation environment\nin real-world settings, where even greater gains are observed.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u53d1\u73b0\u611f\u77e5\u89c4\u5212\u6a21\u578b\u7684\u79bb\u7ebf\u8bc4\u4f30\u4e0e\u5728\u7ebf\u6027\u80fd\u4e4b\u95f4\u5b58\u5728\u8f83\u5dee\u7684\u76f8\u5173\u6027\uff0c\u63d0\u51fa\u57fa\u4e8e\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u79bb\u7ebf\u6307\u6807\uff0c\u5728\u6a21\u62df\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u90fd\u663e\u8457\u63d0\u5347\u4e86\u79bb\u7ebf\u4e0e\u5728\u7ebf\u8bc4\u4f30\u7684\u76f8\u5173\u6027\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u79bb\u7ebf\u9a8c\u8bc1\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u8bc4\u4f30\u96be\u4ee5\u51c6\u786e\u9884\u6d4b\u5728\u7ebf\u5b9e\u9645\u8868\u73b0\uff0c\u8fd9\u79cd\u5dee\u8ddd\u5728\u590d\u6742\u57ce\u5e02\u9a7e\u9a76\u573a\u666f\u4e2d\u5c24\u4e3a\u660e\u663e\uff0c\u9700\u8981\u7814\u7a76\u66f4\u6709\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5927\u91cf\u6a21\u62df\u5b9e\u9a8c\u5206\u6790\u79bb\u7ebf\u4e0e\u5728\u7ebf\u8bc4\u4f30\u7684\u76f8\u5173\u6027\uff0c\u63d0\u51fa\u57fa\u4e8e\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u79bb\u7ebf\u6307\u6807\u6765\u8bc6\u522b\u53ef\u80fd\u5bfc\u81f4\u95ed\u73af\u9519\u8bef\u7684\u4e8b\u4ef6\u3002", "result": "\u53d1\u73b0\u79bb\u7ebf\u4e0e\u5728\u7ebf\u8bc4\u4f30\u7684\u76f8\u5173\u6027\u6bd4\u5148\u524d\u7814\u7a76\u62a5\u9053\u7684\u66f4\u5dee\uff0c\u63d0\u51fa\u7684\u65b0\u6307\u6807\u76f8\u6bd4\u4f20\u7edf\u79bb\u7ebf\u6307\u6807\u63d0\u5347\u4e8613%\u4ee5\u4e0a\u7684\u76f8\u5173\u6027\uff0c\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "\u5f53\u524d\u9a7e\u9a76\u7b56\u7565\u8bc4\u4f30\u5b9e\u8df5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u57fa\u4e8e\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u79bb\u7ebf\u6307\u6807\u80fd\u66f4\u597d\u5730\u6865\u63a5\u79bb\u7ebf\u4e0e\u5728\u7ebf\u8bc4\u4f30\u7684\u5dee\u8ddd\uff0c\u4e3a\u66f4\u53ef\u9760\u7684\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u9a8c\u8bc1\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2510.07772", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07772", "abs": "https://arxiv.org/abs/2510.07772", "authors": ["Tianle Zhou", "Jiakai Xu", "Guanhong Liu", "Jiaxiang Liu", "Haonan Wang", "Eugene Wu"], "title": "An approach for systematic decomposition of complex llm tasks", "comment": null, "summary": "Large Language Models (LLMs) suffer from reliability issues on complex tasks,\nas existing decomposition methods are heuristic and rely on agent or manual\ndecomposition. This work introduces a novel, systematic decomposition framework\nthat we call Analysis of CONstraint-Induced Complexity (ACONIC), which models\nthe task as a constraint problem and leveraging formal complexity measures to\nguide decomposition. On combinatorial (SATBench) and LLM database querying\ntasks (Spider), we find that by decomposing the tasks following the measure of\ncomplexity, agent can perform considerably better (10-40 percentage point).", "AI": {"tldr": "\u63d0\u51faACONIC\u6846\u67b6\uff0c\u901a\u8fc7\u7ea6\u675f\u95ee\u9898\u5efa\u6a21\u548c\u5f62\u5f0f\u5316\u590d\u6742\u5ea6\u5ea6\u91cf\u6765\u6307\u5bfc\u4efb\u52a1\u5206\u89e3\uff0c\u5728\u7ec4\u5408\u4f18\u5316\u548c\u6570\u636e\u5e93\u67e5\u8be2\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd10-40\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u73b0\u6709LLM\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u5b58\u5728\u53ef\u9760\u6027\u95ee\u9898\uff0c\u56e0\u4e3a\u73b0\u6709\u5206\u89e3\u65b9\u6cd5\u662f\u542f\u53d1\u5f0f\u7684\uff0c\u4f9d\u8d56\u4e8e\u667a\u80fd\u4f53\u6216\u624b\u52a8\u5206\u89e3\u3002", "method": "\u5f15\u5165ACONIC\u6846\u67b6\uff0c\u5c06\u4efb\u52a1\u5efa\u6a21\u4e3a\u7ea6\u675f\u95ee\u9898\uff0c\u5229\u7528\u5f62\u5f0f\u5316\u590d\u6742\u5ea6\u5ea6\u91cf\u6765\u6307\u5bfc\u5206\u89e3\u8fc7\u7a0b\u3002", "result": "\u5728\u7ec4\u5408\u4efb\u52a1(SATBench)\u548cLLM\u6570\u636e\u5e93\u67e5\u8be2\u4efb\u52a1(Spider)\u4e0a\uff0c\u901a\u8fc7\u57fa\u4e8e\u590d\u6742\u5ea6\u7684\u5206\u89e3\uff0c\u667a\u80fd\u4f53\u6027\u80fd\u663e\u8457\u63d0\u534710-40\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "ACONIC\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u7684\u4efb\u52a1\u5206\u89e3\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347LLM\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.08572", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08572", "abs": "https://arxiv.org/abs/2510.08572", "authors": ["Rocktim Jyoti Das", "Harsh Singh", "Diana Turmakhan", "Muhammad Abdullah Sohail", "Mingfei Han", "Preslav Nakov", "Fabio Pizzati", "Ivan Laptev"], "title": "BLAZER: Bootstrapping LLM-based Manipulation Agents with Zero-Shot Data Generation", "comment": "11 pages, 8 figures", "summary": "Scaling data and models has played a pivotal role in the remarkable progress\nof computer vision and language. Inspired by these domains, recent efforts in\nrobotics have similarly focused on scaling both data and model size to develop\nmore generalizable and robust policies. However, unlike vision and language,\nrobotics lacks access to internet-scale demonstrations across diverse robotic\ntasks and environments. As a result, the scale of existing datasets typically\nsuffers from the need for manual data collection and curation. To address this\nproblem, here we propose BLAZER, a framework that learns manipulation policies\nfrom automatically generated training data. We build on the zero-shot\ncapabilities of LLM planners and automatically generate demonstrations for\ndiverse manipulation tasks in simulation. Successful examples are then used to\nfinetune an LLM and to improve its planning capabilities without human\nsupervision. Notably, while BLAZER training requires access to the simulator's\nstate, we demonstrate direct transfer of acquired skills to sensor-based\nmanipulation. Through extensive experiments, we show BLAZER to significantly\nimprove zero-shot manipulation in both simulated and real environments.\nMoreover, BLAZER improves on tasks outside of its training pool and enables\ndownscaling of LLM models. Our code and data will be made publicly available on\nthe project page.", "AI": {"tldr": "BLAZER\u662f\u4e00\u4e2a\u4ece\u81ea\u52a8\u751f\u6210\u7684\u6570\u636e\u4e2d\u5b66\u4e60\u673a\u5668\u4eba\u64cd\u4f5c\u7b56\u7565\u7684\u6846\u67b6\uff0c\u5229\u7528LLM\u89c4\u5212\u5668\u7684\u96f6\u6837\u672c\u80fd\u529b\u5728\u6a21\u62df\u73af\u5883\u4e2d\u81ea\u52a8\u751f\u6210\u591a\u6837\u5316\u64cd\u4f5c\u4efb\u52a1\u7684\u6f14\u793a\uff0c\u6210\u529f\u793a\u4f8b\u7528\u4e8e\u5fae\u8c03LLM\u4ee5\u63d0\u5347\u89c4\u5212\u80fd\u529b\uff0c\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u3002", "motivation": "\u673a\u5668\u4eba\u9886\u57df\u7f3a\u4e4f\u4e92\u8054\u7f51\u89c4\u6a21\u7684\u591a\u6837\u5316\u4efb\u52a1\u6f14\u793a\u6570\u636e\uff0c\u73b0\u6709\u6570\u636e\u96c6\u89c4\u6a21\u53d7\u9650\u4e8e\u624b\u52a8\u6570\u636e\u6536\u96c6\u548c\u6574\u7406\uff0c\u9700\u8981\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u4ee5\u5b9e\u73b0\u66f4\u901a\u7528\u548c\u9c81\u68d2\u7684\u7b56\u7565\u3002", "method": "\u57fa\u4e8eLLM\u89c4\u5212\u5668\u7684\u96f6\u6837\u672c\u80fd\u529b\u81ea\u52a8\u751f\u6210\u6a21\u62df\u73af\u5883\u4e2d\u7684\u64cd\u4f5c\u4efb\u52a1\u6f14\u793a\uff0c\u4f7f\u7528\u6210\u529f\u793a\u4f8b\u5fae\u8c03LLM\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u9700\u8981\u6a21\u62df\u5668\u72b6\u6001\u8bbf\u95ee\u4f46\u80fd\u76f4\u63a5\u8fc1\u79fb\u5230\u57fa\u4e8e\u4f20\u611f\u5668\u7684\u5b9e\u9645\u64cd\u4f5c\u3002", "result": "BLAZER\u663e\u8457\u6539\u5584\u4e86\u6a21\u62df\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u96f6\u6837\u672c\u64cd\u4f5c\u80fd\u529b\uff0c\u5728\u8bad\u7ec3\u4efb\u52a1\u6c60\u5916\u7684\u4efb\u52a1\u4e0a\u4e5f\u6709\u63d0\u5347\uff0c\u5e76\u652f\u6301LLM\u6a21\u578b\u7684\u4e0b\u91c7\u6837\u3002", "conclusion": "BLAZER\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u8bad\u7ec3\u6570\u636e\u6709\u6548\u89e3\u51b3\u4e86\u673a\u5668\u4eba\u9886\u57df\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u96f6\u6837\u672c\u64cd\u4f5c\u6027\u80fd\u5e76\u5177\u6709\u826f\u597d\u8fc1\u79fb\u80fd\u529b\u3002"}}
{"id": "2510.07790", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07790", "abs": "https://arxiv.org/abs/2510.07790", "authors": ["Hao Wu", "Wei Liu"], "title": "GCPO: When Contrast Fails, Go Gold", "comment": null, "summary": "Reinforcement learning has been widely applied to enhance the reasoning\ncapabilities of large language models. Extending the inference limits of\nsmaller models has become a prominent research focus. However, algorithms such\nas Group Relative Policy Optimization (GRPO) suffer from a clear drawback: the\nupper bound of a model's rollout responses is entirely determined by the model\nitself, preventing the acquisition of knowledge from samples that are either\nall incorrect or all correct. In this paper, we introduce Group Contrastive\nPolicy Optimization (GCPO), a method that incorporates external standard\nreference answers. When the model cannot solve a problem, the reference answer\nsupplies the correct response, steering the model toward an unequivocally\naccurate update direction. This approach offers two main advantages: (1) it\nimproves training efficiency by fully utilizing every sample; (2) it enables\nthe model to emulate the problem solving strategy of the reference answer\nduring training, thereby enhancing generalization in reasoning. GCPO achieves\noutstanding results across multiple benchmark datasets, yielding substantial\nimprovements over the baseline model. Our code is available at:\nhttps://github.com/AchoWu/GCPO.", "AI": {"tldr": "\u63d0\u51faGCPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5916\u90e8\u6807\u51c6\u53c2\u8003\u7b54\u6848\u6765\u89e3\u51b3GRPO\u7b49\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u8bad\u7ec3\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65f6\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5982GRPO\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff1a\u6a21\u578b\u751f\u6210\u54cd\u5e94\u7684\u4e0a\u9650\u5b8c\u5168\u7531\u6a21\u578b\u81ea\u8eab\u51b3\u5b9a\uff0c\u65e0\u6cd5\u4ece\u5168\u9519\u6216\u5168\u5bf9\u7684\u6837\u672c\u4e2d\u5b66\u4e60\u77e5\u8bc6\u3002", "method": "\u5f15\u5165\u5916\u90e8\u6807\u51c6\u53c2\u8003\u7b54\u6848\uff0c\u5f53\u6a21\u578b\u65e0\u6cd5\u89e3\u51b3\u95ee\u9898\u65f6\uff0c\u53c2\u8003\u7b54\u6848\u63d0\u4f9b\u6b63\u786e\u54cd\u5e94\uff0c\u5f15\u5bfc\u6a21\u578b\u5411\u660e\u786e\u6b63\u786e\u7684\u66f4\u65b0\u65b9\u5411\u5b66\u4e60\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4f18\u5f02\u7ed3\u679c\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "GCPO\u65b9\u6cd5\u80fd\u591f\u5145\u5206\u5229\u7528\u6240\u6709\u6837\u672c\uff0c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\uff0c\u5e76\u8ba9\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5b66\u4e60\u53c2\u8003\u7b54\u6848\u7684\u89e3\u9898\u7b56\u7565\uff0c\u589e\u5f3a\u63a8\u7406\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.07813", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07813", "abs": "https://arxiv.org/abs/2510.07813", "authors": ["Valerio La Gatta", "Dolev Mutzari", "Sarit Kraus", "VS Subrahmanian"], "title": "Strategic Communication under Threat: Learning Information Trade-offs in Pursuit-Evasion Games", "comment": "15 pages, 13 figures", "summary": "Adversarial environments require agents to navigate a key strategic\ntrade-off: acquiring information enhances situational awareness, but may\nsimultaneously expose them to threats. To investigate this tension, we\nformulate a PursuitEvasion-Exposure-Concealment Game (PEEC) in which a pursuer\nagent must decide when to communicate in order to obtain the evader's position.\nEach communication reveals the pursuer's location, increasing the risk of being\ntargeted. Both agents learn their movement policies via reinforcement learning,\nwhile the pursuer additionally learns a communication policy that balances\nobservability and risk. We propose SHADOW (Strategic-communication Hybrid\nAction Decision-making under partial Observation for Warfare), a multi-headed\nsequential reinforcement learning framework that integrates continuous\nnavigation control, discrete communication actions, and opponent modeling for\nbehavior prediction. Empirical evaluations show that SHADOW pursuers achieve\nhigher success rates than six competitive baselines. Our ablation study\nconfirms that temporal sequence modeling and opponent modeling are critical for\neffective decision-making. Finally, our sensitivity analysis reveals that the\nlearned policies generalize well across varying communication risks and\nphysical asymmetries between agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86SHADOW\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5e73\u8861\u8ffd\u51fb\u8005\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u901a\u4fe1\u9700\u6c42\u4e0e\u66b4\u9732\u98ce\u9669\uff0c\u5b9e\u73b0\u4e86\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u66f4\u9ad8\u7684\u6210\u529f\u7387\u3002", "motivation": "\u5bf9\u6297\u73af\u5883\u4e2d\u5b58\u5728\u4fe1\u606f\u83b7\u53d6\u4e0e\u66b4\u9732\u98ce\u9669\u7684\u5173\u952e\u6743\u8861\uff1a\u901a\u4fe1\u53ef\u4ee5\u589e\u5f3a\u6001\u52bf\u611f\u77e5\uff0c\u4f46\u540c\u65f6\u4f1a\u66b4\u9732\u81ea\u8eab\u4f4d\u7f6e\u589e\u52a0\u88ab\u653b\u51fb\u98ce\u9669\u3002", "method": "\u63d0\u51faPEEC\u535a\u5f08\u6846\u67b6\uff0c\u4f7f\u7528SHADOW\u591a\u5934\u90e8\u5e8f\u8d2f\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u96c6\u6210\u8fde\u7eed\u5bfc\u822a\u63a7\u5236\u3001\u79bb\u6563\u901a\u4fe1\u52a8\u4f5c\u548c\u5bf9\u624b\u884c\u4e3a\u9884\u6d4b\u5efa\u6a21\u3002", "result": "SHADOW\u8ffd\u51fb\u8005\u6bd4\u516d\u79cd\u7ade\u4e89\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u66f4\u9ad8\u6210\u529f\u7387\uff0c\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u548c\u5bf9\u624b\u5efa\u6a21\u5bf9\u6709\u6548\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u5b66\u4e60\u5230\u7684\u7b56\u7565\u5728\u4e0d\u540c\u901a\u4fe1\u98ce\u9669\u548c\u7269\u7406\u4e0d\u5bf9\u79f0\u6761\u4ef6\u4e0b\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.07825", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07825", "abs": "https://arxiv.org/abs/2510.07825", "authors": ["Yuping Zhou", "Siqi Lai", "Jindong Han", "Hao Liu"], "title": "An LLM-Powered Cooperative Framework for Large-Scale Multi-Vehicle Navigation", "comment": null, "summary": "The rise of Internet of Vehicles (IoV) technologies is transforming traffic\nmanagement from isolated control to a collective, multi-vehicle process. At the\nheart of this shift is multi-vehicle dynamic navigation, which requires\nsimultaneously routing large fleets under evolving traffic conditions. Existing\npath search algorithms and reinforcement learning methods struggle to scale to\ncity-wide networks, often failing to capture the nonlinear, stochastic, and\ncoupled dynamics of urban traffic. To address these challenges, we propose\nCityNav, a hierarchical, LLM-powered framework for large-scale multi-vehicle\nnavigation. CityNav integrates a global traffic allocation agent, which\ncoordinates strategic traffic flow distribution across regions, with local\nnavigation agents that generate locally adaptive routes aligned with global\ndirectives. To enable effective cooperation, we introduce a cooperative\nreasoning optimization mechanism, in which agents are jointly trained with a\ndual-reward structure: individual rewards promote per-vehicle efficiency, while\nshared rewards encourage network-wide coordination and congestion reduction.\nExtensive experiments on four real-world road networks of varying scales (up to\n1.6 million roads and 430,000 intersections) and traffic datasets demonstrate\nthat CityNav consistently outperforms nine classical path search and RL-based\nbaselines in city-scale travel efficiency and congestion mitigation. Our\nresults highlight the potential of LLMs to enable scalable, adaptive, and\ncooperative city-wide traffic navigation, providing a foundation for\nintelligent, large-scale vehicle routing in complex urban environments. Our\nproject is available at https://github.com/usail-hkust/CityNav.", "AI": {"tldr": "CityNav\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u5206\u5c42\u6846\u67b6\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u591a\u8f66\u8f86\u52a8\u6001\u5bfc\u822a\uff0c\u901a\u8fc7\u5168\u5c40\u4ea4\u901a\u5206\u914d\u4ee3\u7406\u548c\u5c40\u90e8\u5bfc\u822a\u4ee3\u7406\u7684\u534f\u540c\u4f18\u5316\uff0c\u5728\u57ce\u5e02\u89c4\u6a21\u4ea4\u901a\u7f51\u7edc\u4e2d\u663e\u8457\u63d0\u5347\u65c5\u884c\u6548\u7387\u548c\u7f13\u89e3\u62e5\u5835\u3002", "motivation": "\u73b0\u6709\u8def\u5f84\u641c\u7d22\u7b97\u6cd5\u548c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u6269\u5c55\u5230\u57ce\u5e02\u89c4\u6a21\u7f51\u7edc\uff0c\u65e0\u6cd5\u6709\u6548\u6355\u6349\u57ce\u5e02\u4ea4\u901a\u7684\u975e\u7ebf\u6027\u3001\u968f\u673a\u6027\u548c\u8026\u5408\u52a8\u6001\u7279\u6027\u3002", "method": "\u63d0\u51fa\u5206\u5c42LLM\u6846\u67b6\uff0c\u5305\u542b\u5168\u5c40\u4ea4\u901a\u5206\u914d\u4ee3\u7406\u548c\u5c40\u90e8\u5bfc\u822a\u4ee3\u7406\uff0c\u91c7\u7528\u534f\u540c\u63a8\u7406\u4f18\u5316\u673a\u5236\u548c\u53cc\u5956\u52b1\u7ed3\u6784\uff08\u4e2a\u4f53\u5956\u52b1\u548c\u5171\u4eab\u5956\u52b1\uff09\u8fdb\u884c\u8054\u5408\u8bad\u7ec3\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u9053\u8def\u7f51\u7edc\uff08\u6700\u591a160\u4e07\u6761\u9053\u8def\u548c43\u4e07\u4e2a\u4ea4\u53c9\u53e3\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCityNav\u5728\u4e5d\u79cd\u7ecf\u5178\u8def\u5f84\u641c\u7d22\u548c\u57fa\u4e8eRL\u7684\u57fa\u51c6\u65b9\u6cd5\u4e2d\u8868\u73b0\u6700\u4f18\u3002", "conclusion": "LLM\u6709\u6f5c\u529b\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u81ea\u9002\u5e94\u548c\u534f\u540c\u7684\u57ce\u5e02\u8303\u56f4\u4ea4\u901a\u5bfc\u822a\uff0c\u4e3a\u590d\u6742\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u667a\u80fd\u5927\u89c4\u6a21\u8f66\u8f86\u8def\u7531\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2510.07852", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07852", "abs": "https://arxiv.org/abs/2510.07852", "authors": ["Shuangyan Deng", "Haizhou Peng", "Jiachen Xu", "Rui Mao", "Ciprian Doru Giurc\u0103neanu", "Jiamou Liu"], "title": "FinMR: A Knowledge-Intensive Multimodal Benchmark for Advanced Financial Reasoning", "comment": "This paper has been accept by ICAIF 2025", "summary": "Multimodal Large Language Models (MLLMs) have made substantial progress in\nrecent years. However, their rigorous evaluation within specialized domains\nlike finance is hindered by the absence of datasets characterized by\nprofessional-level knowledge intensity, detailed annotations, and advanced\nreasoning complexity. To address this critical gap, we introduce FinMR, a\nhigh-quality, knowledge-intensive multimodal dataset explicitly designed to\nevaluate expert-level financial reasoning capabilities at a professional\nanalyst's standard. FinMR comprises over 3,200 meticulously curated and\nexpertly annotated question-answer pairs across 15 diverse financial topics,\nensuring broad domain diversity and integrating sophisticated mathematical\nreasoning, advanced financial knowledge, and nuanced visual interpretation\ntasks across multiple image types. Through comprehensive benchmarking with\nleading closed-source and open-source MLLMs, we highlight significant\nperformance disparities between these models and professional financial\nanalysts, uncovering key areas for model advancement, such as precise image\nanalysis, accurate application of complex financial formulas, and deeper\ncontextual financial understanding. By providing richly varied visual content\nand thorough explanatory annotations, FinMR establishes itself as an essential\nbenchmark tool for assessing and advancing multimodal financial reasoning\ntoward professional analyst-level competence.", "AI": {"tldr": "FinMR\u662f\u4e00\u4e2a\u9ad8\u8d28\u91cf\u3001\u77e5\u8bc6\u5bc6\u96c6\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u4e13\u4e1a\u5206\u6790\u5e08\u7ea7\u522b\u7684\u91d1\u878d\u63a8\u7406\u80fd\u529b\uff0c\u5305\u542b3200\u591a\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684\u95ee\u9898-\u7b54\u6848\u5bf9\uff0c\u6db5\u76d615\u4e2a\u91d1\u878d\u4e3b\u9898\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u7b49\u4e13\u4e1a\u9886\u57df\u7684\u8bc4\u4f30\u5b58\u5728\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u5177\u6709\u4e13\u4e1a\u7ea7\u77e5\u8bc6\u5f3a\u5ea6\u3001\u8be6\u7ec6\u6ce8\u91ca\u548c\u9ad8\u7ea7\u63a8\u7406\u590d\u6742\u6027\u7684\u6570\u636e\u96c6\u3002", "method": "\u6784\u5efa\u5305\u542b3200\u591a\u4e2a\u4e13\u5bb6\u6807\u6ce8\u95ee\u9898-\u7b54\u6848\u5bf9\u7684FinMR\u6570\u636e\u96c6\uff0c\u6db5\u76d615\u4e2a\u91d1\u878d\u4e3b\u9898\uff0c\u6574\u5408\u4e86\u590d\u6742\u6570\u5b66\u63a8\u7406\u3001\u9ad8\u7ea7\u91d1\u878d\u77e5\u8bc6\u548c\u591a\u7c7b\u578b\u56fe\u50cf\u89e3\u91ca\u4efb\u52a1\u3002", "result": "\u901a\u8fc7\u5bf9\u9886\u5148\u7684\u5f00\u6e90\u548c\u95ed\u6e90MLLMs\u8fdb\u884c\u5168\u9762\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u8fd9\u4e9b\u6a21\u578b\u4e0e\u4e13\u4e1a\u91d1\u878d\u5206\u6790\u5e08\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u7cbe\u786e\u56fe\u50cf\u5206\u6790\u3001\u590d\u6742\u91d1\u878d\u516c\u5f0f\u5e94\u7528\u548c\u6df1\u5ea6\u4e0a\u4e0b\u6587\u7406\u89e3\u65b9\u9762\u3002", "conclusion": "FinMR\u901a\u8fc7\u63d0\u4f9b\u4e30\u5bcc\u7684\u89c6\u89c9\u5185\u5bb9\u548c\u8be6\u7ec6\u89e3\u91ca\u6027\u6ce8\u91ca\uff0c\u6210\u4e3a\u8bc4\u4f30\u548c\u63a8\u8fdb\u591a\u6a21\u6001\u91d1\u878d\u63a8\u7406\u5411\u4e13\u4e1a\u5206\u6790\u5e08\u6c34\u5e73\u53d1\u5c55\u7684\u91cd\u8981\u57fa\u51c6\u5de5\u5177\u3002"}}
{"id": "2510.07858", "categories": ["cs.AI", "cs.LG", "62M10", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.07858", "abs": "https://arxiv.org/abs/2510.07858", "authors": ["Zhiqing Cui", "Binwu Wang", "Qingxiang Liu", "Yeqiang Wang", "Zhengyang Zhou", "Yuxuan Liang", "Yang Wang"], "title": "Augur: Modeling Covariate Causal Associations in Time Series via Large Language Models", "comment": "22 pages, 9 figures", "summary": "Large language models (LLM) have emerged as a promising avenue for time\nseries forecasting, offering the potential to integrate multimodal data.\nHowever, existing LLM-based approaches face notable limitations-such as\nmarginalized role in model architectures, reliance on coarse statistical text\nprompts, and lack of interpretability. In this work, we introduce Augur, a\nfully LLM driven time series forecasting framework that exploits LLM causal\nreasoning to discover and use directed causal associations among covariates.\nAugur uses a two stage teacher student architecture where a powerful teacher\nLLM infers a directed causal graph from time series using heuristic search\ntogether with pairwise causality testing. A lightweight student agent then\nrefines the graph and fine tune on high confidence causal associations that are\nencoded as rich textual prompts to perform forecasting. This design improves\npredictive accuracy while yielding transparent, traceable reasoning about\nvariable interactions. Extensive experiments on real-world datasets with 25\nbaselines demonstrate that Augur achieves competitive performance and robust\nzero-shot generalization.", "AI": {"tldr": "Augur\u662f\u4e00\u4e2a\u5b8c\u5168\u7531LLM\u9a71\u52a8\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u5229\u7528LLM\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\u53d1\u73b0\u548c\u4f7f\u7528\u534f\u53d8\u91cf\u95f4\u7684\u6709\u5411\u56e0\u679c\u5173\u8054\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u5e08\u751f\u67b6\u6784\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u5728\u6a21\u578b\u67b6\u6784\u4e2d\u4f5c\u7528\u8fb9\u7f18\u5316\u3001\u4f9d\u8d56\u7c97\u7cd9\u7684\u7edf\u8ba1\u6587\u672c\u63d0\u793a\u3001\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5e08\u751f\u67b6\u6784\uff1a\u5f3a\u5927\u7684\u6559\u5e08LLM\u901a\u8fc7\u542f\u53d1\u5f0f\u641c\u7d22\u548c\u6210\u5bf9\u56e0\u679c\u68c0\u9a8c\u4ece\u65f6\u95f4\u5e8f\u5217\u63a8\u65ad\u6709\u5411\u56e0\u679c\u56fe\uff1b\u8f7b\u91cf\u7ea7\u5b66\u751f\u4ee3\u7406\u7cbe\u70bc\u8be5\u56fe\uff0c\u5e76\u5728\u9ad8\u7f6e\u4fe1\u5ea6\u56e0\u679c\u5173\u8054\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u8fd9\u4e9b\u5173\u8054\u88ab\u7f16\u7801\u4e3a\u4e30\u5bcc\u7684\u6587\u672c\u63d0\u793a\u7528\u4e8e\u9884\u6d4b\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cAugur\u572825\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u4e2d\u53d6\u5f97\u4e86\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Augur\u6846\u67b6\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u8ffd\u6eaf\u7684\u53d8\u91cf\u4ea4\u4e92\u63a8\u7406\uff0c\u4e3aLLM\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2510.07861", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07861", "abs": "https://arxiv.org/abs/2510.07861", "authors": ["Tianyu Fan", "Xinyao Niu", "Yuxiang Zheng", "Fengji Zhang", "Chengen Huang", "Bei Chen", "Junyang Lin", "Chao Huang"], "title": "Understanding DeepResearch via Reports", "comment": "22 pages, 4 figures", "summary": "DeepResearch agents represent a transformative AI paradigm, conducting\nexpert-level research through sophisticated reasoning and multi-tool\nintegration. However, evaluating these systems remains critically challenging\ndue to open-ended research scenarios and existing benchmarks that focus on\nisolated capabilities rather than holistic performance. Unlike traditional LLM\ntasks, DeepResearch systems must synthesize diverse sources, generate insights,\nand present coherent findings, which are capabilities that resist simple\nverification. To address this gap, we introduce DeepResearch-ReportEval, a\ncomprehensive framework designed to assess DeepResearch systems through their\nmost representative outputs: research reports. Our approach systematically\nmeasures three dimensions: quality, redundancy, and factuality, using an\ninnovative LLM-as-a-Judge methodology achieving strong expert concordance. We\ncontribute a standardized benchmark of 100 curated queries spanning 12\nreal-world categories, enabling systematic capability comparison. Our\nevaluation of four leading commercial systems reveals distinct design\nphilosophies and performance trade-offs, establishing foundational insights as\nDeepResearch evolves from information assistants toward intelligent research\npartners. Source code and data are available at:\nhttps://github.com/HKUDS/DeepResearch-Eval.", "AI": {"tldr": "\u63d0\u51fa\u4e86DeepResearch-ReportEval\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u6df1\u5ea6\u7814\u7a76AI\u7cfb\u7edf\u5728\u7814\u7a76\u62a5\u544a\u751f\u6210\u65b9\u9762\u7684\u7efc\u5408\u80fd\u529b\uff0c\u5305\u62ec\u8d28\u91cf\u3001\u5197\u4f59\u6027\u548c\u4e8b\u5b9e\u6027\u4e09\u4e2a\u7ef4\u5ea6\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u5b64\u7acb\u80fd\u529b\uff0c\u65e0\u6cd5\u8bc4\u4f30\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u5728\u5f00\u653e\u7814\u7a76\u573a\u666f\u4e2d\u7684\u6574\u4f53\u8868\u73b0\uff0c\u7279\u522b\u662f\u7efc\u5408\u591a\u6e90\u4fe1\u606f\u3001\u751f\u6210\u6d1e\u5bdf\u548c\u5448\u73b0\u8fde\u8d2f\u53d1\u73b0\u7684\u80fd\u529b\u3002", "method": "\u91c7\u7528LLM-as-a-Judge\u65b9\u6cd5\uff0c\u6784\u5efa\u5305\u542b100\u4e2a\u67e5\u8be2\u7684\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u6db5\u76d612\u4e2a\u73b0\u5b9e\u4e16\u754c\u7c7b\u522b\uff0c\u7cfb\u7edf\u8bc4\u4f30\u7814\u7a76\u62a5\u544a\u7684\u8d28\u91cf\u3001\u5197\u4f59\u6027\u548c\u4e8b\u5b9e\u6027\u3002", "result": "\u5bf9\u56db\u4e2a\u9886\u5148\u5546\u4e1a\u7cfb\u7edf\u7684\u8bc4\u4f30\u63ed\u793a\u4e86\u4e0d\u540c\u7684\u8bbe\u8ba1\u7406\u5ff5\u548c\u6027\u80fd\u6743\u8861\uff0c\u4e3a\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u4ece\u4fe1\u606f\u52a9\u624b\u5411\u667a\u80fd\u7814\u7a76\u4f19\u4f34\u7684\u6f14\u8fdb\u63d0\u4f9b\u4e86\u57fa\u7840\u89c1\u89e3\u3002", "conclusion": "DeepResearch-ReportEval\u6846\u67b6\u586b\u8865\u4e86\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u7cfb\u7edf\u80fd\u529b\u6bd4\u8f83\u548c\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u5de5\u5177\u3002"}}
{"id": "2510.07920", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07920", "abs": "https://arxiv.org/abs/2510.07920", "authors": ["Xiangyu Li", "Yawen Zeng", "Xiaofen Xing", "Jin Xu", "Xiangmin Xu"], "title": "Profit Mirage: Revisiting Information Leakage in LLM-based Financial Agents", "comment": null, "summary": "LLM-based financial agents have attracted widespread excitement for their\nability to trade like human experts. However, most systems exhibit a \"profit\nmirage\": dazzling back-tested returns evaporate once the model's knowledge\nwindow ends, because of the inherent information leakage in LLMs. In this\npaper, we systematically quantify this leakage issue across four dimensions and\nrelease FinLake-Bench, a leakage-robust evaluation benchmark. Furthermore, to\nmitigate this issue, we introduce FactFin, a framework that applies\ncounterfactual perturbations to compel LLM-based agents to learn causal drivers\ninstead of memorized outcomes. FactFin integrates four core components:\nStrategy Code Generator, Retrieval-Augmented Generation, Monte Carlo Tree\nSearch, and Counterfactual Simulator. Extensive experiments show that our\nmethod surpasses all baselines in out-of-sample generalization, delivering\nsuperior risk-adjusted performance.", "AI": {"tldr": "\u672c\u6587\u63ed\u793aLLM\u91d1\u878d\u4ee3\u7406\u5b58\u5728\"\u5229\u6da6\u5e7b\u8c61\"\u95ee\u9898\uff0c\u63d0\u51faFactFin\u6846\u67b6\u901a\u8fc7\u53cd\u4e8b\u5b9e\u6270\u52a8\u6765\u5b66\u4e60\u56e0\u679c\u9a71\u52a8\u56e0\u7d20\uff0c\u5e76\u53d1\u5e03FinLake-Bench\u8bc4\u4f30\u57fa\u51c6\u3002", "motivation": "\u89e3\u51b3LLM\u91d1\u878d\u4ee3\u7406\u4e2d\u56e0\u4fe1\u606f\u6cc4\u9732\u5bfc\u81f4\u7684\"\u5229\u6da6\u5e7b\u8c61\"\u95ee\u9898\uff0c\u5373\u56de\u6d4b\u6536\u76ca\u5728\u6a21\u578b\u77e5\u8bc6\u7a97\u53e3\u7ed3\u675f\u540e\u6d88\u5931\u7684\u73b0\u8c61\u3002", "method": "\u63d0\u51faFactFin\u6846\u67b6\uff0c\u5305\u542b\u7b56\u7565\u4ee3\u7801\u751f\u6210\u5668\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3001\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u548c\u53cd\u4e8b\u5b9e\u6a21\u62df\u5668\u56db\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u6270\u52a8\u5f3a\u5236\u5b66\u4e60\u56e0\u679c\u9a71\u52a8\u56e0\u7d20\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u6837\u672c\u5916\u6cdb\u5316\u65b9\u9762\u8d85\u8d8a\u6240\u6709\u57fa\u7ebf\uff0c\u63d0\u4f9b\u4f18\u8d8a\u7684\u98ce\u9669\u8c03\u6574\u540e\u6027\u80fd\u3002", "conclusion": "FactFin\u6846\u67b6\u80fd\u6709\u6548\u7f13\u89e3LLM\u91d1\u878d\u4ee3\u7406\u7684\u4fe1\u606f\u6cc4\u9732\u95ee\u9898\uff0c\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5b9e\u9645\u4ea4\u6613\u8868\u73b0\u3002"}}
{"id": "2510.07925", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.07925", "abs": "https://arxiv.org/abs/2510.07925", "authors": ["Rebecca Westh\u00e4u\u00dfer", "Wolfgang Minker", "Sebatian Zepf"], "title": "Enabling Personalized Long-term Interactions in LLM-based Agents through Persistent Memory and User Profiles", "comment": "8 pages, 1 figure, 1 table", "summary": "Large language models (LLMs) increasingly serve as the central control unit\nof AI agents, yet current approaches remain limited in their ability to deliver\npersonalized interactions. While Retrieval Augmented Generation enhances LLM\ncapabilities by improving context-awareness, it lacks mechanisms to combine\ncontextual information with user-specific data. Although personalization has\nbeen studied in fields such as human-computer interaction or cognitive science,\nexisting perspectives largely remain conceptual, with limited focus on\ntechnical implementation. To address these gaps, we build on a unified\ndefinition of personalization as a conceptual foundation to derive technical\nrequirements for adaptive, user-centered LLM-based agents. Combined with\nestablished agentic AI patterns such as multi-agent collaboration or\nmulti-source retrieval, we present a framework that integrates persistent\nmemory, dynamic coordination, self-validation, and evolving user profiles to\nenable personalized long-term interactions. We evaluate our approach on three\npublic datasets using metrics such as retrieval accuracy, response correctness,\nor BertScore. We complement these results with a five-day pilot user study\nproviding initial insights into user feedback on perceived personalization. The\nstudy provides early indications that guide future work and highlights the\npotential of integrating persistent memory and user profiles to improve the\nadaptivity and perceived personalization of LLM-based agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u6301\u4e45\u8bb0\u5fc6\u3001\u52a8\u6001\u534f\u8c03\u3001\u81ea\u6211\u9a8c\u8bc1\u548c\u6f14\u8fdb\u7528\u6237\u6863\u6848\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u73b0\u57fa\u4e8eLLM\u7684\u4e2a\u6027\u5316\u667a\u80fd\u4f53\u957f\u671f\u4ea4\u4e92\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5728\u63d0\u4f9b\u4e2a\u6027\u5316\u4ea4\u4e92\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0cRAG\u867d\u7136\u589e\u5f3a\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u4f46\u7f3a\u4e4f\u7ed3\u5408\u7528\u6237\u7279\u5b9a\u6570\u636e\u7684\u673a\u5236\uff0c\u73b0\u6709\u4e2a\u6027\u5316\u7814\u7a76\u591a\u505c\u7559\u5728\u6982\u5ff5\u5c42\u9762\u800c\u7f3a\u4e4f\u6280\u672f\u5b9e\u73b0\u3002", "method": "\u57fa\u4e8e\u7edf\u4e00\u7684\u4e2a\u6027\u5316\u5b9a\u4e49\uff0c\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u591a\u6e90\u68c0\u7d22\u7b49\u6210\u719fAI\u6a21\u5f0f\uff0c\u6784\u5efa\u4e86\u96c6\u6210\u6301\u4e45\u8bb0\u5fc6\u3001\u52a8\u6001\u534f\u8c03\u3001\u81ea\u6211\u9a8c\u8bc1\u548c\u6f14\u8fdb\u7528\u6237\u6863\u6848\u7684\u6280\u672f\u6846\u67b6\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u68c0\u7d22\u51c6\u786e\u6027\u3001\u54cd\u5e94\u6b63\u786e\u6027\u548cBertScore\u7b49\u6307\u6807\uff0c\u5e76\u901a\u8fc75\u5929\u8bd5\u70b9\u7528\u6237\u7814\u7a76\u83b7\u5f97\u4e86\u5173\u4e8e\u611f\u77e5\u4e2a\u6027\u5316\u7684\u521d\u6b65\u7528\u6237\u53cd\u9988\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u96c6\u6210\u6301\u4e45\u8bb0\u5fc6\u548c\u7528\u6237\u6863\u6848\u6709\u6f5c\u529b\u63d0\u5347\u57fa\u4e8eLLM\u667a\u80fd\u4f53\u7684\u9002\u5e94\u6027\u548c\u611f\u77e5\u4e2a\u6027\u5316\uff0c\u4e3a\u672a\u6765\u5de5\u4f5c\u63d0\u4f9b\u4e86\u6307\u5bfc\u65b9\u5411\u3002"}}
{"id": "2510.07943", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07943", "abs": "https://arxiv.org/abs/2510.07943", "authors": ["Qiushi Tian", "Churong Liang", "Kairan Hong", "Runnan Li"], "title": "Agent-Based Genetic Algorithm for Crypto Trading Strategy Optimization", "comment": "5 pages, 4 figures", "summary": "Cryptocurrency markets present formidable challenges for trading strategy\noptimization due to extreme volatility, non-stationary dynamics, and complex\nmicrostructure patterns that render conventional parameter optimization methods\nfundamentally inadequate. We introduce Cypto Genetic Algorithm Agent\n(CGA-Agent), a pioneering hybrid framework that synergistically integrates\ngenetic algorithms with intelligent multi-agent coordination mechanisms for\nadaptive trading strategy parameter optimization in dynamic financial\nenvironments. The framework uniquely incorporates real-time market\nmicrostructure intelligence and adaptive strategy performance feedback through\nintelligent mechanisms that dynamically guide evolutionary processes,\ntranscending the limitations of static optimization approaches. Comprehensive\nempirical evaluation across three cryptocurrencies demonstrates systematic and\nstatistically significant performance improvements on both total returns and\nrisk-adjusted metrics.", "AI": {"tldr": "\u63d0\u51faCGA-Agent\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u4e0e\u667a\u80fd\u591a\u667a\u80fd\u4f53\u534f\u8c03\u673a\u5236\uff0c\u7528\u4e8e\u52a0\u5bc6\u8d27\u5e01\u4ea4\u6613\u7b56\u7565\u53c2\u6570\u4f18\u5316\uff0c\u5728\u52a8\u6001\u91d1\u878d\u73af\u5883\u4e2d\u5b9e\u73b0\u81ea\u9002\u5e94\u4f18\u5316\u3002", "motivation": "\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u5177\u6709\u6781\u7aef\u6ce2\u52a8\u6027\u3001\u975e\u5e73\u7a33\u52a8\u6001\u548c\u590d\u6742\u5fae\u89c2\u7ed3\u6784\u6a21\u5f0f\uff0c\u4f7f\u4f20\u7edf\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\u5931\u6548\uff0c\u9700\u8981\u65b0\u7684\u81ea\u9002\u5e94\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1CGA-Agent\u6df7\u5408\u6846\u67b6\uff0c\u6574\u5408\u9057\u4f20\u7b97\u6cd5\u4e0e\u591a\u667a\u80fd\u4f53\u534f\u8c03\u673a\u5236\uff0c\u878d\u5165\u5b9e\u65f6\u5e02\u573a\u5fae\u89c2\u7ed3\u6784\u667a\u80fd\u548c\u81ea\u9002\u5e94\u7b56\u7565\u6027\u80fd\u53cd\u9988\uff0c\u52a8\u6001\u6307\u5bfc\u8fdb\u5316\u8fc7\u7a0b\u3002", "result": "\u5728\u4e09\u79cd\u52a0\u5bc6\u8d27\u5e01\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0c\u5728\u603b\u56de\u62a5\u548c\u98ce\u9669\u8c03\u6574\u6307\u6807\u4e0a\u90fd\u5b9e\u73b0\u4e86\u7cfb\u7edf\u6027\u548c\u7edf\u8ba1\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\u3002", "conclusion": "\u8be5\u6846\u67b6\u8d85\u8d8a\u4e86\u9759\u6001\u4f18\u5316\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u52a8\u6001\u91d1\u878d\u73af\u5883\u4e2d\u7684\u4ea4\u6613\u7b56\u7565\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.07972", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07972", "abs": "https://arxiv.org/abs/2510.07972", "authors": ["Pengkun Jiao", "Yiming Jin", "Jianhui Yang", "Chenhe Dong", "Zerui Huang", "Shaowei Yao", "Xiaojiang Zhou", "Dan Ou", "Haihong Tang"], "title": "TaoSR-SHE: Stepwise Hybrid Examination Reinforcement Learning Framework for E-commerce Search Relevance", "comment": null, "summary": "Query-product relevance analysis is a foundational technology in e-commerce\nsearch engines and has become increasingly important in AI-driven e-commerce.\nThe recent emergence of large language models (LLMs), particularly their\nchain-of-thought (CoT) reasoning capabilities, offers promising opportunities\nfor developing relevance systems that are both more interpretable and more\nrobust. However, existing training paradigms have notable limitations: SFT and\nDPO suffer from poor generalization on long-tail queries and from a lack of\nfine-grained, stepwise supervision to enforce rule-aligned reasoning. In\ncontrast, reinforcement learning with verification rewards (RLVR) suffers from\nsparse feedback, which provides insufficient signal to correct erroneous\nintermediate steps, thereby undermining logical consistency and limiting\nperformance in complex inference scenarios.\n  To address these challenges, we introduce the Stepwise Hybrid Examination\nReinforcement Learning framework for Taobao Search Relevance (TaoSR-SHE). At\nits core is Stepwise Reward Policy Optimization (SRPO), a reinforcement\nlearning algorithm that leverages step-level rewards generated by a hybrid of a\nhigh-quality generative stepwise reward model and a human-annotated offline\nverifier, prioritizing learning from critical correct and incorrect reasoning\nsteps. TaoSR-SHE further incorporates two key techniques: diversified data\nfiltering to encourage exploration across varied reasoning paths and mitigate\npolicy entropy collapse, and multi-stage curriculum learning to foster\nprogressive capability growth. Extensive experiments on real-world search\nbenchmarks show that TaoSR-SHE improves both reasoning quality and\nrelevance-prediction accuracy in large-scale e-commerce settings, outperforming\nSFT, DPO, GRPO, and other baselines, while also enhancing interpretability and\nrobustness.", "AI": {"tldr": "\u63d0\u51fa\u4e86TaoSR-SHE\u6846\u67b6\uff0c\u901a\u8fc7\u6b65\u8fdb\u5f0f\u6df7\u5408\u68c0\u67e5\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u7535\u5546\u641c\u7d22\u76f8\u5173\u6027\u5206\u6790\u4e2d\u7684\u63a8\u7406\u4e00\u81f4\u6027\u548c\u6cdb\u5316\u6027\u95ee\u9898\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8bad\u7ec3\u8303\u5f0f\uff08SFT\u3001DPO\u3001RLVR\uff09\u5728\u957f\u5c3e\u67e5\u8be2\u6cdb\u5316\u3001\u7ec6\u7c92\u5ea6\u76d1\u7763\u548c\u63a8\u7406\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u6838\u5fc3\u662fSRPO\u7b97\u6cd5\uff0c\u7ed3\u5408\u751f\u6210\u5f0f\u6b65\u8fdb\u5956\u52b1\u6a21\u578b\u548c\u4eba\u5de5\u6807\u6ce8\u9a8c\u8bc1\u5668\uff0c\u8f85\u4ee5\u591a\u6837\u5316\u6570\u636e\u8fc7\u6ee4\u548c\u591a\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u6280\u672f\u3002", "result": "\u5728\u771f\u5b9e\u641c\u7d22\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTaoSR-SHE\u5728\u63a8\u7406\u8d28\u91cf\u548c\u76f8\u5173\u6027\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u5747\u4f18\u4e8eSFT\u3001DPO\u3001GRPO\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u8fd8\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u7535\u5546\u641c\u7d22\u76f8\u5173\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.07978", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.07978", "abs": "https://arxiv.org/abs/2510.07978", "authors": ["Dhruv Jain", "Harshit Shukla", "Gautam Rajeev", "Ashish Kulkarni", "Chandra Khatri", "Shubham Agarwal"], "title": "VoiceAgentBench: Are Voice Assistants ready for agentic tasks?", "comment": null, "summary": "Large-scale Speech Language Models (SpeechLMs) have enabled voice assistants\ncapable of understanding natural spoken queries and performing complex tasks.\nHowever, existing speech benchmarks primarily focus on isolated capabilities\nsuch as transcription, or question-answering, and do not systematically\nevaluate agentic scenarios encompassing multilingual and cultural\nunderstanding, as well as adversarial robustness. To address this, we introduce\nVoiceAgentBench, a comprehensive benchmark designed to evaluate SpeechLMs in\nrealistic spoken agentic settings. It comprises over 5,500 synthetic spoken\nqueries, including dialogues grounded in Indian context, covering single-tool\ninvocations, multi-tool workflows, multi-turn interactions, and safety\nevaluations. The benchmark supports English, Hindi, and 5 other Indian\nlanguages, reflecting real-world linguistic and cultural diversity. We simulate\nspeaker variability using a novel sampling algorithm that selects audios for\nTTS voice conversion based on its speaker embeddings, maximizing acoustic and\nspeaker diversity. Our evaluation measures tool selection accuracy, structural\nconsistency, and the correctness of tool invocations, including adversarial\nrobustness. Our experiments reveal significant gaps in contextual tool\norchestration tasks, Indic generalization, and adversarial robustness, exposing\ncritical limitations of current SpeechLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86VoiceAgentBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u8bed\u97f3\u4ee3\u7406\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u5305\u542b5500\u591a\u4e2a\u5408\u6210\u8bed\u97f3\u67e5\u8be2\uff0c\u6db5\u76d6\u591a\u8bed\u8a00\u3001\u591a\u5de5\u5177\u8c03\u7528\u548c\u5b89\u5168\u6027\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u8bed\u97f3\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u5b64\u7acb\u80fd\u529b\u5982\u8f6c\u5f55\u6216\u95ee\u7b54\uff0c\u7f3a\u4e4f\u5bf9\u591a\u8bed\u8a00\u6587\u5316\u7406\u89e3\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002", "method": "\u521b\u5efa\u5305\u542b\u82f1\u8bed\u3001\u5370\u5730\u8bed\u548c5\u79cd\u5370\u5ea6\u8bed\u8a00\u7684\u8bed\u97f3\u67e5\u8be2\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u65b0\u9896\u7684\u91c7\u6837\u7b97\u6cd5\u6700\u5927\u5316\u58f0\u5b66\u548c\u8bf4\u8bdd\u4eba\u591a\u6837\u6027\uff0c\u8bc4\u4f30\u5de5\u5177\u9009\u62e9\u51c6\u786e\u6027\u3001\u7ed3\u6784\u4e00\u81f4\u6027\u548c\u5de5\u5177\u8c03\u7528\u6b63\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u5f53\u524d\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u5de5\u5177\u7f16\u6392\u4efb\u52a1\u3001\u5370\u5ea6\u8bed\u8a00\u6cdb\u5316\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "conclusion": "VoiceAgentBench\u66b4\u9732\u4e86\u5f53\u524d\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u4e3a\u6539\u8fdb\u591a\u8bed\u8a00\u8bed\u97f3\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u3002"}}
{"id": "2510.07988", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07988", "abs": "https://arxiv.org/abs/2510.07988", "authors": ["Haitao Jia", "Ming He", "Zimo Yin", "Likang Wu", "Jianping Fan", "Jitao Sang"], "title": "ReInAgent: A Context-Aware GUI Agent Enabling Human-in-the-Loop Mobile Task Navigation", "comment": null, "summary": "Mobile GUI agents exhibit substantial potential to facilitate and automate\nthe execution of user tasks on mobile phones. However, exist mobile GUI agents\npredominantly privilege autonomous operation and neglect the necessity of\nactive user engagement during task execution. This omission undermines their\nadaptability to information dilemmas including ambiguous, dynamically evolving,\nand conflicting task scenarios, leading to execution outcomes that deviate from\ngenuine user requirements and preferences. To address these shortcomings, we\npropose ReInAgent, a context-aware multi-agent framework that leverages dynamic\ninformation management to enable human-in-the-loop mobile task navigation.\nReInAgent integrates three specialized agents around a shared memory module: an\ninformation-managing agent for slot-based information management and proactive\ninteraction with the user, a decision-making agent for conflict-aware planning,\nand a reflecting agent for task reflection and information consistency\nvalidation. Through continuous contextual information analysis and sustained\nuser-agent collaboration, ReInAgent overcomes the limitation of existing\napproaches that rely on clear and static task assumptions. Consequently, it\nenables more adaptive and reliable mobile task navigation in complex,\nreal-world scenarios. Experimental results demonstrate that ReInAgent\neffectively resolves information dilemmas and produces outcomes that are more\nclosely aligned with genuine user preferences. Notably, on complex tasks\ninvolving information dilemmas, ReInAgent achieves a 25% higher success rate\nthan Mobile-Agent-v2.", "AI": {"tldr": "ReInAgent\u662f\u4e00\u4e2a\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u4fe1\u606f\u7ba1\u7406\u548c\u4eba\u673a\u534f\u4f5c\u89e3\u51b3\u79fb\u52a8GUI\u667a\u80fd\u4f53\u5728\u6a21\u7cca\u3001\u52a8\u6001\u548c\u51b2\u7a81\u4efb\u52a1\u573a\u666f\u4e2d\u7684\u4fe1\u606f\u56f0\u5883\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u79fb\u52a8GUI\u667a\u80fd\u4f53\u8fc7\u4e8e\u5f3a\u8c03\u81ea\u4e3b\u64cd\u4f5c\uff0c\u5ffd\u89c6\u4e86\u7528\u6237\u5728\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u4e3b\u52a8\u53c2\u4e0e\uff0c\u5bfc\u81f4\u5728\u4fe1\u606f\u56f0\u5883\u573a\u666f\u4e0b\u65e0\u6cd5\u9002\u5e94\u771f\u5b9e\u7528\u6237\u9700\u6c42\u548c\u504f\u597d\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\u56f4\u7ed5\u5171\u4eab\u5185\u5b58\u6a21\u5757\uff1a\u4fe1\u606f\u7ba1\u7406\u667a\u80fd\u4f53\u8d1f\u8d23\u57fa\u4e8e\u69fd\u4f4d\u7684\u4fe1\u606f\u7ba1\u7406\u548c\u4e3b\u52a8\u7528\u6237\u4ea4\u4e92\uff0c\u51b3\u7b56\u667a\u80fd\u4f53\u8d1f\u8d23\u51b2\u7a81\u611f\u77e5\u89c4\u5212\uff0c\u53cd\u601d\u667a\u80fd\u4f53\u8d1f\u8d23\u4efb\u52a1\u53cd\u601d\u548c\u4fe1\u606f\u4e00\u81f4\u6027\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eReInAgent\u6709\u6548\u89e3\u51b3\u4e86\u4fe1\u606f\u56f0\u5883\uff0c\u5728\u6d89\u53ca\u4fe1\u606f\u56f0\u5883\u7684\u590d\u6742\u4efb\u52a1\u4e0a\u6bd4Mobile-Agent-v2\u6210\u529f\u7387\u9ad8\u51fa25%\u3002", "conclusion": "\u901a\u8fc7\u6301\u7eed\u4e0a\u4e0b\u6587\u4fe1\u606f\u5206\u6790\u548c\u6301\u7eed\u7684\u4eba\u673a\u534f\u4f5c\uff0cReInAgent\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u6e05\u6670\u9759\u6001\u4efb\u52a1\u5047\u8bbe\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u5728\u590d\u6742\u771f\u5b9e\u573a\u666f\u4e2d\u66f4\u81ea\u9002\u5e94\u548c\u53ef\u9760\u7684\u79fb\u52a8\u4efb\u52a1\u5bfc\u822a\u3002"}}
{"id": "2510.08009", "categories": ["cs.AI", "cs.LG", "I.2"], "pdf": "https://arxiv.org/pdf/2510.08009", "abs": "https://arxiv.org/abs/2510.08009", "authors": ["Alex O. Davies", "Roussel Nzoyem", "Nirav Ajmeri", "Telmo M. Silva Filho"], "title": "Language Models Do Not Embed Numbers Continuously", "comment": "12 pages, 10 figures, 3 tables", "summary": "Recent research has extensively studied how large language models manipulate\nintegers in specific arithmetic tasks, and on a more fundamental level, how\nthey represent numeric values. These previous works have found that language\nmodel embeddings can be used to reconstruct the original values, however, they\ndo not evaluate whether language models actually model continuous values as\ncontinuous. Using expected properties of the embedding space, including linear\nreconstruction and principal component analysis, we show that language models\nnot only represent numeric spaces as non-continuous but also introduce\nsignificant noise. Using models from three major providers (OpenAI, Google\nGemini and Voyage AI), we show that while reconstruction is possible with high\nfidelity ($R^2 \\geq 0.95$), principal components only explain a minor share of\nvariation within the embedding space. This indicates that many components\nwithin the embedding space are orthogonal to the simple numeric input space.\nFurther, both linear reconstruction and explained variance suffer with\nincreasing decimal precision, despite the ordinal nature of the input space\nbeing fundamentally unchanged. The findings of this work therefore have\nimplications for the many areas where embedding models are used, in-particular\nwhere high numerical precision, large magnitudes or mixed-sign values are\ncommon.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u5728\u6570\u503c\u8868\u793a\u4e0a\u5b58\u5728\u975e\u8fde\u7eed\u6027\u548c\u663e\u8457\u566a\u58f0\uff0c\u5c3d\u7ba1\u80fd\u9ad8\u4fdd\u771f\u91cd\u5efa\u6570\u503c\uff0c\u4f46\u4e3b\u6210\u5206\u5206\u6790\u663e\u793a\u5d4c\u5165\u7a7a\u95f4\u5927\u90e8\u5206\u6210\u5206\u4e0e\u7b80\u5355\u6570\u503c\u8f93\u5165\u7a7a\u95f4\u6b63\u4ea4\uff0c\u4e14\u7cbe\u5ea6\u589e\u52a0\u65f6\u91cd\u5efa\u8d28\u91cf\u548c\u89e3\u91ca\u65b9\u5dee\u4f1a\u4e0b\u964d\u3002", "motivation": "\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u662f\u5426\u771f\u6b63\u5c06\u8fde\u7eed\u503c\u5efa\u6a21\u4e3a\u8fde\u7eed\u8868\u793a\uff0c\u4ee5\u53ca\u5b83\u4eec\u5728\u6570\u503c\u8868\u793a\u65b9\u9762\u7684\u5b9e\u9645\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u4e09\u4e2a\u4e3b\u8981\u63d0\u4f9b\u5546\uff08OpenAI\u3001Google Gemini\u548cVoyage AI\uff09\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u7ebf\u6027\u91cd\u5efa\u548c\u4e3b\u6210\u5206\u5206\u6790\u8bc4\u4f30\u5d4c\u5165\u7a7a\u95f4\u7684\u9884\u671f\u5c5e\u6027\u3002", "result": "\u867d\u7136\u91cd\u5efa\u53ef\u4ee5\u8fbe\u5230\u9ad8\u4fdd\u771f\u5ea6\uff08R\u00b2\u22650.95\uff09\uff0c\u4f46\u4e3b\u6210\u5206\u4ec5\u80fd\u89e3\u91ca\u5d4c\u5165\u7a7a\u95f4\u53d8\u5f02\u7684\u4e00\u5c0f\u90e8\u5206\uff0c\u8868\u660e\u8bb8\u591a\u5d4c\u5165\u7a7a\u95f4\u6210\u5206\u4e0e\u7b80\u5355\u6570\u503c\u8f93\u5165\u7a7a\u95f4\u6b63\u4ea4\u3002\u968f\u7740\u5341\u8fdb\u5236\u7cbe\u5ea6\u7684\u589e\u52a0\uff0c\u7ebf\u6027\u91cd\u5efa\u548c\u89e3\u91ca\u65b9\u5dee\u90fd\u4f1a\u4e0b\u964d\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u4e0d\u4ec5\u5c06\u6570\u503c\u7a7a\u95f4\u8868\u793a\u4e3a\u975e\u8fde\u7eed\u7684\uff0c\u8fd8\u5f15\u5165\u4e86\u663e\u8457\u566a\u58f0\uff0c\u8fd9\u5bf9\u9700\u8981\u9ad8\u6570\u503c\u7cbe\u5ea6\u3001\u5927\u6570\u503c\u8303\u56f4\u6216\u6df7\u5408\u7b26\u53f7\u503c\u7684\u5e94\u7528\u9886\u57df\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2510.08026", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08026", "abs": "https://arxiv.org/abs/2510.08026", "authors": ["Chen Huang", "Wei Lu", "Wenxuan Zhang"], "title": "PEAR: Phase Entropy Aware Reward for Efficient Reasoning", "comment": "15 pages, 6 figures", "summary": "Large Reasoning Models (LRMs) have achieved impressive performance on complex\nreasoning tasks by generating detailed chain-of-thought (CoT) explanations.\nHowever, these responses are often excessively long, containing redundant\nreasoning steps that inflate inference cost and reduce usability. Controlling\nthe length of generated reasoning without sacrificing accuracy remains an open\nchallenge. Through a systematic empirical analysis, we reveal a consistent\npositive correlation between model entropy and response length at different\nreasoning stages across diverse LRMs: the thinking phase exhibits higher\nentropy, reflecting exploratory behavior of longer responses, while the final\nanswer phase shows lower entropy, indicating a more deterministic solution.This\nobservation suggests that entropy at different reasoning stages can serve as a\ncontrol knob for balancing conciseness and performance. Based on this insight,\nthis paper introduces Phase Entropy Aware Reward (PEAR), a reward mechanism\nthat incorporating phase-dependent entropy into the reward design. Instead of\ntreating all tokens uniformly, PEAR penalize excessive entropy during the\nthinking phase and allowing moderate exploration at the final answer phase,\nwhich encourages models to generate concise reasoning traces that retain\nsufficient flexibility to solve the task correctly. This enables adaptive\ncontrol of response length without relying on explicit length targets or rigid\ntruncation rules. Extensive experiments across four benchmarks demonstrate that\nPEAR consistently reduces response length while sustaining competitive accuracy\nacross model scales. In addition, PEAR demonstrates strong out-of-distribution\n(OOD) robustness beyond the training distribution. Our code is available at:\nhttps://github.com/iNLP-Lab/PEAR.", "AI": {"tldr": "PEAR\u901a\u8fc7\u57fa\u4e8e\u63a8\u7406\u9636\u6bb5\u71b5\u7684\u5956\u52b1\u673a\u5236\uff0c\u5728\u4e0d\u727a\u7272\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u51cf\u5c11\u5927\u63a8\u7406\u6a21\u578b\u7684\u5197\u957f\u63a8\u7406\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u957f\u5ea6\u63a7\u5236\u3002", "motivation": "\u5927\u63a8\u7406\u6a21\u578b\u751f\u6210\u7684\u63a8\u7406\u8fc7\u7a0b\u5f80\u5f80\u8fc7\u4e8e\u5197\u957f\uff0c\u5305\u542b\u5197\u4f59\u63a8\u7406\u6b65\u9aa4\uff0c\u589e\u52a0\u4e86\u63a8\u7406\u6210\u672c\u5e76\u964d\u4f4e\u4e86\u53ef\u7528\u6027\u3002\u5982\u4f55\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u63a7\u5236\u63a8\u7406\u957f\u5ea6\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\u3002", "method": "\u63d0\u51faPEAR\u5956\u52b1\u673a\u5236\uff0c\u5c06\u9636\u6bb5\u4f9d\u8d56\u6027\u71b5\u7eb3\u5165\u5956\u52b1\u8bbe\u8ba1\uff0c\u5728\u601d\u8003\u9636\u6bb5\u60e9\u7f5a\u8fc7\u9ad8\u71b5\u503c\uff0c\u5728\u6700\u7ec8\u7b54\u6848\u9636\u6bb5\u5141\u8bb8\u9002\u5ea6\u63a2\u7d22\uff0c\u9f13\u52b1\u751f\u6210\u7b80\u6d01\u4f46\u6709\u6548\u7684\u63a8\u7406\u8f68\u8ff9\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPEAR\u80fd\u6301\u7eed\u51cf\u5c11\u54cd\u5e94\u957f\u5ea6\uff0c\u540c\u65f6\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0b\u4fdd\u6301\u7ade\u4e89\u529b\u51c6\u786e\u7387\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u5206\u5e03\u5916\u9c81\u68d2\u6027\u3002", "conclusion": "PEAR\u901a\u8fc7\u71b5\u611f\u77e5\u7684\u5956\u52b1\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u63a8\u7406\u957f\u5ea6\u7684\u81ea\u9002\u5e94\u63a7\u5236\uff0c\u4e3a\u5e73\u8861\u63a8\u7406\u6a21\u578b\u7684\u7b80\u6d01\u6027\u548c\u6027\u80fd\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08034", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08034", "abs": "https://arxiv.org/abs/2510.08034", "authors": ["Xiaoshuang Ji", "Zhendong Zhao", "Xiaoyan Gu", "Xiaojun Chen", "Xin Zhao", "Zeyao Liu"], "title": "AILoRA: Function-Aware Asymmetric Initialization for Low-Rank Adaptation of Large Language Models", "comment": "Submitted to AAAI2026", "summary": "Parameter-efficient finetuning (PEFT) aims to mitigate the substantial\ncomputational and memory overhead involved in adapting large-scale pretrained\nmodels to diverse downstream tasks. Among numerous PEFT strategies, Low-Rank\nAdaptation (LoRA) has emerged as one of the most widely adopted approaches due\nto its robust empirical performance and low implementation complexity. In\npractical deployment, LoRA is typically applied to the $W^Q$ and $W^V$\nprojection matrices of self-attention modules, enabling an effective trade-off\nbetween model performance and parameter efficiency. While LoRA has achieved\nconsiderable empirical success, it still encounters challenges such as\nsuboptimal performance and slow convergence. To address these limitations, we\nintroduce \\textbf{AILoRA}, a novel parameter-efficient method that incorporates\nfunction-aware asymmetric low-rank priors. Our empirical analysis reveals that\nthe projection matrices $W^Q$ and $W^V$ in the self-attention mechanism exhibit\ndistinct parameter characteristics, stemming from their functional differences.\nSpecifically, $W^Q$ captures task-specific semantic space knowledge essential\nfor attention distributions computation, making its parameters highly sensitive\nto downstream task variations. In contrast, $W^V$ encodes token-level feature\nrepresentations that tend to remain stable across tasks and layers. Leveraging\nthese insights, AILoRA performs a function-aware initialization by injecting\nthe principal components of $W^Q$ to retain task-adaptive capacity, and the\nminor components of $W^V$ to preserve generalizable feature representations.\nThis asymmetric initialization strategy enables LoRA modules to better capture\nthe specialized roles of attention parameters, thereby enhancing both\nfinetuning performance and convergence efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86AILoRA\u65b9\u6cd5\uff0c\u901a\u8fc7\u51fd\u6570\u611f\u77e5\u7684\u975e\u5bf9\u79f0\u4f4e\u79e9\u5148\u9a8c\u6765\u89e3\u51b3LoRA\u5728\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u4e2d\u7684\u6027\u80fd\u4e0d\u8db3\u548c\u6536\u655b\u6162\u95ee\u9898\u3002", "motivation": "LoRA\u867d\u7136\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u4ecd\u9762\u4e34\u6027\u80fd\u4e0d\u4f18\u548c\u6536\u655b\u6162\u7684\u6311\u6218\uff0c\u9700\u8981\u6539\u8fdb\u5176\u53c2\u6570\u521d\u59cb\u5316\u7b56\u7565\u3002", "method": "AILoRA\u5f15\u5165\u51fd\u6570\u611f\u77e5\u7684\u975e\u5bf9\u79f0\u4f4e\u79e9\u5148\u9a8c\uff0c\u5bf9\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u4e2d\u7684W^Q\u548cW^V\u6295\u5f71\u77e9\u9635\u91c7\u7528\u4e0d\u540c\u7684\u521d\u59cb\u5316\u7b56\u7565\uff1a\u4e3aW^Q\u6ce8\u5165\u4e3b\u6210\u5206\u4ee5\u4fdd\u7559\u4efb\u52a1\u9002\u5e94\u80fd\u529b\uff0c\u4e3aW^V\u6ce8\u5165\u6b21\u8981\u6210\u5206\u4ee5\u4fdd\u6301\u901a\u7528\u7279\u5f81\u8868\u793a\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u6ce8\u610f\u529b\u53c2\u6570\u7684\u4e13\u4e1a\u5316\u89d2\u8272\uff0c\u4ece\u800c\u63d0\u9ad8\u5fae\u8c03\u6027\u80fd\u548c\u6536\u655b\u6548\u7387\u3002", "conclusion": "AILoRA\u901a\u8fc7\u8003\u8651W^Q\u548cW^V\u7684\u529f\u80fd\u5dee\u5f02\uff0c\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u89e3\u51b3\u4e86LoRA\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.08046", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08046", "abs": "https://arxiv.org/abs/2510.08046", "authors": ["Qingyuan Shi", "Qingwen Meng", "Hao Cheng", "Qing Xu", "Jianqiang Wang"], "title": "LinguaSim: Interactive Multi-Vehicle Testing Scenario Generation via Natural Language Instruction Based on Large Language Models", "comment": null, "summary": "The generation of testing and training scenarios for autonomous vehicles has\ndrawn significant attention. While Large Language Models (LLMs) have enabled\nnew scenario generation methods, current methods struggle to balance command\nadherence accuracy with the realism of real-world driving environments. To\nreduce scenario description complexity, these methods often compromise realism\nby limiting scenarios to 2D, or open-loop simulations where background vehicles\nfollow predefined, non-interactive behaviors. We propose LinguaSim, an\nLLM-based framework that converts natural language into realistic, interactive\n3D scenarios, ensuring both dynamic vehicle interactions and faithful alignment\nbetween the input descriptions and the generated scenarios. A feedback\ncalibration module further refines the generation precision, improving fidelity\nto user intent. By bridging the gap between natural language and closed-loop,\ninteractive simulations, LinguaSim constrains adversarial vehicle behaviors\nusing both the scenario description and the autonomous driving model guiding\nthem. This framework facilitates the creation of high-fidelity scenarios that\nenhance safety testing and training. Experiments show LinguaSim can generate\nscenarios with varying criticality aligned with different natural language\ndescriptions (ACT: 0.072 s for dangerous vs. 3.532 s for safe descriptions;\ncomfortability: 0.654 vs. 0.764), and its refinement module effectively reduces\nexcessive aggressiveness in LinguaSim's initial outputs, lowering the crash\nrate from 46.9% to 6.3% to better match user intentions.", "AI": {"tldr": "LinguaSim\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5c06\u81ea\u7136\u8bed\u8a00\u8f6c\u6362\u4e3a\u771f\u5b9e\u3001\u4ea4\u4e92\u5f0f\u76843D\u573a\u666f\uff0c\u786e\u4fdd\u52a8\u6001\u8f66\u8f86\u4ea4\u4e92\u548c\u8f93\u5165\u63cf\u8ff0\u4e0e\u751f\u6210\u573a\u666f\u7684\u51c6\u786e\u5bf9\u9f50\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u573a\u666f\u751f\u6210\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u6307\u4ee4\u9075\u5faa\u51c6\u786e\u6027\u4e0e\u771f\u5b9e\u4e16\u754c\u9a7e\u9a76\u73af\u5883\u7684\u771f\u5b9e\u6027\uff0c\u901a\u5e38\u901a\u8fc7\u9650\u5236\u573a\u666f\u4e3a2D\u6216\u5f00\u653e\u5faa\u73af\u6a21\u62df\u6765\u964d\u4f4e\u590d\u6742\u5ea6\uff0c\u727a\u7272\u4e86\u771f\u5b9e\u611f\u3002", "method": "\u63d0\u51faLinguaSim\u6846\u67b6\uff0c\u5305\u542b\u53cd\u9988\u6821\u51c6\u6a21\u5757\u6765\u4f18\u5316\u751f\u6210\u7cbe\u5ea6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4e0e\u95ed\u73af\u4ea4\u4e92\u6a21\u62df\u7684\u6865\u6881\uff0c\u7ea6\u675f\u5bf9\u6297\u6027\u8f66\u8f86\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u663e\u793aLinguaSim\u80fd\u751f\u6210\u4e0d\u540c\u5173\u952e\u6027\u573a\u666f\uff08\u5371\u9669\u63cf\u8ff0ACT\uff1a0.072\u79d2 vs \u5b89\u5168\u63cf\u8ff0\uff1a3.532\u79d2\uff1b\u8212\u9002\u5ea6\uff1a0.654 vs 0.764\uff09\uff0c\u7cbe\u70bc\u6a21\u5757\u5c06\u78b0\u649e\u7387\u4ece46.9%\u964d\u81f36.3%\u3002", "conclusion": "LinguaSim\u80fd\u591f\u521b\u5efa\u9ad8\u4fdd\u771f\u573a\u666f\uff0c\u589e\u5f3a\u5b89\u5168\u6d4b\u8bd5\u548c\u8bad\u7ec3\uff0c\u6709\u6548\u5f25\u5408\u81ea\u7136\u8bed\u8a00\u4e0e\u4ea4\u4e92\u5f0f\u6a21\u62df\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2510.08075", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08075", "abs": "https://arxiv.org/abs/2510.08075", "authors": ["Qingyang Hao", "Wenbo Liao", "Bingyi Jing", "Hongxin Wei"], "title": "Multi-Condition Conformal Selection", "comment": null, "summary": "Selecting high-quality candidates from large-scale datasets is critically\nimportant in resource-constrained applications such as drug discovery,\nprecision medicine, and the alignment of large language models. While conformal\nselection methods offer a rigorous solution with False Discovery Rate (FDR)\ncontrol, their applicability is confined to single-threshold scenarios (i.e., y\n> c) and overlooks practical needs for multi-condition selection, such as\nconjunctive or disjunctive conditions. In this work, we propose the\nMulti-Condition Conformal Selection (MCCS) algorithm, which extends conformal\nselection to scenarios with multiple conditions. In particular, we introduce a\nnovel nonconformity score with regional monotonicity for conjunctive conditions\nand a global Benjamini-Hochberg (BH) procedure for disjunctive conditions,\nthereby establishing finite-sample FDR control with theoretical guarantees. The\nintegration of these components enables the proposed method to achieve rigorous\nFDR-controlled selection in various multi-condition environments. Extensive\nexperiments validate the superiority of MCCS over baselines, its\ngeneralizability across diverse condition combinations, different real-world\nmodalities, and multi-task scalability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u591a\u6761\u4ef6\u7b26\u5408\u9009\u62e9(MCCS)\u7b97\u6cd5\uff0c\u5c06\u7b26\u5408\u9009\u62e9\u6269\u5c55\u5230\u591a\u6761\u4ef6\u573a\u666f\uff0c\u5305\u62ec\u5408\u53d6\u548c\u6790\u53d6\u6761\u4ef6\uff0c\u5b9e\u73b0\u4e86\u6709\u9650\u6837\u672cFDR\u63a7\u5236\u7684\u7406\u8bba\u4fdd\u8bc1\u3002", "motivation": "\u5728\u836f\u7269\u53d1\u73b0\u3001\u7cbe\u51c6\u533b\u5b66\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u7b49\u8d44\u6e90\u53d7\u9650\u5e94\u7528\u4e2d\uff0c\u4ece\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e2d\u9009\u62e9\u9ad8\u8d28\u91cf\u5019\u9009\u8005\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7b26\u5408\u9009\u62e9\u65b9\u6cd5\u4ec5\u9650\u4e8e\u5355\u9608\u503c\u573a\u666f\uff0c\u65e0\u6cd5\u6ee1\u8db3\u591a\u6761\u4ef6\u9009\u62e9\u7684\u5b9e\u9645\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86MCCS\u7b97\u6cd5\uff0c\u4e3a\u5408\u53d6\u6761\u4ef6\u5f15\u5165\u4e86\u5177\u6709\u533a\u57df\u5355\u8c03\u6027\u7684\u65b0\u975e\u7b26\u5408\u6027\u8bc4\u5206\uff0c\u4e3a\u6790\u53d6\u6761\u4ef6\u5f15\u5165\u4e86\u5168\u5c40Benjamini-Hochberg(BH)\u7a0b\u5e8f\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86MCCS\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u7684\u4f18\u8d8a\u6027\uff0c\u5176\u5728\u591a\u6837\u5316\u6761\u4ef6\u7ec4\u5408\u3001\u4e0d\u540c\u73b0\u5b9e\u4e16\u754c\u6a21\u6001\u548c\u591a\u4efb\u52a1\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MCCS\u7b97\u6cd5\u80fd\u591f\u5728\u5404\u79cd\u591a\u6761\u4ef6\u73af\u5883\u4e2d\u5b9e\u73b0\u4e25\u683c\u7684FDR\u63a7\u5236\u9009\u62e9\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u6761\u4ef6\u573a\u666f\u4e0b\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.08081", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.08081", "abs": "https://arxiv.org/abs/2510.08081", "authors": ["Xiaochong Lan", "Jie Feng", "Yinxing Liu", "Xinlei Shi", "Yong Li"], "title": "AutoQual: An LLM Agent for Automated Discovery of Interpretable Features for Review Quality Assessment", "comment": "EMNLP 2025", "summary": "Ranking online reviews by their intrinsic quality is a critical task for\ne-commerce platforms and information services, impacting user experience and\nbusiness outcomes. However, quality is a domain-dependent and dynamic concept,\nmaking its assessment a formidable challenge. Traditional methods relying on\nhand-crafted features are unscalable across domains and fail to adapt to\nevolving content patterns, while modern deep learning approaches often produce\nblack-box models that lack interpretability and may prioritize semantics over\nquality. To address these challenges, we propose AutoQual, an LLM-based agent\nframework that automates the discovery of interpretable features. While\ndemonstrated on review quality assessment, AutoQual is designed as a general\nframework for transforming tacit knowledge embedded in data into explicit,\ncomputable features. It mimics a human research process, iteratively generating\nfeature hypotheses through reflection, operationalizing them via autonomous\ntool implementation, and accumulating experience in a persistent memory. We\ndeploy our method on a large-scale online platform with a billion-level user\nbase. Large-scale A/B testing confirms its effectiveness, increasing average\nreviews viewed per user by 0.79% and the conversion rate of review readers by\n0.27%.", "AI": {"tldr": "AutoQual\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u53d1\u73b0\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u7279\u522b\u9488\u5bf9\u5728\u7ebf\u8bc4\u8bba\u8d28\u91cf\u8bc4\u4f30\u3002\u5b83\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u7814\u7a76\u8fc7\u7a0b\uff0c\u8fed\u4ee3\u751f\u6210\u7279\u5f81\u5047\u8bbe\u5e76\u5b9e\u73b0\u5de5\u5177\u5316\uff0c\u5728\u5927\u578b\u7535\u5546\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u624b\u5de5\u7279\u5f81\uff0c\u96be\u4ee5\u8de8\u9886\u57df\u6269\u5c55\u548c\u9002\u5e94\u5185\u5bb9\u6a21\u5f0f\u53d8\u5316\uff1b\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u4e14\u53ef\u80fd\u8fc7\u5ea6\u5173\u6ce8\u8bed\u4e49\u800c\u975e\u8d28\u91cf\u3002\u9700\u8981\u4e00\u79cd\u80fd\u81ea\u52a8\u53d1\u73b0\u53ef\u89e3\u91ca\u7279\u5f81\u7684\u65b9\u6cd5\u3002", "method": "AutoQual\u6846\u67b6\u6a21\u62df\u4eba\u7c7b\u7814\u7a76\u8fc7\u7a0b\uff1a\u901a\u8fc7\u53cd\u601d\u8fed\u4ee3\u751f\u6210\u7279\u5f81\u5047\u8bbe\uff0c\u901a\u8fc7\u81ea\u4e3b\u5de5\u5177\u5b9e\u73b0\u7279\u5f81\u64cd\u4f5c\u5316\uff0c\u5e76\u5728\u6301\u4e45\u5185\u5b58\u4e2d\u79ef\u7d2f\u7ecf\u9a8c\u3002", "result": "\u5728\u62e5\u6709\u6570\u5341\u4ebf\u7528\u6237\u7684\u5927\u578b\u5728\u7ebf\u5e73\u53f0\u4e0a\u90e8\u7f72\uff0cA/B\u6d4b\u8bd5\u663e\u793a\uff1a\u6bcf\u4f4d\u7528\u6237\u5e73\u5747\u67e5\u770b\u8bc4\u8bba\u6570\u589e\u52a00.79%\uff0c\u8bc4\u8bba\u9605\u8bfb\u8005\u7684\u8f6c\u5316\u7387\u63d0\u9ad80.27%\u3002", "conclusion": "AutoQual\u6210\u529f\u5c06\u6570\u636e\u4e2d\u7684\u9690\u6027\u77e5\u8bc6\u8f6c\u5316\u4e3a\u663e\u6027\u3001\u53ef\u8ba1\u7b97\u7684\u7279\u5f81\uff0c\u4e0d\u4ec5\u9002\u7528\u4e8e\u8bc4\u8bba\u8d28\u91cf\u8bc4\u4f30\uff0c\u8fd8\u53ef\u4f5c\u4e3a\u901a\u7528\u6846\u67b6\u5e94\u7528\u4e8e\u5176\u4ed6\u9886\u57df\u3002"}}
{"id": "2510.08086", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08086", "abs": "https://arxiv.org/abs/2510.08086", "authors": ["Sukriti Bhattacharya", "Chitro Majumdar"], "title": "From Ethical Declarations to Provable Independence: An Ontology-Driven Optimal-Transport Framework for Certifiably Fair AI Systems", "comment": "19 pages, 2 figures", "summary": "This paper presents a framework for provably fair AI that overcomes the\nlimits of current bias mitigation methods by systematically removing all\nsensitive information and its proxies. Using ontology engineering in OWL 2 QL,\nit formally defines sensitive attributes and infers their proxies through\nlogical reasoning, constructing a sigma algebra G that captures the full\nstructure of biased patterns. Fair representations are then obtained via\nDelbaen Majumdar optimal transport, which generates variables independent of G\nwhile minimizing L2 distance to preserve accuracy. This guarantees true\nindependence rather than mere decorrelation. By modeling bias as dependence\nbetween sigma algebras, compiling ontological knowledge into measurable\nstructures, and using optimal transport as the unique fair transformation, the\napproach ensures complete fairness in tasks like loan approval, where proxies\nsuch as ZIP code reveal race. The result is a certifiable and mathematically\ngrounded method for trustworthy AI.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u8bc1\u660e\u516c\u5e73\u7684AI\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u79fb\u9664\u654f\u611f\u4fe1\u606f\u53ca\u5176\u4ee3\u7406\u53d8\u91cf\u6765\u514b\u670d\u5f53\u524d\u504f\u89c1\u7f13\u89e3\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524d\u504f\u89c1\u7f13\u89e3\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u65e0\u6cd5\u5b8c\u5168\u6d88\u9664\u654f\u611f\u4fe1\u606f\u53ca\u5176\u4ee3\u7406\u53d8\u91cf\u5bf9AI\u51b3\u7b56\u7684\u5f71\u54cd\uff0c\u9700\u8981\u4e00\u79cd\u6570\u5b66\u4e0a\u53ef\u8bc1\u660e\u7684\u516c\u5e73\u6027\u4fdd\u8bc1\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528OWL 2 QL\u672c\u4f53\u5de5\u7a0b\u5f62\u5f0f\u5316\u5b9a\u4e49\u654f\u611f\u5c5e\u6027\uff0c\u901a\u8fc7\u903b\u8f91\u63a8\u7406\u63a8\u65ad\u4ee3\u7406\u53d8\u91cf\uff0c\u6784\u5efa\u6355\u83b7\u504f\u89c1\u6a21\u5f0f\u7684sigma\u4ee3\u6570G\uff0c\u7136\u540e\u901a\u8fc7Delbaen Majumdar\u6700\u4f18\u4f20\u8f93\u83b7\u5f97\u516c\u5e73\u8868\u793a\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u4e0eG\u72ec\u7acb\u7684\u53d8\u91cf\uff0c\u540c\u65f6\u6700\u5c0f\u5316L2\u8ddd\u79bb\u4ee5\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u4fdd\u8bc1\u771f\u6b63\u7684\u72ec\u7acb\u6027\u800c\u4e0d\u4ec5\u4ec5\u662f\u53bb\u76f8\u5173\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u8ba4\u8bc1\u4e14\u6570\u5b66\u57fa\u7840\u624e\u5b9e\u7684\u65b9\u6cd5\uff0c\u786e\u4fdd\u5728\u8d37\u6b3e\u5ba1\u6279\u7b49\u4efb\u52a1\u4e2d\u7684\u5b8c\u5168\u516c\u5e73\u6027\uff0c\u5176\u4e2dZIP\u4ee3\u7801\u7b49\u4ee3\u7406\u53d8\u91cf\u53ef\u80fd\u63ed\u793a\u79cd\u65cf\u4fe1\u606f\u3002"}}
{"id": "2510.08114", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.08114", "abs": "https://arxiv.org/abs/2510.08114", "authors": ["Ali Mazyaki", "Mohammad Naghizadeh", "Samaneh Ranjkhah Zonouzaghi", "Amirhossein Farshi Sotoudeh"], "title": "Can Risk-taking AI-Assistants suitably represent entities", "comment": null, "summary": "Responsible AI demands systems whose behavioral tendencies can be effectively\nmeasured, audited, and adjusted to prevent inadvertently nudging users toward\nrisky decisions or embedding hidden biases in risk aversion. As language models\n(LMs) are increasingly incorporated into AI-driven decision support systems,\nunderstanding their risk behaviors is crucial for their responsible deployment.\nThis study investigates the manipulability of risk aversion (MoRA) in LMs,\nexamining their ability to replicate human risk preferences across diverse\neconomic scenarios, with a focus on gender-specific attitudes, uncertainty,\nrole-based decision-making, and the manipulability of risk aversion. The\nresults indicate that while LMs such as DeepSeek Reasoner and\nGemini-2.0-flash-lite exhibit some alignment with human behaviors, notable\ndiscrepancies highlight the need to refine bio-centric measures of\nmanipulability. These findings suggest directions for refining AI design to\nbetter align human and AI risk preferences and enhance ethical decision-making.\nThe study calls for further advancements in model design to ensure that AI\nsystems more accurately replicate human risk preferences, thereby improving\ntheir effectiveness in risk management contexts. This approach could enhance\nthe applicability of AI assistants in managing risk.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8c03\u67e5\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u98ce\u9669\u538c\u6076\u65b9\u9762\u7684\u53ef\u64cd\u7eb5\u6027\uff0c\u53d1\u73b0\u867d\u7136\u67d0\u4e9b\u6a21\u578b\u4e0e\u4eba\u7c7b\u884c\u4e3a\u6709\u4e00\u5b9a\u4e00\u81f4\u6027\uff0c\u4f46\u4ecd\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u9700\u8981\u6539\u8fdb\u751f\u7269\u4e2d\u5fc3\u7684\u53ef\u64cd\u7eb5\u6027\u6d4b\u91cf\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u878d\u5165AI\u9a71\u52a8\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u7406\u89e3\u5176\u98ce\u9669\u884c\u4e3a\u5bf9\u4e8e\u8d1f\u8d23\u4efb\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u9632\u6b62\u7cfb\u7edf\u65e0\u610f\u4e2d\u5c06\u7528\u6237\u63a8\u5411\u98ce\u9669\u51b3\u7b56\u6216\u5d4c\u5165\u9690\u85cf\u504f\u89c1\u3002", "method": "\u7814\u7a76\u8003\u5bdf\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u7ecf\u6d4e\u573a\u666f\u4e2d\u590d\u5236\u4eba\u7c7b\u98ce\u9669\u504f\u597d\u7684\u80fd\u529b\uff0c\u91cd\u70b9\u5173\u6ce8\u6027\u522b\u7279\u5b9a\u6001\u5ea6\u3001\u4e0d\u786e\u5b9a\u6027\u3001\u57fa\u4e8e\u89d2\u8272\u7684\u51b3\u7b56\u4ee5\u53ca\u98ce\u9669\u538c\u6076\u7684\u53ef\u64cd\u7eb5\u6027\u3002", "result": "DeepSeek Reasoner\u548cGemini-2.0-flash-lite\u7b49\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u4e0e\u4eba\u7c7b\u884c\u4e3a\u7684\u4e00\u4e9b\u4e00\u81f4\u6027\uff0c\u4f46\u663e\u8457\u5dee\u5f02\u7a81\u663e\u4e86\u9700\u8981\u6539\u8fdb\u751f\u7269\u4e2d\u5fc3\u7684\u53ef\u64cd\u7eb5\u6027\u6d4b\u91cf\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u547c\u5401\u8fdb\u4e00\u6b65\u6539\u8fdb\u6a21\u578b\u8bbe\u8ba1\uff0c\u786e\u4fddAI\u7cfb\u7edf\u66f4\u51c6\u786e\u5730\u590d\u5236\u4eba\u7c7b\u98ce\u9669\u504f\u597d\uff0c\u4ece\u800c\u5728\u98ce\u9669\u7ba1\u7406\u73af\u5883\u4e2d\u63d0\u9ad8\u5176\u6709\u6548\u6027\uff0c\u589e\u5f3aAI\u52a9\u624b\u5728\u98ce\u9669\u7ba1\u7406\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2510.08175", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08175", "abs": "https://arxiv.org/abs/2510.08175", "authors": ["Jinling Gan", "Churong Liang", "Runnan Li"], "title": "Prepared mind, fast response: A temporal decoupling framework for adaptive knowledge orchestration in open-domain dialogue", "comment": null, "summary": "The latency-quality tradeoff is a fundamental constraint in open-domain\ndialogue AI systems, since comprehensive knowledge access necessitates\nprohibitive response delays. Contemporary approaches offer two inadequate\nsolutions: lightweight instruct models achieve sub-second latency but lack\nreasoning depth, while tool-augmented ReAct agents enhance factuality through\nexternal knowledge at the cost of synchronous execution that blocks interaction\nduring retrieval processes. PMFR is thus proposed, with a temporal decoupling\nframework that fundamentally resolves the contradiction through asynchronous\nknowledge orchestration. PMFR employs three coordinated components: (1) a\nKnowledge Adequacy Evaluator for real-time sufficiency assessment, (2) a\nLightweight Response Generator for immediate user interaction, and (3) an\nAsynchronous Knowledge Refinement Agent for background knowledge enhancement.\nThis architecture maintains continuous conversational flow while progressively\nenriching knowledge coverage through intelligent triggering mechanisms.\nEvaluation results on TopiOCQA demonstrate PMFR outperforms brute-force\nscaling: PMFR achieves 95.3% latency reduction (23.38s -> 1.09s) while\npreserving response quality comparable to heavyweight synchronous baselines\n(GEval-C: 0.613 vs. 0.620).", "AI": {"tldr": "PMFR\u63d0\u51fa\u4e86\u4e00\u79cd\u5f02\u6b65\u77e5\u8bc6\u7f16\u6392\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u77e5\u8bc6\u68c0\u7d22\u4e0e\u5bf9\u8bdd\u54cd\u5e94\uff0c\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u89e3\u51b3\u5f00\u653e\u57df\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u5ef6\u8fdf\u4e0e\u8d28\u91cf\u7684\u6839\u672c\u77db\u76fe\uff1a\u8f7b\u91cf\u6a21\u578b\u5ef6\u8fdf\u4f4e\u4f46\u63a8\u7406\u6df1\u5ea6\u4e0d\u8db3\uff0c\u5de5\u5177\u589e\u5f3a\u4ee3\u7406\u8d28\u91cf\u9ad8\u4f46\u540c\u6b65\u6267\u884c\u5bfc\u81f4\u5ef6\u8fdf\u8fc7\u9ad8\u3002", "method": "\u91c7\u7528\u4e09\u7ec4\u4ef6\u67b6\u6784\uff1a\u77e5\u8bc6\u5145\u8db3\u6027\u8bc4\u4f30\u5668\uff08\u5b9e\u65f6\u8bc4\u4f30\uff09\u3001\u8f7b\u91cf\u54cd\u5e94\u751f\u6210\u5668\uff08\u5373\u65f6\u4ea4\u4e92\uff09\u3001\u5f02\u6b65\u77e5\u8bc6\u7cbe\u70bc\u4ee3\u7406\uff08\u540e\u53f0\u77e5\u8bc6\u589e\u5f3a\uff09\uff0c\u901a\u8fc7\u667a\u80fd\u89e6\u53d1\u673a\u5236\u5b9e\u73b0\u5f02\u6b65\u77e5\u8bc6\u7f16\u6392\u3002", "result": "\u5728TopiOCQA\u4e0a\u8bc4\u4f30\uff0cPMFR\u5b9e\u73b095.3%\u5ef6\u8fdf\u964d\u4f4e\uff0823.38s\u21921.09s\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u91cd\u91cf\u7ea7\u540c\u6b65\u57fa\u7ebf\u76f8\u5f53\u7684\u54cd\u5e94\u8d28\u91cf\uff08GEval-C: 0.613 vs. 0.620\uff09\u3002", "conclusion": "PMFR\u901a\u8fc7\u65f6\u95f4\u89e3\u8026\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5bf9\u8bdd\u7cfb\u7edf\u7684\u5ef6\u8fdf-\u8d28\u91cf\u6743\u8861\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5f02\u6b65\u77e5\u8bc6\u7f16\u6392\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.08189", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.08189", "abs": "https://arxiv.org/abs/2510.08189", "authors": ["Yi Lu", "Jianing Wang", "Linsen Guo", "Wei He", "Hongyin Tang", "Tao Gui", "Xuanjing Huang", "Xuezhi Cao", "Wei Wang", "Xunliang Cai"], "title": "R-Horizon: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?", "comment": null, "summary": "Recent trends in test-time scaling for reasoning models (e.g., OpenAI o1,\nDeepSeek-R1) have led to remarkable improvements through long Chain-of-Thought\n(CoT). However, existing benchmarks mainly focus on immediate, single-horizon\ntasks, failing to adequately evaluate models' ability to understand and respond\nto complex, long-horizon scenarios. To address this incomplete evaluation of\nLarge Reasoning Models (LRMs), we propose R-HORIZON, a method designed to\nstimulate long-horizon reasoning behaviors in LRMs through query composition.\nBased on R-HORIZON, we construct a long-horizon reasoning benchmark, comprising\ncomplex multi-step reasoning tasks with interdependent problems that span long\nreasoning horizons. Through comprehensive evaluation of LRMs using the\nR-HORIZON benchmark, we find that even the most advanced LRMs suffer\nsignificant performance degradation. Our analysis reveals that LRMs exhibit\nlimited effective reasoning length and struggle to allocate thinking budget\nacross multiple problems appropriately. Recognizing these limitations, we use\nR-HORIZON to construct long-horizon reasoning data for reinforcement learning\nwith verified rewards (RLVR). Compared to training with single-horizon data,\nRLVR with R-HORIZON not only substantially improves performance on the\nmulti-horizon reasoning tasks, but also promotes accuracy on standard reasoning\ntasks, with an increase of 7.5 on AIME2024. These results position R-HORIZON as\na scalable, controllable, and low-cost paradigm for enhancing and evaluating\nthe long-horizon reasoning capabilities of LRMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86R-HORIZON\u65b9\u6cd5\u6765\u8bc4\u4f30\u548c\u589e\u5f3a\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u957f\u89c6\u91ce\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u67e5\u8be2\u7ec4\u5408\u6784\u5efa\u591a\u6b65\u9aa4\u63a8\u7406\u4efb\u52a1\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u957f\u89c6\u91ce\u63a8\u7406\u4e2d\u5b58\u5728\u663e\u8457\u6027\u80fd\u4e0b\u964d\uff0c\u5e76\u5229\u7528\u8be5\u65b9\u6cd5\u751f\u6210\u6570\u636e\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u5373\u65f6\u3001\u5355\u89c6\u91ce\u4efb\u52a1\uff0c\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u6a21\u578b\u7406\u89e3\u548c\u5e94\u5bf9\u590d\u6742\u957f\u89c6\u91ce\u573a\u666f\u7684\u80fd\u529b\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u6d4b\u8bd5\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u957f\u89c6\u91ce\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faR-HORIZON\u65b9\u6cd5\uff0c\u901a\u8fc7\u67e5\u8be2\u7ec4\u5408\u523a\u6fc0\u957f\u89c6\u91ce\u63a8\u7406\u884c\u4e3a\uff0c\u6784\u5efa\u5305\u542b\u590d\u6742\u591a\u6b65\u9aa4\u63a8\u7406\u4efb\u52a1\u7684\u957f\u89c6\u91ce\u63a8\u7406\u57fa\u51c6\uff0c\u5e76\u5229\u7528\u8be5\u57fa\u51c6\u751f\u6210\u6570\u636e\u7528\u4e8e\u5e26\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60(RLVR)\u3002", "result": "\u8bc4\u4f30\u53d1\u73b0\u5373\u4f7f\u6700\u5148\u8fdb\u7684\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u957f\u89c6\u91ce\u63a8\u7406\u4e2d\u4e5f\u5b58\u5728\u663e\u8457\u6027\u80fd\u4e0b\u964d\uff0c\u6a21\u578b\u8868\u73b0\u51fa\u6709\u9650\u7684\u6709\u6548\u63a8\u7406\u957f\u5ea6\u548c\u8de8\u95ee\u9898\u601d\u8003\u9884\u7b97\u5206\u914d\u56f0\u96be\u3002RLVR\u8bad\u7ec3\u4f7f\u7528R-HORIZON\u6570\u636e\u4e0d\u4ec5\u5927\u5e45\u63d0\u5347\u591a\u89c6\u91ce\u63a8\u7406\u4efb\u52a1\u6027\u80fd\uff0c\u8fd8\u5728\u6807\u51c6\u63a8\u7406\u4efb\u52a1\u4e0a\u63d0\u9ad8\u51c6\u786e\u6027\uff0cAIME2024\u63d0\u53477.5\u5206\u3002", "conclusion": "R-HORIZON\u4e3a\u589e\u5f3a\u548c\u8bc4\u4f30\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u957f\u89c6\u91ce\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u63a7\u4e14\u4f4e\u6210\u672c\u7684\u8303\u5f0f\u3002"}}
{"id": "2510.08193", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08193", "abs": "https://arxiv.org/abs/2510.08193", "authors": ["Rashid Mushkani"], "title": "Measuring What Matters: The AI Pluralism Index", "comment": null, "summary": "Artificial intelligence systems increasingly mediate knowledge,\ncommunication, and decision making. Development and governance remain\nconcentrated within a small set of firms and states, raising concerns that\ntechnologies may encode narrow interests and limit public agency. Capability\nbenchmarks for language, vision, and coding are common, yet public, auditable\nmeasures of pluralistic governance are rare. We define AI pluralism as the\ndegree to which affected stakeholders can shape objectives, data practices,\nsafeguards, and deployment. We present the AI Pluralism Index (AIPI), a\ntransparent, evidence-based instrument that evaluates producers and system\nfamilies across four pillars: participatory governance, inclusivity and\ndiversity, transparency, and accountability. AIPI codes verifiable practices\nfrom public artifacts and independent evaluations, explicitly handling\n\"Unknown\" evidence to report both lower-bound (\"evidence\") and known-only\nscores with coverage. We formalize the measurement model; implement a\nreproducible pipeline that integrates structured web and repository analysis,\nexternal assessments, and expert interviews; and assess reliability with\ninter-rater agreement, coverage reporting, cross-index correlations, and\nsensitivity analysis. The protocol, codebook, scoring scripts, and evidence\ngraph are maintained openly with versioned releases and a public adjudication\nprocess. We report pilot provider results and situate AIPI relative to adjacent\ntransparency, safety, and governance frameworks. The index aims to steer\nincentives toward pluralistic practice and to equip policymakers, procurers,\nand the public with comparable evidence.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86AI\u591a\u5143\u6027\u6307\u6570\uff08AIPI\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u900f\u660e\u3001\u57fa\u4e8e\u8bc1\u636e\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u7528\u4e8e\u8861\u91cfAI\u751f\u4ea7\u5546\u548c\u7cfb\u7edf\u5728\u591a\u5143\u6cbb\u7406\u65b9\u9762\u7684\u8868\u73b0\uff0c\u5305\u62ec\u53c2\u4e0e\u5f0f\u6cbb\u7406\u3001\u5305\u5bb9\u6027\u3001\u900f\u660e\u5ea6\u548c\u95ee\u8d23\u5236\u56db\u4e2a\u652f\u67f1\u3002", "motivation": "\u5f53\u524dAI\u53d1\u5c55\u548c\u6cbb\u7406\u96c6\u4e2d\u5728\u5c11\u6570\u516c\u53f8\u548c\u56fd\u5bb6\u624b\u4e2d\uff0c\u53ef\u80fd\u5bfc\u81f4\u6280\u672f\u7f16\u7801\u72ed\u9698\u5229\u76ca\u5e76\u9650\u5236\u516c\u4f17\u53c2\u4e0e\u3002\u73b0\u6709\u80fd\u529b\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u8bed\u8a00\u3001\u89c6\u89c9\u548c\u7f16\u7801\uff0c\u4f46\u7f3a\u4e4f\u53ef\u5ba1\u8ba1\u7684\u591a\u5143\u6cbb\u7406\u8861\u91cf\u6807\u51c6\u3002", "method": "\u5f00\u53d1AIPI\u6d4b\u91cf\u6a21\u578b\uff0c\u5b9e\u73b0\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u6d41\u7a0b\uff0c\u6574\u5408\u7ed3\u6784\u5316\u7f51\u7edc\u548c\u4ed3\u5e93\u5206\u6790\u3001\u5916\u90e8\u8bc4\u4f30\u548c\u4e13\u5bb6\u8bbf\u8c08\uff0c\u901a\u8fc7\u8bc4\u5206\u8005\u95f4\u4e00\u81f4\u6027\u3001\u8986\u76d6\u5ea6\u62a5\u544a\u3001\u8de8\u6307\u6570\u76f8\u5173\u6027\u548c\u654f\u611f\u6027\u5206\u6790\u8bc4\u4f30\u53ef\u9760\u6027\u3002", "result": "\u62a5\u544a\u4e86\u8bd5\u70b9\u4f9b\u5e94\u5546\u7ed3\u679c\uff0c\u5e76\u5c06AIPI\u4e0e\u90bb\u8fd1\u7684\u900f\u660e\u5ea6\u3001\u5b89\u5168\u548c\u6cbb\u7406\u6846\u67b6\u8fdb\u884c\u5bf9\u6bd4\u5b9a\u4f4d\u3002", "conclusion": "AIPI\u65e8\u5728\u5f15\u5bfc\u6fc0\u52b1\u63aa\u65bd\u8f6c\u5411\u591a\u5143\u5b9e\u8df5\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u3001\u91c7\u8d2d\u65b9\u548c\u516c\u4f17\u63d0\u4f9b\u53ef\u6bd4\u8f83\u7684\u8bc1\u636e\u3002"}}
{"id": "2510.08197", "categories": ["cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.08197", "abs": "https://arxiv.org/abs/2510.08197", "authors": ["Diego Garc\u00eda-Zamora", "\u00c1lvaro Labella", "Jos\u00e9 Rui Figueira"], "title": "The Tournament Tree Method for preference elicitation in Multi-criteria decision-making", "comment": null, "summary": "Pairwise comparison methods, such as Fuzzy Preference Relations and Saaty's\nMultiplicative Preference Relations, are widely used to model expert judgments\nin multi-criteria decision-making. However, their application is limited by the\nhigh cognitive load required to complete $m(m-1)/2$ comparisons, the risk of\ninconsistency, and the computational complexity of deriving consistent value\nscales. This paper proposes the Tournament Tree Method (TTM), a novel\nelicitation and evaluation framework that overcomes these limitations. The TTM\nrequires only $m-1$ pairwise comparisons to obtain a complete, reciprocal, and\nconsistent comparison matrix. The method consists of three phases: (i)\nelicitation of expert judgments using a reduced set of targeted comparisons,\n(ii) construction of the consistent pairwise comparison matrix, and (iii)\nderivation of a global value scale from the resulting matrix. The proposed\napproach ensures consistency by design, minimizes cognitive effort, and reduces\nthe dimensionality of preference modeling from $m(m-1)/2$ to $m$ parameters.\nFurthermore, it is compatible with the classical Deck of Cards method, and thus\nit can handle interval and ratio scales. We have also developed a web-based\ntool that demonstrates its practical applicability in real decision-making\nscenarios.", "AI": {"tldr": "\u63d0\u51fa\u9526\u6807\u8d5b\u6811\u65b9\u6cd5(TTM)\uff0c\u4e00\u79cd\u65b0\u7684\u504f\u597d\u5173\u7cfb\u83b7\u53d6\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u53ea\u9700m-1\u6b21\u4e24\u4e24\u6bd4\u8f83\u5c31\u80fd\u83b7\u5f97\u5b8c\u6574\u3001\u4e92\u53cd\u4e14\u4e00\u81f4\u7684\u6bd4\u8f83\u77e9\u9635\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba4\u77e5\u8d1f\u62c5\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u4f20\u7edf\u4e24\u4e24\u6bd4\u8f83\u65b9\u6cd5\u9700\u8981m(m-1)/2\u6b21\u6bd4\u8f83\uff0c\u8ba4\u77e5\u8d1f\u62c5\u91cd\uff0c\u5b58\u5728\u4e0d\u4e00\u81f4\u98ce\u9669\uff0c\u4e14\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u9650\u5236\u4e86\u5728\u591a\u51c6\u5219\u51b3\u7b56\u4e2d\u7684\u5e94\u7528\u3002", "method": "TTM\u65b9\u6cd5\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a(i)\u4f7f\u7528\u7cbe\u7b80\u7684\u76ee\u6807\u6bd4\u8f83\u96c6\u83b7\u53d6\u4e13\u5bb6\u5224\u65ad\uff0c(ii)\u6784\u5efa\u4e00\u81f4\u7684\u4e24\u4e24\u6bd4\u8f83\u77e9\u9635\uff0c(iii)\u4ece\u7ed3\u679c\u77e9\u9635\u63a8\u5bfc\u5168\u5c40\u4ef7\u503c\u5c3a\u5ea6\u3002\u8be5\u65b9\u6cd5\u5c06\u504f\u597d\u5efa\u6a21\u7ef4\u5ea6\u4ecem(m-1)/2\u964d\u81f3m\u4e2a\u53c2\u6570\u3002", "result": "TTM\u65b9\u6cd5\u80fd\u591f\u786e\u4fdd\u4e00\u81f4\u6027\uff0c\u6700\u5c0f\u5316\u8ba4\u77e5\u52aa\u529b\uff0c\u4e0e\u7ecf\u5178\u5361\u7247\u6cd5\u517c\u5bb9\uff0c\u53ef\u5904\u7406\u533a\u95f4\u548c\u6bd4\u7387\u5c3a\u5ea6\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8eweb\u7684\u5de5\u5177\u5c55\u793a\u5176\u5b9e\u9645\u5e94\u7528\u6027\u3002", "conclusion": "\u9526\u6807\u8d5b\u6811\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u4e24\u4e24\u6bd4\u8f83\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u591a\u51c6\u5219\u51b3\u7b56\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u4e00\u81f4\u7684\u504f\u597d\u5efa\u6a21\u6846\u67b6\u3002"}}
{"id": "2510.08207", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08207", "abs": "https://arxiv.org/abs/2510.08207", "authors": ["Matteo Gregorini", "Chiara Boldrini", "Lorenzo Valerio"], "title": "DODO: Causal Structure Learning with Budgeted Interventions", "comment": "Under review. Supported by SoBigData\\.it IR0000013, FAIR PE00000013,\n  ICSC CN00000013", "summary": "Artificial Intelligence has achieved remarkable advancements in recent years,\nyet much of its progress relies on identifying increasingly complex\ncorrelations. Enabling causality awareness in AI has the potential to enhance\nits performance by enabling a deeper understanding of the underlying mechanisms\nof the environment. In this paper, we introduce DODO, an algorithm defining how\nan Agent can autonomously learn the causal structure of its environment through\nrepeated interventions. We assume a scenario where an Agent interacts with a\nworld governed by a causal Directed Acyclic Graph (DAG), which dictates the\nsystem's dynamics but remains hidden from the Agent. The Agent's task is to\naccurately infer the causal DAG, even in the presence of noise. To achieve\nthis, the Agent performs interventions, leveraging causal inference techniques\nto analyze the statistical significance of observed changes. Results show\nbetter performance for DODO, compared to observational approaches, in all but\nthe most limited resource conditions. DODO is often able to reconstruct with as\nlow as zero errors the structure of the causal graph. In the most challenging\nconfiguration, DODO outperforms the best baseline by +0.25 F1 points.", "AI": {"tldr": "DODO\u7b97\u6cd5\u8ba9\u667a\u80fd\u4f53\u901a\u8fc7\u91cd\u590d\u5e72\u9884\u81ea\u4e3b\u5b66\u4e60\u73af\u5883\u7684\u56e0\u679c\u7ed3\u6784\uff0c\u5728\u566a\u58f0\u5b58\u5728\u4e0b\u51c6\u786e\u63a8\u65ad\u56e0\u679c\u6709\u5411\u65e0\u73af\u56fe\uff0c\u76f8\u6bd4\u89c2\u6d4b\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u5f53\u524dAI\u4e3b\u8981\u4f9d\u8d56\u590d\u6742\u76f8\u5173\u6027\uff0c\u800c\u5f15\u5165\u56e0\u679c\u610f\u8bc6\u80fd\u589e\u5f3aAI\u5bf9\u5e95\u5c42\u673a\u5236\u7684\u7406\u89e3\uff0c\u63d0\u5347\u6027\u80fd\u3002", "method": "\u667a\u80fd\u4f53\u5728\u4e0e\u56e0\u679cDAG\u652f\u914d\u7684\u4e16\u754c\u4ea4\u4e92\u4e2d\uff0c\u901a\u8fc7\u6267\u884c\u5e72\u9884\u5e76\u5229\u7528\u56e0\u679c\u63a8\u65ad\u6280\u672f\u5206\u6790\u89c2\u6d4b\u53d8\u5316\u7684\u7edf\u8ba1\u663e\u8457\u6027\u6765\u5b66\u4e60\u56e0\u679c\u7ed3\u6784\u3002", "result": "DODO\u5728\u9664\u6700\u6709\u9650\u8d44\u6e90\u6761\u4ef6\u5916\u7684\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u4f18\u4e8e\u89c2\u6d4b\u65b9\u6cd5\uff0c\u901a\u5e38\u80fd\u4ee5\u96f6\u8bef\u5dee\u91cd\u5efa\u56e0\u679c\u56fe\u7ed3\u6784\uff0c\u5728\u6700\u6311\u6218\u6027\u914d\u7f6e\u4e2d\u6bd4\u6700\u4f73\u57fa\u7ebf\u9ad8\u51fa+0.25 F1\u5206\u6570\u3002", "conclusion": "\u901a\u8fc7\u81ea\u4e3b\u5e72\u9884\u5b66\u4e60\u56e0\u679c\u7ed3\u6784\u7684\u65b9\u6cd5\u6709\u6548\uff0cDODO\u7b97\u6cd5\u5728\u56e0\u679c\u56fe\u63a8\u65ad\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.08222", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08222", "abs": "https://arxiv.org/abs/2510.08222", "authors": ["Yunlong Deng", "Boyang Sun", "Yan Li", "Lingjing Kong", "Zeyu Tang", "Kun Zhang", "Guangyi Chen"], "title": "Selection, Reflection and Self-Refinement: Revisit Reasoning Tasks via a Causal Lens", "comment": null, "summary": "Due to their inherent complexity, reasoning tasks have long been regarded as\nrigorous benchmarks for assessing the capabilities of machine learning models,\nespecially large language models (LLMs). Although humans can solve these tasks\nwith ease, existing models, even after extensive pre-training and post-training\nat scale, still fail to perform reasoning reliably. In this paper, we revisit\nreasoning tasks from a causal perspective, seeking to understand their behavior\nin latent space and to offer insights for addressing their challenges.\nSpecifically, we cast reasoning tasks as a selection mechanism, in which\nhigh-level logical concepts function as selection operators on the given\nobservations, such as, identifying the correct answer in a math problem or\nfilling the appropriate entry in Sudoku. We emphasize two key properties of\nthis formulation that shed light on the difficulty of reasoning tasks. First,\nthe latent space exceeds the observation space in complexity, even when the\ncorrect answer is fully determined by the observed input. Second, the latent\nvariables, corresponding to logical thought, are densely structured and exhibit\nstrong dependencies. Building on this formulation, we introduce a framework,\ncalled SR$^2$, that incorporates the estimated latent variables as feedback\ninto the selection mechanism, thereby facilitating the learning of dense\ndependencies among latent representations. The framework consists of three key\nmodules: reflective representation learning, dependency self-refinement, and\nperiodic intermediate alignment. Experimentally, we show that our approach\nyields significant gains in reasoning accuracy, for example, attaining over\n10$\\%$ improvement in performance with 8$\\times$ fewer parameters on the Sudoku\nand Maze tasks over the recent advances.", "AI": {"tldr": "\u672c\u6587\u4ece\u56e0\u679c\u89c6\u89d2\u91cd\u65b0\u5ba1\u89c6\u63a8\u7406\u4efb\u52a1\uff0c\u5c06\u63a8\u7406\u5efa\u6a21\u4e3a\u9009\u62e9\u673a\u5236\uff0c\u63d0\u51faSR\u00b2\u6846\u67b6\u901a\u8fc7\u6f5c\u5728\u53d8\u91cf\u53cd\u9988\u6765\u5b66\u4e60\u5bc6\u96c6\u4f9d\u8d56\u5173\u7cfb\uff0c\u5728\u63a8\u7406\u51c6\u786e\u6027\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u5c3d\u7ba1\u4eba\u7c7b\u80fd\u8f7b\u677e\u89e3\u51b3\u63a8\u7406\u4efb\u52a1\uff0c\u4f46\u73b0\u6709\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4ecd\u96be\u4ee5\u53ef\u9760\u5730\u8fdb\u884c\u63a8\u7406\u3002\u672c\u6587\u65e8\u5728\u4ece\u56e0\u679c\u89d2\u5ea6\u7406\u89e3\u63a8\u7406\u4efb\u52a1\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u884c\u4e3a\uff0c\u4e3a\u89e3\u51b3\u63a8\u7406\u6311\u6218\u63d0\u4f9b\u89c1\u89e3\u3002", "method": "\u63d0\u51faSR\u00b2\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u6a21\u5757\uff1a\u53cd\u5c04\u8868\u793a\u5b66\u4e60\u3001\u4f9d\u8d56\u81ea\u7cbe\u70bc\u548c\u5468\u671f\u6027\u4e2d\u95f4\u5bf9\u9f50\u3002\u8be5\u6846\u67b6\u5c06\u4f30\u8ba1\u7684\u6f5c\u5728\u53d8\u91cf\u4f5c\u4e3a\u53cd\u9988\u7eb3\u5165\u9009\u62e9\u673a\u5236\uff0c\u4fc3\u8fdb\u6f5c\u5728\u8868\u793a\u95f4\u5bc6\u96c6\u4f9d\u8d56\u5173\u7cfb\u7684\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u63a8\u7406\u51c6\u786e\u6027\u4e0a\u5e26\u6765\u663e\u8457\u63d0\u5347\uff0c\u4f8b\u5982\u5728\u6570\u72ec\u548c\u8ff7\u5bab\u4efb\u52a1\u4e0a\uff0c\u4f7f\u75288\u500d\u66f4\u5c11\u7684\u53c2\u6570\u5b9e\u73b0\u4e86\u8d85\u8fc710%\u7684\u6027\u80fd\u6539\u8fdb\u3002", "conclusion": "\u4ece\u56e0\u679c\u89c6\u89d2\u5c06\u63a8\u7406\u4efb\u52a1\u5efa\u6a21\u4e3a\u9009\u62e9\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u6f5c\u5728\u53d8\u91cf\u53cd\u9988\u5b66\u4e60\u5bc6\u96c6\u4f9d\u8d56\u5173\u7cfb\u7684\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.08238", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08238", "abs": "https://arxiv.org/abs/2510.08238", "authors": ["Jiyang Qiu", "Xinbei Ma", "Yunqing Xu", "Zhuosheng Zhang", "Hai Zhao"], "title": "Chain-of-Trigger: An Agentic Backdoor that Paradoxically Enhances Agentic Robustness", "comment": null, "summary": "The rapid deployment of large language model (LLM)-based agents in real-world\napplications has raised serious concerns about their trustworthiness. In this\nwork, we reveal the security and robustness vulnerabilities of these agents\nthrough backdoor attacks. Distinct from traditional backdoors limited to\nsingle-step control, we propose the Chain-of-Trigger Backdoor (CoTri), a\nmulti-step backdoor attack designed for long-horizon agentic control. CoTri\nrelies on an ordered sequence. It starts with an initial trigger, and\nsubsequent ones are drawn from the environment, allowing multi-step\nmanipulation that diverts the agent from its intended task. Experimental\nresults show that CoTri achieves a near-perfect attack success rate (ASR) while\nmaintaining a near-zero false trigger rate (FTR). Due to training data modeling\nthe stochastic nature of the environment, the implantation of CoTri\nparadoxically enhances the agent's performance on benign tasks and even\nimproves its robustness against environmental distractions. We further validate\nCoTri on vision-language models (VLMs), confirming its scalability to\nmultimodal agents. Our work highlights that CoTri achieves stable, multi-step\ncontrol within agents, improving their inherent robustness and task\ncapabilities, which ultimately makes the attack more stealthy and raises\npotential safty risks.", "AI": {"tldr": "\u63d0\u51faCoTri\u591a\u6b65\u540e\u95e8\u653b\u51fb\uff0c\u901a\u8fc7\u6709\u5e8f\u89e6\u53d1\u5e8f\u5217\u5b9e\u73b0\u5bf9LLM\u667a\u80fd\u4f53\u7684\u957f\u671f\u64cd\u63a7\uff0c\u653b\u51fb\u6210\u529f\u7387\u63a5\u8fd1100%\u4e14\u8bef\u89e6\u53d1\u7387\u63a5\u8fd1\u96f6\uff0c\u540c\u65f6\u610f\u5916\u589e\u5f3a\u4e86\u667a\u80fd\u4f53\u5728\u826f\u6027\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u968f\u7740LLM\u667a\u80fd\u4f53\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u5feb\u901f\u90e8\u7f72\uff0c\u5176\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u5f15\u53d1\u4e25\u91cd\u62c5\u5fe7\uff0c\u9700\u8981\u63ed\u793a\u8fd9\u7c7b\u667a\u80fd\u4f53\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u8bbe\u8ba1Chain-of-Trigger Backdoor (CoTri)\u591a\u6b65\u540e\u95e8\u653b\u51fb\uff0c\u4f7f\u7528\u6709\u5e8f\u89e6\u53d1\u5e8f\u5217\uff0c\u521d\u59cb\u89e6\u53d1\u540e\u4ece\u73af\u5883\u4e2d\u63d0\u53d6\u540e\u7eed\u89e6\u53d1\uff0c\u5b9e\u73b0\u591a\u6b65\u64cd\u63a7\u4f7f\u667a\u80fd\u4f53\u504f\u79bb\u539f\u4efb\u52a1\u3002", "result": "CoTri\u8fbe\u5230\u63a5\u8fd1\u5b8c\u7f8e\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u8bef\u89e6\u53d1\u7387\u63a5\u8fd1\u96f6\u3002\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u5efa\u6a21\u4e86\u73af\u5883\u7684\u968f\u673a\u6027\uff0c\u690d\u5165CoTri\u53cd\u800c\u589e\u5f3a\u4e86\u667a\u80fd\u4f53\u5728\u826f\u6027\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u548c\u5bf9\u73af\u5883\u5e72\u6270\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "CoTri\u5b9e\u73b0\u4e86\u5bf9\u667a\u80fd\u4f53\u7684\u7a33\u5b9a\u591a\u6b65\u63a7\u5236\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u5176\u56fa\u6709\u9c81\u68d2\u6027\u548c\u4efb\u52a1\u80fd\u529b\uff0c\u4f7f\u653b\u51fb\u66f4\u52a0\u9690\u853d\uff0c\u5e26\u6765\u6f5c\u5728\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2510.08263", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08263", "abs": "https://arxiv.org/abs/2510.08263", "authors": ["Shunyu An", "Miao Wang", "Yongchao Li", "Dong Wan", "Lina Wang", "Ling Qin", "Liqin Gao", "Congyao Fan", "Zhiyong Mao", "Jiange Pu", "Wenji Xia", "Dong Zhao", "Rui Hu", "Ji Lu", "Guiyue Zhou", "Baoyu Tang", "Yanqin Gao", "Yongsheng Du", "Daigang Xu", "Lingjun Huang", "Baoli Wang", "Xiwen Zhang", "Luyao Wang", "Shilong Liu"], "title": "Co-TAP: Three-Layer Agent Interaction Protocol Technical Report", "comment": null, "summary": "This paper proposes Co-TAP (T: Triple, A: Agent, P: Protocol), a three-layer\nagent interaction protocol designed to address the challenges faced by\nmulti-agent systems across the three core dimensions of Interoperability,\nInteraction and Collaboration, and Knowledge Sharing. We have designed and\nproposed a layered solution composed of three core protocols: the Human-Agent\nInteraction Protocol (HAI), the Unified Agent Protocol (UAP), and the\nMemory-Extraction-Knowledge Protocol (MEK). HAI focuses on the interaction\nlayer, standardizing the flow of information between users, interfaces, and\nagents by defining a standardized, event-driven communication paradigm. This\nensures the real-time performance, reliability, and synergy of interactions. As\nthe core of the infrastructure layer, UAP is designed to break down\ncommunication barriers among heterogeneous agents through unified service\ndiscovery and protocol conversion mechanisms, thereby enabling seamless\ninterconnection and interoperability of the underlying network. MEK, in turn,\noperates at the cognitive layer. By establishing a standardized ''Memory (M) -\nExtraction (E) - Knowledge (K)'' cognitive chain, it empowers agents with the\nability to learn from individual experiences and form shareable knowledge,\nthereby laying the foundation for the realization of true collective\nintelligence. We believe this protocol framework will provide a solid\nengineering foundation and theoretical guidance for building the next\ngeneration of efficient, scalable, and intelligent multi-agent applications.", "AI": {"tldr": "Co-TAP\u662f\u4e00\u4e2a\u4e09\u5c42\u4ee3\u7406\u4ea4\u4e92\u534f\u8bae\uff0c\u901a\u8fc7HAI\u3001UAP\u548cMEK\u4e09\u4e2a\u6838\u5fc3\u534f\u8bae\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u4e92\u64cd\u4f5c\u6027\u3001\u4ea4\u4e92\u534f\u4f5c\u548c\u77e5\u8bc6\u5171\u4eab\u65b9\u9762\u7684\u6311\u6218\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u4e09\u4e2a\u6838\u5fc3\u7ef4\u5ea6\u9762\u4e34\u7684\u6311\u6218\uff1a\u4e92\u64cd\u4f5c\u6027\u3001\u4ea4\u4e92\u534f\u4f5c\u548c\u77e5\u8bc6\u5171\u4eab\uff0c\u4e3a\u6784\u5efa\u4e0b\u4e00\u4ee3\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u548c\u667a\u80fd\u7684\u591a\u667a\u80fd\u4f53\u5e94\u7528\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e09\u5c42\u534f\u8bae\uff1aHAI\uff08\u4eba\u673a\u4ea4\u4e92\u534f\u8bae\uff09\u6807\u51c6\u5316\u7528\u6237\u3001\u754c\u9762\u548c\u4ee3\u7406\u4e4b\u95f4\u7684\u4fe1\u606f\u6d41\uff1bUAP\uff08\u7edf\u4e00\u4ee3\u7406\u534f\u8bae\uff09\u901a\u8fc7\u7edf\u4e00\u670d\u52a1\u53d1\u73b0\u548c\u534f\u8bae\u8f6c\u6362\u5b9e\u73b0\u5f02\u6784\u4ee3\u7406\u4e92\u8fde\uff1bMEK\uff08\u8bb0\u5fc6-\u63d0\u53d6-\u77e5\u8bc6\u534f\u8bae\uff09\u5efa\u7acb\u6807\u51c6\u5316\u8ba4\u77e5\u94fe\u5b9e\u73b0\u77e5\u8bc6\u5171\u4eab\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u534f\u8bae\u6846\u67b6\uff0c\u80fd\u591f\u786e\u4fdd\u5b9e\u65f6\u6027\u80fd\u3001\u53ef\u9760\u6027\u3001\u4ea4\u4e92\u534f\u540c\u6027\uff0c\u5b9e\u73b0\u5f02\u6784\u4ee3\u7406\u7684\u65e0\u7f1d\u4e92\u8fde\uff0c\u5e76\u4e3a\u5b9e\u73b0\u771f\u6b63\u96c6\u4f53\u667a\u80fd\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "Co-TAP\u534f\u8bae\u6846\u67b6\u4e3a\u6784\u5efa\u4e0b\u4e00\u4ee3\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u548c\u667a\u80fd\u7684\u591a\u667a\u80fd\u4f53\u5e94\u7528\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u5de5\u7a0b\u57fa\u7840\u548c\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2510.08300", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08300", "abs": "https://arxiv.org/abs/2510.08300", "authors": ["Bart Kuipers", "Freek Byrman", "Daniel Uyterlinde", "Alejandro Garc\u00eda-Castellanos"], "title": "Symmetry-Aware Fully-Amortized Optimization with Scale Equivariant Graph Metanetworks", "comment": null, "summary": "Amortized optimization accelerates the solution of related optimization\nproblems by learning mappings that exploit shared structure across problem\ninstances. We explore the use of Scale Equivariant Graph Metanetworks\n(ScaleGMNs) for this purpose. By operating directly in weight space, ScaleGMNs\nenable single-shot fine-tuning of existing models, reducing the need for\niterative optimization. We demonstrate the effectiveness of this approach\nempirically and provide a theoretical result: the gauge freedom induced by\nscaling symmetries is strictly smaller in convolutional neural networks than in\nmulti-layer perceptrons. This insight helps explain the performance differences\nobserved between architectures in both our work and that of Kalogeropoulos et\nal. (2024). Overall, our findings underscore the potential of symmetry-aware\nmetanetworks as a powerful approach for efficient and generalizable neural\nnetwork optimization. Open-source code:\nhttps://github.com/daniuyter/scalegmn_amortization", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u5c3a\u5ea6\u7b49\u53d8\u56fe\u5143\u7f51\u7edc(ScaleGMNs)\u8fdb\u884c\u644a\u9500\u4f18\u5316\uff0c\u901a\u8fc7\u5728\u6743\u91cd\u7a7a\u95f4\u4e2d\u76f4\u63a5\u64cd\u4f5c\u5b9e\u73b0\u73b0\u6709\u6a21\u578b\u7684\u5355\u6b21\u5fae\u8c03\uff0c\u51cf\u5c11\u8fed\u4ee3\u4f18\u5316\u9700\u6c42\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u5c3a\u5ea6\u5bf9\u79f0\u6027\u8bf1\u5bfc\u7684\u89c4\u8303\u81ea\u7531\u5ea6\u6bd4\u591a\u5c42\u611f\u77e5\u673a\u66f4\u5c0f\uff0c\u8fd9\u89e3\u91ca\u4e86\u4e0d\u540c\u67b6\u6784\u95f4\u7684\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u63a2\u7d22\u5229\u7528\u5c3a\u5ea6\u7b49\u53d8\u56fe\u5143\u7f51\u7edc\u6765\u52a0\u901f\u76f8\u5173\u4f18\u5316\u95ee\u9898\u7684\u6c42\u89e3\uff0c\u901a\u8fc7\u5b66\u4e60\u5229\u7528\u95ee\u9898\u5b9e\u4f8b\u95f4\u5171\u4eab\u7ed3\u6784\u7684\u6620\u5c04\uff0c\u51cf\u5c11\u8fed\u4ee3\u4f18\u5316\u7684\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u5c3a\u5ea6\u7b49\u53d8\u56fe\u5143\u7f51\u7edc(ScaleGMNs)\u76f4\u63a5\u5728\u6743\u91cd\u7a7a\u95f4\u4e2d\u64cd\u4f5c\uff0c\u5b9e\u73b0\u5bf9\u73b0\u6709\u6a21\u578b\u7684\u5355\u6b21\u5fae\u8c03\uff0c\u907f\u514d\u4f20\u7edf\u7684\u8fed\u4ee3\u4f18\u5316\u8fc7\u7a0b\u3002", "result": "\u5b9e\u8bc1\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u7ed3\u679c\uff1a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e2d\u5c3a\u5ea6\u5bf9\u79f0\u6027\u8bf1\u5bfc\u7684\u89c4\u8303\u81ea\u7531\u5ea6\u6bd4\u591a\u5c42\u611f\u77e5\u673a\u66f4\u5c0f\uff0c\u8fd9\u89e3\u91ca\u4e86\u4e0d\u540c\u67b6\u6784\u95f4\u7684\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u5bf9\u79f0\u611f\u77e5\u7684\u5143\u7f51\u7edc\u662f\u9ad8\u6548\u4e14\u53ef\u6cdb\u5316\u7684\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u7684\u6709\u529b\u65b9\u6cd5\uff0c\u5177\u6709\u91cd\u8981\u6f5c\u529b\u3002"}}
{"id": "2510.08308", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08308", "abs": "https://arxiv.org/abs/2510.08308", "authors": ["Liwei Kang", "Yue Deng", "Yao Xiao", "Zhanfeng Mo", "Wee Sun Lee", "Lidong Bing"], "title": "First Try Matters: Revisiting the Role of Reflection in Reasoning Models", "comment": null, "summary": "Large language models have recently demonstrated significant gains in\nreasoning ability, often attributed to their capacity to generate longer chains\nof thought and engage in reflective reasoning. However, the contribution of\nreflections to performance improvement remains unclear. In this paper, we\nsystematically analyze the rollouts of eight reasoning models on five\nmathematical datasets. We focus on reflective behaviours where the model has\nalready produced an answer but continues reflecting before finalizing its\noutput. Our analysis reveals that reflections are predominantly confirmatory\nand rarely alter the model's initial answer, a pattern consistent across models\nand datasets. To understand the role of reflections in training, we construct\nsupervised fine-tuning (SFT) datasets with varying amounts of reflection steps.\nWe observe that training models on rollouts with more reflection steps\nprimarily enhances first-answer correctness rather than the ability to correct\ninitially wrong answers through reflections. This motivates us to propose a\nquestion-aware early-stopping method that enhances inference-time token\nefficiency by stopping the reasoning process once a few plausible candidate\nanswers are generated, thereby reducing unnecessary reflection steps. Motivated\nby this, we further propose to dynamically truncate the reflections after a\ncandidate answer has appeared during generation, which reduces reasoning tokens\nby 24.5% across five mathematical datasets, within a 2.9% drop in accuracy.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u53cd\u601d\u884c\u4e3a\uff0c\u53d1\u73b0\u53cd\u601d\u4e3b\u8981\u662f\u786e\u8ba4\u6027\u7684\uff0c\u5f88\u5c11\u6539\u53d8\u521d\u59cb\u7b54\u6848\u3002\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\uff0c\u8bad\u7ec3\u66f4\u591a\u53cd\u601d\u6b65\u9aa4\u4e3b\u8981\u63d0\u9ad8\u9996\u6b21\u7b54\u6848\u6b63\u786e\u7387\uff0c\u800c\u975e\u901a\u8fc7\u53cd\u601d\u7ea0\u6b63\u9519\u8bef\u7684\u80fd\u529b\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u95ee\u9898\u611f\u77e5\u7684\u65e9\u505c\u65b9\u6cd5\uff0c\u53ef\u51cf\u5c1124.5%\u7684\u63a8\u7406token\uff0c\u51c6\u786e\u7387\u4ec5\u4e0b\u964d2.9%\u3002", "motivation": "\u7814\u7a76\u53cd\u601d\u884c\u4e3a\u5728\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u5347\u4e2d\u7684\u5b9e\u9645\u8d21\u732e\uff0c\u63a2\u7d22\u53cd\u601d\u662f\u5426\u771f\u6b63\u6709\u52a9\u4e8e\u7ea0\u6b63\u521d\u59cb\u9519\u8bef\u7b54\u6848\uff0c\u4ee5\u53ca\u5982\u4f55\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u3002", "method": "\u7cfb\u7edf\u5206\u67908\u4e2a\u63a8\u7406\u6a21\u578b\u57285\u4e2a\u6570\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u63a8\u7406\u8fc7\u7a0b\uff1b\u6784\u5efa\u4e0d\u540c\u53cd\u601d\u6b65\u9aa4\u7684SFT\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff1b\u63d0\u51fa\u95ee\u9898\u611f\u77e5\u65e9\u505c\u65b9\u6cd5\uff0c\u5728\u751f\u6210\u5019\u9009\u7b54\u6848\u540e\u52a8\u6001\u622a\u65ad\u53cd\u601d\u3002", "result": "\u53cd\u601d\u4e3b\u8981\u662f\u786e\u8ba4\u6027\u7684\uff0c\u5f88\u5c11\u6539\u53d8\u521d\u59cb\u7b54\u6848\uff1b\u8bad\u7ec3\u66f4\u591a\u53cd\u601d\u6b65\u9aa4\u4e3b\u8981\u63d0\u9ad8\u9996\u6b21\u7b54\u6848\u6b63\u786e\u7387\uff1b\u65e9\u505c\u65b9\u6cd5\u53ef\u51cf\u5c1124.5%\u63a8\u7406token\uff0c\u51c6\u786e\u7387\u4ec5\u4e0b\u964d2.9%\u3002", "conclusion": "\u53cd\u601d\u5728\u63a8\u7406\u4e2d\u4e3b\u8981\u8d77\u786e\u8ba4\u4f5c\u7528\u800c\u975e\u7ea0\u9519\u4f5c\u7528\uff1b\u901a\u8fc7\u52a8\u6001\u622a\u65ad\u53cd\u601d\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u63a8\u7406\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u51c6\u786e\u7387\u3002"}}
{"id": "2510.08325", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.08325", "abs": "https://arxiv.org/abs/2510.08325", "authors": ["Marius Dragoi", "Ioana Pintilie", "Florin Gogianu", "Florin Brad"], "title": "Beyond Pass@k: Breadth-Depth Metrics for Reasoning Boundaries", "comment": "10 pages, 3 figures", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a\npowerful paradigm to improve Large Language Models on reasoning tasks such as\ncoding, math or logic. To assess the reasoning boundary (the fraction of\nproblems a model can solve) researchers often report Pass@k at large sampling\nbudgets. Recent results reveal a crossover phenomenon: while RLVR models\noutperform the base model at small k values, the base model usually outperforms\nthem when sampling a very large number of completions. This has been\ninterpreted as evidence that base models have a larger reasoning boundary. We\nargue that on tasks with discrete answer spaces, such as math with numeric\noutputs, Pass@k at large k reflects the increasingly higher chance of success\nin the limit of the number of trials rather than genuine reasoning, and can\ntherefore be misleading. We propose Cover@tau, which measures the fraction of\nproblems that a model can solve for which at least a tau proportion of\ncompletions are correct. Unlike Pass@k, Cover@tau captures reasoning under an\nexplicit reliability threshold: models that rely on random guessing degrade\nrapidly as tau increases. We evaluate several RLVR models using Cover@tau-based\nmetrics and illustrate how the relative rankings of popular algorithms change\ncompared to Pass@1, offering a different perspective on reasoning boundaries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCover@tau\u6307\u6807\u66ff\u4ee3Pass@k\u6765\u8bc4\u4f30LLM\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u8ba4\u4e3aPass@k\u5728\u5927\u91c7\u6837\u9884\u7b97\u4e0b\u4f1a\u9ad8\u4f30\u968f\u673a\u731c\u6d4b\u7684\u6548\u679c\uff0c\u800cCover@tau\u80fd\u66f4\u597d\u5730\u53cd\u6620\u6a21\u578b\u7684\u771f\u5b9e\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5Pass@k\u5728\u5927\u91c7\u6837\u9884\u7b97\u4e0b\u5b58\u5728\u8bef\u5bfc\u6027\uff0c\u56e0\u4e3a\u5b83\u53cd\u6620\u4e86\u5728\u5927\u91cf\u5c1d\u8bd5\u4e0b\u7684\u6210\u529f\u6982\u7387\u800c\u975e\u771f\u5b9e\u63a8\u7406\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u79bb\u6563\u7b54\u6848\u7a7a\u95f4\u7684\u4efb\u52a1\u4e2d\u3002", "method": "\u63d0\u51faCover@tau\u8bc4\u4f30\u6307\u6807\uff0c\u8861\u91cf\u6a21\u578b\u5728\u81f3\u5c11tau\u6bd4\u4f8b\u8865\u5168\u6b63\u786e\u7684\u60c5\u51b5\u4e0b\u80fd\u89e3\u51b3\u7684\u95ee\u9898\u6bd4\u4f8b\uff0c\u8be5\u6307\u6807\u80fd\u6709\u6548\u8bc6\u522b\u4f9d\u8d56\u968f\u673a\u731c\u6d4b\u7684\u6a21\u578b\u3002", "result": "\u4f7f\u7528Cover@tau\u8bc4\u4f30\u591a\u4e2aRLVR\u6a21\u578b\uff0c\u53d1\u73b0\u4e0ePass@1\u76f8\u6bd4\uff0c\u6d41\u884c\u7b97\u6cd5\u7684\u76f8\u5bf9\u6392\u540d\u53d1\u751f\u4e86\u53d8\u5316\uff0c\u63d0\u4f9b\u4e86\u5bf9\u63a8\u7406\u8fb9\u754c\u7684\u4e0d\u540c\u89c6\u89d2\u3002", "conclusion": "Cover@tau\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u6a21\u578b\u63a8\u7406\u80fd\u529b\u8bc4\u4f30\u65b9\u6cd5\uff0c\u80fd\u66f4\u597d\u5730\u533a\u5206\u771f\u5b9e\u63a8\u7406\u548c\u968f\u673a\u731c\u6d4b\uff0c\u4e3aRLVR\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u6807\u51c6\u3002"}}
{"id": "2510.08338", "categories": ["cs.AI", "I.2.7; J.4"], "pdf": "https://arxiv.org/pdf/2510.08338", "abs": "https://arxiv.org/abs/2510.08338", "authors": ["Benjamin F. Maier", "Ulf Aslak", "Luca Fiaschi", "Nina Rismal", "Kemble Fletcher", "Christian C. Luhmann", "Robbie Dow", "Kli Pappas", "Thomas V. Wiecki"], "title": "LLMs Reproduce Human Purchase Intent via Semantic Similarity Elicitation of Likert Ratings", "comment": "28 pages, 35 figures", "summary": "Consumer research costs companies billions annually yet suffers from panel\nbiases and limited scale. Large language models (LLMs) offer an alternative by\nsimulating synthetic consumers, but produce unrealistic response distributions\nwhen asked directly for numerical ratings. We present semantic similarity\nrating (SSR), a method that elicits textual responses from LLMs and maps these\nto Likert distributions using embedding similarity to reference statements.\nTesting on an extensive dataset comprising 57 personal care product surveys\nconducted by a leading corporation in that market (9,300 human responses), SSR\nachieves 90% of human test-retest reliability while maintaining realistic\nresponse distributions (KS similarity > 0.85). Additionally, these synthetic\nrespondents provide rich qualitative feedback explaining their ratings. This\nframework enables scalable consumer research simulations while preserving\ntraditional survey metrics and interpretability.", "AI": {"tldr": "\u63d0\u51fa\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8bc4\u5206(SSR)\u65b9\u6cd5\uff0c\u4f7f\u7528LLMs\u751f\u6210\u6587\u672c\u54cd\u5e94\u5e76\u901a\u8fc7\u5d4c\u5165\u76f8\u4f3c\u5ea6\u6620\u5c04\u5230Likert\u5206\u5e03\uff0c\u89e3\u51b3\u4f20\u7edf\u6d88\u8d39\u8005\u7814\u7a76\u4e2d\u7684\u9762\u677f\u504f\u5dee\u548c\u89c4\u6a21\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6d88\u8d39\u8005\u7814\u7a76\u6210\u672c\u9ad8\u6602\u4e14\u5b58\u5728\u9762\u677f\u504f\u5dee\u548c\u89c4\u6a21\u9650\u5236\uff0cLLMs\u867d\u80fd\u6a21\u62df\u5408\u6210\u6d88\u8d39\u8005\u4f46\u76f4\u63a5\u83b7\u53d6\u6570\u503c\u8bc4\u5206\u4f1a\u4ea7\u751f\u4e0d\u73b0\u5b9e\u7684\u54cd\u5e94\u5206\u5e03\u3002", "method": "SSR\u65b9\u6cd5\uff1a\u4eceLLMs\u83b7\u53d6\u6587\u672c\u54cd\u5e94\uff0c\u901a\u8fc7\u5d4c\u5165\u76f8\u4f3c\u5ea6\u5c06\u8fd9\u4e9b\u6587\u672c\u6620\u5c04\u5230\u53c2\u8003\u58f0\u660e\u7684Likert\u5206\u5e03\u3002", "result": "\u572857\u4e2a\u4e2a\u4eba\u62a4\u7406\u4ea7\u54c1\u8c03\u67e5\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0cSSR\u8fbe\u5230\u4eba\u7c7b\u6d4b\u8bd5-\u91cd\u6d4b\u53ef\u9760\u6027\u768490%\uff0c\u540c\u65f6\u4fdd\u6301\u73b0\u5b9e\u7684\u54cd\u5e94\u5206\u5e03(KS\u76f8\u4f3c\u5ea6>0.85)\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u6d88\u8d39\u8005\u7814\u7a76\u6a21\u62df\uff0c\u540c\u65f6\u4fdd\u7559\u4f20\u7edf\u8c03\u67e5\u6307\u6807\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5408\u6210\u53d7\u8bbf\u8005\u8fd8\u80fd\u63d0\u4f9b\u4e30\u5bcc\u7684\u5b9a\u6027\u53cd\u9988\u3002"}}
{"id": "2510.08383", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08383", "abs": "https://arxiv.org/abs/2510.08383", "authors": ["Yi Jiang", "Lei Shen", "Lujie Niu", "Sendong Zhao", "Wenbo Su", "Bo Zheng"], "title": "QAgent: A modular Search Agent with Interactive Query Understanding", "comment": "Code is available at https://github.com/OpenStellarTeam/QAgent", "summary": "Large language models (LLMs) excel at natural language tasks but are limited\nby their static parametric knowledge, especially in knowledge-intensive task.\nRetrieval-augmented generation (RAG) mitigates this by integrating external\ninformation. However, (1) traditional RAG struggles with complex query\nunderstanding, and (2) even search agents trained with reinforcement learning\n(RL), despite their promise, still face generalization and deployment\nchallenges. To address these limitations, we propose QAgent, a unified agentic\nRAG framework that employs a search agent for adaptive retrieval. This agent\noptimizes its understanding of the query through interactive reasoning and\nretrieval. To facilitate real-world application, we focus on modular search\nagent for query understanding that are plug-and-play in complex systems.\nSecifically, the agent follows a multi-step decision process trained with RL to\nmaximize retrieval quality and support accurate downstream answers. We further\nanalyze the strengths and weaknesses of end-to-end RL and propose a strategy\nthat focuses on effective retrieval, thereby enhancing generalization in LLM\napplications. Experiments show QAgent excels at QA and serves as a\nplug-and-play module for real-world deployment.", "AI": {"tldr": "\u63d0\u51faQAgent\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u641c\u7d22\u4ee3\u7406\u8fdb\u884c\u81ea\u9002\u5e94\u68c0\u7d22\uff0c\u89e3\u51b3\u4f20\u7edfRAG\u5728\u590d\u6742\u67e5\u8be2\u7406\u89e3\u548c\u90e8\u7f72\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edfRAG\u5728\u590d\u6742\u67e5\u8be2\u7406\u89e3\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u641c\u7d22\u4ee3\u7406\u867d\u7136\u524d\u666f\u5e7f\u9614\uff0c\u4f46\u4ecd\u9762\u4e34\u6cdb\u5316\u6027\u548c\u90e8\u7f72\u6311\u6218\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u641c\u7d22\u4ee3\u7406\u8fdb\u884c\u591a\u6b65\u51b3\u7b56\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4ee5\u6700\u5927\u5316\u68c0\u7d22\u8d28\u91cf\uff0c\u652f\u6301\u51c6\u786e\u7684\u4e0b\u6e38\u7b54\u6848\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660eQAgent\u5728\u95ee\u7b54\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u6a21\u5757\u7528\u4e8e\u5b9e\u9645\u90e8\u7f72\u3002", "conclusion": "QAgent\u901a\u8fc7\u4e13\u6ce8\u4e8e\u6709\u6548\u68c0\u7d22\u7684\u7b56\u7565\uff0c\u589e\u5f3a\u4e86LLM\u5e94\u7528\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08389", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08389", "abs": "https://arxiv.org/abs/2510.08389", "authors": ["Rui Wang", "Zeming Wei", "Guanzhang Yue", "Meng Sun"], "title": "Revisiting Hallucination Detection with Effective Rank-based Uncertainty", "comment": null, "summary": "Detecting hallucinations in large language models (LLMs) remains a\nfundamental challenge for their trustworthy deployment. Going beyond basic\nuncertainty-driven hallucination detection frameworks, we propose a simple yet\npowerful method that quantifies uncertainty by measuring the effective rank of\nhidden states derived from multiple model outputs and different layers.\nGrounded in the spectral analysis of representations, our approach provides\ninterpretable insights into the model's internal reasoning process through\nsemantic variations, while requiring no extra knowledge or additional modules,\nthus offering a combination of theoretical elegance and practical efficiency.\nMeanwhile, we theoretically demonstrate the necessity of quantifying\nuncertainty both internally (representations of a single response) and\nexternally (different responses), providing a justification for using\nrepresentations among different layers and responses from LLMs to detect\nhallucinations. Extensive experiments demonstrate that our method effectively\ndetects hallucinations and generalizes robustly across various scenarios,\ncontributing to a new paradigm of hallucination detection for LLM truthfulness.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9690\u85cf\u72b6\u6001\u6709\u6548\u79e9\u7684LLM\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u591a\u8f93\u51fa\u548c\u591a\u5c42\u8868\u793a\u7684\u8c31\u7279\u6027\u6765\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u65e0\u9700\u989d\u5916\u77e5\u8bc6\u6216\u6a21\u5757\u3002", "motivation": "\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u5bf9\u5176\u53ef\u4fe1\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff0c\u73b0\u6709\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u7684\u68c0\u6d4b\u6846\u67b6\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u66f4\u6df1\u5165\u7406\u89e3\u6a21\u578b\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u901a\u8fc7\u6d4b\u91cf\u6765\u81ea\u591a\u4e2a\u6a21\u578b\u8f93\u51fa\u548c\u4e0d\u540c\u5c42\u7684\u9690\u85cf\u72b6\u6001\u7684\u6709\u6548\u79e9\u6765\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u57fa\u4e8e\u8868\u793a\u8c31\u5206\u6790\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8bed\u4e49\u53d8\u5316\u6d1e\u5bdf\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u5e7b\u89c9\uff0c\u5e76\u5728\u5404\u79cd\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aLLM\u771f\u5b9e\u6027\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u7ed3\u5408\u4e86\u7406\u8bba\u4f18\u96c5\u6027\u548c\u5b9e\u9645\u6548\u7387\uff0c\u8bc1\u660e\u4e86\u540c\u65f6\u91cf\u5316\u5185\u90e8\u548c\u5916\u90e8\u4e0d\u786e\u5b9a\u6027\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2510.08470", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08470", "abs": "https://arxiv.org/abs/2510.08470", "authors": ["Bianca-Mihaela Ganescu", "Suchir Salhan", "Andrew Caines", "Paula Buttery"], "title": "Looking to Learn: Token-wise Dynamic Gating for Low-Resource Vision-Language Modelling", "comment": "Accepted to the EMNLP 2025 BabyLM Workshop", "summary": "Training vision-language models on cognitively-plausible amounts of data\nrequires rethinking how models integrate multimodal information. Within the\nconstraints of the Vision track for the BabyLM Challenge 2025, we propose a\nlightweight decoder-based architecture with (1) token-wise dynamic gating for\nadaptive fusion of linguistic and visual cues, (2) feature modulation and\nchannel attention to maximise the utility of limited visual information and (3)\nauxiliary contrastive objectives for visual grounding. Evaluation on five\nbenchmarks (BLiMP, BLiMP Supplement, EWoK, Winoground and VQA) shows\ncompetitive or superior performance to multimodal baselines. More notably, our\ndynamic gate discovers interpretable patterns without explicit supervision,\nfavouring visual cues for content words and linguistic cues for function words.\nWhile we identify limitations in the Challenge constraints, such as the\ninformation bottleneck created by global image embeddings and training\ninstability from the dataset split, our findings establish dynamic gating as a\npowerful tool for efficient multimodal learning, offering both interpretability\nand performance even under severe constraints.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u89e3\u7801\u5668\u67b6\u6784\uff0c\u4f7f\u7528\u52a8\u6001\u95e8\u63a7\u81ea\u9002\u5e94\u878d\u5408\u8bed\u8a00\u548c\u89c6\u89c9\u4fe1\u606f\uff0c\u5728BabyLM\u6311\u6218\u8d5b\u7ea6\u675f\u4e0b\u5b9e\u73b0\u9ad8\u6548\u591a\u6a21\u6001\u5b66\u4e60", "motivation": "\u5728\u8ba4\u77e5\u5408\u7406\u7684\u6570\u636e\u91cf\u9650\u5236\u4e0b\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003\u6a21\u578b\u5982\u4f55\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f", "method": "\u8f7b\u91cf\u7ea7\u89e3\u7801\u5668\u67b6\u6784\uff0c\u5305\u542b\uff1a(1) \u57fa\u4e8etoken\u7684\u52a8\u6001\u95e8\u63a7\u81ea\u9002\u5e94\u878d\u5408\u8bed\u8a00\u548c\u89c6\u89c9\u7ebf\u7d22\uff1b(2) \u7279\u5f81\u8c03\u5236\u548c\u901a\u9053\u6ce8\u610f\u529b\u6700\u5927\u5316\u6709\u9650\u89c6\u89c9\u4fe1\u606f\u7684\u6548\u7528\uff1b(3) \u7528\u4e8e\u89c6\u89c9\u5b9a\u4f4d\u7684\u8f85\u52a9\u5bf9\u6bd4\u76ee\u6807", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08BLiMP\u3001BLiMP Supplement\u3001EWoK\u3001Winoground\u548cVQA\uff09\u4e0a\u8868\u73b0\u51fa\u4e0e\u591a\u6a21\u6001\u57fa\u7ebf\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd\uff1b\u52a8\u6001\u95e8\u63a7\u5728\u6ca1\u6709\u663e\u5f0f\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u53d1\u73b0\u4e86\u53ef\u89e3\u91ca\u7684\u6a21\u5f0f\uff0c\u5bf9\u5185\u5bb9\u8bcd\u504f\u597d\u89c6\u89c9\u7ebf\u7d22\uff0c\u5bf9\u529f\u80fd\u8bcd\u504f\u597d\u8bed\u8a00\u7ebf\u7d22", "conclusion": "\u5c3d\u7ba1\u5b58\u5728\u6311\u6218\u7ea6\u675f\u7684\u9650\u5236\uff08\u5982\u5168\u5c40\u56fe\u50cf\u5d4c\u5165\u9020\u6210\u7684\u4fe1\u606f\u74f6\u9888\u548c\u6570\u636e\u96c6\u5206\u5272\u5bfc\u81f4\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff09\uff0c\u52a8\u6001\u95e8\u63a7\u88ab\u786e\u7acb\u4e3a\u9ad8\u6548\u591a\u6a21\u6001\u5b66\u4e60\u7684\u5f3a\u5927\u5de5\u5177\uff0c\u5373\u4f7f\u5728\u4e25\u683c\u7ea6\u675f\u4e0b\u4e5f\u80fd\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u548c\u6027\u80fd"}}
{"id": "2510.08511", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08511", "abs": "https://arxiv.org/abs/2510.08511", "authors": ["Shangheng Du", "Xiangchao Yan", "Dengyang Jiang", "Jiakang Yuan", "Yusong Hu", "Xin Li", "Liang He", "Bo Zhang", "Lei Bai"], "title": "AutoMLGen: Navigating Fine-Grained Optimization for Coding Agents", "comment": null, "summary": "Large language models (LLMs) have shown impressive performance in general\nprogramming tasks. However, in Machine Learning Engineering (MLE) scenarios\nsuch as AutoML and Kaggle competitions, achieving high performance depends\nheavily on expert intervention and repeated adjustments rather than simply\ngenerating correct code. When applied directly to these tasks, LLMs often lack\nfine-grained domain priors, and existing MLE approaches that use linear or\ntree-structured searches limit knowledge transfer to adjacent hierarchical\nlinks. As a result, they cannot leverage past full trajectories or share\ninformation across branches, limiting self-evolving ability and search space\ndiversity. To address these limitations, we introduce AutoMLGen, an LLM-based\ncoding agent that integrates a domain knowledge base for high-quality prior\nguidance and Monte Carlo Graph Search (MCGS) for efficient exploration. MCGS\nretains the tree-guided exploration of MCTS while embedding a graph structure\ninto the expansion stage to enable dynamic path reorganization, historical\ntrajectory reuse, and multi-solution fusion to support both self-evolution and\ncollaborative learning. Combined with fine-grained operator sets, this design\nimproves stability and accelerates convergence. Evaluation on the MLE-Bench\nshows that AutoMLGen achieves state-of-the-art performance in numerous\ndimensions, such as the average medal rate and the valid submission rate, under\na 12-hour budget (half the standard runtime). The code is available at\nhttps://github.com/Alpha-Innovator/InternAgent.", "AI": {"tldr": "AutoMLGen\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u7f16\u7801\u4ee3\u7406\uff0c\u901a\u8fc7\u96c6\u6210\u9886\u57df\u77e5\u8bc6\u5e93\u548c\u8499\u7279\u5361\u6d1b\u56fe\u641c\u7d22\u6765\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u6311\u6218\uff0c\u5728MLE-Bench\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684LLM\u5728\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u9886\u57df\u5148\u9a8c\u77e5\u8bc6\uff0c\u4f20\u7edfMLE\u65b9\u6cd5\u7684\u7ebf\u6027\u6216\u6811\u72b6\u641c\u7d22\u9650\u5236\u4e86\u77e5\u8bc6\u4f20\u9012\uff0c\u65e0\u6cd5\u5229\u7528\u5b8c\u6574\u5386\u53f2\u8f68\u8ff9\u6216\u8de8\u5206\u652f\u5171\u4eab\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u81ea\u8fdb\u5316\u80fd\u529b\u548c\u641c\u7d22\u7a7a\u95f4\u591a\u6837\u6027\u3002", "method": "\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u5e93\u63d0\u4f9b\u9ad8\u8d28\u91cf\u5148\u9a8c\u6307\u5bfc\uff0c\u91c7\u7528\u8499\u7279\u5361\u6d1b\u56fe\u641c\u7d22\uff08MCGS\uff09\u5b9e\u73b0\u52a8\u6001\u8def\u5f84\u91cd\u7ec4\u3001\u5386\u53f2\u8f68\u8ff9\u91cd\u7528\u548c\u591a\u89e3\u51b3\u65b9\u6848\u878d\u5408\uff0c\u652f\u6301\u81ea\u8fdb\u5316\u548c\u534f\u4f5c\u5b66\u4e60\uff0c\u914d\u5408\u7ec6\u7c92\u5ea6\u64cd\u4f5c\u7b26\u96c6\u63d0\u9ad8\u7a33\u5b9a\u6027\u548c\u6536\u655b\u901f\u5ea6\u3002", "result": "\u5728MLE-Bench\u8bc4\u4f30\u4e2d\uff0cAutoMLGen\u572812\u5c0f\u65f6\u9884\u7b97\uff08\u6807\u51c6\u8fd0\u884c\u65f6\u95f4\u7684\u4e00\u534a\uff09\u4e0b\uff0c\u5728\u5e73\u5747\u5956\u724c\u7387\u548c\u6709\u6548\u63d0\u4ea4\u7387\u7b49\u591a\u4e2a\u7ef4\u5ea6\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "AutoMLGen\u901a\u8fc7\u96c6\u6210\u9886\u57df\u77e5\u8bc6\u5e93\u548c\u8499\u7279\u5361\u6d1b\u56fe\u641c\u7d22\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.08517", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08517", "abs": "https://arxiv.org/abs/2510.08517", "authors": ["Grace Liu", "Yuxiao Qu", "Jeff Schneider", "Aarti Singh", "Aviral Kumar"], "title": "CaRT: Teaching LLM Agents to Know When They Know Enough", "comment": null, "summary": "Many tasks require learned models to strategically gather relevant\ninformation over multiple rounds of interaction before actually acting on a\ntask. Strategic information gathering requires models to know not only how to\neffectively acquire information, but also when to stop gathering information\nand make a decision, in order to avoid overthinking or getting derailed when\nacting. In this paper, we formalize this problem and introduce Counterfactuals\nand Reasoning for Termination (CaRT), an approach for teaching LLMs when to\nstop seeking information. To appropriately learn when to terminate, CaRT\nfine-tunes LLMs using counterfactual pairs of trajectories, one where\ntermination is appropriate and a minimally modified version of the same\ntrajectory where it is not. It trains the LLM to explain the rationale for the\ntermination decision in either case via verbal reasoning, and imbues this\ncapability into the base LLM via fine-tuning. We instantiate CaRT in two\ndomains: interactive medical diagnosis and math problem solving. In both\ndomains, we find that CaRT improves the efficiency of information gathering and\ntask success rate compared to other fine-tuning methods.", "AI": {"tldr": "CaRT\u65b9\u6cd5\u901a\u8fc7\u53cd\u4e8b\u5b9e\u8f68\u8ff9\u5bf9\u548c\u8bed\u8a00\u63a8\u7406\u8bad\u7ec3LLMs\uff0c\u6559\u4f1a\u6a21\u578b\u4f55\u65f6\u505c\u6b62\u4fe1\u606f\u6536\u96c6\uff0c\u63d0\u9ad8\u591a\u8f6e\u4ea4\u4e92\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u548c\u6210\u529f\u7387\u3002", "motivation": "\u591a\u8f6e\u4ea4\u4e92\u4efb\u52a1\u9700\u8981\u6a21\u578b\u65e2\u80fd\u6709\u6548\u6536\u96c6\u4fe1\u606f\uff0c\u53c8\u80fd\u9002\u65f6\u505c\u6b62\u6536\u96c6\u5e76\u505a\u51fa\u51b3\u7b56\uff0c\u907f\u514d\u8fc7\u5ea6\u601d\u8003\u6216\u504f\u79bb\u4e3b\u9898\u3002", "method": "\u4f7f\u7528\u53cd\u4e8b\u5b9e\u8f68\u8ff9\u5bf9\u8fdb\u884c\u5fae\u8c03\uff0c\u8bad\u7ec3LLMs\u89e3\u91ca\u7ec8\u6b62\u51b3\u7b56\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u5c06\u8fd9\u79cd\u80fd\u529b\u878d\u5165\u57fa\u7840\u6a21\u578b\u3002", "result": "\u5728\u533b\u7597\u8bca\u65ad\u548c\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u4e24\u4e2a\u9886\u57df\uff0cCaRT\u76f8\u6bd4\u5176\u4ed6\u5fae\u8c03\u65b9\u6cd5\u63d0\u9ad8\u4e86\u4fe1\u606f\u6536\u96c6\u6548\u7387\u548c\u4efb\u52a1\u6210\u529f\u7387\u3002", "conclusion": "CaRT\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8f6e\u4ea4\u4e92\u4efb\u52a1\u4e2d\u7684\u7ec8\u6b62\u51b3\u7b56\u95ee\u9898\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u63a8\u7406\u8bad\u7ec3\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6218\u7565\u4fe1\u606f\u6536\u96c6\u80fd\u529b\u3002"}}
{"id": "2510.08521", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08521", "abs": "https://arxiv.org/abs/2510.08521", "authors": ["Yusong Hu", "Runmin Ma", "Yue Fan", "Jinxin Shi", "Zongsheng Cao", "Yuhao Zhou", "Jiakang Yuan", "Xiangchao Yan", "Wenlong Zhang", "Lei Bai", "Bo Zhang"], "title": "FlowSearch: Advancing deep research with dynamic structured knowledge flow", "comment": null, "summary": "Deep research is an inherently challenging task that demands both breadth and\ndepth of thinking. It involves navigating diverse knowledge spaces and\nreasoning over complex, multi-step dependencies, which presents substantial\nchallenges for agentic systems. To address this, we propose FlowSearch, a\nmulti-agent framework that actively constructs and evolves a dynamic structured\nknowledge flow to drive subtask execution and reasoning. FlowSearch is capable\nof strategically planning and expanding the knowledge flow to enable parallel\nexploration and hierarchical task decomposition, while also adjusting the\nknowledge flow in real time based on feedback from intermediate reasoning\noutcomes and insights. FlowSearch achieves state-of-the-art performance on both\ngeneral and scientific benchmarks, including GAIA, HLE, GPQA and TRQA,\ndemonstrating its effectiveness in multi-disciplinary research scenarios and\nits potential to advance scientific discovery. The code is available at\nhttps://github.com/Alpha-Innovator/InternAgent.", "AI": {"tldr": "FlowSearch\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u52a8\u6001\u7ed3\u6784\u5316\u77e5\u8bc6\u6d41\u6765\u9a71\u52a8\u5b50\u4efb\u52a1\u6267\u884c\u548c\u63a8\u7406\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u6df1\u5ea6\u7814\u7a76\u9700\u8981\u5e7f\u5ea6\u548c\u6df1\u5ea6\u7684\u601d\u8003\uff0c\u6d89\u53ca\u5bfc\u822a\u591a\u6837\u5316\u77e5\u8bc6\u7a7a\u95f4\u548c\u590d\u6742\u591a\u6b65\u4f9d\u8d56\u63a8\u7406\uff0c\u8fd9\u5bf9\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51faFlowSearch\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u4e3b\u52a8\u6784\u5efa\u548c\u6f14\u5316\u52a8\u6001\u7ed3\u6784\u5316\u77e5\u8bc6\u6d41\uff0c\u652f\u6301\u5e76\u884c\u63a2\u7d22\u548c\u5c42\u6b21\u5316\u4efb\u52a1\u5206\u89e3\uff0c\u5e76\u6839\u636e\u4e2d\u95f4\u63a8\u7406\u7ed3\u679c\u5b9e\u65f6\u8c03\u6574\u77e5\u8bc6\u6d41\u3002", "result": "\u5728GAIA\u3001HLE\u3001GPQA\u548cTRQA\u7b49\u901a\u7528\u548c\u79d1\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5728\u591a\u5b66\u79d1\u7814\u7a76\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "FlowSearch\u6846\u67b6\u5728\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u63a8\u8fdb\u79d1\u5b66\u53d1\u73b0\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.08558", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08558", "abs": "https://arxiv.org/abs/2510.08558", "authors": ["Kai Zhang", "Xiangchao Chen", "Bo Liu", "Tianci Xue", "Zeyi Liao", "Zhihan Liu", "Xiyao Wang", "Yuting Ning", "Zhaorun Chen", "Xiaohan Fu", "Jian Xie", "Yuxuan Sun", "Boyu Gou", "Qi Qi", "Zihang Meng", "Jianwei Yang", "Ning Zhang", "Xian Li", "Ashish Shah", "Dat Huynh", "Hengduo Li", "Zi Yang", "Sara Cao", "Lawrence Jang", "Shuyan Zhou", "Jiacheng Zhu", "Huan Sun", "Jason Weston", "Yu Su", "Yifan Wu"], "title": "Agent Learning via Early Experience", "comment": "Work in progress", "summary": "A long-term goal of language agents is to learn and improve through their own\nexperience, ultimately outperforming humans in complex, real-world tasks.\nHowever, training agents from experience data with reinforcement learning\nremains difficult in many environments, which either lack verifiable rewards\n(e.g., websites) or require inefficient long-horizon rollouts (e.g., multi-turn\ntool use). As a result, most current agents rely on supervised fine-tuning on\nexpert data, which is challenging to scale and generalizes poorly. This\nlimitation stems from the nature of expert demonstrations: they capture only a\nnarrow range of scenarios and expose the agent to limited environment\ndiversity. We address this limitation with a middle-ground paradigm we call\nearly experience: interaction data generated by the agent's own actions, where\nthe resulting future states serve as supervision without reward signals. Within\nthis paradigm we study two strategies of using such data: (1) Implicit world\nmodeling, which uses collected states to ground the policy in environment\ndynamics; and (2) Self-reflection, where the agent learns from its suboptimal\nactions to improve reasoning and decision-making. We evaluate across eight\ndiverse environments and multiple model families. Our approaches consistently\nimprove effectiveness and out-of-domain generalization, highlighting the value\nof early experience. Moreover, in environments with verifiable rewards, our\nresults provide promising signals that early experience offers a strong\nfoundation for subsequent reinforcement learning, positioning it as a practical\nbridge between imitation learning and fully experience-driven agents.", "AI": {"tldr": "\u63d0\u51fa\"\u65e9\u671f\u7ecf\u9a8c\"\u8303\u5f0f\uff0c\u4f7f\u7528\u667a\u80fd\u4f53\u81ea\u8eab\u4ea4\u4e92\u6570\u636e\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\uff0c\u901a\u8fc7\u9690\u5f0f\u4e16\u754c\u5efa\u6a21\u548c\u81ea\u6211\u53cd\u601d\u4e24\u79cd\u7b56\u7565\u63d0\u5347\u8bed\u8a00\u667a\u80fd\u4f53\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u667a\u80fd\u4f53\u4e3b\u8981\u4f9d\u8d56\u4e13\u5bb6\u6570\u636e\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff0c\u4f46\u4e13\u5bb6\u6570\u636e\u8986\u76d6\u573a\u666f\u6709\u9650\u4e14\u7f3a\u4e4f\u73af\u5883\u591a\u6837\u6027\u3002\u5f3a\u5316\u5b66\u4e60\u5728\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u5956\u52b1\u6216\u9700\u8981\u957f\u5e8f\u5217\u4ea4\u4e92\u7684\u73af\u5883\u4e2d\u8bad\u7ec3\u56f0\u96be\u3002", "method": "1) \u9690\u5f0f\u4e16\u754c\u5efa\u6a21\uff1a\u5229\u7528\u6536\u96c6\u7684\u72b6\u6001\u4fe1\u606f\u8ba9\u7b56\u7565\u57fa\u4e8e\u73af\u5883\u52a8\u6001\uff1b2) \u81ea\u6211\u53cd\u601d\uff1a\u667a\u80fd\u4f53\u4ece\u6b21\u4f18\u884c\u52a8\u4e2d\u5b66\u4e60\u4ee5\u6539\u8fdb\u63a8\u7406\u548c\u51b3\u7b56\u3002\u5728\u516b\u4e2a\u591a\u6837\u5316\u73af\u5883\u4e2d\u8bc4\u4f30\u3002", "result": "\u65b9\u6cd5\u5728\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\u4e2d\u4e00\u81f4\u63d0\u5347\u6709\u6548\u6027\u548c\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002\u5728\u6709\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u73af\u5883\u4e2d\uff0c\u4e3a\u540e\u7eed\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u826f\u597d\u57fa\u7840\u3002", "conclusion": "\u65e9\u671f\u7ecf\u9a8c\u662f\u6a21\u4eff\u5b66\u4e60\u548c\u5b8c\u5168\u7ecf\u9a8c\u9a71\u52a8\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u5b9e\u7528\u6865\u6881\uff0c\u5c55\u793a\u4e86\u901a\u8fc7\u81ea\u8eab\u7ecf\u9a8c\u5b66\u4e60\u63d0\u5347\u6027\u80fd\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.08564", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08564", "abs": "https://arxiv.org/abs/2510.08564", "authors": ["Zhen Zhu", "Yiming Gong", "Yao Xiao", "Yaoyao Liu", "Derek Hoiem"], "title": "How to Teach Large Multimodal Models New Skills", "comment": "In submission. Code is available at\n  https://github.com/jessemelpolio/LMM_CL", "summary": "How can we teach large multimodal models (LMMs) new skills without erasing\nprior abilities? We study sequential fine-tuning on five target skills while\nmonitoring general ability on eight held-out benchmarks across three model\nfamilies. We observe that apparent \"forgetting\" on held-out tasks after narrow\nfine-tuning can partly recover at later stages. We trace this behavior to a\nmeasurable shift in the output token distribution, manifested through a simple\ncounting-bias probe that co-varies with forgetting. Guided by this picture, we\nidentify two simple, robust tuning recipes that learn strongly while limiting\ndrift: (i) updating only the self-attention projection layers, and (ii)\nupdating only the MLP Gate&Up while freezing the Down projection. Across models\nand tasks, these choices deliver strong target gains while largely preserving\nheld-out performance. Code is available at\nhttps://github.com/jessemelpolio/LMM_CL", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u987a\u5e8f\u5fae\u8c03\u4e2d\u7684\u9057\u5fd8\u95ee\u9898\uff0c\u53d1\u73b0\u9057\u5fd8\u73b0\u8c61\u5728\u540e\u671f\u4f1a\u90e8\u5206\u6062\u590d\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u7b80\u5355\u7684\u8c03\u4f18\u65b9\u6cd5\u6765\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u6559\u6388\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u65b0\u6280\u80fd\u7684\u540c\u65f6\u907f\u514d\u9057\u5fd8\u5148\u524d\u80fd\u529b\uff0c\u63a2\u7d22\u987a\u5e8f\u5fae\u8c03\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5728\u4e94\u4e2a\u76ee\u6807\u6280\u80fd\u4e0a\u987a\u5e8f\u5fae\u8c03\uff0c\u540c\u65f6\u5728\u516b\u4e2a\u4fdd\u7559\u57fa\u51c6\u4e0a\u76d1\u63a7\u901a\u7528\u80fd\u529b\uff0c\u4f7f\u7528\u8f93\u51fa\u4ee4\u724c\u5206\u5e03\u53d8\u5316\u4f5c\u4e3a\u9057\u5fd8\u6307\u6807\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u8c03\u4f18\u65b9\u6cd5\uff1a\u4ec5\u66f4\u65b0\u81ea\u6ce8\u610f\u529b\u6295\u5f71\u5c42\uff0c\u6216\u4ec5\u66f4\u65b0MLP\u7684Gate&Up\u5c42\u3002", "result": "\u53d1\u73b0\u7a84\u5fae\u8c03\u540e\u7684\u9057\u5fd8\u73b0\u8c61\u5728\u540e\u671f\u4f1a\u90e8\u5206\u6062\u590d\uff0c\u63d0\u51fa\u7684\u4e24\u79cd\u8c03\u4f18\u65b9\u6cd5\u5728\u591a\u4e2a\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u90fd\u80fd\u5b9e\u73b0\u5f3a\u5927\u7684\u76ee\u6807\u589e\u76ca\uff0c\u540c\u65f6\u57fa\u672c\u4fdd\u7559\u4fdd\u7559\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u9009\u62e9\u6027\u66f4\u65b0\u7279\u5b9a\u5c42\u53ef\u4ee5\u6709\u6548\u5e73\u8861\u65b0\u6280\u80fd\u5b66\u4e60\u548c\u65e7\u80fd\u529b\u4fdd\u7559\uff0c\u4e3a\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u7684\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
