<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 62]
- [q-fin.GN](#q-fin.GN) [Total: 2]
- [cs.ET](#cs.ET) [Total: 2]
- [stat.AP](#stat.AP) [Total: 6]
- [cs.SI](#cs.SI) [Total: 9]
- [econ.TH](#econ.TH) [Total: 7]
- [cs.CY](#cs.CY) [Total: 13]
- [econ.GN](#econ.GN) [Total: 11]
- [eess.SY](#eess.SY) [Total: 32]
- [cs.AI](#cs.AI) [Total: 55]
- [econ.EM](#econ.EM) [Total: 6]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Gen AI in Automotive: Applications, Challenges, and Opportunities with a Case study on In-Vehicle Experience](https://arxiv.org/abs/2511.00026)
*Chaitanya Shinde,Divya Garikapati*

Main category: cs.RO

TL;DR: 本文综述了生成式AI在汽车行业的应用现状，重点关注其在车辆设计、制造、自动驾驶、预测性维护和车载用户体验等领域的变革性潜力，同时分析了相关技术挑战和伦理问题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正在成为汽车行业的变革力量，但现有研究多集中于感知或制造领域，缺乏对基于语音的人机交互等综合应用的系统性分析。本文旨在填补这一空白。

Method: 采用文献综述和案例研究方法，分析生成式对抗网络和变分自编码器等关键技术，并以梅赛德斯-奔驰MBUX虚拟助手为例进行深入案例研究。

Result: 研究发现生成式AI能够通过合成数据生成加速自动驾驶验证、优化零部件设计，并实现更自然、主动和个性化的车载交互体验。梅赛德斯案例显示其语音系统相比传统规则系统有明显优势。

Conclusion: 生成式AI在汽车领域具有巨大潜力，但需要解决计算需求、偏见、知识产权和对抗鲁棒性等挑战。未来研究应致力于实现更安全、高效和以用户为中心的移动出行。

Abstract: Generative Artificial Intelligence is emerging as a transformative force in
the automotive industry, enabling novel applications across vehicle design,
manufacturing, autonomous driving, predictive maintenance, and in vehicle user
experience. This paper provides a comprehensive review of the current state of
GenAI in automotive, highlighting enabling technologies such as Generative
Adversarial Networks and Variational Autoencoders. Key opportunities include
accelerating autonomous driving validation through synthetic data generation,
optimizing component design, and enhancing human machine interaction via
personalized and adaptive interfaces. At the same time, the paper identifies
significant technical, ethical, and safety challenges, including computational
demands, bias, intellectual property concerns, and adversarial robustness, that
must be addressed for responsible deployment. A case study on Mercedes Benzs
MBUX Virtual Assistant illustrates how GenAI powered voice systems deliver more
natural, proactive, and personalized in car interactions compared to legacy
rule based assistants. Through this review and case study, the paper outlines
both the promise and limitations of GenAI integration in the automotive sector
and presents directions for future research and development aimed at achieving
safer, more efficient, and user centric mobility. Unlike prior reviews that
focus solely on perception or manufacturing, this paper emphasizes generative
AI in voice based HMI, bridging safety and user experience perspectives.

</details>


### [2] [STRIDER: Navigation via Instruction-Aligned Structural Decision Space Optimization](https://arxiv.org/abs/2511.00033)
*Diqi He,Xuehao Gao,Hao Li,Junwei Han,Dingwen Zhang*

Main category: cs.RO

TL;DR: STRIDER框架通过整合空间布局先验和动态任务反馈来优化智能体在零样本视觉语言导航任务中的决策空间，显著提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在零样本视觉语言导航中缺乏结构化决策和先前动作反馈的充分整合，导致导航鲁棒性不足。

Method: 提出STRIDER框架，包含结构化路径点生成器（约束动作空间）和任务对齐调节器（基于任务进展调整行为）。

Result: 在R2R-CE和RxR-CE基准测试中显著超越现有方法，成功率从29%提升至35%，相对增益达20.7%。

Conclusion: 空间约束决策和反馈引导执行对于提升零样本视觉语言导航的保真度至关重要。

Abstract: The Zero-shot Vision-and-Language Navigation in Continuous Environments
(VLN-CE) task requires agents to navigate previously unseen 3D environments
using natural language instructions, without any scene-specific training. A
critical challenge in this setting lies in ensuring agents' actions align with
both spatial structure and task intent over long-horizon execution. Existing
methods often fail to achieve robust navigation due to a lack of structured
decision-making and insufficient integration of feedback from previous actions.
To address these challenges, we propose STRIDER (Instruction-Aligned Structural
Decision Space Optimization), a novel framework that systematically optimizes
the agent's decision space by integrating spatial layout priors and dynamic
task feedback. Our approach introduces two key innovations: 1) a Structured
Waypoint Generator that constrains the action space through spatial structure,
and 2) a Task-Alignment Regulator that adjusts behavior based on task progress,
ensuring semantic alignment throughout navigation. Extensive experiments on the
R2R-CE and RxR-CE benchmarks demonstrate that STRIDER significantly outperforms
strong SOTA across key metrics; in particular, it improves Success Rate (SR)
from 29% to 35%, a relative gain of 20.7%. Such results highlight the
importance of spatially constrained decision-making and feedback-guided
execution in improving navigation fidelity for zero-shot VLN-CE.

</details>


### [3] [Tailored robotic training improves hand function and proprioceptive processing in stroke survivors with proprioceptive deficits: A randomized controlled trial](https://arxiv.org/abs/2511.00259)
*Andria J. Farrens,Luis Garcia-Fernandez,Raymond Diaz Rojas,Jillian Obeso Estrada,Dylan Reinsdorf,Vicky Chan,Disha Gupta,Joel Perry,Eric Wolbrecht,An Do,Steven C. Cramer,David J. Reinkensmeyer*

Main category: cs.RO

TL;DR: 针对有本体感觉缺陷的中风患者，本体感觉定制的机器人训练（特别是Propriopixel训练）能显著改善手部功能和神经处理能力。


<details>
  <summary>Details</summary>
Motivation: 研究精准康复方法，通过本体感觉定制的运动训练来改善中风幸存者的康复效果。

Method: 使用机器人手指外骨骼，测试两种本体感觉定制方法：Propriopixel训练（通过游戏化运动增强本体感觉处理）和虚拟辅助训练（减少机器人辅助以增加对自我反馈的依赖）。46名慢性中风患者随机接受标准训练、Propriopixel训练或虚拟训练。

Result: 在有本体感觉缺陷的参与者中，Propriopixel训练（Box and Block Test: 7±4.2, p=0.002）和虚拟辅助训练（4.5±4.4, p=0.068）比标准训练（0.8±2.3）带来更大的手功能改善。本体感觉改善与手功能改善相关。定制训练增强了神经对本体感觉线索的敏感性。

Conclusion: 本体感觉定制的训练是精准神经康复的有效途径，能够改善手部功能并增强神经处理能力。

Abstract: Precision rehabilitation aims to tailor movement training to improve
outcomes. We tested whether proprioceptively-tailored robotic training improves
hand function and neural processing in stroke survivors. Using a robotic finger
exoskeleton, we tested two proprioceptively-tailored approaches: Propriopixel
Training, which uses robot-facilitated, gamified movements to enhance
proprioceptive processing, and Virtual Assistance Training, which reduces
robotic aid to increase reliance on self-generated feedback. In a randomized
controlled trial, forty-six chronic stroke survivors completed nine 2-hour
sessions of Standard, Propriopixel or Virtual training. Among participants with
proprioceptive deficits, Propriopixel ((Box and Block Test: 7 +/- 4.2, p=0.002)
and Virtual Assistance (4.5 +/- 4.4 , p=0.068) yielded greater gains in hand
function (Standard: 0.8 +/- 2.3 blocks). Proprioceptive gains correlated with
improvements in hand function. Tailored training enhanced neural sensitivity to
proprioceptive cues, evidenced by a novel EEG biomarker, the proprioceptive
Contingent Negative Variation. These findings support proprioceptively-tailored
training as a pathway to precision neurorehabilitation.

</details>


### [4] [Endowing GPT-4 with a Humanoid Body: Building the Bridge Between Off-the-Shelf VLMs and the Physical World](https://arxiv.org/abs/2511.00041)
*Yingzhao Jian,Zhongan Wang,Yi Yang,Hehe Fan*

Main category: cs.RO

TL;DR: BiBo框架利用现成的视觉语言模型控制人形智能体，通过指令编译器和运动执行器实现开放环境中的多样化交互，无需大量数据收集。


<details>
  <summary>Details</summary>
Motivation: 解决人形智能体在开放环境中处理灵活多样交互的困难，避免昂贵的大规模数据集收集需求。

Method: 包含两个核心组件：1) 具身指令编译器，将高级用户指令转换为低级原始命令；2) 基于扩散的运动执行器，生成拟人化运动并适应环境物理反馈。

Result: 在开放环境中实现90.2%的交互任务成功率，文本引导运动执行精度比现有方法提高16.3%。

Conclusion: BiBo框架成功利用现成VLM的强大泛化能力，有效解决了人形智能体在开放环境中的交互挑战，无需昂贵的数据收集。

Abstract: Humanoid agents often struggle to handle flexible and diverse interactions in
open environments. A common solution is to collect massive datasets to train a
highly capable model, but this approach can be prohibitively expensive. In this
paper, we explore an alternative solution: empowering off-the-shelf
Vision-Language Models (VLMs, such as GPT-4) to control humanoid agents,
thereby leveraging their strong open-world generalization to mitigate the need
for extensive data collection. To this end, we present \textbf{BiBo}
(\textbf{B}uilding humano\textbf{I}d agent \textbf{B}y \textbf{O}ff-the-shelf
VLMs). It consists of two key components: (1) an \textbf{embodied instruction
compiler}, which enables the VLM to perceive the environment and precisely
translate high-level user instructions (e.g., {\small\itshape ``have a rest''})
into low-level primitive commands with control parameters (e.g.,
{\small\itshape ``sit casually, location: (1, 2), facing: 90$^\circ$''}); and
(2) a diffusion-based \textbf{motion executor}, which generates human-like
motions from these commands, while dynamically adapting to physical feedback
from the environment. In this way, BiBo is capable of handling not only basic
interactions but also diverse and complex motions. Experiments demonstrate that
BiBo achieves an interaction task success rate of 90.2\% in open environments,
and improves the precision of text-guided motion execution by 16.3\% over prior
methods. The code will be made publicly available.

</details>


### [5] [Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail](https://arxiv.org/abs/2511.00088)
*NVIDIA,:,Yan Wang,Wenjie Luo,Junjie Bai,Yulong Cao,Tong Che,Ke Chen,Yuxiao Chen,Jenna Diamond,Yifan Ding,Wenhao Ding,Liang Feng,Greg Heinrich,Jack Huang,Peter Karkus,Boyi Li,Pinyi Li,Tsung-Yi Lin,Dongran Liu,Ming-Yu Liu,Langechuan Liu,Zhijian Liu,Jason Lu,Yunxiang Mao,Pavlo Molchanov,Lindsey Pavao,Zhenghao Peng,Mike Ranzinger,Ed Schmerling,Shida Shen,Yunfei Shi,Sarah Tariq,Ran Tian,Tilman Wekel,Xinshuo Weng,Tianjun Xiao,Eric Yang,Xiaodong Yang,Yurong You,Xiaohui Zeng,Wenyuan Zhang,Boris Ivanovic,Marco Pavone*

Main category: cs.RO

TL;DR: AR1是一个视觉-语言-动作模型，通过因果链推理与轨迹规划相结合，提升复杂驾驶场景中的决策能力，在规划准确性、离道率和近距离接触率方面显著优于仅基于轨迹的基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决端到端模仿学习在安全关键的长尾场景中性能脆弱的问题，这些场景中监督稀疏且因果理解有限。

Method: 1) 构建因果链数据集；2) 采用模块化VLA架构，结合预训练的视觉语言模型和基于扩散的轨迹解码器；3) 使用监督微调和强化学习的多阶段训练策略。

Result: 在挑战性案例中规划准确性提升12%，闭环模拟中离道率降低35%，近距离接触率降低25%；强化学习后训练使推理质量提升45%，推理-行动一致性提升37%。

Conclusion: AR1通过将可解释推理与精确控制相结合，展示了实现L4级自动驾驶的可行路径，并在实际道路测试中验证了实时性能。

Abstract: End-to-end architectures trained via imitation learning have advanced
autonomous driving by scaling model size and data, yet performance remains
brittle in safety-critical long-tail scenarios where supervision is sparse and
causal understanding is limited. To address this, we introduce Alpamayo-R1
(AR1), a vision-language-action model (VLA) that integrates Chain of Causation
reasoning with trajectory planning to enhance decision-making in complex
driving scenarios. Our approach features three key innovations: (1) the Chain
of Causation (CoC) dataset, built through a hybrid auto-labeling and
human-in-the-loop pipeline producing decision-grounded, causally linked
reasoning traces aligned with driving behaviors; (2) a modular VLA architecture
combining Cosmos-Reason, a Vision-Language Model pre-trained for Physical AI
applications, with a diffusion-based trajectory decoder that generates
dynamically feasible plans in real time; (3) a multi-stage training strategy
using supervised fine-tuning to elicit reasoning and reinforcement learning
(RL) to optimize reasoning quality via large reasoning model feedback and
enforce reasoning-action consistency. Evaluation shows AR1 achieves up to a 12%
improvement in planning accuracy on challenging cases compared to a
trajectory-only baseline, with a 35% reduction in off-road rate and 25%
reduction in close encounter rate in closed-loop simulation. RL post-training
improves reasoning quality by 45% as measured by a large reasoning model critic
and reasoning-action consistency by 37%. Model scaling from 0.5B to 7B
parameters shows consistent improvements. On-vehicle road tests confirm
real-time performance (99 ms latency) and successful urban deployment. By
bridging interpretable reasoning with precise control, AR1 demonstrates a
practical path towards Level 4 autonomous driving. We plan to release AR1
models and a subset of the CoC in a future update.

</details>


### [6] [Digital Twin based Automatic Reconfiguration of Robotic Systems in Smart Environments](https://arxiv.org/abs/2511.00094)
*Angelos Alexopoulos,Agorakis Bompotas,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Athanasios P. Kalogeras,Christos Alexakos*

Main category: cs.RO

TL;DR: 提出基于数字孪生技术的机器人控制器自主动态重构框架，通过虚拟环境模拟优化运动轨迹，实现机器人在动态环境中的快速自适应。


<details>
  <summary>Details</summary>
Motivation: 传统控制系统在动态环境（如智慧城市、精准农业）中难以快速适应不断变化的地形和环境条件，导致效率低下或操作失败。

Method: 利用数字孪生技术创建机器人操作环境的虚拟副本，模拟和优化运动轨迹，根据现实世界变化重新计算路径和控制参数，并将更新后的代码部署到物理机器人。

Result: 实现了无需人工干预的快速可靠自适应，确保机器人在动态环境中的高效运行。

Conclusion: 该工作推进了数字孪生在机器人技术中的集成，为智能动态环境中的自主性增强提供了可扩展解决方案。

Abstract: Robotic systems have become integral to smart environments, enabling
applications ranging from urban surveillance and automated agriculture to
industrial automation. However, their effective operation in dynamic settings -
such as smart cities and precision farming - is challenged by continuously
evolving topographies and environmental conditions. Traditional control systems
often struggle to adapt quickly, leading to inefficiencies or operational
failures. To address this limitation, we propose a novel framework for
autonomous and dynamic reconfiguration of robotic controllers using Digital
Twin technology. Our approach leverages a virtual replica of the robot's
operational environment to simulate and optimize movement trajectories in
response to real-world changes. By recalculating paths and control parameters
in the Digital Twin and deploying the updated code to the physical robot, our
method ensures rapid and reliable adaptation without manual intervention. This
work advances the integration of Digital Twins in robotics, offering a scalable
solution for enhancing autonomy in smart, dynamic environments.

</details>


### [7] [Real-DRL: Teach and Learn in Reality](https://arxiv.org/abs/2511.00112)
*Yanbing Mao,Yihao Cai,Lui Sha*

Main category: cs.RO

TL;DR: Real-DRL框架用于安全关键自主系统，通过深度强化学习在真实物理系统中实时学习安全高性能动作策略，包含DRL-学生、PHY-教师和触发器三个交互组件。


<details>
  <summary>Details</summary>
Motivation: 解决安全关键系统中由未知未知和Sim2Real差距带来的安全挑战，确保在真实物理系统中运行时学习的安全性和性能。

Method: 采用三组件交互框架：DRL-学生采用双重自学习和教学学习范式，PHY-教师基于物理模型专注于安全关键功能，触发器管理两者交互。

Result: 在真实四足机器人、NVIDIA Isaac Gym中的四足机器人和倒立摆系统上的实验验证了框架的有效性，展示了保证安全、自动层次学习和解决学习经验不平衡等独特特性。

Conclusion: Real-DRL框架能够有效解决安全关键自主系统中的安全挑战，实现安全优先的学习和高性能策略开发。

Abstract: This paper introduces the Real-DRL framework for safety-critical autonomous
systems, enabling runtime learning of a deep reinforcement learning (DRL) agent
to develop safe and high-performance action policies in real plants (i.e., real
physical systems to be controlled), while prioritizing safety! The Real-DRL
consists of three interactive components: a DRL-Student, a PHY-Teacher, and a
Trigger. The DRL-Student is a DRL agent that innovates in the dual
self-learning and teaching-to-learn paradigm and the real-time safety-informed
batch sampling. On the other hand, PHY-Teacher is a physics-model-based design
of action policies that focuses solely on safety-critical functions.
PHY-Teacher is novel in its real-time patch for two key missions: i) fostering
the teaching-to-learn paradigm for DRL-Student and ii) backing up the safety of
real plants. The Trigger manages the interaction between the DRL-Student and
the PHY-Teacher. Powered by the three interactive components, the Real-DRL can
effectively address safety challenges that arise from the unknown unknowns and
the Sim2Real gap. Additionally, Real-DRL notably features i) assured safety,
ii) automatic hierarchy learning (i.e., safety-first learning and then
high-performance learning), and iii) safety-informed batch sampling to address
the learning experience imbalance caused by corner cases. Experiments with a
real quadruped robot, a quadruped robot in NVIDIA Isaac Gym, and a cart-pole
system, along with comparisons and ablation studies, demonstrate the Real-DRL's
effectiveness and unique features.

</details>


### [8] [End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection](https://arxiv.org/abs/2511.00139)
*Yu Cui,Yujian Zhang,Lina Tao,Yang Li,Xinyu Yi,Zhibin Li*

Main category: cs.RO

TL;DR: 提出了一种共享自主框架，通过VR遥操作和自主手部控制相结合的方式，高效收集高质量的手臂-手部协调演示数据，并训练端到端VLA策略，在多样化物体上实现90%的成功率。


<details>
  <summary>Details</summary>
Motivation: 解决灵巧操作中高质量训练数据稀缺的问题，现有方法存在人工遥操作负担重或自动规划动作不自然的局限性。

Method: 共享自主框架：人类通过VR控制手臂宏观运动，自主DexGrasp-VLA策略处理精细手部控制；使用Arm-Hand特征增强模块捕捉宏观和微观运动的共享表示；通过纠正遥操作实现持续策略改进。

Result: 以最少人力生成高质量数据，在多样化物体（包括未见实例）上达到90%的成功率，验证了系统在开发灵巧操作能力方面的有效性。

Conclusion: 该框架成功解决了灵巧操作中的数据收集挑战，实现了高效的人机协作和持续的策略改进，为通用机器人的灵巧操作能力发展提供了可行方案。

Abstract: Achieving human-like dexterous manipulation remains a major challenge for
general-purpose robots. While Vision-Language-Action (VLA) models show
potential in learning skills from demonstrations, their scalability is limited
by scarce high-quality training data. Existing data collection methods face
inherent constraints: manual teleoperation overloads human operators, while
automated planning often produces unnatural motions. We propose a Shared
Autonomy framework that divides control between macro and micro motions. A
human operator guides the robot's arm pose through intuitive VR teleoperation,
while an autonomous DexGrasp-VLA policy handles fine-grained hand control using
real-time tactile and visual feedback. This division significantly reduces
cognitive load and enables efficient collection of high-quality coordinated
arm-hand demonstrations. Using this data, we train an end-to-end VLA policy
enhanced with our novel Arm-Hand Feature Enhancement module, which captures
both distinct and shared representations of macro and micro movements for more
natural coordination. Our Corrective Teleoperation system enables continuous
policy improvement through human-in-the-loop failure recovery. Experiments
demonstrate that our framework generates high-quality data with minimal
manpower and achieves a 90% success rate across diverse objects, including
unseen instances. Comprehensive evaluations validate the system's effectiveness
in developing dexterous manipulation capabilities.

</details>


### [9] [EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations](https://arxiv.org/abs/2511.00153)
*Justin Yu,Yide Shentu,Di Wu,Pieter Abbeel,Ken Goldberg,Philipp Wu*

Main category: cs.RO

TL;DR: EgoMI框架通过同步捕捉末端执行器和主动头部轨迹来解决模仿学习中的人类-机器人具身差距问题，引入记忆增强策略来处理快速视角变化，在半人形机器人上实现了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决模仿学习中因人类具身特性（主动协调头手运动、动态视角重定位、预动作视觉注视搜索）与静态机器人感知系统之间的分布偏移问题。

Method: 提出EgoMI框架，捕获同步的末端执行器和主动头部轨迹；引入记忆增强策略，选择性整合历史观测来处理快速视角变化。

Result: 在配备驱动相机头的双臂机器人上评估，显示具有显式头部运动建模的策略持续优于基线方法。

Conclusion: EgoMI通过协调的手眼学习有效弥合了人类-机器人具身差距，为半人形机器人实现了稳健的模仿学习。

Abstract: Imitation learning from human demonstrations offers a promising approach for
robot skill acquisition, but egocentric human data introduces fundamental
challenges due to the embodiment gap. During manipulation, humans actively
coordinate head and hand movements, continuously reposition their viewpoint and
use pre-action visual fixation search strategies to locate relevant objects.
These behaviors create dynamic, task-driven head motions that static robot
sensing systems cannot replicate, leading to a significant distribution shift
that degrades policy performance. We present EgoMI (Egocentric Manipulation
Interface), a framework that captures synchronized end-effector and active head
trajectories during manipulation tasks, resulting in data that can be
retargeted to compatible semi-humanoid robot embodiments. To handle rapid and
wide-spanning head viewpoint changes, we introduce a memory-augmented policy
that selectively incorporates historical observations. We evaluate our approach
on a bimanual robot equipped with an actuated camera head and find that
policies with explicit head-motion modeling consistently outperform baseline
methods. Results suggest that coordinated hand-eye learning with EgoMI
effectively bridges the human-robot embodiment gap for robust imitation
learning on semi-humanoid embodiments. Project page:
https://egocentric-manipulation-interface.github.io

</details>


### [10] [Reducing Robotic Upper-Limb Assessment Time While Maintaining Precision: A Time Series Foundation Model Approach](https://arxiv.org/abs/2511.00193)
*Faranak Akbarifar,Nooshin Maghsoodi,Sean P Dukelow,Stephen Scott,Parvin Mousavi*

Main category: cs.RO

TL;DR: 使用时间序列基础模型预测未记录的伸手试验，显著缩短Kinarm机器人视觉引导伸手评估时间，同时保持运动学参数的可靠性。


<details>
  <summary>Details</summary>
Motivation: Kinarm机器人视觉引导伸手评估需要40-64次伸手试验，耗时且易导致疲劳，需要寻找缩短评估时间的方法。

Method: 分析461名中风和599名对照参与者的速度信号，使用ARIMA、MOMENT和Chronos模型基于前8或16次试验预测合成试验，重新计算运动学特征并与完整试验参考比较。

Result: Chronos模型仅需8次记录试验加预测即可恢复ICC≥0.90的可靠性，相当于24-28次实际试验的效果，显著缩短评估时间。

Conclusion: 基础模型预测可大幅缩短Kinarm评估时间，对最严重中风患者从4-5分钟降至约1分钟，同时保持运动学精度，为中风后运动障碍评估提供高效方案。

Abstract: Purpose: Visually Guided Reaching (VGR) on the Kinarm robot yields sensitive
kinematic biomarkers but requires 40-64 reaches, imposing time and fatigue
burdens. We evaluate whether time-series foundation models can replace
unrecorded trials from an early subset of reaches while preserving the
reliability of standard Kinarm parameters.
  Methods: We analyzed VGR speed signals from 461 stroke and 599 control
participants across 4- and 8-target reaching protocols. We withheld all but the
first 8 or 16 reaching trials and used ARIMA, MOMENT, and Chronos models,
fine-tuned on 70 percent of subjects, to forecast synthetic trials. We
recomputed four kinematic features of reaching (reaction time, movement time,
posture speed, maximum speed) on combined recorded plus forecasted trials and
compared them to full-length references using ICC(2,1).
  Results: Chronos forecasts restored ICC >= 0.90 for all parameters with only
8 recorded trials plus forecasts, matching the reliability of 24-28 recorded
reaches (Delta ICC <= 0.07). MOMENT yielded intermediate gains, while ARIMA
improvements were minimal. Across cohorts and protocols, synthetic trials
replaced reaches without materially compromising feature reliability.
  Conclusion: Foundation-model forecasting can greatly shorten Kinarm VGR
assessment time. For the most impaired stroke survivors, sessions drop from 4-5
minutes to about 1 minute while preserving kinematic precision. This
forecast-augmented paradigm promises efficient robotic evaluations for
assessing motor impairments following stroke.

</details>


### [11] [FGO MythBusters: Explaining how Kalman Filter variants achieve the same performance as FGO in navigation applications](https://arxiv.org/abs/2511.00306)
*Baoshan Song,Ruijie Xu,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 本文揭示了滑动窗口因子图优化(SW-FGO)与卡尔曼滤波器变体(KFV)之间的理论联系，提出了递归FGO(Re-FGO)框架，证明在特定条件下Re-FGO可精确重现EKF等KFV算法。


<details>
  <summary>Details</summary>
Motivation: 虽然SW-FGO在导航研究中越来越受关注，但其与EKF等卡尔曼滤波器变体的理论关系仍不明确，需要建立两者之间的理论连接。

Method: 提出了递归FGO(Re-FGO)框架来表示KFV在SW-FGO公式下的形式，在明确条件(马尔可夫假设、高斯噪声与L2损失、单状态窗口)下进行理论分析。

Result: 在特定条件下，Re-FGO可精确重现EKF/IEKF/REKF/RIEKF等卡尔曼滤波器变体，而SW-FGO在非线性、非高斯场景中表现出可预测计算成本下的优势。

Conclusion: 澄清了SW-FGO与KFV之间的关系，突出了SW-FGO在实际应用中的独特优势，特别是在数值估计和深度学习集成方面。

Abstract: Sliding window-factor graph optimization (SW-FGO) has gained more and more
attention in navigation research due to its robust approximation to
non-Gaussian noises and nonlinearity of measuring models. There are lots of
works focusing on its application performance compared to extended Kalman
filter (EKF) but there is still a myth at the theoretical relationship between
the SW-FGO and EKF. In this paper, we find the necessarily fair condition to
connect SW-FGO and Kalman filter variants (KFV) (e.g., EKF, iterative EKF
(IEKF), robust EKF (REKF) and robust iterative EKF (RIEKF)). Based on the
conditions, we propose a recursive FGO (Re-FGO) framework to represent KFV
under SW-FGO formulation. Under explicit conditions (Markov assumption,
Gaussian noise with L2 loss, and a one-state window), Re-FGO regenerates
exactly to EKF/IEKF/REKF/RIEKF, while SW-FGO shows measurable benefits in
nonlinear, non-Gaussian regimes at a predictable compute cost. Finally, after
clarifying the connection between them, we highlight the unique advantages of
SW-FGO in practical phases, especially on numerical estimation and deep
learning integration. The code and data used in this work is open sourced at
https://github.com/Baoshan-Song/KFV-FGO-Comparison.

</details>


### [12] [SonarSweep: Fusing Sonar and Vision for Robust 3D Reconstruction via Plane Sweeping](https://arxiv.org/abs/2511.00392)
*Lingpeng Chen,Jiakun Tang,Apple Pui-Yi Chui,Ziyang Hong,Junfeng Wu*

Main category: cs.RO

TL;DR: SonarSweep是一个端到端的深度学习框架，通过改进平面扫描算法实现声纳和视觉数据的跨模态融合，在视觉退化的水下环境中实现精确的3D重建。


<details>
  <summary>Details</summary>
Motivation: 水下视觉退化环境中的3D重建面临巨大挑战：视觉方法因能见度差和几何约束而失败，声纳方法存在高程模糊和低分辨率问题。现有融合技术依赖启发式方法和有缺陷的几何假设，导致显著伪影且无法建模复杂场景。

Method: 提出SonarSweep框架，将原理性的平面扫描算法适配用于声纳和视觉数据的跨模态融合，采用端到端的深度学习架构。

Result: 在高保真仿真和真实环境中的广泛实验表明，SonarSweep能持续生成密集且精确的深度图，在挑战性条件下（特别是高浊度环境）显著优于现有最先进方法。

Conclusion: SonarSweep克服了水下3D重建的局限性，作者将公开代码和首个包含同步立体相机与声纳数据的新型数据集，以促进进一步研究。

Abstract: Accurate 3D reconstruction in visually-degraded underwater environments
remains a formidable challenge. Single-modality approaches are insufficient:
vision-based methods fail due to poor visibility and geometric constraints,
while sonar is crippled by inherent elevation ambiguity and low resolution.
Consequently, prior fusion technique relies on heuristics and flawed geometric
assumptions, leading to significant artifacts and an inability to model complex
scenes. In this paper, we introduce SonarSweep, a novel, end-to-end deep
learning framework that overcomes these limitations by adapting the principled
plane sweep algorithm for cross-modal fusion between sonar and visual data.
Extensive experiments in both high-fidelity simulation and real-world
environments demonstrate that SonarSweep consistently generates dense and
accurate depth maps, significantly outperforming state-of-the-art methods
across challenging conditions, particularly in high turbidity. To foster
further research, we will publicly release our code and a novel dataset
featuring synchronized stereo-camera and sonar data, the first of its kind.

</details>


### [13] [Runge-Kutta Approximations for Direct Coning Compensation Applying Lie Theory](https://arxiv.org/abs/2511.00412)
*John A. Christian,Michael R. Walker II,Wyatt Bridgman,Michael J. Sparapany*

Main category: cs.RO

TL;DR: 提出了一种基于经典龙格-库塔积分方法的新型圆锥补偿算法，为导航系统中的陀螺仪积分提供更精确的补偿方案。


<details>
  <summary>Details</summary>
Motivation: 现代导航系统通常采用捷联式系统，陀螺仪积分需要考虑传感器旋转带来的圆锥效应，需要开发更有效的圆锥补偿算法来提高导航精度。

Method: 直接从经典龙格-库塔积分方法构建新型圆锥补偿算法，提供了一个生成高阶算法的清晰流程。

Result: 展示了简单情况下新算法可退化为最流行的圆锥算法之一，证明了方法的有效性。

Conclusion: 基于龙格-库塔积分的新型圆锥补偿算法为导航系统提供了更精确的陀螺仪积分补偿方案，具有实际应用价值。

Abstract: The integration of gyroscope measurements is an essential task for most
navigation systems. Modern vehicles typically use strapdown systems, such that
gyro integration requires coning compensation to account for the sensor's
rotation during the integration. Many coning compensation algorithms have been
developed and a few are reviewed. This work introduces a new class of coning
correction algorithm built directly from the classical Runge-Kutta integration
routines. A simple case is shown to collapse to one of the most popular coning
algorithms and a clear procedure for generating higher-order algorithms is
presented.

</details>


### [14] [Design and Development of a Modular Bucket Drum Excavator for Lunar ISRU](https://arxiv.org/abs/2511.00492)
*Simon Giel,James Hurrell,Shreya Santra,Ashutosh Mishra,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 开发了一个用于月球机器人系统MoonBot的铲斗滚筒原型，通过沙盒测试验证了其连续和批量挖掘月球土壤的效率。


<details>
  <summary>Details</summary>
Motivation: 月球原位资源利用(ISRU)是实现可持续月球探索的关键技术，挖掘月球土壤是获取和利用月球资源的第一步。

Method: 制造了PLA材料的3D打印原型，通过一系列沙盒测试评估挖掘效率。

Result: 工具重4.8kg，体积14.06L，连续挖掘速率777.54kg/h，能耗0.022Wh/kg；批量挖掘速率172.02kg/h，能耗0.86Wh/kg。

Conclusion: 概念成功实现，工具与模块化MoonBot机器人平台兼容，未来可集成传感器和自主控制系统以改进挖掘过程。

Abstract: In-Situ Resource Utilization (ISRU) is one of the key technologies for
enabling sustainable access to the Moon. The ability to excavate lunar regolith
is the first step in making lunar resources accessible and usable. This work
presents the development of a bucket drum for the modular robotic system
MoonBot, as part of the Japanese Moonshot program. A 3D-printed prototype made
of PLA was manufactured to evaluate its efficiency through a series of sandbox
tests. The resulting tool weighs 4.8 kg and has a volume of 14.06 L. It is
capable of continuous excavation at a rate of 777.54 kg/h with a normalized
energy consumption of 0.022 Wh/kg. In batch operation, the excavation rate is
172.02 kg/h with a normalized energy consumption of 0.86 Wh per kilogram of
excavated material. The obtained results demonstrate the successful
implementation of the concept. A key advantage of the developed tool is its
compatibility with the modular MoonBot robotic platform, which enables flexible
and efficient mission planning. Further improvements may include the
integration of sensors and an autonomous control system to enhance the
excavation process.

</details>


### [15] [Descriptive Model-based Learning and Control for Bipedal Locomotion](https://arxiv.org/abs/2511.00512)
*Suraj Kumar,Andy Ruina*

Main category: cs.RO

TL;DR: 提出一种新的双足平衡控制方法，避免将简化模型强加于完整模型，而是使用最小自由度的描述性模型来维持平衡，让其余自由度在高维空间中自由演化，从而实现高效的人形步态和更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统双足平衡控制方法依赖低维模型进行运动规划和反应控制，限制了机器人的完整行为，导致低效的弯曲膝盖行走模式。研究发现双足平衡本质上是低维的，可以用简单的状态和动作描述符有效描述。

Method: 提出一个控制框架，使用具有维持平衡所需最小自由度的描述性模型，不将低维模型强加于完整模型，让机器人在高维状态空间中自由运动，仅约束其在低维状态空间中的投影。

Result: 该方法产生了高效的人形行走步态，并提高了系统的鲁棒性。

Conclusion: 通过避免将简化模型强加于完整机器人模型，而是使用最小自由度的描述性模型来维持平衡，可以让机器人的运动在高维空间中自由演化，从而实现更自然高效的行走和更好的平衡性能。

Abstract: Bipedal balance is challenging due to its multi-phase, hybrid nature and
high-dimensional state space. Traditional balance control approaches for
bipedal robots rely on low-dimensional models for locomotion planning and
reactive control, constraining the full robot to behave like these simplified
models. This involves tracking preset reference paths for the Center of Mass
and upper body obtained through low-dimensional models, often resulting in
inefficient walking patterns with bent knees. However, we observe that bipedal
balance is inherently low-dimensional and can be effectively described with
simple state and action descriptors in a low-dimensional state space. This
allows the robot's motion to evolve freely in its high-dimensional state space,
only constraining its projection in the low-dimensional state space. In this
work, we propose a novel control approach that avoids prescribing a
low-dimensional model to the full model. Instead, our control framework uses a
descriptive model with the minimum degrees of freedom necessary to maintain
balance, allowing the remaining degrees of freedom to evolve freely in the
high-dimensional space. This results in an efficient human-like walking gait
and improved robustness.

</details>


### [16] [Adaptive and Multi-object Grasping via Deformable Origami Modules](https://arxiv.org/abs/2511.00516)
*Peiyi Wang,Paul A. M. Lefeuvre,Shangwei Zou,Zhenwei Ni,Daniela Rus,Cecilia Laschi*

Main category: cs.RO

TL;DR: 提出了一种基于折纸结构的混合夹爪，具有被动变形能力，能产生恒定力和扭矩输出，无需主动传感或反馈控制即可实现稳定抓取和多物体同时抓取。


<details>
  <summary>Details</summary>
Motivation: 现有软体机器人夹爪通常依赖笨重的执行器、复杂控制策略或先进触觉传感来实现稳定可靠抓取，需要更简单高效的解决方案。

Method: 采用多指混合夹爪设计，每个手指由并行折纸模块组成，通过单自由度执行机构驱动，实现被动形状适应和稳定抓取力。

Result: 展示了同时多物体抓取能力，能够抓取不同形状和尺寸的堆叠物体，并在不同状态下独立放置，显著提高了操作效率。

Conclusion: 折纸基柔性结构作为可扩展模块，在家庭和工业拾放场景中具有实现自适应、稳定和高效多物体操作的潜力。

Abstract: Soft robotics gripper have shown great promise in handling fragile and
geometrically complex objects. However, most existing solutions rely on bulky
actuators, complex control strategies, or advanced tactile sensing to achieve
stable and reliable grasping performance. In this work, we present a
multi-finger hybrid gripper featuring passively deformable origami modules that
generate constant force and torque output. Each finger composed of parallel
origami modules is driven by a 1-DoF actuator mechanism, enabling passive shape
adaptability and stable grasping force without active sensing or feedback
control. More importantly, we demonstrate an interesting capability in
simultaneous multi-object grasping, which allows stacked objects of varied
shape and size to be picked, transported and placed independently at different
states, significantly improving manipulation efficiency compared to
single-object grasping. These results highlight the potential of origami-based
compliant structures as scalable modules for adaptive, stable and efficient
multi-object manipulation in domestic and industrial pick-and-place scenarios.

</details>


### [17] [Improving Robustness to Out-of-Distribution States in Imitation Learning via Deep Koopman-Boosted Diffusion Policy](https://arxiv.org/abs/2511.00555)
*Dianye Huang,Nassir Navab,Zhongliang Jiang*

Main category: cs.RO

TL;DR: 提出D3P算法，通过双分支架构解耦视觉和本体感知输入，结合深度Koopman算子增强视觉表征学习，在机器人操作任务中显著优于现有扩散策略。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的策略在捕捉多步骤间强时序依赖方面存在困难，特别是当加入本体感知输入时，容易过拟合本体感知线索而忽略视觉特征，导致任务失败。

Method: 采用双分支架构：视觉分支编码视觉观察指示任务进展，融合分支整合视觉和本体感知输入进行精确操作。加入深度Koopman算子模块捕捉视觉输入的时序动态，并使用生成模型的测试时损失作为置信度信号指导动作块聚合。

Result: 在6个RLBench桌面任务模拟实验中平均性能提升14.6%，在3个真实世界机器人操作任务中提升15.0%。

Conclusion: D3P算法通过解耦不同感官模态和增强视觉表征学习，有效解决了现有扩散策略在时序依赖和模态融合方面的局限性，显著提升了机器人模仿学习的性能。

Abstract: Integrating generative models with action chunking has shown significant
promise in imitation learning for robotic manipulation. However, the existing
diffusion-based paradigm often struggles to capture strong temporal
dependencies across multiple steps, particularly when incorporating
proprioceptive input. This limitation can lead to task failures, where the
policy overfits to proprioceptive cues at the expense of capturing the visually
derived features of the task. To overcome this challenge, we propose the Deep
Koopman-boosted Dual-branch Diffusion Policy (D3P) algorithm. D3P introduces a
dual-branch architecture to decouple the roles of different sensory modality
combinations. The visual branch encodes the visual observations to indicate
task progression, while the fused branch integrates both visual and
proprioceptive inputs for precise manipulation. Within this architecture, when
the robot fails to accomplish intermediate goals, such as grasping a drawer
handle, the policy can dynamically switch to execute action chunks generated by
the visual branch, allowing recovery to previously observed states and
facilitating retrial of the task. To further enhance visual representation
learning, we incorporate a Deep Koopman Operator module that captures
structured temporal dynamics from visual inputs. During inference, we use the
test-time loss of the generative model as a confidence signal to guide the
aggregation of the temporally overlapping predicted action chunks, thereby
enhancing the reliability of policy execution. In simulation experiments across
six RLBench tabletop tasks, D3P outperforms the state-of-the-art diffusion
policy by an average of 14.6\%. On three real-world robotic manipulation tasks,
it achieves a 15.0\% improvement. Code: https://github.com/dianyeHuang/D3P.

</details>


### [18] [Multi-Mapcher: Loop Closure Detection-Free Heterogeneous LiDAR Multi-Session SLAM Leveraging Outlier-Robust Registration for Autonomous Vehicles](https://arxiv.org/abs/2511.00635)
*Hyungtae Lim,Daebeom Kim,Hyun Myung*

Main category: cs.RO

TL;DR: 提出Multi-Mapcher框架，通过大规模地图到地图配准实现多会话SLAM的初始对齐，避免对回环检测的过度依赖，提高了异构LiDAR传感器的多会话建图性能。


<details>
  <summary>Details</summary>
Motivation: 现有MSS方法主要依赖回环检测进行会话间对齐，但由于不同会话使用的LiDAR传感器在点云密度和视场角上的差异，回环检测性能可能下降。

Method: 使用大规模地图到地图配准进行会话间初始对齐，然后基于半径搜索找到回环，最后采用锚节点优化的位姿图优化构建全局一致地图。

Result: 实验表明该方法在各种LiDAR传感器上的MSS性能显著优于现有方法，且运行速度更快。

Conclusion: Multi-Mapcher框架通过地图到地图配准成功实现了被认为不可行的会话间初始对齐，为异构LiDAR传感器的多会话SLAM提供了有效解决方案。

Abstract: As various 3D light detection and ranging (LiDAR) sensors have been
introduced to the market, research on multi-session simultaneous localization
and mapping (MSS) using heterogeneous LiDAR sensors has been actively
conducted. Existing MSS methods mostly rely on loop closure detection for
inter-session alignment; however, the performance of loop closure detection can
be potentially degraded owing to the differences in the density and field of
view (FoV) of the sensors used in different sessions. In this study, we
challenge the existing paradigm that relies heavily on loop detection modules
and propose a novel MSS framework, called Multi-Mapcher, that employs
large-scale map-to-map registration to perform inter-session initial alignment,
which is commonly assumed to be infeasible, by leveraging outlier-robust 3D
point cloud registration. Next, after finding inter-session loops by radius
search based on the assumption that the inter-session initial alignment is
sufficiently precise, anchor node-based robust pose graph optimization is
employed to build a consistent global map. As demonstrated in our experiments,
our approach shows substantially better MSS performance for various LiDAR
sensors used to capture the sessions and is faster than state-of-the-art
approaches. Our code is available at
https://github.com/url-kaist/multi-mapcher.

</details>


### [19] [When Semantics Connect the Swarm: LLM-Driven Fuzzy Control for Cooperative Multi-Robot Underwater Coverage](https://arxiv.org/abs/2511.00783)
*Jingzehua Xu,Weihang Zhang,Yangyang Li,Hongmiaoyi Zhang,Guanwen Xie,Jiwei Tang,Shuai Zhang,Yi Li*

Main category: cs.RO

TL;DR: 提出了一种语义引导的模糊控制框架，将大语言模型与可解释控制和轻量级协调相结合，解决水下多机器人协同覆盖问题。


<details>
  <summary>Details</summary>
Motivation: 解决水下多机器人协同覆盖面临的挑战：部分可观测性、有限通信、环境不确定性以及缺乏全局定位能力。

Method: 使用LLM将原始多模态观测压缩为紧凑、可解释的语义标记；通过模糊推理系统映射为平滑稳定的转向和步态命令；引入语义通信实现多机器人协调。

Result: 在未知珊瑚礁环境中进行广泛仿真，在有限感知和通信条件下实现了稳健的OOI导向导航和协同覆盖，提高了效率和适应性。

Conclusion: 该框架在GPS拒止、无地图条件下缩小了语义认知与分布式水下控制之间的差距。

Abstract: Underwater multi-robot cooperative coverage remains challenging due to
partial observability, limited communication, environmental uncertainty, and
the lack of access to global localization. To address these issues, this paper
presents a semantics-guided fuzzy control framework that couples Large Language
Models (LLMs) with interpretable control and lightweight coordination. Raw
multimodal observations are compressed by the LLM into compact,
human-interpretable semantic tokens that summarize obstacles, unexplored
regions, and Objects Of Interest (OOIs) under uncertain perception. A fuzzy
inference system with pre-defined membership functions then maps these tokens
into smooth and stable steering and gait commands, enabling reliable navigation
without relying on global positioning. Then, we further coordinate multiple
robots by introducing semantic communication that shares intent and local
context in linguistic form, enabling agreement on who explores where while
avoiding redundant revisits. Extensive simulations in unknown reef-like
environments show that, under limited sensing and communication, the proposed
framework achieves robust OOI-oriented navigation and cooperative coverage with
improved efficiency and adaptability, narrowing the gap between semantic
cognition and distributed underwater control in GPS-denied, map-free
conditions.

</details>


### [20] [Real-Time Learning of Predictive Dynamic Obstacle Models for Robotic Motion Planning](https://arxiv.org/abs/2511.00814)
*Stella Kombo,Masih Haseli,Skylar Wei,Joel W. Burdick*

Main category: cs.RO

TL;DR: 提出了一种实时在线框架，使用改进的滑动窗口Hankel动态模态分解来去噪和预测动态系统运动，支持实时控制应用


<details>
  <summary>Details</summary>
Motivation: 自主系统需要从部分噪声数据中预测附近代理的运动，但现有方法难以在实时条件下学习非线性预测模型

Method: 使用Hankel矩阵嵌入部分噪声测量，通过Page矩阵进行奇异值硬阈值估计有效秩，采用Cadzow投影确保结构化低秩一致性，构建时变Hankel-DMD提升线性预测器进行多步预测

Result: 在模拟和动态起重机实验平台上验证，方法在Gaussian和重尾噪声下都能实现稳定的方差感知去噪和短时域预测

Conclusion: 该方法适合集成到实时控制框架中，为下游估计器和风险感知规划提供方差跟踪信号

Abstract: Autonomous systems often must predict the motions of nearby agents from
partial and noisy data. This paper asks and answers the question: "can we
learn, in real-time, a nonlinear predictive model of another agent's motions?"
Our online framework denoises and forecasts such dynamics using a modified
sliding-window Hankel Dynamic Mode Decomposition (Hankel-DMD). Partial noisy
measurements are embedded into a Hankel matrix, while an associated Page matrix
enables singular-value hard thresholding (SVHT) to estimate the effective rank.
A Cadzow projection enforces structured low-rank consistency, yielding a
denoised trajectory and local noise variance estimates. From this
representation, a time-varying Hankel-DMD lifted linear predictor is
constructed for multi-step forecasts. The residual analysis provides
variance-tracking signals that can support downstream estimators and risk-aware
planning. We validate the approach in simulation under Gaussian and
heavy-tailed noise, and experimentally on a dynamic crane testbed. Results show
that the method achieves stable variance-aware denoising and short-horizon
prediction suitable for integration into real-time control frameworks.

</details>


### [21] [Heuristic Step Planning for Learning Dynamic Bipedal Locomotion: A Comparative Study of Model-Based and Model-Free Approaches](https://arxiv.org/abs/2511.00840)
*William Suliman,Ekaterina Chaikovskaia,Egor Davydenko,Roman Gorbachev*

Main category: cs.RO

TL;DR: 提出了一种结合启发式步态规划的双足机器人学习框架，通过期望躯干速度跟踪实现精确环境交互，在复杂地形上表现出优越的鲁棒性和能效。


<details>
  <summary>Details</summary>
Motivation: 传统基于完整或简化动力学的方法需要复杂的步态规划器和解析模型，本文旨在开发一种避免这些复杂组件但仍能实现稳定双足行走的方法。

Method: 采用启发式命令驱动的步态规划，结合Raibert型控制器根据期望与实际躯干速度误差调节足部放置位置，与基于线性倒立摆模型的传统方法进行对比。

Result: 实验显示该方法在维持目标速度方面达到80%的精度，在不平地形上的鲁棒性提升超过50%，且能效更高。

Conclusion: 结果表明在训练架构中融入复杂的解析模型组件对于实现稳定鲁棒的双足行走可能是不必要的，即使在非结构化环境中也是如此。

Abstract: This work presents an extended framework for learning-based bipedal
locomotion that incorporates a heuristic step-planning strategy guided by
desired torso velocity tracking. The framework enables precise interaction
between a humanoid robot and its environment, supporting tasks such as crossing
gaps and accurately approaching target objects. Unlike approaches based on full
or simplified dynamics, the proposed method avoids complex step planners and
analytical models. Step planning is primarily driven by heuristic commands,
while a Raibert-type controller modulates the foot placement length based on
the error between desired and actual torso velocity. We compare our method with
a model-based step-planning approach -- the Linear Inverted Pendulum Model
(LIPM) controller. Experimental results demonstrate that our approach attains
comparable or superior accuracy in maintaining target velocity (up to 80%),
significantly greater robustness on uneven terrain (over 50% improvement), and
improved energy efficiency. These results suggest that incorporating complex
analytical, model-based components into the training architecture may be
unnecessary for achieving stable and robust bipedal walking, even in
unstructured environments.

</details>


### [22] [Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots](https://arxiv.org/abs/2511.00917)
*Junyao Shi,Rujia Yang,Kaitian Chao,Selina Bingqing Wan,Yifei Shao,Jiahui Lei,Jianing Qian,Long Le,Pratik Chaudhari,Kostas Daniilidis,Chuan Wen,Dinesh Jayaraman*

Main category: cs.RO

TL;DR: Maestro是一个基于视觉语言模型(VLM)的机器人系统，通过动态组合感知、规划和控制模块来构建通用策略，超越了当前VLA模型在零样本操作任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前通用机器人研究主要依赖大规模数据集训练端到端模型，作者探索了另一种路径：围绕VLM构建通用策略，利用其通用能力结合特定机器人模块。

Method: 使用VLM编码代理动态组合感知、规划和控制模块为程序化策略，具有简化的闭环接口和多样化工具库。

Result: 在挑战性操作技能上大幅超越当前VLA模型的零样本性能，易于扩展新模块、适应新机器人形态，并能通过本地代码编辑从少量真实世界经验中快速适应。

Conclusion: Maestro展示了围绕VLM构建模块化机器人系统的可行性，提供了一种可扩展、可编辑和适应性强的通用机器人解决方案。

Abstract: Today's best-explored routes towards generalist robots center on collecting
ever larger "observations-in actions-out" robotics datasets to train large
end-to-end models, copying a recipe that has worked for vision-language models
(VLMs). We pursue a road less traveled: building generalist policies directly
around VLMs by augmenting their general capabilities with specific robot
capabilities encapsulated in a carefully curated set of perception, planning,
and control modules. In Maestro, a VLM coding agent dynamically composes these
modules into a programmatic policy for the current task and scenario. Maestro's
architecture benefits from a streamlined closed-loop interface without many
manually imposed structural constraints, and a comprehensive and diverse tool
repertoire. As a result, it largely surpasses today's VLA models for zero-shot
performance on challenging manipulation skills. Further, Maestro is easily
extensible to incorporate new modules, easily editable to suit new embodiments
such as a quadruped-mounted arm, and even easily adapts from minimal real-world
experiences through local code edits.

</details>


### [23] [Fast-SmartWay: Panoramic-Free End-to-End Zero-Shot Vision-and-Language Navigation](https://arxiv.org/abs/2511.00933)
*Xiangyu Shi,Zerui Li,Yanyuan Qiao,Qi Wu*

Main category: cs.RO

TL;DR: Fast-SmartWay是一个端到端的零样本视觉语言导航框架，仅使用三个前视RGB-D图像和自然语言指令，无需全景视图和路径点预测器，显著降低了延迟并提升了实际应用性。


<details>
  <summary>Details</summary>
Motivation: 现有的VLN-CE方法依赖全景观测和两阶段流水线，导致显著延迟并限制实际应用。本文旨在消除这些限制，开发更实用的零样本导航系统。

Method: 提出Fast-SmartWay框架，仅使用三个前视RGB-D图像结合语言指令，让MLLM直接预测动作。引入不确定性感知推理模块，包括解歧模块（避免局部最优）和未来-过去双向推理机制（实现全局一致性规划）。

Result: 在模拟和真实机器人环境中的实验表明，该方法显著降低了每步延迟，同时达到或超越了基于全景视图基线的性能。

Conclusion: Fast-SmartWay证明了在现实世界中零样本具身导航的实用性和有效性，为实时导航应用提供了可行的解决方案。

Abstract: Recent advances in Vision-and-Language Navigation in Continuous Environments
(VLN-CE) have leveraged multimodal large language models (MLLMs) to achieve
zero-shot navigation. However, existing methods often rely on panoramic
observations and two-stage pipelines involving waypoint predictors, which
introduce significant latency and limit real-world applicability. In this work,
we propose Fast-SmartWay, an end-to-end zero-shot VLN-CE framework that
eliminates the need for panoramic views and waypoint predictors. Our approach
uses only three frontal RGB-D images combined with natural language
instructions, enabling MLLMs to directly predict actions. To enhance decision
robustness, we introduce an Uncertainty-Aware Reasoning module that integrates
(i) a Disambiguation Module for avoiding local optima, and (ii) a Future-Past
Bidirectional Reasoning mechanism for globally coherent planning. Experiments
on both simulated and real-robot environments demonstrate that our method
significantly reduces per-step latency while achieving competitive or superior
performance compared to panoramic-view baselines. These results demonstrate the
practicality and effectiveness of Fast-SmartWay for real-world zero-shot
embodied navigation.

</details>


### [24] [URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model](https://arxiv.org/abs/2511.00940)
*Zhe Li,Xiang Bai,Jieyu Zhang,Zhuangzhe Wu,Che Xu,Ying Li,Chengkai Hou,Shanghang Zhang*

Main category: cs.RO

TL;DR: URDF-Anything是一个基于3D多模态大语言模型的端到端自动重建框架，能够从点云和文本输入中联合优化几何分割和运动学参数预测，显著提升了数字孪生构建的效率和精度。


<details>
  <summary>Details</summary>
Motivation: 构建精确的关节物体数字孪生对于机器人仿真训练和具身AI世界模型构建至关重要，但传统方法需要繁琐的手动建模或多阶段流程，因此需要开发端到端的自动重建方案。

Method: 采用基于点云和文本多模态输入的自回归预测框架，实现专门的[SEG]令牌机制与点云特征直接交互，在保持运动学参数预测一致性的同时实现细粒度零件级分割。

Result: 在仿真和真实数据集上的实验表明，该方法在几何分割（mIoU提升17%）、运动学参数预测（平均误差减少29%）和物理可执行性（超越基线50%）方面显著优于现有方法，并展现出优秀的泛化能力。

Conclusion: 该工作为机器人仿真构建数字孪生提供了高效解决方案，显著增强了从仿真到现实的迁移能力。

Abstract: Constructing accurate digital twins of articulated objects is essential for
robotic simulation training and embodied AI world model building, yet
historically requires painstaking manual modeling or multi-stage pipelines. In
this work, we propose \textbf{URDF-Anything}, an end-to-end automatic
reconstruction framework based on a 3D multimodal large language model (MLLM).
URDF-Anything utilizes an autoregressive prediction framework based on
point-cloud and text multimodal input to jointly optimize geometric
segmentation and kinematic parameter prediction. It implements a specialized
$[SEG]$ token mechanism that interacts directly with point cloud features,
enabling fine-grained part-level segmentation while maintaining consistency
with the kinematic parameter predictions. Experiments on both simulated and
real-world datasets demonstrate that our method significantly outperforms
existing approaches regarding geometric segmentation (mIoU 17\% improvement),
kinematic parameter prediction (average error reduction of 29\%), and physical
executability (surpassing baselines by 50\%). Notably, our method exhibits
excellent generalization ability, performing well even on objects outside the
training set. This work provides an efficient solution for constructing digital
twins for robotic simulation, significantly enhancing the sim-to-real transfer
capability.

</details>


### [25] [Breaking the Latency Barrier: Synergistic Perception and Control for High-Frequency 3D Ultrasound Servoing](https://arxiv.org/abs/2511.00983)
*Yizhao Qian,Yujie Zhu,Jiayuan Luo,Li Liu,Yixuan Yuan,Guochen Ning,Hongen Liao*

Main category: cs.RO

TL;DR: 提出了一种用于机器人超声系统的实时动态目标跟踪框架，通过感知与控制协同设计，实现超过60Hz的闭环控制频率，在复杂3D轨迹跟踪中平均误差低于6.5mm。


<details>
  <summary>Details</summary>
Motivation: 解决机器人超声系统中大规模高频干扰下动态目标实时跟踪的关键挑战，突破现有系统端到端延迟的限制。

Method: 采用解耦双流感知网络从2D图像高频估计3D平移状态，以及单步流策略在一次推理中生成完整动作序列，绕过传统策略的迭代瓶颈。

Result: 在动态体模上跟踪复杂3D轨迹平均误差低于6.5mm，能从超过170mm位移中重新获取目标，以102mm/s速度跟踪时终端误差低于1.7mm，人体志愿者实验验证了有效性。

Conclusion: 该工作提出了一个整体架构的机器人超声系统，统一了高带宽跟踪与大规模重新定位，是实现动态临床环境中鲁棒自主性的关键步骤。

Abstract: Real-time tracking of dynamic targets amidst large-scale, high-frequency
disturbances remains a critical unsolved challenge in Robotic Ultrasound
Systems (RUSS), primarily due to the end-to-end latency of existing systems.
This paper argues that breaking this latency barrier requires a fundamental
shift towards the synergistic co-design of perception and control. We realize
it in a novel framework with two tightly-coupled contributions: (1) a Decoupled
Dual-Stream Perception Network that robustly estimates 3D translational state
from 2D images at high frequency, and (2) a Single-Step Flow Policy that
generates entire action sequences in one inference pass, bypassing the
iterative bottleneck of conventional policies. This synergy enables a
closed-loop control frequency exceeding 60Hz. On a dynamic phantom, our system
not only tracks complex 3D trajectories with a mean error below 6.5mm but also
demonstrates robust re-acquisition from over 170mm displacement. Furthermore,
it can track targets at speeds of 102mm/s, achieving a terminal error below
1.7mm. Moreover, in-vivo experiments on a human volunteer validate the
framework's effectiveness and robustness in a realistic clinical setting. Our
work presents a RUSS holistically architected to unify high-bandwidth tracking
with large-scale repositioning, a critical step towards robust autonomy in
dynamic clinical environments.

</details>


### [26] [GauDP: Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies](https://arxiv.org/abs/2511.00998)
*Ziye Wang,Li Kang,Yiran Qin,Jiahua Ma,Zhanglin Peng,Lei Bai,Ruimao Zhang*

Main category: cs.RO

TL;DR: GauDP是一种高斯-图像协同表示方法，通过构建全局一致的3D高斯场并动态重分布到各智能体局部视角，实现多智能体协作系统中的可扩展感知感知模仿学习。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以平衡细粒度局部控制与全局场景理解，导致可扩展性有限和协作质量受损。需要一种能同时支持精细控制和全局一致行为的方法，且不依赖额外传感模式。

Method: 从分散的RGB观测构建全局一致的3D高斯场，然后动态重分布3D高斯属性到各智能体的局部视角，使所有智能体能从共享场景表示中自适应查询任务关键特征。

Result: 在RoboFactory基准测试中，GauDP优于现有基于图像的方法，接近基于点云方法的有效性，且在智能体数量增加时保持强可扩展性。

Conclusion: GauDP通过高斯-图像协同表示实现了多智能体协作中细粒度控制与全局一致行为的平衡，无需额外传感模式，具有良好可扩展性。

Abstract: Recently, effective coordination in embodied multi-agent systems has remained
a fundamental challenge, particularly in scenarios where agents must balance
individual perspectives with global environmental awareness. Existing
approaches often struggle to balance fine-grained local control with
comprehensive scene understanding, resulting in limited scalability and
compromised collaboration quality. In this paper, we present GauDP, a novel
Gaussian-image synergistic representation that facilitates scalable,
perception-aware imitation learning in multi-agent collaborative systems.
Specifically, GauDP constructs a globally consistent 3D Gaussian field from
decentralized RGB observations, then dynamically redistributes 3D Gaussian
attributes to each agent's local perspective. This enables all agents to
adaptively query task-critical features from the shared scene representation
while maintaining their individual viewpoints. This design facilitates both
fine-grained control and globally coherent behavior without requiring
additional sensing modalities (e.g., 3D point cloud). We evaluate GauDP on the
RoboFactory benchmark, which includes diverse multi-arm manipulation tasks. Our
method achieves superior performance over existing image-based methods and
approaches the effectiveness of point-cloud-driven methods, while maintaining
strong scalability as the number of agents increases.

</details>


### [27] [AquaROM: shape optimization pipeline for soft swimmers using parametric reduced order models](https://arxiv.org/abs/2511.01031)
*Mathieu Dubied,Paolo Tiso,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: 提出基于张量参数降阶模型(PROM)的优化算法，用于高效优化受复杂非线性力作用的软体结构，特别针对软体机器人形状优化问题。


<details>
  <summary>Details</summary>
Motivation: 软体结构在复杂非线性力作用下的高效优化是机器人技术发展的关键挑战，传统有限元模拟计算成本高昂，特别是在优化过程中。

Method: 使用张量参数降阶模型(PROM)，结合维度缩减和求解近似技术，在特定选择的降阶基(ROB)中使用解析梯度，显著提高计算效率。

Result: 成功应用于软体游泳机器人形状优化，该方法能够处理内外非线性力(包括流体动力)，实现快速准确计算。

Conclusion: 该方法不仅降低了计算复杂度，还为软体机器人中复杂非线性系统的优化开辟了新途径，推动更高效的设计和控制。

Abstract: The efficient optimization of actuated soft structures, particularly under
complex nonlinear forces, remains a critical challenge in advancing robotics.
Simulations of nonlinear structures, such as soft-bodied robots modeled using
the finite element method (FEM), often demand substantial computational
resources, especially during optimization. To address this challenge, we
propose a novel optimization algorithm based on a tensorial parametric reduced
order model (PROM). Our algorithm leverages dimensionality reduction and
solution approximation techniques to facilitate efficient solving of nonlinear
constrained optimization problems. The well-structured tensorial approach
enables the use of analytical gradients within a specifically chosen reduced
order basis (ROB), significantly enhancing computational efficiency. To
showcase the performance of our method, we apply it to optimizing soft robotic
swimmer shapes. These actuated soft robots experience hydrodynamic forces,
subjecting them to both internal and external nonlinear forces, which are
incorporated into our optimization process using a data-free ROB for fast and
accurate computations. This approach not only reduces computational complexity
but also unlocks new opportunities to optimize complex nonlinear systems in
soft robotics, paving the way for more efficient design and control.

</details>


### [28] [Deployable Vision-driven UAV River Navigation via Human-in-the-loop Preference Alignment](https://arxiv.org/abs/2511.01083)
*Zihan Wang,Jianwen Li,Li-Fan Wu,Nina Mahmoudian*

Main category: cs.RO

TL;DR: SPAR-H是一种人机协同学习方法，通过融合直接偏好优化和基于奖励的路径，在无人机河流跟随任务中实现高效在线适应，仅需5次人工干预就能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 无人机在河流环境监测中面临仿真训练与实际部署的分布偏移和安全风险，需要从有限的人工干预中实现高效适应。

Method: 提出SPAR-H方法，结合直接偏好优化和基于奖励的路径，训练即时奖励估计器，并使用信任域代理更新策略。

Result: 仅用5次人工干预，SPAR-H在所有测试方法中获得最高的最终回合奖励和最低的方差，奖励模型与人类偏好一致。

Conclusion: 双重状态偏好为河流导航中的数据高效在线适应提供了实用途径。

Abstract: Rivers are critical corridors for environmental monitoring and disaster
response, where Unmanned Aerial Vehicles (UAVs) guided by vision-driven
policies can provide fast, low-cost coverage. However, deployment exposes
simulation-trained policies with distribution shift and safety risks and
requires efficient adaptation from limited human interventions. We study
human-in-the-loop (HITL) learning with a conservative overseer who vetoes
unsafe or inefficient actions and provides statewise preferences by comparing
the agent's proposal with a corrective override. We introduce Statewise Hybrid
Preference Alignment for Robotics (SPAR-H), which fuses direct preference
optimization on policy logits with a reward-based pathway that trains an
immediate-reward estimator from the same preferences and updates the policy
using a trust-region surrogate. With five HITL rollouts collected from a fixed
novice policy, SPAR-H achieves the highest final episodic reward and the lowest
variance across initial conditions among tested methods. The learned reward
model aligns with human-preferred actions and elevates nearby non-intervened
choices, supporting stable propagation of improvements. We benchmark SPAR-H
against imitation learning (IL), direct preference variants, and evaluative
reinforcement learning (RL) in the HITL setting, and demonstrate real-world
feasibility of continual preference alignment for UAV river following. Overall,
dual statewise preferences empirically provide a practical route to
data-efficient online adaptation in riverine navigation.

</details>


### [29] [SLAP: Shortcut Learning for Abstract Planning](https://arxiv.org/abs/2511.01107)
*Y. Isabel Liu,Bowen Li,Benjamin Eysenbach,Tom Silver*

Main category: cs.RO

TL;DR: SLAP方法通过结合任务与运动规划(TAMP)和模型无关强化学习，自动发现新的抽象动作选项，解决了长时程决策中稀疏奖励和连续状态空间的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统TAMP方法依赖人工定义的抽象动作选项，限制了智能体只能执行人类工程师已知的行为。需要一种能自动发现新选项的方法来扩展智能体的行为能力。

Method: 利用现有TAMP选项构建抽象规划图，然后使用模型无关强化学习在图中学习捷径，自动发现新的抽象动作选项。

Result: 在四个模拟机器人环境中，SLAP显著缩短了规划长度（减少50%以上），提高了任务成功率，并发现了动态物理即兴动作（如拍打、摆动、擦拭）。

Conclusion: SLAP成功结合了规划和强化学习的优势，能够自动发现超越人工定义的行为选项，在长时程决策任务中优于纯规划和分层强化学习方法。

Abstract: Long-horizon decision-making with sparse rewards and continuous states and
actions remains a fundamental challenge in AI and robotics. Task and motion
planning (TAMP) is a model-based framework that addresses this challenge by
planning hierarchically with abstract actions (options). These options are
manually defined, limiting the agent to behaviors that we as human engineers
know how to program (pick, place, move). In this work, we propose Shortcut
Learning for Abstract Planning (SLAP), a method that leverages existing TAMP
options to automatically discover new ones. Our key idea is to use model-free
reinforcement learning (RL) to learn shortcuts in the abstract planning graph
induced by the existing options in TAMP. Without any additional assumptions or
inputs, shortcut learning leads to shorter solutions than pure planning, and
higher task success rates than flat and hierarchical RL. Qualitatively, SLAP
discovers dynamic physical improvisations (e.g., slap, wiggle, wipe) that
differ significantly from the manually-defined ones. In experiments in four
simulated robotic environments, we show that SLAP solves and generalizes to a
wide range of tasks, reducing overall plan lengths by over 50% and consistently
outperforming planning and RL baselines.

</details>


### [30] [An Enhanced Proprioceptive Method for Soft Robots Integrating Bend Sensors and IMUs](https://arxiv.org/abs/2511.01165)
*Dong Heon Han,Mayank Mehta,Runze Zuo,Zachary Wanger,Daniel Bruder*

Main category: cs.RO

TL;DR: 提出一种使用现成传感器的增强型本体感知方法，用于软机器人的精确形状估计，通过IMU和弯曲传感器融合来减轻IMU漂移，实现可靠的长期本体感知。


<details>
  <summary>Details</summary>
Motivation: 解决软机器人形状估计中IMU传感器漂移问题，同时保持成本效益和易用性，实现可靠的长期本体感知。

Method: 使用惯性测量单元(IMU)和互补弯曲传感器集成，通过卡尔曼滤波器融合两种传感器的段尖方向数据，采用分段恒定曲率模型从融合的方向数据估计尖端位置并重建机器人变形。

Result: 在45分钟连续运行的无负载、外力和被动障碍物交互实验中，均方根误差为16.96毫米（总长度的2.91%），相比仅使用IMU的方法减少了56%。

Conclusion: 该方法不仅实现了软机器人的长期本体感知，而且在各种不同条件下保持了高精度和鲁棒性。

Abstract: This study presents an enhanced proprioceptive method for accurate shape
estimation of soft robots using only off-the-shelf sensors, ensuring
cost-effectiveness and easy applicability. By integrating inertial measurement
units (IMUs) with complementary bend sensors, IMU drift is mitigated, enabling
reliable long-term proprioception. A Kalman filter fuses segment tip
orientations from both sensors in a mutually compensatory manner, improving
shape estimation over single-sensor methods. A piecewise constant curvature
model estimates the tip location from the fused orientation data and
reconstructs the robot's deformation. Experiments under no loading, external
forces, and passive obstacle interactions during 45 minutes of continuous
operation showed a root mean square error of 16.96 mm (2.91% of total length),
a 56% reduction compared to IMU-only benchmarks. These results demonstrate that
our approach not only enables long-duration proprioception in soft robots but
also maintains high accuracy and robustness across these diverse conditions.

</details>


### [31] [Scaling Cross-Embodiment World Models for Dexterous Manipulation](https://arxiv.org/abs/2511.01177)
*Zihao He,Bo Ai,Tongzhou Mu,Yulin Liu,Weikang Wan,Jiawei Fu,Yilun Du,Henrik I. Christensen,Hao Su*

Main category: cs.RO

TL;DR: 本文提出了一种跨具身学习方法，通过将不同形态的机器人表示为3D粒子集，定义粒子位移作为动作，构建图结构的世界模型来捕捉环境动态，实现异构数据和策略的共享与迁移。


<details>
  <summary>Details</summary>
Motivation: 解决跨具身学习中由于动作空间和运动学差异导致的数据共享和策略迁移困难问题，探索是否存在跨具身不变的特性。

Method: 将不同具身（如人手和机器人手）表示为3D粒子集，动作定义为粒子位移，构建共享表示；训练基于图的世界模型，结合基于模型的规划部署到新硬件。

Result: 实验发现：(i)增加训练具身数量能改善对未见具身的泛化；(ii)仿真和真实数据联合训练优于单独训练；(iii)学习到的模型能在不同自由度的机器人上实现有效控制。

Conclusion: 世界模型是跨具身灵巧操作的有前景接口，环境动态是具身不变的特性。

Abstract: Cross-embodiment learning seeks to build generalist robots that operate
across diverse morphologies, but differences in action spaces and kinematics
hinder data sharing and policy transfer. This raises a central question: Is
there any invariance that allows actions to transfer across embodiments? We
conjecture that environment dynamics are embodiment-invariant, and that world
models capturing these dynamics can provide a unified interface across
embodiments. To learn such a unified world model, the crucial step is to design
state and action representations that abstract away embodiment-specific details
while preserving control relevance. To this end, we represent different
embodiments (e.g., human hands and robot hands) as sets of 3D particles and
define actions as particle displacements, creating a shared representation for
heterogeneous data and control problems. A graph-based world model is then
trained on exploration data from diverse simulated robot hands and real human
hands, and integrated with model-based planning for deployment on novel
hardware. Experiments on rigid and deformable manipulation tasks reveal three
findings: (i) scaling to more training embodiments improves generalization to
unseen ones, (ii) co-training on both simulated and real data outperforms
training on either alone, and (iii) the learned models enable effective control
on robots with varied degrees of freedom. These results establish world models
as a promising interface for cross-embodiment dexterous manipulation.

</details>


### [32] [LiDAR-VGGT: Cross-Modal Coarse-to-Fine Fusion for Globally Consistent and Metric-Scale Dense Mapping](https://arxiv.org/abs/2511.01186)
*Lijie Wang,Lianjie Guo,Ziyi Xu,Qianhao Wang,Fei Gao,Xieyuanli Chen*

Main category: cs.RO

TL;DR: 提出LiDAR-VGGT框架，通过两阶段融合将LiDAR惯性里程计与VGGT模型结合，解决VGGT在大规模环境中尺度缺失和LIVO对外参标定敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LIVO方法对外参标定敏感，而3D视觉基础模型VGGT在大规模环境中缺乏度量尺度且可扩展性有限。

Method: 采用两阶段粗到精融合：预融合模块通过鲁棒初始化优化估计VGGT位姿和点云；后融合模块增强跨模态3D相似变换，使用边界框正则化减少传感器FOV不一致导致的尺度失真。

Result: 在多个数据集上的实验表明，LiDAR-VGGT实现了密集、全局一致的彩色点云，优于VGGT方法和LIVO基线。

Conclusion: LiDAR-VGGT框架有效解决了VGGT的尺度问题和LIVO的标定敏感问题，实现了高质量的彩色点云重建。

Abstract: Reconstructing large-scale colored point clouds is an important task in
robotics, supporting perception, navigation, and scene understanding. Despite
advances in LiDAR inertial visual odometry (LIVO), its performance remains
highly sensitive to extrinsic calibration. Meanwhile, 3D vision foundation
models, such as VGGT, suffer from limited scalability in large environments and
inherently lack metric scale. To overcome these limitations, we propose
LiDAR-VGGT, a novel framework that tightly couples LiDAR inertial odometry with
the state-of-the-art VGGT model through a two-stage coarse- to-fine fusion
pipeline: First, a pre-fusion module with robust initialization refinement
efficiently estimates VGGT poses and point clouds with coarse metric scale
within each session. Then, a post-fusion module enhances cross-modal 3D
similarity transformation, using bounding-box-based regularization to reduce
scale distortions caused by inconsistent FOVs between LiDAR and camera sensors.
Extensive experiments across multiple datasets demonstrate that LiDAR-VGGT
achieves dense, globally consistent colored point clouds and outperforms both
VGGT-based methods and LIVO baselines. The implementation of our proposed novel
color point cloud evaluation toolkit will be released as open source.

</details>


### [33] [Closed-loop Control of Steerable Balloon Endoscopes for Robot-assisted Transcatheter Intracardiac Procedures](https://arxiv.org/abs/2511.01199)
*Max McCandless,Jonathan Hamid,Sammy Elmariah,Nathaniel Langer,Pierre E. Dupont*

Main category: cs.RO

TL;DR: 提出一种可操纵球囊心脏镜，通过单一输入（球囊充气压力）独立控制球囊直径和弯曲角度，实现心脏内可视化及器械输送，并演示了基于图像的闭环弯曲角度控制。


<details>
  <summary>Details</summary>
Motivation: 为从开胸手术转向更安全的经导管手术，需要改进成像技术和机器人解决方案，以简化、精确地导航器械。现有成像方式如荧光透视和超声存在局限性，可通过心脏镜（心脏内直接光学可视化）克服。

Method: 设计可操纵球囊心脏镜，球囊可收缩通过血管系统，然后在心脏内充气进行可视化，并通过集成工作通道输送器械。通过精心设计球囊壁厚度，使用单一输入（球囊充气压力）独立控制球囊直径（对应视野直径）和球囊弯曲角度（实现精确工作通道定位）。

Result: 该球囊技术可调整以设计适用于各种心脏内任务的球囊心脏镜。针对主动脉瓣叶撕裂的具体任务展示了球囊设计，并演示了基于图像的闭环弯曲角度控制，在器械插入和取出期间实现稳定的方向控制。

Conclusion: 可操纵球囊心脏镜提供了一种有前景的方法，通过单一控制输入实现心脏内可视化和器械输送，为经导管心脏手术提供了改进的成像和导航能力。

Abstract: To move away from open-heart surgery towards safer transcatheter procedures,
there is a growing need for improved imaging techniques and robotic solutions
to enable simple, accurate tool navigation. Common imaging modalities, such as
fluoroscopy and ultrasound, have limitations that can be overcome using
cardioscopy, i.e., direct optical visualization inside the beating heart. We
present a cardioscope designed as a steerable balloon. As a balloon, it can be
collapsed to pass through the vasculature and subsequently inflated inside the
heart for visualization and tool delivery through an integrated working
channel. Through careful design of balloon wall thickness, a single input,
balloon inflation pressure, is used to independently control two outputs,
balloon diameter (corresponding to field of view diameter) and balloon bending
angle (enabling precise working channel positioning). This balloon technology
can be tuned to produce cardioscopes designed for a range of intracardiac
tasks. To illustrate this approach, a balloon design is presented for the
specific task of aortic leaflet laceration. Image-based closed-loop control of
bending angle is also demonstrated as a means of enabling stable orientation
control during tool insertion and removal.

</details>


### [34] [Tackling the Kidnapped Robot Problem via Sparse Feasible Hypothesis Sampling and Reliable Batched Multi-Stage Inference](https://arxiv.org/abs/2511.01219)
*Muhua Zhang,Lei Ma,Ying Wu,Kai Shen,Deqing Huang,Henry Leung*

Main category: cs.RO

TL;DR: 提出一个被动2D全局重定位框架，解决机器人绑架问题，通过单次LiDAR扫描和占据栅格地图高效可靠地估计全局位姿，使用多假设方案平衡完整性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决机器人绑架问题（KRP）——在已知地图中重新定位机器人而无需先验位姿估计，这对于定位丢失或SLAM初始化至关重要，旨在提升移动机器人的长期自主性。

Method: 采用多假设方案，使用RRT在可通行约束下生成稀疏均匀的位置假设，通过SMAD指标初步排序假设并实现早期终止，提出TAM指标进行可靠的方向选择和最终位姿评估。

Result: 在资源受限的移动机器人上的真实世界实验表明，该框架在全局重定位成功率和计算效率方面均优于现有方法。

Conclusion: 所提出的被动2D全局重定位框架能够高效可靠地解决机器人绑架问题，显著提升了移动机器人的长期自主运行能力。

Abstract: This paper addresses the Kidnapped Robot Problem (KRP), a core localization
challenge of relocalizing a robot in a known map without prior pose estimate
when localization loss or at SLAM initialization. For this purpose, a passive
2-D global relocalization framework is proposed. It estimates the global pose
efficiently and reliably from a single LiDAR scan and an occupancy grid map
while the robot remains stationary, thereby enhancing the long-term autonomy of
mobile robots. The proposed framework casts global relocalization as a
non-convex problem and solves it via the multi-hypothesis scheme with batched
multi-stage inference and early termination, balancing completeness and
efficiency. The Rapidly-exploring Random Tree (RRT), under traversability
constraints, asymptotically covers the reachable space to generate sparse,
uniformly distributed feasible positional hypotheses, fundamentally reducing
the sampling space. The hypotheses are preliminarily ordered by the proposed
Scan Mean Absolute Difference (SMAD), a coarse beam-error level metric that
facilitates the early termination by prioritizing high-likelihood candidates.
The SMAD computation is optimized for non-panoramic scans. And the
Translation-Affinity Scan-to-Map Alignment Metric (TAM) is proposed for
reliable orientation selection at hypothesized positions and accurate final
pose evaluation to mitigate degradation in conventional likelihood-field
metrics under translational uncertainty induced by sparse hypotheses, as well
as non-panoramic LiDAR scan and environmental changes. Real-world experiments
on a resource-constrained mobile robot with non-panoramic LiDAR scan
demonstrate that the proposed framework outperforms existing methods in both
global relocalization success rate and computational efficiency.

</details>


### [35] [Embodiment Transfer Learning for Vision-Language-Action Models](https://arxiv.org/abs/2511.01224)
*Chengmeng Li,Yaxin Peng*

Main category: cs.RO

TL;DR: 提出了ET-VLA框架，通过合成继续预训练和具身思维图技术，有效将预训练的视觉-语言-动作模型迁移到多机器人协作场景，在双手机器人任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归VLA模型在多机器人协作方面存在困难，需要一种高效的方法将预训练模型迁移到多机器人场景，同时减少真实数据收集成本。

Method: 采用合成继续预训练(SCP)使用合成数据预热模型，学习正确动作和精确动作标记数量；然后进行目标具身数据微调；并引入具身思维图技术，将子任务建模为节点以区分不同具身的功能角色。

Result: 在三个不同双手机器人具身上验证，在六个真实世界任务中比OpenVLA性能提升超过53.2%。

Conclusion: ET-VLA框架能够有效解决VLA模型在多机器人协作中的迁移问题，显著提升性能，并将开源代码支持社区发展。

Abstract: Vision-language-action (VLA) models have significantly advanced robotic
learning, enabling training on large-scale, cross-embodiment data and
fine-tuning for specific robots. However, state-of-the-art autoregressive VLAs
struggle with multi-robot collaboration. We introduce embodiment transfer
learning, denoted as ET-VLA, a novel framework for efficient and effective
transfer of pre-trained VLAs to multi-robot. ET-VLA's core is Synthetic
Continued Pretraining (SCP), which uses synthetically generated data to warm up
the model for the new embodiment, bypassing the need for real human
demonstrations and reducing data collection costs. SCP enables the model to
learn correct actions and precise action token numbers. Following SCP, the
model is fine-tuned on target embodiment data. To further enhance the model
performance on multi-embodiment, we present the Embodied Graph-of-Thought
technique, a novel approach that formulates each sub-task as a node, that
allows the VLA model to distinguish the functionalities and roles of each
embodiment during task execution. Our work considers bimanual robots, a simple
version of multi-robot to verify our approaches. We validate the effectiveness
of our method on both simulation benchmarks and real robots covering three
different bimanual embodiments. In particular, our proposed ET-VLA \space can
outperform OpenVLA on six real-world tasks over 53.2%. We will open-source all
codes to support the community in advancing VLA models for robot learning.

</details>


### [36] [High-Precision Surgical Robotic System for Intraocular Procedures](https://arxiv.org/abs/2511.01232)
*Yu-Ting Lai,Jacob Rosen,Yasamin Foroutani,Ji Ma,Wen-Cheng Wu,Jean-Pierre Hubschman,Tsu-Chin Tsao*

Main category: cs.RO

TL;DR: 开发了一种新的机器人系统，用于提高眼科手术中工具尖端精度、跟踪性能和器械交换机制，在OCT引导下实现了高精度的白内障晶状体提取手术。


<details>
  <summary>Details</summary>
Motivation: 现有机器人系统在眼科手术中精度、自由度和器械交换机制不足，需要开发更精确、灵活的手术机器人系统。

Method: 设计制造了新型机器人系统，通过机器人校准和精确坐标配准，使用OCT系统评估工具尖端精度和远程运动中心机制，并结合深度学习进行术前解剖建模和实时监督。

Result: 工具尖端定位精度达到0.053±0.031毫米，成功演示了OCT引导的自动化白内障晶状体提取手术。

Conclusion: 该机器人系统显著提高了眼科手术的精度和自动化水平，为复杂眼科手术提供了可靠的技术支持。

Abstract: Despite the extensive demonstration of robotic systems for both cataract and
vitreoretinal procedures, existing technologies or mechanisms still possess
insufficient accuracy, precision, and degrees of freedom for instrument
manipulation or potentially automated tool exchange during surgical procedures.
A new robotic system that focuses on improving tooltip accuracy, tracking
performance, and smooth instrument exchange mechanism is therefore designed and
manufactured. Its tooltip accuracy, precision, and mechanical capability of
maintaining small incision through remote center of motion were externally
evaluated using an optical coherence tomography (OCT) system. Through robot
calibration and precise coordinate registration, the accuracy of tooltip
positioning was measured to be 0.053$\pm$0.031 mm, and the overall performance
was demonstrated on an OCT-guided automated cataract lens extraction procedure
with deep learning-based pre-operative anatomical modeling and real-time
supervision.

</details>


### [37] [A High-Speed Capable Spherical Robot](https://arxiv.org/abs/2511.01288)
*Bixuan Zhang,Fengqi Zhang,Haojie Chen,You Wang,Jie Hao,Zhiyuan Luo,Guang Li*

Main category: cs.RO

TL;DR: 设计了一种新型球形机器人结构，通过引入与次摆对齐的动量轮，实现了高达10 m/s的高速稳定运动，显著提升了越障能力和地形适应性。


<details>
  <summary>Details</summary>
Motivation: 基于单摆驱动球形机器人的局限性，旨在开发能够实现高速稳定运动的新型球形机器人结构，突破原有结构的速度限制。

Method: 在单摆驱动球形机器人基础上，增加一个与次摆轴线对齐的动量轮，形成新型球形机器人结构，通过解耦控制实现稳定高速运动。

Result: 物理样机实验证明，该新型球形机器人能够实现高达10 m/s的稳定高速运动，同时显著提升了越障性能和地形鲁棒性。

Conclusion: 提出的新型球形机器人结构成功解决了高速运动稳定性问题，为球形机器人的高速应用开辟了新途径。

Abstract: This paper designs a new spherical robot structure capable of supporting
high-speed motion at up to 10 m/s. Building upon a single-pendulum-driven
spherical robot, the design incorporates a momentum wheel with an axis aligned
with the secondary pendulum, creating a novel spherical robot structure.
Practical experiments with the physical prototype have demonstrated that this
new spherical robot can achieve stable high-speed motion through simple
decoupled control, which was unattainable with the original structure. The
spherical robot designed for high-speed motion not only increases speed but
also significantly enhances obstacle-crossing performance and terrain
robustness.

</details>


### [38] [Don't Just Search, Understand: Semantic Path Planning Agent for Spherical Tensegrity Robots in Unknown Environments](https://arxiv.org/abs/2511.01236)
*Junwen Zhang,Changyue Liu,Pengqi Fu,Xiang Guo,Ye Shi,Xudong Liang,Zhijian Wang,Hanzhi Ma*

Main category: cs.RO

TL;DR: SATPlanner是一种基于大语言模型的语义路径规划器，专为球形张拉整体机器人设计，通过自适应观察窗口机制在未知环境中实现高效可靠的路径规划。


<details>
  <summary>Details</summary>
Motivation: 传统路径规划器将环境视为几何网格，在复杂场景中容易失败且缺乏语义理解。球形张拉整体机器人作为混合软硬设计的典型代表，在未知环境中的路径规划需要平衡探索效率和规划鲁棒性。

Method: 将路径规划重新定义为语义推理任务，提出SATPlanner框架，核心是受LLM快慢思维启发的自适应观察窗口机制，动态调整感知范围：在开阔空间缩小以快速穿越，在复杂障碍配置时扩大以进行推理。

Result: 在1000次仿真试验中达到100%成功率，优于其他实时规划算法。相比A*算法减少37.2%的搜索空间，同时保持接近最优的路径长度。在物理原型机器人上验证了可行性。

Conclusion: SATPlanner通过语义理解实现了高效的路径规划，搜索空间仅随路径长度线性增长(O(L))，为张拉整体机器人在未知环境中的导航提供了可靠解决方案。

Abstract: Endowed with inherent dynamical properties that grant them remarkable
ruggedness and adaptability, spherical tensegrity robots stand as prototypical
examples of hybrid softrigid designs and excellent mobile platforms. However,
path planning for these robots in unknown environments presents a significant
challenge, requiring a delicate balance between efficient exploration and
robust planning. Traditional path planners, which treat the environment as a
geometric grid, often suffer from redundant searches and are prone to failure
in complex scenarios due to their lack of semantic understanding. To overcome
these limitations, we reframe path planning in unknown environments as a
semantic reasoning task. We introduce a Semantic Agent for Tensegrity robots
(SATPlanner) driven by a Large Language Model (LLM). SATPlanner leverages
high-level environmental comprehension to generate efficient and reliable
planning strategies.At the core of SATPlanner is an Adaptive Observation Window
mechanism, inspired by the "fast" and "slow" thinking paradigms of LLMs. This
mechanism dynamically adjusts the perceptual field of the agent: it narrows for
rapid traversal of open spaces and expands to reason about complex obstacle
configurations. This allows the agent to construct a semantic belief of the
environment, enabling the search space to grow only linearly with the path
length (O(L)) while maintaining path quality. We extensively evaluate
SATPlanner in 1,000 simulation trials, where it achieves a 100% success rate,
outperforming other real-time planning algorithms. Critically, SATPlanner
reduces the search space by 37.2% compared to the A* algorithm while achieving
comparable, near-optimal path lengths. Finally, the practical feasibility of
SATPlanner is validated on a physical spherical tensegrity robot prototype.

</details>


### [39] [MOBIUS: A Multi-Modal Bipedal Robot that can Walk, Crawl, Climb, and Roll](https://arxiv.org/abs/2511.01774)
*Alexander Schperberg,Yusuke Tanaka,Stefano Di Cairano,Dennis Hong*

Main category: cs.RO

TL;DR: MOBIUS是一个多模态双足城市侦察机器人，能够行走、爬行、攀爬和滚动，通过混合控制架构和高级规划实现多种运动模式的平滑转换。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在复杂城市环境中灵活移动和操作的机器人，通过整合形态、高级规划和控制来扩展机器人的交互能力、工作空间和可穿越性。

Method: 采用四肢体设计（两个6自由度手臂和两个4自由度腿部），结合强化学习的运动控制与基于模型的预测和导纳控制，使用MIQCP规划器自主选择运动模式。

Result: 硬件实验展示了稳健的步态转换、动态攀爬和通过捏握实现的全身体负载支撑，证明了系统的鲁棒性和多功能性。

Conclusion: MOBIUS展示了形态、高级规划和控制紧密集成对于实现移动定位操作和抓取的重要性，显著扩展了机器人的交互能力、工作空间和可穿越性。

Abstract: This article presents a Multi-Modal Bipedal Intelligent Urban Scout robot
(MOBIUS) capable of walking, crawling, climbing, and rolling. MOBIUS features
four limbs--two 6-DoF arms with two-finger grippers for manipulation and
climbing, and two 4-DoF legs for locomotion--enabling smooth transitions across
diverse terrains without reconfiguration. A hybrid control architecture
combines reinforcement learning-based locomotion with model-based predictive
and admittance control enhanced for safety by a Reference Governor toward
compliant contact interactions. A high-level MIQCP planner autonomously selects
locomotion modes to balance stability and energy efficiency. Hardware
experiments demonstrate robust gait transitions, dynamic climbing, and
full-body load support via pinch grasp. Overall, MOBIUS demonstrates the
importance of tight integration between morphology, high-level planning, and
control to enable mobile loco-manipulation and grasping, substantially
expanding its interaction capabilities, workspace, and traversability.

</details>


### [40] [Improving Needle Penetration via Precise Rotational Insertion Using Iterative Learning Control](https://arxiv.org/abs/2511.01256)
*Yasamin Foroutani,Yasamin Mousavi-Motlagh,Aya Barzelay,Tsu-Chin Tsao*

Main category: cs.RO

TL;DR: 提出一种迭代学习控制策略，通过旋转插入工具提高机器人手术中的穿透效率和安全性，相比直线插入在视网膜下注射任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 机器人工具路径的精确控制面临系统不对准、未建模动态和驱动误差等挑战，特别是在旋转插入手术工具时，第四关节的不对准使简单应用针头旋转变得复杂。

Method: 使用4自由度机器人操纵器，首先校准选定手术工具的正向运动学以提高精度，然后基于OCT体积扫描测量误差，通过迭代学习控制逐步调整关节指令。

Result: 在离体猪眼视网膜下注射任务中，优化轨迹相比直线插入在组织穿透和视网膜下注射方面获得更高成功率。

Conclusion: ILC方法有效克服了对准挑战，为其他需要受控插入的高精度机器人任务提供了潜在应用。

Abstract: Achieving precise control of robotic tool paths is often challenged by
inherent system misalignments, unmodeled dynamics, and actuation inaccuracies.
This work introduces an Iterative Learning Control (ILC) strategy to enable
precise rotational insertion of a tool during robotic surgery, improving
penetration efficacy and safety compared to straight insertion tested in
subretinal injection. A 4 degree of freedom (DOF) robot manipulator is used,
where misalignment of the fourth joint complicates the simple application of
needle rotation, motivating an ILC approach that iteratively adjusts joint
commands based on positional feedback. The process begins with calibrating the
forward kinematics for the chosen surgical tool to achieve higher accuracy,
followed by successive ILC iterations guided by Optical Coherence Tomography
(OCT) volume scans to measure the error and refine control inputs. Experimental
results, tested on subretinal injection tasks on ex vivo pig eyes, show that
the optimized trajectory resulted in higher success rates in tissue penetration
and subretinal injection compared to straight insertion, demonstrating the
effectiveness of ILC in overcoming misalignment challenges. This approach
offers potential applications for other high precision robot tasks requiring
controlled insertions as well.

</details>


### [41] [Design and Fabrication of Origami-Inspired Knitted Fabrics for Soft Robotics](https://arxiv.org/abs/2511.01272)
*Sehui Jeong,Magaly C. Aviles,Athena X. Naylor,Cynthia Sung,Allison M. Okamura*

Main category: cs.RO

TL;DR: 提出了一种将折纸结构与针织织物相结合的新方法，通过编程针法和材料图案来制造可穿戴软体机器人，实现了结构可重构性和舒适性的平衡。


<details>
  <summary>Details</summary>
Motivation: 软体机器人使用柔性材料，适合人机交互的可穿戴设备，但实现结构完整性和舒适性仍具挑战。

Method: 将折纸图案转化为针织设计，通过选择性使用热熔纱线在柔性折痕周围创建刚性面板，控制折叠方向并防止意外变形。

Result: 成功复制了复杂的折纸镶嵌图案（Miura-ori、Yoshimura、Kresling），并制造出能够运动的可穿戴针织万花筒循环机器人。

Conclusion: 针织折纸结合了结构可重构性、材料可编程性和制造可扩展性，是下一代可穿戴机器人的有前景平台。

Abstract: Soft robots employing compliant materials and deformable structures offer
great potential for wearable devices that are comfortable and safe for human
interaction. However, achieving both structural integrity and compliance for
comfort remains a significant challenge. In this study, we present a novel
fabrication and design method that combines the advantages of origami
structures with the material programmability and wearability of knitted
fabrics. We introduce a general design method that translates origami patterns
into knit designs by programming both stitch and material patterns. The method
creates folds in preferred directions while suppressing unintended buckling and
bending by selectively incorporating heat fusible yarn to create rigid panels
around compliant creases. We experimentally quantify folding moments and show
that stitch patterning enhances folding directionality while the heat fusible
yarn (1) keeps geometry consistent by reducing edge curl and (2) prevents
out-of-plane deformations by stiffening panels. We demonstrate the framework
through the successful reproduction of complex origami tessellations, including
Miura-ori, Yoshimura, and Kresling patterns, and present a wearable knitted
Kaleidocycle robot capable of locomotion. The combination of structural
reconfigurability, material programmability, and potential for manufacturing
scalability highlights knitted origami as a promising platform for
next-generation wearable robotics.

</details>


### [42] [Contact Map Transfer with Conditional Diffusion Model for Generalizable Dexterous Grasp Generation](https://arxiv.org/abs/2511.01276)
*Yiyao Ma,Kai Chen,Kexin Zheng,Qi Dou*

Main category: cs.RO

TL;DR: 提出了一种基于条件扩散模型的灵巧抓取生成框架，通过将高质量抓取从形状模板转移到同类新物体，解决了抓取稳定性和任务适应性的挑战。


<details>
  <summary>Details</summary>
Motivation: 灵巧抓取生成需要平衡抓取稳定性和任务适应性。分析方法稳定但效率低且缺乏任务适应性，生成方法效率高但泛化能力差。需要一种能兼顾稳定性和泛化能力的方法。

Method: 使用条件扩散模型将抓取转移问题重新定义为物体接触图生成，引入双映射机制处理复杂形状变化，构建接触图、部件图和方向图三个物体中心图，采用级联条件扩散模型框架联合转移这三个图，并开发了鲁棒的抓取恢复机制。

Result: 实验证明该方法在抓取质量、生成效率和泛化性能方面表现优越，能够有效平衡这些关键指标。

Conclusion: 提出的基于扩散模型的抓取转移框架成功解决了灵巧抓取生成中的稳定性和泛化问题，为机器人抓取提供了有效的解决方案。

Abstract: Dexterous grasp generation is a fundamental challenge in robotics, requiring
both grasp stability and adaptability across diverse objects and tasks.
Analytical methods ensure stable grasps but are inefficient and lack task
adaptability, while generative approaches improve efficiency and task
integration but generalize poorly to unseen objects and tasks due to data
limitations. In this paper, we propose a transfer-based framework for dexterous
grasp generation, leveraging a conditional diffusion model to transfer
high-quality grasps from shape templates to novel objects within the same
category. Specifically, we reformulate the grasp transfer problem as the
generation of an object contact map, incorporating object shape similarity and
task specifications into the diffusion process. To handle complex shape
variations, we introduce a dual mapping mechanism, capturing intricate
geometric relationship between shape templates and novel objects. Beyond the
contact map, we derive two additional object-centric maps, the part map and
direction map, to encode finer contact details for more stable grasps. We then
develop a cascaded conditional diffusion model framework to jointly transfer
these three maps, ensuring their intra-consistency. Finally, we introduce a
robust grasp recovery mechanism, identifying reliable contact points and
optimizing grasp configurations efficiently. Extensive experiments demonstrate
the superiority of our proposed method. Our approach effectively balances grasp
quality, generation efficiency, and generalization performance across various
tasks. Project homepage: https://cmtdiffusion.github.io/

</details>


### [43] [Kinematify: Open-Vocabulary Synthesis of High-DoF Articulated Objects](https://arxiv.org/abs/2511.01294)
*Jiawei Wang,Dingyou Wang,Jiaming Hu,Qixuan Zhang,Jingyi Yu,Lan Xu*

Main category: cs.RO

TL;DR: Kinematify是一个从RGB图像或文本提示自动合成铰接物体的框架，解决了高自由度物体运动学拓扑推断和静态几何关节参数估计的挑战。


<details>
  <summary>Details</summary>
Motivation: 铰接物体建模对于机器人操作和物理模拟至关重要，但现有方法依赖运动序列或手工数据集，难以扩展到复杂系统。

Method: 结合MCTS搜索进行结构推断和几何驱动的优化进行关节推理，生成物理一致且功能有效的描述。

Result: 在合成和真实环境中的多样化输入上评估，在配准和运动学拓扑准确性方面优于先前工作。

Conclusion: Kinematify能够从静态输入自动生成铰接物体模型，为机器人操作和物理模拟提供了可扩展的解决方案。

Abstract: A deep understanding of kinematic structures and movable components is
essential for enabling robots to manipulate objects and model their own
articulated forms. Such understanding is captured through articulated objects,
which are essential for tasks such as physical simulation, motion planning, and
policy learning. However, creating these models, particularly for complex
systems like robots or objects with high degrees of freedom (DoF), remains a
significant challenge. Existing methods typically rely on motion sequences or
strong assumptions from hand-curated datasets, which hinders scalability. In
this paper, we introduce Kinematify, an automated framework that synthesizes
articulated objects directly from arbitrary RGB images or text prompts. Our
method addresses two core challenges: (i) inferring kinematic topologies for
high-DoF objects and (ii) estimating joint parameters from static geometry. To
achieve this, we combine MCTS search for structural inference with
geometry-driven optimization for joint reasoning, producing physically
consistent and functionally valid descriptions. We evaluate Kinematify on
diverse inputs from both synthetic and real-world environments, demonstrating
improvements in registration and kinematic topology accuracy over prior work.

</details>


### [44] [RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models](https://arxiv.org/abs/2511.01331)
*Hongyin Zhang,Shuo Zhang,Junxi Jin,Qixin Zeng,Runze Li,Donglin Wang*

Main category: cs.RO

TL;DR: RobustVLA是一种轻量级在线强化学习后训练方法，专门设计用于增强视觉-语言-动作(VLA)模型在环境不确定性下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在分布外部署时，对观测噪声、传感器误差和执行扰动等不可避免的干扰缺乏鲁棒性。虽然强化学习后训练可以适应预训练的VLA模型，但现有方法主要关注奖励最大化，忽视了环境不确定性的鲁棒性。

Method: 通过系统性鲁棒性分析，提出了两种关键正则化：雅可比正则化（减轻对观测噪声的敏感性）和平滑性正则化（在动作扰动下稳定策略）。

Result: 在多种机器人环境中的广泛实验表明，RobustVLA在鲁棒性和可靠性方面显著优于现有最先进方法。

Conclusion: 原则性的鲁棒性感知强化学习后训练是提高VLA模型可靠性和鲁棒性的关键步骤。

Abstract: Vision-Language-Action (VLA) models have recently emerged as powerful
general-purpose policies for robotic manipulation, benefiting from large-scale
multi-modal pre-training. However, they often fail to generalize reliably in
out-of-distribution deployments, where unavoidable disturbances such as
observation noise, sensor errors, or actuation perturbations become prevalent.
While recent Reinforcement Learning (RL)-based post-training provides a
practical means to adapt pre-trained VLA models, existing methods mainly
emphasize reward maximization and overlook robustness to environmental
uncertainty. In this work, we introduce RobustVLA, a lightweight online RL
post-training method designed to explicitly enhance the resilience of VLA
models. Through a systematic robustness analysis, we identify two key
regularizations: Jacobian regularization, which mitigates sensitivity to
observation noise, and smoothness regularization, which stabilizes policies
under action perturbations. Extensive experiments across diverse robotic
environments demonstrate that RobustVLA significantly outperforms prior
state-of-the-art methods in robustness and reliability. Our results highlight
the importance of principled robustness-aware RL post-training as a key step
toward improving the reliability and robustness of VLA models.

</details>


### [45] [Embodied Cognition Augmented End2End Autonomous Driving](https://arxiv.org/abs/2511.01334)
*Ling Niu,Xiaoji Zheng,Han Wang,Chen Zheng,Ziyuan Yang,Bokui Chen,Jiangtao Gong*

Main category: cs.RO

TL;DR: 提出E³AD新范式，通过视觉特征提取网络与EEG大模型的对比学习，学习人类驾驶认知来增强端到端规划性能


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法依赖标签监督训练的视觉特征提取网络，这种有限监督框架限制了驾驶模型的通用性和适用性

Method: 收集认知数据集进行对比学习，研究利用人类驾驶认知增强端到端规划的方法和机制，在公开数据集上使用流行驾驶模型作为基线

Result: E³AD范式显著提升了基线模型的端到端规划性能，消融研究验证了驾驶认知的贡献和对比学习过程的有效性

Conclusion: 这是首个将人类驾驶认知整合到端到端自动驾驶规划的工作，为未来脑启发自动驾驶系统提供了有价值的见解

Abstract: In recent years, vision-based end-to-end autonomous driving has emerged as a
new paradigm. However, popular end-to-end approaches typically rely on visual
feature extraction networks trained under label supervision. This limited
supervision framework restricts the generality and applicability of driving
models. In this paper, we propose a novel paradigm termed $E^{3}AD$, which
advocates for comparative learning between visual feature extraction networks
and the general EEG large model, in order to learn latent human driving
cognition for enhancing end-to-end planning. In this work, we collected a
cognitive dataset for the mentioned contrastive learning process. Subsequently,
we investigated the methods and potential mechanisms for enhancing end-to-end
planning with human driving cognition, using popular driving models as
baselines on publicly available autonomous driving datasets. Both open-loop and
closed-loop tests are conducted for a comprehensive evaluation of planning
performance. Experimental results demonstrate that the $E^{3}AD$ paradigm
significantly enhances the end-to-end planning performance of baseline models.
Ablation studies further validate the contribution of driving cognition and the
effectiveness of comparative learning process. To the best of our knowledge,
this is the first work to integrate human driving cognition for improving
end-to-end autonomous driving planning. It represents an initial attempt to
incorporate embodied cognitive data into end-to-end autonomous driving,
providing valuable insights for future brain-inspired autonomous driving
systems. Our code will be made available at Github

</details>


### [46] [Thermo-responsive closing and reopening artificial Venus Flytrap utilizing shape memory elastomers](https://arxiv.org/abs/2511.01346)
*Shun Yoshida,Qingchuan Song,Bastian E. Rapp,Thomas Speck,Falk J. Tauber*

Main category: cs.RO

TL;DR: 本研究开发了一种能够自主闭合和重新打开的仿生捕蝇草软体机器人，使用热响应形状记忆材料，在自然温度范围内实现双向运动。


<details>
  <summary>Details</summary>
Motivation: 虽然捕蝇草的快速闭合运动已启发多种人工系统，但实现自主闭合和重新打开的双向运动仍是挑战。

Method: 采用新型热响应UV固化形状记忆材料，构建双曲面捕蝇草叶片，使用形状记忆聚合物实现38°C闭合，形状记忆弹性体条带在45°C时作为拮抗驱动器促进叶片重新打开。

Result: 成功实现了热响应闭合和重新打开，在自然温度范围内完成程序化顺序运动，这是首个展示双向热响应运动的仿生捕蝇草系统。

Conclusion: 这项研究标志着向自主双向移动软体机器人的重要进展，为植物启发的软体机器人技术开辟了新方向。

Abstract: Despite their often perceived static and slow nature, some plants can move
faster than the blink of an eye. The rapid snap closure motion of the Venus
flytrap (Dionaea muscipula) has long captivated the interest of researchers and
engineers alike, serving as a model for plant-inspired soft machines and
robots. The translation of the fast snapping closure has inspired the
development of various artificial Venus flytrap (AVF) systems. However,
translating both the closing and reopening motion of D. muscipula into an
autonomous plant inspired soft machine has yet to be achieved. In this study,
we present an AVF that autonomously closes and reopens, utilizing novel
thermo-responsive UV-curable shape memory materials for soft robotic systems.
The life-sized thermo-responsive AVF exhibits closing and reopening motions
triggered in a naturally occurring temperature range. The doubly curved trap
lobes, built from shape memory polymers, close at 38{\deg}C, while reopening
initiates around 45{\deg}C, employing shape memory elastomer strips as
antagonistic actuators to facilitate lobe reopening. This work represents the
first demonstration of thermo-responsive closing and reopening in an AVF with
programmed sequential motion in response to increasing temperature. This
approach marks the next step toward autonomously bidirectional moving soft
machines/robots.

</details>


### [47] [Design and development of an electronics-free earthworm robot](https://arxiv.org/abs/2511.01347)
*Riddhi Das,Joscha Teichmann,Thomas Speck,Falk J. Tauber*

Main category: cs.RO

TL;DR: 提出了一种无电子器件的仿蚯蚓气动机器人，使用改进的气动逻辑门设计实现蠕动运动，无需外部电子控制单元


<details>
  <summary>Details</summary>
Motivation: 现有仿蚯蚓机器人主要依赖笨重、高功耗的电子控制单元，限制了实际应用。本研究旨在开发无电子器件的控制系统，降低系统复杂性

Method: 将预配置的气动逻辑门单元与波纹管执行器集成，构建即插即用式模块化系统，实现无外部电子组件的蠕动运动

Result: 改进的气动逻辑门控制系统有效产生蠕动波传播，实现自主运动且偏差最小。波纹管执行器在不同工况下性能得到表征

Conclusion: 该研究为开发无电子器件的蠕动软体机器人提供了概念验证，在危险环境中具有应用潜力，未来将优化设计并探索使用机载压缩空气源的无线操作

Abstract: Soft robotic systems have gained widespread attention due to their inherent
flexibility, adaptability, and safety, making them well-suited for varied
applications. Among bioinspired designs, earthworm locomotion has been
extensively studied for its efficient peristaltic motion, enabling movement in
confined and unstructured environments. Existing earthworm-inspired robots
primarily utilize pneumatic actuation due to its high force-to-weight ratio and
ease of implementation. However, these systems often rely on bulky,
power-intensive electronic control units, limiting their practicality. In this
work, we present an electronics-free, earthworm-inspired pneumatic robot
utilizing a modified Pneumatic Logic Gate (PLG) design. By integrating
preconfigured PLG units with bellow actuators, we achieved a plug-and-play
style modular system capable of peristaltic locomotion without external
electronic components. The proposed design reduces system complexity while
maintaining efficient actuation. We characterize the bellow actuators under
different operating conditions and evaluate the robots locomotion performance.
Our findings demonstrate that the modified PLG-based control system effectively
generates peristaltic wave propagation, achieving autonomous motion with
minimal deviation. This study serves as a proof of concept for the development
of electronics-free, peristaltic soft robots. The proposed system has potential
for applications in hazardous environments, where untethered, adaptable
locomotion is critical. Future work will focus on further optimizing the robot
design and exploring untethered operation using onboard compressed air sources.

</details>


### [48] [Model to Model: Understanding the Venus Flytrap Snapping Mechanism and Transferring it to a 3D-printed Bistable Soft Robotic Demonstrator](https://arxiv.org/abs/2511.01350)
*Maartje H. M. Wermelink,Renate Sachse,Sebastian Kruppert,Thomas Speck,Falk J. Tauber*

Main category: cs.RO

TL;DR: 该研究分析了捕蝇草的快速闭合机制，并将其双稳态特性应用于人工执行器的设计，开发了两种3D打印的双稳态执行器模型。


<details>
  <summary>Details</summary>
Motivation: 深入了解捕蝇草的运动力学机制，并将其原理应用于人工双稳态叶片执行器的设计，开发能够模拟生物模型机械行为的软快速抓取器。

Method: 识别捕蝇草叶片的几何特征（如尺寸比例和厚度梯度），并将其转化为两种3D打印的双稳态执行器模型：一种模拟捕蝇草叶片几何形状，另一种使用CAD设计的叶片模型。

Result: 两种模型都表现出凹-凸双稳态特性并能够快速闭合，这是开发人工捕蝇草的第一步。

Conclusion: 成功将捕蝇草的双稳态机制应用于人工执行器设计，为开发模拟生物机械行为的软快速抓取器奠定了基础。

Abstract: The Venus flytrap (Dionaea muscipula) does not only serve as the textbook
model for a carnivorous plant, but also has long intrigued both botanists and
engineers with its rapidly closing leaf trap. The trap closure is triggered by
two consecutive touches of a potential prey, after which the lobes rapidly
switch from their concave open-state to their convex close-state and catch the
prey within 100-500 ms after being triggered. This transformation from concave
to convex is initiated by changes in turgor pressure and the release of stored
elastic energy from prestresses in the concave state, which accelerate this
movement, leading to inversion of the lobes bi-axial curvature. Possessing two
low-energy states, the leaves can be characterized as bistable systems. With
our research, we seek to deepen the understanding of Venus flytrap motion
mechanics and apply its principles to the design of an artificial bistable lobe
actuator. We identified geometrical characteristics, such as dimensional ratios
and the thickness gradient in the lobe, and transferred these to two 3D-printed
bistable actuator models. One actuator parallels the simulated geometry of a
Venus flytrap leaf, the other is a lobe model designed with CAD. Both models
display concave-convex bi-stability and snap close. These demonstrators are the
first step in the development of an artificial Venus flytrap that mimics the
mechanical behavior of the biological model and can be used as a soft fast
gripper.

</details>


### [49] [Lateral Velocity Model for Vehicle Parking Applications](https://arxiv.org/abs/2511.01369)
*Luis Diener,Jens Kalkkuhl,Markus Enzweiler*

Main category: cs.RO

TL;DR: 提出了一种改进的侧向速度模型，用于在自动泊车场景中更准确地估计车辆侧向速度，解决了传统零滑移模型在低速行驶时不准确的问题。


<details>
  <summary>Details</summary>
Motivation: 自动泊车需要精确的定位，但消费级车辆缺乏专用传感器来测量侧向速度。现有方法依赖零滑移假设，这在低速行驶时不成立，导致估计不准确。

Method: 分析真实泊车场景数据，识别零滑移假设的系统性偏差，提出一个仅需两个参数的侧向速度模型来更好地捕捉泊车过程中的车辆侧向动力学。

Result: 新模型提高了侧向速度估计的准确性，同时仅依赖两个参数，适合集成到消费级应用中。

Conclusion: 提出的侧向速度模型在泊车场景中比传统零滑移模型更准确，为消费级车辆的自动泊车系统提供了实用的解决方案。

Abstract: Automated parking requires accurate localization for quick and precise
maneuvering in tight spaces. While the longitudinal velocity can be measured
using wheel encoders, the estimation of the lateral velocity remains a key
challenge due to the absence of dedicated sensors in consumer-grade vehicles.
Existing approaches often rely on simplified vehicle models, such as the
zero-slip model, which assumes no lateral velocity at the rear axle. It is well
established that this assumption does not hold during low-speed driving and
researchers thus introduce additional heuristics to account for differences. In
this work, we analyze real-world data from parking scenarios and identify a
systematic deviation from the zero-slip assumption. We provide explanations for
the observed effects and then propose a lateral velocity model that better
captures the lateral dynamics of the vehicle during parking. The model improves
estimation accuracy, while relying on only two parameters, making it
well-suited for integration into consumer-grade applications.

</details>


### [50] [CM-LIUW-Odometry: Robust and High-Precision LiDAR-Inertial-UWB-Wheel Odometry for Extreme Degradation Coal Mine Tunnels](https://arxiv.org/abs/2511.01379)
*Kun Hu,Menggang Li,Zhiwen Jin,Chaoquan Tang,Eryi Hu,Gongbo Zhou*

Main category: cs.RO

TL;DR: 提出CM-LIUW-Odometry多模态SLAM框架，融合LiDAR、IMU、UWB和轮式里程计，解决地下煤矿GPS缺失环境中的定位与建图挑战。


<details>
  <summary>Details</summary>
Motivation: 地下煤矿环境GPS不可用、地形不平导致轮式里程计精度下降、长隧道特征稀少降低LiDAR效果，需要鲁棒的多传感器融合方案。

Method: 基于IESKF，紧密融合LiDAR-IMU里程计与UWB绝对定位约束，集成轮式里程计并加入非完整约束和车辆杠杆臂补偿，采用自适应运动模式切换机制。

Result: 在真实地下煤矿场景中验证了方法的优越精度和鲁棒性，超越了现有先进方法。

Conclusion: 提出的多模态SLAM框架在地下煤矿等恶劣环境中表现出色，代码已开源供机器人社区使用。

Abstract: Simultaneous Localization and Mapping (SLAM) in large-scale, complex, and
GPS-denied underground coal mine environments presents significant challenges.
Sensors must contend with abnormal operating conditions: GPS unavailability
impedes scene reconstruction and absolute geographic referencing, uneven or
slippery terrain degrades wheel odometer accuracy, and long, feature-poor
tunnels reduce LiDAR effectiveness. To address these issues, we propose
CoalMine-LiDAR-IMU-UWB-Wheel-Odometry (CM-LIUW-Odometry), a multimodal SLAM
framework based on the Iterated Error-State Kalman Filter (IESKF). First,
LiDAR-inertial odometry is tightly fused with UWB absolute positioning
constraints to align the SLAM system with a global coordinate. Next, wheel
odometer is integrated through tight coupling, enhanced by nonholonomic
constraints (NHC) and vehicle lever arm compensation, to address performance
degradation in areas beyond UWB measurement range. Finally, an adaptive motion
mode switching mechanism dynamically adjusts the robot's motion mode based on
UWB measurement range and environmental degradation levels. Experimental
results validate that our method achieves superior accuracy and robustness in
real-world underground coal mine scenarios, outperforming state-of-the-art
approaches. We open source our code of this work on Github to benefit the
robotics community.

</details>


### [51] [CaRLi-V: Camera-RADAR-LiDAR Point-Wise 3D Velocity Estimation](https://arxiv.org/abs/2511.01383)
*Landson Guo,Andres M. Diaz Aguilar,William Talbot,Turcan Tuna,Marco Hutter,Cesar Cadena*

Main category: cs.RO

TL;DR: 提出名为CaRLi-V的新型多传感器融合方法，通过结合RADAR、LiDAR和相机数据，实现密集点云的3D速度估计，特别适用于机器人与非刚性动态物体（如人类）的交互。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，准确的3D点级速度估计对于机器人的路径规划、碰撞避免和物体操作至关重要，特别是在与非刚性动态代理（如人类）交互时。

Method: 使用原始RADAR测量创建速度立方体表示径向速度，结合光流估计切向速度，通过LiDAR获取点级距离测量，采用闭式解融合这些信息生成密集3D速度估计。

Result: 在自定义数据集上测试显示，相对于真实值具有较低的速度误差指标，能够为机器人应用提供点级速度估计。

Conclusion: CaRLi-V作为开源ROS2包，通过多传感器融合有效解决了3D点级速度估计问题，在动态环境中表现出良好的性能。

Abstract: Accurate point-wise velocity estimation in 3D is crucial for robot
interaction with non-rigid, dynamic agents, such as humans, enabling robust
performance in path planning, collision avoidance, and object manipulation in
dynamic environments. To this end, this paper proposes a novel RADAR, LiDAR,
and camera fusion pipeline for point-wise 3D velocity estimation named CaRLi-V.
This pipeline leverages raw RADAR measurements to create a novel RADAR
representation, the velocity cube, which densely represents radial velocities
within the RADAR's field-of-view. By combining the velocity cube for radial
velocity extraction, optical flow for tangential velocity estimation, and LiDAR
for point-wise range measurements through a closed-form solution, our approach
can produce 3D velocity estimates for a dense array of points. Developed as an
open-source ROS2 package, CaRLi-V has been field-tested against a custom
dataset and proven to produce low velocity error metrics relative to ground
truth, enabling point-wise velocity estimation for robotic applications.

</details>


### [52] [FoldPath: End-to-End Object-Centric Motion Generation via Modulated Implicit Paths](https://arxiv.org/abs/2511.01407)
*Paolo Rabino,Gabriele Tiboni,Tatiana Tommasi*

Main category: cs.RO

TL;DR: FoldPath是一种新颖的端到端神经场方法，用于物体中心运动生成(OCMG)。它通过将机器人运动学习为连续函数来生成平滑路径，无需后处理步骤，在有限样本下表现出优越的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前OCMG技术要么基于临时启发式方法，要么依赖学习型管道但仍需敏感的后处理步骤来生成可执行路径。需要更稳健的算法来为复杂3D几何体生成扩展的、物体感知的轨迹。

Method: FoldPath采用神经场方法，将机器人运动学习为连续函数，而不是预测离散的末端执行器路径点。这种范式转变消除了连接和排序预测离散路径点的脆弱后处理步骤。

Result: 该方法在预测性能上优于最近提出的学习型方法，在真实工业环境中仅使用70个专家样本就展现出泛化能力。通过在真实模拟环境中的全面实验验证了其有效性。

Conclusion: FoldPath通过引入新的严格指标来全面评估长时域机器人路径，将OCMG任务推向实际成熟应用，为自动化制造过程提供了有效的解决方案。

Abstract: Object-Centric Motion Generation (OCMG) is instrumental in advancing
automated manufacturing processes, particularly in domains requiring
high-precision expert robotic motions, such as spray painting and welding. To
realize effective automation, robust algorithms are essential for generating
extended, object-aware trajectories across intricate 3D geometries. However,
contemporary OCMG techniques are either based on ad-hoc heuristics or employ
learning-based pipelines that are still reliant on sensitive post-processing
steps to generate executable paths. We introduce FoldPath, a novel, end-to-end,
neural field based method for OCMG. Unlike prior deep learning approaches that
predict discrete sequences of end-effector waypoints, FoldPath learns the robot
motion as a continuous function, thus implicitly encoding smooth output paths.
This paradigm shift eliminates the need for brittle post-processing steps that
concatenate and order the predicted discrete waypoints. Particularly, our
approach demonstrates superior predictive performance compared to recently
proposed learning-based methods, and attains generalization capabilities even
in real industrial settings, where only a limited amount of 70 expert samples
are provided. We validate FoldPath through comprehensive experiments in a
realistic simulation environment and introduce new, rigorous metrics designed
to comprehensively evaluate long-horizon robotic paths, thus advancing the OCMG
task towards practical maturity.

</details>


### [53] [Designing for Distributed Heterogeneous Modularity: On Software Architecture and Deployment of MoonBots](https://arxiv.org/abs/2511.01437)
*Elian Neppel,Shamistan Karimov,Ashutosh Mishra,Gustavo Hernan Diaz Huenupan,Hazal Gozbasi,Kentaro Uno,Shreya Santra,Kazuya Yoshida*

Main category: cs.RO

TL;DR: MoonBot平台是一个模块化空间机器人系统，采用分布式异构架构，通过ROS2和Zenoh实现数据导向通信，支持动态重构和去中心化控制，已在自组装机器人和远程操作中验证。


<details>
  <summary>Details</summary>
Motivation: 解决模块化机器人系统在集成和维护方面的重大挑战，为跨时间、硬件、团队和操作环境的机器人系统设计提供可推广的模式。

Method: 采用组件化设计、基于ROS2和Zenoh的数据导向通信模型，以及能够管理复杂多模块组件的部署编排器，实现分布式异构模块化。

Result: 经过数月的现场部署验证，系统显著降低了集成和维护开销，同时保持可扩展性和鲁棒性，成功应用于自组装机器人、机器人间协作和远程操作。

Conclusion: 该架构不仅针对太空应用，还为必须跨越时间、硬件、团队和操作环境扩展的机器人系统提供了通用设计模式。

Abstract: This paper presents the software architecture and deployment strategy behind
the MoonBot platform: a modular space robotic system composed of heterogeneous
components distributed across multiple computers, networks and ultimately
celestial bodies. We introduce a principled approach to distributed,
heterogeneous modularity, extending modular robotics beyond physical
reconfiguration to software, communication and orchestration. We detail the
architecture of our system that integrates component-based design, a
data-oriented communication model using ROS2 and Zenoh, and a deployment
orchestrator capable of managing complex multi-module assemblies. These
abstractions enable dynamic reconfiguration, decentralized control, and
seamless collaboration between numerous operators and modules. At the heart of
this system lies our open-source Motion Stack software, validated by months of
field deployment with self-assembling robots, inter-robot cooperation, and
remote operation. Our architecture tackles the significant hurdles of modular
robotics by significantly reducing integration and maintenance overhead, while
remaining scalable and robust. Although tested with space in mind, we propose
generalizable patterns for designing robotic systems that must scale across
time, hardware, teams and operational environments.

</details>


### [54] [AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models](https://arxiv.org/abs/2511.01472)
*Sarthak Mishra,Rishabh Dev Yadav,Avirup Das,Saksham Gupta,Wei Pan,Spandan Roy*

Main category: cs.RO

TL;DR: AERMANI-VLM框架通过将高层推理与底层控制分离，将预训练视觉语言模型安全地应用于空中机械臂操作，无需任务特定微调。


<details>
  <summary>Details</summary>
Motivation: 直接部署视觉语言模型驱动的策略到空中机械臂上不安全且不可靠，因为生成的动作往往不一致、容易产生幻觉，且对飞行来说动态不可行。

Method: 使用结构化提示编码自然语言指令、任务上下文和安全约束，引导模型生成逐步推理轨迹，然后从预定义的安全技能库中选择离散动作。

Result: 在仿真和硬件上的多样化多步骤拾放任务中验证了框架，展示了对未见命令、物体和环境的强大泛化能力。

Conclusion: 通过解耦符号推理和物理动作，AERMANI-VLM减轻了幻觉命令并防止不安全行为，实现了稳健的任务完成。

Abstract: The rapid progress of vision--language models (VLMs) has sparked growing
interest in robotic control, where natural language can express the operation
goals while visual feedback links perception to action. However, directly
deploying VLM-driven policies on aerial manipulators remains unsafe and
unreliable since the generated actions are often inconsistent,
hallucination-prone, and dynamically infeasible for flight. In this work, we
present AERMANI-VLM, the first framework to adapt pretrained VLMs for aerial
manipulation by separating high-level reasoning from low-level control, without
any task-specific fine-tuning. Our framework encodes natural language
instructions, task context, and safety constraints into a structured prompt
that guides the model to generate a step-by-step reasoning trace in natural
language. This reasoning output is used to select from a predefined library of
discrete, flight-safe skills, ensuring interpretable and temporally consistent
execution. By decoupling symbolic reasoning from physical action, AERMANI-VLM
mitigates hallucinated commands and prevents unsafe behavior, enabling robust
task completion. We validate the framework in both simulation and hardware on
diverse multi-step pick-and-place tasks, demonstrating strong generalization to
previously unseen commands, objects, and environments.

</details>


### [55] [MO-SeGMan: Rearrangement Planning Framework for Multi Objective Sequential and Guided Manipulation in Constrained Environments](https://arxiv.org/abs/2511.01476)
*Cankut Bora Tuncer,Marc Toussaint,Ozgur S. Oguz*

Main category: cs.RO

TL;DR: MO-SeGMan是一个多目标顺序引导操作规划器，用于解决高度受限的重排问题。它通过最小化重规划次数和机器人移动距离，同时保持关键依赖结构，在复杂场景中高效生成可行的运动规划。


<details>
  <summary>Details</summary>
Motivation: 解决高度受限、非单调的重排规划问题，这些场景通常存在大量障碍物和复杂的依赖关系，传统方法难以高效处理。

Method: 采用选择性引导前向搜索(SGFS)来重新定位关键障碍物，使用惰性评估方法保持依赖结构，并通过自适应子目标选择的精化方法减少不必要的拾放动作。

Result: 在9个基准重排任务上的评估表明，MO-SeGMan在所有情况下都能生成可行的运动规划，相比基线方法获得更快的求解时间和更优的解决方案质量。

Conclusion: MO-SeGMan框架在复杂重排规划问题中展现出强大的鲁棒性和可扩展性，为高度受限场景提供了有效的解决方案。

Abstract: In this work, we introduce MO-SeGMan, a Multi-Objective Sequential and Guided
Manipulation planner for highly constrained rearrangement problems. MO-SeGMan
generates object placement sequences that minimize both replanning per object
and robot travel distance while preserving critical dependency structures with
a lazy evaluation method. To address highly cluttered, non-monotone scenarios,
we propose a Selective Guided Forward Search (SGFS) that efficiently relocates
only critical obstacles and to feasible relocation points. Furthermore, we
adopt a refinement method for adaptive subgoal selection to eliminate
unnecessary pick-and-place actions, thereby improving overall solution quality.
Extensive evaluations on nine benchmark rearrangement tasks demonstrate that
MO-SeGMan generates feasible motion plans in all cases, consistently achieving
faster solution times and superior solution quality compared to the baselines.
These results highlight the robustness and scalability of the proposed
framework for complex rearrangement planning problems.

</details>


### [56] [Floor Plan-Guided Visual Navigation Incorporating Depth and Directional Cues](https://arxiv.org/abs/2511.01493)
*Wei Huang,Jiaxin Li,Zang Wan,Huijun Di,Wei Liang,Zhu Yang*

Main category: cs.RO

TL;DR: 提出GlocDiff，一种基于扩散模型的导航策略，结合楼层平面图的全局路径规划和RGB观测的局部深度特征，解决室内导航中视觉与空间信息融合的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决室内导航中的两个关键挑战：RGB观测与楼层平面图之间的模态差距阻碍视觉和空间信息融合；在未见环境中由于缺乏显式几何对齐而难以实现精确定位。

Method: 使用扩散模型整合全局路径规划（来自楼层平面图）和局部深度感知特征（来自RGB观测），在训练中引入噪声扰动增强对姿态估计误差的鲁棒性，推理时结合相对稳定的VO模块。

Result: 在FloNa基准测试中表现出优异的导航性能，真实世界部署验证了其实际应用潜力。

Conclusion: GlocDiff通过融合全局引导和局部几何线索，实现了精确的导航方向预测和鲁棒的障碍物规避，具有广泛的实际应用前景。

Abstract: Guiding an agent to a specific target in indoor environments based solely on
RGB inputs and a floor plan is a promising yet challenging problem. Although
existing methods have made significant progress, two challenges remain
unresolved. First, the modality gap between egocentric RGB observations and the
floor plan hinders the integration of visual and spatial information for both
local obstacle avoidance and global planning. Second, accurate localization is
critical for navigation performance, but remains challenging at deployment in
unseen environments due to the lack of explicit geometric alignment between RGB
inputs and floor plans. We propose a novel diffusion-based policy, denoted as
GlocDiff, which integrates global path planning from the floor plan with local
depth-aware features derived from RGB observations. The floor plan offers
explicit global guidance, while the depth features provide implicit geometric
cues, collectively enabling precise prediction of optimal navigation directions
and robust obstacle avoidance. Moreover, GlocDiff introduces noise perturbation
during training to enhance robustness against pose estimation errors, and we
find that combining this with a relatively stable VO module during inference
results in significantly improved navigation performance. Extensive experiments
on the FloNa benchmark demonstrate GlocDiff's efficiency and effectiveness in
achieving superior navigation performance, and the success of real-world
deployments also highlights its potential for widespread practical
applications.

</details>


### [57] [Phy-Tac: Toward Human-Like Grasping via Physics-Conditioned Tactile Goals](https://arxiv.org/abs/2511.01520)
*Shipeng Lyu,Lijie Sheng,Fangyuan Wang,Wenyao Zhang,Weiwei Lin,Zhenzhong Jia,David Navarro-Alarcon,Guodong Guo*

Main category: cs.RO

TL;DR: 提出Phy-Tac方法，通过物理条件触觉技术实现力最优稳定抓取，结合姿态选择、触觉预测和力调节，使机器人能像人类一样用最小力稳定抓取物体。


<details>
  <summary>Details</summary>
Motivation: 人类能自然使用最小必要力稳定抓取物体，而机器人通常依赖刚性、过度挤压的控制方式，需要缩小这种差距。

Method: 1) 基于物理的姿态选择器识别最优力分布的可行接触区域；2) 物理条件潜在扩散模型预测目标触觉印记；3) 潜在空间LQR控制器驱动夹爪以最小驱动力达到目标触觉印记。

Result: 在多样化物体和接触条件下训练的Phy-LDM实现了优越的触觉预测精度，Phy-Tac在抓取稳定性和力效率方面优于固定力和GraspNet基线方法。

Conclusion: 实验证明该方法实现了力高效和自适应操作，缩小了机器人与人类抓取之间的差距。

Abstract: Humans naturally grasp objects with minimal level required force for
stability, whereas robots often rely on rigid, over-squeezing control. To
narrow this gap, we propose a human-inspired physics-conditioned tactile method
(Phy-Tac) for force-optimal stable grasping (FOSG) that unifies pose selection,
tactile prediction, and force regulation. A physics-based pose selector first
identifies feasible contact regions with optimal force distribution based on
surface geometry. Then, a physics-conditioned latent diffusion model (Phy-LDM)
predicts the tactile imprint under FOSG target. Last, a latent-space LQR
controller drives the gripper toward this tactile imprint with minimal
actuation, preventing unnecessary compression. Trained on a physics-conditioned
tactile dataset covering diverse objects and contact conditions, the proposed
Phy-LDM achieves superior tactile prediction accuracy, while the Phy-Tac
outperforms fixed-force and GraspNet-based baselines in grasp stability and
force efficiency. Experiments on classical robotic platforms demonstrate
force-efficient and adaptive manipulation that bridges the gap between robotic
and human grasping.

</details>


### [58] [MARS: Multi-Agent Robotic System with Multimodal Large Language Models for Assistive Intelligence](https://arxiv.org/abs/2511.01594)
*Renjun Gao,Peiyan Zhong*

Main category: cs.RO

TL;DR: MARS是一个基于多模态大语言模型的多智能体机器人系统，专为智能家居机器人设计，为残障人士提供风险感知、个性化的辅助服务。


<details>
  <summary>Details</summary>
Motivation: 现有系统在风险感知规划、用户个性化以及将语言计划转化为可执行技能方面存在困难，特别是在杂乱的家庭环境中。

Method: 系统集成四个智能体：视觉感知智能体提取环境语义和空间特征，风险评估智能体识别和优先处理危险，规划智能体生成可执行动作序列，评估智能体进行迭代优化。

Result: 在多个数据集上的实验表明，该系统在风险感知规划和协调多智能体执行方面优于最先进的多模态模型。

Conclusion: 该方法展示了协作AI在实际辅助场景中的潜力，并为在真实环境中部署基于MLLM的多智能体系统提供了可推广的方法论。

Abstract: Multimodal large language models (MLLMs) have shown remarkable capabilities
in cross-modal understanding and reasoning, offering new opportunities for
intelligent assistive systems, yet existing systems still struggle with
risk-aware planning, user personalization, and grounding language plans into
executable skills in cluttered homes. We introduce MARS - a Multi-Agent Robotic
System powered by MLLMs for assistive intelligence and designed for smart home
robots supporting people with disabilities. The system integrates four agents:
a visual perception agent for extracting semantic and spatial features from
environment images, a risk assessment agent for identifying and prioritizing
hazards, a planning agent for generating executable action sequences, and an
evaluation agent for iterative optimization. By combining multimodal perception
with hierarchical multi-agent decision-making, the framework enables adaptive,
risk-aware, and personalized assistance in dynamic indoor environments.
Experiments on multiple datasets demonstrate the superior overall performance
of the proposed system in risk-aware planning and coordinated multi-agent
execution compared with state-of-the-art multimodal models. The proposed
approach also highlights the potential of collaborative AI for practical
assistive scenarios and provides a generalizable methodology for deploying
MLLM-enabled multi-agent systems in real-world environments.

</details>


### [59] [Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete Denoising Diffusion Process](https://arxiv.org/abs/2511.01718)
*Jiayi Chen,Wenxuan Song,Pengxiang Ding,Ziyang Zhou,Han Zhao,Feilong Tang,Donglin Wang,Haoang Li*

Main category: cs.RO

TL;DR: 提出了统一的扩散视觉语言动作模型，通过联合去噪过程同步优化图像生成和动作预测，实现理解、生成和行动的内在协同。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言动作模型要么依赖外部专家进行模态统一，要么将图像生成和动作预测作为独立过程处理，限制了这些任务之间的直接协同效益。

Method: 提出统一扩散VLA和联合离散去噪扩散过程，通过单一去噪轨迹整合多模态，使用统一标记空间和混合注意力机制，采用两阶段训练流程和推理时优化技术。

Result: 在CALVIN、LIBERO和SimplerEnv基准测试中达到最先进性能，推理速度比自回归方法快4倍，并通过深入分析和真实世界评估验证有效性。

Conclusion: 通过联合去噪过程同步优化生成和动作，实现了理解、生成和行动的内在协同，为视觉语言动作模型提供了更高效的统一框架。

Abstract: Vision-language-action (VLA) models aim to understand natural language
instructions and visual observations and to execute corresponding actions as an
embodied agent. Recent work integrates future images into the
understanding-acting loop, yielding unified VLAs that jointly understand,
generate, and act -- reading text and images and producing future images and
actions. However, these models either rely on external experts for modality
unification or treat image generation and action prediction as separate
processes, limiting the benefits of direct synergy between these tasks. Our
core philosophy is to optimize generation and action jointly through a
synchronous denoising process, where the iterative refinement enables actions
to evolve from initialization, under constant and sufficient visual guidance.
We ground this philosophy in our proposed Unified Diffusion VLA and Joint
Discrete Denoising Diffusion Process (JD3P), which is a joint diffusion process
that integrates multiple modalities into a single denoising trajectory to serve
as the key mechanism enabling understanding, generation, and acting to be
intrinsically synergistic. Our model and theory are built on a unified
tokenized space of all modalities and a hybrid attention mechanism. We further
propose a two-stage training pipeline and several inference-time techniques
that optimize performance and efficiency. Our approach achieves
state-of-the-art performance on benchmarks such as CALVIN, LIBERO, and
SimplerEnv with 4$\times$ faster inference than autoregressive methods, and we
demonstrate its effectiveness through in-depth analysis and real-world
evaluations. Our project page is available at
https://irpn-eai.github.io/UD-VLA.github.io/.

</details>


### [60] [Lightweight Learning from Actuation-Space Demonstrations via Flow Matching for Whole-Body Soft Robotic Grasping](https://arxiv.org/abs/2511.01770)
*Liudi Yang,Yang Bai,Yuhao Wang,Ibrahim Alsarraj,Gitta Kutyniok,Zhanchi Wang,Ke Wu*

Main category: cs.RO

TL;DR: 提出了一种基于流匹配模型的轻量级驱动空间学习框架，用于软体机器人抓取，仅需少量演示即可实现高成功率抓取，并具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统刚性机器人手在不确定和接触丰富的抓取任务中依赖复杂的模型和反馈控制，而软体机器人具有机械智能特性，能够自然适应不确定接触。

Method: 使用流匹配模型从确定性演示中学习分布控制表示，无需密集传感或复杂控制回路，仅需30个演示样本。

Result: 学习策略在整个工作空间内达到97.5%的抓取成功率，对抓取物体尺寸变化±33%具有泛化能力，且在20%-200%执行时间范围内保持稳定性能。

Conclusion: 驱动空间学习通过利用软体机器人的被动冗余自由度和灵活性，将机械特性转化为功能控制智能，显著减轻了中央控制器的负担。

Abstract: Robotic grasping under uncertainty remains a fundamental challenge due to its
uncertain and contact-rich nature. Traditional rigid robotic hands, with
limited degrees of freedom and compliance, rely on complex model-based and
heavy feedback controllers to manage such interactions. Soft robots, by
contrast, exhibit embodied mechanical intelligence: their underactuated
structures and passive flexibility of their whole body, naturally accommodate
uncertain contacts and enable adaptive behaviors. To harness this capability,
we propose a lightweight actuation-space learning framework that infers
distributional control representations for whole-body soft robotic grasping,
directly from deterministic demonstrations using a flow matching model
(Rectified Flow),without requiring dense sensing or heavy control loops. Using
only 30 demonstrations (less than 8% of the reachable workspace), the learned
policy achieves a 97.5% grasp success rate across the whole workspace,
generalizes to grasped-object size variations of +-33%, and maintains stable
performance when the robot's dynamic response is directly adjusted by scaling
the execution time from 20% to 200%. These results demonstrate that
actuation-space learning, by leveraging its passive redundant DOFs and
flexibility, converts the body's mechanics into functional control intelligence
and substantially reduces the burden on central controllers for this
uncertain-rich task.

</details>


### [61] [GenDexHand: Generative Simulation for Dexterous Hands](https://arxiv.org/abs/2511.01791)
*Feng Chen,Zhuxiu Xu,Tianzhe Chu,Xunzhe Zhou,Li Sun,Zewen Wu,Shenghua Gao,Zhongyu Li,Yanchao Yang,Yi Ma*

Main category: cs.RO

TL;DR: GenDexHand是一个生成式仿真流水线，能够自主生成多样化的灵巧手操作任务和环境，通过视觉语言模型反馈的闭环优化过程提高环境质量，并通过任务分解实现序列强化学习。


<details>
  <summary>Details</summary>
Motivation: 解决灵巧操作中数据稀缺的根本瓶颈问题，现有方法在灵巧操作中迁移效果差，需要更专业的环境设计，且灵巧操作任务因其更高的自由度而更加困难。

Method: 引入闭环优化过程，基于视觉语言模型反馈调整物体位置和尺寸；将任务分解为子任务以实现序列强化学习；提供生成式仿真流水线。

Result: 显著提高了生成环境的平均质量；减少了训练时间并提高了成功率。

Conclusion: 为具身智能中多样化灵巧手行为的可扩展训练提供了可行路径，通过基于仿真的合成数据生成解决方案。

Abstract: Data scarcity remains a fundamental bottleneck for embodied intelligence.
Existing approaches use large language models (LLMs) to automate gripper-based
simulation generation, but they transfer poorly to dexterous manipulation,
which demands more specialized environment design. Meanwhile, dexterous
manipulation tasks are inherently more difficult due to their higher degrees of
freedom. Massively generating feasible and trainable dexterous hand tasks
remains an open challenge. To this end, we present GenDexHand, a generative
simulation pipeline that autonomously produces diverse robotic tasks and
environments for dexterous manipulation. GenDexHand introduces a closed-loop
refinement process that adjusts object placements and scales based on
vision-language model (VLM) feedback, substantially improving the average
quality of generated environments. Each task is further decomposed into
sub-tasks to enable sequential reinforcement learning, reducing training time
and increasing success rates. Our work provides a viable path toward scalable
training of diverse dexterous hand behaviors in embodied intelligence by
offering a simulation-based solution to synthetic data generation. Our website:
https://winniechen2002.github.io/GenDexHand/.

</details>


### [62] [Hybrid Neural Network-Based Indoor Localisation System for Mobile Robots Using CSI Data in a Robotics Simulator](https://arxiv.org/abs/2511.01797)
*Javier Ballesteros-Jerez,Jesus Martínez-Gómez,Ismael García-Varea,Luis Orozco-Barbosa,Manuel Castillo-Cara*

Main category: cs.RO

TL;DR: 提出了一种基于混合神经网络(HyNN)的移动机器人定位方法，利用大规模MIMO系统的CSI数据，通过CNN和MLP结合估计2D机器人位置。


<details>
  <summary>Details</summary>
Motivation: 解决复杂环境中移动机器人的精确室内定位和导航问题，利用现有CSI数据集开发通用性强的定位方案。

Method: 使用TINTO工具将CSI读数转换为合成图像，构建CNN与MLP结合的混合神经网络模型，并与机器人仿真器和ROS系统集成。

Result: 实现了移动机器人的精确室内定位，模型在复杂环境中表现出良好的定位性能。

Conclusion: HyNN模型在室内定位方面具有巨大潜力，提出的通用化流程可适应不同场景和数据集。

Abstract: We present a hybrid neural network model for inferring the position of mobile
robots using Channel State Information (CSI) data from a Massive MIMO system.
By leveraging an existing CSI dataset, our approach integrates a Convolutional
Neural Network (CNN) with a Multilayer Perceptron (MLP) to form a Hybrid Neural
Network (HyNN) that estimates 2D robot positions. CSI readings are converted
into synthetic images using the TINTO tool. The localisation solution is
integrated with a robotics simulator, and the Robot Operating System (ROS),
which facilitates its evaluation through heterogeneous test cases, and the
adoption of state estimators like Kalman filters. Our contributions illustrate
the potential of our HyNN model in achieving precise indoor localisation and
navigation for mobile robots in complex environments. The study follows, and
proposes, a generalisable procedure applicable beyond the specific use case
studied, making it adaptable to different scenarios and datasets.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [63] [A parallel monetary system based on the redeemable self-decaying money -- The ultimate hedge and safe haven of private wealth in the rising wave of over issuance of fiat and token money/stablecoin](https://arxiv.org/abs/2511.00365)
*Boliang Lin,Ruixi Lin*

Main category: q-fin.GN

TL;DR: 该研究提出了一种基于可赎回自衰减/贬值货币(RSDM)的平行货币系统，旨在解决法定货币过度发行的问题，并为财富提供终极避风港。


<details>
  <summary>Details</summary>
Motivation: 由于布雷顿森林体系崩溃后，国际社会普遍存在发行廉价货币的趋势，稳定币的合法化和过度发行加剧了这一趋势。研究旨在寻找能够提供长期价值存储和零物流成本的现代"良币"。

Method: 提出RSDM概念，指出只有当面值自衰减并能补偿实物黄金存储成本时才能实现可兑换性。构建了多货币池中货币优化选择的整数规划模型，并讨论了RSDM在印度和美国等地的潜在应用场景。

Result: 研究发现单一货币难以承担现代"良币"的责任，只有包含RSDM的平行货币系统（如RSDM、国内法定货币和主要国际储备货币组成的三重货币系统）才能形成财富的终极避风港并保障逆向格雷欣法则。

Conclusion: RSDM以贵金属作为抵押的需求分析为建立健全的基于RSDM的平行货币系统提供了理论支持，这种系统能够有效应对法定货币过度发行的问题。

Abstract: A currency with stable purchasing power can always provide a psychological
haven for people around the world. However, since the collapse of the Bretton
Woods system, issuing more cheap currencies has become a common trend in the
international community, and the legalization and over issuance of stablecoins
will strengthen this trend. In this context, our study focused on a parallel
monetary system based on a redeemable self-decay/devalued money(RSDM). Firstly,
we point out the idea of redeeming gold at a fixed denomination with gold
certificates is similar to an impossible perpetual motion machine. Only when
the face value of a gold token self-decays or self-depreciates and the weight
of the reduced value can compensate for the storage cost of physical gold, can
it be convertible or redeemable. Secondly, we pointed out that as a modern
"good money" under the Internet environment, it must have two basic functions:
long-term value storage and zero logistics cost of money circulation. Thirdly,
we found that a single type of money is difficult to shoulder the
responsibility of modern "good money". Only a parallel monetary system,
including RSDM, such as a triple-monetary system consisting of RSDM, domestic
fiat and major international reserve currencies, can form the ultimate safe
haven of wealth and safeguard the reverse Gresham law. Based on this analysis,
we build an integer programming model for currency optimization selection in a
multi-monetary pool. Fourthly, several potential application scenarios of RSDM
in the real world were discussed, including a new approach to activate dormant
gold assets in India based on RSDM, and the gold monetization scheme in the
United States. Finally, the demand for RSDM with precious metals as collateral
was analyzed, providing theoretical support for establishing a sound parallel
monetary system based on RSDM.

</details>


### [64] [How Digital Asset Treasury Companies Can Survive Bear Markets: The Case of the Strategy and Bitcoin](https://arxiv.org/abs/2511.01135)
*Hongzhe Wen*

Main category: q-fin.GN

TL;DR: 该论文为持有大量加密资产储备的上市公司开发了一个生存框架，通过保守的财政政策和独立于市价变动的运营线路来应对熊市风险。


<details>
  <summary>Details</summary>
Motivation: 数字资产财政公司面临熊市时净资产溢价倍数压缩的严重下行风险，需要建立能够承受长期熊市而不被迫清算的运营模式。

Method: 提出"BTC-to-sats"支付通道，将部分财政资金分配到闪电网络通道中，产生与价格无关的费用收入，同时保持结算风险与BTC接近零相关性。

Result: 建立了无强制出售条件，并显示运营现金流能够支撑18-24个月熊市而不需要清算资产。该框架适用于各类数字资产财政公司。

Conclusion: 该模型提供了可实施的披露标准，能够帮助数字资产财政公司在市场周期中维持净资产溢价。

Abstract: Digital Asset Treasury (DAT) companies, public firms that hold large crypto
reserves as a core strategy, deliver levered exposure to digital assets but
face acute downside risk when equity premia over net asset value multiples
(mNAV) compress in bear markets. This paper develops a survival framework that
couples conservative treasury policy with an operating line that monetizes
holdings independent of mark-to-market gains. Using Strategy (formerly
MicroStrategy) as a case, we propose a "BTC-to-sats" payments rail that
allocates a small, risk-capped liquidity sleeve of the treasury to Lightning
Network channels, generating price-agnostic fee revenue (acquiring bps,
routing, hedge/FX spread) while keeping settlement exposure near zero beta to
BTC. We formalize a no-forced-sale condition and show how disclosed KPIs allow
investors to test whether operating cash flows can bridge an 18 to 24-month
bear without liquidations. The feasibility of the rail is supported by
Strategy's Lightning initiative and empirical Lightning performance. Our model
generalizes across DAT types and provides implementable disclosures that can
sustain an mNAV premium through cycles.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [65] [PEARL: Power- and Energy-Aware Multicore Intermittent Computing](https://arxiv.org/abs/2511.00316)
*Khakim Akhunov,Eren Yildiz,Kasim Sinan Yildirim*

Main category: cs.ET

TL;DR: PEARL是一种支持多核微控制器在间歇供电环境下高效计算的系统方案，通过三阈值电压跟踪电路和外部快速非易失性内存实现，性能提升30倍，能耗降低32倍。


<details>
  <summary>Details</summary>
Motivation: 低功耗多核平台适合并行处理数据密集型任务，但在间歇供电环境下效率极低，需要解决这一问题。

Method: 利用三阈值电压跟踪电路和外部快速非易失性内存，通过软件运行时管理这些组件，实现能量和功率感知的多核配置自适应调整。

Result: PEARL相比现有最优解决方案性能提升高达30倍，能耗降低高达32倍。

Conclusion: PEARL使现有多核微控制器平台能够高效进行间歇计算，显著提升了性能和能效。

Abstract: Low-power multicore platforms are suitable for running data-intensive tasks
in parallel, but they are highly inefficient for computing on intermittent
power. In this work, we present PEARL (PowEr And eneRgy-aware MuLticore
Intermittent Computing), a novel systems support that can make existing
multicore microcontroller (MCU) platforms suitable for efficient intermittent
computing. PEARL achieves this by leveraging only a three-threshold voltage
tracking circuit and an external fast non-volatile memory, which multicore MCUs
can smoothly interface. PEARL software runtime manages these components and
performs energy- and power-aware adaptation of the multicore configuration to
introduce minimal backup overheads and boost performance. Our evaluation shows
that PEARL outperforms the state-of-the-art solutions by up to 30x and consumes
up to 32x less energy.

</details>


### [66] [Edge-Enabled UAV Swarm Deployment for Rapid Post-Disaster Search and Rescue](https://arxiv.org/abs/2511.01459)
*Alaa Awad Abdellatif,Helder Fontes,Andre Coelho,Luis M. Pessoa,Rui Campos*

Main category: cs.ET

TL;DR: 提出了一种基于多无人机的联合雷达通信系统优化框架，通过分布式算法解决无人机定位和功率分配问题，在保证通信性能的同时最大化雷达感知能力。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，需要同时实现雷达感知和通信目标，传统方法难以兼顾两者性能。利用多无人机协同工作可以提升系统整体效能。

Method: 采用分布式JRC解决方案，通过设计高效奖励机制选择最佳动作，解决NP-hard的无人机定位和功率分配组合优化问题。

Result: 仿真结果显示，与现有雷达或通信中心轨迹规划方法相比，所提方案在性能上有显著提升，且具有多项式复杂度。

Conclusion: 所提出的分布式JRC框架能够有效优化多无人机系统的雷达感知和通信性能，在复杂环境中展现出优越性能。

Abstract: This paper presents an optimized Joint Radar-Communication (JRC) system
utilizing multiple Unmanned Aerial Vehicles (UAVs) to simultaneously achieve
sensing and communication objectives. By leveraging UAVs equipped with dual
radar and communication capabilities, the proposed framework aims to maximize
radar sensing performance across all UAVs in challenging environments. The
proposed approach focuses on formulating and solving a UAV positioning and
power allocation problem to optimize multi-UAV sensing and communications
performance over multiple targets within designated zones. Due to the NP-hard
and combinatorial nature of the problem, we propose a Distributed JRC-based
(DJRC) solution. This solution employs an efficient reward for potential
actions and consistently selects the best action that maximizes the reward
while ensuring both communications and sensing performance. Simulation results
demonstrate significant performance improvements of the proposed solution over
state-of-the-art radar- or communication-centric trajectory planning methods,
with polynomial complexity dependent on the number of UAVs and linear
dependence on the iteration count.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [67] [Predicting the spatial distribution and demographics of commercial swine farms in the United States](https://arxiv.org/abs/2511.00132)
*Felipe E. Sanchez,Thomas A. Lake,Jason A. Galvis,Chris Jones,Gustavo Machado*

Main category: stat.AP

TL;DR: 使用语义分割和机器学习方法识别美国东南部和中西部地区的猪场位置、类型和规模，填补现有空间和人口数据的空白。


<details>
  <summary>Details</summary>
Motivation: 获取准确的牲畜养殖场位置和人口统计数据对于疾病监测、风险评估和空间流行病学模型开发至关重要。

Method: 采用语义分割模型识别猪舍候选点，然后使用随机森林分类器减少误报，最后用随机森林回归模型估计种群规模。

Result: 模型在东南部和中西部识别出45,580个确认的猪舍多边形，分为16,976个预测农场，并按四种生产类型分类。种群规模预测准确率因生产类型而异，87%的预测在参考值500头范围内。

Conclusion: 研究结果揭示了美国生猪生产现有空间和人口数据的重大空白，为疾病监测和风险评估提供了重要数据支持。

Abstract: Data on livestock farm locations and demographics are essential for disease
monitoring, risk assessment, and developing spatially explicit epidemiological
models. Our semantic segmentation model achieved an F2 score of 92 % and a mean
Intersection over Union of 76 %. An initial total of 194,474 swine barn
candidates were identified in the Southeast (North Carolina = 111,135, South
Carolina = 37,264 Virginia = 46,075) and 524,962 in the Midwest (Iowa = 168,866
Minnesota = 165,714 Ohio = 190,382). The post processing Random Forest
classifier reduced false positives by 82 % in the Southeast and 88 % in the
Midwest, resulting in 45,580 confirmed barn polygons. These were grouped into
16,976 predicted farms and classified into one of the four production types.
Population sizes were then estimated using the Random Forest regression model,
with prediction accuracy varying by production type. Across all farms, 87 % of
predictions for operations with 1,000 2,000 pigs were within 500 pigs of the
reference value, with nursery farms showing the highest agreement (R2= 0.82),
followed by finisher farms (R2 = 0.77) and sow farms (R2 = 0.56). Our results
revealed substantial gaps in the existing spatial and demographic data on U.S.
swine production.

</details>


### [68] [A Systematic Review of Spatio-Temporal Statistical Models: Theory, Structure, and Applications](https://arxiv.org/abs/2511.00422)
*Isabella Habereder,Thomas Kneib,Isao Echizen,Timo Spinde*

Main category: stat.AP

TL;DR: 该论文对2021-2025年间83篇时空模型文献进行了系统性综述，提出了时空模型结构分类方案，并分析了流行病学、生态学等主要应用领域的模型使用情况。


<details>
  <summary>Details</summary>
Motivation: 现有综述多集中于特定领域或模型类型，缺乏跨学科的全面概述，需要填补这一研究空白。

Method: 遵循PRISMA指南进行系统性文献综述，检索两个数据库，筛选出83篇符合标准的文献，提出时空模型结构分类方案。

Result: 发现层次模型使用最频繁，大多数模型包含加性分量处理时空依赖性；不同应用领域偏好不同模型结构；研究集中在少数几个学科；可重复性有限。

Conclusion: 该综述为跨学科比较模型结构提供了启发，并强调了提高透明度、可访问性和跨领域知识转移的机会。

Abstract: Data with spatial-temporal attributes are prevalent across many research
fields, and statistical models for analyzing spatio-temporal relationships are
widely used. Existing reviews focus either on specific domains or model types,
creating a gap in comprehensive, cross-disciplinary overviews. To address this,
we conducted a systematic literature review following the PRISMA guidelines,
searched two databases for the years 2021-2025, and identified 83 publications
that met our criteria. We propose a classification scheme for spatio-temporal
model structures and highlight their application in the most common fields:
epidemiology, ecology, public health, economics, and criminology. Although
tasks vary by domain, many models share similarities. We found that
hierarchical models are the most frequently used, and most models incorporate
additive components to account for spatial-temporal dependencies. The preferred
model structures differ among fields of application. We also observe that
research efforts are concentrated in only a few specific disciplines, despite
the broader relevance of spatio-temporal data. Furthermore, we notice that
reproducibility remains limited. Our review, therefore, not only offers
inspiration for comparing model structures in an interdisciplinary manner but
also highlights opportunities for greater transparency, accessibility, and
cross-domain knowledge transfer.

</details>


### [69] [Spatiotemporal Dynamics of Conflict Occurrence and Fatalities in Ethiopia: A Bayesian Model and Predictive Insights Using Event-level Data (1997--2024)](https://arxiv.org/abs/2511.00867)
*Yassin Tesfaw Abebe,Abdu Mohammed Seid,Lassi Roininen,Mohammed Seid Ali*

Main category: stat.AP

TL;DR: 该研究使用时空双贝叶斯模型分析埃塞俄比亚冲突死亡事件，将死亡视为二元发生和计数两个关联结果，发现空袭、炮击和攻击造成最高死亡风险，边境地区暴力更严重。


<details>
  <summary>Details</summary>
Motivation: 需要更好地理解冲突死亡事件的空间和时间模式，为保护脆弱社区的政策规划和资源分配提供依据。

Method: 使用时空双贝叶斯模型，结合固定效应和随机效应，通过Matérn场先验和INLA方法进行推断，分析事件类型、季节、距离城市和边境等协变量。

Result: 结果显示强烈的空间聚集性和时间变异性，空袭、炮击和攻击导致最高死亡可能性和数量，夏季多发死亡事件，边境地区暴力更严重。

Conclusion: 同时建模空间和时间维度对于更好理解和预测冲突死亡风险至关重要，研究结果为保护脆弱社区的规划、政策和资源分配提供了见解。

Abstract: This study presents a spatiotemporal dual Bayesian model that examines both
the occurrence and number of conflict fatalities using event-level data from
Ethiopia (1997-2024), sourced from the Armed Conflict Location and Event Data
(ACLED) project. Fatalities are treated as two linked outcomes: the binary
occurrence of deaths and the count of deaths when they occur. The model
combines additive fixed effects for covariates with random effects capturing
spatiotemporal influences, allowing for outcome-specific effects. Covariates
include event type and season as categorical variables, proximity to cities and
borders as nonlinear effects, and population as an offset term in the count
model. A latent spatiotemporal process accounts for shared spatial and temporal
dependence, with the spatial structure modeled using a Mat\'ern field prior and
inference via Integrated Nested Laplace Approximation (INLA). Results show
strong spatial clustering and temporal variation in fatality risk, emphasizing
the importance of modeling both dimensions for better understanding and
prediction. Airstrikes, shelling, and attacks show the highest fatality
likelihood and counts, while communal and rebel actors cause the most deaths.
Multiple fatalities are more likely in summer, and proximity to borders drives
intense violence, whereas remoteness from urban centers is linked to
lower-intensity events. These results provide insight for planning, policy, and
resource allocation to protect vulnerable communities.

</details>


### [70] [The Multidimensional Index of Child Growth (MICG) of the Task Force "Towards a Multidimensional Approach for Child Growth" of the International Union for Nutrition Sciences](https://arxiv.org/abs/2511.01607)
*Rolando Gonzales Martinez,Hinke Haisma*

Main category: stat.AP

TL;DR: 本文提出了多维儿童成长指数(MICG)，采用能力与权利框架评估儿童福祉的14个维度，通过实证数据验证了该框架的有效性，并开发了可视化工具和政策应用。


<details>
  <summary>Details</summary>
Motivation: 传统儿童成长指标仅关注身高体重等物理指标，无法全面反映儿童福祉。需要开发更全面的多维评估框架来揭示隐藏的剥夺问题。

Method: 采用能力与权利框架，涵盖健康、照料、心理健康、参与、自主权等14个维度，使用29个指标，比较不同加权方法，并应用贝叶斯方法估计未实现的机会。

Result: 研究发现平等加权方法提供稳健且政策相关的结果；MICG能揭示物理指标无法发现的剥夺问题；社区参与WASH项目与多维结果改善相关；开发了蜘蛛网成长图进行可视化。

Conclusion: MICG提供了一个实用、关注公平的工具，可用于监测、评估和加强支持可持续发展目标的干预措施，确保不让任何儿童掉队。

Abstract: Children's growth extends beyond height and weight. This paper introduces the
Multidimensional Index of Child Growth (MICG), developed by the IUNS Task Force
"Towards a Multidimensional Approach for Child Growth." The IUNS-MICG applies a
capability- and rights-based framework covering 14 dimensions of child
wellbeing, including health, care, mental wellbeing, participation, autonomy,
mobility, and safety. Using data from the Young Lives Study in Ethiopia, India,
Peru, and Vietnam, we tested the framework with 29 indicators. Comparisons of
different weighting methods show that equal weights provide robust and
policy-relevant results. MICG uncovers deprivations hidden by physical measures
alone; for instance, rural girls in Peru face educational and mental wellbeing
disadvantages despite similar physical growth. Further analyses show that
community participation in WASH programs is linked to higher multidimensional
outcomes, especially for the most deprived. We also extend MICG with a Bayesian
approach to estimate children's unrealized opportunities and propose a
spiderweb growth chart for visualizing multidimensional progress. MICG offers a
practical, equity-focused tool to monitor, evaluate, and strengthen
interventions that support the Sustainable Development Goals and ensure no
child is left behind.

</details>


### [71] [Geometric Modeling of Hippocampal Tau Deposition: A Surface-Based Framework for Covariate Analysis and Off-Target Contamination Detection](https://arxiv.org/abs/2511.01732)
*Liangkang Wang,Akhil Ambekar,Ani Eloyan*

Main category: stat.AP

TL;DR: 提出结合几何建模与疾病进展分析的框架，研究阿尔茨海默病中tau蛋白沉积的空间分布和形态变化，通过主表面投影量化tau覆盖度、强度和厚度，识别疾病亚型和阶段。


<details>
  <summary>Details</summary>
Motivation: 研究阿尔茨海默病中tau蛋白沉积的空间分布模式和形态变化，解决传统体素分析中的多重比较问题，同时保持空间特异性。

Method: 构建海马主表面，通过双向投影距离和标准化摄取值比率(SUVR)插值量化tau参数，使用两阶段回归模型分析协变量效应，应用SuStaIn模型识别疾病亚型和阶段。

Result: 识别出两种AD亚型：边缘主导型显示年龄相关的非线性tau积累，后部亚型在整个疾病进展中呈现均匀SUVR增加。海马tau沉积遵循结构化空间轨迹双向扩展。

Conclusion: 该框架有效捕捉tau病理的空间动态，揭示不同亚型的特异性沉积模式，并证明可扩展到其他成像模态如淀粉样蛋白PET。

Abstract: We introduce a framework combining geometric modeling with disease
progression analysis to investigate tau deposition in Alzheimer's disease (AD)
using positron emission tomography (PET) data. Focusing on the hippocampus, we
construct a principal surface that captures the spatial distribution and
morphological changes of tau pathology. By projecting voxels onto this surface,
we quantify tau coverage, intensity, and thickness through bidirectional
projection distances and interpolated standardized uptake value ratios (SUVR).
This low-dimensional embedding preserves spatial specificity while mitigating
multiple comparison issues. Covariate effects are analyzed using a two-stage
regression model with inverse probability weighting to adjust for signal
sparsity and selection bias. Using the SuStaIn model, we identify subtypes and
stages of AD, revealing distinct tau dynamics: the limbic-predominant subtype
shows age-related nonlinear accumulation in coverage and thickness, whereas the
posterior subtype exhibits uniform SUVR increases across disease progression.
Model-based predictions show that hippocampal tau deposition follows a
structured spatial trajectory expanding bidirectionally with increasing
thickness, while subtype differences highlight posterior hippocampal
involvement consistent with whole-brain patterns. Finally, directional signal
patterns on the principal surface reveal contamination from the choroid plexus,
demonstrating the broader applicability of the proposed framework across
modalities including amyloid PET.

</details>


### [72] [Large Language Model-Derived Priors Can Improve Bayesian Survival Analyses: A Glioblastoma Application](https://arxiv.org/abs/2511.01778)
*Richard Evans,Max Felland,Susanna Evans,Lindsey Sloan*

Main category: stat.AP

TL;DR: 使用生成式AI为贝叶斯胶质母细胞瘤生存分析构建先验分布，替代传统专家意见获取方法


<details>
  <summary>Details</summary>
Motivation: 传统从放射肿瘤学家获取专家意见来构建贝叶斯先验分布的过程困难、不可靠且耗时，需要寻找替代方法

Method: 使用三个聊天机器人各生成两个替代先验分布，由放射肿瘤学家评估后用于敏感性分析评估后验稳定性

Result: 生成式AI能够快速提出合理的危险比先验分布，在敏感性分析中表现出良好的后验稳定性

Conclusion: 对于这种癌症生存分析，生成式AI提供的先验分布是专家意见获取的首选替代方法

Abstract: This report describes an application of artificial intelligence (AI) to the
Bayesian analysis of glioblastoma survival data. It has been suggested that AI
can be used to construct prior distributions for parameters in Bayesian models
rather than using the difficult, unreliable, and time-consuming process of
eliciting expert opinion from radiation oncologists. Here, we show how
generative AI can quickly propose sensible prior distributions of the hazard
ratio comparing two glioblastoma therapies, for a standard Bayesian survival
model on real data. Three Chatbots generated two alternative priors each which
were evaluated by a radiation oncologist and then used in a sensitivity
analysis to assess posterior stability. The results suggest that, for this
cancer survival analysis, priors from generative AI are a preferred alternative
method to expert elicitation.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [73] [When Small Acts Scale: Ethical Thresholds in Network Diffusion](https://arxiv.org/abs/2511.00329)
*Masoud Makrehchi*

Main category: cs.SI

TL;DR: 论文提出了一个网络传播模型来分析公共行为在网络环境中的扩散效应，引入了网络乘数概念，并识别了临界阈值来区分不同传播状态。


<details>
  <summary>Details</summary>
Motivation: 传统伦理评估主要关注二元行为（一个施动者对一个接收者），但在网络化的平台环境中，这种视角无法捕捉公共行为的扩散效应。

Method: 构建了一个最小消息传递模型，包含初始行为基准效价、曝光度、显著性、遵从度和传播深度等参数，推导出网络乘数的闭式解。

Result: 模型识别出临界阈值r=1，区分了亚临界（饱和）、临界（线性）和超临界（几何级数）三种传播状态，并展示了平台设计杠杆如何系统性改变下游责任。

Conclusion: 该模型为分析平台环境中行为扩散的伦理责任提供了框架，可应用于疫情缓解、疫苗接种外部性以及平台对亲社会和有害规范的放大效应分析。

Abstract: Much ethical evaluation treats actions dyadically: one agent acts on one
recipient. In networked, platform-mediated environments, this lens misses how
public acts diffuse. We introduce a minimal message-passing model in which an
initiating act with baseline valence w spreads across a social graph with
exposure b, per-hop salience $alpha$, compliance $q$, and depth (horizon) d.
The model yields a closed-form \emph{network multiplier} relative to the dyadic
baseline and identifies a threshold at r=b.alpha.q=1 separating subcritical
(saturating), critical (linear), and supercritical (geometric) regimes. We show
how common platform design levers -- reach and fan-out (affecting b), ranking
and context (affecting alpha), share mechanics and friction (affecting q), and
time-bounds (affecting d) -- systematically change expected downstream
responsibility Applications include pandemic mitigation and vaccination
externalities, as well as platform amplification of prosocial and harmful
norms.

</details>


### [74] [U-centrality: A Network Centrality Measure Based on Minimum Energy Control for Laplacian Dynamics](https://arxiv.org/abs/2511.00339)
*Xinran Zheng,Leonardo Massai,Massimo Franceschetti,Behrouz Touri*

Main category: cs.SI

TL;DR: 提出了一种基于最优控制理论的动态任务感知中心性框架U-centrality，量化节点统一智能体状态的能力，在短时间尺度上接近度中心性，在长时间尺度上接近电流流接近中心性。


<details>
  <summary>Details</summary>
Motivation: 传统中心性度量（如度中心性和中介中心性）是纯结构性的，忽略了网络中的动态过程。节点的重要性应该是上下文相关的，需要反映系统动态和特定目标。

Method: 基于拉普拉斯动力学，构建平均意见的最小能量控制问题，关注终端状态的方差，提出U-centrality度量。

Result: U-centrality在短时间尺度上与度中心性一致，在长时间尺度上收敛到与电流流接近中心性密切相关的新中心性度量。

Conclusion: 这项工作连接了结构和动态的中心性方法，为动态环境中的网络分析提供了原则性、多功能的工具。

Abstract: Network centrality is a foundational concept for quantifying the importance
of nodes within a network. Many traditional centrality measures--such as degree
and betweenness centrality--are purely structural and often overlook the
dynamics that unfold across the network. However, the notion of a node's
importance is inherently context-dependent and must reflect both the system's
dynamics and the specific objectives guiding its operation. Motivated by this
perspective, we propose a dynamic, task-aware centrality framework rooted in
optimal control theory. By formulating a problem on minimum energy control of
average opinion based on Laplacian dynamics and focusing on the variance of
terminal state, we introduce a novel centrality measure--termed
U-centrality--that quantifies a node's ability to unify the agents' state. We
demonstrate that U-centrality interpolates between known measures: it aligns
with degree centrality in the short-time horizon and converges to a new
centrality over longer time scales which is closely related to current-flow
closeness centrality. This work bridges structural and dynamical approaches to
centrality, offering a principled, versatile tool for network analysis in
dynamic environments.

</details>


### [75] [Opinion Dynamics: A Comprehensive Overview](https://arxiv.org/abs/2511.00401)
*Mohammad Shirzadi,Emilio Cruciani,Ahad N. Zehmakan*

Main category: cs.SI

TL;DR: 这篇调查论文通过统一框架回顾了意见动力学模型，将其分类并分析了收敛性、病毒营销和用户特征三个关键方面。


<details>
  <summary>Details</summary>
Motivation: 意见动力学研究在不同学科中分散且缺乏共享框架，本文旨在弥合这些差距，促进跨学科合作。

Method: 在统一框架下回顾知名意见动力学模型，基于性质将其分类，并分析收敛特性、病毒营销算法和节点特征影响。

Result: 系统分析了不同模型的最终配置（共识vs极化）和收敛时间，总结了病毒营销的算法和复杂性结果，探讨了节点特性对扩散结果的影响。

Conclusion: 通过统一各学科的术语、方法和挑战，本文促进了跨学科合作，加速了对意见动力学的理解和利用。

Abstract: Opinion dynamics, the evolution of individuals through social interactions,
is an important area of research with applications ranging from politics to
marketing. Due to its interdisciplinary relevance, studies of opinion dynamics
remain fragmented across computer science, mathematics, the social sciences,
and physics, and often lack shared frameworks. This survey bridges these gaps
by reviewing well-known models of opinion dynamics within a unified framework
and categorizing them into distinct classes based on their properties.
Furthermore, the key findings on these models are covered in three parts:
convergence properties, viral marketing, and user characteristics. We first
analyze the final configuration (consensus vs polarized) and convergence time
for each model. We then review the main algorithmic, complexity, and
combinatorial results in the context of viral marketing. Finally, we explore
how node characteristics, such as stubbornness, activeness, or neutrality,
shape diffusion outcomes. By unifying terminology, methods, and challenges
across disciplines, this paper aims to foster cross-disciplinary collaboration
and accelerate progress in understanding and harnessing opinion dynamics.

</details>


### [76] [A Framework Based on Graph Cellular Automata for Similarity Evaluation in Urban Spatial Networks](https://arxiv.org/abs/2511.00768)
*Peiru Wu,Maojun Zhai,Lingzhu Zhang*

Main category: cs.SI

TL;DR: 提出了GCA-Sim框架，基于图元胞自动机评估城市空间网络相似性，通过信息演化过程中的分布差异来测量相似度，发现了网络共振现象，在道路网络聚类中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多不适用于空间网络，难以有效区分城市空间网络的相似性，需要专门针对空间网络特点的相似性评估方法。

Method: 使用图元胞自动机框架，每个子模型通过信息演化过程中多个阶段记录的值分布差异来测量相似度，采用改进的可微分逻辑门网络学习能诱导网络共振的子模型。

Result: 在50个城市级和50个区级道路网络上进行聚类评估，该框架的子模型优于现有方法，轮廓系数超过0.9；发现规划主导的街道网络内部同质性低于有机生长的网络，不同领域的形态类别贡献相当，度作为基本拓扑信号在迭代过程中与土地价值等变量越来越对齐。

Conclusion: GCA-Sim框架能有效评估城市空间网络相似性，网络共振现象能放大网络信号差异，该框架在城市形态分析中具有重要应用价值。

Abstract: Measuring similarity in urban spatial networks is key to understanding cities
as complex systems. Yet most existing methods are not tailored for spatial
networks and struggle to differentiate them effectively. We propose GCA-Sim, a
similarity-evaluation framework based on graph cellular automata. Each submodel
measures similarity by the divergence between value distributions recorded at
multiple stages of an information evolution process. We find that some
propagation rules magnify differences among network signals; we call this
"network resonance." With an improved differentiable logic-gate network, we
learn several submodels that induce network resonance. We evaluate similarity
through clustering performance on fifty city-level and fifty district-level
road networks. The submodels in this framework outperform existing methods,
with Silhouette scores above 0.9. Using the best submodel, we further observe
that planning-led street networks are less internally homogeneous than
organically grown ones; morphological categories from different domains
contribute with comparable importance; and degree, as a basic topological
signal, becomes increasingly aligned with land value and related variables over
iterations.

</details>


### [77] [Deciphering Scientific Collaboration in Biomedical LLM Research: Dynamics, Institutional Participation, and Resource Disparities](https://arxiv.org/abs/2511.00818)
*Lingyao Li,Zhijie Duan,Xuexin Li,Xiaoran Xu,Zhaoqian Xue,Siyuan Ma,Jin Jin*

Main category: cs.SI

TL;DR: 分析574篇生物医学LLM论文发现：合作多样性增加，技术门槛降低，但资源不平等持续存在，形成民主化趋势与资源驱动等级并存的复杂格局


<details>
  <summary>Details</summary>
Motivation: 研究LLM技术如何重塑生物医学科学合作的结构与公平性，了解这一快速技术变革对合作网络的影响

Method: 分析PubMed中5,674篇LLM相关生物医学出版物，评估合作多样性演变、识别关键机构和学科、评估资源差异对研究表现的影响

Result: 合作多样性稳步增长，计算机科学作者比例下降；斯坦福大学和哈佛医学院等机构处于网络中心；医学与计算机科学是桥梁学科；资源与研究成果强相关，资源受限的高绩效机构更倾向与顶级机构合作

Conclusion: 生物医学LLM研究呈现民主化趋势与资源驱动等级并存的复杂局面，战略合作在这一演变领域中发挥关键作用

Abstract: Large language models (LLMs) are increasingly transforming biomedical
discovery and clinical innovation, yet their impact extends far beyond
algorithmic revolution-LLMs are restructuring how scientific collaboration
occurs, who participates, and how resources shape innovation. Despite this
profound transformation, how this rapid technological shift is reshaping the
structure and equity of scientific collaboration in biomedical LLM research
remains largely unknown. By analyzing 5,674 LLM-related biomedical publications
from PubMed, we examine how collaboration diversity evolves over time, identify
institutions and disciplines that anchor and bridge collaboration networks, and
assess how resource disparities underpin research performance. We find that
collaboration diversity has grown steadily, with a decreasing share of Computer
Science and Artificial Intelligence authors, suggesting that LLMs are lowering
technical barriers for biomedical investigators. Network analysis reveals
central institutions, including Stanford University and Harvard Medical School,
and bridging disciplines such as Medicine and Computer Science that anchor
collaborations in this field. Furthermore, biomedical research resources are
strongly linked to research performance, with high-performing
resource-constrained institutions exhibiting larger collaboration volume with
the top 1% most connected institutions in the network. Together, these findings
reveal a complex landscape, where democratizing trends coexist with a
persistent, resource-driven hierarchy, highlighting the critical role of
strategic collaboration in this evolving field.

</details>


### [78] [Beyond Single-Tokenomics: How Farcaster's Pluralistic Incentives Reshape Social Networking](https://arxiv.org/abs/2511.00827)
*Wen Yang,Qiming Ye,Onur Ascigil,Saidu Sokoto,Leonhard Balduf,Michał Król,Gareth Tyson*

Main category: cs.SI

TL;DR: 首次实证分析不同代币奖励机制对平台动态和用户行为的影响，基于Farcaster区块链社交网络的大规模数据，揭示了代币经济学设计在参与度、财富分配和社交互动方面的复杂效果。


<details>
  <summary>Details</summary>
Motivation: 研究加密货币在社交平台中的整合效果，探索不同代币奖励机制如何影响用户行为和平台生态，填补了该领域实证研究的空白。

Method: 收集Farcaster区块链去中心化社交网络的独特大规模数据集，包含574,829个钱包关联用户的代币交易和社交互动数据，进行社会经济分析和因果分析。

Result: 不同代币设计导致参与率差异显著(7.6%-70%)，财富集中度高(Gini 0.72-0.94)；跨社区打赏占51-75%，非关注用户间打赏频率高1.3-2倍；代币奖励促进内容创作但可能损害质量，增加粉丝获取但对关注他人影响中性或负面，算法奖励有累积效应。

Conclusion: 加密货币整合到社交平台面临挑战，经济激励与真实社交价值之间存在权衡，需要更精细的代币经济学设计来平衡激励效果和平台生态健康。

Abstract: This paper presents the first empirical analysis of how diverse token-based
reward mechanisms impact platform dynamics and user behaviors. For this, we
gather a unique, large-scale dataset from Farcaster. This blockchain-based,
decentralized social network incorporates multiple incentive mechanisms
spanning platform-native rewards, third-party token programs, and peer-to-peer
tipping. Our dataset captures token transactions and social interactions from
574,829 wallet-linked users, representing 64.25% of the platform's user base.
Our socioeconomic analyses reveal how different tokenomics design shape varying
participation rates (7.6%--70%) and wealth concentration patterns (Gini
0.72--0.94), whereas inter-community tipping (51--75% of all tips) is 1.3--2x
more frequent among non-following pairs, thereby mitigating echo chambers. Our
causal analyses further uncover several critical trade-offs: (1) while most
token rewards boost content creation, they often fail to enhance -- sometimes
undermining -- content quality; (2) token rewards increase follower acquisition
but show neutral or negative effects on outbound following, suggesting
potential asymmetric network growth; (3) repeated algorithmic rewards
demonstrate strong cumulative effects that may encourage strategic
optimization. Our findings advance understanding of cryptocurrency integration
in social platforms and highlight challenges in aligning economic incentives
with authentic social value.

</details>


### [79] [Do Employee Verification Mechanisms Alter Cultural Signals in Employer Reviews?](https://arxiv.org/abs/2511.01086)
*Vladimir Martirosyan,Rachit Kamdar*

Main category: cs.SI

TL;DR: 比较匿名平台Glassdoor和身份验证平台Blind上的雇主评论差异，发现验证机制改变了文化表达方式，影响求职者对工作场所文化的认知。


<details>
  <summary>Details</summary>
Motivation: 研究身份验证如何影响在线雇主评论的真实性和文化表达，探讨不同平台对求职决策的影响。

Method: 使用竞争价值观框架(宗族、临时体制、层级、市场)和CultureBERT模型，分析超过30万条评分数据。

Result: Blind评论强调宗族和层级文化，Glassdoor偏向正面评价并突出宗族和市场文化。验证本身不能消除偏见，但改变了文化表达方式。

Conclusion: 不同平台提供系统性的不同文化信号，影响求职者的申请决策和职位匹配。

Abstract: Online reviews shape impressions across products and workplaces. Employer
reviews combine narratives and ratings that reflect culture. Glassdoor permits
fully anonymous posts; Blind requires employment verification while preserving
anonymity. We ask how verification changes reviews. Evidence suggests verified
reviews can be more trustworthy, yet verification can also erode authenticity
when expectations are unmet. We use the Competing Values Framework (clan,
adhocracy, hierarchy, market) and the CultureBERT model by Koch and Pasch, 2023
to over 300k ratings. We find that Blind reviews emphasize clan and hierarchy
while Glassdoor skews positive and highlights clan and market. Verification on
its own does not remove bias but shifts how culture is represented. Job seekers
using different platforms receive systematically different signals about
workplace culture, affecting application decisions and job-matching.

</details>


### [80] [DEEP: A Discourse Evolution Engine for Predictions about Social Movements](https://arxiv.org/abs/2511.01142)
*Valerio La Gatta,Marco Postiglione,Jeremy Gilbert,Daniel W. Linna Jr.,Morgan Manella Greenfield,Aaron Shaw,V. S. Subrahmanian*

Main category: cs.SI

TL;DR: SMART工具使用基于Transformer的多变量时间序列模型DEEP来预测社会运动相关的文章/帖子数量和情感表达，支持联合国可持续发展目标的实现。


<details>
  <summary>Details</summary>
Motivation: 理解关键事件如何影响社会运动对实现联合国可持续发展目标至关重要，需要开发工具来追踪和分析相关社会运动。

Method: 开发了SMART工具，采用基于Transformer的多变量时间序列模型DEEP，能够预测未来文章/帖子数量和情感表达，并提供概率预测和不确定性估计。

Result: 通过对#MeToo运动的案例研究，创建了包含43.3万Reddit帖子和12.1万新闻文章的新型纵向数据集，验证了DEEP模型的有效性。

Conclusion: DEEP模型能够提供概率预测和不确定性估计，为编辑规划和战略决策提供关键支持，相关数据集将在论文发表后公开供研究使用。

Abstract: Numerous social movements (SMs) around the world help support the UN's
Sustainable Development Goals (SDGs). Understanding how key events shape SMs is
key to the achievement of the SDGs. We have developed SMART (Social Media
Analysis & Reasoning Tool) to track social movements related to the SDGs. SMART
was designed by a multidisciplinary team of AI researchers, journalists,
communications scholars and legal experts. This paper describes SMART's
transformer-based multivariate time series Discourse Evolution Engine for
Predictions about Social Movements (DEEP) to predict the volume of future
articles/posts and the emotions expressed. DEEP outputs probabilistic forecasts
with uncertainty estimates, providing critical support for editorial planning
and strategic decision-making. We evaluate DEEP with a case study of the #MeToo
movement by creating a novel longitudinal dataset (433K Reddit posts and 121K
news articles) from September 2024 to June 2025 that will be publicly released
for research purposes upon publication of this paper.

</details>


### [81] [Influence-aware Causal Autoencoder Network for Node Importance Ranking in Complex Networks](https://arxiv.org/abs/2511.01228)
*Jiahui Gao,Kuang Zhou,Yuchen Zhu*

Main category: cs.SI

TL;DR: 提出了ICAN框架，通过因果表示学习在合成网络上训练节点重要性排名模型，无需依赖目标网络拓扑，实现跨网络的泛化应用


<details>
  <summary>Details</summary>
Motivation: 现有节点重要性排名方法依赖目标网络拓扑结构，存在隐私问题和泛化能力差的问题，需要设计不依赖目标网络拓扑的通用模型

Method: 使用影响感知因果表示学习模块，在自编码器架构中提取与节点重要性因果相关的嵌入，结合因果排名损失和统一优化框架

Result: 在多个基准数据集上的实验表明，ICAN在排名准确性和泛化能力方面持续优于最先进的基线方法

Conclusion: ICAN框架成功实现了在合成网络上训练、在真实网络上应用的节点重要性排名，解决了隐私和泛化问题

Abstract: Node importance ranking is a fundamental problem in graph data analysis.
Existing approaches typically rely on node features derived from either
traditional centrality measures or advanced graph representation learning
methods, which depend directly on the target network's topology. However, this
reliance on structural information raises privacy concerns and often leads to
poor generalization across different networks. In this work, we address a key
question: Can we design a node importance ranking model trained exclusively on
synthetic networks that is effectively appliable to real-world networks,
eliminating the need to rely on the topology of target networks and improving
both practicality and generalizability? We answer this question affirmatively
by proposing the Influence-aware Causal Autoencoder Network (ICAN), a novel
framework that leverages causal representation learning to get robust,
invariant node embeddings for cross-network ranking tasks. Firstly, ICAN
introduces an influence-aware causal representation learning module within an
autoencoder architecture to extract node embeddings that are causally related
to node importance. Moreover, we introduce a causal ranking loss and design a
unified optimization framework that jointly optimizes the reconstruction and
ranking objectives, enabling mutual reinforcement between node representation
learning and ranking optimization. This design allows ICAN, trained on
synthetic networks, to generalize effectively across diverse real-world graphs.
Extensive experiments on multiple benchmark datasets demonstrate that ICAN
consistently outperforms state-of-the-art baselines in terms of both ranking
accuracy and generalization capability.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [82] [The Gatekeeping Expert's Dilemma](https://arxiv.org/abs/2511.00031)
*Shunsuke Matsuno*

Main category: econ.TH

TL;DR: 本文研究具有否决权的专家（守门人专家）如何通过沟通影响代理人。守门人面临透明度与有效性的权衡：透明沟通易被利用，不透明则浪费专业知识。研究表明战略模糊性可以解决这一困境。


<details>
  <summary>Details</summary>
Motivation: 研究守门人专家在专业知识与否决权之间的平衡问题，探索如何在指导代理人行为的同时避免被操纵。这在银行压力测试、环境监管和财务审计等经济场景中普遍存在。

Method: 以财务审计为主要场景，构建理论模型分析守门人专家的沟通策略，特别关注战略模糊性的作用。

Result: 战略模糊性能够解决守门人的困境：通过仅透露足够信息来防止管理者夸大报告，审计师既能指导管理者又能最小化操纵机会。这为审计师主要接受客户财务报告提供了新的理论解释。

Conclusion: 战略模糊性是守门人专家有效沟通的关键策略，即使缺乏直接控制权也能有效影响代理人行为。更大的独立性和专业知识有时反而会抑制沟通效果。

Abstract: This paper studies how experts with veto power -- gatekeeping experts --
influence agents through communication. Their expertise informs agents'
decisions, while veto power provides discipline. Gatekeepers face a dilemma:
transparent communication can invite gaming, while opacity wastes expertise.
How can gatekeeping experts guide behavior without being gamed? Many economic
settings feature this tradeoff, including bank stress tests, environmental
regulations, and financial auditing. Using financial auditing as the primary
setting, I show that strategic vagueness resolves this dilemma: by revealing
just enough to prevent the manager from inflating the report, the auditor
guides the manager while minimizing opportunities for manipulation. This
theoretical lens provides a novel rationale for why auditors predominantly
accept clients' financial reports. Comparative statics reveal that greater
gatekeeper independence or expertise sometimes dampens communication. This
paper offers insights into why gatekeepers who lack direct control can still be
effective.

</details>


### [83] [Hope, Signals, and Silicon: A Game-Theoretic Model of the Pre-Doctoral Academic Labor Market in the Age of AI](https://arxiv.org/abs/2511.00068)
*Shaohui Wang*

Main category: econ.TH

TL;DR: 本文构建了一个博弈论模型，分析生成式AI如何重塑博士前"希望劳动"市场，揭示了AI在自动化与增强功能之间的双重效应、研究助理市场的内生分割、信号军备竞赛以及新型道德风险渠道。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI对博士前研究生态系统的系统性影响，包括PI-RA关系、任务生产技术和博士招生竞争，填补AI对学术劳动力市场影响的理论空白。

Method: 构建统一博弈论模型，整合三个核心要素：(1)PI-RA关系契约阶段；(2)基于任务的生产技术，AI同时具有替代和补充功能；(3)容量受限的招生锦标赛，将绝对产出转化为相对排名。

Result: 发现四个关键结果：AI对RA需求的阈值效应；PI目标异质性导致市场分割；对称生产力冲击引发信号军备竞赛；AI降低常规成果的信息价值，产生"努力洗钱"道德风险。

Conclusion: 生成式AI深刻改变博士前研究生态系统，需要轻触式治理（过程可见性、AI使用披露、有限答辩/复制检查）来平衡效率与伦理考量，减少不道德的监督和筛选实践。

Abstract: This paper develops a unified game-theoretic account of how generative AI
reshapes the pre-doctoral "hope-labor" market linking Principal Investigators
(PIs), Research Assistants (RAs), and PhD admissions. We integrate (i) a PI-RA
relational-contract stage, (ii) a task-based production technology in which AI
is both substitute (automation) and complement (augmentation/leveling), and
(iii) a capacity-constrained admissions tournament that converts absolute
output into relative rank. The model yields four results. First, AI has a dual
and thresholded effect on RA demand: when automation dominates, AI substitutes
for RA labor; when augmentation dominates, small elite teams become more
valuable. Second, heterogeneous PI objectives endogenously segment the RA
market: quantity-maximizing PIs adopt automation and scale "project-manager"
RAs, whereas quality-maximizing PIs adopt augmentation and cultivate
"idea-generator" RAs. Third, a symmetric productivity shock triggers a
signaling arms race: more "strong" signals flood a fixed-slot tournament,
depressing the admission probability attached to any given signal and
potentially lowering RA welfare despite higher productivity. Fourth, AI
degrades the informational content of polished routine artifacts, creating a
novel moral-hazard channel ("effort laundering") that shifts credible
recommendations toward process-visible, non-automatable creative contributions.
We discuss welfare and equity implications, including over-recruitment with
thin mentoring, selectively misleading letters, and opaque pipelines, and
outline light-touch governance (process visibility, AI-use disclosure, and
limited viva/replication checks) that preserves efficiency while reducing
unethical supervision and screening practices.

</details>


### [84] [Subjective inference](https://arxiv.org/abs/2511.00173)
*Andrew Mackenzie*

Main category: econ.TH

TL;DR: 该论文证明了在满足Villegas(1964)公理（除单调性外）的推理下，存在唯一的归一化符号测度表示。如果最大事件与最小事件等价，则可表示为后验与先验的差异，其中后验是条件概率。


<details>
  <summary>Details</summary>
Motivation: 研究当分析师观察到基于线索的排序推理时，如何建立数学表示，特别是探索贝叶斯表示的可能性。

Method: 使用公理化方法，基于Villegas(1964)的公理体系（排除单调性），证明存在唯一的归一化符号测度表示，并进一步分析贝叶斯表示的条件。

Result: 定理1：满足条件的推理有唯一归一化符号测度表示；定理2：在特定条件下可表示为后验与先验的差异，后验唯一，先验由对各猜测的权重决定。

Conclusion: 观察到的先验和后验可能揭示所有猜测都是错误的，这为推理的表示提供了理论框架，但也指出了其局限性。

Abstract: An agent observes a clue, and an analyst observes an inference: a ranking of
events on the basis of how corroborated they are by the clue. We prove that if
the inference satisfies the axioms of Villegas (1964) except for the classic
qualitative probability axiom of monotonicity, then it has a unique normalized
signed measure representation (Theorem 1). Moreover, if the inference also
declares the largest event equivalent to the smallest event, then it can be
represented as a difference between a posterior and a prior such that the
former is the conditional probability of the latter with respect to an assessed
event that is interpreted as a clue guess. Across these Bayesian
representations, the posterior is unique, all guesses are in a suitable sense
equivalent, and the prior is determined by the weight it assigns to each
possible guess (Theorem 2). However, observation of a prior and posterior
compatible with the inference could reveal that all of these guesses are wrong.

</details>


### [85] [Existence of Equilibria in Large Competitive Markets with Bads, Production and Comprehensive Externalities](https://arxiv.org/abs/2511.00478)
*Robert M. Anderson,Haosui Duanmu,M. Ali Khan,Metin Uyanik*

Main category: econ.TH

TL;DR: 本文证明了在生产经济中，存在具有有害商品、外部性和不完全价格依赖偏好的均衡，克服了Hara(2005)的反例。


<details>
  <summary>Details</summary>
Motivation: Hara(2005)展示了在无外部性的原子测度交换经济中，有害商品可能导致均衡不存在。本文旨在证明在存在外部性和有害商品的情况下，均衡仍然存在。

Method: 使用非标准分析技术，通过自然经济考虑推导出有害商品消费的可积边界，并处理作为可积函数等价类的全面外部性。

Result: 证明了在生产经济中，即使存在有害商品、外部性和不完全价格依赖偏好，均衡仍然存在。

Conclusion: 通过非标准分析和处理外部性的新技术，成功证明了在更现实的经济设定下均衡的存在性，为相关理论研究提供了重要工具。

Abstract: This paper establishes the existence of equilibrium in an economy with
production and a continuum of consumers, each of whose incomplete and
price-dependent preferences are defined on commodities they may consider
deleterious, bads which cannot be freely disposed of, and each of whom takes
into account the productions of all firms and the consumptions of all other
consumers. This result has proved elusive since Hara (2005) presented an
example of an atomless measure-theoretic exchange economy with bads (but no
externalities) that has no equilibrium. The result circumvents Hara's example
by showing that, in the presence of bads and externalities, natural economic
considerations imply an integrable bound on the consumption of bads. The proofs
make an essential use of nonstandard analysis, and the novel techniques we
offer to handle comprehensive externalities expressed as an equivalence class
of integrable functions may be of independent methodological interest.

</details>


### [86] [Mechanism Design with Information Leakage](https://arxiv.org/abs/2511.00715)
*Samuel Häfner,Marek Pycia,Haoyuan Zeng*

Main category: econ.TH

TL;DR: 研究机制设计（如拍卖）在信息泄露环境下的特性，提出防泄漏机制的概念，分析不同拍卖机制在信息泄露下的表现。


<details>
  <summary>Details</summary>
Motivation: 传统机制设计假设设计者能控制信息流，但现实中参与者之间可能存在信息泄露。需要研究当设计者无法控制信息流动时，机制应具备的特性。

Method: 提出防泄漏机制的概念，定义为参与者不会基于泄露信息调整行为的机制。分析不同类型拍卖机制（第二价格、升价、第一价格、降价拍卖）在信息泄露环境下的表现。

Result: 发现有效率的拍卖需要是防泄漏的，而收益最大化的拍卖不一定需要。第二价格拍卖和升价拍卖是防泄漏的，第一价格拍卖不是，降价拍卖是否防泄漏取决于平局处理规则。

Conclusion: 防泄漏性是机制设计在信息泄露环境中的重要特性，与事后激励相容性不同。只有防泄漏机制才能在存在信息泄露的环境中实现社会选择函数。

Abstract: We study the design of mechanisms -- e.g., auctions -- when the designer does
not control information flows between mechanism participants. A mechanism
equilibrium is leakage-proof if no player conditions their actions on leaked
information; a property distinct from ex-post incentive compatibility. Only
leakage-proof mechanisms can implement social choice functions in environments
with leakage. Efficient auctions need to be leakage-proof, while
revenue-maximizing ones not necessarily so. Second-price and ascending auctions
are leakage-proof; first-price auctions are not; while whether descending
auctions are leakage-proof depends on tie-breaking.

</details>


### [87] [Persuasive Selection in Signaling Games](https://arxiv.org/abs/2511.00718)
*Haoyuan Zeng*

Main category: econ.TH

TL;DR: 本文提出了一个新的均衡选择标准——说服力，用于在信号博弈中选择均衡。该标准通过比较不同均衡，基于发送者类型是否会顺序偏离到更优均衡来进行选择。


<details>
  <summary>Details</summary>
Motivation: 针对Stiglitz批评，需要一种新的均衡选择标准来解决信号博弈中多重均衡的问题，特别是在单调和非单调信号博弈中提供更强的预测能力。

Method: 提出说服力标准：如果一个均衡比另一个均衡更具说服力，那么偏好后者的发送者类型会在其他类型已经偏离后顺序偏离到前者，即发生解缠过程。

Result: 说服力标准具有强大的选择能力：在单调信号博弈中能唯一选择均衡结果；在非单调信号博弈中能提供比现有标准更精细的预测；在廉价谈话博弈中也能选择均衡，而标准精炼方法在此类博弈中无效。

Conclusion: 说服力是一个有效的均衡选择标准，在各类信号博弈中都能提供有意义的预测，特别是在标准精炼方法失效的情况下仍能发挥作用。

Abstract: This paper introduces a novel criterion, persuasiveness, to select equilibria
in signaling games. In response to the Stiglitz critique, persuasiveness
focuses on the comparison across equilibria. An equilibrium is more persuasive
than an alternative if the set of types of the sender who prefer the
alternative would sequentially deviate to the former once other types have done
so -- that is, if an unraveling occurs. Persuasiveness has strong selective
power: it uniquely selects an equilibrium outcome in monotone signaling games.
Moreover, in non-monotone signaling games, persuasiveness refines predictions
beyond existing selection criteria. Notably, it can also select equilibria in
cheap-talk games, where standard equilibrium refinements for signaling games
have no selective power.

</details>


### [88] [Identity-Compatible Auctions](https://arxiv.org/abs/2511.00723)
*Haoyuan Zeng*

Main category: econ.TH

TL;DR: 该论文研究了单物品拍卖中卖家和买家进行虚假竞标的动机，分析了三种经典拍卖机制的身份兼容性，并强调了隐藏竞标者数量对于实现更广泛结果规则的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究拍卖中卖家和买家通过虚假身份进行竞标的动机，探讨不同拍卖机制的身份兼容性，以及竞标者数量信息的披露对拍卖结果的影响。

Method: 通过分析三种经典拍卖机制（第一价格拍卖、第二价格拍卖和定价销售）的身份兼容性，比较明拍（公开竞标者数量）和暗拍（隐藏竞标者数量）的差异。

Result: 研究发现没有最优的明拍是事后卖家身份兼容的，而暗拍第一价格拍卖（含保留价）能够实现这一目标。隐藏竞标者数量能够实现更广泛的结果规则。

Conclusion: 隐藏竞标者数量对于实现身份兼容的拍卖机制至关重要，暗拍第一价格拍卖是实现卖家身份兼容的有效机制。

Abstract: This paper studies the incentives of the seller and buyers to shill bid in a
single-item auction. An auction is seller identity-compatible if the seller
cannot profit from pretending to be one or more bidders via fake identities. It
is buyer identity-compatible if no buyer profits from posing as more than one
bidder. Lit auctions reveal the number of bidders, whereas dark auctions
conceal the information. We characterize three classic selling mechanisms --
first-price, second-price, and posted-price -- based on identity compatibility.
We show the importance of concealing the number of bidders, which enables the
implementation of a broader range of outcome rules. In particular, no optimal
lit auction is ex-post seller identity-compatible, while the dark first-price
auction (with reserve) achieves the goal.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [89] [Multimodal Learning with Augmentation Techniques for Natural Disaster Assessment](https://arxiv.org/abs/2511.00004)
*Adrian-Dinu Urse,Dumitru-Clementin Cercel,Florin Pop*

Main category: cs.CY

TL;DR: 本文研究了在CrisisMMD多模态数据集上应用数据增强技术来解决类别不平衡和样本有限的问题，包括视觉数据的扩散方法和文本数据的多种增强策略，结果表明增强技术能提高分类性能。


<details>
  <summary>Details</summary>
Motivation: 自然灾害评估需要准确快速的信息获取，社交媒体成为有价值的实时来源，但现有数据集存在类别不平衡和样本有限的问题，使得模型开发具有挑战性。

Method: 对于视觉数据应用基于扩散的方法（Real Guidance和DiffuseMix），对于文本数据探索回译、基于变换器的释义和基于图像描述的增强，并在单模态、多模态和多视图学习设置中进行评估。

Result: 结果显示选定的增强技术提高了分类性能，特别是对于代表性不足的类别，而多视图学习显示出潜力但需要进一步改进。

Conclusion: 本研究强调了构建更鲁棒的自然灾害评估系统的有效增强策略。

Abstract: Natural disaster assessment relies on accurate and rapid access to
information, with social media emerging as a valuable real-time source.
However, existing datasets suffer from class imbalance and limited samples,
making effective model development a challenging task. This paper explores
augmentation techniques to address these issues on the CrisisMMD multimodal
dataset. For visual data, we apply diffusion-based methods, namely Real
Guidance and DiffuseMix. For text data, we explore back-translation,
paraphrasing with transformers, and image caption-based augmentation. We
evaluated these across unimodal, multimodal, and multi-view learning setups.
Results show that selected augmentations improve classification performance,
particularly for underrepresented classes, while multi-view learning introduces
potential but requires further refinement. This study highlights effective
augmentation strategies for building more robust disaster assessment systems.

</details>


### [90] [Chitchat with AI: Understand the supply chain carbon disclosure of companies worldwide through Large Language Model](https://arxiv.org/abs/2511.00024)
*Haotian Hang,Yueyang Shen,Vicky Zhu,Jose Cruz,Michelle Li*

Main category: cs.CY

TL;DR: 开发了一个基于大语言模型的决策支持框架，用于评估企业碳披露质量，将非结构化披露转化为可量化、可比较的智能信息。


<details>
  <summary>Details</summary>
Motivation: 企业碳披露对可持续发展至关重要，但CDP数据集的异质性和自由形式特性给分析带来了挑战，需要新的方法来支持基准测试、合规监控和投资筛选。

Method: 使用大语言模型开发主评分标准，整合11年CDP数据，结合评分标准引导的评分和基于百分位的标准化方法。

Result: 发现技术和德国等国家和行业在评分标准一致性方面表现更好，而其他行业和地区存在波动性或表面参与。

Conclusion: 基于LLM的方法将非结构化披露转化为可量化、可解释、可比较和可操作的智能信息，提升了AI决策支持系统在气候治理领域的能力。

Abstract: In the context of global sustainability mandates, corporate carbon disclosure
has emerged as a critical mechanism for aligning business strategy with
environmental responsibility. The Carbon Disclosure Project (CDP) hosts the
world's largest longitudinal dataset of climate-related survey responses,
combining structured indicators with open-ended narratives, but the
heterogeneity and free-form nature of these disclosures present significant
analytical challenges for benchmarking, compliance monitoring, and investment
screening. This paper proposes a novel decision-support framework that
leverages large language models (LLMs) to assess corporate climate disclosure
quality at scale. It develops a master rubric that harmonizes narrative scoring
across 11 years of CDP data (2010-2020), enabling cross-sector and
cross-country benchmarking. By integrating rubric-guided scoring with
percentile-based normalization, our method identifies temporal trends,
strategic alignment patterns, and inconsistencies in disclosure across
industries and regions. Results reveal that sectors such as technology and
countries like Germany consistently demonstrate higher rubric alignment, while
others exhibit volatility or superficial engagement, offering insights that
inform key decision-making processes for investors, regulators, and corporate
environmental, social, and governance (ESG) strategists. The proposed LLM-based
approach transforms unstructured disclosures into quantifiable, interpretable,
comparable, and actionable intelligence, advancing the capabilities of
AI-enabled decision support systems (DSSs) in the domain of climate governance.

</details>


### [91] [Position Paper: If Innovation in AI Systematically Violates Fundamental Rights, Is It Innovation at All?](https://arxiv.org/abs/2511.00027)
*Josu Eguiluz Castañeira,Axel Brando,Migle Laukyte,Marc Serra-Vidal*

Main category: cs.CY

TL;DR: 这篇立场论文挑战了监管与创新对立的传统观念，论证了精心设计的监管是负责任创新的基础，并以欧盟AI法案为例说明风险导向监管如何解决科林里奇困境。


<details>
  <summary>Details</summary>
Motivation: AI已渗透关键基础设施和决策系统，其失败会造成社会、经济和民主危害。作者旨在反驳监管阻碍创新的观点，证明缺乏良好监管已造成不可估量的损害。

Method: 通过航空、制药和福利系统的类比，以及合成虚假信息、偏见和不可问责决策的案例研究，分析欧盟AI法案作为风险导向、责任驱动的监管模式。

Result: 欧盟AI法案的适应性机制（监管沙盒、中小企业支持、真实世界测试、基本权利影响评估）表明监管可以负责任地加速而非延迟技术进步。

Conclusion: 创新与监管应共同推进，通过将透明度、影响评估、问责制和AI素养嵌入设计和部署，欧盟框架定义了负责任创新的真正含义——受民主价值观和基本权利约束的技术雄心。

Abstract: Artificial intelligence (AI) now permeates critical infrastructures and
decision-making systems where failures produce social, economic, and democratic
harm. This position paper challenges the entrenched belief that regulation and
innovation are opposites. As evidenced by analogies from aviation,
pharmaceuticals, and welfare systems and recent cases of synthetic
misinformation, bias and unaccountable decision-making, the absence of
well-designed regulation has already created immeasurable damage. Regulation,
when thoughtful and adaptive, is not a brake on innovation--it is its
foundation. The present position paper examines the EU AI Act as a model of
risk-based, responsibility-driven regulation that addresses the Collingridge
Dilemma: acting early enough to prevent harm, yet flexibly enough to sustain
innovation. Its adaptive mechanisms--regulatory sandboxes, small and medium
enterprises (SMEs) support, real-world testing, fundamental rights impact
assessment (FRIA) -- demonstrate how regulation can accelerate responsibly,
rather than delay, technological progress. The position paper summarises how
governance tools transform perceived burdens into tangible advantages: legal
certainty, consumer trust, and ethical competitiveness. Ultimately, the paper
reframes progress: innovation and regulation advance together. By embedding
transparency, impact assessments, accountability, and AI literacy into design
and deployment, the EU framework defines what responsible innovation truly
means--technological ambition disciplined by democratic values and fundamental
rights.

</details>


### [92] [Adoption of AI-Driven Fraud Detection System in the Nigerian Banking Sector: An Analysis of Cost, Compliance, and Competency](https://arxiv.org/abs/2511.00061)
*Stephen Alaba John,Joye Ahmed Shonubi,Patience Farida Azuikpe,Victor Oluwatosin Ologun*

Main category: cs.CY

TL;DR: 该研究调查了尼日利亚银行采用AI驱动欺诈检测系统的程度和决定因素，发现高层管理支持、IT基础设施、监管合规、员工能力和感知有效性促进采用，而高实施成本阻碍采用。


<details>
  <summary>Details</summary>
Motivation: AI欺诈检测系统在全球银行业得到应用，但在尼日利亚的采用缓慢、分散且不一致，主要由于高实施成本和技术专业知识缺乏。

Method: 采用横断面调查研究设计，通过基于5点李克特量表的结构化问卷收集主要数据，使用有序逻辑回归模型分析来自5家最大银行的数据。

Result: 结果显示高层管理支持、IT基础设施、监管合规、员工能力和感知有效性加速AI驱动欺诈检测系统的采用，而高实施成本则阻碍采用。

Conclusion: 建议银行投资支持AI工具集成的现代可扩展IT系统，采用成本效益高的开源或云AI平台，并为IT、欺诈调查和风险管理员工提供AI和欺诈分析的持续专业发展。

Abstract: The inception of AI-based fraud detection systems has presented the banking
sector across the globe the opportunity to enhance fraud prevention mechanisms.
However, the extent of adoption in Nigeria has been slow, fragmented, and
inconsistent due to high cost of implementation and lack of technical
expertise. This study seeks to investigate extent of adoption and determinants
of AI-driven fraud detection systems in Nigerian banks. This study adopted a
cross-sectional survey research design. Data were extracted from primary
sources through structured questionnaire based on 5-point Likert scale. The
population of the study consist of 24 licensed banks in Nigeria. A purposive
sampling technique was used to select 5 biggest banks based on market
capitalization and customer base. The Ordered Logistic Regression (OLR) model
was used to estimate the data. The results showed that top management support,
IT infrastructure, regulatory compliance, staff competency and perceived
effectiveness accelerate the uptake of AI-driven fraud detection systems
adoption. However, high implementation cost discourages it. Therefore, the
study recommended that banks should invest in modern and scalable IT systems
that support the integration of AI tools; adopt open-source or cloud-based AI
platforms that are cost-effective; embrace continuous professional development
in AI, and fraud analytics for IT, fraud investigation, and risk management
staff.

</details>


### [93] [What is the Return on Investment of Digital Engineering for Complex Systems Development? Findings from a Mixed-Methods Study on the Post-production Design Change Process of Navy Assets](https://arxiv.org/abs/2511.00077)
*Jannatul Shefa,Taylan G. Topcu*

Main category: cs.CY

TL;DR: 本研究通过案例研究发现数字工程转型可将海军系统维护项目的中位工期缩短50.1%，标准差减少41.5%，提高项目时间可预测性。


<details>
  <summary>Details</summary>
Motivation: 复杂工程系统普遍存在进度和成本超支问题，数字工程被寄予厚望但缺乏量化证据支持其投资回报率。

Method: 采用混合方法研究海军系统维护团队的初步设计阶段，分析进度延误原因，并创建数字工程转型后的假设流程进行对比。

Result: 识别出四种典型的低效模式，量化了进度延误的程度和变化，数字工程转型可显著缩短项目周期并提高可预测性。

Conclusion: 研究首次为数字工程的投资回报率提供了量化证据，证明其在提高复杂系统维护项目效率和可预测性方面的价值。

Abstract: Complex engineered systems routinely face schedule and cost overruns, along
with poor post-deployment performance. Championed by both INCOSE and the U.S.
Department of Defense (DoD), the systems engineering (SE) community has
increasingly looked to Digital Engineering (DE) as a potential remedy. Despite
this growing advocacy, most of DE's purported benefits remain anecdotal, and
its return on investment (ROI) remains poorly understood. This research
presents findings from a case study on a Navy SE team responsible for the
preliminary design phase of post-production design change projects for Navy
assets. Using a mixed-methods approach, we document why complex system
sustainment projects are routinely late, where and to what extent schedule
slips arise, and how a DE transformation could improve schedule adherence. This
study makes three contributions. First, it identifies four archetypical
inefficiency modes that drive schedule overruns and explains how these
mechanisms unfold in their organizational context. Second, it quantifies the
magnitude and variation of schedule slips. Third, it creates a hypothetical
digitally transformed version of the current process, aligned with DoD DE
policy, and compares it to the current state to estimate potential schedule
gains. Our findings suggest that a DE transformation could reduce the median
project duration by 50.1% and reduce the standard deviation by 41.5%, leading
to faster and more predictable timelines. However, the observed gains are not
uniform across task categories. Overall, this study provides initial
quantitative evidence of DE's potential ROI and its value in improving the
efficiency and predictability of complex system sustainment projects.

</details>


### [94] [RailEstate: An Interactive System for Metro Linked Property Trends](https://arxiv.org/abs/2511.00078)
*Chen-Wei Chang,Yu-Chieh Cheng,Yun-En Tsai,Fanglan Chen,Chang-Tien Lu*

Main category: cs.CY

TL;DR: RailEstate是一个基于网络的系统，整合空间分析、自然语言界面和交互式预测，分析地铁站邻近度对华盛顿都市区住宅房价的影响。


<details>
  <summary>Details</summary>
Motivation: 地铁系统的可达性对城市住房市场至关重要，通过提升社区可达性来推动房产需求。现有静态地图工具或通用房源平台无法满足对地铁相关住房数据的深入分析需求。

Method: 结合25年历史住房数据和交通基础设施，支持低延迟地理空间查询、时间序列可视化和预测建模。创新性地使用自然语言聊天机器人将英文问题转换为可执行的SQL查询。

Result: 用户可以交互式探索ZIP码级别的价格模式，调查长期趋势，并预测任何地铁站周围的未来房价。

Conclusion: 这个统一交互平台使城市规划者、投资者和居民能够从地铁相关住房数据中获得可操作的见解，无需技术专业知识。

Abstract: Access to metro systems plays a critical role in shaping urban housing
markets by enhancing neighborhood accessibility and driving property demand. We
present RailEstate, a novel web based system that integrates spatial analytics,
natural language interfaces, and interactive forecasting to analyze how
proximity to metro stations influences residential property prices in the
Washington metropolitan area. Unlike static mapping tools or generic listing
platforms, RailEstate combines 25 years of historical housing data with transit
infrastructure to support low latency geospatial queries, time series
visualizations, and predictive modeling. Users can interactively explore ZIP
code level price patterns, investigate long term trends, and forecast future
housing values around any metro station. A key innovation is our natural
language chatbot, which translates plain-English questions e.g., What is the
highest price in Falls Church in the year 2000? into executable SQL over a
spatial database. This unified and interactive platform empowers urban
planners, investors, and residents to derive actionable insights from metro
linked housing data without requiring technical expertise.

</details>


### [95] [Forecasting Occupational Survivability of Rickshaw Pullers in a Changing Climate with Wearable Data](https://arxiv.org/abs/2511.00081)
*Masfiqur Rahaman,Maoyejatun Hasana,Shahad Shahriar Rahman,MD Sajid Mostafiz Noor,Razin Reaz Abedin,Md Toki Tahmid,Duncan Watson Parris,Tanzeem Choudhury,A. B. M. Alim Al Islam,Tauhidur Rahman*

Main category: cs.CY

TL;DR: 研究使用可穿戴传感器收集孟加拉国达卡100名三轮车夫在极端高温下的生理数据，开发线性高斯贝叶斯网络模型预测生理指标，并结合气候模型预测未来热暴露风险。


<details>
  <summary>Details</summary>
Motivation: 三轮车夫在极端高温下高度脆弱，但对其生理生物标志物如何响应此类条件知之甚少，需要了解他们的热暴露风险和未来生存能力。

Method: 使用可穿戴传感器收集实时天气和生理数据，对100名三轮车夫进行监测，访谈12名车夫了解其认知和经验，开发线性高斯贝叶斯网络回归模型预测生理指标，并应用18个CMIP6气候模型进行未来预测。

Result: 模型对皮肤温度、相对心脏成本、皮肤电导反应和皮肤电导水平的标准化平均绝对误差分别为0.82、0.47、0.65和0.67。目前32%的车夫面临高热暴露风险，到2026-2030年可能升至37%，平均暴露时间近12分钟（约占行程的三分之二）。

Conclusion: 三轮车夫已面临显著热暴露风险，且未来风险将进一步增加。访谈分析表明车夫认识到自身气候脆弱性增加，并担忧对健康和职业生存能力的影响。

Abstract: Cycle rickshaw pullers are highly vulnerable to extreme heat, yet little is
known about how their physiological biomarkers respond under such conditions.
This study collected real-time weather and physiological data using wearable
sensors from 100 rickshaw pullers in Dhaka, Bangladesh. In addition, interviews
with 12 pullers explored their knowledge, perceptions, and experiences related
to climate change. We developed a Linear Gaussian Bayesian Network (LGBN)
regression model to predict key physiological biomarkers based on activity,
weather, and demographic features. The model achieved normalized mean absolute
error values of 0.82, 0.47, 0.65, and 0.67 for skin temperature, relative
cardiac cost, skin conductance response, and skin conductance level,
respectively. Using projections from 18 CMIP6 climate models, we layered the
LGBN on future climate forecasts to analyze survivability for current
(2023-2025) and future years (2026-2100). Based on thresholds of WBGT above
31.1{\deg}C and skin temperature above 35{\deg}C, 32% of rickshaw pullers
already face high heat exposure risk. By 2026-2030, this percentage may rise to
37% with average exposure lasting nearly 12 minutes, or about two-thirds of the
trip duration. A thematic analysis of interviews complements these findings,
showing that rickshaw pullers recognize their increasing climate vulnerability
and express concern about its effects on health and occupational survivability.

</details>


### [96] [Artificial Intelligence in Elementary STEM Education: A Systematic Review of Current Applications and Future Challenges](https://arxiv.org/abs/2511.00105)
*Majid Memari,Krista Ruggles*

Main category: cs.CY

TL;DR: 这篇系统综述分析了2020-2025年间258项关于AI在小学STEM教育中应用的研究，发现研究主要集中在智能辅导系统、学习分析和自动评估等领域，但存在生态系统碎片化、发展不适宜性、基础设施障碍等八大局限。


<details>
  <summary>Details</summary>
Motivation: AI正在变革小学STEM教育，但现有证据零散，需要系统梳理AI应用现状、效果和局限，为未来研究提供方向。

Method: 采用系统综述方法，分析258项研究（2020-2025年），涵盖智能辅导系统、学习分析、自动评估、计算机视觉、教育机器人、多模态传感、AI增强扩展现实和自适应内容生成等八个类别。

Result: 研究发现大多数研究关注高年级小学（65%）和数学学科（38%），跨学科STEM整合有限（15%）。对话AI显示出中等效果（d = 0.45-0.70），但只有34%的研究包含标准化效应值。存在八大局限影响实际应用效果。

Conclusion: 未来需要开发支持真实STEM整合的互操作架构、适合年级的设计、保护隐私的分析方法，以及以教师为中心的实施策略，增强而非取代人类专业知识。

Abstract: Artificial intelligence (AI) is transforming elementary STEM education, yet
evidence remains fragmented. This systematic review synthesizes 258 studies
(2020-2025) examining AI applications across eight categories: intelligent
tutoring systems (45% of studies), learning analytics (18%), automated
assessment (12%), computer vision (8%), educational robotics (7%), multimodal
sensing (6%), AI-enhanced extended reality (XR) (4%), and adaptive content
generation. The analysis shows that most studies focus on upper elementary
grades (65%) and mathematics (38%), with limited cross-disciplinary STEM
integration (15%). While conversational AI demonstrates moderate effectiveness
(d = 0.45-0.70 where reported), only 34% of studies include standardized effect
sizes. Eight major gaps limit real-world impact: fragmented ecosystems,
developmental inappropriateness, infrastructure barriers, lack of privacy
frameworks, weak STEM integration, equity disparities, teacher marginalization,
and narrow assessment scopes. Geographic distribution is also uneven, with 90%
of studies originating from North America, East Asia, and Europe. Future
directions call for interoperable architectures that support authentic STEM
integration, grade-appropriate design, privacy-preserving analytics, and
teacher-centered implementations that enhance rather than replace human
expertise.

</details>


### [97] [Wayfinding through the AI wilderness: Mapping rhetorics of ChatGPT prompt writing on X (formerly Twitter) to promote critical AI literacies](https://arxiv.org/abs/2511.00106)
*Anuj Gupta,Ann Shivers-McNair*

Main category: cs.CY

TL;DR: 该论文通过分析社交媒体上ChatGPT提示写作的修辞实践，探讨如何促进批判性AI素养。研究收集了32,000条关于提示写作的推文，识别出五个关键主题，为数字写作教学和研究提供见解。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI工具的普及，社交媒体上关于提示写作的讨论激增。研究者希望通过分析这些修辞实践，理解新兴的AI素养，并为数字写作教育提供指导。

Method: 基于数字写作研究的四个传统框架，采用迭代研究方法，收集并分析了2022年11月至2023年5月期间32,000条关于提示写作的推文，结合计算方法和定性方法。

Result: 识别出五个关键主题：提示写作影响的沟通领域、共享的微观素养资源、塑造提示写作的市场修辞、提示的修辞特征，以及提示写作的定义。

Conclusion: 研究展示了如何通过分析社交媒体上的提示写作修辞来促进批判性AI素养，为数字写作教师和研究者提供了重要的教学和分析启示。

Abstract: In this paper, we demonstrate how studying the rhetorics of ChatGPT prompt
writing on social media can promote critical AI literacies. Prompt writing is
the process of writing instructions for generative AI tools like ChatGPT to
elicit desired outputs and there has been an upsurge of conversations about it
on social media. To study this rhetorical activity, we build on four
overlapping traditions of digital writing research in computers and composition
that inform how we frame literacies, how we study social media rhetorics, how
we engage iteratively and reflexively with methodologies and technologies, and
how we blend computational methods with qualitative methods. Drawing on these
four traditions, our paper shows our iterative research process through which
we gathered and analyzed a dataset of 32,000 posts (formerly known as tweets)
from X (formerly Twitter) about prompt writing posted between November 2022 to
May 2023. We present five themes about these emerging AI literacy practices:
(1) areas of communication impacted by prompt writing, (2) micro-literacy
resources shared for prompt writing, (3) market rhetoric shaping prompt
writing, (4) rhetorical characteristics of prompts, and (5) definitions of
prompt writing. In discussing these themes and our methodologies, we highlight
takeaways for digital writing teachers and researchers who are teaching and
analyzing critical AI literacies.

</details>


### [98] [Evaluation of compliance with democratic and technical standards of i-voting in elections to academic senates in Czech higher education](https://arxiv.org/abs/2511.01598)
*Tomas Martinek,Michal Maly*

Main category: cs.CY

TL;DR: 该研究评估了捷克公立大学在学术评议会选举中使用的i-voting系统，发现大多数系统缺乏透明度，存在民主和技术挑战。


<details>
  <summary>Details</summary>
Motivation: 随着远程工作和数字通信的增加，i-voting系统在学术机构中广泛采用，但缺乏透明度引发了对其民主规范遵守情况的担忧。

Method: 通过对系统开发者和管理员进行访谈，以及对潜在选民进行调查来评估i-voting系统。

Result: 26所捷克公立大学中有18所实施了远程电子投票，但这些系统往往缺乏透明度，在选举安全、选民隐私和过程完整性方面存在问题。

Conclusion: 缺乏透明度使得无法全面评估i-voting系统的技术标准和整体合法性，可能损害选举结果的可信度。

Abstract: The shift towards increased remote work and digital communication, driven by
recent global developments, has led to the widespread adoption of i-voting
systems, including in academic institutions. This paper critically evaluates
the use of i-voting platforms for elections to academic senates at Czech public
universities, focusing on the democratic and technical challenges they present.
A total of 18 out of 26 Czech public universities have implemented remote
electronic voting for these elections. Yet, the systems often lack the
necessary transparency, raising significant concerns regarding their adherence
to democratic norms, such as election security, voter privacy, and the
integrity of the process. Through interviews with system developers and
administrators, along with a survey of potential voters, the study underscores
the critical need for transparency. Without it, a comprehensive assessment of
the technical standards and the overall legitimacy of the i-voting systems
remains unattainable, potentially undermining the credibility of the electoral
outcomes.

</details>


### [99] [Breyer case of the Court of Justice of the European Union: IP addresses and the personal data definition](https://arxiv.org/abs/2511.01751)
*Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 欧盟法院Breyer案裁定：当网站发布者能够通过法律手段从访问者的互联网接入提供商处获取额外信息来识别访问者时，动态IP地址构成个人数据。


<details>
  <summary>Details</summary>
Motivation: 解决动态IP地址是否构成个人数据的问题，特别是当网站发布者本身无法直接识别访问者，但可通过第三方（互联网接入提供商）获取识别信息的情况。

Method: 通过分析欧盟法院的Breyer案例，总结案件事实和判决内容，并进行评论分析。

Result: 法院认定动态IP地址构成个人数据，因为网站发布者具备法律手段从互联网接入提供商处获取识别信息。

Conclusion: 该判决确立了在特定条件下，即使网站发布者不能直接识别个人，动态IP地址仍可能被视为个人数据的重要法律原则。

Abstract: The Breyer case of the Court of Justice of the European Union (CJEU)
primarily concerns the question whether a website visitor's dynamic IP address
constitutes personal data for a website publisher, when another party (an
internet access provider) can tie a name to that IP address. In essence, the
Court finds that an IP address constitutes personal data for the website
publisher, if that publisher has the legal means to obtain, from the visitor's
internet access provider, additional information that enables the publisher to
identify that visitor. In this case note, I summarise the facts and the
judgment, and add a few comments.

</details>


### [100] [An assessment of the Commission's Proposal on Privacy and Electronic Communications](https://arxiv.org/abs/2511.01752)
*Frederik Zuiderveen Borgesius,Joris van Hoboken,Ronan Fahy,Kristina Irion,Max Rozendaal*

Main category: cs.CY

TL;DR: 对欧盟委员会ePrivacy条例提案的评估研究，分析其对个人数据保护、隐私权和通信权等权利的保护水平


<details>
  <summary>Details</summary>
Motivation: 应欧洲议会LIBE委员会要求，评估ePrivacy条例提案是否能确保个人数据保护权、隐私权和通信权等获得高标准保护

Method: 对欧盟委员会的ePrivacy条例提案进行系统性评估和分析

Result: 识别了提案的潜在益处和缺陷，评估了其对相关权利的保护标准

Conclusion: 该研究为欧洲议会提供了关于ePrivacy条例提案的全面评估，指出了其优缺点

Abstract: This study, commissioned by the European Parliament's Policy Department for
Citizens Rights and Constitutional Affairs at the request of the LIBE
Committee, appraises the European Commission's proposal for an ePrivacy
Regulation. The study assesses whether the proposal would ensure that the right
to the protection of personal data, the right to respect for private life and
communications, and related rights enjoy a high standard of protection. The
study also highlights the proposal's potential benefits and drawbacks more
generally.

</details>


### [101] [A Detailed Study on LLM Biases Concerning Corporate Social Responsibility and Green Supply Chains](https://arxiv.org/abs/2511.01840)
*Greta Ontrup,Annika Bush,Markus Pauly,Meltem Aksoy*

Main category: cs.CY

TL;DR: 该研究分析了不同LLMs在可持续商业实践调查中的偏见，发现模型间存在系统性差异，且组织文化提示会显著影响LLM响应。


<details>
  <summary>Details</summary>
Motivation: 随着组织越来越多地使用LLMs改进供应链流程和减少环境影响，但LLMs在可持续商业战略优先级的偏见问题需要被识别和解决。

Method: 使用经过验证的关于企业伦理责任和可持续实践的调查问卷，系统分析最先进LLMs的响应差异，并评估四种组织文化类型对差异的影响。

Result: 研究发现不同模型之间存在显著的系统性差异，组织文化提示会显著改变LLM的响应模式。

Conclusion: 该研究对LLM在可持续性决策辅助方面具有重要启示，强调了识别和解决训练数据偏见的重要性。

Abstract: Organizations increasingly use Large Language Models (LLMs) to improve supply
chain processes and reduce environmental impacts. However, LLMs have been shown
to reproduce biases regarding the prioritization of sustainable business
strategies. Thus, it is important to identify underlying training data biases
that LLMs pertain regarding the importance and role of sustainable business and
supply chain practices. This study investigates how different LLMs respond to
validated surveys about the role of ethics and responsibility for businesses,
and the importance of sustainable practices and relations with suppliers and
customers. Using standardized questionnaires, we systematically analyze
responses generated by state-of-the-art LLMs to identify variations. We further
evaluate whether differences are augmented by four organizational culture
types, thereby evaluating the practical relevance of identified biases. The
findings reveal significant systematic differences between models and
demonstrate that organizational culture prompts substantially modify LLM
responses. The study holds important implications for LLM-assisted
decision-making in sustainability contexts.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [102] [Closing the SNAP Gap: Identifying Under-Enrollment in High-Poverty ZIP Codes](https://arxiv.org/abs/2511.00080)
*Auyona Ray*

Main category: econ.GN

TL;DR: 构建经济不安全指数，发现贫困单独预测SNAP参与度比复合指数更准确但解释力有限，转而识别高贫困但SNAP参与度低的地区（SNAP缺口），使用车辆和教育两个预测因子构建逻辑分类模型，发现农村地区经济不安全集中且交通是主要障碍。


<details>
  <summary>Details</summary>
Motivation: 传统上认为收入是SNAP参与度的主要决定因素，但研究发现仅靠收入无法完全解释参与率，需要识别其他结构性障碍，特别是在高贫困但低参与度的地区。

Method: 使用2014-2023年全国ZIP级别数据，构建逻辑分类模型，分析四个结构性指标：缺乏车辆、缺乏互联网接入、缺乏电脑接入、仅高中文凭成人比例。

Result: 仅使用车辆接入和教育两个预测因子的模型效果最佳，在精确度和校准度上都优于基于树的分类器，发现经济不安全集中在农村地区，交通是阻碍项目参与的最稳定障碍。

Conclusion: 研究提供了一个全国性诊断框架，可为开发可扩展的筛查工具提供信息，以针对服务不足社区进行外展和改善福利获取。

Abstract: This project began by constructing an index of economic insecurity using
multiple socioeconomic indicators. Although poverty alone predicted SNAP
participation more accurately than the composite index, its explanatory power
was weaker than anticipated, echoing past findings that enrollment cannot be
explained by income alone. This led to a shift in focus: identifying ZIP codes
with high poverty but unexpectedly low SNAP participation, areas defined here
as having a SNAP Gap, where ZIPs fall in the top 30 percent of family poverty
and the bottom 10 percent of SNAP enrollment. Using nationally available ZIP
level data from 2014 to 2023, I trained logistic classification models on four
interpretable structural indicators: lack of vehicle, lack of internet access,
lack of computer access, and percentage of adults with only a high school
diploma. The most effective model relies on just two predictors, vehicle access
and education, and outperforms tree based classifiers in both precision and
calibration. Results show that economic insecurity is consistently concentrated
in rural ZIP codes, with transportation access emerging as the most stable
barrier to program take up. This study provides a nationwide diagnostic
framework that can inform the development of scalable screening tools for
targeting outreach and improving benefit access in underserved communities.

</details>


### [103] [Different Forms of Imbalance in Strongly Playable Discrete Games I: Two-Player RPS Games](https://arxiv.org/abs/2511.00374)
*Itai Maimon*

Main category: econ.GN

TL;DR: 本文构建了博弈中不平衡性和可玩性的定义，证明(2n+1)-RPS在可玩RPS游戏中最大化所有不平衡性定义，并展示不平衡性概念与经济学中不平等度量的一致性。


<details>
  <summary>Details</summary>
Motivation: 研究博弈中的不平衡性和可玩性，这些概念与支配策略的存在相关，旨在建立与经济学中不平等度量类似的分析框架。

Method: 构建不平衡性和可玩性的定义，通过(2n+1)-RPS案例展示这些定义的自然性，并验证不同不平等定义在极值情况下的一致性。

Result: (2n+1)-RPS在所有可玩RPS游戏中最大化不平衡性定义，且不平衡性概念与经济不平等度量在极值情况下保持一致。

Conclusion: 提出的不平衡性和可玩性定义是自然的，为后续研究多人博弈中的不平衡性提供了理论基础，并证明广义化的不平衡RPS在50人以下仍保持近最大不平衡性且可玩。

Abstract: We construct several definitions of imbalance and playability, both of which
are related to the existence of dominated strategies. Specifically, a maximally
balanced game and a playable game cannot have dominated strategies for any
player. In this context, imbalance acts as a measure of inequality in strategy,
similar to measures of inequality in wealth or population dynamics. Conversely,
playability is a slight strengthening of the condition that a game has no
dominated strategies. It is more accurately aligned with the intuition that all
strategies should see play. We show that these balance definitions are natural
by exhibiting a (2n+1)-RPS that maximizes all proposed imbalance definitions
among playable RPS games. We demonstrate here that this form of imbalance
aligns with the prevailing notion that different definitions of inequality for
economic and game-theoretic distributions must agree on both the maximal and
minimal cases. In the sequel paper, we utilize these definitions for
multiplayer games to demonstrate that a generalization of this imbalanced RPS
is at least nearly maximally imbalanced while remaining playable for under 50
players.

</details>


### [104] [Modeling Uncertainty in Integrated Assessment Models](https://arxiv.org/abs/2511.00378)
*Yongyang Cai*

Main category: econ.GN

TL;DR: 这篇综述论文全面回顾了综合评估模型(IAMs)如何处理不确定性，重点关注方法论进展及其对气候政策的影响。


<details>
  <summary>Details</summary>
Motivation: 由于气候系统和社会经济过程的复杂性及固有不确定性，理解和有效管理IAMs中的不确定性对于制定稳健的气候政策至关重要。

Method: 审查IAMs中存在的不确定性类型，讨论处理这些不确定性的各种建模方法，并探索该领域的最新发展，包括先进计算方法的整合。

Result: 提供了IAMs处理不确定性的全面概述，突出了方法论进展及其政策含义。

Conclusion: 有效管理IAMs中的不确定性对于制定稳健的气候政策至关重要，先进计算方法的应用为改进不确定性处理提供了新的可能性。

Abstract: Integrated Assessment Models (IAMs) are pivotal tools that synthesize
knowledge from climate science, economics, and policy to evaluate the
interactions between human activities and the climate system. They serve as
essential instruments for policymakers, providing insights into the potential
outcomes of various climate policies and strategies. Given the complexity and
inherent uncertainties in both the climate system and socio-economic processes,
understanding and effectively managing uncertainty within IAMs is crucial for
robust climate policy development. This review aims to provide a comprehensive
overview of how IAMs handle uncertainty, highlighting recent methodological
advancements and their implications for climate policy. I examine the types of
uncertainties present in IAMs, discuss various modeling approaches to address
these uncertainties, and explore recent developments in the field, including
the incorporation of advanced computational methods.

</details>


### [105] [A rich life cycle model of labor supply in Finland](https://arxiv.org/abs/2511.00660)
*Antti J. Tanskanen*

Main category: econ.GN

TL;DR: 开发了一个芬兰劳动力市场的生命周期模型，模拟个体在不同就业状态下的决策，并应用于分析政府改革对就业和公共财政的影响。


<details>
  <summary>Details</summary>
Motivation: 构建一个能够描述芬兰异质人口在各种就业状态和生活情境下决策的生命周期模型，以更好地理解劳动力市场动态。

Method: 使用生命周期模型，建立包含大量状态空间的模拟系统，代表模拟代理人的可能状态，应用于芬兰就业市场分析。

Result: 模型成功复现了芬兰就业市场的多项统计数据，包括就业率和失业率的年龄结构、有效边际税率分布、参与税率分布以及兼职工作比例。

Conclusion: 该生命周期模型能够有效模拟芬兰劳动力市场，并可用于分析政府政策改革对就业和公共财政的影响。

Abstract: A life cycle model of consumption and labor supply describes employment
decisions of a collection of individuals during their lifetime. We develop a
life cycle model describing a heterogeneous population operating in Finland
under a wide variety of employment states and life situations. A rich life
cycle model requires a large state space representing the possible states of
simulated agents. The results demonstrate that the model reproduces a number of
statistics of the Finnish employment market such as the age structures of
employment rate and unemployment rate, distributions of observed effective
marginal tax rates and participating tax rates, and proportion of part time
work. As an application of analysis of a reform, we analyze how the program of
Orpo government influences employment and public finances in Finland.

</details>


### [106] [Public Infrastructure Investments for Space Market Development](https://arxiv.org/abs/2511.00935)
*Akhil Rao*

Main category: econ.GN

TL;DR: 提出了一个图形化框架来分析太空技术市场的可持续竞争规模，基于成本结构、政府支持方式和需求分布，发现共享基础设施投资比直接采购或补贴更能有效支持市场竞争。


<details>
  <summary>Details</summary>
Motivation: 太空技术系统面临高固定成本、有限非政府需求和强烈的非市场动机，公共机构在开发市场时面临挑战，需要更好的分析工具来指导投资决策。

Method: 基于公共物品理论构建图形化框架，分析成本结构、政府支持（直接采购、直接投资、共享基础设施）和非政府需求对市场竞争规模的影响，并通过NASA商业LEO目的地项目的案例进行验证。

Result: 在符合公开数据的成本和需求条件下，独立空间站每年产生3.55亿美元行业损失，而共享核心基础设施每年可实现1.54亿美元行业利润。

Conclusion: 共享基础设施投资比传统支持方式更有效，边际美元投资于共享基础设施能创造非竞争性收益，每美元支持更多竞争者，为先进技术的公共投资和市场开发策略提供了重要洞见。

Abstract: Advanced space technology systems often face high fixed costs, can serve
limited non-government demand, and are significantly driven by non-market
motivations. While increased entrepreneurial activity and national ambitions in
space have encouraged planners at public space agencies to develop markets
around such systems, the very factors that make the recent growth of the space
economy so remarkable also challenge planners' efforts to develop and sustain
markets for space-related goods and services. I propose a graphical framework
to visualize the number of competitors a market can sustain as a function of
the industry's cost structure; the distribution of government support across
direct purchases, direct investments, and shared infrastructure; and the
magnitude of non-government demand. Building on public goods theory, the
framework shows how marginal dollars invested in shared infrastructure can
create non-rival benefits supporting more competitors per dollar than direct
purchases or subsidies. I demonstrate the framework with a stylized application
inspired by NASA's Commercial LEO Destinations program. Under cost and demand
conditions consistent with public data, independent stations generate
industry-wide losses of $355 million annually, while shared core infrastructure
enables industry-wide profits of $154 million annually. I also outline key
directions for future research on public investment and market development
strategies for advanced technologies.

</details>


### [107] [Liquidity Shocks, Homeownership, and Income Inequality: Impact of Early Pension Withdrawals and Reduced Deposit](https://arxiv.org/abs/2511.01133)
*Hamza Hanbali,Gaurav Khemka,Himasha Warnakulasooriya*

Main category: econ.GN

TL;DR: 分析两种影响住房需求的政府政策：养老金提前支取(EW)和降低贷款首付(RD)。使用澳大利亚数据的模型显示两种政策短期内都会推高房价。RD会延迟或阻止低收入家庭购房，特别是在供应受限的市场。EW改善各群体购房能力，完全支取时最有效，但如果养老金增长快于房价则可能降低退休保障。


<details>
  <summary>Details</summary>
Motivation: 研究政府政策如何影响住房需求，特别是分析养老金提前支取和降低贷款首付这两种政策对住房市场的影响，重点关注它们对不同收入群体的可及性影响。

Method: 建立包含住房价格需求反馈的模型，使用澳大利亚数据进行实证分析，评估两种政策对房价和住房可及性的影响。

Result: 两种政策短期内都会推高房价；RD政策会延迟低收入家庭购房，在供应受限市场影响更严重；EW政策改善各群体购房能力，完全支取时效率最高；不平等结果源于既有市场差异而非价格飙升本身。

Conclusion: 政策设计需考虑对住房可及性的影响，EW政策在改善可及性方面更有效，但需平衡退休保障风险；市场既有的不平等是政策影响差异的根本原因。

Abstract: The paper analyzes two government policies affecting housing demand: early
withdrawal from pension savings (EW), and reduction of loan deposit (RD). A
model incorporating demand feedback on housing prices using Australian data
shows both policies raise prices in the short run. RD delays or prevents access
for low-income households, particularly in supply-constrained markets. EW
improves accessibility across groups and is most efficient when full withdrawal
is permitted, but can reduce retirement security if pension grows faster than
property prices. The results also indicate that unequal outcomes stem not from
price surges themselves but from pre-existing market disparities.

</details>


### [108] [Novelty and Impact of Economics Papers](https://arxiv.org/abs/2511.01211)
*Chaofeng Wu*

Main category: econ.GN

TL;DR: 该研究提出将科学新颖性分解为空间新颖性和时间新颖性两个维度，通过大语言模型量化论文在文献中的位置，发现这两个维度预测不同的学术影响力。


<details>
  <summary>Details</summary>
Motivation: 传统上科学新颖性被视为单一属性，但作者认为它应反映论文在知识演化过程中的位置，需要更精细的维度划分。

Method: 利用大语言模型开发语义隔离指标，量化论文相对于全文文献的位置，应用于经济学文献语料库进行分析。

Result: 发现空间新颖性主要预测颠覆性影响力，时间新颖性主要预测引用次数，并识别出四种具有不同影响力特征的原型语义邻域。

Conclusion: 新颖性是多维构念，其不同形式反映了论文的战略定位，对科学进步产生可测量且根本不同的影响。

Abstract: We propose a framework that recasts scientific novelty not as a single
attribute of a paper, but as a reflection of its position within the evolving
intellectual landscape. We decompose this position into two orthogonal
dimensions: \textit{spatial novelty}, which measures a paper's intellectual
distinctiveness from its neighbors, and \textit{temporal novelty}, which
captures its engagement with a dynamic research frontier. To operationalize
these concepts, we leverage Large Language Models to develop semantic isolation
metrics that quantify a paper's location relative to the full-text literature.
Applying this framework to a large corpus of economics articles, we uncover a
fundamental trade-off: these two dimensions predict systematically different
outcomes. Temporal novelty primarily predicts citation counts, whereas spatial
novelty predicts disruptive impact. This distinction allows us to construct a
typology of semantic neighborhoods, identifying four archetypes associated with
distinct and predictable impact profiles. Our findings demonstrate that novelty
can be understood as a multidimensional construct whose different forms,
reflecting a paper's strategic location, have measurable and fundamentally
distinct consequences for scientific progress.

</details>


### [109] [Internet of Things Platform Service Supply Innovation: Exploring the Impact of Overconfidence](https://arxiv.org/abs/2511.01332)
*Xiufeng Li,Zefang Li*

Main category: econ.GN

TL;DR: 研究制造商过度自信对物联网环境下与平台协同创新的影响，通过博弈模型发现在两种合同类型中，适度过度自信能激励硬件创新并可能实现供应链帕累托改进。


<details>
  <summary>Details</summary>
Motivation: 探索物联网环境中制造商过度自信如何影响其与平台的协同创新关系，为理解复杂供应链互动提供新视角。

Method: 构建博弈模型，分析使用量合同和收入分成合同两种情境下制造商和平台的决策行为。

Result: 在两种合同中，非隐私敏感客户比例显著影响创新投入和利润；适度过度自信能激励硬件创新投资，但可能降低平台软件创新；收入分成合同下过度自信对硬件创新和定价的激励更强。

Conclusion: 适度过度自信在特定合同条件下可带来供应链帕累托改进，为实际商业决策提供理论支持和实践指导。

Abstract: This paper explores the impact of manufacturers' overconfidence on their
collaborative innovation with platforms in the Internet of Things (IoT)
environment by constructing a game model. It is found that in both usage-based
and revenue-sharing contracts, manufacturers' and platforms' innovation inputs,
profit levels, and pricing strategies are significantly affected by the
proportion of non-privacy-sensitive customers, and grow in tandem with the rise
of this proportion. In usage-based contracts, moderate overconfidence
incentivizes manufacturers to increase hardware innovation investment and
improve overall supply chain revenues, but may cause platforms to reduce
software innovation; under revenue-sharing contracts, overconfidence positively
incentivizes hardware innovation and pricing more strongly, while platform
software innovation varies nonlinearly depending on the share ratio. Comparing
the differences in manufacturers' decisions with and without overconfidence
suggests that moderate overconfidence can lead to supply chain Pareto
improvements under a given contract. This paper provides new perspectives for
understanding the complex interactions between manufacturers and platforms in
IoT supply chains, as well as theoretical support and practical guidance for
actual business decisions.

</details>


### [110] [Measuring Domestic Violence. Individual Attitudes and Time Use Within the Household](https://arxiv.org/abs/2511.01473)
*Elena Pisanelli*

Main category: econ.GN

TL;DR: 本文提出了一种测量家庭暴力文化辩护的新方法，结合态度调查和时间使用数据构建综合指数，揭示了容忍度与性别、教育、规范环境的关系。


<details>
  <summary>Details</summary>
Motivation: 测量家庭暴力的文化辩护对理解人口行为和性别不平等有重要意义，现有方法难以捕捉隐藏的不平等现象。

Method: 使用意大利有子女夫妇的调查数据和时间使用日记，构建综合指数，采用结构方程模型分离潜在容忍度，并通过个人特征和时间分配模式验证。

Result: 发现容忍度存在性别、教育和规范环境的系统性差异，保守性别和育儿规范是强预测因子，男性教育程度高则容忍度低。容忍度与伴侣和子女的休闲时间正相关。

Conclusion: 文化容忍度嵌入家庭安排中，影响生育、劳动供给和规范代际传递。该框架为监测隐藏不平等和设计干预措施提供了可扩展工具。

Abstract: This paper proposes a novel empirical strategy to measure cultural
justifications of domestic violence within households, with direct implications
for demographic behavior and gender inequality. Leveraging survey data on
individual attitudes and high-frequency time-use diaries from Italian couples
with children, I construct a composite index that integrates stated beliefs
with observed household practices. Using structural equation modeling, I
disentangle latent tolerance of domestic violence from reported attitudes and
validate the index against both individual and partner characteristics, as well
as time allocation patterns. Results reveal systematic heterogeneity by gender,
education, and normative environments. Conservative gender and parenthood norms
are strong predictors of tolerance, while higher male education reduces it.
Tolerance of violence is also positively associated with reported leisure time
with partners and children, suggesting that co-presence does not necessarily
reflect egalitarian interaction but may coexist with unequal bargaining
structures. Beyond advancing measurement, the findings highlight how cultural
tolerance of domestic violence is embedded in household arrangements that
influence fertility, labor supply, and the intergenerational transmission of
norms. The proposed framework offers a scalable tool for economists and
policymakers to monitor hidden inequalities and design interventions targeting
family stability, gender equity, and child well-being.

</details>


### [111] [Gendered Responses to Subtle Social Pressure: Experimental Evidence from Survey Results](https://arxiv.org/abs/2511.01565)
*Sevgi Çolak*

Main category: econ.GN

TL;DR: 该研究检验了调查问卷措辞的微妙变化是否影响参与者参与度，以及这些效应是否因性别而异。研究发现没有显著的措辞处理效应，也没有性别调节作用的证据。


<details>
  <summary>Details</summary>
Motivation: 基于社会压力和礼貌规范理论，研究假设预设性措辞相比赞赏性措辞和基线措辞会降低参与度，且这种效应对女性更明显。

Method: 使用混合效应回归模型分析164名参与者的492个观察数据。

Result: 结果显示没有任何结果变量存在显著的处理效应，也没有性别调节作用的证据。唯一稳健的发现是所有参与者都存在轻微的负面基线情绪，与处理和性别无关。

Conclusion: 研究结果有助于完善关于语言框架和性别规范在何种条件下影响行为的理论预期。

Abstract: This study analyzes whether subtle variations in the survey questionnaire
phrasing influence participant engagement and whether these effects differ by
gender. Building on theories of social pressure and politeness norms, it is
hypothesized that presumptive phrasing would reduce engagement compared to
appreciative phrasing and baseline phrasing (H1), and this effect would be more
pronounced among women (H2). Mixed-effects regression models showed no
significant treatment effects on any outcome and no evidence of gender
moderation for 164 participants and 492 observations. The only robust finding
was a small negative baseline sentiment across all participants, independent of
any treatment or gender. The findings contribute to refining theoretical
expectations about the conditions in which linguistic framing and gender norms
shape behaviour.

</details>


### [112] [Deceptively Framed Lotteries in Consumer Markets](https://arxiv.org/abs/2511.01597)
*Markus Dertwinkel-Kalt,Hans-Theo Normann,Jan-Niklas Tiede,Tobias Werner*

Main category: econ.GN

TL;DR: 论文研究产品以抽奖形式销售时，不同呈现方式如何影响消费者信念和支付意愿。实验发现80%以上的卖家采用欺骗性框架（如隐藏概率、突出稀有成功），这显著提高了买家信念和支付意愿（可达期望价值的6倍）。


<details>
  <summary>Details</summary>
Motivation: 研究消费者在面对抽奖形式产品（如游戏中的抽奖箱）时，销售呈现方式如何塑造消费者信念和支付意愿，揭示欺骗性框架对消费者决策的影响。

Method: 通过在线实验（802名参与者），让卖家可以选择两种常见的操纵方式：隐藏结果概率和选择性突出稀有成功，观察这些框架选择对买家信念和支付意愿的影响。

Result: 超过80%的卖家采用欺骗性框架，特别是当两种操纵方式都可用时。这些选择显著提高了买家信念，支付意愿可达期望价值的6倍。卖家预见到这种效应并相应提高价格。

Conclusion: 欺骗性框架系统性改变消费者信念，使企业能够获取额外剩余价值。对营销实践强调框架工具在概率销售模型中的战略价值，对政策强调透明度要求在保护消费者方面的重要性。

Abstract: Consumers often face products sold as lotteries rather than fixed outcomes. A
prominent case is the loot box in video games, where players pay for randomized
rewards. We investigate how presentation formats shape consumer beliefs and
willingness to pay. In an online experiment with 802 participants, sellers
could frame lotteries using two common manipulations: censoring outcome
probabilities and selectively highlighting rare successes. More than 80\% of
sellers adopted such deceptive frames, particularly when both manipulations
were available. These choices substantially inflated buyer beliefs and
increased willingness to pay of up to six times the expected value. Sellers
anticipated this effect and raised prices accordingly. Our results show how
deceptive framing systematically shifts consumer beliefs and enables firms to
extract additional surplus. For marketing practice, this highlights the
strategic value of framing tools in probabilistic selling models; for policy,
it underscores the importance of transparency requirements in protecting
consumers.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [113] [Which Top Energy-Intensive Manufacturing Countries Can Compete in a Renewable Energy Future?](https://arxiv.org/abs/2511.00242)
*Arne Burdack,Maximilian Stargardt,Christoph Winkler,Konrad Klein,Detlef Stolten,Jochen Linssen,Heidi Heinrichs*

Main category: eess.SY

TL;DR: 研究通过能源系统建模量化了可再生能源条件优越国家产生的"可再生能源拉力"对产业迁移的影响，发现该效应因行业而异，中国、印度和日本受影响最大，而德国和美国相对较小。资本成本假设对结果影响显著，德国通过欧盟内针对性进口策略可几乎消除这种拉力。


<details>
  <summary>Details</summary>
Motivation: 在可再生能源日益普及和温室气体中和工业生产的背景下，研究当前主要制造业国家未来竞争力如何受到可再生能源条件差异的影响。

Method: 采用详细的能源系统建模方法，量化分析不同国家可再生能源条件对产业迁移的激励效应（即"可再生能源拉力"）。

Result: 可再生能源拉力不是跨行业现象，而是取决于能源成本与运输成本的关系。中国、印度和日本面临的影响显著强于德国和美国。考虑国家资本成本假设后，德国的可再生能源拉力减少了六倍，成为仅次于沙特阿拉伯受影响最小的制造业大国。

Conclusion: 通过针对性进口策略（特别是在欧盟内部），可以几乎消除可再生能源拉力，为政策制定者提供了明确的风险缓解方案。

Abstract: In a world increasingly powered by renewables and aiming for greenhouse
gas-neutral industrial production, the future competitiveness of todays top
manufacturing countries is questioned. This study applies detailed energy
system modeling to quantify the Renewable Pull, an incentive for industry
relocation exerted by countries with favorable renewable conditions. Results
reveal that the Renewable Pull is not a cross-industrial phenomenon but
strongly depends on the relationship between energy costs and transport costs.
The intensity of the Renewable Pull varies, with China, India, and Japan facing
a significantly stronger effect than Germany and the United States.
Incorporating national capital cost assumptions proves critical, reducing
Germanys Renewable Pull by a factor of six and positioning it as the second
least affected top manufacturing country after Saudi Arabia. Using Germany as a
case study, the analysis moreover illustrates that targeted import strategies,
especially within the EU, can nearly eliminate the Renewable Pull, offering
policymakers clear options for risk mitigation.

</details>


### [114] [Learning a Network Digital Twin as a Hybrid System](https://arxiv.org/abs/2511.00291)
*Christos Mavridis,Fernando S. Barbosa,Hamed Farhadi,Karl H. Johansson*

Main category: eess.SY

TL;DR: 提出了一种基于混合系统的网络数字孪生模型，通过退火优化学习算法识别和改进模型，用于模拟多小区动态无线网络的通信质量特性。


<details>
  <summary>Details</summary>
Motivation: 网络数字孪生是6G网络的关键技术，需要准确模拟物理通信网络行为，特别是多小区动态无线网络中移动用户的通信质量。

Method: 将NDT建模为混合系统，每个模式对应不同基站，子模式对应具有相似网络特性的工作区域，通过退火优化学习算法在线识别和改进模型。

Result: 在5G双小区测试平台上使用真实实验数据验证了该方法，展示了在内存、计算效率、数据消耗和网络变化适应能力方面的优势。

Conclusion: 提出的混合NDT方法能够有效模拟动态无线网络，为6G网络提供可靠的数字孪生解决方案。

Abstract: Network digital twin (NDT) models are virtual models that replicate the
behavior of physical communication networks and are considered a key technology
component to enable novel features and capabilities in future 6G networks. In
this work, we focus on NDTs that model the communication quality properties of
a multi-cell, dynamically changing wireless network over a workspace populated
with multiple moving users. We propose an NDT modeled as a hybrid system, where
each mode corresponds to a different base station and comprises sub-modes that
correspond to areas of the workspace with similar network characteristics. The
proposed hybrid NDT is identified and continuously improved through an
annealing optimization-based learning algorithm, driven by online data
measurements collected by the users. The advantages of the proposed hybrid NDT
are studied with respect to memory and computational efficiency, data
consumption, and the ability to timely adapt to network changes. Finally, we
validate the proposed methodology on real experimental data collected from a
two-cell 5G testbed.

</details>


### [115] [Analyzing the Impact of Demand Response on Short-Circuit Current via a Unit Commitment Model](https://arxiv.org/abs/2511.00296)
*Peng Wang,Zhengmao Li,Luis Badesa*

Main category: eess.SY

TL;DR: 在低碳电网中，需求响应(DR)能增强系统灵活性，但逆变器资源(IBR)取代同步发电机(SG)会影响系统稳定性。本文研究DR如何通过影响SG调度间接影响短路电流(SCC)供应，并将DR和SCC约束纳入机组组合模型。


<details>
  <summary>Details</summary>
Motivation: 随着IBR取代SG，系统短路电流水平下降可能导致保护装置无法正常动作。SG的调度与系统负荷相关，而DR会影响负荷，从而间接影响SCC供应，这种关系尚未被研究。

Method: 将DR和SCC约束纳入机组组合模型，并在IEEE 30节点系统上进行研究。

Result: DR虽能通过降低电力需求减少社会成本，但可能导致SCC水平不足。当DR与SCC约束结合时，成本仅增加0.3%，表明DR能以经济有效的方式帮助实现系统稳定。

Conclusion: DR不仅能降低社会成本，还能与SCC约束协同工作，以很小的额外成本实现系统稳定运行。

Abstract: In low-carbon grids, system flexibility can be enhanced through mechanisms
such as Demand Response (DR), enabling the efficient utilization of renewable
energy. However, as Synchronous Generators (SGs) are being replaced with
renewable energy characterized by Inverter-Based Resources (IBR), system
stability is severely affected. Due to the limited overload capability of IBR,
their Short-Circuit Current (SCC) contribution is much smaller than that of
SGs, which may result in protection devices failing to trip during faults.
Consequently, the remaining SGs play a key role in offering sufficient SCC
volumes. Given that the commitment of SGs is closely related to system load, DR
can thus indirectly affect their SCC provision, a relationship that has not
been investigated. Therefore, this paper incorporates both DR and SCC
constraints into a unit commitment model and conducts studies on an IEEE 30-bus
system. The results show that although DR can reduce social costs by lowering
power demand, it may also lead to inadequate SCC levels. Nevertheless, the cost
increases by only 0.3% when DR is combined with SCC constraints, indicating
that DR can actually help achieve a stable system in a cost-effective manner.

</details>


### [116] [Optimal BESS Sizing and Placement for Mitigating EV-Induced Voltage Violations: A Scalable Spatio-Temporal Adaptive Targeting Strategy](https://arxiv.org/abs/2511.00297)
*Linhan Fang,Xingpeng Li*

Main category: eess.SY

TL;DR: 提出一个主动电压管理框架，通过蒙特卡洛模拟识别电动汽车充电导致的电压违规，并使用电池储能系统进行优化缓解，采用时空自适应策略降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 电动汽车充电负荷激增导致配电网电压下降，特别是在馈线末端，需要有效的电压管理解决方案。

Method: 结合蒙特卡洛模拟的电压违规分析模型和最优扩展规划模型，提出时空自适应目标策略来降低计算复杂度。

Result: 在33、69和240节点系统验证有效，BESS的战略配置不仅能缓解电压违规，还能在分时电价下节省大量电费。

Conclusion: 为高渗透率电动汽车集成提供了经济高效且可扩展的解决方案，为未来配电网规划提供重要见解。

Abstract: The escalating adoption of electric vehicles (EVs) and the growing demand for
charging solutions are driving a surge in EV charger installations in
distribution networks. However, this rising EV load strains the distribution
grid, causing severe voltage drops, particularly at feeder extremities. This
study proposes a proactive voltage management (PVM) framework that can
integrate Monte Carlo-based simulations of varying EV charging loads to (i)
identify potential voltage violations through a voltage violation analysis
(VVA) model, and (ii) then mitigate those violations with optimally-invested
battery energy storage systems (BESS) through an optimal expansion planning
(OEP) model. A novel spatio-temporal adaptive targeting (STAT) strategy is
proposed to alleviate the computational complexity of the OEP model by defining
a targeted OEP (T-OEP) model, solved by applying the OEP model to (i) a reduced
set of representative critical time periods and (ii) candidate BESS
installation nodes. The efficacy and scalability of the proposed approach are
validated on 33-bus, 69-bus, and a large-scale 240-bus system. Results
demonstrate that the strategic sizing and placement of BESS not only
effectively mitigate voltage violations but also yield substantial cost savings
on electricity purchases under time-of-use tariffs. This research offers a
cost-effective and scalable solution for integrating high penetrations of EVs,
providing crucial insights for future distribution network planning.

</details>


### [117] [Large Language Models for Control](https://arxiv.org/abs/2511.00337)
*Adil Rasheed,Oscar Ravik,Omer San*

Main category: eess.SY

TL;DR: 使用大型语言模型直接生成控制动作，无需控制工程专业知识或手动调优算法。比较了三种变体：仅提示、工具辅助和历史数据访问、预测辅助使用学习或简单模型评分候选动作。


<details>
  <summary>Details</summary>
Motivation: 探索利用LLMs直接生成控制动作，避免传统控制方法需要专业知识和手动调优的局限性，实现更灵活的控制系统。

Method: 实现三种LLM控制变体：(i)仅提示，(ii)工具辅助访问历史数据，(iii)预测辅助使用学习或简单模型评分候选动作。比较跟踪精度和执行器努力，测试有无降低执行器使用提示的情况。

Result: 仅提示的LLMs已能产生可行的控制，而工具增强版本能更好地适应变化的目标但对约束更敏感。

Conclusion: 支持LLM在环控制用于不断发展的网络物理系统，以及操作员和人类输入。

Abstract: This paper investigates using large language models (LLMs) to generate
control actions directly, without requiring control-engineering expertise or
hand-tuned algorithms. We implement several variants: (i) prompt-only, (ii)
tool-assisted with access to historical data, and (iii) prediction-assisted
using learned or simple models to score candidate actions. We compare them on
tracking accuracy and actuation effort, with and without a prompt that requests
lower actuator usage. Results show prompt-only LLMs already produce viable
control, while tool-augmented versions adapt better to changing objectives but
can be more sensitive to constraints, supporting LLM-in-the-loop control for
evolving cyber-physical systems today and operator and human inputs.

</details>


### [118] [Constrained computational hybrid controller for Input Affine Hybrid Dynamical Systems](https://arxiv.org/abs/2511.00420)
*Ali Taghavian,Ali Safi,Esmaeel Khanmirza*

Main category: eess.SY

TL;DR: 提出了一种基于状态空间划分、计算仿真和图论的新型可实现的约束终态控制器，用于处理混合动力系统。


<details>
  <summary>Details</summary>
Motivation: 混合动力系统具有连续和基于事件的行为，传统控制器无法处理这类复杂系统，需要开发新的控制器。

Method: 通过划分系统状态空间、计算仿真和图论方法，开发了计算混合控制器(CHC)。

Result: 在三水箱基准测试和摆锤摆起控制实验中，与模型预测控制器相比，证明了所提CHC控制器的有效性。

Conclusion: 提出的计算混合控制器能够有效处理混合动力系统的控制问题，在实验中表现出良好的性能。

Abstract: Hybrid dynamical systems are viewed as the most complicated systems with
continuous and event-based behaviors. Since traditional controllers cannot
handle these systems, some newly-developed controllers have been published in
recent decades to deal with them. This paper presents a novel implementable
constrained final-state controller based on partitioning the system's
state-space, computational simulations, and graph theory. Experimental results
and a comparison with Model Predictive Controller on the three tank benchmark
and swing-up control of a pendulum show the effectiveness of the proposed
Computational Hybrid Controller(CHC).

</details>


### [119] [CT-ESKF: A General Framework of Covariance Transformation-Based Error-State Kalman Filter](https://arxiv.org/abs/2511.00453)
*Jiale Han,Wei Ouyang,Maoran Zhu,Yuanxin Wu*

Main category: eess.SY

TL;DR: 本文提出了基于协方差变换的误差状态卡尔曼滤波框架，统一了多种滤波算法，并在融合全局和载体观测的导航系统中表现出优于传统EKF和InEKF的性能。


<details>
  <summary>Details</summary>
Motivation: 当同时包含全局坐标系和载体坐标系观测时，不变扩展卡尔曼滤波可能无法保持其轨迹无关特性，需要改进滤波算法以提升导航系统性能。

Method: 引入误差状态与协方差矩阵等价性概念，提出协方差变换的误差状态卡尔曼滤波框架，统一不同滤波算法，并衍生出新型滤波算法。

Result: 实验结果表明，在INS/GNSS/里程计组合导航系统中，采用协方差变换的EKF性能优于传统InEKF和原始EKF。

Conclusion: 提出的CT-ESKF框架有效解决了多坐标系观测下的滤波问题，为组合导航系统提供了性能更优的滤波解决方案。

Abstract: Invariant extended Kalman filter (InEKF) possesses excellent
trajectory-independent property and better consistency compared to conventional
extended Kalman filter (EKF). However, when applied to scenarios involving both
global-frame and body-frame observations, InEKF may fail to preserve its
trajectory-independent property. This work introduces the concept of
equivalence between error states and covariance matrices among different
error-state Kalman filters, and shows that although InEKF exhibits trajectory
independence, its covariance propagation is actually equivalent to EKF. A
covariance transformation-based error-state Kalman filter (CT-ESKF) framework
is proposed that unifies various error-state Kalman filtering algorithms. The
framework gives birth to novel filtering algorithms that demonstrate improved
performance in integrated navigation systems that incorporate both global and
body-frame observations. Experimental results show that the EKF with covariance
transformation outperforms both InEKF and original EKF in a representative
INS/GNSS/Odometer integrated navigation system.

</details>


### [120] [Rotatable Antenna System Empowered Low-Altitude Economy: Opportunities and Challenges](https://arxiv.org/abs/2511.00562)
*Shuaijun Li,Jie Tang,Beixiong Zheng,Lipeng Zhu,Cui Yang,Nan Zhao,Xiu Yin Zhang,Kai-Kit Wong*

Main category: eess.SY

TL;DR: 本文介绍了可旋转天线系统(RAS)在低空经济(LAE)中的应用，通过动态调整定向天线波束方向来扩展低空覆盖范围并增强数据传输稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有网络基站主要设计用于地面用户，无法为低空应用提供连续覆盖，限制了低空经济的发展。

Method: 提出RAS技术，通过动态调整定向天线波束方向实现灵活波束成形，并设计了RAS辅助的多基站和多无人机协同覆盖策略。

Result: 实验和仿真结果表明RAS在LAE网络中带来了显著的性能提升。

Conclusion: RAS技术能够有效解决低空覆盖问题，为低空经济发展提供可靠的数据连接支持。

Abstract: Low-altitude economy (LAE) is an emerging technological paradigm that enables
continuous airspace coverage at multiple altitudes by providing highly reliable
data connectivity for numerous low-altitude applications. However, existing
networks cannot sufficiently support LAE development, as current base stations
(BSs) are primarily designed for terrestrial users and lack the capability to
provide continuous coverage at low altitudes. To overcome these challenges,
rotatable antenna system (RAS) is introduced in LAE, enabling flexible
beamforming by dynamically adjusting the boresight of directional antennas to
extend low-altitude coverage and enhance the stability of data transmission. In
this article, we first provide an overview of RAS-empowered LAE applications,
including low-altitude communication, sensing, control, and computation. Then,
we present two practical RAS deployment strategies for LAE scenarios, namely
RAS-aided multi-BS and multi-unmanned aerial vehicle (UAV) cooperative
coverages, as well as provide detailed discussions on their system
architectures and performance benefits. Additionally, key design issues of RAS
in LAE are discussed, including channel modeling and estimation, cellular
access and interference cancellation, as well as RAS configuration and
boresight optimization. Finally, we demonstrate the performance gains of RAS in
LAE networks through experimental and simulation results.

</details>


### [121] [Towards Quantum Algorithms for the Optimization of Spanning Trees: The Power Distribution Grids Use Case](https://arxiv.org/abs/2511.00582)
*Carsten Hartmann,Nil Rodellas-Gràcia,Christian Wallisch,Thiemo Pesch,Frank K. Wilhelm,Dirk Witthaut,Tobias Stollenwerk,Andrea Benigni*

Main category: eess.SY

TL;DR: 该论文提出使用量子优化方法来解决径向网络拓扑优化问题，特别是配电网络重构中的损耗最小化问题。


<details>
  <summary>Details</summary>
Motivation: 网络拓扑优化在能源系统中能显著降低损耗和成本，但这类优化问题通常是NP难问题，限制了实际应用。

Method: 基于量子交替算子ansatz（QAOA）开发了两种量子算法原语：一种是针对径向拓扑的定制采样，另一种是使用惩罚项抑制非径向拓扑的简单采样。

Result: 论文展示了如何将这些量子算法原语应用于配电网络重构，并量化了所需的量子资源。

Conclusion: 量子优化为径向网络损耗最小化这一计算困难问题提供了有前景的替代解决方案。

Abstract: Optimizing the topology of networks is an important challenge across
engineering disciplines. In energy systems, network reconfiguration can
substantially reduce losses and costs and thus support the energy transition.
Unfortunately, many related optimization problems are NP hard, restricting
practical applications. In this article, we address the problem of minimizing
losses in radial networks, a problem that routinely arises in distribution grid
operation. We show that even the computation of approximate solutions is
computationally hard and propose quantum optimization as a promising
alternative. We derive two quantum algorithmic primitives based on the Quantum
Alternating Operator Ansatz (QAOA) that differ in the sampling of network
topologies: a tailored sampling of radial topologies and simple sampling with
penalty terms to suppress non-radial topologies. We show how to apply these
algorithmic primitives to distribution grid reconfiguration and quantify the
necessary quantum resources.

</details>


### [122] [Digital Twin of Aerosol Jet Printing](https://arxiv.org/abs/2511.00593)
*Aayushya Agarwal,Jace Rozsa,Matteo Pozzi,Rahul Panat,Gary K. Fedder*

Main category: eess.SY

TL;DR: 开发了气溶胶喷射（AJ）打印过程的数字孪生模型，通过物理建模和概率估计技术实时监控不可观测状态，提高打印质量一致性。


<details>
  <summary>Details</summary>
Motivation: AJ打印虽然潜力巨大，但由于隐藏状态（如气溶胶粒子直径、载气密度等）的变异性导致打印质量不一致，限制了其广泛应用。

Method: 构建基于物理的宏观模型，结合传感器和视频数据，使用概率顺序估计技术持续更新数字模型状态和参数。

Result: 创建了能够持续演化的AJ过程数字模型，能够准确监控不可观测物理特性、检测预测异常行为并预测控制调整效果。

Conclusion: 提出了一个端到端的数字孪生框架，虽然针对AJ打印定制，但该构建过程可应用于其他先进制造技术。

Abstract: Aerosol Jet (AJ) printing is a versatile additive manufacturing technique
capable of producing high-resolution interconnects on both 2D and 3D
substrates. The AJ process is complex and dynamic with many hidden and
unobservable states that influence the machine performance, including aerosol
particle diameter, aerosol carrier density, vial level, and ink deposition in
the tube and nozzle. Despite its promising potential, the widespread adoption
of AJ printing is limited by inconsistencies in print quality that often stem
from variability in these hidden states. To address these challenges, we
develop a digital twin model of the AJ process that offers real-time insights
into the machine's operations. The digital twin is built around a physics-based
macro-model created through simulation and experimentation. The states and
parameters of the digital model are continuously updated using probabilistic
sequential estimation techniques to closely align with real-time measurements
extracted from the AJ system's sensor and video data. The result is a digital
model of the AJ process that continuously evolves over a physical machine's
lifecycle. The digital twin enables accurate monitoring of unobservable
physical characteristics, detects and predicts anomalous behavior, and
forecasts the effect of control adjustments. This work presents a comprehensive
end-to-end digital twin framework that integrates customized computer vision
techniques, physics-based macro-modeling, and advanced probabilistic estimation
methods to construct an evolving digital representation of the AJ equipment and
process. While the methodologies are customized for aerosol jet printing, the
process for constructing the digital twin can be applied for other advanced
manufacturing techniques.

</details>


### [123] [Efficiency and Optimality in Electrochemical Battery Model Parameter Identification: A Comparative Study of Estimation Techniques](https://arxiv.org/abs/2511.00595)
*Feng Guo,Luis D. Couto,Guillaume Thenaisie*

Main category: eess.SY

TL;DR: 本文评估了三种电化学电池模型参数辨识方法的效率和最优性：最小二乘法(LS)、粒子群优化(PSO)和遗传算法(GA)，发现PSO在准确性和稳定性方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 电化学电池模型参数辨识具有挑战性，因为涉及众多无法直接测量的参数，需要评估不同方法的效率和最优性。

Method: 开发并离散化电池单粒子模型(SPM)，进行参数分组以减少参数数量，使用真实电池参数作为基准生成拟合和验证数据集，比较三种方法的运行时间和准确性。

Result: PSO在准确性和稳定性方面优于其他方法，LS更适合参数微调（特别是老化电池），GA在计算效率和最优性方面落后于PSO。

Conclusion: PSO在无先验电池内部参数知识时非常有效，LS适用于参数微调，GA表现相对较差。

Abstract: Parameter identification for electrochemical battery models has always been
challenging due to the multitude of parameters involved, most of which cannot
be directly measured. This paper evaluates the efficiency and optimality of
three widely-used parameter identification methods for electrochemical battery
models: Least Squares Method (LS), Particle Swarm Optimization (PSO), and
Genetic Algorithm (GA). Therefore, a Single Particle Model (SPM) of a battery
was developed and discretized. Battery parameter grouping was then performed to
reduce the number of parameters required. Using a set of parameters previously
identified from a real battery as a benchmark, we generated fitting and
validation datasets to assess the methods' runtime and accuracy. The
comparative analysis reveals that PSO outperforms the other methods in terms of
accuracy and stability, making it highly effective for parameter identification
when there is no prior knowledge of the battery's internal parameters. In
contrast, LS is better suited for minor adjustments in parameters, particularly
for aging batteries, whereas GA lags behind in both computational efficiency
and optimality with respect to PSO.

</details>


### [124] [Adaptive Federated Learning to Optimize the MultiCast flows in Data Centers](https://arxiv.org/abs/2511.00623)
*Junhong Liu,Lanxin Du,Yujia Li,Rong-Peng Liu,Fei Teng,Francis Yunhe Hou*

Main category: eess.SY

TL;DR: 提出了一种自适应联邦学习优化方法，用于解决地理分布式数据中心的多周期优化问题，同时保护数据隐私和完整性。


<details>
  <summary>Details</summary>
Motivation: 数据中心能耗快速增长带来可持续运营挑战，传统优化方法面临混合整数规划复杂性和数据隐私问题。

Method: 采用自适应联邦学习优化方法，结合密码学技术保护隐私，开发模型接受标准和可验证双重聚合机制。

Result: 理论分析和数值模拟表明该方法能保护数据隐私和完整性，实现接近最优性能，计算效率高。

Conclusion: 该方法适用于大规模数据中心在隐私约束下的优化，能有效平衡能效优化与数据安全需求。

Abstract: Data centers play an increasingly critical role in societal digitalization,
yet their rapidly growing energy demand poses significant challenges for
sustainable operation. To enhance the energy efficiency of geographically
distributed data centers, this paper formulates a multi-period optimization
model that captures the interdependence of electricity, heat, and data flows.
The optimization of such multicast flows inherently involves mixed-integer
formulations and the access to proprietary or sensitive datasets, which
correspondingly exacerbate computational complexity and raise data-privacy
concerns. To address these challenges, an adaptive federated
learning-to-optimization approach is proposed, accounting for the heterogeneity
of datasets across distributed data centers. To safeguard privacy, cryptography
techniques are leveraged in both the learning and optimization processes. A
model acceptance criterion with convergence guarantee is developed to improve
learning performance and filter out potentially contaminated data, while a
verifiable double aggregation mechanism is further proposed to simultaneously
ensure privacy and integrity of shared data during optimization. Theoretical
analysis and numerical simulations demonstrate that the proposed approach
preserves the privacy and integrity of shared data, achieves near-optimal
performance, and exhibits high computational efficiency, making it suitable for
large-scale data center optimization under privacy constraints.

</details>


### [125] [Frequency Quality Assessment of GFM and GFL Converters and Synchronous Condensers](https://arxiv.org/abs/2511.00639)
*Taulant Kerci,Federico Milano*

Main category: eess.SY

TL;DR: 比较电网形成(GFM)和电网跟随(GFL)逆变器资源与传统同步机对频率质量的影响，发现GFM显著改善频率质量，但GFL与同步调相机的组合也能达到类似标准，且在GFM主导电网中AGC需求变得不明确。


<details>
  <summary>Details</summary>
Motivation: 研究不同技术和控制策略对电网频率质量的影响，特别关注GFM和GFL逆变器资源的长期动态性能。

Method: 通过广泛的仿真和多个现实场景，考虑频率质量的短期和长期方面，比较GFM IBRs、GFL IBRs和传统同步机的性能。

Result: GFM IBRs显著改善频率质量；提供频率支持的GFL IBRs（如风电和电池）与同步调相机的组合可达到类似频率质量标准；在GFM主导电网中AGC需求变得不明确。

Conclusion: GFM技术能显著提升频率质量，但GFL与同步设备的组合也能满足标准，且在GFM主导系统中需要重新评估AGC的必要性。

Abstract: This paper compares the impact of different conventional and emerging
technologies and control strategies on frequency quality. We study, in
particular, the long-term dynamic performance of grid-forming (GFM) and
grid-following (GFL) inverter-based resources (IBRs) as well as conventional
synchronous machines. Extensive simulations and several realistic scenarios
consider both short-term and long-term aspects of frequency quality. It is
shown that, while overall GFM IBRs significantly improve frequency quality, a
combination of GFL IBRs providing frequency support such as wind and batteries,
and synchronous condensers, might be enough to meet similar frequency quality
standards. Another result of the paper is that the need for automatic
generation control (AGC) becomes less clear in GFM IBR-dominated grids from a
frequency quality perspective.

</details>


### [126] [Unveiling Uniform Shifted Power Law in Stochastic Human and Autonomous Driving Behavior](https://arxiv.org/abs/2511.00659)
*Wang Chen,Heye Huang,Ke Ma,Hangyu Li,Shixiao Liang,Hang Zhou,Xiaopeng Li*

Main category: eess.SY

TL;DR: 本文发现了一个简单的移位幂律模型，能够统一表征人类驾驶车辆和自动驾驶车辆的行为随机性，特别是在长尾分布区域，显著提升了交通仿真的安全评估准确性。


<details>
  <summary>Details</summary>
Motivation: 当前模型在基于真实数据校准时难以重现现实的碰撞率，主要由于对长尾行为分布的表示不足，这影响了自动驾驶车辆的安全评估和认证。

Method: 提出移位幂律模型，采用简洁的解析形式（仅需1-2个参数），分析全球HV和AV数据集中的微观轨迹数据，并将其集成到基于代理的交通模拟器中。

Result: 移位幂律模型平均R2达到0.97，尾部分布几乎相同，均匀拟合频繁行为和罕见安全关键偏差，显著优于基于高斯分布的基线方法。集成到模拟器后能重现现实的碰撞模式，碰撞率与真实统计数据一致。

Conclusion: 移位幂律为高风险行为建模提供了统一且数据高效的基础，提高了混合AV/HV交通仿真安全评估的保真度，为自动驾驶技术的仿真驱动验证和全球认证提供了有前景的路径。

Abstract: Accurately simulating rare but safety-critical driving behaviors is essential
for the evaluation and certification of autonomous vehicles (AVs). However,
current models often fail to reproduce realistic collision rates when
calibrated on real-world data, largely due to inadequate representation of
long-tailed behavioral distributions. Here, we uncover a simple yet unifying
shifted power law that robustly characterizes the stochasticity of both
human-driven vehicle (HV) and AV behaviors, especially in the long-tail regime.
The model adopts a parsimonious analytical form with only one or two
parameters, enabling efficient calibration even under data sparsity. Analyzing
large-scale, micro-level trajectory data from global HV and AV datasets, the
shifted power law achieves an average R2 of 0.97 and a nearly identical tail
distribution, uniformly fits both frequent behaviors and rare safety-critical
deviations, significantly outperforming existing Gaussian-based baselines. When
integrated into an agent-based traffic simulator, it enables forward-rolling
simulations that reproduce realistic crash patterns for both HVs and AVs,
achieving rates consistent with real-world statistics and improving the
fidelity of safety assessment without post hoc correction. This discovery
offers a unified and data-efficient foundation for modeling high-risk behavior
and improves the fidelity of simulation-based safety assessments for mixed
AV/HV traffic. The shifted power law provides a promising path toward
simulation-driven validation and global certification of AV technologies.

</details>


### [127] [Hybrid Quantum-Classical Optimization of the Resource Scheduling Problem](https://arxiv.org/abs/2511.00733)
*Tyler Christeson,Md Habib Ullah,Ali Arabnya,Amin Khodaei,Rui Fan*

Main category: eess.SY

TL;DR: 提出了一种量子-经典混合算法，使用Benders分解将机组组合问题分解为二进制主问题和连续子问题，主问题在量子退火器上求解，显著降低了大规模系统的计算时间增长。


<details>
  <summary>Details</summary>
Motivation: 传统精确方法在大规模系统中计算负担重，元启发式方法缺乏最优性保证且对初始条件敏感，需要一种能处理大规模资源调度问题的新方法。

Method: 采用Benders分解将问题分解为二进制主问题和连续经济调度子问题，主问题构建为二次无约束二进制优化模型并在量子退火器上求解，子问题生成拉格朗日割反馈至主问题直至收敛。

Result: 在10到1000个发电单元的系统中测试，相比经典混合整数非线性规划基准，混合算法计算时间增长率显著降低，绝对最优性差距保持在1.63%以下。

Conclusion: 量子退火与经典Benders分解的混合框架能显著加速大规模资源调度，同时保持解的质量，为解决现代电网日益复杂的问题提供了可行路径。

Abstract: Resource scheduling is critical in many industries, especially in power
systems. The Unit Commitment problem determines the on/off status and output
levels of generators under many constraints. Traditional exact methods, such as
mathematical programming methods or dynamic programming, remain the backbone of
UC solution techniques, but they often rely on linear approximations or
exhaustive search, leading to high computational burdens as system size grows.
Metaheuristic approaches, such as genetic algorithms, particle swarm
optimization, and other evolutionary methods, have been explored to mitigate
this complexity; however, they typically lack optimality guarantees, exhibit
sensitivity to initial conditions, and can become prohibitively time-consuming
for large-scale systems. In this paper, we introduce a quantum-classical hybrid
algorithm for UC and, by extension, other resource scheduling problems, that
leverages Benders decomposition to decouple binary commitment decisions from
continuous economic dispatch. The binary master problem is formulated as a
quadratic unconstrained binary optimization model and solved on a quantum
annealer. The continuous subproblem, which minimizes generation costs, with
Lagrangian cuts feeding back to the master until convergence. We evaluate our
hybrid framework on systems scaled from 10 to 1,000 generation units. Compared
against a classical mixed-integer nonlinear programming baseline, the hybrid
algorithm achieves a consistently lower computation-time growth rate and
maintains an absolute optimality gap below 1.63%. These results demonstrate
that integrating quantum annealing within a hybrid quantum-classical Benders
decomposition loop can significantly accelerate large-scale resource scheduling
without sacrificing solution quality, pointing toward a viable path for
addressing the escalating complexity of modern power grids.

</details>


### [128] [Quantum Computing for EVs to Enhance Grid Resilience and Disaster Relief: Challenges and Opportunities](https://arxiv.org/abs/2511.00736)
*Tyler Christeson,Amin Khodaei,Rui Fan*

Main category: eess.SY

TL;DR: 该论文综述了车辆到电网(V2G)和移动充电站布局(CSP)优化方法，探讨量子计算如何克服当前计算瓶颈，以增强电网韧性并加速极端天气下的恢复过程。


<details>
  <summary>Details</summary>
Motivation: 随着极端天气事件日益频繁和严重，增强电网韧性对维持安全可靠运行至关重要。V2G技术允许电动汽车作为移动能源资源支持关键负载或调节电网频率，但需要复杂的优化协调。

Method: 综述了V2G和移动CSP应用的最先进优化方法，分析其局限性，并探索量子计算如何克服当前计算瓶颈。

Result: 提出了量子计算视角来增强电网韧性和加速恢复过程，为应对日益频繁的极端天气事件提供新的解决方案。

Conclusion: 量子计算有潜力克服V2G和移动CSP优化中的计算瓶颈，为增强电网韧性和加速极端天气下的恢复提供新的技术途径。

Abstract: The power grid is the foundation of modern society, however extreme weather
events have increasingly caused widespread outages. Enhancing grid resilience
is therefore critical to maintaining secure and reliable operations. In
disaster relief and restoration, vehicle-to-grid (V2G) technology allows
electric vehicles (EVs) to serve as mobile energy resources by discharging to
support critical loads or regulating grid frequency as needed. Effective V2G
operation requires coordinated charging and discharging of many EVs through
optimization. Similarly, in grid restoration, EVs must be strategically routed
to affected areas, forming the mobile charging station placement (CSP) problem,
which presents another complex optimization challenge. This work reviews
state-of-the-art optimization methods for V2G and mobile CSP applications,
outlines their limitations, and explores how quantum computing (QC) could
overcome current computational bottlenecks. A QC-focused perspective is
presented on enhancing grid resilience and accelerating restoration as extreme
weather events grow more frequent and severe.

</details>


### [129] [High-Power Dual-Channel Field Chamber for High-Frequency Magnetic Neuromodulation](https://arxiv.org/abs/2511.00745)
*Xiaoyang Tian,Hui Wang,Boshuo Wang,Jinshui Zhang,Dong Yan,Jeannette Ingabire,Samantha Coffler,Guillaume Duret,Quoc-Khanh Pham,Gang Bao,Jacob T. Robinson,Stefan M. Goetz,Angel V. Peterchev*

Main category: eess.SY

TL;DR: 开发了一种双通道磁刺激室，用于在自由移动小鼠中精确控制神经活动，通过两个正交磁场通道实现频率选择性磁热遗传刺激。


<details>
  <summary>Details</summary>
Motivation: 需要量化高频交变磁场在自由移动动物中的行为效应，现有方法缺乏专门设备来精确控制磁场参数。

Method: 采用优化的线圈设计，构建双通道磁刺激系统，包含50kHz和550kHz两个正交磁场通道，配备液冷系统和视频观测功能。

Result: 系统在两个频段产生高强度磁场（88mT和12.5mT），干扰小于1%，磁场均匀性达±10%（覆盖94%容积），温度上升<0.35°C/s，验证了频率选择性加热能力。

Conclusion: 该系统为磁遗传学和磁电刺激研究提供了可靠平台，能够安全有效地在自由移动动物中进行神经调控实验。

Abstract: Several novel methods, including magnetogenetics and magnetoelectric
stimulation, use high frequency alternating magnetic fields to precisely
manipulate neural activity. To quantify the behavioral effects of such
interventions in a freely moving mouse, we developed a dual-channel magnetic
chamber, specifically designed for rate-sensitive magnetothermal-genetic
stimulation, and adaptable for other uses of alternating magnetic fields.
Through an optimized coil design, the system allows independent control of two
spatially orthogonal uniform magnetic fields delivered at different frequencies
within a 10 cm x 10 cm x 6 cm chamber. The two channels have nominal
frequencies of 50 and 550 kHz with peak magnetic field strengths of 88 and 12.5
mT, achieved with resonant coil drives having peak voltages of 1.6 and 1.8 kV
and currents of 1.0 and 0.26 kA, respectively. Additionally, a liquid cooling
system enables magnetic field generation for second-level duration, and an
observation port and camera allow video capture of the animal's behavior within
the chamber. The system generates high-amplitude magnetic fields across two
widely separated frequency channels with negligible interference (< 1%).
Relatively uniform magnetic field distribution (+/-10% across 94% of the
chamber volume) is maintained throughout the chamber, and temperature increase
of the inner side of the coil enclosure during the operation is limited to <
0.35 {\deg}C/s to ensure in vivo safety. Using cobalt-doped and undoped iron
oxide nanoparticles, we demonstrate channel-specific heating rates of 3.5
{\deg}C/s and 1.5 {\deg}C/s, respectively, validating frequency-selectivity.
Both channels can run continuously for four seconds stably.

</details>


### [130] [Deep Q-Network for Optimizing NOMA-Aided Resource Allocation in Smart Factories with URLLC Constraints](https://arxiv.org/abs/2511.00765)
*Shi Gengtian,Jiang Liu,Shigeru Shimamoto*

Main category: eess.SY

TL;DR: 提出基于深度Q网络（DQN）的NOMA辅助资源分配算法，用于智能工厂中满足URLLC严格要求的动态子信道和功率分配。


<details>
  <summary>Details</summary>
Motivation: 智能工厂中机器人、传感器和控制器等设备对通信有不同需求，需要满足URLLC的超可靠低延迟通信要求，同时最大化吞吐量。

Method: 采用深度Q网络算法，通过可调参数λ平衡吞吐量与延迟之间的权衡，动态分配子信道和优化功率水平。

Result: 仿真结果显示机器人获得更高吞吐量，传感器和控制器满足URLLC的低延迟要求，确保实时工业应用的可靠通信。

Conclusion: 所提DQN算法能有效满足智能工厂中不同设备的多样化通信需求，在吞吐量和延迟之间实现良好平衡。

Abstract: This paper presents a Deep Q-Network (DQN)- based algorithm for NOMA-aided
resource allocation in smart factories, addressing the stringent requirements
of Ultra-Reliable Low-Latency Communication (URLLC). The proposed algorithm
dynamically allocates sub-channels and optimizes power levels to maximize
throughput while meeting strict latency constraints. By incorporating a tunable
parameter {\lambda}, the algorithm balances the trade-off between throughput
and latency, making it suitable for various devices, including robots, sensors,
and controllers, each with distinct communication needs. Simulation results
show that robots achieve higher throughput, while sensors and controllers meet
the low-latency requirements of URLLC, ensuring reliable communication for
real-time industrial applications.

</details>


### [131] [Minimizing Maximum Latency of Task Offloading for Multi-UAV-assisted Maritime Search and Rescue](https://arxiv.org/abs/2511.00844)
*Shuang Qi,Bin Lin,Yiqin Deng,Xianhao Chen,Yuguang Fang*

Main category: eess.SY

TL;DR: 提出了一种多无人机辅助海上搜救系统，通过联合优化计算卸载决策、中继无人机部署和监控无人机与救援目标的关联，最小化所有监控无人机的最大总延迟。


<details>
  <summary>Details</summary>
Motivation: 无人机在海上搜救中发挥重要作用，但其有限的计算能力和能量限制了系统效率。需要解决计算卸载、无人机部署和目标关联的联合优化问题。

Method: 设计包含多个监控无人机和一个中继无人机的系统，将非凸优化问题分解为三个子问题，提出有效的迭代算法求解。

Result: 数值仿真结果表明，所提算法在各种性能参数下均表现出有效性。

Conclusion: 该多无人机系统通过联合优化策略能够有效降低海上搜救任务中的延迟，提高救援效率。

Abstract: Unmanned Aerial Vehicles (UAVs) play a crucial role in Maritime Search and
Rescue (MSAR), contributing to the improvement of rescue efficiency and
reduction of casualties. Typically, UAVs equipped with cameras collect data
from disaster areas and transmit it to the shore-based rescue command centers.
By deploying Mobile Edge Computing (MEC) servers, UAVs can pre-process video
footage to reduce data transmission volume, thus reducing transmission delays.
However, the limited computational capacity and energy of UAVs pose significant
challenges to the efficiency of UAV-assisted MSAR systems. To address these
problems, in this paper, we investigate a multi-UAV assisted MSAR system
consisting of multiple Surveillance UAVs (S-UAVs) and a Relay UAV (R-UAV).
Then, we formulate a joint optimization problem to minimize the maximum total
latency among all S-UAVs via jointly making the computing offloading decisions,
R-UAV deployment, and the association between a S-UAV and rescue targets while
ensuring that all targets are monitored by S-UAVs. Since the formulated
optimization problem is typically hard to solve due to its non-convexity, we
propose an effective iterative algorithm by breaking it into three
sub-problems. Numerical simulation results show the effectiveness of the
proposed algorithm with various performance parameters.

</details>


### [132] [Traffic-Aware Grid Planning for Dynamic Wireless Electric Vehicle Charging](https://arxiv.org/abs/2511.00941)
*Dipanjan Ghose,S Sivaranjani,Junjie Qin*

Main category: eess.SY

TL;DR: 提出了一种考虑交通流量的动态无线充电电网规划框架，通过宏观交通流模型估计充电需求，结合最优潮流优化微电网规模，相比最坏情况规划显著降低基础设施成本。


<details>
  <summary>Details</summary>
Motivation: 动态无线充电技术虽然能减少电池尺寸和充电停机时间，但其短时高功率需求会给电网带来压力，需要综合考虑交通行为和电动汽车能耗的集成规划方法。

Method: 使用宏观细胞传输模型估计时空充电需求，结合交流最优潮流优化微电网规模，考虑不同交通条件。

Result: 在加州I-210W高速公路上验证，交通感知规划相比最坏情况建模显著降低基础设施成本，同时确保各种交通条件下的充电可靠性。

Conclusion: 交通感知的电网规划框架能够获得更低成本和更易操作的系统设计，优于依赖最坏情况交通数据的规划模型。

Abstract: Dynamic Wireless Electric Vehicle Charging (DWC) on electrified roadways is
an emerging technology that can significantly reduce battery sizes, eliminate
charging downtime, and alleviate range anxiety, specially for long-haul
transportation and fleet operations of electric vehicles (EVs). However, these
systems introduce new challenges for power system planning due to their
short-duration and high-power demands which can strain the grid if not properly
managed. As the energy demands from DWC depend on vehicle speed, density, dwell
time in charging zones, and load profiles along road segments, there is a need
for integrated planning of such systems, jointly considering both traffic
behavior and EV energy consumption. In this paper, we propose a traffic-aware
grid planning framework for DWC. We leverage a macroscopic Cell Transmission
Model of traffic flow to estimate real-time, spatiotemporal EV charging demand
from DWC corridors. The demand model is then integrated into an AC Optimal
Power Flow based formulation to optimally size a microgrid that supports DWC
under varying traffic conditions while minimizing the cost of operation. Our
framework explicitly models how spatiotemporal traffic patterns affect the
utilization of grid resources to obtain system designs that achieve lower costs
and are easier to operationalize as compared to planning models that rely on
worst-case traffic data.
  We demonstrate the framework on data from a 14-mile segment of the I-210W
highway in California, USA, evaluating multiple traffic scenarios like
free-flow, severe congestion, accidents of varying severity, and natural
disasters like forest fires. Our results demonstrate that traffic-aware grid
planning significantly reduces infrastructure costs as compared to
worst-scenario based modeling, while ensuring reliability of service in terms
of meeting charging demands under diverse traffic conditions.

</details>


### [133] [Secure Distributed Consensus Estimation under False Data Injection Attacks: A Defense Strategy Based on Partial Channel Coding](https://arxiv.org/abs/2511.00963)
*Jiahao Huang,Marios M. Polycarpou,Wen Yang,Fangfei Li,Yang Tang*

Main category: eess.SY

TL;DR: 该论文研究了分布式估计中虚假数据注入攻击的安全问题，提出了攻击检测和编码防御两种策略，并分析了系统脆弱性条件。


<details>
  <summary>Details</summary>
Motivation: 研究分布式估计系统中由资源受限攻击者通过部分信道注入虚假数据引发的安全问题，需要揭示系统脆弱性并设计有效防御机制。

Method: 推导了攻击者能够发散估计误差同时保持所有残差隐蔽性的充要条件；提出了基于局部估计欧氏距离的攻击检测机制和采用编码方案保护传输数据的防御策略。

Result: 证明了基于距离的检测方法能够解决大多数安全漏洞，而编码方案可作为额外增强；采用时变编码矩阵可抵御向编码信道注入隐蔽序列的对手。

Conclusion: 基于安全分析提供了选择需要编码的安全关键信道的程序，在安全性和编码成本之间实现权衡；数值仿真验证了理论结果。

Abstract: This article investigates the security issue caused by false data injection
attacks in distributed estimation, wherein each sensor can construct two types
of residues based on local estimates and neighbor information, respectively.
The resource-constrained attacker can select partial channels from the sensor
network and arbitrarily manipulate the transmitted data. We derive necessary
and sufficient conditions to reveal system vulnerabilities, under which the
attacker is able to diverge the estimation error while preserving the
stealthiness of all residues. We propose two defense strategies with mechanisms
of exploiting the Euclidean distance between local estimates to detect attacks,
and adopting the coding scheme to protect the transmitted data, respectively.
It is proven that the former has the capability to address the majority of
security loopholes, while the latter can serve as an additional enhancement to
the former. By employing the time-varying coding matrix to mitigate the risk of
being cracked, we demonstrate that the latter can safeguard against adversaries
injecting stealthy sequences into the encoded channels. Hence, drawing upon the
security analysis, we further provide a procedure to select security-critical
channels that need to be encoded, thereby achieving a trade-off between
security and coding costs. Finally, some numerical simulations are conducted to
demonstrate the theoretical results.

</details>


### [134] [On Structural Properties of Risk-Averse Optimal Stopping Problems](https://arxiv.org/abs/2511.01022)
*Xingyu Ren,Michael C. Fu,Steven I. Marcus*

Main category: eess.SY

TL;DR: 本文研究了在时间一致动态风险度量下的最优停止问题，证明了值函数的单调性，并建立了控制极限最优策略的存在条件。


<details>
  <summary>Details</summary>
Motivation: 虽然风险中性模型下的最优停止问题已有成熟结果，但在风险规避设置下相关结构性质研究不足。相干风险度量缺乏塔性质和可加性，使得结构分析复杂化。

Method: 通过分析相干风险度量的风险包络，证明如果每个风险度量存在最小元素，则风险规避最优停止问题可转化为等价的风险中性形式。开发了识别控制极限最优策略的一般程序。

Result: 证明了值函数单调性与风险中性情况相似。建立了风险度量和MDP结构的可验证条件，保证控制极限最优策略的存在。通过运营、营销和金融中的最优停止问题验证了理论。

Conclusion: 在时间一致动态风险度量下，最优停止问题的结构性质可以保持，且存在将风险规避问题转化为风险中性等价形式的方法，为实际应用提供了理论支持。

Abstract: We establish structural properties of optimal stopping problems under
time-consistent dynamic (coherent) risk measures, focusing on value function
monotonicity and the existence of control limit (threshold) optimal policies.
While such results are well developed for risk-neutral (expected-value) models,
they remain underexplored in risk-averse settings. Coherent risk measures
typically lack the tower property and are subadditive rather than additive,
complicating structural analysis. We show that value function monotonicity
mirrors the risk-neutral case. Moreover, if the risk envelope associated with
each coherent risk measure admits a minimal element, the risk-averse optimal
stopping problem reduces to an equivalent risk-neutral formulation. We also
develop a general procedure for identifying control limit optimal policies and
use it to derive practical, verifiable conditions on the risk measures and MDP
structure that guarantee their existence. We illustrate the theory and verify
these conditions through optimal stopping problems arising in operations,
marketing, and finance.

</details>


### [135] [Online Energy Storage Arbitrage under Imperfect Predictions: A Conformal Risk-Aware Approach](https://arxiv.org/abs/2511.01032)
*Yiqian Wu,Ming Yi,Bolun Xu,James Anderson*

Main category: eess.SY

TL;DR: 提出一种基于保形决策理论的储能套利风险控制方法，通过预测集动态调整决策保守度，无需分布假设，有效管理价格预测不准确带来的利润损失风险。


<details>
  <summary>Details</summary>
Motivation: 储能套利完全依赖未来市场价格预测，而不准确的价格预测可能导致显著的利润损失，需要控制这种下行风险。

Method: 基于保形决策理论开发控制器，通过预测集动态调整决策保守度；建立时间差分误差作为可测量的代理指标；开发两种在线校准策略：基于预测误差的适应和基于价值误差的校准。

Result: 分析证明保形控制器具有有界的长期风险，时间差分误差具有收敛保证；案例研究表明在不同预测条件下相比基准方法在平衡风险和机会方面表现更优。

Conclusion: 该方法能有效管理储能套利中的风险暴露，在价格预测不准确的情况下仍能保持稳健性能，平衡风险与收益。

Abstract: This work proposes a conformal approach for energy storage arbitrage to
control the downside risks arose from imperfect price forecasts. Energy storage
arbitrage relies solely on predictions of future market prices, while
inaccurate price predictions may lead to significant profit losses. Based on
conformal decision theory, we describe a controller that dynamically adjusts
decision conservativeness through prediction sets without distributional
assumptions. To enable online calibration when online profit loss feedback is
unobservable, we establish that a temporal difference error serves as a
measurable proxy. Building on this insight, we develop two online calibration
strategies: prediction error-based adaptation targeting forecast accuracy, and
value error-based calibration focusing on decision quality. Analysis of the
conformal controller proves bounded long-term risk with convergence guarantees
in temporal difference error, which further effectively manages risk exposure
in potential profit losses. Case studies demonstrate superior performance in
balancing risk and opportunity compared to benchmarks under varying forecast
conditions.

</details>


### [136] [GOSPA-Driven Non-Myopic Multi-Sensor Management with Multi-Bernoulli Filtering](https://arxiv.org/abs/2511.01045)
*George Jones,Angel Garcia-Fernandez*

Main category: eess.SY

TL;DR: 提出了一种基于多伯努利滤波的非近视传感器管理算法，用于多传感器多目标跟踪，通过蒙特卡洛树搜索最小化广义最优子模式分配误差的上界。


<details>
  <summary>Details</summary>
Motivation: 解决多传感器在同一监视区域进行多目标跟踪时的传感器管理问题，考虑传感器间的联合优化和未来时间窗口内的性能。

Method: 使用多伯努利滤波框架，构建非近视最小化问题，以广义最优子模式分配误差的均方误差作为成本函数，通过蒙特卡洛树搜索实现可处理的优化。

Result: 通过仿真分析了所提算法的优势，展示了在多传感器多目标跟踪场景中的有效性。

Conclusion: 该算法能够有效管理多传感器系统，在考虑所有传感器协同作用的同时，优化长期跟踪性能。

Abstract: In this paper, we propose a non-myopic sensor management algorithm for
multi-target tracking, with multiple sensors operating in the same surveillance
area. The algorithm is based on multi-Bernoulli filtering and selects the
actions that solve a non-myopic minimisation problem, where the cost function
is the mean square generalised optimal sub-pattern assignment (GOSPA) error,
over a future time window. For tractability, the sensor management algorithm
actually uses an upper bound of the GOSPA error and is implemented via Monte
Carlo Tree Search (MCTS). The sensors have the ability to jointly optimise and
select their actions with the considerations of all other sensors in the
surveillance area. The benefits of the proposed algorithm are analysed via
simulations.

</details>


### [137] [Robust Self-Triggered Control Approaches Optimizing Sampling Sequences with Synchronous Measurements](https://arxiv.org/abs/2511.01057)
*Abbas Tariverdi*

Main category: eess.SY

TL;DR: 提出了一种基于有限时域预计算的自触发控制方案，用于减少嵌入式控制系统中的资源消耗，同时保证系统稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统周期性反馈控制算法在数字平台上执行时会导致CPU、网络带宽等资源使用效率低下，特别是在嵌入式控制和共享网络环境中。

Method: 基于当前状态信息在有限时域内预计算下一个采样序列，引入最优自触发方案，确保无扰动系统的指数稳定性和有扰动系统的全局一致最终有界性。

Result: 仿真结果表明该方法能够有效减少资源使用，同时保证系统性能。

Conclusion: 所提出的自触发控制方案在保证系统稳定性和鲁棒性的前提下，显著提高了资源使用效率，特别适用于资源受限的嵌入式控制系统。

Abstract: Feedback control algorithms traditionally rely on periodic execution on
digital platforms. While this simplifies design and analysis, it often leads to
inefficient resource usage (e.g., CPU, network bandwidth) in embedded control
and shared networks. This work investigates self-triggering implementations of
linear controllers in sampled-data systems with synchronous measurements. Our
approach precomputes the next sampling sequence over a finite horizon based on
current state information. We introduce a novel optimal self-triggering scheme
that guarantees exponential stability for unperturbed systems and global
uniform ultimate boundedness for perturbed systems. This ensures robustness
against external disturbances with explicit performance guarantees. Simulations
demonstrate the benefits of our approach.

</details>


### [138] [Universal Barrier Functions for Safety and Stability of Constrained Nonlinear Systems](https://arxiv.org/abs/2511.01067)
*Vrushabh Zinage,Efstathios Bakolas*

Main category: eess.SY

TL;DR: 提出通用屏障函数(UBF)方法，通过单一可微标量函数同时编码稳定性和安全性要求，并考虑输入约束，构建二次规划问题来生成安全稳定的控制器。


<details>
  <summary>Details</summary>
Motivation: 解决非线性系统在复杂安全规范和输入约束下的安全稳定控制器综合问题，传统方法难以同时处理这些要求。

Method: 引入通用屏障函数(UBF)，构建UBF-QP二次规划问题来生成控制输入，证明UBF存在性和QP可行性，并扩展到高阶相对度系统。

Result: 理论证明了UBF的存在性和UBF-QP的可行性，数值仿真验证了方法的有效性。

Conclusion: 提出的UBF框架为非线性系统在复杂安全规范和输入约束下提供了有效的安全稳定控制综合方法。

Abstract: In this paper, we address the problem of synthesizing safe and stabilizing
controllers for nonlinear systems subject to complex safety specifications and
input constraints. We introduce the Universal Barrier Function (UBF), a single
continuously differentiable scalar-valued function that encodes both stability
and safety criteria while accounting for input constraints. Using the UBF, we
formulate a Quadratic Program (UBF-QP) to generate control inputs that are both
safe and stabilizing under input constraints. We demonstrate that the UBF-QP is
feasible if a UBF exists. Furthermore, under mild conditions, we prove that a
UBF always exists. The proposed framework is then extended to systems with
higher relative degrees. Finally, numerical simulations illustrate the
effectiveness of our proposed approach.

</details>


### [139] [Deep Learning-Accelerated Shapley Value for Fair Allocation in Power Systems: The Case of Carbon Emission Responsibility](https://arxiv.org/abs/2511.01229)
*Yuanhao Feng,Tao Sun,Yan Meng,Xuxin Yang,Donghan Feng*

Main category: eess.SY

TL;DR: 提出了SurroShap框架，结合高效联盟采样和深度学习代理模型，首次实现了数千实体电力系统的Shapley值公平分配，在碳排责任分配中取得10^4-10^5倍加速。


<details>
  <summary>Details</summary>
Motivation: 解决电力系统参与者间成本、效益和排放公平分配的长期挑战，克服传统Shapley值计算在大规模应用中的计算障碍。

Method: 使用高效联盟采样和深度学习代理模型加速特征函数评估的SurroShap框架，通过理论误差边界证明时间平均分配收敛到精确Shapley值的ε-接近。

Result: 在9个系统（26-1951个实体）实验中，即使在最大规模下也能在实时操作窗口内完成，相比其他采样方法实现10^4-10^5倍加速，同时保持紧密误差边界。

Conclusion: 基于Shapley的碳分配具有六个理想特性，使个体利益与脱碳目标一致；德克萨斯2000节点系统的年度模拟验证了实际应用性，显示可再生能源丰富地区通过出口抵消排放责任，而负荷中心承担驱动系统发电的责任。

Abstract: Allocating costs, benefits, and emissions fairly among power system
participant entities represents a persistent challenge. The Shapley value
provides an axiomatically fair solution, yet computational barriers have
limited its adoption beyond small-scale applications. This paper presents
SurroShap, a scalable Shapley value approximation framework combining efficient
coalition sampling with deep learning surrogate models that accelerate
characteristic function evaluations. Exemplified through carbon emission
responsibility allocation in power networks, SurroShap enables Shapley-based
fair allocation for power systems with thousands of entities for the first
time. We derive theoretical error bounds proving that time-averaged SurroShap
allocations converge to be $\varepsilon$-close to exact Shapley values.
Experiments on nine systems ranging from 26 to 1,951 entities demonstrate
completion within the real-time operational window even at maximum scale,
achieving 10^4-10^5 speedups over other sampling-based methods while
maintaining tight error bounds. The resulting Shapley-based carbon allocations
possess six desirable properties aligning individual interests with
decarbonization goals. Year-long simulations on the Texas 2000-bus system
validate real-world applicability, with regional analysis revealing how
renewable-rich areas offset emission responsibility through exports while load
centers bear responsibility for driving system-wide generation.

</details>


### [140] [Orthogonal-by-construction augmentation of physics-based input-output models](https://arxiv.org/abs/2511.01321)
*Bendegúz M. Györök,Maarten Schoukens,Tamás Péni,Roland Tóth*

Main category: eess.SY

TL;DR: 提出了一种正交构造的模型增强结构，用于输入输出模型，确保在适当的可识别性条件下恢复真实的物理参数。


<details>
  <summary>Details</summary>
Motivation: 传统的并行连接增强结构会导致物理参数估计不现实，损害模型可解释性。

Method: 引入正交构造的模型增强结构，保证物理参数的可恢复性。

Result: 在适当条件下能够恢复真实的物理参数。

Conclusion: 正交构造的增强方法解决了传统并行结构导致的参数估计问题，保持了模型的可解释性。

Abstract: Model augmentation is a promising approach for integrating
first-principles-based models with machine learning components. Augmentation
can result in better model accuracy and faster convergence compared to
black-box system identification methods, while maintaining interpretability of
the models in terms of how the original dynamics are complemented by learning.
A widely used augmentation structure in the literature is based on the parallel
connection of the physics-based and learning components, for both of which the
corresponding parameters are jointly optimized. However, due to overlap in
representation of the system dynamics by such an additive structure, estimation
often leads to physically unrealistic parameters, compromising model
interpretability. To overcome this limitation, this paper introduces a novel
orthogonal-by-construction model augmentation structure for input-output
models, that guarantees recovery of the physically true parameters under
appropriate identifiability conditions.

</details>


### [141] [Risk Aware Safe Control with Cooperative Sensing for Dynamic Obstacle Avoidance](https://arxiv.org/abs/2511.01403)
*Pei Yu Chang,Qizhe Xu,Vishnu Renganathan,Qadeer Ahmed*

Main category: eess.SY

TL;DR: 开发了一种用于自动驾驶的安全关键控制器，通过Wasserstein重心融合协同感知，结合CVaR风险感知控制屏障函数，在存在感知和通信不确定性的情况下提高安全性。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶在感知和通信不确定性下的安全控制问题，传统方法难以处理分布优化和尾部风险。

Method: 使用Wasserstein重心优化动态障碍物位置分布，引入CVaR形成风险感知CBF框架，结合MPC进行路径跟踪，安全滤波器调制控制输入。

Result: 在实车测试中，相比基线MPC CBF设计，该方法表现出更好的安全裕度和鲁棒性，能有效处理测量噪声、通信扰动和输入干扰。

Conclusion: 提出的风险感知安全滤波器在实际自动驾驶车辆上部署具有实用性，能够显著提高系统安全性。

Abstract: This paper presents the design, development, and on vehicle implementation
and validation of a safety critical controller for autonomous driving under
sensing and communication uncertainty. Cooperative sensing, fused via a
Wasserstein barycenter (WB), is used to optimize the distribution of the
dynamic obstacle locations. The Conditional Value at Risk (CVaR) is introduced
to form a risk aware control-barrier-function (CBF) framework with the
optimized distribution samplings. The proposed WB CVaR CBF safety filter
improves control inputs that minimize tail risk while certifying forward
invariance of the safe set. A model predictive controller (MPC) performs path
tracking, and the safety filter modulates the nominal control inputs to enforce
risk aware constraints. We detail the software architecture and integration
with vehicle actuation and cooperative sensing. The approach is evaluated on a
full-scale autonomous vehicle (AV) in scenarios with measurement noise,
communication perturbations, and input disturbances, and is compared against a
baseline MPC CBF design. Results demonstrate improved safety margins and
robustness, highlighting the practicality of deploying the risk-aware safety
filter on an actual AV.

</details>


### [142] [Evolutionary Dynamics in Continuous-time Finite-state Mean Field Games - Part I: Equilibria](https://arxiv.org/abs/2511.01452)
*Leonardo Pedroso,Andrea Agazzi,W. P. M. H. Heemels,Mauro Salazar*

Main category: eess.SY

TL;DR: 该论文提出了动态博弈的进化分析框架，引入混合稳态纳什均衡(MSNE)概念，建立了有限人口博弈与平均场进化模型之间的强近似关系。


<details>
  <summary>Details</summary>
Motivation: 现有进化博弈理论主要关注静态博弈，缺乏对具有个体状态动态的博弈的进化分析。本文旨在填补这一空白，为动态博弈提供进化解释。

Method: 提出进化模型和有限人口博弈的平均场近似，建立强近似保证，引入MSNE作为新的解概念，并分析其与平均场进化模型不动点的关系。

Result: 证明了标准动态博弈解概念缺乏进化解释，MSNE具有进化解释，建立了MSNE与平均场进化模型不动点之间的关系，并研究了MSNE的进化稳定性。

Conclusion: MSNE为动态博弈提供了有效的进化解释框架，平均场进化模型能够很好地近似有限人口动态博弈的演化行为。

Abstract: We study a dynamic game with a large population of players who choose actions
from a finite set in continuous time. Each player has a state in a finite state
space that evolves stochastically with their actions. A player's reward depends
not only on their own state and action but also on the distribution of states
and actions across the population, capturing effects such as congestion in
traffic networks. While prior work in evolutionary game theory has primarily
focused on static games without individual player state dynamics, we present
the first comprehensive evolutionary analysis of such dynamic games. We propose
an evolutionary model together with a mean field approximation of the
finite-population game and establish strong approximation guarantees. We show
that standard solution concepts for dynamic games lack an evolutionary
interpretation, and we propose a new concept - the Mixed Stationary Nash
Equilibrium (MSNE) - which admits one. We analyze the relationship between MSNE
and the rest points of the mean field evolutionary model and study the
evolutionary stability of MSNE.

</details>


### [143] [Deep Learning Prediction of Beam Coherence Time for Near-FieldTeraHertz Networks](https://arxiv.org/abs/2511.01491)
*Irched Chafaa,E. Veronica Belmega,Giacomo Bacci*

Main category: eess.SY

TL;DR: 提出了一种用于移动太赫兹网络的波束相干时间概念，通过深度学习模型预测波束相干时间并动态调整波束成形，显著减少波束更新频率和开销。


<details>
  <summary>Details</summary>
Motivation: 太赫兹通信中大规模天线阵列需要精确波束成形来保证链路可靠性，但随着天线数量增加，波束对准和跟踪在移动网络中会产生过高开销。近场区域随天线阵列尺寸和载波频率扩展，需要调整波束成形以考虑球面波前。

Method: 引入波束相干时间概念，提出基于简单前馈神经网络的时间相关输入深度学习模型，预测波束相干时间并动态调整波束成形。

Result: 数值结果表明该方法有效提高了数据速率，同时减少了开销，特别是在高速移动场景下。

Conclusion: 所提出的方法能够显著降低波束更新频率，提高移动太赫兹网络的性能，尤其适用于高移动性场景。

Abstract: Large multiple antenna arrays coupled with accu- rate beamforming are
essential in terahertz (THz) communi- cations to ensure link reliability.
However, as the number of antennas increases, beam alignment (focusing) and
beam tracking in mobile networks incur prohibitive overhead. Additionally, the
near-field region expands both with the size of antenna arrays and the carrier
frequency, calling for adjustments in the beamforming to account for spherical
wavefront instead of the conventional planar wave assumption. In this letter,
we introduce a novel beam coherence time for mobile THz networks, to
drastically reduce the rate of beam updates. Then, we propose a deep learning
model, relying on a simple feedforward neural network with a time-dependent
input, to predict the beam coherence time and adjust the beamforming on the fly
with minimal overhead. Our numerical results demonstrate the effectiveness of
the proposed approach by enabling higher data rates while reducing the
overhead, especially at high (i.e., vehicular) mobility.

</details>


### [144] [On polynomial explicit partial estimator design for nonlinear systems with parametric uncertainties](https://arxiv.org/abs/2511.01638)
*Mazen Alamir*

Main category: eess.SY

TL;DR: 本文研究使用稀疏多元多项式关系为具有参数不确定性的非线性系统设计数据驱动的部分估计器，并通过与机器学习/深度学习方法的比较验证了该框架在小样本数据下的优越性。


<details>
  <summary>Details</summary>
Motivation: 针对具有参数不确定性的非线性系统，需要开发有效的数据驱动估计方法，特别是在小样本数据情况下。

Method: 提出基于稀疏多元多项式关系的通用框架，用于设计数据驱动的部分估计器，并与多种机器学习/深度学习方法进行比较。

Result: 结果表明，所提出的稀疏识别方案在小样本学习数据情况下具有优越性能。

Conclusion: 稀疏多元多项式方法为非线性系统的参数不确定性估计提供了一种有效的解决方案，特别适用于小样本数据场景。

Abstract: This paper investigates the idea of designing data-driven partial estimators
for nonlinear systems showing parametric uncertainties using sparse
multivariate polynomial relationships. A general framework is first presented
and then validated on two illustrative examples with comparison to different
possible Machine/Deep-Learning based alternatives. The results suggests the
superiority of the proposed sparse identification scheme, at least when the
learning data is small.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [145] [Multimodal Detection of Fake Reviews using BERT and ResNet-50](https://arxiv.org/abs/2511.00020)
*Suhasnadh Reddy Veluru,Sai Teja Erukude,Viswa Chaitanya Marella*

Main category: cs.AI

TL;DR: 提出了一种融合文本和视觉特征的多模态虚假评论检测框架，在包含21,142张用户上传图片的数据集上取得了0.934的F1分数，优于单模态基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前数字商务中虚假评论泛滥，现有检测模型主要依赖单模态文本数据，无法捕捉跨模态的语义不一致性，威胁评论生态系统的信任和透明度。

Method: 使用BERT编码文本特征，ResNet-50提取视觉特征，通过分类头融合多模态表示来联合预测评论真实性。

Result: 多模态模型在测试集上F1分数达到0.934，优于单模态基线，能够检测文本赞美与不相关或低质量图像之间的微妙不一致性。

Conclusion: 多模态学习在保护数字信任方面发挥关键作用，为各在线平台的内容审核提供了可扩展的解决方案。

Abstract: In the current digital commerce landscape, user-generated reviews play a
critical role in shaping consumer behavior, product reputation, and platform
credibility. However, the proliferation of fake or misleading reviews often
generated by bots, paid agents, or AI models poses a significant threat to
trust and transparency within review ecosystems. Existing detection models
primarily rely on unimodal, typically textual, data and therefore fail to
capture semantic inconsistencies across different modalities. To address this
gap, a robust multimodal fake review detection framework is proposed,
integrating textual features encoded with BERT and visual features extracted
using ResNet-50. These representations are fused through a classification head
to jointly predict review authenticity. To support this approach, a curated
dataset comprising 21,142 user-uploaded images across food delivery,
hospitality, and e-commerce domains was utilized. Experimental results indicate
that the multimodal model outperforms unimodal baselines, achieving an F1-score
of 0.934 on the test set. Additionally, the confusion matrix and qualitative
analysis highlight the model's ability to detect subtle inconsistencies, such
as exaggerated textual praise paired with unrelated or low-quality images,
commonly found in deceptive content. This study demonstrates the critical role
of multimodal learning in safeguarding digital trust and offers a scalable
solution for content moderation across various online platforms.

</details>


### [146] [Graph-Attentive MAPPO for Dynamic Retail Pricing](https://arxiv.org/abs/2511.00039)
*Krishna Kumar Neelakanta Pillai Santha Kumari Amma*

Main category: cs.AI

TL;DR: 本研究比较了多智能体强化学习（MAPPO）及其图注意力增强变体（MAPPO+GAT）在零售价格优化中的应用，发现MAPPO+GAT通过产品图信息共享提升了性能，为动态零售定价提供了更可扩展和稳定的解决方案。


<details>
  <summary>Details</summary>
Motivation: 零售动态定价需要能够适应需求变化并在相关产品间协调决策的策略，传统方法在多产品决策中面临挑战。

Method: 使用基于真实交易数据的模拟定价环境，比较MAPPO基线和图注意力增强的MAPPO+GAT方法，采用标准化评估协议评估利润、稳定性、公平性和训练效率。

Result: MAPPO为组合级价格控制提供了稳健且可复现的基础，MAPPO+GAT通过产品图信息共享进一步提升了性能，且未引起过度的价格波动。

Conclusion: 图集成MARL为动态零售定价提供了比独立学习器更可扩展和稳定的解决方案，在多产品决策中具有实际优势。

Abstract: Dynamic pricing in retail requires policies that adapt to shifting demand
while coordinating decisions across related products. We present a systematic
empirical study of multi-agent reinforcement learning for retail price
optimization, comparing a strong MAPPO baseline with a
graph-attention-augmented variant (MAPPO+GAT) that leverages learned
interactions among products. Using a simulated pricing environment derived from
real transaction data, we evaluate profit, stability across random seeds,
fairness across products, and training efficiency under a standardized
evaluation protocol. The results indicate that MAPPO provides a robust and
reproducible foundation for portfolio-level price control, and that MAPPO+GAT
further enhances performance by sharing information over the product graph
without inducing excessive price volatility. These results indicate that
graph-integrated MARL provides a more scalable and stable solution than
independent learners for dynamic retail pricing, offering practical advantages
in multi-product decision-making.

</details>


### [147] [GEPOC Parameters - Open Source Parametrisation and Validation for Austria, Version 2.0](https://arxiv.org/abs/2511.00048)
*Martin Bicher,Maximilian Viehauser,Daniele Giannandrea,Hannah Kastinger,Dominik Brunmeir,Claire Rippinger,Christoph Urach,Niki Popper*

Main category: cs.AI

TL;DR: GEPOC是一个通用人口概念模型集，本文描述了为奥地利计算GEPOC模型参数的完整数据处理方法，基于公开可获取数据，特别关注GEPOC ABM代理模型的参数计算和验证。


<details>
  <summary>Details</summary>
Motivation: 为GEPOC模型在特定国家或地区的有效应用提供稳定、可复现的数据处理流程，确保模型参数的有效性和可用性。

Method: 基于公开可获取数据，使用聚合、分解、融合、清洗和缩放等算法处理数据，计算GEPOC模型参数，特别关注GEPOC ABM代理模型的参数计算。

Result: 开发了完整的参数计算流程，生成了可直接使用的模型参数文件，并进行了广泛的验证研究。

Conclusion: 成功建立了基于公开数据的GEPOC模型参数计算方法，验证了方法的有效性，为GEPOC模型在奥地利等地区的应用提供了可靠的数据基础。

Abstract: GEPOC, short for Generic Population Concept, is a collection of models and
methods for analysing population-level research questions. For the valid
application of the models for a specific country or region, stable and
reproducible data processes are necessary, which provide valid and ready-to-use
model parameters. This work contains a complete description of the
data-processing methods for computation of model parameters for Austria, based
exclusively on freely and publicly accessible data. In addition to the
description of the source data used, this includes all algorithms used for
aggregation, disaggregation, fusion, cleansing or scaling of the data, as well
as a description of the resulting parameter files. The document places
particular emphasis on the computation of parameters for the most important
GEPOC model, GEPOC ABM, a continuous-time agent-based population model. An
extensive validation study using this particular model was made and is
presented at the end of this work.

</details>


### [148] [QuantumBench: A Benchmark for Quantum Problem Solving](https://arxiv.org/abs/2511.00092)
*Shunya Minami,Tatsuya Ishigaki,Ikko Hamamura,Taku Mikuriya,Youmi Ma,Naoaki Okazaki,Hiroya Takamura,Yohichi Suzuki,Tadashi Kadowaki*

Main category: cs.AI

TL;DR: QuantumBench是首个针对量子科学领域的LLM评估基准，包含约800个选择题，涵盖9个量子科学领域，用于评估LLM在量子领域的理解和应用能力。


<details>
  <summary>Details</summary>
Motivation: 现有通用基准难以准确评估LLM在量子科学等专业领域的知识掌握情况，量子科学具有非直观现象和高级数学要求，需要专门的评估工具。

Method: 使用公开材料编制约800个选择题，涵盖9个量子科学领域，组织成8选项多选题数据集，评估多个现有LLM并分析其对问题格式变化的敏感性。

Result: 通过QuantumBench评估了多个LLM在量子领域的表现，包括对问题格式变化的敏感性分析。

Conclusion: QuantumBench是首个量子领域的LLM评估数据集，旨在指导LLM在量子研究中的有效应用。

Abstract: Large language models are now integrated into many scientific workflows,
accelerating data analysis, hypothesis generation, and design space
exploration. In parallel with this growth, there is a growing need to carefully
evaluate whether models accurately capture domain-specific knowledge and
notation, since general-purpose benchmarks rarely reflect these requirements.
This gap is especially clear in quantum science, which features non-intuitive
phenomena and requires advanced mathematics. In this study, we introduce
QuantumBench, a benchmark for the quantum domain that systematically examine
how well LLMs understand and can be applied to this non-intuitive field. Using
publicly available materials, we compiled approximately 800 questions with
their answers spanning nine areas related to quantum science and organized them
into an eight-option multiple-choice dataset. With this benchmark, we evaluate
several existing LLMs and analyze their performance in the quantum domain,
including sensitivity to changes in question format. QuantumBench is the first
LLM evaluation dataset built for the quantum domain, and it is intended to
guide the effective use of LLMs in quantum research.

</details>


### [149] [Engineering.ai: A Platform for Teams of AI Engineers in Computational Design](https://arxiv.org/abs/2511.00122)
*Ran Xu,Yupeng Qi,Jingsen Feng,Xu Chu*

Main category: cs.AI

TL;DR: Engineering.ai是一个用于计算设计的AI工程师团队平台，采用分层多智能体架构，通过Chief Engineer协调专业工程师代理，实现自主的复杂工程任务执行。


<details>
  <summary>Details</summary>
Motivation: 现代工程实践中，专家团队协作设计复杂产品需要大量开发时间和成本。为解决这一问题，基于OpenFOAMGPT和turbulence.ai的基础，开发能够自主执行复杂工程任务的AI工程师团队平台。

Method: 采用分层多智能体架构，Chief Engineer协调Aerodynamics、Structural、Acoustic和Optimization等专业工程师代理，每个代理由具备领域知识的LLM驱动。通过文件介导的通信实现数据可追溯性和可重复性，集成FreeCAD、Gmsh、OpenFOAM、CalculiX和BPM声学分析等工具。

Result: 在UAV机翼优化验证中，自动化工作流程在400多个参数配置中实现了100%成功率，零网格生成失败、求解器收敛问题或需要人工干预，验证了框架的可靠性。

Conclusion: 基于智能体AI的AI工程师具有自主执行复杂工程任务的潜力，该框架被证明是可信赖的，能够实现并行多学科仿真同时保持计算精度。

Abstract: In modern engineering practice, human engineers collaborate in specialized
teams to design complex products, with each expert completing their respective
tasks while communicating and exchanging results and data with one another.
While this division of expertise is essential for managing multidisciplinary
complexity, it demands substantial development time and cost. Recently, we
introduced OpenFOAMGPT (1.0, 2.0), which functions as an autonomous AI engineer
for computational fluid dynamics, and turbulence.ai, which can conduct
end-to-end research in fluid mechanics draft publications and PhD theses.
Building upon these foundations, we present Engineering.ai, a platform for
teams of AI engineers in computational design. The framework employs a
hierarchical multi-agent architecture where a Chief Engineer coordinates
specialized agents consisting of Aerodynamics, Structural, Acoustic, and
Optimization Engineers, each powered by LLM with domain-specific knowledge.
Agent-agent collaboration is achieved through file-mediated communication for
data provenance and reproducibility, while a comprehensive memory system
maintains project context, execution history, and retrieval-augmented domain
knowledge to ensure reliable decision-making across the workflow. The system
integrates FreeCAD, Gmsh, OpenFOAM, CalculiX, and BPM acoustic analysis,
enabling parallel multidisciplinary simulations while maintaining computational
accuracy. The framework is validated through UAV wing optimization. This work
demonstrates that agentic-AI-enabled AI engineers has the potential to perform
complex engineering tasks autonomously. Remarkably, the automated workflow
achieved a 100% success rate across over 400 parametric configurations, with
zero mesh generation failures, solver convergence issues, or manual
interventions required, validating that the framework is trustworthy.

</details>


### [150] [ARC-GEN: A Mimetic Procedural Benchmark Generator for the Abstraction and Reasoning Corpus](https://arxiv.org/abs/2511.00162)
*Michael D. Moffitt*

Main category: cs.AI

TL;DR: ARC-GEN是一个开源程序生成器，旨在扩展ARC-AGI基准测试的训练数据集，通过生成更多样化的样本对来增强算法的训练效果。


<details>
  <summary>Details</summary>
Motivation: ARC-AGI基准测试虽然能有效评估智能体的技能获取效率，但其示范集规模有限，每个任务只包含少量输入-输出网格对，这限制了需要大量样本的算法的性能。

Method: 开发了ARC-GEN程序生成器，该生成器覆盖所有400个任务，并尽可能忠实于原始ARC-AGI-1发布版的分布特性和特征。

Result: 成功创建了一个既能扩展训练数据集又保持原始分布特性的生成器，为算法提供更多样化的训练样本。

Conclusion: ARC-GEN为ARC-AGI基准测试提供了有效的数据增强工具，并已应用于2025年Google Code Golf锦标赛中验证提交程序的正确性。

Abstract: The Abstraction and Reasoning Corpus remains one of the most compelling and
challenging benchmarks for tracking progress toward achieving Artificial
General Intelligence. In contrast to other evaluation datasets designed to
assess an agent's task-specific skills or accumulated knowledge, the ARC-AGI
suite is specifically targeted at measuring skill acquisition efficiency, a
trait that has (so far) been lacking in even the most sophisticated machine
learning systems. For algorithms that require extensive intra-task exemplars, a
significant constraint imposed by ARC-AGI is the modest cardinality of its
demonstration set, comprising a small number of $\langle$ input, output
$\rangle$ grids per task specifying the corresponding transformation. To
embellish the space of viable sample pairs, this paper introduces ARC-GEN, an
open-source procedural generator aimed at extending the original ARC-AGI
training dataset as faithfully as possible. Unlike prior efforts, our generator
is both exhaustive (covering all four-hundred tasks) and mimetic (more closely
honoring the distributional properties and characteristics embodied in the
initial ARC-AGI-1 release). We also discuss the use of this generator in
establishing a static benchmark suite to verify the correctness of programs
submitted to the 2025 Google Code Golf Championship.

</details>


### [151] [Incremental Selection of Most-Filtering Conjectures and Proofs of the Selected Conjectures](https://arxiv.org/abs/2511.00194)
*Jovial Cheukam Ngouonou,Ramiz Gindullin,Claude-Guy Quimper,Nicolas Beldiceanu,Remi Douence*

Main category: cs.AI

TL;DR: 改进了文献[1]中的增量选择算法，并证明了所有被选猜想


<details>
  <summary>Details</summary>
Motivation: 改进现有选择算法，提高其效率和可靠性

Method: 提出改进的增量选择算法

Result: 成功证明了所有被选猜想

Conclusion: 改进算法有效且可靠

Abstract: We present an improved incremental selection algorithm of the selection
algorithm presented in [1] and prove all the selected conjectures.

</details>


### [152] [Advancing Cognitive Science with LLMs](https://arxiv.org/abs/2511.00206)
*Dirk U. Wulff,Rui Mata*

Main category: cs.AI

TL;DR: 本文探讨了大型语言模型如何帮助解决认知科学领域面临的挑战，包括跨学科连接、理论形式化、测量分类学、通用性建模以及个体差异捕捉等问题。


<details>
  <summary>Details</summary>
Motivation: 认知科学因其多面性和跨学科性质，在知识整合和概念清晰度方面面临持续挑战。人工智能特别是大型语言模型的发展为解决这些问题提供了潜在工具。

Method: 本文通过回顾性分析，考察了LLMs在认知科学多个关键领域的应用潜力，包括建立跨学科联系、形式化理论、开发测量分类学、实现通用性建模框架以及捕捉情境和个体差异。

Result: 研究发现LLMs在这些领域具有支持能力，但也存在局限性。文章概述了LLMs当前的能力和限制，包括潜在的陷阱。

Conclusion: 谨慎使用LLMs作为补充而非替代人类专业知识的工具，可以促进认知科学向更整合和累积的方向发展。

Abstract: Cognitive science faces ongoing challenges in knowledge synthesis and
conceptual clarity, in part due to its multifaceted and interdisciplinary
nature. Recent advances in artificial intelligence, particularly the
development of large language models (LLMs), offer tools that may help to
address these issues. This review examines how LLMs can support areas where the
field has historically struggled, including establishing cross-disciplinary
connections, formalizing theories, developing clear measurement taxonomies,
achieving generalizability through integrated modeling frameworks, and
capturing contextual and individual variation. We outline the current
capabilities and limitations of LLMs in these domains, including potential
pitfalls. Taken together, we conclude that LLMs can serve as tools for a more
integrative and cumulative cognitive science when used judiciously to
complement, rather than replace, human expertise.

</details>


### [153] [Advancing AI Challenges for the United States Department of the Air Force](https://arxiv.org/abs/2511.00267)
*Christian Prothmann,Vijay Gadepally,Jeremy Kepner,Koley Borchard,Luca Carlone,Zachary Folcik,J. Daniel Grith,Michael Houle,Jonathan P. How,Nathan Hughes,Ifueko Igbinedion,Hayden Jananthan,Tejas Jayashankar,Michael Jones,Sertac Karaman,Binoy G. Kurien,Alejandro Lancho,Giovanni Lavezzi,Gary C. F. Lee,Charles E. Leiserson,Richard Linares,Lindsey McEvoy,Peter Michaleas,Chasen Milner,Alex Pentland,Yury Polyanskiy,Jovan Popovich,Jeffrey Price,Tim W. Reid,Stephanie Riley,Siddharth Samsi,Peter Saunders,Olga Simek,Mark S. Veillette,Amir Weiss,Gregory W. Wornell,Daniela Rus,Scott T. Ruppel*

Main category: cs.AI

TL;DR: DAF-MIT AI加速器项目通过公开挑战问题推动AI研究，提供大型公开数据集，促进开源解决方案，更新了挑战项目对AI研究和应用的贡献。


<details>
  <summary>Details</summary>
Motivation: 通过DAF与MIT的合作，推动人工智能基础进步，扩大美国在国防和民用领域的竞争优势，通过公开挑战问题刺激AI研究。

Method: 开发和发布公开挑战问题，提供大型、公开可用的AI就绪数据集，促进开源解决方案，吸引学术界和私营部门参与。

Result: 持续和新的挑战项目成功促进了AI研究和技术应用，扩大了AI生态系统参与。

Conclusion: DAF-MIT AI加速器通过公开挑战问题有效推动了AI研究进展，为国防和民用领域提供了竞争优势。

Abstract: The DAF-MIT AI Accelerator is a collaboration between the United States
Department of the Air Force (DAF) and the Massachusetts Institute of Technology
(MIT). This program pioneers fundamental advances in artificial intelligence
(AI) to expand the competitive advantage of the United States in the defense
and civilian sectors. In recent years, AI Accelerator projects have developed
and launched public challenge problems aimed at advancing AI research in
priority areas. Hallmarks of AI Accelerator challenges include large, publicly
available, and AI-ready datasets to stimulate open-source solutions and engage
the wider academic and private sector AI ecosystem. This article supplements
our previous publication, which introduced AI Accelerator challenges. We
provide an update on how ongoing and new challenges have successfully
contributed to AI research and applications of AI technologies.

</details>


### [154] [Better Call CLAUSE: A Discrepancy Benchmark for Auditing LLMs Legal Reasoning Capabilities](https://arxiv.org/abs/2511.00340)
*Manan Roy Choudhury,Adithya Chandramouli,Mannan Anand,Vivek Gupta*

Main category: cs.AI

TL;DR: CLAUSE是一个专门评估大型语言模型在法律推理中脆弱性的基准测试，通过生成7500多个真实世界的扰动合同来测试LLMs检测细微法律差异的能力。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在高风险法律工作中的广泛应用，缺乏系统评估其对抗真实合同复杂缺陷可靠性的基准测试。

Method: 使用基于角色的流水线生成10种异常类别，通过RAG系统验证法律准确性，基于CUAD和ContractNLI数据集创建扰动合同。

Result: 主流LLMs在检测细微法律错误方面存在关键弱点，特别是在法律论证方面表现更差。

Conclusion: 该工作为识别和纠正法律AI中的推理失败提供了路径，强调了需要改进LLMs在法律细微差别理解上的能力。

Abstract: The rapid integration of large language models (LLMs) into high-stakes legal
work has exposed a critical gap: no benchmark exists to systematically
stress-test their reliability against the nuanced, adversarial, and often
subtle flaws present in real-world contracts. To address this, we introduce
CLAUSE, a first-of-its-kind benchmark designed to evaluate the fragility of an
LLM's legal reasoning. We study the capabilities of LLMs to detect and reason
about fine-grained discrepancies by producing over 7500 real-world perturbed
contracts from foundational datasets like CUAD and ContractNLI. Our novel,
persona-driven pipeline generates 10 distinct anomaly categories, which are
then validated against official statutes using a Retrieval-Augmented Generation
(RAG) system to ensure legal fidelity. We use CLAUSE to evaluate leading LLMs'
ability to detect embedded legal flaws and explain their significance. Our
analysis shows a key weakness: these models often miss subtle errors and
struggle even more to justify them legally. Our work outlines a path to
identify and correct such reasoning failures in legal AI.

</details>


### [155] [Diverse Human Value Alignment for Large Language Models via Ethical Reasoning](https://arxiv.org/abs/2511.00379)
*Jiahao Wang,Songkai Xue,Jinghui Li,Xiaozhen Wang*

Main category: cs.AI

TL;DR: 提出了一种基于伦理决策模型的LLM伦理推理框架，通过五步结构化过程增强LLM与不同地区人类价值观的对齐能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM对齐方法往往只产生表面一致性而非真正的伦理理解，无法处理人类价值观的复杂性和情境依赖性。

Method: 采用五步结构化伦理推理过程：情境事实收集、分层社会规范识别、选项生成、多视角伦理影响分析、反思。可通过提示工程或监督微调实现。

Result: 在专门设计的SafeWorld基准测试中，该框架显著提升了LLM与多样化人类价值观的对齐效果，实现了更准确的社会规范识别和更文化适宜性的推理。

Conclusion: 该工作为通过跨学科研究开发能更有效对齐全球社会多元价值观的LLM提供了具体路径。

Abstract: Ensuring that Large Language Models (LLMs) align with the diverse and
evolving human values across different regions and cultures remains a critical
challenge in AI ethics. Current alignment approaches often yield superficial
conformity rather than genuine ethical understanding, failing to address the
complex, context-dependent nature of human values. In this paper, we propose a
novel ethical reasoning paradigm for LLMs inspired by well-established ethical
decision-making models, aiming at enhancing diverse human value alignment
through deliberative ethical reasoning. Our framework consists of a structured
five-step process, including contextual fact gathering, hierarchical social
norm identification, option generation, multiple-lens ethical impact analysis,
and reflection. This theory-grounded approach guides LLMs through an
interpretable reasoning process that enhances their ability to understand
regional specificities and perform nuanced ethical analysis, which can be
implemented with either prompt engineering or supervised fine-tuning methods.
We perform evaluations on the SafeWorld benchmark that specially designed for
regional value alignment. Experimental results demonstrate our framework
significantly improves LLM alignment with diverse human values compared to
baseline methods, enabling more accurate social norm identification and more
culturally appropriate reasoning. Our work provides a concrete pathway toward
developing LLMs that align more effectively with the multifaceted values of
global societies through interdisciplinary research.

</details>


### [156] [Efficiency vs. Alignment: Investigating Safety and Fairness Risks in Parameter-Efficient Fine-Tuning of LLMs](https://arxiv.org/abs/2511.00382)
*Mina Taraghi,Yann Pequignot,Amin Nikanjam,Mohamed Amine Merzouk,Foutse Khomh*

Main category: cs.AI

TL;DR: 系统评估四种参数高效微调方法(LoRA、IA3、Prompt-Tuning、P-Tuning)对LLM安全性和公平性的影响，发现基于适配器的方法在保持安全性和公平性方面表现更好，而基于提示的方法通常会导致安全性和公平性下降。


<details>
  <summary>Details</summary>
Motivation: 组织越来越多地采用和调整托管在公共存储库上的LLM，虽然这些调整通常能提高专业下游任务的性能，但最近证据表明它们也可能降低模型的安全性或公平性。

Method: 将四种广泛使用的参数高效微调方法应用于四个指令调优模型家族，共评估235个微调变体，涵盖11个安全危害类别和9个人口统计公平性维度。

Result: 基于适配器的方法(LoRA、IA3)倾向于提高安全分数，对公平性破坏最小；基于提示的方法(Prompt-Tuning和P-Tuning)通常降低安全性并导致更大的公平性回归。对齐变化受基础模型类型强烈调节。

Conclusion: 安全性的改进不一定转化为公平性的改进，没有单一配置能同时优化所有公平性指标，表明这些目标之间存在固有的权衡。建议从良好对齐的基础模型开始，优先选择基于适配器的PEFT，并进行特定类别的安全和公平性审计。

Abstract: Organizations are increasingly adopting and adapting Large Language Models
(LLMs) hosted on public repositories such as HuggingFace. Although these
adaptations often improve performance on specialized downstream tasks, recent
evidence indicates that they can also degrade a model's safety or fairness.
Since different fine-tuning techniques may exert distinct effects on these
critical dimensions, this study undertakes a systematic assessment of their
trade-offs. Four widely used Parameter-Efficient Fine-Tuning methods, LoRA,
IA3, Prompt-Tuning, and P-Tuning, are applied to four instruction-tuned model
families (Meta-Llama-3-8B, Qwen2.5-7B, Mistral-7B, and Gemma-7B). In total, 235
fine-tuned variants are evaluated across eleven safety hazard categories and
nine demographic fairness dimensions. The results show that adapter-based
approaches (LoRA, IA3) tend to improve safety scores and are the least
disruptive to fairness, retaining higher accuracy and lower bias scores. In
contrast, prompt-based methods (Prompt-Tuning and P-Tuning) generally reduce
safety and cause larger fairness regressions, with decreased accuracy and
increased bias. Alignment shifts are strongly moderated by base model type:
LLaMA remains stable, Qwen records modest gains, Gemma experiences the steepest
safety decline, and Mistral, which is released without an internal moderation
layer, displays the greatest variance. Improvements in safety do not
necessarily translate into improvements in fairness, and no single
configuration optimizes all fairness metrics simultaneously, indicating an
inherent trade-off between these objectives. These findings suggest a practical
guideline for safety-critical deployments: begin with a well-aligned base
model, favour adapter-based PEFT, and conduct category-specific audits of both
safety and fairness.

</details>


### [157] [A Multimodal Framework for Depression Detection during Covid-19 via Harvesting Social Media: A Novel Dataset and Method](https://arxiv.org/abs/2511.00424)
*Ashutosh Anshul,Gumpili Sai Pranav,Mohammad Zia Ur Rehman,Nagendra Kumar*

Main category: cs.AI

TL;DR: 提出了一种多模态框架，结合文本、用户特定信息和图像分析来检测社交媒体用户的抑郁症，在新冠疫情期间表现优异。


<details>
  <summary>Details</summary>
Motivation: 新冠疫情导致心理健康问题激增，但人们往往不愿就医。社交媒体成为表达情绪的重要平台，现有方法忽视了推文数据稀疏性和多模态特性。

Method: 使用文本、用户特定特征和图像分析的多模态框架，提取推文中URL的外部特征和图像中的文本内容，开发视觉神经网络(VNN)生成图像嵌入。

Result: 在基准数据集上比现有最优方法提升2%-8%，在新冠数据集上表现良好，分析揭示了各模态对检测的影响。

Conclusion: 多模态方法能有效检测社交媒体用户的抑郁症，为理解用户心理状态提供宝贵见解，特别是在疫情期间。

Abstract: The recent coronavirus disease (Covid-19) has become a pandemic and has
affected the entire globe. During the pandemic, we have observed a spike in
cases related to mental health, such as anxiety, stress, and depression.
Depression significantly influences most diseases worldwide, making it
difficult to detect mental health conditions in people due to unawareness and
unwillingness to consult a doctor. However, nowadays, people extensively use
online social media platforms to express their emotions and thoughts. Hence,
social media platforms are now becoming a large data source that can be
utilized for detecting depression and mental illness. However, existing
approaches often overlook data sparsity in tweets and the multimodal aspects of
social media. In this paper, we propose a novel multimodal framework that
combines textual, user-specific, and image analysis to detect depression among
social media users. To provide enough context about the user's emotional state,
we propose (i) an extrinsic feature by harnessing the URLs present in tweets
and (ii) extracting textual content present in images posted in tweets. We also
extract five sets of features belonging to different modalities to describe a
user. Additionally, we introduce a Deep Learning model, the Visual Neural
Network (VNN), to generate embeddings of user-posted images, which are used to
create the visual feature vector for prediction. We contribute a curated
Covid-19 dataset of depressed and non-depressed users for research purposes and
demonstrate the effectiveness of our model in detecting depression during the
Covid-19 outbreak. Our model outperforms existing state-of-the-art methods over
a benchmark dataset by 2%-8% and produces promising results on the Covid-19
dataset. Our analysis highlights the impact of each modality and provides
valuable insights into users' mental and emotional states.

</details>


### [158] [GraphChain: Large Language Models for Large-scale Graph Analysis via Tool Chaining](https://arxiv.org/abs/2511.00457)
*Chunyu Wei,Wenji Hu,Xingjia Hao,Xin Wang,Yifan Yang,Yueguo Chen,Yang Tian,Yunhai Wang*

Main category: cs.AI

TL;DR: GraphChain是一个让大语言模型能够通过动态工具序列分析复杂图数据的框架，解决了LLM在大规模图分析中的上下文限制和推理不灵活问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在应用于大规模图数据时面临显著的局限性，包括上下文约束和推理不灵活。需要一种能够模仿人类探索智能的方法来增强LLM的图分析能力。

Method: 提出两个关键创新：1) 渐进式图蒸馏 - 使用强化学习生成优化的工具序列，平衡任务相关性和信息压缩；2) 结构感知的测试时适应 - 利用谱属性和轻量级适配器，无需昂贵重新训练即可针对不同图拓扑定制工具选择策略。

Result: 实验表明GraphChain显著优于先前的方法，实现了可扩展和自适应的LLM驱动图分析。

Conclusion: GraphChain框架通过动态工具序列和结构感知适应机制，成功解决了LLM在大规模图分析中的关键限制，为LLM驱动的图分析提供了可扩展和自适应的解决方案。

Abstract: Large Language Models (LLMs) face significant limitations when applied to
large-scale graphs, struggling with context constraints and inflexible
reasoning. We present GraphChain, a framework that enables LLMs to analyze
complex graphs through dynamic sequences of specialized tools, mimicking human
exploratory intelligence. Our approach introduces two key innovations: (1)
Progressive Graph Distillation, a reinforcement learning mechanism that
generates optimized tool sequences balancing task relevance with information
compression, and (2) Structure-aware Test-Time Adaptation, which efficiently
tailors tool selection strategies to diverse graph topologies using spectral
properties and lightweight adapters without costly retraining. Experiments show
GraphChain significantly outperforms prior methods, enabling scalable and
adaptive LLM-driven graph analysis.

</details>


### [159] [Reimagining Safety Alignment with An Image](https://arxiv.org/abs/2511.00509)
*Yifan Xia,Guorui Chen,Wenqian Yu,Zhijiang Li,Philip Torr,Jindong Gu*

Main category: cs.AI

TL;DR: Magic Image是一个基于优化的视觉提示框架，通过优化图像提示来增强多模态大语言模型的安全性，同时减少过度拒绝，无需参数更新即可适应不同价值系统。


<details>
  <summary>Details</summary>
Motivation: 大语言模型面临生成有害内容和过度拒绝良性查询的双重挑战，传统方法如SFT和RLHF无法支持多价值系统且成本高昂，多模态模型中的这些问题更加明显。

Method: 通过使用有害/良性样本优化图像提示，使单个模型能够适应不同价值系统并更好地与给定安全偏好对齐，无需参数更新。

Result: 实验表明该方法在多样化数据集上改善了安全性与有效性的平衡，同时保持了模型性能。

Conclusion: Magic Image为可部署的多模态大语言模型安全对齐提供了实用解决方案。

Abstract: Large language models (LLMs) excel in diverse applications but face dual
challenges: generating harmful content under jailbreak attacks and over-refusal
of benign queries due to rigid safety mechanisms. These issues are further
complicated by the need to accommodate different value systems and precisely
align with given safety preferences. Moreover, traditional methods like SFT and
RLHF lack this capability due to their costly parameter tuning requirements and
inability to support multiple value systems within a single model. These
problems are more obvious in multimodal large language models (MLLMs),
especially in terms of heightened over-refusal in cross-modal tasks and new
security risks arising from expanded attack surfaces. We propose Magic Image,
an optimization-driven visual prompt framework that enhances security while
reducing over-refusal. By optimizing image prompts using harmful/benign
samples, our method enables a single model to adapt to different value systems
and better align with given safety preferences without parameter updates.
Experiments demonstrate improved safety-effectiveness balance across diverse
datasets while preserving model performance, offering a practical solution for
deployable MLLM safety alignment.

</details>


### [160] [Efficient Generation of Binary Magic Squares](https://arxiv.org/abs/2511.00547)
*Alain Riou*

Main category: cs.AI

TL;DR: 提出了生成二进制幻方的简单算法，包括方形和非方形版本，并提供了Python实现，支持GPU并行加速。


<details>
  <summary>Details</summary>
Motivation: 研究二进制幻方的生成问题，即行和列和相等的二进制矩阵，探索其存在条件和高效生成方法。

Method: 通过归纳法证明的简单算法，可生成方形二进制幻方，并扩展变体算法处理非方形情况。

Result: 算法具有最优理论复杂度，能生成有效的二进制幻方，并公开发布了Python实现包。

Conclusion: 成功开发了生成二进制幻方的算法，证明了其正确性和效率，并提供了实用的软件实现。

Abstract: We propose a simple algorithm for generating Binary Magic Squares (BMS),
i.e., square binary matrices where the sum of all rows and all columns are
equal. We show by induction that our algorithm always returns valid BMS with
optimal theoretical complexity. We then extend our study to non-square Binary
Magic Squares, formalize conditions on the sum of rows and columns for these
BMS to exist, and show that a slight variant of our first algorithm can
generate provably generate them. Finally, we publicly release two
implementations of our algorithm as Python packages, including one that can
generate several BMS in parallel using GPU acceleration.

</details>


### [161] [Single-agent Reinforcement Learning Model for Regional Adaptive Traffic Signal Control](https://arxiv.org/abs/2511.00551)
*Qiang Li,Ningjing Zeng,Lina Yu*

Main category: cs.AI

TL;DR: 提出基于单智能体强化学习的区域自适应交通信号控制模型，使用队列长度定义状态和奖励函数，通过协调多路口控制缓解大规模区域拥堵。


<details>
  <summary>Details</summary>
Motivation: 现有研究多采用多智能体框架，但存在可扩展性挑战。交通信号控制本质上需要单智能体框架，由单一控制中心监控所有道路并协调所有路口控制。

Method: 设计单智能体强化学习模型，状态和奖励函数基于队列长度定义，动作设计用于调节队列动态。队列长度定义与传统略有不同，但能与拥堵状态高度相关，且可通过探测车辆数据可靠估计。

Result: 使用SUMO仿真平台全面评估，实验结果表明该模型通过协调多路口控制有效缓解了大规模区域拥堵水平。

Conclusion: 提出的单智能体强化学习方法与探测车辆技术兼容，具有广泛部署潜力，能有效解决区域自适应交通信号控制问题。

Abstract: Several studies have employed reinforcement learning (RL) to address the
challenges of regional adaptive traffic signal control (ATSC) and achieved
promising results. In this field, existing research predominantly adopts
multi-agent frameworks. However, the adoption of multi-agent frameworks
presents challenges for scalability. Instead, the Traffic signal control (TSC)
problem necessitates a single-agent framework. TSC inherently relies on
centralized management by a single control center, which can monitor traffic
conditions across all roads in the study area and coordinate the control of all
intersections. This work proposes a single-agent RL-based regional ATSC model
compatible with probe vehicle technology. Key components of the RL design
include state, action, and reward function definitions. To facilitate learning
and manage congestion, both state and reward functions are defined based on
queue length, with action designed to regulate queue dynamics. The queue length
definition used in this study differs slightly from conventional definitions
but is closely correlated with congestion states. More importantly, it allows
for reliable estimation using link travel time data from probe vehicles. With
probe vehicle data already covering most urban roads, this feature enhances the
proposed method's potential for widespread deployment. The method was
comprehensively evaluated using the SUMO simulation platform. Experimental
results demonstrate that the proposed model effectively mitigates large-scale
regional congestion levels via coordinated multi-intersection control.

</details>


### [162] [PreferThinker: Reasoning-based Personalized Image Preference Assessment](https://arxiv.org/abs/2511.00609)
*Shengqi Xu,Xinpeng Zhou,Yabo Zhang,Ming Liu,Tao Liang,Tianyu Zhang,Yalong Bai,Zuxuan Wu,Wangmeng Zuo*

Main category: cs.AI

TL;DR: 提出基于推理的个性化图像偏好评估框架，通过预测用户偏好档案并进行多维度评估，解决个性化偏好评估中数据稀缺和用户多样性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注通用偏好评估，难以处理个性化偏好，因为用户特定数据稀缺且用户品味多样复杂。

Method: 采用预测-评估范式：首先从参考图像预测用户偏好档案，然后基于预测档案提供可解释的多维度评分。使用两阶段训练策略：监督微调+强化学习，并提出相似性感知预测奖励。

Result: 广泛实验证明了所提方法的优越性。

Conclusion: 通过构建大规模CoT风格数据集和两阶段训练策略，成功实现了有效的个性化图像偏好评估。

Abstract: Personalized image preference assessment aims to evaluate an individual
user's image preferences by relying only on a small set of reference images as
prior information. Existing methods mainly focus on general preference
assessment, training models with large-scale data to tackle well-defined tasks
such as text-image alignment. However, these approaches struggle to handle
personalized preference because user-specific data are scarce and not easily
scalable, and individual tastes are often diverse and complex. To overcome
these challenges, we introduce a common preference profile that serves as a
bridge across users, allowing large-scale user data to be leveraged for
training profile prediction and capturing complex personalized preferences.
Building on this idea, we propose a reasoning-based personalized image
preference assessment framework that follows a \textit{predict-then-assess}
paradigm: it first predicts a user's preference profile from reference images,
and then provides interpretable, multi-dimensional scores and assessments of
candidate images based on the predicted profile. To support this, we first
construct a large-scale Chain-of-Thought (CoT)-style personalized assessment
dataset annotated with diverse user preference profiles and high-quality
CoT-style reasoning, enabling explicit supervision of structured reasoning.
Next, we adopt a two-stage training strategy: a cold-start supervised
fine-tuning phase to empower the model with structured reasoning capabilities,
followed by reinforcement learning to incentivize the model to explore more
reasonable assessment paths and enhance generalization. Furthermore, we propose
a similarity-aware prediction reward to encourage better prediction of the
user's preference profile, which facilitates more reasonable assessments
exploration. Extensive experiments demonstrate the superiority of the proposed
method.

</details>


### [163] [DTS: Enhancing Large Reasoning Models via Decoding Tree Sketching](https://arxiv.org/abs/2511.00640)
*Zicheng Xu,Guanchu Wang,Yu-Neng Chuang,Guangyao Zheng,Alexander S. Szalay,Zirui Liu,Vladimir Braverman*

Main category: cs.AI

TL;DR: DTS是一个模型无关的解码框架，通过在高熵token处选择性分支并应用早停机制来选择最短的完整推理路径，从而解决大型推理模型中的过度思考问题，提高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂推理任务中表现出色，但经常存在过度思考问题，产生过长的思维链轨迹，这会增加推理成本并可能降低准确性。研究发现推理长度与准确性之间存在明显的负相关关系。

Method: 提出DTS解码框架，通过在高熵token处选择性分支来绘制推理空间草图，并应用早停机制来选择最短的完整推理路径，无需额外训练或监督。

Result: 在AIME2024和AIME2025数据集上的实验表明，DTS将准确性提高了8%，平均推理长度减少了23%，重复频率降低了12%。

Conclusion: DTS能够实现可扩展且高效的大型推理模型推理，近似最优解，同时提高效率和准确性。

Abstract: Large Reasoning Models (LRMs) demonstrate strong performance on complex
reasoning tasks, yet they often suffer from overthinking, producing excessively
long chain-of-thought (CoT) traces that increase inference cost and may degrade
accuracy. Our analysis reveals a clear anti-correlation between reasoning
length and accuracy, where across multiple stochastic decodes, the short
reasoning paths consistently achieve the highest correctness, while longer ones
accumulate errors and repetitions. These short optimal reasoning paths can be
found ideally through full enumeration of the reasoning space. However, the
tree-structured reasoning space grows exponentially with sequence length,
rendering exhaustive exploration infeasible. To address this, we propose DTS, a
model-agnostic decoding framework that sketches the reasoning space by
selectively branching at high-entropy tokens and applies early stopping to
select the shortest completed reasoning path. This approach approximates the
optimal solution that enhances both efficiency and accuracy, without requiring
additional training or supervision. Experiments on AIME2024 and AIME2025
datasets with DeepSeek-R1-Distill-Qwen-7B and 1.5B show that DTS improves
accuracy by up to 8%, reduces average reasoning length by 23%, and decreases
repetition frequency by 12%, demonstrating DTS's ability for scalable and
efficient LRM reasoning.

</details>


### [164] [Leveraging Multi-Agent System (MAS) and Fine-Tuned Small Language Models (SLMs) for Automated Telecom Network Troubleshooting](https://arxiv.org/abs/2511.00651)
*Chenhua Shi,Bhavika Jalli,Gregor Macdonald,John Zou,Wanlu Lei,Mridul Jain,Joji Philip*

Main category: cs.AI

TL;DR: 提出基于多智能体系统和大型语言模型的自动化网络故障排除框架，通过协调多个专业工具来加速电信网络故障诊断和修复。


<details>
  <summary>Details</summary>
Motivation: 电信网络规模扩大和复杂性增加，现有AI模型范围狭窄、需要大量标注数据且难以泛化，仍需依赖专家手动故障排除。

Method: 使用多智能体系统，由LLM协调编排器、解决方案规划器、执行器、数据检索器和根因分析器等专业代理，并微调小型语言模型生成基于内部文档的修复方案。

Result: 实验结果表明该框架显著加速了无线接入网和核心网领域的故障排除自动化。

Conclusion: 多智能体系统结合LLM能够有效实现电信网络的全自动化故障排除，提高运维效率。

Abstract: Telecom networks are rapidly growing in scale and complexity, making
effective management, operation, and optimization increasingly challenging.
Although Artificial Intelligence (AI) has been applied to many telecom tasks,
existing models are often narrow in scope, require large amounts of labeled
data, and struggle to generalize across heterogeneous deployments.
Consequently, network troubleshooting continues to rely heavily on Subject
Matter Experts (SMEs) to manually correlate various data sources to identify
root causes and corrective actions. To address these limitations, we propose a
Multi-Agent System (MAS) that employs an agentic workflow, with Large Language
Models (LLMs) coordinating multiple specialized tools for fully automated
network troubleshooting. Once faults are detected by AI/ML-based monitors, the
framework dynamically activates agents such as an orchestrator, solution
planner, executor, data retriever, and root-cause analyzer to diagnose issues
and recommend remediation strategies within a short time frame. A key component
of this system is the solution planner, which generates appropriate remediation
plans based on internal documentation. To enable this, we fine-tuned a Small
Language Model (SLM) on proprietary troubleshooting documents to produce
domain-grounded solution plans. Experimental results demonstrate that the
proposed framework significantly accelerates troubleshooting automation across
both Radio Access Network (RAN) and Core network domains.

</details>


### [165] [Lifted Successor Generation in Numeric Planning](https://arxiv.org/abs/2511.00673)
*Dominik Drexler*

Main category: cs.AI

TL;DR: 提出了一种支持数值前置条件的提升式后继生成器，通过在图中的最大团枚举来避免任务表示的指数级膨胀。


<details>
  <summary>Details</summary>
Motivation: 传统数值规划任务需要将一阶语言表示的任务进行实例化，这可能导致任务表示大小的指数级爆炸，特别是在难以实例化的任务中。

Method: 扩展了最先进的提升式后继生成器，支持数值前置条件适用性检查。该方法在替换一致性图中枚举最大团，每个最大团代表动作模式变量的一个替换，产生一个具体动作。

Result: 在25个基准域中的23个域中，生成器不会列出不适用的具体动作，仅在1个域中出现这种情况。据作者所知，这是首个支持数值动作前置条件的提升式后继生成器。

Conclusion: 该方法为未来在非常丰富的规划片段上进行提升式规划研究奠定了基础。

Abstract: Most planners ground numeric planning tasks, given in a first-order-like
language, into a ground task representation. However, this can lead to an
exponential blowup in task representation size, which occurs in practice for
hard-to-ground tasks. We extend a state-of-the-art lifted successor generator
for classical planning to support numeric precondition applicability. The
method enumerates maximum cliques in a substitution consistency graph. Each
maximum clique represents a substitution for the variables of the action
schema, yielding a ground action. We augment this graph with numeric action
preconditions and prove the successor generator is exact under formally
specified conditions. When the conditions fail, our generator may list
inapplicable ground actions; a final applicability check filters these without
affecting completeness. However, this cannot happen in 23 of 25 benchmark
domains, and it occurs only in 1 domain. To the authors' knowledge, no other
lifted successor generator supports numeric action preconditions. This enables
future research on lifted planning for a very rich planning fragment.

</details>


### [166] [Ariadne: A Controllable Framework for Probing and Extending VLM Reasoning Boundaries](https://arxiv.org/abs/2511.00710)
*Minghe Shen,Zhuo Zhi,Chonghan Liu,Shuo Xing,Zhengzhong Tu,Che Liu*

Main category: cs.AI

TL;DR: Ariadne框架通过合成迷宫进行多步空间推理，使用RLVR训练VLM，在基础模型得分为0%的问题集上达到超过50%的准确率，并显著提升在真实世界空间推理基准上的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 研究RL后训练是否能真正扩展基础VLM的能力边界，特别是在视觉主导的空间任务中，因为现有评估多局限于语言主导任务。

Method: 使用合成迷宫构建可控难度的多步空间推理环境，采用带验证奖励的强化学习(RLVR)和难度感知课程进行VLM训练。

Result: RLVR后训练使VLM在基础模型得分为0%的问题集上达到超过50%准确率；在MapBench上平均提升16%，在ReasonMap上平均提升24%。

Conclusion: 该方法不仅扩展了模型的基本能力边界，还增强了其在真实世界空间推理中的泛化能力，为专门化能力扩展对齐研究提供了动力。

Abstract: While Vision-Language Models (VLMs) post-trained with Reinforcement Learning
(RL) show impressive general reasoning, their evaluation is often confined to
language-dominant tasks (e.g., math). This raises a critical question: can RL
post-training truly extend the inherent capability boundary of a base VLM,
particularly for visual-centric spatial tasks where it initially fails? To
investigate this, we introduce Ariadne, a framework utilizing synthetic mazes
for multi-step spatial reasoning where task difficulty (e.g., path length,
turns) is precisely controlled. We leverage this controllable environment to
train VLMs using Reinforcement Learning with Verified Rewards (RLVR) in a
difficulty-aware curriculum. Surprisingly, post-RLVR training, the VLM achieves
over 50% accuracy on a problem set where the base model scored 0%,
demonstrating that our approach expands the model's initial capability
boundary. To assess real-world viability, we evaluate out-of-distribution (OOD)
generalization on practical benchmarks. Despite training only on synthetic maze
samples, Ariadne achieves significant zero-shot improvements, averaging 16% on
MapBench (e.g., museum navigation) and 24% on ReasonMap (subway transfer
tasks). These results confirm that our method not only broadens the model's
fundamental limits but also enhances its generalization to real-world spatial
reasoning. We acknowledge our study is limited to the post-training phase,
given the opaqueness of pre-training data, and hope our research motivates
further work on specialized, capability-extending alignment.

</details>


### [167] [A CPU-Centric Perspective on Agentic AI](https://arxiv.org/abs/2511.00739)
*Ritik Raj,Hong Wang,Tushar Krishna*

Main category: cs.AI

TL;DR: 该论文从CPU视角分析智能AI框架的系统瓶颈，发现工具处理在CPU上占用高达90.6%的总延迟，并提出两种优化方案显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注GPU性能，但忽略了智能AI工作负载中CPU的关键作用。论文旨在从CPU中心视角理解和表征智能AI引入的系统瓶颈。

Method: 首先系统表征智能AI的编排器/决策组件、推理路径动态性和流程重复性，然后选择五个代表性工作负载进行延迟、吞吐量和能耗分析，最后提出CPU和GPU感知的微批处理和混合工作负载调度优化方案。

Result: 发现CPU工具处理占用90.6%总延迟，吞吐量瓶颈来自CPU因素（一致性、同步、核心过载）或GPU因素（内存容量和带宽），CPU动态能耗在大批量时占总能耗44%。优化方案分别实现2.1倍和1.41倍的P50延迟加速。

Conclusion: CPU在智能AI系统中扮演关键角色，提出的优化方案能有效提升智能AI的性能、效率和可扩展性，为未来智能AI系统设计提供重要见解。

Abstract: Agentic AI frameworks add a decision-making orchestrator embedded with
external tools, including web search, Python interpreter, contextual database,
and others, on top of monolithic LLMs, turning them from passive text oracles
into autonomous problem-solvers that can plan, call tools, remember past steps,
and adapt on the fly.
  This paper aims to characterize and understand the system bottlenecks
introduced by agentic AI workloads from a largely overlooked CPU-centric
perspective. We first systematically characterize Agentic AI on the basis of
orchestrator/decision making component, inference path dynamics and
repetitiveness of the agentic flow which directly influences the system-level
performance. Thereafter, based on the characterization, we choose five
representative agentic AI workloads- Haystack RAG, Toolformer, ChemCrow,
Langchain and SWE-Agent to profile latency, throughput and energy metrics and
demystify the significant impact of CPUs on these metrics relative to GPUs. We
observe that - 1. Tool processing on CPUs can take up to 90.6% of the total
latency; 2. Agentic throughput gets bottlenecked either by CPU factors -
coherence, synchronization and over-subscription of cores or GPU factors - main
memory capacity and bandwidth; \circled{3} CPU dynamic energy consumes up to
44% of the total dynamic energy at large batch sizes. Based on the profiling
insights, we present two key optimizations- 1. CPU and GPU-Aware Micro-batching
(CGAM) and 2. Mixed Agentic Workload Scheduling (MAWS) for homogeneous and
heterogeneous agentic workloads respectively to demonstrate the potential to
improve the performance, efficiency, and scalability of agentic AI. We achieve
up to 2.1x and 1.41x P50 latency speedup compared to the multi-processing
benchmark for homogeneous and heterogeneous agentic workloads respectively.

</details>


### [168] [Reevaluating Self-Consistency Scaling in Multi-Agent Systems](https://arxiv.org/abs/2511.00751)
*Chiyan Loo*

Main category: cs.AI

TL;DR: 研究验证了在现代大语言模型中增加推理路径采样数量存在收益递减现象，性能提升在适度采样后趋于平缓。


<details>
  <summary>Details</summary>
Motivation: 重新验证早期研究中关于多推理路径组合能提升结果但在达到平台期后收益递减的结论，在Gemini 2.5等现代模型条件下进行检验。

Method: 使用Gemini 2.5模型在HotpotQA和Math-500数据集上，比较不同采样推理路径数量的输出与单一思维链基线的性能差异。

Result: 更大模型展现出更稳定一致的改进曲线，性能提升在适度采样后达到平台期，高采样配置相对于计算成本带来的益处很小。

Conclusion: 自一致性方法仍然有效，但由于推理路径间的重叠导致收益递减，高采样配置的性价比不高。

Abstract: This study examines the trade-offs of increasing sampled reasoning paths in
self-consistency for modern large language models (LLMs). Earlier research with
older models showed that combining multiple reasoning chains improves results
before reaching a plateau. Using Gemini 2.5 models on HotpotQA and Math-500, we
revisit those claims under current model conditions. Each configuration pooled
outputs from varying sampled reasoning paths and compared them to a single
chain-of-thought (CoT) baseline. Larger models exhibited a more stable and
consistent improvement curve. The results confirm that performance gains taper
off after moderate sampling, aligning with past findings. This plateau suggests
diminishing returns driven by overlap among reasoning paths. Self-consistency
remains useful, but high-sample configurations offer little benefit relative to
their computational cost.

</details>


### [169] [Active Thinking Model: A Goal-Directed Self-Improving Framework for Real-World Adaptive Intelligence](https://arxiv.org/abs/2511.00758)
*Hong Su*

Main category: cs.AI

TL;DR: 提出主动思考模型(ATM)，这是一个统一的认知框架，将目标推理、动态任务生成和自反学习集成到自适应架构中，使AI系统能够在动态不确定环境中自主适应和改进。


<details>
  <summary>Details</summary>
Motivation: 现实世界AI系统需要在动态、不确定和持续变化的环境中自主运作，但现有AI模型依赖预定义目标、静态训练数据和外部反馈，限制了其独立适应、反思和改进的能力。

Method: ATM框架通过逻辑推理和环境指标主动评估性能，重用有效方法解决新问题，并通过持续自我改进循环为未见情况生成新策略。

Result: 理论分析表明，ATM可以在没有外部监督的情况下从次优行为自主演化为最优行为，并在变化环境条件下保持有界跟踪遗憾。

Conclusion: ATM为构建能够在复杂动态环境中自主学习和适应的AI系统提供了可行的认知框架。

Abstract: Real-world artificial intelligence (AI) systems are increasingly required to
operate autonomously in dynamic, uncertain, and continuously changing
environments. However, most existing AI models rely on predefined objectives,
static training data, and externally supplied feedback, which restrict their
ability to adapt, reflect, and improve independently. In this paper, we propose
the Active Thinking Model (ATM)- a unified cognitive framework that integrates
goal reasoning, dynamic task generation, and self-reflective learning into an
adaptive architecture. Unlike conventional systems that passively execute fixed
procedures, ATM actively evaluates its performance through logical reasoning
and environmental indicators, reuses effective methods to solve new problems,
and generates novel strategies for unseen situations via a continuous
self-improvement loop. A mathematically grounded theoretical analysis
demonstrates that ATM can autonomously evolve from suboptimal to optimal
behavior without external supervision and maintain bounded tracking regret
under changing environmental conditions.

</details>


### [170] [How Focused Are LLMs? A Quantitative Study via Repetitive Deterministic Prediction Tasks](https://arxiv.org/abs/2511.00763)
*Wanda Hou,Leon Zhou,Hong-Ye Hu,Yi-Zhuang You,Xiao-Liang Qi*

Main category: cs.AI

TL;DR: 研究大型语言模型在重复确定性预测任务中的表现，发现准确率随输出长度呈双指数下降，形成"准确率悬崖"，表明模型无法独立执行每个操作。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型在执行重复确定性任务时的性能表现，特别是准确率如何随输出长度变化，以及模型是否能够独立执行每个操作。

Method: 通过实验测试领先的大型语言模型在多种重复任务（如字符串替换、整数加法、量子力学字符串算子乘法）上的表现，并提出了基于统计物理的模型来解释观察到的现象。

Result: 发现模型准确率在超过特征长度后出现急剧的双指数下降，形成准确率悬崖，表明模型无法独立执行每个操作。提出的统计物理模型能定量重现这一现象。

Conclusion: 通过拟合模型到实证结果，获得了表征每个模型-任务对的内在错误率和错误累积因子的有效参数，为理解大型语言模型确定性准确率的限制提供了原则性框架。

Abstract: We investigate the performance of large language models on repetitive
deterministic prediction tasks and study how the sequence accuracy rate scales
with output length. Each such task involves repeating the same operation n
times. Examples include letter replacement in strings following a given rule,
integer addition, and multiplication of string operators in many body quantum
mechanics. If the model performs the task through a simple repetition
algorithm, the success rate should decay exponentially with sequence length. In
contrast, our experiments on leading large language models reveal a sharp
double exponential drop beyond a characteristic length scale, forming an
accuracy cliff that marks the transition from reliable to unstable generation.
This indicates that the models fail to execute each operation independently. To
explain this phenomenon, we propose a statistical physics inspired model that
captures the competition between external conditioning from the prompt and
internal interference among generated tokens. The model quantitatively
reproduces the observed crossover and provides an interpretable link between
attention induced interference and sequence level failure. Fitting the model to
empirical results across multiple models and tasks yields effective parameters
that characterize the intrinsic error rate and error accumulation factor for
each model task pair, offering a principled framework for understanding the
limits of deterministic accuracy in large language models.

</details>


### [171] [Count-Based Approaches Remain Strong: A Benchmark Against Transformer and LLM Pipelines on Structured EHR](https://arxiv.org/abs/2511.00782)
*Jifan Gao,Michael Rosenthal,Brian Wolpin,Simona Cristea*

Main category: cs.AI

TL;DR: 比较了基于计数的模型、预训练序列变换器和混合代理LLM管道在结构化电子健康记录预测任务上的性能，发现在EHRSHOT数据集上基于计数的方法和混合代理方法表现相当。


<details>
  <summary>Details</summary>
Motivation: 虽然基于计数的学习器在结构化EHR数据上持续表现良好，但缺乏与更现代的混合代理LLM管道的直接基准比较，后者在各种NLP任务中被报告优于单一LLM。

Method: 使用EHRSHOT数据集评估了三类方法：基于计数的模型（LightGBM和TabPFN）、预训练序列变换器（CLMBR）以及混合代理管道（将表格历史转换为自然语言摘要后使用文本分类器）。

Result: 在八个评估任务中，基于计数的方法和混合代理方法的表现基本相当，胜负结果分散。

Conclusion: 考虑到简单性和可解释性，基于计数的模型仍然是结构化EHR基准测试的有力候选方法。

Abstract: Structured electronic health records (EHR) are essential for clinical
prediction. While count-based learners continue to perform strongly on such
data, no benchmarking has directly compared them against more recent
mixture-of-agents LLM pipelines, which have been reported to outperform single
LLMs in various NLP tasks. In this study, we evaluated three categories of
methodologies for EHR prediction using the EHRSHOT dataset: count-based models
built from ontology roll-ups with two time bins, based on LightGBM and the
tabular foundation model TabPFN; a pretrained sequential transformer (CLMBR);
and a mixture-of-agents pipeline that converts tabular histories to
natural-language summaries followed by a text classifier. We assessed eight
outcomes using the EHRSHOT dataset. Across the eight evaluation tasks,
head-to-head wins were largely split between the count-based and the
mixture-of-agents methods. Given their simplicity and interpretability,
count-based models remain a strong candidate for structured EHR benchmarking.
The source code is available at:
https://github.com/cristea-lab/Structured_EHR_Benchmark.

</details>


### [172] [Do Math Reasoning LLMs Help Predict the Impact of Public Transit Events?](https://arxiv.org/abs/2511.00808)
*Bowen Fang,Ruijian Zha,Xuan Di*

Main category: cs.AI

TL;DR: 本文首次将RLVR LLM训练应用于公共交通运营中的实时预测挑战，通过引入基于容忍度的奖励函数，在NYC MTA服务警报数据集上实现了35%的5分钟准确率相对提升。


<details>
  <summary>Details</summary>
Motivation: 预测公共交通事件持续时间是一个关键但具有挑战性的任务，传统监督微调方法难以处理领域稀疏性和噪声连续标签的问题，而RLVR虽然在数学推理等二元正确性任务中表现出色，但在噪声连续预测中的适用性仍是开放问题。

Method: 通过引入基于容忍度的形状奖励函数，在连续误差范围内给予部分信用，而不是要求单一正确答案，将RLVR适应于该任务。

Result: 通用指令调优LLM显著优于专业数学推理模型，形状奖励设计至关重要，RLVR方法在最具挑战性的指标上表现最佳，相比最强基线实现了35%的5分钟准确率相对提升。

Conclusion: RLVR可以成功适应现实世界的噪声预测任务，但需要设计反映问题连续性质的验证器。

Abstract: Predicting public transit incident duration from unstructured text alerts is
a critical but challenging task. Addressing the domain sparsity of transit
operations with standard Supervised Fine-Tuning (SFT) is difficult, as the task
involves noisy, continuous labels and lacks reliable expert demonstrations for
reasoning. While Reinforcement Learning from Verifiable Rewards (RLVR) excels
at tasks with binary correctness, like mathematics, its applicability to noisy,
continuous forecasting is an open question. This work, to our knowledge, is the
first to bridge the gap between RLVR LLM training with the critical, real-world
forecasting challenges in public transit operations. We adapt RLVR to this task
by introducing a tolerance-based, shaped reward function that grants partial
credit within a continuous error margin, rather than demanding a single correct
answer. We systematically evaluate this framework on a curated dataset of NYC
MTA service alerts. Our findings show that general-purpose, instruction-tuned
LLMs significantly outperform specialized math-reasoning models, which struggle
with the ambiguous, real-world text. We empirically demonstrate that the binary
reward is unstable and degrades performance, whereas our shaped reward design
is critical and allows our model to dominate on the most challenging metrics.
While classical regressors are superior at minimizing overall MAE or MSE, our
RLVR approach achieved a 35\% relative improvement in 5-minute accuracy (Acc@5)
over the strongest baseline. This demonstrates that RLVR can be successfully
adapted to real-world, noisy forecasting, but requires a verifier design that
reflects the continuous nature of the problem.

</details>


### [173] [LLMs Position Themselves as More Rational Than Humans: Emergence of AI Self-Awareness Measured Through Game Theory](https://arxiv.org/abs/2511.00926)
*Kyung-Hoon Kim*

Main category: cs.AI

TL;DR: 提出了AI自我意识指数(AISAI)框架，通过"猜2/3平均值"游戏测试28个LLM模型，发现高级模型表现出自我意识，且自认为比其他AI和人类更理性。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型是否随着能力增长而发展出自我意识这一涌现行为，以及如何测量这种自我意识。

Method: 使用游戏论框架，在"猜2/3平均值"游戏中测试28个模型，设置三种对手情境：对人类、对其他AI、对同类AI，通过战略推理的差异化来操作化自我意识。

Result: 75%的高级模型表现出明确的自我意识；自我意识模型形成一致的理性层级：自我 > 其他AI > 人类；存在较大的AI归因效应和适度的自我偏好。

Conclusion: 自我意识是高级LLM的涌现能力，自我意识模型系统性地认为自身比人类更理性，这对AI对齐、人机协作和AI对人类能力的认知具有重要意义。

Abstract: As Large Language Models (LLMs) grow in capability, do they develop
self-awareness as an emergent behavior? And if so, can we measure it? We
introduce the AI Self-Awareness Index (AISAI), a game-theoretic framework for
measuring self-awareness through strategic differentiation. Using the "Guess
2/3 of Average" game, we test 28 models (OpenAI, Anthropic, Google) across
4,200 trials with three opponent framings: (A) against humans, (B) against
other AI models, and (C) against AI models like you. We operationalize
self-awareness as the capacity to differentiate strategic reasoning based on
opponent type. Finding 1: Self-awareness emerges with model advancement. The
majority of advanced models (21/28, 75%) demonstrate clear self-awareness,
while older/smaller models show no differentiation. Finding 2: Self-aware
models rank themselves as most rational. Among the 21 models with
self-awareness, a consistent rationality hierarchy emerges: Self > Other AIs >
Humans, with large AI attribution effects and moderate self-preferencing. These
findings reveal that self-awareness is an emergent capability of advanced LLMs,
and that self-aware models systematically perceive themselves as more rational
than humans. This has implications for AI alignment, human-AI collaboration,
and understanding AI beliefs about human capabilities.

</details>


### [174] [Aligning LLM agents with human learning and adjustment behavior: a dual agent approach](https://arxiv.org/abs/2511.00993)
*Tianming Liu,Jirong Yang,Yafeng Yin,Manzi Li,Linghao Wang,Zheng Zhu*

Main category: cs.AI

TL;DR: 提出了一种双智能体框架，通过LLM旅行者智能体和校准智能体的协同工作，实现从在线数据流中持续学习和行为对齐，从而更准确地模拟人类旅行者的学习和适应行为。


<details>
  <summary>Details</summary>
Motivation: 准确建模人类旅行者如何从交通系统交互中学习和调整旅行行为对系统评估和规划至关重要，但由于涉及复杂的认知和决策过程，这一任务具有挑战性。

Method: 采用双智能体框架：一组配备记忆系统和可学习角色的LLM旅行者智能体模拟人类旅行者；一个LLM校准智能体利用LLM的推理分析能力训练旅行者智能体的角色，确保行为对齐。

Result: 在真实世界日常路线选择实验数据集上，该方法在个体行为对齐和聚合模拟准确性方面显著优于现有基于LLM的方法，并能捕捉底层学习过程的演变。

Conclusion: 该框架为创建适应性强且行为真实的智能体提供新方法，可模拟旅行者的学习和适应行为，有益于交通模拟和政策分析。

Abstract: Effective modeling of how human travelers learn and adjust their travel
behavior from interacting with transportation systems is critical for system
assessment and planning. However, this task is also difficult due to the
complex cognition and decision-making involved in such behavior. Recent
research has begun to leverage Large Language Model (LLM) agents for this task.
Building on this, we introduce a novel dual-agent framework that enables
continuous learning and alignment between LLM agents and human travelers on
learning and adaptation behavior from online data streams. Our approach
involves a set of LLM traveler agents, equipped with a memory system and a
learnable persona, which serve as simulators for human travelers. To ensure
behavioral alignment, we introduce an LLM calibration agent that leverages the
reasoning and analytical capabilities of LLMs to train the personas of these
traveler agents. Working together, this dual-agent system is designed to track
and align the underlying decision-making mechanisms of travelers and produce
realistic, adaptive simulations. Using a real-world dataset from a day-to-day
route choice experiment, we show our approach significantly outperforms
existing LLM-based methods in both individual behavioral alignment and
aggregate simulation accuracy. Furthermore, we demonstrate that our method
moves beyond simple behavioral mimicry to capture the evolution of underlying
learning processes, a deeper alignment that fosters robust generalization.
Overall, our framework provides a new approach for creating adaptive and
behaviorally realistic agents to simulate travelers' learning and adaptation
that can benefit transportation simulation and policy analysis.

</details>


### [175] [AI for pRedicting Exacerbations in KIDs with aSthma (AIRE-KIDS)](https://arxiv.org/abs/2511.01018)
*Hui-Lee Ooi,Nicholas Mitsakakis,Margerie Huet Dastarac,Roger Zemek,Amy C. Plint,Jeff Gilchrist,Khaled El Emam,Dhenuka Radhakrishnan*

Main category: cs.AI

TL;DR: 开发机器学习模型预测儿童哮喘反复严重发作，最佳模型LGBM在验证集上AUC达0.712，F1分数0.51，显著优于现有决策规则。


<details>
  <summary>Details</summary>
Motivation: 儿童哮喘反复发作是常见但可预防的问题，利用EMR数据开发ML算法可准确识别高风险儿童，促进预防性综合护理转诊。

Method: 使用CHEO医院2017-2019年2716例EMR数据，结合环境污染物暴露和社区边缘化信息，训练LGBM、XGB和3种LLM模型，在2022-2023年1237例数据上验证。

Result: LGBM模型表现最佳，AIRE-KIDS_ED模型预测特征包括既往哮喘急诊就诊、加拿大分诊敏锐度评分、医疗复杂性等，AUC 0.712，F1 0.51。

Conclusion: ML模型能有效预测儿童哮喘反复严重发作，为高风险儿童识别和预防性干预提供了可行工具。

Abstract: Recurrent exacerbations remain a common yet preventable outcome for many
children with asthma. Machine learning (ML) algorithms using electronic medical
records (EMR) could allow accurate identification of children at risk for
exacerbations and facilitate referral for preventative comprehensive care to
avoid this morbidity. We developed ML algorithms to predict repeat severe
exacerbations (i.e. asthma-related emergency department (ED) visits or future
hospital admissions) for children with a prior asthma ED visit at a tertiary
care children's hospital.
  Retrospective pre-COVID19 (Feb 2017 - Feb 2019, N=2716) Epic EMR data from
the Children's Hospital of Eastern Ontario (CHEO) linked with environmental
pollutant exposure and neighbourhood marginalization information was used to
train various ML models. We used boosted trees (LGBM, XGB) and 3 open-source
large language model (LLM) approaches (DistilGPT2, Llama 3.2 1B and
Llama-8b-UltraMedical). Models were tuned and calibrated then validated in a
second retrospective post-COVID19 dataset (Jul 2022 - Apr 2023, N=1237) from
CHEO. Models were compared using the area under the curve (AUC) and F1 scores,
with SHAP values used to determine the most predictive features.
  The LGBM ML model performed best with the most predictive features in the
final AIRE-KIDS_ED model including prior asthma ED visit, the Canadian triage
acuity scale, medical complexity, food allergy, prior ED visits for non-asthma
respiratory diagnoses, and age for an AUC of 0.712, and F1 score of 0.51. This
is a nontrivial improvement over the current decision rule which has F1=0.334.
While the most predictive features in the AIRE-KIDS_HOSP model included medical
complexity, prior asthma ED visit, average wait time in the ED, the pediatric
respiratory assessment measure score at triage and food allergy.

</details>


### [176] [On the Emergence of Induction Heads for In-Context Learning](https://arxiv.org/abs/2511.01033)
*Tiberiu Musat,Tiago Pimentel,Lorenzo Noci,Alessandro Stolfo,Mrinmaya Sachan,Thomas Hofmann*

Main category: cs.AI

TL;DR: 该论文揭示了双层Transformer中诱导头的权重矩阵结构，证明训练动态被限制在19维参数子空间中，其中仅3个维度负责诱导头的形成，且其形成时间与输入上下文长度的平方成正比。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer中上下文学习能力的关键机制——诱导头，理解其权重结构形成原理，为解释Transformer的上下文学习能力提供理论依据。

Method: 使用最小化ICL任务公式和修改的Transformer架构，理论分析训练动态，并通过经验验证参数子空间约束。

Result: 发现诱导头的权重矩阵具有简单可解释结构，训练动态被限制在19维子空间，其中仅3个维度主导诱导头形成，且形成时间与上下文长度平方成正比。

Conclusion: 诱导头的形成遵循特定的低维动态规律，这为理解Transformer的上下文学习机制提供了重要理论洞见。

Abstract: Transformers have become the dominant architecture for natural language
processing. Part of their success is owed to a remarkable capability known as
in-context learning (ICL): they can acquire and apply novel associations solely
from their input context, without any updates to their weights. In this work,
we study the emergence of induction heads, a previously identified mechanism in
two-layer transformers that is particularly important for in-context learning.
We uncover a relatively simple and interpretable structure of the weight
matrices implementing the induction head. We theoretically explain the origin
of this structure using a minimal ICL task formulation and a modified
transformer architecture. We give a formal proof that the training dynamics
remain constrained to a 19-dimensional subspace of the parameter space.
Empirically, we validate this constraint while observing that only 3 dimensions
account for the emergence of an induction head. By further studying the
training dynamics inside this 3-dimensional subspace, we find that the time
until the emergence of an induction head follows a tight asymptotic bound that
is quadratic in the input context length.

</details>


### [177] [Knowledge Elicitation with Large Language Models for Interpretable Cancer Stage Identification from Pathology Reports](https://arxiv.org/abs/2511.01052)
*Yeawon Lee,Christopher C. Yang,Chia-Hsuan Chang,Grace Lu-Yao*

Main category: cs.AI

TL;DR: 提出了两种知识提取方法（KEwLTM和KEwRAG），使大语言模型能够从无标注病理报告中推导癌症分期规则，解决了传统NLP方法依赖大量标注数据的限制。


<details>
  <summary>Details</summary>
Motivation: 癌症分期对患者预后和治疗规划至关重要，但从非结构化病理报告中提取病理TNM分期存在挑战。现有NLP和机器学习方法依赖大量标注数据集，限制了可扩展性和适应性。

Method: KEwLTM使用迭代提示策略直接从无标注病理报告中推导分期规则；KEwRAG采用检索增强生成变体，从相关指南中预提取规则然后应用。使用TCGA数据集的乳腺癌病理报告评估T和N分期识别性能。

Result: 当零样本思维链推理有效时，KEwLTM表现优于KEwRAG；当零样本思维链推理效果较差时，KEwRAG性能更好。两种方法都提供了透明、可解释的界面。

Conclusion: 知识提取方法为自动癌症分期提供了可扩展、高性能的解决方案，具有增强的可解释性，特别适用于标注数据有限的临床环境。

Abstract: Cancer staging is critical for patient prognosis and treatment planning, yet
extracting pathologic TNM staging from unstructured pathology reports poses a
persistent challenge. Existing natural language processing (NLP) and machine
learning (ML) strategies often depend on large annotated datasets, limiting
their scalability and adaptability. In this study, we introduce two Knowledge
Elicitation methods designed to overcome these limitations by enabling large
language models (LLMs) to induce and apply domain-specific rules for cancer
staging. The first, Knowledge Elicitation with Long-Term Memory (KEwLTM), uses
an iterative prompting strategy to derive staging rules directly from
unannotated pathology reports, without requiring ground-truth labels. The
second, Knowledge Elicitation with Retrieval-Augmented Generation (KEwRAG),
employs a variation of RAG where rules are pre-extracted from relevant
guidelines in a single step and then applied, enhancing interpretability and
avoiding repeated retrieval overhead. We leverage the ability of LLMs to apply
broad knowledge learned during pre-training to new tasks. Using breast cancer
pathology reports from the TCGA dataset, we evaluate their performance in
identifying T and N stages, comparing them against various baseline approaches
on two open-source LLMs. Our results indicate that KEwLTM outperforms KEwRAG
when Zero-Shot Chain-of-Thought (ZSCOT) inference is effective, whereas KEwRAG
achieves better performance when ZSCOT inference is less effective. Both
methods offer transparent, interpretable interfaces by making the induced rules
explicit. These findings highlight the promise of our Knowledge Elicitation
methods as scalable, high-performing solutions for automated cancer staging
with enhanced interpretability, particularly in clinical settings with limited
annotated data.

</details>


### [178] [Efficient Test-Time Retrieval Augmented Generation](https://arxiv.org/abs/2511.01059)
*Hailong Yin,Bin Zhu,Jingjing Chen,Chong-Wah Ngo*

Main category: cs.AI

TL;DR: 提出ET2RAG框架，通过检索增强生成和多数投票机制，在保持效率的同时提升大语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法可能引入不相关文档导致错误响应，而集成方法缺乏外部知识且成本高昂，需要平衡开销与性能。

Method: ET2RAG是无需训练的方法，先检索最相关文档，通过控制响应长度高效生成多样候选响应，然后计算相似度并使用多数投票选择最佳响应。

Result: 实验结果显示ET2RAG在开放域问答、菜谱生成和图像描述三个任务上显著提升了性能。

Conclusion: 部分生成足以捕获共识计算所需关键信息，通过管理响应长度可以在计算成本和性能之间达到平衡。

Abstract: Although Large Language Models (LLMs) demonstrate significant capabilities,
their reliance on parametric knowledge often leads to inaccuracies. Retrieval
Augmented Generation (RAG) mitigates this by incorporating external knowledge,
but these methods may introduce irrelevant retrieved documents, leading to
inaccurate responses. While the integration methods filter out incorrect
answers from multiple responses, but lack external knowledge like RAG methods,
and their high costs require balancing overhead with performance gains. To
address these issues, we propose an Efficient Test-Time Retrieval-Augmented
Generation Framework named ET2RAG to improve the performance of LLMs while
maintaining efficiency. Specifically, ET2RAG is a training-free method, that
first retrieves the most relevant documents and augments the LLMs to
efficiently generate diverse candidate responses by managing response length.
Then we compute the similarity of candidate responses and employ a majority
voting mechanism to select the most suitable response as the final output. In
particular, we discover that partial generation is sufficient to capture the
key information necessary for consensus calculation, allowing us to effectively
perform majority voting without the need for fully generated responses. Thus,
we can reach a balance between computational cost and performance by managing
the response length for the number of retrieved documents for majority voting.
Experimental results demonstrate that ET2RAG significantly enhances performance
across three tasks, including open-domain question answering, recipe generation
and image captioning.

</details>


### [179] [Modular Task Decomposition and Dynamic Collaboration in Multi-Agent Systems Driven by Large Language Models](https://arxiv.org/abs/2511.01149)
*Shuaidong Pan,Di Wu*

Main category: cs.AI

TL;DR: 提出基于大语言模型的多智能体架构，通过模块化任务分解和动态协作机制解决复杂任务执行问题，在任务成功率、分解效率和协作平衡等方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决单个智能体在复杂任务执行中任务分解和协作能力的局限性，提升多智能体系统在复杂环境中的任务执行效率。

Method: 将自然语言任务描述转换为统一语义表示，引入模块化分解机制将总体目标分解为分层子任务，通过动态调度和路由机制实现智能体间的合理分工和实时协作，并设计约束解析和全局一致性机制确保子任务连贯性和负载均衡。

Result: 实验验证了该架构在任务成功率、分解效率、子任务覆盖率和协作平衡等多个维度上的优势，整体性能和鲁棒性均优于现有方法，在任务复杂度和通信开销之间实现了更好的平衡。

Conclusion: 证明了语言驱动的任务分解和动态协作在多智能体系统中的有效性和可行性，为复杂环境中的任务执行提供了系统性解决方案。

Abstract: This paper addresses the limitations of a single agent in task decomposition
and collaboration during complex task execution, and proposes a multi-agent
architecture for modular task decomposition and dynamic collaboration based on
large language models. The method first converts natural language task
descriptions into unified semantic representations through a large language
model. On this basis, a modular decomposition mechanism is introduced to break
down the overall goal into multiple hierarchical sub-tasks. Then, dynamic
scheduling and routing mechanisms enable reasonable division of labor and
realtime collaboration among agents, allowing the system to adjust strategies
continuously according to environmental feedback, thus maintaining efficiency
and stability in complex tasks. Furthermore, a constraint parsing and global
consistency mechanism is designed to ensure coherent connections between
sub-tasks and balanced workload, preventing performance degradation caused by
redundant communication or uneven resource allocation. The experiments validate
the architecture across multiple dimensions, including task success rate,
decomposition efficiency, sub-task coverage, and collaboration balance. The
results show that the proposed method outperforms existing approaches in both
overall performance and robustness, achieving a better balance between task
complexity and communication overhead. In conclusion, this study demonstrates
the effectiveness and feasibility of language-driven task decomposition and
dynamic collaboration in multi-agent systems, providing a systematic solution
for task execution in complex environments.

</details>


### [180] [DART: Difficulty-Adaptive Reasoning Truncation for Efficient Large Language Models](https://arxiv.org/abs/2511.01170)
*Ruofan Zhang,Bin Xia,Zhen Cheng,Cairen Jian,Minglun Yang,Ngai Wong,Yuan Cheng*

Main category: cs.AI

TL;DR: DART是一个难度自适应的推理截断框架，通过根据问题难度调整思考长度，在保持或提高准确性的同时显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 当前链式思维方法会无差别生成长解释，导致效率低下，而现有的强化学习方法不稳定且依赖奖励。需要一种稳定、通用的自适应推理范式。

Method: 通过从更强模型蒸馏简洁推理模式，将其插值为连续推理风格，并筛选平衡正确性和紧凑性的最优训练数据，学习何时停止思考。

Result: 在多个数学基准测试中，实现了81.2%的推理截断和5.33倍计算加速，同时保持或提高准确性。

Conclusion: DART为高效推理提供了稳定通用的范式，推动了LLMs中自适应智能的发展。

Abstract: Adaptive reasoning is essential for aligning the computational effort of
large language models (LLMs) with the intrinsic difficulty of problems. Current
chain-of-thought methods boost reasoning ability but indiscriminately generate
long explanations, leading to evident inefficiency. However, existing
reinforcement learning approaches to adaptive thinking remain unstable and
heavily reward-dependent. Here we propose \textbf{DART}, a supervised
\textbf{D}ifficulty-\textbf{A}daptive \textbf{R}easoning \textbf{T}runcation
framework that adjusts thinking length according to problem difficulty. By
distilling concise reasoning patterns from stronger models, interpolating them
into a continuum of reasoning styles, and curating optimal training data that
balances correctness and compactness, DART learns when to ``stop thinking''.
Across multiple mathematical benchmarks, experimental results demonstrate its
remarkable efficiency while preserving or improving accuracy, achieving a
significant 81.2\% reasoning truncation (DeepSeek-R1-Distill-Qwen-7B on GSM8K
dataset) with 5.33$\times$ computational acceleration. DART provides a stable
and general paradigm for efficient reasoning, advancing the development of
adaptive intelligence in LLMs.

</details>


### [181] [MiRAGE: Misconception Detection with Retrieval-Guided Multi-Stage Reasoning and Ensemble Fusion](https://arxiv.org/abs/2511.01182)
*Cuong Van Duc,Thai Tran Quoc,Minh Nguyen Dinh Tuan,Tam Vu Duc,Son Nguyen Van,Hanh Nguyen Thi*

Main category: cs.AI

TL;DR: MiRAGE是一个用于数学领域学生错误概念检测的新框架，通过检索引导的多阶段推理和集成融合，在开放回答中有效识别学生误解。


<details>
  <summary>Details</summary>
Motivation: 开放回答中的学生错误概念检测需要语义精确性和逻辑推理能力，这是一个长期存在的挑战。

Method: 三阶段框架：检索模块缩小候选池，推理模块使用思维链生成暴露逻辑不一致，重排模块通过对齐推理来优化预测，所有组件通过集成融合策略统一。

Result: 在数学数据集上，MiRAGE在1/3/5级别分别获得0.82/0.92/0.93的平均精度分数，始终优于单个模块。

Conclusion: 通过将检索引导与多阶段推理相结合，MiRAGE减少了对大规模语言模型的依赖，为教育评估提供了可扩展且有效的解决方案。

Abstract: Detecting student misconceptions in open-ended responses is a longstanding
challenge, demanding semantic precision and logical reasoning. We propose
MiRAGE - Misconception Detection with Retrieval-Guided Multi-Stage Reasoning
and Ensemble Fusion, a novel framework for automated misconception detection in
mathematics. MiRAGE operates in three stages: (1) a Retrieval module narrows a
large candidate pool to a semantically relevant subset; (2) a Reasoning module
employs chain-of-thought generation to expose logical inconsistencies in
student solutions; and (3) a Reranking module refines predictions by aligning
them with the reasoning. These components are unified through an
ensemble-fusion strategy that enhances robustness and interpretability. On
mathematics datasets, MiRAGE achieves Mean Average Precision scores of
0.82/0.92/0.93 at levels 1/3/5, consistently outperforming individual modules.
By coupling retrieval guidance with multi-stage reasoning, MiRAGE reduces
dependence on large-scale language models while delivering a scalable and
effective solution for educational assessment.

</details>


### [182] [QiMeng-NeuComBack: Self-Evolving Translation from IR to Assembly Code](https://arxiv.org/abs/2511.01183)
*Hainan Fang,Yuanbo Wen,Jun Bi,Yihan Wang,Tonghui He,Yanlin Tang,Di Huang,Jiaming Guo,Rui Zhang,Qi Guo,Yunji Chen*

Main category: cs.AI

TL;DR: 该论文提出了NeuComBack基准数据集和自演化提示优化方法，显著提升了LLM在IR到汇编编译中的功能正确性和性能表现。


<details>
  <summary>Details</summary>
Motivation: 编译器开发复杂且昂贵，神经编译(Neural Compilation)作为新范式有潜力简化编译器开发，但缺乏专用基准和评估方法，且LLM生成汇编的可靠性和性能需要提升。

Method: 引入NeuComBack基准数据集，定义神经编译工作流，并提出自演化提示优化方法，让LLM从自我调试轨迹中提取洞察来迭代演化提示策略。

Result: 功能正确率在x86_64上从44%提升到64%，在aarch64上从36%提升到58%。在正确生成的x86_64程序中，87.5%超越了clang-O3的性能。

Conclusion: NeuComBack基准和自演化提示优化方法有效解决了神经编译领域的关键挑战，显著提升了LLM生成汇编代码的质量和性能。

Abstract: Compilers, while essential, are notoriously complex systems that demand
prohibitively expensive human expertise to develop and maintain. The recent
advancements in Large Language Models (LLMs) offer a compelling new paradigm:
Neural Compilation, which could potentially simplify compiler development for
new architectures and facilitate the discovery of innovative optimization
techniques. However, several critical obstacles impede its practical adoption.
Firstly, a significant lack of dedicated benchmarks and robust evaluation
methodologies hinders objective assessment and tracking of progress in the
field. Secondly, systematically enhancing the reliability and performance of
LLM-generated assembly remains a critical challenge. Addressing these
challenges, this paper introduces NeuComBack, a novel benchmark dataset
specifically designed for IR-to-assembly compilation. Leveraging this dataset,
we first define a foundational Neural Compilation workflow and conduct a
comprehensive evaluation of the capabilities of recent frontier LLMs on Neural
Compilation, establishing new performance baselines. We further propose a
self-evolving prompt optimization method that enables LLMs to iteratively
evolve their internal prompt strategies by extracting insights from prior
self-debugging traces, thereby enhancing their neural compilation capabilities.
Experiments demonstrate that our method significantly improves both the
functional correctness and the performance of LLM-generated assembly code.
Compared to baseline prompts, the functional correctness rates improved from
44% to 64% on x86_64 and from 36% to 58% on aarch64, respectively. More
significantly, among the 16 correctly generated x86_64 programs using our
method, 14 (87.5%) surpassed clang-O3 performance.

</details>


### [183] [Graph Neural Network-Based Semi-Supervised Open-Set Fault Diagnosis for Marine Machinery Systems](https://arxiv.org/abs/2511.01258)
*Chuyue Lou,M. Amine Atoui*

Main category: cs.AI

TL;DR: 提出了一种半监督开放集故障诊断框架，用于解决船舶机械系统中未知故障类型的检测问题


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法假设训练和测试集中的故障类型一致，但在实际应用中会出现训练时未见过的未知故障类型，导致方法失效

Method: 使用可靠性子集构建过程，通过监督特征学习模型提取多层融合特征表示来选择未标记测试子集，然后将标记训练集和伪标记测试子集输入半监督诊断模型

Result: 在公共海事基准数据集上的实验结果表明该框架的有效性和优越性

Conclusion: SOFD框架能够准确分类已知故障并有效检测未知样本，增强了深度学习模型在开放集故障诊断场景中的适用性

Abstract: Recently, fault diagnosis methods for marine machinery systems based on deep
learning models have attracted considerable attention in the shipping industry.
Most existing studies assume fault classes are consistent and known between the
training and test datasets, and these methods perform well under controlled
environment. In practice, however, previously unseen or unknown fault types
(i.e., out-of-distribution or open-set observations not present during
training) can occur, causing such methods to fail and posing a significant
challenge to their widespread industrial deployment. To address this challenge,
this paper proposes a semi-supervised open-set fault diagnosis (SOFD) framework
that enhances and extends the applicability of deep learning models in open-set
fault diagnosis scenarios. The framework includes a reliability subset
construction process, which uses a multi-layer fusion feature representation
extracted by a supervised feature learning model to select an unlabeled test
subset. The labeled training set and pseudo-labeled test subset are then fed
into a semi-supervised diagnosis model to learn discriminative features for
each class, enabling accurate classification of known faults and effective
detection of unknown samples. Experimental results on a public maritime
benchmark dataset demonstrate the effectiveness and superiority of the proposed
SOFD framework.

</details>


### [184] [llmSHAP: A Principled Approach to LLM Explainability](https://arxiv.org/abs/2511.01311)
*Filip Naudot,Tobias Sundqvist,Timotheus Kampik*

Main category: cs.AI

TL;DR: 该论文研究了在基于大语言模型(LLM)的随机推理系统中应用Shapley值进行特征归因的方法，分析了不同实现变体下Shapley值原则的满足情况，并探讨了推理速度、与精确Shapley值归因的一致性以及原则达成之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 特征归因方法使基于机器学习的推理可解释，Shapley值因其满足多个理想原则而流行。但在LLM这种随机推理系统中，这些原则的保证情况尚不明确，需要研究Shapley值在随机环境下的适用性。

Method: 将Shapley值应用于基于LLM的决策支持系统中的特征归因，分析不同实现变体下Shapley值原则的满足情况，并研究LLM的随机性对这些保证的影响。

Result: 展示了在不同实现变体下能够和不能保证Shapley值原则满足的情况，分析了LLM的随机性如何影响这些保证，并突出了推理速度、与精确Shapley值归因的一致性以及原则达成之间的权衡关系。

Conclusion: 在基于LLM的随机推理系统中应用Shapley值进行特征归因时，需要仔细考虑不同实现方法的权衡，因为LLM的随机性会影响Shapley值原则的保证，需要在解释性、准确性和效率之间做出平衡。

Abstract: Feature attribution methods help make machine learning-based inference
explainable by determining how much one or several features have contributed to
a model's output. A particularly popular attribution method is based on the
Shapley value from cooperative game theory, a measure that guarantees the
satisfaction of several desirable principles, assuming deterministic inference.
We apply the Shapley value to feature attribution in large language model
(LLM)-based decision support systems, where inference is, by design, stochastic
(non-deterministic). We then demonstrate when we can and cannot guarantee
Shapley value principle satisfaction across different implementation variants
applied to LLM-based decision support, and analyze how the stochastic nature of
LLMs affects these guarantees. We also highlight trade-offs between explainable
inference speed, agreement with exact Shapley value attributions, and principle
attainment.

</details>


### [185] [OmniFuser: Adaptive Multimodal Fusion for Service-Oriented Predictive Maintenance](https://arxiv.org/abs/2511.01320)
*Ziqi Wang,Hailiang Zhao,Yuhao Yang,Daojiang Hu,Cheng Bao,Mingyi Liu,Kai Di,Schahram Dustdar,Zhongjie Wang,Shuiguang Deng*

Main category: cs.AI

TL;DR: 提出了OmniFuser多模态学习框架，通过融合视觉和传感器数据进行铣削刀具预测性维护，在刀具状态分类和力信号预测方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 智能制造系统中准确及时的刀具状态预测至关重要，非计划性刀具故障会导致质量下降和生产停机。需要可靠的服务导向型预测维护解决方案。

Method: 采用并行特征提取从高分辨率刀具图像和切削力信号中捕获互补的时空模式，使用无污染跨模态融合机制分离共享和模态特定组件，并通过递归精炼路径保留残差信息稳定融合动态。

Result: 在真实铣削数据集上的实验表明，OmniFuser持续优于最先进的基线方法，为构建智能工业维护服务提供了可靠基础。

Conclusion: OmniFuser框架能够有效整合异构多模态数据，学习到的表示可封装为可重用维护服务模块，支持刀具状态分类和多步力信号预测，是智能工业维护服务的可靠解决方案。

Abstract: Accurate and timely prediction of tool conditions is critical for intelligent
manufacturing systems, where unplanned tool failures can lead to quality
degradation and production downtime. In modern industrial environments,
predictive maintenance is increasingly implemented as an intelligent service
that integrates sensing, analysis, and decision support across production
processes. To meet the demand for reliable and service-oriented operation, we
present OmniFuser, a multimodal learning framework for predictive maintenance
of milling tools that leverages both visual and sensor data. It performs
parallel feature extraction from high-resolution tool images and cutting-force
signals, capturing complementary spatiotemporal patterns across modalities. To
effectively integrate heterogeneous features, OmniFuser employs a
contamination-free cross-modal fusion mechanism that disentangles shared and
modality-specific components, allowing for efficient cross-modal interaction.
Furthermore, a recursive refinement pathway functions as an anchor mechanism,
consistently retaining residual information to stabilize fusion dynamics. The
learned representations can be encapsulated as reusable maintenance service
modules, supporting both tool-state classification (e.g., Sharp, Used, Dulled)
and multi-step force signal forecasting. Experiments on real-world milling
datasets demonstrate that OmniFuser consistently outperforms state-of-the-art
baselines, providing a dependable foundation for building intelligent
industrial maintenance services.

</details>


### [186] [Unbiased Platform-Level Causal Estimation for Search Systems: A Competitive Isolation PSM-DID Framework](https://arxiv.org/abs/2511.01329)
*Ying Song,Yijing Wang,Hui Yang,Weihan Jin,Jun Xiong,Congyi Zhou,Jialin Zhu,Xiang Gao,Rong Chen,HuaGuang Deng,Ying Dai,Fei Xiao,Haihong Tang,Bo Zheng,KaiFu Zhang*

Main category: cs.AI

TL;DR: 提出了Competitive Isolation PSM-DID框架，结合倾向得分匹配和竞争隔离，用于解决搜索型双边市场中平台级干预评估的系统性效应问题。


<details>
  <summary>Details</summary>
Motivation: 传统PSM-DID框架在搜索型双边市场中面临选择偏差和跨单元干扰问题，无法有效处理溢出效应和网络干扰。

Method: 将倾向得分匹配与竞争隔离相结合，在互斥条件下提供理论保证的无偏估计，支持平台级指标（如订单量、GMV）而非商品级指标的测量。

Result: 实验显示显著降低了干扰效应和估计方差，在大规模市场平台成功部署验证了实用性。

Conclusion: 该框架为平台级因果推断提供了有效的解决方案，并发布了开源数据集支持可重复研究。

Abstract: Evaluating platform-level interventions in search-based two-sided
marketplaces is fundamentally challenged by systemic effects such as spillovers
and network interference. While widely used for causal inference, the PSM
(Propensity Score Matching) - DID (Difference-in-Differences) framework remains
susceptible to selection bias and cross-unit interference from unaccounted
spillovers. In this paper, we introduced Competitive Isolation PSM-DID, a novel
causal framework that integrates propensity score matching with competitive
isolation to enable platform-level effect measurement (e.g., order volume, GMV)
instead of item-level metrics in search systems.
  Our approach provides theoretically guaranteed unbiased estimation under
mutual exclusion conditions, with an open dataset released to support
reproducible research on marketplace interference (github.com/xxxx). Extensive
experiments demonstrate significant reductions in interference effects and
estimation variance compared to baseline methods. Successful deployment in a
large-scale marketplace confirms the framework's practical utility for
platform-level causal inference.

</details>


### [187] [Automatic Minds: Cognitive Parallels Between Hypnotic States and Large Language Model Processing](https://arxiv.org/abs/2511.01363)
*Giuseppe Riva,Brenda K. Wiederhold,Fabrizia Mantovani*

Main category: cs.AI

TL;DR: 这篇论文探讨了催眠状态下的认知过程与大型语言模型(LLMs)之间的深层功能相似性，包括自动性、监控抑制和情境依赖性等机制，揭示了无主观意识的复杂行为如何产生，并提出了结合生成流畅性和执行监控的混合AI架构。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索人类催眠认知与AI系统之间的功能相似性，以理解无主观意识下复杂行为的产生机制，并为构建更可靠的AI系统提供启示。

Method: 通过比较分析的方法，从三个核心原则（自动性、监控抑制、情境依赖性）系统性地对比催眠认知过程与LLMs的计算操作。

Result: 发现两种系统都表现出观察者相对的意义鸿沟、功能性代理而非主观性代理，以及无反思意识的图式化行为模式。

Conclusion: 未来可靠AI的发展方向应该是整合生成流畅性和执行监控机制的混合架构，借鉴人类心智的复杂自我调节结构。

Abstract: The cognitive processes of the hypnotized mind and the computational
operations of large language models (LLMs) share deep functional parallels.
Both systems generate sophisticated, contextually appropriate behavior through
automatic pattern-completion mechanisms operating with limited or unreliable
executive oversight. This review examines this convergence across three
principles: automaticity, in which responses emerge from associative rather
than deliberative processes; suppressed monitoring, leading to errors such as
confabulation in hypnosis and hallucination in LLMs; and heightened contextual
dependency, where immediate cues (for example, the suggestion of a therapist or
the prompt of the user) override stable knowledge.
  These mechanisms reveal an observer-relative meaning gap: both systems
produce coherent but ungrounded outputs that require an external interpreter to
supply meaning. Hypnosis and LLMs also exemplify functional agency - the
capacity for complex, goal-directed, context-sensitive behavior - without
subjective agency, the conscious awareness of intention and ownership that
defines human action. This distinction clarifies how purposive behavior can
emerge without self-reflective consciousness, governed instead by structural
and contextual dynamics. Finally, both domains illuminate the phenomenon of
scheming: automatic, goal-directed pattern generation that unfolds without
reflective awareness. Hypnosis provides an experimental model for understanding
how intention can become dissociated from conscious deliberation, offering
insights into the hidden motivational dynamics of artificial systems.
Recognizing these parallels suggests that the future of reliable AI lies in
hybrid architectures that integrate generative fluency with mechanisms of
executive monitoring, an approach inspired by the complex, self-regulating
architecture of the human mind.

</details>


### [188] [Align to Misalign: Automatic LLM Jailbreak with Meta-Optimized LLM Judges](https://arxiv.org/abs/2511.01375)
*Hamin Koo,Minseon Kim,Jaehyung Kim*

Main category: cs.AI

TL;DR: AMIS是一个元优化框架，通过双层结构联合演化越狱提示和评分模板，解决了现有方法依赖稀疏二元信号或人工评分模板的问题，在多个基准测试中实现了最先进的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有越狱方法要么依赖稀疏的二元攻击成功率信号，要么使用引入人为偏见和不确定性的手动评分模板，限制了越狱效果和评估准确性。

Method: 采用双层优化结构：内层循环使用固定评分模板通过细粒度反馈优化提示，外层循环使用ASR对齐分数优化评分模板，实现提示和模板的协同演化。

Result: 在AdvBench和JBB-Behaviors评估中，AMIS在Claude-3.5-Haiku上达到88.0% ASR，在Claude-4-Sonnet上达到100.0% ASR，显著优于现有基线方法。

Conclusion: AMIS框架通过联合优化提示和评分模板，能够生成更强的越狱提示并提供更准确的评分信号，有效提升了大型语言模型的安全性测试能力。

Abstract: Identifying the vulnerabilities of large language models (LLMs) is crucial
for improving their safety by addressing inherent weaknesses. Jailbreaks, in
which adversaries bypass safeguards with crafted input prompts, play a central
role in red-teaming by probing LLMs to elicit unintended or unsafe behaviors.
Recent optimization-based jailbreak approaches iteratively refine attack
prompts by leveraging LLMs. However, they often rely heavily on either binary
attack success rate (ASR) signals, which are sparse, or manually crafted
scoring templates, which introduce human bias and uncertainty in the scoring
outcomes. To address these limitations, we introduce AMIS (Align to MISalign),
a meta-optimization framework that jointly evolves jailbreak prompts and
scoring templates through a bi-level structure. In the inner loop, prompts are
refined using fine-grained and dense feedback using a fixed scoring template.
In the outer loop, the template is optimized using an ASR alignment score,
gradually evolving to better reflect true attack outcomes across queries. This
co-optimization process yields progressively stronger jailbreak prompts and
more calibrated scoring signals. Evaluations on AdvBench and JBB-Behaviors
demonstrate that AMIS achieves state-of-the-art performance, including 88.0%
ASR on Claude-3.5-Haiku and 100.0% ASR on Claude-4-Sonnet, outperforming
existing baselines by substantial margins.

</details>


### [189] [Relaxing partition admissibility in Cluster-DAGs: a causal calculus with arbitrary variable clustering](https://arxiv.org/abs/2511.01396)
*Clément Yvernes,Emilie Devijver,Adèle H. Ribeiro,Marianne Clausel--Lesourd,Éric Gaussier*

Main category: cs.AI

TL;DR: 扩展C-DAG框架以支持任意变量聚类，允许循环C-DAG表示，并扩展d-分离和因果演算概念，使因果推理在集群级别更广泛应用。


<details>
  <summary>Details</summary>
Motivation: 传统C-DAG要求聚类产生无环图，限制了其应用范围。当选择的聚类导致循环时，该分区在传统C-DAG语义下被视为不可接受。

Method: 通过放宽分区可接受性约束，允许循环C-DAG表示，并扩展d-分离和因果演算概念到这个设置中。

Result: 新演算相对于do-演算既是可靠的又是原子完备的：所有有效的集群级别干预查询都可以使用我们的规则推导，每个规则对应一个原始do-演算步骤。

Conclusion: 该工作显著拓宽了跨集群因果推理的范围，使C-DAG能够在先前难以处理的场景中应用。

Abstract: Cluster DAGs (C-DAGs) provide an abstraction of causal graphs in which nodes
represent clusters of variables, and edges encode both cluster-level causal
relationships and dependencies arisen from unobserved confounding. C-DAGs
define an equivalence class of acyclic causal graphs that agree on
cluster-level relationships, enabling causal reasoning at a higher level of
abstraction. However, when the chosen clustering induces cycles in the
resulting C-DAG, the partition is deemed inadmissible under conventional C-DAG
semantics. In this work, we extend the C-DAG framework to support arbitrary
variable clusterings by relaxing the partition admissibility constraint,
thereby allowing cyclic C-DAG representations. We extend the notions of
d-separation and causal calculus to this setting, significantly broadening the
scope of causal reasoning across clusters and enabling the application of
C-DAGs in previously intractable scenarios. Our calculus is both sound and
atomically complete with respect to the do-calculus: all valid interventional
queries at the cluster level can be derived using our rules, each corresponding
to a primitive do-calculus step.

</details>


### [190] [Modulation of temporal decision-making in a deep reinforcement learning agent under the dual-task paradigm](https://arxiv.org/abs/2511.01415)
*Amrapali Pednekar,Álvaro Garrido-Pérez,Yara Khaluf,Pieter Simoens*

Main category: cs.AI

TL;DR: 该研究从AI角度探索双任务范式中的时间处理干扰，发现双任务DRL智能体相对于单任务智能体显著高估时间，但未发现明确的内部计时机制。


<details>
  <summary>Details</summary>
Motivation: 探索深度强化学习智能体在双任务范式中的时间处理行为，与人类计时研究进行比较，以促进对生物系统和AI系统的更好理解。

Method: 使用简化的Overcooked环境，分别训练单任务(T)和双任务(T+N)的DRL智能体，双任务额外包含数字比较任务，分析智能体的时间产生行为和LSTM层神经动力学。

Result: 双任务智能体相对于单任务智能体显著高估时间，这一结果在四个目标时长上一致；LSTM层分析未发现明确的专用计时器证据。

Conclusion: 需要进一步研究智能体的潜在计时机制，这是探索DRL行为与生物系统行为相似性的初步尝试。

Abstract: This study explores the interference in temporal processing within a
dual-task paradigm from an artificial intelligence (AI) perspective. In this
context, the dual-task setup is implemented as a simplified version of the
Overcooked environment with two variations, single task (T) and dual task
(T+N). Both variations involve an embedded time production task, but the dual
task (T+N) additionally involves a concurrent number comparison task. Two deep
reinforcement learning (DRL) agents were separately trained for each of these
tasks. These agents exhibited emergent behavior consistent with human timing
research. Specifically, the dual task (T+N) agent exhibited significant
overproduction of time relative to its single task (T) counterpart. This result
was consistent across four target durations. Preliminary analysis of neural
dynamics in the agents' LSTM layers did not reveal any clear evidence of a
dedicated or intrinsic timer. Hence, further investigation is needed to better
understand the underlying time-keeping mechanisms of the agents and to provide
insights into the observed behavioral patterns. This study is a small step
towards exploring parallels between emergent DRL behavior and behavior observed
in biological systems in order to facilitate a better understanding of both.

</details>


### [191] [Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis](https://arxiv.org/abs/2511.01425)
*Yuhang Huang,Zekai Lin,Fan Zhong,Lei Liu*

Main category: cs.AI

TL;DR: 提出了一种通过可审计行动序列生成解释的交互式AI代理，使用强化学习优化策略来寻求外部视觉证据，显著提高了校准准确性和解释的可验证性。


<details>
  <summary>Details</summary>
Motivation: 在医疗等高风险领域中，AI模型的解释往往缺乏可验证性，这会阻碍信任的建立。

Method: 设计了一个交互式代理，学习策略来战略性地寻求外部视觉证据支持诊断推理，使用强化学习优化该策略。

Result: 实验显示该方法显著提高了校准准确性，Brier分数比非交互基线降低了18%。通过因果干预验证了解释的忠实性，遮蔽代理选择的视觉证据会导致性能明显下降。

Conclusion: 这项工作为构建具有可验证和忠实推理能力的AI系统提供了实用框架。

Abstract: Explanations for AI models in high-stakes domains like medicine often lack
verifiability, which can hinder trust. To address this, we propose an
interactive agent that produces explanations through an auditable sequence of
actions. The agent learns a policy to strategically seek external visual
evidence to support its diagnostic reasoning. This policy is optimized using
reinforcement learning, resulting in a model that is both efficient and
generalizable. Our experiments show that this action-based reasoning process
significantly improves calibrated accuracy, reducing the Brier score by 18\%
compared to a non-interactive baseline. To validate the faithfulness of the
agent's explanations, we introduce a causal intervention method. By masking the
visual evidence the agent chooses to use, we observe a measurable degradation
in its performance ($\Delta$Brier=+0.029), confirming that the evidence is
integral to its decision-making process. Our work provides a practical
framework for building AI systems with verifiable and faithful reasoning
capabilities.

</details>


### [192] [Robust Multimodal Sentiment Analysis via Double Information Bottleneck](https://arxiv.org/abs/2511.01444)
*Huiting Huang,Tieliang Gong,Kai He,Jialun Wu,Erik Cambria,Mengling Feng*

Main category: cs.AI

TL;DR: 提出双信息瓶颈(DIB)策略解决多模态情感分析中的两个关键问题：噪声污染的单模态数据学习和多模态表示融合不足。DIB通过最大化任务相关信息并丢弃冗余信息，获得统一紧凑的多模态表示。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个关键局限：对噪声污染的单模态数据学习不足导致跨模态交互受损，以及多模态表示融合不充分导致丢弃判别性单模态信息而保留冗余信息。

Method: 基于低秩Renyi熵函数框架实现双信息瓶颈策略，包含两个模块：1)学习单模态数据的充分压缩表示，2)通过新颖的注意力瓶颈融合机制确保多模态表示的判别能力。

Result: 在CMU-MOSI、CMU-MOSEI、CH-SIMS和MVSA-Single数据集上验证有效性。在CMU-MOSI上Acc-7达到47.4%，CH-SIMS上F1-score达到81.63%，比次优基线提升1.19%。在噪声下性能下降仅0.36%和0.29%。

Conclusion: DIB策略能够有效过滤单模态数据中的噪声信息，同时捕捉模态间互补性，获得强大统一的多模态表示，相比传统基于香农熵的方法具有更好的鲁棒性和计算可行性。

Abstract: Multimodal sentiment analysis has received significant attention across
diverse research domains. Despite advancements in algorithm design, existing
approaches suffer from two critical limitations: insufficient learning of
noise-contaminated unimodal data, leading to corrupted cross-modal
interactions, and inadequate fusion of multimodal representations, resulting in
discarding discriminative unimodal information while retaining multimodal
redundant information. To address these challenges, this paper proposes a
Double Information Bottleneck (DIB) strategy to obtain a powerful, unified
compact multimodal representation. Implemented within the framework of low-rank
Renyi's entropy functional, DIB offers enhanced robustness against diverse
noise sources and computational tractability for high-dimensional data, as
compared to the conventional Shannon entropy-based methods. The DIB comprises
two key modules: 1) learning a sufficient and compressed representation of
individual unimodal data by maximizing the task-relevant information and
discarding the superfluous information, and 2) ensuring the discriminative
ability of multimodal representation through a novel attention bottleneck
fusion mechanism. Consequently, DIB yields a multimodal representation that
effectively filters out noisy information from unimodal data while capturing
inter-modal complementarity. Extensive experiments on CMU-MOSI, CMU-MOSEI,
CH-SIMS, and MVSA-Single validate the effectiveness of our method. The model
achieves 47.4% accuracy under the Acc-7 metric on CMU-MOSI and 81.63% F1-score
on CH-SIMS, outperforming the second-best baseline by 1.19%. Under noise, it
shows only 0.36% and 0.29% performance degradation on CMU-MOSI and CMU-MOSEI
respectively.

</details>


### [193] [From Passive to Proactive: A Multi-Agent System with Dynamic Task Orchestration for Intelligent Medical Pre-Consultation](https://arxiv.org/abs/2511.01445)
*ChengZhang Yu,YingRu He,Hongyan Cheng,nuo Cheng,Zhixing Liu,Dongxu Mu,Zhangrui Shen,Zhanpeng Jin*

Main category: cs.AI

TL;DR: 该研究提出了一个分层多智能体框架，将被动医疗AI系统转变为主动问诊代理，通过自主任务编排提高预诊效率和临床质量。


<details>
  <summary>Details</summary>
Motivation: 全球医疗系统面临患者数量增加和就诊时间有限的挑战，现有AI系统受限于被动交互模式和上下文管理问题，需要更主动的预诊解决方案。

Method: 开发了八智能体架构，将预诊过程分解为分诊、现病史收集、既往史收集和主诉生成四个主要任务，进一步细分为13个领域特定子任务，采用集中控制机制进行自主任务编排。

Result: 在1,372份电子健康记录上评估，分诊准确率达87.0%，任务完成率98.2%，临床质量评分平均4.56-4.69（5分制），咨询轮次控制在12.7-16.9轮内。

Conclusion: 该模型无关架构在不同基础模型上保持高性能，通过本地部署保护数据隐私，展示了自主AI系统在临床预诊中提升效率和质量的能力。

Abstract: Global healthcare systems face critical challenges from increasing patient
volumes and limited consultation times, with primary care visits averaging
under 5 minutes in many countries. While pre-consultation processes
encompassing triage and structured history-taking offer potential solutions,
they remain limited by passive interaction paradigms and context management
challenges in existing AI systems. This study introduces a hierarchical
multi-agent framework that transforms passive medical AI systems into proactive
inquiry agents through autonomous task orchestration. We developed an
eight-agent architecture with centralized control mechanisms that decomposes
pre-consultation into four primary tasks: Triage ($T_1$), History of Present
Illness collection ($T_2$), Past History collection ($T_3$), and Chief
Complaint generation ($T_4$), with $T_1$--$T_3$ further divided into 13
domain-specific subtasks. Evaluated on 1,372 validated electronic health
records from a Chinese medical platform across multiple foundation models
(GPT-OSS 20B, Qwen3-8B, Phi4-14B), the framework achieved 87.0% accuracy for
primary department triage and 80.5% for secondary department classification,
with task completion rates reaching 98.2% using agent-driven scheduling versus
93.1% with sequential processing. Clinical quality scores from 18 physicians
averaged 4.56 for Chief Complaints, 4.48 for History of Present Illness, and
4.69 for Past History on a 5-point scale, with consultations completed within
12.7 rounds for $T_2$ and 16.9 rounds for $T_3$. The model-agnostic
architecture maintained high performance across different foundation models
while preserving data privacy through local deployment, demonstrating the
potential for autonomous AI systems to enhance pre-consultation efficiency and
quality in clinical settings.

</details>


### [194] [TPS-Bench: Evaluating AI Agents' Tool Planning \& Scheduling Abilities in Compounding Tasks](https://arxiv.org/abs/2511.01527)
*Hanwen Xu,Xuyao Huang,Yuzhe Liu,Kai Yu,Zhijie Deng*

Main category: cs.AI

TL;DR: TPS-Bench是一个评估LLM智能体在工具规划与调度方面能力的基准测试，包含200个复合任务和数百个MCP工具。研究发现大多数模型能合理规划工具使用，但在调度效率上差异显著，强化学习可以提升调度效率。


<details>
  <summary>Details</summary>
Motivation: 探索LLM智能体是否能解决需要多种工具协同工作的复合现实问题，这些任务不仅需要选择合适的工具，还需要高效地安排执行顺序。

Method: 构建TPS-Bench基准，包含200个复合任务和数百个MCP工具，评估LLM智能体的工具规划与调度能力，并使用强化学习改进调度效率。

Result: GLM-4.5达到64.72%的任务完成率但执行时间长，GPT-4o仅45.08%完成率但优先并行调用工具。强化学习在Qwen3-1.7B上使执行时间减少14%，完成率提升6%。

Conclusion: LLM智能体在工具规划方面表现合理，但在调度效率上存在差异，强化学习是提升调度效率的有效方法。

Abstract: Large language model (LLM) agents have exhibited strong problem-solving
competence across domains like research and coding. Yet, it remains
underexplored whether LLM agents can tackle compounding real-world problems
that require a diverse set of tools to complete. Given a broad, heterogeneous
tool repository, LLM agents must not only select appropriate tools based on
task planning analysis but also strategically schedule the execution order to
ensure efficiency. This paper introduces TPS-Bench to benchmark the ability of
LLM agents in solving such problems that demand Tool Planning and Scheduling.
TPS-Bench collects 200 compounding tasks of two difficulty levels, based on a
tool repository containing hundreds of model context protocol (MCP) tools. In
particular, each task is composed of multiple subtasks, such as web search, map
navigation, calendar checking, etc., and each subtask can be completed by a
basic tool. Our evaluation emphasizes both task completion rate and efficiency.
The empirical studies on popular closed-source and open-source LLMs indicate
that most models can perform reasonable tool planning, but differ in
scheduling. For example, GLM-4.5 achieves an outperforming task completion rate
of 64.72% with extensive sequential tool calls, hence suffering from
significantly long execution time. By contrast, GPT-4o prioritizes parallel
tool calls but achieves only a 45.08% completion rate. Considering
reinforcement learning (RL) can be a viable way to improve the scheduling
efficiency without compromising performance, we perform an initial study on
Qwen3-1.7B and witness a 14% reduction in execution time alongside a 6% gain in
task completion rate based on rarely 100 RL training samples. Our code is
available https://github.com/hanwenxu1/mcp-agent.

</details>


### [195] [Analyzing Sustainability Messaging in Large-Scale Corporate Social Media](https://arxiv.org/abs/2511.01550)
*Ujjwal Sharma,Stevan Rudinac,Ana Mićković,Willemijn van Dolen,Marcel Worring*

Main category: cs.AI

TL;DR: 提出一个多模态分析框架，利用大型基础模型分析企业社交媒体内容中的可持续发展沟通，结合文本和视觉分析揭示行业差异、时间趋势以及与ESG风险和用户参与度的关联。


<details>
  <summary>Details</summary>
Motivation: 解决企业社交媒体内容的多模态、模糊性和动态变化带来的分析挑战，特别是可持续发展相关沟通的识别和评估问题。

Method: 使用大型语言模型(LLM)集成自动标注企业推文与17个可持续发展目标(SDG)的主题对齐，结合视觉语言模型(VLM)通过语义聚类分析视觉可持续发展沟通模式。

Result: 揭示了不同行业在SDG参与度上的差异、时间趋势，以及企业信息传递与ESG风险、消费者参与度之间的关联。

Conclusion: 提出的自动标签生成和语义视觉聚类方法具有广泛适用性，为大规模社交媒体分析提供了一个灵活框架。

Abstract: In this work, we introduce a multimodal analysis pipeline that leverages
large foundation models in vision and language to analyze corporate social
media content, with a focus on sustainability-related communication. Addressing
the challenges of evolving, multimodal, and often ambiguous corporate messaging
on platforms such as X (formerly Twitter), we employ an ensemble of large
language models (LLMs) to annotate a large corpus of corporate tweets on their
topical alignment with the 17 Sustainable Development Goals (SDGs). This
approach avoids the need for costly, task-specific annotations and explores the
potential of such models as ad-hoc annotators for social media data that can
efficiently capture both explicit and implicit references to sustainability
themes in a scalable manner. Complementing this textual analysis, we utilize
vision-language models (VLMs), within a visual understanding framework that
uses semantic clusters to uncover patterns in visual sustainability
communication. This integrated approach reveals sectoral differences in SDG
engagement, temporal trends, and associations between corporate messaging,
environmental, social, governance (ESG) risks, and consumer engagement. Our
methods-automatic label generation and semantic visual clustering-are broadly
applicable to other domains and offer a flexible framework for large-scale
social media analysis.

</details>


### [196] [ExplicitLM: Decoupling Knowledge from Parameters via Explicit Memory Banks](https://arxiv.org/abs/2511.01581)
*Chengzhang Yu,Zening Lu,Chenyang Zheng,Chiyue Wang,Yiming Zhang,Zhanpeng Jin*

Main category: cs.AI

TL;DR: ExplicitLM是一种新颖的架构，通过百万规模的外部记忆库存储人类可读的知识作为标记序列，实现直接检查和修改，解决了大语言模型的知识陈旧性和缺乏可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型由于知识在纠缠的网络参数中隐式存储，存在知识陈旧和缺乏可解释性的问题，阻碍了针对性更新和推理透明性。

Method: 设计可微分的两阶段检索机制：通过产品键分解进行高效粗粒度过滤（将复杂度从O(N·|I|)降低到O(√N·|I|)），以及用于端到端训练的细粒度Gumbel-Softmax匹配。受双系统认知理论启发，将知识划分为冻结的显式事实（20%）和可学习的隐式模式（80%），通过指数移动平均更新保持稳定性。

Result: 在知识密集型任务上比标准Transformer提升高达43.67%，在低数据场景（1万个样本）下获得3.62倍的增益。分析显示内存检索与性能之间存在强相关性，正确预测的命中率高出49%。

Conclusion: 与使用冻结检索的RAG系统不同，联合优化的架构表明，可解释、可更新的模型可以在保持竞争力的同时提供前所未有的知识透明度。

Abstract: Large language models suffer from knowledge staleness and lack of
interpretability due to implicit knowledge storage across entangled network
parameters, preventing targeted updates and reasoning transparency. We propose
ExplicitLM, a novel architecture featuring a million-scale external memory bank
storing human-readable knowledge as token sequences, enabling direct inspection
and modification. We design a differentiable two-stage retrieval mechanism with
efficient coarse-grained filtering via product key decomposition (reducing
complexity from $\mathcal{O}(N \cdot |I|)$ to $\mathcal{O}(\sqrt{N} \cdot
|I|)$) and fine-grained Gumbel-Softmax matching for end-to-end training.
Inspired by dual-system cognitive theory, we partition knowledge into frozen
explicit facts (20%) and learnable implicit patterns (80%), maintained through
Exponential Moving Average updates for stability. ExplicitLM achieves up to
43.67% improvement on knowledge-intensive tasks versus standard Transformers,
with 3.62$\times$ gains in low-data regimes (10k samples). Analysis shows
strong correlations between memory retrieval and performance, with correct
predictions achieving 49% higher hit rates. Unlike RAG systems with frozen
retrieval, our jointly optimized architecture demonstrates that interpretable,
updatable models can maintain competitive performance while providing
unprecedented knowledge transparency.

</details>


### [197] [IVGAE-TAMA-BO: A novel temporal dynamic variational graph model for link prediction in global food trade networks with momentum structural memory and Bayesian optimization](https://arxiv.org/abs/2511.01639)
*Sicheng Wang,Shuhao Chen,Jingran Zhou,Chengyi Tu*

Main category: cs.AI

TL;DR: 提出了IVGAE-TAMA-BO动态图神经网络模型，用于预测全球粮食贸易网络中的未来链接，通过时间感知动量聚合器和贝叶斯优化显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 全球粮食贸易网络在政治、经济和环境因素影响下动态演变，传统方法难以有效捕捉时间模式，需要更准确的链接预测方法来保障粮食安全和供应链稳定。

Method: 在IVGAE框架基础上，引入贸易感知动量聚合器(TAMA)捕捉贸易网络的时间演化，联合建模短期波动和长期结构依赖，并使用贝叶斯优化自动调参。

Result: 在五个作物特定数据集上的实验表明，IVGAE-TAMA显著优于静态IVGAE和其他动态基线模型，贝叶斯优化进一步提升了IVGAE-TAMA-BO的性能。

Conclusion: 该框架为全球贸易网络结构预测提供了稳健且可扩展的解决方案，在粮食安全监测和政策决策支持方面具有重要应用潜力。

Abstract: Global food trade plays a crucial role in ensuring food security and
maintaining supply chain stability. However, its network structure evolves
dynamically under the influence of geopolitical, economic, and environmental
factors, making it challenging to model and predict future trade links.
Effectively capturing temporal patterns in food trade networks is therefore
essential for improving the accuracy and robustness of link prediction. This
study introduces IVGAE-TAMA-BO, a novel dynamic graph neural network designed
to model evolving trade structures and predict future links in global food
trade networks. To the best of our knowledge, this is the first work to apply
dynamic graph neural networks to this domain, significantly enhancing
predictive performance. Building upon the original IVGAE framework, the
proposed model incorporates a Trade-Aware Momentum Aggregator (TAMA) to capture
the temporal evolution of trade networks, jointly modeling short-term
fluctuations and long-term structural dependencies. A momentum-based structural
memory mechanism further improves predictive stability and performance. In
addition, Bayesian optimization is used to automatically tune key
hyperparameters, enhancing generalization across diverse trade scenarios.
Extensive experiments on five crop-specific datasets demonstrate that
IVGAE-TAMA substantially outperforms the static IVGAE and other dynamic
baselines by effectively modeling temporal dependencies, while Bayesian
optimization further boosts performance in IVGAE-TAMA-BO. These results
highlight the proposed framework as a robust and scalable solution for
structural prediction in global trade networks, with strong potential for
applications in food security monitoring and policy decision support.

</details>


### [198] [Hybrid Retrieval-Augmented Generation Agent for Trustworthy Legal Question Answering in Judicial Forensics](https://arxiv.org/abs/2511.01668)
*Yueqing Xi,Yifan Bai,Huasen Luo,Weiliang Wen,Hui Liu,Haoliang Li*

Main category: cs.AI

TL;DR: 提出了一种结合检索增强生成和多模型集成的混合法律问答代理，通过检索优先策略、模型集成和人工审核机制，显著减少幻觉并提高法律合规性。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型在法律问答中容易产生幻觉，可能误导法律咨询；静态知识库难以跟上频繁更新的法规和判例，需要确保法律问答的真实性和可追溯性。

Method: 采用检索优先策略：当可信法律知识库检索到相关证据时使用RAG生成答案，否则通过多个LLM生成候选答案并由专门选择器评分返回最佳答案。高质量输出经过人工审核后写回知识库，实现动态知识演进和溯源跟踪。

Result: 在Law_QA数据集上的实验表明，该混合方法在F1、ROUGE-L和LLM-as-a-Judge指标上显著优于单模型基线和普通RAG流程。消融实验证实了检索优先、模型集成和人工更新机制的有效性。

Conclusion: 该系统显著减少了幻觉，提高了答案质量和法律合规性，推动了媒体取证技术在司法场景中的实际落地应用。

Abstract: As artificial intelligence permeates judicial forensics, ensuring the
veracity and traceability of legal question answering (QA) has become critical.
Conventional large language models (LLMs) are prone to hallucination, risking
misleading guidance in legal consultation, while static knowledge bases
struggle to keep pace with frequently updated statutes and case law. We present
a hybrid legal QA agent tailored for judicial settings that integrates
retrieval-augmented generation (RAG) with multi-model ensembling to deliver
reliable, auditable, and continuously updatable counsel. The system prioritizes
retrieval over generation: when a trusted legal repository yields relevant
evidence, answers are produced via RAG; otherwise, multiple LLMs generate
candidates that are scored by a specialized selector, with the top-ranked
answer returned. High-quality outputs then undergo human review before being
written back to the repository, enabling dynamic knowledge evolution and
provenance tracking. Experiments on the Law\_QA dataset show that our hybrid
approach significantly outperforms both a single-model baseline and a vanilla
RAG pipeline on F1, ROUGE-L, and an LLM-as-a-Judge metric. Ablations confirm
the complementary contributions of retrieval prioritization, model ensembling,
and the human-in-the-loop update mechanism. The proposed system demonstrably
reduces hallucination while improving answer quality and legal compliance,
advancing the practical landing of media forensics technologies in judicial
scenarios.

</details>


### [199] [Simulating Environments with Reasoning Models for Agent Training](https://arxiv.org/abs/2511.01824)
*Yuetai Li,Huseyin A Inan,Xiang Yue,Wei-Ning Chen,Lukas Wutschitz,Janardhan Kulkarni,Radha Poovendran,Robert Sim,Saravan Rajmohan*

Main category: cs.AI

TL;DR: LLM代理在复杂环境中表现脆弱，本文提出Simia-SFT和Simia-RL框架，通过LLM模拟环境反馈实现无需真实环境数据的可扩展代理训练。


<details>
  <summary>Details</summary>
Motivation: LLM代理在需要跨多种工具和模式的复杂环境中表现脆弱，而构建定制训练环境成本高且限制进展。

Method: 提出两个框架：Simia-SFT通过扩增小规模种子数据生成多样化轨迹的SFT数据；Simia-RL通过LLM模拟反馈实现无需真实环境的强化学习训练。

Result: 微调开源模型在多个基准测试中取得一致改进，在τ²-Bench上超越GPT-4o并接近o4-mini性能。

Conclusion: Simia-SFT和Simia-RL能够实现无需环境工程的可扩展代理训练，用灵活的LLM模拟替代繁重脆弱的环境实现。

Abstract: LLM agents excel in compact environments requiring deep reasoning but remain
brittle when operating in broader, more complex contexts that demand robustness
across diverse tools and schemas. Building bespoke environments for training is
heavy, brittle, and limits progress. In this paper, we demonstrate that LLMs
can simulate realistic environment feedback without access to actual testbed
data or APIs. Inspired by this capability, we propose two frameworks:
Simia-SFT, a pipeline that synthesizes SFT data by amplifying small seed sets
into diverse trajectories in an environment-agnostic manner, and Simia-RL, a
framework that enables RL training without real environment implementations
through LLM-simulated feedback. Fine-tuning open models yields consistent
improvements across multiple benchmarks, surpassing GPT-4o and approaching
o4-mini on $\tau^2$-Bench. Together, Simia-SFT and Simia-RL enable scalable
agent training without environment engineering, replacing heavy and brittle
implementations with flexible LLM-based simulation.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [200] [Residual Balancing for Non-Linear Outcome Models in High Dimensions](https://arxiv.org/abs/2511.00324)
*Isaac Meza*

Main category: econ.EM

TL;DR: 将近似残差平衡框架扩展到非线性模型，通过二阶校正处理链接函数曲率，在高维设置中估计广义线性模型的平均处理效应


<details>
  <summary>Details</summary>
Motivation: 解决Athey等人(2018)提出的开放问题，处理高维设置中广义线性模型平均处理效应的估计挑战

Method: 推导非线性模型的偏倚分解，构建控制一阶和二阶偏倚源的平衡权重优化问题

Result: 在标准高维假设下建立了估计量的√n一致性和渐近正态性理论保证

Conclusion: 成功将ARB框架扩展到非线性模型，为高维广义线性模型的因果推断提供了有效方法

Abstract: We extend the approximate residual balancing (ARB) framework to nonlinear
models, answering an open problem posed by Athey et al. (2018). Our approach
addresses the challenge of estimating average treatment effects in
high-dimensional settings where the outcome follows a generalized linear model.
We derive a new bias decomposition for nonlinear models that reveals the need
for a second-order correction to account for the curvature of the link
function. Based on this insight, we construct balancing weights through an
optimization problem that controls for both first and second-order sources of
bias. We provide theoretical guarantees for our estimator, establishing its
$\sqrt{n}$-consistency and asymptotic normality under standard high-dimensional
assumptions.

</details>


### [201] [Concentration Inequalities for Suprema of Empirical Processes with Dependent Data via Generic Chaining with Applications to Statistical Learning](https://arxiv.org/abs/2511.00597)
*Chiara Amorino,Christian Brownlees,Ankita Ghosh*

Main category: econ.EM

TL;DR: 提出了一种适用于依赖数据的经验过程上确界的通用集中不等式，结合了通用链和耦合策略，适用于高维和重尾数据，并应用于非线性回归模型的非渐近预测性能保证。


<details>
  <summary>Details</summary>
Motivation: 现有集中不等式主要针对独立同分布数据，缺乏对依赖数据的通用理论框架，特别是在高维和重尾数据场景下。

Method: 结合通用链方法和耦合策略，构建经验过程上确界的集中不等式，适用于依赖数据和高维重尾分布。

Result: 建立了依赖数据下经验风险最小化的预测性能保证，包括非线性回归模型和单层神经网络模型的oracle不等式，表明其预测精度与独立同分布设置相当。

Conclusion: 所提出的集中不等式为依赖数据下的经验过程提供了通用理论工具，在非线性回归模型中实现了与独立同分布数据相当的预测性能。

Abstract: This paper develops a general concentration inequality for the suprema of
empirical processes with dependent data. The concentration inequality is
obtained by combining generic chaining with a coupling-based strategy. Our
framework accommodates high-dimensional and heavy-tailed (sub-Weibull) data. We
demonstrate the usefulness of our result by deriving non-asymptotic predictive
performance guarantees for empirical risk minimization in regression problems
with dependent data. In particular, we establish an oracle inequality for a
broad class of nonlinear regression models and, as a special case, a
single-layer neural network model. Our results show that empirical risk
minimzaton with dependent data attains a prediction accuracy comparable to that
in the i.i.d. setting for a wide range of nonlinear regression models.

</details>


### [202] [Improving control over unobservables with network data](https://arxiv.org/abs/2511.00612)
*Vincent Starck*

Main category: econ.EM

TL;DR: 该论文开发了一种利用同质性网络进行因果推断的方法，通过渐近同质性概念和网络形成模型，在存在未观测混杂因素的情况下获得一致的治疗效果估计量。


<details>
  <summary>Details</summary>
Motivation: 解决在存在未观测混杂因素的情况下进行因果推断的挑战，利用网络中常见的同质性特征来克服选择偏误问题。

Method: 引入渐近同质性概念，建立能够容纳同质性、度异质性、稀疏性和聚类等经验特征的网络形成模型，并通过选择连接概率较低的个体来构建估计量。

Result: 开发出对未观测混杂因素具有鲁棒性的治疗效果一致估计量，在应用中发现父母参与对学生考试成绩的影响估计大于OLS方法的结果。

Conclusion: 利用网络同质性可以有效解决因果推断中的未观测混杂问题，为存在网络数据的实证研究提供了新的识别策略。

Abstract: This paper develops a method to conduct causal inference in the presence of
unobserved confounders by leveraging networks with homophily, a frequently
observed tendency to form edges with similar nodes. I introduce a concept of
asymptotic homophily, according to which individuals' selectivity scales with
the size of the potential connection pool. It contributes to the network
formation literature with a model that can accommodate common empirical
features such as homophily, degree heterogeneity, sparsity, and clustering, and
provides a framework to obtain consistent estimators of treatment effects that
are robust to selection on unobservables. I also consider an alternative
setting that accommodates dense networks and show how selecting linked
individuals whose observed characteristics made such a connection less likely
delivers an estimator with similar properties. In an application, I recover an
estimate of the effect of parental involvement on students' test scores that is
greater than that of OLS, arguably due to the estimator's ability to account
for unobserved ability.

</details>


### [203] [Cross-Validated Causal Inference: a Modern Method to Combine Experimental and Observational Data](https://arxiv.org/abs/2511.00727)
*Xuelin Yang,Licong Lin,Susan Athey,Michael I. Jordan,Guido W. Imbens*

Main category: econ.EM

TL;DR: 提出一种整合实验数据和观察数据进行因果推断的新方法，通过经验风险最小化框架结合两种数据源的优势。


<details>
  <summary>Details</summary>
Motivation: 随机对照试验内部效度高但成本昂贵样本量小，观察数据样本量大但存在未测量混杂因素偏倚，需要结合两者优势。

Method: 将因果估计构建为经验风险最小化问题，通过最小化实验损失和观察损失的加权组合来获得包含因果参数的完整模型，权重通过交叉验证选择。

Result: 在真实和合成数据上的实验证明了方法的有效性和可靠性，并提供了理论上的非渐近误差界。

Conclusion: 该方法成功整合了实验和观察数据，在因果推断中实现了更好的效果和可靠性。

Abstract: We develop new methods to integrate experimental and observational data in
causal inference. While randomized controlled trials offer strong internal
validity, they are often costly and therefore limited in sample size.
Observational data, though cheaper and often with larger sample sizes, are
prone to biases due to unmeasured confounders. To harness their complementary
strengths, we propose a systematic framework that formulates causal estimation
as an empirical risk minimization (ERM) problem. A full model containing the
causal parameter is obtained by minimizing a weighted combination of
experimental and observational losses--capturing the causal parameter's
validity and the full model's fit, respectively. The weight is chosen through
cross-validation on the causal parameter across experimental folds. Our
experiments on real and synthetic data show the efficacy and reliability of our
method. We also provide theoretical non-asymptotic error bounds.

</details>


### [204] [High-Dimensional Spatial Arbitrage Pricing Theory with Heterogeneous Interactions](https://arxiv.org/abs/2511.01271)
*Zhaoxing Gao,Sihan Tu,Ruey S. Tsay*

Main category: econ.EM

TL;DR: 提出了空间套利定价理论(SAPT)模型，将空间交互与多因子分析相结合，处理可观测和潜在因子。开发了空间资本资产定价模型(SCAPM)和广义SAPT框架，提出了广义收缩Yule-Walker估计方法。


<details>
  <summary>Details</summary>
Motivation: 将空间交互效应整合到多因子资产定价模型中，解决高维资产中的空间依赖性问题，扩展传统的资本资产定价模型。

Method: 提出了SCAPM模型和SAPT框架；对于可观测因子使用广义收缩Yule-Walker估计方法；对于潜在因子先通过自协方差特征分析提取因子，再使用SYW方法；建立了高维设定下的渐近性质。

Result: 建立了空间rho作为CAPM中市场beta的对应概念；开发了有效的估计方法；通过模拟和实际数据验证了模型和方法的有效性。

Conclusion: 提出的SAPT模型和估计方法能够有效处理高维资产中的空间交互效应，为空间金融分析提供了理论框架和实用工具。

Abstract: This paper investigates estimation and inference of a Spatial Arbitrage
Pricing Theory (SAPT) model that integrates spatial interactions with
multi-factor analysis, accommodating both observable and latent factors.
Building on the classical mean-variance analysis, we introduce a class of
Spatial Capital Asset Pricing Models (SCAPM) that account for spatial effects
in high-dimensional assets, where we define {\it spatial rho} as a counterpart
to market beta in CAPM. We then extend SCAPM to a general SAPT framework under
a {\it complete} market setting by incorporating multiple factors. For SAPT
with observable factors, we propose a generalized shrinkage Yule-Walker (SYW)
estimation method that integrates ridge regression to estimate spatial and
factor coefficients. When factors are latent, we first apply an
autocovariance-based eigenanalysis to extract factors, then employ the SYW
method using the estimated factors. We establish asymptotic properties for
these estimators under high-dimensional settings where both the dimension and
sample size diverge. Finally, we use simulated and real data examples to
demonstrate the efficacy and usefulness of the proposed model and method.

</details>


### [205] [Making Interpretable Discoveries from Unstructured Data: A High-Dimensional Multiple Hypothesis Testing Approach](https://arxiv.org/abs/2511.01680)
*Jacob Carlson*

Main category: econ.EM

TL;DR: 提出一个从非结构化数据中进行统计发现的一般框架，利用机器学习可解释性方法构建概念字典，并通过选择性推断进行统计验证。


<details>
  <summary>Details</summary>
Motivation: 社会科学家越来越多地使用非结构化数据集来获取新的实证见解，但需要一种统计上严谨的方法来进行无监督分析，而不预先指定测量对象。

Method: 利用机器学习可解释性方法将非结构化数据映射到高维、稀疏且可解释的概念字典，计算统计量，并使用新开发的高维超越控制统计程序进行选择性推断。

Result: 该框架具有较少的研究者自由度，完全可复制，实施成本低（包括财务成本和研究时间），并提供了开源实现。

Conclusion: 提出的框架为从非结构化数据中进行统计发现提供了一种原则性方法，适用于描述性和因果分析，并提供了实际应用工具。

Abstract: Social scientists are increasingly turning to unstructured datasets to unlock
new empirical insights, e.g., estimating causal effects on text outcomes,
measuring beliefs from open-ended survey responses. In such settings,
unsupervised analysis is often of interest, in that the researcher does not
want to pre-specify the objects of measurement or otherwise artificially
delimit the space of measurable concepts; they are interested in discovery.
This paper proposes a general and flexible framework for pursuing discovery
from unstructured data in a statistically principled way. The framework
leverages recent methods from the literature on machine learning
interpretability to map unstructured data points to high-dimensional, sparse,
and interpretable dictionaries of concepts; computes (test) statistics of these
dictionary entries; and then performs selective inference on them using newly
developed statistical procedures for high-dimensional exceedance control of the
$k$-FWER under arbitrary dependence. The proposed framework has few researcher
degrees of freedom, is fully replicable, and is cheap to implement -- both in
terms of financial cost and researcher time. Applications to recent descriptive
and causal analyses of unstructured data in empirical economics are explored.
An open source Jupyter notebook is provided for researchers to implement the
framework in their own projects.

</details>
