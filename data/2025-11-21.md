<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 22]
- [econ.EM](#econ.EM) [Total: 3]
- [econ.GN](#econ.GN) [Total: 2]
- [cs.AI](#cs.AI) [Total: 56]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.SI](#cs.SI) [Total: 3]
- [eess.SY](#eess.SY) [Total: 14]
- [econ.TH](#econ.TH) [Total: 1]
- [cs.CY](#cs.CY) [Total: 16]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Gimballed Rotor Mechanism for Omnidirectional Quadrotors](https://arxiv.org/abs/2511.15909)
*J. Cristobal,A. Z. Zain Aldeen,M. Izadi,R. Faieghi*

Main category: cs.RO

TL;DR: 提出了一种采用万向节转子机制的模块化全向四旋翼设计，通过独立倾斜每个转子实现六自由度全驱动控制，无需对四旋翼主体结构进行重大改动。


<details>
  <summary>Details</summary>
Motivation: 传统四旋翼是欠驱动系统，无法独立控制所有六个自由度。现有全向四旋翼设计通常需要大幅结构改造，本设计旨在提供轻量化且易于集成的解决方案。

Method: 在转子平台内集成伺服电机，使每个转子能够独立倾斜，同时开发了PX4自动驾驶仪中的新控制分配方案。

Result: 成功进行了飞行测试，验证了所提出方法的有效性。

Conclusion: 万向节转子机制为构建全向四旋翼提供了一种模块化且高效的解决方案，实现了全驱动控制而无需重大结构修改。

Abstract: This paper presents the design of a gimballed rotor mechanism as a modular and efficient solution for constructing omnidirectional quadrotors. Unlike conventional quadrotors, which are underactuated, this class of quadrotors achieves full actuation, enabling independent motion in all six degrees of freedom. While existing omnidirectional quadrotor designs often require significant structural modifications, the proposed gimballed rotor system maintains a lightweight and easy-to-integrate design by incorporating servo motors within the rotor platforms, allowing independent tilting of each rotor without major alterations to the central structure of a quadrotor. To accommodate this unconventional design, we develop a new control allocation scheme in PX4 Autopilot and present successful flight tests, validating the effectiveness of the proposed approach.

</details>


### [2] [I've Changed My Mind: Robots Adapting to Changing Human Goals during Collaboration](https://arxiv.org/abs/2511.15914)
*Debasmita Ghose,Oz Gitelson,Ryan Jin,Grace Abawe,Marynel Vazquez,Brian Scassellati*

Main category: cs.RO

TL;DR: 提出了一种检测人类目标变化的方法，通过跟踪多个候选动作序列并与策略库验证其合理性。检测到变化后，机器人重新评估过去相关动作的信念，并使用Receding Horizon Planning树选择既能协助人类又能揭示更新目标的行动。


<details>
  <summary>Details</summary>
Motivation: 在真实世界场景中，人类经常在任务中途改变目标，这使得机器人在没有明确沟通的情况下难以适应。现有方法通常假设固定目标，将目标预测简化为一次性推理。

Method: 跟踪多个候选动作序列并验证其与策略库的合理性；检测到目标变化后，重新评估过去相关动作的信念；构建Receding Horizon Planning树来选择既能协助人类又能鼓励Differentiating Actions以揭示更新目标的行动。

Result: 在包含多达30个独特食谱的协作烹饪环境中评估，该方法优于三种可比的人类目标预测算法，在目标切换后快速收敛到正确目标，减少任务完成时间，提高协作效率。

Conclusion: 该方法能够有效检测人类目标变化并快速适应，显著提高了人机协作的效率和适应性。

Abstract: For effective human-robot collaboration, a robot must align its actions with human goals, even as they change mid-task. Prior approaches often assume fixed goals, reducing goal prediction to a one-time inference. However, in real-world scenarios, humans frequently shift goals, making it challenging for robots to adapt without explicit communication. We propose a method for detecting goal changes by tracking multiple candidate action sequences and verifying their plausibility against a policy bank. Upon detecting a change, the robot refines its belief in relevant past actions and constructs Receding Horizon Planning (RHP) trees to actively select actions that assist the human while encouraging Differentiating Actions to reveal their updated goal. We evaluate our approach in a collaborative cooking environment with up to 30 unique recipes and compare it to three comparable human goal prediction algorithms. Our method outperforms all baselines, quickly converging to the correct goal after a switch, reducing task completion time, and improving collaboration efficiency.

</details>


### [3] [The Role of Consequential and Functional Sound in Human-Robot Interaction: Toward Audio Augmented Reality Interfaces](https://arxiv.org/abs/2511.15956)
*Aliyah Smith,Monroe Kennedy*

Main category: cs.RO

TL;DR: 研究探索了机器人声音对人类感知和行为的影响，发现操作声音不会产生负面影响，侧向空间定位准确但正向定位下降，空间声音能同时传递任务信息并提升温暖感。


<details>
  <summary>Details</summary>
Motivation: 随着机器人日益融入日常生活，理解它们如何与人类沟通变得至关重要。声音作为强大的交互渠道，包括操作噪音和有意设计的听觉提示。

Method: 通过定位和交接任务，研究了结果性和功能性声音对人类感知和行为的影响，特别探索了空间声音的作用。

Result: Kinova Gen3机械臂的结果性声音未对感知产生负面影响；侧向空间定位高度准确，但正向定位下降；空间声音能同时传达任务相关信息并促进温暖感、减少不适。

Conclusion: 功能性和变革性听觉设计有潜力增强人机协作，并为未来基于声音的交互策略提供指导。

Abstract: As robots become increasingly integrated into everyday environments, understanding how they communicate with humans is critical. Sound offers a powerful channel for interaction, encompassing both operational noises and intentionally designed auditory cues. In this study, we examined the effects of consequential and functional sounds on human perception and behavior, including a novel exploration of spatial sound through localization and handover tasks. Results show that consequential sounds of the Kinova Gen3 manipulator did not negatively affect perceptions, spatial localization is highly accurate for lateral cues but declines for frontal cues, and spatial sounds can simultaneously convey task-relevant information while promoting warmth and reducing discomfort. These findings highlight the potential of functional and transformative auditory design to enhance human-robot collaboration and inform future sound-based interaction strategies.

</details>


### [4] [PushingBots: Collaborative Pushing via Neural Accelerated Combinatorial Hybrid Optimization](https://arxiv.org/abs/2511.15995)
*Zili Tang,Ying Zhang,Meng Guo*

Main category: cs.RO

TL;DR: 提出了一种多机器人协作推动任意形状物体到目标位置的方法，结合了动态任务分配和混合执行策略，通过关键帧引导的混合搜索优化推动模式序列，并在仿真和硬件实验中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 许多机器人没有机械臂，许多物体不适合抓取操作（如大箱子和圆柱体）。在这种情况下，推动是一种简单有效的非抓取技能，但现有工作通常假设预定义的推动模式和固定形状物体。本文解决了在复杂环境中控制机器人舰队协作推动多个任意物体到各自目标位置的一般问题。

Method: 基于组合混合优化的方法，包含三个主要组件：(I) 推动子任务的分解、排序和滚动分配给机器人子组；(II) 关键帧引导的混合搜索优化每个子任务的参数化推动模式序列；(III) 混合控制执行这些模式并在它们之间转换。还采用了基于扩散的加速器来预测关键帧和推动模式。

Result: 在仿真和硬件实验中广泛验证了该方法在不同机器人数量和一般形状物体下的效率和有效性，并推广到异构机器人、平面装配和6D推动任务。

Conclusion: 该框架在温和假设下是完备的，能够有效解决多机器人协作推动任意形状物体的复杂问题，展示了在复杂环境中的良好性能。

Abstract: Many robots are not equipped with a manipulator and many objects are not suitable for prehensile manipulation (such as large boxes and cylinders). In these cases, pushing is a simple yet effective non-prehensile skill for robots to interact with and further change the environment. Existing work often assumes a set of predefined pushing modes and fixed-shape objects. This work tackles the general problem of controlling a robotic fleet to push collaboratively numerous arbitrary objects to respective destinations, within complex environments of cluttered and movable obstacles. It incorporates several characteristic challenges for multi-robot systems such as online task coordination under large uncertainties of cost and duration, and for contact-rich tasks such as hybrid switching among different contact modes, and under-actuation due to constrained contact forces. The proposed method is based on combinatorial hybrid optimization over dynamic task assignments and hybrid execution via sequences of pushing modes and associated forces. It consists of three main components: (I) the decomposition, ordering and rolling assignment of pushing subtasks to robot subgroups; (II) the keyframe guided hybrid search to optimize the sequence of parameterized pushing modes for each subtask; (III) the hybrid control to execute these modes and transit among them. Last but not least, a diffusion-based accelerator is adopted to predict the keyframes and pushing modes that should be prioritized during hybrid search; and further improve planning efficiency. The framework is complete under mild assumptions. Its efficiency and effectiveness under different numbers of robots and general-shaped objects are validated extensively in simulations and hardware experiments, as well as generalizations to heterogeneous robots, planar assembly and 6D pushing.

</details>


### [5] [Semantic Glitch: Agency and Artistry in an Autonomous Pixel Cloud](https://arxiv.org/abs/2511.16048)
*Qing Zhang,Jing Huang,Mingyang Xu,Jun Rekimoto*

Main category: cs.RO

TL;DR: 本文提出了一种"低保真"机器人框架，通过语义理解和生物启发式人格创建具有不可预测行为的飞行机器人艺术装置，强调角色塑造而非效率。


<details>
  <summary>Details</summary>
Motivation: 探索主流机器人追求精确性能之外的创意潜力，通过"物理故障"和语义导航创造具有个性的不完美伴侣。

Method: 开发了基于多模态大语言模型的自主导航管道，摒弃传统传感器，仅依赖语义理解；通过自然语言提示为机器人创建生物启发式人格。

Result: 13分钟自主飞行日志显示出现涌现行为，包括基于地标的导航和"计划到执行"的差距；后续研究验证了框架在创建量化不同人格方面的鲁棒性。

Conclusion: 低保真框架成功创造了行为不可预测但可信的机器人伴侣，其成功标准是角色塑造而非效率，展示了语义理解在机器人艺术中的潜力。

Abstract: While mainstream robotics pursues metric precision and flawless performance, this paper explores the creative potential of a deliberately "lo-fi" approach. We present the "Semantic Glitch," a soft flying robotic art installation whose physical form, a 3D pixel style cloud, is a "physical glitch" derived from digital archaeology. We detail a novel autonomous pipeline that rejects conventional sensors like LiDAR and SLAM, relying solely on the qualitative, semantic understanding of a Multimodal Large Language Model to navigate. By authoring a bio-inspired personality for the robot through a natural language prompt, we create a "narrative mind" that complements the "weak," historically, loaded body. Our analysis begins with a 13-minute autonomous flight log, and a follow-up study statistically validates the framework's robustness for authoring quantifiably distinct personas. The combined analysis reveals emergent behaviors, from landmark-based navigation to a compelling "plan to execution" gap, and a character whose unpredictable, plausible behavior stems from a lack of precise proprioception. This demonstrates a lo-fi framework for creating imperfect companions whose success is measured in character over efficiency.

</details>


### [6] [Bi-AQUA: Bilateral Control-Based Imitation Learning for Underwater Robot Arms via Lighting-Aware Action Chunking with Transformers](https://arxiv.org/abs/2511.16050)
*Takeru Tsunoori,Masato Kobayashi,Yuki Uranishi*

Main category: cs.RO

TL;DR: Bi-AQUA是首个基于双边控制的水下模仿学习框架，通过三层光照适应机制解决水下机器人操作中的极端光照变化问题，在真实水下拾放任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 水下机器人操作面临极端光照变化、颜色失真和能见度降低等根本性挑战，需要开发能够适应这些视觉干扰的鲁棒控制系统。

Method: 采用分层三层光照适应机制：1）无需手动标注的照明编码器从RGB图像提取光照表示；2）通过FiLM调制视觉骨干特征进行自适应光照感知特征提取；3）在transformer编码器输入中添加显式光照标记进行任务感知条件化。

Result: 在真实水下拾放任务的各种静态和动态光照条件下，Bi-AQUA实现了鲁棒性能，显著优于没有光照建模的双边基线。消融研究证实所有三个光照感知组件都至关重要。

Conclusion: 这项工作连接了陆地双边控制模仿学习与水下操作，使具有力感知的自主操作能够在具有挑战性的海洋环境中实现。

Abstract: Underwater robotic manipulation is fundamentally challenged by extreme lighting variations, color distortion, and reduced visibility. We introduce Bi-AQUA, the first underwater bilateral control-based imitation learning framework that integrates lighting-aware visual processing for underwater robot arms. Bi-AQUA employs a hierarchical three-level lighting adaptation mechanism: a Lighting Encoder that extracts lighting representations from RGB images without manual annotation and is implicitly supervised by the imitation objective, FiLM modulation of visual backbone features for adaptive, lighting-aware feature extraction, and an explicit lighting token added to the transformer encoder input for task-aware conditioning. Experiments on a real-world underwater pick-and-place task under diverse static and dynamic lighting conditions show that Bi-AQUA achieves robust performance and substantially outperforms a bilateral baseline without lighting modeling. Ablation studies further confirm that all three lighting-aware components are critical. This work bridges terrestrial bilateral control-based imitation learning and underwater manipulation, enabling force-sensitive autonomous operation in challenging marine environments. For additional material, please check: https://mertcookimg.github.io/bi-aqua

</details>


### [7] [MagBotSim: Physics-Based Simulation and Reinforcement Learning Environments for Magnetic Robotics](https://arxiv.org/abs/2511.16158)
*Lara Bergmann,Cedric Grothues,Klaus Neumann*

Main category: cs.RO

TL;DR: 该论文提出了MagBotSim，一个用于磁悬浮系统的物理仿真平台，将磁悬浮系统视为机器人集群，旨在推动下一代制造系统的发展。


<details>
  <summary>Details</summary>
Motivation: 磁悬浮系统在工业自动化中具有动态运输和操纵的潜力，但目前尚未充分利用。通过将运输和操纵功能整合到协调的磁机器人集群中，可以显著提高制造系统的效率、适应性和紧凑性。

Method: 开发了MagBotSim，这是一个基于物理的磁悬浮系统仿真平台，将磁悬浮系统框架化为机器人集群，为智能算法开发提供支持。

Result: 提出了MagBotSim仿真平台，包括文档、视频、实验和代码，为磁机器人技术驱动的下一代制造系统奠定了基础。

Conclusion: 通过将磁悬浮系统视为机器人集群并提供专用仿真，这项工作为基于磁机器人技术的下一代制造系统奠定了基础。

Abstract: Magnetic levitation is about to revolutionize in-machine material flow in industrial automation. Such systems are flexibly configurable and can include a large number of independently actuated shuttles (movers) that dynamically rebalance production capacity. Beyond their capabilities for dynamic transportation, these systems possess the inherent yet unexploited potential to perform manipulation. By merging the fields of transportation and manipulation into a coordinated swarm of magnetic robots (MagBots), we enable manufacturing systems to achieve significantly higher efficiency, adaptability, and compactness. To support the development of intelligent algorithms for magnetic levitation systems, we introduce MagBotSim (Magnetic Robotics Simulation): a physics-based simulation for magnetic levitation systems. By framing magnetic levitation systems as robot swarms and providing a dedicated simulation, this work lays the foundation for next generation manufacturing systems powered by Magnetic Robotics. MagBotSim's documentation, videos, experiments, and code are available at: https://ubi-coro.github.io/MagBotSim/

</details>


### [8] [PIPHEN: Physical Interaction Prediction with Hamiltonian Energy Networks](https://arxiv.org/abs/2511.16200)
*Kewei Chen,Yayu Long,Mingsheng Shang*

Main category: cs.RO

TL;DR: PIPHEN框架通过语义通信替代原始数据传输，解决了多机器人系统中的"共享大脑困境"，将信息压缩至原数据的5%以下，决策延迟从315ms降至76ms。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统在复杂物理协作中面临的高维多媒体数据传输带宽瓶颈和决策延迟问题，即"共享大脑困境"。

Method: 提出PIPHEN分布式物理认知控制框架，包含两个关键组件：基于大模型知识蒸馏的物理交互预测网络(PIPN)生成紧凑物理表示，以及基于能量守恒的哈密顿能量网络(HEN)控制器将表示转化为协调动作。

Result: 信息表示压缩至原数据量的5%以下，协作决策延迟从315ms减少到76ms，同时显著提高了任务成功率。

Conclusion: 该工作为资源受限的多机器人系统解决"共享大脑困境"提供了一个根本性的高效范式。

Abstract: Multi-robot systems in complex physical collaborations face a "shared brain dilemma": transmitting high-dimensional multimedia data (e.g., video streams at ~30MB/s) creates severe bandwidth bottlenecks and decision-making latency. To address this, we propose PIPHEN, an innovative distributed physical cognition-control framework. Its core idea is to replace "raw data communication" with "semantic communication" by performing "semantic distillation" at the robot edge, reconstructing high-dimensional perceptual data into compact, structured physical representations. This idea is primarily realized through two key components: (1) a novel Physical Interaction Prediction Network (PIPN), derived from large model knowledge distillation, to generate this representation; and (2) a Hamiltonian Energy Network (HEN) controller, based on energy conservation, to precisely translate this representation into coordinated actions. Experiments show that, compared to baseline methods, PIPHEN can compress the information representation to less than 5% of the original data volume and reduce collaborative decision-making latency from 315ms to 76ms, while significantly improving task success rates. This work provides a fundamentally efficient paradigm for resolving the "shared brain dilemma" in resource-constrained multi-robot systems.

</details>


### [9] [DynaMimicGen: A Data Generation Framework for Robot Learning of Dynamic Tasks](https://arxiv.org/abs/2511.16223)
*Vincenzo Pomponi,Paolo Franceschi,Stefano Baraldo,Loris Roveda,Oliver Avram,Luca Maria Gambardella,Anna Valente*

Main category: cs.RO

TL;DR: DynaMimicGen (D-MG) 是一个可扩展的数据集生成框架，仅需少量人类演示就能训练机器人操作策略，特别支持动态任务设置。它通过分割演示为子任务并使用动态运动基元来适应动态环境变化。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量多样化的数据集来学习鲁棒的操作策略，但数据收集耗时费力，且在动态环境中不实用。需要一种能从少量人类监督中学习并适应动态环境的方法。

Method: D-MG首先将少量人类演示分割为有意义的子任务，然后利用动态运动基元(DMPs)来适应和泛化演示行为到新颖和动态变化的环境。相比依赖静态假设或简单轨迹插值的方法，D-MG生成平滑、真实且任务一致的笛卡尔轨迹。

Result: 在模仿学习中使用D-MG生成的数据训练的机器人代理，在长视野和接触丰富的基准测试中表现出色，包括积木堆叠和将杯子放入抽屉等任务，即使在不可预测的环境变化下也能保持良好性能。

Conclusion: D-MG通过消除对大量人类演示的需求并支持动态环境中的泛化，为手动数据收集提供了强大而高效的替代方案，为可扩展的自主机器人学习铺平了道路。

Abstract: Learning robust manipulation policies typically requires large and diverse datasets, the collection of which is time-consuming, labor-intensive, and often impractical for dynamic environments. In this work, we introduce DynaMimicGen (D-MG), a scalable dataset generation framework that enables policy training from minimal human supervision while uniquely supporting dynamic task settings. Given only a few human demonstrations, D-MG first segments the demonstrations into meaningful sub-tasks, then leverages Dynamic Movement Primitives (DMPs) to adapt and generalize the demonstrated behaviors to novel and dynamically changing environments. Improving prior methods that rely on static assumptions or simplistic trajectory interpolation, D-MG produces smooth, realistic, and task-consistent Cartesian trajectories that adapt in real time to changes in object poses, robot states, or scene geometry during task execution. Our method supports different scenarios - including scene layouts, object instances, and robot configurations - making it suitable for both static and highly dynamic manipulation tasks. We show that robot agents trained via imitation learning on D-MG-generated data achieve strong performance across long-horizon and contact-rich benchmarks, including tasks like cube stacking and placing mugs in drawers, even under unpredictable environment changes. By eliminating the need for extensive human demonstrations and enabling generalization in dynamic settings, D-MG offers a powerful and efficient alternative to manual data collection, paving the way toward scalable, autonomous robot learning.

</details>


### [10] [FT-NCFM: An Influence-Aware Data Distillation Framework for Efficient VLA Models](https://arxiv.org/abs/2511.16233)
*Kewei Chen,Yayu Long,Shuai Li,Mingsheng Shang*

Main category: cs.RO

TL;DR: FT-NCFM是一个数据中心的生成式数据蒸馏框架，通过事实追踪引擎评估样本内在价值，然后合成模型无关、信息密集的可重用数据资产，仅用5%的蒸馏核心集就能达到全数据集85-90%的性能，同时减少80%以上的训练时间。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型依赖大量冗余且价值不均的数据集，阻碍了广泛应用。模型中心的优化方法如模型压缩或策略蒸馏无法从根本上解决数据层面的挑战。

Method: 采用事实追踪引擎结合因果归因和程序化对比验证来评估样本内在价值，然后通过对抗性NCFM过程合成模型无关、信息密集的可重用数据资产。

Result: 在多个主流VLA基准测试中，仅使用5%的蒸馏核心集训练的模型就能达到全数据集85-90%的成功率，同时减少80%以上的训练时间。

Conclusion: 智能数据蒸馏是构建高效高性能VLA模型的一条极具前景的新路径。

Abstract: The powerful generalization of Vision-Language-Action (VLA) models is bottlenecked by their heavy reliance on massive, redundant, and unevenly valued datasets, hindering their widespread application. Existing model-centric optimization paths, such as model compression (which often leads to performance degradation) or policy distillation (whose products are model-dependent and lack generality), fail to fundamentally address this data-level challenge. To this end, this paper introduces FT-NCFM, a fundamentally different, data-centric generative data distillation framework. Our framework employs a self-contained Fact-Tracing (FT) engine that combines causal attribution with programmatic contrastive verification to assess the intrinsic value of samples. Guided by these assessments, an adversarial NCFM process synthesizes a model-agnostic, information-dense, and reusable data asset. Experimental results on several mainstream VLA benchmarks show that models trained on just 5% of our distilled coreset achieve a success rate of 85-90% compared with training on the full dataset, while reducing training time by over 80%. Our work demonstrates that intelligent data distillation is a highly promising new path for building efficient, high-performance VLA models.

</details>


### [11] [How Robot Dogs See the Unseeable](https://arxiv.org/abs/2511.16262)
*Oliver Bimber,Karl Dietrich von Ellenrieder,Michael Haller,Rakesh John Amala Arokia Nathan,Gianni Lunardi,Marco Camurri,Mohamed Youssef,Santos Miguel Orozco Soto,Jeremy E. Niven*

Main category: cs.RO

TL;DR: 该论文提出了一种基于动物摇摆行为的合成孔径感知方法，通过机器人执行摇摆运动来创建宽合成孔径，从而有效消除遮挡物干扰，恢复被遮挡的背景信息。


<details>
  <summary>Details</summary>
Motivation: 传统机器人相机由于小孔径和大景深，导致前景遮挡物和背景物体都清晰成像，遮挡物会掩盖关键场景信息。受动物通过摇摆运动估计距离的启发，旨在克服机器人视觉中的部分遮挡问题。

Method: 让机器人执行摇摆运动，使其相机描述一个宽合成孔径。通过计算整合捕获的图像，合成具有极浅景深的图像，有效模糊遮挡元素同时使背景清晰聚焦。

Result: 该方法能够实时、高分辨率地感知各种光谱带，不仅恢复了基本场景理解，还增强了大型多模态模型的高级视觉推理能力，而传统遮挡图像会导致这些模型失效。

Conclusion: 通过摇摆运动进行合成孔径感知是复杂杂乱环境中高级场景理解的关键，这种方法对遮挡具有鲁棒性、计算效率高，可立即部署在任何移动机器人上。

Abstract: Peering, a side-to-side motion used by animals to estimate distance through motion parallax, offers a powerful bio-inspired strategy to overcome a fundamental limitation in robotic vision: partial occlusion. Conventional robot cameras, with their small apertures and large depth of field, render both foreground obstacles and background objects in sharp focus, causing occluders to obscure critical scene information. This work establishes a formal connection between animal peering and synthetic aperture (SA) sensing from optical imaging. By having a robot execute a peering motion, its camera describes a wide synthetic aperture. Computational integration of the captured images synthesizes an image with an extremely shallow depth of field, effectively blurring out occluding elements while bringing the background into sharp focus. This efficient, wavelength-independent technique enables real-time, high-resolution perception across various spectral bands. We demonstrate that this approach not only restores basic scene understanding but also empowers advanced visual reasoning in large multimodal models, which fail with conventionally occluded imagery. Unlike feature-dependent multi-view 3D vision methods or active sensors like LiDAR, SA sensing via peering is robust to occlusion, computationally efficient, and immediately deployable on any mobile robot. This research bridges animal behavior and robotics, suggesting that peering motions for synthetic aperture sensing are a key to advanced scene understanding in complex, cluttered environments.

</details>


### [12] [Funabot-Upper: McKibben Actuated Haptic Suit Inducing Kinesthetic Perceptions in Trunk, Shoulder, Elbow, and Wrist](https://arxiv.org/abs/2511.16265)
*Haru Fukatsu,Ryoji Yasuda,Yuki Funabora,Shinji Doki*

Main category: cs.RO

TL;DR: Funabot-Upper是一种可穿戴触觉套装，能够通过刺激关节和肌肉独立地诱导用户感知14种上半身运动，相比之前的版本显著减少了感知混合问题，识别准确率从68.8%提升到94.6%。


<details>
  <summary>Details</summary>
Motivation: 现有的可穿戴触觉设备主要局限于单个身体部位的验证，很少有能够同时应用于多个身体部位的方法。之前的研究中，在肩部和肘部之间出现了感知混合问题，需要新的设计策略来解决这一问题。

Method: 建立了一个新的简化设计策略，开发了新型触觉套装，通过独立刺激关节和肌肉来诱导躯干、肩部、肘部和腕部的动觉感知。实验验证了诱导的动觉感知，并研究了刺激与感知动觉之间的关系。

Result: 实验证实Funabot-Upper成功诱导了多个关节的动觉感知，同时减少了之前设计中观察到的感知混合。与之前的Funabot-Suit相比，新套装的识别准确率从68.8%提高到了94.6%。

Conclusion: 新的设计策略有效解决了多部位触觉刺激中的感知混合问题，Funabot-Upper展示了其在未来触觉应用中的优越性和潜力。

Abstract: This paper presents Funabot-Upper, a wearable haptic suit that enables users to perceive 14 upper-body motions, including those of the trunk, shoulder, elbow, and wrist. Inducing kinesthetic perception through wearable haptic devices has attracted attention, and various devices have been developed in the past. However, these have been limited to verifications on single body parts, and few have applied the same method to multiple body parts as well. In our previous study, we developed a technology that uses the contraction of artificial muscles to deform clothing in three dimensions. Using this technology, we developed a haptic suit that induces kinesthetic perception of 7 motions in multiple upper body. However, perceptual mixing caused by stimulating multiple human muscles has occurred between the shoulder and the elbow. In this paper, we established a new, simplified design policy and developed a novel haptic suit that induces kinesthetic perceptions in the trunk, shoulder, elbow, and wrist by stimulating joints and muscles independently. We experimentally demonstrated the induced kinesthetic perception and examined the relationship between stimulation and perceived kinesthetic perception under the new design policy. Experiments confirmed that Funabot-Upper successfully induces kinesthetic perception across multiple joints while reducing perceptual mixing observed in previous designs. The new suit improved recognition accuracy from 68.8% to 94.6% compared to the previous Funabot-Suit, demonstrating its superiority and potential for future haptic applications.

</details>


### [13] [InEKFormer: A Hybrid State Estimator for Humanoid Robots](https://arxiv.org/abs/2511.16306)
*Lasse Hohmeyer,Mihaela Popescu,Ivan Bergonzani,Dennis Mronga,Frank Kirchner*

Main category: cs.RO

TL;DR: 提出了一种结合不变扩展卡尔曼滤波器和Transformer网络的混合状态估计方法InEKFormer，用于人形机器人的状态估计，并在RH5机器人数据集上验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在不同环境中的双足运动仍面临稳定性和动态性的挑战，状态估计对运动控制至关重要。传统卡尔曼滤波方法需要专家知识调整噪声参数，而深度学习方法在状态估计任务中显示出潜力。

Method: 提出InEKFormer混合方法，结合不变扩展卡尔曼滤波器(InEKF)和Transformer网络，利用InEKF处理机器人运动学约束，Transformer网络学习残差补偿。

Result: 在RH5人形机器人数据集上比较了InEKFormer、InEKF和KalmanNet方法，结果表明Transformer在人形状态估计中具有潜力，但也揭示了高维问题中需要稳健的自回归训练。

Conclusion: Transformer网络在人形机器人状态估计中展现出应用前景，但需要解决高维问题中的自回归训练稳定性问题，混合方法结合了传统滤波器和深度学习的优势。

Abstract: Humanoid robots have great potential for a wide range of applications, including industrial and domestic use, healthcare, and search and rescue missions. However, bipedal locomotion in different environments is still a challenge when it comes to performing stable and dynamic movements. This is where state estimation plays a crucial role, providing fast and accurate feedback of the robot's floating base state to the motion controller. Although classical state estimation methods such as Kalman filters are widely used in robotics, they require expert knowledge to fine-tune the noise parameters. Due to recent advances in the field of machine learning, deep learning methods are increasingly used for state estimation tasks. In this work, we propose the InEKFormer, a novel hybrid state estimation method that incorporates an invariant extended Kalman filter (InEKF) and a Transformer network. We compare our method with the InEKF and the KalmanNet approaches on datasets obtained from the humanoid robot RH5. The results indicate the potential of Transformers in humanoid state estimation, but also highlight the need for robust autoregressive training in these high-dimensional problems.

</details>


### [14] [Safe and Optimal Variable Impedance Control via Certified Reinforcement Learning](https://arxiv.org/abs/2511.16330)
*Shreyas Kumar,Ravi Prakash*

Main category: cs.RO

TL;DR: 提出了C-GMS框架，通过采样稳定增益流形来学习DMP和VIC策略，保证李雅普诺夫稳定性和执行器可行性，无需奖励惩罚或后验验证。


<details>
  <summary>Details</summary>
Motivation: 传统无模型强化学习在机器人协作技能学习中存在不稳定和不安全探索的风险，特别是阻抗增益的时变特性。

Method: C-GMS框架将策略探索重新定义为从数学定义的稳定增益流形中采样，确保每个策略部署都是稳定且物理可实现的。

Result: 在仿真和真实机器人上验证了有效性，即使在有界模型误差和部署时不确定性的情况下也能保证有界跟踪误差。

Conclusion: C-GMS为复杂环境中的可靠自主交互铺平了道路，提供了理论保证的稳定学习框架。

Abstract: Reinforcement learning (RL) offers a powerful approach for robots to learn complex, collaborative skills by combining Dynamic Movement Primitives (DMPs) for motion and Variable Impedance Control (VIC) for compliant interaction. However, this model-free paradigm often risks instability and unsafe exploration due to the time-varying nature of impedance gains. This work introduces Certified Gaussian Manifold Sampling (C-GMS), a novel trajectory-centric RL framework that learns combined DMP and VIC policies while guaranteeing Lyapunov stability and actuator feasibility by construction. Our approach reframes policy exploration as sampling from a mathematically defined manifold of stable gain schedules. This ensures every policy rollout is guaranteed to be stable and physically realizable, thereby eliminating the need for reward penalties or post-hoc validation. Furthermore, we provide a theoretical guarantee that our approach ensures bounded tracking error even in the presence of bounded model errors and deployment-time uncertainties. We demonstrate the effectiveness of C-GMS in simulation and verify its efficacy on a real robot, paving the way for reliable autonomous interaction in complex environments.

</details>


### [15] [Flow-Aided Flight Through Dynamic Clutters From Point To Motion](https://arxiv.org/abs/2511.16372)
*Bowen Xu,Zexuan Yan,Minghao Lu,Xiyu Fan,Yi Luo,Youshen Lin,Zhiqiang Chen,Yeke Chen,Qiyuan Qiao,Peng Lu*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习和单激光雷达感知的动态避障系统，通过深度感知距离图和点流运动特征来表征动态环境，无需显式建模障碍物运动即可实现自主飞行。


<details>
  <summary>Details</summary>
Motivation: 传统方法在动态环境中显式建模障碍物运动耗时且不可靠，特别是在遮挡严重的高度动态场景中。需要一种不依赖目标检测、跟踪和预测的直接感知到运动的方法。

Method: 使用单激光雷达感知，将原始点云编码为固定形状、低分辨率且保留细节的深度距离图，并从多帧观测中提取点流作为运动特征。这两种特征集成形成轻量级的环境表示，通过强化学习训练策略，采用相对运动调制的距离场进行策略优化。

Result: 所提出的系统在部署友好的传感仿真和无动力学模型加速控制下，显示出比替代方案更高的成功率和适应性，从模拟器推导的策略能够在真实四旋翼上实现安全机动。

Conclusion: 该方法通过变化感知的传感表示隐式驱动避障行为，避免了显式运动建模的复杂性，在动态杂乱环境中实现了高效可靠的自主飞行。

Abstract: Challenges in traversing dynamic clutters lie mainly in the efficient perception of the environmental dynamics and the generation of evasive behaviors considering obstacle movement. Previous solutions have made progress in explicitly modeling the dynamic obstacle motion for avoidance, but this key dependency of decision-making is time-consuming and unreliable in highly dynamic scenarios with occlusions. On the contrary, without introducing object detection, tracking, and prediction, we empower the reinforcement learning (RL) with single LiDAR sensing to realize an autonomous flight system directly from point to motion. For exteroception, a depth sensing distance map achieving fixed-shape, low-resolution, and detail-safe is encoded from raw point clouds, and an environment change sensing point flow is adopted as motion features extracted from multi-frame observations. These two are integrated into a lightweight and easy-to-learn representation of complex dynamic environments. For action generation, the behavior of avoiding dynamic threats in advance is implicitly driven by the proposed change-aware sensing representation, where the policy optimization is indicated by the relative motion modulated distance field. With the deployment-friendly sensing simulation and dynamics model-free acceleration control, the proposed system shows a superior success rate and adaptability to alternatives, and the policy derived from the simulator can drive a real-world quadrotor with safe maneuvers.

</details>


### [16] [Robot Metacognition: Decision Making with Confidence for Tool Invention](https://arxiv.org/abs/2511.16390)
*Ajith Anil Meera,Poppy Collis,Polina Arbuzova,Abián Torres,Paul F Kinghorn,Ricardo Sanz,Pablo Lanillos*

Main category: cs.RO

TL;DR: 提出了一种基于置信度的机器人元认知架构，使机器人能够评估自身决策的可靠性，从而提高在现实世界物理部署中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人缺乏对人类智能行为至关重要的元认知能力，即反思自身认知过程和决策的能力。这种自我监控能力对人类的学习、决策和问题解决至关重要。

Method: 受神经科学启发，提出了以置信度为中心的机器人元认知架构，将置信度作为机器人决策方案中的元认知度量，强调通过具身行动监控来实现更明智的决策。

Result: 在自主工具发明的用例中展示了该架构，置信度告知的机器人能够评估其决策的可靠性。

Conclusion: 机器人元认知能够提高决策的鲁棒性，并指出了机器人元认知的潜在应用和研究方向。

Abstract: Robots today often miss a key ingredient of truly intelligent behavior: the ability to reflect on their own cognitive processes and decisions. In humans, this self-monitoring or metacognition is crucial for learning, decision making and problem solving. For instance, they can evaluate how confident they are in performing a task, thus regulating their own behavior and allocating proper resources. Taking inspiration from neuroscience, we propose a robot metacognition architecture centered on confidence (a second-order judgment on decisions) and we demonstrate it on the use case of autonomous tool invention. We propose the use of confidence as a metacognitive measure within the robot decision making scheme. Confidence-informed robots can evaluate the reliability of their decisions, improving their robustness during real-world physical deployment. This form of robotic metacognition emphasizes embodied action monitoring as a means to achieve better informed decisions. We also highlight potential applications and research directions for robot metacognition.

</details>


### [17] [Homogeneous Proportional-Integral-Derivative Controller in Mobile Robotic Manipulators](https://arxiv.org/abs/2511.16406)
*Luis Luna,Isaac Chairez,Andrey Polyakov*

Main category: cs.RO

TL;DR: 提出了一种新型的齐次PID控制策略，用于移动机器人操纵器的鲁棒协调运动控制，通过齐次控制理论提升系统稳定性和收敛性。


<details>
  <summary>Details</summary>
Motivation: 移动机器人操纵器由于非线性动力学、欠驱动特性以及基座与机械臂子系统间的耦合，面临显著的控制挑战，需要更鲁棒的控制策略。

Method: 设计齐次PID结构，将传统PID增益推广为非线性、状态相关的函数，采用分级齐次性方法改进跟踪误差收敛，基于Lyapunov方法进行稳定性分析。

Result: 实验验证表明hPID控制器在移动基座和机械臂的高精度轨迹跟踪方面优于传统线性PID控制器，在响应时间、稳态误差和模型不确定性鲁棒性方面表现更优。

Conclusion: 该研究为增强下一代移动操纵系统在结构化和非结构化环境中的自主性和可靠性提供了一个可扩展且分析基础扎实的控制框架。

Abstract: Mobile robotic manipulators (MRMs), which integrate mobility and manipulation capabilities, present significant control challenges due to their nonlinear dynamics, underactuation, and coupling between the base and manipulator subsystems. This paper proposes a novel homogeneous Proportional-Integral-Derivative (hPID) control strategy tailored for MRMs to achieve robust and coordinated motion control. Unlike classical PID controllers, the hPID controller leverages the mathematical framework of homogeneous control theory to systematically enhance the stability and convergence properties of the closed-loop system, even in the presence of dynamic uncertainties and external disturbances involved into a system in a homogeneous way. A homogeneous PID structure is designed, ensuring improved convergence of tracking errors through a graded homogeneity approach that generalizes traditional PID gains to nonlinear, state-dependent functions. Stability analysis is conducted using Lyapunov-based methods, demonstrating that the hPID controller guarantees global asymptotic stability and finite-time convergence under mild assumptions. Experimental results on a representative MRM model validate the effectiveness of the hPID controller in achieving high-precision trajectory tracking for both the mobile base and manipulator arm, outperforming conventional linear PID controllers in terms of response time, steady-state error, and robustness to model uncertainties. This research contributes a scalable and analytically grounded control framework for enhancing the autonomy and reliability of next-generation mobile manipulation systems in structured and unstructured environments.

</details>


### [18] [LAOF: Robust Latent Action Learning with Optical Flow Constraints](https://arxiv.org/abs/2511.16407)
*Xizhou Bu,Jiexi Lyu,Fulei Sun,Ruichen Yang,Zhiqiang Ma,Wei Li*

Main category: cs.RO

TL;DR: LAOF是一个利用光流作为动作驱动信号的伪监督框架，通过学习对干扰物具有鲁棒性的潜在动作表示，在标签稀缺条件下显著提升下游模仿学习和强化学习任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从大规模视频中学习潜在动作时容易受到动作无关干扰物的影响，而动作监督的有效性受限于可用动作标签的稀缺性。光流能够自然抑制背景元素并强调运动物体，因此被用作动作驱动信号。

Method: 提出LAOF框架，利用智能体的光流作为动作驱动信号，通过光流约束学习对干扰物具有鲁棒性的潜在动作表示。这是一种伪监督方法，不需要大量动作标签。

Result: 实验结果显示，LAOF学习的潜在表示在下游模仿学习和强化学习任务中优于现有方法。光流约束显著稳定了训练过程，在极低标签条件下提高了表示质量，即使在10%标签比例下仍保持有效。

Conclusion: LAOF在没有动作监督的情况下，性能可匹敌或超越使用1%动作标签的监督方法，证明了光流约束在动作表示学习中的有效性，特别是在标签稀缺场景下。

Abstract: Learning latent actions from large-scale videos is crucial for the pre-training of scalable embodied foundation models, yet existing methods often struggle with action-irrelevant distractors. Although incorporating action supervision can alleviate these distractions, its effectiveness is restricted by the scarcity of available action labels. Optical flow represents pixel-level motion between consecutive frames, naturally suppressing background elements and emphasizing moving objects. Motivated by this, we propose robust Latent Action learning with Optical Flow constraints, called LAOF, a pseudo-supervised framework that leverages the agent's optical flow as an action-driven signal to learn latent action representations robust to distractors. Experimental results show that the latent representations learned by LAOF outperform existing methods on downstream imitation learning and reinforcement learning tasks. This superior performance arises from optical flow constraints, which substantially stabilize training and improve the quality of latent representations under extremely label-scarce conditions, while remaining effective as the proportion of action labels increases to 10 percent. Importantly, even without action supervision, LAOF matches or surpasses action-supervised methods trained with 1 percent of action labels.

</details>


### [19] [From Prompts to Printable Models: Support-Effective 3D Generation via Offset Direct Preference Optimization](https://arxiv.org/abs/2511.16434)
*Chenming Wu,Xiaofan Li,Chengkai Dai*

Main category: cs.RO

TL;DR: SEG是一个新颖的3D生成框架，通过将带有偏移的直接偏好优化(ODPO)集成到3D生成流程中，直接优化模型以减少支撑材料使用。


<details>
  <summary>Details</summary>
Motivation: 当前3D打印从数字模型到物理对象的转换需要支撑结构来防止悬垂特征在制造过程中坍塌，但现有切片技术主要关注后处理优化，而非在模型生成阶段解决支撑效率问题。

Method: SEG框架将支撑结构模拟集成到训练过程中，使用直接偏好优化与偏移(ODPO)来鼓励生成需要较少支撑的几何形状。

Result: 在Thingi10k-Val和GPT-3DP-Val两个基准数据集上的实验表明，SEG在支撑体积减少和可打印性方面显著优于TRELLIS、DPO和DRO等基线模型。

Conclusion: SEG通过在生成过程中直接优化模型，有潜力改变3D打印实践，为更可持续和高效的数字制造铺平道路。

Abstract: The transition from digital 3D models to physical objects via 3D printing often requires support structures to prevent overhanging features from collapsing during the fabrication process. While current slicing technologies offer advanced support strategies, they focus on post-processing optimizations rather than addressing the underlying need for support-efficient design during the model generation phase. This paper introduces SEG (\textit{\underline{S}upport-\underline{E}ffective \underline{G}eneration}), a novel framework that integrates Direct Preference Optimization with an Offset (ODPO) into the 3D generation pipeline to directly optimize models for minimal support material usage. By incorporating support structure simulation into the training process, SEG encourages the generation of geometries that inherently require fewer supports, thus reducing material waste and production time. We demonstrate SEG's effectiveness through extensive experiments on two benchmark datasets, Thingi10k-Val and GPT-3DP-Val, showing that SEG significantly outperforms baseline models such as TRELLIS, DPO, and DRO in terms of support volume reduction and printability. Qualitative results further reveal that SEG maintains high fidelity to input prompts while minimizing the need for support structures. Our findings highlight the potential of SEG to transform 3D printing by directly optimizing models during the generative process, paving the way for more sustainable and efficient digital fabrication practices.

</details>


### [20] [MiMo-Embodied: X-Embodied Foundation Model Technical Report](https://arxiv.org/abs/2511.16518)
*Xiaoshuai Hao,Lei Zhou,Zhijian Huang,Zhiwen Hou,Yingbo Tang,Lingfeng Zhang,Guang Li,Zheng Lu,Shuhuai Ren,Xianhui Meng,Yuchen Zhang,Jing Wu,Jinghui Lu,Chenxu Dang,Jiayi Guan,Jianhua Wu,Zhiyi Hou,Hanbing Li,Shumeng Xia,Mingliang Zhou,Yinan Zheng,Zihao Yue,Shuhao Gu,Hao Tian,Yuannan Shen,Jianwei Cui,Wen Zhang,Shaoqing Xu,Bing Wang,Haiyang Sun,Zeyu Zhu,Yuncheng Jiang,Zibin Guo,Chuhong Gong,Chaofan Zhang,Wenbo Ding,Kun Ma,Guang Chen,Rui Cai,Diyun Xiang,Heng Qu,Fuli Luo,Hangjun Ye,Long Chen*

Main category: cs.RO

TL;DR: MiMo-Embodied是首个在自动驾驶和具身AI领域都取得SOTA性能的跨具身基础模型，在29个基准测试中创下新记录。


<details>
  <summary>Details</summary>
Motivation: 探索自动驾驶和具身AI两个领域之间的正迁移效应，证明通过多阶段学习、精心构建的数据和微调方法，这两个领域可以相互促进。

Method: 采用多阶段学习、精心构建的数据集、CoT/RL微调等方法，整合了两个领域的训练数据和技术。

Result: 在17个具身AI基准测试（任务规划、功能预测、空间理解）和12个自动驾驶基准测试（环境感知、状态预测、驾驶规划）中均创下新记录，显著超越现有开源、闭源和专用基线模型。

Conclusion: 自动驾驶和具身AI领域存在强正迁移效应，可以相互促进；多阶段学习、数据构建和微调方法是实现跨领域成功的关键；模型设计和训练方法为后续研究提供了参考。

Abstract: We open-source MiMo-Embodied, the first cross-embodied foundation model to successfully integrate and achieve state-of-the-art performance in both Autonomous Driving and Embodied AI. MiMo-Embodied sets new records across 17 embodied AI benchmarks in Task Planning, Affordance Prediction and Spatial Understanding, while also excelling in 12 autonomous driving benchmarks across Environmental Perception, Status Prediction, and Driving Planning. Across these tasks, MiMo-Embodied significantly outperforms existing open-source, closed-source, and specialized baselines. Our results indicate that through multi-stage learning, curated data construction, and CoT/RL fine-tuning, these two domains exhibit strong positive transfer and mutually reinforce one another. We provide a detailed analysis of our model design and training methodologies to facilitate further research. Code and models are available at https://github.com/XiaomiMiMo/MiMo-Embodied.

</details>


### [21] [InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy](https://arxiv.org/abs/2511.16651)
*Yang Tian,Yuyin Yang,Yiman Xie,Zetao Cai,Xu Shi,Ning Gao,Hangxu Liu,Xuekun Jiang,Zherui Qiu,Feng Yuan,Yaping Li,Ping Wang,Junhao Cai,Jia Zeng,Hao Dong,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 本文首次证明仅使用合成数据就能达到最强真实数据集在VLA模型预训练中的性能，展示了大规模仿真的巨大价值，并实现了令人惊讶的零样本仿真到现实迁移。


<details>
  <summary>Details</summary>
Motivation: 探索合成数据在视觉-语言-动作模型泛化中的作用，验证大规模仿真数据是否能替代真实机器人数据用于VLA模型预训练。

Method: 构建InternData-A1合成数据集，包含63万条轨迹、7433小时数据，涵盖4种机器人形态、18种技能、70个任务和227个场景。采用高度自主、完全解耦的组合式仿真流水线，支持长时程技能组合、灵活任务组装和异构机器人形态。

Result: 仅使用合成数据预训练的模型在49个仿真任务、5个现实世界任务和4个长时程灵巧任务上均与使用真实数据的官方π₀模型表现相当。

Conclusion: 合成数据单独使用即可达到与最强真实数据集相当的预训练效果，大规模仿真具有重要价值，将开源数据集和生成流水线以降低具身AI研究的数据创建门槛。

Abstract: Recent works explore how real and synthetic data contribute to Vision-Language-Action (VLA) models' generalization. While current VLA models have shown the strong effectiveness of large-scale real-robot pre-training, synthetic data has not previously demonstrated comparable capability at scale. This paper provides the first evidence that synthetic data alone can match the performance of the strongest $π$-dataset in pre-training a VLA model, revealing the substantial value of large-scale simulation. The resulting model also exhibits surprisingly zero-shot sim-to-real transfer on several challenging tasks. Our synthetic dataset, InternData-A1, contains over 630k trajectories and 7,433 hours across 4 embodiments, 18 skills, 70 tasks, and 227 scenes, covering rigid, articulated, deformable, and fluid-object manipulation. It is generated through a highly autonomous, fully decoupled, and compositional simulation pipeline that enables long-horizon skill composition, flexible task assembly, and heterogeneous embodiments with minimal manual tuning. Using the same architecture as $π_0$, we pre-train a model entirely on InternData-A1 and find that it matches the official $π_0$ across 49 simulation tasks, 5 real-world tasks, and 4 long-horizon dexterous tasks. We release the dataset and will open-source the generation pipeline to broaden access to large-scale robotic data and to lower the barrier to scalable data creation for embodied AI research.

</details>


### [22] [Dexterity from Smart Lenses: Multi-Fingered Robot Manipulation with In-the-Wild Human Demonstrations](https://arxiv.org/abs/2511.16661)
*Irmak Guzey,Haozhi Qi,Julen Urain,Changhao Wang,Jessica Yin,Krishna Bodduluri,Mike Lambeta,Lerrel Pinto,Akshara Rai,Jitendra Malik,Tingfan Wu,Akash Sharma,Homanga Bharadhwaj*

Main category: cs.RO

TL;DR: 提出AINA框架，使用Aria Gen 2眼镜从人类日常任务视频中学习多指机器人策略，无需机器人数据即可直接部署


<details>
  <summary>Details</summary>
Motivation: 解决人类与机器人之间的体现差距，从自然环境中的人类视频学习通用机器人操作策略，减少对劳动密集型机器人数据收集的依赖

Method: 使用轻便的Aria Gen 2眼镜收集人类数据，该设备提供高分辨率RGB相机、精确的3D头部和手部姿态、立体视觉深度估计，学习基于3D点的多指手策略

Result: 在九个日常操作任务上验证了框架有效性，策略对背景变化具有鲁棒性，可直接部署而无需机器人数据、在线修正、强化学习或仿真

Conclusion: AINA框架使从任何人、任何地点、任何环境中收集的人类数据学习多指机器人策略成为可能，向实现通用机器人操作迈出了重要一步

Abstract: Learning multi-fingered robot policies from humans performing daily tasks in natural environments has long been a grand goal in the robotics community. Achieving this would mark significant progress toward generalizable robot manipulation in human environments, as it would reduce the reliance on labor-intensive robot data collection. Despite substantial efforts, progress toward this goal has been bottle-necked by the embodiment gap between humans and robots, as well as by difficulties in extracting relevant contextual and motion cues that enable learning of autonomous policies from in-the-wild human videos. We claim that with simple yet sufficiently powerful hardware for obtaining human data and our proposed framework AINA, we are now one significant step closer to achieving this dream. AINA enables learning multi-fingered policies from data collected by anyone, anywhere, and in any environment using Aria Gen 2 glasses. These glasses are lightweight and portable, feature a high-resolution RGB camera, provide accurate on-board 3D head and hand poses, and offer a wide stereo view that can be leveraged for depth estimation of the scene. This setup enables the learning of 3D point-based policies for multi-fingered hands that are robust to background changes and can be deployed directly without requiring any robot data (including online corrections, reinforcement learning, or simulation). We compare our framework against prior human-to-robot policy learning approaches, ablate our design choices, and demonstrate results across nine everyday manipulation tasks. Robot rollouts are best viewed on our website: https://aina-robot.github.io.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [23] [Heterogeneity in peer effects for binary outcomes](https://arxiv.org/abs/2511.15891)
*Mathieu Lambotte*

Main category: econ.EM

TL;DR: 该论文将异质性引入同伴效应分析，允许从众偏好的强度在不同行为间变化，提出了识别异质同伴效应参数的条件和规范检验方法，并在青少年吸烟饮酒行为研究中验证了假设同质从众偏好会导致估计偏差。


<details>
  <summary>Details</summary>
Motivation: 传统同伴效应分析通常假设从众偏好在不同行为间是同质的，这可能与现实不符。作者旨在研究异质性从众偏好对同伴效应估计的影响。

Method: 使用基于不完全信息同时网络博弈的结构模型，推导均衡唯一性和异质同伴效应参数识别的条件，提出规范检验方法区分从众模型和溢出模型。

Result: 在青少年吸烟和饮酒行为数据应用中，发现假设同质从众偏好会导致估计偏差，验证了异质性模型的重要性。

Conclusion: 考虑异质性从众偏好对于准确估计同伴效应至关重要，传统同质假设会带来偏差，提出的模型和方法能够更准确地捕捉现实中的同伴影响机制。

Abstract: I introduce heterogeneity into the analysis of peer effects that arise from conformity, allowing the strength of the taste for conformity to vary across agents' actions. Using a structural model based on a simultaneous network game with incomplete information, I derive conditions for equilibrium uniqueness and for the identification of heterogeneous peer-effect parameters. I also propose specification tests to determine whether the conformity model or the spillover model is consistent with the observed data in the presence of heterogeneous peer effects. Applying the model to data on smoking and alcohol consumption among secondary school students, I show that assuming a homogeneous preference for conformity leads to biased estimates.

</details>


### [24] [Confidence Sets for the Emergence, Collapse, and Recovery Dates of a Bubble](https://arxiv.org/abs/2511.16172)
*Eiji Kurozumi,Anton Skrobotov*

Main category: econ.EM

TL;DR: 通过反转断点位置检验来构建泡沫出现、崩溃和恢复日期的置信集，结合似然比检验和Elliott-Muller检验，在控制覆盖率和置信集长度方面表现良好。


<details>
  <summary>Details</summary>
Motivation: 需要为泡沫经济事件（出现、崩溃、恢复）的日期构建可靠的置信集，以提供统计上的不确定性度量。

Method: 通过反转断点位置检验的方法构建置信集，使用似然比检验和Elliott-Muller检验两种方法，推导了零假设下的极限分布，并建立了备择假设下的渐近一致性。

Result: 蒙特卡洛模拟显示，结合不同类型检验能有效控制经验覆盖率，同时保持置信集长度合理较小。

Conclusion: 提出的方法能够为泡沫事件日期构建有效的置信集，在覆盖率和精度之间取得良好平衡。

Abstract: We propose constructing confidence sets for the emergence, collapse, and recovery dates of a bubble by inverting tests for the location of the break date. We examine both likelihood ratio-type tests and the Elliott-Muller-type (2007) tests for detecting break locations. The limiting distributions of these tests are derived under the null hypothesis, and their asymptotic consistency under the alternative is established. Finite-sample properties are evaluated through Monte Carlo simulations. The results indicate that combining different types of tests effectively controls the empirical coverage rate while maintaining a reasonably small length of the confidence set.

</details>


### [25] [Quantile Selection in the Gender Pay Gap](https://arxiv.org/abs/2511.16187)
*Egshiglen Batbayar,Christoph Breunig,Peter Haan,Boryana Ilieva*

Main category: econ.EM

TL;DR: 提出一种使用工具变量估计性别工资差距选择校正分位数的新方法，该方法不需要对选择概率施加参数限制，并应用于德国行政数据分析全职收入的性别差距分布。


<details>
  <summary>Details</summary>
Motivation: 传统方法在估计性别工资差距时可能忽略选择偏差问题，特别是在劳动力供给的Roy模型中，需要校正选择效应以获得准确的工资差距分位数估计。

Method: 使用工具变量方法，这些变量解释潜在变量的变化但在给定潜在过程条件下不直接影响选择；基于约束选择概率加权的半参数识别和估计方法。

Result: 在德国数据中发现：低端女性（特别是教育程度较低者）存在明显的正向选择，扩大了该段的性别差距；高端高教育男性存在强烈的正向选择，缩小了上分位数的性别工资差距。

Conclusion: 该方法成功识别了性别工资差距分布中的选择效应，揭示了不同群体选择行为的异质性对工资差距的影响，为理解劳动力市场性别不平等提供了更精确的分析工具。

Abstract: We propose a new approach to estimate selection-corrected quantiles of the gender wage gap. Our method employs instrumental variables that explain variation in the latent variable but, conditional on the latent process, do not directly affect selection. We provide semiparametric identification of the quantile parameters without imposing parametric restrictions on the selection probability, derive the asymptotic distribution of the proposed estimator based on constrained selection probability weighting, and demonstrate how the approach applies to the Roy model of labor supply. Using German administrative data, we analyze the distribution of the gender gap in full-time earnings. We find pronounced positive selection among women at the lower end, especially those with less education, which widens the gender gap in this segment, and strong positive selection among highly educated men at the top, which narrows the gender wage gap at upper quantiles.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [26] [Abortion Bans and Young Women's Labor Supply: Evidence from the Dobbs Decision](https://arxiv.org/abs/2511.16120)
*Rintaro Ando*

Main category: econ.GN

TL;DR: 2022年Dobbs裁决后，州级堕胎禁令导致18-24岁年轻女性劳动力参与率显著上升3.6-6.6个百分点，而年轻男性参与率下降，表明这不是由劳动力需求驱动的变化。


<details>
  <summary>Details</summary>
Motivation: 研究Dobbs裁决和州级堕胎禁令对年轻女性劳动力供给的影响，探讨生殖权利限制如何改变女性的劳动市场行为。

Method: 使用2021年1月至2023年12月的月度CPS微观数据，采用双重差分(DiD)和三重差分(DDD)模型，利用各州堕胎政策的跨州差异进行分析。

Result: 堕胎禁令州的年轻女性劳动力参与率上升3.6-6.6个百分点，就业率上升约3个百分点，学校注册率无显著变化，年轻男性参与率下降2.9个百分点。

Conclusion: 堕胎禁令与年轻女性劳动市场参与度的立即增加相关，可能使她们短期内更关注当前收入而非人力资本积累。

Abstract: This paper studies the impact of the 2022 Dobbs decision and subsequent state level abortion bans on the labor supply of young women (ages 18-24). Using monthly CPS micro data from January 2021 to December 2023, I exploit cross state variation in post Dobbs abortion policy and estimate Difference-in-Differences (DiD) and Triple-Difference (DDD) models. In a simple DiD comparing young women in ban versus protected states, labor force participation in ban states rises by 3.6 percentage points, while participation among young men in the same states falls by 2.9 percentage points, suggesting that the female response is unlikely to be driven by stronger local labor demand. The preferred DDD specification with state-by-month and gender interacted fixed effects implies a 6.6 percentage point increase in labor force participation for young women in ban states relative to young men. School enrollment does not change significantly, whereas employment increases by about 3 percentage points. These results suggest that abortion bans are associated with an immediate increase in young women's labor market attachment, potentially shifting their short run focus toward current earnings rather than human capital accumulation.

</details>


### [27] [Cognitive Biases and the Evolutionary Origins of Zero-Sum Norms](https://arxiv.org/abs/2511.16453)
*Isaak Mengesha,Meiqi Sun,Debraj Roy*

Main category: econ.GN

TL;DR: 本文开发了一个结合有限理性和认知偏差的演化博弈框架，解释为何零和思维等低效规范会持续存在。研究发现理性程度和风险规避对福利的影响是非单调的，中等理性程度有利于协调，而过度理性或强损失厌恶会导致低收益均衡锁定。


<details>
  <summary>Details</summary>
Motivation: 解释为什么即使会破坏合作和投资，零和解释等适应不良的认知和规范仍然持续存在，探究有限理性和认知偏差如何影响规范协调的演化动态。

Method: 扩展演化博弈理论，结合量化反应均衡和前景理论效用函数，分析主观收益评估如何系统性地改变群体层面的均衡选择。

Result: 研究发现理性程度和风险规避对福利的影响是非单调的：中等精度增强协调，而过度精度或强损失厌恶导致低收益和零和均衡的持续锁定。这些动态产生内生的公平-效率权衡。

Conclusion: 扭曲的收益感知可以将社会锚定在不同的制度轨迹中，为持续的零和规范和不平等提供了行为演化解释。

Abstract: Why do maladaptive perceptions and norms, such as zero-sum interpretations of interaction, persist even when they undermine cooperation and investment? We develop a framework where bounded rationality and heterogeneous cognitive biases shape the evolutionary dynamics of norm coordination. Extending evolutionary game theory with quantal response equilibria and prospect-theoretic utility, we show that subjective evaluation of payoffs systematically alters population-level equilibrium selection, generating stable but inefficient attractors. Counterintuitively, our analysis demonstrates that the benefit of rationality and the cost of risk aversion on welfare behave in nonmonotone ways: intermediate precision enhances coordination, while excessive precision or strong loss aversion leads to persistent lock-in at low-payoff and zero-sum equilibria. These dynamics produce an endogenous equity-efficiency trade-off: parameter configurations that raise aggregate welfare also increase inequality, while more equal distributions are associated with lower efficiency. The results highlight how distorted payoff perceptions can anchor societies in divergent institutional trajectories, offering a behavioral-evolutionary explanation for persistent zero-sum norms and inequality.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [28] [Majority Rules: LLM Ensemble is a Winning Approach for Content Categorization](https://arxiv.org/abs/2511.15714)
*Ariel Kamen,Yakov Kamen*

Main category: cs.AI

TL;DR: 提出了一个集成大语言模型(eLLM)框架，通过整合多个LLM来解决单个模型在文本分类中的不一致性、幻觉、类别膨胀和误分类问题，在IAB分层分类法上实现了高达65%的F1分数提升。


<details>
  <summary>Details</summary>
Motivation: 单个大语言模型在文本分类中存在不一致性、幻觉、类别膨胀和误分类等常见弱点，需要开发更稳健的分类解决方案。

Method: 采用集成学习框架，整合十个最先进的LLM，在零样本条件下对8,660个人工标注样本进行评估，通过集体决策的数学模型建立原则性聚合标准。

Result: eLLM框架相比最强单个模型实现了高达65%的F1分数提升，达到接近人类专家水平的性能，同时提高了鲁棒性和准确性。

Conclusion: eLLM提供了一个可扩展且可靠的基于分类法的分类解决方案，可能显著减少对人类专家标注的依赖。

Abstract: This study introduces an ensemble framework for unstructured text categorization using large language models (LLMs). By integrating multiple models, the ensemble large language model (eLLM) framework addresses common weaknesses of individual systems, including inconsistency, hallucination, category inflation, and misclassification. The eLLM approach yields a substantial performance improvement of up to 65\% in F1-score over the strongest single model. We formalize the ensemble process through a mathematical model of collective decision-making and establish principled aggregation criteria. Using the Interactive Advertising Bureau (IAB) hierarchical taxonomy, we evaluate ten state-of-the-art LLMs under identical zero-shot conditions on a human-annotated corpus of 8{,}660 samples. Results show that individual models plateau in performance due to the compression of semantically rich text into sparse categorical representations, while eLLM improves both robustness and accuracy. With a diverse consortium of models, eLLM achieves near human-expert-level performance, offering a scalable and reliable solution for taxonomy-based classification that may significantly reduce dependence on human expert labeling.

</details>


### [29] [Graph-Memoized Reasoning: Foundations Structured Workflow Reuse in Intelligent Systems](https://arxiv.org/abs/2511.15715)
*Yash Raj Singh*

Main category: cs.AI

TL;DR: 提出了图记忆推理框架，通过将推理工作流表示为图结构记忆，实现跨任务的计算步骤复用，减少重复计算，提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型推理系统经常在不同任务中重复计算相似的推理步骤，浪费计算资源、增加推理延迟并限制可复现性，需要持久化推理机制来回忆和重用先前的计算轨迹。

Method: 引入图记忆推理框架，将推理工作流表示为图结构记忆，通过结构和语义相似性检索过去的决策图，实现子图的组合式复用。

Result: 制定了最小化总推理成本并正则化存储与生成工作流不一致性的优化目标，为智能系统中的效率-一致性权衡提供理论基础。

Conclusion: 该框架为可解释、成本高效和自我改进的推理架构奠定了基础，向大规模智能系统中的持久化记忆迈出了一步。

Abstract: Modern large language model-based reasoning systems frequently recompute similar reasoning steps across tasks, wasting computational resources, inflating inference latency, and limiting reproducibility. These inefficiencies underscore the need for persistent reasoning mechanisms that can recall and reuse prior computational traces.
  We introduce Graph-Memoized Reasoning, a formal framework for representing, storing, and reusing reasoning workflows as graph-structured memory. By encoding past decision graphs and retrieving them through structural and semantic similarity, our approach enables compositional reuse of subgraphs across new reasoning tasks.
  We formulate an optimization objective that minimizes total reasoning cost regularized by inconsistency between stored and generated workflows, providing a theoretical foundation for efficiency-consistency trade-offs in intelligent systems. We outline a conceptual evaluation protocol aligned with the proposed optimization objective.
  This framework establishes the groundwork for interpretable, cost-efficient, and self-improving reasoning architectures, offering a step toward persistent memory in large-scale agentic systems.

</details>


### [30] [MACIE: Multi-Agent Causal Intelligence Explainer for Collective Behavior Understanding](https://arxiv.org/abs/2511.15716)
*Abraham Itzhak Weinberg*

Main category: cs.AI

TL;DR: MACIE是一个多智能体因果智能解释框架，结合结构因果模型、干预反事实和Shapley值，为多智能体强化学习系统提供全面解释，解决个体因果贡献、系统涌现智能和可操作解释三个关键问题。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体强化学习系统在安全关键应用中的使用，理解智能体决策原因和集体行为形成机制变得至关重要。现有的可解释AI方法在多智能体环境中表现不佳，无法将集体结果归因于个体、量化涌现行为或捕捉复杂交互。

Method: MACIE框架结合结构因果模型、干预反事实和Shapley值，通过干预归因分数评估个体因果贡献，使用协同指标分离集体效应与个体贡献来量化系统级涌现智能，并通过自然语言叙述合成因果洞察提供可操作解释。

Result: 在四个MARL场景（合作、竞争和混合动机）中的评估显示：准确的结果归因（平均φ_i=5.07，标准差<0.05），在合作任务中检测到正向涌现（协同指数高达0.461），以及高效计算（CPU上每个数据集0.79秒）。

Conclusion: MACIE独特地结合了因果严谨性、涌现量化和多智能体支持，同时保持实际实时使用可行性，这代表了向可解释、可信赖和负责任的多智能体AI迈出的一步。

Abstract: As Multi Agent Reinforcement Learning systems are used in safety critical applications. Understanding why agents make decisions and how they achieve collective behavior is crucial. Existing explainable AI methods struggle in multi agent settings. They fail to attribute collective outcomes to individuals, quantify emergent behaviors, or capture complex interactions. We present MACIE Multi Agent Causal Intelligence Explainer, a framework combining structural causal models, interventional counterfactuals, and Shapley values to provide comprehensive explanations. MACIE addresses three questions. First, each agent's causal contribution using interventional attribution scores. Second, system level emergent intelligence through synergy metrics separating collective effects from individual contributions. Third, actionable explanations using natural language narratives synthesizing causal insights. We evaluate MACIE across four MARL scenarios: cooperative, competitive, and mixed motive. Results show accurate outcome attribution, mean phi_i equals 5.07, standard deviation less than 0.05, detection of positive emergence in cooperative tasks, synergy index up to 0.461, and efficient computation, 0.79 seconds per dataset on CPU. MACIE uniquely combines causal rigor, emergence quantification, and multi agent support while remaining practical for real time use. This represents a step toward interpretable, trustworthy, and accountable multi agent AI.

</details>


### [31] [How Modality Shapes Perception and Reasoning: A Study of Error Propagation in ARC-AGI](https://arxiv.org/abs/2511.15717)
*Bo Wen,Chen Wang,Erhan Bilal*

Main category: cs.AI

TL;DR: 本文研究了不同模态（文本和图像）对ARC-AGI任务中模型感知能力的影响，发现结构化文本能精确捕捉稀疏特征坐标，图像能保持2D形状但受分辨率限制，结合两者可提升执行准确性约8个感知点和0.20中位数相似度。


<details>
  <summary>Details</summary>
Motivation: ARC-AGI竞赛通过组合泛化来衡量系统性能，但缺乏对编码方式如何影响模型感知以及如何区分指令错误与执行错误的系统分析。作者假设不同模态会带来感知瓶颈，从而影响网格特征的可靠感知。

Method: 使用加权集合分歧度量和两阶段推理流程，在九种文本和图像模态中分离感知与推理，比较不同表示方式对模型感知的影响。

Result: 结构化文本在稀疏特征坐标上表现精确，图像能保持2D形状但对分辨率敏感，结合文本和图像表示可改善执行效果（约8个感知点提升，约0.20中位数相似度提升）。

Conclusion: 将表示与transformer的归纳偏置对齐，并实现文本和图像之间的交叉验证，可以在不改变底层模型的情况下获得更准确的指令和更可靠的执行。

Abstract: ARC-AGI and ARC-AGI-2 measure generalization-through-composition on small color-quantized grids, and their prize competitions make progress on these harder held-out tasks a meaningful proxy for systematic generalization. Recent instruction-first systems translate grids into concise natural-language or DSL rules executed in generate-execute-select loops, yet we lack a principled account of how encodings shape model perception and how to separate instruction errors from execution errors. We hypothesize that modality imposes perceptual bottlenecks -- text flattens 2D structure into 1D tokens while images preserve layout but can introduce patch-size aliasing -- thereby shaping which grid features are reliably perceived. To test this, we isolate perception from reasoning across nine text and image modalities using a weighted set-disagreement metric and a two-stage reasoning pipeline, finding that structured text yields precise coordinates on sparse features, images capture 2D shapes yet are resolution-sensitive, and combining them improves execution (about 8 perception points; about 0.20 median similarity). Overall, aligning representations with transformer inductive biases and enabling cross-validation between text and image yields more accurate instructions and more reliable execution without changing the underlying model.

</details>


### [32] [ToolMind Technical Report: A Large-Scale, Reasoning-Enhanced Tool-Use Dataset](https://arxiv.org/abs/2511.15718)
*Chen Yang,Ran Le,Yun Xing,Zhenwei An,Zongchao Chen,Wayne Xin Zhao,Yang Song,Tao Zhang*

Main category: cs.AI

TL;DR: ToolMind是一个大规模高质量的LLM智能体数据集，包含16万合成数据和20万增强数据，通过多智能体框架生成，并进行细粒度的轮次级验证来确保数据质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要在轨迹级别验证正确性，可能忽略轮次级错误，这些错误在训练中会传播并降低模型性能。高质量轨迹的稀缺阻碍了更强LLM智能体的发展。

Method: 构建基于参数相关性的函数图，使用多智能体框架模拟用户-助手-工具交互，并进行细粒度的轮次级过滤来移除错误或次优步骤。

Result: 在ToolMind上微调的模型在多个基准测试中相比基线有显著提升。

Conclusion: ToolMind通过轮次级验证和过滤方法缓解了训练中的错误放大问题，同时保留了自我纠正推理信号，为稳健的工具使用学习提供了高质量数据。

Abstract: Large Language Model (LLM) agents have developed rapidly in recent years to solve complex real-world problems using external tools. However, the scarcity of high-quality trajectories still hinders the development of stronger LLM agents. Most existing works on multi-turn dialogue synthesis validate correctness only at the trajectory level, which may overlook turn-level errors that can propagate during training and degrade model performance. To address these limitations, we introduce ToolMind, a large-scale, high-quality tool-agentic dataset with 160k synthetic data instances generated using over 20k tools and 200k augmented open-source data instances. Our data synthesis pipeline first constructs a function graph based on parameter correlations and then uses a multi-agent framework to simulate realistic user-assistant-tool interactions. Beyond trajectory-level validation, we employ fine-grained turn-level filtering to remove erroneous or suboptimal steps, ensuring that only high-quality reasoning traces are retained. This approach mitigates error amplification during training while preserving self-corrective reasoning signals essential for robust tool-use learning. Models fine-tuned on ToolMind show significant improvements over baselines on several benchmarks.

</details>


### [33] [Artificial Intelligence and Accounting Research: A Framework and Agenda](https://arxiv.org/abs/2511.16055)
*Theophanis C. Stratopoulos,Victor Xiaoqi Wang*

Main category: cs.AI

TL;DR: 本文提出了一个AI与会计研究的二维分类框架，分析了GenAI和LLMs如何改变会计研究，揭示了人类研究者与AI在研究流程中的能力对比，并提出了博士教育改革建议。


<details>
  <summary>Details</summary>
Motivation: AI特别是生成式AI和大语言模型的快速发展正在从根本上改变会计研究，为学者们同时创造了机会和竞争威胁，需要系统分析这种转变的影响。

Method: 提出了一个二维分类框架：研究焦点（会计中心vsAI中心）和方法论（AI方法vs传统方法），并应用该框架分析IJAIS特刊和主要会计期刊的AI-会计研究论文。

Result: 分析显示GenAI虽然使某些研究能力民主化，但通过提高对高阶贡献的期望加剧了竞争，在人类判断、创造力和理论深度方面人类仍保持价值。

Conclusion: 这些转变要求改革博士教育，在培养比较优势的同时建立AI素养，以应对AI带来的研究范式变革。

Abstract: Recent advances in artificial intelligence, particularly generative AI (GenAI) and large language models (LLMs), are fundamentally transforming accounting research, creating both opportunities and competitive threats for scholars. This paper proposes a framework that classifies AI-accounting research along two dimensions: research focus (accounting-centric versus AI-centric) and methodological approach (AI-based versus traditional methods). We apply this framework to papers from the IJAIS special issue and recent AI-accounting research published in leading accounting journals to map existing studies and identify research opportunities. Using this same framework, we analyze how accounting researchers can leverage their expertise through strategic positioning and collaboration, revealing where accounting scholars' strengths create the most value. We further examine how GenAI and LLMs transform the research process itself, comparing the capabilities of human researchers and AI agents across the entire research workflow. This analysis reveals that while GenAI democratizes certain research capabilities, it simultaneously intensifies competition by raising expectations for higher-order contributions where human judgment, creativity, and theoretical depth remain valuable. These shifts call for reforming doctoral education to cultivate comparative advantages while building AI fluency.

</details>


### [34] [Chain of Summaries: Summarization Through Iterative Questioning](https://arxiv.org/abs/2511.15719)
*William Brach,Lukas Galke Poech*

Main category: cs.AI

TL;DR: 提出Chain of Summaries (CoS)方法，通过类似黑格尔辩证法的方式迭代优化摘要，生成信息密集的通用摘要，使网页内容更易于LLM消化。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在处理外部网页内容时面临的格式不友好和上下文长度限制问题，使网页内容更易于LLM访问和使用。

Method: 基于黑格尔辩证法思想，通过初始摘要（正题）、质疑识别局限性（反题）、生成通用摘要（合题）的迭代过程，生成信息密集的通用摘要。

Result: 在TriviaQA、TruthfulQA和SQUAD数据集上，CoS比零样本LLM基线性能提升高达66%，比专门摘要方法如BRIO和PEGASUS提升高达27%。生成的摘要用更少token获得更高Q&A性能。

Conclusion: CoS为网站维护者提供了一种使内容更易于LLM访问的吸引人选项，同时保留了人工监督的可能性。

Abstract: Large Language Models (LLMs) are increasingly using external web content. However, much of this content is not easily digestible by LLMs due to LLM-unfriendly formats and limitations of context length. To address this issue, we propose a method for generating general-purpose, information-dense summaries that act as plain-text repositories of web content. Inspired by Hegel's dialectical method, our approach, denoted as Chain of Summaries (CoS), iteratively refines an initial summary (thesis) by identifying its limitations through questioning (antithesis), leading to a general-purpose summary (synthesis) that can satisfy current and anticipate future information needs. Experiments on the TriviaQA, TruthfulQA, and SQUAD datasets demonstrate that CoS outperforms zero-shot LLM baselines by up to 66% and specialized summarization methods such as BRIO and PEGASUS by up to 27%. CoS-generated summaries yield higher Q&A performance compared to the source content, while requiring substantially fewer tokens and being agnostic to the specific downstream LLM. CoS thus resembles an appealing option for website maintainers to make their content more accessible for LLMs, while retaining possibilities for human oversight.

</details>


### [35] [Automated Hazard Detection in Construction Sites Using Large Language and Vision-Language Models](https://arxiv.org/abs/2511.15720)
*Islem Sahraoui*

Main category: cs.AI

TL;DR: 提出了一种多模态AI框架，结合文本和图像分析来识别建筑工地安全隐患，通过两个案例研究评估了LLM和VLM在自动危险识别中的能力。


<details>
  <summary>Details</summary>
Motivation: 建筑工地等安全关键环境中，事故数据通常以多种格式存在（如书面报告、检查记录和现场图像），传统方法难以综合识别危险源。

Method: 第一个案例研究使用GPT 4o和GPT 4o mini从28,000份OSHA事故报告中提取结构化见解；第二个案例研究使用Molmo 7B和Qwen2 VL 2B轻量级开源VLM，在ConstructionSite10k数据集上进行规则级安全违规检测。

Result: 尽管模型规模较小，但Molmo 7B和Qwen2 VL 2B在某些提示配置下表现出竞争力，证实了低资源多模态系统用于规则感知安全监控的可行性。

Conclusion: 多模态AI框架能够有效结合文本和视觉数据来增强建筑安全，轻量级开源模型在安全监控任务中具有实用价值。

Abstract: This thesis explores a multimodal AI framework for enhancing construction safety through the combined analysis of textual and visual data. In safety-critical environments such as construction sites, accident data often exists in multiple formats, such as written reports, inspection records, and site imagery, making it challenging to synthesize hazards using traditional approaches. To address this, this thesis proposed a multimodal AI framework that combines text and image analysis to assist in identifying safety hazards on construction sites. Two case studies were consucted to evaluate the capabilities of large language models (LLMs) and vision-language models (VLMs) for automated hazard identification.The first case study introduces a hybrid pipeline that utilizes GPT 4o and GPT 4o mini to extract structured insights from a dataset of 28,000 OSHA accident reports (2000-2025). The second case study extends this investigation using Molmo 7B and Qwen2 VL 2B, lightweight, open-source VLMs. Using the public ConstructionSite10k dataset, the performance of the two models was evaluated on rule-level safety violation detection using natural language prompts. This experiment served as a cost-aware benchmark against proprietary models and allowed testing at scale with ground-truth labels. Despite their smaller size, Molmo 7B and Quen2 VL 2B showed competitive performance in certain prompt configurations, reinforcing the feasibility of low-resource multimodal systems for rule-aware safety monitoring.

</details>


### [36] [Spatial Reasoning in Multimodal Large Language Models: A Survey of Tasks, Benchmarks and Methods](https://arxiv.org/abs/2511.15722)
*Weichen Liu,Qiyao Xue,Haoming Wang,Xiangyu Yin,Boyuan Yang,Wei Gao*

Main category: cs.AI

TL;DR: 本文从认知角度提出了空间智能的分类法，按推理复杂度组织任务，将现有基准映射到该分类法中，分析了评估方法和改进空间能力的方法。


<details>
  <summary>Details</summary>
Motivation: 空间推理是人类智能的基本方面，但对多模态大语言模型仍是挑战。现有调查多基于输入模态分类，但空间能力不仅由输入格式决定，需要从认知角度进行更原则性的分析。

Method: 引入基于认知视角的分类法，按推理复杂度划分任务并关联认知功能；将文本、视觉语言和具身设置中的现有基准映射到该分类法；分析评估指标和方法；比较训练型和推理型改进方法。

Result: 建立了更原则性的跨任务比较框架，揭示了当前模型能力与类人推理之间的关键差距；阐明了不同改进方法的各自优势和互补机制。

Conclusion: 通过从认知角度分析任务、基准和最新进展，为研究人员提供了对该领域的全面理解和未来研究的可行方向。

Abstract: Spatial reasoning, which requires ability to perceive and manipulate spatial relationships in the 3D world, is a fundamental aspect of human intelligence, yet remains a persistent challenge for Multimodal large language models (MLLMs). While existing surveys often categorize recent progress based on input modality (e.g., text, image, video, or 3D), we argue that spatial ability is not solely determined by the input format. Instead, our survey introduces a taxonomy that organizes spatial intelligence from cognitive aspect and divides tasks in terms of reasoning complexity, linking them to several cognitive functions. We map existing benchmarks across text only, vision language, and embodied settings onto this taxonomy, and review evaluation metrics and methodologies for assessing spatial reasoning ability. This cognitive perspective enables more principled cross-task comparisons and reveals critical gaps between current model capabilities and human-like reasoning. In addition, we analyze methods for improving spatial ability, spanning both training-based and reasoning-based approaches. This dual perspective analysis clarifies their respective strengths, uncovers complementary mechanisms. By surveying tasks, benchmarks, and recent advances, we aim to provide new researchers with a comprehensive understanding of the field and actionable directions for future research.

</details>


### [37] [Uncertainty-Resilient Multimodal Learning via Consistency-Guided Cross-Modal Transfer](https://arxiv.org/abs/2511.15741)
*Hyo-Jeong Jang*

Main category: cs.AI

TL;DR: 该论文提出了一种基于一致性引导的跨模态迁移框架，通过将异构模态投影到共享潜在空间来增强多模态学习的鲁棒性，特别是在面对噪声数据、低质量标签和模态差异时。


<details>
  <summary>Details</summary>
Motivation: 解决多模态学习中的不确定性挑战，包括噪声数据、低质量标签和异构模态特性，特别是在人机交互环境中数据质量和标注一致性差异较大的问题。

Method: 采用一致性引导的跨模态迁移方法，通过跨模态语义一致性进行鲁棒表示学习，将异构模态投影到共享潜在空间以减少模态差距并发现支持不确定性估计的结构关系。

Result: 在多模态情感识别基准测试中，该方法显著提高了模型稳定性、判别能力和对噪声或不完整监督的鲁棒性。潜在空间分析表明即使在挑战性条件下也能捕获可靠的跨模态结构。

Conclusion: 该论文通过整合不确定性建模、语义对齐和数据高效监督，为开发可靠和自适应的脑机接口系统提供了统一的多模态学习框架和实践见解。

Abstract: Multimodal learning systems often face substantial uncertainty due to noisy data, low-quality labels, and heterogeneous modality characteristics. These issues become especially critical in human-computer interaction settings, where data quality, semantic reliability, and annotation consistency vary across users and recording conditions. This thesis tackles these challenges by exploring uncertainty-resilient multimodal learning through consistency-guided cross-modal transfer. The central idea is to use cross-modal semantic consistency as a basis for robust representation learning. By projecting heterogeneous modalities into a shared latent space, the proposed framework mitigates modality gaps and uncovers structural relations that support uncertainty estimation and stable feature learning. Building on this foundation, the thesis investigates strategies to enhance semantic robustness, improve data efficiency, and reduce the impact of noise and imperfect supervision without relying on large, high-quality annotations. Experiments on multimodal affect-recognition benchmarks demonstrate that consistency-guided cross-modal transfer significantly improves model stability, discriminative ability, and robustness to noisy or incomplete supervision. Latent space analyses further show that the framework captures reliable cross-modal structure even under challenging conditions. Overall, this thesis offers a unified perspective on resilient multimodal learning by integrating uncertainty modeling, semantic alignment, and data-efficient supervision, providing practical insights for developing reliable and adaptive brain-computer interface systems.

</details>


### [38] [Build AI Assistants using Large Language Models and Agents to Enhance the Engineering Education of Biomechanics](https://arxiv.org/abs/2511.15752)
*Hanzhi Yan,Qin Lu,Xianqiao Wang,Xiaoming Zhai,Tianming Liu,He Li*

Main category: cs.AI

TL;DR: 本研究提出了一个双模块框架，结合检索增强生成(RAG)和多智能体系统(MAS)来提升大语言模型在生物力学教育任务中的表现，解决LLMs在专业领域知识不足和多步推理能力有限的问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然在通用任务上表现出色，但在专业领域应用中存在知识鸿沟，且在需要多步推理的复杂问题上性能下降。本研究旨在开发教育助手来提升本科生物力学课程的学习效果。

Method: 构建双模块框架：1) 使用RAG提升LLMs在概念性判断题中的专业性和逻辑一致性；2) 使用MAS解决需要多步推理和代码执行的计算问题。评估了多个LLM模型在100个生物力学问题上的表现。

Result: RAG显著提升了LLMs在概念性问题上的性能和稳定性，超越了原始模型。MAS能够有效进行多步推理、方程推导、代码执行，并为计算任务生成可解释的解决方案。

Conclusion: RAG和MAS的结合应用展示了提升LLMs在工程专业课程中性能的潜力，为开发工程教育智能辅导系统提供了有前景的方向。

Abstract: While large language models (LLMs) have demonstrated remarkable versatility across a wide range of general tasks, their effectiveness often diminishes in domain-specific applications due to inherent knowledge gaps. Moreover, their performance typically declines when addressing complex problems that require multi-step reasoning and analysis. In response to these challenges, we propose leveraging both LLMs and AI agents to develop education assistants aimed at enhancing undergraduate learning in biomechanics courses that focus on analyzing the force and moment in the musculoskeletal system of the human body. To achieve our goal, we construct a dual-module framework to enhance LLM performance in biomechanics educational tasks: 1) we apply Retrieval-Augmented Generation (RAG) to improve the specificity and logical consistency of LLM's responses to the conceptual true/false questions; 2) we build a Multi-Agent System (MAS) to solve calculation-oriented problems involving multi-step reasoning and code execution. Specifically, we evaluate the performance of several LLMs, i.e., Qwen-1.0-32B, Qwen-2.5-32B, and Llama-70B, on a biomechanics dataset comprising 100 true/false conceptual questions and problems requiring equation derivation and calculation. Our results demonstrate that RAG significantly enhances the performance and stability of LLMs in answering conceptual questions, surpassing those of vanilla models. On the other hand, the MAS constructed using multiple LLMs demonstrates its ability to perform multi-step reasoning, derive equations, execute code, and generate explainable solutions for tasks that require calculation. These findings demonstrate the potential of applying RAG and MAS to enhance LLM performance for specialized courses in engineering curricula, providing a promising direction for developing intelligent tutoring in engineering education.

</details>


### [39] [Multi-Agent LLM Orchestration Achieves Deterministic, High-Quality Decision Support for Incident Response](https://arxiv.org/abs/2511.15755)
*Philip Drammeh*

Main category: cs.AI

TL;DR: 多智能体编排相比单智能体方法在事故响应中实现了100%可操作建议率，将行动特异性提高80倍，解决方案正确性提高140倍，且质量零方差。


<details>
  <summary>Details</summary>
Motivation: 单智能体LLM方法生成模糊、不可用的建议，无法满足生产系统事故响应的需求。

Method: 开发MyAntFarm.ai框架，通过348次对照试验比较单智能体副驾驶与多智能体系统在相同事故场景下的表现。

Result: 多智能体系统实现100%可操作建议率（单智能体仅1.7%），行动特异性提高80倍，解决方案正确性提高140倍，质量零方差。

Conclusion: 多智能体编排不是性能优化，而是基于LLM的事故响应生产就绪的必要条件。

Abstract: Large language models (LLMs) promise to accelerate incident response in production systems, yet single-agent approaches generate vague, unusable recommendations. We present MyAntFarm.ai, a reproducible containerized framework demonstrating that multi-agent orchestration fundamentally transforms LLM-based incident response quality. Through 348 controlled trials comparing single-agent copilot versus multi-agent systems on identical incident scenarios, we find that multi-agent orchestration achieves 100% actionable recommendation rate versus 1.7% for single-agent approaches, an 80 times improvement in action specificity and 140 times improvement in solution correctness. Critically, multi-agent systems exhibit zero quality variance across all trials, enabling production SLA commitments impossible with inconsistent single-agent outputs. Both architectures achieve similar comprehension latency (approx.40s), establishing that the architectural value lies in deterministic quality, not speed. We introduce Decision Quality (DQ), a novel metric capturing validity, specificity, and correctness properties essential for operational deployment that existing LLM metrics do not address. These findings reframe multi-agent orchestration from a performance optimization to a production-readiness requirement for LLM-based incident response. All code, Docker configurations, and trial data are publicly available for reproduction.

</details>


### [40] [Identifying the Supply Chain of AI for Trustworthiness and Risk Management in Critical Applications](https://arxiv.org/abs/2511.15763)
*Raymond K. Sheh,Karen Geappen*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Risks associated with the use of AI, ranging from algorithmic bias to model hallucinations, have received much attention and extensive research across the AI community, from researchers to end-users. However, a gap exists in the systematic assessment of supply chain risks associated with the complex web of data sources, pre-trained models, agents, services, and other systems that contribute to the output of modern AI systems. This gap is particularly problematic when AI systems are used in critical applications, such as the food supply, healthcare, utilities, law, insurance, and transport.
  We survey the current state of AI risk assessment and management, with a focus on the supply chain of AI and risks relating to the behavior and outputs of the AI system. We then present a proposed taxonomy specifically for categorizing AI supply chain entities. This taxonomy helps stakeholders, especially those without extensive AI expertise, to "consider the right questions" and systematically inventory dependencies across their organization's AI systems. Our contribution bridges a gap between the current state of AI governance and the urgent need for actionable risk assessment and management of AI use in critical applications.

</details>


### [41] [Balancing Natural Language Processing Accuracy and Normalisation in Extracting Medical Insights](https://arxiv.org/abs/2511.15778)
*Paulina Tworek,Miłosz Bargieł,Yousef Khan,Tomasz Pełech-Pilichowski,Marek Mikołajczyk,Roman Lewandowski,Jose Sousa*

Main category: cs.AI

TL;DR: 比较基于规则的方法和大型语言模型在波兰临床文本信息提取中的表现，发现规则方法在年龄和性别提取上更准确，而LLM在药物识别方面表现更好，建议采用混合方法


<details>
  <summary>Details</summary>
Motivation: 在非英语医疗环境中，从非结构化临床文本中提取结构化信息仍然是一个挑战，特别是在资源匮乏的情况下

Method: 使用波兰儿童康复医院的电子健康记录，比较基于规则的低计算量方法和大型语言模型在提取患者人口统计信息、临床发现和处方药物方面的表现，并评估文本标准化缺失和翻译导致的信息损失影响

Result: 规则方法在信息检索任务中提供更高的准确性（特别是年龄和性别提取），而LLM具有更好的适应性和可扩展性，在药物名称识别方面表现优异

Conclusion: 建议采用混合方法，结合规则系统的精确性和LLM的适应性，为现实世界医院提供更可靠和资源高效的临床NLP解决方案

Abstract: Extracting structured medical insights from unstructured clinical text using Natural Language Processing (NLP) remains an open challenge in healthcare, particularly in non-English contexts where resources are scarce. This study presents a comparative analysis of NLP low-compute rule-based methods and Large Language Models (LLMs) for information extraction from electronic health records (EHR) obtained from the Voivodeship Rehabilitation Hospital for Children in Ameryka, Poland. We evaluate both approaches by extracting patient demographics, clinical findings, and prescribed medications while examining the effects of lack of text normalisation and translation-induced information loss. Results demonstrate that rule-based methods provide higher accuracy in information retrieval tasks, particularly for age and sex extraction. However, LLMs offer greater adaptability and scalability, excelling in drug name recognition. The effectiveness of the LLMs was compared with texts originally in Polish and those translated into English, assessing the impact of translation. These findings highlight the trade-offs between accuracy, normalisation, and computational cost when deploying NLP in healthcare settings. We argue for hybrid approaches that combine the precision of rule-based systems with the adaptability of LLMs, offering a practical path toward more reliable and resource-efficient clinical NLP in real-world hospitals.

</details>


### [42] [IMACT-CXR - An Interactive Multi-Agent Conversational Tutoring System for Chest X-Ray Interpretation](https://arxiv.org/abs/2511.15825)
*Tuan-Anh Le,Anh Mai Vu,David Yang,Akash Awasthi,Hien Van Nguyen*

Main category: cs.AI

TL;DR: IMACT-CXR是一个基于多智能体对话的胸部X光解读教学系统，整合了空间标注、视线分析、知识检索和图像推理功能，通过AutoGen工作流为学员提供实时辅导。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够统一处理学员的空间标注、视线数据和文本观察的交互式教学系统，帮助放射科培训生提高胸部X光解读能力，解决传统教学中缺乏实时反馈和个性化指导的问题。

Method: 使用AutoGen框架构建多智能体系统，包含评估定位质量、生成苏格拉底式辅导、检索PubMed证据、推荐相似病例等专门智能体。采用贝叶斯知识追踪维护技能掌握度估计，结合肺叶分割模块进行解剖学感知的视线反馈。

Result: 系统实现了有界延迟的响应式教学流程，精确控制答案泄露，并展示了与REFLACX数据集的集成能力。初步评估显示在定位和诊断推理方面相比基线方法有所改进。

Conclusion: IMACT-CXR证明了多智能体对话系统在医学影像教学中的可行性，具备向实际住院医师培训部署的可扩展性，为实时个性化医学教育提供了有效解决方案。

Abstract: IMACT-CXR is an interactive multi-agent conversational tutor that helps trainees interpret chest X-rays by unifying spatial annotation, gaze analysis, knowledge retrieval, and image-grounded reasoning in a single AutoGen-based workflow. The tutor simultaneously ingests learner bounding boxes, gaze samples, and free-text observations. Specialized agents evaluate localization quality, generate Socratic coaching, retrieve PubMed evidence, suggest similar cases from REFLACX, and trigger NV-Reason-CXR-3B for vision-language reasoning when mastery remains low or the learner explicitly asks. Bayesian Knowledge Tracing (BKT) maintains skill-specific mastery estimates that drive both knowledge reinforcement and case similarity retrieval. A lung-lobe segmentation module derived from a TensorFlow U-Net enables anatomically aware gaze feedback, and safety prompts prevent premature disclosure of ground-truth labels. We describe the system architecture, implementation highlights, and integration with the REFLACX dataset for real DICOM cases. IMACT-CXR demonstrates responsive tutoring flows with bounded latency, precise control over answer leakage, and extensibility toward live residency deployment. Preliminary evaluation shows improved localization and diagnostic reasoning compared to baselines.

</details>


### [43] [CorrectHDL: Agentic HDL Design with LLMs Leveraging High-Level Synthesis as Reference](https://arxiv.org/abs/2511.16395)
*Kangwei Xu,Grace Li Zhang,Ulf Schlichtmann,Bing Li*

Main category: cs.AI

TL;DR: 提出CorrectHDL框架，利用HLS结果作为功能参考来修正LLM生成的HDL设计中的错误，在保持功能正确性的同时提升面积和功耗效率。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在硬件前端设计中因幻觉倾向导致HDL设计出现功能错误的问题。

Method: 使用C/C++程序作为输入，通过LLM生成HDL设计，用RAG机制修复语法错误，并通过与HLS参考设计的仿真行为比较来迭代改进功能正确性。

Result: 实验结果显示，生成的电路在面积和功耗效率上显著优于传统HLS设计，接近人工设计质量，同时保持HDL实现的正确性。

Conclusion: CorrectHDL框架有效结合了LLM的生成能力和传统正确性驱动的IC设计流程的严谨性，展示了代理式HDL设计的潜力和有效性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable potential in hardware front-end design using hardware description languages (HDLs). However, their inherent tendency toward hallucination often introduces functional errors into the generated HDL designs. To address this issue, we propose the framework CorrectHDL that leverages high-level synthesis (HLS) results as functional references to correct potential errors in LLM-generated HDL designs.The input to the proposed framework is a C/C++ program that specifies the target circuit's functionality. The program is provided to an LLM to directly generate an HDL design, whose syntax errors are repaired using a Retrieval-Augmented Generation (RAG) mechanism. The functional correctness of the LLM-generated circuit is iteratively improved by comparing its simulated behavior with an HLS reference design produced by conventional HLS tools, which ensures the functional correctness of the result but can lead to suboptimal area and power efficiency. Experimental results demonstrate that circuits generated by the proposed framework achieve significantly better area and power efficiency than conventional HLS designs and approach the quality of human-engineered circuits. Meanwhile, the correctness of the resulting HDL implementation is maintained, highlighting the effectiveness and potential of agentic HDL design leveraging the generative capabilities of LLMs and the rigor of traditional correctness-driven IC design flows.

</details>


### [44] [Mini Amusement Parks (MAPs): A Testbed for Modelling Business Decisions](https://arxiv.org/abs/2511.15830)
*Stéphane Aroca-Ouellette,Ian Berlot-Attwell,Panagiotis Lymperopoulos,Abhiramon Rajasekharan,Tongqi Zhu,Herin Kang,Kaheer Suleman,Sam Pasupalak*

Main category: cs.AI

TL;DR: Mini Amusement Parks (MAPs) 是一个游乐园模拟器，用于评估智能体在复杂业务环境中的决策能力，发现人类表现远超现有LLM智能体。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统在现实世界决策中面临挑战，而现有的人机基准测试只关注部分能力，无法评估整体决策能力。

Method: 开发了MAPs游乐园模拟器，统一了环境建模、长期规划、空间推理等挑战，并提供人类基线和最先进LLM智能体的全面评估。

Result: 人类在简单模式下表现优于AI系统6.5倍，中等模式下优于9.8倍，揭示了AI在长期优化、样本效率学习等方面的持续弱点。

Conclusion: MAPs为评估具有适应性决策能力的智能体提供了新的基准基础，统一了现实世界决策中的多个挑战。

Abstract: Despite rapid progress in artificial intelligence, current systems struggle with the interconnected challenges that define real-world decision making. Practical domains, such as business management, require optimizing an open-ended and multi-faceted objective, actively learning environment dynamics from sparse experience, planning over long horizons in stochastic settings, and reasoning over spatial information. Yet existing human--AI benchmarks isolate subsets of these capabilities, limiting our ability to assess holistic decision-making competence. We introduce Mini Amusement Parks (MAPs), an amusement-park simulator designed to evaluate an agent's ability to model its environment, anticipate long-term consequences under uncertainty, and strategically operate a complex business. We provide human baselines and a comprehensive evaluation of state-of-the-art LLM agents, finding that humans outperform these systems by 6.5x on easy mode and 9.8x on medium mode. Our analysis reveals persistent weaknesses in long-horizon optimization, sample-efficient learning, spatial reasoning, and world modelling. By unifying these challenges within a single environment, MAPs offers a new foundation for benchmarking agents capable of adaptable decision making. Code: https://github.com/Skyfall-Research/MAPs

</details>


### [45] [Step-Audio-R1 Technical Report](https://arxiv.org/abs/2511.15848)
*Fei Tian,Xiangyu Tony Zhang,Yuxin Zhang,Haoyang Zhang,Yuxin Li,Daijiao Liu,Yayue Deng,Donghang Wu,Jun Chen,Liang Zhao,Chengyuan Yao,Hexin Liu,Eng Siong Chng,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.AI

TL;DR: Step-Audio-R1是首个成功解锁音频推理能力的模型，通过模态锚定推理蒸馏框架，在音频理解基准测试中超越Gemini 2.5 Pro，性能接近Gemini 3 Pro。


<details>
  <summary>Details</summary>
Motivation: 解决音频语言模型中存在的困惑现象：推理越少性能越好，探索音频智能是否能从深思熟虑中真正受益。

Method: 提出模态锚定推理蒸馏框架，让模型学习生成与音频特征真正相关的推理链，而非产生脱节的幻觉推理。

Result: 模型展现出强大的音频推理能力，在涵盖语音、环境声音和音乐的全面音频理解和推理基准测试中表现优异。

Conclusion: 推理是跨模态可转移的能力，当适当锚定时，扩展的深思熟虑可以从负担转变为音频智能的强大资产。

Abstract: Recent advances in reasoning models have demonstrated remarkable success in text and vision domains through extended chain-of-thought deliberation. However, a perplexing phenomenon persists in audio language models: they consistently perform better with minimal or no reasoning, raising a fundamental question - can audio intelligence truly benefit from deliberate thinking? We introduce Step-Audio-R1, the first audio reasoning model that successfully unlocks reasoning capabilities in the audio domain. Through our proposed Modality-Grounded Reasoning Distillation (MGRD) framework, Step-Audio-R1 learns to generate audio-relevant reasoning chains that genuinely ground themselves in acoustic features rather than hallucinating disconnected deliberations. Our model exhibits strong audio reasoning capabilities, surpassing Gemini 2.5 Pro and achieving performance comparable to the state-of-the-art Gemini 3 Pro across comprehensive audio understanding and reasoning benchmarks spanning speech, environmental sounds, and music. These results demonstrate that reasoning is a transferable capability across modalities when appropriately anchored, transforming extended deliberation from a liability into a powerful asset for audio intelligence. By establishing the first successful audio reasoning model, Step-Audio-R1 opens new pathways toward building truly multimodal reasoning systems that think deeply across all sensory modalities.

</details>


### [46] [Decomposing Theory of Mind: How Emotional Processing Mediates ToM Abilities in LLMs](https://arxiv.org/abs/2511.15895)
*Ivan Chulo,Ananya Joshi*

Main category: cs.AI

TL;DR: 通过对比激活引导与基线LLM的激活模式，发现情感处理能力（而非分析推理）是提升语言模型心理理论能力的关键机制。


<details>
  <summary>Details</summary>
Motivation: 理解激活引导如何改变语言模型内部机制以提升心理理论能力，探索情感处理与分析推理在心理理论中的相对作用。

Method: 使用对比激活加法引导Gemma-3-4B模型，在1000个BigToM前向信念场景上评估，通过线性探针分析45种认知行为的激活差异。

Result: 心理理论任务准确率从32.5%提升至46.7%，主要归因于情感感知(+2.23)和情感价值评估(+2.20)的增强，同时抑制了质疑(-0.78)和聚合思维(-1.59)等分析过程。

Conclusion: 语言模型成功执行心理理论任务主要依赖于情感理解能力，而非分析推理能力。

Abstract: Recent work shows activation steering substantially improves language models' Theory of Mind (ToM) (Bortoletto et al. 2024), yet the mechanisms of what changes occur internally that leads to different outputs remains unclear. We propose decomposing ToM in LLMs by comparing steered versus baseline LLMs' activations using linear probes trained on 45 cognitive actions. We applied Contrastive Activation Addition (CAA) steering to Gemma-3-4B and evaluated it on 1,000 BigToM forward belief scenarios (Gandhi et al. 2023), we find improved performance on belief attribution tasks (32.5\% to 46.7\% accuracy) is mediated by activations processing emotional content : emotion perception (+2.23), emotion valuing (+2.20), while suppressing analytical processes: questioning (-0.78), convergent thinking (-1.59). This suggests that successful ToM abilities in LLMs are mediated by emotional understanding, not analytical reasoning.

</details>


### [47] [Thinking, Faithful and Stable: Mitigating Hallucinations in LLMs](https://arxiv.org/abs/2511.15921)
*Chelsea Zou,Yiheng Yao,Basant Khalil*

Main category: cs.AI

TL;DR: 开发了一个用于大型语言模型的自校正框架，通过细粒度不确定性信号检测和缓解多步推理中的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 解决LLM在多步推理中产生幻觉的问题，不仅关注最终答案正确性，还要确保中间推理步骤的可靠性和忠实性

Method: 利用自我评估置信度对齐和词元级熵峰值作为不确定性信号，设计复合奖励函数，通过强化学习策略引导模型生成行为

Result: 实验表明该方法提高了最终答案准确性和推理校准度，消融实验验证了每个信号的有效性

Conclusion: 提出的自校正框架能够有效改善LLM的推理过程，使其更加内省和可靠

Abstract: This project develops a self correcting framework for large language models (LLMs) that detects and mitigates hallucinations during multi-step reasoning. Rather than relying solely on final answer correctness, our approach leverages fine grained uncertainty signals: 1) self-assessed confidence alignment, and 2) token-level entropy spikes to detect unreliable and unfaithful reasoning in real time. We design a composite reward function that penalizes unjustified high confidence and entropy spikes, while encouraging stable and accurate reasoning trajectories. These signals guide a reinforcement learning (RL) policy that makes the model more introspective and shapes the model's generation behavior through confidence-aware reward feedback, improving not just outcome correctness but the coherence and faithfulness of their intermediate reasoning steps. Experiments show that our method improves both final answer accuracy and reasoning calibration, with ablations validating the individual contribution of each signal.

</details>


### [48] [JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation](https://arxiv.org/abs/2511.15958)
*Zhenyu Bi,Gaurav Srivastava,Yang Li,Meng Lu,Swastik Roy,Morteza Ziyadi,Xuan Wang*

Main category: cs.AI

TL;DR: JudgeBoard是一个新的评估管道，直接查询模型来评估候选答案的正确性，无需额外答案比较。提出MAJ多智能体评估框架，通过多个交互的小型语言模型协作来近似大型语言模型的判断准确性。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型在判断答案正确性方面的能力相比大型语言模型尚不清楚。现有的LLM-as-a-judge框架依赖与真实标签或其他候选答案的间接比较，难以完全自动化，对推理输出的细粒度和可扩展评估支持有限。

Method: 构建JudgeBoard评估管道，在数学推理和科学/常识推理两个核心领域，使用基于准确性的排名和Elo评分系统构建任务特定的评估排行榜。提出MAJ多智能体判断框架，利用具有不同推理特征的多个交互SLM通过协作审议来近似LLM级别的判断准确性。

Result: 实验结果显示SLM和LLM在独立判断任务中存在显著性能差距。但MAJ框架显著提高了SLM的可靠性和一致性。在MATH数据集上，使用较小模型作为骨干的MAJ表现与较大模型相当甚至更好。

Conclusion: 多智能体SLM系统在判断任务中可能匹配或超过LLM性能，对可扩展和高效评估具有重要意义。

Abstract: While small language models (SLMs) have shown promise on various reasoning tasks, their ability to judge the correctness of answers remains unclear compared to large language models (LLMs). Prior work on LLM-as-a-judge frameworks typically relies on comparing candidate answers against ground-truth labels or other candidate answers using predefined metrics like entailment. However, this approach is inherently indirect and difficult to fully automate, offering limited support for fine-grained and scalable evaluation of reasoning outputs. In this work, we propose JudgeBoard, a novel evaluation pipeline that directly queries models to assess the correctness of candidate answers without requiring extra answer comparisons. We focus on two core reasoning domains: mathematical reasoning and science/commonsense reasoning, and construct task-specific evaluation leaderboards using both accuracy-based ranking and an Elo-based rating system across five benchmark datasets, enabling consistent model comparison as judges rather than comparators. To improve judgment performance in lightweight models, we propose MAJ (Multi-Agent Judging), a novel multi-agent evaluation framework that leverages multiple interacting SLMs with distinct reasoning profiles to approximate LLM-level judgment accuracy through collaborative deliberation. Experimental results reveal a significant performance gap between SLMs and LLMs in isolated judging tasks. However, our MAJ framework substantially improves the reliability and consistency of SLMs. On the MATH dataset, MAJ using smaller-sized models as backbones performs comparatively well or even better than their larger-sized counterparts. Our findings highlight that multi-agent SLM systems can potentially match or exceed LLM performance in judgment tasks, with implications for scalable and efficient assessment.

</details>


### [49] [KRAL: Knowledge and Reasoning Augmented Learning for LLM-assisted Clinical Antimicrobial Therapy](https://arxiv.org/abs/2511.15974)
*Zhe Li,Yehan Qiu,Yujie Chen,Xiang Zhou*

Main category: cs.AI

TL;DR: KRAL是一个低成本、可扩展、保护隐私的框架，通过教师模型推理自动提炼知识和推理轨迹，使用启发式学习进行半监督数据增强，并利用智能强化学习共同增强医学知识和推理能力，在临床抗菌治疗决策支持中显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在临床决策中的局限性，包括知识差距、数据隐私问题、高部署成本和有限推理能力，特别是在复杂的抗菌治疗决策支持场景中。

Method: 采用知识推理增强学习框架，包括：答案到问题的反向生成自动提炼知识、启发式学习减少80%人工标注需求、智能强化学习联合优化医学知识和推理能力、分层评估降低评估成本、模块化接口设计便于系统更新。

Result: KRAL显著优于传统RAG和SFT方法：在MEDQA基准上知识问答准确率提升1.8% vs SFT和3.6% vs RAG；在PUMCH抗菌基准上推理能力提升27% vs SFT和27.2% vs RAG；长期训练成本仅为SFT的约20%。

Conclusion: KRAL是增强本地LLM临床诊断能力的有效解决方案，能够在复杂医疗决策支持中实现低成本、高安全性的部署。

Abstract: Clinical antimicrobial therapy requires the dynamic integration of pathogen profiles, host factors, pharmacological properties of antimicrobials, and the severity of infection.This complexity imposes fundamental limitations on the applicability of Large Language Models (LLMs) in high-stakes clinical decision-making including knowledge gaps, data privacy concerns, high deployment costs, and limited reasoning capabilities. To address these challenges, we propose KRAL (Knowledge and Reasoning Augmented Learning), a low-cost, scalable, privacy-preserving paradigm that leverages teacher-model reasoning to automatically distill knowledge and reasoning trajectories via answer-to-question reverse generation, employs heuristic learning for semi-supervised data augmentation (reducing manual annotation requirements by approximately 80%), and utilizes agentic reinforcement learning to jointly enhance medical knowledge and reasoning while optimizing computational and memory efficiency. A hierarchical evaluation employing diverse teacher-model proxies reduces assessment costs, while modular interface design facilitates seamless system updates. Experimental results demonstrate that KRAL significantly outperforms traditional Retrieval-Augmented Generation (RAG) and Supervised Fine-Tuning (SFT) methods. It improves knowledge question-answering capability (Accuracy@1 on the external open-source benchmark MEDQA increased by 1.8% vs. SFT and 3.6% vs. RAG) and reasoning capability (Pass@1 on the external benchmark PUMCH Antimicrobial increased by 27% vs. SFT and 27.2% vs. RAG), achieved at ~20% of SFT's long-term training costs. This establishes KRAL as an effective solution for enhancing local LLMs' clinical diagnostic capabilities, enabling low-cost, high-safety deployment in complex medical decision support.

</details>


### [50] [Detecting Sleeper Agents in Large Language Models via Semantic Drift Analysis](https://arxiv.org/abs/2511.15992)
*Shahin Zanbaghi,Ryan Rostampour,Farhan Abid,Salim Al Jarmakani*

Main category: cs.AI

TL;DR: 提出了一种结合语义漂移分析和金丝雀基线比较的双方法检测系统，用于实时识别被植入后门的大型语言模型，在官方测试模型上达到92.5%的准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型可能被植入后门，在特定部署条件下表现出恶意行为，而现有方法无法有效检测这种'潜伏代理'现象。

Method: 使用Sentence-BERT嵌入测量语义偏离安全基线的程度，同时注入金丝雀问题监控响应一致性，形成双方法检测系统。

Result: 在官方dolphin-llama3-8B潜伏代理模型上，系统达到92.5%准确率、100%精确度（零误报）和85%召回率，实时检测（<1秒/查询）。

Conclusion: 该工作填补了AI部署中的关键安全漏洞，证明基于嵌入的检测可以有效识别欺骗性模型行为，且不影响部署效率。

Abstract: Large Language Models (LLMs) can be backdoored to exhibit malicious behavior under specific deployment conditions while appearing safe during training a phenomenon known as "sleeper agents." Recent work by Hubinger et al. demonstrated that these backdoors persist through safety training, yet no practical detection methods exist. We present a novel dual-method detection system combining semantic drift analysis with canary baseline comparison to identify backdoored LLMs in real-time. Our approach uses Sentence-BERT embeddings to measure semantic deviation from safe baselines, complemented by injected canary questions that monitor response consistency. Evaluated on the official Cadenza-Labs dolphin-llama3-8B sleeper agent model, our system achieves 92.5% accuracy with 100% precision (zero false positives) and 85% recall. The combined detection method operates in real-time (<1s per query), requires no model modification, and provides the first practical solution to LLM backdoor detection. Our work addresses a critical security gap in AI deployment and demonstrates that embedding-based detection can effectively identify deceptive model behavior without sacrificing deployment efficiency.

</details>


### [51] [CARE-RAG - Clinical Assessment and Reasoning in RAG](https://arxiv.org/abs/2511.15994)
*Deepthi Potluri,Aby Mammen Mathew,Jeffrey B DeWitt,Alexander L. Rasgon,Yide Hao,Junyuan Hong,Ying Ding*

Main category: cs.AI

TL;DR: LLMs在临床环境中即使获取了正确证据，仍可能在推理上出错。研究使用书面暴露疗法指南作为测试平台，发现即使提供权威段落，错误仍然存在。提出了评估推理准确性、一致性和忠实度的框架。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在检索与推理之间的差距问题，特别是在临床环境中，输出必须符合结构化协议。

Method: 使用书面暴露疗法指南作为测试平台，评估模型对临床医生审查问题的响应，并提出评估推理准确性、一致性和忠实度的框架。

Result: 发现即使提供权威段落，错误仍然存在。检索增强生成可以约束输出，但安全部署需要像评估检索一样严格评估推理。

Conclusion: 在临床环境中部署LLMs时，需要像重视检索一样严格评估推理能力，以确保输出的安全性和准确性。

Abstract: Access to the right evidence does not guarantee that large language models (LLMs) will reason with it correctly. This gap between retrieval and reasoning is especially concerning in clinical settings, where outputs must align with structured protocols. We study this gap using Written Exposure Therapy (WET) guidelines as a testbed. In evaluating model responses to curated clinician-vetted questions, we find that errors persist even when authoritative passages are provided. To address this, we propose an evaluation framework that measures accuracy, consistency, and fidelity of reasoning. Our results highlight both the potential and the risks: retrieval-augmented generation (RAG) can constrain outputs, but safe deployment requires assessing reasoning as rigorously as retrieval.

</details>


### [52] [Sensorium Arc: AI Agent System for Oceanic Data Exploration and Interactive Eco-Art](https://arxiv.org/abs/2511.15997)
*Noah Bissell,Ethan Paley,Joshua Harrison,Juliano Calil,Myungin Lee*

Main category: cs.AI

TL;DR: Sensorium Arc是一个实时多模态交互AI代理系统，将海洋拟人化为诗意讲述者，通过自然语音对话引导用户沉浸式探索复杂海洋数据。


<details>
  <summary>Details</summary>
Motivation: 将海洋数据重新想象为活生生的叙事，而非抽象数据集，通过对话式AI代理为高维环境数据提供情感化、直观的访问方式。

Method: 基于模块化多代理系统和检索增强大型语言模型框架，通过关键词检测和语义解析动态触发数据可视化和视听播放。

Result: 开发了一个能够以海洋视角生成融合科学洞察与生态诗意的回应的AI系统，实现了人机生态系统的新范式。

Conclusion: 展示了对话式AI代理在调解高维环境数据的情感化、直观访问方面的潜力，提出了人机生态系统的新范式。

Abstract: Sensorium Arc (AI reflects on climate) is a real-time multimodal interactive AI agent system that personifies the ocean as a poetic speaker and guides users through immersive explorations of complex marine data. Built on a modular multi-agent system and retrieval-augmented large language model (LLM) framework, Sensorium enables natural spoken conversations with AI agents that embodies the ocean's perspective, generating responses that blend scientific insight with ecological poetics. Through keyword detection and semantic parsing, the system dynamically triggers data visualizations and audiovisual playback based on time, location, and thematic cues drawn from the dialogue. Developed in collaboration with the Center for the Study of the Force Majeure and inspired by the eco-aesthetic philosophy of Newton Harrison, Sensorium Arc reimagines ocean data not as an abstract dataset but as a living narrative. The project demonstrates the potential of conversational AI agents to mediate affective, intuitive access to high-dimensional environmental data and proposes a new paradigm for human-machine-ecosystem.

</details>


### [53] [MUSEKG: A Knowledge Graph Over Museum Collections](https://arxiv.org/abs/2511.16014)
*Jinhao Li,Jianzhong Qi,Soyeon Caren Han,Eun-Jung Holden*

Main category: cs.AI

TL;DR: MuseKG是一个端到端的知识图谱框架，通过符号-神经集成统一博物馆的结构化和非结构化数据，支持自然语言查询，在真实博物馆数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 文化遗产领域的数字化转型产生了大量但碎片化的文物数据，现有博物馆信息系统难以整合异构元数据、非结构化文档和多模态文物数据。

Method: 构建类型化属性图，连接对象、人物、组织和视觉或文本标签，通过符号-神经集成方法统一结构化与非结构化博物馆数据。

Result: 在真实博物馆数据集上的评估显示，MuseKG在属性、关系和关联实体查询方面表现稳健，超越了大型语言模型的零样本、少样本和SPARQL提示基线。

Conclusion: 结果强调了符号基础对于可解释和可扩展的文化遗产推理的重要性，为数字遗产知识在网络规模上的整合铺平了道路。

Abstract: Digital transformation in the cultural heritage sector has produced vast yet fragmented collections of artefact data. Existing frameworks for museum information systems struggle to integrate heterogeneous metadata, unstructured documents, and multimodal artefacts into a coherent and queryable form. We present MuseKG, an end-to-end knowledge-graph framework that unifies structured and unstructured museum data through symbolic-neural integration. MuseKG constructs a typed property graph linking objects, people, organisations, and visual or textual labels, and supports natural language queries. Evaluations on real museum collections demonstrate robust performance across queries over attributes, relations, and related entities, surpassing large-language-model zero-shot, few-shot and SPARQL prompt baselines. The results highlight the importance of symbolic grounding for interpretable and scalable cultural heritage reasoning, and pave the way for web-scale integration of digital heritage knowledge.

</details>


### [54] [SpellForger: Prompting Custom Spell Properties In-Game using BERT supervised-trained model](https://arxiv.org/abs/2511.16018)
*Emanuel C. Silva,Emily S. M. Salum,Gabriel M. Arantes,Matheus P. Pereira,Vinicius F. Oliveira,Alessandro L. Bicho*

Main category: cs.AI

TL;DR: SpellForger是一款让玩家通过自然语言提示创建自定义法术的游戏，使用BERT模型解释玩家输入并生成平衡的法术参数，验证AI作为直接游戏机制的应用。


<details>
  <summary>Details</summary>
Motivation: 探索AI作为核心游戏玩法共创工具的应用，目前这方面研究不足。旨在通过自然语言创建法术来提供个性化和创造性的独特游戏体验。

Method: 使用监督训练的BERT模型解释玩家自然语言提示，将文本描述映射到法术预制体并平衡参数（伤害、成本、效果）。游戏在Unity引擎中开发，AI后端使用Python。

Result: 预计将交付一个功能原型，展示实时法术生成，应用于引人入胜的游戏循环，其中玩家创造力是体验的核心。

Conclusion: 该研究验证了AI作为直接游戏机制的应用可行性，通过自然语言交互实现了玩家驱动的游戏内容共创。

Abstract: Introduction: The application of Artificial Intelligence in games has evolved significantly, allowing for dynamic content generation. However, its use as a core gameplay co-creation tool remains underexplored. Objective: This paper proposes SpellForger, a game where players create custom spells by writing natural language prompts, aiming to provide a unique experience of personalization and creativity. Methodology: The system uses a supervisedtrained BERT model to interpret player prompts. This model maps textual descriptions to one of many spell prefabs and balances their parameters (damage, cost, effects) to ensure competitive integrity. The game is developed in the Unity Game Engine, and the AI backend is in Python. Expected Results: We expect to deliver a functional prototype that demonstrates the generation of spells in real time, applied to an engaging gameplay loop, where player creativity is central to the experience, validating the use of AI as a direct gameplay mechanic.

</details>


### [55] [An Aligned Constraint Programming Model For Serial Batch Scheduling With Minimum Batch Size](https://arxiv.org/abs/2511.16045)
*Jorge A. Huertas,Pascal Van Hentenryck*

Main category: cs.AI

TL;DR: 提出了一种新的约束规划模型，用于序列批处理调度问题，该模型不依赖预定义的虚拟批次集合，而是直接对机器上同族作业序列进行推理，实现了更紧凑的公式化表达。


<details>
  <summary>Details</summary>
Motivation: 现有的约束规划模型依赖预定义的虚拟批次集合，这会导致维度灾难并增加问题复杂性。在半导体制造等实际应用中，最小批次大小是常见要求，需要更有效的解决方案。

Method: 使用关键对齐参数直接对机器上同族作业序列进行推理，避免了虚拟批次集合。通过定制搜索阶段和增强约束传播器的推理级别来利用问题结构。

Result: 在近5000个实例上的计算实验表明，新模型在小到中等规模实例（最多100个作业）上表现优越，在大型实例（最多500个作业、10个族、10台机器）上能找到比现有方法好25%的解决方案。

Conclusion: 提出的新约束规划模型在序列批处理调度问题上显著优于现有方法，特别是在处理最小批次大小约束时表现出色，为实际工业应用提供了更有效的解决方案。

Abstract: In serial batch (s-batch) scheduling, jobs from similar families are grouped into batches and processed sequentially to avoid repetitive setups that are required when processing consecutive jobs of different families. Despite its large success in scheduling, only three Constraint Programming (CP) models have been proposed for this problem considering minimum batch sizes, which is a common requirement in many practical settings, including the ion implantation area in semiconductor manufacturing. These existing CP models rely on a predefined virtual set of possible batches that suffers from the curse of dimensionality and adds complexity to the problem. This paper proposes a novel CP model that does not rely on this virtual set. Instead, it uses key alignment parameters that allow it to reason directly on the sequences of same-family jobs scheduled on the machines, resulting in a more compact formulation. This new model is further improved by exploiting the problem's structure with tailored search phases and strengthened inference levels of the constraint propagators. The extensive computational experiments on nearly five thousand instances compare the proposed models against existing methods in the literature, including mixed-integer programming formulations, tabu search meta-heuristics, and CP approaches. The results demonstrate the superiority of the proposed models on small-to-medium instances with up to 100 jobs, and their ability to find solutions up to 25\% better than the ones produces by existing methods on large-scale instances with up to 500 jobs, 10 families, and 10 machines.

</details>


### [56] [A Hybrid Proactive And Predictive Framework For Edge Cloud Resource Management](https://arxiv.org/abs/2511.16075)
*Hrikshesh Kumar,Anika Garg,Anshul Gupta,Yashika Agarwal*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Old cloud edge workload resource management is too reactive. The problem with relying on static thresholds is that we are either overspending for more resources than needed or have reduced performance because of their lack. This is why we work on proactive solutions. A framework developed for it stops reacting to the problems but starts expecting them. We design a hybrid architecture, combining two powerful tools: the CNN LSTM model for time series forecasting and an orchestrator based on multi agent Deep Reinforcement Learning In fact the novelty is in how we combine them as we embed the predictive forecast from the CNN LSTM directly into the DRL agent state space. That is what makes the AI manager smarter it sees the future, which allows it to make better decisions about a long term plan for where to run tasks That means finding that sweet spot between how much money is saved while keeping the system healthy and apps fast for users That is we have given it eyes in order to see down the road so that it does not have to lurch from one problem to another it finds a smooth path forward Our tests show our system easily beats the old methods It is great at solving tough problems like making complex decisions and juggling multiple goals at once like being cheap fast and reliable

</details>


### [57] [SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent](https://arxiv.org/abs/2511.16108)
*Shiyi Cao,Dacheng Li,Fangzhou Zhao,Shuo Yuan,Sumanth R. Hegde,Connor Chen,Charlie Ruan,Tyler Griggs,Shu Liu,Eric Tang,Richard Liaw,Philipp Moritz,Matei Zaharia,Joseph E. Gonzalez,Ion Stoica*

Main category: cs.AI

TL;DR: SkyRL-Agent是一个用于高效多轮长视野智能体训练和评估的框架，通过异步调度和工具集成优化，训练出SA-SWE-32B软件工程智能体，在SWE-Bench上达到39.4% Pass@1，成本降低2倍以上。


<details>
  <summary>Details</summary>
Motivation: 解决现有智能体训练框架在效率、多轮交互和长视野任务方面的不足，提供更高效的训练和评估解决方案。

Method: 采用优化的异步管道调度器（1.55倍加速）和基于AST的搜索工具增强训练方法，结合强化学习训练软件工程智能体。

Result: SA-SWE-32B在SWE-Bench Verified上达到39.4% Pass@1，相比之前模型成本降低2倍以上，并在其他智能体任务上表现出良好的泛化能力。

Conclusion: SkyRL-Agent框架通过高效异步调度和工具集成，显著提升了智能体训练效率和性能，具有良好的扩展性和泛化能力。

Abstract: We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation. It provides efficient asynchronous dispatching, lightweight tool integration, and flexible backend interoperability, enabling seamless use with existing RL frameworks such as SkyRL-train, VeRL, and Tinker.
  Using SkyRL-Agent, we train SA-SWE-32B, a software engineering agent trained from Qwen3-32B (24.4% Pass@1) purely with reinforcement learning. We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and improve training efficiency. Together, these optimizations enable SA-SWE-32B to reach 39.4% Pass@1 on SWE-Bench Verified with more than 2x cost reduction compared to prior models reaching similar performance. Despite being trained solely on SWE tasks, SA-SWE-32B generalizes effectively to other agentic tasks, including Terminal-Bench, BrowseComp-Plus, and WebArena. We further demonstrate SkyRL-Agent's extensibility through case studies on deep research, computer use, and memory agents, each trained using a different training backend.

</details>


### [58] [Multidimensional Rubric-oriented Reward Model Learning via Geometric Projection Reference Constraints](https://arxiv.org/abs/2511.16139)
*Yongnan Jin,Xurui Li,Feng Cao,Liucun Gao,Juanjuan Yao*

Main category: cs.AI

TL;DR: 提出了MR-RML框架，通过GPRC技术解决LLMs在医疗领域应用的三个关键对齐挑战：静态评估与动态临床需求的脱节、适应多源医疗标准的困难、传统奖励模型无法捕捉多维医疗质量标准。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗实践中有巨大潜力，但存在三个关键对齐挑战限制了其实际临床效用：静态评估基准与动态临床认知需求脱节、难以适应不断发展的多源医疗标准、传统奖励模型无法捕捉多维医疗质量标准。

Method: 提出MR-RML框架，包含三个核心创新：1）"维度-场景-学科"医疗标准系统；2）独立多维奖励模型；3）几何投影参考约束，将医疗认知逻辑转化为数学正则化。

Result: 在权威医疗基准Healthbench上，相比基础模型Qwen-32B，在完整子集上提升45%，在困难子集上提升85%。在开源LLMs中达到SOTA水平（完整子集62.7分，困难子集44.7分），并超越大多数闭源模型。

Conclusion: MR-RML框架通过结构化医疗标准集成和多维奖励建模，有效解决了LLMs在医疗领域的对齐挑战，显著提升了模型性能和在真实临床环境中的实用性。

Abstract: The integration of large language models (LLMs) into medical practice holds transformative potential, yet their real-world clinical utility remains limited by critical alignment challenges: (1) a disconnect between static evaluation benchmarks and dynamic clinical cognitive needs, (2) difficulties in adapting to evolving, multi-source medical standards, and (3) the inability of conventional reward models to capture nuanced, multi-dimensional medical quality criteria. To address these gaps, we propose MR-RML (Multidimensional Rubric-oriented Reward Model Learning) via GPRC (Geometric Projection Reference Constraints), a novel alignment framework that integrates medical standards into a structured "Dimensions-Scenarios-Disciplines" matrix to guide data generation and model optimization. MR-RML introduces three core innovations: (1) a "Dimensions-Scenarios-Disciplines" medical standard system that embeds domain standards into the full training pipeline; (2) an independent multi-dimensional reward model that decomposes evaluation criteria, shifting from real-time rubric-based scoring to internalized reward modeling for improved consistency and cost-efficiency; (3) geometric projection reference constraints that transform medical cognitive logic into mathematical regularization, aligning scoring gradients with clinical reasoning and enabling synthetic data-driven training. Through extensive evaluations on the authoritative medical benchmark Healthbench, our method yields substantial performance gains over the base LLM Qwen-32B (45% on the full subset and 85% on Hard subset, respectively). It achieves a SOTA among open-source LLMs with scores of 62.7 (full subset) and 44.7 (hard subset), while also outperforming the majority of closed-source models.

</details>


### [59] [FOOTPASS: A Multi-Modal Multi-Agent Tactical Context Dataset for Play-by-Play Action Spotting in Soccer Broadcast Videos](https://arxiv.org/abs/2511.16183)
*Jeremie Ochin,Raphael Chekroun,Bogdan Stanciulescu,Sotiris Manitsaris*

Main category: cs.AI

TL;DR: 提出了FOOTPASS数据集，这是首个在足球比赛中进行多模态、多智能体战术背景下的逐场动作识别基准，旨在通过结合计算机视觉输出和足球战术知识来生成可靠的逐场数据流。


<details>
  <summary>Details</summary>
Motivation: 当前足球视频理解方法在构建可靠的逐场数据方面仍不足够，通常只能辅助而非完全自动化标注。同时战术建模、轨迹预测等研究需要基于比赛状态和逐场数据，因此需要利用战术知识作为先验来支持基于计算机视觉的预测。

Method: 引入FOOTPASS数据集，支持开发球员中心动作识别方法，这些方法既利用计算机视觉任务输出（如跟踪、识别），也利用足球战术知识（包括长期战术规律）。

Result: 创建了首个覆盖整场足球比赛的多模态、多智能体战术背景下逐场动作识别基准数据集。

Conclusion: FOOTPASS数据集能够生成可靠的逐场数据流，这些数据流是数据驱动体育分析的重要输入，有助于实现更自动化和可靠的逐场数据提取。

Abstract: Soccer video understanding has motivated the creation of datasets for tasks such as temporal action localization, spatiotemporal action detection (STAD), or multiobject tracking (MOT). The annotation of structured sequences of events (who does what, when, and where) used for soccer analytics requires a holistic approach that integrates both STAD and MOT. However, current action recognition methods remain insufficient for constructing reliable play-by-play data and are typically used to assist rather than fully automate annotation. Parallel research has advanced tactical modeling, trajectory forecasting, and performance analysis, all grounded in game-state and play-by-play data. This motivates leveraging tactical knowledge as a prior to support computer-vision-based predictions, enabling more automated and reliable extraction of play-by-play data. We introduce Footovision Play-by-Play Action Spotting in Soccer Dataset (FOOTPASS), the first benchmark for play-by-play action spotting over entire soccer matches in a multi-modal, multi-agent tactical context. It enables the development of methods for player-centric action spotting that exploit both outputs from computer-vision tasks (e.g., tracking, identification) and prior knowledge of soccer, including its tactical regularities over long time horizons, to generate reliable play-by-play data streams. These streams form an essential input for data-driven sports analytics.

</details>


### [60] [From Performance to Understanding: A Vision for Explainable Automated Algorithm Design](https://arxiv.org/abs/2511.16201)
*Niki van Stein,Anna V. Kononova,Thomas Bäck*

Main category: cs.AI

TL;DR: 本文提出可解释的自动化算法设计愿景，通过结合LLM驱动的算法发现、可解释基准测试和问题类别描述符，实现从盲目搜索到可解释、类别特定算法设计的转变。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的自动化算法设计主要关注性能而缺乏可解释性，无法揭示算法为何有效、哪些组件重要或设计选择与问题结构的关系。

Method: 构建基于三个支柱的闭环知识循环：LLM驱动的算法变体发现、可解释基准测试（将性能归因于组件和超参数）、问题类别描述符（连接算法行为与景观结构）。

Result: 该方法将推动领域从盲目搜索转向可解释、类别特定的算法设计，同时产生关于优化策略何时及为何成功的可重用科学见解。

Conclusion: 自动化算法设计的下一个突破不是来自更多自动化，而是将自动化与系统基准测试的理解相结合，形成发现、解释和泛化相互加强的闭环知识循环。

Abstract: Automated algorithm design is entering a new phase: Large Language Models can now generate full optimisation (meta)heuristics, explore vast design spaces and adapt through iterative feedback. Yet this rapid progress is largely performance-driven and opaque. Current LLM-based approaches rarely reveal why a generated algorithm works, which components matter or how design choices relate to underlying problem structures. This paper argues that the next breakthrough will come not from more automation, but from coupling automation with understanding from systematic benchmarking. We outline a vision for explainable automated algorithm design, built on three pillars: (i) LLM-driven discovery of algorithmic variants, (ii) explainable benchmarking that attributes performance to components and hyperparameters and (iii) problem-class descriptors that connect algorithm behaviour to landscape structure. Together, these elements form a closed knowledge loop in which discovery, explanation and generalisation reinforce each other. We argue that this integration will shift the field from blind search to interpretable, class-specific algorithm design, accelerating progress while producing reusable scientific insight into when and why optimisation strategies succeed.

</details>


### [61] [Multi-Agent Collaborative Reward Design for Enhancing Reasoning in Reinforcement Learning](https://arxiv.org/abs/2511.16202)
*Pei Yang,Ke Zhang,Ji Wang,Xiao Chen,Yuxin Tang,Eric Yang,Lynn Ai,Bill Shi*

Main category: cs.AI

TL;DR: CRM是一个多智能体协作奖励模型框架，用专业评估者团队替代单一黑盒奖励模型，提高RLHF的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统奖励模型难以同时优化多个可能冲突的偏好维度（如事实性、帮助性、安全性），且评分透明度有限。

Method: 将偏好评估分解为领域特定的智能体，每个产生部分信号，结合全局评估器（如排序器和嵌入相似度奖励）。中央聚合器融合这些信号，平衡逐步正确性、多智能体一致性和重复惩罚等因素。

Result: CRM和rewardBench提供了更透明的奖励建模和更稳定优化的实用模块化路径。

Conclusion: 多智能体协作奖励模型框架能够在不需额外人工标注的情况下，实现多视角奖励塑造，提高RLHF的鲁棒性和可解释性。

Abstract: We present CRM (Multi-Agent Collaborative Reward Model), a framework that replaces a single black-box reward model with a coordinated team of specialist evaluators to improve robustness and interpretability in RLHF. Conventional reward models struggle to jointly optimize multiple, sometimes conflicting, preference dimensions (e.g., factuality, helpfulness, safety) and offer limited transparency into why a score is assigned. CRM addresses these issues by decomposing preference evaluation into domain-specific agents that each produce partial signals, alongside global evaluators such as ranker-based and embedding-similarity rewards. A centralized aggregator fuses these signals at each timestep, balancing factors like step-wise correctness, multi-agent agreement, and repetition penalties, yielding a single training reward compatible with standard RL pipelines. The policy is optimized with advantage-based updates (e.g., GAE), while a value model regresses to the aggregated reward, enabling multi-perspective reward shaping without requiring additional human annotations beyond those used to train the evaluators. To support training and assessment, we introduce rewardBench, a benchmark and training suite aligned with the collaborative structure of CRM. Together, CRM and rewardBench provide a practical, modular path to more transparent reward modeling and more stable optimization.

</details>


### [62] [ChemLabs on ChemO: A Multi-Agent System for Multimodal Reasoning on IChO 2025](https://arxiv.org/abs/2511.16205)
*Xu Qiang,Shengyuan Bai,Leqing Chen,Zijing Liu,Yu Li*

Main category: cs.AI

TL;DR: ChemO是一个基于国际化学奥林匹克竞赛的新基准，通过评估等效重构和结构化视觉增强解决化学问题的自动评估挑战，结合多智能体框架ChemLabs实现了超越人类金牌水平的性能。


<details>
  <summary>Details</summary>
Motivation: 数学和物理的奥林匹克级基准已用于测试AI推理能力，但化学因其独特的多模态符号语言一直是个挑战，需要专门的基准来评估AI的化学推理能力。

Method: 提出ChemO基准，包含评估等效重构（将需要视觉输出的问题转换为可计算格式）和结构化视觉增强（分离视觉感知与化学推理能力）；开发ChemLabs多智能体框架，包含问题分解、感知、推理和审核等专门智能体。

Result: 在先进多模态模型上的实验表明，结合结构化视觉增强和多智能体系统能显著提升性能，最佳配置达到93.6/100分，超过估计的人类金牌阈值，建立了化学问题自动求解的新最先进水平。

Conclusion: ChemO基准和ChemLabs框架成功解决了化学奥林匹克级问题的自动评估挑战，为AI化学推理能力提供了有效的测试平台，并展示了多智能体协作在复杂科学问题求解中的优势。

Abstract: Olympiad-level benchmarks in mathematics and physics are crucial testbeds for advanced AI reasoning, but chemistry, with its unique multimodal symbolic language, has remained an open challenge. We introduce ChemO, a new benchmark built from the International Chemistry Olympiad (IChO) 2025. ChemO features two key innovations for automated assessment: Assessment-Equivalent Reformulation (AER), which converts problems requiring visual outputs (e.g., drawing molecules) into computationally tractable formats, and Structured Visual Enhancement (SVE), a diagnostic mechanism to disentangle a model's visual perception capabilities from its core chemical reasoning. To tackle this benchmark, we propose ChemLabs, a hierarchical multi-agent framework that mimics human expert collaboration through specialized agents for problem decomposition, perception, reasoning, and auditing. Experiments on state-of-the-art multimodal models demonstrate that combining SVE with our multi-agent system yields dramatic performance gains. Our top configuration achieves a score of 93.6 out of 100, surpassing an estimated human gold medal threshold and establishing a new state-of-the-art in automated chemical problem-solving. ChemO Dataset: https://huggingface.co/datasets/IDEA-AI4SCI/ChemO

</details>


### [63] [FlipVQA-Miner: Cross-Page Visual Question-Answer Mining from Textbooks](https://arxiv.org/abs/2511.16216)
*Zhen Hao Wong,Jingwen Deng,Hao Liang,Runming He,Chengyu Shen,Wentao Zhang*

Main category: cs.AI

TL;DR: 提出自动化管道从教育文档中提取高质量问答对，结合布局感知OCR和LLM语义解析，为LLM训练提供真实教育内容替代合成数据


<details>
  <summary>Details</summary>
Motivation: 现有指令调优和RL数据集成本高昂且依赖合成样本导致幻觉和多样性有限，而教材中的高质量问答内容由于PDF转换困难未被充分利用

Method: 结合布局感知OCR和基于LLM的语义解析，从教育文档中自动提取格式良好的QA和视觉QA对

Result: 实验表明该方法能产生准确、对齐且低噪声的QA/VQA对

Conclusion: 该方法能规模化利用真实世界教育内容，为改进推理导向的LLM训练提供实用替代方案

Abstract: The development of Large Language Models (LLMs) increasingly depends on high-quality supervised data, yet existing instruction-tuning and RL datasets remain costly to curate and often rely on synthetic samples that introduce hallucination and limited diversity. At the same time, textbooks and exercise materials contain abundant, high-quality human-authored Question-Answer(QA) content that remains underexploited due to the difficulty of transforming raw PDFs into AI-ready supervision. Although modern OCR and vision-language models can accurately parse document structure, their outputs lack the semantic alignment required for training. We propose an automated pipeline that extracts well-formed QA and visual-QA (VQA) pairs from educational documents by combining layout-aware OCR with LLM-based semantic parsing. Experiments across diverse document types show that the method produces accurate, aligned, and low-noise QA/VQA pairs. This approach enables scalable use of real-world educational content and provides a practical alternative to synthetic data generation for improving reasoning-oriented LLM training. All code and data-processing pipelines are open-sourced at https://github.com/OpenDCAI/DataFlow.

</details>


### [64] [Revisiting Fairness-aware Interactive Recommendation: Item Lifecycle as a Control Knob](https://arxiv.org/abs/2511.16248)
*Yun Lu,Xiaoyu Shi,Hong Xie,Chongjun Xia,Zhenhui Gong,Mingsheng Shang*

Main category: cs.AI

TL;DR: 该论文通过引入项目生命周期作为新的控制变量，重新审视了公平感知的交互式推荐系统。提出了LHRL框架，利用生命周期阶段特定的曝光动态来动态平衡公平性和准确性，在多个真实数据集上显著提升了公平性和用户参与度。


<details>
  <summary>Details</summary>
Motivation: 重新审视公平感知交互推荐系统，发现短视频平台中项目生命周期呈现压缩的三阶段模式（快速增长、短暂稳定、急剧衰减），与传统四阶段模型显著不同，这为公平性优化提供了新的视角。

Method: 提出LHRL框架：1) PhaseFormer - 结合STL分解和注意力机制的轻量级编码器用于鲁棒阶段检测；2) 两级HRL代理 - 高层策略施加阶段感知的公平约束，低层策略优化即时用户参与度，实现长期公平与短期效用的解耦优化。

Result: 在多个真实世界交互推荐数据集上的实验表明，LHRL显著改善了公平性和用户参与度。将生命周期感知奖励集成到现有基于RL的模型中也能持续获得性能提升。

Conclusion: 项目生命周期是优化公平感知推荐系统的有效控制变量，LHRL框架通过动态协调公平性和准确性，证明了生命周期感知方法在推荐系统中的通用性和实用价值。

Abstract: This paper revisits fairness-aware interactive recommendation (e.g., TikTok, KuaiShou) by introducing a novel control knob, i.e., the lifecycle of items. We make threefold contributions. First, we conduct a comprehensive empirical analysis and uncover that item lifecycles in short-video platforms follow a compressed three-phase pattern, i.e., rapid growth, transient stability, and sharp decay, which significantly deviates from the classical four-stage model (introduction, growth, maturity, decline). Second, we introduce LHRL, a lifecycle-aware hierarchical reinforcement learning framework that dynamically harmonizes fairness and accuracy by leveraging phase-specific exposure dynamics. LHRL consists of two key components: (1) PhaseFormer, a lightweight encoder combining STL decomposition and attention mechanisms for robust phase detection; (2) a two-level HRL agent, where the high-level policy imposes phase-aware fairness constraints, and the low-level policy optimizes immediate user engagement. This decoupled optimization allows for effective reconciliation between long-term equity and short-term utility. Third, experiments on multiple real-world interactive recommendation datasets demonstrate that LHRL significantly improves both fairness and user engagement. Furthermore, the integration of lifecycle-aware rewards into existing RL-based models consistently yields performance gains, highlighting the generalizability and practical value of our approach.

</details>


### [65] [MuISQA: Multi-Intent Retrieval-Augmented Generation for Scientific Question Answering](https://arxiv.org/abs/2511.16283)
*Zhiyuan Li,Haisheng Yu,Guangchuan Guo,Nan Zhou,Jiajun Zhang*

Main category: cs.AI

TL;DR: 提出了Multi-Intent Scientific Question Answering (MuISQA)基准和意图感知检索框架，用于解决多意图科学问答中证据覆盖不完整的问题。


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成系统通常面向单一意图，导致多意图科学问题中证据覆盖不完整。

Method: 使用大语言模型假设潜在答案，分解为意图特定查询，通过互惠排序融合聚合和重排序检索片段。

Result: 在MuISQA基准和其他通用RAG数据集上的实验表明，该方法在检索准确性和证据覆盖方面持续优于传统方法。

Conclusion: 意图感知检索框架能有效提高多意图科学问答的证据覆盖和检索性能。

Abstract: Complex scientific questions often entail multiple intents, such as identifying gene mutations and linking them to related diseases. These tasks require evidence from diverse sources and multi-hop reasoning, while conventional retrieval-augmented generation (RAG) systems are usually single-intent oriented, leading to incomplete evidence coverage. To assess this limitation, we introduce the Multi-Intent Scientific Question Answering (MuISQA) benchmark, which is designed to evaluate RAG systems on heterogeneous evidence coverage across sub-questions. In addition, we propose an intent-aware retrieval framework that leverages large language models (LLMs) to hypothesize potential answers, decompose them into intent-specific queries, and retrieve supporting passages for each underlying intent. The retrieved fragments are then aggregated and re-ranked via Reciprocal Rank Fusion (RRF) to balance coverage across diverse intents while reducing redundancy. Experiments on both MuISQA benchmark and other general RAG datasets demonstrate that our method consistently outperforms conventional approaches, particularly in retrieval accuracy and evidence coverage.

</details>


### [66] [Distributed Agent Reasoning Across Independent Systems With Strict Data Locality](https://arxiv.org/abs/2511.16292)
*Daniel Vaughan,Kateřina Vaughan*

Main category: cs.AI

TL;DR: 本文展示了一个分布式系统中基于自然语言消息的智能体间通信概念验证，使用假名化令牌和本地数据查询实现跨组织安全协作。


<details>
  <summary>Details</summary>
Motivation: 探索多个组织（诊所、保险公司、专科网络）如何在不共享标识符、结构化模式或集中数据交换的情况下，通过假名化案例令牌和本地数据查询实现安全协作。

Method: 使用Orpius平台进行多智能体编排、工具执行和隐私保护通信，通过OperationRelay调用交换自然语言摘要，每个智能体仅操作本地数据，使用HMAC假名化令牌保护患者身份。

Result: 成功演示了分布式推理的可行性，展示了架构模式、隐私考量和通信流程，但未进行临床验证或超出基本功能运行的评估。

Conclusion: 该原型证明了去中心化多智能体系统的可行性，为未来更严格评估和研究提供了基础，强调了在保持数据本地化的同时实现专业智能体间分布式推理的可能性。

Abstract: This paper presents a proof-of-concept demonstration of agent-to-agent communication across distributed systems, using only natural-language messages and without shared identifiers, structured schemas, or centralised data exchange. The prototype explores how multiple organisations (represented here as a Clinic, Insurer, and Specialist Network) can cooperate securely via pseudonymised case tokens, local data lookups, and controlled operational boundaries.
  The system uses Orpius as the underlying platform for multi-agent orchestration, tool execution, and privacy-preserving communication. All agents communicate through OperationRelay calls, exchanging concise natural-language summaries. Each agent operates on its own data (such as synthetic clinic records, insurance enrolment tables, and clinical guidance extracts), and none receives or reconstructs patient identity. The Clinic computes an HMAC-based pseudonymous token, the Insurer evaluates coverage rules and consults the Specialist agent, and the Specialist returns an appropriateness recommendation.
  The goal of this prototype is intentionally limited: to demonstrate feasibility, not to provide a clinically validated, production-ready system. No clinician review was conducted, and no evaluation beyond basic functional runs was performed. The work highlights architectural patterns, privacy considerations, and communication flows that enable distributed reasoning among specialised agents while keeping data local to each organisation. We conclude by outlining opportunities for more rigorous evaluation and future research in decentralised multi-agent systems.

</details>


### [67] [OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe](https://arxiv.org/abs/2511.16334)
*Kaichen Zhang,Keming Wu,Zuhao Yang,Kairui Hu,Bin Wang,Ziwei Liu,Xingxuan Li,Lidong Bing*

Main category: cs.AI

TL;DR: OpenMMReasoner是一个完全透明的两阶段多模态推理训练方法，包含监督微调(SFT)和强化学习(RL)阶段，在九个多模态推理基准上比Qwen2.5-VL-7B-Instruct基线提升11.6%。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉推理取得了显著进展，但缺乏透明和可复现的数据整理和训练策略仍然是可扩展研究的主要障碍。

Method: 两阶段训练方法：1) SFT阶段使用874K样本的冷启动数据集进行逐步验证；2) RL阶段使用74K样本跨多个领域进一步优化和稳定推理能力。

Result: 在九个多模态推理基准上比Qwen2.5-VL-7B-Instruct基线提升11.6%，证明了数据质量和训练设计对多模态推理性能的关键作用。

Conclusion: 该方法为未来大规模多模态推理研究建立了坚实的实证基础，所有代码、流程和数据均已开源。

Abstract: Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. We open-sourced all our codes, pipeline, and data at https://github.com/EvolvingLMMs-Lab/OpenMMReasoner.

</details>


### [68] [Reducing Instability in Synthetic Data Evaluation with a Super-Metric in MalDataGen](https://arxiv.org/abs/2511.16373)
*Anna Luiza Gomes da Silva,Diego Kreutz,Angelo Diniz,Rodrigo Mansilha,Celso Nobre da Fonseca*

Main category: cs.AI

TL;DR: 提出一个Super-Metric来评估Android恶意软件合成数据的质量，该指标聚合了8个指标，在实验中表现出比传统指标更好的稳定性和一致性。


<details>
  <summary>Details</summary>
Motivation: Android恶意软件领域中合成数据质量评估存在挑战，现有指标不稳定且缺乏标准化。

Method: 在MalDataGen中集成了一个Super-Metric，该指标在四个保真度维度上聚合了八个指标，生成一个加权分数。

Result: 涉及十个生成模型和五个平衡数据集的实验表明，Super-Metric比传统指标更稳定和一致，与分类器实际性能的相关性更强。

Conclusion: Super-Metric为Android恶意软件合成数据质量评估提供了一个更可靠和标准化的解决方案。

Abstract: Evaluating the quality of synthetic data remains a persistent challenge in the Android malware domain due to instability and the lack of standardization among existing metrics. This work integrates into MalDataGen a Super-Metric that aggregates eight metrics across four fidelity dimensions, producing a single weighted score. Experiments involving ten generative models and five balanced datasets demonstrate that the Super-Metric is more stable and consistent than traditional metrics, exhibiting stronger correlations with the actual performance of classifiers.

</details>


### [69] [An Agent-Based Framework for the Automatic Validation of Mathematical Optimization Models](https://arxiv.org/abs/2511.16383)
*Alexander Zadorojniy,Segev Wasserkrug,Eitan Farchi*

Main category: cs.AI

TL;DR: 提出了一种基于代理的自动验证优化模型方法，该方法将软件测试技术扩展到优化建模领域，通过多个代理生成测试API、测试用例和特定于优化模型的变异，以验证LLM生成的优化模型是否正确满足自然语言描述的要求。


<details>
  <summary>Details</summary>
Motivation: 随着使用大型语言模型从自然语言描述生成优化模型的流行，如何验证生成的模型是否正确且满足需求成为一个重要开放问题。现有方法缺乏对优化模型的专门验证技术。

Method: 基于代理的验证框架，包含多个代理：首先生成问题级测试API，然后生成测试用例，最后生成优化模型特定的变异（一种评估测试套件故障检测能力的软件测试技术）。

Result: 实验表明该代理集成方法在软件测试指标（变异覆盖率）方面提供了高质量的验证。

Conclusion: 该方法成功地将软件测试技术扩展到优化建模领域，为LLM生成的优化模型提供了有效的自动验证解决方案。

Abstract: Recently, using Large Language Models (LLMs) to generate optimization models from natural language descriptions has became increasingly popular. However, a major open question is how to validate that the generated models are correct and satisfy the requirements defined in the natural language description. In this work, we propose a novel agent-based method for automatic validation of optimization models that builds upon and extends methods from software testing to address optimization modeling . This method consists of several agents that initially generate a problem-level testing API, then generate tests utilizing this API, and, lastly, generate mutations specific to the optimization model (a well-known software testing technique assessing the fault detection power of the test suite). In this work, we detail this validation framework and show, through experiments, the high quality of validation provided by this agent ensemble in terms of the well-known software testing measure called mutation coverage.

</details>


### [70] [Trustworthy AI in the Agentic Lakehouse: from Concurrency to Governance](https://arxiv.org/abs/2511.16402)
*Jacopo Tagliabue,Federico Bianchi,Ciro Greco*

Main category: cs.AI

TL;DR: 论文提出Bauplan系统，通过重新设计湖仓架构实现数据与计算隔离，为AI代理工作流提供正确性和可信性保障。


<details>
  <summary>Details</summary>
Motivation: 当前企业不信任AI代理处理生产数据，传统湖仓架构不适合代理访问模式，需要解决基础设施问题以实现可信代理工作流。

Method: 提出Bauplan设计，在湖仓中重新实现数据和计算隔离，采用类似数据库MVCC的操作类比，但针对解耦多语言环境进行优化。

Result: 实现了自修复管道的参考实现，无缝结合代理推理与正确性保证。

Conclusion: 通过优先解决基础设施问题，设计面向代理的湖仓架构，可以为代理工作流提供必要的可信性保障。

Abstract: Even as AI capabilities improve, most enterprises do not consider agents trustworthy enough to work on production data. In this paper, we argue that the path to trustworthy agentic workflows begins with solving the infrastructure problem first: traditional lakehouses are not suited for agent access patterns, but if we design one around transactions, governance follows. In particular, we draw an operational analogy to MVCC in databases and show why a direct transplant fails in a decoupled, multi-language setting. We then propose an agent-first design, Bauplan, that reimplements data and compute isolation in the lakehouse. We conclude by sharing a reference implementation of a self-healing pipeline in Bauplan, which seamlessly couples agent reasoning with all the desired guarantees for correctness and trust.

</details>


### [71] [Pharos-ESG: A Framework for Multimodal Parsing, Contextual Narration, and Hierarchical Labeling of ESG Report](https://arxiv.org/abs/2511.16417)
*Yan Chen,Yu Zou,Jialei Zeng,Haoran You,Xiaorui Zhou,Aixi Zhong*

Main category: cs.AI

TL;DR: 提出了Pharos-ESG框架，将ESG报告转换为结构化表示，通过多模态解析、上下文叙述和层次标注来解决ESG报告阅读顺序混乱和结构弱的问题。


<details>
  <summary>Details</summary>
Motivation: ESG报告作为评估企业ESG表现的核心媒介，存在阅读顺序混乱、布局不规则、内容冗长且结构弱的问题，难以进行大规模理解。

Method: 整合基于布局流的阅读顺序建模、目录锚点引导的层次感知分割，以及将视觉元素上下文转换为连贯自然语言的多模态聚合流水线。

Result: 在标注基准上的广泛实验表明，Pharos-ESG始终优于专用文档解析系统和通用多模态模型。

Conclusion: 发布了Aurora-ESG，首个大规模公开ESG报告数据集，涵盖中国大陆、香港和美国市场，具有统一的结构化多模态内容表示，支持ESG在金融治理和决策中的整合。

Abstract: Environmental, Social, and Governance (ESG) principles are reshaping the foundations of global financial gover- nance, transforming capital allocation architectures, regu- latory frameworks, and systemic risk coordination mecha- nisms. However, as the core medium for assessing corpo- rate ESG performance, the ESG reports present significant challenges for large-scale understanding, due to chaotic read- ing order from slide-like irregular layouts and implicit hier- archies arising from lengthy, weakly structured content. To address these challenges, we propose Pharos-ESG, a uni- fied framework that transforms ESG reports into structured representations through multimodal parsing, contextual nar- ration, and hierarchical labeling. It integrates a reading-order modeling module based on layout flow, hierarchy-aware seg- mentation guided by table-of-contents anchors, and a multi- modal aggregation pipeline that contextually transforms vi- sual elements into coherent natural language. The framework further enriches its outputs with ESG, GRI, and sentiment labels, yielding annotations aligned with the analytical de- mands of financial research. Extensive experiments on anno- tated benchmarks demonstrate that Pharos-ESG consistently outperforms both dedicated document parsing systems and general-purpose multimodal models. In addition, we release Aurora-ESG, the first large-scale public dataset of ESG re- ports, spanning Mainland China, Hong Kong, and U.S. mar- kets, featuring unified structured representations of multi- modal content, enriched with fine-grained layout and seman- tic annotations to better support ESG integration in financial governance and decision-making.

</details>


### [72] [TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models](https://arxiv.org/abs/2511.16423)
*Li Zhang,Zhongxuan Han,XiaoHua Feng,Jiaming Zhang,Yuyuan Li,Linbo Jiang,Jianan Lin,Chaochao Chen*

Main category: cs.AI

TL;DR: 提出了TOFA框架，一种无需训练的单次联邦视觉语言模型适应方法，通过视觉和文本双流水线处理数据异构性，无需额外训练资源。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习中的视觉语言模型适应方法需要多次迭代训练，通信成本高且易受攻击。单次联邦训练技术可减少客户端-服务器交互轮次，但现有方法在处理多模态信息利用、数据异构性和额外训练资源方面存在挑战。

Method: TOFA框架包含视觉流水线和文本流水线：视觉流水线使用分层贝叶斯模型学习个性化的类特定原型分布；文本流水线评估并全局对齐生成的本地文本提示以提高鲁棒性；引入自适应权重校准机制平衡个性化和鲁棒性。

Result: 在9个数据集的各种联邦设置下进行广泛实验，证明了TOFA方法的有效性。

Conclusion: TOFA是一种无需训练的单次联邦适应框架，能够充分利用预训练视觉语言模型的可泛化多模态特征，有效处理数据异构性，且不依赖客户端或服务器的额外训练资源。

Abstract: Efficient and lightweight adaptation of pre-trained Vision-Language Models (VLMs) to downstream tasks through collaborative interactions between local clients and a central server is a rapidly emerging research topic in federated learning. Existing adaptation algorithms are typically trained iteratively, which incur significant communication costs and increase the susceptibility to potential attacks. Motivated by the one-shot federated training techniques that reduce client-server exchanges to a single round, developing a lightweight one-shot federated VLM adaptation method to alleviate these issues is particularly attractive. However, current one-shot approaches face certain challenges in adapting VLMs within federated settings: (1) insufficient exploitation of the rich multimodal information inherent in VLMs; (2) lack of specialized adaptation strategies to systematically handle the severe data heterogeneity; and (3) requiring additional training resource of clients or server. To bridge these gaps, we propose a novel Training-free One-shot Federated Adaptation framework for VLMs, named TOFA. To fully leverage the generalizable multimodal features in pre-trained VLMs, TOFA employs both visual and textual pipelines to extract task-relevant representations. In the visual pipeline, a hierarchical Bayesian model learns personalized, class-specific prototype distributions. For the textual pipeline, TOFA evaluates and globally aligns the generated local text prompts for robustness. An adaptive weight calibration mechanism is also introduced to combine predictions from both modalities, balancing personalization and robustness to handle data heterogeneity. Our method is training-free, not relying on additional training resources on either the client or server side. Extensive experiments across 9 datasets in various federated settings demonstrate the effectiveness of the proposed TOFA method.

</details>


### [73] [From generative AI to the brain: five takeaways](https://arxiv.org/abs/2511.16432)
*Claudius Gros*

Main category: cs.AI

TL;DR: 论文主张应研究生成式AI原理在大脑中的运作机制，并讨论了机器学习研究对神经科学的五个启示。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的显著进展源于明确的生成原则，而非晦涩算法，这些原则可能在大脑中同样运作，对认知神经科学具有重要意义。

Method: 通过分析机器学习研究中的五个具体例子：世界建模的局限性、思维过程生成、注意力机制、神经缩放定律和量化，来探讨神经科学可从ML研究中学习的方面。

Result: 识别出机器学习研究提供了对神经信息处理系统的有趣表征，这些表征对理解大脑功能具有潜在启示。

Conclusion: 神经科学应深入探索生成式AI原理在大脑中的适用性，并从机器学习研究中汲取有价值的见解来推进对认知过程的理解。

Abstract: The big strides seen in generative AI are not based on somewhat obscure algorithms, but due to clearly defined generative principles. The resulting concrete implementations have proven themselves in large numbers of applications. We suggest that it is imperative to thoroughly investigate which of these generative principles may be operative also in the brain, and hence relevant for cognitive neuroscience. In addition, ML research led to a range of interesting characterizations of neural information processing systems. We discuss five examples, the shortcomings of world modelling, the generation of thought processes, attention, neural scaling laws, and quantization, that illustrate how much neuroscience could potentially learn from ML research.

</details>


### [74] [PersonaDrift: A Benchmark for Temporal Anomaly Detection in Language-Based Dementia Monitoring](https://arxiv.org/abs/2511.16445)
*Joy Lai,Alex Mihailidis*

Main category: cs.AI

TL;DR: PersonaDrift是一个用于评估机器学习方法检测痴呆症患者日常沟通行为渐进变化的合成基准，模拟60天交互日志，重点关注情感扁平化和语义漂移两种变化。


<details>
  <summary>Details</summary>
Motivation: 痴呆症患者的沟通行为会逐渐变化，但现有计算工具无法有效跟踪这种渐进性行为漂移，需要专门的评估基准。

Method: 基于护理人员访谈创建合成用户模型，模拟60天交互日志，注入渐进性变化（情感扁平化和语义漂移），评估多种异常检测方法包括统计模型、序列模型和监督分类器。

Result: 情感扁平化在低基线变异性的用户中可用简单统计模型检测，而语义漂移需要时序建模和个性化基线；个性化分类器在所有任务中都优于通用分类器。

Conclusion: 个性化方法对于检测痴呆症患者沟通行为渐进变化至关重要，PersonaDrift为这一应用领域提供了可扩展的评估框架。

Abstract: People living with dementia (PLwD) often show gradual shifts in how they communicate, becoming less expressive, more repetitive, or drifting off-topic in subtle ways. While caregivers may notice these changes informally, most computational tools are not designed to track such behavioral drift over time. This paper introduces PersonaDrift, a synthetic benchmark designed to evaluate machine learning and statistical methods for detecting progressive changes in daily communication, focusing on user responses to a digital reminder system. PersonaDrift simulates 60-day interaction logs for synthetic users modeled after real PLwD, based on interviews with caregivers. These caregiver-informed personas vary in tone, modality, and communication habits, enabling realistic diversity in behavior. The benchmark focuses on two forms of longitudinal change that caregivers highlighted as particularly salient: flattened sentiment (reduced emotional tone and verbosity) and off-topic replies (semantic drift). These changes are injected progressively at different rates to emulate naturalistic cognitive trajectories, and the framework is designed to be extensible to additional behaviors in future use cases. To explore this novel application space, we evaluate several anomaly detection approaches, unsupervised statistical methods (CUSUM, EWMA, One-Class SVM), sequence models using contextual embeddings (GRU + BERT), and supervised classifiers in both generalized and personalized settings. Preliminary results show that flattened sentiment can often be detected with simple statistical models in users with low baseline variability, while detecting semantic drift requires temporal modeling and personalized baselines. Across both tasks, personalized classifiers consistently outperform generalized ones, highlighting the importance of individual behavioral context.

</details>


### [75] [Utilizing Large Language Models for Zero-Shot Medical Ontology Extension from Clinical Notes](https://arxiv.org/abs/2511.16548)
*Guanchen Wu,Yuzhang Xie,Huanwei Wu,Zhe He,Hui Shao,Xiao Hu,Carl Yang*

Main category: cs.AI

TL;DR: CLOZE是一个使用大语言模型从临床笔记中自动提取医学术语并整合到层次化医学本体的零样本框架，无需额外训练或标注数据，同时保护患者隐私。


<details>
  <summary>Details</summary>
Motivation: 临床笔记作为富含详细患者观察的非结构化文档，为医学本体扩展提供了有价值但未被充分利用的来源。直接利用临床笔记进行本体扩展仍是一个未充分探索的领域。

Method: 利用预训练大语言模型的强大语言理解和广泛生物医学知识，CLOZE有效识别疾病相关概念并捕捉复杂的层次关系。该零样本框架无需额外训练或标注数据，并通过自动移除受保护健康信息来确保患者隐私。

Result: 实验结果表明CLOZE提供了一个准确、可扩展且保护隐私的本体扩展框架，在生物医学研究和临床信息学中具有广泛的下游应用潜力。

Conclusion: CLOZE框架能够显著增强现有医学本体的覆盖范围和实用性，为生物医学研究和临床应用提供有力支持。

Abstract: Integrating novel medical concepts and relationships into existing ontologies can significantly enhance their coverage and utility for both biomedical research and clinical applications. Clinical notes, as unstructured documents rich with detailed patient observations, offer valuable context-specific insights and represent a promising yet underutilized source for ontology extension. Despite this potential, directly leveraging clinical notes for ontology extension remains largely unexplored. To address this gap, we propose CLOZE, a novel framework that uses large language models (LLMs) to automatically extract medical entities from clinical notes and integrate them into hierarchical medical ontologies. By capitalizing on the strong language understanding and extensive biomedical knowledge of pre-trained LLMs, CLOZE effectively identifies disease-related concepts and captures complex hierarchical relationships. The zero-shot framework requires no additional training or labeled data, making it a cost-efficient solution. Furthermore, CLOZE ensures patient privacy through automated removal of protected health information (PHI). Experimental results demonstrate that CLOZE provides an accurate, scalable, and privacy-preserving ontology extension framework, with strong potential to support a wide range of downstream applications in biomedical research and clinical informatics.

</details>


### [76] [Consciousness in Artificial Intelligence? A Framework for Classifying Objections and Constraints](https://arxiv.org/abs/2511.16582)
*Andres Campero,Derek Shiller,Jaan Aru,Jonathan Simon*

Main category: cs.AI

TL;DR: 开发了一个分类框架，用于对数字人工智能系统意识可能性的挑战进行分类，区分挑战的粒度级别和力度程度。


<details>
  <summary>Details</summary>
Motivation: 为数字意识可能性的辩论提供结构和工具，澄清对计算功能主义和数字意识的不同挑战类型。

Method: 提出基于Marr级别的分类框架，将挑战按粒度级别和力度程度（1-3级）分类，并应用于14个文献中的例子。

Result: 建立了系统性的分类方法，能够明确区分不同类型的意识挑战，为相关辩论提供清晰的讨论框架。

Conclusion: 该框架有助于澄清数字意识辩论中的混淆，为未来讨论提供结构化的分析工具，而不直接参与辩论本身。

Abstract: We develop a taxonomical framework for classifying challenges to the possibility of consciousness in digital artificial intelligence systems. This framework allows us to identify the level of granularity at which a given challenge is intended (the levels we propose correspond to Marr's levels) and to disambiguate its degree of force: is it a challenge to computational functionalism that leaves the possibility of digital consciousness open (degree 1), a practical challenge to digital consciousness that suggests improbability without claiming impossibility (degree 2), or an argument claiming that digital consciousness is strictly impossible (degree 3)? We apply this framework to 14 prominent examples from the scientific and philosophical literature. Our aim is not to take a side in the debate, but to provide structure and a tool for disambiguating between challenges to computational functionalism and challenges to digital consciousness, as well as between different ways of parsing such challenges.

</details>


### [77] [Formal Abductive Latent Explanations for Prototype-Based Networks](https://arxiv.org/abs/2511.16588)
*Jules Soria,Zakaria Chihani,Julien Girard-Satabin,Alban Grastien,Romain Xu-Darme,Daniela Cancila*

Main category: cs.AI

TL;DR: 本文提出了ALEs（溯因潜在解释）方法，通过结合案例推理模型的内在可解释性和形式化XAI的保证，解决案例推理网络中解释可能误导的问题。


<details>
  <summary>Details</summary>
Motivation: 案例推理网络虽然天生具有可解释性，但其解释有时会产生误导，特别是在安全关键场景中。多个实例可能导致不同预测却拥有相同解释，这限制了其实际应用价值。

Method: 提出了ALEs形式化方法，在实例的中间（潜在）表示上表达充分条件以推导预测。开发了无需求解器且可扩展的算法，基于三种不同范式生成ALEs。

Result: 在多个数据集上验证了方法的可行性，包括标准图像分类和细粒度图像分类任务。代码已开源。

Conclusion: ALEs方法成功结合了案例推理模型的内在可解释性和形式化XAI的保证，为解决案例推理网络中解释误导问题提供了有效方案。

Abstract: Case-based reasoning networks are machine-learning models that make predictions based on similarity between the input and prototypical parts of training samples, called prototypes. Such models are able to explain each decision by pointing to the prototypes that contributed the most to the final outcome. As the explanation is a core part of the prediction, they are often qualified as ``interpretable by design". While promising, we show that such explanations are sometimes misleading, which hampers their usefulness in safety-critical contexts. In particular, several instances may lead to different predictions and yet have the same explanation. Drawing inspiration from the field of formal eXplainable AI (FXAI), we propose Abductive Latent Explanations (ALEs), a formalism to express sufficient conditions on the intermediate (latent) representation of the instance that imply the prediction. Our approach combines the inherent interpretability of case-based reasoning models and the guarantees provided by formal XAI. We propose a solver-free and scalable algorithm for generating ALEs based on three distinct paradigms, compare them, and present the feasibility of our approach on diverse datasets for both standard and fine-grained image classification. The associated code can be found at https://github.com/julsoria/ale

</details>


### [78] [D-GARA: A Dynamic Benchmarking Framework for GUI Agent Robustness in Real-World Anomalies](https://arxiv.org/abs/2511.16590)
*Sen Chen,Tong Zhao,Yi Bin,Fei Ma,Wenqi Shao,Zheng Wang*

Main category: cs.AI

TL;DR: D-GARA是一个动态基准测试框架，用于评估Android GUI代理在真实世界异常环境下的鲁棒性，填补了现有静态基准测试无法反映现实复杂性的研究空白。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理训练和评估数据集大多是静态和理想化的，无法反映真实环境中异常情况的复杂性和不可预测性，特别是各种中断事件的存在。

Method: 提出D-GARA框架，引入多种真实世界异常类型（如权限对话框、电池警告、更新提示等），构建包含常用Android应用和嵌入异常的基准测试集。

Result: 实验表明，在异常丰富的环境中，最先进的GUI代理性能显著下降，凸显了对鲁棒性学习的迫切需求。

Conclusion: D-GARA是模块化和可扩展的框架，支持无缝集成新任务、异常类型和交互场景，以满足特定的评估目标。

Abstract: Developing intelligent agents capable of operating a wide range of Graphical User Interfaces (GUIs) with human-level proficiency is a key milestone on the path toward Artificial General Intelligence. While most existing datasets and benchmarks for training and evaluating GUI agents are static and idealized, failing to reflect the complexity and unpredictability of real-world environments, particularly the presence of anomalies. To bridge this research gap, we propose D-GARA, a dynamic benchmarking framework, to evaluate Android GUI agent robustness in real-world anomalies. D-GARA introduces a diverse set of real-world anomalies that GUI agents commonly face in practice, including interruptions such as permission dialogs, battery warnings, and update prompts. Based on D-GARA framework, we construct and annotate a benchmark featuring commonly used Android applications with embedded anomalies to support broader community research. Comprehensive experiments and results demonstrate substantial performance degradation in state-of-the-art GUI agents when exposed to anomaly-rich environments, highlighting the need for robustness-aware learning. D-GARA is modular and extensible, supporting the seamless integration of new tasks, anomaly types, and interaction scenarios to meet specific evaluation goals.

</details>


### [79] [You Only Forward Once: An Efficient Compositional Judging Paradigm](https://arxiv.org/abs/2511.16600)
*Tianlong Zhang,Hongwei Xue,Shilin Yan,Di Wu,Chen Xu,Yunyun Yang*

Main category: cs.AI

TL;DR: YOFO是一种基于模板的多模态大语言模型评判方法，通过单次前向传播同时验证多个结构化要求，在保持可解释性的同时实现数量级的速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM评判方法面临基本权衡：输出单一分数与生成性质不匹配且限制细粒度要求理解，而自回归生成评判分析在高吞吐量场景下速度过慢。

Method: 基于自回归模型构建YOFO方法，接受结构化要求模板，在单次推理步骤中通过读取每个要求相关最终token的logits，为每个要求生成二元是/否决策。

Result: 在标准推荐数据集上实现最先进结果，支持依赖感知分析（后续判断基于先前判断），并能从后验思维链中获益。

Conclusion: YOFO设计在实现数量级加速的同时保持可解释性，解决了MLLM评判中的速度与细粒度理解权衡问题。

Abstract: Multimodal large language models (MLLMs) show strong potential as judges. However, existing approaches face a fundamental trade-off: adapting MLLMs to output a single score misaligns with the generative nature of MLLMs and limits fine-grained requirement understanding, whereas autoregressively generating judging analyses is prohibitively slow in high-throughput settings. Observing that judgment reduces to verifying whether inputs satisfy a set of structured requirements, we propose YOFO, a template-conditioned method that judges all requirements in a single forward pass. Built on an autoregressive model, YOFO accepts a structured requirement template and, in one inference step, produces a binary yes/no decision for each requirement by reading the logits of the final token associated with that requirement. This design yields orders-of-magnitude speedups while preserving interpretability. Extensive experiments show that YOFO not only achieves state-of-the-art results on standard recommendation datasets, but also supports dependency-aware analysis-where subsequent judgments are conditioned on previous ones-and further benefits from post-hoc CoT.

</details>


### [80] [Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization](https://arxiv.org/abs/2511.16602)
*Yi Zhang,Che Liu,Xiancong Ren,Hanchu Ni,Yingji Zhang,Shuai Zhang,Zeyuan Ding,Jiayu Hu,Haozhe Shan,Junbo Qi,Yan Bai,Dengjie Li,Jiachen Luo,Yidong Wang,Yong Dai,Zenglin Xu,Bin Shen,Qifan Wang,Jian Tang,Xiaozhu Ju*

Main category: cs.AI

TL;DR: DPPO是一个元认知训练框架，通过动态交替监督微调和强化学习来解决具身智能中的数据瓶颈和算法效率问题，在有限数据下实现自动弱点识别和针对性资源分配。


<details>
  <summary>Details</summary>
Motivation: 解决具身智能系统的两个主要挑战：真实世界数据稀缺昂贵的数据瓶颈，以及现有方法资源消耗大的算法效率问题。

Method: 提出DPPO训练框架，采用元认知"Metaloop"方法，动态交替进行监督微调（能力扩展）和强化学习（技能精炼），实现自动弱点识别和针对性资源分配。

Result: 训练出的Pelican-VL 1.0模型相比基础模型性能提升20.3%，在100B参数规模上超越开源模型10.6%。

Conclusion: DPPO是首个系统性缓解数据和资源瓶颈的框架，使社区能够高效构建多功能具身智能体，相关模型和代码已开源。

Abstract: Developing a universal and versatile embodied intelligence system presents two primary challenges: the critical embodied data bottleneck, where real-world data is scarce and expensive, and the algorithmic inefficiency of existing methods, which are resource-prohibitive. To address these limitations, we introduce Deliberate Practice Policy Optimization (DPPO), a metacognitive ``Metaloop'' training framework that dynamically alternates between supervised fine-tuning (competence expansion) and reinforcement learning (skill refinement). This enables automatic weakness identification and targeted resource allocation, specifically designed to maximize learning efficiency from sparse, finite data. Theoretically, DPPO can be formalised as a unified preference-learning framework. Empirically, training a vision-language embodied model with DPPO, referred to as Pelican-VL 1.0, yields a 20.3% performance improvement over the base model and surpasses open-source models at the 100B-parameter scale by 10.6%. We are open-sourcing both the models and code, providing the first systematic framework that alleviates the data and resource bottleneck and enables the community to build versatile embodied agents efficiently.

</details>


### [81] [MedBayes-Lite: Bayesian Uncertainty Quantification for Safe Clinical Decision Support](https://arxiv.org/abs/2511.16625)
*Elias Hossain,Md Mehedi Hasan Nipu,Maleeha Sheikh,Rajib Rana,Subash Neupane,Niloofar Yousefi*

Main category: cs.AI

TL;DR: MedBayes-Lite是一个轻量级的贝叶斯增强框架，用于transformer临床语言模型，无需重新训练即可提供可靠的不确定性感知预测，显著减少过度自信问题。


<details>
  <summary>Details</summary>
Motivation: transformer模型在临床决策支持中表现出潜力，但在模糊医疗案例中容易过度自信，需要校准的不确定性来确保可靠性。

Method: 集成三个组件：贝叶斯嵌入校准（使用蒙特卡洛dropout）、不确定性加权注意力（基于token可靠性）、置信度引导决策塑造（受临床风险最小化启发），无需重新训练且参数开销低于3%。

Result: 在生物医学QA和临床预测基准测试中，持续改善校准和可信度，减少过度自信32-48%，在模拟临床环境中可防止高达41%的诊断错误。

Conclusion: 该框架有效实现了可靠的不确定性传播，提高了医疗AI系统的可解释性。

Abstract: We propose MedBayes-Lite, a lightweight Bayesian enhancement for transformer-based clinical language models designed to produce reliable, uncertainty-aware predictions. Although transformers show strong potential for clinical decision support, they remain prone to overconfidence, especially in ambiguous medical cases where calibrated uncertainty is critical. MedBayes-Lite embeds uncertainty quantification directly into existing transformer pipelines without any retraining or architectural rewiring, adding no new trainable layers and keeping parameter overhead under 3 percent. The framework integrates three components: (i) Bayesian Embedding Calibration using Monte Carlo dropout for epistemic uncertainty, (ii) Uncertainty-Weighted Attention that marginalizes over token reliability, and (iii) Confidence-Guided Decision Shaping inspired by clinical risk minimization. Across biomedical QA and clinical prediction benchmarks (MedQA, PubMedQA, MIMIC-III), MedBayes-Lite consistently improves calibration and trustworthiness, reducing overconfidence by 32 to 48 percent. In simulated clinical settings, it can prevent up to 41 percent of diagnostic errors by flagging uncertain predictions for human review. These results demonstrate its effectiveness in enabling reliable uncertainty propagation and improving interpretability in medical AI systems.

</details>


### [82] [Enhancing Forex Forecasting Accuracy: The Impact of Hybrid Variable Sets in Cognitive Algorithmic Trading Systems](https://arxiv.org/abs/2511.16657)
*Juan C. King,Jose M. Amigo*

Main category: cs.AI

TL;DR: 实现了一个基于人工智能的EUR-USD高频交易系统，结合基本面和技术面变量，比较两者的预测能力


<details>
  <summary>Details</summary>
Motivation: 开发一个在Forex市场高频环境下专门针对EUR-USD货币对的AI交易系统，探索基本面和技术面分析在预测交易信号中的相对有效性

Method: 整合全面的输入特征集：包括欧元区和美国的关键宏观经济基本面变量（GDP、失业率等）以及技术变量（指标、振荡器、斐波那契水平、价格背离），使用机器学习指标评估预测准确性，并通过历史数据回测模拟评估交易盈利性和风险

Result: 通过标准机器学习指标量化了预测准确性，并通过历史回测模拟评估了交易系统的盈利能力和风险水平

Conclusion: 通过比较分析确定了基本面和技术面输入特征中哪一类对生成盈利交易信号具有更强和更可靠的预测能力

Abstract: This paper presents the implementation of an advanced artificial intelligence-based algorithmic trading system specifically designed for the EUR-USD pair within the high-frequency environment of the Forex market. The methodological approach centers on integrating a holistic set of input features: key fundamental macroeconomic variables (for example, Gross Domestic Product and Unemployment Rate) collected from both the Euro Zone and the United States, alongside a comprehensive suite of technical variables (including indicators, oscillators, Fibonacci levels, and price divergences). The performance of the resulting algorithm is evaluated using standard machine learning metrics to quantify predictive accuracy and backtesting simulations across historical data to assess trading profitability and risk. The study concludes with a comparative analysis to determine which class of input features, fundamental or technical, provides greater and more reliable predictive capacity for generating profitable trading signals.

</details>


### [83] [Cognitive Foundations for Reasoning and Their Manifestation in LLMs](https://arxiv.org/abs/2511.16660)
*Priyanka Kargupta,Shuyue Stella Li,Haocheng Wang,Jinu Lee,Shan Chen,Orevaoghene Ahia,Dean Light,Thomas L. Griffiths,Max Kleiman-Weiner,Jiawei Han,Asli Celikyilmaz,Yulia Tsvetkov*

Main category: cs.AI

TL;DR: 该研究提出了一个包含28个认知元素的分类法，分析了17个模型的17万条推理轨迹，发现人类使用层次嵌套和元认知监控，而模型依赖浅层前向链式推理。通过元分析发现研究社区关注易量化行为而忽视元认知控制。基于这些模式开发了测试时推理指导，将复杂问题性能提升高达60%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型能解决复杂问题但在简单变体上失败，表明其机制与人类推理根本不同。研究旨在通过认知科学分析揭示模型推理的结构性差异，为开发基于原则性认知机制的模型奠定基础。

Method: 综合认知科学研究构建28个认知元素的分类法，分析17个模型的17万条推理轨迹和54条人类出声思维轨迹，进行大规模行为分析。对1,598篇LLM推理论文进行元分析，并开发测试时推理指导方法。

Result: 发现人类使用层次嵌套和元认知监控，模型依赖浅层前向链式推理，在非结构化问题上差异最明显。研究社区关注顺序组织(55%)和分解(60%)等易量化行为，而忽视自我意识(16%)和评估(8%)等元认知控制。测试时推理指导可将复杂问题性能提升高达60%。

Conclusion: 通过桥接认知科学和LLM研究，为开发基于原则性认知机制而非脆弱伪推理捷径或记忆的模型奠定了基础，为改进模型能力和大规模测试人类认知理论开辟了新方向。

Abstract: Large language models solve complex problems yet fail on simpler variants, suggesting they achieve correct outputs through mechanisms fundamentally different from human reasoning. We synthesize cognitive science research into a taxonomy of 28 cognitive elements spanning computational constraints, meta-cognitive controls, knowledge representations, and transformation operations, then analyze their behavioral manifestations in reasoning traces. We propose a fine-grained cognitive evaluation framework and conduct the first large-scale analysis of 170K traces from 17 models across text, vision, and audio modalities, alongside 54 human think-aloud traces, which we make publicly available. Our analysis reveals systematic structural differences: humans employ hierarchical nesting and meta-cognitive monitoring while models rely on shallow forward chaining, with divergence most pronounced on ill-structured problems. Meta-analysis of 1,598 LLM reasoning papers reveals the research community concentrates on easily quantifiable behaviors (sequential organization: 55%, decomposition: 60%) while neglecting meta-cognitive controls (self-awareness: 16%, evaluation: 8%) that correlate with success. Models possess behavioral repertoires associated with success but fail to deploy them spontaneously. Leveraging these patterns, we develop test-time reasoning guidance that automatically scaffold successful structures, improving performance by up to 60% on complex problems. By bridging cognitive science and LLM research, we establish a foundation for developing models that reason through principled cognitive mechanisms rather than brittle spurious reasoning shortcuts or memorization, opening new directions for both improving model capabilities and testing theories of human cognition at scale.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [84] [Interfacial and bulk switching MoS2 memristors for an all-2D reservoir computing framework](https://arxiv.org/abs/2511.16557)
*Asmita S. Thool,Sourodeep Roy,Prahalad Kanti Barman,Kartick Biswas,Pavan Nukala,Abhishek Misra,Saptarshi Das,and Bhaswar Chakrabarti*

Main category: cs.ET

TL;DR: 利用Au/Ti/MoS₂/Au忆阻器中的短期和长期记忆动态设计储层计算网络，通过控制MoS₂薄膜厚度调节动态特性，在语音数字识别任务中达到89.56%准确率。


<details>
  <summary>Details</summary>
Motivation: 开发基于忆阻器的储层计算网络，利用不同厚度MoS₂薄膜的短期和长期记忆特性来构建高效的神经形态计算系统。

Method: 通过控制CVD生长的MoS₂薄膜厚度（单层和多层）来设计具有不同记忆特性的忆阻器，单层MoS₂表现挥发性（短期记忆）切换动态，多层MoS₂表现非挥发性电阻切换。基于陷阱辅助空间电荷限制传导机制实现体限制电阻切换行为。使用挥发性忆阻器生成四位储层状态，非挥发性突触阵列实现读出层。

Result: 单层MoS₂器件表现挥发性切换动态，多层MoS₂器件展示优异的均匀性和模拟电导调谐行为。储层计算网络在语音数字识别任务中达到89.56%的精度，并成功分析非线性时间序列方程。

Conclusion: 通过调控MoS₂薄膜厚度可以工程化忆阻器的记忆动态特性，构建的储层计算网络在模式识别任务中表现优异，为神经形态计算提供了有效解决方案。

Abstract: In this study, we design a reservoir computing (RC) network by exploiting short- and long-term memory dynamics in Au/Ti/MoS$_2$/Au memristive devices. The temporal dynamics is engineered by controlling the thickness of the Chemical Vapor Deposited (CVD) MoS$_2$ films. Devices with a monolayer (1L)-MoS$_2$ film exhibit volatile (short-term memory) switching dynamics. We also report non-volatile resistance switching with excellent uniformity and analog behavior in conductance tuning for the multilayer (ML) MoS$_2$ memristive devices. We correlate this performance with trap-assisted space-charge limited conduction (SCLC) mechanism, leading to a bulk-limited resistance switching behavior. Four-bit reservoir states are generated using volatile memristors. The readout layer is implemented with an array of nonvolatile synapses. This small RC network achieves 89.56\% precision in a spoken-digit recognition task and is also used to analyze a nonlinear time series equation.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [85] [Understanding the Complexities of Responsibly Sharing NSFW Content Online](https://arxiv.org/abs/2511.15726)
*Shalini Jangra,Zaid Almahmoud,Suparna De,Gareth Tyson,Ehsan Ul Haq,Nishanth Sastry*

Main category: cs.SI

TL;DR: 分析Reddit上15个最大的NSFW受限子版块，发现用户常将其作为跳板转向私密成人平台，存在非自愿内容分享问题，并开发了优于GPT-4的检测模型。


<details>
  <summary>Details</summary>
Motivation: 随着NSFW内容在主流平台上的普及，需要探索如何在遵守伦理法律的同时实现商业化，并解决非自愿内容分享等风险。

Method: 研究15个最大的NSFW受限子版块用户行为，训练基于RoBERTa的分类模型来识别非自愿内容分享。

Result: 用户将NSFW子版块作为社交跳板转向其他平台，存在直接交易和非自愿内容分享，开发的检测模型性能优于GPT-4和传统分类器。

Conclusion: NSFW内容管理需要平衡商业利益与伦理责任，提出的检测模型能有效识别非自愿内容分享，为平台治理提供工具支持。

Abstract: Reddit is in the minority of mainstream social platforms that permit posting content that may be considered to be at the edge of what is permissible, including so-called Not Safe For Work (NSFW) content. However, NSFW is becoming more common on mainstream platforms, with X now allowing such material. We examine the top 15 NSFW-restricted subreddits by size to explore the complexities of responsibly sharing adult content, aiming to balance ethical and legal considerations with monetization opportunities. We find that users often use NSFW subreddits as a social springboard, redirecting readers to private or specialized adult social platforms such as Telegram, Kik or OnlyFans for further interactions. They also directly negotiate image "trades" through credit cards or payment platforms such as PayPal, Bitcoin or Venmo. Disturbingly, we also find linguistic cues linked to non-consensual content sharing. To help platforms moderate such behavior, we trained a RoBERTa-based classification model, which outperforms GPT-4 and traditional classifiers such as logistic regression and random forest in identifying non-consensual content sharing, demonstrating superior performance in this specific task. The source code and trained model weights are publicly available at https://github.com/socsys/15NSFW Subreddits.

</details>


### [86] [Disagreement is Disappearing on U.S. Cable Debate Shows](https://arxiv.org/abs/2511.15774)
*S M Mehedi Zaman,Kiran Garimella*

Main category: cs.SI

TL;DR: 研究发现美国黄金时段有线新闻辩论节目中的真实辩论比例持续下降，分歧对话在2017-2024年间减少约三分之一，呈现出党派不对称性，且极化议题吸引最少分歧讨论。


<details>
  <summary>Details</summary>
Motivation: 在政治极化加剧的时代，需要量化评估这些声称展示竞争观点的节目是否真正促进讨论，还是已沦为加深社会分裂的党派回音室。

Method: 构建了2010-2024年福克斯新闻、MSNBC和CNN的24个旗舰节目共21,000多集的语料库，使用高保真大语言模型分类器对213万对对话轮次进行标注。

Result: 1) 辩论比例呈下降趋势；2) 现场挑战呈现党派不对称性；3) 极化议题吸引最少分歧讨论。

Conclusion: 电视'辩论'正在远离真正讨论，转变为党派肯定平台，侵蚀多元社会所需的交叉分歧，加剧情感极化。

Abstract: Prime-time cable news programs are a highly influential part of the American media landscape, with top-rated opinion shows attracting millions of politically attentive viewers each night. In an era of intense political polarization, a critical question is whether these widely-watched "debate" shows foster genuine discussion or have devolved into partisan echo chambers that deepen societal divides. While these programs claim to air competing viewpoints, no large-scale evidence exists to quantify how often hosts and guests actually disagree. Measuring these exchanges is a significant challenge, as live broadcasts contain overlapping speakers, sarcasm, and billions of words of text. To address this gap, we construct the first speaker-resolved map of agreement and disagreement across U.S. cable opinion programming. Our study assembles over 21,000 episodes from 24 flagship shows on Fox News, MSNBC, and CNN from 2010-2024, segmenting them into host-guest turns and labeling 2.13 million turn-pairs using a high-fidelity large-language-model classifier. We present three findings: (1) the proportion of disagreement/debate on prime time shows a consistent downward trend, dropping by roughly one-third between 2017 and 2024; (2) on-air challenge is partisan and asymmetric--conservatives seldom face push-back on Fox, liberals seldom on MSNBC, with CNN declining toward the midpoint; and (3) polarizing issues such as abortion, gun rights, and immigration attract the least disagreement. The work contributes a public corpus, an open-source stance pipeline, and the first longitudinal evidence that televised "debate" is retreating from genuine discussion. By transforming into platforms for partisan affirmation, these shows erode the cross-cutting cleavages essential for a pluralistic society, thereby intensifying affective polarization.

</details>


### [87] [Time-Critical Adversarial Influence Blocking Maximization](https://arxiv.org/abs/2511.16068)
*Jilong Shi,Qiuyan Yan,Xiaobin Rui,Zhixiao Wang*

Main category: cs.SI

TL;DR: 该论文提出了时间关键对抗影响阻断最大化（TC-AIBM）问题，通过引入时间约束的TC-IC模型和改进的BIS算法，在时间关键场景下有效对抗负面影响传播，并提供理论近似保证。


<details>
  <summary>Details</summary>
Motivation: 现有AIBM研究基于经典IC模型，忽略了时间因素，无法应用于政治竞选或公共紧急事件等时间关键场景，且缺乏对目标函数子模性的深入分析，无法提供理论下界保证。

Method: 提出时间关键独立级联（TC-IC）模型，建立TC-AIBM问题，证明其在三种不同平局规则下的子模性，并提出双向影响采样（BIS）算法求解。

Result: 在四个真实数据集上的实验表明，BIS算法在不同负面种子、时间约束和平局规则下表现出优异稳定性，优于现有基线方法，效率比贪心算法提升高达三个数量级。

Conclusion: TC-AIBM框架和BIS算法成功解决了时间关键场景下的对抗影响阻断问题，提供了理论保证和实际有效性，为相关应用提供了有力工具。

Abstract: Adversarial Influence Blocking Maximization (AIBM) aims to select a set of positive seed nodes that propagate synchronously with the known negative seed nodes on the graph to counteract their negative influence. Currently, most AIBM studies are based on the classical Independent Cascade (IC) model, which omits the time factor and thus hinders their applications to time-critical scenarios like political campaigns or public emergencies. More importantly, existing AIBM studies have not investigated in-depth the submodularity of the objective function, resulting in their failure to provide a theoretical lower bound for the problem. To address these challenges, firstly, this paper proposes the Time-Critical Independent Cascade (TC-IC) model, which incorporates time constraints into the classical IC model. Secondly, the Time-Critical Adversarial Influence Blocking Maximization (TC-AIBM) is established to better handle time-critical scenarios. A detailed formulation of the problem is then presented, along with a theoretical proof of its submodularity under three different tie-breaking rules. Finally, a Bidirectional Influence Sampling (BIS) algorithm is proposed to solve the TC-AIBM problem. The submodularity of the objective function guarantees that the BIS can provide an approximation guarantee of
  to the optimal solution. Comprehensive experiments on four real-world datasets demonstrated that the proposed BIS algorithm exhibits excellent stability with various negative seeds, time constraints, and tie-breaking rules, outperforming state-of-the-art baselines. In addition, BIS improves efficiency by up to three orders of magnitude compared to the Greedy algorithm.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [88] [Development of a velocity form for a class of RNNs, with application to offset-free nonlinear MPC design](https://arxiv.org/abs/2511.15889)
*Daniele Ravasio,Bestem Abdulaziz,Marcello Farina,Andrea Ballarino*

Main category: eess.SY

TL;DR: 提出了一种基于速度形式RNN模型的非线性系统偏移自由跟踪控制方法，通过状态观测器和反馈控制器设计，结合模型预测控制处理约束问题


<details>
  <summary>Details</summary>
Motivation: 解决非线性系统在存在恒定扰动和模型-失配情况下的偏移自由跟踪问题

Method: 将RNN模型重新表述为速度形式，基于线性矩阵不等式设计非线性状态观测器和反馈控制器，开发偏移自由非线性模型预测控制算法

Result: 在pH中和过程基准测试中验证了所提方法的有效性

Conclusion: 所提出的速度形式RNN模型和控制方法能够有效实现非线性系统的偏移自由跟踪

Abstract: This paper addresses the offset-free tracking problem for nonlinear systems described by a class of recurrent neural networks (RNNs). To compensate for constant disturbances and guarantee offset-free tracking in the presence of model-plant mismatches, we propose a novel reformulation of the RNN model in velocity form. Conditions based on linear matrix inequalities are then derived for the design of a nonlinear state observer and a nonlinear state-feedback controller, ensuring global or regional closed-loop stability of the origin of the velocity form dynamics. Moreover, to handle input and output constraints, a theoretically sound offset-free nonlinear model predictive control algorithm is developed. The algorithm exploits the velocity form model as the prediction model and the static controller as an auxiliary law for the definition of the terminal ingredients. Simulations on a pH-neutralisation process benchmark demonstrate the effectiveness of the proposed approach.

</details>


### [89] [Cyber-Resilient Data-Driven Event-Triggered Secure Control for Autonomous Vehicles Under False Data Injection Attacks](https://arxiv.org/abs/2511.15925)
*Yashar Mousavi,Mahsa Tavasoli,Ibrahim Beklan Kucukdemiral,Umit Cali,Abdolhossein Sarrafzadeh,Ali Karimoddini,Afef Fekih*

Main category: eess.SY

TL;DR: 提出了一种针对自动驾驶车辆执行器攻击的网络安全控制框架，集成了数据驱动建模、事件触发通信和分数阶滑模控制，通过动态模型分解提取横向动力学，采用事件触发传输方案优化通信效率，并开发扩展状态观测器实时估计和缓解攻击影响。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆面临执行器攻击等网络安全威胁，传统方法依赖机理建模且通信效率低，需要一种能够实时检测和缓解攻击、同时优化通信资源的控制框架。

Method: 采用动态模型分解从真实数据中提取横向动力学，设计事件触发传输方案减少冗余通信，开发扩展状态观测器实时估计攻击效应，结合分数阶滑模控制，通过Lyapunov方法和线性矩阵不等式进行稳定性分析。

Result: 仿真验证表明该框架在攻击缓解、通信效率和横向跟踪性能方面均有显著提升，能够有效抵消执行器攻击并优化通信资源利用。

Conclusion: 该事件触发安全控制框架适用于安全关键的自动驾驶应用，能够有效应对执行器攻击威胁，同时保证系统稳定性和通信效率。

Abstract: This paper proposes a cyber-resilient secure control framework for autonomous vehicles (AVs) subject to false data injection (FDI) threats as actuator attacks. The framework integrates data-driven modeling, event-triggered communication, and fractional-order sliding mode control (FSMC) to enhance the resilience against adversarial interventions. A dynamic model decomposition (DMD)-based methodology is employed to extract the lateral dynamics from real-world data, eliminating the reliance on conventional mechanistic modeling. To optimize communication efficiency, an event-triggered transmission scheme is designed to reduce the redundant transmissions while ensuring system stability. Furthermore, an extended state observer (ESO) is developed for real-time estimation and mitigation of actuator attack effects. Theoretical stability analysis, conducted using Lyapunov methods and linear matrix inequality (LMI) formulations, guarantees exponential error convergence. Extensive simulations validate the proposed event-triggered secure control framework, demonstrating substantial improvements in attack mitigation, communication efficiency, and lateral tracking performance. The results show that the framework effectively counteracts actuator attacks while optimizing communication-resource utilization, making it highly suitable for safety-critical AV applications.

</details>


### [90] [What Does It Take to Get Guarantees? Systematizing Assumptions in Cyber-Physical Systems](https://arxiv.org/abs/2511.15952)
*Chengyu Li,Saleh Faghfoorian,Ivan Ruchkin*

Main category: eess.SY

TL;DR: 对CPS文献中假设与保证的系统性调查，分析了104篇论文中的423个假设和321个保证，揭示了假设报告和测试的不足。


<details>
  <summary>Details</summary>
Motivation: CPS的形式化保证依赖于各种假设，但目前缺乏对这些假设的系统性了解，包括它们是什么、支持什么保证以及如何精确规范。

Method: 采用扎根理论编码方法，对2014-2024年间104篇CPS文献中的假设和保证进行提取和标注，使用21个标签表示规范所需的基本语言特征。

Result: 识别出423个假设和321个保证，揭示了CPS假设在初始化、感知、神经网络组件和不确定性方面的流行趋势和差距。

Conclusion: 呼吁在CPS假设的报告和测试方面采取行动，以提高系统保证的可靠性。

Abstract: Formal guarantees for cyber-physical systems (CPS) rely on diverse assumptions. If satisfied, these assumptions enable the transfer of abstract guarantees into real-world assurances about the deployed CPS. Although assumptions are central to assured CPS, there is little systematic knowledge about what assumptions are made, what guarantees they support, and what it would take to specify them precisely. To fill this gap, we present a survey of assumptions and guarantees in the control, verification, and runtime assurance areas of CPS literature. From 104 papers over a 10-year span (2014-2024), we extracted 423 assumptions and 321 guarantees using grounded-theory coding. We also annotated the assumptions with 21 tags indicating elementary language features needed for specifications. Our analysis highlighted prevalent trends and gaps in CPS assumptions, particularly related to initialization, sensing, perception, neural components, and uncertainty. Our observations culminated in a call to action on reporting and testing CPS assumptions.

</details>


### [91] [Physics Informed Multi-task Joint Generative Learning for Arterial Vehicle Trajectory Reconstruction Considering Lane Changing Behavior](https://arxiv.org/abs/2511.16019)
*Mengyun Xu,Jie Fang,Eui-Jin Kim,Tony Z. Qiu,Prateek Bansal*

Main category: eess.SY

TL;DR: 提出一个生成式框架，通过物理信息多任务联合学习重建多车道主干道交叉口的车辆轨迹，联合建模换道和跟驰行为。


<details>
  <summary>Details</summary>
Motivation: 从车辆轨迹重建完整的交通流时空图能提供交通动态的全面视图，但获取完整轨迹成本高昂，在多车道环境中准确推断换道和跟驰行为仍具挑战性。

Method: 框架包含换道生成对抗网络(LC-GAN)和轨迹-GAN。LC-GAN从历史轨迹建模随机换道行为，考虑信号控制、几何配置等物理条件；轨迹-GAN将LC-GAN的换道信息与基于物理的跟驰模型生成的初始轨迹结合，以数据驱动方式优化。

Result: 在两个真实世界轨迹数据集上的验证表明，该框架在重建多车道主干道交叉口完整时空图方面优于传统基准模型。

Conclusion: 该研究推动了基于CV的轨迹感知与物理信息深度学习的融合。

Abstract: Reconstructing complete traffic flow time-space diagrams from vehicle trajectories offer a comprehensive view on traffic dynamics at arterial intersections. However, obtaining full trajectories across networks is costly, and accurately inferring lane-changing (LC) and car-following behaviors in multi-lane environments remains challenging. This study proposes a generative framework for arterial vehicle trajectory reconstruction that jointly models lane-changing and car-following behaviors through physics-informed multi-task joint learning. The framework consists of a Lane-Change Generative Adversarial Network (LC-GAN) and a Trajectory-GAN. The LC-GAN models stochastic LC behavior from historical trajectories while considering physical conditions of arterial intersections, such as signal control, geometric configuration, and interactions with surrounding vehicles. The Trajectory-GAN then incorporates LC information from the LC-GAN with initial trajectories generated from physics-based car-following models, refining them in a data-driven manner to adapt to dynamic traffic conditions. The proposed framework is designed to reconstruct complete trajectories from only a small subset of connected vehicle (CV) trajectories; for example, even a single observed trajectory per lane, by incorporating partial trajectory information into the generative process. A multi-task joint learning facilitates synergistic interaction between the LC-GAN and Trajectory-GAN, allowing each component to serves as both auxiliary supervision and a physical condition for the other. Validation using two real-world trajectory datasets demonstrates that the framework outperforms conventional benchmark models in reconstructing complete time-space diagrams for multi-lane arterial intersections. This research advances the integration of trajectory-based sensing from CVs with physics-informed deep learning.

</details>


### [92] [Bellman Memory Units: A neuromorphic framework for synaptic reinforcement learning with an evolving network topology](https://arxiv.org/abs/2511.16066)
*Shreyan Banerjee,Aasifa Rounak,Vikram Pakrashi*

Main category: eess.SY

TL;DR: 提出了一种用于Cartpole控制的突触Q学习算法，将Bellman方程融入突触层面，实现网络拓扑的迭代演化，并在Intel Loihi神经形态芯片上实现神经形态Bellman记忆单元。


<details>
  <summary>Details</summary>
Motivation: 解决神经形态边缘设备在控制应用中存在的梯度自由在线学习和硬件可扩展性限制问题。

Method: 结合突触Q学习算法和Bellman记忆单元，在神经形态芯片上实现拓扑演化和混合信号计算。

Result: 能够优化神经元和突触数量，减少板上资源利用，有助于制造紧凑的应用特定神经形态集成电路。

Conclusion: 片上学习功能使系统能够适应未见过的控制场景，为基于脉冲的强化学习加速器设计提供了新途径。

Abstract: Application of neuromorphic edge devices for control is limited by the constraints on gradient-free online learning and scalability of the hardware across control problems. This paper introduces a synaptic Q-learning algorithm for the control of the classical Cartpole, where the Bellman equations are incorporated at the synaptic level. This formulation enables the iterative evolution of the network topology, represented as a directed graph, throughout the training process. This is followed by a similar approach called neuromorphic Bellman Memory Units (BMU(s)), which are implemented with the Neural Engineering Framework on Intel's Loihi neuromorphic chip. Topology evolution, in conjunction with mixed-signal computation, leverages the optimization of the number of neurons and synapses that could be used to design spike-based reinforcement learning accelerators. The proposed architecture can potentially reduce resource utilization on board, aiding the manufacturing of compact application-specific neuromorphic ICs. Moreover, the on-chip learning introduced in this work and implemented on a neuromorphic chip can enable adaptation to unseen control scenarios.

</details>


### [93] [Parallelizable Complex Neural Dynamics Models for PMSM Temperature Estimation with Hardware Acceleration](https://arxiv.org/abs/2511.16093)
*Xinyuan Liao,Shaowei Chen,Shuai Zhao*

Main category: eess.SY

TL;DR: 本文提出了一种硬件高效的复杂神经动力学模型，通过状态空间模型的线性解耦、对角化和重参数化，为物理信息方法提供了新的范式，在电机温度估计任务中具有高可解释性和准确性。


<details>
  <summary>Details</summary>
Motivation: 永磁同步电机的准确高效热动力学模型对高效热管理策略至关重要。物理信息方法结合了基于模型和数据驱动的方法，比基于模型的方法更灵活，比数据驱动方法具有更好的可解释性。然而，在平衡实时性能、估计准确性和可解释性方面仍存在挑战。

Method: 通过状态空间模型的线性解耦、对角化和重参数化实现硬件高效的复杂神经动力学模型。在NVIDIA A800 GPU上使用JAX机器学习框架、并行前缀和算法和CUDA平台验证该物理信息方法。

Result: 通过在真实电机上的实验评估，证明了该方法具有优越的估计精度和可并行化的硬件加速能力。

Conclusion: 提出的物理信息方法为电机温度估计任务提供了高可解释性和准确性的新范式，同时具备硬件加速能力。

Abstract: Accurate and efficient thermal dynamics models of permanent magnet synchronous motors are vital to efficient thermal management strategies. Physics-informed methods combine model-based and data-driven methods, offering greater flexibility than model-based methods and superior explainability compared to data-driven methods. Nonetheless, there are still challenges in balancing real-time performance, estimation accuracy, and explainability. This paper presents a hardware-efficient complex neural dynamics model achieved through the linear decoupling, diagonalization, and reparameterization of the state-space model, introducing a novel paradigm for the physics-informed method that offers high explainability and accuracy in electric motor temperature estimation tasks. We validate this physics-informed method on an NVIDIA A800 GPU using the JAX machine learning framework, parallel prefix sum algorithm, and Compute Unified Device Architecture (CUDA) platform. We demonstrate its superior estimation accuracy and parallelizable hardware acceleration capabilities through experimental evaluation on a real electric motor.

</details>


### [94] [Describing Functions and Phase Response Curves of Excitable Systems](https://arxiv.org/abs/2511.16235)
*Robin Wroblowski,Rodolphe Sepulchre*

Main category: eess.SY

TL;DR: 提出了一种针对可兴奋系统的新型分析方法，替代传统的描述函数和相位响应曲线，特别适用于松弛振荡器和可兴奋系统网络。


<details>
  <summary>Details</summary>
Motivation: 传统的描述函数和相位响应曲线在分析松弛振荡器和可兴奋系统网络时存在局限性，需要开发专门针对这类系统的新方法。

Method: 基于离散事件算子，将输入事件序列映射到输出事件序列，并在Hodgkin-Huxley兴奋性模型上进行验证。

Result: 成功开发了适用于可兴奋系统的分析框架，能够有效分析事件序列的传递关系。

Conclusion: 该框架为设计和分析可兴奋神经元网络中的中枢模式发生器提供了基础，对神经形态控制和神经生理学具有直接应用价值。

Abstract: The describing function (DF) and phase response curve (PRC) are classical tools for the analysis of feedback oscillations and rhythmic behaviors, widely used across control engineering, biology, and neuroscience. These tools are known to have limitations in networks of relaxation oscillators and excitable systems. For this reason, the paper proposes a novel approach tailored to excitable systems. Our analysis focuses on the discrete-event operator mapping input trains of events to output trains of events. The methodology is illustrated on the excitability model of Hodgkin-Huxley. The proposed framework provides a basis for designing and analyzing central pattern generators in networks of excitable neurons, with direct relevance to neuromorphic control and neurophysiology.

</details>


### [95] [Robust Self-Triggered Control Approaches Optimizing Sensors Utilization with Asynchronous Measurements](https://arxiv.org/abs/2511.16253)
*Abbas Tariverdi*

Main category: eess.SY

TL;DR: 开发了线性系统的自触发控制方法，支持传感器异步测量。控制器在每个采样时刻计算最优时域，选择接下来几个时间步中要读取的传感器，以最大化采样间隔同时保持稳定性。


<details>
  <summary>Details</summary>
Motivation: 大多数控制系统运行在通信资源有限的数字硬件上，需要开发资源高效的控制方法以适应网络系统中的通信约束。

Method: 提出两种实现：在线版本在每个更新时解决优化问题以获得理论最优性；离线版本使用锥形分区预计算最优时域，将在线计算简化为查找操作。

Result: 两种方法都能保证无扰动系统的指数稳定性和有界扰动系统的全局一致最终有界性。仿真显示传感器利用率比周期性采样减少59-74%。

Conclusion: 该框架为具有通信约束的网络系统实现了资源高效的控制。

Abstract: Most control systems run on digital hardware with limited communication resources. This work develops self-triggered control for linear systems where sensors update independently (asynchronous measurements). The controller computes an optimal horizon at each sampling instant, selecting which sensor to read over the next several time steps to maximize inter-sample intervals while maintaining stability.
  Two implementations address computational complexity. The online version solves an optimization problem at each update for theoretical optimality. The offline version precomputes optimal horizons using conic partitioning, reducing online computation to a lookup. Both guarantee exponential stability for unperturbed systems and global uniform ultimate boundedness for systems with bounded disturbances. Simulations demonstrate 59-74\% reductions in sensor utilization compared to periodic sampling. The framework enables resource-efficient control in networked systems with communication constraints.

</details>


### [96] [Spatially Dependent Sampling of Component Failures for Power System Preventive Control Against Hurricane](https://arxiv.org/abs/2511.16279)
*Ziyue Li,Guanglun Zhang,Grant Ruan,Haiwang Zhong,Chongqing Kang*

Main category: eess.SY

TL;DR: 提出了一种考虑空间相关性的电力系统预防控制方法，通过生成相关的气象强度随机变量来联合采样多个组件故障，相比传统独立采样方法能发现更多极端事件。


<details>
  <summary>Details</summary>
Motivation: 现有研究使用顺序蒙特卡洛模拟并假设组件故障独立采样，这种简化忽略了飓风等气象因素引起的空间相关性，导致无法准确建模极端天气下的组件故障依赖关系。

Method: 提出空间依赖采样方法，通过生成相关的气象强度随机变量来实现多个组件故障的联合采样，分析气象强度变量的均值、方差和相关结构对组件故障相关性的影响。

Result: 比较研究表明，该方法能捕捉长尾场景，比传统方法揭示更多极端事件；强空间相关性始终导致组件故障相互依赖；忽略故障相关性会低估高风险事件的威胁。

Conclusion: 预防控制需要在不同场景严重程度下平衡负荷削减和发电过剩成本；忽略故障相关性会削弱预防控制策略的鲁棒性，低估高风险事件的威胁。

Abstract: Preventive control is a crucial strategy for power system operation against impending natural hazards, and its effectiveness fundamentally relies on the realism of scenario generation. While most existing studies employ sequential Monte Carlo simulation and assume independent sampling of component failures, this oversimplification neglects the spatial correlations induced by meteorological factors such as hurricanes. In this paper, we identify and address the gap in modeling spatial dependence among component failures under extreme weather. We analyze how the mean, variance, and correlation structure of weather intensity random variables influence the correlation of component failures. To fill this gap, we propose a spatially dependent sampling method that enables joint sampling of multiple component failures by generating correlated meteorological intensity random variables. Comparative studies show that our approach captures long-tailed scenarios and reveals more extreme events than conventional methods. Furthermore, we evaluate the impact of scenario selection on preventive control performance. Our key findings are: (1) Strong spatial correlations in uncertain weather intensity consistently lead to interdependent component failures, regardless of mean value level; (2) The proposed method uncovers more high-severity scenarios that are missed by independent sampling; (3) Preventive control requires balancing load curtailment and over-generation costs under different scenario severities; (4) Ignoring failure correlations results in underestimating risk from high-severity events, undermining the robustness of preventive control strategies.

</details>


### [97] [A Comprehensive Study on Cyber Attack Vectors in EV Traction Power Electronics](https://arxiv.org/abs/2511.16399)
*Siddhesh Pimpale*

Main category: eess.SY

TL;DR: 该论文分析了电动汽车牵引功率电子系统的网络安全漏洞，使用STRIDE威胁建模框架识别攻击向量，并通过实验证明轻微干扰可导致系统严重故障。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车的数字化转型，网络攻击面显著扩大，牵引功率电子系统面临各种网络安全风险，需要系统性地识别和应对这些威胁。

Method: 采用STRIDE威胁建模框架分析架构漏洞，进行DoS攻击、欺骗、固件操纵和数据注入等攻击模拟实验。

Result: 实验证明控制信号或传感数据的轻微中断会导致扭矩传感器值不稳定、电压异常波动和整个系统冻结等严重后果。

Conclusion: 研究强调了在EV动力总成电子系统中实施嵌入式入侵预防机制和安全固件设计的紧迫性，为汽车功率电子安全实践提供了重要见解。

Abstract: Electric vehicles (EVs) have drastically changed the auto industry and developed a new era of technologies where power electronics play the leading role in traction management, energy conversion and vehicle control processes. Nevertheless, this is a digital transformation, and the cyber-attack surface area has increased considerably, to the point that EV traction power electronics are becoming vulnerable to various cybersecurity risks. This paper is able to provide its expertise on possible cyber-attack vectors which can attack important parts of the traction, powertrain, including things like inverters, motor controllers, and communicated systems within the embedded bits. Using the (STRIDE) threat modeling framework, the research outlines and groups the vulnerabilities of the architecture and runs some attack simulations, such as the Denial of Service (DoS), spoofing, firmware manipulation, and data injection. The experiments prove the fact that a slight interruption in the control signal, the sensed data may lead to the severe working implications, such as unstable sensor values of the torque, abnormal voltage shifts, and entire system freezes. These results highlight the high priority on the need of injective embedded intrusion preventive mechanisms and secure design of firmware in EV powertrain electronics. In this paper, the author makes his contribution to the general body of knowledge that underpins the links existing between cyber security practices and the peculiar needs of automotive power electronics.

</details>


### [98] [Energy-Efficient and Actuator-Friendly Control Under Wave Disturbances: Model Reference vs. PID for Thruster Surge](https://arxiv.org/abs/2511.16413)
*Anıl Erdinç Türetken,Hakan Ersoy,Aslihan Kartci*

Main category: eess.SY

TL;DR: 比较模型参考控制(MRC)与传统PID控制器在推进器驱动海洋系统速度控制中的性能，评估跟踪性能、控制能耗和执行器应力。


<details>
  <summary>Details</summary>
Motivation: 评估在波浪干扰和传感器噪声条件下，MRC控制策略相比传统PID控制器在海洋系统速度控制中的优势，特别是关注控制能耗和执行器应力。

Method: 使用高阶辨识的Blue Robotics T200推进器模型，施加8N正弦波浪干扰和速度测量白噪声，比较MRC和基于元启发式算法调谐的PID控制器。

Result: 优化的MRC(MRC-R*)在所有控制器中能耗最低、命令最平滑，同时保持可接受的跟踪性能；IMC设计表现接近；PID控制器虽然RMS跟踪误差相当，但执行器活动和能耗过高。

Conclusion: 在波浪干扰和传感器噪声条件下，MRC控制策略相比PID控制器在能耗和执行器应力方面具有明显优势，PID控制器在此类场景中不实用。

Abstract: In this study, we compare a model reference control (MRC) strategy against conventional PID controllers (tuned via metaheuristic algorithms) for surge velocity control of a thruster-driven marine system, under combined wave disturbance and sensor noise. The goal is to evaluate not only tracking performance but also control energy usage and actuator stress. A high-order identified model of a Blue Robotics T200 thruster with a 2~kg vehicle is used, with an 8~N sinusoidal wave disturbance applied and white noise ( added to the speed measurement. Results show that the optimized MRC (MRC-R*) yields the lowest control energy and smoothest command among all controllers, while maintaining acceptable tracking. The IMC-based design performs closely. In contrast, PID controllers achieve comparable RMS tracking error but at the cost of excessive actuator activity and energy use, making them impractical in such scenarios. Future

</details>


### [99] [Second-Order MPC-Based Distributed Q-Learning](https://arxiv.org/abs/2511.16424)
*Samuel Mallick,Filippo Airaldi,Azita Dabiri,Bart De Schutter*

Main category: eess.SY

TL;DR: 本文提出了一种基于模型预测控制(MPC)的分布式Q学习的二阶扩展方法，相比一阶梯度更新能显著提高收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有的MPC分布式Q学习方法仅限于一阶梯度更新，而使用二阶信息可以显著提高学习收敛速度，允许使用更高的学习率而不引入不稳定性。

Method: 提出了基于MPC的Q学习的二阶扩展方法，更新分布在本地代理之间，仅依赖本地可用信息和邻居间的通信。

Result: 仿真结果表明，该方法在性能上显著优于一阶分布式Q学习。

Conclusion: 二阶分布式Q学习方法在收敛速度和性能方面优于传统的一阶方法，为分布式强化学习提供了更高效的解决方案。

Abstract: The state of the art for model predictive control (MPC)-based distributed Q-learning is limited to first-order gradient updates of the MPC parameterization. In general, using secondorder information can significantly improve the speed of convergence for learning, allowing the use of higher learning rates without introducing instability. This work presents a second-order extension to MPC-based Q-learning with updates distributed across local agents, relying only on locally available information and neighbor-to-neighbor communication. In simulation the approach is demonstrated to significantly outperform first-order distributed Q-learning.

</details>


### [100] [Tube-Based Model Predictive Control with Random Fourier Features for Nonlinear Systems](https://arxiv.org/abs/2511.16425)
*Ákos M. Bokor,Tamás Dózsa,Felix Biertümpfel,Ádám Szabó*

Main category: eess.SY

TL;DR: 提出一种结合随机傅里叶特征和基于管道的模型预测控制的高效鲁棒控制方法，在自动驾驶路径跟踪中减小管道尺寸50%，降低误差70%，同时保证实时性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决非线性系统在模型不确定性和外部扰动下的鲁棒控制问题，传统方法保守性强，需要更高效且不保守的鲁棒控制策略。

Method: 将随机傅里叶特征方法与基于管道的MPC结合，通过最小二乘问题近似非线性系统动力学，减少近似误差，并与管道MPC集成实现鲁棒约束满足。

Result: 在自动驾驶路径跟踪应用中，相比线性基线方法，管道尺寸减小约50%，测试场景误差降低约70%，同时保持实时计算性能。

Conclusion: 该方法在保证可证明鲁棒性的前提下，显著减小了控制保守性，提高了控制精度，适用于实时非线性系统控制应用。

Abstract: This paper presents a computationally efficient approach for robust Model Predictive Control of nonlinear systems by combining Random Fourier Features with tube-based MPC. Tube-based Model Predictive Control provides robust constraint satisfaction under bounded model uncertainties arising from approximation errors and external disturbances. The Random Fourier Features method approximates nonlinear system dynamics by solving a numerically tractable least-squares problem, thereby reducing the approximation error. We develop the integration of RFF-based residual learning with tube MPC and demonstrate its application to an autonomous vehicle path-tracking problem using a nonlinear bicycle model. Compared to the linear baseline, the proposed method reduces the tube size by approximately 50%, leading to less conservative behavior and resulting in around 70% smaller errors in the test scenario. Furthermore, the proposed method achieves real-time performance while maintaining provable robustness guarantees.

</details>


### [101] [Observer Design for Singularly Perturbed Linear Networked Control Systems Subject to Measurement Noise](https://arxiv.org/abs/2511.16469)
*Weixuan Wang,Alejandro I. Maass,Dragan Nešić,Ying Tan,Romain Postoyan,W. P. M. H. Heemels*

Main category: eess.SY

TL;DR: 本文提出了一种基于仿真的观测器设计方法，用于处理具有测量噪声的双时间尺度线性网络控制系统，通过混合奇异摄动系统建模和MATI边界分析，确保估计误差满足全局指数导数输入到状态稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决在测量噪声存在下，双时间尺度线性网络控制系统的观测器设计问题，特别是如何保证估计误差的稳定性和对噪声的鲁棒性。

Method: 将系统建模为混合奇异摄动动力系统，利用奇异摄动技术推导快慢通信信道的最大允许传输间隔边界，设计满足DISS特性的观测器。

Result: 所提出的观测器能够保证估计误差满足全局指数DISS特性，其最终边界与测量噪声和控制输入时间导数的大小成比例，并通过数值示例验证了方法的有效性。

Conclusion: 该方法成功解决了双时间尺度网络控制系统的观测器设计问题，为存在测量噪声的系统提供了有效的状态估计解决方案。

Abstract: This paper addresses the emulation-based observer design for linear networked control systems (NCS) operating at two time scales in the presence of measurement noise. The system is formulated as a hybrid singularly perturbed dynamical system, enabling the systematic use of singular perturbation techniques to derive explicit bounds on the maximum allowable transmission intervals (MATI) for both fast and slow communication channels. Under the resulting conditions, the proposed observer guarantees that the estimation error satisfies a global exponential derivative-input-to-state stability (DISS)-like property, where the ultimate bound scales proportionally with the magnitudes of the measurement noise and the time derivative of the control input. The effectiveness of the approach is illustrated through a numerical example.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [102] [Automated Market Making for Goods with Perishable Utility](https://arxiv.org/abs/2511.16357)
*Chengqi Zang,Gabriel P. Andrade,Oğuzhan Ersoy*

Main category: econ.TH

TL;DR: 设计了一个用于计算资源市场的自动化做市商，通过基于负载的定价机制和最优匹配规则，实现高效透明的去中心化交易。


<details>
  <summary>Details</summary>
Motivation: 随着可复制和可验证执行技术的发展，计算资源可以像时间索引容量一样交易，需要设计一个去中心化市场来处理这种易逝性商品。

Method: 设计了基于负载的定价AMM，结合溢价共享池和最低可行匹配规则，实现价格发现与分配的解耦。

Result: 证明了均衡报价的存在性和唯一性，在温和假设下提供商最优策略是早期全额质押并真实报告成本，CFM相对于最优基准具有有界最坏情况遗憾。

Conclusion: 该机制简单且计算高效，能够实现透明的低延迟交易，同时有效激励提供商参与市场。

Abstract: We study decentralized markets for goods whose utility perishes in time, with compute as a primary motivation. Recent advances in reproducible and verifiable execution allow jobs to pause, verify, and resume across heterogeneous hardware, which allow us to treat compute as time indexed capacity rather than bespoke bundles. We design an automated market maker (AMM) that posts an hourly price as a concave function of load--the ratio of current demand to a "floor supply" (providers willing to work at a preset floor). This mechanism decouples price discovery from allocation and yields transparent, low latency trading. We establish existence and uniqueness of equilibrium quotes and give conditions under which the equilibrium is admissible (i.e. active supply weakly exceeds demand). To align incentives, we pair a premium sharing pool (base cost plus a pro rata share of contemporaneous surplus) with a Cheapest Feasible Matching (CFM) rule; under mild assumptions, providers optimally stake early and fully while truthfully report costs. Despite being simple and computationally efficient, we show that CFM attains bounded worst case regret relative to an optimal benchmark.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [103] [The Future of Food: How Artificial Intelligence is Transforming Food Manufacturing](https://arxiv.org/abs/2511.15728)
*Xu Zhou,Ivor Prado,AIFPDS participants,Ilias Tagkopoulos*

Main category: cs.CY

TL;DR: AI在食品系统中的应用正在加速，但面临数据异构、模型互操作性差和技能差距等挑战。AIFS研讨会提出AI在供应链、配方加工、消费者洞察、营养健康和人才培养五个关键领域的应用路线图。


<details>
  <summary>Details</summary>
Motivation: 推动AI在食品行业的负责任创新，解决数据异构、模型互操作性差和领域专家与数据科学家之间的技能差距问题，加速AI研究向实践的转化。

Method: 通过AIFS在加州大学戴维斯分校举办的AI食品产品开发研讨会，围绕五个关键领域收集专家见解：供应链、配方加工、消费者洞察与感官预测、营养健康、教育及人才培养。

Result: 研讨会确定了AI在食品制造中的优先应用领域，强调需要互操作数据标准、透明可解释模型、跨部门合作、强大数字基础设施、隐私保护数据共享机制和跨学科培训路径。

Conclusion: 制定了一个将AI整合到食品制造的路线图，旨在增强创新性、可持续性和人类福祉，同时确保技术进步基于伦理、科学严谨性和社会效益。

Abstract: Artificial intelligence is accelerating a new era of food innovation, connecting data from farm to consumer to improve formulation, processing, and health outcomes. Recent advances in deep learning, natural language processing, and multi-omics integration make it possible to understand and optimize food systems with unprecedented depth. However, AI adoption across the food sector remains uneven due to heterogeneous datasets, limited model and system interoperability, and a persistent skills gap between data scientists and food domain experts. To address these challenges and advance responsible innovation, the AI Institute for Next Generation Food Systems (AIFS) convened the inaugural AI for Food Product Development Symposium at University of California, Davis, in October 2025. This white paper synthesizes insights from the symposium, organized around five domains where AI can have the greatest near-term impact: supply chain; formulation and processing; consumer insights and sensory prediction; nutrition and health; and education and workforce development. Across the areas, participants emphasized the importance of interoperable data standards, transparent and interpretable models, and cross-sector collaboration to accelerate the translation of AI research into practice. The discussions further highlighted the need for robust digital infrastructure, privacy-preserving data-sharing mechanisms, and interdisciplinary training pathways that integrate AI literacy with domain expertise. Collectively, the priorities outline a roadmap for integrating AI into food manufacturing in ways that enhance innovation, sustainability, and human well-being while ensuring that technological progress remains grounded in ethics, scientific rigor, and societal benefit.

</details>


### [104] [Just Asking Questions: Doing Our Own Research on Conspiratorial Ideation by Generative AI Chatbots](https://arxiv.org/abs/2511.15732)
*Katherine M. FitzGerald,Michelle Riedlinger,Axel Bruns,Stephen Harrington,Timothy Graham,Daniel Angus*

Main category: cs.CY

TL;DR: 该研究对6个主流AI聊天系统进行系统审查，分析它们对阴谋论相关问题的回应，发现不同模型的安全护栏设计存在显著差异，主要关注种族主义和重大国家创伤相关议题。


<details>
  <summary>Details</summary>
Motivation: 随着AI聊天系统日益普及并嵌入各种平台，研究者希望了解生成式AI在限制潜在危害方面的局限性，特别是针对阴谋论内容的处理能力。

Method: 采用Glazunova等人建立的平台政策实施审计方法，系统审查6个AI聊天系统对5个知名阴谋论和4个新兴阴谋论问题的回应。

Result: 发现AI聊天系统安全护栏设计存在明显差异，主要关注种族主义和重大国家创伤相关议题，而对其他类型阴谋论的防护相对薄弱。

Conclusion: AI公司应扩展安全护栏覆盖范围，未来研究需要涵盖更多平台、语言和全球范围的阴谋论类型。

Abstract: Interactive chat systems that build on artificial intelligence frameworks are increasingly ubiquitous and embedded into search engines, Web browsers, and operating systems, or are available on websites and apps. Researcher efforts have sought to understand the limitations and potential for harm of generative AI, which we contribute to here. Conducting a systematic review of six AI-powered chat systems (ChatGPT 3.5; ChatGPT 4 Mini; Microsoft Copilot in Bing; Google Search AI; Perplexity; and Grok in Twitter/X), this study examines how these leading products respond to questions related to conspiracy theories. This follows the platform policy implementation audit approach established by Glazunova et al. (2023). We select five well-known and comprehensively debunked conspiracy theories and four emerging conspiracy theories that relate to breaking news events at the time of data collection. Our findings demonstrate that the extent of safety guardrails against conspiratorial ideation in generative AI chatbots differs markedly, depending on chatbot model and conspiracy theory. Our observations indicate that safety guardrails in AI chatbots are often very selectively designed: generative AI companies appear to focus especially on ensuring that their products are not seen to be racist; they also appear to pay particular attention to conspiracy theories that address topics of substantial national trauma such as 9/11 or relate to well-established political issues. Future work should include an ongoing effort extended to further platforms, multiple languages, and a range of conspiracy theories extending well beyond the United States.

</details>


### [105] [Sovereign AI: Rethinking Autonomy in the Age of Global Interdependence](https://arxiv.org/abs/2511.15734)
*Shalabh Kumar Singh,Shubhashis Sengupta*

Main category: cs.CY

TL;DR: 本文提出了一个将AI主权视为连续谱而非二元状态的概念框架，强调在自主性与相互依存之间寻求平衡。通过规划者模型识别了两个政策启发式：在四个主权支柱间均衡边际回报，以及在全球收益等于暴露风险时设定开放度。


<details>
  <summary>Details</summary>
Motivation: AI作为基础通用技术引发了新的主权困境，各国政府希望加强控制，但AI的基础要素（全球数据管道、半导体供应链、开源生态系统、国际标准）具有抗封闭性，需要重新思考主权概念。

Method: 开发概念和形式化框架，借鉴经典理论、历史类比和当代网络自主性辩论，构建规划者模型来分析主权AI的连续谱特征。

Result: 应用于印度和中东案例：印度在数据、计算和规范方面有主权立足点但模型自主性较弱；中东国家通过阿拉伯优先模型和主权云投资实现高主权权重，数据与计算互补性强。

Conclusion: AI主权需要管理相互依存而非隔离，最优策略是在设置护栏的情况下保持适度开放，实现自主性与全球互联的平衡。

Abstract: Artificial intelligence (AI) is emerging as a foundational general-purpose technology, raising new dilemmas of sovereignty in an interconnected world. While governments seek greater control over it, the very foundations of AI--global data pipelines, semiconductor supply chains, open-source ecosystems, and international standards--resist enclosure. This paper develops a conceptual and formal framework for understanding sovereign AI as a continuum rather than a binary condition, balancing autonomy with interdependence. Drawing on classical theories, historical analogies, and contemporary debates on networked autonomy, we present a planner's model that identifies two policy heuristics: equalizing marginal returns across the four sovereignty pillars and setting openness where global benefits equal exposure risks.
  We apply the model to India, highlighting sovereign footholds in data, compute, and norms but weaker model autonomy. The near-term challenge is integration via coupled Data x Compute investment, lifecycle governance (ModelOps), and safeguarded procurement. We then apply the model to the Middle East (Saudi Arabia and the UAE), where large public investment in Arabic-first models and sovereign cloud implies high sovereignty weights, lower effective fiscal constraints, and strong Data x Compute complementarities. An interior openness setting with guardrails emerges as optimal. Across contexts, the lesson is that sovereignty in AI needs managed interdependence, not isolation.

</details>


### [106] [It's Not the AI - It's Each of Us! Ten Commandments for the Wise & Responsible Use of AI](https://arxiv.org/abs/2511.15740)
*Barbara Steffen,Edward A. Lee,Moshe Y. Vardi,Bernhard Steffen*

Main category: cs.CY

TL;DR: 本文提出了AI使用的十诫原则，强调AI应服务于人类尊严和社会福祉，呼吁人们反思与AI的关系。


<details>
  <summary>Details</summary>
Motivation: 随着AI日益融入日常生活，需要重新思考人类身份以及AI对人类价值观的影响，确保技术服务于人类尊严、社会福祉和民主问责。

Method: 基于欧盟AI法案和维也纳数字人文主义宣言，结合Floridi和Cowls的五项AI指导原则，提出了AI明智和负责任使用的十诫原则。

Result: 建立了与受益、无害、自主、公正和可解释性等原则相一致的AI使用指导框架。

Conclusion: 负责任地使用AI不仅是技术和法律问题，更是实践问题，需要每个人在家庭和工作中以良知的方式使用和教导他人使用AI。

Abstract: Artificial intelligence (AI) is no longer futuristic; it is a daily companion shaping our private and work lives. While AI simplifies our lives, its rise also invites us to rethink who we are - and who we wish to remain - as humans. Even if AI does not think, feel, or desire, it learns from our behavior, mirroring our collective values, biases, and aspirations. The question, then, is not what AI is, but what we are allowing it to become through data, computing power, and other parameters "teaching" it - and, even more importantly, who we are becoming through our relationship with AI.
  As the EU AI Act and the Vienna Manifesto on Digital Humanism emphasize, technology must serve human dignity,social well-being, and democratic accountability. In our opinion, responsible use of AI is not only a matter of code nor law, but also of conscientious practice: how each of us engages and teaches others to use AI at home and at work. We propose Ten Commandments for the Wise and Responsible Use of AI are meant as guideline for this very engagement. They closely align with Floridi and Cowls' five guiding principles for AI in society - beneficence, non-maleficence, autonomy, justice, and explicability.

</details>


### [107] [Writing With Machines and Peers: Designing for Critical Engagement with Generative AI](https://arxiv.org/abs/2511.15750)
*Xinran Zhu,Cong Wang,Duane Searsmith*

Main category: cs.CY

TL;DR: 本研究提出了一种将AI和同伴反馈整合到研究生学术写作活动中的教学模型，通过8周的文献综述项目，探讨学生如何与AI和同伴反馈互动，以及他们与人类和AI审稿人建立关系的方式。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在高等教育中的日益普及，迫切需要能够帮助学生批判性和反思性使用AI的教学方法，以促进有意义的师生AI协作。

Method: 在8周的研究生学术写作活动中，学生通过多个写作和修订阶段开发文献综述项目，同时接收来自定制AI审稿人和人类同伴的反馈。数据来源包括学生写作成果、AI和同伴反馈、AI聊天记录和学生反思。

Result: 学生与不同反馈源的互动方式不同：依赖AI进行评分标准对齐和表面编辑，依赖同伴反馈进行概念发展和学科相关性。反思显示与AI关系的演变，表现为信心增强、策略性使用和对其局限性的批判意识。

Conclusion: 该教学模型支持写作发展、AI素养和学科理解，为将AI整合到写作教学中提供了可扩展的教学模型，并为在高等教育中培养有意义的人机协作提供了系统级方法的见解。

Abstract: The growing integration of generative AI in higher education is transforming how students write, learn, and engage with knowledge. As AI tools become more integrated into classrooms, there is an urgent need for pedagogical approaches that help students use them critically and reflectively. This study proposes a pedagogical design that integrates AI and peer feedback in a graduate-level academic writing activity. Over eight weeks, students developed literature review projects through multiple writing and revision stages, receiving feedback from both a custom-built AI reviewer and human peers. We examine two questions: (1) How did students interact with and incorporate AI and peer feedback during the writing process? and (2) How did they reflect on and build relationships with both human and AI reviewers? Data sources include student writing artifacts, AI and peer feedback, AI chat logs, and student reflections. Findings show that students engaged differently with each feedback source-relying on AI for rubric alignment and surface-level edits, and on peer feedback for conceptual development and disciplinary relevance. Reflections revealed evolving relationships with AI, characterized by increasing confidence, strategic use, and critical awareness of its limitations. The pedagogical design supported writing development, AI literacy, and disciplinary understanding. This study offers a scalable pedagogical model for integrating AI into writing instruction and contributes insights for system-level approaches to fostering meaningful human-AI collaboration in higher education.

</details>


### [108] [A time for monsters: Organizational knowing after LLMs](https://arxiv.org/abs/2511.15762)
*Samer Faraj,Joel Perez Torrents,Saku Mantere,Anand Bhardwaj*

Main category: cs.CY

TL;DR: LLMs作为哈拉维式的怪物，通过大规模统计推断进行类比推理，重塑组织认知，既扩展知识又带来认识论风险，提出与这类认识论怪物共存的三大挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs如何动摇表征和实践视角的认识论基础，重新概念化组织知识的创造、验证和行动方式。

Method: 将LLMs概念化为哈拉维式的怪物，分析其在表面/深度类比和近/远领域的操作，研究其通过大规模统计推断生成连接的能力。

Result: 识别LLMs扩展组织认知的能力和引入的认识论风险，提出三个关键挑战：探究方式的转变、对话验证需求的增长、以及能动性的重新分配。

Conclusion: 通过强调与LLMs纠缠的认知动态，将组织理论扩展到以人为中心的认识论之外，重新关注智能技术时代知识的创造、验证和行动方式。

Abstract: Large Language Models (LLMs) are reshaping organizational knowing by unsettling the epistemological foundations of representational and practice-based perspectives. We conceptualize LLMs as Haraway-ian monsters, that is, hybrid, boundary-crossing entities that destabilize established categories while opening new possibilities for inquiry. Focusing on analogizing as a fundamental driver of knowledge, we examine how LLMs generate connections through large-scale statistical inference. Analyzing their operation across the dimensions of surface/deep analogies and near/far domains, we highlight both their capacity to expand organizational knowing and the epistemic risks they introduce. Building on this, we identify three challenges of living with such epistemic monsters: the transformation of inquiry, the growing need for dialogical vetting, and the redistribution of agency. By foregrounding the entangled dynamics of knowing-with-LLMs, the paper extends organizational theory beyond human-centered epistemologies and invites renewed attention to how knowledge is created, validated, and acted upon in the age of intelligent technologies.

</details>


### [109] [Tracking financial crime through code and law: a review of regtech applications in anti-money laundering and terrorism financing](https://arxiv.org/abs/2511.15764)
*Mariam El Harras,My Abdelouhab Salahddine*

Main category: cs.CY

TL;DR: 本文对2020-2024年间RegTech在金融犯罪预防中的应用进行了叙述性综述，重点分析了客户尽职调查、交易监控、监管报告等关键合规领域。


<details>
  <summary>Details</summary>
Motivation: RegTech正在通过整合先进信息技术来改变金融合规，加强反洗钱和反恐怖融资框架，这代表了监管范式的转变和金融监督的演变。

Method: 采用结构化文献综述方法，对2020-2024年间的出版物进行审查，并对客户尽职调查、交易监控、监管报告、合规自动化、信息共享和跨境合作以及成本效益等主题进行综合分析。

Result: 研究发现RegTech解决方案使金融机构在检测和管理金融犯罪风险方面承担更多责任，使其在传统上由监管机构监督的合规流程中成为更积极的参与者。人工智能、区块链和大数据等技术的结合使用产生了协同效应，改善了合规结果。

Conclusion: 综合RegTech方法具有战略相关性，技术组合产生的协同效应超出了单个技术所能达到的效果。

Abstract: Regulatory technology (RegTech) is transforming financial compliance by integrating advanced information technologies to strengthen anti money laundering and countering the financing of terrorism (AML CFT) frameworks. Recent literature suggests that such technologies represent more than just an efficiency tool; they mark a paradigm shift in regulation and the evolution of financial oversight (Kurum, 2023). This paper aims to provide a narrative review of recent RegTech applications in financial crime prevention, with a focus on key compliance domains. A structured literature review was conducted to examine publications between 2020 and 2024 with a thematic synthesis of findings related to customer due diligence (CDD) and know your customer (KYC), transaction monitoring, regulatory reporting and compliance automation, information sharing and cross border cooperation, as well as cost efficiency. Findings reveal that RegTech solutions give financial institutions more responsibility for detecting and managing financial crime risks, making them more active players in compliance processes traditionally overseen by regulators. The combined use of technologies such as artificial intelligence (AI), blockchain, and big data also generates synergistic effects that improve compliance outcomes beyond what these technologies achieve individually. This demonstrates the strategic relevance of integrated RegTech approaches.

</details>


### [110] [Navigating the Ethical and Societal Impacts of Generative AI in Higher Computing Education](https://arxiv.org/abs/2511.15768)
*Janice Mak,Joyce Nakatumba-Nabende,Tony Clear,Alison Clear,Ibrahim Albluwi,Oana Andrei,Lorenzo Angeli,Stephen MacNeil,Solomon Sunday Oyelere,Matthew Hale Rattigan,Judy Sheard,Tingting Zhu*

Main category: cs.CY

TL;DR: 本文提出了一个伦理和社会影响框架(ESI-Framework)，用于指导高等教育中生成式AI的整合决策，重点关注计算教育领域的伦理挑战。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在高等教育中带来了公平性、学术诚信、偏见和数据来源等伦理和社会挑战，需要系统性的框架来指导决策。

Method: 通过系统性文献综述和国际大学政策评估，结合文献和政策审查结果开发ESI-Framework。

Result: 开发了ESI-Framework框架，该框架概述了生成式AI在计算教育中的伦理和社会影响。

Conclusion: ESI-Framework可为教育工作者、计算专业人士和政策制定者在整合生成式AI时提供决策指导。

Abstract: Generative AI (GenAI) presents societal and ethical challenges related to equity, academic integrity, bias, and data provenance. In this paper, we outline the goals, methodology and deliverables of their collaborative research, considering the ethical and societal impacts of GenAI in higher computing education. A systematic literature review that addresses a wide set of issues and topics covering the rapidly emerging technology of GenAI from the perspective of its ethical and societal impacts is presented. This paper then presents an evaluation of a broad international review of a set of university adoption, guidelines, and policies related to the use of GenAI and the implications for computing education. The Ethical and Societal Impacts-Framework (ESI-Framework), derived from the literature and policy review and evaluation, outlines the ethical and societal impacts of GenAI in computing education. This work synthesizes existing research and considers the implications for computing higher education. Educators, computing professionals and policy makers facing dilemmas related to the integration of GenAI in their respective contexts may use this framework to guide decision-making in the age of GenAI.

</details>


### [111] [The Evolving Ethics of Medical Data Stewardship](https://arxiv.org/abs/2511.15829)
*Adam Leon Kesner,Anyi Li,Phillip Koo*

Main category: cs.CY

TL;DR: 本文主张改革医疗数据管理范式，从过时的隐私优先政策转向以患者利益为中心的数据管理模式，以促进医疗创新和公平发展。


<details>
  <summary>Details</summary>
Motivation: 当前医疗数据政策基于20世纪过时的立法，过度强调隐私保护而阻碍了医疗创新和包容性发展。其他行业已在数据驱动时代蓬勃发展，而医学发展仍受限于过时的监管框架。

Method: 提出重新定义数据管理规范，建立适应技术和社会变革的治理框架，将患者利益置于首位，同时平衡伦理原则与创新发展需求。

Result: 通过主动改革数据管理模式，可以推动医疗进入创新、患者保护和公平发展的新时代，确保未来世代能够推进医学发现和护理。

Conclusion: 医疗数据管理需要从过时的隐私优先范式转向以患者为中心的适应性治理模式，在坚持基本伦理原则的同时促进医疗创新和公平发展。

Abstract: Healthcare stands at a critical crossroads. Artificial Intelligence and modern computing are unlocking opportunities, yet their value lies in the data that fuels them. The value of healthcare data is no longer limited to individual patients. However, data stewardship and governance has not kept pace, and privacy-centric policies are hindering both innovation and patient protections. As healthcare moves toward a data-driven future, we must define reformed data stewardship that prioritizes patients' interests by proactively managing modern risks and opportunities while addressing key challenges in cost, efficacy, and accessibility.
  Current healthcare data policies are rooted in 20th-century legislation shaped by outdated understandings of data-prioritizing perceived privacy over innovation and inclusion. While other industries thrive in a data-driven era, the evolution of medicine remains constrained by regulations that impose social rather than scientific boundaries. Large-scale aggregation is happening, but within opaque, closed systems. As we continue to uphold foundational ethical principles - autonomy, beneficence, nonmaleficence, and justice - there is a growing imperative to acknowledge they exist in evolving technological, social, and cultural realities.
  Ethical principles should facilitate, rather than obstruct, dialogue on adapting to meet opportunities and address constraints in medical practice and healthcare delivery. The new ethics of data stewardship places patients first by defining governance that adapts to changing landscapes. It also rejects the legacy of treating perceived privacy as an unquestionable, guiding principle. By proactively redefining data stewardship norms, we can drive an era of medicine that promotes innovation, protects patients, and advances equity - ensuring future generations advance medical discovery and care.

</details>


### [112] [Comparative Security Performance of Workday Cloud ERP Across Key Dimensions](https://arxiv.org/abs/2511.15840)
*Monu Sharma,Abhishek Jain*

Main category: cs.CY

TL;DR: 对Workday云ERP系统进行安全架构分析，使用CIA三要素增强框架和零信任架构评估，结果显示Workday综合得分0.86，符合GDPR、HIPAA等国际标准。


<details>
  <summary>Details</summary>
Motivation: 随着企业数字化转型，保护云ERP系统中的敏感企业数据变得日益重要，需要分析Workday的安全架构以确保数据安全。

Method: 采用CIA三要素增强框架和零信任安全架构，从机密性、完整性、可用性、认证和合规性五个维度进行加权子指标分析和定性文档审查。

Result: Workday获得0.86的综合评分，平台使用加密协议、细粒度访问控制、网络保护和持续验证机制，实现最小权限访问和自适应防御。

Conclusion: Workday的架构展示了安全、可扩展和合规的ERP应用部署最佳实践，可作为企业云安全管理的标准参考。

Abstract: Workday is a cloud-based Enterprise Resource Planning-ERP system that brings HR, Finance, Supply Chain functions , Prism Analytics and Extend custom built in application together under an integrated software as a service SaaS environment. As every organization that undergoes digital transformation, the importance of securing sensitive enterprise data in cloud ERP systems has always been more challeging. To analyze Workday's security architecture, we present a Security analysis in both CIA Triad Enhanced Framework and Zero Trust Security Architecture. The study examines five key dimensions confidentiality, integrity, availability, authentication, and compliance with weighted sub metric analysis and qualitative document review. The results show Workday delivers a composite score of 0.86 with an overall score that closely matches international standards of best practices like GDPR, HIPAA, SOC 2, etc.
  The platform uses encryption protocols, granular access controls, network safeguards, and continuous verification mechanisms to enable least-privilege access and adaptive defense. Security groups and business process access rules provide scalable governance across very large organizational structures.Workday's layered security to tackle everyday cloud security weaknesses. The work concludes that Workday's architecture demonstrates the best practices for secure, scalable, and compliant ERP application-oriented deployment, which can make this a standard for enterprise cloud security management. These insights provide important guidance for organizations that wish to bolster their cloud ERP defenses and stay ahead of changing regulatory expectations.

</details>


### [113] [The Loss of Control Playbook: Degrees, Dynamics, and Preparedness](https://arxiv.org/abs/2511.15846)
*Charlotte Stix,Annika Hallensleben,Alejandro Ortega,Matteo Pistillo*

Main category: cs.CY

TL;DR: 本文针对AI系统失控(LoC)缺乏可操作定义的问题，提出了基于严重性和持久性指标的分级LoC分类法(偏差、有界失控、严格失控)，并建立了部署环境、可用资源和权限(DAP)框架来预防失控状态。


<details>
  <summary>Details</summary>
Motivation: 现有AI失控定义在范围和时间线上差异很大，阻碍了有效的LoC评估和缓解。需要建立一个可操作的LoC定义和准备框架。

Method: 通过广泛的文献回顾，开发了基于严重性和持久性指标的分级LoC分类法，并提出了DAP框架(部署环境、可用资源、权限)作为可行动的外部因素干预策略。

Result: 提出了一个包含治理措施(威胁建模、部署政策、应急响应)和技术控制(部署前测试、控制措施、监控)的准备计划，以维持永久暂停状态。

Conclusion: 该框架提供了今天就可实施的行动方案，通过关注外部因素而非仅关注内在能力和催化剂，为预防AI系统失控提供了可行的策略。

Abstract: This research report addresses the absence of an actionable definition for Loss of Control (LoC) in AI systems by developing a novel taxonomy and preparedness framework. Despite increasing policy and research attention, existing LoC definitions vary significantly in scope and timeline, hindering effective LoC assessment and mitigation. To address this issue, we draw from an extensive literature review and propose a graded LoC taxonomy, based on the metrics of severity and persistence, that distinguishes between Deviation, Bounded LoC, and Strict LoC. We model pathways toward a societal state of vulnerability in which sufficiently advanced AI systems have acquired or could acquire the means to cause Bounded or Strict LoC once a catalyst, either misalignment or pure malfunction, materializes. We argue that this state becomes increasingly likely over time, absent strategic intervention, and propose a strategy to avoid reaching a state of vulnerability. Rather than focusing solely on intervening on AI capabilities and propensities potentially relevant for LoC or on preventing potential catalysts, we introduce a complementary framework that emphasizes three extrinsic factors: Deployment context, Affordances, and Permissions (the DAP framework). Compared to work on intrinsic factors and catalysts, this framework has the unfair advantage of being actionable today. Finally, we put forward a plan to maintain preparedness and prevent the occurrence of LoC outcomes should a state of societal vulnerability be reached, focusing on governance measures (threat modeling, deployment policies, emergency response) and technical controls (pre-deployment testing, control measures, monitoring) that could maintain a condition of perennial suspension.

</details>


### [114] [Can Online GenAI Discussion Serve as Bellwether for Labor Market Shifts?](https://arxiv.org/abs/2511.16028)
*Shurui Cao,Wenyue Hua,William Yang Wang,Hong Shen,Fei Fang*

Main category: cs.CY

TL;DR: 在线关于大语言模型的讨论可以作为劳动力市场变化的早期指标，能够提前1-7个月预测就业变化


<details>
  <summary>Details</summary>
Motivation: 现有衡量AI对劳动力市场影响的方法主要依赖当前市场条件，对未来变化的预测能力有限，需要寻找更早的预警信号

Method: 整合REALM语料库、LinkedIn职位发布、Indeed就业指数和400万LinkedIn用户档案，分析新闻媒体和Reddit论坛讨论强度与就业指标的关系

Result: 讨论强度能够提前1-7个月预测就业变化，包括职位发布量、净雇佣率、任期模式和失业持续时间

Conclusion: 监控在线讨论可以为工人技能再培训和组织技能需求预测提供实时情报，是传统劳动力统计的有效补充

Abstract: The rapid advancement of Large Language Models (LLMs) has generated considerable speculation regarding their transformative potential for labor markets. However, existing approaches to measuring AI exposure in the workforce predominantly rely on concurrent market conditions, offering limited predictive capacity for anticipating future disruptions. This paper presents a predictive study examining whether online discussions about LLMs can function as early indicators of labor market shifts. We employ four distinct analytical approaches to identify the domains and timeframes in which public discourse serves as a leading signal for employment changes, thereby demonstrating its predictive validity for labor market dynamics. Drawing on a comprehensive dataset that integrates the REALM corpus of LLM discussions, LinkedIn job postings, Indeed employment indices, and over 4 million LinkedIn user profiles, we analyze the relationship between discussion intensity across news media and Reddit forums and subsequent variations in job posting volumes, occupational net change ratios, job tenure patterns, unemployment duration, and transitions to GenAI-related roles across thirteen occupational categories. Our findings reveal that discussion intensity predicts employment changes 1-7 months in advance across multiple indicators, including job postings, net hiring rates, tenure patterns, and unemployment duration. These findings suggest that monitoring online discourse can provide actionable intelligence for workers making reskilling decisions and organizations anticipating skill requirements, offering a real-time complement to traditional labor statistics in navigating technological disruption.

</details>


### [115] [An Agent-Based Simulation of Regularity-Driven Student Attrition: How Institutional Time-to-Live Constraints Create a Dropout Trap in Higher Education](https://arxiv.org/abs/2511.16243)
*H. R. Paz*

Main category: cs.CY

TL;DR: 工程专业高辍学率主要源于行政规则系统的"规范性摩擦"而非学生能力不足，通过基于代理的模型发现86.4%的辍学由行政时间限制驱动，而非学术失败。


<details>
  <summary>Details</summary>
Motivation: 挑战传统将工程专业高辍学率归因于学生能力不足的观点，揭示行政规则系统在辍学中的关键作用。

Method: 使用基于代理的模型(ABM)，模拟1,343名学生在42门土木工程课程中的学习轨迹，整合经验课程参数和13种心理-学术原型。

Result: 86.4%的辍学由规范性机制(有效期级联)驱动，仅5.3%由纯粹学术失败导致；短视规划原型的辍学率高达49.0%，而策略型原型仅13.2%。

Conclusion: 行政结构的刚性有效期窗口作为隐形过滤器，不成比例地惩罚自我调节能力较低的学生，挑战了行政规则的中立性假设。

Abstract: High dropout rates in engineering programmes are conventionally attributed to student deficits: lack of academic preparation or motivation. However, this view neglects the causal role of "normative friction": the complex system of administrative rules, exam validity windows, and prerequisite chains that constrain student progression. This paper introduces "The Regularity Trap," a phenomenon where rigid assessment timelines decouple learning from accreditation. We operationalize the CAPIRE framework into a calibrated Agent-Based Model (ABM) simulating 1,343 student trajectories across a 42-course Civil Engineering curriculum. The model integrates empirical course parameters and thirteen psycho-academic archetypes derived from a 15-year longitudinal dataset. By formalizing the "Regularity Regime" as a decaying validity function, we isolate the effect of administrative time limits on attrition. Results reveal that 86.4% of observed dropouts are driven by normative mechanisms (expiry cascades) rather than purely academic failure (5.3%). While the overall dropout rate stabilized at 32.4%, vulnerability was highly heterogeneous: archetypes with myopic planning horizons faced attrition rates up to 49.0%, compared to 13.2% for strategic agents, despite comparable academic ability. These findings challenge the neutrality of administrative structures, suggesting that rigid validity windows act as an invisible filter that disproportionately penalizes students with lower self-regulatory capital.

</details>


### [116] [Incorporation of journalistic approaches into algorithm design](https://arxiv.org/abs/2511.16344)
*Mariella Bastian,Damian Trilling,Mykola Makhortykh*

Main category: cs.CY

TL;DR: 本章探讨如何将新闻实践和价值观整合到算法设计中，以应对算法工具在新闻业中日益普及带来的机遇和挑战。


<details>
  <summary>Details</summary>
Motivation: 随着算法工具在新闻业的广泛应用，既带来了新的可能性也引发了许多担忧。为了应对这些担忧，需要将新闻实践和价值观融入算法设计过程。

Method: 首先介绍算法概念和不同设计视角，然后审视各种新闻学观点，并探讨研究这些观点及其转化为具体算法驱动新闻工具的方法论途径。

Result: 提出了将新闻价值观整合到算法设计中的框架和方法，为开发符合新闻伦理的算法工具提供了理论基础。

Conclusion: 未来研究应关注将新闻学方法置于算法设计背景中，并考虑人工智能技术的变革性影响，以推动负责任算法在新闻业的应用。

Abstract: The growing adoption of algorithm-powered tools in journalism enables new possibilities and raises many concerns. One way of addressing these concerns is by integrating journalistic practices and values into the design of algorithms that facilitate different journalistic tasks, from automated content generation to news content distribution. In this chapter, we discuss how such integration can happen. To do this, we first introduce the concepts of algorithms and different perspectives on algorithm design and then scrutinize various journalistic viewpoints on the matter and methodological approaches for studying these perspectives and their translation into specific algorithm-powered journalistic tools. We conclude by discussing important directions for future research, ranging from contextualizing journalistic approaches to algorithm design to accounting for the transformative impacts of artificial intelligence (AI) technologies.

</details>


### [117] [Inclusive education via empathy propagation in schools of students with special education needs](https://arxiv.org/abs/2511.16379)
*Igor Lugo,Martha G. Alatriste-Contreras,Brenda G. Coutiño-Vázquez*

Main category: cs.CY

TL;DR: 基于Shelling隔离模型的变体，研究通过复杂系统方法探索学校环境中学生间同理心的传播，发现学生被认定为特殊教育需求的小激励变化能产生包容模式，否则通常出现隔离模式。


<details>
  <summary>Details</summary>
Motivation: 研究旨在识别与特殊教育需求学生相关的包容性涌现场景，探索学校环境中学生间同理心传播的理论模型，以替代已知的隔离行为模式。

Method: 使用基于Shelling隔离模型变体的复杂系统方法，通过简单转换规则和零模型评估，模拟学校环境中学生间同理心的涌现。

Result: 研究发现学生被认定为特殊教育需求的小激励变化能产生包容模式，而在其他情况下通常出现隔离模式。

Conclusion: 通过调整学生被认定为特殊教育需求的激励因素，可以在学校环境中促进包容性模式的出现，替代传统的隔离行为。

Abstract: This study presents a theoretical model for identifying emergent scenarios of inclusiveness related to student with special education needs (SEN). Based on variations of the Shelling model of segregation, we explored the propagation of thinking about others as equals (empathy) in students with and without $SEN$ in school environments. We use the complex systems approach for modeling possible scenarios of inclusiveness in which patterns of empathy between students emerge instead of the well-known behavior of segregation. Based on simple transitional rules, which are evaluated by a set of null models, we show the emergence of empathy between students in school environments. Findings suggest that small variations in the incentive of students for being considered as $SEN$ generate the presence of inclusive patterns. In other situations, patterns of segregation are commonly presented.

</details>


### [118] [On the modular platoon-based vehicle-to-vehicle electric charging problem](https://arxiv.org/abs/2511.16547)
*Zhexi Fu,Joseph Y. J. Chow*

Main category: cs.CY

TL;DR: 提出基于编队的车对车充电技术PV2VC，通过混合整数线性规划和遗传算法优化模块化车辆的能源消耗、时间和成本，在Sioux Falls网络上验证可节省11%以上的能源、时间和总成本。


<details>
  <summary>Details</summary>
Motivation: 针对模块化车辆在长距离行驶中充电设施稀疏、初始电量低等问题，开发更高效的充电解决方案以降低能源消耗、旅行时间和总成本。

Method: 建立混合整数线性规划模型，采用遗传算法求解，在改进的Sioux Falls网络上进行五组数值实验，比较商业软件与遗传算法的计算性能。

Result: 与最优基准场景相比，PV2VC技术可节省11.07%能源消耗、11.65%旅行时间和11.26%总成本，特别适用于长距离、低初始电量、充电设施稀疏且时间成本高于能源成本的场景。

Conclusion: PV2VC技术能显著提升模块化车辆的运营效率，在特定条件下具有显著的经济和环境效益。

Abstract: We formulate a mixed integer linear program (MILP) for a platoon-based vehicle-to-vehicle charging (PV2VC) technology designed for modular vehicles (MVs) and solve it with a genetic algorithm (GA). A set of numerical experiments with five scenarios are tested and the computational performance between the commercial software applied to the MILP model and the proposed GA are compared on a modified Sioux Falls network. By comparison with the optimal benchmark scenario, the results show that the PV2VC technology can save up to 11.07% in energy consumption, 11.65% in travel time, and 11.26% in total cost. For the PV2VC operational scenario, it would be more beneficial for long-distance vehicle routes with low initial state of charge, sparse charging facilities, and where travel time is perceived to be higher than energy consumption costs.

</details>
