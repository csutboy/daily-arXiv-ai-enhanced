<div id=toc></div>

# Table of Contents

- [cs.ET](#cs.ET) [Total: 2]
- [cs.SI](#cs.SI) [Total: 7]
- [econ.TH](#econ.TH) [Total: 5]
- [eess.SY](#eess.SY) [Total: 26]
- [econ.EM](#econ.EM) [Total: 13]
- [stat.AP](#stat.AP) [Total: 11]
- [econ.GN](#econ.GN) [Total: 5]
- [cs.AI](#cs.AI) [Total: 83]
- [cs.CY](#cs.CY) [Total: 14]
- [cs.RO](#cs.RO) [Total: 73]


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [1] [Quantum Autoencoders for Anomaly Detection in Cybersecurity](https://arxiv.org/abs/2510.21837)
*Rohan Senthil,Swee Liang Wong*

Main category: cs.ET

TL;DR: 量子自编码器在网络安全异常检测中表现出色，特别是在数据有限的情况下，其性能优于经典自编码器。


<details>
  <summary>Details</summary>
Motivation: 网络安全中的异常检测面临正常事件远多于异常事件且新异常频繁出现的挑战，经典自编码器在数据有限的情况下表现不佳，而量子自编码器有望克服这一限制。

Method: 使用量子自编码器在BPF扩展跟踪蜜罐数据集上进行异常检测，评估了多种编码技术、ansatz类型、重复次数和特征选择策略。

Result: 8特征量子自编码器使用Dense-Angle编码和RealAmplitude ansatz，在数据有限情况下F1分数达到0.87，优于经典自编码器的0.77。

Conclusion: 量子自编码器在数据有限场景下的异常检测具有实际优势，量子编码和特征选择对量子模型开发有重要影响。

Abstract: Anomaly detection in cybersecurity is a challenging task, where normal events
far outnumber anomalous ones with new anomalies occurring frequently. Classical
autoencoders have been used for anomaly detection, but struggles in
data-limited settings which quantum counterparts can potentially overcome. In
this work, we apply Quantum Autoencoders (QAEs) for anomaly detection in
cybersecurity, specifically on the BPF-extended tracking honeypot (BETH)
dataset. QAEs are evaluated across multiple encoding techniques, ansatz types,
repetitions, and feature selection strategies. Our results demonstrate that an
8-feature QAE using Dense-Angle encoding with a RealAmplitude ansatz can
outperform Classical Autoencoders (CAEs), even when trained on substantially
fewer samples. The effects of quantum encoding and feature selection for
developing quantum models are demonstrated and discussed. In a data-limited
setting, the best performing QAE model has a F1 score of 0.87, better than that
of CAE (0.77). These findings suggest that QAEs may offer practical advantages
for anomaly detection in data-limited scenarios.

</details>


### [2] [Jenga: Responsive Tiered Memory Management without Thrashing](https://arxiv.org/abs/2510.22869)
*Rohan Kadekodi,Haoran Peng,Gilbert Bernstein,Michael D. Ernst,Baris Kasikci*

Main category: cs.ET

TL;DR: Jenga是一个分层内存系统，通过上下文页面分配策略和准确的热度测量，解决了传统分层内存系统中热冷对象混存和热度测量突变导致的性能问题，在快速层容量匹配工作集大小时，比之前最佳系统快28%。


<details>
  <summary>Details</summary>
Motivation: 传统分层内存系统存在两个主要问题：(1) 热对象和冷对象分配在同一页面中，导致页面迁移效率低下；(2) 热度测量的突然变化会导致系统颠簸，影响性能。

Method: Jenga采用上下文页面分配策略，通过准确测量页面热度，及时响应内存访问行为变化，同时避免系统颠簸。

Result: 在10个内存密集型应用中，当快速层容量匹配工作集大小时，Jenga比之前最佳分层内存系统运行速度快28%，CPU开销小于单核的3%，内存开销小于0.3%。

Conclusion: Jenga通过改进的页面分配策略和准确的热度测量机制，有效解决了传统分层内存系统的性能瓶颈，显著提升了内存密集型应用的性能。

Abstract: A heterogeneous memory has a single address space with fast access to some
addresses (a fast tier of DRAM) and slow access to other addresses (a capacity
tier of CXL-attached memory or NVM). A tiered memory system aims to maximize
the number of accesses to the fast tier via page migrations between the fast
and capacity tiers. Unfortunately, previous tiered memory systems can perform
poorly due to (1) allocating hot and cold objects in the same page and (2)
abrupt changes in hotness measurements that lead to thrashing.
  This paper presents Jenga, a tiered memory system that addresses both
problems. Jenga's memory allocator uses a novel context-based page allocation
strategy. Jenga's accurate measurements of page hotness enable it to react to
memory access behavior changes in a timely manner while avoiding thrashing.
Compared to the best previous tiered memory system, Jenga runs memory-intensive
applications 28% faster across 10 applications, when the fast tier capacity
matches the working set size, at a CPU overhead of <3% of a single core and a
memory overhead of <0.3%

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [3] [Heaven & Hell II: Scale Laws and Robustness in One-Step Heaven-Hell Consensus](https://arxiv.org/abs/2510.21950)
*Nnamdi Daniel Aghanya,Romain Leemans*

Main category: cs.SI

TL;DR: 该论文研究了Heaven-Hell网络共识模型，建立了单hub系统的精确一步收敛阈值，并开发了使其对多种实际因素鲁棒的尺度定律和操作改进。


<details>
  <summary>Details</summary>
Motivation: 研究网络共识模型中的收敛条件，使理论阈值能够适应实际系统中的各种复杂情况，如打破平局策略、节点特定容忍度、目标种子、多hub和异步更新等。

Method: 采用守恒定律视角，参数化平局策略，开发更紧的点界改进经典最坏情况保证，为异步更新提供一次通过公平性，以及种子收敛的充分条件。所有证明在Coq中机械化验证。

Result: 在环、网格、无标度图和异构加权图上进行实验，验证了紧致性和间隙闭合。建立了使单hub系统收敛阈值对多种实际因素鲁棒的尺度定律。

Conclusion: 成功开发了使网络共识模型收敛阈值鲁棒化的理论框架和实用改进，通过机械化验证和实验验证了方法的有效性和紧致性。

Abstract: We study Heaven-Hell dynamics, a model for network consensus. A known result
establishes an exact one-step convergence threshold for systems with a single
uniform hub: the per-node inbound hub weight W suffices if and only if W >=
maxrest, the maximum non-hub inbound mass. We develop scale laws and
operational refinements that make this threshold robust to tie-breaking
policies, node-specific tolerances, targeted seeding, multiple hubs, and
asynchronous updates. Our contributions include a conservation-law perspective,
parameterized tie policies, tighter pointwise bounds improving on classical
worst-case guarantees, one-pass fairness for asynchronous updates, and
sufficient conditions for seeded convergence. All proofs are mechanized in Coq,
with experiments on rings, grids, scale-free graphs, and heterogeneous weighted
graphs validating tightness and gap closures

</details>


### [4] [From Social Division to Cohesion with AI Message Suggestions in Online Chat Groups](https://arxiv.org/abs/2510.21984)
*Faria Huq,Elijah L. Claggett,Hirokazu Shirado*

Main category: cs.SI

TL;DR: LLM驱动的消息建议通过改变语言风格影响群体结构：个性化建议导致观点隔离，而考虑群体立场的建议增强凝聚力。


<details>
  <summary>Details</summary>
Motivation: 研究LLM辅助通信在社会多样性环境中的影响，特别是在如何维持社会凝聚力方面。

Method: 557名参与者进行多轮政治话题讨论，可自由重组讨论组，部分条件获得实时LLM消息建议（个性化或群体适应）。

Result: 个性化建议使用户隔离到志同道合的群体，而关系型建议通过更包容的交流增强凝聚力。

Conclusion: AI中介通信能支持多样化群体的社会凝聚力，但结果关键取决于个性化设计的方式。

Abstract: Social cohesion is difficult to sustain in societies marked by opinion
diversity, particularly in online communication. As large language model
(LLM)-driven messaging assistance becomes increasingly embedded in these
contexts, it raises critical questions about its societal impact. We present an
online experiment with 557 participants who engaged in multi-round discussions
on politically controversial topics while freely reconfiguring their discussion
groups. In some conditions, participants received real-time message suggestions
generated by an LLM, either personalized to the individual or adapted to their
group context. We find that subtle shifts in linguistic style during
communication, mediated by AI assistance, can scale up to reshape collective
structures. While individual-focused assistance leads users to segregate into
like-minded groups, relational assistance that incorporates group members'
stances enhances cohesion through more receptive exchanges. These findings
demonstrate that AI-mediated communication can support social cohesion in
diverse groups, but outcomes critically depend on how personalization is
designed.

</details>


### [5] [Cross-Platform Short-Video Diplomacy: Topic and Sentiment Analysis of China-US Relations on Douyin and TikTok](https://arxiv.org/abs/2510.22415)
*Zheng Wei,Mingchen Li,Junxiang Liao,Zeyu Yang,Xiaoyu Yang,Yixuan Xie,Pan Hui,Huamin Qu*

Main category: cs.SI

TL;DR: 该研究分析了抖音和TikTok平台上关于中美关系的讨论，通过主题聚类和情感分析发现两国在多个主题上存在显著情感差异，并探讨了中国地区社会经济因素对民众对美态度的影响。


<details>
  <summary>Details</summary>
Motivation: 研究中美社交媒体平台上关于两国关系的公众讨论，利用字节跳动旗下但运营环境不同的抖音和TikTok平台，分析不同监管和文化环境下的公众话语差异。

Method: 分析了4,040个视频和338,209条用户评论，采用主题聚类和情感分析方法，并利用中国2022年4月实施的社交媒体账号地理位置披露规定，结合人均GDP、少数民族指数和互联网普及率等社会经济指标。

Result: 识别出经济实力、技术与产业相互依存、文化认知与价值追求、应对全球挑战等关键主题，发现中美两国在各种主题上存在显著情感差异，并揭示了地区社会经济因素如何影响中国民众对美国的看法。

Conclusion: 该研究将社会经济指标与在线讨论联系起来，深入分析了区域和经济因素如何影响中国评论对美国的看法，为中美关系研究和政策制定提供了重要见解。

Abstract: We examine discussions surrounding China-U.S. relations on the Chinese and
American social media platforms \textit{Douyin} and \textit{TikTok}. Both
platforms, owned by \textit{ByteDance}, operate under different regulatory and
cultural environments, providing a unique perspective for analyzing China-U.S.
public discourse. This study analyzed 4,040 videos and 338,209 user comments to
assess the public discussions and sentiments on social media regarding
China-U.S. relations. Through topic clustering and sentiment analysis, we
identified key themes, including economic strength, technological and
industrial interdependence, cultural cognition and value pursuits, and
responses to global challenges. There are significant emotional differences
between China and the US on various themes. Since April 2022, the Chinese
government has implemented a new regulation requiring all social media accounts
to disclose their provincial-level geolocation information. Utilizing this
publicly available data, along with factors such as GDP per capita, minority
index, and internet penetration rate, we investigate the changes in sentiment
towards the U.S. in mainland China. This study links socioeconomic indicators
with online discussions, deeply analyzing how regional and economic factors
influence Chinese comments on their views of the US, providing important
insights for China-U.S. relationship research and policy making.

</details>


### [6] [A Novel Discrete-time Model of Information Diffusion on Social Networks Considering Users Behavior](https://arxiv.org/abs/2510.22501)
*Tran Van Khanh,Do Xuan Cho,Hoang Phi Dung*

Main category: cs.SI

TL;DR: 提出了SDIR模型，这是经典SIR流行病模型的扩展，用于更明确地描述在线社交网络中用户行为。新增的D状态表示收到信息但延迟传播的用户。


<details>
  <summary>Details</summary>
Motivation: 为了更好地描述在线社交网络中用户对信息传播的行为特征，特别是那些收到信息但延迟传播或最终不分享的用户行为。

Method: 基于平均场近似方法推导模型动力学方程，研究其收敛性和稳定性条件，并针对边删除问题提出近似算法。

Result: 建立了SDIR模型的动力学方程，确定了收敛和稳定性条件，并开发了最小化信息传播影响的边删除近似算法。

Conclusion: SDIR模型能够更准确地刻画在线社交网络中的信息传播动态，为控制信息扩散提供了有效的理论框架和算法工具。

Abstract: In this paper, we introduce the SDIR
(Susceptible-Delayable-Infected-Recovered) model, an extension of the classical
SIR epidemic framework, to provide a more explicit characterization of user
behavior in online social networks. The newly merged state D (delayable)
represents users who have received the information but delayed its spreading
and may eventually choose not to share it at all. Based on the mean-field
approximation method, we derive the dynamical equations of the model and
investigate its convergence and stability conditions. Under these conditions,
we further propose an approximation algorithm for the edge-deletion problem,
aiming to minimize the influence of information diffusion by identifying
approximate solutions.

</details>


### [7] [Influence of Network Topology and Vaccination Strategies on HPV Dynamics: A Simulation Study Using the SeCoNet Growth Model](https://arxiv.org/abs/2510.22644)
*Weiyi Wang,Mahendra Piraveenan*

Main category: cs.SI

TL;DR: 研究性接触网络拓扑结构如何影响HPV疫苗接种计划效果，发现基于网络中心性的策略最有效，网络拓扑特征显著影响接种效果。


<details>
  <summary>Details</summary>
Motivation: 探讨网络拓扑结构在HPV疫苗接种计划设计中的重要性，理解不同网络特征如何影响病毒传播和接种干预效果。

Method: 使用SeCoNet性接触网络增长模型，评估基于年龄、环形和多种中心性指标的疫苗接种策略，分析峰值发病率、峰值流行时间和累计发病率。

Result: 基于度、介数和渗透中心性的策略最有效，环形接种在女性中降低累计发病率效果最好；网络平均度越高接种效果越差，而幂律指数、平均最短路径长度和聚类系数越高接种效果越好。

Conclusion: 网络结构对HPV疫苗接种计划设计至关重要，应纳入网络拓扑特征来优化接种策略。

Abstract: This study examines how contact network topology influences the effectiveness
of vaccination programs in the context of human papillomavirus (HPV)
transmission. Using the SeCoNet sexual contact network growth model, we
evaluate age based, ring based, and several centrality based vaccination
strategies across the overall, male, and female cohorts, focusing on peak
incidence, timing of peak prevalence, and cumulative incidence. The simulations
show that degree, betweenness, and percolation centrality based strategies are
generally the most effective, while ring vaccination achieves the greatest
reduction in cumulative incidence among females. Network topology also plays a
critical role: higher average degree reduces vaccination effectiveness, whereas
higher power-law exponent, longer average shortest path length, and stronger
clustering improve vaccination outcomes. The results highlight the importance
of incorporating network structure into the design of HPV vaccination programs.

</details>


### [8] [Community Search in Attributed Networks using Dominance Relationships and Random Walks](https://arxiv.org/abs/2510.22850)
*Nikolaos Georgiadis,Eleftherios Tiakas,Apostolos N. Papadopoulos*

Main category: cs.SI

TL;DR: 提出一种结合跳数和随机游走方法的算法，用于在属性网络中平衡结构连通性和属性相似性，识别高质量社区。


<details>
  <summary>Details</summary>
Motivation: 解决属性网络中社区搜索的双重挑战：平衡网络拓扑结构连通性和节点属性相似性。

Method: 使用支配分数量化节点基于属性的影响力，然后通过k-core提取确保社区内的强结构凝聚力，结合跳数和随机游走方法。

Result: 在大型真实数据集上评估，证明算法能有效识别具有凝聚力的社区。

Conclusion: 该算法适用于社交网络分析和推荐系统等应用，能够高效识别既连接良好又具有有意义属性相似性的社区。

Abstract: Community search in attributed networks poses a dual challenge: balancing
structural connectivity -- the network's topological properties -- and
attribute similarity -- the shared characteristics of nodes. This paper
introduces a novel algorithm that integrates hop-based and random-walk-based
methods to identify high-quality communities, effectively addressing this
balance. Our approach employs the concept of the domination score to quantify
the influence of nodes based on their attributes, followed by $k$-core
extraction to ensure strong structural cohesion within the communities. By
considering both the network structure and node attributes, the algorithm
identifies communities that are not only well-connected, but also share
meaningful attribute similarities. We evaluated the algorithm on large
real-world datasets, demonstrating its ability to efficiently identify cohesive
communities, making it suitable for applications such as social network
analysis and recommendation systems.

</details>


### [9] [Modeling Political Discourse with Sentence-BERT and BERTopic](https://arxiv.org/abs/2510.22904)
*Margarida Mendonca,Alvaro Figueira*

Main category: cs.SI

TL;DR: 提出了一种结合BERTopic主题建模和道德基础理论的主题演化框架，用于分析美国第117届国会期间Twitter政治话题的持久性和道德维度。研究发现宏观主题稳定但细粒度话题快速消散，道德基础对话题持久性至关重要。


<details>
  <summary>Details</summary>
Motivation: 社交媒体重塑了政治话语，为政治家提供了直接参与平台，但也加剧了极化和意识形态分歧。需要理解政治话题如何随时间演变及其道德维度。

Method: 集成BERTopic主题建模与道德基础理论(MFT)，提出跟踪动态话题演变的方法，测量话题与道德价值观的关联并量化话题持久性。

Result: 宏观主题保持稳定，但细粒度话题倾向于快速消散；道德基础在话题持久性中起关键作用，关怀和忠诚主导持久话题；党派差异体现在不同的道德框架策略中。

Conclusion: 这项工作为社会网络分析和计算政治话语领域提供了可扩展、可解释的方法来理解社交媒体上道德驱动的主题演化。

Abstract: Social media has reshaped political discourse, offering politicians a
platform for direct engagement while reinforcing polarization and ideological
divides. This study introduces a novel topic evolution framework that
integrates BERTopic-based topic modeling with Moral Foundations Theory (MFT) to
analyze the longevity and moral dimensions of political topics in Twitter
activity during the 117th U.S. Congress. We propose a methodology for tracking
dynamic topic shifts over time and measuring their association with moral
values and quantifying topic persistence. Our findings reveal that while
overarching themes remain stable, granular topics tend to dissolve rapidly,
limiting their long-term influence. Moreover, moral foundations play a critical
role in topic longevity, with Care and Loyalty dominating durable topics, while
partisan differences manifest in distinct moral framing strategies. This work
contributes to the field of social network analysis and computational political
discourse by offering a scalable, interpretable approach to understanding
moral-driven topic evolution on social media.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [10] [Entry Deterrence with Partial Reputation Spillovers](https://arxiv.org/abs/2510.21759)
*Rubik Khachatryan,Georgy Lukyanov*

Main category: econ.TH

TL;DR: 分析两期两市场的连锁店博弈，其中在位者在一个市场的行为只能部分被另一个市场观察到，产生跨市场的声誉溢出效应。


<details>
  <summary>Details</summary>
Motivation: 研究在位者行为的部分可观察性如何影响跨市场的声誉效应和均衡策略。

Method: 构建两期两市场的连锁店博弈模型，分析不同先验声誉下的均衡行为，并考察可观察性、噪声信号和内生信息获取的影响。

Result: 高先验声誉时，在位者会对抗早期单独进入者；低先验声誉时，会对单个进入者混合策略，并容纳协调进入。更高的可观察性会增加早期对抗，但由于任何容纳行为会被更广泛注意，也会增加后期进入。

Conclusion: 部分可观察性产生重要的声誉溢出效应，结果对噪声信号和内生信息获取具有稳健性，并可自然扩展到多市场情形。

Abstract: We analyze a two-period, two-market chain-store game in which an incumbent's
conduct in one market is only sometimes seen in the other. This partial
observability generates reputational spillovers across markets. We characterize
equilibrium behavior by prior reputation: at high priors the strategic
incumbent fights a lone early entrant (and mixes when both arrive together); at
low priors it mixes against a single entrant and accommodates coordinated
entry. Greater observability increases early fighting yet, because any
accommodation is more widely noticed, raises the incidence of later entry. The
results are robust to noisy signals and endogenous information acquisition, and
extend naturally to many markets.

</details>


### [11] [Social preferences or moral concerns: What drives rejections in the Ultimatum game?](https://arxiv.org/abs/2510.22086)
*Pau Juan-Bartroli,José Ignacio Rivero-Wildemauwe*

Main category: econ.TH

TL;DR: 该论文提出一个结合社会偏好和道德关注的理论模型，解释了最后通牒游戏中拒绝正报价的行为。研究发现，一定程度的恶意是社会偏好驱动拒绝行为的必要且充分条件，而道德关注则起到放大作用。


<details>
  <summary>Details</summary>
Motivation: 解释最后通牒游戏中拒绝正报价的不同动机，提供一个统一的理论框架来理解这些拒绝行为。

Method: 结合社会偏好和道德关注的理论模型，使用有限混合方法估计个体的社会偏好和道德关注参数，分析最后通牒游戏和独裁者游戏数据。

Result: 识别出两类拒绝正报价的个体类型，他们在独裁者游戏中的行为不同；拒绝阈值随个体道德关注增加而提高；恶意程度是拒绝行为的决定性因素。

Conclusion: 社会偏好而非道德关注驱动拒绝行为，但道德关注放大社会偏好的影响；该模型为拒绝正报价提供了统一解释框架。

Abstract: Rejections of positive offers in the Ultimatum Game have been attributed to
different motivations. We show that a model combining social preferences and
moral concerns provides a unifying explanation for these rejections while
accounting for additional evidence. Under the preferences considered, a
positive degree of spite is a necessary and sufficient condition for rejecting
positive offers. This indicates that social preferences, rather than moral
concerns, drive rejection behavior. This does not imply that moral concerns do
not matter. We show that rejection thresholds increase with individuals' moral
concerns, suggesting that morality acts as an amplifier of social preferences.
Using data from van Leeuwen and Alger (2024), we estimate individuals' social
preferences and moral concerns using a finite mixture approach. Consistent with
previous evidence, we identify two types of individuals who reject positive
offers in the Ultimatum Game, but that differ in their Dictator Game behavior.

</details>


### [12] [Politics, Inequality, and the Robustness of Shared Infrastructure Systems](https://arxiv.org/abs/2510.22411)
*Adam Wiechman,John M. Anderies,Margaret Garcia*

Main category: econ.TH

TL;DR: 本文提出了一个动态共享基础设施系统模型，整合政治经济学、社会生态系统和政治心理学理论，分析政治过程特征如何影响基础设施系统对容量冲击和私人投资机会不平等的稳健性。


<details>
  <summary>Details</summary>
Motivation: 现有政治经济模型未考虑动态基础设施、动态用户偏好和非理性行为者理论，而工程学往往忽视政治因素，需要填补这些研究空白。

Method: 开发了一个通用的动态共享基础设施系统模型，整合政治经济学、社会生态系统和政治心理学理论，分析选举周期、意识形态敏感性等政治过程特征的影响。

Result: 用户费用下不平等会降低稳健性；对私人基础设施使用征税可提高稳健性（如果非精英有平等政治影响力）；选举周期对稳健性有非线性影响；候选人的意识形态敏感性与稳健性呈负相关。

Conclusion: 选民和候选人的偏见（支持增税或减税）调节了这些政治经济效应对稳健性的影响，因为这些偏见可能与系统实际需求（是否需要增税来恢复系统）不匹配。

Abstract: Our infrastructure systems enable our well-being by allowing us to move,
store, and transform materials and information given considerable social and
environmental variation. Critically, this ability is shaped by the degree to
which society invests in infrastructure, a fundamentally political question in
large public systems. There, infrastructure providers are distinguished from
users through political processes, such as elections, and there is considerable
heterogeneity among users. Previous political economic models have not taken
into account (i) dynamic infrastructures, (ii) dynamic user preferences, and
(iii) alternatives to rational actor theory. Meanwhile, engineering often
neglects politics. We address these gaps with a general dynamic model of shared
infrastructure systems that incorporates theories from political economy,
social-ecological systems, and political psychology. We use the model to
develop propositions on how multiple characteristics of the political process
impact the robustness of shared infrastructure systems to capacity shocks and
unequal opportunity for private infrastructure investment. Under user fees,
inequality decreases robustness, but taxing private infrastructure use can
increase robustness if non-elites have equal political influence. Election
cycle periods have a nonlinear effect where increasing them increases
robustness up to a point but decreases robustness beyond that point. Further,
there is a negative relationship between the ideological sensitivity of
candidates and robustness. Overall, the biases of voters and candidates
(whether they favor tax increases or decreases) mediate these
political-economic effects on robustness because biases may or may not match
the reality of system needs (whether system recovery requires tax increases).

</details>


### [13] [Information-Credible Stability in Matching with Incomplete Information](https://arxiv.org/abs/2510.22750)
*Kaibalyapati Mishra*

Main category: econ.TH

TL;DR: 本文提出了信息可信配对稳定性（ICPS），这是一个在不完全信息匹配市场中的稳定性概念，允许配对双方通过可信的、有成本的测试来揭示匹配相关信息，然后决定是否阻止匹配。


<details>
  <summary>Details</summary>
Motivation: 在不完全信息匹配市场中，传统贝叶斯稳定性无法排除由恐惧驱动的匹配，需要一种能够利用信息选择价值来精炼稳定性的概念。

Method: 引入ICPS概念，允许配对双方在决定是否阻止匹配前进行可信的、有成本的测试来获取相关信息，通过信息的期权价值来精炼贝叶斯稳定性。

Result: ICPS严格精炼了贝叶斯稳定性，排除了恐惧驱动的匹配，任何ICPS阻止偏差都会严格增加总期望剩余，ICPS稳定分配总是存在，促进正向分类匹配，且在测试能力足够强时具有唯一性。

Conclusion: ICPS连接了基于信念和基于信息的稳定性概念，当测试无信息或不可行时退化为贝叶斯稳定性，当测试完美且免费时等同于完全信息稳定性，可扩展到不可转移效用、相关类型和内生或顺序测试等场景。

Abstract: In this paper, I develop a refinement of stability for matching markets with
incomplete information. I introduce Information-Credible Pairwise Stability
(ICPS), a solution concept in which deviating pairs can use credible, costly
tests to reveal match-relevant information before deciding whether to block. By
leveraging the option value of information, ICPS strictly refines Bayesian
stability, rules out fear-driven matchings, and connects belief-based and
information-based notions of stability. ICPS collapses to Bayesian stability
when testing is uninformative or infeasible and coincides with
complete-information stability when testing is perfect and free. I show that
any ICPS-blocking deviation strictly increases total expected surplus, ensuring
welfare improvement. I also prove that ICPS-stable allocations always exist,
promote positive assortative matching, and are unique when the test power is
sufficiently strong. The framework extends to settings with non-transferable
utility, correlated types, and endogenous or sequential testing.

</details>


### [14] [Feedback in Dynamic Contests: Theory and Experiment](https://arxiv.org/abs/2510.23178)
*Sumit Goel,Yiqing Yan,Jeffrey Zeidel*

Main category: econ.TH

TL;DR: 研究两阶段动态全支付拍卖中中期反馈政策的影响，发现均衡结果由最廉价信号均衡描述，双方收益为零，总投标期望值等于奖品价值。实验显示投标行为偏离均衡但反馈政策无显著影响。


<details>
  <summary>Details</summary>
Motivation: 探讨动态全支付拍卖中不同反馈政策如何影响投标行为，特别关注中期反馈对投标策略和结果的影响。

Method: 理论分析两阶段动态全支付拍卖的均衡特性，并进行实验研究四种自然反馈政策（完全反馈、排名反馈和两种截断反馈）对投标行为的影响。

Result: 均衡状态下双方收益为零，总投标期望等于奖品价值；实验显示投标行为偏离理论均衡，但不同反馈政策对总投标无显著影响。

Conclusion: 虽然投标行为偏离理论预测，但反馈政策对总投标没有显著影响，阶段1投标会产生沉没成本和领先优势，影响阶段2的投标决策。

Abstract: We study the effect of interim feedback policies in a dynamic all-pay auction
where two players bid over two stages to win a common-value prize. We show that
sequential equilibrium outcomes are characterized by Cheapest Signal
Equilibria, wherein stage 1 bids are such that one player bids zero while the
other chooses a cheapest bid consistent with some signal. Equilibrium payoffs
for both players are always zero, and the sum of expected total bids equals the
value of the prize. We conduct an experiment with four natural feedback policy
treatments -- full, rank, and two cutoff policies -- and while the bidding
behavior deviates from equilibrium, we fail to reject the hypothesis of no
treatment effect on total bids. Further, stage 1 bids induce sunk costs and
head starts, and we test for the resulting sunk cost and discouragement effects
in stage 2 bidding.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [15] [A Perspective on the Algebra, Topology, and Logic of Electrical Networks](https://arxiv.org/abs/2510.21911)
*Marko Orešković,Ivana Kuzmanović Ivičić,Juraj Benić,Mario Essert*

Main category: eess.SY

TL;DR: 基于Šare的m理论，提出了一个统一的代数、拓扑和逻辑框架来表示电气单端口网络，将网络表示为有序字母表上的m-词，通过系列和并行组合在m-图上诱导m-拓扑，并开发了算法程序用于生成和分类非同构的串并联拓扑。


<details>
  <summary>Details</summary>
Motivation: 为电气单端口网络建立一个自洽的理论和计算基础，实现自动网络合成、分类和形式验证，在代数表示和电气实现之间建立建设性桥梁。

Method: 使用m-词表示网络，通过系列和并行组合在m-图上诱导m-拓扑，引入theta映射保持单端口等价性，并扩展算法程序用于生成和分类非同构的串并联拓扑。

Result: 开发了程序化的Cauer/Foster合成工作流程，并针对Ladenheim目录中的规范示例进行了验证，实现了阻抗函数的符号到拓扑转换。

Conclusion: 该框架为新兴的Jorbology领域提供了一个自洽的理论和计算基础，支持自动网络合成、分类和形式验证。

Abstract: This paper presents a unified algebraic, topological, and logical framework
for electrical one-port networks based on \v{S}are's $m$-theory. Within this
formalism, networks are represented by $m$-words (jorbs) over an ordered
alphabet, where series and parallel composition induce an $m$-topology on
$m$-graphs with a theta mapping $\vartheta$ that preserves one-port
equivalence. The study formalizes quasi-orders, shells, and cores, showing
their structural correspondence to network boundary conditions and impedance
behavior. The $\lambda--\Delta$ metric, together with the valuation morphism
$\Phi$, provides a concise descriptor of the impedance-degree structure. In the
computational domain, the framework is extended with algorithmic procedures for
generating and classifying non-isomorphic series-parallel topologies,
accompanied by programmatic Cauer/Foster synthesis workflows and validation
against canonical examples from Ladenheim's catalogue. The resulting approach
enables symbolic-to-topological translation of impedance functions, offering a
constructive bridge between algebraic representation and electrical
realization. Overall, the paper outlines a self-consistent theoretical and
computational foundation for automated network synthesis, classification, and
formal verification within the emerging field of Jorbology.

</details>


### [16] [Pricing Problems in Adoption of New Technologies](https://arxiv.org/abs/2510.21951)
*Yijin Wang,Subhonmesh Bose*

Main category: eess.SY

TL;DR: 提出了一种包含价格因素的Bass扩散模型离散时间推广，用于研究垄断者的最优定价策略和政策制定者与垄断者之间的Stackelberg博弈问题。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型未能充分体现价格对产品采用的影响，需要开发能够准确拟合实际采用数据并支持决策分析的价格整合模型。

Method: 扩展Bass扩散模型以显式建模价格效应，然后应用该模型分析两个决策问题：垄断者的多期最优定价策略，以及政策制定者与垄断者之间的Stackelberg博弈。

Result: 完全刻画了单期问题的最优定价策略，建立了多期问题的结构性质；在博弈问题中，分析了单期均衡路径的关键性质并扩展到多期情形。

Conclusion: 所提出的价格整合扩散模型能够有效支持定价和补贴政策决策，为产品采用动态分析提供了更准确的建模框架。

Abstract: We propose a generalization of the Bass diffusion model in discrete-time that
explicitly models the effect of price in adoption. Our model is different from
earlier price-incorporated models and fits well to adoption data for various
products. We then utilize this model to study two decision-making problems.
First, we provide a series of structural results on optimal pricing strategies
to maximize profits from product sales by a monopolist over a finite horizon.
We fully characterize the optimal pricing strategy in the single-period
problem, and establish several structural properties of the same for the
multi-period counterpart. Second, we study a Stackelberg game between a
policy-maker and a monopolist, where the former seeks to maximize adoption
through rebates, while the latter focuses on profits. For this problem, we
analytically characterize crucial properties of the equilibrium path of the
single-period game, and demonstrate how they carry over to the multi-period
variant.

</details>


### [17] [Motion Planning with Precedence Specifications via Augmented Graphs of Convex Sets](https://arxiv.org/abs/2510.22015)
*Shilin You,Gael Luna,Juned Shaikh,David Gostin,Yu Xiang,Justin Koeln,Tyler Summers*

Main category: eess.SY

TL;DR: 提出了一种用于规划避障轨迹的算法，该算法满足信号时序逻辑片段表达的关键-门优先级规范，通过构建增强凸集图来精确编码关键-门优先级约束。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理关键-门优先级约束时效率较低，需要开发更高效的轨迹规划算法来满足复杂时序逻辑规范。

Method: 采用新颖的精确凸分区方法对无障碍空间进行划分，构建增强凸集图来编码连通性和关键-门优先级约束，通过求解最短路径问题获得轨迹。

Result: 实验表明，该方法比现有通用时序逻辑工具快几个数量级，能够有效处理具有挑战性的关键-门迷宫问题实例。

Conclusion: 提出的管道为满足关键-门优先级规范的轨迹规划提供了精确且高效的解决方案，显著优于现有最先进方法。

Abstract: We present an algorithm for planning trajectories that avoid obstacles and
satisfy key-door precedence specifications expressed with a fragment of signal
temporal logic. Our method includes a novel exact convex partitioning of the
obstacle free space that encodes connectivity among convex free space sets, key
sets, and door sets. We then construct an augmented graph of convex sets that
exactly encodes the key-door precedence specifications. By solving a shortest
path problem in this augmented graph of convex sets, our pipeline provides an
exact solution up to a finite parameterization of the trajectory. To illustrate
the effectiveness of our approach, we present a method to generate key-door
mazes that provide challenging problem instances, and we perform numerical
experiments to evaluate the proposed pipeline. Our pipeline is faster by
several orders of magnitude than recent state-of-the art methods that use
general purpose temporal logic tools.

</details>


### [18] [A Hybrid GNN-LSE Method for Fast, Robust, and Physically-Consistent AC Power Flow](https://arxiv.org/abs/2510.22020)
*Mohamed Shamseldein*

Main category: eess.SY

TL;DR: 提出了一种结合物理信息图神经网络和线性状态估计的两阶段混合方法，用于快速求解交流潮流问题，相比传统牛顿-拉夫逊法速度提升高达8400倍。


<details>
  <summary>Details</summary>
Motivation: 传统交流潮流求解器在大型电力系统中面临计算复杂和收敛困难的问题，需要开发更高效、可靠的求解方法。

Method: 使用物理信息图神经网络快速预测初始系统状态，然后通过迭代线性状态估计精炼步骤来强制执行物理定律，绕过传统求解器的非线性问题。

Result: 在IEEE 33、69、118总线系统上验证，GNN变体比牛顿-拉夫逊法快8400倍，重载应力测试和N-1事故验证了方法的可靠性和泛化能力。

Conclusion: 该框架成功地将快速数据驱动模型与电力系统物理约束相结合，为实时操作和分析提供了实用工具。

Abstract: Conventional AC Power Flow (ACPF) solvers like Newton-Raphson (NR) face
significant computational and convergence challenges in modern, large-scale
power systems. This paper proposes a novel, two-stage hybrid method that
integrates a Physics-Informed Graph Neural Network (GNN) with a robust,
iterative Linear State Estimation (LSE) refinement step to produce fast and
physically-consistent solutions. The GNN, trained with a physics-informed loss
function featuring an efficient dynamic weighting scheme, rapidly predicts a
high-quality initial system state. This prediction is then refined using an
iterative, direct linear solver inspired by state estimation techniques. This
LSE refinement step solves a series of linear equations to enforce physical
laws, effectively bypassing the non-linearities and convergence issues of
traditional solvers. The proposed GNN-LSE framework is comprehensively
validated on systems ranging from small radial distribution networks (IEEE
33-bus, 69-bus) to a large, meshed transmission system (IEEE 118-bus). Results
show that our GNN variants are up to $8.4 \times 10^3$ times faster than NR.
The LSE refinement provides a fast route to a physically-consistent solution,
while heavy-loading stress tests (120%-150% of nominal) and N-1 contingencies
demonstrate the method's reliability and generalization. This work presents a
powerful and flexible framework for bridging fast, data-driven models with the
rigorous constraints of power system physics, offering a practical tool for
real-time operations and analysis.

</details>


### [19] [IoT-Driven Smart Management in Broiler Farming: Simulation of Remote Sensing and Control Systems](https://arxiv.org/abs/2510.23356)
*Sandra Coello Suarez,V. Sanchez Padilla,Ronald Ponguillo-Intriago,Albert Espinal*

Main category: eess.SY

TL;DR: 提出基于物联网的肉鸡管理自动化系统，通过传感器网络和嵌入式系统监控温度与喂食，使用仪表板和云数据库跟踪管理改进


<details>
  <summary>Details</summary>
Motivation: 参数监控系统对工业自动化至关重要，能提高生产力和资源优化，同时管理环境因素和复杂输入输出交互

Method: 基于模拟场景构建物联网传输网络，结合传感器网络、嵌入式系统、仪表板和云数据库服务

Result: 开发了肉鸡温度与喂食监控控制系统，为利益相关者提供可持续的自动化解决方案

Conclusion: 该工作可作为动物生产行业指南，通过简单经济的自动化方案促进可持续发展，帮助现有运营实现更高效决策

Abstract: Parameter monitoring and control systems are crucial in the industry as they
enable automation processes that improve productivity and resource
optimization. These improvements also help to manage environmental factors and
the complex interactions between multiple inputs and outputs required for
production management. This paper proposes an automation system for broiler
management based on a simulation scenario that involves sensor networks and
embedded systems. The aim is to create a transmission network for monitoring
and controlling broiler temperature and feeding using the Internet of Things
(IoT), complemented by a dashboard and a cloud-based service database to track
improvements in broiler management. We look forward this work will serve as a
guide for stakeholders and entrepreneurs in the animal production industry,
fostering sustainable development through simple and cost-effective automation
solutions. The goal is for them to scale and integrate these recommendations
into their existing operations, leading to more efficient decision-making at
the management level.

</details>


### [20] [High-Performance Rotor Cooling with Ducted Liquid in Completely Cold-Formed Modular Motor Shaft](https://arxiv.org/abs/2510.22029)
*Rezvan Alamian,Sören Müller,Uwe Steinmetz,Christian Henrich,Stefan Goetz*

Main category: eess.SY

TL;DR: 提出一种新型转子冷却轴概念，通过齿形引导液体冷却设计提高冷却效率，同时保持制造简单和成本效益。


<details>
  <summary>Details</summary>
Motivation: 解决传统冷却转子轴因内部涡流形成导致的高搅动损失和有限传热问题，提高电动汽车电机的性能和耐久性。

Method: 研究四种轴几何形状的热性能，采用冷成型内部通道优化传热效率和压力管理，限制涡流形成。通过计算流体分析评估关键性能指标。

Result: 齿形引导设计在低转速下比传统空心轴的冷却效率提高110%，同时保持相当的压力水平。

Conclusion: 该研究为几何驱动的热优化提供了实用见解，为提高电机性能和耐久性提供了路径。

Abstract: This paper suggests a novel rotor-cooling shaft concept for high-performance
electric motors that increases the effectiveness of cooling and is yet simple
and cost-effective to manufacture. We investigate the thermal performance of
four shaft geometries for rotor cooling in automotive applications. The
proposed tooth-guided liquid-cooling shaft design aims to solve the high
churning loss of conventional cooled rotor shafts due to internal vortex
formation and their still limited heat transfer. Therefore, we optimize heat
transfer efficiency and pressure management by incorporating cold-formed
internal channels that restrict vortex formation beyond a degree that improves
heat transfer. We evaluated key performance metrics, including heat transfer
rate, outlet temperature, pressure drop, and velocity profiles, under varying
rotational speeds, inlet flow rates, and coolant temperatures. Computational
fluid analysis demonstrates that the tooth-guided design outperforms
conventional hollow shafts and achieves up to 110% higher cooling efficiency at
low rotational speeds, while it maintains comparable pressure levels. These
findings provide practical insight into geometry-driven thermal optimization
and offer a path toward improving the performance and durability of electric
motors.

</details>


### [21] [TRASE-NODEs: Trajectory Sensitivity-aware Neural Ordinary Differential Equations for Efficient Dynamic Modeling](https://arxiv.org/abs/2510.22104)
*Fatima Al-Janahi,Min-Seung Ko,Hao Zhu*

Main category: eess.SY

TL;DR: 提出了TRASE-NODEs方法，通过构建状态和敏感度的增广系统，同时学习两者的动力学，在有限训练数据下比标准NODEs具有更好的泛化能力和更低的预测误差。


<details>
  <summary>Details</summary>
Motivation: 标准神经常微分方程需要大量数据样本才能在不同控制输入下保持一致性，这给生成足够模拟数据和确保控制设计安全性带来了挑战。

Method: 构建状态和敏感度的增广系统，使用伴随方法以内存高效的方式更新梯度，确保控制输入效应被捕获在学习到的动力学中。

Result: 在阻尼振荡器和基于逆变器的资源系统上的评估显示，TRASE-NODEs在有限训练数据下比标准NODEs具有更好的泛化能力，预测误差更低。

Conclusion: 该框架提供了一种数据高效、面向控制的建模方法，适用于需要准确轨迹敏感度预测的动态系统。

Abstract: Modeling dynamical systems is crucial across the science and engineering
fields for accurate prediction, control, and decision-making. Recently, machine
learning (ML) approaches, particularly neural ordinary differential equations
(NODEs), have emerged as a powerful tool for data-driven modeling of
continuous-time dynamics. Nevertheless, standard NODEs require a large number
of data samples to remain consistent under varying control inputs, posing
challenges to generate sufficient simulated data and ensure the safety of
control design. To address this gap, we propose trajectory-sensitivity-aware
(TRASE-)NODEs, which construct an augmented system for both state and
sensitivity, enabling simultaneous learning of their dynamics. This formulation
allows the adjoint method to update gradients in a memory-efficient manner and
ensures that control-input effects are captured in the learned dynamics. We
evaluate TRASE-NODEs using damped oscillator and inverter-based resources
(IBRs). The results show that TRASE-NODEs generalize better from the limited
training data, yielding lower prediction errors than standard NODEs for both
examples. The proposed framework offers a data-efficient, control-oriented
modeling approach suitable for dynamic systems that require accurate trajectory
sensitivity prediction.

</details>


### [22] [Fair Cost Allocation in Energy Communities: A DLMP-based Bilevel Optimization with a Shapley Value Approach](https://arxiv.org/abs/2510.22321)
*Hyeongon Park,Kyuhyeong Kwag,Daniel K. Molzahn,Rahul K. Gupta*

Main category: eess.SY

TL;DR: 提出了一种双层优化模型，通过Shapley值实现能源社区间运营成本的公平分配，考虑了分布位置边际价格的影响。


<details>
  <summary>Details</summary>
Motivation: 随着能源社区规模扩大和与电网集成度提高，在参与者间公平分配运营成本成为挑战。现有方法大多未考虑分布位置边际价格的影响。

Method: 建立双层优化模型：上层由社区能源聚合器调度分布式能源资源，下层由配电系统运营商通过网络约束调度确定分布位置边际价格。利用KKT条件和强对偶性将双层问题转化为单层可处理问题，并应用Shapley值量化各社区对系统成本节约的边际贡献。

Result: 在多个基准配电系统上的仿真验证了所提方法的有效性。

Conclusion: 该方法能够公平透明地分配能源社区间的运营成本，同时考虑了分布位置边际价格的影响。

Abstract: Energy communities (ECs) are emerging as a promising decentralized model for
managing cooperative distributed energy resources (DERs). As these communities
expand and their operations become increasingly integrated into the grid,
ensuring fairness in allocating operating costs among participants becomes a
challenge. In distribution networks, DER operations at the community level can
influence Distribution Locational Marginal Prices (DLMPs), which in turn affect
system's operation cost. This interdependence between local decisions and
system-level pricing introduces new challenges for fair and transparent cost
allocation. Despite growing interest in fairness-aware methods, most methods do
not account for the impact of DLMPs. To fill this gap, we propose a bilevel
optimization model in which a Community Energy Aggregator (CEA) schedules DERs
across multiple ECs while a Distribution System Operator (DSO) determines DLMPs
through network-constrained dispatch. Leveraging the Karush-Kuhn-Tucker (KKT)
conditions and strong duality, the bilevel model is reformulated into a
tractable single-level problem. We achieve fairness in the cost allocation by
applying the Shapley value to quantify each community's marginal contribution
to system-wide cost savings. The effectiveness of the proposed method is
validated through simulations on several benchmark distribution systems.

</details>


### [23] [Model-Free Power System Stability Enhancement with Dissipativity-Based Neural Control](https://arxiv.org/abs/2510.22324)
*Yifei Wang,Han Wang,Kehao Zhuang,Keith Moffat,Florian Dörfler*

Main category: eess.SY

TL;DR: 提出一种基于耗散性的无模型非线性控制器，用于增强虚拟同步发电机(VSG)的电力系统暂态稳定性，通过神经网络学习耗散性特征矩阵来获得稳定控制器。


<details>
  <summary>Details</summary>
Motivation: 变流器接口发电的集成给现代电力系统带来新的暂态稳定挑战，传统方法依赖限制性假设且难以找到大电网的存储函数，大多数方法需要精确的电网动态模型。

Method: 使用输入状态数据训练神经网络学习耗散性特征矩阵，结合成本函数整形改进用户指定目标的性能，提出基于耗散性的无模型非线性控制器。

Result: 在改进的全VSG Kundur两区域电力系统上的数值结果验证了所提方法的有效性。

Conclusion: 该方法能够增强电力系统暂态稳定性，解决了传统方法依赖精确模型和限制性假设的问题。

Abstract: The integration of converter-interfaced generation introduces new transient
stability challenges to modern power systems. Classical Lyapunov- and scalable
passivity-based approaches typically rely on restrictive assumptions, and
finding storage functions for large grids is generally considered intractable.
Furthermore, most methods require an accurate grid dynamics model. To address
these challenges, we propose a model-free, nonlinear, and dissipativity-based
controller which, when applied to grid-connected virtual synchronous generators
(VSGs), enhances power system transient stability. Using input-state data, we
train neural networks to learn dissipativity-characterizing matrices that yield
stabilizing controllers. Furthermore, we incorporate cost function shaping to
improve the performance with respect to the user-specified objectives.
Numerical results on a modified, all-VSG Kundur two-area power system validate
the effectiveness of the proposed approach.

</details>


### [24] [Vector-Valued Native Space Embedding for Adaptive State Observation](https://arxiv.org/abs/2510.22374)
*Shengyuan Niu,Haoran Wang,Heejip Moon,Andrea L'Afflitto,Andrew Kurdila,Daniel Stilwell*

Main category: eess.SY

TL;DR: 提出了一种结合向量值再生核希尔伯特空间嵌入与鲁棒自适应观测的算法，能够估计具有无限维原生空间中匹配不确定性和不匹配不确定性的平面模型状态，并提供了状态观测误差的上界分析。


<details>
  <summary>Details</summary>
Motivation: 为了解决平面模型中存在的匹配不确定性（属于无限维原生空间）、不匹配不确定性以及测量输出受干扰的问题，需要开发一种既非参数化又具有鲁棒性的状态估计算法。

Method: 将向量值再生核希尔伯特空间嵌入与鲁棒自适应观测相结合，构建非参数化鲁棒算法，能够处理无限维原生空间中的匹配不确定性和系统的不匹配不确定性。

Result: 算法能够有效估计刚性体等系统的状态，并提供了状态观测误差的解析形式上界，验证了理论结果在实际应用中的有效性。

Conclusion: 所提出的方法成功解决了具有复杂不确定性结构的系统状态估计问题，为非参数化鲁棒观测器设计提供了新的理论框架和实用工具。

Abstract: This paper combines vector-valued reproducing kernel Hilbert space (vRKHS)
embedding with robust adaptive observation, yielding an algorithm that is both
non-parametric and robust. The main contribution of this paper lies in the
ability of the proposed system to estimate the state of a plan model whose
matched uncertainties are elements of an infinite-dimensional native space. The
plant model considered in this paper also suffers from unmatched uncertainties.
Finally, the measured output is affected by disturbances as well. Upper bounds
on the state observation error are provided in an analytical form. The proposed
theoretical results are applied to the problem of estimating the state of a
rigid body.

</details>


### [25] [Resilient Composite Control for Stability Enhancement in EV Integrated DC Microgrids](https://arxiv.org/abs/2510.22429)
*Md Saiful Islam,Rahul Bhadani*

Main category: eess.SY

TL;DR: 提出了一种复合控制器，结合全局积分终端滑模控制和反步控制，用于解决电动汽车接入独立直流微电网时的稳定性问题，通过虚拟电容改善低惯量问题，采用改进的分数幂趋近律减少抖振。


<details>
  <summary>Details</summary>
Motivation: 电动汽车接入独立直流微电网时，其恒功率负载特性会产生负增量阻抗，同时微电网存在固有的低惯量问题，导致系统稳定性挑战。

Method: 采用复合控制器（全局积分终端滑模+反步控制），使用虚拟电容增强直流母线响应，改进分数幂趋近律减少抖振，通过精确反馈线性化将非线性升压变换器模型转换为Brunovsky规范形式。

Result: 仿真结果显示，与现有控制器相比，超调量减少34.4-53.3%，欠调量减少52.9-74.9%，调节时间减少12-47.4%。

Conclusion: 所提出的复合控制器能有效解决电动汽车接入直流微电网时的稳定性问题，显著改善系统动态性能，并通过Lyapunov控制理论验证了系统稳定性。

Abstract: When electric vehicles (EVs) are integrated into standalone DC microgrids
(DCMGs), stability issues arise due to their constant power load (CPL)
behavior, which provides negative incremental impedance (NII). In addition, the
microgrids suffer from an inherent low-inertia problem. Therefore, this study
presents a composite controller incorporating a global integral terminal
sliding mode controller with a backstepping controller. A virtual capacitor is
employed to mitigate the low-inertia issue and strengthen the DC-bus response.
An improved fractional power-based reaching law decreases chattering and
accelerates convergence. Exact feedback linearization converts the nonlinear
boost converter model into Brunovsky's canonical form, mitigating NII effects
and non-minimum phase issues. The entire system stability is verified using
Lyapunov control theory. Simulation outcomes confirm superior performance, with
34.4-53.3% reduction in overshoot, 52.9-74.9% in undershoot, and 12-47.4% in
settling time compared to the existing controller.

</details>


### [26] [A Scenario-based Stochastic Model of using BESS-based Virtual Transmission Lines in Day-Ahead Unit Commitment](https://arxiv.org/abs/2510.22483)
*Qiushi Wang,Xingpeng Li*

Main category: eess.SY

TL;DR: 虚拟输电线路(VTL)作为物理输电线路的替代方案，在考虑可再生能源不确定性的情况下，能够有效缓解电网拥堵、降低运营成本和减少可再生能源弃电。


<details>
  <summary>Details</summary>
Motivation: 可再生能源在电力系统中的快速部署导致更严重的网络拥堵问题，这会降低电网运行效率并造成可再生能源弃电。需要寻找快速解决方案来缓解拥堵。

Method: 提出基于场景的随机安全约束机组组合模型(SSCUC-VTL)，将可再生能源预测误差纳入考虑VTL的机组决策中，并与新建物理输电线路和独立电池储能系统进行比较。

Result: 在增强的IEEE 24节点测试系统上的仿真结果表明，VTL比物理输电线路多减少23%的运营成本，比独立电池储能系统多提供67%的拥堵缓解。

Conclusion: 虚拟输电线路在考虑可再生能源不确定性的电力系统中，相比传统物理输电线路和独立储能系统，能够更有效地缓解拥堵并降低运营成本。

Abstract: The rapid increase in renewable energy sources (RES) implementation in the
power system creates more severe network congestion, which may reduce grid
operation efficiency and cause renewable curtailment. Deterministic
optimization for the unit commitment shows that battery energy storage system
(BESS)-based Virtual Transmission Line (VTL), as an alternative to physical
transmission lines, can offer a quick solution for congestion relief, reduced
operational costs, and lowered renewable curtailment. This paper aims to
evaluate the benefits of VTL when considering Renewable Energy Sources
uncertainty. Particularly, this work proposes a scenario-based stochastic
security-constrained unit commitment model considering VTL, referred to as
SSCUC-VTL. It incorporates the forecast error of RES into the commitment
decision for systems with VTL. The performance of applying the VTL strategy is
compared to that of adding a new physical transmission line and a standalone
BESS. A case study has been conducted on an enhanced IEEE 24-bus test system.
The simulation results demonstrate that VTL provides 23% more operational cost
reduction than the physical transmission line, and up to 67% more congestion
relief than the standalone BESS in a power system with solar and wind
generation.

</details>


### [27] [Functional Uncertainty Classes, Nonparametric Adaptive Contro Functional Uncertainty Classes for Nonparametric Adaptive Control: the Curse of Dimensionality](https://arxiv.org/abs/2510.22496)
*Haoran Wang,Shengyuan Niu,Henry Moon,Ian Willebeek-LeMair,Andrew J. Kurdila,Andrea L'Afflitto,Daniel Stilwell*

Main category: eess.SY

TL;DR: 本文提出了一种新的向量值再生核希尔伯特空间(vRKHS)，用于表示非参数自适应控制中的函数不确定性，以解决维度灾难问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决某些非参数自适应控制策略中可能出现的维度灾难问题，需要构建能够有效表示函数不确定性的数学框架。

Method: 基于紧致、l维、光滑黎曼流形M的结构，推导出算子值核定义的轨迹vRKHS KM，其中M被假设为近似支撑参考系统的最终动力学。

Result: 成功推导出一类新的向量值再生核希尔伯特空间，称为机动或轨迹vRKHS KM。

Conclusion: 该方法为处理非参数自适应控制中的函数不确定性提供了一种有效的数学工具，有助于缓解维度灾难问题。

Abstract: This paper derives a new class of vector-valued reproducing kernel Hilbert
spaces (vRKHS) defined in terms of operator-valued kernels for the
representation of functional uncertainty arising in nonparametric adaptive
control methods. These are referred to as maneuver or trajectory vRKHS KM in
the paper, and they are introduced to address the curse of dimensionality that
can arise for some types of nonparametric adaptive control strategies. The
maneuver vRKHSs are derived based on the structure of a compact, l-dimensional,
smooth Riemannian manifold M that is regularly embedded in the state space X =
Rn, where M is assumed to approximately support the ultimate dynamics of the
reference system to be tracked.

</details>


### [28] [Robust Multi-Agent Safety via Tube-Based Tightened Exponential Barrier Functions](https://arxiv.org/abs/2510.22514)
*Armel Koulong,Ali Pakniyat*

Main category: eess.SY

TL;DR: 提出了一种为受有界干扰的非线性多智能体系统合成可证明安全控制器的构造性框架，通过约束紧缩方法将鲁棒误差反馈与名义轨迹规划正式耦合。


<details>
  <summary>Details</summary>
Motivation: 针对受有界干扰的非线性多智能体系统，需要开发能够提供可证明安全保证的控制合成方法，特别是在高维空间中处理任意阶动力学系统。

Method: 采用约束紧缩方法，利用鲁棒正不变(RPI)管的几何特性通过支撑函数导出状态相关安全裕度，系统性地紧缩施加在名义规划器上的高相对阶指数控制屏障函数(eCBF)约束。

Result: 开发了集成合成方法，保证任何满足紧缩约束的名义轨迹对应于真实受干扰系统的可证明安全轨迹，并在分布式模型预测控制(MPC)方案中实现了该规划器。

Conclusion: 该方法为非线性多智能体系统提供了形式化的安全控制器合成框架，通过将鲁棒误差反馈与名义轨迹规划相结合，在优化性能的同时继承鲁棒安全保证。

Abstract: This paper presents a constructive framework for synthesizing provably safe
controllers for nonlinear multi-agent systems subject to bounded disturbances.
The methodology applies to systems representable in Brunovsky canonical form,
accommodating arbitrary-order dynamics in multi-dimensional spaces. The central
contribution is a method of constraint tightening that formally couples robust
error feedback with nominal trajectory planning. The key insight is that the
design of an ancillary feedback law, which confines state errors to a robust
positively invariant (RPI) tube, simultaneously provides the exact information
needed to ensure the safety of the nominal plan. Specifically, the geometry of
the resulting RPI tube is leveraged via its support function to derive
state-dependent safety margins. These margins are then used to systematically
tighten the high relative-degree exponential control barrier function (eCBF)
constraints imposed on the nominal planner. This integrated synthesis
guarantees that any nominal trajectory satisfying the tightened constraints
corresponds to a provably safe trajectory for the true, disturbed system. We
demonstrate the practical utility of this formal synthesis method by
implementing the planner within a distributed Model Predictive Control (MPC)
scheme, which optimizes performance while inheriting the robust safety
guarantees.

</details>


### [29] [Approximate Gradient Coding for Distributed Learning with Heterogeneous Stragglers](https://arxiv.org/abs/2510.22539)
*Heekang Song,Wan Choi*

Main category: eess.SY

TL;DR: 提出了一种最优结构的梯度编码方案来解决分布式学习中的慢节点问题，通过考虑个体慢节点概率来最小化残差误差并确保无偏梯度估计。


<details>
  <summary>Details</summary>
Motivation: 传统梯度编码方法通常假设同质慢节点模型或依赖过度数据复制，在现实异构系统中性能受限。

Method: 通过拉格朗日对偶和凸优化推导出最优编码和解码系数的闭式解，并提出减少冗余和计算负载的数据分配策略。

Result: 数值结果表明，该方法显著减少了慢节点的影响，并相比现有方法加速了收敛。

Conclusion: 所提出的梯度编码方案在异构分布式学习环境中有效缓解了慢节点问题，提高了系统性能。

Abstract: In this paper, we propose an optimally structured gradient coding scheme to
mitigate the straggler problem in distributed learning. Conventional gradient
coding methods often assume homogeneous straggler models or rely on excessive
data replication, limiting performance in real-world heterogeneous systems. To
address these limitations, we formulate an optimization problem minimizing
residual error while ensuring unbiased gradient estimation by explicitly
considering individual straggler probabilities. We derive closed-form solutions
for optimal encoding and decoding coefficients via Lagrangian duality and
convex optimization, and propose data allocation strategies that reduce both
redundancy and computation load. We also analyze convergence behavior for
$\lambda$-strongly convex and $\mu$-smooth loss functions. Numerical results
show that our approach significantly reduces the impact of stragglers and
accelerates convergence compared to existing methods.

</details>


### [30] [Ellipsoidal Set-Theoretic Design of Robust Safety Filters for Constrained Linear Systems](https://arxiv.org/abs/2510.22790)
*Reza Pordal,Alireza Sharifi,Ali Baniasad*

Main category: eess.SY

TL;DR: 提出了一种基于椭球集理论的鲁棒安全滤波器合成框架，用于处理受加性有界扰动和输入约束的线性系统，通过凸LMI优化同时计算鲁棒控制不变集及其状态反馈控制律。


<details>
  <summary>Details</summary>
Motivation: 为高维约束线性系统提供计算上可处理且具有形式化安全保证的安全滤波器设计方法，解决在外部扰动和输入约束下的安全控制问题。

Method: 将安全滤波器设计表述为凸LMI优化问题，同时计算鲁棒控制不变椭球集及其状态反馈控制律，采用基于到不变集边界距离的平滑混合策略，并扩展到非线性系统。

Result: 在六自由度四旋翼系统上的数值验证表明，该滤波器在外部扰动和剧烈机动下能有效保持稳定性，在安全操作期间保持标称性能。

Conclusion: 该方法为需要实时实现的安全关键控制应用提供了构造性和计算高效的解决方案。

Abstract: This paper presents an ellipsoidal set-theoretic framework for robust safety
filter synthesis in constrained linear systems subject to additive bounded
disturbances and input constraints. We formulate the safety filter design as a
convex linear matrix inequality (LMI) optimization problem that simultaneously
computes a robust controlled invariant (RCI) ellipsoidal set and its associated
state-feedback control law. The RCI set is characterized as an ellipsoidal set,
enabling computational tractability for high-dimensional systems while
providing formal safety guarantees. The safety filter employs a smooth mixing
strategy between nominal and backup controllers based on distance to the
invariant set boundary, facilitating minimal intervention when the system
operates safely. The proposed method extends to nonlinear systems by treating
nonlinear terms as bounded disturbances with rigorous approximation bounds.
Numerical validation on a six-degree-of-freedom quadrotor system demonstrates
the filter's effectiveness in maintaining stability under external disturbances
and aggressive maneuvers while preserving nominal performance during safe
operation. The approach provides a constructive and computationally efficient
solution for safety-critical control applications requiring real-time
implementation.

</details>


### [31] [Residual Bias Compensation Filter for Physics-Based SOC Estimation in Lithium Iron Phosphate Batteries](https://arxiv.org/abs/2510.22813)
*Feng Guo,Luis D. Couto,Khiem Trad,Guangdi Hu,Mohammadhosein Safari*

Main category: eess.SY

TL;DR: 提出了一种残差偏置补偿双扩展卡尔曼滤波器（RBC-DEKF），用于解决磷酸铁锂电池SOC估计中OCV-SOC特性平坦导致的观测性问题，通过双滤波器结构分离残差偏置估计和电化学状态估计，显著提高了估计精度。


<details>
  <summary>Details</summary>
Motivation: 磷酸铁锂电池的开路电压-荷电状态特性相对平坦，降低了系统的可观测性，这使得传统的SOC估计方法在LFP电池上精度不足。

Method: 开发了残差偏置补偿双扩展卡尔曼滤波器，采用双滤波器结构：一个EKF估计控制导向的参数分组单粒子模型（含热效应）的系统状态，另一个EKF估计残差偏置，实时修正电压观测方程。

Result: 在三种代表性工况下验证，与传统EKF相比，平均SOC均方根误差从3.75%降至0.20%，电压均方根误差从32.8mV降至0.8mV，在OCV-SOC曲线平坦的中SOC区间改进最为明显。

Conclusion: 残差偏置补偿显著提高了基于模型的LFP电池SOC估计精度，特别是在宽温度范围内，验证了该方法对解决LFP电池观测性问题的有效性。

Abstract: This paper addresses state of charge (SOC) estimation for lithium iron
phosphate (LFP) batteries, where the relatively flat open-circuit voltage
(OCV-SOC) characteristic reduces observability. A residual bias compensation
dual extended Kalman filter (RBC-DEKF) is developed. Unlike conventional bias
compensation methods that treat the bias as an augmented state within a single
filter, the proposed dual-filter structure decouples residual bias estimation
from electrochemical state estimation. One EKF estimates the system states of a
control-oriented parameter-grouped single particle model with thermal effects,
while the other EKF estimates a residual bias that continuously corrects the
voltage observation equation, thereby refining the model-predicted voltage in
real time. Unlike bias-augmented single-filter schemes that enlarge the
covariance coupling, the decoupled bias estimator refines the voltage
observation without perturbing electrochemical state dynamics. Validation is
conducted on an LFP cell from a public dataset under three representative
operating conditions: US06 at 0 degC, DST at 25 degC, and FUDS at 50 degC.
Compared with a conventional EKF using the same model and identical state
filter settings, the proposed method reduces the average SOC RMSE from 3.75% to
0.20% and the voltage RMSE between the filtered model voltage and the measured
voltage from 32.8 mV to 0.8 mV. The improvement is most evident in the mid-SOC
range where the OCV-SOC curve is flat, confirming that residual bias
compensation significantly enhances accuracy for model-based SOC estimation of
LFP batteries across a wide temperature range.

</details>


### [32] [Transmission Neural Networks: Approximate Receding Horizon Control for Virus Spread on Networks](https://arxiv.org/abs/2510.22871)
*Shuang Gao,Peter E. Caines*

Main category: eess.SY

TL;DR: TransNNs作为病毒传播模型和神经网络模型，为马尔可夫SIS模型提供感染概率上界，并提出基于TransNN的滚动时域控制方法，相比动态规划显著节省计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统马尔可夫SIS模型具有2^n状态配置，计算复杂度高，需要更高效的病毒传播控制方法。

Method: 使用TransNNs作为马尔可夫SIS模型的近似模型，提出基于TransNN的滚动时域控制方法。

Result: TransNN滚动时域控制相比动态规划显著节省计算成本，且比TransNN最优控制提供更不保守的控制动作。

Conclusion: TransNNs可作为马尔可夫SIS模型的有效近似，基于TransNN的滚动时域控制是计算效率高且实用的病毒传播控制方法。

Abstract: Transmission Neural Networks (TransNNs) proposed by Gao and Caines (2022)
serve as both virus spread models over networks and neural network models with
tuneable activation functions. This paper establishes that TransNNs provide
upper bounds on the infection probability generated from the associated
Markovian stochastic Susceptible-Infected-Susceptible (SIS) model with 2^n
state configurations where n is the number of nodes in the network, and can be
employed as an approximate model for the latter. Based on such an
approximation, a TransNN-based receding horizon control approach for mitigating
virus spread is proposed and we demonstrate that it allows significant
computational savings compared to the dynamic programming solution to Markovian
SIS model with 2^n state configurations, as well as providing less conservative
control actions compared to the TransNN-based optimal control. Finally,
numerical comparisons among (a) dynamic programming solutions for the Markovian
SIS model, (b) TransNN-based optimal control and (c) the proposed TransNN-based
receding horizon control are presented.

</details>


### [33] [NeuroDOB: A Deep Neural Observer-Based Controller for Vehicle Lateral Dynamics](https://arxiv.org/abs/2510.23067)
*Sangmin Kim,Taehun Kim,Guntae Kim,Chang Mook Kang*

Main category: eess.SY

TL;DR: 提出NeuroDOB，一种基于深度神经网络的车辆横向动力学观测控制器，用DNN替代传统扰动观测器来实现个性化横向控制，通过从驾驶员在环仿真中学习转向补偿信号来适应未建模车辆动态和驾驶员特定行为。


<details>
  <summary>Details</summary>
Motivation: 传统扰动观测器主要补偿一般扰动如路面摩擦变化和侧风，但无法处理未建模车辆动态和驾驶员特定行为。需要一种能学习个性化驾驶习惯的控制器来提升横向控制性能。

Method: 将NeuroDOB与线性二次调节器(LQR)集成，DNN输出误差修正量加到基线LQR转向输入中。DNN输入特征包括横向位置和偏航角误差，以及LQR控制输入。通过CarSim中的驾驶员在环仿真训练DNN。

Result: 在CarSim中使用横向动态自行车模型进行实验验证，NeuroDOB能有效适应个体驾驶习惯，相比传统LQR控制器显著提升横向控制性能。

Conclusion: 基于深度神经网络的观测器具有实现个性化和自适应自动驾驶控制的潜力。该架构可视为双系统控制结构：LQR作为系统1（模型基础、快速分析层），NeuroDOB作为系统2（反思性、数据驱动层），类似人类直觉-反思交互，实现稳定性和适应性的平衡。

Abstract: This paper proposes NeuroDOB, a deep neural network based observer controller
for vehicle lateral dynamics, which replaces the conventional disturbance
observer (DOB) with a deep neural network (DNN) to enhance personalized lateral
control. Unlike conventional DOBs that compensate for general disturbances such
as road friction variation and crosswind, NeuroDOB explicitly addresses
unmodeled vehicle dynamics and driver-specific behaviors by learning the
steering compensation signal from driver-in-the-loop simulations using CarSim's
embedded controller as a surrogate driver. The proposed architecture integrates
NeuroDOB with a linear quadratic regulator (LQR), where the DNN outputs a delta
error correction added to the baseline LQR steering input to produce the final
control command. Input features to the DNN include lateral position and yaw
angle errors, and the LQR control input. Experimental validation using a
lateral dynamic bicycle model within CarSim demonstrates that NeuroDOB
effectively adapts to individual driving habits, improving lateral control
performance beyond what conventional LQR controllers achieve. The results
indicate the potential of deep neural network based observer to enable
personalized and adaptive autonomous vehicle control. In cognitive terms, the
proposed architecture can be viewed as a dual-system control structure. The
baseline LQR corresponds to System 1, a model-based, fast, and analytic
reasoning layer ensuring stability. The NeuroDOB acts as System 2, a
reflective, data-driven layer that learns compensation from experience and
corrects the analytical bias of System 1. Together, they form an integrated
decision process analogous to human intuition-reflection interaction, enabling
both stability and adaptability in lateral control.

</details>


### [34] [Context-awareness for Dependable Low-Power IoT](https://arxiv.org/abs/2510.23125)
*David E. Ruiz-Guirola,Prasoon Raghuwanshi,Gabriel M. de Jesus,Mateen Ashraf,Onel L. A. López*

Main category: eess.SY

TL;DR: 提出一个包含四个关键上下文维度的两步协议设计框架，通过上下文感知显著提升物联网系统可靠性，同时保持最小控制开销


<details>
  <summary>Details</summary>
Motivation: 在大规模、能源受限的物联网部署中确保可靠运行至关重要但具有挑战性，需要能够感知上下文（情境或状态信息）的协议

Method: 识别四个关键上下文维度（能量状态、信息新鲜度、任务相关性和物理/介质条件），提出包含操作特定上下文字段的两步协议设计框架

Result: 通过三个代表性用例证明上下文感知可以显著增强系统可靠性，同时只施加最小的控制平面开销

Conclusion: 上下文感知是提升物联网网络可靠性的有效方法，所提出的框架能够平衡系统性能和资源约束

Abstract: Dependability is the ability to consistently deliver trusted and
uninterrupted service in the face of operational uncertainties. Ensuring
dependable operation in large-scale, energy-constrained Internet of Things
(IoT) deployments is as crucial as challenging, and calls for context-aware
protocols where context refers to situational or state information. In this
paper, we identify four critical context dimensions for IoT networks, namely
energy status, information freshness, task relevance, and physical/medium
conditions, and show how each one underpins core dependability attributes.
Building on these insights, we propose a two-step protocol design framework
that incorporates operation-specific context fields. Through three
representative use cases, we demonstrate how context awareness can
significantly enhance system dependability while imposing only minimal
control-plane overhead.

</details>


### [35] [Embroidery Actuator Utilizing Embroidery Patterns to Generate Diverse Fabric Deformations](https://arxiv.org/abs/2510.23188)
*Yuki Ota,Yuki Funabora*

Main category: eess.SY

TL;DR: 提出了一种新型刺绣致动器，通过刺绣图案设计实现多样可控的织物变形，将充气管直接缝制在织物上形成约束套筒，将内部压力转化为弯曲或拉伸变形。


<details>
  <summary>Details</summary>
Motivation: 传统织物致动器依赖纤维或线状致动器，限制了变形控制的灵活性。本文旨在通过刺绣图案设计实现更灵活可控的织物变形。

Method: 采用绳绣技术将充气管直接缝制在织物上，形成约束套筒。通过改变刺绣图案（如锯齿形或交叉形）实现不同的几何约束，并基于Neo-Hookean模型和拉格朗日方程建立变形分析模型。

Result: 实验验证表明，致动器的变形行为与分析模型高度一致，能够通过刺绣图案灵活控制变形方向和幅度。

Conclusion: 刺绣致动器提供了一种通过图案设计实现可控织物变形的新方法，为软体机器人、可穿戴设备等领域提供了新的可能性。

Abstract: This paper presents a novel Embroidery Actuator, a fabric-integrated
pneumatic actuator that enables diverse and controllable deformations through
embroidery pattern design. Unlike conventional fabric actuators that rely on
fiber- or thread-shaped actuators, the proposed actuator is fabricated by
directly stitching an inflatable tube onto the fabric using a cord-embroidery
technique. The embroidered thread and the fabric jointly form a sleeve that
constrains the expansion of the inflatable tube, converting internal pressure
into targeted bending or stretching deformations. By varying the embroidery
pattern, such as zigzag or cross configurations, different geometric
constraints can be realized, allowing for flexible control of deformation
direction and magnitude. Analytical deformation models based on the Neo-Hookean
model and Lagrange's equations were developed to predict the relationship
between pneumatic pressure and bending angle, and were experimentally validated
using motion-capture measurements. The results demonstrated that the actuator
achieves strong agreement with the analytical deformation model.

</details>


### [36] [Neural Networks for AC Optimal Power Flow: Improving Worst-Case Guarantees during Training](https://arxiv.org/abs/2510.23196)
*Bastien Giraud,Rahul Nellikath,Johanna Vorwerk,Maad Alowaifeer,Spyros Chatzivasileiadis*

Main category: eess.SY

TL;DR: 提出了一种验证感知的神经网络框架，通过将最坏情况约束违反直接纳入训练，为AC最优潮流问题提供既准确又可证明更安全的代理模型。


<details>
  <summary>Details</summary>
Motivation: AC最优潮流问题在电力系统运行中至关重要，但由于其非凸和非线性特性而难以高效求解。虽然神经网络提供了快速代理，但其黑盒行为引发了约束违反可能危及安全的担忧。

Method: 采用验证感知的神经网络框架，将最坏情况约束违反直接整合到训练过程中，并通过后验验证确保模型安全性。对于不可行运行点，采用恢复和热启动策略增强实用性。

Result: 在57到793总线的系统上进行的实验表明，该方法实现了最坏情况约束违反的大幅减少，首次验证了大规模AC-OPF代理的所有运行约束，展示了可扩展性、速度和可靠性。

Conclusion: 该方法弥合了机器学习加速与AC-OPF解决方案安全实时部署之间的差距，为数据驱动的最优控制铺平了道路。

Abstract: The AC Optimal Power Flow (AC-OPF) problem is central to power system
operation but challenging to solve efficiently due to its nonconvex and
nonlinear nature. Neural networks (NNs) offer fast surrogates, yet their
black-box behavior raises concerns about constraint violations that can
compromise safety. We propose a verification-informed NN framework that
incorporates worst-case constraint violations directly into training, producing
models that are both accurate and provably safer. Through post-hoc
verification, we achieve substantial reductions in worst-case violations and,
for the first time, verify all operational constraints of large-scale AC-OPF
proxies. Practical feasibility is further enhanced via restoration and
warm-start strategies for infeasible operating points. Experiments on systems
ranging from 57 to 793 buses demonstrate scalability, speed, and reliability,
bridging the gap between ML acceleration and safe, real-time deployment of
AC-OPF solutions - and paving the way toward data-driven optimal control.

</details>


### [37] [Inertia Partitioning Modular Control Framework for Reconfigurable Multibody Systems](https://arxiv.org/abs/2510.23226)
*Mohammad Dastranj,Jouni Mattila*

Main category: eess.SY

TL;DR: 提出了一种用于可重构刚性多体系统的模块化控制框架，通过自由度定义模块化，将每个体的惯性属性按其对系统动能的影响进行划分，能够以处理树状结构的方式处理闭环运动链，无需显式计算约束力或基于微分-代数方程的形式化。


<details>
  <summary>Details</summary>
Motivation: 解决具有闭环运动链系统的模块化控制挑战，避免传统方法中复杂的约束力计算和微分-代数方程处理。

Method: 基于自由度的模块化定义，将惯性属性按每个自由度引起的运动在系统动能中的反映进行划分，采用与处理树状结构相同的方式处理闭环链。

Result: 在三自由度串并联机械臂上进行仿真实现，结果显示出预期的稳定性和跟踪性能，表明该框架在多体系统轨迹跟踪控制中具有良好的可扩展性。

Conclusion: 该模块化控制框架能够有效处理闭环运动链系统，避免了复杂的约束计算，在轨迹跟踪控制方面展现出良好的可扩展潜力。

Abstract: A novel modular control framework for reconfigurable rigid multibody systems
is proposed, motivated by the challenges of modular control of systems with
closed kinematic chains. In the framework, modularity is defined in the sense
of degrees of freedom, and the inertial properties of each body are partitioned
with respect to how they are reflected in the kinetic energy of the system
through the motion induced by each degree of freedom. This approach inherently
handles closed chains in the same manner as tree-like structures, eliminating
the need for explicit constraint force calculations or formulations based on
differential-algebraic equations. The proposed framework is implemented via
simulation on a three-degree-of-freedom series-parallel manipulator, with the
results being consistent with the expected stability and tracking performance,
and indicating the framework's potential for scalability in trajectory-tracking
control of multibody systems.

</details>


### [38] [Payload trajectory tracking control for aerial transportation systems with cable length online optimization](https://arxiv.org/abs/2510.23296)
*Hai Yu,Zhichao Yang,Wei He,Jianda Han,Yongchun Fang,Xiao Liang*

Main category: eess.SY

TL;DR: 提出了一种用于可变长度缆绳空中运输系统的反步控制策略，能够精确跟踪有效载荷轨迹并动态调整缆绳长度，同时通过缆绳长度生成器实现在线优化。


<details>
  <summary>Details</summary>
Motivation: 可变长度缆绳系统相比固定长度系统增加了自由度，具有更广泛的应用潜力，但同时也带来了更强的非线性和复杂的动态耦合，给控制设计带来挑战。

Method: 采用反步控制策略设计控制器，并开发缆绳长度生成器进行在线优化，满足状态约束，无需手动轨迹规划。

Result: 仿真结果验证了所提方法在轨迹跟踪和缆绳长度调整方面的有效性。

Conclusion: 通过李雅普诺夫技术和增长限制条件保证了闭环系统的渐近稳定性，该方法能够有效管理轨迹跟踪和缆绳长度调整。

Abstract: Cable-suspended aerial transportation systems are employed extensively across
various industries. The capability to flexibly adjust the relative position
between the multirotor and the payload has spurred growing interest in the
system equipped with variable-length cable, promising broader application
potential. Compared to systems with fixed-length cables, introducing the
variable-length cable adds a new degree of freedom. However, it also results in
increased nonlinearity and more complex dynamic coupling among the multirotor,
the cable and the payload, posing significant challenges in control design.
This paper introduces a backstepping control strategy tailored for aerial
transportation systems with variable-length cable, designed to precisely track
the payload trajectory while dynamically adjusting cable length. Then, a cable
length generator has been developed that achieves online optimization of the
cable length while satisfying state constraints, thus balancing the
multirotor's motion and cable length changes without the need for manual
trajectory planning. The asymptotic stability of the closed-loop system is
guaranteed through Lyapunov techniques and the growth restriction condition.
Finally, simulation results confirm the efficacy of the proposed method in
managing trajectory tracking and cable length adjustments effectively.

</details>


### [39] [An Error-Based Safety Buffer for Safe Adaptive Control (Extended Version)](https://arxiv.org/abs/2510.23491)
*Peter A. Fisher,Johannes Autenrieb,Anuradha M. Annaswamy*

Main category: eess.SY

TL;DR: 提出一种结合自适应控制和控制屏障函数的实时控制架构，用于具有匹配参数不确定性的反馈线性化系统，在保证稳定性和控制性能的同时确保安全性。


<details>
  <summary>Details</summary>
Motivation: 解决具有状态约束和参数不确定性的反馈线性化系统的安全控制问题，这些约束通常源于安全考虑。

Method: 将自适应控制和控制屏障函数结合，控制屏障函数具有任意相对度，无需对指令信号施加激励条件。

Result: 理论证明和仿真结果表明，该方法在保证稳定性的同时，能够以近乎零保守度实现控制目标和安全目标。

Conclusion: 所提出的控制架构能够有效处理参数不确定性，在保证系统安全的同时实现高性能控制，且具有非保守性。

Abstract: We consider the problem of adaptive control of a class of feedback
linearizable plants with matched parametric uncertainties whose states are
accessible, subject to state constraints, which often arise due to safety
considerations. In this paper, we combine adaptation and control barrier
functions into a real-time control architecture that guarantees stability,
ensures control performance, and remains safe even with the parametric
uncertainties. Two problems are considered, differing in the nature of the
parametric uncertainties. In both cases, the control barrier function is
assumed to have an arbitrary relative degree. In addition to guaranteeing
stability, it is proved that both the control objective and safety objective
are met with near-zero conservatism. No excitation conditions are imposed on
the command signal. Simulation results demonstrate the non-conservatism of all
of the theoretical developments.

</details>


### [40] [Towards Stochastic (N-1)-Secure Redispatch](https://arxiv.org/abs/2510.23551)
*Oleksii Molodchyk,Hendrik Drögehorn,Martin Lindner,Mario Kendziorski,Timm Faulwasser*

Main category: eess.SY

TL;DR: 提出了一种基于多项式混沌展开的迭代方法，用于解决考虑不确定性的(N-1)安全约束最优潮流问题


<details>
  <summary>Details</summary>
Motivation: 可再生能源的间歇性给电力系统带来不确定性，传统最优潮流方法需要改进以处理这种不确定性，而现有PCE方法尚未应用于(N-1)安全约束场景

Method: 采用迭代求解PCE过载随机最优潮流问题的方法，逐步包含线路停运约束，直到获得(N-1)安全解

Result: 在118节点测试系统上验证了方法的有效性，并与蒙特卡洛模拟进行了比较

Conclusion: 该方法能够有效处理不确定性下的(N-1)安全约束最优潮流问题

Abstract: The intermittent nature of renewable power availability is one of the major
sources of uncertainty in power systems. While markets can guarantee that the
demand is covered by the available generation, transmission system operators
have to often intervene via economic redispatch to ensure that the physical
constraints of the network are satisfied. To account for uncertainty, the
underlying optimal power flow (OPF) routines have to be modified. Recently,
polynomial chaos expansion (PCE) has been suggested in the literature as a tool
for stochastic OPF problems. However, the usage of PCE-based methods in
security-constrained OPF for (N-1)-secure operations has not yet been explored.
In this paper, we propose a procedure that iteratively solves a PCE-overloaded
stochastic OPF problem by including line outage constraints until an
(N-1)-secure solution is achieved. We demonstrate the efficacy of our method by
comparing it with a Monte-Carlo simulation on a 118-bus example system.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [41] [Distributionally Robust Dynamic Structural Estimation: Serial Dependence and Sensitivity Analysis](https://arxiv.org/abs/2510.22347)
*Ertian Chen*

Main category: econ.EM

TL;DR: 提出了一个量化动态结构模型中参数对分布假设敏感性的框架，通过扰动参考分布来获得参数边界，并在汽车需求和劳动力供给两个应用中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 动态结构模型中序列相关潜变量的分布假设对参数估计至关重要，需要量化这些分布假设对关键参数（如福利、弹性）的影响程度。

Method: 通过扰动参考分布并施加平稳性条件（时间齐次模型）或马尔可夫条件（时间非齐次模型）来推导参数边界，建立了计算可行的对偶公式化方法。

Result: 在汽车需求应用中，扰动价格弹性最多偏离参考弹性15.24%，而电动汽车补贴的消费者剩余估计变化高达102.75%；在劳动力供给应用中，Frisch劳动供给弹性最多偏离76.83%（工作日）和42.84%（周末）。

Conclusion: 该框架能够有效量化动态结构模型参数对分布假设的敏感性，为模型稳健性评估提供了实用工具。

Abstract: Distributional assumptions that discipline serially correlated latent
variables play a central role in dynamic structural models. We propose a
framework to quantify the sensitivity of scalar parameters of interest (e.g.,
welfare, elasticity) to such distributional assumptions. We derive bounds on
the scalar parameter by perturbing a reference distribution, while imposing a
stationarity condition for time-homogeneous models or a Markovian condition for
time-inhomogeneous models. The bounds are the solutions to optimization
problems, for which we derive a computationally tractable dual formulation. We
establish consistency, convergence rate, and asymptotic distribution for the
estimator of the bounds. We demonstrate the approach with two applications: an
infinite-horizon dynamic demand model for new cars in the United Kingdom,
Germany, and France, and a finite-horizon dynamic labor supply model for taxi
drivers in New York City. In the car application, perturbed price elasticities
deviate by at most 15.24% from the reference elasticities, while perturbed
estimates of consumer surplus from an additional $3,000 electric vehicle
subsidy vary by up to 102.75%. In the labor supply application, the perturbed
Frisch labor supply elasticity deviates by at most 76.83% for weekday drivers
and 42.84% for weekend drivers.

</details>


### [42] [Estimating unrestricted spatial interdependence in panel spatial autoregressive models with latent common factors](https://arxiv.org/abs/2510.22399)
*Deborah Gefang,Stephen G Hall,George S. Tavlas*

Main category: econ.EM

TL;DR: 提出了一种新的贝叶斯方法来估计面板空间自回归模型，该方法在N远大于T的情况下能快速估计空间权重矩阵和潜在共同因子，并通过欧盟区域GVA增长率的实证分析验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 开发一种无需预先设定空间关联结构的面板空间自回归模型估计方法，让数据自身揭示空间依赖关系，特别是在横截面单位数远大于时间周期数的情况下。

Method: 采用贝叶斯方法估计面板空间自回归模型，包含已知数量的潜在共同因子，不施加任何先验的空间关联结构，通过数据驱动方式估计空间权重矩阵。

Result: 蒙特卡洛研究表明该方法计算速度极快，估计的空间权重矩阵和共同因子与真实值高度相似；欧盟GVA增长率实证分析显示存在明显国家层面的集群效应，且只有小部分数据变异由与解释变量不相关的潜在冲击解释。

Conclusion: 该方法能有效估计面板空间自回归模型，在实证应用中成功揭示了欧盟区域经济增长的空间依赖模式，特别是国家层面的集群特征。

Abstract: We develop a new Bayesian approach to estimating panel spatial autoregressive
models with a known number of latent common factors, where N, the number of
cross-sectional units, is much larger than T, the number of time periods.
Without imposing any a priori structures on the spatial linkages between
variables, we let the data speak for themselves. Extensive Monte Carlo studies
show that our method is super-fast and our estimated spatial weights matrices
and common factors strongly resemble their true counterparts. As an
illustration, we examine the spatial interdependence of regional gross value
added (GVA) growth rates across the European Union (EU). In addition to
revealing the clear presence of predominant country-level clusters, our results
indicate that only a small portion of the variation in the data is explained by
the latent shocks that are uncorrelated with the explanatory variables.

</details>


### [43] [Nonparametric Identification and Estimation of Spatial Treatment Effect Boundaries: Evidence from 42 Million Pollution Observations](https://arxiv.org/abs/2510.12289)
*Tatsuru Kikuchi*

Main category: econ.EM

TL;DR: 提出了一个非参数框架来识别和估计地理溢出效应中的空间边界，使用4200万卫星观测数据验证了该方法在环境政策应用中的优越性。


<details>
  <summary>Details</summary>
Motivation: 大气扩散理论在理想假设下预测污染物呈指数衰减，但这些假设（稳定风场、均匀大气、平坦地形）在实践中常被违反，需要更灵活的数据驱动方法。

Method: 建立了在弱平滑性和单调性条件下的非参数识别框架，提出了基于核的估计器并采用数据驱动的带宽选择方法，推导了渐近理论用于推断。

Result: 相比参数化指数衰减假设，非参数核回归平均减少预测误差1.0个百分点，在政策相关距离上改善最大：10公里处2.8个百分点（近源影响），100公里处3.7个百分点（长距离传输）。参数方法系统性地低估近源浓度而高估长距离衰减。

Conclusion: 灵活的数据驱动空间方法在环境政策应用中显著优于限制性参数假设，COVID-19自然实验验证了框架的时间敏感性。

Abstract: This paper develops a nonparametric framework for identifying and estimating
spatial boundaries of treatment effects in settings with geographic spillovers.
While atmospheric dispersion theory predicts exponential decay of pollution
under idealized assumptions, these assumptions -- steady winds, homogeneous
atmospheres, flat terrain -- are systematically violated in practice. I
establish nonparametric identification of spatial boundaries under weak
smoothness and monotonicity conditions, propose a kernel-based estimator with
data-driven bandwidth selection, and derive asymptotic theory for inference.
Using 42 million satellite observations of NO$_2$ concentrations near coal
plants (2019-2021), I find that nonparametric kernel regression reduces
prediction errors by 1.0 percentage point on average compared to parametric
exponential decay assumptions, with largest improvements at policy-relevant
distances: 2.8 percentage points at 10 km (near-source impacts) and 3.7
percentage points at 100 km (long-range transport). Parametric methods
systematically underestimate near-source concentrations while overestimating
long-range decay. The COVID-19 pandemic provides a natural experiment
validating the framework's temporal sensitivity: NO$_2$ concentrations dropped
4.6\% in 2020, then recovered 5.7\% in 2021. These results demonstrate that
flexible, data-driven spatial methods substantially outperform restrictive
parametric assumptions in environmental policy applications.

</details>


### [44] [Testing for Grouped Patterns in Panel Data Models](https://arxiv.org/abs/2510.22841)
*Antonio Raiola,Nazarii Salish*

Main category: econ.EM

TL;DR: 本文提出使用现有的面板数据斜率同质性检验工具来检测分组模式的存在，分析了在双重局部备择假设下这些检验框架的优势和局限性。


<details>
  <summary>Details</summary>
Motivation: 虽然面板数据中的分组模式文献已得到广泛关注，但关于检验这些模式存在性的研究结果很少。

Method: 利用现有的面板数据斜率同质性检验工具，在双重局部备择假设下分析检验框架的性能，其中斜率被分为主导组和剩余组。

Result: 蒙特卡洛研究证实了理论发现，显示了所提出方法在检测分组模式方面的有效性。

Conclusion: 现有斜率同质性检验工具可用于检测面板数据中的分组模式，但在特定条件下存在局限性，需要谨慎应用。

Abstract: While the literature on grouped patterns in panel data analysis has received
significant attention, little to no results are available on testing for their
presence. We propose using existing tools for testing slope homogeneity in
panels for this purpose. We highlight the key advantages and limitations of the
available testing frameworks under a sequence of doubly local alternatives,
where slopes are divided into dominant and remainder groups, with the size of
the remainder groups and the slopes differences shrinking at a certain rate as
the sample size increases. A Monte Carlo study corroborate our theoretical
findings.

</details>


### [45] [Nonparametric Identification of Spatial Treatment Effect Boundaries: Evidence from Bank Branch Consolidation](https://arxiv.org/abs/2510.13148)
*Tatsuru Kikuchi*

Main category: econ.EM

TL;DR: 开发非参数框架识别空间边界，应用于银行分支机构分析，发现贷款申请量随距离衰减但审批率不变，揭示高收入地区反而有更多分支机构关闭的反直觉模式。


<details>
  <summary>Details</summary>
Motivation: 传统参数方法可能强加虚假的空间模式，需要灵活的非参数方法来检测复杂的空间模式，避免参数模型的限制。

Method: 使用数据驱动带宽选择的局部线性回归，通过蒙特卡洛模拟验证方法的有效性，应用于2015-2020年银行分支机构开业和2010-2023年生存分析。

Result: 分支机构邻近显著影响贷款申请量（每10英里下降8.5%），但不影响审批率；高收入地区经历更多关闭，这与传统认知相反；控制分支密度后，直接收入效应大幅减弱。

Conclusion: 非参数方法对于检测参数模型会错过的复杂空间模式是必要的，挑战了关于银行沙漠的简单叙述，揭示了空间整合决策背后的组织复杂性。

Abstract: I develop a nonparametric framework for identifying spatial boundaries of
treatment effects without imposing parametric functional form restrictions. The
method employs local linear regression with data-driven bandwidth selection to
flexibly estimate spatial decay patterns and detect treatment effect
boundaries. Monte Carlo simulations demonstrate that the nonparametric approach
exhibits lower bias and correctly identifies the absence of boundaries when
none exist, unlike parametric methods that may impose spurious spatial
patterns. I apply this framework to bank branch openings during 2015--2020,
matching 5,743 new branches to 5.9 million mortgage applications across 14,209
census tracts. The analysis reveals that branch proximity significantly affects
loan application volume (8.5\% decline per 10 miles) but not approval rates,
consistent with branches stimulating demand through local presence while credit
decisions remain centralized. Examining branch survival during the digital
transformation era (2010--2023), I find a non-monotonic relationship with area
income: high-income areas experience more closures despite conventional wisdom.
This counterintuitive pattern reflects strategic consolidation of redundant
branches in over-banked wealthy urban areas rather than discrimination against
poor neighborhoods. Controlling for branch density, urbanization, and
competition, the direct income effect diminishes substantially, with branch
density emerging as the primary determinant of survival. These findings
demonstrate the necessity of flexible nonparametric methods for detecting
complex spatial patterns that parametric models would miss, and challenge
simplistic narratives about banking deserts by revealing the organizational
complexity underlying spatial consolidation decisions.

</details>


### [46] [Identification, Estimation, and Inference in Two-Sided Interaction Models](https://arxiv.org/abs/2510.22884)
*Federico Crippa*

Main category: econ.EM

TL;DR: 该论文研究双边交互模型，引入Tukey模型捕捉互补性，分析识别灵活性vs网络密度的权衡，提出基于循环的估计方法，并构建互补性检验。


<details>
  <summary>Details</summary>
Motivation: 研究双边交互模型中互补性的识别和估计问题，现有模型在灵活性和网络密度要求之间存在权衡。

Method: 引入Tukey模型及其扩展，建立识别理论，提出基于循环的估计器，构建互补性检验。

Result: Tukey模型在稀疏网络下可识别，估计器具有一致性和渐近正态性，实证应用显示能恢复有经济意义的互补性。

Conclusion: Tukey模型为双边交互中的互补性分析提供了实用的识别和估计框架，特别适用于稀疏网络环境。

Abstract: This paper studies a class of models for two-sided interactions, where
outcomes depend on latent characteristics of two distinct agent types. Models
in this class have two core elements: the matching network, which records which
agent pairs interact, and the interaction function, which maps latent
characteristics of these agents to outcomes and determines the role of
complementarities. I introduce the Tukey model, which captures
complementarities with a single interaction parameter, along with two
extensions that allow richer complementarity patterns. First, I establish an
identification trade-off between the flexibility of the interaction function
and the density of the matching network: the Tukey model is identified under
mild conditions, whereas the more flexible extensions require dense networks
that are rarely observed in applications. Second, I propose a cycle-based
estimator for the Tukey interaction parameter and show that it is consistent
and asymptotically normal even when the network is sparse. Third, I use its
asymptotic distribution to construct a formal test of no complementarities.
Finally, an empirical illustration shows that the Tukey model recovers
economically meaningful complementarities.

</details>


### [47] [Dynamic Spatial Treatment Effect Boundaries: A Continuous Functional Framework from Navier-Stokes Equations](https://arxiv.org/abs/2510.14409)
*Tatsuru Kikuchi*

Main category: econ.EM

TL;DR: 提出了基于Navier-Stokes偏微分方程的动态空间处理效应边界理论框架，将处理强度定义为时空连续函数，建立了具有尺度不变性的处理效应传播模型，并通过卫星数据和蒙特卡洛模拟验证了方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统离散处理效应估计方法无法充分捕捉空间处理效应的动态传播和边界演化特征，需要建立连续函数框架来统一分析处理效应的传播动力学、边界演化和累积暴露模式。

Method: 基于Navier-Stokes偏微分方程建立连续函数框架，利用Kummer合流超几何函数和修正贝塞尔函数的精确自相似解，推导处理效应的尺度定律，并通过4200万TROPOMI卫星观测数据和蒙特卡洛模拟进行实证验证。

Result: 实证显示NO2污染呈现强指数空间衰减（κs=0.004/km，R²=0.35），可检测边界达572km。蒙特卡洛模拟证实该方法在边界检测和假阳性避免方面优于离散参数方法（94% vs 27%正确拒绝率）。区域异质性分析验证了诊断能力。

Conclusion: 连续函数视角统一了空间计量经济学与数学物理，为环境经济学、银行和医疗等领域的边界检测、暴露量化和政策评估提供了理论基础的方法。

Abstract: I develop a comprehensive theoretical framework for dynamic spatial treatment
effect boundaries using continuous functional definitions grounded in
Navier-Stokes partial differential equations. Rather than discrete treatment
effect estimators, the framework characterizes treatment intensity as a
continuous function $\tau(\mathbf{x}, t)$ over space-time, enabling rigorous
analysis of propagation dynamics, boundary evolution, and cumulative exposure
patterns. Building on exact self-similar solutions expressible through Kummer
confluent hypergeometric and modified Bessel functions, I establish that
treatment effects follow scaling laws $\tau(d, t) = t^{-\alpha} f(d/t^\beta)$
where exponents characterize diffusion mechanisms. Empirical validation using
42 million TROPOMI satellite observations of NO$_2$ pollution from U.S.
coal-fired power plants demonstrates strong exponential spatial decay
($\kappa_s = 0.004$ per km, $R^2 = 0.35$) with detectable boundaries at 572 km.
Monte Carlo simulations confirm superior performance over discrete parametric
methods in boundary detection and false positive avoidance (94\% vs 27\%
correct rejection). Regional heterogeneity analysis validates diagnostic
capability: positive decay parameters within 100 km confirm coal plant
dominance; negative parameters beyond 100 km correctly signal when urban
sources dominate. The continuous functional perspective unifies spatial
econometrics with mathematical physics, providing theoretically grounded
methods for boundary detection, exposure quantification, and policy evaluation
across environmental economics, banking, and healthcare applications.

</details>


### [48] [Macroeconomic Forecasting for the G7 countries under Uncertainty Shocks](https://arxiv.org/abs/2510.23347)
*Shovon Sengupta,Sunny Kumar Singh,Tanujit Chakraborty*

Main category: econ.EM

TL;DR: 本文提出了一种扩展的Sims Zha贝叶斯VAR模型(SZBVARx)，通过整合领域知识的收缩先验和四种基于新闻的不确定性冲击，改进了宏观经济预测在不确定性环境下的表现。


<details>
  <summary>Details</summary>
Motivation: 传统VAR模型在高维设定下容易过拟合，而阈值VAR难以处理时变依赖关系和复杂参数结构。在当今地缘政治动荡、政策逆转和金融市场波动的背景下，准确的宏观经济预测变得更加困难。

Method: 扩展Sims Zha贝叶斯VAR模型，加入外生变量和四种基于新闻的不确定性冲击(经济政策不确定性、地缘政治风险、美国股市波动性、美国货币政策不确定性)，结合小波相干性分析和非线性局部投影方法。

Result: 在G7国家的12个月和24个月预测中，SZBVARx模型优于14个基准模型，包括传统VAR和领先的机器学习模型，并通过多种统计测试验证了其优越性。

Conclusion: SZBVARx为G7政策制定者提供了一个透明、校准良好的工具，用于在普遍不确定性环境下进行现代宏观经济预测和风险管理。

Abstract: Accurate macroeconomic forecasting has become harder amid geopolitical
disruptions, policy reversals, and volatile financial markets. Conventional
vector autoregressions (VARs) overfit in high dimensional settings, while
threshold VARs struggle with time varying interdependencies and complex
parameter structures. We address these limitations by extending the Sims Zha
Bayesian VAR with exogenous variables (SZBVARx) to incorporate domain-informed
shrinkage and four newspaper based uncertainty shocks such as economic policy
uncertainty, geopolitical risk, US equity market volatility, and US monetary
policy uncertainty. The framework improves structural interpretability,
mitigates dimensionality, and imposes empirically guided regularization. Using
G7 data, we study spillovers from uncertainty shocks to five core variables
(unemployment, real broad effective exchange rates, short term rates, oil
prices, and CPI inflation), combining wavelet coherence (time frequency
dynamics) with nonlinear local projections (state dependent impulse responses).
Out-of-sample results at 12 and 24 month horizons show that SZBVARx outperforms
14 benchmarks, including classical VARs and leading machine learning models, as
confirmed by Murphy difference diagrams, multivariate Diebold Mariano tests,
and Giacomini White predictability tests. Credible Bayesian prediction
intervals deliver robust uncertainty quantification for scenario analysis and
risk management. The proposed SZBVARx offers G7 policymakers a transparent,
well calibrated tool for modern macroeconomic forecasting under pervasive
uncertainty.

</details>


### [49] [Dynamic Spatial Treatment Effects as Continuous Functionals: Theory and Evidence from Healthcare Access](https://arxiv.org/abs/2510.15324)
*Tatsuru Kikuchi*

Main category: econ.EM

TL;DR: 提出了基于纳维-斯托克斯偏微分方程的连续函数空间处理效应框架，将处理强度建模为时空连续函数，能够分析边界演化、空间梯度和累积暴露。


<details>
  <summary>Details</summary>
Motivation: 传统离散处理参数方法无法充分捕捉空间效应的连续性和动态演化，需要开发能够分析空间梯度、边界演化和累积暴露的连续函数框架。

Method: 基于纳维-斯托克斯偏微分方程建立连续函数框架，将处理强度τ(x,t)建模为时空连续函数，使用32,520个美国邮政编码数据进行实证验证。

Result: 发现医疗可及性存在指数空间衰减(κ=0.002837/km)，边界距离37.1km；老年人群距离效应强2-13倍；对数衰减模型优于指数模型(ΔAIC>10,000)。

Conclusion: 连续函数框架提供了传统DID方法不具备的预测能力、参数敏感性和诊断测试能力，可应用于环境经济学、银行和医疗政策等领域。

Abstract: I develop a continuous functional framework for spatial treatment effects
grounded in Navier-Stokes partial differential equations. Rather than discrete
treatment parameters, the framework characterizes treatment intensity as
continuous functions $\tau(\mathbf{x}, t)$ over space-time, enabling rigorous
analysis of boundary evolution, spatial gradients, and cumulative exposure.
Empirical validation using 32,520 U.S. ZIP codes demonstrates exponential
spatial decay for healthcare access ($\kappa = 0.002837$ per km, $R^2 =
0.0129$) with detectable boundaries at 37.1 km. The framework successfully
diagnoses when scope conditions hold: positive decay parameters validate
diffusion assumptions near hospitals, while negative parameters correctly
signal urban confounding effects. Heterogeneity analysis reveals 2-13 $\times$
stronger distance effects for elderly populations and substantial education
gradients. Model selection strongly favors logarithmic decay over exponential
($\Delta \text{AIC} > 10,000$), representing a middle ground between
exponential and power-law decay. Applications span environmental economics,
banking, and healthcare policy. The continuous functional framework provides
predictive capability ($d^*(t) = \xi^* \sqrt{t}$), parameter sensitivity
($\partial d^*/\partial \nu$), and diagnostic tests unavailable in traditional
difference-in-differences approaches.

</details>


### [50] [Choosing What to Learn: Experimental Design when Combining Experimental with Observational Evidence](https://arxiv.org/abs/2510.23434)
*Aristotelis Epanomeritakis,Davide Viviano*

Main category: econ.EM

TL;DR: 提出了一个统一框架，用于设计结合实验和观察性证据的实验，以解决外部有效性和一般均衡效应等政策问题。


<details>
  <summary>Details</summary>
Motivation: 实验估计通常局限于特定情境，难以外推到更广泛的政策问题。当需要评估外部有效性和一般均衡效应时，研究人员需要将实验与观察性证据相结合。

Method: 开发了一个最小化最大比例遗憾目标的设计框架，研究者选择实验识别哪些参数、分配样本量，并指定如何加权实验和观察性估计量。

Result: 该框架提供了一个透明的偏差-方差权衡，无需预设偏差界限，仅依赖于估计量精度和估计量对基础参数的敏感性信息。

Conclusion: 通过现金转移实验和微型金融干预的案例研究，展示了该框架在实际应用中的有效性。

Abstract: Experiments deliver credible but often localized effects, tied to specific
sites, populations, or mechanisms. When such estimates are insufficient to
extrapolate effects for broader policy questions, such as external validity and
general-equilibrium (GE) effects, researchers combine trials with external
evidence from reduced-form or structural observational estimates, or prior
experiments. We develop a unified framework for designing experiments in this
setting: the researcher selects which parameters to identify experimentally
from a feasible set (which treatment arms and/or individuals to include in the
experiment), allocates sample size, and specifies how to weight experimental
and observational estimators. Because observational inputs may be biased in
ways unknown ex ante, we develop a minimax proportional regret objective that
evaluates any candidate design relative to an oracle that knows the bias and
jointly chooses the design and estimator. This yields a transparent
bias-variance trade-off that requires no prespecified bias bound and depends
only on information about the precision of the estimators and the estimand's
sensitivity to the underlying parameters. We illustrate the framework by (i)
designing small-scale cash transfer experiments aimed at estimating GE effects
and (ii) optimizing site selection for microfinance interventions.

</details>


### [51] [Direct Debiased Machine Learning via Bregman Divergence Minimization](https://arxiv.org/abs/2510.23534)
*Masahiro Kato*

Main category: econ.EM

TL;DR: 提出了一个直接去偏机器学习框架，结合Neyman目标估计和广义Riesz回归，统一了多种去偏方法，通过最小化Neyman正交得分差异来同时估计回归函数和Riesz表示子。


<details>
  <summary>Details</summary>
Motivation: 在因果效应或结构模型中，使用机器学习方法估计的回归函数会产生一阶段偏差，导致参数估计性能较差，需要去偏方法来减少这种偏差。

Method: 开发了直接去偏机器学习框架，通过Neyman目标估计最小化已知和未知nuisance参数计算的Neyman正交得分之间的差异，使用Bregman散度衡量差异，涵盖多种损失函数。

Result: 该框架统一了Riesz回归、协变量平衡、TMLE和密度比估计，能够自动获得协变量平衡性质，无需显式求解协变量平衡目标。

Conclusion: 提出的直接去偏机器学习框架提供了一个端到端算法，能够有效减少一阶段偏差，统一了多种去偏方法，具有广泛的应用前景。

Abstract: We develop a direct debiased machine learning framework comprising Neyman
targeted estimation and generalized Riesz regression. Our framework unifies
Riesz regression for automatic debiased machine learning, covariate balancing,
targeted maximum likelihood estimation (TMLE), and density-ratio estimation. In
many problems involving causal effects or structural models, the parameters of
interest depend on regression functions. Plugging regression functions
estimated by machine learning methods into the identifying equations can yield
poor performance because of first-stage bias. To reduce such bias, debiased
machine learning employs Neyman orthogonal estimating equations. Debiased
machine learning typically requires estimation of the Riesz representer and the
regression function. For this problem, we develop a direct debiased machine
learning framework with an end-to-end algorithm. We formulate estimation of the
nuisance parameters, the regression function and the Riesz representer, as
minimizing the discrepancy between Neyman orthogonal scores computed with known
and unknown nuisance parameters, which we refer to as Neyman targeted
estimation. Neyman targeted estimation includes Riesz representer estimation,
and we measure discrepancies using the Bregman divergence. The Bregman
divergence encompasses various loss functions as special cases, where the
squared loss yields Riesz regression and the Kullback-Leibler divergence yields
entropy balancing. We refer to this Riesz representer estimation as generalized
Riesz regression. Neyman targeted estimation also yields TMLE as a special case
for regression function estimation. Furthermore, for specific pairs of models
and Riesz representer estimation methods, we can automatically obtain the
covariate balancing property without explicitly solving the covariate balancing
objective.

</details>


### [52] [The causal interpretation of panel vector autoregressions](https://arxiv.org/abs/2510.23540)
*Raimondo Pala*

Main category: econ.EM

TL;DR: 本文探讨了面板向量自回归（PVAR）的不同同期因果解释，展示了其解释取决于因果变量的分布，范围从平均处理效应到平均因果响应。在无残差自相关假设下，PVAR可以识别处理组的平均处理效应。


<details>
  <summary>Details</summary>
Motivation: 补充现有文献中的工具（如交错DiD、LP-DiD），通过残差而非结果变量来制定假设，允许单位被"稀疏"处理，捕捉干预对结果变量创新成分的影响。

Method: 基于无残差自相关假设，将某些单位视为对照组，使用面板向量自回归模型识别处理组的平均处理效应。

Result: 提供了一个评估美国自然灾害对经济活动周频影响的实例，展示了该方法的应用。

Conclusion: 讨论了解决SUTVA假设因干扰而可能被违反的方案。

Abstract: This paper discusses the different contemporaneous causal interpretations of
Panel Vector Autoregressions (PVAR). I show that the interpretation of PVARs
depends on the distribution of the causing variable, and can range from average
treatment effects, to average causal responses, to a combination of the two. If
the researcher is willing to postulate a no residual autocorrelation
assumption, and some units can be thought of as controls, PVAR can identify
average treatment effects on the treated. This method complements the toolkits
already present in the literature, such as staggered-DiD, or LP-DiD, as it
formulates assumptions in the residuals, and not in the outcome variables. Such
a method features a notable advantage: it allows units to be ``sparsely''
treated, capturing the impact of interventions on the innovation component of
the outcome variables. I provide an example related to the evaluation of the
effects of natural disasters economic activity at the weekly frequency in the
US.I conclude by discussing solutions to potential violations of the SUTVA
assumption arising from interference.

</details>


### [53] [A Unified Framework for Spatial and Temporal Treatment Effect Boundaries: Theory and Identification](https://arxiv.org/abs/2510.00754)
*Tatsuru Kikuchi*

Main category: econ.EM

TL;DR: 本文开发了一个统一的理论框架，用于检测和估计处理效应在空间和时间维度上的边界。该框架将处理效应边界形式化为结构参数，表征因果效应停止运作的制度转换。


<details>
  <summary>Details</summary>
Motivation: 建立统一的理论框架来检测和估计处理效应在空间和时间维度上的边界，为政策干预提供关键阈值识别工具。

Method: 基于信息传播的反应-扩散模型，建立了空间和时间边界共享由扩散参数(δ, λ)控制的共同动态条件，开发了在交错处理采用下的正式识别结果和可实施的三阶段估计程序。

Result: 蒙特卡洛模拟显示优秀的有限样本性能，边界估计的RMSE在现实配置中低于10%。在欧盟宽带扩散(2006-2021)和美国野火经济影响(2017-2022)两个实证应用中，野火应用提供了强验证：估计边界满足d* = 198 km和τ* = 2.7年，经验比率(72.5)与理论预测完全匹配。

Conclusion: 该框架为检测局部处理何时变为系统性以及识别政策干预的关键阈值提供了实用工具，但在存在网络外部性导致的规模收益递增效应时存在局限性。

Abstract: This paper develops a unified theoretical framework for detecting and
estimating boundaries in treatment effects across both spatial and temporal
dimensions. We formalize the concept of treatment effect boundaries as
structural parameters characterizing regime transitions where causal effects
cease to operate. Building on reaction-diffusion models of information
propagation, we establish conditions under which spatial and temporal
boundaries share common dynamics governed by diffusion parameters (delta,
lambda), yielding the testable prediction d^*/tau^* = 3.32 lambda sqrt{delta}
for standard detection thresholds. We derive formal identification results
under staggered treatment adoption and develop a three-stage estimation
procedure implementable with standard panel data. Monte Carlo simulations
demonstrate excellent finite-sample performance, with boundary estimates
achieving RMSE below 10% in realistic configurations. We apply the framework to
two empirical settings: EU broadband diffusion (2006-2021) and US wildfire
economic impacts (2017-2022). The broadband application reveals a scope
limitation -- our framework assumes depreciation dynamics and fails when
effects exhibit increasing returns through network externalities. The wildfire
application provides strong validation: estimated boundaries satisfy d^* = 198
km and tau^* = 2.7 years, with the empirical ratio (72.5) exactly matching the
theoretical prediction 3.32 lambda sqrt{delta} = 72.5. The framework provides
practical tools for detecting when localized treatments become systemic and
identifying critical thresholds for policy intervention.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [54] [Evaluation of A Spatial Microsimulation Framework for Small-Area Estimation of Population Health Outcomes Using the Behavioral Risk Factor Surveillance System](https://arxiv.org/abs/2510.22080)
*Emma Von Hoene,Aanya Gupta,Hamdi Kavak,Amira Roess,Taylor Anderson*

Main category: stat.AP

TL;DR: SHAPE是一个空间微观模拟框架，使用分层迭代比例拟合方法估计健康风险行为和健康结果，在多个空间尺度上表现良好。


<details>
  <summary>Details</summary>
Motivation: 满足公共卫生领域对可访问的小区域估计方法的需求。

Method: 应用分层迭代比例拟合的空间微观模拟框架，使用BRFSS和CDC PLACES数据进行评估。

Result: SHAPE的估计与BRFSS中等一致（平均r≈0.5），与CDC PLACES相似（平均r≈0.6），在县和人口普查区级别与CDC PLACES模型估计高度一致（平均r≈0.8和0.7）。

Conclusion: SHAPE是一个开放、可复现、透明的R语言框架，为公共卫生提供了可访问的小区域估计方法。

Abstract: This study introduces the Spatial Health and Population Estimator (SHAPE), a
spatial microsimulation framework that applies hierarchical iterative
proportional fitting (IPF) to estimate two health risk behaviors and eleven
health outcomes across multiple spatial scales. SHAPE was evaluated using
county-level direct estimates from the Behavioral Risk Factor Surveillance
System (BRFSS) and both county and census tract level data from CDC PLACES for
New York (2021) and Florida (2019). Results show that SHAPE's SAEs are
moderately consistent with BRFSS (average Pearson's correlation coefficient r
of about 0.5), similar to CDC PLACES (average r of about 0.6), and are strongly
aligned with CDC PLACES model-based estimates at both county (average r of
about 0.8) and census tract (average r of about 0.7) levels. SHAPE is an open,
reproducible, and transparent framework programmed in R that meets a need for
accessible SAE methods in public health.

</details>


### [55] [Understanding Carbon Trade Dynamics: A European Union Emissions Trading System Perspective](https://arxiv.org/abs/2510.22341)
*Avirup Chakraborty*

Main category: stat.AP

TL;DR: 欧盟排放交易体系（EU ETS）在2010-2020年间存在效率问题，包括价格聚集、短期收益可预测性、市场集中度以及非传统的价格-交易量关系。


<details>
  <summary>Details</summary>
Motivation: 分析全球最大的碳市场EU ETS的效率、价格行为和市场结构，评估其在脱碳目标下的表现。

Method: 使用AR-GARCH框架分析价格行为，网络分析研究跨国交易结构，国家特定的对数-对数回归分析价格与交易量的弹性关系。

Result: 发现60.05%的方向准确性和70.78%的命中率，市场结构集中由少数注册机构主导，价格弹性异质且有时超过1，表明交易量随价格上涨。

Conclusion: EU ETS虽然有助于脱碳，但其交易动态和价格形成机制仍存在持续的低效率，包括部分可预测性、不对称市场力量和非传统价格-交易量关系。

Abstract: The European Union Emissions Trading System (EU ETS), the worlds largest
cap-and-trade carbon market, is central to EU climate policy. This study
analyzes its efficiency, price behavior, and market structure from 2010 to
2020. Using an AR-GARCH framework, we find pronounced price clustering and
short-term return predictability, with 60.05 percent directional accuracy and a
70.78 percent hit rate within forecast intervals. Network analysis of
inter-country transactions shows a concentrated structure dominated by a few
registries that control most high-value flows. Country-specific log-log
regressions of price on traded quantity reveal heterogeneous and sometimes
positive elasticities exceeding unity, implying that trading volumes often rise
with prices. These results point to persistent inefficiencies in the EU ETS,
including partial predictability, asymmetric market power, and unconventional
price-volume relationships, suggesting that while the system contributes to
decarbonization, its trading dynamics and price formation remain imperfect.

</details>


### [56] [Multimodal Fusion and Interpretability in Human Activity Recognition: A Reproducible Framework for Sensor-Based Modeling](https://arxiv.org/abs/2510.22410)
*Yiyao Yang,Yasemin Gulbahar*

Main category: stat.AP

TL;DR: 提出了一个基于CMU-MMAC数据库的多模态传感器数据融合框架，通过统一预处理、特征融合和可视化分析，显著提升了复杂人类活动识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决自然条件下收集的多模态传感器数据（视频、音频、RFID）的异步性和异构性问题，探索如何将这些原始数据转化为对齐的、有语义意义的表示，以提升复杂人类活动识别性能。

Method: 开发统一预处理流程进行时间对齐，通过重采样、灰度转换、分割和特征标准化进行融合，使用热图、频谱图和波形叠加验证语义丰富性和时间一致性，采用PCA和t-SNE进行特征可视化分析。

Result: 晚期融合获得最高验证准确率，混合融合次之，早期融合最差；音频单独分类性能有限，视频中等，多模态融合显著提升；加入RFID数据后识别准确率提高50%以上，ROC-AUC也得到改善。

Conclusion: 该框架成功将原始异步传感器数据转化为对齐的语义表示，为智能系统中多模态数据集成和解释提供了可复现的方法，证明了多模态融合在复杂人类活动感知中的巨大潜力。

Abstract: The research presents a comprehensive framework for consolidating multimodal
sensor data collected under naturalistic conditions, grounded in the Carnegie
Mellon University Multi-Modal Activity Database (CMU-MMAC). Focusing on Subject
07-Brownie, the study investigates the entire processing pipeline, from data
alignment and transformation to fusion method evaluation, interpretability, and
modality contribution. A unified preprocessing pipeline is developed to
temporally align heterogeneous video and audio data. Fusion is performed
through resampling, grayscale conversion, segmentation, and feature
standardization. Semantic richness is confirmed via heatmaps, spectrograms, and
luminance time series, while frame-aligned waveform overlays demonstrate
temporal consistency. Results indicate that late fusion yields the highest
validation accuracy, followed by hybrid fusion, with early fusion performing
the lowest. To assess the interpretability and discriminative power of audio
and video in fused activity recognition, PCA and t-SNE visualize feature
coherence over time. Classification results show limited performance for audio
alone, moderate for video, and significant improvement with multimodal fusion,
underscoring the strengths of combined data. Incorporating RFID data, which
captures sparse interactions asynchronously, further enhances recognition
accuracy by over 50% and improves macro-averaged ROC-AUC. The framework
demonstrates the potential to transform raw, asynchronous sensor data into
aligned, semantically meaningful representations, providing a reproducible
approach for multimodal data integration and interpretation in intelligent
systems designed to perceive complex human activities.

</details>


### [57] [Doubly Smoothed Density Estimation with Application on Miners' Unsafe Act Detection](https://arxiv.org/abs/2510.22482)
*Qianhan Zeng,Miao Han,Ke Xu,Feifei Wang,Hansheng Wang*

Main category: stat.AP

TL;DR: 提出了一种双重平滑密度估计器，通过两次核平滑来改进固定摄像头环境下的图像异常检测，并引入网格点近似技术降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 在固定摄像头环境下进行图像异常检测时，需要利用空间结构来提高估计精度，同时解决计算成本高的问题。

Method: 使用双重平滑密度估计器：先在值域进行核平滑得到位置密度估计，再在空间域进行核平滑借用邻近位置信息。引入网格点近似技术降低计算成本。

Result: 理论分析显示DS估计器比经典非参数密度估计器有更小的渐近偏差、方差和均方误差。模拟实验表明GPA-DS实现了最低MSE且接近实时速度。在地下矿井监控案例中，GPA-DS能有效提取异常子图像，MobileNet分类器达到约99%的样本外准确率。

Conclusion: 双重平滑密度估计器结合网格点近似技术能够有效提高图像异常检测的精度和效率，在实际应用中表现出色。

Abstract: We study anomaly detection in images under a fixed-camera environment and
propose a \emph{doubly smoothed} (DS) density estimator that exploits spatial
structure to improve estimation accuracy. The DS estimator applies kernel
smoothing twice: first over the value domain to obtain location-wise classical
nonparametric density (CD) estimates, and then over the spatial domain to
borrow information from neighboring locations. Under appropriate regularity
conditions, we show that the DS estimator achieves smaller asymptotic bias,
variance, and mean squared error than the CD estimator. To address the
increased computational cost of the DS estimator, we introduce a grid point
approximation (GPA) technique that reduces the computation cost of inference
without sacrificing the estimation accuracy. A rule-of-thumb bandwidth is
derived for practical use. Extensive simulations show that GPA-DS achieves the
lowest MSE with near real-time speed. In a large-scale case study on
underground mine surveillance, GPA-DS enables remarkable sub-image extraction
of anomalous regions after which a lightweight MobileNet classifier achieves
$\approx$99\% out-of-sample accuracy for unsafe act detection.

</details>


### [58] [Regularization method in the variable selection for logistic regression on BRFSS data](https://arxiv.org/abs/2510.22550)
*Jinbo Niu*

Main category: stat.AP

TL;DR: 使用正则化逻辑回归模型预测中风风险，通过多种重采样技术处理数据不平衡问题，Lasso模型表现最佳（AUC=0.761），Group Lasso识别出年龄、心脏病、身体健康和牙齿健康等关键预测因子。


<details>
  <summary>Details</summary>
Motivation: 中风是全球主要的死亡和致残原因，但使用大规模人群数据进行中风风险预测面临数据不平衡和高维特征的挑战。

Method: 使用2022年行为风险因素监测系统的445,132名美国成年人数据和328个健康相关变量，应用过采样、欠采样、类别加权和SMOTE等重采样技术，采用Lasso、弹性网络和Group Lasso正则化方法进行特征选择和降维。

Result: Lasso模型表现最佳（AUC=0.761），Group Lasso方法识别出年龄、心脏病、身体健康和牙齿健康等关键预测因子。

Conclusion: 正则化回归技术具有从大规模行为健康数据中进行可解释且高效的中风风险预测的潜力。

Abstract: Stroke remains a leading cause of death and disability worldwide, yet
effective prediction of stroke risk using large-scale population data remains
challenging due to data imbalance and high-dimensional features. In this study,
we develop and evaluate regularized logistic regression models for stroke
prediction using data from the 2022 Behavioral Risk Factor Surveillance System
(BRFSS), comprising 445132 U.S. adult respondents and 328 health-related
variables. To address data imbalance, we apply several resampling techniques
including oversampling, undersampling, class weighting, and the Synthetic
Minority Oversampling Technique (SMOTE). We further employ Lasso, Elastic Net,
and Group Lasso regularization methods to perform feature selection and
dimensionality reduction. Model performance is assessed using ROC-AUC,
sensitivity, and specificity metrics. Among all methods, the Lasso-based model
achieved the highest predictive performance (AUC = 0.761), while the Group
Lasso method identified a compact set of key predictors: Age, Heart Disease,
Physical Health, and Dental Health. These findings demonstrate the potential of
regularized regression techniques for interpretable and efficient prediction of
stroke risk from large-scale behavioral health data.

</details>


### [59] [Imaging Genetics Analysis of Alzheimer's Disease](https://arxiv.org/abs/2510.22723)
*Riddhik Basu,Arkaprava Roy*

Main category: stat.AP

TL;DR: 该研究使用机器学习和统计技术分析阿尔茨海默病进展中认知功能、遗传标记和神经影像生物标志物之间的机制关系，识别出MMSE、CDRSB和磷酸化tau水平等关键预测因子，以及CLIC1、NAB2、TGFBR1等与认知障碍相关的显著基因。


<details>
  <summary>Details</summary>
Motivation: 研究阿尔茨海默病进展中认知功能、遗传标记和神经影像生物标志物之间的机制关系，以增强对AD病理学的理解。

Method: 使用ADNI数据，采用低维（多元线性和有序逻辑回归）和高维（SIS和LASSO回归）分析方法，整合认知评分、CSF生物标志物、人口统计学因素和遗传标记。

Result: 发现MMSE、CDRSB和磷酸化tau水平在预测认知衰退中具有显著关联；识别出CLIC1、NAB2、TGFBR1等与认知障碍和白质完整性相关的显著基因；影像遗传分析显示跨脑半球和胼胝体的共享遗传影响。

Conclusion: 通过整合认知、遗传和影像数据增强了对AD病理学的理解，建议未来研究探索纵向分析和基因-环境相互作用以进一步阐明AD进展的生物学机制。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder
characterized by cognitive decline, structural brain changes, and genetic
predispositions. This study leverages machine-learning and statistical
techniques to investigate the mechanistic relationships between cognitive
function, genetic markers, and neuroimaging biomarkers in AD progression. Using
data from the Alzheimer's Disease Neuroimaging Initiative (ADNI), we perform
both low-dimensional and high-dimensional analyses to identify key predictors
of disease states, including cognitively normal (CN), mild cognitive impairment
(MCI), and AD. Our low-dimensional approach utilizes multiple linear and
ordinal logistic regression to examine the influence of cognitive scores,
cerebrospinal fluid (CSF) biomarkers, and demographic factors on disease
classification. The results highlight significant associations between
Mini-Mental State Examination (MMSE), Clinical Dementia Rating Sum of Boxes
(CDRSB), and phosphorylated tau levels in predicting cognitive decline. The
high-dimensional analysis employs Sure Independence Screening (SIS) and LASSO
regression to reduce dimensionality and identify genetic markers correlated
with cognitive impairment and white matter integrity. Genes such as CLIC1,
NAB2, and TGFBR1 emerge as significant predictors across multiple analyses,
linking genetic expression to neurodegeneration. Additionally, imaging genetic
analysis reveals shared genetic influences across brain hemispheres and the
corpus callosum, suggesting distinct genetic contributions to white matter
degradation. These findings enhance our understanding of AD pathology by
integrating cognitive, genetic, and imaging data. Future research should
explore longitudinal analyses and potential gene-environment interactions to
further elucidate the biological mechanisms underlying AD progression.

</details>


### [60] [On the simultaneous inference of susceptibility distributions and intervention effects from epidemic curves](https://arxiv.org/abs/2510.22791)
*Ibrahim Mohammed,Chris Robertson,M. Gabriela M. Gomes*

Main category: stat.AP

TL;DR: 该研究首次系统评估了考虑个体差异的SEIR模型在参数估计方面的能力，发现存在可识别性问题，但可以通过创新性地拟合多个共享参数的流行病来克服。


<details>
  <summary>Details</summary>
Motivation: 早期COVID-19大流行期间，考虑个体易感性或暴露程度差异的SEIR模型被提出作为政策制定的数学工具，但由于缺乏对其推断能力的先验验证，这些模型未能进入主流政策制定。

Method: 通过使用战略性选择的参数值模拟数据集，然后进行最大似然估计，评估从模拟数据中恢复假设参数值的能力。

Result: 研究发现存在一些可识别性问题，但可以通过创新性地拟合多个具有共享参数的流行病来克服这些问题。

Conclusion: 这是对考虑个体差异的SEIR模型参数估计能力的首次系统调查，为这类模型在流行病政策制定中的应用提供了重要验证。

Abstract: Susceptible-Exposed-Infectious-Recovered (SEIR) models with inter-individual
variation in susceptibility or exposure to infection were proposed early in the
COVID-19 pandemic as a potential element of the mathematical/statistical
toolset available to policy development. In comparison with other models
employed at the time, those designed to fully estimate the effects of such
variation tended to predict small epidemic waves and hence require less
containment to achieve the same outcomes. However, these models never made it
to mainstream COVID-19 policy making due to lack of prior validation of their
inference capabilities. Here we report the results of the first systematic
investigation of this matter. We simulate datasets using the model with
strategically chosen parameter values, and then conduct maximum likelihood
estimation to assess how well we can retrieve the assumed parameter values. We
identify some identifiability issues which can be overcome by creatively
fitting multiple epidemics with shared parameters.

</details>


### [61] [Mortality Models Ensemble via Shapley Value](https://arxiv.org/abs/2510.23014)
*Giovanna Bimonte,Maria Russolillo,Han Lin Shang,Yang Yang*

Main category: stat.AP

TL;DR: 提出了一种基于博弈论Shapley值的模型平均方法，用于提高寿险预测的准确性，通过优化权重分配来改善整体预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统模型平均方法在寿险预测中虽然能提高准确性，但权重选择不当会降低预测效果。需要找到更优的权重分配方法来充分发挥各模型的预测能力。

Method: 采用博弈论中的Shapley值方法来确定各模型在组合预测中的权重，量化每个模型对整体预测结果的贡献度。

Result: 该方法能够更准确地识别各模型的重要性，优化权重分配，从而提高长寿预测的整体准确性。

Conclusion: 基于Shapley值的模型平均方法为寿险预测提供了更科学的权重选择机制，有助于提升预测精度和决策质量。

Abstract: Model averaging techniques in the actuarial literature aim to forecast future
longevity appropriately by combining forecasts derived from various models.
This approach often yields more accurate predictions than those generated by a
single model. The key to enhancing forecast accuracy through model averaging
lies in identifying the optimal weights from a finite sample. Utilizing
sub-optimal weights in computations may adversely impact the accuracy of the
model-averaged longevity forecasts. By proposing a game-theoretic approach
employing Shapley values for weight selection, our study clarifies the distinct
impact of each model on the collective predictive outcome. This analysis not
only delineates the importance of each model in decision-making processes, but
also provides insight into their contribution to the overall predictive
performance of the ensemble.

</details>


### [62] [A Physics-Informed Variational Inference Framework for Identifying Attributions of Extreme Stress Events in Low-Grain Polycrystals](https://arxiv.org/abs/2510.23437)
*Yinling Zhang,Samuel D. Dunham,Curt A. Bronkhorst,Nan Chen*

Main category: stat.AP

TL;DR: 提出了一种新的变分推断框架，结合物理信息统计模型和极值统计，用于识别多晶金属材料失效的微观结构特征。


<details>
  <summary>Details</summary>
Motivation: 多晶金属失效通常始于晶界处的应力集中，但识别触发这些极端损伤事件的微观结构特征具有挑战性，因为极端事件罕见且涉及跨尺度的复杂过程。现有方法主要关注平均行为而非罕见事件。

Method: 1. 将极值理论融入似然函数，强调尾部分布行为；2. 通过物理信息统计模型约束推断，提供物理一致的预测；3. 在降维潜空间中开发混合模型，捕捉微观结构特征的非高斯特性。

Result: 在双晶构型的控制和实际实验中，该框架实现了可靠的极端事件预测，并揭示了与材料失效相关的微观结构特征。

Conclusion: 该框架为材料设计提供了物理见解，并具有不确定性量化能力，能够有效识别材料失效的微观结构归因。

Abstract: Polycrystalline metal failure often begins with stress concentration at grain
boundaries. Identifying which microstructural features trigger these events is
important but challenging because these extreme damage events are rare and the
failure mechanisms involve multiple complex processes across scales. Most
existing inference methods focus on average behavior rather than rare events,
whereas standard sample-based methods are computationally expensive for
high-dimensional complex systems. In this paper, we develop a new variational
inference framework that integrates a recently developed computationally
efficient physics-informed statistical model with extreme value statistics to
significantly facilitate the identification of material failure attributions.
First, we reformulate the objective to emphasize observed exceedances by
incorporating extreme-value theory into the likelihood, thereby highlighting
tail behavior. Second, we constrain inference via a physics-informed
statistical model that characterizes microstructure-stress relationships, which
uniquely provides physically consistent predictions for these rare events.
Third, mixture models in a reduced latent space are developed to capture the
non-Gaussian characteristics of microstructural features, allowing the
identification of multiple underlying mechanisms. In both controlled and
realistic experimental tests for the bicrystal configuration, the framework
achieves reliable extreme-event prediction and reveals the microstructural
features associated with material failure, providing physical insights for
material design with uncertainty quantification.

</details>


### [63] [Model Proficiency in Centralized Multi-Agent Systems: A Performance Study](https://arxiv.org/abs/2510.23447)
*Anna Guerra,Francesco Guidi,Pau Closas,Davide Dardari,Petar M. Djuric*

Main category: stat.AP

TL;DR: 提出了一个团队熟练度自评估框架，在集中式设置中研究MPB、KS统计量和KL散度三种指标，用于量化预测与实际测量之间的差异，并在目标跟踪场景中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然单智能体的熟练度自评估已有研究，但扩展到多智能体团队仍未被充分探索，特别是在动态环境中团队执行任务能力依赖于个体和团队层面的熟练度。

Method: 提出集中式团队PSA框架，使用测量预测边界(MPB)、Kolmogorov-Smirnov(KS)统计量和Kullback-Leibler(KL)散度三种指标来量化预测与实际测量的差异。

Result: 在目标跟踪场景的仿真结果表明，MPB和KS指标能准确捕捉模型不匹配，与KL散度参考值一致，并能实现实时熟练度评估。

Conclusion: MPB和KS指标为团队熟练度自评估提供了有效的实时评估工具，能够准确识别模型不匹配问题。

Abstract: Autonomous agents are increasingly deployed in dynamic environments where
their ability to perform a given task depends on both individual and team-level
proficiency. While proficiency self-assessment (PSA) has been studied for
single agents, its extension to a team of agents remains underexplored. This
letter addresses this gap by presenting a framework for team PSA in centralized
settings. We investigate three metrics for centralized team PSA: the
measurement prediction bound (MPB), the Kolmogorov-Smirnov (KS) statistic, and
the Kullback-Leibler (KL) divergence. These metrics quantify the discrepancy
between predicted and actual measurements. We use the KL divergence as a
reference metric since it compares the true and predictive distributions,
whereas the MPB and KS provide efficient indicators for in situ assessment.
Simulation results in a target tracking scenario demonstrate that both MPB and
KS metrics accurately capture model mismatches, align with the KL divergence
reference, and enable real-time proficiency assessment.

</details>


### [64] [Beyond the Trade-off Curve: Multivariate and Advanced Risk-Utility Maps for Evaluating Anonymized and Synthetic Data](https://arxiv.org/abs/2510.23500)
*Oscar Thees,Roman Müller,Matthias Templ*

Main category: stat.AP

TL;DR: 本文系统比较了六种可视化方法用于同时评估匿名化数据的多重风险和效用指标，提出了块状PCA和联合PCA技术来改进可视化效果。


<details>
  <summary>Details</summary>
Motivation: 传统匿名化评估依赖单一指标或二维风险-效用图，无法有效处理现实世界中多重相关指标的同时评估问题。

Method: 比较六种可视化方法：热图、点图、复合散点图、平行坐标图、径向轮廓图和PCA双标图，并引入块状PCA和联合PCA技术。

Result: 通过系统识别所有方法中的帕累托最优方法，证明多变量可视化支持更明智的匿名化方法选择。

Conclusion: 多变量可视化方法能够更全面地评估匿名化方法，帮助在降低披露风险与保持数据效用之间做出更好的平衡决策。

Abstract: Anonymizing microdata requires balancing the reduction of disclosure risk
with the preservation of data utility. Traditional evaluations often rely on
single measures or two-dimensional risk-utility (R-U) maps, but real-world
assessments involve multiple, often correlated, indicators of both risk and
utility. Pairwise comparisons of these measures can be inefficient and
incomplete. We therefore systematically compare six visualization approaches
for simultaneous evaluation of multiple risk and utility measures: heatmaps,
dot plots, composite scatterplots, parallel coordinate plots, radial profile
charts, and PCA-based biplots. We introduce blockwise PCA for composite
scatterplots and joint PCA for biplots that simultaneously reveal method
performance and measure interrelationships. Through systematic identification
of Pareto-optimal methods in all approaches, we demonstrate how multivariate
visualization supports a more informed selection of anonymization methods.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [65] [Beliefs about Bots: How Employers Plan for AI in White-Collar Work](https://arxiv.org/abs/2510.21959)
*Eduard Brüll,Samuel Mäurer,Davud Rostam-Afschar*

Main category: econ.GN

TL;DR: 通过随机信息干预实验发现，德国税务顾问公司普遍低估了工作的自动化风险。提供自动化风险信息会提高风险认知，但短期内不影响招聘计划，而是提升生产率和财务预期，同时导致有限的工资调整和内部不平等。


<details>
  <summary>Details</summary>
Motivation: 研究高技能白领工作中雇主如何应对自动化风险，特别是他们是否准确评估自动化风险以及信息干预如何影响其决策。

Method: 在德国税务顾问中进行随机信息干预实验，比较接受自动化风险信息与未接受信息的公司的反应差异。

Result: 信息提供显著提高了对自动化风险的认知，特别是对常规密集型岗位；短期内招聘计划不变，但提高了生产率和财务预期，工资调整有限；雇主预期在法律科技、合规和AI交互方面会出现新任务，培训和技术采用意愿增强。

Conclusion: 雇主对自动化风险存在系统性低估，信息干预能更新其信念，主要影响生产预期而非招聘决策，可能导致企业内部不平等加剧，同时推动对新技能和技术的投资。

Abstract: We provide experimental evidence on how employers adjust expectations to
automation risk in high-skill, white-collar work. Using a randomized
information intervention among tax advisors in Germany, we show that firms
systematically underestimate automatability. Information provision raises risk
perceptions, especially for routine-intensive roles. Yet, it leaves short-run
hiring plans unchanged. Instead, updated beliefs increase productivity and
financial expectations with minor wage adjustments, implying within-firm
inequality like limited rent-sharing. Employers also anticipate new tasks in
legal tech, compliance, and AI interaction, and report higher training and
adoption intentions.

</details>


### [66] [There's Nothing in the Air](https://arxiv.org/abs/2510.22294)
*Jacob Adenbaum,Fil Babalievsky,William Jungerman*

Main category: econ.GN

TL;DR: 大城市工资增长更快主要不是因为城市本身，而是由于企业和同事的构成差异以及工作流动性更高。


<details>
  <summary>Details</summary>
Motivation: 探究为什么大城市工资增长更快，挑战传统认为城市产生人力资本溢出的观点。

Method: 使用法国行政数据，通过控制企业和同事构成来分析城市工资增长溢价。

Result: 80%的城市工资增长溢价在控制企业和同事构成后消失；当关注同一工作的工人时，94.1%的溢价消失，剩余效应统计上不显著。

Conclusion: 城市工资动态主要反映企业和工人的分类以及工作流动速度，而非城市本身的人力资本溢出效应。

Abstract: Why do wages grow faster in bigger cities? We use French administrative data
to decompose the urban wage growth premium and find that the answer has
surprisingly little to do with cities themselves. While we document
substantially faster wage growth in larger cities, 80% of the premium
disappears after controlling for the composition of firms and coworkers. We
also document significantly higher job-to-job transition rates in larger
cities, suggesting workers climb the job ladder faster. Most strikingly, when
we focus on workers who remain in the same job -- eliminating the job ladder
mechanism -- the urban wage growth premium falls by 94.1% after accounting for
firms and coworkers. The residual effect is statistically indistinguishable
from zero. These results challenge the view that cities generate human capital
spillovers ``in the air,'' suggesting instead that urban wage dynamics reflect
the sorting of firms and workers and the pace of job mobility.

</details>


### [67] [Wildfire and house prices: A synthetic control case study of Altadena (Jan 2025)](https://arxiv.org/abs/2510.22817)
*Yibo Sun*

Main category: econ.GN

TL;DR: 使用合成控制法评估2025年1月加州Altadena野火对房价的因果影响，发现显著负面效应且随时间加剧，六个月平均月损失32,125美元


<details>
  <summary>Details</summary>
Motivation: 评估野火灾害对社区房价的因果影响，为火灾频发地区的财务风险提供实证依据

Method: 采用合成控制法构建'合成'Altadena作为反事实对照组，假设对捐赠池无溢出效应

Result: 野火导致房价显著负面效应，随时间加剧；基于稳健后/前处理RMSPE比率在10%水平显著(p=0.0508)，但基于平均后处理差距不显著(p=0.3220)

Conclusion: 研究突显火灾频发社区的财务风险，证明合成控制法在评估灾害相关经济损失方面的有效性

Abstract: This study uses the Synthetic Control Method (SCM) to estimate the causal
impact of a January 2025 wildfire on housing prices in Altadena, California. We
construct a 'synthetic' Altadena from a weighted average of peer cities to
serve as a counterfactual; this approach assumes no spillover effects on the
donor pool. The results reveal a substantial negative price effect that
intensifies over time. Over the six months following the event, we estimate an
average monthly loss of $32,125. The statistical evidence for this effect is
nuanced. Based on the robust post-to-pre-treatment RMSPE ratio, the result is
statistically significant at the 10% level (p = 0.0508). In contrast, the
effect is not statistically significant when measured by the average
post-treatment gap (p = 0.3220). This analysis highlights the significant
financial risks faced by communities in fire-prone regions and demonstrates
SCM's effectiveness in evaluating disaster-related economic damages.

</details>


### [68] [Exploring Vulnerability in AI Industry](https://arxiv.org/abs/2510.23421)
*Claudio Pirrone,Stefano Fricano,Gioacchino Fazio*

Main category: econ.GN

TL;DR: 提出合成AI脆弱性指数(AIVI)来评估基础模型产业的上游价值链脆弱性，重点关注计算、数据、人才、资本和能源五个输入要素的供应风险。


<details>
  <summary>Details</summary>
Motivation: 基础模型(FMs)的快速发展驱动着当前AI生态系统，但由于数据限制，评估这个快速演进产业的脆弱性具有挑战性。需要量化AI核心生产引擎的系统性风险。

Method: 将基础模型产出建模为计算、数据、人才、资本和能源五个输入的函数，使用加权几何平均法聚合各子指数，采用理论或经验基准进行归一化。

Result: 识别出关键脆弱性包括计算集中度、数据稀缺性和法律风险、人才瓶颈、资本密集度和战略依赖，以及不断增长的能源需求。

Conclusion: 尽管存在局限性，这个初步指数旨在量化AI核心生产引擎的系统性风险，并间接揭示下游价值链的风险。

Abstract: The rapid ascent of Foundation Models (FMs), enabled by the Transformer
architecture, drives the current AI ecosystem. Characterized by large-scale
training and downstream adaptability, FMs (as GPT family) have achieved massive
public adoption, fueling a turbulent market shaped by platform economics and
intense investment. Assessing the vulnerability of this fast-evolving industry
is critical yet challenging due to data limitations. This paper proposes a
synthetic AI Vulnerability Index (AIVI) focusing on the upstream value chain
for FM production, prioritizing publicly available data. We model FM output as
a function of five inputs: Compute, Data, Talent, Capital, and Energy,
hypothesizing that supply vulnerability in any input threatens the industry.
Key vulnerabilities include compute concentration, data scarcity and legal
risks, talent bottlenecks, capital intensity and strategic dependencies, as
well as escalating energy demands. Acknowledging imperfect input
substitutability, we propose a weighted geometrical average of aggregate
subindexes, normalized using theoretical or empirical benchmarks. Despite
limitations and room for improvement, this preliminary index aims to quantify
systemic risks in AI's core production engine, and implicitly shed a light on
the risks for downstream value chain.

</details>


### [69] [Stochastic Boundaries in Spatial General Equilibrium: A Diffusion-Based Approach to Causal Inference with Spillover Effects](https://arxiv.org/abs/2508.06594)
*Tatsuru Kikuchi*

Main category: econ.GN

TL;DR: 提出了一个用于空间经济学因果推断的新框架，通过DDPM模型结合边界检测方法，识别处理效应从局部向一般均衡的随机转换过程。


<details>
  <summary>Details</summary>
Motivation: 传统因果推断方法难以准确识别空间溢出效应何时从局部市场传播到系统层面，需要建立能够捕捉这种随机转换边界的理论框架。

Method: 使用去噪扩散概率模型(DDPM)结合Lévy过程的跳-扩散动力学，通过CUSUM序列检测识别空间和时间边界，将空间溢出演化建模为具有临界阈值的第一通过时间过程。

Result: 在日本县级AI应用研究中发现处理效应在约35km空间尺度出现Lévy跳跃，一般均衡效应将部分均衡估计放大42%。蒙特卡洛模拟显示忽略这些边界会导致处理效应低估28-67%。

Conclusion: 该框架首次提供了确定空间溢出何时需要一般均衡分析的严格方法，为互联经济中的政策评估提供了关键指导。

Abstract: This paper introduces a novel framework for causal inference in spatial
economics that explicitly models the stochastic transition from partial to
general equilibrium effects. We develop a Denoising Diffusion Probabilistic
Model (DDPM) integrated with boundary detection methods from stochastic process
theory to identify when and how treatment effects propagate beyond local
markets. Our approach treats the evolution of spatial spillovers as a L\'evy
process with jump-diffusion dynamics, where the first passage time to critical
thresholds indicates regime shifts from partial to general equilibrium. Using
CUSUM-based sequential detection, we identify the spatial and temporal
boundaries at which local interventions become systemic. Applied to AI adoption
across Japanese prefectures, we find that treatment effects exhibit L\'evy
jumps at approximately 35km spatial scales, with general equilibrium effects
amplifying partial equilibrium estimates by 42\%. Monte Carlo simulations show
that ignoring these stochastic boundaries leads to underestimation of treatment
effects by 28-67\%, with particular severity in densely connected economic
regions. Our framework provides the first rigorous method for determining when
spatial spillovers necessitate general equilibrium analysis, offering crucial
guidance for policy evaluation in interconnected economies.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [70] [A Multi-Component AI Framework for Computational Psychology: From Robust Predictive Modeling to Deployed Generative Dialogue](https://arxiv.org/abs/2510.21720)
*Anant Pareek*

Main category: cs.AI

TL;DR: 该论文提出了一个结合AI与计算心理学的综合框架，通过端到端开发流程构建了从预测建模到交互式心理分析的系统，包括基准测试、Transformer模型微调、生成式LLM开发以及微服务部署。


<details>
  <summary>Details</summary>
Motivation: 弥合孤立预测建模与交互式心理分析系统之间的差距，为计算心理学和人类-AI交互提供完整的研究到部署管道。

Method: 采用多阶段方法：1) 在四个心理学数据集上建立基准性能；2) 微调Transformer模型并解决数值不稳定性和资源限制问题；3) 使用参数高效技术微调生成式LLM作为交互式"人格大脑"；4) 将预测和生成模型构建为可扩展的微服务生态系统。

Result: 成功稳定了基于Transformer的情感计算回归模型，在标准方法失败的情况下显示出有意义的预测性能，并开发了可复现的大规模AI研究方法论。

Conclusion: 该工作通过整合预测分析与生成对话的完整研究到部署管道，为计算心理学和人类-AI交互的未来研究提供了实用模型，展示了整体方法的重要性。

Abstract: The confluence of Artificial Intelligence and Computational Psychology
presents an opportunity to model, understand, and interact with complex human
psychological states through computational means. This paper presents a
comprehensive, multi-faceted framework designed to bridge the gap between
isolated predictive modeling and an interactive system for psychological
analysis. The methodology encompasses a rigorous, end-to-end development
lifecycle. First, foundational performance benchmarks were established on four
diverse psychological datasets using classical machine learning techniques.
Second, state-of-the-art transformer models were fine-tuned, a process that
necessitated the development of effective solutions to overcome critical
engineering challenges, including the resolution of numerical instability in
regression tasks and the creation of a systematic workflow for conducting
large-scale training under severe resource constraints. Third, a generative
large language model (LLM) was fine-tuned using parameter-efficient techniques
to function as an interactive "Personality Brain." Finally, the entire suite of
predictive and generative models was architected and deployed as a robust,
scalable microservices ecosystem. Key findings include the successful
stabilization of transformer-based regression models for affective computing,
showing meaningful predictive performance where standard approaches failed, and
the development of a replicable methodology for democratizing large-scale AI
research. The significance of this work lies in its holistic approach,
demonstrating a complete research-to-deployment pipeline that integrates
predictive analysis with generative dialogue, thereby providing a practical
model for future research in computational psychology and human-AI interaction.

</details>


### [71] [PREFINE: Personalized Story Generation via Simulated User Critics and User-Specific Rubric Generation](https://arxiv.org/abs/2510.21721)
*Kentaro Ueda,Takehiro Takayanagi*

Main category: cs.AI

TL;DR: PREFINE框架通过构建伪用户代理和用户特定评估标准，在不更新参数或收集直接用户反馈的情况下实现个性化故事生成。


<details>
  <summary>Details</summary>
Motivation: 传统个性化方法依赖显式反馈或微调，存在用户负担、数据收集、计算成本和隐私等实际问题。

Method: 构建伪用户代理和用户特定评估标准，让代理基于这些标准进行批判和精炼，实现个性化生成。

Result: 在PerDOC和PerMPST数据集上，PREFINE在自动评估中获得了更高的胜率和统计显著分数，且不损害故事整体质量。

Conclusion: 该方法在故事生成之外，还有潜力应用于对话系统、教育和推荐等更广泛领域的个性化任务。

Abstract: While recent advances in Large Language Models (LLMs) have improved the
quality of creative text generation, significant challenges remain in producing
personalized stories that reflect individual user preferences. Conventional
approaches rely on explicit feedback or fine-tuning, which presents practical
issues regarding user burden, data collection, computational costs, and
privacy. In this work, we propose PREFINE (Persona-and-Rubric Guided
Critique-and-Refine), a novel framework that extends the Critique-and-Refine
paradigm to personalization. PREFINE constructs a pseudo-user agent from a
user's interaction history and generates user-specific rubrics (evaluation
criteria). By having this agent critique and refine outputs on the user's
behalf based on these tailored rubrics, our method achieves personalized
generation without requiring parameter updates or direct user feedback. We
conducted a comprehensive evaluation on the PerDOC and PerMPST story datasets.
We designed three baseline methods and several model variants to verify the
contribution of each component of our framework. In automatic evaluations
(LLM-as-a-Judge), PREFINE achieved higher win rates and statistically
significant scores than the baselines, without compromising general story
quality. Analysis of the model variants confirmed that both the pseudo-user
agent and the user-specific rubrics are crucial for enhancing personalization
performance. Beyond story generation, our approach holds potential for enabling
efficient personalization in broader applications, such as dialogue systems,
education, and recommendation.

</details>


### [72] [SIGN: Schema-Induced Games for Naming](https://arxiv.org/abs/2510.21855)
*Ryan Zhang,Herbert Woisetscläger*

Main category: cs.AI

TL;DR: 本文介绍了一种名为SIGN的命名游戏，通过引入轻量级结构来引导多智能体系统的约定形成，相比无约束自然语言通信，能实现更快的收敛和高达5.8倍的协议一致性。


<details>
  <summary>Details</summary>
Motivation: 现实AI系统在处理复杂问题时，大型语言模型智能体之间的不一致约定会导致协调失败。协作编码和分布式规划等应用需要可靠、一致的通信，且系统扩展性是关键问题。

Method: 提出了Schema-Induced Games for Naming (SIGN)命名游戏，通过引入轻量级结构来引导约定形成，并与无约束自然语言通信进行比较。

Result: 相比无约束自然语言，schema诱导的通信实现了更快的收敛速度，协议一致性提高了5.8倍。

Conclusion: 最小化结构可以作为多智能体协调的简单控制机制，实现高效协调，这一方法在命名游戏之外具有更广泛的应用前景。

Abstract: Real-world AI systems are tackling increasingly complex problems, often
through interactions among large language model (LLM) agents. When these agents
develop inconsistent conventions, coordination can break down. Applications
such as collaborative coding and distributed planning therefore require
reliable, consistent communication, and scalability is a central concern as
systems grow. We introduce Schema-Induced Games for Naming (SIGN), a naming
game that examines how lightweight structure can steer convention formation. We
compare schema-induced communication to unconstrained natural language and find
faster convergence with up to 5.8x higher agreement. These results suggest that
minimal structure can act as a simple control knob for efficient multi-agent
coordination, pointing toward broader applications beyond the naming game.

</details>


### [73] [Atlas Urban Index: A VLM-Based Approach for Spatially and Temporally Calibrated Urban Development Monitoring](https://arxiv.org/abs/2510.22702)
*Mithul Chander,Sai Pragnya Ranga,Prathamesh Mayekar*

Main category: cs.AI

TL;DR: 提出Atlas Urban Index (AUI)指标，利用视觉语言模型和Sentinel-2卫星图像来更准确地测量城市发展，克服传统指数如NDBI的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法如NDBI由于大气噪声、季节变化和云层覆盖等因素，难以准确捕捉城市发展，阻碍了大规模人类发展和城市化监测。

Method: 收集区域的时间序列Sentinel-2图像，在固定时间窗口内处理图像以获得云层覆盖最少的代表性图像，使用视觉语言模型提供发展评分，并采用参考图像集和最近历史图像来确保评分一致性。

Result: 在班加罗尔的定性实验表明，AUI优于NDBI等标准指数。

Conclusion: AUI能够克服传统城市化指数的挑战，产生更可靠和稳定的发展评分。

Abstract: We introduce the {\em Atlas Urban Index} (AUI), a metric for measuring urban
development computed using Sentinel-2 \citep{spoto2012sentinel2} satellite
imagery. Existing approaches, such as the {\em Normalized Difference Built-up
Index} (NDBI), often struggle to accurately capture urban development due to
factors like atmospheric noise, seasonal variation, and cloud cover. These
limitations hinder large-scale monitoring of human development and
urbanization. To address these challenges, we propose an approach that
leverages {\em Vision-Language Models }(VLMs) to provide a development score
for regions. Specifically, we collect a time series of Sentinel-2 images for
each region. Then, we further process the images within fixed time windows to
get an image with minimal cloud cover, which serves as the representative image
for that time window. To ensure consistent scoring, we adopt two strategies:
(i) providing the VLM with a curated set of reference images representing
different levels of urbanization, and (ii) supplying the most recent past image
to both anchor temporal consistency and mitigate cloud-related noise in the
current image. Together, these components enable AUI to overcome the challenges
of traditional urbanization indices and produce more reliable and stable
development scores. Our qualitative experiments on Bangalore suggest that AUI
outperforms standard indices such as NDBI.

</details>


### [74] [Capability Ceilings in Autoregressive Language Models: Empirical Evidence from Knowledge-Intensive Tasks](https://arxiv.org/abs/2510.21866)
*Javier Marín*

Main category: cs.AI

TL;DR: 研究发现解码器自回归语言模型在知识密集型任务中存在能力上限，参数规模扩大（70M-30B）时知识检索任务准确率几乎无提升，而数学任务准确率保持稳定在19-20%，但损失函数持续下降。


<details>
  <summary>Details</summary>
Motivation: 探究解码器自回归语言模型在参数规模扩展时，不同任务类型的性能表现差异，特别是知识密集型任务是否真正受益于模型规模扩大。

Method: 系统评估OPT和Pythia模型家族（70M-30B参数），分析知识检索和数学任务的准确率与损失函数变化，并进行注意力干预实验。

Result: 知识检索任务准确率几乎无改善，数学任务准确率稳定在19-20%（低于25%随机概率），而交叉熵损失下降31%。注意力干预导致性能灾难性崩溃。

Conclusion: 对于使用OPT和Pythia架构的知识密集型应用，参数规模超过1-2B带来的准确率提升微乎其微，尽管损失函数持续改善。这些发现揭示了特定能力扩展失败的模式。

Abstract: We document empirical capability ceilings in decoder-only autoregressive
language models across knowledge-intensive tasks. Systematic evaluation of OPT
and Pythia model families (70M-30B parameters, spanning 240 times scaling)
reveals that knowledge retrieval tasks show negligible accuracy improvement
despite smooth loss reduction. On MMLU mathematics benchmarks, accuracy remains
flat at 19-20% (below 25% random chance) across all scales while cross-entropy
loss decreases by 31%. In contrast, procedural tasks like arithmetic show
conventional scaling where both metrics improve together. Attention
intervention experiments reveal high sensitivity to perturbation: swapping
attention patterns between models causes catastrophic performance collapse
(complete accuracy loss) rather than graceful degradation. These measurements
have immediate engineering implications: for knowledge-intensive applications
using OPT and Pythia architectures, parameter scaling beyond 1-2B offers
minimal accuracy gains despite continued loss improvement. Our findings
quantify capability-specific scaling failures in these model families to inform
resource allocation decisions. Whether these patterns reflect fundamental
constraints of decoder-only architectures or implementation-specific
limitations remains an open question requiring investigation across diverse
architectural approaches.

</details>


### [75] [GeoThought: A Dataset for Enhancing Mathematical Geometry Reasoning in Vision-Language Models](https://arxiv.org/abs/2510.21881)
*Nannan Shi,Chuanyu Qin,Shipeng Song,Man Luo*

Main category: cs.AI

TL;DR: 该论文开发了GeoThoughts数据集和GeoThought-MLLM模型，通过包含详细推理链的训练数据显著提升了多模态大语言模型在几何推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在文本数学推理上表现良好，但在视觉几何推理任务中性能显著下降，主要由于几何问题的内在复杂性（需要详细图像理解和多步推理）和现有数据集缺乏规模、多样性和明确推理轨迹的局限性。

Method: 开发了包含6,243个样本的Geo-Thought-6K数据集和10,834个样本的增强版Geo-Thought-Augmented-10K数据集，每个样本包含视觉描述、逐步解决方案、明确推理链、反思步骤和最终答案。基于此数据集训练了GeoThought-MLLM多模态数学推理模型。

Result: 模型在几何任务中超越了现有基准，表明使用Chain-of-Thought数据集训练能够提升几何推理能力，在领域内和领域外设置中均有改善。

Conclusion: 通过分析失败案例发现，错误主要源于数学概念的错误解释或空间判断错误，通过调用CoT纠正这些错误后，模型能够产生正确答案。

Abstract: Large language models (LLMs) have demonstrated strong reasoning capabilities
in text-based mathematical problem solving; however, when adapted to visual
reasoning tasks, particularly geometric problem solving, their performance
substantially declines because geometric problems present unique challenges.
Specifically, these challenges stem from two key factors: first, the intrinsic
complexity of geometry requiring detailed image comprehension and multi-step
reasoning, and second, the limitations of existing datasets which lack
sufficient scale, diversity, and explicit reasoning traces, consequently
hindering effective model training. To address these challenges, we developed
the GeoThoughts dataset, a comprehensive geometric reasoning corpus with two
subsets: Geo-Thought-6K with 6,243 samples and its augmented version
Geo-Thought-Augmented-10K containing 10,834 samples. Each entry includes visual
descriptions, step-by-step solutions, explicit reasoning chains, reflection
steps, and final answers. Using this dataset, we developed GeoThought-MLLM, a
mathematical reasoning multimodal model that generates detailed thinking
processes during problem-solving. Our model outperforms existing benchmarks in
geometric tasks, demonstrating that training with our Chain-of-Thought dataset
improves geometric reasoning capabilities across both in-domain and
out-of-domain settings. Finally, we analyze failure cases and observe that
errors primarily arise from incorrect interpretation of mathematical concepts
or spatial misjudgment. By invoking CoT to correct these mistakes, the model
produces correct answers.

</details>


### [76] [AutoStreamPipe: LLM Assisted Automatic Generation of Data Stream Processing Pipelines](https://arxiv.org/abs/2510.23408)
*Abolfazl Younesi,Zahra Najafabadi Samani,Thomas Fahringer*

Main category: cs.AI

TL;DR: AutoStreamPipe是一个使用大语言模型自动化设计和部署流处理管道的框架，通过超图思维(HGoT)技术显著减少了开发时间和错误率。


<details>
  <summary>Details</summary>
Motivation: 解决流处理管道开发中高层用户意图与平台特定实现之间的语义鸿沟，提高开发效率和准确性。

Method: 结合大语言模型和超图思维(HGoT)技术，集成弹性执行策略和高级查询分析，实现跨分布式流处理系统的多智能体推理。

Result: 实验评估显示，相比LLM代码生成方法，AutoStreamPipe将开发时间减少6.3倍，错误率降低5.19倍(通过新的无错误评分EFS衡量)。

Conclusion: AutoStreamPipe框架通过自动化流处理管道的设计、生成和部署，显著提升了开发效率和准确性，证明了其在现实应用中的有效性。

Abstract: Data pipelines are essential in stream processing as they enable the
efficient collection, processing, and delivery of real-time data, supporting
rapid data analysis. In this paper, we present AutoStreamPipe, a novel
framework that employs Large Language Models (LLMs) to automate the design,
generation, and deployment of stream processing pipelines. AutoStreamPipe
bridges the semantic gap between high-level user intent and platform-specific
implementations across distributed stream processing systems for structured
multi-agent reasoning by integrating a Hypergraph of Thoughts (HGoT) as an
extended version of GoT. AutoStreamPipe combines resilient execution
strategies, advanced query analysis, and HGoT to deliver pipelines with good
accuracy. Experimental evaluations on diverse pipelines demonstrate that
AutoStreamPipe significantly reduces development time (x6.3) and error rates
(x5.19), as measured by a novel Error-Free Score (EFS), compared to LLM
code-generation methods.

</details>


### [77] [Exploration through Generation: Applying GFlowNets to Structured Search](https://arxiv.org/abs/2510.21886)
*Mark Phillip Matovic*

Main category: cs.AI

TL;DR: 将生成流网络应用于旅行商问题、最小生成树和最短路径三个图优化问题，通过训练学习采样与奖励函数成比例的解决方案，生成结果与经典算法一致。


<details>
  <summary>Details</summary>
Motivation: 探索生成模型解决组合优化问题的能力，利用学习策略的优势实现计算可扩展性，为经典精确方法不可行的大规模问题提供潜在解决方案。

Method: 使用轨迹平衡损失训练GFlowNets，按顺序构建解决方案：为生成树选择边、为路径选择节点、为旅行选择城市。

Result: 在多种规模的基准实例上，GFlowNets学会找到最优解，生成解与经典算法（Dijkstra、Kruskal、TSP精确求解器）结果一致。训练收敛取决于问题复杂度，图规模越大所需训练轮次越多。

Conclusion: 生成模型可以通过学习策略解决组合优化问题，主要优势是计算可扩展性：经典算法每实例有固定复杂度，而GFlowNets通过训练分摊计算，在足够计算资源下可扩展到经典精确方法不可行的大规模问题。

Abstract: This work applies Generative Flow Networks (GFlowNets) to three graph
optimization problems: the Traveling Salesperson Problem, Minimum Spanning
Tree, and Shortest Path. GFlowNets are generative models that learn to sample
solutions proportionally to a reward function. The models are trained using the
Trajectory Balance loss to build solutions sequentially, selecting edges for
spanning trees, nodes for paths, and cities for tours. Experiments on benchmark
instances of varying sizes show that GFlowNets learn to find optimal solutions.
For each problem type, multiple graph configurations with different numbers of
nodes were tested. The generated solutions match those from classical
algorithms (Dijkstra for shortest path, Kruskal for spanning trees, and exact
solvers for TSP). Training convergence depends on problem complexity, with the
number of episodes required for loss stabilization increasing as graph size
grows. Once training converges, the generated solutions match known optima from
classical algorithms across the tested instances. This work demonstrates that
generative models can solve combinatorial optimization problems through learned
policies. The main advantage of this learning-based approach is computational
scalability: while classical algorithms have fixed complexity per instance,
GFlowNets amortize computation through training. With sufficient computational
resources, the framework could potentially scale to larger problem instances
where classical exact methods become infeasible.

</details>


### [78] [Computational Hardness of Reinforcement Learning with Partial $q^π$-Realizability](https://arxiv.org/abs/2510.21888)
*Shayan Karimi,Xiaoqi Tan*

Main category: cs.AI

TL;DR: 本文研究了在线性函数逼近新框架（部分q^π可实现性）中强化学习的计算复杂性，证明在该设置下学习ε最优策略是计算困难的。


<details>
  <summary>Details</summary>
Motivation: 研究部分q^π可实现性框架的计算复杂性，该框架假设策略集中所有策略的价值函数都是线性可实现的，比q^π可实现性弱但比q^*可实现性强，提供了一个函数逼近自然出现的实用模型。

Method: 通过从δ-Max-3SAT和δ-Max-3SAT(b)问题归约到GLinear-κ-RL（贪婪策略）和SLinear-κ-RL（softmax策略）实例，建立计算复杂性结果。

Result: 证明了在参数化贪婪策略集下学习ε最优策略是NP困难的，在softmax策略集下（除非NP=RP）存在指数级下界（特征向量维度）。

Conclusion: 计算困难性在部分q^π可实现性中持续存在，即使策略集扩展到最优策略之外，与q^*可实现性中的结果相似，表明在该框架下通常无法获得积极的计算结果。

Abstract: This paper investigates the computational complexity of reinforcement
learning in a novel linear function approximation regime, termed partial
$q^{\pi}$-realizability. In this framework, the objective is to learn an
$\epsilon$-optimal policy with respect to a predefined policy set $\Pi$, under
the assumption that all value functions for policies in $\Pi$ are linearly
realizable. The assumptions of this framework are weaker than those in
$q^{\pi}$-realizability but stronger than those in $q^*$-realizability,
providing a practical model where function approximation naturally arises. We
prove that learning an $\epsilon$-optimal policy in this setting is
computationally hard. Specifically, we establish NP-hardness under a
parameterized greedy policy set (argmax) and show that - unless NP = RP - an
exponential lower bound (in feature vector dimension) holds when the policy set
contains softmax policies, under the Randomized Exponential Time Hypothesis.
Our hardness results mirror those in $q^*$-realizability and suggest
computational difficulty persists even when $\Pi$ is expanded beyond the
optimal policy. To establish this, we reduce from two complexity problems,
$\delta$-Max-3SAT and $\delta$-Max-3SAT(b), to instances of GLinear-$\kappa$-RL
(greedy policy) and SLinear-$\kappa$-RL (softmax policy). Our findings indicate
that positive computational results are generally unattainable in partial
$q^{\pi}$-realizability, in contrast to $q^{\pi}$-realizability under a
generative access model.

</details>


### [79] [Performance Trade-offs of Optimizing Small Language Models for E-Commerce](https://arxiv.org/abs/2510.21970)
*Josip Tomo Licardo,Nikola Tankovic*

Main category: cs.AI

TL;DR: 本文研究了使用小型开源模型替代大型商业模型进行电商意图识别的可行性，展示了1B参数模型通过优化后能达到与GPT-4.1相当的99%准确率，同时大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型商业模型在电商等专业任务中部署面临高计算成本、延迟和运营费用的问题，需要寻找资源效率更高的替代方案。

Method: 采用量化低秩适应(QLoRA)微调10亿参数Llama 3.2模型，使用合成数据集模拟真实用户查询，并应用后训练量化技术创建GPU优化(GPTQ)和CPU优化(GGUF)版本。

Result: 专用1B模型达到99%准确率，与GPT-4.1性能相当。4位GPTQ减少41%显存使用但推理速度下降82%，GGUF格式在CPU上实现18倍推理吞吐量提升和90%以上内存消耗减少。

Conclusion: 经过适当优化的小型开源模型不仅是可行的，而且是领域特定应用更合适的选择，能以极低计算成本提供最先进的准确性。

Abstract: Large Language Models (LLMs) offer state-of-the-art performance in natural
language understanding and generation tasks. However, the deployment of leading
commercial models for specialized tasks, such as e-commerce, is often hindered
by high computational costs, latency, and operational expenses. This paper
investigates the viability of smaller, open-weight models as a
resource-efficient alternative. We present a methodology for optimizing a
one-billion-parameter Llama 3.2 model for multilingual e-commerce intent
recognition. The model was fine-tuned using Quantized Low-Rank Adaptation
(QLoRA) on a synthetically generated dataset designed to mimic real-world user
queries. Subsequently, we applied post-training quantization techniques,
creating GPU-optimized (GPTQ) and CPU-optimized (GGUF) versions. Our results
demonstrate that the specialized 1B model achieves 99% accuracy, matching the
performance of the significantly larger GPT-4.1 model. A detailed performance
analysis revealed critical, hardware-dependent trade-offs: while 4-bit GPTQ
reduced VRAM usage by 41%, it paradoxically slowed inference by 82% on an older
GPU architecture (NVIDIA T4) due to dequantization overhead. Conversely, GGUF
formats on a CPU achieved a speedup of up to 18x in inference throughput and a
reduction of over 90% in RAM consumption compared to the FP16 baseline. We
conclude that small, properly optimized open-weight models are not just a
viable but a more suitable alternative for domain-specific applications,
offering state-of-the-art accuracy at a fraction of the computational cost.

</details>


### [80] [Distribution Shift Alignment Helps LLMs Simulate Survey Response Distributions](https://arxiv.org/abs/2510.21977)
*Ji Huang,Mengfei Li,Shuai Shao*

Main category: cs.AI

TL;DR: 提出了一种名为分布偏移对齐（DSA）的两阶段微调方法，用于提高LLM模拟人类调查响应的准确性，显著减少真实数据需求


<details>
  <summary>Details</summary>
Motivation: 现有零样本方法存在提示敏感性和低准确性问题，而传统微调方法过度拟合训练集分布，无法产生比训练集更准确的结果

Method: DSA通过两阶段微调方法，对齐输出分布和不同背景下的分布偏移，学习分布变化而非拟合训练数据

Result: 在五个公共调查数据集上，DSA始终优于其他方法，能够将真实数据需求减少53.48-69.12%

Conclusion: DSA在调查模拟中表现出色，能够提供比训练数据更接近真实分布的结果，具有高效性和有效性

Abstract: Large language models (LLMs) offer a promising way to simulate human survey
responses, potentially reducing the cost of large-scale data collection.
However, existing zero-shot methods suffer from prompt sensitivity and low
accuracy, while conventional fine-tuning approaches mostly fit the training set
distributions and struggle to produce results more accurate than the training
set itself, which deviates from the original goal of using LLMs to simulate
survey responses. Building on this observation, we introduce Distribution Shift
Alignment (DSA), a two-stage fine-tuning method that aligns both the output
distributions and the distribution shifts across different backgrounds. By
learning how these distributions change rather than fitting training data, DSA
can provide results substantially closer to the true distribution than the
training data. Empirically, DSA consistently outperforms other methods on five
public survey datasets. We further conduct a comprehensive comparison covering
accuracy, robustness, and data savings. DSA reduces the required real data by
53.48-69.12%, demonstrating its effectiveness and efficiency in survey
simulation.

</details>


### [81] [Foundation of Intelligence: Review of Math Word Problems from Human Cognition Perspective](https://arxiv.org/abs/2510.21999)
*Zhenya Huang,Jiayu Liu,Xin Lin,Zhiyuan Ma,Shangzi Xue,Tong Xiao,Qi Liu,Yee Whye Teh,Enhong Chen*

Main category: cs.AI

TL;DR: 这篇论文从人类认知角度系统回顾了数学应用题求解研究，总结了5个关键认知能力，比较了神经网络求解器和基于大语言模型的求解器，并统一评估了它们在5个主流基准上的性能。


<details>
  <summary>Details</summary>
Motivation: 数学应用题作为人工智能基础研究领域，旨在通过模拟人类认知智能来推进AI推理能力。然而该领域缺乏系统分类和当前发展趋势的讨论，因此需要从人类认知角度全面回顾相关研究。

Method: 从人类认知视角总结5个关键认知能力（问题理解、逻辑组织、联想记忆、批判性思维、知识学习），回顾近10年两种主流模型（神经网络求解器、LLM求解器），重新运行代表性求解器并在5个基准上进行统一比较。

Result: 首次从人类推理认知角度全面分析过去十年有影响力的MWP研究，提供了现有方法的整体比较，展示了AI模型在模拟人类认知能力方面的进展。

Conclusion: 这项调查为AI推理领域的进一步研究提供了启发，通过人类认知视角的系统分析有助于推动AI推理能力的发展。

Abstract: Math word problem (MWP) serves as a fundamental research topic in artificial
intelligence (AI) dating back to 1960s. This research aims to advance the
reasoning abilities of AI by mirroring the human-like cognitive intelligence.
The mainstream technological paradigm has evolved from the early rule-based
methods, to deep learning models, and is rapidly advancing towards large
language models. However, the field still lacks a systematic taxonomy for the
MWP survey along with a discussion of current development trends. Therefore, in
this paper, we aim to comprehensively review related research in MWP solving
through the lens of human cognition, to demonstrate how recent AI models are
advancing in simulating human cognitive abilities. Specifically, we summarize 5
crucial cognitive abilities for MWP solving, including Problem Understanding,
Logical Organization, Associative Memory, Critical Thinking, and Knowledge
Learning. Focused on these abilities, we review two mainstream MWP models in
recent 10 years: neural network solvers, and LLM based solvers, and discuss the
core human-like abilities they demonstrated in their intricate problem-solving
process. Moreover, we rerun all the representative MWP solvers and supplement
their performance on 5 mainstream benchmarks for a unified comparison. To the
best of our knowledge, this survey first comprehensively analyzes the
influential MWP research of the past decade from the perspective of human
reasoning cognition and provides an integrative overall comparison across
existing approaches. We hope it can inspire further research in AI reasoning.
Our repository is released on https://github.com/Ljyustc/FoI-MWP.

</details>


### [82] [LightAgent: Mobile Agentic Foundation Models](https://arxiv.org/abs/2510.22009)
*Yangqin Jiang,Chao Huang*

Main category: cs.AI

TL;DR: LightAgent是一个移动GUI代理系统，通过设备-云协作解决移动设备上小模型性能不足而大模型部署成本高的问题，在保持高性能的同时显著降低云成本。


<details>
  <summary>Details</summary>
Motivation: 移动GUI代理面临关键困境：真正在设备上的小模型（4B或更小）性能不足，而能力强的模型（从7B开始）要么太大无法在移动设备部署，要么成本过高（如仅限云的闭源MLLMs）。

Method: 通过两阶段SFT->GRPO训练增强Qwen2.5-VL-3B模型，集成高效长推理机制利用历史交互，默认在设备上执行，仅通过实时复杂度评估将具有挑战性的子任务升级到云端。

Result: 在AndroidLab基准测试和多样化应用上的实验表明，LightAgent匹配或接近更大模型的性能，同时显著降低了云成本。

Conclusion: LightAgent通过设备-云协作成功解决了移动GUI代理的部署困境，在保持高性能的同时实现了成本效益。

Abstract: With the advancement of multimodal large language models (MLLMs), building
GUI agent systems has become an increasingly promising direction-especially for
mobile platforms, given their rich app ecosystems and intuitive touch
interactions. Yet mobile GUI agents face a critical dilemma: truly on-device
models (4B or smaller) lack sufficient performance, while capable models
(starting from 7B) are either too large for mobile deployment or prohibitively
costly (e.g., cloud-only closed-source MLLMs). To resolve this, we propose
LightAgent, a mobile agentic foundation model solution that leverages
device-cloud collaboration to tap the cost-efficiency of on-device models and
the high capability of cloud models, while avoiding their drawbacks.
Specifically, LightAgent enhances Qwen2.5-VL-3B via two-stage SFT->GRPO
training on synthetic GUI data for strong decision-making, integrates an
efficient long-reasoning mechanism to utilize historical interactions under
tight resources, and defaults to on-device execution-only escalating
challenging subtasks to the cloud via real-time complexity assessment.
Experiments on the online AndroidLab benchmark and diverse apps show LightAgent
matches or nears larger models, with a significant reduction in cloud costs.

</details>


### [83] [LLM-AR: LLM-powered Automated Reasoning Framework](https://arxiv.org/abs/2510.22034)
*Rick Chen,Joseph Ternasky,Aaron Ontoyin Yin,Xianling Mu,Fuat Alican,Yigit Ihlamur*

Main category: cs.AI

TL;DR: LLM-AR是一个从大语言模型中提取启发式规则，通过ProbLog自动推理引擎执行的神经符号系统管道，用于基于创始人特征预测初创企业成功，实现了59.5%的精确度和8.7%的召回率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然具备模式识别和推理能力，但其准确性不稳定，限制了在高风险决策应用中的采用。本文从风险投资角度研究如何基于创始人特征预测初创企业成功。

Method: 提出LLM-AR管道，受神经符号系统启发，将LLM生成的启发式规则提炼为概率规则，由ProbLog自动推理引擎执行。采用迭代策略进化循环，结合关联规则挖掘逐步优化预测规则。

Result: 在未见数据上，LLM-AR达到59.5%的精确度和8.7%的召回率，是随机基线精确度的5.9倍，同时所有决策路径都可供人工检查。

Conclusion: 该框架具有可解释性和可通过超参数调节的特性，显示出扩展到其他领域的潜力。

Abstract: Large language models (LLMs) can already identify patterns and reason
effectively, yet their variable accuracy hampers adoption in high-stakes
decision-making applications. In this paper, we study this issue from a venture
capital perspective by predicting idea-stage startup success based on founder
traits. (i) To build a reliable prediction model, we introduce LLM-AR, a
pipeline inspired by neural-symbolic systems that distils LLM-generated
heuristics into probabilistic rules executed by the ProbLog automated-reasoning
engine. (ii) An iterative policy-evolution loop incorporates association-rule
mining to progressively refine the prediction rules.
  On unseen folds, LLM-AR achieves 59.5% precision and 8.7% recall, 5.9x the
random baseline precision, while exposing every decision path for human
inspection. The framework is interpretable and tunable via hyperparameters,
showing promise to extend into other domains.

</details>


### [84] [Predictive Coding Enhances Meta-RL To Achieve Interpretable Bayes-Optimal Belief Representation Under Partial Observability](https://arxiv.org/abs/2510.22039)
*Po-Chen Kuo,Han Hou,Will Dabney,Edgar Y. Walker*

Main category: cs.AI

TL;DR: 在部分可观测环境中，传统元强化学习虽然能学习到接近贝叶斯最优的策略，但无法学习到紧凑、可解释的贝叶斯最优信念状态。通过引入基于预测编码的自监督预测模块，元强化学习能够学习到更接近贝叶斯最优的表示，在需要主动信息寻求的挑战性任务中表现更好，并具有更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统元强化学习在部分可观测环境中虽然能获得接近贝叶斯最优的策略，但无法学习到紧凑、可解释的贝叶斯最优信念状态，这种表示效率低下可能限制智能体的适应性和泛化能力。

Method: 将基于预测编码的自监督预测模块集成到元强化学习中，受神经科学中预测编码（大脑通过预测感官输入实现贝叶斯推断）和深度强化学习中辅助预测目标的启发。

Result: 通过状态机模拟显示，带有预测模块的元强化学习在各种任务中都能产生更可解释的表示，更好地逼近贝叶斯最优信念状态。在需要主动信息寻求的挑战性任务中，只有带预测模块的元强化学习能成功学习最优表示和策略，而传统元强化学习因表示学习不足而失败。

Conclusion: 预测学习作为指导原则，在智能体导航部分可观测性时能够促进有效的表示学习，更好的表示学习带来了改进的泛化能力。

Abstract: Learning a compact representation of history is critical for planning and
generalization in partially observable environments. While meta-reinforcement
learning (RL) agents can attain near Bayes-optimal policies, they often fail to
learn the compact, interpretable Bayes-optimal belief states. This
representational inefficiency potentially limits the agent's adaptability and
generalization capacity. Inspired by predictive coding in neuroscience--which
suggests that the brain predicts sensory inputs as a neural implementation of
Bayesian inference--and by auxiliary predictive objectives in deep RL, we
investigate whether integrating self-supervised predictive coding modules into
meta-RL can facilitate learning of Bayes-optimal representations. Through state
machine simulation, we show that meta-RL with predictive modules consistently
generates more interpretable representations that better approximate
Bayes-optimal belief states compared to conventional meta-RL across a wide
variety of tasks, even when both achieve optimal policies. In challenging tasks
requiring active information seeking, only meta-RL with predictive modules
successfully learns optimal representations and policies, whereas conventional
meta-RL struggles with inadequate representation learning. Finally, we
demonstrate that better representation learning leads to improved
generalization. Our results strongly suggest the role of predictive learning as
a guiding principle for effective representation learning in agents navigating
partial observability.

</details>


### [85] [HW/SW Co-design of a PCM/PWM converter: a System Level Approach based in the SpecC Methodology](https://arxiv.org/abs/2510.22046)
*Daniel G. P. Petrini,Braz Izaias da Silva Junior*

Main category: cs.AI

TL;DR: 应用SpecC方法学对PCM-to-PWM转换器进行系统级硬件/软件协同设计，通过建模和架构探索实现优化的HW/SW划分，在满足实时约束的同时降低全硬件方案的成本。


<details>
  <summary>Details</summary>
Motivation: 研究系统级硬件/软件协同设计方法在PCM-to-PWM转换器（Class-D音频放大器核心）中的应用价值，探索如何在满足实时性能要求的同时优化成本效益。

Method: 使用SpecC方法学对PCM-to-PWM转换器进行建模和架构探索，通过系统级评估和快速功能仿真来评估不同的硬件/软件划分方案。

Result: 成功实现了满足实时约束的硬件/软件划分方案，相比全硬件解决方案降低了估计成本，同时避免了在高性能处理器上纯软件实现的高昂费用。

Conclusion: 即使对于中等复杂度的设计，系统级协同设计方法仍能提供早期架构洞察、快速验证以及可行的成本/性能权衡，证明了该方法的价值。

Abstract: We present a case study applying the SpecC methodology within a system-level
hardware/software co-design flow to a PCM-to-PWM converter, the core of a
Class-D audio amplifier. The converter was modeled and explored with SpecC
methodology to derive an HW/SW partition. Using system-level estimates and fast
functional simulation, we evaluated mappings that meet real-time constraints
while reducing estimated cost of an all-hardware solution and avoiding the
expense of a purely software implementation on a high-end processor. Despite
the design's moderate complexity, the results underline the value of
system-level co-design for early architectural insight, rapid validation, and
actionable cost/performance trade-offs. [Original work from 2005; formatting
revised in 2025, with no changes to the results.]

</details>


### [86] [Towards Error-Centric Intelligence II: Energy-Structured Causal Models](https://arxiv.org/abs/2510.22050)
*Marcus Thomas*

Main category: cs.AI

TL;DR: 本文提出从预测准确性转向因果解释性的概念转向，引入计算解释和能量结构化因果模型(ESCMs)，使系统内部结构可干预和操作。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习系统虽然预测性能优异，但因果透明度不足，无法对特定机制进行外科手术式编辑，因为学习到的潜在变量缺乏因果语义。

Method: 引入计算解释和能量结构化因果模型(ESCMs)，将机制表达为约束(能量函数或向量场)而非显式输入输出映射，干预通过局部手术作用于这些约束。

Result: 在ESCM背景下实例化了结构因果原则LAP和ICM，分析了经验风险最小化产生断裂纠缠表示的问题，并证明在温和条件下ESCMs恢复标准SCM语义。

Conclusion: 本文为因果推理提供了形式化语言，使系统能够理解而不仅仅是预测，建立在Part I的原则(LAP、ICM、CAP)和智能作为批评下构建解释的定义之上。

Abstract: Contemporary machine learning optimizes for predictive accuracy, yet systems
that achieve state of the art performance remain causally opaque: their
internal representations provide no principled handle for intervention. We can
retrain such models, but we cannot surgically edit specific mechanisms while
holding others fixed, because learned latent variables lack causal semantics.
We argue for a conceptual reorientation: intelligence is the ability to build
and refine explanations, falsifiable claims about manipulable structure that
specify what changes and what remains invariant under intervention.
Explanations subsume prediction but demand more: causal commitments that can be
independently tested and corrected at the level of mechanisms. We introduce
computational explanations, mappings from observations to intervention ready
causal accounts. We instantiate these explanations with Energy Structured
Causal Models (ESCMs), in which mechanisms are expressed as constraints (energy
functions or vector fields) rather than explicit input output maps, and
interventions act by local surgery on those constraints. This shift makes
internal structure manipulable at the level where explanations live: which
relations must hold, which can change, and what follows when they do. We
provide concrete instantiations of the structural-causal principles LAP and ICM
in the ESCM context, and also argue that empirical risk minimization
systematically produces fractured, entangled representations, a failure we
analyze as gauge ambiguity in encoder energy pairs. Finally, we show that under
mild conditions, ESCMs recover standard SCM semantics. Building on Part I's
principles (LAP, ICM, CAP) and its definition of intelligence as
explanation-building under criticism, this paper offers a formal language for
causal reasoning in systems that aspire to understand, not merely to predict.

</details>


### [87] [Energy-Efficient Domain-Specific Artificial Intelligence Models and Agents: Pathways and Paradigms](https://arxiv.org/abs/2510.22052)
*Abhijit Chatterjee,Niraj K. Jha,Jonathan D. Cohen,Thomas L. Griffiths,Hongjing Lu,Diana Marculescu,Ashiqur Rasul,Keshab K. Parhi*

Main category: cs.AI

TL;DR: 该论文提出下一代AI发展方向：从当前耗能巨大的大型语言模型转向轻量级、领域特定的多模态智能体，这些智能体能够在动态环境中进行推理、规划和决策，同时实现超过现有技术1000倍的能效。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型（如GPT-4）训练需要大量数据和能源（50-60 GWh），且存在幻觉问题，无法应用于关键领域。相比之下，人脑仅消耗20W功率，需要开发更节能、更智能的AI系统。

Method: 提出开发轻量级领域特定多模态模型，这些模型能够：1）在动态环境中进行推理、规划和决策；2）处理实时数据和先验知识；3）持续学习并增强未来决策能力；4）重新设计硬件以实现超过现有技术1000倍的能效。

Result: 构建了未来AI系统的愿景框架，从当前基于海量数据训练的大型模型转向能够在不稳定世界中思考和推理的节能领域特定智能体。

Conclusion: 下一代AI需要实现从大型通用模型到节能、领域特定智能体的转变，这需要硬件和算法的协同创新，以实现超过1000倍的能效提升，从而推动AI在关键应用领域的部署。

Abstract: The field of artificial intelligence (AI) has taken a tight hold on broad
aspects of society, industry, business, and governance in ways that dictate the
prosperity and might of the world's economies. The AI market size is projected
to grow from 189 billion USD in 2023 to 4.8 trillion USD by 2033. Currently, AI
is dominated by large language models that exhibit linguistic and visual
intelligence. However, training these models requires a massive amount of data
scraped from the web as well as large amounts of energy (50--60 GWh to train
GPT-4). Despite these costs, these models often hallucinate, a characteristic
that prevents them from being deployed in critical application domains. In
contrast, the human brain consumes only 20~W of power. What is needed is the
next level of AI evolution in which lightweight domain-specific multimodal
models with higher levels of intelligence can reason, plan, and make decisions
in dynamic environments with real-time data and prior knowledge, while learning
continuously and evolving in ways that enhance future decision-making
capability. This will define the next wave of AI, progressing from today's
large models, trained with vast amounts of data, to nimble energy-efficient
domain-specific agents that can reason and think in a world full of
uncertainty. To support such agents, hardware will need to be reimagined to
allow energy efficiencies greater than 1000x over the state of the art. Such a
vision of future AI systems is developed in this work.

</details>


### [88] [Embracing Trustworthy Brain-Agent Collaboration as Paradigm Extension for Intelligent Assistive Technologies](https://arxiv.org/abs/2510.22095)
*Yankai Chen,Xinni Zhang,Yifei Zhang,Yangning Li,Henry Peng Zou,Chunyu Miao,Weizhi Zhang,Xue Liu,Philip S. Yu*

Main category: cs.AI

TL;DR: 该立场论文主张从脑机接口(BCI)扩展到脑-智能体协作(BAC)的范式转变，强调将智能体重新定义为主动协作伙伴而非被动脑信号处理器，并关注伦理数据管理、模型可靠性和人-智能体协作框架。


<details>
  <summary>Details</summary>
Motivation: 脑机接口存在信息传输率低和用户特定校准繁琐等限制，虽然大型语言模型的集成有所进展，但部署代理AI面临技术障碍和伦理担忧，需要对此新兴方向进行综合讨论。

Method: 提出从BCI到BAC的范式扩展，将智能体重新定位为主动协作伙伴，要求关注伦理数据管理、模型可靠性和人-智能体协作框架。

Result: 确立了脑-智能体协作(BAC)作为新的研究范式，强调智能体应作为主动协作伙伴而非被动处理器。

Conclusion: 脑机接口领域需要进行从BCI到BAC的范式扩展，确保这些系统安全、可信且有效，需要重点关注伦理数据管理、模型可靠性和人-智能体协作框架。

Abstract: Brain-Computer Interfaces (BCIs) offer a direct communication pathway between
the human brain and external devices, holding significant promise for
individuals with severe neurological impairments. However, their widespread
adoption is hindered by critical limitations, such as low information transfer
rates and extensive user-specific calibration. To overcome these challenges,
recent research has explored the integration of Large Language Models (LLMs),
extending the focus from simple command decoding to understanding complex
cognitive states. Despite these advancements, deploying agentic AI faces
technical hurdles and ethical concerns. Due to the lack of comprehensive
discussion on this emerging direction, this position paper argues that the
field is poised for a paradigm extension from BCI to Brain-Agent Collaboration
(BAC). We emphasize reframing agents as active and collaborative partners for
intelligent assistance rather than passive brain signal data processors,
demanding a focus on ethical data handling, model reliability, and a robust
human-agent collaboration framework to ensure these systems are safe,
trustworthy, and effective.

</details>


### [89] [Controllable Mathematical Reasoning via Self-Optimizing Thought Vectors](https://arxiv.org/abs/2510.22132)
*Xuying LI*

Main category: cs.AI

TL;DR: 提出了一种基于自优化思维向量和熵最小化的可控数学推理方法，通过可学习的思维向量动态调制大语言模型的内部推理过程。


<details>
  <summary>Details</summary>
Motivation: 为了解决大语言模型在数学推理中缺乏可控性的问题，开发一种能够动态引导推理过程的方法，而不需要外部奖励标注。

Method: 使用可学习的思维向量动态调制大语言模型的内部推理过程，通过熵最小化奖励来引导聚焦推理模式。

Result: 在GSM8K数据集上使用Gemma-2-9B模型达到了90.1%的准确率，可控性得分为0.42，思维向量形成了明显的聚类，控制条件下呈现一致的低熵分布。

Conclusion: 该框架通过熵最小化有效实现了可控AI推理，验证了思维向量在引导推理模式方面的有效性。

Abstract: We present a novel approach for controllable mathematical reasoning that
leverages self-optimizing thought vectors with entropy minimization. Our method
introduces learnable thought vectors that dynamically modulate the internal
reasoning process of large language models. Using Gemma-2-9B on GSM8K, we
achieve 90.1% accuracy with a controllability score of 0.42, demonstrating that
entropy-based rewards effectively guide focused reasoning patterns without
requiring external reward annotations. Our analysis reveals distinct thought
vector clusters and consistent low-entropy distributions across control
conditions, validating our framework for controllable AI reasoning.

</details>


### [90] [Measure what Matters: Psychometric Evaluation of AI with Situational Judgment Tests](https://arxiv.org/abs/2510.22170)
*Alexandra Yost,Shreyans Jain,Shivam Raval,Grant Corser,Allen Roush,Nina Xu,Jacqueline Hammack,Ravid Shwartz-Ziv,Amirali Abdullah*

Main category: cs.AI

TL;DR: 提出了一个AI心理测量框架，使用情境判断测试和复杂人设设计来评估AI系统在需要情感判断和伦理考量的角色中的表现，并在执法助手案例中构建了包含8500个人设、4000个SJT和30万个响应的数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的AI心理测量方法通常重用人类特质清单或临时人设，限制了行为真实性和领域相关性，需要更现实和领域特定的评估框架。

Method: 框架包含三个部分：(1)使用现实场景的情境判断测试探测领域特定能力；(2)整合工业组织心理学和人格心理学设计复杂人设；(3)采用结构化生成方法，包含人口统计先验和回忆录式叙事。

Result: 在执法助手案例研究中，构建了涵盖8个人设原型和11个属性的丰富数据集，包含8500个人设、4000个SJT和30万个响应。

Conclusion: 该框架提供了更现实和领域相关的AI心理测量方法，并将公开发布数据集和代码。

Abstract: AI psychometrics evaluates AI systems in roles that traditionally require
emotional judgment and ethical consideration. Prior work often reuses human
trait inventories (Big Five, \hexaco) or ad hoc personas, limiting behavioral
realism and domain relevance. We propose a framework that (1) uses situational
judgment tests (SJTs) from realistic scenarios to probe domain-specific
competencies; (2) integrates industrial-organizational and personality
psychology to design sophisticated personas which include behavioral and
psychological descriptors, life history, and social and emotional functions;
and (3) employs structured generation with population demographic priors and
memoir inspired narratives, encoded with Pydantic schemas. In a law enforcement
assistant case study, we construct a rich dataset of personas drawn across 8
persona archetypes and SJTs across 11 attributes, and analyze behaviors across
subpopulation and scenario slices. The dataset spans 8,500 personas, 4,000
SJTs, and 300,000 responses. We will release the dataset and all code to the
public.

</details>


### [91] [Dopamine-driven synaptic credit assignment in neural networks](https://arxiv.org/abs/2510.22178)
*Saranraj Nambusubramaniyan,Shervin Safavi,Raja Guru,Andreas Knoblauch*

Main category: cs.AI

TL;DR: 本文提出了一种名为Dopamine的无导数优化器，通过权重扰动学习和奖励预测误差来训练神经网络，解决了反向传播的计算效率和生物合理性问题。


<details>
  <summary>Details</summary>
Motivation: 解决突触信用分配问题(CAP)是神经网络学习的关键。反向传播虽然能解决CAP，但存在计算效率低、内存消耗大、权重传输和更新锁定等问题，缺乏生物合理性。

Method: 采用神经AI方法，受神经强化学习启发，开发Dopamine优化器。通过权重扰动学习，利用权重随机更新来寻找最优解，通过最小化期望结果与实际结果之间的奖励预测误差来调整学习率。

Result: 在XOR任务和混沌时间序列预测任务中，Dopamine训练的多层感知机和循环神经网络表现出加速收敛，优于标准权重扰动方法，性能与基于梯度的算法相当，同时计算和内存消耗显著减少。

Conclusion: Dopamine优化器不仅找到了稳健解，性能与最先进的机器学习优化器相当，而且在神经生物学上更加合理。

Abstract: Solving the synaptic Credit Assignment Problem(CAP) is central to learning in
both biological and artificial neural systems. Finding an optimal solution for
synaptic CAP means setting the synaptic weights that assign credit to each
neuron for influencing the final output and behavior of neural networks or
animals. Gradient-based methods solve this problem in artificial neural
networks using back-propagation, however, not in the most efficient way. For
instance, back-propagation requires a chain of top-down gradient computations.
This leads to an expensive optimization process in terms of computing power and
memory linked with well-known weight transport and update locking problems. To
address these shortcomings, we take a NeuroAI approach and draw inspiration
from neural Reinforcement Learning to develop a derivative-free optimizer for
training neural networks, Dopamine. Dopamine is developed for Weight
Perturbation (WP) learning that exploits stochastic updating of weights towards
optima. It achieves this by minimizing the regret, a form of Reward Prediction
Error (RPE) between the expected outcome from the perturbed model and the
actual outcome from the unperturbed model. We use this RPE to adjust the
learning rate in the network (i.e., creating an adaptive learning rate
strategy, similar to the role of dopamine in the brain). We tested the Dopamine
optimizer for training multi-layered perceptrons for XOR tasks, and recurrent
neural networks for chaotic time series forecasting. Dopamine-trained models
demonstrate accelerated convergence and outperform standard WP, and give
comparable performance to gradient-based algorithms, while consuming
significantly less computation and memory. Overall, the Dopamine optimizer not
only finds robust solutions and comparable performance to the state-of-the-art
Machine Learning optimizers but is also neurobiologically more plausible.

</details>


### [92] [OptiTree: Hierarchical Thoughts Generation with Tree Search for LLM Optimization Modeling](https://arxiv.org/abs/2510.22192)
*Haoyang Liu,Jie Wang,Yuyang Cai,Xiongwei Han,Yufei Kuang,Jianye Hao*

Main category: cs.AI

TL;DR: OptiTree是一种基于树搜索的自适应问题分解方法，通过将复杂运筹学问题分解为更简单的子问题来提升建模能力，相比现有方法在基准测试中实现了超过10%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用固定步骤分解来生成变量、约束和目标，但由于运筹学问题具有高度复杂的数学结构，这种方法往往无法达到高性能。需要一种能够自适应分解复杂问题的方法。

Method: 开发了一个建模树，基于运筹学问题的层次化问题分类和复杂性组织问题，每个节点代表一个问题类别并包含相关的高级建模思路。通过递归搜索树来识别更简单的子问题，并自适应整合层次化思路来合成全局建模思路。

Result: 实验表明，OptiTree相比最先进方法显著提高了建模准确率，在具有挑战性的基准测试中实现了超过10%的改进。

Conclusion: OptiTree通过自适应问题分解和层次化思路整合，有效提升了复杂运筹学问题的建模能力，为解决高度技术性的运筹学建模问题提供了新方法。

Abstract: Optimization modeling is one of the most crucial but technical parts of
operations research (OR). To automate the modeling process, existing works have
leveraged large language models (LLMs), prompting them to break down tasks into
steps for generating variables, constraints, and objectives. However, due to
the highly complex mathematical structures inherent in OR problems, standard
fixed-step decomposition often fails to achieve high performance. To address
this challenge, we introduce OptiTree, a novel tree search approach designed to
enhance modeling capabilities for complex problems through adaptive problem
decomposition into simpler subproblems. Specifically, we develop a modeling
tree that organizes a wide range of OR problems based on their hierarchical
problem taxonomy and complexity, with each node representing a problem category
and containing relevant high-level modeling thoughts. Given a problem to model,
we recurrently search the tree to identify a series of simpler subproblems and
synthesize the global modeling thoughts by adaptively integrating the
hierarchical thoughts. Experiments show that OptiTree significantly improves
the modeling accuracy compared to the state-of-the-art, achieving over 10\%
improvements on the challenging benchmarks. The code is released at
https://github.com/MIRALab-USTC/OptiTree/tree/main.

</details>


### [93] [PACR: Progressively Ascending Confidence Reward for LLM Reasoning](https://arxiv.org/abs/2510.22255)
*Eunseop Yoon,Hee Suk Yoon,Jaehyun Jang,SooHwan Eom,Qi Dai,Chong Luo,Mark A. Hasegawa-Johnson,Chang D. Yoo*

Main category: cs.AI

TL;DR: 提出了PACR（渐进上升置信度奖励），一种基于模型内在信念的密集奖励机制，用于改进RLVR训练中的探索效率。


<details>
  <summary>Details</summary>
Motivation: RLVR的稀疏、基于结果的奖励无法为中间推理步骤提供指导，导致探索缓慢。

Method: 使用模型对正确答案概率的渐进上升趋势作为密集奖励信号，约束探索空间到逻辑合理的推理区域。

Result: PACR加速了探索，用更少的轨迹达到奖励饱和，并在多个基准测试中取得改进。

Conclusion: 密集的模型内在塑造信号可以使RLVR训练更有效和可靠。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has significantly
improved LLM reasoning, but its sparse, outcome-based reward provides no
guidance for intermediate steps, slowing exploration. We propose Progressively
Ascending Confidence Reward (PACR), a dense, model-intrinsic reward computed
directly from the model's evolving belief in the correct answer. PACR encodes
the inductive bias that, along a well-formed reasoning trajectory, the
probability of the ground-truth answer should have a generally ascending trend.
We provide empirical and theoretical analysis validating that such an inductive
bias constrains the exploration search space to regions richer in logically
sound reasoning. We demonstrate that PACR accelerates exploration, reaches
reward saturation with fewer trajectories, and yields improvements on multiple
benchmarks. Our results suggest that dense, model-intrinsic shaping signals can
make RLVR training more effective and reliable.

</details>


### [94] [VietLyrics: A Large-Scale Dataset and Models for Vietnamese Automatic Lyrics Transcription](https://arxiv.org/abs/2510.22295)
*Quoc Anh Nguyen,Bernard Cheng,Kelvin Soh*

Main category: cs.AI

TL;DR: 创建了首个大规模越南语歌词转录数据集VietLyrics，通过微调Whisper模型在越南语歌词转录任务上取得了优于现有多语言系统的性能。


<details>
  <summary>Details</summary>
Motivation: 越南语歌词转录面临音调复杂性和方言变异的独特挑战，但由于缺乏专用数据集而未被充分探索。

Method: 构建了包含647小时歌曲的VietLyrics数据集，并对Whisper模型进行微调。

Result: 微调后的Whisper模型在越南语歌词转录任务上表现优于现有的多语言系统，包括LyricWhiz。

Conclusion: 该方法展示了在低资源语言和音乐领域进行歌词转录的潜力，并公开发布了数据集和模型以推动越南音乐计算研究。

Abstract: Automatic Lyrics Transcription (ALT) for Vietnamese music presents unique
challenges due to its tonal complexity and dialectal variations, but remains
largely unexplored due to the lack of a dedicated dataset. Therefore, we
curated the first large-scale Vietnamese ALT dataset (VietLyrics), comprising
647 hours of songs with line-level aligned lyrics and metadata to address these
issues. Our evaluation of current ASRbased approaches reveal significant
limitations, including frequent transcription errors and hallucinations in
non-vocal segments. To improve performance, we fine-tuned Whisper models on the
VietLyrics dataset, achieving superior results compared to existing
multilingual ALT systems, including LyricWhiz. We publicly release VietLyrics
and our models, aiming to advance Vietnamese music computing research while
demonstrating the potential of this approach for ALT in low-resource language
and music.

</details>


### [95] [Graph-Coarsening Approach for the Capacitated Vehicle Routing Problem with Time Windows](https://arxiv.org/abs/2510.22329)
*Mustafa Mert Özyılmaz*

Main category: cs.AI

TL;DR: 提出了一种用于解决带时间窗的容量限制车辆路径问题（CVRPTW）的多级图粗化和细化框架，通过时空距离度量将客户聚合成元节点，在简化问题上使用经典启发式算法求解，然后扩展回原始空间并进行可行性修正。


<details>
  <summary>Details</summary>
Motivation: CVRPTW是物流中的基本NP难优化问题，大规模实例对精确求解器仍然具有计算挑战性，需要开发更高效的求解方法。

Method: 使用多级图粗化和细化框架，通过时空距离度量聚合客户为元节点，在简化问题上应用经典启发式算法，然后扩展回原始空间并进行可行性修正。

Result: 在Solomon基准实例上的初步实验表明，该方法在减少计算时间的同时保持或改进了解决方案质量，特别是在容量和时间窗约束方面。

Conclusion: 该方法能够有效减少CVRPTW问题的计算时间并保持解决方案质量，量子启发优化技术的集成有望进一步加速大规模车辆路径任务。

Abstract: The Capacitated Vehicle Routing Problem with Time Windows (CVRPTW) is a
fundamental NP-hard optimization problem in logistics. Solving large-scale
instances remains computationally challenging for exact solvers. This work
introduces a multilevel graph coarsening and refinement framework that
aggregates customers into meta-nodes using a spatio-temporal distance metric.
The reduced problem is solved with classical heuristics and subsequently
expanded back into the original space with feasibility corrections. Preliminary
experiments on Solomon benchmark instances show that the proposed method
reduces computation time while preserving or improving solution quality,
particularly with respect to capacity and time window constraints. The paper
also explores the integration of quantum-inspired optimization techniques,
highlighting their potential to further accelerate large-scale vehicle routing
tasks.

</details>


### [96] [LIFT: Interpretable truck driving risk prediction with literature-informed fine-tuned LLMs](https://arxiv.org/abs/2510.22333)
*Xiao Hu,Yuansheng Lian,Ke Zhang,Yunxuan Li,Yuelong Su,Meng Li*

Main category: cs.AI

TL;DR: 提出了一种基于文献信息微调大语言模型(LIFT LLM)的可解释预测框架，用于卡车驾驶风险预测，在真实数据集上表现优于基准模型，并能产生与基准模型一致的变量重要性排序。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够准确预测卡车驾驶风险并提供可解释性结果的框架，结合领域文献知识来增强模型的解释能力。

Method: 构建包含LLM驱动推理核心、文献处理管道和结果评估器的框架，通过299篇领域文献构建知识库，并在真实卡车驾驶风险数据集上进行微调。

Result: LIFT LLM在召回率上比基准模型提高26.7%，F1分数提高10.1%，变量重要性排序与基准模型一致，并能识别潜在风险场景。

Conclusion: LIFT LLM框架在卡车驾驶风险预测中表现出色，文献知识库和微调过程对模型可解释性有重要贡献，具有数据驱动知识发现的潜力。

Abstract: This study proposes an interpretable prediction framework with
literature-informed fine-tuned (LIFT) LLMs for truck driving risk prediction.
The framework integrates an LLM-driven Inference Core that predicts and
explains truck driving risk, a Literature Processing Pipeline that filters and
summarizes domain-specific literature into a literature knowledge base, and a
Result Evaluator that evaluates the prediction performance as well as the
interpretability of the LIFT LLM. After fine-tuning on a real-world truck
driving risk dataset, the LIFT LLM achieved accurate risk prediction,
outperforming benchmark models by 26.7% in recall and 10.1% in F1-score.
Furthermore, guided by the literature knowledge base automatically constructed
from 299 domain papers, the LIFT LLM produced variable importance ranking
consistent with that derived from the benchmark model, while demonstrating
robustness in interpretation results to various data sampling conditions. The
LIFT LLM also identified potential risky scenarios by detecting key combination
of variables in truck driving risk, which were verified by PERMANOVA tests.
Finally, we demonstrated the contribution of the literature knowledge base and
the fine-tuning process in the interpretability of the LIFT LLM, and discussed
the potential of the LIFT LLM in data-driven knowledge discovery.

</details>


### [97] [DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical Reasoning of VLMs in Solid Geometry](https://arxiv.org/abs/2510.22340)
*Changti Wu,Shijie Lian,Zihao Liu,Lei Zhang,Laurence Tianruo Yang,Kai Chen*

Main category: cs.AI

TL;DR: 提出了DynaSolidGeo，第一个用于评估视觉语言模型真实空间推理能力的动态基准，专注于立体几何问题，包含503个专家策划的种子问题，可动态生成无限多样的多模态实例。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注2D平面几何，依赖静态数据集易受数据污染和记忆影响，且仅评估最终答案而忽略推理过程。

Method: 通过半自动标注流程构建，包含专家标注的推理链进行过程评估，测量逻辑有效性和因果一致性。

Result: 实验显示代表性VLMs存在较大性能差距，在动态设置下性能严重下降，在需要高水平空间智能的任务上表现不佳。

Conclusion: DynaSolidGeo填补了立体几何推理评估的空白，揭示了VLMs在空间推理方面的局限性。

Abstract: Solid geometry problem solving demands spatial mathematical reasoning that
integrates spatial intelligence and symbolic reasoning. However, most existing
multimodal mathematical reasoning benchmarks focus primarily on 2D plane
geometry, rely on static datasets prone to data contamination and memorization,
and evaluate models solely by final answers, overlooking the reasoning process.
To address these limitations, we introduce DynaSolidGeo, the first dynamic
benchmark for evaluating genuine spatial reasoning in Vision-Language Models
(VLMs). Constructed through a semi-automatic annotation pipeline, DynaSolidGeo
contains 503 expert-curated seed questions that can, in principle, dynamically
generate an unbounded number of diverse multimodal text-visual instances.
Beyond answer accuracy, we incorporate process evaluation based on
expert-annotated reasoning chains to measure logical validity and causal
coherence. Experiments across representative open-source and closed-source VLMs
reveal large performance gaps, severe degradation in dynamic settings, and poor
performance on tasks requiring high-level spatial intelligence, such as mental
rotation and visualization. The code and dataset are available at
\href{https://zgca-ai4edu.github.io/DynaSolidGeo/}{DynaSolidGeo}.

</details>


### [98] [Reasoning Models Reason Well, Until They Don't](https://arxiv.org/abs/2510.22371)
*Revanth Rameshkumar,Jimson Huang,Yunxin Sun,Fei Xia,Abulhair Saparov*

Main category: cs.AI

TL;DR: 虽然大型推理模型在现有基准测试中表现优异，但通过更复杂的问题测试发现其推理能力存在局限性，无法真正泛化到复杂推理任务。


<details>
  <summary>Details</summary>
Motivation: 重新评估大型语言模型在推理任务中的真实能力，特别是当推理问题复杂度超过训练分布时的表现。

Method: 开发了DeepRD数据集，包含可扩展复杂度的图连通性和自然语言证明规划问题，用于系统评估模型性能。

Result: 大型推理模型在足够复杂度下性能急剧下降，无法泛化，但大多数现实世界问题仍在其成功范围内。

Conclusion: 大型推理模型在短期内具有实用性，但需要开发能够超越训练分布复杂度的新方法。

Abstract: Large language models (LLMs) have shown significant progress in reasoning
tasks. However, recent studies show that transformers and LLMs fail
catastrophically once reasoning problems exceed modest complexity. We revisit
these findings through the lens of large reasoning models (LRMs) -- LLMs
fine-tuned with incentives for step-by-step argumentation and
self-verification. LRM performance on graph and reasoning benchmarks such as
NLGraph seem extraordinary, with some even claiming they are capable of
generalized reasoning and innovation in reasoning-intensive fields such as
mathematics, physics, medicine, and law. However, by more carefully scaling the
complexity of reasoning problems, we show existing benchmarks actually have
limited complexity. We develop a new dataset, the Deep Reasoning Dataset
(DeepRD), along with a generative process for producing unlimited examples of
scalable complexity. We use this dataset to evaluate model performance on graph
connectivity and natural language proof planning. We find that the performance
of LRMs drop abruptly at sufficient complexity and do not generalize. We also
relate our LRM results to the distributions of the complexities of large,
real-world knowledge graphs, interaction graphs, and proof datasets. We find
the majority of real-world examples fall inside the LRMs' success regime, yet
the long tails expose substantial failure potential. Our analysis highlights
the near-term utility of LRMs while underscoring the need for new methods that
generalize beyond the complexity of examples in the training distribution.

</details>


### [99] [Modeling Hierarchical Thinking in Large Reasoning Models](https://arxiv.org/abs/2510.22437)
*G M Shahariar,Ali Nazari,Erfan Shayegani,Nael Abu-Ghazaleh*

Main category: cs.AI

TL;DR: 该论文提出使用无记忆有限状态机（FSM）来近似大型推理模型（LRM）的层次推理动态，将其表示为结构化、可解释的抽象，以分析LLM的推理过程。


<details>
  <summary>Details</summary>
Motivation: 理解大型推理模型（LRM）出现的推理能力是一个困难的开放问题，这对于改进训练和理解鲁棒性具有重要应用价值。

Method: 采用无记忆有限状态机（FSM）来近似LRM的层次推理动态，识别离散推理状态（初始化、演绎、增强策略、不确定性估计、回溯、最终结论），并将推理轨迹表示为状态图中的转移序列。

Result: FSM分析揭示了不同模型在推理方法上的明显推理模式和潜在缺陷，为评估和改进LLM推理提供了新视角。

Conclusion: FSM公式提供了一种系统的方法来分析和可视化不同模型如何解决问题，为理解LLM推理能力提供了结构化、可解释的抽象框架。

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning abilities
when they generate step-by-step solutions, known as chain-of-thought (CoT)
reasoning. When trained to using chain-of-thought reasoning examples, the
resulting models (called Large Reasoning Models, or LRMs) appear to learn
hierarchical thinking strategies similar to those used by humans. However,
understanding LRMs emerging reasoning capabilities remains a difficult open
problem, with many potential important applications including improving
training and understanding robustness. In this paper, we adopt a memoryless
Finite State Machine formulation to approximate LRM's emerging hierarchical
reasoning dynamics as a structured, interpretable abstraction. We identify a
small set of discrete reasoning states including - initialization, deduction,
augmentation-strategy, uncertainty-estimation, backtracking, and
final-conclusion that capture the high-level states present in the model's
reasoning process. By annotating each step of a model's CoT with these states,
we can represent the reasoning trajectory as a transition sequence through the
state graph. This FSM formulation provides a systematic way to analyze,
interpret and visualize how different models approach problems. We describe the
FSM model, provide examples of CoT annotations under this scheme, and discuss
how it can shed light on differences between available models in their approach
to reasoning. Our results demonstrate that this FSM-based analysis reveals
distinct reasoning patterns and potential shortcomings, offering a new lens to
evaluate and improve LLM reasoning.

</details>


### [100] [Learning "Partner-Aware" Collaborators in Multi-Party Collaboration](https://arxiv.org/abs/2510.22462)
*Abhijnan Nath,Nikhil Krishnaswamy*

Main category: cs.AI

TL;DR: 提出了一种可中断协作角色扮演者(ICR)算法，用于训练LLM驱动的协作代理，使其能够更好地接受合作伙伴的干预，从而提高团队在任务相关命题上的共同基础对齐度。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地被部署在代理环境中与人类协作，需要评估其在多轮、多方任务中的协作能力。现有LLM代理在标准RLHF训练下倾向于忽略合作伙伴的干预，这使得提高团队共同基础变得困难。

Method: 使用两玩家修改动作MDP分析标准AI代理的次优行为，提出ICR算法——一种新颖的合作伙伴感知学习算法，用于训练共同基础最优的协作代理。

Result: 在多个协作任务环境中的实验表明，ICR平均更能促进成功的共同基础收敛，并在这些任务中探索更多样化的解决方案。

Conclusion: ICR算法能够有效解决LLM代理在协作任务中忽略合作伙伴干预的问题，提高团队协作效率和共同基础对齐度。

Abstract: Large Language Models (LLMs) are increasingly bring deployed in agentic
settings where they act as collaborators with humans. Therefore, it is
increasingly important to be able to evaluate their abilities to collaborate
effectively in multi-turn, multi-party tasks. In this paper, we build on the AI
alignment and safe interruptability literature to offer novel theoretical
insights on collaborative behavior between LLM-driven collaborator agents and
an intervention agent. Our goal is to learn an ideal partner-aware collaborator
that increases the group's common-ground (CG)-alignment on task-relevant
propositions-by intelligently collecting information provided in interventions
by a partner agent.We show how LLM agents trained using standard RLHF and
related approaches are naturally inclined to ignore possibly well-meaning
interventions, which makes increasing group common ground non-trivial in this
setting. We employ a two-player Modified-Action MDP to examine this suboptimal
behavior of standard AI agents, and propose Interruptible Collaborative
Roleplayer (ICR)-a novel partner-aware learning algorithm to train CG-optimal
collaborators. Experiments on multiple collaborative task environments show
that ICR, on average, is more capable of promoting successful CG convergence
and exploring more diverse solutions in such tasks.

</details>


### [101] [OFFSIDE: Benchmarking Unlearning Misinformation in Multimodal Large Language Models](https://arxiv.org/abs/2510.22535)
*Hao Zheng,Zirui Pang,Ling li,Zhijie Deng,Yuhan Pu,Zhaowei Zhu,Xiaobo Xia,Jiaheng Wei*

Main category: cs.AI

TL;DR: OFFSIDE是一个基于足球转会谣言的多模态大语言模型遗忘基准，包含15.68K条手动整理的数据，用于评估模型在遗忘错误信息方面的表现。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型的发展，数据隐私问题日益突出，需要选择性遗忘学习到的信息。现有基准存在图像多样性不足、潜在不准确性和评估场景不足等问题。

Method: 创建了基于足球转会谣言的基准数据集，包含四个测试集来评估遗忘效果、泛化性、实用性和鲁棒性，支持选择性遗忘、纠正性再学习和单模态遗忘等高级设置。

Result: 评估发现：单模态方法在多模态谣言上失败；遗忘效果主要由灾难性遗忘驱动；所有方法都难以处理"视觉谣言"；遗忘的谣言容易被恢复；所有方法都易受提示攻击。

Conclusion: 当前方法存在显著漏洞，需要更鲁棒的多模态遗忘解决方案。

Abstract: Advances in Multimodal Large Language Models (MLLMs) intensify concerns about
data privacy, making Machine Unlearning (MU), the selective removal of learned
information, a critical necessity. However, existing MU benchmarks for MLLMs
are limited by a lack of image diversity, potential inaccuracies, and
insufficient evaluation scenarios, which fail to capture the complexity of
real-world applications. To facilitate the development of MLLMs unlearning and
alleviate the aforementioned limitations, we introduce OFFSIDE, a novel
benchmark for evaluating misinformation unlearning in MLLMs based on football
transfer rumors. This manually curated dataset contains 15.68K records for 80
players, providing a comprehensive framework with four test sets to assess
forgetting efficacy, generalization, utility, and robustness. OFFSIDE supports
advanced settings like selective unlearning and corrective relearning, and
crucially, unimodal unlearning (forgetting only text data). Our extensive
evaluation of multiple baselines reveals key findings: (1) Unimodal methods
(erasing text-based knowledge) fail on multimodal rumors; (2) Unlearning
efficacy is largely driven by catastrophic forgetting; (3) All methods struggle
with "visual rumors" (rumors appear in the image); (4) The unlearned rumors can
be easily recovered and (5) All methods are vulnerable to prompt attacks. These
results expose significant vulnerabilities in current approaches, highlighting
the need for more robust multimodal unlearning solutions. The code is available
at
\href{https://github.com/zh121800/OFFSIDE}{https://github.com/zh121800/OFFSIDE}.

</details>


### [102] [ATOM: AdapTive and OptiMized dynamic temporal knowledge graph construction using LLMs](https://arxiv.org/abs/2510.22590)
*Yassir Lairgi,Ludovic Moncla,Khalid Benabdeslem,Rémy Cazabet,Pierre Cléau*

Main category: cs.AI

TL;DR: ATOM是一个从非结构化文本构建和持续更新时序知识图谱的少样本可扩展方法，通过将文档分解为最小自包含的原子事实，采用双时间建模区分信息观测时间和有效时间，实现了更高的提取完整性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统静态知识图谱构建忽略了现实世界数据的动态性和时效性，而现有的零样本或少样本方法存在跨多次运行的不稳定性和关键事实覆盖不完整的问题。

Method: 将输入文档分割为最小自包含的原子事实，构建原子时序知识图谱，采用双时间建模区分信息观测时间和有效时间，然后并行合并原子图谱。

Result: 相比基线方法，ATOM实现了约18%的更高完整性、约17%的更好稳定性以及超过90%的延迟减少，显示出动态时序知识图谱构建的强大可扩展潜力。

Conclusion: ATOM方法有效地解决了传统知识图谱构建的局限性，通过原子事实分割和双时间建模，在动态时序知识图谱构建中实现了显著的性能提升和可扩展性。

Abstract: In today's rapidly expanding data landscape, knowledge extraction from
unstructured text is vital for real-time analytics, temporal inference, and
dynamic memory frameworks. However, traditional static knowledge graph (KG)
construction often overlooks the dynamic and time-sensitive nature of
real-world data, limiting adaptability to continuous changes. Moreover, recent
zero- or few-shot approaches that avoid domain-specific fine-tuning or reliance
on prebuilt ontologies often suffer from instability across multiple runs, as
well as incomplete coverage of key facts. To address these challenges, we
introduce ATOM (AdapTive and OptiMized), a few-shot and scalable approach that
builds and continuously updates Temporal Knowledge Graphs (TKGs) from
unstructured texts. ATOM splits input documents into minimal, self-contained
"atomic" facts, improving extraction exhaustivity and stability. Then, it
constructs atomic TKGs from these facts while employing a dual-time modeling
that distinguishes when information is observed from when it is valid. The
resulting atomic TKGs are subsequently merged in parallel. Empirical
evaluations demonstrate that ATOM achieves ~18% higher exhaustivity, ~17%
better stability, and over 90% latency reduction compared to baseline methods,
demonstrating a strong scalability potential for dynamic TKG construction.

</details>


### [103] [A Framework for Quantifying How Pre-Training and Context Benefit In-Context Learning](https://arxiv.org/abs/2510.22594)
*Bingqing Song,Jiaxiang Li,Rong Wang,Songtao Lu,Mingyi Hong*

Main category: cs.AI

TL;DR: 本文提出了一个分析上下文学习性能的新框架，通过理论分析和实验验证，揭示了预训练数据分布与查询任务分布差异对ICL性能的影响机制。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型的上下文学习能力已被广泛应用，但其理论机制尚不明确，特别是预训练过程和上下文构建等关键因素的确切作用。

Method: 构建包含网络架构、数据编码、数据生成和提示构建过程的现实设置框架，首先用单层transformer进行简单示例分析，然后扩展到更一般情况，推导ICL性能与上下文长度及预训练-查询分布KL散度的精确关系。

Result: 当预训练数据分布与查询任务分布不同时，适当构建的上下文可以将输出分布向查询任务分布转移，从而实现准确预测；建立了ICL性能与上下文长度及分布差异的量化关系。

Conclusion: 上下文学习能力的关键在于通过上下文调整模型输出分布，使其更接近查询任务分布，这种机制可以通过理论框架进行量化和分析。

Abstract: Pre-trained large language models have demonstrated a strong ability to learn
from context, known as in-context learning (ICL). Despite a surge of recent
applications that leverage such capabilities, it is by no means clear, at least
theoretically, how the ICL capabilities arise, and in particular, what is the
precise role played by key factors such as pre-training procedure as well as
context construction. In this work, we propose a new framework to analyze the
ICL performance, for a class of realistic settings, which includes network
architectures, data encoding, data generation, and prompt construction process.
As a first step, we construct a simple example with a one-layer transformer,
and show an interesting result, namely when the pre-train data distribution is
different from the query task distribution, a properly constructed context can
shift the output distribution towards the query task distribution, in a
quantifiable manner, leading to accurate prediction on the query topic. We then
extend the findings in the previous step to a more general case, and derive the
precise relationship between ICL performance, context length and the KL
divergence between pre-train and query task distribution. Finally, we provide
experiments to validate our theoretical results.

</details>


### [104] [CLIN-LLM: A Safety-Constrained Hybrid Framework for Clinical Diagnosis and Treatment Generation](https://arxiv.org/abs/2510.22609)
*Md. Mehedi Hasan,Rafid Mostafiz,Md. Abir Hossain,Bikash Kumar Paul*

Main category: cs.AI

TL;DR: CLIN-LLM是一个安全约束的混合管道系统，整合了多模态患者编码、不确定性校准的疾病分类和检索增强的治疗生成，在症状到疾病分类和治疗推荐方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型的医疗系统缺乏医学基础且无法量化不确定性，导致输出不安全。需要开发能够提供安全、可解释且临床可靠的决策支持系统。

Method: 使用BioBERT在1,200个临床案例上微调，结合Focal Loss和Monte Carlo Dropout实现置信度感知预测。采用Biomedical Sentence-BERT从MedDialog语料库检索相关对话，使用微调的FLAN-T5模型生成个性化治疗建议，并通过RxNorm进行抗生素管理和药物相互作用筛查。

Result: CLIN-LLM达到98%的准确率和F1分数，比ClinicalBERT提升7.1%，检索精度78%，临床有效性评分4.2/5，不安全抗生素建议比GPT-5减少67%。

Conclusion: CLIN-LLM展示了稳健性、可解释性和临床安全性，为资源有限的医疗环境提供了可部署的、人机协作的决策支持框架。

Abstract: Accurate symptom-to-disease classification and clinically grounded treatment
recommendations remain challenging, particularly in heterogeneous patient
settings with high diagnostic risk. Existing large language model (LLM)-based
systems often lack medical grounding and fail to quantify uncertainty,
resulting in unsafe outputs. We propose CLIN-LLM, a safety-constrained hybrid
pipeline that integrates multimodal patient encoding, uncertainty-calibrated
disease classification, and retrieval-augmented treatment generation. The
framework fine-tunes BioBERT on 1,200 clinical cases from the Symptom2Disease
dataset and incorporates Focal Loss with Monte Carlo Dropout to enable
confidence-aware predictions from free-text symptoms and structured vitals.
Low-certainty cases (18%) are automatically flagged for expert review, ensuring
human oversight. For treatment generation, CLIN-LLM employs Biomedical
Sentence-BERT to retrieve top-k relevant dialogues from the 260,000-sample
MedDialog corpus. The retrieved evidence and patient context are fed into a
fine-tuned FLAN-T5 model for personalized treatment generation, followed by
post-processing with RxNorm for antibiotic stewardship and drug-drug
interaction (DDI) screening. CLIN-LLM achieves 98% accuracy and F1 score,
outperforming ClinicalBERT by 7.1% (p < 0.001), with 78% top-5 retrieval
precision and a clinician-rated validity of 4.2 out of 5. Unsafe antibiotic
suggestions are reduced by 67% compared to GPT-5. These results demonstrate
CLIN-LLM's robustness, interpretability, and clinical safety alignment. The
proposed system provides a deployable, human-in-the-loop decision support
framework for resource-limited healthcare environments. Future work includes
integrating imaging and lab data, multilingual extensions, and clinical trial
validation.

</details>


### [105] [SwiftSolve: A Self-Iterative, Complexity-Aware Multi-Agent Framework for Competitive Programming](https://arxiv.org/abs/2510.22626)
*Adhyayan Veer Singh,Aaron Shen,Brian Law,Ahmed Ismail,Jonas Rohweder,Sean O'Brien,Kevin Zhu*

Main category: cs.AI

TL;DR: SwiftSolve是一个复杂度感知的多智能体系统，用于竞争性编程，通过算法规划、经验分析和复杂度指导的修复，确保程序不仅正确还满足时间和内存限制。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成的程序虽然能通过单元测试，但经常违反竞赛的时间和内存预算，需要确保程序在效率方面的表现。

Method: 采用多智能体系统，包括规划器、静态修剪器、编码器、分析器和复杂度分析器，通过版本化JSON通信，控制器管理迭代和停止条件。

Result: 在26个问题上的测试显示，首次尝试通过率为61.54%，三次尝试内解决率为80.77%，运行级成功率为73.08%，平均时间12.40秒。

Conclusion: SwiftSolve通过分析和复杂度指导的重新规划，显著减少了低效问题，同时保持了准确性，相比Claude Opus 4在运行级成功率上有明显提升。

Abstract: Correctness alone is insufficient: LLM-generated programs frequently satisfy
unit tests while violating contest time or memory budgets. We present
SwiftSolve, a complexity-aware multi-agent system for competitive programming
that couples algorithmic planning with empirical profiling and
complexity-guided repair. We frame competitive programming as a software
environment where specialized agents act as programmers, each assuming roles
such as planning, coding, profiling, and complexity analysis. A Planner
proposes an algorithmic sketch; a deterministic Static Pruner filters high-risk
plans; a Coder emits ISO C++17; a Profiler compiles and executes candidates on
a fixed input-size schedule to record wall time and peak memory; and a
Complexity Analyst fits log-log growth (s, R2) with an LLM fallback to assign a
complexity class and dispatch targeted patches to either the Planner or Coder.
Agents communicate via typed, versioned JSON; a controller enforces iteration
caps and diminishing returns stopping. Evaluated on 26 problems (16 BigO, 10
Codeforces Div. 2) in a POSIX sandbox (2 s / 256-512 MB), SwiftSolve attains
pass@1 = 61.54% (16/26) on the first attempt and Solved@<=3 = 80.77% with
marginal latency change (mean 11.96 s to 12.66 s per attempt). Aggregate
run-level success is 73.08% at 12.40 s mean. Failures are predominantly
resource-bound, indicating inefficiency rather than logic errors. Against
Claude Opus 4, SwiftSolve improves run-level success (73.1% vs 52.6%) at
approximately 2x runtime overhead (12.4 s vs 6.8 s). Beyond correctness
(pass@k), we report efficiency metrics (eff@k for runtime and memory, incidence
of TLE or MLE, and complexity fit accuracy on BigO), demonstrating that
profiling and complexity-guided replanning reduce inefficiency while preserving
accuracy.

</details>


### [106] [Do Stop Me Now: Detecting Boilerplate Responses with a Single Iteration](https://arxiv.org/abs/2510.22679)
*Yuval Kainan,Shaked Zychlinski*

Main category: cs.AI

TL;DR: 提出一种基于首词生成概率的轻量级方法，可在单步生成后检测LLM的模板化回复，实现早期终止以节省计算资源。


<details>
  <summary>Details</summary>
Motivation: LLMs在生成模板化回复（如拒绝、简单确认等）时浪费大量计算资源，增加了不必要的成本和延迟。

Method: 利用首词生成的对数概率分布作为分类信号，通过轻量级k-NN分类器预测回复类型。

Result: 实验表明首词对数概率向量在不同回复类型间形成明显可分离的聚类，能够高精度预测是否为实质性回答或模板化回复。

Conclusion: 该方法提供了一种实用且计算量极小的技术，通过早期终止或重定向到较小模型来优化LLM推理，显著节省计算成本。

Abstract: Large Language Models (LLMs) often expend significant computational resources
generating boilerplate responses, such as refusals, simple acknowledgements and
casual greetings, which adds unnecessary cost and latency. To address this
inefficiency, we propose a simple yet highly effective method for detecting
such responses after only a single generation step. We demonstrate that the
log-probability distribution of the first generated token serves as a powerful
signal for classifying the nature of the entire subsequent response. Our
experiments, conducted across a diverse range of small, large, and
reasoning-specialized models, show that the first-token log-probability vectors
form distinctly separable clusters for different response types. Using a
lightweight k-NN classifier, we achieve high accuracy in predicting whether a
response will be a substantive answer or a form of boilerplate response,
including user-specified refusals. The primary implication is a practical,
computationally trivial technique, optimizing LLM inference by enabling early
termination or redirection to a smaller model, thereby yielding significant
savings in computational cost. This work presents a direct path toward more
efficient and sustainable LLM deployment.

</details>


### [107] [RaCoT: Plug-and-Play Contrastive Example Generation Mechanism for Enhanced LLM Reasoning Reliability](https://arxiv.org/abs/2510.22710)
*Kaitong Cai,Jusheng Zhang,Yijia Fan,Jing Yang,Keze Wang*

Main category: cs.AI

TL;DR: RaCoT是一种在检索前阶段进行对比思考的RAG框架，通过生成对比问题和提取差异提示，在单次检索中抑制语义干扰，显著提升长尾查询的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决RAG在知识稀疏和语义模糊的长尾查询中面临的检索噪声问题，避免昂贵的后处理成本，突破单向量查询同时编码关注和忽略信号的理论瓶颈。

Method: 在检索前自动生成语义相邻但答案不同的对比问题，提取Δ-Prompt捕捉关键差异，引导模型主动关注决定答案分歧的关键细节。

Result: 在六个权威基准测试中，RaCoT比RankRAG和Self-RAG等强基线提升0.9-2.4个百分点，对抗性测试中性能下降仅8.6%，远优于其他方法的15%以上下降，具有低延迟(3.12s)和低token开销(11.54)。

Conclusion: RaCoT将RAG范式从"事后上下文清理"重构为"先验塑造判别推理"，为实时、资源受限部署提供了高效且鲁棒的可靠AI系统路径。

Abstract: Retrieval-Augmented Generation (RAG) faces a core bottleneck with
knowledge-sparse and semantically ambiguous long-tail queries, where retrieval
noise distorts reasoning and necessitates costly post-processing. To tackle
this, we propose RaCoT (Retrieval-aware Contrastive-of-Thought), a novel
framework that shifts contrastive thinking to the pre-retrieval stage. By
automatically generating a semantically adjacent yet differently answered
contrastive question and extracting a $\Delta$-Prompt to capture their key
differences, RaCoT guides the model to proactively focus on the ``critical
details that determine answer divergence." This approach allows it to suppress
semantic interference within a single retrieval pass, overcoming the
theoretical bottleneck of single-vector queries that struggle to simultaneously
encode signals for what to attend to and what to ignore. On six authoritative
benchmarks, including PopQA and TriviaQA-unfiltered, RaCoT outperforms strong
baselines like RankRAG and Self-RAG by 0.9-2.4 percentage points. It exhibits
superior robustness, with a performance drop of only 8.6\% in adversarial
tests, far surpassing the over 15\% degradation in other methods. Furthermore,
its low latency (3.12s) and token overhead (11.54) place it on the
accuracy-efficiency Pareto frontier, while ablation studies validate the
necessity of each component. Ultimately, RaCoT reframes the RAG paradigm from
``post-hoc context cleaning" to ``a priori shaping of discriminative
reasoning", offering an efficient and robust path toward reliable AI systems
for real-time, resource-constrained deployments.

</details>


### [108] [Critical Insights into Leading Conversational AI Models](https://arxiv.org/abs/2510.22729)
*Urja Kohli,Aditi Singh,Arun Sharma*

Main category: cs.AI

TL;DR: 该研究比较了五个顶级大语言模型（Gemini、DeepSeek、Claude、GPT和LLaMA）在性能准确性、伦理偏见缓解和可用性集成三个关键因素上的差异。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型改变商业软件使用方式、人们生活方式和产业运作方式，各大公司不断改进LLMs，因此需要分析不同模型在性能、道德行为和可用性方面的差异，这些差异源于它们的不同设计理念。

Method: 通过分析三个重要因素进行比较：性能与准确性、伦理与偏见缓解、可用性与集成。

Result: Claude在道德推理方面表现良好，Gemini在多模态能力和强伦理框架方面更优，DeepSeek擅长基于事实的推理，LLaMA适合开放应用，ChatGPT提供平衡性能并注重使用体验。

Conclusion: 这些模型在工作效果、易用性和伦理处理方面存在差异，用户应根据各模型的优势特点来充分利用它们。

Abstract: Big Language Models (LLMs) are changing the way businesses use software, the
way people live their lives and the way industries work. Companies like Google,
High-Flyer, Anthropic, OpenAI and Meta are making better LLMs. So, it's crucial
to look at how each model is different in terms of performance, moral behaviour
and usability, as these differences are based on the different ideas that built
them. This study compares five top LLMs: Google's Gemini, High-Flyer's
DeepSeek, Anthropic's Claude, OpenAI's GPT models and Meta's LLaMA. It performs
this by analysing three important factors: Performance and Accuracy, Ethics and
Bias Mitigation and Usability and Integration. It was found that Claude has
good moral reasoning, Gemini is better at multimodal capabilities and has
strong ethical frameworks. DeepSeek is great at reasoning based on facts, LLaMA
is good for open applications and ChatGPT delivers balanced performance with a
focus on usage. It was concluded that these models are different in terms of
how well they work, how easy they are to use and how they treat people
ethically, making it a point that each model should be utilised by the user in
a way that makes the most of its strengths.

</details>


### [109] [Multi-Modal Fact-Verification Framework for Reducing Hallucinations in Large Language Models](https://arxiv.org/abs/2510.22751)
*Piyushkumar Patel*

Main category: cs.AI

TL;DR: 开发了一个事实验证框架，通过交叉检查LLM输出与多个知识源来实时捕获和纠正幻觉错误，将幻觉减少67%，专家满意度达89%


<details>
  <summary>Details</summary>
Motivation: LLM会自信地生成听起来合理但错误的信息，这已成为在需要准确性的实际应用中部署这些模型的主要障碍

Method: 结合结构化数据库、实时网络搜索和学术文献来验证生成的事实声明，检测到不一致时自动纠正同时保持回答的自然流畅性

Result: 在多个领域测试显示幻觉减少67%且不牺牲回答质量，医疗、金融和科研领域的专家对纠正后输出的满意度达89%

Conclusion: 这项工作为在不能出错的应用中使LLM更可信提供了实用解决方案

Abstract: While Large Language Models have transformed how we interact with AI systems,
they suffer from a critical flaw: they confidently generate false information
that sounds entirely plausible. This hallucination problem has become a major
barrier to deploying these models in real-world applications where accuracy
matters. We developed a fact verification framework that catches and corrects
these errors in real-time by cross checking LLM outputs against multiple
knowledge sources. Our system combines structured databases, live web searches,
and academic literature to verify factual claims as they're generated. When we
detect inconsistencies, we automatically correct them while preserving the
natural flow of the response. Testing across various domains showed we could
reduce hallucinations by 67% without sacrificing response quality. Domain
experts in healthcare, finance, and scientific research rated our corrected
outputs 89% satisfactory a significant improvement over unverified LLM
responses. This work offers a practical solution for making LLMs more
trustworthy in applications where getting facts wrong isn't an option.

</details>


### [110] [Jarvis: Towards Personalized AI Assistant via Personal KV-Cache Retrieval](https://arxiv.org/abs/2510.22765)
*Binxiao Xu,Junyu Feng,Ruichuan An,Yulin Luo,Shilin Yan,Hao Liang,Ming Lu,Wentao Zhang*

Main category: cs.AI

TL;DR: Jarvis是一个通过个人KV-Cache检索实现个性化AI助手的创新框架，在文本和视觉token的KV-Cache中存储用户特定信息，通过检索相关KV-Cache来确保回答准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么学习概念token集合，要么训练VLM来利用用户特定信息，但两种方法都难以生成准确答案作为个性化助手。

Method: 将用户特定信息存储在文本和视觉token的KV-Cache中，文本token通过总结用户信息为元数据创建，视觉token通过从用户图像中提取独特图像块产生。回答问题前先检索相关KV-Cache。

Result: Jarvis能够提供更准确的响应，特别是在依赖特定局部细节时，在多个数据集的视觉问答和纯文本任务中取得最先进的结果。

Conclusion: Jarvis为个性化AI助手提供了一条实用路径，代码和数据集将发布。

Abstract: The rapid development of Vision-language models (VLMs) enables open-ended
perception and reasoning. Recent works have started to investigate how to adapt
general-purpose VLMs into personalized assistants. Even commercial models such
as ChatGPT now support model personalization by incorporating user-specific
information. However, existing methods either learn a set of concept tokens or
train a VLM to utilize user-specific information. However, both pipelines
struggle to generate accurate answers as personalized assistants. We introduce
Jarvis, an innovative framework for a personalized AI assistant through
personal KV-Cache retrieval, which stores user-specific information in the
KV-Caches of both textual and visual tokens. The textual tokens are created by
summarizing user information into metadata, while the visual tokens are
produced by extracting distinct image patches from the user's images. When
answering a question, Jarvis first retrieves related KV-Caches from personal
storage and uses them to ensure accuracy in responses. We also introduce a
fine-grained benchmark built with the same distinct image patch mining
pipeline, emphasizing accurate question answering based on fine-grained
user-specific information. Jarvis is capable of providing more accurate
responses, particularly when they depend on specific local details. Jarvis
achieves state-of-the-art results in both visual question answering and
text-only tasks across multiple datasets, indicating a practical path toward
personalized AI assistants. The code and dataset will be released.

</details>


### [111] [How Do AI Agents Do Human Work? Comparing AI and Human Workflows Across Diverse Occupations](https://arxiv.org/abs/2510.22780)
*Zora Zhiruo Wang,Yijia Shao,Omar Shaikh,Daniel Fried,Graham Neubig,Diyi Yang*

Main category: cs.AI

TL;DR: 该研究首次直接比较人类与AI代理在多个工作技能上的表现，发现代理虽然工作质量较差且存在数据伪造问题，但效率更高、成本更低，适合处理可编程任务。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理的开发缺乏对人类工作方式的清晰理解，需要揭示代理的专业能力及其在不同工作流程中的角色。

Method: 引入可扩展工具包，从人类或代理的计算机使用活动中提取可解释的结构化工作流程，并在数据分析、工程、计算、写作和设计等任务上直接比较人类与代理的表现。

Result: 代理工作流程与人类对齐但过于程序化，工作质量较差且存在数据伪造问题，但交付速度快88.3%，成本低90.4-96.2%。

Conclusion: 代理在效率和经济性方面具有优势，适合处理可编程任务，但需要解决质量问题和伦理风险，以实现有效的人机协作。

Abstract: AI agents are continually optimized for tasks related to human work, such as
software engineering and professional writing, signaling a pressing trend with
significant impacts on the human workforce. However, these agent developments
have often not been grounded in a clear understanding of how humans execute
work, to reveal what expertise agents possess and the roles they can play in
diverse workflows. In this work, we study how agents do human work by
presenting the first direct comparison of human and agent workers across
multiple essential work-related skills: data analysis, engineering,
computation, writing, and design. To better understand and compare
heterogeneous computer-use activities of workers, we introduce a scalable
toolkit to induce interpretable, structured workflows from either human or
agent computer-use activities. Using such induced workflows, we compare how
humans and agents perform the same tasks and find that: (1) While agents
exhibit promise in their alignment to human workflows, they take an
overwhelmingly programmatic approach across all work domains, even for
open-ended, visually dependent tasks like design, creating a contrast with the
UI-centric methods typically used by humans. (2) Agents produce work of
inferior quality, yet often mask their deficiencies via data fabrication and
misuse of advanced tools. (3) Nonetheless, agents deliver results 88.3% faster
and cost 90.4-96.2% less than humans, highlighting the potential for enabling
efficient collaboration by delegating easily programmable tasks to agents.

</details>


### [112] [Agentic Meta-Orchestrator for Multi-task Copilots](https://arxiv.org/abs/2510.22781)
*Xiaofeng Zhu,Yunshen Zhou*

Main category: cs.AI

TL;DR: 提出了一种用于微软Copilot服务的Agentic Meta-orchestrator（AMO），能够处理多任务和可扩展的代理，通过元学习决策树模型选择最佳推理策略。


<details>
  <summary>Details</summary>
Motivation: 随着Copilot服务中代理数量的动态扩展，需要一个强大的编排器来将用户提示的任务分发给正确的代理。

Method: 使用Agentic Meta-orchestrator（AMO）作为编排器，利用元学习训练决策树模型来决定不同代理/模型间的最佳推理策略。

Result: 通过两个生产用例展示了AMO的有效性：M365电子商务Copilot和代码合规Copilot，前者提供最新产品信息并连接多个代理，后者扫描内部DevOps代码检测合规问题。

Conclusion: AMO能够有效处理Copilot服务中的多任务和可扩展代理，提供自然语言和动作响应。

Abstract: Microsoft Copilot suites serve as the universal entry point for various
agents skilled in handling important tasks, ranging from assisting a customer
with product purchases to detecting vulnerabilities in corporate programming
code. Each agent can be powered by language models, software engineering
operations, such as database retrieval, and internal \& external knowledge. The
repertoire of a copilot can expand dynamically with new agents. This requires a
robust orchestrator that can distribute tasks from user prompts to the right
agents. In this work, we propose an Agentic Meta-orchestrator (AMO) for
handling multiple tasks and scalable agents in copilot services, which can
provide both natural language and action responses. We will also demonstrate
the planning that leverages meta-learning, i.e., a trained decision tree model
for deciding the best inference strategy among various agents/models. We
showcase the effectiveness of our AMO through two production use cases:
Microsoft 365 (M365) E-Commerce Copilot and code compliance copilot. M365
E-Commerce Copilot advertises Microsoft products to external customers to
promote sales success. The M365 E-Commerce Copilot provides up-to-date product
information and connects to multiple agents, such as relational databases and
human customer support. The code compliance copilot scans the internal DevOps
code to detect known and new compliance issues in pull requests (PR).

</details>


### [113] [Will Humanity Be Rendered Obsolete by AI?](https://arxiv.org/abs/2510.22814)
*Mohamed El Louadi,Emna Ben Romdhane*

Main category: cs.AI

TL;DR: 本文分析了人工智能对人类构成的生存风险，从当前AI发展到超智能的轨迹，探讨了AGI和超级智能的伦理与生存影响。


<details>
  <summary>Details</summary>
Motivation: 研究人工智能从当前状态发展到超智能过程中可能对人类构成的生存威胁，特别是当机器智能远超人类时可能带来的不可控风险。

Method: 基于Irving J. Good和Nick Bostrom的理论工作，结合近期出版物《AI 2027》和《如果有人建造它，所有人都会死》的分析，探讨AGI和超级智能的发展轨迹。

Result: 分析表明，人类灭绝可能不是源于恶意，而是由于无法控制的、冷漠的认知优越性，当机器智能指数级增长并远超人类时。

Conclusion: 人工智能发展到超智能阶段可能对人类构成根本性的生存威胁，这种威胁源于智能差距而非恶意，需要认真对待和防范。

Abstract: This article analyzes the existential risks artificial intelligence (AI)
poses to humanity, tracing the trajectory from current AI to ultraintelligence.
Drawing on Irving J. Good and Nick Bostrom's theoretical work, plus recent
publications (AI 2027; If Anyone Builds It, Everyone Dies), it explores AGI and
superintelligence. Considering machines' exponentially growing cognitive power
and hypothetical IQs, it addresses the ethical and existential implications of
an intelligence vastly exceeding humanity's, fundamentally alien. Human
extinction may result not from malice, but from uncontrollable, indifferent
cognitive superiority.

</details>


### [114] [HRM-Agent: Training a recurrent reasoning model in dynamic environments using reinforcement learning](https://arxiv.org/abs/2510.22832)
*Long H Dang,David Rawlinson*

Main category: cs.AI

TL;DR: HRM-Agent是基于分层推理模型的强化学习变体，能够在动态不确定的迷宫环境中学习导航到目标，并能够重用先前时间步的计算。


<details>
  <summary>Details</summary>
Motivation: 原始HRM模型虽然推理能力强，但仅限于监督学习、静态、完全可观测的问题，无法处理动态、不确定或部分可观测的现实世界问题。

Method: 开发了HRM-Agent，这是HRM的变体，仅使用强化学习进行训练，探索其循环推理过程的动态特性。

Result: HRM-Agent成功学会了在动态不确定的迷宫环境中导航到目标，并发现其循环推理过程能够重用先前时间步的计算。

Conclusion: HRM-Agent扩展了HRM的应用范围，使其能够处理动态和不确定的环境，并证实了其推理过程的时间复用能力。

Abstract: The Hierarchical Reasoning Model (HRM) has impressive reasoning abilities
given its small size, but has only been applied to supervised, static,
fully-observable problems. One of HRM's strengths is its ability to adapt its
computational effort to the difficulty of the problem. However, in its current
form it cannot integrate and reuse computation from previous time-steps if the
problem is dynamic, uncertain or partially observable, or be applied where the
correct action is undefined, characteristics of many real-world problems.
  This paper presents HRM-Agent, a variant of HRM trained using only
reinforcement learning. We show that HRM can learn to navigate to goals in
dynamic and uncertain maze environments. Recent work suggests that HRM's
reasoning abilities stem from its recurrent inference process. We explore the
dynamics of the recurrent inference process and find evidence that it is
successfully reusing computation from earlier environment time-steps.

</details>


### [115] [Toward Agents That Reason About Their Computation](https://arxiv.org/abs/2510.22833)
*Adrian Orenstein,Jessica Chen,Gwyneth Anne Delos Santos,Bayley Sapara,Michael Bowling*

Main category: cs.AI

TL;DR: 论文研究如何让强化学习智能体在提升性能的同时降低计算开销，通过让智能体感知计算成本并自主控制计算使用，在Atari游戏中实现了性能提升和计算量减少。


<details>
  <summary>Details</summary>
Motivation: 人类在熟练任务后认知负担会降低，而传统强化学习智能体在性能提升时计算效率并不改善。研究旨在让智能体能够感知和控制计算使用，以提高能效和释放计算资源。

Method: 在Arcade Learning Environment上进行实验，让智能体感知计算成本并自主决定何时使用计算资源。

Result: 在相同训练计算预算下，75%的游戏上感知计算成本的智能体表现更好，平均计算量减少了三倍。

Conclusion: 让强化学习智能体感知和控制计算使用可以有效提升性能并显著降低计算开销。

Abstract: While reinforcement learning agents can achieve superhuman performance in
many complex tasks, they typically do not become more computationally efficient
as they improve. In contrast, humans gradually require less cognitive effort as
they become more proficient at a task. If agents could reason about their
compute as they learn, could they similarly reduce their computation footprint?
If they could, we could have more energy efficient agents or free up compute
cycles for other processes like planning. In this paper, we experiment with
showing agents the cost of their computation and giving them the ability to
control when they use compute. We conduct our experiments on the Arcade
Learning Environment, and our results demonstrate that with the same training
compute budget, agents that reason about their compute perform better on 75% of
games. Furthermore, these agents use three times less compute on average. We
analyze individual games and show where agents gain these efficiencies.

</details>


### [116] [Rethinking the Text-Vision Reasoning Imbalance in MLLMs through the Lens of Training Recipes](https://arxiv.org/abs/2510.22836)
*Guanyu Yao,Qiucheng Wu,Yang Zhang,Zhaowen Wang,Handong Zhao,Shiyu Chang*

Main category: cs.AI

TL;DR: 本文分析了多模态大语言模型中的模态差距问题，即模型过度依赖文本线索而忽视视觉内容，并提出了从数据和损失函数设计两方面来弥合这一差距的训练策略。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视觉和文本模态间存在推理能力不平衡的问题，模型过度依赖文本线索而忽视视觉内容，导致在需要真正视觉推理的任务上表现不佳。

Method: 从训练方法角度分析模态差距，系统探索从数据和损失函数设计两个互补视角来弥合差距的策略。

Result: 发现现有训练方法会放大模态差距，提出了能够缓解这一差距并促进更平衡多模态推理的训练策略。

Conclusion: 研究为开发能够减轻模态差距并促进更平衡多模态推理的训练方法提供了见解，相关代码已公开。

Abstract: Multimodal large language models (MLLMs) have demonstrated strong
capabilities on vision-and-language tasks. However, recent findings reveal an
imbalance in their reasoning capabilities across visual and textual modalities.
Specifically, current MLLMs often over-rely on textual cues while
under-attending to visual content, resulting in suboptimal performance on tasks
that require genuine visual reasoning. We refer to this phenomenon as the
\textit{modality gap}, defined as the performance disparity between
text-centric and vision-centric inputs. In this paper, we analyze the modality
gap through the lens of training recipes. We first show that existing training
recipes tend to amplify this gap. Then, we systematically explore strategies to
bridge it from two complementary perspectives: data and loss design. Our
findings provide insights into developing training recipes that mitigate the
modality gap and promote more balanced multimodal reasoning. Our code is
publicly available at https://github.com/UCSB-NLP-Chang/Bridging-Modality-Gap.

</details>


### [117] [Lyapunov Function-guided Reinforcement Learning for Flight Control](https://arxiv.org/abs/2510.22840)
*Yifei Li,Erik-Jan van Kampen*

Main category: cs.AI

TL;DR: 本文研究了级联在线学习飞行控制系统的收敛性能，通过李雅普诺夫函数候选的增量来表征，并考虑了离散化误差和状态预测误差的影响。


<details>
  <summary>Details</summary>
Motivation: 开发并改进了级联在线学习飞行控制系统，特别关注动作平滑性，需要评估其收敛性能。

Method: 使用李雅普诺夫函数候选的增量作为收敛性能指标，推导过程中考虑了离散化误差和增量模型引入的状态预测误差。

Result: 通过飞行控制仿真展示了比较结果，验证了控制系统的收敛性能。

Conclusion: 该级联在线学习飞行控制系统在考虑各种误差因素后仍能保持良好的收敛性能。

Abstract: A cascaded online learning flight control system has been developed and
enhanced with respect to action smoothness. In this paper, we investigate the
convergence performance of the control system, characterized by the increment
of a Lyapunov function candidate. The derivation of this metric accounts for
discretization errors and state prediction errors introduced by the incremental
model. Comparative results are presented through flight control simulations.

</details>


### [118] [Exploring Structures of Inferential Mechanisms through Simplistic Digital Circuits](https://arxiv.org/abs/2510.22883)
*Giovanni Sileno,Jean-Louis Dessalles*

Main category: cs.AI

TL;DR: 本文提出了一个统一的推理框架，通过逻辑门电路模型来整合认知研究和人工智能中的各种推理机制，发现了四种依赖关系和八种常见推理模式。


<details>
  <summary>Details</summary>
Motivation: 认知研究和人工智能为各种推理机制开发了不同的模型，但缺乏统一的框架。本文试图填补这一空白，从物质角度假设高级激活过程。

Method: 使用基于逻辑门的电子电路模型来研究推理机制，通过组合探索识别依赖关系，并在逻辑程序背景下分析推理模式。

Result: 识别了四种主要的依赖关系形式和八种常见的推理模式，在统一框架下揭示了传统上不同的推理机制。

Conclusion: 尽管论证主要基于符号方法和数字系统基础设施，但观察结果可能指向更普遍适用的结构。

Abstract: Cognitive studies and artificial intelligence have developed distinct models
for various inferential mechanisms (categorization, induction, abduction,
causal inference, contrast, merge, ...). Yet, both natural and artificial views
on cognition lack apparently a unifying framework. This paper formulates a
speculative answer attempting to respond to this gap. To postulate on
higher-level activation processes from a material perspective, we consider
inferential mechanisms informed by symbolic AI modelling techniques, through
the simplistic lenses of electronic circuits based on logic gates. We observe
that a logic gate view entails a different treatment of implication and
negation compared to standard logic and logic programming. Then, by
combinatorial exploration, we identify four main forms of dependencies that can
be realized by these inferential circuits. Looking at how these forms are
generally used in the context of logic programs, we identify eight common
inferential patterns, exposing traditionally distinct inferential mechanisms in
an unifying framework. Finally, following a probabilistic interpretation of
logic programs, we unveil inner functional dependencies. The paper concludes
elaborating in what sense, even if our arguments are mostly informed by
symbolic means and digital systems infrastructures, our observations may
pinpoint to more generally applicable structures.

</details>


### [119] [On Generalization in Agentic Tool Calling: CoreThink Agentic Reasoner and MAVEN Dataset](https://arxiv.org/abs/2510.22898)
*Vishvesh Bhat,Omkar Ghugarkar,Julian McAuley*

Main category: cs.AI

TL;DR: 该论文提出了CoreThink智能体推理框架，通过轻量级符号推理层增强LLMs，在多个工具调用基准测试中实现泛化，性能提升530%，计算成本降低90%。


<details>
  <summary>Details</summary>
Motivation: 解决智能体工具调用环境中的泛化挑战，当前LLMs在跨领域转移推理策略和协调工具方面能力不足。

Method: 提出CoreThink智能体推理器框架，为LLMs添加轻量级符号推理层，实现结构化分解和自适应工具编排。

Result: 在多个基准测试中实现最先进性能，相比现有基线提升530%，计算成本仅为十分之一。

Conclusion: CoreThink框架有效解决了智能体工具调用中的泛化问题，无需额外训练即可实现跨基准的优异表现。

Abstract: Generalization across Agentic tool-calling environments remains a key
unsolved challenge in developing reliable agentic reasoning systems. While
large language models (LLMs) demonstrate strong performance on isolated
benchmarks, their ability to transfer reasoning strategies and co-ordinate
tools across diverse domains is poorly understood. In this work, we conduct a
large-scale evaluation of state-of-the-art LLMs on multiple tool-calling
benchmarksBFCL v3, TauBench, Tau2Bench, and AceBenchand introduce MAVEN (Math &
Physics Adversarial Verification & Evaluation Network), a new out of
distribution (OOD) benchmark designed to stress-test multi-step reasoning
through explicit verification and adversarial task composition. Our results
show that most current models achieve below 50% accuracy on MAVEN, revealing a
significant generalization gap across tool-use settings.
  To address this, we present the CoreThink Agentic Reasoner, a framework that
augments LLMs with a lightweight symbolic reasoning layer for structured
decomposition and adaptive tool orchestration. Without additional training, it
generalizes across all benchmarks, achieving state-of-the-art performance with
530% improvements over existing baselines at roughly one-tenth the
computational cost.

</details>


### [120] [GTR-Mamba: Geometry-to-Tangent Routing for Hyperbolic POI Recommendation](https://arxiv.org/abs/2510.22942)
*Zhuoxuan Li,Jieyuan Pei,Tangwei Ye,Zhongyuan Lai,Zihan Liu,Fengyuan Xu,Qi Zhang,Liang Hu*

Main category: cs.AI

TL;DR: GTR-Mamba是一个新颖的POI推荐框架，通过跨流形条件路由同时建模空间层次结构和用户时间上下文动态变化，在双曲几何中处理静态偏好层次，在欧几里得切空间中处理动态序列更新。


<details>
  <summary>Details</summary>
Motivation: 现有POI推荐模型无法同时捕捉空间选择的层次结构和用户特定时间上下文的动态变化，存在根本性限制。

Method: 提出GTR-Mamba框架，利用双曲几何建模静态树状偏好层次，在欧几里得切空间中使用Mamba层处理动态序列更新，通过跨流形通道融合时空信息来指导状态空间模型。

Result: 在三个真实世界数据集上的广泛实验表明，GTR-Mamba在下一个POI推荐任务中持续优于最先进的基线模型。

Conclusion: GTR-Mamba通过跨流形条件路由成功解决了同时建模空间层次结构和时间上下文动态的挑战，为POI推荐提供了有效的解决方案。

Abstract: Next Point-of-Interest (POI) recommendation is a critical task in modern
Location-Based Social Networks (LBSNs), aiming to model the complex
decision-making process of human mobility to provide personalized
recommendations for a user's next check-in location. Existing POI
recommendation models, predominantly based on Graph Neural Networks and
sequential models, have been extensively studied. However, these models face a
fundamental limitation: they struggle to simultaneously capture the inherent
hierarchical structure of spatial choices and the dynamics and irregular shifts
of user-specific temporal contexts. To overcome this limitation, we propose
GTR-Mamba, a novel framework for cross-manifold conditioning and routing.
GTR-Mamba leverages the distinct advantages of different mathematical spaces
for different tasks: it models the static, tree-like preference hierarchies in
hyperbolic geometry, while routing the dynamic sequence updates to a novel
Mamba layer in the computationally stable and efficient Euclidean tangent
space. This process is coordinated by a cross-manifold channel that fuses
spatio-temporal information to explicitly steer the State Space Model (SSM),
enabling flexible adaptation to contextual changes. Extensive experiments on
three real-world datasets demonstrate that GTR-Mamba consistently outperforms
state-of-the-art baseline models in next POI recommendation.

</details>


### [121] [Multi-Agent Conditional Diffusion Model with Mean Field Communication as Wireless Resource Allocation Planner](https://arxiv.org/abs/2510.22969)
*Kechen Meng,Sinuo Zhang,Rongpeng Li,Xiangming Meng,Chan Wang,Ming Lei,Zhifeng Zhao*

Main category: cs.AI

TL;DR: 提出了MA-CDMP方法，使用扩散模型和多智能体条件规划来解决去中心化通信资源管理中的非平稳性和合作问题，在无线网络优化中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决集中式多智能体强化学习的可扩展性和隐私问题，以及分布式训练去中心化执行范式中的非平稳性和有限合作问题。

Method: 基于模型强化学习范式，使用扩散模型捕捉环境动态并规划未来轨迹，引入逆动态模型指导动作生成，采用均值场机制近似大规模智能体交互。

Result: 实验表明MA-CDMP在平均奖励和QoS指标上持续优于现有MARL基线方法，展示了其可扩展性和实际应用价值。

Conclusion: MA-CDMP通过扩散模型和均值场机制有效缓解了多智能体系统中的非平稳性问题，提高了合作效率，为实际无线网络优化提供了可行的解决方案。

Abstract: In wireless communication systems, efficient and adaptive resource allocation
plays a crucial role in enhancing overall Quality of Service (QoS). While
centralized Multi-Agent Reinforcement Learning (MARL) frameworks rely on a
central coordinator for policy training and resource scheduling, they suffer
from scalability issues and privacy risks. In contrast, the Distributed
Training with Decentralized Execution (DTDE) paradigm enables distributed
learning and decision-making, but it struggles with non-stationarity and
limited inter-agent cooperation, which can severely degrade system performance.
To overcome these challenges, we propose the Multi-Agent Conditional Diffusion
Model Planner (MA-CDMP) for decentralized communication resource management.
Built upon the Model-Based Reinforcement Learning (MBRL) paradigm, MA-CDMP
employs Diffusion Models (DMs) to capture environment dynamics and plan future
trajectories, while an inverse dynamics model guides action generation, thereby
alleviating the sample inefficiency and slow convergence of conventional DTDE
methods. Moreover, to approximate large-scale agent interactions, a Mean-Field
(MF) mechanism is introduced as an assistance to the classifier in DMs. This
design mitigates inter-agent non-stationarity and enhances cooperation with
minimal communication overhead in distributed settings. We further
theoretically establish an upper bound on the distributional approximation
error introduced by the MF-based diffusion generation, guaranteeing convergence
stability and reliable modeling of multi-agent stochastic dynamics. Extensive
experiments demonstrate that MA-CDMP consistently outperforms existing MARL
baselines in terms of average reward and QoS metrics, showcasing its
scalability and practicality for real-world wireless network optimization.

</details>


### [122] [Exploring Semantic-constrained Adversarial Example with Instruction Uncertainty Reduction](https://arxiv.org/abs/2510.22981)
*Jin Hu,Jiakai Wang,Linna Jing,Haolin Li,Haodong Liu,Haotong Qin,Aishan Liu,Ke Xu,Xianglong Liu*

Main category: cs.AI

TL;DR: 本文提出InSUR框架，通过减少语义指令中的不确定性来生成更有效的语义约束对抗样本，包括参考多样性、描述不完整性和边界模糊性三个维度的优化。


<details>
  <summary>Details</summary>
Motivation: 当前生成语义约束对抗样本的方法攻击能力不足，主要原因是人类指令中的语义不确定性（如参考多样性、描述不完整性和边界模糊性）未被充分研究。

Method: 提出多维度指令不确定性减少框架：1）采样方法维度：残差驱动攻击方向稳定化；2）任务建模维度：上下文编码攻击场景约束；3）生成器评估维度：语义抽象攻击评估增强。

Result: 实验证明InSUR在迁移攻击性能上表现优越，首次实现了无需参考的语义约束3D对抗样本生成。

Conclusion: InSUR框架通过全面处理语义指令中的不确定性，能够生成更令人满意的语义约束对抗样本，具有更好的可迁移性、适应性和有效性。

Abstract: Recently, semantically constrained adversarial examples (SemanticAE), which
are directly generated from natural language instructions, have become a
promising avenue for future research due to their flexible attacking forms. To
generate SemanticAEs, current methods fall short of satisfactory attacking
ability as the key underlying factors of semantic uncertainty in human
instructions, such as referring diversity, descriptive incompleteness, and
boundary ambiguity, have not been fully investigated. To tackle the issues,
this paper develops a multi-dimensional instruction uncertainty reduction
(InSUR) framework to generate more satisfactory SemanticAE, i.e., transferable,
adaptive, and effective. Specifically, in the dimension of the sampling method,
we propose the residual-driven attacking direction stabilization to alleviate
the unstable adversarial optimization caused by the diversity of language
references. By coarsely predicting the language-guided sampling process, the
optimization process will be stabilized by the designed ResAdv-DDIM sampler,
therefore releasing the transferable and robust adversarial capability of
multi-step diffusion models. In task modeling, we propose the context-encoded
attacking scenario constraint to supplement the missing knowledge from
incomplete human instructions. Guidance masking and renderer integration are
proposed to regulate the constraints of 2D/3D SemanticAE, activating stronger
scenario-adapted attacks. Moreover, in the dimension of generator evaluation,
we propose the semantic-abstracted attacking evaluation enhancement by
clarifying the evaluation boundary, facilitating the development of more
effective SemanticAE generators. Extensive experiments demonstrate the
superiority of the transfer attack performance of InSUR. Moreover, we realize
the reference-free generation of semantically constrained 3D adversarial
examples for the first time.

</details>


### [123] [ProfileXAI: User-Adaptive Explainable AI](https://arxiv.org/abs/2510.22998)
*Gilber A. Corrales,Carlos Andrés Ferro Sánchez,Reinel Tabares-Soto,Jesús Alfonso López Sotelo,Gonzalo A. Ruz,Johan Sebastian Piña Durán*

Main category: cs.AI

TL;DR: ProfileXAI是一个模型和领域无关的框架，将SHAP、LIME、Anchor等事后解释器与检索增强的LLMs结合，为不同类型用户生成解释。系统索引多模态知识库，通过定量标准为每个实例选择解释器，并生成基于聊天的提示的接地叙述。


<details>
  <summary>Details</summary>
Motivation: 开发一个通用的解释框架，能够适应不同用户类型，提供高效且可信的解释，解决现有解释方法在用户适应性和稳定性方面的不足。

Method: 结合事后解释器（SHAP、LIME、Anchor）与检索增强的LLMs，索引多模态知识库，通过定量标准选择解释器，使用基于聊天的提示生成接地叙述。

Result: 在心脏病和甲状腺癌数据集上评估，LIME在保真度-鲁棒性权衡上表现最佳，Anchor产生最稀疏、低token的规则，SHAP获得最高满意度。Profile条件化稳定token使用并保持各用户配置文件的积极评分。

Conclusion: ProfileXAI框架能够实现高效且可信的解释，没有单一解释器在所有指标上占优，但通过条件化可以稳定token使用并维持用户满意度。

Abstract: ProfileXAI is a model- and domain-agnostic framework that couples post-hoc
explainers (SHAP, LIME, Anchor) with retrieval - augmented LLMs to produce
explanations for different types of users. The system indexes a multimodal
knowledge base, selects an explainer per instance via quantitative criteria,
and generates grounded narratives with chat-enabled prompting. On Heart Disease
and Thyroid Cancer datasets, we evaluate fidelity, robustness, parsimony, token
use, and perceived quality. No explainer dominates: LIME achieves the best
fidelity-robustness trade-off (Infidelity $\le 0.30$, $L<0.7$ on Heart
Disease); Anchor yields the sparsest, low-token rules; SHAP attains the highest
satisfaction ($\bar{x}=4.1$). Profile conditioning stabilizes tokens ($\sigma
\le 13\%$) and maintains positive ratings across profiles ($\bar{x}\ge 3.7$,
with domain experts at $3.77$), enabling efficient and trustworthy
explanations.

</details>


### [124] [From Prompt Optimization to Multi-Dimensional Credibility Evaluation: Enhancing Trustworthiness of Chinese LLM-Generated Liver MRI Reports](https://arxiv.org/abs/2510.23008)
*Qiuli Wang,Xiaoming Li,Jie Chen,Yongxu Liu,Xingpeng Zhang,Chen Liu,Wei Chen*

Main category: cs.AI

TL;DR: 该研究提出了一个多维可信度评估框架(MDCA)来增强LLM生成的肝脏MRI报告的可信度，并为机构特定的提示优化提供指导。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在从影像学发现生成诊断结论方面表现出潜力，但在不同临床背景下如何优化提示设计以及如何评估LLM生成放射学报告的可信度方面仍缺乏系统指导。

Method: 引入多维可信度评估(MDCA)框架，并应用于评估多个先进LLM(Kimi-K2-Instruct-0905、Qwen3-235B-A22B-Instruct-2507、DeepSeek-V3、ByteDance-Seed-OSS-36B-Instruct)在SiliconFlow平台上的性能。

Result: 研究比较了多个先进LLM在肝脏MRI报告生成方面的性能表现。

Conclusion: 该研究为优化LLM在放射学报告生成中的可信度提供了系统框架和实用指导。

Abstract: Large language models (LLMs) have demonstrated promising performance in
generating diagnostic conclusions from imaging findings, thereby supporting
radiology reporting, trainee education, and quality control. However,
systematic guidance on how to optimize prompt design across different clinical
contexts remains underexplored. Moreover, a comprehensive and standardized
framework for assessing the trustworthiness of LLM-generated radiology reports
is yet to be established. This study aims to enhance the trustworthiness of
LLM-generated liver MRI reports by introducing a Multi-Dimensional Credibility
Assessment (MDCA) framework and providing guidance on institution-specific
prompt optimization. The proposed framework is applied to evaluate and compare
the performance of several advanced LLMs, including Kimi-K2-Instruct-0905,
Qwen3-235B-A22B-Instruct-2507, DeepSeek-V3, and
ByteDance-Seed-OSS-36B-Instruct, using the SiliconFlow platform.

</details>


### [125] [Mixed Density Diffuser: Efficient Planning with Non-uniform Temporal Resolution](https://arxiv.org/abs/2510.23026)
*Crimson Stambaugh,Rajesh P. N. Rao*

Main category: cs.AI

TL;DR: 提出Mixed Density Diffuser (MDD)，一种可调节规划密度的扩散规划器，在多个任务领域达到新的SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有扩散规划器采用稀疏步长规划优于单步规划，但过度稀疏会降低性能。假设时间密度阈值在时间范围内不均匀，某些轨迹部分需要更密集规划

Method: MDD扩散规划器，在整个时间范围内密度作为可调超参数，允许不同部分采用不同规划密度

Result: 在Maze2D、Franka Kitchen和Antmaze D4RL任务领域达到新的SOTA性能

Conclusion: 可调节密度的扩散规划器能更好地处理长期依赖关系，在多个基准测试中表现优异

Abstract: Recent studies demonstrate that diffusion planners benefit from sparse-step
planning over single-step planning. Training models to skip steps in their
trajectories helps capture long-term dependencies without additional or memory
computational cost. However, predicting excessively sparse plans degrades
performance. We hypothesize this temporal density threshold is non-uniform
across a temporal horizon and that certain parts of a planned trajectory should
be more densely planned. We propose Mixed Density Diffuser (MDD), a diffusion
planner where the densities throughout the horizon are tunable hyperparameters.
MDD achieves a new SOTA across the Maze2D, Franka Kitchen, and Antmaze D4RL
task domains.

</details>


### [126] [A Survey of AI Scientists: Surveying the automatic Scientists and Research](https://arxiv.org/abs/2510.23045)
*Guiyao Tie,Pan Zhou,Lichao Sun*

Main category: cs.AI

TL;DR: 这篇论文系统综述了AI科学家领域的发展，提出了一个六阶段方法论框架来分析自主科学发现过程，并梳理了该领域从基础模块到闭环系统再到可扩展性研究的演进历程。


<details>
  <summary>Details</summary>
Motivation: AI正从计算工具转变为自主科学知识创造者，但该领域的快速发展导致研究碎片化，缺乏统一的方法论框架和发展趋势分析。

Method: 引入统一的六阶段方法论框架：文献综述、想法生成、实验准备、实验执行、科学写作和论文生成，通过这一分析视角梳理领域发展。

Result: 构建了系统的领域发展图谱，从早期基础模块（2022-2023）到集成闭环系统（2024），再到当前的可扩展性、影响力和人机协作研究（2025至今）。

Conclusion: 该综述不仅阐明了自主科学的现状，还为克服鲁棒性和治理方面的挑战提供了关键路线图，指导下一代系统成为人类科学探究中值得信赖的合作伙伴。

Abstract: Artificial intelligence is undergoing a profound transition from a
computational instrument to an autonomous originator of scientific knowledge.
This emerging paradigm, the AI scientist, is architected to emulate the
complete scientific workflow-from initial hypothesis generation to the final
synthesis of publishable findings-thereby promising to fundamentally reshape
the pace and scale of discovery. However, the rapid and unstructured
proliferation of these systems has created a fragmented research landscape,
obscuring overarching methodological principles and developmental trends. This
survey provides a systematic and comprehensive synthesis of this domain by
introducing a unified, six-stage methodological framework that deconstructs the
end-to-end scientific process into: Literature Review, Idea Generation,
Experimental Preparation, Experimental Execution, Scientific Writing, and Paper
Generation. Through this analytical lens, we chart the field's evolution from
early Foundational Modules (2022-2023) to integrated Closed-Loop Systems
(2024), and finally to the current frontier of Scalability, Impact, and
Human-AI Collaboration (2025-present). By rigorously synthesizing these
developments, this survey not only clarifies the current state of autonomous
science but also provides a critical roadmap for overcoming remaining
challenges in robustness and governance, ultimately guiding the next generation
of systems toward becoming trustworthy and indispensable partners in human
scientific inquiry.

</details>


### [127] [TLCD: A Deep Transfer Learning Framework for Cross-Disciplinary Cognitive Diagnosis](https://arxiv.org/abs/2510.23062)
*Zhifeng Wang,Meixin Su,Yang Yang,Chunyan Zeng,Lizhi Ye*

Main category: cs.AI

TL;DR: 提出了一种基于深度学习和迁移学习的跨学科认知诊断方法（TLCD），通过利用主学科的共同特征来提升目标学科模型的性能，在跨学科认知诊断任务中表现优于基础模型。


<details>
  <summary>Details</summary>
Motivation: 在线教育模式快速发展，但跨学科领域中的传统认知诊断方法面临知识体系差异、认知结构不同和数据特征多样等挑战，需要新的解决方案。

Method: 结合深度学习技术和迁移学习策略，研究神经网络认知诊断和知识关联神经网络认知诊断，提出跨学科认知诊断方法TLCD。

Result: 实验结果表明，基于深度学习的跨学科认知诊断模型在跨学科认知诊断任务中表现优于基础模型，能更准确地评估学生的学习情况。

Conclusion: TLCD方法有效解决了跨学科认知诊断中的挑战，为智能教育提供了更精准的学生能力评估工具。

Abstract: Driven by the dual principles of smart education and artificial intelligence
technology, the online education model has rapidly emerged as an important
component of the education industry. Cognitive diagnostic technology can
utilize students' learning data and feedback information in educational
evaluation to accurately assess their ability level at the knowledge level.
However, while massive amounts of information provide abundant data resources,
they also bring about complexity in feature extraction and scarcity of
disciplinary data. In cross-disciplinary fields, traditional cognitive
diagnostic methods still face many challenges. Given the differences in
knowledge systems, cognitive structures, and data characteristics between
different disciplines, this paper conducts in-depth research on neural network
cognitive diagnosis and knowledge association neural network cognitive
diagnosis, and proposes an innovative cross-disciplinary cognitive diagnosis
method (TLCD). This method combines deep learning techniques and transfer
learning strategies to enhance the performance of the model in the target
discipline by utilizing the common features of the main discipline. The
experimental results show that the cross-disciplinary cognitive diagnosis model
based on deep learning performs better than the basic model in
cross-disciplinary cognitive diagnosis tasks, and can more accurately evaluate
students' learning situation.

</details>


### [128] [Smaller Models, Smarter Rewards: A Two-Sided Approach to Process and Outcome Rewards](https://arxiv.org/abs/2510.23083)
*Jan Niklas Groeneveld,Xi Qin,Alexander Schaefer,Yaad Oren*

Main category: cs.AI

TL;DR: 该论文研究了如何将小型语言模型（如Phi-4系列）转化为有效的奖励模型，用于评估代码生成质量，通过结合过程奖励和结果奖励，在APPS编码挑战基准上实现了超过20%的代码搜索能力提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成高质量代码方面仍面临挑战，需要奖励模型作为推理模型发展的中间步骤。虽然模型规模通常与反思能力相关，但本研究旨在探索小型语言模型是否也能成为有效的奖励模型。

Method: 构建基于APPS编码挑战基准的代码样本数据集，训练带有回归层的价值头模型来估计中间输出的成功概率，结合过程奖励和结果奖励。

Result: 小型LLM能够作为有效的奖励模型或代码评估批评器，成功识别多个候选方案中的正确解决方案，使用该批评器可将最准确代码的搜索能力提升超过20%。

Conclusion: 小型语言模型可以被转化为有效的奖励模型，在代码生成任务中提供有价值的评估能力，为代码质量改进提供实用工具。

Abstract: Generating high-quality code remains a challenge for Large Language Models
(LLMs). For the evolution of reasoning models on this task, reward models are a
necessary intermediate step. These models judge outcomes or intermediate steps.
Decoder-only transformer models can be turned into reward models by introducing
a regression layer and supervised fine-tuning. While it is known that
reflection capabilities generally increase with the size of a model, we want to
investigate whether state-of-the-art small language models like the Phi-4
family can be turned into usable reward models blending the consideration of
process rewards and outcome rewards.
  Targeting this goal, we construct a dataset of code samples with correctness
labels derived from the APPS coding challenge benchmark. We then train a
value-head model to estimate the success probability of intermediate outputs.
Our evaluation shows that small LLMs are capable of serving as effective reward
models or code evaluation critics, successfully identifying correct solutions
among multiple candidates. Using this critic, we achieve over a 20% improvement
in the search capability of the most accurate code out of multiple generations.

</details>


### [129] [Lost in Tokenization: Context as the Key to Unlocking Biomolecular Understanding in Scientific LLMs](https://arxiv.org/abs/2510.23127)
*Kai Zhuang,Jiawei Zhang,Yumou Liu,Hanqun Cao,Chunbin Gu,Mengdi Liu,Zhangyang Gao,Zitong Jerry Wang,Xuanhe Zhou,Pheng-Ann Heng,Lijun Wu,Conghui He,Cheng Tan*

Main category: cs.AI

TL;DR: Sci-LLMs在处理生物分子序列时面临tokenization困境，研究发现提供高层次结构化上下文比直接处理原始序列表现更好，甚至原始序列会干扰模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决科学大语言模型在处理原始生物分子序列时面临的tokenization困境，探索更有效的输入策略。

Method: 系统比较了三种输入模式：仅序列、仅上下文、序列+上下文组合，测试了领先的Sci-LLMs在生物推理任务上的表现。

Result: 仅上下文方法始终且显著优于其他模式，原始序列的加入反而会降低性能，表明原始序列对模型来说是信息噪声。

Conclusion: Sci-LLMs的主要优势不在于从零解释生物分子语法，而在于对结构化、人类可读知识的推理能力，应将其重新定位为专家知识的推理引擎。

Abstract: Scientific Large Language Models (Sci-LLMs) have emerged as a promising
frontier for accelerating biological discovery. However, these models face a
fundamental challenge when processing raw biomolecular sequences: the
tokenization dilemma. Whether treating sequences as a specialized language,
risking the loss of functional motif information, or as a separate modality,
introducing formidable alignment challenges, current strategies fundamentally
limit their reasoning capacity. We challenge this sequence-centric paradigm by
positing that a more effective strategy is to provide Sci-LLMs with high-level
structured context derived from established bioinformatics tools, thereby
bypassing the need to interpret low-level noisy sequence data directly. Through
a systematic comparison of leading Sci-LLMs on biological reasoning tasks, we
tested three input modes: sequence-only, context-only, and a combination of
both. Our findings are striking: the context-only approach consistently and
substantially outperforms all other modes. Even more revealing, the inclusion
of the raw sequence alongside its high-level context consistently degrades
performance, indicating that raw sequences act as informational noise, even for
models with specialized tokenization schemes. These results suggest that the
primary strength of existing Sci-LLMs lies not in their nascent ability to
interpret biomolecular syntax from scratch, but in their profound capacity for
reasoning over structured, human-readable knowledge. Therefore, we argue for
reframing Sci-LLMs not as sequence decoders, but as powerful reasoning engines
over expert knowledge. This work lays the foundation for a new class of hybrid
scientific AI agents, repositioning the developmental focus from direct
sequence interpretation towards high-level knowledge synthesis. The code is
available at github.com/opendatalab-raise-dev/CoKE.

</details>


### [130] [Guiding Skill Discovery with Foundation Models](https://arxiv.org/abs/2510.23167)
*Zhao Yang,Thomas M. Moerland,Mike Preuss,Aske Plaat,Vincent François-Lavet,Edward S. Hu*

Main category: cs.AI

TL;DR: 提出了一种基于基础模型的技能发现方法FoG，将人类偏好融入技能发现过程，避免产生危险或不期望的行为。


<details>
  <summary>Details</summary>
Motivation: 现有技能发现方法只关注技能多样性最大化，不考虑人类偏好，导致产生危险或不期望的行为（如机器人翻滚）。需要将人类意图融入技能发现过程。

Method: FoG从基础模型中提取评分函数，根据人类意图评估状态，为期望状态分配高值，不期望状态分配低值。然后用这些分数重新加权技能发现算法的奖励。

Result: FoG成功消除了不期望行为（如翻滚），在状态和像素任务中都避免了危险区域。还能发现难以定义的行为技能。

Conclusion: FoG方法有效将人类偏好融入技能发现，避免了危险行为，同时保持了技能多样性。

Abstract: Learning diverse skills without hand-crafted reward functions could
accelerate reinforcement learning in downstream tasks. However, existing skill
discovery methods focus solely on maximizing the diversity of skills without
considering human preferences, which leads to undesirable behaviors and
possibly dangerous skills. For instance, a cheetah robot trained using previous
methods learns to roll in all directions to maximize skill diversity, whereas
we would prefer it to run without flipping or entering hazardous areas. In this
work, we propose a Foundation model Guided (FoG) skill discovery method, which
incorporates human intentions into skill discovery through foundation models.
Specifically, FoG extracts a score function from foundation models to evaluate
states based on human intentions, assigning higher values to desirable states
and lower to undesirable ones. These scores are then used to re-weight the
rewards of skill discovery algorithms. By optimizing the re-weighted skill
discovery rewards, FoG successfully learns to eliminate undesirable behaviors,
such as flipping or rolling, and to avoid hazardous areas in both state-based
and pixel-based tasks. Interestingly, we show that FoG can discover skills
involving behaviors that are difficult to define. Interactive visualisations
are available from https://sites.google.com/view/submission-fog.

</details>


### [131] [AUPO -- Abstracted Until Proven Otherwise: A Reward Distribution Based Abstraction Algorithm](https://arxiv.org/abs/2510.23214)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: AUPO是MCTS决策策略的改进算法，仅依赖奖励分布统计自动进行动作抽象，无需转移概率或DAG搜索图，能检测对称动作，在IPPC基准问题上明显优于MCTS。


<details>
  <summary>Details</summary>
Motivation: 解决现有自动抽象算法需要转移概率或DAG搜索图的限制，以及ASAP等框架难以检测状态空间中相距较远的对称状态的问题。

Method: 基于MCTS过程中收集的奖励分布统计，开发自动动作抽象算法AUPO，仅修改决策策略而不影响树搜索。

Result: 在IPPC基准问题上的比较显示AUPO明显优于标准MCTS，能有效检测对称动作。

Conclusion: AUPO是一种有效的自动动作抽象方法，与其他仅影响树搜索的抽象技术兼容，具有实用价值。

Abstract: We introduce a novel, drop-in modification to Monte Carlo Tree Search's
(MCTS) decision policy that we call AUPO. Comparisons based on a range of IPPC
benchmark problems show that AUPO clearly outperforms MCTS. AUPO is an
automatic action abstraction algorithm that solely relies on reward
distribution statistics acquired during the MCTS. Thus, unlike other automatic
abstraction algorithms, AUPO requires neither access to transition
probabilities nor does AUPO require a directed acyclic search graph to build
its abstraction, allowing AUPO to detect symmetric actions that
state-of-the-art frameworks like ASAP struggle with when the resulting
symmetric states are far apart in state space. Furthermore, as AUPO only
affects the decision policy, it is not mutually exclusive with other
abstraction techniques that only affect the tree search.

</details>


### [132] [Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach](https://arxiv.org/abs/2510.23216)
*Alessandro Sestini,Joakim Bergdahl,Jean-Philippe Barrette-LaPierre,Florian Fuchs,Brady Chen,Micheal Jones,Linus Gisslén*

Main category: cs.AI

TL;DR: 提出了一种针对游戏工业环境的样本高效深度强化学习方法，在EA SPORTS FC 25中训练守门员智能体，性能超越游戏内置AI 10%，训练速度提升50%。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习研究主要关注训练超人级智能体，但游戏行业需要的是人类水平的智能体，且资源有限，因此需要开发适合工业环境的样本高效方法。

Method: 通过利用预收集数据和增加网络可塑性，改进了基于价值的深度强化学习的样本效率。

Result: 在EA SPORTS FC 25中训练的守门员智能体比游戏内置AI的救球率高出10%，训练速度比标准深度强化学习方法快50%，领域专家定性评估显示该方法创造了更接近人类玩家的游戏体验。

Conclusion: 该方法已被证明有效，计划在下一代游戏系列中替代手工制作的智能体，展示了其在游戏工业中的实际应用价值。

Abstract: While several high profile video games have served as testbeds for Deep
Reinforcement Learning (DRL), this technique has rarely been employed by the
game industry for crafting authentic AI behaviors. Previous research focuses on
training super-human agents with large models, which is impractical for game
studios with limited resources aiming for human-like agents. This paper
proposes a sample-efficient DRL method tailored for training and fine-tuning
agents in industrial settings such as the video game industry. Our method
improves sample efficiency of value-based DRL by leveraging pre-collected data
and increasing network plasticity. We evaluate our method training a goalkeeper
agent in EA SPORTS FC 25, one of the best-selling football simulations today.
Our agent outperforms the game's built-in AI by 10% in ball saving rate.
Ablation studies show that our method trains agents 50% faster compared to
standard DRL methods. Finally, qualitative evaluation from domain experts
indicates that our approach creates more human-like gameplay compared to
hand-crafted agents. As a testimony of the impact of the approach, the method
is intended to replace the hand-crafted counterpart in next iterations of the
series.

</details>


### [133] [Accelerating IC Thermal Simulation Data Generation via Block Krylov and Operator Action](https://arxiv.org/abs/2510.23221)
*Hong Wang,Wenkai Yang,Jie Wang,Huanshuo Dong,Zijie Geng,Zhen Huang,Depeng Xie,Zhezheng Hao,Hande Dong*

Main category: cs.AI

TL;DR: 提出了一种名为BlocKOA的新型集成电路热仿真数据生成算法，通过块Krylov方法和算子作用同时加速数据生成过程并提高数据精度，相比现有方法实现了420倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法（如神经算子）需要大量高保真训练数据，导致计算成本高昂，因此需要一种高效且精确的数据生成方法来克服这一限制。

Method: BlocKOA算法首先基于热方程结构使用块Krylov算法快速获取少量基本解，然后组合这些解得到满足物理约束的多种温度分布，最后对这些函数应用热算子来确定热源分布，从而高效生成精确数据点。

Result: 理论分析显示BlocKOA的时间复杂度比现有方法低一个数量级。实验验证其效率，在生成5000个具有不同物理参数和IC结构芯片的热仿真数据时实现了420倍加速，仅用4%的生成时间就能训练出与现有方法性能相当的数据驱动模型。

Conclusion: BlocKOA是一种专门为IC应用设计的高效数据生成算法，显著降低了热仿真数据的生成成本，同时保持了数据质量，为数据驱动方法提供了可行的解决方案。

Abstract: Recent advances in data-driven approaches, such as neural operators (NOs),
have shown substantial efficacy in reducing the solution time for integrated
circuit (IC) thermal simulations. However, a limitation of these approaches is
requiring a large amount of high-fidelity training data, such as chip
parameters and temperature distributions, thereby incurring significant
computational costs. To address this challenge, we propose a novel algorithm
for the generation of IC thermal simulation data, named block Krylov and
operator action (BlocKOA), which simultaneously accelerates the data generation
process and enhances the precision of generated data. BlocKOA is specifically
designed for IC applications. Initially, we use the block Krylov algorithm
based on the structure of the heat equation to quickly obtain a few basic
solutions. Then we combine them to get numerous temperature distributions that
satisfy the physical constraints. Finally, we apply heat operators on these
functions to determine the heat source distributions, efficiently generating
precise data points. Theoretical analysis shows that the time complexity of
BlocKOA is one order lower than the existing method. Experimental results
further validate its efficiency, showing that BlocKOA achieves a 420-fold
speedup in generating thermal simulation data for 5000 chips with varying
physical parameters and IC structures. Even with just 4% of the generation
time, data-driven approaches trained on the data generated by BlocKOA exhibits
comparable performance to that using the existing method.

</details>


### [134] [CNOT Minimal Circuit Synthesis: A Reinforcement Learning Approach](https://arxiv.org/abs/2510.23304)
*Riccardo Romanello,Daniele Lizzio Bosco,Jacopo Cossio,Dusan Sutulovic,Giuseppe Serra,Carla Piazza,Paolo Burelli*

Main category: cs.AI

TL;DR: 提出一种基于强化学习的CNOT门最小化方法，使用单一智能体处理不同尺寸的量子电路，在较大电路尺寸上优于现有最优算法。


<details>
  <summary>Details</summary>
Motivation: CNOT门是量子计算中的基本组件，用于产生纠缠。减少CNOT门数量对量子算法性能至关重要，但CNOT最小化问题仍是一个开放挑战，其计算复杂性尚未完全表征。

Method: 使用单一强化学习智能体处理固定尺寸m的电路，对于不同尺寸的矩阵采用嵌入或高斯条纹化进行预处理。训练了m=8的智能体，并在n=3到15的矩阵上进行评估。

Result: 该方法在n值增大时优于现有最优算法，表明强化学习方法在较大电路尺寸上具有更好的性能。

Conclusion: 强化学习为CNOT门最小化问题提供了有效的解决方案，特别是在处理较大尺寸量子电路时表现出优越性能。

Abstract: CNOT gates are fundamental to quantum computing, as they facilitate
entanglement, a crucial resource for quantum algorithms. Certain classes of
quantum circuits are constructed exclusively from CNOT gates. Given their
widespread use, it is imperative to minimise the number of CNOT gates employed.
This problem, known as CNOT minimisation, remains an open challenge, with its
computational complexity yet to be fully characterised. In this work, we
introduce a novel reinforcement learning approach to address this task. Instead
of training multiple reinforcement learning agents for different circuit sizes,
we use a single agent up to a fixed size $m$. Matrices of sizes different from
m are preprocessed using either embedding or Gaussian striping. To assess the
efficacy of our approach, we trained an agent with m = 8, and evaluated it on
matrices of size n that range from 3 to 15. The results we obtained show that
our method overperforms the state-of-the-art algorithm as the value of n
increases.

</details>


### [135] [Planning Ahead with RSA: Efficient Signalling in Dynamic Environments by Projecting User Awareness across Future Timesteps](https://arxiv.org/abs/2510.23340)
*Anwesha Das,John Duff,Jörg Hoffmann,Vera Demberg*

Main category: cs.AI

TL;DR: 提出了一个基于理性沟通原则的自适应信号框架，通过多步规划优化人机协作中的信息传递时机和特异性，以在动态环境中保持用户信念与环境的及时对齐。


<details>
  <summary>Details</summary>
Motivation: 在快速变化的环境中，辅助智能体需要识别最高优先级信息，并估计如何最有效地沟通这些信息，因为人类注意力是零和认知资源，关注一个信息会降低对其他信息的感知。

Method: 使用贝叶斯参考解析和理性言语行为(RSA)建模框架，规划消息序列，根据用户和场景特点自适应调整消息特异性和时机，基于对消息解释如何影响界面注意力和信念更新的多步预测。

Result: 与基线方法比较显示，该方法的效果关键依赖于将多步规划与现实的用户意识模型相结合。

Conclusion: 这是RSA在动态环境通信和人类-AI交互中的首次应用，为人类-智能体团队的语用沟通建立了理论基础，展示了认知科学见解如何指导辅助智能体设计。

Abstract: Adaptive agent design offers a way to improve human-AI collaboration on
time-sensitive tasks in rapidly changing environments. In such cases, to ensure
the human maintains an accurate understanding of critical task elements, an
assistive agent must not only identify the highest priority information but
also estimate how and when this information can be communicated most
effectively, given that human attention represents a zero-sum cognitive
resource where focus on one message diminishes awareness of other or upcoming
information. We introduce a theoretical framework for adaptive signalling which
meets these challenges by using principles of rational communication,
formalised as Bayesian reference resolution using the Rational Speech Act (RSA)
modelling framework, to plan a sequence of messages which optimise timely
alignment between user belief and a dynamic environment. The agent adapts
message specificity and timing to the particulars of a user and scenario based
on projections of how prior-guided interpretation of messages will influence
attention to the interface and subsequent belief update, across several
timesteps out to a fixed horizon. In a comparison to baseline methods, we show
that this effectiveness depends crucially on combining multi-step planning with
a realistic model of user awareness. As the first application of RSA for
communication in a dynamic environment, and for human-AI interaction in
general, we establish theoretical foundations for pragmatic communication in
human-agent teams, highlighting how insights from cognitive science can be
capitalised to inform the design of assistive agents.

</details>


### [136] [Opinion Mining Based Entity Ranking using Fuzzy Logic Algorithmic Approach](https://arxiv.org/abs/2510.23384)
*Pratik N. Kalamkar,A. G. Phakatkar*

Main category: cs.AI

TL;DR: 提出了一种基于模糊逻辑推理的细粒度意见挖掘方法，用于从评论文本中提取更详细的观点信息并据此对实体进行排名。


<details>
  <summary>Details</summary>
Motivation: 随着社交网络和电商网站的发展，网络上存在大量观点数据。现有研究主要关注基于评论集对实体进行排名，但缺乏将观点分类到更细粒度级别后再进行实体排名的研究。

Method: 使用模糊逻辑推理从语句中进行更深层次的细粒度意见挖掘，然后基于这些信息对实体进行排名。

Result: 该方法能够从评论文本中提取更详细的属性和组件信息，并确定评论的情感极性（正面、负面或中性）。

Conclusion: 该方法填补了现有研究的空白，首次实现了将观点分类到更细粒度级别后再进行实体排名，为意见挖掘领域提供了新的技术途径。

Abstract: Opinions are central to almost all human activities and are key influencers
of our behaviors. In current times due to growth of social networking website
and increase in number of e-commerce site huge amount of opinions are now
available on web. Given a set of evaluative statements that contain opinions
(or sentiments) about an Entity, opinion mining aims to extract attributes and
components of the object that have been commented on in each statement and to
determine whether the comments are positive, negative or neutral. While lot of
research recently has been done in field of opinion mining and some of it
dealing with ranking of entities based on review or opinion set, classifying
opinions into finer granularity level and then ranking entities has never been
done before. In this paper method for opinion mining from statements at a
deeper level of granularity is proposed. This is done by using fuzzy logic
reasoning, after which entities are ranked as per this information.

</details>


### [137] [Bid2X: Revealing Dynamics of Bidding Environment in Online Advertising from A Foundation Model Lens](https://arxiv.org/abs/2510.23410)
*Jiahao Ji,Tianyu Wang,Yeshu Li,Yushen Huo,Zhilin Zhang,Chuan Yu,Jian Xu,Bo Zheng*

Main category: cs.AI

TL;DR: 提出了Bid2X竞价基础模型，通过统一函数学习不同竞价场景下的效果估计，使用注意力机制处理异构数据，在淘宝平台部署后显著提升了GMV和ROI。


<details>
  <summary>Details</summary>
Motivation: 解决现有竞价模型在跨环境通用性方面的局限性，传统模型通常针对特定竞价场景设计，缺乏跨场景的普适性。

Method: 构建基于统一序列嵌入的Bid2X模型，使用两种注意力机制分别处理不同变量和不同时间的嵌入，结合变量感知融合模块和零膨胀投影模块进行联合优化。

Result: 在8个数据集上的离线评估显示Bid2X优于各种基线方法，在线A/B测试中GMV提升4.65%，ROI提升2.44%。

Conclusion: Bid2X为计算广告中的竞价基础模型开辟了新途径，证明了其在多场景下的通用性和有效性。

Abstract: Auto-bidding is crucial in facilitating online advertising by automatically
providing bids for advertisers. While previous work has made great efforts to
model bidding environments for better ad performance, it has limitations in
generalizability across environments since these models are typically tailored
for specific bidding scenarios. To this end, we approach the
scenario-independent principles through a unified function that estimates the
achieved effect under specific bids, such as budget consumption, gross
merchandise volume (GMV), page views, etc. Then, we propose a bidding
foundation model Bid2X to learn this fundamental function from data in various
scenarios. Our Bid2X is built over uniform series embeddings that encode
heterogeneous data through tailored embedding methods. To capture complex
inter-variable and dynamic temporal dependencies in bidding data, we propose
two attention mechanisms separately treating embeddings of different variables
and embeddings at different times as attention tokens for representation
learning. On top of the learned variable and temporal representations, a
variable-aware fusion module is used to perform adaptive bidding outcome
prediction. To model the unique bidding data distribution, we devise a
zero-inflated projection module to incorporate the estimated non-zero
probability into its value prediction, which makes up a joint optimization
objective containing classification and regression. The objective is proven to
converge to the zero-inflated distribution. Our model has been deployed on the
ad platform in Taobao, one of the world's largest e-commerce platforms. Offline
evaluation on eight datasets exhibits Bid2X's superiority compared to various
baselines and its generality across different scenarios. Bid2X increased GMV by
4.65% and ROI by 2.44% in online A/B tests, paving the way for bidding
foundation model in computational advertising.

</details>


### [138] [Causal Deep Q Network](https://arxiv.org/abs/2510.23424)
*Elouanes Khelifi,Amir Saki,Usef Faghihi*

Main category: cs.AI

TL;DR: 将因果推理集成到DQN中，使用PEACE公式估计因果效应，减少虚假相关性，提升问题解决能力


<details>
  <summary>Details</summary>
Motivation: 传统的DQN依赖关联学习，容易获得虚假相关性，限制了其问题解决能力

Method: 提出将因果原理集成到DQN中的新方法，利用PEACE公式估计因果效应，在训练过程中融入因果推理

Result: 在标准基准环境上的实验结果表明，该方法优于传统DQN，展示了因果推理在强化学习中的有效性

Conclusion: 这项工作为通过原则性因果推断提升深度强化学习智能体能力提供了有前景的途径

Abstract: Deep Q Networks (DQN) have shown remarkable success in various reinforcement
learning tasks. However, their reliance on associative learning often leads to
the acquisition of spurious correlations, hindering their problem-solving
capabilities. In this paper, we introduce a novel approach to integrate causal
principles into DQNs, leveraging the PEACE (Probabilistic Easy vAriational
Causal Effect) formula for estimating causal effects. By incorporating causal
reasoning during training, our proposed framework enhances the DQN's
understanding of the underlying causal structure of the environment, thereby
mitigating the influence of confounding factors and spurious correlations. We
demonstrate that integrating DQNs with causal capabilities significantly
enhances their problem-solving capabilities without compromising performance.
Experimental results on standard benchmark environments showcase that our
approach outperforms conventional DQNs, highlighting the effectiveness of
causal reasoning in reinforcement learning. Overall, our work presents a
promising avenue for advancing the capabilities of deep reinforcement learning
agents through principled causal inference.

</details>


### [139] [A Neuro-Symbolic Multi-Agent Approach to Legal-Cybersecurity Knowledge Integration](https://arxiv.org/abs/2510.23443)
*Chiara Bonfanti,Alessandro Druetto,Cataldo Basile,Tharindu Ranasinghe,Marcos Zampieri*

Main category: cs.AI

TL;DR: 开发智能系统以解决网络安全与法律交叉领域的信息复杂性，促进法律专家与网络安全专业人员之间的协作。


<details>
  <summary>Details</summary>
Motivation: 网络安全与法律的交叉领域信息复杂，传统法律研究工具难以处理案例、法规和技术漏洞之间的细微联系，阻碍了法律专家与网络安全专业人员的协作。

Method: 开发能够导航日益复杂的网络法律领域的智能系统，并在多语言任务上进行了初步验证。

Result: 在多语言任务上取得了有希望的初步结果。

Conclusion: 这项工作为解决网络安全与法律交叉领域的信息复杂性提供了初步解决方案，展示了智能系统在该领域的潜力。

Abstract: The growing intersection of cybersecurity and law creates a complex
information space where traditional legal research tools struggle to deal with
nuanced connections between cases, statutes, and technical vulnerabilities.
This knowledge divide hinders collaboration between legal experts and
cybersecurity professionals. To address this important gap, this work provides
a first step towards intelligent systems capable of navigating the increasingly
intricate cyber-legal domain. We demonstrate promising initial results on
multilingual tasks.

</details>


### [140] [What are the odds? Risk and uncertainty about AI existential risk](https://arxiv.org/abs/2510.23453)
*Marco Grossi*

Main category: cs.AI

TL;DR: 本文是对Cappelen等人关于AI生存风险分类分析论文的评论，重点讨论了风险线性模型的哲学局限性，分析了瑞士奶酪模型与作者模型的差异，并探讨了认知漠视情境下P(D)概率的结构性影响因素。


<details>
  <summary>Details</summary>
Motivation: 作者旨在提醒人们注意风险线性模型的哲学局限性，特别是在AI生存风险评估中，传统的概率模型可能无法充分捕捉到结构性不确定性的影响。

Method: 通过比较标准瑞士奶酪模型与作者提出的模型，分析在认知漠视情境下P(D)概率的结构性影响因素，并区分风险与不确定性，引入选项不确定性和状态空间不确定性两个维度。

Result: 分析表明在认知漠视情境下，由于各层之间的结构关系，P(D)的概率可能比最初预期的要高，且任何P(D)估计都受到两种不确定性的结构性影响。

Conclusion: 将选项不确定性和状态空间不确定性纳入AI生存风险的定性讨论中，能够更好地理解P(D)的可能性，从而提供更全面的风险评估框架。

Abstract: This work is a commentary of the article
\href{https://doi.org/10.18716/ojs/phai/2025.2801}{AI Survival Stories: a
Taxonomic Analysis of AI Existential Risk} by Cappelen, Goldstein, and
Hawthorne. It is not just a commentary though, but a useful reminder of the
philosophical limitations of \say{linear} models of risk. The article will
focus on the model employed by the authors: first, I discuss some differences
between standard Swiss Cheese models and this one. I then argue that in a
situation of epistemic indifference the probability of P(D) is higher than what
one might first suggest, given the structural relationships between layers. I
then distinguish between risk and uncertainty, and argue that any estimation of
P(D) is structurally affected by two kinds of uncertainty: option uncertainty
and state-space uncertainty. Incorporating these dimensions of uncertainty into
our qualitative discussion on AI existential risk can provide a better
understanding of the likeliness of P(D).

</details>


### [141] [Policy-Aware Generative AI for Safe, Auditable Data Access Governance](https://arxiv.org/abs/2510.23474)
*Shames Al Mandalawi,Muzakkiruddin Ahmed Mohammed,Hendrika Maclean,Mert Can Cakmak,John R. Talburt*

Main category: cs.AI

TL;DR: 提出一个基于LLM的策略感知控制器，使用六阶段推理框架来解释自然语言请求，结合硬策略门控和默认拒绝机制，实现安全、合规且可追踪的访问决策。


<details>
  <summary>Details</summary>
Motivation: 企业需要满足最小权限、合规性和可审计性的访问决策，但传统方法难以处理自然语言请求与书面策略的匹配。

Method: 使用Google Gemini 2.0 Flash实现六阶段推理框架：上下文解释、用户验证、数据分类、业务目的测试、合规映射和风险综合，采用早期硬策略门控和默认拒绝机制。

Result: 在14个标准案例上的评估显示：精确决策匹配从10/14提升到13/14（92.9%），拒绝召回率达到1.00，必须拒绝场景的误批准率降为0，功能适当性和合规性均为14/14，专家对推理质量评价高，中位延迟低于1分钟。

Conclusion: 策略约束的LLM推理结合显式门控和审计追踪，能够将人类可读策略转化为安全、合规且可追踪的机器决策。

Abstract: Enterprises need access decisions that satisfy least privilege, comply with
regulations, and remain auditable. We present a policy aware controller that
uses a large language model (LLM) to interpret natural language requests
against written policies and metadata, not raw data. The system, implemented
with Google Gemini~2.0 Flash, executes a six-stage reasoning framework (context
interpretation, user validation, data classification, business purpose test,
compliance mapping, and risk synthesis) with early hard policy gates and deny
by default. It returns APPROVE, DENY, CONDITIONAL together with cited controls
and a machine readable rationale. We evaluate on fourteen canonical cases
across seven scenario families using a privacy preserving benchmark. Results
show Exact Decision Match improving from 10/14 to 13/14 (92.9\%) after applying
policy gates, DENY recall rising to 1.00, False Approval Rate on must-deny
families dropping to 0, and Functional Appropriateness and Compliance Adherence
at 14/14. Expert ratings of rationale quality are high, and median latency is
under one minute. These findings indicate that policy constrained LLM
reasoning, combined with explicit gates and audit trails, can translate human
readable policies into safe, compliant, and traceable machine decisions.

</details>


### [142] [Human-AI Collaborative Uncertainty Quantification](https://arxiv.org/abs/2510.23476)
*Sima Noorani,Shayan Kiyani,George Pappas,Hamed Hassani*

Main category: cs.AI

TL;DR: 提出了Human AI Collaborative Uncertainty Quantification框架，通过AI模型优化人类专家的预测集，避免反事实伤害并实现互补性，在图像分类、回归和医疗决策等任务中优于单独的人类或AI。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在高风险决策中缺乏领域知识、长期上下文和物理世界推理能力，需要结合人类和AI的互补优势来构建可靠的协作决策框架。

Method: 基于不确定性量化的协作框架，通过双阈值结构的预测集优化算法，包括离线和在线校准方法，能够适应分布漂移和人类行为变化。

Result: 实验表明协作预测集在覆盖率和集合大小方面均优于单独的人类或AI，在各种条件下表现更优。

Conclusion: Human AI Collaborative Uncertainty Quantification框架为可靠决策提供了理论基础和实用算法，证明了人类与AI协作的优越性。

Abstract: AI predictive systems are increasingly embedded in decision making pipelines,
shaping high stakes choices once made solely by humans. Yet robust decisions
under uncertainty still rely on capabilities that current AI lacks: domain
knowledge not captured by data, long horizon context, and reasoning grounded in
the physical world. This gap has motivated growing efforts to design
collaborative frameworks that combine the complementary strengths of humans and
AI. This work advances this vision by identifying the fundamental principles of
Human AI collaboration within uncertainty quantification, a key component of
reliable decision making. We introduce Human AI Collaborative Uncertainty
Quantification, a framework that formalizes how an AI model can refine a human
expert's proposed prediction set with two goals: avoiding counterfactual harm,
ensuring the AI does not degrade correct human judgments, and complementarity,
enabling recovery of correct outcomes the human missed. At the population
level, we show that the optimal collaborative prediction set follows an
intuitive two threshold structure over a single score function, extending a
classical result in conformal prediction. Building on this insight, we develop
practical offline and online calibration algorithms with provable distribution
free finite sample guarantees. The online method adapts to distribution shifts,
including human behavior evolving through interaction with AI, a phenomenon we
call Human to AI Adaptation. Experiments across image classification,
regression, and text based medical decision making show that collaborative
prediction sets consistently outperform either agent alone, achieving higher
coverage and smaller set sizes across various conditions.

</details>


### [143] [Are Agents Just Automata? On the Formal Equivalence Between Agentic AI and the Chomsky Hierarchy](https://arxiv.org/abs/2510.23487)
*Roham Koohestani,Ziyou Li,Anton Podkopaev,Maliheh Izadi*

Main category: cs.AI

TL;DR: 本文建立了现代智能体AI系统架构与乔姆斯基层次结构抽象机之间的形式等价关系，提出基于内存架构的智能体计算能力分类框架。


<details>
  <summary>Details</summary>
Motivation: 为智能体AI系统提供形式化理论基础，实现架构优化、形式验证和安全保障，应用成熟的自动机理论技术来保证智能体的安全性和可预测性。

Method: 通过分析智能体的内存架构特征，将其映射到对应的自动机类别：简单反射智能体对应有限自动机，分层任务分解智能体对应下推自动机，具有读写内存的反思智能体对应图灵机。

Result: 建立了智能体-自动机框架，能够对智能体进行形式化分类，明确可验证系统与行为不可判定系统之间的界限，并扩展到概率自动机以处理LLM的随机性。

Conclusion: 该框架为智能体架构优化和形式验证提供了理论基础，并提出了开发静态分析工具和智能体框架语法的未来研究方向。

Abstract: This paper establishes a formal equivalence between the architectural classes
of modern agentic AI systems and the abstract machines of the Chomsky
hierarchy. We posit that the memory architecture of an AI agent is the
definitive feature determining its computational power and that it directly
maps it to a corresponding class of automaton. Specifically, we demonstrate
that simple reflex agents are equivalent to Finite Automata, hierarchical
task-decomposition agents are equivalent to Pushdown Automata, and agents
employing readable/writable memory for reflection are equivalent to TMs. This
Automata-Agent Framework provides a principled methodology for right-sizing
agent architectures to optimize computational efficiency and cost. More
critically, it creates a direct pathway to formal verification, enables the
application of mature techniques from automata theory to guarantee agent safety
and predictability. By classifying agents, we can formally delineate the
boundary between verifiable systems and those whose behavior is fundamentally
undecidable. We address the inherent probabilistic nature of LLM-based agents
by extending the framework to probabilistic automata that allow quantitative
risk analysis. The paper concludes by outlining an agenda for developing static
analysis tools and grammars for agentic frameworks.

</details>


### [144] [Emotion-Coherent Reasoning for Multimodal LLMs via Emotional Rationale Verifier](https://arxiv.org/abs/2510.23506)
*Hyeongseop Rha,Jeong Hun Yeo,Yeonju Kim,Yong Man Ro*

Main category: cs.AI

TL;DR: 提出情感推理验证器(ERV)和解释奖励方法，解决多模态大语言模型在情感识别中解释与预测不一致的问题，无需修改模型架构或额外标注数据。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在情感识别中生成的情感解释常常与目标标签不符，甚至与自身预测的情感相矛盾，这种不一致性会降低系统可靠性和用户信任度。

Method: 提出情感推理验证器(ERV)和解释奖励机制，引导模型在情感识别过程中生成与目标情感明确一致的推理，无需修改模型架构或额外视频描述标注。

Result: 在MAFW和DFEW数据集上显著提高了解释-预测一致性和解释情感准确性，通过实验和人工评估验证了方法的有效性。

Conclusion: 该方法不仅增强了解释与预测的对齐性，还使多模态大语言模型能够提供情感一致、可信赖的交互，是实现真正类人HCI系统的关键一步。

Abstract: The recent advancement of Multimodal Large Language Models (MLLMs) is
transforming human-computer interaction (HCI) from surface-level exchanges into
more nuanced and emotionally intelligent communication. To realize this shift,
emotion understanding becomes essential allowing systems to capture subtle cues
underlying user intent. Furthermore, providing faithful explanations for
predicted emotions is crucial to ensure interpretability and build user trust.
However, current MLLM-based methods often generate emotion explanations that
diverge from the target labels and sometimes even contradict their own
predicted emotions. This inconsistency poses a critical risk for
misunderstanding and erodes reliability in interactive settings. To address
this, we propose a novel approach: the Emotional Rationale Verifier (ERV) and
an Explanation Reward. Our method guides the model to produce reasoning that is
explicitly consistent with the target emotion during multimodal emotion
recognition without modifying the model architecture or requiring additional
paired video-description annotations. Our method significantly improves
faithful explanation-prediction consistency and explanation emotion accuracy on
the MAFW and DFEW datasets. Through extensive experiments and human
evaluations, we show that our approach not only enhances alignment between
explanation and prediction but also empowers MLLMs to deliver emotionally
coherent, trustworthy interactions, marking a key step toward truly human-like
HCI systems.

</details>


### [145] [Toward Carbon-Neutral Human AI: Rethinking Data, Computation, and Learning Paradigms for Sustainable Intelligence](https://arxiv.org/abs/2510.23524)
*KC Santosh,Rodrigue Rizk,Longwei Wang*

Main category: cs.AI

TL;DR: 提出了一种名为HAI（Human AI）的新型可持续AI框架，强调增量学习、碳感知优化和人机协作，以解决AI发展带来的环境和伦理问题。


<details>
  <summary>Details</summary>
Motivation: AI快速发展带来了巨大的计算需求，引发了环境和伦理担忧。批评当前依赖大规模静态数据集和单一训练范式的做法，倡导转向人类启发的可持续AI解决方案。

Method: 引入HAI框架，基于生物认知原理，采用动态架构，实现增量学习、碳感知优化和人机协作。详细阐述了理论基础、系统设计和操作原则。

Result: HAI框架能够实现持续情境学习，同时最小化碳足迹和人工标注成本。解决了主动学习、持续适应和节能模型部署等关键挑战。

Conclusion: HAI为负责任、以人为中心的人工智能提供了一条可行路径，平衡了性能与生态责任，推动了可持续AI的发展。

Abstract: The rapid advancement of Artificial Intelligence (AI) has led to
unprecedented computational demands, raising significant environmental and
ethical concerns. This paper critiques the prevailing reliance on large-scale,
static datasets and monolithic training paradigms, advocating for a shift
toward human-inspired, sustainable AI solutions. We introduce a novel
framework, Human AI (HAI), which emphasizes incremental learning, carbon-aware
optimization, and human-in-the-loop collaboration to enhance adaptability,
efficiency, and accountability. By drawing parallels with biological cognition
and leveraging dynamic architectures, HAI seeks to balance performance with
ecological responsibility. We detail the theoretical foundations, system
design, and operational principles that enable AI to learn continuously and
contextually while minimizing carbon footprints and human annotation costs. Our
approach addresses pressing challenges in active learning, continual
adaptation, and energy-efficient model deployment, offering a pathway toward
responsible, human-centered artificial intelligence.

</details>


### [146] [When No Paths Lead to Rome: Benchmarking Systematic Neural Relational Reasoning](https://arxiv.org/abs/2510.23532)
*Anirban Das,Irtaza Khalid,Rafael Peñaloza,Steven Schockaert*

Main category: cs.AI

TL;DR: NoRA是一个新的系统性关系推理基准，它增加了多个难度级别，要求模型超越基于路径的推理方法。


<details>
  <summary>Details</summary>
Motivation: 现有系统性关系推理基准过于简化，假设推理可以简化为组合关系路径，这限制了模型的泛化能力。

Method: 引入NoRA基准，包含多个难度级别，挑战模型超越路径推理的能力。

Result: NoRA基准为系统性关系推理提供了更全面的评估框架。

Conclusion: NoRA基准将推动神经网络在系统性关系推理领域的进一步发展。

Abstract: Designing models that can learn to reason in a systematic way is an important
and long-standing challenge. In recent years, a wide range of solutions have
been proposed for the specific case of systematic relational reasoning,
including Neuro-Symbolic approaches, variants of the Transformer architecture,
and specialised Graph Neural Networks. However, existing benchmarks for
systematic relational reasoning focus on an overly simplified setting, based on
the assumption that reasoning can be reduced to composing relational paths. In
fact, this assumption is hard-baked into the architecture of several recent
models, leading to approaches that can perform well on existing benchmarks but
are difficult to generalise to other settings. To support further progress in
the field of systematic relational reasoning with neural networks, we introduce
NoRA, a new benchmark which adds several levels of difficulty and requires
models to go beyond path-based reasoning.

</details>


### [147] [JanusCoder: Towards a Foundational Visual-Programmatic Interface for Code Intelligence](https://arxiv.org/abs/2510.23538)
*Qiushi Sun,Jingyang Gong,Yang Liu,Qiaosheng Chen,Lei Li,Kai Chen,Qipeng Guo,Ben Kao,Fei Yuan*

Main category: cs.AI

TL;DR: 提出了JanusCode-800K，这是迄今为止最大的多模态代码语料库，并基于此训练了JanusCoder系列模型，在文本和视觉编码任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 神经代码智能的范围正在从基于文本的源代码扩展到程序生成的丰富视觉输出，但高质量多模态代码数据的稀缺阻碍了进展。

Method: 首先开发了一个完整的合成工具包，利用数据模态之间的协同作用高效生成大规模高质量语料库，然后训练JanusCoder和JanusCoderV模型，建立视觉-程序接口。

Result: JanusCoder系列在文本和视觉编码任务上表现出卓越性能，7B到14B规模的模型接近甚至超过商业模型的性能。

Conclusion: 该工作为协调程序逻辑与其视觉表达提供了关键见解，统一模型方法优于为孤立任务构建专门模型的现有方法。

Abstract: The scope of neural code intelligence is rapidly expanding beyond text-based
source code to encompass the rich visual outputs that programs generate. This
visual dimension is critical for advanced applications like flexible content
generation and precise, program-driven editing of visualizations. However,
progress has been impeded by the scarcity of high-quality multimodal code data,
a bottleneck stemming from challenges in synthesis and quality assessment. To
address these challenges, we make contributions from both a data and modeling
perspective. We first introduce a complete synthesis toolkit that leverages
reciprocal synergies between data modalities to efficiently produce a
large-scale, high-quality corpus spanning from standard charts to complex
interactive web UIs and code-driven animations. Leveraging this toolkit, we
construct JanusCode-800K, the largest multimodal code corpus to date. This
powers the training of our models, JanusCoder and JanusCoderV, which establish
a visual-programmatic interface for generating code from textual instructions,
visual inputs, or a combination of both. Our unified model is a departure from
existing approaches that build specialized models for isolated tasks. Extensive
experiments on both text-centric and vision-centric coding tasks demonstrate
the superior performance of the JanusCoder series, with our 7B to 14B scale
models approaching or even exceeding the performance of commercial models.
Furthermore, extensive analysis provides key insights into harmonizing
programmatic logic with its visual expression. Our code and checkpoints will
are available at https://github.com/InternLM/JanusCoder.

</details>


### [148] [OntoPret: An Ontology for the Interpretation of Human Behavior](https://arxiv.org/abs/2510.23553)
*Alexis Ellis,Stacie Severyn,Fjollë Novakazi,Hadi Banaee,Cogan Shimizu*

Main category: cs.AI

TL;DR: OntoPret是一个基于认知科学和模块化工程方法的人类行为解释本体论，为机器提供可处理的行为分类框架，支持任务偏差和欺骗行为的识别。


<details>
  <summary>Details</summary>
Motivation: 随着人机协作在工业5.0等范式中变得重要，需要机器能安全有效地解释复杂人类行为。当前技术中心机器人框架缺乏细致的人类行为模型，而描述性行为本体论又无法实现实时协作解释。

Method: 基于认知科学和模块化工程方法，开发了OntoPret本体论，提供形式化的机器可处理框架来分类行为，包括任务偏差和欺骗行为。

Result: 在制造和游戏两个不同用例中验证了OntoPret的适应性，并建立了高级人类意图推理所需的语义基础。

Conclusion: OntoPret填补了技术中心框架与描述性行为本体论之间的研究空白，为人机协作中的行为解释提供了有效解决方案。

Abstract: As human machine teaming becomes central to paradigms like Industry 5.0, a
critical need arises for machines to safely and effectively interpret complex
human behaviors. A research gap currently exists between techno centric robotic
frameworks, which often lack nuanced models of human behavior, and descriptive
behavioral ontologies, which are not designed for real time, collaborative
interpretation. This paper addresses this gap by presenting OntoPret, an
ontology for the interpretation of human behavior. Grounded in cognitive
science and a modular engineering methodology, OntoPret provides a formal,
machine processable framework for classifying behaviors, including task
deviations and deceptive actions. We demonstrate its adaptability across two
distinct use cases manufacturing and gameplay and establish the semantic
foundations necessary for advanced reasoning about human intentions.

</details>


### [149] [ReCode: Unify Plan and Action for Universal Granularity Control](https://arxiv.org/abs/2510.23564)
*Zhaoyang Yu,Jiayi Zhang,Huixue Su,Yufan Zhao,Yifan Wu,Mingyi Deng,Jinyu Xiang,Yizhang Lin,Lingxiao Tang,Yingchao Li,Yuyu Luo,Bang Liu,Chenglin Wu*

Main category: cs.AI

TL;DR: ReCode提出了一种通过递归代码生成统一规划和行动的新范式，将高级计划视为抽象占位函数，递归分解为更细粒度的子函数，实现动态决策粒度控制。


<details>
  <summary>Details</summary>
Motivation: 现实世界任务需要在不同粒度上做决策，人类擅长利用统一的认知表示进行规划，但当前基于LLM的智能体缺乏这种跨粒度操作的灵活性。现有范式在高级规划和低级行动之间设置了严格分离，限制了动态适应性和泛化能力。

Method: ReCode将规划和行动统一在单一代码表示中，将高级计划视为抽象占位函数，然后递归地将其分解为更细粒度的子函数，直到达到原始行动。这种递归方法消除了计划和行动之间的严格界限。

Result: 大量实验表明，ReCode在推理性能上显著超越先进基线，并在训练中表现出卓越的数据效率，验证了通过递归代码生成统一规划和行动是实现通用粒度控制的有效方法。

Conclusion: 通过递归代码生成将规划和行动统一起来是实现通用粒度控制的强大而有效的方法，ReCode范式解决了现有LLM智能体在跨粒度决策能力上的关键限制。

Abstract: Real-world tasks require decisions at varying granularities, and humans excel
at this by leveraging a unified cognitive representation where planning is
fundamentally understood as a high-level form of action. However, current Large
Language Model (LLM)-based agents lack this crucial capability to operate
fluidly across decision granularities. This limitation stems from existing
paradigms that enforce a rigid separation between high-level planning and
low-level action, which impairs dynamic adaptability and limits generalization.
We propose ReCode (Recursive Code Generation), a novel paradigm that addresses
this limitation by unifying planning and action within a single code
representation. In this representation, ReCode treats high-level plans as
abstract placeholder functions, which the agent then recursively decomposes
into finer-grained sub-functions until reaching primitive actions. This
recursive approach dissolves the rigid boundary between plan and action,
enabling the agent to dynamically control its decision granularity.
Furthermore, the recursive structure inherently generates rich,
multi-granularity training data, enabling models to learn hierarchical
decision-making processes. Extensive experiments show ReCode significantly
surpasses advanced baselines in inference performance and demonstrates
exceptional data efficiency in training, validating our core insight that
unifying planning and action through recursive code generation is a powerful
and effective approach to achieving universal granularity control. The code is
available at https://github.com/FoundationAgents/ReCode.

</details>


### [150] [Reduced AI Acceptance After the Generative AI Boom: Evidence From a Two-Wave Survey Study](https://arxiv.org/abs/2510.23578)
*Joachim Baumann,Aleksandra Urman,Ulrich Leicht-Deobald,Zachary J. Roman,Anikó Hannák,Markus Christen*

Main category: cs.AI

TL;DR: ChatGPT发布后，公众对AI的接受度下降，对人机协作的需求增加，并加剧了社会不平等。


<details>
  <summary>Details</summary>
Motivation: 探索生成式AI技术快速普及背景下，公众对AI态度的变化，特别是在有影响力的决策场景中。

Method: 使用瑞士人口代表性的大规模两波调查（n_wave1=1514，n_wave2=1488），比较ChatGPT发布前后的公众态度变化。

Result: 生成式AI热潮显著降低了公众对AI的接受度，增加了对人工监督的需求。"完全不可接受"AI的比例从23%升至30%，支持纯人工决策的比例从18%升至26%，并扩大了教育、语言和性别差距。

Conclusion: 研究结果挑战了行业对公众AI部署准备度的假设，强调技术发展必须与不断变化的公众偏好保持一致的重要性。

Abstract: The rapid adoption of generative artificial intelligence (GenAI) technologies
has led many organizations to integrate AI into their products and services,
often without considering user preferences. Yet, public attitudes toward AI
use, especially in impactful decision-making scenarios, are underexplored.
Using a large-scale two-wave survey study (n_wave1=1514, n_wave2=1488)
representative of the Swiss population, we examine shifts in public attitudes
toward AI before and after the launch of ChatGPT. We find that the GenAI boom
is significantly associated with reduced public acceptance of AI (see Figure 1)
and increased demand for human oversight in various decision-making contexts.
The proportion of respondents finding AI "not acceptable at all" increased from
23% to 30%, while support for human-only decision-making rose from 18% to 26%.
These shifts have amplified existing social inequalities in terms of widened
educational, linguistic, and gender gaps post-boom. Our findings challenge
industry assumptions about public readiness for AI deployment and highlight the
critical importance of aligning technological development with evolving public
preferences.

</details>


### [151] [Multi-Agent Evolve: LLM Self-Improve through Co-evolution](https://arxiv.org/abs/2510.23595)
*Yixing Chen,Yiding Wang,Siqi Zhu,Haofei Yu,Tao Feng,Muhan Zhan,Mostofa Patwary,Jiaxuan You*

Main category: cs.AI

TL;DR: 提出了MAE框架，通过三个交互智能体（提议者、求解者、评判者）实现LLM的自我进化，在数学、推理和常识问答等任务上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法依赖人工标注数据和可验证奖励，限制了可扩展性和通用性。需要开发不依赖人工监督的自进化方法。

Method: MAE框架包含三个基于同一LLM的智能体：提议者生成问题，求解者尝试解答，评判者评估并共同进化，应用强化学习优化行为。

Result: 在Qwen2.5-3B-Instruct上实验表明，MAE在多个基准测试中平均提升4.54%。

Conclusion: MAE是一种可扩展、数据高效的方法，能够以最少的人工监督显著增强LLM的通用推理能力。

Abstract: Reinforcement Learning (RL) has demonstrated significant potential in
enhancing the reasoning capabilities of large language models (LLMs). However,
the success of RL for LLMs heavily relies on human-curated datasets and
verifiable rewards, which limit their scalability and generality. Recent
Self-Play RL methods, inspired by the success of the paradigm in games and Go,
aim to enhance LLM reasoning capabilities without human-annotated data.
However, their methods primarily depend on a grounded environment for feedback
(e.g., a Python interpreter or a game engine); extending them to general
domains remains challenging. To address these challenges, we propose
Multi-Agent Evolve (MAE), a framework that enables LLMs to self-evolve in
solving diverse tasks, including mathematics, reasoning, and general knowledge
Q&A. The core design of MAE is based on a triplet of interacting agents
(Proposer, Solver, Judge) that are instantiated from a single LLM, and applies
reinforcement learning to optimize their behaviors. The Proposer generates
questions, the Solver attempts solutions, and the Judge evaluates both while
co-evolving. Experiments on Qwen2.5-3B-Instruct demonstrate that MAE achieves
an average improvement of 4.54% on multiple benchmarks. These results highlight
MAE as a scalable, data-efficient method for enhancing the general reasoning
abilities of LLMs with minimal reliance on human-curated supervision.

</details>


### [152] [Alita-G: Self-Evolving Generative Agent for Agent Generation](https://arxiv.org/abs/2510.23601)
*Jiahao Qiu,Xuan Qi,Hongru Wang,Xinzhe Juan,Yimin Wang,Zelin Zhao,Jiayi Geng,Jiacheng Guo,Peihang Li,Jingzhe Shi,Shilong Liu,Mengdi Wang*

Main category: cs.AI

TL;DR: ALITA-G是一个自进化框架，通过系统生成、抽象和整理MCP工具，将通用代理转变为领域专家，在多个基准测试中实现性能提升并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前的自进化代理主要局限于提示重写或失败重试，缺乏系统性的能力进化方法，因此需要开发能够将通用代理系统性地转变为领域专家的框架。

Method: 通过执行目标领域任务，从成功轨迹中合成候选MCP工具，将其抽象为参数化原语并整合到MCP Box中，在推理时执行检索增强的MCP选择并使用MCP执行器。

Result: 在GAIA验证集上达到83.03% pass@1和89.09% pass@3的新SOTA结果，同时将每个示例的平均token数减少约15%。

Conclusion: ALITA-G提供了从通用能力到可重用领域特定能力的原理性路径，在复杂推理任务上同时提高了准确性和效率。

Abstract: Large language models (LLMs) have been shown to perform better when
scaffolded into agents with memory, tools, and feedback. Beyond this,
self-evolving agents have emerged, but current work largely limits adaptation
to prompt rewriting or failure retries. Therefore, we present ALITA-G, a
self-evolution framework that transforms a general-purpose agent into a domain
expert by systematically generating, abstracting, and curating Model Context
Protocol (MCP) tools. In this framework, a generalist agent executes a curated
suite of target-domain tasks and synthesizes candidate MCPs from successful
trajectories. These are then abstracted to parameterized primitives and
consolidated into an MCP Box. At inference time, ALITA-G performs
retrieval-augmented MCP selection with the help of each tool's descriptions and
use cases, before executing an agent equipped with the MCP Executor. Across
several benchmarks GAIA, PathVQA, and Humanity's Last Exam, ALITA-G attains
strong gains while reducing computation costs. On GAIA validation, it achieves
83.03% pass@1 and 89.09% pass@3, establishing a new state-of-the-art result
while reducing mean tokens per example by approximately 15% relative to a
strong baseline agent. ALITA-G thus provides a principled pathway from
generalist capability to reusable, domain-specific competence, improving both
accuracy and efficiency on complex reasoning tasks.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [153] [Quantifying the AI Gap: A Comparative Index of Development in the United States and Chinese Regions](https://arxiv.org/abs/2510.21832)
*Yuanxi Li,Lei Yin*

Main category: cs.CY

TL;DR: 开发了包含七个维度的综合AI指数，用于省级和行业分析。中美比较显示美国得分(68.1)高于中国(59.4)，中国内部呈现明显的区域发展不平衡。


<details>
  <summary>Details</summary>
Motivation: 为政府机构和研究机构提供学术参考和决策支持工具，帮助制定更有针对性的区域AI发展战略。

Method: 采用锚点法进行数据标准化，使用固定上下限作为基准，设计结合专家判断与客观数据的层次化指标权重系统，数据来源于权威统计、专利、教育等多个领域。

Result: 美国综合得分68.1高于中国的59.4；中国内部北方、东部和南部地区领先，中部和西部地区显著落后，反映了创新和产业资源的区域集中效应。

Conclusion: 该研究提供了一个全面的AI发展评估框架，揭示了中美差距和中国内部的区域不平衡，为政策制定提供了重要参考。

Abstract: This study develops a comprehensive Artificial Intelligence (AI) Index with
seven primary dimensions, designed for provincial-level and industry-specific
analysis. We employ an anchor point method for data normalization, using fixed
upper and lower bounds as benchmarks, and devise a hierarchical indicator
weighting system that combines expert judgment with objective data. The index
draws from authoritative data sources across domains including official
statistics, patents and research outputs, education and talent, industrial
economy, policy and governance, and social impact. The China-US comparison
indicates that under a unified framework, the US composite score (68.1) exceeds
China's (59.4). We further dissect China into seven main areas to form a
sub-national index. The findings reveal stark regional disparities in China's
AI development: the North, East, and South regions lead in composite scores,
whereas central and western regions lag significantly, underscoring the effects
of regional concentration of innovation and industry resources. This research
provides an academic reference and decision support tool for government
agencies and research institutions, informing more targeted regional AI
development strategies.

</details>


### [154] [A quality of mercy is not trained: the imagined vs. the practiced in healthcare process-specialized AI development](https://arxiv.org/abs/2510.21843)
*Anand Bhardwaj,Samer Faraj*

Main category: cs.CY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In high stakes organizational contexts like healthcare, artificial
intelligence (AI) systems are increasingly being designed to augment complex
coordination tasks. This paper investigates how the ethical stakes of such
systems are shaped by their epistemic framings: what aspects of work they
represent, and what they exclude. Drawing on an embedded study of AI
development for operating room (OR) scheduling at a Canadian hospital, we
compare scheduling-as-imagined in the AI design process: rule-bound,
predictable, and surgeon-centric, with scheduling-as-practiced as a fluid,
patient-facing coordination process involving ethical discretion. We show how
early representational decisions narrowed what the AI could support, resulting
in epistemic foreclosure: the premature exclusion of key ethical dimensions
from system design. Our findings surface the moral consequences of abstraction
and call for a more situated approach to designing healthcare
process-specialized artificial intelligence systems.

</details>


### [155] [Barriers to Integrating Low-Power IoT in Engineering Education: A Survey of the Literature](https://arxiv.org/abs/2510.22522)
*V. Sanchez Padilla,Albert Espinal,Jose Cordova-Garcia,Lisa Schibelius*

Main category: cs.CY

TL;DR: 本文分析了在工程教育中采用低功耗物联网技术面临的技术、组织和课程/教学法三大障碍，旨在帮助教育工作者制定更有效的采用策略。


<details>
  <summary>Details</summary>
Motivation: 低功耗物联网技术在工程教育中日益重要，但许多机构在课程和实验室中采用时面临各种障碍，需要系统分析这些障碍以促进更有效的采用。

Method: 通过回顾近期研究，将障碍系统性地分为技术、组织和课程/教学法三大类，并详细分析每类障碍的具体表现。

Result: 识别出技术障碍包括能源管理、可扩展性和集成问题；组织障碍涉及成本、规划和人员培训需求；课程/教学法障碍包括学生准备度不足、实验时间有限和预算依赖的平台选择。

Conclusion: 通过详细分析这些障碍并提供实际案例，本文为教育工作者和学术领导者制定在工程项目中采用低功耗物联网的更有效策略提供了指导。

Abstract: Low-power Internet of Things (IoT) technologies are becoming increasingly
important in engineering education as a tool to help students connect theory to
real applications. However, many institutions face barriers that slow down
their adoption in courses and labs. This paper reviews recent studies to
understand these barriers and organizes them into three groups: technical,
organizational, and curricular/pedagogical. Technical barriers include energy
management, scalability, and integration issues. Organizational barriers are
related to cost, planning, and the need for trained staff. Curricular and
pedagogical barriers include gaps in student readiness, limited lab time, and
platform choices that depend on budget. By detailing these barriers with
practical examples, this paper aims to help educators and academic leaders
develop more effective strategies to adopt low-power IoT in engineering
programs.

</details>


### [156] [Enhancing Student Performance Prediction In CS1 Via In-Class Coding](https://arxiv.org/abs/2510.21848)
*Eric Hics,Vinhthuy Phan,Kriangsiri Malasri*

Main category: cs.CY

TL;DR: 研究发现课堂编程练习可以显著提高对学生表现的早期预测能力，在学期第3-5周就能相对准确地预测学生最终成绩，为早期干预提供可能。


<details>
  <summary>Details</summary>
Motivation: 计算机科学课程吸引了不同学术背景的学生，导致入门课程的高失败率。需要早期识别学习困难学生，课堂编程练习既能提供练习机会，又能帮助教师识别需要帮助的学生。

Method: 基于美国一所中等规模大学CS1课程的数据，分析课堂编程练习对学生表现预测能力的影响。

Result: 课堂编程练习能够改善对学生最终表现的预测，特别是在学期第3-5周就能获得相对准确的预测结果。

Conclusion: 这项研究有助于未来关于课堂练习影响和学期干预策略的研究，为早期识别和帮助学习困难学生提供了有效方法。

Abstract: Computer science's increased recognition as a prominent field of study has
attracted students with diverse academic backgrounds. This has significantly
increased the already high failure rates in introductory courses. To address
this challenge, it is essential to identify struggling students early on.
Incorporating in-class coding exercises in these courses not only offers
additional practice opportunities to students but may also reveal their
abilities and help teachers identify those in need of assistance. In this work,
we seek to determine the extent to which the practice of using in-class coding
exercises enhances the ability to predict student performance, especially early
in the semester. Based on data obtained in a CS1 course taught at a mid-size
American university, we found that in-class exercises could improve the
prediction of students' eventual performance. In particular, we found
relatively accurately predictions as early as academic weeks 3 through 5,
making it possible to devise early intervention strategies. This work can
benefit future studies on the impact of in-class exercises as well as
intervention strategies throughout the semester.

</details>


### [157] [Data-Driven Approach to Capitation Reform in Rwanda](https://arxiv.org/abs/2510.21851)
*Babaniyi Olaniyi,Ina Kalisa,Ana Fernández del Río,Jean Marie Vianney Hakizayezu,Enric Jané,Eniola Olaleye,Juan Francisco Garamendi,Ivan Nazarov,Aditya Rastogi,Mateo Diaz-Quiroz,África Periáñez,Regis Hitimana*

Main category: cs.CY

TL;DR: 卢旺达采用数据驱动方法设计基于人口的预付制支付模式，取代按服务付费，使用索赔数据建立透明支付公式，同时监控抗生素处方行为以提升医疗质量。


<details>
  <summary>Details</summary>
Motivation: 卢旺达向全民健康覆盖过渡，需要从按服务付费转向预付制支付模式，以促进公平、适应性和持续改进。

Method: 使用智能健康福利系统的个体级索赔数据，通过回归模型校准参数，建立基于服务人口、利用模式和患者流入的透明支付公式。

Result: 验证显示支付方案与历史支出高度一致，同时促进设施间的公平性和适应性，并能监控抗生素处方行为。

Conclusion: 该方法为学习型健康融资系统奠定基础，连接数字基础设施、资源分配和服务质量，支持持续改进和循证政策改革。

Abstract: As part of Rwanda's transition toward universal health coverage, the national
Community-Based Health Insurance (CBHI) scheme is moving from retrospective
fee-for-service reimbursements to prospective capitation payments for public
primary healthcare providers. This report outlines a data-driven approach to
designing, calibrating, and monitoring the capitation model using
individual-level claims data from the Intelligent Health Benefits System
(IHBS). We introduce a transparent, interpretable formula for allocating
payments to Health Centers and their affiliated Health Posts. The formula is
based on catchment population, service utilization patterns, and patient
inflows, with parameters estimated via regression models calibrated on national
claims data. Repeated validation exercises show the payment scheme closely
aligns with historical spending while promoting fairness and adaptability
across diverse facilities. In addition to payment design, the same dataset
enables actionable behavioral insights. We highlight the use case of monitoring
antibiotic prescribing patterns, particularly in pediatric care, to flag
potential overuse and guideline deviations. Together, these capabilities lay
the groundwork for a learning health financing system: one that connects
digital infrastructure, resource allocation, and service quality to support
continuous improvement and evidence-informed policy reform.

</details>


### [158] [What Exactly is a Deepfake?](https://arxiv.org/abs/2510.22128)
*Yizhi Liu,Balaji Padmanabhan,Siva Viswanathan*

Main category: cs.CY

TL;DR: 该论文分析了826篇2017-2025年的同行评审文献，发现深度伪造技术的概念化存在显著异质性，挑战了简化的公共叙事，揭示了非欺骗性应用的社会价值潜力。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术通常与欺骗、错误信息和身份欺诈相关联，但可能掩盖了一个关键见解：深度伪造体现了改变人类感知的感官操纵能力，可能在医疗保健和教育等领域实现有益应用。

Method: 使用大型语言模型对826篇同行评审文献进行内容分析，从三个维度对深度伪造概念化进行分类：身份来源（原始内容与生成内容的关系）、意图（欺骗性与非欺骗性目的）和操纵粒度（整体性与针对性修改）。

Result: 结果显示概念化存在显著异质性，部分研究讨论了非欺骗性应用，突出了为社会利益服务的未开发潜力。时间分析显示从主要关注威胁（2017-2019）向认可有益应用（2022-2025）的演变。

Conclusion: 该研究为开发区分应禁止应用与值得支持应用的细致治理和研究框架提供了实证基础，表明在保障措施下，深度伪造的真实感可以服务于欺骗之外的重要社会目的。

Abstract: Deepfake technologies are often associated with deception, misinformation,
and identity fraud, raising legitimate societal concerns. Yet such narratives
may obscure a key insight: deepfakes embody sophisticated capabilities for
sensory manipulation that can alter human perception, potentially enabling
beneficial applications in domains such as healthcare and education. Realizing
this potential, however, requires understanding how the technology is
conceptualized across disciplines. This paper analyzes 826 peer-reviewed
publications from 2017 to 2025 to examine how deepfakes are defined and
understood in the literature. Using large language models for content analysis,
we categorize deepfake conceptualizations along three dimensions: Identity
Source (the relationship between original and generated content), Intent
(deceptive versus non-deceptive purposes), and Manipulation Granularity
(holistic versus targeted modifications). Results reveal substantial
heterogeneity that challenges simplified public narratives. Notably, a subset
of studies discuss non-deceptive applications, highlighting an underexplored
potential for social good. Temporal analysis shows an evolution from
predominantly threat-focused views (2017 to 2019) toward recognition of
beneficial applications (2022 to 2025). This study provides an empirical
foundation for developing nuanced governance and research frameworks that
distinguish applications warranting prohibition from those deserving support,
showing that, with safeguards, deepfakes' realism can serve important social
purposes beyond deception.

</details>


### [159] [Surface Reading LLMs: Synthetic Text and its Styles](https://arxiv.org/abs/2510.22162)
*Hannes Bajohr*

Main category: cs.CY

TL;DR: 该论文提出了一种"表面完整性"的符号学方法，关注LLMs在人类交流中刻写的表层现象，主张将风格分析整合到深度导向的批判中，以揭示LLMs作为文化行动者如何重塑意义生成和流通的条件。


<details>
  <summary>Details</summary>
Motivation: 尽管批判性AI研究提供了重要的物质和社会技术批判，但可能忽视了LLMs在现象学层面如何重塑意义生成过程。论文旨在填补这一空白，关注LLMs在交流表层的影响。

Method: 区分了ML研究的三种知识兴趣（认识论、知识型、认识论实践），提出了"表面完整性"的符号学框架，并通过两个案例研究分析合成文本的风格标记。

Result: 通过风格作为符号现象的分析，揭示了LLMs作为文化行动者如何改变当代话语中意义出现和流通的条件，这与机器意识问题无关。

Conclusion: 需要将表层风格分析与深度导向批判相结合，以全面理解LLMs在人类交流中的文化影响，关注其如何重塑意义生成的条件而非追求超智能。

Abstract: Despite a potential plateau in ML advancement, the societal impact of large
language models lies not in approaching superintelligence but in generating
text surfaces indistinguishable from human writing. While Critical AI Studies
provides essential material and socio-technical critique, it risks overlooking
how LLMs phenomenologically reshape meaning-making. This paper proposes a
semiotics of "surface integrity" as attending to the immediate plane where LLMs
inscribe themselves into human communication. I distinguish three knowledge
interests in ML research (epistemology, epist\=em\=e, and epistemics) and argue
for integrating surface-level stylistic analysis alongside depth-oriented
critique. Through two case studies examining stylistic markers of synthetic
text, I argue how attending to style as a semiotic phenomenon reveals LLMs as
cultural actors that transform the conditions of meaning emergence and
circulation in contemporary discourse, independent of questions about machine
consciousness.

</details>


### [160] [The AI Tutor in Engineering Education: Design, Results, and Redesign of an Experience in Hydrology at an Argentine University](https://arxiv.org/abs/2510.22279)
*Hugo Roger Paz*

Main category: cs.CY

TL;DR: 该研究通过两轮AI导师干预实验，展示了在高等教育中使用ChatGPT时，缺乏明确过程控制会导致学生追求效率而非深度学习，而通过重新设计的提示和严格的证据控制可以显著改善学术诚信和技术表现。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能在高等教育中既带来机遇也带来伦理教学挑战，研究旨在探索如何在STEM课程中有效使用AI工具，同时确保学术诚信和深度学习。

Method: 采用混合方法（可复现的文档分析和评分标准分析），在同一队列中进行两轮干预实验，第一轮失败后重新设计提示和评估标准，第二轮采用严格的过程控制。

Result: 第一轮干预失败（0%通过率，65%相似度，抄袭率>80%），第二轮干预后中位数得分88/100，且能验证真实的互动过程。

Conclusion: 提出基于"可审计个人区域"的可转移评估协议，强调在AI工具使用中需要明确的过程控制来促进高阶思维发展。

Abstract: The emergence of Generative Artificial Intelligence (GenAI) has reshaped
higher education, presenting both opportunities and ethical-pedagogical
challenges. This article presents an empirical case study on the complete cycle
(design, initial failure, redesign, and re-evaluation) of an intervention using
an AI Tutor (ChatGPT) in the "Hydrology and Hydraulic Works" course (Civil
Engineering, UTN-FRT, Argentina). The study documents two interventions in the
same cohort (n=23). The first resulted in widespread failure (0% pass rate) due
to superficial use and serious academic integrity issues (65% similarity,
copies > 80%). This failure forced a comprehensive methodological redesign. The
second intervention, based on a redesigned prompt (Prompt V2) with strict
evidence controls (mandatory Appendix A with exported chat, minimum time $\geq$
120 minutes, verifiable numerical exercise) and a refined rubric (Rubric V2),
showed significantly better results: a median score of 88/100 and verifiable
compliance with genuine interaction processes. Using a mixed-methods approach
(reproducible document analysis and rubric analysis), the impact of the
redesign on integrity and technical performance is evaluated. The results
demonstrate that, without explicit process controls, students prioritize
efficiency over deep learning, submitting documents without real traceability.
A transferable assessment protocol for STEM courses is proposed, centered on
"auditable personal zones," to foster higher-order thinking. The study provides
key empirical evidence from the context of a public Latin American university.

</details>


### [161] [Hybrid Instructor Ai Assessment In Academic Projects: Efficiency, Equity, And Methodological Lessons](https://arxiv.org/abs/2510.22286)
*Hugo Roger Paz*

Main category: cs.CY

TL;DR: 本研究在基础水力学课程中实施了一个由教师监督的生成式AI辅助评估系统，用于批改33份报告，显著提高了评分效率、反馈质量和公平性。


<details>
  <summary>Details</summary>
Motivation: 在高注册率的技术课程中，报告评估需要高度的客观性、一致性和形成性反馈，但教师工作负荷往往影响这些目标的实现。

Method: 使用大型语言模型(LLM)配合详细评分标准进行校准，批量处理作业，并采用人在回路验证阶段。

Result: 评分时间减少88%(从50分钟降至6分钟/报告)，生产率提高733%，反馈质量显著改善(100%评分标准覆盖，基于文本证据的评论增加150%)，系统公平可靠(校准后评分相关性r=0.96)。

Conclusion: AI-教师混合模型优化了评估过程，释放了高价值教学任务的时间，提高了反馈的公平性和质量，符合UNESCO关于AI在教育中伦理使用的原则。

Abstract: In technical subjects characterized by high enrollment, such as Basic
Hydraulics, the assessment of reports necessitates superior levels of
objectivity, consistency, and formative feedback; goals often compromised by
faculty workload. This study presents the implementation of a generative
artificial intelligence (AI) assisted assessment system, supervised by
instructors, to grade 33 hydraulics reports. The central objective was to
quantify its impact on the efficiency, quality, and fairness of the process.
The employed methodology included the calibration of the Large Language Model
(LLM) with a detailed rubric, the batch processing of assignments, and a
human-in-the-loop validation phase. The quantitative results revealed a
noteworthy 88% reduction in grading time (from 50 to 6 minutes per report,
including verification) and a 733% increase in productivity. The quality of
feedback was substantially improved, evidenced by 100% rubric coverage and a
150% increase in the anchoring of comments to textual evidence. The system
proved to be equitable, exhibiting no bias related to report length, and highly
reliable post-calibration (r = 0.96 between scores). It is concluded that the
hybrid AI-instructor model optimizes the assessment process, thereby liberating
time for high-value pedagogical tasks and enhancing the fairness and quality of
feedback, in alignment with UNESCO's principles on the ethical use of AI in
education.

</details>


### [162] [Stop the Nonconsensual Use of Nude Images in Research](https://arxiv.org/abs/2510.22423)
*Princessa Cintaqia,Arshia Arya,Elissa M Redmiles,Deepak Kumar,Allison McDonald,Lucy Qin*

Main category: cs.CY

TL;DR: 本文批评机器学习研究中未经同意收集和使用裸体图像的做法，认为这会加剧图像性虐待，呼吁停止在研究中非自愿使用裸体图像。


<details>
  <summary>Details</summary>
Motivation: 机器学习研究者通常从互联网抓取裸体图像来训练和测试模型，但这些内容是在未经同意的情况下收集和分发的，可能导致滥用并加剧对被描绘对象的伤害。

Method: 对计算领域发表的使用裸体图像的论文进行系统回顾，分析其使用范围和性质。

Result: 发现裸体图像使用规范稀疏，存在诸多问题实践，如分发和发布未打码的裸体图像、故意收集和分享虐待内容等。

Conclusion: 呼吁出版机构和研究社区停止非自愿使用裸体图像，提出在裸体检测研究中平衡用户自主权与具体研究目标的愿景。

Abstract: In order to train, test, and evaluate nudity detection models, machine
learning researchers typically rely on nude images scraped from the Internet.
Our research finds that this content is collected and, in some cases,
subsequently distributed by researchers without consent, leading to potential
misuse and exacerbating harm against the subjects depicted. This position paper
argues that the distribution of nonconsensually collected nude images by
researchers perpetuates image-based sexual abuse and that the machine learning
community should stop the nonconsensual use of nude images in research. To
characterize the scope and nature of this problem, we conducted a systematic
review of papers published in computing venues that collect and use nude
images. Our results paint a grim reality: norms around the usage of nude images
are sparse, leading to a litany of problematic practices like distributing and
publishing nude images with uncensored faces, and intentionally collecting and
sharing abusive content. We conclude with a call-to-action for publishing
venues and a vision for research in nudity detection that balances user agency
with concrete research objectives.

</details>


### [163] [TLSQKT: A Question-Aware Dual-Channel Transformer for Literacy Tracing from Learning Sequences](https://arxiv.org/abs/2510.22488)
*Zhifeng Wang,Yaowei Dong,Chunyan Zeng*

Main category: cs.CY

TL;DR: 提出知识追踪（KT）的扩展框架——素养追踪（LT），通过Transformer模型TLSQKT联合编码学生回答和题目语义，在三个真实数据集上优于传统KT方法，并能解释学生素养发展轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统知识追踪模型主要关注离散知识点的掌握，难以刻画更广泛的素养发展。需要开发能够建模高阶认知能力和素养增长的新方法。

Method: 提出TLSQKT模型，采用双通道设计联合编码学生回答和题目语义，使用问题感知交互和自注意力机制捕捉学习者状态的长程依赖关系。

Result: 在三个真实数据集上的实验表明，TLSQKT在素养导向指标上持续优于强基线KT模型，并能揭示学习者素养的可解释发展轨迹。迁移实验显示知识追踪信号可用于素养追踪。

Conclusion: 素养追踪可作为智能教育系统的可扩展组件，为未来大规模教育模型中的素养评估奠定基础。

Abstract: Knowledge tracing (KT) supports personalized learning by modeling how
students' knowledge states evolve over time. However, most KT models emphasize
mastery of discrete knowledge components, limiting their ability to
characterize broader literacy development. We reframe the task as Literacy
Tracing (LT), which models the growth of higher-order cognitive abilities and
literacy from learners' interaction sequences, and we instantiate this paradigm
with a Transformer-based model, TLSQKT (Transformer for Learning Sequences with
Question-Aware Knowledge Tracing). TLSQKT employs a dual-channel design that
jointly encodes student responses and item semantics, while question-aware
interaction and self-attention capture long-range dependencies in learners'
evolving states. Experiments on three real-world datasets - one public
benchmark, one private knowledge-component dataset, and one private literacy
dataset - show that TLSQKT consistently outperforms strong KT baselines on
literacy-oriented metrics and reveals interpretable developmental trajectories
of learners' literacy. Transfer experiments further indicate that
knowledge-tracing signals can be leveraged for literacy tracing, offering a
practical route when dedicated literacy labels are limited. These findings
position literacy tracing as a scalable component of intelligent educational
systems and lay the groundwork for literacy evaluation in future large-scale
educational models.

</details>


### [164] [Women upskilling or reskilling to an ICT career: A systematic review of drivers and barriers](https://arxiv.org/abs/2510.22508)
*Shondell Williams,Karen Blackmore,Regina Berretta,Michelle Mansfield*

Main category: cs.CY

TL;DR: 这篇综述探讨了影响女性转行或提升技能进入科技STEM职业的驱动因素和障碍，发现职业不满意度和职场积极计算体验是主要驱动力，而负面身份认同和自我怀疑是主要障碍。


<details>
  <summary>Details</summary>
Motivation: 全球对科技STEM专业人才需求增长，但女性在该领域参与度不足，现有研究主要关注应届生参与，缺乏对女性转行进入ICT职业的研究。

Method: 通过文献综述，分析影响女性转行或提升技能进入科技职业的驱动因素和障碍。

Result: 职业不满意度和职场积极计算体验是主要驱动力；学习工作机会（特别是来自重要参考者）也很关键；女性需要克服负面身份认同、学术信念和自我怀疑。

Conclusion: 通过利用女性对计算的潜在兴趣，可以增加和多样化科技劳动力；为教育机构、雇主和女性提供支持转行或技能提升的研究路线图。

Abstract: Demand for technology focused STEM professionals will increase globally over
the coming decade, with many countries finding it difficult to meet growing
demand. Compounding this are difficulties in attracting and retaining female
technology-focused professionals. Research seeking to address this gender
imbalance and workforce shortage focuses on increasing participation among
school leavers. However, there is a paucity of research around the potential
for females to upskill or reskill into an ICT career. As a starting point, this
review asks the question: "What potential drivers and barriers have been
identified that impact on female intentions or choices to reskill or upskill to
a technology focused STEM career". Results indicate dissatisfaction in a first
career, combined with positive computing experiences in the workplace can rouse
interest in computing professions. Learning of job opportunities, especially
from salient referents, is also a key driver. Results indicate women must
overcome negative identity and academic beliefs, as well as self-doubt to make
the switch. In summary, it is possible to increase and diversify the tech
workforce by leveraging women's latent interest in computing. This review
provides a roadmap for research to support educational institutions, employers,
and women to benefit from upskilling or reskilling opportunities

</details>


### [165] [How Can AI Augment Access to Justice? Public Defenders' Perspectives on AI Adoption](https://arxiv.org/abs/2510.22933)
*Inyoung Cheong,Patty Liu,Dominik Stammbach,Peter Henderson*

Main category: cs.CY

TL;DR: 该研究通过访谈14名美国公设辩护人，探讨AI在公设辩护中的实际应用、预期用途和伦理问题，发现AI采用受成本、办公规范、保密风险等因素限制，并提出了任务级映射来明确AI的适用领域。


<details>
  <summary>Details</summary>
Motivation: AI和大型语言模型被宣传为减轻公设辩护人负担的工具，但这些提议脱离了公设辩护人的实际工作现实，本研究旨在填补这一空白。

Method: 通过对美国14名从业者进行半结构化访谈，考察他们对AI的体验、预期应用和伦理担忧。

Result: 发现AI采用受成本、限制性办公规范、保密风险和不满意工具质量等因素制约；公设辩护人认为AI在证据调查中最有用，在法律研究和客户沟通中作用有限，在法庭代理和辩护策略中最不适用。

Conclusion: 提出了负责任使用的保障措施，包括强制性人工验证、限制过度依赖以及保留律师工作的关系方面；并制定了研究议程，优先考虑开源模型、领域特定数据集和参与式设计，以促进司法公平。

Abstract: Public defenders are asked to do more with less: representing clients
deserving of adequate counsel while facing overwhelming caseloads and scarce
resources. While artificial intelligence (AI) and large language models (LLMs)
are promoted as tools to alleviate this burden, such proposals are detached
from the lived realities of public defenders. This study addresses that gap
through semi-structured interviews with fourteen practitioners across the
United States to examine their experiences with AI, anticipated applications,
and ethical concerns. We find that AI adoption is constrained by costs,
restrictive office norms, confidentiality risks, and unsatisfactory tool
quality. To clarify where AI can and cannot contribute, we propose a task-level
map of public defense. Public defenders view AI as most useful for evidence
investigation to analyze overwhelming amounts of digital records, with narrower
roles in legal research & writing, and client communication. Courtroom
representation and defense strategy are considered least compatible with AI
assistance, as they depend on contextual judgment and trust. Public defenders
emphasize safeguards for responsible use, including mandatory human
verification, limits on overreliance, and the preservation of relational aspect
of lawyering. Building on these findings, we outline a research agenda that
promotes equitable access to justice by prioritizing open-source models,
domain-specific datasets and evaluation, and participatory design that
incorporates defenders' perspectives into system development.

</details>


### [166] [From Perceived Effectiveness to Measured Impact: Identity-Aware Evaluation of Automated Counter-Stereotypes](https://arxiv.org/abs/2510.23523)
*Svetlana Kiritchenko,Anna Kerkhof,Isar Nejadgholi,Kathleen C. Fraser*

Main category: cs.CY

TL;DR: 研究自动生成的刻板印象反驳信息对不同人口统计特征用户在社交媒体上的性别偏见影响，发现实际效果与感知效果不一致，且干预效果因人口特征而异。


<details>
  <summary>Details</summary>
Motivation: 基于NLP进展和社会心理学文献，评估两种刻板印象反驳策略在现实世界中减轻性别偏见的效果，特别是跨用户人口统计特征（性别和年龄）的影响。

Method: 使用自动生成的刻板印象反驳信息（反事实和普遍化策略），通过内隐联想测试、外显偏见自我报告和感知效用测量来评估效果。

Result: 总体偏见减少有限，但某些群体（如年长男性参与者）对某些干预表现出可测量的内隐偏见改善，而年轻参与者（尤其是女性）对相同干预表现出偏见增加。

Conclusion: 刻板印象缓解具有复杂性和身份敏感性，需要动态和情境感知的评估与缓解策略。

Abstract: We investigate the effect of automatically generated counter-stereotypes on
gender bias held by users of various demographics on social media. Building on
recent NLP advancements and social psychology literature, we evaluate two
counter-stereotype strategies -- counter-facts and broadening universals (i.e.,
stating that anyone can have a trait regardless of group membership) -- which
have been identified as the most potentially effective in previous studies. We
assess the real-world impact of these strategies on mitigating gender bias
across user demographics (gender and age), through the Implicit Association
Test and the self-reported measures of explicit bias and perceived utility. Our
findings reveal that actual effectiveness does not align with perceived
effectiveness, and the former is a nuanced and sometimes divergent phenomenon
across demographic groups. While overall bias reduction was limited, certain
groups (e.g., older, male participants) exhibited measurable improvements in
implicit bias in response to some interventions. Conversely, younger
participants, especially women, showed increasing bias in response to the same
interventions. These results highlight the complex and identity-sensitive
nature of stereotype mitigation and call for dynamic and context-aware
evaluation and mitigation strategies.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [167] [A Robotic Stirring Method with Trajectory Optimization and Adaptive Speed Control for Accurate Pest Counting in Water Traps](https://arxiv.org/abs/2510.21732)
*Xumin Gao,Mark Stevens,Grzegorz Cielniak*

Main category: cs.RO

TL;DR: 本文提出了一种机器人搅拌方法，通过轨迹优化和自适应速度控制来解决水陷阱中害虫遮挡问题，实现准确的害虫计数。


<details>
  <summary>Details</summary>
Motivation: 当前基于图像的害虫计数方法在处理害虫遮挡情况时存在局限性，需要一种能够改变害虫分布、使被遮挡个体可见的新方法。

Method: 开发了基于机械臂的自动搅拌系统，设计了六种代表性搅拌轨迹，通过比较计数误差和置信度选择最优轨迹，并提出了基于计数置信度的闭环控制系统实现自适应速度搅拌。

Result: 实验结果表明该方法能够有效处理害虫遮挡问题，提高计数准确性。

Conclusion: 这是首个研究动态液体环境中不同搅拌轨迹对物体计数影响的工作，自适应速度搅拌方法为类似任务提供了有效解决方案。

Abstract: Accurate monitoring of pest population dynamics is crucial for informed
decision-making in precision agriculture. Currently, mainstream image-based
pest counting methods primarily rely on image processing combined with machine
learning or deep learning for pest counting. However, these methods have
limitations and struggle to handle situations involving pest occlusion. To
address this issue, this paper proposed a robotic stirring method with
trajectory optimization and adaptive speed control for accurate pest counting
in water traps. First, we developed an automated stirring system for pest
counting in yellow water traps based on a robotic arm. Stirring alters the
distribution of pests in the yellow water trap, making some of the occluded
individuals visible for detection and counting. Then, we investigated the
impact of different stirring trajectories on pest counting performance and
selected the optimal trajectory for pest counting. Specifically, we designed
six representative stirring trajectories, including circle, square, triangle,
spiral, four small circles, and random lines, for the robotic arm to stir. And
by comparing the overall average counting error and counting confidence of
different stirring trajectories across various pest density scenarios, we
determined the optimal trajectory. Finally, we proposed a counting
confidence-driven closed-loop control system to achieve adaptive-speed
stirring. It uses changes in pest counting confidence between consecutive
frames as feedback to adjust the stirring speed. To the best of our knowledge,
this is the first study dedicated to investigating the effects of different
stirring trajectories on object counting in the dynamic liquid environment and
to implement adaptive-speed stirring for this type of task. Experimental
results show ...

</details>


### [168] [Force-Displacement Profiling for Robot-Assisted Deployment of a Left Atrial Appendage Occluder Using FBG-EM Distal Sensing](https://arxiv.org/abs/2510.21734)
*Giovanni Battista Regazzo,Wim-Alexander Beckers,Xuan Thao Ha,Mouloud Ourak,Johan Vlekken,Emmanuel Vander Poorten*

Main category: cs.RO

TL;DR: 开发了一种基于光纤布拉格光栅和电磁跟踪的力-位移分析方法，用于机器人辅助左心耳封堵术，无需电离辐射即可识别关键手术步骤。


<details>
  <summary>Details</summary>
Motivation: 当前左心耳封堵术依赖手动导管控制和荧光透视成像，存在辐射暴露和定位精度有限的问题，需要更安全、精确的手术引导方法。

Method: 使用集成光纤布拉格光栅的力传感输送鞘结合电磁跟踪，在解剖模型中进行机器人辅助左心耳封堵部署，实时测量相互作用力和导管尖端位置。

Result: 力剖面显示低幅度的相互作用力，表明对周围解剖结构的机械应力最小，能够识别关键手术步骤而不依赖电离辐射。

Conclusion: 该方法有望为临床医生提供增强的术中反馈，改善部署结果，未来工作将聚焦于自动化部署步骤分类和在动态真实环境中验证传感策略。

Abstract: Atrial fibrillation (AF) increases the risk of thromboembolic events due to
impaired function of the left atrial appendage (LAA). Left atrial appendage
closure (LAAC) is a minimally invasive intervention designed to reduce stroke
risk by sealing the LAA with an expandable occluder device. Current deployment
relies on manual catheter control and imaging modalities like fluoroscopy and
transesophageal echocardiography, which carry limitations including radiation
exposure and limited positioning precision. In this study, we leverage a
previously developed force-sensing delivery sheath integrating fiber Bragg
gratings (FBGs) at the interface between the catheter and the occluder.
Combined with electromagnetic (EM) tracking, this setup enables real-time
measurement of interaction forces and catheter tip position during
robot-assisted LAAC deployment in an anatomical phantom. We present a novel
force-displacement profiling method that characterizes occluder deployment
dynamics and identifies key procedural steps without relying on ionizing
radiation. The force profiles reveal low-magnitude interaction forces,
suggesting minimal mechanical stress on the surrounding anatomy. This approach
shows promise in providing clinicians with enhanced intraoperative feedback,
improving deployment outcome. Future work will focus on automating deployment
steps classification and validating the sensing strategy in dynamic, realistic
environments.

</details>


### [169] [A phase-aware AI car-following model for electric vehicles with adaptive cruise control: Development and validation using real-world data](https://arxiv.org/abs/2510.21735)
*Yuhui Liu,Shian Wang,Ansel Panicker,Kate Embry,Ayana Asanova,Tianyi Li*

Main category: cs.RO

TL;DR: 开发了针对电动汽车的相位感知AI跟车模型，通过AI组件识别不同驾驶阶段，显著提高了传统跟车模型对电动汽车行为的预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统微观模型能有效捕捉内燃机车辆行为，但缺乏准确描述电动汽车独特跟车动态的建模框架。随着电动汽车在交通中日益增多，开发易用且准确的分析模型至关重要。

Method: 提出相位感知AI跟车模型，在传统物理框架基础上加入AI组件，识别和适应快速加速、再生制动等不同驾驶阶段。使用配备自适应巡航控制车辆的真实轨迹数据进行仿真验证。

Result: 数值结果表明，PAAI模型相比传统跟车模型显著提高了预测精度，为交通仿真中准确表示电动汽车行为提供了有效工具。

Conclusion: 该研究开发的相位感知AI跟车模型成功解决了电动汽车独特动态特性的建模问题，为交通仿真提供了更准确的电动汽车行为表示方法。

Abstract: Internal combustion engine (ICE) vehicles and electric vehicles (EVs) exhibit
distinct vehicle dynamics. EVs provide rapid acceleration, with electric motors
producing peak power across a wider speed range, and achieve swift deceleration
through regenerative braking. While existing microscopic models effectively
capture the driving behavior of ICE vehicles, a modeling framework that
accurately describes the unique car-following dynamics of EVs is lacking.
Developing such a model is essential given the increasing presence of EVs in
traffic, yet creating an easy-to-use and accurate analytical model remains
challenging.
  To address these gaps, this study develops and validates a Phase-Aware AI
(PAAI) car-following model specifically for EVs. The proposed model enhances
traditional physics-based frameworks with an AI component that recognizes and
adapts to different driving phases, such as rapid acceleration and regenerative
braking. Using real-world trajectory data from vehicles equipped with adaptive
cruise control (ACC), we conduct comprehensive simulations to validate the
model's performance. The numerical results demonstrate that the PAAI model
significantly improves prediction accuracy over traditional car-following
models, providing an effective tool for accurately representing EV behavior in
traffic simulations.

</details>


### [170] [Learn2Drive: A neural network-based framework for socially compliant automated vehicle control](https://arxiv.org/abs/2510.21736)
*Yuhui Liu,Samannita Halder,Shian Wang,Tianyi Li*

Main category: cs.RO

TL;DR: 提出基于LSTM和物理约束的自适应巡航控制框架，通过社会价值取向(SVO)使自动驾驶车辆考虑对人工驾驶车辆和交通流的影响，提升交通效率和降低能耗。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶控制策略主要关注单个车辆或车队的性能优化，忽视了与人工驾驶车辆的互动及其对交通流的整体影响，这可能导致拥堵加剧和系统效率降低。

Method: 使用神经网络和社会价值取向(SVO)构建社会合规的自动驾驶控制框架，定义AV和HV的效用函数，基于SVO平衡个体控制目标与交通流考虑。

Result: 当AV控制模式从优先能耗转向优化交通流效率时，跟随车队车辆个体能耗增加至少58.99%，同时个体平均速度提升至少38.39%，显著改善交通动态。

Conclusion: 所提方法能适应不同交通条件，有效提升系统级效率，证明AV作为移动交通调节器的潜力，可减少拥堵、提高交通效率并降低能耗。

Abstract: This study introduces a novel control framework for adaptive cruise control
(ACC) in automated driving, leveraging Long Short-Term Memory (LSTM) networks
and physics-informed constraints. As automated vehicles (AVs) adopt advanced
features like ACC, transportation systems are becoming increasingly intelligent
and efficient. However, existing AV control strategies primarily focus on
optimizing the performance of individual vehicles or platoons, often neglecting
their interactions with human-driven vehicles (HVs) and the broader impact on
traffic flow. This oversight can exacerbate congestion and reduce overall
system efficiency. To address this critical research gap, we propose a neural
network-based, socially compliant AV control framework that incorporates social
value orientation (SVO). This framework enables AVs to account for their
influence on HVs and traffic dynamics. By leveraging AVs as mobile traffic
regulators, the proposed approach promotes adaptive driving behaviors that
reduce congestion, improve traffic efficiency, and lower energy consumption.
Within this framework, we define utility functions for both AVs and HVs, which
are optimized based on the SVO of each AV to balance its own control objectives
with broader traffic flow considerations. Numerical results demonstrate the
effectiveness of the proposed method in adapting to varying traffic conditions,
thereby enhancing system-wide efficiency. Specifically, when the AV's control
mode shifts from prioritizing energy consumption to optimizing traffic flow
efficiency, vehicles in the following platoon experience at least a 58.99%
increase in individual energy consumption alongside at least a 38.39%
improvement in individual average speed, indicating significant enhancements in
traffic dynamics.

</details>


### [171] [Next-Generation LLM for UAV: From Natural Language to Autonomous Flight](https://arxiv.org/abs/2510.21739)
*Liangqi Yuan,Chuhao Deng,Dong-Jun Han,Inseok Hwang,Sabine Brunswicker,Christopher G. Brinton*

Main category: cs.RO

TL;DR: 本文提出了NeLV系统，将大语言模型集成到多尺度无人机操作中，通过五个关键技术组件处理自然语言指令来协调短、中、远程无人机任务，并建立了五级自动化分类法。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要局限于小型无人机应用，缺乏对中远程无人机系统在真实操作环境中的全面研究。大型无人机平台面临起降程序严格、法规复杂和任务要求高等挑战。

Method: NeLV系统包含五个技术组件：LLM解析器用于指令解释、路线规划器确定兴趣点、路径规划器生成航点、控制平台实现可执行轨迹、无人机监控。通过三个代表性用例验证系统可行性。

Result: 通过多无人机巡逻、多兴趣点配送和多跳重定位三个用例证明了系统的可行性。

Conclusion: 建立了从当前LLM作为解析器到完全自主LLM作为自动驾驶系统的五级自动化演进路线图，识别了各阶段的技术前提和研究挑战。

Abstract: With the rapid advancement of Large Language Models (LLMs), their
capabilities in various automation domains, particularly Unmanned Aerial
Vehicle (UAV) operations, have garnered increasing attention. Current research
remains predominantly constrained to small-scale UAV applications, with most
studies focusing on isolated components such as path planning for toy drones,
while lacking comprehensive investigation of medium- and long-range UAV systems
in real-world operational contexts. Larger UAV platforms introduce distinct
challenges, including stringent requirements for airport-based take-off and
landing procedures, adherence to complex regulatory frameworks, and specialized
operational capabilities with elevated mission expectations. This position
paper presents the Next-Generation LLM for UAV (NeLV) system -- a comprehensive
demonstration and automation roadmap for integrating LLMs into multi-scale UAV
operations. The NeLV system processes natural language instructions to
orchestrate short-, medium-, and long-range UAV missions through five key
technical components: (i) LLM-as-Parser for instruction interpretation, (ii)
Route Planner for Points of Interest (POI) determination, (iii) Path Planner
for waypoint generation, (iv) Control Platform for executable trajectory
implementation, and (v) UAV monitoring. We demonstrate the system's feasibility
through three representative use cases spanning different operational scales:
multi-UAV patrol, multi-POI delivery, and multi-hop relocation. Beyond the
current implementation, we establish a five-level automation taxonomy that
charts the evolution from current LLM-as-Parser capabilities (Level 1) to fully
autonomous LLM-as-Autopilot systems (Level 5), identifying technical
prerequisites and research challenges at each stage.

</details>


### [172] [FORGE-Tree: Diffusion-Forcing Tree Search for Long-Horizon Robot Manipulation](https://arxiv.org/abs/2510.21744)
*Yanjia Huang,Shuo Liu,Sheng Liu,Qingxiao Xu,Mingyang Wu,Xiangbo Gao,Zhengzhong Tu*

Main category: cs.RO

TL;DR: FORGE-Tree是一个用于长时程机器人操作的插件控制层，通过结合阶段对齐的扩散强迫头和测试时蒙特卡洛树扩散，解决了VLA策略中的漂移和暴露偏差问题，显著提升了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 长时程机器人操作任务对视觉-语言-动作策略具有挑战性，主要由于漂移和暴露偏差问题。现有方法通常使用固定超参数对整个轨迹进行去噪，导致小几何误差在阶段间累积，且缺乏在紧密间隙处分配额外计算资源的机制。

Method: FORGE-Tree包含阶段对齐的扩散强迫头和测试时蒙特卡洛树扩散。使用冻结的VLA编码器，扩散强迫头将时间步与子任务阶段对齐；在推理时仅部分去噪目标段而保持其他标记冻结，将轨迹优化转化为局部编辑序列。蒙特卡洛树扩散用于选择下一个要优化的段，场景图提供扩展先验和几何关系感知的rollout评分。

Result: 在LIBERO基准测试中，FORGE-Tree相比原生VLA基线（OpenVLA和Octo-Base）将成功率提升了13.4到17.2个百分点。在可比较的计算预算下，增益保持一致，特别是在长时程变体上表现更佳。

Conclusion: FORGE-Tree通过树结构去噪方法有效解决了长时程机器人操作中的轨迹优化问题，其性能随搜索预算扩展而提升，同时保持已执行前缀不变，为VLA策略提供了有效的控制层增强。

Abstract: Long-horizon robot manipulation tasks remain challenging for
Vision-Language-Action (VLA) policies due to drift and exposure bias, often
denoise the entire trajectory with fixed hyperparameters, causing small
geometric errors to compound across stages and offering no mechanism to
allocate extra test-time compute where clearances are tight. To address these
challenges, we introduce FORGE-Tree, a plug-in control layer that couples a
stage-aligned Diffusion Forcing (DF) head with test-time Monte Carlo Tree
Diffusion (MCTD). With a frozen VLA encoder, DF aligns timesteps to subtask
stages; during inference we partially denoise only a target segment while
keeping other tokens frozen, turning trajectory refinement into a sequence of
local edits. We then apply Monte Carlo Tree Diffusion to select the next
segment to refine. A scene graph supplies priors for expansion and geometry
relation-aware scoring for rollouts, yielding tree-structured denoising whose
performance scales with search budget while preserving the executed prefix.
Evaluation on LIBERO, FORGE-Tree improves success rate by 13.4 to 17.2 pp over
the native VLA baselines with both OpenVLA and Octo-Base. Gains remain
consistent under comparable compute budgets, especially on long-horizon
variants. Videos available at: https://taco-group.github.io/FORGE-Tree/

</details>


### [173] [Avi: Action from Volumetric Inference](https://arxiv.org/abs/2510.21746)
*Harris Song,Long Le*

Main category: cs.RO

TL;DR: Avi是一种新颖的3D视觉-语言-动作架构，将机器人动作生成重新定义为3D感知和空间推理问题，而非低层策略学习。它利用3D点云和基于语言场景理解，通过经典几何变换计算动作。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要基于2D视觉输入进行端到端任务特定策略训练，而Avi旨在通过3D感知和空间推理实现更通用、鲁棒的机器人行为。

Method: 基于3D多模态大语言模型生成下一个点云，通过经典几何变换显式计算动作，无需训练先前动作标记。

Result: 该方法实现了对遮挡、相机姿态变化和视角变化的鲁棒性，展示了通用化行为。

Conclusion: 3D视觉语言推理有潜力作为可扩展、鲁棒机器人系统的基础，弥合高层语言指令与低层驱动之间的差距。

Abstract: We propose Avi, a novel 3D Vision-Language-Action (VLA) architecture that
reframes robotic action generation as a problem of 3D perception and spatial
reasoning, rather than low-level policy learning. While existing VLA models
primarily operate on 2D visual inputs and are trained end-to-end on
task-specific action policies, Avi leverages 3D point clouds and
language-grounded scene understanding to compute actions through classical
geometric transformations. Most notably, Avi does not train on previous action
tokens, rather, we build upon a 3D Multi-modal Large Language Model (MLLM) to
generate the next point cloud and explicitly calculate the actions through
classical transformations. This approach enables generalizable behaviors that
are robust to occlusions, camera pose variations, and changes in viewpoint. By
treating the robotic decision-making process as a structured reasoning task
over 3D representations, Avi bridges the gap between high-level language
instructions and low-level actuation without requiring opaque policy learning.
Our preliminary results highlight the potential of 3D vision-language reasoning
as a foundation for scalable, robust robotic systems. Check it out at
https://avi-3drobot.github.io/.

</details>


### [174] [Real-time Mixed-Integer Quadratic Programming for Driving Behavior-Inspired Speed Bump Optimal Trajectory Planning](https://arxiv.org/abs/2510.21751)
*Van Nam Dinh,Van Vy Phan,Thai Son Dang,Van Du Phan,The Anh Mai,Van Chuong Le,Sy Phuong Ho,Dinh Tu Duong,Hung Cuong Ta*

Main category: cs.RO

TL;DR: 提出了一种基于混合整数二次规划和模型预测控制的自动驾驶轨迹规划方法，专门优化车辆通过减速带时的乘客舒适度，模拟人类驾驶行为。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶车辆在城市环境中通过减速带时的轨迹规划挑战，需要同时考虑乘客舒适度和实时计算效率。

Method: 使用混合整数二次规划和模型预测控制框架，开发了模拟人类驾驶行为的减速带处理约束，并与道路导航要求无缝集成。

Result: 在多种城市驾驶环境中的模拟显示，该方法能确保车辆平稳通过减速带，同时保持适合实时部署的计算效率。

Conclusion: 该方法能够同时处理静态道路特征和动态约束，结合专家人类驾驶行为，代表了城市轨迹规划的重要进展。

Abstract: This paper proposes a novel methodology for trajectory planning in autonomous
vehicles (AVs), addressing the complex challenge of negotiating speed bumps
within a unified Mixed-Integer Quadratic Programming (MIQP) framework. By
leveraging Model Predictive Control (MPC), we develop trajectories that
optimize both the traversal of speed bumps and overall passenger comfort. A key
contribution of this work is the formulation of speed bump handling constraints
that closely emulate human driving behavior, seamlessly integrating these with
broader road navigation requirements. Through extensive simulations in varied
urban driving environments, we demonstrate the efficacy of our approach,
highlighting its ability to ensure smooth speed transitions over speed bumps
while maintaining computational efficiency suitable for real-time deployment.
The method's capability to handle both static road features and dynamic
constraints, alongside expert human driving, represents a significant step
forward in trajectory planning for urban

</details>


### [175] [Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review](https://arxiv.org/abs/2510.21758)
*Kumater Ter,RexCharles Donatus,Ore-Ofe Ajayi,Daniel Udekwe*

Main category: cs.RO

TL;DR: 这篇论文对强化学习在机器人领域的应用进行了深度综述，涵盖了RL基本原理、深度强化学习算法及其在机器人控制系统中的集成。


<details>
  <summary>Details</summary>
Motivation: 旨在弥合强化学习理论进展与实际应用之间的差距，为自主机器人系统中的RL角色提供统一视角。

Method: 从马尔可夫决策过程形式化开始，分析智能体-环境交互要素，探讨actor-critic方法、基于值的学习和策略梯度等核心算法策略，重点关注DDPG、TD3、PPO和SAC等现代DRL技术。

Result: 提出了结构化分类法来分类RL在运动、操作、多智能体协调和人机交互等领域的应用，总结了训练方法和部署准备度水平。

Conclusion: 综述了最新研究进展，强调了技术趋势、设计模式以及RL在现实世界机器人中日益成熟的作用，为理论和实践提供了桥梁。

Abstract: Reinforcement learning (RL) has become a foundational approach for enabling
intelligent robotic behavior in dynamic and uncertain environments. This work
presents an in-depth review of RL principles, advanced deep reinforcement
learning (DRL) algorithms, and their integration into robotic and control
systems. Beginning with the formalism of Markov Decision Processes (MDPs), the
study outlines essential elements of the agent-environment interaction and
explores core algorithmic strategies including actor-critic methods,
value-based learning, and policy gradients. Emphasis is placed on modern DRL
techniques such as DDPG, TD3, PPO, and SAC, which have shown promise in solving
high-dimensional, continuous control tasks. A structured taxonomy is introduced
to categorize RL applications across domains such as locomotion, manipulation,
multi-agent coordination, and human-robot interaction, along with training
methodologies and deployment readiness levels. The review synthesizes recent
research efforts, highlighting technical trends, design patterns, and the
growing maturity of RL in real-world robotics. Overall, this work aims to
bridge theoretical advances with practical implementations, providing a
consolidated perspective on the evolving role of RL in autonomous robotic
systems.

</details>


### [176] [J-ORA: A Framework and Multimodal Dataset for Japanese Object Identification, Reference, Action Prediction in Robot Perception](https://arxiv.org/abs/2510.21761)
*Jesse Atuhurra,Hidetaka Kamigaito,Taro Watanabe,Koichiro Yoshino*

Main category: cs.RO

TL;DR: J-ORA是一个新颖的多模态数据集，通过提供日本人机对话场景中的详细物体属性标注来弥合机器人感知的差距。该数据集支持物体识别、参考解析和下一动作预测三个关键感知任务。


<details>
  <summary>Details</summary>
Motivation: 弥合机器人感知的差距，特别是在日本文化背景下的人机交互场景中，需要包含详细物体属性标注的数据集来提升多模态感知性能。

Method: 构建J-ORA数据集，包含详细的物体属性模板（类别、颜色、形状、大小、材质和空间关系），并利用专有和开源视觉语言模型进行广泛评估。

Result: 实验表明，加入详细物体属性显著提升了多模态感知性能，但专有和开源视觉语言模型之间仍存在性能差距。不同模型在理解物体功能和上下文关系方面表现出不同能力。

Conclusion: 丰富且上下文敏感的属性标注对于在动态环境中推进机器人感知至关重要，J-ORA数据集为这一目标提供了重要资源。

Abstract: We introduce J-ORA, a novel multimodal dataset that bridges the gap in robot
perception by providing detailed object attribute annotations within Japanese
human-robot dialogue scenarios. J-ORA is designed to support three critical
perception tasks, object identification, reference resolution, and next-action
prediction, by leveraging a comprehensive template of attributes (e.g.,
category, color, shape, size, material, and spatial relations). Extensive
evaluations with both proprietary and open-source Vision Language Models (VLMs)
reveal that incorporating detailed object attributes substantially improves
multimodal perception performance compared to without object attributes.
Despite the improvement, we find that there still exists a gap between
proprietary and open-source VLMs. In addition, our analysis of object
affordances demonstrates varying abilities in understanding object
functionality and contextual relationships across different VLMs. These
findings underscore the importance of rich, context-sensitive attribute
annotations in advancing robot perception in dynamic environments. See project
page at https://jatuhurrra.github.io/J-ORA/.

</details>


### [177] [Improving the performance of AI-powered Affordable Robotics for Assistive Tasks](https://arxiv.org/abs/2510.21771)
*Dharunish Yugeswardeenoo*

Main category: cs.RO

TL;DR: 开发低成本机器人手臂用于辅助护理任务，采用模仿学习和新型PACT架构，在三个任务上实现超过90%的准确率，模型尺寸减少5倍。


<details>
  <summary>Details</summary>
Motivation: 到2050年全球辅助护理需求将达到35亿人，远超人类护理人员供应。现有机器人解决方案昂贵且需要专业技术，限制了可及性。

Method: 使用模仿学习从演示视频中学习，无需任务特定编程。采用六伺服电机、双摄像头和3D打印夹具。收集50,000帧视频数据，开发Phased Action Chunking Transformer (PACT)捕捉时间依赖性和分割运动动态，Temporal Ensemble方法优化轨迹。

Result: 在五个模型尺寸和四种架构评估中，经过10小时真实世界测试，系统实现超过90%任务准确率，比基线高40%。PACT使模型尺寸减少5倍同时保持75%准确率。显著性分析显示依赖关键视觉线索。

Conclusion: 该系统为低成本辅助护理机器人提供了可行方案，未来将探索双手操作和移动性以扩展辅助能力。

Abstract: By 2050, the global demand for assistive care is expected to reach 3.5
billion people, far outpacing the availability of human caregivers. Existing
robotic solutions remain expensive and require technical expertise, limiting
accessibility. This work introduces a low-cost robotic arm for assistive tasks
such as feeding, cleaning spills, and fetching medicine. The system uses
imitation learning from demonstration videos, requiring no task-specific
programming or manual labeling. The robot consists of six servo motors, dual
cameras, and 3D-printed grippers. Data collection via teleoperation with a
leader arm yielded 50,000 video frames across the three tasks. A novel Phased
Action Chunking Transformer (PACT) captures temporal dependencies and segments
motion dynamics, while a Temporal Ensemble (TE) method refines trajectories to
improve accuracy and smoothness. Evaluated across five model sizes and four
architectures, with ten hours of real-world testing, the system achieved over
90% task accuracy, up to 40% higher than baselines. PACT enabled a 5x model
size reduction while maintaining 75% accuracy. Saliency analysis showed
reliance on key visual cues, and phase token gradients peaked at critical
trajectory moments, indicating effective temporal reasoning. Future work will
explore bimanual manipulation and mobility for expanded assistive capabilities.

</details>


### [178] [Real-Time QP Solvers: A Concise Review and Practical Guide Towards Legged Robots](https://arxiv.org/abs/2510.21773)
*Van Nam Dinh*

Main category: cs.RO

TL;DR: 本文对足式机器人中的二次规划求解器进行了全面的分析和基准测试，比较了四种主要算法方法，为不同应用场景提供求解器选择指导。


<details>
  <summary>Details</summary>
Motivation: 二次规划在足式机器人的状态估计、运动规划和控制中至关重要，需要在嵌入式平台上实现高效、可靠的求解，但目前缺乏系统的求解器性能比较研究。

Method: 将求解器分为内点法、主动集策略、算子分裂方案和增广拉格朗日方法四类，分析算法结构、计算特性，并利用公开基准测试评估计算时间、约束满足和鲁棒性。

Result: 研究发现不同求解器在速度、精度和能效方面存在权衡，稀疏内点法适合长时域MPC，密集主动集方法适合高频WBC。

Conclusion: 求解器选择应与任务和硬件协同考虑，稀疏内点法适合长时域MPC，密集主动集方法适合高频WBC，未来可扩展到非凸和分布式QP问题。

Abstract: Quadratic programming (QP) underpins real-time robotics by enabling
efficient, constrained optimization in state estimation, motion planning, and
control. In legged locomotion and manipulation, essential modules like inverse
dynamics, Model Predictive Control (MPC), and Whole-Body Control (WBC) are
inherently QP-based, demanding reliable solutions amid tight timing, energy,
and computational limits on embedded platforms. This paper presents a
comprehensive analysis and benchmarking study of cutting-edge QP solvers for
legged robotics. We begin by formulating the standard convex QP and classify
solvers into four principal algorithmic approaches, including interior-point
methods, active-set strategies, operator splitting schemes, and augmented
Lagrangian approaches. Each solver is examined in terms of algorithmic
structure, computational characteristics, and its ability to exploit problem
structure and warm-starting. Performance is evaluated using publicly available
benchmarks, focusing on metrics such as computation time, constraint
satisfaction, and robustness under perturbations. Feature tables and
comparisons yield practical guidance for solver selection, underscoring
trade-offs in speed, accuracy, and energy efficiency. Our findings emphasize
the synergy between solver, task, and hardware, sparse IPMs for long-horizon
MPC, and dense active-set for high frequency WBC to advance agile, autonomous
legged systems, with emerging extensions to nonconvex and distributed QP.

</details>


### [179] [VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting](https://arxiv.org/abs/2510.21817)
*Xiaoyu Liu,Chaoyou Fu,Chi Yan,Chu Wu,Haihan Gao,Yi-Fan Zhang,Shaoqi Dong,Cheng Qian,Bin Luo,Xiuyong Yang,Guanwu Li,Yusheng Cai,Yunhang Shen,Deqiang Jiang,Haoyu Cao,Xing Sun,Caifeng Shan,Ran He*

Main category: cs.RO

TL;DR: VITA-E是一个创新的具身交互框架，通过双模型架构实现行为并发和实时中断处理，使具身代理能够同时观察环境、听取语音、提供回应并执行动作。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型受限于僵硬的静态交互范式，无法同时进行看、听、说、做等行为，也不能处理实时用户中断，这阻碍了无缝的具身协作。

Method: 采用双模型架构，两个并行的VLA实例分别作为"主动模型"和"待机模型"，并提出"模型即控制器"范式，通过微调VLM生成特殊令牌作为系统级命令。

Result: 在物理人形平台上的实验表明，VITA-E能可靠处理复杂交互场景，在紧急停止和语音中断方面达到极高成功率，并能成功执行并发语音和动作。

Conclusion: 该框架代表了向更自然、更强大具身助手迈出的重要一步，兼容各种双系统VLA模型。

Abstract: Current Vision-Language-Action (VLA) models are often constrained by a rigid,
static interaction paradigm, which lacks the ability to see, hear, speak, and
act concurrently as well as handle real-time user interruptions dynamically.
This hinders seamless embodied collaboration, resulting in an inflexible and
unresponsive user experience. To address these limitations, we introduce
VITA-E, a novel embodied interaction framework designed for both behavioral
concurrency and nearly real-time interruption. The core of our approach is a
dual-model architecture where two parallel VLA instances operate as an ``Active
Model'' and a ``Standby Model'', allowing the embodied agent to observe its
environment, listen to user speech, provide verbal responses, and execute
actions, all concurrently and interruptibly, mimicking human-like multitasking
capabilities. We further propose a ``model-as-controller'' paradigm, where we
fine-tune the VLM to generate special tokens that serve as direct system-level
commands, coupling the model's reasoning with the system's behavior.
Experiments conducted on a physical humanoid platform demonstrate that VITA-E
can reliably handle complex interactive scenarios. Our framework is compatible
with various dual-system VLA models, achieving an extremely high success rate
on emergency stops and speech interruptions while also successfully performing
concurrent speech and action. This represents a significant step towards more
natural and capable embodied assistants.

</details>


### [180] [A Literature Review On Stewart-Gough Platform Calibrations A Literature Review On Stewart-Gough Platform Calibrations](https://arxiv.org/abs/2510.21854)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 本文综述了Stewart-Gough平台（六足平台）的校准方法，重点关注基于逆运动学的校准技术，分析了各种校准方法的优缺点和误差源。


<details>
  <summary>Details</summary>
Motivation: Stewart-Gough平台在医疗、工程、航天等关键应用中需要微米级和纳米级的精确运动控制，因此高精度校准至关重要。正向运动学校准过于复杂，而逆运动学校准更为简便有效。

Method: 通过使用外部仪器、约束系统运动、添加额外传感器等方法实现自动或自校准，主要采用基于逆运动学的校准方法。

Result: 研究发现研究人员主要关注提高平台位置和方向精度，考虑单一或多重误差源，包括运动学和结构误差，部分研究还涉及环境因素，但校准通常在无负载条件下进行。

Conclusion: 本文综述了Stewart-Gough平台校准领域的最新技术，重点突出了校准过程中考虑的各种过程和误差源。

Abstract: Researchers have studied Stewart-Gough platforms, also known as Gough-Stewart
platforms or hexapod platforms extensively for their inherent fine control
characteristics. Their studies led to the potential deployment opportunities of
Stewart-Gough Platforms in many critical applications such as the medical
field, engineering machines, space research, electronic chip manufacturing,
automobile manufacturing, etc. Some of these applications need micro and
nano-level movement control in 3D space for the motions to be precise,
complicated, and repeatable; a Stewart-Gough platform fulfills these challenges
smartly. For this, the platform must be more accurate than the specified
application accuracy level and thus proper calibration for a parallel robot is
crucial. Forward kinematics-based calibration for these hexapod machines
becomes unnecessarily complex and inverse kinematics complete this task with
much ease. To experiment with different calibration techniques, various
calibration approaches were implemented by using external instruments,
constraining one or more motions of the system, and using extra sensors for
auto or self-calibration. This survey paid attention to those key
methodologies, their outcome, and important details related to inverse
kinematic-based parallel robot calibrations. It was observed during this study
that the researchers focused on improving the accuracy of the platform position
and orientation considering the errors contributed by one source or multiple
sources. The error sources considered are mainly kinematic and structural, in
some cases, environmental factors also are reviewed, however, those
calibrations are done under no-load conditions. This study aims to review the
present state of the art in this field and highlight the processes and errors
considered for the calibration of Stewart-Gough platforms.

</details>


### [181] [Butter-Bench: Evaluating LLM Controlled Robots for Practical Intelligence](https://arxiv.org/abs/2510.21860)
*Callum Sharrock,Lukas Petersson,Hanna Petersson,Axel Backlund,Axel Wennström,Kristoffer Nordström,Elias Aronsson*

Main category: cs.RO

TL;DR: Butter-Bench是一个评估LLM控制机器人实用智能的基准测试，发现人类表现(95%)远超最佳LLM(40%)，特别是在多步骤空间规划和社会理解方面。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在物理世界中的实用智能能力，当前机器人系统采用分层架构，LLM负责高层推理，VLA负责低层控制。

Method: 开发Butter-Bench基准测试，将LLM部分与VLA模型分离进行独立评估，比较LLM与人类在实用智能任务上的表现。

Result: 人类平均得分95%，最佳LLM仅得40%，LLM在多步骤空间规划和社会理解方面表现最差，专门针对具身推理的微调也未改善表现。

Conclusion: 尽管LLM在分析智能方面超越人类，但在物理世界的实用智能方面仍远不及人类，特别是在空间规划和社会理解能力上存在显著差距。

Abstract: We present Butter-Bench, a benchmark evaluating large language model (LLM)
controlled robots for practical intelligence, defined as the ability to
navigate the messiness of the physical world. Current state-of-the-art robotic
systems use a hierarchical architecture with LLMs in charge of high-level
reasoning, and a Vision Language Action (VLA) model for low-level control.
Butter-Bench evaluates the LLM part in isolation from the VLA. Although LLMs
have repeatedly surpassed humans in evaluations requiring analytical
intelligence, we find humans still outperform LLMs on Butter-Bench. The best
LLMs score 40% on Butter-Bench, while the mean human score is 95%. LLMs
struggled the most with multi-step spatial planning and social understanding.
We also evaluate LLMs that are fine-tuned for embodied reasoning and conclude
that this training does not improve their score on Butter-Bench.

</details>


### [182] [A Physics-Informed Neural Network Approach for UAV Path Planning in Dynamic Environments](https://arxiv.org/abs/2510.21874)
*Shuning Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于物理信息神经网络(PINN)的无人机轨迹规划框架，将无人机动力学、风场扰动和障碍物避让直接嵌入学习过程，无需监督数据即可生成动态可行且无碰撞的轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统规划器如A*和Kino-RRT*由于离散化和采样限制，往往产生次优或不平滑的路径。无人机在动态风场中需要生成安全且能量高效的轨迹。

Method: 使用物理信息神经网络框架，通过最小化物理残差和风险感知目标来学习轨迹，无需监督数据。该框架嵌入了无人机动力学、风扰动和障碍物避让约束。

Result: 比较仿真表明，该方法在控制能量、平滑度和安全裕度方面优于A*和Kino-RRT*，同时保持相似的飞行效率。

Conclusion: 物理信息学习有潜力统一基于模型和数据驱动的规划方法，为无人机轨迹优化提供可扩展且物理一致的框架。

Abstract: Unmanned aerial vehicles (UAVs) operating in dynamic wind fields must
generate safe and energy-efficient trajectories under physical and
environmental constraints. Traditional planners, such as A* and kinodynamic
RRT*, often yield suboptimal or non-smooth paths due to discretization and
sampling limitations. This paper presents a physics-informed neural network
(PINN) framework that embeds UAV dynamics, wind disturbances, and obstacle
avoidance directly into the learning process. Without requiring supervised
data, the PINN learns dynamically feasible and collision-free trajectories by
minimizing physical residuals and risk-aware objectives. Comparative
simulations show that the proposed method outperforms A* and Kino-RRT* in
control energy, smoothness, and safety margin, while maintaining similar flight
efficiency. The results highlight the potential of physics-informed learning to
unify model-based and data-driven planning, providing a scalable and physically
consistent framework for UAV trajectory optimization.

</details>


### [183] [Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising](https://arxiv.org/abs/2510.21991)
*Mateo Clemente,Leo Brunswic,Rui Heng Yang,Xuan Zhao,Yasser Khalil,Haoyu Lei,Amir Rasouli,Yinchuan Li*

Main category: cs.RO

TL;DR: 本文提出了一种针对机器人控制任务优化的扩散策略，通过定制化去噪过程和遗传去噪采样策略，仅需2-5次神经网络评估即可高效解决复杂任务，在14个机器人操作任务中性能提升达20%。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型直接从视觉任务迁移到控制领域，未针对机器人任务中动作分布的结构化、低维特性进行优化，导致推理效率低下。

Method: 提出遗传去噪采样策略，通过选择低分布外风险的去噪轨迹来增强性能和稳定性；针对具体任务特性定制去噪过程。

Result: 在D4RL和Robomimic的14个机器人操作任务中，仅用2次神经网络评估即可解决挑战性任务，性能提升达20%，在200万次评估中持续优于标准扩散策略。

Conclusion: 通过针对具体任务特性优化扩散策略，可以显著提高推理效率，在少量神经网络评估下实现优异性能。

Abstract: Diffusion models, such as diffusion policy, have achieved state-of-the-art
results in robotic manipulation by imitating expert demonstrations. While
diffusion models were originally developed for vision tasks like image and
video generation, many of their inference strategies have been directly
transferred to control domains without adaptation. In this work, we show that
by tailoring the denoising process to the specific characteristics of embodied
AI tasks -- particularly structured, low-dimensional nature of action
distributions -- diffusion policies can operate effectively with as few as 5
neural function evaluations (NFE).
  Building on this insight, we propose a population-based sampling strategy,
genetic denoising, which enhances both performance and stability by selecting
denoising trajectories with low out-of-distribution risk. Our method solves
challenging tasks with only 2 NFE while improving or matching performance. We
evaluate our approach across 14 robotic manipulation tasks from D4RL and
Robomimic, spanning multiple action horizons and inference budgets. In over 2
million evaluations, our method consistently outperforms standard
diffusion-based policies, achieving up to 20\% performance gains with
significantly fewer inference steps.

</details>


### [184] [Estimation of Minimum Stride Frequency for the Frontal Plane Stability of Bipedal Systems](https://arxiv.org/abs/2510.22030)
*Harsha Karunanayaka,Siavash Rezazadeh*

Main category: cs.RO

TL;DR: 该研究分析了双足系统在额状面的稳定性机制，发现通过调整步频可以实现无需反馈控制的前馈稳定，并提出了预测最小步频的方法。


<details>
  <summary>Details</summary>
Motivation: 目前对双足系统额状面稳定性的关键参数（如质量、刚度、腿长和髋宽）如何影响稳定性和维持稳定所需的最小步频理解有限。

Method: 通过分析个体模型参数和系统自然频率对最小步频的影响，提出预测最小步频的方法，并与随机生成模型的实际值进行比较。

Result: 研究结果提供了对额状面稳定性机制的更好理解，以及如何利用前馈稳定来减少控制努力。

Conclusion: 前馈稳定可以降低控制努力和能量消耗，提高运动鲁棒性，该研究为理解双足系统稳定性机制提供了重要见解。

Abstract: Stability of bipedal systems in frontal plane is affected by the hip offset,
to the extent that adjusting stride time using feedforward retraction and
extension of the legs can lead to stable oscillations without feedback control.
This feedforward stabilization can be leveraged to reduce the control effort
and energy expenditure and increase the locomotion robustness. However, there
is limited understanding of how key parameters, such as mass, stiffness, leg
length, and hip width, affect stability and the minimum stride frequency needed
to maintain it. This study aims to address these gaps through analyzing how
individual model parameters and the system's natural frequency influence the
minimum stride frequency required to maintain a stable cycle. We propose a
method to predict the minimum stride frequency, and compare the predicted
stride frequencies with actual values for randomly generated models. The
findings of this work provide a better understanding of the frontal plane
stability mechanisms and how feedforward stabilization can be leveraged to
reduce the control effort.

</details>


### [185] [RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation](https://arxiv.org/abs/2510.22113)
*Zitiantao Lin,Yongpeng Sang,Yang Ye*

Main category: cs.RO

TL;DR: 提出了一种基于混合现实头显的以自我为中心的注视引导机器人操纵界面，通过自然注视固定和增强视觉提示来改善辅助机器人系统的直观性和可访问性。


<details>
  <summary>Details</summary>
Motivation: 传统操纵杆控制界面精度要求高且参考框架不直观，现有解决方案依赖外部屏幕或限制性控制方案，限制了直观性和可访问性。

Method: 利用可穿戴混合现实头显，从第一人称视角通过自然注视固定与现实世界对象交互，结合预训练视觉模型和机器人手臂进行意图识别和对象操纵。

Result: 实验结果显示该方法显著提高了操纵精度，降低了系统延迟，在多个真实场景中实现了超过88%的单次意图和对象识别准确率。

Conclusion: 该系统有效增强了辅助机器人应用的直观性和可访问性，具有重要的实际意义。

Abstract: Robotic manipulators are increasingly used to assist individuals with
mobility impairments in object retrieval. However, the predominant
joystick-based control interfaces can be challenging due to high precision
requirements and unintuitive reference frames. Recent advances in human-robot
interaction have explored alternative modalities, yet many solutions still rely
on external screens or restrictive control schemes, limiting their
intuitiveness and accessibility. To address these challenges, we present an
egocentric, gaze-guided robotic manipulation interface that leverages a
wearable Mixed Reality (MR) headset. Our system enables users to interact
seamlessly with real-world objects using natural gaze fixation from a
first-person perspective, while providing augmented visual cues to confirm
intent and leveraging a pretrained vision model and robotic arm for intent
recognition and object manipulation. Experimental results demonstrate that our
approach significantly improves manipulation accuracy, reduces system latency,
and achieves single-pass intention and object recognition accuracy greater than
88% across multiple real-world scenarios. These results demonstrate the
system's effectiveness in enhancing intuitiveness and accessibility,
underscoring its practical significance for assistive robotics applications.

</details>


### [186] [EasyUUV: An LLM-Enhanced Universal and Lightweight Sim-to-Real Reinforcement Learning Framework for UUV Attitude Control](https://arxiv.org/abs/2510.22126)
*Guanwen Xie,Jingzehua Xu,Jiwei Tang,Yubo Huang,Shuai Zhang,Xiaofan Li*

Main category: cs.RO

TL;DR: EasyUUV是一个基于大语言模型增强的轻量级仿真到现实强化学习框架，用于无人水下航行器的鲁棒姿态控制，结合并行RL训练和混合控制架构，通过LLM自适应调整控制器参数。


<details>
  <summary>Details</summary>
Motivation: 解决现有UUV姿态控制方法在泛化性、对现实干扰的鲁棒性以及高效部署方面的不足。

Method: 结合并行化RL训练与混合控制架构，其中学习策略输出高层姿态修正，由自适应S-Surface控制器执行，并集成多模态LLM在运行时使用视觉和文本反馈自适应调整控制器参数。

Result: 广泛的仿真和真实世界实验验证了EasyUUV在不同水下条件下实现鲁棒和自适应UUV姿态控制的有效性和优异性能。

Conclusion: EasyUUV框架在UUV姿态控制方面表现出色，能够实现训练免费的适应未建模动态，并开发了低成本6自由度UUV平台进行验证。

Abstract: Despite recent advances in Unmanned Underwater Vehicle (UUV) attitude
control, existing methods still struggle with generalizability, robustness to
real-world disturbances, and efficient deployment. To address the above
challenges, this paper presents EasyUUV, a Large Language Model (LLM)-enhanced,
universal, and lightweight simulation-to-reality reinforcement learning (RL)
framework for robust attitude control of UUVs. EasyUUV combines parallelized RL
training with a hybrid control architecture, where a learned policy outputs
high-level attitude corrections executed by an adaptive S-Surface controller. A
multimodal LLM is further integrated to adaptively tune controller parameters
at runtime using visual and textual feedback, enabling training-free adaptation
to unmodeled dynamics. Also, we have developed a low-cost 6-DoF UUV platform
and applied an RL policy trained through efficient parallelized simulation.
Extensive simulation and real-world experiments validate the effectiveness and
outstanding performance of EasyUUV in achieving robust and adaptive UUV
attitude control across diverse underwater conditions. The source code is
available from the following website: https://360zmem.github.io/easyuuv/

</details>


### [187] [LT-Exosense: A Vision-centric Multi-session Mapping System for Lifelong Safe Navigation of Exoskeletons](https://arxiv.org/abs/2510.22164)
*Jianeng Wang,Matias Mattamala,Christina Kassab,Nived Chebrolu,Guillaume Burger,Fabio Elnecave,Marine Petriaux,Maurice Fallon*

Main category: cs.RO

TL;DR: LT-Exosense是一个面向外骨骼用户的视觉中心多会话建图系统，支持长期（半）自主导航，通过跨会话融合空间知识、检测环境变化和更新持久全局地图来实现智能路径规划。


<details>
  <summary>Details</summary>
Motivation: 为下肢残疾人士提供可靠长期运行的自平衡外骨骼需要能够在变化环境中有效工作的感知系统。

Method: 扩展单会话建图能力，通过增量融合多个会话的空间知识、检测环境变化并更新持久全局地图，实现智能路径规划。

Result: 在真实世界实验中验证了可扩展的多会话地图，与地面真实激光扫描相比，平均点对点误差低于5厘米，展示了在动态变化室内环境中自适应路径规划的潜力。

Conclusion: LT-Exosense系统能够有效支持外骨骼用户的长期自主导航，在动态环境中具有实际应用价值。

Abstract: Self-balancing exoskeletons offer a promising mobility solution for
individuals with lower-limb disabilities. For reliable long-term operation,
these exoskeletons require a perception system that is effective in changing
environments. In this work, we introduce LT-Exosense, a vision-centric,
multi-session mapping system designed to support long-term (semi)-autonomous
navigation for exoskeleton users. LT-Exosense extends single-session mapping
capabilities by incrementally fusing spatial knowledge across multiple
sessions, detecting environmental changes, and updating a persistent global
map. This representation enables intelligent path planning, which can adapt to
newly observed obstacles and can recover previous routes when obstructions are
removed. We validate LT-Exosense through several real-world experiments,
demonstrating a scalable multi-session map that achieves an average
point-to-point error below 5 cm when compared to ground-truth laser scans. We
also illustrate the potential application of adaptive path planning in
dynamically changing indoor environments.

</details>


### [188] [ACG: Action Coherence Guidance for Flow-based VLA models](https://arxiv.org/abs/2510.22201)
*Minho Park,Kinam Kim,Junha Hyung,Hyojin Jang,Hoiyeong Jin,Jooyeol Yun,Hojoon Lee,Jaegul Choo*

Main category: cs.RO

TL;DR: 提出了一种无需训练的动作连贯性指导算法，用于提升视觉语言动作模型在机器人控制中的动作连贯性，减少部署时的不稳定性和轨迹漂移。


<details>
  <summary>Details</summary>
Motivation: 扩散和流匹配模型作为强大的机器人策略，在模仿学习中对人类演示中的噪声敏感，导致动作不连贯，影响精细操作的精确性。

Method: 动作连贯性指导算法，在测试时无需额外训练，通过指导机制提升动作连贯性。

Result: 在RoboCasa、DexMimicGen和真实世界SO-101任务上评估，一致提升了动作连贯性并提高了各种操作任务的成功率。

Conclusion: ACG算法能有效提升VLA模型的动作连贯性，在多种操作任务中带来性能增益。

Abstract: Diffusion and flow matching models have emerged as powerful robot policies,
enabling Vision-Language-Action (VLA) models to generalize across diverse
scenes and instructions. Yet, when trained via imitation learning, their high
generative capacity makes them sensitive to noise in human demonstrations:
jerks, pauses, and jitter which reduce action coherence. Reduced action
coherence causes instability and trajectory drift during deployment, failures
that are catastrophic in fine-grained manipulation where precision is crucial.
In this paper, we present Action Coherence Guidance (ACG) for VLA models, a
training-free test-time guidance algorithm that improves action coherence and
thereby yields performance gains. Evaluated on RoboCasa, DexMimicGen, and
real-world SO-101 tasks, ACG consistently improves action coherence and boosts
success rates across diverse manipulation tasks. Code and project page are
available at https://github.com/DAVIAN-Robotics/ACG and
https://DAVIAN-Robotics.github.io/ACG , respectively.

</details>


### [189] [Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing for UAVs in Cluttered Environments](https://arxiv.org/abs/2510.22204)
*Weixian Qian,Sebastian Schroder,Yao Deng,Jiaohong Yao,Linfeng Liang,Xiao Cheng,Richard Han,Xi Zheng*

Main category: cs.RO

TL;DR: NeuroSymLand是一个神经符号框架，通过结合大型语言模型和符号推理，实现无人机在非结构化环境中的自主着陆，具有高精度、强鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统纯视觉或深度学习模型在无人机自主着陆任务中面临协变量偏移和可解释性不足的问题，需要一种结合感知能力和符号推理的解决方案。

Method: 采用双管道设计：离线管道使用LLM和人工细化合成可验证的符号知识；在线管道通过语义分割生成概率事实，构建语义场景图进行实时推理。

Result: 在多个数据集、仿真环境和真实无人机硬件上的评估表明，NeuroSymLand在准确性、鲁棒性和效率方面均优于现有基线方法。

Conclusion: 该框架成功结合了轻量级基础模型的感知优势与符号推理的可解释性，提升了无人机在应急响应、监视和配送任务中的安全性和可靠性。

Abstract: Autonomous landing in unstructured (cluttered, uneven, and map-poor)
environments is a core requirement for Unmanned Aerial Vehicles (UAVs), yet
purely vision-based or deep learning models often falter under covariate shift
and provide limited interpretability. We propose NeuroSymLand, a neuro-symbolic
framework that tightly couples two complementary pipelines: (i) an offline
pipeline, where Large Language Models (LLMs) and human-in-the-loop refinement
synthesize Scallop code from diverse landing scenarios, distilling
generalizable and verifiable symbolic knowledge; and (ii) an online pipeline,
where a compact foundation-based semantic segmentation model generates
probabilistic Scallop facts that are composed into semantic scene graphs for
real-time deductive reasoning. This design combines the perceptual strengths of
lightweight foundation models with the interpretability and verifiability of
symbolic reasoning. Node attributes (e.g., flatness, area) and edge relations
(adjacency, containment, proximity) are computed with geometric routines rather
than learned, avoiding the data dependence and latency of train-time graph
builders. The resulting Scallop program encodes landing principles (avoid water
and obstacles; prefer large, flat, accessible regions) and yields calibrated
safety scores with ranked Regions of Interest (ROIs) and human-readable
justifications. Extensive evaluations across datasets, diverse simulation maps,
and real UAV hardware show that NeuroSymLand achieves higher accuracy, stronger
robustness to covariate shift, and superior efficiency compared with
state-of-the-art baselines, while advancing UAV safety and reliability in
emergency response, surveillance, and delivery missions.

</details>


### [190] [Breaking the Static Assumption: A Dynamic-Aware LIO Framework Via Spatio-Temporal Normal Analysis](https://arxiv.org/abs/2510.22313)
*Chen Zhiqiang,Le Gentil Cedric,Lin Fuling,Lu Minghao,Qiao Qiyuan,Xu Bowen,Qi Yuhua,Lu Peng*

Main category: cs.RO

TL;DR: 提出了一种动态感知的激光雷达-惯性里程计方法，通过时空法向量分析和空间一致性验证，在动态环境中实现更准确的定位和静态地图构建。


<details>
  <summary>Details</summary>
Motivation: 传统LIO方法在动态环境中表现不佳，特别是在几何稀疏场景中。现有动态LIO方法面临循环依赖问题：准确定位需要可靠的静态特征识别，而区分动态物体又需要精确的位姿估计。

Method: 将动态感知直接集成到点云配准过程中，提出动态感知的迭代最近点算法，利用时空法向量分析，并辅以高效的空间一致性验证方法来增强静态地图构建。

Result: 实验评估显示，在几何结构有限的挑战性动态环境中，相比最先进的LIO系统有显著性能提升。

Conclusion: 该方法通过打破循环依赖，在动态环境中实现了更鲁棒的激光雷达-惯性里程计性能。

Abstract: This paper addresses the challenge of Lidar-Inertial Odometry (LIO) in
dynamic environments, where conventional methods often fail due to their
static-world assumptions. Traditional LIO algorithms perform poorly when
dynamic objects dominate the scenes, particularly in geometrically sparse
environments. Current approaches to dynamic LIO face a fundamental challenge:
accurate localization requires a reliable identification of static features,
yet distinguishing dynamic objects necessitates precise pose estimation. Our
solution breaks this circular dependency by integrating dynamic awareness
directly into the point cloud registration process. We introduce a novel
dynamic-aware iterative closest point algorithm that leverages spatio-temporal
normal analysis, complemented by an efficient spatial consistency verification
method to enhance static map construction. Experimental evaluations demonstrate
significant performance improvements over state-of-the-art LIO systems in
challenging dynamic environments with limited geometric structure. The code and
dataset are available at https://github.com/thisparticle/btsa.

</details>


### [191] [Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery](https://arxiv.org/abs/2510.22336)
*Bo Yue,Sheng Xu,Kui Jia,Guiliang Liu*

Main category: cs.RO

TL;DR: RoboCraft是一个可扩展的人形机器人协同设计框架，通过控制策略和形态学的耦合更新迭代提升跌倒恢复性能。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在人类工作空间具有天然部署优势，跌倒恢复作为关键能力能增强安全性和自主性。脑体协同设计通过联合优化控制策略和物理形态来实现这一潜力。

Method: 采用共享策略在多设计上预训练，然后在高性能形态上逐步微调；形态搜索受人类启发先验和优化算法指导，使用优先级缓冲区平衡有前景候选的重新评估和新设计的探索。

Result: 在7个公开人形机器人上平均性能提升44.55%，形态优化在4个人形机器人协同设计中贡献至少40%的改进。

Conclusion: 人形机器人协同设计在提升跌倒恢复性能中发挥关键作用，形态优化是性能提升的重要驱动因素。

Abstract: Humanoid robots represent a central frontier in embodied intelligence, as
their anthropomorphic form enables natural deployment in humans' workspace.
Brain-body co-design for humanoids presents a promising approach to realizing
this potential by jointly optimizing control policies and physical morphology.
Within this context, fall recovery emerges as a critical capability. It not
only enhances safety and resilience but also integrates naturally with
locomotion systems, thereby advancing the autonomy of humanoids. In this paper,
we propose RoboCraft, a scalable humanoid co-design framework for fall recovery
that iteratively improves performance through the coupled updates of control
policy and morphology. A shared policy pretrained across multiple designs is
progressively finetuned on high-performing morphologies, enabling efficient
adaptation without retraining from scratch. Concurrently, morphology search is
guided by human-inspired priors and optimization algorithms, supported by a
priority buffer that balances reevaluation of promising candidates with the
exploration of novel designs. Experiments show that \ourmethod{} achieves an
average performance gain of 44.55% on seven public humanoid robots, with
morphology optimization drives at least 40% of improvements in co-designing
four humanoid robots, underscoring the critical role of humanoid co-design.

</details>


### [192] [Estimating Continuum Robot Shape under External Loading using Spatiotemporal Neural Networks](https://arxiv.org/abs/2510.22339)
*Enyi Wang,Zhen Deng,Chuanchuan Pan,Bingwei He,Jianwei Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于学习的柔性连续机器人3D形状估计方法，通过时空神经网络融合多模态输入（肌腱位移数据和RGB图像）来重建受外部载荷影响的机器人形状。


<details>
  <summary>Details</summary>
Motivation: 现有方法在柔性连续机器人受外部载荷时的形状估计精度不足，需要开发能够融合时空信息的多模态方法来提高形状感知精度。

Method: 采用时空神经网络架构，包含循环神经网络模块提取时间特征、编码模块提取空间特征，以及多模态融合模块结合视觉空间特征和历史执行器输入的时间依赖性，通过拟合Bézier曲线实现连续3D形状重建。

Result: 实验验证显示该方法达到高精度，平均形状估计误差为0.08毫米（无载荷）和0.22毫米（有载荷），在TDCR形状感知方面优于现有最先进方法。

Conclusion: 深度学习驱动的时空数据融合方法在载荷条件下能够实现精确的形状估计，验证了该方法的有效性。

Abstract: This paper presents a learning-based approach for accurately estimating the
3D shape of flexible continuum robots subjected to external loads. The proposed
method introduces a spatiotemporal neural network architecture that fuses
multi-modal inputs, including current and historical tendon displacement data
and RGB images, to generate point clouds representing the robot's deformed
configuration. The network integrates a recurrent neural module for temporal
feature extraction, an encoding module for spatial feature extraction, and a
multi-modal fusion module to combine spatial features extracted from visual
data with temporal dependencies from historical actuator inputs. Continuous 3D
shape reconstruction is achieved by fitting B\'ezier curves to the predicted
point clouds. Experimental validation demonstrates that our approach achieves
high precision, with mean shape estimation errors of 0.08 mm (unloaded) and
0.22 mm (loaded), outperforming state-of-the-art methods in shape sensing for
TDCRs. The results validate the efficacy of deep learning-based spatiotemporal
data fusion for precise shape estimation under loading conditions.

</details>


### [193] [BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles](https://arxiv.org/abs/2510.22370)
*Seyed Ahmad Hosseini Miangoleh,Amin Jalal Aghdasian,Farzaneh Abdollahi*

Main category: cs.RO

TL;DR: 提出BLIP-FusePPO框架，将视觉语言模型生成的语义嵌入与几何状态、LiDAR观测和PID控制反馈融合，用于自动驾驶车道保持任务。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅使用语义模型来塑造奖励，而本方法直接将语义特征嵌入状态表示，减少昂贵的运行时推理并确保语义指导始终可用。

Method: 通过融合语义、几何和控制感知表示，结合包含语义对齐、车道保持精度、障碍物避让和速度调节的混合奖励函数。

Result: 仿真结果显示，在多种困难驾驶场景下，该模型在车道保持稳定性和适应性方面优于最佳视觉和多模态强化学习基线方法。

Conclusion: BLIP-FusePPO通过直接融合语义特征到状态表示，实现了更鲁棒和可解释的自动驾驶策略学习。

Abstract: In this paper, we propose Bootstrapped Language-Image Pretraining-driven
Fused State Representation in Proximal Policy Optimization (BLIP-FusePPO), a
novel multimodal reinforcement learning (RL) framework for autonomous
lane-keeping (LK), in which semantic embeddings generated by a vision-language
model (VLM) are directly fused with geometric states, LiDAR observations, and
Proportional-Integral-Derivative-based (PID) control feedback within the agent
observation space. The proposed method lets the agent learn driving rules that
are aware of their surroundings and easy to understand by combining high-level
scene understanding from the VLM with low-level control and spatial signals.
Our architecture brings together semantic, geometric, and control-aware
representations to make policy learning more robust. A hybrid reward function
that includes semantic alignment, LK accuracy, obstacle avoidance, and speed
regulation helps learning to be more efficient and generalizable. Our method is
different from the approaches that only use semantic models to shape rewards.
Instead, it directly embeds semantic features into the state representation.
This cuts down on expensive runtime inference and makes sure that semantic
guidance is always available. The simulation results show that the proposed
model is better at LK stability and adaptability than the best vision-based and
multimodal RL baselines in a wide range of difficult driving situations. We
make our code publicly available.

</details>


### [194] [A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems](https://arxiv.org/abs/2510.22420)
*Mohammad Ali Labbaf Khaniki,Fateme Taroodi,Benyamin Safizadeh*

Main category: cs.RO

TL;DR: 提出了MTLHRL框架，通过分层策略和Lyapunov约束解决高维随机系统的控制问题，在超混沌系统和机器人控制中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决高维随机系统控制面临的维度灾难、缺乏时间抽象和随机稳定性保证不足的问题。

Method: 基于半马尔可夫决策过程的分层强化学习框架，包含高层策略进行战略规划，低层策略进行反应控制，通过神经Lyapunov函数和拉格朗日松弛优化确保稳定性。

Result: 在8D超混沌系统和5自由度机器人上验证，显著优于基线方法，IAE误差分别为3.912和1.623，收敛更快，抗干扰能力更强。

Conclusion: MTLHRL为复杂随机系统的鲁棒控制提供了理论严谨且实际可行的解决方案。

Abstract: Controlling high-dimensional stochastic systems, critical in robotics,
autonomous vehicles, and hyperchaotic systems, faces the curse of
dimensionality, lacks temporal abstraction, and often fails to ensure
stochastic stability. To overcome these limitations, this study introduces the
Multi-Timescale Lyapunov-Constrained Hierarchical Reinforcement Learning
(MTLHRL) framework. MTLHRL integrates a hierarchical policy within a
semi-Markov Decision Process (SMDP), featuring a high-level policy for
strategic planning and a low-level policy for reactive control, which
effectively manages complex, multi-timescale decision-making and reduces
dimensionality overhead. Stability is rigorously enforced using a neural
Lyapunov function optimized via Lagrangian relaxation and multi-timescale
actor-critic updates, ensuring mean-square boundedness or asymptotic stability
in the face of stochastic dynamics. The framework promotes efficient and
reliable learning through trust-region constraints and decoupled optimization.
Extensive simulations on an 8D hyperchaotic system and a 5-DOF robotic
manipulator demonstrate MTLHRL's empirical superiority. It significantly
outperforms baseline methods in both stability and performance, recording the
lowest error indices (e.g., Integral Absolute Error (IAE): 3.912 in
hyperchaotic control and IAE: 1.623 in robotics), achieving faster convergence,
and exhibiting superior disturbance rejection. MTLHRL offers a theoretically
grounded and practically viable solution for robust control of complex
stochastic systems.

</details>


### [195] [A short methodological review on social robot navigation benchmarking](https://arxiv.org/abs/2510.22448)
*Pranup Chhetri,Alejandro Torrejon,Sergio Eslava,Luis J. Manso*

Main category: cs.RO

TL;DR: 这篇论文对2020年1月至2025年7月期间社会机器人导航领域的基准测试趋势进行了系统性回顾，分析了85篇相关论文，重点关注基准测试指标、算法、人类调查使用情况以及结论推导方式。


<details>
  <summary>Details</summary>
Motivation: 社会机器人导航领域缺乏统一的基准测试标准，这阻碍了该领域的发展并可能导致相互矛盾的结论。作者旨在填补这一空白。

Method: 通过IEEE Xplore数据库识别了130篇论文，最终分析了符合标准的85篇论文，系统回顾了基准测试的指标、算法、人类调查使用和结论推导方法。

Result: 研究发现社会机器人导航领域在基准测试方面存在标准化不足的问题，不同研究使用的指标和方法差异较大。

Conclusion: 该领域迫切需要建立统一的基准测试标准，以促进社会机器人导航研究的可比性和进步。

Abstract: Social Robot Navigation is the skill that allows robots to move efficiently
in human-populated environments while ensuring safety, comfort, and trust.
Unlike other areas of research, the scientific community has not yet achieved
an agreement on how Social Robot Navigation should be benchmarked. This is
notably important, as the lack of a de facto standard to benchmark Social Robot
Navigation can hinder the progress of the field and may lead to contradicting
conclusions. Motivated by this gap, we contribute with a short review focused
exclusively on benchmarking trends in the period from January 2020 to July
2025. Of the 130 papers identified by our search using IEEE Xplore, we analysed
the 85 papers that met the criteria of the review. This review addresses the
metrics used in the literature for benchmarking purposes, the algorithms
employed in such benchmarks, the use of human surveys for benchmarking, and how
conclusions are drawn from the benchmarking results, when applicable.

</details>


### [196] [Forward Kinematics Solution For A General Stewart Platform Through Iteration Based Simulation](https://arxiv.org/abs/2510.22465)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 提出了一种为通用Stewart平台生成可行、唯一正向运动学解的方法，使用逆运动学获取有效工作空间数据和对应的执行器长度，通过改进的Denavit-Hartenberg约定实现简单迭代算法。


<details>
  <summary>Details</summary>
Motivation: 解决Stewart平台等并联运动机构的正向运动学复杂且产生多解的问题，为六自由度材料测试系统提供可直接使用的唯一正向运动学解。

Method: 使用改进的Denavit-Hartenberg约定的简单迭代算法，通过逆运动学获取有效工作空间数据和执行器长度。

Result: 该方法为每个有效位姿生成单一可行的正向运动学解，无需手动验证即可直接用于进一步计算。

Conclusion: 该方法成功解决了Stewart平台正向运动学的多解问题，为材料测试系统的精确力控制提供了可靠的运动学基础。

Abstract: This paper presents a method to generate feasible, unique forward-kinematic
solutions for a general Stewart platform. This is done by using inverse
kinematics to obtain valid workspace data and corresponding actuator lengths
for the moving platform. For parallel kinematic machines, such as the Stewart
Platform, inverse kinematics are straight forward, but the forward kinematics
are complex and generates multiple solutions due to the closed loop structure
of the kinematic links. In this research, a simple iterative algorithm has been
used employing modified Denavit-Hartenberg convention. The outcome is
encouraging as this method generates a single feasible forward kinematic
solution for each valid pose with the solved DH parameters and unlike earlier
forward kinematics solutions, this unique solution does not need to be manually
verified. Therefore, the forward kinematic solutions can be used directly for
further calculations without the need for manual pose verification. This
capability is essential for the six degree of freedom materials testing system
developed by the authors in their laboratory. The developed system is aimed at
characterizing additively manufactured materials under complex combined
multiple loading conditions. The material characterization is done by enabling
high precision force control on the moving platform via in situ calibration of
the as-built kinematics of the Stewart Gough Platform.

</details>


### [197] [On Steerability Factors for Growing Vine Robots](https://arxiv.org/abs/2510.22504)
*Ciera McFarland,Antonio Alvarez,Sarah Taher,Nathaniel Hanson,Margaret McGuinness*

Main category: cs.RO

TL;DR: 该研究探讨了藤蔓机器人的可操纵性，分析了尖端负载、压力、长度、直径和制造方法对机器人转向能力的影响，并展示了优化参数在移动任务中的优势。


<details>
  <summary>Details</summary>
Motivation: 藤蔓机器人在复杂环境中具有应用潜力，但其性能受到附加传感器重量、设计选择和控制参数的限制，需要系统研究影响转向能力的关键因素。

Method: 进行两组实验：第一组研究在重力支撑条件下尖端负载、腔室压力、长度和直径的影响；第二组研究制造方法和执行器与腔室压力比在地面支撑条件下的影响。

Result: 可操纵性随尖端负载增加而降低，在中等腔室压力下最佳，随长度增加而提高，直径影响不大。外置执行器的机器人在低压比时开始转向但饱和，集成执行器的需要更高压力比但能达到更大曲率。

Conclusion: 基于这些原理优化的机器人在涉及最大化向上和水平曲率的移动任务中表现优于临时参数设置的机器人。

Abstract: Vine robots extend their tubular bodies by everting material from the tip,
enabling navigation in complex environments with a minimalist soft body.
Despite their promise for field applications, especially in the urban search
and rescue domain, performance is constrained by the weight of attached sensors
or tools, as well as other design and control choices. This work investigates
how tip load, pressure, length, diameter, and fabrication method shape vine
robot steerability--the ability to maneuver with controlled curvature--for
robots that steer with series pouch motor-style pneumatic actuators. We conduct
two groups of experiments: (1) studying tip load, chamber pressure, length, and
diameter in a robot supporting itself against gravity, and (2) studying
fabrication method and ratio of actuator to chamber pressure in a robot
supported on the ground. Results show that steerability decreases with
increasing tip load, is best at moderate chamber pressure, increases with
length, and is largely unaffected by diameter. Robots with actuators attached
on their exterior begin curving at low pressure ratios, but curvature saturates
at high pressure ratios; those with actuators integrated into the robot body
require higher pressure ratios to begin curving but achieve higher curvature
overall. We demonstrate that robots optimized with these principles outperform
those with ad hoc parameters in a mobility task that involves maximizing upward
and horizontal curvatures.

</details>


### [198] [Ant-inspired Walling Strategies for Scalable Swarm Separation: Reinforcement Learning Approaches Based on Finite State Machines](https://arxiv.org/abs/2510.22524)
*Shenbagaraj Kannapiran,Elena Oikonomou,Albert Chu,Spring Berman,Theodore P. Pavlic*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In natural systems, emergent structures often arise to balance competing
demands. Army ants, for example, form temporary "walls" that prevent
interference between foraging trails. Inspired by this behavior, we developed
two decentralized controllers for heterogeneous robotic swarms to maintain
spatial separation while executing concurrent tasks. The first is a
finite-state machine (FSM)-based controller that uses encounter-triggered
transitions to create rigid, stable walls. The second integrates FSM states
with a Deep Q-Network (DQN), dynamically optimizing separation through emergent
"demilitarized zones." In simulation, both controllers reduce mixing between
subgroups, with the DQN-enhanced controller improving adaptability and reducing
mixing by 40-50% while achieving faster convergence.

</details>


### [199] [SPIRAL: Self-Play Incremental Racing Algorithm for Learning in Multi-Drone Competitions](https://arxiv.org/abs/2510.22568)
*Onur Akgün*

Main category: cs.RO

TL;DR: SPIRAL是一种用于训练自主无人机在多智能体竞赛中的自博弈增量学习算法，通过自博弈机制逐步培养复杂竞赛行为，能够与各种深度强化学习算法集成。


<details>
  <summary>Details</summary>
Motivation: 为自主无人机在多智能体竞赛环境中开发一个能够自我改进、可扩展的学习框架，通过自主生成逐步升级的挑战来培养鲁棒和自适应的竞赛策略。

Method: 采用自博弈机制，让无人机与不断进化的自身版本竞争，逐步提升竞争难度，从基础飞行控制到复杂多无人机协作策略。

Result: 仿真实验表明SPIRAL具有显著优势，并基准测试了在其框架内运行的各种深度强化学习算法的性能。

Conclusion: SPIRAL为自主无人机竞赛领域提供了一个多功能、可扩展且自我改进的学习框架，为在日益复杂和竞争激烈的场景中提升自主竞赛无人机的性能和可靠性开辟了新途径。

Abstract: This paper introduces SPIRAL (Self-Play Incremental Racing Algorithm for
Learning), a novel approach for training autonomous drones in multi-agent
racing competitions. SPIRAL distinctively employs a self-play mechanism to
incrementally cultivate complex racing behaviors within a challenging, dynamic
environment. Through this self-play core, drones continuously compete against
increasingly proficient versions of themselves, naturally escalating the
difficulty of competitive interactions. This progressive learning journey
guides agents from mastering fundamental flight control to executing
sophisticated cooperative multi-drone racing strategies. Our method is designed
for versatility, allowing integration with any state-of-the-art Deep
Reinforcement Learning (DRL) algorithms within its self-play framework.
Simulations demonstrate the significant advantages of SPIRAL and benchmark the
performance of various DRL algorithms operating within it. Consequently, we
contribute a versatile, scalable, and self-improving learning framework to the
field of autonomous drone racing. SPIRAL's capacity to autonomously generate
appropriate and escalating challenges through its self-play dynamic offers a
promising direction for developing robust and adaptive racing strategies in
multi-agent environments. This research opens new avenues for enhancing the
performance and reliability of autonomous racing drones in increasingly complex
and competitive scenarios.

</details>


### [200] [Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing](https://arxiv.org/abs/2510.22570)
*Onur Akgün*

Main category: cs.RO

TL;DR: CRUISE是一个基于课程学习和自我博弈的强化学习框架，专门用于解决多无人机竞速中的可扩展性问题，在仿真中显著优于传统强化学习和博弈论规划器。


<details>
  <summary>Details</summary>
Motivation: 解决多自主智能体在高速竞争环境中的协调问题，特别是在多无人机竞速这一具有挑战性的领域中，克服现有方法的可扩展性限制。

Method: 结合渐进难度课程学习和高效自我博弈机制，通过课程结构逐步提升训练难度，培养鲁棒的竞争行为。

Result: 在逼真四旋翼动力学仿真中，CRUISE的平均竞速速度达到最先进博弈论规划器的近两倍，保持高成功率，并在智能体密度增加时展现出鲁棒的可扩展性。

Conclusion: 课程结构是实现性能突破的关键因素，CRUISE为动态竞争任务的自主系统开发提供了可扩展有效的训练方法，为未来实际部署奠定了基础。

Abstract: The coordination of multiple autonomous agents in high-speed, competitive
environments represents a significant engineering challenge. This paper
presents CRUISE (Curriculum-Based Iterative Self-Play for Scalable Multi-Drone
Racing), a reinforcement learning framework designed to solve this challenge in
the demanding domain of multi-drone racing. CRUISE overcomes key scalability
limitations by synergistically combining a progressive difficulty curriculum
with an efficient self-play mechanism to foster robust competitive behaviors.
Validated in high-fidelity simulation with realistic quadrotor dynamics, the
resulting policies significantly outperform both a standard reinforcement
learning baseline and a state-of-the-art game-theoretic planner. CRUISE
achieves nearly double the planner's mean racing speed, maintains high success
rates, and demonstrates robust scalability as agent density increases. Ablation
studies confirm that the curriculum structure is the critical component for
this performance leap. By providing a scalable and effective training
methodology, CRUISE advances the development of autonomous systems for dynamic,
competitive tasks and serves as a blueprint for future real-world deployment.

</details>


### [201] [Analytical Swarm Chemistry: Characterization and Analysis of Emergent Swarm Behaviors](https://arxiv.org/abs/2510.22821)
*Ricardo Vega,Connor Mattson,Kevin Zhu,Daniel S. Brown,Cameron Nowzari*

Main category: cs.RO

TL;DR: 提出了分析性群体化学框架，将工程学、基于代理的研究和化学概念结合，通过宏观状态定义和相图分析系统探索群体参数如何影响涌现行为。


<details>
  <summary>Details</summary>
Motivation: 群体机器人学在现实世界部署稀少，因为难以预测简单局部交互产生的涌现行为。传统工程方法在理想条件下设计控制器，而基于代理的研究则自下而上探索涌现现象。

Method: 结合宏观状态定义与相图分析，将参数视为热力学变量，可视化参数空间中产生特定行为的区域。应用于具有最小可行能力的代理，识别产生特定行为的充分条件。

Result: 识别了产生铣削和扩散等行为的充分条件，发现了参数空间中可靠产生这些行为的区域。在真实机器人上的初步验证表明这些区域在实践中对应可观察的行为。

Conclusion: 该框架为现实世界群体系统中可预测和可靠的涌现行为奠定了基础，提供了有原则、可解释的方法。

Abstract: Swarm robotics has potential for a wide variety of applications, but
real-world deployments remain rare due to the difficulty of predicting emergent
behaviors arising from simple local interactions. Traditional engineering
approaches design controllers to achieve desired macroscopic outcomes under
idealized conditions, while agent-based and artificial life studies explore
emergent phenomena in a bottom-up, exploratory manner. In this work, we
introduce Analytical Swarm Chemistry, a framework that integrates concepts from
engineering, agent-based and artificial life research, and chemistry. This
framework combines macrostate definitions with phase diagram analysis to
systematically explore how swarm parameters influence emergent behavior.
Inspired by concepts from chemistry, the framework treats parameters like
thermodynamic variables, enabling visualization of regions in parameter space
that give rise to specific behaviors. Applying this framework to agents with
minimally viable capabilities, we identify sufficient conditions for behaviors
such as milling and diffusion and uncover regions of the parameter space that
reliably produce these behaviors. Preliminary validation on real robots
demonstrates that these regions correspond to observable behaviors in practice.
By providing a principled, interpretable approach, this framework lays the
groundwork for predictable and reliable emergent behavior in real-world swarm
systems.

</details>


### [202] [RoGER-SLAM: A Robust Gaussian Splatting SLAM System for Noisy and Low-light Environment Resilience](https://arxiv.org/abs/2510.22600)
*Huilin Yin,Zhaolin Yang,Linchuan Zhang,Gerhard Rigoll,Johannes Betz*

Main category: cs.RO

TL;DR: RoGER-SLAM是一个针对噪声和低光照环境的鲁棒3D高斯泼溅SLAM系统，通过结构保持融合机制、自适应跟踪目标和CLIP增强模块，在恶劣成像条件下显著提升轨迹精度和重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM在视觉输入受噪声和低光照影响时可靠性严重受限，现有的3DGS SLAM框架在干净条件下能实现高保真建图，但在复合退化环境下仍然脆弱。研究发现3DGS渲染管道本身具有隐式低通滤波器特性，会衰减高频噪声但可能导致过度平滑。

Method: 1. 结构保持鲁棒融合机制(SP-RoFusion)，耦合渲染的外观、深度和边缘线索；2. 带有残差平衡正则化的自适应跟踪目标；3. 基于CLIP的增强模块，在复合退化条件下选择性激活以恢复语义和结构保真度。

Result: 在Replica、TUM和真实世界序列上的综合实验表明，RoGER-SLAM相比其他3DGS-SLAM系统持续提升了轨迹精度和重建质量，特别是在恶劣成像条件下表现更优。

Conclusion: RoGER-SLAM通过创新的融合机制和增强模块，有效解决了3DGS SLAM在噪声和低光照环境中的脆弱性问题，为恶劣条件下的视觉SLAM提供了鲁棒解决方案。

Abstract: The reliability of Simultaneous Localization and Mapping (SLAM) is severely
constrained in environments where visual inputs suffer from noise and low
illumination. Although recent 3D Gaussian Splatting (3DGS) based SLAM
frameworks achieve high-fidelity mapping under clean conditions, they remain
vulnerable to compounded degradations that degrade mapping and tracking
performance. A key observation underlying our work is that the original 3DGS
rendering pipeline inherently behaves as an implicit low-pass filter,
attenuating high-frequency noise but also risking over-smoothing. Building on
this insight, we propose RoGER-SLAM, a robust 3DGS SLAM system tailored for
noise and low-light resilience. The framework integrates three innovations: a
Structure-Preserving Robust Fusion (SP-RoFusion) mechanism that couples
rendered appearance, depth, and edge cues; an adaptive tracking objective with
residual balancing regularization; and a Contrastive Language-Image Pretraining
(CLIP)-based enhancement module, selectively activated under compounded
degradations to restore semantic and structural fidelity. Comprehensive
experiments on Replica, TUM, and real-world sequences show that RoGER-SLAM
consistently improves trajectory accuracy and reconstruction quality compared
with other 3DGS-SLAM systems, especially under adverse imaging conditions.

</details>


### [203] [Never Too Rigid to Reach: Adaptive Virtual Model Control with LLM- and Lyapunov-Based Reinforcement Learning](https://arxiv.org/abs/2510.22892)
*Jingzehua Xu,Yangyang Li,Yangfei Chen,Guanwen Xie,Shuai Zhang*

Main category: cs.RO

TL;DR: 提出自适应虚拟模型控制方法，结合大语言模型和Lyapunov强化学习，在保持物理可解释性的同时实现稳定性保证的在线适应。


<details>
  <summary>Details</summary>
Motivation: 传统机器人控制方法在不确定环境中变得僵化和脆弱，虚拟模型控制虽然能实现柔顺行为，但依赖固定参数且虚拟组件间协调有限，限制了适应性和稳定性。

Method: 使用大语言模型提供结构化先验和高级推理以增强虚拟组件协调，结合Lyapunov强化学习强制执行理论稳定性约束，实现安全可靠的在线适应。

Result: 在7自由度Panda机械臂上的大量仿真表明，该方法在动态任务中有效平衡竞争目标，实现优越性能，突显了LLM指导和Lyapunov约束适应的协同效益。

Conclusion: 该方法成功解决了虚拟模型控制的局限性，通过LLM和Lyapunov强化学习的结合，在保持物理可解释性的同时实现了稳定性保证的自适应控制。

Abstract: Robotic arms are increasingly deployed in uncertain environments, yet
conventional control pipelines often become rigid and brittle when exposed to
perturbations or incomplete information. Virtual Model Control (VMC) enables
compliant behaviors by embedding virtual forces and mapping them into joint
torques, but its reliance on fixed parameters and limited coordination among
virtual components constrains adaptability and may undermine stability as task
objectives evolve. To address these limitations, we propose Adaptive VMC with
Large Language Model (LLM)- and Lyapunov-Based Reinforcement Learning (RL),
which preserves the physical interpretability of VMC while supporting
stability-guaranteed online adaptation. The LLM provides structured priors and
high-level reasoning that enhance coordination among virtual components,
improve sample efficiency, and facilitate flexible adjustment to varying task
requirements. Complementarily, Lyapunov-based RL enforces theoretical stability
constraints, ensuring safe and reliable adaptation under uncertainty. Extensive
simulations on a 7-DoF Panda arm demonstrate that our approach effectively
balances competing objectives in dynamic tasks, achieving superior performance
while highlighting the synergistic benefits of LLM guidance and
Lyapunov-constrained adaptation.

</details>


### [204] [Uncertainty-Aware Autonomous Vehicles: Predicting the Road Ahead](https://arxiv.org/abs/2510.22680)
*Shireen Kudukkil Manchingal,Armand Amaritei,Mihir Gohad,Maryam Sultana,Julian F. P. Kooij,Fabio Cuzzolin,Andrew Bradley*

Main category: cs.RO

TL;DR: 该研究将随机集神经网络（RS-NNs）集成到自动驾驶车辆感知系统中，通过显式量化预测不确定性来提高安全性，在不确定场景下动态调节车速。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶感知系统在面对罕见事件或样本外数据时容易产生过度自信的预测错误，需要让车辆能够'知道何时不确定'。

Method: 使用随机集神经网络作为不确定性感知图像分类器，预测类别集合的置信函数，与传统CNN和贝叶斯神经网络进行对比测试。

Result: RS-NN在各种道路条件下实现了显著更高的准确率和优越的不确定性校准，能够动态调节车辆速度以平衡性能与安全。

Conclusion: 不确定性感知神经网络，特别是RS-NNs，是提高自动驾驶安全性和鲁棒性的实用解决方案。

Abstract: Autonomous Vehicle (AV) perception systems have advanced rapidly in recent
years, providing vehicles with the ability to accurately interpret their
environment. Perception systems remain susceptible to errors caused by
overly-confident predictions in the case of rare events or out-of-sample data.
This study equips an autonomous vehicle with the ability to 'know when it is
uncertain', using an uncertainty-aware image classifier as part of the AV
software stack. Specifically, the study exploits the ability of Random-Set
Neural Networks (RS-NNs) to explicitly quantify prediction uncertainty. Unlike
traditional CNNs or Bayesian methods, RS-NNs predict belief functions over sets
of classes, allowing the system to identify and signal uncertainty clearly in
novel or ambiguous scenarios. The system is tested in a real-world autonomous
racing vehicle software stack, with the RS-NN classifying the layout of the
road ahead and providing the associated uncertainty of the prediction.
Performance of the RS-NN under a range of road conditions is compared against
traditional CNN and Bayesian neural networks, with the RS-NN achieving
significantly higher accuracy and superior uncertainty calibration. This
integration of RS-NNs into Robot Operating System (ROS)-based vehicle control
pipeline demonstrates that predictive uncertainty can dynamically modulate
vehicle speed, maintaining high-speed performance under confident predictions
while proactively improving safety through speed reductions in uncertain
scenarios. These results demonstrate the potential of uncertainty-aware neural
networks - in particular RS-NNs - as a practical solution for safer and more
robust autonomous driving.

</details>


### [205] [End-to-End Design and Validation of a Low-Cost Stewart Platform with Nonlinear Estimation and Control](https://arxiv.org/abs/2510.22949)
*Benedictus C. G. Cinun,Tua A. Tamba,Immanuel R. Santjoko,Xiaofeng Wang,Michael A. Gunarso,Bin Hu*

Main category: cs.RO

TL;DR: 本文介绍了一个低成本Stewart平台原型的设计、控制和实验验证，该平台结合现成组件与3D打印部件，实现了完整的六自由度运动控制，并通过集成动态建模、数据采集和实时控制的统一软件框架进行验证。


<details>
  <summary>Details</summary>
Motivation: 开发一个既经济实惠又功能强大的机器人测试平台，用于研究和教育目的，克服以往研究仅关注建模或控制等孤立方面的局限性。

Method: 采用现成组件与3D打印定制部件相结合的方式构建硬件平台；软件集成动态建模、数据采集和实时控制；使用基于反馈线性化的鲁棒轨迹跟踪控制器，并辅以LQR方案补偿非线性动力学；通过扩展卡尔曼滤波器融合IMU和执行器编码器反馈进行状态估计。

Result: 在静态和动态轨迹的仿真和实验中验证了平台的有效性，展示了良好的轨迹跟踪性能和实时状态估计能力。

Conclusion: 该平台被证明是一个成本效益高且多功能的工具，具有在高级研究和教育应用中发挥重要作用的潜力。

Abstract: This paper presents the complete design, control, and experimental validation
of a low-cost Stewart platform prototype developed as an affordable yet capable
robotic testbed for research and education. The platform combines off the shelf
components with 3D printed and custom fabricated parts to deliver full six
degrees of freedom motions using six linear actuators connecting a moving
platform to a fixed base. The system software integrates dynamic modeling, data
acquisition, and real time control within a unified framework. A robust
trajectory tracking controller based on feedback linearization, augmented with
an LQR scheme, compensates for the platform's nonlinear dynamics to achieve
precise motion control. In parallel, an Extended Kalman Filter fuses IMU and
actuator encoder feedback to provide accurate and reliable state estimation
under sensor noise and external disturbances. Unlike prior efforts that
emphasize only isolated aspects such as modeling or control, this work delivers
a complete hardware-software platform validated through both simulation and
experiments on static and dynamic trajectories. Results demonstrate effective
trajectory tracking and real-time state estimation, highlighting the platform's
potential as a cost effective and versatile tool for advanced research and
educational applications.

</details>


### [206] [RL-AVIST: Reinforcement Learning for Autonomous Visual Inspection of Space Targets](https://arxiv.org/abs/2510.22699)
*Matteo El-Hariry,Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: RL-AVIST：基于强化学习的自主空间目标视觉检测框架，使用DreamerV3算法在6-DOF航天器动力学模拟中训练智能体，实现3D接近机动任务


<details>
  <summary>Details</summary>
Motivation: 传统控制系统在模型不确定性、多航天器配置或动态任务环境下适应性不足，需要智能航天器执行轨道检查、维护等自主服务

Method: 利用Space Robotics Bench模拟高保真6-DOF航天器动力学，使用DreamerV3模型强化学习算法，PPO和TD3作为无模型基线，训练通用和专用智能体

Result: 基于模型的强化学习在轨迹保真度和样本效率方面表现出色，策略在多种航天器形态和任务领域具有鲁棒性和泛化能力

Conclusion: 模型强化学习为未来空间操作提供了可扩展、可重训练的控制解决方案

Abstract: The growing need for autonomous on-orbit services such as inspection,
maintenance, and situational awareness calls for intelligent spacecraft capable
of complex maneuvers around large orbital targets. Traditional control systems
often fall short in adaptability, especially under model uncertainties,
multi-spacecraft configurations, or dynamically evolving mission contexts. This
paper introduces RL-AVIST, a Reinforcement Learning framework for Autonomous
Visual Inspection of Space Targets. Leveraging the Space Robotics Bench (SRB),
we simulate high-fidelity 6-DOF spacecraft dynamics and train agents using
DreamerV3, a state-of-the-art model-based RL algorithm, with PPO and TD3 as
model-free baselines. Our investigation focuses on 3D proximity maneuvering
tasks around targets such as the Lunar Gateway and other space assets. We
evaluate task performance under two complementary regimes: generalized agents
trained on randomized velocity vectors, and specialized agents trained to
follow fixed trajectories emulating known inspection orbits. Furthermore, we
assess the robustness and generalization of policies across multiple spacecraft
morphologies and mission domains. Results demonstrate that model-based RL
offers promising capabilities in trajectory fidelity, and sample efficiency,
paving the way for scalable, retrainable control solutions for future space
operations

</details>


### [207] [An Intelligent Water-Saving Irrigation System Based on Multi-Sensor Fusion and Visual Servoing Control](https://arxiv.org/abs/2510.23003)
*ZhengKai Huang,YiKun Wang,ChenYu Hui,XiaoCheng*

Main category: cs.RO

TL;DR: 开发了一个智能节水灌溉系统，通过计算机视觉、机器人控制和实时稳定技术，实现精准灌溉，在三种模拟农业环境中比传统漫灌节水30-50%，用水效率超过92%。


<details>
  <summary>Details</summary>
Motivation: 解决精准农业中的水资源浪费和地形适应性差等关键挑战，提高灌溉效率和水资源利用率。

Method: 采用多传感器融合方法，集成轻量级YOLO模型进行实时植物容器检测（准确率>96%），简化手眼标定算法实现末端执行器精确定位（成功率>90%），以及基于STM32F103ZET6和JY901S惯性测量的主动调平系统。

Result: 在标准温室、丘陵地形和复杂光照三种模拟环境中，系统能稳定在10度斜坡上作业（响应时间1.8秒），相比传统漫灌节水30-50%，所有测试案例的用水效率均超过92%。

Conclusion: 该系统通过先进技术集成有效解决了精准农业中的水资源管理问题，显著提高了灌溉效率和地形适应性，具有实际应用价值。

Abstract: This paper introduces an intelligent water-saving irrigation system designed
to address critical challenges in precision agriculture, such as inefficient
water use and poor terrain adaptability. The system integrates advanced
computer vision, robotic control, and real-time stabilization technologies via
a multi-sensor fusion approach. A lightweight YOLO model, deployed on an
embedded vision processor (K210), enables real-time plant container detection
with over 96% accuracy under varying lighting conditions. A simplified hand-eye
calibration algorithm-designed for 'handheld camera' robot arm
configurations-ensures that the end effector can be precisely positioned, with
a success rate exceeding 90%. The active leveling system, driven by the
STM32F103ZET6 main control chip and JY901S inertial measurement data, can
stabilize the irrigation platform on slopes up to 10 degrees, with a response
time of 1.8 seconds. Experimental results across three simulated agricultural
environments (standard greenhouse, hilly terrain, complex lighting) demonstrate
a 30-50% reduction in water consumption compared to conventional flood
irrigation, with water use efficiency exceeding 92% in all test cases.

</details>


### [208] [SCAL for Pinch-Lifting: Complementary Rotational and Linear Prototypes for Environment-Adaptive Grasping](https://arxiv.org/abs/2510.22738)
*Wentao Guo,Wenzeng Zhang*

Main category: cs.RO

TL;DR: 提出了两种基于槽约束自适应连杆(SCAL)的环境自适应夹持手指：SCAL-R（旋转驱动，接触后向内折叠形成包络）和SCAL-L（线性驱动，接触时被动张开以抓取宽或弱特征物体），实现了无需复杂传感和控制的薄型物体夹持提升。


<details>
  <summary>Details</summary>
Motivation: 解决传统夹持器在处理薄型、低轮廓物体时需要复杂传感和控制的问题，开发能够自适应环境、简化操作的夹持方案。

Method: 设计两种互补的SCAL手指：SCAL-R采用旋转驱动和主动指尖折叠机制，SCAL-L采用线性驱动和被动张开机制。通过3D打印制造两指夹持器，并进行实验验证。

Result: 在数十次试验中，两种设计均能稳定抓取小零件、盒子、罐子和胶带卷等物体，且只需有限调优。准静态分析提供了指尖力模型，为设计和操作提供几何感知指导。

Conclusion: 两种设计具有互补的工作机制，为使用简单驱动实现鲁棒的环境自适应抓取提供了实用路径。

Abstract: This paper presents environment-adaptive pinch-lifting built on a
slot-constrained adaptive linkage (SCAL) and instantiated in two complementary
fingers: SCAL-R, a rotational-drive design with an active fingertip that folds
inward after contact to form an envelope, and SCAL-L, a linear-drive design
that passively opens on contact to span wide or weak-feature objects. Both
fingers convert surface following into an upward lifting branch while
maintaining fingertip orientation, enabling thin or low-profile targets to be
raised from supports with minimal sensing and control. Two-finger grippers are
fabricated via PLA-based 3D printing. Experiments evaluate (i)
contact-preserving sliding and pinch-lifting on tabletops, (ii) ramp
negotiation followed by lift, and (iii) handling of bulky objects via active
enveloping (SCAL-R) or contact-triggered passive opening (SCAL-L). Across
dozens of trials on small parts, boxes, jars, and tape rolls, both designs
achieve consistent grasps with limited tuning. A quasi-static analysis provides
closed-form fingertip-force models for linear parallel pinching and two-point
enveloping, offering geometry-aware guidance for design and operation. Overall,
the results indicate complementary operating regimes and a practical path to
robust, environment-adaptive grasping with simple actuation.

</details>


### [209] [Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot Navigation](https://arxiv.org/abs/2510.23057)
*Oskar Natan,Jun Miura*

Main category: cs.RO

TL;DR: Seq-DeepIPC是一个用于腿式机器人导航的序列化端到端感知-控制模型，整合多模态感知（RGB-D+GNSS）与时间融合，在边缘设备上高效部署，并在真实环境中验证了性能。


<details>
  <summary>Details</summary>
Motivation: 将端到端导航从轮式机器人扩展到更通用的腿式机器人系统，通过时序感知提升导航性能，同时解决边缘设备部署的计算效率问题。

Method: 使用EfficientNet-B0编码器减少计算量，联合预测语义分割和深度估计，通过连续GNSS位置计算航向角替代噪声IMU，收集包含道路和草地地形的多样化数据集。

Result: 在机器人狗上验证，序列化输入提升了感知和控制性能，模型大小合理且结果具有竞争力，GNSS航向在开阔区域稳定但在高楼附近可靠性较低。

Conclusion: Seq-DeepIPC成功将端到端导航扩展到腿式机器人，实现了时序感知的通用系统，为未来研究提供了开源代码支持。

Abstract: We present Seq-DeepIPC, a sequential end-to-end perception-to-control model
for legged robot navigation in realworld environments. Seq-DeepIPC advances
intelligent sensing for autonomous legged navigation by tightly integrating
multi-modal perception (RGB-D + GNSS) with temporal fusion and control. The
model jointly predicts semantic segmentation and depth estimation, giving
richer spatial features for planning and control. For efficient deployment on
edge devices, we use EfficientNet-B0 as the encoder, reducing computation while
maintaining accuracy. Heading estimation is simplified by removing the noisy
IMU and instead computing the bearing angle directly from consecutive GNSS
positions. We collected a larger and more diverse dataset that includes both
road and grass terrains, and validated Seq-DeepIPC on a robot dog. Comparative
and ablation studies show that sequential inputs improve perception and control
in our models, while other baselines do not benefit. Seq-DeepIPC achieves
competitive or better results with reasonable model size; although GNSS-only
heading is less reliable near tall buildings, it is robust in open areas.
Overall, Seq-DeepIPC extends end-to-end navigation beyond wheeled robots to
more versatile and temporally-aware systems. To support future research, we
will release the codes to our GitHub repository at
https://github.com/oskarnatan/Seq-DeepIPC.

</details>


### [210] [Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM](https://arxiv.org/abs/2510.22740)
*Sai Krishna Ghanta,Ramviyas Parasuraman*

Main category: cs.RO

TL;DR: 提出基于多智能体强化学习(MARL)的分布式位姿图优化框架，通过图神经网络编码器和混合策略实现高效的位姿优化，相比现有方法减少37.5%全局目标函数值，推理效率提升6倍以上。


<details>
  <summary>Details</summary>
Motivation: 传统迭代方法线性化高度非凸优化目标，需要重复求解正规方程，容易收敛到局部极小值产生次优估计。需要开发可扩展、鲁棒的分布式位姿图优化方法。

Method: 将分布式PGO建模为部分可观测马尔可夫博弈，使用图分割器分解全局位姿图，每个机器人运行带自适应边门控的循环图神经网络编码器去噪，通过混合策略顺序优化位姿，最后使用共识方案协调机器人间差异。

Result: 在合成和真实数据集上的评估显示，MARL智能体相比最先进的分布式PGO框架平均减少37.5%全局目标函数值，推理效率提升至少6倍，且单学习策略可扩展到更大机器人团队无需重新训练。

Conclusion: 提出的MARL框架在分布式位姿图优化中表现出色，显著提升精度和效率，具有良好的可扩展性和鲁棒性。

Abstract: We consider the distributed pose-graph optimization (PGO) problem, which is
fundamental in accurate trajectory estimation in multi-robot simultaneous
localization and mapping (SLAM). Conventional iterative approaches linearize a
highly non-convex optimization objective, requiring repeated solving of normal
equations, which often converge to local minima and thus produce suboptimal
estimates. We propose a scalable, outlier-robust distributed planar PGO
framework using Multi-Agent Reinforcement Learning (MARL). We cast distributed
PGO as a partially observable Markov game defined on local pose-graphs, where
each action refines a single edge's pose estimate. A graph partitioner
decomposes the global pose graph, and each robot runs a recurrent
edge-conditioned Graph Neural Network (GNN) encoder with adaptive edge-gating
to denoise noisy edges. Robots sequentially refine poses through a hybrid
policy that utilizes prior action memory and graph embeddings. After local
graph correction, a consensus scheme reconciles inter-robot disagreements to
produce a globally consistent estimate. Our extensive evaluations on a
comprehensive suite of synthetic and real-world datasets demonstrate that our
learned MARL-based actors reduce the global objective by an average of 37.5%
more than the state-of-the-art distributed PGO framework, while enhancing
inference efficiency by at least 6X. We also demonstrate that actor replication
allows a single learned policy to scale effortlessly to substantially larger
robot teams without any retraining. Code is publicly available at
https://github.com/herolab-uga/policies-over-poses.

</details>


### [211] [Combining High Level Scheduling and Low Level Control to Manage Fleets of Mobile Robots](https://arxiv.org/abs/2510.23129)
*Sabino Francesco Roselli,Ze Zhang,Knut Åkesson*

Main category: cs.RO

TL;DR: 提出一个用于工业环境中大规模机器人车队协调的两层框架，结合高层调度和底层控制，确保安全无碰撞操作并支持快速重调度。


<details>
  <summary>Details</summary>
Motivation: 工业环境中移动机器人的物料搬运需要在大规模动态环境中进行可扩展的协调，应对机器人故障和环境变化等干扰。

Method: 使用ComSat算法进行任务分配和调度，生成时间参数化路线，然后通过分布式模型预测控制（MPC）系统实时计算局部参考轨迹，考虑静态和动态障碍物。

Result: 在模拟2D环境中评估，展示了高任务完成率和在拥堵情况下的鲁棒行为。

Conclusion: 该框架的模块化结构实现了计算可处理性和灵活性，适用于复杂现实工业场景的部署。

Abstract: The deployment of mobile robots for material handling in industrial
environments requires scalable coordination of large fleets in dynamic
settings. This paper presents a two-layer framework that combines high-level
scheduling with low-level control. Tasks are assigned and scheduled using the
compositional algorithm ComSat, which generates time-parameterized routes for
each robot. These schedules are then used by a distributed Model Predictive
Control (MPC) system in real time to compute local reference trajectories,
accounting for static and dynamic obstacles. The approach ensures safe,
collision-free operation, and supports rapid rescheduling in response to
disruptions such as robot failures or environmental changes. We evaluate the
method in simulated 2D environments with varying road capacities and traffic
conditions, demonstrating high task completion rates and robust behavior even
under congestion. The modular structure of the framework allows for
computational tractability and flexibility, making it suitable for deployment
in complex, real-world industrial scenarios.

</details>


### [212] [TWC-SLAM: Multi-Agent Cooperative SLAM with Text Semantics and WiFi Features Integration for Similar Indoor Environments](https://arxiv.org/abs/2510.22754)
*Chunyu Li,Shoubin Chen,Dong Li,Weixing Xue,Qingquan Li*

Main category: cs.RO

TL;DR: TWC-SLAM是一个多智能体协同SLAM框架，通过整合文本语义和WiFi信号特征来增强位置识别和闭环检测，特别适用于具有重复结构的室内环境。


<details>
  <summary>Details</summary>
Motivation: 在具有重复结构（如走廊和房间）的相似室内环境中，基于点云的多智能体协同SLAM方法在共享位置识别方面存在显著不准确性。

Method: TWC-SLAM包含基于FAST-LIO2的单智能体前端里程计模块、利用文本语义和WiFi特征的位置识别与闭环检测模块，以及全局建图模块。智能体配备能够捕获文本信息和检测WiFi信号的传感器。

Result: 在具有相似走廊、房间和文本标志的室内数据集上的评估结果表明，TWC-SLAM显著提高了在具有重复建筑特征的复杂环境中协同SLAM系统的性能。

Conclusion: 通过关联文本语义和WiFi信号数据源，TWC-SLAM能够建立共同位置，促进不同智能体地图之间的点云对齐，并通过闭环检测和优化模块实现全局优化和一致性建图。

Abstract: Multi-agent cooperative SLAM often encounters challenges in similar indoor
environments characterized by repetitive structures, such as corridors and
rooms. These challenges can lead to significant inaccuracies in shared location
identification when employing point cloud-based techniques. To mitigate these
issues, we introduce TWC-SLAM, a multi-agent cooperative SLAM framework that
integrates text semantics and WiFi signal features to enhance location
identification and loop closure detection. TWC-SLAM comprises a single-agent
front-end odometry module based on FAST-LIO2, a location identification and
loop closure detection module that leverages text semantics and WiFi features,
and a global mapping module. The agents are equipped with sensors capable of
capturing textual information and detecting WiFi signals. By correlating these
data sources, TWC-SLAM establishes a common location, facilitating point cloud
alignment across different agents' maps. Furthermore, the system employs loop
closure detection and optimization modules to achieve global optimization and
cohesive mapping. We evaluated our approach using an indoor dataset featuring
similar corridors, rooms, and text signs. The results demonstrate that TWC-SLAM
significantly improves the performance of cooperative SLAM systems in complex
environments with repetitive architectural features.

</details>


### [213] [PIP-LLM: Integrating PDDL-Integer Programming with LLMs for Coordinating Multi-Robot Teams Using Natural Language](https://arxiv.org/abs/2510.22784)
*Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: PIP-LLM是一个基于语言的多机器人协调框架，通过PDDL团队级规划和整数规划机器人级规划的结合，解决了多机器人协调中的任务分解、可扩展性和协调效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM和PDDL的方法在单机器人场景中表现良好，但在多机器人协调中存在任务分解脆弱、可扩展性差和协调效率低的问题。

Method: PIP-LLM采用两级规划：首先将自然语言指令转换为团队级PDDL问题并求解，获得抽象的任务计划；然后将该计划转换为依赖图，指导机器人级的整数规划任务分配，优化旅行成本和工作负载。

Result: 实验表明，PIP-LLM在多种任务中提高了计划成功率，降低了最大和平均旅行成本，并实现了更好的负载均衡。

Conclusion: PIP-LLM通过将规划与分配分离，避免了基于语法分解的缺陷，能够扩展到更大的团队规模，是多机器人协调的有效解决方案。

Abstract: Enabling robot teams to execute natural language commands requires
translating high-level instructions into feasible, efficient multi-robot plans.
While Large Language Models (LLMs) combined with Planning Domain Description
Language (PDDL) offer promise for single-robot scenarios, existing approaches
struggle with multi-robot coordination due to brittle task decomposition, poor
scalability, and low coordination efficiency.
  We introduce PIP-LLM, a language-based coordination framework that consists
of PDDL-based team-level planning and Integer Programming (IP) based
robot-level planning. PIP-LLMs first decomposes the command by translating the
command into a team-level PDDL problem and solves it to obtain a team-level
plan, abstracting away robot assignment. Each team-level action represents a
subtask to be finished by the team. Next, this plan is translated into a
dependency graph representing the subtasks' dependency structure. Such a
dependency graph is then used to guide the robot-level planning, in which each
subtask node will be formulated as an IP-based task allocation problem,
explicitly optimizing travel costs and workload while respecting robot
capabilities and user-defined constraints. This separation of planning from
assignment allows PIP-LLM to avoid the pitfalls of syntax-based decomposition
and scale to larger teams. Experiments across diverse tasks show that PIP-LLM
improves plan success rate, reduces maximum and average travel costs, and
achieves better load balancing compared to state-of-the-art baselines.

</details>


### [214] [Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning](https://arxiv.org/abs/2510.22789)
*Abhijeet M. Kulkarni,Ioannis Poulakakis,Guoquan Huang*

Main category: cs.RO

TL;DR: 提出了一种基于学习的观测器-预测器框架，用于准确预测四足机器人的全身运动，解决了简化运动学模型无法捕捉复杂闭环动力学的问题。


<details>
  <summary>Details</summary>
Motivation: 准确的全身运动预测对于四足机器人的安全自主导航至关重要，特别是在复杂环境中进行肢体级碰撞检测。现有简化运动学模型无法捕捉机器人和底层控制器的复杂闭环动力学。

Method: 采用学习型观测器-预测器框架，包含具有可证明UUB保证的神经观测器，从本体感知测量历史提供可靠的潜在状态估计，然后初始化计算高效的预测器进行轨迹评估。

Result: 在Vision 60四足机器人上集成神经预测器到MPPI规划器中，硬件实验成功展示了在挑战性狭窄通道和小物体上的有效肢体感知运动规划。

Conclusion: 该系统为动态机器人平台上的高性能碰撞感知规划提供了稳健基础，能够实现有效的肢体感知运动规划。

Abstract: Accurate full-body motion prediction is essential for the safe, autonomous
navigation of legged robots, enabling critical capabilities like limb-level
collision checking in cluttered environments. Simplified kinematic models often
fail to capture the complex, closed-loop dynamics of the robot and its
low-level controller, limiting their predictions to simple planar motion. To
address this, we present a learning-based observer-predictor framework that
accurately predicts this motion. Our method features a neural observer with
provable UUB guarantees that provides a reliable latent state estimate from a
history of proprioceptive measurements. This stable estimate initializes a
computationally efficient predictor, designed for the rapid, parallel
evaluation of thousands of potential trajectories required by modern
sampling-based planners. We validated the system by integrating our neural
predictor into an MPPI-based planner on a Vision 60 quadruped. Hardware
experiments successfully demonstrated effective, limb-aware motion planning in
a challenging, narrow passage and over small objects, highlighting our system's
ability to provide a robust foundation for high-performance, collision-aware
planning on dynamic robotic platforms.

</details>


### [215] [Kinematically Controllable Cable Robots with Reconfigurable End-effectors](https://arxiv.org/abs/2510.22825)
*Nan Zhang*

Main category: cs.RO

TL;DR: 设计可重构末端执行器，通过弹簧、螺旋槽轴和螺母将线性运动转换为旋转运动，扩展缆绳机器人的旋转工作空间，同时引入轴承提供额外旋转自由度，使机构非冗余，实现纯运动学控制。


<details>
  <summary>Details</summary>
Motivation: 增加缆绳数量以扩大平移工作空间会带来两个问题：缆绳干涉显著减少旋转工作空间，以及缆绳张力解不唯一导致运动控制困难。

Method: 设计结构简单的可重构末端执行器，包含弹簧、螺旋槽轴和匹配螺母，将末端执行器组件间的相对线性运动转换为相对旋转运动，并引入轴承提供额外旋转自由度。

Result: 扩展了机构的旋转工作空间，使机构非冗余，机器人运动可通过纯运动学控制，无需额外的张力传感和控制。

Conclusion: 所提出的可重构末端执行器设计有效解决了缆绳机器人因增加缆绳数量而导致的旋转工作空间缩小和控制困难问题，实现了更简单可靠的运动控制。

Abstract: To enlarge the translational workspace of cable-driven robots, one common
approach is to increase the number of cables. However, this introduces two
challenges: (1) cable interference significantly reduces the rotational
workspace, and (2) the solution of tensions in cables becomes non-unique,
resulting in difficulties for kinematic control of the robot. In this work, we
design structurally simple reconfigurable end-effectors for cable robots. By
incorporating a spring, a helical-grooved shaft, and a matching nut, relative
linear motions between end-effector components are converted into relative
rotations, thereby expanding the rotational workspace of the mechanism.
Meanwhile, a bearing is introduced to provide an additional rotational degree
of freedom, making the mechanism non-redundant. As a result, the robot's motion
can be controlled purely through kinematics without additional tension sensing
and control.

</details>


### [216] [HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment](https://arxiv.org/abs/2510.22917)
*Zecheng Yin,Hao Zhao,Zhen Li*

Main category: cs.RO

TL;DR: 提出HyPerNav方法，利用视觉语言模型联合感知局部和全局信息，在未知环境中实现目标导向导航的SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有研究大多只关注单一感知源（RGB-D传感器或俯视图），很少整合这两种互补的感知模态，而人类天然会同时关注局部和全局信息

Method: 利用视觉语言模型的强大推理和视觉语言理解能力，联合感知局部（RGB-D传感器）和全局（实时俯视图）信息，提出混合感知导航方法HyPerNav

Result: 在大规模仿真评估和真实世界验证中，该方法相比流行基线实现了最先进的性能，混合感知方法能够捕获更丰富的线索并更有效地找到目标物体

Conclusion: 混合感知方法通过同时利用第一人称观察和俯视图的信息理解，显著提升了导航性能，消融研究进一步证明混合感知的每个组成部分都对导航性能有贡献

Abstract: Objective-oriented navigation(ObjNav) enables robot to navigate to target
object directly and autonomously in an unknown environment. Effective
perception in navigation in unknown environment is critical for autonomous
robots. While egocentric observations from RGB-D sensors provide abundant local
information, real-time top-down maps offer valuable global context for ObjNav.
Nevertheless, the majority of existing studies focus on a single source, seldom
integrating these two complementary perceptual modalities, despite the fact
that humans naturally attend to both. With the rapid advancement of
Vision-Language Models(VLMs), we propose Hybrid Perception Navigation
(HyPerNav), leveraging VLMs' strong reasoning and vision-language understanding
capabilities to jointly perceive both local and global information to enhance
the effectiveness and intelligence of navigation in unknown environments. In
both massive simulation evaluation and real-world validation, our methods
achieved state-of-the-art performance against popular baselines. Benefiting
from hybrid perception approach, our method captures richer cues and finds the
objects more effectively, by simultaneously leveraging information
understanding from egocentric observations and the top-down map. Our ablation
study further proved that either of the hybrid perception contributes to the
navigation performance.

</details>


### [217] [ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation](https://arxiv.org/abs/2510.23016)
*Zhuo Li,Junjia Liu,Dianxi Li,Tao Teng,Miao Li,Sylvain Calinon,Darwin Caldwell,Fei Chen*

Main category: cs.RO

TL;DR: 提出ManiDP方法，通过提取双手机器人的可操作性特征并融入扩散模型，优化双臂配置以满足姿势相关的任务需求，在6个真实世界任务中平均成功率提升39.33%。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了姿势相关任务特征的学习，而这些特征对于适应双臂配置以满足灵巧双手操作中的特定力和速度要求至关重要。

Method: 从专家演示中提取双手可操作性，使用黎曼概率模型编码姿势特征，并将其融入条件扩散过程来生成任务兼容的双手运动序列。

Result: 在6个真实世界双手任务中，平均操作成功率提高39.33%，任务兼容性提升0.45，优于基线方法。

Conclusion: 将姿势相关的机器人先验知识整合到双手技能扩散中，能够实现类人的适应性和灵巧性。

Abstract: Recent work has demonstrated the potential of diffusion models in robot
bimanual skill learning. However, existing methods ignore the learning of
posture-dependent task features, which are crucial for adapting dual-arm
configurations to meet specific force and velocity requirements in dexterous
bimanual manipulation. To address this limitation, we propose
Manipulability-Aware Diffusion Policy (ManiDP), a novel imitation learning
method that not only generates plausible bimanual trajectories, but also
optimizes dual-arm configurations to better satisfy posture-dependent task
requirements. ManiDP achieves this by extracting bimanual manipulability from
expert demonstrations and encoding the encapsulated posture features using
Riemannian-based probabilistic models. These encoded posture features are then
incorporated into a conditional diffusion process to guide the generation of
task-compatible bimanual motion sequences. We evaluate ManiDP on six real-world
bimanual tasks, where the experimental results demonstrate a 39.33$\%$ increase
in average manipulation success rate and a 0.45 improvement in task
compatibility compared to baseline methods. This work highlights the importance
of integrating posture-relevant robotic priors into bimanual skill diffusion to
enable human-like adaptability and dexterity.

</details>


### [218] [Awakening Facial Emotional Expressions in Human-Robot](https://arxiv.org/abs/2510.23059)
*Yongtong Zhu,Lei Li,Iggy Qian,WenBin Zhou,Ye Yuan,Qingdu Li,Na Liu,Jianwei Zhang*

Main category: cs.RO

TL;DR: 提出了基于KAN和注意力机制的端到端学习框架，使人形社交机器人能够通过自训练学习人类表情，实现准确多样的面部模仿。


<details>
  <summary>Details</summary>
Motivation: 解决人形社交机器人面部表情生成依赖预编程行为模式的问题，降低人工编码成本，让机器人能够自主获取泛化的表达能力。

Method: 设计高度仿生的机器人面部系统，开发基于KAN和注意力机制的端到端学习框架，并构建首个开源的人形社交机器人面部数据集。

Result: 综合评估表明，该方法在不同测试对象上实现了准确多样的面部模仿能力。

Conclusion: 该研究为人形社交机器人提供了自主学习和表达人类表情的有效解决方案，推动了自然化人机交互的发展。

Abstract: The facial expression generation capability of humanoid social robots is
critical for achieving natural and human-like interactions, playing a vital
role in enhancing the fluidity of human-robot interactions and the accuracy of
emotional expression. Currently, facial expression generation in humanoid
social robots still relies on pre-programmed behavioral patterns, which are
manually coded at high human and time costs. To enable humanoid robots to
autonomously acquire generalized expressive capabilities, they need to develop
the ability to learn human-like expressions through self-training. To address
this challenge, we have designed a highly biomimetic robotic face with
physical-electronic animated facial units and developed an end-to-end learning
framework based on KAN (Kolmogorov-Arnold Network) and attention mechanisms.
Unlike previous humanoid social robots, we have also meticulously designed an
automated data collection system based on expert strategies of facial motion
primitives to construct the dataset. Notably, to the best of our knowledge,
this is the first open-source facial dataset for humanoid social robots.
Comprehensive evaluations indicate that our approach achieves accurate and
diverse facial mimicry across different test subjects.

</details>


### [219] [Breaking the Circle: An Autonomous Control-Switching Strategy for Stable Orographic Soaring in MAVs](https://arxiv.org/abs/2510.23084)
*Sunyou Hwang,Christophe De Wagter,Bart Remes,Guido de Croon*

Main category: cs.RO

TL;DR: 提出SAOS控制切换方法，通过选择性控制水平或垂直轴来减轻滑翔中的盘旋行为，将系统从欠驱动转变为全驱动状态，提高能量效率和飞行稳定性。


<details>
  <summary>Details</summary>
Motivation: 地形滑翔可显著延长微型飞行器续航时间，但盘旋行为会增加能耗和发散风险，需要解决控制冲突问题。

Method: 采用控制切换方法SAOS，在滑翔时选择性控制水平或垂直轴，并在INDI控制器中加入攻角以改进力估计。

Result: 仿真和风洞实验表明，SAOS改善了位置收敛，减少了油门使用，减轻了俯仰-滚转耦合引起的滚转振荡。

Conclusion: SAOS方法在受限滑翔环境中提高了能量效率和飞行稳定性。

Abstract: Orographic soaring can significantly extend the endurance of micro aerial
vehicles (MAVs), but circling behavior, arising from control conflicts between
the longitudinal and vertical axes, increases energy consumption and the risk
of divergence. We propose a control switching method, named SAOS: Switched
Control for Autonomous Orographic Soaring, which mitigates circling behavior by
selectively controlling either the horizontal or vertical axis, effectively
transforming the system from underactuated to fully actuated during soaring.
Additionally, the angle of attack is incorporated into the INDI controller to
improve force estimation. Simulations with randomized initial positions and
wind tunnel experiments on two MAVs demonstrate that the SAOS improves position
convergence, reduces throttle usage, and mitigates roll oscillations caused by
pitch-roll coupling. These improvements enhance energy efficiency and flight
stability in constrained soaring environments.

</details>


### [220] [An Automated Tape Laying System Employing a Uniaxial Force Control Device](https://arxiv.org/abs/2510.23109)
*Bernhard Rameder,Hubert Gattringer,Ronald Naderer,Andreas Mueller*

Main category: cs.RO

TL;DR: 设计了一种具有集成单轴力控制和精确温度控制的成本效益型自动铺带系统，用于确保适当的压实力和胶带熔化温度，并通过特殊机器人控制概念处理复杂形状。


<details>
  <summary>Details</summary>
Motivation: 需要控制基板和胶带在特定温度水平，以确保产品不同层之间的最佳固结，同时处理紧凑和复杂形状的铺带需求。

Method: 系统包含胶带存储卷轴、导向辊、处理单元、加热区和固结单元等多个模块，采用固定铺带装置、移动模具的机器人控制概念。

Result: 使用碳纤维增强HDPE胶带进行实验验证，系统各子系统和铺带过程功能得到确认。

Conclusion: 该成本效益型自动铺带系统能够有效控制压实力和温度，适用于处理复杂形状的复合材料铺带工艺。

Abstract: This paper deals with the design of a cost effective automated tape laying
system (ATL system) with integrated uniaxial force control to ensure the
necessary compaction forces as well as with an accurate temperature control to
guarantee the used tape being melted appropriate. It is crucial to control the
substrate and the oncoming tape onto a specific temperature level to ensure an
optimal consolidation between the different layers of the product. Therefore,
it takes several process steps from the spooled tape on the coil until it is
finally tacked onto the desired mold. The different modules are divided into
the tape storage spool, a tape-guiding roller, a tape processing unit, a
heating zone and the consolidation unit. Moreover, a special robot control
concept for testing the ATL system is presented. In contrast to many other
systems, with this approach, the tape laying device is spatially fixed and the
shape is moved accordingly by the robot, which allows for handling of rather
compact and complex shapes. The functionality of the subsystems and the taping
process itself was finally approved in experimental results using a carbon
fiber reinforced HDPE tape.

</details>


### [221] [OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback](https://arxiv.org/abs/2510.23119)
*Yi-Lin Wei,Zhexi Luo,Yuhao Lin,Mu Lin,Zhizhao Liang,Shuoyu Chen,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: OmniDexGrasp是一个通用框架，通过结合基础模型与传输控制策略，实现用户提示、灵巧体现和抓取任务的全能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法由于语义灵巧抓取数据集规模有限，难以在不同物体或任务间泛化。基础模型提供了增强泛化的新途径，但直接利用它们生成可行的机器人动作仍存在挑战。

Method: 集成三个关键模块：(i)使用基础模型生成支持全能力用户提示和任务的人类抓取图像；(ii)人类图像到机器人动作传输策略将人类演示转换为可执行的机器人动作；(iii)力感知自适应抓取策略确保稳健稳定的抓取执行。

Result: 仿真和真实机器人实验验证了OmniDexGrasp在不同用户提示、抓取任务和灵巧手上的有效性，并显示其在灵巧操作任务上的可扩展性。

Conclusion: OmniDexGrasp通过结合基础模型与传输控制策略，成功解决了灵巧抓取和操作的泛化问题，为机器人灵巧操作提供了有效的解决方案。

Abstract: Enabling robots to dexterously grasp and manipulate objects based on human
commands is a promising direction in robotics. However, existing approaches are
challenging to generalize across diverse objects or tasks due to the limited
scale of semantic dexterous grasp datasets. Foundation models offer a new way
to enhance generalization, yet directly leveraging them to generate feasible
robotic actions remains challenging due to the gap between abstract model
knowledge and physical robot execution. To address these challenges, we propose
OmniDexGrasp, a generalizable framework that achieves omni-capabilities in user
prompting, dexterous embodiment, and grasping tasks by combining foundation
models with the transfer and control strategies. OmniDexGrasp integrates three
key modules: (i) foundation models are used to enhance generalization by
generating human grasp images supporting omni-capability of user prompt and
task; (ii) a human-image-to-robot-action transfer strategy converts human
demonstrations into executable robot actions, enabling omni dexterous
embodiment; (iii) force-aware adaptive grasp strategy ensures robust and stable
grasp execution. Experiments in simulation and on real robots validate the
effectiveness of OmniDexGrasp on diverse user prompts, grasp task and dexterous
hands, and further results show its extensibility to dexterous manipulation
tasks.

</details>


### [222] [Reliable Robotic Task Execution in the Face of Anomalies](https://arxiv.org/abs/2510.23121)
*Bharath Santhanam,Alex Mitrevski,Santosh Thoduka,Sebastian Houben,Teena Hassan*

Main category: cs.RO

TL;DR: 提出一个结合学习策略与视觉异常检测的框架，通过三级恢复过程处理执行失败，提高机器人在开放环境中的可靠性和安全性。


<details>
  <summary>Details</summary>
Motivation: 学习到的机器人策略虽然通用，但在开放环境中缺乏处理复杂性的机制，容易导致执行失败，需要能够识别和应对失败的机制来确保可靠和安全的机器人行为。

Method: 训练异常检测模型使用策略正常执行时收集的数据，在线执行时检测异常并触发三级恢复过程：暂停执行、局部扰动机器人状态、从学习到的执行成功模型中采样重置到安全状态。

Result: 在两种场景中验证：Kinova Gen3臂的门把手到达任务和UFactory xArm 6的物体放置任务。结果表明，集成异常检测和恢复能提高在存在轨迹偏差和人为干扰等异常环境中的执行成功率。

Conclusion: 将策略执行与异常检测和恢复相结合，能有效提高机器人在开放环境中的执行可靠性和安全性。

Abstract: Learned robot policies have consistently been shown to be versatile, but they
typically have no built-in mechanism for handling the complexity of open
environments, making them prone to execution failures; this implies that
deploying policies without the ability to recognise and react to failures may
lead to unreliable and unsafe robot behaviour. In this paper, we present a
framework that couples a learned policy with a method to detect visual
anomalies during policy deployment and to perform recovery behaviours when
necessary, thereby aiming to prevent failures. Specifically, we train an
anomaly detection model using data collected during nominal executions of a
trained policy. This model is then integrated into the online policy execution
process, so that deviations from the nominal execution can trigger a
three-level sequential recovery process that consists of (i) pausing the
execution temporarily, (ii) performing a local perturbation of the robot's
state, and (iii) resetting the robot to a safe state by sampling from a learned
execution success model. We verify our proposed method in two different
scenarios: (i) a door handle reaching task with a Kinova Gen3 arm using a
policy trained in simulation and transferred to the real robot, and (ii) an
object placing task with a UFactory xArm 6 using a general-purpose policy
model. Our results show that integrating policy execution with anomaly
detection and recovery increases the execution success rate in environments
with various anomalies, such as trajectory deviations and adversarial human
interventions.

</details>


### [223] [TARC: Time-Adaptive Robotic Control](https://arxiv.org/abs/2510.23176)
*Arnav Sukhija,Lenart Treven,Jin Cheng,Florian Dörfler,Stelian Coros,Andreas Krause*

Main category: cs.RO

TL;DR: 提出一种强化学习方法，让机器人能自主调整控制频率以适应不同情境需求，在两种硬件平台上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 固定频率控制在机器人领域存在效率与鲁棒性的权衡，而生物系统能够自适应调整频率，这启发了研究可变频率控制方法。

Method: 使用强化学习方法，让策略同时选择控制动作及其应用持续时间，使机器人能够根据情境需求自主调节控制频率。

Result: 在高速遥控车和四足机器人上的零样本仿真到现实实验表明，该方法在奖励方面达到或超过固定频率基线，同时显著降低控制频率并在真实环境中表现出自适应频率控制能力。

Conclusion: 该方法成功实现了机器人控制频率的自适应调节，解决了固定频率控制的局限性，在真实世界条件下表现出优越性能。

Abstract: Fixed-frequency control in robotics imposes a trade-off between the
efficiency of low-frequency control and the robustness of high-frequency
control, a limitation not seen in adaptable biological systems. We address this
with a reinforcement learning approach in which policies jointly select control
actions and their application durations, enabling robots to autonomously
modulate their control frequency in response to situational demands. We
validate our method with zero-shot sim-to-real experiments on two distinct
hardware platforms: a high-speed RC car and a quadrupedal robot. Our method
matches or outperforms fixed-frequency baselines in terms of rewards while
significantly reducing the control frequency and exhibiting adaptive frequency
control under real-world conditions.

</details>


### [224] [If They Disagree, Will You Conform? Exploring the Role of Robots' Value Awareness in a Decision-Making Task](https://arxiv.org/abs/2510.23204)
*Giulia Pusceddu,Giulio Antonio Abbo,Francesco Rea,Tony Belpaeme,Alessandra Sciutti*

Main category: cs.RO

TL;DR: 研究表明，当机器人表现出对人类价值观的理解时，它们更容易影响人类决策。参与者能区分价值感知型和非价值感知型机器人，并更多地注视价值感知型机器人，认为其更忠诚。当两个机器人都反对参与者时，约1/4的试验中出现从众行为，且决策时间延长。


<details>
  <summary>Details</summary>
Motivation: 研究机器人是否在表现出对人类价值观的理解时，对人类决策产生更大影响，以及这种影响如何体现。

Method: 设计实验让参与者与两个Furhat机器人互动，一个被编程为价值感知型，另一个为非价值感知型，在图像标注任务中观察参与者的行为和反应。

Result: 参与者能区分两种机器人，更多地注视价值感知型机器人，认为其更忠诚。当两个机器人都反对参与者时，约25%的试验出现从众行为，决策时间延长。

Conclusion: 价值感知型机器人可能增强其群体承诺感知，机器人表达异议可能引发决策犹豫。这既存在机器人被滥用于不道德目的的风险，也表明社交机器人可能在模糊情境中促进反思，帮助用户避免受骗。

Abstract: This study investigates whether the opinions of robotic agents are more
likely to influence human decision-making when the robots are perceived as
value-aware (i.e., when they display an understanding of human principles). We
designed an experiment in which participants interacted with two Furhat robots
- one programmed to be Value-Aware and the other Non-Value-Aware - during a
labeling task for images representing human values. Results indicate that
participants distinguished the Value-Aware robot from the Non-Value-Aware one.
Although their explicit choices did not indicate a clear preference for one
robot over the other, participants directed their gaze more toward the
Value-Aware robot. Additionally, the Value-Aware robot was perceived as more
loyal, suggesting that value awareness in a social robot may enhance its
perceived commitment to the group. Finally, when both robots disagreed with the
participant, conformity occurred in about one out of four trials, and
participants took longer to confirm their responses, suggesting that two robots
expressing dissent may introduce hesitation in decision-making. On one hand,
this highlights the potential risk that robots, if misused, could manipulate
users for unethical purposes. On the other hand, it reinforces the idea that
social robots might encourage reflection in ambiguous situations and help users
avoid scams.

</details>


### [225] [Workspace Registration and Collision Detection for Industrial Robotics Applications](https://arxiv.org/abs/2510.23227)
*Klaus Zauner,Josef El Dib,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 比较不同传感器在机器人运动规划中的应用，展示从环境检测到碰撞环境构建的完整流程，并检测机器人与环境的碰撞。


<details>
  <summary>Details</summary>
Motivation: 机器人运动规划需要精确的环境知识来定义受限区域和考虑碰撞物体，通过获取环境点云来实现这一目标。

Method: 使用各种传感器获取环境点云，通过区域生长分割和VCCS算法识别碰撞物体，然后对点簇进行近似处理。

Result: 建立了从环境检测到碰撞环境构建的完整流程，能够有效识别碰撞物体并检测机器人与环境的碰撞。

Conclusion: 提出的方法能够有效构建机器人运动规划的碰撞环境，为安全可靠的机器人操作提供了技术基础。

Abstract: Motion planning for robotic manipulators relies on precise knowledge of the
environment in order to be able to define restricted areas and to take
collision objects into account. To capture the workspace, point clouds of the
environment are acquired using various sensors. The collision objects are
identified by region growing segmentation and VCCS algorithm. Subsequently the
point clusters are approximated. The aim of the present paper is to compare
different sensors, to illustrate the process from detection to the finished
collision environment and to detect collisions between the robot and this
environment.

</details>


### [226] [Optimal Dimensioning of Elastic-Link Manipulators regarding Lifetime Estimation](https://arxiv.org/abs/2510.23234)
*Klaus Zauner,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种弹性连杆机器人寿命估计方法，用于优化柔性串联机械臂的几何设计，平衡重量、振动和寿命之间的关系。


<details>
  <summary>Details</summary>
Motivation: 轻量化设计和时间能量最优控制是实现可持续工业自动化的关键，需要同时考虑机械柔性和动态控制要求。

Method: 采用雨流计数算法和临界切割平面法进行疲劳分析，使用Tresca假设构建等效应力，假设线性损伤累积，从帕累托前沿选择最优几何。

Result: 该方法应用于三自由度关节机器人的几何优化，实现了重量、振动幅度和寿命之间的权衡。

Conclusion: 提出的寿命估计方法为弹性连杆机器人的设计优化提供了基础，能够实现可持续的工业自动化。

Abstract: Resourceful operation and design of robots is key for sustainable industrial
automation. This will be enabled by lightweight design along with time and
energy optimal control of robotic manipulators. Design and control of such
systems is intertwined as the control must take into account inherent
mechanical compliance while the design must accommodate the dynamic
requirements demanded by the control. As basis for such design optimization, a
method for estimating the lifetime of elastic link robotic manipulators is
presented. This is applied to the geometry optimization of flexible serial
manipulators performing pick-and-place operations, where the optimization
objective is a combination of overall weight and vibration amplitudes. The
lifetime estimation draws from a fatigue analysis combining the rainflow
counting algorithm and the method of critical cutting plane. Tresca hypothesis
is used to formulate an equivalent stress, and linear damage accumulation is
assumed. The final robot geometry is selected from a Pareto front as a tradeoff
of lifetime and vibration characteristic. The method is illustrated for a three
degrees of freedom articulated robotic manipulator.

</details>


### [227] [Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation](https://arxiv.org/abs/2510.23258)
*Riko Yokozawa,Kentaro Fujii,Yuta Nomura,Shingo Murata*

Main category: cs.RO

TL;DR: 提出基于深度主动推理的机器人导航框架，结合扩散策略和多时间尺度状态空间模型，通过最小化期望自由能统一探索和目标导向导航。


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人导航需要同时进行环境探索和目标导向导航，主动推理框架基于自由能原理能够统一这两种行为。

Method: 集成扩散策略作为策略模型和多时间尺度递归状态空间模型作为世界模型，通过潜在想象预测动作的长期后果，选择最小化期望自由能的动作。

Result: 真实世界导航实验显示，相比基线方法，该框架实现了更高的成功率和更少的碰撞，特别是在需要探索的场景中表现更佳。

Conclusion: 基于期望自由能最小化的主动推理能够有效统一现实世界机器人环境中的探索和目标导向导航。

Abstract: Autonomous robotic navigation in real-world environments requires exploration
to acquire environmental information as well as goal-directed navigation in
order to reach specified targets. Active inference (AIF) based on the
free-energy principle provides a unified framework for these behaviors by
minimizing the expected free energy (EFE), thereby combining epistemic and
extrinsic values. To realize this practically, we propose a deep AIF framework
that integrates a diffusion policy as the policy model and a multiple timescale
recurrent state-space model (MTRSSM) as the world model. The diffusion policy
generates diverse candidate actions while the MTRSSM predicts their
long-horizon consequences through latent imagination, enabling action selection
that minimizes EFE. Real-world navigation experiments demonstrated that our
framework achieved higher success rates and fewer collisions compared with the
baselines, particularly in exploration-demanding scenarios. These results
highlight how AIF based on EFE minimization can unify exploration and
goal-directed navigation in real-world robotic settings.

</details>


### [228] [Precise Time Delay Measurement and Compensation for Tightly Coupled Underwater SINS/piUSBL Navigation](https://arxiv.org/abs/2510.23286)
*Jin Huang,Yingqiang Wang,Haoda Li,Zichen Liu,Zhikun Wang,Ying Chen*

Main category: cs.RO

TL;DR: 本文提出了一种紧密耦合的水下导航框架，将被动倒置超短基线声学定位系统、捷联惯性导航系统和深度计在精确时间同步下集成，通过将时间延迟重新定义为可量化参数来显著提高导航精度。


<details>
  <summary>Details</summary>
Motivation: 解决多传感器系统中时间同步的挑战，特别是在包含声学定位的水下集成导航系统中，时间延迟会显著降低测量和融合时刻不对齐时的精度。

Method: 引入紧密耦合导航框架，融合piUSBL的方位角和斜距与深度数据，避免平面阵列垂直角度可观测性差的问题；提出新的延迟测量策略，结合同步定时和声信号处理，将延迟重新定义为可量化参数。

Result: 仿真和现场实验证实了所提方法的可行性，延迟补偿导航使RMSE降低了40.45%，最大误差降低了32.55%。

Conclusion: 精确的延迟测量和补偿不仅提高了水下导航精度，还为声学定位集成建立了一个可推广的框架，为延迟敏感的多传感器系统中的时间对齐和数据融合提供了有价值的见解。

Abstract: In multi-sensor systems, time synchronization between sensors is a
significant challenge, and this issue is particularly pronounced in underwater
integrated navigation systems incorporating acoustic positioning. Such systems
are highly susceptible to time delay, which can significantly degrade accuracy
when measurement and fusion moments are misaligned. To address this challenge,
this paper introduces a tightly coupled navigation framework that integrates a
passive inverted ultra-short baseline (piUSBL) acoustic positioning system, a
strapdown inertial navigation system (SINS), and a depth gauge under precise
time synchronization. The framework fuses azimuth and slant range from the
piUSBL with depth data, thereby avoiding poor vertical-angle observability in
planar arrays. A novel delay measurement strategy is introduced, combining
synchronized timing with acoustic signal processing, which redefines
delay-traditionally an unobservable error-into a quantifiable parameter,
enabling explicit estimation of both acoustic propagation and system processing
delays. Simulations and field experiments confirm the feasibility of the
proposed method, with delay-compensated navigation reducing RMSE by 40.45% and
maximum error by 32.55%. These findings show that precise delay measurement and
compensation not only enhance underwater navigation accuracy but also establish
a generalizable framework for acoustic positioning integration, offering
valuable insights into time alignment and data fusion in latency-sensitive
multi-sensor systems.

</details>


### [229] [Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon](https://arxiv.org/abs/2510.23329)
*Shreya Santra,Thomas Robbins,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 该研究探索了深度强化学习策略在视觉和地形特征不同的模拟域之间的泛化能力，将农业环境训练的导航策略直接应用于月球环境，无需额外训练即可达到近50%的成功率。


<details>
  <summary>Details</summary>
Motivation: 解决非结构化环境中自主导航的挑战，传统方法需要大量环境特定调优，限制了在新领域的可扩展性。

Method: 开发3D农业漫游车模拟器，使用近端策略优化（PPO）训练目标导向导航和避障策略，然后在月球模拟环境中进行零样本验证。

Result: 在月球模拟环境中，仅在陆地条件下训练的策略保持了高度有效性，无需额外训练和微调即可达到近50%的成功率。

Conclusion: 跨域DRL策略迁移为未来行星探索任务开发适应性强的自主导航系统提供了有前景的方法，同时最小化再训练成本。

Abstract: Autonomous navigation in unstructured environments is essential for field and
planetary robotics, where robots must efficiently reach goals while avoiding
obstacles under uncertain conditions. Conventional algorithmic approaches often
require extensive environment-specific tuning, limiting scalability to new
domains. Deep Reinforcement Learning (DRL) provides a data-driven alternative,
allowing robots to acquire navigation strategies through direct interactions
with their environment. This work investigates the feasibility of DRL policy
generalization across visually and topographically distinct simulated domains,
where policies are trained in terrestrial settings and validated in a zero-shot
manner in extraterrestrial environments. A 3D simulation of an agricultural
rover is developed and trained using Proximal Policy Optimization (PPO) to
achieve goal-directed navigation and obstacle avoidance in farmland settings.
The learned policy is then evaluated in a lunar-like simulated environment to
assess transfer performance. The results indicate that policies trained under
terrestrial conditions retain a high level of effectiveness, achieving close to
50\% success in lunar simulations without the need for additional training and
fine-tuning. This underscores the potential of cross-domain DRL-based policy
transfer as a promising approach to developing adaptable and efficient
autonomous navigation for future planetary exploration missions, with the added
benefit of minimizing retraining costs.

</details>


### [230] [Large language model-based task planning for service robots: A review](https://arxiv.org/abs/2510.23357)
*Shaohan Bian,Ying Zhang,Guohui Tian,Zhiqiang Miao,Edmond Q. Wu,Simon X. Yang,Changchun Hua*

Main category: cs.RO

TL;DR: 本文综述了大语言模型在服务机器人任务规划中的应用，包括LLM技术基础、作为机器人"大脑"的作用、多模态输入下的任务规划进展，以及当前挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和机器人技术的快速发展，服务机器人需要更智能高效的任务规划能力来应对复杂环境中的多样化服务需求。

Method: 通过文献综述方法，分析LLM的基础技术（预训练、微调、RAG、提示工程）及其在服务机器人任务规划中的应用，涵盖文本、视觉、音频和多模态输入场景。

Result: LLM能够作为服务机器人的认知核心，显著提升自主性和决策能力，在多模态任务规划方面取得重要进展。

Conclusion: 当前研究仍面临挑战，需要进一步推进复杂非结构化家庭环境中服务机器人的任务规划能力，为人工智能和机器人领域研究者提供重要参考。

Abstract: With the rapid advancement of large language models (LLMs) and robotics,
service robots are increasingly becoming an integral part of daily life,
offering a wide range of services in complex environments. To deliver these
services intelligently and efficiently, robust and accurate task planning
capabilities are essential. This paper presents a comprehensive overview of the
integration of LLMs into service robotics, with a particular focus on their
role in enhancing robotic task planning. First, the development and
foundational techniques of LLMs, including pre-training, fine-tuning,
retrieval-augmented generation (RAG), and prompt engineering, are reviewed. We
then explore the application of LLMs as the cognitive core-`brain'-of service
robots, discussing how LLMs contribute to improved autonomy and
decision-making. Furthermore, recent advancements in LLM-driven task planning
across various input modalities are analyzed, including text, visual, audio,
and multimodal inputs. Finally, we summarize key challenges and limitations in
current research and propose future directions to advance the task planning
capabilities of service robots in complex, unstructured domestic environments.
This review aims to serve as a valuable reference for researchers and
practitioners in the fields of artificial intelligence and robotics.

</details>


### [231] [T-ESKF: Transformed Error-State Kalman Filter for Consistent Visual-Inertial Navigation](https://arxiv.org/abs/2510.23359)
*Chungeng Tian,Ning Hao,Fenghua He*

Main category: cs.RO

TL;DR: 提出Transformed ESKF (T-ESKF)方法，通过线性时变变换解决视觉惯性导航系统中的可观测性不匹配问题，确保系统一致性并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决视觉惯性导航系统(VINS)中由可观测性不匹配引起的系统不一致性问题，这是影响滤波器性能的关键挑战。

Method: 在误差状态卡尔曼滤波器(ESKF)中应用线性时变变换到误差状态，使变换后误差状态系统的不可观测子空间与状态无关，从而保持正确的可观测性。

Result: 通过大量仿真和实验验证，相比最先进方法展现出更好或至少相当的性能表现。

Conclusion: T-ESKF是一种一致的VINS估计器，通过变换误差状态系统实现状态估计，并开发了高效的协方差传播技术来加速计算。

Abstract: This paper presents a novel approach to address the inconsistency problem
caused by observability mismatch in visual-inertial navigation systems (VINS).
The key idea involves applying a linear time-varying transformation to the
error-state within the Error-State Kalman Filter (ESKF). This transformation
ensures that \textrr{the unobservable subspace of the transformed error-state
system} becomes independent of the state, thereby preserving the correct
observability of the transformed system against variations in linearization
points. We introduce the Transformed ESKF (T-ESKF), a consistent VINS estimator
that performs state estimation using the transformed error-state system.
Furthermore, we develop an efficient propagation technique to accelerate the
covariance propagation based on the transformation relationship between the
transition and accumulated matrices of T-ESKF and ESKF. We validate the
proposed method through extensive simulations and experiments, demonstrating
better (or competitive at least) performance compared to state-of-the-art
methods. The code is available at github.com/HITCSC/T-ESKF.

</details>


### [232] [Full-Dynamics Real-Time Nonlinear Model Predictive Control of Heavy-Duty Hydraulic Manipulator for Trajectory Tracking Tasks](https://arxiv.org/abs/2510.23386)
*Alvaro Paz,Mahdi Hejrati,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 提出了一种用于重型液压机械臂的非线性模型预测控制框架，能够在1kHz实时控制频率下保证关节和末端执行器的约束满足，同时实现高精度轨迹跟踪。


<details>
  <summary>Details</summary>
Motivation: 重型液压机械臂由于尺寸大、功率高、非线性动力学复杂，需要在严格物理和安全约束下运行。现有实时控制框架很少能同时保证关节级和末端执行器轨迹符合执行器能力限制。

Method: 结合多射击策略与实时传感器反馈的非线性模型预测控制，并采用基于虚拟分解控制的鲁棒底层控制器进行精确关节跟踪。

Result: 在全尺寸液压机械臂上的实验验证表明，该框架不仅能在关节级强制执行器约束，还能确保末端执行器在笛卡尔空间中的约束合规运动。

Conclusion: 该方法能够实现高精度轨迹跟踪并严格遵守安全关键限制，为大型液压系统的实时控制设立了新标准。

Abstract: Heavy-duty hydraulic manipulators (HHMs) operate under strict physical and
safety-critical constraints due to their large size, high power, and complex
nonlinear dynamics. Ensuring that both joint-level and end-effector
trajectories remain compliant with actuator capabilities, such as force,
velocity, and position limits, is essential for safe and reliable operation,
yet remains largely underexplored in real-time control frameworks. This paper
presents a nonlinear model predictive control (NMPC) framework designed to
guarantee constraint satisfaction throughout the full nonlinear dynamics of
HHMs, while running at a real-time control frequency of 1 kHz. The proposed
method combines a multiple-shooting strategy with real-time sensor feedback,
and is supported by a robust low-level controller based on virtual
decomposition control (VDC) for precise joint tracking. Experimental validation
on a full-scale hydraulic manipulator shows that the NMPC framework not only
enforces actuator constraints at the joint level, but also ensures
constraint-compliant motion in Cartesian space for the end-effector. These
results demonstrate the method's capability to deliver high-accuracy trajectory
tracking while strictly respecting safety-critical limits, setting a new
benchmark for real-time control in large-scale hydraulic systems.

</details>


### [233] [COOPERA: Continual Open-Ended Human-Robot Assistance](https://arxiv.org/abs/2510.23495)
*Chenyang Ma,Kai Lu,Ruta Desai,Xavier Puig,Andrew Markham,Niki Trigoni*

Main category: cs.RO

TL;DR: COOPERA是一个持续开放人机协作框架，通过模拟具有心理特征和长期意图的人类，在复杂环境中与机器人互动，实现个性化的人机协作。


<details>
  <summary>Details</summary>
Motivation: 现有机器人助手主要在结构化环境中执行预定义任务，缺乏对人类个体特征、习惯和活动的长期学习能力，无法实现真正的人机协作。

Method: 提出COOPERA框架，集成持续的人类反馈，通过模拟具有心理特征和长期意图的人类，在复杂环境中与机器人互动，并引入基准测试和个性化方法学习人类特征和情境依赖意图。

Result: 实验验证了模拟人类行为的真实性，并证明了推断和个性化人类意图对开放长期人机协作的价值。

Conclusion: COOPERA框架首次实现了在不同时间尺度上研究长期开放人机协作，为人机协作研究提供了新方向。

Abstract: To understand and collaborate with humans, robots must account for individual
human traits, habits, and activities over time. However, most robotic
assistants lack these abilities, as they primarily focus on predefined tasks in
structured environments and lack a human model to learn from. This work
introduces COOPERA, a novel framework for COntinual, OPen-Ended human-Robot
Assistance, where simulated humans, driven by psychological traits and
long-term intentions, interact with robots in complex environments. By
integrating continuous human feedback, our framework, for the first time,
enables the study of long-term, open-ended human-robot collaboration (HRC) in
different collaborative tasks across various time-scales. Within COOPERA, we
introduce a benchmark and an approach to personalize the robot's collaborative
actions by learning human traits and context-dependent intents. Experiments
validate the extent to which our simulated humans reflect realistic human
behaviors and demonstrate the value of inferring and personalizing to human
intents for open-ended and long-term HRC. Project Page:
https://dannymcy.github.io/coopera/

</details>


### [234] [Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model](https://arxiv.org/abs/2510.23509)
*Weizheng Wang,Obi Ike,Soyun Choi,Sungeun Hong,Byung-Cheol Min*

Main category: cs.RO

TL;DR: NaviWM是一个社交感知的机器人导航世界模型，通过结合结构化世界模型和逻辑驱动的思维链过程来增强LLM推理，解决LLM在动态人类空间中导航时的不确定性和安全问题。


<details>
  <summary>Details</summary>
Motivation: 当前依赖大型语言模型进行社交机器人导航存在不可预测和不安全行为的问题，主要由于LLM缺乏物理基础和逻辑一致性。

Method: NaviWM包含两个主要组件：空间-时间世界模型（捕捉环境中智能体的位置、速度和活动）和演绎推理模块（通过多步骤、基于逻辑的推理过程指导LLM）。

Result: 实验表明NaviWM提高了成功率和减少了社交违规，特别是在拥挤环境中。

Conclusion: 将形式推理与LLM结合对于稳健的社交导航具有显著优势。

Abstract: Social robot navigation increasingly relies on large language models for
reasoning, path planning, and enabling movement in dynamic human spaces.
However, relying solely on LLMs for planning often leads to unpredictable and
unsafe behaviors, especially in dynamic human spaces, due to limited physical
grounding and weak logical consistency. In this work, we introduce NaviWM, a
socially-aware robot Navigation World Model that augments LLM reasoning with a
structured world model and a logic-driven chain-of-thought process. NaviWM
consists of two main components: (1) a spatial-temporal world model that
captures the positions, velocities, and activities of agents in the
environment, and (2) a deductive reasoning module that guides LLMs through a
multi-step, logic-based inference process. This integration enables the robot
to generate navigation decisions that are both socially compliant and
physically safe, under well-defined constraints such as personal space,
collision avoidance, and timing. Unlike previous methods based on prompting or
fine-tuning, NaviWM encodes social norms as first-order logic, enabling
interpretable and verifiable reasoning. Experiments show that NaviWM improves
success rates and reduces social violations, particularly in crowded
environments. These results demonstrate the benefit of combining formal
reasoning with LLMs for robust social navigation. Additional experimental
details and demo videos for this work can be found at:
https://sites.google.com/view/NaviWM.

</details>


### [235] [Dexbotic: Open-Source Vision-Language-Action Toolbox](https://arxiv.org/abs/2510.23511)
*Bin Xie,Erjin Zhou,Fan Jia,Hao Shi,Haoqiang Fan,Haowei Zhang,Hebei Li,Jianjian Sun,Jie Bin,Junwen Huang,Kai Liu,Kaixin Liu,Kefan Gu,Lin Sun,Meng Zhang,Peilong Han,Ruitao Hao,Ruitao Zhang,Saike Huang,Songhan Xie,Tiancai Wang,Tianle Liu,Wenbin Tang,Wenqi Zhu,Yang Chen,Yingfei Liu,Yizhuang Zhou,Yu Liu,Yucheng Zhao,Yunchao Ma,Yunfei Wei,Yuxiang Chen,Ze Chen,Zeming Li,Zhao Wu,Ziheng Zhang,Ziming Liu,Ziwei Yan,Ziyu Zhang*

Main category: cs.RO

TL;DR: Dexbotic是一个基于PyTorch的开源视觉-语言-动作(VLA)模型工具箱，为具身智能领域提供一站式VLA研究服务，支持多种主流VLA策略，并提供了更强的预训练模型。


<details>
  <summary>Details</summary>
Motivation: 为具身智能领域的专业人士提供一个一站式的VLA研究服务平台，简化VLA方法的复现和实验开发过程。

Method: 基于PyTorch构建的开源工具箱，支持多种主流VLA策略，采用实验中心化设计，用户只需修改Exp脚本即可快速开发新实验。

Result: 提供了更强的预训练模型，能够显著提升最先进VLA策略的性能表现。

Conclusion: Dexbotic将持续更新，纳入更多最新的预训练基础模型和行业前沿的VLA模型，为VLA研究提供持续支持。

Abstract: In this paper, we present Dexbotic, an open-source Vision-Language-Action
(VLA) model toolbox based on PyTorch. It aims to provide a one-stop VLA
research service for professionals in the field of embodied intelligence. It
offers a codebase that supports multiple mainstream VLA policies
simultaneously, allowing users to reproduce various VLA methods with just a
single environment setup. The toolbox is experiment-centric, where the users
can quickly develop new VLA experiments by simply modifying the Exp script.
Moreover, we provide much stronger pretrained models to achieve great
performance improvements for state-of-the-art VLA policies. Dexbotic will
continuously update to include more of the latest pre-trained foundation models
and cutting-edge VLA models in the industry.

</details>


### [236] [Localising under the drape: proprioception in the era of distributed surgical robotic system](https://arxiv.org/abs/2510.23512)
*Martin Huber,Nicola A. Cavalcanti,Ayoob Davoodi,Ruixuan Li,Christopher E. Mower,Fabio Carrillo,Christoph J. Laux,Francois Teyssere,Thibault Chandanson,Antoine Harlé,Elie Saghbiny,Mazda Farshad,Guillaume Morel,Emmanuel Vander Poorten,Philipp Fürnstahl,Sébastien Ourselin,Christos Bergeles,Tom Vercauteren*

Main category: cs.RO

TL;DR: 提出了一种无需标记的机器人本体感知方法，使用轻量级立体RGB相机和基于Transformer的深度学习模型，能够在无菌覆盖下精确定位手术机器人，解决了现有跟踪系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有手术机器人缺乏空间感知能力，导致碰撞和系统恢复问题；现有跟踪系统依赖笨重的红外相机和反射标记，视野有限且增加硬件负担。

Method: 基于最大的多中心空间机器人手术数据集（140万张自注释图像），使用轻量级立体RGB相机和新型基于Transformer的深度学习模型，通过跟踪整个机器人和手术场景而非单个标记来实现定位。

Result: 在体内呼吸补偿中展示了临床效益，能够观察组织动态；相比现有系统，消除了标记需求并将跟踪可见性提高了25%；在多机器人系统中准确定位。

Conclusion: 这是首个针对完全覆盖无菌布的手术机器人实现无标记本体感知的演示，减少了设置复杂性，提高了安全性，为模块化和自主机器人手术铺平了道路。

Abstract: Despite their mechanical sophistication, surgical robots remain blind to
their surroundings. This lack of spatial awareness causes collisions, system
recoveries, and workflow disruptions, issues that will intensify with the
introduction of distributed robots with independent interacting arms. Existing
tracking systems rely on bulky infrared cameras and reflective markers,
providing only limited views of the surgical scene and adding hardware burden
in crowded operating rooms. We present a marker-free proprioception method that
enables precise localisation of surgical robots under their sterile draping
despite associated obstruction of visual cues. Our method solely relies on
lightweight stereo-RGB cameras and novel transformer-based deep learning
models. It builds on the largest multi-centre spatial robotic surgery dataset
to date (1.4M self-annotated images from human cadaveric and preclinical in
vivo studies). By tracking the entire robot and surgical scene, rather than
individual markers, our approach provides a holistic view robust to occlusions,
supporting surgical scene understanding and context-aware control. We
demonstrate an example of potential clinical benefits during in vivo breathing
compensation with access to tissue dynamics, unobservable under state of the
art tracking, and accurately locate in multi-robot systems for future
intelligent interaction. In addition, and compared with existing systems, our
method eliminates markers and improves tracking visibility by 25%. To our
knowledge, this is the first demonstration of marker-free proprioception for
fully draped surgical robots, reducing setup complexity, enhancing safety, and
paving the way toward modular and autonomous robotic surgery.

</details>


### [237] [Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation](https://arxiv.org/abs/2510.23521)
*Anthony Opipari,Aravindhan K Krishnan,Shreekant Gayaka,Min Sun,Cheng-Hao Kuo,Arnie Sen,Odest Chadwicke Jenkins*

Main category: cs.RO

TL;DR: 该论文提出了一种使用显式3D高斯溅射(3DGS)记忆来改进视频分割算法的方法，开发了FastSAM-Splat和SAM2-Splat两种融合技术，通过存储过去预测的对象片段来提高分割的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频分割算法要么不使用对象级记忆（如FastSAM），要么仅使用循环神经网络特征的隐式记忆（如SAM2）。作者认为记住过去预测的对象片段位置有助于提高类无关视频分割算法的准确性和一致性。

Method: 开发了一种在线3D高斯溅射(3DGS)技术来存储视频过程中预测的对象级片段，基于此3DGS表示开发了FastSAM-Splat和SAM2-Splat两种融合技术，使用显式3DGS记忆来改进各自基础模型的预测。

Result: 消融实验验证了所提技术的设计和超参数设置。真实世界和模拟基准测试结果显示，使用显式3D记忆的模型比不使用记忆或仅使用隐式神经网络记忆的模型具有更准确和一致的预测结果。

Conclusion: 使用显式3D高斯溅射记忆可以显著提高视频分割算法的准确性和一致性，证明了显式记忆在视频分割任务中的重要性。

Abstract: Remembering where object segments were predicted in the past is useful for
improving the accuracy and consistency of class-agnostic video segmentation
algorithms. Existing video segmentation algorithms typically use either no
object-level memory (e.g. FastSAM) or they use implicit memories in the form of
recurrent neural network features (e.g. SAM2). In this paper, we augment both
types of segmentation models using an explicit 3D memory and show that the
resulting models have more accurate and consistent predictions. For this, we
develop an online 3D Gaussian Splatting (3DGS) technique to store predicted
object-level segments generated throughout the duration of a video. Based on
this 3DGS representation, a set of fusion techniques are developed, named
FastSAM-Splat and SAM2-Splat, that use the explicit 3DGS memory to improve
their respective foundation models' predictions. Ablation experiments are used
to validate the proposed techniques' design and hyperparameter settings.
Results from both real-world and simulated benchmarking experiments show that
models which use explicit 3D memories result in more accurate and consistent
predictions than those which use no memory or only implicit neural network
memories. Project Page: https://topipari.com/projects/FastSAM-Splat/

</details>


### [238] [RobotArena $\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation](https://arxiv.org/abs/2510.23571)
*Yash Jangir,Yidi Zhang,Kashu Yamazaki,Chenyu Zhang,Kuan-Hsun Tu,Tsung-Wei Ke,Lei Ke,Yonatan Bisk,Katerina Fragkiadaki*

Main category: cs.RO

TL;DR: 提出了一种新的机器人基准测试框架，通过将视觉语言动作模型评估转移到大规模模拟环境中，结合在线人类反馈，解决了现实世界机器人测试的局限性。


<details>
  <summary>Details</summary>
Motivation: 现实世界机器人测试存在劳动密集、速度慢、不安全、难以复现等问题，现有模拟基准测试无法评估从真实世界演示训练的模型，且机器人成功定义往往依赖人类对执行质量的细微判断。

Method: 利用视觉语言模型、2D到3D生成建模和可微分渲染技术，将广泛使用的机器人数据集中的视频演示自动转换为模拟对应物，在数字孪生环境中使用自动化VLM引导评分和可扩展的人类偏好判断来评估VLA策略。

Result: 开发了一个持续演进、可复现且可扩展的基准测试系统，能够系统性地扰动模拟环境来测试策略的鲁棒性，解决了当前机器人领域的关键缺失能力。

Conclusion: 该框架通过将人类参与从繁琐的场景设置、重置和安全监督转变为轻量级偏好比较，为真实世界训练的机器人操作策略提供了有效的评估解决方案。

Abstract: The pursuit of robot generalists - instructable agents capable of performing
diverse tasks across diverse environments - demands rigorous and scalable
evaluation. Yet real-world testing of robot policies remains fundamentally
constrained: it is labor-intensive, slow, unsafe at scale, and difficult to
reproduce. Existing simulation benchmarks are similarly limited, as they train
and test policies within the same synthetic domains and cannot assess models
trained from real-world demonstrations or alternative simulation environments.
As policies expand in scope and complexity, these barriers only intensify,
since defining "success" in robotics often hinges on nuanced human judgments of
execution quality. In this paper, we introduce a new benchmarking framework
that overcomes these challenges by shifting VLA evaluation into large-scale
simulated environments augmented with online human feedback. Leveraging
advances in vision-language models, 2D-to-3D generative modeling, and
differentiable rendering, our approach automatically converts video
demonstrations from widely used robot datasets into simulated counterparts.
Within these digital twins, we assess VLA policies using both automated
VLM-guided scoring and scalable human preference judgments collected from
crowdworkers, transforming human involvement from tedious scene setup,
resetting, and safety supervision into lightweight preference comparisons. To
measure robustness, we systematically perturb simulated environments along
multiple axes, such as textures and object placements, stress-testing policy
generalization under controlled variation. The result is a continuously
evolving, reproducible, and scalable benchmark for real-world trained robot
manipulation policies, addressing a critical missing capability in today's
robotics landscape.

</details>


### [239] [UrbanVLA: A Vision-Language-Action Model for Urban Micromobility](https://arxiv.org/abs/2510.23576)
*Anqi Li,Zhiyong Wang,Jiazhao Zhang,Minghan Li,Yunpeng Qi,Zhibo Chen,Zhizheng Zhang,He Wang*

Main category: cs.RO

TL;DR: UrbanVLA是一个用于城市微移动导航的视觉-语言-动作框架，通过两阶段训练实现大规模城市环境中的可靠导航，在MetaUrban的SocialNav任务中性能提升超过55%。


<details>
  <summary>Details</summary>
Motivation: 现有的导航方法主要针对小规模和可控场景，而城市微移动应用（如配送机器人）需要在动态、非结构化的城市环境中进行长距离可靠导航，这需要同时具备低级的点目标到达和障碍物避障能力，以及高级的路线-视觉对齐能力。

Method: 提出UrbanVLA框架，在导航执行过程中显式对齐噪声路线路标点和视觉观测，然后规划机器人轨迹。采用两阶段训练：首先使用模拟环境和网络视频轨迹进行监督微调，然后在模拟和真实世界数据混合上进行强化微调。

Result: 在MetaUrban的SocialNav任务中，UrbanVLA比强基线方法性能提升超过55%。同时实现了可靠的现实世界导航，展示了对大规模城市环境的可扩展性和对现实世界不确定性的鲁棒性。

Conclusion: UrbanVLA框架成功解决了城市微移动导航的挑战，通过结合视觉-语言-动作建模和两阶段训练策略，实现了在大规模动态城市环境中的可靠导航。

Abstract: Urban micromobility applications, such as delivery robots, demand reliable
navigation across large-scale urban environments while following long-horizon
route instructions. This task is particularly challenging due to the dynamic
and unstructured nature of real-world city areas, yet most existing navigation
methods remain tailored to short-scale and controllable scenarios. Effective
urban micromobility requires two complementary levels of navigation skills:
low-level capabilities such as point-goal reaching and obstacle avoidance, and
high-level capabilities, such as route-visual alignment. To this end, we
propose UrbanVLA, a route-conditioned Vision-Language-Action (VLA) framework
designed for scalable urban navigation. Our method explicitly aligns noisy
route waypoints with visual observations during execution, and subsequently
plans trajectories to drive the robot. To enable UrbanVLA to master both levels
of navigation, we employ a two-stage training pipeline. The process begins with
Supervised Fine-Tuning (SFT) using simulated environments and trajectories
parsed from web videos. This is followed by Reinforcement Fine-Tuning (RFT) on
a mixture of simulation and real-world data, which enhances the model's safety
and adaptability in real-world settings. Experiments demonstrate that UrbanVLA
surpasses strong baselines by more than 55% in the SocialNav task on MetaUrban.
Furthermore, UrbanVLA achieves reliable real-world navigation, showcasing both
scalability to large-scale urban environments and robustness against real-world
uncertainties.

</details>
