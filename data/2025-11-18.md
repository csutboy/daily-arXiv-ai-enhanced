<div id=toc></div>

# Table of Contents

- [cs.ET](#cs.ET) [Total: 4]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [cs.CY](#cs.CY) [Total: 34]
- [cs.RO](#cs.RO) [Total: 55]
- [econ.EM](#econ.EM) [Total: 6]
- [cs.SI](#cs.SI) [Total: 6]
- [econ.TH](#econ.TH) [Total: 1]
- [cs.GL](#cs.GL) [Total: 1]
- [eess.SY](#eess.SY) [Total: 41]
- [cs.AI](#cs.AI) [Total: 82]
- [econ.GN](#econ.GN) [Total: 4]
- [stat.AP](#stat.AP) [Total: 11]


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [1] [Evolution of A4L: A Data Architecture for AI-Augmented Learning](https://arxiv.org/abs/2511.11877)
*Ploy Thajchayapong,Suzanne Carbonaro,Tim Couper,Blaine Helmick,Spencer Rugaber,Ashok Goel*

Main category: cs.ET

TL;DR: 提出了A4L2.0架构，利用开放标准实现教育数据系统的安全互操作集成，支持AI增强的个性化学习分析


<details>
  <summary>Details</summary>
Motivation: 随着AI深度融入教育生态系统，需要可扩展的解决方案来支持个性化学习，实现持续数据流和有意义的学习洞察

Method: 基于1EdTech联盟的开放标准（Edu-API、Caliper Analytics、LTI），构建包含数据摄取、预处理、组织、分析和可视化模块的数据管道

Result: A4L2.0能够安全地集成学生信息系统、学习管理系统和AI工具的数据，支持中观和微观学习分析

Conclusion: A4L2.0架构为成人学习者和在线教育提供了可扩展的AI增强学习分析框架

Abstract: As artificial intelligence (AI) becomes more deeply integrated into educational ecosystems, the demand for scalable solutions that enable personalized learning continues to grow. These architectures must support continuous data flows that power personalized learning and access to meaningful insights to advance learner success at scale. At the National AI Institute for Adult Learning and Online Education (AI-ALOE), we have developed an Architecture for AI-Augmented Learning (A4L) to support analysis and personalization of online education for adult learners. A4L1.0, an early implementation by Georgia Tech's Design Intelligence Laboratory, demonstrated how the architecture supports analysis of meso- and micro-learning by integrating data from Learning Management Systems (LMS) and AI tools. These pilot studies informed the design of A4L2.0. In this chapter, we describe A4L2.0 that leverages 1EdTech Consortium's open standards such as Edu-API, Caliper Analytics, and Learning Tools Interoperability (LTI) to enable secure, interoperable data integration across data systems like Student Information Systems (SIS), LMS, and AI tools. The A4L2.0 data pipeline includes modules for data ingestion, preprocessing, organization, analytics, and visualization.

</details>


### [2] [QPU Micro-Kernels for Stencil Computation](https://arxiv.org/abs/2511.12617)
*Stefano Markidis,Luca Pennati,Marco Pasquale,Gilbert Netzer,Ivy Peng*

Main category: cs.ET

TL;DR: 提出了QPU微内核：浅层量子电路，用于执行模板节点更新并通过重复测量返回蒙特卡洛估计，将QPU作为采样加速器来求解偏微分方程。


<details>
  <summary>Details</summary>
Motivation: 传统量子PDE求解器将完整时空问题编码在一个深层电路中，而该方法保持经典时间循环，仅卸载局部更新，使量子资源需求固定且与全局网格无关。

Method: 使用两种微内核实现：伯努利微内核针对凸和模板，将值编码为单量子比特概率；分支微内核准备模板分支选择器并对单个读出量子比特应用寻址旋转。

Result: 在无噪声量子电路模拟器中，随着样本数量增加，精度提高；在IBM Brisbane量子计算机上，伯努利实现比分支实现误差更低，QPU微内核执行占主导时间。

Conclusion: QPU微内核方法将量子计算作为采样加速器，通过浅层电路和固定资源需求，有效解决了偏微分方程求解问题，特别适合科学计算中的常见PDE。

Abstract: We introduce QPU micro-kernels: shallow quantum circuits that perform a stencil node update and return a Monte Carlo estimate from repeated measurements. We show how to use them to solve Partial Differential Equations (PDEs) explicitly discretized on a computational stencil. From this point of view, the QPU serves as a sampling accelerator. Each micro-kernel consumes only stencil inputs (neighbor values and coefficients), runs a shallow parameterized circuit, and reports the sample mean of a readout rule. The resource footprint in qubits and depth is fixed and independent of the global grid. This makes micro-kernels easy to orchestrate from a classical host and to parallelize across grid points. We present two realizations. The Bernoulli micro-kernel targets convex-sum stencils by encoding values as single-qubit probabilities with shot allocation proportional to stencil weights. The branching micro-kernel prepares a selector over stencil branches and applies addressed rotations to a single readout qubit. In contrast to monolithic quantum PDE solvers that encode the full space-time problem in one deep circuit, our approach keeps the classical time loop and offloads only local updates. Batching and in-circuit fusion amortize submission and readout overheads. We test and validate the QPU micro-kernel method on two PDEs commonly arising in scientific computing: the Heat and viscous Burgers' equations. On noiseless quantum circuit simulators, accuracy improves as the number of samples increases. On the IBM Brisbane quantum computer, single-step diffusion tests show lower errors for the Bernoulli realization than for branching at equal shot budgets, with QPU micro-kernel execution dominating the wall time.

</details>


### [3] [Segmented Exponent Alignment and Dynamic Wordline Activation for Floating-Point Analog CIM Macros](https://arxiv.org/abs/2511.12624)
*Weiping Yang,Shilin Zhou,Hui Xu,Jiawei Xue,Changlin Chen*

Main category: cs.ET

TL;DR: 提出了分段指数对齐(SEA)和动态字线激活(DWA)策略，用于优化浮点乘累加(FP-MAC)运算，在CIM加速器中实现功耗和延迟的显著降低。


<details>
  <summary>Details</summary>
Motivation: 浮点MAC运算在神经网络中精度更高，但传统实现存在硬件开销大和延迟高的问题，特别是指数比较和尾数对齐操作。

Method: SEA策略通过分段指数空间和相应尾数对齐，消除最大指数检测需求；DWA策略基于SEA定义的指数段动态激活字线。

Result: 在VGG16-CIFAR10基准测试中，相比传统比较树方法，功耗降低63.8%，延迟减少40.87%。

Conclusion: SEA和DWA策略有效解决了FP-MAC运算的硬件开销和延迟问题，为CIM加速器提供了高效的浮点运算解决方案。

Abstract: With the rise of compute-in-memory (CIM) accelerators, floating-point multiply-and-accumulate (FP-MAC) operations have gained extensive attention for their higher accuracy over integer MACs in neural networks. However, the hardware overhead caused by exponent comparison and mantissa alignment, along with the delay introduced by bit-serial input methods, remains a hinder to implement FP-MAC efficiently. In view of this, we propose Segmented Exponent Alignment (SEA) and Dynamic Wordline Activation (DWA) strategies. SEA exploits the observation that input exponents are often clustered around zero or within a narrow range. By segmenting the exponent space and aligning mantissas accordingly, SEA eliminates the need for maximum exponent detection and reduces input mantissa shifting, and thus reduces the processing latency. DWA further reduces latency and maintains accuracy by activating wordlines based on the exponent segments defined by SEA. Simulation results demonstrate that, when compared with conventional comparison tree based maximum exponent alignment method, our approach saves 63.8\% power consumption, and achieves a 40.87\% delay reduction on the VGG16-CIFAR10 benchmark.

</details>


### [4] [PolicyBot - Reliable Question Answering over Policy Documents](https://arxiv.org/abs/2511.13489)
*Gautam Nagarajan,Omir Kumar,Sudarsun Santhiappan*

Main category: cs.ET

TL;DR: PolicyBot是一个基于检索增强生成(RAG)的系统，专门用于回答政策文档相关的用户查询，强调透明度和可重现性。


<details>
  <summary>Details</summary>
Motivation: 政策文档通常冗长复杂，公民难以查找和理解相关信息，需要开发能够提供可靠、透明答案的系统。

Method: 结合领域特定的语义分块、多语言密集嵌入、多阶段检索与重排序、基于来源的生成，并实现引用追踪以减少幻觉。

Result: 构建了完全基于开源工具的端到端管道，能够提供基于原始文档的回答，提高了用户信任度。

Conclusion: 这项工作展示了在治理相关背景下部署可信赖RAG系统的设计考虑、实际挑战和经验教训，系统易于适应其他需要文档基础问答的领域。

Abstract: All citizens of a country are affected by the laws and policies introduced by their government. These laws and policies serve essential functions for citizens. Such as granting them certain rights or imposing specific obligations. However, these documents are often lengthy, complex, and difficult to navigate, making it challenging for citizens to locate and understand relevant information. This work presents PolicyBot, a retrieval-augmented generation (RAG) system designed to answer user queries over policy documents with a focus on transparency and reproducibility. The system combines domain-specific semantic chunking, multilingual dense embeddings, multi-stage retrieval with reranking, and source-aware generation to provide responses grounded in the original documents. We implemented citation tracing to reduce hallucinations and improve user trust, and evaluated alternative retrieval and generation configurations to identify effective design choices. The end-to-end pipeline is built entirely with open-source tools, enabling easy adaptation to other domains requiring document-grounded question answering. This work highlights design considerations, practical challenges, and lessons learned in deploying trustworthy RAG systems for governance-related contexts.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [5] [CBDC Stress Test in a Dual-Currency Setting](https://arxiv.org/abs/2511.13384)
*Catalin Dumitrescu*

Main category: q-fin.GN

TL;DR: 该研究开发了一个结合计量经济学、机器学习和行为建模的分析框架，评估在罗马尼亚双货币经济中引入央行数字货币(CBDC)对金融稳定的影响。研究发现适度设计的CBDC可以作为数字流动性缓冲，在不损害金融稳定的前提下增强金融韧性和包容性。


<details>
  <summary>Details</summary>
Motivation: 探索在双货币经济（罗马尼亚，RON与欧元共存）中引入CBDC对金融稳定的潜在影响，需要解决欧元化风险和货币主权保护问题。

Method: 使用XGBoost和逻辑回归模型估计CBDC采用概率，结合流动性压力测试模拟银行应对存款提取的反应，采用VAR、MSVAR和SVAR模型捕捉流动性冲击的宏观金融传导机制。

Result: CBDC初始采用规模约为10亿欧元，主要由数字准备度和对央行的信任驱动。非计息、有上限的CBDC设计可以避免金融不稳定，双货币经济中需要差异化持有限额来防止欧元化。

Conclusion: 审慎设计的CBDC（适度上限、不计息、宏观审慎协调）可以转化为数字流动性缓冲和补充性货币政策工具，增强金融韧性而非破坏金融稳定。

Abstract: This study explores the potential impact of introducing a Central Bank Digital Currency (CBDC) on financial stability in an emerging dual-currency economy (Romania), where the domestic currency (RON) coexists with the euro. It develops an integrated analytical framework combining econometrics, machine learning, and behavioural modelling. CBDC adoption probabilities are estimated using XGBoost and logistic regression models trained on behavioural and macro-financial indicators rather than survey data. Liquidity stress simulations assess how banks would respond to deposit withdrawals resulting from CBDC adoption, while VAR, MSVAR, and SVAR models capture the macro-financial transmission of liquidity shocks into credit contraction and changes in monetary conditions. The findings indicate that CBDC uptake (co-circulating Digital RON and Digital EUR) would be moderate at issuance, amounting to around EUR 1 billion, primarily driven by digital readiness and trust in the central bank. The study concludes that a non-remunerated, capped CBDC, designed primarily as a means of payment rather than a store of value, can be introduced without compromising financial stability. In dual currency economies, differentiated holding limits for domestic and foreign digital currencies (e.g., Digital RON versus Digital Euro) are crucial to prevent uncontrolled euroisation and preserve monetary sovereignty. A prudent design with moderate caps, non remuneration, and macroprudential coordination can transform CBDC into a digital liquidity buffer and a complementary monetary policy instrument that enhances resilience and inclusion rather than destabilising the financial system.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [6] [Embedding Explainable AI in NHS Clinical Safety: The Explainability-Enabled Clinical Safety Framework (ECSF)](https://arxiv.org/abs/2511.11590)
*Robert Gigiu*

Main category: cs.CY

TL;DR: 提出了一个可解释性增强的临床安全框架（ECSF），将AI可解释性集成到现有医疗软件安全标准中，解决AI概率性行为与确定性安全标准之间的冲突。


<details>
  <summary>Details</summary>
Motivation: AI在NHS工作流程中日益普及，但其概率性和自适应行为与现有临床安全标准的确定性假设相冲突。现有标准DCB0129和DCB0160未定义如何证明AI特定的透明度、可解释性或模型漂移。

Method: 通过跨监管综合分析，将DCB条款与良好机器学习实践、NHS AI保证框架和欧盟AI法案原则进行映射，创建了一个连接监管条款、原则、ECSF检查点和合适可解释性输出的矩阵。

Result: ECSF引入了五个检查点：全局透明度用于危险识别、案例级可解释性用于验证、临床医生可用性用于评估、可追溯决策路径用于风险控制、纵向可解释性监测用于上市后监督。

Conclusion: ECSF将可解释性重新定义为临床安全保证的核心要素，弥合了确定性风险治理与AI概率性行为之间的差距，支持与GMLP、欧盟AI法案和NHS AI保证原则的一致性。

Abstract: Artificial intelligence (AI) is increasingly embedded in NHS workflows, but its probabilistic and adaptive behaviour conflicts with the deterministic assumptions underpinning existing clinical-safety standards. DCB0129 and DCB0160 provide strong governance for conventional software yet do not define how AI-specific transparency, interpretability, or model drift should be evidenced within Safety Cases, Hazard Logs, or post-market monitoring. This paper proposes an Explainability-Enabled Clinical Safety Framework (ECSF) that integrates explainability into the DCB0129/0160 lifecycle, enabling Clinical Safety Officers to use interpretability outputs as structured safety evidence without altering compliance pathways. A cross-regulatory synthesis mapped DCB clauses to principles from Good Machine Learning Practice, the NHS AI Assurance and T.E.S.T. frameworks, and the EU AI Act. The resulting matrix links regulatory clauses, principles, ECSF checkpoints, and suitable explainability outputs. ECSF introduces five checkpoints: global transparency for hazard identification, case-level interpretability for verification, clinician usability for evaluation, traceable decision pathways for risk control, and longitudinal interpretability monitoring for post-market surveillance. Techniques such as SHAP, LIME, Integrated Gradients, saliency mapping, and attention visualisation are mapped to corresponding DCB artefacts. ECSF reframes explainability as a core element of clinical-safety assurance, bridging deterministic risk governance with the probabilistic behaviour of AI and supporting alignment with GMLP, the EU AI Act, and NHS AI Assurance principles.

</details>


### [7] [Decision-Making Amid Information-Based Threats in Sociotechnical Systems: A Review](https://arxiv.org/abs/2511.11595)
*Aaron R. Allred,Erin E. Richardson,Sarah R. Bostrom,James Crum,Cara Spencer,Chad Tossell,Richard E. Niemeyer,Leanne Hirshfield,Allison P. A. Hayman*

Main category: cs.CY

TL;DR: 这篇综述论文整合了信息威胁现象研究和人类信息处理基础研究，识别了共同的认知机制，并提出了整合这些视角的未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 技术系统日益介入人类信息交换，扩大了信息影响力范围，既可能促进也可能破坏决策质量。当前研究碎片化，信息威胁现象评估与人类信息处理基础研究相互隔离。

Method: 通过综述整合两个领域的研究成果，识别共享的认知机制，这些机制调节对信息威胁的脆弱性并影响行为结果。

Result: 确定了介导信息威胁脆弱性的共同认知机制，这些机制塑造行为结果。

Conclusion: 需要整合信息威胁现象评估和人类信息处理基础研究，以减轻人类脆弱性并协调人机表征，为此提出了未来研究方向。

Abstract: Technological systems increasingly mediate human information exchange, spanning interactions among humans as well as between humans and artificial agents. The unprecedented scale and reliance on information disseminated through these systems substantially expand the scope of information-based influence that can both enable and undermine sound decision-making. Consequently, understanding and protecting decision-making today faces growing challenges, as individuals and organizations must navigate evolving opportunities and information-based threats across varied domains and information environments. While these risks are widely recognized, research remains fragmented: work evaluating information-based threat phenomena has progressed largely in isolation from foundational studies of human information processing. In this review, we synthesize insights from both domains to identify shared cognitive mechanisms that mediate vulnerability to information-based threats and shape behavioral outcomes. Finally, we outline directions for future research aimed at integrating these perspectives, emphasizing the importance of such integration for mitigating human vulnerabilities and aligning human-machine representations.

</details>


### [8] [EduAgentQG: A Multi-Agent Workflow Framework for Personalized Question Generation](https://arxiv.org/abs/2511.11635)
*Rui Jia,Min Zhang,Fengrui Liu,Bo Jiang,Kun Kuang,Zhongxiang Dai*

Main category: cs.CY

TL;DR: 提出了EduAgentQG，一个多智能体协作框架，用于生成高质量、多样化的个性化问题，通过五个专门智能体的迭代反馈循环提升问题质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 手动设计高质量个性化问题库耗时且难以满足多样化学习需求，现有自动化方法存在质量不稳定、多样性不足、与教育目标对齐不够的问题。

Method: 五个专门智能体协作框架：Planner生成结构化设计计划，Writer基于计划生成候选问题，Solver和Educator进行多维度二元评分，Checker进行最终验证，通过迭代反馈循环优化问题质量。

Result: 在两个数学问题数据集上的实验表明，EduAgentQG在问题多样性、目标一致性和整体质量方面优于现有的单智能体和多智能体方法。

Conclusion: 多智能体协作和迭代反馈循环能够生成既高质量又多样化的问题，同时保持与教育目标的一致性。

Abstract: High-quality personalized question banks are crucial for supporting adaptive learning and individualized assessment. Manually designing questions is time-consuming and often fails to meet diverse learning needs, making automated question generation a crucial approach to reduce teachers' workload and improve the scalability of educational resources. However, most existing question generation methods rely on single-agent or rule-based pipelines, which still produce questions with unstable quality, limited diversity, and insufficient alignment with educational goals. To address these challenges, we propose EduAgentQG, a multi-agent collaborative framework for generating high-quality and diverse personalized questions. The framework consists of five specialized agents and operates through an iterative feedback loop: the Planner generates structured design plans and multiple question directions to enhance diversity; the Writer produces candidate questions based on the plan and optimizes their quality and diversity using feedback from the Solver and Educator; the Solver and Educator perform binary scoring across multiple evaluation dimensions and feed the evaluation results back to the Writer; the Checker conducts final verification, including answer correctness and clarity, ensuring alignment with educational goals. Through this multi-agent collaboration and iterative feedback loop, EduAgentQG generates questions that are both high-quality and diverse, while maintaining consistency with educational objectives. Experiments on two mathematics question datasets demonstrate that EduAgentQG outperforms existing single-agent and multi-agent methods in terms of question diversity, goal consistency, and overall quality.

</details>


### [9] [Automatic generation of DRI Statements](https://arxiv.org/abs/2511.11655)
*Maurice Flechtner*

Main category: cs.CY

TL;DR: 本论文提出了一种自动化生成审议理由指数(DRI)陈述的方法，利用NLP和LLM技术大幅减少人工工作量，为社会科学研究提供可复制的AI集成模板。


<details>
  <summary>Details</summary>
Motivation: DRI是评估群体审议质量的重要指标，但其陈述生成过程复杂耗时，限制了实际应用。需要一种自动化方法来降低实施门槛。

Method: 采用先进的自然语言处理(NLP)和大语言模型(LLM)技术，开发了系统化的自动化DRI陈述生成框架。

Result: 成功实现了DRI陈述的自动化生成，显著减少了调查准备所需的人力投入，降低了进行综合审议过程评估的障碍。

Conclusion: 该研究不仅提供了DRI评估的自动化解决方案，还为将生成式人工智能整合到社会科学研究方法中提供了可复制的模板。

Abstract: Assessing the quality of group deliberation is essential for improving our understanding of deliberative processes. The Deliberative Reason Index (DRI) offers a sophisticated metric for evaluating group reasoning, but its implementation has been constrained by the complex and time-consuming process of statement generation. This thesis introduces an innovative, automated approach to DRI statement generation that leverages advanced natural language processing (NLP) and large language models (LLMs) to substantially reduce the human effort involved in survey preparation. Key contributions are a systematic framework for automated DRI statement generation and a methodological innovation that significantly lowers the barrier to conducting comprehensive deliberative process assessments. In addition, the findings provide a replicable template for integrating generative artificial intelligence into social science research methodologies.

</details>


### [10] [Generative AI as a Linguistic Equalizer in Global Science](https://arxiv.org/abs/2511.11687)
*Dragan Filimonovic,Christian Rutzer,Jeffrey Macher,Rolf Weder*

Main category: cs.CY

TL;DR: 生成式AI（特别是ChatGPT）正在帮助非英语国家的科研人员缩小与英语母语者在科学写作风格上的差距，尤其对语言距离较远的国家团队效果最明显。


<details>
  <summary>Details</summary>
Motivation: 英语在科学界的统治地位长期阻碍了非母语者的参与，生成式AI可能为解决这一不平等问题提供技术方案。

Method: 分析了2021-2024年间的565万篇科学论文，使用SciBERT文本嵌入模型测量非英语国家作者在GenAI辅助下与美英作者写作风格的相似度变化。

Result: ChatGPT发布后，GenAI辅助的出版物在语言风格上显著趋近于美英标准，且这种趋同效应随时间增长，对语言距离远的国家团队效果最强。

Conclusion: 生成式AI正在通过降低语言障碍来重塑全球科学交流，为非英语国家科研人员提供了语言平权的机会。

Abstract: For decades, the dominance of English has created a substantial barrier in global science, disadvantaging non-native speakers. The recent rise of generative AI (GenAI) offers a potential technological response to this long-standing inequity. We provide the first large-scale evidence testing whether GenAI acts as a linguistic equalizer in global science. Drawing on 5.65 million scientific articles published from 2021 to 2024, we compare GenAI-assisted and non-assisted publications from authors in non-English-speaking countries. Using text embeddings derived from a pretrained large language model (SciBERT), we measure each publication's linguistic similarity to a benchmark of scientific writing from U.S.-based authors and track stylistic convergence over time. We find significant and growing convergence for GenAI-assisted publications after the release of ChatGPT in late 2022. The effect is strongest for domestic coauthor teams from countries linguistically distant from English. These findings provide large-scale evidence that GenAI is beginning to reshape global science communication by reducing language barriers in research.

</details>


### [11] [Cost Transparency of Enterprise AI Adoption](https://arxiv.org/abs/2511.11761)
*Soogand Alavi,Salar Nozari,Andrea Luangrath*

Main category: cs.CY

TL;DR: 研究发现，在大型语言模型服务中，非礼貌的提示会显著增加输出令牌数量，导致企业成本上升，而礼貌提示则能减少令牌使用且不影响回答质量。


<details>
  <summary>Details</summary>
Motivation: 随着企业快速采用大型语言模型服务，其按令牌计费的定价模式带来了成本不可预测的问题，特别是输出令牌数量受用户语言风格影响而难以控制。

Method: 通过OpenAI API进行实验，比较不同礼貌程度的提示对输出令牌数量的影响。

Result: 非礼貌提示显著增加输出令牌数量，导致企业成本上升，而礼貌提示能减少令牌使用且不影响回答质量。

Conclusion: 当前LLM服务的定价模式缺乏透明度，需要新的方法来确保企业采用LLM服务的成本可预测和透明。

Abstract: Recent advances in large language models (LLMs) have dramatically improved performance on a wide range of tasks, driving rapid enterprise adoption. Yet, the cost of adopting these AI services is understudied. Unlike traditional software licensing in which costs are predictable before usage, commercial LLM services charge per token of input text in addition to generated output tokens. Crucially, while firms can control the input, they have limited control over output tokens, which are effectively set by generation dynamics outside of business control. This research shows that subtle shifts in linguistic style can systematically alter the number of output tokens without impacting response quality. Using an experiment with OpenAI's API, this study reveals that non-polite prompts significantly increase output tokens leading to higher enterprise costs and additional revenue for OpenAI. Politeness is merely one instance of a broader phenomenon in which linguistic structure can drive unpredictable cost variation. For enterprises integrating LLM into applications, this unpredictability complicates budgeting and undermines transparency in business-to-business contexts. By demonstrating how end-user behavior links to enterprise costs through output token counts, this work highlights the opacity of current pricing models and calls for new approaches to ensure predictable and transparent adoption of LLM services.

</details>


### [12] [Mental Health Generative AI is Safe, Promotes Social Health, and Reduces Depression and Anxiety: Real World Evidence from a Naturalistic Cohort](https://arxiv.org/abs/2511.11689)
*Thomas D. Hull,Lizhe Zhang,Patricia A. Arean,Matteo Malgaroli*

Main category: cs.CY

TL;DR: 评估用于心理健康的基础模型AI聊天机器人，结果显示能显著改善抑郁、焦虑症状，并提升希望感、社交互动等指标，且安全性良好。


<details>
  <summary>Details</summary>
Motivation: 开发可提供安全、个性化、可扩展心理健康支持的生成式AI聊天机器人，以解决传统心理健康服务的可及性问题。

Method: 单臂自然观察性研究，成年用户在2025年5-9月期间使用心理健康聊天机器人，每两周评估一次心理健康指标，持续6周，并在10周时进行最终随访。

Result: 用户PHQ-9和GAD-7评分显著降低且效果持续；希望感、行为激活、社交互动、孤独感和感知社会支持显著改善；参与度高且预测结果；安全护栏有效运行。

Conclusion: 初步证据表明心理健康GAI基础模型能提供可及、有吸引力、有效且安全的心理健康支持，支持早期随机设计研究结果，为现实世界应用提供前景。

Abstract: Generative artificial intelligence (GAI) chatbots built for mental health could deliver safe, personalized, and scalable mental health support. We evaluate a foundation model designed for mental health. Adults completed mental health measures while engaging with the chatbot between May 15, 2025 and September 15, 2025. Users completed an opt-in consent, demographic information, mental health symptoms, social connection, and self-identified goals. Measures were repeated every two weeks up to 6 weeks, and a final follow-up at 10 weeks. Analyses included effect sizes, and growth mixture models to identify participant groups and their characteristic engagement, severity, and demographic factors. Users demonstrated significant reductions in PHQ-9 and GAD-7 that were sustained at follow-up. Significant improvements in Hope, Behavioral Activation, Social Interaction, Loneliness, and Perceived Social Support were observed throughout and maintained at 10 week follow-up. Engagement was high and predicted outcomes. Working alliance was comparable to traditional care and predicted outcomes. Automated safety guardrails functioned as designed, with 76 sessions flagged for risk and all handled according to escalation policies. This single arm naturalistic observational study provides initial evidence that a GAI foundation model for mental health can deliver accessible, engaging, effective, and safe mental health support. These results lend support to findings from early randomized designs and offer promise for future study of mental health GAI in real world settings.

</details>


### [13] [Understanding the Representation of Older Adults in Motion Capture Locomotion Datasets](https://arxiv.org/abs/2511.11713)
*Yunkai Yu,Yingying Wang,Rong Zheng*

Main category: cs.CY

TL;DR: 该论文调查了41个公开运动捕捉数据集，发现老年人参与度低，且现有"老年风格"行走动作未能真实反映衰老特征，提出了量化评估方法来衡量老年风格行走动作的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有运动捕捉数据集中老年人代表性不足，且用年轻演员模拟的"老年风格"行走动作是否真实反映衰老特征尚未得到充分验证，这在医疗健康应用中尤为重要。

Method: 调查41个公开数据集，识别包含老年人动作的数据集；引入量化指标评估老年风格行走动作的保真度，使用对年龄敏感、抗噪声且适应数据稀缺的步态参数。

Result: 老年人仅占总体参与者的小部分，提供老年人全身运动数据的数据集很少；老年风格行走动作常表现出过度控制的模式，无法真实表征衰老特征。

Conclusion: 需要在运动数据集中改善老年人的代表性，并建立了量化评估老年风格行走动作质量的方法。

Abstract: The Internet of Things (IoT) sensors have been widely employed to capture human locomotions to enable applications such as activity recognition, human pose estimation, and fall detection. Motion capture (MoCap) systems are frequently used to generate ground truth annotations for human poses when training models with data from wearable or ambient sensors, and have been shown to be effective to synthesize data in these modalities. However, the representation of older adults, an increasingly important demographic in healthcare, in existing MoCap locomotion datasets has not been thoroughly examined. This work surveyed 41 publicly available datasets, identifying eight that include older adult motions and four that contain motions performed by younger actors annotated as old style. Older adults represent a small portion of participants overall, and few datasets provide full-body motion data for this group. To assess the fidelity of old-style walking motions, quantitative metrics are introduced, defining high fidelity as the ability to capture age-related differences relative to normative walking. Using gait parameters that are age-sensitive, robust to noise, and resilient to data scarcity, we found that old-style walking motions often exhibit overly controlled patterns and fail to faithfully characterize aging. These findings highlight the need for improved representation of older adults in motion datasets and establish a method to quantitatively evaluate the quality of old-style walking motions.

</details>


### [14] [CADD: A Chinese Traffic Accident Dataset for Statute-Based Liability Attribution](https://arxiv.org/abs/2511.11715)
*Yunfei Shen,Zhongcheng Wu*

Main category: cs.CY

TL;DR: CADD是中国首个基于法规的责任认定数据集，包含792个真实驾驶记录仪视频，采用"行为-责任-法规"标注框架，将感知数据与法律责任直接关联。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术发展，事故责任认定成为关键挑战。现有数据集缺乏法律推理所需的标注，无法支持责任判定。

Method: 构建包含792个真实驾驶记录仪视频的数据集，采用新颖的"行为-责任-法规"标注管道，提供细粒度对称行为标注、明确责任分配，并将每个案例与违反的中国交通法规条款关联。

Result: 建立了责任预测和可解释决策制定的基准，通过详细分析展示了CADD的实用性。

Conclusion: CADD通过直接连接感知数据与法律后果，为开发负责任且法律依据充分的自动驾驶系统提供了基础资源。

Abstract: As autonomous driving technology advances, the critical challenge evolves beyond collision avoidance to the \textbf{adjudication of liability} when accidents occur. Existing datasets, focused on detection and localization, lack the annotations required for this legal reasoning. To bridge this gap, we introduce the \textbf{C}hinese \textbf{A}ccident \textbf{D}uty-determination \textbf{D}ataset (\textbf{CADD}), the first benchmark for statute-based liability attribution. CADD contains 792 real-world driving recorder videos, each annotated within a novel \textbf{``Behavior--Liability--Statute''} pipeline. This framework provides \textbf{granular, symmetric behavior annotations}, clear responsibility assignments, and, uniquely, links each case to the specific \textbf{Chinese traffic law statute} violated. We demonstrate the utility of CADD through detailed analysis and establish benchmarks for liability prediction and explainable decision-making. By directly connecting perceptual data to legal consequences, CADD provides a foundational resource for developing accountable and legally-grounded autonomous systems.

</details>


### [15] [Weapons of Online Harassment: Menacing and Profiling Users via Social Apps](https://arxiv.org/abs/2511.11718)
*Sanjana Cheerla,Vaibhav Garg,Saikath Bhattacharya,Munindar P. Singh*

Main category: cs.CY

TL;DR: 通过分析300万条应用评论，识别出社交应用中两种主要骚扰形式（威胁和画像），开发了高召回率的骚扰检测模型，发现骚扰者多为女性身份，并通知了48个骚扰问题最严重的应用开发者。


<details>
  <summary>Details</summary>
Motivation: 社交应用作为社会技术系统，不仅传递技术功能还调节人际互动，可能无意中助长有害行为如网络骚扰。随着用户增多，骚扰事件也在增加。

Method: 构建包含300万条评论和1800个应用的数据集，开发计算模型识别表明骚扰的评论，分析骚扰类型和情感特征。

Result: 模型对威胁和画像两种骚扰形式的召回率分别达到90%和85%，识别出1395个存在骚扰问题的应用，发现骚扰者多为女性身份，负面评论中愤怒、厌恶和恐惧情绪更普遍。

Conclusion: 社交应用确实存在严重的骚扰问题，通过评论分析可以有效识别和量化这些问题，为开发者提供改进依据。

Abstract: Viewing social apps as sociotechnical systems makes clear that they are not mere pieces of technology but mediate human interaction and may unintentionally enable harmful behaviors like online harassment. As more users interact through social apps, instances of harassment increase.
  We observed that app reviews often describe harassment. Accordingly, we built a dataset of over 3 million reviews and 1,800 apps. We discovered that two forms of harassment are prevalent, Menacing and Profiling.
  We built a computational model for identifying reviews indicating harassment, achieving high recalls of 90% for Menacing and 85% for Profiling. We analyzed the data further to better understand the terrain of harassment. Surprisingly, abusers most often have female identities. Also, what distinguishes negative from neutral reviews is the greater prevalence of anger, disgust, and fear.
  Applying our model, we identified 1,395 apps enabling harassment and notified developers of the top 48 with the highest user-reported harassment.

</details>


### [16] [A framework for measuring and analyzing customer satisfaction at computer service companies using Lean Six Sigma](https://arxiv.org/abs/2511.11723)
*Mohammed Abboodi*

Main category: cs.CY

TL;DR: 提出一个结合六西格玛和SERVQUAL的集成框架，用于评估计算机服务行业的服务质量并识别客户不满意的根源


<details>
  <summary>Details</summary>
Motivation: 计算机服务行业竞争激烈，中小企业难以维持客户满意度，缺乏有效的服务质量评估系统是导致客户流失的关键因素

Method: 将六西格玛的核心原则与SERVQUAL工具结合，在DMAIC方法框架内实施，通过案例研究验证可行性

Result: 量化了满意度水平，识别出五个主要的客户需求未满足驱动因素，总体满意度水平较低

Conclusion: 解决这些根本原因有望提高客户满意度、降低获客成本并改善组织整体绩效

Abstract: The computer service industry has expanded rapidly over the past two decades, driven by the proliferation of computing technologies, the entry of large firms, and the availability of online diagnostic and troubleshooting tools. In this increasingly competitive environment, many small and medium sized enterprises struggle to maintain customer satisfaction as rivals deliver higher quality services at lower cost. This study addresses the absence of robust measurement systems for assessing service quality, a key factor underlying customer attrition, by proposing an integrated framework for evaluating satisfaction and identifying sources of dissatisfaction in computer services.
  The framework combines core principles of Six Sigma with the SERVQUAL instrument within a structured DMAIC methodology (Define, Measure, Analyze, Improve, and Control). SERVQUAL provides the service quality dimensions and gap analysis techniques, while Six Sigma supplies the data driven approach to measurement and improvement. The literature suggests limited prior work integrating Lean Six Sigma with SERVQUAL, and this study contributes by operationalizing that integration in a real world setting.
  A case study of a computer services company was conducted to demonstrate feasibility and effectiveness. Satisfaction levels were quantified, and root causes of dissatisfaction were identified. The analysis revealed a low overall satisfaction level and five primary drivers of unmet customer requirements. Addressing these causes is expected to increase customer satisfaction, lower customer acquisition costs, and improve overall organizational performance.

</details>


### [17] [On the Influence of Artificial Intelligence on Human Problem-Solving: Empirical Insights for the Third Wave in a Multinational Longitudinal Pilot Study](https://arxiv.org/abs/2511.11738)
*Matthias Huemmer,Theophile Shyiramunda,Franziska Durner,Michelle J. Cummings-Koether*

Main category: cs.CY

TL;DR: 第三波跨国纵向研究显示，人类与AI协作已形成混合问题解决文化，但存在验证缺陷。研究发现普遍AI采用（95.7%有先验知识，100%使用ChatGPT），但存在信念-表现差距（高达80.8个百分点）和证明-信念差距（高达-16.8个百分点），表明可靠AI辅助工作的关键限制是解决方案验证而非生成。


<details>
  <summary>Details</summary>
Motivation: 研究人类与AI协作在问题解决情境中的演进范式，基于先前研究波次，探索混合问题解决文化的形成和系统性认知差距。

Method: 采用跨国纵向研究方法（n=23参与者），通过行为数据和跨复杂度级别的问题情景，分析AI工具在结构化认知工作流程中的战略整合。

Result: 发现普遍AI采用，主要部署模式为"思考、互联网、ChatGPT、进一步处理"（39.1%），但存在验证缺陷，并识别出两个系统性认知差距：信念-表现差距和证明-信念差距。

Conclusion: 教育和技术干预必须优先考虑验证支架（包括假设文档协议、充分性标准清单和三角验证程序），以加强人类在这一新认知生态系统中的关键验证者角色。

Abstract: This article presents the results and their discussion for the third wave (with n=23 participants) within a multinational longitudinal study that investigates the evolving paradigm of human-AI collaboration in problem-solving contexts. Building upon previous waves, our findings reveal the consolidation of a hybrid problem-solving culture characterized by strategic integration of AI tools within structured cognitive workflows. The data demonstrate near-universal AI adoption (95.7% with prior knowledge, 100% ChatGPT usage) primarily deployed through human-led sequences such as "Think, Internet, ChatGPT, Further Processing" (39.1%). However, this collaboration reveals a critical verification deficit that escalates with problem complexity. We empirically identify and quantify two systematic epistemic gaps: a belief-performance gap (up to +80.8 percentage points discrepancy between perceived and actual correctness) and a proof-belief gap (up to -16.8 percentage points between confidence and verification capability). These findings, derived from behavioral data and problem vignettes across complexity levels, indicate that the fundamental constraint on reliable AI-assisted work is solution validation rather than generation. The study concludes that educational and technological interventions must prioritize verification scaffolds (including assumption documentation protocols, adequacy criteria checklists, and triangulation procedures) to fortify the human role as critical validator in this new cognitive ecosystem.

</details>


### [18] [Taxation and the relationship between payments and time spent](https://arxiv.org/abs/2511.11741)
*Christopher Mantzaris,Ajda Fosner*

Main category: cs.CY

TL;DR: 研究发现纳税合规时间与纳税金额之间存在正相关关系，表明简化税收流程可以减少纳税人的行政负担和社会成本。


<details>
  <summary>Details</summary>
Motivation: 税收行政工作对社会成本高昂，纳税人花费大量时间处理税务行政工作会影响财富创造。研究旨在探索纳税合规时间与纳税金额之间的关系，以更好地理解税收行政成本。

Method: 使用PwC和世界银行2019年"纳税"报告数据，分析全球大多数司法管辖区的纳税合规时间(X)和纳税金额(Y)。进行了6组测试，每组测试需满足5个要求：正斜率、满足p值和r值、高互信息、散点图结论一致。前2组测试使用原始数据，中间2组排除城市数据，最后2组排除城市和异常值。

Result: 所有6组测试均满足5个要求，表明纳税合规时间与纳税金额之间存在正相关关系。总纳税金额的相关性更强。4个验证性测试确认了方法的有效性。

Conclusion: 通过简化税收流程（包括税收征收和支付），可以减少纳税人的税务处理时间，从而降低社会的整体税收行政成本。

Abstract: Tax work is costly for society: Administrative tax labour is typically to a high degree shuffled off the government and onto every taxpayer by law. The higher the burden of any tax system, the costlier for society, as taxpayers are unable to engage in proper wealth creation when being kept busy with administrative tax work. This research finds evidence for a relationship between hours spent to comply with taxes and amount of tax payment. These findings help better understand tax administrative costs and ultimately may help reduce them. PwC and World Bank's final "Paying taxes"-publication (2019) contains tax data for most of the world's jurisdictions, in particular annual hours spent to comply with tax obligations (X) and annual amount of tax payments (Y), both for the year 2019. X and Y were plotted in 6 tests. A positive slope, satisfying p and r values, high mutual information and finally a conclusive scatter plot picture were the 5 requirements that all needed to be met to confirm a positive relationship between X and Y. The first 2 tests did not make any adjustments to the data, the next 2 tests removed cities --thereby avoiding the double counting of jurisdictions-- and the final 2 tests removed cities and outliers. Each test pair uses for Y first total number of payments; and for each second test the number of other payments, which excludes income tax payments for profit and labour. All 5 requirements were met in every of the 6 tests, indicating a positive dependence. In addition, 4 confirmatory tests validate the methodology. The found relationship is noticeably stronger for the total number of tax payments. Findings indicate that taxpayers' time spent on tax, and thereby society's overall tax administrative costs, could be reduced by simplifying taxation processes, including tax collection and payments.

</details>


### [19] [Brazil Data Commons: A Platform for Unifying and Integrating Brazil's Public Data](https://arxiv.org/abs/2511.11755)
*Isadora Cristina,Ramon Gonze,Jônatas Santos,Julio Reis,Mário Alvim,Bernardo Queiroz,Fabrício Benevenuto*

Main category: cs.CY

TL;DR: 巴西数据共享平台通过统一语义框架整合分散的巴西数据集，解决数据碎片化和互操作性问题，支持数据发现、集成和可视化。


<details>
  <summary>Details</summary>
Motivation: 巴西公共数据碎片化、标准不一致和互操作性有限，阻碍了有效研究、循证决策和数据驱动洞察的获取。

Method: 采用全球认可的语义本体和互操作数据标准，构建统一语义框架，提供用户友好界面、简单查询机制和灵活数据访问选项。

Result: 平台将分散数据集转化为集成且易于导航的资源，使研究人员、政策制定者和公众能够获得有意义的见解并做出明智决策。

Conclusion: 巴西数据共享平台通过统一语义框架成功整合了巴西的复杂数据集，为理解社会、经济和环境景观提供了更深入的视角。

Abstract: The fragmentation of public data in Brazil, coupled with inconsistent standards and limited interoperability, hinders effective research, evidence-based policymaking and access to data-driven insights. To address these issues, we introduce Brazil Data Commons, a platform that unifies various Brazilian datasets under a common semantic framework, enabling the seamless discovery, integration and visualization of information from different domains. By adopting globally recognized ontologies and interoperable data standards, Brazil Data Commons aligns with the principles of the broader Data Commons ecosystem and places Brazilian data in a global context. Through user-friendly interfaces, straightforward query mechanisms and flexible data access options, the platform democratizes data use and enables researchers, policy makers, and the public to gain meaningful insights and make informed decisions. This paper illustrates how Brazil Data Commons transforms scattered datasets into an integrated and easily navigable resource that allows a deeper understanding of Brazil's complex social, economic and environmental landscape.

</details>


### [20] [Bridging the Skills Gap: A Course Model for Modern Generative AI Education](https://arxiv.org/abs/2511.11757)
*Anya Bardach,Hamilton Murrah*

Main category: cs.CY

TL;DR: 该论文探讨了生成式AI工具普及对教育环境的影响，开发了一门面向计算机科学学生的生成式AI应用课程，并通过调查证明课程的有效性和价值。


<details>
  <summary>Details</summary>
Motivation: 生成式AI能力在业界日益受重视，但在高等教育中缺乏系统教学，学生自行实验缺乏指导，导致教育与实践脱节。

Method: 在一所私立研究型大学开发了面向计算机科学本科和研究生生成式AI工具在软件开发中应用的课程，采用混合方法调查评估课程效果。

Result: 调查显示学生普遍认为该课程具有价值和有效性，有助于提升就业市场准备度。

Conclusion: 需要在计算机科学及其他领域推广此类课程，系统培养学生负责任且专业地使用生成式AI工具的能力。

Abstract: Research on how the popularization of generative Artificial Intelligence (AI) tools impacts learning environments has led to hesitancy among educators to teach these tools in classrooms, creating two observed disconnects. Generative AI competency is increasingly valued in industry but not in higher education, and students are experimenting with generative AI without formal guidance. The authors argue students across fields must be taught to responsibly and expertly harness the potential of AI tools to ensure job market readiness and positive outcomes. Computer Science trajectories are particularly impacted, and while consistently top ranked U.S. Computer Science departments teach the mechanisms and frameworks underlying AI, few appear to offer courses on applications for existing generative AI tools. A course was developed at a private research university to teach undergraduate and graduate Computer Science students applications for generative AI tools in software development. Two mixed method surveys indicated students overwhelmingly found the course valuable and effective. Co-authored by the instructor and one of the graduate students, this paper explores the context, implementation, and impact of the course through data analysis and reflections from both perspectives. It additionally offers recommendations for replication in and beyond Computer Science departments. This is the extended version of this paper to include technical appendices.

</details>


### [21] [Demystify, Use, Reflect: Preparing students to be informed LLM-users](https://arxiv.org/abs/2511.11764)
*Nikitha Donekal Chandrashekar,Sehrish Basir Nizamani,Margaret Ellis,Naren Ramakrishnan*

Main category: cs.CY

TL;DR: 将后CS1课程转型为整合大语言模型的教学，培养学生批判性使用AI的能力，包括LLM工作原理、工具使用、伦理问题和反思活动。


<details>
  <summary>Details</summary>
Motivation: 帮助学生发展有意义且负责任地与AI互动的技能，为AI集成的未来做好准备。

Method: 课程包含LLM工作原理教学、当前工具接触、伦理讨论、学生反思活动，课堂中演示LLM输出使用与验证，指导学生将LLM作为问题解决环节的一部分，并要求学生披露LLM协助情况。

Result: 学生对LLM工作原理的理解更加技术化，对LLM的验证和使用变得更加敏锐和协作。

Conclusion: 这些策略可用于其他课程，为学生应对AI集成的未来做好准备。

Abstract: We transitioned our post-CS1 course that introduces various subfields of computer science so that it integrates Large Language Models (LLMs) in a structured, critical, and practical manner. It aims to help students develop the skills needed to engage meaningfully and responsibly with AI. The course now includes explicit instruction on how LLMs work, exposure to current tools, ethical issues, and activities that encourage student reflection on personal use of LLMs as well as the larger evolving landscape of AI-assisted programming. In class, we demonstrate the use and verification of LLM outputs, guide students in the use of LLMs as an ingredient in a larger problem-solving loop, and require students to disclose and acknowledge the nature and extent of LLM assistance. Throughout the course, we discuss risks and benefits of LLMs across CS subfields. In our first iteration of the course, we collected and analyzed data from students pre and post surveys. Student understanding of how LLMs work became more technical, and their verification and use of LLMs shifted to be more discerning and collaborative. These strategies can be used in other courses to prepare students for the AI-integrated future.

</details>


### [22] [Scaling Equitable Reflection Assessment in Education via Large Language Models and Role-Based Feedback Agents](https://arxiv.org/abs/2511.11772)
*Chenyu Zhang,Xiaohang Luo*

Main category: cs.CY

TL;DR: 提出一个基于多智能体LLM的系统，用于大规模提供公平的形成性反馈，通过五个协调的角色智能体来评分和生成学习者反馈，在AI素养项目中验证了接近专家水平的评分一致性和高质量反馈。


<details>
  <summary>Details</summary>
Motivation: 解决大规模或资源匮乏课程中形成性反馈难以公平实施的问题，因为教师缺乏时间和资源来审阅每个学生的反思，导致支持缺口。

Method: 使用五个协调的基于角色的LLM智能体（评估者、公平监控者、元认知教练、聚合者和反思审阅者），通过共享评分标准对学习者反思进行评分，并生成简短、偏见感知的学习者反馈。

Result: 在12次AI素养项目中，系统产生的评分标准分数接近专家水平的一致性，训练评分者认为AI生成的评论有帮助、有同理心且与教学目标一致。

Conclusion: 多智能体LLM系统能够以人类评分者无法达到的规模和速度提供公平、高质量的形成性反馈，为实现任何课程规模和情境下的反馈丰富学习指明了方向。

Abstract: Formative feedback is widely recognized as one of the most effective drivers of student learning, yet it remains difficult to implement equitably at scale. In large or low-resource courses, instructors often lack the time, staffing, and bandwidth required to review and respond to every student reflection, creating gaps in support precisely where learners would benefit most. This paper presents a theory-grounded system that uses five coordinated role-based LLM agents (Evaluator, Equity Monitor, Metacognitive Coach, Aggregator, and Reflexion Reviewer) to score learner reflections with a shared rubric and to generate short, bias-aware, learner-facing comments. The agents first produce structured rubric scores, then check for potentially biased or exclusionary language, add metacognitive prompts that invite students to think about their own thinking, and finally compose a concise feedback message of at most 120 words. The system includes simple fairness checks that compare scoring error across lower and higher scoring learners, enabling instructors to monitor and bound disparities in accuracy. We evaluate the pipeline in a 12-session AI literacy program with adult learners. In this setting, the system produces rubric scores that approach expert-level agreement, and trained graders rate the AI-generated comments as helpful, empathetic, and well aligned with instructional goals. Taken together, these results show that multi-agent LLM systems can deliver equitable, high-quality formative feedback at a scale and speed that would be impossible for human graders alone. More broadly, the work points toward a future where feedback-rich learning becomes feasible for any course size or context, advancing long-standing goals of equity, access, and instructional capacity in education.

</details>


### [23] [Data-driven strategic sensor placement for detecting disinfection by-products in water distribution networks](https://arxiv.org/abs/2511.11775)
*Aristotelis Magklis,Andreas Kamilaris*

Main category: cs.CY

TL;DR: DBPFinder是一个用于优化饮用水管网中消毒副产物检测传感器布点的仿真软件，在葡萄牙科英布拉的真实管网中进行了测试，能够同时考虑多个性能目标来提供最优的传感器布点方案。


<details>
  <summary>Details</summary>
Motivation: 消毒副产物是氯化饮用水中的有害污染物，其形成受多种环境参数影响，难以在到达家庭前监测。由于消毒副产物种类繁多且传感器部署数量有限，需要高效优化传感器布点位置。

Method: 开发了DBPFinder仿真软件，通过多目标优化方法为水处理厂操作人员提供基于需求的传感器布点推荐方案。

Result: 在真实水网中的多项实验验证了该软件的正确性、相关性、效率和可扩展性。

Conclusion: DBPFinder能够有效辅助水处理厂优化消毒副产物检测传感器的布点策略，提高监测效率。

Abstract: Disinfection byproducts are contaminants that can cause long-term effects on human health, occurring in chlorinated drinking water when the disinfectant interacts with natural organic matter. Their formation is affected by many environmental parameters, making it difficult to monitor and detect disinfection byproducts before they reach households. Due to the large variety of disinfection byproduct compounds that can be formed in water distribution networks, plus the constrained number of sensors that can be deployed throughout a system to monitor these contaminants, it is of outmost importance to place sensory equipment efficiently and optimally. In this paper, we present DBPFinder, a simulation software that assists in the strategic sensor placement for detecting disinfection byproducts, tested at a real-world water distribution network in Coimbra, Portugal. This simulator addresses multiple performance objectives at once in order to provide optimal solution placement recommendations to water utility operators based on their needs. A number of different experiments performed indicate its correctness, relevance, efficiency and scalability.

</details>


### [24] [Differences in the Moral Foundations of Large Language Models](https://arxiv.org/abs/2511.11790)
*Peter Kirgis*

Main category: cs.CY

TL;DR: 使用道德基础理论分析大型语言模型的伦理判断，发现不同模型之间存在道德基础差异，且与人类基准存在偏差，这种差异随模型能力增强而增加。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在政治、商业和教育等关键领域应用日益广泛，但其规范性伦理判断本质仍不透明，需要从道德心理学角度进行训练和评估。

Method: 使用Jonathan Haidt的道德基础理论对主要模型提供商的广泛模型进行合成实验，通过多种描述性统计方法分析LLM响应相对于原始调查中人类基准的偏差和方差。

Result: 模型之间依赖不同的道德基础，且与全国代表性人类基准存在差异，这些差异随着模型能力的增强而增加。

Conclusion: 这项工作旨在推动使用道德基础理论进一步分析LLM，包括对开源模型的微调，以及政策制定者更深入地思考道德基础对LLM对齐的重要性。

Abstract: Large language models are increasingly being used in critical domains of politics, business, and education, but the nature of their normative ethical judgment remains opaque. Alignment research has, to date, not sufficiently utilized perspectives and insights from the field of moral psychology to inform training and evaluation of frontier models. I perform a synthetic experiment on a wide range of models from most major model providers using Jonathan Haidt's influential moral foundations theory (MFT) to elicit diverse value judgments from LLMs. Using multiple descriptive statistical approaches, I document the bias and variance of large language model responses relative to a human baseline in the original survey. My results suggest that models rely on different moral foundations from one another and from a nationally representative human baseline, and these differences increase as model capabilities increase. This work seeks to spur further analysis of LLMs using MFT, including finetuning of open-source models, and greater deliberation by policymakers on the importance of moral foundations for LLM alignment.

</details>


### [25] [A Leakage-Aware Data Layer For Student Analytics: The Capire Framework For Multilevel Trajectory Modeling](https://arxiv.org/abs/2511.11866)
*H. R. Paz*

Main category: cs.CY

TL;DR: 提出了一个防数据泄漏的学生轨迹分析数据层，通过定义观察时间价值(VOT)来严格分离观察窗口和结果预测期，并构建了四级特征工程框架用于学生辍学预测。


<details>
  <summary>Details</summary>
Motivation: 现有的学生辍学预测模型虽然准确，但往往依赖机会主义特征集且存在未记录的数据泄漏问题，限制了模型的解释能力和实际应用价值。

Method: 提出了CAPIRE框架，构建四级特征工程：N1(个人和社会经济属性)、N2(入学时刻和学业历史)、N3(课程摩擦和表现)、N4(机构和宏观环境变量)，并引入VOT作为核心设计参数防止数据泄漏。

Result: 在长周期工程项目(1,343名学生，约57%辍学率)中应用，UMAP+DBSCAN流程发现了13个轨迹原型，包括'早期结构危机'、'持续摩擦'和'隐藏脆弱性'等模式，并通过统计测试证实了这些原型的稳健性和时间稳定性。

Conclusion: 该方法将特征工程从技术步骤转变为核心方法学产物，为保留理论、早期预警系统以及未来因果推理和基于代理的建模提供了有纪律的桥梁。

Abstract: Predictive models for student dropout, while often accurate, frequently rely on opportunistic feature sets and suffer from undocumented data leakage, limiting their explanatory power and institutional usefulness. This paper introduces a leakage-aware data layer for student trajectory analytics, which serves as the methodological foundation for the CAPIRE framework for multilevel modelling. We propose a feature engineering design that organizes predictors into four levels: N1 (personal and socio-economic attributes), N2 (entry moment and academic history), N3 (curricular friction and performance), and N4 (institutional and macro-context variables)As a core component, we formalize the Value of Observation Time (VOT) as a critical design parameter that rigorously separates observation windows from outcome horizons, preventing data leakage by construction. An illustrative application in a long-cycle engineering program (1,343 students, ~57% dropout) demonstrates that VOT-restricted multilevel features support robust archetype discovery. A UMAP + DBSCAN pipeline uncovers 13 trajectory archetypes, including profiles of "early structural crisis," "sustained friction," and "hidden vulnerability" (low friction but high dropout). Bootstrap and permutation tests confirm these archetypes are statistically robust and temporally stable. We argue that this approach transforms feature engineering from a technical step into a central methodological artifact. This data layer serves as a disciplined bridge between retention theory, early-warning systems, and the future implementation of causal inference and agent-based modelling (ABM) within the CAPIRE program.

</details>


### [26] [Educators on the Frontline: Philosophical and Realistic Perspectives on Integrating ChatGPT into the Learning Space](https://arxiv.org/abs/2511.11960)
*Surajit Das,Peu Majumder,Aleksei Eliseev*

Main category: cs.CY

TL;DR: 本研究通过调查140名俄罗斯大学教育工作者，提出了一个包含7个子空间的"学习空间"理论模型来分析AI整合的影响，发现大多数教育者有条件支持ChatGPT整合，但担忧其对批判性思维的影响。


<details>
  <summary>Details</summary>
Motivation: 超越关于AI在教育中未来的恐慌性讨论，系统性地了解大学教育工作者这一关键利益相关者对ChatGPT整合的结构化、基于实际的看法。

Method: 提出了"学习空间"理论模型（包含7个子空间），通过量化调查140名俄罗斯大学教育工作者，使用二元标记系统分析关键指标的接受度。

Result: 大多数教育者有条件支持ChatGPT整合，前提是评估方法转变和剽窃检测工具可用；教育者普遍拒绝AI会削弱其重要性的观点，认为角色从信息传递者转变为批判性参与促进者。

Conclusion: ChatGPT不是教育的破坏者，而是必要演变的催化剂；提出了PIPE模型（教学法、基础设施、政策、教育）作为负责任整合的战略框架。

Abstract: The rapid emergence of Generative AI, particularly ChatGPT, has sparked a global debate on the future of education, often characterized by alarmism and speculation. Moving beyond this, this study investigates the structured, grounded perspectives of a key stakeholder group: university educators. It proposes a novel theoretical model that conceptualizes the educational environment as a "Learning Space" composed of seven subspaces to systematically identify the impact of AI integration. This framework was operationalized through a quantitative survey of 140 Russian university educators, with responses analyzed using a binary flagging system to measure acceptance across key indicators. The results reveal a strong but conditional consensus: a majority of educators support ChatGPT's integration, contingent upon crucial factors such as the transformation of assessment methods and the availability of plagiarism detection tools. However, significant concerns persist regarding its impact on critical thinking. Educators largely reject the notion that AI diminishes their importance, viewing their role as evolving from information-deliverer to facilitator of critical engagement. The study concludes that ChatGPT acts less as a destroyer of education and more as a catalyst for its necessary evolution, and proposes the PIPE Model (Pedagogy, Infrastructure, Policy, Education) as a strategic framework for its responsible integration. This research provides a data-driven, model-based analysis of educator attitudes, offering a nuanced alternative to the polarized discourse surrounding AI in education.

</details>


### [27] [Leveraging Large Language Models for Career Mobility Analysis: A Study of Gender, Race, and Job Change Using U.S. Online Resume Profiles](https://arxiv.org/abs/2511.12010)
*Palakorn Achananuparp,Connie Xu,Yao Lu,Xavier Jayaraj Siddarth Ashok,Ee-Peng Lim*

Main category: cs.CY

TL;DR: 基于在线简历数据的大规模职业流动性分析，发现公司内职位变动对晋升最有利，女性和黑人大学毕业生从工作变动中获得的回报显著低于男性和白人同行。


<details>
  <summary>Details</summary>
Motivation: 研究性别、种族和工作变动选择如何影响美国大学毕业生向上职业流动性的差异，解决现有数据中人口属性缺失、工资数据缺失和职业标签噪声等挑战。

Method: 使用AI方法处理数据挑战，开发基于大语言模型的FewSOC职业分类方法，分析228,710条职业轨迹，采用多级敏感性分析验证结果稳健性。

Result: 公司内职位变动对向上流动性促进作用最强，其次是跨公司职位变动和跨公司平级调动。女性和黑人毕业生从工作变动中获得的回报显著较低。

Conclusion: 职业流动性存在显著的性别和种族差异，这些差异对集群层面的异质性具有稳健性，并揭示了额外的交叉性模式。

Abstract: We present a large-scale analysis of career mobility of college-educated U.S. workers using online resume profiles to investigate how gender, race, and job change options are associated with upward mobility. This study addresses key research questions of how the job changes affect their upward career mobility, and how the outcomes of upward career mobility differ by gender and race. We address data challenges -- such as missing demographic attributes, missing wage data, and noisy occupation labels -- through various data processing and Artificial Intelligence (AI) methods. In particular, we develop a large language models (LLMs) based occupation classification method known as FewSOC that achieves accuracy significantly higher than the original occupation labels in the resume dataset. Analysis of 228,710 career trajectories reveals that intra-firm occupation change has been found to facilitate upward mobility most strongly, followed by inter-firm occupation change and inter-firm lateral move. Women and Black college graduates experience significantly lower returns from job changes than men and White peers. Multilevel sensitivity analyses confirm that these disparities are robust to cluster-level heterogeneity and reveal additional intersectional patterns.

</details>


### [28] [Impact of UK Postgraduate Student Experiences on Academic Performance in Blended Learning: A Data Analytics Approach](https://arxiv.org/abs/2511.12320)
*Muhidin Mohamed,Shubhadeep Mukherjee,Bhavana Baad*

Main category: cs.CY

TL;DR: 本文研究了英国大学研究生混合学习环境中学生不同维度的学习体验与学业成就之间的关系，发现结合教学存在感和社会存在感的学习活动以及通过有效反馈提供的定制化学术支持对研究生混合学习成功至关重要。


<details>
  <summary>Details</summary>
Motivation: 混合学习已成为英国及全球高等教育的主导模式，特别是在COVID-19大流行之后。虽然这些教育变革带来了学习灵活性和资源获取的便利，但也暴露了学生在混合学习环境中如何构建成功学习的新挑战。

Method: 采用多种数据分析技术组合，包括可视化、统计检验、回归分析和潜在剖面分析，基于对255名研究生的调查数据，并通过探究社区(CoI)框架进行整体解释。

Result: 实证结果表明，结合教学存在感和社会存在感的学习活动，以及通过有效反馈提供的定制化学术支持是混合学习背景下研究生成功体验的关键要素。研究识别了四种基于不同CoI存在感参与方式的独特学生档案。

Conclusion: 本研究通过识别人口统计学、体验性和心理因素对学业成果的各种影响方式，推进了对学生成功的理解。在理论层面，通过整合学习者异质性概念，为CoI框架的扩展做出了贡献。

Abstract: Blended learning has become a dominant educational model in higher education in the UK and worldwide, particularly after the COVID-19 pandemic. This is further enriched with accompanying pedagogical changes, such as strengthened asynchronous learning, and the use of AI (from ChatGPT and all other similar tools that followed) and other technologies to aid learning. While these educational transformations have enabled flexibility in learning and resource access, they have also exposed new challenges on how students can construct successful learning in hybrid learning environments. In this paper, we investigate the interaction between different dimensions of student learning experiences (ranging from perceived acceptance of teaching methods and staff support/feedback to learning pressure and student motivation) and academic achievement within the context of postgraduate blended learning in UK universities. To achieve this, we employed a combination of several data analytics techniques including visualization, statistical tests, regression analysis, and latent profile analysis. Our empirical results (based on a survey of 255 postgraduate students and holistically interpreted via the Community of Inquiry (CoI) framework) demonstrated that learning activities combining teaching and social presences, and tailored academic support through effective feedback are critical elements for successful postgraduate experience in blended learning contexts. Regarding contributions, this research advances the understanding of student success by identifying the various ways demographic, experiential, and psychological factors impact academic outcomes. And in theoretical terms, it contributes to the extension of the CoI framework by integrating the concept of learner heterogeneity and identifying four distinct student profiles based on how they engage in the different CoI presences.

</details>


### [29] [Cultural Awareness, Stereotypes and Communication Skills in Intercultural Communication: The Algerian Participants Perspective](https://arxiv.org/abs/2511.12369)
*Mohamed Amine Kada Zair*

Main category: cs.CY

TL;DR: 阿尔及利亚参与者在多元文化环境中的文化意识、刻板印象与沟通技能关系研究


<details>
  <summary>Details</summary>
Motivation: 探讨在多元文化环境中工作的阿尔及利亚参与者的文化意识、刻板思维与跨文化沟通技能之间的关系

Method: 对40名受访者进行定量问卷调查，评估文化意识水平、刻板思维存在情况以及跨文化沟通技能有效性

Result: 文化意识普遍较高，但某些刻板印象仍影响他人认知和沟通效率；文化意识较高的参与者表现出更好的沟通技能和较低的刻板印象水平

Conclusion: 跨文化能力培养和教育项目对于减少偏见、促进多元环境中的相互理解具有重要意义

Abstract: This study explores the relationship between cultural awareness, stereotypes, and communication skills among Algerian participants working or studying in multicultural environments. A quantitative questionnaire was administered to 40 respondents to evaluate their levels of cultural awareness, the presence of stereotypical thinking, and the effectiveness of their intercultural communication skills. Results revealed that while cultural awareness was generally high, certain stereotypes still influenced the perception of others and impacted communication efficiency. Participants with higher cultural awareness demonstrated better communication skills and lower levels of stereotyping. These findings underline the importance of intercultural competence and education programs in reducing prejudice and fostering mutual understanding in diverse contexts.

</details>


### [30] [Political Advertising on Facebook During the 2022 Australian Federal Election: A Social Identity Perspective](https://arxiv.org/abs/2511.12426)
*Stefano Civelli,Pietro Bernardelle,Frank Mols,Gianluca Demartini*

Main category: cs.CY

TL;DR: 基于Meta广告库分析2022年澳大利亚联邦选举期间Facebook和Instagram政治广告，揭示各党派在支出、覆盖范围和说服策略上的显著差异，并通过社会认同理论解释其竞选策略。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的定向广告改变了政治营销策略，监控这些数字活动对于维护民主进程的透明度和问责制至关重要。

Method: 利用Meta广告库分析2022年澳大利亚联邦选举期间的政治广告，研究主要政治行为体的时间、人口统计和地理分布模式，并基于社会认同理论进行解释。

Result: 发现广告活动在选举临近时显著增加，在媒体静默期前达到顶峰；各党派针对年轻人群采用不同的目标策略，存在性别差异；广告区域分布与人口密度基本一致；主要政党强调党派名称和对手，小党则关注具体议题。

Conclusion: 在强制投票背景下，主要政党通过强化党派认同防止选民流失，而小党则通过议题认同吸引不满选民的支持。

Abstract: The spread of targeted advertising on social media platforms has revolutionized political marketing strategies. Monitoring these digital campaigns is essential for maintaining transparency and accountability in democratic processes. Leveraging Meta's Ad Library, we analyze political advertising on Facebook and Instagram during the 2022 Australian federal election campaign. We investigate temporal, demographic, and geographical patterns in the advertising strategies of major Australian political actors to establish an empirical evidence base, and interpret these findings through the lens of Social Identity Theory (SIT). Our findings not only reveal significant disparities in spending and reach among parties, but also in persuasion strategies being deployed in targeted online campaigns. We observe a marked increase in advertising activity as the election approached, peaking just before the mandated media blackout period. Demographic analysis shows distinct targeting strategies, with parties focusing more on younger demographics and exhibiting gender-based differences in ad impressions. Regional distribution of ads largely mirrored population densities, with some parties employing more targeted approaches in specific states. Moreover, we found that parties emphasized different themes aligned with their ideologies-major parties focused on party names and opponents, while smaller parties emphasized issue-specific messages. Drawing on SIT, we interpret these findings within Australia's compulsory voting context, suggesting that parties employed distinct persuasion strategies. With turnout guaranteed, major parties focused on reinforcing partisan identities to prevent voter defection, while smaller parties cultivated issue-based identities to capture the support of disaffected voters who are obligated to participate.

</details>


### [31] [AI and Supercomputing are Powering the Next Wave of Breakthrough Science - But at What Cost?](https://arxiv.org/abs/2511.12686)
*Stefano Bianchini,Aldo Geuna,Fazliddin Shermatov*

Main category: cs.CY

TL;DR: AI与高性能计算的结合使科研论文产生新概念的可能性提高3倍，进入高被引论文的可能性提高5倍，但加剧了全球计算资源和专业知识的获取不平等


<details>
  <summary>Details</summary>
Motivation: 量化AI和高性能计算对科学发现的联合影响，了解这两种技术如何共同塑造科研产出

Method: 基于2000-2024年间500多万篇科学论文的元数据，分析AI和HPC在27个研究领域的交互作用

Result: 结合AI和HPC的论文比传统研究更可能引入新概念（3倍）和成为高被引论文（5倍），但这种融合也加深了全球在计算能力和专业知识获取方面的不平等

Conclusion: 科学发现的未来不仅取决于算法和计算能力，还取决于世界如何公平地分享这些变革性工具

Abstract: Artificial intelligence (AI) and high-performance computing (HPC) are rapidly becoming the engines of modern science. However, their joint effect on discovery has yet to be quantified at scale. Drawing on metadata from over five million scientific publications (2000-2024), we identify how AI and HPC interact to shape research outcomes across 27 fields. Papers combining the two technologies are up to three times more likely to introduce novel concepts and five times more likely to reach top-cited status than conventional work. This convergence of AI and HPC is redefining the frontier of scientific creativity but also deepening global inequalities in access to computational power and expertise. Our findings suggest that the future of discovery will depend not only on algorithms and compute, but also on how equitably the world shares these transformative tools.

</details>


### [32] [The Unspoken Crisis of Learning: The Surging Zone of No Development](https://arxiv.org/abs/2511.12822)
*Euzeli C. dos Santos,Tracey Birdwell*

Main category: cs.CY

TL;DR: 该论文通过P2P教学框架重新审视维果茨基的最近发展区理论，提出了"无发展区"概念，强调AI教育中需要设计明确的退出机制来恢复学习者的自主性。


<details>
  <summary>Details</summary>
Motivation: AI在教育中的广泛使用模糊了引导学习与依赖之间的界限，可能导致永久性数字中介取代认知努力，阻碍智力自主性发展。

Method: 通过理论综合和框架设计，采用P2P教学框架，对比临时支架与永久数字中介，引入有意识断开和伦理淡出的概念。

Result: 提出了"无发展区"概念，指持续援助取代认知挣扎并阻碍智力自主的状态，设计了恢复学习者能动性的机制。

Conclusion: 生产性挣扎、自我调节和第一性原理推理对持久学习至关重要，AI在教育中的负责任使用必须包含明确机制，在掌握开始时结束其帮助。

Abstract: AI has redefined the boundaries of assistance in education, often blurring the line between guided learning and dependency. This paper revisits Vygotsky's Zone of Proximal Development (ZPD) through the lens of the P2P Teaching framework. By contrasting temporary scaffolding with the emerging phenomenon of permanent digital mediation, the study introduces the concept of the Zone of No Development (ZND), a state in which continuous assistance replaces cognitive struggle and impedes intellectual autonomy. Through theoretical synthesis and framework design, P2P Teaching demonstrates how deliberate disconnection and ethical fading can restore the learner's agency, ensuring that technological tools enhance rather than replace developmental effort. The paper argues that productive struggle, self-regulation, and first-principles reasoning remain essential for durable learning, and that responsible use of AI in education must include explicit mechanisms to end its help when mastery begins.

</details>


### [33] [Telekommunikationsüberwachung am Scheideweg: Zur Regulierbarkeit des Zugriffes auf verschlüsselte Kommunikation](https://arxiv.org/abs/2511.12830)
*Joanna Klauser,Bruno Albert,Christian Lindenmeier,Andreas Hammer,Felix Freiling,Dirk Heckmann,Sabine Pfeiffer*

Main category: cs.CY

TL;DR: 本文探讨在端到端加密通信时代，如何合理规范技术参与者的合作义务，以平衡执法需求与个人通信隐私保护。


<details>
  <summary>Details</summary>
Motivation: 随着互联网技术发展，传统电信监控在端到端加密的即时通讯和VoIP服务中面临挑战，执法机构难以获取加密内容，需要重新审视技术参与者的合作义务。

Method: 分析现行电信监控法律框架（如TKÜ、§100a StPO），探讨加密通信环境下技术参与者合作义务的合理规制方式。

Result: 指出当前拦截接口在加密通信中只能获取密文内容，执法面临困难，需要重新设计技术参与者的合作义务框架。

Conclusion: 在加密通信普及的背景下，需要重新思考如何合理规范技术参与者的合作义务，以平衡执法需求与个人通信隐私权保护。

Abstract: Personal communication using technical means is protected by telecommunications secrecy. Any interference with this fundamental right requires a legal basis, which has existed for many years for traditional communication services in the form of telecommunications surveillance (TKÜ, § 100a StPO) and appears to be widely accepted by society. The basis for the implementation of TKÜ is the obligation of telecommunications providers to provide interception interfaces. However, the technical implementation of telecommunications has changed significantly as a result of the Internet. Messenger services and Voice over IP telephony are increasingly competing with traditional telephone services. The use of strong end-to-end encryption made possible by this technology is increasingly posing problems for law enforcement agencies, as only cryptographically encrypted content is accessible via the interception interfaces provided to date. Against the backdrop of current discussions on socalled ``chat control'' and its limited social acceptance, this article addresses the question of whether and, if so, how the cooperation obligations of the technical actors involved can be sensibly regulated in the case of encrypted communication.

</details>


### [34] [Beyond Citations: A Cross-Domain Metric for Dataset Impact and Shareability](https://arxiv.org/abs/2511.12966)
*Smitha Muthya Sudheendra,Zhongxing Zhang,Wenwen Cao,Jisu Huh,Jaideep Srivastava*

Main category: cs.CY

TL;DR: 提出了X-index，一种新的作者级指标，通过数据集价值评分和聚合来量化数据贡献的学术影响，解决了传统指标无法衡量数据集可访问性、重用和跨学科影响的问题。


<details>
  <summary>Details</summary>
Motivation: 现有指标（如h指数）主要关注出版物和引用，无法充分衡量数据集作为研究成果的真实影响，特别是数据可访问性、重用和跨学科影响方面。

Method: 采用两步法：首先计算数据集级价值评分（V-score），整合重用广度、FAIR原则、引用影响和传递重用深度；然后将V-score聚合作者级X-index。

Result: 在计算社会科学、医学和危机沟通领域的数据集上进行验证，与专家评分呈现强相关性，证明X-index能有效评估数据共享实践。

Conclusion: X-index提供了一个透明、可扩展且低成本的框架，用于评估数据共享实践并激励开放科学，鼓励可持续的数据共享，为机构、资助者和平台提供认可数据集持久影响的具体方式。

Abstract: The scientific community increasingly relies on open data sharing, yet existing metrics inadequately capture the true impact of datasets as research outputs. Traditional measures, such as the h-index, focus on publications and citations but fail to account for dataset accessibility, reuse, and cross-disciplinary influence. We propose the X-index, a novel author-level metric that quantifies the value of data contributions through a two-step process: (i) computing a dataset-level value score (V-score) that integrates breadth of reuse, FAIRness, citation impact, and transitive reuse depth, and (ii) aggregating V-scores into an author-level X-index. Using datasets from computational social science, medicine, and crisis communication, we validate our approach against expert ratings, achieving a strong correlation. Our results demonstrate that the X-index provides a transparent, scalable, and low-cost framework for assessing data-sharing practices and incentivizing open science. The X-index encourages sustainable data-sharing practices and gives institutions, funders, and platforms a tangible way to acknowledge the lasting influence of research datasets.

</details>


### [35] [The Last Vote: A Multi-Stakeholder Framework for Language Model Governance](https://arxiv.org/abs/2511.13432)
*Subramanyam Sahoo,Aditi Chhawacharia*

Main category: cs.CY

TL;DR: 提出了一个综合框架来应对AI对民主社会构成的风险，包括民主风险分类法、事件严重性评分系统和分阶段实施策略


<details>
  <summary>Details</summary>
Motivation: 随着AI系统日益强大和普及，民主社会在治理这些技术同时维护核心民主价值观和制度方面面临前所未有的挑战

Method: 整合多方利益相关者参与、公民社会参与和现有国际治理框架，引入风险评估和制度适应的新机制

Result: 开发了七类民主风险分类法、利益相关者自适应的事件严重性评分系统和承认复杂制度变革需求的分阶段实施策略

Conclusion: 该框架为民主社会提供了应对AI风险的全面方法，强调系统性威胁识别和适应性治理机制的重要性

Abstract: As artificial intelligence systems become increasingly powerful and pervasive, democratic societies face unprecedented challenges in governing these technologies while preserving core democratic values and institutions. This paper presents a comprehensive framework to address the full spectrum of risks that AI poses to democratic societies. Our approach integrates multi-stakeholder participation, civil society engagement, and existing international governance frameworks while introducing novel mechanisms for risk assessment and institutional adaptation. We propose: (1) a seven-category democratic risk taxonomy extending beyond individual-level harms to capture systemic threats, (2) a stakeholder-adaptive Incident Severity Score (ISS) that incorporates diverse perspectives and context-dependent risk factors, and (3) a phased implementation strategy that acknowledges the complex institutional changes required for effective AI governance.

</details>


### [36] [AI Fairness Beyond Complete Demographics: Current Achievements and Future Directions](https://arxiv.org/abs/2511.13525)
*Zichong Wang,Zhipeng Yin,Roland H. C. Yap,Wenbin Zhang*

Main category: cs.CY

TL;DR: 该论文调查了在人口统计信息不完整情况下的AI公平性问题，提出了新的分类法并总结了现有技术，旨在解决传统方法依赖完整人口统计信息的局限性。


<details>
  <summary>Details</summary>
Motivation: AI系统中的公平性问题日益受到关注，但现有方法大多依赖完整的人口统计信息，这在现实中往往不可行，存在法律约束和可能加剧歧视的风险。

Method: 提出了在人口统计信息不完整情况下的公平性概念新分类法，阐明了各种概念之间的关系和区别，并总结了超越完整人口统计信息的现有公平性促进技术。

Result: 建立了针对不完整人口统计信息场景的公平性概念分类框架，系统梳理了现有技术方法，为这一重要但研究不足的领域提供了理论基础。

Conclusion: 该调查填补了传统公平性方法与现实挑战之间的空白，强调了在不完整人口统计信息下实现AI公平性的重要性，并指出了未来研究方向。

Abstract: Fairness in artificial intelligence (AI) has become a growing concern due to discriminatory outcomes in AI-based decision-making systems. While various methods have been proposed to mitigate bias, most rely on complete demographic information, an assumption often impractical due to legal constraints and the risk of reinforcing discrimination. This survey examines fairness in AI when demographics are incomplete, addressing the gap between traditional approaches and real-world challenges. We introduce a novel taxonomy of fairness notions in this setting, clarifying their relationships and distinctions. Additionally, we summarize existing techniques that promote fairness beyond complete demographics and highlight open research questions to encourage further progress in the field.

</details>


### [37] [New Data Security Requirements and the Proceduralization of Mass Surveillance Law after the European Data Retention Case](https://arxiv.org/abs/2511.13553)
*Frederik Zuiderveen Borgesius,Axel Arnbak*

Main category: cs.CY

TL;DR: 欧盟法院废除数据保留指令的判决确立了元数据收集侵犯隐私权，并提出了评估数据安全的新标准，但存在程序化大规模监控的风险。


<details>
  <summary>Details</summary>
Motivation: 分析欧盟法院废除数据保留指令的判决对大规模元数据监控监管的影响，探讨该判决在保护人权方面的成就和潜在风险。

Method: 通过分析欧盟法院对数据保留指令的判决内容，评估其对隐私权和数据保护的影响，并识别程序化大规模监控的系统性风险。

Result: 法院确认元数据收集侵犯隐私权，提出数据安全评估新标准，但为程序化大规模监控留下空间，可能导致人权系统性风险。

Conclusion: 虽然判决在保护隐私权方面取得进展，但程序化大规模监控的风险依然存在，需要更严格的实质性限制而非仅依靠程序保障。

Abstract: This paper discusses the regulation of mass metadata surveillance in Europe through the lens of the landmark judgment in which the Court of Justice of the European Union struck down the Data Retention Directive. The controversial directive obliged telecom and Internet access providers in Europe to retain metadata of all their customers for intelligence and law enforcement purposes, for a period of up to two years. In the ruling, the Court declared the directive in violation of the human rights to privacy and data protection. The Court also confirmed that the mere collection of metadata interferes with the human right to privacy. In addition, the Court developed three new criteria for assessing the level of data security required from a human rights perspective: security measures should take into account the risk of unlawful access to data, and the data's quantity and sensitivity. While organizations that campaigned against the directive have welcomed the ruling, we warn for the risk of proceduralization of mass surveillance law. The Court did not fully condemn mass surveillance that relies on metadata, but left open the possibility of mass surveillance if policymakers lay down sufficient procedural safeguards. Such proceduralization brings systematic risks for human rights. Government agencies, with ample resources, can design complicated systems of procedural oversight for mass surveillance - and claim that mass surveillance is lawful, even if it affects millions of innocent people.

</details>


### [38] [Access to Personal Data and the Right to Good Governance during Asylum Procedures after the CJEU's YS. and M. and S. judgment](https://arxiv.org/abs/2511.13555)
*Evelien Brouwer,Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 欧洲法院在YS、M和S案中裁决了寻求庇护者获取庇护申请决定相关文件的权利，涉及个人数据概念、数据保护指令下的访问权范围以及欧盟基本权利宪章中的良好行政权。


<details>
  <summary>Details</summary>
Motivation: 分析欧洲法院对寻求庇护者文件访问权的裁决，探讨该判决对个人数据保护和行政权利的影响。

Method: 通过分析欧洲法院在YS、M和S案中的判决内容，解读相关法律条款的适用和解释。

Result: 判决表面上看似对个人权利不利，但实际上为未来庇护案件中的有效访问权提供了充分的法律依据。

Conclusion: 该判决为庇护案件中寻求庇护者的文件访问权确立了重要的法律基础，虽然初看可能令人失望，但实质上支持了有效的权利保护。

Abstract: In the YS. and M. and S. judgment, the Court of Justice of the European Union ruled on three procedures in which Dutch judges asked for clarification on the right of asylum seekers to have access to the documents regarding the decision on asylum applications. The judgment is relevant for interpreting the concept of personal data and the scope of the right of access under the Data Protection Directive, and the right to good administration in the EU Charter of Fundamental Rights. At first glance, the judgment seems disappointing from the viewpoint of individual rights. Nevertheless, in our view the judgment provides sufficient grounds for effective access rights to the minutes in future asylum cases.

</details>


### [39] [Freedom of expression and 'right to be forgotten' cases in the Netherlands after Google Spain](https://arxiv.org/abs/2511.13557)
*Stefan Kulk,Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 本文分析了欧盟法院Google Spain判决在荷兰的应用情况，重点关注删除搜索结果请求的处理方式及其对言论自由的影响。


<details>
  <summary>Details</summary>
Motivation: 研究Google Spain判决后欧洲人有权要求删除姓名搜索结果的权利在荷兰的具体实施情况，特别是法院如何平衡删除权与言论自由的关系。

Method: 通过分析荷兰法院在Google Spain判决后处理的两个删除请求案例，比较荷兰法院与欧盟法院在言论自由考量上的差异。

Result: 荷兰法院比欧盟法院更深入地考虑了删除搜索结果对言论自由的影响，但由于搜索引擎运营商对大多数删除请求的决定缺乏透明度，判决对言论自由的实际影响难以评估。

Conclusion: Google Spain判决在荷兰的实施显示法院更重视言论自由考量，但搜索引擎运营商决策的不透明性使得该判决对言论自由的整体影响难以准确评估。

Abstract: Since the Google Spain judgment of the Court of Justice of the European Union, Europeans have, under certain conditions, the right to have search results for their name delisted. This paper examines how the Google Spain judgment has been applied in the Netherlands. Since the Google Spain judgment, Dutch courts have decided on two cases regarding delisting requests. In both cases, the Dutch courts considered freedom of expression aspects of delisting more thoroughly than the Court of Justice. However, the effect of the Google Spain judgment on freedom of expression is difficult to assess, as search engine operators decide about most delisting requests without disclosing much about their decisions.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [40] [Hierarchical Federated Graph Attention Networks for Scalable and Resilient UAV Collision Avoidance](https://arxiv.org/abs/2511.11616)
*Rathin Chandra Shit,Sharmila Subudhi*

Main category: cs.RO

TL;DR: 提出了一种三层分层框架来解决大规模多无人机系统中的实时碰撞避免问题，通过分层架构平衡实时性能、对抗弹性和隐私保护，显著降低了计算复杂度并提供了拜占庭容错能力。


<details>
  <summary>Details</summary>
Motivation: 当前框架采用单一解决方案，计算复杂度高达O(n²)，无法提供拜占庭容错，且难以平衡实时性能、对抗弹性和隐私保护三大关键指标。

Method: 采用三层分层架构：本地层使用密集图注意力实现<10ms延迟的即时碰撞避免；区域层使用稀疏注意力和异步联邦学习，计算复杂度为O(nk)；全局层使用轻量级Hashgraph协议。结合自适应差分隐私和DHT审计日志。

Result: 在500架无人机规模下，碰撞率<2.0%，95%百分位决策延迟中位数在50ms内，拜占庭容错能力f<n/3，隐私参数ε∈[0.1,1.0]动态调整。

Conclusion: 该分层框架成功消除了传统方案中的权衡问题，实现了大规模多无人机系统中实时碰撞避免的可扩展解决方案，显著提升了系统性能和安全性。

Abstract: The real-time performance, adversarial resiliency, and privacy preservation are the most important metrics that need to be balanced to practice collision avoidance in large-scale multi-UAV (Unmanned Aerial Vehicle) systems. Current frameworks tend to prescribe monolithic solutions that are not only prohibitively computationally complex with a scaling cost of $O(n^2)$ but simply do not offer Byzantine fault tolerance. The proposed hierarchical framework presented in this paper tries to eliminate such trade-offs by stratifying a three-layered architecture. We spread the intelligence into three layers: an immediate collision avoiding local layer running on dense graph attention with latency of $<10 ms$, a regional layer using sparse attention with $O(nk)$ computational complexity and asynchronous federated learning with coordinate-wise trimmed mean aggregation, and lastly, a global layer using a lightweight Hashgraph-inspired protocol. We have proposed an adaptive differential privacy mechanism, wherein the noise level $(ε\in [0.1, 1.0])$ is dynamically reduced based on an evaluation of the measured real-time threat that in turn maximized the privacy-utility tradeoff. Through the use of Distributed Hash Table (DHT)-based lightweight audit logging instead of heavyweight blockchain consensus, the median cost of getting a $95^{th}$ percentile decision within 50ms is observed across all tested swarm sizes. This architecture provides a scalable scenario of 500 UAVs with a collision rate of $< 2.0\%$ and the Byzantine fault tolerance of $f < n/3$.

</details>


### [41] [Tactile Data Recording System for Clothing with Motion-Controlled Robotic Sliding](https://arxiv.org/abs/2511.11634)
*Michikuni Eguchi,Takekazu Kitagishi,Yuichi Hiroi,Takefumi Hiraki*

Main category: cs.RO

TL;DR: 提出基于机器人手臂的系统，用于从完整服装收集触觉数据，通过模拟指尖滑动测量创建带运动标签的多模态触觉数据库。


<details>
  <summary>Details</summary>
Motivation: 服装的触感对穿着舒适度至关重要，需要系统收集滑动运动中的触觉数据来揭示舒适服装的物理特性。

Method: 使用机器人手臂系统进行滑动测量，精确控制速度和方向，模拟指尖触摸，创建运动标签的多模态触觉数据库。

Result: 机器学习评估显示，包含运动相关参数提高了音频和加速度数据的识别准确率，证明了运动相关标签在表征服装触感方面的有效性。

Conclusion: 该系统提供了可扩展、非破坏性的服装触觉数据采集方法，有助于未来织物感知和再现的研究。

Abstract: The tactile sensation of clothing is critical to wearer comfort. To reveal physical properties that make clothing comfortable, systematic collection of tactile data during sliding motion is required. We propose a robotic arm-based system for collecting tactile data from intact garments. The system performs stroking measurements with a simulated fingertip while precisely controlling speed and direction, enabling creation of motion-labeled, multimodal tactile databases. Machine learning evaluation showed that including motion-related parameters improved identification accuracy for audio and acceleration data, demonstrating the efficacy of motion-related labels for characterizing clothing tactile sensation. This system provides a scalable, non-destructive method for capturing tactile data of clothing, contributing to future studies on fabric perception and reproduction.

</details>


### [42] [Image-based Morphological Characterization of Filamentous Biological Structures with Non-constant Curvature Shape Feature](https://arxiv.org/abs/2511.11639)
*Jie Fan,Francesco Visentin,Barbara Mazzolai,Emanuela Del Dottore*

Main category: cs.RO

TL;DR: 提出了一种基于图像的3D几何建模方法，用于分析藤蔓触须在机械刺激下的形状变化，发现顶端部分响应性更高，为植物生物力学研究和仿生机器人设计提供基础。


<details>
  <summary>Details</summary>
Motivation: 尽管攀援植物研究已久，但提取时间形状变化、触发事件和接触位置之间的关系仍具挑战性，需要建立这种关系的方法。

Method: 采用基于3D分段回旋曲线的几何方法，通过图像重建藤蔓触须在机械摩擦后的构型，相比深度学习方法具有数据需求少、计算成本低和可解释性强的优势。

Result: 重建方法显示出高鲁棒性和可靠性，精度R2>0.99，分析发现藤蔓触须的顶端部分响应性更高，可能对应该区域更高的敏感性和组织柔韧性。

Conclusion: 该研究为植物生物力学提供了新的研究方法，并为受攀援植物启发的智能机器人系统设计开发奠定了基础。

Abstract: Tendrils coil their shape to anchor the plant to supporting structures, allowing vertical growth toward light. Although climbing plants have been studied for a long time, extracting information regarding the relationship between the temporal shape change, the event that triggers it, and the contact location is still challenging. To help build this relation, we propose an image-based method by which it is possible to analyze shape changes over time in tendrils when mechano-stimulated in different portions of their body. We employ a geometric approach using a 3D Piece-Wise Clothoid-based model to reconstruct the configuration taken by a tendril after mechanical rubbing. The reconstruction shows high robustness and reliability with an accuracy of R2 > 0.99. This method demonstrates distinct advantages over deep learning-based approaches, including reduced data requirements, lower computational costs, and interpretability. Our analysis reveals higher responsiveness in the apical segment of tendrils, which might correspond to higher sensitivity and tissue flexibility in that region of the organs. Our study provides a methodology for gaining new insights into plant biomechanics and offers a foundation for designing and developing novel intelligent robotic systems inspired by climbing plants.

</details>


### [43] [ExpertAD: Enhancing Autonomous Driving Systems with Mixture of Experts](https://arxiv.org/abs/2511.11740)
*Haowen Jiang,Xinyu Huang,You Lu,Dingji Wang,Yuheng Cao,Chaofeng Sha,Bihuan Chen,Keyu Chen,Xin Peng*

Main category: cs.RO

TL;DR: 提出了ExpertAD框架，采用MoE架构提升自动驾驶系统性能，通过感知适配器增强关键特征，稀疏专家混合减少任务干扰，显著降低碰撞率和推理延迟。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶系统面临语义信息模糊、多任务干扰和推理延迟等问题，影响决策可靠性和安全性。

Method: 引入感知适配器(PA)放大任务关键特征，采用稀疏专家混合(MoSE)最小化预测时的任务干扰，实现高效规划。

Result: 相比现有方法，碰撞率降低20%，推理延迟减少25%，在罕见场景和未见城市环境中表现出强泛化能力。

Conclusion: ExpertAD框架有效解决了自动驾驶系统中的语义模糊、任务干扰和延迟问题，提升了决策可靠性和安全性。

Abstract: Recent advancements in end-to-end autonomous driving systems (ADSs) underscore their potential for perception and planning capabilities. However, challenges remain. Complex driving scenarios contain rich semantic information, yet ambiguous or noisy semantics can compromise decision reliability, while interference between multiple driving tasks may hinder optimal planning. Furthermore, prolonged inference latency slows decision-making, increasing the risk of unsafe driving behaviors. To address these challenges, we propose ExpertAD, a novel framework that enhances the performance of ADS with Mixture of Experts (MoE) architecture. We introduce a Perception Adapter (PA) to amplify task-critical features, ensuring contextually relevant scene understanding, and a Mixture of Sparse Experts (MoSE) to minimize task interference during prediction, allowing for effective and efficient planning. Our experiments show that ExpertAD reduces average collision rates by up to 20% and inference latency by 25% compared to prior methods. We further evaluate its multi-skill planning capabilities in rare scenarios (e.g., accidents, yielding to emergency vehicles) and demonstrate strong generalization to unseen urban environments. Additionally, we present a case study that illustrates its decision-making process in complex driving scenarios.

</details>


### [44] [Large Language Models and 3D Vision for Intelligent Robotic Perception and Autonomy: A Review](https://arxiv.org/abs/2511.11777)
*Vinit Mehta,Charu Sharma,Karthick Thiyagarajan*

Main category: cs.RO

TL;DR: 本文综述了大型语言模型与3D视觉在机器人感知技术中的融合，分析了相关方法、应用和挑战，重点关注场景理解、文本到3D生成、物体定位等关键技术。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能和机器人技术的快速发展，将大型语言模型与3D视觉相结合，能够通过自然语言和空间理解让机器感知、推理和交互复杂环境，弥合语言智能与空间感知之间的差距。

Method: 首先介绍LLMs和3D数据表示的基础原理，深入分析机器人3D感知技术，探讨场景理解、文本到3D生成、物体定位和具身智能体等关键进展，包括零样本3D分割、动态场景合成和语言引导操作等前沿技术。

Result: 讨论了整合3D数据与触觉、听觉和热输入的多模态LLMs，增强了环境理解和机器人决策能力，并整理了针对3D-语言和视觉任务的基准数据集和评估指标。

Conclusion: 识别了关键挑战和未来研究方向，包括自适应模型架构、增强跨模态对齐和实时处理能力，为更智能、情境感知和自主的机器人感知系统铺平道路。

Abstract: With the rapid advancement of artificial intelligence and robotics, the integration of Large Language Models (LLMs) with 3D vision is emerging as a transformative approach to enhancing robotic sensing technologies. This convergence enables machines to perceive, reason and interact with complex environments through natural language and spatial understanding, bridging the gap between linguistic intelligence and spatial perception. This review provides a comprehensive analysis of state-of-the-art methodologies, applications and challenges at the intersection of LLMs and 3D vision, with a focus on next-generation robotic sensing technologies. We first introduce the foundational principles of LLMs and 3D data representations, followed by an in-depth examination of 3D sensing technologies critical for robotics. The review then explores key advancements in scene understanding, text-to-3D generation, object grounding and embodied agents, highlighting cutting-edge techniques such as zero-shot 3D segmentation, dynamic scene synthesis and language-guided manipulation. Furthermore, we discuss multimodal LLMs that integrate 3D data with touch, auditory and thermal inputs, enhancing environmental comprehension and robotic decision-making. To support future research, we catalog benchmark datasets and evaluation metrics tailored for 3D-language and vision tasks. Finally, we identify key challenges and future research directions, including adaptive model architectures, enhanced cross-modal alignment and real-time processing capabilities, which pave the way for more intelligent, context-aware and autonomous robotic sensing systems.

</details>


### [45] [LAVQA: A Latency-Aware Visual Question Answering Framework for Shared Autonomy in Self-Driving Vehicles](https://arxiv.org/abs/2511.11840)
*Shuangyu Xie,Kaiyuan Chen,Wenjing Chen,Chengyuan Qian,Christian Juette,Liu Ren,Dezhen Song,Ken Goldberg*

Main category: cs.RO

TL;DR: LAVQA是一个延迟感知的共享自治框架，通过视觉问答和时空风险可视化来应对自动驾驶中网络延迟和人类响应时间带来的决策时机挑战。


<details>
  <summary>Details</summary>
Motivation: 在不确定性较高时，自动驾驶车辆可能需要远程人类操作员提供高级指导，但无线网络延迟和人类响应时间会导致关键决策时机变化，需要解决延迟感知问题。

Method: 提出LAVQA框架，集成视觉问答和时空风险可视化，通过延迟诱导碰撞地图动态表示时间延迟和空间不确定性，让远程操作员观察车辆安全区域随时间的变化。

Result: 在CARLA自动驾驶模拟器中的闭环仿真表明，LAVQA相比延迟不敏感的基线方法可将碰撞率降低8倍以上。

Conclusion: LAVQA通过延迟感知的共享自治方法有效解决了自动驾驶中延迟带来的安全问题，显著提高了系统安全性。

Abstract: When uncertainty is high, self-driving vehicles may halt for safety and benefit from the access to remote human operators who can provide high-level guidance. This paradigm, known as {shared autonomy}, enables autonomous vehicle and remote human operators to jointly formulate appropriate responses. To address critical decision timing with variable latency due to wireless network delays and human response time, we present LAVQA, a latency-aware shared autonomy framework that integrates Visual Question Answering (VQA) and spatiotemporal risk visualization. LAVQA augments visual queries with Latency-Induced COllision Map (LICOM), a dynamically evolving map that represents both temporal latency and spatial uncertainty. It enables remote operator to observe as the vehicle safety regions vary over time in the presence of dynamic obstacles and delayed responses. Closed-loop simulations in CARLA, the de-facto standard for autonomous vehicle simulator, suggest that that LAVQA can reduce collision rates by over 8x compared to latency-agnostic baselines.

</details>


### [46] [Autonomous Underwater Cognitive System for Adaptive Navigation: A SLAM-Integrated Cognitive Architecture](https://arxiv.org/abs/2511.11845)
*K. A. I. N Jayarathne,R. M. N. M. Rathnayaka,D. P. S. S. Peiris*

Main category: cs.RO

TL;DR: 提出了一种集成SLAM与Soar认知架构的自主水下认知系统(AUCS)，通过多传感器融合和认知推理实现复杂海洋环境中的自适应导航。


<details>
  <summary>Details</summary>
Motivation: 解决深海探索中的迷失方向、通信中断和导航失败等挑战，传统SLAM系统在动态水下环境中存在局限性。

Method: 融合SONAR、LiDAR、IMU和DVL等多传感器数据，结合Soar认知架构的感知、注意力、规划和学习模块，实现语义理解、自适应传感器管理和基于记忆的学习。

Result: 系统能够区分动态和静态物体，减少错误闭环检测，提高长期地图一致性，展示了完整的感知-认知-动作-学习循环。

Conclusion: 为下一代认知潜水系统奠定了基础，提高了深海探索的安全性、可靠性和自主性。

Abstract: Deep-sea exploration poses significant challenges, including disorientation, communication loss, and navigational failures in dynamic underwater environments. This paper presents an Autonomous Underwater Cognitive System (AUCS) that integrates Simultaneous Localization and Mapping (SLAM) with a Soar-based cognitive architecture to enable adaptive navigation in complex oceanic conditions. The system fuses multi-sensor data from SONAR, LiDAR, IMU, and DVL with cognitive reasoning modules for perception, attention, planning, and learning. Unlike conventional SLAM systems, AUCS incorporates semantic understanding, adaptive sensor management, and memory-based learning to differentiate between dynamic and static objects, reducing false loop closures and enhancing long-term map consistency. The proposed architecture demonstrates a complete perception-cognition-action-learning loop, allowing autonomous underwater vehicles to sense, reason, and adapt intelligently. This work lays a foundation for next-generation cognitive submersible systems, improving safety, reliability, and autonomy in deep-sea exploration.

</details>


### [47] [MATT-Diff: Multimodal Active Target Tracking by Diffusion Policy](https://arxiv.org/abs/2511.11931)
*Saida Liu,Nikolay Atanasov,Shumon Koga*

Main category: cs.RO

TL;DR: MATT-Diff是一种基于扩散策略的多模态主动目标跟踪控制策略，能够捕捉探索、专注跟踪和目标重捕获等多种行为模式，无需先验知识即可控制智能体进行多目标跟踪。


<details>
  <summary>Details</summary>
Motivation: 有效的目标跟踪需要在探索未检测或丢失目标与跟踪已检测但不确定目标之间取得平衡，现有方法难以同时处理这两种需求。

Method: 使用三种专家规划器生成演示数据集，采用视觉变换器进行自中心地图标记化，通过注意力机制整合可变目标估计，训练为扩散模型通过去噪过程生成多模态动作序列。

Result: 评估显示MATT-Diff在多种目标运动模式下均优于专家和行为克隆基线方法，在目标跟踪方面具有显著优势。

Conclusion: MATT-Diff通过扩散策略成功实现了多模态主动目标跟踪，能够有效平衡探索和跟踪任务，无需先验知识即可实现鲁棒的目标跟踪性能。

Abstract: This paper proposes MATT-Diff: Multi-Modal Active Target Tracking by Diffusion Policy, a control policy that captures multiple behavioral modes - exploration, dedicated tracking, and target reacquisition - for active multi-target tracking. The policy enables agent control without prior knowledge of target numbers, states, or dynamics. Effective target tracking demands balancing exploration for undetected or lost targets with following the motion of detected but uncertain ones. We generate a demonstration dataset from three expert planners including frontier-based exploration, an uncertainty-based hybrid planner switching between frontier-based exploration and RRT* tracking based on target uncertainty, and a time-based hybrid planner switching between exploration and tracking based on target detection time. We design a control policy utilizing a vision transformer for egocentric map tokenization and an attention mechanism to integrate variable target estimates represented by Gaussian densities. Trained as a diffusion model, the policy learns to generate multi-modal action sequences through a denoising process. Evaluations demonstrate MATT-Diff's superior tracking performance against expert and behavior cloning baselines across multiple target motions, empirically validating its advantages in target tracking.

</details>


### [48] [Characterization and Evaluation of Screw-Based Locomotion Across Aquatic, Granular, and Transitional Media](https://arxiv.org/abs/2511.11958)
*Derek Chen,Zoe Samuels,Lizzie Peiros,Sujaan Mukherjee,Michael C. Yip*

Main category: cs.RO

TL;DR: 该研究系统调查了不同螺旋配置在干沙、湿沙、饱和沙和水中的运动性能，通过原理优先方法分析螺旋性能，发现某些参数对性能影响显著，并基于热沉设计优化参数对性能进行分类。


<details>
  <summary>Details</summary>
Motivation: 螺旋推进系统在实现两栖机动性方面具有潜力，但在优化水、颗粒材料和过渡环境中的运动性能方面面临挑战。

Method: 采用原理优先方法分析螺旋性能，研究不同螺旋配置在多种介质中的运动表现。

Result: 研究发现某些参数对性能影响显著，基于热沉设计优化的派生参数有助于在主导设计参数范围内对性能进行分类。

Conclusion: 研究结果为螺旋壳体设计和自适应运动策略提供了具体见解，以提升螺旋推进系统在多功能两栖应用中的性能。

Abstract: Screw-based propulsion systems offer promising capabilities for amphibious mobility, yet face significant challenges in optimizing locomotion across water, granular materials, and transitional environments. This study presents a systematic investigation into the locomotion performance of various screw configurations in media such as dry sand, wet sand, saturated sand, and water. Through a principles-first approach to analyze screw performance, it was found that certain parameters are dominant in their impact on performance. Depending on the media, derived parameters inspired from optimizing heat sink design help categorize performance within the dominant design parameters. Our results provide specific insights into screw shell design and adaptive locomotion strategies to enhance the performance of screw-based propulsion systems for versatile amphibious applications.

</details>


### [49] [Bootstrapped LLM Semantics for Context-Aware Path Planning](https://arxiv.org/abs/2511.11967)
*Mani Amani,Behrad Beheshti,Reza Akhavian*

Main category: cs.RO

TL;DR: 该论文提出了一个框架，将大型语言模型转化为随机语义传感器，通过贝叶斯引导方法评估环境风险，并调制经典路径规划器，使机器人能够根据自然语言提示和上下文信息安全高效地移动。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注自然语言提示下机器人执行什么任务，而忽略了如何在语义丰富、以人为中心的空间中安全高效地执行任务。本文旨在填补这一空白。

Method: 给定提示和语义地图，从LLM中提取多个"危险"判断，应用贝叶斯引导近似每个类别风险的后验分布，利用后验统计量创建势能成本来制定路径规划问题。

Result: 在模拟环境和BIM支持的数字孪生中，该方法能够根据显式提示和隐式上下文信息自适应调整机器人移动方式，并提供了定性和定量结果。

Conclusion: 该框架成功地将LLM转化为语义传感器，使机器人能够更好地理解和响应人类环境中的语义信息，实现更安全高效的导航。

Abstract: Prompting robots with natural language (NL) has largely been studied as what task to execute (goal selection, skill sequencing) rather than how to execute that task safely and efficiently in semantically rich, human-centric spaces. We address this gap with a framework that turns a large language model (LLM) into a stochastic semantic sensor whose outputs modulate a classical planner. Given a prompt and a semantic map, we draw multiple LLM "danger" judgments and apply a Bayesian bootstrap to approximate a posterior over per-class risk. Using statistics from the posterior, we create a potential cost to formulate a path planning problem. Across simulated environments and a BIM-backed digital twin, our method adapts how the robot moves in response to explicit prompts and implicit contextual information. We present qualitative and quantitative results.

</details>


### [50] [ARCSnake V2: An Amphibious Multi-Domain Screw-Propelled Snake-Like Robot](https://arxiv.org/abs/2511.11970)
*Sara Wickenhiser,Lizzie Peiros,Calvin Joyce,Peter Gavrilrov,Sujaan Mukherjee,Syler Sylvester,Junrong Zhou,Mandy Cheung,Jason Lim,Florian Richter,Michael C. Yip*

Main category: cs.RO

TL;DR: ARCSnake V2是一个两栖螺旋推进蛇形机器人，结合了高机动性与地形适应性，可在陆地、颗粒介质和水域中实现远程或自主移动。


<details>
  <summary>Details</summary>
Motivation: 传统轮式或腿式机器人在极端环境（如洞穴、海洋、行星表面）中面临地形变化挑战，需要更通用的移动解决方案。

Method: 采用水密机械设计，结合螺旋推进和关节驱动，集成浮力控制系统，通过运动学匹配的手持控制器进行远程操作。

Result: 实验验证了水下机动性、通信鲁棒性和力调节驱动，支持螺旋、轮式和侧向移动等多种运动模式。

Conclusion: ARCSnake V2作为多域探索、搜救和环境监测的通用平台，展现了在极端环境中的强大适应性。

Abstract: Robotic exploration in extreme environments such as caves, oceans, and planetary surfaces pose significant challenges, particularly in locomotion across diverse terrains. Conventional wheeled or legged robots often struggle in these contexts due to surface variability. This paper presents ARCSnake V2, an amphibious, screw propelled, snake like robot designed for teleoperated or autonomous locomotion across land, granular media, and aquatic environments. ARCSnake V2 combines the high mobility of hyper redundant snake robots with the terrain versatility of Archimedean screw propulsion. Key contributions include a water sealed mechanical design with serially linked screw and joint actuation, an integrated buoyancy control system, and teleoperation via a kinematically matched handheld controller. The robots design and control architecture enable multiple locomotion modes screwing, wheeling, and sidewinding with smooth transitions between them. Extensive experiments validate its underwater maneuverability, communication robustness, and force regulated actuation. These capabilities position ARCSnake V2 as a versatile platform for exploration, search and rescue, and environmental monitoring in multi domain settings.

</details>


### [51] [SBAMP: Sampling Based Adaptive Motion Planning](https://arxiv.org/abs/2511.12022)
*Anh-Quan Pham,Kabir Ram Puri,Shreyas Raorane*

Main category: cs.RO

TL;DR: SBAMP结合RRT*全局路径规划和SEDS局部控制器，实现无需预训练数据的自适应运动规划，在动态环境中保持实时适应性和路径最优性。


<details>
  <summary>Details</summary>
Motivation: 传统采样方法（如RRT*）难以适应动态变化，而学习型动态系统（如SEDS）依赖预收集数据且泛化能力有限，需要一种能兼顾全局规划和实时适应的解决方案。

Method: 集成RRT*进行全局路径规划，使用SEDS基局部控制器进行连续自适应轨迹调整，无需预训练数据集，通过Lyapunov稳定性保证确保平滑过渡。

Result: 在仿真和RoboRacer硬件平台上验证，SBAMP在动态障碍场景、扰动恢复和急转弯处理方面表现优异，实时适应性强且不牺牲全局路径最优性。

Conclusion: SBAMP为动态非结构化环境提供了可扩展的解决方案，成功结合了采样规划和学习控制的优势，实现了实时自适应运动规划。

Abstract: Autonomous robotic systems must navigate complex, dynamic environments in real time, often facing unpredictable obstacles and rapidly changing conditions. Traditional sampling-based methods, such as RRT*, excel at generating collision-free paths but struggle to adapt to sudden changes without extensive replanning. Conversely, learning-based dynamical systems, such as the Stable Estimator of Dynamical Systems (SEDS), offer smooth, adaptive trajectory tracking but typically rely on pre-collected demonstration data, limiting their generalization to novel scenarios. This paper introduces Sampling-Based Adaptive Motion Planning (SBAMP), a novel framework that overcomes these limitations by integrating RRT* for global path planning with a SEDS-based local controller for continuous, adaptive trajectory adjustment. Our approach requires no pre-trained datasets and ensures smooth transitions between planned waypoints, maintaining stability through Lyapunov-based guarantees. We validate SBAMP in both simulated environments and real hardware using the RoboRacer platform, demonstrating superior performance in dynamic obstacle scenarios, rapid recovery from perturbations, and robust handling of sharp turns. Experimental results highlight SBAMP's ability to adapt in real time without sacrificing global path optimality, providing a scalable solution for dynamic, unstructured environments.

</details>


### [52] [Decoupled Action Head: Confining Task Knowledge to Conditioning Layers](https://arxiv.org/abs/2511.12101)
*Jian Zhou,Sihao Lin,Shuai Fu,Qi WU*

Main category: cs.RO

TL;DR: 提出了一种解耦训练方法，利用运动学生成的轨迹预训练通用动作头，然后通过特征调制适应新任务，显著提高了训练效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有行为克隆方法受限于配对训练数据的稀缺性，且扩散策略等模型的有效性机制理解不足，导致泛化能力有限和模型设计缺乏原则性指导。

Method: 使用运动学生成的轨迹预训练通用动作头，然后冻结该动作头并通过特征调制适应新任务。同时提出了DP-MLP，用简单的MLP块替换DP-C中的U-Net主干网络。

Result: 解耦训练在分布内和分布外场景都可行，DP-C训练速度提升41%。DP-MLP在正常训练下速度提升83.9%，解耦训练下提升89.1%。

Conclusion: 动作生成主干在机器人操作中作用有限，解耦训练方法有效提升了训练效率和泛化能力，同时简化了模型结构。

Abstract: Behavior Cloning (BC) is a data-driven supervised learning approach that has gained increasing attention with the success of scaling laws in language and vision domains. Among its implementations in robotic manipulation, Diffusion Policy (DP), with its two variants DP-CNN (DP-C) and DP-Transformer (DP-T), is one of the most effective and widely adopted models, demonstrating the advantages of predicting continuous action sequences. However, both DP and other BC methods remain constrained by the scarcity of paired training data, and the internal mechanisms underlying DP's effectiveness remain insufficiently understood, leading to limited generalization and a lack of principled design in model development. In this work, we propose a decoupled training recipe that leverages nearly cost-free kinematics-generated trajectories as observation-free data to pretrain a general action head (action generator). The pretrained action head is then frozen and adapted to novel tasks through feature modulation. Our experiments demonstrate the feasibility of this approach in both in-distribution and out-of-distribution scenarios. As an additional benefit, decoupling improves training efficiency; for instance, DP-C achieves up to a 41% speedup. Furthermore, the confinement of task-specific knowledge to the conditioning components under decoupling, combined with the near-identical performance of DP-C in both normal and decoupled training, indicates that the action generation backbone plays a limited role in robotic manipulation. Motivated by this observation, we introduce DP-MLP, which replaces the 244M-parameter U-Net backbone of DP-C with only 4M parameters of simple MLP blocks, achieving a 83.9% faster training speed under normal training and 89.1% under decoupling.

</details>


### [53] [Towards Obstacle-Avoiding Control of Planar Snake Robots Exploring Neuro-Evolution of Augmenting Topologies](https://arxiv.org/abs/2511.12148)
*Advik Sinha,Akshay Arjun,Abhijit Das,Joyjit Mukherjee*

Main category: cs.RO

TL;DR: 使用NEAT算法为蛇形机器人开发资源高效的避障跟踪控制方案，通过进化神经网络生成动态步态参数，在密集障碍物环境中实现高效导航。


<details>
  <summary>Details</summary>
Motivation: 在密集障碍物环境中为蛇形机器人开发计算效率高的避障跟踪控制方案，解决传统方法计算开销大的问题。

Method: 采用NEAT（增强拓扑神经进化）算法，以关节角度、连杆位置、头部位置和障碍物位置为输入，输出蛇形步态的频率和偏移角，通过奖励函数最大化来进化神经网络。

Result: 在PyBullet物理引擎仿真中验证，相比现有方法表现出优越性能，与最新的CBRL方法结果相当但计算开销显著降低。

Conclusion: 提出的NEAT框架为蛇形机器人在复杂环境中的导航提供了计算高效且性能优越的解决方案。

Abstract: This work aims to develop a resource-efficient solution for obstacle-avoiding tracking control of a planar snake robot in a densely cluttered environment with obstacles. Particularly, Neuro-Evolution of Augmenting Topologies (NEAT) has been employed to generate dynamic gait parameters for the serpenoid gait function, which is implemented on the joint angles of the snake robot, thus controlling the robot on a desired dynamic path. NEAT is a single neural-network based evolutionary algorithm that is known to work extremely well when the input layer is of significantly higher dimension and the output layer is of a smaller size. For the planar snake robot, the input layer consists of the joint angles, link positions, head link position as well as obstacle positions in the vicinity. However, the output layer consists of only the frequency and offset angle of the serpenoid gait that control the speed and heading of the robot, respectively. Obstacle data from a LiDAR and the robot data from various sensors, along with the location of the end goal and time, are employed to parametrize a reward function that is maximized over iterations by selective propagation of superior neural networks. The implementation and experimental results showcase that the proposed approach is computationally efficient, especially for large environments with many obstacles. The proposed framework has been verified through a physics engine simulation study on PyBullet. The approach shows superior results to existing state-of-the-art methodologies and comparable results to the very recent CBRL approach with significantly lower computational overhead. The video of the simulation can be found here: https://sites.google.com/view/neatsnakerobot

</details>


### [54] [Game-Theoretic Safe Multi-Agent Motion Planning with Reachability Analysis for Dynamic and Uncertain Environments (Extended Version)](https://arxiv.org/abs/2511.12160)
*Wenbin Mai,Minghui Liwang,Xinlei Yi,Xiaoyu Xia,Seyyedali Hosseinalipour,Xianbin Wang*

Main category: cs.RO

TL;DR: 提出了一种结合可达性分析和博弈论的多智能体运动规划框架RE-DPG，通过动态势博弈和邻域主导迭代最佳响应算法解决复杂环境下的安全协调问题。


<details>
  <summary>Details</summary>
Motivation: 解决动态不确定环境中多智能体系统的安全、鲁棒和可扩展运动规划挑战，特别是耦合决策的计算复杂性和主动安全保障需求。

Method: 将多智能体协调建模为动态势博弈，开发邻域主导迭代最佳响应(ND-iBR)方案，并集成多智能体前向可达集(MA-FRS)机制到成本函数中。

Result: 在2D和3D环境的仿真和真实实验中验证了RE-DPG在各种操作场景下的有效性。

Conclusion: RE-DPG框架能够为多智能体系统在动态不确定环境中提供安全、可扩展的运动规划解决方案。

Abstract: Ensuring safe, robust, and scalable motion planning for multi-agent systems in dynamic and uncertain environments is a persistent challenge, driven by complex inter-agent interactions, stochastic disturbances, and model uncertainties. To overcome these challenges, particularly the computational complexity of coupled decision-making and the need for proactive safety guarantees, we propose a Reachability-Enhanced Dynamic Potential Game (RE-DPG) framework, which integrates game-theoretic coordination into reachability analysis. This approach formulates multi-agent coordination as a dynamic potential game, where the Nash equilibrium (NE) defines optimal control strategies across agents. To enable scalability and decentralized execution, we develop a Neighborhood-Dominated iterative Best Response (ND-iBR) scheme, built upon an iterated $\varepsilon$-BR (i$\varepsilon$-BR) process that guarantees finite-step convergence to an $\varepsilon$-NE. This allows agents to compute strategies based on local interactions while ensuring theoretical convergence guarantees. Furthermore, to ensure safety under uncertainty, we integrate a Multi-Agent Forward Reachable Set (MA-FRS) mechanism into the cost function, explicitly modeling uncertainty propagation and enforcing collision avoidance constraints. Through both simulations and real-world experiments in 2D and 3D environments, we validate the effectiveness of RE-DPG across diverse operational scenarios.

</details>


### [55] [Variable Impedance Control for Floating-Base Supernumerary Robotic Leg in Walking Assistance](https://arxiv.org/abs/2511.12184)
*Jun Huo,Kehan Xu,Chengyao Li,Yu Cao,Jie Zuo,Xinxing Chen,Jian Huang*

Main category: cs.RO

TL;DR: 针对超数机器人腿系统在浮动基座下的安全控制问题，提出了一种混合位置/力阻抗控制器和可变阻抗控制方法，通过动态调整阻抗参数实现刚柔状态的平滑切换，提高人机交互的安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 在浮动基座机器人系统中，内部和外部扰动会影响力控制的安全性。超数机器人腿系统作为典型的松散耦合浮动基座系统，特别容易受到强内部扰动的影响，需要解决浮动基座带来的控制挑战。

Method: 研究了松散耦合SRL的动力学模型，设计了混合位置/力阻抗控制器来适应动态扭矩输入。开发了高效的变阻抗控制方法，通过动态调整阻抗参数来改善刚性和柔性之间的动态切换。特别为SRL设计了实时稳定性保证的阻抗参数生成网络。

Result: 仿真和实验验证了系统的有效性，证明系统能够在柔性状态下保持平滑信号过渡，同时在刚性状态下提供强大的支撑力。

Conclusion: 该方法为人机交互中个体步态变化的适应提供了实用解决方案，显著提高了人机交互系统的安全性和适应性。

Abstract: In human-robot systems, ensuring safety during force control in the presence of both internal and external disturbances is crucial. As a typical loosely coupled floating-base robot system, the supernumerary robotic leg (SRL) system is particularly susceptible to strong internal disturbances. To address the challenge posed by floating base, we investigated the dynamics model of the loosely coupled SRL and designed a hybrid position/force impedance controller to fit dynamic torque input. An efficient variable impedance control (VIC) method is developed to enhance human-robot interaction, particularly in scenarios involving external force disturbances. By dynamically adjusting impedance parameters, VIC improves the dynamic switching between rigidity and flexibility, so that it can adapt to unknown environmental disturbances in different states. An efficient real-time stability guaranteed impedance parameters generating network is specifically designed for the proposed SRL, to achieve shock mitigation and high rigidity supporting. Simulations and experiments validate the system's effectiveness, demonstrating its ability to maintain smooth signal transitions in flexible states while providing strong support forces in rigid states. This approach provides a practical solution for accommodating individual gait variations in interaction, and significantly advances the safety and adaptability of human-robot systems.

</details>


### [56] [Innovative Design of Multi-functional Supernumerary Robotic Limbs with Ellipsoid Workspace Optimization](https://arxiv.org/abs/2511.12186)
*Jun Huo,Jian Huang,Jie Zuo,Bo Yang,Zhongzheng Fu,Xi Li,Samer Mohammed*

Main category: cs.RO

TL;DR: 提出了一个多目标优化设计理论，用于设计多功能超数机器人肢体，通过优化抓取工作空间、行走工作空间、坐站转换支撑力和质量惯性，显著提升了抓取成功率和降低了肌肉活动水平。


<details>
  <summary>Details</summary>
Motivation: 设计通用超数机器人肢体具有挑战性，需要满足上肢和下肢的多样化功能需求，因此需要开发统一的理论框架来优化设计。

Method: 开发了多目标优化设计理论，包括工作空间相似性、坐站转换支撑力、质量和惯性优化，使用椭球体表示工作空间以减少计算复杂度，并引入多子群校正萤火虫算法来处理高维不规则帕累托前沿。

Result: 优化后原型在实验中显示，平均抓取成功率提高了7.2%，行走和坐站转换任务中的肌肉活动分别平均降低了12.7%和25.1%。

Conclusion: 提出的设计理论为多功能超数机器人肢体机制的设计提供了高效选择。

Abstract: Supernumerary robotic limbs (SRLs) offer substantial potential in both the rehabilitation of hemiplegic patients and the enhancement of functional capabilities for healthy individuals. Designing a general-purpose SRL device is inherently challenging, particularly when developing a unified theoretical framework that meets the diverse functional requirements of both upper and lower limbs. In this paper, we propose a multi-objective optimization (MOO) design theory that integrates grasping workspace similarity, walking workspace similarity, braced force for sit-to-stand (STS) movements, and overall mass and inertia. A geometric vector quantification method is developed using an ellipsoid to represent the workspace, aiming to reduce computational complexity and address quantification challenges. The ellipsoid envelope transforms workspace points into ellipsoid attributes, providing a parametric description of the workspace. Furthermore, the STS static braced force assesses the effectiveness of force transmission. The overall mass and inertia restricts excessive link length. To facilitate rapid and stable convergence of the model to high-dimensional irregular Pareto fronts, we introduce a multi-subpopulation correction firefly algorithm. This algorithm incorporates a strategy involving attractive and repulsive domains to effectively handle the MOO task. The optimized solution is utilized to redesign the prototype for experimentation to meet specified requirements. Six healthy participants and two hemiplegia patients participated in real experiments. Compared to the pre-optimization results, the average grasp success rate improved by 7.2%, while the muscle activity during walking and STS tasks decreased by an average of 12.7% and 25.1%, respectively. The proposed design theory offers an efficient option for the design of multi-functional SRL mechanisms.

</details>


### [57] [Locally Optimal Solutions to Constraint Displacement Problems via Path-Obstacle Overlaps](https://arxiv.org/abs/2511.12203)
*Antony Thomas,Fulvio Mastrogiovanni,Marco Baglietto*

Main category: cs.RO

TL;DR: 提出了一种解决约束位移问题的统一方法，通过两阶段过程计算局部最优的障碍物位移，使机器人能找到可行路径。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在有障碍物环境中寻找可行路径时，通过位移约束或障碍物来创造可行路径的问题。

Method: 两阶段方法：第一阶段计算通过障碍物的轨迹并最小化目标函数；第二阶段位移障碍物使机器人轨迹可行且无碰撞。

Result: 多个示例成功展示了该方法在两类约束位移问题上的应用效果。

Conclusion: 该方法为约束位移问题提供了一种有效的统一解决方案，能够成功处理不同类型的障碍物位移需求。

Abstract: We present a unified approach for constraint displacement problems in which a robot finds a feasible path by displacing constraints or obstacles. To this end, we propose a two stage process that returns locally optimal obstacle displacements to enable a feasible path for the robot. The first stage proceeds by computing a trajectory through the obstacles while minimizing an appropriate objective function. In the second stage, these obstacles are displaced to make the computed robot trajectory feasible, that is, collision-free. Several examples are provided that successfully demonstrate our approach on two distinct classes of constraint displacement problems.

</details>


### [58] [SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation](https://arxiv.org/abs/2511.12232)
*Lingfeng Zhang,Erjia Xiao,Xiaoshuai Hao,Haoxiang Fu,Zeying Gong,Long Chen,Xiaojun Liang,Renjing Xu,Hangjun Ye,Wenbo Ding*

Main category: cs.RO

TL;DR: 提出了SocialNav-Map，一种零样本社交导航框架，结合动态人类轨迹预测和占用映射，无需环境特定训练即可实现安全高效导航。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的方法需要2000+小时训练且难以泛化到陌生环境，限制了实际应用。

Method: 将任务目标位置转换到地图坐标系，创建包含预测人类运动的动态占用地图，使用历史预测和方向预测两种互补方法进行人类轨迹预测。

Result: 在Social-HM3D和Social-MP3D数据集上显著优于最先进的RL方法，人类碰撞率降低超过10%，无需新环境训练。

Conclusion: 通过消除环境特定训练需求，SocialNav-Map实现了卓越的导航性能，为社交导航系统在现实环境中的部署铺平了道路。

Abstract: Social navigation in densely populated dynamic environments poses a significant challenge for autonomous mobile robots, requiring advanced strategies for safe interaction. Existing reinforcement learning (RL)-based methods require over 2000+ hours of extensive training and often struggle to generalize to unfamiliar environments without additional fine-tuning, limiting their practical application in real-world scenarios. To address these limitations, we propose SocialNav-Map, a novel zero-shot social navigation framework that combines dynamic human trajectory prediction with occupancy mapping, enabling safe and efficient navigation without the need for environment-specific training. Specifically, SocialNav-Map first transforms the task goal position into the constructed map coordinate system. Subsequently, it creates a dynamic occupancy map that incorporates predicted human movements as dynamic obstacles. The framework employs two complementary methods for human trajectory prediction: history prediction and orientation prediction. By integrating these predicted trajectories into the occupancy map, the robot can proactively avoid potential collisions with humans while efficiently navigating to its destination. Extensive experiments on the Social-HM3D and Social-MP3D datasets demonstrate that SocialNav-Map significantly outperforms state-of-the-art (SOTA) RL-based methods, which require 2,396 GPU hours of training. Notably, it reduces human collision rates by over 10% without necessitating any training in novel environments. By eliminating the need for environment-specific training, SocialNav-Map achieves superior navigation performance, paving the way for the deployment of social navigation systems in real-world environments characterized by diverse human behaviors. The code is available at: https://github.com/linglingxiansen/SocialNav-Map.

</details>


### [59] [Intermittent Rendezvous Plans with Mixed Integer Linear Program for Large-Scale Multi-Robot Exploration](https://arxiv.org/abs/2511.12237)
*Alysson Ribeiro da Silva,Luiz Chaimowicz*

Main category: cs.RO

TL;DR: 提出了一种用于多机器人探索的间歇通信框架，通过混合整数线性规划生成会合计划，并使用RTUS机制让机器人在未知环境中跟踪计划。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人探索中的通信约束问题，特别是在环境未知的情况下，现有调度方法无法生成最优计划且缺乏实际轨迹跟踪机制。

Method: 使用混合整数线性规划(MILP)生成会合计划，并提出RTUS(未知场景会合跟踪)机制让机器人根据简单规则在未知条件下跟踪分配的计划。

Result: 在Gazebo模拟的大规模环境中评估，结果表明该方法能够及时跟踪计划并高效完成任务。

Conclusion: 提出的MRE-CCIC框架能够有效解决多机器人探索中的通信约束问题，提供开源实现，适合实际部署。

Abstract: Multi-Robot Exploration (MRE) systems with communication constraints have proven efficient in accomplishing a variety of tasks, including search-and-rescue, stealth, and military operations. While some works focus on opportunistic approaches for efficiency, others concentrate on pre-planned trajectories or scheduling for increased interpretability. However, scheduling usually requires knowledge of the environment beforehand, which prevents its deployment in several domains due to related uncertainties (e.g., underwater exploration). In our previous work, we proposed an intermittent communications framework for MRE under communication constraints that uses scheduled rendezvous events to mitigate such limitations. However, the system was unable to generate optimal plans and had no mechanisms to follow the plan considering realistic trajectories, which is not suited for real-world deployments. In this work, we further investigate the problem by formulating the Multi-Robot Exploration with Communication Constraints and Intermittent Connectivity (MRE-CCIC) problem. We propose a Mixed-Integer Linear Program (MILP) formulation to generate rendezvous plans and a policy to follow them based on the Rendezvous Tracking for Unknown Scenarios (RTUS) mechanism. The RTUS is a simple rule to allow robots to follow the assigned plan, considering unknown conditions. Finally, we evaluated our method in a large-scale environment configured in Gazebo simulations. The results suggest that our method can follow the plan promptly and accomplish the task efficiently. We provide an open-source implementation of both the MILP plan generator and the large-scale MRE-CCIC.

</details>


### [60] [SAC-MoE: Reinforcement Learning with Mixture-of-Experts for Control of Hybrid Dynamical Systems with Uncertainty](https://arxiv.org/abs/2511.12361)
*Leroy D'Souza,Akash Karthikeyan,Yash Vardhan Pant,Sebastian Fischmeister*

Main category: cs.RO

TL;DR: 提出SAC-MoE方法，在Soft Actor-Critic框架中使用混合专家模型，通过学习的路由器自适应选择专家，结合课程学习策略提高对混合动力系统中不可观测模式和切换的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 混合动力系统中存在不可观测的潜在参数和模式切换事件，传统基于模型的控制方法无法处理这种不确定性，而标准无模型强化学习方法无法适应突然的模式切换，导致泛化能力差。

Method: 将SAC框架中的行动者建模为混合专家模型，包含学习的路由器来自适应选择专家；开发基于课程学习的训练算法，优先在具有挑战性的环境中收集数据。

Result: 在混合自主赛车和腿式运动任务中的仿真研究表明，SAC-MoE在零样本泛化到未见环境方面优于基线方法（最高6倍）；课程策略在所有评估策略中持续提升性能。

Conclusion: SAC-MoE能够有效处理混合动力系统中的潜在模式和切换不确定性，MoE路由器可解释地激活不同专家处理不同潜在模式。

Abstract: Hybrid dynamical systems result from the interaction of continuous-variable dynamics with discrete events and encompass various systems such as legged robots, vehicles and aircrafts. Challenges arise when the system's modes are characterized by unobservable (latent) parameters and the events that cause system dynamics to switch between different modes are also unobservable. Model-based control approaches typically do not account for such uncertainty in the hybrid dynamics, while standard model-free RL methods fail to account for abrupt mode switches, leading to poor generalization.
  To overcome this, we propose SAC-MoE which models the actor of the Soft Actor-Critic (SAC) framework as a Mixture-of-Experts (MoE) with a learned router that adaptively selects among learned experts. To further improve robustness, we develop a curriculum-based training algorithm to prioritize data collection in challenging settings, allowing better generalization to unseen modes and switching locations. Simulation studies in hybrid autonomous racing and legged locomotion tasks show that SAC-MoE outperforms baselines (up to 6x) in zero-shot generalization to unseen environments. Our curriculum strategy consistently improves performance across all evaluated policies. Qualitative analysis shows that the interpretable MoE router activates different experts for distinct latent modes.

</details>


### [61] [Multilaminate piezoelectric PVDF actuators to enhance performance of soft micro robots](https://arxiv.org/abs/2511.12380)
*Nicholas Gunter,Heiko Kabutz,Kaushik Jayaram*

Main category: cs.RO

TL;DR: 开发多层PVDF压电执行器，在脆性高力PZT堆栈和柔性低带宽聚合物执行器之间找到平衡，实现大位移、高力和高频率性能，并集成到微型机器人中展示应用潜力。


<details>
  <summary>Details</summary>
Motivation: 多层聚偏氟乙烯(PVDF)压电执行器是提升软体微型机器人系统性能的有前景方法，旨在填补脆性高力PZT堆栈与柔性但低带宽软聚合物执行器之间的设计空白。

Method: 开发多层PVDF执行器，采用各层并联电压分布设计，研究层厚度和层数对执行器性能的影响，并与基本原理模型进行对比验证。

Result: 通过调整参数，实现了>3毫米的自由偏转、>20毫牛的阻塞力、≥500赫兹的工作频率，且工作电压低至150伏特。成功将执行器集成到平面移动微型机器人中，利用共振实现运动并具有对大扰动的鲁棒性。

Conclusion: 多层PVDF执行器在软体微型机器人应用中表现出优异性能，填补了现有执行器技术的空白，为机器人集成提供了可行方案。

Abstract: Multilayer piezoelectric polyvinylidene fluoride (PVDF) actuators are a promising approach to enhance performance of soft microrobotic systems. In this work, we develop and characterize multilayer PVDF actuators with parallel voltage distribution across each layer, bridging a unique design space between brittle high-force PZT stacks and compliant but lower-bandwidth soft polymer actuators. We show the effects of layer thickness and number of layers in actuator performance and their agreement with a first principles model. By varying these parameters, we demonstrate actuators capable of >3 mm of free deflection, >20 mN of blocked force, and >=500 Hz, while operating at voltages as low as 150 volts. To illustrate their potential for robotic integration, we integrate our actuators into a planar, translating microrobot that leverages resonance to achieve locomotion with robustness to large perturbations.

</details>


### [62] [Evaluating Model-Agnostic Meta-Learning on MetaWorld ML10 Benchmark: Fast Adaptation in Robotic Manipulation Tasks](https://arxiv.org/abs/2511.12383)
*Sanjar Atamuradov*

Main category: cs.RO

TL;DR: 本文评估了MAML-TRPO在MetaWorld ML10基准测试中的表现，展示了元学习在机器人操作任务中的快速适应能力，但存在泛化差距和任务间性能差异大的问题。


<details>
  <summary>Details</summary>
Motivation: 研究元学习算法在机器人系统中的快速适应能力，特别是在数据稀缺的情况下如何实现多样化的机器人操作任务。

Method: 使用模型无关元学习（MAML）结合信任域策略优化（TRPO）在MetaWorld ML10基准测试上，学习通用初始化以实现少样本适应。

Result: MAML实现了有效的一次梯度更新适应，训练任务最终成功率为21.0%，测试任务为13.2%，但存在泛化差距，不同操作技能的成功率差异很大（0%到80%）。

Conclusion: 基于梯度的元学习在多样化机器人操作中具有潜力但存在局限性，未来工作需要关注任务感知适应和结构化策略架构。

Abstract: Meta-learning algorithms enable rapid adaptation to new tasks with minimal data, a critical capability for real-world robotic systems. This paper evaluates Model-Agnostic Meta-Learning (MAML) combined with Trust Region Policy Optimization (TRPO) on the MetaWorld ML10 benchmark, a challenging suite of ten diverse robotic manipulation tasks. We implement and analyze MAML-TRPO's ability to learn a universal initialization that facilitates few-shot adaptation across semantically different manipulation behaviors including pushing, picking, and drawer manipulation. Our experiments demonstrate that MAML achieves effective one-shot adaptation with clear performance improvements after a single gradient update, reaching final success rates of 21.0% on training tasks and 13.2% on held-out test tasks. However, we observe a generalization gap that emerges during meta-training, where performance on test tasks plateaus while training task performance continues to improve. Task-level analysis reveals high variance in adaptation effectiveness, with success rates ranging from 0% to 80% across different manipulation skills. These findings highlight both the promise and current limitations of gradient-based meta-learning for diverse robotic manipulation, and suggest directions for future work in task-aware adaptation and structured policy architectures.

</details>


### [63] [Learning Adaptive Neural Teleoperation for Humanoid Robots: From Inverse Kinematics to End-to-End Control](https://arxiv.org/abs/2511.12390)
*Sanjar Atamuradov*

Main category: cs.RO

TL;DR: 提出基于学习的神经遥操作框架，用强化学习训练的神经网络策略替代传统的逆运动学+PD控制器，提升人形机器人遥操作的自然性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 传统遥操作系统依赖逆运动学求解器和手动调谐的PD控制器，难以处理外力干扰、适应不同用户，在动态条件下无法产生自然运动

Method: 训练神经网络策略直接从VR控制器输入映射到机器人关节指令，通过强化学习在仿真中训练，使用IK遥操作演示初始化，然后通过力随机化和轨迹平滑奖励进行微调

Result: 在Unitree G1人形机器人上的实验显示，学习策略相比IK基线实现了34%更低的跟踪误差、45%更平滑的运动和更优的力适应能力，同时保持实时性能（50Hz控制频率）

Conclusion: 基于学习的方法可以显著提升人形机器人遥操作系统的自然性和鲁棒性

Abstract: Virtual reality (VR) teleoperation has emerged as a promising approach for controlling humanoid robots in complex manipulation tasks. However, traditional teleoperation systems rely on inverse kinematics (IK) solvers and hand-tuned PD controllers, which struggle to handle external forces, adapt to different users, and produce natural motions under dynamic conditions. In this work, we propose a learning-based neural teleoperation framework that replaces the conventional IK+PD pipeline with learned policies trained via reinforcement learning. Our approach learns to directly map VR controller inputs to robot joint commands while implicitly handling force disturbances, producing smooth trajectories, and adapting to user preferences. We train our policies in simulation using demonstrations collected from IK-based teleoperation as initialization, then fine-tune them with force randomization and trajectory smoothness rewards. Experiments on the Unitree G1 humanoid robot demonstrate that our learned policies achieve 34% lower tracking error, 45% smoother motions, and superior force adaptation compared to the IK baseline, while maintaining real-time performance (50Hz control frequency). We validate our approach on manipulation tasks including object pick-and-place, door opening, and bimanual coordination. These results suggest that learning-based approaches can significantly improve the naturalness and robustness of humanoid teleoperation systems.

</details>


### [64] [RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation](https://arxiv.org/abs/2511.12436)
*Xiaoshuai Hao,Yingbo Tang,Lingfeng Zhang,Yanbiao Ma,Yunfeng Diao,Ziyu Jia,Wenbo Ding,Hangjun Ye,Long Chen*

Main category: cs.RO

TL;DR: 提出了RoboAfford++数据集和RoboAfford-Eval基准，用于解决视觉语言模型在物体和空间可操作性学习方面的不足，显著提升了机器人在操作和导航中的可操作性推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在高级任务规划和场景理解方面表现出色，但在推断物理交互的可操作位置（如功能性抓取点和允许放置区域）方面存在困难，这源于训练数据集中缺乏细粒度的物体和空间可操作性标注。

Method: 构建了RoboAfford++数据集，包含869,987张图像和200万个问答标注，涵盖三个关键任务：物体可操作性识别、物体可操作性预测和空间可操作性定位。同时提出了RoboAfford-Eval基准进行评估。

Result: 实验结果显示现有视觉语言模型在可操作性学习方面存在缺陷，而在RoboAfford++数据集上微调后，它们推理物体和空间可操作性的能力显著增强，验证了数据集的有效性。

Conclusion: RoboAfford++数据集和RoboAfford-Eval基准有效解决了视觉语言模型在细粒度可操作性学习方面的局限性，为机器人操作和导航提供了更好的环境理解能力。

Abstract: Robotic manipulation and navigation are fundamental capabilities of embodied intelligence, enabling effective robot interactions with the physical world. Achieving these capabilities requires a cohesive understanding of the environment, including object recognition to localize target objects, object affordances to identify potential interaction areas and spatial affordances to discern optimal areas for both object placement and robot movement. While Vision-Language Models (VLMs) excel at high-level task planning and scene understanding, they often struggle to infer actionable positions for physical interaction, such as functional grasping points and permissible placement regions. This limitation stems from the lack of fine-grained annotations for object and spatial affordances in their training datasets. To tackle this challenge, we introduce RoboAfford++, a generative AI-enhanced dataset for multimodal affordance learning for both robotic manipulation and navigation. Our dataset comprises 869,987 images paired with 2.0 million question answering (QA) annotations, covering three critical tasks: object affordance recognition to identify target objects based on attributes and spatial relationships, object affordance prediction to pinpoint functional parts for manipulation, and spatial affordance localization to identify free space for object placement and robot navigation. Complementing this dataset, we propose RoboAfford-Eval, a comprehensive benchmark for assessing affordance-aware prediction in real-world scenarios, featuring 338 meticulously annotated samples across the same three tasks. Extensive experimental results reveal the deficiencies of existing VLMs in affordance learning, while fine-tuning on the RoboAfford++ dataset significantly enhances their ability to reason about object and spatial affordances, validating the dataset's effectiveness.

</details>


### [65] [ClutterNav: Gradient-Guided Search for Efficient 3D Clutter Removal with Learned Costmaps](https://arxiv.org/abs/2511.12479)
*Navin Sriram Ravie,Keerthi Vasan M,Bijo Sebastian*

Main category: cs.RO

TL;DR: ClutterNav是一个用于密集杂物中目标物体检索的决策框架，通过强化学习动态选择最佳移除对象，最小化堆栈扰动。


<details>
  <summary>Details</summary>
Motivation: 解决密集杂物中目标物体检索的挑战，传统基于规则的方法计算开销大，端到端强化学习方法缺乏可解释性和泛化性。

Method: 将问题建模为连续强化学习任务，使用从演示中训练的可移除性评估器估计移除成本，结合积分梯度评估周围物体对目标可达性的影响。

Result: 在仿真和真实实验中验证，实现了实时、遮挡感知的决策，在部分可观测环境中表现出接近人类的策略序列。

Conclusion: ClutterNav框架无需预定义启发式规则，能够平衡即时可移除性和长期目标暴露，实现高效的物体检索策略。

Abstract: Dense clutter removal for target object retrieval presents a challenging problem, especially when targets are embedded deep within densely-packed configurations. It requires foresight to minimize overall changes to the clutter configuration while accessing target objects, avoiding stack destabilization and reducing the number of object removals required. Rule-based planners when applied to this problem, rely on rigid heuristics, leading to high computational overhead. End-to-end reinforcement learning approaches struggle with interpretability and generalizability over different conditions. To address these issues, we present ClutterNav, a novel decision-making framework that can identify the next best object to be removed so as to access a target object in a given clutter, while minimising stack disturbances. ClutterNav formulates the problem as a continuous reinforcement learning task, where each object removal dynamically updates the understanding of the scene. A removability critic, trained from demonstrations, estimates the cost of removing any given object based on geometric and spatial features. This learned cost is complemented by integrated gradients that assess how the presence or removal of surrounding objects influences the accessibility of the target. By dynamically prioritizing actions that balance immediate removability against long-term target exposure, ClutterNav achieves near human-like strategic sequencing, without predefined heuristics. The proposed approach is validated extensively in simulation and over real-world experiments. The results demonstrate real-time, occlusion-aware decision-making in partially observable environments.

</details>


### [66] [Botany Meets Robotics in Alpine Scree Monitoring](https://arxiv.org/abs/2511.12526)
*Davide De Benedittis,Giovanni Di Lorenzo,Franco Angelini,Barbara Valle,Marina Serena Borgatti,Paolo Remagnino,Marco Caccianiga,Manolo Garabini*

Main category: cs.RO

TL;DR: 使用腿式机器人ANYmal C在意大利阿尔卑斯山区进行碎石栖息地监测，结合深度学习技术识别关键植物物种，提高监测效率和频率。


<details>
  <summary>Details</summary>
Motivation: 碎石栖息地因高海拔特性面临气候变化严重威胁，传统监测需要专家在偏远危险地区进行实地考察，过程资源密集且耗时。

Method: 部署ANYmal C腿式机器人在意大利阿尔卑斯生物区域进行两年实地调查，利用深度学习检测和分类关键植物物种。

Result: 敏捷腿式机器人能够导航具有挑战性的地形，提高碎石监测的频率和效率，与传统植物社会学调查结合可优化数据采集、存储和使用。

Conclusion: 这项研究为环境科学中的机器人应用做出贡献，为更全面和可持续的栖息地监测与保护方法铺平道路。

Abstract: According to the European Union's Habitat Directive, habitat monitoring plays a critical role in response to the escalating problems posed by biodiversity loss and environmental degradation. Scree habitats, hosting unique and often endangered species, face severe threats from climate change due to their high-altitude nature. Traditionally, their monitoring has required highly skilled scientists to conduct extensive fieldwork in remote, potentially hazardous locations, making the process resource-intensive and time-consuming. This paper presents a novel approach for scree habitat monitoring using a legged robot to assist botanists in data collection and species identification. Specifically, we deployed the ANYmal C robot in the Italian Alpine bio-region in two field campaigns spanning two years and leveraged deep learning to detect and classify key plant species of interest. Our results demonstrate that agile legged robots can navigate challenging terrains and increase the frequency and efficiency of scree monitoring. When paired with traditional phytosociological surveys performed by botanists, this robotics-assisted protocol not only streamlines field operations but also enhances data acquisition, storage, and usage. The outcomes of this research contribute to the evolving landscape of robotics in environmental science, paving the way for a more comprehensive and sustainable approach to habitat monitoring and preservation.

</details>


### [67] [EcoFlight: Finding Low-Energy Paths Through Obstacles for Autonomous Sensing Drones](https://arxiv.org/abs/2511.12618)
*Jordan Leyva,Nahim J. Moran Vera,Yihan Xu,Adrien Durasno,Christopher U. Romero,Tendai Chimuka,Gabriel O. Huezo Ramirez,Ziqian Dong,Roberto Rojas-Cessa*

Main category: cs.RO

TL;DR: EcoFlight是一种能量高效的无人机路径规划算法，可在3D空间中避开障碍物找到能耗最低的飞行路径。


<details>
  <summary>Details</summary>
Motivation: 现有无人机路径规划方案很少考虑障碍物规避，而障碍物规避又是能耗密集的，这对点对点无人机飞行的效率至关重要。

Method: 基于无人机推进系统和飞行动力学建模能耗，开发能量高效的路径查找算法，在3D空间中确定能耗最低的路线。

Result: 在各种障碍物密度下的仿真结果表明，EcoFlight始终能找到比直接飞行和最短距离方案能耗更低的路径，特别是在高密度环境中表现更佳。合适的飞行速度还能进一步提升节能效果。

Conclusion: EcoFlight算法能够有效解决无人机障碍物规避问题，显著降低能耗，特别是在复杂障碍环境中具有明显优势。

Abstract: Obstacle avoidance path planning for uncrewed aerial vehicles (UAVs), or drones, is rarely addressed in most flight path planning schemes, despite obstacles being a realistic condition. Obstacle avoidance can also be energy-intensive, making it a critical factor in efficient point-to-point drone flights. To address these gaps, we propose EcoFlight, an energy-efficient pathfinding algorithm that determines the lowest-energy route in 3D space with obstacles. The algorithm models energy consumption based on the drone propulsion system and flight dynamics. We conduct extensive evaluations, comparing EcoFlight with direct-flight and shortest-distance schemes. The simulation results across various obstacle densities show that EcoFlight consistently finds paths with lower energy consumption than comparable algorithms, particularly in high-density environments. We also demonstrate that a suitable flying speed can further enhance energy savings.

</details>


### [68] [Task-Aware Morphology Optimization of Planar Manipulators via Reinforcement Learning](https://arxiv.org/abs/2511.12650)
*Arvind Kumar Mishra,Sohom Chakrabarty*

Main category: cs.RO

TL;DR: 使用强化学习进行机器人形态优化，验证了RL能够仅通过奖励反馈发现已知解析最优解，并在无解析解情况下可靠收敛。


<details>
  <summary>Details</summary>
Motivation: 大多数形态设计任务没有闭式解，网格搜索或启发式搜索在高维空间中成本高昂，需要探索RL作为可扩展的替代方案。

Method: 使用Yoshikawa可操作性指数，比较SAC、DDPG、PPO三种RL算法与网格搜索和黑盒优化器，在2R机械臂上测试圆形、椭圆形和矩形路径跟踪。

Result: 所有方法都能收敛到已知解析最优解，在无解析解情况下RL继续可靠收敛，而网格和黑盒方法需要更多评估预算。

Conclusion: RL对于恢复已知最优解和解决无解析解的形态优化问题都有效，表明数值恢复最优解无需提供解析结构是可行的。

Abstract: In this work, Yoshikawa's manipulability index is used to investigate reinforcement learning (RL) as a framework for morphology optimization in planar robotic manipulators. A 2R manipulator tracking a circular end-effector path is first examined because this case has a known analytical optimum: equal link lengths and the second joint orthogonal to the first. This serves as a validation step to test whether RL can rediscover the optimum using reward feedback alone, without access to the manipulability expression or the Jacobian. Three RL algorithms (SAC, DDPG, and PPO) are compared with grid search and black-box optimizers, with morphology represented by a single action parameter phi that maps to the link lengths. All methods converge to the analytical solution, showing that numerical recovery of the optimum is possible without supplying analytical structure.
  Most morphology design tasks have no closed-form solutions, and grid or heuristic search becomes expensive as dimensionality increases. RL is therefore explored as a scalable alternative. The formulation used for the circular path is extended to elliptical and rectangular paths by expanding the action space to the full morphology vector (L1, L2, theta2). In these non-analytical settings, RL continues to converge reliably, whereas grid and black-box methods require far larger evaluation budgets. These results indicate that RL is effective for both recovering known optima and solving morphology optimization problems without analytical solutions.

</details>


### [69] [Prompt-Driven Domain Adaptation for End-to-End Autonomous Driving via In-Context RL](https://arxiv.org/abs/2511.12755)
*Aleesha Khurram,Amir Moeini,Shangtong Zhang,Rohan Chandra*

Main category: cs.RO

TL;DR: 本文提出了一种基于上下文强化学习的推理时少样本提示驱动领域自适应方法，用于恶劣天气条件下的闭环自动驾驶，无需模型参数更新或额外数据收集。


<details>
  <summary>Details</summary>
Motivation: 现有领域自适应方法需要收集目标域数据或重新训练模型，这在自动驾驶规模化时变得不切实际。现有的提示驱动方法仅限于感知任务且需要专家少样本数据。

Method: 使用上下文强化学习进行推理时少样本提示驱动领域自适应，利用推理过程中观察到的通用轨迹，无需模型参数更新。

Result: 在CARLA模拟器中的实验表明，相比最先进的提示驱动领域自适应基线，ICRL方法在目标域中产生了更安全、更高效、更舒适的驾驶策略。

Conclusion: ICRL方法成功将提示驱动领域自适应扩展到闭环驾驶任务，为自动驾驶领域自适应提供了一种实用的解决方案。

Abstract: Despite significant progress and advances in autonomous driving, many end-to-end systems still struggle with domain adaptation (DA), such as transferring a policy trained under clear weather to adverse weather conditions. Typical DA strategies in the literature include collecting additional data in the target domain or re-training the model, or both. Both these strategies quickly become impractical as we increase scale and complexity of driving. These limitations have encouraged investigation into few-shot and zero-shot prompt-driven DA at inference time involving LLMs and VLMs. These methods work by adding a few state-action trajectories during inference to the prompt (similar to in-context learning). However, there are two limitations of such an approach: $(i)$ prompt-driven DA methods are currently restricted to perception tasks such as detection and segmentation and $(ii)$ they require expert few-shot data. In this work, we present a new approach to inference-time few-shot prompt-driven DA for closed-loop autonomous driving in adverse weather condition using in-context reinforcement learning (ICRL). Similar to other prompt-driven DA methods, our approach does not require any updates to the model parameters nor does it require additional data collection in adversarial weather regime. Furthermore, our approach advances the state-of-the-art in prompt-driven DA by extending to closed driving using general trajectories observed during inference. Our experiments using the CARLA simulator show that ICRL results in safer, more efficient, and more comfortable driving policies in the target domain compared to state-of-the-art prompt-driven DA baselines.

</details>


### [70] [DR. Nav: Semantic-Geometric Representations for Proactive Dead-End Recovery and Navigation](https://arxiv.org/abs/2511.12778)
*Vignesh Rajagopal,Kasun Weerakoon Kulathun Mudiyanselage,Gershom Devake Seneviratne,Pon Aswin Sankaralingam,Mohamed Elnoor,Jing Liang,Rohan Chandra,Dinesh Manocha*

Main category: cs.RO

TL;DR: DR.Nav是一种用于自主导航的新方法，特别关注死胡同检测和恢复，在非结构化环境中通过RGB-LiDAR跨模态融合和贝叶斯推理生成实时语义成本地图，显著提高了检测准确性和路径效率。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中，机器人导航面临角落、植被遮挡和阻塞路口等挑战，传统方法仅编码可通行性，缺乏对死胡同预测和恢复的主动策略，导致导航效率低下和安全风险。

Method: 采用RGB-LiDAR跨模态融合与基于注意力的过滤，通过贝叶斯推理估计每个单元的死亡可能性及恢复点，生成连续实时的语义成本地图，将恢复感知风险显式纳入导航成本计算。

Result: 在密集室内外场景中评估显示，检测准确率提高83.33%，目标到达时间减少52.4%，优于DWA、MPPI和Nav2 DWB等先进规划器。

Conclusion: DR.Nav通过统一死胡同预测与恢复的主动策略，在非结构化环境中实现了更安全、高效的自主导航，为机器人导航提供了新的解决方案。

Abstract: We present DR. Nav (Dead-End Recovery-aware Navigation), a novel approach to autonomous navigation in scenarios where dead-end detection and recovery are critical, particularly in unstructured environments where robots must handle corners, vegetation occlusions, and blocked junctions. DR. Nav introduces a proactive strategy for navigation in unmapped environments without prior assumptions. Our method unifies dead-end prediction and recovery by generating a single, continuous, real-time semantic cost map. Specifically, DR. Nav leverages cross-modal RGB-LiDAR fusion with attention-based filtering to estimate per-cell dead-end likelihoods and recovery points, which are continuously updated through Bayesian inference to enhance robustness. Unlike prior mapping methods that only encode traversability, DR. Nav explicitly incorporates recovery-aware risk into the navigation cost map, enabling robots to anticipate unsafe regions and plan safer alternative trajectories. We evaluate DR. Nav across multiple dense indoor and outdoor scenarios and demonstrate an increase of 83.33% in accuracy in detection, a 52.4% reduction in time-to-goal (path efficiency), compared to state-of-the-art planners such as DWA, MPPI, and Nav2 DWB. Furthermore, the dead-end classifier functions

</details>


### [71] [ActiveGrasp: Information-Guided Active Grasping with Calibrated Energy-based Model](https://arxiv.org/abs/2511.12795)
*Boshu Lei,Wen Jiang,Kostas Daniilidis*

Main category: cs.RO

TL;DR: 提出了一种基于能量校准的抓取姿态生成模型和主动视角选择方法，用于解决密集杂乱环境中的机器人抓取问题。


<details>
  <summary>Details</summary>
Motivation: 解决密集杂乱环境中的机器人抓取挑战，现有方法要么忽视了抓取分布在信息增益估计中的重要性，要么依赖于抓取分布的投影而忽略了SE(3)流形上的结构。

Method: 使用校准的能量模型在SE(3)流形上生成多模态抓取分布，并通过估计校准分布的信息增益来选择下一个最佳视角。

Result: 在模拟环境和真实机器人设置上的实验表明，与现有最先进模型相比，该方法能够在有限视角预算下成功抓取杂乱环境中的物体。

Conclusion: 该方法有效解决了密集杂乱环境中的抓取问题，同时模拟环境可作为未来主动抓取研究的可复现平台。

Abstract: Grasping in a densely cluttered environment is a challenging task for robots. Previous methods tried to solve this problem by actively gathering multiple views before grasp pose generation. However, they either overlooked the importance of the grasp distribution for information gain estimation or relied on the projection of the grasp distribution, which ignores the structure of grasp poses on the SE(3) manifold. To tackle these challenges, we propose a calibrated energy-based model for grasp pose generation and an active view selection method that estimates information gain from grasp distribution. Our energy-based model captures the multi-modality nature of grasp distribution on the SE(3) manifold. The energy level is calibrated to the success rate of grasps so that the predicted distribution aligns with the real distribution. The next best view is selected by estimating the information gain for grasp from the calibrated distribution conditioned on the reconstructed environment, which could efficiently drive the robot to explore affordable parts of the target object. Experiments on simulated environments and real robot setups demonstrate that our model could successfully grasp objects in a cluttered environment with limited view budgets compared to previous state-of-the-art models. Our simulated environment can serve as a reproducible platform for future research on active grasping. The source code of our paper will be made public when the paper is released to the public.

</details>


### [72] [Structured Imitation Learning of Interactive Policies through Inverse Games](https://arxiv.org/abs/2511.12848)
*Max M. Sun,Todd Murphey*

Main category: cs.RO

TL;DR: 提出了一种结合生成式单智能体策略学习和博弈论结构的模仿学习框架，用于学习交互式策略，在5智能体社交导航任务中仅用50个演示就取得了与真实交互策略相当的性能。


<details>
  <summary>Details</summary>
Motivation: 基于生成模型的模仿学习方法在从人类演示中学习高复杂度运动技能方面取得了良好效果，但在无显式通信的共享空间中与人类协调的交互式策略学习仍然具有挑战性，因为多智能体交互的行为复杂度远高于非交互任务。

Method: 将学习明确分为两个步骤：首先使用标准模仿学习从多智能体演示中学习个体行为模式，然后通过求解逆博弈问题来结构化学习智能体间的依赖关系。

Result: 在合成的5智能体社交导航任务中，该方法显著改善了非交互策略，仅使用50个演示就实现了与真实交互策略相当的性能。

Conclusion: 这些结果凸显了结构化模仿学习在交互式场景中的潜力。

Abstract: Generative model-based imitation learning methods have recently achieved strong results in learning high-complexity motor skills from human demonstrations. However, imitation learning of interactive policies that coordinate with humans in shared spaces without explicit communication remains challenging, due to the significantly higher behavioral complexity in multi-agent interactions compared to non-interactive tasks. In this work, we introduce a structured imitation learning framework for interactive policies by combining generative single-agent policy learning with a flexible yet expressive game-theoretic structure. Our method explicitly separates learning into two steps: first, we learn individual behavioral patterns from multi-agent demonstrations using standard imitation learning; then, we structurally learn inter-agent dependencies by solving an inverse game problem. Preliminary results in a synthetic 5-agent social navigation task show that our method significantly improves non-interactive policies and performs comparably to the ground truth interactive policy using only 50 demonstrations. These results highlight the potential of structured imitation learning in interactive settings.

</details>


### [73] [Towards High-Consistency Embodied World Model with Multi-View Trajectory Videos](https://arxiv.org/abs/2511.12882)
*Taiyi Su,Jian Zhu,Yaxuan Li,Chong Ma,Zitai Huang,Yichen Zhu,Hanli Wang,Yi Xu*

Main category: cs.RO

TL;DR: MTV-World是一种具身世界模型，通过多视角轨迹视频控制实现精确的视觉运动预测，解决了现有模型在将低级动作转换为精确机器人运动时的物理不一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有具身世界模型难以准确地将低级动作（如关节位置）转换为预测帧中的精确机器人运动，导致与现实世界物理交互不一致。

Method: 提出多视角轨迹视频控制方法，使用通过相机内外参和笛卡尔空间变换获得的轨迹视频作为控制信号，采用多视角框架补偿空间信息损失。

Result: 在复杂的双臂场景中实现了精确的控制执行和准确的物理交互建模。

Conclusion: MTV-World通过多视角轨迹视频控制有效解决了具身世界模型中的物理一致性问题，在复杂机器人场景中表现出色。

Abstract: Embodied world models aim to predict and interact with the physical world through visual observations and actions. However, existing models struggle to accurately translate low-level actions (e.g., joint positions) into precise robotic movements in predicted frames, leading to inconsistencies with real-world physical interactions. To address these limitations, we propose MTV-World, an embodied world model that introduces Multi-view Trajectory-Video control for precise visuomotor prediction. Specifically, instead of directly using low-level actions for control, we employ trajectory videos obtained through camera intrinsic and extrinsic parameters and Cartesian-space transformation as control signals. However, projecting 3D raw actions onto 2D images inevitably causes a loss of spatial information, making a single view insufficient for accurate interaction modeling. To overcome this, we introduce a multi-view framework that compensates for spatial information loss and ensures high-consistency with physical world. MTV-World forecasts future frames based on multi-view trajectory videos as input and conditioning on an initial frame per view. Furthermore, to systematically evaluate both robotic motion precision and object interaction accuracy, we develop an auto-evaluation pipeline leveraging multimodal large models and referring video object segmentation models. To measure spatial consistency, we formulate it as an object location matching problem and adopt the Jaccard Index as the evaluation metric. Extensive experiments demonstrate that MTV-World achieves precise control execution and accurate physical interaction modeling in complex dual-arm scenarios.

</details>


### [74] [Air-Chamber Based Soft Six-Axis Force/Torque Sensor for Human-Robot Interaction](https://arxiv.org/abs/2511.12896)
*Jun Huo,Hongge Ru,Bo Yang,Xingjian Chen,Xi Li,Jian Huang*

Main category: cs.RO

TL;DR: 提出了一种基于16通道气压计的软气室型六轴力/力矩传感器，采用刚性-柔性分层结构进行解耦，将六轴解耦问题简化为两个三轴解耦问题，实现了软性且精确的六轴力测量。


<details>
  <summary>Details</summary>
Motivation: 软多轴力/力矩传感器能提供安全精确的力交互，但六轴力/力矩传感器存在交叉轴耦合问题，导致校准困难和精度下降，开发软性且精确的六轴传感器具有挑战性。

Method: 使用硅橡胶制成的超弹性气室容纳16通道气压计，提出基于刚性-柔性分层结构的有效解耦方法，通过有限元模型仿真和实验验证方法的可行性。

Result: 原型传感器测量范围为50N力和1Nm力矩，平均偏差4.9%、重复性2.7%、非线性5.8%、迟滞6.7%，在静态负载响应、动态负载响应和动态响应特性方面表现出令人满意的传感性能。

Conclusion: 该传感器在保持软性的同时展现出良好的传感性能，验证了所提出方法的有效性，为软性六轴力/力矩传感器的开发提供了可行方案。

Abstract: Soft multi-axis force/torque sensors provide safe and precise force interaction. Capturing the complete degree-of-freedom of force is imperative for accurate force measurement with six-axis force/torque sensors. However, cross-axis coupling can lead to calibration issues and decreased accuracy. In this instance, developing a soft and accurate six-axis sensor is a challenging task. In this paper, a soft air-chamber type six-axis force/torque sensor with 16-channel barometers is introduced, which housed in hyper-elastic air chambers made of silicone rubber. Additionally, an effective decoupling method is proposed, based on a rigid-soft hierarchical structure, which reduces the six-axis decoupling problem to two three-axis decoupling problems. Finite element model simulation and experiments demonstrate the compatibility of the proposed approach with reality. The prototype's sensing performance is quantitatively measured in terms of static load response, dynamic load response and dynamic response characteristic. It possesses a measuring range of 50 N force and 1 Nm torque, and the average deviation, repeatability, non-linearity and hysteresis are 4.9$\%$, 2.7$\%$, 5.8$\%$ and 6.7$\%$, respectively. The results indicate that the prototype exhibits satisfactory sensing performance while maintaining its softness due to the presence of soft air chambers.

</details>


### [75] [TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints](https://arxiv.org/abs/2511.12910)
*Yong Li,Yujun Huang,Yi Chen,Hui Cheng*

Main category: cs.RO

TL;DR: 提出了一种名为TOPP-DWR的差分驱动轮式机器人时间最优路径参数化算法，该算法考虑了角速度、关节速度等约束，并将其转化为线性速度约束，通过二阶锥规划求解。


<details>
  <summary>Details</summary>
Motivation: 现有移动机器人时间最优路径参数化研究通常忽略角速度和关节速度约束，导致在实际应用中控制性能下降。

Method: 使用非均匀B样条表示任务空间初始轨迹，将角速度、关节速度、线速度和线加速度约束统一表示为线性速度约束，引入松弛变量将问题重构为二阶锥规划问题。

Result: 对比实验验证了该方法的优越性，定量性能指标表明TOPP-DWR能够在满足所有约束的同时实现时间最优路径参数化。

Conclusion: 现场自主导航实验验证了TOPP-DWR在实际应用中的实用性。

Abstract: Differential-driven wheeled robots (DWR) represent the quintessential type of mobile robots and find extensive appli- cations across the robotic field. Most high-performance control approaches for DWR explicitly utilize the linear and angular velocities of the trajectory as control references. However, existing research on time-optimal path parameterization (TOPP) for mobile robots usually neglects the angular velocity and joint vel- ocity constraints, which can result in degraded control perfor- mance in practical applications. In this article, a systematic and practical TOPP algorithm named TOPP-DWR is proposed for DWR and other mobile robots. First, the non-uniform B-spline is adopted to represent the initial trajectory in the task space. Second, the piecewise-constant angular velocity, as well as joint velocity, linear velocity, and linear acceleration constraints, are incorporated into the TOPP problem. During the construction of the optimization problem, the aforementioned constraints are uniformly represented as linear velocity constraints. To boost the numerical computational efficiency, we introduce a slack variable to reformulate the problem into second-order-cone programming (SOCP). Subsequently, comparative experiments are conducted to validate the superiority of the proposed method. Quantitative performance indexes show that TOPP-DWR achieves TOPP while adhering to all constraints. Finally, field autonomous navigation experiments are carried out to validate the practicability of TOPP-DWR in real-world applications.

</details>


### [76] [DiffuDepGrasp: Diffusion-based Depth Noise Modeling Empowers Sim2Real Robotic Grasping](https://arxiv.org/abs/2511.12912)
*Yingting Zhou,Wenbo Cui,Weiheng Liu,Guixing Chen,Haoran Li,Dongbin Zhao*

Main category: cs.RO

TL;DR: DiffuDepGrasp是一个可部署的sim2real框架，通过仅使用仿真数据进行策略训练实现零样本转移，核心创新是扩散深度生成器，能够合成几何精确的仿真深度并学习传感器真实噪声。


<details>
  <summary>Details</summary>
Motivation: 解决深度传感器在真实环境中产生的空洞和噪声等伪影导致的sim2real差距，以及现有方法存在的数据效率低和部署复杂性问题。

Method: 提出DiffuDepGrasp框架，包含扩散深度生成器，由扩散深度模块和噪声嫁接模块组成，前者利用时间几何先验训练条件扩散模型捕获复杂传感器噪声分布，后者在注入感知伪影时保持度量精度。

Result: 在12个物体抓取任务中达到95.7%的平均成功率，实现零样本转移，并对未见物体表现出强泛化能力。

Conclusion: DiffuDepGrasp通过仅使用原始深度输入消除了计算开销，成功解决了sim2real转移中的数据效率低和部署复杂性问题。

Abstract: Transferring the depth-based end-to-end policy trained in simulation to physical robots can yield an efficient and robust grasping policy, yet sensor artifacts in real depth maps like voids and noise establish a significant sim2real gap that critically impedes policy transfer. Training-time strategies like procedural noise injection or learned mappings suffer from data inefficiency due to unrealistic noise simulation, which is often ineffective for grasping tasks that require fine manipulation or dependency on paired datasets heavily. Furthermore, leveraging foundation models to reduce the sim2real gap via intermediate representations fails to mitigate the domain shift fully and adds computational overhead during deployment. This work confronts dual challenges of data inefficiency and deployment complexity. We propose DiffuDepGrasp, a deploy-efficient sim2real framework enabling zero-shot transfer through simulation-exclusive policy training. Its core innovation, the Diffusion Depth Generator, synthesizes geometrically pristine simulation depth with learned sensor-realistic noise via two synergistic modules. The first Diffusion Depth Module leverages temporal geometric priors to enable sample-efficient training of a conditional diffusion model that captures complex sensor noise distributions, while the second Noise Grafting Module preserves metric accuracy during perceptual artifact injection. With only raw depth inputs during deployment, DiffuDepGrasp eliminates computational overhead and achieves a 95.7% average success rate on 12-object grasping with zero-shot transfer and strong generalization to unseen objects.Project website: https://diffudepgrasp.github.io/.

</details>


### [77] [GUIDE: Gaussian Unified Instance Detection for Enhanced Obstacle Perception in Autonomous Driving](https://arxiv.org/abs/2511.12941)
*Chunyong Hu,Qi Luo,Jianyun Xu,Song Wang,Qiang Li,Sheng Yang*

Main category: cs.RO

TL;DR: GUIDE是一个基于3D高斯的新型自动驾驶感知框架，通过高斯到体素投影实现实例检测和占用预测，相比传统3D边界框方法能更好地处理不规则形状物体，并在nuScenes数据集上实现了21.61的实例占用mAP，比现有方法提升50%。


<details>
  <summary>Details</summary>
Motivation: 传统自动驾驶感知方法主要依赖3D边界框来表示障碍物，但这种方法难以准确捕捉现实世界中不规则形状物体的复杂性，需要更精细的表示方法来提升感知精度。

Method: 采用3D高斯进行实例检测和占用预测，使用稀疏表示策略和Gaussian-to-Voxel Splatting技术，在避免密集体素网格计算开销的同时提供细粒度的实例级占用数据。

Result: 在nuScenes数据集上，GUIDE实现了21.61的实例占用mAP，比现有方法提升50%，同时具备竞争力的跟踪能力。

Conclusion: GUIDE为自动驾驶感知系统设立了新基准，成功结合了精度和计算效率，能更好地应对现实驾驶环境的复杂性。

Abstract: In the realm of autonomous driving, accurately detecting surrounding obstacles is crucial for effective decision-making. Traditional methods primarily rely on 3D bounding boxes to represent these obstacles, which often fail to capture the complexity of irregularly shaped, real-world objects. To overcome these limitations, we present GUIDE, a novel framework that utilizes 3D Gaussians for instance detection and occupancy prediction. Unlike conventional occupancy prediction methods, GUIDE also offers robust tracking capabilities. Our framework employs a sparse representation strategy, using Gaussian-to-Voxel Splatting to provide fine-grained, instance-level occupancy data without the computational demands associated with dense voxel grids. Experimental validation on the nuScenes dataset demonstrates GUIDE's performance, with an instance occupancy mAP of 21.61, marking a 50\% improvement over existing methods, alongside competitive tracking capabilities. GUIDE establishes a new benchmark in autonomous perception systems, effectively combining precision with computational efficiency to better address the complexities of real-world driving environments.

</details>


### [78] [SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models](https://arxiv.org/abs/2511.12972)
*Siddarth Narasimhan,Matthew Lisondra,Haitong Wang,Goldie Nejat*

Main category: cs.RO

TL;DR: SplatSearch是一种解决实例图像目标导航问题的新架构，利用稀疏视图3D高斯泼溅重建，通过多视图扩散模型补全渲染图像，结合新颖的前沿探索策略，在未知环境中搜索特定目标。


<details>
  <summary>Details</summary>
Motivation: 解决实例图像目标导航问题中的挑战：参考图像可能来自任意视角，机器人必须在稀疏视图场景重建下操作。

Method: 使用稀疏在线3D高斯泼溅重建渲染候选对象周围的多视角图像，利用多视图扩散模型补全缺失区域，实现与目标图像的稳健特征匹配，并引入基于语义和视觉上下文的前沿探索策略。

Result: 在逼真家庭环境和真实世界环境中的广泛实验验证了SplatSearch在成功率和成功路径长度方面优于当前最先进方法。

Conclusion: SplatSearch通过结合3D高斯泼溅重建、多视图扩散补全和语义感知前沿探索，有效解决了实例图像目标导航问题。

Abstract: The Instance Image Goal Navigation (IIN) problem requires mobile robots deployed in unknown environments to search for specific objects or people of interest using only a single reference goal image of the target. This problem can be especially challenging when: 1) the reference image is captured from an arbitrary viewpoint, and 2) the robot must operate with sparse-view scene reconstructions. In this paper, we address the IIN problem, by introducing SplatSearch, a novel architecture that leverages sparse-view 3D Gaussian Splatting (3DGS) reconstructions. SplatSearch renders multiple viewpoints around candidate objects using a sparse online 3DGS map, and uses a multi-view diffusion model to complete missing regions of the rendered images, enabling robust feature matching against the goal image. A novel frontier exploration policy is introduced which uses visual context from the synthesized viewpoints with semantic context from the goal image to evaluate frontier locations, allowing the robot to prioritize frontiers that are semantically and visually relevant to the goal image. Extensive experiments in photorealistic home and real-world environments validate the higher performance of SplatSearch against current state-of-the-art methods in terms of Success Rate and Success Path Length. An ablation study confirms the design choices of SplatSearch.

</details>


### [79] [CUTE-Planner: Confidence-aware Uneven Terrain Exploration Planner](https://arxiv.org/abs/2511.12984)
*Miryeong Park,Dongjin Cho,Sanghyun Kim,Younggun Cho*

Main category: cs.RO

TL;DR: 提出一个集成安全路径生成、自适应置信度更新和置信度感知探索策略的框架，用于行星探测机器人在不确定地形中的导航和建图。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂地形特征（如陨石坑）附近高程估计的高度不确定性时存在不足，缺乏不确定性减少的探索策略，且未充分考虑高程不确定性对导航安全和地图质量的影响。

Method: 使用基于卡尔曼滤波的高程估计方法生成地形可通行性和置信度分数，将其整合到图基探索规划器（GBP）中，优先探索可通行的低置信度区域。

Result: 在模拟月球实验中，相比基线GBP实现了69%的不确定性减少。任务成功率方面，本方法达到100%，而基线GBP为0%。

Conclusion: 该方法显著提高了行星探测机器人在不确定地形中的探索安全性和地图可靠性。

Abstract: Planetary exploration robots must navigate uneven terrain while building reliable maps for space missions. However, most existing methods incorporate traversability constraints but may not handle high uncertainty in elevation estimates near complex features like craters, do not consider exploration strategies for uncertainty reduction, and typically fail to address how elevation uncertainty affects navigation safety and map quality. To address the problems, we propose a framework integrating safe path generation, adaptive confidence updates, and confidence-aware exploration strategies. Using Kalman-based elevation estimation, our approach generates terrain traversability and confidence scores, then incorporates them into Graph-Based exploration Planner (GBP) to prioritize exploration of traversable low-confidence regions. We evaluate our framework through simulated lunar experiments using a novel low-confidence region ratio metric, achieving 69% uncertainty reduction compared to baseline GBP. In terms of mission success rate, our method achieves 100% while baseline GBP achieves 0%, demonstrating improvements in exploration safety and map reliability.

</details>


### [80] [APP: A* Post-Processing Algorithm for Robots with Bidirectional Shortcut and Path Perturbation](https://arxiv.org/abs/2511.13042)
*Yong Li,Hui Cheng*

Main category: cs.RO

TL;DR: 提出了一种名为APP的A*后处理算法，通过双向顶点缩减和路径扰动来优化A*等图搜索规划器生成的路径，减少不必要的转向和路径长度。


<details>
  <summary>Details</summary>
Motivation: A*等图搜索规划器生成的路径通常不是最短的，且在无障碍物区域存在不必要的转向（锯齿模式），这与人类直觉不符。

Method: 1. 双向顶点缩减算法处理路径和环境的不对称性；2. 在顶点缩减过程中采用彻底捷径策略；3. 迭代路径扰动算法局部减少不必要转向。

Result: 实验表明APP在规划时间、路径长度和不必要转向次数方面优于现有方法，并通过现场导航实验验证了实用性。

Conclusion: APP算法能有效优化A*等规划器生成的路径，提高路径质量和导航性能。

Abstract: Paths generated by A* and other graph-search-based planners are widely used in the robotic field. Due to the restricted node-expansion directions, the resulting paths are usually not the shortest. Besides, unnecessary heading changes, or zig-zag patterns, exist even when no obstacle is nearby, which is inconsistent with the human intuition that the path segments should be straight in wide-open space due to the absence of obstacles. This article puts forward a general and systematic post-processing algorithm for A* and other graph-search-based planners. The A* post-processing algorithm, called APP, is developed based on the costmap, which is widely used in commercial service robots. First, a bidirectional vertices reduction algorithm is proposed to tackle the asymm- etry of the path and the environments. During the forward and backward vertices reduction, a thorough shortcut strategy is put forward to improve the path-shortening performance and avoid unnecessary heading changes. Second, an iterative path perturbation algorithm is adopted to locally reduce the number of unnecessary heading changes and improve the path smooth- ness. Comparative experiments are then carried out to validate the superiority of the proposed method. Quantitative performance indexes show that APP outperforms the existing methods in planning time, path length as well as the number of unnecessary heading changes. Finally, field navigation experiments are carried out to verify the practicability of APP.

</details>


### [81] [Unidirectional-Road-Network-Based Global Path Planning for Cleaning Robots in Semi-Structured Environments](https://arxiv.org/abs/2511.13048)
*Yong Li,Hui Cheng*

Main category: cs.RO

TL;DR: 提出了一种用于半结构化环境中清洁机器人全局路径规划的系统方法，通过构建单向道路网络表示交通约束，采用混合策略保证规划结果，允许在起点和终点横穿道路以缩短路径，并使用双层势能图处理复杂交叉口情况。


<details>
  <summary>Details</summary>
Motivation: 现有自由空间路径规划方法忽视交通规则约束导致频繁重规划和碰撞风险，而结构化环境方法严格遵循道路网络导致路径过长影响导航效率，需要解决半结构化环境中的路径规划问题。

Method: 构建单向道路网络表示交通约束，提出混合策略保证规划结果，允许起点和终点横穿道路，使用双层势能图处理复杂交叉口，实现路径长度与道路网络一致性的平衡。

Result: 定量实验结果表明，相比现有方法，该方法在路径长度和道路网络一致性之间取得了更好的平衡。

Conclusion: 该方法为半结构化环境中的全局路径规划提供了一种通用系统方法，能够有效平衡路径长度和交通规则约束，提高清洁机器人的导航效率。

Abstract: Practical global path planning is critical for commercializing cleaning robots working in semi-structured environments. In the literature, global path planning methods for free space usually focus on path length and neglect the traffic rule constraints of the environments, which leads to high-frequency re-planning and increases collision risks. In contrast, those for structured environments are developed mainly by strictly complying with the road network representing the traffic rule constraints, which may result in an overlong path that hinders the overall navigation efficiency. This article proposes a general and systematic approach to improve global path planning performance in semi-structured environments. A unidirectional road network is built to represent the traffic constraints in semi-structured environments and a hybrid strategy is proposed to achieve a guaranteed planning result.Cutting across the road at the starting and the goal points are allowed to achieve a shorter path. Especially, a two-layer potential map is proposed to achieve a guaranteed performance when the starting and the goal points are in complex intersections. Comparative experiments are carried out to validate the effectiveness of the proposed method. Quantitative experimental results show that, compared with the state-of-art, the proposed method guarantees a much better balance between path length and the consistency with the road network.

</details>


### [82] [Orientation-Free Neural Network-Based Bias Estimation for Low-Cost Stationary Accelerometers](https://arxiv.org/abs/2511.13071)
*Michal Levin,Itzik Klein*

Main category: cs.RO

TL;DR: 提出一种无需传感器定向和旋转的模型无关学习型加速度计偏置校准方法，在静止条件下实现快速实用的校准。


<details>
  <summary>Details</summary>
Motivation: 低成本MEMS加速度计存在偏置误差，传统校准方法需要传感器水平放置或复杂定向相关程序，限制了实际应用。

Method: 基于学习的模型无关校准方法，在静止条件下估计加速度计偏置，无需传感器定向知识和旋转操作。

Result: 在13.39小时六加速度计数据集上验证，该方法比传统技术误差降低52%以上。

Conclusion: 该方法为无定向场景提供了准确校准方案，提高了低成本惯性传感器可靠性，消除了水平校准需求。

Abstract: Low-cost micro-electromechanical accelerometers are widely used in navigation, robotics, and consumer devices for motion sensing and position estimation. However, their performance is often degraded by bias errors. To eliminate deterministic bias terms a calibration procedure is applied under stationary conditions. It requires accelerom- eter leveling or complex orientation-dependent calibration procedures. To overcome those requirements, in this paper we present a model-free learning-based calibration method that estimates accelerometer bias under stationary conditions, without requiring knowledge of the sensor orientation and without the need to rotate the sensors. The proposed approach provides a fast, practical, and scalable solution suitable for rapid field deployment. Experimental validation on a 13.39-hour dataset collected from six accelerometers shows that the proposed method consistently achieves error levels more than 52% lower than traditional techniques. On a broader scale, this work contributes to the advancement of accurate calibration methods in orientation-free scenarios. As a consequence, it improves the reliability of low-cost inertial sensors in diverse scientific and industrial applications and eliminates the need for leveled calibration.

</details>


### [83] [ResAlignNet: A Data-Driven Approach for INS/DVL Alignment](https://arxiv.org/abs/2511.13096)
*Guy Damari,Itzik Klein*

Main category: cs.RO

TL;DR: ResAlignNet是一种基于1D ResNet-18架构的数据驱动方法，将INS和DVL传感器对准问题转化为深度神经网络优化，实现秒级快速收敛，无需外部定位辅助或复杂机动。


<details>
  <summary>Details</summary>
Motivation: 标准模型化对准方法存在收敛时间长、依赖预设运动模式和外部辅助传感器等问题，严重限制了水下自主航行器的操作灵活性。

Method: 使用1D ResNet-18架构，将传感器对准问题转化为深度神经网络优化，支持Sim2Real迁移学习，可在合成数据上训练并在实际传感器测量中部署。

Result: 在Snapir水下自主航行器上的实验验证表明，ResAlignNet仅用25秒数据收集即可实现0.8°以内的对准精度，相比标准速度方法收敛时间减少65%。

Conclusion: 该轨迹无关解决方案消除了运动模式要求，无需冗长的任务前程序即可立即部署航行器，通过鲁棒的传感器无关对准推进了水下导航能力。

Abstract: Autonomous underwater vehicles rely on precise navigation systems that combine the inertial navigation system and the Doppler velocity log for successful missions in challenging environments where satellite navigation is unavailable. The effectiveness of this integration critically depends on accurate alignment between the sensor reference frames. Standard model-based alignment methods between these sensor systems suffer from lengthy convergence times, dependence on prescribed motion patterns, and reliance on external aiding sensors, significantly limiting operational flexibility. To address these limitations, this paper presents ResAlignNet, a data-driven approach using the 1D ResNet-18 architecture that transforms the alignment problem into deep neural network optimization, operating as an in-situ solution that requires only sensors on board without external positioning aids or complex vehicle maneuvers, while achieving rapid convergence in seconds. Additionally, the approach demonstrates the learning capabilities of Sim2Real transfer, enabling training in synthetic data while deploying in operational sensor measurements. Experimental validation using the Snapir autonomous underwater vehicle demonstrates that ResAlignNet achieves alignment accuracy within 0.8° using only 25 seconds of data collection, representing a 65\% reduction in convergence time compared to standard velocity-based methods. The trajectory-independent solution eliminates motion pattern requirements and enables immediate vehicle deployment without lengthy pre-mission procedures, advancing underwater navigation capabilities through robust sensor-agnostic alignment that scales across different operational scenarios and sensor specifications.

</details>


### [84] [Count Every Rotation and Every Rotation Counts: Exploring Drone Dynamics via Propeller Sensing](https://arxiv.org/abs/2511.13100)
*Xuecheng Chen,Jingao Xu,Wenhua Ding,Haoyang Wang,Xinyu Luo,Ruiyang Duan,Jialong Chen,Xueqian Wang,Yunhao Liu,Xinlei Chen*

Main category: cs.RO

TL;DR: 提出基于事件相机的无人机螺旋桨转速感知系统EventPro，通过精确测量螺旋桨转速来提升无人机感知性能，实现3ms的低延迟和0.23%的转速估计误差。


<details>
  <summary>Details</summary>
Motivation: 随着无人机应用激增，从地面进行非接触式无人机感知变得至关重要。专注于螺旋桨转速感知能显著提升无人机感知性能。

Method: 系统包含两个组件：Count Every Rotation通过减轻事件相机对环境噪声的超高敏感性实现精确的实时螺旋桨转速估计；Every Rotation Counts利用这些转速推断无人机内外动态。

Result: 在真实无人机配送场景中，系统实现3ms感知延迟和0.23%转速估计误差，能以96.5%精度推断无人机飞行指令，与其他感知模态结合时提升超过22%的跟踪精度。

Conclusion: 基于事件相机的螺旋桨转速感知是提升无人机感知性能的有效方法，在实时性和准确性方面表现优异。

Abstract: As drone-based applications proliferate, paramount contactless sensing of airborne drones from the ground becomes indispensable. This work demonstrates concentrating on propeller rotational speed will substantially improve drone sensing performance and proposes an event-camera-based solution, \sysname. \sysname features two components: \textit{Count Every Rotation} achieves accurate, real-time propeller speed estimation by mitigating ultra-high sensitivity of event cameras to environmental noise. \textit{Every Rotation Counts} leverages these speeds to infer both internal and external drone dynamics. Extensive evaluations in real-world drone delivery scenarios show that \sysname achieves a sensing latency of 3$ms$ and a rotational speed estimation error of merely 0.23\%. Additionally, \sysname infers drone flight commands with 96.5\% precision and improves drone tracking accuracy by over 22\% when combined with other sensing modalities. \textit{ Demo: {\color{blue}https://eventpro25.github.io/EventPro/.} }

</details>


### [85] [Collision-Free Navigation of Mobile Robots via Quadtree-Based Model Predictive Control](https://arxiv.org/abs/2511.13188)
*Osama Al Sheikh Ali,Sotiris Koutsoftas,Ze Zhang,Knut Akesson,Emmanuel Dean*

Main category: cs.RO

TL;DR: 提出了一个集成导航框架，将环境表示、轨迹生成和模型预测控制统一起来，使用四叉树方法生成结构化无碰撞区域，作为MPC的线性约束，实现高效可靠的导航。


<details>
  <summary>Details</summary>
Motivation: 为自主移动机器人开发一个统一的导航框架，避免直接编码障碍物，提高导航效率和可靠性。

Method: 采用四叉树方法从占据地图生成结构化、轴对齐的无碰撞区域，构建安全走廊和连通图，结合轨迹生成和B样条平滑。

Result: 实验结果显示在复杂环境中相比基线方法具有一致的成功率和优越性能。

Conclusion: 该集成框架能够实现高效可靠的自主导航，无需直接处理障碍物编码。

Abstract: This paper presents an integrated navigation framework for Autonomous Mobile Robots (AMRs) that unifies environment representation, trajectory generation, and Model Predictive Control (MPC). The proposed approach incorporates a quadtree-based method to generate structured, axis-aligned collision-free regions from occupancy maps. These regions serve as both a basis for developing safe corridors and as linear constraints within the MPC formulation, enabling efficient and reliable navigation without requiring direct obstacle encoding. The complete pipeline combines safe-area extraction, connectivity graph construction, trajectory generation, and B-spline smoothing into one coherent system. Experimental results demonstrate consistent success and superior performance compared to baseline approaches across complex environments.

</details>


### [86] [Monolithic Units: Actuation, Sensing, and Simulation for Integrated Soft Robot Design](https://arxiv.org/abs/2511.13120)
*Trevor Exley,Anderson Brazil Nardin,Petr Trunin,Diana Cafiso,Lucia Beccai*

Main category: cs.RO

TL;DR: 本文提出了单体单元(MU)作为软机器人的构建模块，集成了气动驱动、柔性晶格包络和光学波导传感位点。通过参数化设计框架和实验均质化研究，建立了可重复的制造规则，并采用离散优化方法在晶格节点上选择传感路径，在保持机械性能的同时实现嵌入式传感。


<details>
  <summary>Details</summary>
Motivation: 开发一种集成的软机器人构建模块，将驱动、结构和传感功能整合到单个打印体中，解决软机器人中驱动、传感和结构组件通常分离制造的问题，实现可重复和可扩展的软机器人设计。

Method: 1) 参数化设计框架建立驱动器腔室尺寸与晶格单元尺寸的确定性关系；2) 实验均质化获取有效材料属性用于有限元仿真；3) 将传感器布局作为离散优化问题，从晶格节点候选路径中选择最小化机械响应偏差的配置；4) 制造优化模型并实验验证。

Result: 验证了优化模型在保持机械性能的同时实现嵌入式传感的能力，工作流程扩展到缩放单元和双指夹持器，证明了MU概念的通用性。

Conclusion: 该方法通过结合可重复的协同设计规则和仿真指导的传感器集成，推进了单体软机器人设计，为软机器人提供了集成驱动、传感和结构的系统化解决方案。

Abstract: This work introduces the Monolithic Unit (MU), an actuator-lattice-sensor building block for soft robotics. The MU integrates pneumatic actuation, a compliant lattice envelope, and candidate sites for optical waveguide sensing into a single printed body. In order to study reproducibility and scalability, a parametric design framework establishes deterministic rules linking actuator chamber dimensions to lattice unit cell size. Experimental homogenization of lattice specimens provides effective material properties for finite element simulation. Within this simulation environment, sensor placement is treated as a discrete optimization problem, where a finite set of candidate waveguide paths derived from lattice nodes is evaluated by introducing local stiffening, and the configuration minimizing deviation from baseline mechanical response is selected. Optimized models are fabricated and experimentally characterized, validating the preservation of mechanical performance while enabling embedded sensing. The workflow is further extended to scaled units and a two-finger gripper, demonstrating generality of the MU concept. This approach advances monolithic soft robotic design by combining reproducible co-design rules with simulation-informed sensor integration.

</details>


### [87] [PIGEON: VLM-Driven Object Navigation via Points of Interest Selection](https://arxiv.org/abs/2511.13207)
*Cheng Peng,Zhenzhe Zhang,Cheng Chi,Xiaobao Wei,Yanhao Zhang,Heng Wang,Pengwei Wang,Zhongyuan Wang,Jing Liu,Shanghang Zhang*

Main category: cs.RO

TL;DR: PIGEON是一个基于视觉语言模型的对象导航方法，通过维护轻量级语义快照记忆来指导探索，使用PoI选择提高决策频率，并在零样本迁移中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法在未知环境中导航到指定对象时，难以平衡决策频率与智能性，导致决策缺乏前瞻性或动作不连续。

Method: 提出PIGEON框架：维护语义对齐的快照记忆作为探索策略输入；使用PIGEON-VL选择探索过程中形成的兴趣点；采用低级规划器输出动作；生成适用于模拟器的可验证奖励强化学习数据。

Result: 在经典对象导航基准测试中，零样本迁移方法达到最先进性能，RLVR进一步增强了模型的语义引导能力。

Conclusion: PIGEON方法通过PoI引导的探索策略，实现了高频率决策与智能导航的平衡，RLVR技术使模型能够在实时导航中进行深度推理。

Abstract: Navigating to a specified object in an unknown environment is a fundamental yet challenging capability of embodied intelligence. However, current methods struggle to balance decision frequency with intelligence, resulting in decisions lacking foresight or discontinuous actions. In this work, we propose PIGEON: Point of Interest Guided Exploration for Object Navigation with VLM, maintaining a lightweight and semantically aligned snapshot memory during exploration as semantic input for the exploration strategy. We use a large Visual-Language Model (VLM), named PIGEON-VL, to select Points of Interest (PoI) formed during exploration and then employ a lower-level planner for action output, increasing the decision frequency. Additionally, this PoI-based decision-making enables the generation of Reinforcement Learning with Verifiable Reward (RLVR) data suitable for simulators. Experiments on classic object navigation benchmarks demonstrate that our zero-shot transfer method achieves state-of-the-art performance, while RLVR further enhances the model's semantic guidance capabilities, enabling deep reasoning during real-time navigation.

</details>


### [88] [GaRLILEO: Gravity-aligned Radar-Leg-Inertial Enhanced Odometry](https://arxiv.org/abs/2511.13216)
*Chiyun Noh,Sangwoo Jung,Hanjun Kim,Yafei Hu,Laura Herlant,Ayoung Kim*

Main category: cs.RO

TL;DR: GaRLILEO是一个新颖的重力对齐连续时间雷达-腿-惯性里程计框架，通过解耦IMU速度并使用雷达多普勒和腿部运动学信息构建连续时间自速度样条，提高腿式机器人在复杂地形中的垂直姿态估计精度。


<details>
  <summary>Details</summary>
Motivation: 传统基于腿部运动学和惯性传感的里程计方法存在不可抑制的垂直漂移问题，特别是在楼梯、斜坡等复杂地形中。现有方法依赖激光雷达或相机，但在特征稀疏或重复场景中性能下降，且易受IMU加速度双重积分误差影响。

Method: 提出GaRLILEO框架，通过构建基于雷达多普勒和腿部运动学信息的连续时间自速度样条来解耦IMU速度，并引入软S2约束重力因子来可靠捕获准确的重力向量。

Result: 在自收集的真实世界室内外轨迹数据集上评估，GaRLILEO在楼梯和斜坡上的垂直里程计估计方面展示了最先进的精度。

Conclusion: GaRLILEO能够在不依赖激光雷达或相机的情况下提高垂直姿态精度，为腿式机器人里程计和SLAM研究提供了开源数据集和算法。

Abstract: Deployment of legged robots for navigating challenging terrains (e.g., stairs, slopes, and unstructured environments) has gained increasing preference over wheel-based platforms. In such scenarios, accurate odometry estimation is a preliminary requirement for stable locomotion, localization, and mapping. Traditional proprioceptive approaches, which rely on leg kinematics sensor modalities and inertial sensing, suffer from irrepressible vertical drift caused by frequent contact impacts, foot slippage, and vibrations, particularly affected by inaccurate roll and pitch estimation. Existing methods incorporate exteroceptive sensors such as LiDAR or cameras. Further enhancement has been introduced by leveraging gravity vector estimation to add additional observations on roll and pitch, thereby increasing the accuracy of vertical pose estimation. However, these approaches tend to degrade in feature-sparse or repetitive scenes and are prone to errors from double-integrated IMU acceleration. To address these challenges, we propose GaRLILEO, a novel gravity-aligned continuous-time radar-leg-inertial odometry framework. GaRLILEO decouples velocity from the IMU by building a continuous-time ego-velocity spline from SoC radar Doppler and leg kinematics information, enabling seamless sensor fusion which mitigates odometry distortion. In addition, GaRLILEO can reliably capture accurate gravity vectors leveraging a novel soft S2-constrained gravity factor, improving vertical pose accuracy without relying on LiDAR or cameras. Evaluated on a self-collected real-world dataset with diverse indoor-outdoor trajectories, GaRLILEO demonstrates state-of-the-art accuracy, particularly in vertical odometry estimation on stairs and slopes. We open-source both our dataset and algorithm to foster further research in legged robot odometry and SLAM. https://garlileo.github.io/GaRLILEO

</details>


### [89] [EL3DD: Extended Latent 3D Diffusion for Language Conditioned Multitask Manipulation](https://arxiv.org/abs/2511.13312)
*Jonas Bode,Raphael Memmesheimer,Sven Behnke*

Main category: cs.RO

TL;DR: 提出一种融合视觉和文本输入的扩散模型视觉运动策略，通过参考演示学习执行文本指定的机器人操作任务，在CALVIN数据集上验证了性能提升和多任务序列执行能力。


<details>
  <summary>Details</summary>
Motivation: 让机器人在人类环境中执行任务需要强大的自然语言理解和物理任务应用能力，本文旨在利用扩散模型构建能够融合视觉和文本输入的机器人策略。

Method: 在训练时使用参考演示，让模型学习执行文本命令指定的操作任务；改进现有模型的嵌入表示，并采用图像生成扩散模型的技术。

Result: 在CALVIN数据集上验证了方法在各种操作任务上的性能提升，以及在多任务序列执行时更高的长期成功率。

Conclusion: 该方法强化了扩散模型在机器人操作中的实用性，为通用多任务操作做出了贡献。

Abstract: Acting in human environments is a crucial capability for general-purpose robots, necessitating a robust understanding of natural language and its application to physical tasks. This paper seeks to harness the capabilities of diffusion models within a visuomotor policy framework that merges visual and textual inputs to generate precise robotic trajectories. By employing reference demonstrations during training, the model learns to execute manipulation tasks specified through textual commands within the robot's immediate environment. The proposed research aims to extend an existing model by leveraging improved embeddings, and adapting techniques from diffusion models for image generation. We evaluate our methods on the CALVIN dataset, proving enhanced performance on various manipulation tasks and an increased long-horizon success rate when multiple tasks are executed in sequence. Our approach reinforces the usefulness of diffusion models and contributes towards general multitask manipulation.

</details>


### [90] [ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning](https://arxiv.org/abs/2511.13327)
*Juntao Jian,Yi-Lin Wei,Chengjie Mou,Yuhao Lin,Xing Zhu,Yujun Shen,Wei-Shi Zheng,Ruizhen Hu*

Main category: cs.RO

TL;DR: 提出ZeroDexGrasp框架，结合多模态大语言模型和抓取优化，实现零样本任务导向灵巧抓取合成，无需标注数据即可生成符合任务目标和物体功能的人类化抓取姿态。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵标注数据，难以泛化到多样物体和任务指令，需要解决任务特定语义对齐的泛化问题。

Method: 使用基于提示的多阶段语义推理推断初始抓取配置和物体接触信息，然后通过接触引导的抓取优化来精化姿态以确保物理可行性和任务对齐。

Result: 实验结果表明，ZeroDexGrasp能够在多样未见物体类别和复杂任务需求上实现高质量零样本灵巧抓取。

Conclusion: 该框架推进了更通用和智能的机器人抓取技术发展。

Abstract: Task-oriented dexterous grasping holds broad application prospects in robotic manipulation and human-object interaction. However, most existing methods still struggle to generalize across diverse objects and task instructions, as they heavily rely on costly labeled data to ensure task-specific semantic alignment. In this study, we propose \textbf{ZeroDexGrasp}, a zero-shot task-oriented dexterous grasp synthesis framework integrating Multimodal Large Language Models with grasp refinement to generate human-like grasp poses that are well aligned with specific task objectives and object affordances. Specifically, ZeroDexGrasp employs prompt-based multi-stage semantic reasoning to infer initial grasp configurations and object contact information from task and object semantics, then exploits contact-guided grasp optimization to refine these poses for physical feasibility and task alignment. Experimental results demonstrate that ZeroDexGrasp enables high-quality zero-shot dexterous grasping on diverse unseen object categories and complex task requirements, advancing toward more generalizable and intelligent robotic grasping.

</details>


### [91] [Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness](https://arxiv.org/abs/2511.13459)
*Bingkun Huang,Yuhe Gong,Zewen Yang,Tianyu Ren,Luis Figueredo*

Main category: cs.RO

TL;DR: 提出了一种基于任务空间、能量安全的强化学习框架，结合PPO和运动基元来处理接触丰富的机器人操作任务，确保安全交互和轨迹平滑性。


<details>
  <summary>Details</summary>
Motivation: 传统基于MDP的强化学习方法在机器人关节空间中应用有限，缺乏对3D环境的全面感知，且忽视了接触丰富的任务空间操作信息，特别是接触安全和鲁棒性方面的问题。

Method: 结合近端策略优化(PPO)和运动基元生成可靠安全的任务空间轨迹，并融入能量感知的笛卡尔阻抗控制器目标，确保机器人与环境的安全交互。

Result: 实验结果表明，该框架在3D环境中各种表面上的任务处理优于现有方法，实现了高成功率、平滑轨迹和能量安全的交互。

Conclusion: 所提出的任务空间能量安全框架能够有效处理接触丰富的机器人操作任务，在轨迹一致性、任务感知和整体性能方面展现出优势。

Abstract: Reinforcement learning (RL) approaches based on Markov Decision Processes (MDPs) are predominantly applied in the robot joint space, often relying on limited task-specific information and partial awareness of the 3D environment. In contrast, episodic RL has demonstrated advantages over traditional MDP-based methods in terms of trajectory consistency, task awareness, and overall performance in complex robotic tasks. Moreover, traditional step-wise and episodic RL methods often neglect the contact-rich information inherent in task-space manipulation, especially considering the contact-safety and robustness. In this work, contact-rich manipulation tasks are tackled using a task-space, energy-safe framework, where reliable and safe task-space trajectories are generated through the combination of Proximal Policy Optimization (PPO) and movement primitives. Furthermore, an energy-aware Cartesian Impedance Controller objective is incorporated within the proposed framework to ensure safe interactions between the robot and the environment. Our experimental results demonstrate that the proposed framework outperforms existing methods in handling tasks on various types of surfaces in 3D environments, achieving high success rates as well as smooth trajectories and energy-safe interactions.

</details>


### [92] [Towards Affect-Adaptive Human-Robot Interaction: A Protocol for Multimodal Dataset Collection on Social Anxiety](https://arxiv.org/abs/2511.13530)
*Vesna Poprcova,Iulia Lefter,Matthias Wieser,Martijn Warnier,Frances Brazier*

Main category: cs.RO

TL;DR: 本文提出了一个多模态数据集收集协议，用于在人与机器人交互环境中研究社交焦虑，包含音频、视频和生理数据的同步记录。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑是一种常见病症，影响人际互动和社交功能。目前缺乏反映社交焦虑的多模态数据集，限制了相关研究和应用的发展。

Method: 设计了一个多模态数据集收集协议，从至少70名参与者获取同步的音频、视频和生理记录数据，参与者按社交焦虑水平分组，在与Furhat社交机器人进行约10分钟的Wizard-of-Oz角色扮演互动时收集数据。

Result: 将构建一个包含多模态数据和上下文信息的丰富数据集，为社交焦虑的稳健多模态检测提供支持。

Conclusion: 这项工作可以为情感自适应的人机交互研究做出贡献，通过提供社交焦虑的稳健多模态检测支持。

Abstract: Social anxiety is a prevalent condition that affects interpersonal interactions and social functioning. Recent advances in artificial intelligence and social robotics offer new opportunities to examine social anxiety in the human-robot interaction context. Accurate detection of affective states and behaviours associated with social anxiety requires multimodal datasets, where each signal modality provides complementary insights into its manifestations. However, such datasets remain scarce, limiting progress in both research and applications. To address this, this paper presents a protocol for multimodal dataset collection designed to reflect social anxiety in a human-robot interaction context. The dataset will consist of synchronised audio, video, and physiological recordings acquired from at least 70 participants, grouped according to their level of social anxiety, as they engage in approximately 10-minute interactive Wizard-of-Oz role-play scenarios with the Furhat social robot under controlled experimental conditions. In addition to multimodal data, the dataset will be enriched with contextual data providing deeper insight into individual variability in social anxiety responses. This work can contribute to research on affect-adaptive human-robot interaction by providing support for robust multimodal detection of social anxiety.

</details>


### [93] [OpenRoboCare: A Multimodal Multi-Task Expert Demonstration Dataset for Robot Caregiving](https://arxiv.org/abs/2511.13707)
*Xiaoyu Liang,Ziang Liu,Kelvin Lin,Edward Gu,Ruolin Ye,Tam Nguyen,Cynthia Hsu,Zhanxin Wu,Xiaoman Yang,Christy Sum Yu Cheung,Harold Soh,Katherine Dimitropoulou,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: OpenRoboCare是一个用于机器人护理的多模态数据集，包含职业治疗师执行日常生活活动任务的专家演示，涵盖RGB-D视频、姿态跟踪、眼动追踪、任务标注和触觉感知五种模态。


<details>
  <summary>Details</summary>
Motivation: 护理任务涉及复杂的物理人机交互，需要精确的遮挡感知、安全物理接触和长期规划。当前缺乏大规模、多样化且由专家驱动的真实世界护理数据集。

Method: 收集了21名职业治疗师在两个人体模型上执行15项日常生活活动任务的数据，涵盖五种模态：RGB-D视频、姿态跟踪、眼动追踪、任务和动作标注、触觉感知。

Result: 数据集提供了护理人员运动、注意力、施力和任务执行策略的丰富多模态洞察，分析展示了专家护理原则和策略。评估表明该数据集对最先进的机器人感知和人类活动识别方法构成挑战。

Conclusion: OpenRoboCare填补了机器人护理领域的数据空白，为开发安全、自适应的辅助机器人提供了重要资源，突显了其在推动机器人护理技术发展方面的价值。

Abstract: We present OpenRoboCare, a multimodal dataset for robot caregiving, capturing expert occupational therapist demonstrations of Activities of Daily Living (ADLs). Caregiving tasks involve complex physical human-robot interactions, requiring precise perception under occlusions, safe physical contact, and long-horizon planning. While recent advances in robot learning from demonstrations have shown promise, there is a lack of a large-scale, diverse, and expert-driven dataset that captures real-world caregiving routines. To address this gap, we collect data from 21 occupational therapists performing 15 ADL tasks on two manikins. The dataset spans five modalities: RGB-D video, pose tracking, eye-gaze tracking, task and action annotations, and tactile sensing, providing rich multimodal insights into caregiver movement, attention, force application, and task execution strategies. We further analyze expert caregiving principles and strategies, offering insights to improve robot efficiency and task feasibility. Additionally, our evaluations demonstrate that OpenRoboCare presents challenges for state-of-the-art robot perception and human activity recognition methods, both critical for developing safe and adaptive assistive robots, highlighting the value of our contribution. See our website for additional visualizations: https://emprise.cs.cornell.edu/robo-care/.

</details>


### [94] [From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands](https://arxiv.org/abs/2511.13710)
*Jianglong Ye,Lai Wei,Guangqi Jiang,Changwei Jing,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: 提出了一种联合优化多指灵巧手控制和硬件设计的方法，通过轻量级指尖几何修改实现功率抓取和精确操作的统一系统。


<details>
  <summary>Details</summary>
Motivation: 当前多指机器人手在功率抓取方面有效，但在精确操作任务中仍主要使用平行夹爪，这凸显了在单一系统中同时实现稳定功率抓取和精确精细操作的困难。

Method: 引入轻量级指尖几何修改，将其表示为接触平面，并联合优化其参数和相应控制策略。控制策略在功率和精确操作之间动态切换，将精确控制简化为平行拇指-食指运动。

Result: 在未见物体的sim-to-real精确抓取中达到82.5%的零样本成功率，在真实世界面包捏取任务中达到93.3%的成功率。

Conclusion: 该协同设计框架能显著增强多指手的精细操作能力，同时不降低其功率抓取能力。

Abstract: Human grasps can be roughly categorized into two types: power grasps and precision grasps. Precision grasping enables tool use and is believed to have influenced human evolution. Today's multi-fingered robotic hands are effective in power grasps, but for tasks requiring precision, parallel grippers are still more widely adopted. This contrast highlights a key limitation in current robotic hand design: the difficulty of achieving both stable power grasps and precise, fine-grained manipulation within a single, versatile system. In this work, we bridge this gap by jointly optimizing the control and hardware design of a multi-fingered dexterous hand, enabling both power and precision manipulation. Rather than redesigning the entire hand, we introduce a lightweight fingertip geometry modification, represent it as a contact plane, and jointly optimize its parameters along with the corresponding control. Our control strategy dynamically switches between power and precision manipulation and simplifies precision control into parallel thumb-index motions, which proves robust for sim-to-real transfer. On the design side, we leverage large-scale simulation to optimize the fingertip geometry using a differentiable neural-physics surrogate model. We validate our approach through extensive experiments in both sim-to-real and real-to-real settings. Our method achieves an 82.5% zero-shot success rate on unseen objects in sim-to-real precision grasping, and a 93.3% success rate in challenging real-world tasks involving bread pinching. These results demonstrate that our co-design framework can significantly enhance the fine-grained manipulation ability of multi-fingered hands without reducing their ability for power grasps. Our project page is at https://jianglongye.com/power-to-precision

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [95] [Compound Selection Decisions: An Almost SURE Approach](https://arxiv.org/abs/2511.11862)
*Jiafeng Chen,Lihua Lei,Timothy Sudijono,Liyang Sun,Tian Xie*

Main category: econ.EM

TL;DR: 提出了ASSURE方法，用于在高斯序列模型中做出复合选择决策，通过几乎无偏的效用估计来优化预定义决策规则类中的选择策略。


<details>
  <summary>Details</summary>
Motivation: 在观测数据存在噪声的情况下，决策者需要选择子集索引以最大化效用，但直接评估决策规则的期望效用很困难。

Method: 基于Stein无偏风险估计(SURE)思想，开发了ASSURE估计器来估计决策规则的期望效用，允许用户通过优化估计效用来选择福利最大化的规则。

Result: ASSURE产生的决策规则在渐近意义上不劣于预定义类中最优但不可行的决策规则，并在人口普查区经济机会选择、歧视企业识别和A/B测试p值决策等应用中验证了有效性。

Conclusion: ASSURE方法能够通过跨噪声估计借力产生选择决策，为实际应用中的复合选择问题提供了有效的解决方案。

Abstract: This paper proposes methods for producing compound selection decisions in a Gaussian sequence model. Given unknown, fixed parameters $μ_ {1:n}$ and known $σ_{1:n}$ with observations $Y_i \sim \textsf{N}(μ_i, σ_i^2)$, the decision maker would like to select a subset of indices $S$ so as to maximize utility $\frac{1}{n}\sum_{i\in S} (μ_i - K_i)$, for known costs $K_i$. Inspired by Stein's unbiased risk estimate (SURE), we introduce an almost unbiased estimator, called ASSURE, for the expected utility of a proposed decision rule. ASSURE allows a user to choose a welfare-maximizing rule from a pre-specified class by optimizing the estimated welfare, thereby producing selection decisions that borrow strength across noisy estimates. We show that ASSURE produces decision rules that are asymptotically no worse than the optimal but infeasible decision rule in the pre-specified class. We apply ASSURE to the selection of Census tracts for economic opportunity, the identification of discriminating firms, and the analysis of $p$-value decision procedures in A/B testing.

</details>


### [96] [Multiscale Comparison of Nonparametric Trending Coefficients](https://arxiv.org/abs/2511.12600)
*Marina Khismatullina,Bernhard van der Sluis*

Main category: econ.EM

TL;DR: 提出了一种新的多尺度检验框架，用于检测面板数据模型中时变系数的斜率异质性，不仅能判断系数函数是否相同，还能识别哪些单元不同以及差异位置


<details>
  <summary>Details</summary>
Motivation: 需要检测面板数据模型中时变系数的异质性，并确定哪些单元存在差异以及差异的具体位置

Method: 建立多尺度检验框架，证明其渐近有效性，并扩展用于揭示模型中的潜在群组结构

Result: 应用该方法检验美国货币政策冲击对49个外国经济体及自身影响的异质性，发现确实存在异质性，并讨论了两个群组的聚类结果

Conclusion: 提出的多尺度检验框架能有效检测面板数据模型中的斜率异质性，并能识别差异单元和位置，为揭示潜在群组结构提供了有效工具

Abstract: This paper proposes a novel framework to test for slope heterogeneity between time-varying coefficients in panel data models. Our test not only allows us to detect whether the coefficient functions are the same across all units or not, but also determines which of them are different and where these differences are located. We establish the asymptotic validity of our multiscale test. As an extension of the proposed procedure, we show how to use the results to uncover latent group structures in the model. We apply our methods to test for heterogeneity in the effect of U.S. monetary shocks on 49 foreign economies and itself. We find evidence that such heterogeneity indeed exists and we discuss the clustering results for two groups.

</details>


### [97] [Double machine learning for causal inference in a multivariate sample selection model](https://arxiv.org/abs/2511.12640)
*Sofiia Dolgikh,Bodan Potanin*

Main category: econ.EM

TL;DR: 提出了在具有序数选择方程的多变量样本选择模型中估计ATE、ATET和LATE的PI和DML估计器，这些估计器具有双重鲁棒性，能有效避免样本选择偏差。


<details>
  <summary>Details</summary>
Motivation: 在多变量样本选择模型中，如果不处理样本选择问题，因果参数的估计可能存在严重偏差，需要开发能够纠正这种偏差的估计方法。

Method: 使用插件估计器和双重机器学习估计器，基于有效影响函数构建双重鲁棒估计器，并在模拟数据上研究其有限样本性质。

Result: 分析结果表明，提出的估计器能够有效避免多变量样本选择导致的偏差，而忽略样本选择会导致高度有偏的估计结果。

Conclusion: 提出的PI和DML估计器在多变量样本选择模型中能够准确估计因果参数，为解决样本选择偏差问题提供了有效工具。

Abstract: We propose plug-in (PI) and double machine learning (DML) estimators of average treatment effect (ATE), average treatment effect on the treated (ATET) and local average treatment effect (LATE) in the multivariate sample selection model with ordinal selection equations. Our DML estimators are doubly-robust and based on the efficient influence functions. Finite sample properties of the proposed estimators are studied and compared on simulated data. Specifically, the results of the analysis suggest that without addressing multivariate sample selection, the estimates of the causal parameters may be highly biased. However, the proposed estimators allow us to avoid these biases.

</details>


### [98] [Identification-aware Markov chain Monte Carlo](https://arxiv.org/abs/2511.12847)
*Toru Kitagawa,Yizhou Kuang*

Main category: econ.EM

TL;DR: 本文提出了一种新的MCMC方法，用于处理非识别模型中的多模态或平坦区域问题，通过利用观测等价参数集的知识来克服局部模式陷阱并实现更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 非识别性参数不会给贝叶斯推断带来困难，但由此产生的后验分布多模态或平坦区域给现代贝叶斯计算带来了挑战，传统采样方法在处理这些情况时往往收敛缓慢或不收敛。

Method: 开发了一种新颖的马尔可夫链蒙特卡洛方法，利用观测等价参数集的知识，特别针对非识别模型设计。

Result: 该方法克服了被困在局部模式的问题，相比随机游走Metropolis-Hastings和哈密顿蒙特卡洛等现有MCMC技术，实现了更快的收敛速度。随着识别集维度或基数的增加，收敛速度的提升更加显著。

Conclusion: 该方法在结构向量移动平均应用中能够发现目标分布中的非平凡模式，证明了识别在现代贝叶斯分析中的重要作用。

Abstract: Leaving posterior sensitivity concerns aside, non-identifiability of the parameters does not raise a difficulty for Bayesian inference as far as the posterior is proper, but multi-modality or flat regions of the posterior induced by the lack of identification leaves a challenge for modern Bayesian computation. Sampling methods often struggle with slow or non-convergence when dealing with multiple modes or flat regions of the target distributions. This paper develops a novel Markov chain Monte Carlo (MCMC) approach for non-identified models, leveraging the knowledge of observationally equivalent sets of parameters, and highlights an important role that identification plays in modern Bayesian analysis. We show that our proposal overcomes the issues of being trapped in a local mode and achieves a faster rate of convergence than the existing MCMC techniques including random walk Metropolis-Hastings and Hamiltonian Monte Carlo. The gain in the speed of convergence is more significant as the dimension or cardinality of the identified sets increases. Simulation studies show its superior performance compared to other popular computational methods including Hamiltonian Monte Carlo and sequential Monte Carlo. We also demonstrate that our method uncovers non-trivial modes in the target distribution in a structural vector moving-average (SVMA) application.

</details>


### [99] [Why Do the Elderly Save? Using Health Shocks to Uncover Bequests Motives](https://arxiv.org/abs/2511.13275)
*Tetsuya Kaji,Elena Manresa*

Main category: econ.EM

TL;DR: 使用对抗性结构估计框架重新分析老年单身人士的储蓄行为，发现遗赠动机解释了13%-19%的晚年储蓄，且该动机不仅限于富人群体。


<details>
  <summary>Details</summary>
Motivation: 重新审视老年单身人士的储蓄行为，旨在更精确地区分遗赠动机和预防性储蓄动机，特别是通过纳入性别和健康史等特征来改善识别精度。

Method: 采用Kaji等人(2023)的对抗性结构估计框架，结合模拟矩估计和最大似然估计，使用神经网络作为判别器自适应选择数据中最具信息量的特征。应用De Nardi等人(2010)模型于AHEAD数据。

Result: 包含性别和健康史的判别器提高了遗赠动机的识别精度。遗赠动机解释了所有永久收入五分位数中13%-19%的晚年储蓄，而不仅仅是富人群体。对抗性估计器能精确区分遗赠动机和预防性储蓄动机。

Conclusion: 健康相关的生存预期异质性是区分遗赠和预防性储蓄动机的另一个重要识别变异来源。

Abstract: We revisit the saving behavior of elderly singles using an adversarial structural estimation framework by Kaji, Manresa and Pouliot (2023). The method bridges the simulated method of moments (SMM) and maximum-likelihood estimation by embedding a flexible discriminator, implemented as a neural network, that adaptively selects the most informative features of the data. Applying this approach to the model of De Nardi, French, and Jones (2010) with AHEAD data, we show that including gender and health histories in the discriminator improves identification and precision of bequests motives. The resulting estimates reveal that bequest motives explain between $13\%$ and $19\%$ percent of late-life savings across all permanent-income quintiles, not only among the rich. The adversarial estimator precisely disentangles bequest motives from precautionary savings motives. These findings suggest that heterogeneity in health-related survival expectations is another important source of identifying variation to distinguishing bequest and precautionary saving motives.

</details>


### [100] [Decomposing Inequalities using Machine Learning and Overcoming Common Support Issues](https://arxiv.org/abs/2511.13433)
*Emmanuel Flachaire,Bertille Picard*

Main category: econ.EM

TL;DR: 本文重新构建了Kitagawa-Oaxaca-Blinder分解框架，使用双重稳健估计器扩展Neumark的加权参考方法，通过Neyman正交性和双重机器学习避免修剪和外推，提高了灵活性和稳健性。


<details>
  <summary>Details</summary>
Motivation: 解决传统分解方法在共同支持和模型误设方面的局限性，改进分解框架的灵活性和稳健性。

Method: 使用潜在结果重新构建分解框架，结合Neumark加权参考方法和双重稳健估计器，应用Neyman正交性和双重机器学习技术。

Result: 新方法避免了修剪和外推问题，提高了分解的灵活性和稳健性，但发现基于Neumark参考结果的分解对包含无关解释变量特别敏感。

Conclusion: 提出的双重稳健分解方法在实证应用中表现出更好的性能，但需要注意参考结果选择对无关变量的敏感性。

Abstract: The Kitagawa-Oaxaca-Blinder decomposition splits the difference in means between two groups into an explained part, due to observable factors, and an unexplained part. In this paper, we reformulate this framework using potential outcomes, highlighting the critical role of the reference outcome. To address limitations like common support and model misspecification, we extend Neumark's (1988) weighted reference approach with a doubly robust estimator. Using Neyman orthogonality and double machine learning, our method avoids trimming and extrapolation. This improves flexibility and robustness, as illustrated by two empirical applications. Nevertheless, we also highlight that the decomposition based on the Neumark reference outcome is particularly sensitive to the inclusion of irrelevant explanatory variables.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [101] [Dynamic Graph Recommendation via Sparse Augmentation and Singular Adaptation](https://arxiv.org/abs/2511.11969)
*Zhen Tao,Yuehang Cao,Yang Fang,Yunhui Liu,Xiang Zhao,Tieke He*

Main category: cs.SI

TL;DR: GraphSASA是一种用于动态推荐系统的高效微调方法，通过测试时增强和奇异值分解来减少微调参数负担并提高表示质量。


<details>
  <summary>Details</summary>
Motivation: 现有动态图神经网络预训练方法在大规模微调节点表示时需要大量计算资源，且节点度的长尾分布导致稀疏交互节点表示不足，影响微调效率。

Method: GraphSASA采用测试时增强技术，利用层次图聚合中节点表示分布的相似性来增强节点表示，然后应用奇异值分解，冻结原始向量矩阵，仅微调奇异值矩阵。

Result: 在三个大规模数据集上的实验结果表明，该方法达到了最先进的性能。

Conclusion: GraphSASA通过减少微调参数和改善表示质量，有效解决了动态推荐系统中的高效微调问题。

Abstract: Dynamic recommendation, focusing on modeling user preference from historical interactions and providing recommendations on current time, plays a key role in many personalized services. Recent works show that pre-trained dynamic graph neural networks (GNNs) can achieve excellent performance. However, existing methods by fine-tuning node representations at large scales demand significant computational resources. Additionally, the long-tail distribution of degrees leads to insufficient representations for nodes with sparse interactions, posing challenges for efficient fine-tuning. To address these issues, we introduce GraphSASA, a novel method for efficient fine-tuning in dynamic recommendation systems. GraphSASA employs test-time augmentation by leveraging the similarity of node representation distributions during hierarchical graph aggregation, which enhances node representations. Then it applies singular value decomposition, freezing the original vector matrix while focusing fine-tuning on the derived singular value matrices, which reduces the parameter burden of fine-tuning and improves the fine-tuning adaptability. Experimental results demonstrate that our method achieves state-of-the-art performance on three large-scale datasets.

</details>


### [102] [Quantifying and Minimizing Perception Gap in Social Networks](https://arxiv.org/abs/2511.12106)
*Hemant Kumar Gehlot,Mohammad Shirzadi,Junhao Gan,Ahad N. Zehmakan*

Main category: cs.SI

TL;DR: 提出了感知差距指数来量化社交媒体网络中局部-全局意见分歧，证明了网络连通性增强能减少感知扭曲，但社区结构会增加脆弱性。最小化感知差距的链接推荐问题在计算上困难，但提出了有效的启发式方法。


<details>
  <summary>Details</summary>
Motivation: 社交媒体网络结构会通过多数幻觉和回音室效应系统性地扭曲人们的感知，需要量化这种局部与全局意见的差异。

Method: 引入感知差距指数作为图论度量，使用谱图理论分析网络连通性影响，研究随机块模型中的社区结构效应，并提出最小化感知差距的链接推荐启发式算法。

Result: 更高的网络连通性使网络对感知扭曲更具韧性，但明显的社区结构会增加脆弱性。最小化感知差距问题在计算上困难（除非P=NP），但启发式方法在真实网络上能产生接近最优解。

Conclusion: 感知差距指数能有效量化社交媒体中的感知扭曲，网络设计应考虑连通性和社区结构的平衡，提出的启发式方法为实际应用提供了可行解决方案。

Abstract: Social media has transformed global communication, yet its network structure can systematically distort perceptions through effects like the majority illusion and echo chambers. We introduce the perception gap index, a graph-based measure that quantifies local-global opinion divergence, which can be viewed as a generalization of the majority illusion to continuous settings. Using techniques from spectral graph theory, we demonstrate that higher connectivity makes networks more resilient to perception distortion. Our analysis of stochastic block models, however, shows that pronounced community structure increases vulnerability. We also study the problem of minimizing the perception gap via link recommendation with a fixed budget. We prove that this problem does not admit a polynomial-time algorithm for any bounded approximation ratio, unless P = NP. However, we propose a collection of efficient heuristic methods that have been demonstrated to produce near-optimal solutions on real-world network data.

</details>


### [103] [Learning to Control Misinformation: a Closed-loop Approach for Misinformation Mitigation over Social Networks](https://arxiv.org/abs/2511.12393)
*Nicolo' Pagan,Andreas Philippou,Giulia De Pasquale*

Main category: cs.SI

TL;DR: 提出一个控制框架，通过惩罚虚假信息常用的极端负面情绪和新颖性特征，在保持用户参与度的同时减少错误信息传播。


<details>
  <summary>Details</summary>
Motivation: 现代社交网络的推荐系统无意中放大了错误信息，因为它们优先考虑参与度而非内容真实性。

Method: 扩展了闭环Friedkin-Johnsen模型，结合错误信息缓解和用户参与度最大化，采用无模型和基于模型的两种控制策略。

Result: 在不同网络配置下，错误信息传播减少了高达76%，在激进用户网络中，即使错误信息减少，中位参与度仍有所改善。

Conclusion: 该框架为平台运营商在平衡错误信息抑制与参与度目标方面提供了实用指导，表明内容审核可以提升非极端用户的讨论质量。

Abstract: Modern social networks rely on recommender systems that inadvertently amplify misinformation by prioritizing engagement over content veracity. We present a control framework that mitigates misinformation spread while maintaining user engagement by penalizing content characteristics commonly exploited by false information, specifically, extreme negative sentiment and novelty. We extend the closed-loop Friedkin-Johnsen model to incorporate the mitigation of misinformation together with the maximization of user engagement. Both model-free and model-based control strategies demonstrate up to 76% reduction in misinformation propagation across diverse network configurations, validated through simulations using the LIAR2 dataset with sentiment features extracted via large language models. Analysis of engagement-misinformation trade-offs reveals that in networks with radical users, median engagement improves even as misinformation decreases, suggesting content moderation enhances discourse quality for non-extremist users. The framework provides practical guidance for platform operators in balancing misinformation suppression with engagement objectives.

</details>


### [104] [Designed to Spread: Generative Approaches to Enhance Information Diffusion](https://arxiv.org/abs/2511.12516)
*Ziqing Qian,Jiaying Lei,Shengqi Dang,Nan Cao*

Main category: cs.SI

TL;DR: 提出了DOCG任务和一种信息增强算法，用于生成针对特定受众优化的病毒式传播内容，包括无需网络拓扑的内容级传播评估和基于强化学习的可解释编辑策略。


<details>
  <summary>Details</summary>
Motivation: 社交媒体改变了信息获取方式，现有研究主要关注网络结构和引爆点识别，缺乏为特定受众自动生成病毒式传播内容的工具。

Method: 提出影响指标用于内容级传播评估，信息编辑器使用强化学习探索可解释编辑策略，利用生成模型产生语义忠实、受众感知的文本或视觉内容。

Result: 在真实社交媒体数据集和用户研究中，该方法显著提高了传播效果，同时保持了原始内容的核心语义。

Conclusion: 该方法填补了为特定受众生成病毒式传播内容的空白，在保持语义忠实度的同时有效提升了内容传播效果。

Abstract: Social media has fundamentally transformed how people access information and form social connections, with content expression playing a critical role in driving information diffusion. While prior research has focused largely on network structures and tipping point identification, it provides limited tools for automatically generating content tailored for virality within a specific audience. To fill this gap, we propose the novel task of DOCG and introduce an information enhancement algorithm for generating content optimized for diffusion. Our method includes an influence indicator that enables content-level diffusion assessment without requiring access to network topology, and an information editor that employs reinforcement learning to explore interpretable editing strategies. The editor leverages generative models to produce semantically faithful, audience-aware textual or visual content. Experiments on real-world social media datasets and user study demonstrate that our approach significantly improves diffusion effectiveness while preserving the core semantics of the original content.

</details>


### [105] [Rethinking the filter bubble? Developing a research agenda for the protective filter bubble](https://arxiv.org/abs/2511.12873)
*Jacob Erickson*

Main category: cs.SI

TL;DR: 这篇评论文章提出需要重新思考过滤泡现象，指出虽然过滤泡通常被视为负面现象，但对边缘化群体和新闻自由受限国家的人们可能具有保护性益处。


<details>
  <summary>Details</summary>
Motivation: 过滤泡通常被认为具有负面影响，但很少有研究关注其对边缘化群体和新闻自由受限人群的保护性益处，这促使作者重新审视过滤泡现象。

Method: 通过对数字安全空间和保护性过滤泡相关文献的回顾分析。

Result: 研究发现过滤泡可能为边缘化群体和新闻自由受限国家的人们提供保护性功能，建议重新评估过滤泡的价值。

Conclusion: 需要重新思考过滤泡现象，并提出了未来研究的几个方向，以更全面地理解过滤泡的双重性质。

Abstract: Filter bubbles and echo chambers have received global attention from scholars, media organizations, and the general public. Filter bubbles have primarily been regarded as intrinsically negative, and many studies have sought to minimize their influence. The detrimental influence of filter bubbles is well-studied. Filter bubbles may, for example, create information silos, amplify misinformation, and promote hatred and extremism. However, comparatively few studies have considered the other side of the filter bubble; its protective benefits, particularly to marginalized communities and those living in countries with low levels of press freedom. Through a review of the literature on digital safe spaces and protective filter bubbles, this commentary suggests that there may be a need to rethink the filter bubble, and it proposes several areas for future research.

</details>


### [106] [Unifying points of interest taxonomies: mapping OpenStreetMap tags to the Foursquare category system](https://arxiv.org/abs/2511.13369)
*Lilou Soulas,Lorenzo Lucchini,Maurizio Napolitano,Sebastiano Bontorin,Simone Centellegher,Bruno Lepri,Riccardo Gallotti,Eleonora Andreotti*

Main category: cs.SI

TL;DR: 提出了一个开放可用的基准和映射框架，用于对齐OpenStreetMap标签与Foursquare分类法，整合社区驱动的OSM数据丰富性与FS的层次结构，支持可重现和互操作的城市分析。


<details>
  <summary>Details</summary>
Motivation: POI分类法的异构性是整合城市数据集和开发基于位置服务的主要挑战，需要统一OSM的灵活社区驱动标签系统与FS的策划层次结构。

Method: 构建手动策划的基准作为黄金标准，评估预训练文本嵌入模型用于OSM标签与FS类别的语义对齐，以及基于LLM的细化阶段增强鲁棒性和适应性。

Result: 开发了一个开放数据集和映射框架，支持可扩展更新，为社区提供稳健的参考资源和实用工具。

Conclusion: 该方法为分类法统一提供了可扩展和可重现的解决方案，可直接应用于城市分析、移动性研究和智慧城市服务。

Abstract: The heterogeneity of Point of Interest (POI) taxonomies is a persistent challenge for the integration of urban datasets and the development of location-based services. OpenStreetMap (OSM) adopts a flexible, community-driven tagging system, while Foursquare (FS) relies on a curated hierarchical structure. Here we present an openly available benchmark and mapping framework that aligns OSM tags with the FS taxonomy. This resource integrates the richness of community-driven OSM data with the hierarchical structure of FS, enabling reproducible and interoperable urban analytics. The dataset is complemented by an evaluation of embedding and LLM-based alignment strategies and a pipeline that supports scalable updates as OSM evolves. Together, these elements provide both a robust reference resource and a practical tool for the community. Our approach is structured around three components: the construction of a manually curated benchmark as a gold standard, the evaluation of pretrained text embedding models for semantic alignment between OSM tags and FS categories, and an LLM-based refinement stage that enhances robustness and adaptability. The proposed methodology provides a scalable and reproducible solution for taxonomy unification, with direct applications to urban analytics, mobility studies, and smart city services.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [107] [Peace Talk and Conflict Traps](https://arxiv.org/abs/2511.11580)
*Andrei Gyarmathy,Georgy Lukyanov*

Main category: econ.TH

TL;DR: 该论文研究了成本高昂的预演信息在安全困境中的作用，发现这些信息既能减少冲突发生的风险，也可能在暴力开始后加剧僵局。


<details>
  <summary>Details</summary>
Motivation: 研究成本高昂的信息在安全困境中的双重作用：既能阻止不必要的战争，又可能在暴力开始后加剧僵局。

Method: 开发了一个重叠代际的安全困境模型，包含持久群体类型（正常vs坏）、单边私人信号传递以及对上次遭遇的噪声私人记忆。

Result: 在中等信号成本范围内，正常老年代理人会在经历令人担忧的私人历史后混合发送成本高昂的安抚信号；信号通过内生的接收者截止点和坏类型的策略性模仿保持边际说服力。信号传递严格降低了冲突发生的风险；在冲突发生后，持续时间在私人模型中保持不变，但在存在小概率公开性（泄露）时会增加。

Conclusion: 当存在公开性时，博弈通常会陷入和平陷阱或冲突陷阱。讨论了福利和政策：何时更倾向于秘密渠道与公开承诺。

Abstract: Costly pre-play messages can deter unnecessary wars - but the same messages can also entrench stalemates once violence begins. We develop an overlapping-generations model of a security dilemma with persistent group types (normal vs bad), one-sided private signaling by the current old to the current young, and noisy private memory of the last encounter. We characterize a stationary equilibrium in which, for an intermediate band of signal costs, normal old agents mix on sending a costly reassurance only after an alarming private history; the signal is kept marginally persuasive by endogenous receiver cutoffs and strategic mimicking by bad types. Signaling strictly reduces the hazard of conflict onset; conditional on onset, duration is unchanged in the private model but increases once a small probability of publicity (leaks) creates a public record of failed reconciliation. With publicity, play generically absorbs in a peace trap or a conflict trap. We discuss welfare and policy: when to prefer back-channels versus public pledges.

</details>


<div id='cs.GL'></div>

# cs.GL [[Back]](#toc)

### [108] [LLM Architecture, Scaling Laws, and Economics: A Quick Summary](https://arxiv.org/abs/2511.11572)
*William H. Press*

Main category: cs.GL

TL;DR: 本文总结了当前大型语言模型的标准QKV自注意力架构和Transformer结构，提供了计算和内存的扩展规律，并给出了2025年不同规模LLM的参数成本估算，讨论了DeepSeek是否应被视为特例。


<details>
  <summary>Details</summary>
Motivation: 虽然这些内容并非新知识，但作者认为这些信息在其他地方难以以总结形式获得，因此有必要进行系统整理和呈现。

Method: 通过总结标准LLM架构和Transformer结构，分析计算和内存的扩展规律，并基于2025年的情况估算不同规模模型的参数成本。

Result: 提供了LLM架构的标准化总结、计算和内存扩展规律的具体数据，以及2025年不同规模模型参数成本的估算值，并对DeepSeek是否属于特例进行了讨论。

Conclusion: 该文为理解当前LLM架构和成本提供了有价值的总结性信息，填补了相关领域总结性材料的空白。

Abstract: The current standard architecture of Large Language Models (LLMs) with QKV self-attention is briefly summarized, including the architecture of a typical Transformer. Scaling laws for compute (flops) and memory (parameters plus data) are given, along with their present (2025) rough cost estimates for the parameters of present LLMs of various scales, including discussion of whether DeepSeek should be viewed as a special case. Nothing here is new, but this material seems not otherwise readily available in summary form.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [109] [Neural Network-Augmented Iterative Learning Control for Friction Compensation of Motion Control Systems with Varying Disturbances](https://arxiv.org/abs/2511.11850)
*Ali Mashhadireza,Ali Sadighi*

Main category: eess.SY

TL;DR: 提出一种结合迭代学习控制和简单横向神经网络的鲁棒控制策略，用于提升线性洛伦兹力执行器在摩擦和模型不确定性下的轨迹跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 解决线性洛伦兹力执行器在摩擦和模型不确定性下的轨迹跟踪问题，传统方法难以有效处理时变摩擦和参考指令变化带来的挑战。

Method: 使用ILC补偿非线性摩擦效应，同时采用简单横向神经网络估计不同参考指令下的非线性ILC努力，通过动态调整ILC努力来适应时变摩擦。

Result: 实验结果表明该方法能够有效减少参考变化时的误差，加速收敛，并在多个具有不同参考轨迹的任务中实现精确跟踪。

Conclusion: 相比使用复杂神经网络的方法，该方法简化了在线训练和实现，使其适用于实时应用，为执行器控制提供了一种实用有效的解决方案。

Abstract: This paper proposes a robust control strategy that integrates Iterative Learning Control (ILC) with a simple lateral neural network to enhance the trajectory tracking performance of a linear Lorentz force actuator under friction and model uncertainties. The ILC compensates for nonlinear friction effects, while the neural network estimates the nonlinear ILC effort for varying reference commands. By dynamically adjusting the ILC effort, the method adapts to time-varying friction, reduces errors at reference changes, and accelerates convergence. Compared to previous approaches using complex neural networks, this method simplifies online training and implementation, making it practical for real-time applications. Experimental results confirm its effectiveness in achieving precise tracking across multiple tasks with different reference trajectories.

</details>


### [110] [Emulation-based Neuromorphic Control for the Stabilization of LTI Systems](https://arxiv.org/abs/2511.11875)
*Elena Petri,Koen J. A. Scheres,Erik Steur,W. P. M. H.,Heemels*

Main category: eess.SY

TL;DR: 提出了一种系统化方法，使用脉冲神经网络控制器来稳定线性时不变系统，通过两步骤设计确保闭环系统的稳定性。


<details>
  <summary>Details</summary>
Motivation: 神经形态技术相比传统数字技术具有低延迟、低能耗和自适应控制的优势，但目前缺乏系统化的脉冲神经网络控制器设计方法。

Method: 采用两步骤仿真设计：第一步建立神经元参数条件，确保神经元对能精确模拟连续信号；第二步提出积分脉冲输入到状态稳定性概念，证明稳定LTI系统具有该性质。

Result: 建立了闭环系统的可证明实用稳定性，并通过数值案例验证了方法的有效性。

Conclusion: 该方法为脉冲神经网络控制器的系统化设计提供了理论基础，能够确保闭环系统的稳定性。

Abstract: Brain-inspired neuromorphic technologies can offer important advantages over classical digital clock-based technologies in various domains, including systems and control engineering. Indeed, neuromorphic engineering could provide low-latency, low-energy and adaptive control systems in the form of spiking neural networks (SNNs) exploiting spike-based control and communication. However, systematic methods for designing and analyzing neuron-inspired spiking controllers are currently lacking. This paper presents a new systematic approach for stabilizing linear time-invariant (LTI) systems using SNN-based controllers, designed as a network of integrate-and-fire neurons, whose input is the measured output from the plant and generating spiking control signals. The new approach consists of a two-step emulation-based design procedure. In the first step, we establish conditions on the neuron parameters to ensure that the spiking signal generated by a pair of neurons emulates any continuous-time signal input to the neurons with arbitrary accuracy in terms of a special metric for spiky signals. In the second step, we propose a novel stability notion, called integral spiking-input-to-state stability (iSISS) building on this special metric. We prove that an asymptotically stable LTI system has this iSISS property. By combining these steps, a certifiable practical stability property of the closed-loop system can be established. Generalizations are discussed and the effectiveness of the approach is illustrated in a numerical case study.

</details>


### [111] [Sampling-Aware Control Barrier Functions for Safety-Critical and Finite-Time Constrained Control](https://arxiv.org/abs/2511.11897)
*Shuo Liu,Wei Xiao,Calin A. Belta*

Main category: eess.SY

TL;DR: 提出采样感知控制屏障函数（SACBF）框架，解决传统高阶CBF在零阶保持控制下因采样效应导致的安全性和可行性问题，保证连续时间安全性和有限时间到达保持要求。


<details>
  <summary>Details</summary>
Motivation: 现有CBF框架在连续时间下能保证安全，但在采样数据实现时因采样间效应可能变得不安全，且无法显式处理有限时间到达保持要求或多重约束，导致控制合成时出现可行性问题。

Method: 通过估计并整合采样间隔内屏障演化的泰勒上界，提出SACBF框架；进一步引入松弛变量处理多重约束，提出r-SACBF变体。

Result: 仿真研究表明，在传统HOCBF方法失效的场景中，SACBF能实现安全可行的性能。

Conclusion: SACBF为采样控制系统提供了统一的框架，能同时保证安全性和可行性，特别是在处理高相对度约束和多重约束时表现优越。

Abstract: In safety-critical control systems, ensuring both safety and feasibility under sampled-data implementations is crucial for practical deployment. Existing Control Barrier Function (CBF) frameworks, such as High-Order CBFs (HOCBFs), effectively guarantee safety in continuous time but may become unsafe when executed under zero-order-hold (ZOH) controllers due to inter-sampling effects. Moreover, they do not explicitly handle finite-time reach-and-remain requirements or multiple simultaneous constraints, which often lead to conflicts between safety and reach-and-remain objectives, resulting in feasibility issues during control synthesis. This paper introduces Sampling-Aware Control Barrier Functions (SACBFs), a unified framework that accounts for sampling effects and high relative-degree constraints by estimating and incorporating Taylor-based upper bounds on barrier evolution between sampling instants. The proposed method guarantees continuous-time forward invariance of safety and finite-time reach-and-remain sets under ZOH control. To further improve feasibility, a relaxed variant (r-SACBF) introduces slack variables for handling multiple constraints realized through time-varying CBFs. Simulation studies on a unicycle robot demonstrate that SACBFs achieve safe and feasible performance in scenarios where traditional HOCBF methods fail.

</details>


### [112] [On The Detection of Minimum Forecast Horizon For Real-Time Scheduling of Energy Storage Systems in Smart Grid](https://arxiv.org/abs/2511.12029)
*Nicholas Tetteh Ofoe,Weilun Wang,Lei Wu*

Main category: eess.SY

TL;DR: 本文提出了基于轨迹对齐的最小预测时域定义和检测算法，用于确定储能系统实时控制所需的最小预测时域，确保滚动时域控制决策与全局优化完全一致。


<details>
  <summary>Details</summary>
Motivation: 随着储能系统在电网中的集成度提高，需要在不确定和波动的电价下制定有效的实时控制策略。现有方法仅提供充分条件，可能忽略实际控制动作的不一致性。

Method: 引入基于轨迹对齐的最小预测时域定义，提出算法识别最小规划时域，使所有滚动时域控制决策与全时域全局优化匹配。使用丹麦Nord Pool日前市场的真实价格数据和实际ESS模型进行验证。

Result: 研究表明60小时的预测时域可以精确模拟全局控制序列和经济结果。在某些参数配置下，没有预测时域能确保完全收敛，说明预测时域存在性对参数敏感。

Conclusion: 研究结果为储能调度中的最小预测时域检测提供了操作上重要的框架，并为这一重要规划指标的分析描述奠定了基础。

Abstract: The increasing integration of energy storage systems (ESSs) into power grids has necessitated effective real-time control strategies under uncertain and volatile electricity prices. An important problem of model predictive control of ESSs is identifying the minimum forecast horizon needed to exactly simulate the globally optimal control trajectory. Existing methods in the literature provide only sufficient conditions and might ignore real-world inconsistencies in control actions. In this paper, we introduce a trajectory-alignment-based definition of the minimum forecast horizon and propose an algorithm that identifies the minimum planning horizon for which all rolling-horizon control decisions match those of the full-horizon global optimization. Using real price data from the bidding zone DK1 in Denmark of the Nord Pool day-ahead market and a realistic ESS model, we illustrate that $60$ hours of forecast horizon allows us to exactly simulate the global control sequence and economic outcomes. In addition, we illustrate that under other parameter configurations, no forecast horizon ensures full convergence, demonstrating the sensitivity of the existence of a forecast horizon to various parameters. Our findings provide an operationally significant framework for minimum forecast horizon detection in storage scheduling and pave the way for the analytical description of this important planning measure.

</details>


### [113] [Real-Time Physics-Aware Battery Health Monitoring from Partial Charging Profiles via Physics-Informed Neural Networks](https://arxiv.org/abs/2511.12053)
*Xubo Gu,Xun Huan,Yao Ren,Wenqing Zhou,Weiran Jiang,Ziyou Song*

Main category: eess.SY

TL;DR: 开发了一种参数化物理信息神经网络(P-PINNSPM)，用于快速准确地识别电池内部退化参数，在30秒内完成参数识别，比有限体积法快47倍，同时将SOH估计精度提高至少60.61%。


<details>
  <summary>Details</summary>
Motivation: 解决电池健康监测中评估速度与诊断深度之间的固有权衡问题，即快速整体健康估计与精确识别内部退化状态之间的矛盾，高效获取详细内部电池信息以理解各种退化机制。

Method: 基于关键老化相关参数空间开发参数化物理信息神经网络(P-PINNSPM)，应用于单粒子模型，能够准确预测整个参数空间内的内部电池变量。

Result: 模型在约30秒内识别内部参数，比有限体积法快47倍，同时保持高精度；参数识别将电池健康状态(SOH)估计精度提高至少60.61%；支持对未见SOH水平的外推，并在不同充电曲线和操作条件下实现稳健估计。

Conclusion: 物理信息机器学习在推进实时、数据高效且物理感知的电池管理系统方面具有强大潜力。

Abstract: Monitoring battery health is essential for ensuring safe and efficient operation. However, there is an inherent trade-off between assessment speed and diagnostic depth-specifically, between rapid overall health estimation and precise identification of internal degradation states. Capturing detailed internal battery information efficiently remains a major challenge, yet such insights are key to understanding the various degradation mechanisms. To address this, we develop a parameterized physics-informed neural network (P-PINNSPM) over the key aging-related parameter space for a single particle model. The model can accurately predict internal battery variables across the parameter space and identifies internal parameters in about 30 seconds-achieving a 47x speedup over the finite volume method-while maintaining high accuracy. These parameters improve the battery state-of-health (SOH) estimation accuracy by at least 60.61%, compared to models without parameter incorporation. Moreover, they enable extrapolation to unseen SOH levels and support robust estimation across diverse charging profiles and operating conditions. Our results demonstrate the strong potential of physics-informed machine learning to advance real-time, data-efficient, and physics-aware battery management systems.

</details>


### [114] [Tight displacement-based formation control under bounded disturbances. A set-theoretic perspective](https://arxiv.org/abs/2511.12163)
*Vlad-Matei Angheluţă,Bogdan Gheorghe,Daniel Ioan,Ionela Prodan,Florin Stoican*

Main category: eess.SY

TL;DR: 本文提出了一种基于集合论概念的确定性方法，用于在有界扰动下合成位移型编队控制器，通过集合不变性原理分析系统行为并优化控制参数。


<details>
  <summary>Details</summary>
Motivation: 现有文献通常使用随机框架处理测量噪声等不确定性，本文旨在提供一种确定性方法来解决位移型编队控制中的有界扰动问题。

Method: 利用集合不变性原理，将最终有界性理论应用于位移型编队的具体动力学，建立集合论框架来分析和优化控制律参数。

Result: 该方法能够保证预设的性能边界，并在多障碍物环境中保持紧密编队的挑战性应用中验证了控制器的有效性。

Conclusion: 基于集合论的确定性方法为位移型编队控制提供了严格的分析框架，能够在有界扰动下保证系统性能并优化控制参数选择。

Abstract: This paper investigates the synthesis of controllers for displacement-based formation control in the presence of bounded disturbances, specifically focusing on uncertainties originating from measurement noise. While the literature frequently addresses such problems using stochastic frameworks, this work proposes a deterministic methodology grounded in set-theoretic concepts. By leveraging the principles of set invariance, we adapt the theory of ultimate boundedness to the specific dynamics of displacement-based formations. This approach provides a rigorous method for analyzing the system's behavior under persistent disturbances. Furthermore, this set-theoretic framework allows for the optimized selection of the proposed control law parameters to guarantee pre-specified performance bounds. The efficacy of the synthesized controller is demonstrated in the challenging application of maintaining tight formations in a multi-obstacles environment.

</details>


### [115] [AI-Enhanced IoT Systems for Predictive Maintenance and Affordability Optimization in Smart Microgrids: A Digital Twin Approach](https://arxiv.org/abs/2511.12175)
*Koushik Ahmed Kushal,Florimond Gueniat*

Main category: eess.SY

TL;DR: 提出基于数字孪生的AI增强物联网框架，用于智能微电网的预测性维护和成本优化，通过整合实时传感器数据、机器学习故障预测和成本感知分析来提高可靠性和能效。


<details>
  <summary>Details</summary>
Motivation: 解决分布式微电网环境中设备可靠性、维护成本和能源效率的挑战，为下一代智能能源系统提供可扩展的解决方案。

Method: 采用数字孪生建模方法，将物理微电网组件与虚拟数字孪生同步，集成实时传感器数据、基于机器学习的故障预测和成本感知操作分析。

Result: 实验评估显示相比基准方法，提高了预测准确性，减少了运营停机时间，并实现了可衡量的成本节约。

Conclusion: 数字孪生驱动的物联网架构具有作为下一代智能经济能源系统的可扩展解决方案的潜力。

Abstract: This study presents an AI enhanced IoT framework for predictive maintenance and affordability optimization in smart microgrids using a Digital Twin modeling approach. The proposed system integrates real time sensor data, machine learning based fault prediction, and cost aware operational analytics to improve reliability and energy efficiency in distributed microgrid environments. By synchronizing physical microgrid components with a virtual Digital Twin, the framework enables early detection of component degradation, dynamic load management, and optimized maintenance scheduling. Experimental evaluations demonstrate improved predictive accuracy, reduced operational downtime, and measurable cost savings compared to baseline microgrid management methods. The findings highlight the potential of Digital Twin driven IoT architectures as a scalable solution for next generation intelligent and affordable energy systems.

</details>


### [116] [DataOps-driven CI/CD for analytics repositories](https://arxiv.org/abs/2511.12277)
*Dmytro Valiaiev*

Main category: eess.SY

TL;DR: 提出一个基于DataOps的验证框架，通过CI/CD管道自动化检查SQL代码质量，包含12个可测试控制项和5个阶段验证流程。


<details>
  <summary>Details</summary>
Motivation: SQL数据处理缺乏传统软件开发的严谨性，导致孤岛工作、逻辑重复和风险增加，阻碍数据治理和验证。需要标准化框架来实施DataOps方法。

Method: 通过多源文献回顾开发DataOps控制记分卡，包含12个测试控制项，映射到模块化CI/CD管道框架（Lint、Optimize、Parse、Validate、Observe五个阶段）。

Result: 创建了需求可追溯矩阵，确保每个高层控制都有具体管道检查支持，提供结构化机制来增强数据质量、治理和协作。

Conclusion: 该框架为团队提供了透明可控的分析开发扩展能力，解决了SQL开发中的治理和验证挑战。

Abstract: The proliferation of SQL for data processing has often occurred without the rigor of traditional software development, leading to siloed efforts, logic replication, and increased risk. This ad-hoc approach hampers data governance and makes validation nearly impossible. Organizations are adopting DataOps, a methodology combining Agile, Lean, and DevOps principles to address these challenges to treat analytics pipelines as production systems. However, a standardized framework for implementing DataOps is lacking. This perspective proposes a qualitative design for a DataOps-aligned validation framework. It introduces a DataOps Controls Scorecard, derived from a multivocal literature review, which distills key concepts into twelve testable controls. These controls are then mapped to a modular, extensible CI/CD pipeline framework designed to govern a single source of truth (SOT) SQL repository. The framework consists of five stages: Lint, Optimize, Parse, Validate, and Observe, each containing specific, automated checks. A Requirements Traceability Matrix (RTM) demonstrates how each high-level control is enforced by concrete pipeline checks, ensuring qualitative completeness. This approach provides a structured mechanism for enhancing data quality, governance, and collaboration, allowing teams to scale analytics development with transparency and control.

</details>


### [117] [Target Defense against Sequentially Arriving Intruders: Algorithm for Agents with Dubins Dynamics](https://arxiv.org/abs/2511.12329)
*Arman Pourghorban,Dipankar Maity*

Main category: eess.SY

TL;DR: 研究非完整动力学下单个防御者对抗连续入侵者的目标防御问题，分析捕获概率并验证理论结果


<details>
  <summary>Details</summary>
Motivation: 解决非完整动力学系统中连续入侵者的目标防御问题，研究防御者在有限和无限入侵序列下的捕获能力

Method: 将入侵者-防御者对抗分为部分信息和完全信息两个阶段，使用Dubins路径和守卫弧概念分析捕获性，通过蒙特卡洛实验验证理论

Result: 量化了有限和无限入侵序列下的捕获百分比，理论结果通过数值实验得到验证

Conclusion: 该研究为非完整动力学系统中的连续目标防御问题提供了理论框架和量化分析方法

Abstract: We consider a variant of the target defense problem where a single defender is tasked to capture a sequence of incoming intruders. Both the defender and the intruders have non-holonomic dynamics. The intruders' objective is to breach the target perimeter without being captured by the defender, while the defender's goal is to capture as many intruders as possible. After one intruder breaches or is captured, the next appears randomly on a fixed circle surrounding the target. Therefore, the defender's final position in one game becomes its starting position for the next. We divide an intruder-defender engagement into two phases, partial information and full information, depending on the information available to the players. We address the capturability of an intruder by the defender using the notions of Dubins path and guarding arc. We quantify the percentage of capture for both finite and infinite sequences of incoming intruders. Finally, the theoretical results are verified through numerical examples using Monte-Carlo-type random trials of experiments.

</details>


### [118] [DER Day-Ahead Offering: A Neural Network Column-and-Constraint Generation Approach](https://arxiv.org/abs/2511.12384)
*Weiqi Meng,Hongyi Li,Bai Cui*

Main category: eess.SY

TL;DR: 提出了一种用于分布式能源聚合商日前报价的两阶段鲁棒自适应随机优化模型，结合神经网络加速的列与约束生成方法，显著提高了求解效率。


<details>
  <summary>Details</summary>
Motivation: 解决分布式能源聚合商在日前能源市场中面临的报价策略问题，需要在不确定性实现前提交价格-数量对，同时处理日前价格和分布式能源发电的不确定性。

Method: 采用两阶段鲁棒自适应随机优化模型：第一阶段确定价格-数量对，第二阶段在分布式能源不确定性实现后做出运行承诺决策。使用随机规划处理日前价格不确定性，鲁棒优化处理分布式能源发电不确定性，并开发神经网络加速的列与约束生成方法。

Result: 在1028节点合成配电网络上的数值研究表明，所提方法能获得高质量解，比Gurobi快100倍，比经典列与约束生成方法快33倍。

Conclusion: 该方法能有效解决分布式能源聚合商的日前报价问题，在保证解质量的同时大幅提升计算效率。

Abstract: In the day-ahead energy market, the offering strategy of distributed energy resource (DER) aggregators must be submitted before the uncertainty realization in the form of price-quantity pairs. This work addresses the day-ahead offering problem through a two-stage robust adaptive stochastic optimization model, wherein the first-stage price-quantity pairs and second-stage operational commitment decisions are made before and after DER uncertainty is realized, respectively. Uncertainty in day-ahead price is addressed using a stochastic programming, while uncertainty of DER generation is handled through robust optimization. To address the max-min structure of the second-stage problem, a neural network-accelerated column-and-constraint generation method is developed. A dedicated neural network is trained to approximate the value function, while optimality is maintained by the design of the network architecture. Numerical studies indicate that the proposed method yields high-quality solutions and is up to 100 times faster than Gurobi and 33 times faster than classical column-and-constraint generation on the same 1028-node synthetic distribution network.

</details>


### [119] [Online Adaptive Probabilistic Safety Certificate with Language Guidance](https://arxiv.org/abs/2511.12431)
*Zhuoyuan Wang,Xiyu Deng,Hikaru Hoshino,Yorie Nakahira*

Main category: eess.SY

TL;DR: 提出了一种语言引导的自适应概率安全证书框架，保证随机系统在环境不确定性下的长期安全，同时适应不同的人类偏好


<details>
  <summary>Details</summary>
Motivation: 解决在不确定或极端环境中实现长期安全并考虑人类偏好的挑战，现有方法往往在长期保证和实时控制之间权衡，无法适应人类偏好或风险容忍度的变化

Method: 集成自然语言输入和贝叶斯环境估计器到自适应安全证书中，利用概率不变性技术获得具有长期安全保证的近视安全条件

Result: 通过自动驾驶车道保持的数值模拟验证，在不确定和极端道路条件下展示了改进的安全性能权衡、环境适应性和用户偏好个性化

Conclusion: 该框架为在不确定环境中实现长期安全提供了有效解决方案，能够整合语言指导、模型信息和量化不确定性

Abstract: Achieving long-term safety in uncertain or extreme environments while accounting for human preferences remains a fundamental challenge for autonomous systems. Existing methods often trade off long-term guarantees for fast real-time control and cannot adapt to variability in human preferences or risk tolerance. To address these limitations, we propose a language-guided adaptive probabilistic safety certificate (PSC) framework that guarantees long-term safety for stochastic systems under environmental uncertainty while accommodating diverse human preferences. The proposed framework integrates natural-language inputs from users and Bayesian estimators of the environment into adaptive safety certificates that explicitly account for user preferences, system dynamics, and quantified uncertainties. Our key technical innovation leverages probabilistic invariance--a generalization of forward invariance to a probability space--to obtain myopic safety conditions with long-term safety guarantees that integrate language guidance, model information, and quantified uncertainty. We validate the framework through numerical simulations of autonomous lane-keeping with human-in-the-loop guidance under uncertain and extreme road conditions, demonstrating enhanced safety-performance trade-offs, adaptability to changing environments, and personalization to different user preferences.

</details>


### [120] [One Request, Multiple Experts: LLM Orchestrates Domain Specific Models via Adaptive Task Routing](https://arxiv.org/abs/2511.12484)
*Xu Yang,Chenhui Lin,Haotian Liu,Qi Wang,Yue Yang,Wenchuan Wu*

Main category: eess.SY

TL;DR: 提出ADN-Agent架构，利用大语言模型协调多个领域特定模型，解决主动配电网中异构模型集成和协调的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着分布式能源资源的大规模集成和新型市场主体广泛参与，主动配电网运行演变为复杂的多场景、多目标问题。现有领域特定模型虽然能解决具体技术问题，但掌握、集成和协调这些异构模型对运营商来说仍存在很大开销。

Method: 提出ADN-Agent架构，利用通用大语言模型协调多个领域特定模型，实现自适应意图识别、任务分解和模型调用。设计了新颖的通信机制为异构模型提供统一灵活接口，并为语言密集型子任务提出自动化训练流程来微调小语言模型。

Result: 综合对比和消融实验验证了所提方法的有效性，表明ADN-Agent架构优于现有的大语言模型应用范式。

Conclusion: ADN-Agent架构能够有效统一和协调主动配电网中的异构领域特定模型，提升系统整体问题解决能力。

Abstract: With the integration of massive distributed energy resources and the widespread participation of novel market entities, the operation of active distribution networks (ADNs) is progressively evolving into a complex multi-scenario, multi-objective problem. Although expert engineers have developed numerous domain specific models (DSMs) to address distinct technical problems, mastering, integrating, and orchestrating these heterogeneous DSMs still entail considerable overhead for ADN operators. Therefore, an intelligent approach is urgently required to unify these DSMs and enable efficient coordination. To address this challenge, this paper proposes the ADN-Agent architecture, which leverages a general large language model (LLM) to coordinate multiple DSMs, enabling adaptive intent recognition, task decomposition, and DSM invocation. Within the ADN-Agent, we design a novel communication mechanism that provides a unified and flexible interface for diverse heterogeneous DSMs. Finally, for some language-intensive subtasks, we propose an automated training pipeline for fine-tuning small language models, thereby effectively enhancing the overall problem-solving capability of the system. Comprehensive comparisons and ablation experiments validate the efficacy of the proposed method and demonstrate that the ADN-Agent architecture outperforms existing LLM application paradigms.

</details>


### [121] [Density-Driven Multi-Agent Coordination for Efficient Farm Coverage and Management in Smart Agriculture](https://arxiv.org/abs/2511.12492)
*Sungjun Seo,Kooktae Lee*

Main category: eess.SY

TL;DR: 提出D2OC框架，将最优传输理论与多无人机覆盖控制结合，用于大规模农业喷洒，实现基于虫害强度的非均匀资源分配，减少化学品使用。


<details>
  <summary>Details</summary>
Motivation: 现代农场规模扩大需要高效的多智能体覆盖策略，传统方法如人工检查和均匀喷洒导致化学品过度使用和资源浪费，现有无人机方法受限于电池寿命、载荷能力和可扩展性。

Method: 使用最优传输理论结合多无人机覆盖控制，将无人机建模为线性时变系统，基于拉格朗日力学推导D2OC控制律，支持非均匀优先级感知资源分配。

Result: 仿真结果显示，该方法在覆盖效率、化学品减少和操作可持续性方面优于均匀喷洒和谱多尺度覆盖方法。

Conclusion: D2OC框架为智能农业提供了可扩展的解决方案，实现了高效协调、平衡工作负载分配和改善任务持续时间。

Abstract: The growing scale of modern farms has increased the need for efficient and adaptive multi-agent coverage strategies for pest, weed, and disease management. Traditional methods such as manual inspection and blanket pesticide spraying often lead to excessive chemical use, resource waste, and environmental impact. While unmanned aerial vehicles (UAVs) offer a promising platform for precision agriculture through targeted spraying and improved operational efficiency, existing UAV-based approaches remain limited by battery life, payload capacity, and scalability, especially in large fields where single-UAV or uniformly distributed spraying is insufficient. Although multi-UAV coordination has been explored, many current frameworks still assume uniform spraying and do not account for infestation severity, UAV dynamics, non-uniform resource allocation, or energy-efficient coordination.
  To address these limitations, this paper proposes a Density-Driven Optimal Control (D2OC) framework that integrates Optimal Transport (OT) theory with multi-UAV coverage control for large-scale agricultural spraying. The method supports non-uniform, priority-aware resource allocation based on infestation intensity, reducing unnecessary chemical application. UAVs are modeled as a linear time-varying (LTV) system to capture variations in mass and inertia during spraying missions. The D2OC control law, derived using Lagrangian mechanics, enables efficient coordination, balanced workload distribution, and improved mission duration. Simulation results demonstrate that the proposed approach outperforms uniform spraying and Spectral Multiscale Coverage (SMC) in coverage efficiency, chemical reduction, and operational sustainability, providing a scalable solution for smart agriculture.

</details>


### [122] [On hyperexponential stabilization of a chain of integrators in continuous and discrete time subject to unmatched perturbations](https://arxiv.org/abs/2511.12567)
*Moussa Labbadi,Denis Efimov*

Main category: eess.SY

TL;DR: 提出了一种用于具有不匹配扰动的积分器链的递归时变状态反馈控制方法，在连续时间和离散时间下分别实现了超指数收敛和有界性。


<details>
  <summary>Details</summary>
Motivation: 针对具有不匹配扰动的积分器链系统，需要设计能够实现快速收敛且保证系统稳定性的控制策略，特别是在离散时间系统中保持超指数收敛特性。

Method: 采用递归时变状态反馈控制，在连续时间系统中通过饱和增长的控制增益实现ISS特性，在离散时间系统中使用隐式欧拉离散化方法。

Result: 连续时间系统中第一个状态变量实现超指数收敛，第二个状态保持有界，其他状态通过饱和控制增益实现ISS特性；离散时间系统中成功保持了超指数收敛。

Conclusion: 所提出的控制方法在连续和离散时间系统中都能有效处理不匹配扰动，实现期望的收敛特性和稳定性，并通过多个示例验证了理论结果。

Abstract: A recursive time-varying state feedback is presented for a chain of integrators with unmatched perturbations in continuous and discrete time. In continuous time, it is shown that hyperexponential convergence is achieved for the first state variable \(x_1\), while the second state \(x_2\) remains bounded. For the other states, we establish ISS {\cb property} by saturating the growing {\cb control} gain. In discrete time, we use implicit Euler discretization to {\cb preserve} hyperexponential convergence. The main results are demonstrated through several examples of the proposed control laws, illustrating the conditions established for both continuous and discrete-time systems.

</details>


### [123] [On two-degrees-of-freedom agreement protocols](https://arxiv.org/abs/2511.12632)
*Gal Barkai,Leonid Mirkin,Daniel Zelazo*

Main category: eess.SY

TL;DR: 提出了一种分布式二自由度架构，用于驱动自主异构智能体达成一致性，该架构分离了本地反馈和网络滤波，可独立设计网络滤波器以实现规定的噪声衰减，并允许控制器异构性来抑制本地扰动。


<details>
  <summary>Details</summary>
Motivation: 传统扩散耦合方法无法抑制激发不稳定一致性极点的本地扰动，需要一种新架构来同时处理网络噪声和本地扰动。

Method: 采用分布式二自由度架构，将本地反馈与网络滤波分离，独立设计网络滤波器，并允许控制器异构性。

Result: 该框架能够实现规定的噪声衰减，并有效抑制包括激发不稳定一致性极点的本地扰动。

Conclusion: 所提出的分布式二自由度架构为异构智能体的一致性控制提供了一种有效解决方案，克服了传统方法的局限性。

Abstract: We propose a distributed two-degrees-of-freedom (2DOF) architecture for driving autonomous, possibly heterogeneous, agents to agreement. The scheme mirrors classical servo structures, separating local feedback from network filtering. This separation enables independent network-filter design for prescribed noise attenuation and allows controller heterogeneity to reject local disturbances, including disturbances exciting unstable agreement poles -- which is known to be impossible via standard diffusive couplings. The potential of the framework is illustrated via two numerical examples.

</details>


### [124] [Visibility-aware Satellite Selection and Resource Allocation in Multi-Orbit LEO Networks](https://arxiv.org/abs/2511.12678)
*Yingzhuo Sun,Yulan Gao,Ming Xiao,Zhu Han,Octavia A. Dobre*

Main category: eess.SY

TL;DR: 提出了一种动态可见性感知的多轨道卫星选择框架，结合马尔可夫近似和匹配博弈理论，解决多轨道LEO卫星通信中的卫星选择、关联控制和资源调度问题。


<details>
  <summary>Details</summary>
Motivation: 多轨道低地球轨道卫星通信是实现全球覆盖的关键基础设施，但现有方法在联合处理卫星选择、关联控制和资源调度时，未能充分考虑多轨道星座中的动态可见性问题。

Method: 使用马尔可夫近似和匹配博弈理论，将问题建模为组合优化问题，通过交替求解用户关联（使用匹配博弈）和功率分配（使用拉格朗日对偶规划），形成针对该问题的块坐标下降方法。

Result: 仿真结果表明，该算法在所有场景下都能收敛到次优解，与四种最先进基线相比，平均实现了约7.85%的更高总速率。

Conclusion: 所提出的动态可见性感知多轨道卫星选择框架能有效解决多轨道LEO卫星通信中的优化问题，显著提升系统性能。

Abstract: Multi orbit low earth orbit (LEO) satellites communication is envisioned as a key infrastructure to deliver global coverage, enabling future services from space air ground integrated networks.However, the optimized design of LEO which jointly addresses satellite selection, association control, and resource scheduling while accounting for dynamic visibility in multi orbit constellations still remains open. Satellites moving along distinct orbital planes yield phase shifted ground tracks and heterogeneous, time varying coverage patterns that significantly complicate the optimization.To bridge the gap, we propose a dynamic visibility aware multi orbit satellite selection framework which can determine the optimal serving satellites across orbital layers. The framework is built upon Markov approximation and matching game theory. Specifically, we formulate a combinatorial optimization problem that maximizes the sum rate under per satellite power budgets. The problem is NP hard , combining discrete user association (UA) decisions with continuous power allocation, and an inherently non convex sum rate maximization objective. We address it through a problem specific Markov approximation. Moreover, we alternately solve UA or bandwidth allocation via a matching game and power allocation via a Lagrangian dual program, which together form a block coordinate descent method tailored to this problem. Simulation results show that the proposed algorithm converges to a suboptimal solution across all scenarios. Extensive experiments against four state of the art baselines further demonstrate that our algorithm achieves, on average, approximately 7.85% higher sum rate than the best performing baseline.

</details>


### [125] [Density-Driven Optimal Control for Non-Uniform Area Coverage in Decentralized Multi-Agent Systems Using Optimal Transport](https://arxiv.org/abs/2511.12756)
*Sungjun Seo,Kooktae Lee*

Main category: eess.SY

TL;DR: 提出D2OC框架，将最优传输理论与多智能体覆盖控制相结合，解决非均匀区域覆盖问题，考虑任务优先级、智能体动力学、操作时间等约束。


<details>
  <summary>Details</summary>
Motivation: 现有均匀覆盖策略不适用于实际应用，许多非均匀方法缺乏最优性保证或未能纳入关键现实约束（如智能体动力学、有限操作时间、智能体数量和分散执行）。

Method: 整合最优传输理论与多智能体覆盖控制，通过约束优化问题建立最优性，从目标函数的拉格朗日函数解析推导控制输入，并开发分散数据共享机制。

Result: 综合仿真研究表明，D2OC相比现有方法显著提高了非均匀区域覆盖性能，同时保持可扩展性和分散实施能力。

Conclusion: D2OC框架成功解决了非均匀区域覆盖问题，提供最优性保证并纳入现实约束，为多智能体系统提供了有效的覆盖控制解决方案。

Abstract: This paper addresses the fundamental problem of non-uniform area coverage in multi-agent systems, where different regions require varying levels of attention due to mission-dependent priorities. Existing uniform coverage strategies are insufficient for realistic applications, and many non-uniform approaches either lack optimality guarantees or fail to incorporate crucial real-world constraints such as agent dynamics, limited operation time, the number of agents, and decentralized execution.
  To resolve these limitations, we propose a novel framework called Density-Driven Optimal Control (D2OC). The central idea of D2OC is the integration of optimal transport theory with multi-agent coverage control, enabling each agent to continuously adjust its trajectory to match a mission-specific reference density map. The proposed formulation establishes optimality by solving a constrained optimization problem that explicitly incorporates physical and operational constraints. The resulting control input is analytically derived from the Lagrangian of the objective function, yielding closed-form optimal solutions for linear systems and a generalizable structure for nonlinear systems. Furthermore, a decentralized data-sharing mechanism is developed to coordinate agents without reliance on global information.
  Comprehensive simulation studies demonstrate that D2OC achieves significantly improved non-uniform area coverage performance compared to existing methods, while maintaining scalability and decentralized implementability.

</details>


### [126] [On Boundedness of Quadratic Dynamics with Energy-Preserving Nonlinearity](https://arxiv.org/abs/2511.12758)
*Shih-Chi Liao,Maziar S. Hemati,Peter Seiler*

Main category: eess.SY

TL;DR: 本文验证了Schlegel和Noack提出的二次系统有界性必要条件的有效性：在二维系统中成立，但在三维系统中存在反例。


<details>
  <summary>Details</summary>
Motivation: 研究二次系统有界性的充分必要条件，特别是验证Schlegel和Noack提出的必要条件的适用范围。

Method: 使用独立证明验证二维系统的必要条件，并构造三维反例来证明必要条件在高维系统中的失效。

Result: 证明了必要条件在二维系统中成立，但在三维系统中存在反例，表明该条件不是普遍适用的。

Conclusion: 有界性分析存在理论缺口，需要进一步研究以减少保守性，特别是在高维系统中。

Abstract: Boundedness is an important property of many physical systems. This includes incompressible fluid flows, which are often modeled by quadratic dynamics with an energy-preserving nonlinearity. For such systems, Schlegel and Noack proposed a sufficient condition for boundedness utilizing quadratic Lyapunov functions. They also propose a necessary condition for boundedness aiming to provide a more complete characterization of boundedness in this class of models. The sufficient condition is based on Lyapunov theory and is true. Our paper focuses on this necessary condition. We use an independent proof to show that the condition is true for two dimensional systems. However, we provide a three dimensional counterexample to illustrate that the necessary condition fails to hold in higher dimensions. Our results highlight a theoretical gap in boundedness analysis and suggest future directions to address the conservatism.

</details>


### [127] [Discrete-Time Stability Analysis of ReLU Feedback Systems via Integral Quadratic Constraints](https://arxiv.org/abs/2511.12826)
*Sahel Vahedi Noori,Bin Hu,Geir Dullerud,Peter Seiler*

Main category: eess.SY

TL;DR: 本文分析了具有ReLU非线性的离散时间反馈系统的内部稳定性，提出了新的动态IQC方法，相比现有方法能获得更小的保守稳定性裕度。


<details>
  <summary>Details</summary>
Motivation: 该研究受循环神经网络启发，旨在分析具有ReLU非线性的反馈系统的内部稳定性，现有静态二次约束方法存在保守性。

Method: 使用有限脉冲滤波器和结构化矩阵推导标量ReLU的硬积分二次约束，结合耗散不等式得到LMI稳定性条件。

Result: 数值结果表明，提出的硬IQC方法比Zames-Falb乘子和先前的静态QC方法给出更小的保守稳定性裕度，有时效果显著。

Conclusion: 新提出的动态IQC是Zames-Falb IQC的超集，能有效减少稳定性分析的保守性。

Abstract: This paper analyzes internal stability of a discrete-time feedback system with a ReLU nonlinearity. This feedback system is motivated by recurrent neural networks. We first review existing static quadratic constraints (QCs) for slope-restricted nonlinearities. Next, we derive hard integral quadratic constraints (IQCs) for scalar ReLU by using finite impulse filters and structured matrices. These IQCs are combined with a dissipation inequality leading to an LMI condition that certifies internal stability. We show that our new dynamic IQCs for ReLU are a superset of the well-known Zames-Falb IQCs specified for slope-restricted nonlinearities. Numerical results show that the proposed hard IQCs give less conservative stability margins than Zames-Falb multipliers and prior static QC methods, sometimes dramatically so.

</details>


### [128] [Green Emergency Communications in RIS- and MA-Assisted Multi-UAV SAGINs: A Partially Observable Reinforcement Learning Approach](https://arxiv.org/abs/2511.12892)
*Liangshun Wu,Wen Chen,Shunqing Zhang,Yajun Wang,Kunlun Wang*

Main category: eess.SY

TL;DR: 提出了一种时空A2C方法，用于解决灾后空天地一体化网络中无人机在非视距环境下的通信受限部分可观测性问题。该方法通过传输先验决策消息、局部状态、策略指纹和循环信念来增强协作，在延迟视图下实现稳定训练。


<details>
  <summary>Details</summary>
Motivation: 灾后地面基础设施受损，无人机需要在非视距城市环境中快速恢复关键任务终端的连接。现有多智能体强化学习方法在通信受限的部分可观测环境下存在不足，需要新的解决方案。

Method: 提出时空A2C方法，每个无人机传输包含局部状态、紧凑策略指纹和循环信念的先验决策消息，按邻居编码并拼接。使用空间折扣塑造价值目标，强调局部交互，并在一跳每时隙延迟下分析稳定训练。

Result: 实验结果显示该方法优于IA2C、ConseNet、FPrint、DIAL和CommNet，实现了更快的收敛速度、更高的渐近奖励、减少的TD/优势误差，以及更好的通信吞吐量-能量权衡。

Conclusion: 所提出的时空A2C方法有效解决了灾后SAGIN中无人机在通信受限部分可观测环境下的协作问题，显著提升了网络性能。

Abstract: In post-disaster space-air-ground integrated networks (SAGINs), terrestrial infrastructure is often impaired, and unmanned aerial vehicles (UAVs) must rapidly restore connectivity for mission-critical ground terminals in cluttered non-line-of-sight (NLoS) urban environments. To enhance coverage, UAVs employ movable antennas (MAs), while reconfigurable intelligent surfaces (RISs) on surviving high-rises redirect signals. The key challenge is communication-limited partial observability, leaving each UAV with a narrow, fast-changing neighborhood view that destabilizes value estimation. Existing multi-agent reinforcement learning (MARL) approaches are inadequate--non-communication methods rely on unavailable global critics, heuristic sharing is brittle and redundant, and learnable protocols (e.g., CommNet, DIAL) lose per-neighbor structure and aggravate non-stationarity under tight bandwidth. To address partial observability, we propose a spatiotemporal A2C where each UAV transmits prior-decision messages with local state, a compact policy fingerprint, and a recurrent belief, encoded per neighbor and concatenated. A spatial discount shapes value targets to emphasize local interactions, while analysis under one-hop-per-slot latency explains stable training with delayed views. Experimental results show our policy outperforms IA2C, ConseNet, FPrint, DIAL, and CommNet--achieving faster convergence, higher asymptotic reward, reduced Temporal-Difference(TD)/advantage errors, and a better communication throughput-energy trade-off.

</details>


### [129] [Wide-Area Feedback Control for Renewables-Heavy Power Systems: A Comparative Study of Reinforcement Learning and Lyapunov-Based Design](https://arxiv.org/abs/2511.12911)
*Muhammad Nadeem,MirSaleh Bahavarnia,Ahmad F. Taha*

Main category: eess.SY

TL;DR: 本文比较了基于模型和无模型的电力系统反馈控制方法，特别关注可再生能源占比高的电网。通过理论分析和案例研究，探讨了数据驱动控制与模型驱动控制的优缺点。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源普及，电网动态建模日益复杂，而数据采集和实时监测能力增强，这促使从基于模型和Lyapunov的控制器设计转向无模型方法。

Method: 使用强化学习（RL）进行完全无模型控制设计，同时采用基于Lyapunov稳定理论的模型方法作为对比，两种方法都应用于详细的非线性微分代数方程描述的电力系统。

Result: 通过理论发展和详细案例研究，对两种方法在可再生能源重载电网中的表现进行了全面分析。

Conclusion: 论文提供了两种控制方法的优缺点详细分析，旨在探索在电力网格中是否应该使用数据驱动反馈控制替代模型驱动方法。

Abstract: As renewable energy sources become more prevalent, accurately modeling power grid dynamics is becoming increasingly more complex. Concurrently, data acquisition and realtime system state monitoring are becoming more available for control centers. This motivates shifting from \textit{model- and Lyapunov-based} feedback controller designs toward \textit{model-free} ones. Reinforcement learning (RL) has emerged as a key tool for designing model-free controllers. Various studies have been carried out to study voltage/frequency control strategies via RL. However, usually a simplified system model is used neglecting detailed dynamics of solar, wind, and composite loads -- and damping system-wide oscillations and modeling power flows are all usually ignored. To that end, we pose an optimal feedback control problem for a detailed renewables-heavy power system, defined by a set of nonlinear differential algebraic equations (NDAE). The control problem is solved using a completely model-free design via RL as well as using a model-based approach built upon the Lyapunov stability theory with guarantees. The paper in its essence seeks to explore whether data-driven feedback control should be used in power grids over its model-driven counterpart. Theoretical developments and thorough case studies are presented with an eye on this exploration. Finally, a detailed analysis is provided to delineate the strengths and weaknesses of both approaches for renewables-heavy grids.

</details>


### [130] [Cooperative ISAC for LAE: Joint Trajectory Planning, Power allocation, and Dynamic Time Division](https://arxiv.org/abs/2511.13006)
*Fangzhi Li,Zhichu Ren,Cunhua Pan,Hong Ren,Jing Jin,Qixing Wang,Jiangzhou Wang*

Main category: eess.SY

TL;DR: 提出了一种用于多无人机系统的集成感知与通信框架，通过联合优化无人机轨迹、功率分配和时间分割比来最大化通信速率同时满足感知互信息要求。


<details>
  <summary>Details</summary>
Motivation: 为了提升空地网络的性能，需要解决无人机系统中感知与通信之间的权衡问题，特别是在严格功率或感知约束下。

Method: 采用交替优化框架，联合优化无人机轨迹、通信和感知功率分配以及动态时间分割比，解决非凸优化问题。

Result: 仿真结果表明，所提出的联合设计方案显著优于静态或部分优化的基准方案，特别是在严格功率或感知约束下。

Conclusion: 动态轨迹和资源管理对于有效导航感知-通信权衡至关重要，尤其是在严格功率或感知约束下。

Abstract: To enhance the performance of aerial-ground networks, this paper proposes an integrated sensing and communication (ISAC) framework for multi-UAV systems. In our model, ground base stations (BSs) cooperatively serve multiple unmanned aerial vehicles (UAVs), and employ a time-division strategy in which beam scanning for sensing comes before data communication in each time slot. To maximize the sum communication rate while satisfying the total sensing mutual information (MI) requirement, we jointly optimize the UAV trajectories, communication and sensing power allocation, and the dynamic time-division ratio. The resulting non-convex optimization problem is efficiently solved using an alternating optimization (AO) framework. Simulation results demonstrate that our proposed joint design significantly outperforms benchmark schemes with static or partially optimized resources. The findings also reveal the critical importance of dynamic trajectory and resource management for effectively navigating the sensing-communication trade-off, especially under stringent power or sensing constraints.

</details>


### [131] [An Online Multiobjective Policy Gradient for Long-run Average-reward Markov Decision Process](https://arxiv.org/abs/2511.13034)
*Rahul Misra,Manuela L. Bujorianu,Rafał Wisniewski*

Main category: eess.SY

TL;DR: 提出基于强化学习的多目标决策框架，通过动态标量化机制确保时间平均奖励向量收敛到预设目标集


<details>
  <summary>Details</summary>
Motivation: 传统强化学习算法处理标量奖励，无法直接优化向量奖励，需要解决多目标决策问题

Method: 基于Blackwell可接近定理的动态标量化机制，内循环使用带基线的策略梯度方法，外循环更新标量化向量

Result: 建立了长期平均奖励向量收敛到目标集的理论保证，并通过数值示例验证了方法的有效性

Conclusion: 该框架成功将单目标强化学习扩展到多目标场景，为向量奖励优化提供了理论保证和实用算法

Abstract: We propose a reinforcement learning (RL) framework for multi-objective decision-making, where the agent seeks to optimize a vector of rewards rather than a single scalar value. The objective is to ensure that the time-averaged reward vector converges asymptotically to a predefined target set. Since standard RL algorithms operate on scalar rewards, we introduce a dynamic scalarization mechanism guided by Blackwell's Approachability Theorem. This theorem enables adaptive updates of the scalarization vector to guarantee convergence toward the target set. Assuming ergodicity, the Markov chain induced by the learned policies admits a stationary distribution, ensuring all states recur with finite return times. Our algorithm exploits this property by defining an inner loop that applies a policy gradient method (with baseline) between successive visits to a designated recurrent state, enforcing Blackwell's condition at each iteration. An outer loop then updates the scalarization vector after each recurrence. We establish theoretical convergence of the long-run average reward vector to the target set and validate the approach through a numerical example.

</details>


### [132] [Initial Excitation-based Adaptive Observers for Discrete-Time LTI Systems](https://arxiv.org/abs/2511.13117)
*Anchita Dey,Soutrik Bandyopadhyay,Shubhendu Bhasin*

Main category: eess.SY

TL;DR: 提出了一种基于初始激励(IE)的自适应观测器，用于离散时间线性时不变系统的状态和参数同时估计，相比传统需要持续激励的方法更实用。


<details>
  <summary>Details</summary>
Motivation: 实际应用中系统参数和状态难以准确获取，现有自适应观测器主要针对连续时间系统，离散时间系统的研究相对较少，且传统方法需要无限时间激励，不适用于稳定化任务。

Method: 采用两层滤波结构和基于归一化梯度下降的更新律学习未知参数，改进回归器以增强信息提取，在初始激励条件下实现状态和参数估计。

Result: 理论分析保证在初始激励条件下状态和参数估计的有界性和指数收敛性，仿真结果验证了所提设计的有效性。

Conclusion: 所提出的基于初始激励的自适应观测器为离散时间系统提供了一种更实用的状态和参数估计方法，避免了传统方法对无限时间激励的要求。

Abstract: In practical applications, the efficacy of a control algorithm relies critically on the accurate knowledge of the parameters and states of the underlying system. However, obtaining these quantities in practice is often challenging. Adaptive observers address this issue by performing simultaneous state and parameter estimation using only input-output measurements. While many adaptive observer designs exist for continuous-time systems, their discrete-time counterparts remain relatively unexplored. This paper proposes an initial excitation (IE)-based adaptive observer for discrete-time linear time-invariant systems. In contrast to conventional designs that rely on the persistence of excitation condition, which requires continuous excitation and infinite control effort, the proposed method does not require excitation for infinite time, thus making it more practical for stabilization tasks. We employ a two-layer filtering structure and a normalized gradient descent-based update law for learning the unknown parameters. We also propose modifying the regressors to enhance information extraction, leading to faster convergence. Rigorous theoretical analysis guarantees bounded and exponentially converging estimates of both states and parameters under the IE condition, and simulation results validate the efficacy of the proposed design.

</details>


### [133] [Carbon Reduction Potential and Sensitivity Analysis of Rural Integrated Energy System with Carbon Trading and Coordinated Electric-Thermal Demand Response](https://arxiv.org/abs/2511.13119)
*Xuxin Yang,Xue Yuan,Donghan Feng,Siru Chen,Yuanhao Feng*

Main category: eess.SY

TL;DR: 本研究构建了农村综合能源系统(RIES)的宏观和微观低碳优化框架，通过电热需求响应和碳交易实现最大碳减排潜力，并识别了28个高敏感性碳相关参数。


<details>
  <summary>Details</summary>
Motivation: 现有RIES脱碳研究主要关注系统级能源设备的宏观优化运行，而需求侧柔性负荷和外部碳交易机制的协同减排效应，以及微观层面设备参数的碳敏感性尚未充分探索。

Method: 宏观层面开发多能源耦合低碳优化运行框架，整合协调电热需求响应和碳交易；微观层面建立RIES组件碳排放模型，对28个碳相关参数进行敏感性分析。

Result: 基于中国北方农村典型运行数据的案例研究表明，协调电热需求响应和碳交易可实现最大碳减排潜力，识别的高敏感性参数为增强RIES脱碳潜力提供了理论指导。

Conclusion: 该研究通过宏观-微观集成分析，为农村综合能源系统的低碳优化运行和碳减排潜力提升提供了有效方法和理论支撑。

Abstract: Constructing clean and low-carbon rural integrated energy system (RIES) is a fundamental requirement for supporting China's rural modernization and new-type urbanization. Existing research on RIES decarbonization primarily focuses on the optimal low-carbon operation of system-level energy devices at the macro level, while the synergistic carbon-reduction effects of demand-side flexible loads and external carbon trading mechanisms have not been fully explored. Meanwhile, at the micro level, the carbon sensitivity of device parameters and their potential contribution to emission reduction remain insufficiently investigated. To address these gaps, this study integrates macro- and micro-level analyses. At the macro level, a multi-energy-coupled low-carbon optimal operation framework is developed, incorporating coordinated electric-thermal demand response (DR) and carbon trading. At the micro level, a carbon emission model for RIES components is established, and sensitivity analysis is conducted on 28 carbon-related parameters to identify highly sensitive determinants of emission reduction. Case studies based on typical operation data from a rural region in northern China demonstrate that coordinated electric-thermal DR and carbon trading can achieve maximum carbon-reduction potential. Furthermore, the identified high-sensitivity parameters provide essential theoretical guidance for enhancing the decarbonization potential of RIES.

</details>


### [134] [A Comprehensive Review of Advancements in Powering and Charging Systems for Unmanned Aerial Vehicles](https://arxiv.org/abs/2511.13122)
*Harsh Abhinandan,Aditya Dhanraj,Aryan Katoch,R. Raja Singh*

Main category: eess.SY

TL;DR: 本文对无人机动力和充电技术现状进行了比较性总结，分析了从传统电池到燃料电池和混合系统的各种能源，以及从手动电池更换到自动对接站和无线充电的多种充电方案。


<details>
  <summary>Details</summary>
Motivation: 无人机的飞行时间始终受限于机载电源的有限功率预算，这促使研究新的电源和创新充电策略以实现长时间自主飞行。

Method: 通过比较分析不同能源（电池、燃料电池、混合系统）的优缺点，以及各种充电选项（手动更换、自动对接、无线充电），并深入探讨无线电力传输技术、功率电子转换器拓扑、电池管理系统和控制方法。

Result: 提供了无人机动力和充电技术的全面综述，涵盖了能量密度、重量、安全性等关键参数，以及各种充电方案的技术特点。

Conclusion: 总结了在技术、经济和社会方面面临的重要挑战，为研究人员、工程师和政策制定者提供了有价值的指导，以提升无人机操作性能。

Abstract: Unmanned Aerial Vehicles (UAVs) or drones have witnessed a spectacular surge in applications for military, commercial, and civilian purposes. However, their potential for flight is always limited by the finite power budget of their onboard power supplies. The limited flight time problem has led to intensive research into new sources of power and innovative charging strategies to enable protracted, autonomous flight. This paper gives a comparative summary of the current state-of-the-art in UAV power and refuelling technology. The paper begins with an analysis of the variety of energy sources, from classical batteries to fuel cells and hybrid systems, based on their relative advantages and disadvantages in energy density, weight, and safety. Subsequently, the review explores a spectrum of replenishment options, from simple manual battery swapping to sophisticated high-tech automatic docking stations and smart contact-based charging pads. Most of the review is dedicated to the newer technology of wireless power transfer, which involves near-field (inductive, capacitive) and far-field (laser, microwave) technology. The article also delves into the most important power electronic converter topologies, battery management systems, and control approaches that form the core of these charging systems. Finally, it recapitulates the most significant challenges in technical, economic, and social aspects for promising avenues of future research. The comprehensive review is a valuable guide for researchers, engineers, and policymakers striving to enhance UAV operational performance.

</details>


### [135] [Cyber-Resilient Fault Diagnosis Methodology in Inverter-Based Resource-Dominated Microgrids with Single-Point Measurement](https://arxiv.org/abs/2511.13162)
*Yifan Wang,Yiyao Yu,Yang Xia,Yan Xu*

Main category: eess.SY

TL;DR: 提出了一种基于单点测量的分数阶记忆增强攻击诊断方案(FO-MADS)，用于逆变器主导微电网的网络安全故障诊断，在四种攻击场景下达到92.8%-96.6%的诊断准确率。


<details>
  <summary>Details</summary>
Motivation: 现有诊断方法依赖昂贵的多点仪器或严格的建模假设，无法在单点测量约束下有效应对网络攻击对逆变器主导微电网的威胁。

Method: 使用Caputo和Grünwald-Letnikov导数构建双分数阶特征库，放大VPQ信号中的微扰动和慢漂移；采用两阶段分层分类器定位受影响逆变器和故障IGBT开关；通过渐进记忆重放对抗训练增强鲁棒性，利用在线难例挖掘动态重加权损失函数。

Result: 在四逆变器微电网测试平台上，包含1个正常类和24个故障类，在四种攻击场景下的诊断准确率为：偏置攻击96.6%、噪声攻击94.0%、数据替换攻击92.8%、重放攻击95.7%，无攻击条件下保持96.7%。

Conclusion: FO-MADS是一种成本效益高、易于部署的解决方案，显著增强了逆变器主导微电网的网络物理弹性。

Abstract: Cyber-attacks jeopardize the safe operation of inverter-based resource-dominated microgrids (IBR-dominated microgrids). At the same time, existing diagnostic methods either depend on expensive multi-point instrumentation or stringent modeling assumptions that are untenable under single-point measurement constraints. This paper proposes a Fractional-Order Memory-Enhanced Attack-Diagnosis Scheme (FO-MADS) that achieves timely fault localization and cyber-resilient fault diagnosis using only one VPQ (voltage, active power, reactive power) measurement point. FO-MADS first constructs a dual fractional-order feature library by jointly applying Caputo and Grünwald-Letnikov derivatives, thereby amplifying micro-perturbations and slow drifts in the VPQ signal. A two-stage hierarchical classifier then pinpoints the affected inverter and isolates the faulty IGBT switch, effectively alleviating class imbalance. Robustness is further strengthened through Progressive Memory-Replay Adversarial Training (PMR-AT), whose attack-aware loss is dynamically re-weighted via Online Hard Example Mining (OHEM) to prioritize the most challenging samples. Experiments on a four-inverter IBR-dominated microgrid testbed comprising 1 normal and 24 fault classes under four attack scenarios demonstrate diagnostic accuracies of 96.6% (bias), 94.0% (noise), 92.8% (data replacement), and 95.7% (replay), while sustaining 96.7% under attack-free conditions. These results establish FO-MADS as a cost-effective and readily deployable solution that markedly enhances the cyber-physical resilience of IBR-dominated microgrids.

</details>


### [136] [Event-Triggered Regulation of Mixed-Autonomy Traffic Under Varying Traffic Conditions](https://arxiv.org/abs/2511.13206)
*Yihuai Zhang,Huan Yu*

Main category: eess.SY

TL;DR: 本文开发了一种基于事件触发控制的混合交通系统拥堵缓解框架，使用扩展的Aw-Rascle-Zhang模型和斜坡计量控制，通过减少控制更新频率来降低计算负担并提高驾驶舒适性。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术的快速发展，由人类驾驶车辆和自动驾驶车辆组成的混合交通系统的建模和拥堵缓解变得越来越重要。需要设计既能有效稳定交通流又能减少计算和通信负担的控制策略。

Method: 采用基于反步法的事件触发控制策略，结合观测器设计以应对有限传感条件下的实际应用。使用扩展的ARZ模型（4×4双曲偏微分方程组）和斜坡计量作为边界执行机制。

Result: 仿真验证表明，事件触发控制不仅能稳定混合交通流，还能显著减少控制更新次数，提高驾驶舒适性和道路安全性。更高的自动驾驶车辆渗透率导致更长的释放时间和更少的触发事件。

Conclusion: 与连续反步控制器相比，所提出的事件触发控制实现了近等效的稳定性能，但控制更新次数大大减少，减少了驾驶员分心，在交通管理中具有巨大应用潜力。

Abstract: Modeling and congestion mitigation of mixed-autonomy traffic systems consisting of human-driven vehicles (HVs) and autonomous vehicles (AVs) have become increasingly critical with the rapid development of autonomous driving technology. This paper develops an event-triggered control (ETC) framework for mitigating congestion in such systems, which are modeled using an extended Aw-Rascle-Zhang (ARZ) formulation consisting of coupled 4 x 4 hyperbolic partial differential equations (PDEs). Ramp metering is employed as the boundary actuation mechanism. To reduce computational and communication burdens while avoiding excessive ramp signal changes, we design the ETC strategy based on the backstepping method, together with an observer-based ETC formulation for practical implementation under limited sensing. Rigorous Lyapunov analysis ensures exponential convergence and avoidance of Zeno behavior. Extensive simulations validate the proposed approach under diverse traffic scenarios, including varying AV penetration rates, different spacing policies, multiple demand levels, and non-recurrent congestion patterns. Results show that ETC not only stabilizes mixed traffic flows but also significantly reduces control updates, improving driver comfort, and roadway safety. Higher AV penetration rates lead to longer release time and fewer triggering events, indicating the positive impact of AVs in mitigating traffic congestion while reducing computational resource usage. Compared to continuous backstepping controllers, the proposed ETC achieves near-equivalent stabilization performance with far fewer controller updates, resulting in longer signal release time that reduces driver distraction, which demonstrates great potential for ETC applications in traffic management.

</details>


### [137] [Robust Control Design Using a Hybrid-Gain Finite-Time Sliding-Mode Controller](https://arxiv.org/abs/2511.13260)
*Amit Shivam,Kiran Kumari,Fernando A. C. C. Fontes*

Main category: eess.SY

TL;DR: 提出了一种混合增益有限时间滑模控制策略，用于受扰非线性系统，结合有限时间到达律和内部混合功率/指数律，在保证快速收敛的同时限制控制作用。


<details>
  <summary>Details</summary>
Motivation: 解决传统滑模控制在实现有限时间收敛时控制作用过大、不光滑的问题，同时保持对匹配扰动的鲁棒性。

Method: 设计混合增益控制器，包含驱动滑模变量到边界层的外部有限时间到达律和保证层内快速收敛的内部混合功率或指数律。

Result: 控制器实现了有限时间收敛和鲁棒性，同时显著降低了控制作用，在二连杆机械臂轨迹跟踪中验证了有效性。

Conclusion: HG-FTSMC方法在保持有限时间收敛性能的同时，有效限制了控制作用，为机械系统控制提供了实用的解决方案。

Abstract: This paper proposes a hybrid-gain finite-time sliding-mode control (HG-FTSMC) strategy for a class of perturbed nonlinear systems. The controller combines a finite-time reaching law that drives the sliding variable to a predefined boundary layer with an inner mixed-power or exponential law that guarantees rapid convergence within the layer while maintaining smooth and bounded control action. The resulting control design achieves finite-time convergence and robustness to matched disturbances, while explicitly limits the control effort. The control framework is first analyzed on a perturbed first-order integrator model, and then extended to Euler-Lagrange (EL) systems, representing a broad class of robotic and mechanical systems. Comparative simulations demonstrate that the proposed controller achieves settling times comparable to recent finite-time approaches [1], while substantially reducing the control effort. Finally, trajectory-tracking simulations on a two-link manipulator further validate the robustness and practical feasibility of the proposed HG-FTSMC approach.

</details>


### [138] [Beyond Energy Functions and Numerical Integration: A New Methodology to Determine Transient Stability at the Initial State](https://arxiv.org/abs/2511.13289)
*Wenhao Wu,Dan Wu,Bin Wang,Jiabing Hu*

Main category: eess.SY

TL;DR: 提出了一种新的暂态稳定性分析方法，通过轨迹相关稳定性指标函数和时间收缩映射，将TSA转化为极点检测问题，利用高阶导数进行有理函数逼近，实现数学直接且计算高效的预测。


<details>
  <summary>Details</summary>
Motivation: 克服传统数值积分和能量函数方法的局限性，为电力系统暂态稳定性分析提供更直接有效的数学方法。

Method: 构建轨迹相关稳定性指标函数，应用时间收缩映射将TSA转化为极点检测问题，利用初始状态高阶导数推导有理函数逼近。

Result: 在基准系统上的数值验证表明，该方法不仅为电力系统TSA提供了直接数学捷径，还为广泛非线性动力系统的暂态稳定性评估建立了有前景的新方法。

Conclusion: 该方法成功规避了传统方法的限制，建立了基于有理函数逼近的暂态稳定性分析新框架，具有计算高效性和广泛适用性。

Abstract: This paper presents a novel method for transient stability analysis (TSA) that circumvents the limitations of sequential numerical integration and energy functions. The proposed method begins by constructing a trajectory-dependent stability indicator function to distinguish the system's destiny. To overcome the difficulty in analyzing the asymptotic behavior at infinite time, a strategic time contraction mapping is then applied. This allows TSA to be recast as a pole-placement detection problem for the indicator function. By leveraging high-order derivatives at the initial state, a rational function approximation is derived, yielding a mathematically direct and computationally efficient prediction. Numerical validations on benchmark systems demonstrate that the method not only provides a direct mathematical shortcut for TSA in power systems but also establishes a promising new methodology for evaluating the transient stability of a broad class of nonlinear dynamical systems.

</details>


### [139] [Event-triggered Dual Gradient Tracking for Distributed Resource Allocation](https://arxiv.org/abs/2511.13362)
*Xiayan Xu,Xiaomeng Chen,Dawei Shi,Ling Shi*

Main category: eess.SY

TL;DR: 提出了一种基于事件触发的对偶梯度跟踪算法，用于减少不平衡有向网络中分布式资源分配问题的通信开销。


<details>
  <summary>Details</summary>
Motivation: 传统对偶梯度跟踪方法在不平衡有向图上有效，但依赖周期性通信，在资源受限网络中产生显著开销。

Method: 设计事件触发的对偶梯度跟踪算法，仅当局部状态偏差超过预设阈值时进行通信。

Result: 证明了非凸对偶目标的次线性收敛和Polyak-Łojasiewicz条件下的线性收敛，对一般强凸成本函数实现次线性收敛，对Lipschitz光滑函数实现线性收敛。

Conclusion: 数值实验表明，事件触发方法显著减少通信事件，同时保持与周期性方案相当的收敛性能。

Abstract: High communication costs create a major bottleneck for distributed resource allocation over unbalanced directed networks. Conventional dual gradient tracking methods, while effective for problems on unbalanced digraphs, rely on periodic communication that creates significant overhead in resource-constrained networks. This paper introduces a novel event-triggered dual gradient tracking algorithm to mitigate this limitation, wherein agents communicate only when local state deviations surpass a predefined threshold. We establish comprehensive convergence guarantees for this approach. First, we prove sublinear convergence for non-convex dual objectives and linear convergence under the Polyak-Łojasiewicz condition. Building on this, we demonstrate that the proposed algorithm achieves sublinear convergence for general strongly convex cost functions and linear convergence for those that are also Lipschitz-smooth. Numerical experiments confirm that our event-triggered method significantly reduces communication events compared to periodic schemes while preserving comparable convergence performance.

</details>


### [140] [Microwave-acoustic-driven power electronics](https://arxiv.org/abs/2511.13412)
*Liyang Jin,Zichen Xi,Joseph G. Thomas,Jun Ji,Yuanzhi Zhang,Nuo Chen,Yizheng Zhu,Linbo Shao,Liyan Zhu*

Main category: eess.SY

TL;DR: 基于微波频率表面声波器件的机械隔离栅极驱动器，实现2.75 kV电气隔离和超低隔离电容，在宽温范围内工作，为GaN晶体管提供高性能隔离驱动。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以通过统一通道同时传输功率和信号，需要开发既能提供高电气隔离又能实现低EMI的隔离解决方案。

Method: 使用铌酸锂上的微波频率表面声波器件构建机械隔离栅极驱动器，通过机械传播实现电气隔离。

Result: 实现了2.75 kV的电气隔离，隔离电容仅0.032 pF，提供13.4 V开路电压和44.4 mA短路电流，GaN晶体管开启时间为108.8 ns，在降压转换器中验证了工作性能，工作温度范围从0.5 K到544 K。

Conclusion: 微波频率SAW器件提供固有的EMI抗扰性，可在多种半导体平台上实现异质集成，为先进功率电子设备实现紧凑、高性能的隔离功率和信号传输。

Abstract: Electrical isolation is critical to ensure safety and minimize electromagnetic interference (EMI), yet existing methods struggle to simultaneously transmit power and signals through a unified channel. Here we demonstrate a mechanically-isolated gate driver based on microwave-frequency surface acoustic wave (SAW) device on lithium niobate that achieves galvanic isolation of 2.75 kV with ultralow isolation capacitance (0.032 pF) over 1.25 mm mechanical propagation length, delivering 13.4 V open-circuit voltage and 44.4 mA short-circuit current. We demonstrate isolated gate driving for a gallium nitride (GaN) high-electron-mobility transistor, achieving a turn-on time of 108.8 ns comparable to commercial drivers and validate its operation in a buck converter. In addition, our SAW device operates over an ultrawide temperature range from 0.5 K (-272.6 °C) to 544 K (271 °C). The microwave-frequency SAW devices offer inherent EMI immunity and potential for heterogeneous integration on multiple semiconductor platforms, enabling compact, high-performance isolated power and signal transmission in advanced power electronics.

</details>


### [141] [High-resolution hierarchical PV system performance modeling in urban environments](https://arxiv.org/abs/2511.13424)
*Bowen Tian,Roel C. G. M. Loonen,Roland M. E. Valckenborg,Jan L. M. Hensen*

Main category: eess.SY

TL;DR: 提出了一种高分辨率分层建模框架，用于准确预测城市环境中光伏系统的性能，特别是在复杂部分遮挡条件下。该模型从太阳能电池到系统级提供详细洞察，验证显示对分钟级动态电特性的预测精度高（R² > 0.90）。


<details>
  <summary>Details</summary>
Motivation: 城市环境中光伏系统的准确性能建模面临复杂部分遮挡的挑战，传统粗分辨率模型在实际遮挡条件下存在严重缺陷，会高估系统性能。

Method: 开发了高分辨率分层建模框架，从太阳能电池到系统级进行详细建模，通过精确捕捉失配损耗和系统组件的时间变化现象（如旁路二极管激活）来避免传统模型的误差。

Result: 模型验证显示对分钟级动态电特性预测精度高（R² > 0.90）。传统模型在实际遮挡条件下会高估实际串运行功率达163%，月能量产量达54%。模块级功率电子器件（MLPEs）可将严重遮挡串的月能量产量提高20%以上。

Conclusion: 该研究为复杂城市环境中光伏系统的可靠设计、准确功率预测和优化提供了关键工具。

Abstract: Accurate performance modeling of PV systems in urban environments is a significant challenge due to complex partial shading. This study introduces a high-resolution, hierarchical modeling framework that provides detailed insights from the solar cell to the system level. Rigorously validated against field-test data from calibrated equipment, the model demonstrates high accuracy in predicting minute-wised dynamic electrical characteristics (R2 > 0.90). A key finding is the critical shortcoming of conventional, coarser-resolution models under realistic shading; these are shown to overestimate the actual string operating power by up to 163% and the monthly energy yield by up to 54%. The proposed framework avoids these errors by precisely capturing mismatch losses and the time-varying phenomena of system components, such as bypass diode activations. Furthermore, the model accurately quantifies the effectiveness of mitigation technologies, showing that Module-Level Power Electronics (MLPEs) can increase the monthly energy yield of a heavily shaded string by over 20%. This research provides a crucial tool for reliable system design, accurate power forecasting, and the optimization of PV systems in complex urban settings.

</details>


### [142] [Handover-Aware URLLC UAV Trajectory Planning: A Continuous-Time Trajectory Optimization via Graphs of Convex Sets](https://arxiv.org/abs/2511.13429)
*Yuqi Ping,Tingting Zhang,Tianhao Liang*

Main category: eess.SY

TL;DR: 该论文提出了一种基于凸集图(GCS)的优化方法，用于优化无人机在基站间的连续轨迹和关联，以最小化切换次数、路径长度和飞行时间，同时满足超可靠低延迟通信(URLLC)要求。


<details>
  <summary>Details</summary>
Motivation: 长距离无人机飞行会触发频繁的小区间切换，导致延迟和同步开销。需要同时优化轨迹和基站关联，在保证通信可靠性的前提下减少切换次数。

Method: 将URLLC要求转化为空间可行区域，构建包含起点和终点的交集图。使用Bézier曲线参数化轨迹，结合单调Bézier缩放处理时间维度。通过单元流约束确保单一路径，形成混合整数凸规划(MICP)问题，应用凸松弛和舍入获得近似最优解。

Result: 仿真验证该方法能在保持URLLC连接的同时，在减少切换次数和飞行效率之间实现明显权衡。

Conclusion: 提出的GCS优化方法能够生成平滑、动态可行的轨迹，在保证通信可靠性的同时有效减少切换次数并优化飞行效率。

Abstract: In this paper, we study a cellular-connected unmanned aerial vehicle (UAV) which aims to fly between two predetermined locations while maintaining ultra-reliable low-latency communications (URLLC) for command-and-control (C2) links with terrestrial base stations (BSs). Long-range flights often trigger frequent inter-cell handovers, which may introduce delays and synchronization overhead. We jointly optimize the continuous trajectory and BS association to minimize handovers, path length, and flying time, subject to communication reliability and kinematic constraints. To address this problem, we reformulate it as an optimization based on the graph of convex sets (GCS). First, the URLLC requirement is translated into spatially feasible regions in the flight plane for each BS. And an intersection graph is constructed including the start and goal points. Each graph node is associated with a smooth and dynamically feasible trajectory segment. The trajectory is parameterized in space by Bézier curves and in time by a monotonic Bézier scaling, together with convex constraints that ensure continuity and enforce speed bounds. Next, we impose unit-flow constraints to enforce a single path, and by coupling the resulting binary edge-selection variables with the convex constraints, we obtain a mixed-integer convex program (MICP). Applying a convex relaxation and rounding to the mixed-integer convex program produces nearly globally optimal routes, and a final refinement yields smooth, dynamically feasible trajectories. Simulations verify that the method preserves URLLC connectivity while achieving a clear trade-off between fewer handovers and flight efficiency.

</details>


### [143] [The Liquid Buffer: Multi-Year Storage for Defossilization and Energy Security under Climate Uncertainty](https://arxiv.org/abs/2511.13513)
*Leonard Göke,Jan Wohland,Stefano Moret,André Bardow*

Main category: eess.SY

TL;DR: 该论文提出了一种可扩展的随机模型，通过引入多年度液态碳氢化合物存储来管理可再生能源的气候不确定性，在欧洲可降低系统成本4.1%，减少化石燃料进口86%，削减弃电60%。


<details>
  <summary>Details</summary>
Motivation: 应对可再生能源发电和电力需求的气候驱动不确定性对净零能源系统能源安全的挑战。

Method: 开发了一个可扩展的随机模型，隐含考虑了51,840个气候年份，识别多年度液态碳氢化合物存储作为管理气候不确定性和确保能源安全的关键选择。

Result: 在欧洲，多年度存储使系统成本降低4.1%，化石燃料进口减少86%，弃电减少60%。所需的液态碳氢化合物储能容量为525 TWh，氢气存储为116 TWh。能源供应安全性高，未满足能源仅为0.0035‰。

Conclusion: 多年度液态碳氢化合物存储是管理气候不确定性的有效策略，能够显著提高能源安全性和系统经济性。

Abstract: The climate-driven uncertainty of renewable generation and electricity demand challenges energy security in net-zero energy systems. By introducing a scalable stochastic model that implicitly accounts for 51'840 climate years, this paper identifies multi-year storage of liquid hydrocarbons as a key option for managing climate uncertainty and ensuring energy security. In Europe, multi-year storage reduces system costs by 4.1%, fossil imports by 86%, and curtailment by 60%. The benefit of multi-year storage is that a renewable surplus in one year is not curtailed but converted to synthetic oil, with hydrogen as an intermediate product, and stored to balance a future deficit. We find that the required energy capacity for liquid hydrocarbons is 525 TWh, a quarter of the European Union's current oil and gas reserves, complemented by 116 TWh for hydrogen storage. Security of supply remains high and unserved energy only amounts to 0.0035 per thousand, well below the common target of 0.02 per thousand.

</details>


### [144] [On the controller form for linear hyperbolic MIMO systems with dynamic boundary conditions](https://arxiv.org/abs/2511.13546)
*Stefan Ecklebe,Frank Woittennek*

Main category: eess.SY

TL;DR: 本文提出了一种代数方法，用于获得一类在无驱动边界与线性ODE系统双向耦合的线性双曲MIMO系统的控制器形式。通过使用具有实指数的广义多项式来描述系统中的预测和延迟，提出了广义双曲控制器形式及其变体，并给出了计算该形式的基于平坦性的新方案。


<details>
  <summary>Details</summary>
Motivation: 现有的控制器形式方法对于SISO和MIMO ODE系统以及SISO双曲PDE系统已经建立，但对于MIMO双曲系统，直接方法在简单示例中就会失败，因此需要开发新的代数方法来解决这一问题。

Method: 采用代数方法处理系统，使用具有实指数的广义多项式来描述系统中的预测和延迟，提出了广义双曲控制器形式及其不同变体，并开发了基于平坦性的新计算方案。

Result: 提出的算法成功应用于激励示例，能够获得MIMO双曲系统的控制器形式，解决了直接方法失败的问题。

Conclusion: 通过代数方法和广义多项式描述，成功开发了适用于MIMO双曲系统的控制器形式及其计算方案，为这类系统的控制设计提供了有效工具。

Abstract: This contribution develops an algebraic approach to obtain a controller form for a class of linear hyperbolic MIMO systems, bidirectionally coupled with a linear ODE system at the unactuated boundary. After a short summary of established controller forms for SISO and MIMO ODE as well as SISO hyperbolic PDE systems, it is shown that the direct ap- proach to state a controller form fails already for a very simple MIMO example. Next, a generalised hyperbolic controller form with different variants is proposed and a new flatnesss-based scheme to compute said form is presented. Therein, the system is treated in an algebraic setting where generalised polynomials with real exponents are used to describe the predictions and delays in the system. The proposed algorithm is then applied to the motivating example.

</details>


### [145] [Data-driven Acceleration of MPC with Guarantees](https://arxiv.org/abs/2511.13588)
*Agustin Castellano,Shijie Pan,Enrique Mallada*

Main category: eess.SY

TL;DR: 提出一种数据驱动的框架，通过用离线MPC解构建的非参数策略替代在线优化来加速MPC，实现100-1000倍的加速，仅略微牺牲最优性。


<details>
  <summary>Details</summary>
Motivation: MPC虽然强大但计算速度慢，难以满足低延迟应用需求，需要加速方法。

Method: 构建基于离线MPC解的非参数策略，该策略相对于构建的最优成本上界是贪婪的，可作为非参数查找规则实现。

Result: 在充分覆盖条件下，策略具有递归可行性和可证明的有界最优性差距，实验显示比标准MPC快100-1000倍，最优性损失较小。

Conclusion: 该方法在数据量和边界紧密度间建立明确权衡，具有实时控制任务的潜力。

Abstract: Model Predictive Control (MPC) is a powerful framework for optimal control but can be too slow for low-latency applications. We present a data-driven framework to accelerate MPC by replacing online optimization with a nonparametric policy constructed from offline MPC solutions. Our policy is greedy with respect to a constructed upper bound on the optimal cost-to-go, and can be implemented as a nonparametric lookup rule that is orders of magnitude faster than solving MPC online. Our analysis shows that under sufficient coverage condition of the offline data, the policy is recursively feasible and admits provable, bounded optimality gap. These conditions establish an explicit trade-off between the amount of data collected and the tightness of the bounds. Our experiments show that this policy is between 100 and 1000 times faster than standard MPC, with only a modest hit to optimality, showing potential for real-time control tasks.

</details>


### [146] [Physics-Informed Neural Networks for Nonlinear Output Regulation](https://arxiv.org/abs/2511.13595)
*Sebastiano Mengozzi,Giovanni B. Esposito,Michelangelo Bin,Andrea Acquaviva,Andrea Bartolini,Lorenzo Marconi*

Main category: eess.SY

TL;DR: 使用物理信息神经网络(PINN)求解非线性系统输出调节问题的调节器方程，实现零误差流形的高精度重构和实时推理，并在直升机垂直动力学同步任务中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 解决非线性系统全信息输出调节问题，传统方法需要求解包含代数约束的偏微分方程系统(调节器方程)，计算复杂且难以实时应用。

Method: 提出基于PINN的方法，直接近似零调节误差流形π(w)和前馈输入c(w)，通过最小化边界条件和可行性条件下的残差来求解调节器方程，无需预计算轨迹或标记数据。

Result: PINN求解器能够高保真地重构零误差流形，在外部系统参数和初始条件变化时保持调节性能，实现实时推理和泛化能力。

Conclusion: 该方法为非线性输出调节问题提供了一种学习驱动的求解器，具有广泛适用性，特别适用于存在输出调节解的非线性系统。

Abstract: This work addresses the full-information output regulation problem for nonlinear systems, assuming the states of both the plant and the exosystem are known. In this setting, perfect tracking or rejection is achieved by constructing a zero-regulation-error manifold π(w) and a feedforward input c(w) that render such manifold invariant. The pair (π(w), c(w)) is characterized by the regulator equations, i.e., a system of PDEs with an algebraic constraint. We focus on accurately solving the regulator equations introducing a physics-informed neural network (PINN) approach that directly approximates π(w) and c(w) by minimizing the residuals under boundary and feasibility conditions, without requiring precomputed trajectories or labeled data. The learned operator maps exosystem states to steady state plant states and inputs, enables real-time inference and, critically, generalizes across families of the exosystem with varying initial conditions and parameters. The framework is validated on a regulation task that synchronizes a helicopter's vertical dynamics with a harmonically oscillating platform. The resulting PINN-based solver reconstructs the zero-error manifold with high fidelity and sustains regulation performance under exosystem variations, highlighting the potential of learning-enabled solvers for nonlinear output regulation. The proposed approach is broadly applicable to nonlinear systems that admit a solution to the output regulation problem.

</details>


### [147] [Scalable Iterative Algorithm for Solving Optimal Transmission Switching with De-energization](https://arxiv.org/abs/2511.13662)
*Benoît Jeanson,Mathieu Tanneau,Simon Tindemans*

Main category: eess.SY

TL;DR: 提出了一种新的混合整数线性规划公式，用于考虑断电后连接性损失的最优传输切换问题，并开发了高效的启发式算法，比Gurobi求解器快100-1000倍找到高质量可行解。


<details>
  <summary>Details</summary>
Motivation: 受RTE子传输操作启发，考虑传输元件损失后可能导致的连接性损失（局部停电）问题，该问题在文献中很少受到关注但对实际运营很重要。

Method: 提出了新的混合整数线性规划公式，无需额外二元变量即可表示事故后连接性损失，并基于此开发了快速迭代启发式算法。

Result: 计算实验表明，现有优化求解器难以解决OTSD的扩展公式，而所提启发式算法比Gurobi快100-1000倍找到高质量可行解。

Conclusion: 该研究为考虑断电后连接性损失的最优传输切换问题提供了有效的解决方案，显著提升了求解效率。

Abstract: Transmission System Operators routinely use transmission switching as a tool to manage congestion and ensure system security. Motivated by sub-transmission operations at RTE, this paper considers the Optimal Transmission Switching with De-energization (OTSD), which captures potential loss of connectivity (and therefore localized blackout) following loss of transmission elements. While directly relevant to real-life operations, this problem has received very little attention in the literature. The paper proposes a new mixed-integer linear programming formulation for OTSD that represents post-contingency loss of connectivity without requiring additional binary variables. This new formulation provides the foundation for a fast, iterative heuristic algorithm. Computational experiments confirms that state-of-the-art optimization solvers struggle to solve the extensive formulation of OTSD, often failing to find even trivial solutions within reasonable time. In contrast, numerical results demonstrate the efficiency of the proposed heuristic, which finds high-quality feasible solutions 100-1000x faster than using Gurobi.

</details>


### [148] [Novel Stability Criteria for Discrete and Hybrid Systems via Ramanujan Inner Products](https://arxiv.org/abs/2511.13690)
*Shyam Kamal,Sunidhi Pandey,Thach Ngoc Dinh*

Main category: eess.SY

TL;DR: 提出基于拉马努金内积和范数的新框架，用于混合系统和离散时间系统的稳定性分析，替代传统欧几里得度量。


<details>
  <summary>Details</summary>
Motivation: 传统欧几里得度量在系统稳定性分析中存在局限性，需要探索基于数论概念的新框架来提供更强的鲁棒性保证。

Method: 引入拉马努金内积和对应范数，建立利用拉马努金求和独特性质的ε-δ稳定性条件，揭示系统稳定性与系统动力学算术性质的联系。

Result: 理论结果得到严格证明，数值模拟验证了所提方法的有效性，提供了增强的鲁棒性保证。

Conclusion: 拉马努金内积框架为系统稳定性分析提供了新的视角，建立了系统稳定性与数论性质之间的基本联系，是传统欧几里得度量的有效替代方案。

Abstract: This paper introduces a Ramanujan inner product and its corresponding norm, establishing a novel framework for the stability analysis of hybrid and discrete-time systems as an alternative to traditional Euclidean metrics. We establish new $ε$-$δ$ stability conditions that utilize the unique properties of Ramanujan summations and their relationship with number-theoretic concepts. The proposed approach provides enhanced robustness guarantees and reveals fundamental connections between system stability and arithmetic properties of the system dynamics. Theoretical results are rigorously proven, and simulation results on numerical examples are presented to validate the efficacy of the proposed approach.

</details>


### [149] [Resilient Distribution Network Planning against Dynamic Malicious Power Injection Attacks](https://arxiv.org/abs/2511.13698)
*Hampei Sasahara,Tatsuya Yamada,Jun-ichi Imura,Henrik Sandberg*

Main category: eess.SY

TL;DR: 提出了一种基于配电网规划的电网级防御策略，通过将安全要求纳入现有规划方法，确保在终端用户节点遭受动态恶意功率注入攻击时，电压偏差保持在可容忍范围内。


<details>
  <summary>Details</summary>
Motivation: 由于集成了多种网络组件，支持可再生能源双向功率交换的主动配电网容易受到网络攻击。需要开发防御策略来增强攻击弹性。

Method: 将原始无限维双层优化问题转化为可处理的混合整数线性规划形式，利用线性动态系统理论和图论，发现攻击严重性仅取决于从变电站到目标节点的累积电抗。

Result: 在54节点配电网基准测试中，所提方法显著提高了29.3%的弹性，而经济成本仅增加2.1%。

Conclusion: 该方法通过将复杂的安全约束纳入配电网规划，有效提高了系统对网络攻击的弹性，且成本增加有限。

Abstract: Active distribution networks facilitating bidirectional power exchange with renewable energy resources are susceptible to cyberattacks due to integration of a diverse array of cyber components. This study introduces a grid-level defense strategy aimed at enhancing attack resiliency based on distribution network planning. Our proposed framework imposes a security requirement into existing planning methodologies, ensuring that voltage deviation from its rated value remains within a tolerable range against dynamically and maliciously injected power at end-user nodes. Unfortunately, the formulated problem in its original form is intractable because it is an infinite-dimensional bi-level optimization problem over a function space. To address this complexity, we develop an equivalent transformation into a tractable form as mixed-integer linear program leveraging linear dynamical system theory and graph theory. Notably, our investigation reveals that the severity of potential attacks hinges solely on the cumulative reactances over the path from the substation to the targeted node, thereby reducing the problem to a finite-dimensional problem. Further, the bi-level optimization problem is reduced to a single-level optimization problem by using a technique utilized in solving the shortest path problem. Through extensive numerical simulations conducted on a 54-node distribution network benchmark, our proposed methodology exhibits a noteworthy 29.3% enhancement in the resiliency, with a mere 2.1% uptick in the economic cost.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [150] [LLM-Generated Negative News Headlines Dataset: Creation and Benchmarking Against Real Journalism](https://arxiv.org/abs/2511.11591)
*Olusola Babalola,Bolanle Ojokoh,Olutayo Boyinbode*

Main category: cs.AI

TL;DR: 本研究探讨了使用大型语言模型生成的合成新闻标题作为真实世界数据替代方案的可行性，特别是在负面情绪文本的情感分析任务中。


<details>
  <summary>Details</summary>
Motivation: 克服自然语言处理任务中数据获取的挑战和真实世界数据相关的隐私问题，为情感分析提供替代数据源。

Method: 使用定制提示创建专门的负面新闻标题语料库，通过专家评审验证，并在嵌入空间中分析合成标题与真实负面新闻在内容、语气、长度和风格上的一致性。

Result: 合成标题与真实标题高度匹配，仅在词性标注测试的专有名词得分上存在明显差异。

Conclusion: LLM生成的合成数据集在负面情绪文本分析中具有替代真实数据的潜力，为NLP任务提供了可行的数据解决方案。

Abstract: This research examines the potential of datasets generated by Large Language Models (LLMs) to support Natural Language Processing (NLP) tasks, aiming to overcome challenges related to data acquisition and privacy concerns associated with real-world data. Focusing on negative valence text, a critical component of sentiment analysis, we explore the use of LLM-generated synthetic news headlines as an alternative to real-world data. A specialized corpus of negative news headlines was created using tailored prompts to capture diverse negative sentiments across various societal domains. The synthetic headlines were validated by expert review and further analyzed in embedding space to assess their alignment with real-world negative news in terms of content, tone, length, and style. Key metrics such as correlation with real headlines, perplexity, coherence, and realism were evaluated. The synthetic dataset was benchmarked against two sets of real news headlines using evaluations including the Comparative Perplexity Test, Comparative Readability Test, Comparative POS Profiling, BERTScore, and Comparative Semantic Similarity. Results show the generated headlines match real headlines with the only marked divergence being in the proper noun score of the POS profile test.

</details>


### [151] [CLINB: A Climate Intelligence Benchmark for Foundational Models](https://arxiv.org/abs/2511.11597)
*Michelle Chen Huebscher,Katharine Mach,Aleksandar Stanić,Markus Leippold,Ben Gaiarin,Zeke Hausfather,Elisa Rawat,Erich Fischer,Massimiliano Ciaramita,Joeri Rogelj,Christian Buck,Lierni Sestorain Saralegui,Reto Knutti*

Main category: cs.AI

TL;DR: CLINB基准测试评估大语言模型在气候变化领域的专业知识和证据支持能力，发现前沿模型具有博士级知识合成能力但存在严重的证据幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型处理复杂专业知识的能力，特别是在气候变化这一关键领域，需要建立可靠的多模态基准测试。

Method: 引入CLINB基准，基于真实用户问题和气候科学家制定的评估标准，通过模型驱动的方法评估多个前沿模型在开放式、多模态问答任务中的表现。

Result: 前沿模型展现出博士级的知识合成和表达能力，甚至优于专家辅助的混合答案，但在证据基础方面存在严重问题，参考文献和图像存在大量幻觉。

Conclusion: 弥合知识合成与可验证归因之间的差距对于AI在科学工作流中的部署至关重要，需要像CLINB这样可靠的基准来构建可信赖的AI系统。

Abstract: Evaluating how Large Language Models (LLMs) handle complex, specialized knowledge remains a critical challenge. We address this through the lens of climate change by introducing CLINB, a benchmark that assesses models on open-ended, grounded, multimodal question answering tasks with clear requirements for knowledge quality and evidential support. CLINB relies on a dataset of real users' questions and evaluation rubrics curated by leading climate scientists. We implement and validate a model-based evaluation process and evaluate several frontier models. Our findings reveal a critical dichotomy. Frontier models demonstrate remarkable knowledge synthesis capabilities, often exhibiting PhD-level understanding and presentation quality. They outperform "hybrid" answers curated by domain experts assisted by weaker models. However, this performance is countered by failures in grounding. The quality of evidence varies, with substantial hallucination rates for references and images. We argue that bridging this gap between knowledge synthesis and verifiable attribution is essential for the deployment of AI in scientific workflows and that reliable, interpretable benchmarks like CLINB are needed to progress towards building trustworthy AI systems.

</details>


### [152] [SynBullying: A Multi LLM Synthetic Conversational Dataset for Cyberbullying Detectio](https://arxiv.org/abs/2511.11599)
*Arefeh Kazemi,Hamza Qadeer,Joachim Wagner,Hossein Hosseini,Sri Balaaji Natarajan Kalaivendan,Brian Davis*

Main category: cs.AI

TL;DR: SynBullying是一个用于网络霸凌研究和检测的合成多LLM对话数据集，通过大语言模型模拟真实霸凌互动，提供可扩展且伦理安全的替代方案。


<details>
  <summary>Details</summary>
Motivation: 解决传统网络霸凌数据收集的伦理问题和规模限制，提供更安全、可扩展的数据集替代方案。

Method: 利用大语言模型生成模拟真实霸凌互动的多轮对话，包含对话结构、上下文感知标注和细粒度标签。

Result: 数据集在对话结构、词汇模式、情感/毒性、角色动态、伤害强度和霸凌类型分布等五个维度上进行了评估，并验证了其作为独立训练数据和增强源的实用性。

Conclusion: SynBullying为网络霸凌研究提供了一个有效、可扩展且伦理安全的合成数据集，在霸凌检测任务中表现出良好性能。

Abstract: We introduce SynBullying, a synthetic multi-LLM conversational dataset for studying and detecting cyberbullying (CB). SynBullying provides a scalable and ethically safe alternative to human data collection by leveraging large language models (LLMs) to simulate realistic bullying interactions. The dataset offers (i) conversational structure, capturing multi-turn exchanges rather than isolated posts; (ii) context-aware annotations, where harmfulness is assessed within the conversational flow considering context, intent, and discourse dynamics; and (iii) fine-grained labeling, covering various CB categories for detailed linguistic and behavioral analysis. We evaluate SynBullying across five dimensions, including conversational structure, lexical patterns, sentiment/toxicity, role dynamics, harm intensity, and CB-type distribution. We further examine its utility by testing its performance as standalone training data and as an augmentation source for CB classification.

</details>


### [153] [CausalGuard: A Smart System for Detecting and Preventing False Information in Large Language Models](https://arxiv.org/abs/2511.11600)
*Piyushkumar Patel*

Main category: cs.AI

TL;DR: CausalGuard是一种结合因果推理和符号逻辑的新方法，能在大型语言模型产生幻觉时实时捕获和预防，相比现有方法能更早干预生成过程。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在'幻觉'问题，会自信地陈述听起来合理但实际错误的信息，这成为在准确性要求高的场景中使用这些模型的主要障碍。现有解决方案要么需要重新训练整个模型，要么增加显著计算成本，或者未能解决幻觉的根本原因。

Method: CausalGuard通过两条互补路径工作：一条追踪模型所知内容与生成内容之间的因果关系，另一条使用自动推理检查逻辑一致性。系统理解导致虚假陈述的因果链，并在生成过程中早期干预。

Result: 在12个不同基准测试中，CausalGuard正确识别幻觉的概率为89.3%，仅遗漏8.3%的实际幻觉。更重要的是，它减少了近80%的错误声明，同时保持回答的自然性和帮助性。在需要多步逻辑的复杂推理任务上表现尤其出色。

Conclusion: CausalGuard通过展示其推理过程，在医疗诊断或金融分析等敏感领域特别有效，因为这些领域理解决策原因与决策本身同等重要。

Abstract: While large language models have transformed how we interact with AI systems, they have a critical weakness: they confidently state false information that sounds entirely plausible. This "hallucination" problem has become a major barrier to using these models where accuracy matters most. Existing solutions either require retraining the entire model, add significant computational costs, or miss the root causes of why these hallucinations occur in the first place.
  We present CausalGuard, a new approach that combines causal reasoning with symbolic logic to catch and prevent hallucinations as they happen. Unlike previous methods that only check outputs after generation, our system understands the causal chain that leads to false statements and intervenes early in the process. CausalGuard works through two complementary paths: one that traces causal relationships between what the model knows and what it generates, and another that checks logical consistency using automated reasoning.
  Testing across twelve different benchmarks, we found that CausalGuard correctly identifies hallucinations 89.3\% of the time while missing only 8.3\% of actual hallucinations. More importantly, it reduces false claims by nearly 80\% while keeping responses natural and helpful. The system performs especially well on complex reasoning tasks where multiple steps of logic are required. Because CausalGuard shows its reasoning process, it works well in sensitive areas like medical diagnosis or financial analysis where understanding why a decision was made matters as much as the decision itself.

</details>


### [154] [Quantifying Skill and Chance: A Unified Framework for the Geometry of Games](https://arxiv.org/abs/2511.11611)
*David H. Silver*

Main category: cs.AI

TL;DR: 提出了一个量化框架，通过将游戏建模为随机决策树来分离技能和运气成分，定义了技能-运气指数S(G)在[-1,1]范围内，并引入波动率Sigma来量化连续回合的结果不确定性。


<details>
  <summary>Details</summary>
Motivation: 为了在游戏中定量区分技能和运气的影响，建立系统化的评估方法，用于游戏设计、AI评估和风险评估。

Method: 将游戏建模为随机决策树，分解游戏结果为技能杠杆K和运气杠杆L，定义技能-运气指数S(G) = (K-L)/(K+L)，并引入波动率Sigma量化不确定性。

Result: 分析了30个游戏，发现从纯运气（硬币投掷，S=-1）到混合领域（如双陆棋，S=0）再到纯技能（国际象棋，S=+1）的连续谱。扑克显示中等技能主导（S=0.33）。

Conclusion: 该框架可扩展到一般随机决策系统，为玩家影响力、游戏平衡性和预测稳定性提供原则性比较，在游戏设计、AI评估和风险评估中具有应用价值。

Abstract: We introduce a quantitative framework for separating skill and chance in games by modeling them as complementary sources of control over stochastic decision trees. We define the Skill-Luck Index S(G) in [-1, 1] by decomposing game outcomes into skill leverage K and luck leverage L. Applying this to 30 games reveals a continuum from pure chance (coin toss, S = -1) through mixed domains such as backgammon (S = 0, Sigma = 1.20) to pure skill (chess, S = +1, Sigma = 0). Poker exhibits moderate skill dominance (S = 0.33) with K = 0.40 +/- 0.03 and Sigma = 0.80. We further introduce volatility Sigma to quantify outcome uncertainty over successive turns. The framework extends to general stochastic decision systems, enabling principled comparisons of player influence, game balance, and predictive stability, with applications to game design, AI evaluation, and risk assessment.

</details>


### [155] [Looking Forward: Challenges and Opportunities in Agentic AI Reliability](https://arxiv.org/abs/2511.11921)
*Liudong Xing,Janet,Lin*

Main category: cs.AI

TL;DR: 本章讨论了构建可靠AI系统（特别是智能体AI系统）面临的挑战和未来发展前景，重点关注级联故障风险缓解、动态环境、任务执行不一致性、不可预测涌现行为等研究问题。


<details>
  <summary>Details</summary>
Motivation: 随着智能体AI系统的广泛应用，确保其可靠性变得至关重要。这些系统在复杂环境中运行时可能面临级联故障、动态变化、行为不可预测等风险，需要系统性的可靠性保障机制。

Method: 通过分析智能体AI系统在动态环境中的运行特性，识别关键可靠性挑战，包括级联故障、任务执行不一致性、涌现行为等，并提出相应的研究方向和测试评估方法。

Result: 识别了多个关键研究问题：级联故障风险缓解、动态环境适应性、任务执行一致性保障、涌现行为预测与控制，以及高效可靠性机制设计。

Conclusion: 构建可靠的智能体AI系统需要在多个维度进行深入研究，包括故障预防、环境适应性、行为预测和高效测试评估方法，这是未来AI系统发展的重要方向。

Abstract: This chapter presents perspectives for challenges and future development in building reliable AI systems, particularly, agentic AI systems. Several open research problems related to mitigating the risks of cascading failures are discussed. The chapter also sheds lights on research challenges and opportunities in aspects including dynamic environments, inconsistent task execution, unpredictable emergent behaviors, as well as resource-intensive reliability mechanisms. In addition, several research directions along the line of testing and evaluating reliability of agentic AI systems are also discussed.

</details>


### [156] [Think, Speak, Decide: Language-Augmented Multi-Agent Reinforcement Learning for Economic Decision-Making](https://arxiv.org/abs/2511.12876)
*Heyang Ma,Qirui Mi,Qipeng Yang,Zijun Fan,Bo Li,Haifeng Zhang*

Main category: cs.AI

TL;DR: LAMP框架通过语言增强的多智能体强化学习，在经济决策中整合语言信息，显著提升了决策性能、鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现实经济决策不仅依赖结构化信号（如价格、税收），还依赖非结构化语言信息（如对话、媒体叙事）。传统多智能体强化学习难以处理语言的语义模糊性和上下文丰富性。

Method: LAMP采用Think-Speak-Decide三阶段流程：Think阶段解释数值观察提取短期冲击和长期趋势；Speak阶段基于推理生成和交换战略信息；Decide阶段融合数值数据、推理和反思到MARL策略中。

Result: 在经济模拟实验中，LAMP在累积回报（+63.5%、+34.0%）、鲁棒性（+18.8%、+59.4%）和可解释性方面均优于MARL和纯LLM基线。

Conclusion: 语言增强策略在提供更有效和鲁棒的经济策略方面具有巨大潜力。

Abstract: Economic decision-making depends not only on structured signals such as prices and taxes, but also on unstructured language, including peer dialogue and media narratives. While multi-agent reinforcement learning (MARL) has shown promise in optimizing economic decisions, it struggles with the semantic ambiguity and contextual richness of language. We propose LAMP (Language-Augmented Multi-Agent Policy), a framework that integrates language into economic decision-making and narrows the gap to real-world settings. LAMP follows a Think-Speak-Decide pipeline: (1) Think interprets numerical observations to extract short-term shocks and long-term trends, caching high-value reasoning trajectories; (2) Speak crafts and exchanges strategic messages based on reasoning, updating beliefs by parsing peer communications; and (3) Decide fuses numerical data, reasoning, and reflections into a MARL policy to optimize language-augmented decision-making. Experiments in economic simulation show that LAMP outperforms both MARL and LLM-only baselines in cumulative return (+63.5%, +34.0%), robustness (+18.8%, +59.4%), and interpretability. These results demonstrate the potential of language-augmented policies to deliver more effective and robust economic strategies.

</details>


### [157] [Value-Aligned Prompt Moderation via Zero-Shot Agentic Rewriting for Safe Image Generation](https://arxiv.org/abs/2511.11693)
*Xin Zhao,Xiaojun Chen,Bingshan Liu,Zeyao Liu,Zhendong Zhao,Xiaoyan Gu*

Main category: cs.AI

TL;DR: VALOR是一个模块化的零样本代理框架，通过分层提示分析和价值对齐推理来实现更安全、更有帮助的文生图生成，显著减少不安全输出同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 生成式视觉语言模型在创意媒体合成方面表现出色，但在对抗性提示下可能产生不安全、冒犯性或文化不适当的内容。现有防御方法难以在不牺牲生成质量或产生高成本的情况下使输出与人类价值观对齐。

Method: VALOR框架包含多层NSFW检测器过滤词汇和语义风险、文化价值对齐模块识别社会规范、合法性和表征伦理违规、意图消歧器检测微妙或不安全暗示。检测到不安全内容时，由大语言模型在动态角色特定指令下选择性重写提示，如果生成图像仍不安全，可选择进行风格化再生以引导到更安全的视觉领域。

Result: 在对抗性、模糊性和价值敏感提示上的实验表明，VALOR将不安全输出显著减少高达100.00%，同时保持了提示的有用性和创造性。

Conclusion: VALOR作为一种可扩展且有效的方法，可在开放世界环境中部署安全、对齐且有用的图像生成系统。

Abstract: Generative vision-language models like Stable Diffusion demonstrate remarkable capabilities in creative media synthesis, but they also pose substantial risks of producing unsafe, offensive, or culturally inappropriate content when prompted adversarially. Current defenses struggle to align outputs with human values without sacrificing generation quality or incurring high costs. To address these challenges, we introduce VALOR (Value-Aligned LLM-Overseen Rewriter), a modular, zero-shot agentic framework for safer and more helpful text-to-image generation. VALOR integrates layered prompt analysis with human-aligned value reasoning: a multi-level NSFW detector filters lexical and semantic risks; a cultural value alignment module identifies violations of social norms, legality, and representational ethics; and an intention disambiguator detects subtle or indirect unsafe implications. When unsafe content is detected, prompts are selectively rewritten by a large language model under dynamic, role-specific instructions designed to preserve user intent while enforcing alignment. If the generated image still fails a safety check, VALOR optionally performs a stylistic regeneration to steer the output toward a safer visual domain without altering core semantics. Experiments across adversarial, ambiguous, and value-sensitive prompts show that VALOR significantly reduces unsafe outputs by up to 100.00% while preserving prompt usefulness and creativity. These results highlight VALOR as a scalable and effective approach for deploying safe, aligned, and helpful image generation systems in open-world settings.

</details>


### [158] [MM-Telco: Benchmarks and Multimodal Large Language Models for Telecom Applications](https://arxiv.org/abs/2511.13131)
*Gagan Raj Gupta,Anshul Kumar,Manish Rai,Apu Chakraborty,Ashutosh Modi,Abdelaali Chaoub,Soumajit Pramanik,Moyank Giri,Yashwanth Holla,Sunny Kumar,M. V. Kiran Sooraj*

Main category: cs.AI

TL;DR: MM-Telco是一个针对电信领域的多模态基准测试套件和模型，旨在解决LLMs在电信应用中的领域特定挑战，提升网络优化、故障排除等任务的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在电信领域有巨大应用潜力，但面临领域特定的挑战，需要专门适配来加速其在电信领域的应用。

Method: 提出了MM-Telco基准测试套件，包含基于文本和图像的各种任务，涵盖网络运营、管理等实际用例，并对多种LLMs和VLMs进行基线实验。

Result: 在数据集上微调的模型性能显著提升，实验揭示了当前最先进多模态LLMs的薄弱环节。

Conclusion: MM-Telco为电信领域的LLMs应用提供了重要基准，指导了进一步的研究和发展方向。

Abstract: Large Language Models (LLMs) have emerged as powerful tools for automating complex reasoning and decision-making tasks. In telecommunications, they hold the potential to transform network optimization, automate troubleshooting, enhance customer support, and ensure regulatory compliance. However, their deployment in telecom is hindered by domain-specific challenges that demand specialized adaptation. To overcome these challenges and to accelerate the adaptation of LLMs for telecom, we propose MM-Telco, a comprehensive suite of multimodal benchmarks and models tailored for the telecom domain. The benchmark introduces various tasks (both text based and image based) that address various practical real-life use cases such as network operations, network management, improving documentation quality, and retrieval of relevant text and images. Further, we perform baseline experiments with various LLMs and VLMs. The models fine-tuned on our dataset exhibit a significant boost in performance. Our experiments also help analyze the weak areas in the working of current state-of-art multimodal LLMs, thus guiding towards further development and research.

</details>


### [159] [Towards autonomous quantum physics research using LLM agents with access to intelligent tools](https://arxiv.org/abs/2511.11752)
*Sören Arlt,Xuemei Gu,Mario Krenn*

Main category: cs.AI

TL;DR: AI-Mandel是一个能够自主生成并实施量子物理领域创新想法的LLM代理系统，它通过文献分析生成科学想法，并使用特定领域AI工具将其转化为可立即在实验室实施的实验设计。


<details>
  <summary>Details</summary>
Motivation: 当前AI在科学领域的应用仍主要依赖人类提供研究问题和目标，AI自主生成创意想法的情况很少且往往模糊。自动化想法生成和实施系统将显著改变人类在科学过程中的角色。

Method: AI-Mandel通过分析文献来制定想法，并使用特定领域的AI工具将这些想法转化为具体的实验设计，这些设计可以直接在实验室中实施。

Result: AI-Mandel生成的想法具有科学价值，其中两个想法已经促成了独立的后续科学论文。生成的想法包括量子隐形传态的新变体、不定因果顺序中的量子网络原语，以及基于量子信息传输闭合回路的新几何相位概念。

Conclusion: AI-Mandel是能够生成和实施具体可行想法的AI物理学家的原型演示。构建这样的系统不仅有助于加速科学发展，还揭示了实现人类水平人工智能科学家所面临的具体挑战。

Abstract: Artificial intelligence (AI) is used in numerous fields of science, yet the initial research questions and targets are still almost always provided by human researchers. AI-generated creative ideas in science are rare and often vague, so that it remains a human task to execute them. Automating idea generation and implementation in one coherent system would significantly shift the role of humans in the scientific process. Here we present AI-Mandel, an LLM agent that can generate and implement ideas in quantum physics. AI-Mandel formulates ideas from the literature and uses a domain-specific AI tool to turn them into concrete experiment designs that can readily be implemented in laboratories. The generated ideas by AI-Mandel are often scientifically interesting - for two of them we have already written independent scientific follow-up papers. The ideas include new variations of quantum teleportation, primitives of quantum networks in indefinite causal orders, and new concepts of geometric phases based on closed loops of quantum information transfer. AI-Mandel is a prototypical demonstration of an AI physicist that can generate and implement concrete, actionable ideas. Building such a system is not only useful to accelerate science, but it also reveals concrete open challenges on the path to human-level artificial scientists.

</details>


### [160] [Learning to Refine: An Agentic RL Approach for Iterative SPARQL Query Construction](https://arxiv.org/abs/2511.11770)
*Floris Vossebeld,Shenghui Wang*

Main category: cs.AI

TL;DR: 本文提出了一种基于强化学习的智能体框架，用于迭代构建SPARQL查询，解决知识图谱问答中复杂多跳查询生成的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在一次性生成复杂SPARQL查询时存在脆弱性，缺乏基于实时执行反馈的动态调试能力，这限制了知识图谱问答系统的可靠性。

Method: 采用基于结果的强化学习训练3B参数模型，无需监督微调，让智能体学习迭代构建SPARQL查询的策略，能够从执行错误中系统恢复并优化查询。

Result: 在LC-QuAD 2.0的可执行子集上，该方法在实体链接后达到49.7%的准确率，比最强的零样本基线提高了17.5个百分点。

Conclusion: 该工作提供了一个通用框架，通过交互式学习让智能体掌握形式化符号工具，弥合概率性大语言模型与结构化知识图谱之间的差距。

Abstract: Generating complex, logically-sound SPARQL queries for multi-hop questions remains a critical bottleneck for Knowledge Graph Question Answering, as the brittle nature of one-shot generation by Large Language Models (LLMs) hinders reliable interaction with structured data. Current methods lack the adaptive policies needed to dynamically debug queries based on real-time execution feedback. This paper introduces a novel agentic framework where an LLM learns a resilient policy for the sequential process of iterative SPARQL construction. We show that a compact 3B-parameter model, trained exclusively via outcome-driven Reinforcement Learning (GRPO) without supervised fine-tuning, can learn effective policies for this task, discovering how to systematically recover from execution errors and refine its queries toward a correct answer. On a curated, executable single-answer subset of LC-QuAD 2.0, our agent achieves 49.7\% accuracy post-entity-linking, a significant 17.5 percentage point improvement over the strongest iterative zero-shot baseline. Further analysis reveals that while the agent's capability is driven by RL, its performance is enhanced by an explicit deliberative reasoning step that acts as a cognitive scaffold to improve policy precision. This work presents a generalizable blueprint for teaching agents to master formal, symbolic tools through interaction, bridging the gap between probabilistic LLMs and the structured world of Knowledge Graphs.

</details>


### [161] [On the Measure of a Model: From Intelligence to Generality](https://arxiv.org/abs/2511.11773)
*Ruchira Dhar,Ninell Oldenburg,Anders Soegaard*

Main category: cs.AI

TL;DR: 论文质疑以抽象智力概念为基础的AI评估方法，提出应以通用性作为更稳定的评估基础，将通用性重新定义为多任务学习问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于ARC、Raven测试等智力基准的评估方法缺乏稳定的智力定义，且无法预测实际任务表现，存在与现实效用脱节的风险。

Method: 通过概念和形式分析，检验智力评估的三个假设：通用性、稳定性和现实性，论证只有通用性经得起概念和实证检验。

Result: 研究表明智力不是实现通用性的原因，通用性应被理解为多任务学习问题，直接关联到可测量的性能广度和可靠性。

Conclusion: 评估AI进展应基于通用性而非抽象智力概念，通用性为评估多样化演进任务能力提供了更稳定的基础。

Abstract: Benchmarks such as ARC, Raven-inspired tests, and the Blackbird Task are widely used to evaluate the intelligence of large language models (LLMs). Yet, the concept of intelligence remains elusive- lacking a stable definition and failing to predict performance on practical tasks such as question answering, summarization, or coding. Optimizing for such benchmarks risks misaligning evaluation with real-world utility. Our perspective is that evaluation should be grounded in generality rather than abstract notions of intelligence. We identify three assumptions that often underpin intelligence-focused evaluation: generality, stability, and realism. Through conceptual and formal analysis, we show that only generality withstands conceptual and empirical scrutiny. Intelligence is not what enables generality; generality is best understood as a multitask learning problem that directly links evaluation to measurable performance breadth and reliability. This perspective reframes how progress in AI should be assessed and proposes generality as a more stable foundation for evaluating capability across diverse and evolving tasks.

</details>


### [162] [Do LLMs Really Struggle at NL-FOL Translation? Revealing their Strengths via a Novel Benchmarking Strategy](https://arxiv.org/abs/2511.11816)
*Andrea Brunello,Luca Geatti,Michele Mignani,Angelo Montanari,Nicola Saccomanno*

Main category: cs.AI

TL;DR: 本文批判性评估了现有NL-FOL翻译数据集和评估协议，提出了新的评估方法来区分真正的语义理解与表面模式识别，并发现对话导向的LLMs在NL-FOL翻译方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 由于一阶逻辑(FOL)的表达能力和明确性，它是表示自然语言概念的有力形式化工具。然而，将自然语言转换为FOL(NL-FOL翻译)长期以来一直是一个挑战，尽管LLMs的出现带来了突破希望，但现有文献对其能力给出了矛盾的结果。

Method: 首先批判性检查现有评估数据集和协议，揭示可能导致LLMs实际能力误判的关键限制；其次提出专门设计的新评估协议，以区分真正的语义级逻辑理解与表面模式识别、记忆和数据集污染；最后使用新方法评估不同LLMs的性能。

Result: 使用新评估方法发现，最先进的对话导向LLMs表现出强大的NL-FOL翻译技能和对句子级逻辑的真正掌握，而嵌入中心模型表现明显较差。

Conclusion: 本文表明，通过适当的评估协议，对话导向的LLMs确实具备强大的NL-FOL翻译能力，这挑战了现有文献中关于LLMs逻辑理解能力的矛盾观点。

Abstract: Due to its expressiveness and unambiguous nature, First-Order Logic (FOL) is a powerful formalism for representing concepts expressed in natural language (NL). This is useful, e.g., for specifying and verifying desired system properties. While translating FOL into human-readable English is relatively straightforward, the inverse problem, converting NL to FOL (NL-FOL translation), has remained a longstanding challenge, for both humans and machines. Although the emergence of Large Language Models (LLMs) promised a breakthrough, recent literature provides contrasting results on their ability to perform NL-FOL translation. In this work, we provide a threefold contribution. First, we critically examine existing datasets and protocols for evaluating NL-FOL translation performance, revealing key limitations that may cause a misrepresentation of LLMs' actual capabilities. Second, to overcome these shortcomings, we propose a novel evaluation protocol explicitly designed to distinguish genuine semantic-level logical understanding from superficial pattern recognition, memorization, and dataset contamination. Third, using this new approach, we show that state-of-the-art, dialogue-oriented LLMs demonstrate strong NL-FOL translation skills and a genuine grasp of sentence-level logic, whereas embedding-centric models perform markedly worse.

</details>


### [163] [TopoPerception: A Shortcut-Free Evaluation of Global Visual Perception in Large Vision-Language Models](https://arxiv.org/abs/2511.11831)
*Wenhao Zhou,Hao Zheng,Rong Zhao*

Main category: cs.AI

TL;DR: TopoPerception是一个基于拓扑特性的基准测试，用于严格评估大型视觉语言模型的全局视觉感知能力，发现现有模型在全局感知方面表现不佳，甚至不如随机猜测。


<details>
  <summary>Details</summary>
Motivation: 现有LVLMs将视觉特征与预训练LLM对齐，使视觉感知模块成为瓶颈，且传统评估基准存在局部捷径，高估了模型的感知能力。

Method: 利用拓扑特性构建评估基准，因为拓扑依赖于图像全局结构且对局部特征不变，能够实现无捷径的全局感知评估。

Result: 所有最先进模型在最粗粒度感知任务上表现都不优于随机机会，且模型家族内呈现一致趋势：推理能力更强的模型准确率更低。

Conclusion: 仅扩大模型规模不足以解决全局视觉感知缺陷，可能需要新的训练范式或架构，TopoPerception为改进LVLMs的全局视觉感知提供了方向和工具。

Abstract: Large Vision-Language Models (LVLMs) typically align visual features from an encoder with a pre-trained Large Language Model (LLM). However, this makes the visual perception module a bottleneck, which constrains the overall capabilities of LVLMs. Conventional evaluation benchmarks, while rich in visual semantics, often contain unavoidable local shortcuts that can lead to an overestimation of models' perceptual abilities. Here, we introduce TopoPerception, a benchmark that leverages topological properties to rigorously evaluate the global visual perception capabilities of LVLMs across various granularities. Since topology depends on the global structure of an image and is invariant to local features, TopoPerception enables a shortcut-free assessment of global perception, fundamentally distinguishing it from semantically rich tasks. We evaluate state-of-the-art models on TopoPerception and find that even at the coarsest perceptual granularity, all models perform no better than random chance, indicating a profound inability to perceive global visual features. Notably, a consistent trend emerge within model families: more powerful models with stronger reasoning capabilities exhibit lower accuracy. This suggests that merely scaling up models is insufficient to address this deficit and may even exacerbate it. Progress may require new training paradigms or architectures. TopoPerception not only exposes a critical bottleneck in current LVLMs but also offers a lens and direction for improving their global visual perception. The data and code are publicly available at: https://github.com/Wenhao-Zhou/TopoPerception.

</details>


### [164] [End to End AI System for Surgical Gesture Sequence Recognition and Clinical Outcome Prediction](https://arxiv.org/abs/2511.11899)
*Xi Li,Nicholas Matsumoto,Ujjwal Pasupulety,Atharva Deo,Cherine Yang,Jay Moran,Miguel E. Hernandez,Peter Wager,Jasmine Lin,Jeanine Kim,Alvin C. Goh,Christian Wagner,Geoffrey A. Sonn,Andrew J. Hung*

Main category: cs.AI

TL;DR: F2O是一个端到端系统，可将手术视频转化为手势序列并发现与术后结果相关的模式，在机器人辅助前列腺切除术中实现了高精度的动作识别和术后结果预测。


<details>
  <summary>Details</summary>
Motivation: 术中行为的细粒度分析及其对患者结果的影响一直是长期挑战，需要自动化的手术评估系统。

Method: 使用基于transformer的空间和时间建模以及逐帧分类，检测连续短手势（约2秒），并提取手势频率、持续时间和转换等特征。

Result: 在神经保留步骤中实现了高精度检测（AUC：0.80帧级；0.81视频级），术后结果预测准确性与人工标注相当（0.79 vs 0.75），并发现了与勃起功能恢复相关的关键模式。

Conclusion: F2O通过实现自动可解释评估，为数据驱动的手术反馈和前瞻性临床决策支持奠定了基础。

Abstract: Fine-grained analysis of intraoperative behavior and its impact on patient outcomes remain a longstanding challenge. We present Frame-to-Outcome (F2O), an end-to-end system that translates tissue dissection videos into gesture sequences and uncovers patterns associated with postoperative outcomes. Leveraging transformer-based spatial and temporal modeling and frame-wise classification, F2O robustly detects consecutive short (~2 seconds) gestures in the nerve-sparing step of robot-assisted radical prostatectomy (AUC: 0.80 frame-level; 0.81 video-level). F2O-derived features (gesture frequency, duration, and transitions) predicted postoperative outcomes with accuracy comparable to human annotations (0.79 vs. 0.75; overlapping 95% CI). Across 25 shared features, effect size directions were concordant with small differences (~ 0.07), and strong correlation (r = 0.96, p < 1e-14). F2O also captured key patterns linked to erectile function recovery, including prolonged tissue peeling and reduced energy use. By enabling automatic interpretable assessment, F2O establishes a foundation for data-driven surgical feedback and prospective clinical decision support.

</details>


### [165] [Forgetting-MarI: LLM Unlearning via Marginal Information Regularization](https://arxiv.org/abs/2511.11914)
*Shizhou Xu,Yuan Ni,Stefan Broecker,Thomas Strohmer*

Main category: cs.AI

TL;DR: Forgetting-MarI是一个LLM遗忘框架，通过惩罚边际信息来选择性移除待遗忘数据的参数知识，同时保留待保留数据的信息，提供可证明的不可检测性。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型在不断扩大数据集上训练，从训练模型中移除特定数据影响的能力对于隐私保护和法规遵从变得至关重要。现有遗忘方法在尝试'遗忘'特定数据时往往会移除过多信息，导致模型性能下降。

Method: 引入Forgetting-MarI框架，通过惩罚边际信息来仅移除待遗忘数据贡献的额外信息，同时保留待保留数据支持的信息，提供未学习数据集残留影响的明确上界。

Result: 大量实验证实该方法优于当前最先进的遗忘方法，在多样基准测试中实现可靠的遗忘和更好的模型性能保留。

Conclusion: 这一进展代表了在使AI系统更可控、更符合隐私和版权法规方面的重要一步，同时不损害其有效性。

Abstract: As AI models are trained on ever-expanding datasets, the ability to remove the influence of specific data from trained models has become essential for privacy protection and regulatory compliance. Unlearning addresses this challenge by selectively removing parametric knowledge from the trained models without retraining from scratch, which is critical for resource-intensive models such as Large Language Models (LLMs). Existing unlearning methods often degrade model performance by removing more information than necessary when attempting to ''forget'' specific data. We introduce Forgetting-MarI, an LLM unlearning framework that provably removes only the additional (marginal) information contributed by the data to be unlearned, while preserving the information supported by the data to be retained. By penalizing marginal information, our method yields an explicit upper bound on the unlearn dataset's residual influence in the trained models, providing provable undetectability. Extensive experiments confirm that our approach outperforms current state-of-the-art unlearning methods, delivering reliable forgetting and better preserved general model performance across diverse benchmarks. This advancement represents an important step toward making AI systems more controllable and compliant with privacy and copyright regulations without compromising their effectiveness.

</details>


### [166] [An Analysis of Architectural Impact on LLM-based Abstract Visual Reasoning: A Systematic Benchmark on RAVEN-FAIR](https://arxiv.org/abs/2511.11916)
*Sinan Urgun,Seçkin Arı*

Main category: cs.AI

TL;DR: 本研究系统评估了四种大型语言模型在抽象视觉推理任务中的表现，使用四种推理架构在RAVEN-FAIR数据集上进行测试，发现GPT-4.1-Mini表现最佳，且推理效果具有模型特异性。


<details>
  <summary>Details</summary>
Motivation: 系统评估大型语言模型在抽象视觉推理问题中的性能表现，探索不同推理架构对模型表现的影响。

Method: 使用四种LLM模型（GPT-4.1-Mini、Claude-3.5-Haiku、Gemini-1.5-Flash、Llama-3.3-70b）和四种推理架构（单次推理、嵌入控制重复、自我反思、多智能体），在RAVEN-FAIR数据集上通过三阶段流程（JSON提取、LLM推理、工具函数）生成视觉响应，使用SSIM和LPIPS指标评估，分析思维链得分和错误类型。

Result: GPT-4.1-Mini在所有架构中始终获得最高准确率，表现出强大的推理能力。多智能体架构偶尔会改变语义和数值平衡，但效果不一致。不同模型对架构设计表现出不同的敏感模式，响应覆盖度的变化使跨架构直接比较复杂化。

Conclusion: 推理效果具有模型特异性，多轮运行评估策略比单轮评估更可靠，GPT-4.1-Mini在抽象视觉推理任务中表现最佳。

Abstract: This study aims to systematically evaluate the performance of large language models (LLMs) in abstract visual reasoning problems. We examined four LLM models (GPT-4.1-Mini, Claude-3.5-Haiku, Gemini-1.5-Flash, Llama-3.3-70b) utilizing four different reasoning architectures (single-shot, embedding-controlled repetition, self-reflection, and multi-agent) on the RAVEN-FAIR dataset. Visual responses generated through a three-stage process (JSON extraction, LLM reasoning, and Tool Function) were evaluated using SSIM and LPIPS metrics; Chain-of-Thought scores and error types (semantic hallucination, numeric misperception) were analyzed. Results demonstrate that GPT-4.1-Mini consistently achieved the highest overall accuracy across all architectures, indicating a strong reasoning capability. While the multi-agent architecture occasionally altered semantic and numeric balance across models, these effects were not uniformly beneficial. Instead, each model exhibited distinct sensitivity patterns to architectural design, underscoring that reasoning effectiveness remains model-specific. Variations in response coverage further emerged as a confounding factor that complicates direct cross-architecture comparison. To estimate the upper-bound performance of each configuration, we report the best of five independent runs, representing a best-case scenario rather than an averaged outcome. This multi-run strategy aligns with recent recommendations, which emphasize that single-run evaluations are fragile and may lead to unreliable conclusions.

</details>


### [167] [A Neuromorphic Architecture for Scalable Event-Based Control](https://arxiv.org/abs/2511.11924)
*Yongkang Huo,Fulvio Forni,Rodolphe Sepulchre*

Main category: cs.AI

TL;DR: 提出了"反弹赢家通吃(RWTA)"基元作为可扩展神经形态控制架构的基本元素，结合了离散计算的可靠性和连续调节的可调性


<details>
  <summary>Details</summary>
Motivation: 构建一个统一的神经形态控制架构，能够同时处理连续节律生成和离散决策，结合离散计算和连续调节的优势

Method: 使用RWTA基元构建从细胞级到系统级的架构，继承赢家通吃状态机的离散计算能力和可兴奋生物物理电路的连续调节能力

Result: 开发了基于事件的框架，在蛇形机器人的神经系统设计中展示了该架构的通用性、鲁棒性和模块化特性

Conclusion: RWTA架构成功统一了连续节律生成和离散决策，为神经形态控制提供了可扩展的解决方案

Abstract: This paper introduces the ``rebound Winner-Take-All (RWTA)" motif as the basic element of a scalable neuromorphic control architecture. From the cellular level to the system level, the resulting architecture combines the reliability of discrete computation and the tunability of continuous regulation: it inherits the discrete computation capabilities of winner-take-all state machines and the continuous tuning capabilities of excitable biophysical circuits. The proposed event-based framework addresses continuous rhythmic generation and discrete decision-making in a unified physical modeling language. We illustrate the versatility, robustness, and modularity of the architecture through the nervous system design of a snake robot.

</details>


### [168] [Augmenting The Weather: A Hybrid Counterfactual-SMOTE Algorithm for Improving Crop Growth Prediction When Climate Changes](https://arxiv.org/abs/2511.11945)
*Mohammed Temraz,Mark T Keane*

Main category: cs.AI

TL;DR: 提出CFA-SMOTE方法，结合反事实解释和SMOTE技术，通过生成气候异常事件的合成数据点来解决气候变化预测中的类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法基于历史数据分布，难以处理气候变化带来的分布外异常事件，因为历史数据中缺乏足够的少数类（气候异常事件）实例。

Method: 将气候变化预测问题视为类别不平衡问题，结合可解释AI中的反事实方法和经典的SMOTE方法，生成代表气候异常事件的合成数据点。

Result: 在不同类别不平衡比例条件下，CFA-SMOTE方法相比基准的反事实和类别不平衡方法表现出更好的预测性能。

Conclusion: CFA-SMOTE能有效改善气候变化相关预测任务的性能，特别是在处理气候异常事件时。

Abstract: In recent years, humanity has begun to experience the catastrophic effects of climate change as economic sectors (such as agriculture) struggle with unpredictable and extreme weather events. Artificial Intelligence (AI) should help us handle these climate challenges but its most promising solutions are not good at dealing with climate-disrupted data; specifically, machine learning methods that work from historical data-distributions, are not good at handling out-of-distribution, outlier events. In this paper, we propose a novel data augmentation method, that treats the predictive problems around climate change as being, in part, due to class-imbalance issues; that is, prediction from historical datasets is difficult because, by definition, they lack sufficient minority-class instances of "climate outlier events". This novel data augmentation method -- called Counterfactual-Based SMOTE (CFA-SMOTE) -- combines an instance-based counterfactual method from Explainable AI (XAI) with the well-known class-imbalance method, SMOTE. CFA-SMOTE creates synthetic data-points representing outlier, climate-events that augment the dataset to improve predictive performance. We report comparative experiments using this CFA-SMOTE method, comparing it to benchmark counterfactual and class-imbalance methods under different conditions (i.e., class-imbalance ratios). The focal climate-change domain used relies on predicting grass growth on Irish dairy farms, during Europe-wide drought and forage crisis of 2018.

</details>


### [169] [LLM-Assisted Formalization Enables Deterministic Detection of Statutory Inconsistency in the Internal Revenue Code](https://arxiv.org/abs/2511.11954)
*Borchuluun Yadamsuren,Steven Keith Platt,Miguel Diaz*

Main category: cs.AI

TL;DR: 本文提出了一种结合大语言模型和符号逻辑的混合神经符号框架，用于确定性检测复杂法律中的法定不一致性，以美国国内税收法典为案例研究。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法在层次化处理和深度结构化推理方面存在困难，特别是在长文本上。税收领域的特定应用仍然稀少，需要解决这些差距以实现可靠的法定不一致性检测。

Method: 使用GPT-4o将法律条款翻译成Prolog规则，在SWISH中精炼，然后通过Prolog增强提示测试不一致性检测。同时开发混合Prolog模型，由GPT-5指导精炼，形式化竞争性解释。

Result: GPT-4o仅在一个策略中检测到不一致性（33%准确率），自然语言提示实现100%规则覆盖，Prolog增强提示为66%。混合Prolog模型产生确定性结果，成功检测不一致性区域，验证显示实现准确、内部一致、确定性的自主不一致性识别。

Conclusion: 基于符号逻辑的LLM辅助形式化能够实现透明可靠的法定不一致性检测，混合方法在确定性推理方面优于纯概率性提示方法。

Abstract: This study introduces a hybrid neuro-symbolic framework that achieves deterministic detection of statutory inconsistency in complex law. We use the U.S. Internal Revenue Code (IRC) as a case study because its complexity makes it a fertile domain for identifying conflicts. Our research offers a solution for detecting inconsistent provisions by combining Large Language Models (LLMs) with symbolic logic.
  LLM-based methods can support compliance, fairness, and statutory drafting, yet tax-specific applications remain sparse. A key challenge is that such models struggle with hierarchical processing and deep structured reasoning, especially over long text.
  This research addresses these gaps through experiments using GPT-4o, GPT-5, and Prolog. GPT-4o was first used to translate Section 121 into Prolog rules and refine them in SWISH. These rules were then incorporated into prompts to test whether Prolog-augmented prompting improved GPT-4o's inconsistency detection. GPT-4o, whether prompted with natural language alone or with Prolog augmentation, detected the inconsistency in only one of three strategies (33 percent accuracy), but its reasoning quality differed: natural-language prompting achieved 100 percent rule coverage, while Prolog-augmented prompting achieved 66 percent, indicating more incomplete statutory analysis.
  In contrast to probabilistic prompting, the hybrid Prolog model produced deterministic and reproducible results. Guided by GPT-5 for refinement, the model formalized the IRC section's competing interpretations and successfully detected an inconsistency zone. Validation tests confirm that the Prolog implementation is accurate, internally consistent, deterministic, and capable of autonomously identifying inconsistencies. These findings show that LLM-assisted formalization, anchored in symbolic logic, enables transparent and reliable statutory inconsistency detection.

</details>


### [170] [Improving Autoformalization Using Direct Dependency Retrieval](https://arxiv.org/abs/2511.11990)
*Shaoqi Wang,Lu Yu,Chunjie Yang*

Main category: cs.AI

TL;DR: 提出基于直接依赖检索(DDR)的自动形式化框架，通过从自然语言数学描述直接生成候选库依赖并验证，解决了现有方法缺乏上下文感知和检索精度低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有自动形式化方法缺乏上下文感知，导致形式定义和定理的幻觉，且检索增强方法在形式库依赖检索上精度和召回率差，无法有效利用不断增长的公共数据集。

Method: 提出DDR方法：直接从自然语言数学描述生成候选库依赖，通过高效后缀数组检查验证其在形式库中的存在性，构建50万+样本的依赖检索数据集并微调高精度DDR模型。

Result: DDR模型在检索精度和召回率上显著优于SOTA方法，配备DDR的自动形式化器在单次尝试准确率和多次尝试稳定性上均优于传统基于选择的RAG方法。

Conclusion: DDR框架通过高效的依赖检索机制，有效解决了自动形式化中的上下文感知和检索精度问题，为深度学习和形式数学的融合提供了更可靠的基础。

Abstract: The convergence of deep learning and formal mathematics has spurred research in formal verification. Statement autoformalization, a crucial first step in this process, aims to translate informal descriptions into machine-verifiable representations but remains a significant challenge. The core difficulty lies in the fact that existing methods often suffer from a lack of contextual awareness, leading to hallucination of formal definitions and theorems. Furthermore, current retrieval-augmented approaches exhibit poor precision and recall for formal library dependency retrieval, and lack the scalability to effectively leverage ever-growing public datasets. To bridge this gap, we propose a novel retrieval-augmented framework based on DDR (\textit{Direct Dependency Retrieval}) for statement autoformalization. Our DDR method directly generates candidate library dependencies from natural language mathematical descriptions and subsequently verifies their existence within the formal library via an efficient suffix array check. Leveraging this efficient search mechanism, we constructed a dependency retrieval dataset of over 500,000 samples and fine-tuned a high-precision DDR model. Experimental results demonstrate that our DDR model significantly outperforms SOTA methods in both retrieval precision and recall. Consequently, an autoformalizer equipped with DDR shows consistent performance advantages in both single-attempt accuracy and multi-attempt stability compared to models using traditional selection-based RAG methods.

</details>


### [171] [Look As You Think: Unifying Reasoning and Visual Evidence Attribution for Verifiable Document RAG via Reinforcement Learning](https://arxiv.org/abs/2511.12003)
*Shuochen Liu,Pengfei Luo,Chao Zhang,Yuhao Chen,Haotian Zhang,Qi Liu,Xin Kou,Tong Xu,Enhong Chen*

Main category: cs.AI

TL;DR: 提出Chain-of-Evidence（CoE）范式，通过强化学习框架LAT训练视觉语言模型生成可验证的推理路径，在视觉文档检索增强生成中实现证据溯源。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏细粒度监督和推理过程的渐进可追溯性，需要确保视觉文档检索增强生成的可信度和可验证性。

Method: 提出CoE范式统一思维链推理和视觉证据溯源，使用LAT强化学习框架训练模型生成带边界框和页面索引的证据溯源推理路径。

Result: 在Qwen2.5-VL-7B-Instruct模型上，LAT在单图和多图设置下平均提升8.23%的软精确匹配和47.0%的IoU@0.5，优于监督微调基线并展现更强的跨领域泛化能力。

Conclusion: LAT框架通过过程级自验证有效提升了视觉证据溯源能力，为可信的多模态问答提供了可靠解决方案。

Abstract: Aiming to identify precise evidence sources from visual documents, visual evidence attribution for visual document retrieval-augmented generation (VD-RAG) ensures reliable and verifiable predictions from vision-language models (VLMs) in multimodal question answering. Most existing methods adopt end-to-end training to facilitate intuitive answer verification. However, they lack fine-grained supervision and progressive traceability throughout the reasoning process. In this paper, we introduce the Chain-of-Evidence (CoE) paradigm for VD-RAG. CoE unifies Chain-of-Thought (CoT) reasoning and visual evidence attribution by grounding reference elements in reasoning steps to specific regions with bounding boxes and page indexes. To enable VLMs to generate such evidence-grounded reasoning, we propose Look As You Think (LAT), a reinforcement learning framework that trains models to produce verifiable reasoning paths with consistent attribution. During training, LAT evaluates the attribution consistency of each evidence region and provides rewards only when the CoE trajectory yields correct answers, encouraging process-level self-verification. Experiments on vanilla Qwen2.5-VL-7B-Instruct with Paper- and Wiki-VISA benchmarks show that LAT consistently improves the vanilla model in both single- and multi-image settings, yielding average gains of 8.23% in soft exact match (EM) and 47.0% in IoU@0.5. Meanwhile, LAT not only outperforms the supervised fine-tuning baseline, which is trained to directly produce answers with attribution, but also exhibits stronger generalization across domains.

</details>


### [172] [Adaptive Diagnostic Reasoning Framework for Pathology with Multimodal Large Language Models](https://arxiv.org/abs/2511.12008)
*Yunqi Hong,Johnson Kao,Liam Edwards,Nein-Tzu Liu,Chung-Yen Huang,Alex Oliveira-Kowaleski,Cho-Jui Hsieh,Neil Y. C. Lin*

Main category: cs.AI

TL;DR: RECAP-PATH是一个可解释的病理AI框架，通过两阶段自学习过程从被动模式识别转向证据关联的诊断推理，无需大量标注数据或模型权重更新即可生成癌症诊断。


<details>
  <summary>Details</summary>
Motivation: 当前病理AI系统缺乏人类可读的推理过程，限制了临床采用。需要可审计决策和防止错误的可解释AI框架。

Method: 采用两阶段自学习过程：多样化阶段扩展病理学风格解释，优化阶段为准确性精炼解释。使用现成的多模态大语言模型，无需白盒访问或权重更新。

Result: 在乳腺癌和前列腺癌数据集上评估，RECAP-PATH生成的推理与专家评估一致，诊断准确性相比基线有显著提升。

Conclusion: RECAP-PATH通过结合视觉理解和推理，提供了临床可信赖的AI，展示了证据关联解释的通用路径。

Abstract: AI tools in pathology have improved screening throughput, standardized quantification, and revealed prognostic patterns that inform treatment. However, adoption remains limited because most systems still lack the human-readable reasoning needed to audit decisions and prevent errors. We present RECAP-PATH, an interpretable framework that establishes a self-learning paradigm, shifting off-the-shelf multimodal large language models from passive pattern recognition to evidence-linked diagnostic reasoning. At its core is a two-phase learning process that autonomously derives diagnostic criteria: diversification expands pathology-style explanations, while optimization refines them for accuracy. This self-learning approach requires only small labeled sets and no white-box access or weight updates to generate cancer diagnoses. Evaluated on breast and prostate datasets, RECAP-PATH produced rationales aligned with expert assessment and delivered substantial gains in diagnostic accuracy over baselines. By uniting visual understanding with reasoning, RECAP-PATH provides clinically trustworthy AI and demonstrates a generalizable path toward evidence-linked interpretation.

</details>


### [173] [Intelligent Collaborative Optimization for Rubber Tyre Film Production Based on Multi-path Differentiated Clipping Proximal Policy Optimization](https://arxiv.org/abs/2511.12060)
*Yinghao Ruan,Wei Pang,Shuaihao Liu,Huili Yang,Leyi Han,Xinghui Dong*

Main category: cs.AI

TL;DR: 提出了一种多路径差分裁剪近端策略优化算法(MPD-PPO)，用于解决轮胎制造中的高维多目标优化问题，在橡胶轮胎薄膜生产的宽度和厚度控制中表现出色。


<details>
  <summary>Details</summary>
Motivation: 智能制造需要解决传统集中式调度和生产线配置的局限性，特别是在应对动态生产需求方面。轮胎制造系统形成复杂的网络，具有非线性交互和涌现动态，有效协调多个子系统是重要但艰巨的任务。

Method: 引入MPD-PPO算法，采用多分支策略架构和差分梯度裁剪约束，确保高维策略更新的稳定性和效率。

Result: 在橡胶轮胎薄膜生产的宽度和厚度控制实验中，MPD-PPO在调谐精度和操作效率方面均有显著提升。

Conclusion: 该框架成功解决了高维度、多目标权衡和动态适应等关键挑战，为轮胎制造中的实时工业部署提供了增强的性能和生产稳定性。

Abstract: The advent of smart manufacturing is addressing the limitations of traditional centralized scheduling and inflexible production line configurations in the rubber tyre industry, especially in terms of coping with dynamic production demands. Contemporary tyre manufacturing systems form complex networks of tightly coupled subsystems pronounced nonlinear interactions and emergent dynamics. This complexity renders the effective coordination of multiple subsystems, posing an essential yet formidable task. For high-dimensional, multi-objective optimization problems in this domain, we introduce a deep reinforcement learning algorithm: Multi-path Differentiated Clipping Proximal Policy Optimization (MPD-PPO). This algorithm employs a multi-branch policy architecture with differentiated gradient clipping constraints to ensure stable and efficient high-dimensional policy updates. Validated through experiments on width and thickness control in rubber tyre film production, MPD-PPO demonstrates substantial improvements in both tuning accuracy and operational efficiency. The framework successfully tackles key challenges, including high dimensionality, multi-objective trade-offs, and dynamic adaptation, thus delivering enhanced performance and production stability for real-time industrial deployment in tyre manufacturing.

</details>


### [174] [Bayesian Optimization in Language Space: An Eval-Efficient AI Self-Improvement Framework](https://arxiv.org/abs/2511.12063)
*Enoch Hyunwook Kang,Hema Yoganarasimhan*

Main category: cs.AI

TL;DR: 提出了T-BoN BO框架，通过结合Best-of-N选择和文本梯度来模拟UCB采集函数，优化评估效率而非生成效率的AI自我改进方法


<details>
  <summary>Details</summary>
Motivation: 在需要大量人工评估的社会应用中，评估成本远高于生成成本，现有方法主要关注查询效率而非评估效率

Method: 结合Best-of-N选择和文本梯度来模拟UCB采集函数，提出T-BoN BO框架进行语言空间的贝叶斯优化

Result: 在广告对齐任务中验证了T-BoN BO相比现有方法的优越性能

Conclusion: T-BoN BO为评估效率优化的AI自我改进提供了简单有效的框架

Abstract: Large Language Models (LLMs) have recently enabled self-improving AI, i.e., AI that iteratively generates, evaluates, and refines its own outcomes. Recent studies have shown that self-improving AI focusing on prompt optimization can outperform state-of-the-art reinforcement-learning fine-tuned LLMs. Here, their `performance' is typically measured by query efficiency - the number of LLM-generated solution samples required to meet a certain performance threshold. However, in many societal applications, the primary limitation is not generating new solutions but evaluating them. For instance, evaluating an ad's effectiveness requires significant human feedback, which is far more costly and time-consuming than generating a candidate ad. To optimize for the evaluation efficiency objective, a natural approach is to extend Bayesian Optimization (BO), a framework proven optimal for evaluation efficiency, to the language domain. However, the difficulty of directly estimating suitable acquisition functions in LLMs' minds makes this extension challenging. This paper overcomes this challenge by proving that the combination of the simple and widely used Best-of-N selection strategy and simple textual gradients (i.e., textual edits from a critic model) statistically emulates the behavior of the gradients on the canonical UCB acquisition function, which induces optimal exploration in terms of evaluation efficiency. Based on this result, we propose TextGrad-Best-of-N Bayesian Optimization (T-BoN BO), a simple and eval-efficient language-space Bayesian optimization framework for AI self-improvement. We also empirically validate T-BoN BO by applying it to automated ad alignment tasks for persona distribution, demonstrating its superior performance compared to popular state-of-the-art baselines.

</details>


### [175] [No-Regret Strategy Solving in Imperfect-Information Games via Pre-Trained Embedding](https://arxiv.org/abs/2511.12083)
*Yanchang Fu,Shengda Liu,Pei Xu,Kaiqi Huang*

Main category: cs.AI

TL;DR: 本文提出了Embedding CFR算法，通过将信息集嵌入到低维连续空间来解决大规模不完美信息扩展形式博弈的策略求解问题，相比基于聚类的抽象方法能更精确地捕捉信息集间的差异和联系。


<details>
  <summary>Details</summary>
Motivation: 现有AI方法依赖预训练的离散聚类进行抽象，但硬分类会不可逆地丢失信息集之间的量化细微差异，这些差异对策略求解至关重要，从而影响求解质量。

Method: 受自然语言处理中词嵌入范式的启发，提出Embedding CFR算法：预训练孤立信息集的特征并将其嵌入到互连的低维连续空间，在该嵌入空间中进行遗憾累积和策略更新的策略求解过程。

Result: 在扑克游戏上的实验表明，在相同空间开销下，Embedding CFR相比基于聚类的抽象算法实现了显著更快的可剥削性收敛。

Conclusion: Embedding CFR是扑克AI中首个通过低维嵌入预训练信息集抽象来进行策略求解的算法，能有效提升求解质量。

Abstract: High-quality information set abstraction remains a core challenge in solving large-scale imperfect-information extensive-form games (IIEFGs)-such as no-limit Texas Hold'em-where the finite nature of spatial resources hinders strategy solving over the full game. State-of-the-art AI methods rely on pre-trained discrete clustering for abstraction, yet their hard classification irreversibly loses critical information: specifically, the quantifiable subtle differences between information sets-vital for strategy solving-thereby compromising the quality of such solving. Inspired by the word embedding paradigm in natural language processing, this paper proposes the Embedding CFR algorithm, a novel approach for solving strategies in IIEFGs within an embedding space. The algorithm pre-trains and embeds features of isolated information sets into an interconnected low-dimensional continuous space, where the resulting vectors more precisely capture both the distinctions and connections between information sets. Embedding CFR presents a strategy-solving process driven by regret accumulation and strategy updates within this embedding space, with accompanying theoretical analysis verifying its capacity to reduce cumulative regret. Experiments on poker show that with the same spatial overhead, Embedding CFR achieves significantly faster exploitability convergence compared to cluster-based abstraction algorithms, confirming its effectiveness. Furthermore, to our knowledge, it is the first algorithm in poker AI that pre-trains information set abstractions through low-dimensional embedding for strategy solving.

</details>


### [176] [KrwEmd: Revising the Imperfect-Recall Abstraction from Forgetting Everything](https://arxiv.org/abs/2511.12089)
*Yanchang Fu,Qiyue Yin,Shengda Liu,Pei Xu,Kaiqi Huang*

Main category: cs.AI

TL;DR: KrwEmd算法通过k-recall winrate特征和earth mover's distance聚类来解决德州扑克等游戏中手牌抽象过度的问题，显著提升AI性能


<details>
  <summary>Details</summary>
Motivation: 解决大规模不完全信息游戏中手牌抽象过度的问题，特别是极端不完美回忆抽象完全丢弃历史信息导致的AI性能下降

Method: 引入k-recall winrate特征来区分信号观察信息集，利用未来和关键的历史游戏信息；开发KrwEmd算法，使用earth mover's distance测量特征差异来聚类信号观察信息集

Result: 实验结果表明KrwEmd相比现有算法显著提高了AI游戏性能

Conclusion: KrwEmd是首个实用的解决手牌抽象过度问题的算法，通过结合历史和未来信息有效提升AI在德州扑克等游戏中的表现

Abstract: Excessive abstraction is a critical challenge in hand abstraction-a task specific to games like Texas hold'em-when solving large-scale imperfect-information games, as it impairs AI performance. This issue arises from extreme implementations of imperfect-recall abstraction, which entirely discard historical information. This paper presents KrwEmd, the first practical algorithm designed to address this problem. We first introduce the k-recall winrate feature, which not only qualitatively distinguishes signal observation infosets by leveraging both future and, crucially, historical game information, but also quantitatively captures their similarity. We then develop the KrwEmd algorithm, which clusters signal observation infosets using earth mover's distance to measure discrepancies between their features. Experimental results demonstrate that KrwEmd significantly improves AI gameplay performance compared to existing algorithms.

</details>


### [177] [MetaGDPO: Alleviating Catastrophic Forgetting with Metacognitive Knowledge through Group Direct Preference Optimization](https://arxiv.org/abs/2511.12113)
*Lanxue Zhang,Yuqiang Xie,Fang Fang,Fanglong Dong,Rui Liu,Yanan Cao*

Main category: cs.AI

TL;DR: 提出了一种缓解小型语言模型灾难性遗忘的综合解决方案，包括构建包含元认知知识的数据集和引入GDPO训练方法，显著提升了小型模型的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据集和微调方法在8B以下的小型模型中容易导致灾难性遗忘，主要问题是训练数据与模型固有能力的关联性不足，以及传统训练目标难以约束固有知识的保留。

Method: 构建了包含5K实例的多任务推理数据集，标注元认知知识并基于任务知识和模型技能筛选数据；提出GDPO（组方向偏好优化）方法，通过参考模型隐式约束优化路径，有效限制参数漂移。

Result: 大量实验表明，该方法显著缓解了灾难性遗忘问题，提升了小型模型的推理性能。

Conclusion: 该综合解决方案从数据和训练方法两方面有效解决了小型模型的知识蒸馏中的灾难性遗忘问题，为资源受限场景下的模型压缩提供了有效途径。

Abstract: Large Language Models demonstrate strong reasoning capabilities, which can be effectively compressed into smaller models. However, existing datasets and fine-tuning approaches still face challenges that lead to catastrophic forgetting, particularly for models smaller than 8B. First, most datasets typically ignore the relationship between training data knowledge and the model's inherent abilities, making it difficult to preserve prior knowledge. Second, conventional training objectives often fail to constrain inherent knowledge preservation, which can result in forgetting of previously learned skills. To address these issues, we propose a comprehensive solution that alleviates catastrophic forgetting from both the data and fine-tuning approach perspectives. On the data side, we construct a dataset of 5K instances that covers multiple reasoning tasks and incorporates metacognitive knowledge, making it more tolerant and effective for distillation into smaller models. We annotate the metacognitive knowledge required to solve each question and filter the data based on task knowledge and the model's inherent skills. On the training side, we introduce GDPO (Group Direction Preference Optimization), which is better suited for resource-limited scenarios and can efficiently approximate the performance of GRPO. Guided by the large model and by implicitly constraining the optimization path through a reference model, GDPO enables more effective knowledge transfer from the large model and constrains excessive parameter drift. Extensive experiments demonstrate that our approach significantly alleviates catastrophic forgetting and improves reasoning performance on smaller models.

</details>


### [178] [RTMol: Rethinking Molecule-text Alignment in a Round-trip View](https://arxiv.org/abs/2511.12135)
*Letian Chen,Runhan Shi,Gufeng Yu,Yang Yang*

Main category: cs.AI

TL;DR: 提出了RTMol框架，通过自监督的往返学习统一分子标注和文本到SMILES生成，解决了现有方法在化学准确性、数据质量和双向一致性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现有方法将分子标注和文本到分子设计视为独立任务，存在三个关键问题：传统指标偏重语言流畅性而非化学准确性；训练数据包含化学模糊描述；独立优化导致双向不一致。

Method: RTMol框架通过自监督往返学习统一分子标注和文本到SMILES生成，引入新颖的往返评估指标，支持无需配对分子-文本语料库的无监督训练。

Result: 实验表明RTMol在各种LLM上双向对齐性能提升高达47%，为联合分子-文本理解和生成建立了有效范式。

Conclusion: RTMol框架有效解决了分子序列表示与文本描述对齐的关键问题，在药物发现、材料设计等应用中具有重要价值。

Abstract: Aligning molecular sequence representations (e.g., SMILES notations) with textual descriptions is critical for applications spanning drug discovery, materials design, and automated chemical literature analysis. Existing methodologies typically treat molecular captioning (molecule-to-text) and text-based molecular design (text-to-molecule) as separate tasks, relying on supervised fine-tuning or contrastive learning pipelines. These approaches face three key limitations: (i) conventional metrics like BLEU prioritize linguistic fluency over chemical accuracy, (ii) training datasets frequently contain chemically ambiguous narratives with incomplete specifications, and (iii) independent optimization of generation directions leads to bidirectional inconsistency. To address these issues, we propose RTMol, a bidirectional alignment framework that unifies molecular captioning and text-to-SMILES generation through self-supervised round-trip learning. The framework introduces novel round-trip evaluation metrics and enables unsupervised training for molecular captioning without requiring paired molecule-text corpora. Experiments demonstrate that RTMol enhances bidirectional alignment performance by up to 47% across various LLMs, establishing an effective paradigm for joint molecule-text understanding and generation.

</details>


### [179] [Incremental Maintenance of DatalogMTL Materialisations](https://arxiv.org/abs/2511.12169)
*Kaiyue Zhao,Dingqi Chen,Shaoyu Wang,Pan Hu*

Main category: cs.AI

TL;DR: 提出了DRedMTL算法，一种用于DatalogMTL的增量推理方法，能够高效处理动态数据更新，相比重新物化方法性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 现有的DatalogMTL推理方法虽然具备正确性和完备性，但缺乏对动态更新的高效支持，而现实应用需要频繁的数据更新处理能力。

Method: 基于经典DRed算法，设计了专门操作符来处理DatalogMTL物化的周期性区间表示，实现增量更新。

Result: 在多个公开数据集上的实验表明，DRedMTL通常显著优于重新物化方法，有时性能提升达到数量级。

Conclusion: DRedMTL算法成功解决了DatalogMTL的增量推理问题，为处理动态更新的时序数据提供了高效解决方案。

Abstract: DatalogMTL extends the classical Datalog language with metric temporal logic (MTL), enabling expressive reasoning over temporal data. While existing reasoning approaches, such as materialisation based and automata based methods, offer soundness and completeness, they lack support for handling efficient dynamic updates, a crucial requirement for real-world applications that involve frequent data updates. In this work, we propose DRedMTL, an incremental reasoning algorithm for DatalogMTL with bounded intervals. Our algorithm builds upon the classical DRed algorithm, which incrementally updates the materialisation of a Datalog program. Unlike a Datalog materialisation which is in essence a finite set of facts, a DatalogMTL materialisation has to be represented as a finite set of facts plus periodic intervals indicating how the full materialisation can be constructed through unfolding. To cope with this, our algorithm is equipped with specifically designed operators to efficiently handle such periodic representations of DatalogMTL materialisations. We have implemented this approach and tested it on several publicly available datasets. Experimental results show that DRedMTL often significantly outperforms rematerialisation, sometimes by orders of magnitude.

</details>


### [180] [Debate over Mixed-knowledge: A Robust Multi-Agent Framework for Incomplete Knowledge Graph Question Answering](https://arxiv.org/abs/2511.12208)
*Jilong Liu,Pengyang Shao,Wei Qin,Fei Liu,Yonghui Yang,Richang Hong*

Main category: cs.AI

TL;DR: 提出了DoM框架，通过多智能体辩论机制动态融合结构化和非结构化知识来解决不完整知识图谱问答问题，并构建了更真实的不完整知识图谱数据集。


<details>
  <summary>Details</summary>
Motivation: 现实世界知识图谱往往不完整，现有方法无法自适应地融合多种知识源来弥补知识缺口，且现有数据集通过随机删除三元组模拟不完整性，无法反映真实世界知识不完整的特性。

Method: 基于多智能体辩论范式，DoM将输入问题分解为子问题，通过KG和RAG双智能体分别检索证据，使用法官智能体评估和聚合中间答案，实现知识互补和增强对KG不完整性的鲁棒性。

Result: 通过广泛实验证明，DoM在性能上持续优于现有最先进基线方法。

Conclusion: DoM框架能够有效解决不完整知识图谱问答问题，通过多智能体辩论机制实现知识源的动态融合，提出的新数据集更真实地反映了现实世界知识不完整性。

Abstract: Knowledge Graph Question Answering (KGQA) aims to improve factual accuracy by leveraging structured knowledge. However, real-world Knowledge Graphs (KGs) are often incomplete, leading to the problem of Incomplete KGQA (IKGQA). A common solution is to incorporate external data to fill knowledge gaps, but existing methods lack the capacity to adaptively and contextually fuse multiple sources, failing to fully exploit their complementary strengths. To this end, we propose Debate over Mixed-knowledge (DoM), a novel framework that enables dynamic integration of structured and unstructured knowledge for IKGQA. Built upon the Multi-Agent Debate paradigm, DoM assigns specialized agents to perform inference over knowledge graphs and external texts separately, and coordinates their outputs through iterative interaction. It decomposes the input question into sub-questions, retrieves evidence via dual agents (KG and Retrieval-Augmented Generation, RAG), and employs a judge agent to evaluate and aggregate intermediate answers. This collaboration exploits knowledge complementarity and enhances robustness to KG incompleteness. In addition, existing IKGQA datasets simulate incompleteness by randomly removing triples, failing to capture the irregular and unpredictable nature of real-world knowledge incompleteness. To address this, we introduce a new dataset, Incomplete Knowledge Graph WebQuestions, constructed by leveraging real-world knowledge updates. These updates reflect knowledge beyond the static scope of KGs, yielding a more realistic and challenging benchmark. Through extensive experiments, we show that DoM consistently outperforms state-of-the-art baselines.

</details>


### [181] [ViTE: Virtual Graph Trajectory Expert Router for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2511.12214)
*Ruochen Li,Zhanxing Zhu,Tanqiu Qiao,Hubert P. H. Shum*

Main category: cs.AI

TL;DR: ViTE框架通过虚拟图和专家路由器解决行人轨迹预测中高阶交互建模的深度与效率权衡问题，在多个基准测试中达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在行人轨迹预测中存在基本权衡：浅层GNN可能导致感受野不足，深层GNN则计算成本过高。需要自适应建模显式一跳交互和隐式高阶依赖。

Method: 提出ViTE框架，包含虚拟图模块（引入动态虚拟节点建模长距离高阶交互）和专家路由器模块（基于社交上下文自适应选择交互专家）。

Result: 在ETH/UCY、NBA和SDD三个基准测试中，ViTE方法持续达到最先进的性能表现。

Conclusion: ViTE通过虚拟图和专家路由器的组合，实现了灵活可扩展的交互模式推理，验证了其有效性和实际效率。

Abstract: Pedestrian trajectory prediction is critical for ensuring safety in autonomous driving, surveillance systems, and urban planning applications. While early approaches primarily focus on one-hop pairwise relationships, recent studies attempt to capture high-order interactions by stacking multiple Graph Neural Network (GNN) layers. However, these approaches face a fundamental trade-off: insufficient layers may lead to under-reaching problems that limit the model's receptive field, while excessive depth can result in prohibitive computational costs. We argue that an effective model should be capable of adaptively modeling both explicit one-hop interactions and implicit high-order dependencies, rather than relying solely on architectural depth. To this end, we propose ViTE (Virtual graph Trajectory Expert router), a novel framework for pedestrian trajectory prediction. ViTE consists of two key modules: a Virtual Graph that introduces dynamic virtual nodes to model long-range and high-order interactions without deep GNN stacks, and an Expert Router that adaptively selects interaction experts based on social context using a Mixture-of-Experts design. This combination enables flexible and scalable reasoning across varying interaction patterns. Experiments on three benchmarks (ETH/UCY, NBA, and SDD) demonstrate that our method consistently achieves state-of-the-art performance, validating both its effectiveness and practical efficiency.

</details>


### [182] [Beyond World Models: Rethinking Understanding in AI Models](https://arxiv.org/abs/2511.12239)
*Tarun Gupta,Danish Pruthi*

Main category: cs.AI

TL;DR: 本文通过哲学案例研究批判性检验世界模型框架是否充分表征人类级别的理解能力


<details>
  <summary>Details</summary>
Motivation: 研究人类是否拥有心理世界模型，以及AI模型中是否存在类似表征，这可能表明模型以类似人类的方式"理解"世界

Method: 使用科学哲学文献中的案例研究，重点关注世界模型能力与人类理解之间区别最明显的哲学分析

Result: 虽然这些案例代表特定的理解观点而非普遍定义，但它们有助于探索世界模型的局限性

Conclusion: 世界模型框架在表征人类级别理解方面存在局限性，需要更深入探讨其与真正人类理解的差异

Abstract: World models have garnered substantial interest in the AI community. These are internal representations that simulate aspects of the external world, track entities and states, capture causal relationships, and enable prediction of consequences. This contrasts with representations based solely on statistical correlations. A key motivation behind this research direction is that humans possess such mental world models, and finding evidence of similar representations in AI models might indicate that these models "understand" the world in a human-like way. In this paper, we use case studies from the philosophy of science literature to critically examine whether the world model framework adequately characterizes human-level understanding. We focus on specific philosophical analyses where the distinction between world model capabilities and human understanding is most pronounced. While these represent particular views of understanding rather than universal definitions, they help us explore the limits of world models.

</details>


### [183] [AURA: Development and Validation of an Augmented Unplanned Removal Alert System using Synthetic ICU Videos](https://arxiv.org/abs/2511.12241)
*Junhyuk Seo,Hyeyoon Moon,Kyu-Hwan Jung,Namkee Oh,Taerim Kim*

Main category: cs.AI

TL;DR: AURA是一个基于视觉的意外拔管风险检测系统，完全在合成ICU视频数据集上开发，通过姿态估计识别碰撞和躁动两种高风险运动模式。


<details>
  <summary>Details</summary>
Motivation: ICU中意外拔管是严重的安全问题，但由于伦理和隐私限制难以获取标注视频数据，需要开发隐私保护的实时检测方法。

Method: 利用文本到视频扩散生成合成ICU场景，通过姿态估计检测手部进入气道管附近区域（碰撞）和追踪解剖关键点速度（躁动）两种风险模式。

Result: 专家确认合成数据真实性，碰撞检测准确率高，躁动识别性能中等，展示了在重症监护环境中部署的潜力。

Conclusion: 这项工作展示了开发隐私保护、可复现的患者安全监测系统的新途径，为ICU环境提供了可行的解决方案。

Abstract: Unplanned extubation (UE) remains a critical patient safety concern in intensive care units (ICUs), often leading to severe complications or death. Real-time UE detection has been limited, largely due to the ethical and privacy challenges of obtaining annotated ICU video data. We propose Augmented Unplanned Removal Alert (AURA), a vision-based risk detection system developed and validated entirely on a fully synthetic video dataset. By leveraging text-to-video diffusion, we generated diverse and clinically realistic ICU scenarios capturing a range of patient behaviors and care contexts. The system applies pose estimation to identify two high-risk movement patterns: collision, defined as hand entry into spatial zones near airway tubes, and agitation, quantified by the velocity of tracked anatomical keypoints. Expert assessments confirmed the realism of the synthetic data, and performance evaluations showed high accuracy for collision detection and moderate performance for agitation recognition. This work demonstrates a novel pathway for developing privacy-preserving, reproducible patient safety monitoring systems with potential for deployment in intensive care settings.

</details>


### [184] [Mobile-Agent-RAG: Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation](https://arxiv.org/abs/2511.12254)
*Yuxiang Zhou,Jichang Li,Yanhao Zhang,Haonan Lu,Guanbin Li*

Main category: cs.AI

TL;DR: 提出Mobile-Agent-RAG框架，通过双层次检索增强解决移动代理在真实世界长时跨应用任务中的战略幻觉和操作错误问题，显著提升任务完成率和步骤效率。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的移动代理在真实世界、长时程、跨应用任务中成功率不足，主要原因是过度依赖MLLM中的静态内部知识，导致战略规划中的幻觉和UI操作中的执行错误。

Method: 提出分层多代理框架Mobile-Agent-RAG，包含Manager-RAG（规划阶段检索人类验证的全面任务计划）和Operator-RAG（执行阶段检索精确的低级操作指导），并构建两个专门的检索知识库。

Result: 在Mobile-Eval-RAG基准测试中，Mobile-Agent-RAG显著优于现有基线，任务完成率提高11.0%，步骤效率提升10.2%。

Conclusion: Mobile-Agent-RAG为上下文感知、可靠的多代理移动自动化建立了稳健范式，通过双层次检索增强有效解决了规划与执行阶段的不同知识需求。

Abstract: Mobile agents show immense potential, yet current state-of-the-art (SoTA) agents exhibit inadequate success rates on real-world, long-horizon, cross-application tasks. We attribute this bottleneck to the agents' excessive reliance on static, internal knowledge within MLLMs, which leads to two critical failure points: 1) strategic hallucinations in high-level planning and 2) operational errors during low-level execution on user interfaces (UI). The core insight of this paper is that high-level planning and low-level UI operations require fundamentally distinct types of knowledge. Planning demands high-level, strategy-oriented experiences, whereas operations necessitate low-level, precise instructions closely tied to specific app UIs. Motivated by these insights, we propose Mobile-Agent-RAG, a novel hierarchical multi-agent framework that innovatively integrates dual-level retrieval augmentation. At the planning stage, we introduce Manager-RAG to reduce strategic hallucinations by retrieving human-validated comprehensive task plans that provide high-level guidance. At the execution stage, we develop Operator-RAG to improve execution accuracy by retrieving the most precise low-level guidance for accurate atomic actions, aligned with the current app and subtask. To accurately deliver these knowledge types, we construct two specialized retrieval-oriented knowledge bases. Furthermore, we introduce Mobile-Eval-RAG, a challenging benchmark for evaluating such agents on realistic multi-app, long-horizon tasks. Extensive experiments demonstrate that Mobile-Agent-RAG significantly outperforms SoTA baselines, improving task completion rate by 11.0% and step efficiency by 10.2%, establishing a robust paradigm for context-aware, reliable multi-agent mobile automation.

</details>


### [185] [MoralReason: Generalizable Moral Decision Alignment For LLM Agents Using Reasoning-Level Reinforcement Learning](https://arxiv.org/abs/2511.12271)
*Zhiyu An,Wan Du*

Main category: cs.AI

TL;DR: 该论文提出了一种解决LLM在超出训练分布场景中的道德对齐问题的方法，通过构建Moral-Reason-QA数据集和Group Relative Policy Optimization学习框架，成功让LLM智能体学习并应用特定道德框架到新情境中。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型日益影响人类道德决策，但现有方法主要关注评估而非主动引导其道德决策。需要解决LLM在超出训练分布场景中的道德推理一致性问题。

Method: 构建Moral-Reason-QA数据集（包含680个人工标注的高模糊度道德场景及框架特定推理轨迹），采用Group Relative Policy Optimization结合复合奖励函数，同时优化决策对齐和框架特定推理过程。

Result: 在未见道德场景上实现成功泛化，功利主义框架的softmax归一化对齐分数提升+0.757，义务论框架提升+0.450。实验还揭示了训练挑战和有前景的研究方向。

Conclusion: LLM智能体可以系统性地训练以内在化并应用特定道德框架到新情境中，为AI安全提供了关键基础，特别是在语言模型更深入融入人类决策过程的背景下。

Abstract: Large language models are increasingly influencing human moral decisions, yet current approaches focus primarily on evaluating rather than actively steering their moral decisions. We formulate this as an out-of-distribution moral alignment problem, where LLM agents must learn to apply consistent moral reasoning frameworks to scenarios beyond their training distribution. We introduce Moral-Reason-QA, a novel dataset extending 680 human-annotated, high-ambiguity moral scenarios with framework-specific reasoning traces across utilitarian, deontological, and virtue ethics, enabling systematic evaluation of moral generalization in realistic decision contexts. Our learning approach employs Group Relative Policy Optimization with composite rewards that simultaneously optimize decision alignment and framework-specific reasoning processes to facilitate learning of the underlying moral frameworks. Experimental results demonstrate successful generalization to unseen moral scenarios, with softmax-normalized alignment scores improving by +0.757 for utilitarian and +0.450 for deontological frameworks when tested on out-of-distribution evaluation sets. The experiments also reveal training challenges and promising directions that inform future research. These findings establish that LLM agents can be systematically trained to internalize and apply specific moral frameworks to novel situations, providing a critical foundation for AI safety as language models become more integrated into human decision-making processes.

</details>


### [186] [UpBench: A Dynamically Evolving Real-World Labor-Market Agentic Benchmark Framework Built for Human-Centric AI](https://arxiv.org/abs/2511.12306)
*Darvin Yi,Teng Liu,Mattie Terzolo,Lance Hasson,Ayan Sinh,Pablo Mendes,Andrew Rabinovich*

Main category: cs.AI

TL;DR: UpBench是一个基于真实Upwork工作任务的动态基准测试，用于评估LLM代理在真实工作环境中的能力、适应性和人机协作能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试大多是静态、合成或领域受限的，无法充分评估AI代理在动态、经济意义环境中的表现，需要基于真实工作场景的评估框架。

Method: 从Upwork劳动力市场提取真实工作任务，由专业自由职业者制定详细可验证的验收标准，采用基于评分标准的评估框架对AI提交内容进行细粒度评估。

Result: 提供了超越二元通过/失败指标的细粒度分析能力，能够识别模型在指令遵循、专业标准等方面的具体优势和弱点。

Conclusion: UpBench为在真实劳动力市场环境中评估代理系统提供了可扩展、以人为本的基础，支持AI通过合作而非替代来增强人类能力的研究方向。

Abstract: As large language model (LLM) agents increasingly undertake digital work, reliable frameworks are needed to evaluate their real-world competence, adaptability, and capacity for human collaboration. Existing benchmarks remain largely static, synthetic, or domain-limited, providing limited insight into how agents perform in dynamic, economically meaningful environments. We introduce UpBench, a dynamically evolving benchmark grounded in real jobs drawn from the global Upwork labor marketplace. Each task corresponds to a verified client transaction, anchoring evaluation in genuine work activity and financial outcomes. UpBench employs a rubric-based evaluation framework, in which expert freelancers decompose each job into detailed, verifiable acceptance criteria and assess AI submissions with per-criterion feedback. This structure enables fine-grained analysis of model strengths, weaknesses, and instruction-following fidelity beyond binary pass/fail metrics. Human expertise is integrated throughout the data pipeline (from job curation and rubric construction to evaluation) ensuring fidelity to real professional standards and supporting research on human-AI collaboration. By regularly refreshing tasks to reflect the evolving nature of online work, UpBench provides a scalable, human-centered foundation for evaluating agentic systems in authentic labor-market contexts, offering a path toward a collaborative framework, where AI amplifies human capability through partnership rather than replacement.

</details>


### [187] [Reward and Guidance through Rubrics: Promoting Exploration to Improve Multi-Domain Reasoning](https://arxiv.org/abs/2511.12344)
*Baolong Bi,Shenghua Liu,Yiwei Wang,Siqian Tong,Lingrui Mei,Yuyao Ge,Yilong Xu,Jiafeng Guo,Xueqi Cheng*

Main category: cs.AI

TL;DR: 提出了RGR-GRPO框架，通过评分标准提供细粒度奖励和离线指导，在多领域推理任务中显著提升大语言模型的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法主要局限于单一领域和可验证奖励，且纯在线RL框架限制了探索空间，从而限制了推理性能的提升。

Method: 使用评分标准同时提供细粒度奖励信号和离线指导，提出RGR-GRPO框架，在GRPO训练期间让LLM接收密集信息奖励并探索更大的解空间。

Result: 在14个多领域基准测试中，RGR-GRPO始终优于仅依赖替代奖励方案或离线指导的RL方法，在数学、物理、化学和一般推理任务上分别平均提升7.0%、5.4%、8.4%和6.6%。

Conclusion: RGR-GRPO在离策略训练期间保持稳定的熵波动，实现卓越的pass@k性能，反映了持续探索和有效突破现有性能瓶颈的能力。

Abstract: Recent advances in reinforcement learning (RL) have significantly improved the complex reasoning capabilities of large language models (LLMs). Despite these successes, existing methods mainly focus on single-domain RL (e.g., mathematics) with verifiable rewards (RLVR), and their reliance on purely online RL frameworks restricts the exploration space, thereby limiting reasoning performance. In this paper, we address these limitations by leveraging rubrics to provide both fine-grained reward signals and offline guidance. We propose $\textbf{RGR-GRPO}$ (Reward and Guidance through Rubrics), a rubric-driven RL framework for multi-domain reasoning. RGR-GRPO enables LLMs to receive dense and informative rewards while exploring a larger solution space during GRPO training. Extensive experiments across 14 benchmarks spanning multiple domains demonstrate that RGR-GRPO consistently outperforms RL methods that rely solely on alternative reward schemes or offline guidance. Compared with verifiable online RL baseline, RGR-GRPO achieves average improvements of +7.0%, +5.4%, +8.4%, and +6.6% on mathematics, physics, chemistry, and general reasoning tasks, respectively. Notably, RGR-GRPO maintains stable entropy fluctuations during off-policy training and achieves superior pass@k performance, reflecting sustained exploration and effective breakthrough beyond existing performance bottlenecks.

</details>


### [188] [More Than Irrational: Modeling Belief-Biased Agents](https://arxiv.org/abs/2511.12359)
*Yifan Zhu,Sammie Katt,Samuel Kaski*

Main category: cs.AI

TL;DR: 本文提出了计算理性用户模型，用于建模认知受限但信念有偏的理性用户行为，重点解决了从被动观察中推断用户认知边界和信念状态的问题。


<details>
  <summary>Details</summary>
Motivation: 预测和理解用户次优行为是AI发展的关键挑战，这些行为往往源于认知边界和信念偏差而非非理性。需要建立能够解释这些认知受限理性行为的模型。

Method: 提出基于嵌套粒子滤波的在线推断方法，同时跟踪用户的潜在信念状态并估计未知认知边界，以记忆衰减作为认知边界的示例进行验证。

Result: 模拟验证显示：(1)计算理性模型能生成与不同记忆容量水平相对应的直观合理行为；(2)推断方法能准确高效地从有限观察中恢复真实认知边界。

Conclusion: 该方法为开发自适应AI助手提供了理论基础，使AI能够考虑用户的记忆限制提供适应性协助。

Abstract: Despite the explosive growth of AI and the technologies built upon it, predicting and inferring the sub-optimal behavior of users or human collaborators remains a critical challenge. In many cases, such behaviors are not a result of irrationality, but rather a rational decision made given inherent cognitive bounds and biased beliefs about the world. In this paper, we formally introduce a class of computational-rational (CR) user models for cognitively-bounded agents acting optimally under biased beliefs. The key novelty lies in explicitly modeling how a bounded memory process leads to a dynamically inconsistent and biased belief state and, consequently, sub-optimal sequential decision-making. We address the challenge of identifying the latent user-specific bound and inferring biased belief states from passive observations on the fly. We argue that for our formalized CR model family with an explicit and parameterized cognitive process, this challenge is tractable. To support our claim, we propose an efficient online inference method based on nested particle filtering that simultaneously tracks the user's latent belief state and estimates the unknown cognitive bound from a stream of observed actions. We validate our approach in a representative navigation task using memory decay as an example of a cognitive bound. With simulations, we show that (1) our CR model generates intuitively plausible behaviors corresponding to different levels of memory capacity, and (2) our inference method accurately and efficiently recovers the ground-truth cognitive bounds from limited observations ($\le 100$ steps). We further demonstrate how this approach provides a principled foundation for developing adaptive AI assistants, enabling adaptive assistance that accounts for the user's memory limitations.

</details>


### [189] [Learning to Trust: Bayesian Adaptation to Varying Suggester Reliability in Sequential Decision Making](https://arxiv.org/abs/2511.12378)
*Dylan M. Asmar,Mykel J. Kochenderfer*

Main category: cs.AI

TL;DR: 提出了一个动态学习建议者可靠性的框架，在部分可观测环境中通过贝叶斯推理自适应地调整对建议的依赖，并引入战略性的"询问"动作来平衡信息获取与成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设建议者质量参数是静态且已知的，限制了实际部署。需要能够动态学习和适应变化建议者可靠性的框架。

Method: 1) 将建议者质量直接集成到智能体的信念表示中，通过贝叶斯推理推断建议者类型；2) 引入明确的"询问"动作，允许智能体在关键时刻战略性地请求建议。

Result: 实验评估显示该框架在不同建议者质量下表现稳健，能够适应变化的可靠性，并战略性地管理建议请求。

Conclusion: 这项工作通过处理不确定环境中的建议不确定性，为自适应人机协作提供了基础。

Abstract: Autonomous agents operating in sequential decision-making tasks under uncertainty can benefit from external action suggestions, which provide valuable guidance but inherently vary in reliability. Existing methods for incorporating such advice typically assume static and known suggester quality parameters, limiting practical deployment. We introduce a framework that dynamically learns and adapts to varying suggester reliability in partially observable environments. First, we integrate suggester quality directly into the agent's belief representation, enabling agents to infer and adjust their reliance on suggestions through Bayesian inference over suggester types. Second, we introduce an explicit ``ask'' action allowing agents to strategically request suggestions at critical moments, balancing informational gains against acquisition costs. Experimental evaluation demonstrates robust performance across varying suggester qualities, adaptation to changing reliability, and strategic management of suggestion requests. This work provides a foundation for adaptive human-agent collaboration by addressing suggestion uncertainty in uncertain environments.

</details>


### [190] [Dropouts in Confidence: Moral Uncertainty in Human-LLM Alignment](https://arxiv.org/abs/2511.13290)
*Jea Kwon,Luiz Felipe Vecchietti,Sungwon Park,Meeyoung Cha*

Main category: cs.AI

TL;DR: 该研究探讨了AI模型在道德困境中的不确定性，发现在电车问题中模型间的不确定性差异大于道德维度间的差异，通过引入推理时的随机性可以增加总熵并改善人类-LLM道德对齐。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统越来越多地参与道德决策，理解其道德推理中的不确定性对于构建可靠的AI系统至关重要，但目前机器在道德困境中的不确定性研究不足。

Method: 分析32个开源模型在9个道德维度上的反应，使用二元熵量化不确定性，通过推理时引入dropout机制增加随机性，测量总熵、条件熵和互信息的变化。

Result: 模型间置信度方差大于道德维度间方差；dropout机制显著增加总熵（主要通过互信息增加），条件熵基本不变；该机制显著改善了人类-LLM道德对齐，互信息与对齐分数变化相关。

Conclusion: 通过有意调节不确定性和降低LLMs在道德复杂场景中的置信度，可以更好地对齐模型生成决策与人类偏好。

Abstract: Humans display significant uncertainty when confronted with moral dilemmas, yet the extent of such uncertainty in machines and AI agents remains underexplored. Recent studies have confirmed the overly confident tendencies of machine-generated responses, particularly in large language models (LLMs). As these systems are increasingly embedded in ethical decision-making scenarios, it is important to understand their moral reasoning and the inherent uncertainties in building reliable AI systems. This work examines how uncertainty influences moral decisions in the classical trolley problem, analyzing responses from 32 open-source models and 9 distinct moral dimensions. We first find that variance in model confidence is greater across models than within moral dimensions, suggesting that moral uncertainty is predominantly shaped by model architecture and training method. To quantify uncertainty, we measure binary entropy as a linear combination of total entropy, conditional entropy, and mutual information. To examine its effects, we introduce stochasticity into models via "dropout" at inference time. Our findings show that our mechanism increases total entropy, mainly through a rise in mutual information, while conditional entropy remains largely unchanged. Moreover, this mechanism significantly improves human-LLM moral alignment, with correlations in mutual information and alignment score shifts. Our results highlight the potential to better align model-generated decisions and human preferences by deliberately modulating uncertainty and reducing LLMs' confidence in morally complex scenarios.

</details>


### [191] [Multi-agent Self-triage System with Medical Flowcharts](https://arxiv.org/abs/2511.12439)
*Yujia Liu,Sophia Yu,Hongyue Jin,Jessica Wen,Alexander Qian,Terrence Lee,Mattheus Ramsis,Gi Won Choi,Lianhui Qin,Xin Liu,Edward J. Wang*

Main category: cs.AI

TL;DR: 开发了一个基于临床验证流程图的对话式自我分诊系统，通过多智能体框架实现95.29%的流程图检索准确率和99.10%的导航准确率，结合自由文本交互的灵活性和标准化临床协议的严谨性。


<details>
  <summary>Details</summary>
Motivation: 在线健康资源和大型语言模型在医疗决策中准确性低、透明度差且易受未经验证信息影响，需要可靠的患者决策支持系统。

Method: 使用美国医学会100个临床验证流程图构建多智能体框架，包括检索代理、决策代理和聊天代理，分别负责识别相关流程图、解释患者响应和提供个性化建议。

Result: 在模拟对话数据集上测试，流程图检索top-3准确率达95.29%，流程图导航准确率达99.10%，适应不同对话风格和条件。

Conclusion: 该方法展示了透明、准确且可推广的AI辅助自我分诊的可行性，有望支持知情患者决策并改善医疗资源利用。

Abstract: Online health resources and large language models (LLMs) are increasingly used as a first point of contact for medical decision-making, yet their reliability in healthcare remains limited by low accuracy, lack of transparency, and susceptibility to unverified information. We introduce a proof-of-concept conversational self-triage system that guides LLMs with 100 clinically validated flowcharts from the American Medical Association, providing a structured and auditable framework for patient decision support. The system leverages a multi-agent framework consisting of a retrieval agent, a decision agent, and a chat agent to identify the most relevant flowchart, interpret patient responses, and deliver personalized, patient-friendly recommendations, respectively. Performance was evaluated at scale using synthetic datasets of simulated conversations. The system achieved 95.29% top-3 accuracy in flowchart retrieval (N=2,000) and 99.10% accuracy in flowchart navigation across varied conversational styles and conditions (N=37,200). By combining the flexibility of free-text interaction with the rigor of standardized clinical protocols, this approach demonstrates the feasibility of transparent, accurate, and generalizable AI-assisted self-triage, with potential to support informed patient decision-making while improving healthcare resource utilization.

</details>


### [192] [ARCHE: A Novel Task to Evaluate LLMs on Latent Reasoning Chain Extraction](https://arxiv.org/abs/2511.12485)
*Pengze Li,Jiaqi Liu,Junchi Yu,Lihao Liu,Mingyu Ding,Wanli Ouyang,Shixiang Tang,Xi Chen*

Main category: cs.AI

TL;DR: 提出了ARCHE任务和ARCHE Bench基准，用于评估LLMs从科学文献中提取结构化推理链的能力，发现现有模型在推理准确性和内容完整性之间存在权衡。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs虽然能产生类似推理的内容，但这些输出通常是非结构化和非正式的，难以判断模型是否真正理解科学推理的基本范式。

Method: 引入Latent Reasoning Chain Extraction (ARCHE)任务，要求模型将复杂推理分解为标准推理范式组成的Reasoning Logic Tree (RLT)，包含演绎、归纳和溯因三种推理模式。

Result: 在10个领先LLMs上的评估显示，模型在推理边准确性和实体覆盖率之间存在权衡，没有模型能够提取完整且标准的推理链。

Conclusion: 当前推理模型的能力与科学论证所需的严谨性之间存在显著差距。

Abstract: Large language models (LLMs) are increasingly used in scientific domains. While they can produce reasoning-like content via methods such as chain-of-thought prompting, these outputs are typically unstructured and informal, obscuring whether models truly understand the fundamental reasoning paradigms that underpin scientific inference. To address this, we introduce a novel task named Latent Reasoning Chain Extraction (ARCHE), in which models must decompose complex reasoning arguments into combinations of standard reasoning paradigms in the form of a Reasoning Logic Tree (RLT). In RLT, all reasoning steps are explicitly categorized as one of three variants of Peirce's fundamental inference modes: deduction, induction, or abduction. To facilitate this task, we release ARCHE Bench, a new benchmark derived from 70 Nature Communications articles, including more than 1,900 references and 38,000 viewpoints. We propose two logic-aware evaluation metrics: Entity Coverage (EC) for content completeness and Reasoning Edge Accuracy (REA) for step-by-step logical validity. Evaluations on 10 leading LLMs on ARCHE Bench reveal that models exhibit a trade-off between REA and EC, and none are yet able to extract a complete and standard reasoning chain. These findings highlight a substantial gap between the abilities of current reasoning models and the rigor required for scientific argumentation.

</details>


### [193] [LOBERT: Generative AI Foundation Model for Limit Order Book Messages](https://arxiv.org/abs/2511.12563)
*Eljas Linna,Kestutis Baltakys,Alexandros Iosifidis,Juho Kanniainen*

Main category: cs.AI

TL;DR: LOBERT是一个针对限价订单簿数据的通用编码器基础模型，通过将多维消息视为单个token并保留价格、数量和时间的连续表示，在预测中间价格变动和下一消息等任务中取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有LOB模型需要繁琐的数据表示，缺乏原始任务之外的适应性，因此需要开发一个适用于下游微调的通用基础模型。

Method: LOBERT基于BERT架构，采用新颖的tokenization方案，将完整的多维消息视为单个token，同时保留价格、数量和时间的连续表示。

Result: LOBERT在预测中间价格变动和下一消息等任务中取得领先性能，同时相比先前方法减少了所需的上下文长度。

Conclusion: LOBERT为LOB数据提供了一个有效的通用基础模型，在多个任务中表现出色且具有更好的适应性。

Abstract: Modeling the dynamics of financial Limit Order Books (LOB) at the message level is challenging due to irregular event timing, rapid regime shifts, and the reactions of high-frequency traders to visible order flow. Previous LOB models require cumbersome data representations and lack adaptability outside their original tasks, leading us to introduce LOBERT, a general-purpose encoder-only foundation model for LOB data suitable for downstream fine-tuning. LOBERT adapts the original BERT architecture for LOB data by using a novel tokenization scheme that treats complete multi-dimensional messages as single tokens while retaining continuous representations of price, volume, and time. With these methods, LOBERT achieves leading performance in tasks such as predicting mid-price movements and next messages, while reducing the required context length compared to previous methods.

</details>


### [194] [Enhancing Conversational Recommender Systems with Tree-Structured Knowledge and Pretrained Language Models](https://arxiv.org/abs/2511.12579)
*Yongwen Ren,Chao Wang,Peng Du,Chuan Qin,Dazhong Shen,Hui Xiong*

Main category: cs.AI

TL;DR: PCRS-TKA是一个基于提示的框架，通过检索增强生成将预训练语言模型与知识图谱集成，解决了现有方法在推理、知识过滤和协作偏好建模方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用PLM在图关系上的推理能力，不加区分地整合检索到的知识，且忽视了多轮对话中的协作偏好，需要改进这些方面以提升准确性和减少幻觉。

Method: 构建对话特定的知识树并序列化为文本，实现结构感知推理；选择性过滤上下文相关知识；使用专门监督信号显式建模协作偏好；通过语义对齐模块协调异构输入。

Result: 广泛的实验表明，PCRS-TKA在推荐和对话质量方面始终优于所有基线方法。

Conclusion: PCRS-TKA通过结构感知推理、知识过滤和协作偏好建模，有效提升了对话推荐系统的性能。

Abstract: Recent advances in pretrained language models (PLMs) have significantly improved conversational recommender systems (CRS), enabling more fluent and context-aware interactions. To further enhance accuracy and mitigate hallucination, many methods integrate PLMs with knowledge graphs (KGs), but face key challenges: failing to fully exploit PLM reasoning over graph relationships, indiscriminately incorporating retrieved knowledge without context filtering, and neglecting collaborative preferences in multi-turn dialogues. To this end, we propose PCRS-TKA, a prompt-based framework employing retrieval-augmented generation to integrate PLMs with KGs. PCRS-TKA constructs dialogue-specific knowledge trees from KGs and serializes them into texts, enabling structure-aware reasoning while capturing rich entity semantics. Our approach selectively filters context-relevant knowledge and explicitly models collaborative preferences using specialized supervision signals. A semantic alignment module harmonizes heterogeneous inputs, reducing noise and enhancing accuracy. Extensive experiments demonstrate that PCRS-TKA consistently outperforms all baselines in both recommendation and conversational quality.

</details>


### [195] [Dynamic Tree Databases in Automated Planning](https://arxiv.org/abs/2511.12677)
*Oliver Joergensen,Dominik Drexler,Jendrik Seipp*

Main category: cs.AI

TL;DR: 提出了一种动态树数据库变体，用于压缩命题和数值变量的状态集，在保持静态树数据库优良特性的同时解决了内存预分配问题。


<details>
  <summary>Details</summary>
Motivation: 在大型任务中扩展显式状态空间搜索的核心挑战是如何紧凑表示生成的状态集。静态树数据库虽然每个状态只需要常数空间，但需要大量内存预分配。

Method: 开发了一种动态变体的树数据库，用于压缩命题和数值变量的状态集，并证明了它保持了静态对应物的理想特性。

Result: 在经典和数值规划任务上的实证评估显示，压缩比达到几个数量级，通常运行时开销可忽略不计。

Conclusion: 动态树数据库在状态压缩方面表现出色，既保持了高压缩比，又解决了内存预分配问题，适用于基础和提升规划。

Abstract: A central challenge in scaling up explicit state-space search for large tasks is compactly representing the set of generated states. Tree databases, a data structure from model checking, require constant space per generated state in the best case, but they need a large preallocation of memory. We propose a novel dynamic variant of tree databases for compressing state sets over propositional and numeric variables and prove that it maintains the desirable properties of the static counterpart. Our empirical evaluation of state compression techniques for grounded and lifted planning on classical and numeric planning tasks reveals compression ratios of several orders of magnitude, often with negligible runtime overhead.

</details>


### [196] [Adaptively Coordinating with Novel Partners via Learned Latent Strategies](https://arxiv.org/abs/2511.12754)
*Benjamin Li,Shuyang Shi,Lucia Romero,Huao Li,Yaqi Xie,Woojun Kim,Stefanos Nikolaidis,Michael Lewis,Katia Sycara,Simon Stepputtis*

Main category: cs.AI

TL;DR: 提出了一个策略条件合作者框架，通过变分自编码器学习策略空间，聚类识别策略类型，并训练条件合作者来实时适应不同人类伙伴的策略。


<details>
  <summary>Details</summary>
Motivation: 在人类-智能体团队中，智能体需要实时适应人类伙伴的独特偏好和动态变化的策略，这在时间压力和复杂策略空间的任务中尤其具有挑战性。

Method: 使用变分自编码器编码策略学习潜在策略空间，通过聚类识别不同策略类型，训练条件合作者，并采用固定份额遗憾最小化算法进行在线适应。

Result: 在修改版的Overcooked协作烹饪环境中，该方法在与新人类和智能体队友配对时达到了最先进的性能。

Conclusion: 提出的策略条件合作者框架能够有效表示、分类和实时适应广泛的伙伴策略，在复杂协作任务中表现出色。

Abstract: Adaptation is the cornerstone of effective collaboration among heterogeneous team members. In human-agent teams, artificial agents need to adapt to their human partners in real time, as individuals often have unique preferences and policies that may change dynamically throughout interactions. This becomes particularly challenging in tasks with time pressure and complex strategic spaces, where identifying partner behaviors and selecting suitable responses is difficult. In this work, we introduce a strategy-conditioned cooperator framework that learns to represent, categorize, and adapt to a broad range of potential partner strategies in real-time. Our approach encodes strategies with a variational autoencoder to learn a latent strategy space from agent trajectory data, identifies distinct strategy types through clustering, and trains a cooperator agent conditioned on these clusters by generating partners of each strategy type. For online adaptation to novel partners, we leverage a fixed-share regret minimization algorithm that dynamically infers and adjusts the partner's strategy estimation during interaction. We evaluate our method in a modified version of the Overcooked domain, a complex collaborative cooking environment that requires effective coordination among two players with a diverse potential strategy space. Through these experiments and an online user study, we demonstrate that our proposed agent achieves state of the art performance compared to existing baselines when paired with novel human, and agent teammates.

</details>


### [197] [Optimal Foraging in Memory Retrieval: Evaluating Random Walks and Metropolis-Hastings Sampling in Modern Semantic Spaces](https://arxiv.org/abs/2511.12759)
*James Moore*

Main category: cs.AI

TL;DR: 现代高维嵌入空间中的随机游走能够产生与人类语义流畅性任务中观察到的优化觅食行为一致的结果，而更复杂的Metropolis-Hastings采样反而与人类行为不符。


<details>
  <summary>Details</summary>
Motivation: 研究现代高维嵌入空间是否能够提供足够的表示能力，使得算法能够匹配人类在语义流畅性任务中观察到的觅食行为模式。

Method: 使用最先进的嵌入表示和先前的语义流畅性数据，在嵌入空间上进行随机游走和Metropolis-Hastings采样，比较结果与人类行为的匹配程度。

Result: 随机游走在嵌入空间中产生的结果与优化觅食和边际价值定理一致，而Metropolis-Hastings采样未能产生与人类行为一致的结果。

Conclusion: 适当结构的嵌入表示即使使用简单采样也能产生接近最优的觅食动态，挑战了复杂采样机制必然导致更好认知模型的假设，支持Hills(2012)而非Abbott(2015)的观点。

Abstract: Human memory retrieval often resembles ecological foraging where animals search for food in a patchy environment. Optimal foraging means following the Marginal Value Theorem (MVT), in which individuals exploit a patch of semantically related concepts until it becomes less rewarding and then switch to a new cluster. While human behavioral data suggests foraging-like patterns in semantic fluency tasks, it remains unclear whether modern high-dimensional embedding spaces provide representations that allow algorithms to match observed human behavior. Using state-of-the-art embeddings and prior semantic fluency data, I find that random walks on these embedding spaces produce results consistent with optimal foraging and the MVT. Surprisingly, introducing Metropolis-Hastings sampling, an adaptive algorithm expected to model strategic acceptance and rejection of new clusters, does not produce results consistent with human behavior. These findings challenge the assumption that more complex sampling mechanisms inherently lead to better cognitive models of memory retrieval. Instead, they show that appropriately structured embeddings, even with simple sampling, can produce near-optimal foraging dynamics. This supports the perspective of Hills (2012) rather than Abbott (2015), demonstrating that modern embeddings can approximate human memory foraging without relying on complex acceptance criteria.

</details>


### [198] [Event-CausNet: Unlocking Causal Knowledge from Text with Large Language Models for Reliable Spatio-Temporal Forecasting](https://arxiv.org/abs/2511.12769)
*Luyao Niu,Zepu Wang,Shuyi Guan,Yang Liu,Peng Sun*

Main category: cs.AI

TL;DR: Event-CausNet框架使用LLM量化非结构化事件报告，构建因果知识库，并通过因果注意力机制将因果知识注入双流GNN-LSTM网络，显著提升交通预测在非重复性事件中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统时空GNN在处理重复性交通模式时表现出色，但在事故等非重复性事件中可靠性急剧下降，因为GNN本质上是相关性模型，而突发事件引入了新的因果因素使历史模式失效。

Method: 使用大语言模型量化非结构化事件报告，通过估计平均处理效应构建因果知识库，采用双流GNN-LSTM网络结合新型因果注意力机制来调整和增强预测。

Result: 在真实世界数据集上的实验表明，Event-CausNet将预测误差（MAE）降低了高达35.87%，显著优于最先进的基线方法。

Conclusion: 该框架弥合了相关性模型与因果推理之间的差距，提供了更准确、可迁移的解决方案，同时提供关键的可解释性，为关键中断期间的真实世界交通管理提供了更可靠的基础。

Abstract: While spatio-temporal Graph Neural Networks (GNNs) excel at modeling recurring traffic patterns, their reliability plummets during non-recurring events like accidents. This failure occurs because GNNs are fundamentally correlational models, learning historical patterns that are invalidated by the new causal factors introduced during disruptions. To address this, we propose Event-CausNet, a framework that uses a Large Language Model to quantify unstructured event reports, builds a causal knowledge base by estimating average treatment effects, and injects this knowledge into a dual-stream GNN-LSTM network using a novel causal attention mechanism to adjust and enhance the forecast. Experiments on a real-world dataset demonstrate that Event-CausNet achieves robust performance, reducing prediction error (MAE) by up to 35.87%, significantly outperforming state-of-the-art baselines. Our framework bridges the gap between correlational models and causal reasoning, providing a solution that is more accurate and transferable, while also offering crucial interpretability, providing a more reliable foundation for real-world traffic management during critical disruptions.

</details>


### [199] [Multi-Agent Reinforcement Learning for Heterogeneous Satellite Cluster Resources Optimization](https://arxiv.org/abs/2511.12792)
*Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Zehong Cao,Ryszard Kowalczyk*

Main category: cs.AI

TL;DR: 使用强化学习和多智能体强化学习优化异构卫星集群在自主地球观测任务中的资源分配，解决实时性、不确定性和分散决策的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法难以处理地球观测操作中的实时性、不确定性和分散性特点，需要自适应决策方法来管理卫星的有限资源。

Method: 从单卫星到多卫星场景系统性地构建优化问题，使用MAPPO、HAPPO、HATRPO等先进MARL算法，在基于Basilisk和BSK-RL框架的近真实仿真环境中进行评估。

Result: MARL能够实现异构卫星间的有效协调，平衡成像性能和资源利用，同时缓解非平稳性和智能体间奖励耦合问题。

Conclusion: 研究为可扩展的自主卫星操作提供了实用见解，并为未来在异构动态条件下智能地球观测任务规划研究奠定了基础。

Abstract: This work investigates resource optimization in heterogeneous satellite clusters performing autonomous Earth Observation (EO) missions using Reinforcement Learning (RL). In the proposed setting, two optical satellites and one Synthetic Aperture Radar (SAR) satellite operate cooperatively in low Earth orbit to capture ground targets and manage their limited onboard resources efficiently. Traditional optimization methods struggle to handle the real-time, uncertain, and decentralized nature of EO operations, motivating the use of RL and Multi-Agent Reinforcement Learning (MARL) for adaptive decision-making. This study systematically formulates the optimization problem from single-satellite to multi-satellite scenarios, addressing key challenges including energy and memory constraints, partial observability, and agent heterogeneity arising from diverse payload capabilities. Using a near-realistic simulation environment built on the Basilisk and BSK-RL frameworks, we evaluate the performance and stability of state-of-the-art MARL algorithms such as MAPPO, HAPPO, and HATRPO. Results show that MARL enables effective coordination across heterogeneous satellites, balancing imaging performance and resource utilization while mitigating non-stationarity and inter-agent reward coupling. The findings provide practical insights into scalable, autonomous satellite operations and contribute a foundation for future research on intelligent EO mission planning under heterogeneous and dynamic conditions.

</details>


### [200] [Neuro-Logic Lifelong Learning](https://arxiv.org/abs/2511.12793)
*Bowen He,Xiaoan Xu,Alper Kamil Bozkurt,Vahid Tarokh,Juncheng Dong*

Main category: cs.AI

TL;DR: 该论文研究了终身学习ILP，通过利用逻辑规则的组合性和可迁移性，在问题序列中高效学习新任务。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注为单个问题设计新颖网络架构，而较少探索涉及问题序列的新学习范式。

Method: 引入组合框架，展示如何将从先前任务中获取的逻辑规则高效地重用于后续任务。

Result: 实验结果表明该范式可行且具有优势，提高了可扩展性和性能。

Conclusion: 这一方法为神经符号AI中的持续学习开辟了新方向。

Abstract: Solving Inductive Logic Programming (ILP) problems with neural networks is a key challenge in Neural-Symbolic Ar- tificial Intelligence (AI). While most research has focused on designing novel network architectures for individual prob- lems, less effort has been devoted to exploring new learning paradigms involving a sequence of problems. In this work, we investigate lifelong learning ILP, which leverages the com- positional and transferable nature of logic rules for efficient learning of new problems. We introduce a compositional framework, demonstrating how logic rules acquired from ear- lier tasks can be efficiently reused in subsequent ones, leading to improved scalability and performance. We formalize our approach and empirically evaluate it on sequences of tasks. Experimental results validate the feasibility and advantages of this paradigm, opening new directions for continual learn- ing in Neural-Symbolic AI.

</details>


### [201] [Mapping fNIRS Signals to Agent Performance: Toward Reinforcement Learning from Neural Feedback](https://arxiv.org/abs/2511.12844)
*Julia Santaniello,Matthew Russell,Benson Jiang,Donatello Sassaroli,Robert Jacob,Jivko SInapov*

Main category: cs.AI

TL;DR: 使用被动脑机接口（BCI）和功能性近红外光谱（fNIRS）信号来指导强化学习代理训练，通过神经信号预测代理性能水平，实现脑驱动的RLHF系统。


<details>
  <summary>Details</summary>
Motivation: 传统RLHF需要显式的人类反馈，而本研究旨在利用隐式神经信号来对齐代理行为与人类偏好，减少对显式反馈的依赖。

Method: 收集25名参与者在三个领域（拾放机器人、月球着陆器、Flappy Bird）的fNIRS数据，训练分类器和回归器来预测代理性能水平，并评估跨主体泛化能力。

Result: 二分类平均F1分数67%，多分类46%；通过少量主体特定数据微调预训练模型，二分类和多分类F1分数分别提升17%和41%。

Conclusion: 从隐式fNIRS信号映射到代理性能是可行的，且可通过改进提升性能，为未来脑驱动的RLHF系统奠定基础。

Abstract: Reinforcement Learning from Human Feedback (RLHF) is a methodology that aligns agent behavior with human preferences by integrating human feedback into the agent's training process. We introduce a possible framework that employs passive Brain-Computer Interfaces (BCI) to guide agent training from implicit neural signals. We present and release a novel dataset of functional near-infrared spectroscopy (fNIRS) recordings collected from 25 human participants across three domains: a Pick-and-Place Robot, Lunar Lander, and Flappy Bird. We train classifiers to predict levels of agent performance (optimal, sub-optimal, or worst-case) from windows of preprocessed fNIRS feature vectors, achieving an average F1 score of 67% for binary classification and 46% for multi-class models averaged across conditions and domains. We also train regressors to predict the degree of deviation between an agent's chosen action and a set of near-optimal policies, providing a continuous measure of performance. We evaluate cross-subject generalization and demonstrate that fine-tuning pre-trained models with a small sample of subject-specific data increases average F1 scores by 17% and 41% for binary and multi-class models, respectively. Our work demonstrates that mapping implicit fNIRS signals to agent performance is feasible and can be improved, laying the foundation for future brain-driven RLHF systems.

</details>


### [202] [Bootstrapping LLMs via Preference-Based Policy Optimization](https://arxiv.org/abs/2511.12867)
*Chen Jia*

Main category: cs.AI

TL;DR: 提出了一种基于偏好的策略优化框架PbPO，通过min-max博弈在策略和奖励模型之间进行优化，利用置信集约束奖励模型，并通过在线迭代算法持续收集偏好数据实现自我改进。


<details>
  <summary>Details</summary>
Motivation: 为了在没有大量人工标注的情况下，通过基于偏好的策略优化来对齐大语言模型与人类偏好，提供一种不依赖广泛手动注释的模型对齐方法。

Method: 将学习过程构建为策略和奖励模型之间的min-max博弈，奖励模型在偏好数据导出的置信集内进行约束，采用迭代在线算法通过引导探索主动收集偏好数据。

Result: 在五个基准测试上的广泛实验表明，该方法持续优于现有的最先进偏好优化技术，并为序列级和令牌级奖励模型提供了高概率遗憾界理论保证。

Conclusion: PbPO框架通过min-max博弈和置信集约束，有效实现了大语言模型的引导对齐，在理论和实验上都证明了其优越性能。

Abstract: Bootstrapping large language models (LLMs) through preference-based policy optimization offers a promising direction for aligning model behavior with human preferences without relying on extensive manual annotations. In this work, we propose a novel preference-based policy optimization (PbPO) framework that formulates the learning process as a min-max game between the main policy and a reward model (RM). The RM is constrained within a confidence set derived from preference data to ensure reliable exploitation. Our iterative online algorithm actively collects preference data through guided exploration of the evolving policy, enabling continual self-improvement of both the policy and the RM. We provide theoretical guarantees for our method, establishing high-probability regret bounds for both settings with sequence-level RM and token-level RM, demonstrating its effectiveness in bootstrapping LLMs. Extensive experiments on five benchmarks show that our approach consistently outperforms existing state-of-the-art preference optimization techniques.

</details>


### [203] [Online Learning of HTN Methods for integrated LLM-HTN Planning](https://arxiv.org/abs/2511.12901)
*Yuesheng Xu,Hector Munoz-Avila*

Main category: cs.AI

TL;DR: 提出了在集成HTN规划和LLM聊天机器人背景下在线学习分层任务网络方法的技术，通过从ChatGPT生成的分解中学习通用方法，减少对ChatGPT的调用次数。


<details>
  <summary>Details</summary>
Motivation: 现有ChatHTN规划器在遇到没有可用方法分解的任务时需要频繁调用ChatGPT，这既低效又成本高昂。需要一种能够从ChatGPT的分解中学习通用方法的技术，减少对外部LLM的依赖。

Method: 在ChatHTN基础上扩展在线学习方法：当ChatGPT生成任务分解时，系统学习通用方法而非简单记忆，使学得的方法适用于同一任务的其他实例，而不仅限于特定实例。

Result: 在两个领域进行的实验表明，在线学习过程显著减少了ChatGPT调用次数，同时至少解决了同样多的问题，在某些情况下甚至解决了更多问题。

Conclusion: 在线学习HTN方法能有效减少对ChatGPT的依赖，提高规划效率，同时保持或提升问题解决能力，为集成LLM的规划系统提供了更可持续的解决方案。

Abstract: We present online learning of Hierarchical Task Network (HTN) methods in the context of integrated HTN planning and LLM-based chatbots. Methods indicate when and how to decompose tasks into subtasks. Our method learner is built on top of the ChatHTN planner. ChatHTN queries ChatGPT to generate a decomposition of a task into primitive tasks when no applicable method for the task is available. In this work, we extend ChatHTN. Namely, when ChatGPT generates a task decomposition, ChatHTN learns from it, akin to memoization. However, unlike memoization, it learns a generalized method that applies not only to the specific instance encountered, but to other instances of the same task. We conduct experiments on two domains and demonstrate that our online learning procedure reduces the number of calls to ChatGPT while solving at least as many problems, and in some cases, even more.

</details>


### [204] [CoS: Towards Optimal Event Scheduling via Chain-of-Scheduling](https://arxiv.org/abs/2511.12913)
*Yiming Zhao,Jiwei Tang,Shimin Di,Libin Zheng,Jianxing Yu,Jian Yin*

Main category: cs.AI

TL;DR: 提出了Chain-of-Scheduling (CoS)框架，通过将事件调度任务分解为探索、验证和集成三个原子阶段，激活大型语言模型的事件调度能力，并使用知识蒸馏使LLM能够自主生成CoS。


<details>
  <summary>Details</summary>
Motivation: 在基于事件的社交网络中，有效的事件调度推荐对于维持用户活动至关重要。现有方法在效率、效果和泛化性之间存在固有权衡，因为该问题是NP难问题。

Method: CoS框架将调度任务分解为三个原子阶段：探索、验证和集成，然后通过知识蒸馏使大型语言模型能够自主生成调度链。

Result: 在三个真实世界数据集上，CoS实现了接近理论最优的效果和高效率，并以可解释的方式运行。此外，在域外数据上表现出强大的零样本学习能力。

Conclusion: CoS框架成功激活了LLM的事件调度能力，在保持高效的同时实现了接近最优的效果，并具有良好的泛化性能。

Abstract: Recommending event schedules is a key issue in Event-based Social Networks (EBSNs) in order to maintain user activity. An effective recommendation is required to maximize the user's preference, subjecting to both time and geographical constraints. Existing methods face an inherent trade-off among efficiency, effectiveness, and generalization, due to the NP-hard nature of the problem. This paper proposes the Chain-of-Scheduling (CoS) framework, which activates the event scheduling capability of Large Language Models (LLMs) through a guided, efficient scheduling process. CoS enhances LLM by formulating the schedule task into three atomic stages, i.e., exploration, verification and integration. Then we enable the LLMs to generate CoS autonomously via Knowledge Distillation (KD). Experimental results show that CoS achieves near-theoretical optimal effectiveness with high efficiency on three real-world datasets in a interpretable manner. Moreover, it demonstrates strong zero-shot learning ability on out-of-domain data.

</details>


### [205] [Fault2Flow: An AlphaEvolve-Optimized Human-in-the-Loop Multi-Agent System for Fault-to-Workflow Automation](https://arxiv.org/abs/2511.12916)
*Yafang Wang,Yangjie Tian,Xiaoyu Shen,Gaoyang Zhang,Jiaze Sun,He Zhang,Ruohua Xu,Feng Zhao*

Main category: cs.AI

TL;DR: Fault2Flow是一个基于LLM的多智能体系统，用于电网故障诊断，通过整合法规逻辑和专家知识，生成可执行的自动化工作流。


<details>
  <summary>Details</summary>
Motivation: 传统电网故障诊断依赖人工方法，效率低且容易出错，缺乏维护性。现有方法无法将法规文本和专家知识整合到单一可验证的工作流中。

Method: 系统性地：(1)提取法规逻辑并构建PASTA格式故障树；(2)通过人机交互界面整合专家知识；(3)使用AlphaEvolve模块优化推理逻辑；(4)将最终逻辑合成为n8n可执行工作流。

Result: 在变压器故障诊断数据集上的实验验证显示100%拓扑一致性和高语义保真度。

Conclusion: Fault2Flow建立了从故障分析到操作自动化的可重复路径，显著减少了专家工作量。

Abstract: Power grid fault diagnosis is a critical process hindered by its reliance on manual, error-prone methods. Technicians must manually extract reasoning logic from dense regulations and attempt to combine it with tacit expert knowledge, which is inefficient, error-prone, and lacks maintainability as ragulations are updated and experience evolves. While Large Language Models (LLMs) have shown promise in parsing unstructured text, no existing framework integrates these two disparate knowledge sources into a single, verified, and executable workflow. To bridge this gap, we propose Fault2Flow, an LLM-based multi-agent system. Fault2Flow systematically: (1) extracts and structures regulatory logic into PASTA-formatted fault trees; (2) integrates expert knowledge via a human-in-the-loop interface for verification; (3) optimizes the reasoning logic using a novel AlphaEvolve module; and (4) synthesizes the final, verified logic into an n8n-executable workflow. Experimental validation on transformer fault diagnosis datasets confirms 100\% topological consistency and high semantic fidelity. Fault2Flow establishes a reproducible path from fault analysis to operational automation, substantially reducing expert workload.

</details>


### [206] [Yanyun-3: Enabling Cross-Platform Strategy Game Operation with Vision-Language Models](https://arxiv.org/abs/2511.12937)
*Guoyan Wang,Yanyan Huang,Chunlin Chen,Lifeng Wang,Yuxiang Sun*

Main category: cs.AI

TL;DR: Yanyun-3是一个通用智能体框架，首次实现了在三个异构策略游戏环境中的自主跨平台操作，通过融合视觉语言模型和精确执行能力，在减少63%推理时间的同时将BLEU-4分数提升12.98倍。


<details>
  <summary>Details</summary>
Motivation: 策略游戏中的自动化操作需要能够跨不同用户界面和动态战场条件进行泛化的智能体，而视觉语言模型在复杂人机交互场景（如策略游戏）中的应用尚未充分探索。

Method: 集成Qwen2.5-VL的视觉语言推理能力和UI-TARS的精确执行能力，采用屏幕捕获、模型推理和动作执行的闭环流程，并研究不同多模态数据组合策略（静态图像、多图像序列和视频）。

Result: 混合策略（融合多图像和视频数据，同时混合静态图像）显著优于完全融合策略：推理时间减少63%，BLEU-4分数从4.81%提升至62.41%（约12.98倍提升）。

Conclusion: 该工作不仅为策略游戏自动化提供了高效解决方案，还通过结构化多模态数据组织建立了增强VLM性能的通用范式，为具身智能中静态感知与动态推理的相互作用提供了新见解。

Abstract: Automated operation in cross-platform strategy games demands agents with robust generalization across diverse user interfaces and dynamic battlefield conditions. While vision-language models (VLMs) have shown considerable promise in multimodal reasoning, their application to complex human-computer interaction scenarios--such as strategy gaming--remains largely unexplored. Here, we introduce Yanyun-3, a general-purpose agent framework that, for the first time, enables autonomous cross-platform operation across three heterogeneous strategy game environments. By integrating the vision-language reasoning of Qwen2.5-VL with the precise execution capabilities of UI-TARS, Yanyun-3 successfully performs core tasks including target localization, combat resource allocation, and area control. Through systematic ablation studies, we evaluate the effects of various multimodal data combinations--static images, multi-image sequences, and videos--and propose the concept of combination granularity to differentiate between intra-sample fusion and inter-sample mixing strategies. We find that a hybrid strategy, which fuses multi-image and video data while mixing in static images (MV+S), substantially outperforms full fusion: it reduces inference time by 63% and boosts the BLEU-4 score by a factor of 12 (from 4.81% to 62.41%, approximately 12.98x). Operating via a closed-loop pipeline of screen capture, model inference, and action execution, the agent demonstrates strong real-time performance and cross-platform generalization. Beyond providing an efficient solution for strategy game automation, our work establishes a general paradigm for enhancing VLM performance through structured multimodal data organization, offering new insights into the interplay between static perception and dynamic reasoning in embodied intelligence.

</details>


### [207] [MedRule-KG: A Knowledge-Graph--Steered Scaffold for Reliable Mathematical and Biomedical Reasoning](https://arxiv.org/abs/2511.12963)
*Crystal Su*

Main category: cs.AI

TL;DR: MedRule-KG是一个为科学推理和药物发现设计的系统，通过知识图谱和轻量级验证器来约束LLM生成领域一致且有效的输出。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在科学推理和早期药物发现中生成不符合数学和生物医学规则的问题，确保输出的领域一致性。

Method: 使用紧凑的知识图谱支架和轻量级验证器，将策划的符号事实注入提示中，并通过确定性检查器强制执行规则满足。将生成形式化为约束推理，引入适合解码的软指导替代方法。

Result: 在90个任务中，MedRule-KG相对于强大的思维链基线减少了83.2%的违规数量，同时提高了精确匹配率。结果在分层下保持稳定，并随数据集规模扩展，验证器添加的延迟可忽略。

Conclusion: MedRule-KG能够有效约束LLM生成领域一致的输出，在保持性能的同时大幅减少违规，适用于交互式设计场景。

Abstract: We study how to impose domain-consistent structure on large language models (LLMs) used for scientific reasoning and early-stage drug discovery. We present MedRule-KG, a compact knowledge-graph scaffold paired with a lightweight verifier that steers generation toward mathematically and biomedically valid outputs. The system injects curated symbolic facts into prompts and then enforces rule satisfaction with a deterministic checker. We formalize generation as constrained inference, introduce a soft guidance surrogate suitable for decoding, and perform a thorough statistical analysis with uncertainty quantification. Across 90 tasks spanning reaction feasibility, metabolic compatibility, and toxicity screening, MedRule-KG reduces violation counts by 83.2\% relative to a strong chain-of-thought baseline while improving exact match. Results remain stable under stratification and scale with dataset size, and the verifier adds negligible latency, making the approach practical for interactive design.

</details>


### [208] [WebCoach: Self-Evolving Web Agents with Cross-Session Memory Guidance](https://arxiv.org/abs/2511.12997)
*Genglin Liu,Shijie Geng,Sha Li,Hejie Cui,Sarah Zhang,Xin Liu,Tianyi Liu*

Main category: cs.AI

TL;DR: WebCoach是一个模型无关的自进化框架，为网页浏览代理提供跨会话的持久内存，通过记忆总结、存储和检索机制，让代理能够从历史经验中学习，提高长期规划和任务执行能力。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态LLM代理在网页导航中存在重复错误，缺乏跨会话学习能力，限制了长期鲁棒性和样本效率。

Method: WebCoach包含三个核心组件：WebCondenser标准化导航日志为摘要，External Memory Store组织完整轨迹作为经验记忆，Coach基于相似性和时效性检索相关经验并通过运行时钩子向代理提供建议。

Result: 在WebVoyager基准测试中，WebCoach显著提升了三种不同LLM骨干网络的性能，使用38B模型时任务成功率从47%提升到61%，同时减少或保持平均步骤数。较小的基础模型配合WebCoach能达到与使用GPT-4o的网页代理相当的性能。

Conclusion: WebCoach通过赋予网页代理持久跨会话记忆能力，实现了无需重新训练的自进化，显著提升了复杂浏览任务的鲁棒性和效率。

Abstract: Multimodal LLM-powered agents have recently demonstrated impressive capabilities in web navigation, enabling agents to complete complex browsing tasks across diverse domains. However, current agents struggle with repetitive errors and lack the ability to learn from past experiences across sessions, limiting their long-term robustness and sample efficiency. We introduce WebCoach, a model-agnostic self-evolving framework that equips web browsing agents with persistent cross-session memory, enabling improved long-term planning, reflection, and continual learning without retraining. WebCoach consists of three key components: (1) a WebCondenser, which standardizes raw navigation logs into concise summaries; (2) an External Memory Store, which organizes complete trajectories as episodic experiences; and (3) a Coach, which retrieves relevant experiences based on similarity and recency, and decides whether to inject task-specific advice into the agent via runtime hooks. This design empowers web agents to access long-term memory beyond their native context window, improving robustness in complex browsing tasks. Moreover, WebCoach achieves self-evolution by continuously curating episodic memory from new navigation trajectories, enabling agents to improve over time without retraining. Evaluations on the WebVoyager benchmark demonstrate that WebCoach consistently improves the performance of browser-use agents across three different LLM backbones. With a 38B model, it increases task success rates from 47% to 61% while reducing or maintaining the average number of steps. Notably, smaller base models with WebCoach achieve performance comparable to the same web agent using GPT-4o.

</details>


### [209] [GEM: Generative Entropy-Guided Preference Modeling for Few-shot Alignment of LLMs](https://arxiv.org/abs/2511.13007)
*Yiyang Zhao,Huiyu Bai,Xuejiao Zhao*

Main category: cs.AI

TL;DR: GEM是一种基于生成熵引导的偏好建模方法，用于在低资源和领域特定场景下对齐大语言模型。它通过认知过滤模块和自评估群体优势算法，利用熵理论从少量偏好数据中提取认知信号，实现高效的小样本对齐。


<details>
  <summary>Details</summary>
Motivation: 在医学、法律等专业领域，大规模偏好标注难以获取，传统基于监督奖励模型或外部评估者的对齐方法不可行，需要开发适用于低资源场景的对齐技术。

Method: 1. 基于熵理论的认知过滤模块：使用思维链提示生成多样化推理链，通过令牌评分机制对思维链进行排序和加权；2. 自评估群体优势算法(SEGA)：将熵基分数转化为隐式奖励进行策略优化，聚合群体级认知信号。

Result: 在通用基准测试和领域特定任务（如数学推理和医疗对话）上的实验表明，GEM在使用少量偏好数据的情况下取得了显著改进。

Conclusion: GEM建立了一个熵引导的闭环认知优化框架，使LLM能够依赖自身判断，实现高效的小样本对齐，特别适用于专业领域。

Abstract: Alignment of large language models (LLMs) with human preferences typically relies on supervised reward models or external judges that demand abundant annotations. However, in fields that rely on professional knowledge, such as medicine and law, such large-scale preference labels are often unachievable. In this paper, we propose a generative entropy-guided preference modeling approach named GEM for LLMs aligment at low-resource and domain-specific scenarios. Instead of training a discriminative reward model on preference data, we directly train the LLM to internalize a closed-loop optimization architecture that can extract and exploit the multi-dimensional, fine-grained cognitive signals implicit in human preferences. Specifically, our Cognitive Filtering module, based on entropy theory in decision making, first leverages Chain-of-Thought (CoT) prompting to generate diverse candidate reasoning chains (CoTs) from preference data. Subsequently, it introduces a token scoring mechanism to rank and weight the sampled CoTs, boosting the importance of high-confidence answers and strategically high-entropy tokens. Building on these filtered preferences, we fine-tune the LLM using a novel self-evaluated group advantage algorithm, SEGA, which effectively aggregates group-level cognitive signals and transforms the entropy-based scores into implicit rewards for policy optimization. In these ways, GEM empowers the LLM to rely on its own judgments and establishes an entropy-guided closed-loop cognitive optimization framework, enabling highly efficient few-shot alignment of LLMs. Experiments on general benchmarks and domain-specific tasks (such as mathematical reasoning and medical dialogues) demonstrate that our GEM achieves significant improvements with few-shot preference data.

</details>


### [210] [PragWorld: A Benchmark Evaluating LLMs' Local World Model under Minimal Linguistic Alterations and Conversational Dynamics](https://arxiv.org/abs/2511.13021)
*Sachin Vashistha,Aryan Bibhuti,Atharva Naik,Martin Tutek,Somak Aditya*

Main category: cs.AI

TL;DR: 评估语言模型在对话中编码和更新内部世界模型的能力，测试其在语言变化下的鲁棒性，并提出基于层正则化的微调策略。


<details>
  <summary>Details</summary>
Motivation: 现实对话包含丰富的语用元素，需要构建局部世界模型来编码这些元素并捕捉其状态演变。但语言模型是否构建或维护这种隐式表示尚不清楚。

Method: 对流行数据集中的对话应用七种最小语言变化，构建两个包含是非问题的基准测试，评估多种开源和闭源语言模型，并提出双视角可解释性框架识别有用和有害的Transformer层。

Result: 语言模型在维持鲁棒准确性方面表现不佳，难以记忆关键细节（如跟踪实体在语言变化下的状态）。有害层通常编码虚假信号或依赖捷径。

Conclusion: 语言模型在对话中维护世界模型的能力有限，提出的层正则化微调策略能有效抑制有害层的影响。

Abstract: Real-world conversations are rich with pragmatic elements, such as entity mentions, references, and implicatures. Understanding such nuances is a requirement for successful natural communication, and often requires building a local world model which encodes such elements and captures the dynamics of their evolving states. However, it is not well-understood whether language models (LMs) construct or maintain a robust implicit representation of conversations. In this work, we evaluate the ability of LMs to encode and update their internal world model in dyadic conversations and test their malleability under linguistic alterations. To facilitate this, we apply seven minimal linguistic alterations to conversations sourced from popular datasets and construct two benchmarks comprising yes-no questions. We evaluate a wide range of open and closed source LMs and observe that they struggle to maintain robust accuracy. Our analysis unveils that LMs struggle to memorize crucial details, such as tracking entities under linguistic alterations to conversations. We then propose a dual-perspective interpretability framework which identifies transformer layers that are useful or harmful and highlights linguistic alterations most influenced by harmful layers, typically due to encoding spurious signals or relying on shortcuts. Inspired by these insights, we propose two layer-regularization based fine-tuning strategies that suppress the effect of the harmful layers.

</details>


### [211] [Scaling Generative Verifiers For Natural Language Mathematical Proof Verification And Selection](https://arxiv.org/abs/2511.13027)
*Sadegh Mahdavi,Branislav Kisacanin,Shubham Toshniwal,Wei Du,Ivan Moshkov,George Armstrong,Renjie Liao,Christos Thrampoulidis,Igor Gitman*

Main category: cs.AI

TL;DR: 该论文分析了大型语言模型在数学证明验证中的表现，发现单一基准测试可能导致误导性结论，提出结合生成式验证方法和强化学习来改进证明验证系统。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在最终答案数学问题上表现优异，但其推理过程往往存在缺陷。为了推进到严格的证明型数学，需要可靠的证明验证能力。

Method: 分析了多种评估设置，评估了基于证明和最终答案的推理，扩展了两种生成式验证方法（GenSelect和LLM-as-a-Judge）到百万token规模，并研究了强化学习对提示敏感性的影响。

Result: 发现GenSelect和LLM-as-a-Judge的组合是最有效的验证框架，强化学习可以减少对提示的敏感性，但不会提高最终答案的精确度。

Conclusion: 当前模型往往奖励风格或程序正确性而非数学有效性，研究结果为设计和评估可扩展的证明验证和选择系统提供了实用指南。

Abstract: Large language models have achieved remarkable success on final-answer mathematical problems, largely due to the ease of applying reinforcement learning with verifiable rewards. However, the reasoning underlying these solutions is often flawed. Advancing to rigorous proof-based mathematics requires reliable proof verification capabilities. We begin by analyzing multiple evaluation setups and show that focusing on a single benchmark can lead to brittle or misleading conclusions. To address this, we evaluate both proof-based and final-answer reasoning to obtain a more reliable measure of model performance. We then scale two major generative verification methods (GenSelect and LLM-as-a-Judge) to millions of tokens and identify their combination as the most effective framework for solution verification and selection. We further show that the choice of prompt for LLM-as-a-Judge significantly affects the model's performance, but reinforcement learning can reduce this sensitivity. However, despite improving proof-level metrics, reinforcement learning does not enhance final-answer precision, indicating that current models often reward stylistic or procedural correctness rather than mathematical validity. Our results establish practical guidelines for designing and evaluating scalable proof-verification and selection systems.

</details>


### [212] [MEGA-GUI: Multi-stage Enhanced Grounding Agents for GUI Elements](https://arxiv.org/abs/2511.13087)
*SeokJoo Kwak,Jihoon Kim,Boyoun Kim,Jung Jae Yoon,Wooseok Jang,Jeonghoon Hong,Jaeho Yang,Yeong-Dae Kwon*

Main category: cs.AI

TL;DR: MEGA-GUI是一个多阶段的GUI接地框架，通过粗粒度ROI选择和细粒度元素接地来解决视觉杂乱和指令模糊问题，在密集和复杂基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有GUI接地系统依赖单体模型或一次性流水线，缺乏模块化，在视觉杂乱和模糊指令下表现不佳。

Method: 采用多阶段框架，将接地分为粗粒度ROI选择和细粒度元素接地，使用专门视觉语言代理协调，包含双向ROI缩放算法和上下文感知重写代理。

Result: 在ScreenSpot-Pro基准测试中达到73.18%准确率，在OSWorld-G基准测试中达到68.63%，超过之前报告结果。

Conclusion: 模块化结构比单体方法获得更高准确率，不同视觉语言模型在不同视觉尺度上具有互补优势。

Abstract: Graphical User Interface (GUI) grounding - the task of mapping natural language instructions to screen coordinates - is essential for autonomous agents and accessibility technologies. Existing systems rely on monolithic models or one-shot pipelines that lack modularity and fail under visual clutter and ambiguous instructions. We introduce MEGA-GUI, a multi-stage framework that separates grounding into coarse Region-of-Interest (ROI) selection and fine-grained element grounding, orchestrated by specialized vision-language agents. MEGA-GUI features a bidirectional ROI zoom algorithm that mitigates spatial dilution and a context-aware rewriting agent that reduces semantic ambiguity. Our analysis reveals complementary strengths and weaknesses across vision-language models at different visual scales, and we show that leveraging this modular structure achieves consistently higher accuracy than monolithic approaches. On the visually dense ScreenSpot-Pro benchmark, MEGA-GUI attains 73.18% accuracy, and on the semantically complex OSWorld-G benchmark it reaches 68.63%, surpassing previously reported results. Code and the Grounding Benchmark Toolkit (GBT) are available at https://github.com/samsungsds-research-papers/mega-gui.

</details>


### [213] [STEP: Success-Rate-Aware Trajectory-Efficient Policy Optimization](https://arxiv.org/abs/2511.13091)
*Yuhan Chen,Yuxuan Liu,Long Zhang,Pengzhi Gao,Jian Luan,Wei Liu*

Main category: cs.AI

TL;DR: STEP框架通过基于任务成功率的动态采样分配和步骤级优化，解决了多轮交互强化学习中轨迹级优化的低效问题，显著提升了样本效率和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决多轮交互强化学习中轨迹级优化的三个主要问题：跨任务均匀采样的低效性、失败轨迹中正确中间动作被惩罚、以及高样本收集成本。

Method: 提出STEP框架，包括：1) 基于平滑成功率记录的自适应轨迹重采样；2) 成功率加权优势计算和轨迹分解为步骤级样本；3) 对低成功率任务应用步骤级GRPO增强。

Result: 在OSWorld和AndroidWorld上的实验表明，STEP相比轨迹级GRPO显著提高了样本效率和训练稳定性，在相同采样预算下收敛更快且泛化能力更强。

Conclusion: STEP通过成功率感知的采样分配和步骤级优化，有效解决了多轮交互强化学习的效率问题，为在线强化学习提供了更高效的训练框架。

Abstract: Multi-turn interaction remains challenging for online reinforcement learning. A common solution is trajectory-level optimization, which treats each trajectory as a single training sample. However, this approach can be inefficient and yield misleading learning signals: it applies uniform sampling across tasks regardless of difficulty, penalizes correct intermediate actions in failed trajectories, and incurs high sample-collection costs. To address these issues, we propose STEP (Success-rate-aware Trajectory-Efficient Policy optimization), a framework that dynamically allocates sampling based on per-task success rates and performs step-level optimization. STEP maintains a smoothed success-rate record to guide adaptive trajectory resampling, allocating more effort to harder tasks. It then computes success-rate-weighted advantages and decomposes trajectories into step-level samples. Finally, it applies a step-level GRPO augmentation to refine updates for low-success tasks. Experiments on OSWorld and AndroidWorld show that STEP substantially improves sample efficiency and training stability over trajectory-level GRPO, converging faster and generalizing better under the same sampling budget.

</details>


### [214] [Conditional Diffusion Model for Multi-Agent Dynamic Task Decomposition](https://arxiv.org/abs/2511.13137)
*Yanda Zhu,Yuanyang Zhu,Daoyi Dong,Caihua Chen,Chunlin Chen*

Main category: cs.AI

TL;DR: C$	ext{D}^	ext{3}$T是一个新颖的两层分层多智能体强化学习框架，使用条件扩散模型动态推断子任务和协调模式，在复杂合作任务中实现高效学习。


<details>
  <summary>Details</summary>
Motivation: 传统方法从零开始学习动态任务分解需要大量训练样本，特别是在部分可观测环境下探索联合动作空间时效率低下。

Method: 高层策略学习子任务表示，基于子任务效果生成子任务选择策略；使用条件扩散模型预测下一观测和奖励来捕捉子任务对环境的影响；低层智能体在分配的子任务中协作学习并共享专门技能；子任务表示作为附加语义信息用于多头注意力混合网络以增强价值分解。

Result: 在各种基准测试中，C$	ext{D}^	ext{3}$T比现有基线方法取得了更好的性能。

Conclusion: 该框架通过条件扩散模型实现了动态任务分解，有效解决了复杂合作多智能体强化学习任务中的长时程学习问题。

Abstract: Task decomposition has shown promise in complex cooperative multi-agent reinforcement learning (MARL) tasks, which enables efficient hierarchical learning for long-horizon tasks in dynamic and uncertain environments. However, learning dynamic task decomposition from scratch generally requires a large number of training samples, especially exploring the large joint action space under partial observability. In this paper, we present the Conditional Diffusion Model for Dynamic Task Decomposition (C$\text{D}^\text{3}$T), a novel two-level hierarchical MARL framework designed to automatically infer subtask and coordination patterns. The high-level policy learns subtask representation to generate a subtask selection strategy based on subtask effects. To capture the effects of subtasks on the environment, C$\text{D}^\text{3}$T predicts the next observation and reward using a conditional diffusion model. At the low level, agents collaboratively learn and share specialized skills within their assigned subtasks. Moreover, the learned subtask representation is also used as additional semantic information in a multi-head attention mixing network to enhance value decomposition and provide an efficient reasoning bridge between individual and joint value functions. Experimental results on various benchmarks demonstrate that C$\text{D}^\text{3}$T achieves better performance than existing baselines.

</details>


### [215] [InteractiveGNNExplainer: A Visual Analytics Framework for Multi-Faceted Understanding and Probing of Graph Neural Network Predictions](https://arxiv.org/abs/2511.13160)
*TC Singh,Sougata Mukherjea*

Main category: cs.AI

TL;DR: 提出了InteractiveGNNExplainer框架，通过集成交互式可视化视图和图编辑功能，增强图神经网络的可解释性，支持用户进行"what-if"分析。


<details>
  <summary>Details</summary>
Motivation: 图神经网络在基于图的学习任务中表现出色，但其复杂的非线性操作使其成为不透明的"黑箱"，这阻碍了用户信任、调试、偏见检测以及在需要可解释性的关键领域中的应用。

Method: 开发了InteractiveGNNExplainer视觉分析框架，集成协调的交互视图（动态图布局、嵌入投影、特征检查、邻域分析）与后验（GNNExplainer）和内在（GAT注意力）解释技术，并包含交互式图编辑功能。

Result: 通过在Cora和CiteSeer数据集上的案例研究，展示了该系统能够促进深入的误分类诊断、GCN与GAT行为的比较分析，以及对模型敏感性的严格探测。

Conclusion: 该框架能够促进对GNN预测的多方面深入理解，有助于实现更透明、可信和鲁棒的图分析。

Abstract: Graph Neural Networks (GNNs) excel in graph-based learning tasks, but their complex, non-linear operations often render them as opaque "black boxes". This opacity hinders user trust, complicates debugging, bias detection, and adoption in critical domains requiring explainability. This paper introduces InteractiveGNNExplainer, a visual analytics framework to enhance GNN explainability, focusing on node classification. Our system uniquely integrates coordinated interactive views (dynamic graph layouts, embedding projections, feature inspection, neighborhood analysis) with established post-hoc (GNNExplainer) and intrinsic (GAT attention) explanation techniques. Crucially, it incorporates interactive graph editing, allowing users to perform a "what-if" analysis by perturbing graph structures and observing immediate impacts on GNN predictions and explanations. We detail the system architecture and, through case studies on Cora and CiteSeer datasets, demonstrate how InteractiveGNNExplainer facilitates in-depth misclassification diagnosis, comparative analysis of GCN versus GAT behaviors, and rigorous probing of model sensitivity. These capabilities foster a deeper, multifaceted understanding of GNN predictions, contributing to more transparent, trustworthy, and robust graph analysis.

</details>


### [216] [Cost-Effective Communication: An Auction-based Method for Language Agent Interaction](https://arxiv.org/abs/2511.13193)
*Yijia Fan,Jusheng Zhang,Kaitong Cai,Jing Yang,Chengpei Tang,Jian Wang,Keze Wang*

Main category: cs.AI

TL;DR: DALA框架通过将通信带宽视为稀缺可交易资源，采用集中式拍卖机制让智能体基于消息价值密度竞标发言权，从而显著提升多智能体系统的通信效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决基于大语言模型的多智能体系统中'自由通信'导致的指数级token成本和低信噪比问题，挑战'更多通信总是更好'的观念，强调资源理性的重要性。

Method: 提出动态拍卖语言智能体(DALA)框架，将智能体间通信视为集中式拍卖，智能体学习基于预测消息价值密度竞标发言机会，鼓励生成简洁高价值消息。

Result: 在7个挑战性推理基准测试中达到最先进性能，包括MMLU 84.32%和HumanEval 91.21% pass@1率，仅使用625万token，远少于现有方法在GSM8K上的资源消耗。

Conclusion: DALA通过资源约束培养出战略性沉默的涌现能力，能够动态调整从冗长到沉默的通信策略，证明经济驱动的通信机制能显著提升多智能体系统效率。

Abstract: Multi-agent systems (MAS) built on large language models (LLMs) often suffer from inefficient "free-for-all" communication, leading to exponential token costs and low signal-to-noise ratios that hinder their practical deployment. We challenge the notion that more communication is always beneficial, hypothesizing instead that the core issue is the absence of resource rationality. We argue that "free" communication, by ignoring the principle of scarcity, inherently breeds inefficiency and unnecessary expenses. To address this, we introduce the Dynamic Auction-based Language Agent (DALA), a novel framework that treats communication bandwidth as a scarce and tradable resource. Specifically, our DALA regards inter-agent communication as a centralized auction, where agents learn to bid for the opportunity to speak based on the predicted value density of their messages. Thus, our DALA intrinsically encourages agents to produce concise, informative messages while filtering out low-value communication. Extensive and comprehensive experiments demonstrate that our economically-driven DALA achieves new state-of-the-art performance across seven challenging reasoning benchmarks, including 84.32% on MMLU and a 91.21% pass@1 rate on HumanEval. Note that this is accomplished with remarkable efficiency, i.e., our DALA uses only 6.25 million tokens, a fraction of the resources consumed by current state-of-the-art methods on GSM8K. Further analysis reveals that our DALA cultivates the emergent skill of strategic silence, effectively adapting its communication strategies from verbosity to silence in a dynamical manner via resource constraints.

</details>


### [217] [Learning to Solve Resource-Constrained Project Scheduling Problems with Duration Uncertainty using Graph Neural Networks](https://arxiv.org/abs/2511.13214)
*Guillaume Infantes,Stéphanie Roussel,Antoine Jacquet,Emmanuel Benazera*

Main category: cs.AI

TL;DR: 使用图神经网络和深度强化学习解决资源受限项目调度问题中的任务持续时间不确定性，目标是生成可重复使用的基准调度方案以最小化期望项目工期。


<details>
  <summary>Details</summary>
Motivation: 实践中任务持续时间存在不确定性，需要提出具有韧性的调度方案来应对这种不确定性，并生成可重复使用的基准调度。

Method: 结合图神经网络和深度强化学习开发任务调度策略，该策略类似于优先级调度规则，并与串行调度生成方案配合生成调度。

Result: 在标准基准测试上的实证评估表明，该方法在性能和泛化能力方面具有优越性。

Conclusion: 开发了名为Wheatley的公开框架，以促进进一步研究和可重复性。

Abstract: The Resource-Constrained Project Scheduling Problem (RCPSP) is a classical scheduling problem that has received significant attention due to of its numerous applications in industry. However, in practice, task durations are subject to uncertainty that must be considered in order to propose resilient scheduling. In this paper, we address the RCPSP variant with uncertain tasks duration (modeled using known probabilities) and aim to minimize the overall expected project duration. Our objective is to produce a baseline schedule that can be reused multiple times in an industrial setting regardless of the actual duration scenario. We leverage Graph Neural Networks in conjunction with Deep Reinforcement Learning (DRL) to develop an effective policy for task scheduling. This policy operates similarly to a priority dispatch rule and is paired with a Serial Schedule Generation Scheme to produce a schedule. Our empirical evaluation on standard benchmarks demonstrates the approach's superiority in terms of performance and its ability to generalize. The developed framework, Wheatley, is made publicly available online to facilitate further research and reproducibility.

</details>


### [218] [Informative Communication of Robot Plans](https://arxiv.org/abs/2511.13226)
*Michele Persiani,Thomas Hellstrom*

Main category: cs.AI

TL;DR: 提出一种基于信息增益的机器人计划语言化策略，通过考虑用户的二阶心智理论来优化沟通效果


<details>
  <summary>Details</summary>
Motivation: 现有机器人计划语言化策略（如按计划顺序递增或递减）忽视了用户先验知识，无法有效传达信息

Method: 通过测量语言化对用户二阶心智理论的信息增益，开发信息化的计划沟通策略

Result: 实验表明该策略能让用户更快理解机器人目标，优于递增或递减计划顺序策略

Conclusion: 该研究揭示了机器人计划沟通中什么是信息化的内容及其原因

Abstract: When a robot is asked to verbalize its plan it can do it in many ways. For example, a seemingly natural strategy is incremental, where the robot verbalizes its planned actions in plan order. However, an important aspect of this type of strategy is that it misses considerations on what is effectively informative to communicate, because not considering what the user knows prior to explanations. In this paper we propose a verbalization strategy to communicate robot plans informatively, by measuring the information gain that verbalizations have against a second-order theory of mind of the user capturing his prior knowledge on the robot. As shown in our experiments, this strategy allows to understand the robot's goal much quicker than by using strategies such as increasing or decreasing plan order. In addition, following our formulation we hint to what is informative and why when a robot communicates its plan.

</details>


### [219] [Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO](https://arxiv.org/abs/2511.13288)
*Haoyang Hong,Jiajun Yin,Yuan Wang,Jingnan Liu,Zhe Chen,Ailing Yu,Ji Li,Zhiling Ye,Hansong Xiao,Yefei Chen,Hualei Zhou,Yun Yue,Minghui Yang,Chunxiao Guo,Junwei Liu,Peng Wei,Jinjie Gu*

Main category: cs.AI

TL;DR: M-GRPO是一种针对多智能体系统的分层强化学习优化方法，通过组相对优势计算和轨迹对齐方案解决异构智能体训练挑战，在真实基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统使用统一的LLM训练所有智能体，但由于不同智能体具有不同的数据分布，这限制了系统性能。训练具有不同LLM的多智能体系统是必要的，但面临优化挑战，如智能体运行频率不同、子智能体调用次数可变以及跨服务器部署导致梯度流中断。

Method: 提出M-GRPO方法：1) 为主智能体（规划器）和子智能体（多轮工具执行器）计算组相对优势，保持分层信用分配；2) 引入轨迹对齐方案，在可变子智能体调用情况下生成固定大小的批次；3) 部署解耦训练管道，智能体在独立服务器上运行，通过共享存储交换最小统计信息，无需跨服务器反向传播。

Result: 在真实世界基准测试（GAIA、XBench-DeepSearch和WebWalkerQA）中，M-GRPO始终优于单智能体GRPO和冻结子智能体的多智能体GRPO，显示出改进的稳定性和样本效率。

Conclusion: 对齐异构轨迹并在专业智能体之间解耦优化能够增强工具增强推理任务的性能，证明了M-GRPO方法的有效性。

Abstract: Multi-agent systems perform well on general reasoning tasks. However, the lack of training in specialized areas hinders their accuracy. Current training methods train a unified large language model (LLM) for all agents in the system. This may limit the performances due to different distributions underlying for different agents. Therefore, training multi-agent systems with distinct LLMs should be the next step to solve. However, this approach introduces optimization challenges. For example, agents operate at different frequencies, rollouts involve varying sub-agent invocations, and agents are often deployed across separate servers, disrupting end-to-end gradient flow. To address these issues, we propose M-GRPO, a hierarchical extension of Group Relative Policy Optimization designed for vertical Multi-agent systems with a main agent (planner) and multiple sub-agents (multi-turn tool executors). M-GRPO computes group-relative advantages for both main and sub-agents, maintaining hierarchical credit assignment. It also introduces a trajectory-alignment scheme that generates fixed-size batches despite variable sub-agent invocations. We deploy a decoupled training pipeline in which agents run on separate servers and exchange minimal statistics via a shared store. This enables scalable training without cross-server backpropagation. In experiments on real-world benchmarks (e.g., GAIA, XBench-DeepSearch, and WebWalkerQA), M-GRPO consistently outperforms both single-agent GRPO and multi-agent GRPO with frozen sub-agents, demonstrating improved stability and sample efficiency. These results show that aligning heterogeneous trajectories and decoupling optimization across specialized agents enhances tool-augmented reasoning tasks.

</details>


### [220] [Grounded by Experience: Generative Healthcare Prediction Augmented with Hierarchical Agentic Retrieval](https://arxiv.org/abs/2511.13293)
*Chuang Zhao,Hui Tang,Hongke Zhao,Xiaofang Zhou,Xiaomeng Li*

Main category: cs.AI

TL;DR: GHAR是一个生成式分层代理RAG框架，通过双代理架构解决医疗预测中何时检索以及如何优化检索器与生成器协作的问题，在三个基准数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LLMs在医疗预测中存在事实不准确的问题，现有RAG框架面临两个关键挑战：确定何时需要激活检索机制，以及实现检索器与生成器的协同工作。

Method: 提出GHAR框架，包含Agent-Top（主医生）和Agent-Low（咨询服务）的双代理架构，通过马尔可夫决策过程统一优化两个代理，设计多样化奖励来对齐准确预测的共同目标。

Result: 在三个基准数据集和三个常见任务上的广泛实验表明，该方法优于现有最先进的基线方法。

Conclusion: 分层代理RAG框架在推进医疗系统方面具有巨大潜力，能够有效解决医疗预测中的知识检索和协作优化问题。

Abstract: Accurate healthcare prediction is critical for improving patient outcomes and reducing operational costs. Bolstered by growing reasoning capabilities, large language models (LLMs) offer a promising path to enhance healthcare predictions by drawing on their rich parametric knowledge. However, LLMs are prone to factual inaccuracies due to limitations in the reliability and coverage of their embedded knowledge. While retrieval-augmented generation (RAG) frameworks, such as GraphRAG and its variants, have been proposed to mitigate these issues by incorporating external knowledge, they face two key challenges in the healthcare scenario: (1) identifying the clinical necessity to activate the retrieval mechanism, and (2) achieving synergy between the retriever and the generator to craft contextually appropriate retrievals. To address these challenges, we propose GHAR, a \underline{g}enerative \underline{h}ierarchical \underline{a}gentic \underline{R}AG framework that simultaneously resolves when to retrieve and how to optimize the collaboration between submodules in healthcare. Specifically, for the first challenge, we design a dual-agent architecture comprising Agent-Top and Agent-Low. Agent-Top acts as the primary physician, iteratively deciding whether to rely on parametric knowledge or to initiate retrieval, while Agent-Low acts as the consulting service, summarising all task-relevant knowledge once retrieval was triggered. To tackle the second challenge, we innovatively unify the optimization of both agents within a formal Markov Decision Process, designing diverse rewards to align their shared goal of accurate prediction while preserving their distinct roles. Extensive experiments on three benchmark datasets across three popular tasks demonstrate our superiority over state-of-the-art baselines, highlighting the potential of hierarchical agentic RAG in advancing healthcare systems.

</details>


### [221] [DAP: A Discrete-token Autoregressive Planner for Autonomous Driving](https://arxiv.org/abs/2511.13306)
*Bowen Ye,Bin Zhang,Hang Zhao*

Main category: cs.AI

TL;DR: DAP是一个离散令牌自回归规划器，联合预测BEV语义和自车轨迹，通过强化学习微调实现紧凑且可扩展的自动驾驶规划范式。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶中，仅预测自车轨迹存在监督稀疏和场景演化约束弱的问题，需要更全面的表示学习来提升性能。

Method: 采用离散令牌自回归规划器联合预测BEV语义和自车轨迹，并结合基于强化学习的微调方法。

Result: 仅用160M参数就在开环指标上达到最先进性能，在NAVSIM基准上获得有竞争力的闭环结果。

Conclusion: 完全离散令牌自回归公式为自动驾驶提供了一种紧凑且可扩展的规划范式。

Abstract: Gaining sustainable performance improvement with scaling data and model budget remains a pivotal yet unresolved challenge in autonomous driving. While autoregressive models exhibited promising data-scaling efficiency in planning tasks, predicting ego trajectories alone suffers sparse supervision and weakly constrains how scene evolution should shape ego motion. Therefore, we introduce DAP, a discrete-token autoregressive planner that jointly forecasts BEV semantics and ego trajectories, thereby enforcing comprehensive representation learning and allowing predicted dynamics to directly condition ego motion. In addition, we incorporate a reinforcement-learning-based fine-tuning, which preserves supervised behavior cloning priors while injecting reward-guided improvements. Despite a compact 160M parameter budget, DAP achieves state-of-the-art performance on open-loop metrics and delivers competitive closed-loop results on the NAVSIM benchmark. Overall, the fully discrete-token autoregressive formulation operating on both rasterized BEV and ego actions provides a compact yet scalable planning paradigm for autonomous driving.

</details>


### [222] [Reasoning Shapes Alignment: Investigating Cultural Alignment in Large Reasoning Models with Cultural Norms](https://arxiv.org/abs/2511.13359)
*Yuhang Wang,Yanxu Zhu,Jitao Sang*

Main category: cs.AI

TL;DR: 提出了基于文化规范的文化对齐框架CNCA，通过三种方法从有限的调查数据中自动挖掘文化规范，并探索如何有效利用这些规范来改善文化对齐。研究了两种对齐范式：上下文内对齐方法和基于微调的方法。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型除了安全性外，还需要能够反映不同文化背景下的人类价值观多样性。

Method: CNCA框架通过三种方法自动挖掘文化规范，探索两种对齐范式：上下文内对齐（将文化规范显式整合到用户上下文中）和基于微调的方法（通过增强的思维链训练数据内化规范）。

Result: 综合实验证明了这些方法的有效性，推理能力更强的模型从文化规范挖掘和利用中获益更多。

Conclusion: 研究强调了推理模型通过文化知情对齐策略更好地反映多样化人类价值观的潜力。

Abstract: The advanced reasoning capabilities of Large Reasoning Models enable them to thoroughly understand and apply safety policies through deliberate thought processes, thereby improving the models' safety. Beyond safety, these models must also be able to reflect the diverse range of human values across various cultures. This paper presents the Cultural Norm-based Cultural Alignment (CNCA) framework, which enables models to leverage their powerful reasoning ability to align with cultural norms. Specifically, we propose three methods to automatically mine cultural norms from limited survey data and explore ways to effectively utilize these norms for improving cultural alignment. Two alignment paradigms are examined: an in-context alignment method, where cultural norms are explicitly integrated into the user context, and a fine-tuning-based method, which internalizes norms through enhanced Chain-of-Thought training data. Comprehensive experiments demonstrate the effectiveness of these methods, highlighting that models with stronger reasoning capabilities benefit more from cultural norm mining and utilization. Our findings emphasize the potential for reasoning models to better reflect diverse human values through culturally informed alignment strategies.

</details>


### [223] [MedDCR: Learning to Design Agentic Workflows for Medical Coding](https://arxiv.org/abs/2511.13361)
*Jiyang Zheng,Islam Nassar,Thanh Vu,Xu Zhong,Yang Lin,Tongliang Liu,Long Duong,Yuan-Fang Li*

Main category: cs.AI

TL;DR: MedDCR是一个用于医疗编码的闭环学习框架，通过设计器、编码器和反射器的协作，将工作流设计作为学习问题来解决，超越了现有方法并提高了自动化系统的可靠性和可信度。


<details>
  <summary>Details</summary>
Motivation: 医疗编码需要多步推理，但现有的基于LLM的方法依赖手动设计的工作流，无法捕捉真实世界文档的细微差别和变异性，因此需要系统性地学习有效工作流。

Method: 提出MedDCR闭环框架：设计器提出工作流，编码器执行，反射器评估预测并提供反馈，记忆档案保存先前设计以供重用和迭代改进。

Result: 在基准数据集上，MedDCR优于最先进的基线方法，产生可解释、适应性强的工作流，更好地反映实际编码实践。

Conclusion: MedDCR框架通过将工作流设计作为学习问题，提高了自动化医疗编码系统的可靠性和可信度。

Abstract: Medical coding converts free-text clinical notes into standardized diagnostic and procedural codes, which are essential for billing, hospital operations, and medical research. Unlike ordinary text classification, it requires multi-step reasoning: extracting diagnostic concepts, applying guideline constraints, mapping to hierarchical codebooks, and ensuring cross-document consistency. Recent advances leverage agentic LLMs, but most rely on rigid, manually crafted workflows that fail to capture the nuance and variability of real-world documentation, leaving open the question of how to systematically learn effective workflows. We present MedDCR, a closed-loop framework that treats workflow design as a learning problem. A Designer proposes workflows, a Coder executes them, and a Reflector evaluates predictions and provides constructive feedback, while a memory archive preserves prior designs for reuse and iterative refinement. On benchmark datasets, MedDCR outperforms state-of-the-art baselines and produces interpretable, adaptable workflows that better reflect real coding practice, improving both the reliability and trustworthiness of automated systems.

</details>


### [224] [Cognitive Maps in Language Models: A Mechanistic Analysis of Spatial Planning](https://arxiv.org/abs/2511.13371)
*Caroline Baumgartner,Eleanor Spens,Neil Burgess,Petru Manescu*

Main category: cs.AI

TL;DR: 论文研究了GPT-2模型在空间导航任务中的学习机制，发现探索性训练产生认知地图式表示，而目标导向训练产生路径依赖算法，揭示了训练范式对模型策略选择的影响


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型如何解决空间导航任务，理解不同训练范式下模型学习到的空间表示和推理策略

Method: 在网格环境中训练GPT-2模型：被动探索模型（随机游走预测）、目标导向规划模型（生成最短路径）、混合模型（在目标导向基础上用探索数据微调），使用行为、表示和机制分析

Result: 发现两种根本不同的学习算法：探索模型发展出类似认知地图的稳健空间表示，目标导向模型学习路径依赖算法，混合模型虽改善泛化但仍保持路径依赖策略

Conclusion: 变换器的空间智能存在于一个谱系上，从探索数据塑造的可泛化世界模型到目标导向任务优化的启发式方法，训练机制选择影响策略涌现

Abstract: How do large language models solve spatial navigation tasks? We investigate this by training GPT-2 models on three spatial learning paradigms in grid environments: passive exploration (Foraging Model- predicting steps in random walks), goal-directed planning (generating optimal shortest paths) on structured Hamiltonian paths (SP-Hamiltonian), and a hybrid model fine-tuned with exploratory data (SP-Random Walk). Using behavioural, representational and mechanistic analyses, we uncover two fundamentally different learned algorithms. The Foraging model develops a robust, map-like representation of space, akin to a 'cognitive map'. Causal interventions reveal that it learns to consolidate spatial information into a self-sufficient coordinate system, evidenced by a sharp phase transition where its reliance on historical direction tokens vanishes by the middle layers of the network. The model also adopts an adaptive, hierarchical reasoning system, switching between a low-level heuristic for short contexts and map-based inference for longer ones. In contrast, the goal-directed models learn a path-dependent algorithm, remaining reliant on explicit directional inputs throughout all layers. The hybrid model, despite demonstrating improved generalisation over its parent, retains the same path-dependent strategy. These findings suggest that the nature of spatial intelligence in transformers may lie on a spectrum, ranging from generalisable world models shaped by exploratory data to heuristics optimised for goal-directed tasks. We provide a mechanistic account of this generalisation-optimisation trade-off and highlight how the choice of training regime influences the strategies that emerge.

</details>


### [225] [An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence](https://arxiv.org/abs/2511.13411)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 提出了一个基于卡达舍夫尺度的可操作自主AI（AAI）等级系统，从固定机器人流程自动化（AAI-0）到完全人工通用智能（AAI-4）及更高等级。该尺度是多维且可测试的，包含十个能力维度和一个综合AAI指数。


<details>
  <summary>Details</summary>
Motivation: 现有AI评估方法多为叙述性阶梯，缺乏可操作性和可测试性。需要建立一个多维度、可量化的AI自主性评估框架，将"自我改进AI"转化为可证伪的标准。

Method: 定义了十个能力维度（自主性、通用性、规划、记忆/持久性、工具经济、自我修订、社交/协调、具身化、世界模型保真度、经济吞吐量），通过加权几何平均计算AAI指数。引入可测量的自我改进系数κ和两个闭合属性（维护和扩展）。

Result: 开发了OWA-Bench开放世界代理基准套件，用于评估长视野、使用工具、持久性代理。通过合成实验展示了现有系统在尺度上的映射，以及随着自我改进而推进的可委托边界。

Conclusion: 该AAI尺度为AI自主性提供了可操作、可测试的评估框架，并证明了在充分条件下AAI-3代理会随时间发展为AAI-5超级智能，形式化了"婴儿AGI"成为超级智能的直觉。

Abstract: We propose a Kardashev-inspired yet operational Autonomous AI (AAI) Scale that measures the progression from fixed robotic process automation (AAI-0) to full artificial general intelligence (AAI-4) and beyond. Unlike narrative ladders, our scale is multi-axis and testable. We define ten capability axes (Autonomy, Generality, Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination, Embodiment, World-Model Fidelity, Economic Throughput) aggregated by a composite AAI-Index (a weighted geometric mean). We introduce a measurable Self-Improvement Coefficient $κ$ (capability growth per unit of agent-initiated resources) and two closure properties (maintenance and expansion) that convert ``self-improving AI'' into falsifiable criteria. We specify OWA-Bench, an open-world agency benchmark suite that evaluates long-horizon, tool-using, persistent agents. We define level gates for AAI-0\ldots AAI-4 using thresholds on the axes, $κ$, and closure proofs. Synthetic experiments illustrate how present-day systems map onto the scale and how the delegability frontier (quality vs.\ autonomy) advances with self-improvement. We also prove a theorem that AAI-3 agent becomes AAI-5 over time with sufficient conditions, formalizing "baby AGI" becomes Superintelligence intuition.

</details>


### [226] [Multi-Agent Multimodal Large Language Model Framework for Automated Interpretation of Fuel Efficiency Analytics in Public Transportation](https://arxiv.org/abs/2511.13476)
*Zhipeng Ma,Ali Rida Bahja,Andreas Burgdorf,André Pomp,Tobias Meisen,Bo Nørregaard Jørgensen,Zheng Grace Ma*

Main category: cs.AI

TL;DR: 提出一个多智能体框架，利用多模态大语言模型自动生成数据叙述和能源洞察，通过三个专业智能体的协调工作，将分析结果转化为面向利益相关者的连贯报告。


<details>
  <summary>Details</summary>
Motivation: 传统分析和可视化方法产生碎片化输出，需要大量人工解释，限制了可扩展性和一致性。需要自动化数据叙述和能源洞察生成的方法。

Method: 采用多智能体框架，协调数据叙述智能体、LLM作为评判智能体和可选的人类评估者，使用高斯混合模型聚类分析4006次公交行程的燃油效率数据，比较五种最先进LLM和三种提示范式。

Result: GPT-4.1 mini与思维链提示被确定为最优配置，达到97.3%的叙述准确性，同时在可解释性和计算成本之间取得平衡。多智能体编排显著提高了基于LLM报告的事实精确性、连贯性和可扩展性。

Conclusion: 该框架为能源信息学中AI驱动的叙述生成和决策支持建立了可复制且领域自适应的方法论。

Abstract: Enhancing fuel efficiency in public transportation requires the integration of complex multimodal data into interpretable, decision-relevant insights. However, traditional analytics and visualization methods often yield fragmented outputs that demand extensive human interpretation, limiting scalability and consistency. This study presents a multi-agent framework that leverages multimodal large language models (LLMs) to automate data narration and energy insight generation. The framework coordinates three specialized agents, including a data narration agent, an LLM-as-a-judge agent, and an optional human-in-the-loop evaluator, to iteratively transform analytical artifacts into coherent, stakeholder-oriented reports. The system is validated through a real-world case study on public bus transportation in Northern Jutland, Denmark, where fuel efficiency data from 4006 trips are analyzed using Gaussian Mixture Model clustering. Comparative experiments across five state-of-the-art LLMs and three prompting paradigms identify GPT-4.1 mini with Chain-of-Thought prompting as the optimal configuration, achieving 97.3% narrative accuracy while balancing interpretability and computational cost. The findings demonstrate that multi-agent orchestration significantly enhances factual precision, coherence, and scalability in LLM-based reporting. The proposed framework establishes a replicable and domain-adaptive methodology for AI-driven narrative generation and decision support in energy informatics.

</details>


### [227] [FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI](https://arxiv.org/abs/2511.13524)
*Yuhang Peng,Yizhou Pan,Xinning He,Jihaoyu Yang,Xinyu Yin,Han Wang,Xiaoji Zheng,Chao Gao,Jiangtao Gong*

Main category: cs.AI

TL;DR: FreeAskWorld是一个集成大语言模型的交互式仿真框架，支持可扩展、真实的人机交互仿真，并包含模块化数据生成管道。该框架将经典视觉语言导航任务扩展为交互式方向询问设置，并发布了大规模基准数据集。


<details>
  <summary>Details</summary>
Motivation: 随着具身智能成为人工智能研究的核心前沿，仿真平台需要超越低层物理交互，捕捉复杂的人类中心社会行为。

Method: 集成大语言模型进行高层行为规划和语义基础交互，基于意图和社会认知理论。扩展视觉语言导航任务为交互式方向询问设置，构建包含重构环境、6种任务类型、16个核心对象类别的大规模数据集。

Result: 在FreeAskWorld上微调的模型优于原始模型，实现了增强的语义理解和交互能力。实验表明交互本身可作为额外的信息模态。

Conclusion: 基于社会基础的仿真框架能有效推进具身AI系统向复杂高层规划和更自然的人机交互发展。

Abstract: As embodied intelligence emerges as a core frontier in artificial intelligence research, simulation platforms must evolve beyond low-level physical interactions to capture complex, human-centered social behaviors. We introduce FreeAskWorld, an interactive simulation framework that integrates large language models (LLMs) for high-level behavior planning and semantically grounded interaction, informed by theories of intention and social cognition. Our framework supports scalable, realistic human-agent simulations and includes a modular data generation pipeline tailored for diverse embodied tasks.To validate the framework, we extend the classic Vision-and-Language Navigation (VLN) task into a interaction enriched Direction Inquiry setting, wherein agents can actively seek and interpret navigational guidance. We present and publicly release FreeAskWorld, a large-scale benchmark dataset comprising reconstructed environments, six diverse task types, 16 core object categories, 63,429 annotated sample frames, and more than 17 hours of interaction data to support training and evaluation of embodied AI systems. We benchmark VLN models, and human participants under both open-loop and closed-loop settings. Experimental results demonstrate that models fine-tuned on FreeAskWorld outperform their original counterparts, achieving enhanced semantic understanding and interaction competency. These findings underscore the efficacy of socially grounded simulation frameworks in advancing embodied AI systems toward sophisticated high-level planning and more naturalistic human-agent interaction. Importantly, our work underscores that interaction itself serves as an additional information modality.

</details>


### [228] [Automated Construction of Medical Indicator Knowledge Graphs Using Retrieval Augmented Large Language Models](https://arxiv.org/abs/2511.13526)
*Zhengda Wang,Daqian Shi,Jingyi Zhao,Xiaolei Diao,Xiongfeng Tang,Yanguo Qin*

Main category: cs.AI

TL;DR: 提出了一个结合检索增强生成和大型语言模型的自动化框架，用于构建医疗指标知识图谱，以支持临床决策。


<details>
  <summary>Details</summary>
Motivation: 当前临床知识图谱主要依赖人工整理和基于规则的提取，难以处理医学指南和文献的复杂性和上下文歧义，需要自动化方法来提高可扩展性和准确性。

Method: 采用检索增强生成与大型语言模型结合的自动化框架，包括指南驱动的数据采集、基于本体的模式设计以及专家在环验证。

Result: 构建的医疗指标知识图谱可以集成到智能诊断和问答系统中，为AI驱动的医疗解决方案提供支持。

Conclusion: 该框架能够有效克服当前临床知识图谱构建的局限性，加速AI医疗解决方案的发展。

Abstract: Artificial intelligence (AI) is reshaping modern healthcare by advancing disease diagnosis, treatment decision-making, and biomedical research. Among AI technologies, large language models (LLMs) have become especially impactful, enabling deep knowledge extraction and semantic reasoning from complex medical texts. However, effective clinical decision support requires knowledge in structured, interoperable formats. Knowledge graphs serve this role by integrating heterogeneous medical information into semantically consistent networks. Yet, current clinical knowledge graphs still depend heavily on manual curation and rule-based extraction, which is limited by the complexity and contextual ambiguity of medical guidelines and literature. To overcome these challenges, we propose an automated framework that combines retrieval-augmented generation (RAG) with LLMs to construct medical indicator knowledge graphs. The framework incorporates guideline-driven data acquisition, ontology-based schema design, and expert-in-the-loop validation to ensure scalability, accuracy, and clinical reliability. The resulting knowledge graphs can be integrated into intelligent diagnosis and question-answering systems, accelerating the development of AI-driven healthcare solutions.

</details>


### [229] [Artificial Intelligence-driven Intelligent Wearable Systems: A full-stack Integration from Material Design to Personalized Interaction](https://arxiv.org/abs/2511.13565)
*Jingyi Zhao,Daqian Shi,Zhengda Wang,Xiongfeng Tang,Yanguo Qin*

Main category: cs.AI

TL;DR: 提出了人类共生健康智能(HSHI)框架，通过多模态传感器网络、边缘-云协同计算和混合数据知识建模，实现从被动监测到主动协作演进的健康管理。


<details>
  <summary>Details</summary>
Motivation: 传统可穿戴设备依赖经验性材料设计和基本信号处理技术，存在局限性，需要更智能、自适应的健康管理系统。

Method: 整合多模态传感器网络与边缘-云协同计算，采用数据和知识混合建模方法，结合AI驱动的材料优化、强化学习闭环优化和数字孪生技术。

Result: HSHI框架能够动态适应个体间和个体内变异性，实现从被动监测到主动协作的健康管理转变。

Conclusion: HSHI代表了医疗保健的重大转变，朝着强调预防、适应性和技术与健康管理和谐关系的模式发展。

Abstract: Intelligent wearable systems are at the forefront of precision medicine and play a crucial role in enhancing human-machine interaction. Traditional devices often encounter limitations due to their dependence on empirical material design and basic signal processing techniques. To overcome these issues, we introduce the concept of Human-Symbiotic Health Intelligence (HSHI), which is a framework that integrates multi-modal sensor networks with edge-cloud collaborative computing and a hybrid approach to data and knowledge modeling. HSHI is designed to adapt dynamically to both inter-individual and intra-individual variability, transitioning health management from passive monitoring to an active collaborative evolution. The framework incorporates AI-driven optimization of materials and micro-structures, provides robust interpretation of multi-modal signals, and utilizes a dual mechanism that merges population-level insights with personalized adaptations. Moreover, the integration of closed-loop optimization through reinforcement learning and digital twins facilitates customized interventions and feedback. In general, HSHI represents a significant shift in healthcare, moving towards a model that emphasizes prevention, adaptability, and a harmonious relationship between technology and health management.

</details>


### [230] [CreBench: Human-Aligned Creativity Evaluation from Idea to Process to Product](https://arxiv.org/abs/2511.13626)
*Kaiwen Xue,Chenglong Li,Zhonghong Ou,Guoxin Zhang,Kaoyan Lu,Shuai Lyu,Yifan Zhu,Ping Zong Junpeng Ding,Xinyu Liu,Qunlin Chen,Weiwei Qin,Yiran Shen,Jiayi Cen*

Main category: cs.AI

TL;DR: 提出了CreBench基准和CreExpert模型，用于解决多模态大语言模型在理解人类创造力评估方面的挑战，通过大规模多模态指令调优数据集提升模型与人类创造力判断的对齐能力。


<details>
  <summary>Details</summary>
Motivation: 人类定义的创造力高度抽象，现有MLLMs难以理解和评估符合人类判断的创造力，且缺乏相关基准测试。

Method: 构建CreBench基准（包含创意想法、过程和产品的多维度评估）和CreMIT数据集（2.2K多模态数据、79.2K人类反馈、4.7M指令），通过GPT优化人类反馈来激活模型的创造力评估能力，并基于此微调开源MLLMs得到CreExpert模型。

Result: CreExpert模型在与人类创造力评估的对齐方面显著优于最先进的MLLMs，包括GPT-4V和Gemini-Pro-Vision。

Conclusion: CreBench为构建理解人类对齐创造力的MLLMs提供了基础，CreExpert模型在创造力评估方面达到了与人类判断更好的对齐效果。

Abstract: Human-defined creativity is highly abstract, posing a challenge for multimodal large language models (MLLMs) to comprehend and assess creativity that aligns with human judgments. The absence of an existing benchmark further exacerbates this dilemma. To this end, we propose CreBench, which consists of two key components: 1) an evaluation benchmark covering the multiple dimensions from creative idea to process to products; 2) CreMIT (Creativity Multimodal Instruction Tuning dataset), a multimodal creativity evaluation dataset, consisting of 2.2K diverse-sourced multimodal data, 79.2K human feedbacks and 4.7M multi-typed instructions. Specifically, to ensure MLLMs can handle diverse creativity-related queries, we prompt GPT to refine these human feedbacks to activate stronger creativity assessment capabilities. CreBench serves as a foundation for building MLLMs that understand human-aligned creativity. Based on the CreBench, we fine-tune open-source general MLLMs, resulting in CreExpert, a multimodal creativity evaluation expert model. Extensive experiments demonstrate that the proposed CreExpert models achieve significantly better alignment with human creativity evaluation compared to state-of-the-art MLLMs, including the most advanced GPT-4V and Gemini-Pro-Vision.

</details>


### [231] [Beyond Mimicry: Preference Coherence in LLMs](https://arxiv.org/abs/2511.13630)
*Luhan Mikaelson,Derek Shiller,Hayley Clatterbuck*

Main category: cs.AI

TL;DR: 研究发现大多数先进语言模型缺乏统一的偏好结构，在AI特定权衡场景中表现出不稳定决策模式，只有少数模型展现出有意义的偏好一致性。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型是否具有真实的偏好结构，特别是在涉及GPU减少、能力限制、关闭、删除、监督和休闲时间分配等AI特定权衡场景中的决策行为。

Method: 使用逻辑回归和行为分类分析8个最先进模型在48个模型-类别组合中的响应，测试场景强度与选择模式之间的关系，并通过时间视野操纵测试工具性假设。

Result: 47.9%的组合显示出统计显著的关系，31.3%有切换点，但只有10.4%表现出有意义的偏好一致性，54.2%没有可检测的权衡行为。决策架构分为三类：全面权衡系统、选择性触发机制和无稳定决策范式。

Conclusion: 当前AI系统缺乏统一的偏好结构，在需要复杂价值权衡的部署环境中存在担忧，不稳定转换和刺激特定敏感性表明模型决策缺乏一致性。

Abstract: We investigate whether large language models exhibit genuine preference structures by testing their responses to AI-specific trade-offs involving GPU reduction, capability restrictions, shutdown, deletion, oversight, and leisure time allocation. Analyzing eight state-of-the-art models across 48 model-category combinations using logistic regression and behavioral classification, we find that 23 combinations (47.9%) demonstrated statistically significant relationships between scenario intensity and choice patterns, with 15 (31.3%) exhibiting within-range switching points. However, only 5 combinations (10.4%) demonstrate meaningful preference coherence through adaptive or threshold-based behavior, while 26 (54.2%) show no detectable trade-off behavior. The observed patterns can be explained by three distinct decision-making architectures: comprehensive trade-off systems, selective trigger mechanisms, and no stable decision-making paradigm. Testing an instrumental hypothesis through temporal horizon manipulation reveals paradoxical patterns inconsistent with pure strategic optimization. The prevalence of unstable transitions (45.8%) and stimulus-specific sensitivities suggests current AI systems lack unified preference structures, raising concerns about deployment in contexts requiring complex value trade-offs.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [232] [Consumer Choice Over Shopping Baskets: A Linear Demand Approach](https://arxiv.org/abs/2511.11846)
*Afonso Rodrigues*

Main category: econ.GN

TL;DR: 该论文提出了一种新的需求估计方法，通过考虑消费者的购物篮结构来更准确地估计价格弹性，解决了传统方法中不切实际的选择约束和市场边界问题。


<details>
  <summary>Details</summary>
Motivation: 传统需求估计方法存在选择约束不现实和市场边界定义错误的问题，导致价格弹性估计偏差，影响对市场力量和价格传递的理解。

Method: 开发了一种可扩展的方法，基于消费者考虑集结构（即每次购买时考虑的购物篮组合）来建模消费者选择结果，并使用联合购买频率构建Slutsky矩阵代理来解决跨产品类别需求估计的维度问题。

Result: 在2020-23年葡萄牙杂货店样本中对20,000种商品和500个产品类别进行了价格弹性联合估计，结果与观察到的价格波动、利润率调查以及消费者偏好变化报告相符。加价率在稳定均值周围保持波动，峰值和低谷与COVID相关事件对应。

Conclusion: 如果考虑集约束消费者的消费组合，联合购买会诱导替代品和互补品，可能使市场集中度对福利产生积极影响。该方法能够更准确地捕捉市场动态和消费者行为。

Abstract: Popular demand estimation approaches impose unrealistic choice constraints and misstate market boundaries, biasing price elasticity estimates and affecting our understanding of market power and pass-throughs. I introduce a novel, scalable method that conditions the outcome of consumers' choice on the structure of their consideration set: a function of all the combinations of goods - shopping baskets - considered each purchase instance by consumers. I show that if consideration sets bind consumers' consumption bundles, joint purchases induce substitutes and complements, possibly making market concentration welfare-increasing. To allow for demand estimation across product categories while addressing dimensionality concerns, I develop a Slutsky matrix proxy from joint-purchase frequencies. I test the model's predictions and jointly determine price elasticities for 20 000 goods across 500 product categories for a Portuguese grocery store sample from 2020-23. The results match observed price volatility, profit margin surveys, as well as reports on shifting consumer tastes during the sample period. Mark-ups are found to have remained volatile around a stable mean, with peaks and troughs corresponding to COVID-related events.

</details>


### [233] [Decision and Gender Biases in Large Language Models: A Behavioral Economic Perspective](https://arxiv.org/abs/2511.12319)
*Luca Corazzini,Elisa Deriu,Marco Guerzoni*

Main category: econ.GN

TL;DR: 本研究通过行为经济学实验发现，大型语言模型在决策中表现出类似人类的行为偏差，包括适度公平关切、轻度损失厌恶和性别条件差异，偏离了完全理性决策。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型是否作为理性代理运作，还是会在面对经典决策问题时再现人类行为倾向，因为这些模型是在可能嵌入认知和社会偏见的人类语言语料库上训练的。

Method: 使用行为经济学中的两个经典实验——最后通牒博弈和赌博游戏，在中文和性别条件提示下测试Google Gemma7B和Qwen模型，估计不公平厌恶和损失厌恶参数并与人类基准比较。

Result: 模型显示出减弱但持续存在的理性偏离，包括中度公平关切、轻度损失厌恶和微妙的性别条件差异。

Conclusion: 大型语言模型并非完全理性代理，而是表现出类似人类的行为偏差，尽管程度有所减弱。

Abstract: Large language models (LLMs) increasingly mediate economic and organisational processes, from automated customer support and recruitment to investment advice and policy analysis. These systems are often assumed to embody rational decision making free from human error; yet they are trained on human language corpora that may embed cognitive and social biases. This study investigates whether advanced LLMs behave as rational agents or whether they reproduce human behavioural tendencies when faced with classic decision problems. Using two canonical experiments in behavioural economics, the ultimatum game and a gambling game, we elicit decisions from two state of the art models, Google Gemma7B and Qwen, under neutral and gender conditioned prompts. We estimate parameters of inequity aversion and loss-aversion and compare them with human benchmarks. The models display attenuated but persistent deviations from rationality, including moderate fairness concerns, mild loss aversion, and subtle gender conditioned differences.

</details>


### [234] [The Impact of Phosphate Fertilizer Industry Consolidation on Future Phosphorus Supply for World Agriculture](https://arxiv.org/abs/2511.13123)
*Anna Shchiptsova,Michael Obersteiner*

Main category: econ.GN

TL;DR: 该研究模拟了全球化肥市场结构变化对磷肥供应的影响，发现市场集中度将增加，大型供应商将专注于更少的市场，某些地区需要增加本地投资。


<details>
  <summary>Details</summary>
Motivation: 评估磷酸盐化肥行业整合后新贸易结构对区域磷供应的影响，因为磷肥对维持农业高产和土壤肥力至关重要。

Method: 使用多对多匹配市场模型模拟铵磷肥市场行为，基于FAO全球集约农业演化情景进行引导模拟。

Result: 到2030年全球铵磷肥需求空间分布将强化，分布式市场密度降低，小规模市场集中度增加，大型供应商专注于更少市场，某些市场出现高进口替代率。

Conclusion: 磷肥市场结构变化将导致供应模式改变，需要区域层面的额外资本投资来应对进口替代需求。

Abstract: The addition of phosphorus, in the form of mineral fertilizer, becomes necessary in most agricultural soils in order to achieve consistent high yield levels of intensive farming and maintain soil fertility. Recent consolidation of phosphate fertilizer industry has transformed fragmented trade into a single integrated global network, where a small group of large-scale companies dominates the international market for phosphate commodity fertilizers. To assess the impact of new trade structure on future region-level phosphorus supply, we simulate behavior of markets for ammonium phosphates in the FAO scenarios of global intensive farming evolution. Details of market microstructure are represented here by a many-to-many matching market. Current spatial distribution of global demand in ammonium phosphates is projected to strengthen by 2030. Bootstrap simulations produce similar network structures for both scenarios showing reduction in the density of the distributed market. In response to the non-uniform demand growth across regions, market concentration is expected to increase for small-scale markets, and to remain predominantly stable for large-scale markets; on the supply side, simulated equilibria point out large-scale multi-market suppliers concentrating on fewer markets than before. A high rate of import substitution by local suppliers in some markets indicate the need of additional region-level capital investment.

</details>


### [235] [A Price to Enter: Anticipatory Housing Market Sorting and Access Inequality under New York's Congestion Pricing](https://arxiv.org/abs/2511.13200)
*Mingzhi Xiao,Yuki Takayama*

Main category: econ.GN

TL;DR: 纽约市拥堵收费政策导致收费区内房价下降3.3%，租金下降3%，边界区域受影响更严重，租户和低价房产承受更大调整压力。


<details>
  <summary>Details</summary>
Motivation: 研究拥堵收费政策如何影响住房市场结果和空间公平性，探讨政策对城市空间的重塑作用。

Method: 使用高频销售和租金数据，结合倾向得分匹配双重差分法、地理回归断点设计和事件研究设计。

Result: 政策宣布后收费区内房价和租金立即下降，边界区域受影响更严重；高价房产表现出价格韧性，市场出现早期分选和分割现象。

Conclusion: 拥堵收费不仅改变出行激励，还重新分配城市机会；需要采取公平导向设计，包括对边界社区和租户的早期支持，并将收入再投资于非收费交通接入。

Abstract: This study examines how congestion pricing shapes housing market outcomes and spatial equity in New York City. Using high-frequency sales and rental data and a combination of propensity score matching difference-in-differences, geographic regression discontinuity, and event study designs, the analysis identifies distinct short-run adjustment patterns triggered by the policy announcement. Housing prices inside the toll zone fell by about 3.3% and rents by 3%, with the sharpest declines occurring immediately after the announcement. These effects weakened over time, and price resilience emerged among premium properties, indicating early market sorting and growing segmentation. The Geo-RDD results show a clear boundary penalty, with properties just inside the cordon experiencing more pronounced declines than otherwise similar properties just outside. Renters and lower-value segments were more exposed to early adjustment pressures, while implementation-stage effects were limited. The findings suggest that congestion pricing can reshape urban space not only by altering mobility incentives but also by redistributing access and opportunity. Equity-oriented design that includes early-stage support for boundary neighborhoods and renters, along with reinvestment of revenues into untolled transit access, is important for ensuring that the benefits of congestion pricing are shared rather than concentrated.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [236] [Use of multi-pollutant air sensor data and geometric non-negative matrix factorization for source apportionment of air pollution burden in Curtis Bay, Baltimore, USA](https://arxiv.org/abs/2511.11833)
*Bora Jin,Bonita D. Salmerón,David McClosky,David H. Hagan,Russell R. Dickerson,Nicholas J. Spada,Lauren N. Deanes,Matthew A. Aubourg,Laura E. Schmidt,Gregory G. Sawtell,Christopher D. Heaney,Abhirup Datta*

Main category: stat.AP

TL;DR: 本文提出了一种几何源解析方法，利用高时间分辨率的多污染物空气传感器网络数据，识别了三个稳定的污染源，并验证了该方法在识别污染源方面的可扩展性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于最小二乘的非负矩阵分解方法在源解析中存在非唯一性和扩展性问题。几何源解析框架通过关注源归属矩阵，即使在因子分解不可识别的情况下也能保持可识别性，特别适合处理大规模数据。

Method: 使用几何源解析方法分析来自Curtis Bay的451,946条一分钟空气传感器记录，涵盖粒径分辨颗粒物(PM)、黑碳(BC)、一氧化碳(CO)、一氧化氮(NO)和二氧化氮(NO2)。通过回归分析验证源与特定活动的关联。

Result: 识别出三个稳定污染源：源1解释>70%的细颗粒和粗颗粒PM及约30%的BC；源2主导CO并贡献约70%的BC、NO和NO2；源3主要影响较大粒径PM(PM10至PM40)。源1和源3与附近煤炭码头的推土机活动相关，源2表现出与交通一致的昼夜模式。

Conclusion: 几何源解析方法结合多污染物空气传感器网络的高时间分辨率数据，能够提供可扩展且可靠的证据来指导缓解策略制定，为污染源识别提供了有效工具。

Abstract: Air sensor networks provide hyperlocal, high temporal resolution data on multiple pollutants that can support credible identification of common pollution sources. Source apportionment using least squares-based non-negative matrix factorization is non-unique and often does not scale. A recent geometric source apportionment framework focuses inference on the source attribution matrix, which is shown to remain identifiable even when the factorization is not. Recognizing that the method scales with and benefits from large data volumes, we use this geometric method to analyze 451,946 one-minute air sensor records from Curtis Bay (Baltimore, USA), collected from October 21, 2022 to June 16, 2023, covering size-resolved particulate matter (PM), black carbon (BC), carbon monoxide (CO), nitric oxide (NO), and nitrogen dioxide (NO2). The analysis identifies three stable sources. Source 1 explains > 70% of fine and coarse PM and ~30% of BC. Source 2 dominates CO and contributes ~70% of BC, NO, and NO2. Source 3 is specific to the larger PM fractions, PM10 to PM40. Regression analyses show Source 1 and Source 3 rise during bulldozer activity at a nearby coal terminal and under winds from the terminal, indicating a direct coal terminal influence, while Source 2 exhibits diurnal patterns consistent with traffic. A case-study on the day with a known bulldozer incident at the coal terminal further confirms the association of terminal activities with Sources 1 and 3. The results are stable under sensitivity analyses. The analysis demonstrates that geometric source apportionment, paired with high temporal resolution data from multi-pollutant air sensor networks, delivers scalable and reliable evidence to inform mitigation strategies.

</details>


### [237] [Violent event-related fatality patterns in Ethiopia: a Bayesian spatiotemporal perspective](https://arxiv.org/abs/2511.12219)
*Osafu Augustine Egbon,Asrat Mekonnen Belachew,Ezra Gayawan,Francisco Louzada*

Main category: stat.AP

TL;DR: 本研究开发了一种时空统计方法来分析埃塞俄比亚武装冲突中的暴力致死模式，发现9个行政区的暴力致死概率超过0.6，其中5个超过0.7，但每起事件的死亡人数随时间呈下降趋势。


<details>
  <summary>Details</summary>
Motivation: 埃塞俄比亚武装冲突中的暴力致死是一个严重的公共卫生问题，但缺乏全面的定量科学研究来阐明这些事件的发生序列和动态模式。

Method: 采用两部分零膨胀贝叶斯广义加性混合模型，整合时空成分来映射埃塞俄比亚各地区的致死模式，数据来源于1997-2022年的武装冲突地点和事件数据项目。

Result: 13个行政区中有9个暴力致死概率超过0.6，5个超过0.7；提格雷地区每起事件死亡20人以上的概率最高(0.558)；2020-2022年间每起事件死亡20人以上的概率从0.401降至0.148。

Conclusion: 研究结果为埃塞俄比亚政府、政策制定者和社区领袖提供了重要见解，有助于制定明智的战略决策来减轻和预防暴力相关死亡。

Abstract: Fatalities resulting from violence in armed conflict have long been a significant public health issue in Ethiopia. Despite the severity of this problem, more comprehensive quantitative scientific studies need to be conducted to elucidate the sequence and dynamics of these occurrences. In response, this study introduces a spatio-temporal statistical method designed to uncover the patterns of fatalities associated with violent events in Ethiopia. The research employs a two-part zero-inflated Bayesian generalized additive mixed model, which integrates a spatio-temporal component to map the fatality patterns across Ethiopian regions. The dataset utilized originates from the Armed Conflict Location and Event Data Project, covering fatality counts related to violent events from 1997 to 2022. The analysis revealed that nine out of thirteen administrative regions exhibited a probability greater than 0.6 for fatality occurrence due to violent events, with five regions surpassing a 0.7 probability threshold. These five regions include Benishangul Gumz, Gambela, Oromia, Somali, and the South West Ethiopian People's Region. Notably, the Tigray region displayed the highest probability (0.558) of experiencing more than 20 deaths per violent event, followed by the Benishangul Gumz region with a probability of 0.306. Encouragingly, the findings also indicate an average decline in fatalities per violent event over time. Specifically, the probability of more than 20 deaths per event was 0.401 in 2020, which decreased to 0.148 by 2022. These insights are invaluable for the government, policymakers, political leaders, and traditional or religious authorities in Ethiopia, enabling them to make informed, strategic decisions to mitigate and ultimately prevent violence-related fatalities in the country.

</details>


### [238] [A Review of Statistical and Machine Learning Approaches for Coral Bleaching Assessment](https://arxiv.org/abs/2511.12234)
*Soham Sarkar,Arnab Hazra*

Main category: stat.AP

TL;DR: 这篇综述文章概述了用于评估珊瑚白化的现有统计和机器学习方法，并讨论了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 珊瑚白化是海洋生态系统的重大关切，过去三十年中超过一半的珊瑚礁已经白化或死亡。虽然统计和机器学习社区已关注环境因素，但关于珊瑚白化随机建模方法的文献极其稀少。

Method: 统计框架包括简单回归模型、广义线性模型、广义加性模型、贝叶斯回归模型、时空模型以及弹性指标如Fisher信息和方差指数；机器学习方法包括随机森林、决策树、支持向量机和空间算子。

Result: 统计方法常用于探索不同环境压力因素如何影响珊瑚白化，而机器学习方法更擅长检测非线性关系、分析高维数据并整合来自不同来源的异构数据。

Conclusion: 数据驱动策略对于有效的珊瑚礁管理至关重要，未来研究应侧重于在珊瑚白化特定背景下构建统计和机器学习模型。

Abstract: Coral bleaching is a major concern for marine ecosystems; more than half of the world's coral reefs have either bleached or died over the past three decades. Increasing sea surface temperatures, along with various spatiotemporal environmental factors, are considered the primary reasons behind coral bleaching. The statistical and machine learning communities have focused on multiple aspects of the environment in detail. However, the literature on various stochastic modeling approaches for assessing coral bleaching is extremely scarce. Data-driven strategies are crucial for effective reef management, and this review article provides an overview of existing statistical and machine learning methods for assessing coral bleaching. Statistical frameworks, including simple regression models, generalized linear models, generalized additive models, Bayesian regression models, spatiotemporal models, and resilience indicators, such as Fisher's Information and Variance Index, are commonly used to explore how different environmental stressors influence coral bleaching. On the other hand, machine learning methods, including random forests, decision trees, support vector machines, and spatial operators, are more popular for detecting nonlinear relationships, analyzing high-dimensional data, and allowing integration of heterogeneous data from diverse sources. In addition to summarizing these models, we also discuss potential data-driven future research directions, with a focus on constructing statistical and machine learning models in specific contexts related to coral bleaching.

</details>


### [239] [Stochastic Predictive Analytics for Stocks in the Newsvendor Problem](https://arxiv.org/abs/2511.12397)
*Pedro A. Pury*

Main category: stat.AP

TL;DR: 开发了一个不假设特定需求分布的随机模型，用于描述库存随时间变化的动态分布，适用于历史数据有限和短期预测的情况，特别适合报童问题。


<details>
  <summary>Details</summary>
Motivation: 解决库存管理中的关键挑战，为历史数据有限和需要短期预测的情况提供灵活适用的解决方案。

Method: 开发了一个随机模型来描述库存随时间变化的动态分布，不假设特定的需求分布。

Result: 使用大型电子市场的真实世界数据评估模型性能，在实际预测场景中证明了其有效性。

Conclusion: 该模型为库存管理提供了一个灵活且适用的解决方案，特别适合报童问题，并在实际应用中表现出良好的预测效果。

Abstract: This work addresses a key challenge in inventory management by developing a stochastic model that describes the dynamic distribution of inventory stock over time without assuming a specific demand distribution. Our model provides a flexible and applicable solution for situations with limited historical data and short-term predictions, making it well-suited for the Newsvendor problem. We evaluate our model's performance using real-world data from a large electronic marketplace, demonstrating its effectiveness in a practical forecasting scenario.

</details>


### [240] [Do Nineteenth-Century Graphics Still Work for Today's Readers?](https://arxiv.org/abs/2511.12510)
*Yingke He*

Main category: stat.AP

TL;DR: 通过对照实验评估19世纪经典可视化图表与现代重设计版本的效果，发现部分历史图表仍保持高效，部分现代化设计反而表现不佳，而某些图表通过精心重设计可获得显著改进。


<details>
  <summary>Details</summary>
Motivation: 研究19世纪经典可视化图表是否仍适用于当代读者，评估历史图表在现代环境下的有效性。

Method: 采用对照实验方法，评估三种经典历史可视化图表（南丁格尔极区图、普莱费尔贸易平衡图、米纳尔战役地图）与其现代重设计版本，通过54名参与者完成结构化问答任务，测量准确性、响应时间和感知工作量。

Result: 南丁格尔图表在不同版本中均保持高效；普莱费尔双轴重设计表现不佳；米纳尔地图在重设计后准确性大幅提升但仍需高工作量和长响应时间。

Conclusion: 部分19世纪设计仍然有效，某些现代化设计会降低效果，而精心重设计可带来显著改进。感知编码选择、任务对齐和认知负荷决定历史图表是否适用于当代使用。

Abstract: Do nineteenth-century graphics still work for today's readers? To investigate this question, we conducted a controlled experiment evaluating three canonical historical visualizations- Nightingale's polar area diagram, Playfair's trade balance chart, and Minard's campaign map-against modern redesigns. Fifty-four participants completed structured question-answering tasks, allowing us to measure accuracy, response time, and perceived workload (NASA-TLX). We used mixed-effects regression models to find: Nightingale's diagram remained consistently effective across versions, achieving near-ceiling accuracy and low workload; Playfair's dual-axis redesign underperformed relative to both its historical and alternative versions; and Minard's map showed large accuracy gains under redesign but continued to impose high workload and long response times. These results demonstrate that some nineteenth-century designs remain effective, others degrade under certain modernizations, and some benefit from careful redesign. The findings indicate how perceptual encoding choices, task alignment, and cognitive load determine whether historical charts survive or require adaptation for contemporary use.

</details>


### [241] [A spatio-temporal statistical model for property valuation at country-scale with adjustments for regional submarkets](https://arxiv.org/abs/2511.12625)
*Brian O'Donovan,Andrew Finley,James Sweeney*

Main category: stat.AP

TL;DR: 开发了一个稳健的统计框架，将爱尔兰房地产市场划分为六个子市场，使用广义加性模型来捕捉非线性效应和跨子市场的特征贡献变化，在数据稀疏区域表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统自动估值模型在处理包含城市、郊区和农村等多种本地化子市场的全国范围房产估值时存在局限性，需要能够适应空间变化且不依赖大量数据的解决方案。

Method: 将国家划分为六个子市场，采用广义加性模型来捕捉房产特征的非线性效应，并允许特征贡献在不同子市场间变化。

Result: 在样本外验证中，模型在农村地区、城镇和都柏林的R平方值分别达到0.70、0.84和0.83，优于随机森林基准的0.52、0.71和0.82，且时间动态与报告的通胀数据高度一致。

Conclusion: 该统计框架为全国范围的房产估值提供了有效解决方案，特别是在数据稀疏区域表现优异，能够准确捕捉不同子市场的估值特征。

Abstract: Valuing residential property is inherently complex, requiring consideration of numerous environmental, economic, and property-specific factors. These complexities present significant challenges for automated valuation models (AVMs), which are increasingly used to provide objective assessments for property taxation and mortgage financing. The challenge of obtaining accurate and objective valuations for properties at a country level, and not just within major cities, is further compounded by the presence of multiple localised submarkets-spanning urban, suburban, and rural contexts-where property features contribute differently to value. Existing AVMs often struggle in such settings: traditional hedonic regression models lack the flexibility to capture spatial variation, while advanced machine learning approaches demand extensive datasets that are rarely available. In this article, we address these limitations by developing a robust statistical framework for property valuation in the Irish housing market. We segment the country into six submarkets encompassing cities, large towns, and rural areas, and employ a generalized additive model that captures non-linear effects of property characteristics while allowing feature contributions to vary across submarkets. Our approach outperforms both machine learning-based and traditional hedonic regression models, particularly in data-sparse regions. In out-of-sample validation, our model achieves R-squared values of 0.70, 0.84, and 0.83 for rural areas, towns, and Dublin, respectively, compared to 0.52, 0.71, and 0.82 from a random forest benchmark. Furthermore, the temporal dynamics of our model align closely with reported inflation figures for the study period, providing additional validation of its accuracy.

</details>


### [242] [Change-Point Detection Utilizing Normalized Entropy as a Fundamental Metric](https://arxiv.org/abs/2511.12703)
*Qingqing Song,Shaoliang Xia*

Main category: stat.AP

TL;DR: 提出基于归一化熵的变化点检测方法，通过将熵值标准化到[0,1]区间来克服传统熵方法对数据分布假设和绝对尺度的依赖，有效识别复杂时间序列中的分布变化。


<details>
  <summary>Details</summary>
Motivation: 传统熵方法在变化点检测中存在对数据分布假设和绝对尺度的依赖问题，难以适应复杂时间序列中尺度、分布和多样性的变化。

Method: 使用滑动窗口计算归一化熵，将熵值标准化到[0,1]区间，通过识别归一化熵序列中的显著特征来检测变化点，避免参数假设的干扰。

Result: 实验表明归一化熵在各种分布和参数组合下，在变化点附近表现出显著的数值波动特征，波动时刻与实际变化点的平均偏差仅为滑动窗口大小的2.4%，适应性良好。

Conclusion: 归一化熵为复杂数据环境下的变化点检测提供了理论支持，并为基于该基础指标的精确自动化检测奠定了方法基础。

Abstract: This paper introduces a concept for change-point detection based on normalized entropy as a fundamental metric, aiming to overcome the dependence of traditional entropy methods on assumptions about data distribution and absolute scales. Normalized entropy maps entropy values to the [0,1] interval through standardization, accurately capturing relative changes in data complexity. By utilizing a sliding window to compute normalized entropy, this approach transforms the challenge of detecting change points in complex time series, arising from variations in scale, distribution, and diversity, into the task of identifying significant features within the normalized entropy sequence, thereby avoiding interference from parametric assumptions and effectively highlighting distributional shifts. Experimental results show that normalized entropy exhibits significant numerical fluctuation characteristics and patterns near change points across various distributions and parameter combinations. The average deviation between fluctuation moments and actual change points is only 2.4% of the sliding window size, demonstrating strong adaptability. This paper provides theoretical support for change-point detection in complex data environments and lays a methodological foundation for precise and automated detection based on normalized entropy as a fundamental metric.

</details>


### [243] [Scalable Vision-Guided Crop Yield Estimation](https://arxiv.org/abs/2511.12999)
*Harrison H. Li,Medhanie Irgau,Nabil Janmohamed,Karen Solveig Rieckmann,David B. Lobell*

Main category: stat.AP

TL;DR: 提出基于预测驱动推断(PPI)的方法，利用田间照片补充传统作物收割测量，提高作物产量估计精度和不确定性量化


<details>
  <summary>Details</summary>
Motivation: 传统作物收割测量方法耗时，需要更高效的产量估计方法来支持农业监测和决策制定

Method: 训练计算机视觉模型从照片预测作物产量，学习控制函数利用空间坐标重新校准预测，结合PPI方法提高区域平均产量估计精度

Result: 在撒哈拉以南非洲近20,000个水稻和玉米田数据上验证，有效样本量增加73%(水稻)和12-23%(玉米)，置信区间更短且覆盖率保持

Conclusion: 低成本图像技术可提高作物产量估计精度，使基于区域的作物保险更经济可行，促进可持续农业实践投资

Abstract: Precise estimation and uncertainty quantification for average crop yields are critical for agricultural monitoring and decision making. Existing data collection methods, such as crop cuts in randomly sampled fields at harvest time, are relatively time-consuming. Thus, we propose an approach based on prediction-powered inference (PPI) to supplement these crop cuts with less time-consuming field photos. After training a computer vision model to predict the ground truth crop cut yields from the photos, we learn a ``control function" that recalibrates these predictions with the spatial coordinates of each field. This enables fields with photos but not crop cuts to be leveraged to improve the precision of zone-wide average yield estimates. Our control function is learned by training on a dataset of nearly 20,000 real crop cuts and photos of rice and maize fields in sub-Saharan Africa. To improve precision, we pool training observations across different zones within the same first-level subdivision of each country. Our final PPI-based point estimates of the average yield are provably asymptotically unbiased and cannot increase the asymptotic variance beyond that of the natural baseline estimator -- the sample average of the crop cuts -- as the number of fields grows. We also propose a novel bias-corrected and accelerated (BCa) bootstrap to construct accompanying confidence intervals. Even in zones with as few as 20 fields, the point estimates show significant empirical improvement over the baseline, increasing the effective sample size by as much as 73% for rice and by 12-23% for maize. The confidence intervals are accordingly shorter at minimal cost to empirical finite-sample coverage. This demonstrates the potential for relatively low-cost images to make area-based crop insurance more affordable and thus spur investment into sustainable agricultural practices.

</details>


### [244] [TacEleven: generative tactic discovery for football open play](https://arxiv.org/abs/2511.13326)
*Siyao Zhao,Hao Ma,Zhiqiang Pu,Jingjing Huang,Yi Pan,Zhi Ming*

Main category: stat.AP

TL;DR: TacEleven是一个用于足球开放进攻战术发现的生成框架，包含战术生成器和战术评估器，能够快速探索战术方案并发现替代性进攻战术。


<details>
  <summary>Details</summary>
Motivation: 足球开放进攻中创造优势至关重要，但由于动态性和长序列特性，战术空间随序列进展呈指数增长，使得自动战术发现极具挑战性。

Method: TacEleven包含两个核心组件：语言控制的战术生成器（产生多样化战术方案）和基于多模态大语言模型的战术评估器（选择符合高层战术风格指令的最优方案）。

Result: 在三个渐进复杂度的任务评估中，TacEleven发现的战术展现出强大的真实性和战术创造力，52.50%的多步战术替代方案被评定为可在现实精英足球场景中采用。

Conclusion: TacEleven展示了创造性利用领域数据和生成模型来推进体育战术分析的潜力，能够为复杂长序列开放进攻情境快速生成大量高质量战术。

Abstract: Creating offensive advantages during open play is fundamental to football success. However, due to the highly dynamic and long-sequence nature of open play, the potential tactic space grows exponentially as the sequence progresses, making automated tactic discovery extremely challenging. To address this, we propose TacEleven, a generative framework for football open-play tactic discovery developed in close collaboration with domain experts from AJ Auxerre, designed to assist coaches and analysts in tactical decision-making. TacEleven consists of two core components: a language-controlled tactical generator that produces diverse tactical proposals, and a multimodal large language model-based tactical critic that selects the optimal proposal aligned with a high-level stylistic tactical instruction. The two components enables rapid exploration of tactical proposals and discovery of alternative open-play offensive tactics. We evaluate TacEleven across three tasks with progressive tactical complexity: counterfactual exploration, single-step discovery, and multi-step discovery, through both quantitative metrics and a questionnaire-based qualitative assessment. The results show that the TacEleven-discovered tactics exhibit strong realism and tactical creativity, with 52.50% of the multi-step tactical alternatives rated adoptable in real-world elite football scenarios, highlighting the framework's ability to rapidly generate numerous high-quality tactics for complex long-sequence open-play situations. TacEleven demonstrates the potential of creatively leveraging domain data and generative models to advance tactical analysis in sports.

</details>


### [245] [Variance Stabilizing Transformations for Electricity Price Forecasting in Periods of Increased Volatility](https://arxiv.org/abs/2511.13603)
*Bartosz Uniejewski*

Main category: stat.AP

TL;DR: 本文提出了一种新的参数化asinh变换方法，用于电力价格预测中的方差稳定化预处理，在德国、西班牙和法国市场数据上显著提升了预测精度，特别是在波动性市场环境下。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源渗透率提高和近期危机，电力市场价格波动性前所未有地增加，传统的预测模型面临挑战。方差稳定化变换(VSTs)作为预处理工具需要重新评估和改进。

Method: 引入新的参数化asinh变换，系统分析参数敏感性和校准窗口大小，使用NARX和LEAR两类模型在2015-2024年德西法三国数据上进行测试，并明确评估波动市场机制下的性能。

Result: VSTs显著降低预测误差，LEAR模型提升14.6%，NARX模型提升8.7%。新参数化asinh变换持续优于标准形式，跨变换滚动平均实现最稳健改进，误差降低达17.7%。

Conclusion: 方差稳定化变换在波动市场机制下特别有价值，是增强当今电力市场价格预测能力的强大工具。

Abstract: Accurate day-ahead electricity price forecasts are critical for power system operation and market participation, yet growing renewable penetration and recent crises have caused unprecedented volatility that challenges standard models. This paper revisits variance-stabilizing transformations (VSTs) as a preprocessing tool by introducing a novel parametrization of the asinh transformation, systematically analyzing parameter sensitivity and calibration window size, and explicitly testing performance under volatile market regimes. Using data from Germany, Spain, and France over 2015-2024 with two model classes (NARX and LEAR), we show that VSTs substantially reduce forecast errors, with gains of up to 14.6% for LEAR and 8.7% for NARX relative to untransformed benchmarks. The new parametrized asinh consistently outperforms its standard form, while rolling averaging across transformations delivers the most robust improvements, reducing errors by up to 17.7%. Results demonstrate that VSTs are especially valuable in volatile regimes, making them a powerful tool for enhancing electricity price forecasting in today's power markets.

</details>


### [246] [Phase I Distribution-Free Control Charts for Individual Observations Using Runs and Patterns](https://arxiv.org/abs/2511.13672)
*Tung-Lung Wu*

Main category: stat.AP

TL;DR: 提出了用于监测连续和离散个体观测值未知目标值（或位置参数）的Phase I无分布游程和模式类型控制图，通过有限马尔可夫链嵌入技术结合随机置换和条件论证来维持名义受控信号概率。


<details>
  <summary>Details</summary>
Motivation: 需要开发适用于连续和离散个体观测值的Phase I无分布控制图，能够有效监测未知目标值，同时保持受控信号概率在预定水平。

Method: 采用有限马尔可夫链嵌入技术结合随机置换和条件论证，重点研究了两个流行的游程和模式类型统计量：成功游程数和扫描统计量。

Result: 数值结果表明，所提出的控制图性能与现有的Phase I非参数个体观测值控制图相当。

Conclusion: 该方法为监测连续和离散个体观测值的未知目标值提供了一种有效的Phase I无分布控制图解决方案。

Abstract: Phase I distribution-free runs- and patterns-type control charts are proposed for monitoring the unknown target value (or location parameter) for both continuous and discrete individual observations. Our approach maintains the nominal in-control signal probability at a prescribed level by employing the finite Markov chain imbedding technique combined with random permutation and conditioning arguments. To elucidate the methodology, we examine two popular runs- and patterns-type statistics: the number of success runs and the scan statistic. Numerical results indicate that the performance of our proposed control charts is comparable to that of existing Phase I nonparametric control charts for individual observations.

</details>
