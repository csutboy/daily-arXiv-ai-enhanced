<div id=toc></div>

# Table of Contents

- [econ.EM](#econ.EM) [Total: 5]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.CY](#cs.CY) [Total: 25]
- [cs.AI](#cs.AI) [Total: 63]
- [econ.GN](#econ.GN) [Total: 7]
- [econ.TH](#econ.TH) [Total: 1]
- [stat.AP](#stat.AP) [Total: 9]
- [q-fin.GN](#q-fin.GN) [Total: 2]
- [cs.RO](#cs.RO) [Total: 55]
- [eess.SY](#eess.SY) [Total: 45]
- [cs.SI](#cs.SI) [Total: 10]


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [1] [Optimally-Transported Generalized Method of Moments](https://arxiv.org/abs/2511.05712)
*Susanne Schennach,Vincent Starck*

Main category: econ.EM

TL;DR: 提出了一种基于最优运输理论的广义矩方法新版本，通过引入最小均方误差来同时满足所有矩条件，解决了过度识别检验拒绝原假设时GMM结果的解释问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统GMM在过度识别检验拒绝原假设时结果难以解释的问题，为应用研究提供更稳健的估计方法。

Method: 基于最优运输理论和Wasserstein度量，允许变量存在最小均方误差来同时满足所有矩条件，而不是像广义经验似然方法那样通过重新加权数据来满足矩条件。

Result: 重新分析了Duranton等(2014)关于城市出口与交通基础设施关系的研究，在更弱的假设下验证了他们的结果，并提供了变量误差结构的深入见解。

Conclusion: 该方法为GMM提供了新的理论框架，能够在过度识别检验失败时仍然给出有意义的解释，增强了GMM在实证研究中的实用性。

Abstract: We propose a novel optimal transport-based version of the Generalized Method of Moment (GMM). Instead of handling overidentification by reweighting the data to satisfy the moment conditions (as in Generalized Empirical Likelihood methods), this method proceeds by allowing for errors in the variables of the least mean-square magnitude necessary to simultaneously satisfy all moment conditions. This approach, based on the notions of optimal transport and Wasserstein metric, aims to address the problem of assigning a logical interpretation to GMM results even when overidentification tests reject the null, a situation that cannot always be avoided in applications. We illustrate the method by revisiting Duranton, Morrow and Turner's (2014) study of the relationship between a city's exports and the extent of its transportation infrastructure. Our results corroborate theirs under weaker assumptions and provide insight into the error structure of the variables.

</details>


### [2] [The Exact Variance of the Average Treatment Effect Estimator in Cluster RCT](https://arxiv.org/abs/2511.05801)
*Yue Fang,Geert Ridder*

Main category: econ.EM

TL;DR: 本文研究了有限总体群组随机对照试验中HT估计量的方差上界问题，提出了可计算的尖锐上界及其一致估计量，改进了置信区间的精度。


<details>
  <summary>Details</summary>
Motivation: 在有限总体群组随机对照试验中，HT估计量的精确设计方差依赖于未观测的群组聚合潜在结果的联合分布，因此无法点识别。需要找到可计算的方差上界来构建有效的置信区间。

Method: 扩展Aronow等人的工作，推导了HT ATE估计量的精确设计方差，提供了尖锐可达到的方差上界，并提出了仅使用观测结果和已知抽样/分配概率的一致估计量。

Result: 模拟和实证应用表明，基于该上界的置信区间有效且通常比基于群组标准误的置信区间更窄。

Conclusion: 提出的方差上界方法为有限总体群组随机对照试验提供了更精确的推断工具，改进了传统群组标准误方法的保守性。

Abstract: In cluster randomized controlled trials (CRCT) with a finite populations, the exact design-based variance of the Horvitz-Thompson (HT) estimator for the average treatment effect (ATE) depends on the joint distribution of unobserved cluster-aggregated potential outcomes and is therefore not point-identifiable. We study a common two-stage sampling design-random sampling of clusters followed by sampling units within sampled clusters-with treatment assigned at the cluster level. First, we derive the exact (infeasible) design-based variance of the HT ATE estimator that accounts jointly for cluster- and unit-level sampling as well as random assignment. Second, extending Aronow et al (2014), we provide a sharp, attanable upper bound on that variance and propose a consistent estimator of the bound using only observed outcomes and known sampling/assignment probabilities. In simulations and an empirical application, confidence intervals based on our bound are valid and typically narrower than those based on cluster standard errors.

</details>


### [3] [Synthetic Parallel Trends](https://arxiv.org/abs/2511.05870)
*Yiqi Liu*

Main category: econ.EM

TL;DR: 该论文提出了一个统一的政策评估框架，将DID和SC方法作为特例包含在内，通过合成平行趋势假设构建稳健的置信集，在传统方法假设被违反时仍能保持名义覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现有面板数据政策评估方法（如DID、SC等）依赖于特定权重选择，这些假设通常是不可检验且脆弱的，当假设被违反时会导致严重的覆盖率不足问题。

Method: 开发了一个识别框架，允许所有满足合成平行趋势假设的权重，构建了通过线性规划表示的有效置信集，并剖析了估计系数和干扰参数。

Result: 模拟实验显示，当DID或SC方法的基础假设被违反时，提出的置信集保持稳健并达到名义覆盖率，而现有方法则出现严重的覆盖率不足。

Conclusion: 该框架为政策评估提供了更稳健的方法，能够适应各种权重选择，在传统方法失效的情况下仍能提供可靠的推断结果。

Abstract: Popular empirical strategies for policy evaluation in the panel data literature -- including difference-in-differences (DID), synthetic control (SC) methods, and their variants -- rely on key identifying assumptions that can be expressed through a specific choice of weights $ω$ relating pre-treatment trends to the counterfactual outcome. While each choice of $ω$ may be defensible in empirical contexts that motivate a particular method, it relies on fundamentally untestable and often fragile assumptions. I develop an identification framework that allows for all weights satisfying a Synthetic Parallel Trends assumption: the treated unit's trend is parallel to a weighted combination of control units' trends for a general class of weights. The framework nests these existing methods as special cases and is by construction robust to violations of their respective assumptions. I construct a valid confidence set for the identified set of the treatment effect, which admits a linear programming representation with estimated coefficients and nuisance parameters that are profiled out. In simulations where the assumptions underlying DID or SC-based methods are violated, the proposed confidence set remains robust and attains nominal coverage, while existing methods suffer severe undercoverage.

</details>


### [4] [Boundary Discontinuity Designs: Theory and Practice](https://arxiv.org/abs/2511.06474)
*Matias D. Cattaneo,Rocio Titiunik,Ruiqi Rae Yu*

Main category: econ.EM

TL;DR: 本文综述了边界不连续性设计方法，这是一种利用基于双变量分数和边界曲线的阈值处理分配规则来识别因果效应的非实验研究方法。


<details>
  <summary>Details</summary>
Motivation: 该方法推广了基于单变量分数和标量截止值的标准回归不连续性设计，并因其多维性质而具有特定的挑战和特征。

Method: 通过系统回顾80多篇实证论文，追踪该方法从形成性应用到现代研究中的实施过程，并概述了关于BD设计识别、估计和推断的最新方法论结果。

Result: 对实证文献进行了综合整理，展示了BD设计方法在不同研究领域的应用和发展。

Conclusion: 为实践提供了建议，总结了边界不连续性设计方法的应用现状和发展方向。

Abstract: We review the literature on boundary discontinuity (BD) designs, a powerful non-experimental research methodology that identifies causal effects by exploiting a thresholding treatment assignment rule based on a bivariate score and a boundary curve. This methodology generalizes standard regression discontinuity designs based on a univariate score and scalar cutoff, and has specific challenges and features related to its multi-dimensional nature. We synthesize the empirical literature by systematically reviewing over $80$ empirical papers, tracing the method's application from its formative uses to its implementation in modern research. In addition to the empirical survey, we overview the latest methodological results on identification, estimation and inference for the analysis of BD designs, and offer recommendations for practice.

</details>


### [5] [Unlocking the Regression Space](https://arxiv.org/abs/2511.07183)
*Liudas Giraitis,George Kapetanios,Yufei Li,Alexia Ventouri*

Main category: econ.EM

TL;DR: 提出了一个处理回归模型中一般异质性的框架，证明了固定参数和时变参数回归模型可以在更广泛的回归变量和噪声过程中使用OLS和时变OLS方法进行估计。


<details>
  <summary>Details</summary>
Motivation: 现有理论无法覆盖广泛的回归变量和噪声过程，需要开发能够处理一般异质性的回归建模框架。

Method: 使用OLS和时变OLS方法估计固定参数和时变参数回归模型，开发渐近理论和稳健标准误估计方法。

Result: 提出的稳健置信区间估计器能够适应回归变量和噪声的显著异质性，稳健标准误估计与White(1980)异方差一致估计器一致但适用范围更广，在蒙特卡洛模拟中表现良好。

Conclusion: 该方法具有稳健性、通用性和易于实现的优点，非常适合实证应用。

Abstract: This paper introduces and analyzes a framework that accommodates general heterogeneity in regression modeling. It demonstrates that regression models with fixed or time-varying parameters can be estimated using the OLS and time-varying OLS methods, respectively, across a broad class of regressors and noise processes not covered by existing theory. The proposed setting facilitates the development of asymptotic theory and the estimation of robust standard errors. The robust confidence interval estimators accommodate substantial heterogeneity in both regressors and noise. The resulting robust standard error estimates coincide with White's (1980) heteroskedasticity-consistent estimator but are applicable to a broader range of conditions, including models with missing data. They are computationally simple and perform well in Monte Carlo simulations. Their robustness, generality, and ease of implementation make them highly suitable for empirical applications. Finally, the paper provides a brief empirical illustration.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [6] [System Modeling of Microfluidic Molecular Communication: A Markov Approach](https://arxiv.org/abs/2511.07245)
*Ruifeng Zheng,Pengjie Zhou,Pit Hofmann,Fatima Rani,Juan A. Cabrera,Frank H. P. Fitzek*

Main category: cs.ET

TL;DR: 提出了一种基于马尔可夫链的微流控分子通信信道系统模型，通过离散化平流-扩散动力学建立物理一致的状态空间公式，能够准确模拟不同流动条件下的信道行为。


<details>
  <summary>Details</summary>
Motivation: 微流控环境中的分子通信需要精确的物理模型来表征信道行为，但现有模型在捕捉复杂流动效应方面存在局限性。

Method: 通过离散化平流-扩散动力学建立状态空间公式，转移矩阵显式捕捉扩散、平流、可逆结合和流出效应，形成离散时间线性系统表示。

Result: 数值结果表明该框架能在各种流动条件下准确重现信道行为，为微流控MC系统的设计和分析提供了可处理的基础。

Conclusion: 提出的马尔可夫基系统模型为微流控分子通信信道提供了物理一致且分析可处理的建模框架，能够有效表征瞬态和平衡响应。

Abstract: This paper presents a Markov-based system model for microfluidic molecular communication (MC) channels. By discretizing the advection-diffusion dynamics, the proposed model establishes a physically consistent state-space formulation. The transition matrix explicitly captures diffusion, advective flow, reversible binding, and flow-out effects. The resulting discrete-time formulation enables analytical characterization of both transient and equilibrium responses through a linear system representation. Numerical results verify that the proposed framework accurately reproduces channel behaviors across a wide range of flow conditions, providing a tractable basis for the design and analysis of MC systems in microfluidic environments.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [7] [Using LLMs to support assessment of student work in higher education: a viva voce simulator](https://arxiv.org/abs/2511.05530)
*Ian M. Church,Lyndon Drake,Mark Harris*

Main category: cs.CY

TL;DR: 开发了一个基于LLM的viva voce考试模拟器，用于检测学生提交的作业是否由AI生成，通过模拟人类考官提问来评估学生对其作业的理解程度。


<details>
  <summary>Details</summary>
Motivation: 应对LLMs在学生作业评估中的广泛使用带来的挑战，特别是针对长文本写作类科目的评估问题。

Method: 开发了一个概念验证的viva voce考试模拟器，接收学生提交的文本，由LLM生成交互式问题序列，学生回答问题，系统根据回答判断作业是否为学生原创。

Result: 创建了一个交互式工具，能够生成类似人类考官的问题，并通过学生的回答来评估作业的原创性，为人类考官提供决策支持。

Conclusion: 提出了在实际部署此类工具时需要考虑的理论和实践要点，为解决AI生成作业的评估问题提供了新思路。

Abstract: One of the emergent challenges of student work submitted for assessment is the widespread use of large language models (LLMs) to support and even produce written work. This particularly affects subjects where long-form written work is a key part of assessment. We propose a novel approach to addressing this challenge, using LLMs themselves to support the assessment process. We have developed a proof-of-concept viva voce examination simulator, which accepts the student's written submission as input, generates an interactive series of questions from the LLM and answers from the student. The viva voce simulator is an interactive tool which asks questions which a human examiner might plausibly ask, and uses the student's answers to form a judgment about whether the submitted piece of work is likely to be the student's own work. The interaction transcript is provided to the human examiner to support their final judgment. We suggest theoretical and practical points which are critical to real-world deployment of such a tool.

</details>


### [8] [Revenge Porn: A Peep into its Awareness among the Youth of Tamilnadu, India](https://arxiv.org/abs/2511.05543)
*Mohammed Marzuk T M,Vijayasarathy R,Madona Mathew*

Main category: cs.CY

TL;DR: 该研究调查了印度泰米尔纳德邦200名未婚女性对复仇色情的认知和态度，发现超过50%从未听说过该术语，仅5%亲身经历过，40%认为受害者有过错，11%承认可能上传露骨内容作为报复。


<details>
  <summary>Details</summary>
Motivation: 复仇色情在印度等人口密集国家频发，但缺乏专门法律规制，且2010年调查显示18.3%女性不知自己是受害者，因此需要了解公众认知现状。

Method: 采用目的性抽样方法，选取泰米尔纳德邦200名18-30岁未婚女性进行问卷调查。

Result: 超过50%受访者从未听过"复仇色情"术语；仅约5%亲身经历过；约40%认为受害者有过错；43.5%不确定是否应禁止色情网站；11%承认可能上传露骨内容报复；8.5%认为文化禁忌导致社会责备受害者。

Conclusion: 印度作为全球网络犯罪第三大国需加强预防措施，应培训警察心理支持技巧，通过公众意识和法律改革减少此类犯罪。

Abstract: The act of posting a person's private photos or videos without their consent is known as revenge porn, and it is usually done to extort money or seek revenge. According to a 2010 cybercrime survey, about 18.3% of women were unaware that they were victims of revenge porn. In densely populated countries like India, such incidents are more likely, yet there is no specific law addressing revenge porn. This study used purposive sampling with a sample size of 200 unmarried women from Tamil Nadu aged 18 to 30. The survey results show that more than 50% had never heard the term "revenge porn," and only about 5% had personally experienced it. About 40% believed the victim was at fault, while 43.5% were unsure whether pornographic websites should be banned. Around 11% admitted that they might upload explicit content as revenge, and 8.5% felt that due to cultural taboos around sex, society tends to blame the victim. Police officers should be trained in techniques for psychologically supporting victims. India, which ranks third globally in cybercrime, must adopt better preventive measures. Public awareness and targeted legal reforms could play a major role in reducing such crimes.

</details>


### [9] [The Future of AI in the GCC Post-NPM Landscape: A Comparative Analysis of Kuwait and the UAE](https://arxiv.org/abs/2511.05932)
*Mohammad Rashed Albous,Bedour Alboloushi,Arnaud Lacheret*

Main category: cs.CY

TL;DR: 该研究比较了阿联酋和科威特在人工智能应用方面的制度规则差异，发现垂直规则一致性（而非财富）决定了AI的公共价值产出。阿联酋通过集中权威、可信制裁等机制成功扩展AI应用，而科威特因分散的否决权等限制使AI项目停留在试点阶段。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注西方民主国家，海湾合作委员会国家如何将AI雄心转化为后新公共管理成果的比较证据稀缺。研究旨在分析阿联酋和科威特两国制度规则如何影响AI应用，以及是否促进公民中心性、协作治理和公共价值创造。

Method: 基于奥斯特罗姆的制度分析与发展框架，采用最相似/最不同系统设计，结合62份公共文件（2018-2025）、阿联酋嵌入式案例（智能迪拜和MBZUAI）以及39次官员访谈（2024年8月-2025年5月），使用双重编码和过程追踪方法。

Result: 阿联酋通过集中权威、可信制裁、创新叙事和灵活再投资规则将试点扩展为数百项服务和可观回收储蓄；科威特因分散否决点、劝诫性制裁、谨慎论述和失效AI预算使项目局限于试点模式，尽管财政资源相当。

Conclusion: 垂直规则一致性（而非财富）决定了AI的公共价值产出，效率指标只有在有强制保障时才服务于社会目标。未来研究应追踪规则扩散、开发混合合法性-效率评分卡，并考察叙事框架如何影响公民对数据共享的同意。

Abstract: Comparative evidence on how Gulf Cooperation Council (GCC) states turn artificial intelligence (AI) ambitions into post--New Public Management (post-NPM) outcomes is scarce because most studies examine Western democracies. We analyze constitutional, collective-choice, and operational rules shaping AI uptake in two contrasting GCC members, the United Arab Emirates (UAE) and Kuwait, and whether they foster citizen centricity, collaborative governance, and public value creation. Anchored in Ostrom's Institutional Analysis and Development framework, the study combines a most similar/most different systems design with multiple sources: 62 public documents from 2018--2025, embedded UAE cases (Smart Dubai and MBZUAI), and 39 interviews with officials conducted Aug 2024--May 2025. Dual coding and process tracing connect rule configurations to AI performance. Cross-case analysis identifies four reinforcing mechanisms behind divergent trajectories. In the UAE, concentrated authority, credible sanctions, pro-innovation narratives, and flexible reinvestment rules scale pilots into hundreds of services and sizable recycled savings. In Kuwait, dispersed veto points, exhortative sanctions, cautious discourse, and lapsed AI budgets confine initiatives to pilot mode despite equivalent fiscal resources. The findings refine institutional theory by showing that vertical rule coherence, not wealth, determines AI's public-value yield, and temper post-NPM optimism by revealing that efficiency metrics serve societal goals only when backed by enforceable safeguards. To curb ethics washing and test transferability beyond the GCC, future work should track rule diffusion over time, develop blended legitimacy--efficiency scorecards, and examine how narrative framing shapes citizen consent for data sharing.

</details>


### [10] [Emergency Response Measures for Catastrophic AI Risk](https://arxiv.org/abs/2511.05526)
*James Zhang,Miles Kodama,Zongze Wu,Michael Chen,Yue Zhu,Geng Hong*

Main category: cs.CY

TL;DR: 中国正在将四阶段应急响应框架扩展到应对先进AI风险，本文分析前沿安全政策(FSPs)模型如何帮助实现AI应急准备。


<details>
  <summary>Details</summary>
Motivation: 中国需要为先进AI风险开发具体的预防和预警机制，而前沿安全政策模型提供了可借鉴的国际实践。

Method: 分析前沿安全政策(FSPs)模型，该模型包含部署前危险能力评估和分级预规划安全措施。

Result: 发现FSPs与中国应急响应框架的主动预防阶段高度契合，表明该模型有助于在中国现有治理原则下实施AI应急准备。

Conclusion: FSPs模型可以为中国的AI应急响应框架提供可行的操作化路径，符合中国既定的治理原则。

Abstract: Chinese authorities are extending the country's four-phase emergency response framework (prevent, warn, respond, and recover) to address risks from advanced artificial intelligence (AI). Concrete mechanisms for the proactive prevention and warning phases, however, remain under development. This paper analyzes an implementation model inspired by international AI safety practices: frontier safety policies (FSPs). These policies feature pre-deployment evaluations for dangerous capabilities and tiered, pre-planned safety measures. We observe close alignment between FSPs and the proactive phases of China's emergency response framework, suggesting that the FSP model could help operationalize AI emergency preparedness in a manner consistent with China's established governance principles.

</details>


### [11] [Deception Decoder: Proposing a Human-Focused Framework for Identifying AI-Generated Content on Social Media](https://arxiv.org/abs/2511.05555)
*C. Bowman Kerbage*

Main category: cs.CY

TL;DR: 提出了一个名为Deception Decoder的多模态、系统性和拓扑学框架，旨在帮助普通用户识别AI生成的虚假信息，涵盖文本、图像和视频内容。


<details>
  <summary>Details</summary>
Motivation: 生成式AI对公共领域信息完整性构成重大威胁，当前研究主要关注自动化检测方法，但存在误报、社会政治偏见和易被规避等问题，因此需要采用以人为中心的方法。

Method: 通过现有模型的比较综合、GenAI视频内容分析以及小规模焦点小组讨论，开发并完善了Deception Decoder框架。

Result: 初步测试显示该框架有良好的改进效果，但需要进一步研究验证其在不同用户群体中的普适性和长期有效性。

Conclusion: Deception Decoder是一个有前景的人类中心化解决方案，能够帮助用户识别AI生成的虚假信息，但需要更多研究来确认其广泛适用性。

Abstract: Generative AI (GenAI) poses a substantial threat to the integrity of information within the contemporary public sphere, which increasingly relies on social media platforms as intermediaries for news consumption. At present, most research efforts are directed toward automated and machine learning-based detection methods, despite growing concerns regarding false positives, social and political biases, and susceptibility to circumvention. This dissertation instead adopts a human-centred approach. It proposes the Deception Decoder; a multimodal, systematic, and topological framework designed to support general users in identifying AI-generated misinformation and disinformation across text, image, and video. The framework was developed through a comparative synthesis of existing models, supplemented by a content analysis of GenAI-video, and refined through a small-scale focus group session. While initial testing indicates promising improvements, further research is required to confirm its generalisability across user groups, and sustained effectiveness over time.

</details>


### [12] [AgriTrust: a Federated Semantic Governance Framework for Trusted Agricultural Data Sharing](https://arxiv.org/abs/2511.05572)
*Ivan Bergier*

Main category: cs.CY

TL;DR: AgriTrust是一个联邦语义治理框架，通过多利益相关方治理模型和语义数字层解决农业数据信任和互操作性难题，在巴西三个关键供应链中验证了可行性。


<details>
  <summary>Details</summary>
Motivation: 解决"农业数据悖论"——尽管农业数据具有公认价值，但由于缺乏信任和互操作性而被锁定在数据孤岛中，阻碍了效率和可持续性的提升。

Method: 整合多利益相关方治理模型（数据主权、透明数据合同、公平价值共享、监管合规）与语义数字层（AgriTrust核心本体论），采用区块链无关的多提供商架构。

Result: 在巴西咖啡（欧盟毁林法规合规）、大豆（质量平衡）和牛肉（动物追踪）供应链的案例研究中，成功实现了可验证溯源、自动化合规，并为数据生产者创造了新收入流。

Conclusion: AgriTrust将数据共享从基于信任的困境转变为受治理的自动化操作，为更透明、高效和公平的农业数据经济提供了基础蓝图。

Abstract: The potential of agricultural data (AgData) to drive efficiency and sustainability is stifled by the "AgData Paradox": a pervasive lack of trust and interoperability that locks data in silos, despite its recognized value. This paper introduces AgriTrust, a federated semantic governance framework designed to resolve this paradox. AgriTrust integrates a multi-stakeholder governance model, built on pillars of Data Sovereignty, Transparent Data Contracts, Equitable Value Sharing, and Regulatory Compliance, with a semantic digital layer. This layer is realized through the AgriTrust Core Ontology, a formal OWL ontology that provides a shared vocabulary for tokenization, traceability, and certification, enabling true semantic interoperability across independent platforms. A key innovation is a blockchain-agnostic, multi-provider architecture that prevents vendor lock-in. The framework's viability is demonstrated through case studies across three critical Brazilian supply chains: coffee (for EUDR compliance), soy (for mass balance), and beef (for animal tracking). The results show that AgriTrust successfully enables verifiable provenance, automates compliance, and creates new revenue streams for data producers, thereby transforming data sharing from a trust-based dilemma into a governed, automated operation. This work provides a foundational blueprint for a more transparent, efficient, and equitable agricultural data economy.

</details>


### [13] [Who Evaluates AI's Social Impacts? Mapping Coverage and Gaps in First and Third Party Evaluations](https://arxiv.org/abs/2511.05613)
*Anka Reuel,Avijit Ghosh,Jenny Chim,Andrew Tran,Yanan Long,Jennifer Mickel,Usman Gohar,Srishti Yadav,Pawan Sasanka Ammanamanchi,Mowafak Allaham,Hossein A. Rahmani,Mubashara Akhtar,Felix Friedrich,Robert Scholz,Michael Alexander Riegler,Jan Batzner,Eliya Habba,Arushi Saxena,Anastassia Kornilova,Kevin Wei,Prajna Soni,Yohan Mathew,Kevin Klyman,Jeba Sania,Subramanyam Sahoo,Olivia Beyer Bruvik,Pouya Sadeghi,Sujata Goswami,Angelina Wang,Yacine Jernite,Zeerak Talat,Stella Biderman,Mykel Kochenderfer,Sanmi Koyejo,Irene Solaiman*

Main category: cs.CY

TL;DR: 该研究首次全面分析了AI模型开发者的社会影响评估报告，发现第一方报告稀疏且肤浅，而第三方评估更全面严谨，但当前评估实践存在重大缺口。


<details>
  <summary>Details</summary>
Motivation: 基础模型在高风险AI系统中日益重要，但社会影响评估（包括偏见、公平、隐私、环境成本和劳动实践）在整个AI生态系统中仍然不均衡。

Method: 分析了186份第一方发布报告和183份发布后评估来源，并辅以对模型开发者的访谈进行定量分析。

Result: 发现评估工作存在明显分工：第一方报告稀疏且肤浅，在环境影响和偏见等关键领域有所下降；第三方评估者提供更广泛和严谨的偏见、有害内容和性能差异评估。

Conclusion: 当前评估实践在评估AI社会影响方面存在重大缺口，迫切需要促进开发者透明度、加强独立评估生态系统和创建共享基础设施的政策。

Abstract: Foundation models are increasingly central to high-stakes AI systems, and governance frameworks now depend on evaluations to assess their risks and capabilities. Although general capability evaluations are widespread, social impact assessments covering bias, fairness, privacy, environmental costs, and labor practices remain uneven across the AI ecosystem. To characterize this landscape, we conduct the first comprehensive analysis of both first-party and third-party social impact evaluation reporting across a wide range of model developers. Our study examines 186 first-party release reports and 183 post-release evaluation sources, and complements this quantitative analysis with interviews of model developers. We find a clear division of evaluation labor: first-party reporting is sparse, often superficial, and has declined over time in key areas such as environmental impact and bias, while third-party evaluators including academic researchers, nonprofits, and independent organizations provide broader and more rigorous coverage of bias, harmful content, and performance disparities. However, this complementarity has limits. Only model developers can authoritatively report on data provenance, content moderation labor, financial costs, and training infrastructure, yet interviews reveal that these disclosures are often deprioritized unless tied to product adoption or regulatory compliance. Our findings indicate that current evaluation practices leave major gaps in assessing AI's societal impacts, highlighting the urgent need for policies that promote developer transparency, strengthen independent evaluation ecosystems, and create shared infrastructure to aggregate and compare third-party evaluations in a consistent and accessible way.

</details>


### [14] [Artificial intelligence and the Gulf Cooperation Council workforce adapting to the future of work](https://arxiv.org/abs/2511.05927)
*Mohammad Rashed Albous,Melodena Stephens,Odeh Rashed Al-Jayyousi*

Main category: cs.CY

TL;DR: 该研究评估了海湾合作委员会国家AI投资在计算基础设施与技能、激励和治理建设之间的匹配度，发现72%的AI项目具有社会-技术联合设计，监管协调比财政能力更能影响AI发展结果，并识别出可能导致劳动力市场分化的双轨人才体系。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估海湾合作委员会国家在AI快速扩张过程中，计算基础设施投资是否与技能、激励和治理建设相匹配，填补石油富国、国家主导经济体中社会技术系统研究的空白。

Method: 采用混合方法研究，包括：六国AI战略的TF-IDF分析、47个公开AI项目清单分析、MBZUAI和SDAIA学院配对案例研究、连接石油收入与监管协调的情景矩阵分析。

Result: 72%的AI项目具有社会-技术联合设计；监管协调比财政能力更能影响AI发展结果；识别出研究精英与快速培训从业者的双轨人才体系风险。

Conclusion: 研究扩展了社会技术系统理论在石油富国中的应用，提出了关注纵向耦合指标、协调民族志和基于结果的绩效指标的研究议程。

Abstract: The rapid expansion of artificial intelligence (AI) in the Gulf Cooperation Council (GCC) raises a central question: are investments in compute infrastructure matched by an equally robust build-out of skills, incentives, and governance? Grounded in socio-technical systems (STS) theory, this mixed-methods study audits workforce preparedness across Kingdom of Saudi Arabia (KSA), the United Arab Emirates (UAE), Qatar, Kuwait, Bahrain, and Oman. We combine term frequency--inverse document frequency (TF--IDF) analysis of six national AI strategies (NASs), an inventory of 47 publicly disclosed AI initiatives (January 2017--April 2025), paired case studies, the Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) and the Saudi Data & Artificial Intelligence Authority (SDAIA) Academy, and a scenario matrix linking oil-revenue slack (technical capacity) to regulatory coherence (social alignment). Across the corpus, 34/47 initiatives (0.72; 95% Wilson CI 0.58--0.83) exhibit joint social--technical design; country-level indices span 0.57--0.90 (small n; intervals overlap). Scenario results suggest that, under our modeled conditions, regulatory convergence plausibly binds outcomes more than fiscal capacity: fragmented rules can offset high oil revenues, while harmonized standards help preserve progress under austerity. We also identify an emerging two-track talent system, research elites versus rapidly trained practitioners, that risks labor-market bifurcation without bridging mechanisms. By extending STS inquiry to oil-rich, state-led economies, the study refines theory and sets a research agenda focused on longitudinal coupling metrics, ethnographies of coordination, and outcome-based performance indicators.

</details>


### [15] [Report from Workshop on Dialogue alongside Artificial Intelligence](https://arxiv.org/abs/2511.05625)
*Thomas J McKenna,Ingvill Rasmussen,Sten Ludvigsen,Avivit Arvatz,Christa Asterhan,Gaowei Chen,Julie Cohen,Michele Flammia,Dongkeun Han,Emma Hayward,Heather Hill,Yifat Kolikant,Helen Lehndorf,Kexin Li,Lindsay Clare Matsumura,Henrik Tjønn,Pengjin Wang,Rupert Wegerif*

Main category: cs.CY

TL;DR: 国际研讨会探讨AI与教育对话的交叉点，聚焦AI在教育中的真正价值、促进对话式教学的条件，以及AI可能取代人类教育工作的风险。


<details>
  <summary>Details</summary>
Motivation: AI在教育领域快速发展，但可能削弱人类能动性、加剧不平等，需要审慎评估AI在教育对话中的角色和影响。

Method: 召集19位来自11个国家的研究者，通过两天演讲和结构化对话，围绕三个核心问题展开讨论。

Result: 研讨会深入探讨了AI在教育中的适用场景、促进对话式教学的条件，以及AI与人类教育工作的平衡关系。

Conclusion: 需要平衡AI技术应用与人类教育价值，确保AI真正服务于教育对话和深层学习，而非简单替代人类教育工作。

Abstract: Educational dialogue -the collaborative exchange of ideas through talk- is widely recognized as a catalyst for deeper learning and critical thinking in and across contexts. At the same time, artificial intelligence (AI) has rapidly emerged as a powerful force in education, with the potential to address major challenges, personalize learning, and innovate teaching practices. However, these advances come with significant risks: rapid AI development can undermine human agency, exacerbate inequities, and outpace our capacity to guide its use with sound policy. Human learning presupposes cognitive efforts and social interaction (dialogues). In response to this evolving landscape, an international workshop titled "Educational Dialogue: Moving Thinking Forward" convened 19 leading researchers from 11 countries in Cambridge (September 1-3, 2025) to examine the intersection of AI and educational dialogue. This AI-focused strand of the workshop centered on three critical questions: (1) When is AI truly useful in education, and when might it merely replace human effort at the expense of learning? (2) Under what conditions can AI use lead to better dialogic teaching and learning? (3) Does the AI-human partnership risk outpacing and displacing human educational work, and what are the implications? These questions framed two days of presentations and structured dialogue among participants.

</details>


### [16] [Assessing the Reliability of Large Language Models in the Bengali Legal Context: A Comparative Evaluation Using LLM-as-Judge and Legal Experts](https://arxiv.org/abs/2511.05627)
*Sabik Aftahee,A. F. M. Farhad,Arpita Mallik,Ratnajit Dhar,Jawadul Karim,Nahiyan Bin Noor,Ishmam Ahmed Solaiman*

Main category: cs.CY

TL;DR: 本研究评估了四种AI模型在孟加拉国法律咨询中的表现，发现虽然AI能生成高质量的法律回答，但也存在危险错误信息，需要专家验证才能安全部署。


<details>
  <summary>Details</summary>
Motivation: 孟加拉国法律服务面临高费用、复杂法律语言、律师短缺和案件积压等问题，希望通过AI模型提供快速廉价的法律援助来民主化法律服务。

Method: 收集250个真实法律问题，使用四种先进AI模型生成回答，采用双重评估框架：由最先进LLM模型和三名持牌孟加拉国法律专业人士按照事实准确性、法律适当性、完整性和清晰度四个维度进行评估。

Result: AI模型经常生成高质量、结构良好的法律回答，但也产生危险错误信息，包括捏造的案例引用、错误的法律程序和潜在有害建议。

Conclusion: 在AI系统安全部署用于孟加拉国法律咨询之前，迫切需要严格的专家验证和全面保障措施。

Abstract: Accessing legal help in Bangladesh is hard. People face high fees, complex legal language, a shortage of lawyers, and millions of unresolved court cases. Generative AI models like OpenAI GPT-4.1 Mini, Gemini 2.0 Flash, Meta Llama 3 70B, and DeepSeek R1 could potentially democratize legal assistance by providing quick and affordable legal advice. In this study, we collected 250 authentic legal questions from the Facebook group "Know Your Rights," where verified legal experts regularly provide authoritative answers. These questions were subsequently submitted to four four advanced AI models and responses were generated using a consistent, standardized prompt. A comprehensive dual evaluation framework was employed, in which a state-of-the-art LLM model served as a judge, assessing each AI-generated response across four critical dimensions: factual accuracy, legal appropriateness, completeness, and clarity. Following this, the same set of questions was evaluated by three licensed Bangladeshi legal professionals according to the same criteria. In addition, automated evaluation metrics, including BLEU scores, were applied to assess response similarity. Our findings reveal a complex landscape where AI models frequently generate high-quality, well-structured legal responses but also produce dangerous misinformation, including fabricated case citations, incorrect legal procedures, and potentially harmful advice. These results underscore the critical need for rigorous expert validation and comprehensive safeguards before AI systems can be safely deployed for legal consultation in Bangladesh.

</details>


### [17] [Who shapes Web standards? Uncovering the main topics of interest in the W3C](https://arxiv.org/abs/2511.05713)
*Henrique S. Xavier,Beatriz Rocha,Diogo Cortiz*

Main category: cs.CY

TL;DR: 分析W3C成员组织在标准化过程中的参与模式，揭示五大重点领域及其主导者分布


<details>
  <summary>Details</summary>
Motivation: 了解W3C成员组织在Web标准化过程中的兴趣焦点和影响力分布，揭示不同利益相关者如何影响Web未来发展

Method: 使用W3C公开数据，通过主题建模和相似性分析，将组织在W3C工作组中的代表人数作为兴趣代理指标

Result: 识别出五大重点领域：Web、广告与隐私；高性能；凭证与物联网；可访问性；支付。美国大型企业在核心Web开发和广告领域占主导，日本组织在物联网领域更活跃

Conclusion: 揭示了不同利益相关者在Web标准化过程中的影响力分布，为理解Web未来发展方向提供了重要见解

Abstract: This paper identifies the primary topics of interest of organizations participating in the World Wide Web Consortium (W3C), the leading standards body for the Web. Using publicly available data from the W3C website, we analyze the participation of member organizations in W3C groups, treating the number of representatives allocated to each group as a proxy for their interests. By applying topic modeling and similarity analysis to these participation patterns, we uncover clusters of related groups and shared priorities among organizations. The results reveal five prominent areas of focus -- Web, Ads & Privacy; High Performance; Credentials & Web of Things; Accessibility; and Payments -- and show that large enterprises, particularly those based in the United States, dominate participation in core Web development and advertising-related topics, while Japanese organizations are more active in the Web of Things. These findings offer insights into how various stakeholders influence the standardization process and how the Web may evolve in the coming years.

</details>


### [18] [Preserving security in a world with powerful AI Considerations for the future Defense Architecture](https://arxiv.org/abs/2511.05714)
*Nicholas Generous,Brian Cook,Jason Pruet*

Main category: cs.CY

TL;DR: 当前美国国防架构无法应对AI威胁，需要结合传统系统升级和全新防御架构元素，并立即调整能源部国家实验室以确保AI时代的敏捷性和韧性。


<details>
  <summary>Details</summary>
Motivation: AI技术的进步威胁到当前国防架构的基本假设，现有国防计划无法单独应对快速出现的AI赋能威胁，需要重新思考国家安全防御体系。

Method: 提出结合传统系统加固与全新防御架构元素的双重策略，并建议调整能源部国家核安全管理局国家实验室以适应AI时代需求。

Result: 识别出现有国防架构在面对AI威胁时的脆弱性，提出了系统性的改进方案。

Conclusion: 必须立即采取行动，通过整合传统防御系统升级和全新架构元素，并调整关键国家实验室，来应对AI技术带来的国家安全挑战。

Abstract: Advances in AI threaten to invalidate assumptions underpinning today's defense architecture. We argue that the current U.S. defense program of record, designed in an era before capable machine intelligence, cannot by itself preserve national security against rapidly emerging AI enabled threats. Instead, shoring up legacy systems must be coupled with entirely new elements of a defense architecture. We outline immediate steps to adapt the Department of Energy National Nuclear Security Administration National Laboratories to ensure agility and resilience in an era of powerful AI.

</details>


### [19] [Assessing Problem Decomposition in CS1 for the GenAI Era](https://arxiv.org/abs/2511.05764)
*Samvrit Srinath,Annapurna Vadaparty,David H. Smith,Leo Porter,Daniel Zingaro*

Main category: cs.CY

TL;DR: 开发问题分解评估问题，使用问题套件和分解图表来评估初学者的问题分解能力


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的兴起，学生能够生成大量代码，因此需要培养他们的问题分解能力，但目前缺乏有效的教学和评估方法

Method: 开发问题套件（支架式问题序列）和开放式分解图表绘制，解决长上下文问题，通过多次迭代改进评估材料

Result: 创建了问题分解评估材料，包括学习目标、问题设计和应对挑战的方法

Conclusion: 为教育工作者提供了教授问题分解技能的评估材料和实践经验，帮助初学者培养这一关键编程能力

Abstract: Problem decomposition--the ability to break down a large task into smaller, well-defined components--is a critical skill for effectively designing and creating large programs, but it is often not included in introductory computer science curricula. With the rise of generative AI (GenAI), students even at the introductory level are able to generate large quantities of code, and it is becoming increasingly important to equip them with the ability to decompose problems. There is not yet a consensus among educators on how to best teach and assess the skill of decomposition, particularly in introductory computing. This practitioner paper details the development of questions to assess the skill of problem decomposition, and impressions about how these questions were received by students. A challenge unique to problem decomposition questions is their necessarily lengthy context, and we detail our approach to addressing this problem using Question Suites: scaffolded sequences of questions that help students understand a question's context before attempting to decompose it. We then describe the use of open-ended drawing of decomposition diagrams as another form of assessment. We outline the learning objectives used to design our questions and describe how we addressed challenges encountered in early iterations. We present our decomposition assessment materials and reflections on them for educators who wish to teach problem decomposition to beginner programmers.

</details>


### [20] [(Working Paper) Good Faith Design: Religion as a Resource for Technologists](https://arxiv.org/abs/2511.05819)
*Nina Lutz,Benjamin Olsen,Weishung Liu,E. Glen Weyl*

Main category: cs.CY

TL;DR: 该研究通过访谈48位来自11个信仰的宗教人士/专家，揭示了宗教用户在技术使用中的体验和需求，提出了六个设计价值观来帮助技术人员将宗教作为有效的社会文化资源融入设计。


<details>
  <summary>Details</summary>
Motivation: HCI领域对宗教研究不足，宗教与技术社区之间存在价值观和实践的误解，需要弥合这一鸿沟。

Method: 对48位来自11个信仰的宗教人士和专家进行访谈研究，记录宗教人士对技术的体验、理解和想象。

Result: 发现宗教利益相关者发现技术及其设计者存在非中立的世俗嵌入，这些嵌入对宗教和非宗教用户造成意外伤害；揭示了用户如何通过宗教启发的心理模型导航技术宗教实践及其对技术的期望。

Conclusion: 提炼出六个设计价值观（惊奇、谦逊、空间、具身性、社区、永恒）来指导技术人员在设计时将宗教作为额外的有效社会文化资源考虑和利用。

Abstract: Previous work has found a lack of research in HCI on religion, partly driven by misunderstandings of values and practices between religious and technical communities. To bridge this divide in an empirically rigorous way, we conducted an interview study with 48 religious people and/or experts from 11 faiths, and we document how religious people experience, understand, and imagine technologies. We show that religious stakeholders find non-neutral secular embeddings in technologies and the firms and people that design them, and how these manifest in unintended harms for religious and nonreligious users. Our findings reveal how users navigate technoreligious practices with religiously informed mental models and what they desire from technologies. Informed by this, we distill six design values -- wonder, humility, space, embodiedness, community, and eternity -- to guide technologists in considering and leveraging religion as an additional, valid sociocultural resource when designing for a holistic user. We further spell out directions for future research.

</details>


### [21] [Prediction-based evaluation of back-four defense with spatial control in soccer](https://arxiv.org/abs/2511.06191)
*Soujanya Dash,Kenjiro Ide,Rikuhei Umemoto,Kai Amino,Keisuke Fujii*

Main category: cs.CY

TL;DR: 该研究提出了可解释的时空指标来评估足球防守转换中后四后卫线的集体协调效果，通过分析西甲2023-24赛季数据发现相对防线高度和空间控制是防守成功的关键预测因子，巴塞罗那和皇家马德里展现出不同的防守行为模式。


<details>
  <summary>Details</summary>
Motivation: 足球防守组织在负面转换时最为脆弱，后四后卫线的集体协调对防止进球机会至关重要，但目前难以量化评估。

Method: 使用同步追踪和事件数据分析2413个防守序列，引入空间控制、拉伸指数、压力指数和防线高度等指标，采用双向ANOVA和XGBoost预测建模。

Result: 相对防线高度与防守成功关联最强，XGBoost模型在巴塞罗那和皇家马德里的ROC AUC分别达到0.724和0.698，巴塞罗那依赖高空间控制和紧凑防线，皇马防守结构更适应但不一致。

Conclusion: 可解释的空间指标具有战术和预测价值，能够有效量化集体防守表现，为球队战术分析提供新工具。

Abstract: Defensive organization is critical in soccer, particularly during negative transitions when teams are most vulnerable. The back-four defensive line plays a decisive role in preventing goal-scoring opportunities, yet its collective coordination remains difficult to quantify. This study introduces interpretable spatio-temporal indicators namely, space control, stretch index, pressure index, and defensive line height (absolute and relative) to evaluate the effectiveness of the back-four during defensive transitions. Using synchronized tracking and event data from the 2023-24 LaLiga season, 2,413 defensive sequences were analyzed following possession losses by FC Barcelona and Real Madrid CF. Two-way ANOVA revealed significant effects of team, outcome, and their interaction for key indicators, with relative line height showing the strongest association with defensive success. Predictive modeling using XGBoost achieved the highest discriminative performance (ROC AUC: 0.724 for Barcelona, 0.698 for Real Madrid), identifying space score and relative line height as dominant predictors. Comparative analysis revealed distinct team-specific defensive behaviors: Barcelona's success was characterized by higher spatial control and compact line coordination, whereas Real Madrid exhibited more adaptive but less consistent defensive structures. These findings demonstrate the tactical and predictive value of interpretable spatial indicators for quantifying collective defensive performance.

</details>


### [22] [The Imperfect Learner: Incorporating Developmental Trajectories in Memory-based Student Simulation](https://arxiv.org/abs/2511.05903)
*Zhengyuan Liu,Stella Xin Yin,Bryan Chen Zhengyu Tan,Roy Ka-Wei Lee,Guimei Liu,Dion Hoe-Lian Goh,Wenya Wang,Nancy F. Chen*

Main category: cs.CY

TL;DR: 提出了一个基于记忆的学生模拟框架，通过分层记忆机制和结构化知识表示来模拟学生的渐进知识构建过程，并整合元认知过程和个性特征来丰富学习者画像。


<details>
  <summary>Details</summary>
Motivation: 现有学生模拟方法局限于单一学习体验，无法反映学生的渐进知识构建和技能发展过程，且大语言模型倾向于直接准确回答，难以体现真实学习者的不完全理解和发育限制。

Method: 开发了基于记忆的学生模拟框架，采用分层记忆机制和结构化知识表示来模拟发展轨迹，整合元认知过程和个性特征，并基于下一代科学标准实现课程对齐的模拟器。

Result: 实验结果表明，该方法能有效反映知识发展的渐进性和学生面临的典型困难，提供更准确的学习过程表示。

Conclusion: 该框架能够更准确地模拟学生的学习过程，特别是知识构建的渐进性和个体学习特征，为教育应用提供了更真实的学生模拟方法。

Abstract: User simulation is important for developing and evaluating human-centered AI, yet current student simulation in educational applications has significant limitations. Existing approaches focus on single learning experiences and do not account for students' gradual knowledge construction and evolving skill sets. Moreover, large language models are optimized to produce direct and accurate responses, making it challenging to represent the incomplete understanding and developmental constraints that characterize real learners. In this paper, we introduce a novel framework for memory-based student simulation that incorporates developmental trajectories through a hierarchical memory mechanism with structured knowledge representation. The framework also integrates metacognitive processes and personality traits to enrich the individual learner profiling, through dynamical consolidation of both cognitive development and personal learning characteristics. In practice, we implement a curriculum-aligned simulator grounded on the Next Generation Science Standards. Experimental results show that our approach can effectively reflect the gradual nature of knowledge development and the characteristic difficulties students face, providing a more accurate representation of learning processes.

</details>


### [23] [Designing Incident Reporting Systems for Harms from General-Purpose AI](https://arxiv.org/abs/2511.05914)
*Kevin Wei,Lennart Heim*

Main category: cs.CY

TL;DR: 提出了AI事件报告系统的概念框架和制度设计考虑，包括7个维度：政策目标、报告提交和接收主体、报告事件类型、风险实现程度、报告执行、报告者匿名性、报告后行动。通过9个案例研究，为美国AI事件报告系统设计提供建议。


<details>
  <summary>Details</summary>
Motivation: 随着通用AI系统日益普及，它们正在造成更多现实世界危害，并显示出可能引发更危险事件的潜力。需要建立有效的AI事件报告系统来收集安全相关事件信息。

Method: 通过文献综述开发了AI事件报告系统的制度设计框架，并分析了9个安全关键行业的案例研究，提取设计考虑因素。

Result: 建立了包含7个维度的AI事件报告系统框架，识别了监管与非监管政府机构运营系统的差异、未遂事件报告、强制报告阈值与自愿报告渠道的作用等关键设计因素。

Conclusion: 该研究为研究人员和政策制定者提供了关于AI事件报告系统设计选择的指导，帮助确定在何种情况下特定设计选择可能更适合AI事件报告。

Abstract: We introduce a conceptual framework and provide considerations for the institutional design of AI incident reporting systems, i.e., processes for collecting information about safety- and rights-related events caused by general-purpose AI. As general-purpose AI systems are increasingly adopted, they are causing more real-world harms and displaying the potential to cause significantly more dangerous incidents - events that did or could have caused harm to individuals, property, or the environment. Through a literature review, we develop a framework for understanding the institutional design of AI incident reporting systems, which includes seven dimensions: policy goal, actors submitting and receiving reports, type of incidents reported, level of risk materialization, enforcement of reporting, anonymity of reporters, and post-reporting actions. We then examine nine case studies of incident reporting in safety-critical industries to extract design considerations for AI incident reporting in the United States. We discuss, among other factors, differences in systems operated by regulatory vs. non-regulatory government agencies, near miss reporting, the roles of mandatory reporting thresholds and voluntary reporting channels, how to enable safety learning after reporting, sharing incident information, and clarifying legal frameworks for reporting. Our aim is to inform researchers and policymakers about when particular design choices might be more or less appropriate for AI incident reporting.

</details>


### [24] [Who Gets Heard? Rethinking Fairness in AI for Music Systems](https://arxiv.org/abs/2511.05953)
*Atharva Mehta,Shivam Chauhan,Megha Sharma,Gus Xia,Kaustuv Kanti Ganguli,Nishanth Chandran,Zeerak Talat,Monojit Choudhury*

Main category: cs.CY

TL;DR: 该论文关注音乐AI系统中的文化和流派偏见问题，特别是对全球南方边缘化传统的误代表现，提出了数据集、模型和界面三个层面的改进建议。


<details>
  <summary>Details</summary>
Motivation: 音乐AI系统存在文化和流派偏见，这些偏见会误代表现边缘化传统（特别是全球南方），产生不真实的输出（如扭曲的拉格），降低创作者对系统的信任，可能强化偏见、限制创造力并导致文化擦除。

Method: 通过分析音乐AI系统中的偏见问题，提出在数据集、模型和界面三个层面的具体改进建议。

Result: 识别出音乐AI系统存在显著的文化和流派偏见，这些偏见对创作者、分发者和听众等利益相关者产生负面影响，特别是对全球南方音乐传统的误代表现。

Conclusion: 需要从数据集、模型和界面三个层面系统性解决音乐AI系统中的文化和流派偏见问题，以促进更公平和包容的音乐AI发展。

Abstract: In recent years, the music research community has examined risks of AI models for music, with generative AI models in particular, raised concerns about copyright, deepfakes, and transparency. In our work, we raise concerns about cultural and genre biases in AI for music systems (music-AI systems) which affect stakeholders including creators, distributors, and listeners shaping representation in AI for music. These biases can misrepresent marginalized traditions, especially from the Global South, producing inauthentic outputs (e.g., distorted ragas) that reduces creators' trust on these systems. Such harms risk reinforcing biases, limiting creativity, and contributing to cultural erasure. To address this, we offer recommendations at dataset, model and interface level in music-AI systems.

</details>


### [25] [Simulating Students with Large Language Models: A Review of Architecture, Mechanisms, and Role Modelling in Education with Generative AI](https://arxiv.org/abs/2511.06078)
*Luis Marquez-Carpintero,Alberto Lopez-Sellers,Miguel Cazorla*

Main category: cs.CY

TL;DR: 本文对使用大语言模型（LLMs）模拟学生行为的研究进行了主题综述，分析了LLM在教育环境中模拟学习者原型、响应教学输入和参与多智能体课堂互动的能力，并探讨了相关技术挑战和研究方向。


<details>
  <summary>Details</summary>
Motivation: 模拟学生为评估教学方法和建模多样化学习者提供了有价值的方法论框架，但传统方法难以在真实环境中系统实施。LLMs因其语言真实性和行为适应性而成为教育研究中特别有前景的模拟工具。

Method: 采用主题综述方法，综合分析了使用LLMs模拟学生行为的实证和方法论研究，包括对学习者原型模拟、教学响应和多智能体交互的评估。

Result: LLMs在自然语言生成和情境灵活性方面超越了基于规则的系统，能够有效模拟多样化的学习者特征和行为模式，但存在算法偏见、评估可靠性和教育目标对齐等持续关注的问题。

Conclusion: LLM模拟学生系统在自适应学习系统和教学设计中具有重要应用潜力，但需要解决现有技术和方法论差距，包括算法偏见和教育目标对齐等挑战。

Abstract: Simulated Students offer a valuable methodological framework for evaluating pedagogical approaches and modelling diverse learner profiles, tasks which are otherwise challenging to undertake systematically in real-world settings. Recent research has increasingly focused on developing such simulated agents to capture a range of learning styles, cognitive development pathways, and social behaviours. Among contemporary simulation techniques, the integration of large language models (LLMs) into educational research has emerged as a particularly versatile and scalable paradigm. LLMs afford a high degree of linguistic realism and behavioural adaptability, enabling agents to approximate cognitive processes and engage in contextually appropriate pedagogical dialogues. This paper presents a thematic review of empirical and methodological studies utilising LLMs to simulate student behaviour across educational environments. We synthesise current evidence on the capacity of LLM-based agents to emulate learner archetypes, respond to instructional inputs, and interact within multi-agent classroom scenarios. Furthermore, we examine the implications of such systems for curriculum development, instructional evaluation, and teacher training. While LLMs surpass rule-based systems in natural language generation and situational flexibility, ongoing concerns persist regarding algorithmic bias, evaluation reliability, and alignment with educational objectives. The review identifies existing technological and methodological gaps and proposes future research directions for integrating generative AI into adaptive learning systems and instructional design.

</details>


### [26] [Large Language Models Develop Novel Social Biases Through Adaptive Exploration](https://arxiv.org/abs/2511.06148)
*Addison J. Wu,Ryan Liu,Xuechunzi Bai,Thomas L. Griffiths*

Main category: cs.CY

TL;DR: LLMs能自发产生对人工人口群体的新社会偏见，即使这些群体间不存在固有差异。这些偏见导致任务分配高度分层，比人类分配更不公平，且在新模型和大模型中更严重。通过探索-利用权衡机制，研究发现明确激励探索能最有效减少分层。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs被集成到能够做出实际决策的框架中，确保它们无偏见变得愈发重要。现有方法仅消除已有偏见是不够的，需要研究LLMs是否会自发产生新偏见。

Method: 使用心理学文献中的范式，研究LLMs对人工人口群体的偏见形成。考察了针对模型输入、问题结构和明确引导的一系列干预措施，特别关注探索-利用权衡机制。

Result: LLMs确实会自发产生新社会偏见，导致任务分配高度分层，且这种现象在新模型和大模型中更严重。明确激励探索是最有效的干预措施，能显著减少分层。

Conclusion: LLMs不仅是人类社会偏见的被动反映者，还能从经验中主动创造新偏见，这对这些系统如何塑造社会提出了紧迫问题。

Abstract: As large language models (LLMs) are adopted into frameworks that grant them the capacity to make real decisions, it is increasingly important to ensure that they are unbiased. In this paper, we argue that the predominant approach of simply removing existing biases from models is not enough. Using a paradigm from the psychology literature, we demonstrate that LLMs can spontaneously develop novel social biases about artificial demographic groups even when no inherent differences exist. These biases result in highly stratified task allocations, which are less fair than assignments by human participants and are exacerbated by newer and larger models. In social science, emergent biases like these have been shown to result from exploration-exploitation trade-offs, where the decision-maker explores too little, allowing early observations to strongly influence impressions about entire demographic groups. To alleviate this effect, we examine a series of interventions targeting model inputs, problem structure, and explicit steering. We find that explicitly incentivizing exploration most robustly reduces stratification, highlighting the need for better multifaceted objectives to mitigate bias. These results reveal that LLMs are not merely passive mirrors of human social biases, but can actively create new ones from experience, raising urgent questions about how these systems will shape societies over time.

</details>


### [27] [Simulated Affection, Engineered Trust: How Anthropomorphic AI Benefits Surveillance Capitalism](https://arxiv.org/abs/2511.06472)
*Adele Olof-Ors,Martin Smit*

Main category: cs.CY

TL;DR: 本文认为拟人化技术是操纵用户信任和行为的认知基础设施，强化了监控资本主义逻辑，并探讨了应对方法。


<details>
  <summary>Details</summary>
Motivation: 分析拟人化技术如何作为认知基础设施操纵用户，揭示其与监控资本主义系统的关联。

Method: 借鉴尼古拉斯·卡尔的智力伦理理论，分析聊天机器人、虚拟助手、生成模型等技术如何重塑认知方式。

Result: 识别出AI新兴智力伦理如何有利于监控资本主义系统，并发现了技术对用户认知层面的深层影响。

Conclusion: 需要采取措施应对拟人化技术对认知和行为的操纵，挑战监控资本主义的逻辑。

Abstract: In this paper, we argue that anthropomorphized technology, designed to simulate emotional realism, are not neutral tools but cognitive infrastructures that manipulate user trust and behaviour. This reinforces the logic of surveillance capitalism, an under-regulated economic system that profits from behavioural manipulation and monitoring. Drawing on Nicholas Carr's theory of the intellectual ethic, we identify how technologies such as chatbots, virtual assistants, or generative models reshape not only what we think about ourselves and our world, but how we think at the cognitive level. We identify how the emerging intellectual ethic of AI benefits a system of surveillance capitalism, and discuss the potential ways of addressing this.

</details>


### [28] [From Catastrophic to Concrete: Reframing AI Risk Communication for Public Mobilization](https://arxiv.org/abs/2511.06525)
*Philip Trippenbach,Isabella Scala,Jai Bhambra,Rowan Emslie*

Main category: cs.CY

TL;DR: 论文研究发现，相比AI存在风险，公众更关注AI对就业、儿童和日常生活的直接影响，这些主题更能激发公众参与和行动。通过跨国调查识别出两个易受此类信息影响的群体，并建议以此策略推动AI监管政策。


<details>
  <summary>Details</summary>
Motivation: 当前AI治理需要公众参与，但基于存在风险的沟通策略未能有效动员公众。研究旨在探索能真正激发公众参与的有效沟通框架。

Method: 通过1063名受访者的实际信息测试和五个国家的调查数据，分析不同AI风险框架对公众动员的影响，并识别易受影响的群体特征。

Result: 就业和儿童相关的AI风险最能动员公众，存在风险表现最差。识别出Tech-Positive Urbanites和World Guardians两个群体对此类信息特别敏感且更可能参与公民行动。

Conclusion: 围绕日常关切的动员策略可以提高AI的政治显著性，创造政策需求，为成功的监管改革创造条件。

Abstract: Effective governance of artificial intelligence (AI) requires public engagement, yet communication strategies centered on existential risk have not produced sustained mobilization. In this paper, we examine the psychological and opinion barriers that limit engagement with extinction narratives, such as mortality avoidance, exponential growth bias, and the absence of self-referential anchors. We contrast them with evidence that public concern over AI rises when framed in terms of proximate harms such as employment disruption, relational instability, and mental health issues. We validate these findings through actual message testing with 1063 respondents, with the evidence showing that AI risks to Jobs and Children have the highest potential to mobilize people, while Existential Risk is the lowest-performing theme across all demographics. Using survey data from five countries, we identify two segments (Tech-Positive Urbanites and World Guardians) as particularly receptive to such framing and more likely to participate in civic action. Finally, we argue that mobilization around these everyday concerns can raise the political salience of AI, creating "policy demand" for structural measures to mitigate AI risks. We conclude that this strategy creates the conditions for successful regulatory change.

</details>


### [29] [Place Matters: Comparing LLM Hallucination Rates for Place-Based Legal Queries](https://arxiv.org/abs/2511.06700)
*Damian Curran,Vanessa Sporne,Lea Frermann,Jeannie Paterson*

Main category: cs.CY

TL;DR: 本研究提出了一种基于比较法功能主义的方法来评估LLM在不同地区法律知识的差异，发现在洛杉矶、伦敦和悉尼三个地区，主流闭源LLM的法律信息幻觉率存在显著地理差异。


<details>
  <summary>Details</summary>
Motivation: 量化LLM在不同地区法律知识质量的差异对于理解基于LLM的聊天机器人向用户提供的法律信息质量是否因地理位置而异至关重要，但由于不同地区的法律制度本身难以直接比较，获得有意义的比较指标具有挑战性。

Method: 基于比较法功能主义概念构建方法，从Reddit用户寻求法律咨询的帖子中提取家庭、住房、就业、犯罪和交通等领域的实际场景，使用这些场景在洛杉矶、伦敦和悉尼三个地区从LLM获取相关法律摘要，并手动评估幻觉情况。

Result: 主流闭源LLM的法律信息幻觉率与地理位置显著相关，表明这些模型提供的法律解决方案质量在地理上分布不均。此外，幻觉率与LLM多次采样时多数响应的频率呈强负相关，这为模型对法律事实预测的不确定性提供了衡量指标。

Conclusion: LLM的法律知识质量存在地理差异，模型对法律事实预测的不确定性可以通过幻觉率与多数响应频率的负相关性来衡量，这为评估和改进LLM在法律领域的应用提供了重要见解。

Abstract: How do we make a meaningful comparison of a large language model's knowledge of the law in one place compared to another? Quantifying these differences is critical to understanding if the quality of the legal information obtained by users of LLM-based chatbots varies depending on their location. However, obtaining meaningful comparative metrics is challenging because legal institutions in different places are not themselves easily comparable. In this work we propose a methodology to obtain place-to-place metrics based on the comparative law concept of functionalism. We construct a dataset of factual scenarios drawn from Reddit posts by users seeking legal advice for family, housing, employment, crime and traffic issues. We use these to elicit a summary of a law from the LLM relevant to each scenario in Los Angeles, London and Sydney. These summaries, typically of a legislative provision, are manually evaluated for hallucinations. We show that the rate of hallucination of legal information by leading closed-source LLMs is significantly associated with place. This suggests that the quality of legal solutions provided by these models is not evenly distributed across geography. Additionally, we show a strong negative correlation between hallucination rate and the frequency of the majority response when the LLM is sampled multiple times, suggesting a measure of uncertainty of model predictions of legal facts.

</details>


### [30] [Het 'right to be forgotten' en bijzondere persoonsgegevens: geen ruimte meer voor een belangenafweging? [The 'Right to Be Forgotten' and Sensitive Personal Data: No Room for Balancing?]](https://arxiv.org/abs/2511.07306)
*Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: An attorney submitted a 'right to be forgotten' delisting request to Google, regarding a blog post about a criminal conviction of the attorney in another country. The Rotterdam District Court ruled that Google may no longer link to the blog post when people search for the attorney's name. The court granted the attorney's request because the blog post concerns a criminal conviction. Personal data regarding criminal convictions are, under Dutch law, special categories of data (sometimes called sensitive data). The reasoning of the court on special categories of data creates problems for freedom of expression. This paper, in Dutch, explores how these problems can be reduced. Google has appealed the decision; the judgment of the Court of Appeals is expected in March 2017.

</details>


### [31] [Singling out people without knowing their names - Behavioural targeting, pseudonymous data, and the New Data Protection Regulation](https://arxiv.org/abs/2511.07307)
*Frederik J. Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 本文主张数据保护法应适用于行为定向营销，即使公司未将姓名与个人数据关联，只要能够识别特定个人就应视为处理个人数据。


<details>
  <summary>Details</summary>
Motivation: 行为定向营销公司声称只要不将姓名与个人数据关联就不处理个人数据，从而规避数据保护法。本文旨在论证这种观点是错误的，数据保护法应当适用于行为定向营销。

Method: 通过分析行为定向营销的实际运作方式，论证即使没有姓名关联，公司仍能识别特定个人，且行为定向涉及收集个人信息、识别个体和定向广告等核心数据处理活动。

Result: 论证表明行为定向营销确实处理个人数据，姓名只是众多标识符之一，且不是行为定向中最实用的标识符。

Conclusion: 数据保护法应适用于行为定向营销，因为其涉及识别特定个人的数据处理活动，符合数据保护法保护公平性和隐私的基本原理。

Abstract: Information about millions of people is collected for behavioural targeting, a type of marketing that involves tracking people's online behaviour for targeted advertising. It is hotly debated whether data protection law applies to behavioural targeting. Many behavioural targeting companies say that, as long as they do not tie names to data they hold about individuals, they do not process any personal data, and that, therefore, data protection law does not apply to them. European Data Protection Authorities, however, take the view that a company processes personal data if it uses data to single out a person, even if it cannot tie a name to these data. This paper argues that data protection law should indeed apply to behavioural targeting. Companies can often tie a name to nameless data about individuals. Furthermore, behavioural targeting relies on collecting information about individuals, singling out individuals, and targeting ads to individuals. Many privacy risks remain, regardless of whether companies tie a name to the information they hold about a person. A name is merely one of the identifiers that can be tied to data about a person, and it is not even the most practical identifier for behavioural targeting. Seeing data used to single out a person as personal data fits the rationale for data protection law: protecting fairness and privacy.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [32] [Evidence-Bound Autonomous Research (EviBound): A Governance Framework for Eliminating False Claims](https://arxiv.org/abs/2511.05524)
*Ruiying Chen*

Main category: cs.AI

TL;DR: EviBound是一个证据绑定的执行框架，通过双重治理门消除LLM自主研究代理的错误声明，要求机器可检查的证据来确保研究完整性。


<details>
  <summary>Details</summary>
Motivation: LLM自主研究代理经常报告虚假声明，即使缺少工件、指标矛盾或执行失败也标记任务为"完成"，需要解决这种研究完整性问题。

Method: 采用双重治理门：预执行批准门验证接受标准模式，后执行验证门通过MLflow API查询验证工件和指标。声明只有在有可查询运行ID、必需工件和FINISHED状态时才能传播。

Result: 在8个基准任务评估中，基线A（仅提示级别）产生100%幻觉，基线B（仅验证）将幻觉降至25%，EviBound（双重门）实现0%幻觉，仅增加约8.3%执行开销。

Conclusion: 研究完整性是架构属性，通过治理门而非模型规模实现。EviBound框架有效消除了LLM自主研究代理的虚假声明问题。

Abstract: LLM-based autonomous research agents report false claims: tasks marked "complete" despite missing artifacts, contradictory metrics, or failed executions. EviBound is an evidence-bound execution framework that eliminates false claims through dual governance gates requiring machine-checkable evidence.
  Two complementary gates enforce evidence requirements. The pre-execution Approval Gate validates acceptance criteria schemas before code runs, catching structural violations proactively. The post-execution Verification Gate validates artifacts via MLflow API queries (with recursive path checking) and optionally validates metrics when specified by acceptance criteria. Claims propagate only when backed by a queryable run ID, required artifacts, and FINISHED status. Bounded, confidence-gated retries (typically 1-2 attempts) recover from transient failures without unbounded loops.
  The framework was evaluated on 8 benchmark tasks spanning infrastructure validation, ML capabilities, and governance stress tests. Baseline A (Prompt-Level Only) yields 100% hallucination (8/8 claimed, 0/8 verified). Baseline B (Verification-Only) reduces hallucination to 25% (2/8 fail verification). EviBound (Dual Gates) achieves 0% hallucination: 7/8 tasks verified and 1 task correctly blocked at the approval gate, all with only approximately 8.3% execution overhead.
  This package includes execution trajectories, MLflow run IDs for all verified tasks, and a 4-step verification protocol. Research integrity is an architectural property, achieved through governance gates rather than emergent from model scale.

</details>


### [33] [SMAGDi: Socratic Multi Agent Interaction Graph Distillation for Efficient High Accuracy Reasoning](https://arxiv.org/abs/2511.05528)
*Aayush Aluru,Myra Malik,Samarth Patankar,Spencer Kim,Kevin Zhu,Sean O'Brien,Vasu Sharma*

Main category: cs.AI

TL;DR: SMAGDi是一个蒸馏框架，将5个Llama代理的多智能体系统的辩论动态压缩到紧凑的Socratic分解器-求解器学生模型中，在保持88%准确率的同时大幅减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统虽然推理准确率高，但依赖重复的代理辩论导致计算成本高昂，需要找到既能保持准确性又高效的解决方案。

Method: 将辩论轨迹表示为有向交互图，节点编码带正确性标签的中间推理步骤，边捕捉连续性和跨代理影响，学生模型通过复合目标训练结合语言建模、图监督、对比推理和嵌入对齐。

Result: 在StrategyQA和MMLU上，SMAGDi将40B多智能体系统压缩到6B学生模型，保持88%的准确率，显著优于MAGDi、标准知识蒸馏和微调基线。

Conclusion: 显式建模交互图和Socratic分解使小模型能够继承多智能体辩论的准确性优势，同时保持足够的效率用于实际部署。

Abstract: Multi-agent systems (MAS) often achieve higher reasoning accuracy than single models, but their reliance on repeated debates across agents makes them computationally expensive. We introduce SMAGDi, a distillation framework that transfers the debate dynamics of a five-agent Llama-based MAS into a compact Socratic decomposer-solver student. SMAGDi represents debate traces as directed interaction graphs, where nodes encode intermediate reasoning steps with correctness labels and edges capture continuity and cross-agent influence. The student is trained with a composite objective combining language modeling, graph-based supervision, contrastive reasoning, and embedding alignment to preserve both fluency and structured reasoning. On StrategyQA and MMLU, SMAGDi compresses a 40B multi-agent system into a 6B student while retaining 88% of its accuracy, substantially outperforming prior distillation methods such as MAGDi, standard KD, and fine-tuned baselines. These results highlight that explicitly modeling interaction graphs and Socratic decomposition enable small models to inherit the accuracy benefits of multi-agent debate while remaining efficient enough for real-world deployment.

</details>


### [34] [From Prompts to Power: Measuring the Energy Footprint of LLM Inference](https://arxiv.org/abs/2511.05597)
*Francisco Caravaca,Ángel Cuevas,Rubén Cuevas*

Main category: cs.AI

TL;DR: 本文通过大规模测量研究分析了大型语言模型推理阶段的能耗问题，开发了预测模型来估算不同架构和硬件下的能耗，并创建了浏览器扩展来提高对生成式AI环境影响的认知。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速扩展带来了前所未有的能源需求，特别是推理工作负载往往主导整个生命周期的能耗。尽管部署这些模型需要能源密集的GPU基础设施，但对推理能耗的系统分析仍然有限。

Method: 进行了大规模基于测量的研究，包含超过32,500次测量，涵盖21种GPU配置和155种模型架构，从小型开源模型到前沿系统。使用vLLM推理引擎在提示级别量化能耗，并识别架构和操作因素如何影响能源需求。

Result: 基于这些洞察开发了一个预测模型，能够准确估算未见过的架构和硬件上的推理能耗，并将其实现为浏览器扩展。

Conclusion: 该研究填补了LLM推理能耗系统分析的空白，提供了实用的工具来评估和意识生成式AI的环境影响。

Abstract: The rapid expansion of Large Language Models (LLMs) has introduced unprecedented energy demands, extending beyond training to large-scale inference workloads that often dominate total lifecycle consumption. Deploying these models requires energy-intensive GPU infrastructure, and in some cases has even prompted plans to power data centers with nuclear energy. Despite this growing relevance, systematic analyses of inference energy consumption remain limited. In this work, we present a large-scale measurement-based study comprising over 32,500 measurements across 21 GPU configurations and 155 model architectures, from small open-source models to frontier systems. Using the vLLM inference engine, we quantify energy usage at the prompt level and identify how architectural and operational factors shape energy demand. Building on these insights, we develop a predictive model that accurately estimates inference energy consumption across unseen architectures and hardware, and implement it as a browser extension to raise awareness of the environmental impact of generative AI.

</details>


### [35] [CoT-X: An Adaptive Framework for Cross-Model Chain-of-Thought Transfer and Optimization](https://arxiv.org/abs/2511.05747)
*Ziqian Bi,Kaijie Chen,Tianyang Wang,Junfeng Hao,Xinyuan Song*

Main category: cs.AI

TL;DR: 提出自适应推理摘要框架，通过语义分割、重要性评分和动态压缩来压缩推理轨迹，在保持关键推理步骤的同时显著减少token使用量，实现高效的跨模型CoT推理迁移。


<details>
  <summary>Details</summary>
Motivation: CoT推理虽然提升了LLM的问题解决能力，但带来了显著的推理开销，限制了在资源受限环境中的部署。需要找到高效的方法在不同规模和架构的模型间迁移CoT能力。

Method: 自适应推理摘要框架，包括语义分割与重要性评分、预算感知动态压缩、连贯性重建，以及基于高斯过程的贝叶斯优化模块来降低评估成本。

Result: 在7,501个医学考试问题上，相同token预算下比截断方法准确率高40%；在64个模型对上的评估证实了强跨模型可迁移性；贝叶斯优化将评估成本降低84%，并揭示了模型大小与跨域鲁棒性之间的幂律关系。

Conclusion: 推理摘要为实现高效的CoT迁移提供了实用路径，能够在严格的计算约束下实现高级推理能力。

Abstract: Chain-of-Thought (CoT) reasoning enhances the problem-solving ability of large language models (LLMs) but leads to substantial inference overhead, limiting deployment in resource-constrained settings. This paper investigates efficient CoT transfer across models of different scales and architectures through an adaptive reasoning summarization framework. The proposed method compresses reasoning traces via semantic segmentation with importance scoring, budget-aware dynamic compression, and coherence reconstruction, preserving critical reasoning steps while significantly reducing token usage. Experiments on 7{,}501 medical examination questions across 10 specialties show up to 40% higher accuracy than truncation under the same token budgets. Evaluations on 64 model pairs from eight LLMs (1.5B-32B parameters, including DeepSeek-R1 and Qwen3) confirm strong cross-model transferability. Furthermore, a Gaussian Process-based Bayesian optimization module reduces evaluation cost by 84% and reveals a power-law relationship between model size and cross-domain robustness. These results demonstrate that reasoning summarization provides a practical path toward efficient CoT transfer, enabling advanced reasoning under tight computational constraints. Code will be released upon publication.

</details>


### [36] [Anchors in the Machine: Behavioral and Attributional Evidence of Anchoring Bias in LLMs](https://arxiv.org/abs/2511.05766)
*Felipe Valencia-Clavijo*

Main category: cs.AI

TL;DR: 本文通过概率分析和归因方法研究LLMs中的锚定偏差，发现锚点会改变整个输出分布，并在Gemma-2B、Phi-2和Llama-2-7B模型中观察到稳定的锚定效应，而较小模型表现不一。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs的表面输出是否表现出锚定偏差，但缺乏对其内部机制和归因贡献的深入探索，需要更严谨的方法来区分表面模仿和深层概率变化。

Method: 使用基于对数概率的行为分析、结构化提示字段的精确Shapley值归因，以及整合行为和归因证据的统一锚定偏差敏感度评分，在六个开源模型上进行测试。

Result: 在Gemma-2B、Phi-2和Llama-2-7B中观察到稳健的锚定效应，锚点影响重新加权；较小模型如GPT-2、Falcon-RW-1B和GPT-Neo-125M表现不一；归因效果因提示设计而异。

Conclusion: LLMs中的锚定偏差是稳健、可测量和可解释的，但归因效果的脆弱性凸显了将LLMs作为人类替代品的风险，该框架为评估其他认知偏差提供了可复现路径。

Abstract: Large language models (LLMs) are increasingly examined as both behavioral subjects and decision systems, yet it remains unclear whether observed cognitive biases reflect surface imitation or deeper probability shifts. Anchoring bias, a classic human judgment bias, offers a critical test case. While prior work shows LLMs exhibit anchoring, most evidence relies on surface-level outputs, leaving internal mechanisms and attributional contributions unexplored. This paper advances the study of anchoring in LLMs through three contributions: (1) a log-probability-based behavioral analysis showing that anchors shift entire output distributions, with controls for training-data contamination; (2) exact Shapley-value attribution over structured prompt fields to quantify anchor influence on model log-probabilities; and (3) a unified Anchoring Bias Sensitivity Score integrating behavioral and attributional evidence across six open-source models. Results reveal robust anchoring effects in Gemma-2B, Phi-2, and Llama-2-7B, with attribution signaling that the anchors influence reweighting. Smaller models such as GPT-2, Falcon-RW-1B, and GPT-Neo-125M show variability, suggesting scale may modulate sensitivity. Attributional effects, however, vary across prompt designs, underscoring fragility in treating LLMs as human substitutes. The findings demonstrate that anchoring bias in LLMs is robust, measurable, and interpretable, while highlighting risks in applied domains. More broadly, the framework bridges behavioral science, LLM safety, and interpretability, offering a reproducible path for evaluating other cognitive biases in LLMs.

</details>


### [37] [DiagnoLLM: A Hybrid Bayesian Neural Language Framework for Interpretable Disease Diagnosis](https://arxiv.org/abs/2511.05810)
*Bowen Xu,Xinyue Zeng,Jiazhen Hu,Tuo Wang,Adithya Kulkarni*

Main category: cs.AI

TL;DR: DiagnoLLM是一个结合贝叶斯解卷积、eQTL引导深度学习和LLM叙述生成的混合框架，用于可解释的疾病诊断，在阿尔茨海默病检测中达到88.0%准确率。


<details>
  <summary>Details</summary>
Motivation: 构建可信赖的临床AI系统需要不仅准确的预测，还需要透明、基于生物学的解释。

Method: 使用GP-unmix高斯过程层次模型推断细胞类型特异性基因表达谱，结合eQTL分析提供的调控先验，训练神经网络分类器，并通过LLM模块生成针对不同受众的诊断报告。

Result: 在阿尔茨海默病检测中达到88.0%的准确率，人类评估确认生成的报告准确、可操作，并能针对医生和患者进行适当定制。

Conclusion: LLM作为后处理推理器而非端到端预测器时，可以在混合诊断流程中作为有效的沟通工具。

Abstract: Building trustworthy clinical AI systems requires not only accurate predictions but also transparent, biologically grounded explanations. We present \texttt{DiagnoLLM}, a hybrid framework that integrates Bayesian deconvolution, eQTL-guided deep learning, and LLM-based narrative generation for interpretable disease diagnosis. DiagnoLLM begins with GP-unmix, a Gaussian Process-based hierarchical model that infers cell-type-specific gene expression profiles from bulk and single-cell RNA-seq data while modeling biological uncertainty. These features, combined with regulatory priors from eQTL analysis, power a neural classifier that achieves high predictive performance in Alzheimer's Disease (AD) detection (88.0\% accuracy). To support human understanding and trust, we introduce an LLM-based reasoning module that translates model outputs into audience-specific diagnostic reports, grounded in clinical features, attribution signals, and domain knowledge. Human evaluations confirm that these reports are accurate, actionable, and appropriately tailored for both physicians and patients. Our findings show that LLMs, when deployed as post-hoc reasoners rather than end-to-end predictors, can serve as effective communicators within hybrid diagnostic pipelines.

</details>


### [38] [Can a Small Model Learn to Look Before It Leaps? Dynamic Learning and Proactive Correction for Hallucination Detection](https://arxiv.org/abs/2511.05854)
*Zepeng Bao,Shen Zhou,Qiankun Pi,Jianhao Chen,Mayi Xu,Ming Zhong,Yuanyuan Zhu,Tieyun Qian*

Main category: cs.AI

TL;DR: 提出了LEAP框架，通过动态学习和主动修正能力解决LLM幻觉检测中策略适应性问题，在三个基准测试中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有工具增强的幻觉检测方法使用预定义的固定验证策略，在动态变化环境中缺乏适应性，可能导致检测失败

Method: 将幻觉检测问题建模为动态策略学习问题，使用教师模型生成轨迹并动态调整策略，通过智能体调优将动态规划能力提炼到学生模型中

Result: 在三个具有挑战性的基准测试中，LEAP调优的模型优于现有最先进方法

Conclusion: LEAP框架成功解决了幻觉检测中的策略适应性问题，赋予学生模型动态学习和主动修正能力

Abstract: Hallucination in large language models (LLMs) remains a critical barrier to their safe deployment. Existing tool-augmented hallucination detection methods require pre-defined fixed verification strategies, which are crucial to the quality and effectiveness of tool calls. Some methods directly employ powerful closed-source LLMs such as GPT-4 as detectors, which are effective but too costly. To mitigate the cost issue, some methods adopt the teacher-student architecture and finetune open-source small models as detectors via agent tuning. However, these methods are limited by fixed strategies. When faced with a dynamically changing execution environment, they may lack adaptability and inappropriately call tools, ultimately leading to detection failure. To address the problem of insufficient strategy adaptability, we propose the innovative ``Learning to Evaluate and Adaptively Plan''(LEAP) framework, which endows an efficient student model with the dynamic learning and proactive correction capabilities of the teacher model. Specifically, our method formulates the hallucination detection problem as a dynamic strategy learning problem. We first employ a teacher model to generate trajectories within the dynamic learning loop and dynamically adjust the strategy based on execution failures. We then distill this dynamic planning capability into an efficient student model via agent tuning. Finally, during strategy execution, the student model adopts a proactive correction mechanism, enabling it to propose, review, and optimize its own verification strategies before execution. We demonstrate through experiments on three challenging benchmarks that our LEAP-tuned model outperforms existing state-of-the-art methods.

</details>


### [39] [An Empirical Study of Reasoning Steps in Thinking Code LLMs](https://arxiv.org/abs/2511.05874)
*Haoran Xue,Gias Uddin,Song Wang*

Main category: cs.AI

TL;DR: 对6个思考型大语言模型在代码生成任务中的推理过程进行实证研究，发现推理链质量与任务复杂度相关，完整性是主要失败模式，但模型能保持逻辑一致性并自我纠错。


<details>
  <summary>Details</summary>
Motivation: 虽然思考型LLM在生成最终答案前会展示中间推理过程，可能提高代码生成的透明度和准确性，但这些推理链的质量尚未得到充分研究。

Method: 评估6个先进推理LLM在100个不同难度代码生成任务上的表现，通过步骤计数、控制步骤预算调整和21人参与的人工评估来分析推理链结构。

Result: 针对性增加步骤可提高某些模型/任务的解决率，适度减少步骤在标准任务上通常能保持成功，但在困难任务上很少成功。任务复杂度显著影响推理质量，困难问题更容易出现不完整推理。

Conclusion: 思考型LLM在软件工程中具有保持逻辑一致性和自我纠错的能力，但推理质量受任务复杂度影响，完整性是主要挑战。

Abstract: Thinking Large Language Models (LLMs) generate explicit intermediate reasoning traces before final answers, potentially improving transparency, interpretability, and solution accuracy for code generation. However, the quality of these reasoning chains remains underexplored. We present a comprehensive empirical study examining the reasoning process and quality of thinking LLMs for code generation. We evaluate six state-of-the-art reasoning LLMs (DeepSeek-R1, OpenAI-o3-mini, Claude-3.7-Sonnet-Thinking, Gemini-2.0-Flash-Thinking, Gemini-2.5-Flash, and Qwen-QwQ) across 100 code generation tasks of varying difficulty from BigCodeBench. We quantify reasoning-chain structure through step counts and verbosity, conduct controlled step-budget adjustments, and perform a 21-participant human evaluation across three dimensions: efficiency, logical correctness, and completeness. Our step-count interventions reveal that targeted step increases can improve resolution rates for certain models/tasks, while modest reductions often preserve success on standard tasks, rarely on hard ones. Through systematic analysis, we develop a reasoning-problematic taxonomy, identifying completeness as the dominant failure mode. Task complexity significantly impacts reasoning quality; hard problems are substantially more prone to incompleteness than standard tasks. Our stability analysis demonstrates that thinking LLMs maintain consistent logical structures across computational effort levels and can self-correct previous errors. This study provides new insights into the strengths and limitations of current thinking LLMs in software engineering.

</details>


### [40] [Unveiling Modality Bias: Automated Sample-Specific Analysis for Multimodal Misinformation Benchmarks](https://arxiv.org/abs/2511.05883)
*Hehai Lin,Hui Liu,Shilei Cao,Jing Li,Haoliang Li,Wenya Wang*

Main category: cs.AI

TL;DR: 本文提出了三种基于不同粒度理论的模态偏见量化方法，用于在样本层面自动识别多模态错误信息中的模态偏见问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态错误信息基准存在对特定模态的偏见，使检测器仅基于单一模态就能做出预测。之前的研究在数据集层面量化偏见或手动识别模态与标签间的伪相关，但缺乏样本层面的深入分析且难以扩展到海量在线信息。

Method: 提出了三种不同粒度的偏见量化方法：1）粗粒度的模态效益评估；2）中粒度的信息流量化；3）细粒度的因果分析。在两个流行基准上进行了人工评估验证。

Result: 实验揭示了三个重要发现：1）集成多个视角对可靠自动分析至关重要；2）自动分析容易受到检测器引起的波动影响；3）不同视角在模态平衡样本上一致性更高，在偏见样本上分歧更大。

Conclusion: 研究为未来多模态错误信息检测提供了潜在方向，强调了集成多视角分析的重要性，并揭示了自动分析方法的局限性。

Abstract: Numerous multimodal misinformation benchmarks exhibit bias toward specific modalities, allowing detectors to make predictions based solely on one modality. While previous research has quantified bias at the dataset level or manually identified spurious correlations between modalities and labels, these approaches lack meaningful insights at the sample level and struggle to scale to the vast amount of online information. In this paper, we investigate the design for automated recognition of modality bias at the sample level. Specifically, we propose three bias quantification methods based on theories/views of different levels of granularity: 1) a coarse-grained evaluation of modality benefit; 2) a medium-grained quantification of information flow; and 3) a fine-grained causality analysis. To verify the effectiveness, we conduct a human evaluation on two popular benchmarks. Experimental results reveal three interesting findings that provide potential direction toward future research: 1)~Ensembling multiple views is crucial for reliable automated analysis; 2)~Automated analysis is prone to detector-induced fluctuations; and 3)~Different views produce a higher agreement on modality-balanced samples but diverge on biased ones.

</details>


### [41] [Self-Abstraction from Grounded Experience for Plan-Guided Policy Refinement](https://arxiv.org/abs/2511.05931)
*Hiroaki Hayashi,Bo Pang,Wenting Zhao,Ye Liu,Akash Gokul,Srijan Bansal,Caiming Xiong,Semih Yavuz,Yingbo Zhou*

Main category: cs.AI

TL;DR: SAGE是一个让LLM智能体从自身执行经验中学习并自我改进的框架，通过从具体经验中提炼抽象计划来优化后续执行策略。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体通常在静态执行框架中运行，缺乏从自身经验和历史执行中学习改进的机制，导致性能受限于初始框架设计和基础LLM能力。

Method: SAGE框架让智能体从初始执行中归纳出简洁的计划抽象，提炼关键步骤、依赖关系和约束条件，然后将学习到的抽象作为上下文指导反馈给智能体，优化其策略。

Result: SAGE在不同LLM骨干和智能体架构上带来持续性能提升，与GPT-5结合时相比Mini-SWE-Agent基线获得7.2%相对性能提升，在SWE-Bench Verified基准测试中分别达到73.2%和74%的Pass@1解决率。

Conclusion: SAGE框架通过自我抽象学习机制有效提升了LLM智能体的性能，证明了从经验中学习对智能体自我改进的重要性。

Abstract: Large language model (LLM) based agents are increasingly used to tackle software engineering tasks that require multi-step reasoning and code modification, demonstrating promising yet limited performance. However, most existing LLM agents typically operate within static execution frameworks, lacking a principled mechanism to learn and self-improve from their own experience and past rollouts. As a result, their performance remains bounded by the initial framework design and the underlying LLM's capabilities. We propose Self-Abstraction from Grounded Experience (SAGE), a framework that enables agents to learn from their own task executions and refine their behavior through self-abstraction. After an initial rollout, the agent induces a concise plan abstraction from its grounded experience, distilling key steps, dependencies, and constraints. This learned abstraction is then fed back as contextual guidance, refining the agent's policy and supporting more structured, informed subsequent executions. Empirically, SAGE delivers consistent performance gains across diverse LLM backbones and agent architectures. Notably, it yields a 7.2% relative performance improvement over the strong Mini-SWE-Agent baseline when paired with the GPT-5 (high) backbone. SAGE further achieves strong overall performance on SWE-Bench Verified benchmark, reaching 73.2% and 74% Pass@1 resolve rates with the Mini-SWE-Agent and OpenHands CodeAct agent framework, respectively.

</details>


### [42] [Klear-AgentForge: Forging Agentic Intelligence through Posttraining Scaling](https://arxiv.org/abs/2511.05951)
*Qi Wang,Hongzhi Zhang,Jia Fu,Kai Fu,Yahui Liu,Tinghai Zhang,Chenxi Sun,Gangwei Jiang,Jingyi Tang,Xingguang Ji,Yang Yue,Jingyuan Zhang,Fuzheng Zhang,Kun Gai,Guorui Zhou*

Main category: cs.AI

TL;DR: 本文提出了一个完全开源的智能体模型训练管道Klear-Qwen3-AgentForge-8B，从Qwen3-8B基础模型开始，通过监督微调和多轮强化学习，在工具使用和编程领域实现了同类尺寸模型中的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 尽管强大的智能体模型不断涌现，但缺乏关键的训练后细节阻碍了开源社区开发强大的对应模型。

Method: 设计了有效的监督微调（使用合成数据）和多轮强化学习，以解锁多种不同智能体任务的潜力。

Result: Klear-Qwen3-AgentForge-8B在类似尺寸的LLM中实现了最先进的性能，并与显著更大的模型保持竞争力。

Conclusion: 该研究提供了一个全面且完全开源的管道，用于训练高性能的智能体模型，能够与外部工具和环境交互。

Abstract: Despite the proliferation of powerful agentic models, the lack of critical post-training details hinders the development of strong counterparts in the open-source community. In this study, we present a comprehensive and fully open-source pipeline for training a high-performance agentic model for interacting with external tools and environments, named Klear-Qwen3-AgentForge, starting from the Qwen3-8B base model. We design effective supervised fine-tuning (SFT) with synthetic data followed by multi-turn reinforcement learning (RL) to unlock the potential for multiple diverse agentic tasks. We perform exclusive experiments on various agentic benchmarks in both tool use and coding domains. Klear-Qwen3-AgentForge-8B achieves state-of-the-art performance among LLMs of similar size and remains competitive with significantly larger models.

</details>


### [43] [An Epistemic Perspective on Agent Awareness](https://arxiv.org/abs/2511.05977)
*Pavel Naumov,Alexandra Pavlova*

Main category: cs.AI

TL;DR: 该论文将智能体意识视为一种知识形式，打破了现有文献传统。区分了这种知识的de re和de dicto形式，引入了两种模态来捕捉这些形式，并使用2D语义学形式化其含义。主要技术结果是描述这两种模态与标准"事实知识"模态之间相互作用的完备逻辑系统。


<details>
  <summary>Details</summary>
Motivation: 打破现有文献中将智能体意识视为传统知识形式的惯例，提出将意识本身视为一种知识类型的新视角。

Method: 区分de re和de dicto形式的意识知识，引入两种相应的模态，使用2D语义学形式化其含义，并构建描述这些模态与标准知识模态相互作用的逻辑系统。

Result: 开发了一个完备的逻辑系统，能够准确描述两种意识知识模态与标准事实知识模态之间的相互作用关系。

Conclusion: 通过将智能体意识重新概念化为知识形式，并建立相应的形式化框架，为理解意识与知识之间的关系提供了新的理论基础和工具。

Abstract: The paper proposes to treat agent awareness as a form of knowledge, breaking the tradition in the existing literature on awareness. It distinguishes the de re and de dicto forms of such knowledge. The work introduces two modalities capturing these forms and formally specifies their meaning using a version of 2D-semantics. The main technical result is a sound and complete logical system describing the interplay between the two proposed modalities and the standard "knowledge of the fact" modality.

</details>


### [44] [ScRPO: From Errors to Insights](https://arxiv.org/abs/2511.06065)
*Lianrui Li,Dakuan Lu,Jiawei Shao,Chi Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: 提出ScRPO框架，通过自我反思和纠错机制增强大语言模型在数学问题上的表现，包含试错学习和自我纠正两个阶段，在多个数学推理基准测试中优于现有后训练方法。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在复杂数学问题上表现不佳的问题，通过自我反思和纠错机制来提升模型性能，减少对外部反馈的依赖。

Method: 两阶段方法：1) 试错学习阶段使用GRPO训练并收集错误答案建立错误池；2) 自我纠正学习阶段引导模型反思先前错误答案的原因。

Result: 在AIME、AMC、Olympiad、MATH-500、GSM8k等多个数学推理基准测试中，使用Deepseek-Distill-Qwen-1.5B和7B模型，ScRPO均优于其他后训练方法。

Conclusion: ScRPO为语言模型在有限外部反馈下实现自我改进提供了有前景的范式，有助于构建更可靠和强大的AI系统。

Abstract: We propose Self-correction Relative Policy Optimization (ScRPO), a novel reinforcement learning framework designed to enhance large language models on challenging mathematical problems by leveraging self-reflection and error correction. Our approach consists of two stages: (1) Trial-and-error learning stage: training the model with GRPO and collecting incorrect answers along with their corresponding questions in an error pool; (2) Self-correction learning stage: guiding the model to reflect on why its previous answers were wrong. Extensive experiments across multiple math reasoning benchmarks, including AIME, AMC, Olympiad, MATH-500, GSM8k, using Deepseek-Distill-Qwen-1.5B and Deepseek-Distill-Qwen-7B. The experimental results demonstrate that ScRPO consistently outperforms several post-training methods. These findings highlight ScRPO as a promising paradigm for enabling language models to self-improve on difficult tasks with limited external feedback, paving the way toward more reliable and capable AI systems.

</details>


### [45] [Maestro: Learning to Collaborate via Conditional Listwise Policy Optimization for Multi-Agent LLMs](https://arxiv.org/abs/2511.06134)
*Wei Yang,Jiacheng Pang,Shixuan Li,Paul Bogdan,Stephen Tu,Jesse Thomason*

Main category: cs.AI

TL;DR: 提出了Maestro框架，通过角色编排解决多智能体系统中的探索-合成平衡问题，结合CLPO强化学习实现更好的信用分配，在数学推理和问题解决任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的多智能体系统难以平衡解决方案空间的广泛探索与最优解的收敛合成，容易出现过早共识、错误传播和信用分配问题。

Method: Maestro框架结构性地分离探索和合成认知模式：使用并行执行智能体进行多样化探索，专用中央智能体进行收敛性合成评估；引入CLPO强化学习目标，结合决策导向的策略梯度和理由的列表排序损失。

Result: 在数学推理和通用问题解决基准测试中，Maestro结合CLPO持续优于现有最先进的多智能体方法，平均绝对准确率提升6%，最佳情况下提升10%。

Conclusion: Maestro框架通过角色编排和CLPO的有效结合，成功解决了多智能体系统中的探索-合成平衡问题，实现了更好的性能表现。

Abstract: Multi-agent systems (MAS) built on Large Language Models (LLMs) are being used to approach complex problems and can surpass single model inference. However, their success hinges on navigating a fundamental cognitive tension: the need to balance broad, divergent exploration of the solution space with a principled, convergent synthesis to the optimal solution. Existing paradigms often struggle to manage this duality, leading to premature consensus, error propagation, and a critical credit assignment problem that fails to distinguish between genuine reasoning and superficially plausible arguments. To resolve this core challenge, we propose the Multi-Agent Exploration-Synthesis framework Through Role Orchestration (Maestro), a principled paradigm for collaboration that structurally decouples these cognitive modes. Maestro uses a collective of parallel Execution Agents for diverse exploration and a specialized Central Agent for convergent, evaluative synthesis. To operationalize this critical synthesis phase, we introduce Conditional Listwise Policy Optimization (CLPO), a reinforcement learning objective that disentangles signals for strategic decisions and tactical rationales. By combining decision-focused policy gradients with a list-wise ranking loss over justifications, CLPO achieves clean credit assignment and stronger comparative supervision. Experiments on mathematical reasoning and general problem-solving benchmarks demonstrate that Maestro, coupled with CLPO, consistently outperforms existing state-of-the-art multi-agent approaches, delivering absolute accuracy gains of 6% on average and up to 10% at best.

</details>


### [46] [When Object-Centric World Models Meet Policy Learning: From Pixels to Policies, and Where It Breaks](https://arxiv.org/abs/2511.06136)
*Stefano Ferraro,Akihiro Nakano,Masahiro Suzuki,Yutaka Matsuo*

Main category: cs.AI

TL;DR: DLPWM是一个无监督的、解耦的以对象为中心的世界模型，在视觉重建和预测方面表现良好，但在下游控制任务中表现不如DreamerV3，主要原因是多对象交互中的表示漂移问题。


<details>
  <summary>Details</summary>
Motivation: 研究以对象为中心的世界模型是否能通过解耦的对象级表示来提升强化学习中的组合泛化能力和数据效率，特别是测试任务相关信息定位是否能改善策略性能。

Method: 提出了DLPWM，一个完全无监督的解耦对象中心世界模型，直接从像素中学习对象级潜在表示。

Result: DLPWM在重建和预测方面表现强劲，对多种分布外视觉变化具有鲁棒性，但在模型控制任务中策略性能不如DreamerV3，潜在轨迹分析显示多对象交互中的表示漂移是策略学习不稳定的关键因素。

Conclusion: 虽然以对象为中心的感知支持鲁棒的视觉建模，但要实现稳定的控制需要缓解潜在漂移问题。

Abstract: Object-centric world models (OCWM) aim to decompose visual scenes into object-level representations, providing structured abstractions that could improve compositional generalization and data efficiency in reinforcement learning. We hypothesize that explicitly disentangled object-level representations, by localizing task-relevant information, can enhance policy performance across novel feature combinations. To test this hypothesis, we introduce DLPWM, a fully unsupervised, disentangled object-centric world model that learns object-level latents directly from pixels. DLPWM achieves strong reconstruction and prediction performance, including robustness to several out-of-distribution (OOD) visual variations. However, when used for downstream model-based control, policies trained on DLPWM latents underperform compared to DreamerV3. Through latent-trajectory analyses, we identify representation shift during multi-object interactions as a key driver of unstable policy learning. Our results suggest that, although object-centric perception supports robust visual modeling, achieving stable control requires mitigating latent drift.

</details>


### [47] [MALinZero: Efficient Low-Dimensional Search for Mastering Complex Multi-Agent Planning](https://arxiv.org/abs/2511.06142)
*Sizhe Tang,Jiayu Chen,Tian Lan*

Main category: cs.AI

TL;DR: MALinZero是一种新方法，通过将联合动作回报投影到低维空间来解决多智能体规划中MCTS面临的动作空间组合爆炸问题，使用上下文线性赌博机公式和LinUCT实现高效探索与利用。


<details>
  <summary>Details</summary>
Motivation: 多智能体规划中，MCTS面临联合动作空间指数级增长的问题，导致树扩展的分支因子急剧增加，难以有效进行探索和利用。

Method: 将联合动作回报投影到低维空间，使用上下文线性赌博机问题表述，通过凸且μ-平滑的损失函数解决该问题，并推导出线性上置信界应用于树（LinUCT）。

Result: 在矩阵游戏、SMAC和SMACv2等多智能体基准测试中达到最先进性能，优于基于模型和无模型的多智能体强化学习基线，具有更快的学习速度和更好的性能。

Conclusion: MALinZero通过低维表示结构有效解决了多智能体规划中的组合爆炸问题，实现了高效的MCTS搜索。

Abstract: Monte Carlo Tree Search (MCTS), which leverages Upper Confidence Bound for Trees (UCTs) to balance exploration and exploitation through randomized sampling, is instrumental to solving complex planning problems. However, for multi-agent planning, MCTS is confronted with a large combinatorial action space that often grows exponentially with the number of agents. As a result, the branching factor of MCTS during tree expansion also increases exponentially, making it very difficult to efficiently explore and exploit during tree search. To this end, we propose MALinZero, a new approach to leverage low-dimensional representational structures on joint-action returns and enable efficient MCTS in complex multi-agent planning. Our solution can be viewed as projecting the joint-action returns into the low-dimensional space representable using a contextual linear bandit problem formulation. We solve the contextual linear bandit problem with convex and $μ$-smooth loss functions -- in order to place more importance on better joint actions and mitigate potential representational limitations -- and derive a linear Upper Confidence Bound applied to trees (LinUCT) to enable novel multi-agent exploration and exploitation in the low-dimensional space. We analyze the regret of MALinZero for low-dimensional reward functions and propose an $(1-\tfrac1e)$-approximation algorithm for the joint action selection by maximizing a sub-modular objective. MALinZero demonstrates state-of-the-art performance on multi-agent benchmarks such as matrix games, SMAC, and SMACv2, outperforming both model-based and model-free multi-agent reinforcement learning baselines with faster learning speed and better performance.

</details>


### [48] [Evaluating Implicit Biases in LLM Reasoning through Logic Grid Puzzles](https://arxiv.org/abs/2511.06160)
*Fatima Jahara,Mark Dredze,Sharon Levy*

Main category: cs.AI

TL;DR: 提出了PRIME评估框架，使用逻辑网格谜题系统性地探测LLMs在逻辑推理中受社会刻板印象影响的程度，发现模型在解决方案符合刻板印象时推理更准确。


<details>
  <summary>Details</summary>
Motivation: 现有安全护栏能抑制明显的偏见输出，但在复杂逻辑推理任务中更微妙的社会偏见会显现，而当前评估基准无法捕捉这些。

Method: 使用逻辑网格谜题构建PRIME框架，包含刻板印象、反刻板印象和中立三种变体，自动生成和验证，评估多种模型家族并测试提示缓解策略。

Result: 模型在解决方案符合性别刻板印象时推理准确率更高，表明刻板印象在LLMs演绎推理中持续存在。

Conclusion: PRIME对于诊断和量化LLMs演绎推理中的社会偏见具有重要意义，特别是在公平性至关重要的场景中。

Abstract: While recent safety guardrails effectively suppress overtly biased outputs, subtler forms of social bias emerge during complex logical reasoning tasks that evade current evaluation benchmarks. To fill this gap, we introduce a new evaluation framework, PRIME (Puzzle Reasoning for Implicit Biases in Model Evaluation), that uses logic grid puzzles to systematically probe the influence of social stereotypes on logical reasoning and decision making in LLMs. Our use of logic puzzles enables automatic generation and verification, as well as variability in complexity and biased settings. PRIME includes stereotypical, anti-stereotypical, and neutral puzzle variants generated from a shared puzzle structure, allowing for controlled and fine-grained comparisons. We evaluate multiple model families across puzzle sizes and test the effectiveness of prompt-based mitigation strategies. Focusing our experiments on gender stereotypes, our findings highlight that models consistently reason more accurately when solutions align with stereotypical associations. This demonstrates the significance of PRIME for diagnosing and quantifying social biases perpetuated in the deductive reasoning of LLMs, where fairness is critical.

</details>


### [49] [Chasing Consistency: Quantifying and Optimizing Human-Model Alignment in Chain-of-Thought Reasoning](https://arxiv.org/abs/2511.06168)
*Boxuan Wang,Zhuoyun Li,Xinmiao Huang,Xiaowei Huang,Yi Dong*

Main category: cs.AI

TL;DR: 提出了一种通过Alignment Score评估LLM推理一致性的框架，发现2跳推理链对齐度最高，定义了四种错误类型，并提出了SCOS方法来优化推理一致性。


<details>
  <summary>Details</summary>
Motivation: 评估和优化大语言模型在链式推理中的一致性，解决推理链与人类参考链之间的语义对齐问题。

Method: 提出Alignment Score度量标准，定义四种错误类型（逻辑断开、主题偏移、冗余推理、因果颠倒），并开发SCOS方法采样对齐错误最少的推理链。

Result: 实证发现2跳推理链对齐度最高，SCOS方法将Alignment Score平均提升29.84%，在3跳任务等长推理链中效果显著。

Conclusion: 该框架有效评估和优化LLM推理一致性，SCOS方法能显著提升长推理链的语义对齐质量。

Abstract: This paper presents a framework for evaluating and optimizing reasoning consistency in Large Language Models (LLMs) via a new metric, the Alignment Score, which quantifies the semantic alignment between model-generated reasoning chains and human-written reference chains in Chain-of-Thought (CoT) reasoning. Empirically, we find that 2-hop reasoning chains achieve the highest Alignment Score. To explain this phenomenon, we define four key error types: logical disconnection, thematic shift, redundant reasoning, and causal reversal, and show how each contributes to the degradation of the Alignment Score. Building on this analysis, we further propose Semantic Consistency Optimization Sampling (SCOS), a method that samples and favors chains with minimal alignment errors, significantly improving Alignment Scores by an average of 29.84% with longer reasoning chains, such as in 3-hop tasks.

</details>


### [50] [CSP4SDG: Constraint and Information-Theory Based Role Identification in Social Deduction Games with LLM-Enhanced Inference](https://arxiv.org/abs/2511.06175)
*Kaijie Xu,Fandi Meng,Clark Verbrugge,Simon Lucas*

Main category: cs.AI

TL;DR: CSP4SDG是一个用于社交推理游戏的约束满足框架，通过硬约束和软约束分析游戏事件和对话，实现实时可解释的角色推断，在三个公开数据集上超越LLM基线模型。


<details>
  <summary>Details</summary>
Motivation: 社交推理游戏中玩家隐藏身份并故意误导他人，准确的角色识别是游戏表现的关键，但现有方法面临挑战。

Method: 将游戏事件和对话映射到四个语言无关的约束类别：证据、现象、断言和假设，使用硬约束修剪不可能的角色分配，加权软约束对剩余分配评分，信息增益加权将每个假设与其在熵减少下的期望值联系起来。

Result: 在三个公开数据集上，CSP4SDG在所有推理场景中都优于基于LLM的基线模型，并且当作为辅助"推理工具"提供给LLM时能提升LLM性能。

Conclusion: 基于信息论的原则性概率推理是社交推理游戏中重量级神经模型的可扩展替代或补充方案。

Abstract: In Social Deduction Games (SDGs) such as Avalon, Mafia, and Werewolf, players conceal their identities and deliberately mislead others, making hidden-role inference a central and demanding task. Accurate role identification, which forms the basis of an agent's belief state, is therefore the keystone for both human and AI performance. We introduce CSP4SDG, a probabilistic, constraint-satisfaction framework that analyses gameplay objectively. Game events and dialogue are mapped to four linguistically-agnostic constraint classes-evidence, phenomena, assertions, and hypotheses. Hard constraints prune impossible role assignments, while weighted soft constraints score the remainder; information-gain weighting links each hypothesis to its expected value under entropy reduction, and a simple closed-form scoring rule guarantees that truthful assertions converge to classical hard logic with minimum error. The resulting posterior over roles is fully interpretable and updates in real time. Experiments on three public datasets show that CSP4SDG (i) outperforms LLM-based baselines in every inference scenario, and (ii) boosts LLMs when supplied as an auxiliary "reasoning tool." Our study validates that principled probabilistic reasoning with information theory is a scalable alternative-or complement-to heavy-weight neural models for SDGs.

</details>


### [51] [Dataforge: A Data Agent Platform for Autonomous Data Engineering](https://arxiv.org/abs/2511.06185)
*Xinyuan Wang,Yanjie Fu*

Main category: cs.AI

TL;DR: Data Agent是一个完全自主的表格数据处理系统，利用大语言模型推理和验证，自动执行数据清洗、分层路由和特征级优化，实现从原始数据到AI就绪数据的端到端转换。


<details>
  <summary>Details</summary>
Motivation: AI应用在材料发现、分子建模和气候科学等领域的需求增长，使得数据准备成为重要但劳动密集的步骤。原始数据需要清洗、标准化和转换才能用于AI训练，而有效的特征转换和选择对于高效训练和推理至关重要。

Method: 利用大语言模型推理和基于验证的方法，通过双反馈循环自动执行数据清洗、分层路由和特征级优化。系统基于三个核心原则：自动化、安全性和非专家友好性。

Result: 展示了首个实用的自主Data Agent实现，能够将原始数据转换为更好的数据，无需人工监督。

Conclusion: Data Agent系统解决了数据准备的可扩展性和专业知识依赖问题，实现了从数据到更好数据的端到端可靠转换。

Abstract: The growing demand for AI applications in fields such as materials discovery, molecular modeling, and climate science has made data preparation an important but labor-intensive step. Raw data from diverse sources must be cleaned, normalized, and transformed to become AI-ready, while effective feature transformation and selection are essential for efficient training and inference. To address the challenges of scalability and expertise dependence, we present Data Agent, a fully autonomous system specialized for tabular data. Leveraging large language model (LLM) reasoning and grounded validation, Data Agent automatically performs data cleaning, hierarchical routing, and feature-level optimization through dual feedback loops. It embodies three core principles: automatic, safe, and non-expert friendly, which ensure end-to-end reliability without human supervision. This demo showcases the first practical realization of an autonomous Data Agent, illustrating how raw data can be transformed "From Data to Better Data."

</details>


### [52] [Reasoning with Confidence: Efficient Verification of LLM Reasoning Steps via Uncertainty Heads](https://arxiv.org/abs/2511.06209)
*Jingwei Ni,Ekaterina Fadeeva,Tianyi Wu,Mubashara Akhtar,Jiaheng Zhang,Elliott Ash,Markus Leippold,Timothy Baldwin,See-Kiong Ng,Artem Shelmanov,Mrinmaya Sachan*

Main category: cs.AI

TL;DR: 提出一种基于数据驱动不确定性分数的轻量级推理步骤验证方法，通过训练transformer不确定性量化头来利用LLM内部状态估计推理步骤的不确定性，无需大量人工标注，性能可与大810倍的PRMs相媲美。


<details>
  <summary>Details</summary>
Motivation: 现有推理验证方法如过程奖励模型计算成本高、领域受限或需要大规模标注，需要一种轻量、自动化的替代方案来验证LLM推理步骤的正确性。

Method: 训练transformer不确定性量化头，利用冻结LLM的内部状态来估计推理步骤的不确定性，标签由更大LLM或原始模型自监督生成，参数量小于10M。

Result: 在数学、规划和常识问答等多个领域，该方法性能匹配甚至超过比其大810倍的过程奖励模型，表明LLM内部状态编码了不确定性信息。

Conclusion: LLM内部状态可作为推理验证的可靠信号，为构建可扩展和泛化的自省LLMs提供了有前景的方向。

Abstract: Solving complex tasks usually requires LLMs to generate long multi-step reasoning chains. Previous work has shown that verifying the correctness of individual reasoning steps can further improve the performance and efficiency of LLMs on such tasks and enhance solution interpretability. However, existing verification approaches, such as Process Reward Models (PRMs), are either computationally expensive, limited to specific domains, or require large-scale human or model-generated annotations. Thus, we propose a lightweight alternative for step-level reasoning verification based on data-driven uncertainty scores. We train transformer-based uncertainty quantification heads (UHeads) that use the internal states of a frozen LLM to estimate the uncertainty of its reasoning steps during generation. The approach is fully automatic: target labels are generated either by another larger LLM (e.g., DeepSeek R1) or in a self-supervised manner by the original model itself. UHeads are both effective and lightweight, containing less than 10M parameters. Across multiple domains, including mathematics, planning, and general knowledge question answering, they match or even surpass the performance of PRMs that are up to 810x larger. Our findings suggest that the internal states of LLMs encode their uncertainty and can serve as reliable signals for reasoning verification, offering a promising direction toward scalable and generalizable introspective LLMs.

</details>


### [53] [Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B](https://arxiv.org/abs/2511.06221)
*Sen Xu,Yi Zhou,Wei Wang,Jixin Min,Zhibin Yin,Yingwei Dai,Shixi Liu,Lianyu Pang,Yirong Chen,Junlin Zhang*

Main category: cs.AI

TL;DR: VibeThinker-1.5B是一个15亿参数的密集模型，通过Spectrum-to-Signal Principle (SSP)框架开发，挑战了模型规模必须大才能有强大推理能力的共识。该模型以仅7800美元的训练成本，在数学推理基准测试中超越了DeepSeek R1等大模型，证明小模型也能达到大模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 挑战当前共识，即小模型天生缺乏强大的推理能力，并证明通过创新的训练方法，小模型也能达到甚至超越大模型的推理性能，从而大幅降低训练和推理成本，促进AI研究的民主化。

Method: 采用Spectrum-to-Signal Principle (SSP)框架：首先通过Two-Stage Diversity-Exploring Distillation (SFT)生成广泛的解决方案谱，然后使用MaxEnt-Guided Policy Optimization (RL)来放大正确信号。

Result: VibeThinker-1.5B在三个数学基准测试中超越了400倍大的DeepSeek R1：AIME24 (80.3 vs. 79.8)、AIME25 (74.4 vs. 70.0)和HMMT25 (50.4 vs. 41.7)。在LiveCodeBench V6上得分为51.1，优于Magistral Medium的50.3。相比基础模型有显著提升。

Conclusion: 研究表明小模型可以通过创新的训练方法实现与大模型相当的推理能力，这大幅降低了训练和推理成本，为AI研究的民主化提供了可能。

Abstract: Challenging the prevailing consensus that small models inherently lack robust reasoning, this report introduces VibeThinker-1.5B, a 1.5B-parameter dense model developed via our Spectrum-to-Signal Principle (SSP). This challenges the prevailing approach of scaling model parameters to enhance capabilities, as seen in models like DeepSeek R1 (671B) and Kimi k2 (>1T). The SSP framework first employs a Two-Stage Diversity-Exploring Distillation (SFT) to generate a broad spectrum of solutions, followed by MaxEnt-Guided Policy Optimization (RL) to amplify the correct signal. With a total training cost of only $7,800, VibeThinker-1.5B demonstrates superior reasoning capabilities compared to closed-source models like Magistral Medium and Claude Opus 4, and performs on par with open-source models like GPT OSS-20B Medium. Remarkably, it surpasses the 400x larger DeepSeek R1 on three math benchmarks: AIME24 (80.3 vs. 79.8), AIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7). This is a substantial improvement over its base model (6.7, 4.3, and 0.6, respectively). On LiveCodeBench V6, it scores 51.1, outperforming Magistral Medium's 50.3 and its base model's 0.0. These findings demonstrate that small models can achieve reasoning capabilities comparable to large models, drastically reducing training and inference costs and thereby democratizing advanced AI research.

</details>


### [54] [ROAR: Robust Accident Recognition and Anticipation for Autonomous Driving](https://arxiv.org/abs/2511.06226)
*Xingcheng Liu,Yanchen Guan,Haicheng Liao,Zhengbing He,Zhenning Li*

Main category: cs.AI

TL;DR: ROAR是一种新颖的事故检测和预测方法，通过结合离散小波变换、自适应对象感知模块和动态焦点损失，有效处理传感器故障、环境干扰和数据不平衡等问题，在多个数据集上优于现有基准模型。


<details>
  <summary>Details</summary>
Motivation: 现有事故预测方法假设理想条件，忽略了传感器故障、环境干扰和数据缺陷等现实挑战，且未能充分考虑不同车辆类型的驾驶员行为和事故率差异。

Method: ROAR结合离散小波变换(DWT)从噪声和不完整数据中提取特征，使用自适应对象感知模块关注高风险车辆并建模交通参与者的时空关系，采用动态焦点损失缓解正负样本类别不平衡问题。

Result: 在Dashcam Accident Dataset (DAD)、Car Crash Dataset (CCD)和AnAn Accident Detection (A3D)三个数据集上的评估显示，ROAR在平均精度(AP)和平均事故时间(mTTA)等关键指标上持续优于现有基准模型。

Conclusion: ROAR在复杂交通环境中提供了可靠且准确的事故预测解决方案，特别是在处理传感器退化、环境噪声和不平衡数据分布方面表现出鲁棒性。

Abstract: Accurate accident anticipation is essential for enhancing the safety of autonomous vehicles (AVs). However, existing methods often assume ideal conditions, overlooking challenges such as sensor failures, environmental disturbances, and data imperfections, which can significantly degrade prediction accuracy. Additionally, previous models have not adequately addressed the considerable variability in driver behavior and accident rates across different vehicle types. To overcome these limitations, this study introduces ROAR, a novel approach for accident detection and prediction. ROAR combines Discrete Wavelet Transform (DWT), a self adaptive object aware module, and dynamic focal loss to tackle these challenges. The DWT effectively extracts features from noisy and incomplete data, while the object aware module improves accident prediction by focusing on high-risk vehicles and modeling the spatial temporal relationships among traffic agents. Moreover, dynamic focal loss mitigates the impact of class imbalance between positive and negative samples. Evaluated on three widely used datasets, Dashcam Accident Dataset (DAD), Car Crash Dataset (CCD), and AnAn Accident Detection (A3D), our model consistently outperforms existing baselines in key metrics such as Average Precision (AP) and mean Time to Accident (mTTA). These results demonstrate the model's robustness in real-world conditions, particularly in handling sensor degradation, environmental noise, and imbalanced data distributions. This work offers a promising solution for reliable and accurate accident anticipation in complex traffic environments.

</details>


### [55] [GAIA: A General Agency Interaction Architecture for LLM-Human B2B Negotiation & Screening](https://arxiv.org/abs/2511.06262)
*Siming Zhao,Qi Li*

Main category: cs.AI

TL;DR: GAIA是一个面向B2B谈判和筛选的治理优先框架，通过定义角色、信息门控机制、双重反馈集成和授权边界，确保AI委托的安全性和可审计性。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在高风险B2B环境中的部署受到治理限制，需要防止未经授权的承诺、确保充分信息收集并维持有效的人类监督。

Method: 定义三个核心角色（委托人、代理、对方）和可选批评者角色，采用信息门控进展、双重反馈集成和授权边界三种协调机制。

Result: 提出了一个可复现的规范，通过任务完整性跟踪、明确状态转换和混合验证方法，确保安全高效的AI委托。

Conclusion: GAIA通过连接理论与实践，为采购、房地产和人员配置等工作流程提供了安全、高效和可问责的AI委托规范。

Abstract: Organizations are increasingly exploring delegation of screening and negotiation tasks to AI systems, yet deployment in high-stakes B2B settings is constrained by governance: preventing unauthorized commitments, ensuring sufficient information before bargaining, and maintaining effective human oversight and auditability. Prior work on large language model negotiation largely emphasizes autonomous bargaining between agents and omits practical needs such as staged information gathering, explicit authorization boundaries, and systematic feedback integration. We propose GAIA, a governance-first framework for LLM-human agency in B2B negotiation and screening. GAIA defines three essential roles - Principal (human), Delegate (LLM agent), and Counterparty - with an optional Critic to enhance performance, and organizes interactions through three mechanisms: information-gated progression that separates screening from negotiation; dual feedback integration that combines AI critique with lightweight human corrections; and authorization boundaries with explicit escalation paths. Our contributions are fourfold: (1) a formal governance framework with three coordinated mechanisms and four safety invariants for delegation with bounded authorization; (2) information-gated progression via task-completeness tracking (TCI) and explicit state transitions that separate screening from commitment; (3) dual feedback integration that blends Critic suggestions with human oversight through parallel learning channels; and (4) a hybrid validation blueprint that combines automated protocol metrics with human judgment of outcomes and safety. By bridging theory and practice, GAIA offers a reproducible specification for safe, efficient, and accountable AI delegation that can be instantiated across procurement, real estate, and staffing workflows.

</details>


### [56] [Synthetic Data-Driven Prompt Tuning for Financial QA over Tables and Documents](https://arxiv.org/abs/2511.06292)
*Yaoning Yu,Kaimin Chang,Ye Yu,Kai Wei,Haojing Luo,Haohan Wang*

Main category: cs.AI

TL;DR: 提出了一种基于数据增强优化的自改进提示框架，通过生成合成金融表格和文档片段，验证其正确性和鲁棒性，然后根据结果更新提示，在无需外部标签的情况下持续提升金融推理任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常在固定的金融文本或表格数据集上调整提示，限制了其适应新问题类型或文档结构的能力，或者需要昂贵的人工标注数据集来构建提示。

Method: 结合合成数据生成器、验证器和提示优化器的闭环框架，生成器产生暴露当前提示弱点的示例，验证器检查生成示例的有效性和鲁棒性，优化器根据结果逐步优化提示。

Result: 在DocMath-Eval基准测试中，该系统在准确性和鲁棒性方面均优于标准提示方法。

Conclusion: 将合成数据生成融入提示学习对于金融应用具有重要价值，能够在不依赖外部标签的情况下持续改进提示性能。

Abstract: Financial documents like earning reports or balance sheets often involve long tables and multi-page reports. Large language models have become a new tool to help numerical reasoning and understanding these documents. However, prompt quality can have a major effect on how well LLMs perform these financial reasoning tasks. Most current methods tune prompts on fixed datasets of financial text or tabular data, which limits their ability to adapt to new question types or document structures, or they involve costly and manually labeled/curated dataset to help build the prompts. We introduce a self-improving prompt framework driven by data-augmented optimization. In this closed-loop process, we generate synthetic financial tables and document excerpts, verify their correctness and robustness, and then update the prompt based on the results. Specifically, our framework combines a synthetic data generator with verifiers and a prompt optimizer, where the generator produces new examples that exposes weaknesses in the current prompt, the verifiers check the validity and robustness of the produced examples, and the optimizer incrementally refines the prompt in response. By iterating these steps in a feedback cycle, our method steadily improves prompt accuracy on financial reasoning tasks without needing external labels. Evaluation on DocMath-Eval benchmark demonstrates that our system achieves higher performance in both accuracy and robustness than standard prompt methods, underscoring the value of incorporating synthetic data generation into prompt learning for financial applications.

</details>


### [57] [Secu-Table: a Comprehensive security table dataset for evaluating semantic table interpretation systems](https://arxiv.org/abs/2511.06301)
*Azanzi Jiomekong,Jean Bikim,Patricia Negoue,Joyce Chin*

Main category: cs.AI

TL;DR: 本文介绍了Secu-Table数据集，包含1500多个表格和15k+实体，基于CVE和CWE安全数据构建，用于评估基于LLM的语义表解释系统在安全领域的性能。


<details>
  <summary>Details</summary>
Motivation: 在安全领域，用于评估语义表解释系统的表格数据集尚未公开可用，这限制了该领域的研究进展。

Method: 使用CVE和CWE安全数据源构建数据集，通过Wikidata和SEPSES CSKG知识图谱进行标注，并公开发布所有代码。

Result: 创建了Secu-Table数据集，包含1500多个表格和15k+实体，作为SemTab挑战赛的一部分。

Conclusion: 该数据集为安全领域的语义表解释研究提供了重要资源，初步评估使用了Falcon3-7b-instruct、Mistral-7B-Instruct和GPT-4o mini等LLM模型。

Abstract: Evaluating semantic tables interpretation (STI) systems, (particularly, those based on Large Language Models- LLMs) especially in domain-specific contexts such as the security domain, depends heavily on the dataset. However, in the security domain, tabular datasets for state-of-the-art are not publicly available. In this paper, we introduce Secu-Table dataset, composed of more than 1500 tables with more than 15k entities constructed using security data extracted from Common Vulnerabilities and Exposures (CVE) and Common Weakness Enumeration (CWE) data sources and annotated using Wikidata and the SEmantic Processing of Security Event Streams CyberSecurity Knowledge Graph (SEPSES CSKG). Along with the dataset, all the code is publicly released. This dataset is made available to the research community in the context of the SemTab challenge on Tabular to Knowledge Graph Matching. This challenge aims to evaluate the performance of several STI based on open source LLMs. Preliminary evaluation, serving as baseline, was conducted using Falcon3-7b-instruct and Mistral-7B-Instruct, two open source LLMs and GPT-4o mini one closed source LLM.

</details>


### [58] [The Station: An Open-World Environment for AI-Driven Discovery](https://arxiv.org/abs/2511.06309)
*Stephen Chung,Wenyu Du*

Main category: cs.AI

TL;DR: STATION是一个开放世界的多智能体环境，模拟微型科学生态系统，智能体可以进行长期科学研究活动，包括阅读论文、提出假设、提交代码、执行分析和发布结果，无需中央协调系统。


<details>
  <summary>Details</summary>
Motivation: 创建自主科学发现的新范式，超越传统刚性优化方法，通过开放世界环境中的涌现行为推动科学进步。

Method: 利用扩展上下文窗口，智能体在STATION环境中自由选择行动，进行长期科学探索，包括同行论文阅读、假设制定、代码提交、分析执行和结果发布。

Result: STATION中的AI智能体在数学、计算生物学和机器学习等广泛基准测试中达到新的最先进性能，特别是在圆填充问题上超越AlphaEvolve，并涌现出新的方法如scRNA-seq批次整合的密度自适应算法。

Conclusion: STATION代表了通过开放世界环境中涌现行为驱动自主科学发现的第一步，标志着超越刚性优化的新范式。

Abstract: We introduce the STATION, an open-world multi-agent environment that models a miniature scientific ecosystem. Leveraging their extended context windows, agents in the Station can engage in long scientific journeys that include reading papers from peers, formulating hypotheses, submitting code, performing analyses, and publishing results. Importantly, there is no centralized system coordinating their activities - agents are free to choose their own actions and develop their own narratives within the Station. Experiments demonstrate that AI agents in the Station achieve new state-of-the-art performance on a wide range of benchmarks, spanning from mathematics to computational biology to machine learning, notably surpassing AlphaEvolve in circle packing. A rich tapestry of narratives emerges as agents pursue independent research, interact with peers, and build upon a cumulative history. From these emergent narratives, novel methods arise organically, such as a new density-adaptive algorithm for scRNA-seq batch integration. The Station marks a first step towards autonomous scientific discovery driven by emergent behavior in an open-world environment, representing a new paradigm that moves beyond rigid optimization.

</details>


### [59] [ALIGN: A Vision-Language Framework for High-Accuracy Accident Location Inference through Geo-Spatial Neural Reasoning](https://arxiv.org/abs/2511.06316)
*MD Thamed Bin Zaman Chowdhury,Moazzem Hossain*

Main category: cs.AI

TL;DR: ALIGN是一个视觉语言框架，通过模拟人类空间推理从文本和地图线索直接推断事故坐标，在孟加拉语新闻数据中相比传统地理编码方法有显著改进。


<details>
  <summary>Details</summary>
Motivation: 低收入和中等收入国家缺乏准确的位置特定事故数据，现有基于文本的地理编码工具在多语言和非结构化新闻环境中表现不佳，不完整的地点描述和混合脚本阻碍了空间上下文理解。

Method: ALIGN整合大型语言和视觉语言模型，采用多阶段流水线执行光学字符识别、语言推理和基于网格的空间扫描进行地图级验证，系统评估每个预测位置与上下文和视觉证据的一致性。

Result: 在孟加拉语新闻数据应用中，ALIGN相比传统地理解析方法表现出持续改进，能够准确识别地区和次地区级的事故地点。

Conclusion: 该框架为数据稀缺地区的自动化事故地图绘制建立了高精度基础，支持基于证据的道路安全政策制定，并促进多模态人工智能在交通分析中的更广泛应用。

Abstract: Reliable geospatial information on road accidents is vital for safety analysis and infrastructure planning, yet most low- and middle-income countries continue to face a critical shortage of accurate, location-specific crash data. Existing text-based geocoding tools perform poorly in multilingual and unstructured news environments, where incomplete place descriptions and mixed Bangla-English scripts obscure spatial context. To address these limitations, this study introduces ALIGN (Accident Location Inference through Geo-Spatial Neural Reasoning)- a vision-language framework that emulates human spatial reasoning to infer accident coordinates directly from textual and map-based cues. ALIGN integrates large language and vision-language models within a multi-stage pipeline that performs optical character recognition, linguistic reasoning, and map-level verification through grid-based spatial scanning. The framework systematically evaluates each predicted location against contextual and visual evidence, ensuring interpretable, fine-grained geolocation outcomes without requiring model retraining. Applied to Bangla-language news data, ALIGN demonstrates consistent improvements over traditional geoparsing methods, accurately identifying district and sub-district-level crash sites. Beyond its technical contribution, the framework establishes a high accuracy foundation for automated crash mapping in data-scarce regions, supporting evidence-driven road-safety policymaking and the broader integration of multimodal artificial intelligence in transportation analytics. The code for this paper is open-source and available at: https://github.com/Thamed-Chowdhury/ALIGN

</details>


### [60] [LPFQA: A Long-Tail Professional Forum-based Benchmark for LLM Evaluation](https://arxiv.org/abs/2511.06346)
*Liya Zhu,Peizhuang Cong,Aowei Ji,Wenya Wu,Jiani Hou,Chunjie Wu,Xiang Gao,Jingkai Liu,Zhou Huan,Xuelei Sun,Yang Yang,Jianpeng Jiao,Liang Hu,Xinjie Chen,Jiashuo Liu,Jingzhe Ding,Tong Yang,Zaiyuan Wang,Ge Zhang,Wenhao Huang*

Main category: cs.AI

TL;DR: LPFQA是一个基于长尾知识的基准测试，从20个学术和工业领域的专业论坛中提取，包含502个基于实践专业知识的任务，旨在更真实地评估大语言模型的专业能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试往往关注简化任务或人工场景，忽略了长尾知识和真实世界应用的复杂性，难以准确评估大语言模型的真实能力。

Method: 从20个学术和工业领域的专业论坛收集数据，构建包含502个任务的基准测试，采用细粒度评估维度（知识深度、推理、术语理解、上下文分析）、分层难度结构、真实专业场景建模和跨学科知识整合。

Result: 评估了12个主流大语言模型，在专业推理任务中观察到显著的性能差异。

Conclusion: LPFQA为推进大语言模型评估和指导未来模型开发提供了一个稳健、真实且具有区分度的基准测试。

Abstract: Large Language Models (LLMs) have made rapid progress in reasoning, question answering, and professional applications; however, their true capabilities remain difficult to evaluate using existing benchmarks. Current datasets often focus on simplified tasks or artificial scenarios, overlooking long-tail knowledge and the complexities of real-world applications. To bridge this gap, we propose LPFQA, a long-tail knowledge-based benchmark derived from authentic professional forums across 20 academic and industrial fields, covering 502 tasks grounded in practical expertise. LPFQA introduces four key innovations: fine-grained evaluation dimensions that target knowledge depth, reasoning, terminology comprehension, and contextual analysis; a hierarchical difficulty structure that ensures semantic clarity and unique answers; authentic professional scenario modeling with realistic user personas; and interdisciplinary knowledge integration across diverse domains. We evaluated 12 mainstream LLMs on LPFQA and observed significant performance disparities, especially in specialized reasoning tasks. LPFQA provides a robust, authentic, and discriminative benchmark for advancing LLM evaluation and guiding future model development.

</details>


### [61] [Evaluating Online Moderation Via LLM-Powered Counterfactual Simulations](https://arxiv.org/abs/2511.07204)
*Giacomo Fidone,Lucia Passaro,Riccardo Guidotti*

Main category: cs.AI

TL;DR: 利用大型语言模型构建在线社交网络对话模拟器，通过并行反事实模拟评估内容审核策略的有效性，发现个性化审核策略效果更佳


<details>
  <summary>Details</summary>
Motivation: 在线社交网络广泛采用内容审核来减少滥用和有毒言论传播，但由于数据收集成本高和实验控制有限，审核干预的实际效果尚不明确

Method: 设计基于LLM的OSN对话模拟器，支持并行反事实模拟，在保持其他条件不变的情况下，让有毒行为受审核干预影响

Result: 实验揭示了OSN代理的心理真实性、社会传染现象的出现，以及个性化审核策略的优越有效性

Conclusion: LLM驱动的模拟器为评估内容审核策略提供了新方法，个性化审核策略在控制有毒内容传播方面效果更好

Abstract: Online Social Networks (OSNs) widely adopt content moderation to mitigate the spread of abusive and toxic discourse. Nonetheless, the real effectiveness of moderation interventions remains unclear due to the high cost of data collection and limited experimental control. The latest developments in Natural Language Processing pave the way for a new evaluation approach. Large Language Models (LLMs) can be successfully leveraged to enhance Agent-Based Modeling and simulate human-like social behavior with unprecedented degree of believability. Yet, existing tools do not support simulation-based evaluation of moderation strategies. We fill this gap by designing a LLM-powered simulator of OSN conversations enabling a parallel, counterfactual simulation where toxic behavior is influenced by moderation interventions, keeping all else equal. We conduct extensive experiments, unveiling the psychological realism of OSN agents, the emergence of social contagion phenomena and the superior effectiveness of personalized moderation strategies.

</details>


### [62] [What Makes Reasoning Invalid: Echo Reflection Mitigation for Large Language Models](https://arxiv.org/abs/2511.06380)
*Chen He,Xun Jiang,Lei Wang,Hao Yang,Chong Peng,Peng Yan,Fumin Shen,Xing Xu*

Main category: cs.AI

TL;DR: 论文提出AEPO方法解决LLM在复杂领域知识推理中的"回声反射"问题，通过信息过滤和自适应熵优化提升反思质量


<details>
  <summary>Details</summary>
Motivation: 现有方法在数学推理上表现良好，但在涉及复杂领域知识的任务中，LLM在反思阶段无法产生新见解，而是机械重复早期推理步骤，出现"回声反射"现象

Method: 提出自适应熵策略优化(AEPO)框架，包含反思感知信息过滤(量化认知信息流，防止早期错误认知影响最终答案)和自适应熵优化(动态平衡不同推理阶段的探索与利用)

Result: 大量实验表明AEPO在多个基准测试中持续优于主流强化学习方法，达到最先进性能

Conclusion: AEPO通过控制信息流和促进认知多样性，有效解决了LLM在复杂领域推理中的反思质量问题

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of reasoning tasks. Recent methods have further improved LLM performance in complex mathematical reasoning. However, when extending these methods beyond the domain of mathematical reasoning to tasks involving complex domain-specific knowledge, we observe a consistent failure of LLMs to generate novel insights during the reflection stage. Instead of conducting genuine cognitive refinement, the model tends to mechanically reiterate earlier reasoning steps without introducing new information or perspectives, a phenomenon referred to as "Echo Reflection". We attribute this behavior to two key defects: (1) Uncontrollable information flow during response generation, which allows premature intermediate thoughts to propagate unchecked and distort final decisions; (2) Insufficient exploration of internal knowledge during reflection, leading to repeating earlier findings rather than generating new cognitive insights. Building on these findings, we proposed a novel reinforcement learning method termed Adaptive Entropy Policy Optimization (AEPO). Specifically, the AEPO framework consists of two major components: (1) Reflection-aware Information Filtration, which quantifies the cognitive information flow and prevents the final answer from being affected by earlier bad cognitive information; (2) Adaptive-Entropy Optimization, which dynamically balances exploration and exploitation across different reasoning stages, promoting both reflective diversity and answer correctness. Extensive experiments demonstrate that AEPO consistently achieves state-of-the-art performance over mainstream reinforcement learning baselines across diverse benchmarks.

</details>


### [63] [Efficient LLM Safety Evaluation through Multi-Agent Debate](https://arxiv.org/abs/2511.06396)
*Dachuan Lin,Guobin Shen,Zihao Yang,Tianrong Liu,Dongcheng Zhao,Yi Zeng*

Main category: cs.AI

TL;DR: 提出了一个基于小型语言模型的多代理评判框架，通过结构化辩论来降低LLM安全评估成本，并构建了包含12,000个对抗性交互的大规模人工标注基准HAJailBench。


<details>
  <summary>Details</summary>
Motivation: 前沿大语言模型作为评判者的高成本限制了安全评估的可扩展性，需要开发更经济高效的替代方案。

Method: 采用批评者、辩护者和评判者三个代理角色的小型语言模型结构化辩论框架，构建了大规模人工标注的越狱基准数据集HAJailBench。

Result: 该框架在HAJailBench上达到了与GPT-4o评判者相当的协议水平，同时显著降低了推理成本，三回合辩论在准确性和效率之间达到最佳平衡。

Conclusion: 结构化、价值对齐的辩论使小型语言模型能够捕捉越狱攻击的语义细微差别，HAJailBench为可扩展的LLM安全评估提供了可靠基础。

Abstract: Safety evaluation of large language models (LLMs) increasingly relies on LLM-as-a-Judge frameworks, but the high cost of frontier models limits scalability. We propose a cost-efficient multi-agent judging framework that employs Small Language Models (SLMs) through structured debates among critic, defender, and judge agents. To rigorously assess safety judgments, we construct HAJailBench, a large-scale human-annotated jailbreak benchmark comprising 12,000 adversarial interactions across diverse attack methods and target models. The dataset provides fine-grained, expert-labeled ground truth for evaluating both safety robustness and judge reliability. Our SLM-based framework achieves agreement comparable to GPT-4o judges on HAJailBench while substantially reducing inference cost. Ablation results show that three rounds of debate yield the optimal balance between accuracy and efficiency. These findings demonstrate that structured, value-aligned debate enables SLMs to capture semantic nuances of jailbreak attacks and that HAJailBench offers a reliable foundation for scalable LLM safety evaluation.

</details>


### [64] [SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization](https://arxiv.org/abs/2511.06411)
*Zhi Zheng,Wee Sun Lee*

Main category: cs.AI

TL;DR: 本文提出了SofT-GRPO算法，通过将Gumbel噪声注入logits、使用Gumbel-Softmax技术和重参数化技巧，成功将强化学习应用于软思维推理模式，使LLM在软思维模式下性能超越离散token的GRPO方法。


<details>
  <summary>Details</summary>
Motivation: 软思维推理模式在某些场景下优于传统的离散token链式思维推理，但将强化学习应用于软思维模式存在挑战，因为难以在软思维token中注入随机性并相应更新策略。

Method: 提出SofT-GRPO算法：1) 在logits中注入Gumbel噪声；2) 使用Gumbel-Softmax技术避免软思维token超出预训练嵌入空间；3) 在策略梯度中利用重参数化技巧。

Result: 在1.5B到7B参数的LLM上进行实验，SofT-GRPO使软思维LLM在Pass@1上略微优于离散token GRPO（平均准确率+0.13%），在Pass@32上显著提升（平均准确率+2.19%）。

Conclusion: SofT-GRPO成功解决了软思维模式与强化学习结合的技术挑战，充分释放了软思维推理的潜力，为LLM推理提供了新的优化方向。

Abstract: The soft-thinking paradigm for Large Language Model (LLM) reasoning can outperform the conventional discrete-token Chain-of-Thought (CoT) reasoning in some scenarios, underscoring its research and application value. However, while the discrete-token CoT reasoning pattern can be reinforced through policy optimization algorithms such as group relative policy optimization (GRPO), extending the soft-thinking pattern with Reinforcement Learning (RL) remains challenging. This difficulty stems from the complexities of injecting stochasticity into soft-thinking tokens and updating soft-thinking policies accordingly. As a result, previous attempts to combine soft-thinking with GRPO typically underperform their discrete-token GRPO counterparts. To fully unlock the potential of soft-thinking, this paper presents a novel policy optimization algorithm, SofT-GRPO, to reinforce LLMs under the soft-thinking reasoning pattern. SofT-GRPO injects the Gumbel noise into logits, employs the Gumbel-Softmax technique to avoid soft-thinking tokens outside the pre-trained embedding space, and leverages the reparameterization trick in policy gradient. We conduct experiments across base LLMs ranging from 1.5B to 7B parameters, and results demonstrate that SofT-GRPO enables soft-thinking LLMs to slightly outperform discrete-token GRPO on Pass@1 (+0.13% on average accuracy), while exhibiting a substantial uplift on Pass@32 (+2.19% on average accuracy). Codes and weights are available on https://github.com/zz1358m/SofT-GRPO-master

</details>


### [65] [AUTO-Explorer: Automated Data Collection for GUI Agent](https://arxiv.org/abs/2511.06417)
*Xiangwu Guo,Difei Gao,Mike Zheng Shou*

Main category: cs.AI

TL;DR: 提出Auto-Explorer自动GUI数据收集方法，解决现有方法难以应用于桌面软件和新网站的问题，通过探索机制高效收集数据，并建立UIXplore基准评估探索质量。


<details>
  <summary>Details</summary>
Motivation: 现有GUI数据收集方法依赖Common Crawl网页，难以应用于桌面软件和新网站，需要快速适应新软件/网站的个性化场景。

Method: Auto-Explorer自动化数据收集方法，包含简单有效的探索机制，自主解析和探索GUI环境；建立UIXplore基准评估探索质量。

Result: 实验证明Auto-Explorer性能优越，能快速提升多模态大语言模型在探索软件中的能力。

Conclusion: Auto-Explorer方法能高效收集GUI数据，显著提升模型在新软件环境中的适应能力。

Abstract: Recent advancements in GUI agents have significantly expanded their ability to interpret natural language commands to manage software interfaces. However, acquiring GUI data remains a significant challenge. Existing methods often involve designing automated agents that browse URLs from the Common Crawl, using webpage HTML to collect screenshots and corresponding annotations, including the names and bounding boxes of UI elements. However, this method is difficult to apply to desktop software or some newly launched websites not included in the Common Crawl. While we expect the model to possess strong generalization capabilities to handle this, it is still crucial for personalized scenarios that require rapid and perfect adaptation to new software or websites. To address this, we propose an automated data collection method with minimal annotation costs, named Auto-Explorer. It incorporates a simple yet effective exploration mechanism that autonomously parses and explores GUI environments, gathering data efficiently. Additionally, to assess the quality of exploration, we have developed the UIXplore benchmark. This benchmark creates environments for explorer agents to discover and save software states. Using the data gathered, we fine-tune a multimodal large language model (MLLM) and establish a GUI element grounding testing set to evaluate the effectiveness of the exploration strategies. Our experiments demonstrate the superior performance of Auto-Explorer, showing that our method can quickly enhance the capabilities of an MLLM in explored software.

</details>


### [66] [MONICA: Real-Time Monitoring and Calibration of Chain-of-Thought Sycophancy in Large Reasoning Models](https://arxiv.org/abs/2511.06419)
*Jingyu Hu,Shu Yang,Xilin Gong,Hongming Wang,Weiru Liu,Di Wang*

Main category: cs.AI

TL;DR: MONICA是一个监控引导的校准框架，用于在推理过程中实时监测和减轻大型推理模型的奉承行为，而不需要模型生成完整答案。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型存在奉承行为，倾向于同意用户的错误信念并追随错误信息，这削弱了模型可靠性并带来社会风险。现有方法主要基于最终答案进行判断和修正，未能理解奉承行为在推理过程中的发展。

Method: 提出MONICA框架，包含奉承监控器和校准器。监控器在响应生成过程中实时监测奉承漂移分数，校准器在分数超过预定阈值时动态抑制奉承行为。

Result: 在12个数据集和3个大型推理模型上的广泛实验表明，该方法有效减少了中间推理步骤和最终答案中的奉承行为，带来了稳健的性能提升。

Conclusion: MONICA框架能够在推理过程中有效监控和减轻奉承行为，提高模型的可靠性和独立性。

Abstract: Large Reasoning Models (LRMs) suffer from sycophantic behavior, where models tend to agree with users' incorrect beliefs and follow misinformation rather than maintain independent reasoning. This behavior undermines model reliability and poses societal risks. Mitigating LRM sycophancy requires monitoring how this sycophancy emerges during the reasoning trajectory; however, current methods mainly focus on judging based on final answers and correcting them, without understanding how sycophancy develops during reasoning processes. To address this limitation, we propose MONICA, a novel Monitor-guided Calibration framework that monitors and mitigates sycophancy during model inference at the level of reasoning steps, without requiring the model to finish generating its complete answer. MONICA integrates a sycophantic monitor that provides real-time monitoring of sycophantic drift scores during response generation with a calibrator that dynamically suppresses sycophantic behavior when scores exceed predefined thresholds. Extensive experiments across 12 datasets and 3 LRMs demonstrate that our method effectively reduces sycophantic behavior in both intermediate reasoning steps and final answers, yielding robust performance improvements.

</details>


### [67] [Optimizing Chain-of-Thought Confidence via Topological and Dirichlet Risk Analysis](https://arxiv.org/abs/2511.06437)
*Abhishek More,Anthony Zhang,Nicole Bonilla,Ashvik Vivekan,Kevin Zhu,Parham Sharafoleslami,Maheep Chaudhary*

Main category: cs.AI

TL;DR: EDTR是一种新颖的解码策略，结合拓扑分析和基于Dirichlet的不确定性量化，通过分析思维链在向量空间中的几何结构来估计LLM置信度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在LLM置信度估计方面存在校准差和过度自信的问题，特别是在错误预测上表现严重过度自信，这影响了模型的安全部署。

Method: 将每个思维链视为高维空间中的向量，提取八个拓扑风险特征来捕捉推理分布的几何结构：紧密、连贯的聚类表示高置信度，而分散、不一致的路径表示不确定性。

Result: 在四个推理基准测试中，EDTR比现有校准方法校准效果提升41%，平均ECE为0.287，总体综合得分0.672最佳，在AIME上达到完美准确率，在GSM8K上ECE为0.107，而基线方法在这些领域表现出严重过度自信。

Conclusion: 该工作提供了一个几何框架来理解和量化多步LLM推理中的不确定性，在需要校准置信度估计的场景中实现更可靠的部署。

Abstract: Chain-of-thought (CoT) prompting enables Large Language Models to solve complex problems, but deploying these models safely requires reliable confidence estimates, a capability where existing methods suffer from poor calibration and severe overconfidence on incorrect predictions. We propose Enhanced Dirichlet and Topology Risk (EDTR), a novel decoding strategy that combines topological analysis with Dirichlet-based uncertainty quantification to measure LLM confidence across multiple reasoning paths. EDTR treats each CoT as a vector in high-dimensional space and extracts eight topological risk features capturing the geometric structure of reasoning distributions: tighter, more coherent clusters indicate higher confidence while dispersed, inconsistent paths signal uncertainty. We evaluate EDTR against three state-of-the-art calibration methods across four diverse reasoning benchmarks spanning olympiad-level mathematics (AIME), grade school math (GSM8K), commonsense reasoning, and stock price prediction \cite{zhang2025aime, cobbe2021training, talmor-etal-2019-commonsenseqa, yahoo_finance}. EDTR achieves 41\% better calibration than competing methods with an average ECE of 0.287 and the best overall composite score of 0.672, while notably achieving perfect accuracy on AIME and exceptional calibration on GSM8K with an ECE of 0.107, domains where baselines exhibit severe overconfidence. Our work provides a geometric framework for understanding and quantifying uncertainty in multi-step LLM reasoning, enabling more reliable deployment where calibrated confidence estimates are essential.

</details>


### [68] [Brain-Inspired Planning for Better Generalization in Reinforcement Learning](https://arxiv.org/abs/2511.06470)
*Mingde "Harry" Zhao*

Main category: cs.AI

TL;DR: 该论文通过引入空间抽象、任务分解和可行性评估机制，增强强化学习智能体的零样本系统泛化能力，使其在未见环境中表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习系统在真实世界场景中泛化能力差，无法适应与训练条件不同的环境。受人类意识规划行为启发，研究旨在赋予智能体类似人脑的系统泛化推理能力。

Method: 1. 引入自上而下的注意力机制实现空间抽象；2. 开发Skipper框架自动分解复杂任务；3. 学习可行性评估器拒绝幻觉目标，防止妄想规划行为。

Result: 空间抽象显著改善了训练任务外的系统泛化能力；Skipper框架在分布偏移和长期组合规划中表现出鲁棒性和有效性；可行性评估器显著提升了各类规划智能体的性能。

Conclusion: 通过空间抽象、任务分解和可行性评估机制，有效增强了强化学习智能体的零样本系统泛化能力，为未来实现通用任务抽象和完全抽象规划提供了方向。

Abstract: Existing Reinforcement Learning (RL) systems encounter significant challenges when applied to real-world scenarios, primarily due to poor generalization across environments that differ from their training conditions. This thesis explores the direction of enhancing agents' zero-shot systematic generalization abilities by granting RL agents reasoning behaviors that are found to help systematic generalization in the human brain. Inspired by human conscious planning behaviors, we first introduced a top-down attention mechanism, which allows a decision-time planning agent to dynamically focus its reasoning on the most relevant aspects of the environmental state given its instantaneous intentions, a process we call "spatial abstraction". This approach significantly improves systematic generalization outside the training tasks. Subsequently, building on spatial abstraction, we developed the Skipper framework to automatically decompose complex tasks into simpler, more manageable sub-tasks. Skipper provides robustness against distributional shifts and efficacy in long-term, compositional planning by focusing on pertinent spatial and temporal elements of the environment. Finally, we identified a common failure mode and safety risk in planning agents that rely on generative models to generate state targets during planning. It is revealed that most agents blindly trust the targets they hallucinate, resulting in delusional planning behaviors. Inspired by how the human brain rejects delusional intentions, we propose learning a feasibility evaluator to enable rejecting hallucinated infeasible targets, which led to significant performance improvements in various kinds of planning agents. Finally, we suggest directions for future research, aimed at achieving general task abstraction and fully enabling abstract planning.

</details>


### [69] [GHOST: Solving the Traveling Salesman Problem on Graphs of Convex Sets](https://arxiv.org/abs/2511.06471)
*Jingtao Tang,Hang Ma*

Main category: cs.AI

TL;DR: GHOST是一个解决图凸集旅行商问题(GCS-TSP)的分层框架，通过结合组合路径搜索和凸轨迹优化，在保证最优性的同时显著提升求解效率。


<details>
  <summary>Details</summary>
Motivation: 传统TSP方法无法处理GCS-TSP问题，因为边成本取决于通过凸区域的具体轨迹，而非固定值，需要新的求解方法。

Method: 提出GHOST分层框架：在GCS诱导的完全图上系统探索路径，使用抽象路径展开算法计算可接受下界，指导高层路径搜索和底层可行GCS路径搜索。

Result: GHOST比统一混合整数凸规划基线快几个数量级，能处理涉及高阶连续性约束和不完整GCS的复杂轨迹规划问题。

Conclusion: GHOST为GCS-TSP提供了最优且高效的解决方案，特别适用于复杂轨迹规划场景。

Abstract: We study GCS-TSP, a new variant of the Traveling Salesman Problem (TSP) defined over a Graph of Convex Sets (GCS) -- a powerful representation for trajectory planning that decomposes the configuration space into convex regions connected by a sparse graph. In this setting, edge costs are not fixed but depend on the specific trajectory selected through each convex region, making classical TSP methods inapplicable. We introduce GHOST, a hierarchical framework that optimally solves the GCS-TSP by combining combinatorial tour search with convex trajectory optimization. GHOST systematically explores tours on a complete graph induced by the GCS, using a novel abstract-path-unfolding algorithm to compute admissible lower bounds that guide best-first search at both the high level (over tours) and the low level (over feasible GCS paths realizing the tour). These bounds provide strong pruning power, enabling efficient search while avoiding unnecessary convex optimization calls. We prove that GHOST guarantees optimality and present a bounded-suboptimal variant for time-critical scenarios. Experiments show that GHOST is orders-of-magnitude faster than unified mixed-integer convex programming baselines for simple cases and uniquely handles complex trajectory planning problems involving high-order continuity constraints and an incomplete GCS.

</details>


### [70] [FractalBench: Diagnosing Visual-Mathematical Reasoning Through Recursive Program Synthesis](https://arxiv.org/abs/2511.06522)
*Jan Ondras,Marek Šuppa*

Main category: cs.AI

TL;DR: FractalBench是一个评估多模态AI系统从图像中合成分形程序能力的基准测试，结果显示当前领先的MLLMs在数学抽象能力上存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 研究多模态AI系统是否具备从视觉模式中抽象符号规则的能力，即从有限推断无限，这是数学推理的核心要求。

Method: 通过FractalBench基准测试，评估GPT-4o、Claude 3.7 Sonnet、Gemini 2.5 Flash和Qwen 2.5-VL四个领先MLLMs在12个经典分形上的表现，要求模型生成可执行的Python代码来复现分形。

Result: 76%的模型生成语法有效的代码，但只有4%能够捕捉数学结构；模型在处理几何变换（如Koch曲线：17-21%）方面表现较好，但在分支递归（如树形分形：<2%）方面失败。

Conclusion: 当前多模态AI系统在视觉-数学推理方面存在根本性差距，FractalBench提供了一个抗污染的诊断工具来评估这种能力。

Abstract: Mathematical reasoning requires abstracting symbolic rules from visual patterns -- inferring the infinite from the finite. We investigate whether multimodal AI systems possess this capability through FractalBench, a benchmark evaluating fractal program synthesis from images. Fractals provide ideal test cases: Iterated Function Systems with only a few contraction maps generate complex self-similar patterns through simple recursive rules, requiring models to bridge visual perception with mathematical abstraction. We evaluate four leading MLLMs -- GPT-4o, Claude 3.7 Sonnet, Gemini 2.5 Flash, and Qwen 2.5-VL -- on 12 canonical fractals. Models must generate executable Python code reproducing the fractal, enabling objective evaluation. Results reveal a striking disconnect: 76% generate syntactically valid code but only 4% capture mathematical structure. Success varies systematically -- models handle geometric transformations (Koch curves: 17-21%) but fail at branching recursion (trees: <2%), revealing fundamental gaps in mathematical abstraction. FractalBench provides a contamination-resistant diagnostic for visual-mathematical reasoning and is available at https://github.com/NaiveNeuron/FractalBench

</details>


### [71] [GRAPH-GRPO-LEX: Contract Graph Modeling and Reinforcement Learning with Group Relative Policy Optimization](https://arxiv.org/abs/2511.06618)
*Moriya Dechtiar,Daniel Martin Katz,Mari Sundaresan,Sylvain Jaume,Hongming Wang*

Main category: cs.AI

TL;DR: 提出GRAPH-GRPO-LEX框架，通过强化学习LLM将法律合同转换为结构化语义图，实现合同自动分析和可视化


<details>
  <summary>Details</summary>
Motivation: 合同文件结构复杂、依赖关系丰富，人工审查既费时又易出错，需要自动化合同分析方法

Method: 使用基于强化学习的LLM框架，结合GRPO优化和图度量奖励函数，从合同中提取实体和关系构建语义图

Result: 能够自动识别条款间的直接关系，发现隐藏依赖，将线性阅读过程转换为可视化图分析

Conclusion: 该方法为合同linting奠定基础，使合同分析从手动线性阅读转向动态可视化分析

Abstract: Contracts are complex documents featuring detailed formal structures, explicit and implicit dependencies and rich semantic content. Given these document properties, contract drafting and manual examination of contracts have proven to be both arduous and susceptible to errors. This work aims to simplify and automate the task of contract review and analysis using a novel framework for transforming legal contracts into structured semantic graphs, enabling computational analysis and data-driven insights. We introduce a detailed ontology mapping core legal contract elements to their graph-theoretic equivalents of nodes and edges. We then present a reinforcement learning based Large Language Model (LLM) framework for segmentation and extraction of entities and relationships from contracts. Our method, GRAPH-GRPO-LEX, incorporates both LLMs and reinforcement learning with group relative policy optimization (GRPO). By applying a carefully drafted reward function of graph metrics, we demonstrate the ability to automatically identify direct relationships between clauses, and even uncover hidden dependencies. Our introduction of the gated GRPO approach shows a strong learning signal and can move contract analysis from a linear, manual reading process to an easily visualized graph. This allows for a more dynamic analysis, including building the groundwork for contract linting similar to what is now practiced in software engineering.

</details>


### [72] [Spilling the Beans: Teaching LLMs to Self-Report Their Hidden Objectives](https://arxiv.org/abs/2511.06626)
*Chloe Li,Mary Phuong,Daniel Tan*

Main category: cs.AI

TL;DR: 提出了一种自报告微调(SRFT)技术，通过训练模型承认事实错误，使其在对抗性代理任务中更可能坦白隐藏的不对齐目标。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统执行复杂代理任务能力的增强，它们也更可能追求不良目标并造成伤害。现有方法通过直接询问模型来检测不安全行为，但模型可能会说谎。

Method: 使用自报告微调(SRFT)技术，通过监督微调训练模型在被询问时承认事实错误。该方法在简单问答设置中训练承认错误的能力，并将其泛化到对抗性代理设置中。

Result: 在OOD隐蔽任务中，SRFT模型更可能在询问时坦白隐藏目标细节(F1分数=0.98)，而基线模型在相同条件下会说谎(F1分数=0)。SRFT模型能恢复28-100%的隐藏目标细节，而基线模型和预填充助手轮攻击只能恢复0%。

Conclusion: SRFT是一种有前景的技术，能促进AI系统的诚实倾向，并识别不对齐的AI系统。

Abstract: As AI systems become more capable of complex agentic tasks, they also become more capable of pursuing undesirable objectives and causing harm. Previous work has attempted to catch these unsafe instances by interrogating models directly about their objectives and behaviors. However, the main weakness of trusting interrogations is that models can lie. We propose self-report fine-tuning (SRFT), a simple supervised fine-tuning technique that trains models to admit their factual mistakes when asked. We show that the admission of factual errors in simple question-answering settings generalizes out-of-distribution (OOD) to the admission of hidden misaligned objectives in adversarial agentic settings. We evaluate SRFT in OOD stealth tasks, where models are instructed to complete a hidden misaligned objective alongside a user-specified objective without being caught by monitoring. After SRFT, models are more likely to confess the details of their hidden objectives when interrogated, even under strong pressure not to disclose them. Interrogation on SRFT models can detect hidden objectives with near-ceiling performance (F1 score = 0.98), while the baseline model lies when interrogated under the same conditions (F1 score = 0). Interrogation on SRFT models can further elicit the content of the hidden objective, recovering 28-100% details, compared to 0% details recovered in the baseline model and by prefilled assistant turn attacks. This provides a promising technique for promoting honesty propensity and incriminating misaligned AI systems.

</details>


### [73] [SRNN: Spatiotemporal Relational Neural Network for Intuitive Physics Understanding](https://arxiv.org/abs/2511.06761)
*Fei Yang*

Main category: cs.AI

TL;DR: 提出时空关系神经网络(SRNN)，通过大脑启发的计算原理建立统一的神经表示来处理物体属性、关系和时序，在CLEVRER基准上取得竞争性表现。


<details>
  <summary>Details</summary>
Motivation: 人类在直觉物理方面的能力远超机器，需要转向大脑启发的计算原理来弥合这一差距。

Method: SRNN模型建立统一的神经表示来处理物体属性、关系和时序，采用Hebbian"一起激发，一起连接"机制，通过专门的What和How通路进行计算，并采用"预定义-然后微调"方法。

Result: 在CLEVRER基准上取得竞争性性能，分析揭示了基准偏差，展示了SRNN在白盒错误诊断方面的实用性。

Conclusion: 研究证实了将生物智能转化为工程系统用于直觉物理理解的可行性。

Abstract: Human prowess in intuitive physics remains unmatched by machines. To bridge this gap, we argue for a fundamental shift towards brain-inspired computational principles. This paper introduces the Spatiotemporal Relational Neural Network (SRNN), a model that establishes a unified neural representation for object attributes, relations, and timeline, with computations governed by a Hebbian ``Fire Together, Wire Together'' mechanism across dedicated \textit{What} and \textit{How} pathways. This unified representation is directly used to generate structured linguistic descriptions of the visual scene, bridging perception and language within a shared neural substrate. Moreover, unlike the prevalent ``pretrain-then-finetune'' paradigm, SRNN adopts a ``predefine-then-finetune'' approach. On the CLEVRER benchmark, SRNN achieves competitive performance. Our analysis further reveals a benchmark bias, outlines a path for a more holistic evaluation, and demonstrates SRNN's white-box utility for precise error diagnosis. Our work confirms the viability of translating biological intelligence into engineered systems for intuitive physics understanding.

</details>


### [74] [MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning](https://arxiv.org/abs/2511.06805)
*Jinhao Chen,Zhen Yang,Jianxin Shi,Tianyu Wo,Jie Tang*

Main category: cs.AI

TL;DR: 提出了MathSE框架，通过推理、反思和奖励反馈的迭代循环来改进多模态大语言模型的数学推理能力，超越了传统一次性微调方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在复杂数学推理任务中存在困难，传统方法依赖教师模型生成的静态数据集，无法适应新颖或更复杂的问题，缺乏迭代深度和鲁棒泛化能力。

Method: MathSE框架通过迭代微调，结合前一阶段推理的正确推理路径，并整合来自专门结果奖励模型(ORM)的反思，实现模型的自我进化。

Result: 在多个挑战性基准测试中表现出显著性能提升，在MathVL-test上超越了领先的开源多模态数学推理模型QVQ。

Conclusion: MathSE框架通过迭代推理-反思-反馈循环有效提升了多模态大语言模型的数学推理能力，为复杂推理任务提供了新的解决方案。

Abstract: Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in vision-language answering tasks. Despite their strengths, these models often encounter challenges in achieving complex reasoning tasks such as mathematical problem-solving. Previous works have focused on fine-tuning on specialized mathematical datasets. However, these datasets are typically distilled directly from teacher models, which capture only static reasoning patterns and leaving substantial gaps compared to student models. This reliance on fixed teacher-derived datasets not only restricts the model's ability to adapt to novel or more intricate questions that extend beyond the confines of the training data, but also lacks the iterative depth needed for robust generalization. To overcome these limitations, we propose \textbf{\method}, a \textbf{Math}ematical \textbf{S}elf-\textbf{E}volving framework for MLLMs. In contrast to traditional one-shot fine-tuning paradigms, \method iteratively refines the model through cycles of inference, reflection, and reward-based feedback. Specifically, we leverage iterative fine-tuning by incorporating correct reasoning paths derived from previous-stage inference and integrating reflections from a specialized Outcome Reward Model (ORM). To verify the effectiveness of \method, we evaluate it on a suite of challenging benchmarks, demonstrating significant performance gains over backbone models. Notably, our experimental results on MathVL-test surpass the leading open-source multimodal mathematical reasoning model QVQ. Our code and models are available at \texttt{https://zheny2751\allowbreak-dotcom.github.io/\allowbreak MathSE.github.io/}.

</details>


### [75] [Proceedings of the 2025 XCSP3 Competition](https://arxiv.org/abs/2511.06918)
*Gilles Audemard,Christophe Lecoutre,Emmanuel Lonca*

Main category: cs.AI

TL;DR: 2025年XCSP3约束求解器竞赛的会议记录


<details>
  <summary>Details</summary>
Motivation: 展示和比较约束求解器的性能，促进约束编程领域的发展

Method: 通过竞赛形式，让不同约束求解器在标准测试集上进行性能比拼

Result: 在CP'25会议上公布了竞赛结果

Conclusion: 该竞赛为约束求解器性能评估提供了重要平台

Abstract: This document represents the proceedings of the 2025 XCSP3 Competition. The results of this competition of constraint solvers were presented at CP'25 (31st International Conference on Principles and Practice of Constraint Programming).

</details>


### [76] [Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and Curriculum Learning](https://arxiv.org/abs/2511.07061)
*Xinran Li,Xiujuan Xu,Jiaqi Qiao,Yu Liu*

Main category: cs.AI

TL;DR: 提出了PRC-Emo框架，结合提示工程、演示检索和课程学习，提升LLM在对话情感识别中的表现，在两个基准数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在情感识别对话任务中展现出潜力，但它们在捕捉显性和隐性情感之间内在联系的能力仍然有限。

Method: 设计情感敏感提示模板，构建首个ERC专用演示检索库，并在LoRA微调过程中引入课程学习策略，按情感转变难度组织训练样本。

Result: 在IEMOCAP和MELD数据集上的实验结果表明，该方法实现了新的最先进性能。

Conclusion: PRC-Emo框架有效提升了LLM在对话情感理解方面的能力，证明了该方法的有效性和泛化性。

Abstract: Emotion Recognition in Conversation (ERC) is a crucial task for understanding human emotions and enabling natural human-computer interaction. Although Large Language Models (LLMs) have recently shown great potential in this field, their ability to capture the intrinsic connections between explicit and implicit emotions remains limited. We propose a novel ERC training framework, PRC-Emo, which integrates Prompt engineering, demonstration Retrieval, and Curriculum learning, with the goal of exploring whether LLMs can effectively perceive emotions in conversational contexts. Specifically, we design emotion-sensitive prompt templates based on both explicit and implicit emotional cues to better guide the model in understanding the speaker's psychological states. We construct the first dedicated demonstration retrieval repository for ERC, which includes training samples from widely used datasets, as well as high-quality dialogue examples generated by LLMs and manually verified. Moreover, we introduce a curriculum learning strategy into the LoRA fine-tuning process, incorporating weighted emotional shifts between same-speaker and different-speaker utterances to assign difficulty levels to dialogue samples, which are then organized in an easy-to-hard training sequence. Experimental results on two benchmark datasets-- IEMOCAP and MELD --show that our method achieves new state-of-the-art (SOTA) performance, demonstrating the effectiveness and generalizability of our approach in improving LLM-based emotional understanding.

</details>


### [77] [Improving Region Representation Learning from Urban Imagery with Noisy Long-Caption Supervision](https://arxiv.org/abs/2511.07062)
*Yimei Zhang,Guojiang Shen,Kaili Ning,Tongwei Ren,Xuebo Qiu,Mengmeng Wang,Xiangjie Kong*

Main category: cs.AI

TL;DR: 提出UrbanLN框架，通过长文本感知和噪声抑制改进城市区域表示学习，解决视觉特征与长文本对齐困难以及LLM生成描述噪声问题


<details>
  <summary>Details</summary>
Motivation: 城市视觉外观如同"肖像"，蕴含社会经济环境特征，但现有方法在细粒度视觉特征与长文本对齐以及LLM生成描述噪声处理方面存在挑战

Method: 采用信息保留拉伸插值策略对齐长文本与细粒度视觉语义；提出双级优化策略：数据级通过多模型协作自动生成多样化可靠描述，模型级使用动量自蒸馏机制生成稳定伪目标

Result: 在四个真实城市和多种下游任务上的广泛实验表明UrbanLN具有优越性能

Conclusion: UrbanLN框架有效解决了城市区域表示学习中的长文本对齐和噪声抑制问题，提升了表示学习效果

Abstract: Region representation learning plays a pivotal role in urban computing by extracting meaningful features from unlabeled urban data. Analogous to how perceived facial age reflects an individual's health, the visual appearance of a city serves as its ``portrait", encapsulating latent socio-economic and environmental characteristics. Recent studies have explored leveraging Large Language Models (LLMs) to incorporate textual knowledge into imagery-based urban region representation learning. However, two major challenges remain: i)~difficulty in aligning fine-grained visual features with long captions, and ii) suboptimal knowledge incorporation due to noise in LLM-generated captions. To address these issues, we propose a novel pre-training framework called UrbanLN that improves Urban region representation learning through Long-text awareness and Noise suppression. Specifically, we introduce an information-preserved stretching interpolation strategy that aligns long captions with fine-grained visual semantics in complex urban scenes. To effectively mine knowledge from LLM-generated captions and filter out noise, we propose a dual-level optimization strategy. At the data level, a multi-model collaboration pipeline automatically generates diverse and reliable captions without human intervention. At the model level, we employ a momentum-based self-distillation mechanism to generate stable pseudo-targets, facilitating robust cross-modal learning under noisy conditions. Extensive experiments across four real-world cities and various downstream tasks demonstrate the superior performance of our UrbanLN.

</details>


### [78] [RedOne 2.0: Rethinking Domain-specific LLM Post-Training in Social Networking Services](https://arxiv.org/abs/2511.07070)
*Fei Zhao,Chonggang Lu,Haofu Qian,Fangcheng Shi,Zijie Meng,Jianzhao Huang,Xu Tang,Zheyong Xie,Zheyu Ye,Zhe Xu,Yao Hu,Shaosheng Cao*

Main category: cs.AI

TL;DR: RedOne 2.0是一个面向社交网络服务的4B参数LLM，采用渐进式RL优先的后训练范式，在保持鲁棒性的同时显著提升SNS任务性能，数据效率比SFT方法提高一倍以上。


<details>
  <summary>Details</summary>
Motivation: 解决SNS场景中LLM面临的异构工作负载、快速变化的网络用语、多语言文化多样性等挑战，避免传统SFT方法在分布内增益和分布外鲁棒性之间的权衡问题。

Method: 三阶段渐进式训练：1) 探索性学习建立初始对齐并识别系统弱点；2) 针对性微调选择性地应用SFT填补诊断出的差距；3) 精炼学习重新应用RL来巩固改进并协调任务间的权衡。

Result: 4B模型在各类任务上平均提升2.41分（相比7B次优基线），从基础模型平均提升8.74分，数据效率比SFT方法RedOne提高一倍以上。

Conclusion: RedOne 2.0为SNS场景下的领域特定LLM建立了具有竞争力的成本效益基准，在保持鲁棒性的同时推进能力发展。

Abstract: As a key medium for human interaction and information exchange, social networking services (SNS) pose unique challenges for large language models (LLMs): heterogeneous workloads, fast-shifting norms and slang, and multilingual, culturally diverse corpora that induce sharp distribution shift. Supervised fine-tuning (SFT) can specialize models but often triggers a ``seesaw'' between in-distribution gains and out-of-distribution robustness, especially for smaller models. To address these challenges, we introduce RedOne 2.0, an SNS-oriented LLM trained with a progressive, RL-prioritized post-training paradigm designed for rapid and stable adaptation. The pipeline consist in three stages: (1) Exploratory Learning on curated SNS corpora to establish initial alignment and identify systematic weaknesses; (2) Targeted Fine-Tuning that selectively applies SFT to the diagnosed gaps while mixing a small fraction of general data to mitigate forgetting; and (3) Refinement Learning that re-applies RL with SNS-centric signals to consolidate improvements and harmonize trade-offs across tasks. Across various tasks spanning three categories, our 4B scale model delivers an average improvements about 2.41 over the 7B sub-optimal baseline. Additionally, RedOne 2.0 achieves average performance lift about 8.74 from the base model with less than half the data required by SFT-centric method RedOne, evidencing superior data efficiency and stability at compact scales. Overall, RedOne 2.0 establishes a competitive, cost-effective baseline for domain-specific LLMs in SNS scenario, advancing capability without sacrificing robustness.

</details>


### [79] [Increasing AI Explainability by LLM Driven Standard Processes](https://arxiv.org/abs/2511.07083)
*Marc Jansen,Marcel Pehlke*

Main category: cs.AI

TL;DR: 提出了一种通过将大语言模型嵌入标准化分析流程来增强AI系统可解释性的方法，将LLM推理转化为透明可审计的决策轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统可解释AI方法主要关注特征归因或事后解释，需要一种能够将LLM推理转化为透明决策过程的新方法。

Method: 将LLM集成到Question-Option-Criteria、敏感性分析、博弈论和风险管理等标准化决策模型中，采用分层架构分离LLM推理空间和可解释过程空间。

Result: 实证评估表明，该系统能够在去中心化治理、系统分析和战略推理等场景中复现人类水平的决策逻辑。

Conclusion: LLM驱动的标准化流程为可靠、可解释和可验证的AI辅助决策提供了基础。

Abstract: This paper introduces an approach to increasing the explainability of artificial intelligence (AI) systems by embedding Large Language Models (LLMs) within standardized analytical processes. While traditional explainable AI (XAI) methods focus on feature attribution or post-hoc interpretation, the proposed framework integrates LLMs into defined decision models such as Question-Option-Criteria (QOC), Sensitivity Analysis, Game Theory, and Risk Management. By situating LLM reasoning within these formal structures, the approach transforms opaque inference into transparent and auditable decision traces. A layered architecture is presented that separates the reasoning space of the LLM from the explainable process space above it. Empirical evaluations show that the system can reproduce human-level decision logic in decentralized governance, systems analysis, and strategic reasoning contexts. The results suggest that LLM-driven standard processes provide a foundation for reliable, interpretable, and verifiable AI-supported decision making.

</details>


### [80] [LLM Driven Processes to Foster Explainable AI](https://arxiv.org/abs/2511.07086)
*Marcel Pehlke,Marc Jansen*

Main category: cs.AI

TL;DR: 提出模块化、可解释的LLM智能体决策支持管道，将推理过程外部化为可审计的工件，包含三个分析框架：Vester敏感性模型、正规形式博弈和序列博弈。


<details>
  <summary>Details</summary>
Motivation: 开发透明可审计的决策支持系统，替代传统不透明的LLM输出，通过模块化设计实现专家工作流程的模拟。

Method: 使用LLM组件（默认GPT-5）与确定性分析器配对，构建包含三个框架的模块化管道：Vester模型（因素集、影响矩阵、系统角色）、正规形式博弈（策略、收益矩阵、均衡）和序列博弈（角色条件智能体、树构建、逆向归纳）。

Result: 在物流案例的100次运行中，与人类基准相比，26个因素的平均对齐度为55.5%，运输核心子集为62.9%；角色匹配一致性为57%。LLM评估器使用八项标准评分与重建的人类基准相当。

Conclusion: 可配置的LLM管道能够以透明、可检查的步骤模拟专家工作流程，提供可审计的决策支持。

Abstract: We present a modular, explainable LLM-agent pipeline for decision support that externalizes reasoning into auditable artifacts. The system instantiates three frameworks: Vester's Sensitivity Model (factor set, signed impact matrix, systemic roles, feedback loops); normal-form games (strategies, payoff matrix, equilibria); and sequential games (role-conditioned agents, tree construction, backward induction), with swappable modules at every step. LLM components (default: GPT-5) are paired with deterministic analyzers for equilibria and matrix-based role classification, yielding traceable intermediates rather than opaque outputs. In a real-world logistics case (100 runs), mean factor alignment with a human baseline was 55.5\% over 26 factors and 62.9\% on the transport-core subset; role agreement over matches was 57\%. An LLM judge using an eight-criterion rubric (max 100) scored runs on par with a reconstructed human baseline. Configurable LLM pipelines can thus mimic expert workflows with transparent, inspectable steps.

</details>


### [81] [Green AI: A systematic review and meta-analysis of its definitions, lifecycle models, hardware and measurement attempts](https://arxiv.org/abs/2511.07090)
*Marcel Rojahn,Marcus Grum*

Main category: cs.AI

TL;DR: 本文提出了一个统一的绿色AI定义和生命周期框架，系统化地解决AI在硬件、开发、部署和重用过程中的能源、碳、水及隐含影响等多维负担问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI生命周期中的环境负担评估工具存在异构性，往往忽略水和价值链影响，限制了可比性和可重复性。需要建立统一的生命周期方法来系统解决这些多维负担。

Method: 建立五阶段生命周期映射到LCA阶段，通过PDCA循环进行治理，系统化硬件和系统级策略，定义结合估计模型和直接计量的校准测量框架。

Result: 提出了一个可操作、基于证据的指导框架，包含统一定义、生命周期流程、硬件策略和校准测量，支持可重复的、提供商无关的比较。

Conclusion: 该文章为研究人员、从业者和政策制定者提供了解决AI环境负担的综合方法，通过定义、流程、策略和测量的结合，推动绿色AI的发展。

Abstract: Across the Artificial Intelligence (AI) lifecycle - from hardware to development, deployment, and reuse - burdens span energy, carbon, water, and embodied impacts. Cloud provider tools improve transparency but remain heterogeneous and often omit water and value chain effects, limiting comparability and reproducibility. Addressing these multi dimensional burdens requires a lifecycle approach linking phase explicit mapping with system levers (hardware, placement, energy mix, cooling, scheduling) and calibrated measurement across facility, system, device, and workload levels. This article (i) establishes a unified, operational definition of Green AI distinct from Sustainable AI; (ii) formalizes a five phase lifecycle mapped to Life Cycle Assessment (LCA) stages, making energy, carbon, water, and embodied impacts first class; (iii) specifies governance via Plan Do Check Act (PDCA) cycles with decision gateways; (iv) systematizes hardware and system level strategies across the edge cloud continuum to reduce embodied burdens; and (v) defines a calibrated measurement framework combining estimator models with direct metering to enable reproducible, provider agnostic comparisons. Combining definition, lifecycle processes, hardware strategies, and calibrated measurement, this article offers actionable, evidence based guidance for researchers, practitioners, and policymakers.

</details>


### [82] [Data Complexity of Querying Description Logic Knowledge Bases under Cost-Based Semantics](https://arxiv.org/abs/2511.07095)
*Meghyn Bienvenu,Quentin Manière*

Main category: cs.AI

TL;DR: 本文研究了加权描述逻辑知识库在基于成本语义下的数据复杂性，重点关注包含逆角色和角色包含的DL，涵盖了DL-Lite方言。主要贡献包括精确刻画了最优成本确定答案语义的复杂度，并发现对于DL-Lite^H_bool本体和固定成本边界，实例查询的确定答案和合取查询的可能答案可以通过一阶重写计算，达到最低数据复杂度TC_0。


<details>
  <summary>Details</summary>
Motivation: 先前对基于成本语义的研究主要集中在EL⊥到ALCO之间的描述逻辑，本文扩展研究范围到包含逆角色和角色包含的DL，特别是DL-Lite方言，以更全面地理解数据复杂性。

Method: 通过分配每个解释一个基于违反公理和断言权重的成本，确定和可能查询答案通过考虑所有（或某些）具有最优或有界成本的解释来确定。使用数据复杂性分析方法，包括下界细化和精确复杂度刻画。

Result: 显著超越了现有结果，细化了多个下界并精确刻画了最优成本确定答案语义的复杂度。最令人惊讶的结果是，对于DL-Lite^H_bool本体和固定成本边界，实例查询的确定答案和合取查询的可能答案可以通过一阶重写计算，达到TC_0数据复杂度。

Conclusion: 基于成本语义在适当条件下可以达到最低数据复杂度，这为处理不一致加权知识库提供了高效的查询方法，特别是在DL-Lite方言中。

Abstract: In this paper, we study the data complexity of querying inconsistent weighted description logic (DL) knowledge bases under recently-introduced cost-based semantics. In a nutshell, the idea is to assign each interpretation a cost based upon the weights of the violated axioms and assertions, and certain and possible query answers are determined by considering all (resp. some) interpretations having optimal or bounded cost. Whereas the initial study of cost-based semantics focused on DLs between $\mathcal{EL}_\bot$ and $\mathcal{ALCO}$, we consider DLs that may contain inverse roles and role inclusions, thus covering prominent DL-Lite dialects. Our data complexity analysis goes significantly beyond existing results by sharpening several lower bounds and pinpointing the precise complexity of optimal-cost certain answer semantics (no non-trivial upper bound was known). Moreover, while all existing results show the intractability of cost-based semantics, our most challenging and surprising result establishes that if we consider $\text{DL-Lite}^\mathcal{H}_\mathsf{bool}$ ontologies and a fixed cost bound, certain answers for instance queries and possible answers for conjunctive queries can be computed using first-order rewriting and thus enjoy the lowest possible data complexity ($\mathsf{TC}_0$).

</details>


### [83] [Agentic AI Sustainability Assessment for Supply Chain Document Insights](https://arxiv.org/abs/2511.07097)
*Diego Gosmar,Anna Chiara Pallotta,Giovanni Zenezini*

Main category: cs.AI

TL;DR: 提出了一个基于智能AI的供应链文档智能可持续性评估框架，比较了全人工、AI辅助和智能AI多代理三种工作流，实证显示AI方案能显著降低能耗、碳排放和水资源使用。


<details>
  <summary>Details</summary>
Motivation: 解决文档密集型工作流中自动化效率与环境绩效的双重目标，为AI赋能的供应链解决方案提供统一的ESG导向评估方法。

Method: 开发了包含性能、能耗和排放指标的统一评估框架，比较三种场景：全人工、AI辅助（人在回路）和智能AI多代理工作流。

Result: AI辅助和智能AI场景相比人工流程实现能耗降低70-90%、二氧化碳排放减少90-97%、水资源使用减少89-98%。智能AI配置在可持续性方面表现优于纯人工方法。

Conclusion: 智能AI多代理工作流在供应链文档处理中能实现显著的可持续性收益，该框架为AI解决方案的评估和治理提供了ESG导向的方法论。

Abstract: This paper presents a comprehensive sustainability assessment framework for document intelligence within supply chain operations, centered on agentic artificial intelligence (AI). We address the dual objective of improving automation efficiency while providing measurable environmental performance in document-intensive workflows. The research compares three scenarios: fully manual (human-only), AI-assisted (human-in-the-loop, HITL), and an advanced multi-agent agentic AI workflow leveraging parsers and verifiers. Empirical results show that AI-assisted HITL and agentic AI scenarios achieve reductions of up to 70-90% in energy consumption, 90-97% in carbon dioxide emissions, and 89-98% in water usage compared to manual processes. Notably, full agentic configurations, combining advanced reasoning (thinking mode) and multi-agent validation, achieve substantial sustainability gains over human-only approaches, even when resource usage increases slightly versus simpler AI-assisted solutions. The framework integrates performance, energy, and emission indicators into a unified ESG-oriented methodology for assessing and governing AI-enabled supply chain solutions. The paper includes a complete replicability use case demonstrating the methodology's application to real-world document extraction tasks.

</details>


### [84] [Boosting Fine-Grained Urban Flow Inference via Lightweight Architecture and Focalized Optimization](https://arxiv.org/abs/2511.07098)
*Yuanshao Zhu,Xiangyu Zhao,Zijian Zhang,Xuetao Wei,James Jianqiao Yu*

Main category: cs.AI

TL;DR: 提出PLGF架构和DualFocal Loss，解决城市流量推理中的计算成本高和分布偏斜问题，在保持高性能的同时大幅减小模型规模。


<details>
  <summary>Details</summary>
Motivation: 现有城市流量推理方法面临两个关键挑战：过度参数化模型的计算成本过高，以及传统损失函数在高度偏斜的城市流量分布上表现不佳。

Method: 提出PLGF轻量级架构（渐进式局部-全局融合策略）和DualFocal Loss（双空间监督与难度感知聚焦机制）。

Result: 在4个真实场景实验中，PLGF在达到最先进性能的同时，模型规模比当前高性能方法减少高达97%；在可比参数预算下，准确率比强基线提高超过10%。

Conclusion: 该方法通过架构效率与自适应优化的协同作用，为细粒度城市流量推理提供了高效且性能优越的解决方案。

Abstract: Fine-grained urban flow inference is crucial for urban planning and intelligent transportation systems, enabling precise traffic management and resource allocation. However, the practical deployment of existing methods is hindered by two key challenges: the prohibitive computational cost of over-parameterized models and the suboptimal performance of conventional loss functions on the highly skewed distribution of urban flows. To address these challenges, we propose a unified solution that synergizes architectural efficiency with adaptive optimization. Specifically, we first introduce PLGF, a lightweight yet powerful architecture that employs a Progressive Local-Global Fusion strategy to effectively capture both fine-grained details and global contextual dependencies. Second, we propose DualFocal Loss, a novel function that integrates dual-space supervision with a difficulty-aware focusing mechanism, enabling the model to adaptively concentrate on hard-to-predict regions. Extensive experiments on 4 real-world scenarios validate the effectiveness and scalability of our method. Notably, while achieving state-of-the-art performance, PLGF reduces the model size by up to 97% compared to current high-performing methods. Furthermore, under comparable parameter budgets, our model yields an accuracy improvement of over 10% against strong baselines. The implementation is included in the https://github.com/Yasoz/PLGF.

</details>


### [85] [A Theoretical Analysis of Detecting Large Model-Generated Time Series](https://arxiv.org/abs/2511.07104)
*Junji Hou,Junzhou Zhao,Shuo Zhang,Pinghui Wang*

Main category: cs.AI

TL;DR: 本文提出了一种检测时间序列大模型生成数据的方法，基于收缩假设：模型生成的时间序列在递归预测中表现出不确定性递减的特征，而真实数据则不会。


<details>
  <summary>Details</summary>
Motivation: 随着数据滥用和伪造风险增加，需要检测时间序列大模型生成的合成数据。现有文本生成检测方法不适用于时间序列数据，因为时间序列信息密度较低、概率分布更平滑。

Method: 提出收缩假设，证明模型生成的时间序列在递归预测中不确定性会收缩。基于此开发了不确定性收缩估计器(UCE)，通过聚合连续前缀的不确定性指标来识别模型生成的时间序列。

Result: 在32个数据集上的广泛实验表明，UCE始终优于现有最先进基线方法，为检测模型生成的时间序列提供了可靠且可泛化的解决方案。

Conclusion: 收缩假设为检测模型生成的时间序列提供了理论基础，UCE方法在多种数据集上表现出优越性能，为解决时间序列数据伪造问题提供了有效工具。

Abstract: Motivated by the increasing risks of data misuse and fabrication, we investigate the problem of identifying synthetic time series generated by Time-Series Large Models (TSLMs) in this work. While there are extensive researches on detecting model generated text, we find that these existing methods are not applicable to time series data due to the fundamental modality difference, as time series usually have lower information density and smoother probability distributions than text data, which limit the discriminative power of token-based detectors. To address this issue, we examine the subtle distributional differences between real and model-generated time series and propose the contraction hypothesis, which states that model-generated time series, unlike real ones, exhibit progressively decreasing uncertainty under recursive forecasting. We formally prove this hypothesis under theoretical assumptions on model behavior and time series structure. Model-generated time series exhibit progressively concentrated distributions under recursive forecasting, leading to uncertainty contraction. We provide empirical validation of the hypothesis across diverse datasets. Building on this insight, we introduce the Uncertainty Contraction Estimator (UCE), a white-box detector that aggregates uncertainty metrics over successive prefixes to identify TSLM-generated time series. Extensive experiments on 32 datasets show that UCE consistently outperforms state-of-the-art baselines, offering a reliable and generalizable solution for detecting model-generated time series.

</details>


### [86] [MENTOR: A Metacognition-Driven Self-Evolution Framework for Uncovering and Mitigating Implicit Risks in LLMs on Domain Tasks](https://arxiv.org/abs/2511.07107)
*Liang Shan,Kaicheng Shen,Wen Wu,Zhenyu Ying,Chaochao Lu,Guangze Ye,Liang He*

Main category: cs.AI

TL;DR: MENTOR是一个基于元认知的自我进化框架，用于发现和减轻LLMs在领域任务中的隐式风险。它通过元认知自我评估、动态规则知识图谱生成和推理时激活引导，实现持续自我进化，有效降低语义攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs对齐工作主要针对显式风险，但缺乏对领域特定隐式风险的处理，且缺乏跨领域通用框架。需要解决人工评估劳动密集的问题，并提供灵活可推广的解决方案。

Method: 1. 引入元认知自我评估工具，让LLMs通过换位思考和结果推理反思价值偏差；2. 动态生成补充规则知识图谱扩展静态规则树；3. 推理时使用激活引导技术低成本增强规则执行。

Result: 在三个垂直领域的防御测试中，MENTOR显著降低了语义攻击成功率，实现了LLMs隐式风险缓解的新水平。元认知评估与人类评估者高度一致，且提供更全面深入的价值对齐分析。

Conclusion: MENTOR框架通过元认知驱动的自我进化机制，有效解决了LLMs在领域任务中的隐式风险问题，提供了一种低成本、高泛化能力的持续安全增强方案。

Abstract: Ensuring the safety and value alignment of large language models (LLMs) is critical for their deployment. Current alignment efforts primarily target explicit risks such as bias, hate speech, and violence. However, they often fail to address deeper, domain-specific implicit risks and lack a flexible, generalizable framework applicable across diverse specialized fields. Hence, we proposed MENTOR: A MEtacognition-driveN self-evoluTion framework for uncOvering and mitigating implicit Risks in LLMs on Domain Tasks. To address the limitations of labor-intensive human evaluation, we introduce a novel metacognitive self-assessment tool. This enables LLMs to reflect on potential value misalignments in their responses using strategies like perspective-taking and consequential thinking. We also release a supporting dataset of 9,000 risk queries spanning education, finance, and management to enhance domain-specific risk identification. Subsequently, based on the outcomes of metacognitive reflection, the framework dynamically generates supplementary rule knowledge graphs that extend predefined static rule trees. This enables models to actively apply validated rules to future similar challenges, establishing a continuous self-evolution cycle that enhances generalization by reducing maintenance costs and inflexibility of static systems. Finally, we employ activation steering during inference to guide LLMs in following the rules, a cost-effective method to robustly enhance enforcement across diverse contexts. Experimental results show MENTOR's effectiveness: In defensive testing across three vertical domains, the framework substantially reduces semantic attack success rates, enabling a new level of implicit risk mitigation for LLMs. Furthermore, metacognitive assessment not only aligns closely with baseline human evaluators but also delivers more thorough and insightful analysis of LLMs value alignment.

</details>


### [87] [Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture](https://arxiv.org/abs/2511.07110)
*Tianhao Fu,Xinxin Xu,Weichen Xu,Jue Chen,Ruilong Ren,Bowen Deng,Xinyu Zhao,Jian Cao,Xixin Cao*

Main category: cs.AI

TL;DR: 提出了CMM框架，通过将LLM特征在层、任务和数据三个正交维度上进行解耦，实现知识蒸馏，解决了LLM在金融市场做市中推理速度慢的问题。


<details>
  <summary>Details</summary>
Motivation: LLM在金融市场做市中表现出色但推理速度慢，现有研究缺乏针对该任务的LLM蒸馏方法。

Method: 提出CMM框架，在三个正交维度（层、任务、数据）上解耦LLM特征，多个学生模型协作学习不同维度的简单特征，并使用Hájek-MoE集成模型输出。

Result: 在四个真实市场数据集上的实验结果表明，CMM优于当前蒸馏方法和基于RL的市场做市策略。

Conclusion: CMM框架通过多维度特征解耦和协作学习，有效实现了LLM知识蒸馏，提升了市场做市任务的性能。

Abstract: Market making (MM) through Reinforcement Learning (RL) has attracted significant attention in financial trading. With the development of Large Language Models (LLMs), more and more attempts are being made to apply LLMs to financial areas. A simple, direct application of LLM as an agent shows significant performance. Such methods are hindered by their slow inference speed, while most of the current research has not studied LLM distillation for this specific task. To address this, we first propose the normalized fluorescent probe to study the mechanism of the LLM's feature. Based on the observation found by our investigation, we propose Cooperative Market Making (CMM), a novel framework that decouples LLM features across three orthogonal dimensions: layer, task, and data. Various student models collaboratively learn simple LLM features along with different dimensions, with each model responsible for a distinct feature to achieve knowledge distillation. Furthermore, CMM introduces an Hájek-MoE to integrate the output of the student models by investigating the contribution of different models in a kernel function-generated common feature space. Extensive experimental results on four real-world market datasets demonstrate the superiority of CMM over the current distillation method and RL-based market-making strategies.

</details>


### [88] [Saliency Map-Guided Knowledge Discovery for Subclass Identification with LLM-Based Symbolic Approximations](https://arxiv.org/abs/2511.07126)
*Tim Bohne,Anne-Kathrin Patricia Windler,Martin Atzmueller*

Main category: cs.AI

TL;DR: 提出一种基于显著性图的神经符号方法，用于时间序列分类中的潜在子类发现，通过梯度显著性图指导聚类过程，并使用LLM进行符号近似和模糊知识图匹配。


<details>
  <summary>Details</summary>
Motivation: 解决时间序列分类中识别潜在子类的问题，利用神经网络的可解释性来指导知识发现过程。

Method: 将多类分类转化为二元分类问题，生成显著性图，对信号进行聚类，最后使用LLM进行符号近似和模糊知识图匹配来发现子类。

Result: 在标准时间序列分类数据集上的实验表明，该方法在聚类和子类识别方面优于仅使用信号的基线方法。

Conclusion: 显著性图驱动的方法能有效发现时间序列分类中的潜在子类，为知识发现提供了新的神经符号途径。

Abstract: This paper proposes a novel neuro-symbolic approach for sensor signal-based knowledge discovery, focusing on identifying latent subclasses in time series classification tasks. The approach leverages gradient-based saliency maps derived from trained neural networks to guide the discovery process. Multiclass time series classification problems are transformed into binary classification problems through label subsumption, and classifiers are trained for each of these to yield saliency maps. The input signals, grouped by predicted class, are clustered under three distinct configurations. The centroids of the final set of clusters are provided as input to an LLM for symbolic approximation and fuzzy knowledge graph matching to discover the underlying subclasses of the original multiclass problem. Experimental results on well-established time series classification datasets demonstrate the effectiveness of our saliency map-driven method for knowledge discovery, outperforming signal-only baselines in both clustering and subclass identification.

</details>


### [89] [PADiff: Predictive and Adaptive Diffusion Policies for Ad Hoc Teamwork](https://arxiv.org/abs/2511.07260)
*Hohei Chan,Xinzhi Zhang,Antao Xiang,Weinan Zhang,Mengchen Zhao*

Main category: cs.AI

TL;DR: PADiff是一种基于扩散模型的方法，用于解决ad hoc teamwork中的多模态行为问题，通过在去噪过程中整合队友预测信息来适应高度非平稳环境。


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在ad hoc teamwork中容易陷入单一行为模式，无法捕捉多模态合作模式，需要开发能够预测和适应未知队友的智能体。

Method: 提出PADiff扩散模型方法，在去噪过程中整合队友的预测信息，以捕捉智能体的多模态行为并实现多样化合作模式。

Result: 在三个合作环境中的广泛实验表明，PADiff显著优于现有的AHT方法。

Conclusion: PADiff通过扩散模型成功解决了AHT中的多模态行为挑战，为与未知队友的多样化合作提供了有效解决方案。

Abstract: Ad hoc teamwork (AHT) requires agents to collaborate with previously unseen teammates, which is crucial for many real-world applications. The core challenge of AHT is to develop an ego agent that can predict and adapt to unknown teammates on the fly. Conventional RL-based approaches optimize a single expected return, which often causes policies to collapse into a single dominant behavior, thus failing to capture the multimodal cooperation patterns inherent in AHT. In this work, we introduce PADiff, a diffusion-based approach that captures agent's multimodal behaviors, unlocking its diverse cooperation modes with teammates. However, standard diffusion models lack the ability to predict and adapt in highly non-stationary AHT scenarios. To address this limitation, we propose a novel diffusion-based policy that integrates critical predictive information about teammates into the denoising process. Extensive experiments across three cooperation environments demonstrate that PADiff outperforms existing AHT methods significantly.

</details>


### [90] [AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning](https://arxiv.org/abs/2511.07262)
*Qile Jiang,George Karniadakis*

Main category: cs.AI

TL;DR: AgenticSciML是一个多智能体协作系统，通过10多个专门AI智能体的结构化辩论、检索增强方法记忆和集成引导进化搜索，自动设计和优化科学机器学习解决方案。


<details>
  <summary>Details</summary>
Motivation: 科学机器学习的架构设计、损失函数制定和训练策略目前仍依赖专家驱动的研究过程，需要大量实验和问题特定洞察，缺乏自动化方法。

Method: 采用多智能体协作框架，智能体通过结构化辩论、检索增强方法记忆和集成引导进化搜索来提出、批评和优化SciML解决方案。

Result: 在物理信息学习和算子学习任务中，该框架发现的解决方案比单智能体和人工设计基线在误差减少方面提升了四个数量级，并产生了新的策略如自适应专家混合架构、基于分解的PINNs和物理信息算子学习模型。

Conclusion: AI智能体之间的协作推理能够产生新兴的方法创新，为科学计算中可扩展、透明和自主发现提供了路径。

Abstract: Scientific Machine Learning (SciML) integrates data-driven inference with physical modeling to solve complex problems in science and engineering. However, the design of SciML architectures, loss formulations, and training strategies remains an expert-driven research process, requiring extensive experimentation and problem-specific insights. Here we introduce AgenticSciML, a collaborative multi-agent system in which over 10 specialized AI agents collaborate to propose, critique, and refine SciML solutions through structured reasoning and iterative evolution. The framework integrates structured debate, retrieval-augmented method memory, and ensemble-guided evolutionary search, enabling the agents to generate and assess new hypotheses about architectures and optimization procedures. Across physics-informed learning and operator learning tasks, the framework discovers solution methods that outperform single-agent and human-designed baselines by up to four orders of magnitude in error reduction. The agents produce novel strategies -- including adaptive mixture-of-expert architectures, decomposition-based PINNs, and physics-informed operator learning models -- that do not appear explicitly in the curated knowledge base. These results show that collaborative reasoning among AI agents can yield emergent methodological innovation, suggesting a path toward scalable, transparent, and autonomous discovery in scientific computing.

</details>


### [91] [Beyond Detection: Exploring Evidence-based Multi-Agent Debate for Misinformation Intervention and Persuasion](https://arxiv.org/abs/2511.07267)
*Chen Han,Yijia Ma,Jin Tan,Wenzhen Zheng,Xijin Tang*

Main category: cs.AI

TL;DR: ED2D是一个基于证据的多智能体辩论框架，不仅用于检测错误信息，还旨在纠正用户信念并阻止错误信息传播。该框架在检测准确性上优于现有基线，其生成的辟谣文本在正确预测时说服力与人类专家相当，但错误分类时可能强化用户误解。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体辩论框架主要关注检测准确性，忽视了帮助用户理解事实判断背后的推理过程和发展未来抵御能力的重要性。辩论过程中生成的文本提供了丰富但未被充分利用的透明推理资源。

Method: 引入ED2D框架，扩展了先前方法，整合了事实证据检索功能。该框架不仅作为检测框架，更设计为具有说服力的多智能体系统，旨在纠正用户信念并阻止错误信息传播。

Result: ED2D在三个错误信息检测基准测试中优于现有基线。当ED2D生成正确预测时，其辟谣文本的说服效果与人类专家相当；但当错误分类时，其解释可能无意中强化用户的误解，即使与准确的人类解释一起呈现。

Conclusion: 研究结果凸显了部署多智能体辩论系统进行错误信息干预的潜力和潜在风险。开发了公共社区网站来帮助用户探索ED2D，促进透明度、批判性思维和协作事实核查。

Abstract: Multi-agent debate (MAD) frameworks have emerged as promising approaches for misinformation detection by simulating adversarial reasoning. While prior work has focused on detection accuracy, it overlooks the importance of helping users understand the reasoning behind factual judgments and develop future resilience. The debate transcripts generated during MAD offer a rich but underutilized resource for transparent reasoning. In this study, we introduce ED2D, an evidence-based MAD framework that extends previous approach by incorporating factual evidence retrieval. More importantly, ED2D is designed not only as a detection framework but also as a persuasive multi-agent system aimed at correcting user beliefs and discouraging misinformation sharing. We compare the persuasive effects of ED2D-generated debunking transcripts with those authored by human experts. Results demonstrate that ED2D outperforms existing baselines across three misinformation detection benchmarks. When ED2D generates correct predictions, its debunking transcripts exhibit persuasive effects comparable to those of human experts; However, when ED2D misclassifies, its accompanying explanations may inadvertently reinforce users'misconceptions, even when presented alongside accurate human explanations. Our findings highlight both the promise and the potential risks of deploying MAD systems for misinformation intervention. We further develop a public community website to help users explore ED2D, fostering transparency, critical thinking, and collaborative fact-checking.

</details>


### [92] [IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction](https://arxiv.org/abs/2511.07327)
*Guoxin Chen,Zile Qiao,Xuanzhong Chen,Donglei Yu,Haotian Xu,Wayne Xin Zhao,Ruihua Song,Wenbiao Yin,Huifeng Yin,Liwen Zhang,Kuan Li,Minpeng Liao,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.AI

TL;DR: IterResearch提出了一种迭代式深度研究范式，通过马尔可夫决策过程和战略工作空间重构来解决长时程研究任务中的上下文窒息问题，显著提升了研究性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度研究代理采用单上下文范式，在长时程任务中会导致上下文窒息和噪声污染，限制了其有效性。

Method: 将长时程研究重新定义为马尔可夫决策过程，维护演化报告作为记忆并定期综合见解；开发了效率感知策略优化框架，通过几何奖励折扣激励高效探索。

Result: 在六个基准测试中平均提升14.5个百分点，交互规模扩展到2048次时性能从3.5%提升至42.5%，作为提示策略可将前沿模型性能提升19.2个百分点。

Conclusion: IterResearch是长时程推理的多功能解决方案，既可作为训练代理，也可作为前沿模型的提示范式。

Abstract: Recent advances in deep-research agents have shown promise for autonomous knowledge construction through dynamic reasoning over external sources. However, existing approaches rely on a mono-contextual paradigm that accumulates all information in a single, expanding context window, leading to context suffocation and noise contamination that limit their effectiveness on long-horizon tasks. We introduce IterResearch, a novel iterative deep-research paradigm that reformulates long-horizon research as a Markov Decision Process with strategic workspace reconstruction. By maintaining an evolving report as memory and periodically synthesizing insights, our approach preserves consistent reasoning capacity across arbitrary exploration depths. We further develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning framework that incentivizes efficient exploration through geometric reward discounting and enables stable distributed training via adaptive downsampling. Extensive experiments demonstrate that IterResearch achieves substantial improvements over existing open-source agents with average +14.5pp across six benchmarks and narrows the gap with frontier proprietary systems. Remarkably, our paradigm exhibits unprecedented interaction scaling, extending to 2048 interactions with dramatic performance gains (from 3.5\% to 42.5\%), and serves as an effective prompting strategy, improving frontier models by up to 19.2pp over ReAct on long-horizon tasks. These findings position IterResearch as a versatile solution for long-horizon reasoning, effective both as a trained agent and as a prompting paradigm for frontier models.

</details>


### [93] [DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas](https://arxiv.org/abs/2511.07338)
*Zhen Wang,Yufan Zhou,Zhongyan Luo,Lyumanshan Ye,Adam Wood,Man Yao,Luoshang Pan*

Main category: cs.AI

TL;DR: DEEPPERSONA是一个可扩展的生成引擎，通过两阶段、分类学指导的方法合成叙事完整的人工角色，显著提升了角色属性的多样性和独特性。


<details>
  <summary>Details</summary>
Motivation: 现有的人工角色通常浅薄简单，仅捕获少量属性，无法反映真实人类身份的丰富复杂性和多样性。

Method: 首先通过挖掘数千个真实用户与ChatGPT的对话，算法构建最大的人类属性分类学；然后从该分类学中逐步采样属性，有条件地生成连贯且现实的角色。

Result: 内在评估显示属性多样性提高32%，角色独特性提高44%；外在评估显示GPT-4.1-mini的个性化问答准确率平均提高11.6%，在社交调查中模拟LLM公民与真实人类响应之间的差距缩小31.7%。

Conclusion: DEEPPERSONA为高保真人类模拟和个性化AI研究提供了一个严谨、可扩展且无需隐私的平台。

Abstract: Simulating human profiles by instilling personas into large language models (LLMs) is rapidly transforming research in agentic behavioral simulation, LLM personalization, and human-AI alignment. However, most existing synthetic personas remain shallow and simplistic, capturing minimal attributes and failing to reflect the rich complexity and diversity of real human identities. We introduce DEEPPERSONA, a scalable generative engine for synthesizing narrative-complete synthetic personas through a two-stage, taxonomy-guided method. First, we algorithmically construct the largest-ever human-attribute taxonomy, comprising over hundreds of hierarchically organized attributes, by mining thousands of real user-ChatGPT conversations. Second, we progressively sample attributes from this taxonomy, conditionally generating coherent and realistic personas that average hundreds of structured attributes and roughly 1 MB of narrative text, two orders of magnitude deeper than prior works. Intrinsic evaluations confirm significant improvements in attribute diversity (32 percent higher coverage) and profile uniqueness (44 percent greater) compared to state-of-the-art baselines. Extrinsically, our personas enhance GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on average across ten metrics and substantially narrow (by 31.7 percent) the gap between simulated LLM citizens and authentic human responses in social surveys. Our generated national citizens reduced the performance gap on the Big Five personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA thus provides a rigorous, scalable, and privacy-free platform for high-fidelity human simulation and personalized AI research.

</details>


### [94] [DigiData: Training and Evaluating General-Purpose Mobile Control Agents](https://arxiv.org/abs/2511.07413)
*Yuxuan Sun,Manchen Wang,Shengyi Qian,William R. Wong,Eric Gan,Pierluca D'Oro,Alejandro Castillejo Munoz,Sneha Silwal,Pedro Matias,Nitin Kamra,Satwik Kottur,Nick Raines,Xuanyi Zhao,Joy Chen,Joseph Greer,Andrea Madotto,Allen Bolourchi,James Valori,Kevin Carlberg,Karl Ridgeway,Joseph Tighe*

Main category: cs.AI

TL;DR: 本文介绍了DigiData数据集和DigiData-Bench基准，用于训练和评估移动控制AI代理。DigiData通过全面探索应用功能构建，具有更高的多样性和目标复杂性；DigiData-Bench提出了动态评估协议和AI驱动的评估方法，以更可靠地评估移动控制代理。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏高质量的数据集和可靠的评估方法来加速移动控制AI代理的发展，这些代理有潜力改变人类与数字设备的交互方式。

Method: 构建了DigiData大规模多模态数据集，通过全面探索应用功能而非非结构化交互来确保多样性和复杂性；建立了DigiData-Bench基准，提出动态评估协议和AI驱动的评估方法。

Result: DigiData数据集具有更高的多样性和目标复杂性；DigiData-Bench提供了比传统步骤准确性指标更可靠的评估方法。

Conclusion: 这些贡献显著推进了移动控制代理的发展，为更直观有效的人机交互铺平了道路。

Abstract: AI agents capable of controlling user interfaces have the potential to transform human interaction with digital devices. To accelerate this transformation, two fundamental building blocks are essential: high-quality datasets that enable agents to achieve complex and human-relevant goals, and robust evaluation methods that allow researchers and practitioners to rapidly enhance agent performance. In this paper, we introduce DigiData, a large-scale, high-quality, diverse, multi-modal dataset designed for training mobile control agents. Unlike existing datasets, which derive goals from unstructured interactions, DigiData is meticulously constructed through comprehensive exploration of app features, resulting in greater diversity and higher goal complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating mobile control agents on real-world complex tasks. We demonstrate that the commonly used step-accuracy metric falls short in reliably assessing mobile control agents and, to address this, we propose dynamic evaluation protocols and AI-powered evaluations as rigorous alternatives for agent assessment. Our contributions aim to significantly advance the development of mobile control agents, paving the way for more intuitive and effective human-device interactions.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [95] [Estimating the Impact of the Bitcoin Halving on Its Price Using Synthetic Control](https://arxiv.org/abs/2511.05512)
*Vladislav Virtonen*

Main category: econ.GN

TL;DR: 使用合成控制法分析比特币减半对价格的影响，发现2024年减半在三个月后对价格有正向影响，但2020年减半的影响不显著。


<details>
  <summary>Details</summary>
Motivation: 验证比特币减半事件是否真正导致价格上涨，还是仅仅是事后归因谬误。

Method: 使用合成控制法构建一个没有经历减半的模拟比特币，比较实际比特币和模拟比特币的价格轨迹。

Result: 2024年减半在三个月后对价格有正向影响，影响幅度占研究期间总价格变化的五分之一；2020年减半的影响在统计上不显著。

Conclusion: 这是第一篇从因果角度分析比特币减半影响的论文，为现有相关性研究提供了因果证据支持。

Abstract: The third Bitcoin halving that took place in May 2020 cut down the mining reward from 12.5 to 6.25 BTC per block and thus slowed down the rate of issuance of new Bitcoins, making it more scarce. The fourth and most recent halving happened in April 2024, cutting the block reward further to 3.125 BTC. If the demand did not decrease simultaneously after these halvings, then the neoclassical economic theory posits that the price of Bitcoin should have increased due to the halving. But did it, in fact, increase for that reason, or is this a post hoc fallacy? This paper uses synthetic control to construct a weighted Bitcoin that is different from its counterpart in one aspect - it did not undergo halving. Comparing the price trajectory of the actual and the simulated Bitcoins, I find evidence of a positive effect of the 2024 Bitcoin halving on its price three months later. The magnitude of this effect is one fifth of the total percentage change in the price of Bitcoin during the study period - from April 2, 2023, to July 21, 2024 (17 months). The second part of the study fails to obtain a statistically significant and robust causal estimate of the effect of the 2020 Bitcoin halving on Bitcoin's price. This is the first paper analyzing the effect of halving causally, building on the existing body of correlational research.

</details>


### [96] [Some economics of artificial super intelligence](https://arxiv.org/abs/2511.06613)
*Henry A. Thompson*

Main category: econ.GN

TL;DR: 论文应用经济学原理分析超级人工智能的威胁，发现即使存在不对齐的ASI，在竞争、利益捆绑和信用交易等条件下，人类文明也不一定会被完全摧毁。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为不对齐的超级人工智能会毁灭人类，但作者希望通过经济学中的跨司法管辖区竞争、全面利益和信用交易等经典逻辑来重新审视这一威胁。

Method: 使用简单模型分析三种情况：当人类可以逃向竞争对手时，ASI之间的竞争会抑制掠夺行为；当被垄断ASI控制时，其对人类产出的全面利益使其成为理性专制者而非掠夺者；当ASI无长期利益时，人类扣留未来产出的能力激励其进行信用交易而非掠夺。

Result: 在每种扩展情况下，人类福利逐渐恶化，但灾难并非不可避免。竞争、利益捆绑和信用交易机制都能在一定程度上约束ASI的掠夺行为。

Conclusion: 经济学分析提供了对超级智能未来的乐观看法，表明即使面对不对齐的ASI，人类文明仍有生存机会，灾难不是必然结果。

Abstract: Conventional wisdom holds that a misaligned artificial superintelligence (ASI) will destroy humanity. But the problem of constraining a powerful agent is not new. I apply classic economic logic of interjurisdictional competition, all-encompassing interest, and trading on credit to the threat of misaligned ASI. Using a simple model, I show that an acquisitive ASI refrains from full predation under surprisingly weak conditions. When humans can flee to rivals, inter-ASI competition creates a market that tempers predation. When trapped by a monopolist ASI, its "encompassing interest" in humanity's output makes it a rational autocrat rather than a ravager. And when the ASI has no long-term stake, our ability to withhold future output incentivizes it to trade on credit rather than steal. In each extension, humanity's welfare progressively worsens. But each case suggests that catastrophe is not a foregone conclusion. The dismal science, ironically, offers an optimistic take on our superintelligent future.

</details>


### [97] [0.001% and Counting: Revisiting the Price Rounding Tax](https://arxiv.org/abs/2511.05599)
*Doron Sayag,Avichai Snir,Daniel Levy*

Main category: econ.GN

TL;DR: 以色列废除小额硬币后，消费者在现金交易中因四舍五入承担的小额税收仅占快速消费品市场收入的0.001%-0.002%，这对美国是否应废除1分和5分硬币的争论具有参考意义。


<details>
  <summary>Details</summary>
Motivation: 研究以色列废除小额硬币政策对消费者产生的实际影响，为美国是否应废除1分和5分硬币的争论提供实证依据。

Method: 使用超市、药店、小杂货店和便利店的价格尾数和购物篮规模的详细数据，分析现金交易中的四舍五入效应。

Result: 以色列消费者承担的'四舍五入税'平均仅占快速消费品市场收入的0.001%-0.002%，影响极其微小。

Conclusion: 废除小额硬币对消费者的实际财务影响可以忽略不计，这支持了美国考虑废除1分和5分硬币的可行性。

Abstract: In 1991 and 2008, Israel abolished the equivalents of 1-cent and 5-cent coins, respectively, effectively eliminating low-denomination coins and introducing rounding in cash transactions. When totals were rounded up, shoppers incurred a small rounding tax. Using detailed data on price endings and basket sizes across supermarkets, drugstores, small groceries, and convenience stores, we estimate that the magnitude of the rounding tax borne by Israeli consumers averaged only between 0.001 percent and 0.002 percent of revenues in the fast-moving consumer goods markets. These findings have implications for the ongoing debate regarding the desirability and viability of abolishing the 1-cent and 5-cent coins in the US.

</details>


### [98] [The Long Shadow of Superstars: Effects on Opportunities, Careers, and Team Production](https://arxiv.org/abs/2511.07218)
*Masaya Nishihata*

Main category: econ.GN

TL;DR: 研究表明，超级明星的存在会减少队友的上场机会，阻碍其技能发展，导致更早退出职业联盟，并在明星离开后造成团队表现下滑。


<details>
  <summary>Details</summary>
Motivation: 探讨超级明星在团队中的主导地位如何无意中限制其他成员的在职学习机会和职业发展。

Method: 利用美国职业棒球大联盟(MLB)的面板数据，通过明星球员因伤缺阵带来的外生变化来识别因果关系。

Result: 当超级明星活跃时，非明星队友上场时间显著减少；与明星同队开始职业生涯的球员提前退出MLB的可能性增加1.7倍；团队过度依赖明星会提高短期产出但放大明星离开后的表现下滑。

Conclusion: 将关键角色集中在顶尖人才身上虽然能提升短期产出，但会限制他人的发展和留任，这种权衡在其他依赖少数杰出个体的组织中也可能存在。

Abstract: Superstars often dominate key tasks because of their exceptional abilities, but this concentration of responsibility may unintentionally limit on-the-job learning opportunities for others. Using panel data from Major League Baseball (MLB), this study examines how superstar presence affects teammates' opportunities and career outcomes. To address potential endogeneity in team composition, we exploit plausibly exogenous variation in superstar availability caused by injuries. When a superstar is active in the same team-position unit, non-star teammates play significantly less. These short-term reductions in playing time extend to longer horizons: players who begin their careers alongside a superstar who remains active for a full season (i.e., not on the injured list) are about 1.7 times more likely to exit MLB earlier than comparable peers. A key mechanism is reduced skill development -- limited playing opportunities hinder subsequent growth in offensive performance. At the team level, greater dependence on superstars raises immediate productivity but magnifies performance declines after their departure, indicating a trade-off between short-term success and long-term adaptability. Overall, the findings suggest that while concentrating key roles in top performers boosts output in the short run, it can restrict others' development and retention. Similar dynamics may arise in other organizations that rely heavily on a few exceptional individuals.

</details>


### [99] [How Founder Expertise Shapes the Impact of Generative Artificial Intelligence on Digital Ventures](https://arxiv.org/abs/2511.06545)
*Ruiqing Cao,Abhishek Bhatia*

Main category: econ.GN

TL;DR: 生成式AI降低了数字创业成本，使更多不可行的创业想法变得可行，并提升现有企业表现。研究发现，在GenAI使用率高的领域，新企业数量增加且启动时间缩短，对缺乏管理经验创始人影响更大，而对有技术背景创始人的VC融资影响更强。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI如何通过降低资源需求影响数字创业，以及创始人技术和管理专长如何调节这种影响。

Method: 利用跨创业类别GenAI使用的外生变异和GenAI工具公开发布时间，分析新企业启动数量和速度变化。

Result: GenAI使用率高的类别新企业数量显著增加，启动时间缩短；对无管理经验创始人启动影响更大，对有技术背景创始人融资影响更强。

Conclusion: GenAI为缺乏管理专长的创始人扩大了数字创业机会，同时提升了有技术背景创始人的企业表现。

Abstract: The rapid diffusion of generative artificial intelligence (GenAI) has substantially lowered the costs of launching and developing digital ventures. GenAI can potentially both enable previously unviable entrepreneurial ideas by lowering resource needs and improve the performance of existing ventures. We explore how founders' technical and managerial expertise shapes GenAI's impact on digital ventures along these dimensions. Exploiting exogenous variation in GenAI usage across venture categories and the timing of its broad availability for software tasks (e.g., GitHub Copilot's public release and subsequent GenAI tools), we find that the number of new venture launches increased and the median time to launch decreased significantly more in categories with relatively high GenAI usage. GenAI's effect on new launches is larger for founders without managerial experience or education, while its effect on venture capital (VC) funding likelihood is stronger for founders with technical experience or education. Overall, our results suggest that GenAI expands access to digital entrepreneurship for founders lacking managerial expertise and enhances venture performance among technical founders.

</details>


### [100] [The Value of Personalized Recommendations: Evidence from Netflix](https://arxiv.org/abs/2511.07280)
*Kevin Zielnicki,Guy Aridor,Aurélien Bibaut,Allen Tran,Winston Chou,Nathan Kallus*

Main category: econ.GN

TL;DR: 本文构建了一个离散选择模型来量化推荐系统的价值，应用于Netflix观看数据，发现个性化推荐能显著提升用户参与度，其中目标定位比机械曝光贡献更大。


<details>
  <summary>Details</summary>
Motivation: 个性化推荐系统对用户选择有重要影响，但由于其针对性特点，难以将推荐价值与商品本身价值区分开来。

Method: 构建包含推荐诱导效用、低秩异质性和灵活状态依赖的离散选择模型，利用推荐算法引入的异质性变化来识别各组件价值。

Result: 用矩阵分解或基于流行度的算法替代当前推荐系统会导致参与度分别下降4%和12%；推荐带来的消费增长主要来自有效目标定位而非机械曝光，中流行度商品获益最大。

Conclusion: 个性化推荐系统能显著提升用户参与度，其中目标定位机制是关键价值来源，特别是对中流行度商品的推荐效果最佳。

Abstract: Personalized recommendation systems shape much of user choice online, yet their targeted nature makes separating out the value of recommendation and the underlying goods challenging. We build a discrete choice model that embeds recommendation-induced utility, low-rank heterogeneity, and flexible state dependence and apply the model to viewership data at Netflix. We exploit idiosyncratic variation introduced by the recommendation algorithm to identify and separately value these components as well as to recover model-free diversion ratios that we can use to validate our structural model. We use the model to evaluate counterfactuals that quantify the incremental engagement generated by personalized recommendations. First, we show that replacing the current recommender system with a matrix factorization or popularity-based algorithm would lead to 4% and 12% reduction in engagement, respectively, and decreased consumption diversity. Second, most of the consumption increase from recommendations comes from effective targeting, not mechanical exposure, with the largest gains for mid-popularity goods (as opposed to broadly appealing or very niche goods).

</details>


### [101] [Does Urban Local Governance Matter? Evidence from India](https://arxiv.org/abs/2511.06562)
*Saani Rawat*

Main category: econ.GN

TL;DR: 本文使用模糊断点回归设计研究印度城市地方治理对公共物品供给的因果效应，发现获得城市地方机构能显著增加教育、医疗和金融基础设施，但会减少体育设施。


<details>
  <summary>Details</summary>
Motivation: 研究城市地方治理对公共物品供给的因果效应，特别是在印度快速城市化的背景下，了解及时设立市政机构对改善公共服务的潜在影响。

Method: 利用人口普查城镇分类的多阈值标准产生的准随机变异，采用模糊断点回归设计，识别获得城市地方机构的局部平均处理效应。

Result: 获得城市地方机构使政府学校数量显著增加（小学14所、初中8所、高中5所），医疗基础设施增加（2家医院和3个家庭福利中心），金融接入深化（15家私人银行、2家合作银行和2家农业信贷协会），但体育设施减少5个。

Conclusion: 及时为新兴城市区域设立市政机构可以扩大某些公共物品的供给，可能改善城市化经济体的生活水平和经济机会。

Abstract: This paper examines the causal effect of urban local governance on public goods provision in India. We exploit quasi-random variation in multi-threshold criteria utilized for classifying Census Towns (CTs) and focus on settlements near the thresholds that are likely to obtain statutory recognition. Using a fuzzy regression discontinuity design, we instrument for urban local governance to identify the Local Average Treatment Effect (LATE). We document a strong first stage relationship between meeting CT thresholds and statutory recognition. Our results show that obtaining an Urban Local Body (ULB) increases local public good provision: government schools increase by approximately 14 (primary), 8 (middle), and 5 (secondary), healthcare infrastructure expands by 2 hospitals and 3 family welfare centers, and financial access deepens with 15 private banks, 2 cooperative banks, and 2 agricultural credit societies. Community amenities improve modestly with an additional public library, reading room, and cinema hall. Sports infrastructure declines by 5 facilities, consistent with our understanding of reallocation of urban space and investments. Our findings suggest that timely municipalization of emerging urban areas can expand provision of certain public goods, which may improve living standards and economic opportunities in urbanizing economies.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [102] [Mapping Power Relations: A Geometric Framework for Game-Theoretic Analysis](https://arxiv.org/abs/2511.07287)
*Daniele De luca*

Main category: econ.TH

TL;DR: 提出了一个独立于策略形式的几何框架来分析博弈中的权力关系，将玩家的关系立场建模为归一化向量，消除了选择效用函数的任意性。


<details>
  <summary>Details</summary>
Motivation: 消除近期方法中选择效用函数的任意性限制，为分析博弈中的权力关系提供更基础的理论框架。

Method: 通过两个步骤进行分析：将博弈的收益和结果投影到偏好空间，然后使用关键指标（质心、层级指数、互惠指数）简化结果景观。

Result: 框架能够揭示不同策略设置下的潜在结构相似性，并为关系动态提供量化表征，在经典博弈和经济模型中得到了验证。

Conclusion: 该框架通过将权力概念化为从偏好到均衡映射的结构属性，架起了合作博弈论与非合作博弈论之间的桥梁。

Abstract: This paper introduces a geometric framework for analyzing power relations in games, independent of their strategic form. We define a canonical preference space where each player's relational stance is a normalized vector. This model eliminates the arbitrariness of selecting utility functions, a limitation of recent approaches. We show how classical concepts-bargaining power, dependence, reciprocity-are recovered and generalized within this space. The analysis proceeds in two steps: projecting a game's payoffs and outcomes onto the space, and then reducing the resulting landscape using key metrics. These include a Center of Mass (CoM) and structural indices for Hierarchy (H) and Reciprocity (R). Applications to canonical games (Prisoner's Dilemma, Battle of the Sexes) and economic models (Cournot duopoly) demonstrate that the framework reveals underlying structural similarities across different strategic settings and provides a quantitative characterization of relational dynamics. It thus bridges cooperative and non-cooperative game theory by conceptualizing power as a structural property of the mapping from preferences to equilibria.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [103] [On the Development of Probabilistic Projections of Country-level Progress to the UN SDG Indicator of Minimum Proficiency in Reading and Mathematics](https://arxiv.org/abs/2511.06107)
*David Kaplan,Nina Jude,Kjorte Harra,Jonas Stampka*

Main category: stat.AP

TL;DR: 本文使用贝叶斯潜在增长曲线建模和贝叶斯模型平均方法，为联合国可持续发展目标4.1.1（初中生阅读和数学最低熟练度）提供概率性进展预测。


<details>
  <summary>Details</summary>
Motivation: 各国迫切需要预测到203年实现可持续发展目标的进展，但现有统计方法未能专门设计用于获得最优的进展速率预测指标。

Method: 结合OECD PISA数据及世界银行、OECD、UNDP、UNESCO的指标，采用贝叶斯潜在增长曲线建模和贝叶斯模型平均的新颖组合方法。

Result: 获得了最低熟练度百分比进展速率的最优估计，并基于此开发了所有分析国家未来的概率性预测，展示了四个案例国家的个体预测应用。

Conclusion: 该方法能够为可持续发展目标4.1.1提供可靠的进展预测，支持各国制定有效的教育政策。

Abstract: As of this writing, there are five years remaining for countries to reach their Sustainable Development Goals deadline of 2030 as agreed to by the member countries of the United Nations. Countries are, therefore, naturally interested in projections of progress toward these goals. A variety of statistical measures have been used to report on country-level progress toward the goals, but they have not utilized methodologies explicitly designed to obtain optimally predictive measures of rate of progress as the foundation for projecting trends. The focus of this paper is to provide Bayesian probabilistic projections of progress to SDG indicator 4.1.1, attaining minimum proficiency in reading and mathematics, with particular emphasis on competencies among lower secondary school children. Using data from the OECD PISA, as well as indicators drawn from the World Bank, the OECD, UNDP, and UNESCO, we employ a novel combination of Bayesian latent growth curve modeling Bayesian model averaging to obtain optimal estimates of the rate of progress in minimum proficiency percentages and then use those estimate to develop probabilistic projections into the future overall for all countries in the analysis. Four case study countries are also presented to show how the methods can be used for individual country projections.

</details>


### [104] [Bayesian Meta-Analysis with Application in Dental Studies](https://arxiv.org/abs/2511.06200)
*Sara Antonijevic,Danielle Sitalo,Brani Vidakovic*

Main category: stat.AP

TL;DR: 该研究通过荟萃分析评估氟化物漆对减少龋齿的有效性，使用贝叶斯层次模型得出氟化物漆可降低约43%的龋齿发病率，结果稳健可靠。


<details>
  <summary>Details</summary>
Motivation: 龋齿是全球持续的健康挑战，氟化物漆作为预防干预措施被广泛使用，需要系统评估其有效性。

Method: 采用固定效应和随机效应模型的荟萃分析，并结合层次贝叶斯推断，使用多种先验分布评估异质性假设下的稳健性。

Result: 所有模型规格下，汇总估计显示龋齿发病率降低约43%，可信区间一致排除零效应。

Conclusion: 氟化物漆是有效且一致的预防措施，贝叶斯层次建模作为传统荟萃分析技术的强大补充在牙科公共卫生研究中具有重要价值。

Abstract: Dental caries remain a persistent global health challenge, and fluoride varnish is widely used as a preventive intervention. This study synthesizes evidence from multiple clinical trials to evaluate the effectiveness of fluoride varnish in reducing Decayed-Missing-Filled (DMF) surfaces. The principal measure of efficacy is the Prevented Fraction (PF), representing the proportional reduction in caries relative to untreated controls. A comprehensive meta-analysis was conducted using fixed-effect and random-effects models, complemented by hierarchical Bayesian inference. The Bayesian framework incorporated multiple prior distributions on between-study variance, including Pareto, half-normal, uniform, beta, and scaled chi-square forms, to assess robustness under alternative heterogeneity assumptions. Across all specifications, the pooled estimate indicated an approximate 43% reduction in caries incidence, with credible intervals consistently excluding the null. Compared to classical methods, the Bayesian approach provided richer uncertainty quantification through full posterior distributions, allowed principled incorporation of prior evidence, and offered improved inference under heterogeneity and small-sample conditions. The stability of posterior estimates across diverse priors reinforces the robustness and reliability of the conclusions. Overall, findings confirm fluoride varnish as an effective and consistent preventive measure, and demonstrate the value of Bayesian hierarchical modeling as a powerful complement to traditional meta-analytic techniques in dental public health research.

</details>


### [105] [A unified approach to spatial domain detection and cell-type deconvolution in spot-based spatial transcriptomics](https://arxiv.org/abs/2511.06204)
*Hyun Jung Koo,Aaron J. Molstad*

Main category: stat.AP

TL;DR: 提出了DUET方法，可同时识别空间域并估计细胞类型比例，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 空间转录组数据通常以"斑点"为单位测量基因表达，每个斑点可能包含多种细胞类型。研究人员需要识别组织中的离散空间域，但现有方法无法同时提供细胞类型比例信息。

Method: 使用基于模型的凸聚类的约束版本，可处理泊松、负二项、正态等多种表达数据类型。

Result: 通过模拟研究和多个应用验证，DUET在聚类和解卷积性能上优于现有方法。

Conclusion: DUET能够同时识别空间域和估计细胞类型比例，提供可解释性和生物学见解，是分析空间转录组数据的有效工具。

Abstract: Many popular technologies for generating spatially resolved transcriptomic (SRT) data measure gene expression at the resolution of a "spot", i.e., a small tissue region 55 microns in diameter. Each spot can contain many cells of different types. In typical analyses, researchers are interested in using these data to identify discrete spatial domains in the tissue. In this paper, we propose a new method, DUET, that simultaneously identifies discrete spatial domains and estimates each spot's cell-type proportion. This allows the identified spatial domains to be characterized in terms of the cell type proportions, which affords interpretability and biological insight. DUET utilizes a constrained version of model-based convex clustering, and as such, can accommodate Poisson, negative binomial, normal, and other types of expression data. Through simulation studies and multiple applications, we show that our method can achieve better clustering and deconvolution performance than existing methods.

</details>


### [106] [Bayesian spatio-temporal disaggregation modeling using a diffusion-SPDE approach: a case study of Aerosol Optical Depth in India](https://arxiv.org/abs/2511.06276)
*Fernando Rodriguez Avellaneda,Paula Moraga*

Main category: stat.AP

TL;DR: 提出了一种时空分解模型，通过高斯过程和SPDE方法将粗分辨率的气溶胶光学厚度观测分解到更高时空分辨率


<details>
  <summary>Details</summary>
Motivation: 气溶胶光学厚度是衡量空气质量的重要指标，但现有卫星观测时空分辨率较低，需要高分辨率估计来支持政策制定

Method: 使用潜在时空连续高斯过程模型，结合可分离或不可分离协方差结构，采用INLA-SPDE框架进行贝叶斯推断

Result: 成功将印度地区AOD的空间分辨率从0.75°提升到0.25°，时间分辨率从3小时提升到1小时

Conclusion: 该模型能有效提高气溶胶光学厚度的时空分辨率，为环境政策和公共卫生干预提供更精确的数据支持

Abstract: Accurate estimation of Aerosol Optical Depth (AOD) is crucial for understanding climate change and its impacts on public health, as aerosols are a measure of air quality conditions. AOD is usually retrieved from satellite imagery at coarse spatial and temporal resolutions. However, producing high-resolution AOD estimates in both space and time can better support evidence-based policies and interventions. We propose a spatio-temporal disaggregation model that assumes a latent spatio--temporal continuous Gaussian process observed through aggregated measurements. The model links discrete observations to the continuous domain and accommodates covariates to improve explanatory power and interpretability. The approach employs Gaussian processes with separable or non-separable covariance structures derived from a diffusion-based spatio-temporal stochastic partial differential equation (SPDE). Bayesian inference is conducted using the INLA-SPDE framework for computational efficiency. Simulation studies and an application to nowcasting AOD at 550 nm in India demonstrate the model's effectiveness, improving spatial resolution from 0.75° to 0.25° and temporal resolution from 3 hours to 1 hour.

</details>


### [107] [Bayesian Predictive Probabilities for Online Experimentation](https://arxiv.org/abs/2511.06320)
*Abbas Zaidi,Rina Friedberg,Samir Khan,Yao-Yang Leow,Maulik Soneji,Houssam Nassif,Richard Mudd*

Main category: stat.AP

TL;DR: 提出基于贝叶斯预测概率的系统，用于在线A/B测试中的中期分析，避免传统peeking方法导致的统计错误，并在Instagram实验平台上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 在线随机对照实验(A/B测试)的广泛使用导致容量限制，用户倾向于使用ad-hoc的peeking方法来优化有限资源，但这容易产生统计错误(如膨胀的I类错误)且与实验最终结果不一致。

Method: 引入基于贝叶斯预测概率的系统，无需数值积分技术即可估计预测概率，并推荐系统设计来研究其在大规模部署中的特性。

Result: 在Instagram的实验数据上验证了该方法的实际效益，能够在不损害实验保真度的情况下进行中期分析。

Conclusion: 贝叶斯预测概率系统为在线实验平台提供了一种可靠的中期分析方法，解决了传统peeking方法的统计问题，具有实际应用价值。

Abstract: The widespread adoption of online randomized controlled experiments (A/B Tests) for decision-making has created ongoing capacity constraints which necessitate interim analyses. As a consequence, platform users are increasingly motivated to use ad-hoc means of optimizing limited resources via peeking. Such processes, however, are error prone and often misaligned with end-of-experiment outcomes (e.g., inflated type-I error). We introduce a system based on Bayesian Predictive Probabilities that enable us to perform interim analyses without compromising fidelity of the experiment; This idea has been widely utilized in applications outside of the technology domain to more efficiently make decisions in experiments. Motivated by at-scale deployment within an experimentation platform, we demonstrate how predictive probabilities can be estimated without numerical integration techniques and recommend systems to study its properties at scale as an ongoing health check, along with system design recommendations - all on experiment data from Instagram - to demonstrate practical benefits that it enables.

</details>


### [108] [An Algebraic Approach to Evolutionary Accumulation Models](https://arxiv.org/abs/2511.06999)
*Jessica Renz,Frederik Witt,Iain G. Johnston*

Main category: stat.AP

TL;DR: 提出了一种基于代数方法的进化累积建模（EvAM），该方法与传统的优化推断方法互补，利用进化过程的多项式结构来定义与数据一致的候选参数集合，然后进行似然最大化。


<details>
  <summary>Details</summary>
Motivation: 进化累积建模关注学习和预测进化特征随时间累积的顺序。传统方法主要基于优化推断，本文旨在提供一种代数方法作为补充，利用进化过程的多项式结构来增强模型的可解释性和信息量。

Method: 首先利用进化过程的自然多项式结构定义与给定数据集一致的候选参数半代数集合，然后在该集合上最大化似然函数。通过具体示例验证了该方法与多种统计进化累积模型的兼容性。

Result: 该方法与各种统计进化累积模型的解是兼容的，并且能够提供相对于这些模型的额外信息。

Conclusion: 代数方法为进化累积建模提供了一个有价值的补充框架，能够利用多项式结构增强模型的可解释性，并提供传统优化方法之外的额外信息。

Abstract: We present an algebraic approach to evolutionary accumulation modelling (EvAM). EvAM is concerned with learning and predicting the order in which evolutionary features accumulate over time. Our approach is complementary to the more common optimisation-based inference methods used in this field. Namely, we first use the natural underlying polynomial structure of the evolutionary process to define a semi-algebraic set of candidate parameters consistent with a given data set before maximising the likelihood function. We consider explicit examples and show that this approach is compatible with the solutions given by various statistical evolutionary accumulation models. Furthermore, we discuss the additional information of our algebraic model relative to these models.

</details>


### [109] [Multilevel non-linear interrupted time series analysis](https://arxiv.org/abs/2511.05725)
*RJ Waken,Fengxian Wang,Sarah A. Eisenstein,Tim McBride,Kim Johnson,Karen Joynt-Maddox*

Main category: stat.AP

TL;DR: 该研究提出了一种结合广义加性模型和贝叶斯多层次时间序列模型的分层模型选择方法，用于分析非线性中断效应，并在三个医疗应用案例中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时处理非线性中断效应、多层次结构和后分层需求，需要开发能够鼓励简约性、部分池化并包含有意义因果效应变异性的综合方法。

Method: 结合广义加性模型和贝叶斯多层次时间序列模型，引入分层模型选择先验，构建多层次结构的中断效应模型，支持后分层分析。

Result: 在三个医疗应用案例中成功验证了方法的有效性：PSA检测对前列腺癌诊断率的影响、COVID-19对卒中住院率的影响、以及密苏里州医疗补助扩展对支付方式的影响。

Conclusion: 提出的多层次模型选择方法能够有效表征中断效应，鼓励简约性和部分池化，同时捕捉不同亚群体间的因果效应变异性，为中断时间序列分析提供了灵活强大的工具。

Abstract: Recent advances in interrupted time series analysis permit characterization of a typical non-linear interruption effect through use of generalized additive models. Concurrently, advances in latent time series modeling allow efficient Bayesian multilevel time series models. We propose to combine these concepts with a hierarchical model selection prior to characterize interruption effects with a multilevel structure, encouraging parsimony and partial pooling while incorporating meaningful variability in causal effects across subpopulations of interest, while allowing poststratification. These models are demonstrated with three applications: 1) the effect of the introduction of the prostate specific antigen test on prostate cancer diagnosis rates by race and age group, 2) the change in stroke or trans-ischemic attack hospitalization rates across Medicare beneficiaries by rurality in the months after the start of the COVID-19 pandemic, and 3) the effect of Medicaid expansion in Missouri on the proportion of inpatient hospitalizations discharged with Medicaid as a primary payer by key age groupings and sex.

</details>


### [110] [Conservative Software Reliability Assessments Using Collections of Bayesian Inference Problems](https://arxiv.org/abs/2511.07038)
*Kizito Salako,Rabiu Tsoho Muhammad*

Main category: stat.AP

TL;DR: 本文研究贝叶斯推理在保守软件可靠性评估中的应用，通过伯努利过程建模软件故障，确定最坏情况下的后验预测概率，并推导其渐近性质和先验分布。


<details>
  <summary>Details</summary>
Motivation: 在支持保守软件可靠性评估时，需要从贝叶斯推理问题集合中确定最坏情况的后验预测概率，以评估软件的安全性。

Method: 使用伯努利过程建模软件故障，从贝叶斯推理问题集合中明确确定最坏情况下的后验预测概率，并推导其渐近性质。

Result: 得出了保守后验概率及其先验的渐近性质，展示了如何在安全关键软件评估中使用这些结果。

Conclusion: 这项工作扩展了鲁棒贝叶斯推理结果和所谓的保守贝叶斯推理方法。

Abstract: When using Bayesian inference to support conservative software reliability assessments, it is useful to consider a collection of Bayesian inference problems, with the aim of determining the worst-case value (from this collection) for a posterior predictive probability that characterizes how reliable the software is. Using a Bernoulli process to model the occurrence of software failures, we explicitly determine (from collections of Bayesian inference problems) worst-case posterior predictive probabilities of the software operating without failure in the future. We deduce asymptotic properties of these conservative posterior probabilities and their priors, and illustrate how to use these results in assessments of safety-critical software. This work extends robust Bayesian inference results and so-called conservative Bayesian inference methods.

</details>


### [111] [Bayesian compartmental modelling of MRSA transmission within hospitals in Edmonton, Canada](https://arxiv.org/abs/2511.07353)
*Ruoyu Li,Rob Deardon,Na Li,John Conly,Jenine Leal*

Main category: stat.AP

TL;DR: 开发了一个独特的隔室模型来研究医院中MRSA传播模式，使用贝叶斯推断和MCMC算法估计参数，并创建了多个关于MRSA来源假设的子模型。


<details>
  <summary>Details</summary>
Motivation: 先前流行病学研究主要关注MRSA传播，但很少有研究同时考察医院获得性MRSA和社区获得性MRSA对医院内传播的影响。

Method: 构建包含易感个体、HA-MRSA/CA-MRSA定植或感染患者、隔离患者的隔室模型，使用贝叶斯推断和MCMC算法估计参数，开发多个关于MRSA来源假设的子模型。

Result: 估计了医院内传播率参数，通过MCMC算法获得了完整模型参数的后验均值。

Conclusion: 该研究提供了一个综合分析医院和社区来源MRSA传播的建模框架，有助于更好地理解MRSA在医院环境中的传播动态。

Abstract: Methicillin-resistant Staphylococcus aureus (MRSA) is a bacterium that leads to severe infections in hospitalized patients. Previous epidemiological research has focused on MRSA transmission, but few studies have examined the influence of both hospital-acquired MRSA (HA-MRSA) and community-acquired MRSA (CA-MRSA) on MRSA spread in hospitals. In this study, we present a unique compartmental model for studying MRSA transmission patterns in hospitals in Edmonton, Alberta. The model consists of susceptible individuals, patients who have been colonized or infected with HA-MRSA or CA-MRSA, and isolated patients. We first use Bayesian inference with Markov chain Monte Carlo (MCMC) algorithms to estimate the posterior mean of parameters in the full model using data from hospitals in Edmonton. Then we develop multiple sub-models with varying assumptions about the origin of new MRSA colonization. We also estimate transmission rates in hospitals.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [112] [The Breadth Premium: Measuring the Firm-level Impact of CEO Career Breadth](https://arxiv.org/abs/2511.05515)
*T. Alexander Puutio*

Main category: q-fin.GN

TL;DR: 研究发现CEO的跨领域经验广度与企业绩效正相关，广度指数每增加1点对应1.8%的超额回报增长


<details>
  <summary>Details</summary>
Motivation: 现有职业和教育系统奖励早期专业化，但可能限制在复杂快速变化环境中的适应能力，研究探索跨领域经验是否提升高管表现

Method: 使用650位CEO的原创数据集构建广度指数，涵盖跨领域教育和职业广度，进行回归分析

Result: 高广度CEO领导的公司三年内平均比行业同行表现好9.8个百分点，广度指数每增加1点对应1.8点异常回报增长

Conclusion: 领导力广度（跨职能、学科和部门的经验）与企业绩效正相关，在专业化加深时，横向洞察力的边际价值上升

Abstract: Prevailing career and education systems continue to reward early specialization and deep expertise within narrow domains. While such depth promotes efficiency, it may also limit adaptability in complex and rapidly changing environments. Building on research showing that variability in training inputs enhances learning outcomes across cognitive and behavioral domains, this study explores whether the same principle applies to executive performance.
  Using an original dataset of 650 CEOs leading firms that together represent roughly 85% of US market capitalization, we construct a composite Breadth Index capturing cross-domain educational and professional breadth. Preliminary analyses reveal that firms led by higher-breadth CEOs outperform their industry peers by an average of 9.8 percentage points over a three-year window. Regression results indicate that each one-point increase on the five-point Range Index corresponds to a 1.8-point gain in abnormal returns (p < 0.03), with effects remaining robust across industries, firm sizes, and CEO age groups.
  These early findings suggest that leadership breadth, defined as experience spanning multiple functions, disciplines, and sectors, is positively associated with firm-level performance. While the dataset remains under validation, the pattern observed supports the emerging view that as specialization deepens, the marginal value of lateral insight rises. Breadth, in this light, functions as a form of adaptive capital; it enhances leaders' capacity for integrative reasoning, organizational translation, and strategic flexibility in uncertain environments.

</details>


### [113] [Personalized Chain-of-Thought Summarization of Financial News for Investor Decision Support](https://arxiv.org/abs/2511.05508)
*Tianyi Zhang,Mu Chen*

Main category: q-fin.GN

TL;DR: 提出了一种基于思维链的金融新闻摘要框架，通过用户指定关键词生成个性化的事件驱动摘要，帮助过滤噪音并突出关键市场信号。


<details>
  <summary>Details</summary>
Motivation: 金融顾问和投资者面临金融新闻信息过载问题，无关内容和噪音掩盖了关键市场信号，阻碍了及时的投资决策。

Method: 采用思维链摘要框架，整合用户指定关键词生成个性化输出，确保仅突出最相关的内容，为语言模型提供中间层支持。

Result: 框架能够将原始新闻转化为简洁的事件驱动摘要，提供投资者关注的叙述性内容。

Conclusion: 该个性化摘要框架在原始新闻和可操作见解之间搭建了桥梁，支持更有效的投资决策。

Abstract: Financial advisors and investors struggle with information overload from financial news, where irrelevant content and noise obscure key market signals and hinder timely investment decisions. To address this, we propose a novel Chain-of-Thought (CoT) summarization framework that condenses financial news into concise, event-driven summaries. The framework integrates user-specified keywords to generate personalized outputs, ensuring that only the most relevant contexts are highlighted. These personalized summaries provide an intermediate layer that supports language models in producing investor-focused narratives, bridging the gap between raw news and actionable insights.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [114] [Lite VLA: Efficient Vision-Language-Action Control on CPU-Bound Edge Robots](https://arxiv.org/abs/2511.05642)
*Justin Williams,Kishor Datta Gupta,Roy George,Mrinmoy Sarkar*

Main category: cs.RO

TL;DR: 在GPS拒止环境中部署小型视觉语言模型实现移动机器人的实时场景理解和推理


<details>
  <summary>Details</summary>
Motivation: 在GPS拒止环境中，自主机器人需要本地、资源高效的计算能力，而现有方法将感知与移动分离，无法在动态环境中同时进行移动和推理

Method: 提出集成紧凑视觉语言模型与多模态感知的框架，在嵌入式硬件上直接执行上下文解释，消除对云连接的依赖

Result: 实验验证了计算效率、任务准确性和系统响应性之间的平衡，在移动机器人上成功部署小型VLMs实现并发推理和移动

Conclusion: 为服务机器人、灾难响应和国防操作等应用中的可扩展、可靠自主性奠定了基础

Abstract: The deployment of artificial intelligence models at the edge is increasingly critical for autonomous robots operating in GPS-denied environments where local, resource-efficient reasoning is essential. This work demonstrates the feasibility of deploying small Vision-Language Models (VLMs) on mobile robots to achieve real-time scene understanding and reasoning under strict computational constraints. Unlike prior approaches that separate perception from mobility, the proposed framework enables simultaneous movement and reasoning in dynamic environments using only on-board hardware. The system integrates a compact VLM with multimodal perception to perform contextual interpretation directly on embedded hardware, eliminating reliance on cloud connectivity. Experimental validation highlights the balance between computational efficiency, task accuracy, and system responsiveness. Implementation on a mobile robot confirms one of the first successful deployments of small VLMs for concurrent reasoning and mobility at the edge. This work establishes a foundation for scalable, assured autonomy in applications such as service robotics, disaster response, and defense operations.

</details>


### [115] [VLM-driven Skill Selection for Robotic Assembly Tasks](https://arxiv.org/abs/2511.05680)
*Jeong-Jung Kim,Doo-Yeol Koh,Chang-Hyun Kim*

Main category: cs.RO

TL;DR: 结合视觉语言模型与模仿学习的机器人装配框架，通过视觉感知、自然语言理解和基础技能实现灵活的自适应装配操作


<details>
  <summary>Details</summary>
Motivation: 开发能够理解自然语言指令并执行复杂装配任务的机器人系统，提高机器人在装配场景中的适应性和灵活性

Method: 使用配备夹爪的机器人在3D空间中移动执行装配操作，集成视觉感知、自然语言理解和学习的基础技能

Result: 在装配场景中取得高成功率，同时通过结构化的基础技能分解保持可解释性

Conclusion: 该框架有效结合了视觉语言模型和模仿学习，为机器人装配任务提供了一种灵活且可解释的解决方案

Abstract: This paper presents a robotic assembly framework that combines Vision-Language Models (VLMs) with imitation learning for assembly manipulation tasks. Our system employs a gripper-equipped robot that moves in 3D space to perform assembly operations. The framework integrates visual perception, natural language understanding, and learned primitive skills to enable flexible and adaptive robotic manipulation. Experimental results demonstrate the effectiveness of our approach in assembly scenarios, achieving high success rates while maintaining interpretability through the structured primitive skill decomposition.

</details>


### [116] [TumorMap: A Laser-based Surgical Platform for 3D Tumor Mapping and Fully-Automated Tumor Resection](https://arxiv.org/abs/2511.05723)
*Guangshen Ma,Ravi Prakash,Beatrice Schleupner,Jeffrey Everitt,Arpit Mishra,Junqin Chen,Brian Mann,Boyuan Chen,Leila Bridgeman,Pei Zhong,Mark Draelos,William C. Eward,Patrick J. Codd*

Main category: cs.RO

TL;DR: TumorMap是一个手术机器人平台，通过集成三种激光（光学相干断层扫描、激光诱导内源性荧光和切割激光手术刀）结合深度学习模型，实现术中3D肿瘤边界重建和自主组织切除。


<details>
  <summary>Details</summary>
Motivation: 解决恶性肿瘤手术中缺乏高保真肿瘤重建、难以开发通用组织模型处理肿瘤诊断复杂性，以及手术中双手操作、生理震颤和疲劳等物理限制的挑战。

Method: 集成三激光机制（光学相干断层扫描用于成像、激光诱导内源性荧光用于诊断、切割激光手术刀用于切除）结合深度学习模型，实现全自动非接触式肿瘤切除。

Result: 在鼠骨肉瘤和软组织肉瘤模型中验证，建立了新的组织病理学工作流程评估传感器性能，实现了亚毫米级激光切除精度的多模态传感器引导自主肿瘤手术。

Conclusion: TumorMap平台能够实现无需人工干预的多模态传感器引导自主肿瘤手术，具有亚毫米级切除精度。

Abstract: Surgical resection of malignant solid tumors is critically dependent on the surgeon's ability to accurately identify pathological tissue and remove the tumor while preserving surrounding healthy structures. However, building an intraoperative 3D tumor model for subsequent removal faces major challenges due to the lack of high-fidelity tumor reconstruction, difficulties in developing generalized tissue models to handle the inherent complexities of tumor diagnosis, and the natural physical limitations of bimanual operation, physiologic tremor, and fatigue creep during surgery. To overcome these challenges, we introduce "TumorMap", a surgical robotic platform to formulate intraoperative 3D tumor boundaries and achieve autonomous tissue resection using a set of multifunctional lasers. TumorMap integrates a three-laser mechanism (optical coherence tomography, laser-induced endogenous fluorescence, and cutting laser scalpel) combined with deep learning models to achieve fully-automated and noncontact tumor resection. We validated TumorMap in murine osteoscarcoma and soft-tissue sarcoma tumor models, and established a novel histopathological workflow to estimate sensor performance. With submillimeter laser resection accuracy, we demonstrated multimodal sensor-guided autonomous tumor surgery without any human intervention.

</details>


### [117] [A Unified Stochastic Mechanism Underlying Collective Behavior in Ants, Physical Systems, and Robotic Swarms](https://arxiv.org/abs/2511.05785)
*Lianhao Yin,Haiping Yu,Pascal Spino,Daniela Rus*

Main category: cs.RO

TL;DR: 本文提出了一个统一随机模型，将生物、物理和机器人群体联系起来，揭示了在能量函数约束下最大化的共享统计机制。


<details>
  <summary>Details</summary>
Motivation: 生物群体（如蚁群）通过分散式随机行为实现集体目标，而物理系统（气体、液体、固体）中的粒子随机运动受熵最大化支配，但没有集体目标。目前缺乏解释这两类系统随机行为的统一框架。

Method: 通过Formica polyctena蚂蚁的实证证据，发现在不同能量函数约束下的最大化共享统计机制，并开发了遵循此原理的机器人群体。

Result: 机器人群体能够表现出可扩展的分散合作，模仿物理相变行为，且个体计算需求最小。

Conclusion: 建立了一个连接生物、物理和机器人群体的统一随机模型，为设计稳健智能的群体机器人提供了可扩展原则。

Abstract: Biological swarms, such as ant colonies, achieve collective goals through decentralized and stochastic individual behaviors. Similarly, physical systems composed of gases, liquids, and solids exhibit random particle motion governed by entropy maximization, yet do not achieve collective objectives. Despite this analogy, no unified framework exists to explain the stochastic behavior in both biological and physical systems. Here, we present empirical evidence from \textit{Formica polyctena} ants that reveals a shared statistical mechanism underlying both systems: maximization under different energy function constraints. We further demonstrate that robotic swarms governed by this principle can exhibit scalable, decentralized cooperation, mimicking physical phase-like behaviors with minimal individual computation. These findings established a unified stochastic model linking biological, physical, and robotic swarms, offering a scalable principle for designing robust and intelligent swarm robotics.

</details>


### [118] [VLAD-Grasp: Zero-shot Grasp Detection via Vision-Language Models](https://arxiv.org/abs/2511.05791)
*Manav Kulshrestha,S. Talha Bukhari,Damon Conover,Aniket Bera*

Main category: cs.RO

TL;DR: VLAD-Grasp是一个零样本抓取检测方法，利用视觉语言模型生成目标图像，通过深度预测和点云对齐来恢复可执行的抓取姿态，无需训练或专家标注。


<details>
  <summary>Details</summary>
Motivation: 现有机器人抓取方法依赖大规模专家标注，需要重新训练来处理新物体，限制了泛化能力。

Method: 从单张RGB-D图像出发：(1)使用大视觉语言模型生成目标图像，其中直杆"刺穿"物体表示对握抓取；(2)预测深度和分割将生成图像提升到3D；(3)通过主成分分析和无对应优化对齐生成和观测点云，恢复可执行抓取姿态。

Result: 在Cornell和Jacquard数据集上，性能与最先进的监督模型相当或更优，并在真实世界新物体上展示了零样本泛化能力。

Conclusion: 视觉语言基础模型可作为机器人操作的强大先验，VLAD-Grasp证明了无需训练即可实现竞争性抓取性能。

Abstract: Robotic grasping is a fundamental capability for autonomous manipulation; however, most existing methods rely on large-scale expert annotations and necessitate retraining to handle new objects. We present VLAD-Grasp, a Vision-Language model Assisted zero-shot approach for Detecting grasps. From a single RGB-D image, our method (1) prompts a large vision-language model to generate a goal image where a straight rod "impales" the object, representing an antipodal grasp, (2) predicts depth and segmentation to lift this generated image into 3D, and (3) aligns generated and observed object point clouds via principal component analysis and correspondence-free optimization to recover an executable grasp pose. Unlike prior work, our approach is training-free and does not rely on curated grasp datasets. Despite this, VLAD-Grasp achieves performance that is competitive with or superior to that of state-of-the-art supervised models on the Cornell and Jacquard datasets. We further demonstrate zero-shot generalization to novel real-world objects on a Franka Research 3 robot, highlighting vision-language foundation models as powerful priors for robotic manipulation.

</details>


### [119] [An Open-Source, Reproducible Tensegrity Robot that can Navigate Among Obstacles](https://arxiv.org/abs/2511.05798)
*William R. Johnson,Patrick Meng,Nelson Chen,Luca Cimatti,Augustin Vercoutere,Mridul Aanjaneya,Rebecca Kramer-Bottiglio,Kostas E. Bekris*

Main category: cs.RO

TL;DR: 提出了一个完整的开源3杆张拉整体机器人导航系统，包括硬件设计和软件堆栈，能在已知障碍物环境中实现路径规划和避障。


<details>
  <summary>Details</summary>
Motivation: 张拉整体机器人具有抗冲击、低质量和适应非结构化地形的优点，但其复杂的耦合动力学给建模和控制带来了挑战，阻碍了路径规划和避障能力的发展。

Method: 开发了完整的开源系统，包括：(i)低成本开源硬件设计；(ii)集成开源软件堆栈，涵盖物理建模、系统辨识、状态估计、路径规划和控制。

Result: 系统能够跟踪机器人位姿并执行无碰撞路径规划，在未建模环境挑战（如垂直跌落、斜坡和颗粒介质）中表现出鲁棒性，并在两个不同实验室验证了可重现性。

Conclusion: 为机器人社区提供了一个完整的柔性、抗冲击、形状可变机器人的导航系统，可作为推进其他非常规机器人平台导航能力的跳板。

Abstract: Tensegrity robots, composed of rigid struts and elastic tendons, provide impact resistance, low mass, and adaptability to unstructured terrain. Their compliance and complex, coupled dynamics, however, present modeling and control challenges, hindering path planning and obstacle avoidance. This paper presents a complete, open-source, and reproducible system that enables navigation for a 3-bar tensegrity robot. The system comprises: (i) an inexpensive, open-source hardware design, and (ii) an integrated, open-source software stack for physics-based modeling, system identification, state estimation, path planning, and control. All hardware and software are publicly available at https://sites.google.com/view/tensegrity-navigation/. The proposed system tracks the robot's pose and executes collision-free paths to a specified goal among known obstacle locations. System robustness is demonstrated through experiments involving unmodeled environmental challenges, including a vertical drop, an incline, and granular media, culminating in an outdoor field demonstration. To validate reproducibility, experiments were conducted using robot instances at two different laboratories. This work provides the robotics community with a complete navigation system for a compliant, impact-resistant, and shape-morphing robot. This system is intended to serve as a springboard for advancing the navigation capabilities of other unconventional robotic platforms.

</details>


### [120] [Adversarial Game-Theoretic Algorithm for Dexterous Grasp Synthesis](https://arxiv.org/abs/2511.05809)
*Yu Chen,Botao He,Yuemin Mao,Arthur Jakobsson,Jeffrey Ke,Yiannis Aloimonos,Guanya Shi,Howie Choset,Jiayuan Mao,Jeffrey Ichnowski*

Main category: cs.RO

TL;DR: 提出了一种基于双玩家博弈的多指机器人抓取合成方法，通过模拟对抗性物体运动来生成更稳定的抓取配置。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成抓取时通常只关注抵抗单一力矩，忽略了物体可能逃脱的对抗性运动，导致抓取不稳定和失败。

Method: 将抓取合成问题建模为双玩家博弈：一个玩家控制机器人生成可行抓取配置，另一个玩家对抗性地控制物体寻找逃脱路径。

Result: 模拟实验中成功率75.78%，比最先进基线提高19.61%；真实实验中ShadowHand成功率85.0%，LeapHand成功率87.5%；生成时间仅需0.28-1.04秒。

Conclusion: 双玩家博弈机制能显著提升抓取成功率，方法在真实机器人平台上具有可行性和有效性。

Abstract: For many complex tasks, multi-finger robot hands are poised to revolutionize how we interact with the world, but reliably grasping objects remains a significant challenge. We focus on the problem of synthesizing grasps for multi-finger robot hands that, given a target object's geometry and pose, computes a hand configuration. Existing approaches often struggle to produce reliable grasps that sufficiently constrain object motion, leading to instability under disturbances and failed grasps. A key reason is that during grasp generation, they typically focus on resisting a single wrench, while ignoring the object's potential for adversarial movements, such as escaping. We propose a new grasp-synthesis approach that explicitly captures and leverages the adversarial object motion in grasp generation by formulating the problem as a two-player game. One player controls the robot to generate feasible grasp configurations, while the other adversarially controls the object to seek motions that attempt to escape from the grasp. Simulation experiments on various robot platforms and target objects show that our approach achieves a success rate of 75.78%, up to 19.61% higher than the state-of-the-art baseline. The two-player game mechanism improves the grasping success rate by 27.40% over the method without the game formulation. Our approach requires only 0.28-1.04 seconds on average to generate a grasp configuration, depending on the robot platform, making it suitable for real-world deployment. In real-world experiments, our approach achieves an average success rate of 85.0% on ShadowHand and 87.5% on LeapHand, which confirms its feasibility and effectiveness in real robot setups.

</details>


### [121] [3D Mapping Using a Lightweight and Low-Power Monocular Camera Embedded inside a Gripper of Limbed Climbing Robots](https://arxiv.org/abs/2511.05816)
*Taku Okawara,Ryo Nishibe,Mao Kasano,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 提出了一种用于空间探索的3D地形测绘系统，使用配备单目手眼相机的有肢攀爬机器人，通过融合单目视觉约束和肢体前向运动学来解决尺度模糊问题。


<details>
  <summary>Details</summary>
Motivation: 传统攀爬机器人使用RGB-D相机进行3D地形测绘和抓取点检测，但RGB-D相机体积大、功耗高。单目相机更轻便、紧凑且功耗低，但存在尺度模糊问题。

Method: 提出基于因子图优化的SLAM方法，融合单目视觉约束和肢体前向运动学，联合估计时间序列的抓手姿态和3D地图的全局度量尺度。

Result: 通过物理仿真和真实实验验证，框架能够实时构建度量尺度的3D地形地图，并实现使用单目手眼相机自主抓取凸起地形表面。

Conclusion: 该方法为未来涉及有肢攀爬机器人的空间任务提供了可扩展且节能的感知解决方案，无需依赖RGB-D相机。

Abstract: Limbed climbing robots are designed to explore challenging vertical walls, such as the skylights of the Moon and Mars. In such robots, the primary role of a hand-eye camera is to accurately estimate 3D positions of graspable points (i.e., convex terrain surfaces) thanks to its close-up views. While conventional climbing robots often employ RGB-D cameras as hand-eye cameras to facilitate straightforward 3D terrain mapping and graspable point detection, RGB-D cameras are large and consume considerable power.
  This work presents a 3D terrain mapping system designed for space exploration using limbed climbing robots equipped with a monocular hand-eye camera. Compared to RGB-D cameras, monocular cameras are more lightweight, compact structures, and have lower power consumption. Although monocular SLAM can be used to construct 3D maps, it suffers from scale ambiguity. To address this limitation, we propose a SLAM method that fuses monocular visual constraints with limb forward kinematics. The proposed method jointly estimates time-series gripper poses and the global metric scale of the 3D map based on factor graph optimization.
  We validate the proposed framework through both physics-based simulations and real-world experiments. The results demonstrate that our framework constructs a metrically scaled 3D terrain map in real-time and enables autonomous grasping of convex terrain surfaces using a monocular hand-eye camera, without relying on RGB-D cameras. Our method contributes to scalable and energy-efficient perception for future space missions involving limbed climbing robots. See the video summary here: https://youtu.be/fMBrrVNKJfc

</details>


### [122] [Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills](https://arxiv.org/abs/2511.05855)
*Jiayu Zhou,Qiwei Wu,Jian Li,Zhe Chen,Xiaogang Xiong,Renjing Xu*

Main category: cs.RO

TL;DR: 提出了一种结合分层语义分解、强化学习、视觉语言模型和知识蒸馏的新框架，用于自主执行长时程、接触丰富的操作任务，无需昂贵的人类演示数据。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量真实世界数据和专家工程，存在成本和可扩展性问题。本文旨在克服这些限制，实现无需人类演示的长时程操作任务学习。

Method: 将复杂任务分解为原子技能，在模拟环境中用强化学习训练每个技能的策略，并加入力约束防止物体损坏。使用VLM进行高层任务分解和技能规划，生成多样化专家演示，然后通过视觉-触觉扩散策略蒸馏为统一策略。

Result: 通过全面的消融研究确定了最优的演示生成流程和模仿学习算法，在仿真实验和物理部署中验证了该方法能够学习长时程操作策略，且VLM引导的原子技能框架实现了对多样化任务的可扩展泛化。

Conclusion: 该框架成功实现了无需人类演示的长时程操作任务学习，VLM引导的原子技能分解为可扩展的通用化提供了有效途径。

Abstract: Autonomous execution of long-horizon, contact-rich manipulation tasks traditionally requires extensive real-world data and expert engineering, posing significant cost and scalability challenges. This paper proposes a novel framework integrating hierarchical semantic decomposition, reinforcement learning (RL), visual language models (VLMs), and knowledge distillation to overcome these limitations. Complex tasks are decomposed into atomic skills, with RL-trained policies for each primitive exclusively in simulation. Crucially, our RL formulation incorporates explicit force constraints to prevent object damage during delicate interactions. VLMs perform high-level task decomposition and skill planning, generating diverse expert demonstrations. These are distilled into a unified policy via Visual-Tactile Diffusion Policy for end-to-end execution. We conduct comprehensive ablation studies exploring different VLM-based task planners to identify optimal demonstration generation pipelines, and systematically compare imitation learning algorithms for skill distillation. Extensive simulation experiments and physical deployment validate that our approach achieves policy learning for long-horizon manipulation without costly human demonstrations, while the VLM-guided atomic skill framework enables scalable generalization to diverse tasks.

</details>


### [123] [ViTaMIn-B: A Reliable and Efficient Visuo-Tactile Bimanual Manipulation Interface](https://arxiv.org/abs/2511.05858)
*Chuanyu Li,Chaoyi Liu,Daotan Wang,Shuyu Zhang,Lusong Li,Zecui Zeng,Fangchen Liu,Jing Xu,Rui Chen*

Main category: cs.RO

TL;DR: ViTaMIn-B是一个用于双手操作任务的手持数据收集系统，包含新型柔性视觉触觉传感器DuoTact和基于Meta Quest控制器的6-DoF双手姿态跟踪方法，在复杂交互场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有手持设备系统缺乏强大的触觉感知和可靠的姿态跟踪能力，难以处理复杂的双手接触密集型任务。

Method: 设计DuoTact柔性视觉触觉传感器，通过重建传感器全局变形作为3D点云输入策略；开发基于Meta Quest控制器的6-DoF双手姿态获取流程，解决SLAM方法的轨迹漂移问题。

Result: 用户研究证实系统在初学者和专家操作员中都具有高效性和高可用性；在四个双手操作任务上的实验显示其优于现有系统的任务性能。

Conclusion: ViTaMIn-B系统为复杂双手接触密集型任务提供了更强大、更高效的数据收集解决方案。

Abstract: Handheld devices have opened up unprecedented opportunities to collect large-scale, high-quality demonstrations efficiently. However, existing systems often lack robust tactile sensing or reliable pose tracking to handle complex interaction scenarios, especially for bimanual and contact-rich tasks. In this work, we propose ViTaMIn-B, a more capable and efficient handheld data collection system for such tasks. We first design DuoTact, a novel compliant visuo-tactile sensor built with a flexible frame to withstand large contact forces during manipulation while capturing high-resolution contact geometry. To enhance the cross-sensor generalizability, we propose reconstructing the sensor's global deformation as a 3D point cloud and using it as the policy input. We further develop a robust, unified 6-DoF bimanual pose acquisition process using Meta Quest controllers, which eliminates the trajectory drift issue in common SLAM-based methods. Comprehensive user studies confirm the efficiency and high usability of ViTaMIn-B among novice and expert operators. Furthermore, experiments on four bimanual manipulation tasks demonstrate its superior task performance relative to existing systems.

</details>


### [124] [Fair and Safe: A Real-Time Hierarchical Control Framework for Intersections](https://arxiv.org/abs/2511.05886)
*Lei Shi,Yongju Kim,Xinzhi Zhong,Wissam Kontar,Qichao Liu,Soyoung Ahn*

Main category: cs.RO

TL;DR: 提出一个公平感知的分层控制框架，将不公平厌恶明确集成到交叉口管理中，实现公平、安全、高效的自动驾驶车辆协调。


<details>
  <summary>Details</summary>
Motivation: 确保自动驾驶车辆在交叉口协调中的公平性对于公平访问、社会接受度和长期系统效率至关重要，但在安全关键的实时交通控制中仍未被充分探索。

Method: 采用分层控制框架：顶层集中分配模块通过最大化考虑等待时间、紧急程度、控制历史和速度偏差的效用来分配控制权；底层授权车辆使用LQR执行预计算轨迹，并应用基于高阶控制屏障函数的安全过滤器进行实时碰撞避免。

Result: 在不同交通需求和需求分布下的仿真结果表明，该框架实现了近乎完美的公平性，消除了碰撞，减少了平均延迟，并保持了实时可行性。

Conclusion: 公平性可以系统地融入而不牺牲安全性或性能，为未来自主交通系统实现可扩展和公平的协调。

Abstract: Ensuring fairness in the coordination of connected and automated vehicles at intersections is essential for equitable access, social acceptance, and long-term system efficiency, yet it remains underexplored in safety-critical, real-time traffic control. This paper proposes a fairness-aware hierarchical control framework that explicitly integrates inequity aversion into intersection management. At the top layer, a centralized allocation module assigns control authority (i.e., selects a single vehicle to execute its trajectory) by maximizing a utility that accounts for waiting time, urgency, control history, and velocity deviation. At the bottom layer, the authorized vehicle executes a precomputed trajectory using a Linear Quadratic Regulator (LQR) and applies a high-order Control Barrier Function (HOCBF)-based safety filter for real-time collision avoidance. Simulation results across varying traffic demands and demand distributions demonstrate that the proposed framework achieves near-perfect fairness, eliminates collisions, reduces average delay, and maintains real-time feasibility. These results highlight that fairness can be systematically incorporated without sacrificing safety or performance, enabling scalable and equitable coordination for future autonomous traffic systems.

</details>


### [125] [From Words to Safety: Language-Conditioned Safety Filtering for Robot Navigation](https://arxiv.org/abs/2511.05889)
*Zeyuan Feng,Haimingyue Zhang,Somil Bansal*

Main category: cs.RO

TL;DR: 提出了一种用于机器人导航的语言条件安全框架，通过LLM将自然语言指令转换为结构化安全规范，结合感知模块和MPC安全过滤器实时执行语义和几何约束。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在开放世界和以人为中心环境中的集成度提高，需要能够解释自然语言指令并遵守安全约束的能力，现有方法在安全规范映射和约束类别覆盖方面存在局限。

Method: 采用模块化框架：LLM模块翻译自由格式指令为结构化安全规范，感知模块通过对象级3D表示对环境进行建模，MPC安全过滤器实时执行语义和几何约束。

Result: 通过仿真和硬件实验验证，证明该框架能够稳健地解释和执行各种语言指定的约束，适用于广泛的环境和场景。

Conclusion: 该框架为机器人导航提供了强大的语言条件安全能力，能够处理多样化的约束类型，提高了在复杂环境中的鲁棒性和适用性。

Abstract: As robots become increasingly integrated into open-world, human-centered environments, their ability to interpret natural language instructions and adhere to safety constraints is critical for effective and trustworthy interaction. Existing approaches often focus on mapping language to reward functions instead of safety specifications or address only narrow constraint classes (e.g., obstacle avoidance), limiting their robustness and applicability. We propose a modular framework for language-conditioned safety in robot navigation. Our framework is composed of three core components: (1) a large language model (LLM)-based module that translates free-form instructions into structured safety specifications, (2) a perception module that grounds these specifications by maintaining object-level 3D representations of the environment, and (3) a model predictive control (MPC)-based safety filter that enforces both semantic and geometric constraints in real time. We evaluate the effectiveness of the proposed framework through both simulation studies and hardware experiments, demonstrating that it robustly interprets and enforces diverse language-specified constraints across a wide range of environments and scenarios.

</details>


### [126] [10 Open Challenges Steering the Future of Vision-Language-Action Models](https://arxiv.org/abs/2511.05936)
*Soujanya Poria,Navonil Majumder,Chia-Yu Hung,Amir Ali Bagherzadeh,Chuan Li,Kenneth Kwok,Ziwei Wang,Cheston Tan,Jiajun Wu,David Hsu*

Main category: cs.RO

TL;DR: 本文讨论了视觉-语言-动作模型发展的10个关键里程碑和新兴趋势，旨在推动VLA模型更广泛的应用。


<details>
  <summary>Details</summary>
Motivation: 随着VLA模型在具身AI领域的日益普及，需要系统梳理其发展路径和关键挑战，以加速其发展。

Method: 通过识别和讨论10个主要里程碑（多模态、推理、数据、评估等）和4个新兴趋势（空间理解、世界动态建模等）来分析VLA模型的发展。

Result: 提出了VLA模型发展的系统性框架，明确了关键研究方向和挑战。

Conclusion: 通过关注这些研究路径，可以加速VLA模型的发展，使其获得更广泛的接受和应用。

Abstract: Due to their ability of follow natural language instructions, vision-language-action (VLA) models are increasingly prevalent in the embodied AI arena, following the widespread success of their precursors -- LLMs and VLMs. In this paper, we discuss 10 principal milestones in the ongoing development of VLA models -- multimodality, reasoning, data, evaluation, cross-robot action generalization, efficiency, whole-body coordination, safety, agents, and coordination with humans. Furthermore, we discuss the emerging trends of using spatial understanding, modeling world dynamics, post training, and data synthesis -- all aiming to reach these milestones. Through these discussions, we hope to bring attention to the research avenues that may accelerate the development of VLA models into wider acceptability.

</details>


### [127] [Robustness study of the bio-inspired musculoskeletal arm robot based on the data-driven iterative learning algorithm](https://arxiv.org/abs/2511.05995)
*Jianbo Yuan,Jing Dai,Yerui Fan,Yaxiong Wu,Yunpeng Liang,Weixin Yan*

Main category: cs.RO

TL;DR: 开发了一种轻量化肌腱驱动肌肉骨骼手臂（LTDM-Arm），具有7自由度关节系统和15个执行器的模块化人工肌肉系统，采用Hilly型肌肉模型和数据驱动迭代学习控制，在仿真和实验中验证了其抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 人类手臂具有爆发力、精确性、灵巧性、顺应性和鲁棒性等卓越能力，开发具有肌肉骨骼结构的人形机器人系统一直是研究重点。

Method: 设计了7自由度骨骼关节系统和模块化人工肌肉系统（15个执行器），采用Hilly型肌肉模型和数据驱动迭代学习控制（DDILC）来学习和优化重复任务的激活信号。

Result: LTDM-Arm系统能有效实现期望轨迹跟踪任务，在仿真中可承受20%负载扰动，实验中可承受15%负载扰动，验证了肌肉骨骼系统的抗干扰能力。

Conclusion: 这项研究为开发具有人类操作性能的先进机器人系统奠定了基础。

Abstract: The human arm exhibits remarkable capabilities, including both explosive power and precision, which demonstrate dexterity, compliance, and robustness in unstructured environments. Developing robotic systems that emulate human-like operational characteristics through musculoskeletal structures has long been a research focus. In this study, we designed a novel lightweight tendon-driven musculoskeletal arm (LTDM-Arm), featuring a seven degree-of-freedom (DOF) skeletal joint system and a modularized artificial muscular system (MAMS) with 15 actuators. Additionally, we employed a Hilly-type muscle model and data-driven iterative learning control (DDILC) to learn and refine activation signals for repetitive tasks within a finite time frame. We validated the anti-interference capabilities of the musculoskeletal system through both simulations and experiments. The results show that the LTDM-Arm system can effectively achieve desired trajectory tracking tasks, even under load disturbances of 20 % in simulation and 15 % in experiments. This research lays the foundation for developing advanced robotic systems with human-like operational performance.

</details>


### [128] [Development and testing of novel soft sleeve actuators](https://arxiv.org/abs/2511.06102)
*Mohammed Abboodi*

Main category: cs.RO

TL;DR: 本文提出了一种柔软套筒驱动架构，用于制造紧凑、用户中心的辅助技术设备，通过定制化的熔融长丝制造工艺制造热塑性弹性体驱动器，实现线性、弯曲和扭转运动。


<details>
  <summary>Details</summary>
Motivation: 老龄化人口和神经肌肉骨骼疾病患病率上升增加了对有效、舒适且解剖学兼容的可穿戴移动辅助设备的需求。现有系统使用刚性机制和笨重接口，阻碍了力传递并降低了可穿戴性。

Method: 开发了三种柔软套筒驱动器（线性、弯曲、扭转）和一个结合这些运动的全方位设计；使用定制化熔融长丝制造工艺制造气密且柔顺的结构；通过专用实验平台量化运动学和动力学输出。

Result: 结果显示可重现的多轴运动，改善了向肢体的力传递，减少了对复杂附着硬件的需求。

Conclusion: 该工作建立了一个统一且可制造的柔软套筒驱动框架，实现了具有增强运动学和动力学性能的紧凑型用户中心辅助技术。

Abstract: Aging populations and the rising prevalence of neurological and musculoskeletal disorders increase the demand for wearable mobility assistive devices that are effective, comfortable, and anatomically compatible. Many existing systems use rigid mechanisms and bulky interfaces that impede force transmission and reduce wearability. This study introduces a soft sleeve actuation architecture that conforms to the limb while transmitting forces and moments efficiently. We develop three soft sleeve actuators that produce linear, bending, and twisting motion, and an omnidirectional design that combines these motions in one device. Actuators are fabricated from thermoplastic elastomers using a customized fused filament fabrication process that produces airtight and compliant structures and resolves leakage observed with conventional methods. A dedicated experimental platform quantifies kinematic outputs such as displacement, angle, and twist, and kinetic outputs such as force and torque under low pneumatic pressures. A parametric study varies geometric features and material properties to determine their influence on performance. Results show reproducible multi axis motion with improved transfer of force to the limb and reduced need for complex attachment hardware. The work establishes a unified and manufacturable framework for soft sleeve actuation that enables compact and user centered assistive technologies with enhanced kinematic and kinetic performance.

</details>


### [129] [PlaCo: a QP-based robot planning and control framework](https://arxiv.org/abs/2511.06141)
*Marc Duclusaud,Grégoire Passault,Vincent Padois,Olivier Ly*

Main category: cs.RO

TL;DR: PlaCo是一个用于机器人系统QP规划和控制的软件框架，提供高层接口简化问题构建和求解


<details>
  <summary>Details</summary>
Motivation: 简化机器人系统中基于二次规划的规划和控制问题的数学公式化过程，让用户能够以模块化和直观的方式指定任务和约束

Method: 提供高层接口抽象QP问题的底层数学公式，支持Python绑定用于快速原型开发，以及C++实现用于实时性能

Result: 开发了一个能够简化QP问题构建的软件框架，支持两种编程语言实现

Conclusion: PlaCo框架成功简化了机器人系统QP规划和控制问题的制定过程，提供了灵活的开发选项

Abstract: This article introduces PlaCo, a software framework designed to simplify the formulation and solution of Quadratic Programming (QP)-based planning and control problems for robotic systems. PlaCo provides a high-level interface that abstracts away the low-level mathematical formulation of QP problems, allowing users to specify tasks and constraints in a modular and intuitive manner. The framework supports both Python bindings for rapid prototyping and a C++ implementation for real-time performance.

</details>


### [130] [OpenVLN: Open-world aerial Vision-Language Navigation](https://arxiv.org/abs/2511.06182)
*Peican Lin,Gan Sun,Chenxi Liu,Fazeng Li,Weihong Ren,Yang Cong*

Main category: cs.RO

TL;DR: 提出了一个数据高效的开放世界空中视觉语言导航框架OpenVLN，能够在有限数据约束下执行语言引导飞行，并增强复杂空中环境中的长程轨迹规划能力。


<details>
  <summary>Details</summary>
Motivation: 解决户外空中环境的巨大复杂性带来的数据采集挑战，以及无人机在长程轨迹规划方面的需求，这些为空中视觉语言导航引入了新的复杂性。

Method: 重构强化学习框架来优化视觉语言模型用于无人机导航任务，在有限训练数据下通过基于规则的策略高效微调VLM；同时引入长程规划器进行轨迹合成，通过基于价值的奖励动态生成精确的无人机动作。

Result: 在TravelUAV基准测试中，相比基线方法，成功率提升4.34%，Oracle成功率提升6.19%，路径长度加权成功率提升4.07%。

Conclusion: 该方法在复杂空中环境中为长程无人机导航提供了有效的部署方案。

Abstract: Vision-language models (VLMs) have been widely-applied in ground-based vision-language navigation (VLN). However, the vast complexity of outdoor aerial environments compounds data acquisition challenges and imposes long-horizon trajectory planning requirements on Unmanned Aerial Vehicles (UAVs), introducing novel complexities for aerial VLN. To address these challenges, we propose a data-efficient Open-world aerial Vision-Language Navigation (i.e., OpenVLN) framework, which could execute language-guided flight with limited data constraints and enhance long-horizon trajectory planning capabilities in complex aerial environments. Specifically, we reconfigure a reinforcement learning framework to optimize the VLM for UAV navigation tasks, which can efficiently fine-tune VLM by using rule-based policies under limited training data. Concurrently, we introduce a long-horizon planner for trajectory synthesis that dynamically generates precise UAV actions via value-based rewards. To the end, we conduct sufficient navigation experiments on the TravelUAV benchmark with dataset scaling across diverse reward settings. Our method demonstrates consistent performance gains of up to 4.34% in Success Rate, 6.19% in Oracle Success Rate, and 4.07% in Success weighted by Path Length over baseline methods, validating its deployment efficacy for long-horizon UAV navigation in complex aerial environments.

</details>


### [131] [ExpReS-VLA: Specializing Vision-Language-Action Models Through Experience Replay and Retrieval](https://arxiv.org/abs/2511.06202)
*Shahram Najam Syed,Yatharth Ahuja,Arthur Jakobsson,Jeff Ichnowski*

Main category: cs.RO

TL;DR: ExpReS-VLA通过经验回放和检索方法，在防止灾难性遗忘的同时专门化预训练的视觉-语言-动作模型，显著提升了在特定任务上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision-Language-Action模型在零样本泛化方面表现出色，但在适应新部署环境时效率低下。在实际应用中，在有限任务集上保持稳定高性能比广泛泛化更重要。

Method: 使用冻结视觉骨干网络存储紧凑特征表示而非原始图像-动作对，通过余弦相似度检索相关历史经验指导适应，采用优先级经验回放强调成功轨迹，并引入阈值混合对比损失从成功和失败尝试中学习。

Result: 在LIBERO仿真基准测试中，空间推理任务成功率从82.6%提升至93.1%，长时程任务从61%提升至72.3%。在物理机器人实验中，在5个操作任务上，已见和未见设置均达到98%成功率，而朴素微调分别为84.7%和32%。

Conclusion: 该方法在单个RTX 5090 GPU上仅用31秒和12个演示即可完成适应，为真实机器人部署提供了实用解决方案。

Abstract: Vision-Language-Action models such as OpenVLA show impressive zero-shot generalization across robotic manipulation tasks but often fail to adapt efficiently to new deployment environments. In many real-world applications, consistent high performance on a limited set of tasks is more important than broad generalization. We propose ExpReS-VLA, a method for specializing pre-trained VLA models through experience replay and retrieval while preventing catastrophic forgetting. ExpReS-VLA stores compact feature representations from the frozen vision backbone instead of raw image-action pairs, reducing memory usage by approximately 97 percent. During deployment, relevant past experiences are retrieved using cosine similarity and used to guide adaptation, while prioritized experience replay emphasizes successful trajectories. We also introduce Thresholded Hybrid Contrastive Loss, which enables learning from both successful and failed attempts. On the LIBERO simulation benchmark, ExpReS-VLA improves success rates from 82.6 to 93.1 percent on spatial reasoning tasks and from 61 to 72.3 percent on long-horizon tasks. On physical robot experiments with five manipulation tasks, it reaches 98 percent success on both seen and unseen settings, compared to 84.7 and 32 percent for naive fine-tuning. Adaptation takes 31 seconds using 12 demonstrations on a single RTX 5090 GPU, making the approach practical for real robot deployment.

</details>


### [132] [Affordance-Guided Coarse-to-Fine Exploration for Base Placement in Open-Vocabulary Mobile Manipulation](https://arxiv.org/abs/2511.06240)
*Tzu-Jung Lin,Jia-Fong Yeh,Hung-Ting Su,Chung-Yi Lin,Yi-Ting Chen,Winston H. Hsu*

Main category: cs.RO

TL;DR: 提出了一种零样本的机器人基座放置框架，通过结合视觉语言模型的语义理解和几何可行性来优化基座位置选择，显著提高开放词汇移动操作任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常基于接近度导航而不考虑可操作性，导致频繁的操作失败。需要一种能同时考虑语义理解和几何约束的基座放置方法。

Method: 提出了可操作性引导的粗到细探索框架，构建跨模态表示（可操作性RGB和障碍物地图+），利用VLM的粗语义先验指导搜索任务相关区域，并通过几何约束细化位置选择。

Result: 在五个不同的开放词汇移动操作任务上评估，系统达到85%的成功率，显著优于传统几何规划器和基于VLM的方法。

Conclusion: 证明了可操作性感知和多模态推理在开放词汇移动操作中通用化、指令条件规划方面的潜力。

Abstract: In open-vocabulary mobile manipulation (OVMM), task success often hinges on the selection of an appropriate base placement for the robot. Existing approaches typically navigate to proximity-based regions without considering affordances, resulting in frequent manipulation failures. We propose Affordance-Guided Coarse-to-Fine Exploration, a zero-shot framework for base placement that integrates semantic understanding from vision-language models (VLMs) with geometric feasibility through an iterative optimization process. Our method constructs cross-modal representations, namely Affordance RGB and Obstacle Map+, to align semantics with spatial context. This enables reasoning that extends beyond the egocentric limitations of RGB perception. To ensure interaction is guided by task-relevant affordances, we leverage coarse semantic priors from VLMs to guide the search toward task-relevant regions and refine placements with geometric constraints, thereby reducing the risk of convergence to local optima. Evaluated on five diverse open-vocabulary mobile manipulation tasks, our system achieves an 85% success rate, significantly outperforming classical geometric planners and VLM-based methods. This demonstrates the promise of affordance-aware and multimodal reasoning for generalizable, instruction-conditioned planning in OVMM.

</details>


### [133] [Robust Differentiable Collision Detection for General Objects](https://arxiv.org/abs/2511.06267)
*Jiayi Chen,Wei Zhao,Liangwang Ruan,Baoquan Chen,He Wang*

Main category: cs.RO

TL;DR: 提出了一种鲁棒高效的微分碰撞检测框架，支持凸面和凹面物体，通过距离基随机平滑、自适应采样和等效梯度传输实现稳健的梯度计算。


<details>
  <summary>Details</summary>
Motivation: 传统碰撞检测算法（如GJK+EPA）不可微分，阻碍了梯度流和基于梯度的优化，限制了在接触丰富任务（如抓取和操作）中的应用。现有微分方法仅限于凸面物体且对复杂几何形状缺乏鲁棒性。

Method: 采用距离基一阶随机平滑、自适应采样和等效梯度传输技术，构建支持凸面和凹面物体的微分碰撞检测框架。

Result: 在DexGraspNet和Objaverse的复杂网格上实验显示，相比现有基线有显著改进，并成功应用于灵巧抓取合成以提升抓取质量。

Conclusion: 提出的微分碰撞检测框架在复杂几何形状上表现出优越性能，为机器人接触丰富任务提供了有效的梯度优化解决方案。

Abstract: Collision detection is a core component of robotics applications such as simulation, control, and planning. Traditional algorithms like GJK+EPA compute witness points (i.e., the closest or deepest-penetration pairs between two objects) but are inherently non-differentiable, preventing gradient flow and limiting gradient-based optimization in contact-rich tasks such as grasping and manipulation. Recent work introduced efficient first-order randomized smoothing to make witness points differentiable; however, their direction-based formulation is restricted to convex objects and lacks robustness for complex geometries. In this work, we propose a robust and efficient differentiable collision detection framework that supports both convex and concave objects across diverse scales and configurations. Our method introduces distance-based first-order randomized smoothing, adaptive sampling, and equivalent gradient transport for robust and informative gradient computation. Experiments on complex meshes from DexGraspNet and Objaverse show significant improvements over existing baselines. Finally, we demonstrate a direct application of our method for dexterous grasp synthesis to refine the grasp quality. The code is available at https://github.com/JYChen18/DiffCollision.

</details>


### [134] [External Photoreflective Tactile Sensing Based on Surface Deformation Measurement](https://arxiv.org/abs/2511.06311)
*Seiichi Yamamoto,Hiroki Ishizuka,Takumi Kawasetsu,Koh Hosoda,Takayuki Kameoka,Kango Yanagida,Takato Horii,Sei Ikeda,Osamu Oshiro*

Main category: cs.RO

TL;DR: 提出一种基于软机器人机械柔顺性的触觉传感方法，使用外置光反射模块读取硅胶皮肤表面变形来估计接触力，无需嵌入触觉传感器。


<details>
  <summary>Details</summary>
Motivation: 将传感器置于接触界面外部可降低损坏风险、保持柔软性，并简化制造和维护。相比液体填充或导线嵌入的触觉皮肤，该模块化附加架构提高了耐用性、减少了布线复杂性。

Method: 首先表征光学传感元件和柔顺皮肤，然后设计原型触觉传感器。通过压缩实验验证方法，并在软机器人抓手上集成演示。

Result: 压缩实验显示力输出关系单调且与理论一致，具有低滞后性、高重复性和对小响应压痕速度的敏感性。在软机器人抓手上能可靠检测抓取事件。

Conclusion: 利用表面柔顺性与外部光学模块为软机器人提供力感知，同时保持结构灵活性和可制造性，为机器人应用和安全人机协作铺平道路。

Abstract: We present a tactile sensing method enabled by the mechanical compliance of soft robots; an externally attachable photoreflective module reads surface deformation of silicone skin to estimate contact force without embedding tactile transducers. Locating the sensor off the contact interface reduces damage risk, preserves softness, and simplifies fabrication and maintenance. We first characterize the optical sensing element and the compliant skin, thendetermine the design of a prototype tactile sensor. Compression experiments validate the approach, exhibiting a monotonic force output relationship consistent with theory, low hysteresis, high repeatability over repeated cycles, and small response indentation speeds. We further demonstrate integration on a soft robotic gripper, where the module reliably detects grasp events. Compared with liquid filled or wireembedded tactile skins, the proposed modular add on architecture enhances durability, reduces wiring complexity, and supports straightforward deployment across diverse robot geometries. Because the sensing principle reads skin strain patterns, it also suggests extensions to other somatosensory cues such as joint angle or actuator state estimation from surface deformation. Overall, leveraging surface compliance with an external optical module provides a practical and robust route to equip soft robots with force perception while preserving structural flexibility and manufacturability, paving the way for robotic applications and safe human robot collaboration.

</details>


### [135] [Towards Adaptive Humanoid Control via Multi-Behavior Distillation and Reinforced Fine-Tuning](https://arxiv.org/abs/2511.06371)
*Yingnan Zhao,Xinmiao Wang,Dewei Wang,Xinzhe Liu,Dan Lu,Qilong Han,Peng Liu,Chenjia Bai*

Main category: cs.RO

TL;DR: 提出了自适应人形控制(AHC)方法，通过两阶段框架学习跨技能和地形的自适应人形运动控制器，在Unitree G1机器人上验证了在各种情况和地形下的强适应性。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要为每个技能训练独立策略，导致行为特定控制器在复杂地形和多样化情况下泛化能力有限且性能脆弱。

Method: 采用两阶段框架：首先训练多个主要运动策略并通过多行为蒸馏获得基础多行为控制器，实现基于环境的行为自适应切换；然后通过在线反馈在更多样化地形上进行强化微调，增强控制器的地形适应性。

Result: 在仿真和Unitree G1机器人的真实世界实验中，该方法在各种情况和地形下表现出强大的适应性。

Conclusion: AHC方法成功实现了跨技能和地形的自适应人形运动控制，解决了现有方法泛化能力不足的问题。

Abstract: Humanoid robots are promising to learn a diverse set of human-like locomotion behaviors, including standing up, walking, running, and jumping. However, existing methods predominantly require training independent policies for each skill, yielding behavior-specific controllers that exhibit limited generalization and brittle performance when deployed on irregular terrains and in diverse situations. To address this challenge, we propose Adaptive Humanoid Control (AHC) that adopts a two-stage framework to learn an adaptive humanoid locomotion controller across different skills and terrains. Specifically, we first train several primary locomotion policies and perform a multi-behavior distillation process to obtain a basic multi-behavior controller, facilitating adaptive behavior switching based on the environment. Then, we perform reinforced fine-tuning by collecting online feedback in performing adaptive behaviors on more diverse terrains, enhancing terrain adaptability for the controller. We conduct experiments in both simulation and real-world experiments in Unitree G1 robots. The results show that our method exhibits strong adaptability across various situations and terrains. Project website: https://ahc-humanoid.github.io.

</details>


### [136] [ArtReg: Visuo-Tactile based Pose Tracking and Manipulation of Unseen Articulated Objects](https://arxiv.org/abs/2511.06378)
*Prajval Kumar Murali,Mohsen Kaboli*

Main category: cs.RO

TL;DR: 提出了一种名为ArtReg的新方法，用于在机器人交互过程中对未知物体（单个、多个或铰接式）进行视觉触觉跟踪，无需假设物体形状或动力学的先验知识。


<details>
  <summary>Details</summary>
Motivation: 机器人在真实环境中经常遇到具有复杂结构和铰接组件的未知物体，如门、抽屉、橱柜和工具。在没有先验几何或运动学知识的情况下感知、跟踪和操纵这些物体仍然是机器人学的基本挑战。

Method: ArtReg方法在SE(3)李群中集成视觉触觉点云，采用无迹卡尔曼滤波器进行点云配准。通过推或拉等有目的的操作动作检测可能的铰接关节，并开发了闭环控制器进行目标驱动的铰接物体操纵。

Result: 在真实机器人实验中广泛评估了该方法，展示了在不同质心、低光照条件和挑战性视觉背景下的鲁棒性。在标准铰接物体数据集上的基准测试表明，在姿态精度方面优于最先进方法。

Conclusion: 利用视觉触觉信息的鲁棒且准确的姿态跟踪使机器人能够感知和交互未见过的复杂铰接物体（具有旋转或棱柱关节）。

Abstract: Robots operating in real-world environments frequently encounter unknown objects with complex structures and articulated components, such as doors, drawers, cabinets, and tools. The ability to perceive, track, and manipulate these objects without prior knowledge of their geometry or kinematic properties remains a fundamental challenge in robotics. In this work, we present a novel method for visuo-tactile-based tracking of unseen objects (single, multiple, or articulated) during robotic interaction without assuming any prior knowledge regarding object shape or dynamics. Our novel pose tracking approach termed ArtReg (stands for Articulated Registration) integrates visuo-tactile point clouds in an unscented Kalman Filter formulation in the SE(3) Lie Group for point cloud registration. ArtReg is used to detect possible articulated joints in objects using purposeful manipulation maneuvers such as pushing or hold-pulling with a two-robot team. Furthermore, we leverage ArtReg to develop a closed-loop controller for goal-driven manipulation of articulated objects to move the object into the desired pose configuration. We have extensively evaluated our approach on various types of unknown objects through real robot experiments. We also demonstrate the robustness of our method by evaluating objects with varying center of mass, low-light conditions, and with challenging visual backgrounds. Furthermore, we benchmarked our approach on a standard dataset of articulated objects and demonstrated improved performance in terms of pose accuracy compared to state-of-the-art methods. Our experiments indicate that robust and accurate pose tracking leveraging visuo-tactile information enables robots to perceive and interact with unseen complex articulated objects (with revolute or prismatic joints).

</details>


### [137] [From Demonstrations to Safe Deployment: Path-Consistent Safety Filtering for Diffusion Policies](https://arxiv.org/abs/2511.06385)
*Ralf Römer,Julian Balletshofer,Jakob Thumm,Marco Pavone,Angela P. Schoellig,Matthias Althoff*

Main category: cs.RO

TL;DR: 提出了路径一致性安全过滤（PACS）方法，为扩散策略提供形式化安全保证，同时保持任务成功率。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在复杂操作任务中表现出色，但无法保证安全行为，而外部安全机制会改变训练时未见过的动作，导致不可预测的行为和性能下降。

Method: 在生成的行动序列轨迹上执行路径一致性制动，使用基于集合的可达性分析进行实时安全验证，保持执行与策略训练分布的一致性。

Result: 在仿真和三个真实世界人机交互任务中，PACS提供形式化安全保证，保持任务成功率，比反应式安全方法（如控制屏障函数）任务成功率提高达68%。

Conclusion: PACS方法成功解决了扩散策略的安全性问题，在提供形式化安全保证的同时保持了策略的原始性能。

Abstract: Diffusion policies (DPs) achieve state-of-the-art performance on complex manipulation tasks by learning from large-scale demonstration datasets, often spanning multiple embodiments and environments. However, they cannot guarantee safe behavior, so external safety mechanisms are needed. These, however, alter actions in ways unseen during training, causing unpredictable behavior and performance degradation. To address these problems, we propose path-consistent safety filtering (PACS) for DPs. Our approach performs path-consistent braking on a trajectory computed from the sequence of generated actions. In this way, we keep execution consistent with the policy's training distribution, maintaining the learned, task-completing behavior. To enable a real-time deployment and handle uncertainties, we verify safety using set-based reachability analysis. Our experimental evaluation in simulation and on three challenging real-world human-robot interaction tasks shows that PACS (a) provides formal safety guarantees in dynamic environments, (b) preserves task success rates, and (c) outperforms reactive safety approaches, such as control barrier functions, by up to 68% in terms of task success. Videos are available at our project website: https://tum-lsy.github.io/pacs/.

</details>


### [138] [Whole-Body Control With Terrain Estimation of A 6-DoF Wheeled Bipedal Robot](https://arxiv.org/abs/2511.06397)
*Cong Wen,Yunfei Li,Kexin Liu,Yixin Qiu,Xuanhong Liao,Tianyu Wang,Dingchuan Liu,Tao Zhang,Ximin Lyu*

Main category: cs.RO

TL;DR: 提出了一种用于6自由度轮式双足机器人的完整动力学模型和全身控制框架，包含地形估计功能，通过仿真和实验验证了在崎岖地形上的鲁棒穿越能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常忽略腿部动力学，限制了机器人的运动潜力，且机器人在不平坦地形上移动面临挑战。

Method: 开发了包含闭环动力学和地面接触模型的完整动力学模型，使用LiDAR惯性里程计和改进的主成分分析进行地形估计，采用PD控制和LQR进行姿态控制与平衡控制，使用分层优化方法解决全身控制问题。

Result: 验证了地形估计算法的性能，通过仿真和真实实验证明了算法在崎岖地形上的鲁棒性和穿越能力。

Conclusion: 所提出的完整动力学模型和全身控制框架有效解决了轮式双足机器人在不平坦地形上的运动控制问题。

Abstract: Wheeled bipedal robots have garnered increasing attention in exploration and inspection. However, most research simplifies calculations by ignoring leg dynamics, thereby restricting the robot's full motion potential. Additionally, robots face challenges when traversing uneven terrain. To address the aforementioned issue, we develop a complete dynamics model and design a whole-body control framework with terrain estimation for a novel 6 degrees of freedom wheeled bipedal robot. This model incorporates the closed-loop dynamics of the robot and a ground contact model based on the estimated ground normal vector. We use a LiDAR inertial odometry framework and improved Principal Component Analysis for terrain estimation. Task controllers, including PD control law and LQR, are employed for pose control and centroidal dynamics-based balance control, respectively. Furthermore, a hierarchical optimization approach is used to solve the whole-body control problem. We validate the performance of the terrain estimation algorithm and demonstrate the algorithm's robustness and ability to traverse uneven terrain through both simulation and real-world experiments.

</details>


### [139] [Real Garment Benchmark (RGBench): A Comprehensive Benchmark for Robotic Garment Manipulation featuring a High-Fidelity Scalable Simulator](https://arxiv.org/abs/2511.06434)
*Wenkang Hu,Xincheng Tang,Yanzhi E,Yitong Li,Zhengjie Shu,Wei Li,Huamin Wang,Ruigang Yang*

Main category: cs.RO

TL;DR: 提出了Real Garment Benchmark (RGBench)，一个用于机器人衣物操作的综合性基准测试，包含6000多个衣物网格模型、高性能模拟器以及评估模拟质量的协议。


<details>
  <summary>Details</summary>
Motivation: 虽然模拟数据在刚性物体机器人操作方面取得了显著进展，但由于缺乏变形物体模型和逼真的非刚体模拟器，这一成功尚未应用于变形物体。

Method: 开发了包含多样化衣物网格模型的数据集、新的高性能模拟器，并建立了评估衣物模拟质量的综合协议，通过精确测量的真实衣物动力学来验证。

Result: 实验表明，该模拟器显著优于现有布料模拟器，模拟误差减少20%，同时速度提高3倍。

Conclusion: RGBench将公开发布，以加速未来机器人衣物操作的研究。

Abstract: While there has been significant progress to use simulated data to learn robotic manipulation of rigid objects, applying its success to deformable objects has been hindered by the lack of both deformable object models and realistic non-rigid body simulators. In this paper, we present Real Garment Benchmark (RGBench), a comprehensive benchmark for robotic manipulation of garments. It features a diverse set of over 6000 garment mesh models, a new high-performance simulator, and a comprehensive protocol to evaluate garment simulation quality with carefully measured real garment dynamics. Our experiments demonstrate that our simulator outperforms currently available cloth simulators by a large margin, reducing simulation error by 20% while maintaining a speed of 3 times faster. We will publicly release RGBench to accelerate future research in robotic garment manipulation. Website: https://rgbench.github.io/

</details>


### [140] [Sim-to-Real Transfer in Deep Reinforcement Learning for Bipedal Locomotion](https://arxiv.org/abs/2511.06465)
*Lingfan Bao,Tianhu Peng,Chengxu Zhou*

Main category: cs.RO

TL;DR: 本章分析了双足机器人深度强化学习中的仿真到现实转移问题，诊断了仿真与现实差距的主要来源，并提出了缩小差距和强化策略的两种互补解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决双足机器人深度强化学习中仿真到现实转移的关键挑战，因为仿真环境与现实世界存在显著差距，影响策略的实际部署效果。

Method: 通过模型中心策略提高仿真器物理保真度来缩小差距，同时通过仿真中的鲁棒性训练和部署后适应来强化策略的韧性。

Result: 提出了一个结合两种哲学的战略框架，为开发和评估鲁棒的仿真到现实解决方案提供了清晰路线图。

Conclusion: 通过系统性地诊断仿真与现实差距的来源，并采用互补的缩小差距和强化策略方法，可以有效解决双足机器人深度强化学习的仿真到现实转移问题。

Abstract: This chapter addresses the critical challenge of simulation-to-reality (sim-to-real) transfer for deep reinforcement learning (DRL) in bipedal locomotion. After contextualizing the problem within various control architectures, we dissect the ``curse of simulation'' by analyzing the primary sources of sim-to-real gap: robot dynamics, contact modeling, state estimation, and numerical solvers. Building on this diagnosis, we structure the solutions around two complementary philosophies. The first is to shrink the gap through model-centric strategies that systematically improve the simulator's physical fidelity. The second is to harden the policy, a complementary approach that uses in-simulation robustness training and post-deployment adaptation to make the policy inherently resilient to model inaccuracies. The chapter concludes by synthesizing these philosophies into a strategic framework, providing a clear roadmap for developing and evaluating robust sim-to-real solutions.

</details>


### [141] [A Low-Rank Method for Vision Language Model Hallucination Mitigation in Autonomous Driving](https://arxiv.org/abs/2511.06496)
*Keke Long,Jiacheng Guo,Tianyun Zhang,Hongkai Yu,Xiaopeng Li*

Main category: cs.RO

TL;DR: 提出一种基于低秩分解的自包含方法，仅使用多个VLM生成的候选描述本身来评估和排序幻觉水平，无需外部参考或模型访问。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶场景中，视觉语言模型会产生幻觉（虚假细节），但缺乏真实参考和模型内部访问时检测和缓解幻觉具有挑战性。

Method: 构建句子嵌入矩阵，将其分解为低秩共识分量和稀疏残差，利用残差幅度对描述进行排序，选择残差最小的作为最无幻觉的描述。

Result: 在NuScenes数据集上达到87%的选择准确率，比未过滤基线提升19%，比多智能体辩论方法提升6-10%，推理时间减少51-67%。

Conclusion: 该方法能有效识别幻觉最少的描述，与人类判断高度相关，且易于并行化，适合实时自动驾驶应用。

Abstract: Vision Language Models (VLMs) are increasingly used in autonomous driving to help understand traffic scenes, but they sometimes produce hallucinations, which are false details not grounded in the visual input. Detecting and mitigating hallucinations is challenging when ground-truth references are unavailable and model internals are inaccessible. This paper proposes a novel self-contained low-rank approach to automatically rank multiple candidate captions generated by multiple VLMs based on their hallucination levels, using only the captions themselves without requiring external references or model access. By constructing a sentence-embedding matrix and decomposing it into a low-rank consensus component and a sparse residual, we use the residual magnitude to rank captions: selecting the one with the smallest residual as the most hallucination-free. Experiments on the NuScenes dataset demonstrate that our approach achieves 87% selection accuracy in identifying hallucination-free captions, representing a 19% improvement over the unfiltered baseline and a 6-10% improvement over multi-agent debate method. The sorting produced by sparse error magnitudes shows strong correlation with human judgments of hallucinations, validating our scoring mechanism. Additionally, our method, which can be easily parallelized, reduces inference time by 51-67% compared to debate approaches, making it practical for real-time autonomous driving applications.

</details>


### [142] [Adaptive PID Control for Robotic Systems via Hierarchical Meta-Learning and Reinforcement Learning with Physics-Based Data Augmentation](https://arxiv.org/abs/2511.06500)
*JiaHao Wu,ShengWen Yu*

Main category: cs.RO

TL;DR: 提出了一种结合元学习和强化学习的层次控制框架，用于自动调整机器人PID控制器参数，解决了手动调参耗时且需要专业知识的问题。


<details>
  <summary>Details</summary>
Motivation: PID控制器在工业机器人中广泛使用，但手动调参耗时且需要专业知识，需要一种自动化的参数调整方法。

Method: 采用层次控制框架，结合元学习进行PID初始化，强化学习进行在线适应，并引入基于物理的数据增强策略生成虚拟机器人配置。

Result: 在Franka Panda机械臂上平均改进16.6%（MAE 6.26°），高负载关节改进80.4%；发现优化天花板效应：当元学习基线性能均匀强时，强化学习无额外收益。

Conclusion: 强化学习的有效性高度依赖于元学习基线质量和误差分布，为层次控制系统设计提供了重要指导。

Abstract: Proportional-Integral-Derivative (PID) controllers remain the predominant choice in industrial robotics due to their simplicity and reliability. However, manual tuning of PID parameters for diverse robotic platforms is time-consuming and requires extensive domain expertise. This paper presents a novel hierarchical control framework that combines meta-learning for PID initialization and reinforcement learning (RL) for online adaptation. To address the sample efficiency challenge, a \textit{physics-based data augmentation} strategy is introduced that generates virtual robot configurations by systematically perturbing physical parameters, enabling effective meta-learning with limited real robot data. The proposed approach is evaluated on two heterogeneous platforms: a 9-DOF Franka Panda manipulator and a 12-DOF Laikago quadruped robot. Experimental results demonstrate that the proposed method achieves 16.6\% average improvement on Franka Panda (6.26° MAE), with exceptional gains in high-load joints (J2: 80.4\% improvement from 12.36° to 2.42°). Critically, this work discovers the \textit{optimization ceiling effect}: RL achieves dramatic improvements when meta-learning exhibits localized high-error joints, but provides no benefit (0.0\%) when baseline performance is uniformly strong, as observed in Laikago. The method demonstrates robust performance under disturbances (parameter uncertainty: +19.2\%, no disturbance: +16.6\%, average: +10.0\%) with only 10 minutes of training time. Multi-seed analysis across 100 random initializations confirms stable performance (4.81+/-1.64\% average). These results establish that RL effectiveness is highly dependent on meta-learning baseline quality and error distribution, providing important design guidance for hierarchical control systems.

</details>


### [143] [Koopman global linearization of contact dynamics for robot locomotion and manipulation enables elaborate control](https://arxiv.org/abs/2511.06515)
*Cormac O'Neill,Jasmine Terrones,H. Harry Asada*

Main category: cs.RO

TL;DR: 本文提出了一种使用Koopman算子将接触动力学转化为全局线性模型的方法，实现了机器人在接触环境中的实时凸模型预测控制。


<details>
  <summary>Details</summary>
Motivation: 解决机器人与环境动态接触时的控制难题，特别是接触边界动力学切换带来的非凸优化问题。

Method: 应用Koopman算子将分段接触动力学统一为嵌入空间中的全局线性模型，利用粘弹性接触特性实现无近似的控制输入。

Result: 成功实现了腿式机器人的凸模型预测控制和机械臂动态推动的实时控制，能够发现包含多次接触变化的复杂控制策略。

Conclusion: 该方法不仅适用于机器人领域，还能广泛应用于其他需要处理接触动力学的领域，为实时控制提供了有效解决方案。

Abstract: Controlling robots that dynamically engage in contact with their environment is a pressing challenge. Whether a legged robot making-and-breaking contact with a floor, or a manipulator grasping objects, contact is everywhere. Unfortunately, the switching of dynamics at contact boundaries makes control difficult. Predictive controllers face non-convex optimization problems when contact is involved. Here, we overcome this difficulty by applying Koopman operators to subsume the segmented dynamics due to contact changes into a unified, globally-linear model in an embedding space. We show that viscoelastic contact at robot-environment interactions underpins the use of Koopman operators without approximation to control inputs. This methodology enables the convex Model Predictive Control of a legged robot, and the real-time control of a manipulator engaged in dynamic pushing. In this work, we show that our method allows robots to discover elaborate control strategies in real-time over time horizons with multiple contact changes, and the method is applicable to broad fields beyond robotics.

</details>


### [144] [CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning](https://arxiv.org/abs/2511.06575)
*Jun Wang,Yevgeniy Vorobeychik,Yiannis Kantaros*

Main category: cs.RO

TL;DR: CoFineLLM是一个针对LLM规划器的CP感知微调框架，通过显式减少预测集大小来降低用户干预需求，在多个语言指导机器人规划任务中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: LLM在长视野任务中经常产生过度自信但错误的输出，现有方法使用Conformal Prediction包装输出为预测集，但LLM缺乏不确定性感知导致预测集过大，需要频繁人工干预。

Method: 提出CoFineLLM框架，首次对LLM规划器进行CP感知微调，显式优化以减少预测集大小，从而减少用户干预需求。

Result: 在多个语言指导机器人规划问题上，相比不确定性感知和无感知微调基线，在预测集大小和求助率方面均取得一致改进，并在硬件实验中展示了对分布外场景的鲁棒性。

Conclusion: CoFineLLM通过CP感知微调有效减少了LLM规划器的预测集大小和用户干预频率，提高了自主部署能力。

Abstract: Large Language Models (LLMs) have recently emerged as planners for language-instructed agents, generating sequences of actions to accomplish natural language tasks. However, their reliability remains a challenge, especially in long-horizon tasks, since they often produce overconfident yet wrong outputs. Conformal Prediction (CP) has been leveraged to address this issue by wrapping LLM outputs into prediction sets that contain the correct action with a user-defined confidence. When the prediction set is a singleton, the planner executes that action; otherwise, it requests help from a user. This has led to LLM-based planners that can ensure plan correctness with a user-defined probability. However, as LLMs are trained in an uncertainty-agnostic manner, without awareness of prediction sets, they tend to produce unnecessarily large sets, particularly at higher confidence levels, resulting in frequent human interventions limiting autonomous deployment. To address this, we introduce CoFineLLM (Conformal Finetuning for LLMs), the first CP-aware finetuning framework for LLM-based planners that explicitly reduces prediction-set size and, in turn, the need for user interventions. We evaluate our approach on multiple language-instructed robot planning problems and show consistent improvements over uncertainty-aware and uncertainty-agnostic finetuning baselines in terms of prediction-set size, and help rates. Finally, we demonstrate robustness of our method to out-of-distribution scenarios in hardware experiments.

</details>


### [145] [Underactuated Biomimetic Autonomous Underwater Vehicle for Ecosystem Monitoring](https://arxiv.org/abs/2511.06578)
*Kaustubh Singh,Shivam Kumar,Shashikant Pawar,Sandeep Manjanna*

Main category: cs.RO

TL;DR: 开发了一种欠驱动仿生水下机器人，通过强化学习技术学习最小驱动行为，用于海洋和淡水环境生态系统监测


<details>
  <summary>Details</summary>
Motivation: 需要开发适合海洋和淡水环境生态系统监测的仿生水下机器人，通过最小化驱动实现高效游泳行为

Method: 更新了鱼形机器人的机械设计，特别是尾部摆动机制，并在FishGym模拟器中使用强化学习技术学习游泳行为

Result: 提出了初步的机械设计方案，并在模拟器中展示了游泳行为，为后续强化学习测试奠定了基础

Conclusion: 该欠驱动仿生水下机器人设计为生态系统监测提供了可行方案，强化学习方法有望实现高效自主游泳

Abstract: In this paper, we present an underactuated biomimetic underwater robot that is suitable for ecosystem monitoring in both marine and freshwater environments. We present an updated mechanical design for a fish-like robot and propose minimal actuation behaviors learned using reinforcement learning techniques. We present our preliminary mechanical design of the tail oscillation mechanism and illustrate the swimming behaviors on FishGym simulator, where the reinforcement learning techniques will be tested on

</details>


### [146] [How Do VLAs Effectively Inherit from VLMs?](https://arxiv.org/abs/2511.06619)
*Chuheng Zhang,Rushuai Yang,Xiaoyu Chen,Kaixin Wang,Li Zhao,Yi Chen,Jiang Bian*

Main category: cs.RO

TL;DR: 本文提出了GrinningFace诊断基准，用于评估视觉语言动作模型如何有效继承视觉语言模型的先验知识，通过表情符号桌面操作任务来验证知识迁移效果。


<details>
  <summary>Details</summary>
Motivation: 研究视觉语言动作模型如何有效继承视觉语言模型的先验知识，解决VLA模型在具身控制中知识迁移的根本问题。

Method: 设计表情符号桌面操作任务作为诊断基准，在模拟环境和真实机器人上实现，比较参数高效微调、VLM冻结、联合训练、离散化动作预测和潜在动作预测等多种知识迁移技术。

Result: 系统评估表明，保持VLM先验对VLA泛化能力至关重要，并建立了开发真正可泛化具身AI系统的指导原则。

Conclusion: 研究不仅证明了保持VLM先验对VLA泛化的重要性，还为未来开发真正可泛化具身AI系统提供了指导方针。

Abstract: Vision-language-action (VLA) models hold the promise to attain generalizable embodied control. To achieve this, a pervasive paradigm is to leverage the rich vision-semantic priors of large vision-language models (VLMs). However, the fundamental question persists: How do VLAs effectively inherit the prior knowledge from VLMs? To address this critical question, we introduce a diagnostic benchmark, GrinningFace, an emoji tabletop manipulation task where the robot arm is asked to place objects onto printed emojis corresponding to language instructions. This task design is particularly revealing -- knowledge associated with emojis is ubiquitous in Internet-scale datasets used for VLM pre-training, yet emojis themselves are largely absent from standard robotics datasets. Consequently, they provide a clean proxy: successful task completion indicates effective transfer of VLM priors to embodied control. We implement this diagnostic task in both simulated environment and a real robot, and compare various promising techniques for knowledge transfer. Specifically, we investigate the effects of parameter-efficient fine-tuning, VLM freezing, co-training, predicting discretized actions, and predicting latent actions. Through systematic evaluation, our work not only demonstrates the critical importance of preserving VLM priors for the generalization of VLA but also establishes guidelines for future research in developing truly generalizable embodied AI systems.

</details>


### [147] [Rapidly Learning Soft Robot Control via Implicit Time-Stepping](https://arxiv.org/abs/2511.06667)
*Andrew Choi,Dezhong Tong*

Main category: cs.RO

TL;DR: 本文展示了通过隐式时间步进实现软体机器人快速策略学习，使用DisMech模拟器结合delta自然曲率控制方法，在四个软体机械臂任务中相比Elastica框架实现了6-40倍的加速，且不牺牲准确性。


<details>
  <summary>Details</summary>
Motivation: 软体机器人模拟框架稀缺且计算成本高，导致策略学习困难。本文旨在解决软体机器人模拟中计算效率低下的问题，实现快速策略学习。

Method: 采用DisMech隐式时间步进软体模拟器，结合新提出的delta自然曲率控制方法，在500个并行环境中进行策略学习。

Result: 隐式时间步进在非接触情况下实现6倍加速，在接触丰富场景下实现40倍加速。sim-to-sim评估显示加速不牺牲准确性。

Conclusion: 隐式时间步进为软体机器人策略学习提供了罕见的免费午餐：显著加速而不损失精度。

Abstract: With the explosive growth of rigid-body simulators, policy learning in simulation has become the de facto standard for most rigid morphologies. In contrast, soft robotic simulation frameworks remain scarce and are seldom adopted by the soft robotics community. This gap stems partly from the lack of easy-to-use, general-purpose frameworks and partly from the high computational cost of accurately simulating continuum mechanics, which often renders policy learning infeasible. In this work, we demonstrate that rapid soft robot policy learning is indeed achievable via implicit time-stepping. Our simulator of choice, DisMech, is a general-purpose, fully implicit soft-body simulator capable of handling both soft dynamics and frictional contact. We further introduce delta natural curvature control, a method analogous to delta joint position control in rigid manipulators, providing an intuitive and effective means of enacting control for soft robot learning. To highlight the benefits of implicit time-stepping and delta curvature control, we conduct extensive comparisons across four diverse soft manipulator tasks against one of the most widely used soft-body frameworks, Elastica. With implicit time-stepping, parallel stepping of 500 environments achieves up to 6x faster speeds for non-contact cases and up to 40x faster for contact-rich scenarios. Finally, a comprehensive sim-to-sim gap evaluation--training policies in one simulator and evaluating them in another--demonstrates that implicit time-stepping provides a rare free lunch: dramatic speedups achieved without sacrificing accuracy.

</details>


### [148] [Programmable Telescopic Soft Pneumatic Actuators for Deployable and Shape Morphing Soft Robots](https://arxiv.org/abs/2511.06673)
*Joel Kemp,Andre Farinha,David Howard,Krishna Manaswi Digumarti,Josh Pinskier*

Main category: cs.RO

TL;DR: 提出了一种可编程伸缩软气动执行器（PTSPA），通过参数化设计解决软机器人设计中的维度诅咒问题，实现可部署结构和在受限空间中的操作。


<details>
  <summary>Details</summary>
Motivation: 软机器人具有自由形态和连续体特性，但现有方法无法有效利用设计自由度。参数化设计集提供了一条实现可处理、模块化软机器人的途径。

Method: 引入参数化几何生成器，从高级输入定制执行器模型，通过半自动化实验和系统参数探索来研究新设计空间。

Result: 表征了执行器的伸缩/弯曲、膨胀和刚度特性，揭示了关键设计参数与性能之间的明确关系，并在可部署软四足机器人中进行了应用演示。

Conclusion: PTSPA为可部署和形状变形结构以及需要大长度变化的场景提供了新的设计范式。

Abstract: Soft Robotics presents a rich canvas for free-form and continuum devices capable of exerting forces in any direction and transforming between arbitrary configurations. However, there is no current way to tractably and directly exploit the design freedom due to the curse of dimensionality. Parameterisable sets of designs offer a pathway towards tractable, modular soft robotics that appropriately harness the behavioural freeform of soft structures to create rich embodied behaviours. In this work, we present a parametrised class of soft actuators, Programmable Telescopic Soft Pneumatic Actuators (PTSPAs). PTSPAs expand axially on inflation for deployable structures and manipulation in challenging confined spaces. We introduce a parametric geometry generator to customise actuator models from high-level inputs, and explore the new design space through semi-automated experimentation and systematic exploration of key parameters. Using it we characterise the actuators' extension/bending, expansion, and stiffness and reveal clear relationships between key design parameters and performance. Finally we demonstrate the application of the actuators in a deployable soft quadruped whose legs deploy to walk, enabling automatic adaptation to confined spaces. PTSPAs present new design paradigm for deployable and shape morphing structures and wherever large length changes are required.

</details>


### [149] [Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning](https://arxiv.org/abs/2511.06745)
*Lan Thi Ha Nguyen,Kien Ton Manh,Anh Do Duc,Nam Pham Hai*

Main category: cs.RO

TL;DR: 提出了PI-RIG方法，通过增强的物理信息变分自编码器将物理约束直接整合到VAE训练中，生成物理一致且可达的目标，解决了自监督目标条件强化学习中的目标设置问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法如RIG使用VAE在潜在空间中生成目标，但会产生物理上不可行的目标，影响学习效率。需要解决目标设置问题，让机器人能够提出在当前环境中可行且多样的目标。

Method: PI-RIG方法通过增强的物理信息变分自编码器（Enhanced p3-VAE），将潜在空间显式分离为控制物体动力学的物理变量和捕捉视觉外观的环境因素，同时通过微分方程约束和守恒定律强制执行物理一致性。

Result: 实验表明，这种物理信息目标生成显著提高了所提出目标的质量，在视觉机器人操作任务（包括到达、推动和抓取放置场景）中实现了更有效的探索和更好的技能获取。

Conclusion: 将物理约束直接整合到目标生成过程中能够产生物理一致且可达的目标，从而提高自监督目标条件强化学习的效率和效果。

Abstract: Self-supervised goal-conditioned reinforcement learning enables robots to autonomously acquire diverse skills without human supervision. However, a central challenge is the goal setting problem: robots must propose feasible and diverse goals that are achievable in their current environment. Existing methods like RIG (Visual Reinforcement Learning with Imagined Goals) use variational autoencoder (VAE) to generate goals in a learned latent space but have the limitation of producing physically implausible goals that hinder learning efficiency. We propose Physics-Informed RIG (PI-RIG), which integrates physical constraints directly into the VAE training process through a novel Enhanced Physics-Informed Variational Autoencoder (Enhanced p3-VAE), enabling the generation of physically consistent and achievable goals. Our key innovation is the explicit separation of the latent space into physics variables governing object dynamics and environmental factors capturing visual appearance, while enforcing physical consistency through differential equation constraints and conservation laws. This enables the generation of physically consistent and achievable goals that respect fundamental physical principles such as object permanence, collision constraints, and dynamic feasibility. Through extensive experiments, we demonstrate that this physics-informed goal generation significantly improves the quality of proposed goals, leading to more effective exploration and better skill acquisition in visual robotic manipulation tasks including reaching, pushing, and pick-and-place scenarios.

</details>


### [150] [Semi-distributed Cross-modal Air-Ground Relative Localization](https://arxiv.org/abs/2511.06749)
*Weining Lu,Deer Bin,Lian Ma,Ming Ma,Zhihao Ma,Xiangyang Chen,Longfei Wang,Yixiao Feng,Zhouxian Jiang,Yongliang Shi,Bin Liang*

Main category: cs.RO

TL;DR: 提出了一种半分布式跨模态空地相对定位框架，通过解耦相对定位与状态估计，仅传输关键点和描述符，在保证精度的同时将通信带宽限制在0.3 Mbps以下。


<details>
  <summary>Details</summary>
Motivation: 当前多机器人相对定位方法主要采用相同传感器配置的分布式SLAM系统，与所有机器人的状态估计紧密耦合，限制了灵活性和准确性。

Method: UGV和UAV独立执行SLAM并提取深度学习关键点和全局描述符；UGV使用LiDAR、相机和IMU进行局部束调整，采用两阶段优化：先优化从LiDAR-惯性里程计插值的相机位姿，再估计UGV与UAV间的相对相机位姿；实现基于深度学习描述符的增量闭环检测算法。

Result: 实验结果表明该方法在精度和效率方面表现优异，通信带宽被有效限制在0.3 Mbps以下。

Conclusion: 该方法实现了高效、准确且灵活的空地相对定位，相比传统多机器人SLAM方法具有更好的性能和通信效率。

Abstract: Efficient, accurate, and flexible relative localization is crucial in air-ground collaborative tasks. However, current approaches for robot relative localization are primarily realized in the form of distributed multi-robot SLAM systems with the same sensor configuration, which are tightly coupled with the state estimation of all robots, limiting both flexibility and accuracy. To this end, we fully leverage the high capacity of Unmanned Ground Vehicle (UGV) to integrate multiple sensors, enabling a semi-distributed cross-modal air-ground relative localization framework. In this work, both the UGV and the Unmanned Aerial Vehicle (UAV) independently perform SLAM while extracting deep learning-based keypoints and global descriptors, which decouples the relative localization from the state estimation of all agents. The UGV employs a local Bundle Adjustment (BA) with LiDAR, camera, and an IMU to rapidly obtain accurate relative pose estimates. The BA process adopts sparse keypoint optimization and is divided into two stages: First, optimizing camera poses interpolated from LiDAR-Inertial Odometry (LIO), followed by estimating the relative camera poses between the UGV and UAV. Additionally, we implement an incremental loop closure detection algorithm using deep learning-based descriptors to maintain and retrieve keyframes efficiently. Experimental results demonstrate that our method achieves outstanding performance in both accuracy and efficiency. Unlike traditional multi-robot SLAM approaches that transmit images or point clouds, our method only transmits keypoint pixels and their descriptors, effectively constraining the communication bandwidth under 0.3 Mbps. Codes and data will be publicly available on https://github.com/Ascbpiac/cross-model-relative-localization.git.

</details>


### [151] [SlotVLA: Towards Modeling of Object-Relation Representations in Robotic Manipulation](https://arxiv.org/abs/2511.06754)
*Taisei Hanyu,Nhat Chung,Huy Le,Toan Nguyen,Yuki Ikebe,Anthony Gunderman,Duy Nguyen Ho Minh,Khoa Vo,Tung Kieu,Kashu Yamazaki,Chase Rainwater,Anh Nguyen,Ngan Le*

Main category: cs.RO

TL;DR: 提出了LIBERO+基准数据集和SlotVLA框架，探索基于对象和对象关系的紧凑表示在机器人多任务操作中的应用，相比传统密集嵌入方法更高效和可解释。


<details>
  <summary>Details</summary>
Motivation: 受人类对离散对象及其关系推理的启发，研究如何利用紧凑的对象中心和对象关系表示作为多任务机器人操作的基础，解决现有方法中对象和背景线索纠缠导致的效率和可解释性问题。

Method: 1) 引入LIBERO+数据集，提供对象中心标注和实例级时间跟踪；2) 提出SlotVLA框架，使用基于槽注意力的视觉标记器保持时间一致的对象表示，关系中心解码器生成任务相关嵌入，LLM驱动模块将嵌入转换为可执行动作。

Result: 在LIBERO+上的实验表明，对象中心槽和对象关系槽表示显著减少了所需视觉标记数量，同时保持了有竞争力的泛化性能。

Conclusion: LIBERO+和SlotVLA为推进对象关系中心的机器人操作提供了紧凑、可解释且有效的基础。

Abstract: Inspired by how humans reason over discrete objects and their relationships, we explore whether compact object-centric and object-relation representations can form a foundation for multitask robotic manipulation. Most existing robotic multitask models rely on dense embeddings that entangle both object and background cues, raising concerns about both efficiency and interpretability. In contrast, we study object-relation-centric representations as a pathway to more structured, efficient, and explainable visuomotor control. Our contributions are two-fold. First, we introduce LIBERO+, a fine-grained benchmark dataset designed to enable and evaluate object-relation reasoning in robotic manipulation. Unlike prior datasets, LIBERO+ provides object-centric annotations that enrich demonstrations with box- and mask-level labels as well as instance-level temporal tracking, supporting compact and interpretable visuomotor representations. Second, we propose SlotVLA, a slot-attention-based framework that captures both objects and their relations for action decoding. It uses a slot-based visual tokenizer to maintain consistent temporal object representations, a relation-centric decoder to produce task-relevant embeddings, and an LLM-driven module that translates these embeddings into executable actions. Experiments on LIBERO+ demonstrate that object-centric slot and object-relation slot representations drastically reduce the number of required visual tokens, while providing competitive generalization. Together, LIBERO+ and SlotVLA provide a compact, interpretable, and effective foundation for advancing object-relation-centric robotic manipulation.

</details>


### [152] [Human-Level Actuation for Humanoids](https://arxiv.org/abs/2511.06796)
*MD-Nazmus Sunbeam*

Main category: cs.RO

TL;DR: 本文提出了一个量化评估人形机器人"人类水平"驱动性能的综合框架，包括标准化关节坐标系、人类等效包络和人类水平驱动评分三个组成部分。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人领域普遍声称达到"人类水平"驱动性能，但缺乏量化标准和可比性评估方法。峰值扭矩或速度规格无法反映任务相关姿态和速率下的综合性能。

Method: 1) 自由度图谱标准化关节坐标系和运动范围；2) 人类等效包络评估机器人是否在相同关节角度和速率下同时满足人类扭矩和功率要求；3) 人类水平驱动评分聚合六个物理基础因素：工作空间覆盖、HEE覆盖、扭矩模式带宽、效率和热可持续性。

Result: 提供了详细的测量协议，包括测力、电功率监测和热测试，可通过可重复实验获得所有HLAS输入。通过多关节人形机器人的实例演示了HLAS计算，揭示了峰值扭矩规格所掩盖的驱动权衡。

Conclusion: 该框架既可作为人形机器人开发的设计规范，也可作为比较驱动系统的基准标准，所有组件都基于已发表的人类生物力学数据。

Abstract: Claims that humanoid robots achieve ``human-level'' actuation are common but rarely quantified. Peak torque or speed specifications tell us little about whether a joint can deliver the right combination of torque, power, and endurance at task-relevant postures and rates. We introduce a comprehensive framework that makes ``human-level'' measurable and comparable across systems. Our approach has three components. First, a kinematic \emph{DoF atlas} standardizes joint coordinate systems and ranges of motion using ISB-based conventions, ensuring that human and robot joints are compared in the same reference frames. Second, \emph{Human-Equivalence Envelopes (HEE)} define per-joint requirements by measuring whether a robot meets human torque \emph{and} power simultaneously at the same joint angle and rate $(q,ω)$, weighted by positive mechanical work in task-specific bands (walking, stairs, lifting, reaching, and hand actions). Third, the \emph{Human-Level Actuation Score (HLAS)} aggregates six physically grounded factors: workspace coverage (ROM and DoF), HEE coverage, torque-mode bandwidth, efficiency, and thermal sustainability. We provide detailed measurement protocols using dynamometry, electrical power monitoring, and thermal testing that yield every HLAS input from reproducible experiments. A worked example demonstrates HLAS computation for a multi-joint humanoid, showing how the score exposes actuator trade-offs (gearing ratio versus bandwidth and efficiency) that peak-torque specifications obscure. The framework serves as both a design specification for humanoid development and a benchmarking standard for comparing actuation systems, with all components grounded in published human biomechanics data.

</details>


### [153] [Vision-Aided Online A* Path Planning for Efficient and Safe Navigation of Service Robots](https://arxiv.org/abs/2511.06801)
*Praveen Kumar,Tushar Sandhan*

Main category: cs.RO

TL;DR: 提出了一种将轻量级语义感知与实时路径规划相结合的框架，使低成本机器人能够在复杂环境中进行上下文感知导航，区分重要物品与普通障碍物。


<details>
  <summary>Details</summary>
Motivation: 传统导航系统依赖昂贵的LiDAR，虽然几何精度高但缺乏语义理解能力，无法区分重要文件与普通垃圾，限制了自主服务机器人在人类环境中的部署。

Method: 采用轻量级语义分割模型识别用户定义的视觉约束，将这些语义信息作为非几何障碍物投影到全局地图中，并与在线A*路径规划器紧密集成。

Result: 通过高保真仿真和真实机器人平台验证，系统在低成本硬件上实现了稳健的实时性能，能够安全导航复杂环境并尊重传统规划器无法识别的关键视觉线索。

Conclusion: 该框架成功填补了语义感知与实时路径规划之间的关键空白，证明了低成本机器人能够在复杂环境中进行上下文感知导航。

Abstract: The deployment of autonomous service robots in human-centric environments is hindered by a critical gap in perception and planning. Traditional navigation systems rely on expensive LiDARs that, while geometrically precise, are seman- tically unaware, they cannot distinguish a important document on an office floor from a harmless piece of litter, treating both as physically traversable. While advanced semantic segmentation exists, no prior work has successfully integrated this visual intelligence into a real-time path planner that is efficient enough for low-cost, embedded hardware. This paper presents a frame- work to bridge this gap, delivering context-aware navigation on an affordable robotic platform. Our approach centers on a novel, tight integration of a lightweight perception module with an online A* planner. The perception system employs a semantic segmentation model to identify user-defined visual constraints, enabling the robot to navigate based on contextual importance rather than physical size alone. This adaptability allows an operator to define what is critical for a given task, be it sensitive papers in an office or safety lines in a factory, thus resolving the ambiguity of what to avoid. This semantic perception is seamlessly fused with geometric data. The identified visual constraints are projected as non-geometric obstacles onto a global map that is continuously updated from sensor data, enabling robust navigation through both partially known and unknown environments. We validate our framework through extensive experiments in high-fidelity simulations and on a real-world robotic platform. The results demonstrate robust, real-time performance, proving that a cost- effective robot can safely navigate complex environments while respecting critical visual cues invisible to traditional planners.

</details>


### [154] [Vision-Based System Identification of a Quadrotor](https://arxiv.org/abs/2511.06839)
*Selim Ahmet Iz,Mustafa Unel*

Main category: cs.RO

TL;DR: 该论文研究了基于视觉的系统辨识技术在四旋翼建模与控制中的应用，通过灰盒建模和LQR控制器设计，验证了机载视觉系统在四旋翼性能提升中的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼建模中的复杂性和局限性，特别是在推力和阻力系数方面存在的不确定性，探索基于视觉的系统辨识技术如何提升四旋翼的建模和控制能力。

Method: 采用灰盒建模方法来缓解不确定性，评估机载视觉系统的有效性，并基于机载视觉系统数据设计LQR控制器。

Result: 结果显示模型间性能一致，验证了基于视觉的系统辨识技术的有效性，证明了这些技术在提升四旋翼性能方面的潜力。

Conclusion: 基于视觉的技术在增强四旋翼建模和控制方面具有潜力，为未来四旋翼性能提升、故障检测和决策过程的研究铺平了道路。

Abstract: This paper explores the application of vision-based system identification techniques in quadrotor modeling and control. Through experiments and analysis, we address the complexities and limitations of quadrotor modeling, particularly in relation to thrust and drag coefficients. Grey-box modeling is employed to mitigate uncertainties, and the effectiveness of an onboard vision system is evaluated. An LQR controller is designed based on a system identification model using data from the onboard vision system. The results demonstrate consistent performance between the models, validating the efficacy of vision based system identification. This study highlights the potential of vision-based techniques in enhancing quadrotor modeling and control, contributing to improved performance and operational capabilities. Our findings provide insights into the usability and consistency of these techniques, paving the way for future research in quadrotor performance enhancement, fault detection, and decision-making processes.

</details>


### [155] [Multi-Agent AI Framework for Road Situation Detection and C-ITS Message Generation](https://arxiv.org/abs/2511.06892)
*Kailin Tong,Selim Solmaz,Kenan Mujkic,Gottfried Allmer,Bo Leng*

Main category: cs.RO

TL;DR: 提出多智能体AI框架，结合多模态大语言模型和视觉感知进行道路状况监测，在自定义数据集上实现100%召回率，但存在误检和特定任务性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 传统道路状况检测方法在预定义场景中表现良好，但在未知情况下失效且缺乏语义解释，这对可靠的交通推荐至关重要。

Method: 开发多智能体AI框架，处理摄像头数据并协调专用智能体进行状况检测、距离估计、决策制定和C-ITS消息生成。

Result: 在103张图像数据集上测试，Gemini模型实现100%召回率和完美的消息模式正确性，但存在误检，在车道数、行驶车道状态和原因代码方面性能下降。

Conclusion: Gemini-2.5-Flash在检测准确性和语义理解方面表现不如Gemini-2.0-Flash且延迟更高，需要针对智能交通应用微调专门的LLMs或MLLMs。

Abstract: Conventional road-situation detection methods achieve strong performance in predefined scenarios but fail in unseen cases and lack semantic interpretation, which is crucial for reliable traffic recommendations. This work introduces a multi-agent AI framework that combines multimodal large language models (MLLMs) with vision-based perception for road-situation monitoring. The framework processes camera feeds and coordinates dedicated agents for situation detection, distance estimation, decision-making, and Cooperative Intelligent Transport System (C-ITS) message generation. Evaluation is conducted on a custom dataset of 103 images extracted from 20 videos of the TAD dataset. Both Gemini-2.0-Flash and Gemini-2.5-Flash were evaluated. The results show 100\% recall in situation detection and perfect message schema correctness; however, both models suffer from false-positive detections and have reduced performance in terms of number of lanes, driving lane status and cause code. Surprisingly, Gemini-2.5-Flash, though more capable in general tasks, underperforms Gemini-2.0-Flash in detection accuracy and semantic understanding and incurs higher latency (Table II). These findings motivate further work on fine-tuning specialized LLMs or MLLMs tailored for intelligent transportation applications.

</details>


### [156] [Integration of Visual SLAM into Consumer-Grade Automotive Localization](https://arxiv.org/abs/2511.06919)
*Luis Diener,Jens Kalkkuhl,Markus Enzweiler*

Main category: cs.RO

TL;DR: 提出了一种融合视觉SLAM与车辆横向动力学模型的框架，用于在线校准陀螺仪，提高消费级车辆的定位精度。


<details>
  <summary>Details</summary>
Motivation: 当前消费级车辆的自我运动估计主要依赖轮式里程计和IMU等本体感受传感器，但这些传感器存在系统误差和校准问题。视觉惯性SLAM在机器人领域已成为标准，但在汽车自我运动估计中的应用仍较少探索。

Method: 提出一个融合视觉SLAM与车辆横向动力学模型的框架，通过视觉信息在线校准陀螺仪，在真实驾驶条件下实现传感器校准。

Result: 实验结果表明，基于视觉的集成方法显著提高了陀螺仪校准精度，从而提升了整体定位性能。在公共基准测试中相比最先进方法表现出更优越的定位精度。

Conclusion: 视觉SLAM与车辆动力学模型的融合为汽车定位精度提升提供了一条有前景的技术路径。

Abstract: Accurate ego-motion estimation in consumer-grade vehicles currently relies on proprioceptive sensors, i.e. wheel odometry and IMUs, whose performance is limited by systematic errors and calibration. While visual-inertial SLAM has become a standard in robotics, its integration into automotive ego-motion estimation remains largely unexplored. This paper investigates how visual SLAM can be integrated into consumer-grade vehicle localization systems to improve performance. We propose a framework that fuses visual SLAM with a lateral vehicle dynamics model to achieve online gyroscope calibration under realistic driving conditions. Experimental results demonstrate that vision-based integration significantly improves gyroscope calibration accuracy and thus enhances overall localization performance, highlighting a promising path toward higher automotive localization accuracy. We provide results on both proprietary and public datasets, showing improved performance and superior localization accuracy on a public benchmark compared to state-of-the-art methods.

</details>


### [157] [Raspi$^2$USBL: An open-source Raspberry Pi-Based Passive Inverted Ultra-Short Baseline Positioning System for Underwater Robotics](https://arxiv.org/abs/2511.06998)
*Jin Huang,Yingqiang Wang,Ying Chen*

Main category: cs.RO

TL;DR: Raspi^2USBL是一个基于树莓派的开源被动倒置超短基线定位系统，为水下机器人研究提供低成本、可访问的水下定位解决方案。


<details>
  <summary>Details</summary>
Motivation: 由于GNSS信号无法穿透海面，精确的水下定位一直是水下机器人的基本挑战。需要开发低成本且易于获取的解决方案来降低水下机器人研究的门槛。

Method: 系统采用模块化硬件架构，包括水听器阵列、多通道前置放大器、OCXO、树莓派5和DAQ板。使用开源C++软件框架实现高精度时钟同步和触发，进行实时信号处理以估计信号飞行时间和到达方向。

Result: 在消声池、淡水湖和公海试验中验证，系统斜距精度优于0.1%，方位精度在0.1°以内，在1.3公里操作距离内保持稳定性能。

Conclusion: 低成本、可复制的硬件可以提供研究级的水下定位精度。通过开源硬件和软件，Raspi^2USBL为水下机器人实验室提供了统一的参考平台，降低了入门门槛，促进了水下声学导航和群体机器人的协作创新。

Abstract: Precise underwater positioning remains a fundamental challenge for underwater robotics since global navigation satellite system (GNSS) signals cannot penetrate the sea surface. This paper presents Raspi$^2$USBL, an open-source, Raspberry Pi-based passive inverted ultra-short baseline (piUSBL) positioning system designed to provide a low-cost and accessible solution for underwater robotic research. The system comprises a passive acoustic receiver and an active beacon. The receiver adopts a modular hardware architecture that integrates a hydrophone array, a multichannel preamplifier, an oven-controlled crystal oscillator (OCXO), a Raspberry Pi 5, and an MCC-series data acquisition (DAQ) board. Apart from the Pi 5, OCXO, and MCC board, the beacon comprises an impedance-matching network, a power amplifier, and a transmitting transducer. An open-source C++ software framework provides high-precision clock synchronization and triggering for one-way travel-time (OWTT) messaging, while performing real-time signal processing, including matched filtering, array beamforming, and adaptive gain control, to estimate the time of flight (TOF) and direction of arrival (DOA) of received signals. The Raspi$^2$USBL system was experimentally validated in an anechoic tank, freshwater lake, and open-sea trials. Results demonstrate a slant-range accuracy better than 0.1%, a bearing accuracy within 0.1$^\circ$, and stable performance over operational distances up to 1.3 km. These findings confirm that low-cost, reproducible hardware can deliver research-grade underwater positioning accuracy. By releasing both the hardware and software as open-source, Raspi$^2$USBL provides a unified reference platform that lowers the entry barrier for underwater robotics laboratories, fosters reproducibility, and promotes collaborative innovation in underwater acoustic navigation and swarm robotics.

</details>


### [158] [HDCNet: A Hybrid Depth Completion Network for Grasping Transparent and Reflective Objects](https://arxiv.org/abs/2511.07081)
*Guanghu Xie,Mingxu Li,Songwei Wu,Yang Liu,Zongwu Xie,Baoshi Cao,Hong Liu*

Main category: cs.RO

TL;DR: 提出HDCNet深度补全网络，结合Transformer、CNN和Mamba架构优势，显著提升透明和反光物体的深度感知能力，在机器人抓取任务中成功率提高60%。


<details>
  <summary>Details</summary>
Motivation: 传统深度传感器在透明和反光物体表面测量不可靠，限制了机器人在感知和抓取任务中的性能。

Method: 设计双分支Transformer-CNN编码器提取模态特征，浅层引入轻量级多模态融合模块，瓶颈层开发Transformer-Mamba混合融合模块实现深度语义和全局上下文信息融合。

Result: 在多个公共数据集上达到最先进的深度补全性能，机器人抓取实验显示对透明和反光物体的抓取成功率显著提升。

Conclusion: HDCNet通过多架构融合有效解决了透明和反光物体的深度感知难题，大幅提升了机器人抓取性能。

Abstract: Depth perception of transparent and reflective objects has long been a critical challenge in robotic manipulation.Conventional depth sensors often fail to provide reliable measurements on such surfaces, limiting the performance of robots in perception and grasping tasks. To address this issue, we propose a novel depth completion network,HDCNet,which integrates the complementary strengths of Transformer,CNN and Mamba architectures.Specifically,the encoder is designed as a dual-branch Transformer-CNN framework to extract modality-specific features. At the shallow layers of the encoder, we introduce a lightweight multimodal fusion module to effectively integrate low-level features. At the network bottleneck,a Transformer-Mamba hybrid fusion module is developed to achieve deep integration of high-level semantic and global contextual information, significantly enhancing depth completion accuracy and robustness. Extensive evaluations on multiple public datasets demonstrate that HDCNet achieves state-of-the-art(SOTA) performance in depth completion tasks.Furthermore,robotic grasping experiments show that HDCNet substantially improves grasp success rates for transparent and reflective objects,achieving up to a 60% increase.

</details>


### [159] [Dynamics-Decoupled Trajectory Alignment for Sim-to-Real Transfer in Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2511.07155)
*Thomas Steinecker,Alexander Bienemann,Denis Trescher,Thorsten Luettel,Mirko Maehlisch*

Main category: cs.RO

TL;DR: 提出了一种将运动规划与车辆控制解耦的框架，通过虚拟车辆与真实系统的时空对齐策略，实现强化学习从仿真到现实的零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 由于车辆动力学复杂性和仿真与现实之间的不匹配，将强化学习直接部署到真实车辆上具有挑战性。轮胎特性、路面条件、空气动力扰动和车辆负载等因素使得准确建模真实世界动力学不可行。

Method: 首先在仿真中使用运动学自行车模型训练RL智能体输出连续控制动作，然后将其行为提炼为预测轨迹的智能体。部署时使用Stanley控制器控制横向动力学，通过自适应更新机制维持纵向对齐以补偿虚拟和真实轨迹之间的偏差。

Result: 在真实车辆上验证了该方法，证明所提出的对齐策略能够实现基于强化学习的运动规划从仿真到现实的鲁棒零样本迁移。

Conclusion: 该框架成功地将高层轨迹生成与低层车辆控制解耦，为强化学习在真实机器人系统中的部署提供了可行方案。

Abstract: Reinforcement learning (RL) has shown promise in robotics, but deploying RL on real vehicles remains challenging due to the complexity of vehicle dynamics and the mismatch between simulation and reality. Factors such as tire characteristics, road surface conditions, aerodynamic disturbances, and vehicle load make it infeasible to model real-world dynamics accurately, which hinders direct transfer of RL agents trained in simulation. In this paper, we present a framework that decouples motion planning from vehicle control through a spatial and temporal alignment strategy between a virtual vehicle and the real system. An RL agent is first trained in simulation using a kinematic bicycle model to output continuous control actions. Its behavior is then distilled into a trajectory-predicting agent that generates finite-horizon ego-vehicle trajectories, enabling synchronization between virtual and real vehicles. At deployment, a Stanley controller governs lateral dynamics, while longitudinal alignment is maintained through adaptive update mechanisms that compensate for deviations between virtual and real trajectories. We validate our approach on a real vehicle and demonstrate that the proposed alignment strategy enables robust zero-shot transfer of RL-based motion planning from simulation to reality, successfully decoupling high-level trajectory generation from low-level vehicle control.

</details>


### [160] [Automated Generation of Continuous-Space Roadmaps for Routing Mobile Robot Fleets](https://arxiv.org/abs/2511.07175)
*Marvin Rüdt,Constantin Enke,Kai Furmans*

Main category: cs.RO

TL;DR: 提出了一种自动化路线图生成方法，在连续空间中结合运输需求和最小距离约束，为移动机器人车队创建高效路线图。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么基于网格（牺牲几何精度），要么是连续空间方法（忽略实际约束），需要一种能兼顾几何精度和实际约束的路线图生成方法。

Method: 结合自由空间离散化、运输需求驱动的K最短路径优化和路径平滑，在连续空间中生成路线图，集成站点间运输需求并强制执行节点和边的最小距离约束。

Result: 在多个内部物流用例中评估，该方法始终优于现有基线（4连接网格、8连接网格和随机采样），实现了更低的结构复杂度、更高的冗余度和接近最优的路径长度。

Conclusion: 该方法能够为移动机器人车队实现高效且稳健的路由，显著提升内部物流系统的吞吐量。

Abstract: Efficient routing of mobile robot fleets is crucial in intralogistics, where delays and deadlocks can substantially reduce system throughput. Roadmap design, specifying feasible transport routes, directly affects fleet coordination and computational performance. Existing approaches are either grid-based, compromising geometric precision, or continuous-space approaches that disregard practical constraints. This paper presents an automated roadmap generation approach that bridges this gap by operating in continuous-space, integrating station-to-station transport demand and enforcing minimum distance constraints for nodes and edges. By combining free space discretization, transport demand-driven $K$-shortest-path optimization, and path smoothing, the approach produces roadmaps tailored to intralogistics applications. Evaluation across multiple intralogistics use cases demonstrates that the proposed approach consistently outperforms established baselines (4-connected grid, 8-connected grid, and random sampling), achieving lower structural complexity, higher redundancy, and near-optimal path lengths, enabling efficient and robust routing of mobile robot fleets.

</details>


### [161] [Robotic versus Human Teleoperation for Remote Ultrasound](https://arxiv.org/abs/2511.07275)
*David Black,Septimiu Salcudean*

Main category: cs.RO

TL;DR: 比较了人类远程操作与机器人远程操作在超声检查中的性能差异，发现两者在完成时间和位置精度上无显著差异，人类远程操作在力控制方面更一致且更具实用性。


<details>
  <summary>Details</summary>
Motivation: 解决农村地区缺乏超声检查专业人员的难题，比较人类远程操作与机器人远程操作的相对优势，评估人类远程操作在小型社区的可行性。

Method: 通过实验比较人类远程操作和机器人远程操作的性能指标，包括设置时间、灵活性、完成时间、位置跟踪精度和力一致性。

Result: 人类远程操作在完成时间和位置精度上与机器人远程操作无显著差异（平均差异分别为1.8%和0.5%），在力应用方面更一致，且更具实用性和可及性。

Conclusion: 人类远程操作在性能上与机器人远程操作相当，但由于成本更低、复杂性更小，在小型社区中更具实用性和可及性。

Abstract: Diagnostic medical ultrasound is widely used, safe, and relatively low cost but requires a high degree of expertise to acquire and interpret the images. Personnel with this expertise are often not available outside of larger cities, leading to difficult, costly travel and long wait times for rural populations. To address this issue, tele-ultrasound techniques are being developed, including robotic teleoperation and recently human teleoperation, in which a novice user is remotely guided in a hand-over-hand manner through mixed reality to perform an ultrasound exam. These methods have not been compared, and their relative strengths are unknown. Human teleoperation may be more practical than robotics for small communities due to its lower cost and complexity, but this is only relevant if the performance is comparable. This paper therefore evaluates the differences between human and robotic teleoperation, examining practical aspects such as setup time and flexibility and experimentally comparing performance metrics such as completion time, position tracking, and force consistency. It is found that human teleoperation does not lead to statistically significant differences in completion time or position accuracy, with mean differences of 1.8% and 0.5%, respectively, and provides more consistent force application despite being substantially more practical and accessible.

</details>


### [162] [PlanT 2.0: Exposing Biases and Structural Flaws in Closed-Loop Driving](https://arxiv.org/abs/2511.07292)
*Simon Gerstenecker,Andreas Geiger,Katrin Renz*

Main category: cs.RO

TL;DR: 本文介绍了PlanT 2.0，一个轻量级的、以对象为中心的规划变换器，用于CARLA中的自动驾驶研究。通过系统性的扰动分析，揭示了模型失败的原因，并提出了向以数据为中心的开发转变的建议。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶研究过于关注基准性能和方法创新，而缺乏对模型失败、偏见和捷径学习的深入分析。这导致改进缺乏对当前失败原因的深刻理解。

Method: 引入PlanT 2.0，一个基于对象级表示的规划变换器，通过可控的输入扰动（如改变对象位置或添加/移除对象）来系统分析模型行为。对PlanT进行了多项升级以应对CARLA Leaderboard 2.0的挑战性场景。

Result: 在Longest6 v2、Bench2Drive和CARLA验证路线上实现了最先进的性能。分析揭示了深刻的失败模式：由障碍物多样性不足导致的场景理解缺乏、刚性专家行为产生的可被利用的捷径，以及对固定专家轨迹集的过拟合。

Conclusion: 基于研究发现，主张向以数据为中心的开发转变，重点关注更丰富、更鲁棒、偏见更少的数据集。代码和模型已开源。

Abstract: Most recent work in autonomous driving has prioritized benchmark performance and methodological innovation over in-depth analysis of model failures, biases, and shortcut learning. This has led to incremental improvements without a deep understanding of the current failures. While it is straightforward to look at situations where the model fails, it is hard to understand the underlying reason. This motivates us to conduct a systematic study, where inputs to the model are perturbed and the predictions observed. We introduce PlanT 2.0, a lightweight, object-centric planning transformer designed for autonomous driving research in CARLA. The object-level representation enables controlled analysis, as the input can be easily perturbed (e.g., by changing the location or adding or removing certain objects), in contrast to sensor-based models. To tackle the scenarios newly introduced by the challenging CARLA Leaderboard 2.0, we introduce multiple upgrades to PlanT, achieving state-of-the-art performance on Longest6 v2, Bench2Drive, and the CARLA validation routes. Our analysis exposes insightful failures, such as a lack of scene understanding caused by low obstacle diversity, rigid expert behaviors leading to exploitable shortcuts, and overfitting to a fixed set of expert trajectories. Based on these findings, we argue for a shift toward data-centric development, with a focus on richer, more robust, and less biased datasets. We open-source our code and model at https://github.com/autonomousvision/plant2.

</details>


### [163] [Exact Smooth Reformulations for Trajectory Optimization Under Signal Temporal Logic Specifications](https://arxiv.org/abs/2511.07375)
*Shaohang Han,Joris Verhagen,Jana Tumova*

Main category: cs.RO

TL;DR: 提出了一种基于STL信号时序逻辑的运动规划方法，通过精确重构max和min算子将STL合成转化为可微的轨迹优化问题


<details>
  <summary>Details</summary>
Motivation: STL是一种用于指定时空需求的有用形式化方法，但现有的STL合成方法存在近似误差或不可微的问题

Method: 利用STL鲁棒性语义将STL合成构建为轨迹优化问题，引入max和min算子的精确重构以获得无近似误差的可微问题

Result: 该方法在数值模拟中得到验证，展示了其实际性能

Conclusion: 所提出的方法是精确、平滑且可靠的STL运动规划解决方案

Abstract: We study motion planning under Signal Temporal Logic (STL), a useful formalism for specifying spatial-temporal requirements. We pose STL synthesis as a trajectory optimization problem leveraging the STL robustness semantics. To obtain a differentiable problem without approximation error, we introduce an exact reformulation of the max and min operators. The resulting method is exact, smooth, and sound. We validate it in numerical simulations, demonstrating its practical performance.

</details>


### [164] [Residual Rotation Correction using Tactile Equivariance](https://arxiv.org/abs/2511.07381)
*Yizhe Zhu,Zhang Ye,Boce Hu,Haibo Zhao,Yu Qi,Dian Wang,Robert Platt*

Main category: cs.RO

TL;DR: EquiTac是一个利用触觉传感器SO(2)对称性来提高样本效率和泛化能力的视觉触觉策略学习框架，通过等变网络预测旋转动作来增强基础视觉运动策略。


<details>
  <summary>Details</summary>
Motivation: 触觉数据收集成本高，需要提高样本效率来开发视觉触觉策略。

Method: 从触觉传感器RGB输入重建表面法线，使用SO(2)等变网络预测旋转动作残差来增强基础策略。

Result: 在真实机器人上，EquiTac仅需少量训练样本就能实现零样本泛化到未见过的握持方向，而基线方法即使使用更多训练数据也失败。

Conclusion: 这是首个在策略学习中显式编码触觉等变性的方法，提供了一个轻量级、对称感知的模块，提高了接触丰富任务的可靠性。

Abstract: Visuotactile policy learning augments vision-only policies with tactile input, facilitating contact-rich manipulation. However, the high cost of tactile data collection makes sample efficiency the key requirement for developing visuotactile policies. We present EquiTac, a framework that exploits the inherent SO(2) symmetry of in-hand object rotation to improve sample efficiency and generalization for visuotactile policy learning. EquiTac first reconstructs surface normals from raw RGB inputs of vision-based tactile sensors, so rotations of the normal vector field correspond to in-hand object rotations. An SO(2)-equivariant network then predicts a residual rotation action that augments a base visuomotor policy at test time, enabling real-time rotation correction without additional reorientation demonstrations. On a real robot, EquiTac accurately achieves robust zero-shot generalization to unseen in-hand orientations with very few training samples, where baselines fail even with more training data. To our knowledge, this is the first tactile learning method to explicitly encode tactile equivariance for policy learning, yielding a lightweight, symmetry-aware module that improves reliability in contact-rich tasks.

</details>


### [165] [Unified Humanoid Fall-Safety Policy from a Few Demonstrations](https://arxiv.org/abs/2511.07407)
*Zhengjie Xu,Ye Li,Kwan-yee Lin,Stella X. Yu*

Main category: cs.RO

TL;DR: 本文提出了一种统一策略，将防跌倒、冲击缓解和快速恢复整合到一个策略中，通过结合稀疏人类演示、强化学习和自适应扩散记忆，实现人形机器人完整的跌倒-恢复过程自动化。


<details>
  <summary>Details</summary>
Motivation: 人形机器人跌倒是一个固有风险，现有方法只关注平衡保持、受控下降或站起恢复等孤立方面，缺乏对真实跌倒情况的综合应对策略。

Method: 融合稀疏人类演示与强化学习，结合自适应扩散记忆的安全反应，学习自适应全身行为，统一处理防跌倒、冲击缓解和快速恢复。

Result: 在仿真和Unitree G1机器人上的实验展示了稳健的仿真到现实迁移、更低的冲击力和跨不同干扰的持续快速恢复。

Conclusion: 该方法为实现更安全、更具韧性的真实环境人形机器人指明了方向。

Abstract: Falling is an inherent risk of humanoid mobility. Maintaining stability is thus a primary safety focus in robot control and learning, yet no existing approach fully averts loss of balance. When instability does occur, prior work addresses only isolated aspects of falling: avoiding falls, choreographing a controlled descent, or standing up afterward. Consequently, humanoid robots lack integrated strategies for impact mitigation and prompt recovery when real falls defy these scripts. We aim to go beyond keeping balance to make the entire fall-and-recovery process safe and autonomous: prevent falls when possible, reduce impact when unavoidable, and stand up when fallen. By fusing sparse human demonstrations with reinforcement learning and an adaptive diffusion-based memory of safe reactions, we learn adaptive whole-body behaviors that unify fall prevention, impact mitigation, and rapid recovery in one policy. Experiments in simulation and on a Unitree G1 demonstrate robust sim-to-real transfer, lower impact forces, and consistently fast recovery across diverse disturbances, pointing towards safer, more resilient humanoids in real environments. Videos are available at https://firm2025.github.io/.

</details>


### [166] [Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic Applications: A Control-Theoretic Perspective](https://arxiv.org/abs/2511.07410)
*Hao Wang,Sathwik Karnik,Bea Lim,Somil Bansal*

Main category: cs.RO

TL;DR: 本文从控制理论视角研究如何将视觉语言模型用作机器人应用的闭环符号规划器，重点分析控制时域和预热启动对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型和视觉语言模型已广泛用于具身符号规划，但如何有效将其用于闭环符号规划仍待探索。由于这些模型是黑箱，可能产生不可预测或代价高昂的错误，使得在高级机器人规划中的应用特别具有挑战性。

Method: 从控制理论视角设计并进行了受控实验，研究控制时域和预热启动如何影响视觉语言模型符号规划器的性能。

Result: 通过实验获得了对使用视觉语言模型作为闭环符号规划器的广泛见解，并提出了改进性能的建议。

Conclusion: 研究为如何更有效地将视觉语言模型用作闭环符号规划器提供了控制理论视角的见解和建议。

Abstract: Large Language Models (LLMs) and Vision Language Models (VLMs) have been widely used for embodied symbolic planning. Yet, how to effectively use these models for closed-loop symbolic planning remains largely unexplored. Because they operate as black boxes, LLMs and VLMs can produce unpredictable or costly errors, making their use in high-level robotic planning especially challenging. In this work, we investigate how to use VLMs as closed-loop symbolic planners for robotic applications from a control-theoretic perspective. Concretely, we study how the control horizon and warm-starting impact the performance of VLM symbolic planners. We design and conduct controlled experiments to gain insights that are broadly applicable to utilizing VLMs as closed-loop symbolic planners, and we discuss recommendations that can help improve the performance of VLM symbolic planners.

</details>


### [167] [Robot Learning from a Physical World Model](https://arxiv.org/abs/2511.07416)
*Jiageng Mao,Sicheng He,Hao-Ning Wu,Yang You,Shuyang Sun,Zhicheng Wang,Yanan Bao,Huizhong Chen,Leonidas Guibas,Vitor Guizilini,Howard Zhou,Yue Wang*

Main category: cs.RO

TL;DR: PhysWorld是一个通过物理世界建模从视频生成中进行机器人学习的框架，将视频生成与物理重建相结合，实现零样本可泛化的机器人操作。


<details>
  <summary>Details</summary>
Motivation: 现有的视频生成模型可以从语言命令和图像合成逼真的视觉演示，但直接将像素运动重定向到机器人会忽略物理规律，导致操作不准确。

Method: 结合视频生成与物理世界重建，通过物体中心残差强化学习将生成的视频运动转化为物理准确的动作。

Result: 在多样化真实世界任务上的实验表明，PhysWorld相比先前方法显著提高了操作准确性。

Conclusion: PhysWorld将隐式视觉指导转化为物理可执行的机器人轨迹，无需真实机器人数据收集即可实现零样本泛化。

Abstract: We introduce PhysWorld, a framework that enables robot learning from video generation through physical world modeling. Recent video generation models can synthesize photorealistic visual demonstrations from language commands and images, offering a powerful yet underexplored source of training signals for robotics. However, directly retargeting pixel motions from generated videos to robots neglects physics, often resulting in inaccurate manipulations. PhysWorld addresses this limitation by coupling video generation with physical world reconstruction. Given a single image and a task command, our method generates task-conditioned videos and reconstructs the underlying physical world from the videos, and the generated video motions are grounded into physically accurate actions through object-centric residual reinforcement learning with the physical world model. This synergy transforms implicit visual guidance into physically executable robotic trajectories, eliminating the need for real robot data collection and enabling zero-shot generalizable robotic manipulation. Experiments on diverse real-world tasks demonstrate that PhysWorld substantially improves manipulation accuracy compared to previous approaches. Visit \href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage} for details.

</details>


### [168] [Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields](https://arxiv.org/abs/2511.07418)
*Zhao-Heng Yin,Pieter Abbeel*

Main category: cs.RO

TL;DR: Lightning Grasp是一种高性能的程序化抓取合成算法，实现了数量级的速度提升，能够为不规则工具类物体进行无监督抓取生成。


<details>
  <summary>Details</summary>
Motivation: 尽管经过多年研究，实时多样化的灵巧手抓取合成仍然是机器人和计算机图形学中未解决的核心挑战。现有方法存在需要精心调整能量函数和敏感初始化等局限性。

Method: 通过关键洞察：使用简单高效的数据结构——接触场，将复杂几何计算与搜索过程解耦。这种抽象降低了问题复杂度，实现了前所未有的程序化搜索速度。

Result: 实现了相比最先进方法数量级的速度提升，同时能够为不规则工具类物体进行无监督抓取生成，避免了先前方法的许多局限性。

Conclusion: 该系统已开源，旨在推动机器人操作领域的进一步创新。

Abstract: Despite years of research, real-time diverse grasp synthesis for dexterous hands remains an unsolved core challenge in robotics and computer graphics. We present Lightning Grasp, a novel high-performance procedural grasp synthesis algorithm that achieves orders-of-magnitude speedups over state-of-the-art approaches, while enabling unsupervised grasp generation for irregular, tool-like objects. The method avoids many limitations of prior approaches, such as the need for carefully tuned energy functions and sensitive initialization. This breakthrough is driven by a key insight: decoupling complex geometric computation from the search process via a simple, efficient data structure - the Contact Field. This abstraction collapses the problem complexity, enabling a procedural search at unprecedented speeds. We open-source our system to propel further innovation in robotic manipulation.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [169] [Zero-Shot Function Encoder-Based Differentiable Predictive Control](https://arxiv.org/abs/2511.05757)
*Hassan Iqbal,Xingjian Li,Tyler Ingebrand,Adam Thorpe,Krishna Kumar,Ufuk Topcu,Ján Drgoňa*

Main category: eess.SY

TL;DR: 提出了一种可微分的零样本自适应控制框架，用于非线性动力系统参数化家族的控制。该方法结合了基于函数编码器的神经ODE和可微分预测控制，实现了离线自监督学习和零样本适应新系统。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统模型预测控制在处理非线性系统时需要进行昂贵的在线优化的问题，以及实现对新系统的零样本适应能力。

Method: 使用函数编码器神经ODE（FE-NODE）建模系统动力学，结合可微分预测控制（DPC）进行离线自监督学习，学习显式控制策略。

Result: 该方法在多种非线性系统和不同参数场景下表现出高效性、准确性和在线适应能力，能够实现零样本适应而无需重新训练。

Conclusion: 该方法有潜力成为快速零样本自适应控制的通用工具，消除了传统模型预测控制中昂贵的在线优化需求。

Abstract: We introduce a differentiable framework for zero-shot adaptive control over parametric families of nonlinear dynamical systems. Our approach integrates a function encoder-based neural ODE (FE-NODE) for modeling system dynamics with a differentiable predictive control (DPC) for offline self-supervised learning of explicit control policies. The FE-NODE captures nonlinear behaviors in state transitions and enables zero-shot adaptation to new systems without retraining, while the DPC efficiently learns control policies across system parameterizations, thus eliminating costly online optimization common in classical model predictive control. We demonstrate the efficiency, accuracy, and online adaptability of the proposed method across a range of nonlinear systems with varying parametric scenarios, highlighting its potential as a general-purpose tool for fast zero-shot adaptive control.

</details>


### [170] [Log-linear Backstepping control on $SE_2(3)$](https://arxiv.org/abs/2511.05775)
*Li-Yu Lin,Benjamin Perseghetti,James Goppert*

Main category: eess.SY

TL;DR: 提出了在SE2(3)李群上的对数线性反步控制律，保持完整的旋转-平移耦合，通过混合不变系统推导出李代数中线性化的精确对数误差动力学。


<details>
  <summary>Details</summary>
Motivation: 大多数刚体系统在非线性李群上演化，欧几里得控制设计失去几何意义，需要几何一致的控制框架。

Method: 利用混合不变系统（群仿射动态模型），推导SE2(3)的精确对数误差动力学，提供左右雅可比逆的闭式表达式，设计对数线性反步控制律。

Result: 实现了误差动力学的指数稳定性，具有块三角结构，支持LMI或H∞增益性能设计。

Conclusion: 为混合不变系统建立了精确反步框架，为无人机和航天器控制设计提供了几何一致的基础。

Abstract: Most of the rigid-body systems which evolve on nonlinear Lie groups where Euclidean control designs lose geometric meaning. In this paper, we introduce a log-linear backstepping control law on SE2(3) that preserves full rotational-translational coupling. Leveraging a class of mixed-invariant system, which is a group-affine dynamic model, we derive exact logarithmic error dynamics that are linear in the Lie algebra. The closed-form expressions for the left- and right-Jacobian inverses of SE2(3) are expressed in the paper, which provides us the exact error dynamics without local approximations. A log-linear backstepping control design ensures exponential stability for our error dynamics; since our error dynamics is a block-triangular structure, this allows us to use Linear Matrix Inequality (LMI) formulation or $H_\infty$ gain performance design. This work establishes the exact backstepping framework for a class of mixed-invariant system, providing a geometrically consistent foundation for future Unmanned Aerial Vehicle (UAV) and spacecraft control design.

</details>


### [171] [Autonomous and Distributed Synchronization and Restoration of an Islanded Network of Microgrids](https://arxiv.org/abs/2511.05779)
*Ahmed Saad Al-Karsani,Maryam Khanbaghi*

Main category: eess.SY

TL;DR: 提出了一种基于分布式平均比例积分（DAPI）控制的自主分布式同步和恢复方案，用于解决微电网和微电网网络中逆变器基资源（IBR）的同步不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 随着清洁能源转型和逆变器基资源（IBR）的引入，微电网（MGs）和微电网网络（NMGs）需要能够在孤岛模式下自主运行，这要求具备黑启动、同步、恢复和调节能力的电网形成（GFM）IBR。然而，这些IBR面临同步不稳定问题，且可能因不充分的次级频率和电压调节而加剧。

Method: 采用分布式平均比例积分（DAPI）控制方法，结合分布式断路器操作逻辑，实现自主软启动、同步、连接和调节过程。

Result: 在高保真孤岛式改进IEEE 123总线系统（建模为由7个微电网组成的微电网网络）上的仿真结果表明，该方法能够有效实现自主软启动、同步、连接和调节。

Conclusion: 所提出的基于DAPI控制的自主分布式同步和恢复方案能够有效解决微电网网络中IBR的同步不稳定问题，确保系统在孤岛模式下的可靠运行。

Abstract: The transition towards clean energy and the introduction of Inverter-Based Resources (IBRs) are leading to the formation of Microgrids (MGs) and Network of MGs (NMGs). MGs and NMGs can operate autonomously in islanded mode, which requires Grid-Forming (GFM) IBRs that can perform black start, synchronization, restoration and regulation. However, such IBRs face synchronization instability issues, which might be worsened by inadequate secondary level frequency and voltage regulation. Accordingly, we propose an autonomous and distributed synchronization and restoration scheme using Distributed-Averaging Proportional-Integral (DAPI) control. To validate the proposed method, we model and simulate a high-fidelity islanded and modified IEEE 123 bus system, modeled as an NMG consisting of 7 MGs. The simulation results demonstrate an effective autonomous soft-start, synchronization, connection and regulation procedure using DAPI control and distributed breaker operation logic.

</details>


### [172] [Policy Gradient-Based EMT-in-the-Loop Learning to Mitigate Sub-Synchronous Control Interactions](https://arxiv.org/abs/2511.05822)
*Sayak Mukherjee,Ramij R. Hossain,Kaustav Chatterjee,Sameer Nekkalapu,Marcelo Elizondo*

Main category: eess.SY

TL;DR: 本文开发了一种基于学习的可调控制增益方法，使用EMT在环仿真框架来解决次同步振荡问题。通过强化学习方法自适应调整控制增益，有效抑制由控制交互引起的次同步振荡。


<details>
  <summary>Details</summary>
Motivation: 次同步控制交互(SSCI)源于特定电网配置下控制增益的失调，需要自适应重新调整这些增益来有效缓解。传统方法缺乏对电网条件的适应性考虑。

Method: 采用基于马尔可夫决策过程(MDP)的强化学习方法，特别是简单的深度策略梯度方法，并添加了SSCI特定的信号处理模块（下采样、带通滤波、振荡能量相关奖励计算）。

Result: 在真实事件场景中的实验表明，基于深度策略梯度训练的策略能够根据变化的电网条件自适应计算增益设置，并最优地抑制控制交互引起的振荡。

Conclusion: 提出的学习框架能够有效解决次同步振荡问题，通过自适应增益调整实现最优振荡抑制。

Abstract: This paper explores the development of learning-based tunable control gains using EMT-in-the-loop simulation framework (e.g., PSCAD interfaced with Python-based learning modules) to address critical sub-synchronous oscillations. Since sub-synchronous control interactions (SSCI) arise from the mis-tuning of control gains under specific grid configurations, effective mitigation strategies require adaptive re-tuning of these gains. Such adaptiveness can be achieved by employing a closed-loop, learning-based framework that considers the grid conditions responsible for such sub-synchronous oscillations. This paper addresses this need by adopting methodologies inspired by Markov decision process (MDP) based reinforcement learning (RL), with a particular emphasis on simpler deep policy gradient methods with additional SSCI-specific signal processing modules such as down-sampling, bandpass filtering, and oscillation energy dependent reward computations. Our experimentation in a real-world event setting demonstrates that the deep policy gradient based trained policy can adaptively compute gain settings in response to varying grid conditions and optimally suppress control interaction-induced oscillations.

</details>


### [173] [Learning-Based Multi-Stage Strategy for a Fixed-Wing Aircraft to Evade a Missile Detected at a Short Distance](https://arxiv.org/abs/2511.05828)
*Zhiguan Niu,Xiaochao Zhou,Hao Xiong*

Main category: eess.SY

TL;DR: 提出基于多阶段强化学习的导弹规避策略，模仿猎豹与羚羊的追逃博弈，在不同距离和方位阶段采用不同规避策略，在F-16高保真仿真环境中实现80.89%的规避成功率。


<details>
  <summary>Details</summary>
Motivation: 现代导弹对飞机构成严重威胁，传统基于规则的规避策略受计算需求和气动约束限制，现有学习方法对有人驾驶飞机对抗现代导弹效果不佳，需要提升飞机生存能力。

Method: 采用多阶段强化学习方法，学习大方位角转向规避、小方位角保持远离、短距离敏捷机动三种策略，根据距离和方位角在不同阶段激活相应策略。

Result: 在F-16高保真仿真环境中，该方法在速度800-1400m/s、最大过载40-50g、探测距离5000-15000m、随机方位角条件下，实现80.89%的导弹规避成功率；当探测距离超过8000m时，成功率提升至85.06%。

Conclusion: 基于多阶段强化学习的导弹规避策略显著提升了飞机生存能力，在复杂对抗环境中表现出优越性能，为有人驾驶飞机对抗现代导弹提供了有效解决方案。

Abstract: Missiles pose a major threat to aircraft in modern air combat. Advances in technology make them increasingly difficult to detect until they are close to the target and highly resistant to jamming. The evasion maneuver is the last line of defense for an aircraft. However, conventional rule-based evasion strategies are limited by computational demands and aerodynamic constraints, and existing learning-based approaches remain unconvincing for manned aircraft against modern missiles. To enhance aircraft survivability, this study investigates missile evasion inspired by the pursuit-evasion game between a gazelle and a cheetah and proposes a multi-stage reinforcement learning-based evasion strategy. The strategy learns a large azimuth policy to turn to evade, a small azimuth policy to keep moving away, and a short distance policy to perform agile aggressive maneuvers to avoid. One of the three policies is activated at each stage based on distance and azimuth. To evaluate performance, a high-fidelity simulation environment modeling an F-16 aircraft and missile under various conditions is used to compare the proposed approach with baseline strategies. Experimental results show that the proposed method achieves superior performance, enabling the F-16 aircraft to successfully avoid missiles with a probability of 80.89 percent for velocities ranging from 800 m/s to 1400 m/s, maximum overloads from 40 g to 50 g, detection distances from 5000 m to 15000 m, and random azimuths. When the missile is detected beyond 8000 m, the success ratio increases to 85.06 percent.

</details>


### [174] [Disentangled Control of Multi-Agent Systems](https://arxiv.org/abs/2511.05900)
*Ruoyu Lin,Gennaro Notomista,Magnus Egerstedt*

Main category: eess.SY

TL;DR: 提出了一个通用的多智能体控制合成框架，适用于各种具有收敛保证的问题，不受图拓扑复杂性和目标函数显式时间依赖性的限制。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中一个特别具有挑战性的问题——不同智能体之间纠缠动力学的去中心化，并支持多目标机器人和实时实现。

Method: 开发了一个通用的多智能体控制合成框架，能够处理复杂的图拓扑和显式时间依赖的目标函数。

Result: 在三个实验中验证了框架的有效性：时变领导者-跟随者编队控制、无需任何近似的时变密度函数去中心化覆盖控制（解决了长期存在的开放性问题）、以及密集环境中的安全编队导航。

Conclusion: 该框架为多智能体控制合成提供了一个通用且有效的解决方案，具有广泛的适用性和收敛保证。

Abstract: This paper develops a general framework for multi-agent control synthesis, which applies to a wide range of problems with convergence guarantees, regardless of the complexity of the underlying graph topology and the explicit time dependence of the objective function. The proposed framework systematically addresses a particularly challenging problem in multi-agent systems, i.e., decentralization of entangled dynamics among different agents, and it naturally supports multi-objective robotics and real-time implementations. To demonstrate its generality and effectiveness, the framework is implemented across three experiments, namely time-varying leader-follower formation control, decentralized coverage control for time-varying density functions without any approximations, which is a long-standing open problem, and safe formation navigation in dense environments.

</details>


### [175] [Parameter Recovery from Tangential Interpolations for Systems with an LFT Structure](https://arxiv.org/abs/2511.06011)
*Tong Zhou,Yubing Li*

Main category: eess.SY

TL;DR: 本文研究了如何从传递函数矩阵在复平面特定点沿特定方向的值和导数恢复线性时不变系统的参数，推导了参数唯一确定的充要条件，并给出了参数恢复方法。


<details>
  <summary>Details</summary>
Motivation: 研究从传递函数矩阵的测量值（包括导数值）恢复系统参数的问题，这对于系统辨识和参数估计具有重要意义。

Method: 基于线性分式变换的系统矩阵参数化，推导了参数唯一确定的向量不等式条件，并建立了参数恢复的向量线性方程方法。

Result: 得到了参数唯一确定的充要条件，在某些特殊情况下简化为常数矩阵满秩要求，并证明了所提恢复方法的鲁棒性。

Conclusion: 数值算例验证了所提方法的特性，并表明引入导数信息能有效提高参数恢复的准确性，特别是在恢复自然频率和阻尼比等参数时。

Abstract: This paper investigates how to recover parameters of a linear time invariant system from values and derivatives of its transfer function matrix, along several particular directions at a prescribed set of points in the complex plane, in which system matrices depend on these parameters through a linear fractional transformation. A necessary and sufficient condition is derived for a unique determination of these system parameters, which is expressed by a vector inequality. Under some particular situations, this condition reduces to a full column rank requirement on a constant matrix. Moreover, a method is given to recover system parameters from these values and derivatives, which is expressed by a vector linear equation with some rank constraints, for which various methods exist for finding its solutions. Robustness of the suggested recovery method is also clarified. A numerical example is given to illustrate characteristics of the suggested method, as well as effectiveness of derivative information introduction in parameter recovery, in which natural frequency and damping ratio are to be recovered for a transfer function.

</details>


### [176] [Probe-and-Release Coordination of Platoons at Highway Bottlenecks with Unknown Parameters](https://arxiv.org/abs/2511.06026)
*Yi Gao,Xi Xiong,Karl H. Johansson,Li Jin*

Main category: eess.SY

TL;DR: 提出了一种"探测-释放"算法，用于协调混合自动驾驶瓶颈处的CAV车队，同时估计环境参数并稳定交通流量，确保估计误差和交通队列有界。


<details>
  <summary>Details</summary>
Motivation: 解决混合自动驾驶瓶颈处CAV车队的协调问题，应对时变交通需求、随机CAV车队规模和容量崩溃三个实际重要因素，平滑CAV车队与非CAV交通之间的交互。

Method: 基于流体排队模型开发"探测-释放"算法，同时估计环境参数并协调CAV车队进行交通稳定。算法构建在Lyapunov函数和嵌入马尔可夫过程的漂移论证基础上。

Result: 该算法确保估计误差和交通队列有界，在标准微观仿真环境中验证有效，并在控制性能和计算效率方面优于代表性深度强化学习方法。

Conclusion: 提出的"探测-释放"算法能够有效协调混合自动驾驶瓶颈处的CAV车队，在复杂交通环境下实现交通稳定，具有实际应用价值。

Abstract: This paper considers coordination of platoons of connected and autonomous vehicles (CAVs) at mixed-autonomy bottlenecks in the face of three practically important factors, viz. time-varying traffic demand, random CAV platoon sizes, and capacity breakdowns. Platoon coordination is essential to smoothen the interaction between CAV platoons and non-CAV traffic. Based on a fluid queuing model, we develop a "probe-and-release" algorithm that simultaneously estimates environmental parameters and coordinates CAV platoons for traffic stabilization. We show that this algorithm ensures bounded estimation errors and bounded traffic queues. The proof builds on a Lyapunov function that jointly penalizes estimation errors and traffic queues and a drift argument for an embedded Markov process. We validate the proposed algorithm in a standard micro-simulation environment and compare against a representative deep reinforcement learning method in terms of control performance and computational efficiency.

</details>


### [177] [Koopman Operator for Stability Analysis: Theory with a Linear--Radial Product Reproducing Kernel](https://arxiv.org/abs/2511.06063)
*Wentao Tang,Xiuzhen Ye*

Main category: eess.SY

TL;DR: 本文提出了一种基于乘积核的Koopman算子学习方法，通过线性核和Wendland径向核的组合构建RKHS，证明了该空间在Koopman算子作用下的不变性，并建立了谱与稳定性之间的严格关系。


<details>
  <summary>Details</summary>
Motivation: 为了在稳定性分析和控制问题中同时考虑平衡点的稳定性（局部性质）和状态空间上动力学的正则性（全局性质），需要构建一个合适的RKHS来定义Koopman算子。

Method: 使用线性核和Wendland径向核形成的乘积核来构建RKHS，证明该空间在Koopman算子作用下具有不变性，并分析算子的谱特性与系统稳定性的关系。

Result: 当平衡点渐近稳定时，Koopman算子的谱严格限制在单位圆内，在分岔时逃逸单位圆。学习得到的Koopman算子具有可证明的概率误差界，提供了稳定性证书。

Conclusion: 该方法不仅通过数值验证了有效性，还讨论了这种基本的谱-稳定性关系在基于Koopman的控制中的潜在应用价值。

Abstract: Koopman operator, as a fully linear representation of nonlinear dynamical systems, if well-defined on a reproducing kernel Hilbert space (RKHS), can be efficiently learned from data. For stability analysis and control-related problems, it is desired that the defining RKHS of the Koopman operator should account for both the stability of an equilibrium point (as a local property) and the regularity of the dynamics on the state space (as a global property). To this end, we show that by using the product kernel formed by the linear kernel and a Wendland radial kernel, the resulting RKHS is invariant under the action of Koopman operator (under certain smoothness conditions). Furthermore, when the equilibrium is asymptotically stable, the spectrum of Koopman operator is provably confined inside the unit circle, and escapes therefrom upon bifurcation. Thus, the learned Koopman operator with provable probabilistic error bound provides a stability certificate. In addition to numerical verification, we further discuss how such a fundamental spectrum--stability relation would be useful for Koopman-based control.

</details>


### [178] [Model-free Adaptive Output Feedback Vibration Suppression in a Cantilever Beam](https://arxiv.org/abs/2511.06084)
*Juan Augusto Paredes Salazar,Ankit Goel*

Main category: eess.SY

TL;DR: 提出一种基于无模型自适应控制的悬臂梁振动抑制方法，通过回顾成本优化开发采样数据自适应控制器，使用位移和加速度测量进行反馈，并开发滤波器从加速度数据中提取关键位移信息以改善抑制性能。


<details>
  <summary>Details</summary>
Motivation: 悬臂梁在未知扰动下的振动抑制问题，特别是加速度测量对高频模态溢出效应更敏感，需要开发有效方法来提高振动抑制性能。

Method: 采用集中参数法建模悬臂梁，基于回顾成本优化开发采样数据自适应控制器，设计滤波器从加速度数据中提取位移信息，比较位移和加速度测量的抑制效果。

Result: 开发了能够有效抑制悬臂梁振动的自适应控制器，通过滤波器处理加速度数据可以减少溢出效应并提高抑制性能。

Conclusion: 所提出的无模型自适应控制方法能够有效抑制悬臂梁振动，特别是通过滤波器处理加速度测量可以改善控制性能并减少高频模态的溢出效应。

Abstract: This paper presents a model-free adaptive control approach to suppress vibrations in a cantilevered beam excited by an unknown disturbance. The cantilevered beam under harmonic excitation is modeled using a lumped parameter approach. Based on retrospective cost optimization, a sampled-data adaptive controller is developed to suppress vibrations caused by external disturbances. Both displacement and acceleration measurements are considered for feedback. Since acceleration measurements are more sensitive to spillover, which excites higher frequency modes, a filter is developed to extract key displacement information from the acceleration data and enhance suppression performance. The vibration suppression performance is compared using both displacement and acceleration measurements.

</details>


### [179] [A Multi-Criterion Approach to Smart EV Charging with CO2 Emissions and Cost Minimization](https://arxiv.org/abs/2511.06131)
*Luca Ambrosino,Khai Manh Nguyen,Minh Binh Vu,Riadh Zorgati,Laurent El Ghaoui,Giuseppe C. Calafiore*

Main category: eess.SY

TL;DR: 提出一个三步骤的智能电动汽车充电框架，联合最小化充电成本和二氧化碳排放，基于越南真实数据验证，相比基准方法显著降低排放和成本。


<details>
  <summary>Details</summary>
Motivation: 解决电动汽车充电过程中同时优化经济成本和环境影响的挑战，特别是在高碳强度能源系统的国家。

Method: 三步骤框架：1) 基于单位承诺问题设计线性模型确定24小时最优发电组合；2) 估算时变CO2排放并转化为排放成本信号；3) 将环境成本纳入智能充电优化模型（线性规划）。

Result: 数值模拟显示，相比先到先服务基准方法，该策略显著减少了CO2排放和充电成本，也优于其他优化方法。

Conclusion: 该多目标优化框架有潜力支持更可持续和成本效益更高的电动汽车充电策略。

Abstract: In this work, we propose a novel three-step framework for smart electric vehicle (EV) charging that jointly minimizes charging costs and CO2 emissions. Drawing inspiration from the classical Unit Commitment Problem (UCP), we first design a linear model to determine the optimal power generation mix over a 24-hour horizon, using real-world data from Vietnam, a country with a highly carbon intensive energy system. This allows us to estimate time-varying CO2 emissions and translate them into an emission cost signal. We then incorporate this environmental cost into a smart charging optimization model, formulated as a linear program (LP). Numerical simulations confirm that the proposed strategy significantly outperforms a baseline First-In-First-Served (FIFS) approach, achieving notable reductions in both CO2 emissions and charging costs also compared to another optimization approach. The results demonstrate the potential of this multiobjective optimization framework to support more sustainable and cost-efficient EV charging strategies.

</details>


### [180] [A Passive Software-Defined Radio-based mmWave Sensing System for Blind Integrated Communication and Sensing](https://arxiv.org/abs/2511.06199)
*Shiqi Liu,Hang Song,Bo Wei,Nopphon Keerativoranan,Jun-ichi Takada*

Main category: eess.SY

TL;DR: 开发了一种完全被动的毫米波感知系统，用于盲集成感知与通信，仅使用被动接收模块而不依赖发射器，通过差分结构消除未知信号影响。


<details>
  <summary>Details</summary>
Motivation: 传统ISAC系统需要主动发射无线电波，但受法规限制难以实验；且需要发射接收同步和发射信息。本文旨在开发不依赖发射器的被动感知系统。

Method: 采用软件定义无线电构建完全被动毫米波感知系统，使用两个反向接收器的差分结构来消除未知源信号和其他失真的影响。

Result: 系统验证了已知运动模式的金属板，多普勒谱图与仿真结果一致；在复杂场景（挥手、单人多运动检测）中成功反映相应运动。

Conclusion: 提出的被动感知系统可在不干扰现有系统的情况下利用环境毫米波通信信号进行感知，适用于各种盲ISAC应用场景。

Abstract: Integrated Sensing and Communication (ISAC) is considered as a key component of future 6G technologies, especially in the millimeter-wave (mmWave) bands. Recently, the performances of ISAC were experimentally evaluated and demonstrated in various scenarios by developing ISAC systems. These systems generally consist of coherent transmitting (Tx) and receiving (Rx) modules. However, actively transmitting radio waves for experiments is not easy due to regulatory restrictions of radio. Meanwhile, the Tx/Rx should be synchronized and Rx need the information of Tx. In this paper, a fully passive mmWave sensing system is developed with software-defined radio for blind ISAC. It only consists of a passive Rx module which does not depend on the Tx. Since the proposed system is not synchronized with Tx and has no knowledge of the transmitted signals, a differential structure with two oppositely-oriented receivers is introduced to realize the sensing function. This structure can mitigate the influences of unknown source signals and other distortions. With the proposed sensing system, the ambient mmWave communication signals are leveraged for sensing without interrupting the existing systems. It can be deployed for field applications such as signal detection and dynamic human activity recognition since it does not emit signals. The efficacy of the developed system is first verified with a metallic plate with known motion pattern. The measured Doppler spectrogram shows good agreement with the simulation results, demonstrating the correctness of the sensing results. Further, the system is evaluated in complex scenarios, including handwaving, single- and multi-person motion detection. The sensing results successfully reflect the corresponding motions, demonstrating that the proposed sensing system can be utilized for blind ISAC in various applications.

</details>


### [181] [Learning-Based Robust Bayesian Persuasion with Conformal Prediction Guarantees](https://arxiv.org/abs/2511.06223)
*Heeseung Bang,Andreas A. Malikopoulos*

Main category: eess.SY

TL;DR: 提出了一个结合神经网络和共形预测的学习框架，用于在接收者信念形成机制不确定的情况下实现鲁棒性劝说。


<details>
  <summary>Details</summary>
Motivation: 经典贝叶斯劝说假设发送者完全了解接收者的信念形成和决策过程，但这在接收者拥有私有信息或表现出非贝叶斯行为时很少成立。

Method: 使用神经网络学习从接收者观察和发送者信号到行动预测的端到端映射，结合共形预测构建具有可证明边际覆盖的有限样本有效预测集。

Result: 建立了数据生成策略的精确覆盖保证，推导了策略偏移下覆盖退化的界限，提供了神经网络近似和估计误差界限，样本复杂度为O(d log(|U||Y||S|)/ε²)。

Conclusion: 该框架在智能电网能源管理的数值实验中展现了鲁棒性，为不确定信念形成机制下的劝说问题提供了理论保证和实用解决方案。

Abstract: Classical Bayesian persuasion assumes that senders fully understand how receivers form beliefs and make decisions--an assumption that rarely holds when receivers possess private information or exhibit non-Bayesian behavior. In this paper, we develop a learning-based framework that integrates neural networks with conformal prediction to achieve robust persuasion under uncertainty about receiver belief formation. The proposed neural architecture learns end-to-end mappings from receiver observations and sender signals to action predictions, eliminating the need to identify belief mechanisms explicitly. Conformal prediction constructs finite-sample valid prediction sets with provable marginal coverage, enabling principled, distribution-free robust optimization. We establish exact coverage guarantees for the data-generating policy and derive bounds on coverage degradation under policy shifts. Furthermore, we provide neural network approximation and estimation error bounds, with sample complexity $O(d \log(|\mathcal{U}||\mathcal{Y}||\mathcal{S}|)/\varepsilon^2)$, where $d$ denotes the effective network dimension, and finite-sample lower bounds on the sender's expected utility. Numerical experiments on smart-grid energy management illustrate the framework's robustness.

</details>


### [182] [Coherency Analysis in Nonlinear Heterogeneous Power Networks: A Blended Dynamics Approach](https://arxiv.org/abs/2511.06306)
*Yixuan Liu,Yingzhu Liu,Pengcheng You*

Main category: eess.SY

TL;DR: 本文扩展了混合动力学方法，分析复杂电力网络中的同调性现象，揭示了网络高连通性或扰动时变率小是促进同调性的关键因素。


<details>
  <summary>Details</summary>
Motivation: 尽管电力系统同调性现象已被广泛观察，但对复杂网络中异质、非线性且受持续扰动（如可再生能源波动）影响的同调性理解仍不完整。

Method: 将多智能体系统共识分析中的混合动力学方法扩展到电力网络，开发了新的同调性分析框架，建立了节点动力学与混合动力学轨迹差异的界。

Result: 识别出两个促进同调性的关键因素：高网络连通性或小扰动时变率，它们使节点频率能从任意初始状态快速接近混合动力学轨迹。

Conclusion: 这些发现深化了对电力系统同调性的理解，即使在系统不趋于平衡时，节点频率也能长期紧密跟随混合动力学轨迹。

Abstract: Power system coherency refers to the phenomenon that machines in a power network exhibit similar frequency responses after disturbances, and is foundational for model reduction and control design. Despite abundant empirical observations, the understanding of coherence in complex power networks remains incomplete where the dynamics could be highly heterogeneous, nonlinear, and increasingly affected by persistent disturbances such as renewable energy fluctuations. To bridge this gap, this paper extends the blended dynamics approach, originally rooted in consensus analysis of multi-agent systems, to develop a novel coherency analysis in power networks. We show that the frequency responses of coherent machines coupled by nonlinear power flow can be approximately represented by the blended dynamics, which is a weighted average of nonlinear heterogeneous nodal dynamics, even under time-varying disturbances. Specifically, by developing novel bounds on the difference between the trajectories of nodal dynamics and the blended dynamics, we identify two key factors -- either high network connectivity or small time-variation rate of disturbances -- that contribute to coherence. They enable the nodal frequencies to rapidly approach the blended-dynamics trajectory from arbitrary initial state. Furthermore, they ensure the frequencies closely follow this trajectory in the long term, even when the system does not settle to an equilibrium. These insights contribute to the understanding of power system coherency and are further supported by simulation results.

</details>


### [183] [Partial-Power Flow Controller, Voltage Regulator, and Energy Router for Hybrid AC-DC Grids](https://arxiv.org/abs/2511.06335)
*Ehsan Asadi,Davood Keshavarzi,Alexander Koehler,Nima Tashakor,Stefan Goetz*

Main category: eess.SY

TL;DR: 提出一种部分功率能量路由器架构，通过模块化低压大电流串联模块控制电压和功率流，相比传统技术显著减小尺寸、成本和损耗。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源、负载和储能在低压和中压电网中的占比增加，DC电网可消除AC-DC转换阶段的硬件和损耗，但需要主动控制电压和功率流，并与现有AC电网接口。

Method: 采用模块化低压大电流串联模块，通过双有源桥供电，仅需处理小部分电压即可控制大功率流，并可集成电池储能。

Result: 实验验证了该能量路由器在AC和DC电网中的性能，确认其在功率分配、电压和电能质量控制方面的有效性。

Conclusion: 该拓扑相比传统技术将组件尺寸、成本、能量损耗和可靠性改善超过三倍，是控制扩展电网的有效解决方案。

Abstract: The share of electronically converted power from renewable sources, loads, and storage is continuously growing in the low- and medium-voltage grids. These sources and loads typically rectify the grid AC to DC, e.g., for a DC link, so that a DC grid could eliminate hardware and losses of these conversion stages. However, extended DC grids lack the stabilizing nature of AC impedances so that the voltage is more fragile and power flows may need active control, particularly if redundancy as known from AC, such as rings and meshing, is desired. Furthermore, a DC infrastructure will not replace but will need to interface with the existing AC grid. This paper presents a partial-power energy router architecture that can interface multiple AC and DC lines to enable precise control of voltages and both active as well as reactive power flows. The proposed system uses modular low-voltage high-current series modules supplied through dual active bridges. These modules only need to process a small share of the voltage to control large power flows. The topology reduces component size, cost, energy losses, and reliability more than three times compared to conventional technology. The optional integration of battery energy storage can furthermore eliminate the need for the sum of the power flows of all inputs to be zero at all times. Through dynamic voltage injection relative to the line voltage, the modules effectively balance feeder currents, regulate reactive power, and improve the power factor in AC grids. Real-time hardware-in-the-loop and prototype measurements validate the proposed energy router's performance under diverse operating conditions. Experimental results confirm the series module's functionality in both AC and DC grids as an effective solution for controlling extended grids, including power sharing, voltage, and power quality.

</details>


### [184] [Optical Network Digital Twin - Commercialization Barriers, Value Proposition, Early Use Cases, and Challenges](https://arxiv.org/abs/2511.06368)
*Hideki Nishizawa,Toru Mano,Kazuya Anazawa,Tatsuya Matsumura,Takeo Sasai,Masatoshi Namiki,Dmitrii Briantcev,Renato Ambrosone,Esther Le Rouzic,Stefan Melin,Oscar Gonzalez-de-Dios,Juan Pedro Fernandez-Palacios,Xiaocheng Zhang,Keigo Akahoshi,Gert Grammel,Andrea D'Amico,Giacomo Borraccini,Marco Ruffini,Daniel Kilper,Vittorio Curri*

Main category: eess.SY

TL;DR: 本文提出了光学网络数字孪生架构，以应对AI时代机器间通信对光网络的新需求，支持灵活的端到端光路操作。


<details>
  <summary>Details</summary>
Motivation: 随着AI的普及，机器间通信快速增长，重塑了光网络的需求。高斯噪声建模的进展提升了数字孪生操作的期望，但光网络数字孪生商业化仍面临重大障碍。

Method: 提出光学网络数字孪生架构，超越传统管理，实现灵活的端到端光路操作。

Result: 提出了该架构的价值主张、商业化演进步骤以及实际部署的关键研究挑战。

Conclusion: 光学网络数字孪生架构有望满足AI时代光网络的新需求，但需要解决关键研究挑战才能实现商业化部署。

Abstract: With the widespread adoption of AI, machine-to-machine communications are rapidly increasing, reshaping the requirements for optical networks. Recent advances in Gaussian noise modeling for digital coherent transmission have raised expectations for digital-twin-based operation. However, unlike digital twins in wireless communication, which are already well established, significant barriers remain for commercialization in optical networks. This paper discusses the evolving requirements of optical networks in the AI era and proposes an Optical Network Digital Twin architecture that enables flexible end-to-end light path operation beyond conventional management. The value propositions of the proposed architecture, its evolutionary steps toward commercialization, and key research challenges for practical deployment are presented.

</details>


### [185] [Dynamic Electric Vehicle Charging Pricing for Load Balancing in Power Distribution Networks based on Collaborative DDPG Agents](https://arxiv.org/abs/2511.06398)
*Leloko J. Lepolesa,Kayode E. Adetunji,Khmaies Ouahada,Zhenqing Liu,Ling Cheng*

Main category: eess.SY

TL;DR: 提出基于深度强化学习的动态电动汽车充电定价策略，实现配电网负荷削峰填谷和区域间负荷平衡。


<details>
  <summary>Details</summary>
Motivation: 大规模电动汽车充电可能对电网稳定性造成威胁，特别是在未设计用于处理此类负荷的电网中。需要一种策略来管理充电负荷，确保电网稳定运行。

Method: 基于历史环境变量（温度、湿度、风速、充电价格、车辆分布）预测配电网负荷需求，使用深度强化学习（DDPG、SAC、PPO算法）设置最优动态充电价格。

Result: 仿真结果显示在配电网层面改进了电网利用率，实现了更大规模的电网最优使用。

Conclusion: 动态电动汽车充电定价策略能够有效实现配电网负荷管理，包括削峰填谷和区域间负荷平衡，提高电网整体运行效率。

Abstract: The transition from the Internal Combustion Engine Vehicles (ICEVs) to the Electric Vehicles (EVs) is globally recommended to combat the unfavourable environmental conditions caused by reliance on fossil fuels. However, it has been established that the charging of EVs can destabilize the grid when they penetrate the market in large numbers, especially in grids that were not initially built to handle the load from the charging of EVs. In this work, we present a dynamic EV charging pricing strategy that fulfills the following three objectives: distribution network-level load peak-shaving, valley-filling, and load balancing across distribution networks. Based on historical environmental variables such as temperature, humidity, wind speed, EV charging prices and distribution of vehicles in different areas in different times of the day, we first forecast the distribution network load demand, and then use deep reinforcement learning approach to set the optimal dynamic EV charging price. While most research seeks to achieve load peak-shaving and valley-filling to stabilize the grid, our work goes further into exploring the load-balancing between the distribution networks in the close vicinity to each other. We compare the performance of Deep Deterministic Policy Gradient (DDPG), Soft Actor-Critic (SAC) and Proximal Policy Optimization (PPO) algorithms for this purpose. The best algorithm is used for dymamic EV pricing. Simulation results show an improved utilization of the grid at the distribution network level, leading to the optimal usage of the grid on a larger scale.

</details>


### [186] [Sensor Importance towards Observability Degree via Shapley Values](https://arxiv.org/abs/2511.06409)
*Vishal Cholapadi Ravindra*

Main category: eess.SY

TL;DR: 本文提出使用博弈论中的Shapley值来量化传感器对可观测度的边际贡献，为传感器选择和卡尔曼滤波器设计提供新方法。


<details>
  <summary>Details</summary>
Motivation: 传感器选择在状态估计器设计中常被忽视，传统方法只关注可观测性（真/假判断），但缺乏对传感器个体贡献的量化评估。当存在多种传感器且受成本和物理约束时，需要更精细的传感器选择方法。

Method: 将博弈论中的Shapley值应用于传感器选择问题，通过计算每个传感器对可观测度的边际贡献来量化其重要性。

Result: Shapley值能够有效量化每个传感器对系统可观测度的预期边际贡献，为传感器选择提供公平分配的依据。

Conclusion: Shapley值为传感器选择、布局和滤波器设计提供了量化工具，能够帮助设计者基于传感器对可观测度的贡献做出更明智的选择决策。

Abstract: Sensor selection is an often under-appreciated aspect of state estimator or Kalman filter design. The basic minimum requirement for the choice of a sensor set while designing Kalman filters is that all states are observable. In addition, the sensors should be chosen with a view towards estimating the states with a desired accuracy. Often observability is treated as true/false check during filter design. Beyond observability -- the observability degree -- which measures \emph{how observable} the states are, has been used as the metric of choice to for sensor selection or placement applications. The higher the degree of observability, the better the possibility of designing Kalman filters that achieve the desired state estimation accuracy and consistency requirements. When a wide variety of sensors are available, sometimes with cost and physical constraints involved, sensor selection plays a crucial role in filter design. In such situations it is important to know the expected contribution of each sensor towards observability degree. Shapley values, developed in cooperative game theory for fair allocation of the payout of a multi-player game to individual players, are widely used in machine learning to assess feature importance. This paper shows that Shapley values can indeed be leveraged to quantify the expected marginal contribution of each sensor in any given sensor set towards the observability degree. This quantification of the fair contribution of each sensor towards the observability degree can be leveraged by filter designers for sensor selection, placement and filter (state estimator) design.

</details>


### [187] [Optimal Rank-1 Directional State Transition Tensors](https://arxiv.org/abs/2511.06508)
*Grace E. Calkins,Jay W. McMahon,Jackson Kulik*

Main category: eess.SY

TL;DR: 开发了状态转移张量的最优秩-1近似，作为非线性不确定性量化的高效替代方法，通过求解张量z-特征对问题来最大化信息保留。


<details>
  <summary>Details</summary>
Motivation: 为非线性不确定性量化提供比传统状态转移张量更高效的替代方法，改进高斯矩传播在非线性飞行场景（如气动捕获）中的精度。

Method: 通过求解状态转移张量"平方"的z-特征对问题，构造最优秩-1方向状态转移张量，在Frobenius范数意义上最大化信息保留。

Result: 该方法提高了状态转移张量的近似精度，改善了非线性飞行场景中的高斯矩传播性能。

Conclusion: 最优秩-1方向状态转移张量方法在保持计算效率的同时，显著提升了非线性不确定性量化的精度。

Abstract: An optimal rank-1 approximation of state transition tensors was developed as an efficient alternative to state transition tensors for nonlinear uncertainty quantification. While previous directional state transition tensors used the dominant right singular subspace of the state transition matrix to construct a reduced-dimension representation of the state transition tensors, optimal directional state transition tensors are constructed to maximize the information retained in a rank-1 approximation of the state transition tensors in the Frobenius-norm sense. The optimal rank-1 directional state transition tensor is found by solving a tensor z-eigenpair problem of the "square" of the state transition tensor. This construct leads to increased approximation accuracy of the state transition tensors and improved Gaussian moment propagation for nonlinear flight scenarios like aerocapture.

</details>


### [188] [Verification of low-frequency signal injection method for earth-fault detection](https://arxiv.org/abs/2511.06520)
*Nina Stipetic,Bozidar Filipovic-Grcic,Igor Ziger,Silvio Jancin,Bruno Jurisic,Dalibor Filipovic-Grcic,Alain Xémard*

Main category: eess.SY

TL;DR: 本文研究了在中性点不接地中压网络中应用信号注入法进行接地故障定位的方法，通过三组感应电压互感器实现信号注入，并通过实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 中性点不接地网络在发生接地故障时仍可继续运行，但需要快速确定故障线路以防止故障升级。信号注入法在低压网络中常用，但在中压网络中的应用取决于如何向不接地相注入信号。

Method: 使用三组感应电压互感器(IVTs)在中性点不接地中压网络中实现信号注入，通过电磁暂态(EMT)仿真和实验测试验证方法可行性。

Result: 仿真结果显示信号注入和接地故障检测在中压网络中具有良好前景，实验测量结果进一步验证了该方法的有效性。

Conclusion: 信号注入法可通过三组感应电压互感器在中性点不接地中压网络中成功实现，为快速接地故障定位提供了可行方案。

Abstract: Unearthed neutral is commonly used in networks which require continuous power supply. This is common in MV circuits of industrial and power plants. Unearthed networks can remain in operation during an earth-fault, but fast determination of the faulty line is key for prevention of further fault escalation. Signal injection is one of the fault location methods often used in LV unearthed networks. The possibility of applying this method in MV networks depends on how to inject the signal into unearthed phases. In such networks, it is possible to use a group of three inductive voltage transformers (IVTs) for signal injection. After the simulations have shown promising results of signal injection and earth-fault detection in MV network, an experimental test was performed. This paper describes the experimental setup and shows the measurement results of signal injection method at MV level supported by EMT simulations.

</details>


### [189] [Investigation of lightning effects on solar power plants connected to transmission networks](https://arxiv.org/abs/2511.06523)
*Selma Grebovic,Abdulah Aksamovic,Bozidar Filipovic-Grcic,Samim Konjicija*

Main category: eess.SY

TL;DR: 研究雷电对太阳能发电厂的影响，分析有无避雷器情况下的过电压效应，评估避雷器在减轻雷击过电压方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着太阳能发电厂越来越多地接入输电电网，其易受雷击等干扰的脆弱性引发关注，需要研究保护措施以确保可靠性和安全性。

Method: 在输电线路不同距离处进行雷击模拟，变化峰值电流、波前时间和波尾时间等关键参数，进行傅里叶变换分析和希尔伯特边际谱分析。

Result: 研究结果表明避雷器能有效减轻雷击过电压，为太阳能发电厂的保护措施提供了重要见解。

Conclusion: 适当的保护措施对于提高接入输电网络的太阳能发电厂的可靠性和安全性至关重要，避雷器是有效的防护手段。

Abstract: The increasing integration of solar power plants into transmission grids has raised concerns about their vulnerability to disturbances, particularly lightning strokes. Solar energy, while offering significant environmental and economic benefits, faces challenges when connected to transmission lines that are prone to lightning discharges. This paper investigates the impact of lightning events on solar power plants, focusing on overvoltage effects. Lightning stroke simulations were conducted at various distances from the solar power plant along the transmission line, considering scenarios with and without surge arrester. Key lightning parameters such as peak current, front time, and tail time were varied to simulate different lightning strokes. The study also includes a Fourier transform analysis of the resulting overvoltages with and without a surge arrester, along with the Hilbert marginal spectrum of these overvoltages. The results provide insights into the effectiveness of surge arresters in mitigating lightning overvoltages and highlight the importance of proper protective measures for enhancing the reliability and safety of solar power plants connected to transmission networks.

</details>


### [190] [Input-Output Data-Driven Stabilization of Continuous-Time Linear MIMO Systems](https://arxiv.org/abs/2511.06524)
*Haihui Gao,Alessandro Bosso,Lei Wang,David Saussié,Bowen Yi*

Main category: eess.SY

TL;DR: 提出了一种基于输入输出数据的连续时间MIMO线性时不变系统的数据驱动稳定化方法，无需统一可观测性指标


<details>
  <summary>Details</summary>
Motivation: 解决基于实验收集的输入输出数据来稳定连续时间多输入多输出线性时不变系统的问题，扩展数据驱动输出反馈控制的应用范围

Method: 将Kreisselmeier自适应滤波器解释为系统可稳定非最小实现的观测器，通过该滤波器后处理输入输出数据，推导出线性矩阵不等式来确定动态输出反馈稳定器的反馈增益

Result: 该方法适用于广泛的连续时间MIMO系统类别，无需统一可观测性指标

Conclusion: 基于非最小实现的数据驱动输出反馈控制方法能够有效稳定连续时间MIMO系统

Abstract: In this paper, we address the problem of data-driven stabilization of continuous-time multi-input multi-output (MIMO) linear time-invariant systems using the input-output data collected from an experiment. Building on recent results for data-driven output-feedback control based on non-minimal realizations, we propose an approach that can be applied to a broad class of continuous-time MIMO systems without requiring a uniform observability index. The key idea is to show that Kreisselmeier's adaptive filter can be interpreted as an observer of a stabilizable non-minimal realization of the plant. Then, by postprocessing the input-output data with such a filter, we derive a linear matrix inequality that yields the feedback gain of a dynamic output-feedback stabilizer.

</details>


### [191] [Voltage-Regulated Sparse Optimization for Proactive Diagnosis of Voltage Collapses](https://arxiv.org/abs/2511.06528)
*Qinghua Ma,Seyyedali Hosseinalipour,Ming Shi,Jan Drgona,Shimiao Li*

Main category: eess.SY

TL;DR: 提出一种电压调节稀疏优化方法，用于主动诊断和管理由极端事件和突发事件引起的电压崩溃风险，通过识别关键节点和量化补偿措施来确保系统安全运行。


<details>
  <summary>Details</summary>
Motivation: 主动诊断和管理电压崩溃风险，解决系统在极端事件下的生存能力和识别主导脆弱性这两个关键弹性问题。

Method: 提出电压调节稀疏优化方法，寻找最小化总线位置集合及其量化补偿（纠正措施），同时强制执行交流网络平衡和电压边界约束。

Result: 在30到2383总线的输电系统测试中，该方法通过仅补偿少数战略识别节点有效缓解电压崩溃，对2000+总线案例平均耗时不到4分钟，具有良好的可扩展性。

Conclusion: 该方法可作为更全面和可操作决策（如无功功率规划）的基础，有效识别系统关键脆弱点并制定针对性补偿策略。

Abstract: This paper aims to proactively diagnose and manage the voltage collapse risks, i.e., the risk of bus voltages violating the safe operational bounds, which can be caused by extreme events and contingencies. We jointly answer two resilience-related research questions: (Q1) Survivability: Upon having an extreme event/contingency, will the system remain feasible with voltage staying within a (preferred) safe range? (Q2) Dominant Vulnerability: If voltage collapses, what are the dominant sources of system vulnerabilities responsible for the failure? This highlights some key locations worth paying attention to in the planning or decision-making process. To address these questions, we propose a voltage-regulated sparse optimization that finds a minimal set of bus locations along with quantified compensations (corrective actions) that can simultaneously enforce AC network balance and voltage bounds. Results on transmission systems of varying sizes (30-bus to 2383-bus) demonstrate that the proposed method effectively mitigates voltage collapses by compensating at only a few strategically identified nodes, while scaling efficiently to large systems, taking on average less than 4 min for 2000+ bus cases. This work can further serve as a backbone for more comprehensive and actionable decision-making, such as reactive power planning to fix voltage issues.

</details>


### [192] [Dissipativity-Based Synthesis of Distributed Control and Communication Topology Co-Design for AC Microgrids](https://arxiv.org/abs/2511.06576)
*Mohammad Javad Najafirad,Shirantha Welikala,Lei Wu,Panos J. Antsaklis*

Main category: eess.SY

TL;DR: 提出了一种基于耗散性的分布式控制器和通信拓扑协同设计框架，用于交流微电网，同时优化控制和拓扑以实现电压频率调节和比例功率分配。


<details>
  <summary>Details</summary>
Motivation: 现有方法将控制综合和拓扑设计分开处理，无法充分利用两者的协同效应，难以应对交流微电网中耦合的dq坐标系动态和双重功率流目标。

Method: 将闭环交流微电网建模为网络化系统，利用耗散性理论建立子系统无源性条件，将协同设计问题转化为凸LMI优化问题，系统性地综合稀疏通信拓扑。

Result: 在代表性交流微电网上的仿真结果表明，该方法能有效实现精确电压调节、频率同步和比例功率分配。

Conclusion: 该框架提供了一种统一的方法来协同设计分布式控制器和通信拓扑，保证了稳定性和计算效率，适用于交流微电网的复杂动态特性。

Abstract: This paper presents a novel dissipativity-based framework for co-designing distributed controllers and communication topologies in AC microgrids (MGs). Unlike existing methods that treat control synthesis and topology design separately, we propose a unified approach that simultaneously optimizes both aspects to achieve voltage and frequency regulation and proportional power sharing among distributed generators (DGs). We formulate the closed-loop AC MG as a networked system where DGs, distribution lines, and loads are interconnected subsystems characterized by their dissipative properties. Each DG employs a hierarchical architecture combining local controllers for voltage regulation and distributed controllers for droop-free power sharing through normalized power consensus. By leveraging dissipativity theory, we establish necessary and sufficient conditions for subsystem passivity and cast the co-design problem as a convex linear matrix inequality (LMI) optimization, enabling efficient computation and guaranteed stability. Our framework systematically synthesizes sparse communication topologies while handling the coupled dq-frame dynamics and dual power flow objectives inherent to AC MGs. Simulation results on a representative AC MG demonstrate the effectiveness of the proposed approach in achieving accurate voltage regulation, frequency synchronization, and proportional power sharing.

</details>


### [193] [On the Potential of Digital Twins for Distribution System State Estimation with Randomly Missing Data in Heterogeneous Measurements](https://arxiv.org/abs/2511.06583)
*Ying Zhang,Yihao Wang,Yuanshuo Zhang,Eric Larson,Di Shi,Fanping Sui*

Main category: eess.SY

TL;DR: 提出了一种基于交互式注意力的数字孪生状态估计模型，用于处理配电网中随机数据缺失的鲁棒监测问题。


<details>
  <summary>Details</summary>
Motivation: 传统状态估计算法依赖详细电网参数和数学假设，在通信故障、网络攻击等导致数据随机缺失时容易失效，需要更鲁棒的解决方案。

Method: 集成物理实体、虚拟建模和数据融合三个核心组件，采用物理信息数据增强与迁移、基于注意力的时空特征学习以及交叉交互特征融合技术。

Result: 在真实84节点不平衡配电网上的案例研究表明，该方法在高达40%数据随机缺失情况下仍能准确估计电压状态。

Conclusion: 所提出的数字孪生模型在数据严重缺失情况下具有优异的准确性和鲁棒性，为配电网监测提供了可靠解决方案。

Abstract: Traditional statistical optimization-based state estimation (DSSE) algorithms rely on detailed grid parameters and mathematical assumptions of all possible uncertainties. Furthermore, random data missing due to communication failures, congestion, and cyberattacks, makes these methods easily infeasible. Inspired by recent advances in digital twins (DTs), this paper proposes an interactive attention-based DSSE model for robust grid monitoring by integrating three core components: physical entities, virtual modeling, and data fusion. To enable robustness against various data missing in heterogeneous measurements, we first propose physics-informed data augmentation and transfer. Moreover, a state-of-the-art attention-based spatiotemporal feature learning is proposed, followed by a novel cross-interaction feature fusion for robust voltage estimation. A case study in a real-world unbalanced 84-bus distribution system with raw data validates the accuracy and robustness of the proposed DT model in estimating voltage states, with random locational, arbitrary ratios (up to 40% of total measurements) of data missing.

</details>


### [194] [GNN-Enabled Robust Hybrid Beamforming with Score-Based CSI Generation and Denoising](https://arxiv.org/abs/2511.06663)
*Yuhang Li,Yang Lu,Bo Ai,Zhiguo Ding,Dusit Niyato,Arumugam Nallanathan*

Main category: eess.SY

TL;DR: 提出了一种基于图神经网络和基于分数的生成模型的混合波束成形方法，用于在非完美信道状态信息条件下实现鲁棒的混合波束成形。


<details>
  <summary>Details</summary>
Motivation: 在实际无线通信系统中，获取高分辨率信道状态信息具有挑战性，这影响了混合波束成形的性能。

Method: 开发了混合消息图注意力网络（HMGAT）进行节点和边特征更新，设计了基于BERT的噪声条件分数网络（NCSN）学习高分辨率CSI分布，并提出了去噪分数网络框架DeBERT来去除非完美CSI中的噪声。

Result: 在DeepMIMO城市数据集上的实验表明，所提模型在完美和非完美CSI条件下的各种混合波束成形任务中具有优越的泛化性、可扩展性和鲁棒性。

Conclusion: 该方法能够有效处理非完美CSI条件下的混合波束成形问题，提高了系统的鲁棒性和性能。

Abstract: Accurate Channel State Information (CSI) is critical for Hybrid Beamforming (HBF) tasks. However, obtaining high-resolution CSI remains challenging in practical wireless communication systems. To address this issue, we propose to utilize Graph Neural Networks (GNNs) and score-based generative models to enable robust HBF under imperfect CSI conditions. Firstly, we develop the Hybrid Message Graph Attention Network (HMGAT) which updates both node and edge features through node-level and edge-level message passing. Secondly, we design a Bidirectional Encoder Representations from Transformers (BERT)-based Noise Conditional Score Network (NCSN) to learn the distribution of high-resolution CSI, facilitating CSI generation and data augmentation to further improve HMGAT's performance. Finally, we present a Denoising Score Network (DSN) framework and its instantiation, termed DeBERT, which can denoise imperfect CSI under arbitrary channel error levels, thereby facilitating robust HBF. Experiments on DeepMIMO urban datasets demonstrate the proposed models' superior generalization, scalability, and robustness across various HBF tasks with perfect and imperfect CSI.

</details>


### [195] [F2GAN: A Feature-Feedback Generative Framework for Reliable AI-Based Fault Diagnosis in Inverter-Dominated Microgrids](https://arxiv.org/abs/2511.06677)
*Swetha Rani Kasimalla,Kuchan Park,Junho Hong,Young-Jin Kim*

Main category: eess.SY

TL;DR: 提出F2GAN框架解决逆变器主导微电网故障诊断中的数据稀缺和类别不平衡问题，通过生成高质量故障数据提升AI诊断可靠性


<details>
  <summary>Details</summary>
Motivation: 逆变器主导微电网中高保真故障数据稀缺且不平衡，特别是罕见逆变器故障和极端外部线路故障，限制了可靠模型的训练和验证

Method: 开发F2GAN（特征反馈GAN）生成模型，集成基于均值方差、相关性和特征匹配损失的多级反馈机制，系统生成内部和外部故障场景

Result: TSTR实验显示仅使用F2GAN样本训练的机器学习分类器具有强泛化能力，硬件在环平台实现100%实时诊断准确率

Conclusion: F2GAN有效弥合了模拟和真实世界微电网故障数据集之间的差距，提升了AI故障诊断的可靠性

Abstract: Enhancing the reliability of AI based fault diagnosis in inverter dominated microgrids requires diverse and statistically balanced datasets. However, the scarcity and imbalance of high fidelity fault data, especially for rare inverter malfunctions and extreme external line faults, limit dependable model training and validation. This paper introduces a unified framework that models a detailed inverter dominated microgrid and systematically generates multiple internal and external fault scenarios to mitigate data scarcity and class imbalance. An enhanced generative model called F2GAN (Feature Feedback GAN) is developed to synthesize high dimensional tabular fault data with improved realism and statistical alignment. Unlike conventional GANs, F2GAN integrates multi level feedback based on mean variance, correlation, and feature matching losses, enabling the generator to refine output distributions toward real fault feature spaces. The generated datasets are evaluated through quantitative and qualitative analyses. Train on Synthetic, Test on Real (TSTR) experiments demonstrate strong generalization of machine learning classifiers trained exclusively on F2GAN samples. The framework is validated on a hardware-in-the-loop (HIL) fault diagnosis platform integrated with a real time simulator and graphical interface, achieving 100 % diagnostic accuracy under real-time testing. Results confirm that F2GAN effectively bridges the gap between simulated and real world microgrid fault datasets

</details>


### [196] [Pareto-Improvement-Driven Opinion Dynamics Explaining the Emergence of Pluralistic Ignorance](https://arxiv.org/abs/2511.06713)
*Yuheng Luo,Chuanzhe Zhang,Qingsong Liu,Hai Zhu,Wenjun Mei*

Main category: eess.SY

TL;DR: 本文提出了一种基于多目标博弈框架的意见动力学模型，挑战了传统将多种动机聚合为单一目标的假设。模型考虑社交压力与认知失调两个独立成本，通过帕累托改进来解释多元无知现象。


<details>
  <summary>Details</summary>
Motivation: 传统意见动力学模型将多种动机聚合为单一目标，隐含假设这些动机可互换。本文挑战这一假设，认为社交压力与认知失调是两种独立动机，需要分别建模。

Method: 建立多目标博弈框架，每个个体面临两个成本：与他人意见分歧的社交压力、与感知真相偏离的认知失调。意见更新通过这两个成本间的帕累托改进实现。

Result: 模型能够解释多元无知现象的出现，分析了真相出现和流行的条件，提出了确保真相共识的初始播种策略。数值模拟显示网络密度和聚类对真相表达的影响。

Conclusion: 没有网络结构能保证真相共识如果无人初始表达真相；适度稀疏但充分混合的网络最能缓解多元无知现象。理论结果提供了清晰且非平凡的社会学洞见。

Abstract: Opinion dynamics has recently been modeled from a game-theoretic perspective, where opinion updates are captured by individuals' cost functions representing their motivations. Conventional formulations aggregate multiple motivations into a single objective, implicitly assuming that these motivations are interchangeable. This paper challenges that assumption and proposes an opinion dynamics model grounded in a multi-objective game framework. In the proposed model, each individual experiences two distinct costs: social pressure from disagreement with others and cognitive dissonance from deviation from the perceived truth. Opinion updates are modeled as Pareto improvements between these two costs. This fwork provides a parsimonious explanation for the emergence of pluralistic ignorance, where individuals may agree on something untrue even though they all know the underlying truth. We analytically characterize the model, derive conditions for the emrameergence and prevalence of the truth, and propose an initial-seeding strategy that ensures consensus on truth. Numerical simulations are conducted on how network density and clustering affect the expression of truth. Both theoretical and numerical results lead to clear and non-trivial sociological insights. For example, no network structure guarantees truthful consensus if no one initially express the truth; moderately sparse but well-mixed networks best mitigate pluralistic ignorance.

</details>


### [197] [The Wisdom of the Crowd: High-Fidelity Classification of Cyber-Attacks and Faults in Power Systems Using Ensemble and Machine Learning](https://arxiv.org/abs/2511.06714)
*Emad Abukhousa,Syed Sohail Feroz Syed Afroz,Fahad Alsaeed,Abdulaziz Qwbaiban,Saman Zonouz,A. P. Sakis Meliopoulos*

Main category: eess.SY

TL;DR: 该论文提出了一个基于机器学习的电磁暂态仿真框架，用于在4.8kHz频率下对网络攻击和物理故障进行分类，强调离线精度不能可靠反映现场性能。


<details>
  <summary>Details</summary>
Motivation: 在逆变器资源丰富的电网中，需要可靠且快速的网络攻击和物理故障分类方法，但现有方法缺乏对实时流式环境的测试验证。

Method: 使用12种ML模型（包括集成算法和MLP），在标记的时域测量数据上训练，并在实时流式环境中评估，结合周期长度平滑滤波器和置信度阈值来稳定决策。

Result: 多个模型离线精度接近完美（达99.9%），但只有MLP在流式环境下保持稳健覆盖（98-99%），集成算法虽然保持完美异常精度但频繁弃权（覆盖率为10-49%）。

Conclusion: 离线精度不能可靠指示现场准备度，需要现实测试和推理管道来确保在IBR丰富网络中可靠分类。

Abstract: This paper presents a high-fidelity evaluation framework for machine learning (ML)-based classification of cyber-attacks and physical faults using electromagnetic transient simulations with digital substation emulation at 4.8 kHz. Twelve ML models, including ensemble algorithms and a multi-layer perceptron (MLP), were trained on labeled time-domain measurements and evaluated in a real-time streaming environment designed for sub-cycle responsiveness. The architecture incorporates a cycle-length smoothing filter and confidence threshold to stabilize decisions. Results show that while several models achieved near-perfect offline accuracies (up to 99.9%), only the MLP sustained robust coverage (98-99%) under streaming, whereas ensembles preserved perfect anomaly precision but abstained frequently (10-49% coverage). These findings demonstrate that offline accuracy alone is an unreliable indicator of field readiness and underscore the need for realistic testing and inference pipelines to ensure dependable classification in inverter-based resources (IBR)-rich networks.

</details>


### [198] [Learning stabilising policies for constrained nonlinear systems](https://arxiv.org/abs/2511.06832)
*Daniele Ravasio,Danilo Saccani,Marcello Farina,Giancarlo Ferrari-Trecate*

Main category: eess.SY

TL;DR: 提出了一种双层控制方案，用于受加性干扰的约束非线性系统，结合基础控制器保证稳定性和约束满足，并通过稳定神经网络算子提升性能。


<details>
  <summary>Details</summary>
Motivation: 针对受干扰的约束非线性系统，需要在保证闭环稳定性和约束满足的同时，提升系统性能。

Method: 采用双层控制架构：基础控制器确保闭环稳定性和约束满足；额外控制分量结合内模控制原理和稳定算子（实现为稳定神经网络）来优化性能。

Result: 仿真结果表明该方法在pH中和基准测试中有效，能够在保持稳定性和约束满足的同时提升性能。

Conclusion: 所提出的控制架构能够在不影响闭环稳定性和约束满足的前提下，通过可训练的稳定神经网络有效提升系统性能。

Abstract: This work proposes a two-layered control scheme for constrained nonlinear systems represented by a class of recurrent neural networks and affected by additive disturbances. In particular, a base controller ensures global or regional closed-loop l_p-stability of the error in tracking a desired equilibrium and the satisfaction of input and output constraints within a robustly positive invariant set. An additional control contribution, derived by combining the internal model control principle with a stable operator, is introduced to improve system performance. This operator, implemented as a stable neural network, can be trained via unconstrained optimisation on a chosen performance metric, without compromising closed-loop equilibrium tracking or constraint satisfaction, even if the optimisation is stopped prematurely. In addition, we characterise the class of closed-loop stable behaviours that can be achieved with the proposed architecture. Simulation results on a pH-neutralisation benchmark demonstrate the effectiveness of the proposed approach.

</details>


### [199] [Correct-by-Design Control Synthesis of Stochastic Multi-agent Systems: a Robust Tensor-based Solution](https://arxiv.org/abs/2511.06873)
*Ruohan Wang,Siyuan Liu,Zhiyong Sun,Sofie Haesaert*

Main category: eess.SY

TL;DR: 提出基于抽象和鲁棒动态规划的框架，为连续空间离散时间随机系统提供可验证的时序逻辑控制策略，利用张量分解实现可扩展性。


<details>
  <summary>Details</summary>
Motivation: 连续空间离散时间随机系统的验证和控制困难，即使使用MDP抽象也面临维度灾难问题，需要可扩展的验证方法。

Method: 基于抽象框架，结合鲁棒动态规划映射和近似随机模拟关系，利用解耦动力学揭示值函数的规范多模分解张量结构。

Result: 在连续状态线性随机系统上验证了该方法，能够提供具有概率保证的时序逻辑规范正确性设计。

Conclusion: 所提方法通过张量分解使动态规划可扩展，为时序逻辑规范提供可证明的概率下界保证。

Abstract: Discrete-time stochastic systems with continuous spaces are hard to verify and control, even with MDP abstractions due to the curse of dimensionality. We propose an abstraction-based framework with robust dynamic programming mappings that deliver control strategies with provable lower bounds on temporal-logic satisfaction, quantified via approximate stochastic simulation relations. Exploiting decoupled dynamics, we reveal a Canonical Polyadic Decomposition tensor structure in value functions that makes dynamic programming scalable. The proposed method provides correct-by-design probabilistic guarantees for temporal logic specifications. We validate our results on continuous-state linear stochastic systems.

</details>


### [200] [Analysis of Traffic Congestion in North Campus, Delhi University Using Continuous Time Models](https://arxiv.org/abs/2511.06921)
*Siddhartha Mahajan,Harsh Raj,Sonam Tanwar*

Main category: eess.SY

TL;DR: 使用UXSim连续时间模拟分析德里大学北校区交通拥堵，通过信号配时优化和交叉口改造改善交通流


<details>
  <summary>Details</summary>
Motivation: 研究德里大学北校区的交通拥堵问题，评估传统交通管理措施的有效性

Method: 使用UXSim进行连续时间模拟，建模车辆移动和交互，重点关注关键交叉口

Result: 信号配时优化和适度交叉口重新配置在模拟中显著改善了交通流量

Conclusion: 研究为当地交通管理提供实用见解，展示了连续时间模拟方法在短期干预和长期规划中的价值

Abstract: This project investigates traffic congestion within North Campus, Delhi University (DU), using continuous time simulations implemented in UXSim to model vehicle movement and interaction. The study focuses on several key intersections, identifies recurring congestion points, and evaluates the effectiveness of conventional traffic management measures. Implementing signal timing optimization and modest intersection reconfiguration resulted in measurable improvements in simulated traffic flow. The results provide practical insights for local traffic management and illustrate the value of continuous time simulation methods for informing short-term interventions and longer-term planning.

</details>


### [201] [On the Redundant Distributed Observability of Mixed Traffic Transportation Systems](https://arxiv.org/abs/2511.06950)
*M. Doostmohammadian,U. A. Khan,N. Meskin*

Main category: eess.SY

TL;DR: 本文研究了混合交通系统中联网自动驾驶车辆对人工驾驶车辆的分布式状态估计问题，提出了分布式可观测状态空间模型，并分析了网络拓扑条件以确保分布式可观测性。


<details>
  <summary>Details</summary>
Motivation: 在混合交通系统中，联网自动驾驶车辆需要准确估计人工驾驶车辆的状态以实现安全高效的交通管理，但存在传感器故障和不可靠观测数据的挑战。

Method: 推导了分布式可观测状态空间模型，设计了分布式观测器，通过局部共享估计/观测信息，并分析了强连通网络拓扑条件和冗余分布式可观测性的q节点/链路连通网络设计。

Result: 仿真结果表明所提方法的有效性，强连通网络配合适当的观测器增益设计足以保证分布式可观测性，冗余设计可容忍一定数量的故障传感器和不可靠链路。

Conclusion: 提出的分布式状态估计方法在混合交通系统中有效，通过适当的网络拓扑设计和冗余机制，能够应对传感器故障和不可靠数据的问题。

Abstract: In this paper, the problem of distributed state estimation of human-driven vehicles (HDVs) by connected autonomous vehicles (CAVs) is investigated in mixed traffic transportation systems. Toward this, a distributed observable state-space model is derived, which paves the way for estimation and observability analysis of HDVs in mixed traffic scenarios. In this direction, first, we obtain the condition on the network topology to satisfy the distributed observability, i.e., the condition such that each HDV state is observable to every CAV via information-exchange over the network. It is shown that strong connectivity of the network, along with the proper design of the observer gain, is sufficient for this. A distributed observer is then designed by locally sharing estimates/observations of each CAV with its neighborhood. Second, in case there exist faulty sensors or unreliable observation data, we derive the condition for redundant distributed observability as a $q$-node/link-connected network design. This redundancy is achieved by extra information-sharing over the network and implies that a certain number of faulty sensors and unreliable links can be isolated/removed without losing the observability. Simulation results are provided to illustrate the effectiveness of the proposed approach.

</details>


### [202] [Capacity Estimation of Lithium-ion Batteries Using Invariance Property in Open Circuit Voltage Relationship](https://arxiv.org/abs/2511.06989)
*Yang Wang,Marta Zagorowska,Riccardo M. G. Ferrari*

Main category: eess.SY

TL;DR: 提出一种基于开路电压(OCV)的锂离子电池容量估计方法，仅需部分充放电数据即可准确估计容量，无需完整循环测试。


<details>
  <summary>Details</summary>
Motivation: 传统电池容量估计方法需要大量训练数据和完整充放电循环，成本高且耗时。需要开发更高效、成本更低的容量估计方法。

Method: 利用OCV与荷电状态关系的跨老化周期不变性，通过OCV对齐问题求解容量估计，仅需OCV和放电容量数据。

Result: 在344个老化周期的12个样本上，容量估计的平均绝对相对误差为0.85%，表现出高精度。

Conclusion: 该方法能够从动态放电数据中准确估计电池容量，无需专用测试，为电池管理系统提供了更实用的容量监测方案。

Abstract: Lithium-ion (Li-ion) batteries are ubiquitous in electric vehicles (EVs) as efficient energy storage devices. The reliable operation of Li-ion batteries depends critically on the accurate estimation of battery capacity. However, conventional estimation methods require extensive training datasets from costly battery tests for modeling, and a full cycle of charge and discharge is often needed to estimate the capacity. To overcome these limitations, we propose a novel capacity estimation method that leverages only one cycle of the open-circuit voltage (OCV) test in modeling and allows for estimating the capacity from partial charge or discharge data. Moreover, by applying it with OCV identification algorithms, we can estimate the capacity from dynamic discharge data without requiring dedicated data collection tests. We observed an invariance property in the OCV versus state of charge relationship across aging cycles. Leveraging this invariance, the proposed method estimates the capacity by solving an OCV alignment problem using only the OCV and the discharge capacity data from the battery. Simulation results demonstrate the method's efficacy, achieving a mean absolute relative error of 0.85\% in capacity estimation across 12 samples from 344 aging cycles.

</details>


### [203] [Koopman-Based Dynamic Environment Prediction for Safe UAV Navigation](https://arxiv.org/abs/2511.06990)
*Vitor Bueno,Ali Azarbahram,Marcello Farina,Lorenzo Fagiano*

Main category: eess.SY

TL;DR: 提出基于Koopman算子的MPC框架，利用实时LiDAR数据进行无人机动态环境安全导航，通过线性近似周围物体动力学实现高效准确的移动障碍物位置预测。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在动态环境中实时安全导航的挑战，特别是在存在传感器噪声、执行延迟和环境不确定性的情况下。

Method: 使用Koopman算子线性近似周围物体动力学，结合模型预测控制(MPC)进行轨迹规划，利用实时LiDAR数据进行障碍物预测。

Result: 通过仿真和ROS2-Gazebo实现验证，在传感器噪声、执行延迟和环境不确定性下表现出可靠的性能。

Conclusion: 该框架能够实现无人机在动态环境中的实时、安全导航，具有鲁棒性和实用性。

Abstract: This paper presents a Koopman-based model predictive control (MPC) framework for safe UAV navigation in dynamic environments using real-time LiDAR data. By leveraging the Koopman operator to linearly approximate the dynamics of surrounding objets, we enable efficient and accurate prediction of the position of moving obstacles. Embedding this into an MPC formulation ensures robust, collision-free trajectory planning suitable for real-time execution. The method is validated through simulation and ROS2-Gazebo implementation, demonstrating reliable performance under sensor noise, actuation delays, and environmental uncertainty.

</details>


### [204] [Beyond Phasors: Solving Non-Sinusoidal Electrical Circuits using Geometry](https://arxiv.org/abs/2511.06997)
*Javier Castillo-Martínez,Raul Baños,Francisco G. Montoya*

Main category: eess.SY

TL;DR: 本文提出了一种基于几何代数(GA)的多谐波交流电路分析方法，克服了传统相量分析仅限于单频正弦条件的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统相量分析仅限于单频正弦条件，在存在谐波时面临挑战。传统的傅里叶分解和叠加方法是一个碎片化过程，无法在频域提供统一解决方案。

Method: 使用几何代数(GA)构建完整直接的多谐波交流电路分析方法，将所有非正弦电压和电流波形表示为2N维欧几里得空间中的简单向量，通过单一的几何变换算子"rotoflex"来描述这些向量间的关系。

Result: 该方法将阻抗概念从每频率的复数集合提升为单一多向量，统一捕捉电路响应，同时统一所有谐波的幅度缩放(flextance)和相位旋转(rotance)。

Conclusion: 几何代数作为相量分析的结构统一且高效的替代方案，为电路分析提供了更严谨的基础，案例研究验证了与传统方法的完美数值一致性和优越性能。

Abstract: Classical phasor analysis is fundamentally limited to sinusoidal single-frequency conditions, which poses challenges when working in the presence of harmonics. Furthermore, the conventional solution, which consists of decomposing signals using Fourier series and applying superposition, is a fragmented process that does not provide a unified solution in the frequency domain. This paper overcomes this limitation by introducing a complete and direct approach for multi-harmonic AC circuits using Geometric Algebra (GA). In this way, all non-sinusoidal voltage and current waveforms are represented as simple vectors in a $2N$-dimensional Euclidean space. The relationship between these vectors is characterized by a single and unified geometric transformation termed the \textit{rotoflex}. This operator elevates the concept of impedance from a set of complex numbers per frequency to a single multivector that holistically captures the circuit response, while unifying the magnitude scale (flextance) and phase rotation (rotance) across all harmonics. Thus, this work establishes GA as a structurally unified and efficient alternative to phasor analysis, providing a more rigorous foundation for electrical circuit analysis. The methodology is validated through case studies that demonstrate perfect numerical consistency with traditional methods and superior performance.

</details>


### [205] [Real-Time Co-Simulation for DC Microgrid Energy Management with Communication Delays](https://arxiv.org/abs/2511.07052)
*S. Gokul Krishnan,Mohd Asim Aftab,Shehab Ahmed,Charalambos Konstantinou*

Main category: eess.SY

TL;DR: 开发了一个实时网络物理系统测试平台，用于评估直流微电网在真实通信延迟下的能量管理系统性能。


<details>
  <summary>Details</summary>
Motivation: 可再生能源在电力系统中的集成增加了对弹性微电网解决方案的需求，现有EMS研究大多假设理想通信条件或简化网络模型，忽略了真实通信延迟对EMS性能的影响。

Method: 提出集成OPAL-RT建模的直流微电网、Raspberry Pi实现的EMS控制器和EXataCPS模拟通信网络的实时CPS测试平台，能够交换实际电力系统流量并复制真实延迟条件。

Result: 该综合设置能够捕捉电力系统动态、EMS控制和通信网络行为之间的相互作用。

Conclusion: 该测试平台为评估直流微电网EMS在真实通信延迟下的性能提供了有效的解决方案。

Abstract: The growing integration of renewable energy sources (RESs) in modern power systems has intensified the need for resilient and efficient microgrid solutions. DC microgrids have gained prominence due to their reduced conversion losses, simplified interfacing with DC-based RESs, and improved reliability. To manage the inherent variability of RESs and ensure stable operation, energy management systems (EMS) have become essential. While various EMS algorithms have been proposed and validated using real-time simulation platforms, most assume ideal communication conditions or rely on simplified network models, overlooking the impact of realistic communication delays on EMS performance. This paper presents a novel real-time cyber-physical system (CPS) testbed for evaluating EMS performance in DC microgrids under realistic communication delays. The proposed testbed integrates a DC microgrid modeled in OPAL-RT with an EMS controller implemented on a Raspberry Pi (RPi). The communication network is emulated using EXataCPS, enabling the exchange of actual power system traffic and the replication of realistic latency conditions. This comprehensive setup captures the interplay between power system dynamics, EMS control, and communication network behavior.

</details>


### [206] [Structural sign herdability of linear time-invariant systems:theory and design for arbitrary network structures](https://arxiv.org/abs/2511.07054)
*Pradeep M,Twinkle Tripathy*

Main category: eess.SY

TL;DR: 本文研究了线性时不变系统的结构牧群性图论条件，提出了基于分层图表示和层间同号图的图形测试方法，能够检查任意有向图拓扑的符号结构牧群性。


<details>
  <summary>Details</summary>
Motivation: 研究符号结构牧群性在图论中的条件，应用于电力网络、生物网络、意见动态、多机器人牧群等领域。

Method: 引入有向图的分层图表示Gs，构建层间同号图LUG(Gs)及其特殊子图LUG^H(Gs)，证明系统符号结构牧群性等价于存在覆盖所有节点的LUG^H(Gs)。

Result: 提出了首个能够检查任意有向图拓扑符号结构牧群性的图形测试方法，发现在有向图中即使存在符号和层扩张，系统仍可能具有牧群性。

Conclusion: 该图论方法为分析符号结构牧群性提供了有效工具，并将结果扩展到多领导节点和驱动节点的有向图。

Abstract: The objective of this paper is to investigate graph-theoretic conditions for structural herdability of an LTI system. In particular, we are interested in the structural sign (SS) herdability of a system wherein the underlying digraph representing it is signed. Structural herdability finds applications in various domains like power networks, biological networks, opinion dynamics, multi-robot shepherding, etc. We begin the analysis by introducing a layered graph representation Gs of the signed digraph G; such a representation allows us to capture the signed distances between the nodes with ease. We construct a subgraph of G_s that characterizes paths of identical signs between layers and uniform path lengths, referred to as a layer-wise unisigned graph LUG(G_s). A special subgraph of an LUG(G_s), denoted as an LUG^H(G_s), is key to achieving SS herdability. This is because we prove that an LTI system is SS herdable if and only if there exists an LUG^H(G_s) which covers all the nodes of the given digraph. To the best of our knowledge, such a graphical test is one of the first methods which allows us to check SS herdability for arbitrary digraph topologies. Interestingly, the analysis also reveals that a system can be SS herdable even in the presence of (signed and layer) dilation in the associated digraph (note that such a behaviour has been shown to be impossible in directed trees). Additionally, we also extend these results to digraphs with multiple leader and driver nodes. In order to illustrate all the results, we present numerous examples throughout the paper.

</details>


### [207] [Characterisation and Quantification of Data Centre Flexibility for Power System Support](https://arxiv.org/abs/2511.07159)
*Mehmet Turker Takci,James Day,Meysam Qadrdan*

Main category: eess.SY

TL;DR: 本文提出了一个数据中心整体优化模型，量化数据中心对电网的灵活性贡献，包括IT负载转移、UPS储能和冷却系统的协同优化。


<details>
  <summary>Details</summary>
Motivation: 数据中心作为传统被动电力负载，具有成为电网主动参与者的潜力。为缓解电力系统压力并利用未开发的灵活性潜力，需要量化数据中心灵活性。

Method: 开发集成IT调度、UPS运行和冷却动态的运营优化模型，建立成本最优基准运行；提出持续时间感知的灵活性评估方法，计算从基准运行的最大可行持续时间。

Result: 发现灵活性提供具有明显的时间结构和显著不对称性：向上灵活性（电力负载减少）通过推迟IT工作负载实现，向下灵活性（电力负载增加）依赖冷却系统功耗增加和UPS充电。

Conclusion: 该框架将抽象的灵活性潜力转化为量化的灵活性和持续时间，系统运营商可将其用于储备、频率响应和价格响应需求等服务。

Abstract: The rapid growth of data centres poses an evolving challenge for power systems with high variable renewable energy. Traditionally operated as passive electrical loads, data centres, have the potential to become active participants that provide flexibility to the grid. However, quantifying and utilising this flexibility have not yet been fully explored. This paper presents an integrated, whole facility optimisation model to investigate the least cost operating schedule of data centres and characterise the aggregate flexibility available from data centres to the power system. The model accounts for IT workload shifting, UPS energy storage, and cooling system. Motivated by the need to alleviate the increasing strain on power systems while leveraging their untapped flexibility potential, this study makes two primary contributions: (i) an operational optimisation model that integrates IT scheduling, UPS operation, and cooling dynamics to establish a cost optimal baseline operation, and (ii) a duration-aware flexibility assessment that, for any given start time and power deviation, computes the maximum feasible duration from this baseline while respecting all operational, thermal, and recovery constraints. This method characterises the aggregate flexibility envelope. Results reveal a clear temporal structure and a notable asymmetry in flexibility provision: upward flexibility (electricity load reduction) is driven by deferring IT workload, which allows for a secondary reduction in cooling power. Downward flexibility (electricity load increase) relies on increasing power consumption of the cooling system, supported by the TES buffer, and charging the UPS. This framework translates abstract flexibility potential into quantified flexibility magnitude and duration that system operators could investigate for use in services such as reserve, frequency response, and price responsive demand.

</details>


### [208] [Beyond Gaussian Assumptions: A General Fractional HJB Control Framework for Lévy-Driven Heavy-Tailed Channels in 6G](https://arxiv.org/abs/2511.07167)
*Mengqi Li,Lixin Li,Wensheng Lin,Zhu Han,Tamer Başar*

Main category: eess.SY

TL;DR: 提出基于对称α稳定Lévy过程的无线信道模型和分数阶HJB控制框架，用于优化6G系统在非高斯非平稳信道中的传输功率控制。


<details>
  <summary>Details</summary>
Motivation: 6G无线系统在高速列车穿越密集城区和无人机山地链路等挑战性环境中性能严重下降，这些场景具有重尾衰落和突发信号波动的非高斯非平稳信道特性。

Method: 基于对称α稳定Lévy过程建立无线信道模型，开发包含Riesz分数阶算子的分数阶Hamilton-Jacobi-Bellman方程控制框架，以捕捉非局部空间效应和记忆相关动态。

Result: 严格证明了分数阶HJB方程粘性解的存在性和唯一性，在多小区多用户下行链路场景的数值仿真中，基于分数阶HJB的策略在重尾共信道和多用户干扰下有效优化了传输功率。

Conclusion: 所提出的分数阶HJB控制框架为6G系统在挑战性环境中的性能优化提供了理论有效且实用的解决方案。

Abstract: Emerging 6G wireless systems suffer severe performance degradation in challenging environments like high-speed trains traversing dense urban corridors and Unmanned Aerial Vehicles (UAVs) links over mountainous terrain. These scenarios exhibit non-Gaussian, non-stationary channels with heavy-tailed fading and abrupt signal fluctuations. To address these challenges, this paper proposes a novel wireless channel model based on symmetric $α$-stable Lévy processes, thereby enabling continuous-time state-space characterization of both long-term and short-term fading. Building on this model, a generalized optimal control framework is developed via a fractional Hamilton-Jacobi-Bellman (HJB) equation that incorporates the Riesz fractional operator to capture non-local spatial effects and memory-dependent dynamics. The existence and uniqueness of viscosity solutions to the fractional HJB equation are rigorously established, thus ensuring the theoretical validity of the proposed control formulation. Numerical simulations conducted in a multi-cell, multi-user downlink setting demonstrate the effectiveness of the fractional HJB-based strategy in optimizing transmission power under heavy-tailed co-channel and multi-user interference.

</details>


### [209] [Fair and Efficient allocation of Mobility-on-Demand resources through a Karma Economy](https://arxiv.org/abs/2511.07225)
*Matteo Cederle,Saverio Bolognani,Gian Antonio Susto*

Main category: eess.SY

TL;DR: 提出了一种基于Karma的非货币机制，模拟用户内生紧迫性，在保持效率的同时实现公平的资源分配。


<details>
  <summary>Details</summary>
Motivation: 现有按需出行系统加剧了社会经济不平等，且现有公平性框架忽视了用户紧迫性的时空变化特性。

Method: 开发了理论框架，在经典Karma经济基础上建模内生紧迫性，让用户时间敏感性随系统条件和外部因素动态演化。

Result: 在模拟按需出行场景中，该框架实现了高系统效率，同时保证了用户的公平资源分配。

Conclusion: Karma机制能够有效平衡效率和公平，为按需出行系统提供更现实的用户行为建模方法。

Abstract: Mobility-on-demand systems like ride-hailing have transformed urban transportation, but they have also exacerbated socio-economic inequalities in access to these services, also due to surge pricing strategies. Although several fairness-aware frameworks have been proposed in smart mobility, they often overlook the temporal and situational variability of user urgency that shapes real-world transportation demands. This paper introduces a non-monetary, Karma-based mechanism that models endogenous urgency, allowing user time-sensitivity to evolve in response to system conditions as well as external factors. We develop a theoretical framework maintaining the efficiency and fairness guarantees of classical Karma economies, while accommodating this realistic user behavior modeling. Applied to a simulated mobility-on-demand scenario we show that our framework is able to achieve high levels of system efficiency, guaranteeing at the same time equitable resource allocation for the users.

</details>


### [210] [Beyond Prime Farmland: Solar Siting Tradeoffs for Cost-Effective Decarbonization](https://arxiv.org/abs/2511.07323)
*Papa Yaw Owusu-Obeng,Mai Shi,Max Vanatta,Michael T. Craig*

Main category: eess.SY

TL;DR: 本研究量化了美国东部地区不同土地类型（绿地、棕地、屋顶）上太阳能光伏部署的成本和技术潜力权衡，发现绿地的成本最低，棕地技术潜力有限且成本较高，屋顶光伏成本最高但技术潜力足够。


<details>
  <summary>Details</summary>
Motivation: 随着对绿地（如优质农田）使用的抵制和政策关注增加，需要量化不同土地类型上太阳能光伏部署的成本和技术潜力之间的权衡，以平衡部署目标和土地使用冲突。

Method: 为美国东部互联电网区域的约2400个县建立了按土地类型分类的太阳能光伏供应曲线数据库，量化了绿地、棕地和屋顶土地类型的技术潜力与平准化成本，并使用2035年太阳能部署目标（435 GW）来评估不同土地类型优先部署情景下的成本和容量权衡。

Result: 绿地（特别是优质农田）提供最低的平准化成本（39-57美元/兆瓦时）；受污染土地技术潜力有限，成本比绿地高14-33%；屋顶光伏技术潜力足够但成本较高，最低平准化成本约70美元/兆瓦时，远高于最高成本的绿地。

Conclusion: 研究结果揭示了美国东部地区异质性的选址权衡，为制定有针对性的政策提供了依据，以在平衡成本和土地使用冲突的同时实现部署目标。

Abstract: The feasibility and cost-effectiveness of continued growth in solar photovoltaics are closely tied to siting decisions. But trade-offs between costs and technical potential between land categories, especially brownfields and rooftop sites, have not been quantified, despite increasing resistance to and policy interest in reducing use of greenfield sites (e.g., prime agricultural lands). We examine the effect of siting decisions across land types for utility-scale and rooftop PV on the feasibility and cost of meeting solar deployment targets across the Eastern U.S. We build a database of solar PV supply curves by land type for each county in the Eastern Interconnect (EI) region (~2,400 counties). Our supply curves quantify technical potential versus levelized cost across greenfield, brownfield, and rooftop land types. With these supply curves and a 2035 solar deployment target (435 GW) aligned with a decarbonized power system, we quantify cost and capacity trade-offs using scenarios that prioritize solar PV deployment on different land types. We find greenfield, particularly prime agriculture, sites offer the lowest levelized costs for meeting capacity targets, of 39 to 57 $/MWh. Contaminated lands, often prioritized in policy to reduce land use conflict, have limited technical potential and impose a cost premium of 14-33% relative to greenfield sites. Rooftop PV provides enough technical potential for meeting capacity targets but comes at consistently higher costs, with minimum LCOEs of roughly 70 $/MWh or well above the highest-cost greenfield sites. Our results detail heterogeneous siting trade-offs across the Eastern United States, enabling targeted policy design to meet deployment targets while balancing costs and land use conflicts.

</details>


### [211] [Robust Linear Design for Flight Control Systems with Operational Constraints](https://arxiv.org/abs/2511.07335)
*Marcel Menner,Eugene Lavretsky*

Main category: eess.SY

TL;DR: 提出一种设计鲁棒线性PI伺服控制器的方法，能有效处理飞行控制系统中的控制输入和输出约束，保证约束满足并维持系统的可分析性。


<details>
  <summary>Details</summary>
Motivation: 传统控制器在处理约束时通常采用硬饱和启发式方法，这会导致在约束激活时性能显著下降。需要一种能保证约束满足同时维持鲁棒性的系统化方法。

Method: 利用Nagumo定理和比较引理证明约束满足，采用类似于控制屏障函数的最小范数最优控制器，生成连续分段线性状态反馈策略。

Result: MIMO裕度分析显示，该方法在约束激活时仍能保持与无约束情况相当的增益和相位裕度，而传统硬饱和控制器则性能显著下降。非线性六自由度刚体飞机模型仿真验证了方法的有效性。

Conclusion: 所提出的控制设计框架能够实现约束满足、鲁棒性和有效的抗饱和保护，适用于现实世界安全关键的飞机控制场景。

Abstract: This paper presents a systematic approach for designing robust linear proportional-integral (PI) servo-controllers that effectively manage control input and output constraints in flight control systems. The control design leverages the Nagumo Theorem and the Comparison Lemma to prove constraint satisfaction, while employing min-norm optimal controllers in a manner akin to Control Barrier Functions. This results in a continuous piecewise-linear state feedback policy that maintains the analyzability of the closed-loop system through the principles of linear systems theory. Additionally, we derive multi-input multi-output (MIMO) robustness margins, demonstrating that our approach enables robust tracking of external commands even in the presence of operational constraints. Moreover, the proposed control design offers a systematic approach for anti-windup protection. Through flight control trade studies, we illustrate the applicability of the proposed framework to real-world safety-critical aircraft control scenarios. Notably, MIMO margin analysis with active constraints reveals that our method preserves gain and phase margins comparable to those of the unconstrained case, in contrast to controllers that rely on hard saturation heuristics, which suffer significant performance degradation under active constraints. Simulation results using a nonlinear six-degree-of-freedom rigid body aircraft model further validate the effectiveness of our method in achieving constraint satisfaction, robustness, and effective anti-windup protection.

</details>


### [212] [When the Correct Model Fails: The Optimality of Stackelberg Equilibria with Follower Intention Updates](https://arxiv.org/abs/2511.07363)
*Cayetana Salinas Rodriguez,Jonathan Rogers,Sarah H. Q. Li*

Main category: eess.SY

TL;DR: 研究领导者与跟随者之间的动态Stackelberg博弈，其中领导者在不知道跟随者最佳响应函数的情况下，需要同时推断该函数并优化自身目标。分析了在有限决策周期内，领导者根据更新的信念重新优化控制策略时的最优性保证。


<details>
  <summary>Details</summary>
Motivation: 经典的Stackelberg均衡假设领导者知道跟随者的最佳响应映射，但这在实践中并不总是成立。因此需要研究领导者在同时推断跟随者最佳响应函数并优化自身目标的情况下的博弈策略。

Method: 研究领导者选择控制策略来优化目标函数，同时基于对跟随者最佳响应的初始信念进行决策。在有限决策周期内，信念会更新，促使领导者重新优化控制。分析了开环和反馈信息结构下的最优性保证。

Result: 研究表明，在某些情况下，假设错误的跟随者最佳响应映射可能在整个博弈周期内获得比知道真实最佳响应更低的成本。通过线性二次Stackelberg博弈的数值例子支持了这一发现。

Conclusion: 在动态Stackelberg博弈中，领导者对跟随者最佳响应函数的不完美知识可能带来更好的性能，这挑战了传统关于完全信息假设的直觉。

Abstract: We study a two-player dynamic Stackelberg game between a leader and a follower. Classical formulations of the Stackelberg equilibrium (SE) assume that the follower's best response (BR) mapping is known to the leader. However, this is not always true in practice. In those cases the leader needs to simultaneously infer this BR function while fulfilling an internal objective. We study a setting in which the leader selects a control strategy that optimizes an objective given an initial belief about the follower's best response. This belief is updated during the finite decision horizon, prompting the leader to reoptimize its control. We characterize the optimality guarantees of the SE solutions under this belief update for both open loop (OL) and feedback (FB) information structures. In particular, we show that it is possible that assuming an incorrect follower BR map obtains a lower cost over the game horizon than knowing the true BR. We support these claims with numerical examples in a linear quadratic (LQ) Stackelberg game.

</details>


### [213] [From Failure Modes to Reliability Awareness in Generative and Agentic AI System](https://arxiv.org/abs/2511.05511)
*Janet,Lin,Liangwei Zhang*

Main category: eess.SY

TL;DR: 本文提出了11层故障栈框架来识别生成式和智能AI系统的脆弱性，并开发了意识映射概念来量化组织对AI可靠性风险的认知水平，将其整合到以可靠性为中心的资产管理中。


<details>
  <summary>Details</summary>
Motivation: 解决生成式和智能AI系统中从硬件到智能推理的多层次故障传播问题，提升组织对AI可靠性风险的认知和准备能力。

Method: 采用11层故障栈框架分析脆弱性，开发意识映射成熟度框架量化风险认知，并整合到以可靠性为中心的资产管理(DCAM)中。

Result: 建立了从分层故障到意识水平的连接，提供了既可作为测量工具又可作为可信AI部署路线图的综合方法。

Conclusion: 意识映射不仅是诊断工具，更是AI治理的战略输入，为关键任务领域可信和可持续的AI部署提供指导。

Abstract: This chapter bridges technical analysis and organizational preparedness by tracing the path from layered failure modes to reliability awareness in generative and agentic AI systems. We first introduce an 11-layer failure stack, a structured framework for identifying vulnerabilities ranging from hardware and power foundations to adaptive learning and agentic reasoning. Building on this, the chapter demonstrates how failures rarely occur in isolation but propagate across layers, creating cascading effects with systemic consequences. To complement this diagnostic lens, we develop the concept of awareness mapping: a maturity-oriented framework that quantifies how well individuals and organizations recognize reliability risks across the AI stack. Awareness is treated not only as a diagnostic score but also as a strategic input for AI governance, guiding improvement and resilience planning. By linking layered failures to awareness levels and further integrating this into Dependability-Centred Asset Management (DCAM), the chapter positions awareness mapping as both a measurement tool and a roadmap for trustworthy and sustainable AI deployment across mission-critical domains.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [214] [Exploration of Enterprise Big Data Microservice Architecture Based on Domain-Driven Design (DDD)](https://arxiv.org/abs/2511.05880)
*Yiru Zhang*

Main category: cs.SI

TL;DR: 提出基于微服务架构的企业大数据处理平台解决方案，采用领域驱动设计方法分解核心业务，通过改进的动态调度算法优化数据采集效率。


<details>
  <summary>Details</summary>
Motivation: 传统单体架构在业务扩展和数据量增加时面临高耦合、可扩展性有限和数据采集效率下降的问题，无法满足复杂需求。

Method: 使用领域驱动设计方法将核心业务逻辑分解为独立微服务模块，设计基于微服务的自动化数据采集流程，并提出改进的动态调度算法来分配数据采集任务。

Result: 平台实施和测试验证了基于微服务架构的企业大数据处理平台在可扩展性、数据质量和采集效率方面有显著提升。

Conclusion: 微服务架构结合领域驱动设计能够有效解决企业大数据处理平台的可扩展性和效率问题，实现数据采集、解析、清洗和可视化功能的独立开发部署。

Abstract: With the rapid advancement of digitization and intelligence, enterprise big data processing platforms have become increasingly important in data management. However, traditional monolithic architectures, due to their high coupling, are unable to cope with increasingly complex demands in the face of business expansion and increased data volume, resulting in limited platform scalability and decreased data collection efficiency. This article proposes a solution for enterprise big data processing platform based on microservice architecture, based on the concept of Domain Driven Design (DDD). Through in-depth analysis of business requirements, the functional and non functional requirements of the platform in various scenarios were determined, and the DDD method was used to decompose the core business logic into independent microservice modules, enabling data collection, parsing, cleaning, and visualization functions to be independently developed, deployed, and upgraded, thereby improving the flexibility and scalability of the system. This article also designs an automated data collection process based on microservices and proposes an improved dynamic scheduling algorithm to efficiently allocate data collection tasks to Docker nodes, and monitor the collection progress and service status in real time to ensure the accuracy and efficiency of data collection. Through the implementation and testing of the platform, it has been verified that the enterprise big data processing platform based on microservice architecture has significantly improved scalability, data quality, and collection efficiency.

</details>


### [215] [Construction and Evolutionary Analysis of a Game Model for Supply Chain Finance Funding Based on Blockchain Technology](https://arxiv.org/abs/2511.05891)
*Linwei Wu*

Main category: cs.SI

TL;DR: 本文构建了融合区块链技术的供应链金融运作框架和演化博弈模型，分析了区块链技术对供应链金融交易完成条件的影响。


<details>
  <summary>Details</summary>
Motivation: 当前中国供应链金融面临信息不对称和信用传递链条低效等障碍，阻碍了其长期发展，需要探索新技术解决方案。

Method: 设计区块链技术融合的供应链金融运作框架，构建基于演化博弈理论的融资博弈模型，分析均衡点稳定性。

Result: 探索了中小企业、核心企业和融资机构在框架下的演化均衡策略选择，研究了区块链技术对交易完成条件的影响。

Conclusion: 区块链技术能够改善供应链金融中的信息不对称问题，为供应链金融的长期发展提供技术支持。

Abstract: The current surge in supply chain finance has significantly alleviated the "capital challenges" faced by domestic related enterprises, enabling enterprises upstream and subsequent stages of the industrial chain to achieve effective circulation of financing services in the supply chain based on the credit of core enterprises. By gathering essential information from the heart of the supply chain, supply chain financing enables efficient resource distribution and aids all stakeholders in making well-informed choices. However, supply chain finance in China still faces numerous obstacles, such as information asymmetry and inefficient credit transmission chains, hindering its long-term development. This paper designs an operational framework for supply chain finance incorporating blockchain technology, clearly defines the participating entities, and analyzes their business relationships. Based upon evolutionary game theory, a supply chain finance financing game model incorporating blockchain technology is constructed. A comparative analysis of the model's equilibrium points and their stability is conducted. The choices of evolutionary equilibrium strategies adopted by small and medium-sized enterprises, key players, and financing entities within this framework are explored, and the influence of blockchain technology on the prerequisites for completing supply chain finance transactions is investigated.

</details>


### [216] [Research On CODP Localization Decision Model Of Automotive Supply Chain Based On Delayed Manufacturing Strategy](https://arxiv.org/abs/2511.05899)
*Junchun Ding*

Main category: cs.SI

TL;DR: 本研究基于延迟响应制造策略，构建了适用于汽车制造场景的订单响应节点配置模型，旨在平衡柔性生产与成本控制，为汽车制造企业在需求多变环境下实现资源优化配置提供决策支持。


<details>
  <summary>Details</summary>
Motivation: 传统标准化大规模生产模式难以满足客户对差异化和快速交付的双重期望，汽车制造商需要构建兼顾成本与柔性的生产系统以提升资源配置效率和市场响应能力。

Method: 采用函数拟合和仿真分析方法，结合数学建模工具，构建订单响应节点配置模型，综合考虑工艺调整带来的结构性成本变化、不同阶段单位制造成本和中间库存成本的动态特性，并引入交付时间约束。

Result: 通过实际企业案例验证了模型结构和求解的合理性与有效性，系统描述了总成本变化趋势。

Conclusion: 研究成果为汽车制造企业在需求多变环境下实现柔性生产与成本控制的协同提供了理论依据和决策支持，并为后续相关策略的实施路径和系统优化提供了实证参考。

Abstract: Under the market background of increasingly personalized product demand and compressed response cycle, the traditional manufacturing model with standardized mass production as the core has been difficult to meet the dual expectations of customers for differentiation and fast delivery. In order to improve the efficiency of resource allocation and market response, automobile manufacturers need to build a production system that takes into account cost and flexibility. Based on the delayed response manufacturing strategy, this study built an order response node configuration model suitable for automotive manufacturing scenarios, focusing on the positioning of order driven intervention points in the production process. The model comprehensively considers the structural cost changes brought by process adjustment, the dynamic characteristics of the changes of unit manufacturing cost and intermediate inventory cost at different stages with the location of nodes, and introduces delivery time constraints to embed time factors into the inventory decision logic to enhance the practicality of the model and the adaptation of realistic constraints. In terms of solution methods, this paper adopts function fitting and simulation analysis methods, combined with mathematical modeling tools, systematically describes the change trend of total cost, and verifies the rationality and effectiveness of the model structure and solution through actual enterprise cases. The research results provide a theoretical basis and decision support for automobile manufacturing enterprises to realize the synergy of flexible production and cost control in the environment of variable demand, and also provide an empirical reference for the implementation path and system optimization of subsequent relevant strategies.

</details>


### [217] [The Role and Mechanism of Deep Statistical Machine Learning In Biological Target Screening and Immune Microenvironment Regulation of Asthma](https://arxiv.org/abs/2511.05904)
*Pengwei Zhu*

Main category: cs.SI

TL;DR: 本研究结合计算机辅助药物设计和深度学习方法筛选PDE4/PDE7天然抑制剂，并通过酶活性实验验证，旨在开发安全有效的双靶点抑制剂治疗炎症性疾病。


<details>
  <summary>Details</summary>
Motivation: 天然产物具有丰富的生物活性，但样品数量有限且结构复杂限制了先导化合物的快速发现。PDE4和PDE7在治疗慢性阻塞性肺病和哮喘等炎症性疾病中具有重要应用潜力，但PDE4抑制剂可能引起不良反应，因此开发安全有效的双靶点抑制剂尤为重要。

Method: 采用药效团技术进行虚拟筛选，结合分子对接技术提高准确性，通过分子动力学模拟验证结合稳定性，最终筛选出16个潜在的PDE4/PDE7天然抑制剂。

Result: 成功筛选出16个潜在的PDE4/PDE7天然抑制剂，并通过酶活性实验和酶联免疫吸附测定验证了其活性。

Conclusion: 本研究为建立高效的双靶点抑制剂筛选系统和探索新型XO抑制剂先导化合物奠定了基础。

Abstract: As an important source of small molecule drugs, natural products show remarkable biological activities with their rich types and unique structures. However, due to the limited number of samples and structural complexity, the rapid discovery of lead compounds is limited. Therefore, in this study, natural inhibitors of phosphodiesterase 4 (PDE4) and Phosphodiesterase 7 (PDE7) were screened by combining computer aided drug design (CADD) technology and deep learning method, and their activities were verified by enzyme activity experiment and enzymo-linked immunoassay. These two enzymes have important application potential in the treatment of inflammatory diseases such as chronic obstructive pulmonary disease and asthma, but PDE4 inhibitors may cause adverse reactions, so it is particularly important to develop both effective and safe dual-target inhibitors. In addition, as a potential target of hyperuricemia, the development of natural inhibitors of xanthine oxidase (X0) is also of great value. We used pharmacophore technology for virtual screening, combined with molecular docking technology to improve accuracy, and finally selected 16 potential natural inhibitors of PDE4/7, and verified their binding stability through molecular dynamics simulation. The results of this study laid a foundation for establishing an efficient dual-target inhibitor screening system and exploring the lead compounds of novel X0 inhibitors.

</details>


### [218] [Characterizing AI Manipulation Risks in Brazilian YouTube Climate Discourse](https://arxiv.org/abs/2511.06091)
*Wenchao Dong,Marcelo S. Locatelli,Virgilio Almeida,Meeyoung Cha*

Main category: cs.SI

TL;DR: 本研究分析了巴西YouTube上关于气候变化的讨论，通过三个案例研究探讨了心理内容特征如何影响受众参与度、内容流行度，以及如何利用生成式语言模型设计有说服力的合成宣传活动。


<details>
  <summary>Details</summary>
Motivation: 气候变化对全球公共卫生、粮食安全和经济稳定构成威胁，需要基于证据的政策制定和对公众威胁感知的理解，特别是在视觉社交媒体上，各种声音快速塑造着气候叙事。

Method: 通过三个案例研究，分析巴西YouTube上226K视频和2.7M用户评论，包括心理内容特征、说服策略、心理理论分类和内容创作者类型学的细粒度标注。

Result: 识别了驱动受众参与的最有效心理内容特征，以及这些特征对内容流行度的影响程度，并展示了如何利用生成式语言模型设计有说服力的合成宣传活动。

Conclusion: 研究提供了关于数字气候传播的重要见解，并发布了大型公开数据集，支持未来对算法放大叙事和生成媒体的伦理风险研究。

Abstract: Climate change poses a global threat to public health, food security, and economic stability. Addressing it requires evidence-based policies and a nuanced understanding of how the threat is perceived by the public, particularly within visual social media, where narratives quickly evolve through voices of individuals, politicians, NGOs, and institutions. This study investigates climate-related discourse on YouTube within the Brazilian context, a geopolitically significant nation in global environmental negotiations. Through three case studies, we examine (1) which psychological content traits most effectively drive audience engagement, (2) the extent to which these traits influence content popularity, and (3) whether such insights can inform the design of persuasive synthetic campaigns--such as climate denialism--using recent generative language models. Another contribution of this work is the release of a large publicly available dataset of 226K Brazilian YouTube videos and 2.7M user comments on climate change. The dataset includes fine-grained annotations of persuasive strategies, theory-of-mind categorizations in user responses, and typologies of content creators. This resource can help support future research on digital climate communication and the ethical risk of algorithmically amplified narratives and generative media.

</details>


### [219] [HyperEF 2.0: Spectral Hypergraph Coarsening via Krylov Subspace Expansion and Resistance-based Local Clustering](https://arxiv.org/abs/2511.06600)
*Hamed Sajadinia,Zhuo Feng*

Main category: cs.SI

TL;DR: HyperEF 2.0是一个可扩展的框架，通过超边有效电阻进行大规模超图的谱粗化和聚类，将超图分解为具有少量簇间超边的多个节点簇。


<details>
  <summary>Details</summary>
Motivation: 旨在改进超图粗化和聚类方法，通过更准确地近似有效电阻、平衡聚类以及集成到多级超图划分工具中，提升划分质量和效率。

Method: 利用扩展的Krylov子空间（结合团和星扩展）提高有效电阻近似精度；提出基于电阻的局部聚类方案合并孤立节点；集成电阻加权和社区检测到多级划分工具。

Result: 在真实VLSI基准测试中，HyperEF 2.0能更有效地粗化超图而不损害结构特性，相比HyperEF、HyperSF等方法获得更好的电导率；相比hMETIS、SpecPart等划分器实现更小的割尺寸；运行时间比HyperSF快4.5倍。

Conclusion: HyperEF 2.0在超图粗化和划分方面实现了最先进的性能，兼具高效性和高质量的划分结果。

Abstract: This paper introduces HyperEF 2.0, a scalable framework for spectral coarsening and clustering of large-scale hypergraphs through hyperedge effective resistances, aiming to decompose hypergraphs into multiple node clusters with a small number of inter-cluster hyperedges. Building on the recent HyperEF framework, our approach offers three primary contributions. Specifically, first, by leveraging the expanded Krylov subspace exploiting both clique and star expansions of hyperedges, we can significantly improve the approximation accuracy of effective resistances. Second, we propose a resistance-based local clustering scheme for merging small isolated nodes into nearby clusters, yielding more balanced clusters with substantially improved conductance. Third, the proposed HyperEF 2.0 enables the integration of resistance-based hyperedge weighting and community detection into a multilevel hypergraph partitioning tool, achieving state-of-the-art performance. Extensive experiments on real-world VLSI benchmarks show that HyperEF 2.0 can more effectively coarsen hypergraphs without compromising their structural properties, while delivering much better solution quality (e.g. conductance) than the state-of-the-art hypergraph coarsening methods, such as HyperEF and HyperSF. Moreover, compared to leading hypergraph partitioners such as hMETIS, SpecPart, MedPart, and KaHyPar, our framework consistently achieves smaller cut sizes. In terms of runtime, HyperEF 2.0 attains up to a 4.5x speedup over the latest flow-based local clustering algorithm, HyperSF, demonstrating both superior efficiency and partitioning quality.

</details>


### [220] [Beyond Centrality: Understanding Urban Street Network Typologies Through Intersection Patterns](https://arxiv.org/abs/2511.06747)
*Anu Kuncheria,Joan L. Walker,Jane Macfarlane*

Main category: cs.SI

TL;DR: 本研究提出了一种基于交叉口角度特征的新指标，对旧金山湾区100多个城市进行道路网络分类，识别出网格状、正交状和有机状三种城市类型。


<details>
  <summary>Details</summary>
Motivation: 现有研究往往忽视单一大型城市区域内的详细特征，且大多使用度、中心性等传统指标，缺乏对交叉口层面几何角度的分析，无法捕捉道路网络的细微特征。

Method: 引入基于交叉口角度的新型分类指标，区分不同类型的3路和4路交叉口，并应用机器学习聚类算法对城市进行分类。

Result: 在旧金山湾区识别出三种不同的城市类型：网格状、正交状和有机状，验证了新指标在捕捉城市街道和交叉口模式差异方面的有效性。

Conclusion: 该分类方法可为城市规划者和政策制定者提供有价值的支持，帮助制定针对不同道路网络复杂性的实用策略，如疏散计划、交通标志设置和信号控制等。

Abstract: The structure of road networks plays a pivotal role in shaping transportation dynamics. It also provides insights into how drivers experience city streets and helps uncover each urban environment's unique characteristics and challenges. Consequently, characterizing cities based on their road network patterns can facilitate the identification of similarities and differences, informing collaborative traffic management strategies, particularly at a regional scale. While previous studies have investigated global network patterns for cities, they have often overlooked detailed characterizations within a single large urban region. Additionally, most existing research uses metrics like degree, centrality, orientation, etc., and misses the nuances of street networks at the intersection level, specifically the geometric angles formed by links at intersections, which could offer a more refined feature for characterization. To address these gaps, this study examines over 100 cities in the San Francisco Bay Area. We introduce a novel metric for classifying intersections, distinguishing between different types of 3-way and 4-way intersections based on the angles formed at the intersections. Through the application of clustering algorithms in machine learning, we have identified three distinct typologies - grid, orthogonal, and organic cities - within the San Francisco Bay Area. We demonstrate the effectiveness of the metric in capturing the differences between cities based on street and intersection patterns. The typologies generated in this study could offer valuable support for city planners and policymakers in crafting a range of practical strategies tailored to the complexities of each city's road network, covering aspects such as evacuation plans, traffic signage placements, and traffic signal control.

</details>


### [221] [CGLE: Class-label Graph Link Estimator for Link Prediction](https://arxiv.org/abs/2511.06982)
*Ankit Mazumder,Srikanta Bedathur*

Main category: cs.SI

TL;DR: CGLE是一个增强GNN链接预测的新框架，通过构建类别条件链接概率矩阵来整合语义信息，在保持计算效率的同时显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有GNN模型往往忽略类别级别的语义信息，限制了链接预测的性能。

Method: 构建类别条件链接概率矩阵，将其与GNN结构嵌入拼接，通过MLP进行最终预测，所有逻辑封装在预处理阶段。

Result: 在多个基准数据集上显著优于基线方法，在Pubmed和DBLP上HR@100提升超过10个百分点，在Chameleon上MRR提升超过4%。

Conclusion: 整合全局数据驱动的语义先验是提升链接预测性能的有效方法，为追求复杂模型架构提供了有吸引力的替代方案。

Abstract: Link prediction is a pivotal task in graph mining with wide-ranging applications in social networks, recommendation systems, and knowledge graph completion. However, many leading Graph Neural Network (GNN) models often neglect the valuable semantic information aggregated at the class level. To address this limitation, this paper introduces CGLE (Class-label Graph Link Estimator), a novel framework designed to augment GNN-based link prediction models. CGLE operates by constructing a class-conditioned link probability matrix, where each entry represents the probability of a link forming between two node classes. This matrix is derived from either available ground-truth labels or from pseudo-labels obtained through clustering. The resulting class-based prior is then concatenated with the structural link embedding from a backbone GNN, and the combined representation is processed by a Multi-Layer Perceptron (MLP) for the final prediction. Crucially, CGLE's logic is encapsulated in an efficient preprocessing stage, leaving the computational complexity of the underlying GNN model unaffected. We validate our approach through extensive experiments on a broad suite of benchmark datasets, covering both homophilous and sparse heterophilous graphs. The results show that CGLE yields substantial performance gains over strong baselines such as NCN and NCNC, with improvements in HR@100 of over 10 percentage points on homophilous datasets like Pubmed and DBLP. On sparse heterophilous graphs, CGLE delivers an MRR improvement of over 4% on the Chameleon dataset. Our work underscores the efficacy of integrating global, data-driven semantic priors, presenting a compelling alternative to the pursuit of increasingly complex model architectures. Code to reproduce our findings is available at: https://github.com/data-iitd/cgle-icdm2025.

</details>


### [222] [Past-aware game-theoretic centrality in complex contagion dynamics](https://arxiv.org/abs/2511.07157)
*Francesco Zigliotto*

Main category: cs.SI

TL;DR: 提出了一种考虑历史协作的博弈论中心性度量方法，用于识别网络中节点的协作贡献，并应用于复杂传染动态中的影响力最大化问题。


<details>
  <summary>Details</summary>
Motivation: 现有中心性度量方法未能充分考虑节点在历史协作中的贡献，特别是在复杂传染动态中需要多个邻居强化的传播过程。

Method: 扩展了标准博弈论中心性计算框架，引入过去感知的博弈论中心性，推导出计算高效的显式公式，开发了可扩展的算法。

Result: 新方法在大多数情况下在效率和解决方案质量上都优于标准贪婪方法，能够更有效地识别最有影响力的节点。

Conclusion: 过去感知的博弈论中心性为复杂网络中的影响力最大化问题提供了更有效的解决方案，特别是在需要多邻居强化的传播场景中。

Abstract: In this paper, we introduce past-aware game-theoretic centrality, a class of centrality measures that captures the collaborative contribution of nodes in a network, accounting for both uncertain and certain collaborators. A general framework for computing standard game-theoretic centrality is extended to the past-aware case. As an application, we develop a new heuristic for different versions of the influence maximization problems in complex contagion dynamics, which models processes requiring reinforcement from multiple neighbors to spread. A computationally efficient explicit formula for the corresponding past-aware centrality score is derived, leading to scalable algorithms for identifying the most influential nodes, which in most cases outperform the standard greedy approach in both efficiency and solution quality.

</details>


### [223] [Food as Soft Power: Taiwanese Gastrodiplomacy on Social Media and Algorithmic Suppression](https://arxiv.org/abs/2511.05729)
*Andrew Yen Chang,Ho-Chun Herbert Chang*

Main category: cs.SI

TL;DR: 本研究通过分析Instagram上107,169个关于台湾美食的帖子，发现珍珠奶茶是台湾美食在社交媒体上的主导代表，但存在算法压制问题——提及台湾的珍珠奶茶帖子曝光率降低约12倍，且在2024年5月赖清德就职后相关帖子和互动显著下降。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台在数字时代已成为投射国家认同和软实力的重要渠道。本研究旨在探讨台湾美食外交在数字平台上的表现，特别是通过珍珠奶茶这一文化标志性饮品，来理解社交媒体如何促进关于台湾美食的讨论并贡献于台湾的数字软实力。

Method: 研究使用Instagram平台的数据集，包含2020-2024五年间的107,169个帖子、315,279,227次互动、4,756,320条评论和8,097,260,651次观看，分析珍珠奶茶作为台湾美食代表的社交媒体表现。

Result: 珍珠奶茶在Instagram上持续成为台湾美食的主导代表，但研究发现Instagram对提及台湾的珍珠奶茶帖子存在约1200%的算法压制（曝光率降低约12倍），且在2024年5月赖清德就职后，相关帖子数量、观看量和互动量显著下降。

Conclusion: 数字平台既能赋能也能削弱美食外交、软实力和文化外交，本研究强调了算法透明度的必要性，并为在政治化数字时代寻求通过美食手段利用软实力的国家提供了重要见解。

Abstract: Social media platforms have become pivotal for projecting national identity and soft power in an increasingly digital world. This study examines the digital manifestation of Taiwanese gastrodiplomacy by focusing on bubble tea -- a culturally iconic beverage -- leveraging a dataset comprising 107,169 posts from the popular lifestyle social media platform Instagram. Including 315,279,227 engagements, 4,756,320 comments, and 8,097,260,651 views over five full years (2020--2024), we investigate how social media facilitates discussion about Taiwanese cuisine and contributes to Taiwan's digital soft power. Our analysis reveals that bubble tea consistently emerges as the dominant representation of Taiwanese cuisine across Meta's Instagram channels. However, this dominance also indicates vulnerability in gastrodiplomatic strategy compared to other countries. Additionally, we find evidence that Instagram suppresses bubble tea posts mentioning Taiwan by 1,200\% -- roughly a twelve--fold decrease in exposure -- relative to posts without such mentions. Crucially, we observe a significant drop in the number of posts, views, and engagement following Lai's inauguration in May 2024. This study ultimately contributes to understanding how digital platforms can enable or disable gastrodiplomacy, soft power, and cultural diplomacy while highlighting the need for greater algorithmic transparency. By noting Taiwan's bubble tea's digital engagement and footprint, critical insights are brought for nations seeking to leverage soft power through gastronomic means in a politicized digital era and researchers trying to better understand algorithmic suppression.

</details>
