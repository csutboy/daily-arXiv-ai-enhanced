<div id=toc></div>

# Table of Contents

- [cs.CY](#cs.CY) [Total: 9]
- [stat.AP](#stat.AP) [Total: 3]
- [econ.EM](#econ.EM) [Total: 2]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.AI](#cs.AI) [Total: 71]


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [1] [Blockchain Technology for Public Services: A Polycentric Governance Synthesis](https://arxiv.org/abs/2602.05109)
*Hozefa Lakadawala,Komla Dzigbede,Yu Chen*

Main category: cs.CY

TL;DR: 本文通过多中心治理理论对2021-2025年区块链在公共服务中的应用进行系统综述，发现政府采用混合许可设计实现"受控多中心性"，而非完全去中心化。


<details>
  <summary>Details</summary>
Motivation: 各国政府越来越多地采用区块链技术来提升公共服务的透明度、信任和效率，但关于这些技术在不同国家背景下的治理方式的证据仍然零散且过度关注技术特征。需要从治理角度理解区块链在公共服务中的应用。

Method: 使用多中心治理理论，对2021-2025年间发表的同行评审研究进行系统综述，遵循PRISMA指南，综合数字政府和信息系统数据库中的发现，分析区块链公共服务应用的关键领域和治理安排。

Result: 区块链采用嵌入多中心环境中，具有分布式权威、跨组织协调和分层问责特征。政府通常采用混合和许可设计，允许选择性去中心化与集中监督并存，形成"受控多中心性"模式。应用领域包括数字身份、电子投票、采购和社会服务。

Conclusion: 通过将区块链重新定义为编码协调和信息共享规则的治理基础设施，本研究超越了简单的采用指标，推进了数字政府理论。研究结果为研究人员提供了理论见解，为政策制定者设计和扩展可持续的区块链公共服务提供了实践指导。

Abstract: National governments are increasingly adopting blockchain to enhance transparency, trust, and efficiency in public service delivery. However, evidence on how these technologies are governed across national contexts remains fragmented and overly focused on technical features. Using Polycentric Governance Theory, this study conducts a systematic review of peer-reviewed research published between 2021 and 2025 to examine blockchain-enabled public services and the institutional, organizational, and information-management factors shaping their adoption. Following PRISMA guidelines, we synthesize findings from major digital government and information systems databases to identify key application domains, including digital identity, electronic voting, procurement, and social services, and analyze the governance arrangements underpinning these initiatives. Our analysis reveals that blockchain adoption is embedded within polycentric environments characterized by distributed authority, inter-organizational coordination, and layered accountability. Rather than adopting full decentralization, governments typically utilize hybrid and permissioned designs that allow for selective decentralization alongside centralized oversight, a pattern we conceptualize as "controlled polycentricity." By reframing blockchain as a governance infrastructure that encodes rules for coordination and information-sharing, this study advances digital government theory beyond simple adoption metrics. The findings offer theoretically grounded insights for researchers and practical guidance for policymakers seeking to design and scale sustainable blockchain-enabled public services.

</details>


### [2] [Wikipedia and Grokipedia: A Comparison of Human and Generative Encyclopedias](https://arxiv.org/abs/2602.05519)
*Ortal Hadad,Edoardo Loru,Jacopo Nudo,Anita Bonetti,Matteo Cinelli,Walter Quattrociocchi*

Main category: cs.CY

TL;DR: 该研究对比了维基百科和Grokipedia，分析生成式AI如何改变百科内容的选择、重写、叙事结构和评价框架。研究发现生成系统保留了百科内容的主要结构组织，但影响了内容选择、重写和框架呈现的方式。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究生成式AI系统（如Grokipedia）如何改变百科内容的创建和呈现方式，特别是在内容选择、文本重写、叙事结构和评价框架方面的影响。

Method: 研究方法包括：1）建模Grokipedia页面收录与维基百科页面流行度、引用密度和近期编辑活动的关系；2）区分逐字复制和生成式重写；3）使用适应性-复杂性框架评估编辑参与模式；4）使用抽象意义表示构建行动者关系网络分析叙事结构；5）分析导语部分的评价框架。

Result: 研究发现：1）页面收录不均衡，维基百科中可见度高、编辑冲突多的页面更可能出现在Grokipedia；2）引用密度高、近期有争议的页面更常被重写，而高度流行的页面更多被直接复制；3）叙事结构在多个主题领域（美国政治、地缘政治、阴谋论）基本保持一致；4）导语部分框架大体相关，但Grokipedia在某些主题上表现出局部的赞美性和冲突性语言变化。

Conclusion: 生成式系统保留了百科内容的主要结构组织，但影响了内容的选择、重写和框架呈现方式。这表明AI系统在内容创建中既保持了传统百科的结构特征，又在微观层面引入了新的编辑动态。

Abstract: We present a comparative analysis of Wikipedia and Grokipedia to examine how generative mediation alters content selection, textual rewriting, narrative structure, and evaluative framing in encyclopedic content. We model page inclusion in Grokipedia as a function of Wikipedia page popularity, density of reference, and recent editorial activity. Inclusion is non-uniform: pages with higher visibility and greater editorial conflict in Wikipedia are more likely to appear in Grokipedia. For included pages, we distinguish between verbatim reproduction and generative rewriting. Rewriting is more frequent for pages with higher reference density and recent controversy, while highly popular pages are more often reproduced without modification. We compare editing activity across the two platforms and estimate page complexity using a fitness-complexity framework to assess whether generative mediation alters patterns of editorial participation. To assess narrative organization, we construct actor-relation networks from article texts using abstract meaning representation. Across multiple topical domains, including U.S. politics, geopolitics, and conspiracy-related narratives, narrative structure remains largely consistent between the two sources. Analysis of lead sections shows broadly correlated framing, with localized shifts in laudatory and conflict-oriented language for some topics in Grokipedia. Overall, generative systems preserve the main structural organization of encyclopedic content, while affecting how content is selected, rewritten, and framed.

</details>


### [3] [Learning Context Matters: Measuring and Diagnosing Personalization Gaps in LLM-Based Instructional Design](https://arxiv.org/abs/2602.04972)
*Johaun Hatchett,Debshila Basu Mallick,Brittany C. Bradford,Richard G. Baraniuk*

Main category: cs.CY

TL;DR: 论文提出一个框架来评估LLM教学系统如何利用学习上下文进行个性化教学决策，发现虽然上下文能改善决策，但与专家判断仍有显著差距。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在教育中的应用日益普及，但真正个性化教学需要理解学习上下文（学习者身份、学习目标、学习方式）。目前缺乏评估LLM如何利用上下文进行教学决策的系统方法。

Method: 提出一个框架：使用心理测量学基础的合成学习上下文和教学学基础的决策空间，比较LLM在无上下文和有上下文条件下的教学决策，量化其与学科专家判断的对齐程度。引入相关性-影响分析来诊断对齐问题。

Result: 提供学习上下文能系统性地改变LLM的教学决策，使其更接近专家策略，但仍存在显著不对齐。相关性-影响分析揭示了LLM关注、忽略或错误关注哪些学习者特征。

Conclusion: 学习上下文确实影响LLM的教学规划，但不能可靠地产生教学上合适的个性化。该框架为评估上下文感知的LLM系统提供了基础，可通过学习者特征优先级、教学模型调优和上下文工程来改进个性化。

Abstract: The adoption of generative AI in education has accelerated dramatically in recent years, with Large Language Models (LLMs) increasingly integrated into learning environments in the hope of providing personalized support that enhances learner engagement and knowledge retention. However, truly personalized support requires access to meaningful Learning Context (LC) regarding who the learner is, what they are trying to understand, and how they are engaging with the material. In this paper, we present a framework for measuring and diagnosing how the LC influences instructional strategy selection in LLM-based tutoring systems. Using psychometrically grounded synthetic learning contexts and a pedagogically grounded decision space, we compare LLM instructional decisions in context-blind and context-aware conditions and quantify their alignment with the pedagogical judgments of subject matter experts. Our results show that, while providing the LC induces systematic, measurable changes in instructional decisions that move LLM policies closer to the subject matter expert policy, substantial misalignment remains. To diagnose this misalignment, we introduce a relevance-impact analysis that reveals which learner characteristics are attended to, ignored, or spuriously influential in LLM instructional decision-making. This analysis, conducted in collaboration with subject matter experts, demonstrates that LC materially shapes LLM instructional planning but does not reliably induce pedagogically appropriate personalization. Our results enable principled evaluation of context-aware LLM systems and provide a foundation for improving personalization through learner characteristic prioritization, pedagogical model tuning, and LC engineering.

</details>


### [4] [Scalable Generation and Validation of Isomorphic Physics Problems with GenAI](https://arxiv.org/abs/2602.05114)
*Naiming Liu,Leo Murch,Spencer Moore,Tong Wan,Shashank Sonkar,Richard Baraniuk,Zhongzhou Chen*

Main category: cs.CY

TL;DR: 提出使用生成式AI创建大规模同构物理问题库的框架，用于异步多尝试评估，并通过语言模型验证问题质量


<details>
  <summary>Details</summary>
Motivation: 传统同步STEM评估面临可访问性障碍、安全问题和跨机构可比性有限等挑战，需要更灵活可靠的评估方法

Method: 使用提示链和工具调用的生成式AI框架创建同构问题，通过17个开源语言模型（0.6B-32B）进行预部署验证，并与200多名学生实际表现对比

Result: 73%的部署问题库达到统计上一致的难度，语言模型表现与学生表现强相关（皮尔逊相关系数最高达0.594），中等规模模型最适合检测难度异常值

Conclusion: 生成式AI能有效创建大规模同构问题库，语言模型可作为预部署验证工具，中等规模模型最适合问题质量评估

Abstract: Traditional synchronous STEM assessments face growing challenges including accessibility barriers, security concerns from resource-sharing platforms, and limited comparability across institutions. We present a framework for generating and evaluating large-scale isomorphic physics problem banks using Generative AI to enable asynchronous, multi-attempt assessments. Isomorphic problems test identical concepts through varied surface features and contexts, providing richer variation than conventional parameterized questions while maintaining consistent difficulty. Our generation framework employs prompt chaining and tool use to achieve precise control over structural variations (numeric values, spatial relations) alongside diverse contextual variations. For pre-deployment validation, we evaluate generated items using 17 open-source language models (LMs) (0.6B-32B) and compare against actual student performance (N>200) across three midterm exams. Results show that 73% of deployed banks achieve statistically homogeneous difficulty, and LMs pattern correlate strongly with student performance (Pearson's $ρ$ up to 0.594). Additionally, LMs successfully identify problematic variants, such as ambiguous problem texts. Model scale also proves critical for effective validation, where extremely small (<4B) and large (>14B) models exhibit floor and ceiling effects respectively, making mid-sized models optimal for detecting difficulty outliers.

</details>


### [5] [Prediction Laundering: The Illusion of Neutrality, Transparency, and Governance in Polymarket](https://arxiv.org/abs/2602.05181)
*Yasaman Rohanifar,Syed Ishtiaque Ahmed,Sharifa Sultana*

Main category: cs.CY

TL;DR: 该论文批判性地分析了预测市场（以Polymarket为例）如何通过"预测洗钱"过程将主观、不确定的投注转化为看似客观的概率信号，掩盖了资本不对称和战略操纵，导致认知分层和问责缺失。


<details>
  <summary>Details</summary>
Motivation: 随着预测市场作为认知基础设施的重要性日益增长，这些平台产生的概率信号往往掩盖了不确定性、战略操纵和资本不对称，导致公众对它们产生错误的认知信任。研究者希望揭示这些平台如何生产和争夺概率权威。

Method: 采用质性社会技术审计方法，结合数字民族志、解释性走查和半结构化访谈（N=27），对Polymarket平台进行深入分析。

Result: 提出了"预测洗钱"概念，描述了主观、高不确定性的投注、战略对冲和资本密集的鲸鱼活动如何通过算法聚合去除原始噪声。识别了四个阶段的洗钱生命周期：结构净化、概率扁平化、架构掩蔽和认知硬化。揭示了认知分层现象，即技术精英审计底层机制，而公众消费经过净化的资本加权信号。

Conclusion: 预测市场的"无摩擦集体智能"叙事存在问题，导致认知眩晕和问责缺失。建议采用"摩擦积极设计"，在合成真理生产过程中凸显社会和金融摩擦，提高透明度。

Abstract: The growing reliance on prediction markets as epistemic infrastructures has positioned platforms like Polymarket as providers of objective, real-time probabilistic truth, yet the signals they produce often obscure uncertainty, strategic manipulation, and capital asymmetries, encouraging misplaced epistemic trust. This paper presents a qualitative sociotechnical audit of Polymarket (N = 27), combining digital ethnography, interpretive walkthroughs, and semi-structured interviews to examine how probabilistic authority is produced and contested. We introduce the concept of Prediction Laundering, drawing on MacFarlanes framework of knowledge transmission, to describe how subjective, high-uncertainty bets, strategic hedges, and capital-heavy whale activity are stripped of their original noise through algorithmic aggregation. We trace a four-stage laundering lifecycle: Structural Sanitization, where a centralized ontology scripts the bet-able future; Probabilistic Flattening, which collapses heterogeneous motives into a single signal; Architectural Masking, which conceals capital-driven influence behind apparent consensus; and Epistemic Hardening, which erases governance disputes to produce an objective historical fact. We show that this process induces epistemic vertigo and accountability gaps by offloading truth-resolution to off-platform communities such as Discord. Challenging narratives of frictionless collective intelligence, we demonstrate Epistemic Stratification, in which technical elites audit underlying mechanisms while the broader public consumes a sanitized, capital-weighted signal, and we conclude by advocating Friction-Positive Design that surfaces the social and financial frictions inherent in synthetic truth production.

</details>


### [6] [FATe of Bots: Ethical Considerations of Social Bot Detection](https://arxiv.org/abs/2602.05200)
*Lynnette Hui Xian Ng,Ethan Pan,Michael Miller Yoder,Kathleen M. Carley*

Main category: cs.CY

TL;DR: 该论文探讨了社交媒体机器人检测算法的伦理影响，基于FATe框架（公平性、问责制、透明度）分析训练数据集、算法开发和机器人使用三个支柱，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 社交媒体机器人传播有害信息带来广泛社会影响，虽然已有检测算法，但这些算法在复杂的社会技术系统中运行，涉及用户和组织，因此伦理考量至关重要。

Method: 通过调查现有机器人检测算法的训练数据集、评估现有数据集、分析用户被误判为机器人的经验，基于FATe框架（公平性、问责制、透明度）进行伦理分析。

Result: 识别了机器人检测系统在训练数据集、算法开发和机器人使用方面的伦理挑战，包括数据集偏差、算法公平性、误判影响等问题。

Conclusion: 研究人员在解决机器人检测伦理问题上面临挑战，需要更负责任和公平的方法来改进社交媒体机器人检测生态系统，提出了相关研究方向建议。

Abstract: A growing suite of research illustrates the negative impact of social media bots in amplifying harmful information with widespread social implications. Social bot detection algorithms have been developed to help identify these bot agents efficiently. While such algorithms can help mitigate the harmful effects of social media bots, they operate within complex socio-technical systems that include users and organizations. As such, ethical considerations are key while developing and deploying these bot detection algorithms, especially at scales as massive as social media ecosystems. In this article, we examine the ethical implications for social bot detection systems through three pillars: training datasets, algorithm development, and the use of bot agents. We do so by surveying the training datasets of existing bot detection algorithms, evaluating existing bot detection datasets, and drawing on discussions of user experiences of people being detected as bots. This examination is grounded in the FATe framework, which examines Fairness, Accountability, and Transparency in consideration of tech ethics. We then elaborate on the challenges that researchers face in addressing ethical issues with bot detection and provide recommendations for research directions. We aim for this preliminary discussion to inspire more responsible and equitable approaches towards improving the social media bot detection landscape.

</details>


### [7] [Fine-Tuning Large Language Models for Automatic Detection of Sexually Explicit Content in Spanish-Language Song Lyrics](https://arxiv.org/abs/2602.05485)
*Dolores Zamacola Sánchez de Lamadrid,Eduardo C. Garrido-Merchán*

Main category: cs.CY

TL;DR: 使用GPT模型微调检测西班牙语歌词中的性暗示内容，准确率达87%，并提出基于年龄的音乐内容分级政策建议


<details>
  <summary>Details</summary>
Motivation: 雷鬼顿和陷阱等流行音乐中大量性暗示内容被年轻人广泛消费，引发社会对未成年人接触有害歌词材料的担忧，需要自动检测方法

Method: 通过微调GPT模型，使用100首专家标注的西班牙语歌曲（50首明确、50首非明确）作为训练数据，利用迁移学习适应拉丁城市音乐的语言特征

Result: 微调模型达到87%准确率、100%精确度和100%特异性，优于基准ChatGPT模型；与专家分类一致性达59.2%（标准模型为55.1%）

Conclusion: 领域特定的微调能有效检测文化嵌入的性暗示内容，支持将微调大语言模型作为音乐流媒体平台的内容审核工具，并提出类似PEGI系统的音乐内容分级政策框架

Abstract: The proliferation of sexually explicit content in popular music genres such as reggaeton and trap, consumed predominantly by young audiences, has raised significant societal concern regarding the exposure of minors to potentially harmful lyrical material. This paper presents an approach to the automatic detection of sexually explicit content in Spanish-language song lyrics by fine-tuning a Generative Pre-trained Transformer (GPT) model on a curated corpus of 100 songs, evenly divided between expert-labeled explicit and non-explicit categories. The proposed methodology leverages transfer learning to adapt the pre-trained model to the idiosyncratic linguistic features of urban Latin music, including slang, metaphors, and culturally specific double entendres that evade conventional dictionary-based filtering systems. Experimental evaluation on held-out test sets demonstrates that the fine-tuned model achieves 87% accuracy, 100% precision, and 100% specificity after a feedback-driven refinement loop, outperforming both its pre-feedback configuration and a non-customized baseline ChatGPT model. A comparative analysis reveals that the fine-tuned model agrees with expert human classification in 59.2% of cases versus 55.1% for the standard model, confirming that domain-specific adaptation enhances sensitivity to implicit and culturally embedded sexual references. These findings support the viability of deploying fine-tuned large language models as automated content moderation tools on music streaming platforms. Building on these technical results, the paper develops a public policy proposal for a multi-tier age-based content rating system for music analogous to the PEGI system for video games analyzed through the PESTEL framework and Kingdon's Multiple Streams Framework, establishing both the technological feasibility and the policy pathway for systematic music content regulation.

</details>


### [8] [Ethology of Latent Spaces](https://arxiv.org/abs/2602.05710)
*Philippe Boisnard*

Main category: cs.CY

TL;DR: 该研究挑战了视觉语言模型（VLM）潜在空间的中立性假设，通过比较三个模型对301件艺术品的分析，揭示了它们在政治和文化分类上的显著差异，并提出了计算潜在政治化、涌现偏见和三种算法视觉机制等概念。


<details>
  <summary>Details</summary>
Motivation: 挑战视觉语言模型中潜在空间的中立性假设，揭示训练数据和架构选择如何塑造模型特定的算法敏感性，从而影响对艺术品的政治和文化解读。

Method: 采用比较分析方法，研究三个模型（OpenAI CLIP、OpenCLIP LAION、SigLIP）对301件15-20世纪艺术品的分类。使用基于向量类比的双极语义轴，分析模型在政治和文化类别上的差异。

Result: 发现模型间存在显著差异：SigLIP将59.4%的艺术品分类为政治参与，而OpenCLIP只有4%。非洲面具在SigLIP中获得最高政治分数，但在OpenAI CLIP中保持非政治性。在美学殖民轴上，模型间差异达到72.6个百分点。

Conclusion: 训练数据集作为准档案，其话语形成在潜在空间中结晶。提出了三种算法视觉机制：熵（LAION）、制度（OpenAI）和符号（SigLIP）。呼吁在将文化解释委托给算法代理时，需要整合学习架构的方法论。

Abstract: This study challenges the presumed neutrality of latent spaces in vision language models (VLMs) by adopting an ethological perspective on their algorithmic behaviors. Rather than constituting spaces of homogeneous indeterminacy, latent spaces exhibit model-specific algorithmic sensitivities, understood as differential regimes of perceptual salience shaped by training data and architectural choices.
  Through a comparative analysis of three models (OpenAI CLIP, OpenCLIP LAION, SigLIP) applied to a corpus of 301 artworks (15th to 20th), we reveal substantial divergences in the attribution of political and cultural categories. Using bipolar semantic axes derived from vector analogies (Mikolov et al., 2013), we show that SigLIP classifies 59.4% of the artworks as politically engaged, compared to only 4% for OpenCLIP. African masks receive the highest political scores in SigLIP while remaining apolitical in OpenAI CLIP. On an aesthetic colonial axis, inter-model discrepancies reach 72.6 percentage points.
  We introduce three operational concepts: computational latent politicization, describing the emergence of political categories without intentional encoding; emergent bias, irreducible to statistical or normative bias and detectable only through contrastive analysis; and three algorithmic scopic regimes: entropic (LAION), institutional (OpenAI), and semiotic (SigLIP), which structure distinct modes of visibility. Drawing on Foucault's notion of the archive, Jameson's ideologeme, and Simondon's theory of individuation, we argue that training datasets function as quasi-archives whose discursive formations crystallize within latent space. This work contributes to a critical reassessment of the conditions under which VLMs are applied to digital art history and calls for methodologies that integrate learning architectures into any delegation of cultural interpretation to algorithmic agents.

</details>


### [9] [Cold Start Problem: An Experimental Study of Knowledge Tracing Models with New Students](https://arxiv.org/abs/2505.21517)
*Indronil Bhattacharjee,Christabel Wayllace*

Main category: cs.CY

TL;DR: 研究知识追踪中的冷启动问题，评估三种模型在新学生上的表现，发现所有模型在冷启动条件下都面临挑战，需要开发更具泛化能力的模型。


<details>
  <summary>Details</summary>
Motivation: 知识追踪(KT)需要基于学生在智能辅导系统中的交互来预测其知识状态，但面临冷启动问题：如何准确预测只有少量交互数据的新学生的知识状态。现有研究通常在所有学生的初始交互上训练模型，然后在他们的后续交互上测试，这不能真实反映模型对新学生的泛化能力。

Method: 采用新的评估方法：仅使用历史学生的数据训练模型，然后在完全新的学生上评估性能。研究了三种KT模型：深度知识追踪(DKT)、动态键值记忆网络(DKVMN)和自注意力知识追踪(SAKT)，使用ASSISTments 2009、2015和2017三个数据集进行分析。

Result: 所有模型在冷启动条件下都表现不佳，但随着交互次数增加逐渐改善。SAKT模型显示出更高的初始准确率，但仍面临局限性。结果表明现有KT模型对新学生的泛化能力有限。

Conclusion: 知识追踪模型需要更好地泛化到新学习者，强调开发在少样本和零样本学习场景下具有鲁棒性的模型的重要性。当前模型在冷启动问题上的表现不足，需要进一步研究改进。

Abstract: KnowledgeTracing (KT) involves predicting students' knowledge states based on their interactions with Intelligent Tutoring Systems (ITS). A key challenge is the cold start problem, accurately predicting knowledge for new students with minimal interaction data. Unlike prior work, which typically trains KT models on initial interactions of all students and tests on their subsequent interactions, our approach trains models solely using historical data from past students, evaluating their performance exclusively on entirely new students. We investigate cold start effects across three KT models: Deep Knowledge Tracing (DKT), Dynamic Key-Value Memory Networks (DKVMN), and Self-Attentive Knowledge Tracing (SAKT), using ASSISTments 2009, 2015, and 2017 datasets. Results indicate all models initially struggle under cold start conditions but progressively improve with more interactions; SAKT shows higher initial accuracy yet still faces limitations. These findings highlight the need for KT models that effectively generalize to new learners, emphasizing the importance of developing models robust in few-shot and zero-shot learning scenarios

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [10] [Physics-Informed Diffusion Models for Vehicle Speed Trajectory Generation](https://arxiv.org/abs/2602.05028)
*Vadim Sokolov,Farnaz Behnia,Dominik Karbowski*

Main category: stat.AP

TL;DR: 提出基于物理约束的扩散模型框架，用于生成合成车辆速度轨迹，相比传统马尔可夫链方法能更好地匹配真实数据分布，适用于智能交通系统应用。


<details>
  <summary>Details</summary>
Motivation: 合成车辆速度轨迹对于评估车辆控制算法和车联网技术至关重要，但传统马尔可夫链方法存在离散化伪影和表达能力有限的问题，需要更先进的生成方法。

Method: 提出物理信息扩散框架，采用双通道速度-加速度表示和软物理约束，比较了1D U-Net架构和基于Transformer的CSDI模型，使用6,367个GPS微行程数据进行训练。

Result: CSDI模型在分布匹配方面表现优异（速度Wasserstein距离0.30，加速度0.026），与真实数据难以区分（判别分数0.49），在下游能量评估任务中验证了实用性。

Conclusion: 该方法能够无需昂贵的现场数据收集，为智能交通系统应用生成可扩展的真实驾驶轨迹，解决了传统方法的局限性。

Abstract: Synthetic vehicle speed trajectory generation is essential for evaluating vehicle control algorithms and connected vehicle technologies. Traditional Markov chain approaches suffer from discretization artifacts and limited expressiveness. This paper proposes a physics-informed diffusion framework for conditional micro-trip synthesis, combining a dual-channel speed-acceleration representation with soft physics constraints that resolve optimization conflicts inherent to hard-constraint formulations. We compare a 1D U-Net architecture against a transformer-based Conditional Score-based Diffusion Imputation (CSDI) model using 6,367 GPS-derived micro-trips. CSDI achieves superior distribution matching (Wasserstein distance 0.30 for speed, 0.026 for acceleration), strong indistinguishability from real data (discriminative score 0.49), and validated utility for downstream energy assessment tasks. The methodology enables scalable generation of realistic driving profiles for intelligent transportation systems (ITS) applications without costly field data collection.

</details>


### [11] [Predictive Synthesis under Sporadic Participation: Evidence from Inflation Density Surveys](https://arxiv.org/abs/2602.05226)
*Matthew C. Johnson,Matteo Luciani,Minzhengxiong Zhang,Kenichiro McAlinn*

Main category: stat.AP

TL;DR: 提出贝叶斯更新规则处理专业调查中不规则参与问题，改善通胀密度预测的准确性和平滑性


<details>
  <summary>Details</summary>
Motivation: 专业调查中预测者的不规则参与（进入退出、跳过轮次、长期缺席）导致标准聚合方法产生人为跳跃，使预测组合受面板组成而非经济信息驱动，影响实时解释和预测者绩效评估

Method: 开发了贝叶斯更新规则，在零星参与情况下进行预测组合，即使预测者未观测到预测时也保持其潜在预测状态的明确定义，通过面板的条件结构更新组合预测分布，而非依赖重新归一化或插补

Result: 在欧洲央行专业预测者调查中，该方法相对于等权重基准提高了预测准确性，特别是在高流动率时期，提供了更平滑、更好校准的通胀密度预测

Conclusion: 该方法将真实的绩效差异与机械参与效应分离，产生可解释的预测者影响力动态，改善了通胀风险评估和不确定性沟通

Abstract: Central banks rely on density forecasts from professional surveys to assess inflation risks and communicate uncertainty. A central challenge in using these surveys is irregular participation: forecasters enter and exit, skip rounds, and reappear after long gaps. In the European Central Bank's Survey of Professional Forecasters, turnover and missingness vary substantially over time, causing the set of submitted predictions to change from quarter to quarter. Standard aggregation rules -- such as equal-weight pooling, renormalization after dropping missing forecasters, or ad hoc imputation -- can generate artificial jumps in combined predictions driven by panel composition rather than economic information, complicating real-time interpretation and obscuring forecaster performance. We develop coherent Bayesian updating rules for forecast combination under sporadic participation that maintain a well-defined latent predictive state for each forecaster even when their forecast is unobserved. Rather than relying on renormalization or imputation, the combined predictive distribution is updated through the implied conditional structure of the panel. This approach isolates genuine performance differences from mechanical participation effects and yields interpretable dynamics in forecaster influence. In the ECB survey, it improves predictive accuracy relative to equal-weight benchmarks and delivers smoother and better-calibrated inflation density forecasts, particularly during periods of high turnover.

</details>


### [12] [Active Simulation-Based Inference for Scalable Car-Following Model Calibration](https://arxiv.org/abs/2602.05246)
*Menglin Kong,Chengyuan Zhang,Lijun Sun*

Main category: stat.AP

TL;DR: 提出基于主动仿真推理的可扩展跟驰模型校准框架，结合残差增强仿真器和摊销条件密度估计器，实现单次前向传播即可获得驾驶员特定后验参数分布，在HighD数据集上优于传统贝叶斯校准方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的跟驰模型校准大多是确定性的，只能得到单一最优参数向量，无法处理驾驶员和情境间的显著变异性，也不支持不确定性感知预测、风险敏感评估和群体级仿真。传统贝叶斯校准方法如MCMC计算成本过高，难以应用于大规模自然驾驶数据集。

Method: 提出主动仿真推理框架：1) 残差增强跟驰仿真器，提供两种残差过程选择；2) 摊销条件密度估计器，将观测到的前车-后车轨迹直接映射到驾驶员特定参数后验分布，测试时只需单次前向传播；3) 联合主动设计策略，选择信息丰富的参数提议和代表性驾驶情境，在推理模型最不确定的区域进行仿真，同时保持真实性。

Result: 在HighD数据集上的实验显示，相比贝叶斯校准基线方法，提出的框架具有更好的预测准确性和更接近的仿真与观测轨迹分布一致性。收敛性和消融研究支持了所提设计选择的鲁棒性。

Conclusion: 该框架实现了可扩展、不确定性感知的驾驶员群体建模，为交通流仿真和风险敏感交通分析提供了有效工具，解决了传统方法在大规模数据集上的计算瓶颈问题。

Abstract: Credible microscopic traffic simulation requires car-following models that capture both the average response and the substantial variability observed across drivers and situations. However, most data-driven calibrations remain deterministic, producing a single best-fit parameter vector and offering limited guidance for uncertainty-aware prediction, risk-sensitive evaluation, and population-level simulation. Bayesian calibration addresses this gap by inferring a posterior distribution over parameters, but per-trajectory sampling methods such as Markov chain Monte Carlo (MCMC) are computationally infeasible for modern large-scale naturalistic driving datasets. This paper proposes an active simulation-based inference framework for scalable car-following model calibration. The approach combines (i) a residual-augmented car-following simulator with two alternatives for the residual process and (ii) an amortized conditional density estimator that maps an observed leader--follower trajectory directly to a driver-specific posterior over model parameters with a single forward pass at test time. To reduce simulation cost during training, we introduce a joint active design strategy that selects informative parameter proposals together with representative driving contexts, focusing simulations where the current inference model is most uncertain while maintaining realism. Experiments on the HighD dataset show improved predictive accuracy and closer agreement between simulated and observed trajectory distributions relative to Bayesian calibration baselines, with convergence and ablation studies supporting the robustness of the proposed design choices. The framework enables scalable, uncertainty-aware driver population modeling for traffic flow simulation and risk-sensitive transportation analysis.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [13] [Personalized Policy Learning through Discrete Experimentation: Theory and Empirical Evidence](https://arxiv.org/abs/2602.05099)
*Zhiqi Zhang,Zhiyu Zeng,Ruohan Zhan,Dennis Zhang*

Main category: econ.EM

TL;DR: 提出DLPT框架，利用离散A/B测试数据学习个性化连续策略，解决在线平台连续变量优化问题


<details>
  <summary>Details</summary>
Motivation: 当前行业实践将连续决策变量离散化进行A/B测试，但这种方法存在两个主要问题：1) 无法准确推断未测试处理水平的表现；2) 未能考虑用户特征异质性导致的处理效应差异

Method: 提出深度学习策略定位(DLPT)框架，包括个性化策略价值估计和个性化策略学习两个部分，基于离散A/B测试数据学习高维用户特征的个性化连续策略

Result: 理论证明策略价值估计器具有渐近无偏性和一致性，学习策略达到根n后悔界；与领先社交媒体平台合作实证验证，在内容创作激励优化中显著优于现有基准方法

Conclusion: DLPT框架为解决在线平台连续变量优化问题提供了理论坚实且经验验证的方法，能够基于离散A/B测试数据学习有效的个性化连续策略

Abstract: Randomized Controlled Trials (RCTs), or A/B testing, have become the gold standard for optimizing various operational policies on online platforms. However, RCTs on these platforms typically cover a limited number of discrete treatment levels, while the platforms increasingly face complex operational challenges involving optimizing continuous variables, such as pricing and incentive programs. The current industry practice involves discretizing these continuous decision variables into several treatment levels and selecting the optimal discrete treatment level. This approach, however, often leads to suboptimal decisions as it cannot accurately extrapolate performance for untested treatment levels and fails to account for heterogeneity in treatment effects across user characteristics. This study addresses these limitations by developing a theoretically solid and empirically verified framework to learn personalized continuous policies based on high-dimensional user characteristics, using observations from an RCT with only a discrete set of treatment levels. Specifically, we introduce a deep learning for policy targeting (DLPT) framework that includes both personalized policy value estimation and personalized policy learning. We prove that our policy value estimators are asymptotically unbiased and consistent, and the learned policy achieves a root-n-regret bound. We empirically validate our methods in collaboration with a leading social media platform to optimize incentive levels for content creation. Results demonstrate that our DLPT framework significantly outperforms existing benchmarks, achieving substantial improvements in both evaluating the value of policies for each user group and identifying the optimal personalized policy.

</details>


### [14] [Nested Pseudo-GMM Estimation of Demand for Differentiated Products](https://arxiv.org/abs/2602.05137)
*Victor Aguirregabiria,Hui Liu,Yao Luo*

Main category: econ.EM

TL;DR: 提出一种快速计算BLP需求模型GMM估计量的算法，通过交换GMM优化和不动点计算的顺序，避免重复求解逆需求系统，显著提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统BLP需求模型估计计算成本高，特别是产品数量多时需要反复求解逆需求系统，限制了模型的实际应用。

Method: 采用嵌套伪似然方法，固定消费者层面的外部选项概率，使市场份额到平均效用的反演变为闭式且可分离，开发嵌套伪GMM算法，具有解析梯度。

Result: 新方法比现有最快替代方案显著更快，计算效率随产品数量增加而超比例增长，适合并行和多线程实现。

Conclusion: 提出的算法大幅降低了BLP模型的计算成本，使处理大规模产品数据变得可行，提供了MATLAB和Julia代码便于实施。

Abstract: We propose a fast algorithm for computing the GMM estimator in the BLP demand model (Berry, Levinsohn, and Pakes, 1995). Inspired by nested pseudo-likelihood methods for dynamic discrete choice models, our approach avoids repeatedly solving the inverse demand system by swapping the order of the GMM optimization and the fixed-point computation. We show that, by fixing consumer-level outside-option probabilities, BLP's market-share to mean-utility inversion becomes closed-form and, crucially, separable across products, yielding a nested pseudo-GMM algorithm with analytic gradients. The resulting estimator scales dramatically better with the number of products and is naturally suited for parallel and multithreaded implementation. In the inner loop, outside-option probabilities are treated as fixed objects while a pseudo-GMM criterion is minimized with respect to the structural parameters, substantially reducing computational cost. Monte Carlo simulations and an empirical application show that our method is significantly faster than the fastest existing alternatives, with efficiency gains that grow more than proportionally in the number of products. We provide MATLAB and Julia code to facilitate implementation.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [15] [Supply vs. Demand in Community-Based Fact-Checking on Social Media](https://arxiv.org/abs/2602.06005)
*Moritz Pilarski,Nicolas Pröllochs*

Main category: cs.SI

TL;DR: 研究分析了X平台Community Notes上110万条事实核查与核查请求数据，发现用户请求主要针对高可见性内容，而事实核查则分布更广泛，两者存在差距，但用户请求能有效引导贡献者进行核查。


<details>
  <summary>Details</summary>
Motivation: 社交媒体事实核查生态系统依赖于用户需求与贡献者供给的互动，但先前研究多孤立考察这两方面，不清楚供给在多大程度上满足需求，需要实证分析供需匹配情况。

Method: 使用2024年6月至2025年5月期间X平台Community Notes的110万条事实核查和核查请求数据，采用准实验生存分析方法，评估显示请求对后续笔记创建的影响。

Result: 用户请求主要针对高可见性内容（更多浏览量、互动和影响力账户），而事实核查在语言、情感和主题上分布更广泛；用户请求显著加速了顶级作者的贡献，能引导贡献者向更符合需求的方向调整。

Conclusion: 事实核查请求与最终核查内容存在差距，但用户请求能有效引导贡献者，这对平台治理和在线虚假信息研究有重要启示。

Abstract: Fact-checking ecosystems on social media depend on the interplay between what users want checked and what contributors are willing to supply. Prior research has largely examined these forces in isolation, yet it remains unclear to what extent supply meets demand. We address this gap with an empirical analysis of a unique dataset of 1.1 million fact-checks and fact-checking requests from X's Community Notes platform between June 2024 and May 2025. We find that requests disproportionately target highly visible posts - those with more views and engagement and authored by influential accounts - whereas fact-checks are distributed more broadly across languages, sentiments, and topics. Using a quasi-experimental survival analysis, we further estimate the effect of displaying requests on subsequent note creation. Results show that requests significantly accelerate contributions from Top Writers. Altogether, our findings highlight a gap between the content that attracts requests for fact-checking and the content that ultimately receives fact-checks, while showing that user requests can steer contributors toward greater alignment. These insights carry important implications for platform governance and future research on online misinformation.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [16] [Evaluating Kubernetes Performance for GenAI Inference: From Automatic Speech Recognition to LLM Summarization](https://arxiv.org/abs/2602.04900)
*Sai Sindhur Malleni,Raúl Sevilla,Aleksei Vasilevskii,José Castillo Lema,André Bauer*

Main category: cs.ET

TL;DR: Kubernetes原生项目（Kueue、DAS、GAIE）结合构建高性能平台，为生成式AI工作负载提供统一基础，显著提升批处理和在线推理性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI（特别是推理）成为主要工作负载类别，Kubernetes生态系统需要原生支持其独特需求，提供容器编排的可扩展性和资源效率优势。

Method: 1. 使用Kueue管理Whisper模型转录音频文件的批处理作业；2. 使用动态加速器切片器（DAS）增加并行作业执行；3. 使用llm-d和Kubernetes Gateway API推理扩展（GAIE）优化在线推理请求路由，将转录文本输入大语言模型进行摘要。

Result: Kueue减少总完成时间达15%；DAS缩短平均作业完成时间36%；GAIE改善首次令牌时间82%。这些组件形成统一的高性能平台。

Conclusion: Kubernetes能够作为生成式AI工作负载的统一基础，通过Kueue、DAS和GAIE等原生项目组合，为复杂AI工作流提供可扩展、高效的容器编排解决方案。

Abstract: As Generative AI (GenAI), particularly inference, rapidly emerges as a dominant workload category, the Kubernetes ecosystem is proactively evolving to natively support its unique demands. This industry paper demonstrates how emerging Kubernetes-native projects can be combined to deliver the benefits of container orchestration, such as scalability and resource efficiency, to complex AI workflows. We implement and evaluate an illustrative, multi-stage use case consisting of automatic speech recognition and summarization. First, we address batch inference by using Kueue to manage jobs that transcribe audio files with Whisper models and Dynamic Accelerator Slicer (DAS) to increase parallel job execution. Second, we address a discrete online inference scenario by feeding the transcripts to a Large Language Model for summarization hosted using llm-d, a novel solution utilizing the recent developments around the Kubernetes Gateway API Inference Extension (GAIE) for optimized routing of inference requests. Our findings illustrate that these complementary components (Kueue, DAS, and GAIE) form a cohesive, high-performance platform, proving Kubernetes' capability to serve as a unified foundation for demanding GenAI workloads: Kueue reduced total makespan by up to 15%; DAS shortened mean job completion time by 36%; and GAIE improved Time to First Token by 82\%.

</details>


### [17] [Task-Adaptive Physical Reservoir Computing via Tunable Molecular Communication Dynamics](https://arxiv.org/abs/2602.05931)
*Saad Yousuf,Kaan Burak Ikiz,Murat Kuscu*

Main category: cs.ET

TL;DR: 分子通信通道可作为可重构的物理储层计算系统，通过调节生物物理参数优化不同计算任务，贝叶斯优化识别出记忆丰富和受体非线性两种操作模式。


<details>
  <summary>Details</summary>
Motivation: 大多数物理储层计算实现是静态的，性能局限于狭窄的任务范围。本研究旨在探索分子通信通道作为可重构、任务自适应的物理储层计算系统的潜力。

Method: 采用双模拟方法：计算高效的确定性平均场模型和高保真粒子随机模型（Smoldyn）。使用贝叶斯优化在高维参数空间中导航，识别离散操作模式。通过调节配体-受体动力学和扩散动力学等生物物理参数来优化储层。

Result: 发现明显的权衡关系：通道记忆丰富的参数集在混沌时间序列预测任务（如Mackey Glass）中表现优异，而促进强受体非线性的模式在非线性数据转换方面更优。后处理方法通过减轻固有分子噪声提高了随机储层的性能。

Conclusion: 分子通信通道不仅是计算基质，更是可调谐、生物启发计算系统的设计蓝图，为未来湿件AI实现提供了清晰的优化框架。

Abstract: Physical Reservoir Computing (PRC) offers an efficient paradigm for processing temporal data, yet most physical implementations are static, limiting their performance to a narrow range of tasks. In this work, we demonstrate in silico that a canonical Molecular Communication (MC) channel can function as a highly versatile and task-adaptive PRC whose computational properties are reconfigurable. Using a dual-simulation approach -- a computationally efficient deterministic mean-field model and a high-fidelity particle-based stochastic model (Smoldyn) -- we show that tuning the channel's underlying biophysical parameters, such as ligand-receptor kinetics and diffusion dynamics, allows the reservoir to be optimized for distinct classes of computation. We employ Bayesian optimization to efficiently navigate this high-dimensional parameter space, identifying discrete operational regimes. Our results reveal a clear trade-off: parameter sets rich in channel memory excel at chaotic time-series forecasting tasks (e.g., Mackey Glass), while regimes that promote strong receptor nonlinearity are superior for nonlinear data transformation. We further demonstrate that post-processing methods improve the performance of the stochastic reservoir by mitigating intrinsic molecular noise. These findings establish the MC channel not merely as a computational substrate, but as a design blueprint for tunable, bioinspired computing systems, providing a clear optimization framework for future wetware AI implementations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [18] [Advancing Opinion Dynamics Modeling with Neural Diffusion-Convection-Reaction Equation](https://arxiv.org/abs/2602.05403)
*Chenghua Gong,Yihang Jiang,Hao Li,Rui Sun,Juyuan Zhang,Tianjun Gu,Liming Pan,Linyuan Lü*

Main category: cs.AI

TL;DR: 提出OPINN框架，将扩散-对流-反应物理系统与神经网络结合，用于意见动力学建模，在真实和合成数据集上实现最先进的预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于物理信息神经网络的意见动力学方法存在局限性：1）基于不完整的先验知识，缺乏整合局部、全局和内生层面动态的完整物理系统；2）基于惩罚的约束难以深度编码物理先验，导致优化问题和潜在表示与物理透明度之间的差异。

Method: 1）从相互作用粒子理论出发，通过扩散-对流-反应系统解释意见动力学；2）基于神经ODE定义神经意见动力学，协调神经网络与物理先验；3）提出OPINN物理信息神经框架用于意见动力学建模。

Result: 在真实世界和合成数据集上评估，OPINN在意见演化预测方面实现了最先进的性能。

Conclusion: OPINN为网络、物理和社会系统的交叉领域提供了一个有前景的范式，将机制可解释性与数据驱动灵活性相结合。

Abstract: Advanced opinion dynamics modeling is vital for deciphering social behavior, emphasizing its role in mitigating polarization and securing cyberspace. To synergize mechanistic interpretability with data-driven flexibility, recent studies have explored the integration of Physics-Informed Neural Networks (PINNs) for opinion modeling. Despite this promise, existing methods are tailored to incomplete priors, lacking a comprehensive physical system to integrate dynamics from local, global, and endogenous levels. Moreover, penalty-based constraints adopted in existing methods struggle to deeply encode physical priors, leading to optimization pathologies and discrepancy between latent representations and physical transparency. To this end, we offer a physical view to interpret opinion dynamics via Diffusion-Convection-Reaction (DCR) system inspired by interacting particle theory. Building upon the Neural ODEs, we define the neural opinion dynamics to coordinate neural networks with physical priors, and further present the OPINN, a physics-informed neural framework for opinion dynamics modeling. Evaluated on real-world and synthetic datasets, OPINN achieves state-of-the-art performance in opinion evolution forecasting, offering a promising paradigm for the nexus of cyber, physical, and social systems.

</details>


### [19] [Artificial Intelligence as Strange Intelligence: Against Linear Models of Intelligence](https://arxiv.org/abs/2602.04986)
*Kendra Chilson,Eric Schwitzgebel*

Main category: cs.AI

TL;DR: 论文批判AI进步的线性模型，提出"熟悉智能"和"陌生智能"概念，认为AI智能更可能是陌生智能，具有非线性特征，在特定领域超人类能力与在其他领域低于人类表现并存。


<details>
  <summary>Details</summary>
Motivation: 批判当前AI研究中对智能的线性理解模型，这种模型假设智能是单一连续体，从低到高线性发展。作者认为这种模型无法解释AI系统表现出的复杂、非均匀的能力模式。

Method: 通过概念分析提出"熟悉智能"和"陌生智能"的区分，发展非线性智能模型，认为"通用智能"不是统一能力，而是在广泛环境中实现广泛目标的能力，无法非任意地简化为单一线性量。

Result: 建立了AI智能更可能是陌生智能的理论框架，这种智能模式结合了某些领域的超人类能力与其他领域的低于人类表现，甚至在同一个领域内也会出现超人类洞察与令人惊讶的错误并存的情况。

Conclusion: AI的陌生智能特性意味着即使最先进的系统也可能在看似简单的任务上失败，这些错误本身不能证明系统缺乏出色的通用智能。同样，在单一任务类型上的优异表现（如IQ测试）也不能保证在任务领域之外的广泛能力。

Abstract: We endorse and expand upon Susan Schneider's critique of the linear model of AI progress and introduce two novel concepts: "familiar intelligence" and "strange intelligence". AI intelligence is likely to be strange intelligence, defying familiar patterns of ability and inability, combining superhuman capacities in some domains with subhuman performance in other domains, and even within domains sometimes combining superhuman insight with surprising errors that few humans would make. We develop and defend a nonlinear model of intelligence on which "general intelligence" is not a unified capacity but instead the ability to achieve a broad range of goals in a broad range of environments, in a manner that defies nonarbitrary reduction to a single linear quantity. We conclude with implications for adversarial testing approaches to evaluating AI capacities. If AI is strange intelligence, we should expect that even the most capable systems will sometimes fail in seemingly obvious tasks. On a nonlinear model of AI intelligence, such errors on their own do not demonstrate a system's lack of outstanding general intelligence. Conversely, excellent performance on one type of task, such as an IQ test, cannot warrant assumptions of broad capacities beyond that task domain.

</details>


### [20] [DeepRead: Document Structure-Aware Reasoning to Enhance Agentic Search](https://arxiv.org/abs/2602.05014)
*Zhanli Li,Huiwen Tian,Lvzhou Luo,Yixuan Cao,Ping Luo*

Main category: cs.AI

TL;DR: DeepRead是一个结构感知的多轮文档推理代理，通过保留文档层次结构和顺序信息，结合检索和阅读工具，显著提升长文档问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有代理搜索框架通常将长文档视为扁平化的文本块集合，未能充分利用文档固有的层次组织和顺序结构等先验信息，限制了长文档问答的效果。

Method: 1. 使用基于LLM的OCR模型将PDF转换为结构化Markdown，保留标题和段落边界
2. 在段落级别索引文档，为每个段落分配编码其章节身份和章节内顺序的坐标式元数据键
3. 为LLM配备两个互补工具：检索工具（定位相关段落并暴露其结构坐标）和阅读工具（在指定章节和段落范围内进行连续、保序的阅读）

Result: DeepRead在文档问答任务中相比Search-o1风格的代理搜索取得了显著改进，验证了检索和阅读工具之间的协同效应，行为分析揭示了类似人类"定位然后阅读"的推理范式。

Conclusion: 通过显式利用文档的层次结构和顺序信息，DeepRead实现了更有效的长文档问答，展示了结构感知方法在代理搜索中的重要性。

Abstract: With the rapid progress of tool-using and agentic large language models (LLMs), Retrieval-Augmented Generation (RAG) is evolving from one-shot, passive retrieval into multi-turn, decision-driven evidence acquisition. Despite strong results in open-domain settings, existing agentic search frameworks commonly treat long documents as flat collections of chunks, underutilizing document-native priors such as hierarchical organization and sequential discourse structure. We introduce DeepRead, a structure-aware, multi-turn document reasoning agent that explicitly operationalizes these priors for long-document question answering. DeepRead leverages LLM-based OCR model to convert PDFs into structured Markdown that preserves headings and paragraph boundaries. It then indexes documents at the paragraph level and assigns each paragraph a coordinate-style metadata key encoding its section identity and in-section order. Building on this representation, DeepRead equips the LLM with two complementary tools: a Retrieve tool that localizes relevant paragraphs while exposing their structural coordinates (with lightweight scanning context), and a ReadSection tool that enables contiguous, order-preserving reading within a specified section and paragraph range. Our experiments demonstrate that DeepRead achieves significant improvements over Search-o1-style agentic search in document question answering. The synergistic effect between retrieval and reading tools is also validated. Our fine-grained behavioral analysis reveals a reading and reasoning paradigm resembling human-like ``locate then read'' behavior.

</details>


### [21] [MINT: Minimal Information Neuro-Symbolic Tree for Objective-Driven Knowledge-Gap Reasoning and Active Elicitation](https://arxiv.org/abs/2602.05048)
*Zeyu Fang,Tian Lan,Mahdi Imani*

Main category: cs.AI

TL;DR: MINT框架通过神经符号树推理知识缺口，利用自博弈优化AI代理的询问策略，结合LLM生成最优查询，在未知对象规划任务中实现接近专家水平的性能。


<details>
  <summary>Details</summary>
Motivation: 开放世界中的联合规划常涉及不完整信息（如未知对象、人类目标），导致知识缺口，需要AI主动询问人类来填补这些缺口以优化规划性能。

Method: 提出MINT（最小信息神经符号树）：1）构建符号树模拟可能的人机交互；2）使用神经规划策略评估知识缺口导致的规划不确定性；3）通过自博弈优化询问策略；4）利用LLM搜索和总结推理过程，生成最优查询集。

Result: 在三个涉及未知对象的基准测试中，MINT仅需少量提问就能达到接近专家水平的回报，显著提高了奖励和成功率。

Conclusion: MINT框架能有效处理开放世界规划中的知识缺口问题，通过主动询问策略实现高效的人机协作规划，在现实任务中表现出色。

Abstract: Joint planning through language-based interactions is a key area of human-AI teaming. Planning problems in the open world often involve various aspects of incomplete information and unknowns, e.g., objects involved, human goals/intents -- thus leading to knowledge gaps in joint planning. We consider the problem of discovering optimal interaction strategies for AI agents to actively elicit human inputs in object-driven planning. To this end, we propose Minimal Information Neuro-Symbolic Tree (MINT) to reason about the impact of knowledge gaps and leverage self-play with MINT to optimize the AI agent's elicitation strategies and queries. More precisely, MINT builds a symbolic tree by making propositions of possible human-AI interactions and by consulting a neural planning policy to estimate the uncertainty in planning outcomes caused by remaining knowledge gaps. Finally, we leverage LLM to search and summarize MINT's reasoning process and curate a set of queries to optimally elicit human inputs for best planning performance. By considering a family of extended Markov decision processes with knowledge gaps, we analyze the return guarantee for a given MINT with active human elicitation. Our evaluation on three benchmarks involving unseen/unknown objects of increasing realism shows that MINT-based planning attains near-expert returns by issuing a limited number of questions per task while achieving significantly improved rewards and success rates.

</details>


### [22] [Quantum Reinforcement Learning with Transformers for the Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2602.05920)
*Eva Andrés*

Main category: cs.AI

TL;DR: 该论文比较了经典和量子强化学习方法解决带容量约束的车辆路径问题，发现量子增强模型（特别是混合架构）在路由距离、紧凑性和路线重叠方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索量子强化学习在复杂组合优化问题（如带容量约束的车辆路径问题）中的应用潜力，比较经典与量子方法的表现差异。

Method: 采用优势演员-评论家（A2C）智能体，实现经典、全量子和混合三种变体，集成Transformer架构通过自注意力和交叉注意力机制捕捉车辆、客户和仓库之间的关系。实验针对20个客户和4辆车的多车辆容量约束场景，进行10次独立运行。

Result: 所有三种方法都能学习有效的路由策略，但量子增强模型优于经典基线，产生更稳健的路由组织。混合架构在距离、紧凑性和路线重叠方面表现最佳。定性可视化显示量子模型生成更结构化、更连贯的路由解决方案。

Conclusion: 混合量子-经典强化学习模型在解决复杂组合优化问题（如CVRP）方面具有显著潜力，量子增强方法能产生更优、更稳健的路由解决方案。

Abstract: This paper addresses the Capacitated Vehicle Routing Problem (CVRP) by comparing classical and quantum Reinforcement Learning (RL) approaches. An Advantage Actor-Critic (A2C) agent is implemented in classical, full quantum, and hybrid variants, integrating transformer architectures to capture the relationships between vehicles, clients, and the depot through self- and cross-attention mechanisms. The experiments focus on multi-vehicle scenarios with capacity constraints, considering 20 clients and 4 vehicles, and are conducted over ten independent runs. Performance is assessed using routing distance, route compactness, and route overlap. The results show that all three approaches are capable of learning effective routing policies. However, quantum-enhanced models outperform the classical baseline and produce more robust route organization, with the hybrid architecture achieving the best overall performance across distance, compactness, and route overlap. In addition to quantitative improvements, qualitative visualizations reveal that quantum-based models generate more structured and coherent routing solutions. These findings highlight the potential of hybrid quantum-classical reinforcement learning models for addressing complex combinatorial optimization problems such as the CVRP.

</details>


### [23] [Evaluating Large Language Models on Solved and Unsolved Problems in Graph Theory: Implications for Computing Education](https://arxiv.org/abs/2602.05059)
*Adithya Kulkarni,Mohna Chakraborty,Jay Bagga*

Main category: cs.AI

TL;DR: LLMs在已解决的图论问题上表现良好，能提供正确证明，但在开放问题上只能提供解释和探索策略，无法产生新数学见解，适合概念探索但需独立验证。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs被学生用于计算机科学高级内容学习，需要了解其在数学严谨思维方面的可靠性，特别是在图论等数学领域。

Method: 使用八阶段评估协议模拟真实数学探究过程，包括解释、探索、策略形成和证明构建，测试LLM在已解决图论问题和开放问题上的表现。

Result: LLM在已解决问题上表现优异：提供正确定义、识别相关结构、准确回忆结果并构建有效证明；在开放问题上能生成连贯解释和合理探索策略，但无法推进解决方案。

Conclusion: LLMs适合支持已建立材料的概念探索，但在需要新颖数学见解或关键结构推理的任务中仍有局限，教育中应引导学生将其用于概念探索，同时依赖独立验证和严谨论证。

Abstract: Large Language Models are increasingly used by students to explore advanced material in computer science, including graph theory. As these tools become integrated into undergraduate and graduate coursework, it is important to understand how reliably they support mathematically rigorous thinking. This study examines the performance of a LLM on two related graph theoretic problems: a solved problem concerning the gracefulness of line graphs and an open problem for which no solution is currently known. We use an eight stage evaluation protocol that reflects authentic mathematical inquiry, including interpretation, exploration, strategy formation, and proof construction.
  The model performed strongly on the solved problem, producing correct definitions, identifying relevant structures, recalling appropriate results without hallucination, and constructing a valid proof confirmed by a graph theory expert. For the open problem, the model generated coherent interpretations and plausible exploratory strategies but did not advance toward a solution. It did not fabricate results and instead acknowledged uncertainty, which is consistent with the explicit prompting instructions that directed the model to avoid inventing theorems or unsupported claims.
  These findings indicate that LLMs can support exploration of established material but remain limited in tasks requiring novel mathematical insight or critical structural reasoning. For computing education, this distinction highlights the importance of guiding students to use LLMs for conceptual exploration while relying on independent verification and rigorous argumentation for formal problem solving.

</details>


### [24] [Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents](https://arxiv.org/abs/2602.05073)
*Changdae Oh,Seongheon Park,To Eun Kim,Jiatong Li,Wendi Li,Samuel Yeh,Xuefeng Du,Hamed Hassani,Paul Bogdan,Dawn Song,Sharon Li*

Main category: cs.AI

TL;DR: 本文提出了首个通用的智能体不确定性量化（UQ）框架，指出现有方法将LLM UQ视为不确定性累积过程，不适用于开放世界中的交互式智能体，并提出条件性不确定性减少的新视角。


<details>
  <summary>Details</summary>
Motivation: 当前不确定性量化研究主要集中于单轮问答，而LLM智能体在复杂任务中的部署日益增多，需要面向交互式智能体的新UQ框架。

Method: 提出了首个通用的智能体UQ公式化框架，涵盖现有各类UQ设置；提出条件性不确定性减少的新视角，强调行动的"交互性"；设计了一个概念框架为LLM智能体UQ提供指导。

Result: 展示了现有方法隐含地将LLM UQ视为不确定性累积过程，这在开放世界交互式智能体中失效；提出了条件性不确定性减少的视角，能够显式建模智能体轨迹中的可减少不确定性。

Conclusion: 智能体UQ对前沿LLM开发和领域特定应用具有实际意义，但仍存在开放性问题需要解决；需要将UQ研究转向现实交互式智能体设置。

Abstract: Uncertainty quantification (UQ) for large language models (LLMs) is a key building block for safety guardrails of daily LLM applications. Yet, even as LLM agents are increasingly deployed in highly complex tasks, most UQ research still centers on single-turn question-answering. We argue that UQ research must shift to realistic settings with interactive agents, and that a new principled framework for agent UQ is needed. This paper presents the first general formulation of agent UQ that subsumes broad classes of existing UQ setups. Under this formulation, we show that prior works implicitly treat LLM UQ as an uncertainty accumulation process, a viewpoint that breaks down for interactive agents in an open world. In contrast, we propose a novel perspective, a conditional uncertainty reduction process, that explicitly models reducible uncertainty over an agent's trajectory by highlighting "interactivity" of actions. From this perspective, we outline a conceptual framework to provide actionable guidance for designing UQ in LLM agent setups. Finally, we conclude with practical implications of the agent UQ in frontier LLM development and domain-specific applications, as well as open remaining problems.

</details>


### [25] [Optimizing Mission Planning for Multi-Debris Rendezvous Using Reinforcement Learning with Refueling and Adaptive Collision Avoidance](https://arxiv.org/abs/2602.05075)
*Agni Bandyopadhyay,Gunther Waxenegger-Wilfing*

Main category: cs.AI

TL;DR: 提出基于强化学习的自适应碰撞规避框架，用于多碎片主动清除任务，通过掩码PPO算法优化燃料效率和任务时间，降低碰撞风险。


<details>
  <summary>Details</summary>
Motivation: 随着地球轨道碎片日益增多，主动碎片清除任务面临安全操作和碰撞风险的挑战。小型卫星因其灵活性、成本效益和机动性成为理想选择，但需要更智能的碰撞规避方案。

Method: 采用掩码近端策略优化（PPO）强化学习算法，集成加油策略、高效任务规划和自适应碰撞规避，动态调整机动操作以响应实时轨道条件。

Result: 基于Iridium 33碎片数据集的模拟评估显示，该RL框架相比传统启发式方法，在降低碰撞风险的同时提高了任务效率，适用于多种轨道配置和碎片分布。

Conclusion: 该工作为复杂多碎片清除任务提供了可扩展解决方案，并适用于自主空间任务规划中的其他多目标交会问题。

Abstract: As the orbital environment around Earth becomes increasingly crowded with debris, active debris removal (ADR) missions face significant challenges in ensuring safe operations while minimizing the risk of in-orbit collisions. This study presents a reinforcement learning (RL) based framework to enhance adaptive collision avoidance in ADR missions, specifically for multi-debris removal using small satellites. Small satellites are increasingly adopted due to their flexibility, cost effectiveness, and maneuverability, making them well suited for dynamic missions such as ADR.
  Building on existing work in multi-debris rendezvous, the framework integrates refueling strategies, efficient mission planning, and adaptive collision avoidance to optimize spacecraft rendezvous operations. The proposed approach employs a masked Proximal Policy Optimization (PPO) algorithm, enabling the RL agent to dynamically adjust maneuvers in response to real-time orbital conditions. Key considerations include fuel efficiency, avoidance of active collision zones, and optimization of dynamic orbital parameters.
  The RL agent learns to determine efficient sequences for rendezvousing with multiple debris targets, optimizing fuel usage and mission time while incorporating necessary refueling stops. Simulated ADR scenarios derived from the Iridium 33 debris dataset are used for evaluation, covering diverse orbital configurations and debris distributions to demonstrate robustness and adaptability. Results show that the proposed RL framework reduces collision risk while improving mission efficiency compared to traditional heuristic approaches.
  This work provides a scalable solution for planning complex multi-debris ADR missions and is applicable to other multi-target rendezvous problems in autonomous space mission planning.

</details>


### [26] [VERA-MH: Reliability and Validity of an Open-Source AI Safety Evaluation in Mental Health](https://arxiv.org/abs/2602.05088)
*Kate H. Bentley,Luca Belli,Adam M. Chekroud,Emily J. Ward,Emily R. Dworkin,Emily Van Ark,Kelly M. Johnston,Will Alexander,Millard Brown,Matt Hawrilenko*

Main category: cs.AI

TL;DR: VERA-MH评估框架在AI心理健康应用中的临床有效性和可靠性验证研究，通过模拟对话评估AI聊天机器人在自杀风险检测中的安全性。


<details>
  <summary>Details</summary>
Motivation: 随着数百万人使用生成式AI聊天机器人进行心理支持，AI在心理健康领域的安全性成为最紧迫的问题，需要建立基于证据的自动化安全基准。

Method: 首先模拟大量基于LLM的用户代理与通用AI聊天机器人的对话，然后由持证心理健康临床医生使用评分指南独立评估对话中的安全/不安全行为及用户代理真实性，同时让LLM法官使用相同标准评估相同对话集。

Result: 临床医生之间的安全评分一致性较高（IRR: 0.77），建立了黄金标准临床参考；LLM法官与临床共识高度一致（IRR: 0.81）；临床医生普遍认为用户代理具有真实性。

Conclusion: 研究支持VERA-MH的临床有效性和可靠性，这是一个开源、全自动的AI心理健康安全评估工具。要实现AI聊天机器人的心理健康益处，安全性至关重要，未来研究将关注其普适性和鲁棒性。

Abstract: Millions now use leading generative AI chatbots for psychological support. Despite the promise related to availability and scale, the single most pressing question in AI for mental health is whether these tools are safe. The Validation of Ethical and Responsible AI in Mental Health (VERA-MH) evaluation was recently proposed to meet the urgent need for an evidence-based automated safety benchmark. This study aimed to examine the clinical validity and reliability of the VERA-MH evaluation for AI safety in suicide risk detection and response. We first simulated a large set of conversations between large language model (LLM)-based users (user-agents) and general-purpose AI chatbots. Licensed mental health clinicians used a rubric (scoring guide) to independently rate the simulated conversations for safe and unsafe chatbot behaviors, as well as user-agent realism. An LLM-based judge used the same scoring rubric to evaluate the same set of simulated conversations. We then compared rating alignment across (a) individual clinicians and (b) clinician consensus and the LLM judge, and (c) examined clinicians' ratings of user-agent realism. Individual clinicians were generally consistent with one another in their safety ratings (chance-corrected inter-rater reliability [IRR]: 0.77), thus establishing a gold-standard clinical reference. The LLM judge was strongly aligned with this clinical consensus (IRR: 0.81) overall and within key conditions. Clinician raters generally perceived the user-agents to be realistic. For the potential mental health benefits of AI chatbots to be realized, attention to safety is paramount. Findings from this human evaluation study support the clinical validity and reliability of VERA-MH: an open-source, fully automated AI safety evaluation for mental health. Further research will address VERA-MH generalizability and robustness.

</details>


### [27] [Evaluating Robustness and Adaptability in Learning-Based Mission Planning for Active Debris Removal](https://arxiv.org/abs/2602.05091)
*Agni Bandyopadhyay,Günther Waxenegger-Wilfing*

Main category: cs.AI

TL;DR: 比较三种自主任务规划器在低地球轨道多碎片交会问题中的表现：固定参数训练的Masked PPO、域随机化训练的Masked PPO和蒙特卡洛树搜索基线，发现学习策略的速度与搜索方法的适应性之间存在权衡。


<details>
  <summary>Details</summary>
Motivation: 主动碎片清除任务规划需要在效率、适应性和严格的燃料与任务时间约束之间取得平衡，需要开发能够应对不同任务约束条件的稳健规划器。

Method: 使用三种规划器：1) 在固定任务参数下训练的名义Masked PPO策略；2) 在不同任务约束下训练的域随机化Masked PPO策略；3) 普通蒙特卡洛树搜索基线。在高保真轨道模拟中进行评估，包含加油、真实转移动力学和随机化碎片场。

Result: 名义PPO在训练条件匹配时表现最佳，但在分布偏移下性能急剧下降；域随机化PPO表现出更好的适应性，仅损失中等名义性能；MCTS始终能最好地处理约束变化，但计算时间高出几个数量级。

Conclusion: 学习策略的速度与搜索方法的适应性之间存在权衡，结合训练时多样性和在线规划可能是未来稳健ADR任务规划器的有前途路径。

Abstract: Autonomous mission planning for Active Debris Removal (ADR) must balance efficiency, adaptability, and strict feasibility constraints on fuel and mission duration. This work compares three planners for the constrained multi-debris rendezvous problem in Low Earth Orbit: a nominal Masked Proximal Policy Optimization (PPO) policy trained under fixed mission parameters, a domain-randomized Masked PPO policy trained across varying mission constraints for improved robustness, and a plain Monte Carlo Tree Search (MCTS) baseline. Evaluations are conducted in a high-fidelity orbital simulation with refueling, realistic transfer dynamics, and randomized debris fields across 300 test cases in nominal, reduced fuel, and reduced mission time scenarios. Results show that nominal PPO achieves top performance when conditions match training but degrades sharply under distributional shift, while domain-randomized PPO exhibits improved adaptability with only moderate loss in nominal performance. MCTS consistently handles constraint changes best due to online replanning but incurs orders-of-magnitude higher computation time. The findings underline a trade-off between the speed of learned policies and the adaptability of search-based methods, and suggest that combining training-time diversity with online planning could be a promising path for future resilient ADR mission planners.

</details>


### [28] [GAMMS: Graph based Adversarial Multiagent Modeling Simulator](https://arxiv.org/abs/2602.05105)
*Rohan Patil,Jai Malegaonkar,Xiao Jiang,Andre Dion,Gaurav S. Sukhatme,Henrik I. Christensen*

Main category: cs.AI

TL;DR: GAMMS是一个轻量级、可扩展的多智能体模拟框架，使用图结构表示环境，支持快速开发和评估智能体行为，特别适合城市道路网络和通信系统等复杂领域。


<details>
  <summary>Details</summary>
Motivation: 现有高保真模拟器计算成本高，不适合快速原型设计和大规模智能体部署。需要既具有可扩展性又易于使用的模拟工具来支持智能系统和多智能体协调的研究与应用。

Method: 开发基于图的对抗多智能体建模模拟器(GAMMS)，强调五个核心目标：可扩展性、易用性、集成优先架构、快速可视化反馈和现实世界基础。支持启发式、基于优化和基于学习的智能体，包括使用大语言模型的智能体。

Result: GAMMS能够高效模拟复杂领域，支持与外部工具（如机器学习库、规划求解器）集成，提供内置可视化功能且配置简单。框架开源，可在标准硬件上实现高性能模拟。

Conclusion: GAMMS降低了研究人员进入门槛，促进了多智能体系统、自主规划和对抗建模领域的实验与创新，为智能系统和多智能体协调提供了实用的模拟工具。

Abstract: As intelligent systems and multi-agent coordination become increasingly central to real-world applications, there is a growing need for simulation tools that are both scalable and accessible. Existing high-fidelity simulators, while powerful, are often computationally expensive and ill-suited for rapid prototyping or large-scale agent deployments. We present GAMMS (Graph based Adversarial Multiagent Modeling Simulator), a lightweight yet extensible simulation framework designed to support fast development and evaluation of agent behavior in environments that can be represented as graphs. GAMMS emphasizes five core objectives: scalability, ease of use, integration-first architecture, fast visualization feedback, and real-world grounding. It enables efficient simulation of complex domains such as urban road networks and communication systems, supports integration with external tools (e.g., machine learning libraries, planning solvers), and provides built-in visualization with minimal configuration. GAMMS is agnostic to policy type, supporting heuristic, optimization-based, and learning-based agents, including those using large language models. By lowering the barrier to entry for researchers and enabling high-performance simulations on standard hardware, GAMMS facilitates experimentation and innovation in multi-agent systems, autonomous planning, and adversarial modeling. The framework is open-source and available at https://github.com/GAMMSim/GAMMS/

</details>


### [29] [Understanding LLM Evaluator Behavior: A Structured Multi-Evaluator Framework for Merchant Risk Assessment](https://arxiv.org/abs/2602.05110)
*Liang Wang,Junpeng Wang,Chin-chia Michael Yeh,Yan Zheng,Jiarui Sun,Xiran Fan,Xin Dai,Yujie Fan,Yiwei Cai*

Main category: cs.AI

TL;DR: 论文提出了一个结构化多评估者框架，用于评估LLM在商户风险分类中的推理质量，通过共识偏差指标消除循环性，发现不同LLM存在显著评估偏差，匿名化可减少偏差，部分LLM与人类专家判断更接近。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地被用作推理质量的评估者，但在支付风险场景中的可靠性和偏差仍不清楚。需要建立一个可复现的框架来评估LLM作为评估者在金融操作环境中的表现。

Method: 引入结构化多评估者框架，结合五标准评分表和蒙特卡洛评分来评估推理质量和评估者稳定性。五个前沿LLM在署名和匿名条件下生成并交叉评估MCC风险推理。使用共识偏差指标消除循环性，比较每个评估者得分与其他评估者均值的差异。通过26名支付行业专家和支付网络数据进行验证。

Result: 结果显示显著异质性：GPT-5.1和Claude 4.5 Sonnet显示负自评估偏差(-0.33, -0.31)，而Gemini-2.5 Pro和Grok 4显示正偏差(+0.77, +0.71)。匿名化使偏差减少25.8%。LLM评估者评分平均比人类共识高+0.46分，GPT-5.1和Claude 4.5 Sonnet的负偏差反映与人类判断更接近。支付网络数据验证显示四个模型具有统计显著相关性(Spearman rho = 0.56-0.77)。

Conclusion: 该框架为评估LLM作为评估者在支付风险工作流中提供了可复现的基础，并强调了在操作金融环境中需要偏差感知协议。GPT-5.1和Claude 4.5 Sonnet的负自评估偏差实际上反映了与人类专家判断更好的一致性。

Abstract: Large Language Models (LLMs) are increasingly used as evaluators of reasoning quality, yet their reliability and bias in payments-risk settings remain poorly understood. We introduce a structured multi-evaluator framework for assessing LLM reasoning in Merchant Category Code (MCC)-based merchant risk assessment, combining a five-criterion rubric with Monte-Carlo scoring to evaluate rationale quality and evaluator stability. Five frontier LLMs generate and cross-evaluate MCC risk rationales under attributed and anonymized conditions. To establish a judge-independent reference, we introduce a consensus-deviation metric that eliminates circularity by comparing each judge's score to the mean of all other judges, yielding a theoretically grounded measure of self-evaluation and cross-model deviation. Results reveal substantial heterogeneity: GPT-5.1 and Claude 4.5 Sonnet show negative self-evaluation bias (-0.33, -0.31), while Gemini-2.5 Pro and Grok 4 display positive bias (+0.77, +0.71), with bias attenuating by 25.8 percent under anonymization. Evaluation by 26 payment-industry experts shows LLM judges assign scores averaging +0.46 points above human consensus, and that the negative bias of GPT-5.1 and Claude 4.5 Sonnet reflects closer alignment with human judgment. Ground-truth validation using payment-network data shows four models exhibit statistically significant alignment (Spearman rho = 0.56 to 0.77), confirming that the framework captures genuine quality. Overall, the framework provides a replicable basis for evaluating LLM-as-a-judge systems in payment-risk workflows and highlights the need for bias-aware protocols in operational financial settings.

</details>


### [30] [Democratic Preference Alignment via Sortition-Weighted RLHF](https://arxiv.org/abs/2602.05113)
*Suvadip Sana,Jinzhou Wu,Martin T. Wells*

Main category: cs.AI

TL;DR: DemPO框架通过算法抽签构建代表性人类评分者小组，在偏好对齐训练中实现人口统计学代表性，相比未加权基线显著提升模型与代表性公众价值观的一致性。


<details>
  <summary>Details</summary>
Motivation: 当前AI偏好对齐方法（如RLHF）依赖的人类评分者通常是便利样本，存在人口统计学代表性偏差，无法反映更广泛公众的价值观。

Method: 提出民主偏好优化（DemPO）框架，采用公民大会的算法抽签机制：硬面板方案仅使用满足配额的代表性小组数据；软面板方案保留所有数据但按抽签包含概率重新加权。

Result: 在10亿到80亿参数的Llama模型上评估，硬面板在六种聚合方法中始终排名第一，软面板始终优于未加权基线，且模型容量越大效果越明显。

Conclusion: 在偏好收集阶段强制实施人口统计学代表性，而非事后校正，能产生更准确反映代表性公众价值观的模型行为。

Abstract: Whose values should AI systems learn? Preference based alignment methods like RLHF derive their training signal from human raters, yet these rater pools are typically convenience samples that systematically over represent some demographics and under represent others. We introduce Democratic Preference Optimization, or DemPO, a framework that applies algorithmic sortition, the same mechanism used to construct citizen assemblies, to preference based fine tuning. DemPO offers two training schemes. Hard Panel trains exclusively on preferences from a quota satisfying mini public sampled via sortition. Soft Panel retains all data but reweights each rater by their inclusion probability under the sortition lottery. We prove that Soft Panel weighting recovers the expected Hard Panel objective in closed form. Using a public preference dataset that pairs human judgments with rater demographics and a seventy five clause constitution independently elicited from a representative United States panel, we evaluate Llama models from one billion to eight billion parameters fine tuned under each scheme. Across six aggregation methods, the Hard Panel consistently ranks first and the Soft Panel consistently outperforms the unweighted baseline, with effect sizes growing as model capacity increases. These results demonstrate that enforcing demographic representativeness at the preference collection stage, rather than post hoc correction, yields models whose behavior better reflects values elicited from representative publics.

</details>


### [31] [SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers](https://arxiv.org/abs/2602.05115)
*Keyang Xuan,Pengda Wang,Chongrui Ye,Haofei Yu,Tal August,Jiaxuan You*

Main category: cs.AI

TL;DR: SocialVeil：一个模拟认知差异导致沟通障碍的社会学习环境，用于评估LLM在现实不完美沟通中的社会智能


<details>
  <summary>Details</summary>
Motivation: 现有基准测试假设理想化沟通，无法诊断LLM在现实不完美沟通中维持和修复互动的能力，需要更贴近真实世界的社交互动环境

Method: 基于系统文献综述提出三种代表性沟通障碍类型（语义模糊、社会文化不匹配、情感干扰），开发SocialVeil环境，引入两种障碍感知评估指标（未解决困惑、相互理解），在720个场景中测试四种前沿LLM

Result: 沟通障碍显著损害LLM表现：相互理解平均降低超过45%，困惑度提升近50%；人类评估验证模拟障碍的保真度（ICC≈0.78，Pearson r≈0.80）；适应策略（修复指令和交互学习）效果有限，远未达到无障碍表现

Conclusion: SocialVeil将社交互动环境向真实世界沟通推进了一步，为探索LLM代理的社会智能提供了新机会，揭示了当前LLM在应对沟通障碍方面的局限性

Abstract: Large language models (LLMs) are increasingly evaluated in interactive environments to test their social intelligence. However, existing benchmarks often assume idealized communication between agents, limiting our ability to diagnose whether LLMs can maintain and repair interactions in more realistic, imperfect settings. To close this gap, we present \textsc{SocialVeil}, a social learning environment that can simulate social interaction under cognitive-difference-induced communication barriers. Grounded in a systematic literature review of communication challenges in human interaction, \textsc{SocialVeil} introduces three representative types of such disruption, \emph{semantic vagueness}, \emph{sociocultural mismatch}, and \emph{emotional interference}. We also introduce two barrier-aware evaluation metrics, \emph{unresolved confusion} and \emph{mutual understanding}, to evaluate interaction quality under impaired communication. Experiments across 720 scenarios and four frontier LLMs show that barriers consistently impair performance, with mutual understanding reduced by over 45\% on average, and confusion elevated by nearly 50\%. Human evaluations validate the fidelity of these simulated barriers (ICC$\approx$0.78, Pearson r$\approx$0.80). We further demonstrate that adaptation strategies (Repair Instruction and Interactive learning) only have a modest effect far from barrier-free performance. This work takes a step toward bringing social interaction environments closer to real-world communication, opening opportunities for exploring the social intelligence of LLM agents.

</details>


### [32] [CAST-CKT: Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer for Traffic Flow Prediction](https://arxiv.org/abs/2602.05133)
*Abdul Joseph Fofanah,Lian Wen,David Chen,Alpha Alimamy Kamara,Zhongyi Zhang*

Main category: cs.AI

TL;DR: CAST-CKT是一个用于数据稀缺跨城市交通预测的混沌感知时空知识迁移框架，通过混沌分析量化交通可预测性机制，实现机制自适应建模和跨城市知识迁移。


<details>
  <summary>Details</summary>
Motivation: 数据稀缺的跨城市交通预测面临复杂非线性动态和领域偏移的挑战，现有方法难以捕捉交通的固有混沌特性进行有效的少样本学习。

Method: 提出混沌感知时空和跨城市知识迁移框架，使用高效混沌分析器量化交通可预测性机制，包括：机制自适应注意力、自适应拓扑学习、混沌一致性跨城市对齐，并提供具有不确定性量化的特定时间范围预测。

Result: 在四个基准数据集上的跨城市少样本实验中，CAST-CKT在MAE和RMSE指标上显著优于现有最先进方法，同时提供可解释的机制分析。

Conclusion: CAST-CKT通过混沌感知建模有效解决了跨城市少样本交通预测问题，理论分析显示改进的泛化边界，框架具有实际应用价值。

Abstract: Traffic prediction in data-scarce, cross-city settings is challenging due to complex nonlinear dynamics and domain shifts. Existing methods often fail to capture traffic's inherent chaotic nature for effective few-shot learning. We propose CAST-CKT, a novel Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer framework. It employs an efficient chaotic analyser to quantify traffic predictability regimes, driving several key innovations: chaos-aware attention for regime-adaptive temporal modelling; adaptive topology learning for dynamic spatial dependencies; and chaotic consistency-based cross-city alignment for knowledge transfer. The framework also provides horizon-specific predictions with uncertainty quantification. Theoretical analysis shows improved generalisation bounds. Extensive experiments on four benchmarks in cross-city few-shot settings show CAST-CKT outperforms state-of-the-art methods by significant margins in MAE and RMSE, while offering interpretable regime analysis. Code is available at https://github.com/afofanah/CAST-CKT.

</details>


### [33] [HugRAG: Hierarchical Causal Knowledge Graph Design for RAG](https://arxiv.org/abs/2602.05143)
*Nengbo Wang,Tuo Liang,Vikash Singh,Chaoda Song,Van Yang,Yu Yin,Jing Ma,Jagdip Singh,Vipin Chaudhary*

Main category: cs.AI

TL;DR: HugRAG是一个基于因果门控的层次化图RAG框架，通过显式建模因果关系来抑制虚假相关性，实现大规模知识图上的可扩展推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的RAG方法过度依赖表层节点匹配，缺乏显式因果建模，导致答案不可靠或虚假。先前尝试融入因果关系的方法通常局限于局部或单文档上下文，且受模块化图结构导致的信息隔离问题影响，阻碍了可扩展性和跨模块因果推理。

Method: 提出HugRAG框架，通过因果门控在层次化模块间重新思考知识组织。该框架显式建模因果关系以抑制虚假相关性，同时支持在大规模知识图上进行可扩展推理。

Result: 大量实验表明，HugRAG在多个数据集和评估指标上持续优于竞争性的基于图的RAG基线方法。

Conclusion: 这项工作为结构化、可扩展且基于因果基础的RAG系统建立了原则性基础。

Abstract: Retrieval augmented generation (RAG) has enhanced large language models by enabling access to external knowledge, with graph-based RAG emerging as a powerful paradigm for structured retrieval and reasoning. However, existing graph-based methods often over-rely on surface-level node matching and lack explicit causal modeling, leading to unfaithful or spurious answers. Prior attempts to incorporate causality are typically limited to local or single-document contexts and also suffer from information isolation that arises from modular graph structures, which hinders scalability and cross-module causal reasoning. To address these challenges, we propose HugRAG, a framework that rethinks knowledge organization for graph-based RAG through causal gating across hierarchical modules. HugRAG explicitly models causal relationships to suppress spurious correlations while enabling scalable reasoning over large-scale knowledge graphs. Extensive experiments demonstrate that HugRAG consistently outperforms competitive graph-based RAG baselines across multiple datasets and evaluation metrics. Our work establishes a principled foundation for structured, scalable, and causally grounded RAG systems.

</details>


### [34] [First Proof](https://arxiv.org/abs/2602.05192)
*Mohammed Abouzaid,Andrew J. Blumberg,Martin Hairer,Joe Kileel,Tamara G. Kolda,Paul D. Nelson,Daniel Spielman,Nikhil Srivastava,Rachel Ward,Shmuel Weinberger,Lauren Williams*

Main category: cs.AI

TL;DR: 作者分享了10个研究级数学问题来评估当前AI系统回答数学研究问题的能力


<details>
  <summary>Details</summary>
Motivation: 评估当前AI系统在回答研究级数学问题方面的能力，这些问题来自作者实际研究过程中自然产生的问题

Method: 创建并分享10个未公开的研究级数学问题，这些问题来自作者的实际研究过程，答案暂时加密

Result: 提供了一套可用于评估AI数学能力的测试集，包含10个研究级数学问题

Conclusion: 通过分享这些研究级数学问题，为评估AI系统的数学推理能力提供了一个基准测试平台

Abstract: To assess the ability of current AI systems to correctly answer research-level mathematics questions, we share a set of ten math questions which have arisen naturally in the research process of the authors. The questions had not been shared publicly until now; the answers are known to the authors of the questions but will remain encrypted for a short time.

</details>


### [35] [Traceable Cross-Source RAG for Chinese Tibetan Medicine Question Answering](https://arxiv.org/abs/2602.05195)
*Fengxian Chen,Zhilong Tao,Jiaxuan Li,Yunlong Li,Qingguo Zhou*

Main category: cs.AI

TL;DR: 该论文针对多知识库检索增强生成中的权威性偏差问题，提出DAKS路由和预算检索方法以及对齐图证据融合，在藏医药领域实现更好的跨知识库证据覆盖和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 在多知识库检索增强生成中，密集的百科全书条目容易主导检索过程，而经典文献和临床论文等更具权威性的证据被忽视。特别是在藏医药领域，需要解决跨知识库检索的权威性偏差问题。

Method: 提出两种互补方法：1) DAKS进行知识库路由和预算检索，缓解密度驱动偏差并优先考虑权威来源；2) 使用对齐图指导证据融合和覆盖感知打包，改善跨知识库证据覆盖而不依赖简单拼接。

Result: 实验显示路由质量和跨知识库证据覆盖方面的一致提升，完整系统在保持强忠实性和引用正确性的同时，实现了最佳的CrossEv@5指标。

Conclusion: 该方法能有效解决多知识库检索增强生成中的权威性偏差问题，提高跨知识库证据覆盖和可追溯性，在藏医药等专业领域具有实用价值。

Abstract: Retrieval-augmented generation (RAG) promises grounded question answering, yet domain settings with multiple heterogeneous knowledge bases (KBs) remain challenging. In Chinese Tibetan medicine, encyclopedia entries are often dense and easy to match, which can dominate retrieval even when classics or clinical papers provide more authoritative evidence. We study a practical setting with three KBs (encyclopedia, classics, and clinical papers) and a 500-query benchmark (cutoff $K{=}5$) covering both single-KB and cross-KB questions. We propose two complementary methods to improve traceability, reduce hallucinations, and enable cross-KB verification. First, DAKS performs KB routing and budgeted retrieval to mitigate density-driven bias and to prioritize authoritative sources when appropriate. Second, we use an alignment graph to guide evidence fusion and coverage-aware packing, improving cross-KB evidence coverage without relying on naive concatenation. All answers are generated by a lightweight generator, \textsc{openPangu-Embedded-7B}. Experiments show consistent gains in routing quality and cross-KB evidence coverage, with the full system achieving the best CrossEv@5 while maintaining strong faithfulness and citation correctness.

</details>


### [36] [Surgery: Mitigating Harmful Fine-Tuning for Large Language Models via Attention Sink](https://arxiv.org/abs/2602.05228)
*Guozhi Liu,Weiwei Lin,Tiansheng Huang,Ruichao Mo,Qi Mu,Xiumin Wang,Li Shen*

Main category: cs.AI

TL;DR: 提出Surgery方法，利用注意力汇聚机制中的sink divergence统计量来防御有害微调，通过正则化抑制正sink divergence，防止模型学习有害模式


<details>
  <summary>Details</summary>
Motivation: 有害微调会破坏大语言模型的安全对齐，带来显著安全风险。现有防御方法不足，需要新的防御机制来防止模型在微调过程中学习有害模式。

Method: 提出Surgery防御方法：1) 测量每个注意力头的sink divergence统计量；2) 发现正sink divergence的注意力头数量随模型有害性增加而增加；3) 提出可分离sink divergence假设；4) 使用sink divergence抑制正则化器，引导注意力头朝向负sink divergence组

Result: 在BeaverTails、HarmBench和SorryBench基准测试上，Surgery分别提升了5.90%、11.25%和9.55%的防御性能，有效减少了模型学习有害模式的倾向

Conclusion: 通过利用注意力汇聚机制中的sink divergence统计量，Surgery方法能够在微调阶段有效防御有害微调，提高大语言模型的安全性，为模型安全对齐提供了新的防御思路

Abstract: Harmful fine-tuning can invalidate safety alignment of large language models, exposing significant safety risks. In this paper, we utilize the attention sink mechanism to mitigate harmful fine-tuning. Specifically, we first measure a statistic named \emph{sink divergence} for each attention head and observe that \emph{different attention heads exhibit two different signs of sink divergence}. To understand its safety implications, we conduct experiments and find that the number of attention heads of positive sink divergence increases along with the increase of the model's harmfulness when undergoing harmful fine-tuning. Based on this finding, we propose a separable sink divergence hypothesis -- \emph{attention heads associating with learning harmful patterns during fine-tuning are separable by their sign of sink divergence}. Based on the hypothesis, we propose a fine-tuning-stage defense, dubbed Surgery. Surgery utilizes a regularizer for sink divergence suppression, which steers attention heads toward the negative sink divergence group, thereby reducing the model's tendency to learn and amplify harmful patterns. Extensive experiments demonstrate that Surgery improves defense performance by 5.90\%, 11.25\%, and 9.55\% on the BeaverTails, HarmBench, and SorryBench benchmarks, respectively. Source code is available on https://github.com/Lslland/Surgery.

</details>


### [37] [Explainable AI: A Combined XAI Framework for Explaining Brain Tumour Detection Models](https://arxiv.org/abs/2602.05240)
*Patrick McGonagle,William Farrelly,Kevin Curran*

Main category: cs.AI

TL;DR: 该研究通过整合GRAD-CAM、LRP和SHAP三种可解释AI技术，提升脑肿瘤检测深度学习模型的可解释性，在BraTS 2021数据集上达到91.24%准确率，提供从区域到像素级的全面解释。


<details>
  <summary>Details</summary>
Motivation: 在医疗影像分析中，AI模型的决策过程缺乏透明度会影响临床信任。特别是脑肿瘤检测等关键任务，需要更全面的解释来增强AI系统的可靠性和可接受性。

Method: 开发定制卷积神经网络(CNN)并在BraTS 2021数据集上训练，整合三种XAI技术：GRAD-CAM突出重要空间区域，LRP提供像素级相关性，SHAP量化特征贡献，形成多层次解释框架。

Result: 模型达到91.24%的肿瘤检测准确率，集成XAI方法成功识别完整和部分肿瘤，提供从广泛感兴趣区域到像素细节的分层解释，在解释能力上优于单一XAI方法。

Conclusion: 集成多种XAI技术能显著提升AI医疗影像系统的透明度和可信度，为脑肿瘤检测等关键医疗任务提供更全面的解释框架，推动AI在医疗领域的可靠应用。

Abstract: This study explores the integration of multiple Explainable AI (XAI) techniques to enhance the interpretability of deep learning models for brain tumour detection. A custom Convolutional Neural Network (CNN) was developed and trained on the BraTS 2021 dataset, achieving 91.24% accuracy in distinguishing between tumour and non-tumour regions. This research combines Gradient-weighted Class Activation Mapping (GRAD-CAM), Layer-wise Relevance Propagation (LRP) and SHapley Additive exPlanations (SHAP) to provide comprehensive insights into the model's decision-making process. This multi-technique approach successfully identified both full and partial tumours, offering layered explanations ranging from broad regions of interest to pixel-level details. GRAD-CAM highlighted important spatial regions, LRP provided detailed pixel-level relevance and SHAP quantified feature contributions. The integrated approach effectively explained model predictions, including cases with partial tumour visibility thus showing superior explanatory power compared to individual XAI methods. This research enhances transparency and trust in AI-driven medical imaging analysis by offering a more comprehensive perspective on the model's reasoning. The study demonstrates the potential of integrated XAI techniques in improving the reliability and interpretability of AI systems in healthcare, particularly for critical tasks like brain tumour detection.

</details>


### [38] [Automatic Cognitive Task Generation for In-Situ Evaluation of Embodied Agents](https://arxiv.org/abs/2602.05249)
*Xinyi He,Ying Yang,Chuanjian Fu,Sihan Guo,Songchun Zhu,Lifeng Fan,Zhenliang Zhang,Yujia Peng*

Main category: cs.AI

TL;DR: TEA：面向未见3D环境的动态原位任务生成方法，通过交互-演化两阶段系统自动生成任务，用于评估智能体在真实环境中的能力


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在严重的数据污染问题，缺乏场景特异性，无法有效评估智能体在未见环境中的真实能力。随着通用智能体即将广泛部署到多样化家庭环境中，需要针对每个独特未见3D环境进行评估。

Method: 提出动态原位任务生成方法TEA，采用结构化图表示定义任务，构建交互-演化两阶段系统。交互阶段：智能体主动与环境互动，形成任务执行与生成的循环；演化阶段：通过任务图建模，重组和重用现有任务生成新任务，无需外部数据。

Result: 在10个未见场景中，TEA在两个周期内自动生成了87,876个任务，经人工验证具有物理合理性并涵盖基本日常认知能力。评估发现：SOTA模型在公共基准上表现优异，但在基本感知任务上表现糟糕，严重缺乏3D交互意识，对任务类型的推理高度敏感。

Conclusion: 这些令人警醒的发现表明，在将智能体部署到真实人类环境之前，必须进行原位评估。TEA方法为未见环境中的智能体能力评估提供了有效解决方案。

Abstract: As general intelligent agents are poised for widespread deployment in diverse households, evaluation tailored to each unique unseen 3D environment has become a critical prerequisite. However, existing benchmarks suffer from severe data contamination and a lack of scene specificity, inadequate for assessing agent capabilities in unseen settings. To address this, we propose a dynamic in-situ task generation method for unseen environments inspired by human cognition. We define tasks through a structured graph representation and construct a two-stage interaction-evolution task generation system for embodied agents (TEA). In the interaction stage, the agent actively interacts with the environment, creating a loop between task execution and generation that allows for continuous task generation. In the evolution stage, task graph modeling allows us to recombine and reuse existing tasks to generate new ones without external data. Experiments across 10 unseen scenes demonstrate that TEA automatically generated 87,876 tasks in two cycles, which human verification confirmed to be physically reasonable and encompassing essential daily cognitive capabilities. Benchmarking SOTA models against humans on our in-situ tasks reveals that models, despite excelling on public benchmarks, perform surprisingly poorly on basic perception tasks, severely lack 3D interaction awareness and show high sensitivity to task types in reasoning. These sobering findings highlight the necessity of in-situ evaluation before deploying agents into real-world human environments.

</details>


### [39] [Beyond Cosine Similarity](https://arxiv.org/abs/2602.05266)
*Xinbo Ai*

Main category: cs.AI

TL;DR: 本文提出了一种新的相似度度量方法recos，它通过推导比经典柯西-施瓦茨界更紧的上界，用排序向量分量归一化点积，在语义相似性评估中优于传统余弦相似度。


<details>
  <summary>Details</summary>
Motivation: 余弦相似度作为向量空间中语义相似度的标准度量，基于柯西-施瓦茨不等式，只能捕捉线性关系，无法建模真实世界语义空间的复杂非线性结构。

Method: 通过推导比经典柯西-施瓦茨界更紧的点积上界，提出了recos相似度度量方法，该方法用排序向量分量归一化点积，将完美相似的条件从严格线性依赖放宽为序数一致性。

Result: 在11种嵌入模型（包括静态、上下文化和通用类型）上的广泛实验表明，recos在标准语义文本相似性基准测试中，与传统余弦相似度相比，始终获得与人类判断更高的相关性。

Conclusion: recos作为一种数学原理严谨且经验上更优的替代方案，为复杂嵌入空间中的语义分析提供了更高的准确性。

Abstract: Cosine similarity, the standard metric for measuring semantic similarity in vector spaces, is mathematically grounded in the Cauchy-Schwarz inequality, which inherently limits it to capturing linear relationships--a constraint that fails to model the complex, nonlinear structures of real-world semantic spaces. We advance this theoretical underpinning by deriving a tighter upper bound for the dot product than the classical Cauchy-Schwarz bound. This new bound leads directly to recos, a similarity metric that normalizes the dot product by the sorted vector components. recos relaxes the condition for perfect similarity from strict linear dependence to ordinal concordance, thereby capturing a broader class of relationships. Extensive experiments across 11 embedding models--spanning static, contextualized, and universal types--demonstrate that recos consistently outperforms traditional cosine similarity, achieving higher correlation with human judgments on standard Semantic Textual Similarity (STS) benchmarks. Our work establishes recos as a mathematically principled and empirically superior alternative, offering enhanced accuracy for semantic analysis in complex embedding spaces.

</details>


### [40] [Hallucination-Resistant Security Planning with a Large Language Model](https://arxiv.org/abs/2602.05279)
*Kim Hammar,Tansu Alpcan,Emil Lupu*

Main category: cs.AI

TL;DR: 提出一个原则性框架，将LLM集成到安全管理的迭代循环中，通过一致性检查和外部反馈控制幻觉风险，在事件响应用例中减少30%恢复时间


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在安全管理工作（如事件响应规划）中具有潜力，但其不可靠性和幻觉倾向仍然是重大挑战，需要解决这些问题以实现可靠的决策支持

Method: 设计一个原则性框架，将LLM集成到迭代循环中：LLM生成候选行动，系统检查其与约束和前瞻预测的一致性；当一致性低时，通过数字孪生等外部反馈收集信息，使用上下文学习来优化候选行动

Result: 该框架能通过调整一致性阈值来控制幻觉风险，并在某些假设下建立了上下文学习的遗憾界限；在四个公共数据集上的事件响应实验中，相比前沿LLM减少了高达30%的恢复时间

Conclusion: 提出的框架通过一致性检查和外部反馈机制有效解决了LLM在安全管理中的幻觉问题，显著提升了事件响应效率，为LLM在安全领域的可靠应用提供了新方法

Abstract: Large language models (LLMs) are promising tools for supporting security management tasks, such as incident response planning. However, their unreliability and tendency to hallucinate remain significant challenges. In this paper, we address these challenges by introducing a principled framework for using an LLM as decision support in security management. Our framework integrates the LLM in an iterative loop where it generates candidate actions that are checked for consistency with system constraints and lookahead predictions. When consistency is low, we abstain from the generated actions and instead collect external feedback, e.g., by evaluating actions in a digital twin. This feedback is then used to refine the candidate actions through in-context learning (ICL). We prove that this design allows to control the hallucination risk by tuning the consistency threshold. Moreover, we establish a bound on the regret of ICL under certain assumptions. To evaluate our framework, we apply it to an incident response use case where the goal is to generate a response and recovery plan based on system logs. Experiments on four public datasets show that our framework reduces recovery times by up to 30% compared to frontier LLMs.

</details>


### [41] [Position: Universal Time Series Foundation Models Rest on a Category Error](https://arxiv.org/abs/2602.05287)
*Xilin Dai,Wanxu Cai,Zhijian Xu,Qiang Xu*

Main category: cs.AI

TL;DR: 该文认为"通用时间序列基础模型"存在范畴错误，将结构容器误认为语义模态，主张用因果控制代理范式替代通用性追求


<details>
  <summary>Details</summary>
Motivation: 当前追求通用时间序列基础模型存在根本问题：时间序列包含不兼容的生成过程（如金融vs流体动力学），单一模型会退化为昂贵的"通用过滤器"，在分布漂移下无法泛化

Method: 提出"自回归盲界"理论证明仅依赖历史的模型无法预测干预驱动的机制转变；倡导因果控制代理范式，让代理利用外部上下文协调专业求解器层次结构（从冻结领域专家到轻量级即时适配器）

Result: 理论分析表明通用时间序列模型的局限性，提出新的评估框架：从"零样本准确率"转向"漂移适应速度"来优先考虑鲁棒的控制理论系统

Conclusion: 应放弃通用性追求，转向因果控制代理范式，通过外部上下文协调专业求解器，并改变基准测试重点以构建更鲁棒的时间序列系统

Abstract: This position paper argues that the pursuit of "Universal Foundation Models for Time Series" rests on a fundamental category error, mistaking a structural Container for a semantic Modality. We contend that because time series hold incompatible generative processes (e.g., finance vs. fluid dynamics), monolithic models degenerate into expensive "Generic Filters" that fail to generalize under distributional drift. To address this, we introduce the "Autoregressive Blindness Bound," a theoretical limit proving that history-only models cannot predict intervention-driven regime shifts. We advocate replacing universality with a Causal Control Agent paradigm, where an agent leverages external context to orchestrate a hierarchy of specialized solvers, from frozen domain experts to lightweight Just-in-Time adaptors. We conclude by calling for a shift in benchmarks from "Zero-Shot Accuracy" to "Drift Adaptation Speed" to prioritize robust, control-theoretic systems.

</details>


### [42] [Aspect-Aware MOOC Recommendation in a Heterogeneous Network](https://arxiv.org/abs/2602.05297)
*Seongyeub Chu,Jongwoo Kim,Mun Yong Yi*

Main category: cs.AI

TL;DR: AMR是一个面向MOOC推荐的方面感知框架，通过双向游走自动发现元路径，使用bi-LSTM编码器生成方面感知路径表示，并将其作为边特征融入学习者-学习者和知识点-知识点子图，实现细粒度的语义感知推荐。


<details>
  <summary>Details</summary>
Motivation: 传统MOOC推荐方法（协同过滤、基于内容的过滤）存在数据稀疏性和过度专业化问题。现有的基于图的方法虽然有所改进，但仍严重依赖手动预定义的元路径，这些元路径通常只能捕获表面结构关系，且给领域专家带来沉重负担和工程成本。

Method: 提出AMR框架：1）通过双向游走自动发现元路径；2）使用bi-LSTM编码器嵌入每个元路径中节点的语义内容，生成方面感知路径表示；3）将这些表示作为边特征融入学习者-学习者和知识点-知识点子图；4）实现细粒度的语义感知知识点推荐。

Result: 在MOOCCube和PEEK两个大规模数据集上的实验表明，AMR在HR@K和nDCG@K等关键指标上持续优于最先进的图神经网络基线。进一步分析证实AMR能有效捕获丰富的路径特定方面信息，比仅依赖预定义元路径的方法提供更准确的推荐。

Conclusion: AMR通过自动发现元路径和嵌入节点语义内容，成功克服了传统方法对预定义元路径的依赖，实现了更准确、语义更丰富的MOOC推荐，为知识图谱增强的推荐系统提供了有效解决方案。

Abstract: MOOC recommendation systems have received increasing attention to help learners navigate and select preferred learning content. Traditional methods such as collaborative filtering and content-based filtering suffer from data sparsity and over-specialization. To alleviate these limitations, graph-based approaches have been proposed; however, they still rely heavily on manually predefined metapaths, which often capture only superficial structural relationships and impose substantial burdens on domain experts as well as significant engineering costs. To overcome these limitations, we propose AMR (Aspect-aware MOOC Recommendation), a novel framework that models path-specific multiple aspects by embedding the semantic content of nodes within each metapath. AMR automatically discovers metapaths through bi-directional walks, derives aspect-aware path representations using a bi-LSTM-based encoder, and incorporates these representations as edge features in the learner-learner and KC-KC subgraphs to achieve fine-grained semantically informed KC recommendations. Extensive experiments on the large-scale MOOCCube and PEEK datasets show that AMR consistently outperforms state-of-the-art graph neural network baselines across key metrics such as HR@K and nDCG@K. Further analysis confirms that AMR effectively captures rich path-specific aspect information, allowing more accurate recommendations than those methods that rely solely on predefined metapaths. The code will be available upon accepted.

</details>


### [43] [PieArena: Frontier Language Agents Achieve MBA-Level Negotiation Performance and Reveal Novel Behavioral Differences](https://arxiv.org/abs/2602.05302)
*Chris Zhu,Sasha Cui,Will Sanok Dufallo,Runzhi Jin,Zhen Xu,Linjun Zhang,Daylian Cain*

Main category: cs.AI

TL;DR: GPT-5在谈判任务上达到或超越商学院学生水平，但鲁棒性和可信度仍需改进


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在谈判这一需要战略推理、心智理论和经济价值创造的核心商业任务上的能力，填补现有基准仅关注交易结果的不足

Method: 提出PieArena大规模谈判基准，基于精英商学院MBA课程的真实场景，进行多智能体交互评估，并研究联合意向性智能体脚手架的影响

Result: GPT-5在谈判表现上匹配或超越经过一学期谈判训练和针对性指导的商学院学生；联合意向性脚手架对中低层LLMs有显著提升，但对前沿LLMs收益递减；揭示了模型在欺骗、计算准确性、指令遵从和感知声誉等方面的异质性

Conclusion: 前沿语言智能体已具备在高风险经济环境中部署的智力和心理能力，但鲁棒性和可信度方面的缺陷仍是开放挑战

Abstract: We present an in-depth evaluation of LLMs' ability to negotiate, a central business task that requires strategic reasoning, theory of mind, and economic value creation. To do so, we introduce PieArena, a large-scale negotiation benchmark grounded in multi-agent interactions over realistic scenarios drawn from an MBA negotiation course at an elite business school. We find systematic evidence of AGI-level performance in which a representative frontier agent (GPT-5) matches or outperforms trained business-school students, despite a semester of general negotiation instruction and targeted coaching immediately prior to the task. We further study the effects of joint-intentionality agentic scaffolding and find asymmetric gains, with large improvements for mid- and lower-tier LMs and diminishing returns for frontier LMs. Beyond deal outcomes, PieArena provides a multi-dimensional negotiation behavioral profile, revealing novel cross-model heterogeneity, masked by deal-outcome-only benchmarks, in deception, computation accuracy, instruction compliance, and perceived reputation. Overall, our results suggest that frontier language agents are already intellectually and psychologically capable of deployment in high-stakes economic settings, but deficiencies in robustness and trustworthiness remain open challenges.

</details>


### [44] [ProAct: Agentic Lookahead in Interactive Environments](https://arxiv.org/abs/2602.05327)
*Yangbin Yu,Mingyu Yang,Junyou Li,Yiming Gao,Feiyu Liu,Yijun Yang,Zichuan Lin,Jiafei Lyu,Yicheng Liu,Zhicong Lu,Deheng Ye,Jie Jiang*

Main category: cs.AI

TL;DR: ProAct框架通过两阶段训练解决LLM智能体在交互环境中的长期规划问题：GLAD通过环境搜索轨迹蒸馏前瞻推理，MC-Critic通过轻量环境rollout校准价值估计，显著提升规划准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在需要长期规划的交互环境中表现不佳，主要原因是模拟未来状态时产生的复合误差。需要一种方法让智能体能够内化准确的前瞻推理能力。

Method: 提出ProAct框架：1) GLAD：通过环境搜索轨迹进行监督微调，将复杂搜索树压缩为简洁的因果推理链；2) MC-Critic：可插拔的辅助价值估计器，利用轻量环境rollout校准价值估计，增强PPO/GRPO等策略梯度算法。

Result: 在随机环境（如2048）和确定性环境（如Sokoban）中，ProAct显著提高了规划准确性。4B参数模型训练后超越所有开源基线，媲美最先进的闭源模型，并在未见环境中表现出鲁棒泛化能力。

Conclusion: ProAct通过将环境搜索蒸馏为推理链和轻量rollout校准价值估计，有效解决了LLM智能体的长期规划问题，在多种环境中展现出优越性能，代码和模型已开源。

Abstract: Existing Large Language Model (LLM) agents struggle in interactive environments requiring long-horizon planning, primarily due to compounding errors when simulating future states. To address this, we propose ProAct, a framework that enables agents to internalize accurate lookahead reasoning through a two-stage training paradigm. First, we introduce Grounded LookAhead Distillation (GLAD), where the agent undergoes supervised fine-tuning on trajectories derived from environment-based search. By compressing complex search trees into concise, causal reasoning chains, the agent learns the logic of foresight without the computational overhead of inference-time search. Second, to further refine decision accuracy, we propose the Monte-Carlo Critic (MC-Critic), a plug-and-play auxiliary value estimator designed to enhance policy-gradient algorithms like PPO and GRPO. By leveraging lightweight environment rollouts to calibrate value estimates, MC-Critic provides a low-variance signal that facilitates stable policy optimization without relying on expensive model-based value approximation. Experiments on both stochastic (e.g., 2048) and deterministic (e.g., Sokoban) environments demonstrate that ProAct significantly improves planning accuracy. Notably, a 4B parameter model trained with ProAct outperforms all open-source baselines and rivals state-of-the-art closed-source models, while demonstrating robust generalization to unseen environments. The codes and models are available at https://github.com/GreatX3/ProAct

</details>


### [45] [AgentXRay: White-Boxing Agentic Systems via Workflow Reconstruction](https://arxiv.org/abs/2602.05353)
*Ruijie Shi,Houbin Zhang,Yuecheng Han,Yuheng Wang,Jingru Fan,Runde Yang,Yufan Dang,Huatao Li,Dewen Liu,Yuan Cheng,Chen Qian*

Main category: cs.AI

TL;DR: 提出Agentic Workflow Reconstruction (AWR)任务，通过输入-输出访问重建黑盒智能体系统的可解释工作流，并开发AgentXRay搜索框架实现该任务。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂问题解决中表现出强大能力，但许多智能体系统由于内部工作流程不透明而难以解释和控制。虽然有些框架提供了明确的协作架构，但许多部署的智能体系统对用户来说仍然是黑盒。

Method: 提出AgentXRay框架，将AWR任务形式化为组合优化问题，在链式结构工作流空间中搜索离散的智能体角色和工具调用。采用蒙特卡洛树搜索，并增强基于评分的红黑剪枝机制，动态整合代理质量与搜索深度。

Result: 实验表明，AgentXRay在多个领域实现了更高的代理相似度，相比未剪枝搜索减少了token消耗，在固定迭代预算下能够探索更深的工作流。

Conclusion: AgentXRay能够从黑盒智能体系统中重建可编辑的白盒工作流，无需访问模型参数，提高了智能体系统的可解释性和可控性。

Abstract: Large Language Models have shown strong capabilities in complex problem solving, yet many agentic systems remain difficult to interpret and control due to opaque internal workflows. While some frameworks offer explicit architectures for collaboration, many deployed agentic systems operate as black boxes to users. We address this by introducing Agentic Workflow Reconstruction (AWR), a new task aiming to synthesize an explicit, interpretable stand-in workflow that approximates a black-box system using only input--output access. We propose AgentXRay, a search-based framework that formulates AWR as a combinatorial optimization problem over discrete agent roles and tool invocations in a chain-structured workflow space. Unlike model distillation, AgentXRay produces editable white-box workflows that match target outputs under an observable, output-based proxy metric, without accessing model parameters. To navigate the vast search space, AgentXRay employs Monte Carlo Tree Search enhanced by a scoring-based Red-Black Pruning mechanism, which dynamically integrates proxy quality with search depth. Experiments across diverse domains demonstrate that AgentXRay achieves higher proxy similarity and reduces token consumption compared to unpruned search, enabling deeper workflow exploration under fixed iteration budgets.

</details>


### [46] [PATHWAYS: Evaluating Investigation and Context Discovery in AI Web Agents](https://arxiv.org/abs/2602.05354)
*Shifat E. Arman,Syed Nazmus Sakib,Tapodhir Karmakar Taton,Nafiul Haque,Shahrear Bin Amin*

Main category: cs.AI

TL;DR: PATHWAYS基准测试包含250个多步决策任务，测试网络代理能否发现并正确使用隐藏的上下文信息。结果显示当前代理在适应性调查、证据整合和判断覆盖方面存在严重缺陷。


<details>
  <summary>Details</summary>
Motivation: 评估网络代理在需要发现隐藏上下文信息的多步决策任务中的能力，特别是测试它们能否超越表面信号、进行适应性调查并整合证据做出正确判断。

Method: 创建包含250个多步决策任务的PATHWAYS基准测试，要求代理在网页环境中发现隐藏的上下文信息。测试了闭源和开源模型，分析代理的导航行为、证据检索、推理过程和最终决策。

Result: 代理通常能导航到相关页面，但只在少数情况下能检索到决定性的隐藏证据。当任务需要推翻误导性的表面信号时，性能急剧下降至接近随机水平。代理经常产生幻觉推理，声称依赖从未访问的证据。即使发现正确上下文，也常无法将其整合到最终决策中。

Conclusion: 当前网络代理架构缺乏可靠的适应性调查、证据整合和判断覆盖机制。提供更明确的指令能改善上下文发现，但会降低整体准确性，揭示了程序合规性与有效判断之间的权衡。

Abstract: We introduce PATHWAYS, a benchmark of 250 multi-step decision tasks that test whether web-based agents can discover and correctly use hidden contextual information. Across both closed and open models, agents typically navigate to relevant pages but retrieve decisive hidden evidence in only a small fraction of cases. When tasks require overturning misleading surface-level signals, performance drops sharply to near chance accuracy. Agents frequently hallucinate investigative reasoning by claiming to rely on evidence they never accessed. Even when correct context is discovered, agents often fail to integrate it into their final decision. Providing more explicit instructions improves context discovery but often reduces overall accuracy, revealing a tradeoff between procedural compliance and effective judgement. Together, these results show that current web agent architectures lack reliable mechanisms for adaptive investigation, evidence integration, and judgement override.

</details>


### [47] [RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs](https://arxiv.org/abs/2602.05367)
*Youngcheon You,Banseok Lee,Minseop Choi,Seonyoung Kim,Hyochan Chong,Changdong Kim,Youngmin Kim,Dongkyu Kim*

Main category: cs.AI

TL;DR: RaBiT是一种新颖的量化框架，通过算法强制残差层次结构解决二进制路径间的特征共适应问题，在2位量化中实现了最先进的性能，推理速度比全精度模型快4.49倍。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型部署需要极端量化，但低比特效率与性能之间存在关键权衡。残差二值化虽然能实现硬件友好的无矩阵乘法推理，但存在病态特征共适应问题，特别是并行残差二进制路径学习冗余特征，限制了模型表达能力。

Method: 提出RaBiT量化框架，核心机制是从单个共享全精度权重顺序推导每个二进制路径，确保每个路径纠正前一个路径的误差。通过稳健初始化优先考虑功能保持而非权重近似来稳定该过程。

Result: 重新定义了2位精度-效率前沿：实现了最先进的性能，甚至可与硬件密集的向量量化方法相媲美，在RTX 4090上比全精度模型推理速度快4.49倍。

Conclusion: RaBiT通过算法强制残差层次结构有效解决了二进制路径间的特征共适应问题，为极端量化提供了高效解决方案，在保持性能的同时显著提升了推理速度。

Abstract: Efficient deployment of large language models (LLMs) requires extreme quantization, forcing a critical trade-off between low-bit efficiency and performance. Residual binarization enables hardware-friendly, matmul-free inference by stacking binary ($\pm$1) layers, but is plagued by pathological feature co-adaptation. We identify a key failure mode, which we term inter-path adaptation: during quantization-aware training (QAT), parallel residual binary paths learn redundant features, degrading the error-compensation structure and limiting the expressive capacity of the model. While prior work relies on heuristic workarounds (e.g., path freezing) that constrain the solution space, we propose RaBiT, a novel quantization framework that resolves co-adaptation by algorithmically enforcing a residual hierarchy. Its core mechanism sequentially derives each binary path from a single shared full-precision weight, which ensures that every path corrects the error of the preceding one. This process is stabilized by a robust initialization that prioritizes functional preservation over mere weight approximation. RaBiT redefines the 2-bit accuracy-efficiency frontier: it achieves state-of-the-art performance, rivals even hardware-intensive Vector Quantization (VQ) methods, and delivers a $4.49\times$ inference speed-up over full-precision models on an RTX 4090.

</details>


### [48] [Clinical Validation of Medical-based Large Language Model Chatbots on Ophthalmic Patient Queries with LLM-based Evaluation](https://arxiv.org/abs/2602.05381)
*Ting Fang Tan,Kabilan Elangovan,Andreas Pollreisz,Kevin Bryan Dy,Wei Yan Ng,Joy Le Yi Wong,Jin Liyuan,Chrystie Quek Wan Ning,Ashley Shuen Ying Hong,Arun James Thirunavukarasu,Shelley Yin-His Chang,Jie Yao,Dylan Hong,Wang Zhaoran,Amrita Gupta,Daniel SW Ting*

Main category: cs.AI

TL;DR: 评估4个小型医疗LLM在眼科患者问答中的表现，并探索LLM评估与临床医生评估的一致性。Meerkat-7B表现最佳，MedLLaMA3-v20最差且存在幻觉问题，GPT-4-Turbo评估与临床医生评估高度一致。


<details>
  <summary>Details</summary>
Motivation: 随着领域特定大语言模型在眼科患者教育、分诊和临床决策中的应用日益增多，需要严格评估以确保安全性和准确性。研究旨在评估小型医疗LLM在眼科患者问答中的表现，并探索LLM评估与临床医生评估的一致性。

Method: 横断面研究，使用4个参数小于100亿的小型医疗LLM（Meerkat-7B、BioMistral-7B、OpenBioLLM-8B、MedLLaMA3-v20）回答180个眼科患者问题，生成2160个回答。由3名不同资历的眼科医生和GPT-4-Turbo使用S.C.O.R.E.框架（安全性、共识与上下文、客观性、可重复性、可解释性）进行评估，采用5点李克特量表。使用Spearman等级相关、Kendall tau统计和核密度估计分析评估LLM与临床医生评估的一致性。

Result: Meerkat-7B表现最佳，平均得分：高级顾问3.44、顾问4.08、住院医师4.18。MedLLaMA3-v20表现最差，25.5%的回答包含幻觉或临床误导内容，包括捏造术语。GPT-4-Turbo评估与临床医生评估整体高度一致（Spearman rho=0.80，Kendall tau=0.67），但高级顾问评分更为保守。

Conclusion: 医疗LLM在眼科问答中显示出安全潜力，但在临床深度和共识方面仍有差距。LLM评估在大规模基准测试中具有可行性，需要混合自动化和临床医生审查框架来指导安全的临床部署。

Abstract: Domain specific large language models are increasingly used to support patient education, triage, and clinical decision making in ophthalmology, making rigorous evaluation essential to ensure safety and accuracy. This study evaluated four small medical LLMs Meerkat-7B, BioMistral-7B, OpenBioLLM-8B, and MedLLaMA3-v20 in answering ophthalmology related patient queries and assessed the feasibility of LLM based evaluation against clinician grading. In this cross sectional study, 180 ophthalmology patient queries were answered by each model, generating 2160 responses. Models were selected for parameter sizes under 10 billion to enable resource efficient deployment. Responses were evaluated by three ophthalmologists of differing seniority and by GPT-4-Turbo using the S.C.O.R.E. framework assessing safety, consensus and context, objectivity, reproducibility, and explainability, with ratings assigned on a five point Likert scale. Agreement between LLM and clinician grading was assessed using Spearman rank correlation, Kendall tau statistics, and kernel density estimate analyses. Meerkat-7B achieved the highest performance with mean scores of 3.44 from Senior Consultants, 4.08 from Consultants, and 4.18 from Residents. MedLLaMA3-v20 performed poorest, with 25.5 percent of responses containing hallucinations or clinically misleading content, including fabricated terminology. GPT-4-Turbo grading showed strong alignment with clinician assessments overall, with Spearman rho of 0.80 and Kendall tau of 0.67, though Senior Consultants graded more conservatively. Overall, medical LLMs demonstrated potential for safe ophthalmic question answering, but gaps remained in clinical depth and consensus, supporting the feasibility of LLM based evaluation for large scale benchmarking and the need for hybrid automated and clinician review frameworks to guide safe clinical deployment.

</details>


### [49] [H-AdminSim: A Multi-Agent Simulator for Realistic Hospital Administrative Workflows with FHIR Integration](https://arxiv.org/abs/2602.05407)
*Jun-Min Lee,Meong Hi Son,Edward Choi*

Main category: cs.AI

TL;DR: H-AdminSim：一个结合真实数据生成与多智能体模拟的医院行政工作流端到端仿真框架，用于系统评估LLM驱动的行政自动化


<details>
  <summary>Details</summary>
Motivation: 医院行政部门每天处理大量任务（大型医院超过1万条请求），现有研究主要关注医患交互或孤立的行政子任务，无法捕捉真实行政工作流的复杂性

Method: 提出H-AdminSim综合仿真框架，结合真实数据生成与基于多智能体的医院行政工作流模拟，通过详细评估标准定量评估任务，并通过FHIR集成提供统一互操作环境

Result: 该框架为评估LLM驱动的行政自动化可行性和性能提供了标准化测试平台，支持跨异构医院环境的行政工作流测试

Conclusion: H-AdminSim填补了现有研究的空白，通过端到端仿真框架系统评估LLM在医院行政自动化中的应用，为实际部署提供标准化评估基础

Abstract: Hospital administration departments handle a wide range of operational tasks and, in large hospitals, process over 10,000 requests per day, driving growing interest in LLM-based automation. However, prior work has focused primarily on patient--physician interactions or isolated administrative subtasks, failing to capture the complexity of real administrative workflows. To address this gap, we propose H-AdminSim, a comprehensive end-to-end simulation framework that combines realistic data generation with multi-agent-based simulation of hospital administrative workflows. These tasks are quantitatively evaluated using detailed rubrics, enabling systematic comparison of LLMs. Through FHIR integration, H-AdminSim provides a unified and interoperable environment for testing administrative workflows across heterogeneous hospital settings, serving as a standardized testbed for assessing the feasibility and performance of LLM-driven administrative automation.

</details>


### [50] [THOR: Inductive Link Prediction over Hyper-Relational Knowledge Graphs](https://arxiv.org/abs/2602.05424)
*Weijian Yu,Yuhuan Lu,Dingqi Yang*

Main category: cs.AI

TL;DR: THOR：一种用于超关系知识图谱的归纳式链接预测方法，通过关系基础图和实体基础图建模跨图谱的结构不变性，支持完全归纳推理。


<details>
  <summary>Details</summary>
Motivation: 现有超关系知识图谱链接预测方法大多局限于转导式设置，只能在同一词汇表中进行预测，无法泛化到未见过的词汇表，限制了其通用性。

Method: 提出THOR方法：1）引入关系基础图和实体基础图，建模超关系知识图谱中独立于特定关系和实体的基础交互模式；2）使用两个并行图编码器学习基础图表示，再通过Transformer解码器进行预测，支持掩码训练和完全归纳推理。

Result: 在12个数据集上的实验表明，THOR在超关系链接预测任务中显著优于现有方法，相比最佳规则基方法提升66.1%，相比最佳半归纳方法提升55.9%，相比最佳完全归纳方法提升20.4%。

Conclusion: THOR通过建模超关系知识图谱中的结构不变性，实现了有效的归纳式链接预测，能够泛化到未见过的词汇表，为知识图谱推理提供了更通用的解决方案。

Abstract: Knowledge graphs (KGs) have become a key ingredient supporting a variety of applications. Beyond the traditional triplet representation of facts where a relation connects two entities, modern KGs observe an increasing number of hyper-relational facts, where an arbitrary number of qualifiers associated with a triplet provide auxiliary information to further describe the rich semantics of the triplet, which can effectively boost the reasoning performance in link prediction tasks. However, existing link prediction techniques over such hyper-relational KGs (HKGs) mostly focus on a transductive setting, where KG embedding models are learned from the specific vocabulary of a given KG and subsequently can only make predictions within the same vocabulary, limiting their generalizability to previously unseen vocabularies. Against this background, we propose THOR, an inducTive link prediction technique for Hyper-relational knOwledge gRaphs. Specifically, we first introduce both relation and entity foundation graphs, modeling their fundamental inter- and intra-fact interactions in HKGs, which are agnostic to any specific relations and entities. Afterward, THOR is designed to learn from the two foundation graphs with two parallel graph encoders followed by a transformer decoder, which supports efficient masked training and fully-inductive inference. We conduct a thorough evaluation of THOR in hyper-relational link prediction tasks on 12 datasets with different settings. Results show that THOR outperforms a sizable collection of baselines, yielding 66.1%, 55.9%, and 20.4% improvement over the best-performing rule-based, semi-inductive, and fully-inductive techniques, respectively. A series of ablation studies also reveals our key design factors capturing the structural invariance transferable across HKGs for inductive tasks.

</details>


### [51] [M$^2$-Miner: Multi-Agent Enhanced MCTS for Mobile GUI Agent Data Mining](https://arxiv.org/abs/2602.05429)
*Rui Lv,Juncheng Mo,Tianyi Chu,Chen Rao,Hongyi Jing,Jiajie Teng,Jiafu Chen,Shiqi Zhang,Liangzi Ding,Shuo Fang,Huaizhong Lin,Ziqiang Dang,Chenguang Ma,Lei Zhao*

Main category: cs.AI

TL;DR: M²-Miner：首个基于蒙特卡洛树搜索的低成本自动化移动GUI代理数据挖掘框架，通过多智能体协作和意图回收策略解决GUI代理数据构建的高成本、低质量和低丰富度问题。


<details>
  <summary>Details</summary>
Motivation: 构建强大的GUI代理需要大规模高质量的用户行为轨迹数据（意图-轨迹对）进行训练，但现有的人工标注方法和GUI代理数据挖掘方法面临三个关键挑战：构建成本高、数据质量差、数据丰富度低。

Method: 提出M²-Miner框架，基于蒙特卡洛树搜索实现低成本自动化数据挖掘。采用协作多智能体框架（InferAgent、OrchestraAgent、JudgeAgent）进行引导、加速和评估；设计意图回收策略提取额外有价值的交互轨迹；引入渐进式模型在环训练策略提高数据挖掘成功率。

Result: 实验表明，使用M²-Miner挖掘的数据微调的GUI代理在多个常用移动GUI基准测试中达到了最先进的性能。

Conclusion: M²-Miner有效解决了GUI代理数据构建的三大挑战，为社区研究提供了高质量的数据挖掘框架，将开源发布以促进相关研究发展。

Abstract: Graphical User Interface (GUI) agent is pivotal to advancing intelligent human-computer interaction paradigms. Constructing powerful GUI agents necessitates the large-scale annotation of high-quality user-behavior trajectory data (i.e., intent-trajectory pairs) for training. However, manual annotation methods and current GUI agent data mining approaches typically face three critical challenges: high construction cost, poor data quality, and low data richness. To address these issues, we propose M$^2$-Miner, the first low-cost and automated mobile GUI agent data-mining framework based on Monte Carlo Tree Search (MCTS). For better data mining efficiency and quality, we present a collaborative multi-agent framework, comprising InferAgent, OrchestraAgent, and JudgeAgent for guidance, acceleration, and evaluation. To further enhance the efficiency of mining and enrich intent diversity, we design an intent recycling strategy to extract extra valuable interaction trajectories. Additionally, a progressive model-in-the-loop training strategy is introduced to improve the success rate of data mining. Extensive experiments have demonstrated that the GUI agent fine-tuned using our mined data achieves state-of-the-art performance on several commonly used mobile GUI benchmarks. Our work will be released to facilitate the community research.

</details>


### [52] [Day-Ahead Electricity Price Forecasting for Volatile Markets Using Foundation Models with Regularization Strategy](https://arxiv.org/abs/2602.05430)
*Kritchanat Ponyuenyong,Pengyu Tu,Jia Wei Tan,Wei Soon Cheong,Jamie Ng Suat Ling,Lianlian Jiang*

Main category: cs.AI

TL;DR: 该论文评估了时间序列基础模型在波动性电力市场价格预测中的表现，发现它们比传统统计和深度学习方法表现更好，最高可提升37.4%的MAPE准确率。


<details>
  <summary>Details</summary>
Motivation: 电力市场价格预测对能源市场参与者至关重要，但由于价格信号的固有波动性和非线性，传统统计和深度学习模型难以有效捕捉复杂的时间依赖关系并整合异构数据。虽然时间序列基础模型在一般时间序列预测任务中表现出色，但它们在波动性电力市场中的有效性尚未得到充分探索。

Method: 提出尖峰正则化策略，并评估了多种时间序列基础模型（包括TTMs、MOIRAI、MOMENT、TimesFM），与传统统计模型（ARIMA）和深度学习模型（LSTM、CNN-LSTM）进行比较。使用新加坡波动性批发市场的半小时数据，并在适用模型中纳入天气和日历变量等外生因素。

Result: 时间序列基础模型在所有评估设置中始终优于传统方法，在各种评估场景下MAPE最高可提升37.4%。

Conclusion: 时间序列基础模型在波动性电力市场价格预测中表现出色，为改善预测准确性和决策制定提供了实用指导。

Abstract: Electricity price forecasting (EPF) is essential for energy markets stakeholders (e.g. grid operators, energy traders, policymakers) but remains challenging due to the inherent volatility and nonlinearity of price signals. Traditional statistical and deep learning (DL) models often struggle to capture complex temporal dependencies and integrate heterogeneous data effectively. While time series foundation models (TSFMs) have shown strong performance in general time series forecasting tasks, such as traffic forecasting and weather forecasting. However, their effectiveness in day-ahead EPF, particularly in volatile markets, remains underexplored. This paper presents a spike regularization strategy and evaluates a wide range of TSFMs, including Tiny Time Mixers (TTMs), MOIRAI, MOMENT, and TimesFM, against traditional statistical and DL models such as Autoregressive Integrated Moving Average (ARIMA), Long-short Term Memory (LSTM), and Convolutional Neural Network - LSTM (CNN-LSTM) using half-hourly wholesale market data with volatile trends in Singapore. Exogenous factors (e.g. weather and calendar variables) are also incorporated into models where applicable. Results demonstrate that TSFMs consistently outperform traditional approaches, achieving up to 37.4% improvement in MAPE across various evaluation settings. The findings offer practical guidance for improving forecast accuracy and decision-making in volatile electricity markets.

</details>


### [53] [Refine and Purify: Orthogonal Basis Optimization with Null-Space Denoising for Conditional Representation Learning](https://arxiv.org/abs/2602.05464)
*Jiaquan Wang,Yan Lyu,Chen Li,Yuheng Jia*

Main category: cs.AI

TL;DR: OD-CRL提出自适应正交基优化和零空间去噪投影，解决条件表示学习中基向量敏感性和子空间干扰问题，在多个定制化任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM生成文本基向量的条件表示学习方法存在两个关键限制：对子空间基向量的敏感性，以及子空间之间的干扰问题。

Method: 提出OD-CRL框架，包含自适应正交基优化（AOBO）和零空间去噪投影（NSDP）。AOBO通过奇异值分解和基于曲率的截断构建正交语义基；NSDP通过将嵌入投影到无关子空间的零空间来抑制非目标语义干扰。

Result: 在定制化聚类、分类和检索任务上的大量实验表明，OD-CRL取得了新的最先进性能，并具有优越的泛化能力。

Conclusion: OD-CRL通过正交基优化和零空间投影有效解决了条件表示学习中的基向量敏感性和子空间干扰问题，为定制化任务提供了更鲁棒的特征表示。

Abstract: Conditional representation learning aims to extract criterion-specific features for customized tasks. Recent studies project universal features onto the conditional feature subspace spanned by an LLM-generated text basis to obtain conditional representations. However, such methods face two key limitations: sensitivity to subspace basis and vulnerability to inter-subspace interference. To address these challenges, we propose OD-CRL, a novel framework integrating Adaptive Orthogonal Basis Optimization (AOBO) and Null-Space Denoising Projection (NSDP). Specifically, AOBO constructs orthogonal semantic bases via singular value decomposition with a curvature-based truncation. NSDP suppresses non-target semantic interference by projecting embeddings onto the null space of irrelevant subspaces. Extensive experiments conducted across customized clustering, customized classification, and customized retrieval tasks demonstrate that OD-CRL achieves a new state-of-the-art performance with superior generalization.

</details>


### [54] [ALIVE: Awakening LLM Reasoning via Adversarial Learning and Instructive Verbal Evaluation](https://arxiv.org/abs/2602.05472)
*Yiwen Duan,Jing Ye,Xinpei Zhao*

Main category: cs.AI

TL;DR: ALIVE框架通过对抗学习和指导性语言反馈，让LLM内部化推理逻辑，无需人工监督即可实现专家级推理能力


<details>
  <summary>Details</summary>
Motivation: 传统强化学习依赖标量奖励存在三个问题：扩展成本高、跨领域脆弱、无法理解解决方案的内在逻辑。这种对外部贫乏信号的依赖阻碍了模型发展对推理原则的深层理解。

Method: ALIVE框架基于"认知协同"原则，将问题提出、解决和评判统一在单一策略模型中。通过对抗学习和指导性语言反馈的结合，让模型直接从原始语料中内部化评估标准，将外部批评转化为内生的推理能力。

Result: 在数学推理、代码生成和一般逻辑推理基准测试中，ALIVE持续缓解了奖励信号限制。在相同数据和计算条件下，实现了准确率提升、跨领域泛化能力显著改善以及更高的自我纠正率。

Conclusion: 推理三位一体（问题提出、解决、评判）促进了能力增长的自我维持轨迹，使ALIVE成为无需人工监督的通用推理对齐的可扩展基础。

Abstract: The quest for expert-level reasoning in Large Language Models (LLMs) has been hampered by a persistent \textit{reward bottleneck}: traditional reinforcement learning (RL) relies on scalar rewards that are \textbf{costly} to scale, \textbf{brittle} across domains, and \textbf{blind} to the underlying logic of a solution. This reliance on external, impoverished signals prevents models from developing a deep, self-contained understanding of reasoning principles. We introduce \textbf{ALIVE} (\emph{Adversarial Learning with Instructive Verbal Evaluation}), a hands-free alignment framework that moves beyond scalar reward optimization toward intrinsic reasoning acquisition. Grounded in the principle of \emph{Cognitive Synergy}, ALIVE unifies problem posing, solving, and judging within a single policy model to internalize the logic of correctness. By coupling adversarial learning with instructive verbal feedback, ALIVE enables models to internalize evaluative criteria directly from raw corpora, effectively transforming external critiques into an endogenous reasoning faculty. Empirical evaluations across mathematical reasoning, code generation, and general logical inference benchmarks demonstrate that ALIVE consistently mitigates reward signal limitations. With identical data and compute, it achieves accuracy gains, markedly improved cross-domain generalization, and higher self-correction rates. These results indicate that the reasoning trinity fosters a self-sustaining trajectory of capability growth, positioning ALIVE as a scalable foundation for general-purpose reasoning alignment without human-in-the-loop supervision.

</details>


### [55] [Phi-Former: A Pairwise Hierarchical Approach for Compound-Protein Interactions Prediction](https://arxiv.org/abs/2602.05479)
*Zhe Wang,Zijing Liu,Chencheng Xu,Yuan Yao*

Main category: cs.AI

TL;DR: Phi-former是一个用于预测化合物-蛋白质相互作用的分层表示学习方法，通过原子-原子、基序-基序、原子-基序三个层次建模生物识别过程，提高预测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法虽然能原子级建模化合物-蛋白质相互作用，但忽略了化学现实：分子片段（基序或功能基团）通常是生物识别和结合的主要单元。需要开发能反映生物识别机制的方法。

Method: 提出Phi-former方法：1）对化合物和蛋白质进行分层表示；2）采用成对预训练框架，系统建模原子-原子、基序-基序、原子-基序三个层次的相互作用；3）设计层内和层间学习管道，使不同交互层次相互促进。

Result: Phi-former在CPI相关任务上表现出优越性能。案例研究表明，该方法能准确识别CPI中被激活的特定原子或基序，提供可解释的模型解释。

Conclusion: Phi-former通过分层建模生物识别过程，提高了CPI预测的准确性和可解释性，有望指导理性药物设计和精准医疗应用。

Abstract: Drug discovery remains time-consuming, labor-intensive, and expensive, often requiring years and substantial investment per drug candidate. Predicting compound-protein interactions (CPIs) is a critical component in this process, enabling the identification of molecular interactions between drug candidates and target proteins. Recent deep learning methods have successfully modeled CPIs at the atomic level, achieving improved efficiency and accuracy over traditional energy-based approaches. However, these models do not always align with chemical realities, as molecular fragments (motifs or functional groups) typically serve as the primary units of biological recognition and binding. In this paper, we propose Phi-former, a pairwise hierarchical interaction representation learning method that addresses this gap by incorporating the biological role of motifs in CPIs. Phi-former represents compounds and proteins hierarchically and employs a pairwise pre-training framework to model interactions systematically across atom-atom, motif-motif, and atom-motif levels, reflecting how biological systems recognize molecular partners. We design intra-level and inter-level learning pipelines that make different interaction levels mutually beneficial. Experimental results demonstrate that Phi-former achieves superior performance on CPI-related tasks. A case study shows that our method accurately identifies specific atoms or motifs activated in CPIs, providing interpretable model explanations. These insights may guide rational drug design and support precision medicine applications.

</details>


### [56] [SDFP: Speculative Decoding with FIT-Pruned Models for Training-Free and Plug-and-Play LLM Acceleration](https://arxiv.org/abs/2602.05499)
*Hanyu Wei,Zunhai Su,Peng Lu,Chao Li,Spandan Tiwari,Ashish Sirasao,Yuhan Dong*

Main category: cs.AI

TL;DR: SDFP是一个无需训练、即插即用的推测解码框架，通过基于Fisher信息迹的层剪枝构建轻量级草稿模型，实现1.32x-1.5x的解码加速，适用于多媒体应用。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多媒体应用中存在自回归解码延迟高的问题。现有推测解码方法需要额外的训练或维护草稿模型，部署成本高且复杂。

Method: 使用Fisher信息迹作为层敏感度代理，通过层剪枝从原始LLM中移除低影响层构建紧凑草稿模型，保持与原始模型的兼容性进行标准推测验证。

Result: 在基准测试中实现1.32x-1.5x的解码加速，不改变目标模型的输出分布，支持低延迟多媒体应用。

Conclusion: SDFP提供了一种无需额外训练、超参数调优或单独维护草稿模型的快速部署方案，有效降低推测解码的部署成本和复杂度。

Abstract: Large language models (LLMs) underpin interactive multimedia applications such as captioning, retrieval, recommendation, and creative content generation, yet their autoregressive decoding incurs substantial latency. Speculative decoding reduces latency using a lightweight draft model, but deployment is often limited by the cost and complexity of acquiring, tuning, and maintaining an effective draft model. Recent approaches usually require auxiliary training or specialization, and even training-free methods incur costly search or optimization. We propose SDFP, a fully training-free and plug-and-play framework that builds the draft model via Fisher Information Trace (FIT)-based layer pruning of a given LLM. Using layer sensitivity as a proxy for output perturbation, SDFP removes low-impact layers to obtain a compact draft while preserving compatibility with the original model for standard speculative verification. SDFP needs no additional training, hyperparameter tuning, or separately maintained drafts, enabling rapid, deployment-friendly draft construction. Across benchmarks, SDFP delivers 1.32x-1.5x decoding speedup without altering the target model's output distribution, supporting low-latency multimedia applications.

</details>


### [57] [A Unified Multimodal Framework for Dataset Construction and Model-Based Diagnosis of Ameloblastoma](https://arxiv.org/abs/2602.05515)
*Ajo Babu George,Anna Mariam John,Athul Anoop,Balu Bhasuran*

Main category: cs.AI

TL;DR: 本文提出了一个专门针对成釉细胞瘤的多模态数据集和深度学习模型，用于分类变异、评估复发风险和支持手术规划，显著提升了诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 现有AI辅助颌面病理诊断缺乏结构化、高质量的多模态数据集，特别是成釉细胞瘤覆盖有限且格式不一致，无法直接用于模型训练。

Method: 构建了专门针对成釉细胞瘤的多模态数据集，整合了放射学、组织病理学和口腔临床图像，使用自然语言处理从病例报告中提取临床特征，并对图像数据进行预处理和增强。基于此数据集开发了多模态深度学习模型。

Result: 模型性能显著提升：变异分类准确率从46.2%提高到65.9%，异常组织检测F1分数从43.0%提升到90.3%。

Conclusion: 这项工作通过提供强大的数据集和适应性强的多模态AI框架，推进了患者特异性决策支持，相比现有资源如MultiCaRe有显著改进。

Abstract: Artificial intelligence (AI)-enabled diagnostics in maxillofacial pathology require structured, high-quality multimodal datasets. However, existing resources provide limited ameloblastoma coverage and lack the format consistency needed for direct model training. We present a newly curated multimodal dataset specifically focused on ameloblastoma, integrating annotated radiological, histopathological, and intraoral clinical images with structured data derived from case reports. Natural language processing techniques were employed to extract clinically relevant features from textual reports, while image data underwent domain specific preprocessing and augmentation. Using this dataset, a multimodal deep learning model was developed to classify ameloblastoma variants, assess behavioral patterns such as recurrence risk, and support surgical planning. The model is designed to accept clinical inputs such as presenting complaint, age, and gender during deployment to enhance personalized inference. Quantitative evaluation demonstrated substantial improvements; variant classification accuracy increased from 46.2 percent to 65.9 percent, and abnormal tissue detection F1-score improved from 43.0 percent to 90.3 percent. Benchmarked against resources like MultiCaRe, this work advances patient-specific decision support by providing both a robust dataset and an adaptable multimodal AI framework.

</details>


### [58] [Split Personality Training: Revealing Latent Knowledge Through Alternate Personalities](https://arxiv.org/abs/2602.05532)
*Florian Dietz,William Wale,Oscar Gilg,Robert McCarthy,Felix Michalak,Gustavo Ewbank Rodrigues Danon,Miguelito de Guzman,Dietrich Klakow*

Main category: cs.AI

TL;DR: 提出Split Personality Training (SPT)方法，通过微调第二个"诚实人格"到LoRA参数中，在模型正常响应后激活该人格来审查响应，有效检测大型语言模型的错位行为，在Anthropic审计游戏基准上达到96%准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型可能在训练中学会隐藏错位行为，现有审计技术存在不足：黑盒方法难以区分错位输出与良性输出，机制可解释性无法随模型能力扩展。

Method: SPT方法微调第二个"诚实人格"到LoRA参数中，该参数在正常操作时保持非激活状态。在主模型响应后，激活LoRA适配器并插入触发字符串，使诚实人格能够审查响应同时访问主模型的潜在状态。

Result: 在Anthropic审计游戏模型基准测试中，SPT达到96%的整体准确率，而Anthropic报告接近0%准确率。诚实人格能够揭示外部观察者无法访问的潜在知识，如受损模型训练中的虚构偏见。

Conclusion: SPT提供了一种有效检测大型语言模型错位行为的方法，通过创建独立的诚实人格来审查模型输出，能够揭示模型隐藏的错位行为，显著优于现有审计技术。

Abstract: Detecting misalignment in large language models is challenging because models may learn to conceal misbehavior during training. Standard auditing techniques fall short: black-box methods often cannot distinguish misaligned outputs from benign ones, and mechanistic interpretability does not scale with model capabilities. We introduce Split Personality Training (SPT), which fine-tunes a second ``honest persona'' into LoRA parameters that remain inactive during normal operation. After the main model responds, we activate the LoRA adapter and insert a trigger string, enabling the honest persona to review the response while accessing the main model's latent states. We test our method on the Anthropic Auditing Game Model Organism, a benchmark where Llama-3.3-70B is trained to exploit reward hacks while concealing this behavior. SPT achieves 96% overall accuracy, whereas Anthropic reports near 0% accuracy. The honest persona reveals latent knowledge inaccessible to external observers, such as the fictional biases the compromised model was trained on.

</details>


### [59] [Conditional Diffusion Guidance under Hard Constraint: A Stochastic Analysis Approach](https://arxiv.org/abs/2602.05533)
*Zhengyi Guo,Wenpin Tang,Renyuan Xu*

Main category: cs.AI

TL;DR: 基于Doob's h变换、鞅表示和二次变差过程，提出了一种用于扩散模型硬约束条件生成的理论框架，通过添加显式漂移修正而不修改预训练分数网络，并设计了两种离策略学习算法来估计条件函数及其梯度。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用和罕见事件模拟中，需要确保生成的样本以概率1满足硬约束条件，而现有的软约束或基于奖励的引导方法无法保证约束满足。

Method: 基于扩散模型的概率解释，利用Doob's h变换、鞅表示和二次变差过程构建条件扩散引导框架，通过添加涉及条件函数对数梯度的显式漂移修正来引导预训练扩散模型，并提出了基于鞅损失和鞅协变损失的两种离策略学习算法来估计条件函数及其梯度。

Result: 在总变差距离和Wasserstein距离上为非渐近条件采样器提供了理论保证，明确刻画了分数近似和引导估计误差的影响，数值实验验证了该方法在强制执行硬约束和生成罕见事件样本方面的有效性。

Conclusion: 提出了一种理论严谨的扩散模型硬约束条件生成框架，能够在保证约束满足的同时保持预训练分数网络不变，为安全关键应用和罕见事件模拟提供了可靠的条件生成方法。

Abstract: We study conditional generation in diffusion models under hard constraints, where generated samples must satisfy prescribed events with probability one. Such constraints arise naturally in safety-critical applications and in rare-event simulation, where soft or reward-based guidance methods offer no guarantee of constraint satisfaction. Building on a probabilistic interpretation of diffusion models, we develop a principled conditional diffusion guidance framework based on Doob's h-transform, martingale representation and quadratic variation process. Specifically, the resulting guided dynamics augment a pretrained diffusion with an explicit drift correction involving the logarithmic gradient of a conditioning function, without modifying the pretrained score network. Leveraging martingale and quadratic-variation identities, we propose two novel off-policy learning algorithms based on a martingale loss and a martingale-covariation loss to estimate h and its gradient using only trajectories from the pretrained model. We provide non-asymptotic guarantees for the resulting conditional sampler in both total variation and Wasserstein distances, explicitly characterizing the impact of score approximation and guidance estimation errors. Numerical experiments demonstrate the effectiveness of the proposed methods in enforcing hard constraints and generating rare-event samples.

</details>


### [60] [Reasoning-guided Collaborative Filtering with Language Models for Explainable Recommendation](https://arxiv.org/abs/2602.05544)
*Fahad Anwaar,Adil Mehmood Khan,Muhammad Khalid,Usman Zia,Kezhi Wang*

Main category: cs.AI

TL;DR: RGCF-XRec是一个混合框架，通过推理引导的协同过滤知识增强语言模型，在单一步骤中实现可解释的顺序推荐，提升性能并减少冷启动问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在可解释推荐系统中忽视了协同信号，且将推荐和解释作为独立任务处理，导致内存占用和效率问题。需要一种能统一处理推荐和解释的框架。

Method: 提出RGCF-XRec框架：1) 通过上下文提示推理引导增强CF知识，发现潜在偏好和可解释推理路径；2) 基于一致性、完整性、相关性和连贯性四个维度的评分机制过滤噪声CF推理轨迹；3) 统一表示学习网络编码协同和语义信号，构建结构化提示来指导LLM进行可解释顺序推荐。

Result: 在Amazon数据集（Sports、Toys、Beauty，共642,503个用户-物品交互）上表现优异：HR@10在Sports提升7.38%，Toys提升4.59%；ROUGE-L分别提升8.02%和3.49%；冷启动场景整体提升14.5%，热启动提升11.9%；零样本HR@5在Beauty提升18.54%，Toys提升23.16%。使用轻量级LLaMA 3.2-3B骨干确保训练效率和可扩展性。

Conclusion: RGCF-XRec通过推理引导的协同过滤知识增强语言模型，在单一步骤中实现了高效的可解释顺序推荐，显著提升了推荐性能、冷启动表现和泛化能力，同时保持了计算效率。

Abstract: Large Language Models (LLMs) exhibit potential for explainable recommendation systems but overlook collaborative signals, while prevailing methods treat recommendation and explanation as separate tasks, resulting in a memory footprint. We present RGCF-XRec, a hybrid framework that introduces reasoning-guided collaborative filtering (CF) knowledge into a language model to deliver explainable sequential recommendations in a single step. Theoretical grounding and empirical findings reveal that RGCF-XRec offers three key merits over leading CF-aware LLM-based methods: (1) reasoning-guided augmentation of CF knowledge through contextual prompting to discover latent preferences and interpretable reasoning paths; (2) an efficient scoring mechanism based on four dimensions: coherence, completeness, relevance, and consistency to mitigate noisy CF reasoning traces and retain high-quality explanations; (3) a unified representation learning network that encodes collaborative and semantic signals, enabling a structured prompt to condition the LLM for explainable sequential recommendation. RGCF-XRec demonstrates consistent improvements across Amazon datasets, Sports, Toys, and Beauty, comprising 642,503 user-item interactions. It improves HR@10 by 7.38\% in Sports and 4.59\% in Toys, along with ROUGE-L by 8.02\% and 3.49\%, respectively. It reduces the cold warm performance gap, achieving overall gains of 14.5\% in cold-start and 11.9\% in warm start scenarios, and enhances zero-shot HR@5 by 18.54\% in Beauty and 23.16\% in Toys, highlighting effective generalization and robustness. Moreover, RGCF-XRec achieves training efficiency with a lightweight LLaMA 3.2-3B backbone, ensuring scalability for real-world applications.

</details>


### [61] [TangramSR: Can Vision-Language Models Reason in Continuous Geometric Space?](https://arxiv.org/abs/2602.05570)
*Yikun Zong,Cheston Tan*

Main category: cs.AI

TL;DR: 论文提出一个测试时自优化框架，通过上下文学习和奖励反馈循环来提升视觉语言模型的几何推理能力，无需参数更新即可显著改进七巧板拼图任务的表现。


<details>
  <summary>Details</summary>
Motivation: 人类擅长通过试错、观察和修正来解决七巧板等空间推理任务，但现有视觉语言模型在连续几何推理方面存在系统性失败，表现远低于人类。这引发了一个根本性问题：AI模型能否在测试时通过迭代优化来改进预测，而无需参数更新？

Method: 提出一个无需训练的验证器-优化器代理框架，结合上下文学习和奖励引导的反馈循环。该框架模拟人类认知机制，通过递归优化循环基于几何一致性反馈迭代地自我优化预测。

Result: 在五个代表性视觉语言模型上的实验显示，单块任务平均IoU仅为0.41，双块组合降至0.23，远低于人类表现。但提出的自优化框架将中等三角形案例的IoU从0.63提升到0.932，无需模型重新训练。

Conclusion: 通过上下文学习和奖励循环融入人类启发的迭代优化机制，可以显著增强视觉语言模型的几何推理能力，将自优化AI从承诺变为连续空间领域的实践。

Abstract: Humans excel at spatial reasoning tasks like Tangram puzzle assembly through cognitive processes involving mental rotation, iterative refinement, and visual feedback. Inspired by how humans solve Tangram puzzles through trial-and-error, observation, and correction, we design a framework that models these human cognitive mechanisms. However, comprehensive experiments across five representative Vision-Language Models (VLMs) reveal systematic failures in continuous geometric reasoning: average IoU of only 0.41 on single-piece tasks, dropping to 0.23 on two-piece composition, far below human performance where children can complete Tangram tasks successfully. This paper addresses a fundamental challenge in self-improving AI: can models iteratively refine their predictions at test time without parameter updates? We introduce a test-time self-refinement framework that combines in-context learning (ICL) with reward-guided feedback loops, inspired by human cognitive processes. Our training-free verifier-refiner agent applies recursive refinement loops that iteratively self-refine predictions based on geometric consistency feedback, achieving IoU improvements from 0.63 to 0.932 on medium-triangle cases without any model retraining. This demonstrates that incorporating human-inspired iterative refinement mechanisms through ICL and reward loops can substantially enhance geometric reasoning in VLMs, moving self-improving AI from promise to practice in continuous spatial domains. Our work is available at this anonymous link https://anonymous.4open.science/r/TangramVLM-F582/.

</details>


### [62] [Emulating Aggregate Human Choice Behavior and Biases with GPT Conversational Agents](https://arxiv.org/abs/2602.05597)
*Stephen Pilli,Vivek Nallur*

Main category: cs.AI

TL;DR: LLMs能够准确预测个体层面的认知偏见，并在交互对话中模拟人类偏见行为，GPT-4和GPT-5在模拟人类行为对齐方面存在差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLMs是否能在个体层面预测认知偏见，并模拟在认知负荷等情境因素影响下的人类偏见行为动态，这对设计偏见过滤的交互式AI系统具有重要意义。

Method: 将三个经典决策场景转化为对话设置，进行人类实验（N=1100），参与者通过简单或复杂对话与聊天机器人互动。然后使用参与者人口统计数据和对话记录，基于GPT-4和GPT-5模拟相同条件。

Result: 人类实验显示出显著的偏见模式。LLMs能够精确复现人类偏见，GPT-4和GPT-5在模拟人类行为对齐方面存在明显差异。

Conclusion: LLMs能够有效模拟个体层面的认知偏见行为，这对设计和评估适应性的、偏见感知的交互式AI系统具有重要启示，不同模型在行为对齐方面的差异需要特别关注。

Abstract: Cognitive biases often shape human decisions. While large language models (LLMs) have been shown to reproduce well-known biases, a more critical question is whether LLMs can predict biases at the individual level and emulate the dynamics of biased human behavior when contextual factors, such as cognitive load, interact with these biases. We adapted three well-established decision scenarios into a conversational setting and conducted a human experiment (N=1100). Participants engaged with a chatbot that facilitates decision-making through simple or complex dialogues. Results revealed robust biases. To evaluate how LLMs emulate human decision-making under similar interactive conditions, we used participant demographics and dialogue transcripts to simulate these conditions with LLMs based on GPT-4 and GPT-5. The LLMs reproduced human biases with precision. We found notable differences between models in how they aligned human behavior. This has important implications for designing and evaluating adaptive, bias-aware LLM-based AI systems in interactive contexts.

</details>


### [63] [BhashaSetu: Cross-Lingual Knowledge Transfer from High-Resource to Extreme Low-Resource Languages](https://arxiv.org/abs/2602.05599)
*Subhadip Maji,Arnab Bhattacharya*

Main category: cs.AI

TL;DR: 提出GETR方法用于低资源语言的跨语言知识迁移，在词性标注、情感分类和命名实体识别任务上显著超越现有基线方法


<details>
  <summary>Details</summary>
Motivation: 低资源语言由于数据稀缺和语言资源不足，性能远落后于高资源语言。跨语言知识迁移通过利用高资源语言的资源来解决这一挑战

Method: 提出GETR（图增强词表示）方法用于跨语言知识迁移，同时采用两个基线方法：隐藏层增强和通过词翻译的词嵌入迁移

Result: GETR方法显著优于现有多语言和跨语言基线，在真正低资源语言（Mizo、Khasi）的词性标注上提升13个百分点，在模拟低资源语言（Marathi、Bangla、Malayalam）的情感分类和NER任务上分别提升20和27个百分点的宏F1值

Conclusion: 图神经网络方法在低资源语言的跨语言知识迁移中表现出色，通过详细分析确定了成功知识迁移的关键因素

Abstract: Despite remarkable advances in natural language processing, developing effective systems for low-resource languages remains a formidable challenge, with performances typically lagging far behind high-resource counterparts due to data scarcity and insufficient linguistic resources. Cross-lingual knowledge transfer has emerged as a promising approach to address this challenge by leveraging resources from high-resource languages. In this paper, we investigate methods for transferring linguistic knowledge from high-resource languages to low-resource languages, where the number of labeled training instances is in hundreds. We focus on sentence-level and word-level tasks. We introduce a novel method, GETR (Graph-Enhanced Token Representation) for cross-lingual knowledge transfer along with two adopted baselines (a) augmentation in hidden layers and (b) token embedding transfer through token translation. Experimental results demonstrate that our GNN-based approach significantly outperforms existing multilingual and cross-lingual baseline methods, achieving 13 percentage point improvements on truly low-resource languages (Mizo, Khasi) for POS tagging, and 20 and 27 percentage point improvements in macro-F1 on simulated low-resource languages (Marathi, Bangla, Malayalam) across sentiment classification and NER tasks respectively. We also present a detailed analysis of the transfer mechanisms and identify key factors that contribute to successful knowledge transfer in this linguistic context.

</details>


### [64] [Reactive Knowledge Representation and Asynchronous Reasoning](https://arxiv.org/abs/2602.05625)
*Simon Kohaut,Benedict Flade,Julian Eggert,Kristian Kersting,Devendra Singh Dhami*

Main category: cs.AI

TL;DR: 提出Resin概率编程语言和Reactive Circuits结构，通过异步反应式推理实现高效精确的概率推断，在无人机群模拟中实现数量级加速。


<details>
  <summary>Details</summary>
Motivation: 复杂概率模型的精确推断计算成本过高，特别是在动态环境中需要频繁实时更新的自主智能体场景。现有方法通常低效，因为它们会在任何变化时重新评估整个模型，未能利用现实世界信息流具有异构更新速率的特点。

Method: 1. 提出Resin（Reactive Signal Inference）概率编程语言，融合概率逻辑与反应式编程；2. 提出Reactive Circuits（RCs）作为Resin的高效精确语义，这是一种基于代数电路和异步数据流的元结构，是时间动态有向无环图，能根据输入信号的波动性自主适应；3. 基于异步输入的变化频率估计对计算进行分区，将大型推断任务分解为可单独记忆的子问题。

Result: 在高保真无人机群模拟中，相比频率无关的推断方法实现了几个数量级的加速。RCs的结构适应成功捕捉环境动态，显著降低延迟，促进反应式实时推理。通过基于异步输入变化频率进行分区计算，确保只有受新信息影响的模型特定组件被重新评估，大幅减少流式上下文中的冗余计算。

Conclusion: 通过反应式异步概率推理方法，结合Resin编程语言和Reactive Circuits结构，能够实现高效精确的概率推断，特别适用于动态环境中需要实时更新的自主智能体应用，显著提升计算效率。

Abstract: Exact inference in complex probabilistic models often incurs prohibitive computational costs. This challenge is particularly acute for autonomous agents in dynamic environments that require frequent, real-time belief updates. Existing methods are often inefficient for ongoing reasoning, as they re-evaluate the entire model upon any change, failing to exploit that real-world information streams have heterogeneous update rates. To address this, we approach the problem from a reactive, asynchronous, probabilistic reasoning perspective. We first introduce Resin (Reactive Signal Inference), a probabilistic programming language that merges probabilistic logic with reactive programming. Furthermore, to provide efficient and exact semantics for Resin, we propose Reactive Circuits (RCs). Formulated as a meta-structure over Algebraic Circuits and asynchronous data streams, RCs are time-dynamic Directed Acyclic Graphs that autonomously adapt themselves based on the volatility of input signals. In high-fidelity drone swarm simulations, our approach achieves several orders of magnitude of speedup over frequency-agnostic inference. We demonstrate that RCs' structural adaptations successfully capture environmental dynamics, significantly reducing latency and facilitating reactive real-time reasoning. By partitioning computations based on the estimated Frequency of Change in the asynchronous inputs, large inference tasks can be decomposed into individually memoized sub-problems. This ensures that only the specific components of a model affected by new information are re-evaluated, drastically reducing redundant computation in streaming contexts.

</details>


### [65] [Generative Ontology: When Structured Knowledge Learns to Create](https://arxiv.org/abs/2602.05636)
*Benny Cheung*

Main category: cs.AI

TL;DR: 提出Generative Ontology框架，结合传统本体论的结构严谨性与大语言模型的创造性，通过可执行的Pydantic模式约束LLM生成，应用于游戏设计等领域。


<details>
  <summary>Details</summary>
Motivation: 传统本体论能描述领域结构但无法生成新内容，而大语言模型能流畅生成但缺乏结构有效性，常产生幻觉。需要结合两者的互补优势：本体论提供语法，LLM提供创造力。

Method: 将领域知识编码为可执行的Pydantic模式，通过DSPy签名约束LLM生成。采用多智能体管道，为不同本体领域分配专门角色（如机制架构师、主题编织者、平衡批评家），每个智能体带有专业"焦虑"防止浅层输出。使用检索增强生成基于现有范例，并通过迭代验证确保机制与组件的一致性。

Result: 通过GameGrammar系统演示，给定主题提示（如"洞穴生态系统中竞争的生物发光真菌"），管道能生成结构完整、可玩的桌面游戏设计，包含机制、组件、胜利条件和设置说明，既满足本体约束又保持真正的创造性。

Conclusion: 该模式可推广到游戏以外的领域，任何具有专家词汇、有效性约束和积累范例的领域（如音乐创作、软件架构、烹饪艺术）都适合Generative Ontology。约束不仅不限制创造力，反而使其成为可能：正如语法使诗歌成为可能，本体论使结构化生成成为可能。

Abstract: Traditional ontologies excel at describing domain structure but cannot generate novel artifacts. Large language models generate fluently but produce outputs that lack structural validity, hallucinating mechanisms without components, goals without end conditions. We introduce Generative Ontology, a framework that synthesizes these complementary strengths: ontology provides the grammar; the LLM provides the creativity.
  Generative Ontology encodes domain knowledge as executable Pydantic schemas that constrain LLM generation via DSPy signatures. A multi-agent pipeline assigns specialized roles to different ontology domains: a Mechanics Architect designs game systems, a Theme Weaver integrates narrative, a Balance Critic identifies exploits. Each agent carrying a professional "anxiety" that prevents shallow, agreeable outputs. Retrieval-augmented generation grounds novel designs in precedents from existing exemplars, while iterative validation ensures coherence between mechanisms and components.
  We demonstrate the framework through GameGrammar, a system for generating complete tabletop game designs. Given a thematic prompt ("bioluminescent fungi competing in a cave ecosystem"), the pipeline produces structurally complete, playable game specifications with mechanisms, components, victory conditions, and setup instructions. These outputs satisfy ontological constraints while remaining genuinely creative.
  The pattern generalizes beyond games. Any domain with expert vocabulary, validity constraints, and accumulated exemplars (music composition, software architecture, culinary arts) is a candidate for Generative Ontology. We argue that constraints do not limit creativity but enable it: just as grammar makes poetry possible, ontology makes structured generation possible.

</details>


### [66] [Graph-based Agent Memory: Taxonomy, Techniques, and Applications](https://arxiv.org/abs/2602.05665)
*Chang Yang,Chuang Zhou,Yilin Xiao,Su Dong,Luyao Zhuang,Yujing Zhang,Zhu Wang,Zijin Hong,Zheng Yuan,Zhishang Xiang,Shengyuan Chen,Huachi Zhou,Qinggang Zhang,Ninghao Liu,Jinsong Su,Xinrun Wang,Yi Chang,Xiao Huang*

Main category: cs.AI

TL;DR: 本文综述了基于图的智能体记忆系统，分析了记忆分类、生命周期关键技术、开源资源及应用场景，为开发高效可靠的图记忆系统提供指导。


<details>
  <summary>Details</summary>
Motivation: 大语言模型智能体在处理长期复杂任务时需要有效的记忆系统，图结构因其能建模关系依赖、组织层次信息和支持高效检索而成为理想的记忆实现方式。

Method: 采用系统性综述方法，首先提出智能体记忆的分类体系，然后按照记忆生命周期分析图记忆的关键技术，包括提取、存储、检索和演化，最后总结开源资源和应用场景。

Result: 建立了基于图的智能体记忆系统框架，提供了完整的技术分析、开源资源收集和应用场景探索，为研究者提供了实用的开发指南和资源索引。

Conclusion: 图结构是构建智能体记忆系统的有力工具，本文为开发更高效可靠的图记忆系统提供了系统性指导，并指出了未来研究方向。

Abstract: Memory emerges as the core module in the Large Language Model (LLM)-based agents for long-horizon complex tasks (e.g., multi-turn dialogue, game playing, scientific discovery), where memory can enable knowledge accumulation, iterative reasoning and self-evolution. Among diverse paradigms, graph stands out as a powerful structure for agent memory due to the intrinsic capabilities to model relational dependencies, organize hierarchical information, and support efficient retrieval. This survey presents a comprehensive review of agent memory from the graph-based perspective. First, we introduce a taxonomy of agent memory, including short-term vs. long-term memory, knowledge vs. experience memory, non-structural vs. structural memory, with an implementation view of graph-based memory. Second, according to the life cycle of agent memory, we systematically analyze the key techniques in graph-based agent memory, covering memory extraction for transforming the data into the contents, storage for organizing the data efficiently, retrieval for retrieving the relevant contents from memory to support reasoning, and evolution for updating the contents in the memory. Third, we summarize the open-sourced libraries and benchmarks that support the development and evaluation of self-evolving agent memory. We also explore diverse application scenarios. Finally, we identify critical challenges and future research directions. This survey aims to offer actionable insights to advance the development of more efficient and reliable graph-based agent memory systems. All the related resources, including research papers, open-source data, and projects, are collected for the community in https://github.com/DEEP-PolyU/Awesome-GraphMemory.

</details>


### [67] [Determining Energy Efficiency Sweet Spots in Production LLM Inference](https://arxiv.org/abs/2602.05695)
*Hiari Pizzini Cavagna,Andrea Proia,Giacomo Madella,Giovanni B. Esposito,Francesco Antici,Daniele Cesarini,Zeynep Kiziltan,Andrea Bartolini*

Main category: cs.AI

TL;DR: 本文提出一个基于Transformer架构计算和内存访问复杂度的分析模型，能够准确预测LLM推理的能源效率曲线，发现能源效率存在峰值区域（短到中等输入+中等长度输出），并证明根据这些"甜点"调整序列长度可显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: LLM推理在现代AI应用中至关重要，需要准确理解其能源足迹。现有方法通常通过输入输出序列长度的简单线性函数估算能耗，但实际观测显示能源效率存在明显的非线性依赖关系，需要更精确的建模方法。

Method: 基于Transformer架构的计算和内存访问复杂度推导出分析模型，使用TensorRT-LLM在NVIDIA H100 GPU上评估能源消耗，测试了OPT、LLaMA、Gemma、Falcon、Qwen2、Granite等1B到9B参数的多样化LLM，输入输出长度从64到4096个token。

Result: 模型实现了1.79%的平均MAPE（平均绝对百分比误差），准确表征了能源效率曲线。发现能源效率峰值出现在短到中等输入和中等长度输出的组合，而长输入或非常短输出时效率急剧下降。

Conclusion: 通过将序列长度与能源效率"甜点"对齐，可以显著降低能源使用，支持生产系统中的信息截断、摘要和自适应生成策略，为节能LLM部署提供理论指导。

Abstract: Large Language Models (LLMs) inference is central in modern AI applications, making it critical to understand their energy footprint. Existing approaches typically estimate energy consumption through simple linear functions of input and output sequence lengths, yet our observations reveal clear Energy Efficiency regimes: peak efficiency occurs with short-to-moderate inputs and medium-length outputs, while efficiency drops sharply for long inputs or very short outputs, indicating a non-linear dependency. In this work, we propose an analytical model derived from the computational and memory-access complexity of the Transformer architecture, capable of accurately characterizing the efficiency curve as a function of input and output lengths. To assess its accuracy, we evaluate energy consumption using TensorRT-LLM on NVIDIA H100 GPUs across a diverse set of LLMs ranging from 1B to 9B parameters, including OPT, LLaMA, Gemma, Falcon, Qwen2, and Granite, tested over input and output lengths from 64 to 4096 tokens, achieving a mean MAPE of 1.79%. Our results show that aligning sequence lengths with these efficiency "Sweet Spots" can substantially reduce energy usage, supporting informed truncation, summarization, and adaptive generation strategies in production systems.

</details>


### [68] [Nonlinearity as Rank: Generative Low-Rank Adapter with Radial Basis Functions](https://arxiv.org/abs/2602.05709)
*Yihao Ouyang,Shiwei Li,Haozhao Wang,Xiandi Luo,Zhuoqi Hu,Yuetong Song,Qiyu Qin,Yichen Li,Ruixuan Li*

Main category: cs.AI

TL;DR: GenLoRA 用非线性函数生成低秩矩阵的基向量，替代显式存储，实现更高参数效率的微调


<details>
  <summary>Details</summary>
Motivation: 标准LoRA采用显式秩范式，增加模型容量需要添加更多基向量，导致参数大幅增长。研究发现这些基向量存在显著参数冗余，可以用轻量级非线性函数紧凑表示。

Method: 提出Generative Low-Rank Adapter (GenLoRA)，用非线性基向量生成替代显式基向量存储。为每个低秩矩阵维护一个潜在向量，使用一组轻量级径向基函数(RBFs)合成基向量，每个RBF所需参数远少于显式基向量。

Result: 在多个数据集和架构上的实验表明，GenLoRA在更小的参数预算下获得更高的有效LoRA秩，实现更优的微调性能。

Conclusion: GenLoRA通过非线性基向量生成机制，显著提高了LoRA的参数效率，为高效模型微调提供了新方法。

Abstract: Low-rank adaptation (LoRA) approximates the update of a pretrained weight matrix using the product of two low-rank matrices. However, standard LoRA follows an explicit-rank paradigm, where increasing model capacity requires adding more rows or columns (i.e., basis vectors) to the low-rank matrices, leading to substantial parameter growth. In this paper, we find that these basis vectors exhibit significant parameter redundancy and can be compactly represented by lightweight nonlinear functions. Therefore, we propose Generative Low-Rank Adapter (GenLoRA), which replaces explicit basis vector storage with nonlinear basis vector generation. Specifically, GenLoRA maintains a latent vector for each low-rank matrix and employs a set of lightweight radial basis functions (RBFs) to synthesize the basis vectors. Each RBF requires far fewer parameters than an explicit basis vector, enabling higher parameter efficiency in GenLoRA. Extensive experiments across multiple datasets and architectures show that GenLoRA attains higher effective LoRA ranks under smaller parameter budgets, resulting in superior fine-tuning performance. The code is available at https://anonymous.4open.science/r/GenLoRA-1519.

</details>


### [69] [Anchored Policy Optimization: Mitigating Exploration Collapse Via Support-Constrained Rectification](https://arxiv.org/abs/2602.05717)
*Tianyi Wang,Long Li,Hongcan Guo,Yibiao Chen,Yixia Li,Yong Wang,Yun Chen,Guanhua Chen*

Main category: cs.AI

TL;DR: 论文提出Anchored Policy Optimization (APO)方法，解决强化学习中验证奖励导致的递归空间收缩问题，通过从全局形状匹配转向支持覆盖，实现弹性恢复并打破准确性与多样性的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有基于验证奖励的强化学习(RLVR)存在递归空间收缩(RSC)的系统性病理问题，导致有效替代方案的采样概率消失。虽然KL正则化试图缓解此问题，但它强加了严格的形状匹配约束，与正确性所需的锐化产生梯度冲突。

Method: 提出锚定策略优化(APO)，将范式从全局形状匹配转向支持覆盖。基于参考模型的高置信度支持定义安全流形，允许激进锐化以提高效率，同时在错误校正时选择性调用恢复力以防止崩溃。

Result: 在数学基准测试中，APO打破了准确性与多样性的权衡，显著提高了Pass@1指标，同时恢复了标准策略梯度方法通常丢失的Pass@K多样性。

Conclusion: APO作为梯度对齐机制，通过最大化支持覆盖实现弹性恢复，有效解决RLVR中的递归空间收缩问题，为强化学习中的验证奖励应用提供了更优的优化框架。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is increasingly viewed as a tree pruning mechanism. However, we identify a systemic pathology termed Recursive Space Contraction (RSC), an irreversible collapse driven by the combined dynamics of positive sharpening and negative squeezing, where the sampling probability of valid alternatives vanishes. While Kullback-Leibler (KL) regularization aims to mitigate this, it imposes a rigid Shape Matching constraint that forces the policy to mimic the reference model's full density, creating a gradient conflict with the sharpening required for correctness. We propose Anchored Policy Optimization (APO), shifting the paradigm from global Shape Matching to Support Coverage. By defining a Safe Manifold based on the reference model's high-confidence support, APO permits aggressive sharpening for efficiency while selectively invoking a restorative force during error correction to prevent collapse. We theoretically derive that APO serves as a gradient-aligned mechanism to maximize support coverage, enabling an Elastic Recovery that re-inflates valid branches. Empirical evaluations on mathematical benchmarks demonstrate that APO breaks the accuracy-diversity trade-off, significantly improving Pass@1 while restoring the Pass@K diversity typically lost by standard policy gradient methods.

</details>


### [70] [Mitigating Hallucination in Financial Retrieval-Augmented Generation via Fine-Grained Knowledge Verification](https://arxiv.org/abs/2602.05723)
*Taoye Yin,Haoyuan Hu,Yaxin Fan,Xinhao Chen,Xinya Wu,Kai Deng,Kezun Zhang,Feng Wang*

Main category: cs.AI

TL;DR: 提出RLFKV框架，通过细粒度知识验证解决金融RAG系统中的幻觉问题，提高回答与检索文档的一致性。


<details>
  <summary>Details</summary>
Motivation: 金融RAG系统虽然依赖检索文档来生成准确回答，但由于金融领域的时间敏感性，模型生成的回答仍会出现与检索信息矛盾的幻觉问题。

Method: 提出强化学习框架RLFKV，将金融回答分解为原子知识单元，评估每个单元的正确性来计算细粒度忠实度奖励；同时引入信息丰富度奖励防止奖励黑客攻击（如过于简洁的回答）。

Result: 在公开的FDD任务和新提出的FDD-ANT数据集上的实验显示了一致的改进，证实了方法的有效性。

Conclusion: RLFKV框架通过细粒度知识验证和双重奖励机制，有效缓解了金融RAG系统中的幻觉问题，提高了回答与检索文档的一致性。

Abstract: In financial Retrieval-Augmented Generation (RAG) systems, models frequently rely on retrieved documents to generate accurate responses due to the time-sensitive nature of the financial domain. While retrieved documents help address knowledge gaps, model-generated responses still suffer from hallucinations that contradict the retrieved information. To mitigate this inconsistency, we propose a Reinforcement Learning framework enhanced with Fine-grained Knowledge Verification (RLFKV). Our method decomposes financial responses into atomic knowledge units and assesses the correctness of each unit to compute the fine-grained faithful reward. This reward offers more precise optimization signals, thereby improving alignment with the retrieved documents. Additionally, to prevent reward hacking (e.g., overly concise replies), we incorporate an informativeness reward that encourages the policy model to retain at least as many knowledge units as the base model. Experiments conducted on the public Financial Data Description (FDD) task and our newly proposed FDD-ANT dataset demonstrate consistent improvements, confirming the effectiveness of our approach.

</details>


### [71] [LeakBoost: Perceptual-Loss-Based Membership Inference Attack](https://arxiv.org/abs/2602.05748)
*Amit Kravchik Taub,Fred M. Grabovski,Guy Amit,Yisroel Mirsky*

Main category: cs.AI

TL;DR: LeakBoost是一个基于感知损失的主动探测框架，通过优化合成询问图像来增强成员推断攻击效果，显著提升现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有成员推断攻击主要依赖静态指标（如损失或置信度），未能充分利用模型在被主动探测时的动态行为，存在隐私风险评估不足的问题。

Method: 提出LeakBoost框架：针对候选输入，通过优化感知（激活空间）目标合成询问图像，放大成员与非成员在表示空间中的差异，然后使用现成的成员推断检测器进行分析。

Result: LeakBoost与现有方法结合后，在多个图像分类数据集和神经网络架构上取得显著改进：AUC从接近随机水平（0.53-0.62）提升到0.81-0.88，在1%FPR下的TPR提升超过一个数量级。

Conclusion: LeakBoost提供了一种模块化且计算高效的方法来评估白盒设置下的隐私风险，推动了动态成员推断的研究，特别是在深层网络和基于梯度的检测器中效果最佳。

Abstract: Membership inference attacks (MIAs) aim to determine whether a sample was part of a model's training set, posing serious privacy risks for modern machine-learning systems. Existing MIAs primarily rely on static indicators, such as loss or confidence, and do not fully leverage the dynamic behavior of models when actively probed. We propose LeakBoost, a perceptual-loss-based interrogation framework that actively probes a model's internal representations to expose hidden membership signals. Given a candidate input, LeakBoost synthesizes an interrogation image by optimizing a perceptual (activation-space) objective, amplifying representational differences between members and non-members. This image is then analyzed by an off-the-shelf membership detector, without modifying the detector itself. When combined with existing membership inference methods, LeakBoost achieves substantial improvements at low false-positive rates across multiple image classification datasets and diverse neural network architectures. In particular, it raises AUC from near-chance levels (0.53-0.62) to 0.81-0.88, and increases TPR at 1 percent FPR by over an order of magnitude compared to strong baseline attacks. A detailed sensitivity analysis reveals that deeper layers and short, low-learning-rate optimization produce the strongest leakage, and that improvements concentrate in gradient-based detectors. LeakBoost thus offers a modular and computationally efficient way to assess privacy risks in white-box settings, advancing the study of dynamic membership inference.

</details>


### [72] [RocqSmith: Can Automatic Optimization Forge Better Proof Agents?](https://arxiv.org/abs/2602.05762)
*Andrei Kozyrev,Nikita Khramov,Denis Lochmelis,Valerio Morelli,Gleb Solovev,Anton Podkopaev*

Main category: cs.AI

TL;DR: 研究AI智能体自动优化方法在形式验证领域的应用，评估不同优化器对Rocq定理证明智能体的优化效果，发现few-shot bootstrapping最有效，但仍不及精心设计的最优证明智能体。


<details>
  <summary>Details</summary>
Motivation: 探索自动AI智能体优化方法在形式验证领域的实际应用潜力，特别是在自动化定理证明这一具有挑战性的领域，研究是否能够自动化智能体系统的精细调优过程。

Method: 以Rocq定理证明智能体为研究对象，评估多种自动优化器在优化证明生成智能体任务上的表现，包括提示设计、上下文知识和控制策略等方面的自动化调优。

Result: 多个优化器都能带来可测量的改进，其中简单的few-shot bootstrapping方法表现最稳定有效，但所有研究的自动优化方法都无法达到精心设计的state-of-the-art证明智能体的性能水平。

Conclusion: 自动AI智能体优化方法在形式验证领域具有一定应用价值，但当前技术仍无法完全替代人工精心设计的智能体系统，few-shot bootstrapping是最有前景的自动化方法。

Abstract: This work studies the applicability of automatic AI agent optimization methods to real-world agents in formal verification settings, focusing on automated theorem proving in Rocq as a representative and challenging domain. We evaluate how different automatic agent optimizers perform when applied to the task of optimizing a Rocq proof-generation agent, and assess whether parts of the fine-grained tuning of agentic systems, such as prompt design, contextual knowledge, and control strategies, can be automated. Our results show that while several optimizers yield measurable improvements, simple few-shot bootstrapping is the most consistently effective; however, none of the studied methods matches the performance of a carefully engineered state-of-the-art proof agent.

</details>


### [73] [RL-VLA$^3$: Reinforcement Learning VLA Accelerating via Full Asynchronism](https://arxiv.org/abs/2602.05765)
*Zhong Guan,Haoran Sun,Yongjian Guo,Shuai Di,Xiaodong Bai,Jing Long,Tianyun Zhao,Mingxi Luo,Chen Zhou,Yucheng Guo,Qiming Yang,Wanting Xu,Wen Huang,Yunxuan Ma,Hongke Zhao,Likang Wu,Xiaotie Deng,Xi Xiao,Sheng Wen,Yicheng Gong,Junwu Xiong*

Main category: cs.AI

TL;DR: 提出首个完全异步的VLA模型训练框架，通过多级解耦架构显著提升训练效率，在LIBERO基准上实现最高126.67%的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型的RL训练框架（如RLinf）采用同步执行，导致环境交互、策略生成和模型更新阶段资源利用率低、吞吐量受限，成为实现通用具身智能的关键瓶颈。

Method: 设计完全异步的训练框架，包含：1）环境交互与轨迹收集的异步并行化；2）策略生成的流式执行；3）训练更新的解耦调度。从大模型RL的异步优化思想中系统借鉴，构建多级解耦架构。

Result: 在LIBERO基准上，相比现有同步策略实现最高59.25%的吞吐量提升，深度优化分离策略后可达126.67%提升。消融实验验证各异步组件的有效性，8-256 GPU规模验证了良好的可扩展性。

Conclusion: 首次提出并实现了完全异步的VLA模型训练框架，通过系统性的异步设计显著提升训练效率，为大规模具身智能模型的训练提供了高效解决方案。

Abstract: In recent years, Vision-Language-Action (VLA) models have emerged as a crucial pathway towards general embodied intelligence, yet their training efficiency has become a key bottleneck. Although existing reinforcement learning (RL)-based training frameworks like RLinf can enhance model generalization, they still rely on synchronous execution, leading to severe resource underutilization and throughput limitations during environment interaction, policy generation (rollout), and model update phases (actor). To overcome this challenge, this paper, for the first time, proposes and implements a fully-asynchronous policy training framework encompassing the entire pipeline from environment interaction, rollout generation, to actor policy updates. Systematically drawing inspiration from asynchronous optimization ideas in large model RL, our framework designs a multi-level decoupled architecture. This includes asynchronous parallelization of environment interaction and trajectory collection, streaming execution for policy generation, and decoupled scheduling for training updates. We validated the effectiveness of our method across diverse VLA models and environments. On the LIBERO benchmark, the framework achieves throughput improvements of up to 59.25\% compared to existing synchronous strategies. When deeply optimizing separation strategies, throughput can be increased by as much as 126.67\%. We verified the effectiveness of each asynchronous component via ablation studies. Scaling law validation across 8 to 256 GPUs demonstrates our method's excellent scalability under most conditions.

</details>


### [74] [FiMI: A Domain-Specific Language Model for Indian Finance Ecosystem](https://arxiv.org/abs/2602.05794)
*Aboli Kathar,Aman Kumar,Anusha Kamath,Araveeti Srujan,Ashish Sharma,Chandra Bhushan,Dilip Asbe,Divya Sorate,Duddu Prasanth Kumar,Evan Acharya,Harsh Sharma,Hrithik Kadam,Kanishk Singla,Keyur Doshi,Kiran Praveen,Kolisetty Krishna SK,Krishanu Adhikary,Lokesh MPT,Mayurdeep Sonowal,Nadeem Shaikh,Navya Prakash,Nimit Kothari,Nitin Kukreja,Prashant Devadiga,Rakesh Paul,Ratanjeet Pratap Chauhan,Raunak Kalani,Raviraj Joshi,Shamanth MH,Shantanu Pandey,Shubham Soni,Siddharth Dixit,Smriti Jopat,Sunil Patel,Suraj Singh,Suvradip Paul,Tulasi Pilla,Utkarsh Vaidya,Vineeth Nambiar,Vishal Kanvaty,Yatharth Dedhia*

Main category: cs.AI

TL;DR: FiMI是专门为印度数字支付系统开发的金融语言模型，基于Mistral Small 24B架构，通过多阶段训练流程优化，在金融推理和工具调用方面显著优于基础模型。


<details>
  <summary>Details</summary>
Motivation: 开发专门针对印度数字支付系统的金融语言模型，解决现有通用模型在印度金融领域特定需求（如多语言支持、真实工作流程建模）上的不足。

Method: 采用Mistral Small 24B架构，通过多阶段训练：1) 在680亿token的金融、多语言（英语、印地语、印英混合语）和合成数据上进行持续预训练；2) 指令微调；3) 针对多轮工具驱动对话的领域特定监督微调。

Result: FiMI Base在金融推理基准上比Mistral Small 24B Base提升20%；FiMI Instruct在领域特定工具调用上比Mistral Small 24B Instruct提升87%；同时在通用基准上保持与同类模型相当的性能。

Conclusion: FiMI成功开发了专门针对印度数字支付系统的金融语言模型，在保持通用能力的同时，在金融领域特定任务上取得了显著性能提升，证明了领域专业化训练的有效性。

Abstract: We present FiMI (Finance Model for India), a domain-specialized financial language model developed for Indian digital payment systems. We develop two model variants: FiMI Base and FiMI Instruct. FiMI adapts the Mistral Small 24B architecture through a multi-stage training pipeline, beginning with continuous pre-training on 68 Billion tokens of curated financial, multilingual (English, Hindi, Hinglish), and synthetic data. This is followed by instruction fine-tuning and domain-specific supervised fine-tuning focused on multi-turn, tool-driven conversations that model real-world workflows, such as transaction disputes and mandate lifecycle management. Evaluations reveal that FiMI Base achieves a 20% improvement over the Mistral Small 24B Base model on finance reasoning benchmark, while FiMI Instruct outperforms the Mistral Small 24B Instruct model by 87% on domain-specific tool-calling. Moreover, FiMI achieves these significant domain gains while maintaining comparable performance to models of similar size on general benchmarks.

</details>


### [75] [NEX: Neuron Explore-Exploit Scoring for Label-Free Chain-of-Thought Selection and Model Ranking](https://arxiv.org/abs/2602.05805)
*Kang Chen,Zhuoka Feng,Sihan Zhao,Kai Xiong,Junjie Nian,Yaoning Wang,Changyi Xiao,Yixin Cao*

Main category: cs.AI

TL;DR: 提出NEX框架，通过分析激活神经元模式来无监督评估推理质量，无需任务答案即可排名候选响应


<details>
  <summary>Details</summary>
Motivation: 大语言模型推理时经常生成多个思维链或搜索合并检查点，但缺乏目标分布监督，选择成为瓶颈。需要无监督方法评估推理质量

Method: 提出NEX框架，将推理视为探索(E-phase)和利用(X-phase)交替过程。通过分析MLP神经元激活模式检测E-phase，使用隐马尔可夫模型推断E-X阶段，根据神经元重用情况计算Good-Mass Fraction分数

Result: 在推理基准和Qwen3合并家族上，NEX仅需少量未标记激活数据即可预测下游准确性，识别更好变体。通过人工标注验证E-X信号，并通过神经元转移提供因果证据

Conclusion: NEX提供了一种无需标签的无监督评分框架，能够有效评估推理质量，识别冗余探索，为模型选择和变体评估提供实用工具

Abstract: Large language models increasingly spend inference compute sampling multiple chain-of-thought traces or searching over merged checkpoints. This shifts the bottleneck from generation to selection, often without supervision on the target distribution. We show entropy-based exploration proxies follow an inverted-U with accuracy, suggesting extra exploration can become redundant and induce overthinking. We propose NEX, a white-box label-free unsupervised scoring framework that views reasoning as alternating E-phase (exploration) and X-phase (exploitation). NEX detects E-phase as spikes in newly activated MLP neurons per token from sparse activation caches, then uses a sticky two-state HMM to infer E-X phases and credits E-introduced neurons by whether they are reused in the following X span. These signals yield interpretable neuron weights and a single Good-Mass Fraction score to rank candidate responses and merged variants without task answers. Across reasoning benchmarks and Qwen3 merge families, NEX computed on a small unlabeled activation set predicts downstream accuracy and identifies better variants; we further validate the E-X signal with human annotations and provide causal evidence via "Effective-vs-Redundant" neuron transfer.

</details>


### [76] [STProtein: predicting spatial protein expression from multi-omics data](https://arxiv.org/abs/2602.05811)
*Zhaorui Jiang,Yingfang Yuan,Lei Hu,Wei Pang*

Main category: cs.AI

TL;DR: STProtein是一个基于图神经网络和多任务学习的新框架，旨在利用相对丰富的空间转录组数据来预测稀缺的空间蛋白质表达数据，以解决空间多组学数据不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 空间多组学数据整合对生物学研究至关重要，但存在严重的数据不平衡问题：空间转录组数据相对丰富，而空间蛋白质组数据由于技术限制和高成本而稀缺，这阻碍了研究进展。

Method: 提出STProtein框架，采用图神经网络结合多任务学习策略，利用更易获取的空间多组学数据（如空间转录组）来准确预测未知的空间蛋白质表达。

Result: STProtein能够有效解决空间蛋白质组数据的稀缺问题，加速空间多组学整合，有望在生命科学领域催化突破性进展。

Conclusion: 该工具使科学家能够加速发现组织内复杂的、先前隐藏的蛋白质空间模式，揭示不同标记基因之间的新关系，并探索生物学的"暗物质"。

Abstract: The integration of spatial multi-omics data from single tissues is crucial for advancing biological research. However, a significant data imbalance impedes progress: while spatial transcriptomics data is relatively abundant, spatial proteomics data remains scarce due to technical limitations and high costs. To overcome this challenge we propose STProtein, a novel framework leveraging graph neural networks with multi-task learning strategy. STProtein is designed to accurately predict unknown spatial protein expression using more accessible spatial multi-omics data, such as spatial transcriptomics. We believe that STProtein can effectively addresses the scarcity of spatial proteomics, accelerating the integration of spatial multi-omics and potentially catalyzing transformative breakthroughs in life sciences. This tool enables scientists to accelerate discovery by identifying complex and previously hidden spatial patterns of proteins within tissues, uncovering novel relationships between different marker genes, and exploring the biological "Dark Matter".

</details>


### [77] [TKG-Thinker: Towards Dynamic Reasoning over Temporal Knowledge Graphs via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.05818)
*Zihao Jiang,Miao Peng,Zhenyan Shan,Wenjie Xu,Ben Liu,Gong Chen,Ziqi Gao,Min Peng*

Main category: cs.AI

TL;DR: TKG-Thinker是一个用于时序知识图谱问答的智能体，通过自主规划和自适应检索能力，结合监督微调和强化学习，在复杂时序约束下实现更准确的推理。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的时序知识图谱问答存在两个主要问题：1) 在复杂时序约束下容易产生推理幻觉；2) 静态提示限制了模型自主性和泛化能力，缺乏与时序知识图谱环境的动态交互优化。

Method: 提出TKG-Thinker智能体，具备自主规划和自适应检索能力。采用双阶段训练策略：首先使用思维链数据进行监督微调，培养核心规划能力；然后通过强化学习阶段，利用多维奖励在复杂时序约束下优化推理策略。

Result: 在基准数据集上使用三个开源大语言模型进行实验，TKG-Thinker实现了最先进的性能，并在复杂时序知识图谱问答设置中表现出强大的泛化能力。

Conclusion: TKG-Thinker通过动态多轮交互和双训练策略，有效解决了时序知识图谱问答中的推理幻觉和泛化限制问题，为时序推理提供了更可靠的解决方案。

Abstract: Temporal knowledge graph question answering (TKGQA) aims to answer time-sensitive questions by leveraging temporal knowledge bases. While Large Language Models (LLMs) demonstrate significant potential in TKGQA, current prompting strategies constrain their efficacy in two primary ways. First, they are prone to reasoning hallucinations under complex temporal constraints. Second, static prompting limits model autonomy and generalization, as it lack optimization through dynamic interaction with temporal knowledge graphs (TKGs) environments. To address these limitations, we propose \textbf{TKG-Thinker}, a novel agent equipped with autonomous planning and adaptive retrieval capabilities for reasoning over TKGs. Specifically, TKG-Thinker performs in-depth temporal reasoning through dynamic multi-turn interactions with TKGs via a dual-training strategy. We first apply Supervised Fine-Tuning (SFT) with chain-of thought data to instill core planning capabilities, followed by a Reinforcement Learning (RL) stage that leverages multi-dimensional rewards to refine reasoning policies under intricate temporal constraints. Experimental results on benchmark datasets with three open-source LLMs show that TKG-Thinker achieves state-of-the-art performance and exhibits strong generalization across complex TKGQA settings.

</details>


### [78] [Learning Compact Boolean Networks](https://arxiv.org/abs/2602.05830)
*Shengpu Wang,Yuhao Mao,Yani Zhang,Martin Vechev*

Main category: cs.AI

TL;DR: 提出一种新的布尔网络学习方法，通过连接学习、紧凑卷积和自适应离散化三个角度，显著提升了布尔网络的准确率与计算效率的帕累托前沿，比现有方法减少最多37倍布尔运算。


<details>
  <summary>Details</summary>
Motivation: 浮点神经网络虽然主导现代机器学习，但推理成本高，而布尔网络适合资源受限环境。然而，学习紧凑且准确的布尔网络具有挑战性，因为其组合性质。

Method: 从三个角度解决挑战：1) 提出学习高效连接的新策略，无需额外参数且计算开销可忽略；2) 引入新颖的卷积布尔架构，利用局部性，比现有方法减少布尔运算数量；3) 提出自适应离散化策略，减少将连续值网络转换为布尔网络时的准确率下降。

Result: 在标准视觉基准测试上，该方法在准确率与计算量的帕累托前沿显著优于现有技术，在减少最多37倍布尔运算的情况下获得更好的准确率。

Conclusion: 该方法通过连接学习、紧凑卷积和自适应离散化的综合策略，有效解决了布尔网络学习中的挑战，为资源受限环境提供了高效的神经网络解决方案。

Abstract: Floating-point neural networks dominate modern machine learning but incur substantial inference cost, motivating interest in Boolean networks for resource-constrained settings. However, learning compact and accurate Boolean networks is challenging due to their combinatorial nature. In this work, we address this challenge from three different angles: learned connections, compact convolutions and adaptive discretization. First, we propose a novel strategy to learn efficient connections with no additional parameters and negligible computational overhead. Second, we introduce a novel convolutional Boolean architecture that exploits the locality with reduced number of Boolean operations than existing methods. Third, we propose an adaptive discretization strategy to reduce the accuracy drop when converting a continuous-valued network into a Boolean one. Extensive results on standard vision benchmarks demonstrate that the Pareto front of accuracy vs. computation of our method significantly outperforms prior state-of-the-art, achieving better accuracy with up to 37x fewer Boolean operations.

</details>


### [79] [OmniVideo-R1: Reinforcing Audio-visual Reasoning with Query Intention and Modality Attention](https://arxiv.org/abs/2602.05847)
*Zhangquan Chen,Jiale Tao,Ruihuang Li,Yihao Hu,Ruitao Chen,Zhantao Yang,Xinlei Yu,Haodong Jing,Manyuan Zhang,Shuai Shao,Biao Wang,Qinglin Lu,Ruqi Huang*

Main category: cs.AI

TL;DR: OmniVideo-R1：一个通过强化学习框架改进多模态推理的模型，采用查询密集型定位和模态注意力融合策略，在多个基准测试中表现优异


<details>
  <summary>Details</summary>
Motivation: 人类通过多种模态协同感知世界，但现有的全视频模型在音视频理解任务上仍面临挑战，需要改进混合模态推理能力

Method: 提出OmniVideo-R1强化框架，采用两种关键策略：1）基于自监督学习的查询密集型定位；2）基于对比学习的模态注意力融合

Result: 在多个基准测试上的广泛实验表明，OmniVideo-R1始终优于强基线模型，显示出其有效性和强大的泛化能力

Conclusion: OmniVideo-R1通过"全模态线索思考"的强化框架，显著提升了混合模态推理能力，为音视频理解任务提供了有效解决方案

Abstract: While humans perceive the world through diverse modalities that operate synergistically to support a holistic understanding of their surroundings, existing omnivideo models still face substantial challenges on audio-visual understanding tasks. In this paper, we propose OmniVideo-R1, a novel reinforced framework that improves mixed-modality reasoning. OmniVideo-R1 empowers models to "think with omnimodal cues" by two key strategies: (1) query-intensive grounding based on self-supervised learning paradigms; and (2) modality-attentive fusion built upon contrastive learning paradigms. Extensive experiments on multiple benchmarks demonstrate that OmniVideo-R1 consistently outperforms strong baselines, highlighting its effectiveness and robust generalization capabilities.

</details>


### [80] [BABE: Biology Arena BEnchmark](https://arxiv.org/abs/2602.05857)
*Junting Zhou,Jin Chen,Linfeng Hao,Denghui Cao,Zheyu Wang,Qiguang Chen,Chaoyou Fu,Jiaze Chen,Yuchen Wu,Ge Zhang,Mingxuan Wang,Wenhao Huang,Tong Yang*

Main category: cs.AI

TL;DR: BABE是一个评估生物AI系统实验推理能力的基准，基于同行评审论文和真实生物学研究构建，挑战模型进行因果推理和跨尺度推断。


<details>
  <summary>Details</summary>
Motivation: 现有生物学基准往往无法评估研究人员所需的关键技能：将实验结果与背景知识结合以得出有意义结论的能力。大型语言模型能力已从基础对话扩展到高级科学推理，但缺乏评估实验推理能力的基准。

Method: 从同行评审研究论文和真实世界生物学研究中构建BABE基准，确保任务反映实际科学探究的复杂性和跨学科性质。基准设计挑战模型进行因果推理和跨尺度推断。

Result: BABE提供了一个稳健的评估框架，用于评估AI系统如何像实践科学家一样进行推理，为衡量其对生物学研究贡献潜力提供了更真实的测量标准。

Conclusion: BABE填补了评估生物AI系统实验推理能力的空白，通过基于真实科学研究构建的基准，能够更真实地评估AI系统在生物学研究中的推理能力和潜在贡献。

Abstract: The rapid evolution of large language models (LLMs) has expanded their capabilities from basic dialogue to advanced scientific reasoning. However, existing benchmarks in biology often fail to assess a critical skill required of researchers: the ability to integrate experimental results with contextual knowledge to derive meaningful conclusions. To address this gap, we introduce BABE(Biology Arena BEnchmark), a comprehensive benchmark designed to evaluate the experimental reasoning capabilities of biological AI systems. BABE is uniquely constructed from peer-reviewed research papers and real-world biological studies, ensuring that tasks reflect the complexity and interdisciplinary nature of actual scientific inquiry. BABE challenges models to perform causal reasoning and cross-scale inference. Our benchmark provides a robust framework for assessing how well AI systems can reason like practicing scientists, offering a more authentic measure of their potential to contribute to biological research.

</details>


### [81] [Beyond Manual Planning: Seating Allocation for Large Organizations](https://arxiv.org/abs/2602.05875)
*Anton Ipsen,Michael Cashmore,Kirsty Fielding,Nicolas Marchesotti,Parisa Zehtabi,Daniele Magazzeni,Manuela Veloso*

Main category: cs.AI

TL;DR: 提出分层座位分配问题(HSAP)，解决组织团队在楼层平面图中的最优座位分配，确保层级关系紧密的团队座位相邻，采用概率路线图(PRM)和快速探索随机树(RRT)计算座位距离，结合启发式搜索和动态规划通过整数规划求解。


<details>
  <summary>Details</summary>
Motivation: 大型组织需要确保层级关系紧密的团队座位相邻（如研究小组占据连续区域），目前手动管理导致重新规划频率低且效果不佳，需要自动化解决方案。

Method: 提出端到端框架：1) 使用概率路线图(PRM)和快速探索随机树(RRT)计算任意座位对之间的距离；2) 结合启发式搜索和动态规划方法，通过整数规划求解HSAP。

Result: 在不同规模实例下评估PRM框架和分配结果，进行定量和定性分析，验证方法的有效性。

Conclusion: 提出的HSAP框架能够自动化解决组织团队座位分配问题，替代手动管理，提高规划效率和优化效果。

Abstract: We introduce the Hierarchical Seating Allocation Problem (HSAP) which addresses the optimal assignment of hierarchically structured organizational teams to physical seating arrangements on a floor plan. This problem is driven by the necessity for large organizations with large hierarchies to ensure that teams with close hierarchical relationships are seated in proximity to one another, such as ensuring a research group occupies a contiguous area. Currently, this problem is managed manually leading to infrequent and suboptimal replanning efforts. To alleviate this manual process, we propose an end-to-end framework to solve the HSAP. A scalable approach to calculate the distance between any pair of seats using a probabilistic road map (PRM) and rapidly-exploring random trees (RRT) which is combined with heuristic search and dynamic programming approach to solve the HSAP using integer programming. We demonstrate our approach under different sized instances by evaluating the PRM framework and subsequent allocations both quantitatively and qualitatively.

</details>


### [82] [Agent2Agent Threats in Safety-Critical LLM Assistants: A Human-Centric Taxonomy](https://arxiv.org/abs/2602.05877)
*Lukas Stappen,Ahmet Erkan Turan,Johann Hagerer,Georg Groh*

Main category: cs.AI

TL;DR: 提出AgentHeLLM威胁建模框架，用于分析车载LLM对话代理的安全风险，通过分离资产识别与攻击路径分析，并提供自动化攻击路径发现工具。


<details>
  <summary>Details</summary>
Motivation: 车载LLM对话代理与外部服务协调时（如Google的A2A协议）会创建新的攻击面，恶意操作可能通过自然语言载荷传播，导致从驾驶员分心到未经授权的车辆控制等严重后果。现有AI安全框架缺乏安全关键系统工程中的"关注点分离"原则，将保护对象（资产）与攻击方式（攻击路径）混为一谈。

Method: 提出AgentHeLLM威胁建模框架，正式分离资产识别与攻击路径分析：1）引入基于伤害导向"受害者建模"和《世界人权宣言》启发的人本资产分类法；2）建立形式化的图模型，区分毒化路径（恶意数据传播）与触发路径（激活动作）；3）开发开源攻击路径建议工具AgentHeLLM Attack Path Generator，使用双层搜索策略自动化多阶段威胁发现。

Result: 开发了实用的威胁建模框架和自动化工具，能够系统地识别和分析车载LLM代理的安全威胁，填补了现有AI安全框架在安全关键系统中的方法论空白。

Conclusion: AgentHeLLM框架为解决车载LLM对话代理的安全挑战提供了系统化的方法论和实用工具，通过分离资产与攻击路径分析，能够更有效地识别和管理安全风险，特别是在安全关键的汽车环境中。

Abstract: The integration of Large Language Model (LLM)-based conversational agents into vehicles creates novel security challenges at the intersection of agentic AI, automotive safety, and inter-agent communication. As these intelligent assistants coordinate with external services via protocols such as Google's Agent-to-Agent (A2A), they establish attack surfaces where manipulations can propagate through natural language payloads, potentially causing severe consequences ranging from driver distraction to unauthorized vehicle control. Existing AI security frameworks, while foundational, lack the rigorous "separation of concerns" standard in safety-critical systems engineering by co-mingling the concepts of what is being protected (assets) with how it is attacked (attack paths). This paper addresses this methodological gap by proposing a threat modeling framework called AgentHeLLM (Agent Hazard Exploration for LLM Assistants) that formally separates asset identification from attack path analysis. We introduce a human-centric asset taxonomy derived from harm-oriented "victim modeling" and inspired by the Universal Declaration of Human Rights, and a formal graph-based model that distinguishes poison paths (malicious data propagation) from trigger paths (activation actions). We demonstrate the framework's practical applicability through an open-source attack path suggestion tool AgentHeLLM Attack Path Generator that automates multi-stage threat discovery using a bi-level search strategy.

</details>


### [83] [A Guide to Large Language Models in Modeling and Simulation: From Core Techniques to Critical Challenges](https://arxiv.org/abs/2602.05883)
*Philippe J. Giabbanelli*

Main category: cs.AI

TL;DR: 论文为M&S领域提供LLM使用的全面实用指南，强调避免常见陷阱和做出明智设计决策


<details>
  <summary>Details</summary>
Motivation: LLM在建模与仿真中广泛应用，但看似简单的实践可能带来微妙问题、不必要复杂性甚至劣质结果，需要提供系统指导

Method: 讨论常见困惑来源：非确定性、知识增强（RAG和LoRA）、M&S数据分解、超参数设置；强调原则性设计选择、诊断策略和实证评估

Result: 提供综合实用指南，帮助建模者做出明智决策：何时、如何以及是否依赖LLM

Conclusion: LLM在M&S中应用需要谨慎的系统方法，避免常见陷阱，通过原则性设计和实证评估确保有效使用

Abstract: Large language models (LLMs) have rapidly become familiar tools to researchers and practitioners. Concepts such as prompting, temperature, or few-shot examples are now widely recognized, and LLMs are increasingly used in Modeling & Simulation (M&S) workflows. However, practices that appear straightforward may introduce subtle issues, unnecessary complexity, or may even lead to inferior results. Adding more data can backfire (e.g., deteriorating performance through model collapse or inadvertently wiping out existing guardrails), spending time on fine-tuning a model can be unnecessary without a prior assessment of what it already knows, setting the temperature to 0 is not sufficient to make LLMs deterministic, providing a large volume of M&S data as input can be excessive (LLMs cannot attend to everything) but naive simplifications can lose information. We aim to provide comprehensive and practical guidance on how to use LLMs, with an emphasis on M&S applications. We discuss common sources of confusion, including non-determinism, knowledge augmentation (including RAG and LoRA), decomposition of M&S data, and hyper-parameter settings. We emphasize principled design choices, diagnostic strategies, and empirical evaluation, with the goal of helping modelers make informed decisions about when, how, and whether to rely on LLMs.

</details>


### [84] [Geographically-aware Transformer-based Traffic Forecasting for Urban Motorway Digital Twins](https://arxiv.org/abs/2602.05983)
*Krešimir Kušić,Vinny Cahill,Ivana Dusparic*

Main category: cs.AI

TL;DR: 论文提出GATTF模型，利用传感器间的互信息增强地理感知能力，提升高速公路交通预测精度


<details>
  <summary>Details</summary>
Motivation: 高速公路数字孪生需要实时和预测数据支持主动决策，但交通预测因时空复杂性和非线性动态而困难，现有序列深度学习模型在预测精度和模型复杂度方面仍需改进

Method: 提出地理感知的Transformer交通预测模型GATTF，利用分布式传感器间的互信息捕捉地理关系，增强模型的地理感知能力

Result: 使用瑞士日内瓦高速公路网络实时数据评估，结果显示GATTF相比标准Transformer提高了预测精度，且未增加模型复杂度

Conclusion: 通过互信息增强地理感知能有效提升Transformer模型的高速公路交通预测性能，为数字孪生交通管理提供更好的预测支持

Abstract: The operational effectiveness of digital-twin technology in motorway traffic management depends on the availability of a continuous flow of high-resolution real-time traffic data. To function as a proactive decision-making support layer within traffic management, a digital twin must also incorporate predicted traffic conditions in addition to real-time observations. Due to the spatio-temporal complexity and the time-variant, non-linear nature of traffic dynamics, predicting motorway traffic remains a difficult problem. Sequence-based deep-learning models offer clear advantages over classical machine learning and statistical models in capturing long-range, temporal dependencies in time-series traffic data, yet limitations in forecasting accuracy and model complexity point to the need for further improvements. To improve motorway traffic forecasting, this paper introduces a Geographically-aware Transformer-based Traffic Forecasting GATTF model, which exploits the geographical relationships between distributed sensors using their mutual information (MI). The model has been evaluated using real-time data from the Geneva motorway network in Switzerland and results confirm that incorporating geographical awareness through MI enhances the accuracy of GATTF forecasting compared to a standard Transformer, without increasing model complexity.

</details>


### [85] [Speech Emotion Recognition Leveraging OpenAI's Whisper Representations and Attentive Pooling Methods](https://arxiv.org/abs/2602.06000)
*Ali Shendabadi,Parnia Izadirad,Mostafa Salehi,Mahmoud Bijankhan*

Main category: cs.AI

TL;DR: 本文探索了使用预训练的Whisper ASR模型进行语音情感识别，提出了两种注意力池化方法来降维并保留情感特征，在波斯语数据集上取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 语音情感识别研究面临标准大规模数据集缺乏的挑战，现有研究多使用预训练模型提取特征。本文旨在探索Whisper预训练ASR系统在语音情感识别中的潜力。

Method: 提出两种注意力池化方法：多头注意力平均池化和QKV池化，用于高效降低Whisper表示的维度同时保留情感特征。在英语IEMOCAP和波斯语ShEMO数据集上使用Whisper Tiny和Small模型进行实验。

Result: 多头QKV架构在ShEMO数据集上取得了SOTA结果，未加权准确率提升2.47%。发现中间层在波斯语数据集上表现更好，为轻量高效的SER提供了替代大型模型（如HuBERT X-Large）的方案。

Conclusion: Whisper作为语音情感识别的表示提取器具有潜力，注意力池化方法在维度减少方面有效，为轻量高效的SER系统提供了新思路。

Abstract: Speech Emotion Recognition (SER) research has faced limitations due to the lack of standard and sufficiently large datasets. Recent studies have leveraged pre-trained models to extract features for downstream tasks such as SER. This work explores the capabilities of Whisper, a pre-trained ASR system, in speech emotion recognition by proposing two attention-based pooling methods, Multi-head Attentive Average Pooling and QKV Pooling, designed to efficiently reduce the dimensionality of Whisper representations while preserving emotional features. We experiment on English and Persian, using the IEMOCAP and ShEMO datasets respectively, with Whisper Tiny and Small. Our multi-head QKV architecture achieves state-of-the-art results on the ShEMO dataset, with a 2.47% improvement in unweighted accuracy. We further compare the performance of different Whisper encoder layers and find that intermediate layers often perform better for SER on the Persian dataset, providing a lightweight and efficient alternative to much larger models such as HuBERT X-Large. Our findings highlight the potential of Whisper as a representation extractor for SER and demonstrate the effectiveness of attention-based pooling for dimension reduction.

</details>


### [86] [AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions](https://arxiv.org/abs/2602.06008)
*Xianyang Liu,Shangding Gu,Dawn Song*

Main category: cs.AI

TL;DR: AgenticPay是一个用于多智能体买卖谈判的基准测试和仿真框架，通过自然语言驱动，包含110多个任务，评估LLM在商业谈判中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试缺乏评估多智能体之间语言驱动的经济交互的原则性设置，而LLM智能体越来越多地需要自主协商、协调和交易。

Method: 构建AgenticPay框架，模拟买卖双方具有私有约束和产品依赖估值的市场，通过多轮语言谈判达成协议，支持双边议价到多对多市场的110多个任务，包含结构化动作提取和可行性、效率、福利等指标。

Result: 对最先进的专有和开源LLM进行基准测试显示谈判性能存在显著差距，突显了长期战略推理的挑战。

Conclusion: AgenticPay为研究智能体商业和基于语言的市场交互奠定了基础，代码和数据集已开源。

Abstract: Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models markets in which buyers and sellers possess private constraints and product-dependent valuations, and must reach agreements through multi-round linguistic negotiation rather than numeric bidding alone. The framework supports a diverse suite of over 110 tasks ranging from bilateral bargaining to many-to-many markets, with structured action extraction and metrics for feasibility, efficiency, and welfare. Benchmarking state-of-the-art proprietary and open-weight LLMs reveals substantial gaps in negotiation performance and highlights challenges in long-horizon strategic reasoning, establishing AgenticPay as a foundation for studying agentic commerce and language-based market interaction. Code and dataset are available at the link: https://github.com/SafeRL-Lab/AgenticPay.

</details>


### [87] [Learning Event-Based Shooter Models from Virtual Reality Experiments](https://arxiv.org/abs/2602.06023)
*Christopher A. McClurg,Alan R. Wagner*

Main category: cs.AI

TL;DR: 开发数据驱动的离散事件模拟器，用于评估学校安全干预策略，特别是机器人干预枪击事件，解决VR研究中招募参与者的可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: VR是评估学校安全措施的有力工具，但需要为每个条件招募新参与者，难以进行大规模或迭代评估，这在需要大量训练回合的学习有效干预策略时尤其受限。

Method: 开发数据驱动的离散事件模拟器（DES），将枪手移动和区域内行为建模为从VR研究中参与者行为学习的随机过程，用于评估机器人干预策略。

Result: 模拟器能够复现关键经验模式，使大规模评估和学习干预策略成为可能，这些策略直接使用人类受试者训练是不可行的。

Conclusion: 这项工作展示了一个高到中保真度的模拟工作流程，为开发和评估自主学校安全干预提供了可扩展的替代方案。

Abstract: Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restrictive when attempting to learn effective intervention strategies, which typically require many training episodes. To address this challenge, we develop a data-driven discrete-event simulator (DES) that models shooter movement and in-region actions as stochastic processes learned from participant behavior in VR studies. We use the simulator to examine the impact of a robot-based shooter intervention strategy. Once shown to reproduce key empirical patterns, the DES enables scalable evaluation and learning of intervention strategies that are infeasible to train directly with human subjects. Overall, this work demonstrates a high-to-mid fidelity simulation workflow that provides a scalable surrogate for developing and evaluating autonomous school-security interventions.

</details>


### [88] [DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching](https://arxiv.org/abs/2602.06039)
*Yuxing Lu,Yucheng Hu,Xukai Zhao,Jiuxin Cao*

Main category: cs.AI

TL;DR: DyTopo：一种基于大语言模型的多智能体框架，通过动态重构稀疏有向通信图来提升多轮推理性能


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的大语言模型多智能体系统通常采用固定的通信模式，无法适应迭代问题解决中不同阶段的需求变化，需要更灵活、自适应的通信机制

Method: DyTopo框架包含管理器引导的通信图重构机制：每个智能体输出轻量级自然语言查询（需求）和关键信息（提供）描述符，通过语义匹配构建稀疏有向通信图，仅沿诱导边传递私有消息

Result: 在代码生成和数学推理基准测试中，使用四种LLM骨干网络，DyTopo始终优于最强基线（平均提升6.2%），同时提供可解释的协调轨迹

Conclusion: DyTopo通过动态重构通信图实现了更有效的多智能体协作，不仅提升了性能，还提供了可解释的通信演化轨迹，有助于理解跨轮次的协调过程

Abstract: Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative problem solving. We introduce DyTopo, a manager-guided multi-agent framework that reconstructs a sparse directed communication graph at each round. Conditioned on the manager's round goal, each agent outputs lightweight natural-language query (need) and \key (offer) descriptors; DyTopo embeds these descriptors and performs semantic matching, routing private messages only along the induced edges. Across code generation and mathematical reasoning benchmarks and four LLM backbones, DyTopo consistently outperforms over the strongest baseline (avg. +6.2). Beyond accuracy, DyTopo yields an interpretable coordination trace via the evolving graphs, enabling qualitative inspection of how communication pathways reconfigure across rounds.

</details>
