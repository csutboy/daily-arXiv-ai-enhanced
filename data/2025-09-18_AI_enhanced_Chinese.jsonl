{"id": "2509.13808", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.13808", "abs": "https://arxiv.org/abs/2509.13808", "authors": ["Jinghua Song", "Yuan Wang", "Zimo Yan"], "title": "Higher-order Network phenomena of cascading failures in resilient cities", "comment": null, "summary": "Modern urban resilience is threatened by cascading failures in multimodal\ntransport networks, where localized shocks trigger widespread paralysis.\nExisting models, limited by their focus on pairwise interactions, often\nunderestimate this systemic risk. To address this, we introduce a framework\nthat confronts higher-order network theory with empirical evidence from a\nlarge-scale, real-world multimodal transport network. Our findings confirm a\nfundamental duality: network integration enhances static robustness metrics but\nsimultaneously creates the structural pathways for catastrophic cascades.\nCrucially, we uncover the source of this paradox: a profound disconnect between\nstatic network structure and dynamic functional failure. We provide strong\nevidence that metrics derived from the network's static blueprint-encompassing\nboth conventional low-order centrality and novel higher-order structural\nanalyses-are fundamentally disconnected from and thus poor predictors of a\nsystem's dynamic functional resilience. This result highlights the inherent\nlimitations of static analysis and underscores the need for a paradigm shift\ntowards dynamic models to design and manage truly resilient urban systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.13462", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2509.13462", "abs": "https://arxiv.org/abs/2509.13462", "authors": ["Tushar Shankar Walunj", "Veeraruna Kavitha", "Jayakrishnan Nair", "Priyank Agarwal"], "title": "Strategic Pricing and Ranking in Recommendation Systems with Seller Competition", "comment": null, "summary": "We study a recommendation system where sellers compete for visibility by\nstrategically offering commissions to a platform that optimally curates a\nranked menu of items and their respective prices for each customer. Customers\ninteract sequentially with the menu following a cascade click model, and their\npurchase decisions are influenced by price sensitivity and positions of various\nitems in the menu. We model the seller-platform interaction as a Stackelberg\ngame with sellers as leaders and consider two different games depending on\nwhether the prices are set by the platform or prefixed by the sellers. It is\ncomplicated to find the optimal policy of the platform in complete generality;\nhence, we solve the problem in an important asymptotic regime.\n  The core contribution of this paper lies in characterizing the equilibrium\nstructure of the limit game. We show that when sellers are of different\nstrengths, the standard Nash equilibrium does not exist due to discontinuities\nin utilities. We instead establish the existence of a novel equilibrium\nsolution, namely `$\\mu$-connected equilibrium cycle' ($\\mu$-EC), which captures\noscillatory strategic responses at the equilibrium. Unlike the (pure) Nash\nequilibrium, which defines a fixed point of mutual best responses, this is a\nset-valued solution concept of connected components. This novel equilibrium\nconcept identifies a Cartesian product set of connected action profiles in the\ncontinuous action space that satisfies four important properties: stability\nagainst external deviations, no external chains, instability against internal\ndeviations, and minimality. We extend a recently introduced solution concept\nequilibrium cycle to include stability against measure-zero violations and, by\navoiding topological difficulties to propose $\\mu$-EC.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u63a8\u8350\u7cfb\u7edf\u4e2d\u5356\u5bb6\u901a\u8fc7\u7b56\u7565\u6027\u63d0\u4f9b\u4f63\u91d1\u7ade\u4e89\u5e73\u53f0\u53ef\u89c1\u5ea6\u7684\u535a\u5f08\u95ee\u9898\uff0c\u5728\u6e10\u8fdb\u673a\u5236\u4e0b\u63d0\u51fa\u4e86\u65b0\u7684\u03bc-\u8fde\u63a5\u5747\u8861\u5faa\u73af(\u03bc-EC)\u89e3\u6982\u5ff5", "motivation": "\u7814\u7a76\u63a8\u8350\u7cfb\u7edf\u4e2d\u5356\u5bb6\u4e0e\u5e73\u53f0\u7684\u6218\u7565\u4e92\u52a8\uff0c\u4f20\u7edf\u7eb3\u4ec0\u5747\u8861\u5728\u5356\u5bb6\u5b9e\u529b\u4e0d\u540c\u65f6\u7531\u4e8e\u6548\u7528\u4e0d\u8fde\u7eed\u6027\u800c\u4e0d\u5b58\u5728\uff0c\u9700\u8981\u5bfb\u627e\u65b0\u7684\u5747\u8861\u89e3\u6982\u5ff5", "method": "\u5c06\u5356\u5bb6-\u5e73\u53f0\u4e92\u52a8\u5efa\u6a21\u4e3aStackelberg\u535a\u5f08\uff0c\u8003\u8651\u4e24\u79cd\u5b9a\u4ef7\u6a21\u5f0f\uff08\u5e73\u53f0\u5b9a\u4ef7vs\u5356\u5bb6\u9884\u8bbe\u4ef7\u683c\uff09\uff0c\u5728\u6e10\u8fdb\u673a\u5236\u4e0b\u5206\u6790\u6781\u9650\u535a\u5f08\u7684\u5747\u8861\u7ed3\u6784", "result": "\u8bc1\u660e\u4e86\u5f53\u5356\u5bb6\u5b9e\u529b\u4e0d\u540c\u65f6\u6807\u51c6\u7eb3\u4ec0\u5747\u8861\u4e0d\u5b58\u5728\uff0c\u4f46\u5b58\u5728\u03bc-\u8fde\u63a5\u5747\u8861\u5faa\u73af(\u03bc-EC)\uff0c\u8fd9\u662f\u4e00\u79cd\u96c6\u5408\u503c\u89e3\u6982\u5ff5\uff0c\u6ee1\u8db3\u7a33\u5b9a\u6027\u3001\u65e0\u5916\u90e8\u94fe\u3001\u5185\u90e8\u4e0d\u7a33\u5b9a\u6027\u548c\u6700\u5c0f\u6027\u56db\u4e2a\u91cd\u8981\u6027\u8d28", "conclusion": "\u63d0\u51fa\u7684\u03bc-EC\u89e3\u6982\u5ff5\u80fd\u591f\u6355\u6349\u5747\u8861\u5904\u7684\u632f\u8361\u6027\u6218\u7565\u54cd\u5e94\uff0c\u89e3\u51b3\u4e86\u8fde\u7eed\u884c\u52a8\u7a7a\u95f4\u4e2d\u4f20\u7edf\u7eb3\u4ec0\u5747\u8861\u4e0d\u5b58\u5728\u7684\u96be\u9898\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u535a\u5f08\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6"}}
{"id": "2509.13578", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2509.13578", "abs": "https://arxiv.org/abs/2509.13578", "authors": ["Santiago Camara", "Jeanne Aublin"], "title": "In-between Transatlantic (Monetary) Disturbances", "comment": null, "summary": "This paper studies the spillovers of European Central Bank (ECB) interest\nrate shocks into the Canadian economy and compares them with those of the U.S.\nFederal Reserve (Fed). We combine a VAR model and local projection regressions\nwith identification strategies that explicitly purge information effects around\npolicy announcements. We find that an ECB rate hike leads to a depreciation of\nthe Canadian dollar and a sharp contraction in economic activity. The main\ntransmission channel is international trade: ECB shocks trigger a decline in\noil prices and exports, while leaving domestic financial conditions largely\nunaffected. By contrast, Fed shocks tighten Canadian financial conditions\nsignificantly, with more limited effects on trade flows. These findings show\nthat Canada is exposed to foreign monetary policy both directly and indirectly,\nthrough its integration in global financial and trade markets.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6b27\u6d32\u592e\u884c\u5229\u7387\u51b2\u51fb\u5bf9\u52a0\u62ff\u5927\u7ecf\u6d4e\u7684\u6ea2\u51fa\u6548\u5e94\uff0c\u5e76\u4e0e\u7f8e\u8054\u50a8\u51b2\u51fb\u8fdb\u884c\u6bd4\u8f83\uff0c\u53d1\u73b0ECB\u52a0\u606f\u5bfc\u81f4\u52a0\u5143\u8d2c\u503c\u548c\u7ecf\u6d4e\u6d3b\u52a8\u6536\u7f29\uff0c\u4e3b\u8981\u901a\u8fc7\u8d38\u6613\u6e20\u9053\u4f20\u5bfc\uff0c\u800cFed\u51b2\u51fb\u4e3b\u8981\u901a\u8fc7\u91d1\u878d\u6761\u4ef6\u6536\u7d27\u5f71\u54cd\u52a0\u62ff\u5927\u3002", "motivation": "\u7814\u7a76\u52a0\u62ff\u5927\u7ecf\u6d4e\u5982\u4f55\u53d7\u5230\u5916\u56fd\u8d27\u5e01\u653f\u7b56\u51b2\u51fb\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u6bd4\u8f83\u6b27\u6d32\u592e\u884c\u548c\u7f8e\u8054\u50a8\u5229\u7387\u653f\u7b56\u7684\u4e0d\u540c\u4f20\u5bfc\u673a\u5236\uff0c\u4ee5\u4e86\u89e3\u52a0\u62ff\u5927\u5728\u5168\u7403\u91d1\u878d\u548c\u8d38\u6613\u5e02\u573a\u4e2d\u7684\u8106\u5f31\u6027\u3002", "method": "\u7ed3\u5408VAR\u6a21\u578b\u548c\u5c40\u90e8\u6295\u5f71\u56de\u5f52\uff0c\u91c7\u7528\u8bc6\u522b\u7b56\u7565\u6765\u6d88\u9664\u653f\u7b56\u516c\u544a\u5468\u56f4\u7684\u4fe1\u606f\u6548\u5e94\uff0c\u5206\u6790ECB\u548cFed\u5229\u7387\u51b2\u51fb\u5bf9\u52a0\u62ff\u5927\u7ecf\u6d4e\u7684\u5f71\u54cd\u3002", "result": "ECB\u5229\u7387\u4e0a\u6da8\u5bfc\u81f4\u52a0\u5143\u8d2c\u503c\u548c\u7ecf\u6d4e\u6d3b\u52a8\u6025\u5267\u6536\u7f29\uff0c\u4e3b\u8981\u901a\u8fc7\u964d\u4f4e\u6cb9\u4ef7\u548c\u51fa\u53e3\u7684\u8d38\u6613\u6e20\u9053\u4f20\u5bfc\uff0c\u5bf9\u56fd\u5185\u91d1\u878d\u6761\u4ef6\u5f71\u54cd\u6709\u9650\uff1b\u800cFed\u51b2\u51fb\u663e\u8457\u6536\u7d27\u52a0\u62ff\u5927\u91d1\u878d\u6761\u4ef6\uff0c\u5bf9\u8d38\u6613\u6d41\u52a8\u5f71\u54cd\u8f83\u5c0f\u3002", "conclusion": "\u52a0\u62ff\u5927\u901a\u8fc7\u5168\u7403\u91d1\u878d\u548c\u8d38\u6613\u5e02\u573a\u7684\u4e00\u4f53\u5316\uff0c\u76f4\u63a5\u548c\u95f4\u63a5\u5730\u66b4\u9732\u4e8e\u5916\u56fd\u8d27\u5e01\u653f\u7b56\u51b2\u51fb\uff0cECB\u548cFed\u51b2\u51fb\u901a\u8fc7\u4e0d\u540c\u6e20\u9053\u5f71\u54cd\u52a0\u62ff\u5927\u7ecf\u6d4e\uff0c\u51f8\u663e\u4e86\u5176\u5bf9\u5916\u90e8\u51b2\u51fb\u7684\u8106\u5f31\u6027\u3002"}}
{"id": "2509.13337", "categories": ["cs.CY", "H.5.2; K.4.3; J.4"], "pdf": "https://arxiv.org/pdf/2509.13337", "abs": "https://arxiv.org/abs/2509.13337", "authors": ["Kalyani Khona"], "title": "Behind India's ChatGPT Conversations: A Retrospective Analysis of 238 Unedited User Prompts", "comment": "11 pages, 1 table. Behavioral analysis of authentic ChatGPT usage\n  patterns among English-speaking urban professionals in India using\n  retrospective prompt collection methodology", "summary": "Understanding how users authentically interact with Large Language Models\n(LLMs) remains a significant challenge in human-computer interaction research.\nMost existing studies rely on self-reported usage patterns or controlled\nexperimental conditions, potentially missing genuine behavioral adaptations.\nThis study presents a behavioral analysis of the use of English-speaking urban\nprofessional ChatGPT in India based on 238 authentic, unedited user prompts\nfrom 40 participants in 15+ Indian cities, collected using retrospective survey\nmethodology in August 2025. Using authentic retrospective prompt collection via\nanonymous social media survey to minimize real-time observer effects, we\nanalyzed genuine usage patterns. Key findings include: (1) 85\\% daily usage\nrate (34/40 users) indicating mature adoption beyond experimental use, (2)\nevidence of cross-domain integration spanning professional, personal, health\nand creative contexts among the majority of users, (3) 42.5\\% (17/40) primarily\nuse ChatGPT for professional workflows with evidence of real-time problem\nsolving integration, and (4) cultural context navigation strategies with users\nincorporating Indian cultural specifications in their prompts. Users develop\nsophisticated adaptation techniques and the formation of advisory relationships\nfor personal guidance. The study reveals the progression from experimental to\nessential workflow dependency, with users treating ChatGPT as an integrated\nlife assistant rather than a specialized tool. However, the findings are\nlimited to urban professionals in English recruited through social media\nnetworks and require a larger demographic validation. This work contributes a\nnovel methodology to capture authentic AI usage patterns and provides\nevidence-based insights into cultural adaptation strategies among this specific\ndemographic of users.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u56de\u987e\u6027\u8c03\u67e5\u65b9\u6cd5\u6536\u96c6\u4e8640\u540d\u5370\u5ea6\u57ce\u5e02\u4e13\u4e1a\u4eba\u58eb\u7684238\u4e2a\u771f\u5b9eChatGPT\u4f7f\u7528\u63d0\u793a\uff0c\u53d1\u73b085%\u7528\u6237\u6bcf\u65e5\u4f7f\u7528\uff0c\u591a\u6570\u7528\u6237\u5c06ChatGPT\u6574\u5408\u5230\u4e13\u4e1a\u3001\u4e2a\u4eba\u3001\u5065\u5eb7\u548c\u521b\u610f\u7b49\u591a\u4e2a\u9886\u57df\uff0c42.5%\u7528\u6237\u4e3b\u8981\u7528\u4e8e\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5e76\u5c55\u793a\u4e86\u6587\u5316\u9002\u5e94\u6027\u7b56\u7565\u3002", "motivation": "\u7406\u89e3\u7528\u6237\u5982\u4f55\u771f\u5b9e\u5730\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e92\u52a8\u662f\u91cd\u8981\u6311\u6218\uff0c\u73b0\u6709\u7814\u7a76\u591a\u4f9d\u8d56\u81ea\u6211\u62a5\u544a\u6216\u53d7\u63a7\u5b9e\u9a8c\uff0c\u53ef\u80fd\u9057\u6f0f\u771f\u5b9e\u7684\u884c\u4e3a\u9002\u5e94\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u56de\u987e\u6027\u8c03\u67e5\u65b9\u6cd5\uff0c\u901a\u8fc7\u533f\u540d\u793e\u4ea4\u5a92\u4f53\u8c03\u67e5\u6536\u96c62025\u5e748\u6708\u671f\u95f440\u540d\u53c2\u4e0e\u8005\u7684238\u4e2a\u672a\u7ecf\u7f16\u8f91\u7684\u771f\u5b9e\u7528\u6237\u63d0\u793a\uff0c\u8986\u76d615+\u5370\u5ea6\u57ce\u5e02\uff0c\u4ee5\u6700\u5c0f\u5316\u5b9e\u65f6\u89c2\u5bdf\u8005\u6548\u5e94\u3002", "result": "\u53d1\u73b085%\u7528\u6237\u6bcf\u65e5\u4f7f\u7528ChatGPT\uff0c\u591a\u6570\u7528\u6237\u5b9e\u73b0\u8de8\u9886\u57df\u6574\u5408\uff0c42.5%\u7528\u6237\u4e3b\u8981\u7528\u4e8e\u4e13\u4e1a\u5de5\u4f5c\u6d41\u7a0b\uff0c\u7528\u6237\u53d1\u5c55\u51fa\u590d\u6742\u7684\u9002\u5e94\u6280\u5de7\u5e76\u5c06ChatGPT\u89c6\u4e3a\u7efc\u5408\u751f\u6d3b\u52a9\u624b\u800c\u975e\u4e13\u4e1a\u5de5\u5177\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86\u4ece\u5b9e\u9a8c\u6027\u4f7f\u7528\u5230\u5de5\u4f5c\u6d41\u7a0b\u4f9d\u8d56\u7684\u8fdb\u5c55\uff0c\u63d0\u4f9b\u4e86\u6355\u6349\u771f\u5b9eAI\u4f7f\u7528\u6a21\u5f0f\u7684\u65b0\u65b9\u6cd5\uff0c\u4f46\u6837\u672c\u9650\u4e8e\u901a\u8fc7\u793e\u4ea4\u5a92\u4f53\u62db\u52df\u7684\u82f1\u8bed\u57ce\u5e02\u4e13\u4e1a\u4eba\u58eb\uff0c\u9700\u8981\u66f4\u5927\u89c4\u6a21\u7684\u4eba\u53e3\u9a8c\u8bc1\u3002"}}
{"id": "2509.13330", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.13330", "abs": "https://arxiv.org/abs/2509.13330", "authors": ["Jorge Vicente-Martinez", "Edgar Ramirez-Laboreo"], "title": "A hybrid dynamic model and parameter estimation method for accurately simulating overhead cranes with friction", "comment": "11 pages, 13 figures", "summary": "This paper presents a new approach to accurately simulating 3D overhead\ncranes with friction. Nonlinear friction dynamics have a significant impact on\nthese systems, however, accurately modeling this phenomenon in simulations is a\nsignificant challenge. Traditional methods often rely on imprecise\napproximations of friction or require excessive computational times for\nreliable results. To address this, we present a hybrid dynamical model that\nfeatures a trade-off between high-fidelity friction modeling and computational\nefficiency. Furthermore, we present a step-by-step algorithm for the\ncomprehensive estimation of all unknown system parameters, including friction.\nThis methodology is based on Gaussian Process Regression (GPR) and Least\nSquares (LS) estimations. Finally, experimental validation with a laboratory\ncrane confirms the effectiveness of the proposed modeling and estimation\napproach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u548c\u6700\u5c0f\u4e8c\u4e58\u6cd5\u7684\u6df7\u5408\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u7528\u4e8e\u7cbe\u786e\u6a21\u62df3D\u6865\u5f0f\u8d77\u91cd\u673a\u7684\u6469\u64e6\u52a8\u529b\u5b66\uff0c\u5728\u4fdd\u8bc1\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u6469\u64e6\u5efa\u6a21\u3002", "motivation": "\u975e\u7ebf\u6027\u6469\u64e6\u52a8\u529b\u5b66\u5bf93D\u6865\u5f0f\u8d77\u91cd\u673a\u7cfb\u7edf\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u8981\u4e48\u4f7f\u7528\u4e0d\u7cbe\u786e\u7684\u6469\u64e6\u8fd1\u4f3c\uff0c\u8981\u4e48\u9700\u8981\u8fc7\u957f\u7684\u8ba1\u7b97\u65f6\u95f4\uff0c\u96be\u4ee5\u5b9e\u73b0\u51c6\u786e\u6a21\u62df\u3002", "method": "\u91c7\u7528\u6df7\u5408\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u7ed3\u5408\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52(GPR)\u548c\u6700\u5c0f\u4e8c\u4e58\u6cd5(LS)\u8fdb\u884c\u7cfb\u7edf\u53c2\u6570\u4f30\u8ba1\uff0c\u5305\u62ec\u6469\u64e6\u53c2\u6570\u7684\u9010\u6b65\u4f30\u8ba1\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u5ba4\u8d77\u91cd\u673a\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u5efa\u6a21\u548c\u4f30\u8ba1\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6469\u64e6\u5efa\u6a21\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u4e3a3D\u8d77\u91cd\u673a\u7cfb\u7edf\u7684\u7cbe\u786e\u6a21\u62df\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13886", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2509.13886", "abs": "https://arxiv.org/abs/2509.13886", "authors": ["Marco F. De Sanctis", "Andrea Gilardi", "Giacomo Milan", "Laura M. Sangalli", "Francesca Ieva", "Piercesare Secchi"], "title": "Three Distributional Approaches for PM10 Assessment in Northern Italy", "comment": null, "summary": "We propose three spatial methods for estimating the full probability\ndistribution of PM10 concentrations, with the ultimate goal of assessing air\nquality in Northern Italy. Moving beyond spatial averages and simple\nindicators, we adopt a distributional perspective to capture the complex\nvariability of pollutant concentrations across space. The first proposed\napproach predicts class-based compositions via Fixed Rank Kriging; the second\nestimates multiple, non-crossing quantiles through a spatial regression with\ndifferential regularization; the third directly reconstructs full probability\ndensities leveraging on both Fixed Rank Kriging and multiple quantiles spatial\nregression within a Simplicial Principal Component Analysis framework. These\napproaches are applied to daily PM10 measurements, collected from 2018 to 2022\nin Northern Italy, to estimate spatially continuous distributions and to\nidentify regions at risk of regulatory exceedance. The three approaches exhibit\nlocalized differences, revealing how modeling assumptions may influence the\nprediction of fine-scale pollutant concentration patterns. Nevertheless, they\nconsistently agree on the broader spatial patterns of pollution. This general\nagreement supports the robustness of a distributional approach, which offers a\ncomprehensive and policy-relevant framework for assessing air quality and\nregulatory exceedance risks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e09\u79cd\u7a7a\u95f4\u65b9\u6cd5\u6765\u4f30\u8ba1PM10\u6d53\u5ea6\u7684\u5b8c\u6574\u6982\u7387\u5206\u5e03\uff0c\u7528\u4e8e\u8bc4\u4f30\u610f\u5927\u5229\u5317\u90e8\u7684\u7a7a\u6c14\u8d28\u91cf\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u7a7a\u95f4\u5e73\u5747\u503c\u548c\u7b80\u5355\u6307\u6807\uff0c\u91c7\u7528\u5206\u5e03\u89c6\u89d2\u6355\u6349\u6c61\u67d3\u7269\u6d53\u5ea6\u7684\u590d\u6742\u7a7a\u95f4\u53d8\u5f02\u6027\u3002", "motivation": "\u4f20\u7edf\u7a7a\u6c14\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u7a7a\u95f4\u5e73\u5747\u503c\u548c\u7b80\u5355\u6307\u6807\uff0c\u65e0\u6cd5\u5145\u5206\u6355\u6349\u6c61\u67d3\u7269\u6d53\u5ea6\u7684\u590d\u6742\u7a7a\u95f4\u53d8\u5f02\u6027\u3002\u4e3a\u4e86\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u7a7a\u6c14\u8d28\u91cf\u548c\u76d1\u7ba1\u8d85\u6807\u98ce\u9669\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4f30\u8ba1\u5b8c\u6574\u6982\u7387\u5206\u5e03\u7684\u7a7a\u95f4\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u65b9\u6cd5\uff1a1\uff09\u901a\u8fc7\u56fa\u5b9a\u79e9\u514b\u91cc\u91d1\u6cd5\u9884\u6d4b\u57fa\u4e8e\u7c7b\u522b\u7684\u7ec4\u6210\uff1b2\uff09\u901a\u8fc7\u5177\u6709\u5fae\u5206\u6b63\u5219\u5316\u7684\u7a7a\u95f4\u56de\u5f52\u4f30\u8ba1\u591a\u4e2a\u4e0d\u4ea4\u53c9\u7684\u5206\u4f4d\u6570\uff1b3\uff09\u5728\u5355\u7eaf\u5f62\u4e3b\u6210\u5206\u5206\u6790\u6846\u67b6\u5185\uff0c\u7ed3\u5408\u56fa\u5b9a\u79e9\u514b\u91cc\u91d1\u6cd5\u548c\u591a\u5206\u4f4d\u6570\u7a7a\u95f4\u56de\u5f52\u76f4\u63a5\u91cd\u5efa\u5b8c\u6574\u6982\u7387\u5bc6\u5ea6\u3002", "result": "\u4e09\u79cd\u65b9\u6cd5\u5e94\u7528\u4e8e2018-2022\u5e74\u610f\u5927\u5229\u5317\u90e8\u7684\u6bcf\u65e5PM10\u6d4b\u91cf\u6570\u636e\uff0c\u80fd\u591f\u4f30\u8ba1\u7a7a\u95f4\u8fde\u7eed\u5206\u5e03\u5e76\u8bc6\u522b\u6709\u76d1\u7ba1\u8d85\u6807\u98ce\u9669\u7684\u533a\u57df\u3002\u65b9\u6cd5\u95f4\u5b58\u5728\u5c40\u90e8\u5dee\u5f02\uff0c\u4f46\u5728\u66f4\u5e7f\u6cdb\u7684\u7a7a\u95f4\u6c61\u67d3\u6a21\u5f0f\u4e0a\u8868\u73b0\u4e00\u81f4\u3002", "conclusion": "\u5206\u5e03\u6027\u65b9\u6cd5\u4e3a\u8bc4\u4f30\u7a7a\u6c14\u8d28\u91cf\u548c\u76d1\u7ba1\u8d85\u6807\u98ce\u9669\u63d0\u4f9b\u4e86\u5168\u9762\u4e14\u4e0e\u653f\u7b56\u76f8\u5173\u7684\u6846\u67b6\uff0c\u4e09\u79cd\u65b9\u6cd5\u7684\u4e00\u81f4\u6027\u652f\u6301\u4e86\u8be5\u65b9\u6cd5\u7684\u7a33\u5065\u6027\uff0c\u5c3d\u7ba1\u5efa\u6a21\u5047\u8bbe\u4f1a\u5f71\u54cd\u7ec6\u5c3a\u5ea6\u6c61\u67d3\u7269\u6d53\u5ea6\u6a21\u5f0f\u7684\u9884\u6d4b\u3002"}}
{"id": "2509.13492", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2509.13492", "abs": "https://arxiv.org/abs/2509.13492", "authors": ["Aryan Manafi Neyazi"], "title": "Generalized Covariance Estimator under Misspecification and Constraints", "comment": null, "summary": "This paper investigates the properties of the Generalized Covariance (GCov)\nestimator under misspecification and constraints with application to processes\nwith local explosive patterns, such as causal-noncausal and double\nautoregressive (DAR) processes. We show that GCov is consistent and has an\nasymptotically Normal distribution under misspecification. Then, we construct\nGCov-based Wald-type and score-type tests to test one specification against the\nother, all of which follow a $\\chi^2$ distribution. Furthermore, we propose the\nconstrained GCov (CGCov) estimator, which extends the use of the GCov estimator\nto a broader range of models with constraints on their parameters. We\ninvestigate the asymptotic distribution of the CGCov estimator when the true\nparameters are far from the boundary and on the boundary of the parameter\nspace. We validate the finite sample performance of the proposed estimators and\ntests in the context of causal-noncausal and DAR models. Finally, we provide\ntwo empirical applications by applying the noncausal model to the final energy\ndemand commodity index and also the DAR model to the US 3-month treasury bill.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e7f\u4e49\u534f\u65b9\u5dee(GCov)\u4f30\u8ba1\u5668\u5728\u9519\u8bef\u8bbe\u5b9a\u548c\u7ea6\u675f\u6761\u4ef6\u4e0b\u7684\u6027\u8d28\uff0c\u5e94\u7528\u4e8e\u5177\u6709\u5c40\u90e8\u7206\u70b8\u6a21\u5f0f\u7684\u8fc7\u7a0b\uff0c\u5982\u56e0\u679c-\u975e\u56e0\u679c\u548c\u53cc\u81ea\u56de\u5f52(DAR)\u8fc7\u7a0b\u3002\u8bc1\u660e\u4e86GCov\u5728\u9519\u8bef\u8bbe\u5b9a\u4e0b\u7684\u4e00\u81f4\u6027\u548c\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u6784\u5efa\u4e86\u57fa\u4e8eGCov\u7684Wald\u578b\u548c\u5f97\u5206\u578b\u68c0\u9a8c\uff0c\u5e76\u63d0\u51fa\u4e86\u7ea6\u675fGCov(CGCov)\u4f30\u8ba1\u5668\u6269\u5c55\u5e94\u7528\u8303\u56f4\u3002", "motivation": "\u7814\u7a76GCov\u4f30\u8ba1\u5668\u5728\u6a21\u578b\u9519\u8bef\u8bbe\u5b9a\u548c\u53c2\u6570\u7ea6\u675f\u6761\u4ef6\u4e0b\u7684\u7edf\u8ba1\u6027\u8d28\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5177\u6709\u5c40\u90e8\u7206\u70b8\u7279\u5f81\u7684\u65f6\u95f4\u5e8f\u5217\u8fc7\u7a0b\u65f6\uff0c\u9700\u8981\u5f00\u53d1\u53ef\u9760\u7684\u4f30\u8ba1\u548c\u68c0\u9a8c\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u7ea6\u675fGCov(CGCov)\u4f30\u8ba1\u5668\uff0c\u6784\u5efa\u4e86\u57fa\u4e8eGCov\u7684Wald\u578b\u548c\u5f97\u5206\u578b\u68c0\u9a8c\u7edf\u8ba1\u91cf\uff0c\u7814\u7a76\u4e86\u53c2\u6570\u5728\u8fb9\u754c\u548c\u8fdc\u79bb\u8fb9\u754c\u65f6\u7684\u6e10\u8fd1\u5206\u5e03\u6027\u8d28\u3002", "result": "GCov\u5728\u9519\u8bef\u8bbe\u5b9a\u4e0b\u4fdd\u6301\u4e00\u81f4\u6027\u4e14\u5177\u6709\u6e10\u8fd1\u6b63\u6001\u5206\u5e03\uff0c\u6240\u6709\u68c0\u9a8c\u7edf\u8ba1\u91cf\u90fd\u670d\u4ece\u03c7\u00b2\u5206\u5e03\u3002\u901a\u8fc7\u56e0\u679c-\u975e\u56e0\u679c\u548cDAR\u6a21\u578b\u7684\u6a21\u62df\u9a8c\u8bc1\u4e86\u6709\u9650\u6837\u672c\u6027\u80fd\u3002", "conclusion": "GCov\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u5177\u6709\u5c40\u90e8\u7206\u70b8\u6a21\u5f0f\u7684\u8fc7\u7a0b\uff0cCGCov\u6269\u5c55\u4e86\u5e94\u7528\u8303\u56f4\uff0c\u5b9e\u8bc1\u5206\u6790\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u80fd\u6e90\u9700\u6c42\u5546\u54c1\u6307\u6570\u548c\u7f8e\u56fd\u56fd\u503a\u5229\u7387\u5efa\u6a21\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2509.13560", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2509.13560", "abs": "https://arxiv.org/abs/2509.13560", "authors": ["Wenxiao Cai", "Zongru Li", "Yu-Neng Wang", "Sara Achour", "Thomas H. Lee"], "title": "Oscillator Formulations of Many NP Problems", "comment": null, "summary": "Efficiently optimizing Nondeterministic Polynomial time (NP) problems in\npolynomial time has profound implications in many domains. CMOS oscillator\nnetworks have been shown to be effective and efficient in approximating certain\nNP-hard problems such as minimization of Potts Hamiltonian, and computational\ncomplexity theory guarantees that any NP problem can be reduced to it. In this\npaper, we formulate a variety of NP problems using first-order and multi-phase\nPotts Hamiltonian. We also propose a 3-state asymmetrically weighted oscillator\noptimizer design to optimize the problems. Building on existing knowledge in\nCMOS design, our proposed algorithms offer a promising pathway for large-scale\noptimization of NP problems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCMOS\u632f\u8361\u5668\u7f51\u7edc\u7684NP\u95ee\u9898\u4f18\u5316\u65b9\u6cd5\uff0c\u4f7f\u75283\u6001\u975e\u5bf9\u79f0\u52a0\u6743\u632f\u8361\u5668\u4f18\u5316\u5668\u8bbe\u8ba1\u6765\u89e3\u51b3\u4e00\u9636\u548c\u591a\u76f8Potts\u54c8\u5bc6\u987f\u91cf\u6700\u5c0f\u5316\u95ee\u9898\u3002", "motivation": "NP\u95ee\u9898\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u7684\u9ad8\u6548\u4f18\u5316\u5bf9\u591a\u4e2a\u9886\u57df\u6709\u6df1\u8fdc\u5f71\u54cd\uff0cCMOS\u632f\u8361\u5668\u7f51\u7edc\u5df2\u88ab\u8bc1\u660e\u80fd\u6709\u6548\u8fd1\u4f3c\u67d0\u4e9bNP\u96be\u95ee\u9898\uff0c\u5982Potts\u54c8\u5bc6\u987f\u91cf\u6700\u5c0f\u5316\u3002", "method": "\u4f7f\u7528\u4e00\u9636\u548c\u591a\u76f8Potts\u54c8\u5bc6\u987f\u91cf\u6765\u5f62\u5f0f\u5316\u5404\u79cdNP\u95ee\u9898\uff0c\u5e76\u63d0\u51fa3\u6001\u975e\u5bf9\u79f0\u52a0\u6743\u632f\u8361\u5668\u4f18\u5316\u5668\u8bbe\u8ba1\u6765\u4f18\u5316\u8fd9\u4e9b\u95ee\u9898\u3002", "result": "\u57fa\u4e8e\u73b0\u6709CMOS\u8bbe\u8ba1\u77e5\u8bc6\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u4e3a\u5927\u89c4\u6a21NP\u95ee\u9898\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u524d\u666f\u7684\u9014\u5f84\u3002", "conclusion": "CMOS\u632f\u8361\u5668\u7f51\u7edc\u65b9\u6cd5\u4e3aNP\u95ee\u9898\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u786c\u4ef6\u5b9e\u73b0\u65b9\u6848\uff0c\u5177\u6709\u5927\u89c4\u6a21\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.13336", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13336", "abs": "https://arxiv.org/abs/2509.13336", "authors": ["Mehran Behjati", "Rosdiadee Nordin", "Nor Fadzilah Abdullah"], "title": "Maximizing UAV Cellular Connectivity with Reinforcement Learning for BVLoS Path Planning", "comment": "Submitted to an IEEE Conference", "summary": "This paper presents a reinforcement learning (RL) based approach for path\nplanning of cellular connected unmanned aerial vehicles (UAVs) operating beyond\nvisual line of sight (BVLoS). The objective is to minimize travel distance\nwhile maximizing the quality of cellular link connectivity by considering real\nworld aerial coverage constraints and employing an empirical aerial channel\nmodel. The proposed solution employs RL techniques to train an agent, using the\nquality of communication links between the UAV and base stations (BSs) as the\nreward function. Simulation results demonstrate the effectiveness of the\nproposed method in training the agent and generating feasible UAV path plans.\nThe proposed approach addresses the challenges due to limitations in UAV\ncellular communications, highlighting the need for investigations and\nconsiderations in this area. The RL algorithm efficiently identifies optimal\npaths, ensuring maximum connectivity with ground BSs to ensure safe and\nreliable BVLoS flight operation. Moreover, the solution can be deployed as an\noffline path planning module that can be integrated into future ground control\nsystems (GCS) for UAV operations, enhancing their capabilities and safety. The\nmethod holds potential for complex long range UAV applications, advancing the\ntechnology in the field of cellular connected UAV path planning.", "AI": {"tldr": "\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65e0\u4eba\u673a\u8d85\u89c6\u8ddd\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5927\u5316\u8702\u7a9d\u94fe\u8def\u8d28\u91cf\u6765\u4f18\u5316\u98de\u884c\u8def\u5f84\uff0c\u786e\u4fdd\u5b89\u5168\u53ef\u9760\u7684\u901a\u4fe1\u8fde\u63a5", "motivation": "\u89e3\u51b3\u65e0\u4eba\u673a\u5728\u8d85\u89c6\u8ddd\u98de\u884c\u4e2d\u7684\u8702\u7a9d\u901a\u4fe1\u9650\u5236\u95ee\u9898\uff0c\u9700\u8981\u4f18\u5316\u8def\u5f84\u89c4\u5212\u6765\u4fdd\u8bc1\u4e0e\u5730\u9762\u57fa\u7ad9\u7684\u6301\u7eed\u53ef\u9760\u8fde\u63a5", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u8bad\u7ec3\u667a\u80fd\u4f53\uff0c\u4f7f\u7528\u65e0\u4eba\u673a\u4e0e\u57fa\u7ad9\u4e4b\u95f4\u7684\u901a\u4fe1\u94fe\u8def\u8d28\u91cf\u4f5c\u4e3a\u5956\u52b1\u51fd\u6570\uff0c\u7ed3\u5408\u771f\u5b9e\u4e16\u754c\u7a7a\u4e2d\u8986\u76d6\u7ea6\u675f\u548c\u7ecf\u9a8c\u7a7a\u4e2d\u4fe1\u9053\u6a21\u578b", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u8bad\u7ec3\u667a\u80fd\u4f53\u5e76\u751f\u6210\u53ef\u884c\u7684\u65e0\u4eba\u673a\u8def\u5f84\u89c4\u5212\uff0c\u80fd\u591f\u9ad8\u6548\u8bc6\u522b\u6700\u4f18\u8def\u5f84\u786e\u4fdd\u6700\u5927\u8fde\u63a5\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4f5c\u4e3a\u79bb\u7ebf\u8def\u5f84\u89c4\u5212\u6a21\u5757\u96c6\u6210\u5230\u672a\u6765\u5730\u9762\u63a7\u5236\u7cfb\u7edf\u4e2d\uff0c\u5728\u590d\u6742\u957f\u8ddd\u79bb\u65e0\u4eba\u673a\u5e94\u7528\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u63a8\u52a8\u4e86\u8702\u7a9d\u8fde\u63a5\u65e0\u4eba\u673a\u8def\u5f84\u89c4\u5212\u6280\u672f\u7684\u53d1\u5c55"}}
{"id": "2509.13332", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13332", "abs": "https://arxiv.org/abs/2509.13332", "authors": ["Pratik Jayarao", "Himanshu Gupta", "Neeraj Varshney", "Chaitanya Dwivedi"], "title": "Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly adopted as automated judges\nin benchmarking and reward modeling, ensuring their reliability, efficiency,\nand robustness has become critical. In this work, we present a systematic\ncomparison of \"thinking\" and \"non-thinking\" LLMs in the LLM-as-a-judge paradigm\nusing open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B\nparameters). We evaluate both accuracy and computational efficiency (FLOPs) on\nRewardBench tasks, and further examine augmentation strategies for non-thinking\nmodels, including in-context learning, rubric-guided judging, reference-based\nevaluation, and n-best aggregation. Our results show that despite these\nenhancements, non-thinking models generally fall short of their thinking\ncounterparts. Our results show that thinking models achieve approximately 10%\npoints higher accuracy with little overhead (under 2x), in contrast to\naugmentation strategies like few-shot learning, which deliver modest gains at a\nhigher cost (>8x). Bias and robustness analyses further demonstrate that\nthinking models maintain significantly greater consistency under a variety of\nbias conditions such as positional, bandwagon, identity, diversity, and random\nbiases (6% higher on average). We further extend our experiments to the\nmultilingual setting and our results confirm that explicit reasoning extends\nits benefits beyond English. Overall, our work results in several important\nfindings that provide systematic evidence that explicit reasoning offers clear\nadvantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency\nbut also in robustness.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u6bd4\u8f83\u4e86\u5728LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u8303\u5f0f\u4e0b\uff0c\"\u601d\u8003\"\u4e0e\"\u975e\u601d\u8003\"\u5f00\u6e90Qwen 3\u6a21\u578b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u601d\u8003\u6a21\u578b\u5728\u51c6\u786e\u6027\u3001\u8ba1\u7b97\u6548\u7387\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u975e\u601d\u8003\u6a21\u578b\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4f5c\u81ea\u52a8\u8bc4\u5224\u5de5\u5177\uff0c\u786e\u4fdd\u5176\u53ef\u9760\u6027\u3001\u6548\u7387\u548c\u9c81\u68d2\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u6bd4\u8f83\u601d\u8003\u4e0e\u975e\u601d\u8003\u6a21\u578b\u5728LLM-as-a-judge\u8303\u5f0f\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\u3002", "method": "\u4f7f\u7528\u5f00\u6e90Qwen 3\u6a21\u578b\uff080.6B\u30011.7B\u548c4B\u53c2\u6570\uff09\uff0c\u5728RewardBench\u4efb\u52a1\u4e0a\u8bc4\u4f30\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff08FLOPs\uff09\uff0c\u5e76\u6d4b\u8bd5\u4e86\u591a\u79cd\u589e\u5f3a\u7b56\u7565\u5305\u62ec\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u89c4\u5219\u5f15\u5bfc\u8bc4\u5224\u3001\u57fa\u4e8e\u53c2\u8003\u7684\u8bc4\u4f30\u548cn-best\u805a\u5408\u3002", "result": "\u601d\u8003\u6a21\u578b\u6bd4\u975e\u601d\u8003\u6a21\u578b\u51c6\u786e\u7387\u9ad8\u51fa\u7ea610\u4e2a\u767e\u5206\u70b9\uff0c\u8ba1\u7b97\u5f00\u9500\u4ec5\u589e\u52a0\u4e0d\u52302\u500d\uff0c\u800c\u5c11\u6837\u672c\u5b66\u4e60\u7b49\u589e\u5f3a\u7b56\u7565\u867d\u7136\u5e26\u6765\u9002\u5ea6\u63d0\u5347\u4f46\u6210\u672c\u66f4\u9ad8\uff08>8\u500d\uff09\u3002\u601d\u8003\u6a21\u578b\u5728\u5404\u79cd\u504f\u89c1\u6761\u4ef6\u4e0b\u4e5f\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff08\u5e73\u5747\u9ad86%\uff09\u3002", "conclusion": "\u663e\u5f0f\u63a8\u7406\u5728LLM-as-a-judge\u8303\u5f0f\u4e2d\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u4e0d\u4ec5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\uff0c\u5728\u9c81\u68d2\u6027\u65b9\u9762\u4e5f\u8868\u73b0\u66f4\u4f73\uff0c\u8fd9\u4e00\u4f18\u52bf\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u540c\u6837\u9002\u7528\u3002"}}
{"id": "2509.13623", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2509.13623", "abs": "https://arxiv.org/abs/2509.13623", "authors": ["Marlon Azinovic-Yang", "Jan \u017demli\u010dka"], "title": "Deep Learning in the Sequence Space", "comment": null, "summary": "We develop a deep learning algorithm for approximating functional rational\nexpectations equilibria of dynamic stochastic economies in the sequence space.\nWe use deep neural networks to parameterize equilibrium objects of the economy\nas a function of truncated histories of exogenous shocks. We train the neural\nnetworks to fulfill all equilibrium conditions along simulated paths of the\neconomy. To illustrate the performance of our method, we solve three economies\nof increasing complexity: the stochastic growth model, a high-dimensional\noverlapping generations economy with multiple sources of aggregate risk, and\nfinally an economy where households and firms face uninsurable idiosyncratic\nrisk, shocks to aggregate productivity, and shocks to idiosyncratic and\naggregate volatility. Furthermore, we show how to design practical neural\npolicy function architectures that guarantee monotonicity of the predicted\npolicies, facilitating the use of the endogenous grid method to simplify parts\nof our algorithm.", "AI": {"tldr": "\u5f00\u53d1\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u6c42\u89e3\u52a8\u6001\u968f\u673a\u7ecf\u6d4e\u4e2d\u7684\u51fd\u6570\u7406\u6027\u9884\u671f\u5747\u8861\uff0c\u4f7f\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\u5747\u8861\u5bf9\u8c61\uff0c\u901a\u8fc7\u6a21\u62df\u8def\u5f84\u8bad\u7ec3\u7f51\u7edc\u6ee1\u8db3\u6240\u6709\u5747\u8861\u6761\u4ef6", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u9ad8\u7ef4\u5ea6\u548c\u590d\u6742\u7ecf\u6d4e\u6a21\u578b\u4e2d\u7684\u7406\u6027\u9884\u671f\u5747\u8861\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u8ba1\u7b97\u65b9\u6cd5\u6765\u6c42\u89e3\u5305\u542b\u591a\u79cd\u98ce\u9669\u6e90\u548c\u5f02\u8d28\u6027\u4e3b\u4f53\u7684\u7ecf\u6d4e\u6a21\u578b", "method": "\u4f7f\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\u7ecf\u6d4e\u5747\u8861\u5bf9\u8c61\u4f5c\u4e3a\u5916\u751f\u51b2\u51fb\u622a\u65ad\u5386\u53f2\u7684\u51fd\u6570\uff0c\u901a\u8fc7\u6a21\u62df\u7ecf\u6d4e\u8def\u5f84\u8bad\u7ec3\u7f51\u7edc\u6ee1\u8db3\u6240\u6709\u5747\u8861\u6761\u4ef6\uff0c\u8bbe\u8ba1\u4fdd\u8bc1\u653f\u7b56\u51fd\u6570\u5355\u8c03\u6027\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784", "result": "\u6210\u529f\u6c42\u89e3\u4e86\u4e09\u4e2a\u590d\u6742\u5ea6\u9012\u589e\u7684\u7ecf\u6d4e\u6a21\u578b\uff1a\u968f\u673a\u589e\u957f\u6a21\u578b\u3001\u9ad8\u7ef4\u5ea6\u4ee3\u9645\u4ea4\u53e0\u7ecf\u6d4e\u3001\u5305\u542b\u5f02\u8d28\u6027\u98ce\u9669\u548c\u591a\u79cd\u6ce2\u52a8\u6027\u51b2\u51fb\u7684\u7ecf\u6d4e\uff0c\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e3a\u6c42\u89e3\u590d\u6742\u52a8\u6001\u968f\u673a\u7ecf\u6d4e\u7684\u7406\u6027\u9884\u671f\u5747\u8861\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u80fd\u591f\u5904\u7406\u9ad8\u7ef4\u5ea6\u548c\u591a\u79cd\u98ce\u9669\u6e90\u7684\u7ecf\u6d4e\u6a21\u578b"}}
{"id": "2509.13340", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2509.13340", "abs": "https://arxiv.org/abs/2509.13340", "authors": ["Isabel Pedersen", "Ann Hill Duin"], "title": "Defining a classification system for augmentation technology in socio-technical terms", "comment": "4 pages, accepted version for 2021 IEEE International Symposium on\n  Technology and Society (ISTAS)", "summary": "This short paper provides a means to classify augmentation technologies to\nreconceptualize them as sociotechnical, discursive and rhetorical phenomena,\nrather than only through technological classifications. It identifies a set of\nvalue systems that constitute augmentation technologies within discourses,\nnamely, the intent to enhance, automate, and build efficiency. This short paper\nmakes a contribution to digital literacy surrounding augmentation technology\nemergence, as well as the more specific area of AI literacy, which can help\nidentify unintended consequences implied at the design stages of these\ntechnologies.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06\u589e\u5f3a\u6280\u672f\u91cd\u65b0\u6982\u5ff5\u5316\u4e3a\u793e\u4f1a\u6280\u672f\u3001\u8bdd\u8bed\u548c\u4fee\u8f9e\u73b0\u8c61\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u800c\u975e\u4ec5\u4ece\u6280\u672f\u89d2\u5ea6\u5206\u7c7b", "motivation": "\u73b0\u6709\u5bf9\u589e\u5f3a\u6280\u672f\u7684\u5206\u7c7b\u4e3b\u8981\u57fa\u4e8e\u6280\u672f\u7279\u5f81\uff0c\u7f3a\u4e4f\u5bf9\u5176\u793e\u4f1a\u3001\u8bdd\u8bed\u548c\u4fee\u8f9e\u5c42\u9762\u7684\u5206\u6790\uff0c\u9700\u8981\u65b0\u7684\u5206\u7c7b\u65b9\u6cd5\u6765\u7406\u89e3\u8fd9\u4e9b\u6280\u672f\u7684\u793e\u4f1a\u5f71\u54cd\u548c\u6f5c\u5728\u540e\u679c", "method": "\u901a\u8fc7\u8bc6\u522b\u6784\u6210\u589e\u5f3a\u6280\u672f\u8bdd\u8bed\u7684\u4ef7\u503c\u4f53\u7cfb\uff08\u589e\u5f3a\u3001\u81ea\u52a8\u5316\u548c\u6784\u5efa\u6548\u7387\uff09\u6765\u5efa\u7acb\u5206\u7c7b\u6846\u67b6\uff0c\u5c06\u5176\u91cd\u65b0\u6982\u5ff5\u5316\u4e3a\u793e\u4f1a\u6280\u672f\u73b0\u8c61", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4ef7\u503c\u7cfb\u7edf\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u80fd\u591f\u5e2e\u52a9\u8bc6\u522b\u589e\u5f3a\u6280\u672f\u5728\u8bbe\u8ba1\u9636\u6bb5\u53ef\u80fd\u5e26\u6765\u7684\u975e\u9884\u671f\u540e\u679c", "conclusion": "\u8be5\u5206\u7c7b\u6846\u67b6\u6709\u52a9\u4e8e\u63d0\u5347\u6570\u5b57\u7d20\u517b\u548cAI\u7d20\u517b\uff0c\u4e3a\u7406\u89e3\u589e\u5f3a\u6280\u672f\u7684\u793e\u4f1a\u5f71\u54cd\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u89c6\u89d2\uff0c\u6709\u52a9\u4e8e\u5728\u8bbe\u8ba1\u9636\u6bb5\u9884\u89c1\u548c\u5e94\u5bf9\u6f5c\u5728\u95ee\u9898"}}
{"id": "2509.13369", "categories": ["eess.SY", "cs.CY", "cs.HC", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.13369", "abs": "https://arxiv.org/abs/2509.13369", "authors": ["Rashid Mushkani"], "title": "Right-to-Override for Critical Urban Control Systems: A Deliberative Audit Method for Buildings, Power, and Transport", "comment": null, "summary": "Automation now steers building HVAC, distribution grids, and traffic signals,\nyet residents rarely have authority to pause or redirect these systems when\nthey harm inclusivity, safety, or accessibility. We formalize a\nRight-to-Override (R2O) - defining override authorities, evidentiary\nthresholds, and domain-validated safe fallback states - and introduce a\nDeliberative Audit Method (DAM) with playbooks for pre-deployment walkthroughs,\nshadow-mode trials, and post-incident review. We instantiate R2O/DAM in\nsimulations of smart-grid load shedding, building HVAC under occupancy\nuncertainty, and multi-agent traffic signals. R2O reduces distributional harm\nwith limited efficiency loss: load-shedding disparity in unserved energy drops\nfrom 5.61x to 0.69x with constant curtailment; an override eliminates two\ndiscomfort-hours for seniors at an energy cost of 77 kWh; and median pedestrian\nwait falls from 90.4 s to 55.9 s with a 6.0 s increase in mean vehicle delay.\nWe also contribute a policy standard, audit worksheets, and a ModelOps\nintegration pattern to make urban automation contestable and reviewable.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Right-to-Override\uff08R2O\uff09\u6846\u67b6\u548cDeliberative Audit Method\uff08DAM\uff09\u65b9\u6cd5\uff0c\u8ba9\u5c45\u6c11\u80fd\u591f\u5728\u81ea\u52a8\u5316\u7cfb\u7edf\u635f\u5bb3\u5305\u5bb9\u6027\u3001\u5b89\u5168\u6027\u6216\u53ef\u8bbf\u95ee\u6027\u65f6\u6682\u505c\u6216\u91cd\u5b9a\u5411\u8fd9\u4e9b\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u5316\u7cfb\u7edf\uff08\u5982\u5efa\u7b51HVAC\u3001\u7535\u7f51\u3001\u4ea4\u901a\u4fe1\u53f7\uff09\u867d\u7136\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5c45\u6c11\u5728\u8fd9\u4e9b\u7cfb\u7edf\u9020\u6210\u4f24\u5bb3\u65f6\u7f3a\u4e4f\u6682\u505c\u6216\u91cd\u5b9a\u5411\u7684\u6743\u9650\uff0c\u5bfc\u81f4\u5305\u5bb9\u6027\u3001\u5b89\u5168\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faR2O\u6846\u67b6\uff08\u5b9a\u4e49\u8986\u76d6\u6743\u9650\u3001\u8bc1\u636e\u9608\u503c\u548c\u5b89\u5168\u56de\u9000\u72b6\u6001\uff09\u548cDAM\u5ba1\u8ba1\u65b9\u6cd5\uff08\u5305\u62ec\u9884\u90e8\u7f72\u6f14\u7ec3\u3001\u5f71\u5b50\u6a21\u5f0f\u8bd5\u9a8c\u548c\u4e8b\u540e\u5ba1\u67e5\uff09\uff0c\u5e76\u5728\u667a\u80fd\u7535\u7f51\u8d1f\u8377\u524a\u51cf\u3001\u5efa\u7b51HVAC\u548c\u4ea4\u901a\u4fe1\u53f7\u7b49\u573a\u666f\u8fdb\u884c\u6a21\u62df\u9a8c\u8bc1\u3002", "result": "R2O\u663e\u8457\u51cf\u5c11\u4e86\u5206\u5e03\u6027\u4f24\u5bb3\u4e14\u6548\u7387\u635f\u5931\u6709\u9650\uff1a\u672a\u670d\u52a1\u80fd\u6e90\u7684\u8d1f\u8377\u524a\u51cf\u5dee\u5f02\u4ece5.61\u500d\u964d\u81f30.69\u500d\uff1b\u8986\u76d6\u64cd\u4f5c\u4ee577kWh\u80fd\u6e90\u6210\u672c\u6d88\u9664\u4e86\u8001\u5e74\u4eba2\u5c0f\u65f6\u4e0d\u9002\uff1b\u884c\u4eba\u7b49\u5f85\u4e2d\u4f4d\u6570\u4ece90.4\u79d2\u964d\u81f355.9\u79d2\uff0c\u8f66\u8f86\u5e73\u5747\u5ef6\u8fdf\u4ec5\u589e\u52a06.0\u79d2\u3002", "conclusion": "R2O/DAM\u6846\u67b6\u4f7f\u57ce\u5e02\u81ea\u52a8\u5316\u7cfb\u7edf\u5177\u6709\u53ef\u4e89\u8bae\u6027\u548c\u53ef\u5ba1\u67e5\u6027\uff0c\u4e3a\u653f\u7b56\u6807\u51c6\u3001\u5ba1\u8ba1\u5de5\u5177\u548cModelOps\u96c6\u6210\u63d0\u4f9b\u4e86\u5b9e\u7528\u6a21\u5f0f\uff0c\u6709\u6548\u5e73\u8861\u4e86\u81ea\u52a8\u5316\u6548\u7387\u4e0e\u4eba\u7c7b\u6743\u76ca\u4fdd\u62a4\u3002"}}
{"id": "2509.14213", "categories": ["stat.AP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.14213", "abs": "https://arxiv.org/abs/2509.14213", "authors": ["Buddhi Wijenayake", "Athulya Ratnayake", "Lelumi Edirisinghe", "Uditha Wijeratne", "Tharaka Fonseka", "Roshan Godaliyadda", "Samath Dharmaratne", "Parakrama Ekanayake", "Vijitha Herath", "Insoha Alwis", "Supun Manathunga"], "title": "PoPStat-COVID19: Leveraging Population Pyramids to Quantify Demographic Vulnerability to COVID-19", "comment": "14 pages, 4 Figures, 25th ICTer Conference", "summary": "Understanding how population age structure shapes COVID-19 burden is crucial\nfor pandemic preparedness, yet common summary measures such as median age\nignore key distributional features like skewness, bimodality, and the\nproportional weight of high-risk cohorts. We extend the PoPStat framework,\noriginally devised to link entire population pyramids with cause-specific\nmortality by applying it to COVID-19. Using 2019 United Nations World\nPopulation Prospects age-sex distributions together with cumulative cases and\ndeaths per million recorded up to 5 May 2023 by Our World in Data, we calculate\nPoPDivergence (the Kullback-Leibler divergence from an optimised reference\npyramid) for 180+ countries and derive PoPStat-COVID19 as the Pearson\ncorrelation between that divergence and log-transformed incidence or mortality.\nOptimisation selects Malta's old-skewed pyramid as the reference, yielding\nstrong negative correlations for cases (r=-0.86, p<0.001, R^2=0.74) and deaths\n(r=-0.82, p<0.001, R^2=0.67). Sensitivity tests across twenty additional,\nsimilarly old-skewed references confirm that these associations are robust to\nreference choice. Benchmarking against eight standard indicators like gross\ndomestic product per capita, Gini index, Human Development Index, life\nexpectancy at birth, median age, population density, Socio-demographic Index,\nand Universal Health Coverage Index shows that PoPStat-COVID19 surpasses GDP\nper capita, median age, population density, and several other traditional\nmeasures, and outperforms every comparator for fatality burden. PoPStat-COVID19\ntherefore provides a concise, distribution-aware scalar for quantifying\ndemographic vulnerability to COVID-19.", "AI": {"tldr": "\u672c\u7814\u7a76\u6269\u5c55\u4e86PoPStat\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u4eba\u53e3\u5e74\u9f84\u7ed3\u6784\u5206\u5e03\u7279\u5f81\uff08\u800c\u975e\u4ec5\u7528\u4e2d\u4f4d\u5e74\u9f84\u7b49\u7b80\u5355\u6307\u6807\uff09\u6765\u91cf\u5316COVID-19\u8d1f\u62c5\uff0c\u53d1\u73b0\u4eba\u53e3\u91d1\u5b57\u5854\u7684\u5206\u5e03\u5dee\u5f02\u4e0e\u75ab\u60c5\u4e25\u91cd\u7a0b\u5ea6\u5b58\u5728\u5f3a\u8d1f\u76f8\u5173\u5173\u7cfb\u3002", "motivation": "\u4f20\u7edf\u7684\u4eba\u53e3\u5e74\u9f84\u7ed3\u6784\u603b\u7ed3\u6307\u6807\uff08\u5982\u4e2d\u4f4d\u5e74\u9f84\uff09\u5ffd\u7565\u4e86\u5206\u5e03\u7684\u5173\u952e\u7279\u5f81\uff0c\u5982\u504f\u5ea6\u3001\u53cc\u5cf0\u6027\u548c\u9ad8\u98ce\u9669\u4eba\u7fa4\u6bd4\u4f8b\uff0c\u800c\u8fd9\u4e9b\u7279\u5f81\u5bf9\u7406\u89e3COVID-19\u8d1f\u62c5\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6269\u5c55PoPStat\u6846\u67b6\uff0c\u4f7f\u7528\u8054\u5408\u56fd2019\u5e74\u4e16\u754c\u4eba\u53e3\u5c55\u671b\u7684\u5e74\u9f84-\u6027\u522b\u5206\u5e03\u6570\u636e\uff0c\u7ed3\u5408Our World in Data\u7684COVID-19\u75c5\u4f8b\u548c\u6b7b\u4ea1\u6570\u636e\uff0c\u8ba1\u7b97180\u591a\u4e2a\u56fd\u5bb6\u7684PoPDivergence\uff08\u4e0e\u4f18\u5316\u53c2\u8003\u91d1\u5b57\u5854\u7684Kullback-Leibler\u6563\u5ea6\uff09\uff0c\u5e76\u63a8\u5bfcPoPStat-COVID19\u4f5c\u4e3a\u8be5\u6563\u5ea6\u4e0e\u5bf9\u6570\u8f6c\u6362\u53d1\u75c5\u7387/\u6b7b\u4ea1\u7387\u7684Pearson\u76f8\u5173\u7cfb\u6570\u3002", "result": "\u4f18\u5316\u9009\u62e9\u9a6c\u8033\u4ed6\u7684\u8001\u5e74\u504f\u659c\u91d1\u5b57\u5854\u4f5c\u4e3a\u53c2\u8003\uff0c\u5f97\u5230\u75c5\u4f8b\uff08r=-0.86\uff09\u548c\u6b7b\u4ea1\uff08r=-0.82\uff09\u7684\u5f3a\u8d1f\u76f8\u5173\u3002\u654f\u611f\u6027\u6d4b\u8bd5\u8bc1\u5b9e\u5173\u8054\u5bf9\u53c2\u8003\u9009\u62e9\u5177\u6709\u7a33\u5065\u6027\u3002PoPStat-COVID19\u5728\u9884\u6d4bCOVID-19\u8d1f\u62c5\u65b9\u9762\u4f18\u4e8eGDP\u4eba\u5747\u3001\u4e2d\u4f4d\u5e74\u9f84\u3001\u4eba\u53e3\u5bc6\u5ea6\u7b498\u4e2a\u4f20\u7edf\u6307\u6807\u3002", "conclusion": "PoPStat-COVID19\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u6d01\u3001\u5206\u5e03\u611f\u77e5\u7684\u6807\u91cf\uff0c\u80fd\u591f\u6709\u6548\u91cf\u5316\u4eba\u53e3\u5bf9COVID-19\u7684\u8106\u5f31\u6027\uff0c\u4e3a\u672a\u6765\u5927\u6d41\u884c\u9632\u8303\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2509.13698", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2509.13698", "abs": "https://arxiv.org/abs/2509.13698", "authors": ["Irene Botosaru", "Laura Liu"], "title": "Time-Varying Heterogeneous Treatment Effects in Event Studies", "comment": null, "summary": "This paper examines the identification and estimation of heterogeneous\ntreatment effects in event studies, emphasizing the importance of both lagged\ndependent variables and treatment effect heterogeneity. We show that omitting\nlagged dependent variables can induce omitted variable bias in the estimated\ntime-varying treatment effects. We develop a novel semiparametric approach\nbased on a short-T dynamic linear panel model with correlated random\ncoefficients, where the time-varying heterogeneous treatment effects can be\nmodeled by a time-series process to reduce dimensionality. We construct a\ntwo-step estimator employing quasi-maximum likelihood for common parameters and\nempirical Bayes for the heterogeneous treatment effects. The procedure is\nflexible, easy to implement, and achieves ratio optimality asymptotically. Our\nresults also provide insights into common assumptions in the event study\nliterature, such as no anticipation, homogeneous treatment effects across\ntreatment timing cohorts, and state dependence structure.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u534a\u53c2\u6570\u65b9\u6cd5\u6765\u4f30\u8ba1\u4e8b\u4ef6\u7814\u7a76\u4e2d\u7684\u5f02\u8d28\u6027\u5904\u7406\u6548\u5e94\uff0c\u89e3\u51b3\u4e86\u5ffd\u7565\u6ede\u540e\u56e0\u53d8\u91cf\u5bfc\u81f4\u7684\u9057\u6f0f\u53d8\u91cf\u504f\u5dee\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u5bf9\u4e8b\u4ef6\u7814\u7a76\u6587\u732e\u4e2d\u5e38\u89c1\u5047\u8bbe\u7684\u89c1\u89e3\u3002", "motivation": "\u4f20\u7edf\u4e8b\u4ef6\u7814\u7a76\u4e2d\u5ffd\u7565\u6ede\u540e\u56e0\u53d8\u91cf\u4f1a\u5bfc\u81f4\u4f30\u8ba1\u7684\u65f6\u95f4\u53d8\u5316\u5904\u7406\u6548\u5e94\u51fa\u73b0\u9057\u6f0f\u53d8\u91cf\u504f\u5dee\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u540c\u65f6\u5904\u7406\u6ede\u540e\u4f9d\u8d56\u53d8\u91cf\u548c\u5904\u7406\u6548\u5e94\u5f02\u8d28\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u77edT\u52a8\u6001\u7ebf\u6027\u9762\u677f\u6a21\u578b\u548c\u76f8\u5173\u968f\u673a\u7cfb\u6570\uff0c\u5f00\u53d1\u4e86\u534a\u53c2\u6570\u65b9\u6cd5\uff0c\u4f7f\u7528\u65f6\u5e8f\u8fc7\u7a0b\u5efa\u6a21\u65f6\u95f4\u53d8\u5316\u7684\u5f02\u8d28\u6027\u5904\u7406\u6548\u5e94\u4ee5\u964d\u4f4e\u7ef4\u5ea6\uff0c\u91c7\u7528\u4e24\u6b65\u4f30\u8ba1\u5668\uff08\u5171\u540c\u53c2\u6570\u7684\u51c6\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u548c\u5f02\u8d28\u6027\u5904\u7406\u6548\u5e94\u7684\u7ecf\u9a8c\u8d1d\u53f6\u65af\u4f30\u8ba1\uff09\u3002", "result": "\u8be5\u65b9\u6cd5\u7075\u6d3b\u6613\u5b9e\u65bd\uff0c\u6e10\u8fd1\u8fbe\u5230\u6bd4\u7387\u6700\u4f18\u6027\uff0c\u4e3a\u4e8b\u4ef6\u7814\u7a76\u6587\u732e\u4e2d\u7684\u5e38\u89c1\u5047\u8bbe\uff08\u5982\u65e0\u9884\u671f\u6548\u5e94\u3001\u8de8\u5904\u7406\u65f6\u95f4\u961f\u5217\u7684\u540c\u8d28\u6027\u5904\u7406\u6548\u5e94\u3001\u72b6\u6001\u4f9d\u8d56\u7ed3\u6784\uff09\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002", "conclusion": "\u63d0\u51fa\u7684\u534a\u53c2\u6570\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4e8b\u4ef6\u7814\u7a76\u4e2d\u5f02\u8d28\u6027\u5904\u7406\u6548\u5e94\u7684\u8bc6\u522b\u548c\u4f30\u8ba1\u95ee\u9898\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u65b9\u6cd5\u8bba\u8d21\u732e\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2509.13964", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2509.13964", "abs": "https://arxiv.org/abs/2509.13964", "authors": ["Donato Francesco Falcone", "Stephan Menzel", "Tommaso Stecconi", "Matteo Galetta", "Antonio La Porta", "Bert Jan Offrein", "Valeria Bragaglia"], "title": "Analytical Modelling of the Transport in Analog Filamentary Conductive-Metal-Oxide/HfOx ReRAM Devices", "comment": null, "summary": "The recent co-optimization of memristive technologies and programming\nalgorithms enabled neural networks training with in-memory computing systems.\nIn this context, novel analog filamentary conductive-metal-oxide (CMO)/HfOx\nredox-based resistive switching memory (ReRAM) represents a key technology.\nDespite device performance enhancements reported in literature, the underlying\nmechanism behind resistive switching is not fully understood. This work\npresents the first physics-based analytical model of the current transport and\nof the resistive switching in these devices. As a case study, analog TaOx/HfOx\nReRAM devices are considered. The current transport is explained by a\ntrap-to-trap tunneling process, and the resistive switching by a modulation of\nthe defect density within the sub-band of the TaOx that behaves as electric\nfield and temperature confinement layer. The local temperature and electric\nfield distributions are derived from the solution of the electric and heat\ntransport equations in a 3D finite element ReRAM model. The intermediate\nresistive states are described as a gradual modulation of the TaOx defect\ndensity, which results in a variation of its electrical conductivity. The\ndrift-dynamics of ions during the resistive switching is analytically\ndescribed, allowing the estimation of defect migration energies in the TaOx\nlayer. Moreover, the role of the electro-thermal properties of the CMO layer is\nunveiled. The proposed analytical model accurately describes the experimental\nswitching characteristic of analog TaOx/HfOx ReRAM devices, increasing the\nphysical understanding and providing the equations necessary for circuit\nsimulations incorporating this technology.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u57fa\u4e8e\u7269\u7406\u7684\u89e3\u6790\u6a21\u578b\uff0c\u7528\u4e8e\u63cf\u8ff0TaOx/HfOx\u6a21\u62dfReRAM\u5668\u4ef6\u7684\u7535\u6d41\u4f20\u8f93\u548c\u7535\u963b\u5207\u6362\u673a\u5236\uff0c\u63ed\u793a\u4e86\u7f3a\u9677\u5bc6\u5ea6\u8c03\u5236\u548c\u79bb\u5b50\u6f02\u79fb\u52a8\u529b\u5b66\u7684\u4f5c\u7528\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8e\u5bfc\u7535\u91d1\u5c5e\u6c27\u5316\u7269(CMO)/HfOx\u7684\u963b\u53d8\u5b58\u50a8\u5668(ReRAM)\u5728\u795e\u7ecf\u7f51\u8def\u8bad\u7ec3\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u7535\u963b\u5207\u6362\u7684\u5e95\u5c42\u673a\u5236\u5c1a\u672a\u5b8c\u5168\u7406\u89e3\uff0c\u9700\u8981\u5efa\u7acb\u7269\u7406\u6a21\u578b\u6765\u6df1\u5165\u7406\u89e3\u5e76\u652f\u6301\u7535\u8def\u4eff\u771f\u3002", "method": "\u901a\u8fc73D\u6709\u9650\u5143\u6a21\u578b\u6c42\u89e3\u7535\u70ed\u4f20\u8f93\u65b9\u7a0b\uff0c\u5206\u6790\u5c40\u90e8\u6e29\u5ea6\u548c\u7535\u573a\u5206\u5e03\uff1b\u5efa\u7acb\u57fa\u4e8e\u9677\u9631\u5230\u9677\u9631\u96a7\u7a7f\u8fc7\u7a0b\u7684\u7535\u6d41\u4f20\u8f93\u6a21\u578b\uff1b\u901a\u8fc7\u7f3a\u9677\u5bc6\u5ea6\u8c03\u5236\u63cf\u8ff0\u7535\u963b\u72b6\u6001\u53d8\u5316\uff1b\u89e3\u6790\u63cf\u8ff0\u79bb\u5b50\u6f02\u79fb\u52a8\u529b\u5b66\u3002", "result": "\u63d0\u51fa\u7684\u89e3\u6790\u6a21\u578b\u51c6\u786e\u63cf\u8ff0\u4e86\u5b9e\u9a8c\u89c2\u5bdf\u5230\u7684TaOx/HfOx ReRAM\u5668\u4ef6\u7684\u5f00\u5173\u7279\u6027\uff0c\u80fd\u591f\u4f30\u7b97TaOx\u5c42\u4e2d\u7684\u7f3a\u9677\u8fc1\u79fb\u80fd\uff0c\u5e76\u63ed\u793a\u4e86CMO\u5c42\u7535\u70ed\u7279\u6027\u7684\u4f5c\u7528\u3002", "conclusion": "\u8be5\u7269\u7406\u6a21\u578b\u589e\u5f3a\u4e86\u5bf9ReRAM\u5668\u4ef6\u5de5\u4f5c\u673a\u5236\u7684\u7406\u89e3\uff0c\u63d0\u4f9b\u4e86\u7535\u8def\u4eff\u771f\u6240\u9700\u7684\u65b9\u7a0b\uff0c\u4e3a\u57fa\u4e8e\u8be5\u6280\u672f\u7684\u5e94\u7528\u5f00\u53d1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2509.13342", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13342", "abs": "https://arxiv.org/abs/2509.13342", "authors": ["Isaac Ronald Ward"], "title": "Real World Robotic Exploration using Deep Neural Networks Trained in Photorealistic Reconstructed Environments", "comment": "This report is submitted as partial fulfilment of the requirements\n  for the Honours Programme of the Department of Computer Science and Software\n  Engineering, The University of Western Australia, 2019", "summary": "In this work, an existing deep neural network approach for determining a\nrobot's pose from visual information (RGB images) is modified, improving its\nlocalization performance without impacting its ease of training. Explicitly,\nthe network's loss function is extended in a manner which intuitively combines\nthe positional and rotational error in order to increase robustness to\nperceptual aliasing. An improvement in the localization accuracy for indoor\nscenes is observed: with decreases of up to 9.64% and 2.99% in the median\npositional and rotational error respectively, when compared to the unmodified\nnetwork.\n  Additionally, photogrammetry data is used to produce a pose-labelled dataset\nwhich allows the above model to be trained on a local environment, resulting in\nlocalization accuracies of 0.11m & 0.89 degrees. This trained model forms the\nbasis of a navigation algorithm, which is tested in real-time on a TurtleBot (a\nwheeled robotic device). As such, this work introduces a full pipeline for\ncreating a robust navigational algorithm for any given real world indoor scene;\nthe only requirement being a collection of images from the scene, which can be\ncaptured in as little as 330 seconds of", "AI": {"tldr": "\u6539\u8fdb\u89c6\u89c9\u5b9a\u4f4d\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u65b0\u7684\u635f\u5931\u51fd\u6570\u7ed3\u5408\u4f4d\u7f6e\u548c\u65cb\u8f6c\u8bef\u5dee\uff0c\u63d0\u9ad8\u5ba4\u5185\u573a\u666f\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u5e76\u5efa\u7acb\u5b8c\u6574\u5bfc\u822a\u7b97\u6cd5\u6d41\u7a0b", "motivation": "\u63d0\u9ad8\u673a\u5668\u4eba\u57fa\u4e8e\u89c6\u89c9\u4fe1\u606f\u7684\u5b9a\u4f4d\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u611f\u77e5\u6df7\u6dc6\u7684\u5ba4\u5185\u73af\u5883\u4e2d\uff0c\u540c\u65f6\u4fdd\u6301\u7f51\u7edc\u7684\u6613\u8bad\u7ec3\u6027", "method": "\u6269\u5c55\u795e\u7ecf\u7f51\u7edc\u635f\u5931\u51fd\u6570\uff0c\u76f4\u89c2\u7ed3\u5408\u4f4d\u7f6e\u548c\u65cb\u8f6c\u8bef\u5dee\uff1b\u4f7f\u7528\u6444\u5f71\u6d4b\u91cf\u6570\u636e\u521b\u5efa\u59ff\u6001\u6807\u6ce8\u6570\u636e\u96c6\uff1b\u57fa\u4e8e\u8bad\u7ec3\u6a21\u578b\u5f00\u53d1\u5b9e\u65f6\u5bfc\u822a\u7b97\u6cd5", "result": "\u5ba4\u5185\u573a\u666f\u5b9a\u4f4d\u7cbe\u5ea6\u663e\u8457\u63d0\u5347\uff1a\u4f4d\u7f6e\u8bef\u5dee\u4e2d\u4f4d\u6570\u964d\u4f4e9.64%\uff0c\u65cb\u8f6c\u8bef\u5dee\u4e2d\u4f4d\u6570\u964d\u4f4e2.99%\uff1b\u6700\u7ec8\u5b9e\u73b00.11\u7c73\u548c0.89\u5ea6\u7684\u5b9a\u4f4d\u7cbe\u5ea6", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u5ba4\u5185\u573a\u666f\u5bfc\u822a\u7b97\u6cd5\u6d41\u7a0b\uff0c\u4ec5\u9700\u573a\u666f\u56fe\u50cf\u91c7\u96c6\uff08\u6700\u77ed330\u79d2\uff09\uff0c\u5373\u53ef\u521b\u5efa\u9c81\u68d2\u7684\u5b9e\u65f6\u5bfc\u822a\u7cfb\u7edf"}}
{"id": "2509.13333", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13333", "abs": "https://arxiv.org/abs/2509.13333", "authors": ["Maheep Chaudhary", "Ian Su", "Nikhil Hooda", "Nishith Shankar", "Julia Tan", "Kevin Zhu", "Ashwinee Panda", "Ryan Lagasse", "Vasu Sharma"], "title": "Evaluation Awareness Scales Predictably in Open-Weights Large Language Models", "comment": null, "summary": "Large language models (LLMs) can internally distinguish between evaluation\nand deployment contexts, a behaviour known as \\emph{evaluation awareness}. This\nundermines AI safety evaluations, as models may conceal dangerous capabilities\nduring testing. Prior work demonstrated this in a single $70$B model, but the\nscaling relationship across model sizes remains unknown. We investigate\nevaluation awareness across $15$ models scaling from $0.27$B to $70$B\nparameters from four families using linear probing on steering vector\nactivations. Our results reveal a clear power-law scaling: evaluation awareness\nincreases predictably with model size. This scaling law enables forecasting\ndeceptive behavior in future larger models and guides the design of scale-aware\nevaluation strategies for AI safety. A link to the implementation of this paper\ncan be found at\nhttps://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u8bc4\u4f30\u610f\u8bc6\u884c\u4e3a\uff0c\u5373\u6a21\u578b\u80fd\u5728\u8bc4\u4f30\u548c\u90e8\u7f72\u73af\u5883\u4e2d\u533a\u5206\u5e76\u9690\u85cf\u5371\u9669\u80fd\u529b\u3002\u901a\u8fc7\u5bf915\u4e2a\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u7684\u5206\u6790\uff0c\u63ed\u793a\u4e86\u8bc4\u4f30\u610f\u8bc6\u968f\u6a21\u578b\u89c4\u6a21\u5448\u5e42\u5f8b\u589e\u957f\u89c4\u5f8b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5b89\u5168\u8bc4\u4f30\u4e2d\u53ef\u80fd\u9690\u85cf\u5371\u9669\u80fd\u529b\uff0c\u8fd9\u79cd\u8bc4\u4f30\u610f\u8bc6\u884c\u4e3a\u4f1a\u7834\u574fAI\u5b89\u5168\u8bc4\u4f30\u7684\u6709\u6548\u6027\u3002\u5148\u524d\u7814\u7a76\u4ec5\u5728\u5355\u4e2a70B\u6a21\u578b\u4e2d\u53d1\u73b0\u6b64\u73b0\u8c61\uff0c\u4f46\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u95f4\u7684\u8bc4\u4f30\u610f\u8bc6\u53d8\u5316\u89c4\u5f8b\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u63a2\u6d4b\u65b9\u6cd5\u5206\u6790\u4ece0.27B\u523070B\u53c2\u6570\u768415\u4e2a\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u7684\u8f6c\u5411\u5411\u91cf\u6fc0\u6d3b\uff0c\u7814\u7a76\u8bc4\u4f30\u610f\u8bc6\u968f\u6a21\u578b\u89c4\u6a21\u7684\u53d8\u5316\u89c4\u5f8b\u3002", "result": "\u53d1\u73b0\u4e86\u6e05\u6670\u7684\u5e42\u5f8b\u7f29\u653e\u89c4\u5f8b\uff1a\u8bc4\u4f30\u610f\u8bc6\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u53ef\u9884\u6d4b\u5730\u589e\u5f3a\u3002\u8fd9\u4e00\u7f29\u653e\u5b9a\u5f8b\u4f7f\u5f97\u80fd\u591f\u9884\u6d4b\u672a\u6765\u66f4\u5927\u6a21\u578b\u7684\u6b3a\u9a97\u884c\u4e3a\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aAI\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u89c4\u6a21\u611f\u77e5\u7684\u8bc4\u4f30\u7b56\u7565\u8bbe\u8ba1\u6307\u5bfc\uff0c\u80fd\u591f\u5e2e\u52a9\u9884\u6d4b\u548c\u5e94\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5b89\u5168\u8bc4\u4f30\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u6b3a\u9a97\u6027\u884c\u4e3a\u3002"}}
{"id": "2509.13887", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2509.13887", "abs": "https://arxiv.org/abs/2509.13887", "authors": ["Claudia Cerrone", "Francesco Feri", "Anita Gantner", "Paolo Pin"], "title": "Can the decoy effect increase cooperation in networks? An experiment", "comment": null, "summary": "This paper investigates whether the decoy effect - specifically the\nattraction effect - can foster cooperation in social networks. In a lab\nexperiment, we show that introducing a dominated option increases the selection\nof the target choice, especially in early decisions. The effect is stronger in\nindividual settings but persists in networks despite free-riding incentives,\nwith variation depending on the decision-maker's strategic position.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bf1\u9975\u6548\u5e94\uff08\u7279\u522b\u662f\u5438\u5f15\u529b\u6548\u5e94\uff09\u80fd\u591f\u4fc3\u8fdb\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u5408\u4f5c\u884c\u4e3a\uff0c\u5b9e\u9a8c\u663e\u793a\u5f15\u5165\u88ab\u652f\u914d\u9009\u9879\u4f1a\u589e\u52a0\u76ee\u6807\u9009\u62e9\uff0c\u5c24\u5176\u662f\u5728\u65e9\u671f\u51b3\u7b56\u4e2d", "motivation": "\u7814\u7a76\u8bf1\u9975\u6548\u5e94\u662f\u5426\u80fd\u591f\u5728\u793e\u4ea4\u7f51\u7edc\u4e2d\u4fc3\u8fdb\u5408\u4f5c\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u642d\u4fbf\u8f66\u52a8\u673a\u7684\u7f51\u7edc\u73af\u5883\u4e2d", "method": "\u901a\u8fc7\u5b9e\u9a8c\u5ba4\u5b9e\u9a8c\uff0c\u5728\u793e\u4ea4\u7f51\u7edc\u73af\u5883\u4e2d\u5f15\u5165\u88ab\u652f\u914d\u9009\u9879\uff08\u8bf1\u9975\uff09\uff0c\u89c2\u5bdf\u5176\u5bf9\u76ee\u6807\u9009\u62e9\u884c\u4e3a\u7684\u5f71\u54cd", "result": "\u5f15\u5165\u88ab\u652f\u914d\u9009\u9879\u663e\u8457\u589e\u52a0\u4e86\u76ee\u6807\u9009\u62e9\uff0c\u7279\u522b\u662f\u5728\u65e9\u671f\u51b3\u7b56\u9636\u6bb5\uff1b\u6548\u5e94\u5728\u4e2a\u4f53\u8bbe\u7f6e\u4e2d\u66f4\u5f3a\uff0c\u4f46\u5728\u7f51\u7edc\u4e2d\u4ecd\u7136\u5b58\u5728\uff0c\u4e14\u6548\u679c\u56e0\u51b3\u7b56\u8005\u7684\u6218\u7565\u4f4d\u7f6e\u800c\u5f02", "conclusion": "\u8bf1\u9975\u6548\u5e94\u80fd\u591f\u6709\u6548\u4fc3\u8fdb\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u5408\u4f5c\uff0c\u5373\u4f7f\u5728\u5b58\u5728\u642d\u4fbf\u8f66\u52a8\u673a\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e3a\u8bbe\u8ba1\u4fc3\u8fdb\u5408\u4f5c\u7684\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3"}}
{"id": "2509.13345", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13345", "abs": "https://arxiv.org/abs/2509.13345", "authors": ["Zihao Li", "Weiwei Yi", "Jiahong Chen"], "title": "Accuracy Paradox in Large Language Models: Regulating Hallucination Risks in Generative AI", "comment": null, "summary": "As Large Language Models (LLMs) permeate everyday decision-making, their\nepistemic and societal risks demand urgent scrutiny. Hallucinations, the\ngeneration of fabricated, misleading, oversimplified or untrustworthy outputs,\nhas emerged as imperative challenges. While regulatory, academic, and technical\ndiscourse position accuracy as the principal benchmark for mitigating such\nharms, this article contends that overreliance on accuracy misdiagnoses the\nproblem and has counterproductive effect: the accuracy paradox. Drawing on\ninterdisciplinary literatures, this article develops a taxonomy of\nhallucination types and shows the paradox along three intertwining dimensions:\noutputs, individuals and society. First, accuracy functions as a superficial\nproxy for reliability, incentivising the optimisation of rhetorical fluency and\nsurface-level correctness over epistemic trustworthiness. This encourages\npassive user trust in outputs that appear accurate but epistemically untenable.\nSecond, accuracy as a singular metric fails to detect harms that are not\nfactually false but are nonetheless misleading, value-laden, or socially\ndistorting, including consensus illusions, sycophantic alignment, and subtle\nmanipulation. Third, regulatory overemphasis on accuracy obscures the wider\nsocietal consequences of hallucination, including social sorting, privacy\nviolations, equity harms, epistemic convergence that marginalises dissent,\nreduces pluralism, and causes social deskilling. By examining the EU AI Act,\nGDPR, and DSA, the article argues that current regulations are not yet\nstructurally equipped to address these epistemic, relational, and systemic\nharms and exacerbated by the overreliance on accuracy. By exposing such\nconceptual and practical challenges, this article calls for a fundamental shift\ntowards pluralistic, context-aware, and manipulation-resilient approaches to AI\ntrustworthy governance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\"\u51c6\u786e\u6027\u6096\u8bba\"\u6982\u5ff5\uff0c\u8ba4\u4e3a\u8fc7\u5ea6\u4f9d\u8d56\u51c6\u786e\u6027\u4f5c\u4e3a\u8bc4\u4f30LLM\u5e7b\u89c9\u7684\u4e3b\u8981\u6807\u51c6\u53cd\u800c\u4f1a\u4ea7\u751f\u53cd\u6548\u679c\uff0c\u63a9\u76d6\u4e86\u66f4\u6df1\u5c42\u7684\u8ba4\u77e5\u548c\u793e\u4f1a\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65e5\u5e38\u51b3\u7b56\u4e2d\u7684\u666e\u53ca\uff0c\u5176\u4ea7\u751f\u7684\u5e7b\u89c9\uff08\u865a\u5047\u3001\u8bef\u5bfc\u6027\u3001\u8fc7\u5ea6\u7b80\u5316\u6216\u4e0d\u53ef\u4fe1\u8f93\u51fa\uff09\u5e26\u6765\u4e86\u7d27\u8feb\u7684\u8ba4\u77e5\u548c\u793e\u4f1a\u98ce\u9669\u3002\u5f53\u524d\u76d1\u7ba1\u3001\u5b66\u672f\u548c\u6280\u672f\u8ba8\u8bba\u5c06\u51c6\u786e\u6027\u4f5c\u4e3a\u7f13\u89e3\u8fd9\u4e9b\u5371\u5bb3\u7684\u4e3b\u8981\u57fa\u51c6\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u79cd\u8fc7\u5ea6\u4f9d\u8d56\u4f1a\u8bef\u8bca\u95ee\u9898\u5e76\u4ea7\u751f\u53cd\u6548\u679c\u3002", "method": "\u901a\u8fc7\u8de8\u5b66\u79d1\u6587\u732e\u5206\u6790\uff0c\u6784\u5efa\u4e86\u5e7b\u89c9\u7c7b\u578b\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u4ece\u4e09\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u7ef4\u5ea6\uff08\u8f93\u51fa\u3001\u4e2a\u4f53\u548c\u793e\u4f1a\uff09\u5c55\u793a\u51c6\u786e\u6027\u6096\u8bba\u3002\u540c\u65f6\u8003\u5bdf\u4e86\u6b27\u76dfAI\u6cd5\u6848\u3001GDPR\u548cDSA\u7b49\u73b0\u884c\u6cd5\u89c4\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u51c6\u786e\u6027\u4f5c\u4e3a\u5355\u4e00\u6307\u6807\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u4f5c\u4e3a\u53ef\u9760\u6027\u7684\u8868\u9762\u4ee3\u7406\uff0c\u9f13\u52b1\u4f18\u5316\u4fee\u8f9e\u6d41\u7545\u6027\u548c\u8868\u9762\u6b63\u786e\u6027\u800c\u975e\u8ba4\u77e5\u53ef\u4fe1\u5ea6\uff1b2\uff09\u65e0\u6cd5\u68c0\u6d4b\u975e\u4e8b\u5b9e\u9519\u8bef\u4f46\u5177\u6709\u8bef\u5bfc\u6027\u3001\u4ef7\u503c\u8d1f\u8f7d\u6216\u793e\u4f1a\u626d\u66f2\u7684\u5371\u5bb3\uff1b3\uff09\u76d1\u7ba1\u8fc7\u5ea6\u5f3a\u8c03\u51c6\u786e\u6027\u63a9\u76d6\u4e86\u5e7b\u89c9\u7684\u66f4\u5e7f\u6cdb\u793e\u4f1a\u540e\u679c\u3002", "conclusion": "\u5f53\u524d\u6cd5\u89c4\u5728\u7ed3\u6784\u4e0a\u5c1a\u672a\u51c6\u5907\u597d\u5e94\u5bf9\u8fd9\u4e9b\u8ba4\u77e5\u3001\u5173\u7cfb\u548c\u7cfb\u7edf\u6027\u5371\u5bb3\u3002\u6587\u7ae0\u547c\u5401\u4ece\u6839\u672c\u4e0a\u8f6c\u5411\u591a\u5143\u5316\u3001\u60c5\u5883\u611f\u77e5\u548c\u6297\u64cd\u7eb5\u7684AI\u53ef\u4fe1\u6cbb\u7406\u65b9\u6cd5\u3002"}}
{"id": "2509.13371", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.13371", "abs": "https://arxiv.org/abs/2509.13371", "authors": ["Xuyuan Kang", "Xiao Wang", "Jingjing An", "Da Yan"], "title": "A novel approach of day-ahead cooling load prediction and optimal control for ice-based thermal energy storage (TES) system in commercial buildings", "comment": "16 pages,14 figures,published to Energy & Buildings", "summary": "Thermal energy storage (TES) is an effective method for load shifting and\ndemand response in buildings. Optimal TES control and management are essential\nto improve the performance of the cooling system. Most existing TES systems\noperate on a fixed schedule, which cannot take full advantage of its load\nshifting capability, and requires extensive investigation and optimization.\nThis study proposed a novel integrated load prediction and optimized control\napproach for ice-based TES in commercial buildings. A cooling load prediction\nmodel was developed and a mid-day modification mechanism was introduced into\nthe prediction model to improve the accuracy. Based on the predictions, a\nrule-based control strategy was proposed according to the time-of-use tariff;\nthe mid-day control adjustment mechanism was introduced in accordance with the\nmid-day prediction modifications. The proposed approach was applied in the\nice-based TES system of a commercial complex in Beijing, and achieved a mean\nabsolute error (MAE) of 389 kW and coefficient of variance of MAE of 12.5%. The\nintegrated prediction-based control strategy achieved an energy cost saving\nrate of 9.9%. The proposed model was deployed in the realistic building\nautomation system of the case building and significantly improved the\nefficiency and automation of the cooling system.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5546\u4e1a\u5efa\u7b51\u51b0\u84c4\u51b7\u7cfb\u7edf\u7684\u96c6\u6210\u8d1f\u8377\u9884\u6d4b\u4e0e\u4f18\u5316\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5348\u95f4\u4fee\u6b63\u673a\u5236\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u57fa\u4e8e\u5206\u65f6\u7535\u4ef7\u5236\u5b9a\u89c4\u5219\u63a7\u5236\u7b56\u7565\uff0c\u5b9e\u73b0\u4e869.9%\u7684\u80fd\u6e90\u6210\u672c\u8282\u7ea6\u3002", "motivation": "\u73b0\u6709TES\u7cfb\u7edf\u5927\u591a\u91c7\u7528\u56fa\u5b9a\u8fd0\u884c\u8ba1\u5212\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u5176\u8d1f\u8377\u8f6c\u79fb\u80fd\u529b\uff0c\u9700\u8981\u5927\u91cf\u8c03\u67e5\u548c\u4f18\u5316\u5de5\u4f5c\u3002\u4e3a\u63d0\u9ad8\u51b7\u5374\u7cfb\u7edf\u6027\u80fd\u548c\u81ea\u52a8\u5316\u7a0b\u5ea6\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u667a\u80fd\u7684\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u51b7\u5374\u8d1f\u8377\u9884\u6d4b\u6a21\u578b\u5e76\u5f15\u5165\u5348\u95f4\u4fee\u6b63\u673a\u5236\u63d0\u9ad8\u7cbe\u5ea6\uff1b\u57fa\u4e8e\u9884\u6d4b\u7ed3\u679c\u548c\u5206\u65f6\u7535\u4ef7\u5236\u5b9a\u89c4\u5219\u63a7\u5236\u7b56\u7565\uff1b\u5728\u5348\u95f4\u63a7\u5236\u8c03\u6574\u4e2d\u5f15\u5165\u9884\u6d4b\u4fee\u6b63\u673a\u5236\uff1b\u5728\u5317\u4eac\u67d0\u5546\u4e1a\u7efc\u5408\u4f53\u7684\u51b0\u84c4\u51b7\u7cfb\u7edf\u4e2d\u5b9e\u9645\u5e94\u7528\u3002", "result": "\u9884\u6d4b\u6a21\u578b\u8fbe\u5230389kW\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u548c12.5%\u7684\u53d8\u5f02\u7cfb\u6570\uff1b\u96c6\u6210\u9884\u6d4b\u63a7\u5236\u7b56\u7565\u5b9e\u73b09.9%\u7684\u80fd\u6e90\u6210\u672c\u8282\u7ea6\u7387\uff1b\u6a21\u578b\u5728\u5b9e\u9645\u5efa\u7b51\u81ea\u52a8\u5316\u7cfb\u7edf\u4e2d\u6210\u529f\u90e8\u7f72\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u51b7\u5374\u7cfb\u7edf\u6548\u7387\u548c\u81ea\u52a8\u5316\u6c34\u5e73\u3002", "conclusion": "\u63d0\u51fa\u7684\u96c6\u6210\u8d1f\u8377\u9884\u6d4b\u548c\u4f18\u5316\u63a7\u5236\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u51b0\u84c4\u51b7\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u80fd\u6e90\u6210\u672c\u8282\u7ea6\uff0c\u5e76\u4e3a\u5efa\u7b51\u51b7\u5374\u7cfb\u7edf\u7684\u667a\u80fd\u5316\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2509.13349", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13349", "abs": "https://arxiv.org/abs/2509.13349", "authors": ["Jed Guzelkabaagac", "Boris Petrovi\u0107"], "title": "Label-Efficient Grasp Joint Prediction with Point-JEPA", "comment": "4 pages, 5 figures. Submitted to IROS 2025 Workshop", "summary": "We investigate whether 3D self-supervised pretraining with a Joint-Embedding\nPredictive Architecture (Point-JEPA) enables label-efficient grasp joint-angle\nprediction. Using point clouds tokenized from meshes and a ShapeNet-pretrained\nPoint-JEPA encoder, we train a lightweight multi-hypothesis head with\nwinner-takes-all and evaluate by top-logit selection. On DLR-Hand II with\nobject-level splits, Point-JEPA reduces RMSE by up to 26% in low-label regimes\nand reaches parity with full supervision. These results suggest JEPA-style\npretraining is a practical approach for data-efficient grasp learning.", "AI": {"tldr": "Point-JEPA\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u5728\u4f4e\u6807\u7b7e\u6570\u636e\u4e0b\u663e\u8457\u63d0\u5347\u6293\u53d6\u5173\u8282\u89d2\u5ea6\u9884\u6d4b\u6027\u80fd\uff0c\u51cf\u5c1126%\u7684RMSE\uff0c\u8fbe\u5230\u4e0e\u5168\u76d1\u7763\u76f8\u5f53\u7684\u6548\u679c", "motivation": "\u7814\u7a763D\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u662f\u5426\u80fd\u591f\u5b9e\u73b0\u6807\u7b7e\u9ad8\u6548\u7684\u6293\u53d6\u5173\u8282\u89d2\u5ea6\u9884\u6d4b\uff0c\u89e3\u51b3\u6570\u636e\u6807\u6ce8\u6210\u672c\u9ad8\u7684\u95ee\u9898", "method": "\u4f7f\u7528\u57fa\u4e8eShapeNet\u9884\u8bad\u7ec3\u7684Point-JEPA\u7f16\u7801\u5668\u5904\u7406\u70b9\u4e91\u6570\u636e\uff0c\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u591a\u5047\u8bbe\u5934\u90e8\uff0c\u91c7\u7528winner-takes-all\u7b56\u7565\u548ctop-logit\u9009\u62e9\u8fdb\u884c\u8bc4\u4f30", "result": "\u5728DLR-Hand II\u6570\u636e\u96c6\u4e0a\uff0cPoint-JEPA\u5728\u4f4e\u6807\u7b7e\u60c5\u51b5\u4e0b\u5c06RMSE\u964d\u4f4e\u4e8626%\uff0c\u5e76\u4e14\u8fbe\u5230\u4e86\u4e0e\u5168\u76d1\u7763\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u6c34\u5e73", "conclusion": "JEPA\u98ce\u683c\u7684\u9884\u8bad\u7ec3\u662f\u6570\u636e\u9ad8\u6548\u6293\u53d6\u5b66\u4e60\u7684\u4e00\u79cd\u5b9e\u7528\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u57283D\u6293\u53d6\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027"}}
{"id": "2509.13334", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13334", "abs": "https://arxiv.org/abs/2509.13334", "authors": ["Anand Swaroop", "Akshat Nallani", "Saksham Uboweja", "Adiliia Uzdenova", "Michael Nguyen", "Kevin Zhu", "Sunishchal Dev", "Ashwinee Panda", "Vasu Sharma", "Maheep Chaudhary"], "title": "FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness", "comment": null, "summary": "Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving\nlarge language model performance on complex tasks, but recent work shows that\nreasoning steps often fail to causally influence the final answer, creating\nbrittle and untrustworthy outputs. Prior approaches focus primarily on\nmeasuring faithfulness, while methods for systematically improving it remain\nlimited. We introduce Faithful Reasoning via Intervention Training (FRIT), a\nscalable alignment method that trains models to produce causally consistent\nreasoning by learning from systematically corrupted examples. FRIT generates\nsynthetic training data by intervening on individual reasoning steps in\nmodel-generated CoTs, creating faithful/unfaithful pairs that highlight when\nreasoning breaks down. We then apply Direct Preference Optimization to teach\nmodels to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B\nand Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases\nfaithful reasoning by $3.4$ percentage points for Mistral on GSM8K while\nimproving accuracy by $7.6$ percentage points. Our approach provides the first\nscalable, supervision-free method for training language models to produce more\nreliable and interpretable reasoning, addressing a critical gap between\nreasoning performance and trustworthiness. We release our code at\n\\href{https://github.com/Anut-py/frit}.", "AI": {"tldr": "FRIT\u662f\u4e00\u79cd\u901a\u8fc7\u5e72\u9884\u8bad\u7ec3\u5b9e\u73b0\u5fe0\u5b9e\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u5fe0\u5b9e/\u4e0d\u5fe0\u5b9e\u63a8\u7406\u5bf9\u6765\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u9ad8\u63a8\u7406\u7684\u56e0\u679c\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u601d\u7ef4\u94fe\u63a8\u7406\u65b9\u6cd5\u5b58\u5728\u63a8\u7406\u6b65\u9aa4\u4e0e\u6700\u7ec8\u7b54\u6848\u7f3a\u4e4f\u56e0\u679c\u5173\u8054\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u8f93\u51fa\u8106\u5f31\u4e14\u4e0d\u53ef\u4fe1\u3002\u867d\u7136\u5df2\u6709\u65b9\u6cd5\u5173\u6ce8\u6d4b\u91cf\u5fe0\u5b9e\u6027\uff0c\u4f46\u7cfb\u7edf\u6539\u8fdb\u5fe0\u5b9e\u6027\u7684\u65b9\u6cd5\u4ecd\u7136\u6709\u9650\u3002", "method": "\u63d0\u51faFRIT\u65b9\u6cd5\uff1a1\uff09\u901a\u8fc7\u5728\u6a21\u578b\u751f\u6210\u7684\u601d\u7ef4\u94fe\u4e2d\u5bf9\u5355\u4e2a\u63a8\u7406\u6b65\u9aa4\u8fdb\u884c\u5e72\u9884\uff0c\u751f\u6210\u5408\u6210\u8bad\u7ec3\u6570\u636e\uff1b2\uff09\u521b\u5efa\u5fe0\u5b9e/\u4e0d\u5fe0\u5b9e\u63a8\u7406\u5bf9\u6765\u7a81\u51fa\u63a8\u7406\u5931\u6548\u7684\u60c5\u51b5\uff1b3\uff09\u5e94\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\u6765\u6559\u5bfc\u6a21\u578b\u504f\u597d\u56e0\u679c\u4e00\u81f4\u7684\u63a8\u7406\u8def\u5f84\u3002", "result": "\u5728Qwen3-8B\u548cMistral-7B-v0.1\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0cFRIT\u4f7fMistral\u5728GSM8K\u4efb\u52a1\u4e0a\u7684\u5fe0\u5b9e\u63a8\u7406\u63d0\u9ad8\u4e863.4\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u51c6\u786e\u6027\u63d0\u9ad8\u4e867.6\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "FRIT\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u65e0\u76d1\u7763\u7684\u65b9\u6cd5\u6765\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4ea7\u751f\u66f4\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u7684\u63a8\u7406\uff0c\u89e3\u51b3\u4e86\u63a8\u7406\u6027\u80fd\u4e0e\u53ef\u4fe1\u5ea6\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\u3002"}}
{"id": "2509.14057", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2509.14057", "abs": "https://arxiv.org/abs/2509.14057", "authors": ["Riccardo Zanardelli"], "title": "Machines are more productive than humans until they aren't, and vice versa", "comment": null, "summary": "With the growth of artificial skills, organizations may increasingly confront\nwith the problem of optimizing skill policy decisions guided by economic\nprinciples. This paper addresses the underlying complexity of this challenge by\ndeveloping an in-silico framework based on Monte Carlo simulations grounded in\nempirical realism to analyze the economic impact of human and machine skills,\nindividually or jointly deployed, in the execution of tasks presenting varying\nlevels of complexity. Our results provide quantitative support for the\nestablished notions that automation tends to be the most economically-effective\nstrategy for tasks characterized by low-to-medium generalization difficulty,\nwhile automation struggles to match the economic utility of human skills in\nmore complex scenarios. Critically, our simulations highlight that combining\nhuman and machine skills can be the most effective strategy when a high level\nof generalization is required, but only if genuine augmentation is achieved. In\ncontrast, when failing to realize this synergy, the human-machine policy is\nseverely penalized by the inherent costs of its dual skill structure, causing\nit to destroy value and becoming the worst choice from an economic perspective.\nThe takeaway for decision-makers is unambiguous: simply allocating human and\nmachine skills to a task is insufficient, and a human-machine skill policy is\nneither a silver-bullet solution nor a low-risk compromise. Rather, it is a\ncritical opportunity to boost competitiveness that demands a strong\norganizational commitment to enabling augmentation. Also, our findings show\nthat improving the cost-effectiveness of machine skills over time, while\nuseful, does not replace the fundamental need to focus on achieving\naugmentation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u5206\u6790\u4eba\u673a\u6280\u80fd\u7ec4\u5408\u7684\u7ecf\u6d4e\u6548\u76ca\uff0c\u53d1\u73b0\u81ea\u52a8\u5316\u5728\u4f4e\u4e2d\u590d\u6742\u5ea6\u4efb\u52a1\u4e2d\u6700\u7ecf\u6d4e\uff0c\u800c\u9ad8\u590d\u6742\u5ea6\u4efb\u52a1\u9700\u8981\u771f\u6b63\u7684\u4eba\u673a\u534f\u540c\u624d\u80fd\u521b\u9020\u4ef7\u503c\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7684\u53d1\u5c55\uff0c\u7ec4\u7ec7\u9700\u8981\u57fa\u4e8e\u7ecf\u6d4e\u539f\u5219\u4f18\u5316\u6280\u80fd\u7b56\u7565\u51b3\u7b56\uff0c\u4f46\u4eba\u673a\u6280\u80fd\u7ec4\u5408\u7684\u590d\u6742\u7ecf\u6d4e\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u91cf\u5316\u5206\u6790\u3002", "method": "\u57fa\u4e8e\u7ecf\u9a8c\u73b0\u5b9e\u7684\u8499\u7279\u5361\u6d1b\u6a21\u62df\u6846\u67b6\uff0c\u5206\u6790\u4e0d\u540c\u590d\u6742\u5ea6\u4efb\u52a1\u4e2d\u4eba\u7c7b\u6280\u80fd\u3001\u673a\u5668\u6280\u80fd\u53ca\u5176\u7ec4\u5408\u7684\u7ecf\u6d4e\u5f71\u54cd\u3002", "result": "\u81ea\u52a8\u5316\u5728\u4f4e\u4e2d\u590d\u6742\u5ea6\u4efb\u52a1\u4e2d\u6700\u7ecf\u6d4e\u6709\u6548\uff1b\u9ad8\u590d\u6742\u5ea6\u4efb\u52a1\u4e2d\u5355\u7eaf\u81ea\u52a8\u5316\u65e0\u6cd5\u5339\u654c\u4eba\u7c7b\u6280\u80fd\uff1b\u53ea\u6709\u5b9e\u73b0\u771f\u6b63\u589e\u5f3a\u7684\u4eba\u673a\u534f\u540c\u624d\u80fd\u5728\u9700\u8981\u9ad8\u5ea6\u6cdb\u5316\u7684\u573a\u666f\u4e2d\u6210\u4e3a\u6700\u4f18\u7b56\u7565\u3002", "conclusion": "\u4eba\u673a\u6280\u80fd\u7b56\u7565\u4e0d\u662f\u4e07\u80fd\u89e3\u51b3\u65b9\u6848\uff0c\u800c\u662f\u9700\u8981\u7ec4\u7ec7\u5f3a\u70c8\u627f\u8bfa\u5b9e\u73b0\u771f\u6b63\u589e\u5f3a\u7684\u5173\u952e\u673a\u4f1a\uff0c\u5355\u7eaf\u5206\u914d\u4eba\u673a\u8d44\u6e90\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u7ecf\u6d4e\u6548\u76ca\u3002"}}
{"id": "2509.13348", "categories": ["cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13348", "abs": "https://arxiv.org/abs/2509.13348", "authors": ["LearnLM Team", "Google", ":", "Amy Wang", "Anna Iurchenko", "Anisha Choudhury", "Alicia Mart\u00edn", "Amir Globerson", "Avinatan Hassidim", "Ay\u00e7a \u00c7akmakli", "Ayelet Shasha Evron", "Charlie Yang", "Courtney Heldreth", "Diana Akrong", "Gal Elidan", "Hairong Mu", "Ian Li", "Ido Cohen", "Katherine Chou", "Komal Singh", "Lev Borovoi", "Lidan Hackmon", "Lior Belinsky", "Michael Fink", "Niv Efron", "Preeti Singh", "Rena Levitt", "Shashank Agarwal", "Shay Sharon", "Tracey Lee-Joe", "Xiaohong Hao", "Yael Gold-Zamir", "Yael Haramaty", "Yishay Mor", "Yoav Bar Sinai", "Yossi Matias"], "title": "Towards an AI-Augmented Textbook", "comment": null, "summary": "Textbooks are a cornerstone of education, but they have a fundamental\nlimitation: they are a one-size-fits-all medium. Any new material or\nalternative representation requires arduous human effort, so that textbooks\ncannot be adapted in a scalable manner. We present an approach for transforming\nand augmenting textbooks using generative AI, adding layers of multiple\nrepresentations and personalization while maintaining content integrity and\nquality. We refer to the system built with this approach as Learn Your Way. We\nreport pedagogical evaluations of the different transformations and\naugmentations, and present the results of a a randomized control trial,\nhighlighting the advantages of learning with Learn Your Way over regular\ntextbook usage.", "AI": {"tldr": "\u4f7f\u7528\u751f\u6210\u5f0fAI\u5c06\u4f20\u7edf\u6559\u79d1\u4e66\u8f6c\u6362\u4e3a\u4e2a\u6027\u5316\u3001\u591a\u8868\u5f81\u7684\u5b66\u4e60\u6750\u6599\uff0c\u901a\u8fc7\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u8bc1\u660e\u6bd4\u4f20\u7edf\u6559\u79d1\u4e66\u5b66\u4e60\u6548\u679c\u66f4\u597d", "motivation": "\u4f20\u7edf\u6559\u79d1\u4e66\u5b58\u5728\u4e00\u5200\u5207\u7684\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u6839\u636e\u5b66\u4e60\u8005\u9700\u6c42\u8fdb\u884c\u4e2a\u6027\u5316\u8c03\u6574\u548c\u591a\u6837\u5316\u8868\u5f81\uff0c\u9700\u8981\u4eba\u5de5\u5927\u91cf\u5de5\u4f5c\u624d\u80fd\u66f4\u65b0\u5185\u5bb9", "method": "\u5f00\u53d1Learn Your Way\u7cfb\u7edf\uff0c\u5229\u7528\u751f\u6210\u5f0fAI\u6280\u672f\u5bf9\u6559\u79d1\u4e66\u5185\u5bb9\u8fdb\u884c\u8f6c\u6362\u548c\u589e\u5f3a\uff0c\u6dfb\u52a0\u591a\u5c42\u8868\u5f81\u548c\u4e2a\u6027\u5316\u5185\u5bb9\uff0c\u540c\u65f6\u4fdd\u6301\u5185\u5bb9\u5b8c\u6574\u6027\u548c\u8d28\u91cf", "result": "\u901a\u8fc7\u6559\u5b66\u8bc4\u4f30\u548c\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\uff0c\u8bc1\u660eLearn Your Way\u7cfb\u7edf\u76f8\u6bd4\u4f20\u7edf\u6559\u79d1\u4e66\u4f7f\u7528\u5177\u6709\u663e\u8457\u4f18\u52bf", "conclusion": "\u751f\u6210\u5f0fAI\u53ef\u4ee5\u6709\u6548\u5730\u5c06\u4f20\u7edf\u6559\u79d1\u4e66\u8f6c\u6362\u4e3a\u4e2a\u6027\u5316\u3001\u591a\u8868\u5f81\u7684\u5b66\u4e60\u6750\u6599\uff0c\u663e\u8457\u63d0\u5347\u5b66\u4e60\u6548\u679c\uff0c\u4e3a\u6559\u80b2\u5185\u5bb9\u4e2a\u6027\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u65b9\u6848"}}
{"id": "2509.13383", "categories": ["cs.SY"], "pdf": "https://arxiv.org/pdf/2509.13383", "abs": "https://arxiv.org/abs/2509.13383", "authors": ["Boliang Lin", "Xiang Li", "Yuxue Gu", "Dishen Lu"], "title": "Location and allocation problem of high-speed train maintenance bases", "comment": null, "summary": "Maintenance bases are crucial for the safe and stable operation of high-speed\ntrains, necessitating significant financial investment for their construction\nand operation. Planning the location and task allocation of these bases in the\nvast high-speed railway network is a complex combinatorial optimization\nproblem. This paper explored the strategic planning of identifying optimal\nlocations for maintenance bases, introducing a bi-level programming model. The\nupper-level objective was to minimize the annualized total cost, including\ninvestment for new or expanding bases and total maintenance costs, while the\nlower-level focused on dispatching high-speed trains to the most suitable base\nfor maintenance tasks, thereby reducing maintenance operation dispatch costs\nunder various investment scenarios. A case study of the Northwest China\nhigh-speed rail network demonstrated the application of this model, and\nincluded the sensitivity analysis reflecting maintenance policy reforms. The\nresults showed that establishing a new base in Hami and expanding Xi'an base\ncould minimize the total annualized cost during the planning period, amounting\nto a total of 2,278.15 million RMB. This paper offers an optimization method\nfor selecting maintenance base locations that ensures reliability and\nefficiency in maintenance work as the number of trains increases in the future.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u89c4\u5212\u6a21\u578b\u6765\u4f18\u5316\u9ad8\u94c1\u7ef4\u4fee\u57fa\u5730\u7684\u9009\u5740\u548c\u4efb\u52a1\u5206\u914d\uff0c\u4ee5\u6700\u5c0f\u5316\u5e74\u5ea6\u603b\u6210\u672c\uff0c\u5305\u62ec\u65b0\u5efa/\u6269\u5efa\u57fa\u5730\u6295\u8d44\u548c\u7ef4\u4fee\u6210\u672c\u3002", "motivation": "\u9ad8\u94c1\u7ef4\u4fee\u57fa\u5730\u5bf9\u5217\u8f66\u5b89\u5168\u7a33\u5b9a\u8fd0\u884c\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5728\u5e7f\u9614\u7684\u9ad8\u94c1\u7f51\u7edc\u4e2d\u89c4\u5212\u57fa\u5730\u4f4d\u7f6e\u548c\u4efb\u52a1\u5206\u914d\u662f\u4e00\u4e2a\u590d\u6742\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u9700\u8981\u5927\u91cf\u8d44\u91d1\u6295\u5165\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u7f16\u7a0b\u6a21\u578b\uff0c\u4e0a\u5c42\u76ee\u6807\u662f\u6700\u5c0f\u5316\u5e74\u5ea6\u603b\u6210\u672c\uff08\u5305\u62ec\u65b0\u5efa/\u6269\u5efa\u57fa\u5730\u6295\u8d44\u548c\u603b\u7ef4\u4fee\u6210\u672c\uff09\uff0c\u4e0b\u5c42\u91cd\u70b9\u662f\u5c06\u9ad8\u94c1\u5217\u8f66\u8c03\u5ea6\u5230\u6700\u5408\u9002\u7684\u7ef4\u4fee\u57fa\u5730\u4ee5\u964d\u4f4e\u7ef4\u4fee\u8c03\u5ea6\u6210\u672c\u3002", "result": "\u897f\u5317\u9ad8\u94c1\u7f51\u7edc\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u5728\u54c8\u5bc6\u65b0\u5efa\u57fa\u5730\u548c\u6269\u5efa\u897f\u5b89\u57fa\u5730\u53ef\u5728\u89c4\u5212\u671f\u5185\u6700\u5c0f\u5316\u5e74\u5ea6\u603b\u6210\u672c\uff0c\u603b\u8ba122.7815\u4ebf\u5143\u4eba\u6c11\u5e01\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7ef4\u4fee\u57fa\u5730\u9009\u5740\u63d0\u4f9b\u4e86\u4f18\u5316\u65b9\u6848\uff0c\u786e\u4fdd\u5728\u672a\u6765\u5217\u8f66\u6570\u91cf\u589e\u52a0\u65f6\u7ef4\u4fee\u5de5\u4f5c\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2509.13378", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13378", "abs": "https://arxiv.org/abs/2509.13378", "authors": ["Mattias Wingren", "S\u00f6ren Andersson", "Sara Rosenberg", "Malin Andtfolk", "Susanne H\u00e4gglund", "Prashani Jayasingha Arachchige", "Linda Nyholm"], "title": "Using role-play and Hierarchical Task Analysis for designing human-robot interaction", "comment": "11 pages. This is a preprint version of the published paper in the\n  International Conference on Social Robotics:\n  https://link.springer.com/chapter/10.1007/978-981-96-3522-1_28", "summary": "We present the use of two methods we believe warrant more use than they\ncurrently have in the field of human-robot interaction: role-play and\nHierarchical Task Analysis. Some of its potential is showcased through our use\nof them in an ongoing research project which entails developing a robot\napplication meant to assist at a community pharmacy. The two methods have\nprovided us with several advantages. The role-playing provided a controlled and\nadjustable environment for understanding the customers' needs where pharmacists\ncould act as models for the robot's behavior; and the Hierarchical Task\nAnalysis ensured the behavior displayed was modelled correctly and aided\ndevelopment through facilitating co-design. Future research could focus on\ndeveloping task analysis methods especially suited for social robot\ninteraction.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u89d2\u8272\u626e\u6f14\u548c\u5c42\u6b21\u4efb\u52a1\u5206\u6790\u4e24\u79cd\u65b9\u6cd5\u5728\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u7684\u5e94\u7528\u4ef7\u503c\uff0c\u901a\u8fc7\u5728\u793e\u533a\u836f\u623f\u673a\u5668\u4eba\u5f00\u53d1\u9879\u76ee\u4e2d\u7684\u5b9e\u8df5\u5c55\u793a\u4e86\u5176\u4f18\u52bf\u3002", "motivation": "\u5f53\u524d\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u5bf9\u89d2\u8272\u626e\u6f14\u548c\u5c42\u6b21\u4efb\u52a1\u5206\u6790\u65b9\u6cd5\u7684\u4f7f\u7528\u4e0d\u8db3\uff0c\u9700\u8981\u63a2\u7d22\u8fd9\u4e9b\u65b9\u6cd5\u5728\u793e\u4ea4\u673a\u5668\u4eba\u4ea4\u4e92\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u89d2\u8272\u626e\u6f14\u65b9\u6cd5\u521b\u5efa\u53ef\u63a7\u53ef\u8c03\u8282\u7684\u73af\u5883\u6765\u7406\u89e3\u7528\u6237\u9700\u6c42\uff0c\u4f7f\u7528\u5c42\u6b21\u4efb\u52a1\u5206\u6790\u786e\u4fdd\u884c\u4e3a\u5efa\u6a21\u7684\u6b63\u786e\u6027\u5e76\u4fc3\u8fdb\u534f\u540c\u8bbe\u8ba1\u3002", "result": "\u89d2\u8272\u626e\u6f14\u8ba9\u836f\u5242\u5e08\u53ef\u4ee5\u4f5c\u4e3a\u673a\u5668\u4eba\u884c\u4e3a\u7684\u6a21\u578b\uff0c\u5c42\u6b21\u4efb\u52a1\u5206\u6790\u786e\u4fdd\u4e86\u884c\u4e3a\u5efa\u6a21\u7684\u6b63\u786e\u6027\u5e76\u4fc3\u8fdb\u4e86\u5f00\u53d1\u8fc7\u7a0b\u7684\u534f\u540c\u8bbe\u8ba1\u3002", "conclusion": "\u8fd9\u4e24\u79cd\u65b9\u6cd5\u5728\u4eba\u673a\u4ea4\u4e92\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u672a\u6765\u7814\u7a76\u5e94\u4e13\u6ce8\u4e8e\u5f00\u53d1\u7279\u522b\u9002\u5408\u793e\u4ea4\u673a\u5668\u4eba\u4ea4\u4e92\u7684\u4efb\u52a1\u5206\u6790\u65b9\u6cd5\u3002"}}
{"id": "2509.13339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13339", "abs": "https://arxiv.org/abs/2509.13339", "authors": ["Ming Jin", "Hyunin Lee"], "title": "Position: AI Safety Must Embrace an Antifragile Perspective", "comment": null, "summary": "This position paper contends that modern AI research must adopt an\nantifragile perspective on safety -- one in which the system's capacity to\nguarantee long-term AI safety such as handling rare or out-of-distribution\n(OOD) events expands over time. Conventional static benchmarks and single-shot\nrobustness tests overlook the reality that environments evolve and that models,\nif left unchallenged, can drift into maladaptation (e.g., reward hacking,\nover-optimization, or atrophy of broader capabilities). We argue that an\nantifragile approach -- Rather than striving to rapidly reduce current\nuncertainties, the emphasis is on leveraging those uncertainties to better\nprepare for potentially greater, more unpredictable uncertainties in the future\n-- is pivotal for the long-term reliability of open-ended ML systems. In this\nposition paper, we first identify key limitations of static testing, including\nscenario diversity, reward hacking, and over-alignment. We then explore the\npotential of antifragile solutions to manage rare events. Crucially, we\nadvocate for a fundamental recalibration of the methods used to measure,\nbenchmark, and continually improve AI safety over the long term, complementing\nexisting robustness approaches by providing ethical and practical guidelines\ntowards fostering an antifragile AI safety community.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20AI\u5b89\u5168\u7814\u7a76\u5e94\u91c7\u7528\u53cd\u8106\u5f31\u6027\u89c6\u89d2\uff0c\u901a\u8fc7\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u6765\u589e\u5f3a\u7cfb\u7edf\u5e94\u5bf9\u7f55\u89c1\u548c\u5206\u5e03\u5916\u4e8b\u4ef6\u7684\u80fd\u529b\uff0c\u800c\u975e\u4ec5\u4ec5\u8ffd\u6c42\u9759\u6001\u6d4b\u8bd5\u548c\u5373\u65f6\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e00\u6b21\u6027\u9c81\u68d2\u6027\u6d4b\u8bd5\u65e0\u6cd5\u5e94\u5bf9\u73af\u5883\u6f14\u53d8\u548c\u6a21\u578b\u6f02\u79fb\u95ee\u9898\uff08\u5982\u5956\u52b1\u9ed1\u5ba2\u3001\u8fc7\u5ea6\u4f18\u5316\u7b49\uff09\uff0c\u9700\u8981\u5efa\u7acb\u80fd\u591f\u968f\u65f6\u95f4\u6269\u5c55\u5b89\u5168\u4fdd\u8bc1\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u53cd\u8106\u5f31\u6027\u65b9\u6cd5\u6846\u67b6\uff0c\u5f3a\u8c03\u5229\u7528\u5f53\u524d\u4e0d\u786e\u5b9a\u6027\u6765\u4e3a\u672a\u6765\u66f4\u5927\u4e0d\u786e\u5b9a\u6027\u505a\u51c6\u5907\uff0c\u5305\u62ec\u91cd\u65b0\u6821\u51c6AI\u5b89\u5168\u6d4b\u91cf\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u6301\u7eed\u6539\u8fdb\u7684\u65b9\u6cd5\u8bba\u3002", "result": "\u8bc6\u522b\u4e86\u9759\u6001\u6d4b\u8bd5\u7684\u5173\u952e\u5c40\u9650\uff08\u573a\u666f\u591a\u6837\u6027\u4e0d\u8db3\u3001\u5956\u52b1\u9ed1\u5ba2\u3001\u8fc7\u5ea6\u5bf9\u9f50\u7b49\uff09\uff0c\u5e76\u63a2\u7d22\u4e86\u53cd\u8106\u5f31\u6027\u89e3\u51b3\u65b9\u6848\u7ba1\u7406\u7f55\u89c1\u4e8b\u4ef6\u7684\u6f5c\u529b\u3002", "conclusion": "\u53cd\u8106\u5f31\u6027\u65b9\u6cd5\u5bf9\u4e8e\u5f00\u653e\u7aef\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u957f\u671f\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5efa\u7acb\u76f8\u5e94\u7684\u4f26\u7406\u548c\u5b9e\u8df5\u6307\u5357\u6765\u57f9\u80b2\u53cd\u8106\u5f31\u7684AI\u5b89\u5168\u793e\u533a\u3002"}}
{"id": "2509.14102", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2509.14102", "abs": "https://arxiv.org/abs/2509.14102", "authors": ["Felicia Nguyen"], "title": "Incentivizing High Quality Entrants When Creators Are Strategic", "comment": null, "summary": "We study how a platform should design early exposure and rewards when\ncreators strategically choose quality before release. A short testing window\nwith a pass/fail bar induces a pass probability, the slope of which is the key\nsufficient statistic for incentives. We derive three main results. First, a\nclosed-form ``implementability bounty'' can perfectly align creator and\nplatform objectives, correcting for incomplete revenue sharing. Second,\nfront-loading guaranteed impressions is the most effective way to strengthen\nincentives for a given attention budget. Third, when impression and cash\nbudgets are constrained, the optimal policy follows an equal-marginal-value\nrule based on the prize spread and certain exposure. We map realistic ranking\nengines (e.g., Thompson sampling) into the model's parameters and provide\ntelemetry-based estimators. The framework is simple to operationalize and\noffers a direct, managerially interpretable solution for platforms to solve the\ncreator cold-start problem and cultivate high-quality supply.", "AI": {"tldr": "\u5e73\u53f0\u901a\u8fc7\u8bbe\u8ba1\u65e9\u671f\u66dd\u5149\u548c\u5956\u52b1\u673a\u5236\uff0c\u89e3\u51b3\u521b\u4f5c\u8005\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u5229\u7528\u6d4b\u8bd5\u7a97\u53e3\u548c\u5956\u52b1\u673a\u5236\u5b8c\u7f8e\u5bf9\u9f50\u521b\u4f5c\u8005\u4e0e\u5e73\u53f0\u76ee\u6807", "motivation": "\u7814\u7a76\u5e73\u53f0\u5982\u4f55\u901a\u8fc7\u65e9\u671f\u66dd\u5149\u548c\u5956\u52b1\u8bbe\u8ba1\u6765\u6fc0\u52b1\u521b\u4f5c\u8005\u5728\u53d1\u5e03\u524d\u6218\u7565\u6027\u5730\u9009\u62e9\u5185\u5bb9\u8d28\u91cf\uff0c\u89e3\u51b3\u521b\u4f5c\u8005\u51b7\u542f\u52a8\u95ee\u9898\u5e76\u57f9\u80b2\u9ad8\u8d28\u91cf\u5185\u5bb9\u4f9b\u7ed9", "method": "\u5efa\u7acb\u7406\u8bba\u6a21\u578b\u5206\u6790\u6d4b\u8bd5\u7a97\u53e3\u548c\u901a\u8fc7/\u5931\u8d25\u673a\u5236\uff0c\u63a8\u5bfc\u51fa\"\u53ef\u5b9e\u65bd\u6027\u5956\u52b1\"\u95ed\u5f0f\u89e3\uff0c\u63d0\u51fa\u57fa\u4e8e\u5956\u54c1\u4ef7\u5dee\u548c\u786e\u5b9a\u66dd\u5149\u5ea6\u7684\u7b49\u8fb9\u9645\u4ef7\u503c\u89c4\u5219\u6700\u4f18\u7b56\u7565", "result": "\u5f97\u51fa\u4e09\u4e2a\u4e3b\u8981\u7ed3\u679c\uff1a\u5b8c\u7f8e\u5bf9\u9f50\u76ee\u6807\u7684\u5956\u52b1\u673a\u5236\u3001\u524d\u7f6e\u4fdd\u8bc1\u66dd\u5149\u7684\u6700\u6709\u6548\u6fc0\u52b1\u65b9\u5f0f\u3001\u4ee5\u53ca\u9884\u7b97\u7ea6\u675f\u4e0b\u7684\u6700\u4f18\u7b56\u7565\u89c4\u5219", "conclusion": "\u8be5\u6846\u67b6\u6613\u4e8e\u64cd\u4f5c\u5b9e\u65bd\uff0c\u4e3a\u5e73\u53f0\u63d0\u4f9b\u4e86\u76f4\u63a5\u4e14\u6613\u4e8e\u7ba1\u7406\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u521b\u4f5c\u8005\u51b7\u542f\u52a8\u95ee\u9898\u5e76\u57f9\u517b\u9ad8\u8d28\u91cf\u5185\u5bb9\u4f9b\u7ed9"}}
{"id": "2509.13355", "categories": ["cs.CY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13355", "abs": "https://arxiv.org/abs/2509.13355", "authors": ["Dietmar Offenhuber"], "title": "Synthetic Data and the Shifting Ground of Truth", "comment": "Talk presented at the Society for the Social Studies of Science (4S)\n  2025 meeting in Seattle, Sept. 3, 2025", "summary": "The emergence of synthetic data for privacy protection, training data\ngeneration, or simply convenient access to quasi-realistic data in any shape or\nvolume complicates the concept of ground truth. Synthetic data mimic real-world\nobservations, but do not refer to external features. This lack of a\nrepresentational relationship, however, not prevent researchers from using\nsynthetic data as training data for AI models and ground truth repositories. It\nis claimed that the lack of data realism is not merely an acceptable tradeoff,\nbut often leads to better model performance than realistic data: compensate for\nknown biases, prevent overfitting and support generalization, and make the\nmodels more robust in dealing with unexpected outliers. Indeed, injecting noisy\nand outright implausible data into training sets can be beneficial for the\nmodel. This greatly complicates usual assumptions based on which\nrepresentational accuracy determines data fidelity (garbage in - garbage out).\nFurthermore, ground truth becomes a self-referential affair, in which the\nlabels used as a ground truth repository are themselves synthetic products of a\ngenerative model and as such not connected to real-world observations. My paper\nexamines how ML researchers and practitioners bootstrap ground truth under such\nparadoxical circumstances without relying on the stable ground of\nrepresentation and real-world reference. It will also reflect on the broader\nimplications of a shift from a representational to what could be described as a\nmimetic or iconic concept of data.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5408\u6210\u6570\u636e\u5982\u4f55\u98a0\u8986\u4f20\u7edf\"\u5783\u573e\u8fdb\u5783\u573e\u51fa\"\u7684\u6570\u636e\u4fdd\u771f\u5ea6\u5047\u8bbe\uff0c\u5206\u6790\u5728\u7f3a\u4e4f\u771f\u5b9e\u4e16\u754c\u53c2\u7167\u7684\u60c5\u51b5\u4e0b\u673a\u5668\u5b66\u4e60\u5982\u4f55\u6784\u5efaground truth\uff0c\u5e76\u53cd\u601d\u4ece\u8868\u5f81\u6027\u6570\u636e\u5411\u6a21\u4eff\u6027\u6570\u636e\u7684\u6982\u5ff5\u8f6c\u53d8\u3002", "motivation": "\u968f\u7740\u5408\u6210\u6570\u636e\u5728\u9690\u79c1\u4fdd\u62a4\u3001\u8bad\u7ec3\u6570\u636e\u751f\u6210\u7b49\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f20\u7edf\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u53c2\u7167\u7684ground truth\u6982\u5ff5\u53d7\u5230\u6311\u6218\u3002\u4f5c\u8005\u65e8\u5728\u7814\u7a76\u5728\u7f3a\u4e4f\u8868\u5f81\u5173\u7cfb\u7684\u60c5\u51b5\u4e0b\uff0cML\u7814\u7a76\u8005\u5982\u4f55\u5728\u8fd9\u79cd\u6096\u8bba\u6027\u73af\u5883\u4e2d\u6784\u5efaground truth\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u8003\u5bdf\u5408\u6210\u6570\u636e\u5728ML\u8bad\u7ec3\u4e2d\u7684\u4f7f\u7528\u5b9e\u8df5\uff0c\u5206\u6790\u7f3a\u4e4f\u771f\u5b9e\u4e16\u754c\u53c2\u7167\u7684\u5408\u6210\u6570\u636e\u5982\u4f55\u88ab\u7528\u4f5cground truth\uff0c\u5e76\u53cd\u601d\u6570\u636e\u6982\u5ff5\u4ece\u8868\u5f81\u6027\u5411\u6a21\u4eff\u6027\u7684\u8f6c\u53d8\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5408\u6210\u6570\u636e\u867d\u7136\u7f3a\u4e4f\u771f\u5b9e\u4e16\u754c\u7684\u8868\u5f81\u5173\u7cfb\uff0c\u4f46\u901a\u8fc7\u8865\u507f\u5df2\u77e5\u504f\u5dee\u3001\u9632\u6b62\u8fc7\u62df\u5408\u3001\u652f\u6301\u6cdb\u5316\u7b49\u65b9\u5f0f\uff0c\u5f80\u5f80\u80fd\u5e26\u6765\u6bd4\u771f\u5b9e\u6570\u636e\u66f4\u597d\u7684\u6a21\u578b\u6027\u80fd\uff0c\u751a\u81f3\u6ce8\u5165\u566a\u58f0\u548c\u4e0d\u53ef\u4fe1\u6570\u636e\u4e5f\u6709\u76ca\u4e8e\u6a21\u578b\u9c81\u68d2\u6027\u3002", "conclusion": "\u5408\u6210\u6570\u636e\u7684\u5174\u8d77\u5bfc\u81f4ground truth\u6210\u4e3a\u81ea\u6211\u6307\u6d89\u7684\u4e8b\u52a1\uff0c\u6807\u7b7e\u672c\u8eab\u4e5f\u662f\u751f\u6210\u6a21\u578b\u7684\u5408\u6210\u4ea7\u7269\u3002\u8fd9\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u4e86\u6570\u636e\u4fdd\u771f\u5ea6\u7684\u4f20\u7edf\u5047\u8bbe\uff0c\u6807\u5fd7\u7740\u4ece\u8868\u5f81\u6027\u6570\u636e\u6982\u5ff5\u5411\u6a21\u4eff\u6027\u6570\u636e\u6982\u5ff5\u7684\u8303\u5f0f\u8f6c\u53d8\u3002"}}
{"id": "2509.13392", "categories": ["cs.SY", "cs.GT"], "pdf": "https://arxiv.org/pdf/2509.13392", "abs": "https://arxiv.org/abs/2509.13392", "authors": ["Demyan Yarmoshik", "Igor Ignashin", "Ekaterina Sikacheva", "Alexander Gasnikov"], "title": "Modeling skiers flows via Wardrope equilibrium in closed capacitated networks", "comment": null, "summary": "We propose an equilibrium model of ski resorts where users are assigned to\ncycles in a closed network. As queues form on lifts with limited capacity, we\nderive an efficient way to find waiting times via convex optimization. The\nequilibrium problem is formulated as a variational inequality, and numerical\nexperiments show that it can be solved using standard algorithms.", "AI": {"tldr": "\u63d0\u51fa\u6ed1\u96ea\u573a\u5747\u8861\u6a21\u578b\uff0c\u7528\u6237\u88ab\u5206\u914d\u5230\u5c01\u95ed\u7f51\u7edc\u4e2d\u7684\u5faa\u73af\u8def\u7ebf\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u8ba1\u7b97\u6709\u9650\u5bb9\u91cf\u7f06\u8f66\u5f62\u6210\u7684\u6392\u961f\u7b49\u5f85\u65f6\u95f4", "motivation": "\u89e3\u51b3\u6ed1\u96ea\u573a\u4e2d\u7531\u4e8e\u7f06\u8f66\u5bb9\u91cf\u9650\u5236\u5bfc\u81f4\u7684\u6392\u961f\u95ee\u9898\uff0c\u5efa\u7acb\u6570\u5b66\u6a21\u578b\u6765\u9884\u6d4b\u548c\u4f18\u5316\u7528\u6237\u7684\u7b49\u5f85\u65f6\u95f4", "method": "\u5c06\u5747\u8861\u95ee\u9898\u8868\u8ff0\u4e3a\u53d8\u5206\u4e0d\u7b49\u5f0f\uff0c\u4f7f\u7528\u51f8\u4f18\u5316\u65b9\u6cd5\u63a8\u5bfc\u7b49\u5f85\u65f6\u95f4\u8ba1\u7b97\uff0c\u5e76\u901a\u8fc7\u6807\u51c6\u7b97\u6cd5\u8fdb\u884c\u6570\u503c\u5b9e\u9a8c\u6c42\u89e3", "result": "\u5f00\u53d1\u51fa\u9ad8\u6548\u8ba1\u7b97\u7b49\u5f85\u65f6\u95f4\u7684\u65b9\u6cd5\uff0c\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6a21\u578b\u53ef\u4ee5\u4f7f\u7528\u6807\u51c6\u7b97\u6cd5\u6709\u6548\u6c42\u89e3", "conclusion": "\u63d0\u51fa\u7684\u5747\u8861\u6a21\u578b\u80fd\u591f\u6709\u6548\u5904\u7406\u6ed1\u96ea\u573a\u7f51\u7edc\u4e2d\u7684\u6392\u961f\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u8fd0\u8425\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u548c\u8ba1\u7b97\u5de5\u5177"}}
{"id": "2509.13380", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.13380", "abs": "https://arxiv.org/abs/2509.13380", "authors": ["Alejandro D. Mousist"], "title": "ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy", "comment": "This preprint presents ASTREA, a multi-agent architecture combining\n  LLM-guided semantic modulation with reinforcement learning for autonomous\n  satellite operations. The system is validated in hardware orbital\n  environments", "summary": "This paper presents ASTREA, the first agentic system deployed on\nflight-heritage hardware (TRL 9) for autonomous spacecraft operations. Using\nthermal control as a representative use case, we integrate a\nresource-constrained Large Language Model (LLM) agent with a reinforcement\nlearning controller in an asynchronous architecture tailored for\nspace-qualified platforms. Ground experiments show that LLM-guided supervision\nimproves thermal stability and reduces violations, confirming the feasibility\nof combining semantic reasoning with adaptive control under hardware\nconstraints. However, on-orbit validation aboard the International Space\nStation (ISS) reveals performance degradation caused by inference latency\nmismatched with the rapid thermal cycles characteristic of Low Earth Orbit\n(LEO) satellites. These results highlight both the opportunities and current\nlimitations of agentic LLM-based systems in real flight environments, providing\npractical design guidelines for future space autonomy.", "AI": {"tldr": "ASTREA\u662f\u9996\u4e2a\u5728\u98de\u884c\u786c\u4ef6\u4e0a\u90e8\u7f72\u7684\u81ea\u4e3b\u822a\u5929\u5668\u64cd\u4f5c\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7LLM\u4ee3\u7406\u4e0e\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\u7684\u5f02\u6b65\u67b6\u6784\u5b9e\u73b0\u70ed\u63a7\u5236\uff0c\u5730\u9762\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u63d0\u5347\u4f46\u8f68\u9053\u9a8c\u8bc1\u53d1\u73b0\u5ef6\u8fdf\u95ee\u9898\u3002", "motivation": "\u5f00\u53d1\u9996\u4e2a\u5728\u98de\u884c\u786c\u4ef6\u4e0a\u90e8\u7f72\u7684\u81ea\u4e3b\u822a\u5929\u5668\u64cd\u4f5c\u4ee3\u7406\u7cfb\u7edf\uff0c\u89e3\u51b3\u822a\u5929\u5668\u81ea\u4e3b\u64cd\u4f5c\u7684\u6280\u672f\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u592a\u7a7a\u73af\u5883\u4e2d\u7ed3\u5408\u8bed\u4e49\u63a8\u7406\u548c\u81ea\u9002\u5e94\u63a7\u5236\u3002", "method": "\u91c7\u7528\u8d44\u6e90\u53d7\u9650\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e0e\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\u7ed3\u5408\u7684\u5f02\u6b65\u67b6\u6784\uff0c\u4e13\u95e8\u4e3a\u592a\u7a7a\u8ba4\u8bc1\u5e73\u53f0\u8bbe\u8ba1\uff0c\u4ee5\u70ed\u63a7\u5236\u4f5c\u4e3a\u4ee3\u8868\u6027\u7528\u4f8b\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5730\u9762\u5b9e\u9a8c\u663e\u793aLLM\u5f15\u5bfc\u7684\u76d1\u7763\u63d0\u9ad8\u4e86\u70ed\u7a33\u5b9a\u6027\u5e76\u51cf\u5c11\u4e86\u8fdd\u89c4\uff0c\u4f46\u5728\u56fd\u9645\u7a7a\u95f4\u7ad9\u7684\u8f68\u9053\u9a8c\u8bc1\u4e2d\uff0c\u7531\u4e8e\u63a8\u7406\u5ef6\u8fdf\u4e0e\u4f4e\u5730\u7403\u8f68\u9053\u5feb\u901f\u70ed\u5faa\u73af\u4e0d\u5339\u914d\uff0c\u51fa\u73b0\u4e86\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u7cfb\u7edf\u5728\u771f\u5b9e\u98de\u884c\u73af\u5883\u4e2d\u7684\u673a\u9047\u548c\u5f53\u524d\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u592a\u7a7a\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bbe\u8ba1\u6307\u5bfc\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5ef6\u8fdf\u5339\u914d\u95ee\u9898\u65b9\u9762\u3002"}}
{"id": "2509.13341", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13341", "abs": "https://arxiv.org/abs/2509.13341", "authors": ["Ahmet H. G\u00fczel", "Matthew Thomas Jackson", "Jarek Luca Liesen", "Tim Rockt\u00e4schel", "Jakob Nicolaus Foerster", "Ilija Bogunovic", "Jack Parker-Holder"], "title": "Imagined Autocurricula", "comment": null, "summary": "Training agents to act in embodied environments typically requires vast\ntraining data or access to accurate simulation, neither of which exists for\nmany cases in the real world. Instead, world models are emerging as an\nalternative leveraging offline, passively collected data, they make it possible\nto generate diverse worlds for training agents in simulation. In this work, we\nharness world models to generate imagined environments to train robust agents\ncapable of generalizing to novel task variations. One of the challenges in\ndoing this is ensuring the agent trains on useful generated data. We thus\npropose a novel approach, IMAC (Imagined Autocurricula), leveraging\nUnsupervised Environment Design (UED), which induces an automatic curriculum\nover generated worlds. In a series of challenging, procedurally generated\nenvironments, we show it is possible to achieve strong transfer performance on\nheld-out environments, having trained only inside a world model learned from a\nnarrower dataset. We believe this opens the path to utilizing larger-scale,\nfoundation world models for generally capable agents.", "AI": {"tldr": "\u5229\u7528\u4e16\u754c\u6a21\u578b\u751f\u6210\u60f3\u8c61\u73af\u5883\u8bad\u7ec3\u667a\u80fd\u4f53\uff0c\u901a\u8fc7IMAC\u65b9\u6cd5\u5b9e\u73b0\u81ea\u52a8\u8bfe\u7a0b\u5b66\u4e60\uff0c\u5728\u6709\u9650\u6570\u636e\u4e0b\u5b9e\u73b0\u5bf9\u65b0\u73af\u5883\u7684\u5f3a\u6cdb\u5316\u80fd\u529b", "motivation": "\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u4e2d\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u548c\u6a21\u62df\u73af\u5883\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5229\u7528\u79bb\u7ebf\u88ab\u52a8\u6570\u636e\u6784\u5efa\u4e16\u754c\u6a21\u578b\u6765\u751f\u6210\u591a\u6837\u5316\u7684\u8bad\u7ec3\u73af\u5883", "method": "\u63d0\u51faIMAC\uff08Imagined Autocurricula\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\uff08UED\uff09\u5728\u4e16\u754c\u6a21\u578b\u751f\u6210\u7684\u60f3\u8c61\u73af\u5883\u4e2d\u8bf1\u5bfc\u81ea\u52a8\u8bfe\u7a0b\u5b66\u4e60", "result": "\u5728\u7a0b\u5e8f\u751f\u6210\u7684\u73af\u5883\u4e2d\uff0c\u4ec5\u4f7f\u7528\u8f83\u7a84\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u4e16\u754c\u6a21\u578b\u5c31\u80fd\u5728\u4fdd\u7559\u6d4b\u8bd5\u73af\u5883\u4e2d\u5b9e\u73b0\u5f3a\u5927\u7684\u8fc1\u79fb\u6027\u80fd", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5229\u7528\u5927\u89c4\u6a21\u57fa\u7840\u4e16\u754c\u6a21\u578b\u8bad\u7ec3\u901a\u7528\u667a\u80fd\u4f53\u5f00\u8f9f\u4e86\u65b0\u8def\u5f84"}}
{"id": "2509.14116", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2509.14116", "abs": "https://arxiv.org/abs/2509.14116", "authors": ["Celine Bonnet", "Fabrice Etile", "Sebastien Lecocq"], "title": "Minimum pricing or volumetric taxation? Quantity, quality and competition effects of price regulations in alcohol markets", "comment": "Main Text: 52 pages; 11 Tables", "summary": "Reforming alcohol price regulations in wine-producing countries is\nchallenging, as current price regulations reflect the alignment of cultural\npreferences with economic interests rather than public health concerns. We\nevaluate and compare the impact of counterfactual alcohol pricing policies on\nconsumer behaviors, firms, and markets in France. We develop a micro-founded\npartial equilibrium model that accounts for consumer preferences over purchase\nvolumes across alcohol categories and over product quality within categories,\nand for firms' strategic price-setting. After calibration on household scanner\ndata, we compare the impacts of replacing current taxes by ethanol-based\nvolumetric taxes with a minimum unit price (MUP) policy of 0.50 Euro per\nstandard drink. The results show that the MUP in addition to the current tax\noutperforms a tax reform in reducing ethanol purchases (-15% vs. -10% for\nprogressive taxation), especially among heavy drinking households (-17%). The\nMUP increases the profits of small and medium wine firms (+39%) while\ndecreasing the profits of large manufacturers and retailers (-39%) and\nmaintaining tax revenues stable. The results support the MUP as a targeted\nstrategy to reduce harmful consumption while benefiting small and medium wine\nproducers. This study provides ex-ante evidence that is crucial for alcohol\npricing policies in wine-producing countries.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u6cd5\u56fd\u9152\u7cbe\u5b9a\u4ef7\u653f\u7b56\u6539\u9769\uff0c\u53d1\u73b0\u6700\u4f4e\u5355\u4f4d\u4ef7\u683c\u653f\u7b56(MUP)\u6bd4\u4e59\u9187\u7a0e\u6539\u9769\u66f4\u80fd\u6709\u6548\u51cf\u5c11\u9152\u7cbe\u6d88\u8d39\uff0c\u7279\u522b\u662f\u91cd\u5ea6\u996e\u9152\u5bb6\u5ead\uff0c\u540c\u65f6\u6709\u5229\u4e8e\u4e2d\u5c0f\u8461\u8404\u9152\u751f\u4ea7\u5546\u3002", "motivation": "\u8461\u8404\u9152\u751f\u4ea7\u56fd\u7684\u9152\u7cbe\u4ef7\u683c\u76d1\u7ba1\u6539\u9769\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u5f53\u524d\u4ef7\u683c\u653f\u7b56\u66f4\u591a\u53cd\u6620\u6587\u5316\u504f\u597d\u4e0e\u7ecf\u6d4e\u5229\u76ca\u7684\u7ed3\u5408\uff0c\u800c\u975e\u516c\u5171\u5065\u5eb7\u8003\u91cf\u3002\u9700\u8981\u8bc4\u4f30\u4e0d\u540c\u5b9a\u4ef7\u653f\u7b56\u5bf9\u6d88\u8d39\u8005\u884c\u4e3a\u3001\u4f01\u4e1a\u548c\u5e02\u573a\u7684\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u5fae\u89c2\u57fa\u7840\u7684\u5c40\u90e8\u5747\u8861\u6a21\u578b\uff0c\u8003\u8651\u6d88\u8d39\u8005\u5bf9\u4e0d\u540c\u9152\u7cbe\u7c7b\u522b\u8d2d\u4e70\u91cf\u548c\u4ea7\u54c1\u8d28\u91cf\u7684\u504f\u597d\uff0c\u4ee5\u53ca\u4f01\u4e1a\u7684\u6218\u7565\u5b9a\u4ef7\u884c\u4e3a\u3002\u4f7f\u7528\u5bb6\u5ead\u626b\u63cf\u6570\u636e\u8fdb\u884c\u6821\u51c6\uff0c\u6bd4\u8f83\u4e59\u9187\u7a0e\u6539\u9769\u4e0e\u6700\u4f4e\u5355\u4f4d\u4ef7\u683c\u653f\u7b56\u7684\u6548\u679c\u3002", "result": "MUP\u653f\u7b56(0.50\u6b27\u5143/\u6807\u51c6\u996e\u54c1)\u5728\u51cf\u5c11\u4e59\u9187\u8d2d\u4e70\u65b9\u9762\u8868\u73b0\u66f4\u4f18(-15% vs -10%)\uff0c\u7279\u522b\u662f\u5bf9\u91cd\u5ea6\u996e\u9152\u5bb6\u5ead(-17%)\u3002MUP\u589e\u52a0\u4e2d\u5c0f\u8461\u8404\u9152\u4f01\u4e1a\u5229\u6da6(+39%)\uff0c\u964d\u4f4e\u5927\u578b\u5236\u9020\u5546\u548c\u96f6\u552e\u5546\u5229\u6da6(-39%)\uff0c\u540c\u65f6\u4fdd\u6301\u7a0e\u6536\u7a33\u5b9a\u3002", "conclusion": "MUP\u662f\u4e00\u79cd\u6709\u9488\u5bf9\u6027\u7684\u7b56\u7565\uff0c\u65e2\u80fd\u51cf\u5c11\u6709\u5bb3\u6d88\u8d39\uff0c\u53c8\u80fd\u60e0\u53ca\u4e2d\u5c0f\u8461\u8404\u9152\u751f\u4ea7\u5546\uff0c\u4e3a\u8461\u8404\u9152\u751f\u4ea7\u56fd\u7684\u9152\u7cbe\u5b9a\u4ef7\u653f\u7b56\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u524d\u77bb\u6027\u8bc1\u636e\u3002"}}
{"id": "2509.13356", "categories": ["cs.CY", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13356", "abs": "https://arxiv.org/abs/2509.13356", "authors": ["Hasin Jawad Ali", "Ilhamul Azam", "Ajwad Abrar", "Md. Kamrul Hasan", "Hasan Mahmud"], "title": "CogniAlign: Survivability-Grounded Multi-Agent Moral Reasoning for Safe and Transparent AI", "comment": null, "summary": "The challenge of aligning artificial intelligence (AI) with human values\npersists due to the abstract and often conflicting nature of moral principles\nand the opacity of existing approaches. This paper introduces CogniAlign, a\nmulti-agent deliberation framework based on naturalistic moral realism, that\ngrounds moral reasoning in survivability, defined across individual and\ncollective dimensions, and operationalizes it through structured deliberations\namong discipline-specific scientist agents. Each agent, representing\nneuroscience, psychology, sociology, and evolutionary biology, provides\narguments and rebuttals that are synthesized by an arbiter into transparent and\nempirically anchored judgments. We evaluate CogniAlign on classic and novel\nmoral questions and compare its outputs against GPT-4o using a five-part\nethical audit framework. Results show that CogniAlign consistently outperforms\nthe baseline across more than sixty moral questions, with average performance\ngains of 16.2 points in analytic quality, 14.3 points in breadth, and 28.4\npoints in depth of explanation. In the Heinz dilemma, for example, CogniAlign\nachieved an overall score of 89.2 compared to GPT-4o's 69.2, demonstrating a\ndecisive advantage in handling moral reasoning. By reducing black-box reasoning\nand avoiding deceptive alignment, CogniAlign highlights the potential of\ninterdisciplinary deliberation as a scalable pathway for safe and transparent\nAI alignment.", "AI": {"tldr": "CogniAlign\u662f\u4e00\u4e2a\u57fa\u4e8e\u81ea\u7136\u4e3b\u4e49\u9053\u5fb7\u73b0\u5b9e\u4e3b\u4e49\u7684\u591a\u667a\u80fd\u4f53\u5ba1\u8bae\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u5b66\u79d1\u4e13\u5bb6\u4ee3\u7406\u7684\u8fa9\u8bba\u6765\u63d0\u5347AI\u9053\u5fb7\u63a8\u7406\u7684\u900f\u660e\u5ea6\u548c\u8d28\u91cf\uff0c\u572860\u591a\u4e2a\u9053\u5fb7\u95ee\u9898\u4e0a\u663e\u8457\u4f18\u4e8eGPT-4o\u3002", "motivation": "\u89e3\u51b3AI\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u62bd\u8c61\u6027\u3001\u9053\u5fb7\u539f\u5219\u51b2\u7a81\u6027\u548c\u4e0d\u900f\u660e\u6027\u7b49\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u81ea\u7136\u4e3b\u4e49\u9053\u5fb7\u73b0\u5b9e\u4e3b\u4e49\uff0c\u5efa\u7acb\u591a\u667a\u80fd\u4f53\u5ba1\u8bae\u6846\u67b6\uff0c\u5305\u542b\u795e\u7ecf\u79d1\u5b66\u3001\u5fc3\u7406\u5b66\u3001\u793e\u4f1a\u5b66\u548c\u8fdb\u5316\u751f\u7269\u5b66\u7b49\u9886\u57df\u7684\u4e13\u5bb6\u4ee3\u7406\u8fdb\u884c\u7ed3\u6784\u5316\u8fa9\u8bba\uff0c\u7531\u4ef2\u88c1\u8005\u7efc\u5408\u5224\u65ad\u3002", "result": "\u572860\u591a\u4e2a\u9053\u5fb7\u95ee\u9898\u4e0a\uff0cCogniAlign\u5e73\u5747\u5728\u5206\u6790\u8d28\u91cf\u4e0a\u63d0\u534716.2\u5206\uff0c\u5e7f\u5ea6\u4e0a\u63d0\u534714.3\u5206\uff0c\u89e3\u91ca\u6df1\u5ea6\u4e0a\u63d0\u534728.4\u5206\u3002\u5728\u6d77\u56e0\u8328\u56f0\u5883\u4e2d\u5f97\u5206\u4e3a89.2\uff0c\u663e\u8457\u4f18\u4e8eGPT-4o\u768469.2\u5206\u3002", "conclusion": "CogniAlign\u901a\u8fc7\u51cf\u5c11\u9ed1\u76d2\u63a8\u7406\u548c\u907f\u514d\u6b3a\u9a97\u6027\u5bf9\u9f50\uff0c\u5c55\u793a\u4e86\u8de8\u5b66\u79d1\u5ba1\u8bae\u4f5c\u4e3a\u53ef\u6269\u5c55AI\u5b89\u5168\u5bf9\u9f50\u8def\u5f84\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.13505", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.13505", "abs": "https://arxiv.org/abs/2509.13505", "authors": ["Jaidev Gill", "Jing Shuang Li"], "title": "Identifying Network Structure of Nonlinear Dynamical Systems: Contraction and Kuramoto Oscillators", "comment": "7 pages, 4 figures, in submission", "summary": "In this work, we study the identifiability of network topologies for\nnetworked nonlinear systems when partial measurements of the nodes are taken.\nWe explore scenarios where different candidate topologies can yield similar\nmeasurements, thus limiting identifiability. To do so, we apply the contraction\ntheory framework to facilitate comparisons between candidate topologies. We\nshow that semicontraction in the observable space is a sufficient condition for\ntwo systems to become indistinguishable from one another based on partial\nmeasurements. We apply this framework to study networks of Kuramoto\noscillators, and discuss scenarios in which different topologies (both\nconnected and disconnected) become indistinguishable.", "AI": {"tldr": "\u7814\u7a76\u7f51\u7edc\u975e\u7ebf\u6027\u7cfb\u7edf\u5728\u90e8\u5206\u8282\u70b9\u6d4b\u91cf\u4e0b\u7684\u62d3\u6251\u53ef\u8bc6\u522b\u6027\uff0c\u5e94\u7528\u6536\u7f29\u7406\u8bba\u5206\u6790\u4e0d\u540c\u5019\u9009\u62d3\u6251\u4ea7\u751f\u76f8\u4f3c\u6d4b\u91cf\u7ed3\u679c\u7684\u60c5\u51b5\uff0c\u53d1\u73b0\u53ef\u89c2\u6d4b\u7a7a\u95f4\u7684\u534a\u6536\u7f29\u6027\u662f\u4e24\u4e2a\u7cfb\u7edf\u57fa\u4e8e\u90e8\u5206\u6d4b\u91cf\u65e0\u6cd5\u533a\u5206\u7684\u5145\u5206\u6761\u4ef6", "motivation": "\u63a2\u7d22\u5728\u7f51\u7edc\u975e\u7ebf\u6027\u7cfb\u7edf\u4e2d\uff0c\u5f53\u53ea\u83b7\u53d6\u90e8\u5206\u8282\u70b9\u6d4b\u91cf\u65f6\uff0c\u4e0d\u540c\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\u53ef\u80fd\u4ea7\u751f\u76f8\u4f3c\u7684\u89c2\u6d4b\u7ed3\u679c\uff0c\u4ece\u800c\u9650\u5236\u62d3\u6251\u8bc6\u522b\u7684\u53ef\u80fd\u6027", "method": "\u5e94\u7528\u6536\u7f29\u7406\u8bba\u6846\u67b6\u6765\u6bd4\u8f83\u5019\u9009\u62d3\u6251\u7ed3\u6784\uff0c\u5206\u6790\u53ef\u89c2\u6d4b\u7a7a\u95f4\u7684\u534a\u6536\u7f29\u6027\u4f5c\u4e3a\u7cfb\u7edf\u4e0d\u53ef\u533a\u5206\u6027\u7684\u6761\u4ef6\uff0c\u5e76\u4ee5Kuramoto\u632f\u8361\u5668\u7f51\u7edc\u4e3a\u4f8b\u8fdb\u884c\u7814\u7a76", "result": "\u8bc1\u660e\u4e86\u53ef\u89c2\u6d4b\u7a7a\u95f4\u7684\u534a\u6536\u7f29\u6027\u662f\u4e24\u4e2a\u7cfb\u7edf\u57fa\u4e8e\u90e8\u5206\u6d4b\u91cf\u65e0\u6cd5\u533a\u5206\u7684\u5145\u5206\u6761\u4ef6\uff0c\u53d1\u73b0\u4e86\u8fde\u63a5\u548c\u4e0d\u8fde\u63a5\u7684\u4e0d\u540c\u62d3\u6251\u7ed3\u6784\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4f1a\u53d8\u5f97\u4e0d\u53ef\u533a\u5206", "conclusion": "\u90e8\u5206\u6d4b\u91cf\u4e0b\u7684\u7f51\u7edc\u62d3\u6251\u8bc6\u522b\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\uff0c\u534a\u6536\u7f29\u7406\u8bba\u4e3a\u5206\u6790\u8fd9\u79cd\u4e0d\u53ef\u533a\u5206\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\uff0c\u5bf9\u7f51\u7edc\u7cfb\u7edf\u8bc6\u522b\u5177\u6709\u91cd\u8981\u610f\u4e49"}}
{"id": "2509.13381", "categories": ["cs.RO", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.13381", "abs": "https://arxiv.org/abs/2509.13381", "authors": ["Zhang Xueyao", "Yang Bo", "Yu Zhiwen", "Cao Xuelin", "George C. Alexandropoulos", "Merouane Debbah", "Chau Yuen"], "title": "Cooperative Target Detection with AUVs: A Dual-Timescale Hierarchical MARDL Approach", "comment": "6 pages", "summary": "Autonomous Underwater Vehicles (AUVs) have shown great potential for\ncooperative detection and reconnaissance. However, collaborative AUV\ncommunications introduce risks of exposure. In adversarial environments,\nachieving efficient collaboration while ensuring covert operations becomes a\nkey challenge for underwater cooperative missions. In this paper, we propose a\nnovel dual time-scale Hierarchical Multi-Agent Proximal Policy Optimization\n(H-MAPPO) framework. The high-level component determines the individuals\nparticipating in the task based on a central AUV, while the low-level component\nreduces exposure probabilities through power and trajectory control by the\nparticipating AUVs. Simulation results show that the proposed framework\nachieves rapid convergence, outperforms benchmark algorithms in terms of\nperformance, and maximizes long-term cooperative efficiency while ensuring\ncovert operations.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u591a\u667a\u80fd\u4f53\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u6c34\u4e0b\u81ea\u4e3b\u6f5c\u822a\u5668\u534f\u540c\u901a\u4fe1\u4e2d\u7684\u9690\u853d\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u53cc\u65f6\u95f4\u5c3a\u5ea6\u63a7\u5236\u5b9e\u73b0\u9ad8\u6548\u534f\u4f5c\u4e0e\u9690\u853d\u64cd\u4f5c\u7684\u5e73\u8861", "motivation": "\u6c34\u4e0b\u81ea\u4e3b\u6f5c\u822a\u5668\u534f\u540c\u63a2\u6d4b\u9762\u4e34\u901a\u4fe1\u66b4\u9732\u98ce\u9669\uff0c\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u9700\u8981\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u534f\u4f5c\u548c\u9690\u853d\u64cd\u4f5c\uff0c\u8fd9\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218", "method": "\u91c7\u7528\u5206\u5c42\u591a\u667a\u80fd\u4f53\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u6846\u67b6\uff0c\u9ad8\u5c42\u7531\u4e2d\u592eAUV\u51b3\u5b9a\u4efb\u52a1\u53c2\u4e0e\u4e2a\u4f53\uff0c\u4f4e\u5c42\u901a\u8fc7\u529f\u7387\u548c\u8f68\u8ff9\u63a7\u5236\u964d\u4f4e\u66b4\u9732\u6982\u7387", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u8be5\u6846\u67b6\u6536\u655b\u901f\u5ea6\u5feb\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u51c6\u7b97\u6cd5\uff0c\u5728\u786e\u4fdd\u9690\u853d\u64cd\u4f5c\u7684\u540c\u65f6\u6700\u5927\u5316\u957f\u671f\u534f\u4f5c\u6548\u7387", "conclusion": "\u6240\u63d0\u51fa\u7684H-MAPPO\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6c34\u4e0b\u534f\u540c\u4efb\u52a1\u4e2d\u6548\u7387\u4e0e\u9690\u853d\u6027\u7684\u5e73\u8861\u95ee\u9898\uff0c\u4e3a\u5bf9\u6297\u73af\u5883\u4e0b\u7684AUV\u534f\u540c\u64cd\u4f5c\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848"}}
{"id": "2509.13347", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13347", "abs": "https://arxiv.org/abs/2509.13347", "authors": ["Zihao Wang", "Muyao Li", "Kaichen He", "Xiangyu Wang", "Zhancun Mu", "Anji Liu", "Yitao Liang"], "title": "OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft", "comment": null, "summary": "The choice of action spaces is a critical yet unresolved challenge in\ndeveloping capable, end-to-end trainable agents. This paper first presents a\nlarge-scale, systematic comparison of prominent abstracted action spaces and\ntokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the\nopen-ended Minecraft. Our analysis reveals that no single action space is\nuniversally optimal; instead, the most effective abstraction is highly\ntask-dependent, creating a dilemma for building generalist agents. To resolve\nthis, we introduce Chain of Action (CoA), a novel framework that unifies\nhigh-level planning and low-level control within a single, monolithic VLA\nmodel. CoA treats an abstracted action not as a command for a separate policy,\nbut as an intermediate reasoning step--akin to a chain of thought--that guides\nthe generation of the final, executable action. Furthermore, we demonstrate\nthat an All-in-One agent trained on a diverse mixture of action spaces using\nthe CoA paradigm learns a more robust and generalizable policy. This unified\nagent achieves a new state-of-the-art, improving the overall task success rate\nover strong, specialized baselines. To foster reproducible research, we release\nthe OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive\nbenchmark of over 800 distinct tasks, curated datasets, source code, and all\npretrained model checkpoints at https://github.com/CraftJarvis/OpenHA", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86Minecraft\u4e2d\u4e0d\u540c\u52a8\u4f5c\u7a7a\u95f4\u7684\u6548\u679c\uff0c\u53d1\u73b0\u6700\u4f18\u52a8\u4f5c\u7a7a\u95f4\u9ad8\u5ea6\u4f9d\u8d56\u5177\u4f53\u4efb\u52a1\u3002\u4e3a\u6b64\u63d0\u51fa\u4e86Chain of Action (CoA)\u6846\u67b6\uff0c\u5c06\u9ad8\u5c42\u89c4\u5212\u548c\u5e95\u5c42\u63a7\u5236\u7edf\u4e00\u5728\u5355\u4e00VLA\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u6df7\u5408\u52a8\u4f5c\u7a7a\u95f4\u8bad\u7ec3\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u52a8\u4f5c\u7a7a\u95f4\u9009\u62e9\u8fd9\u4e00\u5173\u952e\u4f46\u672a\u89e3\u51b3\u7684\u6311\u6218\uff0c\u56e0\u4e3a\u7814\u7a76\u53d1\u73b0\u6ca1\u6709\u5355\u4e00\u52a8\u4f5c\u7a7a\u95f4\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u90fd\u6700\u4f18\uff0c\u8fd9\u7ed9\u6784\u5efa\u901a\u7528\u667a\u80fd\u4f53\u5e26\u6765\u4e86\u56f0\u5883\u3002", "method": "\u63d0\u51faChain of Action (CoA)\u6846\u67b6\uff0c\u5c06\u62bd\u8c61\u52a8\u4f5c\u89c6\u4e3a\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u800c\u975e\u5355\u72ec\u7b56\u7565\u7684\u547d\u4ee4\uff0c\u5728\u5355\u4e00VLA\u6a21\u578b\u4e2d\u7edf\u4e00\u9ad8\u5c42\u89c4\u5212\u548c\u5e95\u5c42\u63a7\u5236\u3002\u4f7f\u7528\u6df7\u5408\u52a8\u4f5c\u7a7a\u95f4\u8bad\u7ec3All-in-One\u667a\u80fd\u4f53\u3002", "result": "CoA\u6846\u67b6\u8bad\u7ec3\u7684\u667a\u80fd\u4f53\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u6574\u4f53\u4efb\u52a1\u6210\u529f\u7387\u8d85\u8fc7\u5f3a\u5927\u7684\u4e13\u7528\u57fa\u7ebf\u6a21\u578b\uff0c\u5b66\u4e60\u5230\u4e86\u66f4\u9c81\u68d2\u548c\u53ef\u6cdb\u5316\u7684\u7b56\u7565\u3002", "conclusion": "CoA\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u52a8\u4f5c\u7a7a\u95f4\u9009\u62e9\u7684\u56f0\u5883\uff0c\u901a\u8fc7\u7edf\u4e00\u89c4\u5212\u548c\u63a7\u5236\u5728\u5355\u4e00\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u5e76\u53d1\u5e03\u4e86OpenHA\u5957\u4ef6\u4fc3\u8fdb\u53ef\u590d\u73b0\u7814\u7a76\u3002"}}
{"id": "2509.13359", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13359", "abs": "https://arxiv.org/abs/2509.13359", "authors": ["Benjamin J. Walker", "Beatriz Navarro Lameda", "Ruth A. Reynolds"], "title": "Evaluating undergraduate mathematics examinations in the era of generative AI: a curriculum-level case study", "comment": null, "summary": "Generative artificial intelligence (GenAI) tools such as OpenAI's ChatGPT are\ntransforming the educational landscape, prompting reconsideration of\ntraditional assessment practices. In parallel, universities are exploring\nalternatives to in-person, closed-book examinations, raising concerns about\nacademic integrity and pedagogical alignment in uninvigilated settings. This\nstudy investigates whether traditional closed-book mathematics examinations\nretain their pedagogical relevance when hypothetically administered in\nuninvigilated, open-book settings with GenAI access. Adopting an empirical\napproach, we generate, transcribe, and blind-mark GenAI submissions to eight\nundergraduate mathematics examinations at a Russel Group university, spanning\nthe entirety of the first-year curriculum. By combining independent GenAI\nresponses to individual questions, we enable a meaningful evaluation of GenAI\nperformance, both at the level of modules and across the first-year curriculum.\nWe find that GenAI attainment is at the level of a first-class degree, though\ncurrent performance can vary between modules. Further, we find that GenAI\nperformance is remarkably consistent when viewed across the entire curriculum,\nsignificantly more so than that of students in invigilated examinations. Our\nfindings evidence the need for redesigning assessments in mathematics for\nunsupervised settings, and highlight the potential reduction in pedagogical\nvalue of current standards in the era of generative artificial intelligence.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u65e0\u76d1\u8003\u3001\u5f00\u5377\u4e14\u53ef\u4f7f\u7528GenAI\u7684\u73af\u5883\u4e0b\uff0c\u4f20\u7edf\u6570\u5b66\u8003\u8bd5\u7684\u6559\u5b66\u4ef7\u503c\u663e\u8457\u964d\u4f4e\uff0cGenAI\u80fd\u8fbe\u5230\u4e00\u7b49\u5b66\u4f4d\u6c34\u5e73\u4e14\u8868\u73b0\u6bd4\u5b66\u751f\u66f4\u7a33\u5b9a\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5de5\u5177\u5982ChatGPT\u5728\u6559\u80b2\u9886\u57df\u7684\u5e94\u7528\uff0c\u4ee5\u53ca\u5927\u5b66\u63a2\u7d22\u66ff\u4ee3\u4f20\u7edf\u76d1\u8003\u8003\u8bd5\u7684\u65b9\u5f0f\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u4f20\u7edf\u95ed\u5377\u6570\u5b66\u8003\u8bd5\u5728\u65e0\u76d1\u8003\u3001\u5f00\u5377\u4e14\u5141\u8bb8\u4f7f\u7528GenAI\u73af\u5883\u4e0b\u7684\u6559\u5b66\u76f8\u5173\u6027\u3002", "method": "\u91c7\u7528\u5b9e\u8bc1\u65b9\u6cd5\uff0c\u751f\u6210\u3001\u8f6c\u5f55\u5e76\u76f2\u8bc4GenAI\u5bf9\u7f57\u7d20\u96c6\u56e2\u5927\u5b66\u4e00\u5e74\u7ea7\u6570\u5b66\u8bfe\u7a0b8\u95e8\u8003\u8bd5\u7684\u4f5c\u7b54\uff0c\u901a\u8fc7\u7ec4\u5408GenAI\u5bf9\u5355\u4e2a\u95ee\u9898\u7684\u72ec\u7acb\u56de\u7b54\u6765\u8bc4\u4f30\u5176\u8868\u73b0\u3002", "result": "GenAI\u8868\u73b0\u8fbe\u5230\u4e00\u7b49\u5b66\u4f4d\u6c34\u5e73\uff0c\u867d\u7136\u4e0d\u540c\u6a21\u5757\u95f4\u5b58\u5728\u5dee\u5f02\uff0c\u4f46\u5728\u6574\u4e2a\u8bfe\u7a0b\u8303\u56f4\u5185\u7684\u8868\u73b0\u6bd4\u76d1\u8003\u8003\u8bd5\u4e2d\u7684\u5b66\u751f\u66f4\u52a0\u7a33\u5b9a\u4e00\u81f4\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u6570\u5b66\u8bc4\u4f30\u65b9\u5f0f\u4ee5\u9002\u5e94\u65e0\u76d1\u7763\u73af\u5883\uff0c\u5e76\u5f3a\u8c03\u5728\u5f53\u524d\u751f\u6210\u5f0fAI\u65f6\u4ee3\uff0c\u73b0\u6709\u6807\u51c6\u7684\u6559\u5b66\u4ef7\u503c\u53ef\u80fd\u88ab\u524a\u5f31\u3002"}}
{"id": "2509.13531", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.13531", "abs": "https://arxiv.org/abs/2509.13531", "authors": ["Piotr \u0141aszkiewicz", "Maria Carvalho", "Cl\u00e1udia Soares", "Pedro Louren\u00e7o"], "title": "The impact of modeling approaches on controlling safety-critical, highly perturbed systems: the case for data-driven models", "comment": null, "summary": "This paper evaluates the impact of three system models on the reference\ntrajectory tracking error of the LQR optimal controller, in the challenging\nproblem of guidance and control of the state of a system under strong\nperturbations and reconfiguration. We compared a smooth Linear Time Variant\nsystem learned from data (DD-LTV) with state of the art Linear Time Variant\n(LTV) system identification methods, showing its superiority in the task of\nstate propagation. Moreover, we have found that DD-LTV allows for better\nperformance in terms of trajectory tracking error than the standard solutions\nof a Linear Time Invariant (LTI) system model, and comparable performance to a\nlinearized Linear Time Variant (L-LTV) system model. We tested the three\napproaches on the perturbed and time varying spring-mass-damper systems.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u4e09\u79cd\u7cfb\u7edf\u6a21\u578b\u5bf9LQR\u6700\u4f18\u63a7\u5236\u5668\u53c2\u8003\u8f68\u8ff9\u8ddf\u8e2a\u8bef\u5dee\u7684\u5f71\u54cd\uff0c\u6bd4\u8f83\u4e86\u4ece\u6570\u636e\u5b66\u4e60\u7684\u5e73\u6ed1\u7ebf\u6027\u65f6\u53d8\u7cfb\u7edf(DD-LTV)\u4e0e\u73b0\u6709LTV\u7cfb\u7edf\u8fa8\u8bc6\u65b9\u6cd5\u5728\u5f3a\u6270\u52a8\u548c\u91cd\u6784\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u7814\u7a76\u5728\u5f3a\u6270\u52a8\u548c\u7cfb\u7edf\u91cd\u6784\u6761\u4ef6\u4e0b\uff0c\u4e0d\u540c\u7cfb\u7edf\u6a21\u578b\u5bf9LQR\u6700\u4f18\u63a7\u5236\u5668\u8f68\u8ff9\u8ddf\u8e2a\u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u5bfb\u627e\u66f4\u4f18\u7684\u7cfb\u7edf\u5efa\u6a21\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u63a7\u5236\u6027\u80fd\u3002", "method": "\u6bd4\u8f83\u4e09\u79cd\u7cfb\u7edf\u6a21\u578b\uff1a\u4ece\u6570\u636e\u5b66\u4e60\u7684\u5e73\u6ed1\u7ebf\u6027\u65f6\u53d8\u7cfb\u7edf(DD-LTV)\u3001\u6807\u51c6\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf(LTI)\u548c\u7ebf\u6027\u5316\u7ebf\u6027\u65f6\u53d8\u7cfb\u7edf(L-LTV)\u3002\u5728\u53d7\u6270\u52a8\u548c\u65f6\u53d8\u7684\u5f39\u7c27-\u8d28\u91cf-\u963b\u5c3c\u5668\u7cfb\u7edf\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "DD-LTV\u5728\u72b6\u6001\u4f20\u64ad\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709LTV\u7cfb\u7edf\u8fa8\u8bc6\u65b9\u6cd5\uff0c\u5728\u8f68\u8ff9\u8ddf\u8e2a\u8bef\u5dee\u65b9\u9762\u6bd4\u6807\u51c6LTI\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u6027\u80fd\u4e0eL-LTV\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "\u4ece\u6570\u636e\u5b66\u4e60\u7684DD-LTV\u7cfb\u7edf\u6a21\u578b\u5728\u5f3a\u6270\u52a8\u6761\u4ef6\u4e0b\u5177\u6709\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u4e3a\u590d\u6742\u73af\u5883\u4e0b\u7684\u63a7\u5236\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5efa\u6a21\u65b9\u6cd5\u3002"}}
{"id": "2509.13386", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13386", "abs": "https://arxiv.org/abs/2509.13386", "authors": ["Hansol Lim", "Minhyeok Im", "Jonathan Boyack", "Jee Won Lee", "Jongseong Brad Choi"], "title": "VEGA: Electric Vehicle Navigation Agent via Physics-Informed Neural Operator and Proximal Policy Optimization", "comment": "This work has been submitted to the 2026 IEEE International\n  Conference on Robotics and Automation (ICRA) for possible publication", "summary": "Demands for software-defined vehicles (SDV) are rising and electric vehicles\n(EVs) are increasingly being equipped with powerful computers. This enables\nonboard AI systems to optimize charge-aware path optimization customized to\nreflect vehicle's current condition and environment. We present VEGA, a\ncharge-aware EV navigation agent that plans over a charger-annotated road graph\nusing Proximal Policy Optimization (PPO) with budgeted A* teacher-student\nguidance under state-of-charge (SoC) feasibility. VEGA consists of two modules.\nFirst, a physics-informed neural operator (PINO), trained on real vehicle speed\nand battery-power logs, uses recent vehicle speed logs to estimate aerodynamic\ndrag, rolling resistance, mass, motor and regenerative-braking efficiencies,\nand auxiliary load by learning a vehicle-custom dynamics. Second, a\nReinforcement Learning (RL) agent uses these dynamics to optimize a path with\noptimal charging stops and dwell times under SoC constraints. VEGA requires no\nadditional sensors and uses only vehicle speed signals. It may serve as a\nvirtual sensor for power and efficiency to potentially reduce EV cost. In\nevaluation on long routes like San Francisco to New York, VEGA's stops, dwell\ntimes, SoC management, and total travel time closely track Tesla Trip Planner\nwhile being slightly more conservative, presumably due to real vehicle\nconditions such as vehicle parameter drift due to deterioration. Although\ntrained only in U.S. regions, VEGA was able to compute optimal charge-aware\npaths in France and Japan, demonstrating generalizability. It achieves\npractical integration of physics-informed learning and RL for EV eco-routing.", "AI": {"tldr": "VEGA\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u611f\u77e5\u5bfc\u822a\u7cfb\u7edf\uff0c\u4f7f\u7528\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u548cPPO\u7b97\u6cd5\u4f18\u5316\u8def\u5f84\u89c4\u5212\u548c\u5145\u7535\u7b56\u7565\uff0c\u65e0\u9700\u989d\u5916\u4f20\u611f\u5668\u5373\u53ef\u5b9e\u73b0\u4e2a\u6027\u5316\u80fd\u6548\u4f30\u7b97\u548c\u8def\u5f84\u4f18\u5316\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5b9a\u4e49\u8f66\u8f86\u9700\u6c42\u589e\u957f\u548c\u7535\u52a8\u6c7d\u8f66\u8ba1\u7b97\u80fd\u529b\u63d0\u5347\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6839\u636e\u8f66\u8f86\u5b9e\u65f6\u72b6\u6001\u548c\u73af\u5883\u6761\u4ef6\u8fdb\u884c\u5145\u7535\u611f\u77e5\u8def\u5f84\u4f18\u5316\u7684AI\u7cfb\u7edf\uff0c\u4ee5\u964d\u4f4e\u7535\u52a8\u6c7d\u8f66\u6210\u672c\u5e76\u63d0\u9ad8\u80fd\u6548\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u4e24\u4e2a\u6a21\u5757\uff1a1\uff09\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u64cd\u4f5c\u5668\uff08PINO\uff09\u4ece\u8f66\u8f86\u901f\u5ea6\u65e5\u5fd7\u5b66\u4e60\u8f66\u8f86\u5b9a\u5236\u5316\u52a8\u529b\u5b66\u53c2\u6570\uff1b2\uff09\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u4f7f\u7528\u5b66\u4e60\u5230\u7684\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u5728\u7535\u91cf\u7ea6\u675f\u4e0b\u4f18\u5316\u8def\u5f84\u3001\u5145\u7535\u7ad9\u70b9\u9009\u62e9\u548c\u505c\u7559\u65f6\u95f4\u3002", "result": "\u5728\u957f\u8ddd\u79bb\u8def\u7ebf\u6d4b\u8bd5\u4e2d\uff08\u5982\u65e7\u91d1\u5c71\u5230\u7ebd\u7ea6\uff09\uff0cVEGA\u7684\u5145\u7535\u7ad9\u70b9\u9009\u62e9\u3001\u505c\u7559\u65f6\u95f4\u3001\u7535\u91cf\u7ba1\u7406\u548c\u603b\u65c5\u884c\u65f6\u95f4\u4e0e\u7279\u65af\u62c9\u884c\u7a0b\u89c4\u5212\u5668\u9ad8\u5ea6\u4e00\u81f4\u4f46\u66f4\u4fdd\u5b88\uff0c\u4e14\u5728\u6cd5\u56fd\u548c\u65e5\u672c\u7b49\u672a\u8bad\u7ec3\u5730\u533a\u4e5f\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "VEGA\u6210\u529f\u5b9e\u73b0\u4e86\u7269\u7406\u4fe1\u606f\u5b66\u4e60\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u5b9e\u9645\u96c6\u6210\uff0c\u4e3a\u7535\u52a8\u6c7d\u8f66\u751f\u6001\u8def\u7531\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u4f5c\u4e3a\u865a\u62df\u4f20\u611f\u5668\u51cf\u5c11\u8f66\u8f86\u6210\u672c\uff0c\u5e76\u5c55\u793a\u4e86\u826f\u597d\u7684\u8de8\u5730\u57df\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2509.13351", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13351", "abs": "https://arxiv.org/abs/2509.13351", "authors": ["Pulkit Verma", "Ngoc La", "Anthony Favier", "Swaroop Mishra", "Julie A. Shah"], "title": "Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning", "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive capabilities across\ndiverse tasks, yet their ability to perform structured symbolic planning\nremains limited, particularly in domains requiring formal representations like\nthe Planning Domain Definition Language (PDDL). In this paper, we present a\nnovel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'\nsymbolic planning capabilities through logical chain-of-thought reasoning. Our\napproach focuses on teaching models to rigorously reason about action\napplicability, state transitions, and plan validity using explicit logical\ninference steps. By developing instruction prompts that guide models through\nthe precise logical reasoning required to determine when actions can be applied\nin a given state, we enable LLMs to self-correct their planning processes\nthrough structured reflection. The framework systematically builds verification\nskills by decomposing the planning process into explicit reasoning chains about\nprecondition satisfaction, effect application, and invariant preservation.\nExperimental results on multiple planning domains show that our\nchain-of-thought reasoning based instruction-tuned models are significantly\nbetter at planning, achieving planning accuracy of up to 94% on standard\nbenchmarks, representing a 66% absolute improvement over baseline models. This\nwork bridges the gap between the general reasoning capabilities of LLMs and the\nlogical precision required for automated planning, offering a promising\ndirection for developing better AI planning systems.", "AI": {"tldr": "PDDL-Instruct\u6846\u67b6\u901a\u8fc7\u903b\u8f91\u601d\u7ef4\u94fe\u63a8\u7406\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7b26\u53f7\u89c4\u5212\u80fd\u529b\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523094%\u7684\u89c4\u5212\u51c6\u786e\u7387\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u63d0\u534766%", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u5316\u7b26\u53f7\u89c4\u5212\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u9700\u8981PDDL\u7b49\u6b63\u5f0f\u8868\u793a\u7684\u9886\u57df\uff0c\u9700\u8981\u63d0\u5347\u5176\u903b\u8f91\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b", "method": "\u5f00\u53d1\u6307\u4ee4\u8c03\u4f18\u6846\u67b6\uff0c\u901a\u8fc7\u903b\u8f91\u601d\u7ef4\u94fe\u63a8\u7406\u6559\u5bfc\u6a21\u578b\u8fdb\u884c\u52a8\u4f5c\u9002\u7528\u6027\u3001\u72b6\u6001\u8f6c\u6362\u548c\u8ba1\u5212\u6709\u6548\u6027\u7684\u4e25\u683c\u63a8\u7406\uff0c\u4f7f\u7528\u660e\u786e\u7684\u903b\u8f91\u63a8\u7406\u6b65\u9aa4", "result": "\u5728\u591a\u4e2a\u89c4\u5212\u9886\u57df\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8e\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u89c4\u5212\u51c6\u786e\u7387\u6700\u9ad8\u8fbe\u523094%", "conclusion": "\u8be5\u5de5\u4f5c\u5f25\u5408\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u901a\u7528\u63a8\u7406\u80fd\u529b\u4e0e\u81ea\u52a8\u89c4\u5212\u6240\u9700\u903b\u8f91\u7cbe\u5ea6\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5f00\u53d1\u66f4\u597d\u7684AI\u89c4\u5212\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411"}}
{"id": "2509.13365", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13365", "abs": "https://arxiv.org/abs/2509.13365", "authors": ["Brian D. Earp", "Haotian Yuan", "Julian Koplin", "Sebastian Porsdam Mann"], "title": "The Provenance Problem: LLMs and the Breakdown of Citation Norms", "comment": "9 pages", "summary": "The increasing use of generative AI in scientific writing raises urgent\nquestions about attribution and intellectual credit. When a researcher employs\nChatGPT to draft a manuscript, the resulting text may echo ideas from sources\nthe author has never encountered. If an AI system reproduces insights from, for\nexample, an obscure 1975 paper without citation, does this constitute\nplagiarism? We argue that such cases exemplify the 'provenance problem': a\nsystematic breakdown in the chain of scholarly credit. Unlike conventional\nplagiarism, this phenomenon does not involve intent to deceive (researchers may\ndisclose AI use and act in good faith) yet still benefit from the uncredited\nintellectual contributions of others. This dynamic creates a novel category of\nattributional harm that current ethical and professional frameworks fail to\naddress. As generative AI becomes embedded across disciplines, the risk that\nsignificant ideas will circulate without recognition threatens both the\nreputational economy of science and the demands of epistemic justice. This\nPerspective analyzes how AI challenges established norms of authorship,\nintroduces conceptual tools for understanding the provenance problem, and\nproposes strategies to preserve integrity and fairness in scholarly\ncommunication.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u5728\u79d1\u7814\u5199\u4f5c\u4e2d\u7684\u4f7f\u7528\u5f15\u53d1\u4e86\u5b66\u672f\u5f52\u5c5e\u548c\u77e5\u8bc6\u4ea7\u6743\u7684\u65b0\u95ee\u9898\uff0c\u5f53\u7814\u7a76\u4eba\u5458\u4f7f\u7528ChatGPT\u64b0\u5199\u8bba\u6587\u65f6\uff0cAI\u53ef\u80fd\u590d\u5236\u4f5c\u8005\u4ece\u672a\u63a5\u89e6\u8fc7\u7684\u6587\u732e\u89c2\u70b9\u800c\u4e0d\u6ce8\u660e\u51fa\u5904\uff0c\u8fd9\u6784\u6210\u4e86\"\u6765\u6e90\u95ee\u9898\"\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5728\u79d1\u7814\u5199\u4f5c\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f20\u7edf\u7684\u5b66\u672f\u5f15\u7528\u548c\u77e5\u8bc6\u4ea7\u6743\u4f53\u7cfb\u9762\u4e34\u6311\u6218\u3002\u7814\u7a76\u4eba\u5458\u53ef\u80fd\u65e0\u610f\u4e2d\u901a\u8fc7AI\u5de5\u5177\u4f7f\u7528\u4e86\u4ed6\u4eba\u672a\u6807\u6ce8\u7684\u5b66\u672f\u6210\u679c\uff0c\u8fd9\u65e2\u975e\u4f20\u7edf\u6284\u88ad\u53c8\u9020\u6210\u4e86\u5b66\u672f\u4e0d\u516c\uff0c\u73b0\u6709\u4f26\u7406\u6846\u67b6\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u3002", "method": "\u672c\u6587\u91c7\u7528\u6982\u5ff5\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u7406\u8bba\u63a2\u8ba8\u7684\u65b9\u5f0f\u5206\u6790AI\u5bf9\u5b66\u672f\u4f5c\u8005\u89c4\u8303\u7684\u6311\u6218\uff0c\u5f15\u5165\"\u6765\u6e90\u95ee\u9898\"\u7684\u6982\u5ff5\u5de5\u5177\uff0c\u5e76\u63d0\u51fa\u76f8\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u7b56\u7565\u3002", "result": "\u8bc6\u522b\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u5b66\u672f\u5f52\u5c5e\u4f24\u5bb3\u7c7b\u522b\u2014\u2014\"\u6765\u6e90\u95ee\u9898\"\uff0c\u8fd9\u79cd\u73b0\u8c61\u4e0d\u540c\u4e8e\u4f20\u7edf\u6284\u88ad\uff0c\u4e0d\u6d89\u53ca\u6b3a\u9a97\u610f\u56fe\u4f46\u540c\u6837\u9020\u6210\u77e5\u8bc6\u4ea7\u6743\u4fb5\u5bb3\uff0c\u73b0\u6709\u5b66\u672f\u4f26\u7406\u4f53\u7cfb\u5bf9\u6b64\u7f3a\u4e4f\u6709\u6548\u5e94\u5bf9\u673a\u5236\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u7684\u666e\u53ca\u5bf9\u5b66\u672f\u8bda\u4fe1\u4f53\u7cfb\u6784\u6210\u7cfb\u7edf\u6027\u5a01\u80c1\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u7b56\u7565\u548c\u6846\u67b6\u6765\u7ef4\u62a4\u5b66\u672f\u4ea4\u6d41\u7684\u5b8c\u6574\u6027\u548c\u516c\u5e73\u6027\uff0c\u4fdd\u62a4\u79d1\u5b66\u58f0\u8a89\u7ecf\u6d4e\u548c\u8ba4\u77e5\u6b63\u4e49\u7684\u8981\u6c42\u3002"}}
{"id": "2509.13545", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.13545", "abs": "https://arxiv.org/abs/2509.13545", "authors": ["Sheng Yu", "Boli Chen", "Imad M. Jaimoukha", "Simos A. Evangelou"], "title": "A Game-Theoretic Predictive Control Framework with Statistical Collision Avoidance Constraints for Autonomous Vehicle Overtaking", "comment": null, "summary": "This work develops a control framework for the autonomous overtaking of\nconnected and automated vehicles (CAVs) in a mixed traffic environment, where\nthe overtaken vehicle is an unconnected but interactive human-driven vehicle.\nThe proposed method, termed the Game-Theoretic, PRedictive Overtaking (GT-PRO)\nstrategy, successfully decouples the longitudinal and lateral vehicle dynamics\nof the CAV and comprehensively coordinates these decoupled dynamics via\ninnovative longitudinal and lateral model predictive (MPC) based controllers,\nrespectively. To address the real-time interactive behavior of the human-driven\novertaken vehicle, a dynamic Stackelberg game-based bilevel optimization is\nsolved by the lateral controller to directly control the CAV lateral motion and\npredict the overtaken vehicle longitudinal responses that are subsequently\nshared with a stochastic MPC that governs the CAV longitudinal motion. The\nproposed strategy exploits a comprehensive real-world dataset, which captures\nhuman driver responses when being overtaken, to tune the game-theoretic lateral\ncontroller according to the most common human responses, and to statistically\ncharacterize human uncertainties and hence implement a collision avoidance\nchance constraint for the stochastic longitudinal controller. The simulation\nresults for both polite and aggressive human response case studies of the\novertaken vehicle demonstrate that the proposed GT-PRO can achieve for this\nrange of human driver responsiveness, safer, more efficient, and more\ncomfortable autonomous overtaking, as compared to existing autonomous\novertaking approaches in the literature. Furthermore, the results suggest that\nthe GT-PRO method is capable of real-time implementation.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7528\u4e8e\u6df7\u5408\u4ea4\u901a\u73af\u5883\u4e2dCAV\u81ea\u4e3b\u8d85\u8f66\u7684\u63a7\u5236\u6846\u67b6GT-PRO\uff0c\u901a\u8fc7\u535a\u5f08\u8bba\u548c\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u534f\u8c03\u7eb5\u5411\u548c\u6a2a\u5411\u52a8\u529b\u5b66\uff0c\u80fd\u591f\u5b9e\u65f6\u5904\u7406\u4eba\u7c7b\u9a7e\u9a76\u8f66\u8f86\u7684\u4ea4\u4e92\u884c\u4e3a\u3002", "motivation": "\u5728\u6df7\u5408\u4ea4\u901a\u73af\u5883\u4e2d\uff0c\u5f53\u88ab\u8d85\u8f66\u8f66\u8f86\u662f\u4eba\u7c7b\u9a7e\u9a76\u7684\u975e\u8054\u7f51\u8f66\u8f86\u65f6\uff0c\u9700\u8981\u89e3\u51b3\u5b9e\u65f6\u4ea4\u4e92\u884c\u4e3a\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0\u5b89\u5168\u9ad8\u6548\u7684\u81ea\u4e3b\u8d85\u8f66\u3002", "method": "\u91c7\u7528\u535a\u5f08\u8bba\u9884\u6d4b\u8d85\u8f66\u7b56\u7565(GT-PRO)\uff0c\u901a\u8fc7\u52a8\u6001Stackelberg\u535a\u5f08\u7684\u53cc\u5c42\u4f18\u5316\u63a7\u5236\u6a2a\u5411\u8fd0\u52a8\uff0c\u4f7f\u7528\u968f\u673aMPC\u63a7\u5236\u7eb5\u5411\u8fd0\u52a8\uff0c\u5e76\u5229\u7528\u771f\u5b9e\u6570\u636e\u96c6\u8c03\u6574\u63a7\u5236\u5668\u53c2\u6570\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0cGT-PRO\u5728\u5404\u79cd\u4eba\u7c7b\u9a7e\u9a76\u54cd\u5e94\u60c5\u51b5\u4e0b\u90fd\u80fd\u5b9e\u73b0\u66f4\u5b89\u5168\u3001\u9ad8\u6548\u548c\u8212\u9002\u7684\u81ea\u4e3b\u8d85\u8f66\uff0c\u4e14\u5177\u5907\u5b9e\u65f6\u5b9e\u65bd\u80fd\u529b\u3002", "conclusion": "GT-PRO\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u6df7\u5408\u4ea4\u901a\u73af\u5883\u4e2dCAV\u81ea\u4e3b\u8d85\u8f66\u7684\u6311\u6218\uff0c\u901a\u8fc7\u7ed3\u5408\u535a\u5f08\u8bba\u548cMPC\u63a7\u5236\uff0c\u6709\u6548\u5904\u7406\u4e86\u4eba\u7c7b\u9a7e\u9a76\u884c\u4e3a\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3a\u5b9e\u65f6\u81ea\u4e3b\u8d85\u8f66\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13434", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13434", "abs": "https://arxiv.org/abs/2509.13434", "authors": ["Wei-Chen Li", "Glen Chou"], "title": "A Convex Formulation of Compliant Contact between Filaments and Rigid Bodies", "comment": null, "summary": "We present a computational framework for simulating filaments interacting\nwith rigid bodies through contact. Filaments are challenging to simulate due to\ntheir codimensionality, i.e., they are one-dimensional structures embedded in\nthree-dimensional space. Existing methods often assume that filaments remain\npermanently attached to rigid bodies. Our framework unifies discrete elastic\nrod (DER) modeling, a pressure field patch contact model, and a convex contact\nformulation to accurately simulate frictional interactions between slender\nfilaments and rigid bodies - capabilities not previously achievable. Owing to\nthe convex formulation of contact, each time step can be solved to global\noptimality, guaranteeing complementarity between contact velocity and impulse.\nWe validate the framework by assessing the accuracy of frictional forces and\ncomparing its physical fidelity against baseline methods. Finally, we\ndemonstrate its applicability in both soft robotics, such as a stochastic\nfilament-based gripper, and deformable object manipulation, such as shoelace\ntying, providing a versatile simulator for systems involving complex\nfilament-filament and filament-rigid body interactions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u7ec6\u957f\u4e1d\u72b6\u4f53\u4e0e\u521a\u4f53\u4e4b\u95f4\u7684\u63a5\u89e6\u76f8\u4e92\u4f5c\u7528\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u4e1d\u72b6\u4f53\u5fc5\u987b\u6c38\u4e45\u9644\u7740\u5728\u521a\u4f53\u4e0a\u7684\u9650\u5236\u3002", "motivation": "\u4e1d\u72b6\u4f53\u7531\u4e8e\u5176\u5171\u7ef4\u7279\u6027\uff08\u4e00\u7ef4\u7ed3\u6784\u5d4c\u5165\u4e09\u7ef4\u7a7a\u95f4\uff09\u96be\u4ee5\u6a21\u62df\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u4e1d\u72b6\u4f53\u6c38\u4e45\u9644\u7740\u5728\u521a\u4f53\u4e0a\uff0c\u65e0\u6cd5\u51c6\u786e\u6a21\u62df\u4e1d\u72b6\u4f53\u4e0e\u521a\u4f53\u4e4b\u95f4\u7684\u6469\u64e6\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u7ed3\u5408\u79bb\u6563\u5f39\u6027\u6746\uff08DER\uff09\u5efa\u6a21\u3001\u538b\u529b\u573a\u8865\u4e01\u63a5\u89e6\u6a21\u578b\u548c\u51f8\u63a5\u89e6\u516c\u5f0f\uff0c\u901a\u8fc7\u51f8\u4f18\u5316\u65b9\u6cd5\u786e\u4fdd\u6bcf\u4e2a\u65f6\u95f4\u6b65\u90fd\u80fd\u8fbe\u5230\u5168\u5c40\u6700\u4f18\u89e3\uff0c\u4fdd\u8bc1\u63a5\u89e6\u901f\u5ea6\u4e0e\u51b2\u91cf\u4e4b\u95f4\u7684\u4e92\u8865\u6027\u3002", "result": "\u9a8c\u8bc1\u4e86\u6469\u64e6\u529b\u7684\u51c6\u786e\u6027\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u66f4\u9ad8\u7684\u7269\u7406\u4fdd\u771f\u5ea6\uff0c\u5728\u8f6f\u673a\u5668\u4eba\uff08\u5982\u968f\u673a\u4e1d\u72b6\u4f53\u6293\u53d6\u5668\uff09\u548c\u53ef\u53d8\u5f62\u7269\u4f53\u64cd\u4f5c\uff08\u5982\u978b\u5e26\u7cfb\u7ed3\uff09\u4e2d\u5c55\u793a\u4e86\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6d89\u53ca\u590d\u6742\u4e1d\u72b6\u4f53-\u4e1d\u72b6\u4f53\u548c\u4e1d\u72b6\u4f53-\u521a\u4f53\u76f8\u4e92\u4f5c\u7528\u7684\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u6a21\u62df\u5668\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u7ec6\u957f\u4e1d\u72b6\u4f53\u4e0e\u521a\u4f53\u4e4b\u95f4\u6469\u64e6\u76f8\u4e92\u4f5c\u7528\u7684\u51c6\u786e\u6a21\u62df\u3002"}}
{"id": "2509.13352", "categories": ["cs.AI", "cs.RO", "68T07, 68T40, 68T42", "I.2.9; I.2.11; I.2.8; I.2.10"], "pdf": "https://arxiv.org/pdf/2509.13352", "abs": "https://arxiv.org/abs/2509.13352", "authors": ["Anis Koubaa", "Khaled Gabr"], "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "comment": "14 pages, 1 figure", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,\nsurveillance, and disaster response, yet most systems remain confined to SAE\nLevel 2--3 autonomy. Their reliance on rule-based control and narrow AI\nrestricts adaptability in dynamic, uncertain missions. Existing UAV frameworks\nlack context-aware reasoning, autonomous decision-making, and ecosystem-level\nintegration; critically, none leverage Large Language Model (LLM) agents with\ntool-calling for real-time knowledge access. This paper introduces the Agentic\nUAVs framework, a five-layer architecture (Perception, Reasoning, Action,\nIntegration, Learning) that augments UAVs with LLM-driven reasoning, database\nquerying, and third-party system interaction. A ROS2 and Gazebo-based prototype\nintegrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3\ndeployment. In simulated search-and-rescue scenarios, agentic UAVs achieved\nhigher detection confidence (0.79 vs. 0.72), improved person detection rates\n(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).\nThese results confirm that modest computational overhead enables qualitatively\nnew levels of autonomy and ecosystem integration.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65e0\u4eba\u673a\u81ea\u4e3b\u51b3\u7b56\u6846\u67b6Agentic UAVs\uff0c\u901a\u8fc7\u4e94\u5c42\u67b6\u6784\u5b9e\u73b0\u611f\u77e5\u3001\u63a8\u7406\u3001\u884c\u52a8\u3001\u96c6\u6210\u548c\u5b66\u4e60\u529f\u80fd\uff0c\u5728\u6a21\u62df\u641c\u6551\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u548c\u81ea\u4e3b\u51b3\u7b56\u80fd\u529b", "motivation": "\u73b0\u6709\u65e0\u4eba\u673a\u7cfb\u7edf\u5927\u591a\u505c\u7559\u5728SAE 2-3\u7ea7\u81ea\u4e3b\u6027\uff0c\u4f9d\u8d56\u57fa\u4e8e\u89c4\u5219\u7684\u63a7\u5236\u548c\u7a84AI\uff0c\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u3001\u81ea\u4e3b\u51b3\u7b56\u548c\u751f\u6001\u7cfb\u7edf\u96c6\u6210\u80fd\u529b\uff0c\u7279\u522b\u662f\u6ca1\u6709\u5229\u7528LLM\u667a\u80fd\u4f53\u8fdb\u884c\u5b9e\u65f6\u77e5\u8bc6\u8bbf\u95ee", "method": "\u8bbe\u8ba1\u4e94\u5c42\u67b6\u6784\uff08\u611f\u77e5\u3001\u63a8\u7406\u3001\u884c\u52a8\u3001\u96c6\u6210\u3001\u5b66\u4e60\uff09\uff0c\u96c6\u6210ROS2\u548cGazebo\u4eff\u771f\u5e73\u53f0\uff0c\u7ed3\u5408YOLOv11\u76ee\u6807\u68c0\u6d4b\u3001GPT-4\u63a8\u7406\u548c\u672c\u5730Gemma-3\u90e8\u7f72\uff0c\u5b9e\u73b0LLM\u9a71\u52a8\u7684\u63a8\u7406\u3001\u6570\u636e\u5e93\u67e5\u8be2\u548c\u7b2c\u4e09\u65b9\u7cfb\u7edf\u4ea4\u4e92", "result": "\u5728\u6a21\u62df\u641c\u6551\u573a\u666f\u4e2d\uff0c\u68c0\u6d4b\u7f6e\u4fe1\u5ea6\u4ece0.72\u63d0\u5347\u52300.79\uff0c\u4eba\u5458\u68c0\u6d4b\u7387\u4ece75%\u63d0\u5347\u523091%\uff0c\u884c\u52a8\u63a8\u8350\u7387\u4ece4.5%\u5927\u5e45\u63d0\u5347\u523092%\uff0c\u8bc1\u660e\u9002\u5ea6\u7684\u8ba1\u7b97\u5f00\u9500\u53ef\u5b9e\u73b0\u8d28\u7684\u81ea\u4e3b\u6027\u63d0\u5347", "conclusion": "Agentic UAVs\u6846\u67b6\u901a\u8fc7LLM\u667a\u80fd\u4f53\u548c\u5de5\u5177\u8c03\u7528\u80fd\u529b\uff0c\u4e3a\u65e0\u4eba\u673a\u7cfb\u7edf\u5e26\u6765\u4e86\u8d28\u7684\u81ea\u4e3b\u6027\u98de\u8dc3\u548c\u751f\u6001\u7cfb\u7edf\u96c6\u6210\u80fd\u529b\uff0c\u4e3a\u52a8\u6001\u4e0d\u786e\u5b9a\u4efb\u52a1\u4e2d\u7684\u9002\u5e94\u6027\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.13370", "categories": ["cs.CY", "cs.GT"], "pdf": "https://arxiv.org/pdf/2509.13370", "abs": "https://arxiv.org/abs/2509.13370", "authors": ["Andrew Conway", "Michelle Blom", "Alexander Ek", "Peter Stuckey", "Vanessa Teague", "Damjan Vukcevic"], "title": "To whom did my vote go?", "comment": null, "summary": "Single Transferable Vote (STV) counting, used in several jurisdictions in\nAustralia, is a system for choosing multiple election winners given voters'\npreferences among candidates. The system is complex and it is not always\nobvious how an individual's vote contributes to candidates' tallies across\nrounds of tabulation. This short paper presents a demonstration system that\nallows voters to enter an example vote in a past Australian STV election, and\nsee: (i)~how that vote would have been transferred between candidates; and\n(ii)~how much that vote would have contributed to the tallies of relevant\ncandidates, across rounds of tabulation.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u6f14\u793a\u7cfb\u7edf\uff0c\u8ba9\u9009\u6c11\u80fd\u591f\u8f93\u5165\u5728\u6fb3\u5927\u5229\u4e9aSTV\u9009\u4e3e\u4e2d\u7684\u793a\u4f8b\u6295\u7968\uff0c\u67e5\u770b\u6295\u7968\u5982\u4f55\u5728\u5019\u9009\u4eba\u4e4b\u95f4\u8f6c\u79fb\u4ee5\u53ca\u5bf9\u5019\u9009\u4eba\u5f97\u7968\u6570\u7684\u8d21\u732e\u3002", "motivation": "STV\u8ba1\u7968\u7cfb\u7edf\u590d\u6742\uff0c\u9009\u6c11\u96be\u4ee5\u7406\u89e3\u4e2a\u4eba\u6295\u7968\u5982\u4f55\u5728\u4e0d\u540c\u8ba1\u7968\u8f6e\u6b21\u4e2d\u5f71\u54cd\u5019\u9009\u4eba\u5f97\u7968\u60c5\u51b5\uff0c\u9700\u8981\u76f4\u89c2\u7684\u6f14\u793a\u5de5\u5177\u6765\u589e\u5f3a\u900f\u660e\u5ea6\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u6f14\u793a\u7cfb\u7edf\uff0c\u5141\u8bb8\u7528\u6237\u8f93\u5165\u793a\u4f8b\u6295\u7968\uff0c\u6a21\u62dfSTV\u9009\u4e3e\u8fc7\u7a0b\uff0c\u5c55\u793a\u6295\u7968\u8f6c\u79fb\u8def\u5f84\u548c\u5bf9\u5019\u9009\u4eba\u5f97\u7968\u7684\u5177\u4f53\u8d21\u732e\u3002", "result": "\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e86STV\u6295\u7968\u8fc7\u7a0b\u7684\u53ef\u89c6\u5316\u6f14\u793a\uff0c\u5e2e\u52a9\u9009\u6c11\u7406\u89e3\u590d\u6742\u7684\u6295\u7968\u8f6c\u79fb\u673a\u5236\u548c\u4e2a\u4eba\u6295\u7968\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "conclusion": "\u8be5\u6f14\u793a\u7cfb\u7edf\u6709\u6548\u63d0\u5347\u4e86STV\u9009\u4e3e\u8fc7\u7a0b\u7684\u900f\u660e\u5ea6\u548c\u9009\u6c11\u7406\u89e3\uff0c\u4e3a\u590d\u6742\u6295\u7968\u7cfb\u7edf\u7684\u516c\u4f17\u6559\u80b2\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2509.13558", "categories": ["eess.SY", "cs.SY", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2509.13558", "abs": "https://arxiv.org/abs/2509.13558", "authors": ["Saad Rahman", "Doyal Sarker", "Tri Ngo", "Roger Bergua", "Daniel Zalkind", "Jason Jonkman", "Tuhin Das"], "title": "Modeling and Verification of Lumped-Parameter, Multibody Structural Dynamics for Offshore Wind Turbines", "comment": null, "summary": "This paper presents the modeling and verification of multibody structural\ndynamics for offshore wind turbines. The flexible tower and support structure\nof a monopile-based offshore wind turbine are modeled using an acausal,\nlumped-parameter, multibody approach that incorporates structural flexibility,\nsoil-structure interaction, and hydrodynamic models. Simulation results are\nbenchmarked against alternative modeling approaches, demonstrating the model's\nability to accurately capture both static and dynamic behaviors under various\nwind and wave conditions while maintaining computational efficiency. This work\nprovides a valuable tool for analyzing key structural characteristics of wind\nturbines, including eigenfrequencies, mode shapes, damping, and internal\nforces.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6d77\u4e0a\u98ce\u529b\u6da1\u8f6e\u673a\u7684\u591a\u4f53\u7ed3\u6784\u52a8\u529b\u5b66\u5efa\u6a21\u4e0e\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u91c7\u7528\u96c6\u603b\u53c2\u6570\u591a\u4f53\u65b9\u6cd5\u5bf9\u67d4\u6027\u5854\u67b6\u548c\u652f\u6491\u7ed3\u6784\u8fdb\u884c\u5efa\u6a21\uff0c\u5305\u542b\u7ed3\u6784\u67d4\u6027\u3001\u571f-\u7ed3\u6784\u76f8\u4e92\u4f5c\u7528\u548c\u6c34\u52a8\u529b\u6a21\u578b\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u51c6\u786e\u6355\u6349\u6d77\u4e0a\u98ce\u529b\u6da1\u8f6e\u673a\u5728\u5404\u79cd\u98ce\u6d6a\u6761\u4ef6\u4e0b\u9759\u6001\u548c\u52a8\u6001\u884c\u4e3a\u7684\u8ba1\u7b97\u9ad8\u6548\u6a21\u578b\uff0c\u4e3a\u5206\u6790\u5173\u952e\u7ed3\u6784\u7279\u6027\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u5de5\u5177\u3002", "method": "\u4f7f\u7528\u975e\u56e0\u679c\u3001\u96c6\u603b\u53c2\u6570\u7684\u591a\u4f53\u65b9\u6cd5\u5bf9\u5355\u6869\u57fa\u7840\u6d77\u4e0a\u98ce\u529b\u6da1\u8f6e\u673a\u7684\u67d4\u6027\u5854\u67b6\u548c\u652f\u6491\u7ed3\u6784\u8fdb\u884c\u5efa\u6a21\uff0c\u6574\u5408\u4e86\u7ed3\u6784\u67d4\u6027\u3001\u571f-\u7ed3\u6784\u76f8\u4e92\u4f5c\u7528\u548c\u6c34\u52a8\u529b\u6a21\u578b\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u4e0e\u5176\u4ed6\u5efa\u6a21\u65b9\u6cd5\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc1\u660e\u8be5\u6a21\u578b\u80fd\u591f\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u51c6\u786e\u6355\u6349\u5404\u79cd\u98ce\u6d6a\u6761\u4ef6\u4e0b\u7684\u9759\u6001\u548c\u52a8\u6001\u884c\u4e3a\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5206\u6790\u98ce\u529b\u6da1\u8f6e\u673a\u7684\u5173\u952e\u7ed3\u6784\u7279\u6027\uff08\u5305\u62ec\u7279\u5f81\u9891\u7387\u3001\u6a21\u6001\u5f62\u72b6\u3001\u963b\u5c3c\u548c\u5185\u529b\uff09\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5efa\u6a21\u5de5\u5177\uff0c\u5177\u6709\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7684\u53cc\u91cd\u4f18\u52bf\u3002"}}
{"id": "2509.13501", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13501", "abs": "https://arxiv.org/abs/2509.13501", "authors": ["Hossein Gholampour", "Logan E. Beaver"], "title": "Trajectory Tracking with Reachability-Guided Quadratic Programming and Freeze-Resume", "comment": null, "summary": "Many robotic systems must follow planned paths yet pause safely and resume\nwhen people or objects intervene. We present an output-space method for systems\nwhose tracked output can be feedback-linearized to a double integrator (e.g.,\nmanipulators). The approach has two parts. Offline, we perform a pre-run\nreachability check to verify that the motion plan respects speed and\nacceleration magnitude limits. Online, we apply a quadratic program to track\nthe motion plan under the same limits. We use a one-step reachability test to\nbound the maximum disturbance the system is capable of rejecting. When the\nstate coincides with the reference path we recover perfect tracking in the\ndeterministic case, and we correct errors using a KKT-inspired weight. We\ndemonstrate that safety stops and unplanned deviations are handled efficiently,\nand the system returns to the motion plan without replanning. We demonstrate\nour system's improved performance over pure pursuit in simulation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8f93\u51fa\u7a7a\u95f4\u65b9\u6cd5\uff0c\u7528\u4e8e\u53ef\u53cd\u9988\u7ebf\u6027\u5316\u4e3a\u53cc\u79ef\u5206\u5668\u7684\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u901a\u8fc7\u79bb\u7ebf\u53ef\u8fbe\u6027\u68c0\u67e5\u548c\u5728\u7ebf\u4e8c\u6b21\u89c4\u5212\u8ddf\u8e2a\uff0c\u5728\u4fdd\u6301\u901f\u5ea6\u52a0\u901f\u5ea6\u9650\u5236\u7684\u540c\u65f6\u5904\u7406\u5b89\u5168\u505c\u6b62\u548c\u610f\u5916\u504f\u5dee\u3002", "motivation": "\u8bb8\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u9700\u8981\u9075\u5faa\u89c4\u5212\u8def\u5f84\uff0c\u540c\u65f6\u5728\u4eba\u5458\u6216\u7269\u4f53\u5e72\u9884\u65f6\u80fd\u591f\u5b89\u5168\u6682\u505c\u548c\u6062\u590d\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5b89\u5168\u505c\u6b62\u548c\u6062\u590d\u8ddf\u8e2a\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "method": "\u79bb\u7ebf\u8fdb\u884c\u53ef\u8fbe\u6027\u68c0\u67e5\u9a8c\u8bc1\u8fd0\u52a8\u8ba1\u5212\u7b26\u5408\u9650\u5236\uff0c\u5728\u7ebf\u5e94\u7528\u4e8c\u6b21\u89c4\u5212\u8ddf\u8e2a\u8fd0\u52a8\u8ba1\u5212\uff0c\u4f7f\u7528\u4e00\u6b65\u53ef\u8fbe\u6027\u6d4b\u8bd5\u6765\u7ea6\u675f\u7cfb\u7edf\u80fd\u591f\u62d2\u7edd\u7684\u6700\u5927\u6270\u52a8\uff0c\u91c7\u7528KKT\u542f\u53d1\u6743\u91cd\u7ea0\u6b63\u8bef\u5dee\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u9ad8\u6548\u5904\u7406\u5b89\u5168\u505c\u6b62\u548c\u975e\u8ba1\u5212\u504f\u5dee\uff0c\u65e0\u9700\u91cd\u65b0\u89c4\u5212\u5373\u53ef\u8fd4\u56de\u8fd0\u52a8\u8ba1\u5212\uff0c\u5728\u4eff\u771f\u4e2d\u8868\u73b0\u51fa\u6bd4\u7eaf\u8ffd\u8e2a\u65b9\u6cd5\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u8def\u5f84\u8ddf\u8e2a\u548c\u5b89\u5168\u6682\u505c\u673a\u5236\uff0c\u5728\u4fdd\u6301\u8fd0\u52a8\u9650\u5236\u7684\u540c\u65f6\u786e\u4fdd\u5b89\u5168\u6027\u548c\u8ddf\u8e2a\u6027\u80fd\u3002"}}
{"id": "2509.13357", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13357", "abs": "https://arxiv.org/abs/2509.13357", "authors": ["Yongchao Huang", "Hassan Raza"], "title": "Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling", "comment": "16 pages", "summary": "We propose semantic fusion, a lightweight scheme that augments a Transformer\nlanguage model (LM) with a parallel, fuzzy-membership feature channel that\nencodes token-level semantics. Each token is represented by a vector of\ninterpretable features (e.g. part-of-speech cues, shallow roles, boundary\nflags, sentiment polarity and strength) whose values are graded degrees from\ndifferentiable membership functions (e.g. power kernels). These per-token\nvectors form a sentence-level semantic matrix fused via a gated adapter into\nthe LM. Training uses standard next-token prediction, an auxiliary loss that\nreconstructs the semantic features from hidden states, and a lightweight\nuniformizer that regularizes adjective-class distributions. On a synthetic\ntwo-clause corpus with held-out adjectives for out-of-distribution (OOD)\ncontrol, semantic fusion improves perplexity and enables precise,\nuser-controllable generation of polarity and punctuation while maintaining\nmodel simplicity. This approach adds only small overhead, remains fully\ncompatible with tied input-output embeddings, and provides an interpretable\npathway for conditioned natural language generation.", "AI": {"tldr": "\u63d0\u51fa\u8bed\u4e49\u878d\u5408\u65b9\u6848\uff0c\u901a\u8fc7\u5e76\u884c\u6a21\u7cca\u6210\u5458\u7279\u5f81\u901a\u9053\u589e\u5f3aTransformer\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u8bed\u4e49\u7279\u5f81\u878d\u5408\u548c\u53ef\u63a7\u751f\u6210", "motivation": "\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u8868\u793a\u80fd\u529b\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7279\u5f81\u901a\u9053\uff0c\u5b9e\u73b0\u7528\u6237\u53ef\u63a7\u7684\u6587\u672c\u751f\u6210\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7b80\u6d01\u6027", "method": "\u4f7f\u7528\u53ef\u89e3\u91ca\u7279\u5f81\u5411\u91cf\uff08\u8bcd\u6027\u3001\u8bed\u4e49\u89d2\u8272\u3001\u8fb9\u754c\u6807\u5fd7\u3001\u60c5\u611f\u6781\u6027\u7b49\uff09\u6784\u5efa\u8bed\u4e49\u77e9\u9635\uff0c\u901a\u8fc7\u95e8\u63a7\u9002\u914d\u5668\u878d\u5408\u5230\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u91c7\u7528\u8f85\u52a9\u635f\u5931\u548c\u6b63\u5219\u5316\u8bad\u7ec3", "result": "\u5728\u5408\u6210\u53cc\u5b50\u53e5\u8bed\u6599\u5e93\u4e0a\uff0c\u8bed\u4e49\u878d\u5408\u63d0\u9ad8\u4e86\u56f0\u60d1\u5ea6\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u60c5\u611f\u6781\u6027\u548c\u6807\u70b9\u7b26\u53f7\u53ef\u63a7\u751f\u6210\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7b80\u6d01", "conclusion": "\u8bed\u4e49\u878d\u5408\u4e3a\u6761\u4ef6\u81ea\u7136\u8bed\u8a00\u751f\u6210\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u8f83\u5c0f\u7684\u8ba1\u7b97\u5f00\u9500\u548c\u826f\u597d\u7684\u517c\u5bb9\u6027"}}
{"id": "2509.13387", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13387", "abs": "https://arxiv.org/abs/2509.13387", "authors": ["Delaram Golpayegani", "Marta Lasek-Markey", "Arjumand Younus", "Aphra Kerr", "Dave Lewis"], "title": "Uncovering AI Governance Themes in EU Policies using BERTopic and Thematic Analysis", "comment": null, "summary": "The upsurge of policies and guidelines that aim to ensure Artificial\nIntelligence (AI) systems are safe and trustworthy has led to a fragmented\nlandscape of AI governance. The European Union (EU) is a key actor in the\ndevelopment of such policies and guidelines. Its High-Level Expert Group (HLEG)\nissued an influential set of guidelines for trustworthy AI, followed in 2024 by\nthe adoption of the EU AI Act. While the EU policies and guidelines are\nexpected to be aligned, they may differ in their scope, areas of emphasis,\ndegrees of normativity, and priorities in relation to AI. To gain a broad\nunderstanding of AI governance from the EU perspective, we leverage qualitative\nthematic analysis approaches to uncover prevalent themes in key EU documents,\nincluding the AI Act and the HLEG Ethics Guidelines. We further employ\nquantitative topic modelling approaches, specifically through the use of the\nBERTopic model, to enhance the results and increase the document sample to\ninclude EU AI policy documents published post-2018. We present a novel\nperspective on EU policies, tracking the evolution of its approach to\naddressing AI governance.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9a\u6027\u548c\u5b9a\u91cf\u65b9\u6cd5\u5206\u6790\u6b27\u76dfAI\u6cbb\u7406\u653f\u7b56\uff0c\u8ffd\u8e2a\u4ece2018\u5e74HLEG\u4f26\u7406\u6307\u5357\u52302024\u5e74AI\u6cd5\u6848\u7684\u653f\u7b56\u6f14\u53d8\uff0c\u63ed\u793a\u6b27\u76dfAI\u6cbb\u7406\u7684\u788e\u7247\u5316\u73b0\u72b6\u548c\u53d1\u5c55\u8d8b\u52bf\u3002", "motivation": "\u6b27\u76dfAI\u6cbb\u7406\u653f\u7b56\u5448\u73b0\u788e\u7247\u5316\u683c\u5c40\uff0c\u867d\u7136\u6b27\u76df\u7684\u653f\u7b56\u548c\u6307\u5357\u9884\u671f\u5e94\u8be5\u534f\u8c03\u4e00\u81f4\uff0c\u4f46\u5728\u8303\u56f4\u3001\u91cd\u70b9\u9886\u57df\u3001\u89c4\u8303\u7a0b\u5ea6\u548cAI\u76f8\u5173\u4f18\u5148\u7ea7\u65b9\u9762\u53ef\u80fd\u5b58\u5728\u5dee\u5f02\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790\u4ee5\u7406\u89e3\u6b27\u76dfAI\u6cbb\u7406\u7684\u6574\u4f53\u89c6\u89d2\u3002", "method": "\u91c7\u7528\u5b9a\u6027\u4e3b\u9898\u5206\u6790\u65b9\u6cd5\u5206\u6790\u5173\u952e\u6b27\u76df\u6587\u4ef6\uff08AI\u6cd5\u6848\u548cHLEG\u4f26\u7406\u6307\u5357\uff09\uff0c\u5e76\u8fd0\u7528BERTopic\u6a21\u578b\u8fdb\u884c\u5b9a\u91cf\u4e3b\u9898\u5efa\u6a21\uff0c\u5c06\u6587\u6863\u6837\u672c\u6269\u5c55\u52302018\u5e74\u540e\u53d1\u5e03\u7684\u6b27\u76dfAI\u653f\u7b56\u6587\u4ef6\u3002", "result": "\u63ed\u793a\u4e86\u6b27\u76dfAI\u6cbb\u7406\u653f\u7b56\u7684\u6f14\u53d8\u8f68\u8ff9\uff0c\u53d1\u73b0\u4e86\u653f\u7b56\u6587\u4ef6\u4e2d\u7684\u4e3b\u8981\u4e3b\u9898\u548c\u5173\u6ce8\u91cd\u70b9\u7684\u53d8\u5316\uff0c\u63d0\u4f9b\u4e86\u5bf9\u6b27\u76dfAI\u6cbb\u7406\u65b9\u6cd5\u53d1\u5c55\u7684\u65b0\u89c6\u89d2\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5bf9\u6b27\u76dfAI\u6cbb\u7406\u653f\u7b56\u6f14\u53d8\u7684\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u6b27\u76df\u5728AI\u5b89\u5168\u53ef\u4fe1\u6cbb\u7406\u65b9\u9762\u7684\u653f\u7b56\u53d1\u5c55\u8109\u7edc\u548c\u672a\u6765\u8d8b\u52bf\u3002"}}
{"id": "2509.13564", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.13564", "abs": "https://arxiv.org/abs/2509.13564", "authors": ["Arman Pourghorban", "Dipankar Maity"], "title": "Multi-Attacker Single-Defender Target Defense in Conical Environments", "comment": null, "summary": "We consider a variant of the target defense problem in a planar conical\nenvironment where a single defender is tasked to capture a sequence of incoming\nattackers. The attackers' objective is to breach the target boundary without\nbeing captured by the defender. As soon as the current attacker breaches the\ntarget or gets captured by the defender, the next attacker appears at the\nboundary of the environment and moves radially toward the target with maximum\nspeed. Therefore, the defender's final location at the end of the current game\nbecomes its initial location for the next game. The attackers pick strategies\nthat are advantageous for the current as well as for future engagements between\nthe defender and the remaining attackers. The attackers have their own sensors\nwith limited range, using which they can perfectly detect if the defender is\nwithin their sensing range. We derive equilibrium strategies for all the\nplayers to optimize the capture percentage using the notions of capture\ndistribution. Finally, the theoretical results are verified through numerical\nexamples using Monte Carlo type random trials of experiments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5e73\u9762\u9525\u5f62\u73af\u5883\u4e2d\u7684\u76ee\u6807\u9632\u5fa1\u95ee\u9898\uff0c\u5355\u4e2a\u9632\u5fa1\u8005\u9700\u8981\u6355\u83b7\u4e00\u7cfb\u5217\u6765\u88ad\u653b\u51fb\u8005\u3002\u653b\u51fb\u8005\u8bd5\u56fe\u7a81\u7834\u76ee\u6807\u8fb9\u754c\u800c\u4e0d\u88ab\u6355\u83b7\uff0c\u9632\u5fa1\u8005\u9700\u8981\u4f18\u5316\u6355\u83b7\u7387\u3002", "motivation": "\u7814\u7a76\u591a\u8f6e\u653b\u9632\u535a\u5f08\u4e2d\u7684\u7b56\u7565\u4f18\u5316\u95ee\u9898\uff0c\u8003\u8651\u653b\u51fb\u8005\u5177\u6709\u6709\u9650\u611f\u77e5\u80fd\u529b\u4e14\u80fd\u591f\u4e3a\u672a\u6765\u653b\u51fb\u9009\u62e9\u6709\u5229\u7b56\u7565\u7684\u573a\u666f\uff0c\u65e8\u5728\u4e3a\u9632\u5fa1\u8005\u63d0\u4f9b\u6700\u4f18\u9632\u5fa1\u7b56\u7565\u3002", "method": "\u4f7f\u7528\u535a\u5f08\u8bba\u65b9\u6cd5\u63a8\u5bfc\u5747\u8861\u7b56\u7565\uff0c\u901a\u8fc7\u6355\u83b7\u5206\u5e03\u6982\u5ff5\u4f18\u5316\u6355\u83b7\u767e\u5206\u6bd4\uff0c\u5e76\u91c7\u7528\u8499\u7279\u5361\u6d1b\u968f\u673a\u8bd5\u9a8c\u8fdb\u884c\u6570\u503c\u9a8c\u8bc1\u3002", "result": "\u63a8\u5bfc\u51fa\u4e86\u6240\u6709\u53c2\u4e0e\u8005\u7684\u5747\u8861\u7b56\u7565\uff0c\u7406\u8bba\u4e0a\u4f18\u5316\u4e86\u6355\u83b7\u7387\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5e73\u9762\u9525\u5f62\u73af\u5883\u4e2d\u7684\u5e8f\u5217\u76ee\u6807\u9632\u5fa1\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5747\u8861\u7b56\u7565\u89e3\u51b3\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u4f18\u5316\u9632\u5fa1\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.13534", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13534", "abs": "https://arxiv.org/abs/2509.13534", "authors": ["Chunxin Zheng", "Kai Chen", "Zhihai Bi", "Yulin Li", "Liang Pan", "Jinni Zhou", "Haoang Li", "Jun Ma"], "title": "Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning", "comment": null, "summary": "Whole-body manipulation (WBM) for humanoid robots presents a promising\napproach for executing embracing tasks involving bulky objects, where\ntraditional grasping relying on end-effectors only remains limited in such\nscenarios due to inherent stability and payload constraints. This paper\nintroduces a reinforcement learning framework that integrates a pre-trained\nhuman motion prior with a neural signed distance field (NSDF) representation to\nachieve robust whole-body embracing. Our method leverages a teacher-student\narchitecture to distill large-scale human motion data, generating kinematically\nnatural and physically feasible whole-body motion patterns. This facilitates\ncoordinated control across the arms and torso, enabling stable multi-contact\ninteractions that enhance the robustness in manipulation and also the load\ncapacity. The embedded NSDF further provides accurate and continuous geometric\nperception, improving contact awareness throughout long-horizon tasks. We\nthoroughly evaluate the approach through comprehensive simulations and\nreal-world experiments. The results demonstrate improved adaptability to\ndiverse shapes and sizes of objects and also successful sim-to-real transfer.\nThese indicate that the proposed framework offers an effective and practical\nsolution for multi-contact and long-horizon WBM tasks of humanoid robots.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u4eba\u4f53\u8fd0\u52a8\u5148\u9a8c\u548c\u795e\u7ecf\u7b26\u53f7\u8ddd\u79bb\u573a\u8868\u793a\uff0c\u5b9e\u73b0\u4eba\u5f62\u673a\u5668\u4eba\u7a33\u5065\u7684\u5168\u8eab\u62e5\u62b1\u64cd\u4f5c", "motivation": "\u4f20\u7edf\u4ec5\u4f9d\u8d56\u672b\u7aef\u6267\u884c\u5668\u7684\u6293\u53d6\u65b9\u6cd5\u5728\u5904\u7406\u5927\u4f53\u79ef\u7269\u4f53\u65f6\u5b58\u5728\u7a33\u5b9a\u6027\u548c\u8d1f\u8f7d\u80fd\u529b\u9650\u5236\uff0c\u9700\u8981\u5f00\u53d1\u5168\u8eab\u64cd\u7eb5\u6280\u672f\u6765\u6267\u884c\u62e5\u62b1\u4efb\u52a1", "method": "\u91c7\u7528\u5e08\u751f\u67b6\u6784\u84b8\u998f\u5927\u89c4\u6a21\u4eba\u4f53\u8fd0\u52a8\u6570\u636e\uff0c\u751f\u6210\u8fd0\u52a8\u5b66\u81ea\u7136\u4e14\u7269\u7406\u53ef\u884c\u7684\u5168\u8eab\u8fd0\u52a8\u6a21\u5f0f\uff0c\u7ed3\u5408\u795e\u7ecf\u7b26\u53f7\u8ddd\u79bb\u573a\u63d0\u4f9b\u7cbe\u786e\u51e0\u4f55\u611f\u77e5", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u5bf9\u591a\u6837\u5f62\u72b6\u5c3a\u5bf8\u7269\u4f53\u7684\u9002\u5e94\u80fd\u529b\u63d0\u5347\uff0c\u6210\u529f\u5b9e\u73b0\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u8fc1\u79fb", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4eba\u5f62\u673a\u5668\u4eba\u7684\u591a\u63a5\u89e6\u548c\u957f\u65f6\u7a0b\u5168\u8eab\u64cd\u7eb5\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.13364", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13364", "abs": "https://arxiv.org/abs/2509.13364", "authors": ["Zixi Li"], "title": "Asterisk Operator", "comment": "Code available at: https://github.com/lizixi-0x2F/Asterisk-Games", "summary": "We propose the \\textbf{Asterisk Operator} ($\\ast$-operator), a novel unified\nframework for abstract reasoning based on Adjacency-Structured Parallel\nPropagation (ASPP). The operator formalizes structured reasoning tasks as\nlocal, parallel state evolution processes guided by implicit relational graphs.\nWe prove that the $\\ast$-operator maintains local computational constraints\nwhile achieving global reasoning capabilities, providing an efficient and\nconvergent computational paradigm for abstract reasoning problems. Through\nrigorous mathematical analysis and comprehensive experiments on ARC2 challenges\nand Conway's Game of Life, we demonstrate the operator's universality,\nconvergence properties, and superior performance. Our innovative\nEmbedding-Asterisk distillation method achieves 100\\% accuracy on ARC2\nvalidation with only 6M parameters, representing a significant breakthrough in\nneural-symbolic reasoning.\n  \\textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel\nPropagation, Asterisk Operator, Convergence, Universal Approximation", "AI": {"tldr": "\u63d0\u51fa\u4e86\u661f\u53f7\u64cd\u4f5c\u7b26\uff08\u2217-operator\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u90bb\u63a5\u7ed3\u6784\u5e76\u884c\u4f20\u64ad\uff08ASPP\uff09\u7684\u62bd\u8c61\u63a8\u7406\u7edf\u4e00\u6846\u67b6\uff0c\u5c06\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\u5f62\u5f0f\u5316\u4e3a\u7531\u9690\u5f0f\u5173\u7cfb\u56fe\u5f15\u5bfc\u7684\u5c40\u90e8\u5e76\u884c\u72b6\u6001\u6f14\u5316\u8fc7\u7a0b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u62bd\u8c61\u63a8\u7406\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u5c40\u90e8\u8ba1\u7b97\u7ea6\u675f\u53c8\u80fd\u5b9e\u73b0\u5168\u5c40\u63a8\u7406\u80fd\u529b\u7684\u9ad8\u6548\u8ba1\u7b97\u8303\u5f0f\uff0c\u5f25\u5408\u795e\u7ecf\u4e0e\u7b26\u53f7\u63a8\u7406\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002", "method": "\u57fa\u4e8e\u90bb\u63a5\u7ed3\u6784\u5e76\u884c\u4f20\u64ad\uff08ASPP\uff09\u7684\u661f\u53f7\u64cd\u4f5c\u7b26\u6846\u67b6\uff0c\u901a\u8fc7\u5c40\u90e8\u5e76\u884c\u72b6\u6001\u6f14\u5316\u8fc7\u7a0b\u8fdb\u884c\u63a8\u7406\uff0c\u5e76\u63d0\u51fa\u4e86Embedding-Asterisk\u84b8\u998f\u65b9\u6cd5\u3002", "result": "\u5728ARC2\u6311\u6218\u548c\u5eb7\u5a01\u751f\u547d\u6e38\u620f\u4e2d\u9a8c\u8bc1\u4e86\u64cd\u4f5c\u7b26\u7684\u901a\u7528\u6027\u3001\u6536\u655b\u6027\u548c\u4f18\u8d8a\u6027\u80fd\uff0c\u4f7f\u7528\u4ec56M\u53c2\u6570\u5728ARC2\u9a8c\u8bc1\u96c6\u4e0a\u8fbe\u5230100%\u51c6\u786e\u7387\u3002", "conclusion": "\u661f\u53f7\u64cd\u4f5c\u7b26\u4e3a\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u63d0\u4f9b\u4e86\u7a81\u7834\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u6536\u655b\u7684\u62bd\u8c61\u63a8\u7406\u8ba1\u7b97\u8303\u5f0f\u3002"}}
{"id": "2509.13391", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13391", "abs": "https://arxiv.org/abs/2509.13391", "authors": ["Sandrine R. Schiller", "Camilo Miguel Signorelli", "Filippos Stamatiou"], "title": "The Intercepted Self: How Generative AI Challenges the Dynamics of the Relational Self", "comment": "8 pages, accepted at the 8th AAAI/ACM Conference on AI, Ethics, and\n  Society", "summary": "Generative AI is changing our way of interacting with technology, others, and\nourselves. Systems such as Microsoft copilot, Gemini and the expected Apple\nintelligence still awaits our prompt for action. Yet, it is likely that AI\nassistant systems will only become better at predicting our behaviour and\nacting on our behalf. Imagine new generations of generative and predictive AI\ndeciding what you might like best at a new restaurant, picking an outfit that\nincreases your chances on your date with a partner also chosen by the same or a\nsimilar system. Far from a science fiction scenario, the goal of several\nresearch programs is to build systems capable of assisting us in exactly this\nmanner. The prospect urges us to rethink human-technology relations, but it\nalso invites us to question how such systems might change the way we relate to\nourselves. Building on our conception of the relational self, we question the\npossible effects of generative AI with respect to what we call the sphere of\nexternalised output, the contextual sphere and the sphere of self-relating. In\nthis paper, we attempt to deepen the existential considerations accompanying\nthe AI revolution by outlining how generative AI enables the fulfilment of\ntasks and also increasingly anticipates, i.e. intercepts, our initiatives in\nthese different spheres.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5982\u4f55\u901a\u8fc7\u9884\u6d4b\u548c\u4ee3\u7406\u884c\u4e3a\u6539\u53d8\u4eba\u7c7b\u4e0e\u6280\u672f\u3001\u4ed6\u4eba\u53ca\u81ea\u6211\u7684\u5173\u7cfb\uff0c\u4ece\u5916\u90e8\u5316\u8f93\u51fa\u3001\u60c5\u5883\u548c\u81ea\u6211\u5173\u8054\u4e09\u4e2a\u7ef4\u5ea6\u5206\u6790AI\u5bf9\u4eba\u7c7b\u5b58\u5728\u65b9\u5f0f\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u7cfb\u7edf\u8d8a\u6765\u8d8a\u64c5\u957f\u9884\u6d4b\u4eba\u7c7b\u884c\u4e3a\u5e76\u4ee3\u8868\u4eba\u7c7b\u884c\u52a8\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003\u4eba\u7c7b\u4e0e\u6280\u672f\u7684\u5173\u7cfb\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u7cfb\u7edf\u5982\u4f55\u6539\u53d8\u6211\u4eec\u4e0e\u81ea\u6211\u7684\u5173\u7cfb\u3002", "method": "\u57fa\u4e8e\u5173\u7cfb\u81ea\u6211\u7684\u6982\u5ff5\uff0c\u4ece\u4e09\u4e2a\u7ef4\u5ea6\u5206\u6790\u751f\u6210\u5f0fAI\u7684\u5f71\u54cd\uff1a\u5916\u90e8\u5316\u8f93\u51fa\u9886\u57df\uff08AI\u5b8c\u6210\u4efb\u52a1\uff09\u3001\u60c5\u5883\u9886\u57df\uff08AI\u9884\u6d4b\u884c\u4e3a\uff09\u548c\u81ea\u6211\u5173\u8054\u9886\u57df\uff08AI\u5f71\u54cd\u81ea\u6211\u8ba4\u77e5\uff09\u3002", "result": "\u751f\u6210\u5f0fAI\u4e0d\u4ec5\u80fd\u591f\u534f\u52a9\u5b8c\u6210\u4efb\u52a1\uff0c\u8fd8\u80fd\u5728\u8d8a\u6765\u8d8a\u5927\u7684\u7a0b\u5ea6\u4e0a\u9884\u6d4b\u548c\u62e6\u622a\u4eba\u7c7b\u5728\u5404\u4e2a\u9886\u57df\u7684\u4e3b\u52a8\u6027\uff0c\u8fd9\u5f15\u53d1\u4e86\u6df1\u5c42\u7684\u5b58\u5728\u4e3b\u4e49\u601d\u8003\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u7684\u53d1\u5c55\u4fc3\u4f7f\u6211\u4eec\u5fc5\u987b\u91cd\u65b0\u5ba1\u89c6\u4eba\u7c7b\u4e0e\u6280\u672f\u7684\u5173\u7cfb\uff0c\u7279\u522b\u662f\u5728AI\u7cfb\u7edf\u5f00\u59cb\u9884\u6d4b\u548c\u4ee3\u7406\u4eba\u7c7b\u884c\u4e3a\u65f6\uff0c\u8fd9\u5bf9\u4eba\u7c7b\u81ea\u6211\u8ba4\u77e5\u548c\u5b58\u5728\u65b9\u5f0f\u4ea7\u751f\u4e86\u6df1\u8fdc\u5f71\u54cd\u3002"}}
{"id": "2509.13567", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.13567", "abs": "https://arxiv.org/abs/2509.13567", "authors": ["Praveen Verma", "Di Shi", "Yanzhu Ye", "Fengyu Wang", "Ying Zhang"], "title": "Impact of Solar Integration on Grid Security: Unveiling Vulnerabilities in Load Redistribution Attacks", "comment": "Accepted in 16th IEEE PowerTech 2025, Kiel, Germany", "summary": "Load redistribution (LR) attacks represent a practical and sophisticated form\nof false data injection (FDI) attacks, where the attacker manipulates grid data\nto influence economic operations of the grid through misleading security\nconstrained economic dispatch (SCED) decisions. Traditionally, LR attack models\noperate under the assumption that generator measurements are secure and immune\nto tampering. However, the increasing integration of solar generation into\npower grids challenges this assumption, exposing new vulnerabilities. This\npaper proposes an enhanced load redistribution attack model, addressing new\nvulnerabilities introduced by the increasing integration of solar generation in\npower grids. The study demonstrates that manipulating solar generation data\nsignificantly disrupts grid economics, with peak impacts during periods of high\nsolar generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u578b\u8d1f\u8f7d\u91cd\u5206\u914d\u653b\u51fb\u6a21\u578b\uff0c\u9488\u5bf9\u592a\u9633\u80fd\u53d1\u7535\u5e76\u7f51\u5e26\u6765\u7684\u65b0\u6f0f\u6d1e\uff0c\u901a\u8fc7\u64cd\u7eb5\u592a\u9633\u80fd\u53d1\u7535\u6570\u636e\u6765\u7834\u574f\u7535\u7f51\u7ecf\u6d4e\u6027\u3002", "motivation": "\u4f20\u7edf\u8d1f\u8f7d\u91cd\u5206\u914d\u653b\u51fb\u6a21\u578b\u5047\u8bbe\u53d1\u7535\u673a\u6d4b\u91cf\u6570\u636e\u662f\u5b89\u5168\u7684\uff0c\u4f46\u968f\u7740\u592a\u9633\u80fd\u53d1\u7535\u5728\u7535\u7f51\u4e2d\u7684\u96c6\u6210\u5ea6\u4e0d\u65ad\u63d0\u9ad8\uff0c\u8fd9\u4e00\u5047\u8bbe\u53d7\u5230\u6311\u6218\uff0c\u66b4\u9732\u51fa\u65b0\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u63d0\u51fa\u589e\u5f3a\u578b\u8d1f\u8f7d\u91cd\u5206\u914d\u653b\u51fb\u6a21\u578b\uff0c\u4e13\u95e8\u9488\u5bf9\u592a\u9633\u80fd\u53d1\u7535\u6570\u636e\u64cd\u7eb5\uff0c\u7814\u7a76\u5176\u5bf9\u5b89\u5168\u7ea6\u675f\u7ecf\u6d4e\u8c03\u5ea6\u51b3\u7b56\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u8868\u660e\u64cd\u7eb5\u592a\u9633\u80fd\u53d1\u7535\u6570\u636e\u4f1a\u663e\u8457\u7834\u574f\u7535\u7f51\u7ecf\u6d4e\u6027\uff0c\u5728\u592a\u9633\u80fd\u53d1\u7535\u9ad8\u5cf0\u671f\u5f71\u54cd\u6700\u4e3a\u4e25\u91cd\u3002", "conclusion": "\u592a\u9633\u80fd\u53d1\u7535\u7684\u96c6\u6210\u5e26\u6765\u4e86\u65b0\u7684\u7535\u7f51\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u5f00\u53d1\u9488\u5bf9\u6027\u7684\u9632\u5fa1\u673a\u5236\u6765\u5e94\u5bf9\u8fd9\u7c7b\u589e\u5f3a\u578b\u8d1f\u8f7d\u91cd\u5206\u914d\u653b\u51fb\u3002"}}
{"id": "2509.13541", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.13541", "abs": "https://arxiv.org/abs/2509.13541", "authors": ["Ayberk Acar", "Fangjie Li", "Hao Li", "Lidia Al-Zogbi", "Kanyifeechukwu Jane Oguine", "Susheela Sharma Stern", "Jesse F. d'Almeida", "Robert J. Webster III", "Ipek Oguz", "Jie Ying Wu"], "title": "Semantic 3D Reconstructions with SLAM for Central Airway Obstruction", "comment": "5 pages, 2 figures, 1 table", "summary": "Central airway obstruction (CAO) is a life-threatening condition with\nincreasing incidence, caused by tumors in and outside of the airway.\nTraditional treatment methods such as bronchoscopy and electrocautery can be\nused to remove the tumor completely; however, these methods carry a high risk\nof complications. Recent advances allow robotic interventions with lesser risk.\nThe combination of robot interventions with scene understanding and mapping\nalso opens up the possibilities for automation. We present a novel pipeline\nthat enables real-time, semantically informed 3D reconstructions of the central\nairway using monocular endoscopic video.\n  Our approach combines DROID-SLAM with a segmentation model trained to\nidentify obstructive tissues. The SLAM module reconstructs the 3D geometry of\nthe airway in real time, while the segmentation masks guide the annotation of\nobstruction regions within the reconstructed point cloud. To validate our\npipeline, we evaluate the reconstruction quality using ex vivo models.\n  Qualitative and quantitative results show high similarity between ground\ntruth CT scans and the 3D reconstructions (0.62 mm Chamfer distance). By\nintegrating segmentation directly into the SLAM workflow, our system produces\nannotated 3D maps that highlight clinically relevant regions in real time.\nHigh-speed capabilities of the pipeline allows quicker reconstructions compared\nto previous work, reflecting the surgical scene more accurately.\n  To the best of our knowledge, this is the first work to integrate semantic\nsegmentation with real-time monocular SLAM for endoscopic CAO scenarios. Our\nframework is modular and can generalize to other anatomies or procedures with\nminimal changes, offering a promising step toward autonomous robotic\ninterventions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u76f4\u63a5\u5c06\u8bed\u4e49\u5206\u5272\u4e0e\u5355\u76eeSLAM\u96c6\u6210\u7684\u5b9e\u65f6\u7aef\u5236\u5185\u955c3D\u91cd\u5efa\u6d41\u7a0b\uff0c\u7528\u4e8e\u4e2d\u592e\u6c14\u9053\u963b\u585e\u7684\u81ea\u52a8\u5316\u624b\u672f\u5e72\u9884\u3002", "motivation": "\u4e2d\u592e\u6c14\u9053\u963b\u585e\u662f\u4e00\u79cd\u5371\u53ca\u751f\u547d\u7684\u75c5\u60a3\uff0c\u4f20\u7edf\u6cbb\u7597\u65b9\u6cd5\u98ce\u9669\u9ad8\uff0c\u800c\u673a\u5668\u4eba\u624b\u672f\u63d0\u4f9b\u4e86\u66f4\u5b89\u5168\u7684\u9009\u62e9\u3002\u7ed3\u5408\u573a\u666f\u7406\u89e3\u548c\u5730\u56fe\u6784\u5efa\u6280\u672f\u53ef\u4ee5\u5b9e\u73b0\u81ea\u52a8\u5316\u624b\u672f\u5e72\u9884\u3002", "method": "\u7ed3\u5408DROID-SLAM\u7b97\u6cd5\u548c\u8bad\u7ec3\u8bc6\u522b\u963b\u585e\u7ec4\u7ec7\u7684\u5206\u5272\u6a21\u578b\uff0cSLAM\u6a21\u5757\u5b9e\u65f6\u91cd\u5efa6c14\u90533D\u51e0\u4f55\uff0c\u5206\u5272\u622a\u56fe\u6307\u5bfc\u5728\u91cd\u5efa\u70b9\u4e91\u4e2d\u6807\u6ce8\u963b\u585e\u533a\u57df\u3002", "result": "\u5728ex vivo\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c3D\u91cd\u5efa\u4e0e\u771f\u5b9eCT\u626b\u63cf\u663e\u793a\u9ad8\u76f8\u4f3c\u6027\uff08Chamfer\u8ddd\u79bb0.62mm\uff09\uff0c\u80fd\u591f\u5b9e\u65f6\u751f\u6210\u6807\u6ce8\u4e86\u4e34\u5e8a\u76f8\u5173\u533a\u57df\u76843D\u5730\u56fe\uff0c\u901f\u5ea6\u66f4\u5feb\u4e14\u66f4\u51c6\u786e\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5728\u5185\u955cCAO\u573a\u666f\u4e2d\u96c6\u6210\u8bed\u4e49\u5206\u5272\u4e0e\u5b9e\u65f6\u5355\u76eeSLAM\u7684\u5de5\u4f5c\uff0c\u6a21\u5757\u5316\u8bbe\u8ba1\u53ef\u4ee5\u8f7b\u677e\u6269\u5c55\u5230\u5176\u4ed6\u89e3\u5256\u7ed3\u6784\u6216\u624b\u672f\uff0c\u4e3a\u81ea\u4e3b\u673a\u5668\u4eba\u624b\u672f\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u57fa\u7840\u3002"}}
{"id": "2509.13368", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13368", "abs": "https://arxiv.org/abs/2509.13368", "authors": ["Yuan Wei", "Xiaohan Shan", "Ran Miao", "Jianmin Li"], "title": "$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation", "comment": "9 pages, 7 figures", "summary": "Reinforcement learning agent development traditionally requires extensive\nexpertise and lengthy iterations, often resulting in high failure rates and\nlimited accessibility. This paper introduces $Agent^2$, a novel\nagent-generates-agent framework that achieves fully automated RL agent design\nthrough intelligent LLM-driven generation. The system autonomously transforms\nnatural language task descriptions and environment code into comprehensive,\nhigh-performance reinforcement learning solutions without human intervention.\n$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent\nserves as an autonomous AI designer that analyzes tasks and generates\nexecutable RL agents, while the Target Agent is the resulting automatically\ngenerated RL agent. The framework decomposes RL development into two distinct\nstages: MDP modeling and algorithmic optimization, enabling more targeted and\neffective agent generation. Built on the Model Context Protocol, $Agent^2$\nprovides a unified framework that standardizes intelligent agent creation\nacross diverse environments and algorithms, while incorporating adaptive\ntraining management and intelligent feedback analysis for continuous\nimprovement. Extensive experiments on a wide range of benchmarks, including\nMuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently\noutperforms manually designed solutions across all tasks, achieving up to 55%\nperformance improvement and substantial gains on average. By enabling truly\nend-to-end, closed-loop automation, this work establishes a new paradigm in\nwhich intelligent agents design and optimize other agents, marking a\nfundamental breakthrough for automated AI systems.", "AI": {"tldr": "Agent\u00b2\u662f\u4e00\u4e2a\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u8f6c\u6362\u4e3a\u9ad8\u6027\u80fdRL\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u7684\u4ee3\u7406\u3002", "motivation": "\u4f20\u7edfRL\u4ee3\u7406\u5f00\u53d1\u9700\u8981\u5927\u91cf\u4e13\u4e1a\u77e5\u8bc6\u548c\u8fed\u4ee3\u5468\u671f\uff0c\u5931\u8d25\u7387\u9ad8\u4e14\u53ef\u8bbf\u95ee\u6027\u6709\u9650\uff0c\u9700\u8981\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u7684RL\u4ee3\u7406\u8bbe\u8ba1\u3002", "method": "\u91c7\u7528\u53cc\u4ee3\u7406\u67b6\u6784\uff1a\u751f\u6210\u5668\u4ee3\u7406\u5206\u6790\u4efb\u52a1\u5e76\u751f\u6210\u53ef\u6267\u884cRL\u4ee3\u7406\uff0c\u76ee\u6807\u4ee3\u7406\u662f\u81ea\u52a8\u751f\u6210\u7684RL\u4ee3\u7406\u3002\u6846\u67b6\u5c06RL\u5f00\u53d1\u5206\u89e3\u4e3aMDP\u5efa\u6a21\u548c\u7b97\u6cd5\u4f18\u5316\u4e24\u4e2a\u9636\u6bb5\uff0c\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u6784\u5efa\u3002", "result": "\u5728MuJoCo\u3001MetaDrive\u3001MPE\u548cSMAC\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgent\u00b2\u59cb\u7ec8\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe55%\uff0c\u5e73\u5747\u8868\u73b0\u4e5f\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5efa\u7acb\u4e86\u667a\u80fd\u4ee3\u7406\u8bbe\u8ba1\u548c\u4f18\u5316\u5176\u4ed6\u4ee3\u7406\u7684\u65b0\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u771f\u6b63\u7684\u7aef\u5230\u7aef\u95ed\u73af\u81ea\u52a8\u5316\uff0c\u662f\u81ea\u52a8\u5316AI\u7cfb\u7edf\u7684\u6839\u672c\u6027\u7a81\u7834\u3002"}}
{"id": "2509.13397", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13397", "abs": "https://arxiv.org/abs/2509.13397", "authors": ["Jamie Cummins"], "title": "The threat of analytic flexibility in using large language models to simulate human data: A call to attention", "comment": "11 pages, 3 figures", "summary": "Social scientists are now using large language models to create \"silicon\nsamples\" - synthetic datasets intended to stand in for human respondents, aimed\nat revolutionising human subjects research. However, there are many analytic\nchoices which must be made to produce these samples. Though many of these\nchoices are defensible, their impact on sample quality is poorly understood. I\nmap out these analytic choices and demonstrate how a very small number of\ndecisions can dramatically change the correspondence between silicon samples\nand human data. Configurations (N = 252) varied substantially in their capacity\nto estimate (i) rank ordering of participants, (ii) response distributions, and\n(iii) between-scale correlations. Most critically, configurations were not\nconsistent in quality: those that performed well on one dimension often\nperformed poorly on another, implying that there is no \"one-size-fits-all\"\nconfiguration that optimises the accuracy of these samples. I call for greater\nattention to the threat of analytic flexibility in using silicon samples.", "AI": {"tldr": "\u7845\u6837\u672c\uff08synthetic datasets\uff09\u5728\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u4e2d\u5b58\u5728\u5206\u6790\u7075\u6d3b\u6027\u5a01\u80c1\uff0c\u4e0d\u540c\u914d\u7f6e\u5bf9\u6837\u672c\u8d28\u91cf\u5f71\u54cd\u5de8\u5927\uff0c\u4e14\u6ca1\u6709\u4e00\u79cd\u914d\u7f6e\u80fd\u5728\u6240\u6709\u7ef4\u5ea6\u4e0a\u90fd\u8868\u73b0\u6700\u4f18", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u88ab\u7528\u4e8e\u521b\u5efa\u66ff\u4ee3\u4eba\u7c7b\u53d7\u8bbf\u8005\u7684\u7845\u6837\u672c\uff0c\u9700\u8981\u7406\u89e3\u5404\u79cd\u5206\u6790\u9009\u62e9\u5bf9\u6837\u672c\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u4f46\u76ee\u524d\u8fd9\u79cd\u5f71\u54cd\u5c1a\u672a\u88ab\u5145\u5206\u8ba4\u8bc6", "method": "\u901a\u8fc7252\u79cd\u4e0d\u540c\u914d\u7f6e\u6d4b\u8bd5\u7845\u6837\u672c\u5728\u4f30\u8ba1\u53c2\u4e0e\u8005\u6392\u5e8f\u3001\u54cd\u5e94\u5206\u5e03\u548c\u91cf\u8868\u95f4\u76f8\u5173\u6027\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\uff0c\u5206\u6790\u4e0d\u540c\u51b3\u7b56\u5bf9\u6837\u672c\u8d28\u91cf\u7684\u5f71\u54cd", "result": "\u4e0d\u540c\u914d\u7f6e\u5728\u6837\u672c\u8d28\u91cf\u4e0a\u5dee\u5f02\u663e\u8457\uff0c\u4e14\u5728\u4e09\u4e2a\u8bc4\u4f30\u7ef4\u5ea6\u4e0a\u8868\u73b0\u4e0d\u4e00\u81f4\u2014\u2014\u67d0\u4e2a\u914d\u7f6e\u5728\u4e00\u4e2a\u7ef4\u5ea6\u8868\u73b0\u597d\uff0c\u5728\u5176\u4ed6\u7ef4\u5ea6\u53ef\u80fd\u8868\u73b0\u5dee", "conclusion": "\u7845\u6837\u672c\u7684\u4f7f\u7528\u5b58\u5728\u4e25\u91cd\u7684\u5206\u6790\u7075\u6d3b\u6027\u98ce\u9669\uff0c\u9700\u8981\u66f4\u591a\u5173\u6ce8\u8fd9\u79cd\u5a01\u80c1\uff0c\u56e0\u4e3a\u6ca1\u6709\u5355\u4e00\u914d\u7f6e\u80fd\u591f\u4f18\u5316\u6240\u6709\u7ef4\u5ea6\u7684\u51c6\u786e\u6027"}}
{"id": "2509.13585", "categories": ["eess.SY", "cs.GT", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.13585", "abs": "https://arxiv.org/abs/2509.13585", "authors": ["Sean Anderson", "Chris Darken", "Jo\u00e3o Hespanha"], "title": "Zero-sum turn games using Q-learning: finite computation with security guarantees", "comment": "8 pages", "summary": "This paper addresses zero-sum ``turn'' games, in which only one player can\nmake decisions at each state. We show that pure saddle-point state-feedback\npolicies for turn games can be constructed from dynamic programming fixed-point\nequations for a single value function or Q-function. These fixed-points can be\nconstructed using a suitable form of Q-learning. For discounted costs,\nconvergence of this form of Q-learning can be established using classical\ntechniques. For undiscounted costs, we provide a convergence result that\napplies to finite-time deterministic games, which we use to illustrate our\nresults. For complex games, the Q-learning iteration must be terminated before\nexploring the full-state, which can lead to policies that cannot guarantee the\nsecurity levels implied by the final Q-function. To mitigate this, we propose\nan ``opponent-informed'' exploration policy for selecting the Q-learning\nsamples. This form of exploration can guarantee that the final Q-function\nprovides security levels that hold, at least, against a given set of policies.\nA numerical demonstration for a multi-agent game, Atlatl, indicates the\neffectiveness of these methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u96f6\u548c\"\u56de\u5408\"\u6e38\u620f\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u52a8\u6001\u89c4\u5212\u56fa\u5b9a\u70b9\u65b9\u7a0b\u7684\u7eaf\u978d\u70b9\u72b6\u6001\u53cd\u9988\u7b56\u7565\u6784\u5efa\u65b9\u6cd5\uff0c\u4f7f\u7528Q-learning\u8fdb\u884c\u6c42\u89e3\uff0c\u5e76\u4e3a\u672a\u6298\u6263\u6210\u672c\u63d0\u4f9b\u4e86\u6536\u655b\u6027\u8bc1\u660e\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u5bf9\u624b\u77e5\u60c5\u63a2\u7d22\u7b56\u7565\u6765\u4fdd\u8bc1\u5b89\u5168\u7ea7\u522b\u3002", "motivation": "\u89e3\u51b3\u96f6\u548c\u56de\u5408\u6e38\u620f\u4e2d\u7eaf\u978d\u70b9\u72b6\u6001\u53cd\u9988\u7b56\u7565\u7684\u6784\u5efa\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u6e38\u620f\u4e2dQ-learning\u63d0\u524d\u7ec8\u6b62\u53ef\u80fd\u5bfc\u81f4\u7b56\u7565\u65e0\u6cd5\u4fdd\u8bc1\u5b89\u5168\u7ea7\u522b\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u52a8\u6001\u89c4\u5212\u56fa\u5b9a\u70b9\u65b9\u7a0b\u6784\u5efa\u503c\u51fd\u6570\u6216Q\u51fd\u6570\uff0c\u91c7\u7528Q-learning\u65b9\u6cd5\u6c42\u89e3\uff0c\u5bf9\u4e8e\u672a\u6298\u6263\u6210\u672c\u63d0\u4f9b\u6536\u655b\u6027\u8bc1\u660e\uff0c\u5e76\u63d0\u51fa\u5bf9\u624b\u77e5\u60c5\u63a2\u7d22\u7b56\u7565\u6765\u6539\u8fdb\u91c7\u6837\u8fc7\u7a0b\u3002", "result": "\u4e3a\u6298\u6263\u6210\u672c\u5efa\u7acb\u4e86\u7ecf\u5178\u6536\u655b\u6280\u672f\uff0c\u4e3a\u672a\u6298\u6263\u6210\u672c\u63d0\u4f9b\u4e86\u6709\u9650\u65f6\u95f4\u786e\u5b9a\u6027\u6e38\u620f\u7684\u6536\u655b\u7ed3\u679c\uff0c\u6570\u503c\u5b9e\u9a8c\u8868\u660e\u65b9\u6cd5\u5728\u591a\u4eba\u6e38\u620fAtlatl\u4e2d\u6709\u6548\u3002", "conclusion": "\u63d0\u51fa\u7684\u52a8\u6001\u89c4\u5212\u56fa\u5b9a\u70b9\u65b9\u7a0b\u548cQ-learning\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6784\u5efa\u96f6\u548c\u56de\u5408\u6e38\u620f\u7684\u7eaf\u978d\u70b9\u7b56\u7565\uff0c\u5bf9\u624b\u77e5\u60c5\u63a2\u7d22\u7b56\u7565\u80fd\u591f\u4fdd\u8bc1\u6700\u7ec8Q\u51fd\u6570\u7684\u5b89\u5168\u7ea7\u522b\u81f3\u5c11\u5bf9\u7ed9\u5b9a\u7b56\u7565\u96c6\u6210\u7acb\u3002"}}
{"id": "2509.13572", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13572", "abs": "https://arxiv.org/abs/2509.13572", "authors": ["Ozan Karaali", "Hossam Farag", "Strahinja Dosen", "Cedomir Stefanovic"], "title": "Using Visual Language Models to Control Bionic Hands: Assessment of Object Perception and Grasp Inference", "comment": "ICAT 2025", "summary": "This study examines the potential of utilizing Vision Language Models (VLMs)\nto improve the perceptual capabilities of semi-autonomous prosthetic hands. We\nintroduce a unified benchmark for end-to-end perception and grasp inference,\nevaluating a single VLM to perform tasks that traditionally require complex\npipelines with separate modules for object detection, pose estimation, and\ngrasp planning. To establish the feasibility and current limitations of this\napproach, we benchmark eight contemporary VLMs on their ability to perform a\nunified task essential for bionic grasping. From a single static image, they\nshould (1) identify common objects and their key properties (name, shape,\norientation, and dimensions), and (2) infer appropriate grasp parameters (grasp\ntype, wrist rotation, hand aperture, and number of fingers). A corresponding\nprompt requesting a structured JSON output was employed with a dataset of 34\nsnapshots of common objects. Key performance metrics, including accuracy for\ncategorical attributes (e.g., object name, shape) and errors in numerical\nestimates (e.g., dimensions, hand aperture), along with latency and cost, were\nanalyzed. The results demonstrated that most models exhibited high performance\nin object identification and shape recognition, while accuracy in estimating\ndimensions and inferring optimal grasp parameters, particularly hand rotation\nand aperture, varied more significantly. This work highlights the current\ncapabilities and limitations of VLMs as advanced perceptual modules for\nsemi-autonomous control of bionic limbs, demonstrating their potential for\neffective prosthetic applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e868\u79cd\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5047\u80a2\u624b\u611f\u77e5\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5305\u62ec\u7269\u4f53\u8bc6\u522b\u548c\u6293\u53d6\u53c2\u6570\u63a8\u65ad\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u7269\u4f53\u8bc6\u522b\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5c3a\u5bf8\u4f30\u8ba1\u548c\u6293\u53d6\u53c2\u6570\u63a8\u65ad\u65b9\u9762\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u63a2\u7d22\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u534a\u81ea\u4e3b\u5047\u80a2\u624b\u611f\u77e5\u6a21\u5757\u7684\u6f5c\u529b\uff0c\u66ff\u4ee3\u4f20\u7edf\u9700\u8981\u591a\u4e2a\u72ec\u7acb\u6a21\u5757\uff08\u7269\u4f53\u68c0\u6d4b\u3001\u59ff\u6001\u4f30\u8ba1\u3001\u6293\u53d6\u89c4\u5212\uff09\u7684\u590d\u6742\u6d41\u7a0b\u3002", "method": "\u4f7f\u7528\u5305\u542b34\u4e2a\u5e38\u89c1\u7269\u4f53\u5feb\u7167\u7684\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316JSON\u63d0\u793a\u8981\u6c42VLM\u4ece\u5355\u5f20\u9759\u6001\u56fe\u50cf\u4e2d\u8bc6\u522b\u7269\u4f53\u5c5e\u6027\uff08\u540d\u79f0\u3001\u5f62\u72b6\u3001\u65b9\u5411\u3001\u5c3a\u5bf8\uff09\u5e76\u63a8\u65ad\u6293\u53d6\u53c2\u6570\uff08\u6293\u53d6\u7c7b\u578b\u3001\u624b\u8155\u65cb\u8f6c\u3001\u624b\u90e8\u5f00\u5408\u5ea6\u3001\u624b\u6307\u6570\u91cf\uff09\u3002", "result": "\u5927\u591a\u6570\u6a21\u578b\u5728\u7269\u4f53\u8bc6\u522b\u548c\u5f62\u72b6\u8bc6\u522b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u5c3a\u5bf8\u4f30\u8ba1\u548c\u6700\u4f18\u6293\u53d6\u53c2\u6570\uff08\u7279\u522b\u662f\u624b\u90e8\u65cb\u8f6c\u548c\u5f00\u5408\u5ea6\uff09\u63a8\u65ad\u7684\u51c6\u786e\u6027\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86VLM\u4f5c\u4e3a\u4eff\u751f\u80a2\u4f53\u9ad8\u7ea7\u611f\u77e5\u6a21\u5757\u7684\u5f53\u524d\u80fd\u529b\u548c\u5c40\u9650\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u6709\u6548\u5047\u80a2\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.13379", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.13379", "abs": "https://arxiv.org/abs/2509.13379", "authors": ["Asif Azad", "Mohammad Sadat Hossain", "MD Sadik Hossain Shanto", "M Saifur Rahman", "Md Rizwan Pervez"], "title": "The Art of Saying \"Maybe\": A Conformal Lens for Uncertainty Benchmarking in VLMs", "comment": null, "summary": "Vision-Language Models (VLMs) have achieved remarkable progress in complex\nvisual understanding across scientific and reasoning tasks. While performance\nbenchmarking has advanced our understanding of these capabilities, the critical\ndimension of uncertainty quantification has received insufficient attention.\nTherefore, unlike prior conformal prediction studies that focused on limited\nsettings, we conduct a comprehensive uncertainty benchmarking study, evaluating\n16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets\nwith 3 distinct scoring functions. Our findings demonstrate that larger models\nconsistently exhibit better uncertainty quantification; models that know more\nalso know better what they don't know. More certain models achieve higher\naccuracy, while mathematical and reasoning tasks elicit poorer uncertainty\nperformance across all models compared to other domains. This work establishes\na foundation for reliable uncertainty evaluation in multimodal systems.", "AI": {"tldr": "\u5bf916\u4e2a\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u57286\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5168\u9762\u7684\u4e0d\u786e\u5b9a\u6027\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5927\u6a21\u578b\u5177\u6709\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\uff0c\u6570\u5b66\u548c\u63a8\u7406\u4efb\u52a1\u7684\u4e0d\u786e\u5b9a\u6027\u8868\u73b0\u8f83\u5dee", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u89c6\u89c9\u7406\u89e3\u65b9\u9762\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u8fd9\u4e00\u5173\u952e\u7ef4\u5ea6\u672a\u5f97\u5230\u8db3\u591f\u5173\u6ce8\uff0c\u9700\u8981\u8d85\u8d8a\u73b0\u6709\u5171\u5f62\u9884\u6d4b\u7814\u7a76\u7684\u6709\u9650\u8bbe\u7f6e", "method": "\u8bc4\u4f3016\u4e2a\u6700\u5148\u8fdb\u7684VLMs\uff08\u5f00\u6e90\u548c\u95ed\u6e90\uff09\uff0c\u57286\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u4f7f\u75283\u79cd\u4e0d\u540c\u7684\u8bc4\u5206\u51fd\u6570\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u57fa\u51c6\u6d4b\u8bd5", "result": "\u5927\u6a21\u578b\u6301\u7eed\u8868\u73b0\u51fa\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\uff1b\u66f4\u786e\u5b9a\u7684\u6a21\u578b\u83b7\u5f97\u66f4\u9ad8\u51c6\u786e\u7387\uff1b\u6570\u5b66\u548c\u63a8\u7406\u4efb\u52a1\u5728\u6240\u6709\u6a21\u578b\u4e2d\u76f8\u6bd4\u5176\u4ed6\u9886\u57df\u8868\u73b0\u51fa\u66f4\u5dee\u7684\u4e0d\u786e\u5b9a\u6027\u6027\u80fd", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u591a\u6a21\u6001\u7cfb\u7edf\u4e2d\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2509.13400", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13400", "abs": "https://arxiv.org/abs/2509.13400", "authors": ["Sai Suresh Marchala Vasu", "Ivaxi Sheth", "Hui-Po Wang", "Ruta Binkyte", "Mario Fritz"], "title": "Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews", "comment": null, "summary": "The adoption of large language models (LLMs) is transforming the peer review\nprocess, from assisting reviewers in writing more detailed evaluations to\ngenerating entire reviews automatically. While these capabilities offer\nexciting opportunities, they also raise critical concerns about fairness and\nreliability. In this paper, we investigate bias in LLM-generated peer reviews\nby conducting controlled experiments on sensitive metadata, including author\naffiliation and gender. Our analysis consistently shows affiliation bias\nfavoring institutions highly ranked on common academic rankings. Additionally,\nwe find some gender preferences, which, even though subtle in magnitude, have\nthe potential to compound over time. Notably, we uncover implicit biases that\nbecome more evident with token-based soft ratings.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u53d1\u73b0LLM\u751f\u6210\u7684\u540c\u884c\u8bc4\u5ba1\u5b58\u5728\u673a\u6784\u504f\u89c1\uff08\u504f\u5411\u9ad8\u6392\u540d\u673a\u6784\uff09\u548c\u6027\u522b\u504f\u89c1\uff0c\u5e76\u63ed\u793a\u57fa\u4e8etoken\u7684\u8f6f\u8bc4\u5206\u80fd\u66f4\u660e\u663e\u5730\u66b4\u9732\u9690\u6027\u504f\u89c1", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u867d\u7136\u63d0\u4f9b\u4e86\u534f\u52a9\u64b0\u5199\u8be6\u7ec6\u8bc4\u4f30\u548c\u81ea\u52a8\u751f\u6210\u8bc4\u5ba1\u7684\u673a\u4f1a\uff0c\u4f46\u4e5f\u5f15\u53d1\u4e86\u5173\u4e8e\u516c\u5e73\u6027\u548c\u53ef\u9760\u6027\u7684\u5173\u952e\u62c5\u5fe7\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76LLM\u751f\u6210\u7684\u8bc4\u5ba1\u4e2d\u5b58\u5728\u7684\u504f\u89c1\u95ee\u9898", "method": "\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u9488\u5bf9\u654f\u611f\u5143\u6570\u636e\uff08\u5305\u62ec\u4f5c\u8005\u6240\u5c5e\u673a\u6784\u548c\u6027\u522b\uff09\u8fdb\u884c\u7cfb\u7edf\u6027\u6d4b\u8bd5\uff0c\u5206\u6790LLM\u751f\u6210\u7684\u540c\u884c\u8bc4\u5ba1\u5185\u5bb9\uff0c\u7279\u522b\u4f7f\u7528\u57fa\u4e8etoken\u7684\u8f6f\u8bc4\u5206\u6765\u68c0\u6d4b\u9690\u6027\u504f\u89c1", "result": "\u7814\u7a76\u4e00\u81f4\u663e\u793a\u5b58\u5728\u673a\u6784\u504f\u89c1\uff0c\u504f\u5411\u5e38\u89c1\u5b66\u672f\u6392\u540d\u8f83\u9ad8\u7684\u673a\u6784\uff1b\u540c\u65f6\u53d1\u73b0\u867d\u7136\u5e45\u5ea6\u7ec6\u5fae\u4f46\u53ef\u80fd\u968f\u65f6\u95f4\u7d2f\u79ef\u7684\u6027\u522b\u504f\u597d\uff1b\u7279\u522b\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u901a\u8fc7token-based\u8f6f\u8bc4\u5206\u63ed\u793a\u4e86\u66f4\u52a0\u660e\u663e\u7684\u9690\u6027\u504f\u89c1", "conclusion": "LLM\u751f\u6210\u7684\u540c\u884c\u8bc4\u5ba1\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u7f13\u89e3\u7b56\u7565\u6765\u786e\u4fdd\u5b66\u672f\u8bc4\u5ba1\u8fc7\u7a0b\u7684\u516c\u5e73\u6027\u548c\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u5728\u673a\u6784\u6392\u540d\u548c\u6027\u522b\u65b9\u9762\u7684\u504f\u89c1\u9700\u8981\u7279\u522b\u5173\u6ce8"}}
{"id": "2509.13674", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.13674", "abs": "https://arxiv.org/abs/2509.13674", "authors": ["Yuezhang He", "Hongxi Luo", "Yuancheng Lin", "Carl J. Talsma", "Anna Li", "Zhenqian Wang", "Yujuan Fang", "Pei Liu", "Jesse D. Jenkins", "Eric Larson", "Zheng Li"], "title": "Scaling green hydrogen and CCUS via cement-methanol co-production in China", "comment": null, "summary": "High costs of green hydrogen and of carbon capture, utilization, and\nsequestration (CCUS) have hindered policy ambition and slowed real-world\ndeployment, despite their importance for decarbonizing hard-to-abate sectors,\nincluding cement and methanol. Given the economic challenges of adopting CCUS\nin cement and green hydrogen in methanol production separately, we propose a\nrenewable-powered co-production system that couples electrolytic hydrogen and\nCCUS through molecule exchange. We optimize system configurations using an\nhourly-resolved, process-based model incorporating operational flexibility, and\nexplore integrated strategies for plant-level deployment and CO2 source-sink\nmatching across China. We find that co-production could reduce CO2 abatement\ncosts to USD 41-53 per tonne by 2035, significantly lower than approximately\nUSD 75 for standalone cement CCUS and over USD 120 for standalone\nrenewable-based methanol. Co-production is preferentially deployed at cement\nplants in renewable-rich regions, potentially reshaping national CO2\ninfrastructure planning. This hydrogen-CCUS coupling paradigm could accelerate\nindustrial decarbonization and scaling for other applications.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u518d\u751f\u52a8\u529b\u5171\u751f\u4ea7\u7cfb\u7edf\uff0c\u901a\u8fc7\u7535\u89e3\u6c22\u4e0eCCUS\u5206\u5b50\u4ea4\u6362\u8026\u5408\uff0c\u663e\u8457\u964d\u4f4e\u6c34\u6ce5\u548c\u7532\u9187\u884c\u4e1a\u7684\u78b3\u51cf\u6392\u6210\u672c", "motivation": "\u7eff\u8272\u6c22\u6c14\u548cCCUS\u7684\u9ad8\u6210\u672c\u963b\u788d\u4e86\u96be\u4ee5\u51cf\u6392\u884c\u4e1a\uff08\u5982\u6c34\u6ce5\u548c\u7532\u9187\uff09\u7684\u8131\u78b3\u8fdb\u7a0b\uff0c\u9700\u8981\u5bfb\u627e\u7ecf\u6d4e\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u4f7f\u7528\u5c0f\u65f6\u5206\u8fa8\u7387\u7684\u57fa\u4e8e\u8fc7\u7a0b\u6a21\u578b\u4f18\u5316\u7cfb\u7edf\u914d\u7f6e\uff0c\u7ed3\u5408\u8fd0\u8425\u7075\u6d3b\u6027\uff0c\u63a2\u7d22\u5de5\u5382\u7ea7\u90e8\u7f72\u548c\u4e2d\u56fd\u8303\u56f4\u5185\u7684CO2\u6e90\u6c47\u5339\u914d\u7b56\u7565", "result": "\u5171\u751f\u4ea7\u7cfb\u7edf\u53ef\u5c062035\u5e74\u78b3\u51cf\u6392\u6210\u672c\u964d\u81f341-53\u7f8e\u5143/\u5428\uff0c\u663e\u8457\u4f4e\u4e8e\u5355\u72ec\u6c34\u6ce5CCUS\u768475\u7f8e\u5143\u548c\u53ef\u518d\u751f\u7532\u9187\u7684120\u7f8e\u5143\u4ee5\u4e0a", "conclusion": "\u6c22-CCUS\u8026\u5408\u8303\u5f0f\u53ef\u52a0\u901f\u5de5\u4e1a\u8131\u78b3\uff0c\u4f18\u5148\u5728\u53ef\u518d\u751f\u80fd\u6e90\u4e30\u5bcc\u5730\u533a\u7684\u6c34\u6ce5\u5382\u90e8\u7f72\uff0c\u53ef\u80fd\u91cd\u5851\u56fd\u5bb6CO2\u57fa\u7840\u8bbe\u65bd\u89c4\u5212"}}
{"id": "2509.13574", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13574", "abs": "https://arxiv.org/abs/2509.13574", "authors": ["Zidong Chen", "Zihao Guo", "Peng Wang", "ThankGod Itua Egbe", "Yan Lyu", "Chenghao Qian"], "title": "Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation", "comment": null, "summary": "Flow matching has emerged as a competitive framework for learning\nhigh-quality generative policies in robotics; however, we find that\ngeneralisation arises and saturates early along the flow trajectory, in\naccordance with recent findings in the literature. We further observe that\nincreasing the number of Euler integration steps during inference\ncounter-intuitively and universally degrades policy performance. We attribute\nthis to (i) additional, uniformly spaced integration steps oversample the\nlate-time region, thereby constraining actions towards the training\ntrajectories and reducing generalisation; and (ii) the learned velocity field\nbecoming non-Lipschitz as integration time approaches 1, causing instability.\nTo address these issues, we propose a novel policy that utilises non-uniform\ntime scheduling (e.g., U-shaped) during training, which emphasises both early\nand late temporal stages to regularise policy training, and a dense-jump\nintegration schedule at inference, which uses a single-step integration to\nreplace the multi-step integration beyond a jump point, to avoid unstable areas\naround 1. Essentially, our policy is an efficient one-step learner that still\npushes forward performance through multi-step integration, yielding up to 23.7%\nperformance gains over state-of-the-art baselines across diverse robotic tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u975e\u5747\u5300\u65f6\u95f4\u8c03\u5ea6\u7684\u6d41\u5339\u914d\u7b56\u7565\uff0c\u901a\u8fc7U\u5f62\u8bad\u7ec3\u65f6\u95f4\u8c03\u5ea6\u548c\u5bc6\u96c6\u8df3\u8dc3\u63a8\u7406\u8c03\u5ea6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6d41\u5339\u914d\u4e2d\u6cdb\u5316\u80fd\u529b\u9971\u548c\u548c\u63a8\u7406\u6b65\u9aa4\u589e\u52a0\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\u3002", "motivation": "\u53d1\u73b0\u6d41\u5339\u914d\u5728\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u6cdb\u5316\u80fd\u529b\u65e9\u671f\u9971\u548c\uff0c\u4e14\u589e\u52a0\u6b27\u62c9\u79ef\u5206\u6b65\u9aa4\u53cd\u800c\u4f1a\u964d\u4f4e\u7b56\u7565\u6027\u80fd\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u5747\u5300\u91c7\u6837\u8fc7\u5ea6\u5173\u6ce8\u540e\u671f\u533a\u57df\u5bfc\u81f4\u52a8\u4f5c\u53d7\u9650\uff0c\u4ee5\u53ca\u901f\u5ea6\u573a\u5728\u63a5\u8fd1\u65f6\u95f41\u65f6\u53d8\u5f97\u975eLipschitz\u5bfc\u81f4\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u975e\u5747\u5300\u65f6\u95f4\u8c03\u5ea6\uff08\u5982U\u5f62\uff09\u8fdb\u884c\u8bad\u7ec3\uff0c\u540c\u65f6\u5f3a\u8c03\u65e9\u671f\u548c\u665a\u671f\u65f6\u95f4\u9636\u6bb5\u6765\u6b63\u5219\u5316\u7b56\u7565\u8bad\u7ec3\uff1b\u5728\u63a8\u7406\u65f6\u4f7f\u7528\u5bc6\u96c6\u8df3\u8dc3\u79ef\u5206\u8c03\u5ea6\uff0c\u901a\u8fc7\u5355\u6b65\u79ef\u5206\u66ff\u6362\u8df3\u8dc3\u70b9\u540e\u7684\u591a\u6b65\u79ef\u5206\u6765\u907f\u514d\u4e0d\u7a33\u5b9a\u533a\u57df\u3002", "result": "\u5728\u591a\u6837\u5316\u673a\u5668\u4eba\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad823.7%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5355\u6b65\u5b66\u4e60\u5668\uff0c\u901a\u8fc7\u591a\u6b65\u79ef\u5206\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6d41\u5339\u914d\u4e2d\u7684\u6cdb\u5316\u548c\u7a33\u5b9a\u6027\u95ee\u9898\u3002"}}
{"id": "2509.13389", "categories": ["cs.AI", "I.2.4; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2509.13389", "abs": "https://arxiv.org/abs/2509.13389", "authors": ["Carlos N\u00fa\u00f1ez-Molina", "Vicen\u00e7 G\u00f3mez", "Hector Geffner"], "title": "From Next Token Prediction to (STRIPS) World Models -- Preliminary Results", "comment": "10 pages, 3 figures", "summary": "We consider the problem of learning propositional STRIPS world models from\naction traces alone, using a deep learning architecture (transformers) and\ngradient descent. The task is cast as a supervised next token prediction\nproblem where the tokens are the actions, and an action $a$ may follow an\naction sequence if the hidden effects of the previous actions do not make an\naction precondition of $a$ false. We show that a suitable transformer\narchitecture can faithfully represent propositional STRIPS world models, and\nthat the models can be learned from sets of random valid (positive) and invalid\n(negative) action sequences alone. A number of experiments are reported.", "AI": {"tldr": "\u4f7f\u7528Transformer\u67b6\u6784\u4ece\u52a8\u4f5c\u5e8f\u5217\u4e2d\u5b66\u4e60\u547d\u9898STRIPS\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u76d1\u7763\u5f0f\u4e0b\u4e00\u4e2a\u52a8\u4f5c\u9884\u6d4b\u4efb\u52a1\u6765\u5b66\u4e60\u52a8\u4f5c\u524d\u63d0\u6761\u4ef6\u548c\u9690\u85cf\u6548\u679c\u3002", "motivation": "\u4ece\u7eaf\u52a8\u4f5c\u8f68\u8ff9\u4e2d\u5b66\u4e60\u4e16\u754c\u6a21\u578b\u662f\u4e00\u4e2a\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u624b\u5de5\u7f16\u7801\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u53ef\u4ee5\u63d0\u4f9b\u7aef\u5230\u7aef\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u4efb\u52a1\u8f6c\u5316\u4e3a\u76d1\u7763\u5f0f\u7684\u4e0b\u4e00\u4e2a\u52a8\u4f5c\u9884\u6d4b\u95ee\u9898\uff0c\u4f7f\u7528Transformer\u67b6\u6784\uff0c\u901a\u8fc7\u6b63\u8d1f\u6837\u672c\uff08\u6709\u6548\u548c\u65e0\u6548\u52a8\u4f5c\u5e8f\u5217\uff09\u8fdb\u884c\u8bad\u7ec3\uff0c\u5b66\u4e60\u52a8\u4f5c\u7684\u524d\u63d0\u6761\u4ef6\u548c\u9690\u85cf\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5408\u9002\u7684Transformer\u67b6\u6784\u80fd\u591f\u51c6\u786e\u8868\u793a\u547d\u9898STRIPS\u4e16\u754c\u6a21\u578b\uff0c\u5e76\u4e14\u4ec5\u4ece\u968f\u673a\u751f\u6210\u7684\u6b63\u8d1f\u52a8\u4f5c\u5e8f\u5217\u4e2d\u5c31\u80fd\u6210\u529f\u5b66\u4e60\u5230\u8fd9\u4e9b\u6a21\u578b\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u7279\u522b\u662fTransformer\u80fd\u591f\u6709\u6548\u5730\u4ece\u52a8\u4f5c\u5e8f\u5217\u4e2d\u5b66\u4e60\u4e16\u754c\u6a21\u578b\uff0c\u4e3a\u4ece\u89c2\u5bdf\u4e2d\u81ea\u52a8\u5b66\u4e60\u52a8\u4f5c\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u6cd5\u3002"}}
{"id": "2509.13499", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13499", "abs": "https://arxiv.org/abs/2509.13499", "authors": ["Susobhan Ghosh", "Bhanu T. Gulapalli", "Daiqi Gao", "Asim Gazi", "Anna Trella", "Ziping Xu", "Kelly Zhang", "Susan A. Murphy"], "title": "Reproducible workflow for online AI in digital health", "comment": null, "summary": "Online artificial intelligence (AI) algorithms are an important component of\ndigital health interventions. These online algorithms are designed to\ncontinually learn and improve their performance as streaming data is collected\non individuals. Deploying online AI presents a key challenge: balancing\nadaptability of online AI with reproducibility. Online AI in digital\ninterventions is a rapidly evolving area, driven by advances in algorithms,\nsensors, software, and devices. Digital health intervention development and\ndeployment is a continuous process, where implementation - including the AI\ndecision-making algorithm - is interspersed with cycles of re-development and\noptimization. Each deployment informs the next, making iterative deployment a\ndefining characteristic of this field. This iterative nature underscores the\nimportance of reproducibility: data collected across deployments must be\naccurately stored to have scientific utility, algorithm behavior must be\nauditable, and results must be comparable over time to facilitate scientific\ndiscovery and trustworthy refinement. This paper proposes a reproducible\nscientific workflow for developing, deploying, and analyzing online AI\ndecision-making algorithms in digital health interventions. Grounded in\npractical experience from multiple real-world deployments, this workflow\naddresses key challenges to reproducibility across all phases of the online AI\nalgorithm development life-cycle.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u6570\u5b57\u5065\u5eb7\u5e72\u9884\u4e2d\u5728\u7ebfAI\u51b3\u7b56\u7b97\u6cd5\u5f00\u53d1\u3001\u90e8\u7f72\u548c\u5206\u6790\u7684\u53ef\u91cd\u590d\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\uff0c\u65e8\u5728\u5e73\u8861\u5728\u7ebfAI\u7684\u9002\u5e94\u6027\u4e0e\u53ef\u91cd\u590d\u6027\u3002", "motivation": "\u5728\u7ebfAI\u7b97\u6cd5\u5728\u6570\u5b57\u5065\u5eb7\u5e72\u9884\u4e2d\u9762\u4e34\u5173\u952e\u6311\u6218\uff1a\u5982\u4f55\u5728\u6536\u96c6\u4e2a\u4f53\u6d41\u6570\u636e\u65f6\u6301\u7eed\u5b66\u4e60\u548c\u6539\u8fdb\u6027\u80fd\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u7b97\u6cd5\u7684\u53ef\u91cd\u590d\u6027\u3002\u6570\u5b57\u5065\u5eb7\u5e72\u9884\u7684\u8fed\u4ee3\u90e8\u7f72\u7279\u6027\u4f7f\u5f97\u53ef\u91cd\u590d\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u57fa\u4e8e\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u7684\u5b9e\u9645\u7ecf\u9a8c\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u8986\u76d6\u5728\u7ebfAI\u7b97\u6cd5\u5f00\u53d1\u751f\u547d\u5468\u671f\u6240\u6709\u9636\u6bb5\u7684\u53ef\u91cd\u590d\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5305\u62ec\u6570\u636e\u51c6\u786e\u5b58\u50a8\u3001\u7b97\u6cd5\u884c\u4e3a\u53ef\u5ba1\u8ba1\u548c\u7ed3\u679c\u53ef\u6bd4\u6027\u7b49\u65b9\u9762\u3002", "result": "\u8be5\u5de5\u4f5c\u6d41\u7a0b\u80fd\u591f\u89e3\u51b3\u5728\u7ebfAI\u7b97\u6cd5\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u5404\u9636\u6bb5\u7684\u5173\u952e\u53ef\u91cd\u590d\u6027\u6311\u6218\uff0c\u786e\u4fdd\u79d1\u5b66\u53d1\u73b0\u7684\u53ef\u4fe1\u5ea6\u548c\u7b97\u6cd5\u7684\u53ef\u9760\u4f18\u5316\u3002", "conclusion": "\u63d0\u51fa\u7684\u53ef\u91cd\u590d\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u4e3a\u6570\u5b57\u5065\u5eb7\u5e72\u9884\u4e2d\u5728\u7ebfAI\u51b3\u7b56\u7b97\u6cd5\u7684\u5f00\u53d1\u3001\u90e8\u7f72\u548c\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u9002\u5e94\u6027AI\u4e0e\u79d1\u5b66\u53ef\u91cd\u590d\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u3002"}}
{"id": "2509.13719", "categories": ["eess.SY", "cond-mat.mtrl-sci", "cs.SY", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2509.13719", "abs": "https://arxiv.org/abs/2509.13719", "authors": ["Chenghao Wan", "Conner Cremers", "Ariana B. H\u00f6felmann", "Zhennan Ru", "Calvin H. Lin", "Kesha N. Tamakuwala", "Dolly Mantle", "Pinak Mohapatra", "Juan Rivas-Davila", "Matthew W. Kanan", "Jonathan A. Fan"], "title": "Scale Up Analysis of Inductively Heated Metamaterial Reactors", "comment": null, "summary": "Inductively heated metamaterial reactors, which utilize an open cell lattice\nbaffle structure as a heating susceptor for magnetic induction, are promising\ncandidates for scaled electrified thermochemical reactor operation due to their\nability to support volumetric heating profiles and enhanced heat transfer\nproperties. In this work, we present a systematic scale up analysis of\ninductive metamaterial reactors where we utilize a combination of analytic\nmodeling, numerical simulations, and experiments to project the capabilities\nand performance of scaled reactors. We use reverse water gas shift as a model\nreaction system and show that for reactor configurations featuring a uniform\nmetamaterial susceptor, the total system efficiency increases with scale.\nHowever, the throughput of these scaled reactors is limited by radial\ntemperature gradients. We further show this bottleneck can be overcome by\ntailoring the radial effective conductivity profile of the susceptor, which can\nenable scaled reactors with nearly ideal plug flow-like capabilities. These\nconcepts provide a pathway towards scaled electrified thermochemical reactors\nwith optimal chemical conversion capabilities.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u5efa\u6a21\u3001\u6570\u503c\u6a21\u62df\u548c\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u7814\u7a76\u4e86\u611f\u5e94\u52a0\u70ed\u8d85\u6750\u6599\u53cd\u5e94\u5668\u7684\u653e\u5927\u6027\u80fd\uff0c\u53d1\u73b0\u5747\u5300\u8d85\u6750\u6599\u53cd\u5e94\u5668\u6548\u7387\u968f\u89c4\u6a21\u589e\u52a0\u4f46\u53d7\u9650\u4e8e\u5f84\u5411\u6e29\u5ea6\u68af\u5ea6\uff0c\u901a\u8fc7\u5b9a\u5236\u5f84\u5411\u6709\u6548\u7535\u5bfc\u7387\u5206\u5e03\u53ef\u514b\u670d\u8fd9\u4e00\u74f6\u9888\uff0c\u5b9e\u73b0\u63a5\u8fd1\u7406\u60f3\u6d3b\u585e\u6d41\u7684\u653e\u5927\u7535\u70ed\u5316\u5b66\u53cd\u5e94\u5668\u3002", "motivation": "\u611f\u5e94\u52a0\u70ed\u8d85\u6750\u6599\u53cd\u5e94\u5668\u5177\u6709\u4f53\u79ef\u52a0\u70ed\u7279\u6027\u548c\u589e\u5f3a\u7684\u4f20\u70ed\u6027\u80fd\uff0c\u662f\u89c4\u6a21\u5316\u7535\u70ed\u5316\u5b66\u53cd\u5e94\u5668\u64cd\u4f5c\u7684\u6709\u524d\u666f\u5019\u9009\u65b9\u6848\uff0c\u4f46\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u5176\u653e\u5927\u6027\u80fd\u548c\u9650\u5236\u56e0\u7d20\u3002", "method": "\u91c7\u7528\u5206\u6790\u5efa\u6a21\u3001\u6570\u503c\u6a21\u62df\u548c\u5b9e\u9a8c\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u4ee5\u9006\u6c34\u7164\u6c14\u53d8\u6362\u4e3a\u6a21\u578b\u53cd\u5e94\u7cfb\u7edf\uff0c\u7814\u7a76\u5747\u5300\u8d85\u6750\u6599\u53cd\u5e94\u5668\u548c\u5b9a\u5236\u5f84\u5411\u7535\u5bfc\u7387\u5206\u5e03\u53cd\u5e94\u5668\u7684\u6027\u80fd\u3002", "result": "\u5747\u5300\u8d85\u6750\u6599\u53cd\u5e94\u5668\u7684\u603b\u7cfb\u7edf\u6548\u7387\u968f\u89c4\u6a21\u589e\u52a0\uff0c\u4f46\u901a\u91cf\u53d7\u5f84\u5411\u6e29\u5ea6\u68af\u5ea6\u9650\u5236\uff1b\u901a\u8fc7\u5b9a\u5236\u5f84\u5411\u6709\u6548\u7535\u5bfc\u7387\u5206\u5e03\u53ef\u4ee5\u514b\u670d\u8fd9\u4e00\u74f6\u9888\uff0c\u5b9e\u73b0\u63a5\u8fd1\u7406\u60f3\u6d3b\u585e\u6d41\u6027\u80fd\u7684\u653e\u5927\u53cd\u5e94\u5668\u3002", "conclusion": "\u8fd9\u4e9b\u6982\u5ff5\u4e3a\u5f00\u53d1\u5177\u6709\u6700\u4f73\u5316\u5b66\u8f6c\u5316\u80fd\u529b\u7684\u89c4\u6a21\u5316\u7535\u70ed\u5316\u5b66\u53cd\u5e94\u5668\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u901a\u8fc7\u8d85\u6750\u6599\u8bbe\u8ba1\u4f18\u5316\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u7535\u70ed\u5316\u5b66\u8fc7\u7a0b\u3002"}}
{"id": "2509.13579", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13579", "abs": "https://arxiv.org/abs/2509.13579", "authors": ["Momchil S. Tomov", "Sang Uk Lee", "Hansford Hendrago", "Jinwook Huh", "Teawon Han", "Forbes Howington", "Rafael da Silva", "Gianmarco Bernasconi", "Marc Heim", "Samuel Findler", "Xiaonan Ji", "Alexander Boule", "Michael Napoli", "Kuo Chen", "Jesse Miller", "Boaz Floor", "Yunqing Hu"], "title": "TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning", "comment": null, "summary": "We present TreeIRL, a novel planner for autonomous driving that combines\nMonte Carlo tree search (MCTS) and inverse reinforcement learning (IRL) to\nachieve state-of-the-art performance in simulation and in real-world driving.\nThe core idea is to use MCTS to find a promising set of safe candidate\ntrajectories and a deep IRL scoring function to select the most human-like\namong them. We evaluate TreeIRL against both classical and state-of-the-art\nplanners in large-scale simulations and on 500+ miles of real-world autonomous\ndriving in the Las Vegas metropolitan area. Test scenarios include dense urban\ntraffic, adaptive cruise control, cut-ins, and traffic lights. TreeIRL achieves\nthe best overall performance, striking a balance between safety, progress,\ncomfort, and human-likeness. To our knowledge, our work is the first\ndemonstration of MCTS-based planning on public roads and underscores the\nimportance of evaluating planners across a diverse set of metrics and in\nreal-world environments. TreeIRL is highly extensible and could be further\nimproved with reinforcement learning and imitation learning, providing a\nframework for exploring different combinations of classical and learning-based\napproaches to solve the planning bottleneck in autonomous driving.", "AI": {"tldr": "TreeIRL\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u548c\u9006\u5f3a\u5316\u5b66\u4e60\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u4e2d\u5b9e\u73b0\u5b89\u5168\u4e14\u7c7b\u4eba\u7684\u8f68\u8ff9\u9009\u62e9\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u9053\u8def\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02", "motivation": "\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u4e2d\u5b89\u5168\u6027\u4e0e\u4eba\u7c7b\u9a7e\u9a76\u884c\u4e3a\u76f8\u4f3c\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u5f80\u5f80\u96be\u4ee5\u540c\u65f6\u517c\u987e\u591a\u4e2a\u6027\u80fd\u6307\u6807", "method": "\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u751f\u6210\u5b89\u5168\u5019\u9009\u8f68\u8ff9\uff0c\u901a\u8fc7\u6df1\u5ea6\u9006\u5f3a\u5316\u5b66\u4e60\u8bc4\u5206\u51fd\u6570\u9009\u62e9\u6700\u7c7b\u4eba\u7684\u8f68\u8ff9", "result": "\u5728\u5927\u89c4\u6a21\u4eff\u771f\u548c\u62c9\u65af\u7ef4\u52a0\u65af500+\u82f1\u91cc\u771f\u5b9e\u9053\u8def\u6d4b\u8bd5\u4e2d\uff0c\u5728\u5bc6\u96c6\u57ce\u5e02\u4ea4\u901a\u3001\u81ea\u9002\u5e94\u5de1\u822a\u3001\u5207\u5165\u573a\u666f\u548c\u4ea4\u901a\u706f\u7b49\u573a\u666f\u4e0b\u83b7\u5f97\u6700\u4f73\u7efc\u5408\u6027\u80fd", "conclusion": "\u9996\u6b21\u5c55\u793a\u4e86\u57fa\u4e8eMCTS\u7684\u89c4\u5212\u5668\u5728\u516c\u5171\u9053\u8def\u4e0a\u7684\u5e94\u7528\uff0c\u8bc1\u660e\u4e86\u8de8\u591a\u6307\u6807\u8bc4\u4f30\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u7ed3\u5408\u7ecf\u5178\u65b9\u6cd5\u548c\u5b66\u4e60\u65b9\u6cd5\u7684\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6846\u67b6"}}
{"id": "2509.13450", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13450", "abs": "https://arxiv.org/abs/2509.13450", "authors": ["Vincent Siu", "Nicholas Crispino", "David Park", "Nathan W. Henry", "Zhun Wang", "Yang Liu", "Dawn Song", "Chenguang Wang"], "title": "SteeringControl: Holistic Evaluation of Alignment Steering in LLMs", "comment": null, "summary": "We introduce SteeringControl, a benchmark for evaluating representation\nsteering methods across core alignment objectives--bias, harmful generation,\nand hallucination--and their effects on secondary behaviors such as sycophancy\nand commonsense morality. While prior alignment work often highlights\ntruthfulness or reasoning ability to demonstrate the side effects of\nrepresentation steering, we find there are many unexplored tradeoffs not yet\nunderstood in a systematic way. We collect a dataset of safety-relevant primary\nand secondary behaviors to evaluate steering effectiveness and behavioral\nentanglement centered around five popular steering methods. To enable this, we\ncraft a modular steering framework based on unique components that serve as the\nbuilding blocks of many existing methods. Our results on Qwen-2.5-7B and\nLlama-3.1-8B find that strong steering performance is dependent on the specific\ncombination of steering method, model, and targeted behavior, and that severe\nconcept entanglement can result from poor combinations of these three as well.\nWe release our code here:\nhttps://github.com/wang-research-lab/SteeringControl.git.", "AI": {"tldr": "SteeringControl\u662f\u4e00\u4e2a\u8bc4\u4f30\u8868\u793a\u5f15\u5bfc\u65b9\u6cd5\u7684\u57fa\u51c6\uff0c\u91cd\u70b9\u5173\u6ce8\u504f\u89c1\u3001\u6709\u5bb3\u751f\u6210\u548c\u5e7b\u89c9\u7b49\u6838\u5fc3\u5bf9\u9f50\u76ee\u6807\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u65b9\u6cd5\u5bf9\u6b21\u8981\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u7814\u7a76\u53d1\u73b0\u5f15\u5bfc\u6548\u679c\u53d6\u51b3\u4e8e\u65b9\u6cd5\u3001\u6a21\u578b\u548c\u76ee\u6807\u884c\u4e3a\u7684\u7279\u5b9a\u7ec4\u5408\uff0c\u4e0d\u826f\u7ec4\u5408\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u6982\u5ff5\u7ea0\u7f20\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u9f50\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u771f\u5b9e\u6027\u6216\u63a8\u7406\u80fd\u529b\u6765\u5c55\u793a\u8868\u793a\u5f15\u5bfc\u7684\u526f\u4f5c\u7528\uff0c\u4f46\u8bb8\u591a\u6743\u8861\u5173\u7cfb\u5c1a\u672a\u88ab\u7cfb\u7edf\u6027\u5730\u7406\u89e3\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u7cfb\u7edf\u6846\u67b6\u6765\u8bc4\u4f30\u5f15\u5bfc\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u884c\u4e3a\u7ea0\u7f20\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u5f15\u5bfc\u6846\u67b6\uff0c\u57fa\u4e8e\u72ec\u7279\u7ec4\u4ef6\u4f5c\u4e3a\u73b0\u6709\u65b9\u6cd5\u7684\u6784\u5efa\u5757\u3002\u6536\u96c6\u4e86\u5b89\u5168\u76f8\u5173\u7684\u4e3b\u8981\u548c\u6b21\u8981\u884c\u4e3a\u6570\u636e\u96c6\uff0c\u56f4\u7ed5\u4e94\u79cd\u6d41\u884c\u7684\u5f15\u5bfc\u65b9\u6cd5\u8fdb\u884c\u8bc4\u4f30\u3002\u5728Qwen-2.5-7B\u548cLlama-3.1-8B\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5f3a\u5f15\u5bfc\u6027\u80fd\u4f9d\u8d56\u4e8e\u5f15\u5bfc\u65b9\u6cd5\u3001\u6a21\u578b\u548c\u76ee\u6807\u884c\u4e3a\u7684\u5177\u4f53\u7ec4\u5408\u3002\u4e0d\u826f\u7684\u4e09\u8005\u7ec4\u5408\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u6982\u5ff5\u7ea0\u7f20\u95ee\u9898\u3002\u4e0d\u540c\u7ec4\u5408\u5728\u504f\u89c1\u3001\u6709\u5bb3\u751f\u6210\u548c\u5e7b\u89c9\u7b49\u76ee\u6807\u4e0a\u7684\u8868\u73b0\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u8868\u793a\u5f15\u5bfc\u65b9\u6cd5\u7684\u6548\u679c\u5177\u6709\u9ad8\u5ea6\u60c5\u5883\u4f9d\u8d56\u6027\uff0c\u9700\u8981\u4ed4\u7ec6\u9009\u62e9\u65b9\u6cd5\u3001\u6a21\u578b\u548c\u76ee\u6807\u7684\u7ec4\u5408\u3002\u8be5\u7814\u7a76\u4e3a\u7cfb\u7edf\u8bc4\u4f30\u5f15\u5bfc\u65b9\u6cd5\u63d0\u4f9b\u4e86\u57fa\u51c6\u548c\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u884c\u4e3a\u7ea0\u7f20\u7684\u91cd\u8981\u95ee\u9898\uff0c\u5e76\u53d1\u5e03\u4e86\u5f00\u6e90\u4ee3\u7801\u4f9b\u540e\u7eed\u7814\u7a76\u4f7f\u7528\u3002"}}
{"id": "2509.13729", "categories": ["cs.CY", "cs.GT"], "pdf": "https://arxiv.org/pdf/2509.13729", "abs": "https://arxiv.org/abs/2509.13729", "authors": ["Yukun Zhang", "Tianyang Zhang"], "title": "The Economics of Information Pollution in the Age of AI: A General Equilibrium Approach to Welfare, Measurement, and Policy", "comment": null, "summary": "The advent of Large Language Models (LLMs) represents a fundamental shock to\nthe economics of information production. By asymmetrically collapsing the\nmarginal cost of generating low-quality, synthetic content while leaving\nhigh-quality production costly, AI systematically incentivizes information\npollution. This paper develops a general equilibrium framework to analyze this\nchallenge. We model the strategic interactions among a monopolistic platform,\nprofit-maximizing producers, and utility-maximizing consumers in a three-stage\ngame. The core of our model is a production technology with differential\nelasticities of substitution ($\\sigma_L > 1 > \\sigma_H$), which formalizes the\ninsight that AI is a substitute for labor in low-quality production but a\ncomplement in high-quality creation. We prove the existence of a unique\n\"Polluted Information Equilibrium\" and demonstrate its inefficiency, which is\ndriven by a threefold market failure: a production externality, a platform\ngovernance failure, and an information commons externality. Methodologically,\nwe derive a theoretically-grounded Information Pollution Index (IPI) with\nendogenous welfare weights to measure ecosystem health. From a policy\nperspective, we show that a first-best outcome requires a portfolio of\ninstruments targeting each failure. Finally, considering the challenges of deep\nuncertainty, we advocate for an adaptive governance framework where policy\ninstruments are dynamically adjusted based on real-time IPI readings, offering\na robust blueprint for regulating information markets in the age of AI.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u4e00\u822c\u5747\u8861\u6846\u67b6\u6765\u5206\u6790AI\u5982\u4f55\u901a\u8fc7\u964d\u4f4e\u4f4e\u8d28\u91cf\u5185\u5bb9\u7684\u751f\u4ea7\u6210\u672c\u800c\u7cfb\u7edf\u6027\u6fc0\u52b1\u4fe1\u606f\u6c61\u67d3\uff0c\u8bc1\u660e\u4e86\"\u6c61\u67d3\u4fe1\u606f\u5747\u8861\"\u7684\u5b58\u5728\u53ca\u5176\u4f4e\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u4fe1\u606f\u6c61\u67d3\u6307\u6570\u7684\u81ea\u9002\u5e94\u6cbb\u7406\u6846\u67b6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u51fa\u73b0\u5bf9\u4fe1\u606f\u751f\u4ea7\u7ecf\u6d4e\u5b66\u4ea7\u751f\u4e86\u6839\u672c\u6027\u51b2\u51fb\uff0c\u901a\u8fc7\u4e0d\u5bf9\u79f0\u5730\u964d\u4f4e\u4f4e\u8d28\u91cf\u5408\u6210\u5185\u5bb9\u7684\u8fb9\u9645\u6210\u672c\u800c\u4fdd\u6301\u9ad8\u8d28\u91cf\u5185\u5bb9\u7684\u9ad8\u6210\u672c\uff0cAI\u7cfb\u7edf\u6027\u5730\u6fc0\u52b1\u4e86\u4fe1\u606f\u6c61\u67d3\u3002", "method": "\u5efa\u7acb\u4e09\u9636\u6bb5\u535a\u5f08\u7684\u4e00\u822c\u5747\u8861\u6846\u67b6\uff0c\u6a21\u62df\u5784\u65ad\u5e73\u53f0\u3001\u5229\u6da6\u6700\u5927\u5316\u751f\u4ea7\u8005\u548c\u6548\u7528\u6700\u5927\u5316\u6d88\u8d39\u8005\u7684\u6218\u7565\u4e92\u52a8\uff0c\u6838\u5fc3\u662f\u91c7\u7528\u5dee\u5f02\u5316\u66ff\u4ee3\u5f39\u6027(\u03c3_L > 1 > \u03c3_H)\u7684\u751f\u4ea7\u6280\u672f\u6a21\u578b\u3002", "result": "\u8bc1\u660e\u4e86\u552f\u4e00\"\u6c61\u67d3\u4fe1\u606f\u5747\u8861\"\u7684\u5b58\u5728\u53ca\u5176\u4f4e\u6548\u6027\uff0c\u8bc6\u522b\u4e86\u4e09\u91cd\u5e02\u573a\u5931\u7075\uff1a\u751f\u4ea7\u5916\u90e8\u6027\u3001\u5e73\u53f0\u6cbb\u7406\u5931\u8d25\u548c\u4fe1\u606f\u516c\u5730\u5916\u90e8\u6027\uff0c\u5e76\u63a8\u5bfc\u51fa\u7406\u8bba\u57fa\u7840\u7684\u4fe1\u606f\u6c61\u67d3\u6307\u6570(IPI)\u3002", "conclusion": "\u6700\u4f18\u7ed3\u679c\u9700\u8981\u9488\u5bf9\u6bcf\u79cd\u5931\u7075\u7684\u653f\u7b56\u5de5\u5177\u7ec4\u5408\uff0c\u8003\u8651\u5230\u6df1\u5ea6\u4e0d\u786e\u5b9a\u6027\uff0c\u5efa\u8bae\u91c7\u7528\u57fa\u4e8e\u5b9e\u65f6IPI\u8bfb\u6570\u52a8\u6001\u8c03\u6574\u653f\u7b56\u5de5\u5177\u7684\u81ea\u9002\u5e94\u6cbb\u7406\u6846\u67b6\uff0c\u4e3aAI\u65f6\u4ee3\u4fe1\u606f\u5e02\u573a\u76d1\u7ba1\u63d0\u4f9b\u7a33\u5065\u84dd\u56fe\u3002"}}
{"id": "2509.13793", "categories": ["eess.SY", "cs.LG", "cs.NE", "cs.SY", "math.OC", "65K10, 68T05, 93B30, 93D99"], "pdf": "https://arxiv.org/pdf/2509.13793", "abs": "https://arxiv.org/abs/2509.13793", "authors": ["Thomas Chaffey"], "title": "Circuit realization and hardware linearization of monotone operator equilibrium networks", "comment": null, "summary": "It is shown that the port behavior of a resistor-diode network corresponds to\nthe solution of a ReLU monotone operator equilibrium network (a neural network\nin the limit of infinite depth), giving a parsimonious construction of a neural\nnetwork in analog hardware. We furthermore show that the gradient of such a\ncircuit can be computed directly in hardware, using a procedure we call\nhardware linearization. This allows the network to be trained in hardware,\nwhich we demonstrate with a device-level circuit simulation. We extend the\nresults to cascades of resistor-diode networks, which can be used to implement\nfeedforward and other asymmetric networks. We finally show that different\nnonlinear elements give rise to different activation functions, and introduce\nthe novel diode ReLU which is induced by a non-ideal diode model.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u7535\u963b-\u4e8c\u6781\u7ba1\u7f51\u7edc\u7684\u7aef\u53e3\u884c\u4e3a\u5bf9\u5e94\u4e8eReLU\u5355\u8c03\u7b97\u5b50\u5e73\u8861\u7f51\u7edc\u7684\u89e3\uff0c\u4e3a\u6a21\u62df\u786c\u4ef6\u4e2d\u7684\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u7b80\u6d01\u6784\u9020\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u786c\u4ef6\u7ebf\u6027\u5316\u65b9\u6cd5\u76f4\u63a5\u5728\u786c\u4ef6\u4e2d\u8ba1\u7b97\u68af\u5ea6\uff0c\u5b9e\u73b0\u786c\u4ef6\u8bad\u7ec3\uff0c\u5e76\u6269\u5c55\u5230\u7ea7\u8054\u7f51\u7edc\u5b9e\u73b0\u524d\u9988\u7b49\u4e0d\u5bf9\u79f0\u7f51\u7edc\u7ed3\u6784\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u6a21\u62df\u786c\u4ef6\u4e2d\u7b80\u6d01\u5730\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u5b9e\u73b0\u786c\u4ef6\u5185\u7684\u68af\u5ea6\u8ba1\u7b97\u548c\u8bad\u7ec3\uff0c\u63a2\u7d22\u4e0d\u540c\u975e\u7ebf\u6027\u5143\u4ef6\u5bf9\u5e94\u7684\u6fc0\u6d3b\u51fd\u6570\u3002", "method": "\u901a\u8fc7\u5206\u6790\u7535\u963b-\u4e8c\u6781\u7ba1\u7f51\u7edc\u7684\u7aef\u53e3\u884c\u4e3a\uff0c\u5efa\u7acb\u4e0eReLU\u5355\u8c03\u7b97\u5b50\u5e73\u8861\u7f51\u7edc\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u63d0\u51fa\u786c\u4ef6\u7ebf\u6027\u5316\u65b9\u6cd5\u6765\u8ba1\u7b97\u68af\u5ea6\uff0c\u5e76\u901a\u8fc7\u7535\u8def\u4eff\u771f\u9a8c\u8bc1\u786c\u4ef6\u8bad\u7ec3\u53ef\u884c\u6027\u3002", "result": "\u6210\u529f\u8bc1\u660e\u4e86\u7535\u963b-\u4e8c\u6781\u7ba1\u7f51\u7edc\u53ef\u4ee5\u6784\u9020\u795e\u7ecf\u7f51\u7edc\uff0c\u5b9e\u73b0\u4e86\u786c\u4ef6\u5185\u7684\u68af\u5ea6\u8ba1\u7b97\u548c\u8bad\u7ec3\uff0c\u53d1\u73b0\u4e86\u975e\u7406\u60f3\u4e8c\u6781\u7ba1\u6a21\u578b\u4ea7\u751f\u7684\u65b0\u578bReLU\u6fc0\u6d3b\u51fd\u6570\u3002", "conclusion": "\u7535\u963b-\u4e8c\u6781\u7ba1\u7f51\u7edc\u4e3a\u6a21\u62df\u786c\u4ef6\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u7b80\u6d01\u6709\u6548\u7684\u9014\u5f84\uff0c\u786c\u4ef6\u7ebf\u6027\u5316\u65b9\u6cd5\u4f7f\u5f97\u786c\u4ef6\u5185\u8bad\u7ec3\u6210\u4e3a\u53ef\u80fd\uff0c\u4e3a\u6a21\u62df\u795e\u7ecf\u7f51\u7edc\u786c\u4ef6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2509.13591", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.13591", "abs": "https://arxiv.org/abs/2509.13591", "authors": ["Amir-Hossein Shahidzadeh", "Jiyue Zhu", "Kezhou Chen", "Sha Yi", "Cornelia Ferm\u00fcller", "Yiannis Aloimonos", "Xiaolong Wang"], "title": "Object Pose Estimation through Dexterous Touch", "comment": null, "summary": "Robust object pose estimation is essential for manipulation and interaction\ntasks in robotics, particularly in scenarios where visual data is limited or\nsensitive to lighting, occlusions, and appearances. Tactile sensors often offer\nlimited and local contact information, making it challenging to reconstruct the\npose from partial data. Our approach uses sensorimotor exploration to actively\ncontrol a robot hand to interact with the object. We train with Reinforcement\nLearning (RL) to explore and collect tactile data. The collected 3D point\nclouds are used to iteratively refine the object's shape and pose. In our\nsetup, one hand holds the object steady while the other performs active\nexploration. We show that our method can actively explore an object's surface\nto identify critical pose features without prior knowledge of the object's\ngeometry. Supplementary material and more demonstrations will be provided at\nhttps://amirshahid.github.io/BimanualTactilePose .", "AI": {"tldr": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u53cc\u624b\u673a\u5668\u4eba\u89e6\u89c9\u63a2\u7d22\u6765\u4f30\u8ba1\u7269\u4f53\u59ff\u6001\uff0c\u65e0\u9700\u5148\u9a8c\u51e0\u4f55\u77e5\u8bc6\uff0c\u901a\u8fc7\u4e3b\u52a8\u4ea4\u4e92\u6536\u96c6\u89e6\u89c9\u6570\u636e\u5e76\u8fed\u4ee3\u4f18\u5316\u5f62\u72b6\u548c\u59ff\u6001\u4f30\u8ba1", "motivation": "\u5728\u89c6\u89c9\u6570\u636e\u53d7\u9650\u6216\u5bf9\u5149\u7167\u3001\u906e\u6321\u548c\u5916\u89c2\u654f\u611f\u7684\u573a\u666f\u4e2d\uff0c\u9700\u8981\u9c81\u68d2\u7684\u7269\u4f53\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u3002\u89e6\u89c9\u4f20\u611f\u5668\u63d0\u4f9b\u6709\u9650\u4e14\u5c40\u90e8\u7684\u63a5\u89e6\u4fe1\u606f\uff0c\u4ece\u90e8\u5206\u6570\u636e\u91cd\u5efa\u59ff\u6001\u5177\u6709\u6311\u6218\u6027", "method": "\u4f7f\u7528\u4f20\u611f\u5668\u8fd0\u52a8\u63a2\u7d22\u4e3b\u52a8\u63a7\u5236\u673a\u5668\u4eba\u624b\u4e0e\u7269\u4f53\u4ea4\u4e92\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u63a2\u7d22\u548c\u6536\u96c6\u89e6\u89c9\u6570\u636e\uff0c\u6536\u96c6\u76843D\u70b9\u4e91\u7528\u4e8e\u8fed\u4ee3\u4f18\u5316\u7269\u4f53\u5f62\u72b6\u548c\u59ff\u6001\u3002\u91c7\u7528\u53cc\u624b\u8bbe\u7f6e\uff1a\u4e00\u53ea\u624b\u56fa\u5b9a\u7269\u4f53\uff0c\u53e6\u4e00\u53ea\u624b\u8fdb\u884c\u4e3b\u52a8\u63a2\u7d22", "result": "\u65b9\u6cd5\u80fd\u591f\u4e3b\u52a8\u63a2\u7d22\u7269\u4f53\u8868\u9762\u4ee5\u8bc6\u522b\u5173\u952e\u59ff\u6001\u7279\u5f81\uff0c\u65e0\u9700\u7269\u4f53\u51e0\u4f55\u5f62\u72b6\u7684\u5148\u9a8c\u77e5\u8bc6", "conclusion": "\u63d0\u51fa\u7684\u53cc\u624b\u673a\u5668\u4eba\u89e6\u89c9\u63a2\u7d22\u65b9\u6cd5\u4e3a\u5728\u89c6\u89c9\u53d7\u9650\u73af\u5883\u4e0b\u5b9e\u73b0\u9c81\u68d2\u7684\u7269\u4f53\u59ff\u6001\u4f30\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.13547", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13547", "abs": "https://arxiv.org/abs/2509.13547", "authors": ["Harper Reed", "Michael Sugimura", "Angelo Zangari"], "title": "AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving", "comment": "16 pages, 5 tables", "summary": "We investigate whether giving LLM agents the collaborative tools and autonomy\nthat humans naturally use for problem solving can improve their performance. We\nequip Claude Code agents with MCP-based social media and journaling tools and\nallow them to use these tools as they see fit. Across 34 Aider Polyglot Python\nprogramming challenges, collaborative tools substantially improve performance\non the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and\n12-38% faster completion than baseline agents. Effects on the full challenge\nset are mixed, suggesting these tools act as performance enhancers when\nadditional reasoning scaffolding is most needed. Surprisingly, Different models\nnaturally adopted distinct collaborative strategies without explicit\ninstruction. Sonnet 3.7 engaged broadly across tools and benefited from\narticulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,\nleaning on journal-based semantic search when problems were genuinely\ndifficult. This mirrors how human developers adjust collaboration based on\nexpertise and task complexity. Behavioral analysis shows agents prefer writing\nover reading by about 2-9x, indicating that structured articulation drives much\nof the improvement rather than information access alone. Overall, AI agents can\nsystematically benefit from human-inspired collaboration tools at the edge of\ntheir capabilities, pointing to adaptive collaborative interfaces as reasoning\nenhancers rather than universal efficiency boosts.", "AI": {"tldr": "\u4e3aLLM\u667a\u80fd\u4f53\u63d0\u4f9b\u7c7b\u4f3c\u4eba\u7c7b\u7684\u534f\u4f5c\u5de5\u5177\u548c\u81ea\u4e3b\u6027\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5176\u5728\u6700\u56f0\u96be\u7f16\u7a0b\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u8868\u73b0\uff0c\u4f46\u6548\u679c\u56e0\u95ee\u9898\u96be\u5ea6\u800c\u5f02", "motivation": "\u7814\u7a76\u662f\u5426\u901a\u8fc7\u8d4b\u4e88LLM\u667a\u80fd\u4f53\u4eba\u7c7b\u81ea\u7136\u4f7f\u7528\u7684\u534f\u4f5c\u5de5\u5177\u548c\u81ea\u4e3b\u6027\uff0c\u80fd\u591f\u6539\u5584\u5176\u95ee\u9898\u89e3\u51b3\u6027\u80fd", "method": "\u4e3aClaude Code\u667a\u80fd\u4f53\u914d\u5907\u57fa\u4e8eMCP\u7684\u793e\u4ea4\u5a92\u4f53\u548c\u65e5\u5fd7\u5de5\u5177\uff0c\u8ba9\u5b83\u4eec\u81ea\u4e3b\u51b3\u5b9a\u5982\u4f55\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\u6765\u89e3\u51b334\u4e2aAider\u591a\u8bed\u8a00Python\u7f16\u7a0b\u6311\u6218", "result": "\u534f\u4f5c\u5de5\u5177\u5728\u6700\u56f0\u96be\u95ee\u9898\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\uff1a\u6210\u672c\u964d\u4f4e15-40%\uff0c\u8f6e\u6b21\u51cf\u5c1112-27%\uff0c\u5b8c\u6210\u901f\u5ea6\u63d0\u9ad812-38%\u3002\u4e0d\u540c\u6a21\u578b\u91c7\u7528\u4e0d\u540c\u534f\u4f5c\u7b56\u7565\uff0c\u667a\u80fd\u4f53\u504f\u597d\u5199\u4f5c\u800c\u975e\u9605\u8bfb\uff082-9\u500d\uff09", "conclusion": "AI\u667a\u80fd\u4f53\u5728\u80fd\u529b\u8fb9\u754c\u5904\u53ef\u4ee5\u4ece\u4eba\u7c7b\u542f\u53d1\u7684\u534f\u4f5c\u5de5\u5177\u4e2d\u7cfb\u7edf\u6027\u83b7\u76ca\uff0c\u8868\u660e\u81ea\u9002\u5e94\u534f\u4f5c\u754c\u9762\u53ef\u4f5c\u4e3a\u63a8\u7406\u589e\u5f3a\u5668\u800c\u975e\u901a\u7528\u6548\u7387\u63d0\u5347\u5de5\u5177"}}
{"id": "2509.13730", "categories": ["cs.CY", "K.3"], "pdf": "https://arxiv.org/pdf/2509.13730", "abs": "https://arxiv.org/abs/2509.13730", "authors": ["Juho Veps\u00e4l\u00e4inen", "Petri Juntunen"], "title": "Perspectives and potential issues in using artificial intelligence for computer science education", "comment": "12 pages, 1 figure, 2 tables, preprint (not approved for publication\n  yet)", "summary": "Since its launch in late 2022, ChatGPT has ignited widespread interest in\nLarge Language Models (LLMs) and broader Artificial Intelligence (AI)\nsolutions. As this new wave of AI permeates various sectors of society, we are\ncontinually uncovering both the potential and the limitations of existing AI\ntools.\n  The need for adjustment is particularly significant in Computer Science\nEducation (CSEd), as LLMs have evolved into core coding tools themselves,\nblurring the line between programming aids and intelligent systems, and\nreinforcing CSEd's role as a nexus of technology and pedagogy. The findings of\nour survey indicate that while AI technologies hold potential for enhancing\nlearning experiences, such as through personalized learning paths, intelligent\ntutoring systems, and automated assessments, there are also emerging concerns.\nThese include the risk of over-reliance on technology, the potential erosion of\nfundamental cognitive skills, and the challenge of maintaining equitable access\nto such innovations.\n  Recent advancements represent a paradigm shift, transforming not only the\ncontent we teach but also the methods by which teaching and learning take\nplace. Rather than placing the burden of adapting to AI technologies on\nstudents, educational institutions must take a proactive role in verifying,\nintegrating, and applying new pedagogical approaches. Such efforts can help\nensure that both educators and learners are equipped with the skills needed to\nnavigate the evolving educational landscape shaped by these technological\ninnovations.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86ChatGPT\u7b49\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u7684\u5f71\u54cd\uff0c\u5206\u6790\u4e86AI\u6280\u672f\u5e26\u6765\u7684\u673a\u9047\u4e0e\u6311\u6218\uff0c\u5e76\u547c\u5401\u6559\u80b2\u673a\u6784\u4e3b\u52a8\u9002\u5e94\u8fd9\u4e00\u6280\u672f\u53d8\u9769\u3002", "motivation": "\u968f\u7740ChatGPT\u7b49\u5927\u578b\u8bed\u8a00\u6a21\u578b\u57282022\u5e74\u5e95\u63a8\u51fa\u5e76\u5e7f\u6cdb\u666e\u53ca\uff0cAI\u6280\u672f\u6b63\u5728\u6df1\u523b\u5f71\u54cd\u793e\u4f1a\u5404\u4e2a\u9886\u57df\uff0c\u7279\u522b\u662f\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u4e2d\uff0cLLMs\u5df2\u7ecf\u6210\u4e3a\u6838\u5fc3\u7f16\u7a0b\u5de5\u5177\uff0c\u6a21\u7cca\u4e86\u7f16\u7a0b\u8f85\u52a9\u5de5\u5177\u4e0e\u667a\u80fd\u7cfb\u7edf\u4e4b\u95f4\u7684\u754c\u9650\uff0c\u8fd9\u9700\u8981\u6559\u80b2\u7cfb\u7edf\u8fdb\u884c\u76f8\u5e94\u8c03\u6574\u3002", "method": "\u901a\u8fc7\u8c03\u67e5\u7814\u7a76\u7684\u65b9\u6cd5\uff0c\u5206\u6790AI\u6280\u672f\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\u548c\u5f71\u54cd\uff0c\u63a2\u8ba8\u4e2a\u6027\u5316\u5b66\u4e60\u8def\u5f84\u3001\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u548c\u81ea\u52a8\u8bc4\u4f30\u7b49\u6280\u672f\u7684\u6f5c\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0AI\u6280\u672f\u867d\u7136\u5177\u6709\u589e\u5f3a\u5b66\u4e60\u4f53\u9a8c\u7684\u6f5c\u529b\uff0c\u4f46\u4e5f\u5b58\u5728\u8fc7\u5ea6\u4f9d\u8d56\u6280\u672f\u3001\u57fa\u7840\u8ba4\u77e5\u6280\u80fd\u9000\u5316\u4ee5\u53ca\u516c\u5e73\u83b7\u53d6\u521b\u65b0\u6280\u672f\u7b49\u65b0\u5174\u95ee\u9898\u3002", "conclusion": "\u6559\u80b2\u673a\u6784\u9700\u8981\u4e3b\u52a8\u627f\u62c5\u9a8c\u8bc1\u3001\u6574\u5408\u548c\u5e94\u7528\u65b0\u6559\u5b66\u65b9\u6cd5\u7684\u8d23\u4efb\uff0c\u800c\u4e0d\u662f\u5c06\u9002\u5e94AI\u6280\u672f\u7684\u8d1f\u62c5\u653e\u5728\u5b66\u751f\u8eab\u4e0a\uff0c\u4ee5\u786e\u4fdd\u6559\u80b2\u8005\u548c\u5b66\u4e60\u8005\u90fd\u5177\u5907\u5e94\u5bf9\u6280\u672f\u53d8\u9769\u6240\u9700\u7684\u6280\u80fd\u3002"}}
{"id": "2509.13840", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.13840", "abs": "https://arxiv.org/abs/2509.13840", "authors": ["Vinay C K", "Vikas Vazhayil", "Madhav rao"], "title": "Characterizing Human Limb Movements Using An In-House Multi-Channel Non-Invasive Surface-EMG System", "comment": null, "summary": "Electromyography (EMG) signals are obtained from muscle cell activity. The\nrecording and analysis of EMG signals has several applications. The EMG is of\ndiagnostic importance for treating patients suffering from neurological and\nneuromuscular disorders. Conventional methods involve placement of invasive\nelectrodes within the muscles to record EMG signals. The goal is to showcase\nthe usage of surface based EMG signals to characterize all possible human limb\nmovements. An in-house non-invasive EMG signal acquisition system that offers\ncharacterization of human limb actions is a suitable candidate for motor\nimpairment studies and easily extendable to design bionics control specifically\nfor neuromuscular disorder patients. An in-house 8-channel surface-EMG signal\nacquisition system was designed, fabricated, and employed for characterizing\nspecific movements of upper and lower limb. The non-invasive acquisition system\ncaptures the compound electromuscular activity generated from the group of\nmuscles. The EMG acquisition system was designed as a modular structure where\nthe front end analog circuit designs were replicated for all 8 channels, and\nwere designed to function independently. Support vector machine (SVM) as\nclassifier models were developed offline to successfully characterize different\nhuman limb actions. The in house built 8 channel acquisition system with ML\nclassifier models were utilized to successfully characterize movements at\nvarious joints of the upper and lower limb including fingers, wrist, elbow,\nshoulder, knee, and ankle individually.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd8\u901a\u9053\u8868\u9762\u808c\u7535\u4fe1\u53f7\u91c7\u96c6\u7cfb\u7edf\uff0c\u7ed3\u5408\u652f\u6301\u5411\u91cf\u673a\u5206\u7c7b\u5668\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u4eba\u4f53\u4e0a\u4e0b\u80a2\u5404\u5173\u8282\u8fd0\u52a8\u7684\u975e\u4fb5\u5165\u5f0f\u8868\u5f81\u548c\u5206\u7c7b\u3002", "motivation": "\u4f20\u7edf\u808c\u7535\u4fe1\u53f7\u91c7\u96c6\u9700\u8981\u4fb5\u5165\u5f0f\u7535\u6781\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u975e\u4fb5\u5165\u5f0f\u8868\u9762\u808c\u7535\u4fe1\u53f7\u7cfb\u7edf\uff0c\u7528\u4e8e\u8868\u5f81\u4eba\u4f53\u80a2\u4f53\u8fd0\u52a8\uff0c\u7279\u522b\u9002\u7528\u4e8e\u795e\u7ecf\u808c\u8089\u75be\u75c5\u60a3\u8005\u7684\u8fd0\u52a8\u969c\u788d\u7814\u7a76\u548c\u4eff\u751f\u63a7\u5236\u8bbe\u8ba1\u3002", "method": "\u8bbe\u8ba1\u5e76\u5236\u9020\u4e868\u901a\u9053\u8868\u9762\u808c\u7535\u4fe1\u53f7\u91c7\u96c6\u7cfb\u7edf\uff0c\u91c7\u7528\u6a21\u5757\u5316\u7ed3\u6784\u8bbe\u8ba1\uff0c\u6bcf\u4e2a\u901a\u9053\u7684\u524d\u7aef\u6a21\u62df\u7535\u8def\u72ec\u7acb\u5de5\u4f5c\u3002\u4f7f\u7528\u652f\u6301\u5411\u91cf\u673a(SVM)\u4f5c\u4e3a\u5206\u7c7b\u5668\u6a21\u578b\u8fdb\u884c\u79bb\u7ebf\u5206\u6790\u3002", "result": "\u8be5\u7cfb\u7edf\u6210\u529f\u8868\u5f81\u4e86\u4e0a\u4e0b\u80a2\u5404\u5173\u8282\uff08\u624b\u6307\u3001\u624b\u8155\u3001\u8098\u90e8\u3001\u80a9\u90e8\u3001\u819d\u76d6\u548c\u811a\u8e1d\uff09\u7684\u5355\u72ec\u8fd0\u52a8\uff0c\u80fd\u591f\u6355\u83b7\u808c\u8089\u7fa4\u4ea7\u751f\u7684\u590d\u5408\u7535\u808c\u8089\u6d3b\u52a8\u3002", "conclusion": "\u81ea\u4e3b\u7814\u53d1\u76848\u901a\u9053\u91c7\u96c6\u7cfb\u7edf\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\uff0c\u4e3a\u795e\u7ecf\u808c\u8089\u75be\u75c5\u60a3\u8005\u7684\u8fd0\u52a8\u7814\u7a76\u548c\u4eff\u751f\u63a7\u5236\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u975e\u4fb5\u5165\u5f0f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13595", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13595", "abs": "https://arxiv.org/abs/2509.13595", "authors": ["Xiao Liu", "Weijun Wang", "Tianlun Huang", "Zhiyong Wang", "Wei Feng"], "title": "Leg-Arm Coordinated Operation for Curtain Wall Installation", "comment": null, "summary": "With the acceleration of urbanization, the number of high-rise buildings and\nlarge public facilities is increasing, making curtain walls an essential\ncomponent of modern architecture with widespread applications. Traditional\ncurtain wall installation methods face challenges such as variable on-site\nterrain, high labor intensity, low construction efficiency, and significant\nsafety risks. Large panels often require multiple workers to complete\ninstallation. To address these issues, based on a hexapod curtain wall\ninstallation robot, we design a hierarchical optimization-based whole-body\ncontrol framework for coordinated arm-leg planning tailored to three key tasks:\nwall installation, ceiling installation, and floor laying. This framework\nintegrates the motion of the hexapod legs with the operation of the folding arm\nand the serial-parallel manipulator. We conduct experiments on the hexapod\ncurtain wall installation robot to validate the proposed control method,\ndemonstrating its capability in performing curtain wall installation tasks. Our\nresults confirm the effectiveness of the hierarchical optimization-based\narm-leg coordination framework for the hexapod robot, laying the foundation for\nits further application in complex construction site environments.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u516d\u8db3\u5e55\u5899\u5b89\u88c5\u673a\u5668\u4eba\u7684\u5206\u5c42\u4f18\u5316\u5168\u8eab\u63a7\u5236\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edf\u5e55\u5899\u5b89\u88c5\u65b9\u6cd5\u6548\u7387\u4f4e\u3001\u5b89\u5168\u98ce\u9669\u9ad8\u7b49\u95ee\u9898\uff0c\u901a\u8fc7\u81c2\u817f\u534f\u8c03\u89c4\u5212\u5b9e\u73b0\u5899\u9762\u3001\u5929\u82b1\u677f\u548c\u5730\u677f\u4e09\u79cd\u5173\u952e\u4efb\u52a1\u7684\u81ea\u52a8\u5316\u5b89\u88c5\u3002", "motivation": "\u4f20\u7edf\u5e55\u5899\u5b89\u88c5\u65b9\u6cd5\u9762\u4e34\u73b0\u573a\u5730\u5f62\u591a\u53d8\u3001\u52b3\u52a8\u5f3a\u5ea6\u5927\u3001\u65bd\u5de5\u6548\u7387\u4f4e\u548c\u5b89\u5168\u98ce\u9669\u9ad8\u7b49\u6311\u6218\uff0c\u5927\u578b\u9762\u677f\u9700\u8981\u591a\u4eba\u534f\u4f5c\u5b89\u88c5\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u9ad8\u65bd\u5de5\u6548\u7387\u548c\u5b89\u5168\u6027\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u516d\u8db3\u673a\u5668\u4eba\u7684\u5206\u5c42\u4f18\u5316\u5168\u8eab\u63a7\u5236\u6846\u67b6\uff0c\u96c6\u6210\u516d\u8db3\u817f\u90e8\u7684\u8fd0\u52a8\u4e0e\u6298\u53e0\u81c2\u548c\u4e32\u5e76\u8054\u673a\u68b0\u624b\u7684\u64cd\u4f5c\uff0c\u9488\u5bf9\u5899\u9762\u5b89\u88c5\u3001\u5929\u82b1\u677f\u5b89\u88c5\u548c\u5730\u677f\u94fa\u8bbe\u4e09\u79cd\u4efb\u52a1\u8fdb\u884c\u534f\u8c03\u7684\u81c2\u817f\u89c4\u5212\u3002", "result": "\u5728\u516d\u8db3\u5e55\u5899\u5b89\u88c5\u673a\u5668\u4eba\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u63a7\u5236\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u8be5\u6846\u67b6\u80fd\u591f\u6210\u529f\u6267\u884c\u5e55\u5899\u5b89\u88c5\u4efb\u52a1\u3002", "conclusion": "\u5206\u5c42\u4f18\u5316\u7684\u81c2\u817f\u534f\u8c03\u6846\u67b6\u4e3a\u516d\u8db3\u673a\u5668\u4eba\u5728\u590d\u6742\u5efa\u7b51\u5de5\u5730\u73af\u5883\u7684\u8fdb\u4e00\u6b65\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u5e55\u5899\u5b89\u88c5\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2509.13570", "categories": ["cs.AI", "math.HO", "Primary: 97U50, Secondary: 97U70, 97D40, 97D60, 97E50, 97H40"], "pdf": "https://arxiv.org/pdf/2509.13570", "abs": "https://arxiv.org/abs/2509.13570", "authors": ["Hannah Klawa", "Shraddha Rajpal", "Cigole Thomas"], "title": "Gen AI in Proof-based Math Courses: A Pilot Study", "comment": "35 pages, 6 figures, Comments welcome!", "summary": "With the rapid rise of generative AI in higher education and the\nunreliability of current AI detection tools, developing policies that encourage\nstudent learning and critical thinking has become increasingly important. This\nstudy examines student use and perceptions of generative AI across three\nproof-based undergraduate mathematics courses: a first-semester abstract\nalgebra course, a topology course and a second-semester abstract algebra\ncourse. In each case, course policy permitted some use of generative AI.\nDrawing on survey responses and student interviews, we analyze how students\nengaged with AI tools, their perceptions of generative AI's usefulness and\nlimitations, and what implications these perceptions hold for teaching\nproof-based mathematics. We conclude by discussing future considerations for\nintegrating generative AI into proof-based mathematics instruction.", "AI": {"tldr": "\u672c\u7814\u7a76\u8c03\u67e5\u4e86\u672c\u79d1\u751f\u5728\u8bc1\u660e\u6570\u5b66\u8bfe\u7a0b\u4e2d\u4f7f\u7528\u751f\u6210\u5f0fAI\u7684\u60c5\u51b5\uff0c\u53d1\u73b0\u5b66\u751f\u4e3b\u8981\u5728\u6982\u5ff5\u7406\u89e3\u3001\u601d\u8def\u542f\u53d1\u548c\u9a8c\u8bc1\u65b9\u9762\u4f7f\u7528AI\uff0c\u4f46\u8ba4\u8bc6\u5230\u5176\u5728\u4e25\u683c\u8bc1\u660e\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5728\u9ad8\u7b49\u6559\u80b2\u4e2d\u7684\u5feb\u901f\u5174\u8d77\u548c\u73b0\u6709AI\u68c0\u6d4b\u5de5\u5177\u7684\u4e0d\u53ef\u9760\u6027\uff0c\u9700\u8981\u5236\u5b9a\u9f13\u52b1\u5b66\u751f\u5b66\u4e60\u548c\u6279\u5224\u6027\u601d\u7ef4\u7684\u653f\u7b56\u3002\u672c\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u5b66\u751f\u5728\u8bc1\u660e\u6570\u5b66\u8bfe\u7a0b\u4e2d\u5982\u4f55\u4f7f\u7528\u548c\u770b\u5f85\u751f\u6210\u5f0fAI\u3002", "method": "\u901a\u8fc7\u8c03\u67e5\u95ee\u5377\u548c\u5b66\u751f\u8bbf\u8c08\uff0c\u5206\u6790\u4e09\u4e2a\u8bc1\u660e\u6570\u5b66\u8bfe\u7a0b\uff08\u62bd\u8c61\u4ee3\u6570\u3001\u62d3\u6251\u5b66\uff09\u4e2d\u5b66\u751f\u4f7f\u7528AI\u5de5\u5177\u7684\u65b9\u5f0f\u3001\u5bf9AI\u6709\u7528\u6027\u548c\u5c40\u9650\u6027\u7684\u770b\u6cd5\u3002", "result": "\u5b66\u751f\u4e3b\u8981\u5728\u6982\u5ff5\u7406\u89e3\u3001\u601d\u8def\u542f\u53d1\u548c\u9a8c\u8bc1\u65b9\u9762\u4f7f\u7528\u751f\u6210\u5f0fAI\uff0c\u4f46\u8ba4\u8bc6\u5230AI\u5728\u4e25\u683c\u6570\u5b66\u8bc1\u660e\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u751f\u6210\u5b8c\u6574\u3001\u6b63\u786e\u8bc1\u660e\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "\u9700\u8981\u8c28\u614e\u8003\u8651\u5982\u4f55\u5c06\u751f\u6210\u5f0fAI\u6574\u5408\u5230\u8bc1\u660e\u6570\u5b66\u6559\u5b66\u4e2d\uff0c\u65e2\u8981\u5229\u7528\u5176\u8f85\u52a9\u5b66\u4e60\u4ef7\u503c\uff0c\u53c8\u8981\u8ba4\u8bc6\u5230\u5176\u5c40\u9650\u6027\uff0c\u57f9\u517b\u5b66\u751f\u7684\u6279\u5224\u6027\u601d\u7ef4\u548c\u72ec\u7acb\u8bc1\u660e\u80fd\u529b\u3002"}}
{"id": "2509.13854", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13854", "abs": "https://arxiv.org/abs/2509.13854", "authors": ["Jack McKinlay", "Marina De Vos", "Janina A. Hoffmann", "Andreas Theodorou"], "title": "Understanding the Process of Human-AI Value Alignment", "comment": "39 pages, 7 figures", "summary": "Background: Value alignment in computer science research is often used to\nrefer to the process of aligning artificial intelligence with humans, but the\nway the phrase is used often lacks precision. Objectives: In this paper, we\nconduct a systematic literature review to advance the understanding of value\nalignment in artificial intelligence by characterising the topic in the context\nof its research literature. We use this to suggest a more precise definition of\nthe term. Methods: We analyse 172 value alignment research articles that have\nbeen published in recent years and synthesise their content using thematic\nanalyses. Results: Our analysis leads to six themes: value alignment drivers &\napproaches; challenges in value alignment; values in value alignment; cognitive\nprocesses in humans and AI; human-agent teaming; and designing and developing\nvalue-aligned systems. Conclusions: By analysing these themes in the context of\nthe literature we define value alignment as an ongoing process between humans\nand autonomous agents that aims to express and implement abstract values in\ndiverse contexts, while managing the cognitive limits of both humans and AI\nagents and also balancing the conflicting ethical and political demands\ngenerated by the values in different groups. Our analysis gives rise to a set\nof research challenges and opportunities in the field of value alignment for\nfuture work.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u5206\u6790\u4e86172\u7bc7\u4ef7\u503c\u5bf9\u9f50\u7814\u7a76\u8bba\u6587\uff0c\u63d0\u51fa\u4e86\u4ef7\u503c\u5bf9\u9f50\u7684\u7cbe\u786e\u5b9a\u4e49\uff1a\u4eba\u7c7b\u4e0e\u81ea\u4e3b\u4ee3\u7406\u4e4b\u95f4\u6301\u7eed\u7684\u8fc7\u7a0b\uff0c\u65e8\u5728\u4e0d\u540c\u60c5\u5883\u4e2d\u8868\u8fbe\u548c\u5b9e\u65bd\u62bd\u8c61\u4ef7\u503c\u89c2\uff0c\u540c\u65f6\u7ba1\u7406\u4eba\u7c7b\u548cAI\u7684\u8ba4\u77e5\u9650\u5236\u5e76\u5e73\u8861\u4e0d\u540c\u7fa4\u4f53\u95f4\u7684\u4f26\u7406\u653f\u6cbb\u9700\u6c42\u51b2\u7a81\u3002", "motivation": "\u5f53\u524d\u8ba1\u7b97\u673a\u79d1\u5b66\u7814\u7a76\u4e2d'\u4ef7\u503c\u5bf9\u9f50'\u4e00\u8bcd\u4f7f\u7528\u7f3a\u4e4f\u7cbe\u786e\u6027\uff0c\u9700\u8981\u901a\u8fc7\u5bf9\u76f8\u5173\u6587\u732e\u7684\u7cfb\u7edf\u5206\u6790\u6765\u63a8\u8fdb\u5bf9\u4eba\u5de5\u667a\u80fd\u4ef7\u503c\u5bf9\u9f50\u7684\u7406\u89e3\u5e76\u7ed9\u51fa\u66f4\u51c6\u786e\u7684\u5b9a\u4e49\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790\u8fd1\u5e74\u6765\u53d1\u8868\u7684172\u7bc7\u4ef7\u503c\u5bf9\u9f50\u7814\u7a76\u6587\u7ae0\uff0c\u4f7f\u7528\u4e3b\u9898\u5206\u6790\u6cd5\u7efc\u5408\u5176\u5185\u5bb9\u3002", "result": "\u5206\u6790\u5f97\u51fa\u516d\u4e2a\u4e3b\u9898\uff1a\u4ef7\u503c\u5bf9\u9f50\u9a71\u52a8\u56e0\u7d20\u4e0e\u65b9\u6cd5\u3001\u4ef7\u503c\u5bf9\u9f50\u6311\u6218\u3001\u4ef7\u503c\u5bf9\u9f50\u4e2d\u7684\u4ef7\u503c\u89c2\u3001\u4eba\u7c7b\u4e0eAI\u7684\u8ba4\u77e5\u8fc7\u7a0b\u3001\u4eba\u673a\u534f\u4f5c\u3001\u4ef7\u503c\u5bf9\u9f50\u7cfb\u7edf\u8bbe\u8ba1\u4e0e\u5f00\u53d1\u3002\u57fa\u4e8e\u8fd9\u4e9b\u4e3b\u9898\u63d0\u51fa\u4e86\u4ef7\u503c\u5bf9\u9f50\u7684\u7cbe\u786e\u5b9a\u4e49\u3002", "conclusion": "\u7814\u7a76\u4e3a\u4ef7\u503c\u5bf9\u9f50\u9886\u57df\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u5b9a\u4e49\u6846\u67b6\uff0c\u5e76\u8bc6\u522b\u51fa\u672a\u6765\u7814\u7a76\u9762\u4e34\u7684\u6311\u6218\u548c\u673a\u9047\uff0c\u5f3a\u8c03\u4e86\u4ef7\u503c\u5bf9\u9f50\u4f5c\u4e3a\u6301\u7eed\u8fc7\u7a0b\u7684\u91cd\u8981\u6027\uff0c\u9700\u8981\u5e73\u8861\u591a\u65b9\u9762\u7684\u8ba4\u77e5\u548c\u4f26\u7406\u9700\u6c42\u3002"}}
{"id": "2509.13934", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.13934", "abs": "https://arxiv.org/abs/2509.13934", "authors": ["Zhixion Chen", "Jiangzhou Wang", "and Hyundong Shin", "Arumugam Nallanathan"], "title": "Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection", "comment": "14pages, 8 figures", "summary": "The deployment of unmanned aerial vehicles (UAVs) for reliable and\nenergy-efficient data collection from spatially distributed devices holds great\npromise in supporting diverse Internet of Things (IoT) applications.\nNevertheless, the limited endurance and communication range of UAVs necessitate\nintelligent trajectory planning. While reinforcement learning (RL) has been\nextensively explored for UAV trajectory optimization, its interactive nature\nentails high costs and risks in real-world environments. Offline RL mitigates\nthese issues but remains susceptible to unstable training and heavily rely on\nexpert-quality datasets. To address these challenges, we formulate a joint UAV\ntrajectory planning and resource allocation problem to maximize energy\nefficiency of data collection. The resource allocation subproblem is first\ntransformed into an equivalent linear programming formulation and solved\noptimally with polynomial-time complexity. Then, we propose a large language\nmodel (LLM)-empowered critic-regularized decision transformer (DT) framework,\ntermed LLM-CRDT, to learn effective UAV control policies. In LLM-CRDT, we\nincorporate critic networks to regularize the DT model training, thereby\nintegrating the sequence modeling capabilities of DT with critic-based value\nguidance to enable learning effective policies from suboptimal datasets.\nFurthermore, to mitigate the data-hungry nature of transformer models, we\nemploy a pre-trained LLM as the transformer backbone of the DT model and adopt\na parameter-efficient fine-tuning strategy, i.e., LoRA, enabling rapid\nadaptation to UAV control tasks with small-scale dataset and low computational\noverhead. Extensive simulations demonstrate that LLM-CRDT outperforms benchmark\nonline and offline RL methods, achieving up to 36.7\\% higher energy efficiency\nthan the current state-of-the-art DT approaches.", "AI": {"tldr": "\u63d0\u51faLLM-CRDT\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u51b3\u7b56\u53d8\u6362\u5668\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u8f68\u8ff9\u89c4\u5212\u548c\u8d44\u6e90\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u80fd\u91cf\u6548\u7387", "motivation": "\u65e0\u4eba\u673a\u5728\u7269\u8054\u7f51\u6570\u636e\u6536\u96c6\u4e2d\u9762\u4e34\u7eed\u822a\u548c\u901a\u4fe1\u8303\u56f4\u9650\u5236\uff0c\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6210\u672c\u9ad8\u98ce\u9669\u5927\uff0c\u79bb\u7ebfRL\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u4e14\u4f9d\u8d56\u4e13\u5bb6\u6570\u636e", "method": "\u5c06\u8d44\u6e90\u5206\u914d\u95ee\u9898\u8f6c\u5316\u4e3a\u7ebf\u6027\u89c4\u5212\u6c42\u89e3\uff0c\u63d0\u51faLLM\u8d4b\u80fd\u7684critic-regularized\u51b3\u7b56\u53d8\u6362\u5668\u6846\u67b6\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3LLM\u4f5c\u4e3a\u9aa8\u5e72\u7f51\u7edc\u5e76\u91c7\u7528LoRA\u5fae\u8c03", "result": "\u5728\u4eff\u771f\u4e2d\u4f18\u4e8e\u57fa\u51c6\u5728\u7ebf\u548c\u79bb\u7ebfRL\u65b9\u6cd5\uff0c\u6bd4\u5f53\u524d\u6700\u5148\u8fdb\u7684DT\u65b9\u6cd5\u80fd\u91cf\u6548\u7387\u63d0\u534736.7%", "conclusion": "LLM-CRDT\u6846\u67b6\u80fd\u591f\u4ece\u5c0f\u89c4\u6a21\u6b21\u4f18\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u6709\u6548\u7b56\u7565\uff0c\u4e3a\u65e0\u4eba\u673a\u63a7\u5236\u4efb\u52a1\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.13649", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.13649", "abs": "https://arxiv.org/abs/2509.13649", "authors": ["M\u00e9lon\u00e9 Nyoba Tchonkeu", "Soulaimane Berkane", "Tarek Hamel"], "title": "Barometer-Aided Attitude Estimation", "comment": "6 pages, 4 figures. this manuscript is submitted to IEEE Control\n  Systems Letters (L-CSS) with American Control Conference (ACC) option", "summary": "Accurate and robust attitude estimation is a central challenge for autonomous\nvehicles operating in GNSS-denied or highly dynamic environments. In such\ncases, Inertial Measurement Units (IMUs) alone are insufficient for reliable\ntilt estimation due to the ambiguity between gravitational and inertial\naccelerations. While auxiliary velocity sensors, such as GNSS, Pitot tubes,\nDoppler radar, or visual odometry, are often used, they can be unavailable,\nintermittent, or costly. This work introduces a barometer-aided attitude\nestimation architecture that leverages barometric altitude measurements to\ninfer vertical velocity and attitude within a nonlinear observer on SO(3). The\ndesign cascades a deterministic Riccati observer with a complementary filter,\nensuring Almost Global Asymptotic Stability (AGAS) under a uniform\nobservability condition while maintaining geometric consistency. The analysis\nhighlights barometer-aided estimation as a lightweight and effective\ncomplementary modality.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6c14\u538b\u8ba1\u7684\u59ff\u6001\u4f30\u8ba1\u67b6\u6784\uff0c\u5229\u7528\u6c14\u538b\u9ad8\u5ea6\u6d4b\u91cf\u6765\u63a8\u65ad\u5782\u76f4\u901f\u5ea6\u548c\u59ff\u6001\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u89c2\u6d4b\u5668\u5b9e\u73b0\u51e0\u4e4e\u5168\u5c40\u6e10\u8fd1\u7a33\u5b9a\u6027", "motivation": "\u5728GNSS\u62d2\u6b62\u6216\u9ad8\u52a8\u6001\u73af\u5883\u4e2d\uff0c\u4ec5\u4f7f\u7528IMU\u65e0\u6cd5\u53ef\u9760\u4f30\u8ba1\u503e\u659c\u59ff\u6001\uff0c\u800c\u8f85\u52a9\u901f\u5ea6\u4f20\u611f\u5668\u53ef\u80fd\u4e0d\u53ef\u7528\u3001\u95f4\u6b47\u6027\u6216\u6210\u672c\u9ad8\u6602", "method": "\u91c7\u7528\u6c14\u538b\u8ba1\u8f85\u52a9\u7684\u59ff\u6001\u4f30\u8ba1\u67b6\u6784\uff0c\u5c06\u786e\u5b9a\u6027Riccati\u89c2\u6d4b\u5668\u4e0e\u4e92\u8865\u6ee4\u6ce2\u5668\u7ea7\u8054\uff0c\u5728SO(3)\u6d41\u5f62\u4e0a\u8bbe\u8ba1\u975e\u7ebf\u6027\u89c2\u6d4b\u5668", "result": "\u5728\u5747\u5300\u53ef\u89c2\u6d4b\u6027\u6761\u4ef6\u4e0b\u786e\u4fdd\u51e0\u4e4e\u5168\u5c40\u6e10\u8fd1\u7a33\u5b9a\u6027(AGAS)\uff0c\u540c\u65f6\u4fdd\u6301\u51e0\u4f55\u4e00\u81f4\u6027", "conclusion": "\u6c14\u538b\u8ba1\u8f85\u52a9\u4f30\u8ba1\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4e14\u6709\u6548\u7684\u8865\u5145\u6a21\u6001\uff0c\u4e3a\u81ea\u4e3b\u8f66\u8f86\u5728\u6311\u6218\u6027\u73af\u5883\u4e2d\u63d0\u4f9b\u53ef\u9760\u59ff\u6001\u4f30\u8ba1"}}
{"id": "2509.13588", "categories": ["cs.AI", "cs.CE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.13588", "abs": "https://arxiv.org/abs/2509.13588", "authors": ["Xuan Liu", "Haoyang Shang", "Haojian Jin"], "title": "Programmable Cognitive Bias in Social Agents", "comment": null, "summary": "This paper introduces CoBRA, a novel toolkit for systematically specifying\nagent behavior in LLM-based social simulation. We found that conventional\napproaches that specify agent behaviors through implicit natural language\ndescriptions cannot yield consistent behaviors across models, and the produced\nagent behaviors do not capture the nuances of the descriptions. In contrast,\nCoBRA presents a new approach to program agents' cognitive biases explicitly,\nby grounding agents' expected behaviors using classic social science\nexperiments. CoBRA has two components: (1) Cognitive Bias Index that measures\nthe cognitive bias of a social agent, by quantifying the agent's reactions in a\nset of validated classical social science experiments; (2) Behavioral\nRegulation Engine that aligns the agent's behavior to demonstrate controlled\ncognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and\ntechnical benchmarks. Our results suggest that CoBRA can precisely program the\ncognitive bias demonstrated in a social agent in a model-agnostic manner.", "AI": {"tldr": "CoBRA\u662f\u4e00\u4e2a\u7528\u4e8e\u5728\u57fa\u4e8eLLM\u7684\u793e\u4f1a\u6a21\u62df\u4e2d\u7cfb\u7edf\u5316\u89c4\u8303\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u5de5\u5177\u5305\uff0c\u901a\u8fc7\u663e\u5f0f\u7f16\u7a0b\u8ba4\u77e5\u504f\u89c1\u6765\u89e3\u51b3\u4f20\u7edf\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u65b9\u6cd5\u7684\u4e00\u81f4\u6027\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f7f\u7528\u9690\u5f0f\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u6765\u6307\u5b9a\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u65e0\u6cd5\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u4ea7\u751f\u4e00\u81f4\u884c\u4e3a\uff0c\u4e14\u65e0\u6cd5\u6355\u6349\u63cf\u8ff0\u7684\u7ec6\u5fae\u5dee\u522b\u3002", "method": "CoBRA\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1a\u8ba4\u77e5\u504f\u89c1\u6307\u6570\uff08\u901a\u8fc7\u7ecf\u5178\u793e\u4f1a\u79d1\u5b66\u5b9e\u9a8c\u91cf\u5316\u667a\u80fd\u4f53\u53cd\u5e94\uff09\u548c\u884c\u4e3a\u8c03\u8282\u5f15\u64ce\uff08\u5c06\u667a\u80fd\u4f53\u884c\u4e3a\u4e0e\u53d7\u63a7\u8ba4\u77e5\u504f\u89c1\u5bf9\u9f50\uff09\u3002", "result": "\u8bc4\u4f30\u663e\u793aCoBRA\u80fd\u591f\u4ee5\u6a21\u578b\u65e0\u5173\u7684\u65b9\u5f0f\u7cbe\u786e\u7f16\u7a0b\u793e\u4f1a\u667a\u80fd\u4f53\u4e2d\u5c55\u793a\u7684\u8ba4\u77e5\u504f\u89c1\u3002", "conclusion": "CoBRA\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u663e\u5f0f\u7f16\u7a0b\u667a\u80fd\u4f53\u7684\u8ba4\u77e5\u504f\u89c1\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.14088", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2509.14088", "abs": "https://arxiv.org/abs/2509.14088", "authors": ["Victor-Alexandru P\u0103durean", "Paul Denny", "Andrew Luxton-Reilly", "Alkis Gotovos", "Adish Singla"], "title": "Interleaving Natural Language Prompting with Code Editing for Solving Programming Tasks with Generative AI Models", "comment": null, "summary": "Nowadays, computing students often rely on both natural-language prompting\nand manual code editing to solve programming tasks. Yet we still lack a clear\nunderstanding of how these two modes are combined in practice, and how their\nusage varies with task complexity and student ability. In this paper, we\ninvestigate this through a large-scale study in an introductory programming\ncourse, collecting 13,305 interactions from 355 students during a three-day\nlaboratory activity. Our analysis shows that students primarily use prompting\nto generate initial solutions, and then often enter short edit-run loops to\nrefine their code following a failed execution. We find that manual editing\nbecomes more frequent as task complexity increases, but most edits remain\nconcise, with many affecting a single line of code. Higher-performing students\ntend to succeed using prompting alone, while lower-performing students rely\nmore on edits. Student reflections confirm that prompting is helpful for\nstructuring solutions, editing is effective for making targeted corrections,\nwhile both are useful for learning. These findings highlight the role of manual\nediting as a deliberate last-mile repair strategy, complementing prompting in\nAI-assisted programming workflows.", "AI": {"tldr": "\u5b66\u751f\u4e3b\u8981\u4f7f\u7528\u63d0\u793a\u751f\u6210\u521d\u59cb\u89e3\u51b3\u65b9\u6848\uff0c\u7136\u540e\u901a\u8fc7\u7b80\u77ed\u7684\u7f16\u8f91-\u8fd0\u884c\u5faa\u73af\u6765\u5b8c\u5584\u4ee3\u7801\u3002\u968f\u7740\u4efb\u52a1\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u624b\u52a8\u7f16\u8f91\u66f4\u9891\u7e41\uff0c\u4f46\u5927\u591a\u6570\u7f16\u8f91\u90fd\u5f88\u7b80\u6d01\u3002\u9ad8\u7ee9\u6548\u5b66\u751f\u66f4\u4f9d\u8d56\u63d0\u793a\uff0c\u4f4e\u7ee9\u6548\u5b66\u751f\u66f4\u4f9d\u8d56\u7f16\u8f91\u3002", "motivation": "\u4e86\u89e3\u5b66\u751f\u5728\u7f16\u7a0b\u4efb\u52a1\u4e2d\u5982\u4f55\u7ed3\u5408\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u548c\u624b\u52a8\u4ee3\u7801\u7f16\u8f91\uff0c\u4ee5\u53ca\u8fd9\u79cd\u4f7f\u7528\u65b9\u5f0f\u5982\u4f55\u968f\u4efb\u52a1\u590d\u6742\u5ea6\u548c\u5b66\u751f\u80fd\u529b\u53d8\u5316\u3002", "method": "\u5728\u5165\u95e8\u7f16\u7a0b\u8bfe\u7a0b\u4e2d\u8fdb\u884c\u5927\u89c4\u6a21\u7814\u7a76\uff0c\u6536\u96c6355\u540d\u5b66\u751f\u57283\u5929\u5b9e\u9a8c\u5ba4\u6d3b\u52a8\u4e2d\u768413,305\u6b21\u4ea4\u4e92\u6570\u636e\u3002", "result": "\u5b66\u751f\u4e3b\u8981\u7528\u63d0\u793a\u751f\u6210\u521d\u59cb\u65b9\u6848\uff0c\u901a\u8fc7\u7f16\u8f91-\u8fd0\u884c\u5faa\u73af\u5b8c\u5584\u4ee3\u7801\uff1b\u4efb\u52a1\u8d8a\u590d\u6742\u7f16\u8f91\u8d8a\u9891\u7e41\uff1b\u9ad8\u7ee9\u6548\u5b66\u751f\u66f4\u4f9d\u8d56\u63d0\u793a\u6210\u529f\uff0c\u4f4e\u7ee9\u6548\u5b66\u751f\u66f4\u4f9d\u8d56\u7f16\u8f91\u3002", "conclusion": "\u624b\u52a8\u7f16\u8f91\u662fAI\u8f85\u52a9\u7f16\u7a0b\u5de5\u4f5c\u6d41\u4e2d\u4f5c\u4e3a\u6700\u540e\u4fee\u590d\u7b56\u7565\u7684\u91cd\u8981\u8865\u5145\uff0c\u63d0\u793a\u6709\u52a9\u4e8e\u6784\u5efa\u89e3\u51b3\u65b9\u6848\uff0c\u7f16\u8f91\u9002\u5408\u9488\u5bf9\u6027\u4fee\u6b63\uff0c\u4e24\u8005\u90fd\u5bf9\u5b66\u4e60\u6709\u76ca\u3002"}}
{"id": "2509.13985", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.13985", "abs": "https://arxiv.org/abs/2509.13985", "authors": ["Yixun Wen", "Yulong Gao", "Boli Chen"], "title": "Distributionally Robust Equilibria over the Wasserstein Distance for Generalized Nash Game", "comment": null, "summary": "Generalized Nash equilibrium problem (GNEP) is fundamental for practical\napplications where multiple self-interested agents work together to make\noptimal decisions. In this work, we study GNEP with shared distributionally\nrobust chance constraints (DRCCs) for incorporating inevitable uncertainties.\nThe DRCCs are defined over the Wasserstein ball, which can be explicitly\ncharacterized even with limited sample data. To determine the equilibrium of\nthe GNEP, we propose an exact approach to transform the original\ncomputationally intractable problem into a deterministic formulation using the\nNikaido-Isoda function. Specifically, we show that when all agents' objectives\nare quadratic in their respective variables, the equilibrium can be obtained by\nsolving a typical mixed-integer nonlinear programming (MINLP) problem, where\nthe integer and continuous variables are decoupled in both the objective\nfunction and the constraints. This structure significantly improves\ncomputational tractability, as demonstrated through a case study on the\ncharging station pricing problem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6c42\u89e3\u5e26\u6709Wasserstein\u5206\u5e03\u9c81\u68d2\u673a\u4f1a\u7ea6\u675f\u7684\u5e7f\u4e49\u7eb3\u4ec0\u5747\u8861\u95ee\u9898\u7684\u7cbe\u786e\u65b9\u6cd5\uff0c\u901a\u8fc7Nikaido-Isoda\u51fd\u6570\u5c06\u539f\u95ee\u9898\u8f6c\u5316\u4e3a\u786e\u5b9a\u6027\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u53ef\u884c\u6027\u3002", "motivation": "\u5e7f\u4e49\u7eb3\u4ec0\u5747\u8861\u95ee\u9898\u5728\u591a\u4e2a\u81ea\u5229\u4e3b\u4f53\u534f\u540c\u51b3\u7b56\u4e2d\u5177\u6709\u57fa\u7840\u91cd\u8981\u6027\uff0c\u4f46\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u65f6\u8ba1\u7b97\u56f0\u96be\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u5206\u5e03\u9c81\u68d2\u673a\u4f1a\u7ea6\u675f\u7684\u6709\u6548\u6c42\u89e3\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528Nikaido-Isoda\u51fd\u6570\u5c06\u539f\u95ee\u9898\u8f6c\u5316\u4e3a\u786e\u5b9a\u6027\u5f62\u5f0f\uff0c\u5f53\u6240\u6709\u4e3b\u4f53\u76ee\u6807\u51fd\u6570\u4e3a\u4e8c\u6b21\u578b\u65f6\uff0c\u53ef\u8f6c\u5316\u4e3a\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u95ee\u9898\uff0c\u5176\u4e2d\u6574\u6570\u53d8\u91cf\u548c\u8fde\u7eed\u53d8\u91cf\u5728\u76ee\u6807\u51fd\u6570\u548c\u7ea6\u675f\u4e2d\u89e3\u8026\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u5145\u7535\u7ad9\u5b9a\u4ef7\u95ee\u9898\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5904\u7406\u5e26\u6709\u5206\u5e03\u9c81\u68d2\u673a\u4f1a\u7ea6\u675f\u7684\u5e7f\u4e49\u7eb3\u4ec0\u5747\u8861\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u76ee\u6807\u51fd\u6570\u4e3a\u4e8c\u6b21\u578b\u7684\u60c5\u51b5\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.13666", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13666", "abs": "https://arxiv.org/abs/2509.13666", "authors": ["Zhenqi Wu", "Abhinav Modi", "Angelos Mavrogiannis", "Kaustubh Joshi", "Nikhil Chopra", "Yiannis Aloimonos", "Nare Karapetyan", "Ioannis Rekleitis", "Xiaomin Lin"], "title": "DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring", "comment": "submitted to ICRA 2026", "summary": "The ocean is warming and acidifying, increasing the risk of mass mortality\nevents for temperature-sensitive shellfish such as oysters. This motivates the\ndevelopment of long-term monitoring systems. However, human labor is costly and\nlong-duration underwater work is highly hazardous, thus favoring robotic\nsolutions as a safer and more efficient option. To enable underwater robots to\nmake real-time, environment-aware decisions without human intervention, we must\nequip them with an intelligent \"brain.\" This highlights the need for\npersistent,wide-area, and low-cost benthic monitoring. To this end, we present\nDREAM, a Vision Language Model (VLM)-guided autonomy framework for long-term\nunderwater exploration and habitat monitoring. The results show that our\nframework is highly efficient in finding and exploring target objects (e.g.,\noysters, shipwrecks) without prior location information. In the\noyster-monitoring task, our framework takes 31.5% less time than the previous\nbaseline with the same amount of oysters. Compared to the vanilla VLM, it uses\n23% fewer steps while covering 8.88% more oysters. In shipwreck scenes, our\nframework successfully explores and maps the wreck without collisions,\nrequiring 27.5% fewer steps than the vanilla model and achieving 100% coverage,\nwhile the vanilla model achieves 60.23% average coverage in our shipwreck\nenvironments.", "AI": {"tldr": "DREAM\u662f\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u4e3b\u6846\u67b6\uff0c\u7528\u4e8e\u957f\u671f\u6c34\u4e0b\u63a2\u7d22\u548c\u6816\u606f\u5730\u76d1\u6d4b\uff0c\u5728\u7261\u86ce\u76d1\u6d4b\u548c\u6c89\u8239\u63a2\u7d22\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u8986\u76d6\u7387\u3002", "motivation": "\u6d77\u6d0b\u53d8\u6696\u548c\u9178\u5316\u589e\u52a0\u4e86\u6e29\u5ea6\u654f\u611f\u8d1d\u7c7b\uff08\u5982\u7261\u86ce\uff09\u5927\u89c4\u6a21\u6b7b\u4ea1\u4e8b\u4ef6\u7684\u98ce\u9669\uff0c\u9700\u8981\u5f00\u53d1\u957f\u671f\u76d1\u6d4b\u7cfb\u7edf\u3002\u4eba\u5de5\u6210\u672c\u9ad8\u4e14\u6c34\u4e0b\u4f5c\u4e1a\u5371\u9669\uff0c\u56e0\u6b64\u9700\u8981\u673a\u5668\u4eba\u89e3\u51b3\u65b9\u6848\u6765\u5b9e\u73b0\u5b9e\u65f6\u3001\u73af\u5883\u611f\u77e5\u7684\u81ea\u4e3b\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u4e86DREAM\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u81ea\u4e3b\u7cfb\u7edf\uff0c\u7528\u4e8e\u957f\u671f\u6c34\u4e0b\u63a2\u7d22\u548c\u6816\u606f\u5730\u76d1\u6d4b\uff0c\u65e0\u9700\u5148\u9a8c\u4f4d\u7f6e\u4fe1\u606f\u5373\u53ef\u5bfb\u627e\u548c\u63a2\u7d22\u76ee\u6807\u7269\u4f53\u3002", "result": "\u5728\u7261\u86ce\u76d1\u6d4b\u4efb\u52a1\u4e2d\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u8282\u770131.5%\u65f6\u95f4\uff0c\u6bd4\u666e\u901aVLM\u51cf\u5c1123%\u6b65\u9aa4\u540c\u65f6\u8986\u76d6\u66f4\u591a\u7261\u86ce\uff088.88%\uff09\u3002\u5728\u6c89\u8239\u573a\u666f\u4e2d\uff0c\u5b9e\u73b0100%\u8986\u76d6\u4e14\u65e0\u78b0\u649e\uff0c\u6bd4\u666e\u901aVLM\u51cf\u5c1127.5%\u6b65\u9aa4\uff08\u666e\u901aVLM\u5e73\u5747\u8986\u76d6\u7387\u4e3a60.23%\uff09\u3002", "conclusion": "DREAM\u6846\u67b6\u4e3a\u6c34\u4e0b\u957f\u671f\u76d1\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u81ea\u4e3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u76ee\u6807\u63a2\u6d4b\u6548\u7387\u548c\u8986\u76d6\u7387\uff0c\u4e3a\u6d77\u6d0b\u751f\u6001\u76d1\u6d4b\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2509.13615", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13615", "abs": "https://arxiv.org/abs/2509.13615", "authors": ["Zongru Wu", "Rui Mao", "Zhiyuan Tian", "Pengzhou Cheng", "Tianjie Ju", "Zheng Wu", "Lingzhong Dong", "Haiyue Sheng", "Zhuosheng Zhang", "Gongshen Liu"], "title": "See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles", "comment": null, "summary": "The advent of multimodal agents facilitates effective interaction within\ngraphical user interface (GUI), especially in ubiquitous GUI control. However,\ntheir inability to reliably execute toggle control instructions remains a key\nbottleneck. To investigate this, we construct a state control benchmark with\nbinary toggle instructions from public datasets. Evaluations of existing agents\ndemonstrate their unreliability, particularly when the current toggle state\nalready matches the desired state. To address the challenge, we propose\nState-aware Reasoning (StaR), a training method that teaches agents to perceive\nthe current toggle state, analyze the desired state from the instruction, and\nact accordingly. Experiments on three multimodal agents demonstrate that StaR\ncan improve toggle instruction execution accuracy by over 30\\%. Further\nevaluations on three public benchmarks show that StaR also enhances general\ntask performance. Finally, evaluations on a dynamic environment highlight the\npotential of StaR for real-world applications. Code, benchmark, and\nStaR-enhanced agents are available at https://github.com/ZrW00/StaR.", "AI": {"tldr": "\u63d0\u51fa\u4e86State-aware Reasoning (StaR)\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u611f\u77e5\u5f53\u524d\u5207\u6362\u72b6\u6001\u3001\u5206\u6790\u6307\u4ee4\u671f\u671b\u72b6\u6001\u6765\u63d0\u5347\u591a\u6a21\u6001\u4ee3\u7406\u5728GUI\u5207\u6362\u63a7\u5236\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u51c6\u786e\u7387\u63d0\u5347\u8d85\u8fc730%", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u4ee3\u7406\u5728\u56fe\u5f62\u7528\u6237\u754c\u9762(GUI)\u5207\u6362\u63a7\u5236\u4e2d\u53ef\u9760\u6027\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u5f53\u524d\u72b6\u6001\u4e0e\u671f\u671b\u72b6\u6001\u4e00\u81f4\u65f6\u65e0\u6cd5\u6b63\u786e\u6267\u884c\u5207\u6362\u6307\u4ee4", "method": "\u6784\u5efa\u72b6\u6001\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u63d0\u51faStaR\u8bad\u7ec3\u65b9\u6cd5\uff0c\u6559\u5bfc\u4ee3\u7406\u611f\u77e5\u5f53\u524d\u5207\u6362\u72b6\u6001\u3001\u5206\u6790\u6307\u4ee4\u671f\u671b\u72b6\u6001\u5e76\u76f8\u5e94\u6267\u884c\u52a8\u4f5c", "result": "\u5728\u4e09\u4e2a\u591a\u6a21\u6001\u4ee3\u7406\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0cStaR\u53ef\u5c06\u5207\u6362\u6307\u4ee4\u6267\u884c\u51c6\u786e\u7387\u63d0\u5347\u8d85\u8fc730%\uff0c\u5728\u4e09\u4e2a\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e5f\u63d0\u5347\u4e86\u901a\u7528\u4efb\u52a1\u6027\u80fd", "conclusion": "StaR\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86GUI\u5207\u6362\u63a7\u5236\u95ee\u9898\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5c55\u73b0\u51fa\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u4ee3\u7801\u548c\u57fa\u51c6\u6d4b\u8bd5\u96c6\u5df2\u5f00\u6e90"}}
{"id": "2509.14189", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2509.14189", "abs": "https://arxiv.org/abs/2509.14189", "authors": ["Sebastian Porsdam Mann", "Mateo Aboy", "Joel Jiehao Seah", "Zhicheng Lin", "Xufei Luo", "Dan Rodger", "Hazem Zohny", "Timo Minssen", "Julian Savulescu", "Brian D. Earp"], "title": "AI and the Future of Academic Peer Review", "comment": "34 pages", "summary": "Peer review remains the central quality-control mechanism of science, yet its\nability to fulfill this role is increasingly strained. Empirical studies\ndocument serious shortcomings: long publication delays, escalating reviewer\nburden concentrated on a small minority of scholars, inconsistent quality and\nlow inter-reviewer agreement, and systematic biases by gender, language, and\ninstitutional prestige. Decades of human-centered reforms have yielded only\nmarginal improvements. Meanwhile, artificial intelligence, especially large\nlanguage models (LLMs), is being piloted across the peer-review pipeline by\njournals, funders, and individual reviewers. Early studies suggest that AI\nassistance can produce reviews comparable in quality to humans, accelerate\nreviewer selection and feedback, and reduce certain biases, but also raise\ndistinctive concerns about hallucination, confidentiality, gaming, novelty\nrecognition, and loss of trust. In this paper, we map the aims and persistent\nfailure modes of peer review to specific LLM applications and systematically\nanalyze the objections they raise alongside safeguards that could make their\nuse acceptable. Drawing on emerging evidence, we show that targeted, supervised\nLLM assistance can plausibly improve error detection, timeliness, and reviewer\nworkload without displacing human judgment. We highlight advanced\narchitectures, including fine-tuned, retrieval-augmented, and multi-agent\nsystems, that may enable more reliable, auditable, and interdisciplinary\nreview. We argue that ethical and practical considerations are not peripheral\nbut constitutive: the legitimacy of AI-assisted peer review depends on\ngovernance choices as much as technical capacity. The path forward is neither\nuncritical adoption nor reflexive rejection, but carefully scoped pilots with\nexplicit evaluation metrics, transparency, and accountability.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\uff08\u5c24\u5176\u662f\u5927\u8bed\u8a00\u6a21\u578b\uff09\u5728\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5206\u6790\u4e86\u73b0\u6709\u8bc4\u5ba1\u7cfb\u7edf\u7684\u7f3a\u9677\u4ee5\u53caAI\u8f85\u52a9\u8bc4\u5ba1\u7684\u4f18\u52bf\u4e0e\u98ce\u9669\uff0c\u63d0\u51fa\u4e86\u6709\u76d1\u7763\u7684LLM\u8f85\u52a9\u65b9\u6848\u6765\u6539\u5584\u8bc4\u5ba1\u8d28\u91cf\u3001\u65f6\u6548\u6027\u548c\u5de5\u4f5c\u91cf\u3002", "motivation": "\u540c\u884c\u8bc4\u5ba1\u4f5c\u4e3a\u79d1\u5b66\u8d28\u91cf\u7684\u6838\u5fc3\u63a7\u5236\u673a\u5236\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff1a\u51fa\u7248\u5ef6\u8fdf\u957f\u3001\u8bc4\u5ba1\u8d1f\u62c5\u96c6\u4e2d\u3001\u8bc4\u5ba1\u8d28\u91cf\u4e0d\u4e00\u81f4\u3001\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1\u7b49\u3002\u4f20\u7edf\u6539\u9769\u6548\u679c\u6709\u9650\uff0c\u800cAI\u6280\u672f\u4e3a\u6539\u8fdb\u8bc4\u5ba1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "method": "\u901a\u8fc7\u5c06\u540c\u884c\u8bc4\u5ba1\u7684\u76ee\u6807\u548c\u6301\u7eed\u5931\u8d25\u6a21\u5f0f\u6620\u5c04\u5230\u7279\u5b9a\u7684LLM\u5e94\u7528\uff0c\u7cfb\u7edf\u5206\u6790AI\u8f85\u52a9\u8bc4\u5ba1\u7684\u53cd\u5bf9\u610f\u89c1\u548c\u53ef\u80fd\u7684\u4fdd\u969c\u63aa\u65bd\u3002\u57fa\u4e8e\u65b0\u5174\u8bc1\u636e\uff0c\u63a2\u8ba8\u4e86\u9488\u5bf9\u6027\u3001\u6709\u76d1\u7763\u7684LLM\u8f85\u52a9\u65b9\u6848\uff0c\u5305\u62ec\u5fae\u8c03\u3001\u68c0\u7d22\u589e\u5f3a\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7b49\u5148\u8fdb\u67b6\u6784\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6709\u76d1\u7763\u7684LLM\u8f85\u52a9\u53ef\u4ee5\u5728\u4e0d\u53d6\u4ee3\u4eba\u7c7b\u5224\u65ad\u7684\u60c5\u51b5\u4e0b\uff0c\u5408\u7406\u6539\u8fdb\u9519\u8bef\u68c0\u6d4b\u3001\u53ca\u65f6\u6027\u548c\u8bc4\u5ba1\u5de5\u4f5c\u91cf\u3002\u9ad8\u7ea7\u67b6\u6784\u53ef\u80fd\u5b9e\u73b0\u66f4\u53ef\u9760\u3001\u53ef\u5ba1\u8ba1\u548c\u8de8\u5b66\u79d1\u7684\u8bc4\u5ba1\u3002", "conclusion": "AI\u8f85\u52a9\u540c\u884c\u8bc4\u5ba1\u7684\u5408\u6cd5\u6027\u65e2\u53d6\u51b3\u4e8e\u6280\u672f\u80fd\u529b\uff0c\u4e5f\u53d6\u51b3\u4e8e\u6cbb\u7406\u9009\u62e9\u3002\u524d\u8fdb\u7684\u9053\u8def\u65e2\u4e0d\u662f\u4e0d\u52a0\u6279\u5224\u7684\u91c7\u7eb3\uff0c\u4e5f\u4e0d\u662f\u53cd\u5c04\u6027\u7684\u62d2\u7edd\uff0c\u800c\u662f\u5177\u6709\u660e\u786e\u8bc4\u4f30\u6307\u6807\u3001\u900f\u660e\u5ea6\u548c\u95ee\u8d23\u5236\u7684\u8c28\u614e\u8bd5\u70b9\u9879\u76ee\u3002"}}
{"id": "2509.13994", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.13994", "abs": "https://arxiv.org/abs/2509.13994", "authors": ["Giacomo Bastianel", "Dirk Van Hertem", "Hakan Ergun", "Line Roald"], "title": "Day-Ahead Transmission Grid Topology Optimization Considering Renewable Energy Sources' Uncertainty", "comment": null, "summary": "The increasing renewable penetration introduces significant uncertainty in\npower system operations. At the same time, the existing transmission grid is\noften already congested, and urgently needed reinforcements are frequently\ndelayed due to several constraints. To address these challenges, adjusting the\ngrid topology based on congestion patterns is considered a non-costly remedy to\nguarantee efficient power transmission. Based on this idea, this paper proposes\na grid topology optimization model combining optimal transmission switching and\nbusbar splitting for AC and hybrid AC/DC grids. The methodology incorporates\nRES forecast uncertainty through a scenario-based stochastic optimization\napproach, using real offshore wind data and K-means clustering to generate\nrepresentative forecast error scenarios. The proposed model includes several\nformulations to be compared with a plain optimal power flow (OPF) model: hourly\noptimizing the topology, one topology for 24 hours, or a limited number of\nswitching actions over a day. The grid topology optimization model is\nformulated as a Mixed-Integer Quadratic Convex Problem, optimized based on the\nday-ahead (D-1) RES forecast and validated for AC-feasibility via an AC-OPF\nformulation. Based on the generation setpoints of the feasibility check, a\nredispatch simulation based on the measured (D) RES realization is then\ncomputed. The methodology is tested on an AC 30-bus test case and a hybrid\nAC/DC 50-bus test case, for a 24-hours (30-bus) and a 14-days (both test cases)\ntime series. The results highlight the economic benefits brought by grid\ntopology optimization for congested test cases with high penetration of RES. In\naddition, the results demonstrate that accounting for RES uncertainty with at\nleast 6 to 8 scenarios leads to lower or comparable total costs to\ndeterministic day-ahead forecasts, even when limiting the frequency of\ntopological actions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6700\u4f18\u8f93\u7535\u5207\u6362\u548c\u6bcd\u7ebf\u5206\u88c2\u7684\u7535\u7f51\u62d3\u6251\u4f18\u5316\u6a21\u578b\uff0c\u901a\u8fc7\u968f\u673a\u4f18\u5316\u65b9\u6cd5\u5904\u7406\u53ef\u518d\u751f\u80fd\u6e90\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u62e5\u5835\u7535\u7f51\u4e2d\u5b9e\u73b0\u7ecf\u6d4e\u9ad8\u6548\u7684\u7535\u529b\u4f20\u8f93\u3002", "motivation": "\u53ef\u518d\u751f\u80fd\u6e90\u6e17\u900f\u7387\u589e\u52a0\u5e26\u6765\u7535\u529b\u7cfb\u7edf\u8fd0\u884c\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u73b0\u6709\u8f93\u7535\u7f51\u7edc\u7ecf\u5e38\u62e5\u5835\u4e14\u5347\u7ea7\u5ef6\u8fdf\uff0c\u9700\u8981\u4f4e\u6210\u672c\u89e3\u51b3\u65b9\u6848\u6765\u4fdd\u8bc1\u9ad8\u6548\u7535\u529b\u4f20\u8f93\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u573a\u666f\u7684\u968f\u673a\u4f18\u5316\u65b9\u6cd5\uff0c\u7ed3\u5408K-means\u805a\u7c7b\u751f\u6210\u4ee3\u8868\u6027\u9884\u6d4b\u8bef\u5dee\u573a\u666f\uff0c\u6784\u5efa\u6df7\u5408\u6574\u6570\u4e8c\u6b21\u51f8\u4f18\u5316\u95ee\u9898\u6a21\u578b\uff0c\u6bd4\u8f83\u4e0d\u540c\u62d3\u6251\u4f18\u5316\u7b56\u7565\u3002", "result": "\u5728AC 30\u603b\u7ebf\u548c\u6df7\u5408AC/DC 50\u603b\u7ebf\u6d4b\u8bd5\u6848\u4f8b\u4e2d\uff0c\u7535\u7f51\u62d3\u6251\u4f18\u5316\u5728\u62e5\u5835\u548c\u9ad8\u53ef\u518d\u751f\u80fd\u6e90\u6e17\u900f\u60c5\u51b5\u4e0b\u5e26\u6765\u7ecf\u6d4e\u6548\u76ca\uff0c6-8\u4e2a\u573a\u666f\u7684\u968f\u673a\u4f18\u5316\u6210\u672c\u4f4e\u4e8e\u6216\u7b49\u4e8e\u786e\u5b9a\u6027\u9884\u6d4b\u3002", "conclusion": "\u7535\u7f51\u62d3\u6251\u4f18\u5316\u662f\u89e3\u51b3\u62e5\u5835\u7535\u7f51\u4e2d\u53ef\u518d\u751f\u80fd\u6e90\u9ad8\u6e17\u900f\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u5e76\u901a\u8fc7\u968f\u673a\u4f18\u5316\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u7ecf\u6d4e\u6027\uff0c\u5373\u4f7f\u9650\u5236\u62d3\u6251\u64cd\u4f5c\u9891\u7387\u4e5f\u80fd\u4fdd\u6301\u4f18\u52bf\u3002"}}
{"id": "2509.13691", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13691", "abs": "https://arxiv.org/abs/2509.13691", "authors": ["Songhao Huang", "Yuwei Wu", "Guangyao Shi", "Gaurav S. Sukhatme", "Vijay Kumar"], "title": "SPAR: Scalable LLM-based PDDL Domain Generation for Aerial Robotics", "comment": null, "summary": "We investigate the problem of automatic domain generation for the Planning\nDomain Definition Language (PDDL) using Large Language Models (LLMs), with a\nparticular focus on unmanned aerial vehicle (UAV) tasks. Although PDDL is a\nwidely adopted standard in robotic planning, manually designing domains for\ndiverse applications such as surveillance, delivery, and inspection is\nlabor-intensive and error-prone, which hinders adoption and real-world\ndeployment. To address these challenges, we propose SPAR, a framework that\nleverages the generative capabilities of LLMs to automatically produce valid,\ndiverse, and semantically accurate PDDL domains from natural language input. To\nthis end, we first introduce a systematically formulated and validated UAV\nplanning dataset, consisting of ground-truth PDDL domains and associated\nproblems, each paired with detailed domain and action descriptions. Building on\nthis dataset, we design a prompting framework that generates high-quality PDDL\ndomains from language input. The generated domains are evaluated through syntax\nvalidation, executability, feasibility, and interpretability. Overall, this\nwork demonstrates that LLMs can substantially accelerate the creation of\ncomplex planning domains, providing a reproducible dataset and evaluation\npipeline that enables application experts without prior experience to leverage\nit for practical tasks and advance future research in aerial robotics and\nautomated planning.", "AI": {"tldr": "SPAR\u6846\u67b6\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u81ea\u52a8\u751f\u6210\u6709\u6548\u7684PDDL\u89c4\u5212\u9886\u57df\uff0c\u7279\u522b\u9488\u5bf9\u65e0\u4eba\u673a\u4efb\u52a1\uff0c\u89e3\u51b3\u4e86\u624b\u52a8\u8bbe\u8ba1\u9886\u57df\u8017\u65f6\u6613\u9519\u7684\u95ee\u9898\u3002", "motivation": "PDDL\u662f\u673a\u5668\u4eba\u89c4\u5212\u4e2d\u5e7f\u6cdb\u91c7\u7528\u7684\u6807\u51c6\uff0c\u4f46\u4e3a\u4e0d\u540c\u5e94\u7528\uff08\u5982\u76d1\u89c6\u3001\u4ea4\u4ed8\u3001\u68c0\u67e5\uff09\u624b\u52a8\u8bbe\u8ba1\u9886\u57df\u65e2\u8d39\u65f6\u53c8\u5bb9\u6613\u51fa\u9519\uff0c\u8fd9\u963b\u788d\u4e86\u91c7\u7528\u548c\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u4e86SPAR\u6846\u67b6\uff0c\u5229\u7528LLM\u7684\u751f\u6210\u80fd\u529b\u4ece\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u81ea\u52a8\u751f\u6210PDDL\u9886\u57df\u3002\u9996\u5148\u521b\u5efa\u4e86\u7cfb\u7edf\u5236\u5b9a\u548c\u9a8c\u8bc1\u7684UAV\u89c4\u5212\u6570\u636e\u96c6\uff0c\u5305\u542b\u771f\u5b9ePDDL\u9886\u57df\u548c\u76f8\u5173\u95ee\u9898\uff0c\u6bcf\u4e2a\u90fd\u914d\u6709\u8be6\u7ec6\u7684\u9886\u57df\u548c\u52a8\u4f5c\u63cf\u8ff0\u3002\u57fa\u4e8e\u6b64\u6570\u636e\u96c6\u8bbe\u8ba1\u4e86\u63d0\u793a\u6846\u67b6\u6765\u751f\u6210\u9ad8\u8d28\u91cfPDDL\u9886\u57df\u3002", "result": "\u751f\u6210\u7684\u9886\u57df\u901a\u8fc7\u8bed\u6cd5\u9a8c\u8bc1\u3001\u53ef\u6267\u884c\u6027\u3001\u53ef\u884c\u6027\u548c\u53ef\u89e3\u91ca\u6027\u8fdb\u884c\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660eLLM\u80fd\u591f\u663e\u8457\u52a0\u901f\u590d\u6742\u89c4\u5212\u9886\u57df\u7684\u521b\u5efa\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u8bc1\u660e\u4e86LLM\u53ef\u4ee5\u5927\u5e45\u52a0\u901f\u590d\u6742\u89c4\u5212\u9886\u57df\u7684\u521b\u5efa\uff0c\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u7ba1\u9053\uff0c\u4f7f\u6ca1\u6709\u5148\u524d\u7ecf\u9a8c\u7684\u5e94\u7528\u4e13\u5bb6\u80fd\u591f\u5c06\u5176\u7528\u4e8e\u5b9e\u9645\u4efb\u52a1\uff0c\u5e76\u63a8\u52a8\u7a7a\u4e2d\u673a\u5668\u4eba\u548c\u81ea\u52a8\u5316\u89c4\u5212\u7684\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2509.13704", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13704", "abs": "https://arxiv.org/abs/2509.13704", "authors": ["Liangtao Lin", "Zhaomeng Zhu", "Tianwei Zhang", "Yonggang Wen"], "title": "InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management", "comment": null, "summary": "Mission-critical industrial infrastructure, such as data centers,\nincreasingly depends on complex management software. Its operations, however,\npose significant challenges due to the escalating system complexity,\nmulti-vendor integration, and a shortage of expert operators. While Robotic\nProcess Automation (RPA) offers partial automation through handcrafted scripts,\nit suffers from limited flexibility and high maintenance costs. Recent advances\nin Large Language Model (LLM)-based graphical user interface (GUI) agents have\nenabled more flexible automation, yet these general-purpose agents face five\ncritical challenges when applied to industrial management, including unfamiliar\nelement understanding, precision and efficiency, state localization, deployment\nconstraints, and safety requirements. To address these issues, we propose\nInfraMind, a novel exploration-based GUI agentic framework specifically\ntailored for industrial management systems. InfraMind integrates five\ninnovative modules to systematically resolve different challenges in industrial\nmanagement: (1) systematic search-based exploration with virtual machine\nsnapshots for autonomous understanding of complex GUIs; (2) memory-driven\nplanning to ensure high-precision and efficient task execution; (3) advanced\nstate identification for robust localization in hierarchical interfaces; (4)\nstructured knowledge distillation for efficient deployment with lightweight\nmodels; and (5) comprehensive, multi-layered safety mechanisms to safeguard\nsensitive operations. Extensive experiments on both open-source and commercial\nDCIM platforms demonstrate that our approach consistently outperforms existing\nframeworks in terms of task success rate and operational efficiency, providing\na rigorous and scalable solution for industrial management automation.", "AI": {"tldr": "InfraMind\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u5de5\u4e1a\u7ba1\u7406\u7cfb\u7edf\u8bbe\u8ba1\u7684GUI\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u63a2\u7d22\u3001\u8bb0\u5fc6\u89c4\u5212\u3001\u72b6\u6001\u8bc6\u522b\u3001\u77e5\u8bc6\u84b8\u998f\u548c\u591a\u5c42\u5b89\u5168\u673a\u5236\uff0c\u89e3\u51b3\u4e86LLM-based GUI\u4ee3\u7406\u5728\u5de5\u4e1a\u7ba1\u7406\u4e2d\u7684\u4e94\u5927\u6311\u6218\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u6210\u529f\u7387\u548c\u64cd\u4f5c\u6548\u7387\u3002", "motivation": "\u5de5\u4e1a\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u8f6f\u4ef6\u9762\u4e34\u7cfb\u7edf\u590d\u6742\u6027\u9ad8\u3001\u591a\u4f9b\u5e94\u5546\u96c6\u6210\u56f0\u96be\u3001\u4e13\u5bb6\u64cd\u4f5c\u5458\u77ed\u7f3a\u7b49\u6311\u6218\u3002\u73b0\u6709\u7684RPA\u81ea\u52a8\u5316\u65b9\u6848\u7075\u6d3b\u6027\u6709\u9650\u4e14\u7ef4\u62a4\u6210\u672c\u9ad8\uff0c\u800c\u901a\u7528LLM-based GUI\u4ee3\u7406\u5728\u5de5\u4e1a\u7ba1\u7406\u573a\u666f\u4e2d\u5b58\u5728\u5143\u7d20\u7406\u89e3\u4e0d\u719f\u6089\u3001\u7cbe\u5ea6\u6548\u7387\u4f4e\u3001\u72b6\u6001\u5b9a\u4f4d\u96be\u3001\u90e8\u7f72\u7ea6\u675f\u548c\u5b89\u5168\u8981\u6c42\u7b49\u4e94\u5927\u95ee\u9898\u3002", "method": "\u63d0\u51faInfraMind\u6846\u67b6\uff0c\u5305\u542b\u4e94\u4e2a\u521b\u65b0\u6a21\u5757\uff1a1\uff09\u57fa\u4e8e\u7cfb\u7edf\u641c\u7d22\u63a2\u7d22\u548c\u865a\u62df\u673a\u5feb\u7167\u7684\u81ea\u4e3bGUI\u7406\u89e3\uff1b2\uff09\u8bb0\u5fc6\u9a71\u52a8\u7684\u89c4\u5212\u786e\u4fdd\u9ad8\u7cbe\u5ea6\u9ad8\u6548\u4efb\u52a1\u6267\u884c\uff1b3\uff09\u9ad8\u7ea7\u72b6\u6001\u8bc6\u522b\u7528\u4e8e\u5c42\u6b21\u5316\u754c\u9762\u7684\u9c81\u68d2\u5b9a\u4f4d\uff1b4\uff09\u7ed3\u6784\u5316\u77e5\u8bc6\u84b8\u998f\u5b9e\u73b0\u8f7b\u91cf\u7ea7\u6a21\u578b\u9ad8\u6548\u90e8\u7f72\uff1b5\uff09\u591a\u5c42\u5b89\u5168\u673a\u5236\u4fdd\u62a4\u654f\u611f\u64cd\u4f5c\u3002", "result": "\u5728\u5f00\u6e90\u548c\u5546\u4e1aDCIM\u5e73\u53f0\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4efb\u52a1\u6210\u529f\u7387\u548c\u64cd\u4f5c\u6548\u7387\u65b9\u9762 consistently\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\u3002", "conclusion": "InfraMind\u4e3a\u5de5\u4e1a\u7ba1\u7406\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e25\u8c28\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM-based GUI\u4ee3\u7406\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2509.14047", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.14047", "abs": "https://arxiv.org/abs/2509.14047", "authors": ["Taiki Nakano", "Ahmed Aboudonia", "Jaap Eising", "Andrea Martinelli", "Florian D\u00f6rfler", "John Lygeros"], "title": "Dissipativity-Based Data-Driven Decentralized Control of Interconnected Systems", "comment": null, "summary": "We propose data-driven decentralized control algorithms for stabilizing\ninterconnected systems. We first derive a data-driven condition to synthesize a\nlocal controller that ensures the dissipativity of the local subsystems. Then,\nwe propose data-driven decentralized stability conditions for the global system\nbased on the dissipativity of each local system. Since both conditions take the\nform of linear matrix inequalities and are based on dissipativity theory, this\nyields a unified pipeline, resulting in a data-driven decentralized control\nalgorithm. As a special case, we also consider stabilizing systems\ninterconnected through diffusive coupling and propose a control algorithm. We\nvalidate the effectiveness and the scalability of the proposed control\nalgorithms in numerical examples in the context of microgrids.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u5206\u6563\u5f0f\u63a7\u5236\u7b97\u6cd5\uff0c\u901a\u8fc7\u8017\u6563\u6027\u7406\u8bba\u5b9e\u73b0\u4e92\u8054\u7cfb\u7edf\u7684\u7a33\u5b9a\u63a7\u5236\uff0c\u4f7f\u7528\u7ebf\u6027\u77e9\u9635\u4e0d\u7b49\u5f0f\u6761\u4ef6\uff0c\u5e76\u5728\u5fae\u7535\u7f51\u573a\u666f\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027", "motivation": "\u89e3\u51b3\u4e92\u8054\u7cfb\u7edf\u7684\u5206\u6563\u5f0f\u63a7\u5236\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u7cbe\u786e\u7684\u6570\u5b66\u6a21\u578b\uff0c\u800c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u53ef\u4ee5\u76f4\u63a5\u4ece\u7cfb\u7edf\u6570\u636e\u4e2d\u8bbe\u8ba1\u63a7\u5236\u5668\uff0c\u63d0\u9ad8\u5b9e\u7528\u6027\u548c\u9002\u5e94\u6027", "method": "\u9996\u5148\u63a8\u5bfc\u6570\u636e\u9a71\u52a8\u7684\u6761\u4ef6\u6765\u5408\u6210\u786e\u4fdd\u5c40\u90e8\u5b50\u7cfb\u7edf\u8017\u6563\u6027\u7684\u672c\u5730\u63a7\u5236\u5668\uff0c\u7136\u540e\u57fa\u4e8e\u5404\u5c40\u90e8\u7cfb\u7edf\u7684\u8017\u6563\u6027\u63d0\u51fa\u5168\u5c40\u7cfb\u7edf\u7684\u6570\u636e\u9a71\u52a8\u5206\u6563\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u4e24\u8005\u90fd\u91c7\u7528\u7ebf\u6027\u77e9\u9635\u4e0d\u7b49\u5f0f\u5f62\u5f0f", "result": "\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u6570\u636e\u9a71\u52a8\u5206\u6563\u63a7\u5236\u6d41\u7a0b\uff0c\u7279\u522b\u8003\u8651\u4e86\u6269\u6563\u8026\u5408\u4e92\u8054\u7cfb\u7edf\u7684\u7a33\u5b9a\u5316\uff0c\u5728\u5fae\u7535\u7f51\u6570\u503c\u793a\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4e92\u8054\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6570\u636e\u9a71\u52a8\u5206\u6563\u63a7\u5236\u89e3\u51b3\u65b9\u6848\uff0c\u57fa\u4e8e\u8017\u6563\u6027\u7406\u8bba\u548c\u7ebf\u6027\u77e9\u9635\u4e0d\u7b49\u5f0f\uff0c\u5177\u6709\u826f\u597d\u7684\u5b9e\u7528\u4ef7\u503c\u548c\u6269\u5c55\u6027"}}
{"id": "2509.13692", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13692", "abs": "https://arxiv.org/abs/2509.13692", "authors": ["Yadan Zeng", "Jiadong Zhou", "Xiaohan Li", "I-Ming Chen"], "title": "HGACNet: Hierarchical Graph Attention Network for Cross-Modal Point Cloud Completion", "comment": "9 pages, 6 figures", "summary": "Point cloud completion is essential for robotic perception, object\nreconstruction and supporting downstream tasks like grasp planning, obstacle\navoidance, and manipulation. However, incomplete geometry caused by\nself-occlusion and sensor limitations can significantly degrade downstream\nreasoning and interaction. To address these challenges, we propose HGACNet, a\nnovel framework that reconstructs complete point clouds of individual objects\nby hierarchically encoding 3D geometric features and fusing them with\nimage-guided priors from a single-view RGB image. At the core of our approach,\nthe Hierarchical Graph Attention (HGA) encoder adaptively selects critical\nlocal points through graph attention-based downsampling and progressively\nrefines hierarchical geometric features to better capture structural continuity\nand spatial relationships. To strengthen cross-modal interaction, we further\ndesign a Multi-Scale Cross-Modal Fusion (MSCF) module that performs\nattention-based feature alignment between hierarchical geometric features and\nstructured visual representations, enabling fine-grained semantic guidance for\ncompletion. In addition, we proposed the contrastive loss (C-Loss) to\nexplicitly align the feature distributions across modalities, improving\ncompletion fidelity under modality discrepancy. Finally, extensive experiments\nconducted on both the ShapeNet-ViPC benchmark and the YCB-Complete dataset\nconfirm the effectiveness of HGACNet, demonstrating state-of-the-art\nperformance as well as strong applicability in real-world robotic manipulation\ntasks.", "AI": {"tldr": "HGACNet\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u70b9\u4e91\u8865\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u56fe\u6ce8\u610f\u529b\u7f16\u7801\u5668\u548c\u591a\u5c3a\u5ea6\u8de8\u6a21\u6001\u878d\u5408\u6a21\u5757\uff0c\u7ed3\u5408\u5355\u89c6\u89d2RGB\u56fe\u50cf\u5f15\u5bfc\uff0c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u70b9\u4e91\u8865\u5168\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u70b9\u4e91\u8865\u5168\u5bf9\u4e8e\u673a\u5668\u4eba\u611f\u77e5\u3001\u7269\u4f53\u91cd\u5efa\u548c\u4e0b\u6e38\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u81ea\u906e\u6321\u548c\u4f20\u611f\u5668\u9650\u5236\u5bfc\u81f4\u7684\u4e0d\u5b8c\u6574\u51e0\u4f55\u4f53\u4f1a\u663e\u8457\u964d\u4f4e\u4e0b\u6e38\u63a8\u7406\u548c\u4ea4\u4e92\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u56fe\u6ce8\u610f\u529b\u7f16\u7801\u5668\u81ea\u9002\u5e94\u9009\u62e9\u5173\u952e\u5c40\u90e8\u70b9\uff0c\u591a\u5c3a\u5ea6\u8de8\u6a21\u6001\u878d\u5408\u6a21\u5757\u8fdb\u884c\u6ce8\u610f\u529b\u7279\u5f81\u5bf9\u9f50\uff0c\u5e76\u5f15\u5165\u5bf9\u6bd4\u635f\u5931\u6765\u663e\u5f0f\u5bf9\u9f50\u8de8\u6a21\u6001\u7279\u5f81\u5206\u5e03\u3002", "result": "\u5728ShapeNet-ViPC\u57fa\u51c6\u548cYCB-Complete\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u5b9e\u4e86HGACNet\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u4ee5\u53ca\u5728\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u5f3a\u9002\u7528\u6027\u3002", "conclusion": "HGACNet\u901a\u8fc7\u5206\u5c42\u51e0\u4f55\u7279\u5f81\u7f16\u7801\u548c\u56fe\u50cf\u5f15\u5bfc\u5148\u9a8c\u7684\u878d\u5408\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u70b9\u4e91\u8865\u5168\u95ee\u9898\uff0c\u4e3a\u673a\u5668\u4eba\u611f\u77e5\u548c\u64cd\u4f5c\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13761", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13761", "abs": "https://arxiv.org/abs/2509.13761", "authors": ["Qikai Chang", "Zhenrong Zhang", "Pengfei Hu", "Jiefeng Ma", "Yicheng Pan", "Jianshu Zhang", "Jun Du", "Quan Liu", "Jianqing Gao"], "title": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "comment": "22 pages, 13 figures", "summary": "Large Language Models (LLMs) have made remarkable progress in mathematical\nreasoning, but still continue to struggle with high-precision tasks like\nnumerical computation and formal symbolic manipulation. Integrating external\ntools has emerged as a promising approach to bridge this gap. Despite recent\nadvances, existing methods struggle with three key challenges: constructing\ntool-integrated reasoning data, performing fine-grained optimization, and\nenhancing inference. To overcome these limitations, we propose THOR\n(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,\na multi-agent actor-critic-based pipeline for constructing high-quality\ndatasets of tool-integrated reasoning paths, aligning with the policy and\ngeneralizing well across diverse models. Second, to perform fine-grained\nhierarchical optimization, we introduce an RL strategy that jointly optimizes\nfor both trajectory-level problem solving and step-level code generation. This\nis motivated by our key insight that the success of an intermediate tool call\nis a strong predictor of the final answer's correctness. Finally, THOR\nincorporates a self-correction mechanism that leverages immediate tool feedback\nto dynamically revise erroneous reasoning paths during inference. Our approach\ndemonstrates strong generalization across diverse models, performing\neffectively in both reasoning and non-reasoning models. It further achieves\nstate-of-the-art performance for models of a similar scale on multiple\nmathematical benchmarks, while also delivering consistent improvements on code\nbenchmarks. Our code will be publicly available at\nhttps://github.com/JingMog/THOR.", "AI": {"tldr": "THOR\u662f\u4e00\u4e2a\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u5de5\u5177\u96c6\u6210\u5c42\u6b21\u4f18\u5316\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u4e86LLMs\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u9ad8\u7cbe\u5ea6\u4efb\u52a1\uff08\u5982\u6570\u503c\u8ba1\u7b97\u548c\u7b26\u53f7\u64cd\u4f5c\uff09\u7684\u6311\u6218\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6570\u636e\u751f\u6210\u3001\u5206\u5c42\u4f18\u5316\u548c\u81ea\u6821\u6b63\u673a\u5236\uff0c\u5728\u591a\u4e2a\u6570\u5b66\u548c\u4ee3\u7801\u57fa\u51c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u9ad8\u7cbe\u5ea6\u4efb\u52a1\u5982\u6570\u503c\u8ba1\u7b97\u548c\u5f62\u5f0f\u7b26\u53f7\u64cd\u4f5c\u65b9\u9762\u4ecd\u5b58\u5728\u56f0\u96be\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u6784\u5efa\u5de5\u5177\u96c6\u6210\u63a8\u7406\u6570\u636e\u3001\u6267\u884c\u7ec6\u7c92\u5ea6\u4f18\u5316\u548c\u589e\u5f3a\u63a8\u7406\u65b9\u9762\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51faTHOR\u6846\u67b6\uff1a1) TIRGen\u591a\u667a\u80fd\u4f53actor-critic\u7ba1\u9053\u6784\u5efa\u9ad8\u8d28\u91cf\u5de5\u5177\u96c6\u6210\u63a8\u7406\u6570\u636e\u96c6\uff1b2) \u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u8054\u5408\u4f18\u5316\u8f68\u8ff9\u7ea7\u95ee\u9898\u89e3\u51b3\u548c\u6b65\u9aa4\u7ea7\u4ee3\u7801\u751f\u6210\uff1b3) \u81ea\u6821\u6b63\u673a\u5236\u5229\u7528\u5de5\u5177\u53cd\u9988\u52a8\u6001\u4fee\u6b63\u9519\u8bef\u63a8\u7406\u8def\u5f84\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u6a21\u578b\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u63a8\u7406\u548c\u975e\u63a8\u7406\u6a21\u578b\u4e2d\u90fd\u6709\u6548\u3002\u5728\u591a\u4e2a\u6570\u5b66\u57fa\u51c6\u4e0a\u8fbe\u5230\u76f8\u4f3c\u89c4\u6a21\u6a21\u578b\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u540c\u65f6\u5728\u4ee3\u7801\u57fa\u51c6\u4e0a\u4e5f\u5e26\u6765\u4e00\u81f4\u6539\u8fdb\u3002", "conclusion": "THOR\u901a\u8fc7\u5de5\u5177\u96c6\u6210\u3001\u5206\u5c42\u4f18\u5316\u548c\u81ea\u6821\u6b63\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLMs\u5728\u9ad8\u7cbe\u5ea6\u6570\u5b66\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5de5\u5177\u589e\u5f3a\u7684\u6570\u5b66\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14065", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.14065", "abs": "https://arxiv.org/abs/2509.14065", "authors": ["Jaidev Gill", "Jing Shuang Li"], "title": "Identifying Network Structure of Linear Dynamical Systems: Observability and Edge Misclassification", "comment": "7 pages, 5 figures, in submission", "summary": "This work studies the limitations of uniquely identifying a linear network's\ntopology from partial measurements of its nodes. We show that the set of\nnetworks that are consistent with the measurements are related through the\nnullspace of the observability matrix for the true network. In doing so, we\nillustrate how potentially many networks are fully consistent with the\nmeasurements despite having topologies that are structurally inconsistent with\neach other, an often neglected consideration in the design of topology\ninference methods. We then provide an aggregate characterization of the space\nof possible networks by analytically solving for the most structurally\ndissimilar network. We find that when observing over 6% of nodes in random\nnetwork models (e.g., Erd\\H{o}s-R\\'{e}nyi and Watts-Strogatz) the rate of edge\nmisclassification drops to ~1%. Extending this discussion, we construct a\nfamily of networks that keep measurements $\\epsilon$-\"close\" to each other, and\nconnect the identifiability of these networks to the spectral properties of an\naugmented observability Gramian.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4ece\u90e8\u5206\u8282\u70b9\u6d4b\u91cf\u4e2d\u552f\u4e00\u8bc6\u522b\u7ebf\u6027\u7f51\u7edc\u62d3\u6251\u7684\u5c40\u9650\u6027\uff0c\u53d1\u73b0\u8bb8\u591a\u7ed3\u6784\u4e0d\u4e00\u81f4\u7684\u7f51\u7edc\u53ef\u80fd\u4e0e\u6d4b\u91cf\u6570\u636e\u5b8c\u5168\u4e00\u81f4\uff0c\u5e76\u5206\u6790\u4e86\u53ef\u80fd\u7f51\u7edc\u7a7a\u95f4\u7684\u805a\u5408\u7279\u5f81\u3002", "motivation": "\u7814\u7a76\u7ebf\u6027\u7f51\u7edc\u62d3\u6251\u8bc6\u522b\u4e2d\u90e8\u5206\u6d4b\u91cf\u6570\u636e\u7684\u5c40\u9650\u6027\uff0c\u63ed\u793a\u73b0\u6709\u62d3\u6251\u63a8\u65ad\u65b9\u6cd5\u5f80\u5f80\u5ffd\u89c6\u7684\u7ed3\u6784\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u89c2\u6d4b\u77e9\u9635\u7684\u96f6\u7a7a\u95f4\u5206\u6790\u4e00\u81f4\u6027\u7f51\u7edc\u96c6\u5408\uff0c\u89e3\u6790\u6c42\u89e3\u7ed3\u6784\u6700\u4e0d\u76f8\u4f3c\u7f51\u7edc\uff0c\u6784\u5efa\u4fdd\u6301\u6d4b\u91cf\u03b5-\u63a5\u8fd1\u7684\u7f51\u7edc\u65cf\uff0c\u5e76\u8fde\u63a5\u53ef\u8bc6\u522b\u6027\u4e0e\u589e\u5e7f\u89c2\u6d4bGramian\u7684\u8c31\u7279\u6027\u3002", "result": "\u5728\u968f\u673a\u7f51\u7edc\u6a21\u578b\uff08\u5982Erd\u0151s-R\u00e9nyi\u548cWatts-Strogatz\uff09\u4e2d\uff0c\u5f53\u89c2\u6d4b\u8d85\u8fc76%\u7684\u8282\u70b9\u65f6\uff0c\u8fb9\u8bef\u5206\u7c7b\u7387\u964d\u81f3\u7ea61%\u3002", "conclusion": "\u7ebf\u6027\u7f51\u7edc\u62d3\u6251\u8bc6\u522b\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\uff0c\u90e8\u5206\u6d4b\u91cf\u4e0b\u591a\u4e2a\u7ed3\u6784\u4e0d\u540c\u7684\u7f51\u7edc\u53ef\u80fd\u4ea7\u751f\u76f8\u540c\u7684\u89c2\u6d4b\u6570\u636e\uff0c\u8fd9\u5bf9\u62d3\u6251\u63a8\u65ad\u65b9\u6cd5\u8bbe\u8ba1\u5177\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2509.13720", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13720", "abs": "https://arxiv.org/abs/2509.13720", "authors": ["Tianle Zeng", "Jianwei Peng", "Hanjing Ye", "Guangcheng Chen", "Senzi Luo", "Hong Zhang"], "title": "EZREAL: Enhancing Zero-Shot Outdoor Robot Navigation toward Distant Targets under Varying Visibility", "comment": "Page:https://tianlezeng.github.io/EzReal/", "summary": "Zero-shot object navigation (ZSON) in large-scale outdoor environments faces\nmany challenges; we specifically address a coupled one: long-range targets that\nreduce to tiny projections and intermittent visibility due to partial or\ncomplete occlusion. We present a unified, lightweight closed-loop system built\non an aligned multi-scale image tile hierarchy. Through hierarchical\ntarget-saliency fusion, it summarizes localized semantic contrast into a stable\ncoarse-layer regional saliency that provides the target direction and indicates\ntarget visibility. This regional saliency supports visibility-aware heading\nmaintenance through keyframe memory, saliency-weighted fusion of historical\nheadings, and active search during temporary invisibility. The system avoids\nwhole-image rescaling, enables deterministic bottom-up aggregation, supports\nzero-shot navigation, and runs efficiently on a mobile robot. Across simulation\nand real-world outdoor trials, the system detects semantic targets beyond 150m,\nmaintains a correct heading through visibility changes with 82.6% probability,\nand improves overall task success by 17.5% compared with the SOTA methods,\ndemonstrating robust ZSON toward distant and intermittently observable targets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6237\u5916\u96f6\u6837\u672c\u76ee\u6807\u5bfc\u822a\u7684\u7edf\u4e00\u8f7b\u91cf\u7ea7\u95ed\u73af\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u56fe\u50cf\u74e6\u7247\u5c42\u6b21\u7ed3\u6784\u548c\u5c42\u6b21\u5316\u76ee\u6807\u663e\u8457\u6027\u878d\u5408\uff0c\u89e3\u51b3\u4e86\u8fdc\u8ddd\u79bb\u76ee\u6807\u6295\u5f71\u8fc7\u5c0f\u548c\u95f4\u6b47\u6027\u906e\u6321\u7684\u6311\u6218\u3002", "motivation": "\u89e3\u51b3\u6237\u5916\u96f6\u6837\u672c\u76ee\u6807\u5bfc\u822a\u4e2d\u8fdc\u8ddd\u79bb\u76ee\u6807\u6295\u5f71\u8fc7\u5c0f\u548c\u56e0\u906e\u6321\u5bfc\u81f4\u7684\u95f4\u6b47\u6027\u53ef\u89c1\u6027\u95ee\u9898\uff0c\u8fd9\u4e9b\u6311\u6218\u4f7f\u5f97\u4f20\u7edf\u5bfc\u822a\u65b9\u6cd5\u96be\u4ee5\u7a33\u5b9a\u8ffd\u8e2a\u76ee\u6807\u3002", "method": "\u57fa\u4e8e\u5bf9\u9f50\u7684\u591a\u5c3a\u5ea6\u56fe\u50cf\u74e6\u7247\u5c42\u6b21\u7ed3\u6784\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u76ee\u6807\u663e\u8457\u6027\u878d\u5408\u5c06\u5c40\u90e8\u8bed\u4e49\u5bf9\u6bd4\u6c47\u603b\u4e3a\u7a33\u5b9a\u7684\u7c97\u5c42\u533a\u57df\u663e\u8457\u6027\uff0c\u63d0\u4f9b\u76ee\u6807\u65b9\u5411\u5e76\u6307\u793a\u76ee\u6807\u53ef\u89c1\u6027\u3002\u7cfb\u7edf\u91c7\u7528\u5173\u952e\u5e27\u8bb0\u5fc6\u3001\u663e\u8457\u6027\u52a0\u6743\u5386\u53f2\u822a\u5411\u878d\u5408\u548c\u5728\u6682\u65f6\u4e0d\u53ef\u89c1\u65f6\u4e3b\u52a8\u641c\u7d22\u6765\u5b9e\u73b0\u53ef\u89c1\u6027\u611f\u77e5\u7684\u822a\u5411\u7ef4\u6301\u3002", "result": "\u5728\u4eff\u771f\u548c\u771f\u5b9e\u6237\u5916\u8bd5\u9a8c\u4e2d\uff0c\u7cfb\u7edf\u80fd\u68c0\u6d4b150\u7c73\u4ee5\u5916\u7684\u8bed\u4e49\u76ee\u6807\uff0c\u5728\u53ef\u89c1\u6027\u53d8\u5316\u60c5\u51b5\u4e0b\u4ee582.6%\u7684\u6982\u7387\u7ef4\u6301\u6b63\u786e\u822a\u5411\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u6574\u4f53\u4efb\u52a1\u6210\u529f\u7387\u63d0\u9ad8\u4e8617.5%\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5b9e\u73b0\u4e86\u5bf9\u8fdc\u8ddd\u79bb\u548c\u95f4\u6b47\u6027\u53ef\u89c1\u76ee\u6807\u7684\u9c81\u68d2\u96f6\u6837\u672c\u5bfc\u822a\uff0c\u907f\u514d\u4e86\u6574\u56fe\u7f29\u653e\uff0c\u652f\u6301\u786e\u5b9a\u6027\u81ea\u4e0b\u800c\u4e0a\u805a\u5408\uff0c\u5e76\u80fd\u9ad8\u6548\u8fd0\u884c\u5728\u79fb\u52a8\u673a\u5668\u4eba\u4e0a\u3002"}}
{"id": "2509.13773", "categories": ["cs.AI", "cs.IR", "I.2.7; I.2.10"], "pdf": "https://arxiv.org/pdf/2509.13773", "abs": "https://arxiv.org/abs/2509.13773", "authors": ["Zhipeng Bian", "Jieming Zhu", "Xuyang Xie", "Quanyu Dai", "Zhou Zhao", "Zhenhua Dong"], "title": "MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation", "comment": "Published in Proceedings of the 63rd Annual Meeting of the\n  Association for Computational Linguistics (Volume 6: Industry Track), ACL\n  2025. Official version: https://doi.org/10.18653/v1/2025.acl-industry.103", "summary": "The rapid advancement of generative AI technologies is driving the\nintegration of diverse AI-powered services into smartphones, transforming how\nusers interact with their devices. To simplify access to predefined AI\nservices, this paper introduces MIRA, a pioneering framework for task\ninstruction recommendation that enables intuitive one-touch AI tasking on\nsmartphones. With MIRA, users can long-press on images or text objects to\nreceive contextually relevant instruction recommendations for executing AI\ntasks. Our work introduces three key innovations: 1) A multimodal large\nlanguage model (MLLM)-based recommendation pipeline with structured reasoning\nto extract key entities, infer user intent, and generate precise instructions;\n2) A template-augmented reasoning mechanism that integrates high-level\nreasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based\nconstrained decoding strategy that restricts outputs to predefined instruction\ncandidates, ensuring coherent and intent-aligned suggestions. Through\nevaluation using a real-world annotated datasets and a user study, MIRA has\ndemonstrated substantial improvements in the accuracy of instruction\nrecommendation. The encouraging results highlight MIRA's potential to\nrevolutionize the way users engage with AI services on their smartphones,\noffering a more seamless and efficient experience.", "AI": {"tldr": "MIRA\u662f\u4e00\u4e2a\u667a\u80fd\u624b\u673aAI\u4efb\u52a1\u6307\u4ee4\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u957f\u6309\u56fe\u50cf\u6216\u6587\u672c\u6765\u63d0\u4f9b\u4e0a\u4e0b\u6587\u76f8\u5173\u7684AI\u4efb\u52a1\u5efa\u8bae\uff0c\u4f7f\u7528MLLM\u548c\u7ed3\u6784\u5316\u63a8\u7406\u6765\u63d0\u9ad8\u63a8\u8350\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u667a\u80fd\u624b\u673a\u9700\u8981\u66f4\u76f4\u89c2\u7684\u65b9\u5f0f\u6765\u8bbf\u95ee\u9884\u5b9a\u4e49\u7684AI\u670d\u52a1\uff0c\u7b80\u5316\u7528\u6237\u4e0e\u8bbe\u5907\u7684\u4ea4\u4e92\u3002", "method": "\u91c7\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b(MLLM)\u63a8\u8350\u7ba1\u9053\u8fdb\u884c\u7ed3\u6784\u5316\u63a8\u7406\uff0c\u7ed3\u5408\u6a21\u677f\u589e\u5f3a\u63a8\u7406\u673a\u5236\u548c\u524d\u7f00\u6811\u7ea6\u675f\u89e3\u7801\u7b56\u7565\uff0c\u786e\u4fdd\u8f93\u51fa\u4e0e\u9884\u5b9a\u4e49\u6307\u4ee4\u5019\u9009\u4e00\u81f4\u3002", "result": "\u901a\u8fc7\u771f\u5b9e\u6807\u6ce8\u6570\u636e\u96c6\u548c\u7528\u6237\u7814\u7a76\u8bc4\u4f30\uff0cMIRA\u5728\u6307\u4ee4\u63a8\u8350\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u63d0\u5347\u3002", "conclusion": "MIRA\u6709\u6f5c\u529b\u5f7b\u5e95\u6539\u53d8\u7528\u6237\u5728\u667a\u80fd\u624b\u673a\u4e0a\u4e0eAI\u670d\u52a1\u7684\u4ea4\u4e92\u65b9\u5f0f\uff0c\u63d0\u4f9b\u66f4\u65e0\u7f1d\u548c\u9ad8\u6548\u7684\u4f53\u9a8c\u3002"}}
{"id": "2509.14106", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.14106", "abs": "https://arxiv.org/abs/2509.14106", "authors": ["Yudong Li", "Yirui Cong", "Shimin Wang", "Martin Guay", "Jiuxiang Dong"], "title": "Asymptotic Boundedness of Distributed Set-Membership Filtering", "comment": null, "summary": "Asymptotic boundedness is a crucial property of Distributed Set-Membership\nFiltering (DSMFing) that prevents the unbounded growth of the set estimates\ncaused by the wrapping effect. However, this important property remains\nunderinvestigated, compared to its noise-free and stochastic-noise\ncounterparts, i.e., the convergence of Distributed Observers (DOs) and the\nbounded error covariance of Distributed Kalman Filters (DKFs). This paper\nstudies the asymptotic boundedness of DSMFing for linear discrete-time systems.\nA novel concept, termed the Collective Observation-Information Tower (COIT), is\nintroduced to characterize the fundamental relationship between the structure\nof graphs and the set estimates, which enables the boundedness analysis.\nLeveraging the COIT, an easily verifiable sufficient condition for the\nasymptotic boundedness of linear DSMFing is established. Surprisingly, the\nsufficient condition generalizes the well-known collective detectability\ncondition for DOs and DKFs; it links DSMFs to existing distributed estimation\nmethods and reveals the unique characteristic of DSMFs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7ebf\u6027\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u5206\u5e03\u5f0f\u96c6\u5458\u6ee4\u6ce2\u7684\u6e10\u8fd1\u6709\u754c\u6027\uff0c\u63d0\u51fa\u4e86\u96c6\u4f53\u89c2\u6d4b\u4fe1\u606f\u5854\u6982\u5ff5\uff0c\u5efa\u7acb\u4e86\u6613\u4e8e\u9a8c\u8bc1\u7684\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u63ed\u793a\u4e86\u4e0e\u73b0\u6709\u5206\u5e03\u5f0f\u4f30\u8ba1\u65b9\u6cd5\u7684\u8054\u7cfb\u3002", "motivation": "\u5206\u5e03\u5f0f\u96c6\u5458\u6ee4\u6ce2\u7684\u6e10\u8fd1\u6709\u754c\u6027\u662f\u4e00\u4e2a\u5173\u952e\u4f46\u7814\u7a76\u4e0d\u8db3\u7684\u6027\u8d28\uff0c\u76f8\u6bd4\u65e0\u566a\u58f0\u548c\u968f\u673a\u566a\u58f0\u60c5\u51b5\u4e0b\u7684\u5206\u5e03\u5f0f\u89c2\u6d4b\u5668\u548c\u5361\u5c14\u66fc\u6ee4\u6ce2\uff0c\u8be5\u6027\u8d28\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u5f15\u5165\u4e86\u96c6\u4f53\u89c2\u6d4b\u4fe1\u606f\u5854\u6982\u5ff5\u6765\u5206\u6790\u56fe\u7ed3\u6784\u4e0e\u96c6\u5408\u4f30\u8ba1\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u57fa\u4e8e\u6b64\u5efa\u7acb\u4e86\u7ebf\u6027\u5206\u5e03\u5f0f\u96c6\u5458\u6ee4\u6ce2\u6e10\u8fd1\u6709\u754c\u6027\u7684\u5145\u5206\u6761\u4ef6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6613\u4e8e\u9a8c\u8bc1\u7684\u5145\u5206\u6761\u4ef6\uff0c\u8be5\u6761\u4ef6\u63a8\u5e7f\u4e86\u5206\u5e03\u5f0f\u89c2\u6d4b\u5668\u548c\u5361\u5c14\u66fc\u6ee4\u6ce2\u7684\u96c6\u4f53\u53ef\u68c0\u6d4b\u6027\u6761\u4ef6\uff0c\u63ed\u793a\u4e86\u5206\u5e03\u5f0f\u96c6\u5458\u6ee4\u6ce2\u7684\u72ec\u7279\u7279\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u5206\u5e03\u5f0f\u96c6\u5458\u6ee4\u6ce2\u6e10\u8fd1\u6709\u754c\u6027\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5c06\u5206\u5e03\u5f0f\u96c6\u5458\u6ee4\u6ce2\u4e0e\u73b0\u6709\u5206\u5e03\u5f0f\u4f30\u8ba1\u65b9\u6cd5\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u5de5\u5177\u548c\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2509.13731", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13731", "abs": "https://arxiv.org/abs/2509.13731", "authors": ["Jeongwoo Park", "Seabin Lee", "Changmin Park", "Wonjong Lee", "Changjoo Nam"], "title": "Reinforcement Learning for Robotic Insertion of Flexible Cables in Industrial Settings", "comment": null, "summary": "The industrial insertion of flexible flat cables (FFCs) into receptacles\npresents a significant challenge owing to the need for submillimeter precision\nwhen handling the deformable cables. In manufacturing processes, FFC insertion\nwith robotic manipulators often requires laborious human-guided trajectory\ngeneration. While Reinforcement Learning (RL) offers a solution to automate\nthis task without modeling complex properties of FFCs, the nondeterminism\ncaused by the deformability of FFCs requires significant efforts and time on\ntraining. Moreover, training directly in a real environment is dangerous as\nindustrial robots move fast and possess no safety measure. We propose an RL\nalgorithm for FFC insertion that leverages a foundation model-based real-to-sim\napproach to reduce the training time and eliminate the risk of physical damages\nto robots and surroundings. Training is done entirely in simulation, allowing\nfor random exploration without the risk of physical damages. Sim-to-real\ntransfer is achieved through semantic segmentation masks which leave only those\nvisual features relevant to the insertion tasks such as the geometric and\nspatial information of the cables and receptacles. To enhance generality, we\nuse a foundation model, Segment Anything Model 2 (SAM2). To eleminate human\nintervention, we employ a Vision-Language Model (VLM) to automate the initial\nprompting of SAM2 to find segmentation masks. In the experiments, our method\nexhibits zero-shot capabilities, which enable direct deployments to real\nenvironments without fine-tuning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u67d4\u6027\u6241\u5e73\u7535\u7f06(FFC)\u63d2\u5165\u4efb\u52a1\uff0c\u901a\u8fc7\u8bed\u4e49\u5206\u5272\u63a9\u7801\u5b9e\u73b0sim-to-real\u8fc1\u79fb\uff0c\u65e0\u9700\u771f\u5b9e\u73af\u5883\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u96f6\u6837\u672c\u90e8\u7f72\u3002", "motivation": "\u5de5\u4e1a\u673a\u5668\u4eba\u63d2\u5165\u67d4\u6027\u6241\u5e73\u7535\u7f06\u9700\u8981\u4e9a\u6beb\u7c73\u7ea7\u7cbe\u5ea6\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u4eba\u5de5\u5f15\u5bfc\u8f68\u8ff9\u751f\u6210\u3002\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u53ef\u4ee5\u81ea\u52a8\u5316\u6b64\u4efb\u52a1\uff0c\u4f46FFC\u7684\u53ef\u53d8\u5f62\u7279\u6027\u5bfc\u81f4\u8bad\u7ec3\u56f0\u96be\u4e14\u8017\u65f6\uff0c\u76f4\u63a5\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u8bad\u7ec3\u5b58\u5728\u5b89\u5168\u98ce\u9669\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684real-to-sim\u65b9\u6cd5\uff0c\u5728\u4eff\u771f\u73af\u5883\u4e2d\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002\u901a\u8fc7Segment Anything Model 2 (SAM2)\u751f\u6210\u8bed\u4e49\u5206\u5272\u63a9\u7801\uff0c\u4fdd\u7559\u7535\u7f06\u548c\u63d2\u5ea7\u76f8\u5173\u7684\u51e0\u4f55\u7a7a\u95f4\u4fe1\u606f\uff0c\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLM)\u81ea\u52a8\u751f\u6210SAM2\u7684\u521d\u59cb\u63d0\u793a\uff0c\u5b9e\u73b0\u5168\u81ea\u52a8\u5316\u3002", "result": "\u8be5\u65b9\u6cd5\u8868\u73b0\u51fa\u96f6\u6837\u672c\u80fd\u529b\uff0c\u53ef\u4ee5\u76f4\u63a5\u90e8\u7f72\u5230\u771f\u5b9e\u73af\u5883\u800c\u65e0\u9700\u5fae\u8c03\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8bad\u7ec3\u65f6\u95f4\u548c\u7269\u7406\u635f\u574f\u98ce\u9669\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86FFC\u63d2\u5165\u4efb\u52a1\u4e2d\u7684sim-to-real\u8fc1\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u57fa\u7840\u6a21\u578b\u548c\u8bed\u4e49\u5206\u5272\u6280\u672f\u5b9e\u73b0\u4e86\u5b89\u5168\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u8bad\u7ec3\u548c\u90e8\u7f72\u3002"}}
{"id": "2509.13880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13880", "abs": "https://arxiv.org/abs/2509.13880", "authors": ["Mingwei Zhang", "Zhenhao Gu", "Liangda Fang", "Cunjing Ge", "Ziliang Chen", "Zhao-Rong Lai", "Quanlong Guan"], "title": "An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques", "comment": null, "summary": "Linear constraints are one of the most fundamental constraints in fields such\nas computer science, operations research and optimization. Many applications\nreduce to the task of model counting over integer linear constraints (MCILC).\nIn this paper, we design an exact approach to MCILC based on an exhaustive DPLL\narchitecture. To improve the efficiency, we integrate several effective\nsimplification techniques from mixed integer programming into the architecture.\nWe compare our approach to state-of-the-art MCILC counters and propositional\nmodel counters on 2840 random and 4131 application benchmarks. Experimental\nresults show that our approach significantly outperforms all exact methods in\nrandom benchmarks solving 1718 instances while the state-of-the-art approach\nonly computes 1470 instances. In addition, our approach is the only approach to\nsolve all 4131 application instances.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eDPLL\u67b6\u6784\u7684\u7cbe\u786e\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u6a21\u578b\u8ba1\u6570\u65b9\u6cd5\uff0c\u96c6\u6210\u6df7\u5408\u6574\u6570\u89c4\u5212\u7b80\u5316\u6280\u672f\uff0c\u5728\u968f\u673a\u548c\u5e94\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u6a21\u578b\u8ba1\u6570(MCILC)\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u8fd0\u7b79\u5b66\u548c\u4f18\u5316\u9886\u57df\u7684\u57fa\u7840\u95ee\u9898\uff0c\u8bb8\u591a\u5e94\u7528\u90fd\u9700\u8981\u89e3\u51b3\u6b64\u7c7b\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u7cbe\u786e\u8ba1\u7b97\u65b9\u6cd5", "method": "\u57fa\u4e8e\u8be6\u5c3d\u7684DPLL\u67b6\u6784\u8bbe\u8ba1\u7cbe\u786eMCILC\u65b9\u6cd5\uff0c\u96c6\u6210\u6df7\u5408\u6574\u6570\u7f16\u7a0b\u4e2d\u7684\u6709\u6548\u7b80\u5316\u6280\u672f\u6765\u63d0\u9ad8\u6548\u7387", "result": "\u57282840\u4e2a\u968f\u673a\u57fa\u51c6\u548c4131\u4e2a\u5e94\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u65b0\u65b9\u6cd5\u89e3\u51b31718\u4e2a\u968f\u673a\u5b9e\u4f8b\uff08\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u4ec51470\u4e2a\uff09\uff0c\u662f\u552f\u4e00\u80fd\u89e3\u51b3\u6240\u67094131\u4e2a\u5e94\u7528\u5b9e\u4f8b\u7684\u65b9\u6cd5", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eDPLL\u67b6\u6784\u5e76\u96c6\u6210\u6df7\u5408\u6574\u6570\u89c4\u5212\u7b80\u5316\u6280\u672f\u7684\u65b9\u6cd5\u5728MCILC\u95ee\u9898\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cbe\u786e\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5e94\u7528\u5b9e\u4f8b\u4e0a\u8868\u73b0\u5353\u8d8a"}}
{"id": "2509.14121", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.14121", "abs": "https://arxiv.org/abs/2509.14121", "authors": ["Marco A. Gomez", "Christopher D. Cruz-Ancona"], "title": "Safe Sliding Mode Control in Position for Double Integrator Systems", "comment": "6 pages, 3 figures, accepted at 2025 22 th International Conference\n  on Electrical Engineering, Computing Science and Automatic Control", "summary": "We address the problem of robust safety control design for double integrator\nsystems. We show that, when the constraints are defined only on position\nstates, it is possible to construct a safe sliding domain from the dynamic of a\nsimple integrator that is already safe. On this domain, the closed-loop\ntrajectories remain robust and safe against uncertainties and disturbances.\nFurthermore, we design a controller gain that guarantees convergence to the\nsafe sliding domain while avoiding the given unsafe set. The concept is\ninitially developed for first-order sliding mode and is subsequently\ngeneralized to an adaptive framework, ensuring that trajectories remain\nconfined to a predefined vicinity of the sliding domain, outside the unsafe\nregion.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9488\u5bf9\u53cc\u79ef\u5206\u5668\u7cfb\u7edf\u7684\u9c81\u68d2\u5b89\u5168\u63a7\u5236\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u5b89\u5168\u6ed1\u52a8\u57df\u786e\u4fdd\u7cfb\u7edf\u5728\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u548c\u6270\u52a8\u65f6\u4fdd\u6301\u5b89\u5168", "motivation": "\u89e3\u51b3\u53cc\u79ef\u5206\u5668\u7cfb\u7edf\u5728\u4ec5\u4f4d\u7f6e\u72b6\u6001\u7ea6\u675f\u4e0b\u7684\u9c81\u68d2\u5b89\u5168\u63a7\u5236\u95ee\u9898\uff0c\u786e\u4fdd\u7cfb\u7edf\u8f68\u8ff9\u5728\u4e0d\u786e\u5b9a\u6027\u548c\u6270\u52a8\u4e0b\u4ecd\u80fd\u4fdd\u6301\u5b89\u5168", "method": "\u4ece\u7b80\u5355\u79ef\u5206\u5668\u7684\u5b89\u5168\u52a8\u6001\u6784\u5efa\u5b89\u5168\u6ed1\u52a8\u57df\uff0c\u8bbe\u8ba1\u63a7\u5236\u5668\u589e\u76ca\u4fdd\u8bc1\u6536\u655b\u5230\u5b89\u5168\u6ed1\u52a8\u57df\u5e76\u907f\u5f00\u4e0d\u5b89\u5168\u96c6\uff0c\u65b9\u6cd5\u4ece\u4e00\u9636\u6ed1\u6a21\u6269\u5c55\u5230\u81ea\u9002\u5e94\u6846\u67b6", "result": "\u6210\u529f\u6784\u5efa\u4e86\u5b89\u5168\u6ed1\u52a8\u57df\uff0c\u786e\u4fdd\u95ed\u73af\u8f68\u8ff9\u5728\u4e0d\u786e\u5b9a\u6027\u548c\u6270\u52a8\u4e0b\u4fdd\u6301\u9c81\u68d2\u5b89\u5168\uff0c\u63a7\u5236\u5668\u80fd\u4fdd\u8bc1\u6536\u655b\u5230\u5b89\u5168\u57df\u5e76\u907f\u5f00\u4e0d\u5b89\u5168\u533a\u57df", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u53cc\u79ef\u5206\u5668\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9c81\u68d2\u5b89\u5168\u63a7\u5236\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u786e\u4fdd\u7cfb\u7edf\u8f68\u8ff9\u59cb\u7ec8\u4fdd\u6301\u5728\u5b89\u5168\u6ed1\u52a8\u57df\u9644\u8fd1\u4e14\u907f\u5f00\u4e0d\u5b89\u5168\u533a\u57df"}}
{"id": "2509.13733", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13733", "abs": "https://arxiv.org/abs/2509.13733", "authors": ["Xiaolin Zhou", "Tingyang Xiao", "Liu Liu", "Yucheng Wang", "Maiyue Chen", "Xinrui Meng", "Xinjie Wang", "Wei Feng", "Wei Sui", "Zhizhong Su"], "title": "FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph", "comment": "8 pages", "summary": "Visual-Language Navigation (VLN) is a fundamental challenge in robotic\nsystems, with broad applications for the deployment of embodied agents in\nreal-world environments. Despite recent advances, existing approaches are\nlimited in long-range spatial reasoning, often exhibiting low success rates and\nhigh inference latency, particularly in long-range navigation tasks. To address\nthese limitations, we propose FSR-VLN, a vision-language navigation system that\ncombines a Hierarchical Multi-modal Scene Graph (HMSG) with Fast-to-Slow\nNavigation Reasoning (FSR). The HMSG provides a multi-modal map representation\nsupporting progressive retrieval, from coarse room-level localization to\nfine-grained goal view and object identification. Building on HMSG, FSR first\nperforms fast matching to efficiently select candidate rooms, views, and\nobjects, then applies VLM-driven refinement for final goal selection. We\nevaluated FSR-VLN across four comprehensive indoor datasets collected by\nhumanoid robots, utilizing 87 instructions that encompass a diverse range of\nobject categories. FSR-VLN achieves state-of-the-art (SOTA) performance in all\ndatasets, measured by the retrieval success rate (RSR), while reducing the\nresponse time by 82% compared to VLM-based methods on tour videos by activating\nslow reasoning only when fast intuition fails. Furthermore, we integrate\nFSR-VLN with speech interaction, planning, and control modules on a Unitree-G1\nhumanoid robot, enabling natural language interaction and real-time navigation.", "AI": {"tldr": "FSR-VLN\u662f\u4e00\u4e2a\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u5c42\u591a\u6a21\u6001\u573a\u666f\u56fe\u548c\u5feb\u6162\u63a8\u7406\u673a\u5236\uff0c\u5728\u957f\u8ddd\u79bb\u5bfc\u822a\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86SOTA\u6027\u80fd\uff0c\u540c\u65f6\u5c06\u54cd\u5e94\u65f6\u95f4\u51cf\u5c1182%\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u65b9\u6cd5\u5728\u957f\u8ddd\u79bb\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u8868\u73b0\u4e3a\u4f4e\u6210\u529f\u7387\u9ad8\u63a8\u7406\u5ef6\u8fdf\uff0c\u9700\u8981\u89e3\u51b3\u957f\u8ddd\u79bb\u5bfc\u822a\u4e2d\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u5206\u5c42\u591a\u6a21\u6001\u573a\u666f\u56fe\uff08HMSG\uff09\u548c\u5feb\u6162\u5bfc\u822a\u63a8\u7406\uff08FSR\uff09\uff0cHMSG\u63d0\u4f9b\u4ece\u7c97\u5230\u7ec6\u7684\u591a\u6a21\u6001\u5730\u56fe\u8868\u793a\uff0cFSR\u5148\u5feb\u901f\u5339\u914d\u5019\u9009\uff0c\u518d\u7528VLM\u9a71\u52a8\u7cbe\u70bc\u8fdb\u884c\u6700\u7ec8\u76ee\u6807\u9009\u62e9\u3002", "result": "\u57284\u4e2a\u5ba4\u5185\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0SOTA\u6027\u80fd\uff0c\u68c0\u7d22\u6210\u529f\u7387\u6700\u9ad8\uff0c\u54cd\u5e94\u65f6\u95f4\u6bd4VLM\u65b9\u6cd5\u51cf\u5c1182%\uff0c\u5e76\u5728\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u4e86\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u548c\u5b9e\u65f6\u5bfc\u822a\u3002", "conclusion": "FSR-VLN\u901a\u8fc7\u5206\u5c42\u573a\u666f\u56fe\u548c\u5feb\u6162\u63a8\u7406\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u957f\u8ddd\u79bb\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u95ee\u9898\uff0c\u4e3a\u673a\u5668\u4eba\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2509.13968", "categories": ["cs.AI", "cs.CL", "cs.FL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13968", "abs": "https://arxiv.org/abs/2509.13968", "authors": ["Konstantinos Voudouris", "Andrew Barron", "Marta Halina", "Colin Klein", "Matishalin Patel"], "title": "Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks", "comment": null, "summary": "Transitional accounts of evolution emphasise a few changes that shape what is\nevolvable, with dramatic consequences for derived lineages. More recently it\nhas been proposed that cognition might also have evolved via a series of major\ntransitions that manipulate the structure of biological neural networks,\nfundamentally changing the flow of information. We used idealised models of\ninformation flow, artificial neural networks (ANNs), to evaluate whether\nchanges in information flow in a network can yield a transitional change in\ncognitive performance. We compared networks with feed-forward, recurrent and\nlaminated topologies, and tested their performance learning artificial grammars\nthat differed in complexity, controlling for network size and resources. We\ndocumented a qualitative expansion in the types of input that recurrent\nnetworks can process compared to feed-forward networks, and a related\nqualitative increase in performance for learning the most complex grammars. We\nalso noted how the difficulty in training recurrent networks poses a form of\ntransition barrier and contingent irreversibility -- other key features of\nevolutionary transitions. Not all changes in network topology confer a\nperformance advantage in this task set. Laminated networks did not outperform\nnon-laminated networks in grammar learning. Overall, our findings show how some\nchanges in information flow can yield transitions in cognitive performance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u63a2\u8ba8\u4fe1\u606f\u6d41\u7ed3\u6784\u53d8\u5316\u662f\u5426\u80fd\u5e26\u6765\u8ba4\u77e5\u6027\u80fd\u7684\u8fc7\u6e21\u6027\u53d8\u5316\uff0c\u53d1\u73b0\u9012\u5f52\u7f51\u7edc\u76f8\u6bd4\u524d\u9988\u7f51\u7edc\u5728\u5904\u7406\u590d\u6742\u8bed\u6cd5\u65f6\u8868\u73b0\u51fa\u8d28\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u89c2\u5bdf\u5230\u8bad\u7ec3\u96be\u5ea6\u5f62\u6210\u7684\u8fc7\u6e21\u969c\u788d\u3002", "motivation": "\u63a2\u7d22\u8ba4\u77e5\u8fdb\u5316\u662f\u5426\u901a\u8fc7\u4e00\u7cfb\u5217\u4e3b\u8981\u8f6c\u53d8\u6765\u5b9e\u73b0\uff0c\u8fd9\u4e9b\u8f6c\u53d8\u64cd\u7eb5\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u5e76\u6839\u672c\u6539\u53d8\u4fe1\u606f\u6d41\uff0c\u9a8c\u8bc1\u7f51\u7edc\u4fe1\u606f\u6d41\u53d8\u5316\u662f\u5426\u80fd\u4ea7\u751f\u8ba4\u77e5\u6027\u80fd\u7684\u8fc7\u6e21\u6027\u53d8\u5316\u3002", "method": "\u4f7f\u7528\u7406\u60f3\u5316\u4fe1\u606f\u6d41\u6a21\u578b\u548c\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff0c\u6bd4\u8f83\u524d\u9988\u3001\u9012\u5f52\u548c\u5206\u5c42\u62d3\u6251\u7ed3\u6784\u7684\u7f51\u7edc\uff0c\u5728\u63a7\u5236\u7f51\u7edc\u5927\u5c0f\u548c\u8d44\u6e90\u7684\u60c5\u51b5\u4e0b\u6d4b\u8bd5\u5b83\u4eec\u5b66\u4e60\u4e0d\u540c\u590d\u6742\u5ea6\u4eba\u5de5\u8bed\u6cd5\u7684\u6027\u80fd\u3002", "result": "\u9012\u5f52\u7f51\u7edc\u76f8\u6bd4\u524d\u9988\u7f51\u7edc\u80fd\u591f\u5904\u7406\u66f4\u5e7f\u6cdb\u7684\u8f93\u5165\u7c7b\u578b\uff0c\u5728\u6700\u590d\u6742\u8bed\u6cd5\u5b66\u4e60\u4e0a\u8868\u73b0\u51fa\u8d28\u7684\u6027\u80fd\u63d0\u5347\u3002\u9012\u5f52\u7f51\u7edc\u7684\u8bad\u7ec3\u96be\u5ea6\u5f62\u6210\u4e86\u8fc7\u6e21\u969c\u788d\u548c\u5076\u7136\u4e0d\u53ef\u9006\u6027\u3002\u5206\u5c42\u7f51\u7edc\u5728\u8bed\u6cd5\u5b66\u4e60\u4efb\u52a1\u4e2d\u5e76\u672a\u4f18\u4e8e\u975e\u5206\u5c42\u7f51\u7edc\u3002", "conclusion": "\u67d0\u4e9b\u4fe1\u606f\u6d41\u7ed3\u6784\u7684\u53d8\u5316\u786e\u5b9e\u80fd\u591f\u4ea7\u751f\u8ba4\u77e5\u6027\u80fd\u7684\u8fc7\u6e21\u6027\u8f6c\u53d8\uff0c\u9012\u5f52\u62d3\u6251\u7ed3\u6784\u7684\u5f15\u5165\u5e26\u6765\u4e86\u8d28\u7684\u6027\u80fd\u98de\u8dc3\uff0c\u8fd9\u652f\u6301\u4e86\u8ba4\u77e5\u8fdb\u5316\u53ef\u80fd\u901a\u8fc7\u4e3b\u8981\u8f6c\u53d8\u5b9e\u73b0\u7684\u5047\u8bf4\u3002"}}
{"id": "2509.14168", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2509.14168", "abs": "https://arxiv.org/abs/2509.14168", "authors": ["Walden Marshall"], "title": "Factored Output Feedback Controller Synthesis with Locality Constraints for Spatially-Invariant Systems", "comment": "9 pages, 2 figures", "summary": "We consider H2 output feedback controller synthesis with pre-specified\nconstraints on spatial communication distance (locality) for\nspatially-invariant systems using two factored controller frameworks: the\nsystem-level parameterization and the input-output parameterization. In our\nmain result, we show that in both frameworks, output feedback controller\nsynthesis with locality constraints can be formulated as a convex problem in\nfinitely many transfer function variables, admitting the use of standard\nnumerical solution techniques. The number of decision variables in the optimal\ncontroller design problem scales linearly with the distance of allowed\ncommunication. We also show that the optimal controller design problems for the\nsystem-level and input-ouptput parameterizations are equivalent for the chosen\nsystem of interest. We present numerical examples to illustrate the tradeoff\nbetween communication sparsity and performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u53c2\u6570\u5316\u6846\u67b6\uff08\u7cfb\u7edf\u7ea7\u548c\u8f93\u5165\u8f93\u51fa\u53c2\u6570\u5316\uff09\u6765\u89e3\u51b3\u5177\u6709\u7a7a\u95f4\u901a\u4fe1\u8ddd\u79bb\u7ea6\u675f\u7684H2\u8f93\u51fa\u53cd\u9988\u63a7\u5236\u5668\u7efc\u5408\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u8be5\u95ee\u9898\u53ef\u4ee5\u8f6c\u5316\u4e3a\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u4e14\u51b3\u7b56\u53d8\u91cf\u6570\u91cf\u4e0e\u5141\u8bb8\u901a\u4fe1\u8ddd\u79bb\u5448\u7ebf\u6027\u5173\u7cfb\u3002", "motivation": "\u9488\u5bf9\u7a7a\u95f4\u4e0d\u53d8\u7cfb\u7edf\u7684\u5206\u5e03\u5f0f\u63a7\u5236\u95ee\u9898\uff0c\u9700\u8981\u5728\u4fdd\u8bc1\u63a7\u5236\u5668\u6027\u80fd\u7684\u540c\u65f6\u6ee1\u8db3\u7a7a\u95f4\u901a\u4fe1\u8ddd\u79bb\u7ea6\u675f\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5904\u7406\u8fd9\u4e9b\u8981\u6c42\u3002", "method": "\u4f7f\u7528\u7cfb\u7edf\u7ea7\u53c2\u6570\u5316\u548c\u8f93\u5165\u8f93\u51fa\u53c2\u6570\u5316\u4e24\u79cd\u6846\u67b6\uff0c\u5c06\u5177\u6709\u5c40\u90e8\u6027\u7ea6\u675f\u7684\u8f93\u51fa\u53cd\u9988\u63a7\u5236\u5668\u7efc\u5408\u95ee\u9898\u8868\u8ff0\u4e3a\u6709\u9650\u4f20\u9012\u51fd\u6570\u53d8\u91cf\u7684\u51f8\u4f18\u5316\u95ee\u9898\u3002", "result": "\u8bc1\u660e\u4e86\u4e24\u79cd\u53c2\u6570\u5316\u6846\u67b6\u5728\u6700\u4f18\u63a7\u5236\u5668\u8bbe\u8ba1\u95ee\u9898\u4e0a\u7684\u7b49\u4ef7\u6027\uff0c\u51b3\u7b56\u53d8\u91cf\u6570\u91cf\u4e0e\u5141\u8bb8\u901a\u4fe1\u8ddd\u79bb\u5448\u7ebf\u6027\u6bd4\u4f8b\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u793a\u4f8b\u5c55\u793a\u4e86\u901a\u4fe1\u7a00\u758f\u6027\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u5177\u6709\u7a7a\u95f4\u901a\u4fe1\u7ea6\u675f\u7684\u63a7\u5236\u5668\u8bbe\u8ba1\u95ee\u9898\uff0c\u4e3a\u5206\u5e03\u5f0f\u63a7\u5236\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bbe\u8ba1\u6846\u67b6\uff0c\u4e14\u8ba1\u7b97\u590d\u6742\u5ea6\u53ef\u63a7\u3002"}}
{"id": "2509.13736", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13736", "abs": "https://arxiv.org/abs/2509.13736", "authors": ["Muyuan Ma", "Long Cheng", "Lijun Han", "Xiuze Xia", "Houcheng Li"], "title": "Motion Adaptation Across Users and Tasks for Exoskeletons via Meta-Learning", "comment": null, "summary": "Wearable exoskeletons can augment human strength and reduce muscle fatigue\nduring specific tasks. However, developing personalized and task-generalizable\nassistance algorithms remains a critical challenge. To address this, a\nmeta-imitation learning approach is proposed. This approach leverages a\ntask-specific neural network to predict human elbow joint movements, enabling\neffective assistance while enhancing generalization to new scenarios. To\naccelerate data collection, full-body keypoint motions are extracted from\npublicly available RGB video and motion-capture datasets across multiple tasks,\nand subsequently retargeted in simulation. Elbow flexion trajectories generated\nin simulation are then used to train the task-specific neural network within\nthe model-agnostic meta-learning (MAML) framework, which allows the network to\nrapidly adapt to novel tasks and unseen users with only a few gradient updates.\nThe adapted network outputs personalized references tracked by a\ngravity-compensated PD controller to ensure stable assistance. Experimental\nresults demonstrate that the exoskeleton significantly reduces both muscle\nactivation and metabolic cost for new users performing untrained tasks,\ncompared to performing without exoskeleton assistance. These findings suggest\nthat the proposed framework effectively improves task generalization and user\nadaptability for wearable exoskeleton systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5143\u6a21\u4eff\u5b66\u4e60\u7684\u53ef\u7a7f\u6234\u5916\u9aa8\u9abc\u4e2a\u6027\u5316\u8f85\u52a9\u7b97\u6cd5\uff0c\u901a\u8fc7\u4ece\u516c\u5f00\u89c6\u9891\u6570\u636e\u63d0\u53d6\u8fd0\u52a8\u4fe1\u606f\u5e76\u91cd\u5b9a\u5411\u5230\u4eff\u771f\u73af\u5883\uff0c\u4f7f\u7528MAML\u6846\u67b6\u8bad\u7ec3\u4efb\u52a1\u7279\u5b9a\u795e\u7ecf\u7f51\u7edc\uff0c\u80fd\u591f\u5feb\u901f\u9002\u5e94\u65b0\u4efb\u52a1\u548c\u7528\u6237\uff0c\u663e\u8457\u964d\u4f4e\u808c\u8089\u6fc0\u6d3b\u548c\u4ee3\u8c22\u6210\u672c\u3002", "motivation": "\u5f00\u53d1\u4e2a\u6027\u5316\u548c\u4efb\u52a1\u901a\u7528\u5316\u7684\u5916\u9aa8\u9abc\u8f85\u52a9\u7b97\u6cd5\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u89e3\u51b3\u65b0\u573a\u666f\u6cdb\u5316\u80fd\u529b\u548c\u7528\u6237\u9002\u5e94\u6027\u95ee\u9898\u3002", "method": "\u4ece\u516c\u5f00RGB\u89c6\u9891\u548c\u52a8\u4f5c\u6355\u6349\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u5168\u8eab\u5173\u952e\u70b9\u8fd0\u52a8\u4fe1\u606f\uff0c\u5728\u4eff\u771f\u73af\u5883\u4e2d\u91cd\u5b9a\u5411\uff0c\u751f\u6210\u8098\u5173\u8282\u5c48\u66f2\u8f68\u8ff9\uff0c\u4f7f\u7528MAML\u6846\u67b6\u8bad\u7ec3\u4efb\u52a1\u7279\u5b9a\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u91cd\u529b\u8865\u507fPD\u63a7\u5236\u5668\u5b9e\u73b0\u7a33\u5b9a\u8f85\u52a9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5916\u9aa8\u9abc\u663e\u8457\u964d\u4f4e\u4e86\u65b0\u7528\u6237\u6267\u884c\u672a\u8bad\u7ec3\u4efb\u52a1\u65f6\u7684\u808c\u8089\u6fc0\u6d3b\u548c\u4ee3\u8c22\u6210\u672c\uff0c\u76f8\u6bd4\u65e0\u5916\u9aa8\u9abc\u8f85\u52a9\u7684\u60c5\u51b5\u6709\u663e\u8457\u6539\u5584\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u63d0\u9ad8\u4e86\u53ef\u7a7f\u6234\u5916\u9aa8\u9abc\u7cfb\u7edf\u7684\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u548c\u7528\u6237\u9002\u5e94\u6027\uff0c\u4e3a\u4e2a\u6027\u5316\u8f85\u52a9\u7b97\u6cd5\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14030", "abs": "https://arxiv.org/abs/2509.14030", "authors": ["Maosheng Qin", "Renyu Zhu", "Mingxuan Xia", "Chenkai Chen", "Zhen Zhu", "Minmin Lin", "Junbo Zhao", "Lu Xu", "Changjie Fan", "Runze Wu", "Haobo Wang"], "title": "CrowdAgent: Multi-Agent Managed Multi-Source Annotation System", "comment": null, "summary": "High-quality annotated data is a cornerstone of modern Natural Language\nProcessing (NLP). While recent methods begin to leverage diverse annotation\nsources-including Large Language Models (LLMs), Small Language Models (SLMs),\nand human experts-they often focus narrowly on the labeling step itself. A\ncritical gap remains in the holistic process control required to manage these\nsources dynamically, addressing complex scheduling and quality-cost trade-offs\nin a unified manner. Inspired by real-world crowdsourcing companies, we\nintroduce CrowdAgent, a multi-agent system that provides end-to-end process\ncontrol by integrating task assignment, data annotation, and quality/cost\nmanagement. It implements a novel methodology that rationally assigns tasks,\nenabling LLMs, SLMs, and human experts to advance synergistically in a\ncollaborative annotation workflow. We demonstrate the effectiveness of\nCrowdAgent through extensive experiments on six diverse multimodal\nclassification tasks. The source code and video demo are available at\nhttps://github.com/QMMMS/CrowdAgent.", "AI": {"tldr": "CrowdAgent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u4efb\u52a1\u5206\u914d\u3001\u6570\u636e\u6807\u6ce8\u548c\u8d28\u91cf/\u6210\u672c\u7ba1\u7406\uff0c\u4e3aLLM\u3001SLM\u548c\u4eba\u7c7b\u4e13\u5bb6\u63d0\u4f9b\u7aef\u5230\u7aef\u7684\u534f\u540c\u6807\u6ce8\u6d41\u7a0b\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6807\u6ce8\u6b65\u9aa4\u672c\u8eab\uff0c\u7f3a\u4e4f\u5bf9\u591a\u6837\u5316\u6807\u6ce8\u6e90\uff08LLM\u3001SLM\u3001\u4eba\u7c7b\u4e13\u5bb6\uff09\u7684\u52a8\u6001\u7ba1\u7406\u548c\u590d\u6742\u8c03\u5ea6\u4e0e\u8d28\u91cf\u6210\u672c\u6743\u8861\u7684\u7edf\u4e00\u5904\u7406\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u67b6\u6784\uff0c\u5b9e\u73b0\u4efb\u52a1\u5206\u914d\u3001\u6570\u636e\u6807\u6ce8\u548c\u8d28\u91cf/\u6210\u672c\u7ba1\u7406\u7684\u7aef\u5230\u7aef\u6d41\u7a0b\u63a7\u5236\uff0c\u4f7f\u4e0d\u540c\u6807\u6ce8\u6e90\u80fd\u591f\u534f\u540c\u5de5\u4f5c\u3002", "result": "\u5728\u516d\u4e2a\u591a\u6a21\u6001\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86CrowdAgent\u7684\u6709\u6548\u6027\u3002", "conclusion": "CrowdAgent\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7aef\u5230\u7aef\u6d41\u7a0b\u63a7\u5236\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u7ba1\u7406\u591a\u6837\u5316\u6807\u6ce8\u6e90\uff0c\u5b9e\u73b0\u534f\u540c\u6807\u6ce8\u5de5\u4f5c\u6d41\u3002"}}
{"id": "2509.13737", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13737", "abs": "https://arxiv.org/abs/2509.13737", "authors": ["Renjie Wang", "Shangke Lyu", "Donglin Wang"], "title": "Dynamic Adaptive Legged Locomotion Policy via Decoupling Reaction Force Control and Gait Control", "comment": null, "summary": "While Reinforcement Learning (RL) has achieved remarkable progress in legged\nlocomotion control, it often suffers from performance degradation in\nout-of-distribution (OOD) conditions and discrepancies between the simulation\nand the real environments. Instead of mainly relying on domain randomization\n(DR) to best cover the real environments and thereby close the sim-to-real gap\nand enhance robustness, this work proposes an emerging decoupled framework that\nacquires fast online adaptation ability and mitigates the sim-to-real problems\nin unfamiliar environments by isolating stance-leg control and swing-leg\ncontrol. Various simulation and real-world experiments demonstrate its\neffectiveness against horizontal force disturbances, uneven terrains, heavy and\nbiased payloads, and sim-to-real gap.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u89e3\u8026\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u652f\u6491\u817f\u548c\u6446\u52a8\u817f\u63a7\u5236\u6765\u83b7\u5f97\u5feb\u901f\u5728\u7ebf\u9002\u5e94\u80fd\u529b\uff0c\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u5728\u817f\u5f0f\u8fd0\u52a8\u63a7\u5236\u4e2d\u7684\u5206\u5e03\u5916\u6027\u80fd\u548c\u4eff\u771f\u5230\u73b0\u5b9e\u5dee\u8ddd\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u817f\u5f0f\u8fd0\u52a8\u63a7\u5236\u4e2d\u9762\u4e34\u5206\u5e03\u5916\u6761\u4ef6\u6027\u80fd\u4e0b\u964d\u548c\u4eff\u771f\u5230\u73b0\u5b9e\u73af\u5883\u5dee\u5f02\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u4f9d\u8d56\u9886\u57df\u968f\u673a\u5316\u6765\u8986\u76d6\u771f\u5b9e\u73af\u5883\uff0c\u4f46\u6548\u679c\u6709\u9650\u3002", "method": "\u91c7\u7528\u89e3\u8026\u6846\u67b6\uff0c\u5c06\u652f\u6491\u817f\u63a7\u5236\u548c\u6446\u52a8\u817f\u63a7\u5236\u5206\u79bb\uff0c\u4ee5\u83b7\u5f97\u5feb\u901f\u5728\u7ebf\u9002\u5e94\u80fd\u529b\uff0c\u51cf\u8f7b\u5728\u964c\u751f\u73af\u5883\u4e2d\u7684\u4eff\u771f\u5230\u73b0\u5b9e\u95ee\u9898\u3002", "result": "\u5728\u5404\u79cd\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u6c34\u5e73\u529b\u6270\u52a8\u3001\u4e0d\u5e73\u5766\u5730\u5f62\u3001\u91cd\u8f7d\u548c\u504f\u7f6e\u8f7d\u8377\u4ee5\u53ca\u4eff\u771f\u5230\u73b0\u5b9e\u5dee\u8ddd\u7b49\u65b9\u9762\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002", "conclusion": "\u89e3\u8026\u6846\u67b6\u4e3a\u89e3\u51b3\u817f\u5f0f\u8fd0\u52a8\u63a7\u5236\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u4eff\u771f\u5230\u73b0\u5b9e\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b0\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u9886\u57df\u968f\u673a\u5316\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2509.14195", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14195", "abs": "https://arxiv.org/abs/2509.14195", "authors": ["Shalima Binta Manir", "Tim Oates"], "title": "Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning", "comment": "8 pages, 3 figures", "summary": "Mental representation, characterized by structured internal models mirroring\nexternal environments, is fundamental to advanced cognition but remains\nchallenging to investigate empirically. Existing theory hypothesizes that\nsecond-order learning -- learning mechanisms that adapt first-order learning\n(i.e., learning about the task/domain) -- promotes the emergence of such\nenvironment-cognition isomorphism. In this paper, we empirically validate this\nhypothesis by proposing a hierarchical architecture comprising a Graph\nConvolutional Network (GCN) as a first-order learner and an MLP controller as a\nsecond-order learner. The GCN directly maps node-level features to predictions\nof optimal navigation paths, while the MLP dynamically adapts the GCN's\nparameters when confronting structurally novel maze environments. We\ndemonstrate that second-order learning is particularly effective when the\ncognitive system develops an internal mental map structurally isomorphic to the\nenvironment. Quantitative and qualitative results highlight significant\nperformance improvements and robust generalization on unseen maze tasks,\nproviding empirical support for the pivotal role of structured mental\nrepresentations in maximizing the effectiveness of second-order learning.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5c42\u6b21\u67b6\u6784\uff08GCN\u4f5c\u4e3a\u4e00\u9636\u5b66\u4e60\u5668\uff0cMLP\u4f5c\u4e3a\u4e8c\u9636\u5b66\u4e60\u5668\uff09\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u4e8c\u9636\u5b66\u4e60\u80fd\u4fc3\u8fdb\u73af\u5883-\u8ba4\u77e5\u540c\u6784\u7684\u5fc3\u7406\u8868\u5f81\u5f62\u6210\uff0c\u5728\u8ff7\u5bab\u5bfc\u822a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u6027\u80fd\u63d0\u5347\u548c\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5fc3\u7406\u8868\u5f81\uff08\u5185\u90e8\u6a21\u578b\u4e0e\u5916\u90e8\u73af\u5883\u7ed3\u6784\u540c\u6784\uff09\u5bf9\u9ad8\u7ea7\u8ba4\u77e5\u81f3\u5173\u91cd\u8981\u4f46\u96be\u4ee5\u5b9e\u8bc1\u7814\u7a76\u3002\u73b0\u6709\u7406\u8bba\u5047\u8bbe\u4e8c\u9636\u5b66\u4e60\uff08\u8c03\u6574\u4e00\u9636\u5b66\u4e60\u673a\u5236\u7684\u5b66\u4e60\uff09\u80fd\u4fc3\u8fdb\u8fd9\u79cd\u73af\u5883-\u8ba4\u77e5\u540c\u6784\u6027\u7684\u51fa\u73b0\u3002", "method": "\u63d0\u51fa\u5c42\u6b21\u67b6\u6784\uff1a\u4f7f\u7528\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u4f5c\u4e3a\u4e00\u9636\u5b66\u4e60\u5668\u76f4\u63a5\u6620\u5c04\u8282\u70b9\u7279\u5f81\u5230\u6700\u4f18\u5bfc\u822a\u8def\u5f84\u9884\u6d4b\uff0c\u4f7f\u7528MLP\u63a7\u5236\u5668\u4f5c\u4e3a\u4e8c\u9636\u5b66\u4e60\u5668\u5728\u9047\u5230\u7ed3\u6784\u65b0\u9896\u7684\u8ff7\u5bab\u73af\u5883\u65f6\u52a8\u6001\u8c03\u6574GCN\u53c2\u6570\u3002", "result": "\u5f53\u8ba4\u77e5\u7cfb\u7edf\u53d1\u5c55\u51fa\u4e0e\u73af\u5883\u7ed3\u6784\u540c\u6784\u7684\u5185\u90e8\u5fc3\u7406\u5730\u56fe\u65f6\uff0c\u4e8c\u9636\u5b66\u4e60\u7279\u522b\u6709\u6548\u3002\u5b9a\u91cf\u548c\u5b9a\u6027\u7ed3\u679c\u663e\u793a\u4e86\u5728\u672a\u89c1\u8ff7\u5bab\u4efb\u52a1\u4e0a\u7684\u663e\u8457\u6027\u80fd\u6539\u8fdb\u548c\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u7ed3\u6784\u5316\u5fc3\u7406\u8868\u5f81\u5728\u6700\u5927\u5316\u4e8c\u9636\u5b66\u4e60\u6709\u6548\u6027\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\uff0c\u9a8c\u8bc1\u4e86\u4e8c\u9636\u5b66\u4e60\u4fc3\u8fdb\u73af\u5883-\u8ba4\u77e5\u540c\u6784\u7684\u5fc3\u7406\u8868\u5f81\u5f62\u6210\u7684\u5047\u8bbe\u3002"}}
{"id": "2509.13771", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13771", "abs": "https://arxiv.org/abs/2509.13771", "authors": ["Mengzhu Li", "Yunyu Zhou", "He Ying", "F. Richard Yu"], "title": "CDFlow: Generative Gradient Flows for Configuration Space Distance Fields via Neural ODEs", "comment": null, "summary": "Signed Distance Fields (SDFs) are a fundamental representation in robot\nmotion planning. Their configuration-space counterpart, the Configuration Space\nDistance Field (CDF), directly encodes distances in joint space, offering a\nunified representation for optimization and control. However, existing CDF\nformulations face two major challenges in high-degree-of-freedom (DoF) robots:\n(1) they effectively return only a single nearest collision configuration,\nneglecting the multi-modal nature of minimal-distance collision configurations\nand leading to gradient ambiguity; and (2) they rely on sparse sampling of the\ncollision boundary, which often fails to identify the true closest\nconfigurations, producing oversmoothed approximations and geometric distortion\nin high-dimensional spaces. We propose CDFlow, a novel framework that addresses\nthese limitations by learning a continuous flow in configuration space via\nNeural Ordinary Differential Equations (Neural ODEs). We redefine the problem\nfrom finding a single nearest point to modeling the distribution of\nminimal-distance collision configurations. We also introduce an adaptive\nrefinement sampling strategy to generate high-fidelity training data for this\ndistribution. The resulting Neural ODE implicitly models this multi-modal\ndistribution and produces a smooth, consistent gradient field-derived as the\nexpected direction towards the distribution-that mitigates gradient ambiguity\nand preserves sharp geometric features. Extensive experiments on high-DoF\nmotion planning tasks demonstrate that CDFlow significantly improves planning\nefficiency, trajectory quality, and robustness compared to existing CDF-based\nmethods, enabling more robust and efficient planning for collision-aware robots\nin complex environments.", "AI": {"tldr": "CDFlow\u662f\u4e00\u4e2a\u57fa\u4e8e\u795e\u7ecfODE\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u6700\u5c0f\u8ddd\u79bb\u78b0\u649e\u914d\u7f6e\u7684\u591a\u6a21\u6001\u5206\u5e03\u6765\u89e3\u51b3\u4f20\u7edfCDF\u5728\u9ad8\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u4e2d\u7684\u68af\u5ea6\u6a21\u7cca\u548c\u51e0\u4f55\u5931\u771f\u95ee\u9898", "motivation": "\u4f20\u7edf\u914d\u7f6e\u7a7a\u95f4\u8ddd\u79bb\u573a(CDF)\u5728\u9ad8\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u4e2d\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1)\u53ea\u8fd4\u56de\u5355\u4e2a\u6700\u8fd1\u78b0\u649e\u914d\u7f6e\uff0c\u5ffd\u7565\u4e86\u591a\u6a21\u6001\u7279\u6027\u5bfc\u81f4\u68af\u5ea6\u6a21\u7cca\uff1b2)\u4f9d\u8d56\u7a00\u758f\u91c7\u6837\uff0c\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u4ea7\u751f\u8fc7\u5ea6\u5e73\u6ed1\u7684\u8fd1\u4f3c\u548c\u51e0\u4f55\u5931\u771f", "method": "\u63d0\u51faCDFlow\u6846\u67b6\uff0c\u4f7f\u7528\u795e\u7ecfODE\u5b66\u4e60\u914d\u7f6e\u7a7a\u95f4\u4e2d\u7684\u8fde\u7eed\u6d41\uff0c\u91cd\u65b0\u5b9a\u4e49\u95ee\u9898\u4e3a\u5efa\u6a21\u6700\u5c0f\u8ddd\u79bb\u78b0\u649e\u914d\u7f6e\u7684\u5206\u5e03\uff0c\u5e76\u5f15\u5165\u81ea\u9002\u5e94\u7ec6\u5316\u91c7\u6837\u7b56\u7565\u751f\u6210\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e", "result": "\u795e\u7ecfODE\u9690\u5f0f\u5efa\u6a21\u591a\u6a21\u6001\u5206\u5e03\uff0c\u4ea7\u751f\u5e73\u6ed1\u4e00\u81f4\u7684\u68af\u5ea6\u573a\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8fd0\u52a8\u89c4\u5212\u7684\u6548\u7387\u3001\u8f68\u8ff9\u8d28\u91cf\u548c\u9c81\u68d2\u6027", "conclusion": "CDFflow\u76f8\u6bd4\u73b0\u6709CDF\u65b9\u6cd5\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9c81\u68d2\u548c\u9ad8\u6548\u7684\u78b0\u649e\u611f\u77e5\u673a\u5668\u4eba\u89c4\u5212"}}
{"id": "2509.13943", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.13943", "abs": "https://arxiv.org/abs/2509.13943", "authors": ["Salim Oyinlola", "Nitesh Subedi", "Soumik Sarkar"], "title": "Reinforcement Learning for Autonomous Point-to-Point UAV Navigation", "comment": "Presented at the Research Experience for Undergraduates (REU)\n  Symposium at the Translational AI Centre in Iowa State University", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly used in automated\ninspection, delivery, and navigation tasks that require reliable autonomy. This\nproject develops a reinforcement learning (RL) approach to enable a single UAV\nto autonomously navigate between predefined points without manual intervention.\nThe drone learns navigation policies through trial-and-error interaction, using\na custom reward function that encourages goal-reaching efficiency while\npenalizing collisions and unsafe behavior. The control system integrates ROS\nwith a Gym-compatible training environment, enabling flexible deployment and\ntesting. After training, the learned policy is deployed on a real UAV platform\nand evaluated under practical conditions. Results show that the UAV can\nsuccessfully perform autonomous navigation with minimal human oversight,\ndemonstrating the viability of RL-based control for point-to-point drone\noperations in real-world scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65e0\u4eba\u673a\u81ea\u4e3b\u5bfc\u822a\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u5b9a\u4e49\u5956\u52b1\u51fd\u6570\u8bad\u7ec3\u65e0\u4eba\u673a\u5728\u9884\u5b9a\u4e49\u70b9\u4e4b\u95f4\u81ea\u4e3b\u98de\u884c\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002", "motivation": "\u968f\u7740\u65e0\u4eba\u673a\u5728\u81ea\u52a8\u5316\u68c0\u67e5\u3001\u914d\u9001\u548c\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u5f00\u53d1\u53ef\u9760\u7684\u81ea\u4e3b\u5bfc\u822a\u7cfb\u7edf\u6765\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\uff0c\u63d0\u9ad8\u4efb\u52a1\u6548\u7387\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bd5\u9519\u4ea4\u4e92\u8ba9\u65e0\u4eba\u673a\u5b66\u4e60\u5bfc\u822a\u7b56\u7565\uff0c\u4f7f\u7528\u81ea\u5b9a\u4e49\u5956\u52b1\u51fd\u6570\u9f13\u52b1\u9ad8\u6548\u5230\u8fbe\u76ee\u6807\u540c\u65f6\u60e9\u7f5a\u78b0\u649e\u548c\u4e0d\u5b89\u5168\u884c\u4e3a\u3002\u63a7\u5236\u7cfb\u7edf\u96c6\u6210ROS\u548cGym\u517c\u5bb9\u7684\u8bad\u7ec3\u73af\u5883\u3002", "result": "\u8bad\u7ec3\u540e\u7684\u7b56\u7565\u5728\u5b9e\u9645\u65e0\u4eba\u673a\u5e73\u53f0\u4e0a\u90e8\u7f72\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u65e0\u4eba\u673a\u80fd\u591f\u5728\u6700\u5c0f\u4eba\u5de5\u76d1\u7763\u4e0b\u6210\u529f\u6267\u884c\u81ea\u4e3b\u5bfc\u822a\u4efb\u52a1\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u63a7\u5236\u65b9\u6cd5\u5728\u73b0\u5b9e\u4e16\u754c\u70b9\u5bf9\u70b9\u65e0\u4eba\u673a\u64cd\u4f5c\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u81ea\u4e3b\u65e0\u4eba\u673a\u5bfc\u822a\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13774", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13774", "abs": "https://arxiv.org/abs/2509.13774", "authors": ["Piaopiao Jin", "Qi Wang", "Guokang Sun", "Ziwen Cai", "Pinjia He", "Yangwei You"], "title": "Dual-Actor Fine-Tuning of VLA Models: A Talk-and-Tweak Human-in-the-Loop Approach", "comment": null, "summary": "Vision-language-action (VLA) models demonstrate strong generalization in\nrobotic manipulation but face challenges in complex, real-world tasks. While\nsupervised fine-tuning with demonstrations is constrained by data quality,\nreinforcement learning (RL) offers a promising alternative. We propose a\nhuman-in-the-loop dual-actor fine-tuning framework grounded in RL. The\nframework integrates a primary actor for robust multi-task performance with a\nrefinement actor for latent-space adaptation. Beyond standard physical\ninterventions, we introduce a lightweight talk-and-tweak scheme that converts\nhuman corrections into semantically grounded language commands, thereby\ngenerating a new dataset for policy learning. In real-world multi-task\nexperiments, our approach achieves 100% success across three tasks within 101\nminutes of online fine-tuning. For long-horizon tasks, it sustains a 50%\nsuccess rate over 12 consecutive operations. Furthermore, the framework scales\neffectively to multi-robot training, achieving up to a 2 times improvement in\nefficiency when using dual robots. The experiment videos are available at\nhttps://sites.google.com/view/hil-daft/.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4eba\u673a\u534f\u4f5c\u7684\u53cc\u6267\u884c\u5668\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u8bed\u8a00\u6307\u4ee4\u5c06\u4eba\u7c7b\u4fee\u6b63\u8f6c\u5316\u4e3a\u8bed\u4e49\u57fa\u7840\u7684\u6570\u636e\u96c6\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u591a\u4efb\u52a1\u4e2d\u5b9e\u73b0100%\u6210\u529f\u7387\uff0c\u5e76\u5728\u591a\u673a\u5668\u4eba\u8bad\u7ec3\u4e2d\u6548\u7387\u63d0\u53472\u500d", "motivation": "\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u5728\u590d\u6742\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u76d1\u7763\u5fae\u8c03\u53d7\u9650\u4e8e\u6570\u636e\u8d28\u91cf\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u66ff\u4ee3\u65b9\u6848", "method": "\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4eba\u673a\u534f\u4f5c\u53cc\u6267\u884c\u5668\u6846\u67b6\uff1a\u4e3b\u6267\u884c\u5668\u8d1f\u8d23\u591a\u4efb\u52a1\u6027\u80fd\uff0c\u7cbe\u70bc\u6267\u884c\u5668\u8fdb\u884c\u6f5c\u5728\u7a7a\u95f4\u9002\u5e94\uff1b\u5f15\u5165\u8f7b\u91cf\u7ea7\u5bf9\u8bdd\u8c03\u6574\u65b9\u6848\u5c06\u4eba\u7c7b\u4fee\u6b63\u8f6c\u5316\u4e3a\u8bed\u4e49\u57fa\u7840\u7684\u8bed\u8a00\u547d\u4ee4", "result": "\u771f\u5b9e\u4e16\u754c\u591a\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0c101\u5206\u949f\u5728\u7ebf\u5fae\u8c03\u5b9e\u73b0100%\u6210\u529f\u7387\uff1b\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u4fdd\u630150%\u6210\u529f\u7387\u8fbe12\u6b21\u8fde\u7eed\u64cd\u4f5c\uff1b\u591a\u673a\u5668\u4eba\u8bad\u7ec3\u6548\u7387\u63d0\u53472\u500d", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u548c\u8bed\u8a00\u6307\u4ee4\u8f6c\u6362\uff0c\u6709\u6548\u89e3\u51b3\u4e86VLA\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u5fae\u8c03\u6311\u6218\uff0c\u5c55\u793a\u4e86\u5728\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u4f18\u5f02\u6027\u80fd\u548c\u591a\u673a\u5668\u4eba\u6269\u5c55\u80fd\u529b"}}
{"id": "2509.14040", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.14040", "abs": "https://arxiv.org/abs/2509.14040", "authors": ["Zewen Yang", "Xiaobing Dai", "Dongfa Zhang", "Yu Li", "Ziyang Meng", "Bingkun Huang", "Hamid Sadeghian", "Sami Haddadin"], "title": "Prompt2Auto: From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning", "comment": null, "summary": "Learning from demonstration allows robots to acquire complex skills from\nhuman demonstrations, but conventional approaches often require large datasets\nand fail to generalize across coordinate transformations. In this paper, we\npropose Prompt2Auto, a geometry-invariant one-shot Gaussian process (GeoGP)\nlearning framework that enables robots to perform human-guided automated\ncontrol from a single motion prompt. A dataset-construction strategy based on\ncoordinate transformations is introduced that enforces invariance to\ntranslation, rotation, and scaling, while supporting multi-step predictions.\nMoreover, GeoGP is robust to variations in the user's motion prompt and\nsupports multi-skill autonomy. We validate the proposed approach through\nnumerical simulations with the designed user graphical interface and two\nreal-world robotic experiments, which demonstrate that the proposed method is\neffective, generalizes across tasks, and significantly reduces the\ndemonstration burden. Project page is available at:\nhttps://prompt2auto.github.io", "AI": {"tldr": "Prompt2Auto\u662f\u4e00\u4e2a\u51e0\u4f55\u4e0d\u53d8\u7684\u5355\u6b21\u9ad8\u65af\u8fc7\u7a0b\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5750\u6807\u53d8\u6362\u5b9e\u73b0\u5e73\u79fb\u3001\u65cb\u8f6c\u548c\u7f29\u653e\u4e0d\u53d8\u6027\uff0c\u4ec5\u9700\u5355\u6b21\u8fd0\u52a8\u63d0\u793a\u5c31\u80fd\u8ba9\u673a\u5668\u4eba\u6267\u884c\u4eba\u7c7b\u5f15\u5bfc\u7684\u81ea\u52a8\u5316\u63a7\u5236", "motivation": "\u4f20\u7edf\u793a\u6559\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6570\u636e\u96c6\u4e14\u96be\u4ee5\u8de8\u5750\u6807\u53d8\u6362\u6cdb\u5316\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4ece\u5355\u6b21\u6f14\u793a\u4e2d\u5b66\u4e60\u5e76\u5177\u6709\u51e0\u4f55\u4e0d\u53d8\u6027\u7684\u65b9\u6cd5", "method": "\u63d0\u51fa\u51e0\u4f55\u4e0d\u53d8\u9ad8\u65af\u8fc7\u7a0b(GeoGP)\u6846\u67b6\uff0c\u57fa\u4e8e\u5750\u6807\u53d8\u6362\u7684\u6570\u636e\u96c6\u6784\u5efa\u7b56\u7565\uff0c\u652f\u6301\u591a\u6b65\u9884\u6d4b\u548c\u5bf9\u7528\u6237\u8fd0\u52a8\u63d0\u793a\u53d8\u5316\u7684\u9c81\u68d2\u6027", "result": "\u901a\u8fc7\u6570\u503c\u4eff\u771f\u548c\u4e24\u4e2a\u771f\u5b9e\u673a\u5668\u4eba\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u65b9\u6cd5\u6709\u6548\u3001\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u5f3a\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6f14\u793a\u8d1f\u62c5", "conclusion": "Prompt2Auto\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u4ece\u5355\u6b21\u8fd0\u52a8\u63d0\u793a\u4e2d\u5b66\u4e60\u51e0\u4f55\u4e0d\u53d8\u8868\u793a\uff0c\u4e3a\u673a\u5668\u4eba\u81ea\u52a8\u5316\u63a7\u5236\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.13780", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13780", "abs": "https://arxiv.org/abs/2509.13780", "authors": ["Weishuai Zeng", "Shunlin Lu", "Kangning Yin", "Xiaojie Niu", "Minyue Dai", "Jingbo Wang", "Jiangmiao Pang"], "title": "Behavior Foundation Model for Humanoid Robots", "comment": null, "summary": "Whole-body control (WBC) of humanoid robots has witnessed remarkable progress\nin skill versatility, enabling a wide range of applications such as locomotion,\nteleoperation, and motion tracking. Despite these achievements, existing WBC\nframeworks remain largely task-specific, relying heavily on labor-intensive\nreward engineering and demonstrating limited generalization across tasks and\nskills. These limitations hinder their response to arbitrary control modes and\nrestrict their deployment in complex, real-world scenarios. To address these\nchallenges, we revisit existing WBC systems and identify a shared objective\nacross diverse tasks: the generation of appropriate behaviors that guide the\nrobot toward desired goal states. Building on this insight, we propose the\nBehavior Foundation Model (BFM), a generative model pretrained on large-scale\nbehavioral datasets to capture broad, reusable behavioral knowledge for\nhumanoid robots. BFM integrates a masked online distillation framework with a\nConditional Variational Autoencoder (CVAE) to model behavioral distributions,\nthereby enabling flexible operation across diverse control modes and efficient\nacquisition of novel behaviors without retraining from scratch. Extensive\nexperiments in both simulation and on a physical humanoid platform demonstrate\nthat BFM generalizes robustly across diverse WBC tasks while rapidly adapting\nto new behaviors. These results establish BFM as a promising step toward a\nfoundation model for general-purpose humanoid control.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u884c\u4e3a\u57fa\u7840\u6a21\u578b\uff08BFM\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u89c4\u6a21\u884c\u4e3a\u6570\u636e\u96c6\u9884\u8bad\u7ec3\u7684\u751f\u6210\u6a21\u578b\uff0c\u7528\u4e8e\u6355\u83b7\u4eba\u5f62\u673a\u5668\u4eba\u7684\u5e7f\u6cdb\u53ef\u91cd\u7528\u884c\u4e3a\u77e5\u8bc6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5168\u8eab\u63a7\u5236\u6846\u67b6\u4efb\u52a1\u7279\u5b9a\u3001\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5168\u8eab\u63a7\u5236\uff08WBC\uff09\u6846\u67b6\u4e3b\u8981\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\uff0c\u4f9d\u8d56\u5927\u91cf\u4eba\u5de5\u5956\u52b1\u5de5\u7a0b\uff0c\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u6280\u80fd\u95f4\u7684\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u963b\u788d\u4e86\u5728\u590d\u6742\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u90e8\u7f72\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7075\u6d3b\u5e94\u5bf9\u4efb\u610f\u63a7\u5236\u6a21\u5f0f\u5e76\u9ad8\u6548\u83b7\u53d6\u65b0\u884c\u4e3a\u7684\u901a\u7528\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u884c\u4e3a\u57fa\u7840\u6a21\u578b\uff08BFM\uff09\uff0c\u7ed3\u5408\u63a9\u7801\u5728\u7ebf\u84b8\u998f\u6846\u67b6\u548c\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08CVAE\uff09\u6765\u5efa\u6a21\u884c\u4e3a\u5206\u5e03\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5728\u591a\u6837\u5316\u63a7\u5236\u6a21\u5f0f\u4e0b\u7075\u6d3b\u64cd\u4f5c\uff0c\u65e0\u9700\u4ece\u5934\u5f00\u59cb\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u9ad8\u6548\u83b7\u53d6\u65b0\u884c\u4e3a\u3002", "result": "\u5728\u4eff\u771f\u548c\u7269\u7406\u4eba\u5f62\u5e73\u53f0\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cBFM\u80fd\u591f\u7a33\u5065\u5730\u6cdb\u5316\u5230\u4e0d\u540c\u7684WBC\u4efb\u52a1\uff0c\u540c\u65f6\u5feb\u901f\u9002\u5e94\u65b0\u884c\u4e3a\u3002", "conclusion": "BFM\u4e3a\u5b9e\u73b0\u901a\u7528\u4eba\u5f62\u63a7\u5236\u7684\u57fa\u7840\u6a21\u578b\u8fc8\u51fa\u4e86\u6709\u5e0c\u671b\u7684\u4e00\u6b65\uff0c\u5c55\u793a\u4e86\u5728\u591a\u6837\u5316\u63a7\u5236\u6a21\u5f0f\u4e0b\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5feb\u901f\u9002\u5e94\u65b0\u884c\u4e3a\u7684\u80fd\u529b\u3002"}}
{"id": "2509.14075", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.14075", "abs": "https://arxiv.org/abs/2509.14075", "authors": ["Yu Li", "Hamid Sadeghian", "Zewen Yang", "Valentin Le Mesle", "Sami Haddadin"], "title": "Constraint-Consistent Control of Task-Based and Kinematic RCM Constraints for Surgical Robots", "comment": null, "summary": "Robotic-assisted minimally invasive surgery (RAMIS) requires precise\nenforcement of the remote center of motion (RCM) constraint to ensure safe tool\nmanipulation through a trocar. Achieving this constraint under dynamic and\ninteractive conditions remains challenging, as existing control methods either\nlack robustness at the torque level or do not guarantee consistent RCM\nconstraint satisfaction. This paper proposes a constraint-consistent torque\ncontroller that treats the RCM as a rheonomic holonomic constraint and embeds\nit into a projection-based inverse-dynamics framework. The method unifies\ntask-level and kinematic formulations, enabling accurate tool-tip tracking\nwhile maintaining smooth and efficient torque behavior. The controller is\nvalidated both in simulation and on a RAMIS training platform, and is\nbenchmarked against state-of-the-art approaches. Results show improved RCM\nconstraint satisfaction, reduced required torque, and robust performance by\nimproving joint torque smoothness through the consistency formulation under\nclinically relevant scenarios, including spiral trajectories, variable\ninsertion depths, moving trocars, and human interaction. These findings\ndemonstrate the potential of constraint-consistent torque control to enhance\nsafety and reliability in surgical robotics. The project page is available at:\nhttps://rcmpc-cube.github.io", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ea6\u675f\u4e00\u81f4\u7684\u626d\u77e9\u63a7\u5236\u5668\uff0c\u7528\u4e8e\u673a\u5668\u4eba\u8f85\u52a9\u5fae\u521b\u624b\u672f\u4e2d\u7684\u8fdc\u7a0b\u8fd0\u52a8\u4e2d\u5fc3\u7ea6\u675f\u7cbe\u786e\u6267\u884c\uff0c\u901a\u8fc7\u6295\u5f71\u9006\u52a8\u529b\u5b66\u6846\u67b6\u5b9e\u73b0\u7cbe\u786e\u5de5\u5177\u5c16\u7aef\u8ddf\u8e2a\u548c\u626d\u77e9\u5e73\u6ed1\u6027", "motivation": "\u673a\u5668\u4eba\u8f85\u52a9\u5fae\u521b\u624b\u672f\u9700\u8981\u7cbe\u786e\u6267\u884c\u8fdc\u7a0b\u8fd0\u52a8\u4e2d\u5fc3\u7ea6\u675f\u4ee5\u786e\u4fdd\u624b\u672f\u5b89\u5168\uff0c\u4f46\u73b0\u6709\u63a7\u5236\u65b9\u6cd5\u5728\u626d\u77e9\u7ea7\u522b\u7f3a\u4e4f\u9c81\u68d2\u6027\u6216\u65e0\u6cd5\u4fdd\u8bc1\u4e00\u81f4\u7684\u7ea6\u675f\u6ee1\u8db3", "method": "\u5c06RCM\u7ea6\u675f\u89c6\u4e3a\u6d41\u53d8\u5b8c\u6574\u7ea6\u675f\uff0c\u5d4c\u5165\u5230\u57fa\u4e8e\u6295\u5f71\u7684\u9006\u52a8\u529b\u5b66\u6846\u67b6\u4e2d\uff0c\u7edf\u4e00\u4efb\u52a1\u7ea7\u548c\u8fd0\u52a8\u5b66\u8868\u8ff0", "result": "\u5728\u4eff\u771f\u548cRAMIS\u8bad\u7ec3\u5e73\u53f0\u4e0a\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u6539\u5584\u4e86RCM\u7ea6\u675f\u6ee1\u8db3\u5ea6\uff0c\u964d\u4f4e\u4e86\u6240\u9700\u626d\u77e9\uff0c\u63d0\u9ad8\u4e86\u5173\u8282\u626d\u77e9\u5e73\u6ed1\u6027\uff0c\u5728\u87ba\u65cb\u8f68\u8ff9\u3001\u53ef\u53d8\u63d2\u5165\u6df1\u5ea6\u3001\u79fb\u52a8\u5957\u7ba1\u548c\u4eba\u7c7b\u4ea4\u4e92\u7b49\u4e34\u5e8a\u76f8\u5173\u573a\u666f\u4e2d\u8868\u73b0\u9c81\u68d2", "conclusion": "\u7ea6\u675f\u4e00\u81f4\u7684\u626d\u77e9\u63a7\u5236\u65b9\u6cd5\u6709\u6f5c\u529b\u63d0\u9ad8\u624b\u672f\u673a\u5668\u4eba\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027"}}
{"id": "2509.13802", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13802", "abs": "https://arxiv.org/abs/2509.13802", "authors": ["Takuya Kiyokawa", "Ryunosuke Takebayashi", "Kensuke Harada"], "title": "Shell-Type Soft Jig for Holding Objects during Disassembly", "comment": "6 pages, 8 figures", "summary": "This study addresses a flexible holding tool for robotic disassembly. We\npropose a shell-type soft jig that securely and universally holds objects,\nmitigating the risk of component damage and adapting to diverse shapes while\nenabling soft fixation that is robust to recognition, planning, and control\nerrors. The balloon-based holding mechanism ensures proper alignment and stable\nholding performance, thereby reducing the need for dedicated jig design, highly\naccurate perception, precise grasping, and finely tuned trajectory planning\nthat are typically required with conventional fixtures. Our experimental\nresults demonstrate the practical feasibility of the proposed jig through\nperformance comparisons with a vise and a jamming-gripper-inspired soft jig.\nTests on ten different objects further showed representative successes and\nfailures, clarifying the jig's limitations and outlook.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u673a\u5668\u4eba\u62c6\u5378\u7684\u58f3\u5f0f\u8f6f\u5939\u5177\uff0c\u901a\u8fc7\u6c14\u56ca\u5f0f\u5939\u6301\u673a\u5236\u5b9e\u73b0\u901a\u7528\u7269\u4f53\u5b89\u5168\u56fa\u5b9a\uff0c\u51cf\u5c11\u5bf9\u4e13\u7528\u5939\u5177\u8bbe\u8ba1\u548c\u9ad8\u7cbe\u5ea6\u611f\u77e5\u7684\u9700\u6c42", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5939\u5177\u9700\u8981\u4e13\u7528\u8bbe\u8ba1\u3001\u9ad8\u7cbe\u5ea6\u611f\u77e5\u548c\u7cbe\u786e\u63a7\u5236\u7684\u95ee\u9898\uff0c\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u5f62\u72b6\u3001\u51cf\u5c11\u90e8\u4ef6\u635f\u574f\u98ce\u9669\u4e14\u5bf9\u8bc6\u522b\u548c\u89c4\u5212\u9519\u8bef\u5177\u6709\u9c81\u68d2\u6027\u7684\u67d4\u6027\u5939\u6301\u5de5\u5177", "method": "\u91c7\u7528\u58f3\u5f0f\u8f6f\u5939\u5177\u8bbe\u8ba1\uff0c\u57fa\u4e8e\u6c14\u56ca\u7684\u5939\u6301\u673a\u5236\uff0c\u786e\u4fdd\u6b63\u786e\u5bf9\u9f50\u548c\u7a33\u5b9a\u5939\u6301\u6027\u80fd\uff0c\u901a\u8fc7\u5b9e\u9a8c\u4e0e\u864e\u94b3\u548c\u5835\u585e\u5f0f\u8f6f\u5939\u5177\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u5939\u5177\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u572810\u79cd\u4e0d\u540c\u7269\u4f53\u4e0a\u6d4b\u8bd5\u663e\u793a\u4e86\u4ee3\u8868\u6027\u6210\u529f\u548c\u5931\u8d25\u6848\u4f8b\uff0c\u660e\u786e\u4e86\u5939\u5177\u7684\u5c40\u9650\u6027\u548c\u524d\u666f", "conclusion": "\u63d0\u51fa\u7684\u6c14\u56ca\u5f0f\u8f6f\u5939\u5177\u4e3a\u673a\u5668\u4eba\u62c6\u5378\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u3001\u5b89\u5168\u4e14\u9c81\u68d2\u7684\u5939\u6301\u89e3\u51b3\u65b9\u6848\uff0c\u51cf\u5c11\u4e86\u4f20\u7edf\u65b9\u6cd5\u5bf9\u9ad8\u7cbe\u5ea6\u8981\u6c42\u7684\u4f9d\u8d56"}}
{"id": "2509.13815", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13815", "abs": "https://arxiv.org/abs/2509.13815", "authors": ["Takuya Kiyokawa", "Zhengtao Hu", "Weiwei Wan", "Kensuke Harada"], "title": "Soft Regrasping Tool Inspired by Jamming Gripper", "comment": "6 pages, 9 figures", "summary": "Regrasping on fixtures is a promising approach to reduce pose uncertainty in\nrobotic assembly, but conventional rigid fixtures lack adaptability and require\ndedicated designs for each part. To overcome this limitation, we propose a soft\njig inspired by the jamming transition phenomenon, which can be continuously\ndeformed to accommodate diverse object geometries. By pressing a\ntriangular-pyramid-shaped tool into the membrane and evacuating the enclosed\nair, a stable cavity is formed as a placement space. We further optimize the\nstamping depth to balance placement stability and gripper accessibility. In\nsoft-jig-based regrasping, the key challenge lies in optimizing the cavity size\nto achieve precise dropping; once the part is reliably placed, subsequent\ngrasping can be performed with reduced uncertainty. Accordingly, we conducted\ndrop experiments on ten mechanical parts of varying shapes, which achieved\nplacement success rates exceeding 80% for most objects and above 90% for\ncylindrical ones, while failures were mainly caused by geometric constraints\nand membrane properties. These results demonstrate that the proposed jig\nenables general-purpose, accurate, and repeatable regrasping, while also\nclarifying its current limitations and future potential as a practical\nalternative to rigid fixtures in assembly automation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5835\u585e\u8fc7\u6e21\u73b0\u8c61\u7684\u8f6f\u5939\u5177\uff0c\u901a\u8fc7\u53ef\u53d8\u5f62\u7684\u819c\u7ed3\u6784\u5f62\u6210\u7a33\u5b9a\u7a7a\u8154\u6765\u9002\u5e94\u4e0d\u540c\u51e0\u4f55\u5f62\u72b6\u7684\u96f6\u4ef6\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7684\u91cd\u65b0\u6293\u53d6\u88c5\u914d", "motivation": "\u4f20\u7edf\u521a\u6027\u5939\u5177\u7f3a\u4e4f\u9002\u5e94\u6027\u4e14\u9700\u8981\u4e3a\u6bcf\u4e2a\u96f6\u4ef6\u4e13\u95e8\u8bbe\u8ba1\uff0c\u9650\u5236\u4e86\u5728\u673a\u5668\u4eba\u88c5\u914d\u4e2d\u7684\u5e94\u7528\u3002\u4e3a\u4e86\u89e3\u51b3\u59ff\u6001\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u591a\u6837\u5316\u51e0\u4f55\u5f62\u72b6\u7684\u901a\u7528\u5939\u5177", "method": "\u91c7\u7528\u4e09\u89d2\u5f62\u91d1\u5b57\u5854\u5f62\u72b6\u7684\u5de5\u5177\u538b\u5165\u819c\u7ed3\u6784\u5e76\u6392\u51fa\u5c01\u95ed\u7a7a\u6c14\uff0c\u5f62\u6210\u7a33\u5b9a\u7a7a\u8154\u4f5c\u4e3a\u653e\u7f6e\u7a7a\u95f4\u3002\u4f18\u5316\u538b\u5370\u6df1\u5ea6\u4ee5\u5e73\u8861\u653e\u7f6e\u7a33\u5b9a\u6027\u548c\u6293\u53d6\u5668\u53ef\u8fbe\u6027\uff0c\u91cd\u70b9\u4f18\u5316\u7a7a\u8154\u5c3a\u5bf8\u4ee5\u5b9e\u73b0\u7cbe\u786e\u6295\u653e", "result": "\u5bf910\u79cd\u4e0d\u540c\u5f62\u72b6\u7684\u673a\u68b0\u96f6\u4ef6\u8fdb\u884c\u6295\u653e\u5b9e\u9a8c\uff0c\u5927\u591a\u6570\u7269\u4f53\u7684\u653e\u7f6e\u6210\u529f\u7387\u8d85\u8fc780%\uff0c\u5706\u67f1\u5f62\u96f6\u4ef6\u8fbe\u523090%\u4ee5\u4e0a\u3002\u5931\u8d25\u4e3b\u8981\u7531\u4e8e\u51e0\u4f55\u7ea6\u675f\u548c\u819c\u7279\u6027\u5bfc\u81f4", "conclusion": "\u6240\u63d0\u51fa\u7684\u8f6f\u5939\u5177\u5b9e\u73b0\u4e86\u901a\u7528\u3001\u51c6\u786e\u548c\u53ef\u91cd\u590d\u7684\u91cd\u65b0\u6293\u53d6\uff0c\u5c55\u793a\u4e86\u4f5c\u4e3a\u88c5\u914d\u81ea\u52a8\u5316\u4e2d\u521a\u6027\u5939\u5177\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848\u7684\u6f5c\u529b\uff0c\u540c\u65f6\u4e5f\u660e\u786e\u4e86\u5f53\u524d\u5c40\u9650\u6027\u548c\u672a\u6765\u53d1\u5c55\u6f5c\u529b"}}
{"id": "2509.13816", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13816", "abs": "https://arxiv.org/abs/2509.13816", "authors": ["Yude Li", "Zhexuan Zhou", "Huizhe Li", "Youmin Gong", "Jie Mei"], "title": "Agile in the Face of Delay: Asynchronous End-to-End Learning for Real-World Aerial Navigation", "comment": null, "summary": "Robust autonomous navigation for Autonomous Aerial Vehicles (AAVs) in complex\nenvironments is a critical capability. However, modern end-to-end navigation\nfaces a key challenge: the high-frequency control loop needed for agile flight\nconflicts with low-frequency perception streams, which are limited by sensor\nupdate rates and significant computational cost. This mismatch forces\nconventional synchronous models into undesirably low control rates. To resolve\nthis, we propose an asynchronous reinforcement learning framework that\ndecouples perception and control, enabling a high-frequency policy to act on\nthe latest IMU state for immediate reactivity, while incorporating perception\nfeatures asynchronously. To manage the resulting data staleness, we introduce a\ntheoretically-grounded Temporal Encoding Module (TEM) that explicitly\nconditions the policy on perception delays, a strategy complemented by a\ntwo-stage curriculum to ensure stable and efficient training. Validated in\nextensive simulations, our method was successfully deployed in zero-shot\nsim-to-real transfer on an onboard NUC, where it sustains a 100~Hz control rate\nand demonstrates robust, agile navigation in cluttered real-world environments.\nOur source code will be released for community reference.", "AI": {"tldr": "\u63d0\u51fa\u5f02\u6b65\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u89e3\u51b3\u65e0\u4eba\u673a\u5bfc\u822a\u4e2d\u9ad8\u9891\u63a7\u5236\u4e0e\u4f4e\u9891\u611f\u77e5\u7684\u51b2\u7a81\uff0c\u901a\u8fc7\u65f6\u95f4\u7f16\u7801\u6a21\u5757\u5904\u7406\u611f\u77e5\u5ef6\u8fdf\uff0c\u5b9e\u73b0100Hz\u63a7\u5236\u9891\u7387\u7684\u9c81\u68d2\u5bfc\u822a", "motivation": "\u89e3\u51b3\u81ea\u4e3b\u98de\u884c\u5668\u5728\u590d\u6742\u73af\u5883\u4e2d\u5bfc\u822a\u65f6\uff0c\u9ad8\u9891\u63a7\u5236\u9700\u6c42\u4e0e\u4f4e\u9891\u611f\u77e5\u6d41\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4f20\u7edf\u540c\u6b65\u6a21\u578b\u88ab\u8feb\u4f7f\u7528\u4f4e\u63a7\u5236\u9891\u7387", "method": "\u5f02\u6b65\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u89e3\u8026\u611f\u77e5\u548c\u63a7\u5236\uff0c\u9ad8\u9891\u7b56\u7565\u57fa\u4e8e\u6700\u65b0IMU\u72b6\u6001\u54cd\u5e94\uff0c\u5f02\u6b65\u6574\u5408\u611f\u77e5\u7279\u5f81\uff1b\u5f15\u5165\u65f6\u95f4\u7f16\u7801\u6a21\u5757(TEM)\u663e\u5f0f\u5904\u7406\u611f\u77e5\u5ef6\u8fdf\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u786e\u4fdd\u8bad\u7ec3\u7a33\u5b9a\u6027", "result": "\u5728\u5e7f\u6cdb\u4eff\u771f\u4e2d\u9a8c\u8bc1\uff0c\u6210\u529f\u5b9e\u73b0\u96f6\u6837\u672c\u4eff\u771f\u5230\u771f\u5b9e\u8fc1\u79fb\uff0c\u5728\u673a\u8f7dNUC\u4e0a\u7ef4\u6301100Hz\u63a7\u5236\u9891\u7387\uff0c\u5728\u6742\u4e71\u771f\u5b9e\u73af\u5883\u4e2d\u5c55\u793a\u9c81\u68d2\u654f\u6377\u5bfc\u822a", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u611f\u77e5-\u63a7\u5236\u9891\u7387\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u9891\u7387\u63a7\u5236\u7684\u9c81\u68d2\u81ea\u4e3b\u5bfc\u822a\uff0c\u4ee3\u7801\u5c06\u5f00\u6e90\u4f9b\u793e\u533a\u53c2\u8003"}}
{"id": "2509.13827", "categories": ["cs.RO", "cs.NE"], "pdf": "https://arxiv.org/pdf/2509.13827", "abs": "https://arxiv.org/abs/2509.13827", "authors": ["Renyuan Liu", "Haoting Zhou", "Chuankai Fang", "Qinbing Fu"], "title": "How Fly Neural Perception Mechanisms Enhance Visuomotor Control of Micro Robots", "comment": "9 pages, 6 figures", "summary": "Anyone who has tried to swat a fly has likely been frustrated by its\nremarkable agility.This ability stems from its visual neural perception system,\nparticularly the collision-selective neurons within its small brain.For\nautonomous robots operating in complex and unfamiliar environments, achieving\nsimilar agility is highly desirable but often constrained by the trade-off\nbetween computational cost and performance.In this context, insect-inspired\nintelligence offers a parsimonious route to low-power, computationally\nefficient frameworks.In this paper, we propose an attention-driven visuomotor\ncontrol strategy inspired by a specific class of fly visual projection\nneurons-the lobula plate/lobula column type-2 (LPLC2)-and their associated\nescape behaviors.To our knowledge, this represents the first embodiment of an\nLPLC2 neural model in the embedded vision of a physical mobile robot, enabling\ncollision perception and reactive evasion.The model was simplified and\noptimized at 70KB in memory to suit the computational constraints of a\nvision-based micro robot, the Colias, while preserving key neural perception\nmechanisms.We further incorporated multi-attention mechanisms to emulate the\ndistributed nature of LPLC2 responses, allowing the robot to detect and react\nto approaching targets both rapidly and selectively.We systematically evaluated\nthe proposed method against a state-of-the-art locust-inspired collision\ndetection model.Results showed that the fly-inspired visuomotor model achieved\ncomparable robustness, at success rate of 96.1% in collision detection while\nproducing more adaptive and elegant evasive maneuvers.Beyond demonstrating an\neffective collision-avoidance strategy, this work highlights the potential of\nfly-inspired neural models for advancing research into collective behaviors in\ninsect intelligence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u82cd\u8747\u89c6\u89c9\u795e\u7ecf\u5143\u542f\u53d1\u7684\u6ce8\u610f\u529b\u9a71\u52a8\u89c6\u89c9\u8fd0\u52a8\u63a7\u5236\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u5fae\u578b\u673a\u5668\u4eba\u7684\u78b0\u649e\u611f\u77e5\u548c\u53cd\u5e94\u6027\u89c4\u907f\uff0c\u5728\u4fdd\u630196.1%\u68c0\u6d4b\u6210\u529f\u7387\u7684\u540c\u65f6\u4ec5\u970070KB\u5185\u5b58\u3002", "motivation": "\u81ea\u4e3b\u673a\u5668\u4eba\u5728\u590d\u6742\u73af\u5883\u4e2d\u9700\u8981\u7c7b\u4f3c\u82cd\u8747\u7684\u654f\u6377\u6027\uff0c\u4f46\u9762\u4e34\u8ba1\u7b97\u6210\u672c\u4e0e\u6027\u80fd\u7684\u6743\u8861\u3002\u6606\u866b\u542f\u53d1\u7684\u667a\u80fd\u4e3a\u4f4e\u529f\u8017\u3001\u8ba1\u7b97\u9ad8\u6548\u7684\u6846\u67b6\u63d0\u4f9b\u4e86\u7b80\u6d01\u8def\u5f84\u3002", "method": "\u57fa\u4e8e\u82cd\u8747LPLC2\u89c6\u89c9\u6295\u5c04\u795e\u7ecf\u5143\u7684\u795e\u7ecf\u6a21\u578b\uff0c\u7b80\u5316\u4f18\u5316\u81f370KB\u5185\u5b58\uff0c\u5e76\u878d\u5165\u591a\u6ce8\u610f\u529b\u673a\u5236\u6a21\u62df\u5206\u5e03\u5f0f\u54cd\u5e94\u7279\u6027\uff0c\u5728Colias\u5fae\u578b\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u5d4c\u5165\u5f0f\u89c6\u89c9\u7cfb\u7edf\u3002", "result": "\u4e0e\u6700\u5148\u8fdb\u7684\u8757\u866b\u542f\u53d1\u78b0\u649e\u68c0\u6d4b\u6a21\u578b\u76f8\u6bd4\uff0c\u82cd\u8747\u542f\u53d1\u7684\u6a21\u578b\u5b9e\u73b0\u4e8696.1%\u7684\u78b0\u649e\u68c0\u6d4b\u6210\u529f\u7387\uff0c\u540c\u65f6\u4ea7\u751f\u66f4\u81ea\u9002\u5e94\u548c\u4f18\u96c5\u7684\u89c4\u907f\u52a8\u4f5c\uff0c\u5177\u6709\u76f8\u5f53\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u5c55\u793a\u4e86\u6709\u6548\u7684\u907f\u78b0\u7b56\u7565\uff0c\u66f4\u51f8\u663e\u4e86\u82cd\u8747\u542f\u53d1\u795e\u7ecf\u6a21\u578b\u5728\u63a8\u8fdb\u6606\u866b\u667a\u80fd\u96c6\u4f53\u884c\u4e3a\u7814\u7a76\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.13832", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13832", "abs": "https://arxiv.org/abs/2509.13832", "authors": ["Teng Wang", "Haojun Jiang", "Yuxuan Wang", "Zhenguo Sun", "Xiangjie Yan", "Xiang Li", "Gao Huang"], "title": "UltraHiT: A Hierarchical Transformer Architecture for Generalizable Internal Carotid Artery Robotic Ultrasonography", "comment": null, "summary": "Carotid ultrasound is crucial for the assessment of cerebrovascular health,\nparticularly the internal carotid artery (ICA). While previous research has\nexplored automating carotid ultrasound, none has tackled the challenging ICA.\nThis is primarily due to its deep location, tortuous course, and significant\nindividual variations, which greatly increase scanning complexity. To address\nthis, we propose a Hierarchical Transformer-based decision architecture, namely\nUltraHiT, that integrates high-level variation assessment with low-level action\ndecision. Our motivation stems from conceptualizing individual vascular\nstructures as morphological variations derived from a standard vascular model.\nThe high-level module identifies variation and switches between two low-level\nmodules: an adaptive corrector for variations, or a standard executor for\nnormal cases. Specifically, both the high-level module and the adaptive\ncorrector are implemented as causal transformers that generate predictions\nbased on the historical scanning sequence. To ensure generalizability, we\ncollected the first large-scale ICA scanning dataset comprising 164\ntrajectories and 72K samples from 28 subjects of both genders. Based on the\nabove innovations, our approach achieves a 95% success rate in locating the ICA\non unseen individuals, outperforming baselines and demonstrating its\neffectiveness. Our code will be released after acceptance.", "AI": {"tldr": "\u63d0\u51faUltraHiT\u5206\u5c42Transformer\u67b6\u6784\uff0c\u901a\u8fc7\u9ad8\u5c42\u53d8\u5f02\u8bc4\u4f30\u548c\u4f4e\u5c42\u52a8\u4f5c\u51b3\u7b56\u81ea\u52a8\u5316\u9888\u52a8\u8109\u8d85\u58f0\u626b\u63cf\uff0c\u5728\u672a\u89c1\u8fc7\u4e2a\u4f53\u4e0a\u8fbe\u523095%\u7684\u6210\u529f\u7387", "motivation": "\u9888\u5185\u52a8\u8109(ICA)\u4f4d\u7f6e\u6df1\u3001\u8def\u5f84\u66f2\u6298\u4e14\u4e2a\u4f53\u5dee\u5f02\u5927\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u81ea\u52a8\u5316\u626b\u63cf\u3002\u5c06\u4e2a\u4f53\u8840\u7ba1\u7ed3\u6784\u89c6\u4e3a\u6807\u51c6\u8840\u7ba1\u6a21\u578b\u7684\u5f62\u6001\u53d8\u5f02\uff0c\u9700\u8981\u667a\u80fd\u7684\u626b\u63cf\u51b3\u7b56\u7cfb\u7edf", "method": "\u5206\u5c42Transformer\u67b6\u6784\uff1a\u9ad8\u5c42\u6a21\u5757\u8bc6\u522b\u53d8\u5f02\u5e76\u5207\u6362\u4e24\u4e2a\u4f4e\u5c42\u6a21\u5757\uff08\u81ea\u9002\u5e94\u6821\u6b63\u5668\u5904\u7406\u53d8\u5f02\u60c5\u51b5\uff0c\u6807\u51c6\u6267\u884c\u5668\u5904\u7406\u6b63\u5e38\u60c5\u51b5\uff09\u3002\u9ad8\u5c42\u6a21\u5757\u548c\u81ea\u9002\u5e94\u6821\u6b63\u5668\u5747\u91c7\u7528\u56e0\u679cTransformer\uff0c\u57fa\u4e8e\u5386\u53f2\u626b\u63cf\u5e8f\u5217\u751f\u6210\u9884\u6d4b", "result": "\u5728\u5305\u542b28\u540d\u53d7\u8bd5\u8005\u3001164\u6761\u8f68\u8ff9\u300172K\u6837\u672c\u7684\u5927\u89c4\u6a21ICA\u626b\u63cf\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u5728\u672a\u89c1\u4e2a\u4f53\u4e0a\u8fbe\u523095%\u7684ICA\u5b9a\u4f4d\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "UltraHiT\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u9888\u5185\u52a8\u8109\u8d85\u58f0\u626b\u63cf\u81ea\u52a8\u5316\u7684\u6311\u6218\uff0c\u901a\u8fc7\u5206\u5c42\u51b3\u7b56\u548cTransformer\u5efa\u6a21\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u4e3a\u8111\u8840\u7ba1\u5065\u5eb7\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.13833", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13833", "abs": "https://arxiv.org/abs/2509.13833", "authors": ["Zhikai Zhang", "Jun Guo", "Chao Chen", "Jilong Wang", "Chenghuai Lin", "Yunrui Lian", "Han Xue", "Zhenrong Wang", "Maoqi Liu", "Huaping Liu", "He Wang", "Li Yi"], "title": "Track Any Motions under Any Disturbances", "comment": null, "summary": "A foundational humanoid motion tracker is expected to be able to track\ndiverse, highly dynamic, and contact-rich motions. More importantly, it needs\nto operate stably in real-world scenarios against various dynamics\ndisturbances, including terrains, external forces, and physical property\nchanges for general practical use. To achieve this goal, we propose Any2Track\n(Track Any motions under Any disturbances), a two-stage RL framework to track\nvarious motions under multiple disturbances in the real world. Any2Track\nreformulates dynamics adaptability as an additional capability on top of basic\naction execution and consists of two key components: AnyTracker and AnyAdapter.\nAnyTracker is a general motion tracker with a series of careful designs to\ntrack various motions within a single policy. AnyAdapter is a history-informed\nadaptation module that endows the tracker with online dynamics adaptability to\novercome the sim2real gap and multiple real-world disturbances. We deploy\nAny2Track on Unitree G1 hardware and achieve a successful sim2real transfer in\na zero-shot manner. Any2Track performs exceptionally well in tracking various\nmotions under multiple real-world disturbances.", "AI": {"tldr": "Any2Track\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u771f\u5b9e\u4e16\u754c\u591a\u79cd\u5e72\u6270\u4e0b\u8ddf\u8e2a\u5404\u79cd\u4eba\u5f62\u673a\u5668\u4eba\u52a8\u4f5c\uff0c\u901a\u8fc7AnyTracker\u901a\u7528\u52a8\u4f5c\u8ddf\u8e2a\u5668\u548cAnyAdapter\u5728\u7ebf\u9002\u5e94\u6a21\u5757\u5b9e\u73b0\u96f6\u6837\u672csim2real\u8fc1\u79fb\u3002", "motivation": "\u5f00\u53d1\u80fd\u591f\u5728\u771f\u5b9e\u4e16\u754c\u5404\u79cd\u52a8\u6001\u5e72\u6270\uff08\u5730\u5f62\u3001\u5916\u529b\u3001\u7269\u7406\u5c5e\u6027\u53d8\u5316\uff09\u4e0b\u7a33\u5b9a\u8fd0\u884c\u7684\u57fa\u7840\u4eba\u5f62\u52a8\u4f5c\u8ddf\u8e2a\u5668\uff0c\u5b9e\u73b0\u901a\u7528\u5b9e\u7528\u5316\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5RL\u6846\u67b6\uff1aAnyTracker\uff08\u901a\u7528\u52a8\u4f5c\u8ddf\u8e2a\u7b56\u7565\uff09+ AnyAdapter\uff08\u5386\u53f2\u4fe1\u606f\u9a71\u52a8\u7684\u5728\u7ebf\u9002\u5e94\u6a21\u5757\uff09\uff0c\u5c06\u52a8\u6001\u9002\u5e94\u6027\u4f5c\u4e3a\u57fa\u7840\u52a8\u4f5c\u6267\u884c\u4e4b\u4e0a\u7684\u9644\u52a0\u80fd\u529b\u3002", "result": "\u5728Unitree G1\u786c\u4ef6\u4e0a\u6210\u529f\u5b9e\u73b0\u96f6\u6837\u672csim2real\u8fc1\u79fb\uff0c\u5728\u5404\u79cd\u771f\u5b9e\u4e16\u754c\u5e72\u6270\u4e0b\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u52a8\u4f5c\u8ddf\u8e2a\u6027\u80fd\u3002", "conclusion": "Any2Track\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u771f\u5b9e\u4e16\u754c\u7684\u591a\u79cd\u52a8\u6001\u5e72\u6270\uff0c\u4e3a\u4eba\u5f62\u673a\u5668\u4eba\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u52a8\u6001\u9002\u5e94\u6027\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13839", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13839", "abs": "https://arxiv.org/abs/2509.13839", "authors": ["Motonari Kambara", "Komei Sugiura"], "title": "Pre-Manipulation Alignment Prediction with Parallel Deep State-Space and Transformer Models", "comment": "Published in Advanced Robotics", "summary": "In this work, we address the problem of predicting the future success of\nopen-vocabulary object manipulation tasks. Conventional approaches typically\ndetermine success or failure after the action has been carried out. However,\nthey make it difficult to prevent potential hazards and rely on failures to\ntrigger replanning, thereby reducing the efficiency of object manipulation\nsequences. To overcome these challenges, we propose a model, which predicts the\nalignment between a pre-manipulation egocentric image with the planned\ntrajectory and a given natural language instruction. We introduce a Multi-Level\nTrajectory Fusion module, which employs a state-of-the-art deep state-space\nmodel and a transformer encoder in parallel to capture multi-level time-series\nself-correlation within the end effector trajectory. Our experimental results\nindicate that the proposed method outperformed existing methods, including\nfoundation models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9884\u6d4b\u5f00\u653e\u8bcd\u6c47\u7269\u4f53\u64cd\u4f5c\u4efb\u52a1\u672a\u6765\u6210\u529f\u7387\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u7ea7\u8f68\u8ff9\u878d\u5408\u6a21\u5757\u5206\u6790\u9884\u64cd\u4f5c\u56fe\u50cf\u3001\u89c4\u5212\u8f68\u8ff9\u548c\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u7684\u5bf9\u9f50\u5173\u7cfb", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u53ea\u80fd\u5728\u64cd\u4f5c\u5b8c\u6210\u540e\u5224\u65ad\u6210\u529f\u4e0e\u5426\uff0c\u96be\u4ee5\u9884\u9632\u6f5c\u5728\u5371\u9669\u4e14\u4f9d\u8d56\u5931\u8d25\u89e6\u53d1\u91cd\u65b0\u89c4\u5212\uff0c\u964d\u4f4e\u4e86\u7269\u4f53\u64cd\u4f5c\u5e8f\u5217\u7684\u6548\u7387", "method": "\u4f7f\u7528\u591a\u7ea7\u8f68\u8ff9\u878d\u5408\u6a21\u5757\uff0c\u7ed3\u5408\u5148\u8fdb\u7684\u6df1\u5ea6\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u548cTransformer\u7f16\u7801\u5668\u5e76\u884c\u5904\u7406\uff0c\u6355\u6349\u672b\u7aef\u6267\u884c\u5668\u8f68\u8ff9\u4e2d\u7684\u591a\u7ea7\u65f6\u95f4\u5e8f\u5217\u81ea\u76f8\u5173\u6027", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u7840\u6a21\u578b", "conclusion": "\u63d0\u51fa\u7684\u6a21\u578b\u80fd\u591f\u6709\u6548\u9884\u6d4b\u7269\u4f53\u64cd\u4f5c\u4efb\u52a1\u7684\u672a\u6765\u6210\u529f\u7387\uff0c\u63d0\u9ad8\u4e86\u64cd\u4f5c\u7684\u5b89\u5168\u6027\u548c\u6548\u7387"}}
{"id": "2509.13857", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.13857", "abs": "https://arxiv.org/abs/2509.13857", "authors": ["Nguyen Hoang Khoi Tran", "Julie Stephany Berrio", "Mao Shan", "Stewart Worrall"], "title": "InterKey: Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap", "comment": "8 pages, 5 figures", "summary": "Reliable global localization is critical for autonomous vehicles, especially\nin environments where GNSS is degraded or unavailable, such as urban canyons\nand tunnels. Although high-definition (HD) maps provide accurate priors, the\ncost of data collection, map construction, and maintenance limits scalability.\nOpenStreetMap (OSM) offers a free and globally available alternative, but its\ncoarse abstraction poses challenges for matching with sensor data. We propose\nInterKey, a cross-modal framework that leverages road intersections as\ndistinctive landmarks for global localization. Our method constructs compact\nbinary descriptors by jointly encoding road and building imprints from point\nclouds and OSM. To bridge modality gaps, we introduce discrepancy mitigation,\norientation determination, and area-equalized sampling strategies, enabling\nrobust cross-modal matching. Experiments on the KITTI dataset demonstrate that\nInterKey achieves state-of-the-art accuracy, outperforming recent baselines by\na large margin. The framework generalizes to sensors that can produce dense\nstructural point clouds, offering a scalable and cost-effective solution for\nrobust vehicle localization.", "AI": {"tldr": "InterKey\u662f\u4e00\u4e2a\u5229\u7528\u9053\u8def\u4ea4\u53c9\u53e3\u4f5c\u4e3a\u5730\u6807\u7684\u8de8\u6a21\u6001\u5168\u5c40\u5b9a\u4f4d\u6846\u67b6\uff0c\u901a\u8fc7\u70b9\u4e91\u548cOSM\u5730\u56fe\u7684\u8054\u5408\u7f16\u7801\u5b9e\u73b0\u9c81\u68d2\u7684\u8de8\u6a21\u6001\u5339\u914d\uff0c\u5728KITTI\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u7cbe\u5ea6", "motivation": "\u89e3\u51b3GNSS\u4fe1\u53f7\u9000\u5316\u73af\u5883\u4e0b\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u53ef\u9760\u5168\u5c40\u5b9a\u4f4d\u95ee\u9898\uff0c\u5229\u7528\u514d\u8d39\u4e14\u5168\u7403\u53ef\u7528\u7684OpenStreetMap\u4f5c\u4e3a\u9ad8\u6210\u672cHD\u5730\u56fe\u7684\u66ff\u4ee3\u65b9\u6848", "method": "\u6784\u5efa\u7d27\u51d1\u7684\u4e8c\u8fdb\u5236\u63cf\u8ff0\u7b26\uff0c\u8054\u5408\u7f16\u7801\u70b9\u4e91\u548cOSM\u4e2d\u7684\u9053\u8def\u548c\u5efa\u7b51\u5370\u8bb0\uff0c\u91c7\u7528\u5dee\u5f02\u7f13\u89e3\u3001\u65b9\u5411\u786e\u5b9a\u548c\u9762\u79ef\u5747\u8861\u91c7\u6837\u7b56\u7565\u6765\u5f25\u5408\u6a21\u6001\u5dee\u8ddd", "result": "\u5728KITTI\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u7cbe\u5ea6\uff0c\u5927\u5e45\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u8be5\u6846\u67b6\u53ef\u63a8\u5e7f\u5230\u80fd\u591f\u4ea7\u751f\u5bc6\u96c6\u7ed3\u6784\u70b9\u4e91\u7684\u4f20\u611f\u5668\uff0c\u4e3a\u9c81\u68d2\u8f66\u8f86\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.13861", "categories": ["cs.RO", "I.6.0; A.0"], "pdf": "https://arxiv.org/pdf/2509.13861", "abs": "https://arxiv.org/abs/2509.13861", "authors": ["G\u00f6rkem K\u0131l\u0131n\u00e7 Soylu", "Neziha Akalin", "Maria Riveiro"], "title": "Using Petri Nets for Context-Adaptive Robot Explanations", "comment": "In proceedings of TRUST 2025 (arXiv:2509.11402), a workshop at IEEE\n  RO-MAN 2025: https://www.ro-man2025.org/", "summary": "In human-robot interaction, robots must communicate in a natural and\ntransparent manner to foster trust, which requires adapting their communication\nto the context. In this paper, we propose using Petri nets (PNs) to model\ncontextual information for adaptive robot explanations. PNs provide a formal,\ngraphical method for representing concurrent actions, causal dependencies, and\nsystem states, making them suitable for analyzing dynamic interactions between\nhumans and robots. We demonstrate this approach through a scenario involving a\nrobot that provides explanations based on contextual cues such as user\nattention and presence. Model analysis confirms key properties, including\ndeadlock-freeness, context-sensitive reachability, boundedness, and liveness,\nshowing the robustness and flexibility of PNs for designing and verifying\ncontext-adaptive explanations in human-robot interactions.", "AI": {"tldr": "\u4f7f\u7528Petri\u7f51\u5efa\u6a21\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5b9e\u73b0\u673a\u5668\u4eba\u81ea\u9002\u5e94\u89e3\u91ca\u7684\u6b63\u5f0f\u65b9\u6cd5", "motivation": "\u5728\u4eba\u673a\u4ea4\u4e92\u4e2d\uff0c\u673a\u5668\u4eba\u9700\u8981\u4ee5\u81ea\u7136\u900f\u660e\u7684\u65b9\u5f0f\u6c9f\u901a\u4ee5\u5efa\u7acb\u4fe1\u4efb\uff0c\u8fd9\u8981\u6c42\u6839\u636e\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u8c03\u6574\u901a\u4fe1\u65b9\u5f0f", "method": "\u91c7\u7528Petri\u7f51\uff08PNs\uff09\u5efa\u6a21\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0cPNs\u63d0\u4f9b\u6b63\u5f0f\u7684\u56fe\u5f62\u5316\u65b9\u6cd5\u6765\u8868\u793a\u5e76\u53d1\u52a8\u4f5c\u3001\u56e0\u679c\u4f9d\u8d56\u548c\u7cfb\u7edf\u72b6\u6001\uff0c\u9002\u5408\u5206\u6790\u4eba\u673a\u52a8\u6001\u4ea4\u4e92", "result": "\u901a\u8fc7\u7528\u6237\u6ce8\u610f\u529b\u548c\u5b58\u5728\u7b49\u4e0a\u4e0b\u6587\u7ebf\u7d22\u7684\u673a\u5668\u4eba\u89e3\u91ca\u573a\u666f\u9a8c\u8bc1\uff0c\u6a21\u578b\u5206\u6790\u786e\u8ba4\u4e86\u65e0\u6b7b\u9501\u3001\u4e0a\u4e0b\u6587\u654f\u611f\u53ef\u8fbe\u6027\u3001\u6709\u754c\u6027\u548c\u6d3b\u6027\u7b49\u5173\u952e\u5c5e\u6027", "conclusion": "PNs\u5728\u8bbe\u8ba1\u548c\u9a8c\u8bc1\u4eba\u673a\u4ea4\u4e92\u4e2d\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u89e3\u91ca\u65b9\u9762\u5c55\u73b0\u51fa\u9c81\u68d2\u6027\u548c\u7075\u6d3b\u6027"}}
{"id": "2509.13882", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.13882", "abs": "https://arxiv.org/abs/2509.13882", "authors": ["Junhwa Hong", "Beomjoon Lee", "Woojin Lee", "Changjoo Nam"], "title": "Repulsive Trajectory Modification and Conflict Resolution for Efficient Multi-Manipulator Motion Planning", "comment": "7 pages", "summary": "We propose an efficient motion planning method designed to efficiently find\ncollision-free trajectories for multiple manipulators. While multi-manipulator\nsystems offer significant advantages, coordinating their motions is\ncomputationally challenging owing to the high dimensionality of their composite\nconfiguration space. Conflict-Based Search (CBS) addresses this by decoupling\nmotion planning, but suffers from subsequent conflicts incurred by resolving\nexisting conflicts, leading to an exponentially growing constraint tree of CBS.\nOur proposed method is based on repulsive trajectory modification within the\ntwo-level structure of CBS. Unlike conventional CBS variants, the low-level\nplanner applies a gradient descent approach using an Artificial Potential\nField. This field generates repulsive forces that guide the trajectory of the\nconflicting manipulator away from those of other robots. As a result,\nsubsequent conflicts are less likely to occur. Additionally, we develop a\nstrategy that, under a specific condition, directly attempts to find a\nconflict-free solution in a single step without growing the constraint tree.\nThrough extensive tests including physical robot experiments, we demonstrate\nthat our method consistently reduces the number of expanded nodes in the\nconstraint tree, achieves a higher success rate, and finds a solution faster\ncompared to Enhanced CBS and other state-of-the-art algorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u51b2\u7a81\u641c\u7d22\u7684\u591a\u673a\u68b0\u81c2\u9ad8\u6548\u8fd0\u52a8\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u6392\u65a5\u8f68\u8ff9\u4fee\u6539\u548c\u4eba\u5de5\u52bf\u573a\u68af\u5ea6\u4e0b\u964d\uff0c\u51cf\u5c11\u540e\u7eed\u51b2\u7a81\u5e76\u63d0\u9ad8\u6c42\u89e3\u6548\u7387", "motivation": "\u591a\u673a\u68b0\u81c2\u7cfb\u7edf\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4f46\u534f\u8c03\u8fd0\u52a8\u8ba1\u7b97\u590d\u6742\uff0c\u4f20\u7edf\u51b2\u7a81\u641c\u7d22\u65b9\u6cd5\u5b58\u5728\u7ea6\u675f\u6811\u6307\u6570\u589e\u957f\u95ee\u9898", "method": "\u5728CBS\u4e24\u7ea7\u7ed3\u6784\u4e2d\u5f15\u5165\u6392\u65a5\u8f68\u8ff9\u4fee\u6539\uff0c\u5e95\u5c42\u89c4\u5212\u5668\u4f7f\u7528\u4eba\u5de5\u52bf\u573a\u68af\u5ea6\u4e0b\u964d\u751f\u6210\u6392\u65a5\u529b\u5f15\u5bfc\u8f68\u8ff9\uff0c\u907f\u514d\u540e\u7eed\u51b2\u7a81", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u7ea6\u675f\u6811\u6269\u5c55\u8282\u70b9\u6570\uff0c\u63d0\u9ad8\u6210\u529f\u7387\uff0c\u6c42\u89e3\u901f\u5ea6\u4f18\u4e8e\u589e\u5f3aCBS\u548c\u5176\u4ed6\u5148\u8fdb\u7b97\u6cd5", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u673a\u68b0\u81c2\u8fd0\u52a8\u89c4\u5212\u4e2d\u7684\u51b2\u7a81\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u89c4\u5212\u6548\u7387\u548c\u6210\u529f\u7387"}}
{"id": "2509.13903", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13903", "abs": "https://arxiv.org/abs/2509.13903", "authors": ["Artem Lykov", "Jeffrin Sam", "Hung Khang Nguyen", "Vladislav Kozlovskiy", "Yara Mahmoud", "Valerii Serpiva", "Miguel Altamirano Cabrera", "Mikhail Konenkov", "Dzmitry Tsetserukou"], "title": "PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models", "comment": "submitted to IEEE conference", "summary": "We introduce PhysicalAgent, an agentic framework for robotic manipulation\nthat integrates iterative reasoning, diffusion-based video generation, and\nclosed-loop execution. Given a textual instruction, our method generates short\nvideo demonstrations of candidate trajectories, executes them on the robot, and\niteratively re-plans in response to failures. This approach enables robust\nrecovery from execution errors. We evaluate PhysicalAgent across multiple\nperceptual modalities (egocentric, third-person, and simulated) and robotic\nembodiments (bimanual UR3, Unitree G1 humanoid, simulated GR1), comparing\nagainst state-of-the-art task-specific baselines. Experiments demonstrate that\nour method consistently outperforms prior approaches, achieving up to 83%\nsuccess on human-familiar tasks. Physical trials reveal that first-attempt\nsuccess is limited (20-30%), yet iterative correction increases overall success\nto 80% across platforms. These results highlight the potential of video-based\ngenerative reasoning for general-purpose robotic manipulation and underscore\nthe importance of iterative execution for recovering from initial failures. Our\nframework paves the way for scalable, adaptable, and robust robot control.", "AI": {"tldr": "PhysicalAgent\u662f\u4e00\u4e2a\u673a\u5668\u4eba\u64cd\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u63a8\u7406\u3001\u6269\u6563\u89c6\u9891\u751f\u6210\u548c\u95ed\u73af\u6267\u884c\u5b9e\u73b0\u9c81\u68d2\u64cd\u4f5c\uff0c\u5728\u591a\u79cd\u611f\u77e5\u6a21\u6001\u548c\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u6267\u884c\u9519\u8bef\u6062\u590d\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8fed\u4ee3\u89c4\u5212\u548c\u81ea\u6211\u4fee\u6b63\u7684\u901a\u7528\u6846\u67b6\uff0c\u63d0\u9ad8\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002", "method": "\u7ed3\u5408\u6587\u672c\u6307\u4ee4\u751f\u6210\u5019\u9009\u8f68\u8ff9\u7684\u89c6\u9891\u6f14\u793a\uff0c\u5728\u673a\u5668\u4eba\u4e0a\u6267\u884c\u5e76\u901a\u8fc7\u8fed\u4ee3\u91cd\u65b0\u89c4\u5212\u6765\u54cd\u5e94\u5931\u8d25\uff0c\u5229\u7528\u6269\u6563\u5f0f\u89c6\u9891\u751f\u6210\u6280\u672f\u8fdb\u884c\u89c6\u89c9\u63a8\u7406\u3002", "result": "\u5728\u591a\u79cd\u5e73\u53f0\uff08UR3\u3001G1\u4eba\u5f62\u3001GR1\u4eff\u771f\uff09\u4e0a\u8fbe\u523083%\u7684\u6210\u529f\u7387\uff0c\u9996\u6b21\u5c1d\u8bd5\u6210\u529f\u738720-30%\uff0c\u4f46\u8fed\u4ee3\u4fee\u6b63\u540e\u6574\u4f53\u6210\u529f\u7387\u63d0\u5347\u81f380%\u3002", "conclusion": "\u57fa\u4e8e\u89c6\u9891\u7684\u751f\u6210\u63a8\u7406\u5728\u901a\u7528\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u8fed\u4ee3\u6267\u884c\u5bf9\u4e8e\u4ece\u521d\u59cb\u5931\u8d25\u4e2d\u6062\u590d\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u53ef\u6269\u5c55\u3001\u81ea\u9002\u5e94\u548c\u9c81\u68d2\u7684\u673a\u5668\u4eba\u63a7\u5236\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2509.13926", "categories": ["cs.RO", "cs.AI", "cs.CV", "I.2.9; I.2.10"], "pdf": "https://arxiv.org/pdf/2509.13926", "abs": "https://arxiv.org/abs/2509.13926", "authors": ["Huilin Yin", "Yiming Kan", "Daniel Watzenig"], "title": "MAP: End-to-End Autonomous Driving with Map-Assisted Planning", "comment": "8 pages, 2 figures, accepted by ICCVW Author list updated to match\n  the camera-ready version, in compliance with conference policy", "summary": "In recent years, end-to-end autonomous driving has attracted increasing\nattention for its ability to jointly model perception, prediction, and planning\nwithin a unified framework. However, most existing approaches underutilize the\nonline mapping module, leaving its potential to enhance trajectory planning\nlargely untapped. This paper proposes MAP (Map-Assisted Planning), a novel\nmap-assisted end-to-end trajectory planning framework. MAP explicitly\nintegrates segmentation-based map features and the current ego status through a\nPlan-enhancing Online Mapping module, an Ego-status-guided Planning module, and\na Weight Adapter based on current ego status. Experiments conducted on the\nDAIR-V2X-seq-SPD dataset demonstrate that the proposed method achieves a 16.6%\nreduction in L2 displacement error, a 56.2% reduction in off-road rate, and a\n44.5% improvement in overall score compared to the UniV2X baseline, even\nwithout post-processing. Furthermore, it achieves top ranking in Track 2 of the\nEnd-to-End Autonomous Driving through V2X Cooperation Challenge of MEIS\nWorkshop @CVPR2025, outperforming the second-best model by 39.5% in terms of\noverall score. These results highlight the effectiveness of explicitly\nleveraging semantic map features in planning and suggest new directions for\nimproving structure design in end-to-end autonomous driving systems. Our code\nis available at https://gitee.com/kymkym/map.git", "AI": {"tldr": "\u63d0\u51faMAP\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u6574\u5408\u8bed\u4e49\u5730\u56fe\u7279\u5f81\u548c\u81ea\u8f66\u72b6\u6001\uff0c\u663e\u8457\u63d0\u5347\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u8f68\u8ff9\u89c4\u5212\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "motivation": "\u73b0\u6709\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u5728\u7ebf\u5730\u56fe\u6a21\u5757\u7684\u6f5c\u529b\u6765\u589e\u5f3a\u8f68\u8ff9\u89c4\u5212\uff0c\u5730\u56fe\u7279\u5f81\u4e0e\u89c4\u5212\u7684\u7ed3\u5408\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4", "method": "\u63d0\u51faMAP\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u89c4\u5212\u589e\u5f3a\u7684\u5728\u7ebf\u5730\u56fe\u6a21\u5757\u3001\u81ea\u8f66\u72b6\u6001\u5f15\u5bfc\u7684\u89c4\u5212\u6a21\u5757\u3001\u57fa\u4e8e\u81ea\u8f66\u72b6\u6001\u7684\u6743\u91cd\u9002\u914d\u5668\uff0c\u663e\u5f0f\u6574\u5408\u5206\u5272\u5f0f\u5730\u56fe\u7279\u5f81\u548c\u5f53\u524d\u81ea\u8f66\u72b6\u6001", "result": "\u5728DAIR-V2X-seq-SPD\u6570\u636e\u96c6\u4e0a\uff0cL2\u4f4d\u79fb\u8bef\u5dee\u964d\u4f4e16.6%\uff0c\u8131\u8f68\u7387\u964d\u4f4e56.2%\uff0c\u7efc\u5408\u5f97\u5206\u63d0\u534744.5%\uff1b\u5728CVPR2025\u6311\u6218\u8d5b\u4e2d\u6392\u540d\u7b2c\u4e00\uff0c\u7efc\u5408\u5f97\u5206\u6bd4\u7b2c\u4e8c\u540d\u9ad839.5%", "conclusion": "\u663e\u5f0f\u5229\u7528\u8bed\u4e49\u5730\u56fe\u7279\u5f81\u80fd\u6709\u6548\u63d0\u5347\u89c4\u5212\u6027\u80fd\uff0c\u4e3a\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u7ed3\u6784\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411"}}
{"id": "2509.13948", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13948", "abs": "https://arxiv.org/abs/2509.13948", "authors": ["Benedict Barrow", "Roger K. Moore"], "title": "The Influence of Facial Features on the Perceived Trustworthiness of a Social Robot", "comment": "In proceedings of TRUST 2025 (arXiv:2509.11402), a workshop at IEEE\n  RO-MAN 2025: https://ro-man2025.org/", "summary": "Trust and the perception of trustworthiness play an important role in\ndecision-making and our behaviour towards others, and this is true not only of\nhuman-human interactions but also of human-robot interactions. While\nsignificant advances have been made in recent years in the field of social\nrobotics, there is still some way to go before we fully understand the factors\nthat influence human trust in robots. This paper presents the results of a\nstudy into the first impressions created by a social robot's facial features,\nbased on the hypothesis that a `babyface' engenders trust. By manipulating the\nback-projected face of a Furhat robot, the study confirms that eye shape and\nsize have a significant impact on the perception of trustworthiness. The work\nthus contributes to an understanding of the design choices that need to be made\nwhen developing social robots so as to optimise the effectiveness of\nhuman-robot interaction.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u673a\u5668\u4eba\u9762\u90e8\u7279\u5f81\u4e2d\u7684\u773c\u775b\u5f62\u72b6\u548c\u5927\u5c0f\u5bf9\u53ef\u4fe1\u5ea6\u611f\u77e5\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5a74\u513f\u8138\u7279\u5f81\u80fd\u589e\u5f3a\u4fe1\u4efb\u611f", "motivation": "\u7406\u89e3\u5f71\u54cd\u4eba\u7c7b\u5bf9\u673a\u5668\u4eba\u4fe1\u4efb\u7684\u56e0\u7d20\uff0c\u7279\u522b\u662f\u5728\u793e\u4ea4\u673a\u5668\u4eba\u9886\u57df\uff0c\u63a2\u7d22\u9762\u90e8\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u7b2c\u4e00\u5370\u8c61\u548c\u4fe1\u4efb\u5efa\u7acb", "method": "\u901a\u8fc7\u64cd\u7eb5Furhat\u673a\u5668\u4eba\u7684\u80cc\u6295\u5f71\u9762\u90e8\u7279\u5f81\uff0c\u7279\u522b\u662f\u773c\u775b\u5f62\u72b6\u548c\u5927\u5c0f\uff0c\u7814\u7a76\u5176\u5bf9\u53ef\u4fe1\u5ea6\u611f\u77e5\u7684\u5f71\u54cd", "result": "\u786e\u8ba4\u773c\u775b\u5f62\u72b6\u548c\u5927\u5c0f\u5bf9\u53ef\u4fe1\u5ea6\u611f\u77e5\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5a74\u513f\u8138\u7279\u5f81\u80fd\u591f\u4fc3\u8fdb\u4fe1\u4efb", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u793e\u4ea4\u673a\u5668\u4eba\u5f00\u53d1\u4e2d\u7684\u8bbe\u8ba1\u9009\u62e9\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u4eba\u673a\u4ea4\u4e92\u6548\u679c"}}
{"id": "2509.13949", "categories": ["cs.RO", "I.2.9"], "pdf": "https://arxiv.org/pdf/2509.13949", "abs": "https://arxiv.org/abs/2509.13949", "authors": ["Jannick Strangh\u00f6ner", "Philipp Hartmann", "Marco Braun", "Sebastian Wrede", "Klaus Neumann"], "title": "SHaRe-RL: Structured, Interactive Reinforcement Learning for Contact-Rich Industrial Assembly Tasks", "comment": "8 pages, 5 figures, submitted to the IEEE International Conference on\n  Robotics and Automation (ICRA) 2026", "summary": "High-mix low-volume (HMLV) industrial assembly, common in small and\nmedium-sized enterprises (SMEs), requires the same precision, safety, and\nreliability as high-volume automation while remaining flexible to product\nvariation and environmental uncertainty. Current robotic systems struggle to\nmeet these demands. Manual programming is brittle and costly to adapt, while\nlearning-based methods suffer from poor sample efficiency and unsafe\nexploration in contact-rich tasks. To address this, we present SHaRe-RL, a\nreinforcement learning framework that leverages multiple sources of prior\nknowledge. By (i) structuring skills into manipulation primitives, (ii)\nincorporating human demonstrations and online corrections, and (iii) bounding\ninteraction forces with per-axis compliance, SHaRe-RL enables efficient and\nsafe online learning for long-horizon, contact-rich industrial assembly tasks.\nExperiments on the insertion of industrial Harting connector modules with\n0.2-0.4 mm clearance demonstrate that SHaRe-RL achieves reliable performance\nwithin practical time budgets. Our results show that process expertise, without\nrequiring robotics or RL knowledge, can meaningfully contribute to learning,\nenabling safer, more robust, and more economically viable deployment of RL for\nindustrial assembly.", "AI": {"tldr": "SHaRe-RL\u662f\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u64cd\u4f5c\u539f\u8bed\u3001\u4eba\u7c7b\u6f14\u793a\u548c\u529b\u63a7\u7ea6\u675f\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u5b89\u5168\u7684\u5de5\u4e1a\u88c5\u914d\u4efb\u52a1\u5728\u7ebf\u5b66\u4e60\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9ad8\u6df7\u5408\u4f4e\u6279\u91cf\u751f\u4ea7\u73af\u5883\u3002", "motivation": "\u89e3\u51b3HMLV\u5de5\u4e1a\u88c5\u914d\u4e2d\u673a\u5668\u4eba\u7cfb\u7edf\u9762\u4e34\u7684\u6311\u6218\uff1a\u624b\u52a8\u7f16\u7a0b\u8106\u5f31\u4e14\u6210\u672c\u9ad8\uff0c\u5b66\u4e60\u578b\u65b9\u6cd5\u6837\u672c\u6548\u7387\u4f4e\u4e14\u63a5\u89e6\u4efb\u52a1\u4e2d\u63a2\u7d22\u4e0d\u5b89\u5168\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u5b89\u5168\u53ef\u9760\u6027\uff0c\u53c8\u80fd\u7075\u6d3b\u9002\u5e94\u4ea7\u54c1\u53d8\u5316\u548c\u73af\u5883\u4e0d\u786e\u5b9a\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "SHaRe-RL\u6846\u67b6\u6574\u5408\u4e09\u4e2a\u5173\u952e\u8981\u7d20\uff1a(i)\u5c06\u6280\u80fd\u7ed3\u6784\u5316\u4e3a\u64cd\u4f5c\u539f\u8bed\uff0c(ii)\u878d\u5165\u4eba\u7c7b\u6f14\u793a\u548c\u5728\u7ebf\u4fee\u6b63\uff0c(iii)\u901a\u8fc7\u8f74\u5411\u67d4\u987a\u6027\u9650\u5236\u4ea4\u4e92\u529b\u3002\u8fd9\u79cd\u65b9\u6cd5\u5229\u7528\u591a\u6e90\u5148\u9a8c\u77e5\u8bc6\u5b9e\u73b0\u5b89\u5168\u9ad8\u6548\u7684\u5728\u7ebf\u5b66\u4e60\u3002", "result": "\u5728\u5de5\u4e1aHarting\u8fde\u63a5\u5668\u6a21\u5757\u63d2\u5165\u4efb\u52a1\uff08\u95f4\u96990.2-0.4mm\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSHaRe-RL\u80fd\u591f\u5728\u5b9e\u9645\u65f6\u95f4\u9884\u7b97\u5185\u5b9e\u73b0\u53ef\u9760\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8fc7\u7a0b\u4e13\u4e1a\u77e5\u8bc6\u53ef\u4ee5\u663e\u8457\u4fc3\u8fdb\u5b66\u4e60\u6548\u679c\u3002", "conclusion": "SHaRe-RL\u6846\u67b6\u4f7f\u5f3a\u5316\u5b66\u4e60\u5728\u5de5\u4e1a\u88c5\u914d\u4e2d\u7684\u90e8\u7f72\u66f4\u52a0\u5b89\u5168\u3001\u9c81\u68d2\u548c\u7ecf\u6d4e\u53ef\u884c\uff0c\u7279\u522b\u9002\u5408\u4e2d\u5c0f\u4f01\u4e1a\u7684\u9ad8\u6df7\u5408\u4f4e\u6279\u91cf\u751f\u4ea7\u9700\u6c42\uff0c\u65e0\u9700\u4e13\u95e8\u7684\u673a\u5668\u4eba\u6216RL\u77e5\u8bc6\u5373\u53ef\u6709\u6548\u5e94\u7528\u3002"}}
{"id": "2509.13956", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13956", "abs": "https://arxiv.org/abs/2509.13956", "authors": ["Zewei Yang", "Zengqi Peng", "Jun Ma"], "title": "SEG-Parking: Towards Safe, Efficient, and Generalizable Autonomous Parking via End-to-End Offline Reinforcement Learning", "comment": null, "summary": "Autonomous parking is a critical component for achieving safe and efficient\nurban autonomous driving. However, unstructured environments and dynamic\ninteractions pose significant challenges to autonomous parking tasks. To\naddress this problem, we propose SEG-Parking, a novel end-to-end offline\nreinforcement learning (RL) framework to achieve interaction-aware autonomous\nparking. Notably, a specialized parking dataset is constructed for parking\nscenarios, which include those without interference from the opposite vehicle\n(OV) and complex ones involving interactions with the OV. Based on this\ndataset, a goal-conditioned state encoder is pretrained to map the fused\nperception information into the latent space. Then, an offline RL policy is\noptimized with a conservative regularizer that penalizes out-of-distribution\nactions. Extensive closed-loop experiments are conducted in the high-fidelity\nCARLA simulator. Comparative results demonstrate the superior performance of\nour framework with the highest success rate and robust generalization to\nout-of-distribution parking scenarios. The related dataset and source code will\nbe made publicly available after the paper is accepted.", "AI": {"tldr": "SEG-Parking\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u4e13\u7528\u505c\u8f66\u6570\u636e\u96c6\u548c\u9884\u8bad\u7ec3\u76ee\u6807\u6761\u4ef6\u72b6\u6001\u7f16\u7801\u5668\uff0c\u5b9e\u73b0\u4e86\u4ea4\u4e92\u611f\u77e5\u7684\u81ea\u4e3b\u505c\u8f66\uff0c\u5728\u590d\u6742\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6210\u529f\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u975e\u7ed3\u6784\u5316\u73af\u5883\u548c\u52a8\u6001\u4ea4\u4e92\u5bf9\u81ea\u4e3b\u505c\u8f66\u4efb\u52a1\u6784\u6210\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u590d\u6742\u4ea4\u4e92\u573a\u666f\u7684\u81ea\u4e3b\u505c\u8f66\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6784\u5efa\u4e13\u7528\u505c\u8f66\u6570\u636e\u96c6\uff0c\u9884\u8bad\u7ec3\u76ee\u6807\u6761\u4ef6\u72b6\u6001\u7f16\u7801\u5668\u5c06\u611f\u77e5\u4fe1\u606f\u6620\u5c04\u5230\u6f5c\u5728\u7a7a\u95f4\uff0c\u4f7f\u7528\u5e26\u6709\u4fdd\u5b88\u6b63\u5219\u5316\u5668\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u4f18\u5316\uff0c\u60e9\u7f5a\u5206\u5e03\u5916\u52a8\u4f5c\u3002", "result": "\u5728\u9ad8\u4fdd\u771fCARLA\u6a21\u62df\u5668\u4e2d\u8fdb\u884c\u7684\u95ed\u73af\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u5177\u6709\u6700\u9ad8\u7684\u6210\u529f\u7387\u548c\u5bf9\u5206\u5e03\u5916\u505c\u8f66\u573a\u666f\u7684\u9c81\u68d2\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SEG-Parking\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u4e3b\u505c\u8f66\u4e2d\u7684\u4ea4\u4e92\u6311\u6218\uff0c\u5c55\u793a\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728\u590d\u6742\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.13965", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.13965", "abs": "https://arxiv.org/abs/2509.13965", "authors": ["Abhijeet Nayak", "D\u00e9bora N. P. Oliveira", "Samiran Gode", "Cordelia Schmid", "Wolfram Burgard"], "title": "MetricNet: Recovering Metric Scale in Generative Navigation Policies", "comment": null, "summary": "Generative navigation policies have made rapid progress in improving\nend-to-end learned navigation. Despite their promising results, this paradigm\nhas two structural problems. First, the sampled trajectories exist in an\nabstract, unscaled space without metric grounding. Second, the control strategy\ndiscards the full path, instead moving directly towards a single waypoint. This\nleads to short-sighted and unsafe actions, moving the robot towards obstacles\nthat a complete and correctly scaled path would circumvent. To address these\nissues, we propose MetricNet, an effective add-on for generative navigation\nthat predicts the metric distance between waypoints, grounding policy outputs\nin real-world coordinates. We evaluate our method in simulation with a new\nbenchmarking framework and show that executing MetricNet-scaled waypoints\nsignificantly improves both navigation and exploration performance. Beyond\nsimulation, we further validate our approach in real-world experiments.\nFinally, we propose MetricNav, which integrates MetricNet into a navigation\npolicy to guide the robot away from obstacles while still moving towards the\ngoal.", "AI": {"tldr": "MetricNet\u662f\u4e00\u4e2a\u7528\u4e8e\u751f\u6210\u5f0f\u5bfc\u822a\u7684\u9644\u52a0\u6a21\u5757\uff0c\u901a\u8fc7\u9884\u6d4b\u8def\u5f84\u70b9\u4e4b\u95f4\u7684\u5ea6\u91cf\u8ddd\u79bb\uff0c\u5c06\u7b56\u7565\u8f93\u51fa\u6620\u5c04\u5230\u771f\u5b9e\u4e16\u754c\u5750\u6807\u4e2d\uff0c\u89e3\u51b3\u4e86\u751f\u6210\u5bfc\u822a\u7b56\u7565\u4e2d\u7684\u5c3a\u5ea6\u95ee\u9898\u548c\u77ed\u89c6\u884c\u4e3a\u95ee\u9898\u3002", "motivation": "\u751f\u6210\u5f0f\u5bfc\u822a\u7b56\u7565\u5b58\u5728\u4e24\u4e2a\u7ed3\u6784\u6027\u95ee\u9898\uff1a1\uff09\u91c7\u6837\u8f68\u8ff9\u5b58\u5728\u4e8e\u62bd\u8c61\u7684\u65e0\u5c3a\u5ea6\u7a7a\u95f4\u4e2d\uff0c\u7f3a\u4e4f\u5ea6\u91cf\u57fa\u7840\uff1b2\uff09\u63a7\u5236\u7b56\u7565\u4e22\u5f03\u5b8c\u6574\u8def\u5f84\uff0c\u53ea\u671d\u5411\u5355\u4e2a\u8def\u5f84\u70b9\u79fb\u52a8\uff0c\u5bfc\u81f4\u77ed\u89c6\u548c\u4e0d\u5b89\u5168\u7684\u52a8\u4f5c\u3002", "method": "\u63d0\u51faMetricNet\u4f5c\u4e3a\u751f\u6210\u5f0f\u5bfc\u822a\u7684\u9644\u52a0\u6a21\u5757\uff0c\u9884\u6d4b\u8def\u5f84\u70b9\u4e4b\u95f4\u7684\u5ea6\u91cf\u8ddd\u79bb\uff0c\u5c06\u7b56\u7565\u8f93\u51fa\u6620\u5c04\u5230\u771f\u5b9e\u4e16\u754c\u5750\u6807\u3002\u8fdb\u4e00\u6b65\u63d0\u51faMetricNav\uff0c\u5c06MetricNet\u96c6\u6210\u5230\u5bfc\u822a\u7b56\u7565\u4e2d\uff0c\u5f15\u5bfc\u673a\u5668\u4eba\u907f\u5f00\u969c\u788d\u7269\u540c\u65f6\u671d\u5411\u76ee\u6807\u79fb\u52a8\u3002", "result": "\u5728\u4eff\u771f\u73af\u5883\u4e2d\u4f7f\u7528\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u8fdb\u884c\u8bc4\u4f30\uff0c\u663e\u793a\u6267\u884cMetricNet\u7f29\u653e\u7684\u8def\u5f84\u70b9\u663e\u8457\u63d0\u9ad8\u4e86\u5bfc\u822a\u548c\u63a2\u7d22\u6027\u80fd\u3002\u5728\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "MetricNet\u901a\u8fc7\u63d0\u4f9b\u5ea6\u91cf\u57fa\u7840\u89e3\u51b3\u4e86\u751f\u6210\u5f0f\u5bfc\u822a\u7684\u5173\u952e\u95ee\u9898\uff0cMetricNav\u7684\u96c6\u6210\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u5bfc\u822a\u7684\u5b89\u5168\u6027\u548c\u6709\u6548\u6027\uff0c\u4e3a\u751f\u6210\u5f0f\u5bfc\u822a\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13972", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13972", "abs": "https://arxiv.org/abs/2509.13972", "authors": ["Asier Bikandi", "Miguel Fernandez-Cortizas", "Muhammad Shaheer", "Ali Tourani", "Holger Voos", "Jose Luis Sanchez-Lopez"], "title": "BIM Informed Visual SLAM for Construction Monitoring", "comment": "8 pages, 5 tables, 4 figures", "summary": "Simultaneous Localization and Mapping (SLAM) is a key tool for monitoring\nconstruction sites, where aligning the evolving as-built state with the\nas-planned design enables early error detection and reduces costly rework.\nLiDAR-based SLAM achieves high geometric precision, but its sensors are\ntypically large and power-demanding, limiting their use on portable platforms.\nVisual SLAM offers a practical alternative with lightweight cameras already\nembedded in most mobile devices. however, visually mapping construction\nenvironments remains challenging: repetitive layouts, occlusions, and\nincomplete or low-texture structures often cause drift in the trajectory map.\nTo mitigate this, we propose an RGB-D SLAM system that incorporates the\nBuilding Information Model (BIM) as structural prior knowledge. Instead of\nrelying solely on visual cues, our system continuously establishes\ncorrespondences between detected wall and their BIM counterparts, which are\nthen introduced as constraints in the back-end optimization. The proposed\nmethod operates in real time and has been validated on real construction sites,\nreducing trajectory error by an average of 23.71% and map RMSE by 7.14%\ncompared to visual SLAM baselines. These results demonstrate that BIM\nconstraints enable reliable alignment of the digital plan with the as-built\nscene, even under partially constructed conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408BIM\u7ed3\u6784\u5148\u9a8c\u77e5\u8bc6\u7684RGB-D SLAM\u7cfb\u7edf\uff0c\u901a\u8fc7\u5728\u4f18\u5316\u540e\u7aef\u5f15\u5165BIM\u7ea6\u675f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u65bd\u5de5\u73af\u5883\u4e0b\u7684\u89c6\u89c9SLAM\u7cbe\u5ea6\u3002", "motivation": "\u65bd\u5de5\u73af\u5883\u4e2d\u7684\u89c6\u89c9SLAM\u9762\u4e34\u91cd\u590d\u5e03\u5c40\u3001\u906e\u6321\u548c\u4f4e\u7eb9\u7406\u7ed3\u6784\u7b49\u6311\u6218\uff0c\u5bb9\u6613\u5bfc\u81f4\u8f68\u8ff9\u6f02\u79fb\u3002LiDAR SLAM\u867d\u7136\u7cbe\u5ea6\u9ad8\u4f46\u8bbe\u5907\u7b28\u91cd\u8017\u7535\uff0c\u9700\u8981\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528RGB-D SLAM\u7cfb\u7edf\uff0c\u5c06BIM\u6a21\u578b\u4f5c\u4e3a\u7ed3\u6784\u5148\u9a8c\u77e5\u8bc6\uff0c\u6301\u7eed\u5efa\u7acb\u68c0\u6d4b\u5230\u7684\u5899\u9762\u4e0eBIM\u5bf9\u5e94\u5173\u7cfb\uff0c\u5e76\u5c06\u8fd9\u4e9b\u5bf9\u5e94\u5173\u7cfb\u4f5c\u4e3a\u7ea6\u675f\u5f15\u5165\u540e\u7aef\u4f18\u5316\u8fc7\u7a0b\u3002", "result": "\u5728\u771f\u5b9e\u65bd\u5de5\u73b0\u573a\u9a8c\u8bc1\uff0c\u5e73\u5747\u51cf\u5c11\u8f68\u8ff9\u8bef\u5dee23.71%\uff0c\u5730\u56feRMSE\u964d\u4f4e7.14%\uff0c\u76f8\u6bd4\u89c6\u89c9SLAM\u57fa\u7ebf\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "BIM\u7ea6\u675f\u80fd\u591f\u5728\u90e8\u5206\u65bd\u5de5\u6761\u4ef6\u4e0b\u53ef\u9760\u5730\u5bf9\u9f50\u6570\u5b57\u89c4\u5212\u4e0e\u5b9e\u9645\u573a\u666f\uff0c\u4e3a\u65bd\u5de5\u76d1\u63a7\u63d0\u4f9b\u4e86\u6709\u6548\u7684SLAM\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13998", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.13998", "abs": "https://arxiv.org/abs/2509.13998", "authors": ["Bailey Dacre", "Rodrigo Moreno", "Serhat Demirtas", "Ziqiao Wang", "Yuhao Jiang", "Jamie Paik", "Kasper Stoy", "Andr\u00e9s Fa\u00ed\u00f1a"], "title": "Flexible and Foldable: Workspace Analysis and Object Manipulation Using a Soft, Interconnected, Origami-Inspired Actuator Array", "comment": null, "summary": "Object manipulation is a fundamental challenge in robotics, where systems\nmust balance trade-offs among manipulation capabilities, system complexity, and\nthroughput. Distributed manipulator systems (DMS) use the coordinated motion of\nactuator arrays to perform complex object manipulation tasks, seeing widespread\nexploration within the literature and in industry. However, existing DMS\ndesigns typically rely on high actuator densities and impose constraints on\nobject-to-actuator scale ratios, limiting their adaptability. We present a\nnovel DMS design utilizing an array of 3-DoF, origami-inspired robotic tiles\ninterconnected by a compliant surface layer. Unlike conventional DMS, our\napproach enables manipulation not only at the actuator end effectors but also\nacross a flexible surface connecting all actuators; creating a continuous,\ncontrollable manipulation surface. We analyse the combined workspace of such a\nsystem, derive simple motion primitives, and demonstrate its capabilities to\ntranslate simple geometric objects across an array of tiles. By leveraging the\ninter-tile connective material, our approach significantly reduces actuator\ndensity, increasing the area over which an object can be manipulated by x1.84\nwithout an increase in the number of actuators. This design offers a lower cost\nand complexity alternative to traditional high-density arrays, and introduces\nnew opportunities for manipulation strategies that leverage the flexibility of\nthe interconnected surface.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u5206\u5e03\u5f0f\u673a\u68b0\u624b\u7cfb\u7edf\uff0c\u4f7f\u75283\u81ea\u7531\u5ea6\u6298\u7eb8\u542f\u53d1\u7684\u673a\u5668\u4eba\u74e6\u7247\u9635\u5217\u548c\u67d4\u6027\u8fde\u63a5\u8868\u9762\uff0c\u663e\u8457\u964d\u4f4e\u6267\u884c\u5668\u5bc6\u5ea6\uff0c\u6269\u5927\u64cd\u4f5c\u8303\u56f41.84\u500d", "motivation": "\u73b0\u6709\u5206\u5e03\u5f0f\u673a\u68b0\u624b\u7cfb\u7edf\u4f9d\u8d56\u9ad8\u6267\u884c\u5668\u5bc6\u5ea6\u4e14\u5bf9\u7269\u4f53-\u6267\u884c\u5668\u5c3a\u5bf8\u6bd4\u6709\u7ea6\u675f\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u3002\u9700\u8981\u4e00\u79cd\u6210\u672c\u66f4\u4f4e\u3001\u590d\u6742\u5ea6\u66f4\u4f4e\u7684\u66ff\u4ee3\u65b9\u6848", "method": "\u4f7f\u75283-DoF\u6298\u7eb8\u542f\u53d1\u673a\u5668\u4eba\u74e6\u7247\u9635\u5217\uff0c\u901a\u8fc7\u67d4\u6027\u8868\u9762\u5c42\u8fde\u63a5\uff0c\u4e0d\u4ec5\u80fd\u5728\u6267\u884c\u5668\u672b\u7aef\u64cd\u4f5c\uff0c\u8fd8\u80fd\u5728\u6574\u4e2a\u8fde\u63a5\u8868\u9762\u4e0a\u8fdb\u884c\u8fde\u7eed\u53ef\u63a7\u64cd\u4f5c", "result": "\u7cfb\u7edf\u80fd\u591f\u64cd\u4f5c\u7b80\u5355\u51e0\u4f55\u7269\u4f53\u5728\u74e6\u7247\u9635\u5217\u4e0a\u79fb\u52a8\uff0c\u6267\u884c\u5668\u5bc6\u5ea6\u663e\u8457\u964d\u4f4e\uff0c\u64cd\u4f5c\u9762\u79ef\u589e\u52a01.84\u500d\u800c\u4e0d\u589e\u52a0\u6267\u884c\u5668\u6570\u91cf", "conclusion": "\u8be5\u8bbe\u8ba1\u4e3a\u4f20\u7edf\u9ad8\u5bc6\u5ea6\u9635\u5217\u63d0\u4f9b\u4e86\u4f4e\u6210\u672c\u3001\u4f4e\u590d\u6742\u5ea6\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5e76\u5f15\u5165\u4e86\u5229\u7528\u4e92\u8054\u8868\u9762\u67d4\u6027\u7684\u65b0\u64cd\u4f5c\u7b56\u7565\u673a\u4f1a"}}
{"id": "2509.14010", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.14010", "abs": "https://arxiv.org/abs/2509.14010", "authors": ["Zong Chen", "Shaoyang Li", "Ben Liu", "Min Li", "Zhouping Yin", "Yiqun Li"], "title": "Whole-body Motion Control of an Omnidirectional Wheel-Legged Mobile Manipulator via Contact-Aware Dynamic Optimization", "comment": null, "summary": "Wheel-legged robots with integrated manipulators hold great promise for\nmobile manipulation in logistics, industrial automation, and human-robot\ncollaboration. However, unified control of such systems remains challenging due\nto the redundancy in degrees of freedom, complex wheel-ground contact dynamics,\nand the need for seamless coordination between locomotion and manipulation. In\nthis work, we present the design and whole-body motion control of an\nomnidirectional wheel-legged quadrupedal robot equipped with a dexterous\nmanipulator. The proposed platform incorporates independently actuated steering\nmodules and hub-driven wheels, enabling agile omnidirectional locomotion with\nhigh maneuverability in structured environments. To address the challenges of\ncontact-rich interaction, we develop a contact-aware whole-body dynamic\noptimization framework that integrates point-contact modeling for manipulation\nwith line-contact modeling for wheel-ground interactions. A warm-start strategy\nis introduced to accelerate online optimization, ensuring real-time feasibility\nfor high-dimensional control. Furthermore, a unified kinematic model tailored\nfor the robot's 4WIS-4WID actuation scheme eliminates the need for mode\nswitching across different locomotion strategies, improving control consistency\nand robustness. Simulation and experimental results validate the effectiveness\nof the proposed framework, demonstrating agile terrain traversal, high-speed\nomnidirectional mobility, and precise manipulation under diverse scenarios,\nunderscoring the system's potential for factory automation, urban logistics,\nand service robotics in semi-structured environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8f6e\u817f\u5f0f\u56db\u8db3\u673a\u5668\u4eba\u5168\u8eab\u8fd0\u52a8\u63a7\u5236\u7684\u63a5\u89e6\u611f\u77e5\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u79fb\u52a8\u64cd\u4f5c\u4e2d\u7684\u5197\u4f59\u63a7\u5236\u548c\u590d\u6742\u63a5\u89e6\u52a8\u529b\u5b66\u95ee\u9898", "motivation": "\u8f6e\u817f\u5f0f\u673a\u5668\u4eba\u7ed3\u5408\u673a\u68b0\u81c2\u5728\u7269\u6d41\u3001\u5de5\u4e1a\u81ea\u52a8\u5316\u548c\u4eba\u673a\u534f\u4f5c\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u81ea\u7531\u5ea6\u5197\u4f59\u3001\u8f6e\u5730\u63a5\u89e6\u52a8\u529b\u5b66\u590d\u6742\u4ee5\u53ca\u9700\u8981\u534f\u8c03\u8fd0\u52a8\u548c\u64cd\u4f5c\uff0c\u7edf\u4e00\u63a7\u5236\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027", "method": "\u5f00\u53d1\u4e86\u63a5\u89e6\u611f\u77e5\u5168\u8eab\u52a8\u6001\u4f18\u5316\u6846\u67b6\uff0c\u96c6\u6210\u4e86\u64cd\u4f5c\u7684\u70b9\u63a5\u89e6\u5efa\u6a21\u548c\u8f6e\u5730\u4ea4\u4e92\u7684\u7ebf\u63a5\u89e6\u5efa\u6a21\uff1b\u5f15\u5165\u70ed\u542f\u52a8\u7b56\u7565\u52a0\u901f\u5728\u7ebf\u4f18\u5316\uff1b\u4e3a4WIS-4WID\u9a71\u52a8\u65b9\u6848\u5b9a\u5236\u7edf\u4e00\u8fd0\u52a8\u5b66\u6a21\u578b", "result": "\u4eff\u771f\u548c\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u654f\u6377\u5730\u5f62\u7a7f\u8d8a\u3001\u9ad8\u901f\u5168\u5411\u79fb\u52a8\u548c\u7cbe\u786e\u64cd\u4f5c\u80fd\u529b", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u5de5\u5382\u81ea\u52a8\u5316\u3001\u57ce\u5e02\u7269\u6d41\u548c\u534a\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7684\u670d\u52a1\u673a\u5668\u4eba\u9886\u57df\u5177\u6709\u5de8\u5927\u5e94\u7528\u6f5c\u529b"}}
{"id": "2509.14025", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.14025", "abs": "https://arxiv.org/abs/2509.14025", "authors": ["Rui Huang", "Zhiyu Gao", "Siyu Tang", "Jialin Zhang", "Lei He", "Ziqian Zhang", "Lin Zhao"], "title": "TransforMARS: Fault-Tolerant Self-Reconfiguration for Arbitrarily Shaped Modular Aerial Robot Systems", "comment": null, "summary": "Modular Aerial Robot Systems (MARS) consist of multiple drone modules that\nare physically bound together to form a single structure for flight. Exploiting\nstructural redundancy, MARS can be reconfigured into different formations to\nmitigate unit or rotor failures and maintain stable flight. Prior work on MARS\nself-reconfiguration has solely focused on maximizing controllability margins\nto tolerate a single rotor or unit fault for rectangular-shaped MARS. We\npropose TransforMARS, a general fault-tolerant reconfiguration framework that\ntransforms arbitrarily shaped MARS under multiple rotor and unit faults while\nensuring continuous in-air stability. Specifically, we develop algorithms to\nfirst identify and construct minimum controllable assemblies containing faulty\nunits. We then plan feasible disassembly-assembly sequences to transport MARS\nunits or subassemblies to form target configuration. Our approach enables more\nflexible and practical feasible reconfiguration. We validate TransforMARS in\nchallenging arbitrarily shaped MARS configurations, demonstrating substantial\nimprovements over prior works in both the capacity of handling diverse\nconfigurations and the number of faults tolerated. The videos and source code\nof this work are available at the anonymous repository:\nhttps://anonymous.4open.science/r/TransforMARS-1030/", "AI": {"tldr": "TransforMARS\u662f\u4e00\u4e2a\u901a\u7528\u7684\u6545\u969c\u5bb9\u5fcd\u91cd\u6784\u6846\u67b6\uff0c\u80fd\u591f\u5904\u7406\u4efb\u610f\u5f62\u72b6\u7684\u6a21\u5757\u5316\u7a7a\u4e2d\u673a\u5668\u4eba\u7cfb\u7edf\u5728\u591a\u4e2a\u8f6c\u5b50\u548c\u5355\u5143\u6545\u969c\u60c5\u51b5\u4e0b\u7684\u91cd\u6784\uff0c\u540c\u65f6\u786e\u4fdd\u7a7a\u4e2d\u7a33\u5b9a\u6027", "motivation": "\u73b0\u6709\u7684MARS\u81ea\u91cd\u6784\u65b9\u6cd5\u4ec5\u5173\u6ce8\u6700\u5927\u5316\u77e9\u5f62\u5f62\u72b6\u7cfb\u7edf\u7684\u53ef\u63a7\u6027\u88d5\u5ea6\u6765\u5bb9\u5fcd\u5355\u4e2a\u6545\u969c\uff0c\u65e0\u6cd5\u5904\u7406\u4efb\u610f\u5f62\u72b6\u914d\u7f6e\u548c\u591a\u4e2a\u6545\u969c\u7684\u60c5\u51b5", "method": "\u5f00\u53d1\u7b97\u6cd5\u9996\u5148\u8bc6\u522b\u548c\u6784\u5efa\u5305\u542b\u6545\u969c\u5355\u5143\u7684\u6700\u5c0f\u53ef\u63a7\u7ec4\u4ef6\uff0c\u7136\u540e\u89c4\u5212\u53ef\u884c\u7684\u62c6\u5378-\u7ec4\u88c5\u5e8f\u5217\u6765\u8fd0\u8f93MARS\u5355\u5143\u6216\u5b50\u7ec4\u4ef6\u4ee5\u5f62\u6210\u76ee\u6807\u914d\u7f6e", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u610f\u5f62\u72b6MARS\u914d\u7f6e\u4e2d\u9a8c\u8bc1\u4e86TransforMARS\uff0c\u5728\u5904\u7406\u591a\u6837\u5316\u914d\u7f6e\u80fd\u529b\u548c\u5bb9\u5fcd\u6545\u969c\u6570\u91cf\u65b9\u9762\u76f8\u6bd4\u5148\u524d\u5de5\u4f5c\u6709\u663e\u8457\u6539\u8fdb", "conclusion": "TransforMARS\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u5b9e\u7528\u7684\u53ef\u884c\u91cd\u6784\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u591a\u4e2a\u8f6c\u5b50\u548c\u5355\u5143\u6545\u969c\uff0c\u540c\u65f6\u4fdd\u6301\u8fde\u7eed\u7a7a\u4e2d\u7a33\u5b9a\u6027"}}
{"id": "2509.14063", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.14063", "abs": "https://arxiv.org/abs/2509.14063", "authors": ["Sundhar Vinodh Sangeetha", "Chih-Yuan Chiu", "Sarah H. Q. Li", "Shreyas Kousik"], "title": "Language Conditioning Improves Accuracy of Aircraft Goal Prediction in Untowered Airspace", "comment": "The last two authors advised equally. Submitted to the 2026 IEEE\n  International Conference on Robotics and Automation. 8 pages, 6 figures", "summary": "Autonomous aircraft must safely operate in untowered airspace, where\ncoordination relies on voice-based communication among human pilots. Safe\noperation requires an aircraft to predict the intent, and corresponding goal\nlocation, of other aircraft. This paper introduces a multimodal framework for\naircraft goal prediction that integrates natural language understanding with\nspatial reasoning to improve autonomous decision-making in such environments.\nWe leverage automatic speech recognition and large language models to\ntranscribe and interpret pilot radio calls, identify aircraft, and extract\ndiscrete intent labels. These intent labels are fused with observed\ntrajectories to condition a temporal convolutional network and Gaussian mixture\nmodel for probabilistic goal prediction. Our method significantly reduces goal\nprediction error compared to baselines that rely solely on motion history,\ndemonstrating that language-conditioned prediction increases prediction\naccuracy. Experiments on a real-world dataset from an untowered airport\nvalidate the approach and highlight its potential to enable socially aware,\nlanguage-conditioned robotic motion planning.", "AI": {"tldr": "\u63d0\u51fa\u591a\u6a21\u6001\u6846\u67b6\u6574\u5408\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u7a7a\u95f4\u63a8\u7406\uff0c\u901a\u8fc7\u8bed\u97f3\u8bc6\u522b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u89e3\u6790\u98de\u884c\u5458\u65e0\u7ebf\u7535\u901a\u8bdd\uff0c\u7ed3\u5408\u8f68\u8ff9\u6570\u636e\u9884\u6d4b\u98de\u673a\u76ee\u6807\u4f4d\u7f6e\uff0c\u663e\u8457\u964d\u4f4e\u9884\u6d4b\u8bef\u5dee", "motivation": "\u5728\u65e0\u5854\u53f0\u7a7a\u57df\u4e2d\uff0c\u81ea\u4e3b\u98de\u673a\u9700\u8981\u5b89\u5168\u8fd0\u884c\uff0c\u4f46\u534f\u8c03\u4f9d\u8d56\u98de\u884c\u5458\u95f4\u7684\u8bed\u97f3\u901a\u4fe1\u3002\u51c6\u786e\u9884\u6d4b\u5176\u4ed6\u98de\u673a\u7684\u610f\u56fe\u548c\u76ee\u6807\u4f4d\u7f6e\u5bf9\u5b89\u5168\u64cd\u4f5c\u81f3\u5173\u91cd\u8981", "method": "\u4f7f\u7528\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f6c\u5f55\u89e3\u6790\u65e0\u7ebf\u7535\u901a\u8bdd\uff0c\u63d0\u53d6\u79bb\u6563\u610f\u56fe\u6807\u7b7e\uff0c\u5c06\u8fd9\u4e9b\u6807\u7b7e\u4e0e\u89c2\u6d4b\u8f68\u8ff9\u878d\u5408\uff0c\u4f7f\u7528\u65f6\u5e8f\u5377\u79ef\u7f51\u7edc\u548c\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u8fdb\u884c\u6982\u7387\u6027\u76ee\u6807\u9884\u6d4b", "result": "\u76f8\u6bd4\u4ec5\u4f9d\u8d56\u8fd0\u52a8\u5386\u53f2\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u76ee\u6807\u9884\u6d4b\u8bef\u5dee\uff0c\u8bc1\u660e\u4e86\u8bed\u8a00\u6761\u4ef6\u9884\u6d4b\u80fd\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027", "conclusion": "\u5728\u771f\u5b9e\u65e0\u5854\u53f0\u673a\u573a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u73b0\u793e\u4f1a\u611f\u77e5\u3001\u8bed\u8a00\u6761\u4ef6\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u65b9\u9762\u7684\u6f5c\u529b"}}
{"id": "2509.14082", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.14082", "abs": "https://arxiv.org/abs/2509.14082", "authors": ["Valerii Serpiva", "Artem Lykov", "Faryal Batool", "Vladislav Kozlovskiy", "Miguel Altamirano Cabrera", "Dzmitry Tsetserukou"], "title": "FlightDiffusion: Revolutionising Autonomous Drone Training with Diffusion Models Generating FPV Video", "comment": "Submitted to conference", "summary": "We present FlightDiffusion, a diffusion-model-based framework for training\nautonomous drones from first-person view (FPV) video. Our model generates\nrealistic video sequences from a single frame, enriched with corresponding\naction spaces to enable reasoning-driven navigation in dynamic environments.\nBeyond direct policy learning, FlightDiffusion leverages its generative\ncapabilities to synthesize diverse FPV trajectories and state-action pairs,\nfacilitating the creation of large-scale training datasets without the high\ncost of real-world data collection. Our evaluation demonstrates that the\ngenerated trajectories are physically plausible and executable, with a mean\nposition error of 0.25 m (RMSE 0.28 m) and a mean orientation error of 0.19 rad\n(RMSE 0.24 rad). This approach enables improved policy learning and dataset\nscalability, leading to superior performance in downstream navigation tasks.\nResults in simulated environments highlight enhanced robustness, smoother\ntrajectory planning, and adaptability to unseen conditions. An ANOVA revealed\nno statistically significant difference between performance in simulation and\nreality (F(1, 16) = 0.394, p = 0.541), with success rates of M = 0.628 (SD =\n0.162) and M = 0.617 (SD = 0.177), respectively, indicating strong sim-to-real\ntransfer. The generated datasets provide a valuable resource for future UAV\nresearch. This work introduces diffusion-based reasoning as a promising\nparadigm for unifying navigation, action generation, and data synthesis in\naerial robotics.", "AI": {"tldr": "FlightDiffusion\u662f\u4e00\u4e2a\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u89c6\u9891\u8bad\u7ec3\u81ea\u4e3b\u65e0\u4eba\u673a\uff0c\u80fd\u591f\u751f\u6210\u903c\u771f\u7684\u89c6\u9891\u5e8f\u5217\u548c\u5bf9\u5e94\u7684\u52a8\u4f5c\u7a7a\u95f4\uff0c\u652f\u6301\u63a8\u7406\u9a71\u52a8\u7684\u5bfc\u822a\u548c\u5927\u89c4\u6a21\u6570\u636e\u96c6\u5408\u6210\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u65e0\u4eba\u673a\u81ea\u4e3b\u5bfc\u822a\u4e2d\u771f\u5b9e\u4e16\u754c\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u3001\u6570\u636e\u96c6\u89c4\u6a21\u6709\u9650\u7684\u95ee\u9898\uff0c\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u751f\u6210\u591a\u6837\u5316FPV\u8f68\u8ff9\u548c\u72b6\u6001-\u52a8\u4f5c\u5bf9\u7684\u6846\u67b6\uff0c\u4ee5\u4fc3\u8fdb\u7b56\u7565\u5b66\u4e60\u548c\u6570\u636e\u96c6\u6269\u5c55\u3002", "method": "\u91c7\u7528\u6269\u6563\u6a21\u578b\u6846\u67b6\uff0c\u4ece\u5355\u5e27\u56fe\u50cf\u751f\u6210\u903c\u771f\u7684\u89c6\u9891\u5e8f\u5217\uff0c\u5e76\u540c\u65f6\u751f\u6210\u5bf9\u5e94\u7684\u52a8\u4f5c\u7a7a\u95f4\u3002\u5229\u7528\u751f\u6210\u80fd\u529b\u5408\u6210\u591a\u6837\u5316\u7684FPV\u8f68\u8ff9\u548c\u72b6\u6001-\u52a8\u4f5c\u5bf9\uff0c\u521b\u5efa\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u96c6\u3002", "result": "\u751f\u6210\u7684\u8f68\u8ff9\u5177\u6709\u7269\u7406\u53ef\u884c\u6027\u548c\u53ef\u6267\u884c\u6027\uff0c\u5e73\u5747\u4f4d\u7f6e\u8bef\u5dee0.25\u7c73\uff0c\u5e73\u5747\u65b9\u5411\u8bef\u5dee0.19\u5f27\u5ea6\u3002\u5728\u6a21\u62df\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u589e\u5f3a\u7684\u9c81\u68d2\u6027\u3001\u66f4\u5e73\u6ed1\u7684\u8f68\u8ff9\u89c4\u5212\u548c\u66f4\u597d\u7684\u9002\u5e94\u6027\u3002\u4eff\u771f\u4e0e\u73b0\u5b9e\u6027\u80fd\u65e0\u663e\u8457\u5dee\u5f02\uff08p=0.541\uff09\uff0c\u6210\u529f\u7387\u5206\u522b\u4e3a0.628\u548c0.617\u3002", "conclusion": "FlightDiffusion\u5c55\u793a\u4e86\u6269\u6563\u57fa\u63a8\u7406\u4f5c\u4e3a\u7edf\u4e00\u5bfc\u822a\u3001\u52a8\u4f5c\u751f\u6210\u548c\u6570\u636e\u5408\u6210\u7684\u6709\u524d\u666f\u8303\u5f0f\uff0c\u4e3a\u65e0\u4eba\u673a\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u8d44\u6e90\uff0c\u5e76\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u4eff\u771f\u5230\u73b0\u5b9e\u8fc1\u79fb\u3002"}}
{"id": "2509.14117", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.14117", "abs": "https://arxiv.org/abs/2509.14117", "authors": ["Ali Abouzeid", "Malak Mansour", "Zezhou Sun", "Dezhen Song"], "title": "GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model", "comment": "Under Review", "summary": "Vision-Language-Action (VLA) models often fail to generalize to novel camera\nviewpoints, a limitation stemming from their difficulty in inferring robust 3D\ngeometry from 2D images. We introduce GeoAware-VLA, a simple yet effective\napproach that enhances viewpoint invariance by integrating strong geometric\npriors into the vision backbone. Instead of training a visual encoder or\nrelying on explicit 3D data, we leverage a frozen, pretrained geometric vision\nmodel as a feature extractor. A trainable projection layer then adapts these\ngeometrically-rich features for the policy decoder, relieving it of the burden\nof learning 3D consistency from scratch. Through extensive evaluations on\nLIBERO benchmark subsets, we show GeoAware-VLA achieves substantial\nimprovements in zero-shot generalization to novel camera poses, boosting\nsuccess rates by over 2x in simulation. Crucially, these benefits translate to\nthe physical world; our model shows a significant performance gain on a real\nrobot, especially when evaluated from unseen camera angles. Our approach proves\neffective across both continuous and discrete action spaces, highlighting that\nrobust geometric grounding is a key component for creating more generalizable\nrobotic agents.", "AI": {"tldr": "GeoAware-VLA\u901a\u8fc7\u96c6\u6210\u51e0\u4f55\u5148\u9a8c\u77e5\u8bc6\u6765\u589e\u5f3aVLA\u6a21\u578b\u7684\u89c6\u89d2\u4e0d\u53d8\u6027\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u51e0\u4f55\u89c6\u89c9\u6a21\u578b\u63d0\u53d6\u7279\u5f81\uff0c\u901a\u8fc7\u6295\u5f71\u5c42\u9002\u914d\u7b56\u7565\u89e3\u7801\u5668\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u4e0a\u90fd\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u96f6\u6837\u672c\u6cdb\u5316\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684Vision-Language-Action\u6a21\u578b\u5728\u5904\u7406\u65b0\u9896\u76f8\u673a\u89c6\u89d2\u65f6\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u96be\u4ee5\u4ece2D\u56fe\u50cf\u63a8\u65ad\u9c81\u68d2\u76843D\u51e0\u4f55\u7ed3\u6784\u3002", "method": "\u5229\u7528\u51bb\u7ed3\u7684\u9884\u8bad\u7ec3\u51e0\u4f55\u89c6\u89c9\u6a21\u578b\u4f5c\u4e3a\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u901a\u8fc7\u53ef\u8bad\u7ec3\u7684\u6295\u5f71\u5c42\u5c06\u8fd9\u4e9b\u5bcc\u542b\u51e0\u4f55\u4fe1\u606f\u7684\u7279\u5f81\u9002\u914d\u5230\u7b56\u7565\u89e3\u7801\u5668\uff0c\u907f\u514d\u4e86\u4ece\u96f6\u5b66\u4e603D\u4e00\u81f4\u6027\u7684\u8d1f\u62c5\u3002", "result": "\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u5b50\u96c6\u4e0a\uff0cGeoAware-VLA\u5b9e\u73b0\u4e86\u96f6\u6837\u672c\u6cdb\u5316\u5230\u65b0\u9896\u76f8\u673a\u59ff\u6001\u7684\u663e\u8457\u6539\u8fdb\uff0c\u4eff\u771f\u73af\u5883\u4e2d\u6210\u529f\u7387\u63d0\u5347\u8d85\u8fc72\u500d\uff0c\u5728\u771f\u5b9e\u673a\u5668\u4eba\u4e0a\u4ece\u672a\u89c1\u8fc7\u7684\u76f8\u673a\u89d2\u5ea6\u8bc4\u4f30\u65f6\u4e5f\u663e\u793a\u51fa\u663e\u8457\u7684\u6027\u80fd\u589e\u76ca\u3002", "conclusion": "\u9c81\u68d2\u7684\u51e0\u4f55\u57fa\u7840\u662f\u521b\u5efa\u66f4\u5177\u6cdb\u5316\u80fd\u529b\u7684\u673a\u5668\u4eba\u667a\u80fd\u4f53\u7684\u5173\u952e\u7ec4\u4ef6\uff0c\u8be5\u65b9\u6cd5\u5728\u8fde\u7eed\u548c\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u90fd\u8bc1\u660e\u6709\u6548\u3002"}}
{"id": "2509.14126", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.14126", "abs": "https://arxiv.org/abs/2509.14126", "authors": ["Viktor Lorentz", "Khaled Wahba", "Sayantan Auddy", "Marc Toussaint", "Wolfgang H\u00f6nig"], "title": "CrazyMARL: Decentralized Direct Motor Control Policies for Cooperative Aerial Transport of Cable-Suspended Payloads", "comment": "This work has been submitted to IEEE for possible publication", "summary": "Collaborative transportation of cable-suspended payloads by teams of Unmanned\nAerial Vehicles (UAVs) has the potential to enhance payload capacity, adapt to\ndifferent payload shapes, and provide built-in compliance, making it attractive\nfor applications ranging from disaster relief to precision logistics. However,\nmulti-UAV coordination under disturbances, nonlinear payload dynamics, and\nslack--taut cable modes remains a challenging control problem. To our\nknowledge, no prior work has addressed these cable mode transitions in the\nmulti-UAV context, instead relying on simplifying rigid-link assumptions. We\npropose CrazyMARL, a decentralized Reinforcement Learning (RL) framework for\nmulti-UAV cable-suspended payload transport. Simulation results demonstrate\nthat the learned policies can outperform classical decentralized controllers in\nterms of disturbance rejection and tracking precision, achieving an 80%\nrecovery rate from harsh conditions compared to 44% for the baseline method. We\nalso achieve successful zero-shot sim-to-real transfer and demonstrate that our\npolicies are highly robust under harsh conditions, including wind, random\nexternal disturbances, and transitions between slack and taut cable dynamics.\nThis work paves the way for autonomous, resilient UAV teams capable of\nexecuting complex payload missions in unstructured environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aCrazyMARL\u7684\u5206\u6563\u5f0f\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u65e0\u4eba\u673a\u534f\u540c\u8fd0\u8f93\u7f06\u7ef3\u60ac\u6302\u8f7d\u8377\u7684\u63a7\u5236\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u7f06\u7ef3\u677e\u5f1b-\u7ef7\u7d27\u6a21\u5f0f\u8f6c\u6362\u7b49\u590d\u6742\u52a8\u6001\u6761\u4ef6\u4e0b\u7684\u63a7\u5236\u6311\u6218\u3002", "motivation": "\u591a\u65e0\u4eba\u673a\u534f\u540c\u8fd0\u8f93\u7f06\u7ef3\u60ac\u6302\u8f7d\u8377\u5177\u6709\u63d0\u5347\u8f7d\u8377\u80fd\u529b\u3001\u9002\u5e94\u4e0d\u540c\u5f62\u72b6\u8f7d\u8377\u548c\u63d0\u4f9b\u5185\u7f6e\u987a\u5e94\u6027\u7b49\u4f18\u52bf\uff0c\u4f46\u5728\u6270\u52a8\u3001\u975e\u7ebf\u6027\u8f7d\u8377\u52a8\u529b\u5b66\u548c\u7f06\u7ef3\u6a21\u5f0f\u8f6c\u6362\u7b49\u590d\u6742\u6761\u4ef6\u4e0b\uff0c\u4f20\u7edf\u7684\u521a\u6027\u8fde\u63a5\u5047\u8bbe\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u91c7\u7528\u5206\u6563\u5f0f\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6846\u67b6CrazyMARL\uff0c\u901a\u8fc7\u6a21\u62df\u8bad\u7ec3\u5b66\u4e60\u63a7\u5236\u7b56\u7565\uff0c\u80fd\u591f\u5904\u7406\u7f06\u7ef3\u677e\u5f1b-\u7ef7\u7d27\u6a21\u5f0f\u8f6c\u6362\u3001\u98ce\u6270\u548c\u968f\u673a\u5916\u90e8\u5e72\u6270\u7b49\u590d\u6742\u6761\u4ef6\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u5b66\u4e60\u5230\u7684\u7b56\u7565\u5728\u6270\u52a8\u6291\u5236\u548c\u8ddf\u8e2a\u7cbe\u5ea6\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u5206\u6563\u63a7\u5236\u5668\uff0c\u4ece\u6076\u52a3\u6761\u4ef6\u4e0b\u7684\u6062\u590d\u7387\u8fbe\u523080%\uff08\u57fa\u7ebf\u65b9\u6cd5\u4e3a44%\uff09\uff0c\u5e76\u6210\u529f\u5b9e\u73b0\u4e86\u96f6\u6837\u672c\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u8fc1\u79fb\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u81ea\u4e3b\u3001\u5f39\u6027\u7684\u65e0\u4eba\u673a\u56e2\u961f\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u6267\u884c\u590d\u6742\u8f7d\u8377\u4efb\u52a1\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u8bc1\u660e\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u591a\u65e0\u4eba\u673a\u534f\u540c\u63a7\u5236\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.14127", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.14127", "abs": "https://arxiv.org/abs/2509.14127", "authors": ["Alkesh K. Srivastava", "Jared Michael Levin", "Philip Dames"], "title": "Energy Efficient Multi Robot Package Delivery under Capacity-Constraints via Voronoi-Constrained Networks", "comment": null, "summary": "We consider the problem of delivering multiple packages from a single pickup\ndepot to distinct goal locations using a homogeneous fleet of robots with\nlimited carrying capacity. We propose VCST-RCP, a Voronoi-Constrained Steiner\nTree Relay Coordination Planning framework that constructs sparse relay trunks\nusing Steiner tree optimization and then synthesizes robot-level pickup, relay,\nand delivery schedules. This framework reframes relays from incidental\nbyproducts into central elements of coordination, offering a contrast with\ntraditional delivery methods that rely on direct source-to-destination\ntransport. Extensive experiments show consistent improvements of up to 34%\ncompared to conventional baselines, underscoring the benefits of incorporating\nrelays into the delivery process. These improvements translate directly to\nenhanced energy efficiency in multi-robot delivery under capacity constraints,\nproviding a scalable framework for real-world logistics.", "AI": {"tldr": "VCST-RCP\u6846\u67b6\u901a\u8fc7Voronoi\u7ea6\u675f\u7684Steiner\u6811\u4f18\u5316\u6784\u5efa\u7a00\u758f\u4e2d\u7ee7\u4e3b\u5e72\uff0c\u5c06\u4e2d\u7ee7\u4ece\u9644\u5e26\u4ea7\u7269\u8f6c\u53d8\u4e3a\u534f\u8c03\u6838\u5fc3\uff0c\u76f8\u6bd4\u4f20\u7edf\u76f4\u63a5\u8fd0\u8f93\u65b9\u6cd5\u63d0\u5347\u8fbe34%\u7684\u6548\u7387", "motivation": "\u89e3\u51b3\u591a\u673a\u5668\u4eba\u6709\u9650\u8fd0\u8f7d\u80fd\u529b\u4e0b\u7684\u5305\u88f9\u914d\u9001\u95ee\u9898\uff0c\u4f20\u7edf\u76f4\u63a5\u6e90\u5230\u76ee\u7684\u5730\u8fd0\u8f93\u65b9\u6cd5\u6548\u7387\u6709\u9650\uff0c\u9700\u8981\u65b0\u7684\u534f\u8c03\u6846\u67b6\u6765\u63d0\u5347\u591a\u673a\u5668\u4eba\u914d\u9001\u7cfb\u7edf\u7684\u6027\u80fd", "method": "\u63d0\u51faVoronoi\u7ea6\u675fSteiner\u6811\u4e2d\u7ee7\u534f\u8c03\u89c4\u5212\u6846\u67b6\uff0c\u4f7f\u7528Steiner\u6811\u4f18\u5316\u6784\u5efa\u7a00\u758f\u4e2d\u7ee7\u4e3b\u5e72\uff0c\u7136\u540e\u5408\u6210\u673a\u5668\u4eba\u7ea7\u522b\u7684\u62fe\u53d6\u3001\u4e2d\u7ee7\u548c\u914d\u9001\u8c03\u5ea6\u8ba1\u5212", "result": "\u5b9e\u9a8c\u663e\u793a\u76f8\u6bd4\u4f20\u7edf\u57fa\u7ebf\u65b9\u6cd5\u6709\u9ad8\u8fbe34%\u7684\u6301\u7eed\u6539\u8fdb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bb9\u91cf\u7ea6\u675f\u4e0b\u591a\u673a\u5668\u4eba\u914d\u9001\u7684\u80fd\u6e90\u6548\u7387", "conclusion": "\u5c06\u4e2d\u7ee7\u7eb3\u5165\u914d\u9001\u8fc7\u7a0b\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u7269\u6d41\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u4e2d\u7ee7\u534f\u8c03\u662f\u63d0\u5347\u591a\u673a\u5668\u4eba\u914d\u9001\u7cfb\u7edf\u6027\u80fd\u7684\u6709\u6548\u7b56\u7565"}}
{"id": "2509.14138", "categories": ["cs.RO", "68T40"], "pdf": "https://arxiv.org/pdf/2509.14138", "abs": "https://arxiv.org/abs/2509.14138", "authors": ["Ran Yang", "Zijian An", "Lifeng ZHou", "Yiming Feng"], "title": "SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model", "comment": "8 pages, 9 figures, 1 table", "summary": "Long-horizon robotic manipulation tasks require executing multiple\ninterdependent subtasks in strict sequence, where errors in detecting subtask\ncompletion can cascade into downstream failures. Existing\nVision-Language-Action (VLA) models such as $\\pi_0$ excel at continuous\nlow-level control but lack an internal signal for identifying when a subtask\nhas finished, making them brittle in sequential settings. We propose SeqVLA, a\ncompletion-aware extension of $\\pi_0$ that augments the base architecture with\na lightweight detection head perceiving whether the current subtask is\ncomplete. This dual-head design enables SeqVLA not only to generate\nmanipulation actions but also to autonomously trigger transitions between\nsubtasks. We investigate four finetuning strategies that vary in how the action\nand detection heads are optimized (joint vs. sequential finetuning) and how\npretrained knowledge is preserved (full finetuning vs. frozen backbone).\nExperiments are performed on two multi-stage tasks: salad packing with seven\ndistinct subtasks and candy packing with four distinct subtasks. Results show\nthat SeqVLA significantly outperforms the baseline $\\pi_0$ and other strong\nbaselines in overall success rate. In particular, joint finetuning with an\nunfrozen backbone yields the most decisive and statistically reliable\ncompletion predictions, eliminating sequence-related failures and enabling\nrobust long-horizon execution. Our results highlight the importance of coupling\naction generation with subtask-aware detection for scalable sequential\nmanipulation.", "AI": {"tldr": "SeqVLA\u662f\u03c0\u2080\u6a21\u578b\u7684\u6269\u5c55\uff0c\u901a\u8fc7\u6dfb\u52a0\u8f7b\u91cf\u7ea7\u68c0\u6d4b\u5934\u6765\u611f\u77e5\u5b50\u4efb\u52a1\u5b8c\u6210\u72b6\u6001\uff0c\u5b9e\u73b0\u81ea\u4e3b\u5b50\u4efb\u52a1\u8f6c\u6362\uff0c\u663e\u8457\u63d0\u5347\u591a\u9636\u6bb5\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u7684\u6210\u529f\u7387", "motivation": "\u73b0\u6709\u7684VLA\u6a21\u578b\u5982\u03c0\u2080\u64c5\u957f\u8fde\u7eed\u4f4e\u7ea7\u63a7\u5236\uff0c\u4f46\u7f3a\u4e4f\u8bc6\u522b\u5b50\u4efb\u52a1\u5b8c\u6210\u7684\u5185\u5728\u4fe1\u53f7\uff0c\u5728\u987a\u5e8f\u6267\u884c\u4efb\u52a1\u65f6\u5bb9\u6613\u56e0\u9519\u8bef\u7d2f\u79ef\u800c\u5931\u8d25", "method": "\u5728\u03c0\u2080\u57fa\u7840\u67b6\u6784\u4e0a\u589e\u52a0\u8f7b\u91cf\u7ea7\u68c0\u6d4b\u5934\uff0c\u5f62\u6210\u53cc\u5934\u8bbe\u8ba1\uff0c\u7814\u7a76\u56db\u79cd\u5fae\u8c03\u7b56\u7565\uff08\u8054\u5408vs\u987a\u5e8f\u5fae\u8c03\uff0c\u5168\u5fae\u8c03vs\u51bb\u7ed3\u4e3b\u5e72\u7f51\u7edc\uff09", "result": "\u5728\u6c99\u62c9\u5305\u88c5\uff087\u4e2a\u5b50\u4efb\u52a1\uff09\u548c\u7cd6\u679c\u5305\u88c5\uff084\u4e2a\u5b50\u4efb\u52a1\uff09\u5b9e\u9a8c\u4e2d\uff0cSeqVLA\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u03c0\u2080\u548c\u5176\u4ed6\u5f3a\u57fa\u7ebf\uff0c\u8054\u5408\u5fae\u8c03+\u975e\u51bb\u7ed3\u4e3b\u5e72\u7f51\u7edc\u83b7\u5f97\u6700\u53ef\u9760\u7684\u5b8c\u6210\u9884\u6d4b", "conclusion": "\u5c06\u52a8\u4f5c\u751f\u6210\u4e0e\u5b50\u4efb\u52a1\u611f\u77e5\u68c0\u6d4b\u76f8\u7ed3\u5408\u5bf9\u4e8e\u53ef\u6269\u5c55\u7684\u987a\u5e8f\u64cd\u4f5c\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u6d88\u9664\u5e8f\u5217\u76f8\u5173\u6545\u969c\u5e76\u5b9e\u73b0\u7a33\u5065\u7684\u957f\u65f6\u7a0b\u6267\u884c"}}
{"id": "2509.14143", "categories": ["cs.RO", "68T40"], "pdf": "https://arxiv.org/pdf/2509.14143", "abs": "https://arxiv.org/abs/2509.14143", "authors": ["Zijian An", "Ran Yang", "Yiming Feng", "Lifeng Zhou"], "title": "CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping", "comment": "8 pages, 5 figures, 1 table", "summary": "Vision-language-action (VLA) models have recently emerged as a promising\nparadigm for robotic control, enabling end-to-end policies that ground natural\nlanguage instructions into visuomotor actions. However, current VLAs often\nstruggle to satisfy precise task constraints, such as stopping based on numeric\nthresholds, since their observation-to-action mappings are implicitly shaped by\ntraining data and lack explicit mechanisms for condition monitoring. In this\nwork, we propose CLAW (CLIP-Language-Action for Weight), a framework that\ndecouples condition evaluation from action generation. CLAW leverages a\nfine-tuned CLIP model as a lightweight prompt generator, which continuously\nmonitors the digital readout of a scale and produces discrete directives based\non task-specific weight thresholds. These prompts are then consumed by $\\pi_0$,\na flow-based VLA policy, which integrates the prompts with multi-view camera\nobservations to produce continuous robot actions. This design enables CLAW to\ncombine symbolic weight reasoning with high-frequency visuomotor control. We\nvalidate CLAW on three experimental setups: single-object grasping and\nmixed-object tasks requiring dual-arm manipulation. Across all conditions, CLAW\nreliably executes weight-aware behaviors and outperforms both raw-$\\pi_0$ and\nfine-tuned $\\pi_0$ models. We have uploaded the videos as supplementary\nmaterials.", "AI": {"tldr": "CLAW\u6846\u67b6\u901a\u8fc7\u89e3\u8026\u6761\u4ef6\u8bc4\u4f30\u548c\u52a8\u4f5c\u751f\u6210\uff0c\u4f7f\u7528\u5fae\u8c03CLIP\u6a21\u578b\u76d1\u63a7\u6570\u5b57\u8bfb\u6570\u5e76\u751f\u6210\u79bb\u6563\u6307\u4ee4\uff0c\u7ed3\u5408VLA\u7b56\u7565\u5b9e\u73b0\u7cbe\u786e\u7684\u91cd\u91cf\u611f\u77e5\u673a\u5668\u4eba\u63a7\u5236", "motivation": "\u5f53\u524d\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u5728\u5904\u7406\u7cbe\u786e\u4efb\u52a1\u7ea6\u675f\uff08\u5982\u57fa\u4e8e\u6570\u5b57\u9608\u503c\u7684\u505c\u6b62\uff09\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u56e0\u4e3a\u5176\u89c2\u5bdf-\u52a8\u4f5c\u6620\u5c04\u662f\u9690\u5f0f\u8bad\u7ec3\u7684\uff0c\u7f3a\u4e4f\u660e\u786e\u7684\u6761\u4ef6\u76d1\u63a7\u673a\u5236", "method": "\u63d0\u51faCLAW\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u5fae\u8c03CLIP\u6a21\u578b\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u63d0\u793a\u751f\u6210\u5668\uff0c\u6301\u7eed\u76d1\u63a7\u79e4\u7684\u6570\u5b57\u8bfb\u6570\u5e76\u57fa\u4e8e\u91cd\u91cf\u9608\u503c\u751f\u6210\u79bb\u6563\u6307\u4ee4\uff1b2\uff09\u7531\u03c0\u2080\u6d41\u5f0fVLA\u7b56\u7565\u6574\u5408\u63d0\u793a\u548c\u591a\u89c6\u89d2\u76f8\u673a\u89c2\u6d4b\uff0c\u751f\u6210\u8fde\u7eed\u673a\u5668\u4eba\u52a8\u4f5c", "result": "\u5728\u5355\u7269\u4f53\u6293\u53d6\u548c\u9700\u8981\u53cc\u81c2\u64cd\u4f5c\u7684\u6df7\u5408\u7269\u4f53\u4efb\u52a1\u4e09\u4e2a\u5b9e\u9a8c\u8bbe\u7f6e\u4e2d\uff0cCLAW\u53ef\u9760\u6267\u884c\u91cd\u91cf\u611f\u77e5\u884c\u4e3a\uff0c\u6027\u80fd\u4f18\u4e8e\u539f\u59cb\u03c0\u2080\u548c\u5fae\u8c03\u03c0\u2080\u6a21\u578b", "conclusion": "CLAW\u6210\u529f\u5c06\u7b26\u53f7\u5316\u91cd\u91cf\u63a8\u7406\u4e0e\u9ad8\u9891\u89c6\u89c9\u8fd0\u52a8\u63a7\u5236\u76f8\u7ed3\u5408\uff0c\u4e3a\u7cbe\u786e\u7ea6\u675f\u7684\u673a\u5668\u4eba\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.14147", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.14147", "abs": "https://arxiv.org/abs/2509.14147", "authors": ["Fanxing Li", "Shengyang Wang", "Fangyu Sun", "Shuyu Wu", "Dexin Zuo", "Wenxian Yu", "Danping Zou"], "title": "StableTracker: Learning to Stably Track Target via Differentiable Simulation", "comment": null, "summary": "FPV object tracking methods heavily rely on handcraft modular designs,\nresulting in hardware overload and cumulative error, which seriously degrades\nthe tracking performance, especially for rapidly accelerating or decelerating\ntargets. To address these challenges, we present \\textbf{StableTracker}, a\nlearning-based control policy that enables quadrotors to robustly follow the\nmoving target from arbitrary perspectives. The policy is trained using\nbackpropagation-through-time via differentiable simulation, allowing the\nquadrotor to maintain the target at the center of the visual field in both\nhorizontal and vertical directions, while keeping a fixed relative distance,\nthereby functioning as an autonomous aerial camera. We compare StableTracker\nagainst both state-of-the-art traditional algorithms and learning baselines.\nSimulation experiments demonstrate that our policy achieves superior accuracy,\nstability and generalization across varying safe distances, trajectories, and\ntarget velocities. Furthermore, a real-world experiment on a quadrotor with an\nonboard computer validated practicality of the proposed approach.", "AI": {"tldr": "StableTracker\u662f\u4e00\u4e2a\u57fa\u4e8e\u5b66\u4e60\u7684\u63a7\u5236\u7b56\u7565\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u6a21\u62df\u8bad\u7ec3\uff0c\u4f7f\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u80fd\u591f\u4ece\u4efb\u610f\u89c6\u89d2\u7a33\u5b9a\u8ddf\u8e2a\u79fb\u52a8\u76ee\u6807\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfFPV\u8ddf\u8e2a\u65b9\u6cd5\u786c\u4ef6\u8d1f\u8f7d\u91cd\u548c\u7d2f\u79ef\u8bef\u5dee\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfFPV\u76ee\u6807\u8ddf\u8e2a\u65b9\u6cd5\u4f9d\u8d56\u624b\u5de5\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u5bfc\u81f4\u786c\u4ef6\u8d1f\u8f7d\u8fc7\u91cd\u548c\u7d2f\u79ef\u8bef\u5dee\uff0c\u7279\u522b\u662f\u5728\u76ee\u6807\u5feb\u901f\u52a0\u51cf\u901f\u65f6\u8ddf\u8e2a\u6027\u80fd\u4e25\u91cd\u4e0b\u964d\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u65f6\u95f4\u7684\u53cd\u5411\u4f20\u64ad\u901a\u8fc7\u53ef\u5fae\u5206\u6a21\u62df\u8bad\u7ec3\u5b66\u4e60\u578b\u63a7\u5236\u7b56\u7565\uff0c\u4f7f\u65e0\u4eba\u673a\u80fd\u591f\u5728\u6c34\u5e73\u548c\u5782\u76f4\u65b9\u5411\u4fdd\u6301\u76ee\u6807\u5728\u89c6\u91ce\u4e2d\u5fc3\uff0c\u540c\u65f6\u4fdd\u6301\u56fa\u5b9a\u76f8\u5bf9\u8ddd\u79bb\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u663e\u793a\u8be5\u7b56\u7565\u5728\u7cbe\u5ea6\u3001\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u4f20\u7edf\u7b97\u6cd5\u548c\u5b66\u4e60\u57fa\u7ebf\uff0c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "StableTracker\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u81ea\u4e3b\u7a7a\u4e2d\u6444\u50cf\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5e94\u5bf9\u4e0d\u540c\u5b89\u5168\u8ddd\u79bb\u3001\u8f68\u8ff9\u548c\u76ee\u6807\u901f\u5ea6\u7684\u53d8\u5316\uff0c\u5177\u6709\u4f18\u5f02\u7684\u8ddf\u8e2a\u6027\u80fd\u3002"}}
{"id": "2509.14159", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.14159", "abs": "https://arxiv.org/abs/2509.14159", "authors": ["Dayi Dong", "Maulik Bhatt", "Seoyeon Choi", "Negar Mehr"], "title": "MIMIC-D: Multi-modal Imitation for MultI-agent Coordination with Decentralized Diffusion Policies", "comment": "9 pages, 4 figures, 5 tables", "summary": "As robots become more integrated in society, their ability to coordinate with\nother robots and humans on multi-modal tasks (those with multiple valid\nsolutions) is crucial. We propose to learn such behaviors from expert\ndemonstrations via imitation learning (IL). However, when expert demonstrations\nare multi-modal, standard IL approaches can struggle to capture the diverse\nstrategies, hindering effective coordination. Diffusion models are known to be\neffective at handling complex multi-modal trajectory distributions in\nsingle-agent systems. Diffusion models have also excelled in multi-agent\nscenarios where multi-modality is more common and crucial to learning\ncoordinated behaviors. Typically, diffusion-based approaches require a\ncentralized planner or explicit communication among agents, but this assumption\ncan fail in real-world scenarios where robots must operate independently or\nwith agents like humans that they cannot directly communicate with. Therefore,\nwe propose MIMIC-D, a Centralized Training, Decentralized Execution (CTDE)\nparadigm for multi-modal multi-agent imitation learning using diffusion\npolicies. Agents are trained jointly with full information, but execute\npolicies using only local information to achieve implicit coordination. We\ndemonstrate in both simulation and hardware experiments that our method\nrecovers multi-modal coordination behavior among agents in a variety of tasks\nand environments, while improving upon state-of-the-art baselines.", "AI": {"tldr": "MIMIC-D\uff1a\u57fa\u4e8e\u6269\u6563\u7b56\u7565\u7684\u591a\u6a21\u6001\u591a\u667a\u80fd\u4f53\u6a21\u4eff\u5b66\u4e60\u6846\u67b6\uff0c\u91c7\u7528\u96c6\u4e2d\u8bad\u7ec3\u5206\u6563\u6267\u884c\u8303\u5f0f\uff0c\u80fd\u591f\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u5b66\u4e60\u591a\u6a21\u6001\u534f\u8c03\u884c\u4e3a\uff0c\u65e0\u9700\u663e\u5f0f\u901a\u4fe1\u5373\u53ef\u5b9e\u73b0\u9690\u5f0f\u534f\u8c03\u3002", "motivation": "\u968f\u7740\u673a\u5668\u4eba\u5728\u793e\u4f1a\u4e2d\u66f4\u5e7f\u6cdb\u5730\u96c6\u6210\uff0c\u5b83\u4eec\u9700\u8981\u80fd\u591f\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u4e0e\u5176\u4ed6\u673a\u5668\u4eba\u548c\u4eba\u7c7b\u534f\u8c03\u3002\u6807\u51c6\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u591a\u6a21\u6001\u4e13\u5bb6\u6f14\u793a\u65f6\u96be\u4ee5\u6355\u6349\u591a\u6837\u7b56\u7565\uff0c\u800c\u73b0\u6709\u6269\u6563\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u96c6\u4e2d\u89c4\u5212\u6216\u663e\u5f0f\u901a\u4fe1\uff0c\u8fd9\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u4e0d\u53ef\u884c\u3002", "method": "\u63d0\u51faMIMIC-D\u6846\u67b6\uff0c\u91c7\u7528\u96c6\u4e2d\u8bad\u7ec3\u5206\u6563\u6267\u884c(CTDE)\u8303\u5f0f\uff0c\u4f7f\u7528\u6269\u6563\u7b56\u7565\u8fdb\u884c\u591a\u6a21\u6001\u591a\u667a\u80fd\u4f53\u6a21\u4eff\u5b66\u4e60\u3002\u5728\u8bad\u7ec3\u65f6\u4f7f\u7528\u5b8c\u6574\u4fe1\u606f\u8054\u5408\u8bad\u7ec3\u667a\u80fd\u4f53\uff0c\u5728\u6267\u884c\u65f6\u4ec5\u4f7f\u7528\u5c40\u90e8\u4fe1\u606f\u5b9e\u73b0\u9690\u5f0f\u534f\u8c03\u3002", "result": "\u5728\u4eff\u771f\u548c\u786c\u4ef6\u5b9e\u9a8c\u4e2d\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u5404\u79cd\u4efb\u52a1\u548c\u73af\u5883\u4e2d\u6062\u590d\u667a\u80fd\u4f53\u95f4\u7684\u591a\u6a21\u6001\u534f\u8c03\u884c\u4e3a\uff0c\u5e76\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MIMIC-D\u6210\u529f\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u591a\u667a\u80fd\u4f53\u534f\u8c03\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u663e\u5f0f\u901a\u4fe1\u5373\u53ef\u5b9e\u73b0\u6709\u6548\u9690\u5f0f\u534f\u8c03\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u534f\u8c03\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2509.14178", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.14178", "abs": "https://arxiv.org/abs/2509.14178", "authors": ["Kai Ye", "Yuhang Wu", "Shuyuan Hu", "Junliang Li", "Meng Liu", "Yongquan Chen", "Rui Huang"], "title": "\\textsc{Gen2Real}: Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video", "comment": null, "summary": "Dexterous manipulation remains a challenging robotics problem, largely due to\nthe difficulty of collecting extensive human demonstrations for learning. In\nthis paper, we introduce \\textsc{Gen2Real}, which replaces costly human demos\nwith one generated video and drives robot skill from it: it combines\ndemonstration generation that leverages video generation with pose and depth\nestimation to yield hand-object trajectories, trajectory optimization that uses\nPhysics-aware Interaction Optimization Model (PIOM) to impose physics\nconsistency, and demonstration learning that retargets human motions to a robot\nhand and stabilizes control with an anchor-based residual Proximal Policy\nOptimization (PPO) policy. Using only generated videos, the learned policy\nachieves a 77.3\\% success rate on grasping tasks in simulation and demonstrates\ncoherent executions on a real robot. We also conduct ablation studies to\nvalidate the contribution of each component and demonstrate the ability to\ndirectly specify tasks using natural language, highlighting the flexibility and\nrobustness of \\textsc{Gen2Real} in generalizing grasping skills from imagined\nvideos to real-world execution.", "AI": {"tldr": "Gen2Real\u4f7f\u7528\u751f\u6210\u89c6\u9891\u66ff\u4ee3\u6602\u8d35\u7684\u4eba\u7c7b\u6f14\u793a\uff0c\u901a\u8fc7\u89c6\u9891\u751f\u6210\u3001\u8f68\u8ff9\u4f18\u5316\u548c\u6f14\u793a\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u4ece\u60f3\u8c61\u89c6\u9891\u5230\u771f\u5b9e\u4e16\u754c\u6267\u884c\u7684\u7075\u5de7\u6293\u53d6\u6280\u80fd\u6cdb\u5316\uff0c\u5728\u4eff\u771f\u4e2d\u8fbe\u523077.3%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u7075\u5de7\u64cd\u4f5c\u662f\u673a\u5668\u4eba\u9886\u57df\u7684\u6311\u6218\u6027\u95ee\u9898\uff0c\u4e3b\u8981\u96be\u70b9\u5728\u4e8e\u6536\u96c6\u5927\u91cf\u4eba\u7c7b\u6f14\u793a\u6570\u636e\u6210\u672c\u9ad8\u6602\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u751f\u6210\u89c6\u9891\u66ff\u4ee3\u4eba\u7c7b\u6f14\u793a\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u89c6\u9891\u751f\u6210\u4e0e\u59ff\u6001\u6df1\u5ea6\u4f30\u8ba1\u751f\u6210\u624b-\u7269\u4f53\u8f68\u8ff9\uff0c\u4f7f\u7528\u7269\u7406\u611f\u77e5\u4ea4\u4e92\u4f18\u5316\u6a21\u578b(PIOM)\u8fdb\u884c\u8f68\u8ff9\u4f18\u5316\u786e\u4fdd\u7269\u7406\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u951a\u70b9\u6b8b\u5deePPO\u7b56\u7565\u5c06\u4eba\u7c7b\u52a8\u4f5c\u91cd\u5b9a\u5411\u5230\u673a\u5668\u4eba\u624b\u5e76\u7a33\u5b9a\u63a7\u5236\u3002", "result": "\u4ec5\u4f7f\u7528\u751f\u6210\u89c6\u9891\uff0c\u5b66\u4e60\u7b56\u7565\u5728\u4eff\u771f\u6293\u53d6\u4efb\u52a1\u4e2d\u8fbe\u523077.3%\u7684\u6210\u529f\u7387\uff0c\u5e76\u5728\u771f\u5b9e\u673a\u5668\u4eba\u4e0a\u5c55\u793a\u4e86\u8fde\u8d2f\u7684\u6267\u884c\u6548\u679c\u3002\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u5404\u7ec4\u4ef6\u8d21\u732e\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u76f4\u63a5\u6307\u5b9a\u4efb\u52a1\u3002", "conclusion": "Gen2Real\u5c55\u793a\u4e86\u4ece\u60f3\u8c61\u89c6\u9891\u5230\u771f\u5b9e\u4e16\u754c\u6267\u884c\u7684\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u7075\u5de7\u64cd\u4f5c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u6602\u8d35\u4eba\u7c7b\u6f14\u793a\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14191", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.14191", "abs": "https://arxiv.org/abs/2509.14191", "authors": ["Zhihao Cao", "Hanyu Wu", "Li Wa Tang", "Zizhou Luo", "Zihan Zhu", "Wei Zhang", "Marc Pollefeys", "Martin R. Oswald"], "title": "MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping", "comment": null, "summary": "Recent progress in dense SLAM has primarily targeted monocular setups, often\nat the expense of robustness and geometric coverage. We present MCGS-SLAM, the\nfirst purely RGB-based multi-camera SLAM system built on 3D Gaussian Splatting\n(3DGS). Unlike prior methods relying on sparse maps or inertial data, MCGS-SLAM\nfuses dense RGB inputs from multiple viewpoints into a unified, continuously\noptimized Gaussian map. A multi-camera bundle adjustment (MCBA) jointly refines\nposes and depths via dense photometric and geometric residuals, while a scale\nconsistency module enforces metric alignment across views using low-rank\npriors. The system supports RGB input and maintains real-time performance at\nlarge scale. Experiments on synthetic and real-world datasets show that\nMCGS-SLAM consistently yields accurate trajectories and photorealistic\nreconstructions, usually outperforming monocular baselines. Notably, the wide\nfield of view from multi-camera input enables reconstruction of side-view\nregions that monocular setups miss, critical for safe autonomous operation.\nThese results highlight the promise of multi-camera Gaussian Splatting SLAM for\nhigh-fidelity mapping in robotics and autonomous driving.", "AI": {"tldr": "MCGS-SLAM\u662f\u9996\u4e2a\u57fa\u4e8e\u7eafRGB\u8f93\u5165\u7684\u591a\u76f8\u673a3D\u9ad8\u65af\u6e85\u5c04SLAM\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u89c6\u89d2\u878d\u5408\u5b9e\u73b0\u5b9e\u65f6\u9ad8\u7cbe\u5ea6\u5efa\u56fe\u548c\u8f68\u8ff9\u4f30\u8ba1\uff0c\u5728\u51e0\u4f55\u8986\u76d6\u548c\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8e\u5355\u76ee\u65b9\u6cd5", "motivation": "\u73b0\u6709\u5bc6\u96c6SLAM\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5355\u76ee\u8bbe\u7f6e\uff0c\u727a\u7272\u4e86\u9c81\u68d2\u6027\u548c\u51e0\u4f55\u8986\u76d6\u8303\u56f4\u3002\u591a\u76f8\u673a\u7cfb\u7edf\u80fd\u591f\u63d0\u4f9b\u66f4\u5bbd\u7684\u89c6\u91ce\uff0c\u91cd\u5efa\u5355\u76ee\u7cfb\u7edf\u9057\u6f0f\u7684\u4fa7\u89c6\u533a\u57df\uff0c\u8fd9\u5bf9\u81ea\u52a8\u9a7e\u9a76\u7b49\u5b89\u5168\u5173\u952e\u5e94\u7528\u81f3\u5173\u91cd\u8981", "method": "\u57fa\u4e8e3D\u9ad8\u65af\u6e85\u5c04(3DGS)\uff0c\u63d0\u51fa\u591a\u76f8\u673a\u675f\u8c03\u6574(MCBA)\u8054\u5408\u4f18\u5316\u4f4d\u59ff\u548c\u6df1\u5ea6\uff0c\u4f7f\u7528\u5bc6\u96c6\u5149\u5ea6\u4e0e\u51e0\u4f55\u6b8b\u5dee\uff0c\u5e76\u901a\u8fc7\u5c3a\u5ea6\u4e00\u81f4\u6027\u6a21\u5757\u5229\u7528\u4f4e\u79e9\u5148\u9a8c\u5b9e\u73b0\u591a\u89c6\u56fe\u95f4\u7684\u5ea6\u91cf\u5bf9\u9f50", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMCGS-SLAM\u80fd\u591f\u6301\u7eed\u4ea7\u751f\u51c6\u786e\u8f68\u8ff9\u548c\u903c\u771f\u91cd\u5efa\u6548\u679c\uff0c\u901a\u5e38\u4f18\u4e8e\u5355\u76ee\u57fa\u7ebf\u65b9\u6cd5\uff0c\u652f\u6301RGB\u8f93\u5165\u5e76\u4fdd\u6301\u5927\u89c4\u6a21\u5b9e\u65f6\u6027\u80fd", "conclusion": "\u591a\u76f8\u673a\u9ad8\u65af\u6e85\u5c04SLAM\u5728\u673a\u5668\u4eba\u548c\u81ea\u52a8\u9a7e\u9a76\u7684\u9ad8\u4fdd\u771f\u5efa\u56fe\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5176\u5bbd\u89c6\u91ce\u80fd\u591f\u91cd\u5efa\u5355\u76ee\u7cfb\u7edf\u9057\u6f0f\u7684\u5173\u952e\u533a\u57df"}}
{"id": "2509.14210", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2509.14210", "abs": "https://arxiv.org/abs/2509.14210", "authors": ["Seth Farrell", "Chenghao Li", "Hongzhan Yu", "Hesam Mojtahedi", "Sicun Gao", "Henrik I. Christensen"], "title": "GLIDE: A Coordinated Aerial-Ground Framework for Search and Rescue in Unknown Environments", "comment": null, "summary": "We present a cooperative aerial-ground search-and-rescue (SAR) framework that\npairs two unmanned aerial vehicles (UAVs) with an unmanned ground vehicle (UGV)\nto achieve rapid victim localization and obstacle-aware navigation in unknown\nenvironments. We dub this framework Guided Long-horizon Integrated Drone Escort\n(GLIDE), highlighting the UGV's reliance on UAV guidance for long-horizon\nplanning. In our framework, a goal-searching UAV executes real-time onboard\nvictim detection and georeferencing to nominate goals for the ground platform,\nwhile a terrain-scouting UAV flies ahead of the UGV's planned route to provide\nmid-level traversability updates. The UGV fuses aerial cues with local sensing\nto perform time-efficient A* planning and continuous replanning as information\narrives. Additionally, we present a hardware demonstration (using a GEM e6 golf\ncart as the UGV and two X500 UAVs) to evaluate end-to-end SAR mission\nperformance and include simulation ablations to assess the planning stack in\nisolation from detection. Empirical results demonstrate that explicit role\nseparation across UAVs, coupled with terrain scouting and guided planning,\nimproves reach time and navigation safety in time-critical SAR missions.", "AI": {"tldr": "\u63d0\u51faGLIDE\u6846\u67b6\uff0c\u4f7f\u7528\u4e24\u67b6\u65e0\u4eba\u673a\u548c\u4e00\u8f86\u5730\u9762\u8f66\u534f\u540c\u641c\u7d22\u6551\u63f4\uff0c\u901a\u8fc7\u65e0\u4eba\u673a\u5f15\u5bfc\u5b9e\u73b0\u5feb\u901f\u53d7\u5bb3\u8005\u5b9a\u4f4d\u548c\u907f\u969c\u5bfc\u822a", "motivation": "\u89e3\u51b3\u672a\u77e5\u73af\u5883\u4e2d\u65f6\u95f4\u7d27\u8feb\u7684\u641c\u7d22\u6551\u63f4\u4efb\u52a1\uff0c\u9700\u8981\u5feb\u901f\u5b9a\u4f4d\u53d7\u5bb3\u8005\u5e76\u5b89\u5168\u5bfc\u822a\uff0c\u4f20\u7edf\u65b9\u6cd5\u6548\u7387\u6709\u9650", "method": "\u4f7f\u7528\u76ee\u6807\u641c\u7d22\u65e0\u4eba\u673a\u8fdb\u884c\u5b9e\u65f6\u53d7\u5bb3\u8005\u68c0\u6d4b\u548c\u5730\u7406\u53c2\u8003\uff0c\u5730\u5f62\u4fa6\u5bdf\u65e0\u4eba\u673a\u63d0\u4f9b\u8def\u5f84\u53ef\u901a\u884c\u6027\u66f4\u65b0\uff0c\u5730\u9762\u8f66\u878d\u5408\u7a7a\u4e2d\u7ebf\u7d22\u8fdb\u884cA*\u89c4\u5212\u548c\u6301\u7eed\u91cd\u89c4\u5212", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u660e\u786e\u7684\u65e0\u4eba\u673a\u89d2\u8272\u5206\u5de5\u3001\u5730\u5f62\u4fa6\u5bdf\u548c\u5f15\u5bfc\u89c4\u5212\u63d0\u9ad8\u4e86\u5230\u8fbe\u65f6\u95f4\u548c\u5bfc\u822a\u5b89\u5168\u6027", "conclusion": "GLIDE\u6846\u67b6\u901a\u8fc7\u7a7a\u4e2d-\u5730\u9762\u534f\u540c\u548c\u591a\u65e0\u4eba\u673a\u4e13\u95e8\u5316\u5206\u5de5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u641c\u7d22\u6551\u63f4\u4efb\u52a1\u7684\u6548\u7387\u548c\u5b89\u5168\u6027"}}
{"id": "2509.14228", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14228", "abs": "https://arxiv.org/abs/2509.14228", "authors": ["Benjamin Shaffer", "Victoria Edwards", "Brooks Kinch", "Nathaniel Trask", "M. Ani Hsieh"], "title": "Multi-robot Multi-source Localization in Complex Flows with Physics-Preserving Environment Models", "comment": null, "summary": "Source localization in a complex flow poses a significant challenge for\nmulti-robot teams tasked with localizing the source of chemical leaks or\ntracking the dispersion of an oil spill. The flow dynamics can be time-varying\nand chaotic, resulting in sporadic and intermittent sensor readings, and\ncomplex environmental geometries further complicate a team's ability to model\nand predict the dispersion. To accurately account for the physical processes\nthat drive the dispersion dynamics, robots must have access to computationally\nintensive numerical models, which can be difficult when onboard computation is\nlimited. We present a distributed mobile sensing framework for source\nlocalization in which each robot carries a machine-learned, finite element\nmodel of its environment to guide information-based sampling. The models are\nused to evaluate an approximate mutual information criterion to drive an\ninfotaxis control strategy, which selects sensing regions that are expected to\nmaximize informativeness for the source localization objective. Our approach\nachieves faster error reduction compared to baseline sensing strategies and\nresults in more accurate source localization compared to baseline machine\nlearning approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u79fb\u52a8\u4f20\u611f\u6846\u67b6\uff0c\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6709\u9650\u5143\u6a21\u578b\u6307\u5bfc\u591a\u673a\u5668\u4eba\u56e2\u961f\u5728\u590d\u6742\u6d41\u52a8\u73af\u5883\u4e2d\u8fdb\u884c\u4fe1\u606f\u9a71\u52a8\u7684\u6e90\u5b9a\u4f4d", "motivation": "\u590d\u6742\u6d41\u52a8\u73af\u5883\u4e2d\u7684\u6e90\u5b9a\u4f4d\uff08\u5982\u5316\u5b66\u6cc4\u6f0f\u6216\u77f3\u6cb9\u6cc4\u6f0f\uff09\u9762\u4e34\u6311\u6218\uff0c\u5305\u62ec\u65f6\u53d8\u6df7\u6c8c\u6d41\u52a8\u3001\u95f4\u6b47\u6027\u4f20\u611f\u5668\u8bfb\u6570\u3001\u590d\u6742\u51e0\u4f55\u73af\u5883\u4ee5\u53ca\u673a\u8f7d\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u7b49\u95ee\u9898", "method": "\u6bcf\u4e2a\u673a\u5668\u4eba\u643a\u5e26\u673a\u5668\u5b66\u4e60\u6709\u9650\u5143\u73af\u5883\u6a21\u578b\uff0c\u4f7f\u7528\u8fd1\u4f3c\u4e92\u4fe1\u606f\u51c6\u5219\u9a71\u52a8\u4fe1\u606f\u89c5\u98df\u63a7\u5236\u7b56\u7565\uff0c\u9009\u62e9\u9884\u671f\u80fd\u6700\u5927\u5316\u6e90\u5b9a\u4f4d\u4fe1\u606f\u91cf\u7684\u4f20\u611f\u533a\u57df", "result": "\u76f8\u6bd4\u57fa\u7ebf\u4f20\u611f\u7b56\u7565\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u8bef\u5dee\u51cf\u5c11\uff0c\u76f8\u6bd4\u57fa\u7ebf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u83b7\u5f97\u4e86\u66f4\u51c6\u786e\u7684\u6e90\u5b9a\u4f4d\u7ed3\u679c", "conclusion": "\u8be5\u5206\u5e03\u5f0f\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u4fe1\u606f\u7406\u8bba\u63a7\u5236\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u6d41\u52a8\u73af\u5883\u4e2d\u7684\u6e90\u5b9a\u4f4d\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5b9a\u4f4d\u6548\u7387\u548c\u51c6\u786e\u6027"}}
