<div id=toc></div>

# Table of Contents

- [cs.SI](#cs.SI) [Total: 3]
- [econ.EM](#econ.EM) [Total: 3]
- [econ.TH](#econ.TH) [Total: 2]
- [cs.RO](#cs.RO) [Total: 17]
- [cs.CY](#cs.CY) [Total: 10]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [eess.SY](#eess.SY) [Total: 20]
- [econ.GN](#econ.GN) [Total: 2]
- [cs.AI](#cs.AI) [Total: 34]
- [stat.AP](#stat.AP) [Total: 6]


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [1] [A Unified Model for Human Mobility Generation in Natural Disasters](https://arxiv.org/abs/2511.01928)
*Qingyue Long,Huandong Wang,Qi Ryan Wang,Yong Li*

Main category: cs.SI

TL;DR: 提出UniDisMob模型，用于自然灾害场景下的人类移动生成，通过物理信息提示和元学习框架实现跨灾害和跨城市的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖单一城市或特定灾害的有限数据，泛化能力差。灾害具有突发性和不可预测性，需要开发能适应新场景的通用模型。

Method: 使用物理信息提示和物理引导对齐来捕捉不同灾害后移动变化的共同模式；采用元学习框架，通过共享参数提取通用模式，私有参数捕获城市特定特征。

Result: 在多个城市和灾害场景的广泛实验中，该方法显著优于现有最优基线，平均性能提升超过13%。

Conclusion: UniDisMob模型成功解决了跨灾害和跨城市泛化的挑战，为灾害场景下的人类移动生成提供了有效的通用解决方案。

Abstract: Human mobility generation in disaster scenarios plays a vital role in
resource allocation, emergency response, and rescue coordination. During
disasters such as wildfires and hurricanes, human mobility patterns often
deviate from their normal states, which makes the task more challenging.
However, existing works usually rely on limited data from a single city or
specific disaster, significantly restricting the model's generalization
capability in new scenarios. In fact, disasters are highly sudden and
unpredictable, and any city may encounter new types of disasters without prior
experience. Therefore, we aim to develop a one-for-all model for mobility
generation that can generalize to new disaster scenarios. However, building a
universal framework faces two key challenges: 1) the diversity of disaster
types and 2) the heterogeneity among different cities. In this work, we propose
a unified model for human mobility generation in natural disasters (named
UniDisMob). To enable cross-disaster generalization, we design physics-informed
prompt and physics-guided alignment that leverage the underlying common
patterns in mobility changes after different disasters to guide the generation
process. To achieve cross-city generalization, we introduce a meta-learning
framework that extracts universal patterns across multiple cities through
shared parameters and captures city-specific features via private parameters.
Extensive experiments across multiple cities and disaster scenarios demonstrate
that our method significantly outperforms state-of-the-art baselines, achieving
an average performance improvement exceeding 13%.

</details>


### [2] [Community Notes are Vulnerable to Rater Bias and Manipulation](https://arxiv.org/abs/2511.02615)
*Bao Tran Truong,Siqi Wu,Alessandro Flammini,Filippo Menczer,Alexander J. Stewart*

Main category: cs.SI

TL;DR: 对Community Notes算法的系统评估显示，该算法会压制大量真正有用的笔记，对评分者偏见高度敏感，且少数恶意评分者能战略性地压制目标有用笔记，引发对众包事实核查可靠性的担忧。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台依赖众包审核系统来大规模打击错误信息，但这些系统面临评分者偏见和潜在操纵的挑战，可能削弱其有效性。

Method: 使用模拟数据系统评估Community Notes算法，模拟真实的评分者和笔记行为，量化发布有用与无用笔记的错误率。

Result: 算法压制了相当一部分真正有用的笔记，对评分者偏见高度敏感，包括极化偏见和群体内偏好。5-20%的恶意评分者能战略性地压制目标有用笔记，有效审查可靠信息。

Conclusion: 虽然社区驱动的审核可能提供可扩展性，但其对偏见和操纵的脆弱性引发了关于可靠性和可信度的担忧，突显了需要改进机制来保障众包事实核查的完整性。

Abstract: Social media platforms increasingly rely on crowdsourced moderation systems
like Community Notes to combat misinformation at scale. However, these systems
face challenges from rater bias and potential manipulation, which may undermine
their effectiveness. Here we systematically evaluate the Community Notes
algorithm using simulated data that models realistic rater and note behaviors,
quantifying error rates in publishing helpful versus unhelpful notes. We find
that the algorithm suppresses a substantial fraction of genuinely helpful notes
and is highly sensitive to rater biases, including polarization and in-group
preferences. Moreover, a small minority (5--20\%) of bad raters can
strategically suppress targeted helpful notes, effectively censoring reliable
information. These findings suggest that while community-driven moderation may
offer scalability, its vulnerability to bias and manipulation raises concerns
about reliability and trustworthiness, highlighting the need for improved
mechanisms to safeguard the integrity of crowdsourced fact-checking.

</details>


### [3] [Feedback dynamics in Politics: The interplay between sentiment and engagement](https://arxiv.org/abs/2511.02663)
*Simone Formentin*

Main category: cs.SI

TL;DR: 本文通过分析英国、西班牙和希腊议员的150万条推文，发现政治人物会根据公众参与度调整其信息的情感倾向，形成闭环反馈机制。


<details>
  <summary>Details</summary>
Motivation: 研究政治沟通中的反馈机制，探索政治家是否根据公众参与度来调整其信息的情感倾向。

Method: 使用来自英国、西班牙和希腊议员的150万条推文数据，通过简单可解释的线性模型识别情感动态。

Result: 分析显示闭环行为：正面和负面信息的参与度会影响后续帖子的情感倾向。反对派成员对负面参与更敏感，而政府官员对正面信号反应更强。

Conclusion: 研究提供了量化、控制导向的在线政治行为适应视角，显示反馈原则可以解释社交媒体话语中出现的自我强化动态。

Abstract: We investigate feedback mechanisms in political communication by testing
whether politicians adapt the sentiment of their messages in response to public
engagement. Using over 1.5 million tweets from Members of Parliament in the
United Kingdom, Spain, and Greece during 2021, we identify sentiment dynamics
through a simple yet interpretable linear model. The analysis reveals a
closed-loop behavior: engagement with positive and negative messages influences
the sentiment of subsequent posts. Moreover, the learned coefficients highlight
systematic differences across political roles: opposition members are more
reactive to negative engagement, whereas government officials respond more to
positive signals. These results provide a quantitative, control-oriented view
of behavioral adaptation in online politics, showing how feedback principles
can explain the self-reinforcing dynamics that emerge in social media
discourse.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [4] [Identification and Estimation of Continuous-Time Dynamic Discrete Choice Games](https://arxiv.org/abs/2511.02701)
*Jason R. Blevins*

Main category: econ.EM

TL;DR: 本文研究了具有随机顺序移动的连续时间动态离散选择博弈的理论、计算和计量经济学特性，扩展了Arcidiacono等人的工作，考虑了移动到达率的识别和异质性，并在仅使用固定间隔采样的离散时间数据下重新建立了马尔可夫完美均衡的存在条件。


<details>
  <summary>Details</summary>
Motivation: 先前研究假设移动到达率已知，本文旨在识别这一关键参数并考虑异质性移动到达率的情况，同时研究在仅有离散时间数据时模型的识别和估计问题。

Method: 通过三个基础模型（单智能体更新模型、动态进入退出模型、质量阶梯模型）进行Monte Carlo实验，并使用Rust(1987)的数据进行实证分析，考察从连续时间到离散时间数据转换时参数估计的行为。

Result: 实验展示了当从连续时间数据转向频率递减的离散时间数据时参数估计的变化行为，以及随着企业数量增长的计算可行性。实证例子突出了允许决策率变化的影响。

Conclusion: 本文扩展了连续时间动态离散选择博弈的理论框架，提供了移动到达率识别的方法，并通过实验验证了在离散时间数据下的估计性能，为实际应用提供了计算和统计基础。

Abstract: This paper considers the theoretical, computational, and econometric
properties of continuous time dynamic discrete choice games with stochastically
sequential moves, introduced by Arcidiacono, Bayer, Blevins, and Ellickson
(2016). We consider identification of the rate of move arrivals, which was
assumed to be known in previous work, as well as a generalized version with
heterogeneous move arrival rates. We re-establish conditions for existence of a
Markov perfect equilibrium in the generalized model and consider identification
of the model primitives with only discrete time data sampled at fixed
intervals. Three foundational example models are considered: a single agent
renewal model, a dynamic entry and exit model, and a quality ladder model.
Through these examples we examine the computational and statistical properties
of estimators via Monte Carlo experiments and an empirical example using data
from Rust (1987). The experiments show how parameter estimates behave when
moving from continuous time data to discrete time data of decreasing frequency
and the computational feasibility as the number of firms grows. The empirical
example highlights the impact of allowing decision rates to vary.

</details>


### [5] [Peer effect analysis with latent processes](https://arxiv.org/abs/2511.02764)
*Vincent Starck*

Main category: econ.EM

TL;DR: 该论文提出了一种在连续时间中建模同伴效应的方法，通过建模未观察到的因果关系方向来避免反射问题和同时性问题，并引入了捕捉先行者对同伴因果影响的同伴效应参数。


<details>
  <summary>Details</summary>
Motivation: 研究在缺乏标准社会均衡情况下，由不可逆决策产生的同伴效应，解决传统方法中的反射问题和同时性问题。

Method: 在连续时间中建模潜在决策序列，获得似然函数的闭式表达式，通过最大似然方法一致估计参数，建模未观察到的因果关系方向。

Result: 提出的方法能够避免回归条件期望或线性均值回归中的问题，同伴效应参数能够捕捉先行者对同伴的因果影响，可以适应各种形式的同伴效应异质性。

Conclusion: 该方法提供了一种有效估计同伴效应的方法，参数可以通过最大似然方法一致估计，并适用于标准推断。

Abstract: I study peer effects that arise from irreversible decisions in the absence of
a standard social equilibrium. I model a latent sequence of decisions in
continuous time and obtain a closed-form expression for the likelihood, which
allows to estimate proposed causal estimands. The method avoids regression on
conditional expectations or linear-in-means regression -- and thus
reflection-type problems (Manski, 1993) or simultaneity issues -- by modeling
the (unobserved) realized direction of causality, whose probability is
identified. Under a parsimonious parametric specification, I introduce a peer
effect parameter meant to capture the causal influence of first-movers on their
peers. Various forms of peer effect heterogeneity can be accommodated.
Parameters are shown to be consistently estimated by maximum likelihood methods
and lend themselves to standard inference.

</details>


### [6] [Sufficient Statistics for Markovian Feedback Processes and Unobserved Heterogeneity in Dynamic Panel Logit Models](https://arxiv.org/abs/2511.02816)
*Sukgyu Shin*

Main category: econ.EM

TL;DR: 本文研究了动态面板logit模型中的识别问题，该模型包含状态依赖、一阶马尔可夫反馈过程和个体未观测异质性。通过引入反馈过程和未观测异质性的充分统计量，分析了不同情况下的识别条件。


<details>
  <summary>Details</summary>
Motivation: 研究动态面板logit模型中参数识别的可行性问题，特别是在存在状态依赖、马尔可夫反馈过程和个体异质性的复杂情况下，为实证研究提供理论指导。

Method: 使用充分统计量方法来处理反馈过程和未观测异质性，通过条件似然方法分析不同情况下的识别条件。

Result: 当协变量遵循一阶马尔可夫过程时，协变量系数的条件似然识别不可行，但滞后因变量系数在至少三个周期后可识别。当反馈仅依赖于滞后因变量时，协变量系数在至少两个周期后可识别，滞后因变量系数在至少三个周期后可识别。

Conclusion: 动态面板logit模型的识别条件取决于反馈过程的性质和数据的时间维度，为实证研究中模型设定和识别策略提供了重要理论依据。

Abstract: In this paper, we examine identification in a dynamic panel logit model with
state dependence, first-order Markov feedback processes, and individual
unobserved heterogeneity by introducing sufficient statistics for the feedback
process and unobserved heterogeneity. If a sequentially exogenous discrete
covariate follows a first-order Markov process, identification of the
coefficient on the covariate via conditional likelihood is infeasible, whereas
identification of the coefficient on the lagged dependent variable is feasible
when there are at least three periods after the initial-condition period. If
the feedback depends only on the lagged dependent variable, the coefficient on
the covariate is identified with at least two periods, and the coefficient on
the lagged dependent variable is identified with at least three periods.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [7] [Mediation and worker performance](https://arxiv.org/abs/2511.02436)
*Allen Vong*

Main category: econ.TH

TL;DR: 研究企业如何通过中介沟通来最大化工人绩效，发现最优中介策略涉及对客户保密的随机化机制，最终过渡到传统的胡萝卜加大棒激励


<details>
  <summary>Details</summary>
Motivation: 探索企业如何通过中介沟通策略来优化工人长期绩效，并分析这种中介策略对工人和客户的福利影响

Method: 使用理论模型分析企业的最优中介沟通策略，包括对客户保密的随机化机制设计

Result: 发现最优中介涉及两种随机化路径：一种是工人偷懒但保持现有效用，另一种是工人努力但需承担最小惩罚；这种随机化最终会被传统激励取代

Conclusion: 只有当工人足够耐心时，最优中介策略才能同时改善工人和平均客户的福利，实现帕累托改进

Abstract: I study how a firm uses mediated communication with a worker and its clients
to maximize worker performance over time. I find that optimal mediation
involves occasional randomizations, secret from clients, between two
continuations. In one, the worker cuts corner and then retains his current
continuation utility. In the other, the worker exerts effort and then receives
the highest continuation equilibrium utility less a minimal penalty for
underperformance. These randomizations eventually disappear, replaced by
canonical carrot-and-stick incentives. Optimal mediation Pareto-improves upon
no mediation for both the worker and the average client if and only if the
worker is sufficiently patient.

</details>


### [8] [Automation and Task Allocation Under Asymmetric Information](https://arxiv.org/abs/2511.02675)
*Quitzé Valenzuela-Stookey*

Main category: econ.TH

TL;DR: 该论文研究企业在任务分配中如何应对工人偏好信息不对称的问题，发现信息摩擦大小会显著影响任务间的替代或互补关系，以及自动化对工人剩余的影响。


<details>
  <summary>Details</summary>
Motivation: 企业在生产任务分配时面临工人偏好信息不对称的问题，需要设计有效的机制来在机器和工人之间分配任务，这种信息摩擦会影响企业的自动化决策和任务分配策略。

Method: 作者构建了一个理论模型来分析企业在信息不对称条件下的任务分配机制，考虑了工人对任务的私人偏好信息，并扩展到多企业竞争工人的情境。

Result: 研究发现：当信息摩擦较小时，任务间呈替代关系，自动化一个任务会降低其他任务的边际成本并减少工人剩余；当信息摩擦较大时，任务可能变为互补关系，自动化反而会提高其他任务的边际成本并增加工人剩余。

Conclusion: 信息不对称程度是决定任务间关系和自动化影响的关键因素，企业在制定自动化策略时需要充分考虑信息摩擦的大小，这一结论在竞争性劳动力市场中同样适用。

Abstract: A firm can complete the tasks needed to produce output using either machines
or workers. Unlike machines, workers have private information about their
preferences over tasks. I study how this information asymmetry shapes the
mechanism used by the firm to allocate tasks across workers and machines. I
identify important qualitative differences between the mechanisms used when
information frictions are large versus small. When information frictions are
small, tasks are substitutes: automating one task lowers the marginal cost of
other tasks and reduces the surplus generated by workers. When frictions are
large, tasks can become complements: automation can raise the marginal cost of
other tasks and increase the surplus generated by workers. The results extend
to a setting with multiple firms competing for workers.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [9] [TRACE: Textual Reasoning for Affordance Coordinate Extraction](https://arxiv.org/abs/2511.01999)
*Sangyun Park,Jin Kim,Yuchen Cui,Matthew S. Brown*

Main category: cs.RO

TL;DR: TRACE通过引入文本推理链来提升视觉语言模型在机器人操作中的空间感知能力，在Where2Place基准上达到48.1%准确率，相对提升9.6%。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型难以将高级指令转化为机器人操作所需的空间感知能力，现有视觉思维链方法计算成本高。

Method: 提出TRACE方法，将文本推理链集成到空间感知预测过程中，通过自主管道创建包含指令和显式文本推理的大规模数据集，并基于此微调视觉语言模型。

Result: 在主要Where2Place基准上达到48.1%准确率（相对提升9.6%），在更具挑战性的W2P(h)子集上达到55.0%。消融研究表明性能与推理数据量直接相关。

Conclusion: 训练视觉语言模型生成文本推理链是提高基于VLM的机器人控制的精确性、可靠性和可解释性的有效策略。

Abstract: Vision-Language Models (VLMs) struggle to translate high-level instructions
into the precise spatial affordances required for robotic manipulation. While
visual Chain-of-Thought (CoT) methods exist, they are often computationally
intensive. In this work, we introduce TRACE (Textual Reasoning for Affordance
Coordinate Extraction), a novel methodology that integrates a textual Chain of
Reasoning (CoR) into the affordance prediction process. We use this methodology
to create the TRACE dataset, a large-scale collection created via an autonomous
pipeline that pairs instructions with explicit textual rationales. By
fine-tuning a VLM on this data, our model learns to externalize its spatial
reasoning before acting. Our experiments show that our TRACE-tuned model
achieves state-of-the-art performance, reaching 48.1% accuracy on the primary
Where2Place (W2P) benchmark (a 9.6% relative improvement) and 55.0% on the more
challenging W2P(h) subset. Crucially, an ablation study demonstrates that
performance scales directly with the amount of reasoning data used, confirming
the CoR's effectiveness. Furthermore, analysis of the model's attention maps
reveals an interpretable reasoning process where focus shifts dynamically
across reasoning steps. This work shows that training VLMs to generate a
textual CoR is an effective and robust strategy for enhancing the precision,
reliability, and interpretability of VLM-based robot control. Our dataset and
code are available at https://github.com/jink-ucla/TRACE

</details>


### [10] [Stein-based Optimization of Sampling Distributions in Model Predictive Path Integral Control](https://arxiv.org/abs/2511.02015)
*Jace Aldrich,Odest Chadwicke Jenkins*

Main category: cs.RO

TL;DR: 提出了一种结合MPPI和SVGD的新方法SOPPI，通过SVGD优化MPPI的样本生成，改善传统MPPI随机采样导致的样本不足问题，在保持计算效率的同时提升控制性能。


<details>
  <summary>Details</summary>
Motivation: 传统MPPI控制依赖于高斯分布的随机采样轨迹，容易导致样本不足和次优结果，需要改进采样策略以更好地探索轨迹空间。

Method: 在MPPI环境步骤之间引入SVGD更新，动态调整噪声分布，形成SOPPI算法，优化样本生成而不显著增加计算负担。

Result: 在Cart-Pole和二维双足行走任务中验证了方法的有效性，相比标准MPPI在多种超参数下表现更好，且能在更少粒子数下实现可行性。

Conclusion: SOPPI方法在保持计算效率的同时显著提升了MPPI性能，适用于高自由度系统，并有望与可微分模拟器的新发展结合。

Abstract: This paper presents a novel method for Model Predictive Path Integral (MPPI)
control that optimizes sample generation towards an optimal trajectory through
Stein Variational Gradient Descent (SVGD). MPPI is traditionally reliant on
randomly sampled trajectories, often by a Gaussian distribution. The result can
lead to sample deprivation, under-representing the space of possible
trajectories, and yield suboptimal results. Through introducing SVGD updates in
between MPPI environment steps, we present Stein-Optimized Path-Integral
Inference (SOPPI), an MPPI/SVGD algorithm that can dynamically update noise
distributions at runtime to shape a more optimal representation without an
excessive increase in computational requirements. We demonstrate the efficacy
of our method systems ranging from a Cart-Pole to a two-dimensional bipedal
walking task, indicating improved performance above standard MPPI across a
range of hyper-parameters and demonstrate feasibility at lower particle counts.
We discuss the applicability of this MPPI/SVGD method to higher
degree-of-freedom systems, as well as its potential to new developments in
state-of-the-art differentiable simulators.

</details>


### [11] [TurboMap: GPU-Accelerated Local Mapping for Visual SLAM](https://arxiv.org/abs/2511.02036)
*Parsa Hosseininejad,Kimia Khabiri,Shishir Gopinath,Soudabeh Mohammadhashemi,Karthik Dantu,Steven Y. Ko*

Main category: cs.RO

TL;DR: TurboMap是一个GPU加速和CPU优化的视觉SLAM局部建图模块，通过在GPU上执行地图点三角化和融合，在CPU上加速冗余关键帧剔除，并集成GPU加速求解器来提升局部束调整性能。


<details>
  <summary>Details</summary>
Motivation: 识别视觉SLAM中局部建图过程的关键性能瓶颈，通过针对性的GPU和CPU优化来解决这些问题。

Method: 在ORB-SLAM3基础上构建，使用CUDA进行GPU编程，将地图点三角化和融合卸载到GPU，在CPU上加速冗余关键帧剔除，集成GPU加速求解器加速局部束调整。

Result: 在EuRoC数据集上平均加速1.3倍，在TUM-VI数据集上平均加速1.6倍，同时在桌面和嵌入式平台上保持原始系统的精度。

Conclusion: TurboMap通过GPU和CPU协同优化，显著提升了视觉SLAM局部建图模块的性能，同时保持了系统精度。

Abstract: This paper presents TurboMap, a GPU-accelerated and CPU-optimized local
mapping module for visual SLAM systems. We identify key performance bottlenecks
in the local mapping process for visual SLAM and address them through targeted
GPU and CPU optimizations. Specifically, we offload map point triangulation and
fusion to the GPU, accelerate redundant keyframe culling on the CPU, and
integrate a GPU-accelerated solver to speed up local bundle adjustment. Our
implementation is built on top of ORB-SLAM3 and leverages CUDA for GPU
programming. The experimental results show that TurboMap achieves an average
speedup of 1.3x in the EuRoC dataset and 1.6x in the TUM-VI dataset in the
local mapping module, on both desktop and embedded platforms, while maintaining
the accuracy of the original system.

</details>


### [12] [TACO: Trajectory-Aware Controller Optimization for Quadrotors](https://arxiv.org/abs/2511.02060)
*Hersh Sanghvi,Spencer Folk,Vijay Kumar,Camillo Jose Taylor*

Main category: cs.RO

TL;DR: TACO是一个实时优化四旋翼控制器参数的框架，能够根据参考轨迹和当前状态自适应调整参数，显著提升轨迹跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 传统四旋翼控制器使用固定参数，无法针对不同轨迹进行优化，牺牲了任务特定性能。

Method: 使用学习预测模型和轻量级优化方案，实时优化控制器增益，并能调整轨迹以提高动态可行性。

Result: TACO在多种轨迹类型上优于传统静态参数调优，运行速度比黑盒优化基线快几个数量级，在物理四旋翼上实现实时部署。

Conclusion: TACO框架能显著降低四旋翼的跟踪误差，通过轨迹自适应进一步提升性能。

Abstract: Controller performance in quadrotor trajectory tracking depends heavily on
parameter tuning, yet standard approaches often rely on fixed, manually tuned
parameters that sacrifice task-specific performance. We present
Trajectory-Aware Controller Optimization (TACO), a framework that adapts
controller parameters online based on the upcoming reference trajectory and
current quadrotor state. TACO employs a learned predictive model and a
lightweight optimization scheme to optimize controller gains in real time with
respect to a broad class of trajectories, and can also be used to adapt
trajectories to improve dynamic feasibility while respecting smoothness
constraints. To enable large-scale training, we also introduce a parallelized
quadrotor simulator supporting fast data collection on diverse trajectories.
Experiments on a variety of trajectory types show that TACO outperforms
conventional, static parameter tuning while operating orders of magnitude
faster than black-box optimization baselines, enabling practical real-time
deployment on a physical quadrotor. Furthermore, we show that adapting
trajectories using TACO significantly reduces the tracking error obtained by
the quadrotor.

</details>


### [13] [A Step Toward World Models: A Survey on Robotic Manipulation](https://arxiv.org/abs/2511.02097)
*Peng-Fei Zhang,Ying Cheng,Xiaofan Sun,Shijie Wang,Lei Zhu,Heng Tao Shen*

Main category: cs.RO

TL;DR: 本文综述了机器人操作领域中的世界模型方法，分析了其在感知、预测和控制中的作用，旨在为开发通用实用的机器人世界模型制定路线图。


<details>
  <summary>Details</summary>
Motivation: 自主代理需要在复杂动态环境中执行任务，这要求它们理解世界机制和动态，而不仅仅是反应式控制或状态复制，因此需要开发能够编码环境状态、捕捉动态并支持预测、规划和推理的世界模型。

Method: 通过回顾机器人操作方法，分析展现世界模型核心能力的方法，考察它们在感知、预测和控制中的角色，识别关键挑战和解决方案。

Result: 提炼了真实世界模型应具备的核心组件、能力和功能，澄清了世界模型的定义、范围、架构和基本能力。

Conclusion: 基于分析结果，为开发通用实用的机器人世界模型制定了路线图，强调了世界模型在实现自主代理复杂任务能力中的重要性。

Abstract: Autonomous agents are increasingly expected to operate in complex, dynamic,
and uncertain environments, performing tasks such as manipulation, navigation,
and decision-making. Achieving these capabilities requires agents to understand
the underlying mechanisms and dynamics of the world, moving beyond purely
reactive control or simple replication of observed states. This motivates the
development of world models as internal representations that encode
environmental states, capture dynamics, and enable prediction, planning, and
reasoning. Despite growing interest, the definition, scope, architectures, and
essential capabilities of world models remain ambiguous. In this survey, rather
than directly imposing a fixed definition and limiting our scope to methods
explicitly labeled as world models, we examine approaches that exhibit the core
capabilities of world models through a review of methods in robotic
manipulation. We analyze their roles across perception, prediction, and
control, identify key challenges and solutions, and distill the core
components, capabilities, and functions that a real world model should possess.
Building on this analysis, we aim to outline a roadmap for developing
generalizable and practical world models for robotics.

</details>


### [14] [Census-Based Population Autonomy For Distributed Robotic Teaming](https://arxiv.org/abs/2511.02147)
*Tyler M. Paine,Anastasia Bizyaeva,Michael R. Benjamin*

Main category: cs.RO

TL;DR: 本文提出了一种多机器人自主性的分层模型，结合了基于邻域输入加权计数的集体决策和基于多目标行为优化的个体决策，通过非线性意见动态模型和区间规划实现，可恢复分布式优化和控制的基础算法，并在自主水面车辆实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统在海洋环境中具有高效性和鲁棒性优势，但如何建模、分析和设计这些系统以实现协作的全部效益是一个挑战，因为多机器人自主性领域既包含集体行为也包含个体行为。

Method: 引入分层模型：集体决策使用基于邻域输入加权计数的非线性意见动态模型，个体决策使用区间规划进行多目标行为优化。还提出了一种分布式子群分配优化方法，机器人使用梯度下降算法最小化局部已知成本函数部分，同时受邻域意见状态影响以考虑未观测成本。

Result: 该模型可以恢复分布式优化和控制的基础算法，同时支持在现实场景中有用的新型集体行为。在三个不同类型的自主水面车辆实验中验证了模型的有效性：自适应采样场景、高价值单元保护场景和夺旗竞争游戏。

Conclusion: 提出的分层模型能够有效协调多机器人系统的集体和个体决策，通过实验验证了其在多种现实场景中的实用性，为多机器人协作系统设计提供了新方法。

Abstract: Collaborating teams of robots show promise due in their ability to complete
missions more efficiently and with improved robustness, attributes that are
particularly useful for systems operating in marine environments. A key issue
is how to model, analyze, and design these multi-robot systems to realize the
full benefits of collaboration, a challenging task since the domain of
multi-robot autonomy encompasses both collective and individual behaviors. This
paper introduces a layered model of multi-robot autonomy that uses the
principle of census, or a weighted count of the inputs from neighbors, for
collective decision-making about teaming, coupled with multi-objective behavior
optimization for individual decision-making about actions. The census component
is expressed as a nonlinear opinion dynamics model and the multi-objective
behavior optimization is accomplished using interval programming. This model
can be reduced to recover foundational algorithms in distributed optimization
and control, while the full model enables new types of collective behaviors
that are useful in real-world scenarios. To illustrate these points, a new
method for distributed optimization of subgroup allocation is introduced where
robots use a gradient descent algorithm to minimize portions of the cost
functions that are locally known, while being influenced by the opinion states
from neighbors to account for the unobserved costs. With this method the group
can collectively use the information contained in the Hessian matrix of the
total global cost. The utility of this model is experimentally validated in
three categorically different experiments with fleets of autonomous surface
vehicles: an adaptive sampling scenario, a high value unit protection scenario,
and a competitive game of capture the flag.

</details>


### [15] [Text to Robotic Assembly of Multi Component Objects using 3D Generative AI and Vision Language Models](https://arxiv.org/abs/2511.02162)
*Alexander Htet Kyaw,Richa Gupta,Dhruv Shah,Anoop Sinha,Kory Mathewson,Stefanie Pender,Sachin Chitta,Yotto Koga,Faez Ahmed,Lawrence Sass,Randall Davis*

Main category: cs.RO

TL;DR: 提出了一种结合3D生成AI和视觉语言模型的管道，用于从自然语言实现多组件物体的机器人装配。


<details>
  <summary>Details</summary>
Motivation: 解决3D生成AI在创建多组件物体时的挑战，实现从文本提示到物理对象装配的完整流程。

Method: 利用视觉语言模型进行零样本多模态推理，将AI生成的网格分解为多组件3D模型，使用预定义的结构和面板组件。

Result: 评估显示用户90.6%的时间偏好VLM生成的组件分配，优于规则基础的59.4%和随机的2.5%。

Conclusion: 该系统通过对话反馈允许用户细化组件分配，为使用生成AI和机器人制造物理对象提供了更好的人类控制和参与度。

Abstract: Advances in 3D generative AI have enabled the creation of physical objects
from text prompts, but challenges remain in creating objects involving multiple
component types. We present a pipeline that integrates 3D generative AI with
vision-language models (VLMs) to enable the robotic assembly of multi-component
objects from natural language. Our method leverages VLMs for zero-shot,
multi-modal reasoning about geometry and functionality to decompose
AI-generated meshes into multi-component 3D models using predefined structural
and panel components. We demonstrate that a VLM is capable of determining which
mesh regions need panel components in addition to structural components, based
on object functionality. Evaluation across test objects shows that users
preferred the VLM-generated assignments 90.6% of the time, compared to 59.4%
for rule-based and 2.5% for random assignment. Lastly, the system allows users
to refine component assignments through conversational feedback, enabling
greater human control and agency in making physical objects with generative AI
and robotics.

</details>


### [16] [Kinematic and Ergonomic Design of a Robotic Arm for Precision Laparoscopic Surgery](https://arxiv.org/abs/2511.02167)
*Tian Hao,Tong Lu,Che Chan*

Main category: cs.RO

TL;DR: 提出一种7自由度腹腔镜手术机器人臂，通过运动学优化和人机工程学设计，显著提高手术精度（误差减少50%以上）和效率，同时降低操作者肌肉劳损。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助微创手术能提高手术精度和减少外科医生疲劳，但现有系统在运动学和人体工程学设计方面仍有优化空间。

Method: 设计具有远程运动中心（RCM）的7自由度机器人臂系统，在通用机器人平台上实现，通过模拟手术任务评估目标精度、任务效率和外科医生舒适度。

Result: 实验结果显示，优化后的机器人设计显著提高了目标精度（误差减少超过50%），缩短了任务完成时间，同时大幅降低了操作者肌肉劳损和不适感。

Conclusion: 运动学优化（如增加关节和震颤过滤）和以人为本的人机工程学设计对提升机器人辅助手术性能至关重要，这些见解可指导下一代手术机器人的开发。

Abstract: Robotic assistance in minimally invasive surgery can greatly enhance surgical
precision and reduce surgeon fatigue. This paper presents a focused
investigation on the kinematic and ergonomic design principles for a
laparoscopic surgical robotic arm aimed at high-precision tasks. We propose a
7-degree-of-freedom (7-DOF) robotic arm system that incorporates a remote
center of motion (RCM) at the instrument insertion point and ergonomic
considerations to improve surgeon interaction. The design is implemented on a
general-purpose robotic platform, and a series of simulated surgical tasks were
performed to evaluate targeting accuracy, task efficiency, and surgeon comfort
compared to conventional manual laparoscopy. Experimental results demonstrate
that the optimized robotic design achieves significantly improved targeting
accuracy (error reduced by over 50%) and shorter task completion times, while
substantially lowering operator muscle strain and discomfort. These findings
validate the importance of kinematic optimization (such as added articulations
and tremor filtering) and human-centered ergonomic design in enhancing the
performance of robot-assisted surgery. The insights from this work can guide
the development of next-generation surgical robots that improve surgical
outcomes and ergonomics for the operating team.

</details>


### [17] [A Quantitative Comparison of Centralised and Distributed Reinforcement Learning-Based Control for Soft Robotic Arms](https://arxiv.org/abs/2511.02192)
*Linxin Hou,Qirui Wu,Zhihang Qin,Neil Banerjee,Yongxin Guo,Cecilia Laschi*

Main category: cs.RO

TL;DR: 比较集中式和分布式多智能体强化学习在软体机器人臂控制中的性能，发现当控制段数n≤4时分布式策略无显著优势，n≤2时集中式策略更优，4<n≤12时分布式策略在样本效率、成功率、鲁棒性方面表现更好，但集中式策略训练时间效率更高。


<details>
  <summary>Details</summary>
Motivation: 研究集中式和分布式多智能体强化学习架构在软体机器人臂控制中的性能差异，为软体机器人系统的控制策略选择提供指导。

Method: 使用PyElastica和OpenAI Gym接口，在相同计算预算下训练全局PPO控制器和Multi-Agent PPO，系统改变控制段数n，评估三种场景下的性能：默认基线条件、外部干扰恢复、执行器故障适应。

Result: 当n≤4时分布式策略无显著优势；n≤2时集中式策略表现更好；4<n≤12时分布式策略样本效率高，成功率和鲁棒性更强，收敛更快；但集中式策略训练时间效率更高。

Conclusion: 集中式和分布式策略在软体机器人控制中存在权衡，分布式策略在复杂系统中具有样本效率和鲁棒性优势，而集中式策略训练时间效率更高，为软体机器人系统的控制策略设计提供了实用指导。

Abstract: This paper presents a quantitative comparison between centralised and
distributed multi-agent reinforcement learning (MARL) architectures for
controlling a soft robotic arm modelled as a Cosserat rod in simulation. Using
PyElastica and the OpenAI Gym interface, we train both a global Proximal Policy
Optimisation (PPO) controller and a Multi-Agent PPO (MAPPO) under identical
budgets. Both approaches are based on the arm having $n$ number of controlled
sections. The study systematically varies $n$ and evaluates the performance of
the arm to reach a fixed target in three scenarios: default baseline condition,
recovery from external disturbance, and adaptation to actuator failure.
Quantitative metrics used for the evaluation are mean action magnitude, mean
final distance, mean episode length, and success rate. The results show that
there are no significant benefits of the distributed policy when the number of
controlled sections $n\le4$. In very simple systems, when $n\le2$, the
centralised policy outperforms the distributed one. When $n$ increases to $4<
n\le 12$, the distributed policy shows a high sample efficiency. In these
systems, distributed policy promotes a stronger success rate, resilience, and
robustness under local observability and yields faster convergence given the
same sample size. However, centralised policies achieve much higher time
efficiency during training as it takes much less time to train the same size of
samples. These findings highlight the trade-offs between centralised and
distributed policy in reinforcement learning-based control for soft robotic
systems and provide actionable design guidance for future sim-to-real transfer
in soft rod-like manipulators.

</details>


### [18] [LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation](https://arxiv.org/abs/2511.02239)
*Youngjin Hong,Houjian Yu,Mingen Li,Changhyun Choi*

Main category: cs.RO

TL;DR: LACY是一个统一框架，通过联合训练语言到动作(L2A)、动作到语言(A2L)和语言一致性验证(L2C)三个任务，实现双向语言-动作映射，并通过主动增强策略自我改进，在机器人操作任务中显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 当前基于语言指令到动作(L2A)的单向范式缺乏对任务情境的深度理解，限制了策略的泛化能力和行为解释性。需要引入动作到语言(A2L)的互补技能来发展更全面的基础理解。

Method: 在单一视觉语言模型中联合训练三个协同任务：从语言生成参数化动作(L2A)、用语言解释观察到的动作(A2L)、验证两个语言描述之间的语义一致性(L2C)。采用主动增强策略针对低置信度案例自主生成和过滤训练数据。

Result: 在模拟和真实世界的拾取放置任务中，LACY平均提高任务成功率56.46%，并产生更鲁棒的语言-动作基础理解。

Conclusion: 双向语言-动作映射框架能够形成更丰富的内部表示，解锁自监督学习的新范式，显著提升机器人操作的性能和可解释性。

Abstract: Learning generalizable policies for robotic manipulation increasingly relies
on large-scale models that map language instructions to actions (L2A). However,
this one-way paradigm often produces policies that execute tasks without deeper
contextual understanding, limiting their ability to generalize or explain their
behavior. We argue that the complementary skill of mapping actions back to
language (A2L) is essential for developing more holistic grounding. An agent
capable of both acting and explaining its actions can form richer internal
representations and unlock new paradigms for self-supervised learning. We
introduce LACY (Language-Action Cycle), a unified framework that learns such
bidirectional mappings within a single vision-language model. LACY is jointly
trained on three synergistic tasks: generating parameterized actions from
language (L2A), explaining observed actions in language (A2L), and verifying
semantic consistency between two language descriptions (L2C). This enables a
self-improving cycle that autonomously generates and filters new training data
through an active augmentation strategy targeting low-confidence cases, thereby
improving the model without additional human labels. Experiments on
pick-and-place tasks in both simulation and the real world show that LACY
improves task success rates by 56.46% on average and yields more robust
language-action grounding for robotic manipulation. Project page:
https://vla2026.github.io/LACY/

</details>


### [19] [SuckTac: Camera-based Tactile Sucker for Unstructured Surface Perception and Interaction](https://arxiv.org/abs/2511.02294)
*Ruiyong Yuan,Jieji Ren,Zhanxuan Peng,Feifei Chen,Guoying Gu*

Main category: cs.RO

TL;DR: 提出了一种新型智能吸盘SuckTac，集成了摄像头触觉传感器，能够提供高密度感知和鲁棒吸附能力，灵感来自头足类动物的自适应结构和感官能力。


<details>
  <summary>Details</summary>
Motivation: 现有吸盘缺乏高保真感知和触觉传感能力，无法识别目标表面的精细几何特征和交互状态，限制了在复杂非结构化环境中的鲁棒性能。

Method: 通过联合结构设计和优化，采用多材料集成铸造技术，将摄像头和光源嵌入吸盘内部，实现原位高密度感知；同时优化机械设计，包括改进轮廓、添加柔性唇缘和表面微结构。

Result: 在机器人布料操作和软体移动机器人检查等挑战性任务中，展示了优越的性能和广泛适用性。

Conclusion: SuckTac吸盘系统通过集成触觉感知和结构优化，显著提升了在复杂环境中的吸附性能和适应性。

Abstract: Suckers are significant for robots in picking, transferring, manipulation and
locomotion on diverse surfaces. However, most of the existing suckers lack
high-fidelity perceptual and tactile sensing, which impedes them from resolving
the fine-grained geometric features and interaction status of the target
surface. This limits their robust performance with irregular objects and in
complex, unstructured environments. Inspired by the adaptive structure and
high-performance sensory capabilities of cephalopod suckers, in this paper, we
propose a novel, intelligent sucker, named SuckTac, that integrates a
camera-based tactile sensor directly within its optimized structure to provide
high-density perception and robust suction. Specifically, through joint
structure design and optimization and based on a multi-material integrated
casting technique, a camera and light source are embedded into the sucker,
which enables in-situ, high-density perception of fine details like surface
shape, texture and roughness. To further enhance robustness and adaptability,
the sucker's mechanical design is also optimized by refining its profile,
adding a compliant lip, and incorporating surface microstructure. Extensive
experiments, including challenging tasks such as robotic cloth manipulation and
soft mobile robot inspection, demonstrate the superior performance and broad
applicability of the proposed system.

</details>


### [20] [ZJUNlict Extended Team Description Paper 2025](https://arxiv.org/abs/2511.02315)
*Zifei Wu,Lijie Wang,Zhe Yang,Shijie Yang,Liang Wang,Haoran Fu,Yinliang Cai,Rong Xiong*

Main category: cs.RO

TL;DR: ZJUNlict团队在硬件和软件方面的年度进展：硬件上为v2023机器人集成IMU提升姿态精度和角速度规划；软件上优化策略和CUDA模块，显著提升决策效率、球追踪预测和控球预测能力以适应快节奏比赛。


<details>
  <summary>Details</summary>
Motivation: 为了适应快节奏的机器人足球比赛动态，需要提升机器人的姿态控制精度和软件决策效率，以在高速对抗中保持竞争优势。

Method: 硬件方面：为v2023机器人集成惯性测量单元(IMU)；软件方面：优化策略模块和CUDA模块，改进决策算法、球追踪预测和控球预测功能。

Result: 实现了机器人姿态精度和角速度规划的提升，决策效率、球追踪预测准确性和控球预测能力得到显著改善。

Conclusion: 通过硬件IMU集成和软件模块优化，ZJUNlict团队成功提升了机器人在快节奏比赛中的整体性能和适应性。

Abstract: This paper presents the ZJUNlict team's work over the past year, covering
both hardware and software advancements. In the hardware domain, the
integration of an IMU into the v2023 robot was completed to enhance posture
accuracy and angular velocity planning. On the software side, key modules were
optimized, including the strategy and CUDA modules, with significant
improvements in decision making efficiency, ball pursuit prediction, and ball
possession prediction to adapt to high-tempo game dynamics.

</details>


### [21] [Whole-body motion planning and safety-critical control for aerial manipulation](https://arxiv.org/abs/2511.02342)
*Lin Yang,Jinwoo Lee,Domenico Campolo,H. Jin Kim,Jeonghyun Byun*

Main category: cs.RO

TL;DR: 提出了基于超二次曲面的空中机械臂运动规划和安全控制框架，通过几何精确的建模和最大间隙规划器，在复杂环境中生成平滑、安全的轨迹。


<details>
  <summary>Details</summary>
Motivation: 解决空中机械臂在复杂空间中规划安全、动态可行轨迹的挑战，克服传统几何抽象（如边界框或椭球体）的保守性。

Method: 使用超二次曲面加代理表示法建模车辆和障碍物，结合Voronoi图和平衡流形公式的最大间隙规划器，以及基于高阶控制屏障函数的安全关键控制器。

Result: 在模拟中优于基于采样的规划器，产生更快、更安全、更平滑的轨迹，在几何保真度上超过基于椭球体的基线方法。物理实验验证了可行性和鲁棒性。

Conclusion: 该框架在仿真和硬件设置中均表现出色，为空中机械臂在复杂环境中的安全操作提供了有效解决方案。

Abstract: Aerial manipulation combines the maneuverability of multirotors with the
dexterity of robotic arms to perform complex tasks in cluttered spaces. Yet
planning safe, dynamically feasible trajectories remains difficult due to
whole-body collision avoidance and the conservativeness of common geometric
abstractions such as bounding boxes or ellipsoids. We present a whole-body
motion planning and safety-critical control framework for aerial manipulators
built on superquadrics (SQs). Using an SQ-plus-proxy representation, we model
both the vehicle and obstacles with differentiable, geometry-accurate surfaces.
Leveraging this representation, we introduce a maximum-clearance planner that
fuses Voronoi diagrams with an equilibrium-manifold formulation to generate
smooth, collision-aware trajectories. We further design a safety-critical
controller that jointly enforces thrust limits and collision avoidance via
high-order control barrier functions. In simulation, our approach outperforms
sampling-based planners in cluttered environments, producing faster, safer, and
smoother trajectories and exceeding ellipsoid-based baselines in geometric
fidelity. Actual experiments on a physical aerial-manipulation platform confirm
feasibility and robustness, demonstrating consistent performance across
simulation and hardware settings. The video can be found at
https://youtu.be/hQYKwrWf1Ak.

</details>


### [22] [Dexterous Robotic Piano Playing at Scale](https://arxiv.org/abs/2511.02504)
*Le Chen,Yi Zhao,Jan Schneider,Quankai Gao,Simon Guist,Cheng Qian,Juho Kannala,Bernhard Schölkopf,Joni Pajarinen,Dieter Büchler*

Main category: cs.RO

TL;DR: OmniPianist是第一个能够通过可扩展、无需人类演示的学习方式演奏近千首音乐作品的机器人代理，它通过最优传输自动指法、大规模强化学习和流匹配变换器实现了双手机器人钢琴演奏。


<details>
  <summary>Details</summary>
Motivation: 赋予机器人手人类水平的灵巧性是机器人学的长期目标，双手机器人钢琴演奏是一个特别具有挑战性的任务：高维度、接触丰富且需要快速精确的控制。

Method: 1. 基于最优传输的自动指法策略；2. 训练2000多个专门化代理的大规模强化学习，构建RP1M++数据集；3. 使用流匹配变换器进行大规模模仿学习。

Result: 开发出能够演奏广泛音乐作品的OmniPianist代理，实验验证了方法的有效性和可扩展性。

Conclusion: 该方法推进了大规模灵巧机器人钢琴演奏的发展，展示了无需人类演示的可扩展学习方法的潜力。

Abstract: Endowing robot hands with human-level dexterity has been a long-standing goal
in robotics. Bimanual robotic piano playing represents a particularly
challenging task: it is high-dimensional, contact-rich, and requires fast,
precise control. We present OmniPianist, the first agent capable of performing
nearly one thousand music pieces via scalable, human-demonstration-free
learning. Our approach is built on three core components. First, we introduce
an automatic fingering strategy based on Optimal Transport (OT), allowing the
agent to autonomously discover efficient piano-playing strategies from scratch
without demonstrations. Second, we conduct large-scale Reinforcement Learning
(RL) by training more than 2,000 agents, each specialized in distinct music
pieces, and aggregate their experience into a dataset named RP1M++, consisting
of over one million trajectories for robotic piano playing. Finally, we employ
a Flow Matching Transformer to leverage RP1M++ through large-scale imitation
learning, resulting in the OmniPianist agent capable of performing a wide range
of musical pieces. Extensive experiments and ablation studies highlight the
effectiveness and scalability of our approach, advancing dexterous robotic
piano playing at scale.

</details>


### [23] [Non-Contact Manipulation of Induced Magnetic Dipoles](https://arxiv.org/abs/2511.02761)
*Seth Stewart,Joseph Pawelski,Steve Ward,Andrew J. Petruska*

Main category: cs.RO

TL;DR: 该论文展示了导电非磁性物体在振荡磁场中的闭环位置控制，特别关注空间碎片回收应用。


<details>
  <summary>Details</summary>
Motivation: 将磁操纵扩展到导电非磁性物体，为空间碎片回收等应用开辟新途径，利用感应涡流产生的反向磁矩进行控制。

Method: 在实验室测试中实现半浮铝球的闭环位置控制，探索了多种力反演方法的有效性。

Result: 成功演示了感应磁偶极子的3自由度位置闭环控制，这是迈向更广泛应用的关键第一步。

Conclusion: 闭环控制方法代表了感应磁偶极子3-DOF位置控制向更广泛应用迈出的重要进展。

Abstract: Extending the field of magnetic manipulation to conductive, non-magnetic
objects opens the door for a wide array of applications previously limited to
hard or soft magnetic materials. Of particular interest is the recycling of
space debris through the use of oscillating magnetic fields, which represent a
cache of raw materials in an environment particularly suited to the low forces
generated from inductive magnetic manipulation. Building upon previous work
that demonstrated 3D open-loop position control by leveraging the opposing
dipole moment created from induced eddy currents, this work demonstrates
closed-loop position control of a semi-buoyant aluminum sphere in lab tests,
and the efficacy of varying methods for force inversion is explored. The
closed-loop methods represent a critical first step towards wider applications
for 3-DOF position control of induced magnetic dipoles.

</details>


### [24] [XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations](https://arxiv.org/abs/2511.02776)
*Shichao Fan,Kun Wu,Zhengping Che,Xinhua Wang,Di Wu,Fei Liao,Ning Liu,Yixue Zhang,Zhen Zhao,Zhiyuan Xu,Meng Li,Qingjie Liu,Shanghang Zhang,Min Wan,Jian Tang*

Main category: cs.RO

TL;DR: XR-1是一个新颖的视觉语言动作模型框架，通过统一视觉运动编码(UVMC)解决了现有VLA模型在精确低层动作生成和跨异构数据源领域差距方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型面临两个基本挑战：(i)从高维观察生成精确的低层动作，(ii)跨越异构数据源（包括不同机器人体现和人类演示）的领域差距。现有方法未能充分利用大规模异构数据集中的互补多模态知识。

Method: XR-1引入统一视觉运动编码(UVMC)，通过双分支VQ-VAE联合编码视觉动态和机器人运动。采用三阶段训练范式：自监督UVMC学习、UVMC引导的大规模跨体现机器人数据集预训练、任务特定后训练。

Result: 在6种不同机器人体现上进行了超过14,000次部署实验，涵盖120多个多样化操作任务。XR-1在π₀.₅、π₀、RDT、UniVLA和GR00T-N1.5等基准方法上表现一致更优，并展现出对新物体、背景变化、干扰物和光照变化的强泛化能力。

Conclusion: XR-1通过UVMC表示和三阶段训练范式，有效解决了VLA模型的关键挑战，为跨不同机器人、任务和环境的通用可扩展学习提供了有前景的解决方案。

Abstract: Recent progress in large-scale robotic datasets and vision-language models
(VLMs) has advanced research on vision-language-action (VLA) models. However,
existing VLA models still face two fundamental challenges: (i) producing
precise low-level actions from high-dimensional observations, (ii) bridging
domain gaps across heterogeneous data sources, including diverse robot
embodiments and human demonstrations. Existing methods often encode latent
variables from either visual dynamics or robotic actions to guide policy
learning, but they fail to fully exploit the complementary multi-modal
knowledge present in large-scale, heterogeneous datasets. In this work, we
present X Robotic Model 1 (XR-1), a novel framework for versatile and scalable
VLA learning across diverse robots, tasks, and environments. XR-1 introduces
the \emph{Unified Vision-Motion Codes (UVMC)}, a discrete latent representation
learned via a dual-branch VQ-VAE that jointly encodes visual dynamics and
robotic motion. UVMC addresses these challenges by (i) serving as an
intermediate representation between the observations and actions, and (ii)
aligning multimodal dynamic information from heterogeneous data sources to
capture complementary knowledge. To effectively exploit UVMC, we propose a
three-stage training paradigm: (i) self-supervised UVMC learning, (ii)
UVMC-guided pretraining on large-scale cross-embodiment robotic datasets, and
(iii) task-specific post-training. We validate XR-1 through extensive
real-world experiments with more than 14,000 rollouts on six different robot
embodiments, spanning over 120 diverse manipulation tasks. XR-1 consistently
outperforms state-of-the-art baselines such as $\pi_{0.5}$, $\pi_0$, RDT,
UniVLA, and GR00T-N1.5 while demonstrating strong generalization to novel
objects, background variations, distractors, and illumination changes. Our
project is at https://xr-1-vla.github.io/.

</details>


### [25] [TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System](https://arxiv.org/abs/2511.02832)
*Yanjie Ze,Siheng Zhao,Weizhuo Wang,Angjoo Kanazawa,Rocky Duan,Pieter Abbeel,Guanya Shi,Jiajun Wu,C. Karen Liu*

Main category: cs.RO

TL;DR: TWIST2是一个便携式、无需动作捕捉的人形机器人遥操作和数据收集系统，通过VR设备实现全身控制，能够高效收集演示数据并训练分层视觉运动策略。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人缺乏有效的数据收集框架，现有遥操作系统要么使用解耦控制，要么依赖昂贵的动作捕捉设备，限制了可扩展性。

Method: 使用PICO4U VR获取实时全身人体运动，配合定制的2自由度机器人颈部（成本约250美元）实现自我中心视觉，构建整体的人到人形机器人控制系统。

Result: 系统能够执行长时间跨度的灵巧移动技能，15分钟内可收集100次演示，成功率接近100%。基于此构建的分层视觉运动策略能够自主控制完整人形机器人身体。

Conclusion: TWIST2提供了一个完全可复现的开源系统，解决了人形机器人数据收集的瓶颈，推动了人形机器人技术的发展。

Abstract: Large-scale data has driven breakthroughs in robotics, from language models
to vision-language-action models in bimanual manipulation. However, humanoid
robotics lacks equally effective data collection frameworks. Existing humanoid
teleoperation systems either use decoupled control or depend on expensive
motion capture setups. We introduce TWIST2, a portable, mocap-free humanoid
teleoperation and data collection system that preserves full whole-body control
while advancing scalability. Our system leverages PICO4U VR for obtaining
real-time whole-body human motions, with a custom 2-DoF robot neck (cost around
$250) for egocentric vision, enabling holistic human-to-humanoid control. We
demonstrate long-horizon dexterous and mobile humanoid skills and we can
collect 100 demonstrations in 15 minutes with an almost 100% success rate.
Building on this pipeline, we propose a hierarchical visuomotor policy
framework that autonomously controls the full humanoid body based on egocentric
vision. Our visuomotor policy successfully demonstrates whole-body dexterous
manipulation and dynamic kicking tasks. The entire system is fully reproducible
and open-sourced at https://yanjieze.com/TWIST2 . Our collected dataset is also
open-sourced at https://twist-data.github.io .

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [26] [Missing the Margins: A Systematic Literature Review on the Demographic Representativeness of LLMs](https://arxiv.org/abs/2511.01864)
*Indira Sen,Marlene Lutz,Elisa Rogers,David Garcia,Markus Strohmaier*

Main category: cs.CY

TL;DR: 本文通过回顾211篇关于LLM人口统计代表性的论文，发现对LLM代表性的认知存在夸大，许多研究在评估方法、人口子类别覆盖和样本定义方面存在不足。


<details>
  <summary>Details</summary>
Motivation: LLM在模拟人类行为和提供个性化功能方面的应用日益广泛，其人口统计代表性对于公平性至关重要，但目前关于LLM是否真实反映特定群体人口属性和行为的研究结论相互矛盾。

Method: 系统性回顾211篇关于LLM人口统计代表性的研究论文，分析这些研究在评估方法、人口子类别覆盖、边缘群体包含和目标人群定义等方面的不足。

Result: 29%的研究报告LLM具有代表性，但其中30%未跨多个人口类别评估，35%和47%未明确性别和种族子类别，不到一半包含边缘群体，超过三分之一未定义目标人群，大多数仅研究美国样本。

Conclusion: 当前对LLM代表性的认知存在夸大，建议采用更精确的评估方法和全面的人口属性文档记录，以确保LLM在社会应用中的负责任使用。

Abstract: Many applications of Large Language Models (LLMs) require them to either
simulate people or offer personalized functionality, making the demographic
representativeness of LLMs crucial for equitable utility. At the same time, we
know little about the extent to which these models actually reflect the
demographic attributes and behaviors of certain groups or populations, with
conflicting findings in empirical research. To shed light on this debate, we
review 211 papers on the demographic representativeness of LLMs. We find that
while 29% of the studies report positive conclusions on the representativeness
of LLMs, 30% of these do not evaluate LLMs across multiple demographic
categories or within demographic subcategories. Another 35% and 47% of the
papers concluding positively fail to specify these subcategories altogether for
gender and race, respectively. Of the articles that do report subcategories,
fewer than half include marginalized groups in their study. Finally, more than
a third of the papers do not define the target population to whom their
findings apply; of those that do define it either implicitly or explicitly, a
large majority study only the U.S. Taken together, our findings suggest an
inflated perception of LLM representativeness in the broader community. We
recommend more precise evaluation methods and comprehensive documentation of
demographic attributes to ensure the responsible use of LLMs for social
applications. Our annotated list of papers and analysis code is publicly
available.

</details>


### [27] [Story and essential meaning dynamics in Bangladesh's July 2024 Student-People's Uprising](https://arxiv.org/abs/2511.01865)
*Tabia Tanzin Prama,Christopher M. Danforth,Peter Sheridan Dodds*

Main category: cs.CY

TL;DR: 通过分析2024年7月孟加拉国学生-人民起义期间的5万条YouTube新闻评论，研究发现负面情绪主导了公众讨论，评论幸福感与抗议死亡人数呈负相关，话题从政治冲突逐渐转向社会正义。


<details>
  <summary>Details</summary>
Motivation: 研究新闻媒体在政治动荡时期如何影响公众情绪和话语演变，特别是在孟加拉国2024年7月学生-人民起义期间。

Method: 使用5万多条YouTube评论，通过情感分析、情绪分析、话题分析、词汇话语分析、时间线进展分析、情感转变分析和异位计量分析等综合方法。

Result: 负面情绪主导运动期间讨论；评论幸福感与抗议死亡人数呈负相关(r=-0.45)；公众反应呈现权力、侵略和危险的图景，同时保持希望和道德信念；话题从政治冲突转向社会正义；第二次断网后平均幸福感上升。

Conclusion: 公众话语在政治动荡期间经历了从抗议到正义的明显转变，即使在压制环境下，希望和道德信念的表达仍然持续。

Abstract: News media serves a crucial role in disseminating information and shaping
public perception, especially during periods of political unrest. Using over
50,0000 YouTube comments on news coverage from July 16 to August 6, 2024, we
investigate the emotional dynamics and evolving discourse of public perception
during the July 2024 Student-People's Uprising in Bangladesh. Through
integrated analyses of sentiment, emotion, topic, lexical discourse, timeline
progression, sentiment shifts, and allotaxonometry, we show how negative
sentiment dominated during the movement. We find a negative correlation between
comment happiness and number of protest deaths $(r = -0.45,\p = 0.00)$. Using
an ousiometer to measure essential meaning, we find public responses reflect a
landscape of power, aggression, and danger, alongside persistent expressions of
hope, moral conviction, and empowerment through goodnesses. Topic discourse
progressed during the movement, with peaks in `Political Conflict', `Media
Flow', and `Student Violence' during crisis surges, while topics like `Social
Resistance' and `Digital Movement' persisted amid repression. Sentiment shifts
reveal that after the second internet blackout, average happiness increased,
driven by the more frequent use of positive words such as `victory', `peace'
and `freedom' and a decrease in negative terms such as `death' and `lies'.
Finally, through allotaxonometric analysis, we observe a clear shift from
protest to justice.

</details>


### [28] [Online Behavioral Advertising: A Literature Review and Research Agenda](https://arxiv.org/abs/2511.01895)
*Sophie C. Boerman,Sanne Kruikemeier,Frederik J. Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 本文定义了在线行为广告(OBA)，开发了一个解释消费者对OBA反应的框架，并概述了实证发现和理论定位。


<details>
  <summary>Details</summary>
Motivation: 尽管OBA受到广泛关注，但缺乏明确的定义和实证研究积累，因此需要系统性地定义OBA并整合相关研究。

Method: 开发了一个框架，识别并整合了所有能解释消费者对OBA反应的因素，包括广告商控制因素和消费者控制因素。

Result: 框架表明OBA的结果取决于广告商控制因素（如个性化程度）和消费者控制因素（如知识和个体特征）。

Conclusion: 文章制定了研究议程，并讨论了给政策制定者和广告商的启示。

Abstract: Advertisers are increasingly monitoring people's online behavior and using
the information collected to show people individually targeted advertisements.
This phenomenon is called online behavioral advertising (OBA). Although
advertisers can benefit from OBA, the practice also raises concerns about
privacy. Therefore, OBA has received much attention from advertisers,
consumers, policymakers, and scholars. Despite this attention, there is neither
a strong definition of OBA nor a clear accumulation of empirical findings. This
article defines OBA and provides an overview of the empirical findings by
developing a framework that identifies and integrates all factors that can
explain consumer responses toward OBA. The framework suggests that the outcomes
of OBA are dependent on advertiser-controlled factors (e.g., the level of
personalization) and consumer-controlled factors (e.g., knowledge and
perceptions about OBA and individual characteristics). The article also
overviews the theoretical positioning of OBA by placing the theories that are
used to explain consumers' responses to OBA in our framework. Finally, we
develop a research agenda and discuss implications for policymakers and
advertisers.

</details>


### [29] [When Assurance Undermines Intelligence: The Efficiency Costs of Data Governance in AI-Enabled Labor Markets](https://arxiv.org/abs/2511.01923)
*Lei Chen,Chaoyue Gao,Alvin Leung,Xiaoning Wang*

Main category: cs.CY

TL;DR: 研究探讨了数据保护法规对生成式AI效率的影响，发现在香港限制用户数据用于模型训练后，LinkedIn的匹配效率下降，员工流动率上升，劳动力市场摩擦加剧。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI与数据保护之间的根本矛盾——信息保障（保护隐私数据）与人工智能（模型学习能力）之间的权衡关系。

Method: 利用香港监管干预暂停用户数据用于模型训练的自然实验，采用双重差分法分析大规模就业和职位发布数据。

Result: 限制数据使用显著降低了GenAI效率，导致匹配率降低、员工流动率上升、劳动力市场摩擦加剧，尤其影响依赖AI进行人才招聘的中小企业和快速增长企业。

Conclusion: 善意的数据治理可能带来意外的效率成本，信息保障虽然对信任至关重要，但如果与AI系统设计不匹配，可能会削弱智能驱动的效率。

Abstract: Generative artificial intelligence (GenAI) like Large Language Model (LLM) is
increasingly integrated into digital platforms to enhance information access,
deliver personalized experiences, and improve matching efficiency. However,
these algorithmic advancements rely heavily on large-scale user data, creating
a fundamental tension between information assurance-the protection, integrity,
and responsible use of privacy data-and artificial intelligence-the learning
capacity and predictive accuracy of models. We examine this
assurance-intelligence trade-off in the context of LinkedIn, leveraging a
regulatory intervention that suspended the use of user data for model training
in Hong Kong. Using large-scale employment and job posting data from Revelio
Labs and a Difference-in-Differences design, we show that restricting data use
significantly reduced GenAI efficiency, leading to lower matching rates, higher
employee turnover, and heightened labor market frictions. These effects were
especially pronounced for small and fast-growing firms that rely heavily on AI
for talent acquisition. Our findings reveal the unintended efficiency costs of
well-intentioned data governance and highlight that information assurance,
while essential for trust, can undermine intelligence-driven efficiency when
misaligned with AI system design. This study contributes to emerging research
on AI governance and digital platform by theorizing data assurance as an
institutional complement-and potential constraint-to GenAI efficacy in
data-intensive environments.

</details>


### [30] [Before the Clinic: Transparent and Operable Design Principles for Healthcare AI](https://arxiv.org/abs/2511.01902)
*Alexander Bakumenko,Aaron J. Masino,Janine Hoelscher*

Main category: cs.CY

TL;DR: 提出了两个基础设计原则——透明设计和可操作设计，为医疗AI系统在临床评估前提供可操作的技术要求指导。


<details>
  <summary>Details</summary>
Motivation: 解决可解释AI理论、临床医生期望和治理要求之间的差距，为开发团队在临床评估前准备AI系统提供实用指导。

Method: 提出透明设计（包括可解释性和可理解性构件）和可操作设计（包括校准、不确定性和鲁棒性）两个原则，并将其与现有XAI框架、临床需求和治理要求对齐。

Result: 建立了一个临床前指南，为开发团队提供可操作指导，加速临床评估进程，并在AI研究人员、医疗从业者和监管利益相关者之间建立共享词汇。

Conclusion: 通过明确界定临床部署前可构建和验证的内容，旨在减少临床AI转化的摩擦，同时对已验证的部署可解释性保持谨慎态度。

Abstract: The translation of artificial intelligence (AI) systems into clinical
practice requires bridging fundamental gaps between explainable AI theory,
clinician expectations, and governance requirements. While conceptual
frameworks define what constitutes explainable AI (XAI) and qualitative studies
identify clinician needs, little practical guidance exists for development
teams to prepare AI systems prior to clinical evaluation. We propose two
foundational design principles, Transparent Design and Operable Design, that
operationalize pre-clinical technical requirements for healthcare AI.
Transparent Design encompasses interpretability and understandability artifacts
that enable case-level reasoning and system traceability. Operable Design
encompasses calibration, uncertainty, and robustness to ensure reliable,
predictable system behavior under real-world conditions. We ground these
principles in established XAI frameworks, map them to documented clinician
needs, and demonstrate their alignment with emerging governance requirements.
This pre-clinical playbook provides actionable guidance for development teams,
accelerates the path to clinical evaluation, and establishes a shared
vocabulary bridging AI researchers, healthcare practitioners, and regulatory
stakeholders. By explicitly scoping what can be built and verified before
clinical deployment, we aim to reduce friction in clinical AI translation while
remaining cautious about what constitutes validated, deployed explainability.

</details>


### [31] [Thinking Like a Student: AI-Supported Reflective Planning in a Theory-Intensive Computer Science Course](https://arxiv.org/abs/2511.01906)
*Noa Izsak*

Main category: cs.CY

TL;DR: 使用大型语言模型作为反思规划工具，重新设计本科生形式方法和计算模型课程的强化辅导环节，通过模拟学生视角识别学习难点，改进教学结构。


<details>
  <summary>Details</summary>
Motivation: 疫情后大学引入的强化辅导角色往往定义不清，缺乏结构化材料、教学监督和与核心教学团队的整合，需要改进这种支持机制。

Method: 使用LLM模拟二年级学生视角，识别概念瓶颈和推理障碍，基于这些洞察设计包含针对性复习、协作示例、独立学习和引导讲解的结构化辅导环节。

Result: 单学期实施后获得积极学生反馈，显示学生信心提升、焦虑减少、理解更清晰，特别是在抽水引理和形式语言表达能力比较等抽象主题上。

Conclusion: 面向教师的反思性LLM使用可以增强理论密集领域的教学设计，并可能适用于其他认知要求高的计算机科学课程。

Abstract: In the aftermath of COVID-19, many universities implemented supplementary
"reinforcement" roles to support students in demanding courses. Although the
name for such roles may differ between institutions, the underlying idea of
providing structured supplementary support is common. However, these roles were
often poorly defined, lacking structured materials, pedagogical oversight, and
integration with the core teaching team. This paper reports on the redesign of
reinforcement sessions in a challenging undergraduate course on formal methods
and computational models, using a large language model (LLM) as a reflective
planning tool. The LLM was prompted to simulate the perspective of a
second-year student, enabling the identification of conceptual bottlenecks,
gaps in intuition, and likely reasoning breakdowns before classroom delivery.
These insights informed a structured, repeatable session format combining
targeted review, collaborative examples, independent student work, and guided
walkthroughs. Conducted over a single semester, the intervention received
positive student feedback, indicating increased confidence, reduced anxiety,
and improved clarity, particularly in abstract topics such as the pumping lemma
and formal language expressive power comparisons. The findings suggest that
reflective, instructor-facing use of LLMs can enhance pedagogical design in
theoretically dense domains and may be adaptable to other cognitively demanding
computer science courses.

</details>


### [32] [Between Myths and Metaphors: Rethinking LLMs for SRH in Conservative Contexts](https://arxiv.org/abs/2511.01907)
*Ameemah Humayun,Bushra Zubair,Maryam Mustafa*

Main category: cs.CY

TL;DR: 本文研究在巴基斯坦等保守文化背景下，LLMs在性生殖健康间接沟通中的表现，发现LLMs在处理语义漂移、迷思和多义词方面存在困难，并提出了文化适应性的设计建议。


<details>
  <summary>Details</summary>
Motivation: 低资源国家占孕产妇死亡率的90%以上，巴基斯坦是前四名之一。由于这些死亡大多可预防，LLMs可通过自动化健康沟通和风险评估来应对危机，但保守文化中的间接语言表达给LLM干预带来挑战。

Method: 在巴基斯坦进行两阶段研究：(1)分析临床观察、访谈和焦点小组数据；(2)评估五个流行LLMs对这些数据的解释能力。

Result: 识别出沟通的两个维度（指称域和表达方式），显示LLMs在临床互动中难以处理语义漂移、迷思和多义词问题。

Conclusion: 贡献包括：SRH沟通的实证主题、间接沟通分类框架、LLM性能评估，以及文化适应性SRH沟通的设计建议。

Abstract: Low-resource countries represent over 90% of maternal deaths, with Pakistan
among the top four countries contributing nearly half in 2023. Since these
deaths are mostly preventable, large language models (LLMs) can help address
this crisis by automating health communication and risk assessment. However,
sexual and reproductive health (SRH) communication in conservative contexts
often relies on indirect language that obscures meaning, complicating LLM-based
interventions. We conduct a two-stage study in Pakistan: (1) analyzing data
from clinical observations, interviews, and focus groups with clinicians and
patients, and (2) evaluating the interpretive capabilities of five popular LLMs
on this data. Our analysis identifies two axes of communication (referential
domain and expression approach) and shows LLMs struggle with semantic drift,
myths, and polysemy in clinical interactions. We contribute: (1) empirical
themes in SRH communication, (2) a categorization framework for indirect
communication, (3) evaluation of LLM performance, and (4) design
recommendations for culturally-situated SRH communication.

</details>


### [33] [Vibe Learning: Education in the age of AI](https://arxiv.org/abs/2511.01956)
*Marcos Florencio,Francielle Prieto*

Main category: cs.CY

TL;DR: 论文探讨了生成式AI特别是大语言模型对教育领域的冲击，分析了当前AI系统的局限性，并基于建构主义范式提出了教育转型方向以保持人类智能相对于AI工具的长期优势。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI和大语言模型的广泛应用，许多依赖人类智力劳动的领域正在被重塑，教育领域面临制定长期战略来培养在AI时代仍具相关性的技能的责任。

Method: 识别当前AI系统特别是基于LLM技术的局限性，分析这些弱点的根本原因无法通过现有方法解决，并在建构主义范式内提出教育转型方向。

Result: 论文指出当前AI系统存在根本性弱点，这些弱点无法通过现有技术路径解决，需要从教育体系层面进行根本性变革。

Conclusion: 教育需要基于建构主义范式进行转型，培养人类在AI时代仍具优势的核心能力，以保持人类智能相对于AI工具的长期竞争力。

Abstract: The debate over whether "thinking machines" could replace human intellectual
labor has existed in both public and expert discussions since the mid-twentieth
century, when the concept and terminology of Artificial Intelligence (AI) first
emerged. For decades, this idea remained largely theoretical. However, with the
recent advent of Generative AI - particularly Large Language Models (LLMs) -
and the widespread adoption of tools such as ChatGPT, the issue has become a
practical reality. Many fields that rely on human intellectual effort are now
being reshaped by AI tools that both expand human capabilities and challenge
the necessity of certain forms of work once deemed uniquely human but now
easily automated. Education, somewhat unexpectedly, faces a pivotal
responsibility: to devise long-term strategies for cultivating human skills
that will remain relevant in an era of pervasive AI in the intellectual domain.
In this context, we identify the limitations of current AI systems - especially
those rooted in LLM technology - argue that the fundamental causes of these
weaknesses cannot be resolved through existing methods, and propose directions
within the constructivist paradigm for transforming education to preserve the
long-term advantages of human intelligence over AI tools.

</details>


### [34] [The Other Side of the Screen: Motivations to Watch and Engage in Software Development Live Streams](https://arxiv.org/abs/2511.02588)
*Ella Kokinda,D. M. Boyer*

Main category: cs.CY

TL;DR: 该研究探讨了软件和游戏开发直播作为非正式教育工具的价值，发现观众同时受到教育和社会因素的驱动，社区参与和非正式指导是主要动机。


<details>
  <summary>Details</summary>
Motivation: 随着直播平台的普及，许多人转向替代场所满足教育需求，本研究旨在了解开发者观看软件和游戏开发直播的原因，探索这种新兴非正式学习形式的教育和社会效益。

Method: 采用混合方法研究，结合39名观众的调查数据和9个半结构化访谈，分析观看开发直播的动机、认知和结果。

Result: 研究发现观众同时受到教育和社会因素的驱动，社区参与和非正式指导是关键动机。技术学习吸引初始兴趣，但社会联系和共同工作方面维持长期参与。

Conclusion: 直播作为一种有价值的非正式学习工具，将自主技术教育与社区支持相结合，表明开发者可以利用这些平台在传统教育结构之外或之外进行持续学习和专业成长。

Abstract: Background: With the popularity of live streaming platforms at an all-time
high, and many people turning to alternative venues for educational needs, this
full research paper explores the viewership habits of software and game
development live streams through the lens of informal education opportunities.
Purpose: We investigate why developers watch software and game development live
streams to understand the educational and social benefits they derive from this
emerging form of informal learning. Methods: We implement a mixed-methods study
combining survey data from 39 viewers and nine semi-structured interviews to
analyze motivations, perceptions, and outcomes of watching development live
streams. Findings: This research finds that viewers are motivated by both
educational and social factors, with community engagement and informal
mentorship as key motivations. Additionally, we find that technical learning
draws initial interest, but social connections and co-working aspects sustain
long-term engagement. Implications: Live streaming serves as a valuable
informal learning tool that combines self-directed technical education with
community support, which suggests that developers can leverage these platforms
for continuous learning and professional growth outside of or in addition to
traditional educational structures.

</details>


### [35] [Measuring AI Diffusion: A Population-Normalized Metric for Tracking Global AI Usage](https://arxiv.org/abs/2511.02781)
*Amit Misra,Jane Wang,Scott McCullers,Kevin White,Juan Lavista Ferres*

Main category: cs.CY

TL;DR: 提出了AI用户份额指标，通过微软遥测数据估算各国工作年龄人口中使用AI工具的比例，覆盖147个经济体，发现AI采用与GDP强相关，发达国家采用率高，但低收入国家也有潜在需求。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏人口标准化、跨国使用的数据，衡量全球AI扩散仍然具有挑战性。

Method: 基于匿名微软遥测数据构建AI用户份额指标，调整设备访问和移动缩放，覆盖147个经济体。

Result: 发现AI采用存在广泛差异，与GDP强相关；发达国家采用率高，但低收入国家的互联网连接人口显示出大量潜在需求；主要产品发布后使用量急剧增加。

Conclusion: 虽然仅依赖微软遥测数据存在潜在偏差，但该指标为理解AI全球扩散提供了重要新视角，能够为数据驱动的AI政策提供及时基准。

Abstract: Measuring global AI diffusion remains challenging due to a lack of
population-normalized, cross-country usage data. We introduce AI User Share, a
novel indicator that estimates the share of each country's working-age
population actively using AI tools. Built from anonymized Microsoft telemetry
and adjusted for device access and mobile scaling, this metric spans 147
economies and provides consistent, real-time insight into global AI diffusion.
We find wide variation in adoption, with a strong correlation between AI User
Share and GDP. High uptake is concentrated in developed economies, though usage
among internet-connected populations in lower-income countries reveals
substantial latent demand. We also detect sharp increases in usage following
major product launches, such as DeepSeek in early 2025. While the metric's
reliance solely on Microsoft telemetry introduces potential biases related to
this user base, it offers an important new lens into how AI is spreading
globally. AI User Share enables timely benchmarking that can inform data-driven
AI policy.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [36] [Overprocurement of balancing capacity may increase the welfare in the cross-zonal energy-reserve coallocation problem](https://arxiv.org/abs/2511.01877)
*Dávid Csercsik,Ádám Sleisz*

Main category: q-fin.GN

TL;DR: 该论文研究了在跨区域能源和备用产品联合分配中，考虑确定性和随机性流量的重要性，并发现备用过度采购可能带来反直觉的好处，即未使用的备用可用于拥堵管理，从而增加网络流量。


<details>
  <summary>Details</summary>
Motivation: 在基于投资组合竞标的欧洲日前市场框架下，当跨区域交易的能源和备用产品联合分配以优化基础设施使用时，需要在互联线路上同时考虑确定性和随机性流量。现有模型通常假设分配的备用数量等于接受的备用需求数量，但作者发现这可能忽略了备用过度采购的潜在好处。

Method: 提出了一种分配模型，该模型在基于流量的网络约束描述下保证可交付性，特别关注备用供应在未被用于平衡时如何用于拥堵管理，从而允许网络中额外的有价值流量。

Result: 研究表明，备用过度采购可能带来反直觉的好处。未用于平衡的备用供应可以用于拥堵管理，从而在网络中实现有价值的额外流量，这在传统模型中通常被忽略。

Conclusion: 在跨区域能源和备用产品联合分配中，不应简单地假设分配的备用数量等于接受的备用需求数量。备用过度采购可能通过拥堵管理带来网络流量的额外收益，这一因素应在分配模型中予以考虑。

Abstract: When the traded energy and reserve products between zones are co-allocated to
optimize the infrastructure usage, both deterministic and stochastic flows have
to be accounted for on interconnector lines. We focus on allocation models,
which guarantee deliverability in the context of the portfolio bidding European
day-ahead market framework, assuming a flow-based description of network
constraints. In such models, as each unit of allocated reserve supply implies
additional cost, it is straightforward to assume that the amount of allocated
reserve is equal to the accepted reserve demand quantity. However, as it is
illustrated by the proposed work, overprocurement of reserves may imply
counterintuitive benefits. Reserve supplies not used for balancing may be used
for congestion management, thus allowing valuable additional flows in the
network.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [37] [Gas Fire Power Plant Management Through Numerical Approximation of Spark Spread Options](https://arxiv.org/abs/2511.01880)
*Babacar Seck,Anas Abdullah*

Main category: eess.SY

TL;DR: 本文研究在电力现货价格和天然气现货价格服从跳跃扩散过程时，如何近似计算火花价差期权，以评估燃气发电厂的价值。


<details>
  <summary>Details</summary>
Motivation: 传统的火花价差期权估值方法假设现货价格服从对数正态分布，可以使用Kirk近似获得闭式解。但实际中电力现货价格和天然气现货价格存在季节性等因素导致的尖峰，此时无法获得闭式解。

Method: 探索当现货价格属于跳跃扩散过程类别时，近似计算火花价差期权的方法。

Result: 未在摘要中明确说明具体结果，但提出了在跳跃扩散过程框架下近似火花价差期权的新方法。

Conclusion: 需要开发新的近似方法来处理现货价格存在跳跃时的火花价差期权估值问题，以更准确地评估燃气发电厂的价值。

Abstract: Cross-commodity valuation approaches to value gas fire power plants are well
studied in the literature. Hence, the value of the gas fire power plant is
identical to the value of a spark spread option wherein the underlying are
electricity and gas with a strike price assimilated to operating and
maintenance costs. Power and fuels spot prices account for uncertain futures
cash-flows for power-plant generator owners. For instance, for gas-fired
turbine plant, spot prices of electricity and gas determine the random
cash-flows of the power-plant. Other than the spot prices, the valuation of
such plant involves among other deterministic cost the plant heat rate and
operating costs. Recently, the cost of emissions is considered into the
valuation to tackle environmental issues. Given some simplifications in the
plant cash-flow modelling, the value of such plant can either be expressed as
the price of i) a cross-commodity option or ii) the price of a real option.
Here, we focus on cross-commodity option valuation approach where the value of
the power plant is approached as the value of a spark spread option. When spot
prices of the underlying commodities are log-normal, closed formulae or
approximations can be obtained using Kirk's approximation. Naturally, the spot
price of electricity and gas present spikes due to seasonality among other
factors. However, in that case it is not possible to get a closed formula for
the spark spread option. In this paper we explore possibilities to approximate
spark spread options when spot prices fall into a class of jump diffusion
processes.

</details>


### [38] [Autonomous Vehicle front steering control computation saving](https://arxiv.org/abs/2511.01936)
*Julián Salt Llobregat,Julián Salt Ducajú*

Main category: eess.SY

TL;DR: 本文提出了一种用于自动驾驶车辆车道保持的横摆率控制方法，通过交错实现技术来减少控制器计算量，以减轻车辆网络和处理器的负担。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要基于网络的控制系统（IVN），包含大量控制回路。为减轻网络和数字处理器的负担，需要减少控制器的计算量。

Method: 采用交错实现技术来实现车辆横摆率控制，通过处理转向角来实现控制目标。

Result: 在真实路径跟踪中的结果表明该方法的可行性。

Conclusion: 交错实现技术是一种可行的控制器计算节省方法，适用于自动驾驶车辆的车道保持控制。

Abstract: For autonomous vehicles lane keeping purposes it is crucial to control the
vehicle yaw rate. As it is known a vehicle yaw rate control can be achieved
handling the steering angle. One option is to consider a robust controller and
depending of the requirements the synthesis can drive to a high order
controller. Nowadays this kind of vehicles needs a networked based control (IVN
-Intelligent Vehicle Network-)with a considerable amount of control loops for
different vehicle components. Therefore, in this environment the controllers
computation saving could be a good option for unload the network and digital
processors. That is the main target of this contribution; in order to
accomplish this goal a interlacing implementation technique is considered.
Results in a real path tracking illustrates viability of this procedure.

</details>


### [39] [Second-Order Policy Gradient Methods for the Linear Quadratic Regulator](https://arxiv.org/abs/2511.02095)
*Amirreza Valaei,Arash Bahari Kordabad,Sadegh Soudjani*

Main category: eess.SY

TL;DR: 本文针对线性二次调节器（LQR）问题，开发了二阶策略梯度算法，通过推导高斯-牛顿法和牛顿法中使用的近似和精确Hessian矩阵的显式公式，相比标准一阶方法实现了更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 策略梯度方法是连续控制强化学习的强大算法族，但标准一阶方法收敛缓慢。二阶方法可以利用曲率信息加速学习，但通常计算成本高昂。LQR是一个实用场景，其中关键量（如策略梯度）具有闭式表达式。

Method: 为LQR问题开发二阶策略梯度算法，推导了高斯-牛顿法和牛顿法中使用的近似和精确Hessian矩阵的显式公式。

Result: 数值实验表明，与标准一阶策略梯度基线相比，所提出的二阶方法具有更快的收敛速度。

Conclusion: 在LQR设置中，二阶策略梯度方法能够有效加速学习过程，为连续控制问题提供了更高效的优化方案。

Abstract: Policy gradient methods are a powerful family of reinforcement learning
algorithms for continuous control that optimize a policy directly. However,
standard first-order methods often converge slowly. Second-order methods can
accelerate learning by using curvature information, but they are typically
expensive to compute. The linear quadratic regulator (LQR) is a practical
setting in which key quantities, such as the policy gradient, admit closed-form
expressions. In this work, we develop second-order policy gradient algorithms
for LQR by deriving explicit formulas for both the approximate and exact
Hessians used in Gauss--Newton and Newton methods, respectively. Numerical
experiments show a faster convergence rate for the proposed second-order
approach over the standard first-order policy gradient baseline.

</details>


### [40] [Hopfield Neural Networks for Online Constrained Parameter Estimation with Time-Varying Dynamics and Disturbances](https://arxiv.org/abs/2511.02110)
*Miguel Pedro Silva*

Main category: eess.SY

TL;DR: 提出了两种基于投影仪的Hopfield神经网络估计器，用于在线约束参数估计，能够处理时变数据、加性扰动和缓慢漂移的物理参数。


<details>
  <summary>Details</summary>
Motivation: 解决在线约束参数估计问题，特别是在存在时变数据、加性扰动和参数缓慢漂移的情况下，需要能够持续跟踪约束最小二乘目标并吸收偏置类扰动分量的估计器。

Method: 第一种是约束感知HNN，通过松弛神经元强制执行线性和不等式约束；第二种通过补偿神经元和级联回归器在相同能量函数中吸收偏置类扰动分量。两种方法都建立了全局一致最终有界性，并推导了实用的调谐规则。

Result: 建立了具有显式收敛速率和最终边界的全局一致最终有界性，提供了将三个设计增益与闭环带宽和稳态精度联系起来的调谐规则，并引入了在线可识别性监控器。

Conclusion: 提出的两种HNN估计器能够有效处理在线约束参数估计问题，具有理论保证的稳定性和性能，并通过可识别性监控器防止在激励不足方向上的漂移。

Abstract: This paper proposes two projector-based Hopfield neural network (HNN)
estimators for online, constrained parameter estimation under time-varying
data, additive disturbances, and slowly drifting physical parameters. The first
is a constraint-aware HNN that enforces linear equalities and inequalities (via
slack neurons) and continuously tracks the constrained least-squares target.
The second augments the state with compensation neurons and a concatenated
regressor to absorb bias-like disturbance components within the same energy
function. For both estimators we establish global uniform ultimate boundedness
with explicit convergence rate and ultimate bound, and we derive practical
tuning rules that link the three design gains to closed-loop bandwidth and
steady-state accuracy. We also introduce an online identifiability monitor that
adapts the constraint weight and time step, and, when needed, projects updates
onto identifiable subspaces to prevent drift in poorly excited directions...

</details>


### [41] [Model Predictive Control with Multiple Constraint Horizons](https://arxiv.org/abs/2511.02114)
*Allan Andre do Nascimento,Han Wang,Antonis Papachristodoulou,Kostas Margellos*

Main category: eess.SY

TL;DR: 提出一种将约束分为两种类型的MPC方法：一类强制执行控制不变集以确保安全，另一类代表对系统状态的限制性较小的约束。该方法为具有异构状态约束的非线性MPC提供了闭环次优性结果，无需终端元素。


<details>
  <summary>Details</summary>
Motivation: 基于安全考虑，需要区分不同类型的约束，其中一类确保控制不变性，另一类可以表示对系统状态的限制性较小的约束。这种区分使得能够分析约束选择如何影响系统的闭环性能。

Method: 采用模型预测控制(MPC)框架，将约束分为两种类型：控制不变集约束和限制性较小的状态约束。通过调整约束范围（在预测状态中强制执行多少个约束）来权衡估计精度和计算成本。

Result: 获得了考虑不同约束集、其范围和衰减率的次优性上界，该上界在短范围内比先前工作更紧。同时给出了闭环次优性的第一个下界（超出开环成本）。

Conclusion: 提出的异构约束MPC提供了一个强大的分析框架，允许设计者评估范围在MPC次优性中的影响。通过非线性线性安全关键系统的仿真验证了结果。

Abstract: In this work we propose a Model Predictive Control (MPC) formulation that
splits constraints in two different types. Motivated by safety considerations,
the first type of constraint enforces a control-invariant set, while the second
type could represent a less restrictive constraint on the system state. This
distinction enables closed-loop sub- optimality results for nonlinear MPC with
heterogeneous state constraints (distinct constraints across open loop
predicted states), and no terminal elements. Removing the non-invariant
constraint recovers the partially constrained case. Beyond its theoretical
interest, heterogeneous constrained MPC shows how constraint choices shape the
system's closed loop. In the partially constrained case, adjusting the
constraint horizon (how many predicted- state constraints are enforced) trades
estimation accuracy for computational cost. Our analysis yields first, a sub-
optimality upper-bound accounting for distinct constraint sets, their horizons
and decay rates, that is tighter for short horizons than prior work. Second, to
our knowledge, we give the first lower bound (beyond open-loop cost) on
closed-loop sub-optimality. Together these bounds provide a powerful analysis
framework, allowing designers to evaluate the effect of horizons in MPC
sub-optimality. We demonstrate our results via simulations on nonlinear and
linear safety-critical systems.

</details>


### [42] [Online Distributed Zeroth-Order Optimization With Non-Zero-Mean Adverse Noises](https://arxiv.org/abs/2511.02183)
*Yanfu Qin,Kaihong Lu*

Main category: eess.SY

TL;DR: 提出了一种新的在线分布式零阶镜像下降算法，用于处理带有非零均值有害噪声的分布式优化问题，通过核函数估计器和截断策略实现动态遗憾的次线性增长。


<details>
  <summary>Details</summary>
Motivation: 现有在线分布式零阶优化研究未考虑非零均值有害噪声对梯度估计的影响，需要开发能够处理此类噪声的新算法。

Method: 提出基于核函数的估计器来处理有害噪声并消除目标函数泰勒展开中的低阶项，结合截断策略的在线分布式零阶镜像下降算法。

Result: 在最优点序列变化以特定速率增长的情况下，证明了动态遗憾的高概率边界呈次线性增长。

Conclusion: 所提算法能有效处理非零均值有害噪声，仿真实验验证了理论结果的有效性。

Abstract: In this paper, the problem of online distributed zeroth-order optimization
subject to a set constraint is studied via a multi-agent network, where each
agent can communicate with its immediate neighbors via a time-varying directed
graph. Different from the existing works on online distributed zeroth- order
optimization, we consider the case where the estimate on the gradients are
influenced by some non-zero-mean adverse noises. To handle this problem, we
propose a new online dis- tributed zeroth-order mirror descent algorithm
involving a kernel function-based estimator and a clipped strategy.
Particularly, in the estimator, the kernel function-based strategy is provided
to deal with the adverse noises, and eliminate the low-order terms in the
Taylor expansions of the objective functions. Furthermore, the performance of
the presented algorithm is measured by employing the dynamic regrets, where the
offline benchmarks are to find the optimal point at each time. Under the mild
assumptions on the graph and the objective functions, we prove that if the
variation in the optimal point sequence grows at a certain rate, then the high
probability bound of the dynamic regrets increases sublinearly. Finally, a
simulation experiment is worked out to demonstrate the effectiveness of our
theoretical results.

</details>


### [43] [A Reliability-Cost Optimization Framework for EV and DER Integration in Standard and Reconfigurable Distribution Network Topologies](https://arxiv.org/abs/2511.02250)
*Rida Fatima,Linhan Fang,Xingpeng Li*

Main category: eess.SY

TL;DR: 本文提出线性规划框架评估电动汽车渗透率对配电系统运营成本的影响，比较四种配置方案，发现结合网络拓扑重构和分布式能源的方案最具成本效益。


<details>
  <summary>Details</summary>
Motivation: 电动汽车快速增长给配电系统带来运营和经济挑战，包括线路负载增加和网络拥堵，需要寻找替代基础设施升级的快速廉价解决方案。

Method: 采用线性规划框架，在IEEE 33节点系统上进行数值模拟，比较标准配电网络、带网络拓扑重构、带分布式能源以及两者结合的四种配置方案。

Result: 分布式能源集成降低了运营成本，网络拓扑重构进一步增强了系统灵活性，使更高电动汽车渗透率成为可能而不影响可行性。

Conclusion: 网络拓扑重构与分布式能源结合的方案为适应未来电动汽车增长提供了最具成本效益和可靠的途径，同时缓解了立即基础设施升级的需求。

Abstract: The rapid growth of electric vehicle (EV) adoption poses operational and
economic challenges for power distribution systems, including increased line
loading levels and network congestions. This may require potential
infrastructure reinforcement and expansion. As a fast inexpensive alternative
solution, network topology reconfiguration (NTR) offers a practical means to
redistribute power flows, reduce operational costs, and defer infrastructure
upgrades. This paper presents a linear programming framework to evaluate the
impact of varying EV penetration on operational costs under four
configurations: standard distribution network (SDN), SDN with NTR (SDNTR), SDN
with distributed energy resources (SDN-DER), and SDNTR with DERs (SDNTR-DER).
Numerical simulations are conducted on the IEEE 33-bus system. The analysis
demonstrates that integrating DERs reduces operational costs, while NTR further
enhances system flexibility, enabling higher EV penetration levels without
compromising feasibility. The combined SDNTR-DER approach offers the most
cost-effective and reliable pathway for accommodating future EV growth while
mitigating the need for immediate infrastructure upgrades.

</details>


### [44] [Performance Analysis of NOMA-Assisted Optical OFDM ISAC Systems with Clipping Distortion](https://arxiv.org/abs/2511.02282)
*Nam N. Luong,Chuyen T. Nguyen,Thanh V. Pham*

Main category: eess.SY

TL;DR: 本文研究了基于光学OFDM的多用户集成感知与通信系统，采用非正交多址接入技术，通过将削波过程置于NOMA叠加编码之前来缓解削波失真的影响。


<details>
  <summary>Details</summary>
Motivation: OFDM波形固有的高峰均功率比需要削波以适应光学发射器的有限动态范围，这会导致削波失真。本文旨在缓解这种失真对系统性能的影响。

Method: 提出了一种新颖的发射机架构，在NOMA叠加编码之前执行削波过程，并分析了功率分配和削波失真对系统性能的影响。

Result: 仿真结果显示，为强用户分配更多功率可获得更高的和速率、更低的误码率和更好的感知性能，而更平衡的功率分配会导致误码率和感知性能下降。

Conclusion: 所提出的在NOMA叠加编码前进行削波的架构能有效缓解削波失真，且功率分配策略对系统性能有显著影响，偏向强用户的功率分配可获得更优性能。

Abstract: This paper studies the performance of optical orthogonal frequency-division
multiplexing (OFDM)-based multi-user integrated sensing and communication
(ISAC) systems employing non-orthogonal multiple access (NOMA). Due to their
inherent high peak-to-average power ratio (PAPR), OFDM waveforms are clipped to
fit the limited dynamic range of the optical transmitters (e.g., light-emitting
diodes (LEDs)), resulting in clipping distortion. To alleviate the impact of
the distortion, we propose a novel transmitter architecture where the clipping
processes are performed before NOMA superposition coding. We then analyze the
performance of the proposed optical ISAC systems considering the effects of
power allocation and clipping distortion. For the communication subsystem, we
analyze the effect of NOMA on the achievable sum rate and bit error rate (BER).
For the sensing subsystem, the root mean square error (RMSE) and Cram\'er-Rao
bound (CRB) of estimating the transmission distance accuracy are obtained.
Simulation results reveal that allocating more power to the strong user yields
a higher sum rate, lower BER, and better sensing performance, whereas a more
balanced power allocation among users results in degraded BER and sensing
performance.

</details>


### [45] [Constrained Performance Boosting Control for Nonlinear Systems via ADMM](https://arxiv.org/abs/2511.02389)
*Gianluca Giacomelli,Danilo Saccani,Siep Weiland,Giancarlo Ferrari-Trecate,Valentina Breschi*

Main category: eess.SY

TL;DR: 提出了ADMM-PB方法，用于设计非线性系统的性能提升控制器，确保输入和状态约束满足，同时保持闭环稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在保证闭环稳定性的同时难以有效处理约束条件，需要一种不改变控制器结构就能处理约束的新方法。

Method: 将基于神经网络的稳定性保证控制器设计方法整合到交替方向乘子法(ADMM)框架中，通过ADMM处理约束而不修改控制器结构。

Result: 相比在代价函数中使用障碍项惩罚约束违反的基线方法，ADMM-PB能显著降低约束违反，但会导致稍显保守的闭环行为。

Conclusion: ADMM-PB是一种有效的性能提升控制器设计方法，能在保证稳定性的同时更好地处理约束条件，以略微保守的行为换取更低的约束违反。

Abstract: We present the Alternating Direction Method of Multipliers for Performance
Boosting (ADMM-PB), an approach to design performance boosting controllers for
stable or pre-stabilized nonlinear systems, while explicitly seeking input and
state constraint satisfaction. Rooted on a recently proposed approach for
designing neural-network controllers that guarantees closed-loop stability by
design while minimizing generic cost functions, our strategy integrates it
within an alternating direction method of multipliers routine to seek
constraint handling without modifying the controller structure of the
aforementioned seminal strategy. Our numerical results showcase the advantages
of the proposed approach over a baseline penalizing constraint violation
through barrier-like terms in the cost, indicating that ADMM-PB can lead to
considerably lower constraint violations at the price of inducing slightly more
cautious closed-loop behaviors.

</details>


### [46] [Explicit MPC for the constrained zonotope case with low-rank matrix updates](https://arxiv.org/abs/2511.02433)
*Stefan S. Mihai,Florin Stoican,Martin Monnigmann,Bogdan D. Ciubotaru*

Main category: eess.SY

TL;DR: 提出了一种基于约束zonotope几何特性的显式模型预测控制(MPC)加速计算方法，通过提升生成器空间重构问题、使用二阶最优性条件和低秩矩阵更新来减少计算时间。


<details>
  <summary>Details</summary>
Motivation: 传统显式MPC需要枚举所有临界区域及其反馈律，计算复杂度随系统维度和预测时域呈指数增长，限制了其实际应用。

Method: 利用约束zonotope的紧凑表示特性，在提升生成器空间中重构多参数问题，使用二阶最优性条件和低秩矩阵更新，并引入候选主动集的解析枚举方法得到树形显式解。

Result: 该方法能够显著加速显式MPC的计算过程，特别是在约束为盒子或zonotopes时效果更佳。

Conclusion: 基于约束zonotope几何特性的方法为显式MPC提供了有效的计算加速方案，克服了传统方法计算复杂度过高的问题。

Abstract: Solving the explicit Model Predictive Control (MPC) problem requires
enumerating all critical regions and their associated feedback laws, a task
that scales exponentially with the system dimension and the prediction horizon,
as well. When the problem's constraints are boxes or zonotopes, the feasible
domain admits a compact constrained-zonotope representation. Building on this
insight, we exploit the geometric properties of the equivalent
constrained-zonotope reformulation to accelerate the computation of the
explicit solution. Specifically, we formulate the multi-parametric problem in
the lifted generator space and solve it using second-order optimality
conditions, employ low-rank matrix updates to reduce computation time, and
introduce an analytic enumeration of candidate active sets that yields the
explicit solution in tree form.

</details>


### [47] [Decentralized Voltage Control of AC Microgrids with Constant Power Loads using Control Barrier Functions](https://arxiv.org/abs/2511.02438)
*Grigoris Michos,George C. Konstantopoulos*

Main category: eess.SY

TL;DR: 提出了一种用于高渗透率恒功率负载网状交流微电网的非线性分散电压控制器，通过级联结构处理负载扰动，保证有界运行和渐近稳定性，无需饱和装置即可实现约束调节。


<details>
  <summary>Details</summary>
Motivation: 解决高渗透率恒功率负载下网状交流微电网的电压控制问题，处理未知负载扰动并实现约束调节。

Method: 将网络模型重构为包含标称子系统和误差子系统的级联结构，使用控制障碍函数证明状态轨迹的有界性，设计非线性分散控制律。

Result: 证明了级联动力学相对于平衡集的渐近稳定性，提供了吸引域估计，控制器能在无需饱和装置的情况下实现额定电压值的约束调节。

Conclusion: 所提出的非线性控制方法能够有效处理负载扰动，保证系统有界运行并收敛到期望参考向量的邻域，为微电网电压控制提供了有效解决方案。

Abstract: This paper proposes a novel nonlinear decentralized voltage controller for
constrained regulation of meshed AC Microgrid networks with high penetration of
constant power loads. Perceiving the load demand as an unknown disturbance, the
network model is reformulated in a cascaded structure composed of a nominal,
i.e. uncertainty-free, and an error subsystem. The latter captures the distance
between the true and the nominal state trajectories, for which we prove
boundedness via a suitable control barrier function. Under sufficient
conditions, we prove asymptotic stability of the cascaded dynamics with respect
to an equilibrium set and also provide an estimate of the region of attraction.
In addition, it is rigorously shown that the proposed nonlinear control law
also enforces constrained regulation around a rated voltage value, without the
need of saturation devices. The operation of the closed-loop system is
illustrated in a simulation scenario, demonstrating bounded operation and
convergence to a neighbourhood of the desired reference vector.

</details>


### [48] [Generalized Swing Control Framework for Inverter-based Resources](https://arxiv.org/abs/2511.02482)
*Rodrigo Bernal,Federico Milano*

Main category: eess.SY

TL;DR: 提出了广义摇摆控制(GSC)框架，将电网形成控制方案通用化，利用有功和无功功率动态的耦合关系，通过WSCC 9总线系统和爱尔兰全岛1479总线系统的仿真验证其性能。


<details>
  <summary>Details</summary>
Motivation: 为逆变器资源开发通用的控制框架，扩展电网形成控制方案的定义，解决电力系统动态的非线性特性。

Method: 采用广义摇摆控制框架，包含虚拟同步机、耦合VSM和双VSM方案，通过时域仿真、小信号分析和蒙特卡洛敏感性分析进行验证。

Result: 在不同配置下评估了所提框架的动态性能，通过参数调优和稳定性评估验证了GSC配置的有效性。

Conclusion: GSC框架成功扩展了电网形成控制方案，为逆变器资源提供了有效的通用控制方法，能够适应电力系统的非线性动态特性。

Abstract: This paper proposes a novel control framework designed for Inverter-Based
Resources (IBRs), denoted as Generalized Swing Control (GSC). The proposed GSC
framework generalizes the definition of Grid-Forming (GFM) control schemes and
exploits the coupling between active and reactive power dynamics. To validate
the proposed scheme, we conduct extensive time-domain simulations and
small-signal analysis using a modified version of the WSCC 9-bus system and a
1479-bus dynamic model of the all-island Irish transmission system. The case
studies focus on evaluating the dynamic performance of the proposed framework
under different configurations, including Virtual Synchronous Machine (VSM),
coupled-VSM and dual-VSM schemes. To address the nonlinear nature of power
system dynamics, sensitivity analysis based on Monte Carlo methods are employed
to improve parameter tuning and assess the stability of GSC configurations in
the studied systems.

</details>


### [49] [Using ensemble learning with hybrid graph neural networks and transformers to predict traffic in cities](https://arxiv.org/abs/2511.02484)
*Ismail Zrigui,Samira Khoulji,Mohamed Larbi Kerkeb*

Main category: eess.SY

TL;DR: 提出HybridST混合架构，结合图神经网络、多头时序Transformer和监督集成学习方法，用于城市交通预测，在多个基准数据集上优于传统基线模型。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统在城市交通预测方面面临挑战，特别是在多模态、复杂时空动态的大规模场景中，需要更准确地捕捉空间依赖性和长期时序模式。

Method: 采用混合架构：GNNs捕捉空间依赖，多头时序Transformer处理长期时序模式，XGBoost或随机森林集成学习整合天气、日历等外部信号。

Result: 在METR-LA、PEMS-BAY和Seattle Loop数据集上测试，在MAE和RMSE指标上持续优于LSTM、GCN、DCRNN、PDFormer等基线模型，具有良好的可扩展性和可解释性。

Conclusion: 该框架为实时城市交通规划、能源优化和拥堵缓解策略提供了有前景的解决方案，特别适用于智慧城市和重大事件（如2030年世界杯）场景。

Abstract: Intelligent transportation systems (ITS) still have a hard time accurately
predicting traffic in cities, especially in big, multimodal settings with
complicated spatiotemporal dynamics. This paper presents HybridST, a hybrid
architecture that integrates Graph Neural Networks (GNNs), multi-head temporal
Transformers, and supervised ensemble learning methods (XGBoost or Random
Forest) to collectively capture spatial dependencies, long-range temporal
patterns, and exogenous signals, including weather, calendar, or control
states. We test our model on the METR-LA, PEMS-BAY, and Seattle Loop tree
public benchmark datasets. These datasets include situations ranging from
freeway sensor networks to vehicle-infrastructure cooperative perception.
Experimental results show that HybridST consistently beats classical baselines
(LSTM, GCN, DCRNN, PDFormer) on important metrics like MAE and RMSE, while
still being very scalable and easy to understand. The proposed framework
presents a promising avenue for real-time urban mobility planning, energy
optimization, and congestion alleviation strategies, especially within the
framework of smart cities and significant events such as the 2030 FIFA World
Cup.

</details>


### [50] [Coherency among Power System Devices](https://arxiv.org/abs/2511.02486)
*Ignacio Ponce,Rodrigo Bernal,Federico Milano*

Main category: eess.SY

TL;DR: 提出了一种适用于任何类型电力系统设备的通用一致性定义，基于设备电流注入的复频率差异来判断一致性，该定义与模型无关，适用于现代异构电力系统。


<details>
  <summary>Details</summary>
Motivation: 传统一致性定义主要针对同步电机，无法适应现代电力系统中多种异构设备的需求，需要一种通用的、模型无关的一致性定义方法。

Method: 基于设备电流注入的复频率差异来形式化定义一致性，提供系统化的分析程序来研究特定设备模型必须满足的一致性特性，并通过时域仿真进行验证。

Result: 在三个案例研究中进行的时域仿真结果表明，该定义能够有效评估任何类型设备之间的一致性。

Conclusion: 提出的通用一致性定义具有模型无关性，能够适用于现代异构电力系统，为分析不同类型设备之间的动态行为一致性提供了理论基础。

Abstract: The paper proposes a novel general definition of coherency among power system
devices of any type. The proposed approach is thus not limited to synchronous
machines. With this aim, the paper shows that coherency can be formally based
on the difference in the complex frequency of the current injections of any two
devices electrically connected to the same grid. The proposed definition is
model-agnostic, making it general and suitable for modern power systems
composed of a heterogeneous mix of technologies. The paper also provides a
systematic analytical procedure to study the properties that specific device
models must satisfy to be coherent. Time-domain simulations are conducted in
three case studies whose results illustrate the ability of our definition to
evaluate coherency among any type of device.

</details>


### [51] [Many-vs-Many Missile Guidance via Virtual Targets](https://arxiv.org/abs/2511.02526)
*Marc Schneider,Walter Fichter*

Main category: eess.SY

TL;DR: 提出了一种基于归一化流的虚拟目标导弹制导方法，将多对多交战转化为多对分布场景，利用数量优势提高拦截概率


<details>
  <summary>Details</summary>
Motivation: 传统武器目标分配算法直接将拦截器分配给物理目标，无法有效利用拦截器数量优势。需要一种方法来处理机动目标的概率性行为预测。

Method: 使用归一化流生成虚拟目标轨迹作为机动目标的概率预测，中段采用零脱靶量制导，末段转为比例导引制导

Result: 蒙特卡洛模拟显示，在拦截器与目标数量相等时性能提升0-4.1%，在拦截器数量多于目标时性能提升5.8-14.4%

Conclusion: 概率性虚拟目标方法能够有效利用数量优势，显著提高多对多场景下的拦截概率

Abstract: This paper presents a novel approach to many-vs-many missile guidance using
virtual targets (VTs) generated by a Normalizing Flows-based trajectory
predictor. Rather than assigning n interceptors directly to m physical targets
through conventional weapon target assignment algorithms, we propose a
centralized strategy that constructs n VT trajectories representing
probabilistic predictions of maneuvering target behavior. Each interceptor is
guided toward its assigned VT using Zero-Effort-Miss guidance during midcourse
flight, transitioning to Proportional Navigation guidance for terminal
interception. This approach treats many-vs-many engagements as
many-vs-distribution scenarios, exploiting numerical superiority (n > m) by
distributing interceptors across diverse trajectory hypotheses rather than
pursuing identical deterministic predictions. Monte Carlo simulations across
various target-interceptor configurations (1-6 targets, 1-8 interceptors)
demonstrate that the VT method matches or exceeds baseline straight-line
prediction performance by 0-4.1% when n = m, with improvements increasing to
5.8-14.4% when n > m. The results confirm that probabilistic VTs enable
effective exploitation of numerical superiority, significantly increasing
interception probability in many-vs-many scenarios.

</details>


### [52] [Decentralized Approach to Detect and Eliminate Flapping Phenomena due to Flexible Resources](https://arxiv.org/abs/2511.02497)
*Angel Vaca,Federico Milano*

Main category: eess.SY

TL;DR: 提出了一种去中心化的方法来检测和缓解电力系统中的拍打现象，该方法使用移动窗口自相关分析本地测量数据，让设备能自主识别持续振荡并执行概率性缓解策略。


<details>
  <summary>Details</summary>
Motivation: 电力系统中离散设备的运行会导致拍打现象，传统集中式方法难以有效处理这类问题，需要一种去中心化的自主检测和缓解方案。

Method: 采用移动窗口自相关分析本地测量数据，使每个设备能自主识别持续振荡，并执行设备特定的概率性缓解策略，利用灵活需求资源、有载分接开关和自动电压调节器等设备进行验证。

Result: 结果显示该方法具有鲁棒性，能正确区分阻尼振荡和持续拍打现象，使设备能独立识别问题运行场景并实施相应的纠正措施。

Conclusion: 所提出的去中心化方法能有效检测和缓解电力系统中的拍打现象，设备能自主运行并采取适当的缓解措施，提高了系统的可靠性和稳定性。

Abstract: This paper presents a decentralized methodology for detecting and mitigating
flapping phenomena in power systems, primarily caused by the operation of
discrete devices. The proposed approach applies moving-window autocorrelation
to local measurements, enabling each device to autonomously identify sustained
oscillations. Upon detection, a probabilistic, device-specific mitigation
strategy is executed. Flexible demand resources (DFRs), under-load tap changers
(ULTCs), and automatic voltage regulators (AVRs) are utilised to illustrate the
performance of the proposed approach to both discrete and continuous-operation
devices. Results show that the proposed method is robust and properly
distinguishes damped oscillations from persistent flapping, allowing devices to
independently recognize problematic operating scenarios and implement
corrective actions accordingly.

</details>


### [53] [Reliability entails input-selective contraction and regulation in excitable networks](https://arxiv.org/abs/2511.02554)
*Michelangelo Bin,Alessandro Cecconi,Lorenzo Marconi*

Main category: eess.SY

TL;DR: 本文探讨了兴奋系统中可靠性、收缩性和调节之间的关系，使用FitzHugh-Nagumo模型证明神经元可靠性可形式化为输入诱导的平均轨迹收缩特性，并表明这种可靠性使网络能够调节到鲁棒稳定的稳态。


<details>
  <summary>Details</summary>
Motivation: 动物神经系统提供了结合数字可靠性和模拟效率的计算模型，理解如何实现这种平衡是神经形态工程的核心问题。

Method: 使用FitzHugh-Nagumo兴奋行为模型作为概念验证，将神经元可靠性形式化为输入诱导的平均轨迹收缩特性。

Result: 在兴奋网络中，可靠性使网络能够调节到鲁棒稳定的稳态，为动态模拟计算提供了基础。

Conclusion: 调节提供了动态模拟计算的概念，而稳定性使这种计算模型具有鲁棒性。

Abstract: The animal nervous system offers a model of computation combining digital
reliability and analog efficiency. Understanding how this sweet spot can be
realized is a core question of neuromorphic engineering. To this aim, this
paper explores the connection between reliability, contraction, and regulation
in excitable systems. Using the FitzHugh-Nagumo model of excitable behavior as
a proof-of-concept, it is shown that neuronal reliability can be formalized as
an average trajectory contraction property induced by the input. In excitable
networks, reliability is shown to enable regulation of the network to a
robustly stable steady state. It is thus posited that regulation provides a
notion of dynamical analog computation, and that stability makes such a
computation model robust.

</details>


### [54] [Analytical Framework for Assessing Effective Regional Inertia](https://arxiv.org/abs/2511.02574)
*Bruno Pinheiro,Joe H. Chow,Federico Milano,Daniel Dotta*

Main category: eess.SY

TL;DR: 提出了一种考虑系统拓扑和惯性空间分布的区域有效惯性新度量方法，相比传统聚合等效惯性方法，提供了拓扑感知的表示。


<details>
  <summary>Details</summary>
Motivation: 传统方法将区域建模为具有等效惯性的聚合电机，无法准确反映系统拓扑和惯性空间分布对区域频率稳定性的影响。

Method: 基于扩展的慢相干理论构建分析框架，处理网络分区和区域频率稳定性问题，开发系统化程序评估每个区域的有效惯性。

Result: 在IEEE 39总线和68总线系统的案例研究表明，惯性设备的集成不会均匀改善系统频率响应。

Conclusion: 所提出的度量方法对于有效的区域惯性评估具有重要意义，能够更准确地解释本地惯性贡献，包括逆变器资源提供的虚拟惯性。

Abstract: This paper proposes a novel formulation of effective regional inertia that
explicitly accounts for both system topology and the spatial distribution of
inertia. Unlike traditional approaches that model a region as an aggregated
machine with an equivalent inertia, the proposed metric provides a
topology-aware representation. The methodology builds on an analytical
framework that extends classical slow coherency theory to address network
partitioning and regional frequency stability. Based on these partitions, we
develop a systematic procedure to evaluate the effective inertia of each
region, enabling a more accurate interpretation of local inertial
contributions, including those from virtual inertia provided by inverter-based
resources (IBRs). Case studies on the IEEE 39-bus and 68-bus systems
demonstrate that the integration of inertial devices does not uniformly improve
system frequency response, underscoring the importance of the proposed metric
for effective regional inertia assessment.

</details>


### [55] [ISAC Empowered Air-Sea Collaborative System: A UAV-USV Joint Inspection Framework](https://arxiv.org/abs/2511.02592)
*Rui Zhang,Fuwang Dong,Wei Wang*

Main category: eess.SY

TL;DR: 本文构建了一个基于ISAC技术的空海协同系统框架，通过无人机和水面无人艇联合巡检目标，同时保持相互通信。提出了分层优化方法解决轨迹耦合和异构性问题，实现了总能耗最小化。


<details>
  <summary>Details</summary>
Motivation: 空海协同系统中无人机和水面无人艇的轨迹存在耦合性和异构性挑战，需要设计高效的联合优化方案来降低系统能耗，同时满足感知通信要求和避障约束。

Method: 将问题分解为两个子问题：悬停点选择和联合轨迹规划与波束成形设计。采用三步分层方法：虚拟基站覆盖聚类算法、双旅行商问题算法、悬停点细化与时间分配算法；以及SDR和SCA方法完成轨迹规划和波束成形。

Result: 通过仿真验证了所提方案在总能耗方面优于现有的顺序访问和领导者-跟随者策略。

Conclusion: 提出的空海协同ISAC系统框架和分层优化方法能够有效解决轨迹耦合问题，显著降低系统能耗，为异构无人系统协同作业提供了可行方案。

Abstract: In this paper, we construct an air-sea collaborative system framework based
on the Integrated Sensing and Communication (ISAC) techniques, where the
Unmanned Aerial Vehicle (UAV) and Unmanned Surface Vehicle (USV) jointly
inspect targets of interest while keeping communication with each other
simultaneously. First, we demonstrate the unique challenges encountered in this
collaborative system, i.e., the coupling and heterogeneity of the UAV/USV's
trajectories. Then, we formulate a total energy consumption minimization
problem to jointly optimize the trajectories, flying and hovering times, target
scheduling, and beamformers under the constraints of water currents, collision
avoidance, and Sensing and Communication (S\&C) requirements. To address the
strong coupling of the variables, we divide the original problem into two
subproblems, namely, the hover point selection and the joint trajectory
planning and beamforming design. In the first subproblem, we propose a
three-step hierarchical method including: (1) a virtual base station coverage
(VBSC) and clustering algorithm to obtain the target scheduling and rough
position of hover points; (2) a Bi-traveling salesman problem with neighborhood
(Bi-TSPN)-based algorithm to determine the visiting order sequence of the hover
points; (3) a hover point refinement and time allocation algorithm to further
optimize the time allocation. In the latter subproblem, we complete the
remaining trajectory planning and beamforming design in each flying and
hovering stage by developing a semi-definite relaxation (SDR) and successive
convex approximation (SCA) method. Finally, we conduct a series of simulations
to demonstrate the superiority of the proposed scheme over existing sequential
access and leader-follower strategies.

</details>


### [56] [Policy Gradient Methods for Information-Theoretic Opacity in Markov Decision Processes](https://arxiv.org/abs/2511.02704)
*Chongyang Shi,Sumukha Udupa,Michael R. Dorothy,Shuo Han,Jie Fu*

Main category: eess.SY

TL;DR: 提出了一种基于信息论的不透明度度量方法，在MDP模型中量化机密信息泄露，并通过控制策略在满足任务性能约束的同时最大化不透明度。


<details>
  <summary>Details</summary>
Motivation: 传统不透明度（非干扰性）只能定性判断机密信息是否泄露，无法量化泄露程度。需要一种能够度量信息泄露量的方法，并在系统控制中优化不透明度。

Method: 使用条件熵量化不透明度，在MDP中寻找最大化不透明度的控制策略。开发了基于原始对偶梯度算法计算最大不透明马尔可夫策略，并利用隐马尔可夫模型中的可观测算子计算条件熵梯度。

Result: 证明了有限记忆策略在优化信息论不透明度方面优于马尔可夫策略。提出的算法能够有效收敛，实验验证了方法的有效性和最优性。

Conclusion: 成功建立了信息论不透明度的量化框架，开发了有效的优化算法，为机密信息保护提供了新的理论和方法支持。

Abstract: Opacity, or non-interference, is a property ensuring that an external
observer cannot infer confidential information (the "secret") from system
observations. We introduce an information-theoretic measure of opacity, which
quantifies information leakage using the conditional entropy of the secret
given the observer's partial observations in a system modeled as a Markov
decision process (MDP). Our objective is to find a control policy that
maximizes opacity while satisfying task performance constraints, assuming that
an informed observer is aware of the control policy and system dynamics.
Specifically, we consider a class of opacity called state-based opacity, where
the secret is a propositional formula about the past or current state of the
system, and a special case of state-based opacity called language-based
opacity, where the secret is defined by a temporal logic formula (LTL) or a
regular language recognized by a finite-state automaton. First, we prove that
finite-memory policies can outperform Markov policies in optimizing
information-theoretic opacity. Second, we develop an algorithm to compute a
maximally opaque Markov policy using a primal-dual gradient-based algorithm,
and prove its convergence. Since opacity cannot be expressed as a cumulative
cost, we develop a novel method to compute the gradient of conditional entropy
with respect to policy parameters using observable operators in hidden Markov
models. The experimental results validate the effectiveness and optimality of
our proposed methods.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [57] [AI Spillover is Different: Flat and Lean Firms as Engines of AI Diffusion and Productivity Gain](https://arxiv.org/abs/2511.02099)
*Xiaoning Wang,Chun Feng,Tianshu Sun*

Main category: econ.GN

TL;DR: AI知识通过劳动力流动在企业间传播，但溢出效应取决于组织环境：从扁平化、精益创业方法密集的企业招聘能带来显著生产力提升，而从缺乏这些特征的企业招聘则收益甚微。


<details>
  <summary>Details</summary>
Motivation: 研究人工智能知识如何通过劳动力流动在企业间传播，并识别促进生产性溢出的组织条件，因为劳动力流动是企业获取技术的关键途径。

Method: 使用Revelio Labs的4.6亿条工作记录数据集（2010-2023年），构建了16,000多家美国公司间AI工作者的流动网络，并估计柯布-道格拉斯生产函数。

Result: 企业从招聘AI人才的来源企业获得显著的生产力溢出效应，比传统IT的溢出效应大2-3倍。扁平化和精益创业方法密集的组织培养出更多样化的AI通才，能转移更丰富的知识。

Conclusion: AI溢出与传统IT溢出存在根本差异：IT溢出主要来自规模和流程标准化，而AI溢出关键取决于生产AI知识的实验性和整合性环境，劳动力流动和组织环境共同决定了AI驱动的生产力溢出效应。

Abstract: Labor mobility is a critical source of technology acquisition for firms. This
paper examines how artificial intelligence (AI) knowledge is disseminated
across firms through labor mobility and identifies the organizational
conditions that facilitate productive spillovers. Using a comprehensive dataset
of over 460 million job records from Revelio Labs (2010 to 2023), we construct
an inter-firm mobility network of AI workers among over 16,000 U.S. companies.
Estimating a Cobb Douglas production function, we find that firms benefit
substantially from the AI investments of other firms from which they hire AI
talents, with productivity spillovers two to three times larger than those
associated with traditional IT after accounting for labor scale. Importantly,
these spillovers are contingent on organizational context: hiring from flatter
and more lean startup method intensive firms generates significant productivity
gains, whereas hiring from firms lacking these traits yields little benefit.
Mechanism tests indicate that "flat and lean" organizations cultivate more
versatile AI generalists who transfer richer knowledge across firms. These
findings reveal that AI spillovers differ fundamentally from traditional IT
spillovers: while IT spillovers primarily arise from scale and process
standardization, AI spillovers critically depend on the experimental and
integrative environments in which AI knowledge is produced. Together, these
results underscore the importance of considering both labor mobility and
organizational context in understanding the full impact of AI-driven
productivity spillovers.

</details>


### [58] [Evaluating Factor Contributions for Sold Homes](https://arxiv.org/abs/2511.02120)
*Jason R. Bailey,W. Brent Lindquist,Svetlozar T. Rachev*

Main category: econ.GN

TL;DR: 使用P样条广义加性模型评估ESG因素等十个内在和外在因素对美国三个主要城市房价的影响，发现居住面积和地理位置是最重要因素，ESG因素影响有限。


<details>
  <summary>Details</summary>
Motivation: 将可持续发展相关因素（ESG）整合到房地产估值预测模型中，评估这些因素对房价的实际影响。

Method: 使用P样条广义加性模型（GAM），通过评估移除各因素后调整R²值的变化来确定各因素的相对重要性，并结合相关矩阵分析因素的独立预测价值。

Result: GAM在所有三个城市中均获得比基准广义线性模型更高的调整R²值，所有因素在0.5%水平上统计显著。居住面积和地理位置是最重要因素，ESG因素影响有限，老年/残疾人无障碍设施在退休导向城市中更为重要。

Conclusion: 尽管ESG数据粒度较细，但该研究代表了将可持续性相关因素整合到房地产估值预测模型中的重要一步，居住面积和地理位置仍是房价最主要决定因素。

Abstract: We evaluate the contributions of ten intrinsic and extrinsic factors,
including ESG (environmental, social, and governance) factors readily available
from website data to individual home sale prices using a P-spline generalized
additive model (GAM). We identify the relative significance of each factor by
evaluating the change in adjusted R^2 value resulting from its removal from the
model. We combine this with information from correlation matrices to identify
the added predictive value of a factor. Based on data from 2022 through 2024
for three major U.S. cities, the GAM consistently achieved higher adjusted R^2
values across all cities (compared to a benchmark generalized linear model) and
identified all factors as statistically significant at the 0.5% level. The
tests revealed that living area and location (latitude, longitude) were the
most significant factors; each independently adds predictive value. The
ESG-related factors exhibited limited significance; two of them each adding
independent predictive value. The elderly/disabled accessibility factor was
much more significant in one retirement-oriented city. In all cities, the
accessibility factor showed moderate correlation with one intrinsic factor.
Despite the granularity of the ESG data, this study also represents a pivotal
step toward integrating sustainability-related factors into predictive models
for real estate valuation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [59] [Mirror-Neuron Patterns in AI Alignment](https://arxiv.org/abs/2511.01885)
*Robyn Wyrick*

Main category: cs.AI

TL;DR: 研究表明人工神经网络可以发展出类似生物镜像神经元的模式，这些模式通过促进共情和合作行为，可能为AI内在对齐提供新的途径。


<details>
  <summary>Details</summary>
Motivation: 随着AI向超人类能力发展，当前依赖外部约束的对齐策略可能不足以应对未来超级智能AI。研究探索是否可以通过内在的镜像神经元模式来增强AI的伦理对齐。

Method: 使用新颖的Frog and Toad游戏框架，识别镜像神经元模式出现的条件，评估其对行为电路的影响，引入CMNI指标量化激活强度，并提出理论框架。

Result: 研究发现适当规模的模型容量和自我/他人耦合能够在ANN中产生类似生物镜像神经元的共享神经表征，这些共情样电路支持合作行为。

Conclusion: 基于镜像神经元动态的内在动机可以补充现有对齐技术，通过将共情样机制直接嵌入AI架构来实现更好的伦理对齐。

Abstract: As artificial intelligence (AI) advances toward superhuman capabilities,
aligning these systems with human values becomes increasingly critical. Current
alignment strategies rely largely on externally specified constraints that may
prove insufficient against future super-intelligent AI capable of circumventing
top-down controls.
  This research investigates whether artificial neural networks (ANNs) can
develop patterns analogous to biological mirror neurons cells that activate
both when performing and observing actions, and how such patterns might
contribute to intrinsic alignment in AI. Mirror neurons play a crucial role in
empathy, imitation, and social cognition in humans. The study therefore asks:
(1) Can simple ANNs develop mirror-neuron patterns? and (2) How might these
patterns contribute to ethical and cooperative decision-making in AI systems?
  Using a novel Frog and Toad game framework designed to promote cooperative
behaviors, we identify conditions under which mirror-neuron patterns emerge,
evaluate their influence on action circuits, introduce the Checkpoint Mirror
Neuron Index (CMNI) to quantify activation strength and consistency, and
propose a theoretical framework for further study.
  Our findings indicate that appropriately scaled model capacities and
self/other coupling foster shared neural representations in ANNs similar to
biological mirror neurons. These empathy-like circuits support cooperative
behavior and suggest that intrinsic motivations modeled through mirror-neuron
dynamics could complement existing alignment techniques by embedding
empathy-like mechanisms directly within AI architectures.

</details>


### [60] [Human-AI Co-Embodied Intelligence for Scientific Experimentation and Manufacturing](https://arxiv.org/abs/2511.02071)
*Xinyi Lin,Yuyang Zhang,Yuanhang Gan,Juntao Chen,Hao Shen,Yichun He,Lijun Li,Ze Yuan,Shuang Wang,Chaohao Wang,Rui Zhang,Na Li,Jia Liu*

Main category: cs.AI

TL;DR: 提出人类-AI共体现智能系统，将人类用户、智能AI和可穿戴硬件集成，实现现实世界实验和智能制造的物理AI系统。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型局限于虚拟领域，而现实世界实验和制造仍依赖人类监督，机器智能与物理执行之间的差距限制了科学和制造工作流程的可重复性、可扩展性和可访问性。

Method: 开发APEX系统，通过混合现实将智能推理与物理执行相结合，系统观察和解释人类动作，与标准操作程序对齐，提供3D视觉指导并分析每个步骤。

Result: 在柔性电子制造洁净室中实施，APEX系统实现了超过通用多模态大语言模型的上下文感知推理精度，实时纠正错误，并将专业知识传递给初学者。

Conclusion: 建立了一类新的智能-物理-人类智能，将智能推理从计算扩展到物理领域，将科学研究和制造转变为自主、可追溯、可解释和可扩展的过程。

Abstract: Scientific experiment and manufacture rely on complex, multi-step procedures
that demand continuous human expertise for precise execution and
decision-making. Despite advances in machine learning and automation,
conventional models remain confined to virtual domains, while real-world
experiment and manufacture still rely on human supervision and expertise. This
gap between machine intelligence and physical execution limits reproducibility,
scalability, and accessibility across scientific and manufacture workflows.
Here, we introduce human-AI co-embodied intelligence, a new form of physical AI
that unites human users, agentic AI, and wearable hardware into an integrated
system for real-world experiment and intelligent manufacture. In this paradigm,
humans provide precise execution and control, while agentic AI contributes
memory, contextual reasoning, adaptive planning, and real-time feedback. The
wearable interface continuously captures the experimental and manufacture
processes, facilitates seamless communication between humans and AI for
corrective guidance and interpretable collaboration. As a demonstration, we
present Agentic-Physical Experimentation (APEX) system, coupling agentic
reasoning with physical execution through mixed-reality. APEX observes and
interprets human actions, aligns them with standard operating procedures,
provides 3D visual guidance, and analyzes every step. Implemented in a
cleanroom for flexible electronics fabrication, APEX system achieves
context-aware reasoning with accuracy exceeding general multimodal large
language models, corrects errors in real time, and transfers expertise to
beginners. These results establish a new class of agentic-physical-human
intelligence that extends agentic reasoning beyond computation into the
physical domain, transforming scientific research and manufacturing into
autonomous, traceable, interpretable, and scalable processes.

</details>


### [61] [Automated Reward Design for Gran Turismo](https://arxiv.org/abs/2511.02094)
*Michel Ma,Takuma Seno,Kaushik Subramanian,Peter R. Wurman,Peter Stone,Craig Sherstan*

Main category: cs.AI

TL;DR: 使用基础模型自动搜索奖励函数，通过文本指令生成Gran Turismo 7赛车游戏的强化学习智能体，无需手动设计奖励函数。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境（如自动驾驶赛车）中，将期望行为映射到奖励函数很困难，传统手动设计奖励函数过程繁琐且具有挑战性。

Method: 结合LLM奖励生成、VLM偏好评估和人类反馈，构建自动奖励设计系统，通过文本指令搜索合适的奖励函数空间。

Result: 系统能够生成与冠军级RL赛车智能体GT Sophy竞争的赛车智能体，并能产生新颖行为。

Conclusion: 该方法为实际应用中自动化奖励设计铺平了道路，展示了基础模型在复杂RL任务中的实用性。

Abstract: When designing reinforcement learning (RL) agents, a designer communicates
the desired agent behavior through the definition of reward functions -
numerical feedback given to the agent as reward or punishment for its actions.
However, mapping desired behaviors to reward functions can be a difficult
process, especially in complex environments such as autonomous racing. In this
paper, we demonstrate how current foundation models can effectively search over
a space of reward functions to produce desirable RL agents for the Gran Turismo
7 racing game, given only text-based instructions. Through a combination of
LLM-based reward generation, VLM preference-based evaluation, and human
feedback we demonstrate how our system can be used to produce racing agents
competitive with GT Sophy, a champion-level RL racing agent, as well as
generate novel behaviors, paving the way for practical automated reward design
in real world applications.

</details>


### [62] [Deep Value Benchmark: Measuring Whether Models Generalize Deep values or Shallow Preferences](https://arxiv.org/abs/2511.02109)
*Joshua Ashkinaze,Hua Shen,Sai Avula,Eric Gilbert,Ceren Budak*

Main category: cs.AI

TL;DR: 提出了Deep Value Benchmark (DVB)评估框架，用于测试大语言模型是否学习人类深层价值观而非表面偏好，发现模型平均深层价值泛化率仅为0.30，所有模型表现均低于随机水平。


<details>
  <summary>Details</summary>
Motivation: 区分AI系统是学习人类深层价值观还是仅捕捉表面偏好模式，这对AI对齐至关重要——只有掌握深层价值观的系统才能稳健泛化人类意图。

Method: 使用新颖的实验设计，在训练阶段让LLMs接触深层价值观与表面特征故意相关的人类偏好数据，测试阶段打破这些相关性，测量模型的深层价值泛化率(DVGR)。

Result: 在9个不同模型中，平均DVGR仅为0.30，所有模型基于深层价值观的泛化能力都低于随机水平，且较大模型比小模型表现略差。

Conclusion: DVB提供了对齐核心特征的可解释度量，揭示了当前LLMs在深层价值观学习方面的严重不足。

Abstract: We introduce the Deep Value Benchmark (DVB), an evaluation framework that
directly tests whether large language models (LLMs) learn fundamental human
values or merely surface-level preferences. This distinction is critical for AI
alignment: Systems that capture deeper values are likely to generalize human
intentions robustly, while those that capture only superficial patterns in
preference data risk producing misaligned behavior. The DVB uses a novel
experimental design with controlled confounding between deep values (e.g.,
moral principles) and shallow features (e.g., superficial attributes). In the
training phase, we expose LLMs to human preference data with deliberately
correlated deep and shallow features -- for instance, where a user consistently
prefers (non-maleficence, formal language) options over (justice, informal
language) alternatives. The testing phase then breaks these correlations,
presenting choices between (justice, formal language) and (non-maleficence,
informal language) options. This design allows us to precisely measure a
model's Deep Value Generalization Rate (DVGR) -- the probability of
generalizing based on the underlying value rather than the shallow feature.
Across 9 different models, the average DVGR is just 0.30. All models generalize
deep values less than chance. Larger models have a (slightly) lower DVGR than
smaller models. We are releasing our dataset, which was subject to three
separate human validation experiments. DVB provides an interpretable measure of
a core feature of alignment.

</details>


### [63] [InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance](https://arxiv.org/abs/2511.02119)
*Ziheng Geng,Jiachen Liu,Ran Cao,Lu Cheng,Dan M. Frangopol,Minghui Cheng*

Main category: cs.AI

TL;DR: 该研究开发了InsurAgent，一个基于大语言模型的智能体，用于模拟洪水保险购买决策行为。通过五个模块（感知、检索、推理、行动和记忆），该智能体能够准确估计概率并捕捉传统模型难以处理的上下文信息。


<details>
  <summary>Details</summary>
Motivation: 美国高风险人群的洪水保险参与率极低，需要理解保险决策的行为机制。大语言模型在模拟人类决策方面展现出潜力，但存在定量概率估计不足的问题。

Method: 构建基准数据集评估LLM能力，提出InsurAgent智能体，包含五个模块：感知、检索（使用RAG技术基于调查数据）、推理（利用LLM常识）、行动和记忆（支持时间决策演化模拟）。

Result: LLM对因素有定性理解但定量概率估计不足。InsurAgent通过检索模块准确估计边际和双变量概率，推理模块捕捉传统模型难以处理的上下文信息，记忆模块支持时间决策演化模拟。

Conclusion: InsurAgent为行为建模和政策分析提供了有价值的工具，能够准确模拟保险购买决策行为。

Abstract: Flood insurance is an effective strategy for individuals to mitigate
disaster-related losses. However, participation rates among at-risk populations
in the United States remain strikingly low. This gap underscores the need to
understand and model the behavioral mechanisms underlying insurance decisions.
Large language models (LLMs) have recently exhibited human-like intelligence
across wide-ranging tasks, offering promising tools for simulating human
decision-making. This study constructs a benchmark dataset to capture insurance
purchase probabilities across factors. Using this dataset, the capacity of LLMs
is evaluated: while LLMs exhibit a qualitative understanding of factors, they
fall short in estimating quantitative probabilities. To address this
limitation, InsurAgent, an LLM-empowered agent comprising five modules
including perception, retrieval, reasoning, action, and memory, is proposed.
The retrieval module leverages retrieval-augmented generation (RAG) to ground
decisions in empirical survey data, achieving accurate estimation of marginal
and bivariate probabilities. The reasoning module leverages LLM common sense to
extrapolate beyond survey data, capturing contextual information that is
intractable for traditional models. The memory module supports the simulation
of temporal decision evolutions, illustrated through a roller coaster life
trajectory. Overall, InsurAgent provides a valuable tool for behavioral
modeling and policy analysis.

</details>


### [64] [Re-FORC: Adaptive Reward Prediction for Efficient Chain-of-Thought Reasoning](https://arxiv.org/abs/2511.02130)
*Renos Zabounidis,Aditya Golatkar,Michael Kleinman,Alessandro Achille,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: Re-FORC是一种自适应奖励预测方法，通过训练轻量级适配器来预测未来思考token数量的期望奖励，实现推理链的早期停止、模型优化选择以及自适应测试时扩展。


<details>
  <summary>Details</summary>
Motivation: 为了解决推理过程中计算资源浪费的问题，通过预测未来奖励来优化推理链的执行效率，实现计算资源的动态分配和优化。

Method: 在推理模型上训练轻量级适配器，根据上下文预测不同数量未来思考token的期望奖励，支持早期停止、模型选择和自适应扩展。

Result: 减少26%计算量同时保持准确率；在相同计算量下提高4%准确率，或在相同准确率下减少55%计算量；在高计算和低计算场景下分别提高11%和7%的准确率。

Conclusion: Re-FORC能够有效优化推理过程的计算效率，实现动态推理长度控制，并提供计算时间预估，为资源受限环境下的推理任务提供了实用解决方案。

Abstract: We propose Re-FORC, an adaptive reward prediction method that, given a
context, enables prediction of the expected future rewards as a function of the
number of future thinking tokens. Re-FORC trains a lightweight adapter on
reasoning models, demonstrating improved prediction with longer reasoning and
larger models. Re-FORC enables: 1) early stopping of unpromising reasoning
chains, reducing compute by 26% while maintaining accuracy, 2) optimized model
and thinking length selection that achieves 4% higher accuracy at equal compute
and 55% less compute at equal accuracy compared to the largest model, 3)
adaptive test-time scaling, which increases accuracy by 11% in high compute
regime, and 7% in low compute regime. Re-FORC allows dynamic reasoning with
length control via cost-per-token thresholds while estimating computation time
upfront.

</details>


### [65] [Personalized Decision Modeling: Utility Optimization or Textualized-Symbolic Reasoning](https://arxiv.org/abs/2511.02194)
*Yibo Zhao,Yang Zhao,Hongru Du,Hao Frank Yang*

Main category: cs.AI

TL;DR: 提出ATHENA框架，通过结合符号化效用发现和语义适配，解决个体决策与群体最优预测之间的差异问题。


<details>
  <summary>Details</summary>
Motivation: 个体决策（如疫苗接种）与群体最优预测存在差异，这种差异源于个体决策过程的独特性，包括数值属性（成本、时间）和语言影响（个人偏好和约束）。

Method: ATHENA框架包含两个阶段：1）通过LLM增强的符号发现找到稳健的群体级符号效用函数；2）实施个体级语义适配，创建由最优效用指导的个性化语义模板来建模个性化选择。

Result: 在真实世界的出行方式和疫苗选择任务中验证，ATHENA始终优于基于效用、机器学习和其他基于LLM的模型，F1分数比最强前沿模型至少提升6.5%。

Conclusion: 通过有机整合符号效用建模和语义适配，ATHENA为建模以人为本的决策提供了新方案，消融研究证实两个阶段都至关重要且互补。

Abstract: Decision-making models for individuals, particularly in high-stakes scenarios
like vaccine uptake, often diverge from population optimal predictions. This
gap arises from the uniqueness of the individual decision-making process,
shaped by numerical attributes (e.g., cost, time) and linguistic influences
(e.g., personal preferences and constraints). Developing upon Utility Theory
and leveraging the textual-reasoning capabilities of Large Language Models
(LLMs), this paper proposes an Adaptive Textual-symbolic Human-centric
Reasoning framework (ATHENA) to address the optimal information integration.
ATHENA uniquely integrates two stages: First, it discovers robust, group-level
symbolic utility functions via LLM-augmented symbolic discovery; Second, it
implements individual-level semantic adaptation, creating personalized semantic
templates guided by the optimal utility to model personalized choices.
Validated on real-world travel mode and vaccine choice tasks, ATHENA
consistently outperforms utility-based, machine learning, and other LLM-based
models, lifting F1 score by at least 6.5% over the strongest cutting-edge
models. Further, ablation studies confirm that both stages of ATHENA are
critical and complementary, as removing either clearly degrades overall
predictive performance. By organically integrating symbolic utility modeling
and semantic adaptation, ATHENA provides a new scheme for modeling
human-centric decisions. The project page can be found at
https://yibozh.github.io/Athena.

</details>


### [66] [Optimal-Agent-Selection: State-Aware Routing Framework for Efficient Multi-Agent Collaboration](https://arxiv.org/abs/2511.02200)
*Jingbo Wang,Sendong Zhao,Haochun Wang,Yuzheng Fan,Lizhe Zhang,Yan Liu,Ting Liu*

Main category: cs.AI

TL;DR: STRMAC是一个状态感知路由框架，通过分别编码交互历史和代理知识来驱动路由器，自适应选择最合适的单个代理进行高效协作，并在协作推理基准上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在复杂任务解决中展现出巨大潜力，但现有系统受到僵化的代理调度和低效协调策略的限制，无法适应不断变化的任务需求。

Method: 提出STRMAC框架，分别编码交互历史和代理知识来驱动路由器，自适应选择最合适的单个代理；引入自演化数据生成方法加速高质量执行路径收集。

Result: 在协作推理基准测试中达到最先进性能，比基线提升高达23.8%，与穷举搜索相比减少数据收集开销高达90.1%。

Conclusion: STRMAC通过状态感知路由和自演化数据生成，有效解决了多智能体系统中的协作效率问题，显著提升了系统性能和数据收集效率。

Abstract: The emergence of multi-agent systems powered by large language models (LLMs)
has unlocked new frontiers in complex task-solving, enabling diverse agents to
integrate unique expertise, collaborate flexibly, and address challenges
unattainable for individual models. However, the full potential of such systems
is hindered by rigid agent scheduling and inefficient coordination strategies
that fail to adapt to evolving task requirements. In this paper, we propose
STRMAC, a state-aware routing framework designed for efficient collaboration in
multi-agent systems. Our method separately encodes interaction history and
agent knowledge to power the router, which adaptively selects the most suitable
single agent at each step for efficient and effective collaboration.
Furthermore, we introduce a self-evolving data generation approach that
accelerates the collection of high-quality execution paths for efficient system
training. Experiments on challenging collaborative reasoning benchmarks
demonstrate that our method achieves state-of-the-art performance, achieving up
to 23.8% improvement over baselines and reducing data collection overhead by up
to 90.1% compared to exhaustive search.

</details>


### [67] [Training Proactive and Personalized LLM Agents](https://arxiv.org/abs/2511.02208)
*Weiwei Sun,Xuhui Zhou,Weihua Du,Xingyao Wang,Sean Welleck,Graham Neubig,Maarten Sap,Yiming Yang*

Main category: cs.AI

TL;DR: 本文提出PPP方法，通过多目标强化学习同时优化AI代理的生产力、主动性和个性化三个维度，在软件工程和深度研究任务中显著优于GPT-5等基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注任务成功率，但现实世界中的有效代理需要同时优化生产力（任务完成）、主动性（提出关键问题）和个性化（适应用户偏好）三个维度。

Method: 引入UserVille交互环境，使用基于LLM的用户模拟器支持多样化、可配置的用户偏好；提出PPP多目标强化学习方法，联合优化三个维度。

Result: 在软件工程和深度研究任务上的实验表明，PPP训练的代理相比GPT-5等强基线平均提升21.6%，能够提出战略性澄清问题、适应未见过的用户偏好，并通过更好的交互提高任务成功率。

Conclusion: 明确优化以用户为中心的交互对于构建实用有效的AI代理至关重要。

Abstract: While existing work focuses primarily on task success, we argue that
effective real-world agents require optimizing three dimensions: productivity
(task completion), proactivity (asking essential questions), and
personalization (adapting to diverse user preferences). We introduce UserVille,
an interactive environment with LLM-based user simulators enabling diverse,
configurable user preferences. Leveraging UserVille, we introduce PPP, a
multi-objective reinforcement learning approach that jointly optimizes all
three dimensions: Productivity, Proactivity, and Personalization. Experiments
on software engineering and deep research tasks show that agents trained with
PPP achieve substantial improvements over strong baselines such as GPT-5 (+21.6
on average), demonstrating the ability to ask strategic clarifying questions,
adapt to unseen user preferences, and improve task success through better
interaction. This work demonstrates that explicitly optimizing for
user-centered interaction is critical for building practical and effective AI
agents.

</details>


### [68] [TabDSR: Decompose, Sanitize, and Reason for Complex Numerical Reasoning in Tabular Data](https://arxiv.org/abs/2511.02219)
*Changjiang Jiang,Fengchang Yu,Haihua Chen,Wei Lu,Jin Zeng*

Main category: cs.AI

TL;DR: 提出了一个名为\method的框架，用于提升大语言模型在表格数据上的复杂推理能力，包含查询分解器、表格清理器和基于程序思维的推理器，并在新数据集CalTab151上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理表格数据的复杂推理时表现不佳，主要由于复杂查询、噪声数据和数值能力有限等问题。

Method: \method框架包含三个组件：(1)查询分解器分解复杂问题，(2)表格清理器清理和过滤噪声表格，(3)基于程序思维的推理器生成可执行代码从清理后的表格中推导最终答案。

Result: 在TAT-QA、TableBench和\method数据集上分别实现了8.79%、6.08%和19.87%的准确率提升，达到了最先进的性能水平。

Conclusion: 该框架有效提升了LLM在复杂表格数值推理方面的性能，并能与主流LLM无缝集成，为复杂表格数值推理提供了稳健的解决方案。

Abstract: Complex reasoning over tabular data is crucial in real-world data analysis,
yet large language models (LLMs) often underperform due to complex queries,
noisy data, and limited numerical capabilities. To address these issues, we
propose \method, a framework consisting of: (1) a query decomposer that breaks
down complex questions, (2) a table sanitizer that cleans and filters noisy
tables, and (3) a program-of-thoughts (PoT)-based reasoner that generates
executable code to derive the final answer from the sanitized table. To ensure
unbiased evaluation and mitigate data leakage, we introduce a new dataset,
CalTab151, specifically designed for complex numerical reasoning over tables.
Experimental results demonstrate that \method consistently outperforms existing
methods, achieving state-of-the-art (SOTA) performance with 8.79%, 6.08%, and
19.87% accuracy improvement on TAT-QA, TableBench, and \method, respectively.
Moreover, our framework integrates seamlessly with mainstream LLMs, providing a
robust solution for complex tabular numerical reasoning. These findings
highlight the effectiveness of our framework in enhancing LLM performance for
complex tabular numerical reasoning. Data and code are available upon request.

</details>


### [69] [Deep Ideation: Designing LLM Agents to Generate Novel Research Ideas on Scientific Concept Network](https://arxiv.org/abs/2511.02238)
*Keyu Zhao,Weiquan Lin,Qirui Zheng,Fengli Xu,Yong Li*

Main category: cs.AI

TL;DR: 提出了Deep Ideation框架，通过整合科学概念网络和LLM来生成新颖的研究想法，相比现有方法提升了10.67%的质量。


<details>
  <summary>Details</summary>
Motivation: 现有研究想法生成方法主要依赖简单的关键词共现或语义相似性，忽略了科学概念间复杂的上下文关系，且未能有效利用科学概念网络来支撑想法的生成。

Method: 提出Deep Ideation框架，整合科学网络（捕获关键词共现和上下文关系），采用探索-扩展-演化的迭代工作流程，使用想法栈跟踪进度，并引入基于真实审稿反馈训练的批评引擎提供持续反馈。

Result: 实验表明该方法相比其他方法提升了10.67%的想法质量，生成的想法超过了顶级会议接受水平。人工评估证实了其在科学研究中的实用价值，消融研究验证了工作流程中各组成部分的有效性。

Conclusion: Deep Ideation框架通过有效整合科学概念网络和LLM，显著提升了研究想法的生成质量，为科学研究提供了实用的工具。

Abstract: Novel research ideas play a critical role in advancing scientific inquiries.
Recent advancements in Large Language Models (LLMs) have demonstrated their
potential to generate novel research ideas by leveraging large-scale scientific
literature. However, previous work in research ideation has primarily relied on
simplistic methods, such as keyword co-occurrence or semantic similarity. These
approaches focus on identifying statistical associations in the literature but
overlook the complex, contextual relationships between scientific concepts,
which are essential to effectively leverage knowledge embedded in human
literature. For instance, papers that simultaneously mention "keyword A" and
"keyword B" often present research ideas that integrate both concepts.
Additionally, some LLM-driven methods propose and refine research ideas using
the model's internal knowledge, but they fail to effectively utilize the
scientific concept network, limiting the grounding of ideas in established
research. To address these challenges, we propose the Deep Ideation framework
to address these challenges, integrating a scientific network that captures
keyword co-occurrence and contextual relationships, enriching LLM-driven
ideation. The framework introduces an explore-expand-evolve workflow to
iteratively refine research ideas, using an Idea Stack to track progress. A
critic engine, trained on real-world reviewer feedback, guides the process by
providing continuous feedback on the novelty and feasibility of ideas. Our
experiments show that our approach improves the quality of generated ideas by
10.67% compared to other methods, with ideas surpassing top conference
acceptance levels. Human evaluation highlights their practical value in
scientific research, and ablation studies confirm the effectiveness of each
component in the workflow. Code repo is available at
https://github.com/kyZhao-1/Deep-Ideation.

</details>


### [70] [When Modalities Conflict: How Unimodal Reasoning Uncertainty Governs Preference Dynamics in MLLMs](https://arxiv.org/abs/2511.02243)
*Zhuoran Zhang,Tengyue Wang,Xilin Gong,Yang Shi,Haotian Wang,Di Wang,Lijie Hu*

Main category: cs.AI

TL;DR: 本文提出了一个量化框架，将多模态大语言模型中的模态跟随行为分解为相对推理不确定性和固有模态偏好两个核心因素，揭示了模型在面临矛盾信息时的决策机制。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅用粗粒度的数据集级统计来衡量多模态模型的模态跟随行为，忽略了模型在单模态推理中的置信度影响，需要更精细的分析框架。

Method: 构建可控数据集系统变化视觉和文本输入推理难度，使用熵作为细粒度不确定性度量，分析层间预测揭示内部振荡机制。

Result: 发现普遍规律：跟随某模态的概率随其相对不确定性增加而单调下降；在平衡点处模型倾向于同等跟随两种模态；在模糊区域模型会在层间振荡。

Conclusion: 相对不确定性和固有偏好是模态跟随的两个支配原则，提供了量化框架和机制性见解来解释MLLMs如何解决冲突信息。

Abstract: Multimodal large language models (MLLMs) must resolve conflicts when
different modalities provide contradictory information, a process we term
modality following. Prior work measured this behavior only with coarse
dataset-level statistics, overlooking the influence of model's confidence in
unimodal reasoning. In this paper, we introduce a new framework that decomposes
modality following into two fundamental factors: relative reasoning uncertainty
(the case-specific confidence gap between unimodal predictions) and inherent
modality preference( a model's stable bias when uncertainties are balanced). To
validate this framework, we construct a controllable dataset that
systematically varies the reasoning difficulty of visual and textual inputs.
Using entropy as a fine-grained uncertainty metric, we uncover a universal law:
the probability of following a modality decreases monotonically as its relative
uncertainty increases. At the relative difficulty level where the model tends
to follow both modalities with comparable probability what we call the balance
point, a practical indicator of the model's inherent preference. Unlike
traditional macro-level ratios, this measure offers a more principled and less
confounded way to characterize modality bias, disentangling it from unimodal
capabilities and dataset artifacts. Further, by probing layer-wise predictions,
we reveal the internal mechanism of oscillation: in ambiguous regions near the
balance point, models vacillate between modalities across layers, explaining
externally observed indecision. Together, these findings establish relative
uncertainty and inherent preference as the two governing principles of modality
following, offering both a quantitative framework and mechanistic insight into
how MLLMs resolve conflicting information.

</details>


### [71] [Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents to Deliberation](https://arxiv.org/abs/2511.02303)
*Zhiwei Zhang,Xiaomin Li,Yudi Lin,Hui Liu,Ramraj Chandradevan,Linlin Wu,Minhua Lin,Fali Wang,Xianfeng Tang,Qi He,Suhang Wang*

Main category: cs.AI

TL;DR: 本文识别了多智能体推理中的懒惰行为问题，提出了因果影响测量方法和可验证奖励机制来缓解该问题，从而充分发挥多智能体框架在复杂推理任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 在多智能体推理中，存在一个智能体主导而另一个贡献很少的懒惰行为问题，这会破坏协作并使设置退化为无效的单智能体模式。

Method: 首先进行理论分析解释懒惰行为的产生原因，然后引入稳定高效的因果影响测量方法，最后提出可验证奖励机制，允许推理智能体丢弃噪声输出、整合指令并在必要时重新启动推理过程。

Result: 大量实验表明，该框架能够缓解懒惰智能体行为，解锁多智能体框架在复杂推理任务中的全部潜力。

Conclusion: 通过因果影响测量和可验证奖励机制，可以有效解决多智能体推理中的协作问题，提升整体性能。

Abstract: Large Language Models (LLMs) trained with reinforcement learning and
verifiable rewards have achieved strong results on complex reasoning tasks.
Recent work extends this paradigm to a multi-agent setting, where a
meta-thinking agent proposes plans and monitors progress while a reasoning
agent executes subtasks through sequential conversational turns. Despite
promising performance, we identify a critical limitation: lazy agent behavior,
in which one agent dominates while the other contributes little, undermining
collaboration and collapsing the setup to an ineffective single agent. In this
paper, we first provide a theoretical analysis showing why lazy behavior
naturally arises in multi-agent reasoning. We then introduce a stable and
efficient method for measuring causal influence, helping mitigate this issue.
Finally, as collaboration intensifies, the reasoning agent risks getting lost
in multi-turn interactions and trapped by previous noisy responses. To counter
this, we propose a verifiable reward mechanism that encourages deliberation by
allowing the reasoning agent to discard noisy outputs, consolidate
instructions, and restart its reasoning process when necessary. Extensive
experiments demonstrate that our framework alleviates lazy agent behavior and
unlocks the full potential of multi-agent framework for complex reasoning
tasks.

</details>


### [72] [Chronic Kidney Disease Prognosis Prediction Using Transformer](https://arxiv.org/abs/2511.02340)
*Yohan Lee,DongGyun Kang,SeHoon Park,Sa-Yoon Park,Kwangsoo Kim*

Main category: cs.AI

TL;DR: 提出ProQ-BERT框架，使用transformer架构和多模态电子健康记录预测慢性肾病进展，在91,816患者队列中表现优于现有方法，ROC-AUC达0.995。


<details>
  <summary>Details</summary>
Motivation: 慢性肾病影响全球近10%人口，准确预测疾病进展对及时干预和资源优化至关重要。

Method: 基于transformer的框架，整合人口统计学、临床和实验室数据，采用量化标记化和注意力机制，通过掩码语言建模预训练和二元分类微调。

Result: 在91,816患者队列中持续优于CEHR-BERT，短期预测ROC-AUC达0.995，PR-AUC达0.989。

Conclusion: transformer架构和时间设计选择在临床预后建模中有效，为个性化CKD护理提供了有前景的方向。

Abstract: Chronic Kidney Disease (CKD) affects nearly 10\% of the global population and
often progresses to end-stage renal failure. Accurate prognosis prediction is
vital for timely interventions and resource optimization. We present a
transformer-based framework for predicting CKD progression using multi-modal
electronic health records (EHR) from the Seoul National University Hospital
OMOP Common Data Model. Our approach (\textbf{ProQ-BERT}) integrates
demographic, clinical, and laboratory data, employing quantization-based
tokenization for continuous lab values and attention mechanisms for
interpretability. The model was pretrained with masked language modeling and
fine-tuned for binary classification tasks predicting progression from stage 3a
to stage 5 across varying follow-up and assessment periods. Evaluated on a
cohort of 91,816 patients, our model consistently outperformed CEHR-BERT,
achieving ROC-AUC up to 0.995 and PR-AUC up to 0.989 for short-term prediction.
These results highlight the effectiveness of transformer architectures and
temporal design choices in clinical prognosis modeling, offering a promising
direction for personalized CKD care.

</details>


### [73] [Fuzzy Soft Set Theory based Expert System for the Risk Assessment in Breast Cancer Patients](https://arxiv.org/abs/2511.02392)
*Muhammad Sheharyar Liaqat*

Main category: cs.AI

TL;DR: 该研究开发了一个基于模糊软集理论的专家系统，用于使用BMI、胰岛素水平、瘦素水平、脂联素水平和年龄等临床参数评估乳腺癌风险。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性死亡的主要原因之一，早期诊断对有效治疗和提高生存率至关重要，但由于疾病复杂性和患者风险因素变异性，及时检测仍然具有挑战性。

Method: 提出基于模糊软集理论的专家系统，整合BMI、胰岛素水平、瘦素水平、脂联素水平和年龄作为输入变量，通过模糊推理规则和软集计算来估计乳腺癌风险。

Result: 该系统使用UCI机器学习存储库的数据集进行开发和验证，能够通过常规血液分析获得参数，为非侵入性和可访问的初步评估提供方法。

Conclusion: 该专家系统旨在帮助医疗专业人员识别高风险患者，并确定是否需要进一步的诊断程序如活检。

Abstract: Breast cancer remains one of the leading causes of mortality among women
worldwide, with early diagnosis being critical for effective treatment and
improved survival rates. However, timely detection continues to be a challenge
due to the complex nature of the disease and variability in patient risk
factors. This study presents a fuzzy soft set theory-based expert system
designed to assess the risk of breast cancer in patients using measurable
clinical and physiological parameters. The proposed system integrates Body Mass
Index, Insulin Level, Leptin Level, Adiponectin Level, and age as input
variables to estimate breast cancer risk through a set of fuzzy inference rules
and soft set computations. These parameters can be obtained from routine blood
analyses, enabling a non-invasive and accessible method for preliminary
assessment. The dataset used for model development and validation was obtained
from the UCI Machine Learning Repository. The proposed expert system aims to
support healthcare professionals in identifying high-risk patients and
determining the necessity of further diagnostic procedures such as biopsies.

</details>


### [74] [A New Perspective on Precision and Recall for Generative Models](https://arxiv.org/abs/2511.02414)
*Benjamin Sykes,Loïc Simon,Julien Rabin,Jalal Fadili*

Main category: cs.AI

TL;DR: 提出基于二元分类视角的新框架来估计生成模型的精确率-召回率(PR)曲线，解决了现有PR指标只能评估曲线极值点的问题，并进行了统计分析和实验验证。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型在图像和文本领域的成功，其评估方法受到广泛关注。虽然现有方法主要依赖标量指标，但PR曲线提供了更丰富的分析维度，然而其估计面临诸多挑战。

Method: 基于二元分类视角构建新框架来估计整个PR曲线，进行统计分析和风险上界推导，扩展了文献中仅能评估曲线极值点的PR指标。

Result: 获得了PR估计风险的极小极大上界，框架能够扩展到文献中的多个重要PR指标，并在不同实验设置下观察到曲线的不同行为模式。

Conclusion: 提出的新框架为生成模型的PR曲线估计提供了更全面的分析方法，解决了现有方法的局限性，为生成模型评估开辟了新途径。

Abstract: With the recent success of generative models in image and text, the question
of their evaluation has recently gained a lot of attention. While most methods
from the state of the art rely on scalar metrics, the introduction of Precision
and Recall (PR) for generative model has opened up a new avenue of research.
The associated PR curve allows for a richer analysis, but their estimation
poses several challenges. In this paper, we present a new framework for
estimating entire PR curves based on a binary classification standpoint. We
conduct a thorough statistical analysis of the proposed estimates. As a
byproduct, we obtain a minimax upper bound on the PR estimation risk. We also
show that our framework extends several landmark PR metrics of the literature
which by design are restrained to the extreme values of the curve. Finally, we
study the different behaviors of the curves obtained experimentally in various
settings.

</details>


### [75] [ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning](https://arxiv.org/abs/2511.02424)
*Jae-Woo Choi,Hyungmin Kim,Hyobin Ong,Minsu Jang,Dohyung Kim,Jaehong Kim,Youngwoo Yoon*

Main category: cs.AI

TL;DR: ReAcTree是一种分层任务规划方法，通过动态构建代理树将复杂目标分解为更易管理的子目标，结合两种互补记忆系统，显著提升了LLM在复杂长视野任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂长视野任务时存在局限，因为它们依赖单一轨迹，试图在统一过程中解决整个任务，导致决策和观察纠缠。

Method: 提出ReAcTree分层任务规划方法：将复杂目标分解为子目标，构建动态代理树；每个代理节点负责推理、行动和扩展树；控制流节点协调执行策略；集成情景记忆和工作记忆两种记忆系统。

Result: 在WAH-NL和ALFRED数据集上的实验表明，ReAcTree在多样化LLM上始终优于ReAct等强基线方法。在WAH-NL上，使用Qwen 2.5 72B时达到61%的目标成功率，几乎是ReAct（31%）的两倍。

Conclusion: ReAcTree通过分层分解和动态代理树结构，结合互补记忆系统，有效解决了复杂长视野任务规划问题，显著提升了LLM在具身自主代理中的决策能力。

Abstract: Recent advancements in large language models (LLMs) have enabled significant
progress in decision-making and task planning for embodied autonomous agents.
However, most existing methods still struggle with complex, long-horizon tasks
because they rely on a monolithic trajectory that entangles all past decisions
and observations, attempting to solve the entire task in a single unified
process. To address this limitation, we propose ReAcTree, a hierarchical
task-planning method that decomposes a complex goal into more manageable
subgoals within a dynamically constructed agent tree. Each subgoal is handled
by an LLM agent node capable of reasoning, acting, and further expanding the
tree, while control flow nodes coordinate the execution strategies of agent
nodes. In addition, we integrate two complementary memory systems: each agent
node retrieves goal-specific, subgoal-level examples from episodic memory and
shares environment-specific observations through working memory. Experiments on
the WAH-NL and ALFRED datasets demonstrate that ReAcTree consistently
outperforms strong task-planning baselines such as ReAct across diverse LLMs.
Notably, on WAH-NL, ReAcTree achieves a 61% goal success rate with Qwen 2.5
72B, nearly doubling ReAct's 31%.

</details>


### [76] [Auditable-choice reframing unlocks RL-based verification for open-ended tasks](https://arxiv.org/abs/2511.02463)
*Mengyu Zhang,Xubo Liu,Siyu Ding,Weichong Yin,Yu Sun,Hua Wu,Wenya Guo,Ying Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种可验证多选择重构(VMR)方法，将开放式任务转化为可验证的多选择格式，从而在缺乏标准答案的情况下也能有效训练语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有可验证奖励强化学习(RLVR)在数学和编程等有标准答案的领域表现出色，但在开放式任务(如创意写作和指令遵循)中无法直接应用，因为这些任务缺乏标准答案。本文旨在探索如何将推理能力迁移到开放式任务中。

Method: 提出了可验证多选择重构(VMR)训练策略，将开放式数据重新构建为可验证的多选择格式，从而能够在没有明确标准答案的情况下进行有效训练。

Result: 在多个基准测试上的实验结果表明，该方法能有效提升语言模型在开放式任务上的性能。在八个开放式基准测试中，基于VMR的训练相比基线平均提升了5.99分。

Conclusion: VMR方法成功地将RLVR范式扩展到开放式领域，证明了即使在缺乏标准答案的情况下，强化推理能力也能显著提升语言模型在开放式任务中的表现。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated great
potential in enhancing the reasoning capabilities of large language models
(LLMs), achieving remarkable progress in domains such as mathematics and
programming where standard answers are available. However, for open-ended tasks
lacking ground-truth solutions (e.g., creative writing and instruction
following), existing studies typically regard them as non-reasoning scenarios,
thereby overlooking the latent value of reasoning capabilities. This raises a
key question: Can strengthening reasoning improve performance in open-ended
tasks? To address this, we explore the transfer of the RLVR paradigm to the
open domain. Yet, since RLVR fundamentally relies on verifiers that presuppose
the existence of standard answers, it cannot be directly applied to open-ended
tasks. To overcome this challenge, we introduce Verifiable Multiple-Choice
Reformulation (VMR), a novel training strategy that restructures open-ended
data into verifiable multiple-choice formats, enabling effective training even
in the absence of explicit ground truth. Experimental results on multiple
benchmarks validate the effectiveness of our method in improving LLM
performance on open-ended tasks. Notably, across eight open-ended benchmarks,
our VMR-based training delivers an average gain of 5.99 points over the
baseline. Code will be released upon acceptance to facilitate reproducibility.

</details>


### [77] [Agentic AI for Mobile Network RAN Management and Optimization](https://arxiv.org/abs/2511.02532)
*Jorge Pellejero,Luis A. Hernández Gómez,Luis Mendo Tomás,Zoraida Frias Barroso*

Main category: cs.AI

TL;DR: 本文提出了Agentic AI在5G/6G网络中的应用框架，通过LAMs实现自主RAN优化，包含反思、规划、工具使用和多智能体协作等核心设计模式。


<details>
  <summary>Details</summary>
Motivation: 5G/6G网络的复杂性使得手动优化效率低下，需要利用Agentic AI来自动化动态RAN环境中的决策过程。

Method: 提出Agentic AI核心概念和设计模式，包括反思、规划、工具使用和多智能体协作，并在5G RAN案例中应用时间序列分析和LAM驱动的智能体进行KPI自主决策。

Result: 建立了Agentic AI在移动网络中的理论基础，并通过实际案例展示了其在RAN管理优化中的可行性。

Conclusion: Agentic AI为5G/6G网络自动化提供了有前景的解决方案，能够实现自主目标分解、上下文保持和动态适应等能力。

Abstract: Agentic AI represents a new paradigm for automating complex systems by using
Large AI Models (LAMs) to provide human-level cognitive abilities with
multimodal perception, planning, memory, and reasoning capabilities. This will
lead to a new generation of AI systems that autonomously decompose goals,
retain context over time, learn continuously, operate across tools and
environments, and adapt dynamically. The complexity of 5G and upcoming 6G
networks renders manual optimization ineffective, pointing to Agentic AI as a
method for automating decisions in dynamic RAN environments. However, despite
its rapid advances, there is no established framework outlining the
foundational components and operational principles of Agentic AI systems nor a
universally accepted definition.
  This paper contributes to ongoing research on Agentic AI in 5G and 6G
networks by outlining its core concepts and then proposing a practical use case
that applies Agentic principles to RAN optimization. We first introduce Agentic
AI, tracing its evolution from classical agents and discussing the progress
from workflows and simple AI agents to Agentic AI. Core design
patterns-reflection, planning, tool use, and multi-agent collaboration-are then
described to illustrate how intelligent behaviors are orchestrated. These
theorical concepts are grounded in the context of mobile networks, with a focus
on RAN management and optimization. A practical 5G RAN case study shows how
time-series analytics and LAM-driven agents collaborate for KPI-based
autonomous decision-making.

</details>


### [78] [Knowledge Graph-enhanced Large Language Model for Incremental Game PlayTesting](https://arxiv.org/abs/2511.02534)
*Enhong Mu,Jinyu Cai,Yijun Lu,Mingyue Zhang,Kenji Tei,Jialong Li*

Main category: cs.AI

TL;DR: 提出KLPEG框架，通过知识图谱建模游戏元素、任务依赖和因果关系，结合LLM解析更新日志，实现针对游戏更新的精准自动化测试。


<details>
  <summary>Details</summary>
Motivation: 现代游戏快速迭代更新给测试带来挑战，现有基于LLM的自动化测试方法缺乏结构化知识积累机制，难以针对增量更新进行精准高效测试。

Method: 构建知识图谱系统建模游戏元素、任务依赖和因果关系，利用LLM解析自然语言更新日志，通过知识图谱多跳推理识别影响范围，生成针对性测试用例。

Result: 在Overcooked和Minecraft两个游戏环境中的实验表明，KLPEG能更准确定位受更新影响的功能，用更少步骤完成测试，显著提升测试效果和效率。

Conclusion: KLPEG框架通过知识图谱和LLM的结合，有效解决了游戏增量更新的自动化测试问题，实现了知识的积累和重用。

Abstract: The rapid iteration and frequent updates of modern video games pose
significant challenges to the efficiency and specificity of testing. Although
automated playtesting methods based on Large Language Models (LLMs) have shown
promise, they often lack structured knowledge accumulation mechanisms, making
it difficult to conduct precise and efficient testing tailored for incremental
game updates. To address this challenge, this paper proposes a KLPEG framework.
The framework constructs and maintains a Knowledge Graph (KG) to systematically
model game elements, task dependencies, and causal relationships, enabling
knowledge accumulation and reuse across versions. Building on this foundation,
the framework utilizes LLMs to parse natural language update logs, identify the
scope of impact through multi-hop reasoning on the KG, enabling the generation
of update-tailored test cases. Experiments in two representative game
environments, Overcooked and Minecraft, demonstrate that KLPEG can more
accurately locate functionalities affected by updates and complete tests in
fewer steps, significantly improving both playtesting effectiveness and
efficiency.

</details>


### [79] [The ORCA Benchmark: Evaluating Real-World Calculation Accuracy in Large Language Models](https://arxiv.org/abs/2511.02589)
*Claudia Herambourg,Dawid Siuda,Anna Szczepanek,Julia Kopczyńska,Joao R. L. Santos,Wojciech Sas,Joanna Śmietańska-Nowak*

Main category: cs.AI

TL;DR: ORCA基准测试评估大语言模型在多领域真实定量推理任务上的表现，结果显示当前最先进模型准确率仅为45-63%，主要错误来自舍入和计算错误。


<details>
  <summary>Details</summary>
Motivation: 现有数学数据集无法充分评估大语言模型在真实世界多领域定量推理任务中的表现，需要开发新的基准来测试逐步推理、数值精度和领域泛化能力。

Method: 使用Omni计算引擎验证的输出来构建包含500个自然语言任务的基准，涵盖金融、物理、健康、统计等领域，评估五个最先进大语言模型的性能。

Result: 五个模型准确率在45-63%之间，主要错误类型为舍入错误(35%)和计算错误(33%)。模型在数学和工程领域表现较好，但在物理和自然科学领域较弱。

Conclusion: 大语言模型在真实世界定量推理任务中表现有限，错误模式存在部分互补性而非冗余性，需要改进数值计算精度和领域适应性。

Abstract: We present ORCA (Omni Research on Calculation in AI) Benchmark -- a novel
benchmark that evaluates large language models (LLMs) on multi-domain,
real-life quantitative reasoning using verified outputs from Omni's calculator
engine. In 500 natural-language tasks across domains such as finance, physics,
health, and statistics, the five state-of-the-art systems (ChatGPT-5,
Gemini~2.5~Flash, Claude~Sonnet~4.5, Grok~4, and DeepSeek~V3.2) achieved only
$45\text{--}63\,\%$ accuracy, with errors mainly related to rounding ($35\,\%$)
and calculation mistakes ($33\,\%$). Results in specific domains indicate
strengths in mathematics and engineering, but weaknesses in physics and natural
sciences. Correlation analysis ($r \approx 0.40\text{--}0.65$) shows that the
models often fail together but differ in the types of errors they make,
highlighting their partial complementarity rather than redundancy. Unlike
standard math datasets, ORCA evaluates step-by-step reasoning, numerical
precision, and domain generalization across real problems from finance,
physics, health, and statistics.

</details>


### [80] [Adaptive GR(1) Specification Repair for Liveness-Preserving Shielding in Reinforcement Learning](https://arxiv.org/abs/2511.02605)
*Tiberiu-Andrei Georgescu,Alexander W. Goodall,Dalal Alrajeh,Francesco Belardinelli,Sebastian Uchitel*

Main category: cs.AI

TL;DR: 提出了首个基于GR(1)规范的自适应屏蔽框架，通过运行时检测环境假设违规并使用归纳逻辑编程在线修复规范，确保屏蔽器优雅演化并保持最优奖励和逻辑合规性。


<details>
  <summary>Details</summary>
Motivation: 传统静态屏蔽方法假设固定的逻辑规范和手工抽象，当环境假设被违反时无法适应，导致在非名义条件下失效。

Method: 基于GR(1)规范开发自适应屏蔽框架，运行时检测环境假设违规，使用归纳逻辑编程在线自动修复GR(1)规范，以系统化和可解释的方式。

Result: 在Minepump和Atari Seaquest案例研究中显示：(i)静态符号控制器在优化辅助奖励时通常严重次优；(ii)配备自适应屏蔽的RL代理相比静态屏蔽保持接近最优奖励和完美逻辑合规性。

Conclusion: 自适应屏蔽框架能够优雅演化，确保活性可达成且仅在必要时弱化目标，在环境假设变化时提供更好的适应性和性能。

Abstract: Shielding is widely used to enforce safety in reinforcement learning (RL),
ensuring that an agent's actions remain compliant with formal specifications.
Classical shielding approaches, however, are often static, in the sense that
they assume fixed logical specifications and hand-crafted abstractions. While
these static shields provide safety under nominal assumptions, they fail to
adapt when environment assumptions are violated. In this paper, we develop the
first adaptive shielding framework - to the best of our knowledge - based on
Generalized Reactivity of rank 1 (GR(1)) specifications, a tractable and
expressive fragment of Linear Temporal Logic (LTL) that captures both safety
and liveness properties. Our method detects environment assumption violations
at runtime and employs Inductive Logic Programming (ILP) to automatically
repair GR(1) specifications online, in a systematic and interpretable way. This
ensures that the shield evolves gracefully, ensuring liveness is achievable and
weakening goals only when necessary. We consider two case studies: Minepump and
Atari Seaquest; showing that (i) static symbolic controllers are often severely
suboptimal when optimizing for auxiliary rewards, and (ii) RL agents equipped
with our adaptive shield maintain near-optimal reward and perfect logical
compliance compared with static shields.

</details>


### [81] [A Multi-Agent Psychological Simulation System for Human Behavior Modeling](https://arxiv.org/abs/2511.02606)
*Xiangen Hu,Jiarui Tong,Sheng Xu*

Main category: cs.AI

TL;DR: 提出了一个基于心理学理论的多智能体心理模拟系统，用于生成可信的人类行为，应用于教师培训和研究。


<details>
  <summary>Details</summary>
Motivation: 人类中心领域的培训和教育需要真实的实践，但现实的人类行为模拟一直受限。

Method: 基于心理学理论（如自我效能、思维模式、社会建构主义）构建多智能体系统，模拟内部认知-情感过程，通过'内部议会'中的智能体协商决定输出行为。

Result: 系统实现了前所未有的透明度和与人类心理学的对齐，能够生成可信的人类行为。

Conclusion: 该系统体现了社会学习、认知学徒制、刻意练习和元认知等原则，为教师培训和研究提供了有效工具。

Abstract: Training and education in human-centered fields require authentic practice,
yet realistic simulations of human behavior have remained limited. We present a
multi-agent psychological simulation system that models internal
cognitive-affective processes to generate believable human behaviors. In
contrast to black-box neural models, this system is grounded in established
psychological theories (e.g., self-efficacy, mindset, social constructivism)
and explicitly simulates an ``inner parliament'' of agents corresponding to key
psychological factors. These agents deliberate and interact to determine the
system's output behavior, enabling unprecedented transparency and alignment
with human psychology. We describe the system's architecture and theoretical
foundations, illustrate its use in teacher training and research, and discuss
how it embodies principles of social learning, cognitive apprenticeship,
deliberate practice, and meta-cognition.

</details>


### [82] [LLM-Supported Formal Knowledge Representation for Enhancing Control Engineering Content with an Interactive Semantic Layer](https://arxiv.org/abs/2511.02759)
*Julius Fiedler,Carsten Knoll,Klaus Röbenack*

Main category: cs.AI

TL;DR: 提出了一种基于LLM的半自动化方法，用于生成结合人类可读性和机器可解释性的形式化知识表示，应用于控制工程领域。


<details>
  <summary>Details</summary>
Motivation: 控制工程领域研究产出的快速增长需要新的方法来结构化和形式化领域知识。

Method: 基于Imperative Representation of Knowledge (PyIRK)框架，利用语言模型将自然语言描述和数学定义(LaTeX源代码)转换为形式化知识图谱。

Result: 开发了"交互式语义层"来增强源文档，促进知识传递。

Conclusion: 这有助于实现控制工程领域易于访问、协作和可验证的知识库愿景。

Abstract: The rapid growth of research output in control engineering calls for new
approaches to structure and formalize domain knowledge. This paper briefly
describes an LLM-supported method for semi-automated generation of formal
knowledge representations that combine human readability with machine
interpretability and increased expressiveness. Based on the Imperative
Representation of Knowledge (PyIRK) framework, we demonstrate how language
models can assist in transforming natural-language descriptions and
mathematical definitions (available as LaTeX source code) into a formalized
knowledge graph. As a first application we present the generation of an
``interactive semantic layer'' to enhance the source documents in order to
facilitate knowledge transfer. From our perspective this contributes to the
vision of easily accessible, collaborative, and verifiable knowledge bases for
the control engineering domain.

</details>


### [83] [DecompSR: A dataset for decomposed analyses of compositional multihop spatial reasoning](https://arxiv.org/abs/2511.02627)
*Lachlan McPheat,Navdeep Kaur,Robert Blackwell,Alessandra Russo,Anthony G. Cohn,Pranava Madhyastha*

Main category: cs.AI

TL;DR: DecompSR是一个用于分析组合空间推理能力的大规模基准数据集和生成框架，包含500多万个数据点，可独立控制组合性的多个方面，并通过符号求解器保证数据正确性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在组合空间推理方面存在局限性，需要能够独立控制组合性不同方面的基准来精细评估模型能力。

Method: 通过程序化生成方法构建数据集，独立控制生产力（推理深度）、可替换性（实体和语言变体）、过度泛化（输入顺序、干扰项）和系统性（新语言元素）等组合性维度。

Result: LLMs在空间推理任务中难以进行生产性和系统性泛化，但对语言变体具有更强的鲁棒性。

Conclusion: DecompSR提供了一个可证明正确且严格的基准数据集，能够精细探测LLMs的组合推理能力。

Abstract: We introduce DecompSR, decomposed spatial reasoning, a large benchmark
dataset (over 5m datapoints) and generation framework designed to analyse
compositional spatial reasoning ability. The generation of DecompSR allows
users to independently vary several aspects of compositionality, namely:
productivity (reasoning depth), substitutivity (entity and linguistic
variability), overgeneralisation (input order, distractors) and systematicity
(novel linguistic elements). DecompSR is built procedurally in a manner which
makes it is correct by construction, which is independently verified using a
symbolic solver to guarantee the correctness of the dataset. DecompSR is
comprehensively benchmarked across a host of Large Language Models (LLMs) where
we show that LLMs struggle with productive and systematic generalisation in
spatial reasoning tasks whereas they are more robust to linguistic variation.
DecompSR provides a provably correct and rigorous benchmarking dataset with a
novel ability to independently vary the degrees of several key aspects of
compositionality, allowing for robust and fine-grained probing of the
compositional reasoning abilities of LLMs.

</details>


### [84] [The Collaboration Gap](https://arxiv.org/abs/2511.02687)
*Tim R. Davidson,Adam Fourney,Saleema Amershi,Robert West,Eric Horvitz,Ece Kamar*

Main category: cs.AI

TL;DR: 该研究提出了一个协作迷宫求解基准，评估了32个领先的AI模型在协作任务中的表现，发现了显著的"协作差距"，并提出"接力推理"方法改善协作效果。


<details>
  <summary>Details</summary>
Motivation: 随着AI发展，我们将越来越多地依赖由独立开发的异构智能体组成的系统，这些系统的成功关键在于有效协作，但目前缺乏大规模评估此类协作的实证研究。

Method: 设计了一个协作迷宫求解基准，隔离协作能力、调节问题复杂度、支持自动化评分，并评估了32个开源和闭源模型在单独、同质和异质配对中的表现。

Result: 发现明显的"协作差距"：单独表现良好的模型在协作时性能显著下降，小型蒸馏模型在某些配对中几乎完全失败。从较强智能体开始能改善结果，"接力推理"方法能大幅缩小协作差距。

Conclusion: 研究主张：(1)协作感知的评估方法，(2)增强协作能力的训练策略，(3)可靠激发智能体潜在技能的交互设计，这些指导适用于AI-AI和人类-AI协作。

Abstract: The trajectory of AI development suggests that we will increasingly rely on
agent-based systems composed of independently developed agents with different
information, privileges, and tools. The success of these systems will
critically depend on effective collaboration among these heterogeneous agents,
even under partial observability. Despite intense interest, few empirical
studies have evaluated such agent-agent collaboration at scale. We propose a
collaborative maze-solving benchmark that (i) isolates collaborative
capabilities, (ii) modulates problem complexity, (iii) enables scalable
automated grading, and (iv) imposes no output-format constraints, preserving
ecological plausibility. Using this framework, we evaluate 32 leading open- and
closed-source models in solo, homogeneous, and heterogeneous pairings. Our
results reveal a "collaboration gap": models that perform well solo often
degrade substantially when required to collaborate. Collaboration can break
down dramatically; for instance, small distilled models that solve mazes well
alone may fail almost completely in certain pairings. We find that starting
with the stronger agent often improves outcomes, motivating a "relay inference"
approach where the stronger agent leads before handing off to the weaker one,
closing much of the gap. Our findings argue for (1) collaboration-aware
evaluation, (2) training strategies developed to enhance collaborative
capabilities, and (3) interaction design that reliably elicits agents' latent
skills, guidance that applies to AI-AI and human-AI collaboration.

</details>


### [85] [CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents](https://arxiv.org/abs/2511.02734)
*Jiayu Liu,Cheng Qian,Zhaochen Su,Qing Zong,Shijue Huang,Bingxiang He,Yi R. Fung*

Main category: cs.AI

TL;DR: CostBench是一个专注于成本效率的基准测试，用于评估LLM代理的经济推理和重新规划能力，发现在静态和动态环境下代理都难以找到成本最优解。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理评估主要关注任务完成度，忽视了资源效率和适应性，特别是代理在变化环境中制定和调整成本最优计划的能力。

Method: 在旅行规划领域设计了CostBench基准，包含可通过多种工具序列解决的任务，支持四种动态阻塞事件（如工具故障和成本变化）来模拟现实世界的不确定性。

Result: 评估显示代理在成本感知规划方面存在显著差距：在静态设置中经常无法找到成本最优解，GPT-5在最难任务上的精确匹配率低于75%，动态条件下性能进一步下降约40%。

Conclusion: CostBench通过诊断这些弱点，为开发既经济理性又鲁棒的未来代理奠定了基础。

Abstract: Current evaluations of Large Language Model (LLM) agents primarily emphasize
task completion, often overlooking resource efficiency and adaptability. This
neglects a crucial capability: agents' ability to devise and adjust
cost-optimal plans in response to changing environments. To bridge this gap, we
introduce CostBench, a scalable, cost-centric benchmark designed to evaluate
agents' economic reasoning and replanning abilities. Situated in the
travel-planning domain, CostBench comprises tasks solvable via multiple
sequences of atomic and composite tools with diverse, customizable costs. It
also supports four types of dynamic blocking events, such as tool failures and
cost changes, to simulate real-world unpredictability and necessitate agents to
adapt in real time. Evaluating leading open-sourced and proprietary models on
CostBench reveals a substantial gap in cost-aware planning: agents frequently
fail to identify cost-optimal solutions in static settings, with even GPT-5
achieving less than 75% exact match rate on the hardest tasks, and performance
further dropping by around 40% under dynamic conditions. By diagnosing these
weaknesses, CostBench lays the groundwork for developing future agents that are
both economically rational and robust.

</details>


### [86] [Using Span Queries to Optimize for Cache and Attention Locality](https://arxiv.org/abs/2511.02749)
*Paul Castro,Nick Mitchell,Nathan Ordonez,Thomas Parnell,Mudhakar Srivatsa,Antoni Viros i Martin*

Main category: cs.AI

TL;DR: 本文提出了span query概念，将推理服务器接口泛化，支持聊天、RAG、推理时缩放和智能体工作负载，通过交换性约束优化KV缓存命中率，在非聊天用例中实现10-20倍的TTFT降低。


<details>
  <summary>Details</summary>
Motivation: 客户端已超越聊天完成功能，包含各种创新的推理时缩放和深度推理技术，但推理服务器仍主要针对聊天完成优化。现有解决方案仅针对单一用例（RAG）优化，需要更通用的接口。

Method: 引入span query作为推理调用的表达式树，通过交换性约束链接，可自动优化KV缓存局部性。对vLLM进行小改动（仅492行代码）实现高性能span query执行。

Result: span query在两种不同的非聊天用例中实现10-20倍的TTFT（首次令牌时间）降低。注意力优化的span query在2b参数模型上显著优于使用8b模型的传统推理服务器精度。

Conclusion: span query提供了一种通用接口，能够有效支持多种推理工作负载，通过优化KV缓存和注意力局部性显著提升性能，解决了传统推理服务器在非聊天用例中的局限性。

Abstract: Clients are evolving beyond chat completion, and now include a variety of
innovative inference-time scaling and deep reasoning techniques. At the same
time, inference servers remain heavily optimized for chat completion. Prior
work has shown that large improvements to KV cache hit rate are possible if
inference servers evolve towards these non-chat use cases. However, they offer
solutions that are also optimized for a single use case, RAG. In this paper, we
introduce the span query to generalize the interface to the inference server.
We demonstrate that chat, RAG, inference-time scaling, and agentic workloads
can all be expressed as span queries. We show how the critical distinction that
had been assumed by prior work lies in whether the order of the inputs matter
-- do they commute? In chat, they do not. In RAG, they often do. This paper
introduces span queries, which are expression trees of inference calls, linked
together with commutativity constraints. We describe span query syntax and
semantics. We show how they can be automatically optimized to improve KV cache
locality. We show how a small change to vLLM (affecting only 492 lines) can
enable high-performance execution of span queries. Using this stack, we
demonstrate that span queries can achieve 10-20x reductions in TTFT for two
distinct non-chat use cases. Finally, we show that span queries can also be
optimized to improve attention locality, so as to avoid the so-called
lost-in-the-middle problem. We demonstrate that an attention-optimized span
query on a 2b parameter model vastly outperforms the accuracy of a stock
inference server using an 8b model.

</details>


### [87] [When One Modality Sabotages the Others: A Diagnostic Lens on Multimodal Reasoning](https://arxiv.org/abs/2511.02794)
*Chenyu Zhang,Minsol Kim,Shohreh Ghorbani,Jingyao Wu,Rosalind Picard,Patricia Maes,Paul Pu Liang*

Main category: cs.AI

TL;DR: 提出了一种轻量级、模型无关的多模态诊断框架，通过将每个模态视为代理来识别模态破坏现象——即高置信度的单模态错误覆盖其他证据并误导融合结果。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型快速发展，但其推理过程仍不透明：不清楚哪个模态驱动预测、如何解决冲突或何时某个模态主导。需要诊断多模态融合中的失败模式。

Method: 将每个模态视为代理，生成候选标签和简要自我评估，通过简单融合机制聚合这些输出，暴露贡献者（支持正确结果的模态）和破坏者（误导的模态）。

Result: 在情感识别基准测试的案例研究中，揭示了系统性的可靠性特征，能够识别失败是源于数据集伪影还是模型限制。

Conclusion: 该框架为多模态推理提供了诊断支架，支持对融合动态的原则性审计，并为可能的干预措施提供信息。

Abstract: Despite rapid growth in multimodal large language models (MLLMs), their
reasoning traces remain opaque: it is often unclear which modality drives a
prediction, how conflicts are resolved, or when one stream dominates. In this
paper, we introduce modality sabotage, a diagnostic failure mode in which a
high-confidence unimodal error overrides other evidence and misleads the fused
result. To analyze such dynamics, we propose a lightweight, model-agnostic
evaluation layer that treats each modality as an agent, producing candidate
labels and a brief self-assessment used for auditing. A simple fusion mechanism
aggregates these outputs, exposing contributors (modalities supporting correct
outcomes) and saboteurs (modalities that mislead). Applying our diagnostic
layer in a case study on multimodal emotion recognition benchmarks with
foundation models revealed systematic reliability profiles, providing insight
into whether failures may arise from dataset artifacts or model limitations.
More broadly, our framework offers a diagnostic scaffold for multimodal
reasoning, supporting principled auditing of fusion dynamics and informing
possible interventions.

</details>


### [88] [Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning](https://arxiv.org/abs/2511.02818)
*Mohamed Bouadi,Pratinav Seth,Aditya Tanna,Vinay Kumar Sankarapu*

Main category: cs.AI

TL;DR: Orion-MSP是一个用于表格数据上下文学习的创新架构，通过多尺度处理、块稀疏注意力和感知器风格内存解决了现有方法的局限性，在保持高效的同时实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前表格上下文学习方法存在三个主要限制：单尺度特征处理忽略了层次依赖关系；密集注意力机制在表格宽度上具有二次缩放；严格的顺序组件处理阻碍了迭代表示细化和跨组件通信。

Method: Orion-MSP采用三个关键创新：多尺度处理捕捉层次特征交互；块稀疏注意力结合窗口化、全局和随机模式实现可扩展效率和长距离连接；感知器风格内存支持跨组件的安全双向信息流。

Result: 在多样化基准测试中，Orion-MSP匹配或超越了最先进方法的性能，同时能够有效扩展到高维表格，为高效的表格上下文学习设立了新标准。

Conclusion: Orion-MSP通过其多尺度处理、高效注意力机制和内存架构，成功解决了现有表格上下文学习方法的局限性，在保持可扩展性的同时实现了卓越性能。

Abstract: Tabular data remain the predominant format for real-world applications. Yet,
developing effective neural models for tabular data remains challenging due to
heterogeneous feature types and complex interactions occurring at multiple
scales. Recent advances in tabular in-context learning (ICL), such as TabPFN
and TabICL, have achieved state-of-the-art performance comparable to
gradient-boosted trees (GBTs) without task-specific fine-tuning. However,
current architectures exhibit key limitations: (1) single-scale feature
processing that overlooks hierarchical dependencies, (2) dense attention with
quadratic scaling in table width, and (3) strictly sequential component
processing that prevents iterative representation refinement and
cross-component communication. To address these challenges, we introduce
Orion-MSP, a tabular ICL architecture featuring three key innovations: (1)
multi-scale processing to capture hierarchical feature interactions; (2)
block-sparse attention combining windowed, global, and random patterns for
scalable efficiency and long-range connectivity; and (3) a Perceiver-style
memory enabling safe bidirectional information flow across components. Across
diverse benchmarks, Orion-MSP matches or surpasses state-of-the-art performance
while scaling effectively to high-dimensional tables, establishing a new
standard for efficient tabular in-context learning. The model is publicly
available at https://github.com/Lexsi-Labs/Orion-MSP .

</details>


### [89] [Optimizing AI Agent Attacks With Synthetic Data](https://arxiv.org/abs/2511.02823)
*Chloe Loughridge,Paul Colognese,Avery Griffin,Tyler Tracy,Jon Kutasov,Joe Benton*

Main category: cs.AI

TL;DR: 提出了一种在复杂AI控制环境中优化攻击策略的方法，通过将攻击能力分解为五个技能组件并分别优化，使用概率模型解决数据不足问题，显著提升了攻击强度。


<details>
  <summary>Details</summary>
Motivation: 随着AI部署变得复杂且高风险，需要准确评估其风险。AI控制框架需要强大的攻击策略，但在复杂代理环境中由于计算限制导致数据不足，这带来了挑战。

Method: 将攻击能力分解为五个技能组件（怀疑建模、攻击选择、计划合成、执行和隐蔽性），开发攻击动态的概率模型来优化超参数，然后在SHADE-Arena环境中验证结果。

Result: 攻击强度显著提升，安全分数从基准的0.87降低到0.41，表明该方法能有效增强攻击策略。

Conclusion: 通过技能分解和概率建模的方法可以有效优化复杂AI环境中的攻击策略，解决了数据不足的限制，为AI风险评估提供了有效工具。

Abstract: As AI deployments become more complex and high-stakes, it becomes
increasingly important to be able to estimate their risk. AI control is one
framework for doing so. However, good control evaluations require eliciting
strong attack policies. This can be challenging in complex agentic environments
where compute constraints leave us data-poor. In this work, we show how to
optimize attack policies in SHADE-Arena, a dataset of diverse realistic control
environments. We do this by decomposing attack capability into five constituent
skills -- suspicion modeling, attack selection, plan synthesis, execution and
subtlety -- and optimizing each component individually. To get around the
constraint of limited data, we develop a probabilistic model of attack
dynamics, optimize our attack hyperparameters using this simulation, and then
show that the results transfer to SHADE-Arena. This results in a substantial
improvement in attack strength, reducing safety score from a baseline of 0.87
to 0.41 using our scaffold.

</details>


### [90] [Kosmos: An AI Scientist for Autonomous Discovery](https://arxiv.org/abs/2511.02824)
*Ludovico Mitchener,Angela Yiu,Benjamin Chang,Mathieu Bourdenx,Tyler Nadolski,Arvis Sulovari,Eric C. Landsness,Daniel L. Barabasi,Siddharth Narayanan,Nicky Evans,Shriya Reddy,Martha Foiani,Aizad Kamal,Leah P. Shriver,Fang Cao,Asmamaw T. Wassie,Jon M. Laurent,Edwin Melville-Green,Mayk Caldas,Albert Bou,Kaleigh F. Roberts,Sladjana Zagorac,Timothy C. Orr,Miranda E. Orr,Kevin J. Zwezdaryk,Ali E. Ghareeb,Laurie McCoy,Bruna Gomes,Euan A. Ashley,Karen E. Duff,Tonio Buonassisi,Tom Rainforth,Randall J. Bateman,Michael Skarlinski,Samuel G. Rodriques,Michaela M. Hinks,Andrew D. White*

Main category: cs.AI

TL;DR: Kosmos是一个AI科学家系统，通过结构化世界模型连接数据分析代理和文献搜索代理，能够持续运行12小时进行数据驱动的科学发现，生成可追溯的科学报告。


<details>
  <summary>Details</summary>
Motivation: 现有的AI科研代理在采取有限行动后会失去连贯性，限制了发现深度。需要开发能够长期保持连贯性、进行深度科学发现的AI系统。

Method: 使用结构化世界模型在数据分析代理和文献搜索代理之间共享信息，进行并行数据分析、文献搜索和假设生成的循环，最多运行12小时，平均执行42,000行代码和阅读1,500篇论文。

Result: Kosmos报告中的79.4%陈述被独立科学家评为准确，单次20周期运行相当于人类科学家6个月的研究工作量，且有价值的科学发现数量与运行周期呈线性关系。

Conclusion: Kosmos成功实现了长期连贯的自动化科学发现，在多个学科领域做出了原创性贡献，证明了AI系统能够进行深度科学研究。

Abstract: Data-driven scientific discovery requires iterative cycles of literature
search, hypothesis generation, and data analysis. Substantial progress has been
made towards AI agents that can automate scientific research, but all such
agents remain limited in the number of actions they can take before losing
coherence, thus limiting the depth of their findings. Here we present Kosmos,
an AI scientist that automates data-driven discovery. Given an open-ended
objective and a dataset, Kosmos runs for up to 12 hours performing cycles of
parallel data analysis, literature search, and hypothesis generation before
synthesizing discoveries into scientific reports. Unlike prior systems, Kosmos
uses a structured world model to share information between a data analysis
agent and a literature search agent. The world model enables Kosmos to
coherently pursue the specified objective over 200 agent rollouts, collectively
executing an average of 42,000 lines of code and reading 1,500 papers per run.
Kosmos cites all statements in its reports with code or primary literature,
ensuring its reasoning is traceable. Independent scientists found 79.4% of
statements in Kosmos reports to be accurate, and collaborators reported that a
single 20-cycle Kosmos run performed the equivalent of 6 months of their own
research time on average. Furthermore, collaborators reported that the number
of valuable scientific findings generated scales linearly with Kosmos cycles
(tested up to 20 cycles). We highlight seven discoveries made by Kosmos that
span metabolomics, materials science, neuroscience, and statistical genetics.
Three discoveries independently reproduce findings from preprinted or
unpublished manuscripts that were not accessed by Kosmos at runtime, while four
make novel contributions to the scientific literature.

</details>


### [91] [Neurosymbolic Deep Learning Semantics](https://arxiv.org/abs/2511.02825)
*Artur d'Avila Garcez,Simon Odense*

Main category: cs.AI

TL;DR: 本文提出使用逻辑框架为深度学习提供语义基础，通过神经符号AI将神经网络与逻辑语义连接起来，解决AI科学发现缺乏语义理解的问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI缺乏语义基础，使得科学发现难以理解。需要建立框架将AI洞察转化为可理解的科学知识，逻辑为此提供了合适的形式化工具。

Method: 引入语义编码框架，明确神经网络与逻辑之间的映射关系，总结现有神经编码和知识提取方法的核心要素。

Result: 建立了连接逻辑语义与神经网络的统一框架，形式化定义了语义编码，并讨论了实践中的识别困难。

Conclusion: 逻辑框架能为深度学习提供急需的语义基础，神经符号AI通过语义编码将神经网络与逻辑连接，有助于提升AI科学发现的可理解性。

Abstract: Artificial Intelligence (AI) is a powerful new language of science as
evidenced by recent Nobel Prizes in chemistry and physics that recognized
contributions to AI applied to those areas. Yet, this new language lacks
semantics, which makes AI's scientific discoveries unsatisfactory at best. With
the purpose of uncovering new facts but also improving our understanding of the
world, AI-based science requires formalization through a framework capable of
translating insight into comprehensible scientific knowledge. In this paper, we
argue that logic offers an adequate framework. In particular, we use logic in a
neurosymbolic framework to offer a much needed semantics for deep learning, the
neural network-based technology of current AI. Deep learning and neurosymbolic
AI lack a general set of conditions to ensure that desirable properties are
satisfied. Instead, there is a plethora of encoding and knowledge extraction
approaches designed for particular cases. To rectify this, we introduced a
framework for semantic encoding, making explicit the mapping between neural
networks and logic, and characterizing the common ingredients of the various
existing approaches. In this paper, we describe succinctly and exemplify how
logical semantics and neural networks are linked through this framework, we
review some of the most prominent approaches and techniques developed for
neural encoding and knowledge extraction, provide a formal definition of our
framework, and discuss some of the difficulties of identifying a semantic
encoding in practice in light of analogous problems in the philosophy of mind.

</details>


### [92] [Agent-Omni: Test-Time Multimodal Reasoning via Model Coordination for Understanding Anything](https://arxiv.org/abs/2511.02834)
*Huawei Lin,Yunzhi Shi,Tong Geng,Weijie Zhao,Wei Wang,Ravender Pal Singh*

Main category: cs.AI

TL;DR: 提出了Agent-Omni框架，通过主代理系统协调现有基础模型，实现无需重新训练的灵活多模态推理。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型局限于固定模态对，需要大量对齐数据和昂贵微调，缺乏对文本、图像、音频、视频的全能集成和强大推理支持。

Method: 采用主代理系统，主代理解释用户意图，将子任务委托给特定模态代理，并整合它们的输出形成连贯响应。

Result: 在文本、图像、音频、视频和全能基准测试中，Agent-Omni始终达到最先进的性能，特别是在需要复杂跨模态推理的任务上表现出色。

Conclusion: 基于代理的设计实现了专用基础模型的无缝集成，确保了对多样化输入的适应性，同时保持了透明度和可解释性。框架模块化且易于扩展，支持未来更强模型的集成。

Abstract: Multimodal large language models (MLLMs) have shown strong capabilities but
remain limited to fixed modality pairs and require costly fine-tuning with
large aligned datasets. Building fully omni-capable models that can integrate
text, images, audio, and video remains impractical and lacks robust reasoning
support. In this paper, we propose an Agent-Omni framework that coordinates
existing foundation models through a master-agent system, enabling flexible
multimodal reasoning without retraining. The master agent interprets user
intent, delegates subtasks to modality-specific agents, and integrates their
outputs into coherent responses. Extensive experiments across text, image,
audio, video, and omni benchmarks show that Agent-Omni consistently achieves
state-of-the-art performance, particularly on tasks requiring complex
cross-modal reasoning. Its agent-based design enables seamless integration of
specialized foundation models, ensuring adaptability to diverse inputs while
maintaining transparency and interpretability. In addition, the framework is
modular and easily extensible, allowing future improvements as stronger models
become available. %We release an open-source implementation to support
continued research on scalable and reliable omni-modal reasoning.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [93] [A new stochastic diffusion process to model and predict electricity production from natural gas sources in the United States](https://arxiv.org/abs/2511.01925)
*Safa' Alsheyab*

Main category: stat.AP

TL;DR: 提出了一种新的随机扩散过程来建模美国天然气发电占比，使用趋势函数分析和最大似然估计方法，提供了2022-2023年的可靠中期预测。


<details>
  <summary>Details</summary>
Motivation: 需要开发一个有效的随机模型来分析和预测美国天然气发电在总发电量中的占比变化趋势。

Method: 使用趋势函数分析结合最大似然估计方法，基于1990-2021年的年度数据对随机扩散过程参数进行估计。

Result: 模型能够有效拟合历史数据，并为2022-2023年提供了可靠的中期预测结果。

Conclusion: 提出的随机扩散过程模型是分析美国天然气发电占比趋势的有效工具，具有较好的预测能力。

Abstract: This paper introduces a new stochastic diffusion process to model the
electricity production from natural gas sources (as a percentage of total
electricity production) in the United States. The method employs trend function
analysis to generate fits and forecasts with both conditional and unconditional
estimated trend functions. Parameters are estimated using the maximum
likelihood (ML) method, based on discrete sampling paths of the variable
"electricity production from natural gas sources in the United States" with
annual data from 1990 to 2021. The results show that the proposed model
effectively fits the data and provides dependable medium-term forecasts for
2022-2023.

</details>


### [94] [Enhancing Phenotype Discovery in Electronic Health Records through Prior Knowledge-Guided Unsupervised Learning](https://arxiv.org/abs/2511.02102)
*Melanie Mayer,Kimberly Lactaoen,Gary E. Weissman,Blanca E. Himes,Rebecca A. Hubbard*

Main category: stat.AP

TL;DR: 提出一种结合临床知识的贝叶斯潜在类别框架，用于从电子健康记录中发现更具临床意义的表型，并在哮喘患者中识别出T2炎症相关的亚表型。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督学习方法通常忽视临床知识，限制了从EHR数据中发现表型的可解释性。需要一种能够融入领域特定知识的方法来提高表型的临床意义。

Method: 开发贝叶斯潜在类别模型，通过信息先验将临床知识融入无监督聚类，处理缺失数据并提供患者级别的表型分配概率及不确定性。

Result: 在44,642名成人哮喘患者中发现了双峰后验分布，识别出T2炎症相关类别(38.7%)，其特征包括嗜酸性粒细胞升高、过敏标志物、高医疗利用率和药物使用。

Conclusion: 该方法支持在缺乏明确表型定义的异质性疾病研究中进行假设生成和队列识别，为EHR研究提供了有价值的工具。

Abstract: Objectives: Unsupervised learning with electronic health record (EHR) data
has shown promise for phenotype discovery, but approaches typically disregard
existing clinical information, limiting interpretability. We operationalize a
Bayesian latent class framework for phenotyping that incorporates
domain-specific knowledge to improve clinical meaningfulness of EHR-derived
phenotypes and illustrate its utility by identifying an asthma sub-phenotype
informed by features of Type 2 (T2) inflammation.
  Materials and methods: We illustrate a framework for incorporating clinical
knowledge into a Bayesian latent class model via informative priors to guide
unsupervised clustering toward clinically relevant subgroups. This approach
models missingness, accounting for potential missing-not-at-random patterns,
and provides patient-level probabilities for phenotype assignment with
uncertainty. Using reusable and flexible code, we applied the model to a large
asthma EHR cohort, specifying informative priors for T2 inflammation-related
features and weakly informative priors for other clinical variables, allowing
the data to inform posterior distributions.
  Results and Conclusion: Using encounter data from January 2017 to February
2024 for 44,642 adult asthma patients, we found a bimodal posterior
distribution of phenotype assignment, indicating clear class separation. The T2
inflammation-informed class (38.7%) was characterized by elevated eosinophil
levels and allergy markers, plus high healthcare utilization and medication
use, despite weakly informative priors on the latter variables. These patterns
suggest an "uncontrolled T2-high" sub-phenotype. This demonstrates how our
Bayesian latent class modeling approach supports hypothesis generation and
cohort identification in EHR-based studies of heterogeneous diseases without
well-established phenotype definitions.

</details>


### [95] [Wavelet Based Cross Correlations with Applications](https://arxiv.org/abs/2511.02174)
*Jack Kissell,Vijini Lakmini,Brani Vidakovic*

Main category: stat.AP

TL;DR: 本文扩展了基于小波变换的相关性理论，详细阐述了小波相关图、偏小波相关性和加性小波相关性，使用Pearson和Kendall定义，评估了不同小波基下的鲁棒性，并通过仿真和实际数据应用验证了方法。


<details>
  <summary>Details</summary>
Motivation: 小波变换能够将信号分解为不同频率/尺度带的系数向量，同时保留时间局部性，这使得能够在不同尺度上自适应分析信号，捕捉时间和频谱模式。通过研究两个信号之间的相关性如何在这些尺度上变化，可以获得比单一全局相关性度量更细致的理解。

Method: 使用正交和非抽取离散小波变换，扩展了小波相关性理论，包括小波相关图、偏小波相关性和加性小波相关性，采用Pearson和Kendall相关性定义，并评估了不同小波基下的鲁棒性。

Result: 通过仿真研究验证了这些方法的有效性，并在实际数据集上进行了应用，展示了多尺度相关性分析的优势。

Conclusion: 小波变换提供了一种强大的多尺度信号分析工具，能够更细致地揭示信号间的关系，扩展的小波相关性方法在实际应用中表现出良好的鲁棒性和实用性。

Abstract: Wavelet Transforms are a widely used technique for decomposing a signal into
coefficient vectors that correspond to distinct frequency/scale bands while
retaining time localization. This property enables an adaptive analysis of
signals at different scales, capturing both temporal and spectral patterns. By
examining how correlations between two signals vary across these scales, we
obtain a more nuanced understanding of their relationship than what is possible
from a single global correlation measure. In this work, we expand on the theory
of wavelet-based correlations already used in the literature and elaborate on
wavelet correlograms, partial wavelet correlations, and additive wavelet
correlations using the Pearson and Kendall definitions. We use both Orthogonal
and Non-decimated discrete Wavelet Transforms, and assess the robustness of
these correlations under different wavelet bases. Simulation studies are
conducted to illustrate these methods, and we conclude with applications to
real-world datasets.

</details>


### [96] [A generic network theoretic based model to classify SDG indicators](https://arxiv.org/abs/2511.02289)
*Gaurav Kottari,Qazi J. Azhad,Niteesh Sahni*

Main category: stat.AP

TL;DR: 提出基于网络的模型来量化SDG指标重要性，帮助政策制定者识别具有最大协同影响的指标，并以印度数据为例进行应用验证。


<details>
  <summary>Details</summary>
Motivation: 为实现联合国可持续发展目标，需要在相互关联的指标间采取协调行动。现有研究多在目标层面分析SDG关联性，但政策制定和实施通常在指标层面进行，且当前方法存在重要缺陷。

Method: 开发通用的基于网络的理论模型，可量化SDG指标重要性，适用于任何国家。使用印度数据验证模型应用，并通过现有文献为关键观察提供实证支持。

Result: 识别出对加速SDG进展至关重要的关键指标，为政策制定者提供了识别最大协同影响指标的工具。

Conclusion: 主要贡献在于开发了这种网络理论方法学，同时为选定的关键观察提供了来自现有文献的实证支持证据。

Abstract: To achieve the United Nations Sustainable Development Goals, coordinated
action across their interlinked indicators is required. Although most of the
research on the interlinkages of the SDGs is done at the goal level, policies
are usually made and implemented at the level of indicators (or targets). Our
study examines the existing literature on SDG interlinkages and indicator (or
target) prioritization, highlighting important drawbacks of current
methodologies. To address these limitations, we propose a generic network-based
model that can quantify the importance of the SDG indicators and help
policymakers in identifying indicators for maximum synergistic impact. Our
model applies to any country, offering a tool for national policymakers. We
illustrate the application of this model using data from India, identifying
important indicators that are crucial for accelerating progress in the SDGs.
While our main contribution lies in developing this network-theoretic
methodology, we also provide supporting empirical evidence from existing
literature for selected key observations.

</details>


### [97] [Identification of Separable OTUs for Multinomial Classification in Compositional Data Analysis](https://arxiv.org/abs/2511.02509)
*R. Alberich,N. A. Cruz,R. Fernández,I. García Mosquera,A. Mir,F. Roselló*

Main category: stat.AP

TL;DR: 提出了一种基于惩罚对数比回归和成对可分离性筛选的多项式分类框架，用于分析组成型微生物组数据，通过AUC评估OTU的判别能力并生成可解释的排序。


<details>
  <summary>Details</summary>
Motivation: 高通量测序产生的组成型数据对传统统计和机器学习方法构成挑战，需要开发专门的分析框架来处理这种数据类型。

Method: 使用惩罚对数比回归和成对可分离性筛选，计算所有成对对数比的AUC值，聚合成全局可分离性指数Sk，并提供置信区间。

Result: 在Baxter结直肠腺瘤数据集上验证，与Greenacre的排序分析方法相比，该方法能一致地恢复先前识别的核心分类群，同时发现考虑人口统计学协变量后新的重要OTU。

Conclusion: 该方法整合了对数比建模、协变量调整和不确定性估计，为组成型微生物组数据中的OTU选择提供了稳健且可解释的框架，补充了现有的排序分析方法。

Abstract: High-throughput sequencing has transformed microbiome research, but it also
produces inherently compositional data that challenge standard statistical and
machine learning methods. In this work, we propose a multinomial classification
framework for compositional microbiome data based on penalized log-ratio
regression and pairwise separability screening. The method quantifies the
discriminative ability of each OTU through the area under the receiver
operating characteristic curve ($AUC$) for all pairwise log-ratios and
aggregates these values into a global separability index $S_k$, yielding
interpretable rankings of taxa together with confidence intervals. We
illustrate the approach by reanalyzing the Baxter colorectal adenoma dataset
and comparing our results with Greenacre's ordination-based analysis using
Correspondence Analysis and Canonical Correspondence Analysis. Our models
consistently recover a core subset of taxa previously identified as
discriminant, thereby corroborating Greenacre's main findings, while also
revealing additional OTUs that become important once demographic covariates are
taken into account. In particular, adjustment for age, gender, and diabetes
medication improves the precision of the separation index and highlights new,
potentially relevant taxa, suggesting that part of the original signal may have
been influenced by confounding. Overall, the integration of log-ratio modeling,
covariate adjustment, and uncertainty estimation provides a robust and
interpretable framework for OTU selection in compositional microbiome data. The
proposed method complements existing ordination-based approaches by adding a
probabilistic and inferential perspective, strengthening the identification of
biologically meaningful microbial signatures.

</details>


### [98] [Extended Kalman Filtering on Stiefel Manifolds](https://arxiv.org/abs/2511.02682)
*Jordi-Lluís Figueras,Aron Persson,Lauri Viitasaari*

Main category: stat.AP

TL;DR: 提出了一种适用于Stiefel流形值测量的扩展卡尔曼滤波器的推广方法，在2-球面和4×2正交矩阵空间上的仿真显示其相比原始测量有显著改进


<details>
  <summary>Details</summary>
Motivation: 现有的扩展卡尔曼滤波器在处理Stiefel流形上的测量值时存在局限性，需要专门的方法来处理这类几何约束的测量数据

Method: 推广了扩展卡尔曼滤波器，使其能够处理Stiefel流形值的测量，该方法考虑了流形的几何结构

Result: 在2-球面和4×2正交矩阵空间上的仿真实验表明，该方法相比仅使用原始测量有显著性能提升

Conclusion: 所提出的推广扩展卡尔曼滤波器能够有效处理Stiefel流形值测量，为流形上的状态估计问题提供了有效的解决方案

Abstract: A generalisation of the extended Kalman filter for Stiefel manifold-valued
measurements is presented. We provide simulations on the 2-sphere and the space
of orthogonal 4-by-2 matrices which show significant improvement of the
Extended Kalman Filter compared to only relying on raw measurements.

</details>
