{"id": "2511.19717", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19717", "abs": "https://arxiv.org/abs/2511.19717", "authors": ["Vikram Ramavarapu", "Jo\u00e3o Alfredo Cardoso Lamy", "Mohammad Dindoost", "David A. Bader"], "title": "Large Scale Community-Aware Network Generation", "comment": "22 pages, 10 figures, code made available at https://github.com/illinois-or-research-analytics/reccs", "summary": "Community detection, or network clustering, is used to identify latent community structure in networks. Due to the scarcity of labeled ground truth in real-world networks, evaluating these algorithms poses significant challenges. To address this, researchers use synthetic network generators that produce networks with ground-truth community labels. RECCS is one such algorithm that takes a network and its clustering as input and generates a synthetic network through a modular pipeline. Each generated ground truth cluster preserves key characteristics of the corresponding input cluster, including connectivity, minimum degree, and degree sequence distribution. The output consists of a synthetically generated network, and disjoint ground truth cluster labels for all nodes. In this paper, we present two enhanced versions: RECCS+ and RECCS++. RECCS+ maintains algorithmic fidelity to the original RECCS while introducing parallelization through an orchestrator that coordinates algorithmic components across multiple processes and employs multithreading. RECCS++ builds upon this foundation with additional algorithmic optimizations to achieve further speedup. Our experimental results demonstrate that RECCS+ and RECCS++ achieve speedups of up to 49x and 139x respectively on our benchmark datasets, with RECCS++'s additional performance gains involving a modest accuracy tradeoff. With this newfound performance, RECCS++ can now scale to networks with over 100 million nodes and nearly 2 billion edges.", "AI": {"tldr": "RECCS+\u548cRECCS++\u662fRECCS\u7b97\u6cd5\u7684\u589e\u5f3a\u7248\u672c\uff0c\u901a\u8fc7\u5e76\u884c\u5316\u548c\u7b97\u6cd5\u4f18\u5316\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u5206\u522b\u8fbe\u523049\u500d\u548c139\u500d\u7684\u52a0\u901f\u6bd4\uff0c\u4f7f\u7b97\u6cd5\u80fd\u591f\u6269\u5c55\u5230\u8d85\u8fc71\u4ebf\u8282\u70b9\u548c\u8fd120\u4ebf\u8fb9\u7684\u5927\u89c4\u6a21\u7f51\u7edc\u3002", "motivation": "\u7531\u4e8e\u771f\u5b9e\u7f51\u7edc\u7f3a\u4e4f\u5e26\u6807\u7b7e\u7684\u57fa\u51c6\u4e8b\u5b9e\uff0c\u8bc4\u4f30\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\u5177\u6709\u6311\u6218\u6027\u3002\u9700\u8981\u80fd\u591f\u751f\u6210\u5e26\u57fa\u51c6\u4e8b\u5b9e\u793e\u533a\u6807\u7b7e\u7684\u5408\u6210\u7f51\u7edc\u751f\u6210\u5668\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u7f51\u7edc\u65f6\u6548\u7387\u4e0d\u8db3\u3002", "method": "RECCS+\u5728\u4fdd\u6301\u539f\u59cbRECCS\u7b97\u6cd5\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u534f\u8c03\u5668\u5b9e\u73b0\u591a\u8fdb\u7a0b\u5e76\u884c\u5316\u548c\u591a\u7ebf\u7a0b\u6280\u672f\u3002RECCS++\u5728\u6b64\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u7b97\u6cd5\u4f18\u5316\u4ee5\u5b9e\u73b0\u8fdb\u4e00\u6b65\u7684\u52a0\u901f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cRECCS+\u548cRECCS++\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5206\u522b\u5b9e\u73b0\u4e86\u6700\u9ad849\u500d\u548c139\u500d\u7684\u52a0\u901f\u6bd4\uff0c\u5176\u4e2dRECCS++\u7684\u6027\u80fd\u63d0\u5347\u6d89\u53ca\u9002\u5ea6\u7684\u51c6\u786e\u6027\u6743\u8861\u3002", "conclusion": "\u901a\u8fc7\u6027\u80fd\u63d0\u5347\uff0cRECCS++\u73b0\u5728\u80fd\u591f\u6269\u5c55\u5230\u8d85\u8fc71\u4ebf\u8282\u70b9\u548c\u8fd120\u4ebf\u8fb9\u7684\u5927\u89c4\u6a21\u7f51\u7edc\uff0c\u4e3a\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5408\u6210\u7f51\u7edc\u751f\u6210\u5de5\u5177\u3002"}}
{"id": "2511.20546", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.20546", "abs": "https://arxiv.org/abs/2511.20546", "authors": ["Aatman Vaidya", "Harsh Bhagat", "Seema Nagar", "Amit A. Nanavati"], "title": "Modelling the Spread of Toxicity and Exploring its Mitigation on Online Social Networks", "comment": null, "summary": "Hate speech on online platforms has been credibly linked to multiple instances of real world violence. This calls for an urgent need to understand how toxic content spreads and how it might be mitigated on online social networks, and expectedly has been the topic of extensive research in recent times. Prior work has largely modelled hate through epidemic or spread activation based diffusion models, in which the users are often divided into two categories, hateful or not. In this work, users are treated as transformers of toxicity, based on how they respond to incoming toxicity. Compared with the incoming toxicity, users amplify, attenuate, or replicate (effectively, transform) the toxicity and send it forward. We do a temporal analysis of toxicity on Twitter, Koo and Gab and find that (a) toxicity is not conserved in the network; (b) only a subset of users change behaviour over time; and (c) there is no evidence of homophily among behaviour-changing users. In our model, each user transforms incoming toxicity by applying a \"shift\" to it prior to sending it forward. Based on this, we develop a network model of toxicity spread that incorporates time-varying behaviour of users. We find that the \"shift\" applied by a user is dependent on the input toxicity and the category. Based on this finding, we propose an intervention strategy for toxicity reduction. This is simulated by deploying peace-bots. Through experiments on both real-world and synthetic networks, we demonstrate that peace-bot interventions can reduce toxicity, though their effectiveness depends on network structure and placement strategy.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ec7\u6068\u8a00\u8bba\u4f20\u64ad\u6a21\u578b\uff0c\u5c06\u7528\u6237\u89c6\u4e3a\u6bd2\u6027\u7684\u8f6c\u6362\u8005\u800c\u975e\u7b80\u5355\u7684\u4f20\u64ad\u8005\uff0c\u5e76\u901a\u8fc7\u90e8\u7f72\u548c\u5e73\u673a\u5668\u4eba\u6765\u51cf\u5c11\u7f51\u7edc\u6bd2\u6027\u3002", "motivation": "\u5728\u7ebf\u5e73\u53f0\u4e0a\u7684\u4ec7\u6068\u8a00\u8bba\u4e0e\u73b0\u5b9e\u4e16\u754c\u66b4\u529b\u4e8b\u4ef6\u5bc6\u5207\u76f8\u5173\uff0c\u8feb\u5207\u9700\u8981\u7406\u89e3\u6bd2\u6027\u5185\u5bb9\u5982\u4f55\u4f20\u64ad\u4ee5\u53ca\u5982\u4f55\u5728\u793e\u4ea4\u7f51\u7edc\u4e0a\u7f13\u89e3\u3002\u73b0\u6709\u7814\u7a76\u901a\u5e38\u5c06\u7528\u6237\u7b80\u5355\u5206\u4e3a\u4ec7\u6068\u548c\u975e\u4ec7\u6068\u4e24\u7c7b\uff0c\u7f3a\u4e4f\u5bf9\u7528\u6237\u884c\u4e3a\u52a8\u6001\u53d8\u5316\u7684\u8003\u8651\u3002", "method": "\u5c06\u7528\u6237\u5efa\u6a21\u4e3a\u6bd2\u6027\u7684\u8f6c\u6362\u8005\uff08\u653e\u5927\u3001\u8870\u51cf\u6216\u590d\u5236\u6bd2\u6027\uff09\uff0c\u901a\u8fc7\u65f6\u95f4\u5e8f\u5217\u5206\u6790Twitter\u3001Koo\u548cGab\u5e73\u53f0\u6570\u636e\uff0c\u5f00\u53d1\u5305\u542b\u65f6\u53d8\u7528\u6237\u884c\u4e3a\u7684\u7f51\u7edc\u4f20\u64ad\u6a21\u578b\uff0c\u5e76\u6a21\u62df\u90e8\u7f72\u548c\u5e73\u673a\u5668\u4eba\u8fdb\u884c\u5e72\u9884\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a(a)\u6bd2\u6027\u5728\u7f51\u7edc\u4e2d\u4e0d\u5b88\u6052\uff1b(b)\u53ea\u6709\u90e8\u5206\u7528\u6237\u968f\u65f6\u95f4\u6539\u53d8\u884c\u4e3a\uff1b(c)\u884c\u4e3a\u6539\u53d8\u7528\u6237\u95f4\u4e0d\u5b58\u5728\u540c\u8d28\u6027\u3002\u7528\u6237\u5bf9\u6bd2\u6027\u7684\"\u504f\u79fb\"\u53d6\u51b3\u4e8e\u8f93\u5165\u6bd2\u6027\u548c\u7528\u6237\u7c7b\u522b\u3002\u548c\u5e73\u673a\u5668\u4eba\u5e72\u9884\u80fd\u51cf\u5c11\u6bd2\u6027\uff0c\u4f46\u6548\u679c\u53d6\u51b3\u4e8e\u7f51\u7edc\u7ed3\u6784\u548c\u90e8\u7f72\u7b56\u7565\u3002", "conclusion": "\u7528\u6237\u4f5c\u4e3a\u6bd2\u6027\u8f6c\u6362\u8005\u7684\u6a21\u578b\u80fd\u66f4\u51c6\u786e\u5730\u63cf\u8ff0\u4ec7\u6068\u8a00\u8bba\u4f20\u64ad\uff0c\u57fa\u4e8e\u7528\u6237\u884c\u4e3a\u52a8\u6001\u7684\u5e72\u9884\u7b56\u7565\uff08\u5982\u548c\u5e73\u673a\u5668\u4eba\uff09\u6709\u671b\u6709\u6548\u51cf\u5c11\u7f51\u7edc\u6bd2\u6027\uff0c\u4f46\u9700\u8981\u9488\u5bf9\u5177\u4f53\u7f51\u7edc\u7ed3\u6784\u4f18\u5316\u90e8\u7f72\u3002"}}
{"id": "2511.19469", "categories": ["econ.GN", "econ.EM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.19469", "abs": "https://arxiv.org/abs/2511.19469", "authors": ["Jorge A. Arroyo"], "title": "Big Wins, Small Net Gains: Direct and Spillover Effects of First Industry Entries in Puerto Rico", "comment": null, "summary": "I study how first sizable industry entries reshape local and neighboring labor markets in Puerto Rico. Using over a decade of quarterly municipality--industry data (2014Q1--2025Q1), I identify ``first sizable entries'' as large, persistent jumps in establishments, covered employment, and wage bill, and treat these as shocks to local industry presence at the municipio--industry level. Methodologically, I combine staggered-adoption difference-in-differences estimators that are robust to heterogeneous treatment timing with an imputation-based event-study approach, and I use a doubly robust difference-in-differences framework that explicitly allows for interference through pre-specified exposure mappings on a contiguity graph. The estimates show large and persistent direct gains in covered employment and wage bill in the treated municipality--industry cells over 0--16 quarters. Same-industry neighbors experience sizable short-run gains that reverse over the medium run, while within-municipality cross-industry and neighbor all-industries spillovers are small and imprecisely estimated. Once these spillovers are taken into account and spatially robust inference and sensitivity checks are applied, the net regional 0--16 quarter effect on covered employment is positive but modest in magnitude and estimated with considerable uncertainty. The results imply that first sizable entries generate substantial local gains where they occur, but much smaller and less precisely measured net employment gains for the broader regional economy, highlighting the importance of accounting for spatial spillovers when evaluating place-based policies.", "AI": {"tldr": "\u7814\u7a76\u9996\u6b21\u5927\u89c4\u6a21\u4ea7\u4e1a\u8fdb\u5165\u5982\u4f55\u91cd\u5851\u6ce2\u591a\u9ece\u5404\u672c\u5730\u53ca\u90bb\u8fd1\u52b3\u52a8\u529b\u5e02\u573a\uff0c\u53d1\u73b0\u76f4\u63a5\u5c31\u4e1a\u548c\u5de5\u8d44\u589e\u957f\u663e\u8457\u4f46\u533a\u57df\u51c0\u6548\u5e94\u8f83\u5c0f\uff0c\u5f3a\u8c03\u7a7a\u95f4\u6ea2\u51fa\u6548\u5e94\u5728\u8bc4\u4f30\u5730\u65b9\u653f\u7b56\u65f6\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u63a2\u7a76\u9996\u6b21\u5927\u89c4\u6a21\u4ea7\u4e1a\u8fdb\u5165\u5bf9\u5f53\u5730\u548c\u90bb\u8fd1\u52b3\u52a8\u529b\u5e02\u573a\u7684\u91cd\u5851\u4f5c\u7528\uff0c\u7279\u522b\u5173\u6ce8\u7a7a\u95f4\u6ea2\u51fa\u6548\u5e94\uff0c\u4e3a\u8bc4\u4f30\u5730\u65b9\u4ea7\u4e1a\u653f\u7b56\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e\u3002", "method": "\u4f7f\u75282014Q1-2025Q1\u5b63\u5ea6\u5e02\u653f-\u4ea7\u4e1a\u6570\u636e\uff0c\u7ed3\u5408\u4ea4\u9519\u91c7\u7528DID\u4f30\u8ba1\u5668\u3001\u57fa\u4e8e\u63d2\u8865\u7684\u4e8b\u4ef6\u7814\u7a76\u65b9\u6cd5\u548c\u53cc\u91cd\u7a33\u5065DID\u6846\u67b6\uff0c\u8003\u8651\u90bb\u63a5\u56fe\u4e0a\u7684\u7a7a\u95f4\u5e72\u6270\u3002", "result": "\u53d7\u5904\u7406\u5e02\u653f-\u4ea7\u4e1a\u5355\u5143\u57280-16\u5b63\u5ea6\u5185\u5c31\u4e1a\u548c\u5de5\u8d44\u663e\u8457\u589e\u957f\uff0c\u540c\u884c\u4e1a\u90bb\u8fd1\u5730\u533a\u77ed\u671f\u589e\u957f\u4f46\u4e2d\u671f\u9006\u8f6c\uff0c\u8de8\u884c\u4e1a\u548c\u5168\u884c\u4e1a\u6ea2\u51fa\u6548\u5e94\u5c0f\u4e14\u4e0d\u7cbe\u786e\u3002", "conclusion": "\u9996\u6b21\u5927\u89c4\u6a21\u4ea7\u4e1a\u8fdb\u5165\u4ea7\u751f\u663e\u8457\u7684\u672c\u5730\u6536\u76ca\uff0c\u4f46\u533a\u57df\u51c0\u5c31\u4e1a\u589e\u957f\u8f83\u5c0f\u4e14\u4e0d\u786e\u5b9a\u6027\u9ad8\uff0c\u8bc4\u4f30\u5730\u65b9\u653f\u7b56\u65f6\u5fc5\u987b\u8003\u8651\u7a7a\u95f4\u6ea2\u51fa\u6548\u5e94\u3002"}}
{"id": "2511.19781", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.19781", "abs": "https://arxiv.org/abs/2511.19781", "authors": ["Xiaopeng Zeng", "Erbao Cao", "Xiangqian Yang"], "title": "Dynamic Mechanism Collapse: A Boundary Characterization", "comment": "Working paper, 2025", "summary": "When are dynamics valuable? In Bayesian environments with public signals and no intertemporal commitment, we study a seller who allocates an economically single-shot resource over time. We provide necessary and sufficient conditions under which the optimal dynamic mechanism collapses to a simple terminal design: a single public experiment at date 0 followed by a posterior-dependent static mechanism executed at a deterministic date, with no further disclosure. The key condition is the existence of a global affine shadow value that supports the posterior-based revenue frontier and uniformly bounds all history-dependent revenues. When this condition fails, a collapse statistic pinpoints the dates and public state variables that generate genuine dynamic value. The characterization combines martingale concavification on the belief space with an affine-support duality for concave envelopes.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5728\u8d1d\u53f6\u65af\u73af\u5883\u4e2d\uff0c\u5f53\u5b58\u5728\u516c\u5171\u4fe1\u53f7\u4e14\u65e0\u8de8\u671f\u627f\u8bfa\u65f6\uff0c\u5356\u65b9\u5982\u4f55\u968f\u65f6\u95f4\u5206\u914d\u4e00\u6b21\u6027\u8d44\u6e90\u3002\u7ed9\u51fa\u4e86\u6700\u4f18\u52a8\u6001\u673a\u5236\u9000\u5316\u4e3a\u7b80\u5355\u7ec8\u7aef\u8bbe\u8ba1\u7684\u5145\u8981\u6761\u4ef6\uff1a\u5728\u65e5\u671f0\u8fdb\u884c\u5355\u4e00\u516c\u5171\u5b9e\u9a8c\uff0c\u7136\u540e\u5728\u786e\u5b9a\u65e5\u671f\u6267\u884c\u540e\u9a8c\u4f9d\u8d56\u7684\u9759\u6001\u673a\u5236\uff0c\u65e0\u9700\u8fdb\u4e00\u6b65\u62ab\u9732\u3002", "motivation": "\u7814\u7a76\u5728\u4ec0\u4e48\u6761\u4ef6\u4e0b\u52a8\u6001\u673a\u5236\u5177\u6709\u4ef7\u503c\uff0c\u4ee5\u53ca\u4f55\u65f6\u6700\u4f18\u52a8\u6001\u673a\u5236\u53ef\u4ee5\u7b80\u5316\u4e3a\u7b80\u5355\u7684\u7ec8\u7aef\u8bbe\u8ba1\uff0c\u4ece\u800c\u907f\u514d\u590d\u6742\u7684\u52a8\u6001\u62ab\u9732\u8fc7\u7a0b\u3002", "method": "\u7ed3\u5408\u4fe1\u5ff5\u7a7a\u95f4\u4e0a\u7684\u9785\u51f9\u5316\u4e0e\u51f9\u5305\u7edc\u7684\u4eff\u5c04\u652f\u6491\u5bf9\u5076\uff0c\u901a\u8fc7\u5b58\u5728\u5168\u5c40\u4eff\u5c04\u5f71\u5b50\u4ef7\u503c\u6765\u652f\u6301\u540e\u9a8c\u6536\u76ca\u524d\u6cbf\u5e76\u7edf\u4e00\u7ea6\u675f\u6240\u6709\u5386\u53f2\u4f9d\u8d56\u6536\u76ca\u3002", "result": "\u5f53\u5b58\u5728\u5168\u5c40\u4eff\u5c04\u5f71\u5b50\u4ef7\u503c\u65f6\uff0c\u6700\u4f18\u52a8\u6001\u673a\u5236\u9000\u5316\u4e3a\u7b80\u5355\u7ec8\u7aef\u8bbe\u8ba1\uff1b\u5f53\u8be5\u6761\u4ef6\u4e0d\u6ee1\u8db3\u65f6\uff0c\u5d29\u6e83\u7edf\u8ba1\u91cf\u80fd\u8bc6\u522b\u4ea7\u751f\u771f\u6b63\u52a8\u6001\u4ef7\u503c\u7684\u65e5\u671f\u548c\u516c\u5171\u72b6\u6001\u53d8\u91cf\u3002", "conclusion": "\u901a\u8fc7\u4eff\u5c04\u652f\u6491\u5bf9\u5076\u548c\u9785\u51f9\u5316\u7684\u7ed3\u5408\uff0c\u4e3a\u52a8\u6001\u673a\u5236\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7b80\u6d01\u7684\u5145\u8981\u6761\u4ef6\uff0c\u63ed\u793a\u4e86\u52a8\u6001\u4ef7\u503c\u4ea7\u751f\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2511.19574", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.19574", "abs": "https://arxiv.org/abs/2511.19574", "authors": ["Ruizhe Zhang", "Jooyoung Kong", "Dylan S. Small", "William Bekerman"], "title": "Beyond the ACE Score: Replicable Combinations of Adverse Childhood Experiences That Worsen Depression Risk", "comment": null, "summary": "Adverse childhood experiences (ACEs) are categories of childhood abuse, neglect, and household dysfunction. Screening by a single additive ACE score (e.g., a $\\ge 4$ cutoff) has poor individual-level discrimination. We instead identify replicable combinations of ACEs that elevate adult depression risk. Our data turnover framework enables a single research team to explore, confirm, and replicate within one observational dataset while controlling the family-wise error rate. We integrate isotonic subgroup selection (ISS) to estimate a higher-risk subgroup under a monotonicity assumption -- additional ACE exposure or higher intensity cannot reduce depression risk. We pre-specify a risk threshold $\u03c4$ corresponding to roughly a two-fold increase in the odds of depression relative to the no-ACE baseline. Within data turnover, the prespecified component improves power while maintaining FWER control, as demonstrated in simulations. Guided by EDA, we adopt frequency coding for ACE items, retaining intensity information that reduces false positives relative to binary or score codings. The result is a replicable, pattern-based higher-risk subgroup. On held-out BRFSS 2022, we show that, at the same level of specificity (0.95), using our replicable subgroup as the screening rule increases sensitivity by 26\\% compared with an ACE-score cutoff, yielding concrete triggers that are straightforward to implement and help target scarce clinical screening resources toward truly higher-risk profiles.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u6570\u636e\u8f6e\u6362\u6846\u67b6\uff0c\u8bc6\u522b\u53ef\u590d\u73b0\u7684\u7ae5\u5e74\u4e0d\u826f\u7ecf\u5386\u7ec4\u5408\u6a21\u5f0f\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684ACE\u603b\u5206\u7b5b\u67e5\u65b9\u6cd5\uff0c\u80fd\u66f4\u51c6\u786e\u5730\u8bc6\u522b\u6210\u4eba\u6291\u90c1\u75c7\u9ad8\u98ce\u9669\u4eba\u7fa4\u3002", "motivation": "\u4f20\u7edf\u7684\u7ae5\u5e74\u4e0d\u826f\u7ecf\u5386\u5355\u4e00\u7d2f\u52a0\u8bc4\u5206\u65b9\u6cd5\u5728\u4e2a\u4f53\u5c42\u9762\u5224\u522b\u80fd\u529b\u8f83\u5dee\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7cbe\u786e\u7684\u7b5b\u67e5\u65b9\u6cd5\u6765\u8bc6\u522b\u771f\u6b63\u7684\u9ad8\u98ce\u9669\u4eba\u7fa4\uff0c\u4ee5\u4f18\u5316\u4e34\u5e8a\u7b5b\u67e5\u8d44\u6e90\u914d\u7f6e\u3002", "method": "\u91c7\u7528\u6570\u636e\u8f6e\u6362\u6846\u67b6\u7ed3\u5408\u7b49\u6e17\u5b50\u7ec4\u9009\u62e9\u65b9\u6cd5\uff0c\u5728\u5355\u8c03\u6027\u5047\u8bbe\u4e0b\u8bc6\u522b\u9ad8\u98ce\u9669\u5b50\u7ec4\uff0c\u4f7f\u7528\u9891\u7387\u7f16\u7801\u4fdd\u7559ACE\u5f3a\u5ea6\u4fe1\u606f\uff0c\u63a7\u5236\u5bb6\u5ead\u9519\u8bef\u7387\u3002", "result": "\u5728BRFSS 2022\u6570\u636e\u4e0a\u9a8c\u8bc1\uff0c\u5728\u76f8\u540c\u7279\u5f02\u6027\u6c34\u5e73\u4e0b\uff0c\u76f8\u6bd4ACE\u603b\u5206\u622a\u65ad\u6cd5\uff0c\u65b0\u65b9\u6cd5\u7684\u654f\u611f\u6027\u63d0\u9ad8\u4e8626%\uff0c\u80fd\u66f4\u6709\u6548\u5730\u8bc6\u522b\u6291\u90c1\u75c7\u9ad8\u98ce\u9669\u4eba\u7fa4\u3002", "conclusion": "\u57fa\u4e8e\u6a21\u5f0f\u7684\u53ef\u590d\u73b0\u9ad8\u98ce\u9669\u5b50\u7ec4\u7b5b\u67e5\u65b9\u6cd5\u6bd4\u4f20\u7edfACE\u603b\u5206\u7b5b\u67e5\u66f4\u6709\u6548\uff0c\u63d0\u4f9b\u4e86\u6613\u4e8e\u5b9e\u65bd\u7684\u4e34\u5e8a\u7b5b\u67e5\u89e6\u53d1\u6761\u4ef6\uff0c\u6709\u52a9\u4e8e\u7cbe\u51c6\u5206\u914d\u7a00\u7f3a\u7684\u4e34\u5e8a\u7b5b\u67e5\u8d44\u6e90\u3002"}}
{"id": "2511.19482", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19482", "abs": "https://arxiv.org/abs/2511.19482", "authors": ["Matthew Nyaaba", "Macharious Nabang", "Patrick Kyeremeh", "Ibrahim Nantomah", "Collins Owusu-Fordjour", "Martin Ako", "Bismark Nyaaba Akanzire", "Kassim Korah Nantom", "Cecilia Issaka", "Xiaoming Zhai"], "title": "Human Experts' Evaluation of Generative AI for Contextualizing STEAM Education in the Global South", "comment": null, "summary": "This study investigates how human experts evaluate the capacity of Generative AI (GenAI) to contextualize STEAM education in the Global South, with a focus on Ghana. Using a convergent mixed-methods design, four STEAM specialists assessed GenAI-generated lesson plans created with a customized Culturally Responsive Lesson Planner (CRLP) and compared them to standardized lesson plans from the Ghana National Council for Curriculum and Assessment (NaCCA). Quantitative ratings were based on a validated 25-item Culturally Responsive Pedagogy Rubric measuring bias awareness, cultural representation, contextual relevance, linguistic responsiveness, and teacher agency. Qualitative reflections provided additional insight into how GenAI handles cultural and pedagogical appropriateness.\n  Findings show that GenAI, when paired with the CRLP tool, can support contextualized STEAM instruction by linking abstract curriculum standards to learners' cultural knowledge, community practices, and everyday experiences. Experts rated GenAI-assisted lessons as more culturally grounded and pedagogically responsive than NaCCA plans, integrating Indigenous knowledge, bilingual elements, and locally relevant examples. However, GenAI struggled to represent Ghana's cultural pluralism, often offering surface-level references to language, history, and identity. These weaknesses were most evident in Mathematics and Computing, where cultural nuance was limited. The results highlight the need for continued teacher mediation, community involvement, and culturally attuned refinement of AI outputs. Future work should include classroom trials, expanded expert participation, and model fine-tuning using Indigenous language corpora to strengthen cultural fidelity in Global South contexts.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u751f\u6210\u5f0fAI\u5728\u52a0\u7eb3STEAM\u6559\u80b2\u4e2d\u7684\u6587\u5316\u60c5\u5883\u5316\u80fd\u529b\uff0c\u53d1\u73b0AI\u7ed3\u5408\u5b9a\u5236\u5de5\u5177\u80fd\u521b\u9020\u6bd4\u6807\u51c6\u6559\u6848\u66f4\u5177\u6587\u5316\u54cd\u5e94\u6027\u7684\u8bfe\u7a0b\uff0c\u4f46\u5728\u5904\u7406\u6587\u5316\u591a\u5143\u6027\u65b9\u9762\u4ecd\u6709\u5c40\u9650\u3002", "motivation": "\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5728\u5168\u7403\u5316\u5357\u65b9STEAM\u6559\u80b2\u4e2d\u7684\u6587\u5316\u60c5\u5883\u5316\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u52a0\u7eb3\u8fd9\u6837\u7684\u591a\u5143\u6587\u5316\u73af\u5883\u4e2d\u5982\u4f55\u5c06\u62bd\u8c61\u8bfe\u7a0b\u6807\u51c6\u4e0e\u5b66\u4e60\u8005\u6587\u5316\u77e5\u8bc6\u76f8\u7ed3\u5408\u3002", "method": "\u91c7\u7528\u6536\u655b\u6df7\u5408\u65b9\u6cd5\u8bbe\u8ba1\uff0c\u56db\u4f4dSTEAM\u4e13\u5bb6\u4f7f\u7528\u9a8c\u8bc1\u8fc7\u768425\u9879\u6587\u5316\u54cd\u5e94\u6559\u5b66\u6cd5\u8bc4\u5206\u8868\uff0c\u8bc4\u4f30AI\u751f\u6210\u7684\u8bfe\u7a0b\u8ba1\u5212\u4e0e\u52a0\u7eb3\u56fd\u5bb6\u8bfe\u7a0b\u8bc4\u4f30\u59d4\u5458\u4f1a\u6807\u51c6\u6559\u6848\u7684\u5bf9\u6bd4\u3002", "result": "AI\u8f85\u52a9\u8bfe\u7a0b\u5728\u6587\u5316\u57fa\u7840\u548c\u6559\u5b66\u54cd\u5e94\u6027\u65b9\u9762\u4f18\u4e8e\u6807\u51c6\u6559\u6848\uff0c\u80fd\u6574\u5408\u672c\u571f\u77e5\u8bc6\u3001\u53cc\u8bed\u5143\u7d20\u548c\u672c\u5730\u76f8\u5173\u6848\u4f8b\uff0c\u4f46\u5728\u6570\u5b66\u548c\u8ba1\u7b97\u9886\u57df\u6587\u5316\u7ec6\u5fae\u5dee\u522b\u6709\u9650\uff0c\u4e14\u96be\u4ee5\u5145\u5206\u4ee3\u8868\u52a0\u7eb3\u6587\u5316\u591a\u5143\u6027\u3002", "conclusion": "AI\u5728\u6559\u80b2\u60c5\u5883\u5316\u4e2d\u5177\u6709\u6f5c\u529b\u4f46\u9700\u8981\u6559\u5e08\u8c03\u89e3\u3001\u793e\u533a\u53c2\u4e0e\u548c\u6587\u5316\u8c03\u9002\uff0c\u672a\u6765\u9700\u8fdb\u884c\u8bfe\u5802\u8bd5\u9a8c\u3001\u6269\u5927\u4e13\u5bb6\u53c2\u4e0e\u548c\u4f7f\u7528\u672c\u571f\u8bed\u8a00\u8bed\u6599\u5e93\u8fdb\u884c\u6a21\u578b\u5fae\u8c03\u3002"}}
{"id": "2511.19449", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19449", "abs": "https://arxiv.org/abs/2511.19449", "authors": ["Adeline Gu\u00e9ret"], "title": "Power sector models featuring individual BEV profiles: Assessing the time-accuracy trade-off", "comment": null, "summary": "Electrifying passenger cars will impact future power systems. To understand the challenges and opportunities that arise, it is necessary to reflect \"sector coupling\" in the modeling space. This paper focuses on a specific modeling approach that includes dozens of individual BEV profiles rather than one aggregated BEV profile. Although including additional BEV profiles increases model complexity and runtime, it avoids losing information in the aggregation process. We investigate how many profiles are needed to ensure the accuracy of the results and the extent to which fewer profiles can be traded for runtime efficiency gains. We also examine whether selecting specific profiles influences optimal results. We demonstrate that including too few profiles may result in distorted optimal solutions. However, beyond a certain threshold, adding more profiles does not significantly enhance the robustness of the results. More generally, for fleets of 5 to 20 million BEVs, we derive a rule of thumb consisting in including enough profiles such that each profile represents 200,000 to 250,000 vehicles, ensuring accurate results without excessive runtime.", "AI": {"tldr": "\u7814\u7a76\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u5bf9\u7535\u529b\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4f7f\u7528\u591a\u4e2a\u72ec\u7acbBEV\u6863\u6848\u6bd4\u5355\u4e00\u805a\u5408\u6863\u6848\u66f4\u51c6\u786e\uff0c\u4f46\u9700\u8981\u5e73\u8861\u6863\u6848\u6570\u91cf\u4e0e\u8ba1\u7b97\u6548\u7387\u3002\u5efa\u8bae\u6bcf20-25\u4e07\u8f86\u8f66\u4f7f\u7528\u4e00\u4e2a\u6863\u6848\u4f5c\u4e3a\u7ecf\u9a8c\u6cd5\u5219\u3002", "motivation": "\u7406\u89e3\u7535\u52a8\u6c7d\u8f66\u666e\u53ca\u5bf9\u7535\u529b\u7cfb\u7edf\u7684\u6311\u6218\u548c\u673a\u9047\uff0c\u9700\u8981\u51c6\u786e\u53cd\u6620\"\u90e8\u95e8\u8026\u5408\"\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u907f\u514d\u805a\u5408\u8fc7\u7a0b\u4e2d\u4fe1\u606f\u4e22\u5931\u3002", "method": "\u91c7\u7528\u5305\u542b\u591a\u4e2a\u72ec\u7acbBEV\u6863\u6848\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u7814\u7a76\u4e0d\u540c\u6863\u6848\u6570\u91cf\u5bf9\u7ed3\u679c\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7684\u5f71\u54cd\uff0c\u5e76\u5206\u6790\u6863\u6848\u9009\u62e9\u5bf9\u6700\u4f18\u89e3\u7684\u5f71\u54cd\u3002", "result": "\u8fc7\u5c11\u7684\u6863\u6848\u4f1a\u5bfc\u81f4\u6700\u4f18\u89e3\u5931\u771f\uff0c\u4f46\u8d85\u8fc7\u4e00\u5b9a\u9608\u503c\u540e\u589e\u52a0\u6863\u6848\u4e0d\u4f1a\u663e\u8457\u63d0\u5347\u7ed3\u679c\u7a33\u5065\u6027\u3002\u5bf9\u4e8e500\u4e07\u81f32000\u4e07\u8f86BEV\u8f66\u961f\uff0c\u5efa\u8bae\u6bcf20-25\u4e07\u8f86\u8f66\u4f7f\u7528\u4e00\u4e2a\u6863\u6848\u3002", "conclusion": "\u5728BEV\u5efa\u6a21\u4e2d\u9700\u8981\u5e73\u8861\u6863\u6848\u6570\u91cf\u4e0e\u8ba1\u7b97\u6548\u7387\uff0c\u91c7\u7528\u9002\u5f53\u7684\u6863\u6848\u6570\u91cf\u53ef\u4ee5\u786e\u4fdd\u51c6\u786e\u7ed3\u679c\u800c\u4e0d\u4ea7\u751f\u8fc7\u591a\u8ba1\u7b97\u8d1f\u62c5\u3002"}}
{"id": "2511.19528", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19528", "abs": "https://arxiv.org/abs/2511.19528", "authors": ["Rushuai Yang", "Zhiyuan Feng", "Tianxiang Zhang", "Kaixin Wang", "Chuheng Zhang", "Li Zhao", "Xiu Su", "Yi Chen", "Jiang Bian"], "title": "Discover, Learn, and Reinforce: Scaling Vision-Language-Action Pretraining with Diverse RL-Generated Trajectories", "comment": null, "summary": "Scaling vision-language-action (VLA) model pre-training requires large volumes of diverse, high-quality manipulation trajectories. Most current data is obtained via human teleoperation, which is expensive and difficult to scale. Reinforcement learning (RL) methods learn useful skills through autonomous exploration, making them a viable approach for generating data. However, standard RL training collapses to a narrow execution pattern, limiting its utility for large-scale pre-training. We propose Discover, Lea rn and Reinforce (DLR), an information-theoretic pattern discovery framework that generates multiple distinct, high-success behavioral patterns for VLA pretraining. Empirically, DLR generates a markedly more diverse trajectory corpus on LIBERO. Specifically, it learns multiple distinct, high-success strategies for the same task where standard RL discovers only one, and hence it covers substantially broader regions of the state-action space. When adapted to unseen downstream task suites, VLA models pretrained on our diverse RL data surpass counterparts trained on equal-sized standard RL datasets. Moreover, DLR exhibits positive data-scaling behavior that single-pattern RL lacks. These results position multi-pattern RL as a practical, scalable data engine for embodied foundation models.", "AI": {"tldr": "\u63d0\u51fa\u4e86DLR\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u606f\u8bba\u6a21\u5f0f\u53d1\u73b0\u751f\u6210\u591a\u79cd\u4e0d\u540c\u7684\u9ad8\u6210\u529f\u7387\u884c\u4e3a\u6a21\u5f0f\uff0c\u4e3a\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u9884\u8bad\u7ec3\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u6570\u636e\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u9884\u8bad\u7ec3\u9700\u8981\u5927\u91cf\u591a\u6837\u5316\u3001\u9ad8\u8d28\u91cf\u7684\u64cd\u4f5c\u8f68\u8ff9\u6570\u636e\uff0c\u4f46\u4eba\u7c7b\u8fdc\u7a0b\u64cd\u4f5c\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55\u3002\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u80fd\u901a\u8fc7\u81ea\u4e3b\u63a2\u7d22\u5b66\u4e60\u6709\u7528\u6280\u80fd\uff0c\u4f46\u6807\u51c6RL\u8bad\u7ec3\u4f1a\u6536\u655b\u5230\u5355\u4e00\u6267\u884c\u6a21\u5f0f\uff0c\u9650\u5236\u4e86\u5176\u5728\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "DLR\uff08\u53d1\u73b0\u3001\u5b66\u4e60\u548c\u5f3a\u5316\uff09\u662f\u4e00\u4e2a\u4fe1\u606f\u8bba\u6a21\u5f0f\u53d1\u73b0\u6846\u67b6\uff0c\u80fd\u591f\u751f\u6210\u591a\u79cd\u4e0d\u540c\u7684\u9ad8\u6210\u529f\u7387\u884c\u4e3a\u6a21\u5f0f\u3002\u8be5\u6846\u67b6\u5728LIBERO\u57fa\u51c6\u4e0a\u751f\u6210\u660e\u663e\u66f4\u591a\u6837\u5316\u7684\u8f68\u8ff9\u8bed\u6599\u5e93\u3002", "result": "DLR\u4e3a\u540c\u4e00\u4efb\u52a1\u5b66\u4e60\u591a\u79cd\u4e0d\u540c\u7684\u9ad8\u6210\u529f\u7387\u7b56\u7565\uff0c\u800c\u6807\u51c6RL\u53ea\u53d1\u73b0\u4e00\u79cd\u7b56\u7565\uff0c\u56e0\u6b64\u8986\u76d6\u4e86\u66f4\u5e7f\u6cdb\u7684\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u3002\u5728\u672a\u89c1\u8fc7\u7684\u4e0b\u6e38\u4efb\u52a1\u5957\u4ef6\u4e0a\uff0c\u4f7f\u7528DLR\u591a\u6837\u5316RL\u6570\u636e\u9884\u8bad\u7ec3\u7684VLA\u6a21\u578b\u4f18\u4e8e\u4f7f\u7528\u540c\u7b49\u89c4\u6a21\u6807\u51c6RL\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\u3002", "conclusion": "DLR\u5c55\u73b0\u51fa\u5355\u4e00\u6a21\u5f0fRL\u6240\u7f3a\u4e4f\u7684\u6b63\u5411\u6570\u636e\u6269\u5c55\u884c\u4e3a\uff0c\u5c06\u591a\u6a21\u5f0fRL\u5b9a\u4f4d\u4e3a\u5177\u8eab\u57fa\u7840\u6a21\u578b\u7684\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u6570\u636e\u5f15\u64ce\u3002"}}
{"id": "2511.19791", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.19791", "abs": "https://arxiv.org/abs/2511.19791", "authors": ["Sen Zhang", "Lingjun Xiong", "Yipie Liu", "Brian L. Mark", "Lei Yang", "Zebo Yang", "Weiwen Jiang"], "title": "An End-to-End Distributed Quantum Circuit Simulator", "comment": null, "summary": "Quantum computing has made substantial progress in recent years; however, its scalability remains constrained on a monolithic quantum processing unit (QPU). Distributed quantum computing (DQC) offers a pathway by coordinating multiple QPUs to execute large-scale circuits. Yet, DQC still faces practical barriers, as its realization depends on advances in hardware-level components such as quantum transducers and high-fidelity entanglement-distribution modules. While these technologies continue to improve, mature DQC platforms remain unavailable. In the meantime, researchers need to assess the benefits of DQC and evaluate emerging DQC designs, but the software ecosystem lacks a circuit-level simulator that models heterogeneous backends, noisy connections, and distributed execution. To fill this gap, this paper proposes SimDisQ, the first end-to-end circuit-level DQC simulator, composed of a set of novel DQC-oriented automated simulation toolkits and communication noise models that can interoperate with existing toolkits in mainstream quantum software ecosystems. Leveraging circuit-level simulation capabilities, SimDisQ enables quantitative exploration of architectural design trade-offs, communication fidelity constraints, and new circuit optimization challenges introduced by DQC, providing a foundation for future research in this promising direction. Benchmarking experiments using SimDisQ respond to a couple of open questions in the community; for example, noisy simulation of superconducting and trapped-ion qubits, with a reasonable entanglement-distribution fidelity, reveal that heterogeneous QPUs can indeed yield higher execution fidelity.", "AI": {"tldr": "SimDisQ\u662f\u9996\u4e2a\u7aef\u5230\u7aef\u7684\u7535\u8def\u7ea7\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u6a21\u62df\u5668\uff0c\u586b\u8865\u4e86\u91cf\u5b50\u8f6f\u4ef6\u751f\u6001\u4e2d\u7f3a\u4e4f\u80fd\u591f\u6a21\u62df\u5f02\u6784\u540e\u7aef\u3001\u566a\u58f0\u8fde\u63a5\u548c\u5206\u5e03\u5f0f\u6267\u884c\u7684\u6a21\u62df\u5668\u7684\u7a7a\u767d\u3002", "motivation": "\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\uff08DQC\uff09\u662f\u6269\u5c55\u91cf\u5b50\u8ba1\u7b97\u89c4\u6a21\u7684\u91cd\u8981\u9014\u5f84\uff0c\u4f46\u76ee\u524d\u6210\u719f\u7684DQC\u5e73\u53f0\u5c1a\u4e0d\u53ef\u7528\uff0c\u7814\u7a76\u4eba\u5458\u9700\u8981\u8bc4\u4f30DQC\u7684\u4f18\u52bf\u548c\u65b0\u5174\u8bbe\u8ba1\uff0c\u4f46\u73b0\u6709\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u7f3a\u4e4f\u80fd\u591f\u6a21\u62df\u5f02\u6784\u540e\u7aef\u3001\u566a\u58f0\u8fde\u63a5\u548c\u5206\u5e03\u5f0f\u6267\u884c\u7684\u7535\u8def\u7ea7\u6a21\u62df\u5668\u3002", "method": "\u63d0\u51faSimDisQ\u6a21\u62df\u5668\uff0c\u5305\u542b\u4e00\u5957\u65b0\u9896\u7684DQC\u5bfc\u5411\u81ea\u52a8\u5316\u6a21\u62df\u5de5\u5177\u5305\u548c\u901a\u4fe1\u566a\u58f0\u6a21\u578b\uff0c\u80fd\u591f\u4e0e\u4e3b\u6d41\u91cf\u5b50\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u73b0\u6709\u5de5\u5177\u5305\u4e92\u64cd\u4f5c\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u9a8c\u56de\u7b54\u4e86\u793e\u533a\u4e2d\u7684\u51e0\u4e2a\u5f00\u653e\u6027\u95ee\u9898\uff0c\u4f8b\u5982\u5728\u5408\u7406\u7684\u7ea0\u7f20\u5206\u5e03\u4fdd\u771f\u5ea6\u4e0b\uff0c\u8d85\u5bfc\u548c\u56da\u7981\u79bb\u5b50\u91cf\u5b50\u4f4d\u7684\u566a\u58f0\u6a21\u62df\u663e\u793a\u5f02\u6784\u91cf\u5b50\u5904\u7406\u5355\u5143\u786e\u5b9e\u80fd\u591f\u4ea7\u751f\u66f4\u9ad8\u7684\u6267\u884c\u4fdd\u771f\u5ea6\u3002", "conclusion": "SimDisQ\u4e3a\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u63d0\u4f9b\u4e86\u5b9a\u91cf\u63a2\u7d22\u67b6\u6784\u8bbe\u8ba1\u6743\u8861\u3001\u901a\u4fe1\u4fdd\u771f\u5ea6\u7ea6\u675f\u4ee5\u53caDQC\u5f15\u5165\u7684\u65b0\u7535\u8def\u4f18\u5316\u6311\u6218\u7684\u57fa\u7840\uff0c\u4e3a\u8fd9\u4e00\u6709\u524d\u666f\u65b9\u5411\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.19722", "categories": ["econ.EM", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19722", "abs": "https://arxiv.org/abs/2511.19722", "authors": ["Ilya O. Ryzhov", "John Gunnar Carlsson", "Yinchu Zhu"], "title": "Individual and group fairness in geographical partitioning", "comment": null, "summary": "Socioeconomic segregation often arises in school districting and other contexts, causing some groups to be over- or under-represented within a particular district. This phenomenon is closely linked with disparities in opportunities and outcomes. We formulate a new class of geographical partitioning problems in which the population is heterogeneous, and it is necessary to ensure fair representation for each group at each facility. We prove that the optimal solution is a novel generalization of the additively weighted Voronoi diagram, and we propose a simple and efficient algorithm to compute it, thus resolving an open question dating back to Dvoretzky et al. (1951). The efficacy and potential for practical insight of the approach are demonstrated in a realistic case study involving seven demographic groups and $78$ district offices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5730\u7406\u5206\u533a\u95ee\u9898\uff0c\u786e\u4fdd\u4e0d\u540c\u4eba\u53e3\u7fa4\u4f53\u5728\u6bcf\u4e2a\u8bbe\u65bd\u4e2d\u90fd\u80fd\u83b7\u5f97\u516c\u5e73\u4ee3\u8868\uff0c\u89e3\u51b3\u4e86Dvoretzky\u7b49\u4eba1951\u5e74\u63d0\u51fa\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002", "motivation": "\u793e\u4f1a\u7ecf\u6d4e\u9694\u79bb\u5728\u5b66\u6821\u5206\u533a\u7b49\u573a\u666f\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u5bfc\u81f4\u67d0\u4e9b\u7fa4\u4f53\u5728\u67d0\u4e9b\u533a\u57df\u88ab\u8fc7\u5ea6\u6216\u4e0d\u8db3\u4ee3\u8868\uff0c\u8fd9\u4e0e\u673a\u4f1a\u548c\u7ed3\u679c\u7684\u4e0d\u5e73\u7b49\u5bc6\u5207\u76f8\u5173\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u5730\u7406\u5206\u533a\u95ee\u9898\uff0c\u8bc1\u660e\u6700\u4f18\u89e3\u662f\u52a0\u6027\u52a0\u6743Voronoi\u56fe\u7684\u65b0\u63a8\u5e7f\uff0c\u5e76\u63d0\u51fa\u7b80\u5355\u9ad8\u6548\u7684\u7b97\u6cd5\u6765\u8ba1\u7b97\u8be5\u89e3\u3002", "result": "\u5728\u5305\u542b7\u4e2a\u4eba\u53e3\u7fa4\u4f53\u548c78\u4e2a\u533a\u57df\u529e\u516c\u5ba4\u7684\u73b0\u5b9e\u6848\u4f8b\u7814\u7a76\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u9645\u6d1e\u5bdf\u6f5c\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u957f\u671f\u5b58\u5728\u7684\u5f00\u653e\u6027\u95ee\u9898\uff0c\u4e3a\u516c\u5e73\u5730\u7406\u5206\u533a\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u7b97\u6cd5\u3002"}}
{"id": "2511.19577", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.19577", "abs": "https://arxiv.org/abs/2511.19577", "authors": ["Abhay Goyal", "Navin Kumar", "Kimberly DiMeola", "Rafael Trujillo", "Soorya Ram Shimgekar", "Christian Poellabauer", "Pi Zonooz", "Ermonda Gjoni-Markaj", "Declan Barry", "Lynn Madden"], "title": "Using Wearable Devices to Improve Chronic PainTreatment among Patients with Opioid Use Disorder", "comment": null, "summary": "Chronic pain (CP) and opioid use disorder (OUD) are common and interrelated chronic medical conditions. Currently, there is a paucity of evidence-based integrated treatments for CP and OUD among individuals receiving medication for opioid use disorder (MOUD). Wearable devices have the potential to monitor complex patient information and inform treatment development for persons with OUD and CP, including pain variability (e.g., exacerbations of pain or pain spikes) and clinical correlates (e.g., perceived stress). However, the application of large language models (LLMs) with wearable data for understanding pain spikes, remains unexplored. Consequently, the aim of this pilot study was to examine the clinical correlates of pain spikes using a range of AI approaches. We found that machine learning models achieved relatively high accuracy (>0.7) in predicting pain spikes, while LLMs were limited in providing insights on pain spikes. Real-time monitoring through wearable devices, combined with advanced AI models, could facilitate early detection of pain spikes and support personalized interventions that may help mitigate the risk of opioid relapse, improve adherence to MOUD, and enhance the integration of CP and OUD care. Given overall limited LLM performance, these findings highlight the need to develop LLMs which can provide actionable insights in the OUD/CP context.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u4f7f\u7528\u53ef\u7a7f\u6234\u8bbe\u5907\u548cAI\u65b9\u6cd5\u9884\u6d4b\u6162\u6027\u75bc\u75db\u548c\u9e26\u7247\u4f7f\u7528\u969c\u788d\u60a3\u8005\u7684\u75bc\u75db\u5cf0\u503c\uff0c\u53d1\u73b0\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u7387\u8f83\u9ad8\uff0c\u4f46\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u9886\u57df\u7684\u5e94\u7528\u6548\u679c\u6709\u9650\u3002", "motivation": "\u6162\u6027\u75bc\u75db\u548c\u9e26\u7247\u4f7f\u7528\u969c\u788d\u662f\u76f8\u4e92\u5173\u8054\u7684\u5e38\u89c1\u6162\u6027\u75be\u75c5\uff0c\u76ee\u524d\u7f3a\u4e4f\u9488\u5bf9\u8fd9\u4e24\u79cd\u75be\u75c5\u7684\u6574\u5408\u6cbb\u7597\u65b9\u6848\u3002\u53ef\u7a7f\u6234\u8bbe\u5907\u6709\u6f5c\u529b\u76d1\u6d4b\u590d\u6742\u60a3\u8005\u4fe1\u606f\uff0c\u4f46\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u75bc\u75db\u5cf0\u503c\u5206\u6790\u4e2d\u7684\u5e94\u7528\u5c1a\u672a\u88ab\u63a2\u7d22\u3002", "method": "\u91c7\u7528\u8bd5\u70b9\u7814\u7a76\u65b9\u6cd5\uff0c\u4f7f\u7528\u53ef\u7a7f\u6234\u8bbe\u5907\u6536\u96c6\u6570\u636e\uff0c\u5e76\u5e94\u7528\u591a\u79cdAI\u65b9\u6cd5\uff08\u5305\u62ec\u673a\u5668\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u5206\u6790\u75bc\u75db\u5cf0\u503c\u7684\u4e34\u5e8a\u76f8\u5173\u6027\u3002", "result": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9884\u6d4b\u75bc\u75db\u5cf0\u503c\u65b9\u9762\u53d6\u5f97\u4e86\u76f8\u5bf9\u8f83\u9ad8\u7684\u51c6\u786e\u7387\uff08>0.7\uff09\uff0c\u4f46\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63d0\u4f9b\u75bc\u75db\u5cf0\u503c\u89c1\u89e3\u65b9\u9762\u8868\u73b0\u6709\u9650\u3002", "conclusion": "\u53ef\u7a7f\u6234\u8bbe\u5907\u7684\u5b9e\u65f6\u76d1\u6d4b\u7ed3\u5408\u5148\u8fdbAI\u6a21\u578b\u53ef\u4ee5\u4fc3\u8fdb\u75bc\u75db\u5cf0\u503c\u7684\u65e9\u671f\u68c0\u6d4b\uff0c\u652f\u6301\u4e2a\u6027\u5316\u5e72\u9884\u3002\u9274\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6574\u4f53\u8868\u73b0\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u6b64\u80cc\u666f\u4e0b\u63d0\u4f9b\u53ef\u64cd\u4f5c\u89c1\u89e3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2511.19570", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.19570", "abs": "https://arxiv.org/abs/2511.19570", "authors": ["Sumit Agarwal", "H. Luke Shaefer", "Samiul Jubaed", "William Schneider", "Eric Finegood", "Mona Hanna"], "title": "Cash Transfers in the Perinatal Period and Child Welfare System Involvement Among Infants: Evidence from the Rx Kids Program in Flint, Michigan", "comment": null, "summary": "Infants are most vulnerable to child maltreatment, which may be due in part to economic instability during the perinatal period. In 2024, Rx Kids was launched in Flint, Michigan, achieving near 100% aggregate take up and providing every expectant mother with unconditional cash transfers during pregnancy and infancy. Synthetic difference-in-differences was used to compare changes in allegations of maltreatment within the first six months of life in Flint before and after implementation of Rx Kids relative to the corresponding change in control cities without the program. In the three years prior to the implementation of Rx Kids, the proportion of infants with a maltreatment allegation within the first six months of life was 21.7% in Flint and 19.5% among control cities. After implementation of Rx Kids in 2024, the maltreatment allegation rate dropped to 15.5% in Flint, falling below the maltreatment allegation rate of 20.6% among the control cities. Rx Kids was associated with a statistically significant 7.0 percentage-point decrease in the maltreatment allegation rate (p = 0.021), corresponding to a 32% decrease relative to the pre-intervention period. There was a decrease in the rate of neglect-related, non-neglect-related, and substantiated allegations; these were directionally consistent with the primary outcome but not statistically significant. Results were robust to alternative model specifications. The Rx Kids prenatal and infant cash prescription program led to a significant reduction in allegations of maltreatment among infants. These findings provide important evidence about the role of economic stability in preventing child welfare system involvement.", "AI": {"tldr": "\u5bc6\u6b47\u6839\u5dde\u5f17\u6797\u7279\u5e02\u5b9e\u65bd\u7684Rx Kids\u65e0\u6761\u4ef6\u73b0\u91d1\u8f6c\u79fb\u8ba1\u5212\u663e\u8457\u964d\u4f4e\u4e86\u5a74\u513f\u8650\u5f85\u6307\u63a7\u7387\uff0c\u4e0e\u5bf9\u7167\u7ec4\u76f8\u6bd4\u51cf\u5c11\u4e867\u4e2a\u767e\u5206\u70b9\uff0832%\u76f8\u5bf9\u51cf\u5c11\uff09\u3002", "motivation": "\u5a74\u513f\u662f\u513f\u7ae5\u8650\u5f85\u6700\u8106\u5f31\u7684\u7fa4\u4f53\uff0c\u8fd9\u53ef\u80fd\u90e8\u5206\u4e0e\u56f4\u4ea7\u671f\u7ecf\u6d4e\u4e0d\u7a33\u5b9a\u6709\u5173\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u65e0\u6761\u4ef6\u73b0\u91d1\u8f6c\u79fb\u5bf9\u9884\u9632\u513f\u7ae5\u8650\u5f85\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u5408\u6210\u53cc\u91cd\u5dee\u5206\u6cd5\uff0c\u6bd4\u8f83\u5f17\u6797\u7279\u5e02\u5728Rx Kids\u8ba1\u5212\u5b9e\u65bd\u524d\u540e6\u4e2a\u6708\u5185\u5a74\u513f\u8650\u5f85\u6307\u63a7\u7387\u7684\u53d8\u5316\uff0c\u5e76\u4e0e\u65e0\u8be5\u8ba1\u5212\u7684\u5bf9\u7167\u57ce\u5e02\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "Rx Kids\u5b9e\u65bd\u540e\uff0c\u5f17\u6797\u7279\u5e02\u5a74\u513f\u8650\u5f85\u6307\u63a7\u7387\u4ece21.7%\u964d\u81f315.5%\uff0c\u800c\u5bf9\u7167\u7ec4\u4ece19.5%\u5347\u81f320.6%\u3002\u8be5\u8ba1\u5212\u4e0e7.0\u4e2a\u767e\u5206\u70b9\u7684\u663e\u8457\u51cf\u5c11\u76f8\u5173\uff08p=0.021\uff09\uff0c\u76f8\u5f53\u4e8e\u5e72\u9884\u524d\u6c34\u5e73\u768432%\u51cf\u5c11\u3002", "conclusion": "Rx Kids\u4ea7\u524d\u548c\u5a74\u513f\u73b0\u91d1\u5904\u65b9\u8ba1\u5212\u663e\u8457\u51cf\u5c11\u4e86\u5a74\u513f\u8650\u5f85\u6307\u63a7\uff0c\u4e3a\u7ecf\u6d4e\u7a33\u5b9a\u5728\u9884\u9632\u513f\u7ae5\u798f\u5229\u7cfb\u7edf\u4ecb\u5165\u4e2d\u7684\u4f5c\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u8bc1\u636e\u3002"}}
{"id": "2511.19828", "categories": ["econ.TH", "cs.GT", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2511.19828", "abs": "https://arxiv.org/abs/2511.19828", "authors": ["Nikos Dimou", "Alex McAvoy"], "title": "Expectation-enforcing strategies for repeated games", "comment": "42 pages; comments welcome", "summary": "Originating in evolutionary game theory, the class of \"zero-determinant\" strategies enables a player to unilaterally enforce linear payoff relationships in simple repeated games. An upshot of this kind of payoff constraint is that it can shape the incentives for the opponent in a predetermined way. An example is when a player ensures that the agents get equal payoffs. While extensively studied in infinite-horizon games, extensions to discounted games, nonlinear payoff relationships, richer strategic environments, and behaviors with long memory remain incompletely understood. In this paper, we provide necessary and sufficient conditions for a player to enforce arbitrary payoff relationships (linear or nonlinear), in expectation, in discounted games. These conditions characterize precisely which payoff relationships are enforceable using strategies of arbitrary complexity. Our main result establishes that any such enforceable relationship can actually be implemented using a simple two-point reactive learning strategy, which conditions on the opponent's most recent action and the player's own previous mixed action, using information from only one round into the past. For additive payoff constraints, we show that enforcement is possible using even simpler (reactive) strategies that depend solely on the opponent's last move. In other words, this tractable class is universal within expectation-enforcing strategies. As examples, we apply these results to characterize extortionate, generous, equalizer, and fair strategies in the iterated prisoner's dilemma, asymmetric donation game, nonlinear donation game, and the hawk-dove game, identifying precisely when each class of strategy is enforceable and with what minimum discount factor.", "AI": {"tldr": "\u672c\u6587\u4e3a\u96f6\u884c\u5217\u5f0f\u7b56\u7565\u7406\u8bba\u63d0\u4f9b\u4e86\u901a\u7528\u6846\u67b6\uff0c\u5728\u6298\u6263\u91cd\u590d\u535a\u5f08\u4e2d\u5efa\u7acb\u4e86\u4efb\u610f\u7ebf\u6027\u6216\u975e\u7ebf\u6027\u6536\u76ca\u5173\u7cfb\u7684\u5f3a\u5236\u6267\u884c\u6761\u4ef6\uff0c\u5e76\u8bc1\u660e\u7b80\u5355\u4e24\u70b9\u53cd\u5e94\u5f0f\u5b66\u4e60\u7b56\u7565\u5373\u53ef\u5b9e\u73b0\u6240\u6709\u53ef\u6267\u884c\u5173\u7cfb\u3002", "motivation": "\u867d\u7136\u96f6\u884c\u5217\u5f0f\u7b56\u7565\u5728\u65e0\u9650\u671f\u535a\u5f08\u4e2d\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5728\u6298\u6263\u535a\u5f08\u3001\u975e\u7ebf\u6027\u6536\u76ca\u5173\u7cfb\u3001\u590d\u6742\u6218\u7565\u73af\u5883\u548c\u957f\u8bb0\u5fc6\u884c\u4e3a\u65b9\u9762\u7684\u6269\u5c55\u4ecd\u4e0d\u5b8c\u5584\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5efa\u7acb\u4e86\u6298\u6263\u535a\u5f08\u4e2d\u4efb\u610f\u6536\u76ca\u5173\u7cfb\u5f3a\u5236\u6267\u884c\u7684\u5fc5\u8981\u548c\u5145\u5206\u6761\u4ef6\uff0c\u8bc1\u660e\u6240\u6709\u53ef\u6267\u884c\u5173\u7cfb\u90fd\u80fd\u901a\u8fc7\u7b80\u5355\u7684\u4e24\u70b9\u53cd\u5e94\u5f0f\u5b66\u4e60\u7b56\u7565\u5b9e\u73b0\uff0c\u8be5\u7b56\u7565\u4ec5\u4f9d\u8d56\u5bf9\u624b\u6700\u8fd1\u884c\u52a8\u548c\u73a9\u5bb6\u81ea\u8eab\u5148\u524d\u6df7\u5408\u884c\u52a8\u3002", "result": "\u786e\u5b9a\u4e86\u53ef\u6267\u884c\u6536\u76ca\u5173\u7cfb\u7684\u7cbe\u786e\u7279\u5f81\uff0c\u8bc1\u660e\u4e86\u7b80\u5355\u53cd\u5e94\u5f0f\u7b56\u7565\u7684\u901a\u7528\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u535a\u5f08\u6a21\u578b\u4e2d\u5177\u4f53\u5206\u6790\u4e86\u6572\u8bc8\u3001\u6177\u6168\u3001\u5747\u8861\u548c\u516c\u5e73\u7b56\u7565\u7684\u53ef\u6267\u884c\u6761\u4ef6\u3002", "conclusion": "\u672c\u6587\u4e3a\u6298\u6263\u91cd\u590d\u535a\u5f08\u4e2d\u7684\u6536\u76ca\u5173\u7cfb\u5f3a\u5236\u6267\u884c\u63d0\u4f9b\u4e86\u5b8c\u6574\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u7b80\u5355\u7b56\u7565\u7684\u666e\u904d\u9002\u7528\u6027\uff0c\u5e76\u7cbe\u786e\u523b\u753b\u4e86\u5404\u7c7b\u7b56\u7565\u5728\u591a\u79cd\u535a\u5f08\u73af\u5883\u4e2d\u7684\u53ef\u6267\u884c\u6761\u4ef6\u3002"}}
{"id": "2511.19642", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.19642", "abs": "https://arxiv.org/abs/2511.19642", "authors": ["Wuhuan Deng"], "title": "A Win-Expectancy Framework for Contextualizing Runs Batted In: Introducing ARBI and CRBI", "comment": null, "summary": "Runs Batted IN (RBI) records the number of runs a hitter directly drives in during their plate appearances and reflects a batter's ability to convert opportunities into scoring. Because producing runs determines game outcomes, RBI has long served as a central statistic in evaluating offensive performance. However, traditional RBI treats all batted-in runs equally and ignores th game context in which they occur, such as leverage, score state, and the actual impact of a run on a team's chance of winning. In this paper, we introduce two new context-aware metrics-Adjusted RBI (ARBI) and Contextual RBI (CRBI)-that address the fundamental limitations of RBI by incorporating Win Expectancy (WE). ARBI rescales each RBI according to the change in WE before and after the scoring event, assigning more value to runs that meaningfully shift the likelihood of winning and less to runs scored in low-leverage situations. We then extend this framework to CRBI, which further differentiates RBIs with the same WE change by accounting for the terminal WE at the end of the event. This refinement captures the idea that an RBI increasing WE from, for example, 0.45 to 0.65 has a larger competitive impact than one increasing WE from 0.05 to 0.25, even though both represent a 20% increase. Together, ARBI and CRBI provide calibrated, context-sensitive measures of offensive contribution that more accurately reflect the true value of run production. These metrics modernize the interpretation of RBI and have broad applications in player evaluation, forecasting, contract evaluation, and decision-making in baseball analytics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u60c5\u5883\u611f\u77e5\u6307\u6807ARBI\u548cCRBI\uff0c\u901a\u8fc7\u6574\u5408\u80dc\u7387\u671f\u671b\u6765\u6539\u8fdb\u4f20\u7edf\u6253\u70b9\u7edf\u8ba1\uff0c\u66f4\u51c6\u786e\u5730\u8861\u91cf\u51fb\u7403\u5458\u7684\u8fdb\u653b\u8d21\u732e\u3002", "motivation": "\u4f20\u7edf\u6253\u70b9\u7edf\u8ba1\u5c06\u6240\u6709\u6253\u70b9\u89c6\u4e3a\u540c\u7b49\u91cd\u8981\uff0c\u5ffd\u7565\u4e86\u6bd4\u8d5b\u60c5\u5883\uff08\u5982\u6760\u6746\u7387\u3001\u6bd4\u5206\u72b6\u6001\u3001\u5f97\u5206\u5bf9\u80dc\u7387\u7684\u5f71\u54cd\uff09\uff0c\u65e0\u6cd5\u53cd\u6620\u6253\u70b9\u7684\u771f\u5b9e\u4ef7\u503c\u3002", "method": "ARBI\u6839\u636e\u5f97\u5206\u4e8b\u4ef6\u524d\u540e\u7684\u80dc\u7387\u671f\u671b\u53d8\u5316\u91cd\u65b0\u8c03\u6574\u6bcf\u4e2a\u6253\u70b9\u7684\u4ef7\u503c\uff1bCRBI\u8fdb\u4e00\u6b65\u8003\u8651\u4e8b\u4ef6\u7ed3\u675f\u65f6\u7684\u7ec8\u672b\u80dc\u7387\u671f\u671b\uff0c\u533a\u5206\u76f8\u540c\u80dc\u7387\u53d8\u5316\u4f46\u4e0d\u540c\u7ade\u4e89\u5f71\u54cd\u7684\u6253\u70b9\u3002", "result": "ARBI\u548cCRBI\u63d0\u4f9b\u4e86\u7ecf\u8fc7\u6821\u51c6\u7684\u60c5\u5883\u654f\u611f\u6307\u6807\uff0c\u80fd\u66f4\u51c6\u786e\u5730\u53cd\u6620\u6253\u70b9\u751f\u4ea7\u7684\u771f\u5b9e\u4ef7\u503c\uff0c\u533a\u5206\u9ad8\u6760\u6746\u548c\u4f4e\u6760\u6746\u60c5\u5883\u4e0b\u7684\u6253\u70b9\u8d21\u732e\u3002", "conclusion": "ARBI\u548cCRBI\u73b0\u4ee3\u5316\u4e86\u6253\u70b9\u7edf\u8ba1\u7684\u89e3\u91ca\uff0c\u5728\u7403\u5458\u8bc4\u4f30\u3001\u9884\u6d4b\u3001\u5408\u540c\u8bc4\u4f30\u548c\u68d2\u7403\u5206\u6790\u51b3\u7b56\u4e2d\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.19488", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19488", "abs": "https://arxiv.org/abs/2511.19488", "authors": ["Hsien-Te Kao", "Aleksey Panasyuk", "Peter Bautista", "William Dupree", "Gabriel Ganberg", "Jeffrey M. Beaubien", "Laura Cassani", "Svitlana Volkova"], "title": "Building Resilient Information Ecosystems: Large LLM-Generated Dataset of Persuasion Attacks", "comment": null, "summary": "Organization's communication is essential for public trust, but the rise of generative AI models has introduced significant challenges by generating persuasive content that can form competing narratives with official messages from government and commercial organizations at speed and scale. This has left agencies in a reactive position, often unaware of how these models construct their persuasive strategies, making it more difficult to sustain communication effectiveness. In this paper, we introduce a large LLM-generated persuasion attack dataset, which includes 134,136 attacks generated by GPT-4, Gemma 2, and Llama 3.1 on agency news. These attacks span 23 persuasive techniques from SemEval 2023 Task 3, directed toward 972 press releases from ten agencies. The generated attacks come in two mediums, press release statements and social media posts, covering both long-form and short-form communication strategies. We analyzed the moral resonance of these persuasion attacks to understand their attack vectors. GPT-4's attacks mainly focus on Care, with Authority and Loyalty also playing a role. Gemma 2 emphasizes Care and Authority, while Llama 3.1 centers on Loyalty and Care. Analyzing LLM-generated persuasive attacks across models will enable proactive defense, allow to create the reputation armor for organizations, and propel the development of both effective and resilient communications in the information ecosystem.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u5927\u578bLLM\u751f\u6210\u7684\u529d\u8bf4\u653b\u51fb\u6570\u636e\u96c6\uff0c\u5305\u542b13.4\u4e07\u6761\u7531GPT-4\u3001Gemma 2\u548cLlama 3.1\u9488\u5bf9\u673a\u6784\u65b0\u95fb\u751f\u6210\u7684\u653b\u51fb\uff0c\u6db5\u76d623\u79cd\u529d\u8bf4\u6280\u5de7\uff0c\u7528\u4e8e\u5206\u6790\u4e0d\u540c\u6a21\u578b\u7684\u653b\u51fb\u7b56\u7565\u5e76\u652f\u6301\u4e3b\u52a8\u9632\u5fa1\u3002", "motivation": "\u751f\u6210\u5f0fAI\u6a21\u578b\u80fd\u591f\u5feb\u901f\u5927\u89c4\u6a21\u751f\u6210\u6709\u8bf4\u670d\u529b\u7684\u5185\u5bb9\uff0c\u4e0e\u5b98\u65b9\u4fe1\u606f\u5f62\u6210\u7ade\u4e89\u6027\u53d9\u4e8b\uff0c\u4f7f\u673a\u6784\u5904\u4e8e\u88ab\u52a8\u5730\u4f4d\uff0c\u96be\u4ee5\u7ef4\u6301\u6c9f\u901a\u6548\u679c\u3002", "method": "\u521b\u5efa\u5305\u542b134,136\u6761\u653b\u51fb\u7684\u5927\u578b\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u653b\u51fb\u7531\u4e09\u79cdLLM\u9488\u5bf910\u4e2a\u673a\u6784\u7684972\u4efd\u65b0\u95fb\u7a3f\u751f\u6210\uff0c\u6db5\u76d6\u65b0\u95fb\u7a3f\u58f0\u660e\u548c\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u4e24\u79cd\u5a92\u4ecb\uff0c\u5206\u679023\u79cd\u529d\u8bf4\u6280\u5de7\u548c\u9053\u5fb7\u5171\u9e23\u3002", "result": "GPT-4\u653b\u51fb\u4e3b\u8981\u5173\u6ce8\u5173\u6000\uff0c\u6743\u5a01\u548c\u5fe0\u8bda\u4e5f\u8d77\u4f5c\u7528\uff1bGemma 2\u5f3a\u8c03\u5173\u6000\u548c\u6743\u5a01\uff1bLlama 3.1\u4ee5\u5fe0\u8bda\u548c\u5173\u6000\u4e3a\u4e2d\u5fc3\u3002\u4e0d\u540c\u6a21\u578b\u5c55\u73b0\u51fa\u4e0d\u540c\u7684\u529d\u8bf4\u7b56\u7565\u504f\u597d\u3002", "conclusion": "\u5206\u6790LLM\u751f\u6210\u7684\u529d\u8bf4\u653b\u51fb\u80fd\u591f\u5b9e\u73b0\u4e3b\u52a8\u9632\u5fa1\uff0c\u4e3a\u7ec4\u7ec7\u521b\u5efa\u58f0\u8a89\u62a4\u7532\uff0c\u63a8\u52a8\u4fe1\u606f\u751f\u6001\u7cfb\u7edf\u4e2d\u6709\u6548\u4e14\u5177\u6709\u97e7\u6027\u7684\u6c9f\u901a\u53d1\u5c55\u3002"}}
{"id": "2511.19451", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19451", "abs": "https://arxiv.org/abs/2511.19451", "authors": ["Apurva Patil", "Alfredo Duarte", "Fabrizio Bisetti", "Takashi Tanaka"], "title": "Strong Duality and Dual Ascent Approach to Continuous-Time Chance-Constrained Stochastic Optimal Control", "comment": "arXiv admin note: substantial text overlap with arXiv:2504.17154", "summary": "The paper addresses a continuous-time continuous-space chance-constrained stochastic optimal control (SOC) problem where the probability of failure to satisfy given state constraints is explicitly bounded. We leverage the notion of exit time from continuous-time stochastic calculus to formulate a chance-constrained SOC problem. Without any conservative approximation, the chance constraint is transformed into an expectation of an indicator function which can be incorporated into the cost function by considering a dual formulation. We then express the dual function in terms of the solution to a Hamilton-Jacobi-Bellman partial differential equation parameterized by the dual variable. Under a certain assumption on the system dynamics and cost function, it is shown that a strong duality holds between the primal chance-constrained problem and its dual. The Path integral approach is utilized to numerically solve the dual problem via gradient ascent using open-loop samples of system trajectories. We present simulation studies on chance-constrained motion planning for spatial navigation of mobile robots and the solution of the path integral approach is compared with that of the finite difference method.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u8fde\u7eed\u65f6\u95f4\u8fde\u7eed\u7a7a\u95f4\u673a\u4f1a\u7ea6\u675f\u968f\u673a\u6700\u4f18\u63a7\u5236\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u9000\u51fa\u65f6\u95f4\u6982\u5ff5\u5c06\u673a\u4f1a\u7ea6\u675f\u8f6c\u5316\u4e3a\u671f\u671b\u51fd\u6570\uff0c\u5229\u7528\u5bf9\u5076\u516c\u5f0f\u548c\u8def\u5f84\u79ef\u5206\u65b9\u6cd5\u8fdb\u884c\u6570\u503c\u6c42\u89e3\u3002", "motivation": "\u89e3\u51b3\u8fde\u7eed\u65f6\u95f4\u8fde\u7eed\u7a7a\u95f4\u4e2d\u968f\u673a\u7cfb\u7edf\u6ee1\u8db3\u72b6\u6001\u7ea6\u675f\u7684\u6982\u7387\u6709\u660e\u786e\u4e0a\u9650\u7684\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u7684\u4fdd\u5b88\u8fd1\u4f3c\u3002", "method": "\u5229\u7528\u9000\u51fa\u65f6\u95f4\u6982\u5ff5\u5c06\u673a\u4f1a\u7ea6\u675f\u8f6c\u5316\u4e3a\u671f\u671b\u51fd\u6570\uff0c\u91c7\u7528\u5bf9\u5076\u516c\u5f0f\u5c06\u7ea6\u675f\u7eb3\u5165\u6210\u672c\u51fd\u6570\uff0c\u4f7f\u7528\u8def\u5f84\u79ef\u5206\u65b9\u6cd5\u901a\u8fc7\u68af\u5ea6\u4e0a\u5347\u6c42\u89e3\u5bf9\u5076\u95ee\u9898\u3002", "result": "\u5728\u7279\u5b9a\u7cfb\u7edf\u52a8\u6001\u548c\u6210\u672c\u51fd\u6570\u5047\u8bbe\u4e0b\uff0c\u8bc1\u660e\u4e86\u539f\u59cb\u673a\u4f1a\u7ea6\u675f\u95ee\u9898\u4e0e\u5176\u5bf9\u5076\u95ee\u9898\u4e4b\u95f4\u7684\u5f3a\u5bf9\u5076\u6027\uff0c\u5e76\u901a\u8fc7\u79fb\u52a8\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u4eff\u771f\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u8fde\u7eed\u65f6\u95f4\u8fde\u7eed\u7a7a\u95f4\u673a\u4f1a\u7ea6\u675f\u968f\u673a\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u8def\u5f84\u79ef\u5206\u65b9\u6cd5\u76f8\u6bd4\u6709\u9650\u5dee\u5206\u6cd5\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2511.19543", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19543", "abs": "https://arxiv.org/abs/2511.19543", "authors": ["Omar Faris", "S\u0142awomir Tadeja", "Fulvio Forni"], "title": "A Virtual Mechanical Interaction Layer Enables Resilient Human-to-Robot Object Handovers", "comment": null, "summary": "Object handover is a common form of interaction that is widely present in collaborative tasks. However, achieving it efficiently remains a challenge. We address the problem of ensuring resilient robotic actions that can adapt to complex changes in object pose during human-to-robot object handovers. We propose the use of Virtual Model Control to create an interaction layer that controls the robot and adapts to the dynamic changes in the handover process. Additionally, we propose the use of augmented reality to facilitate bidirectional communication between humans and robots during handovers. We assess the performance of our controller in a set of experiments that demonstrate its resilience to various sources of uncertainties, including complex changes to the object's pose during the handover. Finally, we performed a user study with 16 participants to understand human preferences for different robot control profiles and augmented reality visuals in object handovers. Our results showed a general preference for the proposed approach and revealed insights that can guide further development in adapting the interaction with the user.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u865a\u62df\u6a21\u578b\u63a7\u5236\u548c\u589e\u5f3a\u73b0\u5b9e\u7684\u4eba\u673a\u7269\u4f53\u4ea4\u63a5\u65b9\u6cd5\uff0c\u80fd\u591f\u9002\u5e94\u4ea4\u63a5\u8fc7\u7a0b\u4e2d\u7684\u52a8\u6001\u53d8\u5316\u548c\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u89e3\u51b3\u4eba\u673a\u7269\u4f53\u4ea4\u63a5\u8fc7\u7a0b\u4e2d\u56e0\u7269\u4f53\u59ff\u6001\u590d\u6742\u53d8\u5316\u5bfc\u81f4\u7684\u6548\u7387\u95ee\u9898\uff0c\u786e\u4fdd\u673a\u5668\u4eba\u52a8\u4f5c\u7684\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u4f7f\u7528\u865a\u62df\u6a21\u578b\u63a7\u5236\u521b\u5efa\u4ea4\u4e92\u5c42\u6765\u63a7\u5236\u673a\u5668\u4eba\u5e76\u9002\u5e94\u4ea4\u63a5\u8fc7\u7a0b\u7684\u52a8\u6001\u53d8\u5316\uff0c\u540c\u65f6\u5229\u7528\u589e\u5f3a\u73b0\u5b9e\u4fc3\u8fdb\u4eba\u673a\u53cc\u5411\u901a\u4fe1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u63a7\u5236\u5668\u5bf9\u5404\u79cd\u4e0d\u786e\u5b9a\u6027\u5177\u6709\u9c81\u68d2\u6027\uff0c\u7528\u6237\u7814\u7a76\u663e\u793a\u53c2\u4e0e\u8005\u666e\u904d\u504f\u597d\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4eba\u673a\u7269\u4f53\u4ea4\u63a5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u672a\u6765\u4ea4\u4e92\u9002\u5e94\u5f00\u53d1\u63d0\u4f9b\u4e86\u6307\u5bfc\u6027\u89c1\u89e3\u3002"}}
{"id": "2511.20237", "categories": ["eess.SY", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20237", "abs": "https://arxiv.org/abs/2511.20237", "authors": ["Zeynab Kaseb", "Matthias Moller", "Lindsay Spoor", "Jerry J. Guo", "Yu Xiang", "Peter Palensky", "Pedro P. Vergara"], "title": "Quantum-Enhanced Reinforcement Learning for Accelerating Newton-Raphson Convergence with Ising Machines: A Case Study for Power Flow Analysis", "comment": "10 pages, 9 figures, 4 tables", "summary": "The Newton-Raphson (NR) method is widely used for solving power flow (PF) equations due to its quadratic convergence. However, its performance deteriorates under poor initialization or extreme operating scenarios, e.g., high levels of renewable energy penetration. Traditional NR initialization strategies often fail to address these challenges, resulting in slow convergence or even divergence. We propose the use of reinforcement learning (RL) to optimize the initialization of NR, and introduce a novel quantum-enhanced RL environment update mechanism to mitigate the significant computational cost of evaluating power system states over a combinatorially large action space at each RL timestep by formulating the voltage adjustment task as a quadratic unconstrained binary optimization problem. Specifically, quantum/digital annealers are integrated into the RL environment update to evaluate state transitions using a problem Hamiltonian designed for PF. Results demonstrate significant improvements in convergence speed, a reduction in NR iteration counts, and enhanced robustness under different operating conditions.", "AI": {"tldr": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u725b\u987f-\u62c9\u592b\u900a\u6cd5\u7684\u521d\u59cb\u5316\uff0c\u7ed3\u5408\u91cf\u5b50\u9000\u706b\u5668\u89e3\u51b3\u5927\u89c4\u6a21\u52a8\u4f5c\u7a7a\u95f4\u7684\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6536\u655b\u901f\u5ea6\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u725b\u987f-\u62c9\u592b\u900a\u6cd5\u5728\u4e0d\u826f\u521d\u59cb\u5316\u6216\u6781\u7aef\u8fd0\u884c\u573a\u666f\u4e0b\u6027\u80fd\u4e0b\u964d\uff0c\u7279\u522b\u662f\u5728\u9ad8\u53ef\u518d\u751f\u80fd\u6e90\u6e17\u900f\u7387\u60c5\u51b5\u4e0b\uff0c\u4f20\u7edf\u521d\u59cb\u5316\u7b56\u7565\u5f80\u5f80\u5bfc\u81f4\u6536\u655b\u7f13\u6162\u751a\u81f3\u53d1\u6563\u3002", "method": "\u63d0\u51fa\u5f3a\u5316\u5b66\u4e60\u4f18\u5316NR\u521d\u59cb\u5316\uff0c\u5f15\u5165\u91cf\u5b50\u589e\u5f3a\u7684RL\u73af\u5883\u66f4\u65b0\u673a\u5236\uff0c\u5c06\u7535\u538b\u8c03\u6574\u4efb\u52a1\u5efa\u6a21\u4e3a\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\u95ee\u9898\uff0c\u96c6\u6210\u91cf\u5b50/\u6570\u5b57\u9000\u706b\u5668\u8bc4\u4f30\u72b6\u6001\u8f6c\u79fb\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6536\u655b\u901f\u5ea6\u663e\u8457\u63d0\u5347\uff0cNR\u8fed\u4ee3\u6b21\u6570\u51cf\u5c11\uff0c\u5728\u4e0d\u540c\u8fd0\u884c\u6761\u4ef6\u4e0b\u9c81\u68d2\u6027\u589e\u5f3a\u3002", "conclusion": "\u91cf\u5b50\u589e\u5f3a\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u725b\u987f-\u62c9\u592b\u900a\u6cd5\u5728\u6781\u7aef\u573a\u666f\u4e0b\u7684\u521d\u59cb\u5316\u95ee\u9898\uff0c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u548c\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002"}}
{"id": "2511.19824", "categories": ["econ.EM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.19824", "abs": "https://arxiv.org/abs/2511.19824", "authors": ["Junlin Yang"], "title": "Institutional Learning and Volatility Transmission in ASEAN Equity Markets: A Network-Integrated Regime-Dependent Approach", "comment": null, "summary": "This paper investigates how institutional learning and regional spillovers shape volatility dynamics in ASEAN equity markets. Using daily data for Indonesia, Malaysia, the Philippines, and Thailand from 2010 to 2024, we construct a high-frequency institutional learning index via a MIDAS-EPU approach. Unlike existing studies that treat institutional quality as a static background characteristic, this paper models institutions as a dynamic mechanism that reacts to policy shocks, information pressure, and crisis events. Building on this perspective, we introduce two new volatility frameworks: the Institutional Response Dynamics Model (IRDM), which embeds crisis memory, policy shocks, and information flows; and the Network-Integrated IRDM (N-IRDM), which incorporates dynamic-correlation and institutional-similarity networks to capture cross-market transmission. Empirical results show that institutional learning amplifies short-run sensitivity to shocks yet accelerates post-crisis normalization. Crisis-memory terms explain prolonged volatility clustering, while network interactions improve tail behavior and short-horizon forecasts. Robustness checks using placebo and lagged networks indicate that spillovers reflect a strong regional common factor rather than dependence on specific correlation topologies. Diebold-Mariano and ENCNEW tests confirm that the N-IRDM significantly outperforms baseline GARCH benchmarks. The findings highlight a dual role of institutions and offer policy insights on transparency enhancement, macroprudential communication, and coordinated regional governance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5236\u5ea6\u5b66\u4e60\u548c\u533a\u57df\u6ea2\u51fa\u5982\u4f55\u5f71\u54cd\u4e1c\u76df\u80a1\u5e02\u6ce2\u52a8\u52a8\u6001\uff0c\u901a\u8fc7\u6784\u5efa\u9ad8\u9891\u5236\u5ea6\u5b66\u4e60\u6307\u6570\u548c\u4e24\u4e2a\u65b0\u6ce2\u52a8\u6846\u67b6\uff0c\u53d1\u73b0\u5236\u5ea6\u5b66\u4e60\u653e\u5927\u77ed\u671f\u51b2\u51fb\u654f\u611f\u6027\u4f46\u52a0\u901f\u5371\u673a\u540e\u6b63\u5e38\u5316\uff0c\u7f51\u7edc\u4e92\u52a8\u6539\u5584\u5c3e\u90e8\u884c\u4e3a\u548c\u77ed\u671f\u9884\u6d4b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c06\u5236\u5ea6\u8d28\u91cf\u89c6\u4e3a\u9759\u6001\u80cc\u666f\u7279\u5f81\uff0c\u672c\u6587\u5c06\u5176\u5efa\u6a21\u4e3a\u5bf9\u653f\u7b56\u51b2\u51fb\u3001\u4fe1\u606f\u538b\u529b\u548c\u5371\u673a\u4e8b\u4ef6\u505a\u51fa\u53cd\u5e94\u7684\u52a8\u6001\u673a\u5236\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u4e1c\u76df\u80a1\u5e02\u6ce2\u52a8\u52a8\u6001\u3002", "method": "\u4f7f\u75282010-2024\u5e74\u5370\u5c3c\u3001\u9a6c\u6765\u897f\u4e9a\u3001\u83f2\u5f8b\u5bbe\u548c\u6cf0\u56fd\u7684\u65e5\u5ea6\u6570\u636e\uff0c\u901a\u8fc7MIDAS-EPU\u65b9\u6cd5\u6784\u5efa\u9ad8\u9891\u5236\u5ea6\u5b66\u4e60\u6307\u6570\uff0c\u63d0\u51fa\u5236\u5ea6\u54cd\u5e94\u52a8\u6001\u6a21\u578b(IRDM)\u548c\u7f51\u7edc\u96c6\u6210IRDM(N-IRDM)\u4e24\u4e2a\u65b0\u6ce2\u52a8\u6846\u67b6\u3002", "result": "\u5236\u5ea6\u5b66\u4e60\u653e\u5927\u77ed\u671f\u51b2\u51fb\u654f\u611f\u6027\u4f46\u52a0\u901f\u5371\u673a\u540e\u6b63\u5e38\u5316\uff0c\u5371\u673a\u8bb0\u5fc6\u9879\u89e3\u91ca\u6301\u7eed\u6ce2\u52a8\u805a\u7c7b\uff0c\u7f51\u7edc\u4e92\u52a8\u6539\u5584\u5c3e\u90e8\u884c\u4e3a\u548c\u77ed\u671f\u9884\u6d4b\uff0cN-IRDM\u663e\u8457\u4f18\u4e8e\u57fa\u51c6GARCH\u6a21\u578b\u3002", "conclusion": "\u5236\u5ea6\u5177\u6709\u53cc\u91cd\u4f5c\u7528\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u900f\u660e\u5ea6\u63d0\u5347\u3001\u5b8f\u89c2\u5ba1\u614e\u6c9f\u901a\u548c\u533a\u57df\u534f\u8c03\u6cbb\u7406\u63d0\u4f9b\u4e86\u653f\u7b56\u542f\u793a\u3002"}}
{"id": "2511.19663", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.19663", "abs": "https://arxiv.org/abs/2511.19663", "authors": ["Ahmed Awadallah", "Yash Lara", "Raghav Magazine", "Hussein Mozannar", "Akshay Nambi", "Yash Pandya", "Aravind Rajeswaran", "Corby Rosset", "Alexey Taymanov", "Vibhav Vineet", "Spencer Whitehead", "Andrew Zhao"], "title": "Fara-7B: An Efficient Agentic Model for Computer Use", "comment": null, "summary": "Progress in computer use agents (CUAs) has been constrained by the absence of large and high-quality datasets that capture how humans interact with a computer. While LLMs have thrived on abundant textual data, no comparable corpus exists for CUA trajectories. To address these gaps, we introduce FaraGen, a novel synthetic data generation system for multi-step web tasks. FaraGen can propose diverse tasks from frequently used websites, generate multiple solution attempts, and filter successful trajectories using multiple verifiers. It achieves high throughput, yield, and diversity for multi-step web tasks, producing verified trajectories at approximately $1 each. We use this data to train Fara-7B, a native CUA model that perceives the computer using only screenshots, executes actions via predicted coordinates, and is small enough to run on-device. We find that Fara-7B outperforms other CUA models of comparable size on benchmarks like WebVoyager, Online-Mind2Web, and WebTailBench -- our novel benchmark that better captures under-represented web tasks in pre-existing benchmarks. Furthermore, Fara-7B is competitive with much larger frontier models, illustrating key benefits of scalable data generation systems in advancing small efficient agentic models. We are making Fara-7B open-weight on Microsoft Foundry and HuggingFace, and we are releasing WebTailBench.", "AI": {"tldr": "FaraGen\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6b65\u9aa4\u7f51\u9875\u4efb\u52a1\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u7cfb\u7edf\uff0c\u80fd\u591f\u751f\u6210\u591a\u6837\u5316\u7684\u4efb\u52a1\u548c\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u7b5b\u9009\u6210\u529f\u8f68\u8ff9\u3002\u57fa\u4e8e\u8fd9\u4e9b\u6570\u636e\u8bad\u7ec3\u7684Fara-7B\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u751a\u81f3\u80fd\u4e0e\u66f4\u5927\u7684\u524d\u6cbf\u6a21\u578b\u7ade\u4e89\u3002", "motivation": "\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\uff08CUA\uff09\u7684\u53d1\u5c55\u53d7\u5230\u7f3a\u4e4f\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u7684\u9650\u5236\uff0c\u73b0\u6709\u6570\u636e\u96c6\u65e0\u6cd5\u6355\u6349\u4eba\u7c7b\u4e0e\u8ba1\u7b97\u673a\u7684\u4ea4\u4e92\u65b9\u5f0f\u3002", "method": "\u5f00\u53d1FaraGen\u7cfb\u7edf\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u5305\u62ec\u63d0\u51fa\u591a\u6837\u5316\u4efb\u52a1\u3001\u751f\u6210\u591a\u4e2a\u89e3\u51b3\u65b9\u6848\u5c1d\u8bd5\uff0c\u5e76\u4f7f\u7528\u591a\u4e2a\u9a8c\u8bc1\u5668\u7b5b\u9009\u6210\u529f\u8f68\u8ff9\u3002\u57fa\u4e8e\u8fd9\u4e9b\u6570\u636e\u8bad\u7ec3Fara-7B\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u4ec5\u901a\u8fc7\u622a\u56fe\u611f\u77e5\u8ba1\u7b97\u673a\uff0c\u901a\u8fc7\u9884\u6d4b\u5750\u6807\u6267\u884c\u52a8\u4f5c\u3002", "result": "FaraGen\u80fd\u4ee5\u7ea61\u7f8e\u5143\u7684\u6210\u672c\u751f\u6210\u6bcf\u4e2a\u9a8c\u8bc1\u8f68\u8ff9\uff0c\u5177\u6709\u9ad8\u541e\u5410\u91cf\u3001\u4ea7\u91cf\u548c\u591a\u6837\u6027\u3002Fara-7B\u5728WebVoyager\u3001Online-Mind2Web\u548cWebTailBench\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u540c\u7c7b\u89c4\u6a21\u6a21\u578b\uff0c\u5e76\u4e0e\u66f4\u5927\u7684\u524d\u6cbf\u6a21\u578b\u7ade\u4e89\u3002", "conclusion": "\u53ef\u6269\u5c55\u7684\u6570\u636e\u751f\u6210\u7cfb\u7edf\u5728\u63a8\u8fdb\u5c0f\u578b\u9ad8\u6548\u4ee3\u7406\u6a21\u578b\u65b9\u9762\u5177\u6709\u5173\u952e\u4f18\u52bf\u3002Fara-7B\u6a21\u578b\u5df2\u5f00\u6e90\u53d1\u5e03\uff0c\u540c\u65f6\u53d1\u5e03\u4e86WebTailBench\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2511.19627", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.19627", "abs": "https://arxiv.org/abs/2511.19627", "authors": ["Paolo Pedotti"], "title": "Total Factor Productivity and its determinants: an analysis of the relationship at firm level through unsupervised learning techniques", "comment": "56 pages with 47 figures", "summary": "The paper is related to the identification of firm's features which serve as determinants for firm's total factor productivity through unsupervised learning techniques (principal component analysis, self organizing maps, clustering). This bottom-up approach can effectively manage the problem of the heterogeneity of the firms and provides new ways to look at firms' standard classifications. Using the large sample provided by the ORBIS database, the analyses covers the years before the outbreak of Covid-19 (2015-2019) and the immediate post-Covid period (year 2020). It has been shown that in both periods, the main determinants of productivity growth are related to profitability, credit/debts measures, cost and capital efficiency, and effort and outcome of the R&D activity conducted by the firms. Finally, a linear relationship between determinants and productivity growth has been found.", "AI": {"tldr": "\u4f7f\u7528\u65e0\u76d1\u7763\u5b66\u4e60\u6280\u672f\u8bc6\u522b\u4f01\u4e1a\u5168\u8981\u7d20\u751f\u4ea7\u7387\u7684\u5173\u952e\u51b3\u5b9a\u56e0\u7d20\uff0c\u53d1\u73b0\u76c8\u5229\u80fd\u529b\u3001\u4fe1\u8d37/\u503a\u52a1\u6307\u6807\u3001\u6210\u672c\u4e0e\u8d44\u672c\u6548\u7387\u4ee5\u53ca\u7814\u53d1\u6d3b\u52a8\u662f\u4e3b\u8981\u5f71\u54cd\u56e0\u7d20\u3002", "motivation": "\u89e3\u51b3\u4f01\u4e1a\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u4e0b\u800c\u4e0a\u7684\u65b9\u6cd5\u91cd\u65b0\u5ba1\u89c6\u4f01\u4e1a\u6807\u51c6\u5206\u7c7b\uff0c\u8bc6\u522b\u5f71\u54cd\u4f01\u4e1a\u5168\u8981\u7d20\u751f\u4ea7\u7387\u7684\u5173\u952e\u7279\u5f81\u3002", "method": "\u4f7f\u7528\u65e0\u76d1\u7763\u5b66\u4e60\u6280\u672f\uff08\u4e3b\u6210\u5206\u5206\u6790\u3001\u81ea\u7ec4\u7ec7\u6620\u5c04\u3001\u805a\u7c7b\uff09\uff0c\u57fa\u4e8eORBIS\u6570\u636e\u5e93\u7684\u5927\u6837\u672c\u6570\u636e\uff0c\u5206\u67902015-2019\u5e74\u548c2020\u5e74\u4e24\u4e2a\u65f6\u671f\u3002", "result": "\u5728\u4e24\u4e2a\u65f6\u671f\u4e2d\uff0c\u751f\u4ea7\u7387\u589e\u957f\u7684\u4e3b\u8981\u51b3\u5b9a\u56e0\u7d20\u90fd\u4e0e\u76c8\u5229\u80fd\u529b\u3001\u4fe1\u8d37/\u503a\u52a1\u6307\u6807\u3001\u6210\u672c\u4e0e\u8d44\u672c\u6548\u7387\u4ee5\u53ca\u7814\u53d1\u6d3b\u52a8\u76f8\u5173\u3002", "conclusion": "\u53d1\u73b0\u4e86\u51b3\u5b9a\u56e0\u7d20\u4e0e\u751f\u4ea7\u7387\u589e\u957f\u4e4b\u95f4\u7684\u7ebf\u6027\u5173\u7cfb\uff0c\u4e3a\u7406\u89e3\u4f01\u4e1a\u751f\u4ea7\u7387\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2511.19838", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.19838", "abs": "https://arxiv.org/abs/2511.19838", "authors": ["Yijun Liu"], "title": "Dynamic Reward Design", "comment": null, "summary": "This paper studies a dynamic screening model in which a principal hires an agent with limited liability. The agent's private cost of working is an i.i.d. draw from a continuous distribution. His working status is publicly observable. The limited liability constraint requires that payments remain nonnegative at all times. In this setting, despite costs being i.i.d. and the payoffs being additively separable across periods, the optimal mechanism does not treat each period independently. Instead, it features backloading payments and requires the agent to work in consecutive periods. Specifically, I characterize conditions under which the optimal mechanism either grants the agent flexibility to start working in any period or restricts the starting period to the first. In either case, once the agent begins working, he is incentivized to work consecutively until the end.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e00\u4e2a\u52a8\u6001\u7b5b\u9009\u6a21\u578b\uff0c\u5176\u4e2d\u59d4\u6258\u4eba\u96c7\u4f63\u5177\u6709\u6709\u9650\u8d23\u4efb\u7684\u4ee3\u7406\u4eba\u3002\u4ee3\u7406\u4eba\u7684\u5de5\u4f5c\u6210\u672c\u662f\u72ec\u7acb\u540c\u5206\u5e03\u7684\u968f\u673a\u53d8\u91cf\uff0c\u5de5\u4f5c\u72b6\u6001\u53ef\u516c\u5f00\u89c2\u5bdf\u3002\u6700\u4f18\u673a\u5236\u4e0d\u72ec\u7acb\u5904\u7406\u6bcf\u4e2a\u65f6\u671f\uff0c\u800c\u662f\u91c7\u7528\u5ef6\u8fdf\u652f\u4ed8\u5e76\u8981\u6c42\u4ee3\u7406\u4eba\u8fde\u7eed\u5de5\u4f5c\u3002", "motivation": "\u7814\u7a76\u5728\u6709\u9650\u8d23\u4efb\u7ea6\u675f\u4e0b\uff0c\u5f53\u4ee3\u7406\u4eba\u5de5\u4f5c\u6210\u672c\u72ec\u7acb\u540c\u5206\u5e03\u4e14\u8de8\u671f\u6536\u76ca\u53ef\u52a0\u65f6\uff0c\u6700\u4f18\u673a\u5236\u662f\u5426\u5e94\u8be5\u72ec\u7acb\u5904\u7406\u6bcf\u4e2a\u65f6\u671f\uff0c\u4ee5\u53ca\u5982\u4f55\u8bbe\u8ba1\u6fc0\u52b1\u673a\u5236\u3002", "method": "\u6784\u5efa\u52a8\u6001\u7b5b\u9009\u6a21\u578b\uff0c\u5206\u6790\u6709\u9650\u8d23\u4efb\u7ea6\u675f\u4e0b\u7684\u6700\u4f18\u673a\u5236\u8bbe\u8ba1\uff0c\u63a8\u5bfc\u51fa\u6700\u4f18\u652f\u4ed8\u65b9\u6848\u548c\u5de5\u4f5c\u5b89\u6392\u7684\u7279\u5f81\u3002", "result": "\u53d1\u73b0\u6700\u4f18\u673a\u5236\u4e0d\u72ec\u7acb\u5904\u7406\u6bcf\u4e2a\u65f6\u671f\uff0c\u800c\u662f\u91c7\u7528\u5ef6\u8fdf\u652f\u4ed8\u7b56\u7565\uff0c\u5e76\u8981\u6c42\u4ee3\u7406\u4eba\u4e00\u65e6\u5f00\u59cb\u5de5\u4f5c\u5c31\u5fc5\u987b\u8fde\u7eed\u5de5\u4f5c\u76f4\u5230\u7ed3\u675f\u3002\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u5141\u8bb8\u4ee3\u7406\u4eba\u7075\u6d3b\u9009\u62e9\u5f00\u59cb\u5de5\u4f5c\u65f6\u95f4\uff0c\u4f46\u4e00\u65e6\u5f00\u59cb\u5c31\u5fc5\u987b\u8fde\u7eed\u5de5\u4f5c\u3002", "conclusion": "\u5373\u4f7f\u5728\u6210\u672c\u72ec\u7acb\u540c\u5206\u5e03\u548c\u6536\u76ca\u53ef\u52a0\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u9650\u8d23\u4efb\u7ea6\u675f\u4f7f\u5f97\u6700\u4f18\u673a\u5236\u5fc5\u987b\u8de8\u671f\u5173\u8054\uff0c\u901a\u8fc7\u5ef6\u8fdf\u652f\u4ed8\u548c\u8fde\u7eed\u5de5\u4f5c\u8981\u6c42\u6765\u63d0\u4f9b\u6709\u6548\u6fc0\u52b1\u3002"}}
{"id": "2511.19672", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.19672", "abs": "https://arxiv.org/abs/2511.19672", "authors": ["Wuhuan Deng", "Scott Nestler"], "title": "Introducing Discipline Score Based on League Overall Swinging Probability", "comment": null, "summary": "Plate discipline is an important feature of a hitter's success. Hitter who are able to recognize good pitches to swing at and balls to take are generally recognized as disciplined hitters. Although there are some metrics that can provide insight into the patience of a hitter, most do not capture the ability of a batter to take balls. In this research, we introduce two new metrics, Discipline Score (DS) and Adjusted Discipline Score (ADS), which evaluate batters' discipline when the pitch is a ball compared with the predicted tendencies of all batters in the league.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u4e2a\u65b0\u6307\u6807DS\u548cADS\uff0c\u7528\u4e8e\u8bc4\u4f30\u51fb\u7403\u5458\u5bf9\u574f\u7403\u7684\u7eaa\u5f8b\u6027\uff0c\u4e0e\u8054\u76df\u5e73\u5747\u6c34\u5e73\u5bf9\u6bd4", "motivation": "\u73b0\u6709\u6307\u6807\u5927\u591a\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u51fb\u7403\u5458\u653e\u6389\u574f\u7403\u7684\u80fd\u529b\uff0c\u800c\u597d\u7403\u533a\u7eaa\u5f8b\u6027\u662f\u51fb\u7403\u5458\u6210\u529f\u7684\u91cd\u8981\u7279\u5f81", "method": "\u5f15\u5165\u7eaa\u5f8b\u6027\u5f97\u5206(DS)\u548c\u8c03\u6574\u7eaa\u5f8b\u6027\u5f97\u5206(ADS)\uff0c\u57fa\u4e8e\u51fb\u7403\u5458\u5bf9\u574f\u7403\u7684\u5904\u7406\u4e0e\u8054\u76df\u9884\u6d4b\u8d8b\u52bf\u7684\u5bf9\u6bd4", "result": "\u5f00\u53d1\u4e86\u80fd\u591f\u91cf\u5316\u8bc4\u4f30\u51fb\u7403\u5458\u653e\u6389\u574f\u7403\u80fd\u529b\u7684\u65b0\u6307\u6807", "conclusion": "DS\u548cADS\u6307\u6807\u80fd\u66f4\u597d\u5730\u8bc4\u4f30\u51fb\u7403\u5458\u7684\u7eaa\u5f8b\u6027\uff0c\u7279\u522b\u662f\u5bf9\u574f\u7403\u7684\u8bc6\u522b\u80fd\u529b"}}
{"id": "2511.19492", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19492", "abs": "https://arxiv.org/abs/2511.19492", "authors": ["Parker Whitfill", "Ben Snodin", "Joel Becker"], "title": "Forecasting AI Time Horizon Under Compute Slowdowns", "comment": null, "summary": "METR's time horizon metric has grown exponentially since 2019, along with compute. However, it is unclear whether compute scaling will persist at current rates through 2030, raising the question of how possible compute slowdowns might impact AI agent capability forecasts. Given a model of time horizon as a function of training compute and algorithms, along with a model of how compute investment spills into algorithmic progress (which, notably, precludes the possibility of a software-only singularity), and the empirical fact that both time horizon and compute have grown at constant rates over 2019--2025, we derive that time horizon growth must be proportional to compute growth. We provide additional, albeit limited, experimental evidence consistent with this theory. We use our model to project time horizon growth under OpenAI's compute projection, finding substantial projected delays in some cases. For example, 1-month time horizons at $80\\%$ reliability occur $7$ years later than simple trend extrapolation suggests.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u8ba1\u7b97\u80fd\u529b\u589e\u957f\u653e\u7f13\u5bf9AI\u667a\u80fd\u4f53\u80fd\u529b\u9884\u6d4b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u65f6\u95f4\u8303\u56f4\u589e\u957f\u5fc5\u987b\u4e0e\u8ba1\u7b97\u589e\u957f\u6210\u6b63\u6bd4\uff0c\u5e76\u9884\u6d4b\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4f1a\u51fa\u73b0\u663e\u8457\u5ef6\u8fdf\u3002", "motivation": "\u7814\u7a76\u8ba1\u7b97\u80fd\u529b\u6269\u5c55\u662f\u5426\u80fd\u57282030\u5e74\u524d\u4fdd\u6301\u5f53\u524d\u901f\u5ea6\uff0c\u4ee5\u53ca\u8ba1\u7b97\u589e\u957f\u653e\u7f13\u5982\u4f55\u5f71\u54cdAI\u667a\u80fd\u4f53\u80fd\u529b\u9884\u6d4b\uff0c\u7279\u522b\u662f\u65f6\u95f4\u8303\u56f4\u6307\u6807\u7684\u9884\u6d4b\u3002", "method": "\u5efa\u7acb\u65f6\u95f4\u8303\u56f4\u4f5c\u4e3a\u8bad\u7ec3\u8ba1\u7b97\u548c\u7b97\u6cd5\u51fd\u6570\u7684\u6a21\u578b\uff0c\u7ed3\u5408\u8ba1\u7b97\u6295\u8d44\u5bf9\u7b97\u6cd5\u8fdb\u6b65\u7684\u5f71\u54cd\u6a21\u578b\uff0c\u57fa\u4e8e2019-2025\u5e74\u65f6\u95f4\u8303\u56f4\u548c\u8ba1\u7b97\u4ee5\u6052\u5b9a\u901f\u7387\u589e\u957f\u7684\u7ecf\u9a8c\u4e8b\u5b9e\u8fdb\u884c\u63a8\u5bfc\u3002", "result": "\u63a8\u5bfc\u51fa\u65f6\u95f4\u8303\u56f4\u589e\u957f\u5fc5\u987b\u4e0e\u8ba1\u7b97\u589e\u957f\u6210\u6b63\u6bd4\uff0c\u5e76\u63d0\u4f9b\u6709\u9650\u7684\u5b9e\u9a8c\u8bc1\u636e\u652f\u6301\u8fd9\u4e00\u7406\u8bba\u3002\u4f7f\u7528\u8be5\u6a21\u578b\u9884\u6d4b\u5728OpenAI\u8ba1\u7b97\u9884\u6d4b\u4e0b\u7684\u65f6\u95f4\u8303\u56f4\u589e\u957f\u3002", "conclusion": "\u8ba1\u7b97\u589e\u957f\u653e\u7f13\u4f1a\u5bfc\u81f4AI\u667a\u80fd\u4f53\u80fd\u529b\u53d1\u5c55\u663e\u8457\u5ef6\u8fdf\uff0c\u4f8b\u598280%\u53ef\u9760\u6027\u76841\u4e2a\u6708\u65f6\u95f4\u8303\u56f4\u6bd4\u7b80\u5355\u8d8b\u52bf\u5916\u63a8\u9884\u6d4b\u665a7\u5e74\u5b9e\u73b0\u3002"}}
{"id": "2511.19452", "categories": ["eess.SY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.19452", "abs": "https://arxiv.org/abs/2511.19452", "authors": ["Yi Zhang", "Yushen Long", "Liping Huang", "Yicheng Zhang", "Sheng Zhang", "Yifang Yin"], "title": "A Data-Driven Model Predictive Control Framework for Multi-Aircraft TMA Routing Under Travel Time Uncertainty", "comment": "This is the complete 8-page version of accepted workshop paper for Artificial Intelligence for Air Transportation (AI4AT) @ AAAI 2026", "summary": "This paper presents a closed-loop framework for conflict-free routing and scheduling of multi-aircraft in Terminal Manoeuvring Areas (TMA), aimed at reducing congestion and enhancing landing efficiency. Leveraging data-driven arrival inputs (either historical or predicted), we formulate a mixed-integer optimization model for real-time control, incorporating an extended TMA network spanning a 50-nautical-mile radius around Changi Airport. The model enforces safety separation, speed adjustments, and holding time constraints while maximizing runway throughput. A rolling-horizon Model Predictive Control (MPC) strategy enables closed-loop integration with a traffic simulator, dynamically updating commands based on real-time system states and predictions. Computational efficiency is validated across diverse traffic scenarios, demonstrating a 7-fold reduction in computation time during peak congestion compared to onetime optimization, using Singapore ADS-B dataset. Monte Carlo simulations under travel time disturbances further confirm the framework's robustness. Results highlight the approach's operational resilience and computational scalability, offering actionable decision support for Air Traffic Controller Officers (ATCOs) through real-time optimization and adaptive replanning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u95ed\u73af\u6846\u67b6\uff0c\u7528\u4e8e\u7ec8\u7aef\u673a\u52a8\u533a\u57df\u5185\u591a\u822a\u7a7a\u5668\u7684\u65e0\u51b2\u7a81\u8def\u7531\u548c\u8c03\u5ea6\uff0c\u65e8\u5728\u51cf\u5c11\u62e5\u5835\u5e76\u63d0\u9ad8\u7740\u9646\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u7ec8\u7aef\u673a\u52a8\u533a\u57df\u5185\u7684\u822a\u7a7a\u5668\u62e5\u5835\u95ee\u9898\uff0c\u63d0\u9ad8\u8dd1\u9053\u541e\u5410\u91cf\u548c\u7740\u9646\u6548\u7387\uff0c\u4e3a\u7a7a\u4e2d\u4ea4\u901a\u7ba1\u5236\u5458\u63d0\u4f9b\u5b9e\u65f6\u51b3\u7b56\u652f\u6301\u3002", "method": "\u91c7\u7528\u6570\u636e\u9a71\u52a8\u7684\u5230\u8fbe\u8f93\u5165\uff0c\u5efa\u7acb\u6df7\u5408\u6574\u6570\u4f18\u5316\u6a21\u578b\uff0c\u7ed3\u5408\u6269\u5c55\u7684\u7ec8\u7aef\u673a\u52a8\u533a\u57df\u7f51\u7edc\uff0c\u5b9e\u65bd\u6eda\u52a8\u65f6\u57df\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7b56\u7565\uff0c\u5e76\u4e0e\u4ea4\u901a\u6a21\u62df\u5668\u8fdb\u884c\u95ed\u73af\u96c6\u6210\u3002", "result": "\u5728\u9ad8\u5cf0\u62e5\u5835\u671f\u95f4\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c117\u500d\uff0c\u8499\u7279\u5361\u6d1b\u6a21\u62df\u9a8c\u8bc1\u4e86\u6846\u67b6\u5728\u65c5\u884c\u65f6\u95f4\u6270\u52a8\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5c55\u793a\u4e86\u64cd\u4f5c\u5f39\u6027\u548c\u8ba1\u7b97\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5b9e\u65f6\u4f18\u5316\u548c\u81ea\u9002\u5e94\u91cd\u65b0\u89c4\u5212\uff0c\u4e3a\u7a7a\u4e2d\u4ea4\u901a\u7ba1\u5236\u5458\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u51b3\u7b56\u652f\u6301\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7ec8\u7aef\u673a\u52a8\u533a\u57df\u7684\u7ba1\u7406\u6548\u7387\u3002"}}
{"id": "2511.19647", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19647", "abs": "https://arxiv.org/abs/2511.19647", "authors": ["Jennifer Grannen", "Michelle Pan", "Kenneth Llontop", "Cherie Ho", "Mark Zolotas", "Jeannette Bohg", "Dorsa Sadigh"], "title": "Robot-Powered Data Flywheels: Deploying Robots in the Wild for Continual Data Collection and Foundation Model Adaptation", "comment": null, "summary": "Foundation models (FM) have unlocked powerful zero-shot capabilities in vision and language, yet their reliance on internet pretraining data leaves them brittle in unstructured, real-world settings. The messy, real-world data encountered during deployment (e.g. occluded or multilingual text) remains massively underrepresented in existing corpora. Robots, as embodied agents, are uniquely positioned to close this gap: they can act in physical environments to collect large-scale, real-world data that enriches FM training with precisely the examples current models lack. We introduce the Robot-Powered Data Flywheel, a framework that transforms robots from FM consumers into data generators. By deploying robots equipped with FMs in the wild, we enable a virtuous cycle: robots perform useful tasks while collecting real-world data that improves both domain-specific adaptation and domain-adjacent generalization. We instantiate this framework with Scanford, a mobile manipulator deployed in the East Asia Library for 2 weeks. Scanford autonomously scans shelves, identifies books using a vision-language model (VLM), and leverages the library catalog to label images without human annotation. This deployment both aids librarians and produces a dataset to finetune the underlying VLM, improving performance on the domain-specific in-the-wild library setting and on domain-adjacent multilingual OCR benchmarks. Using data collected from 2103 shelves, Scanford improves VLM performance on book identification from 32.0% to 71.8% and boosts domain-adjacent multilingual OCR from 24.8% to 46.6% (English) and 30.8% to 38.0% (Chinese), while saving an ~18.7 hrs of human time. These results highlight how robot-powered data flywheels can both reduce human effort in real deployments and unlock new pathways for continually adapting FMs to the messiness of reality. More details are at: https://scanford-robot.github.io", "AI": {"tldr": "\u63d0\u51fa\u4e86\u673a\u5668\u4eba\u9a71\u52a8\u7684\u6570\u636e\u98de\u8f6e\u6846\u67b6\uff0c\u5c06\u673a\u5668\u4eba\u4ece\u57fa\u7840\u6a21\u578b\u6d88\u8d39\u8005\u8f6c\u53d8\u4e3a\u6570\u636e\u751f\u6210\u5668\uff0c\u901a\u8fc7\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u90e8\u7f72\u673a\u5668\u4eba\u6536\u96c6\u6570\u636e\u6765\u6539\u8fdb\u57fa\u7840\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u4e92\u8054\u7f51\u9884\u8bad\u7ec3\u6570\u636e\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u771f\u5b9e\u4e16\u754c\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u8868\u73b0\u8106\u5f31\u3002\u673a\u5668\u4eba\u4f5c\u4e3a\u5177\u8eab\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u6536\u96c6\u5927\u89c4\u6a21\u771f\u5b9e\u4e16\u754c\u6570\u636e\u6765\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u5f00\u53d1\u4e86Scanford\u79fb\u52a8\u673a\u68b0\u81c2\uff0c\u5728\u56fe\u4e66\u9986\u90e8\u7f722\u5468\uff0c\u81ea\u4e3b\u626b\u63cf\u4e66\u67b6\uff0c\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bc6\u522b\u4e66\u7c4d\uff0c\u5e76\u5229\u7528\u56fe\u4e66\u9986\u76ee\u5f55\u81ea\u52a8\u6807\u6ce8\u56fe\u50cf\u3002", "result": "\u4ece2103\u4e2a\u4e66\u67b6\u6536\u96c6\u6570\u636e\uff0c\u5c06\u4e66\u7c4d\u8bc6\u522b\u51c6\u786e\u7387\u4ece32.0%\u63d0\u5347\u81f371.8%\uff0c\u591a\u8bed\u8a00OCR\u6027\u80fd\u4ece24.8%\u63d0\u5347\u81f346.6%\uff08\u82f1\u6587\uff09\u548c30.8%\u63d0\u5347\u81f338.0%\uff08\u4e2d\u6587\uff09\uff0c\u8282\u7701\u7ea618.7\u5c0f\u65f6\u4eba\u5de5\u65f6\u95f4\u3002", "conclusion": "\u673a\u5668\u4eba\u9a71\u52a8\u7684\u6570\u636e\u98de\u8f6e\u65e2\u80fd\u51cf\u5c11\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u4eba\u5de5\u52aa\u529b\uff0c\u53c8\u80fd\u4e3a\u6301\u7eed\u9002\u5e94\u73b0\u5b9e\u4e16\u754c\u590d\u6742\u6027\u63d0\u4f9b\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.19669", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19669", "abs": "https://arxiv.org/abs/2511.19669", "authors": ["Souradip Poddar", "Chia-Tung Ho", "Ziming Wei", "Weidong Cao", "Haoxing Ren", "David Z. Pan"], "title": "HeaRT: A Hierarchical Circuit Reasoning Tree-Based Agentic Framework for AMS Design Optimization", "comment": null, "summary": "Conventional AI-driven AMS design automation algorithms remain constrained by their reliance on high-quality datasets to capture underlying circuit behavior, coupled with poor transferability across architectures, and a lack of adaptive mechanisms. This work proposes HeaRT, a foundational reasoning engine for automation loops and a first step toward intelligent, adaptive, human-style design optimization. HeaRT consistently demonstrates reasoning accuracy >97% and Pass@1 performance >98% across our 40-circuit benchmark repository, even as circuit complexity increases, while operating at <0.5x real-time token budget of SOTA baselines. Our experiments show that HeaRT yields >3x faster convergence in both sizing and topology design adaptation tasks across diverse optimization approaches, while preserving prior design intent.", "AI": {"tldr": "HeaRT\u662f\u4e00\u4e2a\u57fa\u7840\u63a8\u7406\u5f15\u64ce\uff0c\u7528\u4e8eAMS\u8bbe\u8ba1\u81ea\u52a8\u5316\uff0c\u5b9e\u73b0\u4e86>97%\u7684\u63a8\u7406\u51c6\u786e\u7387\u548c>98%\u7684Pass@1\u6027\u80fd\uff0c\u572840\u7535\u8def\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u8fd0\u884c\u6210\u672c\u4ec5\u4e3aSOTA\u57fa\u7ebf\u76840.5\u500d\u3002", "motivation": "\u4f20\u7edfAI\u9a71\u52a8\u7684AMS\u8bbe\u8ba1\u81ea\u52a8\u5316\u7b97\u6cd5\u53d7\u9650\u4e8e\u5bf9\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u7684\u4f9d\u8d56\u3001\u8de8\u67b6\u6784\u53ef\u79fb\u690d\u6027\u5dee\u4ee5\u53ca\u7f3a\u4e4f\u81ea\u9002\u5e94\u673a\u5236\u3002", "method": "\u63d0\u51faHeaRT\u57fa\u7840\u63a8\u7406\u5f15\u64ce\uff0c\u4f5c\u4e3a\u667a\u80fd\u81ea\u9002\u5e94\u8bbe\u8ba1\u4f18\u5316\u7684\u7b2c\u4e00\u6b65\uff0c\u91c7\u7528\u4eba\u7c7b\u98ce\u683c\u7684\u8bbe\u8ba1\u4f18\u5316\u65b9\u6cd5\u3002", "result": "HeaRT\u5728\u7535\u8def\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u4ecd\u4fdd\u6301\u9ad8\u7cbe\u5ea6\uff0c\u5728\u5c3a\u5bf8\u548c\u62d3\u6251\u8bbe\u8ba1\u9002\u5e94\u4efb\u52a1\u4e2d\u5b9e\u73b0>3\u500d\u7684\u6536\u655b\u901f\u5ea6\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u7559\u5148\u524d\u7684\u8bbe\u8ba1\u610f\u56fe\u3002", "conclusion": "HeaRT\u662f\u5411\u667a\u80fd\u81ea\u9002\u5e94AMS\u8bbe\u8ba1\u81ea\u52a8\u5316\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bbe\u8ba1\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2511.19680", "categories": ["econ.GN"], "pdf": "https://arxiv.org/pdf/2511.19680", "abs": "https://arxiv.org/abs/2511.19680", "authors": ["Ying Bao", "Jessie Liu"], "title": "Spiral of Silence: How Neutral Moderation Polarizes Content Creation", "comment": null, "summary": "This paper investigates how content moderation affects content creation in an ideologically diverse online environments. We develop a model in which users act as both creators and consumers, differing in their ideological affiliation and propensity to produce toxic content. Affective polarization, i.e., users' aversion to ideologically opposed content, interacts with moderation in unintended ways. We show that even ideologically neutral moderation that targets only toxicity can suppress non-toxic content creation, particularly from ideological minorities. Our analysis reveals a content-level externality: when toxic content is removed, non-toxic posts gain exposure. While creators from the ideological majority group sometimes benefit from this exposure, they do not internalize the negative spillovers, i.e., increased out-group animosity toward minority creators. This can discourage minority creation and polarize the content supply, ultimately leaving minority users in a more ideologically imbalanced environment: a mechanism reminiscent of the \"spiral of silence.\" Thus, our model offers an alternative perspective to a common debate: what appears as bias in moderation needs not reflect bias in rules, but can instead emerge endogenously as self-censorship in equilibrium. We also extend the model to explore how content personalization interacts with moderation policies.", "AI": {"tldr": "\u5185\u5bb9\u5ba1\u6838\u5728\u610f\u8bc6\u5f62\u6001\u591a\u5143\u7684\u5728\u7ebf\u73af\u5883\u4e2d\u5982\u4f55\u5f71\u54cd\u5185\u5bb9\u521b\u4f5c\uff0c\u5373\u4f7f\u4e2d\u7acb\u5730\u9488\u5bf9\u6bd2\u6027\u5185\u5bb9\uff0c\u4e5f\u53ef\u80fd\u6291\u5236\u975e\u6bd2\u6027\u5185\u5bb9\u521b\u4f5c\uff0c\u7279\u522b\u662f\u6765\u81ea\u610f\u8bc6\u5f62\u6001\u5c11\u6570\u7fa4\u4f53\u7684\u521b\u4f5c\u3002", "motivation": "\u7814\u7a76\u5185\u5bb9\u5ba1\u6838\u5728\u610f\u8bc6\u5f62\u6001\u591a\u5143\u5728\u7ebf\u73af\u5883\u4e2d\u7684\u5f71\u54cd\uff0c\u63a2\u8ba8\u5373\u4f7f\u4e2d\u7acb\u5ba1\u6838\u6bd2\u6027\u5185\u5bb9\uff0c\u5982\u4f55\u53ef\u80fd\u65e0\u610f\u4e2d\u6291\u5236\u975e\u6bd2\u6027\u5185\u5bb9\u521b\u4f5c\uff0c\u7279\u522b\u662f\u610f\u8bc6\u5f62\u6001\u5c11\u6570\u7fa4\u4f53\u7684\u521b\u4f5c\u3002", "method": "\u5f00\u53d1\u4e00\u4e2a\u6a21\u578b\uff0c\u7528\u6237\u65e2\u662f\u521b\u4f5c\u8005\u4e5f\u662f\u6d88\u8d39\u8005\uff0c\u5177\u6709\u4e0d\u540c\u7684\u610f\u8bc6\u5f62\u6001\u5f52\u5c5e\u548c\u4ea7\u751f\u6bd2\u6027\u5185\u5bb9\u7684\u503e\u5411\uff0c\u5206\u6790\u60c5\u611f\u6781\u5316\u4e0e\u5185\u5bb9\u5ba1\u6838\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u5373\u4f7f\u9488\u5bf9\u6bd2\u6027\u7684\u610f\u8bc6\u5f62\u6001\u4e2d\u7acb\u5ba1\u6838\u4e5f\u4f1a\u6291\u5236\u975e\u6bd2\u6027\u5185\u5bb9\u521b\u4f5c\uff0c\u7279\u522b\u662f\u6765\u81ea\u610f\u8bc6\u5f62\u6001\u5c11\u6570\u7fa4\u4f53\uff1b\u5185\u5bb9\u79fb\u9664\u4ea7\u751f\u5916\u90e8\u6027\uff0c\u975e\u6bd2\u6027\u5185\u5bb9\u83b7\u5f97\u66f4\u591a\u66dd\u5149\uff0c\u4f46\u591a\u6570\u7fa4\u4f53\u521b\u4f5c\u8005\u4e0d\u5185\u5316\u8d1f\u9762\u6ea2\u51fa\u6548\u5e94\uff0c\u5bfc\u81f4\u5c11\u6570\u7fa4\u4f53\u521b\u4f5c\u51cf\u5c11\u548c\u5185\u5bb9\u4f9b\u5e94\u6781\u5316\u3002", "conclusion": "\u5185\u5bb9\u5ba1\u6838\u4e2d\u7684\u504f\u89c1\u4e0d\u4e00\u5b9a\u53cd\u6620\u89c4\u5219\u504f\u89c1\uff0c\u800c\u662f\u53ef\u80fd\u4f5c\u4e3a\u5747\u8861\u4e2d\u7684\u81ea\u6211\u5ba1\u67e5\u5185\u751f\u51fa\u73b0\uff1b\u5185\u5bb9\u4e2a\u6027\u5316\u4e0e\u5ba1\u6838\u653f\u7b56\u7684\u76f8\u4e92\u4f5c\u7528\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2511.20077", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.20077", "abs": "https://arxiv.org/abs/2511.20077", "authors": ["Yuan Gao", "Xi Jin", "Manshu Khanna"], "title": "Reserve System with Beneficiary-Share Guarantee", "comment": null, "summary": "We study allocation problems with reserve systems under minimum beneficiary-share guarantees, requirements that targeted matches constitute at least a specified percentage of total matches. While such mandates promote targeted matches, they inherently conflict with maximizing total matches. We characterize the complete non-domination frontier using minimal cycles, where each point represents an allocation that cannot increase targeted matches without sacrificing total matches. Our main results: (i) the frontier exhibits concave structure with monotonically decreasing slope, (ii) traversing from maximum targeted matches to maximum total matches reduces matches by at most half, (iii) the Repeated Hungarian Algorithm computes all frontier points in polynomial time, and (iv) mechanisms with beneficiary-share guarantees can respect category-dependent priority orderings but necessarily violate path-independence. These results enable rigorous evaluation of beneficiary-share policies across diverse allocation contexts.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5177\u6709\u6700\u4f4e\u53d7\u76ca\u8005\u4efd\u989d\u4fdd\u8bc1\u7684\u5206\u914d\u7cfb\u7edf\uff0c\u5206\u6790\u4e86\u76ee\u6807\u5339\u914d\u4e0e\u603b\u5339\u914d\u6700\u5927\u5316\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u5e76\u523b\u753b\u4e86\u5b8c\u6574\u7684\u975e\u652f\u914d\u524d\u6cbf\u3002", "motivation": "\u7814\u7a76\u5177\u6709\u53d7\u76ca\u8005\u4efd\u989d\u4fdd\u8bc1\u7684\u5206\u914d\u95ee\u9898\uff0c\u8fd9\u7c7b\u653f\u7b56\u867d\u7136\u80fd\u4fc3\u8fdb\u76ee\u6807\u5339\u914d\uff0c\u4f46\u4f1a\u4e0e\u6700\u5927\u5316\u603b\u5339\u914d\u4ea7\u751f\u5185\u5728\u51b2\u7a81\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u5206\u6790\u8fd9\u79cd\u6743\u8861\u5173\u7cfb\u3002", "method": "\u4f7f\u7528\u6700\u5c0f\u5faa\u73af\u6765\u523b\u753b\u5b8c\u6574\u7684\u975e\u652f\u914d\u524d\u6cbf\uff0c\u5f00\u53d1\u4e86\u91cd\u590d\u5308\u7259\u5229\u7b97\u6cd5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u8ba1\u7b97\u6240\u6709\u524d\u6cbf\u70b9\uff0c\u5e76\u5206\u6790\u4e86\u673a\u5236\u8bbe\u8ba1\u5c5e\u6027\u3002", "result": "\u53d1\u73b0\u524d\u6cbf\u5177\u6709\u51f9\u7ed3\u6784\u548c\u5355\u8c03\u9012\u51cf\u659c\u7387\uff0c\u4ece\u6700\u5927\u76ee\u6807\u5339\u914d\u5230\u6700\u5927\u603b\u5339\u914d\u7684\u8f6c\u6362\u6700\u591a\u51cf\u5c11\u4e00\u534a\u5339\u914d\uff0c\u673a\u5236\u53ef\u4ee5\u5c0a\u91cd\u7c7b\u522b\u4f9d\u8d56\u4f18\u5148\u7ea7\u4f46\u5fc5\u7136\u8fdd\u53cd\u8def\u5f84\u72ec\u7acb\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u5728\u4e0d\u540c\u5206\u914d\u80cc\u666f\u4e0b\u4e25\u683c\u8bc4\u4f30\u53d7\u76ca\u8005\u4efd\u989d\u653f\u7b56\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2511.19742", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.19742", "abs": "https://arxiv.org/abs/2511.19742", "authors": ["Nathaniel Dyrkton", "Shomoita Alam", "Susan Shepherd", "Ibrahim Sana", "Kevin Phelan", "Jay JH Park"], "title": "Anchoring Convenience Survey Samples to a Baseline Census for Vaccine Coverage Monitoring in Global Health", "comment": "5 figures, 2 tables", "summary": "While conducting probabilistic surveys is the gold standard for assessing vaccine coverage, implementing these surveys poses challenges for global health. There is a need for more convenient option that is more affordable and practical. Motivated by childhood vaccine monitoring programs in rural areas of Chad and Niger, we conducted a simulation study to evaluate calibration-weighted design-based and logistic regression-based imputation estimators of the finite-population proportion of MCV1 coverage. These estimators use a hybrid approach that anchors non-probabilistic follow-up survey to probabilistic baseline census to account for selection bias. We explored varying degrees of non-ignorable selection bias (odds ratios from 1.0-1.5), percentage of villages sampled (25-75%), and village-level survey response rate to the follow-up survey (50-80%). Our performance metrics included bias, coverage, and proportion of simulated 95% confidence intervals falling within equivalence margins of 5% and 7.5% (equivalence tolerance). For both adjustment methods, the performance worsened with higher selection bias and lower response rate and generally improved as a larger proportion of villages was sampled. Under the worst scenario with 1.5 OR, 25% village sampled, and 50% survey response rate, both methods showed empirical biases of 2.1% or less, below 95% coverage, and low equivalence tolerances. In more realistic scenarios, the performance of our estimators showed lower biases and close to 95% coverage. For example, at OR$\\leq$1.2, both methods showed high performance, except at the lowest village sampling and participation rates. Our simulations show that a hybrid anchoring survey approach is a feasible survey option for vaccine monitoring.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u4f7f\u7528\u6821\u51c6\u52a0\u6743\u8bbe\u8ba1\u6cd5\u548c\u903b\u8f91\u56de\u5f52\u63d2\u8865\u6cd5\u6765\u4f30\u8ba1MCV1\u75ab\u82d7\u8986\u76d6\u7387\u7684\u6df7\u5408\u8c03\u67e5\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u975e\u6982\u7387\u968f\u8bbf\u8c03\u67e5\u4e0e\u6982\u7387\u57fa\u7ebf\u666e\u67e5\u76f8\u7ed3\u5408\u4ee5\u6821\u6b63\u9009\u62e9\u504f\u501a\u3002", "motivation": "\u5728\u4e4d\u5f97\u548c\u5c3c\u65e5\u5c14\u519c\u6751\u5730\u533a\u513f\u7ae5\u75ab\u82d7\u76d1\u6d4b\u9879\u76ee\u7684\u80cc\u666f\u4e0b\uff0c\u9700\u8981\u66f4\u7ecf\u6d4e\u5b9e\u7528\u7684\u75ab\u82d7\u8986\u76d6\u7387\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ee5\u66ff\u4ee3\u4f20\u7edf\u6982\u7387\u8c03\u67e5\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u6a21\u62df\u7814\u7a76\uff0c\u8bc4\u4f30\u6821\u51c6\u52a0\u6743\u8bbe\u8ba1\u6cd5\u548c\u903b\u8f91\u56de\u5f52\u63d2\u8865\u6cd5\uff0c\u8003\u8651\u4e0d\u540c\u7a0b\u5ea6\u7684\u9009\u62e9\u504f\u501a(OR 1.0-1.5)\u3001\u6751\u5e84\u62bd\u6837\u6bd4\u4f8b(25-75%)\u548c\u8c03\u67e5\u54cd\u5e94\u7387(50-80%)\u3002", "result": "\u5728\u8f83\u73b0\u5b9e\u7684\u573a\u666f\u4e2d(OR\u22641.2)\uff0c\u4e24\u79cd\u65b9\u6cd5\u8868\u73b0\u826f\u597d\uff0c\u504f\u5dee\u8f83\u4f4e\u4e14\u8986\u76d6\u7387\u63a5\u8fd195%\u3002\u5728\u6700\u5dee\u573a\u666f\u4e0b(OR=1.5, 25%\u6751\u5e84\u62bd\u6837, 50%\u54cd\u5e94\u7387)\uff0c\u504f\u5dee\u4ecd\u22642.1%\u3002", "conclusion": "\u6df7\u5408\u951a\u5b9a\u8c03\u67e5\u65b9\u6cd5\u662f\u75ab\u82d7\u76d1\u6d4b\u7684\u53ef\u884c\u9009\u62e9\uff0c\u7279\u522b\u662f\u5728\u9009\u62e9\u504f\u501a\u8f83\u5c0f\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.19580", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.19580", "abs": "https://arxiv.org/abs/2511.19580", "authors": ["Mutlu Cukurova", "Wannapon Suraworachet", "Qi Zhou", "Sahan Bulathwela"], "title": "Towards Synergistic Teacher-AI Interactions with Generative Artificial Intelligence", "comment": "18 pages, 6 pages", "summary": "Generative artificial intelligence (GenAI) is increasingly used in education, posing significant challenges for teachers adapting to these changes. GenAI offers unprecedented opportunities for accessibility, scalability and productivity in educational tasks. However, the automation of teaching tasks through GenAI raises concerns about reduced teacher agency, potential cognitive atrophy, and the broader deprofessionalisation of teaching. Drawing findings from prior literature on AI in Education, and refining through a recent systematic literature review, this chapter presents a conceptualisation of five levels of teacher-AI teaming: transactional, situational, operational, praxical and synergistic teaming. The framework aims to capture the nuanced dynamics of teacher-AI interactions, particularly with GenAI, that may lead to the replacement, complementarity, or augmentation of teachers' competences and professional practice. GenAI technological affordances required in supporting teaming, along with empirical studies, are discussed. Drawing on empirical observations, we outline a future vision that moves beyond individual teacher agency toward collaborative decision-making between teachers and AI, in which both agents engage in negotiation, constructive challenge, and co-reasoning that enhance each other's capabilities and enable outcomes neither could realise independently. Further discussion of socio-technical factors beyond teacher-AI teaming is also included to streamline the synergy of teachers and AI in education ethically and practically.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6559\u5e08\u4e0e\u751f\u6210\u5f0fAI\u534f\u4f5c\u7684\u4e94\u5c42\u6b21\u6846\u67b6\uff0c\u63a2\u8ba8\u4e86GenAI\u5728\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u5bf9\u6559\u5e08\u4e13\u4e1a\u5b9e\u8df5\u7684\u5f71\u54cd\uff0c\u4ece\u66ff\u4ee3\u5230\u4e92\u8865\u518d\u5230\u80fd\u529b\u589e\u5f3a\u7684\u4e0d\u540c\u53ef\u80fd\u6027\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u6559\u80b2\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u7ed9\u6559\u5e08\u5e26\u6765\u4e86\u9002\u5e94\u6311\u6218\uff0c\u867d\u7136\u63d0\u4f9b\u4e86\u53ef\u8bbf\u95ee\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u751f\u4ea7\u529b\u7684\u673a\u4f1a\uff0c\u4f46\u4e5f\u5f15\u53d1\u4e86\u6559\u5e08\u81ea\u4e3b\u6743\u51cf\u5c11\u3001\u8ba4\u77e5\u9000\u5316\u548c\u6559\u5e08\u804c\u4e1a\u53bb\u4e13\u4e1a\u5316\u7b49\u62c5\u5fe7\u3002", "method": "\u57fa\u4e8e\u5148\u524dAI\u6559\u80b2\u6587\u732e\u548c\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u6784\u5efa\u4e86\u6559\u5e08-AI\u534f\u4f5c\u7684\u4e94\u5c42\u6b21\u6982\u5ff5\u6846\u67b6\uff1a\u4ea4\u6613\u6027\u3001\u60c5\u5883\u6027\u3001\u64cd\u4f5c\u6027\u3001\u5b9e\u8df5\u6027\u548c\u534f\u540c\u6027\u534f\u4f5c\u3002", "result": "\u63d0\u51fa\u4e86\u652f\u6301\u6559\u5e08-AI\u534f\u4f5c\u6240\u9700\u7684\u6280\u672f\u6761\u4ef6\uff0c\u5e76\u57fa\u4e8e\u5b9e\u8bc1\u89c2\u5bdf\u63cf\u7ed8\u4e86\u8d85\u8d8a\u4e2a\u4f53\u6559\u5e08\u81ea\u4e3b\u6743\u7684\u672a\u6765\u613f\u666f\uff0c\u5f3a\u8c03\u6559\u5e08\u4e0eAI\u4e4b\u95f4\u7684\u534f\u4f5c\u51b3\u7b56\u3001\u534f\u5546\u548c\u5171\u540c\u63a8\u7406\u3002", "conclusion": "\u9700\u8981\u8d85\u8d8a\u6559\u5e08-AI\u534f\u4f5c\u7684\u793e\u4f1a\u6280\u672f\u56e0\u7d20\u8003\u91cf\uff0c\u4ee5\u786e\u4fdd\u6559\u5e08\u4e0eAI\u5728\u6559\u80b2\u4e2d\u7684\u534f\u540c\u4f5c\u7528\u5728\u4f26\u7406\u548c\u5b9e\u8df5\u4e0a\u90fd\u80fd\u5b9e\u73b0\uff0c\u8fbe\u5230\u53cc\u65b9\u5355\u72ec\u65e0\u6cd5\u5b9e\u73b0\u7684\u6210\u679c\u3002"}}
{"id": "2511.19454", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19454", "abs": "https://arxiv.org/abs/2511.19454", "authors": ["Xiubin Chen"], "title": "A K-means Inspired Solution Framework for Large-Scale Multi-Traveling Salesman Problems", "comment": null, "summary": "The Multi-Traveling Salesman Problem (MTSP) is a commonly used mathematical model for multi-agent task allocation. However, as the number of agents and task targets increases, existing optimization-based methods often incur prohibitive computational costs, posing significant challenges to large-scale coordination in unmanned systems. To address this issue, this paper proposes a K-means-inspired task allocation framework that reformulates the MTSP as a spatially constrained classification process. By leveraging spatial coherence, the proposed method enables fast estimation of path costs and efficient task grouping, thereby fundamentally reducing overall computational complexity. Extensive simulation results demonstrate that the framework can maintain high solution quality even in extremely large-scale scenarios-for instance, in tasks involving 1000 agents and 5000 targets. The findings indicate that this \"cluster-then-route\" decomposition strategy offers an efficient and reliable solution for large-scale multi-agent task allocation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eK-means\u7684\u4efb\u52a1\u5206\u914d\u6846\u67b6\uff0c\u5c06\u591a\u65c5\u884c\u5546\u95ee\u9898\u91cd\u6784\u4e3a\u7a7a\u95f4\u7ea6\u675f\u5206\u7c7b\u8fc7\u7a0b\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u573a\u666f\uff08\u59821000\u4e2a\u667a\u80fd\u4f53\u548c5000\u4e2a\u76ee\u6807\uff09\u3002", "motivation": "\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u591a\u667a\u80fd\u4f53\u4efb\u52a1\u5206\u914d\u65f6\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u96be\u4ee5\u6ee1\u8db3\u65e0\u4eba\u7cfb\u7edf\u5927\u89c4\u6a21\u534f\u8c03\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\"\u5148\u805a\u7c7b\u540e\u8def\u7531\"\u7684\u5206\u89e3\u7b56\u7565\uff0c\u5229\u7528\u7a7a\u95f4\u76f8\u5e72\u6027\u5feb\u901f\u4f30\u8ba1\u8def\u5f84\u6210\u672c\u5e76\u9ad8\u6548\u5206\u7ec4\u4efb\u52a1\uff0c\u5c06MTSP\u91cd\u6784\u4e3a\u7a7a\u95f4\u7ea6\u675f\u5206\u7c7b\u95ee\u9898\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u6781\u5927\u89c4\u6a21\u573a\u666f\u4e0b\u4ecd\u80fd\u4fdd\u6301\u9ad8\u8d28\u91cf\u89e3\uff0c\u8ba1\u7b97\u6548\u7387\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8fd9\u79cd\u57fa\u4e8e\u805a\u7c7b\u7684\u5206\u89e3\u7b56\u7565\u4e3a\u5927\u89c4\u6a21\u591a\u667a\u80fd\u4f53\u4efb\u52a1\u5206\u914d\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19651", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19651", "abs": "https://arxiv.org/abs/2511.19651", "authors": ["Lishuo Pan", "Mattia Catellani", "Thales C. Silva", "Lorenzo Sabattini", "Nora Ayanian"], "title": "Online Learning-Enhanced High Order Adaptive Safety Control", "comment": "8 pages, 7 figures, submitted to RA-L", "summary": "Control barrier functions (CBFs) are an effective model-based tool to formally certify the safety of a system. With the growing complexity of modern control problems, CBFs have received increasing attention in both optimization-based and learning-based control communities as a safety filter, owing to their provable guarantees. However, success in transferring these guarantees to real-world systems is critically tied to model accuracy. For example, payloads or wind disturbances can significantly influence the dynamics of an aerial vehicle and invalidate the safety guarantee. In this work, we propose an efficient yet flexible online learning-enhanced high-order adaptive control barrier function using Neural ODEs. Our approach improves the safety of a CBF-certified system on the fly, even under complex time-varying model perturbations. In particular, we deploy our hybrid adaptive CBF controller on a 38g nano quadrotor, keeping a safe distance from the obstacle, against 18km/h wind.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecfODE\u7684\u5728\u7ebf\u5b66\u4e60\u589e\u5f3a\u9ad8\u9636\u81ea\u9002\u5e94\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u590d\u6742\u65f6\u53d8\u6a21\u578b\u6270\u52a8\u4e0b\u5b9e\u65f6\u63d0\u9ad8CBF\u8ba4\u8bc1\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u5e76\u572838g\u7eb3\u7c73\u56db\u65cb\u7ffc\u4e0a\u6210\u529f\u9a8c\u8bc1\uff0c\u572818km/h\u98ce\u901f\u4e0b\u4fdd\u6301\u4e0e\u969c\u788d\u7269\u7684\u5b89\u5168\u8ddd\u79bb\u3002", "motivation": "\u63a7\u5236\u5c4f\u969c\u51fd\u6570(CBFs)\u662f\u4fdd\u8bc1\u7cfb\u7edf\u5b89\u5168\u6027\u7684\u6709\u6548\u5de5\u5177\uff0c\u4f46\u5176\u5b89\u5168\u4fdd\u8bc1\u7684\u6210\u529f\u8f6c\u79fb\u5230\u73b0\u5b9e\u7cfb\u7edf\u4e25\u91cd\u4f9d\u8d56\u4e8e\u6a21\u578b\u51c6\u786e\u6027\u3002\u6709\u6548\u8f7d\u8377\u6216\u98ce\u6270\u52a8\u7b49\u4f1a\u663e\u8457\u5f71\u54cd\u98de\u884c\u5668\u52a8\u529b\u5b66\u5e76\u4f7f\u5b89\u5168\u4fdd\u8bc1\u5931\u6548\u3002", "method": "\u4f7f\u7528\u795e\u7ecfODE\u5f00\u53d1\u9ad8\u6548\u7684\u5728\u7ebf\u5b66\u4e60\u589e\u5f3a\u9ad8\u9636\u81ea\u9002\u5e94\u63a7\u5236\u5c4f\u969c\u51fd\u6570\uff0c\u7ed3\u5408\u6df7\u5408\u81ea\u9002\u5e94CBF\u63a7\u5236\u5668\u3002", "result": "\u572838g\u7eb3\u7c73\u56db\u65cb\u7ffc\u4e0a\u6210\u529f\u90e8\u7f72\uff0c\u572818km/h\u98ce\u901f\u4e0b\u80fd\u591f\u4fdd\u6301\u4e0e\u969c\u788d\u7269\u7684\u5b89\u5168\u8ddd\u79bb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u590d\u6742\u65f6\u53d8\u6a21\u578b\u6270\u52a8\u4e0b\u5b9e\u65f6\u63d0\u9ad8CBF\u8ba4\u8bc1\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u7cfb\u7edf\u7684\u5b89\u5168\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19671", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19671", "abs": "https://arxiv.org/abs/2511.19671", "authors": ["Rishab Sharma", "Iman Saberi", "Elham Alipour", "Jie JW Wu", "Fatemeh Fard"], "title": "FISCAL: Financial Synthetic Claim-document Augmented Learning for Efficient Fact-Checking", "comment": "3 tables, 11 pages, 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Generative AI in Finance", "summary": "Financial applications of large language models (LLMs) require factual reliability and computational efficiency, yet current systems often hallucinate details and depend on prohibitively large models. We propose FISCAL (Financial Synthetic Claim-Document Augmented Learning), a modular framework for generating synthetic data tailored to financial fact-checking. Using FISCAL, we generate a dataset called FISCAL-data and use it to train MiniCheck-FISCAL, a lightweight verifier for numerical financial claims. MiniCheck-FISCAL outperforms its baseline, surpasses GPT-3.5 Turbo and other open-source peers of similar size, and approaches the accuracy of much larger systems (20x), such as Mixtral-8x22B and Command R+. On external datasets FinDVer and Fin-Fact, it rivals GPT-4o and Claude-3.5 while outperforming Gemini-1.5 Flash. These results show that domain-specific synthetic data, combined with efficient fine-tuning, enables compact models to achieve state-of-the-art accuracy, robustness, and scalability for practical financial AI. The dataset and scripts are available in the project repository (link provided in the paper).", "AI": {"tldr": "\u63d0\u51fa\u4e86FISCAL\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u91d1\u878d\u4e8b\u5b9e\u6838\u67e5\u7684\u5408\u6210\u6570\u636e\uff0c\u5e76\u8bad\u7ec3\u4e86\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668MiniCheck-FISCAL\uff0c\u5728\u591a\u4e2a\u91d1\u878d\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u63a5\u8fd1\u66f4\u5927\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u91d1\u878d\u5e94\u7528\u4e2d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4e8b\u5b9e\u53ef\u9760\u6027\u4e0d\u8db3\u548c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528FISCAL\u6846\u67b6\u751f\u6210\u91d1\u878d\u5408\u6210\u6570\u636eFISCAL-data\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668MiniCheck-FISCAL\u3002", "result": "MiniCheck-FISCAL\u5728\u591a\u4e2a\u91d1\u878d\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86GPT-3.5 Turbo\u548c\u7c7b\u4f3c\u89c4\u6a21\u7684\u5f00\u6e90\u6a21\u578b\uff0c\u63a5\u8fd1Mixtral-8x22B\u7b49\u592720\u500d\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u5728\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u4e0eGPT-4o\u548cClaude-3.5\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "\u9886\u57df\u7279\u5b9a\u7684\u5408\u6210\u6570\u636e\u7ed3\u5408\u9ad8\u6548\u5fae\u8c03\uff0c\u80fd\u4f7f\u7d27\u51d1\u6a21\u578b\u5728\u91d1\u878dAI\u5e94\u7528\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.20283", "categories": ["econ.GN", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20283", "abs": "https://arxiv.org/abs/2511.20283", "authors": ["Marta Grzeskiewicz"], "title": "Solving Heterogeneous Agent Models with Physics-informed Neural Networks", "comment": null, "summary": "Understanding household behaviour is essential for modelling macroeconomic dynamics and designing effective policy. While heterogeneous agent models offer a more realistic alternative to representative agent frameworks, their implementation poses significant computational challenges, particularly in continuous time. The Aiyagari-Bewley-Huggett (ABH) framework, recast as a system of partial differential equations, typically relies on grid-based solvers that suffer from the curse of dimensionality, high computational cost, and numerical inaccuracies. This paper introduces the ABH-PINN solver, an approach based on Physics-Informed Neural Networks (PINNs), which embeds the Hamilton-Jacobi-Bellman and Kolmogorov Forward equations directly into the neural network training objective. By replacing grid-based approximation with mesh-free, differentiable function learning, the ABH-PINN solver benefits from the advantages of PINNs of improved scalability, smoother solutions, and computational efficiency. Preliminary results show that the PINN-based approach is able to obtain economically valid results matching the established finite-difference solvers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc(PINNs)\u7684ABH-PINN\u6c42\u89e3\u5668\uff0c\u7528\u4e8e\u89e3\u51b3\u8fde\u7eed\u65f6\u95f4\u5f02\u8d28\u4ee3\u7406\u4eba\u6a21\u578b\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u7f51\u683c\u6c42\u89e3\u65b9\u6cd5\u3002", "motivation": "\u5f02\u8d28\u4ee3\u7406\u4eba\u6a21\u578b\u6bd4\u4ee3\u8868\u6027\u4ee3\u7406\u4eba\u6846\u67b6\u66f4\u73b0\u5b9e\uff0c\u4f46\u5728\u8fde\u7eed\u65f6\u95f4\u4e0b\u5b58\u5728\u663e\u8457\u8ba1\u7b97\u6311\u6218\u3002\u4f20\u7edf\u7684\u7f51\u683c\u6c42\u89e3\u5668\u9762\u4e34\u7ef4\u5ea6\u8bc5\u5492\u3001\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u6570\u503c\u4e0d\u51c6\u786e\u7b49\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc(PINNs)\uff0c\u5c06Hamilton-Jacobi-Bellman\u548cKolmogorov Forward\u65b9\u7a0b\u76f4\u63a5\u5d4c\u5165\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u76ee\u6807\uff0c\u7528\u65e0\u7f51\u683c\u3001\u53ef\u5fae\u5206\u51fd\u6570\u5b66\u4e60\u66ff\u4ee3\u7f51\u683c\u8fd1\u4f3c\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8ePINN\u7684\u65b9\u6cd5\u80fd\u591f\u83b7\u5f97\u7ecf\u6d4e\u4e0a\u6709\u6548\u7684\u7ed3\u679c\uff0c\u4e0e\u5df2\u5efa\u7acb\u7684\u6709\u9650\u5dee\u5206\u6c42\u89e3\u5668\u76f8\u5339\u914d\u3002", "conclusion": "ABH-PINN\u6c42\u89e3\u5668\u5177\u6709\u6539\u8fdb\u7684\u53ef\u6269\u5c55\u6027\u3001\u66f4\u5e73\u6ed1\u7684\u89e3\u51b3\u65b9\u6848\u548c\u8ba1\u7b97\u6548\u7387\u7b49PINNs\u4f18\u52bf\uff0c\u4e3a\u5f02\u8d28\u4ee3\u7406\u4eba\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u6c42\u89e3\u65b9\u6cd5\u3002"}}
{"id": "2511.20303", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2511.20303", "abs": "https://arxiv.org/abs/2511.20303", "authors": ["Chengfeng Shen", "Felix K\u00fcbler", "Zhennan Zhou"], "title": "Recursive contracts in non-convex environments", "comment": null, "summary": "In this paper we examine non-convex dynamic optimization problems with forward looking constraints. We prove that the recursive multiplier formulation in \\cite{marcet2019recursive} gives the optimal value if one assumes that the planner has access to a public randomization device and forward looking constraints only have to hold in expectations. Whether one formulates the functional equation as a sup-inf problem or as an inf-sup problem is essential for the timing of the optimal lottery and for determining which constraints have to hold in expectations. We discuss for which economic problems the use of lotteries can be considered a reasonable assumption. We provide a general method to recover the optimal policy from a solution of the functional equation. As an application of our results, we consider the Ramsey problem of optimal government policy and give examples where lotteries are essential for the optimal solution.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5177\u6709\u524d\u77bb\u6027\u7ea6\u675f\u7684\u975e\u51f8\u52a8\u6001\u4f18\u5316\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5728\u5047\u8bbe\u89c4\u5212\u8005\u53ef\u4ee5\u4f7f\u7528\u516c\u5171\u968f\u673a\u5316\u8bbe\u5907\u4e14\u524d\u77bb\u6027\u7ea6\u675f\u53ea\u9700\u5728\u671f\u671b\u4e2d\u6210\u7acb\u7684\u60c5\u51b5\u4e0b\uff0c\u9012\u5f52\u4e58\u5b50\u516c\u5f0f\u7ed9\u51fa\u6700\u4f18\u503c\u3002", "motivation": "\u7814\u7a76\u975e\u51f8\u52a8\u6001\u4f18\u5316\u95ee\u9898\u4e2d\u524d\u77bb\u6027\u7ea6\u675f\u7684\u5904\u7406\u65b9\u6cd5\uff0c\u63a2\u8ba8\u968f\u673a\u5316\u5728\u89e3\u51b3\u6b64\u7c7b\u95ee\u9898\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u4f7f\u7528\u9012\u5f52\u4e58\u5b50\u516c\u5f0f\uff0c\u5206\u6790sup-inf\u548cinf-sup\u95ee\u9898\u8868\u8ff0\u5bf9\u6700\u4f18\u5f69\u7968\u65f6\u673a\u548c\u7ea6\u675f\u671f\u671b\u503c\u7684\u5f71\u54cd\uff0c\u63d0\u4f9b\u4ece\u51fd\u6570\u65b9\u7a0b\u89e3\u4e2d\u6062\u590d\u6700\u4f18\u7b56\u7565\u7684\u4e00\u822c\u65b9\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u516c\u5171\u968f\u673a\u5316\u8bbe\u5907\u548c\u671f\u671b\u7ea6\u675f\u6761\u4ef6\u4e0b\uff0c\u9012\u5f52\u4e58\u5b50\u516c\u5f0f\u80fd\u7ed9\u51fa\u6700\u4f18\u503c\uff0c\u5e76\u5c55\u793a\u4e86\u5f69\u7968\u5728\u67d0\u4e9b\u7ecf\u6d4e\u95ee\u9898\u4e2d\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u5f69\u7968\u7684\u4f7f\u7528\u5bf9\u4e8e\u67d0\u4e9b\u7ecf\u6d4e\u95ee\u9898\u7684\u4f18\u5316\u89e3\u662f\u5fc5\u8981\u7684\uff0c\u7279\u522b\u662f\u5728Ramsey\u6700\u4f18\u653f\u5e9c\u653f\u7b56\u95ee\u9898\u4e2d\uff0c\u5f69\u7968\u5728\u6700\u4f18\u89e3\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2511.20069", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.20069", "abs": "https://arxiv.org/abs/2511.20069", "authors": ["D\u00e1ire Healy", "Ilaria Prosdocimi", "Isadora Antoniano-Villalobos"], "title": "Non-stationarities in extreme hourly precipitation over the Piave Basin, northern Italy", "comment": null, "summary": "We study the spatio-temporal features of extremal sub-daily precipitation data over the Piave river basin in northeast Italy using a rich database of observed hourly rainfall. Empirical evidence suggests that both the marginal and dependence structures for extreme precipitation in the area exhibit seasonal patterns, and spatial dependence appears to weaken as events become more extreme. We investigate factors affecting the marginal distributions, the spatial dependence and the interplay between them. Capturing these features is essential to provide a realistic description of extreme precipitation processes in order to better estimate their associated risks. With this aim, we identify various climatic covariates at different spatio-temporal scales and explore their usefulness. We go beyond existing literature by investigating and comparing the performance of recently proposed covariate-dependent models for both the marginal and dependence structures of extremes. Furthermore, a flexible max-id model, which encompasses both asymptotic dependence and independence, is used to learn about the spatio-temporal variability of rainfall processes at extreme levels. We find that modelling non-stationarity only at the marginal level does not fully capture the variability of precipitation extremes, and that it is important to also capture the seasonal variation of extremal dependence.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u610f\u5927\u5229\u76ae\u4e9a\u97e6\u6cb3\u6d41\u57df\u6781\u7aef\u5c0f\u65f6\u964d\u6c34\u7684\u65f6\u7a7a\u7279\u5f81\uff0c\u53d1\u73b0\u8fb9\u9645\u5206\u5e03\u548c\u7a7a\u95f4\u4f9d\u8d56\u7ed3\u6784\u5b58\u5728\u5b63\u8282\u6027\u6a21\u5f0f\uff0c\u4e14\u6781\u7aef\u4e8b\u4ef6\u7684\u7a7a\u95f4\u4f9d\u8d56\u968f\u4e8b\u4ef6\u6781\u7aef\u7a0b\u5ea6\u589e\u52a0\u800c\u51cf\u5f31\u3002\u7814\u7a76\u6bd4\u8f83\u4e86\u591a\u79cd\u534f\u53d8\u91cf\u4f9d\u8d56\u6a21\u578b\uff0c\u53d1\u73b0\u4ec5\u5efa\u6a21\u8fb9\u9645\u975e\u5e73\u7a33\u6027\u4e0d\u8db3\u4ee5\u5b8c\u5168\u6355\u6349\u6781\u7aef\u964d\u6c34\u7684\u53d8\u5f02\u6027\u3002", "motivation": "\u51c6\u786e\u63cf\u8ff0\u6781\u7aef\u964d\u6c34\u8fc7\u7a0b\u7684\u65f6\u7a7a\u7279\u5f81\u5bf9\u4e8e\u66f4\u597d\u5730\u8bc4\u4f30\u76f8\u5173\u98ce\u9669\u81f3\u5173\u91cd\u8981\uff0c\u73b0\u6709\u7814\u7a76\u5728\u540c\u65f6\u5efa\u6a21\u8fb9\u9645\u548c\u4f9d\u8d56\u7ed3\u6784\u7684\u975e\u5e73\u7a33\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u89c2\u6d4b\u7684\u5c0f\u65f6\u964d\u96e8\u6570\u636e\uff0c\u8bc6\u522b\u4e0d\u540c\u65f6\u7a7a\u5c3a\u5ea6\u7684\u6c14\u5019\u534f\u53d8\u91cf\uff0c\u6bd4\u8f83\u4e86\u6700\u8fd1\u63d0\u51fa\u7684\u534f\u53d8\u91cf\u4f9d\u8d56\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u7075\u6d3b\u7684max-id\u6a21\u578b\u6765\u5b66\u4e60\u6781\u7aef\u6c34\u5e73\u4e0b\u964d\u6c34\u8fc7\u7a0b\u7684\u65f6\u7a7a\u53d8\u5f02\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8fb9\u9645\u5206\u5e03\u548c\u6781\u503c\u4f9d\u8d56\u90fd\u5b58\u5728\u5b63\u8282\u6027\u53d8\u5316\uff0c\u7a7a\u95f4\u4f9d\u8d56\u968f\u4e8b\u4ef6\u6781\u7aef\u7a0b\u5ea6\u589e\u52a0\u800c\u51cf\u5f31\u3002\u4ec5\u5efa\u6a21\u8fb9\u9645\u975e\u5e73\u7a33\u6027\u4e0d\u80fd\u5b8c\u5168\u6355\u6349\u6781\u7aef\u964d\u6c34\u7684\u53d8\u5f02\u6027\uff0c\u9700\u8981\u540c\u65f6\u6355\u6349\u6781\u503c\u4f9d\u8d56\u7684\u5b63\u8282\u6027\u53d8\u5316\u3002", "conclusion": "\u4e3a\u4e86\u51c6\u786e\u63cf\u8ff0\u6781\u7aef\u964d\u6c34\u8fc7\u7a0b\uff0c\u9700\u8981\u540c\u65f6\u8003\u8651\u8fb9\u9645\u5206\u5e03\u548c\u4f9d\u8d56\u7ed3\u6784\u7684\u975e\u5e73\u7a33\u6027\uff0c\u7279\u522b\u662f\u6781\u503c\u4f9d\u8d56\u7684\u5b63\u8282\u6027\u53d8\u5316\u7279\u5f81\u3002"}}
{"id": "2511.19688", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.19688", "abs": "https://arxiv.org/abs/2511.19688", "authors": ["Paula Lackie", "Elliot Pickens", "Dashiell Coyier"], "title": "The DataSquad Experiment: Lessons for Preparing Data and Computer Scientists for Work", "comment": null, "summary": "The DataSquad at Carleton College addresses a common problem at small liberal arts colleges: limited capacity for data services and few opportunities for students to gain practical experience with data and software development. Academic Technologist Paula Lackie designed the program as a work-study position that trains undergraduates through structured peer mentorship and real client projects. Students tackle data problems of increasing complexity-from basic data analysis to software development-while learning FAIR data principles and open science practices. The model's core components (peer mentorship structure, project-based learning, and communication training) make it adaptable to other institutions. UCLA and other colleges have adopted the model using openly shared materials through \"DataSquad International.\" This paper describes the program's implementation at Carleton College and examines how structured peer mentorship can simultaneously improve institutional data services and provide students with professional skills and confidence.", "AI": {"tldr": "Carleton College\u7684DataSquad\u9879\u76ee\u901a\u8fc7\u7ed3\u6784\u5316\u540c\u4f34\u6307\u5bfc\u548c\u771f\u5b9e\u5ba2\u6237\u9879\u76ee\uff0c\u89e3\u51b3\u6587\u7406\u5b66\u9662\u6570\u636e\u670d\u52a1\u80fd\u529b\u6709\u9650\u548c\u5b66\u751f\u5b9e\u8df5\u7ecf\u9a8c\u7f3a\u4e4f\u7684\u95ee\u9898\uff0c\u57f9\u517b\u672c\u79d1\u751f\u6570\u636e\u6280\u80fd\u3002", "motivation": "\u5c0f\u578b\u6587\u7406\u5b66\u9662\u6570\u636e\u670d\u52a1\u80fd\u529b\u6709\u9650\uff0c\u5b66\u751f\u7f3a\u4e4f\u6570\u636e\u5b9e\u8df5\u673a\u4f1a\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u6301\u7eed\u7684\u6570\u636e\u670d\u52a1\u6a21\u5f0f\u540c\u65f6\u57f9\u517b\u5b66\u751f\u4e13\u4e1a\u6280\u80fd\u3002", "method": "\u91c7\u7528\u5e26\u85aa\u5de5\u4f5c\u5b66\u4e60\u804c\u4f4d\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u540c\u4f34\u6307\u5bfc\u3001\u57fa\u4e8e\u9879\u76ee\u7684\u5b66\u4e60\u548c\u6c9f\u901a\u57f9\u8bad\uff0c\u8ba9\u5b66\u751f\u4ece\u57fa\u7840\u6570\u636e\u5206\u6790\u9010\u6b65\u8fc7\u6e21\u5230\u8f6f\u4ef6\u5f00\u53d1\u3002", "result": "\u9879\u76ee\u6210\u529f\u5b9e\u65bd\uff0cUCLA\u7b49\u9662\u6821\u901a\u8fc7\"DataSquad International\"\u91c7\u7528\u8be5\u6a21\u5f0f\uff0c\u4f7f\u7528\u516c\u5f00\u5171\u4eab\u6750\u6599\u3002", "conclusion": "\u7ed3\u6784\u5316\u540c\u4f34\u6307\u5bfc\u80fd\u540c\u65f6\u63d0\u5347\u673a\u6784\u6570\u636e\u670d\u52a1\u6c34\u5e73\u548c\u5b66\u751f\u4e13\u4e1a\u80fd\u529b\u4e0e\u81ea\u4fe1\u5fc3\uff0c\u8be5\u6a21\u5f0f\u5177\u6709\u53ef\u79fb\u690d\u6027\u3002"}}
{"id": "2511.19522", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19522", "abs": "https://arxiv.org/abs/2511.19522", "authors": ["Jinming Gao", "Yijing Wang", "Wentao Zhang", "Rui Zhao", "Yang Shi", "Zhiqiang Zuo"], "title": "Active Secure Neighbor Selection in Multi-Agent Systems with Byzantine Attacks", "comment": null, "summary": "This paper investigates the problem of resilient control for multi-agent systems in the presence of Byzantine adversaries via an active secure neighbor selection framework. A pre-discriminative graph is first constructed to characterize the admissible set of candidate neighbors for each agent. Based on this graph, a dynamic in-neighbor selection strategy is proposed, wherein each agent actively selects a subset of its pre-discriminative neighbors. The number of selected neighbors is adjustable, allowing for a trade-off between communication overhead and robustness, with the minimal case requiring only a single in-neighbor. The proposed strategy facilitates the reconstruction of a directed spanning tree among normal agents following the detection and isolation of Byzantine agents. It achieves resilient consensus without imposing any assumptions on the initial connectivity among normal agents. Moreover, the approach significantly reduces communication burden while maintaining resilience to adversarial behavior. A numerical example is provided to illustrate the effectiveness of the proposed method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e3b\u52a8\u5b89\u5168\u90bb\u5c45\u9009\u62e9\u6846\u67b6\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5f39\u6027\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u9884\u5224\u522b\u56fe\u5e76\u52a8\u6001\u9009\u62e9\u90bb\u5c45\uff0c\u5728\u62dc\u5360\u5ead\u653b\u51fb\u4e0b\u5b9e\u73b0\u5f39\u6027\u5171\u8bc6\uff0c\u540c\u65f6\u964d\u4f4e\u901a\u4fe1\u8d1f\u62c5\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u5b58\u5728\u62dc\u5360\u5ead\u654c\u5bf9\u8005\u65f6\u7684\u5f39\u6027\u63a7\u5236\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u8f83\u5f3a\u7684\u521d\u59cb\u8fde\u901a\u6027\u5047\u8bbe\u4e14\u901a\u4fe1\u5f00\u9500\u8f83\u5927\u3002", "method": "\u9996\u5148\u6784\u5efa\u9884\u5224\u522b\u56fe\u5b9a\u4e49\u5019\u9009\u90bb\u5c45\u96c6\uff0c\u7136\u540e\u63d0\u51fa\u52a8\u6001\u5165\u90bb\u5c45\u9009\u62e9\u7b56\u7565\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u4e3b\u52a8\u9009\u62e9\u9884\u5224\u522b\u90bb\u5c45\u7684\u5b50\u96c6\uff0c\u9009\u62e9\u6570\u91cf\u53ef\u8c03\u4ee5\u5e73\u8861\u901a\u4fe1\u5f00\u9500\u548c\u9c81\u68d2\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u68c0\u6d4b\u548c\u9694\u79bb\u62dc\u5360\u5ead\u667a\u80fd\u4f53\u540e\uff0c\u5728\u6b63\u5e38\u667a\u80fd\u4f53\u95f4\u91cd\u5efa\u6709\u5411\u751f\u6210\u6811\uff0c\u5b9e\u73b0\u5f39\u6027\u5171\u8bc6\uff0c\u4e14\u4e0d\u8981\u6c42\u6b63\u5e38\u667a\u80fd\u4f53\u95f4\u7684\u521d\u59cb\u8fde\u901a\u6027\u5047\u8bbe\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e3b\u52a8\u5b89\u5168\u90bb\u5c45\u9009\u62e9\u6846\u67b6\u6709\u6548\u964d\u4f4e\u4e86\u901a\u4fe1\u8d1f\u62c5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5bf9\u654c\u5bf9\u884c\u4e3a\u7684\u5f39\u6027\uff0c\u6570\u503c\u793a\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.19653", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19653", "abs": "https://arxiv.org/abs/2511.19653", "authors": ["Mahmud Suhaimi Ibrahim", "Shantanu Rahman", "Muhammad Samin Hasan", "Minhaj Uddin Ahmad", "Abdullah Abrar"], "title": "Flow-Based Path Planning for Multiple Homogenous UAVs for Outdoor Formation-Flying", "comment": "9 pages, 15 figures, conference", "summary": "Collision-free path planning is the most crucial component in multi-UAV formation-flying (MFF). We use unlabeled homogenous quadcopters (UAVs) to demonstrate the use of a flow network to create complete (inter-UAV) collision-free paths. This procedure has three main parts: 1) Creating a flow network graph from physical GPS coordinates, 2) Finding a path of minimum cost (least distance) using any graph-based path-finding algorithm, and 3) Implementing the Ford-Fulkerson Method to find the paths with the maximum flow (no collision). Simulations of up to 64 UAVs were conducted for various formations, followed by a practical experiment with 3 quadcopters for testing physical plausibility and feasibility. The results of these tests show the efficacy of this method's ability to produce safe, collision-free paths.", "AI": {"tldr": "\u4f7f\u7528\u6d41\u7f51\u7edc\u65b9\u6cd5\u4e3a\u591a\u65e0\u4eba\u673a\u7f16\u961f\u98de\u884c\u89c4\u5212\u65e0\u78b0\u649e\u8def\u5f84\uff0c\u5305\u542b\u4e09\u4e2a\u4e3b\u8981\u6b65\u9aa4\uff1a\u6784\u5efa\u6d41\u7f51\u7edc\u56fe\u3001\u5bfb\u627e\u6700\u5c0f\u6210\u672c\u8def\u5f84\u3001\u5e94\u7528Ford-Fulkerson\u65b9\u6cd5\u786e\u4fdd\u6700\u5927\u6d41\u91cf\uff08\u65e0\u78b0\u649e\uff09\u3002", "motivation": "\u591a\u65e0\u4eba\u673a\u7f16\u961f\u98de\u884c\u4e2d\uff0c\u65e0\u78b0\u649e\u8def\u5f84\u89c4\u5212\u662f\u6700\u5173\u952e\u7684\u7ec4\u6210\u90e8\u5206\uff0c\u9700\u8981\u786e\u4fdd\u540c\u8d28\u65e0\u4eba\u673a\u5728\u98de\u884c\u8fc7\u7a0b\u4e2d\u4e0d\u4f1a\u76f8\u4e92\u78b0\u649e\u3002", "method": "1) \u4ece\u7269\u7406GPS\u5750\u6807\u6784\u5efa\u6d41\u7f51\u7edc\u56fe\uff1b2) \u4f7f\u7528\u56fe\u57fa\u8def\u5f84\u5bfb\u627e\u7b97\u6cd5\u627e\u5230\u6700\u5c0f\u6210\u672c\uff08\u6700\u77ed\u8ddd\u79bb\uff09\u8def\u5f84\uff1b3) \u5b9e\u65bdFord-Fulkerson\u65b9\u6cd5\u627e\u5230\u5177\u6709\u6700\u5927\u6d41\u91cf\uff08\u65e0\u78b0\u649e\uff09\u7684\u8def\u5f84\u3002", "result": "\u5bf9\u6700\u591a64\u67b6\u65e0\u4eba\u673a\u8fdb\u884c\u4e86\u5404\u79cd\u7f16\u961f\u7684\u6a21\u62df\uff0c\u968f\u540e\u75283\u67b6\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u8fdb\u884c\u4e86\u5b9e\u9645\u5b9e\u9a8c\u3002\u6d4b\u8bd5\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u751f\u6210\u5b89\u5168\u7684\u65e0\u78b0\u649e\u8def\u5f84\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4e3a\u591a\u65e0\u4eba\u673a\u7f16\u961f\u98de\u884c\u4ea7\u751f\u5b89\u5168\u3001\u65e0\u78b0\u649e\u7684\u8def\u5f84\uff0c\u8bc1\u660e\u4e86\u5176\u7269\u7406\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2511.19749", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19749", "abs": "https://arxiv.org/abs/2511.19749", "authors": ["Farzan Karimi-Malekabadi", "Pooya Razavi", "Sonya Powers"], "title": "Scaling Item-to-Standard Alignment with Large Language Models: Accuracy, Limits, and Solutions", "comment": null, "summary": "As educational systems evolve, ensuring that assessment items remain aligned with content standards is essential for maintaining fairness and instructional relevance. Traditional human alignment reviews are accurate but slow and labor-intensive, especially across large item banks. This study examines whether Large Language Models (LLMs) can accelerate this process without sacrificing accuracy. Using over 12,000 item-skill pairs in grades K-5, we tested three LLMs (GPT-3.5 Turbo, GPT-4o-mini, and GPT-4o) across three tasks that mirror real-world challenges: identifying misaligned items, selecting the correct skill from the full set of standards, and narrowing candidate lists prior to classification. In Study 1, GPT-4o-mini correctly identified alignment status in approximately 83-94% of cases, including subtle misalignments. In Study 2, performance remained strong in mathematics but was lower for reading, where standards are more semantically overlapping. Study 3 demonstrated that pre-filtering candidate skills substantially improved results, with the correct skill appearing among the top five suggestions more than 95% of the time. These findings suggest that LLMs, particularly when paired with candidate filtering strategies, can significantly reduce the manual burden of item review while preserving alignment accuracy. We recommend the development of hybrid pipelines that combine LLM-based screening with human review in ambiguous cases, offering a scalable solution for ongoing item validation and instructional alignment.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u52a0\u901f\u6559\u80b2\u8bc4\u4f30\u9879\u76ee\u4e0e\u5185\u5bb9\u6807\u51c6\u5bf9\u9f50\u8fc7\u7a0b\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u901a\u8fc7\u4e09\u4e2a\u5b9e\u9a8c\u9a8c\u8bc1\u4e86LLMs\u5728\u8bc6\u522b\u9519\u8bef\u5bf9\u9f50\u9879\u76ee\u3001\u9009\u62e9\u6b63\u786e\u6280\u80fd\u6807\u51c6\u4ee5\u53ca\u9884\u7b5b\u9009\u5019\u9009\u6280\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u4eba\u5de5\u5bf9\u9f50\u8bc4\u5ba1\u867d\u7136\u51c6\u786e\u4f46\u8017\u65f6\u8017\u529b\uff0c\u7279\u522b\u662f\u5728\u5927\u578b\u9879\u76ee\u5e93\u4e2d\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLMs\u662f\u5426\u80fd\u52a0\u901f\u8fd9\u4e00\u8fc7\u7a0b\u800c\u4e0d\u727a\u7272\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u8d85\u8fc712,000\u4e2aK-5\u5e74\u7ea7\u7684\u9879\u76ee-\u6280\u80fd\u5bf9\uff0c\u6d4b\u8bd5\u4e86\u4e09\u79cdLLM\u6a21\u578b(GPT-3.5 Turbo\u3001GPT-4o-mini\u548cGPT-4o)\uff0c\u6db5\u76d6\u4e09\u4e2a\u4efb\u52a1\uff1a\u8bc6\u522b\u9519\u8bef\u5bf9\u9f50\u9879\u76ee\u3001\u4ece\u5b8c\u6574\u6807\u51c6\u96c6\u4e2d\u9009\u62e9\u6b63\u786e\u6280\u80fd\u3001\u4ee5\u53ca\u5728\u5206\u7c7b\u524d\u7f29\u5c0f\u5019\u9009\u5217\u8868\u3002", "result": "GPT-4o-mini\u5728\u8bc6\u522b\u5bf9\u9f50\u72b6\u6001\u65b9\u9762\u8fbe\u523083-94%\u7684\u51c6\u786e\u7387\uff1b\u6570\u5b66\u9886\u57df\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u9605\u8bfb\u9886\u57df\u56e0\u6807\u51c6\u8bed\u4e49\u91cd\u53e0\u800c\u8868\u73b0\u8f83\u4f4e\uff1b\u9884\u7b5b\u9009\u5019\u9009\u6280\u80fd\u663e\u8457\u6539\u5584\u7ed3\u679c\uff0c\u6b63\u786e\u6280\u80fd\u51fa\u73b0\u5728\u524d\u4e94\u5efa\u8bae\u4e2d\u7684\u6982\u7387\u8d85\u8fc795%\u3002", "conclusion": "LLMs\u7279\u522b\u662f\u7ed3\u5408\u5019\u9009\u7b5b\u9009\u7b56\u7565\u65f6\uff0c\u80fd\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u8bc4\u5ba1\u8d1f\u62c5\u540c\u65f6\u4fdd\u6301\u5bf9\u9f50\u51c6\u786e\u6027\u3002\u5efa\u8bae\u5f00\u53d1\u7ed3\u5408LLM\u7b5b\u9009\u548c\u4eba\u5de5\u8bc4\u5ba1\u7684\u6df7\u5408\u6d41\u7a0b\uff0c\u4e3a\u6301\u7eed\u9879\u76ee\u9a8c\u8bc1\u548c\u6559\u5b66\u5bf9\u9f50\u63d0\u4f9b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20183", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.20183", "abs": "https://arxiv.org/abs/2511.20183", "authors": ["Nils Baillie", "Baptiste Kerleguer", "Cyril Feau", "Josselin Garnier"], "title": "Efficient multi-fidelity Gaussian process regression for noisy outputs and non-nested experimental designs", "comment": null, "summary": "This paper presents a multi-fidelity Gaussian process surrogate modeling that generalizes the recursive formulation of the auto-regressive model when the high-fidelity and low-fidelity data sets are noisy and not necessarily nested. The estimation of high-fidelity parameters by the EM (expectation-maximization) algorithm is shown to be still possible in this context and a closed-form update formula is derived when the scaling factor is a parametric linear predictor function. This yields a decoupled optimization strategy for the parameter selection that is more efficient and scalable than the direct maximum likelihood maximization. The proposed approach is compared to other multi-fidelity models, and benchmarks for different application cases of increasing complexity are provided.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u4fdd\u771f\u5ea6\u9ad8\u65af\u8fc7\u7a0b\u4ee3\u7406\u5efa\u6a21\u65b9\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u975e\u5d4c\u5957\u4e14\u542b\u566a\u58f0\u7684\u9ad8\u4fdd\u771f\u5ea6\u548c\u4f4e\u4fdd\u771f\u5ea6\u6570\u636e\u96c6\uff0c\u901a\u8fc7EM\u7b97\u6cd5\u4f30\u8ba1\u53c2\u6570\u5e76\u63a8\u5bfc\u51fa\u95ed\u5f0f\u66f4\u65b0\u516c\u5f0f\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u591a\u4fdd\u771f\u5ea6\u5efa\u6a21\u65b9\u6cd5\u5728\u5904\u7406\u975e\u5d4c\u5957\u3001\u542b\u566a\u58f0\u6570\u636e\u96c6\u65f6\u7684\u5c40\u9650\u6027\uff0c\u63d0\u9ad8\u53c2\u6570\u4f30\u8ba1\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u57fa\u4e8e\u9012\u5f52\u81ea\u56de\u5f52\u6a21\u578b\u7684\u591a\u4fdd\u771f\u5ea6\u9ad8\u65af\u8fc7\u7a0b\u5efa\u6a21\uff0c\u4f7f\u7528EM\u7b97\u6cd5\u8fdb\u884c\u53c2\u6570\u4f30\u8ba1\uff0c\u5f53\u7f29\u653e\u56e0\u5b50\u4e3a\u53c2\u6570\u5316\u7ebf\u6027\u9884\u6d4b\u51fd\u6570\u65f6\u63a8\u5bfc\u51fa\u95ed\u5f0f\u66f4\u65b0\u516c\u5f0f\u3002", "result": "\u63d0\u51fa\u4e86\u89e3\u8026\u4f18\u5316\u7b56\u7565\uff0c\u6bd4\u76f4\u63a5\u6700\u5927\u4f3c\u7136\u6700\u5927\u5316\u66f4\u9ad8\u6548\u548c\u53ef\u6269\u5c55\uff0c\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u5e94\u7528\u6848\u4f8b\u4e2d\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u975e\u5d4c\u5957\u542b\u566a\u58f0\u591a\u4fdd\u771f\u5ea6\u6570\u636e\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u53c2\u6570\u9009\u62e9\u7b56\u7565\u3002"}}
{"id": "2511.19863", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.19863", "abs": "https://arxiv.org/abs/2511.19863", "authors": ["Yoshua Bengio", "Stephen Clare", "Carina Prunkl", "Maksym Andriushchenko", "Ben Bucknall", "Philip Fox", "Nestor Maslej", "Conor McGlynn", "Malcolm Murray", "Shalaleh Rismani", "Stephen Casper", "Jessica Newman", "Daniel Privitera", "S\u00f6ren Mindermann", "Daron Acemoglu", "Thomas G. Dietterich", "Fredrik Heintz", "Geoffrey Hinton", "Nick Jennings", "Susan Leavy", "Teresa Ludermir", "Vidushi Marda", "Helen Margetts", "John McDermid", "Jane Munga", "Arvind Narayanan", "Alondra Nelson", "Clara Neppel", "Gopal Ramchurn", "Stuart Russell", "Marietje Schaake", "Bernhard Sch\u00f6lkopf", "Alavaro Soto", "Lee Tiedrich", "Ga\u00ebl Varoquaux", "Andrew Yao", "Ya-Qin Zhang", "Leandro Aguirre", "Olubunmi Ajala", "Fahad Albalawi", "Noora AlMalek", "Christian Busch", "Andr\u00e9 Carvalho", "Jonathan Collas", "Amandeep Gill", "Ahmet Hatip", "Juha Heikkil\u00e4", "Chris Johnson", "Gill Jolly", "Ziv Katzir", "Mary Kerema", "Hiroaki Kitano", "Antonio Kr\u00fcger", "Aoife McLysaght", "Oleksii Molchanovskyi", "Andrea Monti", "Kyoung Mu Lee", "Mona Nemer", "Nuria Oliver", "Raquel Pezoa", "Audrey Plonk", "Jos\u00e9 Portillo", "Balaraman Ravindran", "Hammam Riza", "Crystal Rugege", "Haroon Sheikh", "Denise Wong", "Yi Zeng", "Liming Zhu"], "title": "International AI Safety Report 2025: Second Key Update: Technical Safeguards and Risk Management", "comment": null, "summary": "This second update to the 2025 International AI Safety Report assesses new developments in general-purpose AI risk management over the past year. It examines how researchers, public institutions, and AI developers are approaching risk management for general-purpose AI. In recent months, for example, three leading AI developers applied enhanced safeguards to their new models, as their internal pre-deployment testing could not rule out the possibility that these models could be misused to help create biological weapons. Beyond specific precautionary measures, there have been a range of other advances in techniques for making AI models and systems more reliable and resistant to misuse. These include new approaches in adversarial training, data curation, and monitoring systems. In parallel, institutional frameworks that operationalise and formalise these technical capabilities are starting to emerge: the number of companies publishing Frontier AI Safety Frameworks more than doubled in 2025, and governments and international organisations have established a small number of governance frameworks for general-purpose AI, focusing largely on transparency and risk assessment.", "AI": {"tldr": "2025\u5e74\u56fd\u9645AI\u5b89\u5168\u62a5\u544a\u66f4\u65b0\uff1a\u8bc4\u4f30\u901a\u7528AI\u98ce\u9669\u7ba1\u7406\u65b0\u8fdb\u5c55\uff0c\u5305\u62ec\u5f00\u53d1\u8005\u91c7\u53d6\u7684\u5b89\u5168\u63aa\u65bd\u3001\u6280\u672f\u6539\u8fdb\u548c\u65b0\u5174\u6cbb\u7406\u6846\u67b6\u3002", "motivation": "\u968f\u7740\u901a\u7528AI\u80fd\u529b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u6301\u7eed\u8bc4\u4f30\u548c\u66f4\u65b0\u98ce\u9669\u7ba1\u7406\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u9488\u5bf9\u751f\u7269\u6b66\u5668\u7b49\u9ad8\u98ce\u9669\u6ee5\u7528\u573a\u666f\u3002", "method": "\u901a\u8fc7\u5206\u6790AI\u5f00\u53d1\u8005\u3001\u7814\u7a76\u673a\u6784\u548c\u516c\u5171\u673a\u6784\u7684\u6700\u65b0\u5b9e\u8df5\uff0c\u5305\u62ec\u589e\u5f3a\u5b89\u5168\u9632\u62a4\u3001\u5bf9\u6297\u8bad\u7ec3\u3001\u6570\u636e\u7ba1\u7406\u548c\u76d1\u63a7\u7cfb\u7edf\u7b49\u6280\u672f\u624b\u6bb5\u3002", "result": "\u4e3b\u8981AI\u5f00\u53d1\u8005\u5df2\u5bf9\u65b0\u578b\u53f7\u5b9e\u65bd\u989d\u5916\u5b89\u5168\u63aa\u65bd\uff1b\u524d\u6cbfAI\u5b89\u5168\u6846\u67b6\u53d1\u5e03\u516c\u53f8\u6570\u91cf\u7ffb\u500d\uff1b\u653f\u5e9c\u548c\u56fd\u9645\u7ec4\u7ec7\u5f00\u59cb\u5efa\u7acb\u900f\u660e\u5ea6\u4e0e\u98ce\u9669\u8bc4\u4f30\u4e3a\u4e3b\u7684\u6cbb\u7406\u6846\u67b6\u3002", "conclusion": "\u901a\u7528AI\u98ce\u9669\u7ba1\u7406\u5728\u6280\u672f\u548c\u5236\u5ea6\u5c42\u9762\u90fd\u6709\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u4ecd\u9700\u6301\u7eed\u52aa\u529b\u5e94\u5bf9\u65b0\u5174\u98ce\u9669\u3002"}}
{"id": "2511.19683", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19683", "abs": "https://arxiv.org/abs/2511.19683", "authors": ["Eugene Lavretsky"], "title": "State Feedback Controllers with Operational Constraints", "comment": "33 pages, 13 figures. These are the original detailed design notes where my recent CBF-related papers came from", "summary": "In this paper, a state feedback control design with min/max operational limiting constraints is developed for multi-input-multi-output linear time invariant systems. Specifically, servo-tracking control problems with input and output constraints are considered. For static servo-controllers, the output design limits are imposed component-wise on the system selected output, which is of the same dimension as the control input. For dynamic servo-controllers, operational constraints are applied to the system inputs and outputs. The proposed control solution also includes an anti-windup protection logic for dynamic servo-controllers with integral action. The developed method is based on the Nagumo Theorem for forward invariance, the Comparison Lemma for inclusion of input/output inequality constraints, and on the min-norm optimal controllers for synthesis. The derived design is similar and directly related to the method of Control Barrier Functions. Simulation trade studies are presented to illustrate benefits of the proposed control methodology for aerial flight critical systems.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u591a\u8f93\u5165\u591a\u8f93\u51fa\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u5e26\u6709\u6700\u5c0f/\u6700\u5927\u8fd0\u884c\u9650\u5236\u7ea6\u675f\u7684\u72b6\u6001\u53cd\u9988\u63a7\u5236\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u5177\u6709\u8f93\u5165\u548c\u8f93\u51fa\u7ea6\u675f\u7684\u4f3a\u670d\u8ddf\u8e2a\u63a7\u5236\u95ee\u9898\u3002", "motivation": "\u4e3a\u591a\u8f93\u5165\u591a\u8f93\u51fa\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf\u8bbe\u8ba1\u80fd\u591f\u5728\u8fd0\u884c\u9650\u5236\u7ea6\u675f\u4e0b\u5de5\u4f5c\u7684\u4f3a\u670d\u8ddf\u8e2a\u63a7\u5236\u5668\uff0c\u7279\u522b\u662f\u9488\u5bf9\u822a\u7a7a\u98de\u884c\u5173\u952e\u7cfb\u7edf\uff0c\u786e\u4fdd\u7cfb\u7edf\u5728\u7ea6\u675f\u8303\u56f4\u5185\u5b89\u5168\u8fd0\u884c\u3002", "method": "\u57fa\u4e8eNagumo\u5b9a\u7406\u7684\u524d\u5411\u4e0d\u53d8\u6027\u3001\u6bd4\u8f83\u5f15\u7406\u7528\u4e8e\u8f93\u5165/\u8f93\u51fa\u4e0d\u7b49\u5f0f\u7ea6\u675f\u7684\u5305\u542b\uff0c\u4ee5\u53ca\u6700\u5c0f\u8303\u6570\u6700\u4f18\u63a7\u5236\u5668\u8fdb\u884c\u7efc\u5408\u3002\u5305\u62ec\u9759\u6001\u548c\u52a8\u6001\u4f3a\u670d\u63a7\u5236\u5668\u8bbe\u8ba1\uff0c\u52a8\u6001\u63a7\u5236\u5668\u8fd8\u5305\u542b\u6297\u9971\u548c\u4fdd\u62a4\u903b\u8f91\u3002", "result": "\u63d0\u51fa\u7684\u63a7\u5236\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u8f93\u5165\u548c\u8f93\u51fa\u7ea6\u675f\uff0c\u786e\u4fdd\u7cfb\u7edf\u5728\u6307\u5b9a\u9650\u5236\u8303\u56f4\u5185\u8fd0\u884c\uff0c\u7c7b\u4f3c\u4e8e\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u65b9\u6cd5\u3002", "conclusion": "\u6240\u5f00\u53d1\u7684\u63a7\u5236\u65b9\u6cd5\u4e3a\u5177\u6709\u8fd0\u884c\u7ea6\u675f\u7684\u591a\u8f93\u5165\u591a\u8f93\u51fa\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u822a\u7a7a\u98de\u884c\u5173\u952e\u7cfb\u7edf\uff0c\u901a\u8fc7\u4eff\u771f\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u4f18\u52bf\u3002"}}
{"id": "2511.19655", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19655", "abs": "https://arxiv.org/abs/2511.19655", "authors": ["Shantanu Rahman", "Nayeb Hasin", "Mainul Islam"], "title": "Development of a Testbed for Autonomous Vehicles: Integrating MPC Control with Monocular Camera Lane Detection", "comment": "49 pages, 23 figures", "summary": "Autonomous vehicles are becoming popular day by day not only for autonomous road traversal but also for industrial automation, farming and military. Most of the standard vehicles follow the Ackermann style steering mechanism. This has become to de facto standard for large and long faring vehicles. The local planner of an autonomous vehicle controls the low-level vehicle movement upon which the vehicle will perform its motor actuation. In our work, we focus on autonomous vehicles in road and perform experiments to analyze the effect of low-level controllers in the simulation and a real environment. To increase the precision and stability of trajectory tracking in autonomous cars, a novel method that combines lane identification with Model Predictive Control (MPC) is presented. The research focuses on camera-equipped autonomous vehicles and uses methods like edge recognition, sliding window-based straight-line identification for lane line extraction, and dynamic region of interest (ROI) extraction. Next, to follow the identified lane line, an MPC built on a bicycle vehicle dynamics model is created. A single-lane road simulation model is built using ROS Gazebo and tested in order to verify the controller's performance. The root mean square error between the optimal tracking trajectory and the target trajectory was reduced by 27.65% in the simulation results, demonstrating the high robustness and flexibility of the developed controller.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8f66\u9053\u8bc6\u522b\u4e0e\u6a21\u578b\u9884\u6d4b\u63a7\u5236(MPC)\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u8f68\u8ff9\u8ddf\u8e2a\u7684\u7cbe\u5ea6\u548c\u7a33\u5b9a\u6027\uff0c\u5728\u4eff\u771f\u4e2d\u8f68\u8ff9\u8ddf\u8e2a\u8bef\u5dee\u964d\u4f4e\u4e8627.65%\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u9053\u8def\u5e94\u7528\u4e2d\u9700\u8981\u63d0\u9ad8\u8f68\u8ff9\u8ddf\u8e2a\u7684\u7cbe\u5ea6\u548c\u7a33\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u91c7\u7528\u963f\u514b\u66fc\u8f6c\u5411\u673a\u5236\u7684\u6807\u51c6\u8f66\u8f86\u3002", "method": "\u4f7f\u7528\u8fb9\u7f18\u8bc6\u522b\u3001\u6ed1\u52a8\u7a97\u53e3\u76f4\u7ebf\u8bc6\u522b\u8fdb\u884c\u8f66\u9053\u7ebf\u63d0\u53d6\uff0c\u7ed3\u5408\u57fa\u4e8e\u81ea\u884c\u8f66\u8f66\u8f86\u52a8\u529b\u5b66\u6a21\u578b\u7684MPC\u63a7\u5236\u5668\uff0c\u5728ROS Gazebo\u4e2d\u6784\u5efa\u5355\u8f66\u9053\u9053\u8def\u4eff\u771f\u6a21\u578b\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u6700\u4f18\u8ddf\u8e2a\u8f68\u8ff9\u4e0e\u76ee\u6807\u8f68\u8ff9\u4e4b\u95f4\u7684\u5747\u65b9\u6839\u8bef\u5dee\u964d\u4f4e\u4e8627.65%\uff0c\u8bc1\u660e\u4e86\u6240\u5f00\u53d1\u63a7\u5236\u5668\u7684\u9ad8\u9c81\u68d2\u6027\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u8f66\u9053\u8bc6\u522b\u4e0eMPC\u7ed3\u5408\u65b9\u6cd5\u6709\u6548\u63d0\u9ad8\u4e86\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u8f68\u8ff9\u8ddf\u8e2a\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.19773", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.19773", "abs": "https://arxiv.org/abs/2511.19773", "authors": ["Meng Lu", "Ran Xu", "Yi Fang", "Wenxuan Zhang", "Yue Yu", "Gaurav Srivastava", "Yuchen Zhuang", "Mohamed Elhoseiny", "Charles Fleming", "Carl Yang", "Zhengzhong Tu", "Yang Xie", "Guanghua Xiao", "Hanrui Wang", "Di Jin", "Wenqi Shi", "Xuan Wang"], "title": "Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs", "comment": "17 pages, 9 figures, work in progress", "summary": "While recent vision-language models (VLMs) demonstrate strong image understanding, their ability to \"think with images\", i.e., to reason through multi-step visual interactions, remains limited. We introduce VISTA-Gym, a scalable training environment for incentivizing tool-integrated visual reasoning capabilities in VLMs. VISTA-Gym unifies diverse real-world multimodal reasoning tasks (7 tasks from 13 datasets in total) with a standardized interface for visual tools (e.g., grounding, parsing), executable interaction loops, verifiable feedback signals, and efficient trajectory logging, enabling visual agentic reinforcement learning at scale. While recent VLMs exhibit strong text-only reasoning, both proprietary and open-source models still struggle with tool selection, invocation, and coordination. With VISTA-Gym, we train VISTA-R1 to interleave tool-use with agentic reasoning via multi-turn trajectory sampling and end-to-end reinforcement learning. Extensive experiments across 11 public reasoning-intensive VQA benchmarks show that VISTA-R1-8B outperforms state-of-the-art baselines with similar sizes by 9.51%-18.72%, demonstrating VISTA-Gym as an effective training ground to unlock the tool-integrated reasoning capabilities for VLMs.", "AI": {"tldr": "VISTA-Gym\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u8bad\u7ec3\u73af\u5883\uff0c\u65e8\u5728\u589e\u5f3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6b65\u9aa4\u89c6\u89c9\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u7edf\u4e00\u591a\u6a21\u6001\u4efb\u52a1\u63a5\u53e3\u548c\u5de5\u5177\u96c6\u6210\u6765\u8bad\u7ec3VISTA-R1\u6a21\u578b\uff0c\u572811\u4e2aVQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u540c\u7c7b\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u50cf\u7406\u89e3\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u6b65\u9aa4\u89c6\u89c9\u63a8\u7406\u548c\u5de5\u5177\u96c6\u6210\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u4e13\u95e8\u7684\u8bad\u7ec3\u73af\u5883\u6765\u63d0\u5347\u8fd9\u4e9b\u80fd\u529b\u3002", "method": "\u5f00\u53d1VISTA-Gym\u8bad\u7ec3\u73af\u5883\uff0c\u7edf\u4e007\u4e2a\u4efb\u52a113\u4e2a\u6570\u636e\u96c6\u7684\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\uff0c\u63d0\u4f9b\u6807\u51c6\u5316\u89c6\u89c9\u5de5\u5177\u63a5\u53e3\u3001\u53ef\u6267\u884c\u4ea4\u4e92\u5faa\u73af\u548c\u53cd\u9988\u4fe1\u53f7\uff0c\u901a\u8fc7\u591a\u8f6e\u8f68\u8ff9\u91c7\u6837\u548c\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3VISTA-R1\u6a21\u578b\u3002", "result": "VISTA-R1-8B\u572811\u4e2a\u516c\u5f00\u63a8\u7406\u5bc6\u96c6\u578bVQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6bd4\u540c\u7c7b\u89c4\u6a21\u7684\u6700\u5148\u8fdb\u57fa\u7ebf\u6a21\u578b\u6027\u80fd\u63d0\u53479.51%-18.72%\u3002", "conclusion": "VISTA-Gym\u662f\u89e3\u9501\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5de5\u5177\u96c6\u6210\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u8bad\u7ec3\u5e73\u53f0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u590d\u6742\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2511.20481", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.20481", "abs": "https://arxiv.org/abs/2511.20481", "authors": ["Leonardo Cefalo", "Crescenza Calculli", "Alessio Pollice"], "title": "Investigating access to support centers for Violence Against Women in Apulia: A Spatial analysis over multiple years", "comment": null, "summary": "In this study, we address the challenge of modelling the spatial variability in violence against women across municipalities in a Southern Italian region by proposing a Bayesian spatio-temporal Poisson regression model. Using data on access to Local Anti-Violence Centers in the Apulia region from 2021 to 2024, we investigate the impact of municipality-level socioeconomic characteristics and local vulnerabilities on both the incidence and reporting of gender-based violence. To explicitly account for spatial dependence, we compare four spatial models within the Integrated Nested Laplace Approximation framework for Bayesian model estimation. We assess the relative fit of the competing models, discussing their prior assumptions, spatial confounding effects, and inferential implications. Our findings indicate that access to support services decreases with distance from the residential municipality, highlighting spatial constraints in reporting and the strategic importance of support center location. Furthermore, lower education levels appear to contribute to under-reporting in disadvantaged areas, while higher economic development may be associated with a lower incidence of reported violence. This study emphasises the critical role of spatial modelling in capturing reporting dynamics and informing policy interventions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8d1d\u53f6\u65af\u65f6\u7a7a\u6cca\u677e\u56de\u5f52\u6a21\u578b\u6765\u5206\u6790\u610f\u5927\u5229\u5357\u90e8\u5730\u533a\u5973\u6027\u66b4\u529b\u7684\u7a7a\u95f4\u53d8\u5f02\u6027\uff0c\u53d1\u73b0\u652f\u6301\u670d\u52a1\u7684\u53ef\u53ca\u6027\u3001\u6559\u80b2\u6c34\u5e73\u548c\u7ecf\u6d4e\u53d1\u5c55\u7a0b\u5ea6\u662f\u5f71\u54cd\u66b4\u529b\u62a5\u544a\u548c\u53d1\u751f\u7387\u7684\u5173\u952e\u56e0\u7d20\u3002", "motivation": "\u89e3\u51b3\u5973\u6027\u66b4\u529b\u5728\u4e0d\u540c\u57ce\u5e02\u95f4\u7a7a\u95f4\u53d8\u5f02\u6027\u7684\u5efa\u6a21\u6311\u6218\uff0c\u7814\u7a76\u793e\u4f1a\u7ecf\u6d4e\u7279\u5f81\u548c\u5f53\u5730\u8106\u5f31\u6027\u5bf9\u6027\u522b\u66b4\u529b\u53d1\u751f\u7387\u548c\u62a5\u544a\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u65f6\u7a7a\u6cca\u677e\u56de\u5f52\u6a21\u578b\uff0c\u5728\u96c6\u6210\u5d4c\u5957\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\u6846\u67b6\u5185\u6bd4\u8f83\u56db\u79cd\u7a7a\u95f4\u6a21\u578b\uff0c\u5206\u67902021-2024\u5e74\u666e\u5229\u4e9a\u5927\u533a\u53cd\u66b4\u529b\u4e2d\u5fc3\u8bbf\u95ee\u6570\u636e\u3002", "result": "\u652f\u6301\u670d\u52a1\u7684\u53ef\u53ca\u6027\u968f\u5c45\u4f4f\u5730\u8ddd\u79bb\u589e\u52a0\u800c\u51cf\u5c11\uff1b\u6559\u80b2\u6c34\u5e73\u8f83\u4f4e\u5730\u533a\u5b58\u5728\u62a5\u544a\u4e0d\u8db3\uff1b\u7ecf\u6d4e\u53d1\u5c55\u7a0b\u5ea6\u8f83\u9ad8\u5730\u533a\u62a5\u544a\u7684\u66b4\u529b\u53d1\u751f\u7387\u53ef\u80fd\u8f83\u4f4e\u3002", "conclusion": "\u7a7a\u95f4\u5efa\u6a21\u5728\u6355\u6349\u62a5\u544a\u52a8\u6001\u548c\u4e3a\u653f\u7b56\u5e72\u9884\u63d0\u4f9b\u4fe1\u606f\u65b9\u9762\u5177\u6709\u5173\u952e\u4f5c\u7528\uff0c\u5f3a\u8c03\u4e86\u652f\u6301\u4e2d\u5fc3\u4f4d\u7f6e\u6218\u7565\u91cd\u8981\u6027\u3002"}}
{"id": "2511.20036", "categories": ["cs.CY", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.20036", "abs": "https://arxiv.org/abs/2511.20036", "authors": ["Mykola Makhortykh", "Tobias Rohrbach", "Maryna Sydorova"], "title": "Invisible in Search? Auditing Aesthetic Bias in the Visual Representation of Holocaust Victims on Google", "comment": "22 pages", "summary": "Information retrieval systems, such as search engines, increasingly shape the representation of the past and present states of social reality. Despite their importance, these systems face challenges in dealing with the ethical aspects of representation due to various forms of bias, including aesthetic bias that perpetuates hegemonic patterns of representation. While most research on aesthetic bias has examined it in the context of current societal issues, it is also crucial for historical representation, particularly of sensitive subjects such as historical atrocities. To address this gap, we conduct a comparative audit of the visual representation of Holocaust victims on Google. We find that Google tends to propagate a male-dominated representation of Holocaust victims with an emphasis on atrocity context, risking rendering invisible gender-specific suffering and decreasing potential for nurturing empathy. We also observe a variation in representation across geographic locations, suggesting that search algorithms may produce their own aesthetic of victimhood.", "AI": {"tldr": "\u5bf9Google\u4e0a\u5927\u5c60\u6740\u53d7\u5bb3\u8005\u89c6\u89c9\u5448\u73b0\u7684\u6bd4\u8f83\u5ba1\u8ba1\u663e\u793a\uff0c\u5b58\u5728\u7537\u6027\u4e3b\u5bfc\u7684\u5448\u73b0\u504f\u5411\uff0c\u8fc7\u5ea6\u5f3a\u8c03\u66b4\u884c\u80cc\u666f\uff0c\u53ef\u80fd\u63a9\u76d6\u6027\u522b\u7279\u5b9a\u7684\u82e6\u96be\u5e76\u524a\u5f31\u5171\u60c5\u6f5c\u529b\u3002", "motivation": "\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u5728\u5851\u9020\u793e\u4f1a\u73b0\u5b9e\u8868\u5f81\u65b9\u9762\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u9762\u4e34\u7f8e\u5b66\u504f\u89c1\u7b49\u4f26\u7406\u6311\u6218\u3002\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u5f53\u4ee3\u793e\u4f1a\u95ee\u9898\uff0c\u800c\u5386\u53f2\u8868\u5f81\u7279\u522b\u662f\u654f\u611f\u5386\u53f2\u4e8b\u4ef6\u5982\u5927\u5c60\u6740\u7684\u7f8e\u5b66\u504f\u89c1\u7814\u7a76\u5b58\u5728\u7a7a\u767d\u3002", "method": "\u5bf9Google\u4e0a\u5927\u5c60\u6740\u53d7\u5bb3\u8005\u89c6\u89c9\u5448\u73b0\u8fdb\u884c\u5bf9\u6bd4\u5ba1\u8ba1\u7814\u7a76\u3002", "result": "\u53d1\u73b0Google\u503e\u5411\u4e8e\u4f20\u64ad\u7537\u6027\u4e3b\u5bfc\u7684\u5927\u5c60\u6740\u53d7\u5bb3\u8005\u8868\u5f81\uff0c\u5f3a\u8c03\u66b4\u884c\u80cc\u666f\uff0c\u53ef\u80fd\u4f7f\u6027\u522b\u7279\u5b9a\u82e6\u96be\u9690\u5f62\u5e76\u964d\u4f4e\u5171\u60c5\u6f5c\u529b\u3002\u4e0d\u540c\u5730\u7406\u4f4d\u7f6e\u7684\u5448\u73b0\u5b58\u5728\u5dee\u5f02\uff0c\u8868\u660e\u641c\u7d22\u7b97\u6cd5\u53ef\u80fd\u4ea7\u751f\u81ea\u8eab\u7684\u53d7\u5bb3\u8005\u7f8e\u5b66\u3002", "conclusion": "\u641c\u7d22\u7b97\u6cd5\u5728\u5386\u53f2\u8868\u5f81\u4e2d\u4ea7\u751f\u7f8e\u5b66\u504f\u89c1\uff0c\u9700\u8981\u5173\u6ce8\u5176\u5bf9\u654f\u611f\u5386\u53f2\u4e8b\u4ef6\u5448\u73b0\u7684\u4f26\u7406\u5f71\u54cd\u3002"}}
{"id": "2511.19715", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19715", "abs": "https://arxiv.org/abs/2511.19715", "authors": ["Theodor Hagstr\u00f6m", "Lars Herre"], "title": "Understanding Risk and Revenue in the Nordic 15-minute mFRR market: An EV Aggregation Study", "comment": null, "summary": "Decarbonisation, decentralisation, and intermittency are driving the development of flexibility markets towards shorter market time units (MTU). Shorter MTUs and shorter gate closures lower the entrance barriers of demand side aggregators that face significant uncertainty on longer time scales. We study the business case for aggregated EV fleets participating in the Nordic 15-minute mFRR Energy Activation Market (EAM). Motivated by increasing system granularity and rapid EV uptake, we represent fleet flexibility as a virtual battery with time-varying power and energy envelopes and formulate a risk-aware stochastic optimisation that co-ordinates day-ahead scheduling with quarter-hour mFRR bidding. Using synthetic residential charging cohorts and observed day-ahead prices on two stylised days, we compare an independent day-ahead baseline to a co-optimised strategy under conservative availability and a CVaR-augmented objective. Across both price cases, co-optimisation increases expected profit and lowers downside risk: the model buys less energy day-ahead and shifts procurement toward mFRR down while flattening the charging plan to retain eligibility for mFRR up. Profit decomposition shows that the uplift is driven by higher mFRR down revenues and reduced reliance on unwinding day-ahead positions. We discuss operational implications for bidding and outline two extensions: rolling 45-minute re-optimisation and a V2G framework.", "AI": {"tldr": "\u7814\u7a76\u7535\u52a8\u6c7d\u8f66\u8f66\u961f\u53c2\u4e0e\u5317\u6b2715\u5206\u949fmFRR\u80fd\u6e90\u6fc0\u6d3b\u5e02\u573a\u7684\u5546\u4e1a\u6a21\u5f0f\uff0c\u901a\u8fc7\u98ce\u9669\u611f\u77e5\u968f\u673a\u4f18\u5316\u534f\u8c03\u65e5\u524d\u8c03\u5ea6\u4e0e15\u5206\u949fmFRR\u6295\u6807\uff0c\u63d0\u9ad8\u9884\u671f\u5229\u6da6\u5e76\u964d\u4f4e\u4e0b\u884c\u98ce\u9669\u3002", "motivation": "\u8131\u78b3\u5316\u3001\u53bb\u4e2d\u5fc3\u5316\u548c\u95f4\u6b47\u6027\u63a8\u52a8\u7075\u6d3b\u6027\u5e02\u573a\u5411\u66f4\u77ed\u5e02\u573a\u65f6\u95f4\u5355\u4f4d\u53d1\u5c55\uff0c\u66f4\u77ed\u7684MTU\u548c\u5173\u95f8\u65f6\u95f4\u964d\u4f4e\u4e86\u9700\u6c42\u4fa7\u805a\u5408\u5546\u7684\u8fdb\u5165\u95e8\u69db\uff0c\u8fd9\u4e9b\u805a\u5408\u5546\u5728\u8f83\u957f\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u9762\u4e34\u663e\u8457\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u5c06\u8f66\u961f\u7075\u6d3b\u6027\u8868\u793a\u4e3a\u5177\u6709\u65f6\u53d8\u529f\u7387\u548c\u80fd\u91cf\u5305\u7edc\u7684\u865a\u62df\u7535\u6c60\uff0c\u5236\u5b9a\u98ce\u9669\u611f\u77e5\u968f\u673a\u4f18\u5316\uff0c\u534f\u8c03\u65e5\u524d\u8c03\u5ea6\u4e0e15\u5206\u949fmFRR\u6295\u6807\uff0c\u4f7f\u7528\u4fdd\u5b88\u53ef\u7528\u6027\u548cCVaR\u589e\u5f3a\u76ee\u6807\u51fd\u6570\u3002", "result": "\u5728\u4e24\u79cd\u4ef7\u683c\u60c5\u666f\u4e0b\uff0c\u534f\u540c\u4f18\u5316\u90fd\u63d0\u9ad8\u4e86\u9884\u671f\u5229\u6da6\u5e76\u964d\u4f4e\u4e86\u4e0b\u884c\u98ce\u9669\uff1a\u6a21\u578b\u5728\u65e5\u524d\u8d2d\u4e70\u66f4\u5c11\u80fd\u6e90\uff0c\u5c06\u91c7\u8d2d\u8f6c\u5411mFRR\u4e0b\u8c03\uff0c\u540c\u65f6\u5e73\u6574\u5145\u7535\u8ba1\u5212\u4ee5\u4fdd\u6301mFRR\u4e0a\u8c03\u8d44\u683c\u3002\u5229\u6da6\u5206\u89e3\u663e\u793a\u63d0\u5347\u4e3b\u8981\u6765\u81ea\u66f4\u9ad8\u7684mFRR\u4e0b\u8c03\u6536\u5165\u548c\u51cf\u5c11\u5bf9\u5e73\u4ed3\u65e5\u524d\u5934\u5bf8\u7684\u4f9d\u8d56\u3002", "conclusion": "\u534f\u540c\u4f18\u5316\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u7535\u52a8\u6c7d\u8f66\u8f66\u961f\u5728\u7075\u6d3b\u6027\u5e02\u573a\u4e2d\u7684\u76c8\u5229\u80fd\u529b\uff0c\u8ba8\u8bba\u4e86\u6295\u6807\u7684\u64cd\u4f5c\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u4e2a\u6269\u5c55\uff1a\u6eda\u52a845\u5206\u949f\u91cd\u65b0\u4f18\u5316\u548cV2G\u6846\u67b6\u3002"}}
{"id": "2511.19691", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19691", "abs": "https://arxiv.org/abs/2511.19691", "authors": ["Thomas Marshall Vielmetti", "Devansh R Agrawal", "Dimitra Panagou"], "title": "Multi-Agent gatekeeper: Safe Flight Planning and Formation Control for Urban Air Mobility", "comment": "13 pages, 4 figures, to appear AIAA SciTech 2026", "summary": "We present Multi-Agent gatekeeper, a framework that provides provable safety guarantees for leader-follower formation control in cluttered 3D environments. Existing methods face a trad-off: online planners and controllers lack formal safety guarantees, while offline planners lack adaptability to changes in the number of agents or desired formation. To address this gap, we propose a hybrid architecture where a single leader tracks a pre-computed, safe trajectory, which serves as a shared trajectory backup set for all follower agents. Followers execute a nominal formation-keeping tracking controller, and are guaranteed to remain safe by always possessing a known-safe backup maneuver along the leader's path. We formally prove this method ensures collision avoidance with both static obstacles and other agents. The primary contributions are: (1) the multi-agent gatekeeper algorithm, which extends our single-agent gatekeeper framework to multi-agent systems; (2) the trajectory backup set for provably safe inter-agent coordination for leader-follower formation control; and (3) the first application of the gatekeeper framework in a 3D environment. We demonstrate our approach in a simulated 3D urban environment, where it achieved a 100% collision-avoidance success rate across 100 randomized trials, significantly outperforming baseline CBF and NMPC methods. Finally, we demonstrate the physical feasibility of the resulting trajectories on a team of quadcopters.", "AI": {"tldr": "\u63d0\u51faMulti-Agent Gatekeeper\u6846\u67b6\uff0c\u4e3a3D\u62e5\u6324\u73af\u5883\u4e2d\u7684\u9886\u5bfc\u8005-\u8ddf\u968f\u8005\u7f16\u961f\u63a7\u5236\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u901a\u8fc7\u9886\u5bfc\u8005\u9884\u8ba1\u7b97\u5b89\u5168\u8f68\u8ff9\u4f5c\u4e3a\u5171\u4eab\u5907\u4efd\uff0c\u786e\u4fdd\u8ddf\u968f\u8005\u59cb\u7ec8\u62e5\u6709\u5b89\u5168\u5907\u4efd\u673a\u52a8\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u6743\u8861\uff1a\u5728\u7ebf\u89c4\u5212\u5668\u548c\u63a7\u5236\u5668\u7f3a\u4e4f\u6b63\u5f0f\u5b89\u5168\u4fdd\u8bc1\uff0c\u800c\u79bb\u7ebf\u89c4\u5212\u5668\u65e0\u6cd5\u9002\u5e94\u4ee3\u7406\u6570\u91cf\u6216\u671f\u671b\u7f16\u961f\u7684\u53d8\u5316\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63d0\u4f9b\u5b89\u5168\u4fdd\u8bc1\u53c8\u5177\u6709\u9002\u5e94\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u6df7\u5408\u67b6\u6784\uff0c\u5355\u4e2a\u9886\u5bfc\u8005\u8ddf\u8e2a\u9884\u8ba1\u7b97\u7684\u5b89\u5168\u8f68\u8ff9\u4f5c\u4e3a\u5171\u4eab\u8f68\u8ff9\u5907\u4efd\u96c6\uff0c\u8ddf\u968f\u8005\u6267\u884c\u540d\u4e49\u7f16\u961f\u4fdd\u6301\u8ddf\u8e2a\u63a7\u5236\u5668\uff0c\u59cb\u7ec8\u62e5\u6709\u6cbf\u9886\u5bfc\u8005\u8def\u5f84\u7684\u5df2\u77e5\u5b89\u5168\u5907\u4efd\u673a\u52a8\u3002", "result": "\u5728\u6a21\u62df3D\u57ce\u5e02\u73af\u5883\u4e2d\uff0c100\u6b21\u968f\u673a\u8bd5\u9a8c\u4e2d\u5b9e\u73b0\u4e86100%\u7684\u907f\u78b0\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebfCBF\u548cNMPC\u65b9\u6cd5\uff0c\u5e76\u5728\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u56e2\u961f\u4e0a\u9a8c\u8bc1\u4e86\u8f68\u8ff9\u7684\u7269\u7406\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u8bc1\u660e\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u9886\u5bfc\u8005-\u8ddf\u968f\u8005\u7f16\u961f\u63a7\u5236\u5728\u590d\u67423D\u73af\u5883\u4e2d\u7684\u5b89\u5168\u534f\u8c03\u95ee\u9898\u3002"}}
{"id": "2511.19780", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19780", "abs": "https://arxiv.org/abs/2511.19780", "authors": ["Ioannis Tzachristas", "Aifen Sui"], "title": "NOEM$^{3}$A: A Neuro-Symbolic Ontology-Enhanced Method for Multi-Intent Understanding in Mobile Agents", "comment": null, "summary": "We introduce a neuro-symbolic framework for multi-intent understanding in mobile AI agents by integrating a structured intent ontology with compact language models. Our method leverages retrieval-augmented prompting, logit biasing and optional classification heads to inject symbolic intent structure into both input and output representations. We formalize a new evaluation metric-Semantic Intent Similarity (SIS)-based on hierarchical ontology depth, capturing semantic proximity even when predicted intents differ lexically. Experiments on a subset of ambiguous/demanding dialogues of MultiWOZ 2.3 (with oracle labels from GPT-o3) demonstrate that a 3B Llama model with ontology augmentation approaches GPT-4 accuracy (85% vs 90%) at a tiny fraction of the energy and memory footprint. Qualitative comparisons show that ontology-augmented models produce more grounded, disambiguated multi-intent interpretations. Our results validate symbolic alignment as an effective strategy for enabling accurate and efficient on-device NLU.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7ed3\u6784\u5316\u610f\u56fe\u672c\u4f53\u4e0e\u7d27\u51d1\u8bed\u8a00\u6a21\u578b\u96c6\u6210\uff0c\u5b9e\u73b0\u79fb\u52a8AI\u4ee3\u7406\u7684\u591a\u610f\u56fe\u7406\u89e3\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u63d0\u793a\u3001logit\u504f\u7f6e\u548c\u53ef\u9009\u5206\u7c7b\u5934\uff0c\u5c06\u7b26\u53f7\u610f\u56fe\u7ed3\u6784\u6ce8\u5165\u8f93\u5165\u548c\u8f93\u51fa\u8868\u793a\u4e2d\u3002", "motivation": "\u89e3\u51b3\u79fb\u52a8AI\u4ee3\u7406\u4e2d\u591a\u610f\u56fe\u7406\u89e3\u7684\u6311\u6218\uff0c\u901a\u8fc7\u5728\u7d27\u51d1\u6a21\u578b\u4e2d\u6ce8\u5165\u7b26\u53f7\u610f\u56fe\u7ed3\u6784\uff0c\u5b9e\u73b0\u51c6\u786e\u4e14\u9ad8\u6548\u7684\u8bbe\u5907\u7aef\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u3002", "method": "\u96c6\u6210\u7ed3\u6784\u5316\u610f\u56fe\u672c\u4f53\u4e0e\u7d27\u51d1\u8bed\u8a00\u6a21\u578b\uff0c\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u63d0\u793a\u3001logit\u504f\u7f6e\u548c\u53ef\u9009\u5206\u7c7b\u5934\uff0c\u5c06\u7b26\u53f7\u610f\u56fe\u7ed3\u6784\u6ce8\u5165\u8f93\u5165\u548c\u8f93\u51fa\u8868\u793a\u3002", "result": "\u5728MultiWOZ 2.3\u7684\u6a21\u7cca/\u82db\u523b\u5bf9\u8bdd\u5b50\u96c6\u4e0a\uff0c3B Llama\u6a21\u578b\u901a\u8fc7\u672c\u4f53\u589e\u5f3a\u63a5\u8fd1GPT-4\u51c6\u786e\u7387\uff0885% vs 90%\uff09\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u80fd\u8017\u548c\u5185\u5b58\u5360\u7528\u3002", "conclusion": "\u7b26\u53f7\u5bf9\u9f50\u662f\u5b9e\u73b0\u5728\u8bbe\u5907\u7aef\u51c6\u786e\u9ad8\u6548\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u7684\u6709\u6548\u7b56\u7565\uff0c\u672c\u4f53\u589e\u5f3a\u6a21\u578b\u4ea7\u751f\u66f4\u63a5\u5730\u6c14\u3001\u6d88\u6b67\u7684\u591a\u610f\u56fe\u89e3\u91ca\u3002"}}
{"id": "2511.20616", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.20616", "abs": "https://arxiv.org/abs/2511.20616", "authors": ["Yueming Shen", "Christian Pean", "David Dunson", "Samuel Berchuck"], "title": "Discovering Spatial Patterns of Readmission Risk Using a Bayesian Competing Risks Model with Spatially Varying Coefficients", "comment": null, "summary": "Time-to-event models are commonly used to study associations between risk factors and disease outcomes in the setting of electronic health records (EHR). In recent years, focus has intensified on social determinants of health, highlighting the need for methods that account for patients' locations. We propose a Bayesian approach for introducing point-referenced spatial effects into a competing risks proportional hazards model. Our method leverages Gaussian process (GP) priors for spatially varying intercept and slope. To improve computational efficiency under a large number of spatial locations, we implemented a Hilbert space low-rank approximation of the GP. We modeled the baseline hazard curves as piecewise constant, and introduced a novel multiplicative gamma process prior to induce shrinkage and smoothing. A loss-based clustering method was then used on the spatial random effects to identify high-risk regions. We demonstrate the utility of this method through simulation and a real-world analysis of EHR data from Duke Hospital to study readmission risk of elderly patients with upper extremity fractures. Our results showed that the proposed method improved inference efficiency and provided valuable insights for downstream policy decisions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8d1d\u53f6\u65af\u65b9\u6cd5\uff0c\u5c06\u70b9\u53c2\u8003\u7a7a\u95f4\u6548\u5e94\u5f15\u5165\u7ade\u4e89\u98ce\u9669\u6bd4\u4f8b\u98ce\u9669\u6a21\u578b\uff0c\u7528\u4e8e\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u7684\u65f6\u95f4-\u4e8b\u4ef6\u5206\u6790\uff0c\u901a\u8fc7\u9ad8\u65af\u8fc7\u7a0b\u5148\u9a8c\u548c\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4f4e\u79e9\u8fd1\u4f3c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u968f\u7740\u5bf9\u5065\u5eb7\u793e\u4f1a\u51b3\u5b9a\u56e0\u7d20\u7684\u5173\u6ce8\u589e\u52a0\uff0c\u9700\u8981\u80fd\u591f\u8003\u8651\u60a3\u8005\u5730\u7406\u4f4d\u7f6e\u7684\u65b9\u6cd5\u6765\u7814\u7a76\u98ce\u9669\u56e0\u7d20\u4e0e\u75be\u75c5\u7ed3\u5c40\u7684\u5173\u8054\u3002", "method": "\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u5148\u9a8c\u5904\u7406\u7a7a\u95f4\u53d8\u5316\u7684\u622a\u8ddd\u548c\u659c\u7387\uff0c\u91c7\u7528\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4f4e\u79e9\u8fd1\u4f3c\u5904\u7406\u5927\u91cf\u7a7a\u95f4\u4f4d\u7f6e\uff0c\u57fa\u7ebf\u98ce\u9669\u66f2\u7ebf\u5efa\u6a21\u4e3a\u5206\u6bb5\u5e38\u6570\uff0c\u5f15\u5165\u4e58\u6cd5\u4f3d\u9a6c\u8fc7\u7a0b\u5148\u9a8c\u8fdb\u884c\u6536\u7f29\u548c\u5e73\u6ed1\uff0c\u6700\u540e\u4f7f\u7528\u57fa\u4e8e\u635f\u5931\u7684\u805a\u7c7b\u65b9\u6cd5\u8bc6\u522b\u9ad8\u98ce\u9669\u533a\u57df\u3002", "result": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u63a8\u65ad\u6548\u7387\uff0c\u5e76\u5728\u675c\u514b\u533b\u9662\u8001\u5e74\u60a3\u8005\u4e0a\u80a2\u9aa8\u6298\u518d\u5165\u9662\u98ce\u9669\u5206\u6790\u4e2d\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u653f\u7b56\u51b3\u7b56\u89c1\u89e3\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u7a7a\u95f4\u98ce\u9669\u8bc6\u522b\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u4e0b\u6e38\u653f\u7b56\u51b3\u7b56\u63d0\u4f9b\u4e86\u6709\u7528\u5de5\u5177\u3002"}}
{"id": "2511.20094", "categories": ["cs.CY", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.20094", "abs": "https://arxiv.org/abs/2511.20094", "authors": ["Giovanni Spitale", "Federico Germani"], "title": "The Making of Digital Ghosts: Designing Ethical AI Afterlives", "comment": null, "summary": "Advances in artificial intelligence now make it possible to simulate the dead through chatbots, voice clones, and video avatars trained on a person's digital traces. These \"digital ghosts\" are moving from fiction to commercial reality, reshaping how people mourn and remember. This paper offers a conceptual and ethical analysis of AI-mediated digital afterlives. We define what counts as a digital ghost, trace their rise across personal, commercial, and institutional contexts, and identify core ethical tensions around grief and well-being, truthfulness and deception, consent and posthumous privacy, dignity and misrepresentation, and the commercialization of mourning. To analyze these challenges, we propose a nine-dimensional taxonomy of digital afterlife technologies and, building on it, outline the features of an ethically acceptable digital ghost: premortem intent, mutual consent, transparent and limited data use, clear disclosure, restricted purposes and access, family or estate stewardship, and minimal behavioral agency. We argue for targeted regulation and professional guidelines to ensure that digital ghosts can aid remembrance without slipping into forms of deception.", "AI": {"tldr": "\u672c\u6587\u5bf9AI\u9a71\u52a8\u7684\u6570\u5b57\u6765\u4e16\u6280\u672f\u8fdb\u884c\u6982\u5ff5\u548c\u4f26\u7406\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u6570\u5b57\u5e7d\u7075\u7684\u5b9a\u4e49\u3001\u4e5d\u7ef4\u5206\u7c7b\u6cd5\uff0c\u4ee5\u53ca\u6784\u5efa\u5408\u4e4e\u4f26\u7406\u7684\u6570\u5b57\u5e7d\u7075\u7684\u5173\u952e\u539f\u5219\u3002", "motivation": "\u968f\u7740AI\u6280\u672f\u53d1\u5c55\uff0c\u6a21\u62df\u901d\u8005\u7684\u804a\u5929\u673a\u5668\u4eba\u3001\u8bed\u97f3\u514b\u9686\u548c\u89c6\u9891\u5316\u8eab\u6b63\u4ece\u79d1\u5e7b\u8d70\u5411\u5546\u4e1a\u73b0\u5b9e\uff0c\u8fd9\u91cd\u5851\u4e86\u4eba\u4eec\u7684\u54c0\u60bc\u548c\u7eaa\u5ff5\u65b9\u5f0f\uff0c\u9700\u8981\u5bf9\u5176\u4f26\u7406\u5f71\u54cd\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\u3002", "method": "\u901a\u8fc7\u6982\u5ff5\u5206\u6790\u5b9a\u4e49\u6570\u5b57\u5e7d\u7075\uff0c\u8ffd\u8e2a\u5176\u5728\u4e2a\u4eba\u3001\u5546\u4e1a\u548c\u673a\u6784\u80cc\u666f\u4e0b\u7684\u5174\u8d77\uff0c\u8bc6\u522b\u6838\u5fc3\u4f26\u7406\u5f20\u529b\uff0c\u5e76\u63d0\u51fa\u4e5d\u7ef4\u5206\u7c7b\u6cd5\u6765\u5206\u6790\u8fd9\u4e9b\u6280\u672f\u3002", "result": "\u8bc6\u522b\u4e86\u56f4\u7ed5\u60b2\u4f24\u4e0e\u798f\u7949\u3001\u771f\u5b9e\u6027\u4e0e\u6b3a\u9a97\u3001\u540c\u610f\u4e0e\u6b7b\u540e\u9690\u79c1\u3001\u5c0a\u4e25\u4e0e\u6b6a\u66f2\u3001\u54c0\u60bc\u5546\u4e1a\u5316\u7b49\u6838\u5fc3\u4f26\u7406\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u5408\u4e4e\u4f26\u7406\u7684\u6570\u5b57\u5e7d\u7075\u5e94\u5177\u5907\u7684\u7279\u5f81\u3002", "conclusion": "\u9700\u8981\u6709\u9488\u5bf9\u6027\u7684\u76d1\u7ba1\u548c\u4e13\u4e1a\u6307\u5357\uff0c\u786e\u4fdd\u6570\u5b57\u5e7d\u7075\u80fd\u591f\u5e2e\u52a9\u7eaa\u5ff5\u800c\u4e0d\u9677\u5165\u6b3a\u9a97\u5f62\u5f0f\uff0c\u5f3a\u8c03\u751f\u524d\u610f\u56fe\u3001\u76f8\u4e92\u540c\u610f\u3001\u900f\u660e\u6570\u636e\u4f7f\u7528\u7b49\u5173\u952e\u539f\u5219\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.19770", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19770", "abs": "https://arxiv.org/abs/2511.19770", "authors": ["Peter Iwer Hoedt Karstensen", "Roberto Galeazzi"], "title": "Multi-Hypotheses Ego-Tracking for Resilient Navigation", "comment": null, "summary": "Autonomous robots relying on radio frequency (RF)-based localization such as global navigation satellite system (GNSS), ultra-wide band (UWB), and 5G integrated sensing and communication (ISAC) are vulnerable to spoofing and sensor manipulation. This paper presents a resilient navigation architecture that combines multi-hypothesis estimation with a Poisson binomial windowed-count detector for anomaly identification and isolation. A state machine coordinates transitions between operation, diagnosis, and mitigation, enabling adaptive response to adversarial conditions. When attacks are detected, trajectory re-planning based on differential flatness allows information-gathering maneuvers minimizing performance loss. Case studies demonstrate effective detection of biased sensors, maintenance of state estimation, and recovery of nominal operation under persistent spoofing attacks", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u591a\u5047\u8bbe\u4f30\u8ba1\u548c\u6cca\u677e\u4e8c\u9879\u7a97\u53e3\u8ba1\u6570\u68c0\u6d4b\u5668\u7684\u5f39\u6027\u5bfc\u822a\u67b6\u6784\uff0c\u7528\u4e8e\u5bf9\u6297RF\u5b9a\u4f4d\u7cfb\u7edf\u4e2d\u7684\u6b3a\u9a97\u653b\u51fb\u548c\u4f20\u611f\u5668\u64cd\u7eb5\u3002", "motivation": "\u4f9d\u8d56RF\u5b9a\u4f4d\u7684\u81ea\u4e3b\u673a\u5668\u4eba\u5bb9\u6613\u53d7\u5230\u6b3a\u9a97\u548c\u4f20\u611f\u5668\u64cd\u7eb5\u653b\u51fb\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8bc6\u522b\u548c\u9694\u79bb\u5f02\u5e38\u7684\u5b89\u5168\u5bfc\u822a\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u591a\u5047\u8bbe\u4f30\u8ba1\u4e0e\u6cca\u677e\u4e8c\u9879\u7a97\u53e3\u8ba1\u6570\u68c0\u6d4b\u5668\u8fdb\u884c\u5f02\u5e38\u8bc6\u522b\u548c\u9694\u79bb\uff0c\u901a\u8fc7\u72b6\u6001\u673a\u534f\u8c03\u64cd\u4f5c\u3001\u8bca\u65ad\u548c\u7f13\u89e3\u4e4b\u95f4\u7684\u8f6c\u6362\uff0c\u5f53\u68c0\u6d4b\u5230\u653b\u51fb\u65f6\u4f7f\u7528\u57fa\u4e8e\u5fae\u5206\u5e73\u5766\u5ea6\u7684\u8f68\u8ff9\u91cd\u89c4\u5212\u8fdb\u884c\u4fe1\u606f\u6536\u96c6\u673a\u52a8\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u6709\u6548\u68c0\u6d4b\u504f\u7f6e\u4f20\u611f\u5668\uff0c\u5728\u6301\u7eed\u6b3a\u9a97\u653b\u51fb\u4e0b\u4fdd\u6301\u72b6\u6001\u4f30\u8ba1\u5e76\u6062\u590d\u540d\u4e49\u64cd\u4f5c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5f39\u6027\u5bfc\u822a\u67b6\u6784\u80fd\u591f\u6709\u6548\u5e94\u5bf9RF\u5b9a\u4f4d\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u786e\u4fdd\u81ea\u4e3b\u673a\u5668\u4eba\u5728\u5bf9\u6297\u73af\u5883\u4e0b\u7684\u53ef\u9760\u8fd0\u884c\u3002"}}
{"id": "2511.19709", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19709", "abs": "https://arxiv.org/abs/2511.19709", "authors": ["Lukas Molnar", "Jin Cheng", "Gabriele Fadini", "Dongho Kang", "Fatemeh Zargarbashi", "Stelian Coros"], "title": "Whole-Body Inverse Dynamics MPC for Legged Loco-Manipulation", "comment": "9 pages, 6 figures, to be published in IEEE Robotics and Automation Letters (Special Issue: Advancements in MPC and Learning Algorithms for Legged Robots)", "summary": "Loco-manipulation demands coordinated whole-body motion to manipulate objects effectively while maintaining locomotion stability, presenting significant challenges for both planning and control. In this work, we propose a whole-body model predictive control (MPC) framework that directly optimizes joint torques through full-order inverse dynamics, enabling unified motion and force planning and execution within a single predictive layer. This approach allows emergent, physically consistent whole-body behaviors that account for the system's dynamics and physical constraints. We implement our MPC formulation using open software frameworks (Pinocchio and CasADi), along with the state-of-the-art interior-point solver Fatrop. In real-world experiments on a Unitree B2 quadruped equipped with a Unitree Z1 manipulator arm, our MPC formulation achieves real-time performance at 80 Hz. We demonstrate loco-manipulation tasks that demand fine control over the end-effector's position and force to perform real-world interactions like pulling heavy loads, pushing boxes, and wiping whiteboards.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u8eab\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u5168\u9636\u9006\u52a8\u529b\u5b66\u76f4\u63a5\u4f18\u5316\u5173\u8282\u626d\u77e9\uff0c\u5b9e\u73b0\u8fd0\u52a8\u548c\u529b\u7684\u7edf\u4e00\u89c4\u5212\u4e0e\u6267\u884c\uff0c\u5728\u56db\u8db3\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u4e8680Hz\u7684\u5b9e\u65f6\u6027\u80fd\u3002", "motivation": "\u5168\u8eab\u8fd0\u52a8\u64cd\u4f5c\u9700\u8981\u534f\u8c03\u5168\u8eab\u8fd0\u52a8\u6765\u6709\u6548\u64cd\u7eb5\u7269\u4f53\uff0c\u540c\u65f6\u4fdd\u6301\u8fd0\u52a8\u7a33\u5b9a\u6027\uff0c\u8fd9\u5bf9\u89c4\u5212\u548c\u63a7\u5236\u90fd\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6218\u3002", "method": "\u4f7f\u7528\u5168\u8eab\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u5168\u9636\u9006\u52a8\u529b\u5b66\u76f4\u63a5\u4f18\u5316\u5173\u8282\u626d\u77e9\uff0c\u91c7\u7528Pinocchio\u3001CasADi\u8f6f\u4ef6\u6846\u67b6\u548cFatrop\u5185\u70b9\u6c42\u89e3\u5668\u5b9e\u73b0\u3002", "result": "\u5728\u914d\u5907\u673a\u68b0\u81c2\u7684Unitree B2\u56db\u8db3\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u4e8680Hz\u7684\u5b9e\u65f6\u6027\u80fd\uff0c\u6210\u529f\u5b8c\u6210\u4e86\u62c9\u91cd\u7269\u3001\u63a8\u7bb1\u5b50\u548c\u64e6\u767d\u677f\u7b49\u5b9e\u9645\u4ea4\u4e92\u4efb\u52a1\u3002", "conclusion": "\u8be5MPC\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u7269\u7406\u4e00\u81f4\u7684\u5168\u8eab\u884c\u4e3a\uff0c\u6709\u6548\u5904\u7406\u7cfb\u7edf\u52a8\u529b\u5b66\u548c\u7269\u7406\u7ea6\u675f\uff0c\u4e3a\u5168\u8eab\u8fd0\u52a8\u64cd\u4f5c\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u89c4\u5212\u548c\u63a7\u5236\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19798", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.19798", "abs": "https://arxiv.org/abs/2511.19798", "authors": ["Weizhi Liu", "Xi Chen", "Zekun Jiang", "Liang Zhao", "Kunyuan Jiang", "Ruisi Tang", "Li Wang", "Mingke You", "Hanyu Zhou", "Hongyu Chen", "Qiankun Xiong", "Yong Nie", "Kang Li", "Jian Li"], "title": "KOM: A Multi-Agent Artificial Intelligence System for Precision Management of Knee Osteoarthritis (KOA)", "comment": null, "summary": "Knee osteoarthritis (KOA) affects more than 600 million individuals globally and is associated with significant pain, functional impairment, and disability. While personalized multidisciplinary interventions have the potential to slow disease progression and enhance quality of life, they typically require substantial medical resources and expertise, making them difficult to implement in resource-limited settings. To address this challenge, we developed KOM, a multi-agent system designed to automate KOA evaluation, risk prediction, and treatment prescription. This system assists clinicians in performing essential tasks across the KOA care pathway and supports the generation of tailored management plans based on individual patient profiles, disease status, risk factors, and contraindications. In benchmark experiments, KOM demonstrated superior performance compared to several general-purpose large language models in imaging analysis and prescription generation. A randomized three-arm simulation study further revealed that collaboration between KOM and clinicians reduced total diagnostic and planning time by 38.5% and resulted in improved treatment quality compared to each approach used independently. These findings indicate that KOM could help facilitate automated KOA management and, when integrated into clinical workflows, has the potential to enhance care efficiency. The modular architecture of KOM may also offer valuable insights for developing AI-assisted management systems for other chronic conditions.", "AI": {"tldr": "KOM\u662f\u4e00\u4e2a\u7528\u4e8e\u819d\u9aa8\u5173\u8282\u708e\u7ba1\u7406\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u8bc4\u4f30\u3001\u98ce\u9669\u9884\u6d4b\u548c\u6cbb\u7597\u5904\u65b9\uff0c\u5728\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u4e2d\u63d0\u9ad8\u8bca\u7597\u6548\u7387\u3002", "motivation": "\u819d\u9aa8\u5173\u8282\u708e\u5f71\u54cd\u5168\u74036\u4ebf\u591a\u4eba\uff0c\u4e2a\u6027\u5316\u591a\u5b66\u79d1\u5e72\u9884\u867d\u6709\u6548\u4f46\u8d44\u6e90\u9700\u6c42\u5927\uff0c\u96be\u4ee5\u5728\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e2d\u5b9e\u65bd\u3002", "method": "\u5f00\u53d1KOM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u81ea\u52a8\u5316KOA\u8bc4\u4f30\u3001\u98ce\u9669\u9884\u6d4b\u548c\u6cbb\u7597\u5904\u65b9\u751f\u6210\uff0c\u652f\u6301\u57fa\u4e8e\u60a3\u8005\u4e2a\u4f53\u7279\u5f81\u7684\u5b9a\u5236\u7ba1\u7406\u8ba1\u5212\u3002", "result": "\u57fa\u51c6\u5b9e\u9a8c\u663e\u793aKOM\u5728\u5f71\u50cf\u5206\u6790\u548c\u5904\u65b9\u751f\u6210\u65b9\u9762\u4f18\u4e8e\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff1b\u968f\u673a\u4e09\u81c2\u6a21\u62df\u7814\u7a76\u8868\u660e\u4e0e\u4e34\u5e8a\u533b\u751f\u534f\u4f5c\u53ef\u5c06\u8bca\u65ad\u548c\u89c4\u5212\u65f6\u95f4\u51cf\u5c1138.5%\uff0c\u5e76\u63d0\u9ad8\u6cbb\u7597\u8d28\u91cf\u3002", "conclusion": "KOM\u6709\u52a9\u4e8e\u5b9e\u73b0\u81ea\u52a8\u5316KOA\u7ba1\u7406\uff0c\u6574\u5408\u5230\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u53ef\u63d0\u9ad8\u62a4\u7406\u6548\u7387\uff0c\u5176\u6a21\u5757\u5316\u67b6\u6784\u5bf9\u5176\u4ed6\u6162\u6027\u75c5AI\u8f85\u52a9\u7ba1\u7406\u7cfb\u7edf\u5f00\u53d1\u5177\u6709\u53c2\u8003\u4ef7\u503c\u3002"}}
{"id": "2511.20130", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.20130", "abs": "https://arxiv.org/abs/2511.20130", "authors": ["H. R. Paz"], "title": "Dual Stressors in Engineering Education: Lagged Causal Effects of Academic Staff Strikes and Inflation on Dropout within the CAPIRE Framework", "comment": null, "summary": "This study provides a causal validation of the dual-stressor hypothesis in a long-cycle engineering programme in Argentina, testing whether academic staff strikes (proximal shocks) and inflation (distal shocks) jointly shape student dropout. Using a leak-aware longitudinal panel of 1,343 students and a manually implemented LinearDML estimator, we estimate lagged causal effects of strike exposure and its interaction with inflation at entry. The temporal profile is clear: only strikes occurring two semesters earlier have a significant impact on next-semester dropout in simple lagged logit models (ATE = 0.0323, p = 0.0173), while other lags are negligible. When we move to double machine learning and control flexibly for academic progression, curriculum friction and calendar effects, the main effect of strikes at lag 2 becomes small and statistically non-significant, but the interaction between strikes and inflation at entry remains positive and robust (estimate = 0.0625, p = 0.0033). A placebo model with a synthetic strike variable yields null effects, and a robustness audit (seed sensitivity, model comparisons, SHAP inspection) confirms the stability of the interaction across specifications. SHAP analysis also reveals that Strikes_Lag2 and Inflation_at_Entry jointly contribute strongly to predicted dropout risk. These findings align with the CAPIRE-MACRO agent-based simulations and support the view that macro shocks act as coupled stressors mediated by curriculum friction and financial resilience rather than isolated events.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9a8c\u8bc1\u4e86\u53cc\u91cd\u538b\u529b\u5047\u8bf4\uff0c\u53d1\u73b0\u963f\u6839\u5ef7\u5de5\u7a0b\u4e13\u4e1a\u4e2d\u6559\u5e08\u7f62\u5de5\uff08\u8fd1\u7aef\u51b2\u51fb\uff09\u548c\u901a\u8d27\u81a8\u80c0\uff08\u8fdc\u7aef\u51b2\u51fb\uff09\u5171\u540c\u5f71\u54cd\u5b66\u751f\u8f8d\u5b66\u7387\uff0c\u5176\u4e2d\u7f62\u5de5\u6ede\u540e\u4e24\u5b66\u671f\u4e0e\u5165\u5b66\u65f6\u901a\u80c0\u7684\u4ea4\u4e92\u4f5c\u7528\u5bf9\u8f8d\u5b66\u6709\u663e\u8457\u56e0\u679c\u5f71\u54cd\u3002", "motivation": "\u9a8c\u8bc1\u53cc\u91cd\u538b\u529b\u5047\u8bf4\uff0c\u63a2\u7a76\u5b66\u672f\u673a\u6784\u7f62\u5de5\u548c\u5b8f\u89c2\u7ecf\u6d4e\u51b2\u51fb\u5982\u4f55\u5171\u540c\u5f71\u54cd\u9ad8\u7b49\u6559\u80b2\u4e2d\u7684\u5b66\u751f\u8f8d\u5b66\u884c\u4e3a\u3002", "method": "\u4f7f\u7528\u5305\u542b1,343\u540d\u5b66\u751f\u7684\u7eb5\u5411\u9762\u677f\u6570\u636e\uff0c\u91c7\u7528LinearDML\u4f30\u8ba1\u5668\u548c\u53cc\u91cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5206\u6790\u7f62\u5de5\u66b4\u9732\u53ca\u5176\u4e0e\u5165\u5b66\u65f6\u901a\u80c0\u7684\u4ea4\u4e92\u4f5c\u7528\u5bf9\u8f8d\u5b66\u7684\u6ede\u540e\u56e0\u679c\u6548\u5e94\u3002", "result": "\u7f62\u5de5\u6ede\u540e\u4e24\u5b66\u671f\u5728\u7b80\u5355\u6a21\u578b\u4e2d\u663e\u8457\u5f71\u54cd\u8f8d\u5b66\uff08ATE=0.0323, p=0.0173\uff09\uff0c\u4f46\u5728\u63a7\u5236\u5b66\u4e1a\u8fdb\u5ea6\u7b49\u56e0\u7d20\u540e\u4e3b\u6548\u5e94\u4e0d\u663e\u8457\uff1b\u7f62\u5de5\u4e0e\u5165\u5b66\u901a\u80c0\u7684\u4ea4\u4e92\u4f5c\u7528\u4fdd\u6301\u7a33\u5065\u6b63\u76f8\u5173\uff08\u4f30\u8ba1\u503c=0.0625, p=0.0033\uff09\u3002", "conclusion": "\u5b8f\u89c2\u51b2\u51fb\u4f5c\u4e3a\u8026\u5408\u538b\u529b\u6e90\u901a\u8fc7\u8bfe\u7a0b\u6469\u64e6\u548c\u8d22\u52a1\u97e7\u6027\u4e2d\u4ecb\u5f71\u54cd\u5b66\u751f\u8f8d\u5b66\uff0c\u800c\u975e\u5b64\u7acb\u4e8b\u4ef6\uff0c\u652f\u6301\u4e86CAPIRE-MACRO\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u62df\u7ed3\u679c\u3002"}}
{"id": "2511.19884", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19884", "abs": "https://arxiv.org/abs/2511.19884", "authors": ["Mobina Nankali", "Michael W. Levin"], "title": "An Exact Solution Algorithm for the Bi-Level Optimization Problem of Electric Vehicles Charging Station Placement", "comment": null, "summary": "This work addresses electric vehicle (EV) charging station placement through a bi-level optimization model, where the upper-level planner maximizes net revenue by selecting station locations under budget constraints, while EV users at the lower level choose routes and charging stations to minimize travel and charging costs. To account for range anxiety, we construct a battery-expanded network and apply a shortest path algorithm with Frank-Wolfe traffic assignment. Our primary contribution is developing the first exact solution algorithm for large scale EV charging station placement problems. We propose a Branch-and-Price-and-Cut algorithm enhanced with value function cuts and column generation. While existing research relies on heuristic methods that provide no optimality guarantees or exact algorithms that require prohibitively long runtimes, our exact algorithm delivers globally optimal solutions with mathematical certainty under a reasonable runtime. Computational experiments on the Eastern Massachusetts network (74 nodes, 248 links), the Anaheim network (416 nodes, 914 links), and the Barcelona network (110 zones, 1,020 nodes, and 2,512 links) demonstrate exceptional performance. Our algorithm terminates within minutes rather than hours, while achieving optimality gaps below 1% across all instances. This result represents a computational speedup of over two orders of magnitude compared to existing methods. The algorithm successfully handles problems with over 300,000 feasible combinations, which transform EV charging infrastructure planning from a computationally prohibitive problem into a tractable optimization task suitable for practical decision making problem for real world networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u7528\u4e8e\u5927\u89c4\u6a21\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u7ad9\u9009\u5740\u95ee\u9898\u7684\u7cbe\u786e\u6c42\u89e3\u7b97\u6cd5\uff0c\u901a\u8fc7\u5206\u652f\u5b9a\u4ef7\u5272\u5e73\u9762\u65b9\u6cd5\u5728\u5408\u7406\u65f6\u95f4\u5185\u83b7\u5f97\u5168\u5c40\u6700\u4f18\u89e3\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4f9d\u8d56\u65e0\u6cd5\u4fdd\u8bc1\u6700\u4f18\u6027\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u6216\u9700\u8981\u8fc7\u957f\u8fd0\u884c\u65f6\u95f4\u7684\u7cbe\u786e\u7b97\u6cd5\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u9645\u51b3\u7b56\u9700\u6c42\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u6a21\u578b\uff0c\u4e0a\u5c42\u89c4\u5212\u8005\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u9009\u62e9\u5145\u7535\u7ad9\u4f4d\u7f6e\u6700\u5927\u5316\u51c0\u6536\u76ca\uff0c\u4e0b\u5c42EV\u7528\u6237\u9009\u62e9\u8def\u7ebf\u548c\u5145\u7535\u7ad9\u6700\u5c0f\u5316\u51fa\u884c\u548c\u5145\u7535\u6210\u672c\u3002\u63d0\u51fa\u5206\u652f\u5b9a\u4ef7\u5272\u5e73\u9762\u7b97\u6cd5\uff0c\u7ed3\u5408\u503c\u51fd\u6570\u5272\u548c\u5217\u751f\u6210\u6280\u672f\u3002", "result": "\u5728\u9a6c\u8428\u8bf8\u585e\u5dde\u4e1c\u90e8\u7f51\u7edc\u3001\u963f\u7eb3\u6d77\u59c6\u7f51\u7edc\u548c\u5df4\u585e\u7f57\u90a3\u7f51\u7edc\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7b97\u6cd5\u5728\u51e0\u5206\u949f\u5185\u7ec8\u6b62\uff0c\u6700\u4f18\u6027\u5dee\u8ddd\u4f4e\u4e8e1%\uff0c\u8ba1\u7b97\u901f\u5ea6\u6bd4\u73b0\u6709\u65b9\u6cd5\u5feb\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u6210\u529f\u5904\u7406\u8d85\u8fc730\u4e07\u4e2a\u53ef\u884c\u7ec4\u5408\u7684\u95ee\u9898\uff0c\u5c06\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u4ece\u8ba1\u7b97\u4e0a\u4e0d\u53ef\u884c\u7684\u95ee\u9898\u8f6c\u53d8\u4e3a\u9002\u5408\u5b9e\u9645\u51b3\u7b56\u7684\u53ef\u5904\u7406\u4f18\u5316\u4efb\u52a1\u3002"}}
{"id": "2511.19859", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19859", "abs": "https://arxiv.org/abs/2511.19859", "authors": ["Xiangkai Ma", "Lekai Xing", "Han Zhang", "Wenzhong Li", "Sanglu Lu"], "title": "Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation", "comment": null, "summary": "Vision-Language-Action (VLA) models built upon Chain-of-Thought (CoT) have achieved remarkable success in advancing general-purpose robotic agents, owing to its significant perceptual comprehension. Recently, since text-only CoT struggles to adequately capture scene details in complex spatial environments, a highly promising strategy involves leveraging visual priors to guide robotic action generation. Nevertheless, these strategies face two inherent challenges: (i) a modality gap between visual observations and low-level actions, and (ii) unstable training due to competing objectives between visual prediction and action generation. To address these challenges, we propose a Vision-Integrated Trajectory Alignment (VITA) framework that learns a shared discrete latent space for vision and action, enabling joint modeling of perception and motor control. VITA introduces a implicit visual CoT: autoregressively generated tokens is simultaneously decoded into future frames predictions and robot actions, thereby internalizing visual dynamics as an inductive bias for motion planning. Extensive experiments on simulated and real-world environments demonstrate state-of-the-art performance. VITA improves 14.5\\%, 9.6\\% and 12.1\\% over existing baselines on CALVIN, LIBERO and SimplerEnv. Furthermore, VITA attains an average success rate of 80.5\\% across six real-world tasks, demonstrating its potential as a generalist robotic manipulation model.", "AI": {"tldr": "\u63d0\u51fa\u4e86VITA\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u89c6\u89c9\u548c\u52a8\u4f5c\u7684\u5171\u4eab\u79bb\u6563\u6f5c\u5728\u7a7a\u95f4\uff0c\u89e3\u51b3\u4e86\u89c6\u89c9\u89c2\u5bdf\u4e0e\u4f4e\u7ea7\u52a8\u4f5c\u4e4b\u95f4\u7684\u6a21\u6001\u5dee\u8ddd\u95ee\u9898\uff0c\u540c\u65f6\u5c06\u89c6\u89c9\u52a8\u6001\u4f5c\u4e3a\u8fd0\u52a8\u89c4\u5212\u7684\u5f52\u7eb3\u504f\u7f6e\u3002", "motivation": "\u57fa\u4e8e\u601d\u7ef4\u94fe\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u5728\u673a\u5668\u4eba\u4ee3\u7406\u65b9\u9762\u53d6\u5f97\u663e\u8457\u6210\u529f\uff0c\u4f46\u7eaf\u6587\u672c\u601d\u7ef4\u94fe\u96be\u4ee5\u6355\u6349\u590d\u6742\u7a7a\u95f4\u73af\u5883\u4e2d\u7684\u573a\u666f\u7ec6\u8282\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u89c6\u89c9\u89c2\u5bdf\u4e0e\u52a8\u4f5c\u7684\u6a21\u6001\u5dee\u8ddd\u4ee5\u53ca\u89c6\u89c9\u9884\u6d4b\u4e0e\u52a8\u4f5c\u751f\u6210\u76ee\u6807\u51b2\u7a81\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u89c6\u89c9\u96c6\u6210\u8f68\u8ff9\u5bf9\u9f50(VITA)\u6846\u67b6\uff0c\u5b66\u4e60\u89c6\u89c9\u548c\u52a8\u4f5c\u7684\u5171\u4eab\u79bb\u6563\u6f5c\u5728\u7a7a\u95f4\uff0c\u901a\u8fc7\u9690\u5f0f\u89c6\u89c9\u601d\u7ef4\u94fe\u540c\u65f6\u89e3\u7801\u751f\u6210\u672a\u6765\u5e27\u9884\u6d4b\u548c\u673a\u5668\u4eba\u52a8\u4f5c\uff0c\u5c06\u89c6\u89c9\u52a8\u6001\u5185\u5316\u4e3a\u8fd0\u52a8\u89c4\u5212\u7684\u5f52\u7eb3\u504f\u7f6e\u3002", "result": "\u5728CALVIN\u3001LIBERO\u548cSimplerEnv\u57fa\u51c6\u4e0a\u5206\u522b\u6bd4\u73b0\u6709\u57fa\u7ebf\u63d0\u534714.5%\u30019.6%\u548c12.1%\uff0c\u5728\u516d\u4e2a\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u5e73\u5747\u6210\u529f\u7387\u8fbe\u523080.5%\u3002", "conclusion": "VITA\u6846\u67b6\u5728\u6a21\u62df\u548c\u771f\u5b9e\u73af\u5883\u4e2d\u5747\u8868\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u901a\u7528\u673a\u5668\u4eba\u64cd\u4f5c\u6a21\u578b\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.19829", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19829", "abs": "https://arxiv.org/abs/2511.19829", "authors": ["Ke Chen", "Yifeng Wang", "Hassan Almosapeeh", "Haohan Wang"], "title": "A Unified Evaluation-Instructed Framework for Query-Dependent Prompt Optimization", "comment": null, "summary": "Most prompt-optimization methods refine a single static template, making them ineffective in complex and dynamic user scenarios. Existing query-dependent approaches rely on unstable textual feedback or black-box reward models, providing weak and uninterpretable optimization signals. More fundamentally, prompt quality itself lacks a unified, systematic definition, resulting in fragmented and unreliable evaluation signals. Our approach first establishes a performance-oriented, systematic, and comprehensive prompt evaluation framework. Furthermore, we develop and finetune an execution-free evaluator that predicts multi-dimensional quality scores directly from text. The evaluator then instructs a metric-aware optimizer that diagnoses failure modes and rewrites prompts in an interpretable, query-dependent manner. Our evaluator achieves the strongest accuracy in predicting prompt performance, and the evaluation-instructed optimization consistently surpass both static-template and query-dependent baselines across eight datasets and on three backbone models. Overall, we propose a unified, metric-grounded perspective on prompt quality, and demonstrated that our evaluation-instructed optimization pipeline delivers stable, interpretable, and model-agnostic improvements across diverse tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bc4\u4f30\u6307\u5bfc\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5efa\u7acb\u7cfb\u7edf\u5316\u7684\u63d0\u793a\u8bc4\u4f30\u6846\u67b6\u548c\u8bad\u7ec3\u6267\u884c\u65e0\u5173\u7684\u8bc4\u4f30\u5668\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u3001\u67e5\u8be2\u4f9d\u8d56\u7684\u63d0\u793a\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u4f18\u5316\u9759\u6001\u6a21\u677f\uff0c\u5728\u590d\u6742\u52a8\u6001\u573a\u666f\u4e2d\u6548\u679c\u6709\u9650\uff1b\u67e5\u8be2\u4f9d\u8d56\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u7a33\u5b9a\u7684\u6587\u672c\u53cd\u9988\u6216\u9ed1\u76d2\u5956\u52b1\u6a21\u578b\uff0c\u63d0\u4f9b\u5f31\u4e14\u4e0d\u53ef\u89e3\u91ca\u7684\u4f18\u5316\u4fe1\u53f7\uff1b\u63d0\u793a\u8d28\u91cf\u7f3a\u4e4f\u7edf\u4e00\u7cfb\u7edf\u5b9a\u4e49\u3002", "method": "\u5efa\u7acb\u6027\u80fd\u5bfc\u5411\u7684\u7cfb\u7edf\u5316\u63d0\u793a\u8bc4\u4f30\u6846\u67b6\uff1b\u5f00\u53d1\u5e76\u5fae\u8c03\u6267\u884c\u65e0\u5173\u7684\u8bc4\u4f30\u5668\uff0c\u76f4\u63a5\u4ece\u6587\u672c\u9884\u6d4b\u591a\u7ef4\u8d28\u91cf\u5206\u6570\uff1b\u8bc4\u4f30\u5668\u6307\u5bfc\u6307\u6807\u611f\u77e5\u7684\u4f18\u5316\u5668\u8bca\u65ad\u5931\u8d25\u6a21\u5f0f\u5e76\u4ee5\u53ef\u89e3\u91ca\u65b9\u5f0f\u91cd\u5199\u63d0\u793a\u3002", "result": "\u8bc4\u4f30\u5668\u5728\u9884\u6d4b\u63d0\u793a\u6027\u80fd\u65b9\u9762\u8fbe\u5230\u6700\u9ad8\u51c6\u786e\u7387\uff1b\u8bc4\u4f30\u6307\u5bfc\u7684\u4f18\u5316\u57288\u4e2a\u6570\u636e\u96c6\u548c3\u4e2a\u9aa8\u5e72\u6a21\u578b\u4e0a\u6301\u7eed\u8d85\u8d8a\u9759\u6001\u6a21\u677f\u548c\u67e5\u8be2\u4f9d\u8d56\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u3001\u57fa\u4e8e\u6307\u6807\u7684\u63d0\u793a\u8d28\u91cf\u89c6\u89d2\uff0c\u8bc1\u660e\u4e86\u8bc4\u4f30\u6307\u5bfc\u7684\u4f18\u5316\u7ba1\u9053\u80fd\u591f\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e2d\u63d0\u4f9b\u7a33\u5b9a\u3001\u53ef\u89e3\u91ca\u4e14\u6a21\u578b\u65e0\u5173\u7684\u6539\u8fdb\u3002"}}
{"id": "2511.20554", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.20554", "abs": "https://arxiv.org/abs/2511.20554", "authors": ["Aditya Shah", "Tyler Menezes"], "title": "Assessing the Effectiveness of Selective Marketing to Broaden Participation in CS Education", "comment": "Accepted at SIGCSE TS 2026", "summary": "Many studies have aimed to broaden participation in computing (BPC) through extracurricular educational initiatives. When these initiatives are structured as open-enrollment extracurricular programs, their success often depends on their marketing approach. However, there is little in the computing education research literature about how to conduct effective marketing for these initiatives. We describe the changes made to the marketing strategy of one such program, an educational hackathon for middle school and high school students in the Pacific Northwest. These included reducing promotion to affluent families, using targeted school-based communication, and emphasizing cost supports during initial promotion. We then compare attendance and self-reported demographics before and after the intervention. Results indicate a higher proportion of students from marginalized and low-income communities and no reduction in overall attendance.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6539\u8fdb\u6559\u80b2\u6027\u9ed1\u5ba2\u677e\u7684\u8425\u9500\u7b56\u7565\uff0c\u6210\u529f\u63d0\u9ad8\u4e86\u8fb9\u7f18\u5316\u548c\u4f4e\u6536\u5165\u793e\u533a\u5b66\u751f\u7684\u53c2\u4e0e\u6bd4\u4f8b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u603b\u4f53\u53c2\u4e0e\u4eba\u6570\u3002", "motivation": "\u8ba1\u7b97\u6559\u80b2\u9886\u57df\u7684\u8bfe\u5916\u9879\u76ee\u901a\u5e38\u4f9d\u8d56\u8425\u9500\u7b56\u7565\u6765\u5438\u5f15\u53c2\u4e0e\u8005\uff0c\u4f46\u73b0\u6709\u6587\u732e\u7f3a\u4e4f\u5173\u4e8e\u5982\u4f55\u6709\u6548\u8425\u9500\u8fd9\u4e9b\u9879\u76ee\u7684\u6307\u5bfc\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u6539\u8fdb\u8425\u9500\u7b56\u7565\u6765\u62d3\u5bbd\u8ba1\u7b97\u6559\u80b2\u7684\u53c2\u4e0e\u8303\u56f4\u3002", "method": "\u5bf9\u4e00\u4e2a\u9762\u5411\u4e2d\u5b66\u751f\u7684\u6559\u80b2\u6027\u9ed1\u5ba2\u677e\u9879\u76ee\u8fdb\u884c\u8425\u9500\u7b56\u7565\u8c03\u6574\uff1a\u51cf\u5c11\u5bf9\u5bcc\u88d5\u5bb6\u5ead\u7684\u63a8\u5e7f\u3001\u4f7f\u7528\u9488\u5bf9\u5b66\u6821\u7684\u5b9a\u5411\u6c9f\u901a\u3001\u5728\u521d\u671f\u5ba3\u4f20\u4e2d\u5f3a\u8c03\u6210\u672c\u652f\u6301\u3002\u7136\u540e\u6bd4\u8f83\u5e72\u9884\u524d\u540e\u7684\u53c2\u4e0e\u60c5\u51b5\u548c\u4eba\u53e3\u7edf\u8ba1\u6570\u636e\u3002", "result": "\u5e72\u9884\u540e\uff0c\u6765\u81ea\u8fb9\u7f18\u5316\u548c\u4f4e\u6536\u5165\u793e\u533a\u7684\u5b66\u751f\u6bd4\u4f8b\u663e\u8457\u63d0\u9ad8\uff0c\u603b\u4f53\u53c2\u4e0e\u4eba\u6570\u6ca1\u6709\u51cf\u5c11\u3002", "conclusion": "\u901a\u8fc7\u6709\u9488\u5bf9\u6027\u7684\u8425\u9500\u7b56\u7565\u8c03\u6574\uff0c\u53ef\u4ee5\u5728\u4e0d\u964d\u4f4e\u603b\u4f53\u53c2\u4e0e\u7387\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u63d0\u9ad8\u8ba1\u7b97\u6559\u80b2\u9879\u76ee\u4e2d\u8fb9\u7f18\u5316\u548c\u4f4e\u6536\u5165\u5b66\u751f\u7684\u53c2\u4e0e\u5ea6\u3002"}}
{"id": "2511.19961", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19961", "abs": "https://arxiv.org/abs/2511.19961", "authors": ["Zhenyu Tao", "Wei Xu", "Xiaohu You"], "title": "Toward Trustworthy Digital Twins in Agentic AI-based Wireless Network Optimization: Challenges, Solutions, and Opportunities", "comment": null, "summary": "Optimizing modern wireless networks is exceptionally challenging due to their high dynamism and complexity. While the agentic artificial intelligence (AI) powered by reinforcement learning (RL) offers a promising solution, its practical application is limited by prohibitive exploration costs and potential risks in the real world. The emerging digital twin (DT) technology provides a safe and controlled virtual environment for agentic AI training, but its effectiveness critically depends on the DT's fidelity. Policies trained in a low-fidelity DT that does not accurately represent the physical network may experience severe performance degradation upon real-world deployment. In this article, we introduce a unified DT evaluation framework to ensure trustworthy DTs in agentic AI-based network optimization. This evaluation framework shifts from conventional isolated physical accuracy metrics, such as wireless channel and user trajectory similarities, to a more holistic, task-centric DT assessment. We demonstrate it as an effective guideline for design, selection, and lifecycle management of wireless network DTs. A comprehensive case study on a real-world wireless network testbed shows how this evaluation framework is used to pre-filter candidate DTs, leading to a significant reduction in training and testing costs without sacrificing deployment performance. Finally, potential research opportunities are discussed.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u7684\u6570\u5b57\u5b6a\u751f\u8bc4\u4f30\u6846\u67b6\uff0c\u4ece\u4f20\u7edf\u7269\u7406\u7cbe\u5ea6\u6307\u6807\u8f6c\u5411\u4efb\u52a1\u4e2d\u5fc3\u5316\u8bc4\u4f30\uff0c\u786e\u4fdd\u57fa\u4e8e\u667a\u80fdAI\u7684\u7f51\u7edc\u4f18\u5316\u4e2d\u53ef\u4fe1\u8d56\u7684\u6570\u5b57\u5b6a\u751f\u3002", "motivation": "\u73b0\u4ee3\u65e0\u7ebf\u7f51\u7edc\u4f18\u5316\u9762\u4e34\u9ad8\u52a8\u6001\u6027\u548c\u590d\u6742\u6027\u6311\u6218\uff0c\u667a\u80fdAI\u63d0\u4f9b\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u53d7\u9650\u4e8e\u9ad8\u6602\u7684\u63a2\u7d22\u6210\u672c\u548c\u73b0\u5b9e\u98ce\u9669\u3002\u6570\u5b57\u5b6a\u751f\u6280\u672f\u63d0\u4f9b\u5b89\u5168\u8bad\u7ec3\u73af\u5883\uff0c\u4f46\u5176\u6709\u6548\u6027\u53d6\u51b3\u4e8e\u4fdd\u771f\u5ea6\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u7684\u6570\u5b57\u5b6a\u751f\u8bc4\u4f30\u6846\u67b6\uff0c\u4ece\u5b64\u7acb\u7269\u7406\u7cbe\u5ea6\u6307\u6807\u8f6c\u5411\u6574\u4f53\u4efb\u52a1\u4e2d\u5fc3\u5316\u8bc4\u4f30\uff0c\u4f5c\u4e3a\u65e0\u7ebf\u7f51\u7edc\u6570\u5b57\u5b6a\u751f\u8bbe\u8ba1\u3001\u9009\u62e9\u548c\u751f\u547d\u5468\u671f\u7ba1\u7406\u7684\u6709\u6548\u6307\u5357\u3002", "result": "\u5728\u771f\u5b9e\u65e0\u7ebf\u7f51\u7edc\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u8bc4\u4f30\u6846\u67b6\u53ef\u7528\u4e8e\u9884\u7b5b\u9009\u5019\u9009\u6570\u5b57\u5b6a\u751f\uff0c\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6210\u672c\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u90e8\u7f72\u6027\u80fd\u3002", "conclusion": "\u8be5\u8bc4\u4f30\u6846\u67b6\u4e3a\u57fa\u4e8e\u667a\u80fdAI\u7684\u7f51\u7edc\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u4fe1\u8d56\u7684\u6570\u5b57\u5b6a\u751f\u4fdd\u969c\uff0c\u5e76\u8ba8\u8bba\u4e86\u6f5c\u5728\u7684\u7814\u7a76\u673a\u4f1a\u3002"}}
{"id": "2511.19869", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19869", "abs": "https://arxiv.org/abs/2511.19869", "authors": ["Eito Sato", "Takahiro Wada"], "title": "Human-Centered Cooperative Control Coupling Autonomous and Haptic Shared Control via Control Barrier Function", "comment": null, "summary": "Haptic shared control (HSC) is effective in teleoperation when full autonomy is limited by uncertainty or sensing constraints. However, autonomous control performance achieved by maximizing HSC strength is limited because the dynamics of the joystick and human arm affect the robot's behavior. We propose a cooperative framework coupling a joystick-independent autonomous controller with HSC. A control barrier function ignores joystick inputs within a safe region determined by the human operator in real-time, while HSC is engaged otherwise. A pilot experiment on simulated tasks with tele-operated underwater robot in virtual environment demonstrated improved accuracy and reduced required time over conventional HSC.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u72ec\u7acb\u81ea\u4e3b\u63a7\u5236\u5668\u4e0e\u89e6\u89c9\u5171\u4eab\u63a7\u5236\u7684\u534f\u4f5c\u6846\u67b6\uff0c\u5728\u5b89\u5168\u533a\u57df\u5185\u5ffd\u7565\u64cd\u7eb5\u6746\u8f93\u5165\uff0c\u5176\u4ed6\u60c5\u51b5\u4e0b\u542f\u7528\u89e6\u89c9\u5171\u4eab\u63a7\u5236\uff0c\u63d0\u9ad8\u4e86\u8fdc\u7a0b\u64cd\u4f5c\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u89e6\u89c9\u5171\u4eab\u63a7\u5236\u5728\u6700\u5927\u5316\u63a7\u5236\u5f3a\u5ea6\u65f6\uff0c\u7531\u4e8e\u64cd\u7eb5\u6746\u548c\u4eba\u7c7b\u624b\u81c2\u7684\u52a8\u529b\u5b66\u5f71\u54cd\u673a\u5668\u4eba\u884c\u4e3a\uff0c\u5176\u81ea\u4e3b\u63a7\u5236\u6027\u80fd\u53d7\u5230\u9650\u5236\u3002", "method": "\u63d0\u51fa\u534f\u4f5c\u6846\u67b6\uff0c\u5c06\u72ec\u7acb\u4e8e\u64cd\u7eb5\u6746\u7684\u81ea\u4e3b\u63a7\u5236\u5668\u4e0e\u89e6\u89c9\u5171\u4eab\u63a7\u5236\u8026\u5408\u3002\u4f7f\u7528\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u5728\u4eba\u7c7b\u64cd\u4f5c\u5458\u5b9e\u65f6\u786e\u5b9a\u7684\u5b89\u5168\u533a\u57df\u5185\u5ffd\u7565\u64cd\u7eb5\u6746\u8f93\u5165\uff0c\u5176\u4ed6\u60c5\u51b5\u4e0b\u542f\u7528\u89e6\u89c9\u5171\u4eab\u63a7\u5236\u3002", "result": "\u5728\u865a\u62df\u73af\u5883\u4e2d\u5bf9\u8fdc\u7a0b\u64cd\u4f5c\u6c34\u4e0b\u673a\u5668\u4eba\u8fdb\u884c\u6a21\u62df\u4efb\u52a1\u7684\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u4f20\u7edf\u89e6\u89c9\u5171\u4eab\u63a7\u5236\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u5e76\u51cf\u5c11\u4e86\u6240\u9700\u65f6\u95f4\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u534f\u4f5c\u6846\u67b6\u80fd\u591f\u6709\u6548\u514b\u670d\u4f20\u7edf\u89e6\u89c9\u5171\u4eab\u63a7\u5236\u7684\u5c40\u9650\u6027\uff0c\u5728\u8fdc\u7a0b\u64cd\u4f5c\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2511.19849", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19849", "abs": "https://arxiv.org/abs/2511.19849", "authors": ["Dominik Wagner", "Leon Witzman", "Luke Ong"], "title": "Reinforcement Learning with $\u03c9$-Regular Objectives and Constraints", "comment": null, "summary": "Reinforcement learning (RL) commonly relies on scalar rewards with limited ability to express temporal, conditional, or safety-critical goals, and can lead to reward hacking. Temporal logic expressible via the more general class of $\u03c9$-regular objectives addresses this by precisely specifying rich behavioural properties. Even still, measuring performance by a single scalar (be it reward or satisfaction probability) masks safety-performance trade-offs that arise in settings with a tolerable level of risk.\n  We address both limitations simultaneously by combining $\u03c9$-regular objectives with explicit constraints, allowing safety requirements and optimisation targets to be treated separately. We develop a model-based RL algorithm based on linear programming, which in the limit produces a policy maximising the probability of satisfying an $\u03c9$-regular objective while also adhering to $\u03c9$-regular constraints within specified thresholds. Furthermore, we establish a translation to constrained limit-average problems with optimality-preserving guarantees.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u03c9-\u6b63\u5219\u76ee\u6807\u548c\u663e\u5f0f\u7ea6\u675f\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u89e3\u51b3\u4f20\u7edf\u6807\u91cf\u5956\u52b1\u8868\u8fbe\u80fd\u529b\u6709\u9650\u548c\u5b89\u5168\u6027-\u6027\u80fd\u6743\u8861\u95ee\u9898", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4f9d\u8d56\u6807\u91cf\u5956\u52b1\uff0c\u8868\u8fbe\u80fd\u529b\u6709\u9650\u4e14\u5bb9\u6613\u5bfc\u81f4\u5956\u52b1\u7834\u89e3\uff0c\u65e0\u6cd5\u6709\u6548\u8868\u8fbe\u65f6\u95f4\u6027\u3001\u6761\u4ef6\u6027\u6216\u5b89\u5168\u5173\u952e\u76ee\u6807\uff0c\u540c\u65f6\u5355\u4e00\u6807\u91cf\u6307\u6807\u63a9\u76d6\u4e86\u5b89\u5168\u6027-\u6027\u80fd\u6743\u8861", "method": "\u5f00\u53d1\u57fa\u4e8e\u7ebf\u6027\u89c4\u5212\u7684\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u7ed3\u5408\u03c9-\u6b63\u5219\u76ee\u6807\u548c\u7ea6\u675f\uff0c\u5c06\u5b89\u5168\u8981\u6c42\u548c\u4f18\u5316\u76ee\u6807\u5206\u5f00\u5904\u7406", "result": "\u7b97\u6cd5\u5728\u6781\u9650\u60c5\u51b5\u4e0b\u80fd\u4ea7\u751f\u6700\u5927\u5316\u6ee1\u8db3\u03c9-\u6b63\u5219\u76ee\u6807\u6982\u7387\u7684\u7b56\u7565\uff0c\u540c\u65f6\u9075\u5b88\u6307\u5b9a\u9608\u503c\u7684\u03c9-\u6b63\u5219\u7ea6\u675f", "conclusion": "\u5efa\u7acb\u4e86\u5230\u7ea6\u675f\u6781\u9650\u5e73\u5747\u95ee\u9898\u7684\u8f6c\u6362\uff0c\u5e76\u4fdd\u6301\u6700\u4f18\u6027\u4fdd\u8bc1\uff0c\u4e3a\u89e3\u51b3\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6"}}
{"id": "2511.20637", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2511.20637", "abs": "https://arxiv.org/abs/2511.20637", "authors": ["Frederik Zuiderveen Borgesius"], "title": "Behavioural Sciences and the Regulation of Privacy on the Internet", "comment": null, "summary": "This chapter examines the policy implications of behavioural sciences insights for the regulation of privacy on the Internet, by focusing in particular on behavioural targeting. This marketing technique involves tracking people's online behaviour to use the collected information to show people individually targeted advertisements. Enforcing data protection law may not be enough to protect privacy in this area. I argue that, if society is better off when certain behavioural targeting practices do not happen, policymakers should consider banning them.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u884c\u4e3a\u79d1\u5b66\u5bf9\u4e92\u8054\u7f51\u9690\u79c1\u76d1\u7ba1\u7684\u653f\u7b56\u542f\u793a\uff0c\u7279\u522b\u5173\u6ce8\u884c\u4e3a\u5b9a\u5411\u8425\u9500\u3002\u4f5c\u8005\u8ba4\u4e3a\u4ec5\u9760\u6570\u636e\u4fdd\u62a4\u6cd5\u4e0d\u8db3\u4ee5\u4fdd\u62a4\u9690\u79c1\uff0c\u5efa\u8bae\u7981\u6b62\u67d0\u4e9b\u6709\u5bb3\u7684\u884c\u4e3a\u5b9a\u5411\u5b9e\u8df5\u3002", "motivation": "\u884c\u4e3a\u5b9a\u5411\u8425\u9500\u901a\u8fc7\u8ffd\u8e2a\u7528\u6237\u5728\u7ebf\u884c\u4e3a\u6765\u5c55\u793a\u4e2a\u6027\u5316\u5e7f\u544a\uff0c\u73b0\u6709\u6570\u636e\u4fdd\u62a4\u6cd5\u53ef\u80fd\u4e0d\u8db3\u4ee5\u6709\u6548\u4fdd\u62a4\u9690\u79c1\uff0c\u9700\u8981\u4ece\u884c\u4e3a\u79d1\u5b66\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u76d1\u7ba1\u653f\u7b56\u3002", "method": "\u901a\u8fc7\u5206\u6790\u884c\u4e3a\u5b9a\u5411\u8425\u9500\u7684\u6280\u672f\u539f\u7406\u548c\u9690\u79c1\u5f71\u54cd\uff0c\u7ed3\u5408\u884c\u4e3a\u79d1\u5b66\u7406\u8bba\uff0c\u8bba\u8bc1\u73b0\u6709\u6cd5\u5f8b\u4fdd\u62a4\u7684\u5c40\u9650\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4ec5\u4f9d\u9760\u6570\u636e\u4fdd\u62a4\u6cd5\u6267\u884c\u65e0\u6cd5\u5145\u5206\u4fdd\u62a4\u9690\u79c1\uff0c\u67d0\u4e9b\u884c\u4e3a\u5b9a\u5411\u5b9e\u8df5\u5bf9\u793e\u4f1a\u6574\u4f53\u6709\u5bb3\u3002", "conclusion": "\u5982\u679c\u67d0\u4e9b\u884c\u4e3a\u5b9a\u5411\u5b9e\u8df5\u5bf9\u793e\u4f1a\u4e0d\u5229\uff0c\u653f\u7b56\u5236\u5b9a\u8005\u5e94\u8003\u8651\u76f4\u63a5\u7981\u6b62\u8fd9\u4e9b\u5b9e\u8df5\uff0c\u800c\u4e0d\u4ec5\u4ec5\u4f9d\u8d56\u6570\u636e\u4fdd\u62a4\u6cd5\u7684\u6267\u884c\u3002"}}
{"id": "2511.20043", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20043", "abs": "https://arxiv.org/abs/2511.20043", "authors": ["Youzhe Yang", "Hafiz Majid Hussain", "Juha Haakana", "Pedro Nardelli"], "title": "Assessing the Technical and Environmental Impacts of Energy Management Systems in Smart Ports", "comment": null, "summary": "A vital strategy for ports to mitigate the environmental impact of the maritime industry, while complying with frameworks such as the European Green Deal and the Sustainable Development Goals (SDGs), entails the systematic implementation of comprehensive energy management solutions. This paper provides a baseline evaluation of the energy management systems (EMSs) implementation and their impact on energy consumption, carbon emissions, and operational costs in smart ports. Initially, we provide a systematic review of the literature focusing on case studies from prominent ports, including Hamburg, Genoa, Jurong, and Shanghai Yangshan Phase IV. The analysis emphasises key aspects such as energy efficiency, reductions in emissions, and the minimization of operational costs. Subsequently, we formulate an optimisation model to simulate load dispatch, carbon emission reduction, and transport scheduling. Results indicate that EMS deployment reduces annual energy consumption and carbon emissions significantly by approximately 7%-8% and 11%-12% respectively, while achieving substantial cost savings of 30%. The study also identifies critical challenges, including system integration, data quality issues, cybersecurity risks, and the need for standardization. These findings provide valuable insights for port authorities and policymakers, supporting the transition toward more sustainable and efficient port operations.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u667a\u80fd\u6e2f\u53e3\u80fd\u6e90\u7ba1\u7406\u7cfb\u7edf(EMS)\u7684\u5b9e\u65bd\u6548\u679c\uff0c\u53d1\u73b0\u5176\u80fd\u663e\u8457\u964d\u4f4e\u80fd\u80177%-8%\u3001\u78b3\u6392\u653e11%-12%\uff0c\u5e76\u8282\u770130%\u8fd0\u8425\u6210\u672c\uff0c\u4f46\u9762\u4e34\u7cfb\u7edf\u96c6\u6210\u3001\u6570\u636e\u8d28\u91cf\u7b49\u6311\u6218\u3002", "motivation": "\u4e3a\u5e2e\u52a9\u6e2f\u53e3\u51cf\u5c11\u6d77\u4e8b\u884c\u4e1a\u73af\u5883\u5f71\u54cd\uff0c\u9075\u5b88\u6b27\u6d32\u7eff\u8272\u534f\u8bae\u548c\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\uff0c\u9700\u8981\u7cfb\u7edf\u5b9e\u65bd\u7efc\u5408\u80fd\u6e90\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u9996\u5148\u5bf9\u6c49\u5821\u3001\u70ed\u90a3\u4e9a\u3001\u88d5\u5eca\u548c\u4e0a\u6d77\u6d0b\u5c71\u56db\u671f\u7b49\u4e3b\u8981\u6e2f\u53e3\u6848\u4f8b\u8fdb\u884c\u7cfb\u7edf\u6587\u732e\u56de\u987e\uff0c\u7136\u540e\u6784\u5efa\u4f18\u5316\u6a21\u578b\u6a21\u62df\u8d1f\u8377\u8c03\u5ea6\u3001\u78b3\u51cf\u6392\u548c\u8fd0\u8f93\u8c03\u5ea6\u3002", "result": "EMS\u90e8\u7f72\u4f7f\u5e74\u80fd\u8017\u964d\u4f4e\u7ea67%-8%\uff0c\u78b3\u6392\u653e\u51cf\u5c1111%-12%\uff0c\u5e76\u5b9e\u73b030%\u7684\u6210\u672c\u8282\u7ea6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u6e2f\u53e3\u7ba1\u7406\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\uff0c\u652f\u6301\u5411\u66f4\u53ef\u6301\u7eed\u548c\u9ad8\u6548\u7684\u6e2f\u53e3\u8fd0\u8425\u8f6c\u578b\uff0c\u4f46\u9700\u89e3\u51b3\u7cfb\u7edf\u96c6\u6210\u3001\u6570\u636e\u8d28\u91cf\u7b49\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2511.19914", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19914", "abs": "https://arxiv.org/abs/2511.19914", "authors": ["Dapeng Zhang", "Fei Shen", "Rui Zhao", "Yinda Chen", "Peng Zhi", "Chenyang Li", "Rui Zhou", "Qingguo Zhou"], "title": "CoC-VLA: Delving into Adversarial Domain Transfer for Explainable Autonomous Driving via Chain-of-Causality Visual-Language-Action Model", "comment": null, "summary": "Autonomous driving represents a prominent application of artificial intelligence. Recent approaches have shifted from focusing solely on common scenarios to addressing complex, long-tail situations such as subtle human behaviors, traffic accidents, and non-compliant driving patterns. Given the demonstrated capabilities of large language models (LLMs) in understanding visual and natural language inputs and following instructions, recent methods have integrated LLMs into autonomous driving systems to enhance reasoning, interpretability, and performance across diverse scenarios. However, existing methods typically rely either on real-world data, which is suitable for industrial deployment, or on simulation data tailored to rare or hard case scenarios. Few approaches effectively integrate the complementary advantages of both data sources. To address this limitation, we propose a novel VLM-guided, end-to-end adversarial transfer framework for autonomous driving that transfers long-tail handling capabilities from simulation to real-world deployment, named CoC-VLA. The framework comprises a teacher VLM model, a student VLM model, and a discriminator. Both the teacher and student VLM models utilize a shared base architecture, termed the Chain-of-Causality Visual-Language Model (CoC VLM), which integrates temporal information via an end-to-end text adapter. This architecture supports chain-of-thought reasoning to infer complex driving logic. The teacher and student VLM models are pre-trained separately on simulated and real-world datasets. The discriminator is trained adversarially to facilitate the transfer of long-tail handling capabilities from simulated to real-world environments by the student VLM model, using a novel backpropagation strategy.", "AI": {"tldr": "\u63d0\u51faCoC-VLA\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u8fc1\u79fb\u5b66\u4e60\u5c06\u6a21\u62df\u73af\u5883\u4e2d\u7684\u957f\u5c3e\u573a\u666f\u5904\u7406\u80fd\u529b\u8f6c\u79fb\u5230\u771f\u5b9e\u4e16\u754c\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u771f\u5b9e\u4e16\u754c\u6570\u636e\uff08\u9002\u5408\u5de5\u4e1a\u90e8\u7f72\uff09\uff0c\u8981\u4e48\u4f7f\u7528\u6a21\u62df\u6570\u636e\uff08\u9488\u5bf9\u7f55\u89c1\u573a\u666f\uff09\uff0c\u4f46\u5f88\u5c11\u80fd\u6709\u6548\u6574\u5408\u4e24\u8005\u7684\u4e92\u8865\u4f18\u52bf", "method": "\u4f7f\u7528\u6559\u5e08-\u5b66\u751fVLM\u6a21\u578b\u548c\u5224\u522b\u5668\uff0c\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u5c06\u6a21\u62df\u73af\u5883\u4e2d\u7684\u957f\u5c3e\u5904\u7406\u80fd\u529b\u8fc1\u79fb\u5230\u771f\u5b9e\u4e16\u754c\uff0c\u91c7\u7528\u94fe\u5f0f\u56e0\u679c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6574\u5408\u65f6\u5e8f\u4fe1\u606f", "result": "\u6846\u67b6\u652f\u6301\u590d\u6742\u9a7e\u9a76\u903b\u8f91\u7684\u63a8\u7406\uff0c\u80fd\u591f\u5c06\u6a21\u62df\u73af\u5883\u4e2d\u7684\u957f\u5c3e\u573a\u666f\u5904\u7406\u80fd\u529b\u6709\u6548\u8fc1\u79fb\u5230\u771f\u5b9e\u4e16\u754c\u90e8\u7f72", "conclusion": "CoC-VLA\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u6a21\u62df\u4e0e\u771f\u5b9e\u4e16\u754c\u6570\u636e\u6574\u5408\u7684\u6311\u6218\uff0c\u63d0\u5347\u4e86\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u590d\u6742\u957f\u5c3e\u573a\u666f\u4e2d\u7684\u5904\u7406\u80fd\u529b"}}
{"id": "2511.19864", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19864", "abs": "https://arxiv.org/abs/2511.19864", "authors": ["Valerie Lockhart", "Dan McCreary", "Troy A. Peterson"], "title": "MicroSims: A Framework for AI-Generated, Scalable Educational Simulations with Universal Embedding and Adaptive Learning Support", "comment": "42 pages, 4 figures", "summary": "Educational simulations have long been recognized as powerful tools for enhancing learning outcomes, yet their creation has traditionally required substantial resources and technical expertise. This paper introduces MicroSims a novel framework for creating lightweight, interactive educational simulations that can be rapidly generated using artificial intelligence, universally embedded across digital learning platforms, and easily customized without programming knowledge. MicroSims occupy a unique position at the intersection of three key innovations: (1) standardized design patterns that enable AI-assisted generation, (2) iframe-based architecture that provides universal embedding and sandboxed security, and (3) transparent, modifiable code that supports customization and pedagogical transparency. We present a comprehensive framework encompassing design principles, technical architecture, metadata standards, and development workflows. Drawing on empirical research from physics education studies and meta-analyses across STEM disciplines, we demonstrate that interactive simulations can improve conceptual understanding by up to 30-40\\% compared to traditional instruction. MicroSims extend these benefits while addressing persistent barriers of cost, technical complexity, and platform dependence. This work has significant implications for educational equity, and low-cost intelligent interactive textbooks that enabling educators worldwide to create customized, curriculum-aligned simulations on demand. We discuss implementation considerations, present evidence of effectiveness, and outline future directions for AI-powered adaptive learning systems built on the MicroSim foundation.", "AI": {"tldr": "MicroSims\u662f\u4e00\u4e2a\u7528\u4e8e\u521b\u5efa\u8f7b\u91cf\u7ea7\u4ea4\u4e92\u5f0f\u6559\u80b2\u6a21\u62df\u7684AI\u9a71\u52a8\u6846\u67b6\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u8bbe\u8ba1\u6a21\u5f0f\u3001iframe\u67b6\u6784\u548c\u53ef\u4fee\u6539\u4ee3\u7801\uff0c\u4f7f\u6559\u80b2\u5de5\u4f5c\u8005\u65e0\u9700\u7f16\u7a0b\u77e5\u8bc6\u5c31\u80fd\u5feb\u901f\u751f\u6210\u548c\u5b9a\u5236\u6a21\u62df\u5185\u5bb9\u3002", "motivation": "\u4f20\u7edf\u6559\u80b2\u6a21\u62df\u521b\u5efa\u9700\u8981\u5927\u91cf\u8d44\u6e90\u548c\u6280\u672f\u4e13\u957f\uff0c\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002MicroSims\u65e8\u5728\u89e3\u51b3\u6210\u672c\u3001\u6280\u672f\u590d\u6742\u6027\u548c\u5e73\u53f0\u4f9d\u8d56\u7b49\u969c\u788d\uff0c\u4fc3\u8fdb\u6559\u80b2\u516c\u5e73\u3002", "method": "\u91c7\u7528\u6807\u51c6\u5316\u8bbe\u8ba1\u6a21\u5f0f\u5b9e\u73b0AI\u8f85\u52a9\u751f\u6210\uff0ciframe\u67b6\u6784\u786e\u4fdd\u901a\u7528\u5d4c\u5165\u548c\u6c99\u76d2\u5b89\u5168\uff0c\u900f\u660e\u53ef\u4fee\u6539\u4ee3\u7801\u652f\u6301\u5b9a\u5236\u5316\uff0c\u5305\u542b\u8bbe\u8ba1\u539f\u5219\u3001\u6280\u672f\u67b6\u6784\u3001\u5143\u6570\u636e\u6807\u51c6\u548c\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "\u57fa\u4e8e\u7269\u7406\u6559\u80b2\u7814\u7a76\u548cSTEM\u5143\u5206\u6790\uff0c\u4ea4\u4e92\u5f0f\u6a21\u62df\u53ef\u5c06\u6982\u5ff5\u7406\u89e3\u63d0\u534730-40%\u3002MicroSims\u5728\u4fdd\u6301\u8fd9\u4e9b\u76ca\u5904\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u521b\u5efa\u95e8\u69db\u3002", "conclusion": "MicroSims\u4e3a\u5168\u7403\u6559\u80b2\u5de5\u4f5c\u8005\u63d0\u4f9b\u4e86\u6309\u9700\u521b\u5efa\u5b9a\u5236\u5316\u3001\u8bfe\u7a0b\u5bf9\u9f50\u6a21\u62df\u7684\u80fd\u529b\uff0c\u4e3a\u57fa\u4e8eAI\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.19932", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19932", "abs": "https://arxiv.org/abs/2511.19932", "authors": ["Lidi Zhang", "Han Wu", "Liyu Zhang", "Ruofeng Liu", "Haotian Wang", "Chao Li", "Desheng Zhang", "Yunhuai Liu", "Tian He"], "title": "Collaborate sim and real: Robot Bin Packing Learning in Real-world and Physical Engine", "comment": null, "summary": "The 3D bin packing problem, with its diverse industrial applications, has garnered significant research attention in recent years. Existing approaches typically model it as a discrete and static process, while real-world applications involve continuous gravity-driven interactions. This idealized simplification leads to infeasible deployments (e.g., unstable packing) in practice. Simulations with physical engine offer an opportunity to emulate continuous gravity effects, enabling the training of reinforcement learning (RL) agents to address such limitations and improve packing stability. However, a simulation-to-reality gap persists due to dynamic variations in physical properties of real-world objects, such as various friction coefficients, elasticity, and non-uniform weight distributions. To bridge this gap, we propose a hybrid RL framework that collaborates with physical simulation with real-world data feedback. Firstly, domain randomization is applied during simulation to expose agents to a spectrum of physical parameters, enhancing their generalization capability. Secondly, the RL agent is fine-tuned with real-world deployment feedback, further reducing collapse rates. Extensive experiments demonstrate that our method achieves lower collapse rates in both simulated and real-world scenarios. Large-scale deployments in logistics systems validate the practical effectiveness, with a 35\\% reduction in packing collapse compared to baseline methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7269\u7406\u4eff\u771f\u4e0e\u771f\u5b9e\u4e16\u754c\u6570\u636e\u53cd\u9988\u534f\u4f5c\uff0c\u89e3\u51b33D\u88c5\u7bb1\u95ee\u9898\u4e2d\u7684\u4eff\u771f\u5230\u73b0\u5b9e\u5dee\u8ddd\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5305\u88c5\u574d\u584c\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c063D\u88c5\u7bb1\u95ee\u9898\u5efa\u6a21\u4e3a\u79bb\u6563\u9759\u6001\u8fc7\u7a0b\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u6d89\u53ca\u8fde\u7eed\u91cd\u529b\u9a71\u52a8\u4ea4\u4e92\uff0c\u8fd9\u79cd\u7406\u60f3\u5316\u7b80\u5316\u5bfc\u81f4\u5b9e\u9645\u90e8\u7f72\u4e0d\u53ef\u884c\uff08\u5982\u4e0d\u7a33\u5b9a\u5305\u88c5\uff09\u3002\u7269\u7406\u4eff\u771f\u867d\u80fd\u6a21\u62df\u91cd\u529b\u6548\u5e94\uff0c\u4f46\u7531\u4e8e\u771f\u5b9e\u7269\u4f53\u7269\u7406\u5c5e\u6027\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5b58\u5728\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\u3002", "method": "\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff1a1\uff09\u5728\u4eff\u771f\u4e2d\u5e94\u7528\u9886\u57df\u968f\u673a\u5316\uff0c\u8ba9\u667a\u80fd\u4f53\u63a5\u89e6\u5404\u79cd\u7269\u7406\u53c2\u6570\u4ee5\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\uff1b2\uff09\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u53cd\u9988\u5bf9RL\u667a\u80fd\u4f53\u8fdb\u884c\u5fae\u8c03\uff0c\u8fdb\u4e00\u6b65\u964d\u4f4e\u574d\u584c\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4eff\u771f\u548c\u771f\u5b9e\u573a\u666f\u4e2d\u5747\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u574d\u584c\u7387\u3002\u5728\u7269\u6d41\u7cfb\u7edf\u4e2d\u7684\u5927\u89c4\u6a21\u90e8\u7f72\u9a8c\u8bc1\u4e86\u5b9e\u9645\u6709\u6548\u6027\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5305\u88c5\u574d\u584c\u7387\u964d\u4f4e\u4e8635%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6df7\u5408RL\u6846\u67b6\u6709\u6548\u5f25\u5408\u4e86\u4eff\u771f\u4e0e\u73b0\u5b9e\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u663e\u8457\u63d0\u9ad8\u4e863D\u88c5\u7bb1\u7684\u7a33\u5b9a\u6027\uff0c\u5728\u5b9e\u9645\u7269\u6d41\u7cfb\u7edf\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.19865", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19865", "abs": "https://arxiv.org/abs/2511.19865", "authors": ["Mingkai Chen", "Zijie Feng", "Lei Wang", "Yaser Khamayseh"], "title": "Agentic AI-Empowered Conversational Embodied Intelligence Networks in 6G", "comment": "7 pages, 8 figures. Preprint submitted to IEEE Vehicle Technology Magazine", "summary": "In the 6G era, semantic collaboration among multiple embodied intelligent devices (MEIDs) becomes crucial for complex task execution. However, existing systems face challenges in multimodal information fusion, adaptive communication, and decision interpretability. To address these limitations, we propose a collaborative Conversational Embodied Intelligence Network (CC-EIN) integrating multimodal feature fusion, adaptive semantic communication, task coordination, and interpretability. PerceptiNet performs cross-modal fusion of image and radar data to generate unified semantic representations. An adaptive semantic communication strategy dynamically adjusts coding schemes and transmission power according to task urgency and channel quality. A semantic-driven collaboration mechanism further supports task decomposition and conflict-free coordination among heterogeneous devices. Finally, the InDec module enhances decision transparency through Grad-CAM visualization. Simulation results in post-earthquake rescue scenarios demonstrate that CC-EIN achieves 95.4% task completion rate and 95% transmission efficiency while maintaining strong semantic consistency and energy efficiency.", "AI": {"tldr": "\u63d0\u51faCC-EIN\u7f51\u7edc\u89e3\u51b36G\u65f6\u4ee3\u591a\u667a\u80fd\u4f53\u8bed\u4e49\u534f\u4f5c\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u878d\u5408\u3001\u81ea\u9002\u5e94\u8bed\u4e49\u901a\u4fe1\u548c\u53ef\u89e3\u91ca\u6027\u673a\u5236\uff0c\u5728\u707e\u540e\u6551\u63f4\u573a\u666f\u4e2d\u5b9e\u73b095.4%\u4efb\u52a1\u5b8c\u6210\u7387\u548c95%\u4f20\u8f93\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u5728\u591a\u6a21\u6001\u4fe1\u606f\u878d\u5408\u3001\u81ea\u9002\u5e94\u901a\u4fe1\u548c\u51b3\u7b56\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u96be\u4ee5\u6ee1\u8db36G\u65f6\u4ee3\u591a\u667a\u80fd\u4f53\u8bbe\u5907\u590d\u6742\u4efb\u52a1\u6267\u884c\u7684\u9700\u6c42\u3002", "method": "\u96c6\u6210\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408(PerceptiNet)\u3001\u81ea\u9002\u5e94\u8bed\u4e49\u901a\u4fe1\u3001\u4efb\u52a1\u534f\u8c03\u673a\u5236\u548c\u53ef\u89e3\u91ca\u6027\u6a21\u5757(InDec)\uff0c\u901a\u8fc7Grad-CAM\u53ef\u89c6\u5316\u589e\u5f3a\u51b3\u7b56\u900f\u660e\u5ea6\u3002", "result": "\u5728\u707e\u540e\u6551\u63f4\u573a\u666f\u4eff\u771f\u4e2d\uff0c\u8fbe\u523095.4%\u4efb\u52a1\u5b8c\u6210\u7387\u548c95%\u4f20\u8f93\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u80fd\u91cf\u6548\u7387\u3002", "conclusion": "CC-EIN\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u8bed\u4e49\u534f\u4f5c\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a6G\u65f6\u4ee3\u667a\u80fd\u8bbe\u5907\u534f\u4f5c\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20239", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20239", "abs": "https://arxiv.org/abs/2511.20239", "authors": ["Jan Krej\u010d\u00ed", "Oliver Kost", "Yuxuan Xia", "Lennart Svensson", "Ond\u0159ej Straka"], "title": "Occlusion-Aware Multi-Object Tracking via Expected Probability of Detection", "comment": "Submitted to IEEE Transactions on Aerospace and Electronic Systems (TAES)", "summary": "This paper addresses multi-object systems, where objects may occlude one another relative to the sensor. The standard point-object model for detection-based sensors is enhanced so that the probability of detection considers the presence of all objects. A principled tracking method is derived, assigning each object an expected probability of detection, where the expectation is taken over the reduced Palm density, which means conditionally on the object's existence. The assigned probability thus considers the object's visibility relative to the sensor, under the presence of other objects. Unlike existing methods, the proposed method systematically accounts for uncertainties related to all objects in a clear and manageable way. The method is demonstrated through a visual tracking application using the multi-Bernoulli mixture (MBM) filter with marks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u591a\u76ee\u6807\u8ddf\u8e2a\u65b9\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u76ee\u6807\u95f4\u76f8\u4e92\u906e\u6321\u5bf9\u68c0\u6d4b\u6982\u7387\u7684\u5f71\u54cd\uff0c\u4f7f\u7528\u57fa\u4e8e\u51cf\u5c11Palm\u5bc6\u5ea6\u7684\u671f\u671b\u68c0\u6d4b\u6982\u7387\u6765\u7cfb\u7edf\u6027\u5730\u5904\u7406\u6240\u6709\u76ee\u6807\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u5728\u591a\u76ee\u6807\u7cfb\u7edf\u4e2d\uff0c\u76ee\u6807\u4e4b\u95f4\u53ef\u80fd\u5b58\u5728\u76f8\u4e92\u906e\u6321\uff0c\u5f71\u54cd\u4f20\u611f\u5668\u7684\u68c0\u6d4b\u6982\u7387\u3002\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u7cfb\u7edf\u6027\u5730\u8003\u8651\u6240\u6709\u76ee\u6807\u5b58\u5728\u5e26\u6765\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u589e\u5f3a\u6807\u51c6\u70b9\u76ee\u6807\u6a21\u578b\uff0c\u4e3a\u6bcf\u4e2a\u76ee\u6807\u5206\u914d\u671f\u671b\u68c0\u6d4b\u6982\u7387\uff0c\u8be5\u671f\u671b\u57fa\u4e8e\u51cf\u5c11Palm\u5bc6\u5ea6\u8ba1\u7b97\uff08\u5373\u6761\u4ef6\u4e8e\u76ee\u6807\u5b58\u5728\uff09\u3002\u4f7f\u7528\u5e26\u6807\u8bb0\u7684\u591a\u4f2f\u52aa\u5229\u6df7\u5408(MBM)\u6ee4\u6ce2\u5668\u8fdb\u884c\u89c6\u89c9\u8ddf\u8e2a\u5e94\u7528\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6e05\u6670\u4e14\u53ef\u7ba1\u7406\u5730\u8003\u8651\u6240\u6709\u76ee\u6807\u76f8\u5173\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u7cfb\u7edf\u5730\u5904\u7406\u906e\u6321\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u8003\u8651\u76ee\u6807\u95f4\u906e\u6321\u6548\u5e94\uff0c\u4e3a\u591a\u76ee\u6807\u8ddf\u8e2a\u63d0\u4f9b\u4e86\u4e00\u79cd\u539f\u5219\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u4f20\u611f\u5668\u68c0\u6d4b\u6982\u7387\u7684\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2511.19955", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19955", "abs": "https://arxiv.org/abs/2511.19955", "authors": ["Jinxuan Zhu", "Zihao Yan", "Yangyu Xiao", "Jingxiang Guo", "Chenrui Tie", "Xinyi Cao", "Yuhang Zheng", "Lin Shao"], "title": "ShapeForce: Low-Cost Soft Robotic Wrist for Contact-Rich Manipulation", "comment": null, "summary": "Contact feedback is essential for contact-rich robotic manipulation, as it allows the robot to detect subtle interaction changes and adjust its actions accordingly. Six-axis force-torque sensors are commonly used to obtain contact feedback, but their high cost and fragility have discouraged many researchers from adopting them in contact-rich tasks. To offer a more cost-efficient and easy-accessible source of contact feedback, we present ShapeForce, a low-cost, plug-and-play soft wrist that provides force-like signals for contact-rich robotic manipulation. Inspired by how humans rely on relative force changes in contact rather than precise force magnitudes, ShapeForce converts external force and torque into measurable deformations of its compliant core, which are then estimated via marker-based pose tracking and converted into force-like signals. Our design eliminates the need for calibration or specialized electronics to obtain exact values, and instead focuses on capturing force and torque changes sufficient for enabling contact-rich manipulation. Extensive experiments across diverse contact-rich tasks and manipulation policies demonstrate that ShapeForce delivers performance comparable to six-axis force-torque sensors at an extremely low cost.", "AI": {"tldr": "ShapeForce\u662f\u4e00\u4e2a\u4f4e\u6210\u672c\u3001\u5373\u63d2\u5373\u7528\u7684\u8f6f\u8155\u88c5\u7f6e\uff0c\u901a\u8fc7\u5c06\u5916\u529b\u8f6c\u6362\u4e3a\u53ef\u6d4b\u91cf\u7684\u53d8\u5f62\u6765\u63d0\u4f9b\u7c7b\u4f3c\u529b\u7684\u4fe1\u53f7\uff0c\u7528\u4e8e\u63a5\u89e6\u4e30\u5bcc\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u3002", "motivation": "\u516d\u7ef4\u529b\u626d\u77e9\u4f20\u611f\u5668\u6210\u672c\u9ad8\u4e14\u6613\u788e\uff0c\u9650\u5236\u4e86\u5728\u63a5\u89e6\u4e30\u5bcc\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002\u9700\u8981\u4e00\u79cd\u6210\u672c\u6548\u76ca\u9ad8\u3001\u6613\u4e8e\u83b7\u53d6\u7684\u63a5\u89e6\u53cd\u9988\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u67d4\u6027\u6838\u5fc3\u5c06\u5916\u529b\u548c\u626d\u77e9\u8f6c\u6362\u4e3a\u53ef\u6d4b\u91cf\u7684\u53d8\u5f62\uff0c\u4f7f\u7528\u57fa\u4e8e\u6807\u8bb0\u7684\u59ff\u6001\u8ddf\u8e2a\u4f30\u8ba1\u53d8\u5f62\uff0c\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u7c7b\u4f3c\u529b\u7684\u4fe1\u53f7\u3002\u65e0\u9700\u6821\u51c6\u6216\u4e13\u7528\u7535\u5b50\u8bbe\u5907\u3002", "result": "\u5728\u591a\u79cd\u63a5\u89e6\u4e30\u5bcc\u4efb\u52a1\u548c\u64cd\u4f5c\u7b56\u7565\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cShapeForce\u4ee5\u6781\u4f4e\u6210\u672c\u5b9e\u73b0\u4e86\u4e0e\u516d\u7ef4\u529b\u626d\u77e9\u4f20\u611f\u5668\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "ShapeForce\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u7684\u63a5\u89e6\u53cd\u9988\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u66ff\u4ee3\u6602\u8d35\u7684\u516d\u7ef4\u529b\u626d\u77e9\u4f20\u611f\u5668\uff0c\u5728\u63a5\u89e6\u4e30\u5bcc\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.19872", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19872", "abs": "https://arxiv.org/abs/2511.19872", "authors": ["Daniel I Jackson", "Emma L Jensen", "Syed-Amad Hussain", "Emre Sezgin"], "title": "Simulated Self-Assessment in Large Language Models: A Psychometric Approach to AI Self-Efficacy", "comment": "25 pages,5 tables, 3 figures", "summary": "Self-assessment is a key aspect of reliable intelligence, yet evaluations of large language models (LLMs) focus mainly on task accuracy. We adapted the 10-item General Self-Efficacy Scale (GSES) to elicit simulated self-assessments from ten LLMs across four conditions: no task, computational reasoning, social reasoning, and summarization. GSES responses were highly stable across repeated administrations and randomized item orders. However, models showed significantly different self-efficacy levels across conditions, with aggregate scores lower than human norms. All models achieved perfect accuracy on computational and social questions, whereas summarization performance varied widely. Self-assessment did not reliably reflect ability: several low-scoring models performed accurately, while some high-scoring models produced weaker summaries. Follow-up confidence prompts yielded modest, mostly downward revisions, suggesting mild overestimation in first-pass assessments. Qualitative analysis showed that higher self-efficacy corresponded to more assertive, anthropomorphic reasoning styles, whereas lower scores reflected cautious, de-anthropomorphized explanations. Psychometric prompting provides structured insight into LLM communication behavior but not calibrated performance estimates.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u901a\u7528\u81ea\u6211\u6548\u80fd\u611f\u91cf\u8868(GSES)\u5e94\u7528\u4e8e10\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u5728\u4e0d\u540c\u4efb\u52a1\u6761\u4ef6\u4e0b\u6a21\u578b\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u81ea\u6211\u6548\u80fd\u611f\u6c34\u5e73\uff0c\u4f46\u81ea\u6211\u8bc4\u4f30\u5e76\u4e0d\u80fd\u53ef\u9760\u53cd\u6620\u5b9e\u9645\u80fd\u529b\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u8bc4\u4f30\u80fd\u529b\uff0c\u56e0\u4e3a\u81ea\u6211\u8bc4\u4f30\u662f\u53ef\u9760\u667a\u80fd\u7684\u5173\u952e\u65b9\u9762\uff0c\u800c\u73b0\u6709\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u4efb\u52a1\u51c6\u786e\u6027\u3002", "method": "\u5c0610\u9879\u901a\u7528\u81ea\u6211\u6548\u80fd\u611f\u91cf\u8868(GSES)\u5e94\u7528\u4e8e10\u4e2aLLM\uff0c\u5728\u56db\u79cd\u6761\u4ef6\u4e0b\u8fdb\u884c\u6d4b\u8bd5\uff1a\u65e0\u4efb\u52a1\u3001\u8ba1\u7b97\u63a8\u7406\u3001\u793e\u4f1a\u63a8\u7406\u548c\u6458\u8981\u4efb\u52a1\uff0c\u5206\u6790\u54cd\u5e94\u7a33\u5b9a\u6027\u3001\u81ea\u6211\u6548\u80fd\u611f\u6c34\u5e73\u548c\u5b9e\u9645\u8868\u73b0\u7684\u5173\u7cfb\u3002", "result": "\u6a21\u578b\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u663e\u8457\u4e0d\u540c\u7684\u81ea\u6211\u6548\u80fd\u611f\u6c34\u5e73\uff0c\u603b\u4f53\u5f97\u5206\u4f4e\u4e8e\u4eba\u7c7b\u6807\u51c6\u3002\u6240\u6709\u6a21\u578b\u5728\u8ba1\u7b97\u548c\u793e\u4f1a\u95ee\u9898\u4e0a\u90fd\u8fbe\u5230\u5b8c\u7f8e\u51c6\u786e\u7387\uff0c\u4f46\u6458\u8981\u8868\u73b0\u5dee\u5f02\u5f88\u5927\u3002\u81ea\u6211\u8bc4\u4f30\u4e0d\u80fd\u53ef\u9760\u53cd\u6620\u80fd\u529b\uff0c\u9ad8\u81ea\u6211\u6548\u80fd\u611f\u6a21\u578b\u53ef\u80fd\u8868\u73b0\u8f83\u5dee\uff0c\u4f4e\u81ea\u6211\u6548\u80fd\u611f\u6a21\u578b\u53cd\u800c\u8868\u73b0\u51c6\u786e\u3002", "conclusion": "\u5fc3\u7406\u6d4b\u91cf\u63d0\u793a\u4e3aLLM\u6c9f\u901a\u884c\u4e3a\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u6d1e\u5bdf\uff0c\u4f46\u4e0d\u80fd\u63d0\u4f9b\u6821\u51c6\u7684\u6027\u80fd\u4f30\u8ba1\u3002\u81ea\u6211\u6548\u80fd\u611f\u8f83\u9ad8\u7684\u6a21\u578b\u503e\u5411\u4e8e\u4f7f\u7528\u66f4\u81ea\u4fe1\u3001\u62df\u4eba\u5316\u7684\u63a8\u7406\u98ce\u683c\uff0c\u800c\u5f97\u5206\u8f83\u4f4e\u7684\u6a21\u578b\u5219\u53cd\u6620\u8c28\u614e\u3001\u53bb\u62df\u4eba\u5316\u7684\u89e3\u91ca\u3002"}}
{"id": "2511.20276", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20276", "abs": "https://arxiv.org/abs/2511.20276", "authors": ["Lianzhe Hu", "Yu Wang", "Bikash Pal"], "title": "LLM-Driven Transient Stability Assessment: From Automated Simulation to Neural Architecture Design", "comment": null, "summary": "This paper presents an LLM-driven, end-to-end workflow that addresses the lack of automation and intelligence in power system transient stability assessment (TSA). The proposed agentic framework integrates large language models (LLMs) with a professional simulator (ANDES) to automatically generate and filter disturbance scenarios from natural language, and employs an LLM-driven Neural Network Design (LLM-NND) pipeline to autonomously design and optimize TSA models through performance-guided, closed-loop feedback. On the IEEE 39-bus system, the LLM-NND models achieve 93.71% test accuracy on four-class TSA with only 4.78M parameters, while maintaining real-time inference latency (less than 0.95 ms per sample). Compared with a manually designed DenseNet (25.9M parameters, 80.05% accuracy), the proposed approach jointly improves accuracy and efficiency. Ablation studies confirm that the synergy among domain-grounded retrieval, reasoning augmentation, and feedback mechanisms is essential for robust automation. The results demonstrate that LLM agents can reliably accelerate TSA research from scenario generation and data acquisition to model design and interpretation, offering a scalable paradigm that is readily extensible to other power system tasks such as optimal power flow, fault analysis, and market operations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u7aef\u5230\u7aef\u5de5\u4f5c\u6d41\uff0c\u7528\u4e8e\u7535\u529b\u7cfb\u7edf\u6682\u6001\u7a33\u5b9a\u8bc4\u4f30\u7684\u81ea\u52a8\u5316\u548c\u667a\u80fd\u5316\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u7684\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u7ba1\u9053\u81ea\u52a8\u4f18\u5316TSA\u6a21\u578b\uff0c\u5728IEEE 39\u8282\u70b9\u7cfb\u7edf\u4e2d\u8fbe\u523093.71%\u7684\u6d4b\u8bd5\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3\u7535\u529b\u7cfb\u7edf\u6682\u6001\u7a33\u5b9a\u8bc4\u4f30\u4e2d\u81ea\u52a8\u5316\u548c\u667a\u80fd\u5316\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\uff0c\u6548\u7387\u4f4e\u4e0b\u4e14\u96be\u4ee5\u6269\u5c55\u3002", "method": "\u96c6\u6210\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u4e13\u4e1a\u6a21\u62df\u5668(ANDES)\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u81ea\u52a8\u751f\u6210\u548c\u7b5b\u9009\u6270\u52a8\u573a\u666f\uff0c\u91c7\u7528LLM\u9a71\u52a8\u7684\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u7ba1\u9053\u901a\u8fc7\u6027\u80fd\u5f15\u5bfc\u7684\u95ed\u73af\u53cd\u9988\u81ea\u4e3b\u8bbe\u8ba1\u548c\u4f18\u5316TSA\u6a21\u578b\u3002", "result": "\u5728IEEE 39\u8282\u70b9\u7cfb\u7edf\u4e2d\uff0cLLM-NND\u6a21\u578b\u5728\u56db\u7c7bTSA\u4efb\u52a1\u4e0a\u8fbe\u523093.71%\u7684\u6d4b\u8bd5\u7cbe\u5ea6\uff0c\u4ec5\u97004.78M\u53c2\u6570\uff0c\u5b9e\u65f6\u63a8\u7406\u5ef6\u8fdf\u5c0f\u4e8e0.95\u6beb\u79d2/\u6837\u672c\uff0c\u76f8\u6bd4\u624b\u52a8\u8bbe\u8ba1\u7684DenseNet(25.9M\u53c2\u6570\uff0c80.05%\u7cbe\u5ea6)\u540c\u65f6\u63d0\u9ad8\u4e86\u7cbe\u5ea6\u548c\u6548\u7387\u3002", "conclusion": "LLM\u4ee3\u7406\u80fd\u591f\u53ef\u9760\u5730\u52a0\u901fTSA\u7814\u7a76\u4ece\u573a\u666f\u751f\u6210\u3001\u6570\u636e\u91c7\u96c6\u5230\u6a21\u578b\u8bbe\u8ba1\u548c\u89e3\u91ca\u7684\u5168\u8fc7\u7a0b\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u8303\u5f0f\uff0c\u53ef\u8f7b\u677e\u6269\u5c55\u5230\u5176\u4ed6\u7535\u529b\u7cfb\u7edf\u4efb\u52a1\u3002"}}
{"id": "2511.20050", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20050", "abs": "https://arxiv.org/abs/2511.20050", "authors": ["Yan Li", "Yingzhao Li", "Gim Hee Lee"], "title": "Active3D: Active High-Fidelity 3D Reconstruction via Hierarchical Uncertainty Quantification", "comment": null, "summary": "In this paper, we present an active exploration framework for high-fidelity 3D reconstruction that incrementally builds a multi-level uncertainty space and selects next-best-views through an uncertainty-driven motion planner. We introduce a hybrid implicit-explicit representation that fuses neural fields with Gaussian primitives to jointly capture global structural priors and locally observed details. Based on this hybrid state, we derive a hierarchical uncertainty volume that quantifies both implicit global structure quality and explicit local surface confidence. To focus optimization on the most informative regions, we propose an uncertainty-driven keyframe selection strategy that anchors high-entropy viewpoints as sparse attention nodes, coupled with a viewpoint-space sliding window for uncertainty-aware local refinement. The planning module formulates next-best-view selection as an Expected Hybrid Information Gain problem and incorporates a risk-sensitive path planner to ensure efficient and safe exploration. Extensive experiments on challenging benchmarks demonstrate that our approach consistently achieves state-of-the-art accuracy, completeness, and rendering quality, highlighting its effectiveness for real-world active reconstruction and robotic perception tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u9ad8\u4fdd\u771f3D\u91cd\u5efa\u7684\u4e3b\u52a8\u63a2\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u591a\u7ea7\u4e0d\u786e\u5b9a\u6027\u7a7a\u95f4\u548c\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u7684\u8fd0\u52a8\u89c4\u5212\u6765\u9009\u62e9\u6700\u4f73\u89c6\u89d2\u3002", "motivation": "\u89e3\u51b33D\u91cd\u5efa\u4e2d\u5982\u4f55\u6709\u6548\u9009\u62e9\u4fe1\u606f\u91cf\u6700\u5927\u7684\u89c6\u89d2\u6765\u4f18\u5316\u91cd\u5efa\u8d28\u91cf\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u573a\u666f\u4e0b\u5b9e\u73b0\u9ad8\u6548\u548c\u5b89\u5168\u7684\u63a2\u7d22\u3002", "method": "\u91c7\u7528\u6df7\u5408\u9690\u5f0f-\u663e\u5f0f\u8868\u793a\u878d\u5408\u795e\u7ecf\u573a\u4e0e\u9ad8\u65af\u57fa\u5143\uff0c\u6784\u5efa\u5206\u5c42\u4e0d\u786e\u5b9a\u6027\u4f53\u79ef\uff0c\u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u7684\u5173\u952e\u5e27\u9009\u62e9\u7b56\u7565\u548c\u98ce\u9669\u654f\u611f\u7684\u8def\u5f84\u89c4\u5212\u5668\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u5b8c\u6574\u6027\u548c\u6e32\u67d3\u8d28\u91cf\u65b9\u9762\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u4e3b\u52a8\u91cd\u5efa\u548c\u673a\u5668\u4eba\u611f\u77e5\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2511.19895", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19895", "abs": "https://arxiv.org/abs/2511.19895", "authors": ["Yuanyuan Lin", "Xiangyu Ouyang", "Teng Zhang", "Kaixin Sui"], "title": "RPM-MCTS: Knowledge-Retrieval as Process Reward Model with Monte Carlo Tree Search for Code Generation", "comment": "Accepted at AAAI 2026", "summary": "Tree search-based methods have made significant progress in enhancing the code generation capabilities of large language models. However, due to the difficulty in effectively evaluating intermediate algorithmic steps and the inability to locate and timely correct erroneous steps, these methods often generate incorrect code and incur increased computational costs. To tackle these problems, we propose RPM-MCTS, an effective method that utilizes Knowledge-Retrieval as Process Reward Model based on Monte Carlo Tree Search to evaluate intermediate algorithmic steps. By utilizing knowledge base retrieval, RPM-MCTS avoids the complex training of process reward models. During the expansion phase, similarity filtering is employed to remove redundant nodes, ensuring diversity in reasoning paths. Furthermore, our method utilizes sandbox execution feedback to locate erroneous algorithmic steps during generation, enabling timely and targeted corrections. Extensive experiments on four public code generation benchmarks demonstrate that RPM-MCTS outperforms current state-of-the-art methods while achieving an approximately 15% reduction in token consumption. Furthermore, full fine-tuning of the base model using the data constructed by RPM-MCTS significantly enhances its code capabilities.", "AI": {"tldr": "RPM-MCTS\u662f\u4e00\u79cd\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u77e5\u8bc6\u68c0\u7d22\u4f5c\u4e3a\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u6765\u8bc4\u4f30\u4e2d\u95f4\u7b97\u6cd5\u6b65\u9aa4\uff0c\u65e0\u9700\u590d\u6742\u8bad\u7ec3\uff0c\u80fd\u51cf\u5c1115%\u7684token\u6d88\u8017\u5e76\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6811\u641c\u7d22\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u8bc4\u4f30\u4e2d\u95f4\u7b97\u6cd5\u6b65\u9aa4\uff0c\u65e0\u6cd5\u53ca\u65f6\u5b9a\u4f4d\u548c\u7ea0\u6b63\u9519\u8bef\u6b65\u9aa4\uff0c\u5bfc\u81f4\u751f\u6210\u9519\u8bef\u4ee3\u7801\u548c\u8ba1\u7b97\u6210\u672c\u589e\u52a0\u3002", "method": "\u4f7f\u7528\u77e5\u8bc6\u68c0\u7d22\u4f5c\u4e3a\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u5728\u6269\u5c55\u9636\u6bb5\u91c7\u7528\u76f8\u4f3c\u6027\u8fc7\u6ee4\u53bb\u9664\u5197\u4f59\u8282\u70b9\uff0c\u5229\u7528\u6c99\u7bb1\u6267\u884c\u53cd\u9988\u5b9a\u4f4d\u9519\u8bef\u6b65\u9aa4\u5e76\u8fdb\u884c\u9488\u5bf9\u6027\u4fee\u6b63\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\uff0ctoken\u6d88\u8017\u51cf\u5c11\u7ea615%\uff0c\u4f7f\u7528RPM-MCTS\u6784\u5efa\u7684\u6570\u636e\u8fdb\u884c\u5168\u5fae\u8c03\u53ef\u663e\u8457\u63d0\u5347\u57fa\u7840\u6a21\u578b\u7684\u4ee3\u7801\u80fd\u529b\u3002", "conclusion": "RPM-MCTS\u901a\u8fc7\u77e5\u8bc6\u68c0\u7d22\u548c\u6c99\u7bb1\u53cd\u9988\u6709\u6548\u89e3\u51b3\u4e86\u4e2d\u95f4\u6b65\u9aa4\u8bc4\u4f30\u548c\u9519\u8bef\u4fee\u6b63\u95ee\u9898\uff0c\u5728\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2511.20294", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20294", "abs": "https://arxiv.org/abs/2511.20294", "authors": ["Dnyandeep Mandaokar", "Bernhard Rinner"], "title": "SAFE-IMM: Robust and Lightweight Radar-Based Object Tracking on Mobile Platforms", "comment": null, "summary": "Tracking maneuvering targets requires estimators that are both responsive and robust. Interacting Multiple Model (IMM) filters are a standard tracking approach, but fusing models via Gaussian mixtures can lag during maneuvers. Recent winnertakes-all (WTA) approaches react quickly but may produce discontinuities. We propose SAFE-IMM, a lightweight IMM variant for tracking on mobile and resource-limited platforms with a safe covariance-aware gate that permits WTA only when the implied jump from the mixture to the winner is provably bounded. In simulations and on nuScenes front-radar data, SAFE-IMM achieves high accuracy at real-time rates, reducing ID switches while maintaining competitive performance. The method is simple to integrate, numerically stable, and clutter-robust, offering a practical balance between responsiveness and smoothness.", "AI": {"tldr": "SAFE-IMM\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7IMM\u6ee4\u6ce2\u5668\u53d8\u4f53\uff0c\u901a\u8fc7\u5b89\u5168\u534f\u65b9\u5dee\u611f\u77e5\u95e8\u63a7\u673a\u5236\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\u4e0a\u5b9e\u73b0\u5feb\u901f\u54cd\u5e94\u548c\u5e73\u7a33\u8ddf\u8e2a\u7684\u5e73\u8861\u3002", "motivation": "\u4f20\u7edfIMM\u6ee4\u6ce2\u5668\u5728\u878d\u5408\u6a21\u578b\u65f6\u5b58\u5728\u6ede\u540e\u95ee\u9898\uff0c\u800c\u8d62\u5bb6\u901a\u5403\u65b9\u6cd5\u867d\u7136\u54cd\u5e94\u5feb\u4f46\u4f1a\u4ea7\u751f\u4e0d\u8fde\u7eed\u6027\uff0c\u9700\u8981\u5728\u79fb\u52a8\u548c\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\u4e0a\u5b9e\u73b0\u54cd\u5e94\u6027\u548c\u9c81\u68d2\u6027\u7684\u5e73\u8861\u3002", "method": "\u63d0\u51faSAFE-IMM\u65b9\u6cd5\uff0c\u91c7\u7528\u5b89\u5168\u534f\u65b9\u5dee\u611f\u77e5\u95e8\u63a7\uff0c\u4ec5\u5728\u4ece\u6df7\u5408\u6a21\u578b\u5230\u83b7\u80dc\u6a21\u578b\u7684\u8df3\u8dc3\u88ab\u8bc1\u660e\u6709\u754c\u65f6\u624d\u5141\u8bb8\u8d62\u5bb6\u901a\u5403\u7b56\u7565\u3002", "result": "\u5728\u4eff\u771f\u548cnuScenes\u524d\u96f7\u8fbe\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSAFE-IMM\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u5b9e\u65f6\u8ddf\u8e2a\uff0c\u51cf\u5c11\u4e86ID\u5207\u6362\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u6027\u80fd\u3002", "conclusion": "SAFE-IMM\u65b9\u6cd5\u7b80\u5355\u6613\u96c6\u6210\u3001\u6570\u503c\u7a33\u5b9a\u3001\u5bf9\u6742\u6ce2\u9c81\u68d2\uff0c\u5728\u54cd\u5e94\u6027\u548c\u5e73\u6ed1\u6027\u4e4b\u95f4\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5e73\u8861\u3002"}}
{"id": "2511.20180", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20180", "abs": "https://arxiv.org/abs/2511.20180", "authors": ["Ryohei Kobayashi", "Kosei Isomoto", "Kosei Yamao", "Soma Fumoto", "Koshun Arimura", "Naoki Yamaguchi", "Akinobu Mizutani", "Tomoya Shiba", "Kouki Kimizuka", "Yuta Ohno", "Ryo Terashima", "Hiromasa Yamaguchi", "Tomoaki Fujino", "Ryoga Maruno", "Wataru Yoshimura", "Kazuhito Mine", "Tang Phu Thien Nhan", "Yuga Yano", "Yuichiro Tanaka", "Takeshi Nishida", "Takashi Morie", "Hakaru Tamukoh"], "title": "Hibikino-Musashi@Home 2025 Team Description Paper", "comment": null, "summary": "This paper provides an overview of the techniques employed by Hibikino-Musashi@Home, which intends to participate in the domestic standard platform league. The team developed a dataset generator for training a robot vision system and an open-source development environment running on a Human Support Robot simulator. The large-language-model-powered task planner selects appropriate primitive skills to perform the task requested by the user. Moreover, the team has focused on research involving brain-inspired memory models for adaptation to individual home environments. This approach aims to provide intuitive and personalized assistance. Additionally, the team contributed to the reusability of the navigation system developed by Pumas in RoboCup2024. The team aimed to design a home service robot to assist humans in their homes and continuously attend competitions to evaluate and improve the developed system.", "AI": {"tldr": "Hibikino-Musashi@Home\u56e2\u961f\u5f00\u53d1\u4e86\u673a\u5668\u4eba\u89c6\u89c9\u7cfb\u7edf\u8bad\u7ec3\u6570\u636e\u96c6\u751f\u6210\u5668\u3001\u5f00\u6e90\u5f00\u53d1\u73af\u5883\u3001LLM\u9a71\u52a8\u7684\u4efb\u52a1\u89c4\u5212\u5668\u3001\u8111\u542f\u53d1\u8bb0\u5fc6\u6a21\u578b\uff0c\u5e76\u6539\u8fdb\u4e86\u5bfc\u822a\u7cfb\u7edf\uff0c\u65e8\u5728\u8bbe\u8ba1\u80fd\u591f\u5728\u5bb6\u4e2d\u4e3a\u4eba\u7c7b\u63d0\u4f9b\u4e2a\u6027\u5316\u8f85\u52a9\u7684\u670d\u52a1\u673a\u5668\u4eba\u3002", "motivation": "\u8bbe\u8ba1\u80fd\u591f\u5728\u5bb6\u4e2d\u4e3a\u4eba\u7c7b\u63d0\u4f9b\u8f85\u52a9\u7684\u670d\u52a1\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u6301\u7eed\u53c2\u52a0\u6bd4\u8d5b\u6765\u8bc4\u4f30\u548c\u6539\u8fdb\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u6570\u636e\u96c6\u751f\u6210\u5668\u8bad\u7ec3\u673a\u5668\u4eba\u89c6\u89c9\u7cfb\u7edf\uff0c\u521b\u5efa\u5f00\u6e90\u5f00\u53d1\u73af\u5883\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4efb\u52a1\u89c4\u5212\uff0c\u7814\u7a76\u8111\u542f\u53d1\u8bb0\u5fc6\u6a21\u578b\u4ee5\u9002\u5e94\u4e2a\u6027\u5316\u5bb6\u5ead\u73af\u5883\uff0c\u6539\u8fdb\u5bfc\u822a\u7cfb\u7edf\u3002", "result": "\u6784\u5efa\u4e86\u5b8c\u6574\u7684\u5bb6\u5ead\u670d\u52a1\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u5305\u62ec\u89c6\u89c9\u3001\u89c4\u5212\u3001\u8bb0\u5fc6\u548c\u5bfc\u822a\u7b49\u6838\u5fc3\u6a21\u5757\uff0c\u4e3a\u4e2a\u6027\u5316\u5bb6\u5ead\u8f85\u52a9\u63d0\u4f9b\u4e86\u6280\u672f\u57fa\u7840\u3002", "conclusion": "\u8be5\u56e2\u961f\u901a\u8fc7\u591a\u6280\u672f\u878d\u5408\u7684\u65b9\u6cd5\u5f00\u53d1\u4e86\u5bb6\u5ead\u670d\u52a1\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u7ade\u8d5b\u6301\u7eed\u4f18\u5316\uff0c\u4e3a\u5b9e\u73b0\u76f4\u89c2\u548c\u4e2a\u6027\u5316\u7684\u5bb6\u5ead\u8f85\u52a9\u670d\u52a1\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.19925", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19925", "abs": "https://arxiv.org/abs/2511.19925", "authors": ["Qiyao Wei", "Edward Morrell", "Lea Goetz", "Mihaela van der Schaar"], "title": "Semantic-KG: Using Knowledge Graphs to Construct Benchmarks for Measuring Semantic Similarity", "comment": null, "summary": "Evaluating the open-form textual responses generated by Large Language Models (LLMs) typically requires measuring the semantic similarity of the response to a (human generated) reference. However, there is evidence that current semantic similarity methods may capture syntactic or lexical forms over semantic content. While benchmarks exist for semantic equivalence, they often suffer from high generation costs due to reliance on subjective human judgment, limited availability for domain-specific applications, and unclear definitions of equivalence. This paper introduces a novel method for generating benchmarks to evaluate semantic similarity methods for LLM outputs, specifically addressing these limitations. Our approach leverages knowledge graphs (KGs) to generate pairs of natural-language statements that are semantically similar or dissimilar, with dissimilar pairs categorized into one of four sub-types. We generate benchmark datasets in four different domains (general knowledge, biomedicine, finance, biology), and conduct a comparative study of semantic similarity methods including traditional natural language processing scores and LLM-as-a-judge predictions. We observe that the sub-type of semantic variation, as well as the domain of the benchmark impact the performance of semantic similarity methods, with no method being consistently superior. Our results present important implications for the use of LLM-as-a-judge in detecting the semantic content of text. Code is available at https://github.com/QiyaoWei/semantic-kg and the dataset is available at https://huggingface.co/datasets/QiyaoWei/Semantic-KG.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u57fa\u51c6\u6570\u636e\u96c6\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u8f93\u51fa\u8bed\u4e49\u76f8\u4f3c\u5ea6\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u6570\u636e\u96c6\u751f\u6210\u6210\u672c\u9ad8\u3001\u9886\u57df\u9002\u7528\u6027\u6709\u9650\u7b49\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u8bed\u4e49\u76f8\u4f3c\u5ea6\u65b9\u6cd5\u53ef\u80fd\u66f4\u5173\u6ce8\u53e5\u6cd5\u6216\u8bcd\u6c47\u5f62\u5f0f\u800c\u975e\u8bed\u4e49\u5185\u5bb9\uff0c\u73b0\u6709\u57fa\u51c6\u6570\u636e\u96c6\u5b58\u5728\u751f\u6210\u6210\u672c\u9ad8\u3001\u9886\u57df\u9002\u7528\u6027\u6709\u9650\u3001\u7b49\u4ef7\u5b9a\u4e49\u4e0d\u660e\u786e\u7b49\u5c40\u9650\u6027\u3002", "method": "\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u8bed\u4e49\u76f8\u4f3c\u6216\u4e0d\u76f8\u4f3c\u7684\u81ea\u7136\u8bed\u8a00\u9648\u8ff0\u5bf9\uff0c\u5176\u4e2d\u4e0d\u76f8\u4f3c\u5bf9\u5206\u4e3a\u56db\u79cd\u5b50\u7c7b\u578b\uff0c\u5728\u56db\u4e2a\u4e0d\u540c\u9886\u57df\u751f\u6210\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u6bd4\u8f83\u4f20\u7edfNLP\u8bc4\u5206\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u6027\u80fd\u3002", "result": "\u8bed\u4e49\u53d8\u5316\u7684\u5b50\u7c7b\u578b\u548c\u57fa\u51c6\u9886\u57df\u90fd\u4f1a\u5f71\u54cd\u8bed\u4e49\u76f8\u4f3c\u5ea6\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u6ca1\u6709\u4e00\u79cd\u65b9\u6cd5\u59cb\u7ec8\u8868\u73b0\u6700\u4f18\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9\u4f7f\u7528LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u68c0\u6d4b\u6587\u672c\u8bed\u4e49\u5185\u5bb9\u5177\u6709\u91cd\u8981\u542f\u793a\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002"}}
{"id": "2511.20383", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20383", "abs": "https://arxiv.org/abs/2511.20383", "authors": ["Viet-Anh Le", "Andreas A. Malikopoulos"], "title": "Accelerating Time-Optimal Trajectory Planning for Connected and Automated Vehicles with Graph Neural Networks", "comment": "submitted to IFAC WC 2026", "summary": "In this paper, we present a learning-based framework that accelerates time- and energy-optimal trajectory planning for connected and automated vehicles (CAVs) using graph neural networks (GNNs). We formulate the multi-agent coordination problem encountered in traffic scenarios as a cooperative trajectory planning problem that minimizes travel time, subject to motion primitives derived from energy-optimal solutions. The effectiveness of this framework can be further improved through replanning at each time step, enabling the system to incorporate newly observed information. To achieve real-time execution of such a multi-agent replanning scheme, we employ a GNN architecture to learn the solutions of the time-optimal trajectory planning problem from offline-generated data. The trained model produces online predictions that serve as warm-start solutions for numerical optimization, thereby enabling rapid computation of minimal exit times and the associated feasible trajectories. This learning-augmented approach substantially reduces computation time while ensuring that all state, input, and safety constraints are satisfied.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60\u6846\u67b6\uff0c\u52a0\u901f\u8054\u7f51\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u65f6\u95f4\u548c\u80fd\u91cf\u6700\u4f18\u8f68\u8ff9\u89c4\u5212\uff0c\u901a\u8fc7GNN\u5b66\u4e60\u79bb\u7ebf\u6570\u636e\u751f\u6210\u5728\u7ebf\u9884\u6d4b\u4f5c\u4e3a\u4f18\u5316\u70ed\u542f\u52a8\uff0c\u5b9e\u73b0\u5b9e\u65f6\u591a\u667a\u80fd\u4f53\u91cd\u89c4\u5212\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u534f\u8c03\u95ee\u9898\u4e2d\u7684\u5b9e\u65f6\u8f68\u8ff9\u89c4\u5212\u6311\u6218\uff0c\u9700\u8981\u5728\u6ee1\u8db3\u7ea6\u675f\u7684\u540c\u65f6\u6700\u5c0f\u5316\u65c5\u884c\u65f6\u95f4\uff0c\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u96be\u4ee5\u5b9e\u65f6\u6267\u884c\u3002", "method": "\u5c06\u591a\u667a\u80fd\u4f53\u534f\u8c03\u95ee\u9898\u5efa\u6a21\u4e3a\u5408\u4f5c\u8f68\u8ff9\u89c4\u5212\u95ee\u9898\uff0c\u4f7f\u7528GNN\u67b6\u6784\u4ece\u79bb\u7ebf\u6570\u636e\u5b66\u4e60\u65f6\u95f4\u6700\u4f18\u8f68\u8ff9\u89c4\u5212\u7684\u89e3\uff0c\u5728\u7ebf\u9884\u6d4b\u4f5c\u4e3a\u6570\u503c\u4f18\u5316\u7684\u70ed\u542f\u52a8\u89e3\u3002", "result": "\u5b66\u4e60\u589e\u5f3a\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\uff0c\u540c\u65f6\u786e\u4fdd\u6240\u6709\u72b6\u6001\u3001\u8f93\u5165\u548c\u5b89\u5168\u7ea6\u675f\u5f97\u5230\u6ee1\u8db3\uff0c\u5b9e\u73b0\u5b9e\u65f6\u591a\u667a\u80fd\u4f53\u91cd\u89c4\u5212\u3002", "conclusion": "\u57fa\u4e8eGNN\u7684\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u52a0\u901fCAV\u7684\u8f68\u8ff9\u89c4\u5212\uff0c\u901a\u8fc7\u79bb\u7ebf\u5b66\u4e60\u5728\u7ebf\u9884\u6d4b\u5b9e\u73b0\u5b9e\u65f6\u6027\u80fd\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u534f\u8c03\u63d0\u4f9b\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20226", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20226", "abs": "https://arxiv.org/abs/2511.20226", "authors": ["Yu Sun", "Yaosheng Deng", "Wenjie Mei", "Xiaogang Xiong", "Yang Bai", "Masaki Ogura", "Zeyu Zhou", "Mir Feroskhan", "Michael Yu Wang", "Qiyang Zuo", "Yao Li", "Yunjiang Lou"], "title": "Toward generic control for soft robotic systems", "comment": null, "summary": "Soft robotics has advanced rapidly, yet its control methods remain fragmented: different morphologies and actuation schemes still require task-specific controllers, hindering theoretical integration and large-scale deployment. A generic control framework is therefore essential, and a key obstacle lies in the persistent use of rigid-body control logic, which relies on precise models and strict low-level execution. Such a paradigm is effective for rigid robots but fails for soft robots, where the ability to tolerate and exploit approximate action representations, i.e., control compliance, is the basis of robustness and adaptability rather than a disturbance to be eliminated. Control should thus shift from suppressing compliance to explicitly exploiting it. Human motor control exemplifies this principle: instead of computing exact dynamics or issuing detailed muscle-level commands, it expresses intention through high-level movement tendencies, while reflexes and biomechanical mechanisms autonomously resolve local details. This architecture enables robustness, flexibility, and cross-task generalization. Motivated by this insight, we propose a generic soft-robot control framework grounded in control compliance and validate it across robots with diverse morphologies and actuation mechanisms. The results demonstrate stable, safe, and cross-platform transferable behavior, indicating that embracing control compliance, rather than resisting it, may provide a widely applicable foundation for unified soft-robot control.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63a7\u5236\u67d4\u987a\u6027\u7684\u901a\u7528\u8f6f\u4f53\u673a\u5668\u4eba\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u5c42\u8fd0\u52a8\u610f\u56fe\u8868\u8fbe\u548c\u5c40\u90e8\u81ea\u4e3b\u7ec6\u8282\u89e3\u51b3\uff0c\u5b9e\u73b0\u8de8\u5f62\u6001\u548c\u9a71\u52a8\u673a\u5236\u7684\u7a33\u5b9a\u3001\u5b89\u5168\u63a7\u5236\u3002", "motivation": "\u5f53\u524d\u8f6f\u4f53\u673a\u5668\u4eba\u63a7\u5236\u65b9\u6cd5\u5206\u6563\uff0c\u4e0d\u540c\u5f62\u6001\u548c\u9a71\u52a8\u65b9\u6848\u9700\u8981\u7279\u5b9a\u63a7\u5236\u5668\u3002\u4f20\u7edf\u521a\u4f53\u63a7\u5236\u903b\u8f91\u4f9d\u8d56\u7cbe\u786e\u6a21\u578b\u548c\u4e25\u683c\u6267\u884c\uff0c\u4e0d\u9002\u5408\u8f6f\u4f53\u673a\u5668\u4eba\u3002\u63a7\u5236\u67d4\u987a\u6027\uff08\u5bb9\u5fcd\u548c\u5229\u7528\u8fd1\u4f3c\u52a8\u4f5c\u8868\u793a\uff09\u5e94\u662f\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u7684\u57fa\u7840\uff0c\u800c\u975e\u9700\u8981\u6d88\u9664\u7684\u5e72\u6270\u3002", "method": "\u501f\u9274\u4eba\u7c7b\u8fd0\u52a8\u63a7\u5236\u539f\u7406\uff0c\u901a\u8fc7\u9ad8\u5c42\u8fd0\u52a8\u8d8b\u52bf\u8868\u8fbe\u610f\u56fe\uff0c\u53cd\u5c04\u548c\u751f\u7269\u529b\u5b66\u673a\u5236\u81ea\u4e3b\u89e3\u51b3\u5c40\u90e8\u7ec6\u8282\u3002\u63d0\u51fa\u57fa\u4e8e\u63a7\u5236\u67d4\u987a\u6027\u7684\u901a\u7528\u8f6f\u4f53\u673a\u5668\u4eba\u63a7\u5236\u6846\u67b6\u3002", "result": "\u5728\u591a\u79cd\u5f62\u6001\u548c\u9a71\u52a8\u673a\u5236\u7684\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u4e86\u7a33\u5b9a\u3001\u5b89\u5168\u4e14\u8de8\u5e73\u53f0\u53ef\u8f6c\u79fb\u7684\u884c\u4e3a\u3002", "conclusion": "\u62e5\u62b1\u800c\u975e\u62b5\u6297\u63a7\u5236\u67d4\u987a\u6027\uff0c\u53ef\u4e3a\u7edf\u4e00\u8f6f\u4f53\u673a\u5668\u4eba\u63a7\u5236\u63d0\u4f9b\u5e7f\u6cdb\u5e94\u7528\u57fa\u7840\u3002"}}
{"id": "2511.19933", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19933", "abs": "https://arxiv.org/abs/2511.19933", "authors": ["Vaishali Vinay"], "title": "A System-Level Taxonomy of Failure Modes in Large Language Model Applications", "comment": null, "summary": "Large language models (LLMs) are being rapidly integrated into decision-support tools, automation workflows, and AI-enabled software systems. However, their behavior in production environments remains poorly understood, and their failure patterns differ fundamentally from those of traditional machine learning models. This paper presents a system-level taxonomy of fifteen hidden failure modes that arise in real-world LLM applications, including multi-step reasoning drift, latent inconsistency, context-boundary degradation, incorrect tool invocation, version drift, and cost-driven performance collapse. Using this taxonomy, we analyze the growing gap in evaluation and monitoring practices: existing benchmarks measure knowledge or reasoning but provide little insight into stability, reproducibility, drift, or workflow integration. We further examine the production challenges associated with deploying LLMs - including observability limitations, cost constraints, and update-induced regressions - and outline high-level design principles for building reliable, maintainable, and cost-aware LLM systems. Finally, we outline high-level design principles for building reliable, maintainable, and cost-aware LLM-based systems. By framing LLM reliability as a system-engineering problem rather than a purely model-centric one, this work provides an analytical foundation for future research on evaluation methodology, AI system robustness, and dependable LLM deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u7ea7\u5206\u7c7b\u6cd5\uff0c\u8bc6\u522b\u4e8615\u79cd\u771f\u5b9e\u4e16\u754cLLM\u5e94\u7528\u4e2d\u7684\u9690\u85cf\u6545\u969c\u6a21\u5f0f\uff0c\u5206\u6790\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u6784\u5efa\u53ef\u9760LLM\u7cfb\u7edf\u7684\u8bbe\u8ba1\u539f\u5219\u3002", "motivation": "\u968f\u7740LLM\u88ab\u5feb\u901f\u96c6\u6210\u5230\u51b3\u7b56\u652f\u6301\u5de5\u5177\u548c\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u4e2d\uff0c\u5176\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u884c\u4e3a\u4ecd\u7136\u96be\u4ee5\u7406\u89e3\uff0c\u4e14\u6545\u969c\u6a21\u5f0f\u4e0e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6709\u672c\u8d28\u4e0d\u540c\u3002", "method": "\u63d0\u51fa\u7cfb\u7edf\u7ea7\u5206\u7c7b\u6cd5\u8bc6\u522b15\u79cd\u9690\u85cf\u6545\u969c\u6a21\u5f0f\uff0c\u5206\u6790\u8bc4\u4f30\u4e0e\u76d1\u63a7\u5b9e\u8df5\u7684\u5dee\u8ddd\uff0c\u5e76\u7814\u7a76\u90e8\u7f72\u6311\u6218\u3002", "result": "\u8bc6\u522b\u4e86\u591a\u6b65\u63a8\u7406\u6f02\u79fb\u3001\u6f5c\u5728\u4e0d\u4e00\u81f4\u6027\u3001\u4e0a\u4e0b\u6587\u8fb9\u754c\u9000\u5316\u3001\u9519\u8bef\u5de5\u5177\u8c03\u7528\u3001\u7248\u672c\u6f02\u79fb\u548c\u6210\u672c\u9a71\u52a8\u6027\u80fd\u5d29\u6e83\u7b49\u5173\u952e\u6545\u969c\u6a21\u5f0f\u3002", "conclusion": "\u901a\u8fc7\u5c06LLM\u53ef\u9760\u6027\u6846\u67b6\u5316\u4e3a\u7cfb\u7edf\u5de5\u7a0b\u95ee\u9898\u800c\u975e\u7eaf\u6a21\u578b\u4e2d\u5fc3\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u8bc4\u4f30\u65b9\u6cd5\u3001AI\u7cfb\u7edf\u9c81\u68d2\u6027\u548c\u53ef\u9760LLM\u90e8\u7f72\u7814\u7a76\u63d0\u4f9b\u4e86\u5206\u6790\u57fa\u7840\u3002"}}
{"id": "2511.20443", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20443", "abs": "https://arxiv.org/abs/2511.20443", "authors": ["Amy K. Strong", "Samuel Akinwande", "Leila Bridgeman"], "title": "Adaptive Meshing for CPA Lyapunov Function Synthesis", "comment": null, "summary": "Continuous piecewise affine (CPA) Lyapunov function synthesis is one method to perform Lyapunov stability analysis for nonlinear systems. This method first generates a mesh over the region of interest in the system's state space and then solves a linear program (LP), which enforces constraints on each vertex of the mesh, to synthesize a Lyapunov function. Finer meshes broaden the class of Lyapunov function candidates, but CPA function synthesis is more computationally expensive for finer meshes -- particularly so in higher dimensional systems. This paper explores methods to mesh the region of interest more efficiently so that a Lyapunov function can be synthesized using less computational effort. Three methods are explored -- adaptive meshing, meshing using knowledge of the system model, and a combination of the two. Numerical examples for two and three dimensional nonlinear dynamical systems are used to compare the efficacy of the three methods.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e09\u79cd\u66f4\u9ad8\u6548\u7684\u7f51\u683c\u5212\u5206\u65b9\u6cd5\uff08\u81ea\u9002\u5e94\u7f51\u683c\u3001\u57fa\u4e8e\u7cfb\u7edf\u6a21\u578b\u7684\u7f51\u683c\u4ee5\u53ca\u4e24\u8005\u7ed3\u5408\uff09\u6765\u964d\u4f4e\u8fde\u7eed\u5206\u6bb5\u4eff\u5c04Lyapunov\u51fd\u6570\u5408\u6210\u7684\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u8fde\u7eed\u5206\u6bb5\u4eff\u5c04Lyapunov\u51fd\u6570\u5408\u6210\u65b9\u6cd5\u5728\u66f4\u7cbe\u7ec6\u7684\u7f51\u683c\u4e0a\u8ba1\u7b97\u6210\u672c\u8f83\u9ad8\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u7cfb\u7edf\u4e2d\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u7f51\u683c\u5212\u5206\u65b9\u6cd5\u6765\u51cf\u5c11\u8ba1\u7b97\u8d1f\u62c5\u3002", "method": "\u63a2\u7d22\u4e86\u4e09\u79cd\u7f51\u683c\u5212\u5206\u65b9\u6cd5\uff1a\u81ea\u9002\u5e94\u7f51\u683c\u5212\u5206\u3001\u57fa\u4e8e\u7cfb\u7edf\u6a21\u578b\u77e5\u8bc6\u7684\u7f51\u683c\u5212\u5206\u4ee5\u53ca\u4e24\u8005\u7684\u7ec4\u5408\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u4e8c\u7ef4\u548c\u4e09\u7ef4\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u7684\u6570\u503c\u7b97\u4f8b\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u901a\u8fc7\u6570\u503c\u7b97\u4f8b\u9a8c\u8bc1\u4e86\u4e09\u79cd\u65b9\u6cd5\u5728\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e09\u79cd\u7f51\u683c\u5212\u5206\u65b9\u6cd5\u80fd\u591f\u66f4\u9ad8\u6548\u5730\u5408\u6210Lyapunov\u51fd\u6570\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u975e\u7ebf\u6027\u7cfb\u7edf\u5206\u6790\u4e2d\u5177\u6709\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.20275", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20275", "abs": "https://arxiv.org/abs/2511.20275", "authors": ["Chenhui Dong", "Haozhe Xu", "Wenhao Feng", "Zhipeng Wang", "Yanmin Zhou", "Yifei Zhao", "Bin He"], "title": "HAFO: Humanoid Force-Adaptive Control for Intense External Force Interaction Environments", "comment": null, "summary": "Reinforcement learning controllers have made impressive progress in humanoid locomotion and light load manipulation. However, achieving robust and precise motion with strong force interaction remains a significant challenge. Based on the above limitations, this paper proposes HAFO, a dual-agent reinforcement learning control framework that simultaneously optimizes both a robust locomotion strategy and a precise upper-body manipulation strategy through coupled training under external force interaction environments. Simultaneously, we explicitly model the external pulling disturbances through a spring-damper system and achieve fine-grained force control by manipulating the virtual spring. During this process, the reinforcement-learning policy spontaneously generates disturbance-rejection response by exploiting environmental feedback. Moreover, HAFO employs an asymmetric Actor-Critic framework in which the Critic-network access to privileged spring-damping forces guides the actor-network to learn a generalizable, robust policy for resisting external disturbances. The experimental results demonstrate that HAFO achieves stable control of humanoid robot under various strong force interactions, showing remarkable performance in load tasks and ensuring stable robot operation under rope tension disturbances. Project website: hafo-robot.github.io.", "AI": {"tldr": "\u63d0\u51faHAFO\u53cc\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u8026\u5408\u8bad\u7ec3\u540c\u65f6\u4f18\u5316\u7a33\u5065\u7684\u6b65\u6001\u7b56\u7565\u548c\u7cbe\u786e\u7684\u4e0a\u534a\u8eab\u64cd\u4f5c\u7b56\u7565\uff0c\u5728\u5f3a\u5916\u529b\u4ea4\u4e92\u73af\u5883\u4e0b\u5b9e\u73b0\u4eba\u5f62\u673a\u5668\u4eba\u7684\u7a33\u5b9a\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\u5728\u4eff\u4eba\u673a\u5668\u4eba\u6b65\u6001\u548c\u8f7b\u8d1f\u8f7d\u64cd\u4f5c\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5728\u5f3a\u5916\u529b\u4ea4\u4e92\u4e0b\u5b9e\u73b0\u7a33\u5065\u7cbe\u786e\u8fd0\u52a8\u4ecd\u9762\u4e34\u6311\u6218\u3002", "method": "\u91c7\u7528\u53cc\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5f39\u7c27-\u963b\u5c3c\u7cfb\u7edf\u663e\u5f0f\u5efa\u6a21\u5916\u90e8\u62c9\u529b\u6270\u52a8\uff0c\u5229\u7528\u975e\u5bf9\u79f0Actor-Critic\u6846\u67b6\uff0c\u5176\u4e2dCritic\u7f51\u7edc\u8bbf\u95ee\u7279\u6743\u5f39\u7c27\u963b\u5c3c\u529b\u4fe1\u606f\u6307\u5bfcActor\u7f51\u7edc\u5b66\u4e60\u53ef\u6cdb\u5316\u7684\u7a33\u5065\u7b56\u7565\u3002", "result": "HAFO\u5728\u5404\u79cd\u5f3a\u5916\u529b\u4ea4\u4e92\u4e0b\u5b9e\u73b0\u4e86\u4eba\u5f62\u673a\u5668\u4eba\u7684\u7a33\u5b9a\u63a7\u5236\uff0c\u5728\u8d1f\u8f7d\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5728\u7ef3\u7d22\u5f20\u529b\u6270\u52a8\u4e0b\u786e\u4fdd\u673a\u5668\u4eba\u7a33\u5b9a\u8fd0\u884c\u3002", "conclusion": "HAFO\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u5f3a\u5916\u529b\u4ea4\u4e92\uff0c\u4e3a\u4eff\u4eba\u673a\u5668\u4eba\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u7a33\u5065\u64cd\u4f5c\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19969", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19969", "abs": "https://arxiv.org/abs/2511.19969", "authors": ["Weizi Shao", "Taolin Zhang", "Zijie Zhou", "Chen Chen", "Chengyu Wang", "Xiaofeng He"], "title": "M$^3$Prune: Hierarchical Communication Graph Pruning for Efficient Multi-Modal Multi-Agent Retrieval-Augmented Generation", "comment": null, "summary": "Recent advancements in multi-modal retrieval-augmented generation (mRAG), which enhance multi-modal large language models (MLLMs) with external knowledge, have demonstrated that the collective intelligence of multiple agents can significantly outperform a single model through effective communication. Despite impressive performance, existing multi-agent systems inherently incur substantial token overhead and increased computational costs, posing challenges for large-scale deployment. To address these issues, we propose a novel Multi-Modal Multi-agent hierarchical communication graph PRUNING framework, termed M$^3$Prune. Our framework eliminates redundant edges across different modalities, achieving an optimal balance between task performance and token overhead. Specifically, M$^3$Prune first applies intra-modal graph sparsification to textual and visual modalities, identifying the edges most critical for solving the task. Subsequently, we construct a dynamic communication topology using these key edges for inter-modal graph sparsification. Finally, we progressively prune redundant edges to obtain a more efficient and hierarchical topology. Extensive experiments on both general and domain-specific mRAG benchmarks demonstrate that our method consistently outperforms both single-agent and robust multi-agent mRAG systems while significantly reducing token consumption.", "AI": {"tldr": "\u63d0\u51fa\u4e86M\u00b3Prune\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u56fe\u526a\u679d\u6d88\u9664\u5197\u4f59\u8fb9\uff0c\u5728\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6027\u80fd\u4e0etoken\u5f00\u9500\u7684\u6700\u4f73\u5e73\u8861\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b58\u5728\u663e\u8457\u7684token\u5f00\u9500\u548c\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5927\u89c4\u6a21\u90e8\u7f72\u3002", "method": "\u9996\u5148\u8fdb\u884c\u6a21\u6001\u5185\u56fe\u7a00\u758f\u5316\u8bc6\u522b\u5173\u952e\u8fb9\uff0c\u7136\u540e\u6784\u5efa\u52a8\u6001\u901a\u4fe1\u62d3\u6251\u8fdb\u884c\u6a21\u6001\u95f4\u56fe\u7a00\u758f\u5316\uff0c\u6700\u540e\u6e10\u8fdb\u526a\u679d\u5197\u4f59\u8fb9\u83b7\u5f97\u9ad8\u6548\u5206\u5c42\u62d3\u6251\u3002", "result": "\u5728\u901a\u7528\u548c\u9886\u57df\u7279\u5b9amRAG\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u548c\u9c81\u68d2\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11token\u6d88\u8017\u3002", "conclusion": "M\u00b3Prune\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6548\u7387\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2511.20463", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20463", "abs": "https://arxiv.org/abs/2511.20463", "authors": ["Amy K. Strong", "Ali Kashani", "Claus Danielson", "Leila Bridgeman"], "title": "Learning Control Barrier Functions with Deterministic Safety Guarantees", "comment": null, "summary": "Barrier functions (BFs) characterize safe sets of dynamical systems, where hard constraints are never violated as the system evolves over time. Computing a valid safe set and BF for a nonlinear (and potentially unmodeled), non-autonomous dynamical system is a difficult task. This work explores the design of BFs using data to obtain safe sets with deterministic assurances of control invariance. We leverage ReLU neural networks (NNs) to create continuous piecewise affine (CPA) BFs with deterministic safety guarantees for Lipschitz continuous, discrete-time dynamical system using sampled one-step trajectories. The CPA structure admits a novel classifier term to create a relaxed \\ac{bf} condition and construction via a data driven constrained optimization. We use iterative convex overbounding (ICO) to solve this nonconvex optimization problem through a series of convex optimization steps. We then demonstrate our method's efficacy on two-dimensional autonomous and non-autonomous dynamical systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528ReLU\u795e\u7ecf\u7f51\u7edc\u6784\u5efa\u8fde\u7eed\u5206\u6bb5\u4eff\u5c04\u5c4f\u969c\u51fd\u6570\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u4f18\u5316\u4e3a\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u63d0\u4f9b\u786e\u5b9a\u6027\u5b89\u5168\u4fdd\u969c\u3002", "motivation": "\u4e3a\u975e\u7ebf\u6027\u3001\u975e\u81ea\u6cbb\u52a8\u529b\u7cfb\u7edf\u8ba1\u7b97\u6709\u6548\u7684\u5b89\u5168\u96c6\u548c\u5c4f\u969c\u51fd\u6570\u662f\u4e00\u4e2a\u56f0\u96be\u4efb\u52a1\uff0c\u9700\u8981\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u6765\u83b7\u5f97\u5177\u6709\u786e\u5b9a\u6027\u4fdd\u8bc1\u7684\u63a7\u5236\u4e0d\u53d8\u6027\u3002", "method": "\u5229\u7528ReLU\u795e\u7ecf\u7f51\u7edc\u521b\u5efa\u8fde\u7eed\u5206\u6bb5\u4eff\u5c04\u5c4f\u969c\u51fd\u6570\uff0c\u901a\u8fc7\u91c7\u6837\u7684\u4e00\u6b65\u8f68\u8ff9\u6570\u636e\uff0c\u91c7\u7528\u8fed\u4ee3\u51f8\u4e0a\u754c\u65b9\u6cd5\u89e3\u51b3\u975e\u51f8\u4f18\u5316\u95ee\u9898\u3002", "result": "\u5728\u4e8c\u7ef4\u81ea\u6cbb\u548c\u975e\u81ea\u6cbb\u52a8\u529b\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u83b7\u5f97\u5177\u6709\u786e\u5b9a\u6027\u5b89\u5168\u4fdd\u8bc1\u7684\u5b89\u5168\u96c6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u4e3a\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u6784\u5efa\u4e86\u6570\u636e\u9a71\u52a8\u7684\u5c4f\u969c\u51fd\u6570\uff0c\u63d0\u4f9b\u4e86\u786e\u5b9a\u6027\u7684\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2511.20292", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20292", "abs": "https://arxiv.org/abs/2511.20292", "authors": ["Dong Wang", "Daniel Casado Herraez", "Stefan May", "Andreas N\u00fcchter"], "title": "Dynamic-ICP: Doppler-Aware Iterative Closest Point Registration for Dynamic Scenes", "comment": "8 pages, 5 figures", "summary": "Reliable odometry in highly dynamic environments remains challenging when it relies on ICP-based registration: ICP assumes near-static scenes and degrades in repetitive or low-texture geometry. We introduce Dynamic-ICP, a Doppler-aware registration framework. The method (i) estimates ego motion from per-point Doppler velocity via robust regression and builds a velocity filter, (ii) clusters dynamic objects and reconstructs object-wise translational velocities from ego-compensated radial measurements, (iii) predicts dynamic points with a constant-velocity model, and (iv) aligns scans using a compact objective that combines point-to-plane geometry residual with a translation-invariant, rotation-only Doppler residual. The approach requires no external sensors or sensor-vehicle calibration and operates directly on FMCW LiDAR range and Doppler velocities. We evaluate Dynamic-ICP on three datasets-HeRCULES, HeLiPR, AevaScenes-focusing on highly dynamic scenes. Dynamic-ICP consistently improves rotational stability and translation accuracy over the state-of-the-art methods. Our approach is also simple to integrate into existing pipelines, runs in real time, and provides a lightweight solution for robust registration in dynamic environments. To encourage further research, the code is available at: https://github.com/JMUWRobotics/Dynamic-ICP.", "AI": {"tldr": "Dynamic-ICP\u662f\u4e00\u79cd\u57fa\u4e8e\u591a\u666e\u52d2\u7684LiDAR\u91cc\u7a0b\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u51e0\u4f55\u6b8b\u5dee\u548c\u591a\u666e\u52d2\u6b8b\u5dee\uff0c\u5728\u9ad8\u5ea6\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u7a33\u5065\u7684\u4f4d\u59ff\u4f30\u8ba1\uff0c\u65e0\u9700\u5916\u90e8\u4f20\u611f\u5668\u6216\u6807\u5b9a\u3002", "motivation": "\u5728\u9ad8\u5ea6\u52a8\u6001\u73af\u5883\u4e2d\uff0c\u4f20\u7edf\u7684ICP\u65b9\u6cd5\u5047\u8bbe\u573a\u666f\u8fd1\u4f3c\u9759\u6001\uff0c\u5728\u91cd\u590d\u6216\u4f4e\u7eb9\u7406\u51e0\u4f55\u4e2d\u6027\u80fd\u4e0b\u964d\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u52a8\u6001\u7269\u4f53\u7684\u53ef\u9760\u91cc\u7a0b\u8ba1\u65b9\u6cd5\u3002", "method": "1) \u901a\u8fc7\u7a33\u5065\u56de\u5f52\u4ece\u591a\u666e\u52d2\u901f\u5ea6\u4f30\u8ba1\u81ea\u6211\u8fd0\u52a8\u5e76\u6784\u5efa\u901f\u5ea6\u6ee4\u6ce2\u5668\uff1b2) \u805a\u7c7b\u52a8\u6001\u7269\u4f53\u5e76\u91cd\u5efa\u7269\u4f53\u5e73\u79fb\u901f\u5ea6\uff1b3) \u4f7f\u7528\u6052\u5b9a\u901f\u5ea6\u6a21\u578b\u9884\u6d4b\u52a8\u6001\u70b9\uff1b4) \u7ed3\u5408\u70b9\u5bf9\u9762\u51e0\u4f55\u6b8b\u5dee\u548c\u65cb\u8f6c\u4e0d\u53d8\u7684\u591a\u666e\u52d2\u6b8b\u5dee\u8fdb\u884c\u626b\u63cf\u5bf9\u9f50\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cDynamic-ICP\u5728\u65cb\u8f6c\u7a33\u5b9a\u6027\u548c\u5e73\u79fb\u7cbe\u5ea6\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u80fd\u591f\u5b9e\u65f6\u8fd0\u884c\u3002", "conclusion": "Dynamic-ICP\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u76f4\u63a5\u96c6\u6210\u5230\u73b0\u6709\u6d41\u7a0b\u4e2d\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u7a33\u5065\u7684\u914d\u51c6\u3002"}}
{"id": "2511.20048", "categories": ["cs.AI", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.20048", "abs": "https://arxiv.org/abs/2511.20048", "authors": ["Zixiao Huang", "Wen Zeng", "Tianyu Fu", "Tengxuan Liu", "Yizhou Sun", "Ke Hong", "Xinhao Yang", "Chengchun Liu", "Yan Li", "Quanlu Zhang", "Guohao Dai", "Zhenhua Zhu", "Yu Wang"], "title": "Reducing Latency of LLM Search Agent via Speculation-based Algorithm-System Co-Design", "comment": null, "summary": "LLM-based search agents achieve strong performance but suffer from severe latency, as each step requires serialized LLM reasoning followed by action of tool execution. We revisit this bottleneck through the lens of speculation. While traditional predict-verify speculation paradigm can break serial execution, its benefit remains limited, as it retains the full original workload and adds extra inference overhead. We observe that early agent steps often involve simple evidence-gathering, where correct actions can often be predicted without full reasoning. Building on these observations, we present SPAgent, an algorithm-system co-design framework that expands the role of speculation in search agents to reduce latency. Algorithmically, SPAgent introduces a two-phase adaptive speculation mechanism that selectively omits verification when safe. System-wise, a two-level scheduler regulates speculative requests based on engine load to ensure speculation remains beneficial. We implement SPAgent in real-world systems. Across extensive experimental settings, SPAgent achieves up to $1.65\\times$ end-to-end speedup while maintaining same or even achieving higher accuracy, enabling practical deployment of multi-step search agents.", "AI": {"tldr": "SPAgent\u901a\u8fc7\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u4f7f\u7528\u4e24\u9636\u6bb5\u81ea\u9002\u5e94\u63a8\u6d4b\u673a\u5236\u548c\u4e24\u7ea7\u8c03\u5ea6\u5668\uff0c\u663e\u8457\u964d\u4f4e\u57fa\u4e8eLLM\u7684\u641c\u7d22\u4ee3\u7406\u7684\u5ef6\u8fdf\uff0c\u5b9e\u73b0\u6700\u9ad81.65\u500d\u7684\u7aef\u5230\u7aef\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u57fa\u4e8eLLM\u7684\u641c\u7d22\u4ee3\u7406\u6027\u80fd\u5f3a\u5927\u4f46\u5ef6\u8fdf\u4e25\u91cd\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u6b65\u9aa4\u90fd\u9700\u8981\u4e32\u884c\u5316\u7684LLM\u63a8\u7406\u548c\u5de5\u5177\u6267\u884c\u3002\u4f20\u7edf\u63a8\u6d4b\u8303\u5f0f\u867d\u7136\u80fd\u6253\u7834\u4e32\u884c\u6267\u884c\uff0c\u4f46\u6548\u76ca\u6709\u9650\uff0c\u56e0\u4e3a\u4fdd\u7559\u4e86\u5b8c\u6574\u539f\u59cb\u5de5\u4f5c\u8d1f\u8f7d\u5e76\u589e\u52a0\u4e86\u989d\u5916\u63a8\u7406\u5f00\u9500\u3002", "method": "SPAgent\u91c7\u7528\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\uff1a\u7b97\u6cd5\u5c42\u9762\u5f15\u5165\u4e24\u9636\u6bb5\u81ea\u9002\u5e94\u63a8\u6d4b\u673a\u5236\uff0c\u5728\u5b89\u5168\u65f6\u9009\u62e9\u6027\u7701\u7565\u9a8c\u8bc1\uff1b\u7cfb\u7edf\u5c42\u9762\u4f7f\u7528\u4e24\u7ea7\u8c03\u5ea6\u5668\u6839\u636e\u5f15\u64ce\u8d1f\u8f7d\u8c03\u8282\u63a8\u6d4b\u8bf7\u6c42\uff0c\u786e\u4fdd\u63a8\u6d4b\u59cb\u7ec8\u6709\u76ca\u3002", "result": "\u5728\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bbe\u7f6e\u4e2d\uff0cSPAgent\u5b9e\u73b0\u4e86\u6700\u9ad81.65\u500d\u7684\u7aef\u5230\u7aef\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u751a\u81f3\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u4f7f\u591a\u6b65\u641c\u7d22\u4ee3\u7406\u7684\u5b9e\u9645\u90e8\u7f72\u6210\u4e3a\u53ef\u80fd\u3002", "conclusion": "SPAgent\u901a\u8fc7\u6269\u5c55\u63a8\u6d4b\u5728\u641c\u7d22\u4ee3\u7406\u4e2d\u7684\u4f5c\u7528\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u641c\u7d22\u4ee3\u7406\u7684\u5ef6\u8fdf\u74f6\u9888\uff0c\u4e3a\u591a\u6b65\u641c\u7d22\u4ee3\u7406\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.20508", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20508", "abs": "https://arxiv.org/abs/2511.20508", "authors": ["Elise Zhang", "Fran\u00e7ois Mirall\u00e8s", "St\u00e9phane Dellacherie", "Di Wu", "Benoit Boulet"], "title": "Causal Feature Selection for Weather-Driven Residential Load Forecasting", "comment": "5 pages, 3 figures, 3 tables", "summary": "Weather is a dominant external driver of residential electricity demand, but adding many meteorological covariates can inflate model complexity and may even impair accuracy. Selecting appropriate exogenous features is non-trivial and calls for a principled selection framework, given the direct operational implications for day-to-day planning and reliability. This work investigates whether causal feature selection can retain the most informative weather drivers while improving parsimony and robustness for short-term load forecasting. We present a case study on Southern Ontario with two open-source datasets: (i) IESO hourly electricity consumption by Forward Sortation Areas; (ii) ERA5 weather reanalysis data. We compare different feature selection regimes (no feature selection, non-causal selection, PCMCI-causal selection) on city-level forecasting with three different time series forecasting models: GRU, TCN, PatchTST. In the feature analysis, non-causal selection prioritizes radiation and moisture variables that show correlational dependence, whereas PCMCI-causal selection emphasizes more direct thermal drivers and prunes the indirect covariates. We detail the evaluation pipeline and report diagnostics on prediction accuracy and extreme-weather robustness, positioning causal feature selection as a practical complement to modern forecasters when integrating weather into residential load forecasting.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u56e0\u679c\u7279\u5f81\u9009\u62e9\u5728\u77ed\u671f\u8d1f\u8377\u9884\u6d4b\u4e2d\u5982\u4f55\u63d0\u9ad8\u5929\u6c14\u53d8\u91cf\u7684\u7b80\u7ea6\u6027\u548c\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u5728\u4e09\u4e2a\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u5929\u6c14\u662f\u4f4f\u5b85\u7535\u529b\u9700\u6c42\u7684\u4e3b\u8981\u5916\u90e8\u9a71\u52a8\u56e0\u7d20\uff0c\u4f46\u6dfb\u52a0\u8fc7\u591a\u6c14\u8c61\u534f\u53d8\u91cf\u4f1a\u589e\u52a0\u6a21\u578b\u590d\u6742\u6027\u5e76\u53ef\u80fd\u964d\u4f4e\u51c6\u786e\u6027\u3002\u9700\u8981\u4e00\u79cd\u539f\u5219\u6027\u7684\u7279\u5f81\u9009\u62e9\u6846\u67b6\u6765\u4f18\u5316\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u5b89\u5927\u7565\u7701\u5357\u90e8\u7684\u4e24\u4e2a\u5f00\u6e90\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u4e86\u65e0\u7279\u5f81\u9009\u62e9\u3001\u975e\u56e0\u679c\u9009\u62e9\u548cPCMCI\u56e0\u679c\u9009\u62e9\u4e09\u79cd\u65b9\u6cd5\uff0c\u5728GRU\u3001TCN\u548cPatchTST\u4e09\u4e2a\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u4e0a\u8fdb\u884c\u57ce\u5e02\u7ea7\u9884\u6d4b\u3002", "result": "\u975e\u56e0\u679c\u9009\u62e9\u4f18\u5148\u8003\u8651\u8f90\u5c04\u548c\u6e7f\u5ea6\u53d8\u91cf\uff0c\u800c\u56e0\u679c\u9009\u62e9\u5f3a\u8c03\u66f4\u76f4\u63a5\u7684\u70ed\u9a71\u52a8\u56e0\u7d20\u5e76\u4fee\u526a\u95f4\u63a5\u534f\u53d8\u91cf\u3002\u56e0\u679c\u7279\u5f81\u9009\u62e9\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u6781\u7aef\u5929\u6c14\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u56e0\u679c\u7279\u5f81\u9009\u62e9\u53ef\u4ee5\u4f5c\u4e3a\u73b0\u4ee3\u9884\u6d4b\u5668\u7684\u5b9e\u7528\u8865\u5145\uff0c\u5728\u5c06\u5929\u6c14\u56e0\u7d20\u6574\u5408\u5230\u4f4f\u5b85\u8d1f\u8377\u9884\u6d4b\u65f6\u63d0\u9ad8\u6a21\u578b\u7684\u7b80\u7ea6\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.20299", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.20299", "abs": "https://arxiv.org/abs/2511.20299", "authors": ["R\u00f3is\u00edn Keenan", "Joost C. Dessing"], "title": "How Robot Kinematics Influence Human Performance in Virtual Robot-to-Human Handover Tasks", "comment": null, "summary": "Recent advancements in robotics have increased the possibilities for integrating robotic systems into human-involved workplaces, highlighting the need to examine and optimize human-robot coordination in collaborative settings. This study explores human-robot interactions during handover tasks using Virtual Reality (VR) to investigate differences in human motor performance across various task dynamics and robot kinematics. A VR-based robot handover simulation afforded safe and controlled assessments of human-robot interactions. In separate experiments, four potential influences on human performance were examined (1) control over task initiation and robot movement synchrony (temporal and spatiotemporal); (2) partner appearance (human versus robotic); (3) robot velocity profiles (minimum jerk, constant velocity, constant acceleration, and biphasic); and (4) the timing of rotational object motion. Findings across experiments emphasize humans benefit from robots providing early and salient visual information about task-relevant object motion, and advantages of human-like smooth robot trajectories. To varying degrees, these manipulations improved predictive accuracy and synchronization during interaction. This suggests that human-robot interactions should be designed to allow humans to leverage their natural capabilities for detecting biological motion, which conversely may reduce the need for costly robotic computations or added cognitive adaptation on the human side.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7VR\u5b9e\u9a8c\u63a2\u7d22\u4eba\u673a\u534f\u4f5c\u4e2d\u7684\u7269\u4f53\u4f20\u9012\u4efb\u52a1\uff0c\u53d1\u73b0\u4eba\u7c7b\u4ece\u673a\u5668\u4eba\u63d0\u4f9b\u7684\u65e9\u671f\u89c6\u89c9\u4fe1\u606f\u548c\u7c7b\u4eba\u5e73\u6ed1\u8f68\u8ff9\u4e2d\u53d7\u76ca\uff0c\u8fd9\u6709\u52a9\u4e8e\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u548c\u540c\u6b65\u6027\u3002", "motivation": "\u968f\u7740\u673a\u5668\u4eba\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u878d\u5165\u4eba\u7c7b\u5de5\u4f5c\u73af\u5883\uff0c\u9700\u8981\u4f18\u5316\u4eba\u673a\u534f\u8c03\u534f\u4f5c\uff0c\u7279\u522b\u662f\u5728\u7269\u4f53\u4f20\u9012\u7b49\u4ea4\u4e92\u4efb\u52a1\u4e2d\u3002", "method": "\u4f7f\u7528VR\u6a21\u62df\u673a\u5668\u4eba\u4f20\u9012\u4efb\u52a1\uff0c\u5206\u522b\u8003\u5bdf\u56db\u4e2a\u56e0\u7d20\u5bf9\u4eba\u7c7b\u8868\u73b0\u7684\u5f71\u54cd\uff1a\u4efb\u52a1\u542f\u52a8\u63a7\u5236\u548c\u673a\u5668\u4eba\u8fd0\u52a8\u540c\u6b65\u6027\u3001\u4f19\u4f34\u5916\u89c2\u3001\u673a\u5668\u4eba\u901f\u5ea6\u66f2\u7ebf\u3001\u65cb\u8f6c\u7269\u4f53\u8fd0\u52a8\u65f6\u673a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4eba\u7c7b\u53d7\u76ca\u4e8e\u673a\u5668\u4eba\u63d0\u4f9b\u65e9\u671f\u89c6\u89c9\u4fe1\u606f\u548c\u7c7b\u4eba\u5e73\u6ed1\u8f68\u8ff9\uff0c\u8fd9\u4e9b\u56e0\u7d20\u4e0d\u540c\u7a0b\u5ea6\u5730\u6539\u5584\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u4ea4\u4e92\u540c\u6b65\u6027\u3002", "conclusion": "\u4eba\u673a\u4ea4\u4e92\u8bbe\u8ba1\u5e94\u8ba9\u4eba\u7c7b\u80fd\u591f\u5229\u7528\u5176\u68c0\u6d4b\u751f\u7269\u8fd0\u52a8\u7684\u81ea\u7136\u80fd\u529b\uff0c\u8fd9\u53ef\u4ee5\u51cf\u5c11\u673a\u5668\u4eba\u8ba1\u7b97\u6210\u672c\u6216\u4eba\u7c7b\u8ba4\u77e5\u9002\u5e94\u9700\u6c42\u3002"}}
{"id": "2511.20067", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.20067", "abs": "https://arxiv.org/abs/2511.20067", "authors": ["Marta Sumyk", "Oleksandr Kosovan"], "title": "\"Are We Done Yet?\": A Vision-Based Judge for Autonomous Task Completion of Computer Use Agents", "comment": "This work has been accepted to appear at the AAAI 2026 Workshop on Trust and Control in Agentic AI (TrustAgent)", "summary": "Computer Use Agents (CUAs) are designed to autonomously operate digital interfaces, yet they often fail to reliably determine whether a given task has been completed. We present an autonomous evaluation and feedback framework that uses vision-language models to assess task completion directly from screenshots and task descriptions. Our dataset covers 42 built-in macOS applications and 1,260 human-labeled tasks across a wide range of scenarios. Our framework achieves up to 73 percent accuracy in task success detection and yields an average relative improvement of 27 percent in overall task success when evaluator feedback is applied. These results show that vision-based evaluation can serve as an effective feedback mechanism that improves the reliability and self-correction of autonomous computer-use agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u4e3b\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5c4f\u5e55\u622a\u56fe\u548c\u4efb\u52a1\u63cf\u8ff0\u6765\u8bc4\u4f30\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u4efb\u52a1\u5b8c\u6210\u60c5\u51b5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u5728\u81ea\u4e3b\u64cd\u4f5c\u6570\u5b57\u754c\u9762\u65f6\uff0c\u5f80\u5f80\u65e0\u6cd5\u53ef\u9760\u5224\u65ad\u4efb\u52a1\u662f\u5426\u5b8c\u6210\uff0c\u9700\u8981\u6709\u6548\u7684\u8bc4\u4f30\u673a\u5236\u6765\u63d0\u9ad8\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u4ece\u5c4f\u5e55\u622a\u56fe\u548c\u4efb\u52a1\u63cf\u8ff0\u4e2d\u8bc4\u4f30\u4efb\u52a1\u5b8c\u6210\u60c5\u51b5\uff0c\u6784\u5efa\u4e86\u6db5\u76d642\u4e2amacOS\u5e94\u7528\u548c1,260\u4e2a\u4eba\u5de5\u6807\u6ce8\u4efb\u52a1\u7684\u6570\u636e\u96c6\u3002", "result": "\u6846\u67b6\u5728\u4efb\u52a1\u6210\u529f\u68c0\u6d4b\u4e2d\u8fbe\u523073%\u7684\u51c6\u786e\u7387\uff0c\u5e94\u7528\u8bc4\u4f30\u53cd\u9988\u540e\u6574\u4f53\u4efb\u52a1\u6210\u529f\u7387\u5e73\u5747\u76f8\u5bf9\u63d0\u534727%\u3002", "conclusion": "\u57fa\u4e8e\u89c6\u89c9\u7684\u8bc4\u4f30\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u53cd\u9988\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u81ea\u4e3b\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u53ef\u9760\u6027\u548c\u81ea\u6211\u7ea0\u6b63\u80fd\u529b\u3002"}}
{"id": "2511.20552", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20552", "abs": "https://arxiv.org/abs/2511.20552", "authors": ["Haoyu Wang", "Andrea Alfonsi", "Roberto Ponciroli", "Richard Vilim"], "title": "From Features to States: Data-Driven Selection of Measured State Variables via RFE-DMDc", "comment": null, "summary": "The behavior of a dynamical system under a given set of inputs can be captured by tracking the response of an optimal subset of process variables (\\textit{state variables}). For many engineering systems, however, first-principles, model-based identification is impractical, motivating data-driven approaches for Digital Twins used in control and diagnostics. In this paper, we present RFE-DMDc, a supervised, data-driven workflow that uses Recursive Feature Elimination (RFE) to select a minimal, physically meaningful set of variables to monitor and then derives a linear state-space model via Dynamic Mode Decomposition with Control (DMDc). The workflow includes a cross-subsystem selection step that mitigates feature \\textit{overshadowing} in multi-component systems. To corroborate the results, we implement a GA-DMDc baseline that jointly optimizes the state set and model fit under a common accuracy cost on states and outputs. Across a truth-known RLC benchmark and a realistic Integrated Energy System (IES) with multiple thermally coupled components and thousands of candidate variables, RFE-DMDc consistently recovers compact state sets (\\(\\approx 10\\) variables) that achieve test errors comparable to GA-DMDc while requiring an order of magnitude less computational time. The selected variables retain clear physical interpretation across subsystems, and the resulting models demonstrate competitive predictive accuracy, computational efficiency, and robustness to overfitting.", "AI": {"tldr": "RFE-DMDc\u662f\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u9012\u5f52\u7279\u5f81\u6d88\u9664\u9009\u62e9\u6700\u5c0f\u5316\u7269\u7406\u610f\u4e49\u53d8\u91cf\u96c6\uff0c\u7136\u540e\u4f7f\u7528\u5e26\u63a7\u5236\u7684\u52a8\u6001\u6a21\u6001\u5206\u89e3\u5efa\u7acb\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u7ade\u4e89\u6027\u9884\u6d4b\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u5bf9\u4e8e\u8bb8\u591a\u5de5\u7a0b\u7cfb\u7edf\uff0c\u57fa\u4e8e\u7b2c\u4e00\u6027\u539f\u7406\u7684\u6a21\u578b\u8bc6\u522b\u4e0d\u5207\u5b9e\u9645\uff0c\u9700\u8981\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u7528\u4e8e\u63a7\u5236\u548c\u8bca\u65ad\u7684\u6570\u5b57\u5b6a\u751f\u3002", "method": "\u4f7f\u7528\u9012\u5f52\u7279\u5f81\u6d88\u9664\u9009\u62e9\u6700\u5c0f\u5316\u7269\u7406\u610f\u4e49\u53d8\u91cf\u96c6\uff0c\u7136\u540e\u901a\u8fc7\u5e26\u63a7\u5236\u7684\u52a8\u6001\u6a21\u6001\u5206\u89e3\u63a8\u5bfc\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u5305\u542b\u8de8\u5b50\u7cfb\u7edf\u9009\u62e9\u6b65\u9aa4\u4ee5\u7f13\u89e3\u591a\u7ec4\u4ef6\u7cfb\u7edf\u4e2d\u7684\u7279\u5f81\u906e\u853d\u95ee\u9898\u3002", "result": "\u5728RLC\u57fa\u51c6\u6d4b\u8bd5\u548c\u96c6\u6210\u80fd\u6e90\u7cfb\u7edf\u4e0a\uff0cRFE-DMDc\u59cb\u7ec8\u6062\u590d\u7d27\u51d1\u7684\u72b6\u6001\u96c6\uff08\u7ea610\u4e2a\u53d8\u91cf\uff09\uff0c\u6d4b\u8bd5\u8bef\u5dee\u4e0eGA-DMDc\u76f8\u5f53\uff0c\u4f46\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c11\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u6240\u9009\u53d8\u91cf\u5728\u5b50\u7cfb\u7edf\u95f4\u4fdd\u6301\u6e05\u6670\u7684\u7269\u7406\u89e3\u91ca\uff0c\u6240\u5f97\u6a21\u578b\u5c55\u73b0\u51fa\u7ade\u4e89\u6027\u7684\u9884\u6d4b\u7cbe\u5ea6\u3001\u8ba1\u7b97\u6548\u7387\u548c\u6297\u8fc7\u62df\u5408\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.20330", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.20330", "abs": "https://arxiv.org/abs/2511.20330", "authors": ["Yuhan Wu", "Tiantian Wei", "Shuo Wang", "ZhiChao Wang", "Yanyong Zhang", "Daniel Cremers", "Yan Xia"], "title": "ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation", "comment": null, "summary": "Interactive articulated manipulation requires long-horizon, multi-step interactions with appliances while maintaining physical consistency. Existing vision-language and diffusion-based policies struggle to generalize across parts, instances, and categories. We first introduce ArtiBench, a five-level benchmark covering kitchen, storage, office, and tool environments. ArtiBench enables structured evaluation from cross-part and cross-instance variation to long-horizon multi-object tasks, revealing the core generalization challenges of articulated object manipulation. Building on this benchmark, we propose ArtiBrain, a modular framework that unifies high-level reasoning with adaptive low-level control. ArtiBrain uses a VLM-based Task Reasoner (GPT-4.1) to decompose and validate subgoals, and employs a Hybrid Controller that combines geometry-aware keyframe execution with affordance-guided diffusion for precise and interpretable manipulation. An Affordance Memory Bank continually accumulates successful execution episodes and propagates part-level actionable affordances to unseen articulated parts and configurations. Extensive experiments on ArtiBench show that our ArtiBrain significantly outperforms state-of-the-art multimodal and diffusion-based methods in robustness and generalization. Code and dataset will be released upon acceptance.", "AI": {"tldr": "\u63d0\u51fa\u4e86ArtiBench\u57fa\u51c6\u6d4b\u8bd5\u548cArtiBrain\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5173\u8282\u7269\u4f53\u64cd\u4f5c\u4e2d\u7684\u6cdb\u5316\u6311\u6218\uff0c\u7ed3\u5408\u9ad8\u5c42\u63a8\u7406\u548c\u81ea\u9002\u5e94\u4f4e\u5c42\u63a7\u5236\uff0c\u5728\u591a\u4e2a\u73af\u5883\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9\u8bed\u8a00\u548c\u57fa\u4e8e\u6269\u6563\u7684\u7b56\u7565\u5728\u8de8\u90e8\u4ef6\u3001\u5b9e\u4f8b\u548c\u7c7b\u522b\u7684\u5173\u8282\u64cd\u4f5c\u4e2d\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u9700\u8981\u89e3\u51b3\u7269\u7406\u4e00\u81f4\u6027\u548c\u957f\u65f6\u7a0b\u4ea4\u4e92\u7684\u6311\u6218\u3002", "method": "ArtiBrain\u6846\u67b6\u5305\u542bVLM\u4efb\u52a1\u63a8\u7406\u5668\u8fdb\u884c\u5b50\u76ee\u6807\u5206\u89e3\u548c\u9a8c\u8bc1\uff0c\u6df7\u5408\u63a7\u5236\u5668\u7ed3\u5408\u51e0\u4f55\u611f\u77e5\u5173\u952e\u5e27\u6267\u884c\u548c\u53ef\u4f9b\u6027\u5f15\u5bfc\u6269\u6563\uff0c\u4ee5\u53ca\u6301\u7eed\u79ef\u7d2f\u6210\u529f\u7ecf\u9a8c\u7684Affordance Memory Bank\u3002", "result": "\u5728ArtiBench\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cArtiBrain\u5728\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u548c\u57fa\u4e8e\u6269\u6563\u7684\u65b9\u6cd5\u3002", "conclusion": "ArtiBrain\u901a\u8fc7\u6a21\u5757\u5316\u6846\u67b6\u7edf\u4e00\u9ad8\u5c42\u63a8\u7406\u548c\u81ea\u9002\u5e94\u4f4e\u5c42\u63a7\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5173\u8282\u7269\u4f53\u64cd\u4f5c\u7684\u6cdb\u5316\u6311\u6218\uff0c\u4e3a\u4ea4\u4e92\u5f0f\u64cd\u4f5c\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20085", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.20085", "abs": "https://arxiv.org/abs/2511.20085", "authors": ["Chujie Wang", "Zhiyuan Luo", "Ruiqi Liu", "Can Ran", "Shenghua Fan", "Xi Chen", "Chu He"], "title": "VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis", "comment": null, "summary": "The current remote sensing image analysis task is increasingly evolving from traditional object recognition to complex intelligence reasoning, which places higher requirements on the model's reasoning ability and the flexibility of tool invocation. To this end, we propose a new multimodal agent framework, Vision-Interleaved Chain-of-Thought Framework (VICoT), which implements explicit multi-round reasoning by dynamically incorporating visual tools into the chain of thought. Through a stack-based reasoning structure and a modular MCP-compatible tool suite, VICoT enables LLMs to efficiently perform multi-round, interleaved vision-language reasoning tasks with strong generalization and flexibility.We also propose the Reasoning Stack distillation method to migrate complex Agent behaviors to small, lightweight models, which ensures the reasoning capability while significantly reducing complexity. Experiments on multiple remote sensing benchmarks demonstrate that VICoT significantly outperforms existing SOTA frameworks in reasoning transparency, execution efficiency, and generation quality.", "AI": {"tldr": "\u63d0\u51fa\u4e86VICoT\u591a\u6a21\u6001\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u6574\u5408\u89c6\u89c9\u5de5\u5177\u5230\u601d\u7ef4\u94fe\u4e2d\u5b9e\u73b0\u663e\u5f0f\u591a\u8f6e\u63a8\u7406\uff0c\u5728\u9065\u611f\u56fe\u50cf\u5206\u6790\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709SOTA\u65b9\u6cd5\u3002", "motivation": "\u9065\u611f\u56fe\u50cf\u5206\u6790\u4efb\u52a1\u6b63\u4ece\u4f20\u7edf\u76ee\u6807\u8bc6\u522b\u5411\u590d\u6742\u667a\u80fd\u63a8\u7406\u6f14\u8fdb\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\u548c\u7075\u6d3b\u7684\u5de5\u5177\u8c03\u7528\u80fd\u529b\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6808\u7684\u63a8\u7406\u7ed3\u6784\u548c\u6a21\u5757\u5316MCP\u517c\u5bb9\u5de5\u5177\u5957\u4ef6\uff0c\u4f7fLLM\u80fd\u591f\u9ad8\u6548\u6267\u884c\u591a\u8f6e\u4ea4\u9519\u7684\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u4efb\u52a1\uff1b\u63d0\u51fa\u63a8\u7406\u6808\u84b8\u998f\u65b9\u6cd5\u5c06\u590d\u6742\u667a\u80fd\u4f53\u884c\u4e3a\u8fc1\u79fb\u5230\u8f7b\u91cf\u7ea7\u6a21\u578b\u3002", "result": "\u5728\u591a\u4e2a\u9065\u611f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVICoT\u5728\u63a8\u7406\u900f\u660e\u5ea6\u3001\u6267\u884c\u6548\u7387\u548c\u751f\u6210\u8d28\u91cf\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709SOTA\u6846\u67b6\u3002", "conclusion": "VICoT\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u591a\u8f6e\u63a8\u7406\u548c\u5de5\u5177\u52a8\u6001\u6574\u5408\uff0c\u6709\u6548\u63d0\u5347\u4e86\u9065\u611f\u56fe\u50cf\u5206\u6790\u7684\u63a8\u7406\u80fd\u529b\u548c\u7075\u6d3b\u6027\uff0c\u5e76\u901a\u8fc7\u84b8\u998f\u65b9\u6cd5\u5b9e\u73b0\u4e86\u590d\u6742\u63a8\u7406\u80fd\u529b\u7684\u8f7b\u91cf\u5316\u8fc1\u79fb\u3002"}}
{"id": "2511.20603", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20603", "abs": "https://arxiv.org/abs/2511.20603", "authors": ["Winfrey Paul Sagayam Dennis"], "title": "Exploring Urban Air Mobility Adoption Potential in San Francisco Bay Area Region: A Systems of Systems Level Case Study on Passenger Waiting Times and Travel Efficiency", "comment": null, "summary": "Urban Air mobility has gained momentum with recent advancements in the electric vertical take-off and landing (eVTOL) vehicles, offering faster point-to-point air taxi services that could help relieve traffic congestion in chronically overburdened cities. The research assesses the feasibility and systems-of-systems level adoption potential of UAM operations in the San Francisco Bay Area by comparing passenger departure, waiting, travel, and arrival times across key regional nodes, including San Francisco, Oakland, San Jose, and Palo Alto airports, with conventional ground transportation. A multi-agent simulation was developed in MATLAB to evaluate the fleet operations and to model demand arrival using a Poisson process under stochastic passenger flows and turnaround constraints. Results indicate that utilizing UAM during peak demand could reduce total travel times up to eighty percent across the region. The findings of this paper highlight the critical operational factors for fleet schedule optimization. Especially how the fleet size, passengers' request volumes, and turnaround time directly influence waiting time, operating cost, and overall user acceptance.", "AI": {"tldr": "\u8bc4\u4f30\u65e7\u91d1\u5c71\u6e7e\u533a\u57ce\u5e02\u7a7a\u4e2d\u4ea4\u901a(UAM)\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u4eff\u771f\u6bd4\u8f83UAM\u4e0e\u4f20\u7edf\u5730\u9762\u4ea4\u901a\u7684\u65f6\u95f4\u6548\u7387\uff0c\u53d1\u73b0\u5728\u9ad8\u5cf0\u65f6\u6bb5\u53ef\u51cf\u5c1180%\u7684\u65c5\u884c\u65f6\u95f4\u3002", "motivation": "\u968f\u7740\u7535\u52a8\u5782\u76f4\u8d77\u964d(eVTOL)\u8f66\u8f86\u7684\u53d1\u5c55\uff0c\u57ce\u5e02\u7a7a\u4e2d\u4ea4\u901a\u6709\u671b\u7f13\u89e3\u57ce\u5e02\u4ea4\u901a\u62e5\u5835\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5728\u65e7\u91d1\u5c71\u6e7e\u533a\u7684\u7cfb\u7edf\u7ea7\u91c7\u7528\u6f5c\u529b\u3002", "method": "\u5728MATLAB\u4e2d\u5f00\u53d1\u591a\u667a\u80fd\u4f53\u4eff\u771f\uff0c\u4f7f\u7528\u6cca\u677e\u8fc7\u7a0b\u6a21\u62df\u968f\u673a\u4e58\u5ba2\u6d41\u548c\u5468\u8f6c\u7ea6\u675f\u4e0b\u7684\u9700\u6c42\u5230\u8fbe\uff0c\u8bc4\u4f30\u673a\u961f\u8fd0\u8425\u3002", "result": "\u5728\u9ad8\u5cf0\u9700\u6c42\u65f6\u6bb5\uff0cUAM\u53ef\u5c06\u6574\u4e2a\u533a\u57df\u7684\u65c5\u884c\u65f6\u95f4\u51cf\u5c11\u9ad8\u8fbe80%\u3002", "conclusion": "\u673a\u961f\u89c4\u6a21\u3001\u4e58\u5ba2\u8bf7\u6c42\u91cf\u548c\u5468\u8f6c\u65f6\u95f4\u7b49\u5173\u952e\u8fd0\u8425\u56e0\u7d20\u76f4\u63a5\u5f71\u54cd\u7b49\u5f85\u65f6\u95f4\u3001\u8fd0\u8425\u6210\u672c\u548c\u7528\u6237\u63a5\u53d7\u5ea6\uff0c\u5bf9\u673a\u961f\u8c03\u5ea6\u4f18\u5316\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.20353", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20353", "abs": "https://arxiv.org/abs/2511.20353", "authors": ["Benjamin Sportich", "Kenza Boubakri", "Olivier Simonin", "Alessandro Renzaglia"], "title": "Quality-guided UAV Surface Exploration for 3D Reconstruction", "comment": null, "summary": "Reasons for mapping an unknown environment with autonomous robots are wide-ranging, but in practice, they are often overlooked when developing planning strategies. Rapid information gathering and comprehensive structural assessment of buildings have different requirements and therefore necessitate distinct methodologies. In this paper, we propose a novel modular Next-Best-View (NBV) planning framework for aerial robots that explicitly uses a reconstruction quality objective to guide the exploration planning. In particular, our approach introduces new and efficient methods for view generation and selection of viewpoint candidates that are adaptive to the user-defined quality requirements, fully exploiting the uncertainty encoded in a Truncated Signed Distance field (TSDF) representation of the environment. This results in informed and efficient exploration decisions tailored towards the predetermined objective. Finally, we validate our method via extensive simulations in realistic environments. We demonstrate that it successfully adjusts its behavior to the user goal while consistently outperforming conventional NBV strategies in terms of coverage, quality of the final 3D map and path efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7a7a\u4e2d\u673a\u5668\u4eba\u7684\u6a21\u5757\u5316Next-Best-View\u89c4\u5212\u6846\u67b6\uff0c\u4f7f\u7528\u91cd\u5efa\u8d28\u91cf\u76ee\u6807\u6307\u5bfc\u63a2\u7d22\u89c4\u5212\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u89c6\u56fe\u751f\u6210\u548c\u9009\u62e9\u65b9\u6cd5\uff0c\u5728\u8986\u76d6\u8303\u56f4\u30013D\u5730\u56fe\u8d28\u91cf\u548c\u8def\u5f84\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u4f20\u7edfNBV\u7b56\u7565\u3002", "motivation": "\u81ea\u4e3b\u673a\u5668\u4eba\u5728\u672a\u77e5\u73af\u5883\u4e2d\u7684\u5efa\u56fe\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u73b0\u6709\u89c4\u5212\u7b56\u7565\u5f80\u5f80\u5ffd\u89c6\u4e0d\u540c\u5e94\u7528\u573a\u666f\uff08\u5982\u5feb\u901f\u4fe1\u606f\u6536\u96c6\u548c\u5efa\u7b51\u7269\u7ed3\u6784\u8bc4\u4f30\uff09\u7684\u4e0d\u540c\u9700\u6c42\uff0c\u9700\u8981\u9488\u5bf9\u7279\u5b9a\u76ee\u6807\u7684\u65b9\u6cd5\u8bba\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316NBV\u89c4\u5212\u6846\u67b6\uff0c\u5f15\u5165\u57fa\u4e8eTSDF\u73af\u5883\u8868\u793a\u4e2d\u7f16\u7801\u7684\u4e0d\u786e\u5b9a\u6027\u7684\u9ad8\u6548\u89c6\u56fe\u751f\u6210\u548c\u5019\u9009\u89c6\u70b9\u9009\u62e9\u65b9\u6cd5\uff0c\u80fd\u591f\u81ea\u9002\u5e94\u4e8e\u7528\u6237\u5b9a\u4e49\u7684\u8d28\u91cf\u8981\u6c42\u3002", "result": "\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u5e7f\u6cdb\u6a21\u62df\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u6839\u636e\u7528\u6237\u76ee\u6807\u8c03\u6574\u884c\u4e3a\uff0c\u5728\u8986\u76d6\u8303\u56f4\u3001\u6700\u7ec83D\u5730\u56fe\u8d28\u91cf\u548c\u8def\u5f84\u6548\u7387\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u4f20\u7edfNBV\u7b56\u7565\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u9488\u5bf9\u9884\u5b9a\u76ee\u6807\u505a\u51fa\u660e\u667a\u4e14\u9ad8\u6548\u7684\u63a2\u7d22\u51b3\u7b56\uff0c\u4e3a\u4e0d\u540c\u8d28\u91cf\u8981\u6c42\u7684\u5efa\u56fe\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20138", "categories": ["cs.AI", "cs.DM", "cs.LG", "math.CO"], "pdf": "https://arxiv.org/pdf/2511.20138", "abs": "https://arxiv.org/abs/2511.20138", "authors": ["Jason Lo", "Mohammadnima Jafari"], "title": "From data to concepts via wiring diagrams", "comment": "19 pages", "summary": "A wiring diagram is a labeled directed graph that represents an abstract concept such as a temporal process. In this article, we introduce the notion of a quasi-skeleton wiring diagram graph, and prove that quasi-skeleton wiring diagram graphs correspond to Hasse diagrams. Using this result, we designed algorithms that extract wiring diagrams from sequential data. We used our algorithms in analyzing the behavior of an autonomous agent playing a computer game, and the algorithms correctly identified the winning strategies. We compared the performance of our main algorithm with two other algorithms based on standard clustering techniques (DBSCAN and agglomerative hierarchical), including when some of the data was perturbed. Overall, this article brings together techniques in category theory, graph theory, clustering, reinforcement learning, and data engineering.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u51c6\u9aa8\u67b6\u63a5\u7ebf\u56fe\u7684\u6982\u5ff5\uff0c\u8bc1\u660e\u5176\u4e0eHasse\u56fe\u5bf9\u5e94\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4ece\u5e8f\u5217\u6570\u636e\u4e2d\u63d0\u53d6\u63a5\u7ebf\u56fe\u7684\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u5728\u5206\u6790\u81ea\u4e3b\u4ee3\u7406\u73a9\u7535\u8111\u6e38\u620f\u65f6\u6210\u529f\u8bc6\u522b\u4e86\u83b7\u80dc\u7b56\u7565\uff0c\u5e76\u4e0eDBSCAN\u548c\u51dd\u805a\u5c42\u6b21\u805a\u7c7b\u7b97\u6cd5\u8fdb\u884c\u4e86\u6027\u80fd\u6bd4\u8f83\u3002", "motivation": "\u63a5\u7ebf\u56fe\u662f\u8868\u793a\u62bd\u8c61\u6982\u5ff5\uff08\u5982\u65f6\u95f4\u8fc7\u7a0b\uff09\u7684\u6709\u5411\u6807\u8bb0\u56fe\u3002\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4ece\u5e8f\u5217\u6570\u636e\u4e2d\u63d0\u53d6\u63a5\u7ebf\u56fe\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4ee5\u5206\u6790\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u884c\u4e3a\u6a21\u5f0f\u3002", "method": "\u5f15\u5165\u51c6\u9aa8\u67b6\u63a5\u7ebf\u56fe\u6982\u5ff5\uff0c\u8bc1\u660e\u5176\u4e0eHasse\u56fe\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u6b64\u7684\u7b97\u6cd5\u4ece\u5e8f\u5217\u6570\u636e\u4e2d\u63d0\u53d6\u63a5\u7ebf\u56fe\u3002\u4f7f\u7528\u805a\u7c7b\u6280\u672f\uff08DBSCAN\u548c\u51dd\u805a\u5c42\u6b21\u805a\u7c7b\uff09\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u3002", "result": "\u7b97\u6cd5\u6210\u529f\u8bc6\u522b\u4e86\u81ea\u4e3b\u4ee3\u7406\u5728\u7535\u8111\u6e38\u620f\u4e2d\u7684\u83b7\u80dc\u7b56\u7565\u3002\u4e0e\u6807\u51c6\u805a\u7c7b\u65b9\u6cd5\u76f8\u6bd4\uff0c\u4e3b\u8981\u7b97\u6cd5\u5728\u6570\u636e\u6270\u52a8\u60c5\u51b5\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u8303\u7574\u8bba\u3001\u56fe\u8bba\u3001\u805a\u7c7b\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u6570\u636e\u5de5\u7a0b\u6280\u672f\u76f8\u7ed3\u5408\uff0c\u4e3a\u4ece\u5e8f\u5217\u6570\u636e\u4e2d\u63d0\u53d6\u63a5\u7ebf\u56fe\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7406\u8bba\u6846\u67b6\u548c\u7b97\u6cd5\u5de5\u5177\u3002"}}
{"id": "2511.20467", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20467", "abs": "https://arxiv.org/abs/2511.20467", "authors": ["Liangkai Liu", "Weisong Shi", "Kang G. Shin"], "title": "Power-Efficient Autonomous Mobile Robots", "comment": "13 pages, 16 figures", "summary": "This paper presents pNav, a novel power-management system that significantly enhances the power/energy-efficiency of Autonomous Mobile Robots (AMRs) by jointly optimizing their physical/mechanical and cyber subsystems. By profiling AMRs' power consumption, we identify three challenges in achieving CPS (cyber-physical system) power-efficiency that involve both cyber (C) and physical (P) subsystems: (1) variabilities of system power consumption breakdown, (2) environment-aware navigation locality, and (3) coordination of C and P subsystems. pNav takes a multi-faceted approach to achieve power-efficiency of AMRs. First, it integrates millisecond-level power consumption prediction for both C and P subsystems. Second, it includes novel real-time modeling and monitoring of spatial and temporal navigation localities for AMRs. Third, it supports dynamic coordination of AMR software (navigation, detection) and hardware (motors, DVFS driver) configurations. pNav is prototyped using the Robot Operating System (ROS) Navigation Stack, 2D LiDAR, and camera. Our in-depth evaluation with a real robot and Gazebo environments demonstrates a >96% accuracy in predicting power consumption and a 38.1% reduction in power consumption without compromising navigation accuracy and safety.", "AI": {"tldr": "pNav\u662f\u4e00\u4e2a\u65b0\u578b\u7535\u6e90\u7ba1\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u81ea\u4e3b\u79fb\u52a8\u673a\u5668\u4eba\u7684\u7269\u7406/\u673a\u68b0\u548c\u7f51\u7edc\u5b50\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u9ad8\u5176\u529f\u7387/\u80fd\u6548\u3002", "motivation": "\u901a\u8fc7\u5206\u6790AMR\u7684\u529f\u8017\u7279\u5f81\uff0c\u53d1\u73b0\u5b9e\u73b0CPS\u80fd\u6548\u9762\u4e34\u4e09\u4e2a\u6311\u6218\uff1a\u7cfb\u7edf\u529f\u8017\u5206\u89e3\u7684\u53d8\u5f02\u6027\u3001\u73af\u5883\u611f\u77e5\u5bfc\u822a\u5c40\u90e8\u6027\u3001\u4ee5\u53caC\u548cP\u5b50\u7cfb\u7edf\u7684\u534f\u8c03\u95ee\u9898\u3002", "method": "\u91c7\u7528\u591a\u5c42\u9762\u65b9\u6cd5\uff1a\u96c6\u6210\u6beb\u79d2\u7ea7\u529f\u8017\u9884\u6d4b\u3001\u5b9e\u65f6\u5efa\u6a21\u548c\u76d1\u63a7\u5bfc\u822a\u65f6\u7a7a\u5c40\u90e8\u6027\u3001\u52a8\u6001\u534f\u8c03\u8f6f\u4ef6\u548c\u786c\u4ef6\u914d\u7f6e\u3002\u57fa\u4e8eROS\u5bfc\u822a\u6808\u30012D LiDAR\u548c\u6444\u50cf\u5934\u8fdb\u884c\u539f\u578b\u5f00\u53d1\u3002", "result": "\u5728\u771f\u5b9e\u673a\u5668\u4eba\u548cGazebo\u73af\u5883\u4e2d\u7684\u6df1\u5ea6\u8bc4\u4f30\u663e\u793a\uff0c\u529f\u8017\u9884\u6d4b\u51c6\u786e\u7387>96%\uff0c\u529f\u8017\u964d\u4f4e38.1%\uff0c\u4e14\u4e0d\u5f71\u54cd\u5bfc\u822a\u7cbe\u5ea6\u548c\u5b89\u5168\u6027\u3002", "conclusion": "pNav\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86AMR\u7684\u80fd\u6548\u95ee\u9898\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u7f51\u7edc\u548c\u7269\u7406\u5b50\u7cfb\u7edf\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u529f\u8017\u964d\u4f4e\u3002"}}
{"id": "2511.20394", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20394", "abs": "https://arxiv.org/abs/2511.20394", "authors": ["Shiqian Liu", "Azlan Mohd Zain", "Le-le Mao"], "title": "Improved adaptive wind driven optimization algorithm for real-time path planning", "comment": "23 pages, 4 figures", "summary": "Recently, path planning has achieved remarkable progress in enhancing global search capability and convergence accuracy through heuristic and learning-inspired optimization frameworks. However, real-time adaptability in dynamic environments remains a critical challenge for autonomous navigation, particularly when robots must generate collision-free, smooth, and efficient trajectories under complex constraints. By analyzing the difficulties in dynamic path planning, the Wind Driven Optimization (WDO) algorithm emerges as a promising framework owing to its physically interpretable search dynamics. Motivated by these observations, this work revisits the WDO principle and proposes a variant formulation, Multi-hierarchical adaptive wind driven optimization(MAWDO), that improves adaptability and robustness in time-varying environments. To mitigate instability and premature convergence, a hierarchical-guidance mechanism divides the population into multiple groups guided by individual, regional, and global leaders to balance exploration and exploitation. Extensive evaluations on sixteen benchmark functions show that MAWDO achieves superior optimization accuracy, convergence stability, and adaptability over state-of-the art metaheuristics. In dynamic path planning, MAWDO shortens the path length to 469.28 pixels, improving over Multi-strategy ensemble wind driven optimization(MEWDO), Adaptive wind driven optimization(AWDO) and WDO by 3.51\\%, 11.63\\% and 14.93\\%, and achieves the smallest optimality gap (1.01) with smoothness 0.71 versus 13.50 and 15.67 for AWDO and WDO, leading to smoother, shorter, and collision-free trajectories that confirm its effectiveness for real-time path planning in complex environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u98ce\u9a71\u52a8\u4f18\u5316\u7b97\u6cd5MAWDO\uff0c\u901a\u8fc7\u5206\u5c42\u5f15\u5bfc\u673a\u5236\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u8def\u5f84\u89c4\u5212\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u7f29\u77ed\u8def\u5f84\u957f\u5ea63.51%-14.93%\uff0c\u5e76\u751f\u6210\u66f4\u5e73\u6ed1\u7684\u8f68\u8ff9\u3002", "motivation": "\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u9002\u5e94\u6027\u662f\u81ea\u4e3b\u5bfc\u822a\u7684\u5173\u952e\u6311\u6218\uff0c\u4f20\u7edf\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u9002\u5e94\u6027\u4e0d\u8db3\uff0c\u800c\u98ce\u9a71\u52a8\u4f18\u5316\u7b97\u6cd5\u56e0\u5176\u7269\u7406\u53ef\u89e3\u91ca\u7684\u641c\u7d22\u52a8\u6001\u800c\u663e\u793a\u51fa\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u591a\u5c42\u7ea7\u81ea\u9002\u5e94\u98ce\u9a71\u52a8\u4f18\u5316(MAWDO)\uff0c\u91c7\u7528\u5206\u5c42\u5f15\u5bfc\u673a\u5236\u5c06\u79cd\u7fa4\u5212\u5206\u4e3a\u591a\u4e2a\u7ec4\uff0c\u5206\u522b\u7531\u4e2a\u4f53\u3001\u533a\u57df\u548c\u5168\u5c40\u9886\u5bfc\u8005\u5f15\u5bfc\uff0c\u4ee5\u5e73\u8861\u63a2\u7d22\u548c\u5f00\u53d1\u80fd\u529b\u3002", "result": "\u572816\u4e2a\u57fa\u51c6\u51fd\u6570\u4e0a\u8bc4\u4f30\u663e\u793aMAWDO\u5728\u4f18\u5316\u7cbe\u5ea6\u3001\u6536\u655b\u7a33\u5b9a\u6027\u548c\u9002\u5e94\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002\u5728\u52a8\u6001\u8def\u5f84\u89c4\u5212\u4e2d\uff0c\u8def\u5f84\u957f\u5ea6\u7f29\u77ed\u81f3469.28\u50cf\u7d20\uff0c\u76f8\u6bd4MEWDO\u3001AWDO\u548cWDO\u5206\u522b\u63d0\u53473.51%\u300111.63%\u548c14.93%\uff0c\u6700\u4f18\u6027\u5dee\u8ddd\u6700\u5c0f(1.01)\uff0c\u5e73\u6ed1\u5ea6\u4e3a0.71\u3002", "conclusion": "MAWDO\u80fd\u591f\u751f\u6210\u66f4\u5e73\u6ed1\u3001\u66f4\u77ed\u4e14\u65e0\u78b0\u649e\u7684\u8f68\u8ff9\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u65f6\u8def\u5f84\u89c4\u5212\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.20196", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20196", "abs": "https://arxiv.org/abs/2511.20196", "authors": ["Zhen Zeng", "Leijiang Gu", "Zhangling Duan", "Feng Li", "Zenglin Shi", "Cees G. M. Snoek", "Meng Wang"], "title": "Towards Benign Memory Forgetting for Selective Multimodal Large Language Model Unlearning", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) achieve remarkable capabilities but can inadvertently memorize privacy-sensitive information. Although existing unlearning methods can remove such knowledge, they fail to achieve benign forgetting because they often degrade the model's general image understanding performance. To address this, we propose the Sculpted Memory Forgetting Adapter (SMFA), which confines forgetting to targeted memory regions while preserving overall capabilities. SMFA first fine-tunes the model to replace sensitive responses with refusals, yielding a memory forgetting adapter, and then applies a retaining anchor-guided masking mechanism to prevent interference with unrelated knowledge and understanding ability. To systematically evaluate selective MLLM unlearning, we introduce S-MLLMUn Bench, the first benchmark designed to jointly assess the removal of sensitive knowledge and retention of general visual understanding. Extensive experiments show that, unlike prior methods, SMFA achieves precise and controllable unlearning while maintaining the model's foundational image understanding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSMFA\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bb0\u5fc6\u9057\u5fd8\u9002\u914d\u5668\u548c\u4fdd\u7559\u951a\u70b9\u5f15\u5bfc\u7684\u63a9\u7801\u673a\u5236\uff0c\u5b9e\u73b0\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9690\u79c1\u654f\u611f\u4fe1\u606f\u7684\u7cbe\u786e\u53ef\u63a7\u9057\u5fd8\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u4e00\u822c\u56fe\u50cf\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4f1a\u65e0\u610f\u4e2d\u8bb0\u5fc6\u9690\u79c1\u654f\u611f\u4fe1\u606f\uff0c\u800c\u73b0\u6709\u7684\u9057\u5fd8\u65b9\u6cd5\u5728\u79fb\u9664\u8fd9\u4e9b\u77e5\u8bc6\u65f6\u5f80\u5f80\u4f1a\u635f\u5bb3\u6a21\u578b\u7684\u901a\u7528\u56fe\u50cf\u7406\u89e3\u6027\u80fd\uff0c\u65e0\u6cd5\u5b9e\u73b0\u826f\u6027\u9057\u5fd8\u3002", "method": "\u63d0\u51faSculpted Memory Forgetting Adapter (SMFA)\uff0c\u9996\u5148\u5fae\u8c03\u6a21\u578b\u5c06\u654f\u611f\u54cd\u5e94\u66ff\u6362\u4e3a\u62d2\u7edd\u56de\u7b54\uff0c\u5f97\u5230\u8bb0\u5fc6\u9057\u5fd8\u9002\u914d\u5668\uff0c\u7136\u540e\u5e94\u7528\u4fdd\u7559\u951a\u70b9\u5f15\u5bfc\u7684\u63a9\u7801\u673a\u5236\u9632\u6b62\u5bf9\u65e0\u5173\u77e5\u8bc6\u548c\u7406\u89e3\u80fd\u529b\u7684\u5e72\u6270\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u4e0d\u540c\uff0cSMFA\u80fd\u591f\u5b9e\u73b0\u7cbe\u786e\u53ef\u63a7\u7684\u9057\u5fd8\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u57fa\u7840\u56fe\u50cf\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "SMFA\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u9690\u79c1\u654f\u611f\u4fe1\u606f\u9057\u5fd8\u7684\u95ee\u9898\uff0c\u5728\u79fb\u9664\u654f\u611f\u77e5\u8bc6\u7684\u540c\u65f6\u6709\u6548\u4fdd\u7559\u4e86\u6a21\u578b\u7684\u901a\u7528\u89c6\u89c9\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2511.20593", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20593", "abs": "https://arxiv.org/abs/2511.20593", "authors": ["Allen Emmanuel Binny", "Mahathi Anand", "Hugo T. M. Kussaba", "Lingyun Chen", "Shreenabh Agrawal", "Fares J. Abu-Dakka", "Abdalla Swikir"], "title": "Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning", "comment": null, "summary": "Learning safe and stable robot motions from demonstrations remains a challenge, especially in complex, nonlinear tasks involving dynamic, obstacle-rich environments. In this paper, we propose Safe and Stable Neural Network Dynamical Systems S$^2$-NNDS, a learning-from-demonstration framework that simultaneously learns expressive neural dynamical systems alongside neural Lyapunov stability and barrier safety certificates. Unlike traditional approaches with restrictive polynomial parameterizations, S$^2$-NNDS leverages neural networks to capture complex robot motions providing probabilistic guarantees through split conformal prediction in learned certificates. Experimental results on various 2D and 3D datasets -- including LASA handwriting and demonstrations recorded kinesthetically from the Franka Emika Panda robot -- validate S$^2$-NNDS effectiveness in learning robust, safe, and stable motions from potentially unsafe demonstrations.", "AI": {"tldr": "S\u00b2-NNDS\u662f\u4e00\u4e2a\u4ece\u6f14\u793a\u4e2d\u5b66\u4e60\u673a\u5668\u4eba\u8fd0\u52a8\u7684\u6846\u67b6\uff0c\u540c\u65f6\u5b66\u4e60\u795e\u7ecf\u52a8\u6001\u7cfb\u7edf\u4ee5\u53ca\u795e\u7ecfLyapunov\u7a33\u5b9a\u6027\u548c\u5c4f\u969c\u5b89\u5168\u8bc1\u4e66\uff0c\u63d0\u4f9b\u6982\u7387\u5b89\u5168\u4fdd\u8bc1\u3002", "motivation": "\u5728\u590d\u6742\u975e\u7ebf\u6027\u4efb\u52a1\u4e2d\uff0c\u4ece\u6f14\u793a\u4e2d\u5b66\u4e60\u5b89\u5168\u7a33\u5b9a\u7684\u673a\u5668\u4eba\u8fd0\u52a8\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u5728\u52a8\u6001\u3001\u969c\u788d\u7269\u4e30\u5bcc\u7684\u73af\u5883\u4e2d\u3002", "method": "\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u6355\u6349\u590d\u6742\u673a\u5668\u4eba\u8fd0\u52a8\uff0c\u901a\u8fc7\u5206\u88c2\u4fdd\u5f62\u9884\u6d4b\u5728\u5b66\u4e60\u8bc1\u4e66\u4e2d\u63d0\u4f9b\u6982\u7387\u4fdd\u8bc1\uff0c\u4e0e\u4f20\u7edf\u9650\u5236\u6027\u591a\u9879\u5f0f\u53c2\u6570\u5316\u65b9\u6cd5\u4e0d\u540c\u3002", "result": "\u57282D\u548c3D\u6570\u636e\u96c6\uff08\u5305\u62ecLASA\u624b\u5199\u548cFranka Emika Panda\u673a\u5668\u4eba\u6f14\u793a\uff09\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86S\u00b2-NNDS\u4ece\u6f5c\u5728\u4e0d\u5b89\u5168\u6f14\u793a\u4e2d\u5b66\u4e60\u9c81\u68d2\u3001\u5b89\u5168\u3001\u7a33\u5b9a\u8fd0\u52a8\u7684\u6709\u6548\u6027\u3002", "conclusion": "S\u00b2-NNDS\u6846\u67b6\u80fd\u591f\u540c\u65f6\u5b66\u4e60\u8868\u8fbe\u6027\u795e\u7ecf\u52a8\u6001\u7cfb\u7edf\u548c\u5b89\u5168\u7a33\u5b9a\u6027\u8bc1\u4e66\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u5b89\u5168\u7a33\u5b9a\u7684\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\u4e60\u3002"}}
{"id": "2511.20200", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20200", "abs": "https://arxiv.org/abs/2511.20200", "authors": ["Yitian Huang", "Yuxuan Lei", "Jianxun Lian", "Hao Liao"], "title": "Interactive AI NPCs Powered by LLMs: Technical Report for the CPDC Challenge 2025", "comment": null, "summary": "This report presents the solution and results of our team MSRA\\_SC in the Commonsense Persona-Grounded Dialogue Challenge (CPDC 2025). We propose a simple yet effective framework that unifies improvements across both GPU Track and API Track. Our method centers on two key components. First, Context Engineering applies dynamic tool pruning and persona clipping for input compression, combined with post-processing techniques such as parameter normalization and function merging. Together with manually refined prompts, this design improves tool call stability, execution reliability, and role-playing guidance. Second, in the GPU Track, we further adopt GRPO training, replacing supervised fine-tuning with reinforcement learning directly optimized by reward signals. This mitigates small-sample overfitting and significantly enhances task-oriented dialogue performance. In the final evaluation, our team ranks 1st in Task 2 API, 2nd in Task 1 API, and 3rd in both Task 3 API and GPU track, demonstrating the effectiveness of our approach. Our code is publicly available at https://gitlab.aicrowd.com/nikoo_yu/cpdc-2025-winning-solution", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u6709\u6548\u7684\u6846\u67b6\uff0c\u5728CPDC 2025\u6311\u6218\u8d5b\u4e2d\u53d6\u5f97\u4f18\u5f02\u6210\u7ee9\uff0c\u5305\u62ecAPI Track\u7b2c\u4e00\u540d\u548cGPU Track\u7b2c\u4e09\u540d\u3002", "motivation": "\u89e3\u51b3\u5de5\u5177\u8c03\u7528\u7a33\u5b9a\u6027\u3001\u6267\u884c\u53ef\u9760\u6027\u548c\u89d2\u8272\u626e\u6f14\u6307\u5bfc\u7684\u95ee\u9898\uff0c\u540c\u65f6\u7f13\u89e3\u5c0f\u6837\u672c\u8fc7\u62df\u5408\u3002", "method": "\u4e0a\u4e0b\u6587\u5de5\u7a0b\uff08\u52a8\u6001\u5de5\u5177\u526a\u679d\u3001\u89d2\u8272\u526a\u88c1\u3001\u53c2\u6570\u5f52\u4e00\u5316\u3001\u51fd\u6570\u5408\u5e76\uff09\u548cGRPO\u8bad\u7ec3\uff08\u7528\u5f3a\u5316\u5b66\u4e60\u66ff\u4ee3\u76d1\u7763\u5fae\u8c03\uff09\u3002", "result": "\u5728\u6700\u7ec8\u8bc4\u4f30\u4e2d\uff0cTask 2 API\u6392\u540d\u7b2c\u4e00\uff0cTask 1 API\u6392\u540d\u7b2c\u4e8c\uff0cTask 3 API\u548cGPU Track\u5747\u6392\u540d\u7b2c\u4e09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5e38\u8bc6\u4eba\u7269\u63a5\u5730\u5bf9\u8bdd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.20492", "categories": ["cs.RO", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.20492", "abs": "https://arxiv.org/abs/2511.20492", "authors": ["Cyrill P\u00fcntener", "Johann Schwabe", "Dominique Garmier", "Jonas Frey", "Marco Hutter"], "title": "Kleinkram: Open Robotic Data Management", "comment": "for associated source code, see https://github.com/leggedrobotics/kleinkram", "summary": "We introduce Kleinkram, a free and open-source system designed to solve the challenge of managing massive, unstructured robotic datasets. Designed as a modular, on-premises cloud solution, Kleinkram enables scalable storage, indexing, and sharing of datasets, ranging from individual experiments to large-scale research collections. Kleinkram natively integrates with standard formats such as ROS bags and MCAP and utilises S3-compatible storage for flexibility. Beyond storage, Kleinkram features an integrated \"Action Runner\" that executes customizable Docker-based workflows for data validation, curation, and benchmarking. Kleinkram has successfully managed over 30 TB of data from diverse robotic systems, streamlining the research lifecycle through a modern web interface and a robust Command Line Interface (CLI).", "AI": {"tldr": "Kleinkram\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u673a\u5668\u4eba\u6570\u636e\u96c6\u7ba1\u7406\u7cfb\u7edf\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u5b58\u50a8\u3001\u7d22\u5f15\u548c\u5171\u4eab\u529f\u80fd\uff0c\u652f\u6301ROS bags\u548cMCAP\u7b49\u6807\u51c6\u683c\u5f0f\uff0c\u5e76\u5305\u542b\u57fa\u4e8eDocker\u7684\u5de5\u4f5c\u6d41\u6267\u884c\u5668\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u3001\u975e\u7ed3\u6784\u5316\u673a\u5668\u4eba\u6570\u636e\u96c6\u7684\u7ba1\u7406\u6311\u6218\uff0c\u652f\u6301\u4ece\u5355\u4e2a\u5b9e\u9a8c\u5230\u5927\u89c4\u6a21\u7814\u7a76\u6570\u636e\u96c6\u7684\u5b58\u50a8\u548c\u5171\u4eab\u9700\u6c42\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u7684\u672c\u5730\u4e91\u89e3\u51b3\u65b9\u6848\uff0c\u96c6\u6210S3\u517c\u5bb9\u5b58\u50a8\uff0c\u652f\u6301\u6807\u51c6\u6570\u636e\u683c\u5f0f\uff0c\u5e76\u5185\u7f6e\u57fa\u4e8eDocker\u7684Action Runner\u6267\u884c\u81ea\u5b9a\u4e49\u5de5\u4f5c\u6d41\u3002", "result": "\u5df2\u6210\u529f\u7ba1\u7406\u8d85\u8fc730TB\u6765\u81ea\u4e0d\u540c\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u6570\u636e\uff0c\u901a\u8fc7\u73b0\u4ee3Web\u754c\u9762\u548cCLI\u7b80\u5316\u4e86\u7814\u7a76\u751f\u547d\u5468\u671f\u3002", "conclusion": "Kleinkram\u4e3a\u673a\u5668\u4eba\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u6570\u636e\u96c6\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u6570\u636e\u9a8c\u8bc1\u3001\u6574\u7406\u548c\u57fa\u51c6\u6d4b\u8bd5\u7b49\u4efb\u52a1\u3002"}}
{"id": "2511.20216", "categories": ["cs.AI", "cs.CE", "cs.CV", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20216", "abs": "https://arxiv.org/abs/2511.20216", "authors": ["Haebin Seong", "Sungmin Kim", "Minchan Kim", "Yongjun Cho", "Myunchul Joe", "Suhwan Choi", "Jaeyoon Jung", "Jiyong Youn", "Yoonshik Kim", "Samwoo Seong", "Yubeen Park", "Youngjae Yu", "Yunsung Lee"], "title": "CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents", "comment": null, "summary": "Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \\emph{CostNav}, a \\textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \\textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\\% SLA compliance but is \\emph{not} commercially viable: yielding a loss of \\$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.", "AI": {"tldr": "CostNav\u662f\u9996\u4e2a\u8bc4\u4f30\u81ea\u4e3b\u9001\u8d27\u673a\u5668\u4eba\u5546\u4e1a\u53ef\u884c\u6027\u7684\u5fae\u89c2\u5bfc\u822a\u7ecf\u6d4e\u6d4b\u8bd5\u5e73\u53f0\uff0c\u901a\u8fc7\u6210\u672c\u6536\u76ca\u5206\u6790\u63ed\u793a\u5bfc\u822a\u7814\u7a76\u6307\u6807\u4e0e\u5546\u4e1a\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u5bfc\u822a\u57fa\u51c6\u53ea\u5173\u6ce8\u4efb\u52a1\u6210\u529f\u7387\uff0c\u5ffd\u7565\u4e86\u7ecf\u6d4e\u53ef\u884c\u6027\u8fd9\u4e00\u5bf9\u5546\u4e1a\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u7684\u56e0\u7d20\u3002", "method": "CostNav\u5efa\u6a21\u5b8c\u6574\u7684\u7ecf\u6d4e\u751f\u547d\u5468\u671f\uff0c\u5305\u62ec\u786c\u4ef6\u3001\u8bad\u7ec3\u3001\u80fd\u6e90\u3001\u7ef4\u62a4\u6210\u672c\u548c\u914d\u9001\u6536\u5165\uff0c\u4f7f\u7528\u884c\u4e1a\u53c2\u6570\u8fdb\u884c\u6210\u672c\u6536\u76ca\u5206\u6790\u3002", "result": "\u57fa\u51c6\u6a21\u578b\u8fbe\u523043.0%\u7684\u670d\u52a1\u6c34\u5e73\u534f\u8bae\u5408\u89c4\u7387\uff0c\u4f46\u4e0d\u53ef\u884c\uff1a\u6bcf\u6b21\u8fd0\u884c\u4e8f\u635f30.009\u7f8e\u5143\uff0c\u7ef4\u62a4\u6210\u672c\u536099.7%\uff0c\u4e3b\u8981\u6765\u81ea\u78b0\u649e\u3002", "conclusion": "CostNav\u586b\u8865\u4e86\u5bfc\u822a\u7814\u7a76\u4e0e\u5546\u4e1a\u90e8\u7f72\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u8bc4\u4f30\u57fa\u4e8e\u89c4\u5219\u7684\u5bfc\u822a\u3001\u6a21\u4eff\u5b66\u4e60\u548c\u6210\u672c\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.20496", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20496", "abs": "https://arxiv.org/abs/2511.20496", "authors": ["Jiaxin Liu", "Min Li", "Wanting Xu", "Liang Li", "Jiaqi Yang", "Laurent Kneip"], "title": "Metric, inertially aligned monocular state estimation via kinetodynamic priors", "comment": null, "summary": "Accurate state estimation for flexible robotic systems poses significant challenges, particular for platforms with dynamically deforming structures that invalidate rigid-body assumptions. This paper tackles this problem and allows to extend existing rigid-body pose estimation methods to non-rigid systems. Our approach hinges on two core assumptions: first, the elastic properties are captured by an injective deformation-force model, efficiently learned via a Multi-Layer Perceptron; second, we solve the platform's inherently smooth motion using continuous-time B-spline kinematic models. By continuously applying Newton's Second Law, our method establishes a physical link between visually-derived trajectory acceleration and predicted deformation-induced acceleration. We demonstrate that our approach not only enables robust and accurate pose estimation on non-rigid platforms, but that the properly modeled platform physics instigate inertial sensing properties. We demonstrate this feasibility on a simple spring-camera system, and show how it robustly resolves the typically ill-posed problem of metric scale and gravity recovery in monocular visual odometry.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u73b0\u6709\u521a\u4f53\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u6269\u5c55\u5230\u975e\u521a\u6027\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u53ef\u5b66\u4e60\u7684\u53d8\u5f62-\u529b\u6a21\u578b\u548c\u8fde\u7eed\u65f6\u95f4B\u6837\u6761\u8fd0\u52a8\u6a21\u578b\uff0c\u5728\u67d4\u6027\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u51c6\u786e\u7684\u72b6\u6001\u4f30\u8ba1\u3002", "motivation": "\u67d4\u6027\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u52a8\u6001\u53d8\u5f62\u7ed3\u6784\u4f7f\u521a\u4f53\u5047\u8bbe\u5931\u6548\uff0c\u7ed9\u51c6\u786e\u72b6\u6001\u4f30\u8ba1\u5e26\u6765\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u975e\u521a\u6027\u7cfb\u7edf\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u673a\u5b66\u4e60\u6ce8\u5165\u5f0f\u53d8\u5f62-\u529b\u6a21\u578b\uff0c\u7ed3\u5408\u8fde\u7eed\u65f6\u95f4B\u6837\u6761\u8fd0\u52a8\u6a21\u578b\uff0c\u901a\u8fc7\u8fde\u7eed\u5e94\u7528\u725b\u987f\u7b2c\u4e8c\u5b9a\u5f8b\u5efa\u7acb\u89c6\u89c9\u8f68\u8ff9\u52a0\u901f\u5ea6\u4e0e\u53d8\u5f62\u8bf1\u5bfc\u52a0\u901f\u5ea6\u4e4b\u95f4\u7684\u7269\u7406\u8054\u7cfb\u3002", "result": "\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u5728\u975e\u521a\u6027\u5e73\u53f0\u4e0a\u5b9e\u73b0\u9c81\u68d2\u51c6\u786e\u7684\u59ff\u6001\u4f30\u8ba1\uff0c\u8fd8\u80fd\u901a\u8fc7\u6b63\u786e\u5efa\u6a21\u7684\u5e73\u53f0\u7269\u7406\u7279\u6027\u6fc0\u53d1\u60ef\u6027\u4f20\u611f\u7279\u6027\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5355\u76ee\u89c6\u89c9\u91cc\u7a0b\u8ba1\u4e2d\u5ea6\u91cf\u5c3a\u5ea6\u548c\u91cd\u529b\u6062\u590d\u7684\u5178\u578b\u4e0d\u9002\u5b9a\u95ee\u9898\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u6269\u5c55\u4e86\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u7684\u5e94\u7528\u8303\u56f4\uff0c\u4e3a\u67d4\u6027\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u72b6\u6001\u4f30\u8ba1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5728\u7b80\u5355\u5f39\u7c27-\u76f8\u673a\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\u3002"}}
{"id": "2511.20236", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20236", "abs": "https://arxiv.org/abs/2511.20236", "authors": ["Szymon Bobek", "\u0141ukasz Ba\u0142ec", "Grzegorz J. Nalepa"], "title": "Actionable and diverse counterfactual explanations incorporating domain knowledge and causal constraints", "comment": null, "summary": "Counterfactual explanations enhance the actionable interpretability of machine learning models by identifying the minimal changes required to achieve a desired outcome of the model. However, existing methods often ignore the complex dependencies in real-world datasets, leading to unrealistic or impractical modifications. Motivated by cybersecurity applications in the email marketing domain, we propose a method for generating Diverse, Actionable, and kNowledge-Constrained Explanations (DANCE), which incorporates feature dependencies and causal constraints to ensure plausibility and real-world feasibility of counterfactuals. Our method learns linear and nonlinear constraints from data or integrates expert-provided dependency graphs, ensuring counterfactuals are plausible and actionable. By maintaining consistency with feature relationships, the method produces explanations that align with real-world constraints. Additionally, it balances plausibility, diversity, and sparsity, effectively addressing key limitations in existing algorithms. The work is developed based on a real-life case study with Freshmail, the largest email marketing company in Poland and supported by a joint R&D project Sendguard. Furthermore, we provide an extensive evaluation using 140 public datasets, which highlights its ability to generate meaningful, domain-relevant counterfactuals that outperform other existing approaches based on widely used metrics. The source code for reproduction of the results can be found in a GitHub repository we provide.", "AI": {"tldr": "\u63d0\u51faDANCE\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u7279\u5f81\u4f9d\u8d56\u5173\u7cfb\u548c\u56e0\u679c\u7ea6\u675f\u6765\u751f\u6210\u591a\u6837\u5316\u3001\u53ef\u64cd\u4f5c\u4e14\u7b26\u5408\u77e5\u8bc6\u7ea6\u675f\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u786e\u4fdd\u53cd\u4e8b\u5b9e\u7684\u5408\u7406\u6027\u548c\u73b0\u5b9e\u53ef\u884c\u6027\u3002", "motivation": "\u73b0\u6709\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\u5f80\u5f80\u5ffd\u7565\u771f\u5b9e\u6570\u636e\u96c6\u4e2d\u7684\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\uff0c\u5bfc\u81f4\u4ea7\u751f\u4e0d\u73b0\u5b9e\u6216\u4e0d\u5207\u5b9e\u9645\u7684\u4fee\u6539\u3002\u53d7\u7f51\u7edc\u5b89\u5168\u5728\u7535\u5b50\u90ae\u4ef6\u8425\u9500\u9886\u57df\u5e94\u7528\u7684\u542f\u53d1\uff0c\u9700\u8981\u786e\u4fdd\u53cd\u4e8b\u5b9e\u7684\u5408\u7406\u6027\u548c\u73b0\u5b9e\u53ef\u884c\u6027\u3002", "method": "\u63d0\u51faDANCE\u65b9\u6cd5\uff0c\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u7ea6\u675f\uff0c\u6216\u6574\u5408\u4e13\u5bb6\u63d0\u4f9b\u7684\u4f9d\u8d56\u56fe\uff0c\u786e\u4fdd\u53cd\u4e8b\u5b9e\u5408\u7406\u4e14\u53ef\u64cd\u4f5c\u3002\u901a\u8fc7\u4fdd\u6301\u4e0e\u7279\u5f81\u5173\u7cfb\u7684\u4e00\u81f4\u6027\uff0c\u751f\u6210\u7b26\u5408\u73b0\u5b9e\u7ea6\u675f\u7684\u89e3\u91ca\u3002", "result": "\u5728140\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u6709\u610f\u4e49\u3001\u9886\u57df\u76f8\u5173\u7684\u53cd\u4e8b\u5b9e\uff0c\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u6307\u6807\u4e0a\u4f18\u4e8e\u5176\u4ed6\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DANCE\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u7b97\u6cd5\u5728\u5408\u7406\u6027\u3001\u591a\u6837\u6027\u548c\u7a00\u758f\u6027\u65b9\u9762\u7684\u5173\u952e\u9650\u5236\uff0c\u4e3a\u53cd\u4e8b\u5b9e\u89e3\u91ca\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20570", "categories": ["cs.RO", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20570", "abs": "https://arxiv.org/abs/2511.20570", "authors": ["Tasha Kim", "Oiwi Parker Jones"], "title": "Gated Uncertainty-Aware Runtime Dual Invariants for Neural Signal-Controlled Robotics", "comment": "Embodied and Safe-Assured Robotic Systems workshop at NeurIPS 2025", "summary": "Safety-critical assistive systems that directly decode user intent from neural signals require rigorous guarantees of reliability and trust. We present GUARDIAN (Gated Uncertainty-Aware Runtime Dual Invariants), a framework for real-time neuro-symbolic verification for neural signal-controlled robotics. GUARDIAN enforces both logical safety and physiological trust by coupling confidence-calibrated brain signal decoding with symbolic goal grounding and dual-layer runtime monitoring. On the BNCI2014 motor imagery electroencephalogram (EEG) dataset with 9 subjects and 5,184 trials, the system performs at a high safety rate of 94-97% even with lightweight decoder architectures with low test accuracies (27-46%) and high ECE confidence miscalibration (0.22-0.41). We demonstrate 1.7x correct interventions in simulated noise testing versus at baseline. The monitor operates at 100Hz and sub-millisecond decision latency, making it practically viable for closed-loop neural signal-based systems. Across 21 ablation results, GUARDIAN exhibits a graduated response to signal degradation, and produces auditable traces from intent, plan to action, helping to link neural evidence to verifiable robot action.", "AI": {"tldr": "GUARDIAN\u662f\u4e00\u4e2a\u5b9e\u65f6\u795e\u7ecf\u7b26\u53f7\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u7f6e\u4fe1\u5ea6\u6821\u51c6\u7684\u8111\u4fe1\u53f7\u89e3\u7801\u548c\u7b26\u53f7\u76ee\u6807\u57fa\u7840\uff0c\u4e3a\u795e\u7ecf\u4fe1\u53f7\u63a7\u5236\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u903b\u8f91\u5b89\u5168\u548c\u751f\u7406\u4fe1\u4efb\u4fdd\u969c\u3002", "motivation": "\u5b89\u5168\u5173\u952e\u7684\u8f85\u52a9\u7cfb\u7edf\u9700\u8981\u4ece\u795e\u7ecf\u4fe1\u53f7\u76f4\u63a5\u89e3\u7801\u7528\u6237\u610f\u56fe\uff0c\u8fd9\u8981\u6c42\u4e25\u683c\u7684\u53ef\u9760\u6027\u548c\u4fe1\u4efb\u4fdd\u8bc1\u3002", "method": "\u91c7\u7528\u53cc\u5c42\u7ea7\u8fd0\u884c\u65f6\u76d1\u63a7\uff0c\u7ed3\u5408\u7f6e\u4fe1\u5ea6\u6821\u51c6\u7684\u8111\u4fe1\u53f7\u89e3\u7801\u4e0e\u7b26\u53f7\u76ee\u6807\u57fa\u7840\uff0c\u5728BNCI2014\u8fd0\u52a8\u60f3\u8c61EEG\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u7cfb\u7edf\u5728\u8f7b\u91cf\u7ea7\u89e3\u7801\u5668\u67b6\u6784\u4e0b\u8fbe\u523094-97%\u7684\u5b89\u5168\u7387\uff0c\u5728\u6a21\u62df\u566a\u58f0\u6d4b\u8bd5\u4e2d\u5b9e\u73b01.7\u500d\u7684\u6b63\u786e\u5e72\u9884\uff0c\u76d1\u63a7\u5668\u4ee5100Hz\u9891\u7387\u548c\u4e9a\u6beb\u79d2\u5ef6\u8fdf\u8fd0\u884c\u3002", "conclusion": "GUARDIAN\u6846\u67b6\u80fd\u591f\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u5b89\u5168\u4fdd\u969c\uff0c\u4ea7\u751f\u4ece\u610f\u56fe\u5230\u884c\u52a8\u7684\u53ef\u5ba1\u8ba1\u8ffd\u8e2a\uff0c\u5c06\u795e\u7ecf\u8bc1\u636e\u4e0e\u53ef\u9a8c\u8bc1\u7684\u673a\u5668\u4eba\u884c\u52a8\u8054\u7cfb\u8d77\u6765\u3002"}}
{"id": "2511.20285", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20285", "abs": "https://arxiv.org/abs/2511.20285", "authors": ["Mingyu Jeon", "Jaeyoung Suh", "Suwan Cho"], "title": "SMoG: Schema Matching on Graph", "comment": null, "summary": "Schema matching is a critical task in data integration, particularly in the medical domain where disparate Electronic Health Record (EHR) systems must be aligned to standard models like OMOP CDM. While Large Language Models (LLMs) have shown promise in schema matching, they suffer from hallucination and lack of up-to-date domain knowledge. Knowledge Graphs (KGs) offer a solution by providing structured, verifiable knowledge. However, existing KG-augmented LLM approaches often rely on inefficient complex multi-hop queries or storage-intensive vector-based retrieval methods. This paper introduces SMoG (Schema Matching on Graph), a novel framework that leverages iterative execution of simple 1-hop SPARQL queries, inspired by successful strategies in Knowledge Graph Question Answering (KGQA). SMoG enhances explainability and reliability by generating human-verifiable query paths while significantly reducing storage requirements by directly querying SPARQL endpoints. Experimental results on real-world medical datasets demonstrate that SMoG achieves performance comparable to state-of-the-art baselines, validating its effectiveness and efficiency in KG-augmented schema matching.", "AI": {"tldr": "SMoG\u6846\u67b6\u4f7f\u7528\u7b80\u5355\u76841\u8df3SPARQL\u67e5\u8be2\u8fdb\u884c\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u7684\u6a21\u5f0f\u5339\u914d\uff0c\u5728\u533b\u7597\u6570\u636e\u96c6\u6210\u4e2d\u5b9e\u73b0\u9ad8\u6027\u80fd\u3001\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u4f4e\u5b58\u50a8\u9700\u6c42", "motivation": "\u89e3\u51b3LLM\u5728\u6a21\u5f0f\u5339\u914d\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u548c\u7f3a\u4e4f\u6700\u65b0\u9886\u57df\u77e5\u8bc6\u7684\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u73b0\u6709KG\u589e\u5f3a\u65b9\u6cd5\u7684\u590d\u6742\u591a\u8df3\u67e5\u8be2\u548c\u5b58\u50a8\u5bc6\u96c6\u578b\u68c0\u7d22", "method": "\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u7684\u6210\u529f\u7b56\u7565\uff0c\u4f7f\u7528\u8fed\u4ee3\u6267\u884c\u7684\u7b80\u53551\u8df3SPARQL\u67e5\u8be2\uff0c\u76f4\u63a5\u67e5\u8be2SPARQL\u7aef\u70b9", "result": "\u5728\u771f\u5b9e\u533b\u7597\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e0e\u6700\u5148\u8fdb\u57fa\u7ebf\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027", "conclusion": "SMoG\u5728\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u7684\u6a21\u5f0f\u5339\u914d\u4e2d\u6709\u6548\u4e14\u9ad8\u6548\uff0c\u7279\u522b\u9002\u7528\u4e8e\u533b\u7597\u9886\u57df\u7684OMOP CDM\u5bf9\u9f50\u4efb\u52a1"}}
{"id": "2511.20297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20297", "abs": "https://arxiv.org/abs/2511.20297", "authors": ["Shashank Kirtania", "Param Biyani", "Priyanshu Gupta", "Yasharth Bajpai", "Roshni Iyer", "Sumit Gulwani", "Gustavo Soares"], "title": "Improving Language Agents through BREW", "comment": null, "summary": "Large Language Model (LLM)-based agents are increasingly applied to tasks requiring structured reasoning, tool use, and environmental adaptation, such as data manipulation, multistep planning, and computer-use automation. However, despite their versatility, current training paradigms for model weight optimization methods, like PPO and GRPO, remain relatively impractical with their high computational overhead for rollout convergence. In addition, the resulting agent policies are difficult to interpret, adapt, or incrementally improve. To address this, we investigate creating and refining structured memory of experiential learning of an agent from its environment as an alternative route to agent optimization. We introduce BREW (Bootstrapping expeRientially-learned Environmental knoWledge), a framework for agent optimization for downstream tasks via KB construction and refinement. In our formulation, we introduce an effective method for partitioning agent memory for more efficient retrieval and refinement. BREW uses task graders and behavior rubrics to learn insights while leveraging state-space search for ensuring robustness from the noise and non-specificity in natural language. Empirical results on real world, domain-grounded benchmarks -- OSWorld, $\u03c4^2$Bench, and SpreadsheetBench -- show BREW achieves $10-20\\%$ improvement in task precision, $10-15\\%$ reduction in API/tool calls leading to faster execution time, all while maintaining computational efficiency on par with base models. Unlike prior work where memory is treated as static context, we establish the KB as a modular and controllable substrate for agent optimization -- an explicit lever for shaping behavior in a transparent, interpretable, and extensible manner.", "AI": {"tldr": "BREW\u6846\u67b6\u901a\u8fc7\u6784\u5efa\u548c\u4f18\u5316\u7ecf\u9a8c\u77e5\u8bc6\u5e93\u6765\u6539\u8fdbLLM\u667a\u80fd\u4f53\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u4efb\u52a1\u7cbe\u5ea610-20%\uff0c\u51cf\u5c11API\u8c03\u752810-15%\uff0c\u5b9e\u73b0\u66f4\u900f\u660e\u53ef\u63a7\u7684\u667a\u80fd\u4f53\u4f18\u5316\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8ePPO\u548cGRPO\u7684\u667a\u80fd\u4f53\u8bad\u7ec3\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u6536\u655b\u56f0\u96be\uff0c\u4e14\u751f\u6210\u7684\u7b56\u7565\u96be\u4ee5\u89e3\u91ca\u3001\u9002\u5e94\u6216\u589e\u91cf\u6539\u8fdb\u3002\u9700\u8981\u4e00\u79cd\u66f4\u5b9e\u7528\u3001\u53ef\u89e3\u91ca\u7684\u667a\u80fd\u4f53\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51faBREW\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u548c\u4f18\u5316\u7ecf\u9a8c\u77e5\u8bc6\u5e93\u6765\u4f18\u5316\u667a\u80fd\u4f53\u3002\u5f15\u5165\u6709\u6548\u7684\u8bb0\u5fc6\u5206\u533a\u65b9\u6cd5\u63d0\u9ad8\u68c0\u7d22\u548c\u4f18\u5316\u6548\u7387\uff0c\u4f7f\u7528\u4efb\u52a1\u8bc4\u5206\u5668\u548c\u884c\u4e3a\u51c6\u5219\u5b66\u4e60\u6d1e\u5bdf\uff0c\u5229\u7528\u72b6\u6001\u7a7a\u95f4\u641c\u7d22\u786e\u4fdd\u9c81\u68d2\u6027\u3002", "result": "\u5728OSWorld\u3001\u03c4\u00b2Bench\u548cSpreadsheetBench\u7b49\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBREW\u5b9e\u73b0\u4e8610-20%\u7684\u4efb\u52a1\u7cbe\u5ea6\u63d0\u5347\uff0c10-15%\u7684API/\u5de5\u5177\u8c03\u7528\u51cf\u5c11\uff0c\u6267\u884c\u65f6\u95f4\u66f4\u5feb\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u57fa\u7840\u6a21\u578b\u76f8\u5f53\u7684\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u4e0e\u5c06\u8bb0\u5fc6\u89c6\u4e3a\u9759\u6001\u4e0a\u4e0b\u6587\u7684\u5148\u524d\u5de5\u4f5c\u4e0d\u540c\uff0cBREW\u5c06\u77e5\u8bc6\u5e93\u5efa\u7acb\u4e3a\u6a21\u5757\u5316\u548c\u53ef\u63a7\u7684\u667a\u80fd\u4f53\u4f18\u5316\u57fa\u7840\u2014\u2014\u4e00\u4e2a\u7528\u4e8e\u4ee5\u900f\u660e\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6269\u5c55\u65b9\u5f0f\u5851\u9020\u884c\u4e3a\u7684\u660e\u786e\u6760\u6746\u3002"}}
{"id": "2511.20633", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20633", "abs": "https://arxiv.org/abs/2511.20633", "authors": ["Jiahui Zhang", "Ze Huang", "Chun Gu", "Zipei Ma", "Li Zhang"], "title": "Reinforcing Action Policies by Prophesying", "comment": "https://LogosRoboticsGroup.github.io/ProphRL", "summary": "Vision-Language-Action (VLA) policies excel in aligning language, perception, and robot control. However, most VLAs are trained purely by imitation, which overfits to demonstrations, and is brittle under distribution shift. Reinforcement learning (RL) directly optimizes task reward and thus addresses this misalignment, but real-robot interaction is expensive and conventional simulators are hard to engineer and transfer. We address both data efficiency and optimization stability in VLA post-training via a learned world model and an RL procedure tailored to flow-based action heads. Specifically, we introduce Prophet, a unified action-to-video robot actuation pretrained across large-scale, heterogeneous robot data to learn reusable action-outcome dynamics. It is able to few-shot adapt to new robots, objects, and environments, yielding a rollout-ready simulator. Upon Prophet, we reinforce action policies with Flow-action-GRPO (FA-GRPO), which adapts Flow-GRPO to operate on VLA actions, and with FlowScale, a stepwise reweighting that rescales per-step gradients in the flow head. Together, Prophet, FA-GRPO, and FlowScale constitute ProphRL, a practical, data- and compute-efficient path to VLA post-training. Experiments show 5-17% success gains on public benchmarks and 24-30% gains on real robots across different VLA variants.", "AI": {"tldr": "ProphRL\u901a\u8fc7\u7ed3\u5408\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578bProphet\u548c\u4e13\u95e8\u9488\u5bf9\u6d41\u5f0f\u52a8\u4f5c\u5934\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5FA-GRPO\uff0c\u89e3\u51b3\u4e86VLA\u7b56\u7565\u5728\u6a21\u4eff\u5b66\u4e60\u4e2d\u5b58\u5728\u7684\u8fc7\u62df\u5408\u548c\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6570\u636e\u9ad8\u6548\u548c\u4f18\u5316\u7a33\u5b9a\u7684VLA\u540e\u8bad\u7ec3\u3002", "motivation": "\u5927\u591a\u6570VLA\u7b56\u7565\u4ec5\u901a\u8fc7\u6a21\u4eff\u5b66\u4e60\u8bad\u7ec3\uff0c\u5bb9\u6613\u8fc7\u62df\u5408\u6f14\u793a\u6570\u636e\u4e14\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u8868\u73b0\u8106\u5f31\u3002\u5f3a\u5316\u5b66\u4e60\u80fd\u76f4\u63a5\u4f18\u5316\u4efb\u52a1\u5956\u52b1\u4f46\u771f\u5b9e\u673a\u5668\u4eba\u4ea4\u4e92\u6210\u672c\u9ad8\uff0c\u4f20\u7edf\u6a21\u62df\u5668\u96be\u4ee5\u6784\u5efa\u548c\u8fc1\u79fb\u3002", "method": "\u63d0\u51faProphet\u4f5c\u4e3a\u7edf\u4e00\u52a8\u4f5c\u5230\u89c6\u9891\u7684\u673a\u5668\u4eba\u9a71\u52a8\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5b66\u4e60\u53ef\u91cd\u7528\u7684\u52a8\u4f5c-\u7ed3\u679c\u52a8\u6001\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\u4f7f\u7528FA-GRPO\u5f3a\u5316\u52a8\u4f5c\u7b56\u7565\uff0c\u7ed3\u5408FlowScale\u8fdb\u884c\u68af\u5ea6\u91cd\u7f29\u653e\u3002", "result": "\u5728\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u83b7\u5f975-17%\u7684\u6210\u529f\u7387\u63d0\u5347\uff0c\u5728\u771f\u5b9e\u673a\u5668\u4eba\u4e0a\u83b7\u5f9724-30%\u7684\u63d0\u5347\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u7684VLA\u53d8\u4f53\u3002", "conclusion": "ProphRL\u4e3aVLA\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u3001\u6570\u636e\u548c\u8ba1\u7b97\u9ad8\u6548\u7684\u9053\u8def\uff0c\u663e\u8457\u63d0\u5347\u4e86VLA\u7b56\u7565\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6027\u80fd\u3002"}}
{"id": "2511.20312", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20312", "abs": "https://arxiv.org/abs/2511.20312", "authors": ["Alexander Beiser", "Flavio Martinelli", "Wulfram Gerstner", "Johanni Brea"], "title": "Data Augmentation Techniques to Reverse-Engineer Neural Network Weights from Input-Output Queries", "comment": "Proceedings of the III edition of the Workshop on Unifying Representations in Neural Models (UniReps 2025)", "summary": "Network weights can be reverse-engineered given enough informative samples of a network's input-output function. In a teacher-student setup, this translates into collecting a dataset of the teacher mapping -- querying the teacher -- and fitting a student to imitate such mapping. A sensible choice of queries is the dataset the teacher is trained on. But current methods fail when the teacher parameters are more numerous than the training data, because the student overfits to the queries instead of aligning its parameters to the teacher. In this work, we explore augmentation techniques to best sample the input-output mapping of a teacher network, with the goal of eliciting a rich set of representations from the teacher hidden layers. We discover that standard augmentations such as rotation, flipping, and adding noise, bring little to no improvement to the identification problem. We design new data augmentation techniques tailored to better sample the representational space of the network's hidden layers. With our augmentations we extend the state-of-the-art range of recoverable network sizes. To test their scalability, we show that we can recover networks of up to 100 times more parameters than training data-points.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\u6765\u6539\u8fdb\u6559\u5e08\u7f51\u7edc\u53c2\u6570\u7684\u53cd\u5411\u5de5\u7a0b\uff0c\u80fd\u591f\u6062\u590d\u53c2\u6570\u6570\u91cf\u662f\u8bad\u7ec3\u6570\u636e100\u500d\u7684\u7f51\u7edc\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6559\u5e08\u7f51\u7edc\u53c2\u6570\u591a\u4e8e\u8bad\u7ec3\u6570\u636e\u65f6\u4f1a\u5931\u8d25\uff0c\u56e0\u4e3a\u5b66\u751f\u4f1a\u8fc7\u5ea6\u62df\u5408\u67e5\u8be2\u6570\u636e\u800c\u4e0d\u662f\u5bf9\u9f50\u6559\u5e08\u53c2\u6570\u3002\u9700\u8981\u66f4\u597d\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\u6765\u5145\u5206\u91c7\u6837\u6559\u5e08\u7f51\u7edc\u7684\u8f93\u5165-\u8f93\u51fa\u6620\u5c04\u3002", "method": "\u8bbe\u8ba1\u4e13\u95e8\u9488\u5bf9\u7f51\u7edc\u9690\u85cf\u5c42\u8868\u793a\u7a7a\u95f4\u91c7\u6837\u7684\u65b0\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u800c\u4e0d\u662f\u4f7f\u7528\u6807\u51c6\u589e\u5f3a\u65b9\u6cd5\u5982\u65cb\u8f6c\u3001\u7ffb\u8f6c\u548c\u6dfb\u52a0\u566a\u58f0\u3002", "result": "\u65b0\u589e\u5f3a\u6280\u672f\u6269\u5c55\u4e86\u53ef\u6062\u590d\u7f51\u7edc\u5927\u5c0f\u7684\u6700\u5148\u8fdb\u8303\u56f4\uff0c\u80fd\u591f\u6062\u590d\u53c2\u6570\u6570\u91cf\u662f\u8bad\u7ec3\u6570\u636e100\u500d\u7684\u7f51\u7edc\u3002", "conclusion": "\u4e13\u95e8\u8bbe\u8ba1\u7684\u8868\u793a\u7a7a\u95f4\u6570\u636e\u589e\u5f3a\u6280\u672f\u663e\u8457\u6539\u8fdb\u4e86\u6559\u5e08\u7f51\u7edc\u53c2\u6570\u7684\u53cd\u5411\u5de5\u7a0b\u6548\u679c\u3002"}}
{"id": "2511.20321", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20321", "abs": "https://arxiv.org/abs/2511.20321", "authors": ["Patrick Kenny"], "title": "Active Inference in Discrete State Spaces from First Principles", "comment": "56 pages", "summary": "We seek to clarify the concept of active inference by disentangling it from the Free Energy Principle. We show how the optimizations that need to be carried out in order to implement active inference in discrete state spaces can be formulated as constrained divergence minimization problems which can be solved by standard mean field methods that do not appeal to the idea of expected free energy. When it is used to model perception, the perception/action divergence criterion that we propose coincides with variational free energy. When it is used to model action, it differs from an expected free energy functional by an entropy regularizer.", "AI": {"tldr": "\u672c\u6587\u533a\u5206\u4e86\u4e3b\u52a8\u63a8\u7406\u4e0e\u81ea\u7531\u80fd\u539f\u7406\uff0c\u63d0\u51fa\u5728\u79bb\u6563\u72b6\u6001\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u4e3b\u52a8\u63a8\u7406\u7684\u4f18\u5316\u53ef\u8868\u8ff0\u4e3a\u7ea6\u675f\u6563\u5ea6\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u53ef\u901a\u8fc7\u6807\u51c6\u5e73\u5747\u573a\u65b9\u6cd5\u6c42\u89e3\uff0c\u65e0\u9700\u4f9d\u8d56\u671f\u671b\u81ea\u7531\u80fd\u6982\u5ff5\u3002", "motivation": "\u6f84\u6e05\u4e3b\u52a8\u63a8\u7406\u6982\u5ff5\uff0c\u5c06\u5176\u4e0e\u81ea\u7531\u80fd\u539f\u7406\u5206\u79bb\u5f00\u6765\uff0c\u5c55\u793a\u4e3b\u52a8\u63a8\u7406\u5728\u79bb\u6563\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u5b9e\u73b0\u65b9\u5f0f\u3002", "method": "\u5c06\u4e3b\u52a8\u63a8\u7406\u4f18\u5316\u95ee\u9898\u8868\u8ff0\u4e3a\u7ea6\u675f\u6563\u5ea6\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u6807\u51c6\u5e73\u5747\u573a\u65b9\u6cd5\u6c42\u89e3\uff0c\u4e0d\u4f9d\u8d56\u671f\u671b\u81ea\u7531\u80fd\u6982\u5ff5\u3002", "result": "\u5728\u5efa\u6a21\u611f\u77e5\u65f6\uff0c\u63d0\u51fa\u7684\u611f\u77e5/\u884c\u52a8\u6563\u5ea6\u51c6\u5219\u4e0e\u53d8\u5206\u81ea\u7531\u80fd\u4e00\u81f4\uff1b\u5728\u5efa\u6a21\u884c\u52a8\u65f6\uff0c\u4e0e\u671f\u671b\u81ea\u7531\u80fd\u6cdb\u51fd\u76f8\u5dee\u4e00\u4e2a\u71b5\u6b63\u5219\u9879\u3002", "conclusion": "\u4e3b\u52a8\u63a8\u7406\u53ef\u4ee5\u901a\u8fc7\u7ea6\u675f\u6563\u5ea6\u6700\u5c0f\u5316\u6846\u67b6\u5b9e\u73b0\uff0c\u65e0\u9700\u8bc9\u8bf8\u671f\u671b\u81ea\u7531\u80fd\u6982\u5ff5\uff0c\u8fd9\u4e3a\u7406\u89e3\u4e3b\u52a8\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u7684\u6570\u5b66\u57fa\u7840\u3002"}}
{"id": "2511.20333", "categories": ["cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.20333", "abs": "https://arxiv.org/abs/2511.20333", "authors": ["Roman Kochnev", "Waleed Khalid", "Tolgay Atinc Uzun", "Xi Zhang", "Yashkumar Sanjaybhai Dhameliya", "Furui Qin", "Chandini Vysyaraju", "Raghuvir Duvvuri", "Avi Goyal", "Dmitry Ignatov", "Radu Timofte"], "title": "NNGPT: Rethinking AutoML with Large Language Models", "comment": null, "summary": "Building self-improving AI systems remains a fundamental challenge in the AI domain. We present NNGPT, an open-source framework that turns a large language model (LLM) into a self-improving AutoML engine for neural network development, primarily for computer vision. Unlike previous frameworks, NNGPT extends the dataset of neural networks by generating new models, enabling continuous fine-tuning of LLMs based on closed-loop system of generation, assessment, and self-improvement. It integrates within one unified workflow five synergistic LLM-based pipelines: zero-shot architecture synthesis, hyperparameter optimization (HPO), code-aware accuracy/early-stop prediction, retrieval-augmented synthesis of scope-closed PyTorch blocks (NN-RAG), and reinforcement learning. Built on the LEMUR dataset as an audited corpus with reproducible metrics, NNGPT emits from a single prompt and validates network architecture, preprocessing code, and hyperparameters, executes them end-to-end, and learns from result. The PyTorch adapter makes NNGPT framework-agnostic, enabling strong performance: NN-RAG achieves 73% executability on 1,289 targets, 3-shot prompting boosts accuracy on common datasets, and hash-based deduplication saves hundreds of runs. One-shot prediction matches search-based AutoML, reducing the need for numerous trials. HPO on LEMUR achieves RMSE 0.60, outperforming Optuna (0.64), while the code-aware predictor reaches RMSE 0.14 with Pearson r=0.78. The system has already generated over 5K validated models, proving NNGPT as an autonomous AutoML engine. Upon acceptance, the code, prompts, and checkpoints will be released for public access to enable reproducibility and facilitate community usage.", "AI": {"tldr": "NNGPT\u662f\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f6c\u5316\u4e3a\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u5f00\u53d1\u7684\u81ea\u6539\u8fdbAutoML\u5f15\u64ce\uff0c\u901a\u8fc7\u751f\u6210-\u8bc4\u4f30-\u81ea\u6539\u8fdb\u7684\u95ed\u73af\u7cfb\u7edf\u6301\u7eed\u4f18\u5316\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u6784\u5efa\u81ea\u6539\u8fdbAI\u7cfb\u7edf\u662fAI\u9886\u57df\u7684\u6839\u672c\u6311\u6218\uff0c\u73b0\u6709\u6846\u67b6\u5728\u795e\u7ecf\u7f51\u7edc\u6570\u636e\u96c6\u6269\u5c55\u548c\u6301\u7eed\u4f18\u5316\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "\u96c6\u6210\u4e94\u4e2a\u534f\u540c\u7684LLM\u7ba1\u9053\uff1a\u96f6\u6837\u672c\u67b6\u6784\u5408\u6210\u3001\u8d85\u53c2\u6570\u4f18\u5316\u3001\u4ee3\u7801\u611f\u77e5\u7cbe\u5ea6\u9884\u6d4b\u3001\u68c0\u7d22\u589e\u5f3a\u7684PyTorch\u5757\u5408\u6210\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u57fa\u4e8eLEMUR\u6570\u636e\u96c6\u6784\u5efa\u95ed\u73af\u7cfb\u7edf\u3002", "result": "NN-RAG\u57281,289\u4e2a\u76ee\u6807\u4e0a\u8fbe\u523073%\u53ef\u6267\u884c\u6027\uff0cHPO\u5728LEMUR\u4e0aRMSE\u4e3a0.60\u4f18\u4e8eOptuna\uff0c\u5df2\u751f\u6210\u8d85\u8fc75K\u9a8c\u8bc1\u6a21\u578b\u3002", "conclusion": "NNGPT\u88ab\u8bc1\u660e\u662f\u4e00\u4e2a\u81ea\u4e3b\u7684AutoML\u5f15\u64ce\uff0c\u80fd\u591f\u663e\u8457\u51cf\u5c11\u8bd5\u9a8c\u6b21\u6570\u5e76\u63d0\u5347\u6027\u80fd\uff0c\u4ee3\u7801\u5c06\u516c\u5f00\u53d1\u5e03\u4ee5\u4fc3\u8fdb\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2511.20422", "categories": ["cs.AI", "cs.CV", "cs.GR", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20422", "abs": "https://arxiv.org/abs/2511.20422", "authors": ["Bo Pang", "Chenxi Xu", "Jierui Ren", "Guoping Wang", "Sheng Li"], "title": "VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning", "comment": null, "summary": "Understanding the physical world requires perceptual models grounded in physical laws rather than mere statistical correlations. However, existing multimodal learning frameworks, focused on vision and language, lack physical consistency and overlook the intrinsic causal relationships among an object's geometry, material, vibration modes, and the sounds it produces. We introduce VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly bridges the causal chain from 3D geometry -> physical attributes -> modal parameters -> acoustic signals. Each 3D model has explicit physical properties (density, Young's modulus, Poisson's ratio) and volumetric geometry, from which modal eigenfrequencies and eigenvectors are computed for impact sound synthesis under controlled excitations. To establish this coherence, we introduce CLASP, a contrastive learning framework for cross-modal alignment that preserves the causal correspondence between an object's physical structure and its acoustic response. This framework enforces physically consistent alignment across modalities, ensuring that every sample is coherent, traceable to the governing equations, and embedded within a unified representation space spanning shape, image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks for geometry-to-sound prediction, sound-guided shape reconstruction, and cross-modal representation learning. Extensive validations on these tasks demonstrate that models trained on VibraVerse exhibit superior accuracy, interpretability, and generalization across modalities. These results establish VibraVerse as a benchmark for physically consistent and causally interpretable multimodal learning, providing a foundation for sound-guided embodied perception and a deeper understanding of the physical world. The dataset will be open-sourced.", "AI": {"tldr": "VibraVerse\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u51e0\u4f55-\u58f0\u5b66\u5bf9\u9f50\u6570\u636e\u96c6\uff0c\u901a\u8fc7CLASP\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u5efa\u7acb\u7269\u7406\u4e00\u81f4\u6027\u8de8\u6a21\u6001\u5bf9\u9f50\uff0c\u4ece3D\u51e0\u4f55\u5230\u7269\u7406\u5c5e\u6027\u518d\u5230\u58f0\u5b66\u4fe1\u53f7\u7684\u56e0\u679c\u94fe\uff0c\u4e3a\u7269\u7406\u4e00\u81f4\u7684\u591a\u6a21\u6001\u5b66\u4e60\u63d0\u4f9b\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\u7f3a\u4e4f\u7269\u7406\u4e00\u81f4\u6027\uff0c\u5ffd\u89c6\u4e86\u7269\u4f53\u51e0\u4f55\u3001\u6750\u6599\u3001\u632f\u52a8\u6a21\u5f0f\u548c\u4ea7\u751f\u58f0\u97f3\u4e4b\u95f4\u7684\u5185\u5728\u56e0\u679c\u5173\u7cfb\uff0c\u9700\u8981\u5efa\u7acb\u57fa\u4e8e\u7269\u7406\u5b9a\u5f8b\u7684\u611f\u77e5\u6a21\u578b\u3002", "method": "\u6784\u5efaVibraVerse\u6570\u636e\u96c6\uff0c\u5305\u542b3D\u6a21\u578b\u7684\u7269\u7406\u5c5e\u6027\u548c\u4f53\u79ef\u51e0\u4f55\uff0c\u8ba1\u7b97\u6a21\u6001\u7279\u5f81\u53c2\u6570\u8fdb\u884c\u51b2\u51fb\u58f0\u5408\u6210\uff1b\u63d0\u51faCLASP\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u5b9e\u73b0\u8de8\u6a21\u6001\u5bf9\u9f50\uff0c\u4fdd\u6301\u7269\u7406\u7ed3\u6784\u5230\u58f0\u5b66\u54cd\u5e94\u7684\u56e0\u679c\u5bf9\u5e94\u3002", "result": "\u5728\u51e0\u4f55\u5230\u58f0\u97f3\u9884\u6d4b\u3001\u58f0\u97f3\u5f15\u5bfc\u5f62\u72b6\u91cd\u5efa\u548c\u8de8\u6a21\u6001\u8868\u793a\u5b66\u4e60\u7b49\u57fa\u51c6\u4efb\u52a1\u4e0a\uff0c\u57fa\u4e8eVibraVerse\u8bad\u7ec3\u7684\u6a21\u578b\u5c55\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8de8\u6a21\u6001\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "VibraVerse\u4e3a\u7269\u7406\u4e00\u81f4\u548c\u56e0\u679c\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u5b66\u4e60\u5efa\u7acb\u4e86\u57fa\u51c6\uff0c\u4e3a\u58f0\u97f3\u5f15\u5bfc\u7684\u5177\u8eab\u611f\u77e5\u548c\u7269\u7406\u4e16\u754c\u7406\u89e3\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u6570\u636e\u96c6\u5c06\u5f00\u6e90\u3002"}}
{"id": "2511.20468", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20468", "abs": "https://arxiv.org/abs/2511.20468", "authors": ["Yuanhao Li", "Mingshan Liu", "Hongbo Wang", "Yiding Zhang", "Yifei Ma", "Wei Tan"], "title": "DRAFT-RL: Multi-Agent Chain-of-Draft Reasoning for Reinforcement Learning-Enhanced LLMs", "comment": null, "summary": "Large Language Models (LLMs) have shown impressive capabilities in multi-step reasoning and problem-solving.Recent works introduce multi-agent reflection frameworks where multiple LLM agents critique and refine each other's outputs using reinforcement learning (RL). However, these approaches often rely on single-shot responses and lack structural diversity in reasoning exploration. In this paper, we propose DRAFT-RL, a novel framework that integrates Chain-of-Draft (CoD) reasoning into multi-agent RL training. Instead of generating single responses, each agent produces multiple drafts per query, which are then evaluated by peer agents and a learned reward model to identify the most promising trajectory. These selected drafts are used to refine future reasoning strategies through actor-critic learning.DRAFT-RL enables explicit multi-path exploration, peer-guided reflection, and reward-aligned selection, resulting in more robust and interpretable LLM agent behavior. We evaluate our method on complex reasoning tasks including code synthesis, symbolic math, and knowledge-intensive QA,demonstrating that DRAFT-RL outperforms existing reflective and RL-based agents by significant margins in both accuracy and convergence speed", "AI": {"tldr": "DRAFT-RL\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u94fe\u5f0f\u8349\u7a3f\u63a8\u7406\u96c6\u6210\u5230\u591a\u667a\u80fd\u4f53\u8bad\u7ec3\u4e2d\uff0c\u901a\u8fc7\u751f\u6210\u591a\u4e2a\u8349\u7a3f\u3001\u540c\u884c\u8bc4\u4f30\u548c\u5956\u52b1\u6a21\u578b\u9009\u62e9\u6765\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u667a\u80fd\u4f53\u53cd\u601d\u6846\u67b6\u901a\u5e38\u4f9d\u8d56\u5355\u6b21\u54cd\u5e94\uff0c\u7f3a\u4e4f\u63a8\u7406\u63a2\u7d22\u7684\u7ed3\u6784\u591a\u6837\u6027\uff0c\u9650\u5236\u4e86LLM\u667a\u80fd\u4f53\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u6bcf\u4e2a\u667a\u80fd\u4f53\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u751f\u6210\u591a\u4e2a\u8349\u7a3f\uff0c\u7531\u540c\u884c\u667a\u80fd\u4f53\u548c\u5b66\u4e60\u7684\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\uff0c\u9009\u62e9\u6700\u6709\u524d\u666f\u7684\u8f68\u8ff9\uff0c\u901a\u8fc7actor-critic\u5b66\u4e60\u4f18\u5316\u672a\u6765\u63a8\u7406\u7b56\u7565\u3002", "result": "\u5728\u4ee3\u7801\u5408\u6210\u3001\u7b26\u53f7\u6570\u5b66\u548c\u77e5\u8bc6\u5bc6\u96c6\u578b\u95ee\u7b54\u7b49\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\uff0cDRAFT-RL\u5728\u51c6\u786e\u6027\u548c\u6536\u655b\u901f\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u53cd\u601d\u548c\u57fa\u4e8eRL\u7684\u667a\u80fd\u4f53\u3002", "conclusion": "DRAFT-RL\u901a\u8fc7\u663e\u5f0f\u591a\u8def\u5f84\u63a2\u7d22\u3001\u540c\u884c\u5f15\u5bfc\u53cd\u601d\u548c\u5956\u52b1\u5bf9\u9f50\u9009\u62e9\uff0c\u5b9e\u73b0\u4e86\u66f4\u9c81\u68d2\u548c\u53ef\u89e3\u91ca\u7684LLM\u667a\u80fd\u4f53\u884c\u4e3a\u3002"}}
{"id": "2511.20471", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20471", "abs": "https://arxiv.org/abs/2511.20471", "authors": ["Yuto Suzuki", "Farnoush Banaei-Kashani"], "title": "Universe of Thoughts: Enabling Creative Reasoning with Large Language Models", "comment": null, "summary": "Reasoning based on Large Language Models (LLMs) has garnered increasing attention due to outstanding performance of these models in mathematical and complex logical tasks. Beginning with the Chain-of-Thought (CoT) prompting technique, numerous reasoning methods have emerged that decompose problems into smaller, sequential steps (or thoughts). However, existing reasoning models focus on conventional problem-solving and do not necessarily generate creative solutions by ``creative reasoning''. In domains where the solution space is expansive and conventional solutions are suboptimal, such as drug discovery or business strategization, creative reasoning to discover innovative solutions is crucial. To address this gap, first we introduce a computational framework for creative reasoning inspired by established cognitive science principles. With this framework, we propose three core creative reasoning paradigms, namely, \\textit{combinational}, \\textit{exploratory}, and \\textit{transformative} reasoning, where each offers specific directions for systematic exploration of the universe of thoughts to generate creative solutions. Next, to materialize this framework using LLMs, we introduce the \\textit{Universe of Thoughts} (or \\textit{UoT}, for short), a novel set of methods to implement the aforementioned three creative processes. Finally, we introduce three novel tasks that necessitate creative problem-solving, along with an evaluation benchmark to assess creativity from three orthogonal perspectives: feasibility as constraint, and utility and novelty as metrics. With a comparative analysis against the state-of-the-art (SOTA) reasoning techniques as well as representative commercial models with reasoning capability, we show that UoT demonstrates superior performance in creative reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u521b\u9020\u6027\u63a8\u7406\u6846\u67b6\uff0c\u5305\u62ec\u7ec4\u5408\u5f0f\u3001\u63a2\u7d22\u5f0f\u548c\u8f6c\u5316\u5f0f\u4e09\u79cd\u6838\u5fc3\u63a8\u7406\u8303\u5f0f\uff0c\u5e76\u5f00\u53d1\u4e86\"\u601d\u60f3\u5b87\u5b99\"\u65b9\u6cd5\u6765\u5b9e\u73b0\u8fd9\u4e9b\u521b\u9020\u6027\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u5e38\u89c4\u95ee\u9898\u89e3\u51b3\uff0c\u4f46\u5728\u836f\u7269\u53d1\u73b0\u3001\u5546\u4e1a\u7b56\u7565\u7b49\u9700\u8981\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u7684\u9886\u57df\uff0c\u521b\u9020\u6027\u63a8\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u539f\u7406\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u5305\u542b\u4e09\u79cd\u521b\u9020\u6027\u63a8\u7406\u8303\u5f0f\uff0c\u5e76\u5f00\u53d1\u4e86UoT\u65b9\u6cd5\u6765\u5b9e\u73b0\u8fd9\u4e9b\u8fc7\u7a0b\u3002", "result": "\u4e0e\u6700\u5148\u8fdb\u7684\u63a8\u7406\u6280\u672f\u548c\u5546\u4e1a\u6a21\u578b\u76f8\u6bd4\uff0cUoT\u5728\u521b\u9020\u6027\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "UoT\u6846\u67b6\u4e3aLLM\u7684\u521b\u9020\u6027\u63a8\u7406\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\uff0c\u5728\u9700\u8981\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u7684\u9886\u57df\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.20497", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20497", "abs": "https://arxiv.org/abs/2511.20497", "authors": ["Van Tran", "Shinan Liu", "Tian Li", "Nick Feamster"], "title": "Quantifying the Privacy Implications of High-Fidelity Synthetic Network Traffic", "comment": "14 pages, 13 Figures, 6 Tables", "summary": "To address the scarcity and privacy concerns of network traffic data, various generative models have been developed to produce synthetic traffic. However, synthetic traffic is not inherently privacy-preserving, and the extent to which it leaks sensitive information, and how to measure such leakage, remain largely unexplored. This challenge is further compounded by the diversity of model architectures, which shape how traffic is represented and synthesized. We introduce a comprehensive set of privacy metrics for synthetic network traffic, combining standard approaches like membership inference attacks (MIA) and data extraction attacks with network-specific identifiers and attributes. Using these metrics, we systematically evaluate the vulnerability of different representative generative models and examine the factors that influence attack success. Our results reveal substantial variability in privacy risks across models and datasets. MIA success ranges from 0% to 88%, and up to 100% of network identifiers can be recovered from generated traffic, highlighting serious privacy vulnerabilities. We further identify key factors that significantly affect attack outcomes, including training data diversity and how well the generative model fits the training data. These findings provide actionable guidance for designing and deploying generative models that minimize privacy leakage, establishing a foundation for safer synthetic network traffic generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u5408\u6210\u7f51\u7edc\u6d41\u91cf\u7684\u9690\u79c1\u8bc4\u4f30\u6307\u6807\uff0c\u53d1\u73b0\u4e0d\u540c\u751f\u6210\u6a21\u578b\u5b58\u5728\u663e\u8457\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0cMIA\u653b\u51fb\u6210\u529f\u7387\u6700\u9ad8\u8fbe88%\uff0c\u7f51\u7edc\u6807\u8bc6\u7b26\u6062\u590d\u7387\u53ef\u8fbe100%\u3002", "motivation": "\u89e3\u51b3\u5408\u6210\u7f51\u7edc\u6d41\u91cf\u6570\u636e\u7a00\u7f3a\u548c\u9690\u79c1\u95ee\u9898\uff0c\u4f46\u73b0\u6709\u751f\u6210\u6a21\u578b\u4ea7\u751f\u7684\u6d41\u91cf\u5e76\u975e\u5929\u7136\u9690\u79c1\u4fdd\u62a4\uff0c\u5176\u654f\u611f\u4fe1\u606f\u6cc4\u9732\u7a0b\u5ea6\u548c\u6d4b\u91cf\u65b9\u6cd5\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u5957\u5168\u9762\u7684\u9690\u79c1\u8bc4\u4f30\u6307\u6807\uff0c\u7ed3\u5408\u6807\u51c6\u65b9\u6cd5\uff08\u5982\u6210\u5458\u63a8\u65ad\u653b\u51fbMIA\u548c\u6570\u636e\u63d0\u53d6\u653b\u51fb\uff09\u4e0e\u7f51\u7edc\u7279\u5b9a\u6807\u8bc6\u7b26\u548c\u5c5e\u6027\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u4ee3\u8868\u6027\u751f\u6210\u6a21\u578b\u7684\u8106\u5f31\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4e0d\u540c\u6a21\u578b\u548c\u6570\u636e\u96c6\u95f4\u7684\u9690\u79c1\u98ce\u9669\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0cMIA\u6210\u529f\u7387\u4ece0%\u523088%\uff0c\u7f51\u7edc\u6807\u8bc6\u7b26\u6062\u590d\u7387\u53ef\u8fbe100%\uff0c\u63ed\u793a\u4e86\u4e25\u91cd\u7684\u9690\u79c1\u6f0f\u6d1e\u3002", "conclusion": "\u8bc6\u522b\u4e86\u5f71\u54cd\u653b\u51fb\u7ed3\u679c\u7684\u5173\u952e\u56e0\u7d20\uff08\u5982\u8bad\u7ec3\u6570\u636e\u591a\u6837\u6027\u548c\u6a21\u578b\u62df\u5408\u5ea6\uff09\uff0c\u4e3a\u8bbe\u8ba1\u6700\u5c0f\u5316\u9690\u79c1\u6cc4\u9732\u7684\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u6307\u5bfc\uff0c\u5efa\u7acb\u4e86\u66f4\u5b89\u5168\u7684\u5408\u6210\u7f51\u7edc\u6d41\u91cf\u751f\u6210\u57fa\u7840\u3002"}}
{"id": "2511.20510", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20510", "abs": "https://arxiv.org/abs/2511.20510", "authors": ["Yuto Suzuki", "Paul Awolade", "Daniel V. LaBarbera", "Farnoush Banaei-Kashani"], "title": "FRAGMENTA: End-to-end Fragmentation-based Generative Model with Agentic Tuning for Drug Lead Optimization", "comment": null, "summary": "Molecule generation using generative AI is vital for drug discovery, yet class-specific datasets often contain fewer than 100 training examples. While fragment-based models handle limited data better than atom-based approaches, existing heuristic fragmentation limits diversity and misses key fragments. Additionally, model tuning typically requires slow, indirect collaboration between medicinal chemists and AI engineers. We introduce FRAGMENTA, an end-to-end framework for drug lead optimization comprising: 1) a novel generative model that reframes fragmentation as a \"vocabulary selection\" problem, using dynamic Q-learning to jointly optimize fragmentation and generation; and 2) an agentic AI system that refines objectives via conversational feedback from domain experts. This system removes the AI engineer from the loop and progressively learns domain knowledge to eventually automate tuning. In real-world cancer drug discovery experiments, FRAGMENTA's Human-Agent configuration identified nearly twice as many high-scoring molecules as baselines. Furthermore, the fully autonomous Agent-Agent system outperformed traditional Human-Human tuning, demonstrating the efficacy of agentic tuning in capturing expert intent.", "AI": {"tldr": "FRAGMENTA\u662f\u4e00\u4e2a\u7528\u4e8e\u836f\u7269\u5148\u5bfc\u5316\u5408\u7269\u4f18\u5316\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u5305\u542b\u751f\u6210\u6a21\u578b\u548c\u667a\u80fdAI\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001Q\u5b66\u4e60\u4f18\u5316\u5206\u5b50\u788e\u7247\u5316\u548c\u751f\u6210\uff0c\u5e76\u901a\u8fc7\u5bf9\u8bdd\u53cd\u9988\u5b66\u4e60\u9886\u57df\u77e5\u8bc6\uff0c\u5728\u764c\u75c7\u836f\u7269\u53d1\u73b0\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5206\u5b50\u751f\u6210\u5728\u836f\u7269\u53d1\u73b0\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u7c7b\u522b\u7279\u5b9a\u6570\u636e\u96c6\u901a\u5e38\u5c11\u4e8e100\u4e2a\u8bad\u7ec3\u6837\u672c\u3002\u73b0\u6709\u788e\u7247\u5316\u65b9\u6cd5\u591a\u6837\u6027\u6709\u9650\u4e14\u9519\u8fc7\u5173\u952e\u7247\u6bb5\uff0c\u6a21\u578b\u8c03\u4f18\u9700\u8981\u5316\u5b66\u5bb6\u548cAI\u5de5\u7a0b\u5e08\u4e4b\u95f4\u7684\u7f13\u6162\u534f\u4f5c\u3002", "method": "1) \u65b0\u9896\u751f\u6210\u6a21\u578b\uff0c\u5c06\u788e\u7247\u5316\u91cd\u6784\u4e3a\"\u8bcd\u6c47\u9009\u62e9\"\u95ee\u9898\uff0c\u4f7f\u7528\u52a8\u6001Q\u5b66\u4e60\u8054\u5408\u4f18\u5316\u788e\u7247\u5316\u548c\u751f\u6210\uff1b2) \u667a\u80fdAI\u7cfb\u7edf\u901a\u8fc7\u9886\u57df\u4e13\u5bb6\u7684\u5bf9\u8bdd\u53cd\u9988\u7cbe\u70bc\u76ee\u6807\uff0c\u9010\u6b65\u5b66\u4e60\u9886\u57df\u77e5\u8bc6\u5b9e\u73b0\u81ea\u52a8\u5316\u8c03\u4f18\u3002", "result": "\u5728\u771f\u5b9e\u764c\u75c7\u836f\u7269\u53d1\u73b0\u5b9e\u9a8c\u4e2d\uff0cFRAGMENTA\u7684\u4eba\u7c7b-\u667a\u80fd\u4f53\u914d\u7f6e\u8bc6\u522b\u7684\u9ad8\u5206\u5206\u5b50\u6570\u91cf\u662f\u57fa\u7ebf\u7684\u8fd1\u4e24\u500d\u3002\u5b8c\u5168\u81ea\u4e3b\u7684\u667a\u80fd\u4f53-\u667a\u80fd\u4f53\u7cfb\u7edf\u4f18\u4e8e\u4f20\u7edf\u7684\u4eba\u7c7b-\u4eba\u7c7b\u8c03\u4f18\u3002", "conclusion": "FRAGMENTA\u5c55\u793a\u4e86\u667a\u80fd\u4f53\u8c03\u4f18\u5728\u6355\u6349\u4e13\u5bb6\u610f\u56fe\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u836f\u7269\u53d1\u73b0\u6d41\u7a0b\u5e76\u63d0\u9ad8\u6548\u7387\u3002"}}
{"id": "2511.20526", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20526", "abs": "https://arxiv.org/abs/2511.20526", "authors": ["Xinran Wang", "Boran Zhu", "Shujuan Zhou", "Ziwen Long", "Dehua Zhou", "Shu Zhang"], "title": "Assessing LLMs' Performance: Insights from the Chinese Pharmacist Exam", "comment": "15 pages, 4 figures", "summary": "Background: As large language models (LLMs) become increasingly integrated into digital health education and assessment workflows, their capabilities in supporting high-stakes, domain-specific certification tasks remain underexplored.In China, the national pharmacist licensure exam serves as a standardized benchmark for evaluating pharmacists' clinical and theoretical competencies. Objective: This study aimed to compare the performance of two LLMs: ChatGPT-4o and DeepSeek-R1 on real questions from the Chinese Pharmacist Licensing Examination (2017-2021), and to discuss the implications of these performance differences for AI-enabled formative evaluation. Methods: A total of 2,306 multiple-choice (text-only) questions were compiled from official exams, training materials, and public databases. Questions containing tables or images were excluded. Each item was input in its original Chinese format, and model responses were evaluated for exact accuracy. Pearson's Chi-squared test was used to compare overall performance, and Fisher's exact test was applied to year-wise multiple-choice accuracy. Results: DeepSeek-R1 outperformed ChatGPT-4o with a significantly higher overall accuracy (90.0% vs. 76.1%, p < 0.001). Unit-level analyses revealed consistent advantages for DeepSeek-R1, particularly in foundational and clinical synthesis modules. While year-by-year multiple-choice performance also favored DeepSeek-R1, this performance gap did not reach statistical significance in any specific unit-year (all p > 0.05). Conclusion: DeepSeek-R1 demonstrated robust alignment with the structural and semantic demands of the pharmacist licensure exam. These findings suggest that domain-specific models warrant further investigation for this context, while also reinforcing the necessity of human oversight in legally and ethically sensitive contexts.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86ChatGPT-4o\u548cDeepSeek-R1\u5728\u4e2d\u56fd\u836f\u5e08\u6267\u4e1a\u8d44\u683c\u8003\u8bd5\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0DeepSeek-R1\u5728\u51c6\u786e\u7387\u4e0a\u663e\u8457\u4f18\u4e8eChatGPT-4o\uff0890.0% vs 76.1%\uff09\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b57\u5065\u5eb7\u6559\u80b2\u548c\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5728\u7279\u5b9a\u9886\u57df\u9ad8\u5229\u5bb3\u8ba4\u8bc1\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u3002\u4e2d\u56fd\u836f\u5e08\u6267\u4e1a\u8d44\u683c\u8003\u8bd5\u4f5c\u4e3a\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u9002\u5408\u8bc4\u4f30\u6a21\u578b\u5728\u836f\u5b66\u9886\u57df\u7684\u4e34\u5e8a\u548c\u7406\u8bba\u80fd\u529b\u3002", "method": "\u6536\u96c62017-2021\u5e74\u5b98\u65b9\u8003\u8bd5\u4e2d\u76842,306\u9053\u7eaf\u6587\u672c\u9009\u62e9\u9898\uff0c\u6392\u9664\u542b\u8868\u683c\u6216\u56fe\u50cf\u7684\u9898\u76ee\u3002\u5c06\u9898\u76ee\u4ee5\u4e2d\u6587\u539f\u683c\u5f0f\u8f93\u5165\u6a21\u578b\uff0c\u8bc4\u4f30\u6a21\u578b\u54cd\u5e94\u7684\u51c6\u786e\u7387\uff0c\u4f7f\u7528Pearson\u5361\u65b9\u68c0\u9a8c\u6bd4\u8f83\u6574\u4f53\u8868\u73b0\uff0cFisher\u7cbe\u786e\u68c0\u9a8c\u5206\u6790\u5e74\u5ea6\u9009\u62e9\u9898\u51c6\u786e\u7387\u3002", "result": "DeepSeek-R1\u6574\u4f53\u51c6\u786e\u7387\u663e\u8457\u9ad8\u4e8eChatGPT-4o\uff0890.0% vs 76.1%\uff0cp < 0.001\uff09\u3002\u5355\u5143\u5206\u6790\u663e\u793aDeepSeek-R1\u5728\u57fa\u7840\u548c\u4e34\u5e8a\u7efc\u5408\u6a21\u5757\u4e2d\u8868\u73b0\u4e00\u81f4\u66f4\u4f18\u3002\u867d\u7136\u5e74\u5ea6\u9009\u62e9\u9898\u8868\u73b0\u4e5f\u503e\u5411\u4e8eDeepSeek-R1\uff0c\u4f46\u5728\u4efb\u4f55\u7279\u5b9a\u5355\u5143-\u5e74\u4efd\u7ec4\u5408\u4e2d\u8fd9\u4e00\u5dee\u8ddd\u672a\u8fbe\u5230\u7edf\u8ba1\u663e\u8457\u6027\u3002", "conclusion": "DeepSeek-R1\u5728\u836f\u5e08\u6267\u4e1a\u8d44\u683c\u8003\u8bd5\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u8981\u6c42\u65b9\u9762\u8868\u73b0\u51fa\u826f\u597d\u7684\u5bf9\u9f50\u6027\u3002\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\u7279\u5b9a\u9886\u57df\u6a21\u578b\u5728\u6b64\u80cc\u666f\u4e0b\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u540c\u65f6\u4e5f\u5f3a\u8c03\u4e86\u5728\u6cd5\u5f8b\u548c\u4f26\u7406\u654f\u611f\u60c5\u5883\u4e2d\u4fdd\u6301\u4eba\u5de5\u76d1\u7763\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2511.20531", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20531", "abs": "https://arxiv.org/abs/2511.20531", "authors": ["Shamima Hossain"], "title": "Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models", "comment": "Accepted as poster at NewInML Workshop ICML, 2025", "summary": "Visual Language Models (VLMs) are powerful generative tools but often produce factually inaccurate outputs due to a lack of robust reasoning capabilities. While extensive research has been conducted on integrating external knowledge for reasoning in large language models (LLMs), such efforts remain underexplored in VLMs, where the challenge is compounded by the need to bridge multiple modalities seamlessly. This work introduces a framework for knowledge-guided reasoning in VLMs, leveraging structured knowledge graphs for multi-hop verification using image-captioning task to illustrate our framework. Our approach enables systematic reasoning across multiple steps, including visual entity recognition, knowledge graph traversal, and fact-based caption refinement. We evaluate the framework using hierarchical, triple-based and bullet-point based knowledge representations, analyzing their effectiveness in factual accuracy and logical inference. Empirical results show that our approach improves factual accuracy by approximately 31% on preliminary experiments on a curated dataset of mixtures from Google Landmarks v2, Conceptual captions and Coco captions revealing key insights into reasoning patterns and failure modes. This work demonstrates the potential of integrating external knowledge for advancing reasoning in VLMs, paving the way for more reliable and knowledgable multimodal systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u8df3\u9a8c\u8bc1\u63d0\u5347\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u5728\u521d\u6b65\u5b9e\u9a8c\u4e2d\u5b9e\u73b0\u4e86\u7ea631%\u7684\u4e8b\u5b9e\u51c6\u786e\u7387\u63d0\u5347", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u867d\u7136\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u5e38\u5e38\u4ea7\u751f\u4e8b\u5b9e\u4e0d\u51c6\u786e\u7684\u8f93\u51fa\uff0c\u7f3a\u4e4f\u7a33\u5065\u7684\u63a8\u7406\u80fd\u529b\u3002\u76ee\u524d\u5bf9\u5916\u90e8\u77e5\u8bc6\u96c6\u6210\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u7eaf\u8bed\u8a00\u6a21\u578b\uff0c\u800c\u5728\u591a\u6a21\u6001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u63a2\u7d22\u4e0d\u8db3", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u77e5\u8bc6\u5f15\u5bfc\u7684\u63a8\u7406\u6846\u67b6\uff0c\u5229\u7528\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u591a\u8df3\u9a8c\u8bc1\u3002\u65b9\u6cd5\u5305\u62ec\u89c6\u89c9\u5b9e\u4f53\u8bc6\u522b\u3001\u77e5\u8bc6\u56fe\u8c31\u904d\u5386\u548c\u57fa\u4e8e\u4e8b\u5b9e\u7684\u6807\u9898\u7cbe\u70bc\u7b49\u591a\u4e2a\u7cfb\u7edf\u63a8\u7406\u6b65\u9aa4", "result": "\u5728\u7531Google Landmarks v2\u3001Conceptual captions\u548cCoco captions\u6df7\u5408\u7ec4\u6210\u7684\u5b9a\u5236\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u521d\u6b65\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u4e8b\u5b9e\u51c6\u786e\u7387\u63d0\u9ad8\u4e86\u7ea631%", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u96c6\u6210\u5916\u90e8\u77e5\u8bc6\u5728\u63a8\u8fdb\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u3001\u77e5\u8bc6\u66f4\u4e30\u5bcc\u7684\u591a\u6a21\u6001\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def"}}
{"id": "2511.20586", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20586", "abs": "https://arxiv.org/abs/2511.20586", "authors": ["Koffi Ismael Ouattara", "Ioannis Krontiris", "Theo Dimitrakos", "Dennis Eisermann", "Frank Kargl"], "title": "PaTAS: A Parallel System for Trust Propagation in Neural Networks Using Subjective Logic", "comment": null, "summary": "Trustworthiness has become a key requirement for the deployment of artificial intelligence systems in safety-critical applications. Conventional evaluation metrics such as accuracy and precision fail to capture uncertainty or the reliability of model predictions, particularly under adversarial or degraded conditions. This paper introduces the \\emph{Parallel Trust Assessment System (PaTAS)}, a framework for modeling and propagating trust in neural networks using Subjective Logic (SL). PaTAS operates in parallel with standard neural computation through \\emph{Trust Nodes} and \\emph{Trust Functions} that propagate input, parameter, and activation trust across the network. The framework defines a \\emph{Parameter Trust Update} mechanism to refine parameter reliability during training and an \\emph{Inference-Path Trust Assessment (IPTA)} method to compute instance-specific trust at inference. Experiments on real-world and adversarial datasets demonstrate that PaTAS produces interpretable, symmetric, and convergent trust estimates that complement accuracy and expose reliability gaps in poisoned, biased, or uncertain data scenarios. The results show that PaTAS effectively distinguishes between benign and adversarial inputs and identifies cases where model confidence diverges from actual reliability. By enabling transparent and quantifiable trust reasoning within neural architectures, PaTAS provides a principled foundation for evaluating model reliability across the AI lifecycle.", "AI": {"tldr": "\u63d0\u51fa\u4e86PaTAS\u6846\u67b6\uff0c\u4f7f\u7528\u4e3b\u89c2\u903b\u8f91\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u5efa\u6a21\u548c\u4f20\u64ad\u4fe1\u4efb\u5ea6\uff0c\u901a\u8fc7\u5e76\u884c\u4fe1\u4efb\u8282\u70b9\u548c\u51fd\u6570\u8bc4\u4f30\u8f93\u5165\u3001\u53c2\u6570\u548c\u6fc0\u6d3b\u7684\u53ef\u9760\u6027\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u4fe1\u4efb\u8bc4\u4f30\u3002", "motivation": "\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\u5982\u51c6\u786e\u7387\u65e0\u6cd5\u6355\u6349\u6a21\u578b\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u6216\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u5728\u5bf9\u6297\u6027\u6216\u9000\u5316\u6761\u4ef6\u4e0b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u91cf\u5316\u6a21\u578b\u4fe1\u4efb\u5ea6\u7684\u7cfb\u7edf\u6765\u786e\u4fddAI\u7cfb\u7edf\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "PaTAS\u6846\u67b6\u5305\u542b\u4fe1\u4efb\u8282\u70b9\u548c\u4fe1\u4efb\u51fd\u6570\uff0c\u5728\u6807\u51c6\u795e\u7ecf\u7f51\u7edc\u8ba1\u7b97\u4e2d\u5e76\u884c\u8fd0\u884c\uff0c\u4f20\u64ad\u8f93\u5165\u3001\u53c2\u6570\u548c\u6fc0\u6d3b\u7684\u4fe1\u4efb\u5ea6\u3002\u5b9a\u4e49\u4e86\u53c2\u6570\u4fe1\u4efb\u66f4\u65b0\u673a\u5236\u548c\u63a8\u7406\u8def\u5f84\u4fe1\u4efb\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u548c\u5bf9\u6297\u6027\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPaTAS\u4ea7\u751f\u53ef\u89e3\u91ca\u3001\u5bf9\u79f0\u4e14\u6536\u655b\u7684\u4fe1\u4efb\u4f30\u8ba1\uff0c\u80fd\u6709\u6548\u533a\u5206\u826f\u6027\u8f93\u5165\u548c\u5bf9\u6297\u6027\u8f93\u5165\uff0c\u8bc6\u522b\u6a21\u578b\u7f6e\u4fe1\u5ea6\u4e0e\u5b9e\u9645\u53ef\u9760\u6027\u4e0d\u4e00\u81f4\u7684\u60c5\u51b5\u3002", "conclusion": "PaTAS\u901a\u8fc7\u5728\u795e\u7ecf\u67b6\u6784\u4e2d\u5b9e\u73b0\u900f\u660e\u548c\u53ef\u91cf\u5316\u7684\u4fe1\u4efb\u63a8\u7406\uff0c\u4e3a\u8bc4\u4f30AI\u751f\u547d\u5468\u671f\u4e2d\u7684\u6a21\u578b\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u57fa\u7840\u3002"}}
{"id": "2511.20610", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20610", "abs": "https://arxiv.org/abs/2511.20610", "authors": ["Gaspard Merten", "Mahmoud Sakr", "Gilles Dejaegere"], "title": "Building a Foundation Model for Trajectory from Scratch", "comment": null, "summary": "Foundation models are transformative in artificial intelligence, but building them from scratch, especially for mobility trajectories, is not yet clear or documented. This tutorial bridges this gap by demonstrating the steps and code of a minimal implementation of a trajectory-focused foundation model starting from GPT-2. Through a concise, step-by-step, code-driven process, we demonstrate adapting GPT-2 for spatiotemporal data. We then review and compare representative trajectory foundation models, such as TrajFM and TrajGPT, highlighting their architectural innovations and differences. Additionally, we introduce complementary techniques from related domains, like TimesFM's patching approach. Targeted at researchers and practitioners, this tutorial aims to explain the concepts and terminology of foundation models, at the implementation level. We find it timely and indispensable to create this educational material in order to support the SIGSPATIAL community in building and evaluating mobility foundation models, enhancing both research clarity and peer-review effectiveness in mobility AI.", "AI": {"tldr": "\u672c\u6559\u7a0b\u901a\u8fc7\u4ee3\u7801\u9a71\u52a8\u7684\u5206\u6b65\u8fc7\u7a0b\uff0c\u5c55\u793a\u4e86\u4eceGPT-2\u5f00\u59cb\u6784\u5efa\u8f68\u8ff9\u57fa\u7840\u6a21\u578b\u7684\u6700\u5c0f\u5b9e\u73b0\uff0c\u6bd4\u8f83\u4e86TrajFM\u548cTrajGPT\u7b49\u4ee3\u8868\u6027\u6a21\u578b\uff0c\u5e76\u4ecb\u7ecd\u4e86TimesFM\u7684\u8865\u4e01\u65b9\u6cd5\u7b49\u8865\u5145\u6280\u672f\u3002", "motivation": "\u867d\u7136\u57fa\u7840\u6a21\u578b\u5728\u4eba\u5de5\u667a\u80fd\u4e2d\u5177\u6709\u53d8\u9769\u6027\uff0c\u4f46\u4e3a\u79fb\u52a8\u8f68\u8ff9\u4ece\u5934\u5f00\u59cb\u6784\u5efa\u8fd9\u4e9b\u6a21\u578b\u7684\u65b9\u6cd5\u5c1a\u4e0d\u660e\u786e\u6216\u7f3a\u4e4f\u6587\u6863\u8bb0\u5f55\uff0c\u672c\u6559\u7a0b\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u4ee3\u7801\u9a71\u52a8\u7684\u5206\u6b65\u8fc7\u7a0b\uff0c\u6f14\u793a\u5982\u4f55\u5c06GPT-2\u9002\u914d\u4e8e\u65f6\u7a7a\u6570\u636e\uff0c\u5e76\u6bd4\u8f83\u4ee3\u8868\u6027\u8f68\u8ff9\u57fa\u7840\u6a21\u578b\u7684\u67b6\u6784\u521b\u65b0\u548c\u5dee\u5f02\u3002", "result": "\u63d0\u4f9b\u4e86\u6784\u5efa\u548c\u8bc4\u4f30\u79fb\u52a8\u57fa\u7840\u6a21\u578b\u7684\u5b9e\u7528\u6307\u5357\uff0c\u652f\u6301SIGSPATIAL\u793e\u533a\u5728\u6b64\u9886\u57df\u7684\u7814\u7a76\u5de5\u4f5c\u3002", "conclusion": "\u521b\u5efa\u8fd9\u79cd\u6559\u80b2\u6750\u6599\u5bf9\u4e8e\u652f\u6301SIGSPATIAL\u793e\u533a\u6784\u5efa\u548c\u8bc4\u4f30\u79fb\u52a8\u57fa\u7840\u6a21\u578b\u3001\u63d0\u9ad8\u79fb\u52a8AI\u7814\u7a76\u6e05\u6670\u5ea6\u548c\u540c\u884c\u8bc4\u5ba1\u6548\u679c\u662f\u53ca\u65f6\u4e14\u4e0d\u53ef\u6216\u7f3a\u7684\u3002"}}
{"id": "2511.20623", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20623", "abs": "https://arxiv.org/abs/2511.20623", "authors": ["David Szczecina", "Senan Gaffori", "Edmond Li"], "title": "Copyright Detection in Large Language Models: An Ethical Approach to Generative AI Development", "comment": "4 pages, 3 figures", "summary": "The widespread use of Large Language Models (LLMs) raises critical concerns regarding the unauthorized inclusion of copyrighted content in training data. Existing detection frameworks, such as DE-COP, are computationally intensive, and largely inaccessible to independent creators. As legal scrutiny increases, there is a pressing need for a scalable, transparent, and user-friendly solution. This paper introduce an open-source copyright detection platform that enables content creators to verify whether their work was used in LLM training datasets. Our approach enhances existing methodologies by facilitating ease of use, improving similarity detection, optimizing dataset validation, and reducing computational overhead by 10-30% with efficient API calls. With an intuitive user interface and scalable backend, this framework contributes to increasing transparency in AI development and ethical compliance, facilitating the foundation for further research in responsible AI development and copyright enforcement.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5f00\u6e90\u7248\u6743\u68c0\u6d4b\u5e73\u53f0\uff0c\u5e2e\u52a9\u5185\u5bb9\u521b\u4f5c\u8005\u9a8c\u8bc1\u5176\u4f5c\u54c1\u662f\u5426\u88ab\u7528\u4e8eLLM\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u964d\u4f4e10-30%\uff0c\u5e76\u63d0\u4f9b\u7528\u6237\u53cb\u597d\u7684\u754c\u9762\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u4f7f\u7528\u5f15\u53d1\u7248\u6743\u5185\u5bb9\u672a\u7ecf\u6388\u6743\u7eb3\u5165\u8bad\u7ec3\u6570\u636e\u7684\u62c5\u5fe7\uff0c\u73b0\u6709\u68c0\u6d4b\u6846\u67b6\u8ba1\u7b97\u5bc6\u96c6\u4e14\u5bf9\u72ec\u7acb\u521b\u4f5c\u8005\u4e0d\u53cb\u597d\uff0c\u9700\u8981\u53ef\u6269\u5c55\u3001\u900f\u660e\u4e14\u7528\u6237\u53cb\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u4f18\u5316API\u8c03\u7528\u6548\u7387\uff0c\u6539\u8fdb\u76f8\u4f3c\u6027\u68c0\u6d4b\u548c\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u6784\u5efa\u5177\u6709\u76f4\u89c2\u7528\u6237\u754c\u9762\u548c\u53ef\u6269\u5c55\u540e\u7aef\u7684\u5f00\u6e90\u5e73\u53f0\u3002", "result": "\u8ba1\u7b97\u5f00\u9500\u964d\u4f4e10-30%\uff0c\u63d0\u4f9b\u7528\u6237\u53cb\u597d\u7684\u68c0\u6d4b\u754c\u9762\uff0c\u589e\u5f3aAI\u5f00\u53d1\u900f\u660e\u5ea6\u548c\u4f26\u7406\u5408\u89c4\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8d1f\u8d23\u4efbAI\u5f00\u53d1\u548c\u7248\u6743\u6267\u6cd5\u7814\u7a76\u5960\u5b9a\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8AI\u5f00\u53d1\u7684\u900f\u660e\u5ea6\u3002"}}
{"id": "2511.20627", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20627", "abs": "https://arxiv.org/abs/2511.20627", "authors": ["Anastasia Mavridou", "Divya Gopinath", "Corina S. P\u0103s\u0103reanu"], "title": "Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems", "comment": null, "summary": "The integration of AI components, particularly Deep Neural Networks (DNNs), into safety-critical systems such as aerospace and autonomous vehicles presents fundamental challenges for assurance. The opacity of AI systems, combined with the semantic gap between high-level requirements and low-level network representations, creates barriers to traditional verification approaches. These AI-specific challenges are amplified by longstanding issues in Requirements Engineering, including ambiguity in natural language specifications and scalability bottlenecks in formalization. We propose an approach that leverages AI itself to address these challenges through two complementary components. REACT (Requirements Engineering with AI for Consistency and Testing) employs Large Language Models (LLMs) to bridge the gap between informal natural language requirements and formal specifications, enabling early verification and validation. SemaLens (Semantic Analysis of Visual Perception using large Multi-modal models) utilizes Vision Language Models (VLMs) to reason about, test, and monitor DNN-based perception systems using human-understandable concepts. Together, these components provide a comprehensive pipeline from informal requirements to validated implementations.", "AI": {"tldr": "\u63d0\u51fa\u4e86REACT\u548cSemaLens\u4e24\u4e2a\u4e92\u8865\u7ec4\u4ef6\uff0c\u5229\u7528AI\u6280\u672f\u89e3\u51b3\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2dAI\u7ec4\u4ef6\u96c6\u6210\u7684\u9a8c\u8bc1\u6311\u6218\uff0c\u4ece\u975e\u6b63\u5f0f\u9700\u6c42\u5230\u9a8c\u8bc1\u5b9e\u73b0\u63d0\u4f9b\u5b8c\u6574\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "AI\u7ec4\u4ef6\uff08\u7279\u522b\u662f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff09\u96c6\u6210\u5230\u822a\u7a7a\u822a\u5929\u548c\u81ea\u52a8\u9a7e\u9a76\u7b49\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u9762\u4e34\u9a8c\u8bc1\u6311\u6218\uff0cAI\u7cfb\u7edf\u7684\u4e0d\u900f\u660e\u6027\u4ee5\u53ca\u9ad8\u5c42\u9700\u6c42\u4e0e\u4f4e\u5c42\u7f51\u7edc\u8868\u793a\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\u963b\u788d\u4e86\u4f20\u7edf\u9a8c\u8bc1\u65b9\u6cd5\u3002", "method": "REACT\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fde\u63a5\u975e\u6b63\u5f0f\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u548c\u5f62\u5f0f\u5316\u89c4\u8303\uff0c\u5b9e\u73b0\u65e9\u671f\u9a8c\u8bc1\uff1bSemaLens\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u57fa\u4e8e\u4eba\u7c7b\u53ef\u7406\u89e3\u6982\u5ff5\u5bf9DNN\u611f\u77e5\u7cfb\u7edf\u8fdb\u884c\u63a8\u7406\u3001\u6d4b\u8bd5\u548c\u76d1\u63a7\u3002", "result": "\u6784\u5efa\u4e86\u4ece\u975e\u6b63\u5f0f\u9700\u6c42\u5230\u9a8c\u8bc1\u5b9e\u73b0\u7684\u5b8c\u6574\u7ba1\u9053\uff0c\u89e3\u51b3\u4e86\u9700\u6c42\u5de5\u7a0b\u4e2d\u7684\u6a21\u7cca\u6027\u548c\u53ef\u6269\u5c55\u6027\u74f6\u9888\u95ee\u9898\u3002", "conclusion": "\u5229\u7528AI\u6280\u672f\u672c\u8eab\u53ef\u4ee5\u89e3\u51b3AI\u7cfb\u7edf\u96c6\u6210\u5230\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u7684\u9a8c\u8bc1\u6311\u6218\uff0cREACT\u548cSemaLens\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
