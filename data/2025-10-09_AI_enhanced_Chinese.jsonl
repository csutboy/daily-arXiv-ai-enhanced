{"id": "2510.06368", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.06368", "abs": "https://arxiv.org/abs/2510.06368", "authors": ["Carson Hunsberger", "David Schwab", "Roshan Eapen", "Puneet Singla"], "title": "Comparing Normal Form Representations for Station-Keeping near Cislunar Libration Points", "comment": "2025 AAS/AIAA Space Flight Mechanics Meeting", "summary": "The normal forms provide useful approximations for many trajectories of\ninterest within the circular restricted three-body problem. This paper aims to\nthoroughly compare two of these forms: the Birkhoff normal form and the\nresonant normal form, highlighting the strengths of each for the representation\nof center manifold trajectories. A method of station-keeping is introduced,\nanalogous to Floquet modes, in which the unstable component is minimized at\nspecific points along a trajectory through impulsive maneuvers. Three different\nformulations of the same station-keeping approach are posed, collectively\nspanning Lyapunov, vertical, and halo orbits, as well as Lissajous and\nquasihalo trajectories.", "AI": {"tldr": "\u6bd4\u8f83Birkhoff\u548c\u5171\u632f\u4e24\u79cd\u6b63\u89c4\u5f62\u5f0f\u5728\u5706\u5f62\u9650\u5236\u6027\u4e09\u4f53\u95ee\u9898\u4e2d\u8868\u793a\u4e2d\u5fc3\u6d41\u5f62\u8f68\u8ff9\u7684\u80fd\u529b\uff0c\u5e76\u5f15\u5165\u57fa\u4e8eFloquet\u6a21\u5f0f\u7684\u7ad9\u4fdd\u6301\u65b9\u6cd5", "motivation": "\u6b63\u89c4\u5f62\u5f0f\u4e3a\u5706\u5f62\u9650\u5236\u6027\u4e09\u4f53\u95ee\u9898\u4e2d\u7684\u8bb8\u591a\u611f\u5174\u8da3\u8f68\u8ff9\u63d0\u4f9b\u4e86\u6709\u7528\u7684\u8fd1\u4f3c\uff0c\u9700\u8981\u7cfb\u7edf\u6bd4\u8f83\u4e0d\u540c\u6b63\u89c4\u5f62\u5f0f\u7684\u4f18\u7f3a\u70b9", "method": "\u6bd4\u8f83Birkhoff\u6b63\u89c4\u5f62\u5f0f\u548c\u5171\u632f\u6b63\u89c4\u5f62\u5f0f\uff0c\u5f15\u5165\u7c7b\u4f3cFloquet\u6a21\u5f0f\u7684\u7ad9\u4fdd\u6301\u65b9\u6cd5\uff0c\u901a\u8fc7\u8109\u51b2\u673a\u52a8\u5728\u8f68\u8ff9\u7279\u5b9a\u70b9\u6700\u5c0f\u5316\u4e0d\u7a33\u5b9a\u5206\u91cf", "result": "\u63d0\u51fa\u4e86\u4e09\u79cd\u76f8\u540c\u7ad9\u4fdd\u6301\u65b9\u6cd5\u7684\u8868\u8ff0\uff0c\u5171\u540c\u6db5\u76d6Lyapunov\u3001\u5782\u76f4\u548c\u6655\u8f68\u9053\uff0c\u4ee5\u53caLissajous\u548c\u51c6\u6655\u8f68\u8ff9", "conclusion": "\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4e24\u79cd\u6b63\u89c4\u5f62\u5f0f\u5728\u4e2d\u5fc3\u6d41\u5f62\u8f68\u8ff9\u8868\u793a\u4e2d\u7684\u4f18\u52bf\uff0c\u5e76\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u7ad9\u4fdd\u6301\u6846\u67b6"}}
{"id": "2510.06394", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2510.06394", "abs": "https://arxiv.org/abs/2510.06394", "authors": ["Praveen Kumar Ranjan", "Abhinav Sinha", "Yongcan Cao"], "title": "Three-dimensional Integrated Guidance and Control for Leader-Follower Flexible Formation of Fixed Wing UAVs", "comment": null, "summary": "This paper presents a nonlinear integrated guidance and control (IGC)\napproach for flexible leader-follower formation flight of fixed-wing unmanned\naerial vehicles (UAVs) while accounting for high-fidelity aerodynamics and\nthrust dynamics. Unlike conventional leader-follower schemes that fix the\nfollower's position relative to the leader, the follower is steered to maintain\nrange and bearing angles (which is the angle between its velocity vector and\nits line-of-sight (LOS) with respect to the leader) arbitrarily close to the\nprescribed values, enabling the follower to maintain formation on a\nhemispherical region behind the leader. The proposed IGC framework directly\nmaps leader-follower relative range dynamics to throttle commands, and the\nfollower's velocity orientation relative to the LOS to aerodynamic control\nsurface deflections. This enables synergism between guidance and control\nsubsystems. The control design uses a dynamic surface control-based\nbackstepping approach to achieve convergence to the desired formation set,\nwhere Lyapunov barrier functions are incorporated to ensure the follower's\nbearing angle is constrained within specified bounds. Rigorous stability\nanalysis guarantees uniform ultimate boundedness of all error states and strict\nconstraint satisfaction in the presence of aerodynamic nonlinearities. The\nproposed flexible formation scheme allows the follower to have an orientation\nmismatch relative to the leader to execute anticipatory reconfiguration by\ntransitioning between the relative positions in the admissible formation set\nwhen the leader aggressively maneuvers. The proposed IGC law relies only on\nrelative information and onboard sensors without the information about the\nleader's maneuver, making it suitable for GPS-denied or non-cooperative\nscenarios. Finally, we present simulation results to vindicate the\neffectiveness and robustness of our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u7ebf\u6027\u96c6\u6210\u5236\u5bfc\u4e0e\u63a7\u5236\u65b9\u6cd5\uff0c\u7528\u4e8e\u56fa\u5b9a\u7ffc\u65e0\u4eba\u673a\u7684\u67d4\u6027\u7f16\u961f\u98de\u884c\uff0c\u8003\u8651\u9ad8\u4fdd\u771f\u6c14\u52a8\u529b\u5b66\u548c\u63a8\u529b\u52a8\u529b\u5b66\uff0c\u901a\u8fc7\u52a8\u6001\u8868\u9762\u63a7\u5236\u5b9e\u73b0\u7f16\u961f\u4fdd\u6301\u548c\u7ea6\u675f\u6ee1\u8db3\u3002", "motivation": "\u4f20\u7edf\u9886\u5bfc\u8005-\u8ddf\u968f\u8005\u7f16\u961f\u65b9\u6848\u56fa\u5b9a\u8ddf\u968f\u8005\u76f8\u5bf9\u4e8e\u9886\u5bfc\u8005\u7684\u4f4d\u7f6e\uff0c\u9650\u5236\u4e86\u7f16\u961f\u7684\u7075\u6d3b\u6027\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u67d4\u6027\u7f16\u961f\u65b9\u6cd5\uff0c\u4f7f\u8ddf\u968f\u8005\u80fd\u591f\u5728\u534a\u7403\u5f62\u533a\u57df\u5185\u4fdd\u6301\u7f16\u961f\uff0c\u5e76\u9002\u5e94\u9886\u5bfc\u8005\u7684\u5267\u70c8\u673a\u52a8\u3002", "method": "\u91c7\u7528\u52a8\u6001\u8868\u9762\u63a7\u5236\u7684\u53cd\u6b65\u6cd5\uff0c\u5c06\u9886\u5bfc\u8005-\u8ddf\u968f\u8005\u76f8\u5bf9\u8ddd\u79bb\u52a8\u6001\u6620\u5c04\u5230\u6cb9\u95e8\u6307\u4ee4\uff0c\u5c06\u901f\u5ea6\u65b9\u5411\u76f8\u5bf9\u4e8e\u89c6\u7ebf\u89d2\u7684\u52a8\u6001\u6620\u5c04\u5230\u6c14\u52a8\u63a7\u5236\u9762\u504f\u8f6c\u3002\u7ed3\u5408Lyapunov\u5c4f\u969c\u51fd\u6570\u786e\u4fdd\u7ea6\u675f\u6ee1\u8db3\u3002", "result": "\u4e25\u683c\u7684\u7a33\u5b9a\u6027\u5206\u6790\u4fdd\u8bc1\u4e86\u6240\u6709\u8bef\u5dee\u72b6\u6001\u7684\u5747\u5300\u6700\u7ec8\u6709\u754c\u6027\uff0c\u5e76\u5728\u5b58\u5728\u6c14\u52a8\u975e\u7ebf\u6027\u65f6\u4e25\u683c\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\u3002\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684IGC\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u76f8\u5bf9\u4fe1\u606f\u548c\u673a\u8f7d\u4f20\u611f\u5668\uff0c\u65e0\u9700\u9886\u5bfc\u8005\u673a\u52a8\u4fe1\u606f\uff0c\u9002\u7528\u4e8eGPS\u62d2\u6b62\u6216\u975e\u5408\u4f5c\u573a\u666f\uff0c\u5b9e\u73b0\u4e86\u67d4\u6027\u7f16\u961f\u98de\u884c\u548c\u9884\u671f\u91cd\u6784\u80fd\u529b\u3002"}}
{"id": "2510.06470", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.06470", "abs": "https://arxiv.org/abs/2510.06470", "authors": ["Abd\u00fclbaki \u015eanlan", "Fatih Erol", "Murad Abu-Khalaf", "Emre Koyuncu"], "title": "Terrain-Aided Navigation Using a Point Cloud Measurement Sensor", "comment": null, "summary": "We investigate the use of a point cloud measurement in terrain-aided\nnavigation. Our goal is to aid an inertial navigation system, by exploring ways\nto generate a useful measurement innovation error for effective nonlinear state\nestimation. We compare two such measurement models that involve the scanning of\na digital terrain elevation model: a) one that is based on typical ray-casting\nfrom a given pose, that returns the predicted point cloud measurement from that\npose, and b) another computationally less intensive one that does not require\nraycasting and we refer to herein as a sliding grid. Besides requiring a pose,\nit requires the pattern of the point cloud measurement itself and returns a\npredicted point cloud measurement. We further investigate the observability\nproperties of the altitude for both measurement models. As a baseline, we\ncompare the use of a point cloud measurement performance to the use of a radar\naltimeter and show the gains in accuracy. We conclude by showing that a point\ncloud measurement outperforms the use of a radar altimeter, and the point cloud\nmeasurement model to use depends on the computational resources", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5728\u57fa\u4e8e\u5730\u5f62\u7684\u5bfc\u822a\u4e2d\u4f7f\u7528\u70b9\u4e91\u6d4b\u91cf\u6765\u8f85\u52a9\u60ef\u6027\u5bfc\u822a\u7cfb\u7edf\uff0c\u6bd4\u8f83\u4e86\u4e24\u79cd\u70b9\u4e91\u6d4b\u91cf\u6a21\u578b\uff1a\u57fa\u4e8e\u5149\u7ebf\u6295\u5c04\u7684\u6a21\u578b\u548c\u8ba1\u7b97\u91cf\u66f4\u5c0f\u7684\u6ed1\u52a8\u7f51\u683c\u6a21\u578b\uff0c\u5e76\u8bc1\u660e\u70b9\u4e91\u6d4b\u91cf\u4f18\u4e8e\u96f7\u8fbe\u9ad8\u5ea6\u8ba1\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u70b9\u4e91\u6d4b\u91cf\u751f\u6210\u6709\u6548\u7684\u6d4b\u91cf\u521b\u65b0\u8bef\u5dee\uff0c\u4ee5\u8f85\u52a9\u60ef\u6027\u5bfc\u822a\u7cfb\u7edf\u8fdb\u884c\u975e\u7ebf\u6027\u72b6\u6001\u4f30\u8ba1\uff0c\u63d0\u9ad8\u5bfc\u822a\u7cbe\u5ea6\u3002", "method": "\u6bd4\u8f83\u4e24\u79cd\u70b9\u4e91\u6d4b\u91cf\u6a21\u578b\uff1a1\uff09\u57fa\u4e8e\u5149\u7ebf\u6295\u5c04\u7684\u6a21\u578b\uff0c\u4ece\u7ed9\u5b9a\u59ff\u6001\u8fd4\u56de\u9884\u6d4b\u70b9\u4e91\u6d4b\u91cf\uff1b2\uff09\u6ed1\u52a8\u7f51\u683c\u6a21\u578b\uff0c\u4e0d\u9700\u8981\u5149\u7ebf\u6295\u5c04\uff0c\u8ba1\u7b97\u91cf\u66f4\u5c0f\u3002\u8fd8\u5206\u6790\u4e86\u4e24\u79cd\u6a21\u578b\u7684\u59ff\u6001\u53ef\u89c2\u6d4b\u6027\u7279\u6027\u3002", "result": "\u70b9\u4e91\u6d4b\u91cf\u5728\u5bfc\u822a\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u96f7\u8fbe\u9ad8\u5ea6\u8ba1\uff0c\u4e14\u4e24\u79cd\u70b9\u4e91\u6d4b\u91cf\u6a21\u578b\u7684\u9009\u62e9\u53d6\u51b3\u4e8e\u8ba1\u7b97\u8d44\u6e90\u3002\u6ed1\u52a8\u7f51\u683c\u6a21\u578b\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u70b9\u4e91\u6d4b\u91cf\u6bd4\u96f7\u8fbe\u9ad8\u5ea6\u8ba1\u6027\u80fd\u66f4\u597d\uff0c\u5177\u4f53\u4f7f\u7528\u54ea\u79cd\u70b9\u4e91\u6d4b\u91cf\u6a21\u578b\u5e94\u6839\u636e\u53ef\u7528\u8ba1\u7b97\u8d44\u6e90\u6765\u51b3\u5b9a\u3002"}}
{"id": "2510.06547", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.06547", "abs": "https://arxiv.org/abs/2510.06547", "authors": ["Christopher Martin", "Apurva Patil", "Wei Li", "Takashi Tanaka", "Dongmei Chen"], "title": "Model Predictive Path Integral Control for Roll-to-Roll Manufacturing", "comment": "6 pages, 4 figures", "summary": "Roll-to-roll (R2R) manufacturing is a continuous processing technology\nessential for scalable production of thin-film materials and printed\nelectronics, but precise control remains challenging due to subsystem\ninteractions, nonlinearities, and process disturbances. This paper proposes a\nModel Predictive Path Integral (MPPI) control formulation for R2R systems,\nleveraging a GPU-based Monte-Carlo sampling approach to efficiently approximate\noptimal controls online. Crucially, MPPI easily handles non-differentiable cost\nfunctions, enabling the incorporation of complex performance criteria relevant\nto advanced manufacturing processes. A case study is presented that\ndemonstrates that MPPI significantly improves tension regulation performance\ncompared to conventional model predictive control (MPC), highlighting its\nsuitability for real-time control in advanced manufacturing.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGPU\u7684\u6a21\u578b\u9884\u6d4b\u8def\u5f84\u79ef\u5206(MPPI)\u63a7\u5236\u65b9\u6cd5\uff0c\u7528\u4e8e\u6eda\u5bf9\u6eda(R2R)\u5236\u9020\u7cfb\u7edf\uff0c\u76f8\u6bd4\u4f20\u7edf\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u663e\u8457\u63d0\u5347\u4e86\u5f20\u529b\u8c03\u8282\u6027\u80fd\u3002", "motivation": "\u6eda\u5bf9\u6eda\u5236\u9020\u662f\u8584\u819c\u6750\u6599\u548c\u5370\u5237\u7535\u5b50\u4ea7\u54c1\u89c4\u6a21\u5316\u751f\u4ea7\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u7531\u4e8e\u5b50\u7cfb\u7edf\u4ea4\u4e92\u3001\u975e\u7ebf\u6027\u548c\u8fc7\u7a0b\u6270\u52a8\u7b49\u56e0\u7d20\uff0c\u7cbe\u786e\u63a7\u5236\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8eGPU\u7684\u8499\u7279\u5361\u6d1b\u91c7\u6837\u65b9\u6cd5\u5728\u7ebf\u9ad8\u6548\u903c\u8fd1\u6700\u4f18\u63a7\u5236\uff0cMPPI\u80fd\u591f\u8f7b\u677e\u5904\u7406\u4e0d\u53ef\u5fae\u6210\u672c\u51fd\u6570\uff0c\u4fbf\u4e8e\u878d\u5165\u590d\u6742\u5236\u9020\u8fc7\u7a0b\u7684\u76f8\u5173\u6027\u80fd\u6807\u51c6\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cMPPI\u76f8\u6bd4\u4f20\u7edf\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u663e\u8457\u63d0\u9ad8\u4e86\u5f20\u529b\u8c03\u8282\u6027\u80fd\u3002", "conclusion": "MPPI\u63a7\u5236\u65b9\u6cd5\u9002\u7528\u4e8e\u5148\u8fdb\u5236\u9020\u4e2d\u7684\u5b9e\u65f6\u63a7\u5236\u9700\u6c42\u3002"}}
{"id": "2510.06253", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06253", "abs": "https://arxiv.org/abs/2510.06253", "authors": ["Yong Oh Lee", "Byeonghun Bang", "Sejun Oh"], "title": "LLM-Driven Rubric-Based Assessment of Algebraic Competence in Multi-Stage Block Coding Tasks with Design and Field Evaluation", "comment": null, "summary": "As online education platforms continue to expand, there is a growing need for\nassessment methods that not only measure answer accuracy but also capture the\ndepth of students' cognitive processes in alignment with curriculum objectives.\nThis study proposes and evaluates a rubric-based assessment framework powered\nby a large language model (LLM) for measuring algebraic competence,\nreal-world-context block coding tasks. The problem set, designed by mathematics\neducation experts, aligns each problem segment with five predefined rubric\ndimensions, enabling the LLM to assess both correctness and quality of\nstudents' problem-solving processes. The system was implemented on an online\nplatform that records all intermediate responses and employs the LLM for\nrubric-aligned achievement evaluation. To examine the practical effectiveness\nof the proposed framework, we conducted a field study involving 42 middle\nschool students engaged in multi-stage quadratic equation tasks with block\ncoding. The study integrated learner self-assessments and expert ratings to\nbenchmark the system's outputs. The LLM-based rubric evaluation showed strong\nagreement with expert judgments and consistently produced rubric-aligned,\nprocess-oriented feedback. These results demonstrate both the validity and\nscalability of incorporating LLM-driven rubric assessment into online\nmathematics and STEM education platforms.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u5206\u6807\u51c6\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u7ebf\u6559\u80b2\u5e73\u53f0\u4e2d\u6d4b\u91cf\u4ee3\u6570\u80fd\u529b\u548c\u771f\u5b9e\u60c5\u5883\u4e0b\u7684\u79ef\u6728\u7f16\u7a0b\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u5728\u7ebf\u6559\u80b2\u5e73\u53f0\u7684\u6269\u5c55\uff0c\u9700\u8981\u80fd\u591f\u540c\u65f6\u8bc4\u4f30\u7b54\u6848\u51c6\u786e\u6027\u548c\u5b66\u751f\u8ba4\u77e5\u8fc7\u7a0b\u6df1\u5ea6\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ee5\u7b26\u5408\u8bfe\u7a0b\u76ee\u6807\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eLLM\u7684\u8bc4\u5206\u6807\u51c6\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u95ee\u9898\u7247\u6bb5\u4e0e\u4e94\u4e2a\u9884\u5b9a\u4e49\u8bc4\u5206\u7ef4\u5ea6\u5bf9\u9f50\uff0c\u5728\u8bb0\u5f55\u6240\u6709\u4e2d\u95f4\u54cd\u5e94\u7684\u5728\u7ebf\u5e73\u53f0\u4e0a\u5b9e\u65bd\uff0c\u5e76\u901a\u8fc742\u540d\u4e2d\u5b66\u751f\u7684\u5b9e\u5730\u7814\u7a76\u9a8c\u8bc1\u6548\u679c\u3002", "result": "LLM\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u4f30\u4e0e\u4e13\u5bb6\u5224\u65ad\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5e76\u6301\u7eed\u4ea7\u751f\u7b26\u5408\u8bc4\u5206\u6807\u51c6\u3001\u9762\u5411\u8fc7\u7a0b\u7684\u53cd\u9988\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\u5c06LLM\u9a71\u52a8\u7684\u8bc4\u5206\u6807\u51c6\u8bc4\u4f30\u6574\u5408\u5230\u5728\u7ebf\u6570\u5b66\u548cSTEM\u6559\u80b2\u5e73\u53f0\u4e2d\u5177\u6709\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2510.06416", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.06416", "abs": "https://arxiv.org/abs/2510.06416", "authors": ["Xiyuan Ren", "Zhenglei Ji", "Joseph Y. J. Chow"], "title": "Distributional welfare impacts and compensatory transit strategies under NYC congestion pricing", "comment": null, "summary": "Early evaluations of NYC's congestion pricing program indicate overall\nimprovements in vehicle speed and transit ridership. However, its\ndistributional impacts remain understudied, as does the design of compensatory\ntransit strategies to mitigate potential welfare losses. This study identifies\npopulation segments and regions most affected by congestion pricing, and\nevaluates how welfare losses can be compensated through transit improvements.\nWe estimate joint mode and destination models using aggregated synthetic trips\nin New York and New Jersey and calibrate toll-related parameters with traffic\ncounts reported by the MTA. The results show that the program leads to an\naccessibility-related welfare loss of approximately $240 million per year,\nwhich is considerably lower than the gains from toll revenues: the gross\nrevenue estimated by our models ($1.077 billion per year) and the net revenue\nprojected by the MTA ($450 million per year). However, these benefits gains\nconceal significant disparities. Welfare losses are concentrated in Upper\nManhattan, Brooklyn, and Hudson County, NJ, particularly among travelers less\nable to shift to transit or alternative destinations. For NYC residents,\ncompensating aggregate welfare loss requires a 0.48-minute reduction in transit\nwait time or a $135.59 million annual fare subsidy. Ensuring accessibility\ngains for all populations and counties (Pareto improving) requires a 1-2 minute\nreduction in wait time combined with an annual subsidy of about $100-300\nmillion. For New Jersey residents, achieving aggregate welfare gains primarily\nthrough fare discounts (requiring $108.53 million per year) is more feasible\nand efficient; however, uniform discounts should be replaced by targeted\nmechanisms such as origin-based fare reductions or commuter pass bundles.", "AI": {"tldr": "\u7ebd\u7ea6\u62e5\u5835\u6536\u8d39\u9879\u76ee\u6539\u5584\u4e86\u4ea4\u901a\u901f\u5ea6\u4f46\u5b58\u5728\u5206\u914d\u4e0d\u5747\u95ee\u9898\uff0c\u7814\u7a76\u901a\u8fc7\u5efa\u6a21\u5206\u6790\u53d1\u73b0\u798f\u5229\u635f\u5931\u96c6\u4e2d\u5728\u7279\u5b9a\u533a\u57df\u548c\u4eba\u7fa4\uff0c\u63d0\u51fa\u4e86\u901a\u8fc7\u6539\u5584\u516c\u5171\u4ea4\u901a\u6765\u8865\u507f\u7684\u5177\u4f53\u65b9\u6848\u3002", "motivation": "\u7814\u7a76\u7ebd\u7ea6\u62e5\u5835\u6536\u8d39\u9879\u76ee\u7684\u5206\u914d\u5f71\u54cd\u548c\u8865\u507f\u7b56\u7565\uff0c\u56e0\u4e3a\u73b0\u6709\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u6574\u4f53\u6548\u76ca\uff0c\u800c\u5ffd\u89c6\u4e86\u4e0d\u540c\u4eba\u7fa4\u548c\u5730\u533a\u7684\u798f\u5229\u635f\u5931\u5dee\u5f02\u3002", "method": "\u4f7f\u7528\u7ebd\u7ea6\u548c\u65b0\u6cfd\u897f\u7684\u5408\u6210\u51fa\u884c\u6570\u636e\u5efa\u7acb\u8054\u5408\u6a21\u5f0f\u548c\u76ee\u7684\u5730\u6a21\u578b\uff0c\u5e76\u7528MTA\u62a5\u544a\u7684\u4ea4\u901a\u8ba1\u6570\u6570\u636e\u6821\u51c6\u6536\u8d39\u76f8\u5173\u53c2\u6570\u3002", "result": "\u9879\u76ee\u5bfc\u81f4\u6bcf\u5e74\u7ea62.4\u4ebf\u7f8e\u5143\u7684\u798f\u5229\u635f\u5931\uff0c\u4f46\u8fdc\u4f4e\u4e8e\u6536\u8d39\u6536\u5165\u3002\u798f\u5229\u635f\u5931\u96c6\u4e2d\u5728\u66fc\u54c8\u987f\u4e0a\u57ce\u3001\u5e03\u9c81\u514b\u6797\u548c\u65b0\u6cfd\u897f\u54c8\u5fb7\u900a\u53bf\uff0c\u7279\u522b\u662f\u96be\u4ee5\u8f6c\u5411\u516c\u5171\u4ea4\u901a\u7684\u4eba\u7fa4\u3002", "conclusion": "\u9700\u8981\u901a\u8fc7\u6709\u9488\u5bf9\u6027\u7684\u516c\u5171\u4ea4\u901a\u6539\u5584\u6765\u8865\u507f\u798f\u5229\u635f\u5931\uff0c\u5982\u51cf\u5c11\u7b49\u5f85\u65f6\u95f4\u6216\u63d0\u4f9b\u7968\u4ef7\u8865\u8d34\uff0c\u5bf9\u7ebd\u7ea6\u5c45\u6c11\u9700\u89810.48\u5206\u949f\u7b49\u5f85\u65f6\u95f4\u51cf\u5c11\u62161.36\u4ebf\u7f8e\u5143\u5e74\u8865\u8d34\uff0c\u5bf9\u65b0\u6cfd\u897f\u5c45\u6c11\u5219\u66f4\u9002\u5408\u7968\u4ef7\u6298\u6263\u65b9\u6848\u3002"}}
{"id": "2510.06264", "categories": ["stat.AP", "cs.CY", "cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.06264", "abs": "https://arxiv.org/abs/2510.06264", "authors": ["Md. Saiful Bari Siddiqui", "Anupam Debashis Roy"], "title": "A Mixed-Methods Analysis of Repression and Mobilization in Bangladesh's July Revolution Using Machine Learning and Statistical Modeling", "comment": "Submitted to Social Forces. Final version may vary from this preprint", "summary": "The 2024 July Revolution in Bangladesh represents a landmark event in the\nstudy of civil resistance. This study investigates the central paradox of the\nsuccess of this student-led civilian uprising: how state violence, intended to\nquell dissent, ultimately fueled the movement's victory. We employ a\nmixed-methods approach. First, we develop a qualitative narrative of the\nconflict's timeline to generate specific, testable hypotheses. Then, using a\ndisaggregated, event-level dataset, we employ a multi-method quantitative\nanalysis to dissect the complex relationship between repression and\nmobilisation. We provide a framework to analyse explosive modern uprisings like\nthe July Revolution. Initial pooled regression models highlight the crucial\nrole of protest momentum in sustaining the movement. To isolate causal effects,\nwe specify a Two-Way Fixed Effects panel model, which provides robust evidence\nfor a direct and statistically significant local suppression backfire effect.\nOur Vector Autoregression (VAR) analysis provides clear visual evidence of an\nimmediate, nationwide mobilisation in response to increased lethal violence. We\nfurther demonstrate that this effect was non-linear. A structural break\nanalysis reveals that the backfire dynamic was statistically insignificant in\nthe conflict's early phase but was triggered by the catalytic moral shock of\nthe first wave of lethal violence, and its visuals circulated around July 16th.\nA complementary machine learning analysis (XGBoost, out-of-sample R$^{2}$=0.65)\ncorroborates this from a predictive standpoint, identifying \"excessive force\nagainst protesters\" as the single most dominant predictor of nationwide\nescalation. We conclude that the July Revolution was driven by a contingent,\nnon-linear backfire, triggered by specific catalytic moral shocks and\naccelerated by the viral reaction to the visual spectacle of state brutality.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e862024\u5e74\u5b5f\u52a0\u62c9\u56fd\u4e03\u6708\u9769\u547d\u4e2d\u653f\u5e9c\u66b4\u529b\u9547\u538b\u5982\u4f55\u9002\u5f97\u5176\u53cd\uff0c\u53cd\u800c\u63a8\u52a8\u4e86\u5b66\u751f\u4e3b\u5bfc\u7684\u516c\u6c11\u8d77\u4e49\u7684\u6210\u529f\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u81f4\u547d\u7684\u66b4\u529b\u9547\u538b\u5f15\u53d1\u4e86\u5168\u56fd\u8303\u56f4\u7684\u52a8\u5458\uff0c\u8fd9\u79cd\u53cd\u6548\u679c\u662f\u975e\u7ebf\u6027\u7684\uff0c\u7531\u7279\u5b9a\u7684\u9053\u5fb7\u51b2\u51fb\u89e6\u53d1\u5e76\u901a\u8fc7\u89c6\u89c9\u4f20\u64ad\u52a0\u901f\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u91ca\u4e03\u6708\u9769\u547d\u4e2d\u7684\u6838\u5fc3\u6096\u8bba\uff1a\u4e3a\u4f55\u653f\u5e9c\u65e8\u5728\u538b\u5236\u5f02\u8bae\u7684\u66b4\u529b\u9547\u538b\u6700\u7ec8\u53cd\u800c\u63a8\u52a8\u4e86\u8fd0\u52a8\u7684\u80dc\u5229\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a\u9996\u5148\u5efa\u7acb\u51b2\u7a81\u65f6\u95f4\u7ebf\u7684\u5b9a\u6027\u53d9\u8ff0\u4ee5\u751f\u6210\u53ef\u68c0\u9a8c\u5047\u8bbe\uff0c\u7136\u540e\u4f7f\u7528\u4e8b\u4ef6\u7ea7\u6570\u636e\u96c6\u8fdb\u884c\u591a\u65b9\u6cd5\u5b9a\u91cf\u5206\u6790\uff0c\u5305\u62ec\u53cc\u5411\u56fa\u5b9a\u6548\u5e94\u9762\u677f\u6a21\u578b\u3001\u5411\u91cf\u81ea\u56de\u5f52\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5b58\u5728\u663e\u8457\u7684\u672c\u5730\u9547\u538b\u53cd\u6548\u679c\uff0c\u81f4\u547d\u66b4\u529b\u589e\u52a0\u4f1a\u7acb\u5373\u5f15\u53d1\u5168\u56fd\u8303\u56f4\u7684\u52a8\u5458\u3002\u8fd9\u79cd\u53cd\u6548\u679c\u662f\u975e\u7ebf\u6027\u7684\uff0c\u5728\u51b2\u7a81\u65e9\u671f\u4e0d\u663e\u8457\uff0c\u4f46\u57287\u670816\u65e5\u7b2c\u4e00\u6ce2\u81f4\u547d\u66b4\u529b\u53ca\u5176\u89c6\u89c9\u4f20\u64ad\u540e\u89e6\u53d1\u3002\u673a\u5668\u5b66\u4e60\u5206\u6790\u786e\u8ba4\"\u5bf9\u6297\u8bae\u8005\u8fc7\u5ea6\u4f7f\u7528\u6b66\u529b\"\u662f\u5168\u56fd\u8303\u56f4\u5347\u7ea7\u7684\u6700\u4e3b\u8981\u9884\u6d4b\u56e0\u5b50\u3002", "conclusion": "\u4e03\u6708\u9769\u547d\u662f\u7531\u5076\u7136\u7684\u3001\u975e\u7ebf\u6027\u7684\u53cd\u6548\u679c\u9a71\u52a8\u7684\uff0c\u7531\u7279\u5b9a\u7684\u50ac\u5316\u6027\u9053\u5fb7\u51b2\u51fb\u89e6\u53d1\uff0c\u5e76\u901a\u8fc7\u56fd\u5bb6\u66b4\u529b\u7684\u89c6\u89c9\u5947\u89c2\u7684\u75c5\u6bd2\u5f0f\u4f20\u64ad\u800c\u52a0\u901f\u3002"}}
{"id": "2510.07180", "categories": ["econ.EM", "cs.LG", "q-fin.CP", "q-fin.PM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.07180", "abs": "https://arxiv.org/abs/2510.07180", "authors": ["Masahiro Kato", "Kentaro Baba", "Hibiki Kaibuchi", "Ryo Inokuchi"], "title": "Bayesian Portfolio Optimization by Predictive Synthesis", "comment": null, "summary": "Portfolio optimization is a critical task in investment. Most existing\nportfolio optimization methods require information on the distribution of\nreturns of the assets that make up the portfolio. However, such distribution\ninformation is usually unknown to investors. Various methods have been proposed\nto estimate distribution information, but their accuracy greatly depends on the\nuncertainty of the financial markets. Due to this uncertainty, a model that\ncould well predict the distribution information at one point in time may\nperform less accurately compared to another model at a different time. To solve\nthis problem, we investigate a method for portfolio optimization based on\nBayesian predictive synthesis (BPS), one of the Bayesian ensemble methods for\nmeta-learning. We assume that investors have access to multiple asset return\nprediction models. By using BPS with dynamic linear models to combine these\npredictions, we can obtain a Bayesian predictive posterior about the mean\nrewards of assets that accommodate the uncertainty of the financial markets. In\nthis study, we examine how to construct mean-variance portfolios and\nquantile-based portfolios based on the predicted distribution information.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u9884\u6d4b\u5408\u6210(BPS)\u7684\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u96c6\u6210\u591a\u4e2a\u8d44\u4ea7\u6536\u76ca\u9884\u6d4b\u6a21\u578b\u6765\u5e94\u5bf9\u91d1\u878d\u5e02\u573a\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u65b9\u6cd5\u9700\u8981\u8d44\u4ea7\u6536\u76ca\u5206\u5e03\u4fe1\u606f\uff0c\u4f46\u8fd9\u4e9b\u4fe1\u606f\u901a\u5e38\u672a\u77e5\u4e14\u96be\u4ee5\u51c6\u786e\u4f30\u8ba1\uff0c\u91d1\u878d\u5e02\u573a\u7684\u65f6\u53d8\u4e0d\u786e\u5b9a\u6027\u4f7f\u5f97\u5355\u4e00\u6a21\u578b\u9884\u6d4b\u6548\u679c\u4e0d\u7a33\u5b9a\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u9884\u6d4b\u5408\u6210(BPS)\u7ed3\u5408\u52a8\u6001\u7ebf\u6027\u6a21\u578b\u6765\u96c6\u6210\u591a\u4e2a\u8d44\u4ea7\u6536\u76ca\u9884\u6d4b\u6a21\u578b\uff0c\u83b7\u5f97\u8003\u8651\u5e02\u573a\u4e0d\u786e\u5b9a\u6027\u7684\u8d1d\u53f6\u65af\u9884\u6d4b\u540e\u9a8c\u5206\u5e03\u3002", "result": "\u57fa\u4e8e\u9884\u6d4b\u5206\u5e03\u4fe1\u606f\u6784\u5efa\u4e86\u5747\u503c-\u65b9\u5dee\u6295\u8d44\u7ec4\u5408\u548c\u57fa\u4e8e\u5206\u4f4d\u6570\u7684\u6295\u8d44\u7ec4\u5408\u3002", "conclusion": "BPS\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u96c6\u6210\u591a\u4e2a\u9884\u6d4b\u6a21\u578b\uff0c\u4e3a\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u8d44\u4ea7\u6536\u76ca\u5206\u5e03\u4f30\u8ba1\uff0c\u9002\u5e94\u91d1\u878d\u5e02\u573a\u7684\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2510.06339", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.06339", "abs": "https://arxiv.org/abs/2510.06339", "authors": ["Leiyao Cui", "Zihang Zhao", "Sirui Xie", "Wenhuan Zhang", "Zhi Han", "Yixin Zhu"], "title": "Vi-TacMan: Articulated Object Manipulation via Vision and Touch", "comment": null, "summary": "Autonomous manipulation of articulated objects remains a fundamental\nchallenge for robots in human environments. Vision-based methods can infer\nhidden kinematics but can yield imprecise estimates on unfamiliar objects.\nTactile approaches achieve robust control through contact feedback but require\naccurate initialization. This suggests a natural synergy: vision for global\nguidance, touch for local precision. Yet no framework systematically exploits\nthis complementarity for generalized articulated manipulation. Here we present\nVi-TacMan, which uses vision to propose grasps and coarse directions that seed\na tactile controller for precise execution. By incorporating surface normals as\ngeometric priors and modeling directions via von Mises-Fisher distributions,\nour approach achieves significant gains over baselines (all p<0.0001).\nCritically, manipulation succeeds without explicit kinematic models -- the\ntactile controller refines coarse visual estimates through real-time contact\nregulation. Tests on more than 50,000 simulated and diverse real-world objects\nconfirm robust cross-category generalization. This work establishes that coarse\nvisual cues suffice for reliable manipulation when coupled with tactile\nfeedback, offering a scalable paradigm for autonomous systems in unstructured\nenvironments.", "AI": {"tldr": "Vi-TacMan\u7ed3\u5408\u89c6\u89c9\u548c\u89e6\u89c9\u8fdb\u884c\u5173\u8282\u7269\u4f53\u64cd\u4f5c\uff1a\u89c6\u89c9\u63d0\u4f9b\u5168\u5c40\u6293\u53d6\u5efa\u8bae\u548c\u7c97\u7565\u65b9\u5411\uff0c\u89e6\u89c9\u63a7\u5236\u5668\u8fdb\u884c\u7cbe\u786e\u6267\u884c\uff0c\u65e0\u9700\u663e\u5f0f\u8fd0\u52a8\u5b66\u6a21\u578b\u3002", "motivation": "\u89c6\u89c9\u65b9\u6cd5\u80fd\u63a8\u65ad\u9690\u85cf\u8fd0\u52a8\u5b66\u4f46\u4e0d\u7cbe\u786e\uff0c\u89e6\u89c9\u65b9\u6cd5\u901a\u8fc7\u63a5\u89e6\u53cd\u9988\u5b9e\u73b0\u9c81\u68d2\u63a7\u5236\u4f46\u9700\u8981\u51c6\u786e\u521d\u59cb\u5316\uff0c\u4e24\u8005\u5177\u6709\u4e92\u8865\u6027\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u5316\u878d\u5408\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u89c6\u89c9\u63d0\u51fa\u6293\u53d6\u548c\u7c97\u7565\u65b9\u5411\u4f5c\u4e3a\u89e6\u89c9\u63a7\u5236\u5668\u7684\u79cd\u5b50\uff0c\u7ed3\u5408\u8868\u9762\u6cd5\u7ebf\u4f5c\u4e3a\u51e0\u4f55\u5148\u9a8c\uff0c\u901a\u8fc7von Mises-Fisher\u5206\u5e03\u5efa\u6a21\u65b9\u5411\uff0c\u89e6\u89c9\u63a7\u5236\u5668\u901a\u8fc7\u5b9e\u65f6\u63a5\u89e6\u8c03\u8282\u7ec6\u5316\u89c6\u89c9\u4f30\u8ba1\u3002", "result": "\u5728\u8d85\u8fc750,000\u4e2a\u6a21\u62df\u548c\u771f\u5b9e\u7269\u4f53\u4e0a\u6d4b\u8bd5\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\uff08\u6240\u6709p<0.0001\uff09\uff0c\u5b9e\u73b0\u8de8\u7c7b\u522b\u7684\u9c81\u68d2\u6cdb\u5316\u3002", "conclusion": "\u7c97\u7c92\u5ea6\u89c6\u89c9\u7ebf\u7d22\u7ed3\u5408\u89e6\u89c9\u53cd\u9988\u8db3\u4ee5\u5b9e\u73b0\u53ef\u9760\u64cd\u4f5c\uff0c\u4e3a\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u8303\u5f0f\u3002"}}
{"id": "2510.06245", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06245", "abs": "https://arxiv.org/abs/2510.06245", "authors": ["Laurent Brisson", "C\u00e9cile Bothorel", "Nicolas Duminy"], "title": "DynBenchmark: Customizable Ground Truths to Benchmark Community Detection and Tracking in Temporal Networks", "comment": null, "summary": "Graph models help understand network dynamics and evolution. Creating graphs\nwith controlled topology and embedded partitions is a common strategy for\nevaluating community detection algorithms. However, existing benchmarks often\noverlook the need to track the evolution of communities in real-world networks.\nTo address this, a new community-centered model is proposed to generate\ncustomizable evolving community structures where communities can grow, shrink,\nmerge, split, appear or disappear. This benchmark also generates the underlying\ntemporal network, where nodes can appear, disappear, or move between\ncommunities. The benchmark has been used to test three methods, measuring their\nperformance in tracking nodes' cluster membership and detecting community\nevolution. Python libraries, drawing utilities, and validation metrics are\nprovided to compare ground truth with algorithm results for detecting dynamic\ncommunities.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u793e\u533a\u4e2d\u5fc3\u6a21\u578b\uff0c\u7528\u4e8e\u751f\u6210\u53ef\u81ea\u5b9a\u4e49\u7684\u6f14\u5316\u793e\u533a\u7ed3\u6784\uff0c\u5e76\u6d4b\u8bd5\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\u5728\u8ddf\u8e2a\u52a8\u6001\u793e\u533a\u65b9\u9762\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5f80\u5f80\u5ffd\u89c6\u8ddf\u8e2a\u771f\u5b9e\u7f51\u7edc\u4e2d\u793e\u533a\u6f14\u5316\u7684\u9700\u6c42\uff0c\u9700\u8981\u80fd\u591f\u6a21\u62df\u793e\u533a\u589e\u957f\u3001\u6536\u7f29\u3001\u5408\u5e76\u3001\u5206\u88c2\u3001\u51fa\u73b0\u6216\u6d88\u5931\u7684\u57fa\u51c6\u6a21\u578b\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u793e\u533a\u4e2d\u5fc3\u6a21\u578b\uff0c\u751f\u6210\u53ef\u81ea\u5b9a\u4e49\u7684\u6f14\u5316\u793e\u533a\u7ed3\u6784\uff0c\u540c\u65f6\u751f\u6210\u5e95\u5c42\u65f6\u5e8f\u7f51\u7edc\uff0c\u5176\u4e2d\u8282\u70b9\u53ef\u4ee5\u51fa\u73b0\u3001\u6d88\u5931\u6216\u5728\u793e\u533a\u95f4\u79fb\u52a8\u3002", "result": "\u8be5\u57fa\u51c6\u5df2\u7528\u4e8e\u6d4b\u8bd5\u4e09\u79cd\u65b9\u6cd5\uff0c\u6d4b\u91cf\u5b83\u4eec\u5728\u8ddf\u8e2a\u8282\u70b9\u805a\u7c7b\u6210\u5458\u8d44\u683c\u548c\u68c0\u6d4b\u793e\u533a\u6f14\u5316\u65b9\u9762\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u4f9b\u4e86Python\u5e93\u3001\u7ed8\u56fe\u5de5\u5177\u548c\u9a8c\u8bc1\u6307\u6807\uff0c\u7528\u4e8e\u6bd4\u8f83\u771f\u5b9e\u60c5\u51b5\u4e0e\u7b97\u6cd5\u5728\u68c0\u6d4b\u52a8\u6001\u793e\u533a\u65b9\u9762\u7684\u7ed3\u679c\u3002"}}
{"id": "2510.06413", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2510.06413", "abs": "https://arxiv.org/abs/2510.06413", "authors": ["Yuqi Zhang", "Yuxin Yang", "Feixiong Chen", "Cheng-Chang Lu", "Nima Saeidi", "Samuel L. Volchenboum", "Junhan Zhao", "Siwei Chen", "Weiwen Jiang", "Qiang Guan"], "title": "A Hybrid Quantum-AI Framework for Protein Structure Prediction on NISQ Devices", "comment": "20 pages, 6 figures", "summary": "Variational quantum algorithms provide a direct, physics-based approach to\nprotein structure prediction, but their accuracy is limited by the coarse\nresolution of the energy landscapes generated on current noisy devices. We\npropose a hybrid framework that combines quantum computation with deep\nlearning, formulating structure prediction as a problem of energy fusion.\nCandidate conformations are obtained through the Variational Quantum\nEigensolver (VQE) executed on IBM's 127-qubit superconducting processor, which\ndefines a global yet low-resolution quantum energy surface. To refine these\nbasins, secondary structure probabilities and dihedral angle distributions\npredicted by the NSP3 neural network are incorporated as statistical\npotentials. These additional terms sharpen the valleys of the quantum\nlandscape, resulting in a fused energy function that enhances effective\nresolution and better distinguishes native-like structures. Evaluation on 375\nconformations from 75 protein fragments shows consistent improvements over\nAlphaFold3, ColabFold, and quantum-only predictions, achieving a mean RMSD of\n4.9 {\\AA} with statistical significance (p < 0.001). The findings demonstrate\nthat energy fusion offers a systematic method for combining data-driven models\nwith quantum algorithms, improving the practical applicability of near-term\nquantum computing to molecular and structural biology.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u6df7\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u80fd\u91cf\u878d\u5408\u65b9\u6cd5\u6539\u8fdb\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\u5728\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\u4e2d\u53d7\u9650\u4e8e\u5f53\u524d\u566a\u58f0\u8bbe\u5907\u751f\u6210\u7684\u80fd\u91cf\u666f\u89c2\u5206\u8fa8\u7387\u8f83\u4f4e\uff0c\u9700\u8981\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u3002", "method": "\u4f7f\u7528IBM 127\u91cf\u5b50\u4f4d\u8d85\u5bfc\u5904\u7406\u5668\u4e0a\u7684VQE\u7b97\u6cd5\u83b7\u5f97\u5019\u9009\u6784\u8c61\uff0c\u7ed3\u5408NSP3\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u7684\u4e8c\u7ea7\u7ed3\u6784\u6982\u7387\u548c\u4e8c\u9762\u89d2\u5206\u5e03\u4f5c\u4e3a\u7edf\u8ba1\u52bf\u80fd\uff0c\u901a\u8fc7\u80fd\u91cf\u878d\u5408\u65b9\u6cd5\u9510\u5316\u91cf\u5b50\u666f\u89c2\u3002", "result": "\u572875\u4e2a\u86cb\u767d\u8d28\u7247\u6bb5\u7684375\u4e2a\u6784\u8c61\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4AlphaFold3\u3001ColabFold\u548c\u7eaf\u91cf\u5b50\u9884\u6d4b\u6709\u663e\u8457\u6539\u8fdb\uff0c\u5e73\u5747RMSD\u8fbe\u52304.9\u00c5\uff08p < 0.001\uff09\u3002", "conclusion": "\u80fd\u91cf\u878d\u5408\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\uff0c\u5c06\u6570\u636e\u9a71\u52a8\u6a21\u578b\u4e0e\u91cf\u5b50\u7b97\u6cd5\u7ed3\u5408\uff0c\u63d0\u9ad8\u4e86\u8fd1\u671f\u91cf\u5b50\u8ba1\u7b97\u5728\u5206\u5b50\u548c\u7ed3\u6784\u751f\u7269\u5b66\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6027\u3002"}}
{"id": "2510.06556", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.06556", "abs": "https://arxiv.org/abs/2510.06556", "authors": ["Abdelhafid Khazzar", "Yassine Sekaki", "Yasser Lachhab", "Said El-marzouki"], "title": "Artificial Intelligence in Port Logistics: A Bibliometric Analysis of Technological Integration and Research Dynamics", "comment": null, "summary": "The paper explores the transformation of port logistics operations with\nartificial intelligence during the port transformation into a smart port. The\nresearch integrates capabilities-based resource analysis and dynamic\ncapabilities with sociotechnicalimplementations of technologies and resilience\napproaches of complex systems under disruptions. The system applies robustdata\ninfrastructures to propel analytical and AI modules that become effective once\nintegrated with sufficient governance systems and trained personnel and\noperational processes to transform planning and safety and sustainability\noperations.It applies Scopus bibliometric research to analyze 123 articles\nusing a systematic approach with both a search protocol and a document\nscreening and duplication verification. It incorporates annual behavior and\ndistribution of author and country performance analysis with science mapping\ntechniques that explore keyword relation and co-citation and bibliographic\ncoupling and conceptual structuring tools that construct thematic maps and\nmultiple correspondence analysis with community detection while applying\nexplicit thresholding and robust tests.The research connects AI applications to\nsmart port domains through specific data-to-impact pathways while providing a\nmethod for bibliometric analysis that enables future updates. The research\npresents a step-by-step approach for data readiness followed by predictive and\noptimization implementation and organizational integration. The paper supports\npublic policy through recommendations for data sharing standards and complete\nenvironmental benefit assessments. The research proposes a future study plan\nwhichcombines field-based testing with multiple port assessments to enhance\nboth cause-effect understanding and research applicability.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u6e2f\u53e3\u5411\u667a\u6167\u6e2f\u53e3\u8f6c\u578b\u8fc7\u7a0b\u4e2d\u5bf9\u7269\u6d41\u8fd0\u8425\u7684\u53d8\u9769\uff0c\u901a\u8fc7\u6587\u732e\u8ba1\u91cf\u5206\u6790123\u7bc7\u76f8\u5173\u6587\u732e\uff0c\u63d0\u51fa\u4e86\u4ece\u6570\u636e\u51c6\u5907\u5230\u9884\u6d4b\u4f18\u5316\u518d\u5230\u7ec4\u7ec7\u6574\u5408\u7684\u5b9e\u65bd\u8def\u5f84\uff0c\u5e76\u4e3a\u516c\u5171\u653f\u7b56\u63d0\u4f9b\u5efa\u8bae\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4eba\u5de5\u667a\u80fd\u5982\u4f55\u63a8\u52a8\u6e2f\u53e3\u7269\u6d41\u8fd0\u8425\u7684\u667a\u80fd\u5316\u8f6c\u578b\uff0c\u7279\u522b\u662f\u5728\u667a\u6167\u6e2f\u53e3\u5efa\u8bbe\u80cc\u666f\u4e0b\uff0c\u6574\u5408\u8d44\u6e90\u5206\u6790\u3001\u52a8\u6001\u80fd\u529b\u548c\u793e\u4f1a\u6280\u672f\u5b9e\u65bd\uff0c\u4ee5\u589e\u5f3a\u7cfb\u7edf\u5728\u5e72\u6270\u4e0b\u7684\u97e7\u6027\u3002", "method": "\u91c7\u7528Scopus\u6587\u732e\u8ba1\u91cf\u7814\u7a76\u65b9\u6cd5\uff0c\u7cfb\u7edf\u5206\u6790123\u7bc7\u6587\u7ae0\uff0c\u5305\u62ec\u641c\u7d22\u534f\u8bae\u3001\u6587\u6863\u7b5b\u9009\u548c\u91cd\u590d\u9a8c\u8bc1\uff0c\u8fd0\u7528\u79d1\u5b66\u56fe\u8c31\u6280\u672f\u5206\u6790\u5173\u952e\u8bcd\u5173\u7cfb\u3001\u5171\u5f15\u3001\u6587\u732e\u8026\u5408\uff0c\u6784\u5efa\u4e3b\u9898\u5730\u56fe\u548c\u591a\u91cd\u5bf9\u5e94\u5206\u6790\u3002", "result": "\u7814\u7a76\u5efa\u7acb\u4e86AI\u5e94\u7528\u4e0e\u667a\u6167\u6e2f\u53e3\u9886\u57df\u7684\u5177\u4f53\u6570\u636e\u5230\u5f71\u54cd\u8def\u5f84\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u66f4\u65b0\u7684\u6587\u732e\u8ba1\u91cf\u5206\u6790\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4ece\u6570\u636e\u51c6\u5907\u5230\u9884\u6d4b\u4f18\u5316\u518d\u5230\u7ec4\u7ec7\u6574\u5408\u7684\u5206\u6b65\u5b9e\u65bd\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u4e3a\u516c\u5171\u653f\u7b56\u63d0\u4f9b\u4e86\u6570\u636e\u5171\u4eab\u6807\u51c6\u548c\u73af\u5883\u6548\u76ca\u8bc4\u4f30\u5efa\u8bae\uff0c\u5e76\u8ba1\u5212\u672a\u6765\u7ed3\u5408\u5b9e\u5730\u6d4b\u8bd5\u548c\u591a\u6e2f\u53e3\u8bc4\u4f30\uff0c\u4ee5\u589e\u5f3a\u56e0\u679c\u7406\u89e3\u548c\u7814\u7a76\u9002\u7528\u6027\u3002"}}
{"id": "2510.06261", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06261", "abs": "https://arxiv.org/abs/2510.06261", "authors": ["Zhanke Zhou", "Chentao Cao", "Xiao Feng", "Xuan Li", "Zongze Li", "Xiangyu Lu", "Jiangchao Yao", "Weikai Huang", "Linrui Xu", "Tian Cheng", "Guanyu Jiang", "Yiming Zheng", "Brando Miranda", "Tongliang Liu", "Sanmi Koyejo", "Masashi Sugiyama", "Bo Han"], "title": "AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning", "comment": "Ongoing project", "summary": "We present AlphaApollo, a self-evolving agentic reasoning system that aims to\naddress two bottlenecks in foundation model (FM) reasoning-limited\nmodel-intrinsic capacity and unreliable test-time iteration. AlphaApollo\norchestrates multiple models with professional tools to enable deliberate,\nverifiable reasoning. It couples (i) a computation tool (Python with numerical\nand symbolic libraries) and (ii) a retrieval tool (task-relevant external\ninformation) to execute exact calculations and ground decisions. The system\nfurther supports multi-round, multi-model solution evolution via a shared state\nmap that records candidates, executable checks, and feedback for iterative\nrefinement. In evaluations on AIME 2024/2025 across multiple models,\nAlphaApollo delivers consistent gains: +5.15% Average@32 and +23.34% Pass@32\nfor Qwen2.5-14B-Instruct, and +8.91% Average@32 with +26.67% Pass@32 for\nLlama-3.3-70B-Instruct. Tool-use analysis shows that more than 80% of tool\ncalls are successfully executed, with consistent outperformance of non-tool\nbaselines, thereby lifting the capability ceiling of FMs. More empirical\nresults and implementation details will be updated at\nhttps://github.com/tmlr-group/AlphaApollo.", "AI": {"tldr": "AlphaApollo\u662f\u4e00\u4e2a\u81ea\u6f14\u5316\u7684\u667a\u80fd\u63a8\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u591a\u4e2a\u6a21\u578b\u548c\u4e13\u4e1a\u5de5\u5177\u6765\u89e3\u51b3\u57fa\u7840\u6a21\u578b\u63a8\u7406\u80fd\u529b\u6709\u9650\u548c\u6d4b\u8bd5\u65f6\u8fed\u4ee3\u4e0d\u53ef\u9760\u7684\u95ee\u9898\uff0c\u5728AIME 2024/2025\u8bc4\u4f30\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u57fa\u7840\u6a21\u578b\u63a8\u7406\u80fd\u529b\u6709\u9650\u548c\u6d4b\u8bd5\u65f6\u8fed\u4ee3\u4e0d\u53ef\u9760\u4e24\u4e2a\u74f6\u9888\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u7684\u5b9e\u9645\u63a8\u7406\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u7f16\u6392\u591a\u4e2a\u6a21\u578b\u548c\u4e13\u4e1a\u5de5\u5177\u5b9e\u73b0\u6df1\u601d\u719f\u8651\u3001\u53ef\u9a8c\u8bc1\u7684\u63a8\u7406\uff0c\u7ed3\u5408\u8ba1\u7b97\u5de5\u5177\uff08Python\u6570\u503c\u548c\u7b26\u53f7\u5e93\uff09\u548c\u68c0\u7d22\u5de5\u5177\uff08\u4efb\u52a1\u76f8\u5173\u5916\u90e8\u4fe1\u606f\uff09\u6267\u884c\u7cbe\u786e\u8ba1\u7b97\u548c\u51b3\u7b56\u57fa\u7840\uff0c\u4f7f\u7528\u5171\u4eab\u72b6\u6001\u5730\u56fe\u652f\u6301\u591a\u8f6e\u591a\u6a21\u578b\u89e3\u51b3\u65b9\u6848\u6f14\u5316\u3002", "result": "\u5728AIME 2024/2025\u8bc4\u4f30\u4e2d\uff0cQwen2.5-14B-Instruct\u6a21\u578b\u83b7\u5f97+5.15% Average@32\u548c+23.34% Pass@32\u63d0\u5347\uff0cLlama-3.3-70B-Instruct\u6a21\u578b\u83b7\u5f97+8.91% Average@32\u548c+26.67% Pass@32\u63d0\u5347\uff0c\u8d85\u8fc780%\u7684\u5de5\u5177\u8c03\u7528\u6210\u529f\u6267\u884c\u3002", "conclusion": "AlphaApollo\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u63d0\u5347\u57fa\u7840\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u4e0a\u9650\uff0c\u901a\u8fc7\u5de5\u5177\u4f7f\u7528\u548c\u8fed\u4ee3\u4f18\u5316\u5b9e\u73b0\u6027\u80fd\u7684\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2510.06583", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.06583", "abs": "https://arxiv.org/abs/2510.06583", "authors": ["Xiaokan Yang", "Ding Zhang", "Wei Chen", "Li Qiu"], "title": "A Cascade of Systems and the Product of Their $\u03b8$-Symmetric Scaled Relative Graphs", "comment": "9 pages, 4 figures", "summary": "In this paper, we utilize a variant of the scaled relative graph (SRG),\nreferred to as the $\\theta$-symmetric SRG, to develop a graphical stability\ncriterion for the feedback interconnection of a cascade of systems. A crucial\nsubmultiplicative property of $\\theta$-symmetric SRG is established, enabling\nit to handle cyclic interconnections for which conventional graph separation\nmethods are not applicable. By integrating both gain and refined phase\ninformation, the $\\theta$-symmetric SRG provides a unified graphical\ncharacterization of the system, which better captures system properties and\nyields less conservative results. In the scalar case, the $\\theta$-symmetric\nSRG can be reduced exactly to the scalar itself, whereas the standard SRG\nappears to be a conjugate pair. Consequently, the frequency-wise\n$\\theta$-symmetric SRG is more suitable than the standard SRG as a multi-input\nmulti-output extension of the classical Nyquist plot. Illustrative examples are\nincluded to demonstrate the effectiveness of the $\\theta$-symmetric SRG.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u03b8\u5bf9\u79f0\u7f29\u653e\u76f8\u5bf9\u56fe\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u7ea7\u8054\u7cfb\u7edf\u7684\u53cd\u9988\u4e92\u8054\u7a33\u5b9a\u6027\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u80fd\u5904\u7406\u5faa\u73af\u4e92\u8054\u5e76\u63d0\u4f9b\u66f4\u4e0d\u4fdd\u5b88\u7684\u7ed3\u679c\u3002", "motivation": "\u4f20\u7edf\u56fe\u5f62\u5206\u79bb\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u5faa\u73af\u4e92\u8054\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u6574\u5408\u589e\u76ca\u548c\u76f8\u4f4d\u4fe1\u606f\u7684\u7edf\u4e00\u56fe\u5f62\u8868\u5f81\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u03b8\u5bf9\u79f0\u7f29\u653e\u76f8\u5bf9\u56fe\u7684\u6b21\u4e58\u6027\u8d28\uff0c\u5f00\u53d1\u56fe\u5f62\u7a33\u5b9a\u6027\u5224\u636e\uff0c\u8be5\u65b9\u6cd5\u80fd\u7cbe\u786e\u8fd8\u539f\u6807\u91cf\u60c5\u51b5\uff0c\u66f4\u9002\u5408\u4f5c\u4e3a\u7ecf\u5178\u5948\u594e\u65af\u7279\u56fe\u7684\u591a\u8f93\u5165\u591a\u8f93\u51fa\u6269\u5c55\u3002", "result": "\u03b8\u5bf9\u79f0SRG\u6bd4\u6807\u51c6SRG\u66f4\u9002\u5408\u4f5c\u4e3aMIMO\u7cfb\u7edf\u7684\u5948\u594e\u65af\u7279\u56fe\u6269\u5c55\uff0c\u80fd\u66f4\u597d\u5730\u6355\u6349\u7cfb\u7edf\u7279\u6027\u5e76\u83b7\u5f97\u66f4\u4e0d\u4fdd\u5b88\u7684\u7ed3\u679c\u3002", "conclusion": "\u03b8\u5bf9\u79f0\u7f29\u653e\u76f8\u5bf9\u56fe\u65b9\u6cd5\u4e3a\u7ea7\u8054\u7cfb\u7edf\u53cd\u9988\u4e92\u8054\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u56fe\u5f62\u7a33\u5b9a\u6027\u5206\u6790\u5de5\u5177\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u7684\u5faa\u73af\u4e92\u8054\u573a\u666f\u3002"}}
{"id": "2510.06255", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.06255", "abs": "https://arxiv.org/abs/2510.06255", "authors": ["Juan Segundo Hevia", "Facundo Arredondo", "Vishesh Kumar"], "title": "Towards an Efficient, Customizable, and Accessible AI Tutor", "comment": "AAAI - iRAISE 2025", "summary": "The integration of large language models (LLMs) into education offers\nsignificant potential to enhance accessibility and engagement, yet their high\ncomputational demands limit usability in low-resource settings, exacerbating\neducational inequities. To address this, we propose an offline\nRetrieval-Augmented Generation (RAG) pipeline that pairs a small language model\n(SLM) with a robust retrieval mechanism, enabling factual, contextually\nrelevant responses without internet connectivity. We evaluate the efficacy of\nthis pipeline using domain-specific educational content, focusing on biology\ncoursework. Our analysis highlights key challenges: smaller models, such as\nSmolLM, struggle to effectively leverage extended contexts provided by the RAG\npipeline, particularly when noisy or irrelevant chunks are included. To improve\nperformance, we propose exploring advanced chunking techniques, alternative\nsmall or quantized versions of larger models, and moving beyond traditional\nmetrics like MMLU to a holistic evaluation framework assessing free-form\nresponse. This work demonstrates the feasibility of deploying AI tutors in\nconstrained environments, laying the groundwork for equitable, offline, and\ndevice-based educational tools.", "AI": {"tldr": "\u63d0\u51fa\u79bb\u7ebfRAG\u7ba1\u9053\uff0c\u5c06\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u68c0\u7d22\u673a\u5236\u7ed3\u5408\uff0c\u4e3a\u4f4e\u8d44\u6e90\u73af\u5883\u63d0\u4f9b\u6559\u80b2AI\u52a9\u624b\uff0c\u89e3\u51b3LLM\u5728\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6559\u80b2\u4e2d\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u9ad8\u8ba1\u7b97\u9700\u6c42\u9650\u5236\u4e86\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u7684\u4f7f\u7528\uff0c\u52a0\u5267\u6559\u80b2\u4e0d\u5e73\u7b49\u3002\u9700\u8981\u5f00\u53d1\u79bb\u7ebf\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7ba1\u9053\uff0c\u5c06\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u5f3a\u5065\u68c0\u7d22\u673a\u5236\u914d\u5bf9\uff0c\u65e0\u9700\u4e92\u8054\u7f51\u8fde\u63a5\u5373\u53ef\u63d0\u4f9b\u4e8b\u5b9e\u6027\u3001\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u56de\u7b54\u3002", "result": "\u5206\u6790\u663e\u793a\u5c0f\u578b\u6a21\u578b(\u5982SmolLM)\u96be\u4ee5\u6709\u6548\u5229\u7528RAG\u63d0\u4f9b\u7684\u6269\u5c55\u4e0a\u4e0b\u6587\uff0c\u7279\u522b\u662f\u5728\u5305\u542b\u566a\u58f0\u6216\u4e0d\u76f8\u5173\u5757\u65f6\u3002\u6027\u80fd\u6709\u5f85\u63d0\u5347\u3002", "conclusion": "\u8bc1\u660e\u4e86\u5728\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72AI\u5bfc\u5e08\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u516c\u5e73\u3001\u79bb\u7ebf\u548c\u8bbe\u5907\u5316\u6559\u80b2\u5de5\u5177\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5efa\u8bae\u63a2\u7d22\u5148\u8fdb\u5206\u5757\u6280\u672f\u3001\u91cf\u5316\u6a21\u578b\u548c\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2510.06903", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.06903", "abs": "https://arxiv.org/abs/2510.06903", "authors": ["Yu Liu", "Wenwen Li", "Yifan Dou", "Guangnan Ye"], "title": "When Machines Meet Each Other: Network Effects and the Strategic Role of History in Multi-Agent AI", "comment": null, "summary": "As artificial intelligence (AI) enters the agentic era, large language models\n(LLMs) are increasingly deployed as autonomous agents that interact with one\nanother rather than operate in isolation. This shift raises a fundamental\nquestion: how do machine agents behave in interdependent environments where\noutcomes depend not only on their own choices but also on the coordinated\nexpectations of peers? To address this question, we study LLM agents in a\ncanonical network-effect game, where economic theory predicts convergence to a\nfulfilled expectation equilibrium (FEE). We design an experimental framework in\nwhich 50 heterogeneous GPT-5-based agents repeatedly interact under\nsystematically varied network-effect strengths, price trajectories, and\ndecision-history lengths. The results reveal that LLM agents systematically\ndiverge from FEE: they underestimate participation at low prices, overestimate\nat high prices, and sustain persistent dispersion. Crucially, the way history\nis structured emerges as a design lever. Simple monotonic histories-where past\noutcomes follow a steady upward or downward trend-help stabilize coordination,\nwhereas nonmonotonic histories amplify divergence and path dependence.\nRegression analyses at the individual level further show that price is the\ndominant driver of deviation, history moderates this effect, and network\neffects amplify contextual distortions. Together, these findings advance\nmachine behavior research by providing the first systematic evidence on\nmulti-agent AI systems under network effects and offer guidance for configuring\nsuch systems in practice.", "AI": {"tldr": "\u7814\u7a76LLM\u667a\u80fd\u4f53\u5728\u7f51\u7edc\u6548\u5e94\u535a\u5f08\u4e2d\u7684\u884c\u4e3a\uff0c\u53d1\u73b0\u5b83\u4eec\u4f1a\u7cfb\u7edf\u6027\u504f\u79bb\u7406\u8bba\u9884\u6d4b\u7684\u671f\u671b\u5747\u8861\uff0c\u4ef7\u683c\u662f\u4e3b\u8981\u504f\u5dee\u9a71\u52a8\u56e0\u7d20\uff0c\u5386\u53f2\u7ed3\u6784\u5bf9\u534f\u8c03\u7a33\u5b9a\u6027\u6709\u91cd\u8981\u5f71\u54cd\u3002", "motivation": "\u968f\u7740AI\u8fdb\u5165\u667a\u80fd\u4f53\u65f6\u4ee3\uff0cLLM\u8d8a\u6765\u8d8a\u591a\u5730\u4f5c\u4e3a\u81ea\u4e3b\u667a\u80fd\u4f53\u76f8\u4e92\u4ea4\u4e92\uff0c\u9700\u8981\u4e86\u89e3\u5b83\u4eec\u5728\u76f8\u4e92\u4f9d\u8d56\u73af\u5883\u4e2d\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u7279\u522b\u662f\u5728\u7f51\u7edc\u6548\u5e94\u535a\u5f08\u4e2d\u7684\u534f\u8c03\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u5b9e\u9a8c\u6846\u67b6\uff0c\u8ba950\u4e2a\u57fa\u4e8eGPT-5\u7684\u5f02\u8d28\u667a\u80fd\u4f53\u5728\u7f51\u7edc\u6548\u5e94\u535a\u5f08\u4e2d\u91cd\u590d\u4ea4\u4e92\uff0c\u7cfb\u7edf\u53d8\u5316\u7f51\u7edc\u6548\u5e94\u5f3a\u5ea6\u3001\u4ef7\u683c\u8f68\u8ff9\u548c\u51b3\u7b56\u5386\u53f2\u957f\u5ea6\u7b49\u53c2\u6570\u3002", "result": "LLM\u667a\u80fd\u4f53\u7cfb\u7edf\u6027\u504f\u79bb\u671f\u671b\u5747\u8861\uff1a\u5728\u4f4e\u4ef7\u65f6\u4f4e\u4f30\u53c2\u4e0e\u5ea6\uff0c\u9ad8\u4ef7\u65f6\u9ad8\u4f30\u53c2\u4e0e\u5ea6\uff0c\u5e76\u7ef4\u6301\u6301\u7eed\u5206\u6563\u3002\u5355\u8c03\u5386\u53f2\u6709\u52a9\u4e8e\u7a33\u5b9a\u534f\u8c03\uff0c\u975e\u5355\u8c03\u5386\u53f2\u52a0\u5267\u5206\u6b67\u3002", "conclusion": "\u4ef7\u683c\u662f\u504f\u5dee\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u5386\u53f2\u7ed3\u6784\u8c03\u8282\u8fd9\u4e00\u6548\u5e94\uff0c\u7f51\u7edc\u6548\u5e94\u653e\u5927\u60c5\u5883\u626d\u66f2\uff0c\u4e3a\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u914d\u7f6e\u63d0\u4f9b\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2510.06755", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.06755", "abs": "https://arxiv.org/abs/2510.06755", "authors": ["Katarina Skopalova", "Jafet Osuna", "Wei Zhang"], "title": "Estimating temporary emigration from capture-recapture data in the presence of latent identification", "comment": "34 pages (19 + supplemetary material), 22 figures/tables (6 + 16 in\n  supplementary material)", "summary": "Most capture-recapture models assume that individuals either do not emigrate\nor emigrate permanently from the sampling area during the sampling period. This\nassumption is violated when individuals temporarily leave the sampling area and\nreturn during later capture occasions, which can result in biased or less\nprecise inferences under normal capture-recapture models. Existing temporary\nemigration models require that individuals are uniquely and correctly\nidentified. To our knowledge, no studies to date have addressed temporary\nemigration in the presence of latent individual identification, which can arise\nin many scenarios such as misidentification, data integration, and batch\nmarking. In this paper, we propose a new latent multinomial temporary\nemigration modelling framework for analysing capture-recapture data with latent\nidentification. The framework is applicable to both closed- and open-population\nproblems, accommodates data with or without individual identification, and\nflexibly incorporates different emigration processes, including the completely\nrandom and Markovian emigration. Through simulations, we demonstrate that model\nparameters can be reliably estimated in various emigration scenarios. We apply\nthe proposed framework to a real dataset on golden mantella collected using\nbatch marks under Pollock's robust design. The results show that accounting for\ntemporary emigration provides a better fit to the data compared to the previous\nmodel without temporary emigration.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6f5c\u5728\u591a\u9879\u4e34\u65f6\u8fc1\u51fa\u5efa\u6a21\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u5177\u6709\u6f5c\u5728\u4e2a\u4f53\u8bc6\u522b\u7684\u6355\u83b7-\u91cd\u6355\u83b7\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6a21\u578b\u65e0\u6cd5\u5904\u7406\u4e34\u65f6\u8fc1\u51fa\u548c\u4e2a\u4f53\u8bc6\u522b\u4e0d\u5b8c\u6574\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u6355\u83b7-\u91cd\u6355\u83b7\u6a21\u578b\u5047\u8bbe\u4e2a\u4f53\u4e0d\u8fc1\u51fa\u6216\u6c38\u4e45\u8fc1\u51fa\u91c7\u6837\u533a\u57df\uff0c\u4f46\u73b0\u5b9e\u4e2d\u4e2a\u4f53\u53ef\u80fd\u4e34\u65f6\u79bb\u5f00\u540e\u8fd4\u56de\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u63a8\u65ad\u504f\u5dee\u3002\u73b0\u6709\u4e34\u65f6\u8fc1\u51fa\u6a21\u578b\u8981\u6c42\u4e2a\u4f53\u88ab\u552f\u4e00\u6b63\u786e\u8bc6\u522b\uff0c\u800c\u65e0\u6cd5\u5904\u7406\u6f5c\u5728\u4e2a\u4f53\u8bc6\u522b\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u6f5c\u5728\u591a\u9879\u4e34\u65f6\u8fc1\u51fa\u5efa\u6a21\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u5c01\u95ed\u548c\u5f00\u653e\u79cd\u7fa4\u95ee\u9898\uff0c\u53ef\u5904\u7406\u6709\u65e0\u4e2a\u4f53\u8bc6\u522b\u7684\u6570\u636e\uff0c\u5e76\u80fd\u7075\u6d3b\u7eb3\u5165\u4e0d\u540c\u8fc1\u51fa\u8fc7\u7a0b\uff08\u5b8c\u5168\u968f\u673a\u548c\u9a6c\u5c14\u53ef\u592b\u8fc1\u51fa\uff09\u3002", "result": "\u6a21\u62df\u7814\u7a76\u8868\u660e\u6a21\u578b\u53c2\u6570\u5728\u5404\u79cd\u8fc1\u51fa\u60c5\u666f\u4e0b\u90fd\u80fd\u53ef\u9760\u4f30\u8ba1\u3002\u5e94\u7528\u4e8e\u91d1\u66fc\u7279\u62c9\u86d9\u7684\u5b9e\u9645\u6570\u636e\u96c6\u663e\u793a\uff0c\u8003\u8651\u4e34\u65f6\u8fc1\u51fa\u6bd4\u4e0d\u8003\u8651\u7684\u6a21\u578b\u80fd\u66f4\u597d\u5730\u62df\u5408\u6570\u636e\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5904\u7406\u5177\u6709\u6f5c\u5728\u4e2a\u4f53\u8bc6\u522b\u7684\u6355\u83b7-\u91cd\u6355\u83b7\u6570\u636e\u4e2d\u7684\u4e34\u65f6\u8fc1\u51fa\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u63d0\u9ad8\u4e86\u79cd\u7fa4\u53c2\u6570\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2510.07204", "categories": ["econ.EM", "math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.07204", "abs": "https://arxiv.org/abs/2510.07204", "authors": ["Karsten Reichold", "Ulrike Schneider"], "title": "Beyond the Oracle Property: Adaptive LASSO in Cointegrating Regressions", "comment": null, "summary": "This paper establishes new asymptotic results for the adaptive LASSO\nestimator in cointegrating regression models. We study model selection\nprobabilities, estimator consistency, and limiting distributions under both\nstandard and moving-parameter asymptotics. We also derive uniform convergence\nrates and the fastest local-to-zero rates that can still be detected by the\nestimator, complementing and extending the results of Lee, Shi, and Gao (2022,\nJournal of Econometrics, 229, 322--349). Our main findings include that under\nconservative tuning, the adaptive LASSO estimator is uniformly $T$-consistent\nand the cut-off rate for local-to-zero coefficients that can be detected by the\nprocedure is $1/T$. Under consistent tuning, however, both rates are slower and\ndepend on the tuning parameter. The theoretical results are complemented by a\ndetailed simulation study showing that the finite-sample distribution of the\nadaptive LASSO estimator deviates substantially from what is suggested by the\noracle property, whereas the limiting distributions derived under\nmoving-parameter asymptotics provide much more accurate approximations.\nFinally, we show that our results also extend to models with local-to-unit-root\nregressors and to predictive regressions with unit-root predictors.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u81ea\u9002\u5e94LASSO\u4f30\u8ba1\u91cf\u5728\u534f\u6574\u56de\u5f52\u6a21\u578b\u4e2d\u7684\u6e10\u8fd1\u6027\u8d28\uff0c\u5305\u62ec\u6a21\u578b\u9009\u62e9\u6982\u7387\u3001\u4f30\u8ba1\u91cf\u4e00\u81f4\u6027\u3001\u6781\u9650\u5206\u5e03\uff0c\u4ee5\u53ca\u5747\u5300\u6536\u655b\u901f\u7387\u548c\u53ef\u68c0\u6d4b\u7684\u6700\u5feb\u5c40\u90e8\u8d8b\u96f6\u901f\u7387\u3002", "motivation": "\u6269\u5c55Lee, Shi\u548cGao(2022)\u7684\u7ed3\u679c\uff0c\u6df1\u5165\u7406\u89e3\u81ea\u9002\u5e94LASSO\u5728\u534f\u6574\u56de\u5f52\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u4fdd\u5b88\u8c03\u4f18\u548c\u4e00\u81f4\u8c03\u4f18\u4e0b\u7684\u4e0d\u540c\u884c\u4e3a\u3002", "method": "\u4f7f\u7528\u6807\u51c6\u6e10\u8fd1\u548c\u79fb\u52a8\u53c2\u6570\u6e10\u8fd1\u65b9\u6cd5\uff0c\u63a8\u5bfc\u6a21\u578b\u9009\u62e9\u6982\u7387\u3001\u4f30\u8ba1\u91cf\u4e00\u81f4\u6027\u3001\u6781\u9650\u5206\u5e03\uff0c\u5e76\u8fdb\u884c\u8be6\u7ec6\u7684\u6a21\u62df\u7814\u7a76\u9a8c\u8bc1\u7406\u8bba\u7ed3\u679c\u3002", "result": "\u5728\u4fdd\u5b88\u8c03\u4f18\u4e0b\uff0c\u81ea\u9002\u5e94LASSO\u4f30\u8ba1\u91cf\u662f\u5747\u5300T\u4e00\u81f4\u7684\uff0c\u53ef\u68c0\u6d4b\u7684\u5c40\u90e8\u8d8b\u96f6\u7cfb\u6570\u622a\u65ad\u901f\u7387\u4e3a1/T\uff1b\u5728\u4e00\u81f4\u8c03\u4f18\u4e0b\uff0c\u8fd9\u4e24\u4e2a\u901f\u7387\u90fd\u8f83\u6162\u4e14\u4f9d\u8d56\u4e8e\u8c03\u4f18\u53c2\u6570\u3002", "conclusion": "\u81ea\u9002\u5e94LASSO\u4f30\u8ba1\u91cf\u7684\u6709\u9650\u6837\u672c\u5206\u5e03\u4e0eoracle\u6027\u8d28\u5efa\u8bae\u7684\u6709\u663e\u8457\u504f\u5dee\uff0c\u800c\u79fb\u52a8\u53c2\u6570\u6e10\u8fd1\u5bfc\u51fa\u7684\u6781\u9650\u5206\u5e03\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u8fd1\u4f3c\u3002\u7ed3\u679c\u8fd8\u6269\u5c55\u5230\u5177\u6709\u5c40\u90e8\u5355\u4f4d\u6839\u56de\u5f52\u5143\u548c\u9884\u6d4b\u56de\u5f52\u7684\u6a21\u578b\u3002"}}
{"id": "2510.06351", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.06351", "abs": "https://arxiv.org/abs/2510.06351", "authors": ["Kaleb Ben Naveed", "Devansh R. Agrawal", "Dimitra Panagou"], "title": "A Formal gatekeeper Framework for Safe Dual Control with Active Exploration", "comment": "Submitted to American Control Conference (ACC) 2026", "summary": "Planning safe trajectories under model uncertainty is a fundamental\nchallenge. Robust planning ensures safety by considering worst-case\nrealizations, yet ignores uncertainty reduction and leads to overly\nconservative behavior. Actively reducing uncertainty on-the-fly during a\nnominal mission defines the dual control problem. Most approaches address this\nby adding a weighted exploration term to the cost, tuned to trade off the\nnominal objective and uncertainty reduction, but without formal consideration\nof when exploration is beneficial. Moreover, safety is enforced in some methods\nbut not in others. We propose a framework that integrates robust planning with\nactive exploration under formal guarantees as follows: The key innovation and\ncontribution is that exploration is pursued only when it provides a verifiable\nimprovement without compromising safety. To achieve this, we utilize our\nearlier work on gatekeeper as an architecture for safety verification, and\nextend it so that it generates both safe and informative trajectories that\nreduce uncertainty and the cost of the mission, or keep it within a\nuser-defined budget. The methodology is evaluated via simulation case studies\non the online dual control of a quadrotor under parametric uncertainty.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5c06\u9c81\u68d2\u89c4\u5212\u4e0e\u4e3b\u52a8\u63a2\u7d22\u76f8\u7ed3\u5408\u7684\u5b89\u5168\u6846\u67b6\uff0c\u4ec5\u5728\u63a2\u7d22\u80fd\u5e26\u6765\u53ef\u9a8c\u8bc1\u6539\u8fdb\u4e14\u4e0d\u635f\u5bb3\u5b89\u5168\u6027\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u63a2\u7d22\u3002", "motivation": "\u89e3\u51b3\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5b89\u5168\u8f68\u8ff9\u89c4\u5212\u95ee\u9898\uff0c\u4f20\u7edf\u9c81\u68d2\u89c4\u5212\u8fc7\u4e8e\u4fdd\u5b88\u4e14\u5ffd\u7565\u4e0d\u786e\u5b9a\u6027\u51cf\u5c11\uff0c\u800c\u73b0\u6709\u53cc\u63a7\u5236\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u63a2\u7d22\u65f6\u673a\u548c\u5b89\u5168\u6027\u7684\u6b63\u5f0f\u8003\u8651\u3002", "method": "\u5229\u7528gatekeeper\u67b6\u6784\u8fdb\u884c\u5b89\u5168\u9a8c\u8bc1\uff0c\u6269\u5c55\u5176\u751f\u6210\u65e2\u5b89\u5168\u53c8\u4fe1\u606f\u4e30\u5bcc\u7684\u8f68\u8ff9\uff0c\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027\u548c\u4efb\u52a1\u6210\u672c\uff0c\u6216\u4fdd\u6301\u5728\u7528\u6237\u5b9a\u4e49\u7684\u9884\u7b97\u5185\u3002", "result": "\u901a\u8fc7\u56db\u65cb\u7ffc\u98de\u884c\u5668\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u7684\u5728\u7ebf\u53cc\u63a7\u5236\u4eff\u771f\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u4fdd\u8bc1\u5b89\u5168\u7684\u524d\u63d0\u4e0b\uff0c\u667a\u80fd\u5730\u5e73\u8861\u4e86\u63a2\u7d22\u548c\u5229\u7528\uff0c\u4ec5\u5728\u63a2\u7d22\u80fd\u5e26\u6765\u53ef\u9a8c\u8bc1\u6536\u76ca\u65f6\u624d\u8fdb\u884c\u63a2\u7d22\u3002"}}
{"id": "2510.06788", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.06788", "abs": "https://arxiv.org/abs/2510.06788", "authors": ["Zheng Wei", "Yunqi Li", "Yucheng He", "Yuelu Li", "Xian Xu", "Huamin Qu", "Pan Hui", "Muzhi Zhou"], "title": "Unpacking Discourses on Childbirth and Parenthood in Popular Social Media Platforms Across China, Japan, and South Korea", "comment": "Accepted for publication at The International AAAI Conference on Web\n  and Social Media (ICWSM 2026)", "summary": "Social media use has been shown to be associated with low fertility desires.\nHowever, we know little about the discourses surrounding childbirth and\nparenthood that people consume online. We analyze 219,127 comments on 668 short\nvideos related to reproduction and parenthood from Douyin and Tiktok in China,\nSouth Korea, and Japan, a region famous for its extremely low fertility level,\nto examine the topics and sentiment expressed online. BERTopic model is used to\nassist thematic analysis, and a large language model QWen is applied to label\nsentiment. We find that comments focus on childrearing costs in all countries,\nutility of children, particularly in Japan and South Korea, and individualism,\nprimarily in China. Comments from Douyin exhibit the strongest anti-natalist\nsentiments, while the Japanese and Korean comments are more neutral. Short\nvideo characteristics, such as their stances or account type, significantly\ninfluence the responses, alongside regional socioeconomic indicators, including\nGDP, urbanization, and population sex ratio. This work provides one of the\nfirst comprehensive analyses of online discourses on family formation via\npopular algorithm-fed video sharing platforms in regions experiencing low\nfertility rates, making a valuable contribution to our understanding of the\nspread of family values online.", "AI": {"tldr": "\u5206\u6790\u6296\u97f3\u548cTikTok\u4e0a\u5173\u4e8e\u751f\u80b2\u548c\u80b2\u513f\u7684\u77ed\u89c6\u9891\u8bc4\u8bba\uff0c\u53d1\u73b0\u5728\u4e2d\u56fd\u3001\u97e9\u56fd\u548c\u65e5\u672c\uff0c\u8bc4\u8bba\u4e3b\u8981\u5173\u6ce8\u80b2\u513f\u6210\u672c\u3001\u5b69\u5b50\u7684\u6548\u7528\u548c\u4e2a\u4eba\u4e3b\u4e49\uff0c\u5176\u4e2d\u6296\u97f3\u8bc4\u8bba\u53cd\u751f\u80b2\u60c5\u7eea\u6700\u5f3a\u3002", "motivation": "\u4e86\u89e3\u793e\u4ea4\u5a92\u4f53\u4e0a\u5173\u4e8e\u751f\u80b2\u548c\u80b2\u513f\u7684\u8bdd\u8bed\uff0c\u7279\u522b\u662f\u5728\u4f4e\u751f\u80b2\u7387\u5730\u533a\uff0c\u4ee5\u63a2\u7a76\u5728\u7ebf\u5bb6\u5ead\u4ef7\u503c\u89c2\u7684\u4f20\u64ad\u3002", "method": "\u4f7f\u7528BERTopic\u6a21\u578b\u8fdb\u884c\u4e3b\u9898\u5206\u6790\uff0c\u5e76\u5e94\u7528\u5927\u8bed\u8a00\u6a21\u578bQWen\u8fdb\u884c\u60c5\u611f\u6807\u6ce8\uff0c\u5206\u6790\u4e86219,127\u6761\u8bc4\u8bba\u548c668\u4e2a\u77ed\u89c6\u9891\u3002", "result": "\u8bc4\u8bba\u5728\u6240\u6709\u56fd\u5bb6\u90fd\u5173\u6ce8\u80b2\u513f\u6210\u672c\uff0c\u65e5\u672c\u548c\u97e9\u56fd\u5173\u6ce8\u5b69\u5b50\u7684\u6548\u7528\uff0c\u4e2d\u56fd\u5173\u6ce8\u4e2a\u4eba\u4e3b\u4e49\uff1b\u6296\u97f3\u8bc4\u8bba\u53cd\u751f\u80b2\u60c5\u7eea\u6700\u5f3a\uff0c\u65e5\u97e9\u8bc4\u8bba\u66f4\u4e2d\u6027\u3002", "conclusion": "\u77ed\u89c6\u9891\u7279\u5f81\u548c\u533a\u57df\u793e\u4f1a\u7ecf\u6d4e\u6307\u6807\u663e\u8457\u5f71\u54cd\u5728\u7ebf\u56de\u5e94\uff0c\u8fd9\u6709\u52a9\u4e8e\u7406\u89e3\u4f4e\u751f\u80b2\u7387\u5730\u533a\u5728\u7ebf\u5bb6\u5ead\u4ef7\u503c\u89c2\u7684\u4f20\u64ad\u3002"}}
{"id": "2510.06608", "categories": ["cs.ET", "astro-ph.IM", "cs.GR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.06608", "abs": "https://arxiv.org/abs/2510.06608", "authors": ["Benjamin Nuernberger", "Samuel-Hunter Berndt", "Robert Tapella", "Laura Mann", "Aaron Plave", "Sasha Samochina", "Victor X. Luo"], "title": "A Review of 10 Years of ProtoSpace: Spacecraft CAD Visualization in Collaborative Augmented Reality", "comment": "16 pages, 29 figures", "summary": "ProtoSpace is a custom JPL-built platform to help scientists and engineers\nvisualize their CAD models collaboratively in augmented reality (AR) and on the\nweb in 3D. In addition to this main use case, ProtoSpace has been used\nthroughout the entire spacecraft mission lifecycle and beyond: ventilator\ndesign and assembly; providing AR-based instructions to astronauts in-training;\neducating the next generation on the process of spacecraft design; etc.\nProtoSpace has been used for a decade by NASA missions-including Mars\nPerseverance, Europa Clipper, NISAR, SPHEREx, CAL, and Mars Sample Return-to\nreduce cost and risk by helping engineers and scientists fix problems earlier\nthrough reducing miscommunication and helping people understand the spatial\ncontext of their spacecraft in the appropriate physical context more quickly.\nThis paper will explore how ProtoSpace came to be, define the system\narchitecture and overview-including HoloLens and 3D web clients, the ProtoSpace\nserver, and the CAD model optimizer-and dive into the use cases, spin-offs, and\nlessons learned that led to 10 years of success at NASA's Jet Propulsion\nLaboratory.", "AI": {"tldr": "ProtoSpace\u662fJPL\u5f00\u53d1\u7684\u53ef\u89c6\u5316\u5e73\u53f0\uff0c\u652f\u6301\u79d1\u5b66\u5bb6\u548c\u5de5\u7a0b\u5e08\u5728AR\u548cWeb 3D\u4e2d\u534f\u4f5c\u67e5\u770bCAD\u6a21\u578b\uff0c\u5df2\u5728NASA\u591a\u4e2a\u4efb\u52a1\u4e2d\u5e94\u752810\u5e74\uff0c\u6709\u6548\u964d\u4f4e\u6210\u672c\u548c\u98ce\u9669\u3002", "motivation": "\u5e2e\u52a9\u5de5\u7a0b\u5e08\u548c\u79d1\u5b66\u5bb6\u901a\u8fc7\u51cf\u5c11\u6c9f\u901a\u8bef\u89e3\u3001\u66f4\u5feb\u7406\u89e3\u822a\u5929\u5668\u7a7a\u95f4\u80cc\u666f\u6765\u66f4\u65e9\u53d1\u73b0\u95ee\u9898\uff0c\u4ece\u800c\u964d\u4f4e\u4efb\u52a1\u6210\u672c\u548c\u98ce\u9669\u3002", "method": "\u6784\u5efa\u5305\u542bHoloLens\u548c3D Web\u5ba2\u6237\u7aef\u3001ProtoSpace\u670d\u52a1\u5668\u3001CAD\u6a21\u578b\u4f18\u5316\u5668\u7684\u7cfb\u7edf\u67b6\u6784\uff0c\u652f\u6301AR\u548cWeb 3D\u534f\u4f5c\u53ef\u89c6\u5316\u3002", "result": "\u6210\u529f\u5e94\u7528\u4e8eNASA\u591a\u4e2a\u4efb\u52a1\uff08\u5982Mars Perseverance\u3001Europa Clipper\u7b49\uff0910\u5e74\uff0c\u6269\u5c55\u5230\u822a\u5929\u5668\u4efb\u52a1\u5168\u751f\u547d\u5468\u671f\u53ca\u533b\u7597\u8bbe\u5907\u8bbe\u8ba1\u3001\u5b87\u822a\u5458\u57f9\u8bad\u7b49\u9886\u57df\u3002", "conclusion": "ProtoSpace\u901a\u8fc7AR\u548c3D Web\u53ef\u89c6\u5316\u6280\u672f\uff0c\u5728NASA JPL\u5b9e\u73b0\u4e8610\u5e74\u7684\u6210\u529f\u5e94\u7528\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u51cf\u5c11\u6c9f\u901a\u9519\u8bef\u3001\u52a0\u901f\u7a7a\u95f4\u7406\u89e3\u65b9\u9762\u7684\u4ef7\u503c\u3002"}}
{"id": "2510.06274", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06274", "abs": "https://arxiv.org/abs/2510.06274", "authors": ["Mohammad Mahdi Samiei Paqaleh", "Arash Marioriyad", "Arman Tahmasebi-Zadeh", "Mohamadreza Fereydooni", "Mahdi Ghaznavai", "Mahdieh Soleymani Baghshah"], "title": "Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization", "comment": null, "summary": "Recent progress has pushed AI frontiers from pattern recognition tasks toward\nproblems that require step by step, System2 style reasoning, especially with\nlarge language models. Yet, unlike learning, where generalization and out of\ndistribution (OoD) evaluation concepts are well formalized, there is no clear,\nconsistent definition or metric for reasoning ability. We propose Complexity\nOut of Distribution (Complexity OoD) generalization as a framework and problem\nsetting to define and measure reasoning. A model exhibits Complexity OoD\ngeneralization when it maintains performance on test instances whose minimal\nrequired solution complexity, either representational (richer solution\nstructure) or computational (more reasoning steps/program length), exceeds that\nof all training examples. We formalize complexity via solution description\nKolmogorov complexity and operational proxies (e.g., object/relation counts;\nreasoning step counts), clarifying how Complexity OoD differs from length and\ncompositional OoD. This lens unifies learning and reasoning: many cases\nsolvable with System1 like processing at low complexity become System2 like\nunder complexity pressure, while System2 can be viewed as generalization over\nsolution structures. We translate this perspective into practice with\nrecommendations for operationalizing Complexity OoD across the stack:\nincorporating complexity into benchmark and evaluation metric design,\nrethinking supervision to target solution traces, seeking and designing\ninductive biases for Complexity OoD generalization, addressing learning to\nreason spillovers such as spurious shortcuts, semantic robustness, catastrophic\nforgetting, and step wise calibration. Because Complexity OoD cannot be solved\nby scaling data alone, progress toward robust reasoning will require\narchitectures and training regimes that explicitly model and allocate\ncomputation with respect to complexity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u590d\u6742\u6027\u5206\u5e03\u5916\u6cdb\u5316\u6846\u67b6\u6765\u5b9a\u4e49\u548c\u8861\u91cf\u63a8\u7406\u80fd\u529b\uff0c\u5f3a\u8c03\u5f53\u6d4b\u8bd5\u5b9e\u4f8b\u6240\u9700\u7684\u6700\u5c0f\u89e3\u51b3\u65b9\u6848\u590d\u6742\u6027\u8d85\u8fc7\u6240\u6709\u8bad\u7ec3\u793a\u4f8b\u65f6\uff0c\u6a21\u578b\u4ecd\u80fd\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u5f53\u524dAI\u4ece\u6a21\u5f0f\u8bc6\u522b\u4efb\u52a1\u8f6c\u5411\u9700\u8981\u9010\u6b65\u63a8\u7406\u7684\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u63a8\u7406\u80fd\u529b\u7684\u660e\u786e\u5b9a\u4e49\u548c\u5ea6\u91cf\u6807\u51c6\u3002", "method": "\u901a\u8fc7\u89e3\u51b3\u65b9\u6848\u63cf\u8ff0\u7684\u67ef\u5c14\u83ab\u54e5\u6d1b\u592b\u590d\u6742\u6027\u548c\u64cd\u4f5c\u4ee3\u7406\u6765\u5f62\u5f0f\u5316\u590d\u6742\u6027\uff0c\u533a\u5206\u590d\u6742\u6027\u5206\u5e03\u5916\u4e0e\u957f\u5ea6\u548c\u7ec4\u5408\u5206\u5e03\u5916\u7684\u5dee\u5f02\u3002", "result": "\u8be5\u6846\u67b6\u7edf\u4e00\u4e86\u5b66\u4e60\u548c\u63a8\u7406\uff1a\u4f4e\u590d\u6742\u6027\u65f6\u53ef\u7528\u7cfb\u7edf1\u5904\u7406\u7684\u95ee\u9898\u5728\u590d\u6742\u6027\u538b\u529b\u4e0b\u53d8\u4e3a\u7cfb\u7edf2\u5904\u7406\uff0c\u7cfb\u7edf2\u53ef\u89c6\u4e3a\u89e3\u51b3\u65b9\u6848\u7ed3\u6784\u7684\u6cdb\u5316\u3002", "conclusion": "\u590d\u6742\u6027\u5206\u5e03\u5916\u4e0d\u80fd\u4ec5\u901a\u8fc7\u6269\u5c55\u6570\u636e\u89e3\u51b3\uff0c\u9700\u8981\u660e\u786e\u5efa\u6a21\u548c\u5206\u914d\u8ba1\u7b97\u590d\u6742\u6027\u7684\u67b6\u6784\u548c\u8bad\u7ec3\u673a\u5236\u6765\u5b9e\u73b0\u7a33\u5065\u63a8\u7406\u3002"}}
{"id": "2510.06661", "categories": ["eess.SY", "cs.AI", "cs.SY", "93D09, 93D20, 93C10, 68T07", "I.2.0; I.2.3; I.2.8; B.1.3; G.2; F.3"], "pdf": "https://arxiv.org/pdf/2510.06661", "abs": "https://arxiv.org/abs/2510.06661", "authors": ["Hamidreza Montazeri Hedesh", "Milad Siami"], "title": "Delay Independent Safe Control with Neural Networks: Positive Lur'e Certificates for Risk Aware Autonomy", "comment": "Submitted to 2026 American Control Conference (ACC), New Orleans, LA", "summary": "We present a risk-aware safety certification method for autonomous, learning\nenabled control systems. Focusing on two realistic risks, state/input delays\nand interval matrix uncertainty, we model the neural network (NN) controller\nwith local sector bounds and exploit positivity structure to derive linear,\ndelay-independent certificates that guarantee local exponential stability\nacross admissible uncertainties. To benchmark performance, we adopt and\nimplement a state-of-the-art IQC NN verification pipeline. On representative\ncases, our positivity-based tests run orders of magnitude faster than SDP-based\nIQC while certifying regimes the latter cannot-providing scalable safety\nguarantees that complement risk-aware control.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u81ea\u4e3b\u5b66\u4e60\u63a7\u5236\u7cfb\u7edf\u7684\u98ce\u9669\u611f\u77e5\u5b89\u5168\u8ba4\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c40\u90e8\u6247\u533a\u8fb9\u754c\u5efa\u6a21\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u5668\uff0c\u5229\u7528\u6b63\u6027\u7ed3\u6784\u63a8\u5bfc\u7ebf\u6027\u3001\u5ef6\u8fdf\u65e0\u5173\u7684\u8bc1\u4e66\uff0c\u4fdd\u8bc1\u5728\u5141\u8bb8\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5c40\u90e8\u6307\u6570\u7a33\u5b9a\u6027\u3002", "motivation": "\u9488\u5bf9\u81ea\u4e3b\u5b66\u4e60\u63a7\u5236\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u72b6\u6001/\u8f93\u5165\u5ef6\u8fdf\u548c\u533a\u95f4\u77e9\u9635\u4e0d\u786e\u5b9a\u6027\u4e24\u79cd\u73b0\u5b9e\u98ce\u9669\uff0c\u9700\u8981\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u5b89\u5168\u4fdd\u8bc1\u6765\u8865\u5145\u98ce\u9669\u611f\u77e5\u63a7\u5236\u3002", "method": "\u4f7f\u7528\u5c40\u90e8\u6247\u533a\u8fb9\u754c\u5bf9\u795e\u7ecf\u7f51\u7edc\u63a7\u5236\u5668\u8fdb\u884c\u5efa\u6a21\uff0c\u5229\u7528\u6b63\u6027\u7ed3\u6784\u63a8\u5bfc\u7ebf\u6027\u3001\u5ef6\u8fdf\u65e0\u5173\u7684\u8ba4\u8bc1\u8bc1\u4e66\uff0c\u5e76\u4e0e\u6700\u5148\u8fdb\u7684IQC\u795e\u7ecf\u7f51\u7edc\u9a8c\u8bc1\u6d41\u7a0b\u8fdb\u884c\u6027\u80fd\u5bf9\u6bd4\u3002", "result": "\u5728\u4ee3\u8868\u6027\u6848\u4f8b\u4e2d\uff0c\u57fa\u4e8e\u6b63\u6027\u7684\u6d4b\u8bd5\u6bd4\u57fa\u4e8eSDP\u7684IQC\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u540c\u65f6\u80fd\u591f\u8ba4\u8bc1\u540e\u8005\u65e0\u6cd5\u5904\u7406\u7684\u673a\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u80fd\u591f\u6709\u6548\u8865\u5145\u98ce\u9669\u611f\u77e5\u63a7\u5236\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2510.06259", "categories": ["cs.CY", "cs.LG", "68T05, 62P10, 68T07", "I.2.11; K.4.1; J.3"], "pdf": "https://arxiv.org/pdf/2510.06259", "abs": "https://arxiv.org/abs/2510.06259", "authors": ["Jahidul Arafat", "Fariha Tasmin", "Sanjaya Poudel", "Ahsan Habib Tareq", "Iftekhar Haider"], "title": "Beyond Static Knowledge Messengers: Towards Adaptive, Fair, and Scalable Federated Learning for Medical AI", "comment": "20 pages, 4 figures, 14 tables. Proposes Adaptive Fair Federated\n  Learning (AFFL) algorithm and MedFedBench benchmark suite for healthcare\n  federated learning", "summary": "Medical AI faces challenges in privacy-preserving collaborative learning\nwhile ensuring fairness across heterogeneous healthcare institutions. Current\nfederated learning approaches suffer from static architectures, slow\nconvergence (45-73 rounds), fairness gaps marginalizing smaller institutions,\nand scalability constraints (15-client limit). We propose Adaptive Fair\nFederated Learning (AFFL) through three innovations: (1) Adaptive Knowledge\nMessengers dynamically scaling capacity based on heterogeneity and task\ncomplexity, (2) Fairness-Aware Distillation using influence-weighted\naggregation, and (3) Curriculum-Guided Acceleration reducing rounds by 60-70%.\nOur theoretical analysis provides convergence guarantees with epsilon-fairness\nbounds, achieving O(T^{-1/2}) + O(H_max/T^{3/4}) rates. Projected results show\n55-75% communication reduction, 56-68% fairness improvement, 34-46% energy\nsavings, and 100+ institution support. The framework enables multi-modal\nintegration across imaging, genomics, EHR, and sensor data while maintaining\nHIPAA/GDPR compliance. We propose MedFedBench benchmark suite for standardized\nevaluation across six healthcare dimensions: convergence efficiency,\ninstitutional fairness, privacy preservation, multi-modal integration,\nscalability, and clinical deployment readiness. Economic projections indicate\n400-800% ROI for rural hospitals and 15-25% performance gains for academic\ncenters. This work presents a seven-question research agenda, 24-month\nimplementation roadmap, and pathways toward democratizing healthcare AI.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u516c\u5e73\u8054\u90a6\u5b66\u4e60(AFFL)\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u77e5\u8bc6\u4f20\u9012\u3001\u516c\u5e73\u611f\u77e5\u84b8\u998f\u548c\u8bfe\u7a0b\u5f15\u5bfc\u52a0\u901f\u4e09\u5927\u521b\u65b0\uff0c\u89e3\u51b3\u533b\u7597AI\u5728\u9690\u79c1\u4fdd\u62a4\u534f\u4f5c\u5b66\u4e60\u4e2d\u7684\u516c\u5e73\u6027\u548c\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u533b\u7597AI\u9762\u4e34\u9690\u79c1\u4fdd\u62a4\u534f\u4f5c\u5b66\u4e60\u7684\u6311\u6218\uff0c\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u9759\u6001\u67b6\u6784\u3001\u6536\u655b\u6162\u3001\u516c\u5e73\u6027\u5dee\u8ddd\u548c\u53ef\u6269\u5c55\u6027\u9650\u5236\u7b49\u95ee\u9898\uff0c\u7279\u522b\u662f\u5bf9\u5c0f\u673a\u6784\u7684\u8fb9\u7f18\u5316\u95ee\u9898\u3002", "method": "1) \u81ea\u9002\u5e94\u77e5\u8bc6\u4f20\u9012\u5668\u6839\u636e\u5f02\u6784\u6027\u548c\u4efb\u52a1\u590d\u6742\u5ea6\u52a8\u6001\u6269\u5c55\u5bb9\u91cf\uff1b2) \u4f7f\u7528\u5f71\u54cd\u52a0\u6743\u805a\u5408\u7684\u516c\u5e73\u611f\u77e5\u84b8\u998f\uff1b3) \u8bfe\u7a0b\u5f15\u5bfc\u52a0\u901f\u51cf\u5c1160-70%\u7684\u8bad\u7ec3\u8f6e\u6b21\u3002", "result": "\u7406\u8bba\u5206\u6790\u63d0\u4f9b\u6536\u655b\u4fdd\u8bc1\u548cepsilon\u516c\u5e73\u6027\u8fb9\u754c\uff0c\u8fbe\u5230O(T^{-1/2}) + O(H_max/T^{3/4})\u6536\u655b\u901f\u7387\u3002\u9884\u8ba1\u51cf\u5c1155-75%\u901a\u4fe1\uff0c\u63d0\u534756-68%\u516c\u5e73\u6027\uff0c\u8282\u770134-46%\u80fd\u8017\uff0c\u652f\u6301100+\u673a\u6784\u3002", "conclusion": "\u8be5\u6846\u67b6\u652f\u6301\u591a\u6a21\u6001\u6570\u636e\u96c6\u6210\uff0c\u4fdd\u6301HIPAA/GDPR\u5408\u89c4\u6027\uff0c\u63d0\u51faMedFedBench\u57fa\u51c6\u5957\u4ef6\uff0c\u7ecf\u6d4e\u9884\u6d4b\u663e\u793a\u519c\u6751\u533b\u9662400-800% ROI\uff0c\u5b66\u672f\u4e2d\u5fc315-25%\u6027\u80fd\u63d0\u5347\uff0c\u63a8\u52a8\u533b\u7597AI\u6c11\u4e3b\u5316\u3002"}}
{"id": "2510.07004", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.07004", "abs": "https://arxiv.org/abs/2510.07004", "authors": ["Joanna \u0106wi\u0105ka\u0142a", "Waldemar Gajda", "Micha\u0142 \u0106wi\u0105ka\u0142a", "Ernest G\u00f3rka", "Dariusz Baran", "Gabriela Wojak", "Piotr Mrzyg\u0142\u00f3d", "Maciej Frasunkiewicz", "Piotr R\u0119czajski", "Jan Piwnik"], "title": "The importance of emotional intelligence in leadership for building an effective team", "comment": null, "summary": "This study investigates the significance of emotional intelligence (EI) as a\nfundamental component of effective leadership and its impact on building\ncohesive, motivated, and high-performing teams. Drawing on data from a survey\nof 100 professionals, the research examines how EI competencies including\nself-awareness, self-regulation, empathy, and social skills shape leadership\neffectiveness, team collaboration, conflict resolution, and workplace\nmotivation. The results demonstrate strong correlations between EI and key\nleadership traits such as empathy, ethical conduct, social competence, and\nmotivational effectiveness. Leaders with higher levels of EI are perceived as\nmore empathetic, ethical, and capable of fostering trust, resolving conflicts,\nand inspiring commitment, thereby improving team dynamics and overall\norganizational performance. The study also highlights that ethical leadership\nsignificantly enhances motivation and that social competence is essential for\nengaging and aligning teams toward common goals. While the findings are\nexploratory due to the limited sample size, they provide valuable insights for\nleadership development programs, emphasizing the importance of integrating\nEI-focused training, coaching, and assessment tools into organizational\nstrategies. The research contributes to leadership theory by demonstrating that\nemotional intelligence is not an isolated skill but a central driver of\ninterpersonal effectiveness, employee engagement, and sustainable business\nsuccess.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u60c5\u5546\u5728\u9886\u5bfc\u529b\u4e2d\u7684\u91cd\u8981\u6027\u53ca\u5176\u5bf9\u56e2\u961f\u5efa\u8bbe\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u9ad8\u60c5\u5546\u9886\u5bfc\u8005\u80fd\u66f4\u597d\u5730\u57f9\u517b\u4fe1\u4efb\u3001\u89e3\u51b3\u51b2\u7a81\u5e76\u6fc0\u52b1\u56e2\u961f\uff0c\u4ece\u800c\u63d0\u5347\u7ec4\u7ec7\u7ee9\u6548\u3002", "motivation": "\u7814\u7a76\u60c5\u5546\u4f5c\u4e3a\u6709\u6548\u9886\u5bfc\u529b\u6838\u5fc3\u7ec4\u6210\u90e8\u5206\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u5b83\u5982\u4f55\u5f71\u54cd\u56e2\u961f\u51dd\u805a\u529b\u3001\u52a8\u673a\u548c\u9ad8\u7ee9\u6548\u3002", "method": "\u901a\u8fc7\u5bf9100\u540d\u4e13\u4e1a\u4eba\u58eb\u7684\u8c03\u67e5\uff0c\u8003\u5bdf\u60c5\u5546\u80fd\u529b\uff08\u81ea\u6211\u610f\u8bc6\u3001\u81ea\u6211\u8c03\u8282\u3001\u5171\u60c5\u548c\u793e\u4ea4\u6280\u80fd\uff09\u5982\u4f55\u5f71\u54cd\u9886\u5bfc\u6548\u80fd\u3001\u56e2\u961f\u534f\u4f5c\u3001\u51b2\u7a81\u89e3\u51b3\u548c\u5de5\u4f5c\u52a8\u673a\u3002", "result": "\u7ed3\u679c\u663e\u793a\u60c5\u5546\u4e0e\u9886\u5bfc\u7279\u8d28\uff08\u5171\u60c5\u3001\u9053\u5fb7\u884c\u4e3a\u3001\u793e\u4ea4\u80fd\u529b\u548c\u6fc0\u52b1\u6548\u679c\uff09\u4e4b\u95f4\u5b58\u5728\u5f3a\u76f8\u5173\u6027\u3002\u9ad8\u60c5\u5546\u9886\u5bfc\u8005\u88ab\u8ba4\u4e3a\u66f4\u5177\u5171\u60c5\u529b\u3001\u9053\u5fb7\u611f\uff0c\u80fd\u66f4\u597d\u5730\u57f9\u517b\u4fe1\u4efb\u3001\u89e3\u51b3\u51b2\u7a81\u5e76\u6fc0\u52b1\u627f\u8bfa\u3002", "conclusion": "\u60c5\u5546\u4e0d\u662f\u5b64\u7acb\u6280\u80fd\uff0c\u800c\u662f\u4eba\u9645\u6548\u80fd\u3001\u5458\u5de5\u53c2\u4e0e\u5ea6\u548c\u53ef\u6301\u7eed\u5546\u4e1a\u6210\u529f\u7684\u6838\u5fc3\u9a71\u52a8\u529b\uff0c\u5e94\u5c06\u5176\u7eb3\u5165\u9886\u5bfc\u529b\u53d1\u5c55\u8ba1\u5212\u3002"}}
{"id": "2510.07194", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.07194", "abs": "https://arxiv.org/abs/2510.07194", "authors": ["Binyu Yang", "Jinxiao Du", "Junlin He", "Shi An", "Wei Ma"], "title": "Estimating Real Demand Using a Flipped Queueing Model: A Case of Shared Micro-Mobility Services", "comment": null, "summary": "The spatial-temporal imbalance between supply and demand in shared\nmicro-mobility services often leads to observed demand being censored,\nresulting in incomplete records of the underlying real demand. This phenomenon\nundermines the reliability of the collected demand data and hampers downstream\napplications such as demand forecasting, fleet management, and micro-mobility\nplanning. How to accurately estimate the real demand is challenging and has not\nbeen well explored in existing studies. In view of this, we contribute to real\ndemand estimation for shared micro-mobility services by proposing an analytical\nmethod that rigorously derives the real demand under appropriate assumptions.\nRather than directly modeling the intractable relationship between observed\ndemand and real demand, we propose a novel random variable, Generalized Vehicle\nSurvival Time (GVST), which is observable from trip records. The relationship\nbetween GVST and real demand is characterized by introducing a flipped queueing\nmodel (FQM) that captures the operational dynamics of shared micro-mobility\nservices. Specifically, the distribution of GVST is derived within the FQM,\nwhich allows the real demand estimation problem to be transformed into an\ninverse queueing problem. We analytically derive the real demand in closed form\nusing a one-sided estimation method, and solve the problem by a system of\nequations in a two-sided estimation method. We validate the proposed methods\nusing synthetic data and conduct empirical analyses using real-world datasets\nfrom bike-sharing and shared e-scooter systems. The experimental results show\nthat both the two-sided and one-sided methods outperform benchmark models. In\nparticular, the one-sided approach provides a closed-form solution that\ndelivers acceptable accuracy, constituting a practical rule of thumb for\ndemand-related analytics and decision-making processes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f30\u8ba1\u5171\u4eab\u5fae\u51fa\u884c\u670d\u52a1\u771f\u5b9e\u9700\u6c42\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5e7f\u4e49\u8f66\u8f86\u751f\u5b58\u65f6\u95f4(GVST)\u548c\u7ffb\u8f6c\u6392\u961f\u6a21\u578b(FQM)\uff0c\u5c06\u771f\u5b9e\u9700\u6c42\u4f30\u8ba1\u95ee\u9898\u8f6c\u5316\u4e3a\u9006\u6392\u961f\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u95ed\u5f0f\u89e3\u548c\u7cfb\u7edf\u65b9\u7a0b\u4e24\u79cd\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5171\u4eab\u5fae\u51fa\u884c\u670d\u52a1\u4e2d\u4f9b\u9700\u65f6\u7a7a\u4e0d\u5e73\u8861\u5bfc\u81f4\u89c2\u6d4b\u9700\u6c42\u88ab\u622a\u65ad\uff0c\u65e0\u6cd5\u51c6\u786e\u8bb0\u5f55\u771f\u5b9e\u9700\u6c42\uff0c\u8fd9\u5f71\u54cd\u4e86\u9700\u6c42\u9884\u6d4b\u3001\u8f66\u961f\u7ba1\u7406\u7b49\u4e0b\u6e38\u5e94\u7528\u7684\u53ef\u9760\u6027\u3002\u73b0\u6709\u7814\u7a76\u5c1a\u672a\u5f88\u597d\u5730\u89e3\u51b3\u5982\u4f55\u51c6\u786e\u4f30\u8ba1\u771f\u5b9e\u9700\u6c42\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5e7f\u4e49\u8f66\u8f86\u751f\u5b58\u65f6\u95f4(GVST)\u4f5c\u4e3a\u53ef\u89c2\u6d4b\u53d8\u91cf\uff0c\u5f15\u5165\u7ffb\u8f6c\u6392\u961f\u6a21\u578b(FQM)\u63cf\u8ff0GVST\u4e0e\u771f\u5b9e\u9700\u6c42\u7684\u5173\u7cfb\uff0c\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u9006\u6392\u961f\u95ee\u9898\u3002\u63d0\u4f9b\u5355\u8fb9\u4f30\u8ba1(\u95ed\u5f0f\u89e3)\u548c\u53cc\u8fb9\u4f30\u8ba1(\u65b9\u7a0b\u7ec4)\u4e24\u79cd\u65b9\u6cd5\u3002", "result": "\u4f7f\u7528\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u4e24\u79cd\u65b9\u6cd5\u5747\u4f18\u4e8e\u57fa\u51c6\u6a21\u578b\u3002\u5355\u8fb9\u65b9\u6cd5\u63d0\u4f9b\u95ed\u5f0f\u89e3\u4e14\u7cbe\u5ea6\u53ef\u63a5\u53d7\uff0c\u53ef\u4f5c\u4e3a\u9700\u6c42\u76f8\u5173\u5206\u6790\u548c\u51b3\u7b56\u7684\u5b9e\u7528\u7ecf\u9a8c\u6cd5\u5219\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u4f30\u8ba1\u5171\u4eab\u5fae\u51fa\u884c\u670d\u52a1\u7684\u771f\u5b9e\u9700\u6c42\uff0c\u89e3\u51b3\u4e86\u89c2\u6d4b\u9700\u6c42\u622a\u65ad\u95ee\u9898\uff0c\u4e3a\u9700\u6c42\u9884\u6d4b\u548c\u8fd0\u8425\u7ba1\u7406\u63d0\u4f9b\u4e86\u53ef\u9760\u5de5\u5177\u3002"}}
{"id": "2510.06357", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06357", "abs": "https://arxiv.org/abs/2510.06357", "authors": ["Grayson Byrd", "Corban Rivera", "Bethany Kemp", "Meghan Booker", "Aurora Schmidt", "Celso M de Melo", "Lalithkumar Seenivasan", "Mathias Unberath"], "title": "Constrained Natural Language Action Planning for Resilient Embodied Systems", "comment": null, "summary": "Replicating human-level intelligence in the execution of embodied tasks\nremains challenging due to the unconstrained nature of real-world environments.\nNovel use of large language models (LLMs) for task planning seeks to address\nthe previously intractable state/action space of complex planning tasks, but\nhallucinations limit their reliability, and thus, viability beyond a research\ncontext. Additionally, the prompt engineering required to achieve adequate\nsystem performance lacks transparency, and thus, repeatability. In contrast to\nLLM planning, symbolic planning methods offer strong reliability and\nrepeatability guarantees, but struggle to scale to the complexity and ambiguity\nof real-world tasks. We introduce a new robotic planning method that augments\nLLM planners with symbolic planning oversight to improve reliability and\nrepeatability, and provide a transparent approach to defining hard constraints\nwith considerably stronger clarity than traditional prompt engineering.\nImportantly, these augmentations preserve the reasoning capabilities of LLMs\nand retain impressive generalization in open-world environments. We demonstrate\nour approach in simulated and real-world environments. On the ALFWorld planning\nbenchmark, our approach outperforms current state-of-the-art methods, achieving\na near-perfect 99% success rate. Deployment of our method to a real-world\nquadruped robot resulted in 100% task success compared to 50% and 30% for pure\nLLM and symbolic planners across embodied pick and place tasks. Our approach\npresents an effective strategy to enhance the reliability, repeatability and\ntransparency of LLM-based robot planners while retaining their key strengths:\nflexibility and generalizability to complex real-world environments. We hope\nthat this work will contribute to the broad goal of building resilient embodied\nintelligent systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LLM\u89c4\u5212\u548c\u7b26\u53f7\u89c4\u5212\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b26\u53f7\u89c4\u5212\u76d1\u7763\u589e\u5f3aLLM\u89c4\u5212\u5668\u7684\u53ef\u9760\u6027\u548c\u53ef\u91cd\u590d\u6027\uff0c\u5728ALFWorld\u57fa\u51c6\u4e0a\u8fbe\u523099%\u6210\u529f\u7387\uff0c\u5728\u771f\u5b9e\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u5b9e\u73b0100%\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3LLM\u89c4\u5212\u5728\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u548c\u53ef\u9760\u6027\u4e0d\u8db3\uff0c\u540c\u65f6\u514b\u670d\u7eaf\u7b26\u53f7\u89c4\u5212\u65b9\u6cd5\u5728\u590d\u6742\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u5c06LLM\u89c4\u5212\u4e0e\u7b26\u53f7\u89c4\u5212\u76d1\u7763\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u7b26\u53f7\u89c4\u5212\u63d0\u4f9b\u786c\u7ea6\u675f\u548c\u53ef\u9760\u6027\u4fdd\u8bc1\uff0c\u540c\u65f6\u4fdd\u7559LLM\u7684\u63a8\u7406\u80fd\u529b\u548c\u6cdb\u5316\u6027\u3002", "result": "\u5728ALFWorld\u89c4\u5212\u57fa\u51c6\u4e0a\u8fbe\u523099%\u6210\u529f\u7387\uff0c\u5728\u771f\u5b9e\u56db\u8db3\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u5b9e\u73b0100%\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u7eafLLM\u89c4\u5212\uff0850%\uff09\u548c\u7eaf\u7b26\u53f7\u89c4\u5212\uff0830%\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u57fa\u4e8eLLM\u7684\u673a\u5668\u4eba\u89c4\u5212\u5668\u7684\u53ef\u9760\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u900f\u660e\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5176\u5728\u590d\u6742\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u7075\u6d3b\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.06797", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.06797", "abs": "https://arxiv.org/abs/2510.06797", "authors": ["Hayato Shinto", "Yu Ohki", "Kenji Mizumoto", "Kei Saito"], "title": "Visualization of Interpersonal Communication using Indoor Positioning Technology with UWB Tags", "comment": null, "summary": "In conjunction with a social gathering held on a university campus, the\nmovement of attendees were tracked within the venue for approximately two hours\nusing a UWB indoor positioning system, in order to visualize their\ninterpersonal communication. Network and community analyses were performed on\nattendee interaction data, and the evolution of communities over time was\nfurther investigated through repeated community analysis at different time\npoints. Furthermore, recognizing the influence of distance thresholds on\ndefining contact, we discussed how varying these thresholds affected the\nresulting network structure and community analysis outcomes. This study\nconfirmed that the temporal evolution of communities identified through\ncommunity analysis broadly corresponded with the visually observed groupings of\nparticipants using the UWB indoor positioning system.", "AI": {"tldr": "\u4f7f\u7528UWB\u5ba4\u5185\u5b9a\u4f4d\u7cfb\u7edf\u8ffd\u8e2a\u5927\u5b66\u793e\u4ea4\u805a\u4f1a\u53c2\u4e0e\u8005\u7684\u79fb\u52a8\uff0c\u901a\u8fc7\u793e\u533a\u5206\u6790\u7814\u7a76\u4eba\u9645\u4ea4\u6d41\u7684\u52a8\u6001\u6f14\u53d8\uff0c\u5e76\u63a2\u8ba8\u8ddd\u79bb\u9608\u503c\u5bf9\u7f51\u7edc\u7ed3\u6784\u7684\u5f71\u54cd\u3002", "motivation": "\u901a\u8fc7\u7cbe\u786e\u7684\u5ba4\u5185\u5b9a\u4f4d\u6280\u672f\u53ef\u89c6\u5316\u4eba\u9645\u4ea4\u6d41\u6a21\u5f0f\uff0c\u7814\u7a76\u793e\u4ea4\u6d3b\u52a8\u4e2d\u793e\u533a\u5f62\u6210\u7684\u52a8\u6001\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528UWB\u5ba4\u5185\u5b9a\u4f4d\u7cfb\u7edf\u8ffd\u8e2a\u53c2\u4e0e\u8005\u79fb\u52a8\uff0c\u8fdb\u884c\u7f51\u7edc\u548c\u793e\u533a\u5206\u6790\uff0c\u5e76\u5728\u4e0d\u540c\u65f6\u95f4\u70b9\u91cd\u590d\u793e\u533a\u5206\u6790\u4ee5\u7814\u7a76\u793e\u533a\u6f14\u5316\uff0c\u540c\u65f6\u63a2\u8ba8\u4e0d\u540c\u8ddd\u79bb\u9608\u503c\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "result": "\u793e\u533a\u5206\u6790\u8bc6\u522b\u51fa\u7684\u793e\u533a\u65f6\u95f4\u6f14\u5316\u4e0eUWB\u7cfb\u7edf\u89c6\u89c9\u89c2\u5bdf\u5230\u7684\u53c2\u4e0e\u8005\u5206\u7ec4\u57fa\u672c\u4e00\u81f4\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9e\u4e86\u901a\u8fc7\u793e\u533a\u5206\u6790\u8bc6\u522b\u7684\u793e\u533a\u65f6\u95f4\u6f14\u5316\u4e0e\u89c6\u89c9\u89c2\u5bdf\u7ed3\u679c\u76f8\u7b26\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u5206\u6790\u4eba\u9645\u4ea4\u6d41\u52a8\u6001\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.07009", "categories": ["cs.ET", "cs.HC", "I.3.7"], "pdf": "https://arxiv.org/pdf/2510.07009", "abs": "https://arxiv.org/abs/2510.07009", "authors": ["Takahiro Matsumoto", "Takahiro Kusabuka", "Hiroshi Chigira", "Kazuhiko Murasaki", "Kakagu Komazaki", "Masafumi Suzuki", "Masakatsu Aoki"], "title": "The Stage Comes to You: A Real-Time Tele-Immersive System with 3D Point Clouds and Vibrotactile Feedback", "comment": "2 pages, 1 figure. Accepted for presentation at SIGGRAPH Asia 2025\n  Posters. The final version will appear in the ACM Digital Library", "summary": "We present a low-latency tele-immersive entertainment system that streams 3D\npoint clouds and performers' footstep vibrations, creating the sense that the\nstage is present. Moving performers and their surroundings are captured as\ndynamic point clouds under rapidly changing lighting, then processed,\ntransmitted, and rendered within a total latency of less than 100 ms. Under\nhigh ambient noise, footstep vibrations are sensed by wearable accelerometers.\nReal-time visual and haptic streams are delivered to a remote venue, where a\nlarge 3D LED wall and a vibration-efficient haptic floor envelop dozens of\nspectators. A public trial at Expo 2025 linked sites 20 km apart: visitors\nwatched a live dance show and conversed with performers without noticeable\ndelay.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4f4e\u5ef6\u8fdf\u7684\u8fdc\u7a0b\u6c89\u6d78\u5f0f\u5a31\u4e50\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f20\u8f933D\u70b9\u4e91\u548c\u811a\u6b65\u632f\u52a8\uff0c\u5728100ms\u603b\u5ef6\u8fdf\u5185\u5b9e\u73b0\u8fdc\u7a0b\u821e\u53f0\u7684\u5b9e\u65f6\u5448\u73b0\u3002", "motivation": "\u4e3a\u4e86\u521b\u5efa\u8fdc\u7a0b\u821e\u53f0\u7684\u4e34\u573a\u611f\uff0c\u8ba9\u89c2\u4f17\u80fd\u591f\u5b9e\u65f6\u89c2\u770b\u8868\u6f14\u5e76\u4e0e\u8868\u6f14\u8005\u4e92\u52a8\uff0c\u6d88\u9664\u5730\u7406\u8ddd\u79bb\u5e26\u6765\u7684\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u52a8\u6001\u70b9\u4e91\u6355\u6349\u79fb\u52a8\u8868\u6f14\u8005\u53ca\u5176\u73af\u5883\uff0c\u901a\u8fc7\u53ef\u7a7f\u6234\u52a0\u901f\u5ea6\u8ba1\u611f\u77e5\u811a\u6b65\u632f\u52a8\uff0c\u5c06\u5b9e\u65f6\u89c6\u89c9\u548c\u89e6\u89c9\u6d41\u4f20\u8f93\u5230\u8fdc\u7a0b\u573a\u5730\uff0c\u901a\u8fc7\u5927\u578b3D LED\u5899\u548c\u632f\u52a8\u89e6\u89c9\u5730\u677f\u5448\u73b0\u7ed9\u89c2\u4f17\u3002", "result": "\u57282025\u5e74\u4e16\u535a\u4f1a\u4e0a\u6210\u529f\u8fde\u63a5\u76f8\u8ddd20\u516c\u91cc\u7684\u573a\u5730\uff0c\u89c2\u4f17\u89c2\u770b\u73b0\u573a\u821e\u8e48\u8868\u6f14\u5e76\u4e0e\u8868\u6f14\u8005\u4ea4\u8c08\uff0c\u6ca1\u6709\u660e\u663e\u5ef6\u8fdf\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u8bc1\u660e\u4e86\u5728100ms\u5ef6\u8fdf\u5185\u5b9e\u73b0\u8fdc\u7a0b\u6c89\u6d78\u5f0f\u5a31\u4e50\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u8fdc\u7a0b\u8868\u6f14\u548c\u4e92\u52a8\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2510.06288", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06288", "abs": "https://arxiv.org/abs/2510.06288", "authors": ["Raj Ghugare", "Catherine Ji", "Kathryn Wantlin", "Jin Schofield", "Benjamin Eysenbach"], "title": "BuilderBench -- A benchmark for generalist agents", "comment": "Project page: https://rajghugare19.github.io/builderbench and Code:\n  https://github.com/rajghugare19/builderbench", "summary": "Today's AI models learn primarily through mimicry and sharpening, so it is\nnot surprising that they struggle to solve problems beyond the limits set by\nexisting data. To solve novel problems, agents should acquire skills for\nexploring and learning through experience. Finding a scalable learning\nmechanism for developing agents that learn through interaction remains a major\nopen problem. In this work, we introduce BuilderBench, a benchmark to\naccelerate research into agent pre-training that centers open-ended\nexploration. BuilderBench requires agents to learn how to build any structure\nusing blocks. BuilderBench is equipped with $(1)$ a hardware accelerated\nsimulator of a robotic agent interacting with various physical blocks, and\n$(2)$ a task-suite with over 42 diverse target structures that are carefully\ncurated to test an understanding of physics, mathematics, and long-horizon\nplanning. During training, agents have to explore and learn general principles\nabout the environment without any external supervision. During evaluation,\nagents have to build the unseen target structures from the task suite. Solving\nthese tasks requires a sort of \\emph{embodied reasoning} that is not reflected\nin words but rather in actions, experimenting with different strategies and\npiecing them together. Our experiments show that many of these tasks challenge\nthe current iteration of algorithms. Hence, we also provide a ``training\nwheels'' protocol, in which agents are trained and evaluated to build a single\ntarget structure from the task suite. Finally, we provide single-file\nimplementations of six different algorithms as a reference point for\nresearchers.", "AI": {"tldr": "\u63d0\u51fa\u4e86BuilderBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u52a0\u901f\u9762\u5411\u5f00\u653e\u63a2\u7d22\u7684\u667a\u80fd\u4f53\u9884\u8bad\u7ec3\u7814\u7a76\u3002\u8be5\u57fa\u51c6\u5305\u542b\u786c\u4ef6\u52a0\u901f\u7684\u673a\u5668\u4eba\u6a21\u62df\u5668\u548c42\u4e2a\u591a\u6837\u5316\u76ee\u6807\u7ed3\u6784\u4efb\u52a1\uff0c\u8981\u6c42\u667a\u80fd\u4f53\u901a\u8fc7\u65e0\u76d1\u7763\u63a2\u7d22\u5b66\u4e60\u7269\u7406\u539f\u7406\u548c\u957f\u671f\u89c4\u5212\u80fd\u529b\u3002", "motivation": "\u5f53\u524dAI\u6a21\u578b\u4e3b\u8981\u901a\u8fc7\u6a21\u4eff\u5b66\u4e60\uff0c\u96be\u4ee5\u89e3\u51b3\u8d85\u51fa\u5df2\u6709\u6570\u636e\u8303\u56f4\u7684\u65b0\u95ee\u9898\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u901a\u8fc7\u4ea4\u4e92\u63a2\u7d22\u5b66\u4e60\u7684\u667a\u80fd\u4f53\uff0c\u4f46\u53ef\u6269\u5c55\u7684\u5b66\u4e60\u673a\u5236\u4ecd\u662f\u4e3b\u8981\u5f00\u653e\u6027\u95ee\u9898\u3002", "method": "\u6784\u5efaBuilderBench\u57fa\u51c6\uff0c\u5305\u542b\uff1a(1)\u786c\u4ef6\u52a0\u901f\u7684\u673a\u5668\u4eba\u6a21\u62df\u5668\uff0c\u6a21\u62df\u4e0e\u7269\u7406\u79ef\u6728\u7684\u4ea4\u4e92\uff1b(2)42\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684\u76ee\u6807\u7ed3\u6784\u4efb\u52a1\uff0c\u6d4b\u8bd5\u7269\u7406\u3001\u6570\u5b66\u7406\u89e3\u548c\u957f\u671f\u89c4\u5212\u80fd\u529b\u3002\u667a\u80fd\u4f53\u5728\u8bad\u7ec3\u9636\u6bb5\u65e0\u76d1\u7763\u63a2\u7d22\u5b66\u4e60\u73af\u5883\u539f\u7406\uff0c\u5728\u8bc4\u4f30\u9636\u6bb5\u6784\u5efa\u672a\u89c1\u8fc7\u7684\u76ee\u6807\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5f53\u524d\u7b97\u6cd5\u5728\u591a\u6570\u4efb\u52a1\u4e0a\u4ecd\u9762\u4e34\u6311\u6218\u3002\u4e3a\u6b64\u63d0\u4f9b\u4e86\"\u8bad\u7ec3\u8f6e\"\u534f\u8bae\uff0c\u8ba9\u667a\u80fd\u4f53\u9488\u5bf9\u5355\u4e2a\u76ee\u6807\u7ed3\u6784\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002\u540c\u65f6\u63d0\u4f9b\u4e86\u516d\u79cd\u7b97\u6cd5\u7684\u5355\u6587\u4ef6\u5b9e\u73b0\u4f5c\u4e3a\u53c2\u8003\u57fa\u51c6\u3002", "conclusion": "BuilderBench\u57fa\u51c6\u63a8\u52a8\u4e86\u9762\u5411\u5f00\u653e\u63a2\u7d22\u7684\u667a\u80fd\u4f53\u9884\u8bad\u7ec3\u7814\u7a76\uff0c\u8981\u6c42\u667a\u80fd\u4f53\u53d1\u5c55\u5177\u8eab\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u884c\u52a8\u800c\u975e\u8bed\u8a00\u8fdb\u884c\u5b9e\u9a8c\u548c\u7b56\u7565\u6574\u5408\uff0c\u4e3a\u89e3\u51b3\u65b0\u9896\u95ee\u9898\u63d0\u4f9b\u4e86\u91cd\u8981\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2510.06835", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.06835", "abs": "https://arxiv.org/abs/2510.06835", "authors": ["Hongjian Chen", "Changyun Wen", "Xiaolei Li", "Jiaqi Yan"], "title": "Resilient Multi-Dimensional Consensus and Distributed Optimization against Agent-Based and Denial-of-Service Attacks", "comment": null, "summary": "In this paper, we consider the resilient multi-dimensional consensus and\ndistributed optimization problems of multi-agent systems (MASs) in the presence\nof both agent-based and denial-of-service (DoS) attacks. The considered\nagent-based attacks can cover malicious, Byzantine, and stubborn agents. The\nlinks between agents in the network can be blocked by DoS attacks, which may\nlead the digraph to be time-varying and even disconnected. The objective is to\nensure that the remaining benign agents achieve consensus. To this end, an\n\"auxiliary point\"-based resilient control algorithm is proposed for MASs. Under\nthe proposed algorithm, each healthy agent constructs a \"safe kernel\" utilizing\nthe states of its in-neighbors and updates its state toward a specific point\nwithin this kernel at each iteration. If an agent cannot receive its neighbors'\nstates owing to DoS attacks, it will use the states received immediately before\nthe DoS period. Moreover, a resilient multi-dimensional distributed\noptimization (RMDO) algorithm is also proposed. Theoretical proofs and\nnumerical examples are presented to demonstrate the effectiveness of the\nproposed algorithms.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\"\u8f85\u52a9\u70b9\"\u7684\u5f39\u6027\u63a7\u5236\u7b97\u6cd5\uff0c\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u4ee3\u7406\u653b\u51fb\u548cDoS\u653b\u51fb\u4e0b\u7684\u591a\u7ef4\u5ea6\u5171\u8bc6\u548c\u5206\u5e03\u5f0f\u4f18\u5316\u95ee\u9898", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u540c\u65f6\u9762\u4e34\u4ee3\u7406\u653b\u51fb\uff08\u6076\u610f\u3001\u62dc\u5360\u5ead\u3001\u987d\u56fa\u4ee3\u7406\uff09\u548cDoS\u653b\u51fb\u65f6\u7684\u5f39\u6027\u5171\u8bc6\u548c\u4f18\u5316\u95ee\u9898\uff0c\u786e\u4fdd\u826f\u6027\u4ee3\u7406\u8fbe\u6210\u5171\u8bc6", "method": "\u4f7f\u7528\"\u8f85\u52a9\u70b9\"\u5f39\u6027\u63a7\u5236\u7b97\u6cd5\uff0c\u6bcf\u4e2a\u5065\u5eb7\u4ee3\u7406\u6784\u5efa\"\u5b89\u5168\u6838\"\u5e76\u66f4\u65b0\u72b6\u6001\uff1bDoS\u671f\u95f4\u4f7f\u7528\u6700\u8fd1\u63a5\u6536\u7684\u72b6\u6001\uff1b\u63d0\u51fa\u5f39\u6027\u591a\u7ef4\u5ea6\u5206\u5e03\u5f0f\u4f18\u5316\u7b97\u6cd5", "result": "\u7406\u8bba\u8bc1\u660e\u548c\u6570\u503c\u793a\u4f8b\u9a8c\u8bc1\u4e86\u6240\u63d0\u7b97\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u4ee3\u7406\u653b\u51fb\u548cDoS\u653b\u51fb\uff0c\u786e\u4fdd\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u591a\u7ef4\u5171\u8bc6\u548c\u5206\u5e03\u5f0f\u4f18\u5316\u4e2d\u7684\u5f39\u6027\u6027\u80fd"}}
{"id": "2510.06279", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.06279", "abs": "https://arxiv.org/abs/2510.06279", "authors": ["Lawrence Feldman", "Matthew Bomparola"], "title": "Technical Overview of Safe3Step (S3S): Power Ratings and quality wins for selecting at-large teams to the NCAA Division I Men's Lacrosse Championship", "comment": "Whitepaper; 5 pages", "summary": "This document describes a system for selecting teams to the NCAA Men's\nDivision I Lacrosse Championship Tournament called \"Safe3Step\" (S3S) that was\ndeveloped in conversation with the NCAA Lacrosse Selection Criteria and Ranking\nCommittee (SCR) with the objective of improving on the Ratings Percentage Index\n(RPI). S3S employs three steps that: 1) evaluate the strength of each team\nbased on score data, 2) award S3S points to each team based on the quality of\nits wins and losses, ranking teams accordingly, and 3) examine each pair of\nteams with adjacent rankings, swapping ranks if the lower-ranked team has a\nbetter head-to-head record against the higher-ranked team. Safe3Step is not\nentirely new, but it improves on other \"quality win\" methods by using Power\nRatings to identify team strengths, respecting head-to-head records, and\nadhering to standards of simplicity, transparency, and objectivity. Empirical\nanalysis is left to future work.", "AI": {"tldr": "Safe3Step (S3S) \u662f\u4e00\u4e2a\u7528\u4e8eNCAA\u7537\u5b50\u957f\u66f2\u68cd\u7403\u9526\u6807\u8d5b\u961f\u4f0d\u9009\u62d4\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e09\u4e2a\u6b65\u9aa4\u6539\u8fdbRPI\u8bc4\u5206\uff1a\u8bc4\u4f30\u961f\u4f0d\u5b9e\u529b\u3001\u57fa\u4e8e\u6bd4\u8d5b\u8d28\u91cf\u5206\u914d\u79ef\u5206\u3001\u8c03\u6574\u76f8\u90bb\u6392\u540d\u961f\u4f0d\u7684\u987a\u5e8f\u3002", "motivation": "\u6539\u8fdb\u73b0\u6709\u7684RPI\u8bc4\u5206\u7cfb\u7edf\uff0c\u4e3aNCAA\u957f\u66f2\u68cd\u7403\u9526\u6807\u8d5b\u63d0\u4f9b\u66f4\u7b80\u5355\u3001\u900f\u660e\u548c\u5ba2\u89c2\u7684\u961f\u4f0d\u9009\u62d4\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e09\u6b65\u6cd5\uff1a1) \u57fa\u4e8e\u6bd4\u5206\u6570\u636e\u8bc4\u4f30\u961f\u4f0d\u5b9e\u529b\uff1b2) \u6839\u636e\u80dc\u5229\u548c\u5931\u8d25\u7684\u8d28\u91cf\u5206\u914dS3S\u79ef\u5206\u5e76\u6392\u540d\uff1b3) \u68c0\u67e5\u76f8\u90bb\u6392\u540d\u961f\u4f0d\u7684\u5bf9\u6218\u8bb0\u5f55\uff0c\u5fc5\u8981\u65f6\u4ea4\u6362\u6392\u540d\u3002", "result": "\u5f00\u53d1\u4e86Safe3Step\u7cfb\u7edf\uff0c\u8be5\u65b9\u6cd5\u4f7f\u7528\u5b9e\u529b\u8bc4\u7ea7\u8bc6\u522b\u961f\u4f0d\u5f3a\u5ea6\uff0c\u5c0a\u91cd\u5bf9\u6218\u8bb0\u5f55\uff0c\u5e76\u4fdd\u6301\u7b80\u5355\u6027\u3001\u900f\u660e\u5ea6\u548c\u5ba2\u89c2\u6027\u6807\u51c6\u3002", "conclusion": "Safe3Step\u662f\u5bf9\u73b0\u6709\"\u8d28\u91cf\u80dc\u5229\"\u65b9\u6cd5\u7684\u6539\u8fdb\uff0c\u4f46\u5b9e\u8bc1\u5206\u6790\u7559\u5f85\u672a\u6765\u5de5\u4f5c\u5b8c\u6210\u3002"}}
{"id": "2510.07016", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.07016", "abs": "https://arxiv.org/abs/2510.07016", "authors": ["Dariusz Baran", "Ernest G\u00f3rka", "Micha\u0142 \u0106wi\u0105ka\u0142a", "Gabriela Wojak", "Mateusz Grzelak", "Katarzyna Olszy\u0144ska", "Piotr Mrzyg\u0142\u00f3d", "Maciej Frasunkiewicz", "Piotr R\u0119czajski", "Maciej \u015alusarczyk", "Jan Piwnik"], "title": "The role of communication in effective business management", "comment": null, "summary": "This paper examines the impact of internal communication on effective\nbusiness management through a comparative analysis of two medium-sized car\nrental companies operating in Poland. Using a structured survey completed by\n220 employees, the study evaluates 15 communication-related factors, including\nfeedback culture, managerial accessibility, message clarity, and\ninterdepartmental coordination. The findings indicate that Company X\nsignificantly outperforms Company Y across all evaluated dimensions, largely\ndue to its use of advanced communication technologies, participatory models,\nand clear feedback mechanisms. The research highlights the strategic role of\ntwo-way communication in fostering employee engagement, organizational\ntransparency, and operational efficiency. It contributes to the field by\noffering a rare, data-driven comparison within one industry and supports\nexisting models that link internal communication to job satisfaction and\nmotivation. Limitations include reliance on self-reported data and focus on a\nsingle industry and country. Future studies are recommended to explore\ncross-sector and longitudinal perspectives, especially in the context of\ndigital and hybrid work environments.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6bd4\u8f83\u6ce2\u5170\u4e24\u5bb6\u4e2d\u578b\u6c7d\u8f66\u79df\u8d41\u516c\u53f8\u7684\u5185\u90e8\u6c9f\u901a\u5b9e\u8df5\uff0c\u53d1\u73b0\u91c7\u7528\u5148\u8fdb\u6c9f\u901a\u6280\u672f\u3001\u53c2\u4e0e\u5f0f\u6a21\u5f0f\u548c\u6e05\u6670\u53cd\u9988\u673a\u5236\u7684\u516c\u53f8\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6c9f\u901a\u6a21\u5f0f\u7684\u516c\u53f8\uff0c\u5f3a\u8c03\u4e86\u53cc\u5411\u6c9f\u901a\u5bf9\u5458\u5de5\u53c2\u4e0e\u5ea6\u548c\u8fd0\u8425\u6548\u7387\u7684\u6218\u7565\u91cd\u8981\u6027\u3002", "motivation": "\u7814\u7a76\u5185\u90e8\u6c9f\u901a\u5bf9\u6709\u6548\u4f01\u4e1a\u7ba1\u7406\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u6c7d\u8f66\u79df\u8d41\u884c\u4e1a\u4e2d\u8fdb\u884c\u6570\u636e\u9a71\u52a8\u7684\u6bd4\u8f83\u5206\u6790\uff0c\u586b\u8865\u8be5\u9886\u57df\u5b9e\u8bc1\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u5316\u95ee\u5377\u8c03\u67e5\u65b9\u6cd5\uff0c\u5bf9220\u540d\u5458\u5de5\u8fdb\u884c\u4e86\u8c03\u67e5\uff0c\u8bc4\u4f30\u4e8615\u4e2a\u6c9f\u901a\u76f8\u5173\u56e0\u7d20\uff0c\u5305\u62ec\u53cd\u9988\u6587\u5316\u3001\u7ba1\u7406\u8005\u53ef\u53ca\u6027\u3001\u4fe1\u606f\u6e05\u6670\u5ea6\u548c\u8de8\u90e8\u95e8\u534f\u8c03\u7b49\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u516c\u53f8X\u5728\u6240\u6709\u8bc4\u4f30\u7ef4\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u516c\u53f8Y\uff0c\u4e3b\u8981\u5f52\u56e0\u4e8e\u5176\u4f7f\u7528\u5148\u8fdb\u6c9f\u901a\u6280\u672f\u3001\u53c2\u4e0e\u5f0f\u6a21\u5f0f\u548c\u6e05\u6670\u53cd\u9988\u673a\u5236\u3002", "conclusion": "\u5185\u90e8\u6c9f\u901a\u5728\u4fc3\u8fdb\u5458\u5de5\u53c2\u4e0e\u3001\u7ec4\u7ec7\u900f\u660e\u5ea6\u548c\u8fd0\u8425\u6548\u7387\u65b9\u9762\u5177\u6709\u6218\u7565\u4f5c\u7528\uff0c\u672a\u6765\u7814\u7a76\u5e94\u63a2\u7d22\u8de8\u884c\u4e1a\u548c\u7eb5\u5411\u89c6\u89d2\uff0c\u7279\u522b\u662f\u5728\u6570\u5b57\u548c\u6df7\u5408\u5de5\u4f5c\u73af\u5883\u80cc\u666f\u4e0b\u3002"}}
{"id": "2510.06481", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.06481", "abs": "https://arxiv.org/abs/2510.06481", "authors": ["Amirhossein Mollaei Khass", "Guangyi Liu", "Vivek Pandey", "Wen Jiang", "Boshu Lei", "Kostas Daniilidis", "Nader Motee"], "title": "Active Next-Best-View Optimization for Risk-Averse Path Planning", "comment": null, "summary": "Safe navigation in uncertain environments requires planning methods that\nintegrate risk aversion with active perception. In this work, we present a\nunified framework that refines a coarse reference path by constructing\ntail-sensitive risk maps from Average Value-at-Risk statistics on an\nonline-updated 3D Gaussian-splat Radiance Field. These maps enable the\ngeneration of locally safe and feasible trajectories. In parallel, we formulate\nNext-Best-View (NBV) selection as an optimization problem on the SE(3) pose\nmanifold, where Riemannian gradient descent maximizes an expected information\ngain objective to reduce uncertainty most critical for imminent motion. Our\napproach advances the state-of-the-art by coupling risk-averse path refinement\nwith NBV planning, while introducing scalable gradient decompositions that\nsupport efficient online updates in complex environments. We demonstrate the\neffectiveness of the proposed framework through extensive computational\nstudies.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u7ebf\u66f4\u65b0\u76843D\u9ad8\u65af\u6e85\u5c04\u8f90\u5c04\u573a\u6784\u5efa\u5c3e\u90e8\u654f\u611f\u98ce\u9669\u5730\u56fe\u6765\u7ec6\u5316\u53c2\u8003\u8def\u5f84\uff0c\u540c\u65f6\u5c06\u6700\u4f73\u89c6\u70b9\u9009\u62e9\u5efa\u6a21\u4e3aSE(3)\u6d41\u5f62\u4e0a\u7684\u4f18\u5316\u95ee\u9898\uff0c\u8026\u5408\u98ce\u9669\u89c4\u907f\u8def\u5f84\u7ec6\u5316\u4e0e\u4e3b\u52a8\u611f\u77e5\u3002", "motivation": "\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u5b9e\u73b0\u5b89\u5168\u5bfc\u822a\u9700\u8981\u5c06\u98ce\u9669\u89c4\u907f\u4e0e\u4e3b\u52a8\u611f\u77e5\u76f8\u7ed3\u5408\uff0c\u4ee5\u751f\u6210\u5c40\u90e8\u5b89\u5168\u53ef\u884c\u7684\u8f68\u8ff9\u5e76\u51cf\u5c11\u5bf9\u5373\u5c06\u8fd0\u52a8\u6700\u5173\u952e\u7684\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u4f7f\u7528\u5728\u7ebf\u66f4\u65b0\u76843D\u9ad8\u65af\u6e85\u5c04\u8f90\u5c04\u573a\u6784\u5efa\u57fa\u4e8e\u5e73\u5747\u98ce\u9669\u4ef7\u503c\u7edf\u8ba1\u7684\u5c3e\u90e8\u654f\u611f\u98ce\u9669\u5730\u56fe\u6765\u7ec6\u5316\u53c2\u8003\u8def\u5f84\uff1b\u5c06\u6700\u4f73\u89c6\u70b9\u9009\u62e9\u5efa\u6a21\u4e3aSE(3)\u6d41\u5f62\u4e0a\u7684\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u9ece\u66fc\u68af\u5ea6\u4e0b\u964d\u6700\u5927\u5316\u671f\u671b\u4fe1\u606f\u589e\u76ca\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u8ba1\u7b97\u7814\u7a76\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u98ce\u9669\u89c4\u907f\u8def\u5f84\u7ec6\u5316\u4e0e\u6700\u4f73\u89c6\u70b9\u89c4\u5212\u7684\u8026\u5408\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u53ef\u6269\u5c55\u7684\u68af\u5ea6\u5206\u89e3\u652f\u6301\u590d\u6742\u73af\u5883\u4e2d\u7684\u9ad8\u6548\u5728\u7ebf\u66f4\u65b0\uff0c\u63a8\u8fdb\u4e86\u98ce\u9669\u89c4\u907f\u8def\u5f84\u7ec6\u5316\u4e0e\u4e3b\u52a8\u611f\u77e5\u76f8\u7ed3\u5408\u7684\u6280\u672f\u6c34\u5e73\u3002"}}
{"id": "2510.07226", "categories": ["cs.SI", "cs.CL", "cs.CY", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2510.07226", "abs": "https://arxiv.org/abs/2510.07226", "authors": ["Lucio La Cava", "Luca Maria Aiello", "Andrea Tagarelli"], "title": "Machines in the Crowd? Measuring the Footprint of Machine-Generated Text on Reddit", "comment": null, "summary": "Generative Artificial Intelligence is reshaping online communication by\nenabling large-scale production of Machine-Generated Text (MGT) at low cost.\nWhile its presence is rapidly growing across the Web, little is known about how\nMGT integrates into social media environments. In this paper, we present the\nfirst large-scale characterization of MGT on Reddit. Using a state-of-the-art\nstatistical method for detection of MGT, we analyze over two years of activity\n(2022-2024) across 51 subreddits representative of Reddit's main community\ntypes such as information seeking, social support, and discussion. We study the\nconcentration of MGT across communities and over time, and compared MGT to\nhuman-authored text in terms of social signals it expresses and engagement it\nreceives. Our very conservative estimate of MGT prevalence indicates that\nsynthetic text is marginally present on Reddit, but it can reach peaks of up to\n9% in some communities in some months. MGT is unevenly distributed across\ncommunities, more prevalent in subreddits focused on technical knowledge and\nsocial support, and often concentrated in the activity of a small fraction of\nusers. MGT also conveys distinct social signals of warmth and status giving\ntypical of language of AI assistants. Despite these stylistic differences, MGT\nachieves engagement levels comparable than human-authored content and in a few\ncases even higher, suggesting that AI-generated text is becoming an organic\ncomponent of online social discourse. This work offers the first perspective on\nthe MGT footprint on Reddit, paving the way for new investigations involving\nplatform governance, detection strategies, and community dynamics.", "AI": {"tldr": "\u5bf9Reddit\u4e0a\u673a\u5668\u751f\u6210\u6587\u672c(MGT)\u7684\u9996\u4e2a\u5927\u89c4\u6a21\u7814\u7a76\uff0c\u53d1\u73b0MGT\u5728Reddit\u4e0a\u603b\u4f53\u5360\u6bd4\u4e0d\u9ad8\u4f46\u5206\u5e03\u4e0d\u5747\uff0c\u5728\u6280\u672f\u77e5\u8bc6\u548c\u793e\u4f1a\u652f\u6301\u7c7b\u793e\u533a\u53ef\u8fbe9%\uff0c\u4e14\u8868\u8fbe\u51fa\u72ec\u7279\u7684AI\u52a9\u624b\u8bed\u8a00\u98ce\u683c\uff0c\u4f46\u83b7\u5f97\u7684\u53c2\u4e0e\u5ea6\u4e0e\u4eba\u7c7b\u5185\u5bb9\u76f8\u5f53\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u673a\u5668\u751f\u6210\u6587\u672c\u5728\u7f51\u7edc\u4e0a\u8fc5\u901f\u589e\u957f\uff0c\u4f46\u5bf9\u5176\u5982\u4f55\u878d\u5165\u793e\u4ea4\u5a92\u4f53\u73af\u5883\u77e5\u4e4b\u751a\u5c11\uff0c\u9700\u8981\u7814\u7a76MGT\u5728Reddit\u7b49\u5e73\u53f0\u4e0a\u7684\u5206\u5e03\u7279\u5f81\u548c\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u6700\u5148\u8fdb\u7684\u7edf\u8ba1\u65b9\u6cd5\u68c0\u6d4bMGT\uff0c\u5206\u67902022-2024\u5e7451\u4e2a\u4ee3\u8868\u6027Reddit\u5b50\u793e\u533a\u7684\u4e24\u5e74\u6d3b\u52a8\u6570\u636e\uff0c\u7814\u7a76MGT\u5728\u4e0d\u540c\u793e\u533a\u548c\u65f6\u95f4\u4e0a\u7684\u5206\u5e03\uff0c\u5e76\u6bd4\u8f83MGT\u4e0e\u4eba\u7c7b\u6587\u672c\u7684\u793e\u4f1a\u4fe1\u53f7\u8868\u8fbe\u548c\u53c2\u4e0e\u5ea6\u3002", "result": "\u4fdd\u5b88\u4f30\u8ba1\u663e\u793aMGT\u5728Reddit\u4e0a\u603b\u4f53\u5360\u6bd4\u4e0d\u9ad8\uff0c\u4f46\u5728\u6280\u672f\u77e5\u8bc6\u548c\u793e\u4f1a\u652f\u6301\u7c7b\u793e\u533a\u53ef\u8fbe9%\uff1bMGT\u5206\u5e03\u4e0d\u5747\uff0c\u96c6\u4e2d\u5728\u5c11\u6570\u7528\u6237\u6d3b\u52a8\u4e2d\uff1b\u8868\u8fbe\u51fa\u6e29\u6696\u548c\u5730\u4f4d\u7b49\u5178\u578b\u7684AI\u52a9\u624b\u8bed\u8a00\u98ce\u683c\uff1b\u53c2\u4e0e\u5ea6\u4e0e\u4eba\u7c7b\u5185\u5bb9\u76f8\u5f53\u751a\u81f3\u66f4\u9ad8\u3002", "conclusion": "AI\u751f\u6210\u6587\u672c\u6b63\u6210\u4e3a\u5728\u7ebf\u793e\u4ea4\u8bdd\u8bed\u7684\u6709\u673a\u7ec4\u6210\u90e8\u5206\uff0c\u8fd9\u9879\u7814\u7a76\u4e3a\u5e73\u53f0\u6cbb\u7406\u3001\u68c0\u6d4b\u7b56\u7565\u548c\u793e\u533a\u52a8\u6001\u7684\u65b0\u8c03\u67e5\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.07079", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2510.07079", "abs": "https://arxiv.org/abs/2510.07079", "authors": ["Stefano Markidis", "Gilbert Netzer", "Luca Pennati", "Ivy Peng"], "title": "An HPC-Inspired Blueprint for a Technology-Agnostic Quantum Middle Layer", "comment": "Accepted at \"The First International Workshop for Software Frameworks\n  and Workload Management on Quantum-HPC Ecosystems\"", "summary": "We present a blueprint for a quantum middle layer that supports applications\nacross various quantum technologies. Inspired by concepts and abstractions from\nHPC libraries and middleware, our design is backend-neutral and context-aware.\nA program only needs to specify its intent once as typed data and operator\ndescriptors. It declares what the quantum registers mean and which logical\ntransformations are required, without committing to gates, pulses,\ncontinuous-variable routines, or anneal backend. Such execution details are\ncarried separately in a context descriptor and can change per backend without\nmodifying the intent artifacts.\n  We develop a proof of concept implementation that uses JSON files for the\ndescriptors and two backends: a gate-model path realized with IBM Qiskit Aer\nsimulator and an annealing path realized with D-Wave Ocean's simulated\nannealer. On a Max-Cut problem instance, the same typed problem runs on both\nbackends by varying only the operator formulation (Quantum Approximated\nOptimization Algorithm formulation vs. Ising Hamiltonian formulation) and the\ncontext. The proposed middle layer concepts are characterized by portability,\ncomposability, and its minimal core can evolve with hardware capabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u91cf\u5b50\u4e2d\u95f4\u5c42\u84dd\u56fe\uff0c\u652f\u6301\u8de8\u4e0d\u540c\u91cf\u5b50\u6280\u672f\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u610f\u56fe\u63cf\u8ff0\u7b26\u548c\u4e0a\u4e0b\u6587\u63cf\u8ff0\u7b26\u5b9e\u73b0\u540e\u7aef\u4e2d\u7acb\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u91cf\u5b50\u7f16\u7a0b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u91cf\u5b50\u8ba1\u7b97\u4e2d\u4e0d\u540c\u540e\u7aef\u6280\u672f\uff08\u95e8\u6a21\u578b\u3001\u9000\u706b\u7b49\uff09\u4e4b\u95f4\u7684\u517c\u5bb9\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u7f16\u7a0b\u62bd\u8c61\u5c42\uff0c\u4f7f\u7a0b\u5e8f\u53ea\u9700\u6307\u5b9a\u610f\u56fe\u800c\u4e0d\u4f9d\u8d56\u5177\u4f53\u6267\u884c\u7ec6\u8282\u3002", "method": "\u8bbe\u8ba1\u540e\u7aef\u4e2d\u7acb\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u91cf\u5b50\u4e2d\u95f4\u5c42\u67b6\u6784\uff0c\u4f7f\u7528\u7c7b\u578b\u5316\u6570\u636e\u548c\u64cd\u4f5c\u7b26\u63cf\u8ff0\u7b26\u6765\u58f0\u660e\u91cf\u5b50\u5bc4\u5b58\u5668\u7684\u542b\u4e49\u548c\u903b\u8f91\u53d8\u6362\u9700\u6c42\uff0c\u6267\u884c\u7ec6\u8282\u901a\u8fc7\u4e0a\u4e0b\u6587\u63cf\u8ff0\u7b26\u5355\u72ec\u643a\u5e26\u3002", "result": "\u5f00\u53d1\u4e86\u6982\u5ff5\u9a8c\u8bc1\u5b9e\u73b0\uff0c\u4f7f\u7528JSON\u6587\u4ef6\u4f5c\u4e3a\u63cf\u8ff0\u7b26\uff0c\u5728IBM Qiskit Aer\u6a21\u62df\u5668\u548cD-Wave Ocean\u6a21\u62df\u9000\u706b\u5668\u4e0a\u6210\u529f\u8fd0\u884c\u76f8\u540c\u7684Max-Cut\u95ee\u9898\u5b9e\u4f8b\u3002", "conclusion": "\u8be5\u91cf\u5b50\u4e2d\u95f4\u5c42\u6982\u5ff5\u5177\u6709\u53ef\u79fb\u690d\u6027\u3001\u53ef\u7ec4\u5408\u6027\uff0c\u5176\u6700\u5c0f\u6838\u5fc3\u53ef\u968f\u786c\u4ef6\u80fd\u529b\u6f14\u8fdb\uff0c\u4e3a\u8de8\u91cf\u5b50\u6280\u672f\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.06302", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06302", "abs": "https://arxiv.org/abs/2510.06302", "authors": ["Ksenija Lace", "Marite Kirikova"], "title": "Requirements for Game-Based Learning Design Framework for Information System Integration in the Context of Post-Merger Integration", "comment": null, "summary": "Post-merger integration states unique challenges for professionals\nresponsible for information system integration aimed on alignment and\ncombination diverse system architectures of merging organizations. Although the\ntheoretical and practical guidance exists for post-merger integration on the\nbusiness level, there is a significant gap in training for information system\nintegration in this context. In prior research specific methods AMILI (Support\nmethod for informed decision identification) and AMILP (Support method for\ninformed decision-making) were introduced for the support of information system\nintegration decisions in the post-merger integration. But during the practical\napplication was reported high learning curve and low learner motivation. This\npaper explores how game-based learning design can address these limitations by\ntransforming static method training into engaging learning experience. The\nstudy analyzes foundational learning theories, cognitive load and motivation\nmodels, and serious game design frameworks to identify the essential\nrequirements for a game-based learning design framework tailored to information\nsystem integration in post-merger integration. Requirements are structured in\ntwo components: the transformation process and resulting learning experience.\nThe paper concludes with a plan for developing and evaluating the proposed\nframework through iterative design and real-world validation.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u6e38\u620f\u5316\u5b66\u4e60\u8bbe\u8ba1\u89e3\u51b3\u4fe1\u606f\u7cfb\u7edf\u6574\u5408\u57f9\u8bad\u4e2d\u5b66\u4e60\u66f2\u7ebf\u9ad8\u548c\u52a8\u673a\u4f4e\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u9488\u5bf9\u5e76\u8d2d\u540e\u6574\u5408\u7684\u5b9a\u5236\u5316\u6e38\u620f\u5b66\u4e60\u6846\u67b6\u3002", "motivation": "\u5e76\u8d2d\u540e\u4fe1\u606f\u7cfb\u7edf\u6574\u5408\u9762\u4e34\u72ec\u7279\u6311\u6218\uff0c\u73b0\u6709\u57f9\u8bad\u65b9\u6cd5\u5b58\u5728\u5b66\u4e60\u66f2\u7ebf\u9ad8\u3001\u5b66\u4e60\u8005\u52a8\u673a\u4f4e\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5b66\u4e60\u65b9\u6848\u3002", "method": "\u5206\u6790\u57fa\u7840\u5b66\u4e60\u7406\u8bba\u3001\u8ba4\u77e5\u8d1f\u8377\u4e0e\u52a8\u673a\u6a21\u578b\u3001\u4e25\u8083\u6e38\u620f\u8bbe\u8ba1\u6846\u67b6\uff0c\u8bc6\u522b\u6e38\u620f\u5316\u5b66\u4e60\u8bbe\u8ba1\u7684\u5173\u952e\u8981\u6c42\uff0c\u6784\u5efa\u5305\u542b\u8f6c\u6362\u8fc7\u7a0b\u548c\u7ed3\u679c\u5b66\u4e60\u4f53\u9a8c\u4e24\u90e8\u5206\u7684\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u5e76\u8d2d\u540e\u4fe1\u606f\u7cfb\u7edf\u6574\u5408\u7684\u6e38\u620f\u5316\u5b66\u4e60\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u8bbe\u8ba1\u548c\u5b9e\u9645\u9a8c\u8bc1\u8fdb\u884c\u5f00\u53d1\u8bc4\u4f30\u3002", "conclusion": "\u6e38\u620f\u5316\u5b66\u4e60\u8bbe\u8ba1\u80fd\u591f\u5c06\u9759\u6001\u65b9\u6cd5\u57f9\u8bad\u8f6c\u5316\u4e3a\u5f15\u4eba\u5165\u80dc\u7684\u5b66\u4e60\u4f53\u9a8c\uff0c\u6709\u6548\u89e3\u51b3\u73b0\u6709\u57f9\u8bad\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.06846", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.06846", "abs": "https://arxiv.org/abs/2510.06846", "authors": ["Johannes Autenrieb", "Mark Spiller"], "title": "Decentralized CBF-based Safety Filters for Collision Avoidance of Cooperative Missile Systems with Input Constraints", "comment": "7 pages, 5 figures", "summary": "This paper presents a decentralized safety filter for collision avoidance in\nmulti-agent aerospace interception scenarios. The approach leverages robust\ncontrol barrier functions (RCBFs) to guarantee forward invariance of safety\nsets under bounded inputs and high-relative-degree dynamics. Each effector\nexecutes its nominal cooperative guidance command, while a local quadratic\nprogram (QP) modifies the input only when necessary. Event-triggered activation\nbased on range and zero-effort miss (ZEM) criteria ensures scalability by\nrestricting active constraints to relevant neighbors. To resolve feasibility\nissues from simultaneous constraints, a slack-variable relaxation scheme is\nintroduced that prioritizes critical agents in a Pareto-optimal manner.\nSimulation results in many-on-many interception scenarios demonstrate that the\nproposed framework maintains collision-free operation with minimal deviation\nfrom nominal guidance, providing a computationally efficient and scalable\nsolution for safety-critical multi-agent aerospace systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u822a\u5929\u62e6\u622a\u573a\u666f\u7684\u5206\u6563\u5f0f\u5b89\u5168\u6ee4\u6ce2\u5668\uff0c\u901a\u8fc7\u9c81\u68d2\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u4fdd\u8bc1\u5b89\u5168\u96c6\u7684\u6b63\u5411\u4e0d\u53d8\u6027\uff0c\u4f7f\u7528\u4e8b\u4ef6\u89e6\u53d1\u673a\u5236\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u901a\u8fc7\u677e\u5f1b\u53d8\u91cf\u65b9\u6848\u89e3\u51b3\u53ef\u884c\u6027\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u822a\u5929\u62e6\u622a\u573a\u666f\u4e2d\u7684\u78b0\u649e\u907f\u514d\u95ee\u9898\uff0c\u9700\u8981\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\u7ef4\u6301\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u91c7\u7528\u9c81\u68d2\u63a7\u5236\u5c4f\u969c\u51fd\u6570(RCBFs)\u548c\u5c40\u90e8\u4e8c\u6b21\u89c4\u5212(QP)\uff0c\u7ed3\u5408\u57fa\u4e8e\u8ddd\u79bb\u548c\u96f6\u52aa\u529b\u8131\u9776\u91cf(ZEM)\u7684\u4e8b\u4ef6\u89e6\u53d1\u673a\u5236\uff0c\u4ee5\u53ca\u677e\u5f1b\u53d8\u91cf\u65b9\u6848\u6765\u5904\u7406\u540c\u65f6\u7ea6\u675f\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u591a\u5bf9\u591a\u62e6\u622a\u573a\u666f\u4e2d\u80fd\u591f\u4fdd\u6301\u65e0\u78b0\u649e\u64cd\u4f5c\uff0c\u4e14\u5bf9\u540d\u4e49\u5236\u5bfc\u7684\u504f\u79bb\u6700\u5c0f\uff0c\u63d0\u4f9b\u4e86\u8ba1\u7b97\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5206\u6563\u5f0f\u5b89\u5168\u6ee4\u6ce2\u5668\u4e3a\u5b89\u5168\u5173\u952e\u7684\u591a\u667a\u80fd\u4f53\u822a\u5929\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u78b0\u649e\u907f\u514d\u65b9\u6cd5\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2510.06280", "categories": ["cs.CY", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.06280", "abs": "https://arxiv.org/abs/2510.06280", "authors": ["Zohaib Hasan Siddiqui", "Dayam Nadeem", "Mohammad Masudur Rahman", "Mohammad Nadeem", "Shahab Saquib Sohail", "Beenish Moalla Chaudhry"], "title": "Surgeons Are Indian Males and Speech Therapists Are White Females: Auditing Biases in Vision-Language Models for Healthcare Professionals", "comment": null, "summary": "Vision language models (VLMs), such as CLIP and OpenCLIP, can encode and\nreflect stereotypical associations between medical professions and demographic\nattributes learned from web-scale data. We present an evaluation protocol for\nhealthcare settings that quantifies associated biases and assesses their\noperational risk. Our methodology (i) defines a taxonomy spanning clinicians\nand allied healthcare roles (e.g., surgeon, cardiologist, dentist, nurse,\npharmacist, technician), (ii) curates a profession-aware prompt suite to probe\nmodel behavior, and (iii) benchmarks demographic skew against a balanced face\ncorpus. Empirically, we observe consistent demographic biases across multiple\nroles and vision models. Our work highlights the importance of bias\nidentification in critical domains such as healthcare as AI-enabled hiring and\nworkforce analytics can have downstream implications for equity, compliance,\nand patient trust.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u804c\u4e1a\u4e2d\u5b58\u5728\u7684\u523b\u677f\u5370\u8c61\u548c\u4eba\u53e3\u7edf\u8ba1\u504f\u89c1\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u804c\u4e1a\u5206\u7c7b\u3001\u63d0\u793a\u5957\u4ef6\u548c\u57fa\u51c6\u6d4b\u8bd5\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u53d1\u73b0\u591a\u4e2a\u6a21\u578b\u5b58\u5728\u4e00\u81f4\u7684\u504f\u89c1\u95ee\u9898\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4ece\u7f51\u7edc\u89c4\u6a21\u6570\u636e\u4e2d\u5b66\u4e60\u5230\u7684\u533b\u7597\u804c\u4e1a\u4e0e\u4eba\u53e3\u5c5e\u6027\u4e4b\u95f4\u7684\u523b\u677f\u5173\u8054\u53ef\u80fd\u5728\u533b\u7597\u4fdd\u5065\u7b49\u5173\u952e\u9886\u57df\u5e26\u6765\u64cd\u4f5c\u98ce\u9669\uff0c\u5f71\u54cd\u516c\u5e73\u6027\u3001\u5408\u89c4\u6027\u548c\u60a3\u8005\u4fe1\u4efb\u3002", "method": "\u5b9a\u4e49\u4e86\u533b\u7597\u804c\u4e1a\u5206\u7c7b\u6cd5\uff0c\u7b56\u5212\u4e86\u804c\u4e1a\u611f\u77e5\u63d0\u793a\u5957\u4ef6\u6765\u63a2\u6d4b\u6a21\u578b\u884c\u4e3a\uff0c\u5e76\u4f7f\u7528\u5e73\u8861\u7684\u4eba\u8138\u8bed\u6599\u5e93\u5bf9\u4eba\u53e3\u7edf\u8ba1\u504f\u5dee\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\u591a\u4e2a\u89c6\u89c9\u6a21\u578b\u5728\u4e0d\u540c\u533b\u7597\u89d2\u8272\u4e2d\u90fd\u5b58\u5728\u4e00\u81f4\u7684\u4eba\u53e3\u7edf\u8ba1\u504f\u89c1\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u533b\u7597\u7b49\u5173\u952e\u9886\u57df\u8bc6\u522bAI\u504f\u89c1\u7684\u91cd\u8981\u6027\uff0c\u56e0\u4e3aAI\u8f85\u52a9\u62db\u8058\u548c\u52b3\u52a8\u529b\u5206\u6790\u53ef\u80fd\u5bf9\u516c\u5e73\u6027\u3001\u5408\u89c4\u6027\u548c\u60a3\u8005\u4fe1\u4efb\u4ea7\u751f\u4e0b\u6e38\u5f71\u54cd\u3002"}}
{"id": "2510.07025", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.07025", "abs": "https://arxiv.org/abs/2510.07025", "authors": ["D\u00e1vid Csercsik", "Mih\u00e1ly Andr\u00e1s V\u00e1ghy"], "title": "Optimal bidding in multiperiod day-ahead electricity markets assuming non-uniform uncertainty of clearing prices", "comment": null, "summary": "In a recent publication, using a simple two-period model, which is already\ncapable to capture essential non-convex multiperiod bids, Richstein et al. have\nshown that in the case of optimal bidding, multi-part bidding always ensures a\nhigher expected profit for the bidder, compared to simple bidding and\nblock-bidding. The model proposed in their analysis assumes a uniform\ndistribution of the market-clearing prices in both periods. In this paper, we\nstudy how the conclusions of the analysis are affected, if a very simple,\nsymmetric, stepwise-constant but non-uniform distribution is assumed in the\ncase of the market-clearing price. We show that the results of Richstein et al.\nalso hold in this case.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5e02\u573a\u51fa\u6e05\u4ef7\u683c\u91c7\u7528\u7b80\u5355\u5bf9\u79f0\u4f46\u975e\u5747\u5300\u5206\u5e03\u7684\u60c5\u51b5\u4e0b\uff0c\u591a\u90e8\u5206\u6295\u6807\u662f\u5426\u4ecd\u6bd4\u7b80\u5355\u6295\u6807\u548c\u5757\u6295\u6807\u5e26\u6765\u66f4\u9ad8\u9884\u671f\u5229\u6da6\u3002", "motivation": "Richstein\u7b49\u4eba\u7684\u7814\u7a76\u5047\u8bbe\u5e02\u573a\u51fa\u6e05\u4ef7\u683c\u670d\u4ece\u5747\u5300\u5206\u5e03\uff0c\u672c\u6587\u65e8\u5728\u9a8c\u8bc1\u5f53\u4ef7\u683c\u5206\u5e03\u4e3a\u975e\u5747\u5300\u65f6\uff0c\u5176\u7ed3\u8bba\u662f\u5426\u4ecd\u7136\u6210\u7acb\u3002", "method": "\u91c7\u7528\u7b80\u5355\u5bf9\u79f0\u4f46\u975e\u5747\u5300\u7684\u9636\u68af\u5e38\u6570\u5206\u5e03\u6765\u6a21\u62df\u5e02\u573a\u51fa\u6e05\u4ef7\u683c\uff0c\u91cd\u65b0\u5206\u6790\u591a\u90e8\u5206\u6295\u6807\u3001\u7b80\u5355\u6295\u6807\u548c\u5757\u6295\u6807\u7684\u9884\u671f\u5229\u6da6\u3002", "result": "\u7814\u7a76\u8bc1\u5b9e\uff0c\u5373\u4f7f\u5728\u975e\u5747\u5300\u4ef7\u683c\u5206\u5e03\u4e0b\uff0c\u591a\u90e8\u5206\u6295\u6807\u4ecd\u80fd\u786e\u4fdd\u6295\u6807\u4eba\u83b7\u5f97\u6bd4\u7b80\u5355\u6295\u6807\u548c\u5757\u6295\u6807\u66f4\u9ad8\u7684\u9884\u671f\u5229\u6da6\u3002", "conclusion": "Richstein\u7b49\u4eba\u7684\u7ed3\u8bba\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5373\u4f7f\u5728\u975e\u5747\u5300\u4ef7\u683c\u5206\u5e03\u5047\u8bbe\u4e0b\uff0c\u591a\u90e8\u5206\u6295\u6807\u7684\u4f18\u52bf\u4f9d\u7136\u5b58\u5728\u3002"}}
{"id": "2510.06492", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.06492", "abs": "https://arxiv.org/abs/2510.06492", "authors": ["Matthew Kim", "Kensuke Nakamura", "Andrea Bajcsy"], "title": "What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?", "comment": "8 tables 6 figures", "summary": "Safe control techniques, such as Hamilton-Jacobi reachability, provide\nprincipled methods for synthesizing safety-preserving robot policies but\ntypically assume hand-designed state spaces and full observability. Recent work\nhas relaxed these assumptions via latent-space safe control, where state\nrepresentations and dynamics are learned jointly through world models that\nreconstruct future high-dimensional observations (e.g., RGB images) from\ncurrent observations and actions. This enables safety constraints that are\ndifficult to specify analytically (e.g., spilling) to be framed as\nclassification problems in latent space, allowing controllers to operate\ndirectly from raw observations. However, these methods assume that\nsafety-critical features are observable in the learned latent state. We ask:\nwhen are latent state spaces sufficient for safe control? To study this, we\nexamine temperature-based failures, comparable to overheating in cooking or\nmanufacturing tasks, and find that RGB-only observations can produce myopic\nsafety behaviors, e.g., avoiding seeing failure states rather than preventing\nfailure itself. To predict such behaviors, we introduce a mutual\ninformation-based measure that identifies when observations fail to capture\nsafety-relevant features. Finally, we propose a multimodal-supervised training\nstrategy that shapes the latent state with additional sensory inputs during\ntraining, but requires no extra modalities at deployment, and validate our\napproach in simulation and on hardware with a Franka Research 3 manipulator\npreventing a pot of wax from overheating.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8eRGB\u89c2\u6d4b\u7684\u6f5c\u5728\u7a7a\u95f4\u5b89\u5168\u63a7\u5236\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e92\u4fe1\u606f\u5ea6\u91cf\u6765\u8bc6\u522b\u89c2\u6d4b\u65e0\u6cd5\u6355\u6349\u5b89\u5168\u76f8\u5173\u7279\u5f81\u7684\u60c5\u51b5\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u6a21\u6001\u76d1\u7763\u8bad\u7ec3\u7b56\u7565\u6765\u6539\u8fdb\u6f5c\u5728\u72b6\u6001\u8868\u793a\u3002", "motivation": "\u73b0\u6709\u6f5c\u5728\u7a7a\u95f4\u5b89\u5168\u63a7\u5236\u65b9\u6cd5\u5047\u8bbe\u5b89\u5168\u5173\u952e\u7279\u5f81\u5728\u5b66\u4e60\u7684\u6f5c\u5728\u72b6\u6001\u4e2d\u53ef\u89c2\u6d4b\uff0c\u4f46\u5b9e\u9645\u4e2dRGB\u89c2\u6d4b\u53ef\u80fd\u4ea7\u751f\u77ed\u89c6\u7684\u5b89\u5168\u884c\u4e3a\uff0c\u65e0\u6cd5\u771f\u6b63\u9884\u9632\u6545\u969c\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u5ea6\u91cf\u6765\u9884\u6d4b\u89c2\u6d4b\u65e0\u6cd5\u6355\u6349\u5b89\u5168\u76f8\u5173\u7279\u5f81\u7684\u60c5\u51b5\uff1b\u63d0\u51fa\u591a\u6a21\u6001\u76d1\u7763\u8bad\u7ec3\u7b56\u7565\uff0c\u5728\u8bad\u7ec3\u65f6\u4f7f\u7528\u989d\u5916\u611f\u5b98\u8f93\u5165\u5851\u9020\u6f5c\u5728\u72b6\u6001\uff0c\u4f46\u90e8\u7f72\u65f6\u65e0\u9700\u989d\u5916\u6a21\u6001\u3002", "result": "\u5728\u4eff\u771f\u548cFranka Research 3\u673a\u68b0\u81c2\u786c\u4ef6\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\uff0c\u6210\u529f\u9632\u6b62\u8721\u9505\u8fc7\u70ed\u3002", "conclusion": "RGB\u89c2\u6d4b\u53ef\u80fd\u4e0d\u8db3\u4ee5\u6355\u6349\u5b89\u5168\u76f8\u5173\u7279\u5f81\uff0c\u591a\u6a21\u6001\u76d1\u7763\u8bad\u7ec3\u53ef\u4ee5\u6539\u5584\u6f5c\u5728\u72b6\u6001\u8868\u793a\uff0c\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u5b89\u5168\u63a7\u5236\u3002"}}
{"id": "2510.07116", "categories": ["cs.ET", "cs.AR", "cs.HC", "cs.SE", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.07116", "abs": "https://arxiv.org/abs/2510.07116", "authors": ["Ruben Ruiz-Mateos Serrano", "Joe G Troughton", "Nima Mirkhani", "Natalia Martinez", "Massimo Mariello", "Jordan Tsigarides", "Simon Williamson", "Juan Sapriza", "Ioana Susnoschi Luca", "Antonio Dominguez-Alfaro", "Estelle Cuttaz", "Nicole Thompson", "Sydney Swedick", "Latifah Almulla", "Amparo Guemes"], "title": "From Neural Sensing to Stimulation: An Interdisciplinary Roadmap for Neurotechnology", "comment": null, "summary": "Neurotechnologies are transforming how we measure, interpret, and modulate\nbrain-body interactions, integrating real-time sensing, computation, and\nstimulation to enable precise physiological control. They hold transformative\npotential across clinical and non-clinical domains, from treating disorders to\nenhancing cognition and performance. Realizing this potential requires\nnavigating complex, interdisciplinary challenges spanning neuroscience,\nmaterials science, device engineering, signal processing, computational\nmodelling, and regulatory and ethical frameworks. This Perspective presents a\nstrategic roadmap for neurotechnology development, created by early-career\nresearchers, highlighting their role at the intersection of disciplines and\ntheir capacity to bridge traditional silos. We identify five cross-cutting\ntrade-offs that constrain progress across functionality, scalability,\nadaptability, and translatability, and illustrate how technical domains\ninfluence their resolution. Rather than a domain-specific review, we focus on\nshared challenges and strategic opportunities that transcend disciplines. We\npropose a unified framework for collaborative innovation and education,\nhighlight ethical and regulatory priorities, and outline a timeline for\novercoming key bottlenecks. By aligning technical development with\ntranslational and societal needs, this roadmap aims to accelerate equitable,\neffective, and future-ready adaptive neurotechnologies, guiding coordinated\nefforts across the global research and innovation community.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u795e\u7ecf\u6280\u672f\u53d1\u5c55\u7684\u6218\u7565\u8def\u7ebf\u56fe\uff0c\u91cd\u70b9\u5173\u6ce8\u8de8\u5b66\u79d1\u5408\u4f5c\u3001\u6280\u672f\u6743\u8861\u548c\u4f26\u7406\u76d1\u7ba1\uff0c\u65e8\u5728\u52a0\u901f\u516c\u5e73\u6709\u6548\u7684\u81ea\u9002\u5e94\u795e\u7ecf\u6280\u672f\u53d1\u5c55\u3002", "motivation": "\u795e\u7ecf\u6280\u672f\u5728\u4e34\u5e8a\u548c\u975e\u4e34\u5e8a\u9886\u57df\u5177\u6709\u53d8\u9769\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u8de8\u5b66\u79d1\u590d\u6742\u6311\u6218\uff0c\u9700\u8981\u534f\u8c03\u5404\u9886\u57df\u53d1\u5c55\u4ee5\u5b9e\u73b0\u5176\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u65e9\u671f\u804c\u4e1a\u7814\u7a76\u4eba\u5458\u521b\u5efa\u6218\u7565\u8def\u7ebf\u56fe\uff0c\u8bc6\u522b\u4e94\u4e2a\u8de8\u9886\u57df\u6743\u8861\uff0c\u63d0\u51fa\u7edf\u4e00\u534f\u4f5c\u6846\u67b6\u548c\u6559\u80b2\u4f53\u7cfb\uff0c\u5236\u5b9a\u65f6\u95f4\u8868\u89e3\u51b3\u5173\u952e\u74f6\u9888\u3002", "result": "\u5efa\u7acb\u4e86\u795e\u7ecf\u6280\u672f\u53d1\u5c55\u7684\u7efc\u5408\u6846\u67b6\uff0c\u5f3a\u8c03\u6280\u672f\u5f00\u53d1\u4e0e\u8f6c\u5316\u9700\u6c42\u7684\u5bf9\u9f50\uff0c\u4fc3\u8fdb\u5168\u7403\u7814\u7a76\u521b\u65b0\u793e\u533a\u7684\u534f\u8c03\u52aa\u529b\u3002", "conclusion": "\u901a\u8fc7\u8de8\u5b66\u79d1\u5408\u4f5c\u548c\u6218\u7565\u8def\u7ebf\u56fe\uff0c\u53ef\u4ee5\u52a0\u901f\u5f00\u53d1\u516c\u5e73\u3001\u6709\u6548\u4e14\u9762\u5411\u672a\u6765\u7684\u81ea\u9002\u5e94\u795e\u7ecf\u6280\u672f\uff0c\u5b9e\u73b0\u795e\u7ecf\u6280\u672f\u7684\u53d8\u9769\u6f5c\u529b\u3002"}}
{"id": "2510.06307", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06307", "abs": "https://arxiv.org/abs/2510.06307", "authors": ["Wentao Deng", "Jiahuan Pei", "Zhiwei Xu", "Zhaochun Ren", "Zhumin Chen", "Pengjie Ren"], "title": "Belief-Calibrated Multi-Agent Consensus Seeking for Complex NLP Tasks", "comment": "This paper has been accepted by NeurIPS 2025", "summary": "A multi-agent system (MAS) enhances its capacity to solve complex natural\nlanguage processing (NLP) tasks through collaboration among multiple agents,\nwhere consensus-seeking serves as a fundamental mechanism. However, existing\nconsensus-seeking approaches typically rely on voting mechanisms to judge\nconsensus, overlooking contradictions in system-internal beliefs that\ndestabilize the consensus. Moreover, these methods often involve agents\nupdating their results through indiscriminate collaboration with every other\nagent. Such uniform interaction fails to identify the optimal collaborators for\neach agent, hindering the emergence of a stable consensus. To address these\nchallenges, we provide a theoretical framework for selecting optimal\ncollaborators that maximize consensus stability. Based on the theorems, we\npropose the Belief-Calibrated Consensus Seeking (BCCS) framework to facilitate\nstable consensus via selecting optimal collaborators and calibrating the\nconsensus judgment by system-internal beliefs. Experimental results on the MATH\nand MMLU benchmark datasets demonstrate that the proposed BCCS framework\noutperforms the best existing results by 2.23% and 3.95% of accuracy on\nchallenging tasks, respectively. Our code and data are available at\nhttps://github.com/dengwentao99/BCCS.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4fe1\u5ff5\u6821\u51c6\u5171\u8bc6\u5bfb\u6c42\uff08BCCS\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u6700\u4f18\u5408\u4f5c\u8005\u548c\u6821\u51c6\u7cfb\u7edf\u5185\u90e8\u4fe1\u5ff5\u6765\u4fc3\u8fdb\u7a33\u5b9a\u5171\u8bc6\uff0c\u5728MATH\u548cMMLU\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u5171\u8bc6\u5bfb\u6c42\u65b9\u6cd5\u4f9d\u8d56\u6295\u7968\u673a\u5236\uff0c\u5ffd\u7565\u4e86\u7cfb\u7edf\u5185\u90e8\u4fe1\u5ff5\u7684\u77db\u76fe\uff0c\u4e14\u901a\u8fc7\u65e0\u5dee\u522b\u534f\u4f5c\u66f4\u65b0\u7ed3\u679c\uff0c\u65e0\u6cd5\u4e3a\u6bcf\u4e2a\u667a\u80fd\u4f53\u8bc6\u522b\u6700\u4f18\u5408\u4f5c\u8005\uff0c\u963b\u788d\u7a33\u5b9a\u5171\u8bc6\u7684\u5f62\u6210\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u6765\u9009\u62e9\u6700\u5927\u5316\u5171\u8bc6\u7a33\u5b9a\u6027\u7684\u6700\u4f18\u5408\u4f5c\u8005\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86BCCS\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u6700\u4f18\u5408\u4f5c\u8005\u548c\u6821\u51c6\u7cfb\u7edf\u5185\u90e8\u4fe1\u5ff5\u6765\u4fc3\u8fdb\u7a33\u5b9a\u5171\u8bc6\u3002", "result": "\u5728MATH\u548cMMLU\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cBCCS\u6846\u67b6\u5728\u6311\u6218\u6027\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u7387\u5206\u522b\u6bd4\u73b0\u6709\u6700\u4f73\u7ed3\u679c\u63d0\u9ad8\u4e862.23%\u548c3.95%\u3002", "conclusion": "BCCS\u6846\u67b6\u901a\u8fc7\u9009\u62e9\u6700\u4f18\u5408\u4f5c\u8005\u548c\u6821\u51c6\u7cfb\u7edf\u5185\u90e8\u4fe1\u5ff5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5171\u8bc6\u5bfb\u6c42\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742NLP\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2510.06970", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.06970", "abs": "https://arxiv.org/abs/2510.06970", "authors": ["Marlon M\u00fcller", "Florian Finkeldei", "Hanna Krasowski", "Murat Arcak", "Matthias Althoff"], "title": "Falsification-Driven Reinforcement Learning for Maritime Motion Planning", "comment": null, "summary": "Compliance with maritime traffic rules is essential for the safe operation of\nautonomous vessels, yet training reinforcement learning (RL) agents to adhere\nto them is challenging. The behavior of RL agents is shaped by the training\nscenarios they encounter, but creating scenarios that capture the complexity of\nmaritime navigation is non-trivial, and real-world data alone is insufficient.\nTo address this, we propose a falsification-driven RL approach that generates\nadversarial training scenarios in which the vessel under test violates maritime\ntraffic rules, which are expressed as signal temporal logic specifications. Our\nexperiments on open-sea navigation with two vessels demonstrate that the\nproposed approach provides more relevant training scenarios and achieves more\nconsistent rule compliance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cd\u4f8b\u9a71\u52a8\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u8fdd\u53cd\u6d77\u4e8b\u4ea4\u901a\u89c4\u5219\u7684\u5bf9\u6297\u6027\u8bad\u7ec3\u573a\u666f\u6765\u63d0\u9ad8\u81ea\u4e3b\u8239\u8236\u7684\u89c4\u5219\u9075\u5b88\u80fd\u529b\u3002", "motivation": "\u8bad\u7ec3\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u9075\u5b88\u6d77\u4e8b\u4ea4\u901a\u89c4\u5219\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u4ee3\u7406\u884c\u4e3a\u53d7\u8bad\u7ec3\u573a\u666f\u5f71\u54cd\uff0c\u800c\u521b\u5efa\u80fd\u6355\u6349\u6d77\u4e8b\u5bfc\u822a\u590d\u6742\u6027\u7684\u573a\u666f\u5f88\u56f0\u96be\uff0c\u4ec5\u9760\u771f\u5b9e\u6570\u636e\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u53cd\u4f8b\u9a71\u52a8\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u751f\u6210\u8fdd\u53cd\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\u89c4\u8303\u7684\u6d77\u4e8b\u4ea4\u901a\u89c4\u5219\u7684\u5bf9\u6297\u6027\u8bad\u7ec3\u573a\u666f\u3002", "result": "\u5728\u53cc\u8239\u5f00\u653e\u6d77\u57df\u5bfc\u822a\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u76f8\u5173\u7684\u8bad\u7ec3\u573a\u666f\uff0c\u5e76\u5b9e\u73b0\u4e86\u66f4\u4e00\u81f4\u7684\u89c4\u5219\u9075\u5b88\u3002", "conclusion": "\u53cd\u4f8b\u9a71\u52a8\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u80fd\u6709\u6548\u751f\u6210\u5bf9\u6297\u6027\u8bad\u7ec3\u573a\u666f\uff0c\u63d0\u9ad8\u81ea\u4e3b\u8239\u8236\u5bf9\u6d77\u4e8b\u4ea4\u901a\u89c4\u5219\u7684\u9075\u5b88\u80fd\u529b\u3002"}}
{"id": "2510.06350", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06350", "abs": "https://arxiv.org/abs/2510.06350", "authors": ["Mattia Samory", "Diana Pamfile", "Andrew To", "Shruti Phadke"], "title": "Asking For It: Question-Answering for Predicting Rule Infractions in Online Content Moderation", "comment": "Accepted at ICWSM 2026", "summary": "Online communities rely on a mix of platform policies and community-authored\nrules to define acceptable behavior and maintain order. However, these rules\nvary widely across communities, evolve over time, and are enforced\ninconsistently, posing challenges for transparency, governance, and automation.\nIn this paper, we model the relationship between rules and their enforcement at\nscale, introducing ModQ, a novel question-answering framework for\nrule-sensitive content moderation. Unlike prior classification or\ngeneration-based approaches, ModQ conditions on the full set of community rules\nat inference time and identifies which rule best applies to a given comment. We\nimplement two model variants - extractive and multiple-choice QA - and train\nthem on large-scale datasets from Reddit and Lemmy, the latter of which we\nconstruct from publicly available moderation logs and rule descriptions. Both\nmodels outperform state-of-the-art baselines in identifying moderation-relevant\nrule violations, while remaining lightweight and interpretable. Notably, ModQ\nmodels generalize effectively to unseen communities and rules, supporting\nlow-resource moderation settings and dynamic governance environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86ModQ\u6846\u67b6\uff0c\u4e00\u79cd\u57fa\u4e8e\u95ee\u7b54\u7684\u5185\u5bb9\u5ba1\u6838\u65b9\u6cd5\uff0c\u80fd\u591f\u6839\u636e\u793e\u533a\u89c4\u5219\u8bc6\u522b\u8bc4\u8bba\u8fdd\u89c4\u60c5\u51b5\uff0c\u5e76\u5728\u672a\u89c1\u8fc7\u7684\u793e\u533a\u548c\u89c4\u5219\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5728\u7ebf\u793e\u533a\u7684\u89c4\u5219\u5dee\u5f02\u5927\u3001\u53d8\u5316\u5feb\u4e14\u6267\u884c\u4e0d\u4e00\u81f4\uff0c\u7ed9\u900f\u660e\u5ea6\u3001\u6cbb\u7406\u548c\u81ea\u52a8\u5316\u5e26\u6765\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7406\u89e3\u89c4\u5219\u4e0e\u6267\u884c\u5173\u7cfb\u7684\u6a21\u578b\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e24\u79cd\u6a21\u578b\u53d8\u4f53\uff1a\u62bd\u53d6\u5f0f\u95ee\u7b54\u548c\u591a\u9009\u95ee\u7b54\uff0c\u57fa\u4e8eReddit\u548cLemmy\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8bad\u7ec3\uff0c\u5728\u63a8\u7406\u65f6\u8003\u8651\u5b8c\u6574\u7684\u793e\u533a\u89c4\u5219\u96c6\u3002", "result": "\u4e24\u79cd\u6a21\u578b\u5728\u8bc6\u522b\u4e0e\u5ba1\u6838\u76f8\u5173\u7684\u89c4\u5219\u8fdd\u89c4\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u8f7b\u91cf\u7ea7\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "ModQ\u6846\u67b6\u80fd\u591f\u6709\u6548\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u793e\u533a\u548c\u89c4\u5219\uff0c\u652f\u6301\u4f4e\u8d44\u6e90\u5ba1\u6838\u8bbe\u7f6e\u548c\u52a8\u6001\u6cbb\u7406\u73af\u5883\uff0c\u4e3a\u89c4\u5219\u654f\u611f\u7684\u5185\u5bb9\u5ba1\u6838\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2510.07039", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.07039", "abs": "https://arxiv.org/abs/2510.07039", "authors": ["Shaunak Kulkarni", "Rohan Ajay Dubey"], "title": "Exchange for Growth: Currency Dynamics in Emerging Markets", "comment": null, "summary": "Currency crises are frequently discussed retrospectively as a necessary and\ndeterministic outcome of a finite sequence of fiscal decisions, monetary\nmanoeuvres, and limited exogenous inputs. Parallelly, the Twin Deficits\nHypothesis (TDH) posits that an increase in the budget deficit leads to a\ndirect rise in the current account deficit; although analogous to the idea of\ncurrency crises being the outcome of finite inputs (through a balance of\npayments crisis here), this notion runs contrary to the conclusion that\nindependent intervention can have bearing on the expression of a currency\ncrisis.\n  Since its introduction by Mundell and Fleming in 1960, the TDH has sparked\nconsiderable academic debate regarding its validity. Given its assumption of a\nstable private savings gap, and conflicting empirical evidence, we believe\nthere are novel insights to be gained from a more nuanced approach\nincorporating theoretical frameworks from contemporary Monetary Economics in\norder to reconcile criticisms of the TDH with the basis for its broad\napplicability.\n  The results from this paper thus investigate the link - or lack thereof -\nbetween real economic factors, which can support the assessment of fiscal\npolicy autonomy, and thereby a government's ability, to meet domestic policy\nobjectives without compromising trade policy autonomy and current account\nsustainability.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u53cc\u8d64\u5b57\u5047\u8bf4\uff0c\u63a2\u8ba8\u8d22\u653f\u8d64\u5b57\u4e0e\u7ecf\u5e38\u8d26\u6237\u8d64\u5b57\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5206\u6790\u653f\u5e9c\u5728\u4fdd\u6301\u8d38\u6613\u653f\u7b56\u81ea\u4e3b\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u56fd\u5185\u653f\u7b56\u76ee\u6807\u7684\u80fd\u529b\u3002", "motivation": "\u53cc\u8d64\u5b57\u5047\u8bf4\u81ea\u63d0\u51fa\u4ee5\u6765\u4e00\u76f4\u5b58\u5728\u5b66\u672f\u4e89\u8bae\uff0c\u5176\u5047\u8bbe\u79c1\u4eba\u50a8\u84c4\u7f3a\u53e3\u7a33\u5b9a\u4e14\u7ecf\u9a8c\u8bc1\u636e\u76f8\u4e92\u77db\u76fe\u3002\u4f5c\u8005\u8ba4\u4e3a\u9700\u8981\u7ed3\u5408\u5f53\u4ee3\u8d27\u5e01\u7ecf\u6d4e\u5b66\u7406\u8bba\u6846\u67b6\uff0c\u4ee5\u66f4\u7ec6\u81f4\u7684\u65b9\u6cd5\u6765\u8c03\u548cTDH\u7684\u6279\u8bc4\u4e0e\u5176\u5e7f\u6cdb\u5e94\u7528\u57fa\u7840\u4e4b\u95f4\u7684\u77db\u76fe\u3002", "method": "\u91c7\u7528\u7ed3\u5408\u5f53\u4ee3\u8d27\u5e01\u7ecf\u6d4e\u5b66\u7406\u8bba\u6846\u67b6\u7684\u7ec6\u81f4\u5206\u6790\u65b9\u6cd5\uff0c\u7814\u7a76\u5b9e\u9645\u7ecf\u6d4e\u56e0\u7d20\u4e0e\u8d22\u653f\u653f\u7b56\u81ea\u4e3b\u6027\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63a2\u8ba8\u4e86\u5b9e\u9645\u7ecf\u6d4e\u56e0\u7d20\u4e0e\u8d22\u653f\u653f\u7b56\u81ea\u4e3b\u6027\u4e4b\u95f4\u7684\u8054\u7cfb\uff08\u6216\u7f3a\u4e4f\u8054\u7cfb\uff09\uff0c\u8fd9\u6709\u52a9\u4e8e\u8bc4\u4f30\u653f\u5e9c\u5728\u4fdd\u6301\u8d38\u6613\u653f\u7b56\u81ea\u4e3b\u6027\u548c\u7ecf\u5e38\u8d26\u6237\u53ef\u6301\u7eed\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u56fd\u5185\u653f\u7b56\u76ee\u6807\u7684\u80fd\u529b\u3002", "conclusion": "\u9700\u8981\u66f4\u7ec6\u81f4\u7684\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3\u53cc\u8d64\u5b57\u5047\u8bf4\uff0c\u4ee5\u534f\u8c03\u5176\u6279\u8bc4\u4e0e\u5e7f\u6cdb\u5e94\u7528\u57fa\u7840\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u4ece\u800c\u66f4\u597d\u5730\u8bc4\u4f30\u653f\u5e9c\u5728\u5b9e\u73b0\u653f\u7b56\u76ee\u6807\u65f6\u7684\u81ea\u4e3b\u80fd\u529b\u3002"}}
{"id": "2510.06518", "categories": ["cs.RO", "cs.CV", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.06518", "abs": "https://arxiv.org/abs/2510.06518", "authors": ["Malakhi Hopkins", "Varun Murali", "Vijay Kumar", "Camillo J Taylor"], "title": "Real-Time Glass Detection and Reprojection using Sensor Fusion Onboard Aerial Robots", "comment": "8 pages, 8 figures, submitted to ICRA 2026", "summary": "Autonomous aerial robots are increasingly being deployed in real-world\nscenarios, where transparent obstacles present significant challenges to\nreliable navigation and mapping. These materials pose a unique problem for\ntraditional perception systems because they lack discernible features and can\ncause conventional depth sensors to fail, leading to inaccurate maps and\npotential collisions. To ensure safe navigation, robots must be able to\naccurately detect and map these transparent obstacles. Existing methods often\nrely on large, expensive sensors or algorithms that impose high computational\nburdens, making them unsuitable for low Size, Weight, and Power (SWaP) robots.\nIn this work, we propose a novel and computationally efficient framework for\ndetecting and mapping transparent obstacles onboard a sub-300g quadrotor. Our\nmethod fuses data from a Time-of-Flight (ToF) camera and an ultrasonic sensor\nwith a custom, lightweight 2D convolution model. This specialized approach\naccurately detects specular reflections and propagates their depth into\ncorresponding empty regions of the depth map, effectively rendering transparent\nobstacles visible. The entire pipeline operates in real-time, utilizing only a\nsmall fraction of a CPU core on an embedded processor. We validate our system\nthrough a series of experiments in both controlled and real-world environments,\ndemonstrating the utility of our method through experiments where the robot\nmaps indoor environments containing glass. Our work is, to our knowledge, the\nfirst of its kind to demonstrate a real-time, onboard transparent obstacle\nmapping system on a low-SWaP quadrotor using only the CPU.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5c0f\u578b\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u7684\u5b9e\u65f6\u900f\u660e\u969c\u788d\u7269\u68c0\u6d4b\u4e0e\u5efa\u56fe\u7cfb\u7edf\uff0c\u878d\u5408ToF\u76f8\u673a\u548c\u8d85\u58f0\u6ce2\u4f20\u611f\u5668\u6570\u636e\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea72D\u5377\u79ef\u6a21\u578b\u68c0\u6d4b\u955c\u9762\u53cd\u5c04\u5e76\u586b\u8865\u6df1\u5ea6\u56fe\u7a7a\u767d\u533a\u57df\u3002", "motivation": "\u900f\u660e\u969c\u788d\u7269\u5bf9\u81ea\u4e3b\u98de\u884c\u673a\u5668\u4eba\u6784\u6210\u91cd\u5927\u6311\u6218\uff0c\u4f20\u7edf\u611f\u77e5\u7cfb\u7edf\u96be\u4ee5\u68c0\u6d4b\u8fd9\u4e9b\u7f3a\u4e4f\u53ef\u8bc6\u522b\u7279\u5f81\u7684\u6750\u6599\uff0c\u5bfc\u81f4\u5efa\u56fe\u4e0d\u51c6\u786e\u548c\u6f5c\u5728\u78b0\u649e\u98ce\u9669\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5927\u578b\u6602\u8d35\u4f20\u611f\u5668\u6216\u9ad8\u8ba1\u7b97\u91cf\u7b97\u6cd5\uff0c\u4e0d\u9002\u5408\u4f4eSWaP\u673a\u5668\u4eba\u3002", "method": "\u878d\u5408ToF\u76f8\u673a\u548c\u8d85\u58f0\u6ce2\u4f20\u611f\u5668\u6570\u636e\uff0c\u4f7f\u7528\u5b9a\u5236\u8f7b\u91cf\u7ea72D\u5377\u79ef\u6a21\u578b\u68c0\u6d4b\u955c\u9762\u53cd\u5c04\uff0c\u5e76\u5c06\u6df1\u5ea6\u4fe1\u606f\u4f20\u64ad\u5230\u6df1\u5ea6\u56fe\u7684\u5bf9\u5e94\u7a7a\u767d\u533a\u57df\uff0c\u4f7f\u900f\u660e\u969c\u788d\u7269\u53ef\u89c1\u3002\u6574\u4e2a\u6d41\u6c34\u7ebf\u5728\u5d4c\u5165\u5f0f\u5904\u7406\u5668\u4e0a\u4ec5\u5360\u7528\u5c11\u91cfCPU\u6838\u5fc3\u8d44\u6e90\u5b9e\u65f6\u8fd0\u884c\u3002", "result": "\u5728\u53d7\u63a7\u548c\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u673a\u5668\u4eba\u5728\u5305\u542b\u73bb\u7483\u7684\u5ba4\u5185\u73af\u5883\u4e2d\u5efa\u56fe\u7684\u80fd\u529b\u3002\u7cfb\u7edf\u5728\u4f4eSWaP\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u4e0a\u5b9e\u73b0\u4e86\u5b9e\u65f6\u900f\u660e\u969c\u788d\u7269\u5efa\u56fe\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5728\u4f4eSWaP\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u4e0a\u4ec5\u4f7f\u7528CPU\u5b9e\u73b0\u5b9e\u65f6\u673a\u8f7d\u900f\u660e\u969c\u788d\u7269\u5efa\u56fe\u7684\u7cfb\u7edf\uff0c\u4e3a\u5c0f\u578b\u81ea\u4e3b\u98de\u884c\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u900f\u660e\u969c\u788d\u7269\u611f\u77e5\u80fd\u529b\u3002"}}
{"id": "2510.06410", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06410", "abs": "https://arxiv.org/abs/2510.06410", "authors": ["Aochong Oliver Li", "Tanya Goyal"], "title": "Off-Trajectory Reasoning: Can LLMs Collaborate on Reasoning Trajectory?", "comment": null, "summary": "Reasoning LLMs are trained to verbalize their reasoning process, yielding\nstrong gains on complex tasks. This transparency also opens a promising\ndirection: multiple reasoners can directly collaborate on each other's thinking\nwithin a shared trajectory, yielding better inference efficiency and\nexploration. A key prerequisite, however, is the ability to assess the\nusefulness and build on another model's partial thinking -- we call this\noff-trajectory reasoning. Our paper investigates a critical question: can\nstandard solo-reasoning training pipelines deliver desired off-trajectory\nbehaviors? We propose twin tests that capture the two extremes of the\noff-trajectory spectrum, namely Recoverability, which tests whether LLMs can\nbacktrack from \"distractions\" induced by misleading reasoning traces, and\nGuidability, which tests their ability to build upon correct reasoning from\nstronger collaborators. Our study evaluates 15 open-weight LLMs (1.5B-32B) and\nreveals a counterintuitive finding -- \"stronger\" LLMs on benchmarks are often\nmore fragile under distraction. Moreover, all models tested fail to effectively\nleverage guiding steps from collaborators on problems beyond their inherent\ncapabilities with solve rates remaining under 9.2%. Finally, we conduct control\nstudies to isolate the effects of three factors in post-training on these\nbehaviors: the choice of distillation teacher, the use of RL, and data\nselection strategy. Our results provide actionable insights for training\nnatively strong reasoning collaborators; e.g., we find that suboptimal\nrecoverability behaviors of teacher models are transferred to distilled\nstudents even if the distillation trajectories are correct. Taken together,\nthis work lays the groundwork for evaluating multi-model collaborations in\nshared reasoning trajectories and highlights the limitations of off-the-shelf\nreasoning LLMs.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5171\u4eab\u63a8\u7406\u8f68\u8ff9\u4e2d\u534f\u4f5c\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u6807\u51c6\u5355\u72ec\u63a8\u7406\u8bad\u7ec3\u65e0\u6cd5\u5b9e\u73b0\u6709\u6548\u7684\u79bb\u8f68\u8ff9\u63a8\u7406\u884c\u4e3a\uff0c\u66f4\u5f3a\u7684\u6a21\u578b\u5728\u5e72\u6270\u4e0b\u53cd\u800c\u66f4\u8106\u5f31\uff0c\u4e14\u6240\u6709\u6a21\u578b\u90fd\u96be\u4ee5\u5229\u7528\u534f\u4f5c\u8005\u7684\u6b63\u786e\u63a8\u7406\u6b65\u9aa4\u3002", "motivation": "\u7814\u7a76\u63a8\u7406LLMs\u662f\u5426\u80fd\u5728\u5171\u4eab\u63a8\u7406\u8f68\u8ff9\u4e2d\u76f4\u63a5\u534f\u4f5c\uff0c\u8bc4\u4f30\u5176\u5904\u7406\u5176\u4ed6\u6a21\u578b\u90e8\u5206\u63a8\u7406\u7ed3\u679c\u7684\u80fd\u529b\uff08\u79bb\u8f68\u8ff9\u63a8\u7406\uff09\uff0c\u8fd9\u5bf9\u4e8e\u591a\u6a21\u578b\u534f\u4f5c\u63a8\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u53cc\u6d4b\u8bd5\u6846\u67b6\uff1a\u53ef\u6062\u590d\u6027\u6d4b\u8bd5\u6a21\u578b\u4ece\u8bef\u5bfc\u6027\u63a8\u7406\u75d5\u8ff9\u4e2d\u56de\u6eaf\u7684\u80fd\u529b\uff0c\u53ef\u5f15\u5bfc\u6027\u6d4b\u8bd5\u6a21\u578b\u57fa\u4e8e\u66f4\u5f3a\u534f\u4f5c\u8005\u6b63\u786e\u63a8\u7406\u8fdb\u884c\u6784\u5efa\u7684\u80fd\u529b\u3002\u8bc4\u4f30\u4e8615\u4e2a\u5f00\u6e90LLMs\uff081.5B-32B\uff09\uff0c\u5e76\u8fdb\u884c\u63a7\u5236\u7814\u7a76\u5206\u6790\u540e\u8bad\u7ec3\u56e0\u7d20\u7684\u5f71\u54cd\u3002", "result": "\u53cd\u76f4\u89c9\u53d1\u73b0\uff1a\u57fa\u51c6\u6d4b\u8bd5\u66f4\u5f3a\u7684LLMs\u5728\u5e72\u6270\u4e0b\u5f80\u5f80\u66f4\u8106\u5f31\uff1b\u6240\u6709\u6a21\u578b\u5728\u8d85\u51fa\u81ea\u8eab\u80fd\u529b\u7684\u95ee\u9898\u4e0a\u5229\u7528\u5f15\u5bfc\u6b65\u9aa4\u7684\u89e3\u51b3\u7387\u4f4e\u4e8e9.2%\uff1b\u6559\u5e08\u6a21\u578b\u7684\u4e0d\u4f73\u53ef\u6062\u590d\u6027\u884c\u4e3a\u4f1a\u4f20\u9012\u7ed9\u84b8\u998f\u5b66\u751f\u3002", "conclusion": "\u6807\u51c6\u5355\u72ec\u63a8\u7406\u8bad\u7ec3\u65e0\u6cd5\u4ea7\u751f\u7406\u60f3\u7684\u79bb\u8f68\u8ff9\u63a8\u7406\u884c\u4e3a\uff0c\u9700\u8981\u4e13\u95e8\u8bad\u7ec3\u539f\u751f\u5f3a\u63a8\u7406\u534f\u4f5c\u8005\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u8bc4\u4f30\u591a\u6a21\u578b\u5728\u5171\u4eab\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u534f\u4f5c\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u63ed\u793a\u4e86\u73b0\u6210\u63a8\u7406LLMs\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.07102", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.07102", "abs": "https://arxiv.org/abs/2510.07102", "authors": ["Bart van der Holst", "Thomas Swarts", "Phuong Nguyen", "Johan Morren", "Koen Kok"], "title": "Mitigating Increase-Decrease Gaming with Alternative Connection Agreements: A Defender-Attacker-Defender Game", "comment": null, "summary": "Redispatch markets are widely used by system operators to manage network\ncongestion. A well-known drawback, however, is that Flexibility Service\nProviders (FSPs) may strategically adjust their baselines in anticipation of\nredispatch actions, thereby aggravating congestion and raising system costs. To\naddress this increase-decrease gaming, Distribution System Operators (DSOs)\ncould use Alternative Connection Agreements (ACAs) to conditionally limit the\navailable connection capacity of market participants in the day-ahead stage. In\nthis paper, we present a novel Defender-Attacker-Defender game to investigate\nthe potential of this approach in distribution networks under load and price\nuncertainty. We solve the resulting trilevel optimization model using a custom\nbranch-and-bound algorithm, and we demonstrate that it efficiently solves the\nproblem without exploring many nodes in the branch-and-bound search tree for\nmost simulated scenarios. The case study demonstrates that applying ACAs can\nsubstantially lower redispatch costs (e.g. by 25%) for the DSO with only a\nlimited impact on FSP profits. The effectiveness of the approach critically\ndepends on how often the DSO can invoke ACAs and on the extent to which the DSO\ncan anticipate strategic bidding behavior of the FSP.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u9632\u5fa1\u8005-\u653b\u51fb\u8005-\u9632\u5fa1\u8005\u535a\u5f08\u6a21\u578b\uff0c\u7814\u7a76\u5728\u914d\u7535\u7f51\u4e2d\u901a\u8fc7\u66ff\u4ee3\u8fde\u63a5\u534f\u8bae(ACAs)\u6765\u9650\u5236\u5e02\u573a\u53c2\u4e0e\u8005\u7684\u53ef\u7528\u8fde\u63a5\u5bb9\u91cf\uff0c\u4ee5\u5e94\u5bf9\u7075\u6d3b\u6027\u670d\u52a1\u63d0\u4f9b\u5546(FSPs)\u7684\u7b56\u7565\u6027\u57fa\u51c6\u8c03\u6574\u884c\u4e3a\uff0c\u4ece\u800c\u964d\u4f4e\u518d\u8c03\u5ea6\u6210\u672c\u3002", "motivation": "\u518d\u8c03\u5ea6\u5e02\u573a\u88ab\u7cfb\u7edf\u8fd0\u8425\u5546\u5e7f\u6cdb\u7528\u4e8e\u7ba1\u7406\u7f51\u7edc\u62e5\u585e\uff0c\u4f46\u7075\u6d3b\u6027\u670d\u52a1\u63d0\u4f9b\u5546\u53ef\u80fd\u4f1a\u7b56\u7565\u6027\u5730\u8c03\u6574\u5176\u57fa\u51c6\u4ee5\u9884\u671f\u518d\u8c03\u5ea6\u884c\u52a8\uff0c\u4ece\u800c\u52a0\u5267\u62e5\u585e\u5e76\u63d0\u9ad8\u7cfb\u7edf\u6210\u672c\u3002", "method": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u4e09\u5c42\u6b21\u4f18\u5316\u6a21\u578b\uff0c\u4f7f\u7528\u81ea\u5b9a\u4e49\u7684\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\u6c42\u89e3\uff0c\u5728\u5927\u591a\u6570\u6a21\u62df\u573a\u666f\u4e2d\u65e0\u9700\u63a2\u7d22\u5206\u652f\u5b9a\u754c\u641c\u7d22\u6811\u4e2d\u7684\u8bb8\u591a\u8282\u70b9\u5373\u53ef\u9ad8\u6548\u89e3\u51b3\u95ee\u9898\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u5e94\u7528\u66ff\u4ee3\u8fde\u63a5\u534f\u8bae\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u914d\u7535\u7f51\u8fd0\u8425\u5546\u7684\u518d\u8c03\u5ea6\u6210\u672c(\u4f8b\u5982\u964d\u4f4e25%)\uff0c\u540c\u65f6\u5bf9\u7075\u6d3b\u6027\u670d\u52a1\u63d0\u4f9b\u5546\u7684\u5229\u6da6\u5f71\u54cd\u6709\u9650\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u5173\u952e\u53d6\u51b3\u4e8e\u914d\u7535\u7f51\u8fd0\u8425\u5546\u80fd\u591f\u8c03\u7528\u66ff\u4ee3\u8fde\u63a5\u534f\u8bae\u7684\u9891\u7387\uff0c\u4ee5\u53ca\u5176\u80fd\u591f\u9884\u671f\u7075\u6d3b\u6027\u670d\u52a1\u63d0\u4f9b\u5546\u7b56\u7565\u6027\u6295\u6807\u884c\u4e3a\u7684\u7a0b\u5ea6\u3002"}}
{"id": "2510.06997", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06997", "abs": "https://arxiv.org/abs/2510.06997", "authors": ["Mrityunjay Kumar"], "title": "The Limits of Goal-Setting Theory in LLM-Driven Assessment", "comment": "Accepted at T4E 2025 for poster", "summary": "Many users interact with AI tools like ChatGPT using a mental model that\ntreats the system as human-like, which we call Model H. According to\ngoal-setting theory, increased specificity in goals should reduce performance\nvariance. If Model H holds, then prompting a chatbot with more detailed\ninstructions should lead to more consistent evaluation behavior.\n  This paper tests that assumption through a controlled experiment in which\nChatGPT evaluated 29 student submissions using four prompts with increasing\nspecificity. We measured consistency using intra-rater reliability (Cohen's\nKappa) across repeated runs.\n  Contrary to expectations, performance did not improve consistently with\nincreased prompt specificity, and performance variance remained largely\nunchanged. These findings challenge the assumption that LLMs behave like human\nevaluators and highlight the need for greater robustness and improved input\nintegration in future model development.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u7528\u6237\u503e\u5411\u4e8e\u5c06AI\u5de5\u5177\u89c6\u4e3a\u7c7b\u4eba\u6a21\u578b\uff08Model H\uff09\uff0c\u4f46\u589e\u52a0\u63d0\u793a\u8bed\u7684\u5177\u4f53\u6027\u5e76\u4e0d\u80fd\u63d0\u9ad8ChatGPT\u8bc4\u4f30\u5b66\u751f\u4f5c\u4e1a\u7684\u4e00\u81f4\u6027\uff0c\u8fd9\u4e0e\u76ee\u6807\u8bbe\u5b9a\u7406\u8bba\u7684\u9884\u671f\u76f8\u53cd\u3002", "motivation": "\u9a8c\u8bc1\u7528\u6237\u5c06AI\u89c6\u4e3a\u7c7b\u4eba\u6a21\u578b\uff08Model H\uff09\u7684\u5047\u8bbe\uff0c\u5373\u6839\u636e\u76ee\u6807\u8bbe\u5b9a\u7406\u8bba\uff0c\u66f4\u5177\u4f53\u7684\u63d0\u793a\u5e94\u8be5\u51cf\u5c11\u6027\u80fd\u65b9\u5dee\uff0c\u63d0\u9ad8\u8bc4\u4f30\u4e00\u81f4\u6027\u3002", "method": "\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\uff0c\u8ba9ChatGPT\u4f7f\u7528\u56db\u79cd\u4e0d\u540c\u5177\u4f53\u7a0b\u5ea6\u7684\u63d0\u793a\u8bed\u8bc4\u4f3029\u4efd\u5b66\u751f\u4f5c\u4e1a\uff0c\u5e76\u901a\u8fc7\u91cd\u590d\u8fd0\u884c\u7684Cohen's Kappa\u6d4b\u91cf\u8bc4\u4f30\u4e00\u81f4\u6027\u3002", "result": "\u4e0e\u9884\u671f\u76f8\u53cd\uff0c\u63d0\u793a\u8bed\u5177\u4f53\u6027\u7684\u589e\u52a0\u5e76\u672a\u6301\u7eed\u6539\u5584\u6027\u80fd\uff0c\u6027\u80fd\u65b9\u5dee\u57fa\u672c\u4fdd\u6301\u4e0d\u53d8\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u6311\u6218\u4e86LLMs\u884c\u4e3a\u7c7b\u4f3c\u4eba\u7c7b\u8bc4\u4f30\u8005\u7684\u5047\u8bbe\uff0c\u5f3a\u8c03\u4e86\u672a\u6765\u6a21\u578b\u5f00\u53d1\u4e2d\u9700\u8981\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u6539\u8fdb\u7684\u8f93\u5165\u6574\u5408\u80fd\u529b\u3002"}}
{"id": "2510.07047", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.07047", "abs": "https://arxiv.org/abs/2510.07047", "authors": ["Ernest G\u00f3rka", "Dariusz Baran", "Micha\u0142 \u0106wi\u0105ka\u0142a", "Gabriela Wojak", "Robert Marszczuk", "Katarzyna Olszy\u0144ska", "Piotr Mrzyg\u0142\u00f3d", "Maciej Frasunkiewicz", "Piotr R\u0119czajski", "Kamil Sa\u0142uga", "Maciej \u015alusarczyk", "Jan Piwnik"], "title": "Analysis of managerial behaviors in business management", "comment": null, "summary": "This study explores how different managerial behaviors influence team\neffectiveness and organizational outcomes, using Kenneth Blanchard's\nsituational leadership model as a diagnostic tool. Conducted across ten\ncompanies, the research evaluates leadership adaptability through a\nscenario-based questionnaire identifying instructional, teaching, supportive,\nand delegating styles. Results show that the supportive (affiliative) style is\ndominant, present in 60 percent of surveyed companies, with delegating being\nsecond. Correlation analysis reveals strong negative relationships between\ncertain styles, particularly instructional and supportive, indicating that\nflexibility in leadership is crucial. The findings suggest that over-reliance\non any one style may lead to inefficiencies, while a balanced, situational\napproach enhances decision-making, morale, and adaptability. The research\ncontributes to leadership theory by demonstrating how behavioral combinations,\nnot static traits, influence outcomes. It offers practical implications for\nmanagerial training, recommending the integration of diagnostic tools like the\nBlanchard test to improve style awareness and behavioral flexibility.\nLimitations include reliance on self-assessment data and a small sample size.\nFuture research should explore longitudinal and cross-industry analyses to\nassess how leadership behaviors evolve over time or under pressure.", "AI": {"tldr": "\u57fa\u4e8eBlanchard\u60c5\u5883\u9886\u5bfc\u6a21\u578b\u7684\u7814\u7a76\u53d1\u73b0\uff0c\u652f\u6301\u578b\u9886\u5bfc\u98ce\u683c\u6700\u666e\u904d\uff08\u536060%\u516c\u53f8\uff09\uff0c\u6388\u6743\u578b\u6b21\u4e4b\u3002\u9886\u5bfc\u98ce\u683c\u7075\u6d3b\u6027\u5bf9\u56e2\u961f\u6548\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u8fc7\u5ea6\u4f9d\u8d56\u5355\u4e00\u98ce\u683c\u4f1a\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002", "motivation": "\u63a2\u7d22\u4e0d\u540c\u7ba1\u7406\u884c\u4e3a\u5982\u4f55\u5f71\u54cd\u56e2\u961f\u6548\u80fd\u548c\u7ec4\u7ec7\u6210\u679c\uff0c\u4f7f\u7528Blanchard\u60c5\u5883\u9886\u5bfc\u6a21\u578b\u4f5c\u4e3a\u8bca\u65ad\u5de5\u5177\u3002", "method": "\u572810\u5bb6\u516c\u53f8\u8fdb\u884c\u8c03\u7814\uff0c\u901a\u8fc7\u57fa\u4e8e\u60c5\u5883\u7684\u95ee\u5377\u8bc4\u4f30\u9886\u5bfc\u9002\u5e94\u6027\uff0c\u8bc6\u522b\u6307\u5bfc\u578b\u3001\u6559\u5bfc\u578b\u3001\u652f\u6301\u578b\u548c\u6388\u6743\u578b\u56db\u79cd\u9886\u5bfc\u98ce\u683c\u3002", "result": "\u652f\u6301\u578b\uff08\u4eb2\u548c\u578b\uff09\u9886\u5bfc\u98ce\u683c\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u5b58\u5728\u4e8e60%\u7684\u88ab\u8c03\u67e5\u516c\u53f8\u4e2d\uff0c\u6388\u6743\u578b\u6b21\u4e4b\u3002\u76f8\u5173\u6027\u5206\u6790\u663e\u793a\u67d0\u4e9b\u98ce\u683c\u95f4\u5b58\u5728\u5f3a\u8d1f\u76f8\u5173\uff0c\u7279\u522b\u662f\u6307\u5bfc\u578b\u4e0e\u652f\u6301\u578b\u4e4b\u95f4\u3002", "conclusion": "\u9886\u5bfc\u884c\u4e3a\u7ec4\u5408\uff08\u800c\u975e\u9759\u6001\u7279\u8d28\uff09\u5f71\u54cd\u7ed3\u679c\uff0c\u5e73\u8861\u7684\u60c5\u5883\u65b9\u6cd5\u80fd\u63d0\u5347\u51b3\u7b56\u3001\u58eb\u6c14\u548c\u9002\u5e94\u6027\u3002\u5efa\u8bae\u5c06Blanchard\u6d4b\u8bd5\u7b49\u8bca\u65ad\u5de5\u5177\u7eb3\u5165\u7ba1\u7406\u57f9\u8bad\u4ee5\u63d0\u9ad8\u98ce\u683c\u610f\u8bc6\u548c\u884c\u4e3a\u7075\u6d3b\u6027\u3002"}}
{"id": "2510.06546", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.06546", "abs": "https://arxiv.org/abs/2510.06546", "authors": ["Mohammad Nazeri", "Sheldon Mei", "Jeffrey Watchorn", "Alex Zhang", "Erin Ng", "Tao Wen", "Abhijoy Mandal", "Kevin Golovin", "Alan Aspuru-Guzik", "Frank Gu"], "title": "RAISE: A self-driving laboratory for interfacial property formulation discovery", "comment": "Mohammad Nazeri, Sheldon Mei, and Jeffrey Watchorn contributed\n  equally to this work. *Corresponding author: Frank Gu (f.gu@utoronto.ca)", "summary": "Surface wettability is a critical design parameter for biomedical devices,\ncoatings, and textiles. Contact angle measurements quantify liquid-surface\ninteractions, which depend strongly on liquid formulation. Herein, we present\nthe Robotic Autonomous Imaging Surface Evaluator (RAISE), a closed-loop,\nself-driving laboratory that is capable of linking liquid formulation\noptimization with surface wettability assessment. RAISE comprises a full\nexperimental orchestrator with the ability of mixing liquid ingredients to\ncreate varying formulation cocktails, transferring droplets of prepared\nformulations to a high-throughput stage, and using a pick-and-place camera tool\nfor automated droplet image capture. The system also includes an automated\nimage processing pipeline to measure contact angles. This closed loop\nexperiment orchestrator is integrated with a Bayesian Optimization (BO) client,\nwhich enables iterative exploration of new formulations based on previous\ncontact angle measurements to meet user-defined objectives. The system operates\nin a high-throughput manner and can achieve a measurement rate of approximately\n1 contact angle measurement per minute. Here we demonstrate RAISE can be used\nto explore surfactant wettability and how surfactant combinations create\ntunable formulations that compensate for purity-related variations.\nFurthermore, multi-objective BO demonstrates how precise and optimal\nformulations can be reached based on application-specific goals. The\noptimization is guided by a desirability score, which prioritizes formulations\nthat are within target contact angle ranges, minimize surfactant usage and\nreduce cost. This work demonstrates the capabilities of RAISE to autonomously\nlink liquid formulations to contact angle measurements in a closed-loop system,\nusing multi-objective BO to efficiently identify optimal formulations aligned\nwith researcher-defined criteria.", "AI": {"tldr": "RAISE\u662f\u4e00\u4e2a\u81ea\u4e3b\u673a\u5668\u4eba\u5b9e\u9a8c\u5ba4\u7cfb\u7edf\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u4f18\u5316\u81ea\u52a8\u63a2\u7d22\u6db2\u4f53\u914d\u65b9\u4e0e\u8868\u9762\u6da6\u6e7f\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5b9e\u73b0\u9ad8\u901a\u91cf\u63a5\u89e6\u89d2\u6d4b\u91cf\u548c\u914d\u65b9\u4f18\u5316\u3002", "motivation": "\u8868\u9762\u6da6\u6e7f\u6027\u662f\u751f\u7269\u533b\u5b66\u8bbe\u5907\u3001\u6d82\u5c42\u548c\u7eba\u7ec7\u54c1\u7684\u5173\u952e\u8bbe\u8ba1\u53c2\u6570\uff0c\u4f46\u6db2\u4f53\u914d\u65b9\u5bf9\u63a5\u89e6\u89d2\u6d4b\u91cf\u5f71\u54cd\u5f88\u5927\uff0c\u9700\u8981\u81ea\u52a8\u5316\u7cfb\u7edf\u6765\u9ad8\u6548\u63a2\u7d22\u914d\u65b9\u4e0e\u6da6\u6e7f\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u5f00\u53d1\u4e86RAISE\u7cfb\u7edf\uff0c\u5305\u542b\u6db2\u4f53\u914d\u65b9\u6df7\u5408\u3001\u6db2\u6ef4\u8f6c\u79fb\u3001\u81ea\u52a8\u56fe\u50cf\u91c7\u96c6\u548c\u63a5\u89e6\u89d2\u6d4b\u91cf\u7ba1\u9053\uff0c\u96c6\u6210\u8d1d\u53f6\u65af\u4f18\u5316\u5ba2\u6237\u7aef\u8fdb\u884c\u8fed\u4ee3\u914d\u65b9\u63a2\u7d22\u3002", "result": "\u7cfb\u7edf\u6d4b\u91cf\u901f\u7387\u7ea6\u6bcf\u5206\u949f1\u4e2a\u63a5\u89e6\u89d2\uff0c\u80fd\u63a2\u7d22\u8868\u9762\u6d3b\u6027\u5242\u6da6\u6e7f\u6027\uff0c\u901a\u8fc7\u591a\u76ee\u6807\u8d1d\u53f6\u65af\u4f18\u5316\u627e\u5230\u7b26\u5408\u7279\u5b9a\u5e94\u7528\u76ee\u6807\u7684\u6700\u4f18\u914d\u65b9\u3002", "conclusion": "RAISE\u6210\u529f\u5c55\u793a\u4e86\u5728\u95ed\u73af\u7cfb\u7edf\u4e2d\u81ea\u4e3b\u8fde\u63a5\u6db2\u4f53\u914d\u65b9\u4e0e\u63a5\u89e6\u89d2\u6d4b\u91cf\u7684\u80fd\u529b\uff0c\u4f7f\u7528\u591a\u76ee\u6807\u8d1d\u53f6\u65af\u4f18\u5316\u9ad8\u6548\u8bc6\u522b\u7b26\u5408\u7814\u7a76\u8005\u5b9a\u4e49\u6807\u51c6\u7684\u6700\u4f18\u914d\u65b9\u3002"}}
{"id": "2510.06433", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06433", "abs": "https://arxiv.org/abs/2510.06433", "authors": ["Aryan Singh Dalal", "Yinglun Zhang", "Duru Do\u011fan", "Atalay Mert \u0130leri", "Hande K\u00fc\u00e7\u00fck McGinty"], "title": "Flavonoid Fusion: Creating a Knowledge Graph to Unveil the Interplay Between Food and Health", "comment": null, "summary": "The focus on \"food as medicine\" is gaining traction in the field of health\nand several studies conducted in the past few years discussed this aspect of\nfood in the literature. However, very little research has been done on\nrepresenting the relationship between food and health in a standardized,\nmachine-readable format using a semantic web that can help us leverage this\nknowledge effectively. To address this gap, this study aims to create a\nknowledge graph to link food and health through the knowledge graph's ability\nto combine information from various platforms focusing on flavonoid contents of\nfood found in the USDA databases and cancer connections found in the\nliterature. We looked closely at these relationships using KNARM methodology\nand represented them in machine-operable format. The proposed knowledge graph\nserves as an example for researchers, enabling them to explore the complex\ninterplay between dietary choices and disease management. Future work for this\nstudy involves expanding the scope of the knowledge graph by capturing nuances,\nadding more related data, and performing inferences on the acquired knowledge\nto uncover hidden relationships.", "AI": {"tldr": "\u8be5\u7814\u7a76\u521b\u5efa\u4e86\u4e00\u4e2a\u77e5\u8bc6\u56fe\u8c31\uff0c\u5c06\u98df\u7269\u4e0e\u5065\u5eb7\u8054\u7cfb\u8d77\u6765\uff0c\u91cd\u70b9\u5173\u6ce8\u9ec4\u916e\u7c7b\u5316\u5408\u7269\u542b\u91cf\u4e0e\u764c\u75c7\u5173\u8054\uff0c\u4f7f\u7528KNARM\u65b9\u6cd5\u6784\u5efa\u673a\u5668\u53ef\u64cd\u4f5c\u7684\u8bed\u4e49\u7f51\u7edc\u8868\u793a\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5f88\u5c11\u4ee5\u6807\u51c6\u5316\u3001\u673a\u5668\u53ef\u8bfb\u7684\u8bed\u4e49\u7f51\u7edc\u683c\u5f0f\u8868\u793a\u98df\u7269\u4e0e\u5065\u5eb7\u7684\u5173\u7cfb\uff0c\u65e0\u6cd5\u6709\u6548\u5229\u7528\u8fd9\u4e9b\u77e5\u8bc6\u3002", "method": "\u4f7f\u7528KNARM\u65b9\u6cd5\uff0c\u7ed3\u5408USDA\u6570\u636e\u5e93\u4e2d\u7684\u98df\u7269\u9ec4\u916e\u7c7b\u5316\u5408\u7269\u542b\u91cf\u6570\u636e\u548c\u6587\u732e\u4e2d\u7684\u764c\u75c7\u5173\u8054\u4fe1\u606f\uff0c\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u3002", "result": "\u6210\u529f\u521b\u5efa\u4e86\u8fde\u63a5\u98df\u7269\u4e0e\u5065\u5eb7\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63a2\u7d22\u996e\u98df\u9009\u62e9\u4e0e\u75be\u75c5\u7ba1\u7406\u7684\u590d\u6742\u5173\u7cfb\u63d0\u4f9b\u4e86\u793a\u4f8b\u3002", "conclusion": "\u8be5\u77e5\u8bc6\u56fe\u8c31\u53ef\u4f5c\u4e3a\u7814\u7a76\u57fa\u7840\uff0c\u672a\u6765\u9700\u8981\u6269\u5c55\u8303\u56f4\u3001\u6dfb\u52a0\u66f4\u591a\u76f8\u5173\u6570\u636e\u5e76\u8fdb\u884c\u63a8\u7406\u4ee5\u53d1\u73b0\u9690\u85cf\u5173\u7cfb\u3002"}}
{"id": "2510.07113", "categories": ["eess.SY", "cond-mat.quant-gas", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.07113", "abs": "https://arxiv.org/abs/2510.07113", "authors": ["Nikolaus W\u00fcrkner", "Yevhenii Kuriatnikov", "Karthikeyan Kumaran", "Marupaka Venkat Ramana", "J\u00f6rg Schmiedmayer", "Andreas Kugi", "Maximilian Pr\u00fcfer", "Andreas Deutschmann-Olek"], "title": "Identification and optimal control strategies for the transversal splitting of ultra--cold Bose gases", "comment": "To be published in IEEE Transactions on Control Systems Technology", "summary": "Splitting a Bose--Einstein condensate (BEC) is a key operation in fundamental\nphysics experiments and emerging quantum technologies, where precise\npreparation of well--defined initial states requires fast yet coherent control\nof the condensate's nonlinear dynamics. This work formulates the BEC splitting\nprocess as an optimal feedforward control problem based on a physically\ninterpretable, reduced--order model identified from limited experimental data.\nWe introduce a systematic calibration strategy that combines optimal experiment\nselection and constrained nonlinear parameter estimation, enabling accurate\nsystem identification with minimal experimental overhead. Using this calibrated\nmodel, we compute energy--optimal trajectories via indirect optimal control to\nrealize shortcuts to adiabaticity (STAs), achieving rapid transitions to the\nground state of a double--well potential while suppressing excitations.\nExperiments confirm that the proposed control framework yields high--fidelity\nstate transfers across multiple configurations, demonstrating its robustness\nand scalability for quantum control applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u6a21\u578b\u7684BEC\u5206\u88c2\u6700\u4f18\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u8fa8\u8bc6\u548c\u95f4\u63a5\u6700\u4f18\u63a7\u5236\u5b9e\u73b0\u5feb\u901f\u9ad8\u4fdd\u771f\u6001\u8f6c\u79fb", "motivation": "BEC\u5206\u88c2\u5728\u57fa\u7840\u7269\u7406\u5b9e\u9a8c\u548c\u91cf\u5b50\u6280\u672f\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5feb\u901f\u4e14\u76f8\u5e72\u5730\u63a7\u5236\u51dd\u805a\u4f53\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u6765\u7cbe\u786e\u5236\u5907\u521d\u59cb\u6001", "method": "\u57fa\u4e8e\u6709\u9650\u5b9e\u9a8c\u6570\u636e\u5efa\u7acb\u7269\u7406\u53ef\u89e3\u91ca\u7684\u964d\u9636\u6a21\u578b\uff0c\u7ed3\u5408\u6700\u4f18\u5b9e\u9a8c\u9009\u62e9\u548c\u7ea6\u675f\u975e\u7ebf\u6027\u53c2\u6570\u4f30\u8ba1\u8fdb\u884c\u7cfb\u7edf\u6821\u51c6\uff0c\u4f7f\u7528\u95f4\u63a5\u6700\u4f18\u63a7\u5236\u8ba1\u7b97\u80fd\u91cf\u6700\u4f18\u8f68\u8ff9\u5b9e\u73b0\u7edd\u70ed\u6377\u5f84", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u63a7\u5236\u6846\u67b6\u5728\u591a\u79cd\u914d\u7f6e\u4e0b\u5b9e\u73b0\u9ad8\u4fdd\u771f\u6001\u8f6c\u79fb\uff0c\u5c55\u793a\u4e86\u5176\u5728\u91cf\u5b50\u63a7\u5236\u5e94\u7528\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027", "conclusion": "\u8be5\u5de5\u4f5c\u4e3aBEC\u5206\u88c2\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u6027\u7684\u6700\u4f18\u63a7\u5236\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u6700\u5c0f\u5b9e\u9a8c\u5f00\u9500\u4e0b\u5b9e\u73b0\u5feb\u901f\u9ad8\u4fdd\u771f\u91cf\u5b50\u6001\u64cd\u63a7"}}
{"id": "2510.07010", "categories": ["cs.CY", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.07010", "abs": "https://arxiv.org/abs/2510.07010", "authors": ["Mrityunjay Kumar", "Venkatesh Choppella"], "title": "Early Results from Teaching Modelling for Software Comprehension in New-Hire Onboarding", "comment": "Accepted at COMPUTE 2025 as short paper", "summary": "Working effectively with large, existing software systems requires strong\ncomprehension skills, yet most graduates enter the industry with little\npreparation for this challenge. We report early results from a pilot\nintervention integrated into a SaaS company's onboarding program: a\nfive-session course introducing systems thinking and Labelled Transition System\n(LTS) modelling. Participants articulated their understanding of product\nbehaviour using a structured template and completed matched pre- and\npost-assessments. Of 35 new hires, 31 provided paired records for analysis.\nAcross the full cohort, gains were small and not statistically significant.\nHowever, participants below the median on the pre-test improved by 15\npercentage points on average (statistically significant), while those above the\nmedian regressed slightly (not statistically significant). Course feedback\nindicated high engagement and perceived applicability. These results suggest\nthat short, modelling-focused onboarding interventions can accelerate\ncomprehension for less-prepared new hires. At the same time, they point to the\nneed for differentiated pathways for stronger participants, and to the\npotential for companies to adopt such interventions at scale as a low-cost\ncomplement to existing onboarding.", "AI": {"tldr": "\u5728SaaS\u516c\u53f8\u5165\u804c\u57f9\u8bad\u4e2d\u5f15\u5165\u7cfb\u7edf\u601d\u7ef4\u548cLTS\u5efa\u6a21\u7684\u4e94\u6b21\u8bfe\u7a0b\u5e72\u9884\uff0c\u7ed3\u679c\u663e\u793a\u5bf9\u9884\u5907\u77e5\u8bc6\u8f83\u5c11\u7684\u65b0\u5458\u5de5\u7406\u89e3\u529b\u63d0\u5347\u663e\u8457\uff0815\u4e2a\u767e\u5206\u70b9\uff09\uff0c\u4f46\u5bf9\u9884\u5907\u77e5\u8bc6\u8f83\u597d\u7684\u5458\u5de5\u6548\u679c\u4e0d\u660e\u663e\u3002", "motivation": "\u5927\u591a\u6570\u6bd5\u4e1a\u751f\u8fdb\u5165\u884c\u4e1a\u65f6\u7f3a\u4e4f\u5904\u7406\u5927\u578b\u8f6f\u4ef6\u7cfb\u7edf\u7684\u51c6\u5907\uff0c\u9700\u8981\u63d0\u5347\u7cfb\u7edf\u7406\u89e3\u80fd\u529b\u3002", "method": "\u5728\u5165\u804c\u57f9\u8bad\u4e2d\u96c6\u6210\u4e94\u6b21\u8bfe\u7a0b\uff0c\u6559\u6388\u7cfb\u7edf\u601d\u7ef4\u548cLTS\u5efa\u6a21\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u6a21\u677f\u8868\u8fbe\u4ea7\u54c1\u884c\u4e3a\u7406\u89e3\uff0c\u5e76\u8fdb\u884c\u524d\u540e\u6d4b\u8bd5\u8bc4\u4f30\u3002", "result": "35\u540d\u65b0\u5458\u5de5\u4e2d31\u4eba\u63d0\u4f9b\u914d\u5bf9\u6570\u636e\uff0c\u6574\u4f53\u63d0\u5347\u4e0d\u663e\u8457\uff0c\u4f46\u9884\u5907\u77e5\u8bc6\u4f4e\u4e8e\u4e2d\u4f4d\u6570\u7684\u53c2\u4e0e\u8005\u5e73\u5747\u63d0\u534715\u4e2a\u767e\u5206\u70b9\uff08\u663e\u8457\uff09\uff0c\u9ad8\u4e8e\u4e2d\u4f4d\u6570\u7684\u53c2\u4e0e\u8005\u7565\u6709\u9000\u6b65\uff08\u4e0d\u663e\u8457\uff09\u3002", "conclusion": "\u77ed\u671f\u7684\u5efa\u6a21\u5bfc\u5411\u5165\u804c\u5e72\u9884\u80fd\u52a0\u901f\u9884\u5907\u77e5\u8bc6\u8f83\u5c11\u65b0\u5458\u5de5\u7684\u7406\u89e3\u529b\uff0c\u4f46\u9700\u8981\u4e3a\u9884\u5907\u77e5\u8bc6\u8f83\u597d\u7684\u5458\u5de5\u63d0\u4f9b\u5dee\u5f02\u5316\u8def\u5f84\uff0c\u6b64\u7c7b\u4f4e\u6210\u672c\u5e72\u9884\u53ef\u89c4\u6a21\u5316\u8865\u5145\u73b0\u6709\u5165\u804c\u57f9\u8bad\u3002"}}
{"id": "2510.06566", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.06566", "abs": "https://arxiv.org/abs/2510.06566", "authors": ["Vincent Lam", "Robin Chhabra"], "title": "Safe Obstacle-Free Guidance of Space Manipulators in Debris Removal Missions via Deep Reinforcement Learning", "comment": null, "summary": "The objective of this study is to develop a model-free workspace trajectory\nplanner for space manipulators using a Twin Delayed Deep Deterministic Policy\nGradient (TD3) agent to enable safe and reliable debris capture. A local\ncontrol strategy with singularity avoidance and manipulability enhancement is\nemployed to ensure stable execution. The manipulator must simultaneously track\na capture point on a non-cooperative target, avoid self-collisions, and prevent\nunintended contact with the target. To address these challenges, we propose a\ncurriculum-based multi-critic network where one critic emphasizes accurate\ntracking and the other enforces collision avoidance. A prioritized experience\nreplay buffer is also used to accelerate convergence and improve policy\nrobustness. The framework is evaluated on a simulated seven-degree-of-freedom\nKUKA LBR iiwa mounted on a free-floating base in Matlab/Simulink, demonstrating\nsafe and adaptive trajectory generation for debris removal missions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTD3\u5f3a\u5316\u5b66\u4e60\u7684\u65e0\u6a21\u578b\u7a7a\u95f4\u673a\u68b0\u81c2\u8f68\u8ff9\u89c4\u5212\u5668\uff0c\u901a\u8fc7\u591a\u6279\u8bc4\u7f51\u7edc\u548c\u8bfe\u7a0b\u5b66\u4e60\u5b9e\u73b0\u5b89\u5168\u53ef\u9760\u7684\u592a\u7a7a\u788e\u7247\u6355\u83b7", "motivation": "\u5f00\u53d1\u80fd\u591f\u5728\u8ffd\u8e2a\u975e\u5408\u4f5c\u76ee\u6807\u6355\u83b7\u70b9\u7684\u540c\u65f6\u907f\u514d\u81ea\u78b0\u649e\u548c\u610f\u5916\u63a5\u89e6\u7684\u5b89\u5168\u8f68\u8ff9\u89c4\u5212\u65b9\u6cd5\uff0c\u89e3\u51b3\u592a\u7a7a\u788e\u7247\u6e05\u9664\u4efb\u52a1\u4e2d\u7684\u590d\u6742\u7ea6\u675f\u95ee\u9898", "method": "\u4f7f\u7528TD3\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u7ed3\u5408\u5c40\u90e8\u63a7\u5236\u7b56\u7565\u8fdb\u884c\u5947\u70b9\u907f\u514d\u548c\u53ef\u64cd\u4f5c\u6027\u589e\u5f3a\uff0c\u91c7\u7528\u57fa\u4e8e\u8bfe\u7a0b\u7684\u591a\u6279\u8bc4\u7f51\u7edc\uff08\u4e00\u4e2a\u5173\u6ce8\u7cbe\u786e\u8ffd\u8e2a\uff0c\u4e00\u4e2a\u5173\u6ce8\u78b0\u649e\u907f\u514d\uff09\u548c\u4f18\u5148\u7ecf\u9a8c\u56de\u653e", "result": "\u5728Matlab/Simulink\u4e2d\u6a21\u62df\u7684\u4e03\u81ea\u7531\u5ea6KUKA LBR iiwa\u673a\u68b0\u81c2\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u751f\u6210\u5b89\u5168\u81ea\u9002\u5e94\u7684\u788e\u7247\u6e05\u9664\u8f68\u8ff9", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u4e3a\u7a7a\u95f4\u673a\u68b0\u81c2\u5728\u788e\u7247\u6e05\u9664\u4efb\u52a1\u4e2d\u751f\u6210\u5b89\u5168\u53ef\u9760\u7684\u8f68\u8ff9\uff0c\u540c\u65f6\u6ee1\u8db3\u591a\u91cd\u7ea6\u675f\u6761\u4ef6"}}
{"id": "2510.06475", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.06475", "abs": "https://arxiv.org/abs/2510.06475", "authors": ["Yitao Long", "Yuru Jiang", "Hongjun Liu", "Yilun Zhao", "Jingchen Sun", "Yiqiu Shen", "Chen Zhao", "Arman Cohan", "Dennis Shasha"], "title": "PuzzlePlex: Benchmarking Foundation Models on Reasoning and Planning with Puzzles", "comment": null, "summary": "This work investigates the reasoning and planning capabilities of foundation\nmodels and their scalability in complex, dynamic environments. We introduce\nPuzzlePlex, a benchmark designed to assess these capabilities through a diverse\nset of puzzles. PuzzlePlex consists of 15 types of puzzles, including\ndeterministic and stochastic games of varying difficulty, as well as\nsingle-player and two-player scenarios. The PuzzlePlex framework provides a\ncomprehensive environment for each game, and supports extensibility to generate\nmore challenging instances as foundation models evolve. Additionally, we\nimplement customized game-playing strategies for comparison. Building on this\nbenchmark, we develop fine-grained metrics to measure performance and conduct\nan in-depth analysis of frontier foundation models across two settings:\ninstruction-based and code-based. Furthermore, we systematically investigate\ntheir scaling limits. Our findings show that reasoning models outperform others\nin instruction-based settings, while code-based execution presents greater\nchallenges but offers a scalable and efficient alternative. PuzzlePlex enables\ntargeted evaluation and guides future improvements in reasoning, planning, and\ngeneralization for foundation models.", "AI": {"tldr": "PuzzlePlex\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u5305\u542b15\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u8c1c\u9898\u6e38\u620f\uff0c\u652f\u6301\u6307\u4ee4\u5f0f\u548c\u4ee3\u7801\u5f0f\u4e24\u79cd\u6267\u884c\u65b9\u5f0f\uff0c\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u5728\u6307\u4ee4\u5f0f\u8bbe\u7f6e\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u800c\u4ee3\u7801\u5f0f\u6267\u884c\u867d\u5177\u6311\u6218\u6027\u4f46\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u7814\u7a76\u57fa\u7840\u6a21\u578b\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u7684\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\u53ca\u5176\u53ef\u6269\u5c55\u6027\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u5168\u9762\u7684\u8bc4\u4f30\u57fa\u51c6\u6765\u7cfb\u7edf\u6027\u5730\u6d4b\u8bd5\u8fd9\u4e9b\u80fd\u529b\u3002", "method": "\u5f15\u5165PuzzlePlex\u57fa\u51c6\uff0c\u5305\u542b15\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u8c1c\u9898\uff08\u786e\u5b9a\u6027/\u968f\u673a\u6027\u3001\u5355\u4eba/\u53cc\u4eba\u6e38\u620f\uff09\uff0c\u63d0\u4f9b\u5b9a\u5236\u5316\u6e38\u620f\u7b56\u7565\u8fdb\u884c\u6bd4\u8f83\uff0c\u5f00\u53d1\u7ec6\u7c92\u5ea6\u6027\u80fd\u6307\u6807\uff0c\u5728\u6307\u4ee4\u5f0f\u548c\u4ee3\u7801\u5f0f\u4e24\u79cd\u8bbe\u7f6e\u4e0b\u5bf9\u524d\u6cbf\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u6df1\u5165\u5206\u6790\u3002", "result": "\u63a8\u7406\u6a21\u578b\u5728\u6307\u4ee4\u5f0f\u8bbe\u7f6e\u4e2d\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u4ee3\u7801\u5f0f\u6267\u884c\u9762\u4e34\u66f4\u5927\u6311\u6218\u4f46\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u4e86\u6a21\u578b\u7684\u6269\u5c55\u6781\u9650\u3002", "conclusion": "PuzzlePlex\u80fd\u591f\u8fdb\u884c\u9488\u5bf9\u6027\u8bc4\u4f30\uff0c\u5e76\u4e3a\u672a\u6765\u57fa\u7840\u6a21\u578b\u5728\u63a8\u7406\u3001\u89c4\u5212\u548c\u6cdb\u5316\u65b9\u9762\u7684\u6539\u8fdb\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2510.07145", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.07145", "abs": "https://arxiv.org/abs/2510.07145", "authors": ["Jhon Manuel Portella Delgado", "Ankit Goel"], "title": "Stability Preserving Safe Control of a Bicopter", "comment": null, "summary": "This paper presents a control law for stabilization and trajectory tracking\nof a multicopter subject to safety constraints. The proposed approach\nguarantees forward invariance of a prescribed safety set while ensuring smooth\ntracking performance. Unlike conventional control barrier function methods, the\nconstrained control problem is transformed into an unconstrained one using\nstate-dependent mappings together with carefully constructed Lyapunov\nfunctions. This approach enables explicit synthesis of the control law, instead\nof requiring a solution of constrained optimization at each step. The\ntransformation also enables the controller to enforce safety without\nsacrificing stability or performance. Simulation results for a polytopic\nreference trajectory confined within a designated safe region demonstrate the\neffectiveness of the proposed method.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u591a\u65cb\u7ffc\u98de\u884c\u5668\u7684\u5b89\u5168\u7ea6\u675f\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u72b6\u6001\u6620\u5c04\u5c06\u7ea6\u675f\u63a7\u5236\u95ee\u9898\u8f6c\u5316\u4e3a\u65e0\u7ea6\u675f\u95ee\u9898\uff0c\u5b9e\u73b0\u5b89\u5168\u96c6\u7684\u4fdd\u6301\u548c\u8f68\u8ff9\u8ddf\u8e2a\u3002", "motivation": "\u4f20\u7edf\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u65b9\u6cd5\u9700\u8981\u5728\u6bcf\u4e2a\u6b65\u9aa4\u6c42\u89e3\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u8ba1\u7b97\u8d1f\u62c5\u5927\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u4fdd\u8bc1\u5b89\u5168\u7ea6\u675f\u540c\u65f6\u786e\u4fdd\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u7684\u663e\u5f0f\u63a7\u5236\u5f8b\u3002", "method": "\u4f7f\u7528\u72b6\u6001\u4f9d\u8d56\u6620\u5c04\u5c06\u7ea6\u675f\u63a7\u5236\u95ee\u9898\u8f6c\u5316\u4e3a\u65e0\u7ea6\u675f\u95ee\u9898\uff0c\u7ed3\u5408\u7cbe\u5fc3\u6784\u9020\u7684Lyapunov\u51fd\u6570\uff0c\u5b9e\u73b0\u63a7\u5236\u5f8b\u7684\u663e\u5f0f\u5408\u6210\uff0c\u65e0\u9700\u6bcf\u4e00\u6b65\u6c42\u89e3\u7ea6\u675f\u4f18\u5316\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u8fb9\u5f62\u53c2\u8003\u8f68\u8ff9\u7ea6\u675f\u5728\u6307\u5b9a\u5b89\u5168\u533a\u57df\u5185\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5de5\u4f5c\uff0c\u80fd\u591f\u540c\u65f6\u4fdd\u8bc1\u5b89\u5168\u6027\u548c\u8ddf\u8e2a\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u72b6\u6001\u6620\u5c04\u6280\u672f\u6210\u529f\u89e3\u51b3\u4e86\u591a\u65cb\u7ffc\u98de\u884c\u5668\u7684\u5b89\u5168\u7ea6\u675f\u63a7\u5236\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u96c6\u4e0d\u53d8\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5e73\u6ed1\u7684\u8f68\u8ff9\u8ddf\u8e2a\u6027\u80fd\u3002"}}
{"id": "2510.07268", "categories": ["cs.CY", "cs.AI", "J.4; K.3; K.4; K.5"], "pdf": "https://arxiv.org/pdf/2510.07268", "abs": "https://arxiv.org/abs/2510.07268", "authors": ["Pompeu Casanovas"], "title": "On the false election between regulation and innovation. Ideas for regulation through the responsible use of artificial intelligence in research and education.[Spanish version]", "comment": "20 pages, in Spanish language, 1 figure, 1 table, AI Hub-CSIC /\n  EduCaixa, Escuela de Verano, Auditorio CaixaForum, Zaragoza, Spain, 4 July\n  2025", "summary": "This short essay is a reworking of the answers offered by the author at the\nDebate Session of the AIHUB (CSIC) and EduCaixa Summer School, organized by\nMarta Garcia-Matos and Lissette Lemus, and coordinated by Albert Sabater\n(OEIAC, UG), with the participation of Vanina Martinez-Posse (IIIA-CSIC),\nEulalia Soler (Eurecat) and Pompeu Casanovas (IIIA-CSIC) on July 4th 2025.\nAlbert Sabater posed three questions: (1) How can regulatory frameworks\npriori-tise the protection of fundamental rights (privacy, non-discrimination,\nautonomy, etc.) in the development of AI, without falling into the false\ndichotomy between regulation and innova-tion? (2) Given the risks of AI (bias,\nmass surveillance, manipulation), what examples of regu-lations or policies\nhave demonstrated that it is possible to foster responsible innovation, putting\nthe public interest before profitability, without giving in to competitive\npressure from actors such as China or the US? (3) In a scenario where the US\nprioritizes flexibility, what mecha-nisms could ensure that international\ncooperation in AI does not become a race to the bottom in rights, but rather a\nglobal standard of accountability? The article attempts to answer these three\nquestions and concludes with some reflections on the relevance of the answers\nfor education and research.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8AI\u76d1\u7ba1\u6846\u67b6\u5982\u4f55\u5e73\u8861\u57fa\u672c\u6743\u5229\u4fdd\u62a4\u4e0e\u521b\u65b0\uff0c\u5206\u6790\u73b0\u6709\u653f\u7b56\u6848\u4f8b\uff0c\u5e76\u63d0\u51fa\u56fd\u9645\u5408\u4f5c\u673a\u5236\u5efa\u8bae\u3002", "motivation": "\u9488\u5bf9AI\u53d1\u5c55\u4e2d\u7684\u76d1\u7ba1\u4e0e\u521b\u65b0\u77db\u76fe\u3001\u6743\u5229\u4fdd\u62a4\u98ce\u9669\u4ee5\u53ca\u56fd\u9645\u7ade\u4e89\u538b\u529b\uff0c\u5bfb\u6c42\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u5b66\u672f\u8fa9\u8bba\u548c\u95ee\u7b54\u5f62\u5f0f\uff0c\u5206\u6790\u4e09\u4e2a\u6838\u5fc3\u95ee\u9898\uff1a\u6743\u5229\u4fdd\u62a4\u4e0e\u521b\u65b0\u7684\u5e73\u8861\u3001\u8d1f\u8d23\u4efb\u521b\u65b0\u653f\u7b56\u6848\u4f8b\u3001\u56fd\u9645\u5408\u4f5c\u673a\u5236\u3002", "result": "\u63d0\u51fa\u4e86\u5728AI\u76d1\u7ba1\u4e2d\u4fdd\u62a4\u57fa\u672c\u6743\u5229\u7684\u5177\u4f53\u65b9\u6cd5\uff0c\u8bc6\u522b\u4e86\u6210\u529f\u7684\u653f\u7b56\u6848\u4f8b\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9632\u6b62\u6743\u5229\u6807\u51c6\u964d\u4f4e\u7684\u56fd\u9645\u5408\u4f5c\u673a\u5236\u3002", "conclusion": "AI\u76d1\u7ba1\u9700\u8981\u5728\u4fdd\u62a4\u57fa\u672c\u6743\u5229\u4e0e\u4fc3\u8fdb\u521b\u65b0\u4e4b\u95f4\u627e\u5230\u5e73\u8861\uff0c\u901a\u8fc7\u56fd\u9645\u5408\u4f5c\u5efa\u7acb\u5168\u7403\u95ee\u8d23\u6807\u51c6\uff0c\u8fd9\u5bf9\u6559\u80b2\u548c\u7814\u7a76\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.06633", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.06633", "abs": "https://arxiv.org/abs/2510.06633", "authors": ["Kruthika Gangaraju", "Tanmayi Inaparthy", "Jiaqi Yang", "Yihao Zheng", "Fengpei Yuan"], "title": "Assist-As-Needed: Adaptive Multimodal Robotic Assistance for Medication Management in Dementia Care", "comment": null, "summary": "People living with dementia (PLWDs) face progressively declining abilities in\nmedication management-from simple forgetfulness to complete task breakdown-yet\nmost assistive technologies fail to adapt to these changing needs. This\none-size-fits-all approach undermines autonomy, accelerates dependence, and\nincreases caregiver burden. Occupational therapy principles emphasize matching\nassistance levels to individual capabilities: minimal reminders for those who\nmerely forget, spatial guidance for those who misplace items, and comprehensive\nmultimodal support for those requiring step-by-step instruction. However,\nexisting robotic systems lack this adaptive, graduated response framework\nessential for maintaining PLWD independence. We present an adaptive multimodal\nrobotic framework using the Pepper robot that dynamically adjusts assistance\nbased on real-time assessment of user needs. Our system implements a\nhierarchical intervention model progressing from (1) simple verbal reminders,\nto (2) verbal + gestural cues, to (3) full multimodal guidance combining\nphysical navigation to medication locations with step-by-step verbal and\ngestural instructions. Powered by LLM-driven interaction strategies and\nmultimodal sensing, the system continuously evaluates task states to provide\njust-enough assistance-preserving autonomy while ensuring medication adherence.\nWe conducted a preliminary study with healthy adults and dementia care\nstakeholders in a controlled lab setting, evaluating the system's usability,\ncomprehensibility, and appropriateness of adaptive feedback mechanisms. This\nwork contributes: (1) a theoretically grounded adaptive assistance framework\ntranslating occupational therapy principles into HRI design, (2) a multimodal\nrobotic implementation that preserves PLWD dignity through graduated support,\nand (3) empirical insights into stakeholder perceptions of adaptive robotic\ncare.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePepper\u673a\u5668\u4eba\u7684\u81ea\u9002\u5e94\u591a\u6a21\u6001\u6846\u67b6\uff0c\u4e3a\u75f4\u5446\u75c7\u60a3\u8005\u63d0\u4f9b\u52a8\u6001\u8c03\u6574\u7684\u836f\u7269\u7ba1\u7406\u8f85\u52a9\uff0c\u4ece\u7b80\u5355\u63d0\u9192\u5230\u5168\u9762\u6307\u5bfc\u7684\u6e10\u8fdb\u5f0f\u652f\u6301\u3002", "motivation": "\u73b0\u6709\u8f85\u52a9\u6280\u672f\u65e0\u6cd5\u9002\u5e94\u75f4\u5446\u75c7\u60a3\u8005\u80fd\u529b\u8870\u9000\u7684\u53d8\u5316\u9700\u6c42\uff0c\u4e00\u5200\u5207\u7684\u65b9\u6cd5\u635f\u5bb3\u81ea\u4e3b\u6027\u3001\u52a0\u901f\u4f9d\u8d56\u5e76\u589e\u52a0\u62a4\u7406\u8d1f\u62c5\u3002", "method": "\u4f7f\u7528Pepper\u673a\u5668\u4eba\u5b9e\u73b0\u5206\u5c42\u5e72\u9884\u6a21\u578b\uff1a\u4ece\u53e3\u5934\u63d0\u9192\u5230\u53e3\u5934+\u624b\u52bf\u63d0\u793a\uff0c\u518d\u5230\u7ed3\u5408\u7269\u7406\u5bfc\u822a\u548c\u9010\u6b65\u6307\u5bfc\u7684\u5b8c\u6574\u591a\u6a21\u6001\u652f\u6301\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u7b56\u7565\u548c\u591a\u6a21\u6001\u611f\u77e5\u5b9e\u65f6\u8bc4\u4f30\u9700\u6c42\u3002", "result": "\u5728\u5b9e\u9a8c\u5ba4\u73af\u5883\u4e2d\u5bf9\u5065\u5eb7\u6210\u4eba\u548c\u75f4\u5446\u75c7\u62a4\u7406\u5229\u76ca\u76f8\u5173\u8005\u8fdb\u884c\u521d\u6b65\u7814\u7a76\uff0c\u8bc4\u4f30\u4e86\u7cfb\u7edf\u7684\u53ef\u7528\u6027\u3001\u53ef\u7406\u89e3\u6027\u548c\u81ea\u9002\u5e94\u53cd\u9988\u673a\u5236\u7684\u9002\u5f53\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8d21\u732e\u5305\u62ec\uff1a\u57fa\u4e8e\u804c\u4e1a\u6cbb\u7597\u539f\u5219\u7684\u81ea\u9002\u5e94\u8f85\u52a9\u6846\u67b6\u3001\u901a\u8fc7\u6e10\u8fdb\u5f0f\u652f\u6301\u7ef4\u62a4\u5c0a\u4e25\u7684\u591a\u6a21\u6001\u673a\u5668\u4eba\u5b9e\u73b0\uff0c\u4ee5\u53ca\u5bf9\u81ea\u9002\u5e94\u673a\u5668\u4eba\u62a4\u7406\u5229\u76ca\u76f8\u5173\u8005\u770b\u6cd5\u7684\u5b9e\u8bc1\u89c1\u89e3\u3002"}}
{"id": "2510.06534", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06534", "abs": "https://arxiv.org/abs/2510.06534", "authors": ["Jiahe Jin", "Abhijay Paladugu", "Chenyan Xiong"], "title": "Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them", "comment": null, "summary": "Agentic search leverages large language models (LLMs) to interpret complex\nuser information needs and execute a multi-step process of planning, searching,\nand synthesizing information to provide answers. This paradigm introduces\nunique challenges for LLMs' reasoning and agentic capabilities when interacting\nwith retrieval systems and the broader web. In this paper, we propose a\nreasoning-driven LLM-based pipeline to study effective reasoning behavior\npatterns in agentic search. Using this pipeline, we analyze successful agentic\nsearch trajectories and identify four beneficial reasoning behaviors:\nInformation Verification, Authority Evaluation, Adaptive Search, and Error\nRecovery. Based on these findings, we propose a technique called Behavior\nPriming to train more effective agentic search models. It synthesizes agentic\nsearch trajectories that exhibit these four behaviors and integrates them into\nthe agentic search model through supervised fine-tuning (SFT), followed by\nstandard reinforcement learning (RL). Experiments on three benchmarks (GAIA,\nWebWalker, and HLE) demonstrate that behavior priming yields over 35% gains in\nLlama3.2-3B and Qwen3-1.7B compared to directly training agentic search models\nwith RL. Crucially, we demonstrate that the desired reasoning behaviors in the\nSFT data, rather than the correctness of the final answer, is the critical\nfactor for achieving strong final performance after RL: fine-tuning on\ntrajectories with desirable reasoning behaviors but incorrect answers leads to\nbetter performance than fine-tuning on trajectories with correct answers. Our\nanalysis further reveals the underlying mechanism: the introduced reasoning\nbehaviors endow models with more effective exploration (higher pass@k and\nentropy) and test-time scaling (longer trajectories) capabilities, providing a\nstrong foundation for RL. Our code will be released as open source.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u884c\u4e3a\u5f15\u5bfc\u6280\u672f\uff0c\u901a\u8fc7\u8bc6\u522b\u56db\u79cd\u6709\u76ca\u63a8\u7406\u884c\u4e3a\uff08\u4fe1\u606f\u9a8c\u8bc1\u3001\u6743\u5a01\u8bc4\u4f30\u3001\u81ea\u9002\u5e94\u641c\u7d22\u3001\u9519\u8bef\u6062\u590d\uff09\u6765\u8bad\u7ec3\u66f4\u6709\u6548\u7684\u667a\u80fd\u641c\u7d22\u4ee3\u7406\uff0c\u76f8\u6bd4\u76f4\u63a5\u5f3a\u5316\u5b66\u4e60\u63d0\u534735%\u4ee5\u4e0a\u3002", "motivation": "\u667a\u80fd\u641c\u7d22\u5229\u7528LLMs\u89e3\u91ca\u590d\u6742\u7528\u6237\u9700\u6c42\u5e76\u6267\u884c\u591a\u6b65\u641c\u7d22\u8fc7\u7a0b\uff0c\u8fd9\u5bf9LLMs\u7684\u63a8\u7406\u548c\u4ee3\u7406\u80fd\u529b\u63d0\u51fa\u4e86\u72ec\u7279\u6311\u6218\uff0c\u9700\u8981\u7814\u7a76\u6709\u6548\u7684\u63a8\u7406\u884c\u4e3a\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u63a8\u7406\u9a71\u52a8\u7684LLM\u7ba1\u9053\u5206\u6790\u6210\u529f\u641c\u7d22\u8f68\u8ff9\uff0c\u8bc6\u522b\u56db\u79cd\u6709\u76ca\u63a8\u7406\u884c\u4e3a\uff0c\u7136\u540e\u901a\u8fc7\u884c\u4e3a\u5f15\u5bfc\u6280\u672f\u5408\u6210\u5c55\u73b0\u8fd9\u4e9b\u884c\u4e3a\u7684\u8f68\u8ff9\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08GAIA\u3001WebWalker\u3001HLE\uff09\u4e0a\uff0c\u884c\u4e3a\u5f15\u5bfc\u4f7fLlama3.2-3B\u548cQwen3-1.7B\u76f8\u6bd4\u76f4\u63a5RL\u8bad\u7ec3\u83b7\u5f97\u8d85\u8fc735%\u7684\u63d0\u5347\u3002", "conclusion": "SFT\u6570\u636e\u4e2d\u671f\u671b\u7684\u63a8\u7406\u884c\u4e3a\uff08\u800c\u975e\u6700\u7ec8\u7b54\u6848\u7684\u6b63\u786e\u6027\uff09\u662fRL\u540e\u83b7\u5f97\u5f3a\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5f15\u5165\u7684\u63a8\u7406\u884c\u4e3a\u8d4b\u4e88\u6a21\u578b\u66f4\u6709\u6548\u7684\u63a2\u7d22\u548c\u6d4b\u8bd5\u65f6\u6269\u5c55\u80fd\u529b\u3002"}}
{"id": "2510.06710", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.06710", "abs": "https://arxiv.org/abs/2510.06710", "authors": ["Hongzhi Zang", "Mingjie Wei", "Si Xu", "Yongji Wu", "Zhen Guo", "Yuanqing Wang", "Hao Lin", "Liangzhi Shi", "Yuqing Xie", "Zhexuan Xu", "Zhihao Liu", "Kang Chen", "Wenhao Tang", "Quanlu Zhang", "Weinan Zhang", "Chao Yu", "Yu Wang"], "title": "RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training", "comment": "This is the technical report of the RLinf Team, focusing on the\n  algorithm side. For the system-level design, please refer to\n  arXiv:2509.15965. The open-sourced code link: https://github.com/RLinf/RLinf", "summary": "Recent progress in vision and language foundation models has significantly\nadvanced multimodal understanding, reasoning, and generation, inspiring a surge\nof interest in extending such capabilities to embodied settings through\nvision-language-action (VLA) models. Yet, most VLA models are still trained\nwith supervised fine-tuning (SFT), which struggles to generalize under\ndistribution shifts due to error accumulation. Reinforcement learning (RL)\noffers a promising alternative by directly optimizing task performance through\ninteraction, but existing attempts remain fragmented and lack a unified\nplatform for fair and systematic comparison across model architectures and\nalgorithmic designs. To address this gap, we introduce RLinf-VLA, a unified and\nefficient framework for scalable RL training of VLA models. The system adopts a\nhighly flexible resource allocation design that addresses the challenge of\nintegrating rendering, training, and inference in RL+VLA training. In\nparticular, for GPU-parallelized simulators, RLinf-VLA implements a novel\nhybrid fine-grained pipeline allocation mode, achieving a 1.61x-1.88x speedup\nin training. Through a unified interface, RLinf-VLA seamlessly supports diverse\nVLA architectures (e.g., OpenVLA, OpenVLA-OFT), multiple RL algorithms (e.g.,\nPPO, GRPO), and various simulators (e.g., ManiSkill, LIBERO). In simulation, a\nunified model achieves 98.11\\% across 130 LIBERO tasks and 97.66\\% across 25\nManiSkill tasks. Beyond empirical performance, our study distills a set of best\npractices for applying RL to VLA training and sheds light on emerging patterns\nin this integration. Furthermore, we present preliminary deployment on a\nreal-world Franka robot, where RL-trained policies exhibit stronger\ngeneralization than those trained with SFT. We envision RLinf-VLA as a\nfoundation to accelerate and standardize research on embodied intelligence.", "AI": {"tldr": "\u63d0\u51fa\u4e86RLinf-VLA\u6846\u67b6\uff0c\u4e00\u4e2a\u7528\u4e8e\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u7edf\u4e00\u9ad8\u6548\u5e73\u53f0\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7cfb\u7edf\u6bd4\u8f83\u7684\u95ee\u9898\uff0c\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u4e0a\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\u5927\u591a\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\uff0c\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u80fd\u76f4\u63a5\u4f18\u5316\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u5e73\u53f0\u8fdb\u884c\u516c\u5e73\u7cfb\u7edf\u6bd4\u8f83\u3002", "method": "\u8bbe\u8ba1\u4e86RLinf-VLA\u6846\u67b6\uff0c\u91c7\u7528\u7075\u6d3b\u7684\u8d44\u6e90\u5206\u914d\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u6e32\u67d3\u3001\u8bad\u7ec3\u548c\u63a8\u7406\u7684\u9ad8\u6548\u96c6\u6210\u3002\u7279\u522b\u9488\u5bf9GPU\u5e76\u884c\u5316\u6a21\u62df\u5668\uff0c\u5b9e\u73b0\u4e86\u6df7\u5408\u7ec6\u7c92\u5ea6\u6d41\u6c34\u7ebf\u5206\u914d\u6a21\u5f0f\u3002", "result": "\u5728\u4eff\u771f\u4e2d\uff0c\u7edf\u4e00\u6a21\u578b\u5728130\u4e2aLIBERO\u4efb\u52a1\u4e0a\u8fbe\u523098.11%\u6210\u529f\u7387\uff0c\u572825\u4e2aManiSkill\u4efb\u52a1\u4e0a\u8fbe\u523097.66%\u6210\u529f\u7387\u3002\u771f\u5b9e\u673a\u5668\u4eba\u90e8\u7f72\u663e\u793aRL\u8bad\u7ec3\u7b56\u7565\u6bd4SFT\u5177\u6709\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "RLinf-VLA\u4e3a\u5177\u8eab\u667a\u80fd\u7814\u7a76\u63d0\u4f9b\u4e86\u52a0\u901f\u548c\u6807\u51c6\u5316\u7684\u57fa\u7840\uff0c\u603b\u7ed3\u4e86RL\u5e94\u7528\u4e8eVLA\u8bad\u7ec3\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u5e76\u63ed\u793a\u4e86\u8fd9\u79cd\u6574\u5408\u4e2d\u7684\u65b0\u5174\u6a21\u5f0f\u3002"}}
{"id": "2510.06538", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06538", "abs": "https://arxiv.org/abs/2510.06538", "authors": ["Jiajie Li", "Huayi Zhang", "Peng Lin", "Jinjun Xiong", "Wei Xu"], "title": "Auto-Prompt Ensemble for LLM Judge", "comment": null, "summary": "We present a novel framework that improves the reliability of LLM judges by\nselectively augmenting LLM with auxiliary evaluation dimensions. Existing LLM\njudges often miss crucial evaluation dimensions because they fail to recognize\nthe implicit standards underlying human assessments. To address this challenge,\nwe propose the Auto-Prompt Ensemble (APE), an adaptive framework that\nautomatically learns evaluation dimensions from its failure cases. APE\nincorporates a confidence-based ensemble mechanism to decide when to adopt the\njudgments from additional evaluation dimensions through a novel confidence\nestimation approach called Collective Confidence. Extensive experiments\ndemonstrate that APE improves the reliability of LLM Judge across diverse\nstandard benchmarks. For instance, APE enhances GPT-4o agreement rate on Reward\nBench from 87.2% to 90.5% in the zero-shot setting. Overall, APE provides a\nprincipled approach for LLM Judge to leverage test-time computation, and bridge\nthe evaluation gap between human and LLM judges.", "AI": {"tldr": "\u63d0\u51fa\u4e86Auto-Prompt Ensemble (APE)\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u589e\u5f3aLLM\u8f85\u52a9\u8bc4\u4f30\u7ef4\u5ea6\u6765\u63d0\u9ad8LLM\u6cd5\u5b98\u7684\u53ef\u9760\u6027\u3002\u8be5\u6846\u67b6\u81ea\u52a8\u4ece\u5931\u8d25\u6848\u4f8b\u4e2d\u5b66\u4e60\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u96c6\u6210\u673a\u5236\u6765\u51b3\u5b9a\u4f55\u65f6\u91c7\u7528\u989d\u5916\u8bc4\u4f30\u7ef4\u5ea6\u7684\u5224\u65ad\u3002", "motivation": "\u73b0\u6709LLM\u6cd5\u5b98\u7ecf\u5e38\u9057\u6f0f\u5173\u952e\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u56e0\u4e3a\u5b83\u4eec\u65e0\u6cd5\u8bc6\u522b\u4eba\u7c7b\u8bc4\u4f30\u80cc\u540e\u7684\u9690\u542b\u6807\u51c6\uff0c\u5bfc\u81f4\u8bc4\u4f30\u53ef\u9760\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51faAPE\u6846\u67b6\uff0c\u5305\u542b\u81ea\u9002\u5e94\u5b66\u4e60\u8bc4\u4f30\u7ef4\u5ea6\u7684\u80fd\u529b\uff0c\u91c7\u7528\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u96c6\u6210\u673a\u5236\uff0c\u901a\u8fc7Collective Confidence\u65b9\u6cd5\u4f30\u8ba1\u7f6e\u4fe1\u5ea6\u6765\u51b3\u5b9a\u662f\u5426\u91c7\u7528\u989d\u5916\u8bc4\u4f30\u7ef4\u5ea6\u7684\u5224\u65ad\u3002", "result": "\u5728\u591a\u6837\u5316\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAPE\u663e\u8457\u63d0\u9ad8\u4e86LLM\u6cd5\u5b98\u7684\u53ef\u9760\u6027\u3002\u4f8b\u5982\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\uff0cGPT-4o\u5728Reward Bench\u4e0a\u7684\u4e00\u81f4\u6027\u7387\u4ece87.2%\u63d0\u5347\u523090.5%\u3002", "conclusion": "APE\u4e3aLLM\u6cd5\u5b98\u63d0\u4f9b\u4e86\u4e00\u79cd\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u5229\u7528\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6765\u5f25\u5408\u4eba\u7c7b\u4e0eLLM\u6cd5\u5b98\u4e4b\u95f4\u7684\u8bc4\u4f30\u5dee\u8ddd\u3002"}}
{"id": "2510.06717", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.06717", "abs": "https://arxiv.org/abs/2510.06717", "authors": ["Yuanfei Lin", "Sebastian Illing", "Matthias Althoff"], "title": "SanDRA: Safe Large-Language-Model-Based Decision Making for Automated Vehicles Using Reachability Analysis", "comment": "@2025 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Large language models have been widely applied to knowledge-driven\ndecision-making for automated vehicles due to their strong generalization and\nreasoning capabilities. However, the safety of the resulting decisions cannot\nbe ensured due to possible hallucinations and the lack of integrated vehicle\ndynamics. To address this issue, we propose SanDRA, the first safe\nlarge-language-model-based decision making framework for automated vehicles\nusing reachability analysis. Our approach starts with a comprehensive\ndescription of the driving scenario to prompt large language models to generate\nand rank feasible driving actions. These actions are translated into temporal\nlogic formulas that incorporate formalized traffic rules, and are subsequently\nintegrated into reachability analysis to eliminate unsafe actions. We validate\nour approach in both open-loop and closed-loop driving environments using\noff-the-shelf and finetuned large language models, showing that it can provide\nprovably safe and, where possible, legally compliant driving actions, even\nunder high-density traffic conditions. To ensure transparency and facilitate\nfuture research, all code and experimental setups are publicly available at\ngithub.com/CommonRoad/SanDRA.", "AI": {"tldr": "SanDRA\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u8fbe\u6027\u5206\u6790\u5b89\u5168\u51b3\u7b56\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\uff0c\u901a\u8fc7\u5c06LLM\u751f\u6210\u7684\u52a8\u4f5c\u8f6c\u5316\u4e3a\u65f6\u5e8f\u903b\u8f91\u516c\u5f0f\u5e76\u7ed3\u5408\u53ef\u8fbe\u6027\u5206\u6790\u6765\u786e\u4fdd\u9a7e\u9a76\u5b89\u5168\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u9a7e\u9a76\u51b3\u7b56\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\u548c\u7f3a\u4e4f\u8f66\u8f86\u52a8\u529b\u5b66\u96c6\u6210\uff0c\u65e0\u6cd5\u786e\u4fdd\u51b3\u7b56\u5b89\u5168\u6027\u3002", "method": "\u9996\u5148\u901a\u8fc7\u573a\u666f\u63cf\u8ff0\u63d0\u793aLLM\u751f\u6210\u5e76\u6392\u5e8f\u53ef\u884c\u9a7e\u9a76\u52a8\u4f5c\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u52a8\u4f5c\u8f6c\u5316\u4e3a\u5305\u542b\u5f62\u5f0f\u5316\u4ea4\u901a\u89c4\u5219\u7684\u65f6\u5e8f\u903b\u8f91\u516c\u5f0f\uff0c\u6700\u540e\u901a\u8fc7\u53ef\u8fbe\u6027\u5206\u6790\u6d88\u9664\u4e0d\u5b89\u5168\u52a8\u4f5c\u3002", "result": "\u5728\u5f00\u73af\u548c\u95ed\u73af\u9a7e\u9a76\u73af\u5883\u4e2d\u9a8c\u8bc1\uff0c\u80fd\u591f\u63d0\u4f9b\u53ef\u8bc1\u660e\u5b89\u5168\u7684\u9a7e\u9a76\u52a8\u4f5c\uff0c\u5728\u9ad8\u5bc6\u5ea6\u4ea4\u901a\u6761\u4ef6\u4e0b\u4e5f\u80fd\u4fdd\u6301\u5408\u6cd5\u5408\u89c4\u3002", "conclusion": "SanDRA\u6846\u67b6\u80fd\u591f\u4e3a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u9a7e\u9a76\u51b3\u7b56\u63d0\u4f9b\u5b89\u5168\u4fdd\u969c\uff0c\u4ee3\u7801\u548c\u5b9e\u9a8c\u8bbe\u7f6e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2510.06587", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06587", "abs": "https://arxiv.org/abs/2510.06587", "authors": ["Jingbo Yang", "Bairu Hou", "Wei Wei", "Shiyu Chang", "Yujia Bao"], "title": "WebDART: Dynamic Decomposition and Re-planning for Complex Web Tasks", "comment": null, "summary": "Large language model (LLM) agents are becoming competent at straightforward\nweb tasks, such as opening an item page or submitting a form, but still\nstruggle with objectives that require long horizon navigation, large scale\ninformation extraction, and reasoning under constraints. We present WebDART, a\ngeneral framework that enables a single LLM to handle such complex chores.\nWebDART (i) dynamically decomposes each objective into three focused subtasks:\nnavigation, information extraction, and execution, so the model concentrates on\none skill at a time, and (ii) continuously replans the decomposition as new\nwebpages are revealed, taking advantage of newly discovered filters or\nshortcuts and avoiding redundant exploration. Evaluated on WebChoreArena,\nWebDART lifts success rates by up to 13.7 percentage points over previous SOTA\nagents, while matching their performance on the easier WebArena suite and\ncompleting tasks with up to 14.7 fewer navigation steps.", "AI": {"tldr": "WebDART\u662f\u4e00\u4e2aLLM\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u5206\u89e3\u4efb\u52a1\u4e3a\u5bfc\u822a\u3001\u4fe1\u606f\u63d0\u53d6\u548c\u6267\u884c\u4e09\u4e2a\u5b50\u4efb\u52a1\uff0c\u5e76\u6301\u7eed\u91cd\u65b0\u89c4\u5212\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u7f51\u9875\u4efb\u52a1\u7684\u5b8c\u6210\u7387\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u5728\u5904\u7406\u9700\u8981\u957f\u65f6\u7a0b\u5bfc\u822a\u3001\u5927\u89c4\u6a21\u4fe1\u606f\u63d0\u53d6\u548c\u7ea6\u675f\u63a8\u7406\u7684\u590d\u6742\u7f51\u9875\u4efb\u52a1\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u5c06\u76ee\u6807\u52a8\u6001\u5206\u89e3\u4e3a\u4e09\u4e2a\u4e13\u6ce8\u5b50\u4efb\u52a1\uff08\u5bfc\u822a\u3001\u4fe1\u606f\u63d0\u53d6\u3001\u6267\u884c\uff09\uff0c\u5e76\u5728\u53d1\u73b0\u65b0\u7f51\u9875\u65f6\u6301\u7eed\u91cd\u65b0\u89c4\u5212\u5206\u89e3\u7b56\u7565\u3002", "result": "\u5728WebChoreArena\u4e0a\u6bd4\u4e4b\u524dSOTA\u4ee3\u7406\u63d0\u534713.7\u4e2a\u767e\u5206\u70b9\u6210\u529f\u7387\uff0c\u5728WebArena\u4e0a\u8868\u73b0\u76f8\u5f53\uff0c\u4e14\u5bfc\u822a\u6b65\u9aa4\u51cf\u5c11\u8fbe14.7\u6b65\u3002", "conclusion": "WebDART\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347LLM\u4ee3\u7406\u5904\u7406\u590d\u6742\u7f51\u9875\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\u548c\u52a8\u6001\u89c4\u5212\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2510.06754", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.06754", "abs": "https://arxiv.org/abs/2510.06754", "authors": ["Christian Maurer", "Snehal Jauhri", "Sophie Lueth", "Georgia Chalvatzaki"], "title": "UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene", "comment": "Project website: https://sites.google.com/view/uniffield", "summary": "Comprehensive visual, geometric, and semantic understanding of a 3D scene is\ncrucial for successful execution of robotic tasks, especially in unstructured\nand complex environments. Additionally, to make robust decisions, it is\nnecessary for the robot to evaluate the reliability of perceived information.\nWhile recent advances in 3D neural feature fields have enabled robots to\nleverage features from pretrained foundation models for tasks such as\nlanguage-guided manipulation and navigation, existing methods suffer from two\ncritical limitations: (i) they are typically scene-specific, and (ii) they lack\nthe ability to model uncertainty in their predictions. We present UniFField, a\nunified uncertainty-aware neural feature field that combines visual, semantic,\nand geometric features in a single generalizable representation while also\npredicting uncertainty in each modality. Our approach, which can be applied\nzero shot to any new environment, incrementally integrates RGB-D images into\nour voxel-based feature representation as the robot explores the scene,\nsimultaneously updating uncertainty estimation. We evaluate our uncertainty\nestimations to accurately describe the model prediction errors in scene\nreconstruction and semantic feature prediction. Furthermore, we successfully\nleverage our feature predictions and their respective uncertainty for an active\nobject search task using a mobile manipulator robot, demonstrating the\ncapability for robust decision-making.", "AI": {"tldr": "UniFField\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u795e\u7ecf\u7279\u5f81\u573a\uff0c\u7ed3\u5408\u4e86\u89c6\u89c9\u3001\u8bed\u4e49\u548c\u51e0\u4f55\u7279\u5f81\uff0c\u5e76\u9884\u6d4b\u6bcf\u4e2a\u6a21\u6001\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u53ef\u96f6\u6837\u672c\u5e94\u7528\u4e8e\u65b0\u73af\u5883\uff0c\u652f\u6301\u673a\u5668\u4eba\u7a33\u5065\u51b3\u7b56\u3002", "motivation": "3D\u573a\u666f\u7684\u5168\u9762\u89c6\u89c9\u3001\u51e0\u4f55\u548c\u8bed\u4e49\u7406\u89e3\u5bf9\u673a\u5668\u4eba\u4efb\u52a1\u6267\u884c\u81f3\u5173\u91cd\u8981\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u573a\u666f\u7279\u5b9a\u6027\u548c\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4f53\u7d20\u7684\u901a\u7528\u5316\u7279\u5f81\u8868\u793a\uff0c\u589e\u91cf\u96c6\u6210RGB-D\u56fe\u50cf\uff0c\u540c\u65f6\u66f4\u65b0\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u652f\u6301\u96f6\u6837\u672c\u5e94\u7528\u3002", "result": "\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u80fd\u51c6\u786e\u63cf\u8ff0\u573a\u666f\u91cd\u5efa\u548c\u8bed\u4e49\u7279\u5f81\u9884\u6d4b\u7684\u6a21\u578b\u8bef\u5dee\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u79fb\u52a8\u673a\u68b0\u81c2\u7684\u4e3b\u52a8\u7269\u4f53\u641c\u7d22\u4efb\u52a1\u3002", "conclusion": "UniFField\u4e3a\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u7a33\u5065\u51b3\u7b56\u80fd\u529b\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7279\u5f81\u573a\u5b9e\u73b0\u4e86\u8de8\u573a\u666f\u7684\u901a\u7528\u53163D\u7406\u89e3\u3002"}}
{"id": "2510.06600", "categories": ["cs.AI", "H.3.3; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.06600", "abs": "https://arxiv.org/abs/2510.06600", "authors": ["Zhaochun Ren", "Zhou Yang", "Chenglong Ye", "Haizhou Sun", "Chao Chen", "Xiaofei Zhu", "Xiangwen Liao"], "title": "Fine-Grained Emotion Recognition via In-Context Learning", "comment": "9 pages, 10 figures, 4 tables", "summary": "Fine-grained emotion recognition aims to identify the emotional type in\nqueries through reasoning and decision-making processes, playing a crucial role\nin various systems. Recent methods use In-Context Learning (ICL), enhancing the\nrepresentation of queries in the reasoning process through semantically similar\nexamples, while further improving emotion recognition by explaining the\nreasoning mechanisms. However, these methods enhance the reasoning process but\noverlook the decision-making process. This paper investigates decision-making\nin fine-grained emotion recognition through prototype theory. We show that ICL\nrelies on similarity matching between query representations and emotional\nprototypes within the model, where emotion-accurate representations are\ncritical. However, semantically similar examples often introduce emotional\ndiscrepancies, hindering accurate representations and causing errors. To\naddress this, we propose Emotion In-Context Learning (EICL), which introduces\nemotionally similar examples and uses a dynamic soft-label strategy to improve\nquery representations in the emotion reasoning process. A two-stage exclusion\nstrategy is then employed to assess similarity from multiple angles, further\noptimizing the decision-making process. Extensive experiments show that EICL\nsignificantly outperforms ICL on multiple datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEICL\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u60c5\u611f\u76f8\u4f3c\u793a\u4f8b\u548c\u52a8\u6001\u8f6f\u6807\u7b7e\u7b56\u7565\u6539\u8fdb\u7ec6\u7c92\u5ea6\u60c5\u611f\u8bc6\u522b\u4e2d\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edfICL\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709ICL\u65b9\u6cd5\u867d\u7136\u589e\u5f3a\u4e86\u63a8\u7406\u8fc7\u7a0b\uff0c\u4f46\u5ffd\u89c6\u4e86\u51b3\u7b56\u8fc7\u7a0b\u7684\u91cd\u8981\u6027\u3002\u8bed\u4e49\u76f8\u4f3c\u793a\u4f8b\u5e38\u5f15\u5165\u60c5\u611f\u5dee\u5f02\uff0c\u5bfc\u81f4\u8868\u793a\u4e0d\u51c6\u786e\u548c\u8bc6\u522b\u9519\u8bef\u3002", "method": "\u63d0\u51faEICL\u65b9\u6cd5\uff1a1) \u5f15\u5165\u60c5\u611f\u76f8\u4f3c\u793a\u4f8b\uff1b2) \u4f7f\u7528\u52a8\u6001\u8f6f\u6807\u7b7e\u7b56\u7565\u6539\u8fdb\u67e5\u8be2\u8868\u793a\uff1b3) \u91c7\u7528\u4e24\u9636\u6bb5\u6392\u9664\u7b56\u7565\u4ece\u591a\u89d2\u5ea6\u8bc4\u4f30\u76f8\u4f3c\u6027\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cEICL\u663e\u8457\u4f18\u4e8eICL\u65b9\u6cd5\u3002", "conclusion": "EICL\u901a\u8fc7\u4f18\u5316\u60c5\u611f\u63a8\u7406\u548c\u51b3\u7b56\u8fc7\u7a0b\uff0c\u6709\u6548\u89e3\u51b3\u4e86ICL\u5728\u7ec6\u7c92\u5ea6\u60c5\u611f\u8bc6\u522b\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5347\u4e86\u8bc6\u522b\u51c6\u786e\u6027\u3002"}}
{"id": "2510.06836", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.06836", "abs": "https://arxiv.org/abs/2510.06836", "authors": ["Jes\u00fas Bautista", "H\u00e9ctor Garc\u00eda de Marina"], "title": "Distributed 3D Source Seeking via SO(3) Geometric Control of Robot Swarms", "comment": "7 pages, 3 figures. Submitted for presentation at the IFAC World\n  Congress 2026", "summary": "This paper presents a geometric control framework on the Lie group SO(3) for\n3D source-seeking by robots with first-order attitude dynamics and constant\ntranslational speed. By working directly on SO(3), the approach avoids\nEuler-angle singularities and quaternion ambiguities, providing a unique,\nintrinsic representation of orientation. We design a proportional feed-forward\ncontroller that ensures exponential alignment of each agent to an estimated\nascending direction toward a 3D scalar field source. The controller adapts to\nbounded unknown variations and preserves well-posed swarm formations. Numerical\nsimulations demonstrate the effectiveness of the method, with all code provided\nopen source for reproducibility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728SO(3)\u674e\u7fa4\u4e0a\u7684\u51e0\u4f55\u63a7\u5236\u6846\u67b6\uff0c\u7528\u4e8e\u5177\u6709\u4e00\u9636\u59ff\u6001\u52a8\u529b\u5b66\u548c\u6052\u5b9a\u5e73\u79fb\u901f\u5ea6\u7684\u673a\u5668\u4eba\u8fdb\u884c3D\u6e90\u641c\u7d22\u3002", "motivation": "\u901a\u8fc7\u5728SO(3)\u4e0a\u76f4\u63a5\u5de5\u4f5c\uff0c\u907f\u514d\u4e86\u6b27\u62c9\u89d2\u5947\u5f02\u6027\u548c\u56db\u5143\u6570\u6b67\u4e49\u6027\uff0c\u63d0\u4f9b\u4e86\u552f\u4e00\u7684\u5185\u5728\u65b9\u5411\u8868\u793a\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6bd4\u4f8b\u524d\u9988\u63a7\u5236\u5668\uff0c\u786e\u4fdd\u6bcf\u4e2a\u667a\u80fd\u4f53\u4e0e\u4f30\u8ba1\u7684\u671d\u54113D\u6807\u91cf\u573a\u6e90\u7684\u4e0a\u5347\u65b9\u5411\u5448\u6307\u6570\u5bf9\u9f50\u3002\u63a7\u5236\u5668\u9002\u5e94\u6709\u754c\u672a\u77e5\u53d8\u5316\u5e76\u4fdd\u6301\u826f\u597d\u5f62\u6210\u7684\u7fa4\u4f53\u7f16\u961f\u3002", "result": "\u6570\u503c\u4eff\u771f\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u6240\u6709\u4ee3\u7801\u5f00\u6e90\u63d0\u4f9b\u4ee5\u786e\u4fdd\u53ef\u91cd\u73b0\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a3D\u6e90\u641c\u7d22\u63d0\u4f9b\u4e86\u9c81\u68d2\u4e14\u65e0\u5947\u5f02\u7684\u63a7\u5236\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u534f\u8c03\u641c\u7d22\u4efb\u52a1\u3002"}}
{"id": "2510.06674", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06674", "abs": "https://arxiv.org/abs/2510.06674", "authors": ["Cen", "Zhao", "Tiantian Zhang", "Hanchen Su", "Yufeng", "Zhang", "Shaowei Su", "Mingzhi Xu", "Yu", "Liu", "Wei Han", "Jeremy Werner", "Claire Na Cheng", "Yashar Mehdad"], "title": "Agent-in-the-Loop: A Data Flywheel for Continuous Improvement in LLM-based Customer Support", "comment": "EMNLP 2025 Industry Track submission (Paper #305). Preprint. Main\n  text within the 7-page industry limit (references/appendices excluded).\n  Contains multiple figures and tables", "summary": "We introduce an Agent-in-the-Loop (AITL) framework that implements a\ncontinuous data flywheel for iteratively improving an LLM-based customer\nsupport system. Unlike standard offline approaches that rely on batch\nannotations, AITL integrates four key types of annotations directly into live\ncustomer operations: (1) pairwise response preferences, (2) agent adoption and\nrationales, (3) knowledge relevance checks, and (4) identification of missing\nknowledge. These feedback signals seamlessly feed back into models' updates,\nreducing retraining cycles from months to weeks. Our production pilot involving\nUS-based customer support agents demonstrated significant improvements in\nretrieval accuracy (+11.7% recall@75, +14.8% precision@8), generation quality\n(+8.4% helpfulness) and agent adoption rates (+4.5%). These results underscore\nthe effectiveness of embedding human feedback loops directly into operational\nworkflows to continuously refine LLM-based customer support system.", "AI": {"tldr": "\u63d0\u51fa\u4e86Agent-in-the-Loop\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u56db\u79cd\u5b9e\u65f6\u53cd\u9988\u4fe1\u53f7\uff08\u54cd\u5e94\u504f\u597d\u3001\u4ee3\u7406\u91c7\u7eb3\u3001\u77e5\u8bc6\u76f8\u5173\u6027\u68c0\u67e5\u3001\u7f3a\u5931\u77e5\u8bc6\u8bc6\u522b\uff09\u6765\u6301\u7eed\u6539\u8fdb\u57fa\u4e8eLLM\u7684\u5ba2\u6237\u652f\u6301\u7cfb\u7edf\uff0c\u5c06\u91cd\u65b0\u8bad\u7ec3\u5468\u671f\u4ece\u6570\u6708\u7f29\u77ed\u81f3\u6570\u5468\u3002", "motivation": "\u4f20\u7edf\u7684\u79bb\u7ebf\u6279\u6ce8\u65b9\u6cd5\u4f9d\u8d56\u6279\u91cf\u6807\u6ce8\uff0c\u65e0\u6cd5\u5b9e\u65f6\u6539\u8fdbLLM\u5ba2\u6237\u652f\u6301\u7cfb\u7edf\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5c06\u4eba\u7c7b\u53cd\u9988\u76f4\u63a5\u5d4c\u5165\u64cd\u4f5c\u5de5\u4f5c\u6d41\u7a0b\u7684\u8fde\u7eed\u6539\u8fdb\u673a\u5236\u3002", "method": "AITL\u6846\u67b6\u6574\u5408\u56db\u79cd\u5b9e\u65f6\u53cd\u9988\u7c7b\u578b\uff1a\u54cd\u5e94\u504f\u597d\u914d\u5bf9\u3001\u4ee3\u7406\u91c7\u7eb3\u53ca\u7406\u7531\u3001\u77e5\u8bc6\u76f8\u5173\u6027\u68c0\u67e5\u3001\u7f3a\u5931\u77e5\u8bc6\u8bc6\u522b\uff0c\u8fd9\u4e9b\u4fe1\u53f7\u76f4\u63a5\u53cd\u9988\u5230\u6a21\u578b\u66f4\u65b0\u4e2d\u3002", "result": "\u751f\u4ea7\u8bd5\u70b9\u663e\u793a\u68c0\u7d22\u51c6\u786e\u7387\u663e\u8457\u63d0\u5347\uff08\u53ec\u56de\u7387+11.7%\uff0c\u7cbe\u786e\u7387+14.8%\uff09\uff0c\u751f\u6210\u8d28\u91cf\u63d0\u9ad8\uff08\u5e2e\u52a9\u6027+8.4%\uff09\uff0c\u4ee3\u7406\u91c7\u7eb3\u7387\u589e\u52a0\uff08+4.5%\uff09\u3002", "conclusion": "\u5c06\u4eba\u7c7b\u53cd\u9988\u5faa\u73af\u76f4\u63a5\u5d4c\u5165\u64cd\u4f5c\u5de5\u4f5c\u6d41\u7a0b\u80fd\u6709\u6548\u6301\u7eed\u6539\u8fdb\u57fa\u4e8eLLM\u7684\u5ba2\u6237\u652f\u6301\u7cfb\u7edf\uff0c\u8bc1\u660e\u4e86AITL\u6846\u67b6\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.07027", "categories": ["cs.RO", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2510.07027", "abs": "https://arxiv.org/abs/2510.07027", "authors": ["Saravana Prashanth Murali Babu", "Aida Parvaresh", "Ahmad Rafsanjani"], "title": "Tailoring materials into kirigami robots", "comment": null, "summary": "Kirigami, the traditional paper-cutting craft, holds immense potential for\nrevolutionizing robotics by providing multifunctional, lightweight, and\nadaptable solutions. Kirigami structures, characterized by their\nbending-dominated deformation, offer resilience to tensile forces and\nfacilitate shape morphing under small actuation forces. Kirigami components\nsuch as actuators, sensors, batteries, controllers, and body structures can be\ntailored to specific robotic applications by optimizing cut patterns. Actuators\nbased on kirigami principles exhibit complex motions programmable through\nvarious energy sources, while kirigami sensors bridge the gap between\nelectrical conductivity and compliance. Kirigami-integrated batteries enable\nenergy storage directly within robot structures, enhancing flexibility and\ncompactness. Kirigami-controlled mechanisms mimic mechanical computations,\nenabling advanced functionalities such as shape morphing and memory functions.\nApplications of kirigami-enabled robots include grasping, locomotion, and\nwearables, showcasing their adaptability to diverse environments and tasks.\nDespite promising opportunities, challenges remain in the design of cut\npatterns for a given function and streamlining fabrication techniques.", "AI": {"tldr": "Kirigami\u526a\u7eb8\u6280\u672f\u5728\u673a\u5668\u4eba\u9886\u57df\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u901a\u8fc7\u4f18\u5316\u5207\u5272\u56fe\u6848\u53ef\u5236\u9020\u591a\u529f\u80fd\u3001\u8f7b\u91cf\u5316\u7684\u673a\u5668\u4eba\u7ec4\u4ef6\uff0c\u5305\u62ec\u6267\u884c\u5668\u3001\u4f20\u611f\u5668\u3001\u7535\u6c60\u548c\u63a7\u5236\u5668\uff0c\u5e94\u7528\u4e8e\u6293\u53d6\u3001\u79fb\u52a8\u548c\u53ef\u7a7f\u6234\u8bbe\u5907\u7b49\u9886\u57df\u3002", "motivation": "\u5229\u7528Kirigami\u526a\u7eb8\u6280\u672f\u7684\u5f2f\u66f2\u4e3b\u5bfc\u53d8\u5f62\u7279\u6027\uff0c\u4e3a\u673a\u5668\u4eba\u63d0\u4f9b\u6297\u62c9\u4f38\u80fd\u529b\u548c\u5c0f\u9a71\u52a8\u529b\u4e0b\u7684\u5f62\u72b6\u53d8\u6362\u80fd\u529b\uff0c\u5f00\u53d1\u8f7b\u91cf\u5316\u3001\u9002\u5e94\u6027\u5f3a\u7684\u673a\u5668\u4eba\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u4f18\u5316\u5207\u5272\u56fe\u6848\u6765\u5b9a\u5236Kirigami\u7ec4\u4ef6\uff0c\u5305\u62ec\u57fa\u4e8eKirigami\u539f\u7406\u7684\u6267\u884c\u5668\u3001\u4f20\u611f\u5668\u3001\u7535\u6c60\u548c\u63a7\u5236\u5668\uff0c\u8fd9\u4e9b\u7ec4\u4ef6\u53ef\u901a\u8fc7\u4e0d\u540c\u80fd\u6e90\u9a71\u52a8\u5e76\u5b9e\u73b0\u590d\u6742\u8fd0\u52a8\u3002", "result": "Kirigami\u673a\u5668\u4eba\u7ec4\u4ef6\u5c55\u73b0\u51fa\u53ef\u7f16\u7a0b\u590d\u6742\u8fd0\u52a8\u3001\u7535\u5bfc\u6027\u4e0e\u67d4\u987a\u6027\u7684\u7ed3\u5408\u3001\u7ed3\u6784\u5185\u80fd\u91cf\u5b58\u50a8\u7b49\u7279\u6027\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u6293\u53d6\u3001\u79fb\u52a8\u548c\u53ef\u7a7f\u6234\u8bbe\u5907\u7b49\u573a\u666f\u3002", "conclusion": "Kirigami\u6280\u672f\u4e3a\u673a\u5668\u4eba\u9886\u57df\u63d0\u4f9b\u4e86\u9769\u547d\u6027\u7684\u591a\u529f\u80fd\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5728\u5207\u5272\u56fe\u6848\u8bbe\u8ba1\u548c\u5236\u9020\u5de5\u827a\u4f18\u5316\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\u3002"}}
{"id": "2510.06711", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06711", "abs": "https://arxiv.org/abs/2510.06711", "authors": ["Batu El", "Mert Yuksekgonul", "James Zou"], "title": "Inefficiencies of Meta Agents for Agent Design", "comment": null, "summary": "Recent works began to automate the design of agentic systems using\nmeta-agents that propose and iteratively refine new agent architectures. In\nthis paper, we examine three key challenges in a common class of meta-agents.\nFirst, we investigate how a meta-agent learns across iterations and find that\nsimply expanding the context with all previous agents, as proposed by previous\nworks, performs worse than ignoring prior designs entirely. We show that the\nperformance improves with an evolutionary approach. Second, although the\nmeta-agent designs multiple agents during training, it typically commits to a\nsingle agent at test time. We find that the designed agents have low behavioral\ndiversity, limiting the potential for their complementary use. Third, we assess\nwhen automated design is economically viable. We find that only in a few\ncases--specifically, two datasets--the overall cost of designing and deploying\nthe agents is lower than that of human-designed agents when deployed on over\n15,000 examples. In contrast, the performance gains for other datasets do not\njustify the design cost, regardless of scale.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5143\u4ee3\u7406\u81ea\u52a8\u8bbe\u8ba1\u4ee3\u7406\u7cfb\u7edf\u7684\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a\u8de8\u8fed\u4ee3\u5b66\u4e60\u673a\u5236\u3001\u884c\u4e3a\u591a\u6837\u6027\u4e0d\u8db3\u4ee5\u53ca\u7ecf\u6d4e\u53ef\u884c\u6027\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u5143\u4ee3\u7406\u81ea\u52a8\u8bbe\u8ba1\u4ee3\u7406\u7cfb\u7edf\u7684\u5174\u8d77\uff0c\u9700\u8981\u6df1\u5165\u7406\u89e3\u8fd9\u7c7b\u7cfb\u7edf\u7684\u5b9e\u9645\u6548\u679c\u548c\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u5b66\u4e60\u673a\u5236\u3001\u884c\u4e3a\u591a\u6837\u6027\u548c\u7ecf\u6d4e\u6210\u672c\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u5143\u4ee3\u7406\u5728\u4e0d\u540c\u8fed\u4ee3\u7b56\u7565\u4e0b\u7684\u5b66\u4e60\u6548\u679c\uff0c\u8bc4\u4f30\u8bbe\u8ba1\u4ee3\u7406\u7684\u884c\u4e3a\u591a\u6837\u6027\uff0c\u5e76\u8ba1\u7b97\u81ea\u52a8\u5316\u8bbe\u8ba1\u4e0e\u4eba\u5de5\u8bbe\u8ba1\u7684\u6210\u672c\u6548\u76ca\u6bd4\u3002", "result": "\u53d1\u73b0\u6269\u5c55\u4e0a\u4e0b\u6587\u5305\u542b\u6240\u6709\u5148\u524d\u4ee3\u7406\u7684\u65b9\u6cd5\u8868\u73b0\u4e0d\u5982\u5ffd\u7565\u5148\u524d\u8bbe\u8ba1\uff1b\u8fdb\u5316\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\uff1b\u8bbe\u8ba1\u7684\u4ee3\u7406\u884c\u4e3a\u591a\u6837\u6027\u4f4e\uff1b\u4ec5\u5728\u5c11\u6570\u6570\u636e\u96c6\u4e0a\u81ea\u52a8\u5316\u8bbe\u8ba1\u5728\u7ecf\u6d4e\u4e0a\u53ef\u884c\u3002", "conclusion": "\u5f53\u524d\u5143\u4ee3\u7406\u81ea\u52a8\u8bbe\u8ba1\u7cfb\u7edf\u5728\u8de8\u8fed\u4ee3\u5b66\u4e60\u3001\u884c\u4e3a\u591a\u6837\u6027\u548c\u7ecf\u6d4e\u53ef\u884c\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff0c\u9700\u8981\u6539\u8fdb\u5b66\u4e60\u673a\u5236\u548c\u591a\u6837\u6027\u7b56\u7565\u624d\u80fd\u5b9e\u73b0\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2510.07028", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07028", "abs": "https://arxiv.org/abs/2510.07028", "authors": ["Sicong Pan", "Xuying Huang", "Maren Bennewitz"], "title": "Temporal-Prior-Guided View Planning for Periodic 3D Plant Reconstruction", "comment": "Accepted to the Active Perception Workshop at IROS 2025", "summary": "Periodic 3D reconstruction is essential for crop monitoring, but costly when\neach cycle restarts from scratch, wasting resources and ignoring information\nfrom previous captures. We propose temporal-prior-guided view planning for\nperiodic plant reconstruction, in which a previously reconstructed model of the\nsame plant is non-rigidly aligned to a new partial observation to form an\napproximation of the current geometry. To accommodate plant growth, we inflate\nthis approximation and solve a set covering optimization problem to compute a\nminimal set of views. We integrated this method into a complete pipeline that\nacquires one additional next-best view before registration for robustness and\nthen plans a globally shortest path to connect the planned set of views and\noutputs the best view sequence. Experiments on maize and tomato under\nhemisphere and sphere view spaces show that our system maintains or improves\nsurface coverage while requiring fewer views and comparable movement cost\ncompared to state-of-the-art baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65f6\u95f4\u5148\u9a8c\u7684\u5468\u671f\u6027\u690d\u7269\u4e09\u7ef4\u91cd\u5efa\u89c6\u56fe\u89c4\u5212\u65b9\u6cd5\uff0c\u5229\u7528\u5148\u524d\u91cd\u5efa\u6a21\u578b\u6307\u5bfc\u5f53\u524d\u91cd\u5efa\u8fc7\u7a0b\uff0c\u51cf\u5c11\u89c6\u56fe\u6570\u91cf\u548c\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u5468\u671f\u60273D\u91cd\u5efa\u5bf9\u4f5c\u7269\u76d1\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u6bcf\u6b21\u4ece\u5934\u5f00\u59cb\u91cd\u5efa\u6d6a\u8d39\u8d44\u6e90\u4e14\u5ffd\u7565\u5386\u53f2\u4fe1\u606f\u3002", "method": "\u5c06\u5148\u524d\u91cd\u5efa\u6a21\u578b\u975e\u521a\u6027\u5bf9\u9f50\u5230\u65b0\u89c2\u6d4b\u6570\u636e\u5f62\u6210\u51e0\u4f55\u8fd1\u4f3c\uff0c\u901a\u8fc7\u81a8\u80c0\u9002\u5e94\u690d\u7269\u751f\u957f\uff0c\u6c42\u89e3\u96c6\u5408\u8986\u76d6\u4f18\u5316\u95ee\u9898\u8ba1\u7b97\u6700\u5c0f\u89c6\u56fe\u96c6\uff0c\u96c6\u6210\u5b8c\u6574\u7ba1\u9053\u5305\u62ec\u989d\u5916\u6700\u4f73\u89c6\u56fe\u83b7\u53d6\u548c\u5168\u5c40\u6700\u77ed\u8def\u5f84\u89c4\u5212\u3002", "result": "\u5728\u7389\u7c73\u548c\u756a\u8304\u4e0a\u7684\u534a\u7403\u548c\u7403\u4f53\u89c6\u56fe\u7a7a\u95f4\u5b9e\u9a8c\u4e2d\uff0c\u7cfb\u7edf\u5728\u4fdd\u6301\u6216\u6539\u5584\u8868\u9762\u8986\u76d6\u7387\u7684\u540c\u65f6\uff0c\u6240\u9700\u89c6\u56fe\u6570\u91cf\u66f4\u5c11\uff0c\u79fb\u52a8\u6210\u672c\u4e0e\u6700\u5148\u8fdb\u57fa\u7ebf\u76f8\u5f53\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5229\u7528\u65f6\u95f4\u5148\u9a8c\u4fe1\u606f\uff0c\u663e\u8457\u51cf\u5c11\u5468\u671f\u6027\u690d\u7269\u91cd\u5efa\u6240\u9700\u7684\u89c6\u56fe\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u91cd\u5efa\u8d28\u91cf\u3002"}}
{"id": "2510.06742", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.06742", "abs": "https://arxiv.org/abs/2510.06742", "authors": ["Ali Sarabadani", "Kheirolah Rahsepar Fard"], "title": "MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease Knowledge Graphs Using Large Language Models", "comment": null, "summary": "The advent of large language models (LLMs) has revolutionized the integration\nof knowledge graphs (KGs) in biomedical and cognitive sciences, overcoming\nlimitations in traditional machine learning methods for capturing intricate\nsemantic links among genes, diseases, and cognitive processes. We introduce\nMultiCNKG, an innovative framework that merges three key knowledge sources: the\nCognitive Neuroscience Knowledge Graph (CNKG) with 2.9K nodes and 4.3K edges\nacross 9 node types and 20 edge types; Gene Ontology (GO) featuring 43K nodes\nand 75K edges in 3 node types and 4 edge types; and Disease Ontology (DO)\ncomprising 11.2K nodes and 8.8K edges with 1 node type and 2 edge types.\nLeveraging LLMs like GPT-4, we conduct entity alignment, semantic similarity\ncomputation, and graph augmentation to create a cohesive KG that interconnects\ngenetic mechanisms, neurological disorders, and cognitive functions. The\nresulting MultiCNKG encompasses 6.9K nodes across 5 types (e.g., Genes,\nDiseases, Cognitive Processes) and 11.3K edges spanning 7 types (e.g., Causes,\nAssociated with, Regulates), facilitating a multi-layered view from molecular\nto behavioral domains. Assessments using metrics such as precision (85.20%),\nrecall (87.30%), coverage (92.18%), graph consistency (82.50%), novelty\ndetection (40.28%), and expert validation (89.50%) affirm its robustness and\ncoherence. Link prediction evaluations with models like TransE (MR: 391, MRR:\n0.411) and RotatE (MR: 263, MRR: 0.395) show competitive performance against\nbenchmarks like FB15k-237 and WN18RR. This KG advances applications in\npersonalized medicine, cognitive disorder diagnostics, and hypothesis\nformulation in cognitive neuroscience.", "AI": {"tldr": "MultiCNKG\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u77e5\u8bc6\u56fe\u8c31\u6846\u67b6\uff0c\u6574\u5408\u4e86\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u77e5\u8bc6\u56fe\u8c31\u3001\u57fa\u56e0\u672c\u4f53\u548c\u75be\u75c5\u672c\u4f53\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u4f53\u5bf9\u9f50\u548c\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8ba1\u7b97\uff0c\u6784\u5efa\u4e86\u8fde\u63a5\u57fa\u56e0\u673a\u5236\u3001\u795e\u7ecf\u7cfb\u7edf\u75be\u75c5\u548c\u8ba4\u77e5\u529f\u80fd\u7684\u7edf\u4e00\u77e5\u8bc6\u56fe\u8c31\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u6355\u6349\u57fa\u56e0\u3001\u75be\u75c5\u548c\u8ba4\u77e5\u8fc7\u7a0b\u4e4b\u95f4\u590d\u6742\u8bed\u4e49\u8054\u7cfb\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6574\u5408\u591a\u6e90\u77e5\u8bc6\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f18\u52bf\u7684\u65b0\u6846\u67b6\u3002", "method": "\u6574\u5408\u4e09\u4e2a\u5173\u952e\u77e5\u8bc6\u6e90\uff08CNKG\u3001GO\u3001DO\uff09\uff0c\u5229\u7528GPT-4\u7b49\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u4f53\u5bf9\u9f50\u3001\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u548c\u56fe\u589e\u5f3a\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u8de8\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u3002", "result": "\u6784\u5efa\u7684MultiCNKG\u5305\u542b6.9K\u4e2a\u8282\u70b9\u548c11.3K\u6761\u8fb9\uff0c\u5728\u7cbe\u5ea6\uff0885.20%\uff09\u3001\u53ec\u56de\u7387\uff0887.30%\uff09\u3001\u8986\u76d6\u7387\uff0892.18%\uff09\u7b49\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u94fe\u63a5\u9884\u6d4b\u6027\u80fd\u4e0e\u57fa\u51c6\u6570\u636e\u96c6\u76f8\u5f53\u3002", "conclusion": "\u8be5\u77e5\u8bc6\u56fe\u8c31\u63a8\u52a8\u4e86\u7cbe\u51c6\u533b\u7597\u3001\u8ba4\u77e5\u969c\u788d\u8bca\u65ad\u548c\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u5047\u8bbe\u751f\u6210\u7b49\u5e94\u7528\uff0c\u4e3a\u4ece\u5206\u5b50\u5230\u884c\u4e3a\u5c42\u9762\u7684\u591a\u5c42\u7ea7\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2510.07030", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07030", "abs": "https://arxiv.org/abs/2510.07030", "authors": ["Abhinav Kumar", "Fan Yang", "Sergio Aguilera Marinovic", "Soshi Iba", "Rana Soltani Zarrin", "Dmitry Berenson"], "title": "Diffusing Trajectory Optimization Problems for Recovery During Multi-Finger Manipulation", "comment": null, "summary": "Multi-fingered hands are emerging as powerful platforms for performing fine\nmanipulation tasks, including tool use. However, environmental perturbations or\nexecution errors can impede task performance, motivating the use of recovery\nbehaviors that enable normal task execution to resume. In this work, we take\nadvantage of recent advances in diffusion models to construct a framework that\nautonomously identifies when recovery is necessary and optimizes contact-rich\ntrajectories to recover. We use a diffusion model trained on the task to\nestimate when states are not conducive to task execution, framed as an\nout-of-distribution detection problem. We then use diffusion sampling to\nproject these states in-distribution and use trajectory optimization to plan\ncontact-rich recovery trajectories. We also propose a novel diffusion-based\napproach that distills this process to efficiently diffuse the full\nparameterization, including constraints, goal state, and initialization, of the\nrecovery trajectory optimization problem, saving time during online execution.\nWe compare our method to a reinforcement learning baseline and other methods\nthat do not explicitly plan contact interactions, including on a hardware\nscrewdriver-turning task where we show that recovering using our method\nimproves task performance by 96% and that ours is the only method evaluated\nthat can attempt recovery without causing catastrophic task failure. Videos can\nbe found at https://dtourrecovery.github.io/.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6062\u590d\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u6307\u624b\u5728\u6267\u884c\u7cbe\u7ec6\u64cd\u4f5c\u4efb\u52a1\u65f6\u81ea\u4e3b\u68c0\u6d4b\u5f02\u5e38\u72b6\u6001\u5e76\u89c4\u5212\u63a5\u89e6\u4e30\u5bcc\u7684\u6062\u590d\u8f68\u8ff9", "motivation": "\u591a\u6307\u624b\u5728\u6267\u884c\u7cbe\u7ec6\u64cd\u4f5c\u4efb\u52a1\u65f6\uff0c\u73af\u5883\u6270\u52a8\u6216\u6267\u884c\u9519\u8bef\u4f1a\u5f71\u54cd\u4efb\u52a1\u6027\u80fd\uff0c\u9700\u8981\u6062\u590d\u884c\u4e3a\u6765\u6062\u590d\u6b63\u5e38\u4efb\u52a1\u6267\u884c", "method": "\u4f7f\u7528\u6269\u6563\u6a21\u578b\u68c0\u6d4b\u4efb\u52a1\u6267\u884c\u4e0d\u987a\u5229\u7684\u72b6\u6001\uff08OOD\u68c0\u6d4b\uff09\uff0c\u901a\u8fc7\u6269\u6563\u91c7\u6837\u5c06\u72b6\u6001\u6295\u5f71\u56de\u5206\u5e03\u5185\uff0c\u5e76\u7528\u8f68\u8ff9\u4f18\u5316\u89c4\u5212\u63a5\u89e6\u4e30\u5bcc\u7684\u6062\u590d\u8f68\u8ff9\u3002\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6269\u6563\u65b9\u6cd5\uff0c\u5728\u5728\u7ebf\u6267\u884c\u65f6\u9ad8\u6548\u6269\u6563\u6062\u590d\u8f68\u8ff9\u4f18\u5316\u95ee\u9898\u7684\u5b8c\u6574\u53c2\u6570\u5316", "result": "\u4e0e\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\u548c\u5176\u4ed6\u4e0d\u663e\u5f0f\u89c4\u5212\u63a5\u89e6\u4ea4\u4e92\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u786c\u4ef6\u87ba\u4e1d\u5200\u8f6c\u52a8\u4efb\u52a1\u4e2d\uff0c\u4f7f\u7528\u8be5\u65b9\u6cd5\u6062\u590d\u53ef\u5c06\u4efb\u52a1\u6027\u80fd\u63d0\u9ad896%\uff0c\u5e76\u4e14\u662f\u552f\u4e00\u80fd\u5728\u4e0d\u5bfc\u81f4\u707e\u96be\u6027\u4efb\u52a1\u5931\u8d25\u7684\u60c5\u51b5\u4e0b\u5c1d\u8bd5\u6062\u590d\u7684\u65b9\u6cd5", "conclusion": "\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6062\u590d\u6846\u67b6\u80fd\u591f\u6709\u6548\u8bc6\u522b\u5f02\u5e38\u72b6\u6001\u5e76\u89c4\u5212\u63a5\u89e6\u4e30\u5bcc\u7684\u6062\u590d\u8f68\u8ff9\uff0c\u663e\u8457\u63d0\u9ad8\u591a\u6307\u624b\u5728\u7cbe\u7ec6\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd"}}
{"id": "2510.06756", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06756", "abs": "https://arxiv.org/abs/2510.06756", "authors": ["Dennis Gross", "Helge Spieker", "Arnaud Gotlieb"], "title": "Verifying Memoryless Sequential Decision-making of Large Language Models", "comment": null, "summary": "We introduce a tool for rigorous and automated verification of large language\nmodel (LLM)- based policies in memoryless sequential decision-making tasks.\nGiven a Markov decision process (MDP) representing the sequential\ndecision-making task, an LLM policy, and a safety requirement expressed as a\nPCTL formula, our approach incrementally constructs only the reachable portion\nof the MDP guided by the LLM's chosen actions. Each state is encoded as a\nnatural language prompt, the LLM's response is parsed into an action, and\nreachable successor states by the policy are expanded. The resulting formal\nmodel is checked with Storm to determine whether the policy satisfies the\nspecified safety property. In experiments on standard grid world benchmarks, we\nshow that open source LLMs accessed via Ollama can be verified when\ndeterministically seeded, but generally underperform deep reinforcement\nlearning baselines. Our tool natively integrates with Ollama and supports\nPRISM-specified tasks, enabling continuous benchmarking in user-specified\nsequential decision-making tasks and laying a practical foundation for formally\nverifying increasingly capable LLMs.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u7528\u4e8e\u9a8c\u8bc1\u57fa\u4e8eLLM\u7684\u7b56\u7565\u5728\u65e0\u8bb0\u5fc6\u987a\u5e8f\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u901a\u8fc7\u589e\u91cf\u6784\u5efaMDP\u6a21\u578b\u5e76\u4f7f\u7528Storm\u6a21\u578b\u68c0\u67e5\u5668\u9a8c\u8bc1PCTL\u5b89\u5168\u5c5e\u6027\u3002", "motivation": "\u968f\u7740LLM\u5728\u987a\u5e8f\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981\u786e\u4fdd\u8fd9\u4e9b\u7b56\u7565\u6ee1\u8db3\u5b89\u5168\u8981\u6c42\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9LLM\u7b56\u7565\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u80fd\u529b\u3002", "method": "\u7ed9\u5b9aMDP\u3001LLM\u7b56\u7565\u548cPCTL\u5b89\u5168\u8981\u6c42\uff0c\u589e\u91cf\u6784\u5efa\u53ef\u8fbe\u7684MDP\u72b6\u6001\uff0c\u5c06\u72b6\u6001\u7f16\u7801\u4e3a\u81ea\u7136\u8bed\u8a00\u63d0\u793a\uff0c\u89e3\u6790LLM\u54cd\u5e94\u4e3a\u52a8\u4f5c\uff0c\u5e76\u4f7f\u7528Storm\u6a21\u578b\u68c0\u67e5\u5668\u9a8c\u8bc1\u5b89\u5168\u5c5e\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5f00\u6e90LLM\u5728\u786e\u5b9a\u6027\u79cd\u5b50\u4e0b\u53ef\u88ab\u9a8c\u8bc1\uff0c\u4f46\u6027\u80fd\u901a\u5e38\u4f4e\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\u3002\u5de5\u5177\u4e0eOllama\u548cPRISM\u96c6\u6210\uff0c\u652f\u6301\u7528\u6237\u6307\u5b9a\u7684\u987a\u5e8f\u51b3\u7b56\u4efb\u52a1\u3002", "conclusion": "\u8be5\u5de5\u5177\u4e3a\u9a8c\u8bc1\u65e5\u76ca\u5f3a\u5927\u7684LLM\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\uff0c\u652f\u6301\u5728\u987a\u5e8f\u51b3\u7b56\u4efb\u52a1\u4e2d\u8fdb\u884c\u6301\u7eed\u57fa\u51c6\u6d4b\u8bd5\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002"}}
{"id": "2510.07067", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07067", "abs": "https://arxiv.org/abs/2510.07067", "authors": ["Daria Pugacheva", "Andrey Moskalenko", "Denis Shepelev", "Andrey Kuznetsov", "Vlad Shakhuro", "Elena Tutubalina"], "title": "Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models", "comment": null, "summary": "Vision Language Action (VLA) models are widely used in Embodied AI, enabling\nrobots to interpret and execute language instructions. However, their\nrobustness to natural language variability in real-world scenarios has not been\nthoroughly investigated. In this work, we present a novel systematic study of\nthe robustness of state-of-the-art VLA models under linguistic perturbations.\nSpecifically, we evaluate model performance under two types of instruction\nnoise: (1) human-generated paraphrasing and (2) the addition of irrelevant\ncontext. We further categorize irrelevant contexts into two groups according to\ntheir length and their semantic and lexical proximity to robot commands. In\nthis study, we observe consistent performance degradation as context size\nexpands. We also demonstrate that the model can exhibit relative robustness to\nrandom context, with a performance drop within 10%, while semantically and\nlexically similar context of the same length can trigger a quality decline of\naround 50%. Human paraphrases of instructions lead to a drop of nearly 20%. To\nmitigate this, we propose an LLM-based filtering framework that extracts core\ncommands from noisy inputs. Incorporating our filtering step allows models to\nrecover up to 98.5% of their original performance under noisy conditions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c(VLA)\u6a21\u578b\u5bf9\u8bed\u8a00\u6270\u52a8\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u8bed\u4e49\u548c\u8bcd\u6c47\u76f8\u4f3c\u7684\u65e0\u76f8\u5173\u4e0a\u4e0b\u6587\u4e0b\u6027\u80fd\u4e0b\u964d\u7ea650%\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u8fc7\u6ee4\u6846\u67b6\u6765\u6062\u590d\u6027\u80fd\u3002", "motivation": "VLA\u6a21\u578b\u5728\u5177\u8eabAI\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u9762\u5bf9\u81ea\u7136\u8bed\u8a00\u53d8\u5f02\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u5bf9\u8bed\u8a00\u6270\u52a8\u7684\u654f\u611f\u6027\u3002", "method": "\u8bc4\u4f30VLA\u6a21\u578b\u5728\u4e24\u79cd\u6307\u4ee4\u566a\u58f0\u4e0b\u7684\u6027\u80fd\uff1a(1)\u4eba\u5de5\u751f\u6210\u7684\u6539\u5199\u6307\u4ee4\uff1b(2)\u6dfb\u52a0\u65e0\u76f8\u5173\u4e0a\u4e0b\u6587\u3002\u8fdb\u4e00\u6b65\u5c06\u65e0\u76f8\u5173\u4e0a\u4e0b\u6587\u6309\u957f\u5ea6\u3001\u8bed\u4e49\u548c\u8bcd\u6c47\u76f8\u4f3c\u5ea6\u5206\u7c7b\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u8fc7\u6ee4\u6846\u67b6\u63d0\u53d6\u6838\u5fc3\u547d\u4ee4\u3002", "result": "\u6a21\u578b\u6027\u80fd\u968f\u4e0a\u4e0b\u6587\u6269\u5c55\u800c\u6301\u7eed\u4e0b\u964d\uff1b\u5bf9\u968f\u673a\u4e0a\u4e0b\u6587\u76f8\u5bf9\u9c81\u68d2(\u6027\u80fd\u4e0b\u964d<10%)\uff0c\u4f46\u5bf9\u8bed\u4e49\u8bcd\u6c47\u76f8\u4f3c\u7684\u4e0a\u4e0b\u6587\u6027\u80fd\u4e0b\u964d\u7ea650%\uff1b\u4eba\u5de5\u6539\u5199\u6307\u4ee4\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u8fd120%\uff1b\u63d0\u51fa\u7684\u8fc7\u6ee4\u6846\u67b6\u53ef\u4f7f\u6a21\u578b\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u6062\u590d\u9ad8\u8fbe98.5%\u7684\u539f\u59cb\u6027\u80fd\u3002", "conclusion": "VLA\u6a21\u578b\u5bf9\u8bed\u8a00\u6270\u52a8\u654f\u611f\uff0c\u7279\u522b\u662f\u8bed\u4e49\u76f8\u4f3c\u7684\u65e0\u5173\u4e0a\u4e0b\u6587\u4f1a\u663e\u8457\u5f71\u54cd\u6027\u80fd\uff0c\u4f46\u901a\u8fc7LLM\u8fc7\u6ee4\u6846\u67b6\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u9ad8\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.06761", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.06761", "abs": "https://arxiv.org/abs/2510.06761", "authors": ["Zhi Zhang", "Yan Liu", "Zhejing Hu", "Gong Chen", "Sheng-hua Zhong", "Jiannong Cao"], "title": "Evolving and Executing Research Plans via Double-Loop Multi-Agent Collaboration", "comment": null, "summary": "Automating the end-to-end scientific research process poses a fundamental\nchallenge: it requires both evolving high-level plans that are novel and sound,\nand executing these plans correctly amidst dynamic and uncertain conditions. To\naddress this bilevel challenge, we propose a novel Double-Loop Multi-Agent\n(DLMA) framework to solve the given research problem automatically. The leader\nloop, composed of professor agents, is responsible for evolving research plans.\nIt employs an evolutionary algorithm through involvement, improvement, and\nintegration meetings to iteratively generate and refine a pool of research\nproposals, exploring the solution space effectively. The follower loop,\ncomposed of doctoral student agents, is responsible for executing the\nbest-evolved plan. It dynamically adjusts the plan during implementation via\npre-hoc and post-hoc meetings, ensuring each step (e.g., drafting, coding) is\nwell-supported by contextual and external observations. Extensive experiments\non benchmarks like ACLAward and Laboratory show that DLMA generates research\npapers that achieve state-of-the-art scores in automated evaluation,\nsignificantly outperforming strong baselines. Ablation studies confirm the\ncritical roles of both loops, with evolution driving novelty and execution\nensuring soundness.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u5faa\u73af\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff08DLMA\uff09\u6765\u81ea\u52a8\u5316\u7aef\u5230\u7aef\u79d1\u5b66\u7814\u7a76\u8fc7\u7a0b\uff0c\u901a\u8fc7\u6559\u6388\u667a\u80fd\u4f53\u7684\u9886\u5bfc\u5faa\u73af\u8fdb\u5316\u7814\u7a76\u8ba1\u5212\uff0c\u535a\u58eb\u5b66\u751f\u667a\u80fd\u4f53\u7684\u8ddf\u968f\u5faa\u73af\u6267\u884c\u6700\u4f73\u8ba1\u5212\uff0c\u5728ACLAward\u548cLaboratory\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u81ea\u52a8\u5316\u7aef\u5230\u7aef\u79d1\u5b66\u7814\u7a76\u8fc7\u7a0b\u9762\u4e34\u53cc\u91cd\u6311\u6218\uff1a\u9700\u8981\u751f\u6210\u65b0\u9896\u4e14\u5408\u7406\u7684\u9ad8\u5c42\u8ba1\u5212\uff0c\u5e76\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u6761\u4ef6\u4e0b\u6b63\u786e\u6267\u884c\u8fd9\u4e9b\u8ba1\u5212\u3002", "method": "DLMA\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u5faa\u73af\uff1a\u9886\u5bfc\u5faa\u73af\u4f7f\u7528\u8fdb\u5316\u7b97\u6cd5\u901a\u8fc7\u53c2\u4e0e\u3001\u6539\u8fdb\u548c\u6574\u5408\u4f1a\u8bae\u8fed\u4ee3\u751f\u6210\u548c\u4f18\u5316\u7814\u7a76\u63d0\u6848\u6c60\uff1b\u8ddf\u968f\u5faa\u73af\u901a\u8fc7\u4e8b\u524d\u548c\u4e8b\u540e\u4f1a\u8bae\u52a8\u6001\u8c03\u6574\u8ba1\u5212\u6267\u884c\uff0c\u786e\u4fdd\u6bcf\u4e2a\u6b65\u9aa4\u5f97\u5230\u4e0a\u4e0b\u6587\u548c\u5916\u90e8\u89c2\u5bdf\u7684\u652f\u6301\u3002", "result": "\u5728ACLAward\u548cLaboratory\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDLMA\u751f\u6210\u7684\u7814\u7a76\u8bba\u6587\u5728\u81ea\u52a8\u8bc4\u4f30\u4e2d\u83b7\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e86\u4e24\u4e2a\u5faa\u73af\u7684\u5173\u952e\u4f5c\u7528\uff1a\u8fdb\u5316\u9a71\u52a8\u65b0\u9896\u6027\uff0c\u6267\u884c\u786e\u4fdd\u5408\u7406\u6027\uff0cDLMA\u6210\u529f\u89e3\u51b3\u4e86\u79d1\u5b66\u7814\u7a76\u81ea\u52a8\u5316\u7684\u53cc\u5c42\u6311\u6218\u3002"}}
{"id": "2510.07077", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.07077", "abs": "https://arxiv.org/abs/2510.07077", "authors": ["Kento Kawaharazuka", "Jihoon Oh", "Jun Yamada", "Ingmar Posner", "Yuke Zhu"], "title": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications", "comment": "Accepted to IEEE Access, website: https://vla-survey.github.io", "summary": "Amid growing efforts to leverage advances in large language models (LLMs) and\nvision-language models (VLMs) for robotics, Vision-Language-Action (VLA) models\nhave recently gained significant attention. By unifying vision, language, and\naction data at scale, which have traditionally been studied separately, VLA\nmodels aim to learn policies that generalise across diverse tasks, objects,\nembodiments, and environments. This generalisation capability is expected to\nenable robots to solve novel downstream tasks with minimal or no additional\ntask-specific data, facilitating more flexible and scalable real-world\ndeployment. Unlike previous surveys that focus narrowly on action\nrepresentations or high-level model architectures, this work offers a\ncomprehensive, full-stack review, integrating both software and hardware\ncomponents of VLA systems. In particular, this paper provides a systematic\nreview of VLAs, covering their strategy and architectural transition,\narchitectures and building blocks, modality-specific processing techniques, and\nlearning paradigms. In addition, to support the deployment of VLAs in\nreal-world robotic applications, we also review commonly used robot platforms,\ndata collection strategies, publicly available datasets, data augmentation\nmethods, and evaluation benchmarks. Throughout this comprehensive survey, this\npaper aims to offer practical guidance for the robotics community in applying\nVLAs to real-world robotic systems. All references categorized by training\napproach, evaluation method, modality, and dataset are available in the table\non our project website: https://vla-survey.github.io .", "AI": {"tldr": "\u672c\u6587\u5bf9\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c(VLA)\u6a21\u578b\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u6db5\u76d6\u8f6f\u4ef6\u548c\u786c\u4ef6\u7ec4\u4ef6\uff0c\u65e8\u5728\u4e3a\u673a\u5668\u4eba\u793e\u533a\u63d0\u4f9b\u5b9e\u9645\u5e94\u7528\u6307\u5bfc\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u673a\u5668\u4eba\u9886\u57df\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0cVLA\u6a21\u578b\u901a\u8fc7\u7edf\u4e00\u89c6\u89c9\u3001\u8bed\u8a00\u548c\u52a8\u4f5c\u6570\u636e\uff0c\u65e8\u5728\u5b66\u4e60\u80fd\u591f\u6cdb\u5316\u5230\u591a\u6837\u5316\u4efb\u52a1\u3001\u5bf9\u8c61\u3001\u73af\u5883\u548c\u4f53\u73b0\u5f62\u5f0f\u7684\u7b56\u7565\uff0c\u5b9e\u73b0\u66f4\u7075\u6d3b\u548c\u53ef\u6269\u5c55\u7684\u673a\u5668\u4eba\u90e8\u7f72\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u7684\u5168\u6808\u5f0f\u7efc\u8ff0\u65b9\u6cd5\uff0c\u6574\u5408VLA\u7cfb\u7edf\u7684\u8f6f\u4ef6\u548c\u786c\u4ef6\u7ec4\u4ef6\uff0c\u6db5\u76d6\u7b56\u7565\u548c\u67b6\u6784\u8f6c\u6362\u3001\u67b6\u6784\u548c\u6784\u5efa\u6a21\u5757\u3001\u6a21\u6001\u7279\u5b9a\u5904\u7406\u6280\u672f\u3001\u5b66\u4e60\u8303\u5f0f\uff0c\u4ee5\u53ca\u673a\u5668\u4eba\u5e73\u53f0\u3001\u6570\u636e\u6536\u96c6\u7b56\u7565\u3001\u6570\u636e\u96c6\u3001\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u548c\u8bc4\u4f30\u57fa\u51c6\u3002", "result": "\u63d0\u4f9b\u4e86VLA\u6a21\u578b\u7684\u5168\u9762\u6280\u672f\u7efc\u8ff0\uff0c\u5305\u62ec\u8bad\u7ec3\u65b9\u6cd5\u3001\u8bc4\u4f30\u65b9\u6cd5\u3001\u6a21\u6001\u548c\u6570\u636e\u96c6\u7b49\u5206\u7c7b\u53c2\u8003\uff0c\u6240\u6709\u53c2\u8003\u8d44\u6599\u53ef\u5728\u9879\u76ee\u7f51\u7ad9\u83b7\u53d6\u3002", "conclusion": "\u672c\u7efc\u8ff0\u4e3a\u673a\u5668\u4eba\u793e\u533a\u5728\u5b9e\u9645\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u5e94\u7528VLA\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u4fc3\u8fdb\u4e86VLA\u6280\u672f\u5728\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u3002"}}
{"id": "2510.06857", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06857", "abs": "https://arxiv.org/abs/2510.06857", "authors": ["Qi Guo", "Jianing Wang", "Jianfei Zhang", "Deyang Kong", "Xiangzhou Huang", "Xiangyu Xi", "Wei Wang", "Jingang Wang", "Xunliang Cai", "Shikun Zhang", "Wei Ye"], "title": "Autoformalizer with Tool Feedback", "comment": null, "summary": "Autoformalization addresses the scarcity of data for Automated Theorem\nProving (ATP) by translating mathematical problems from natural language into\nformal statements. Efforts in recent work shift from directly prompting large\nlanguage models to training an end-to-end formalizer model from scratch,\nachieving remarkable advancements. However, existing formalizer still struggles\nto consistently generate valid statements that meet syntactic validity and\nsemantic consistency. To address this issue, we propose the Autoformalizer with\nTool Feedback (ATF), a novel approach that incorporates syntactic and\nconsistency information as tools into the formalization process. By integrating\nLean 4 compilers for syntax corrections and employing a multi-LLMs-as-judge\napproach for consistency validation, the model is able to adaptively refine\ngenerated statements according to the tool feedback, enhancing both syntactic\nvalidity and semantic consistency. The training of ATF involves a cold-start\nphase on synthetic tool-calling data, an expert iteration phase to improve\nformalization capabilities, and Direct Preference Optimization to alleviate\nineffective revisions. Experimental results show that ATF markedly outperforms\na range of baseline formalizer models, with its superior performance further\nvalidated by human evaluations. Subsequent analysis reveals that ATF\ndemonstrates excellent inference scaling properties. Moreover, we open-source\nNumina-ATF, a dataset containing 750K synthetic formal statements to facilitate\nadvancements in autoformalization and ATP research.", "AI": {"tldr": "\u63d0\u51fa\u4e86ATF\u65b9\u6cd5\uff0c\u901a\u8fc7\u96c6\u6210\u8bed\u6cd5\u68c0\u67e5\u548c\u4e00\u81f4\u6027\u9a8c\u8bc1\u5de5\u5177\u6765\u6539\u8fdb\u81ea\u52a8\u5f62\u5f0f\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f62\u5f0f\u5316\u8bed\u53e5\u7684\u8bed\u6cd5\u6709\u6548\u6027\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u5f62\u5f0f\u5316\u65b9\u6cd5\u5728\u751f\u6210\u8bed\u6cd5\u6709\u6548\u4e14\u8bed\u4e49\u4e00\u81f4\u7684\u8bed\u53e5\u65b9\u9762\u4ecd\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u6539\u8fdb\u81ea\u52a8\u5f62\u5f0f\u5316\u7684\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3002", "method": "ATF\u65b9\u6cd5\u6574\u5408Lean 4\u7f16\u8bd1\u5668\u8fdb\u884c\u8bed\u6cd5\u4fee\u6b63\uff0c\u91c7\u7528\u591aLLM\u5224\u65ad\u8fdb\u884c\u4e00\u81f4\u6027\u9a8c\u8bc1\uff0c\u901a\u8fc7\u5de5\u5177\u53cd\u9988\u81ea\u9002\u5e94\u4f18\u5316\u751f\u6210\u8bed\u53e5\u3002\u8bad\u7ec3\u8fc7\u7a0b\u5305\u62ec\u51b7\u542f\u52a8\u3001\u4e13\u5bb6\u8fed\u4ee3\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u4e09\u4e2a\u9636\u6bb5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eATF\u660e\u663e\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u4eba\u7c7b\u8bc4\u4f30\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\uff0c\u4e14\u5c55\u73b0\u51fa\u826f\u597d\u7684\u63a8\u7406\u6269\u5c55\u7279\u6027\u3002", "conclusion": "ATF\u901a\u8fc7\u5de5\u5177\u53cd\u9988\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86\u81ea\u52a8\u5f62\u5f0f\u5316\u7684\u8d28\u91cf\uff0c\u5f00\u6e90\u7684\u6570\u636e\u96c6Numina-ATF\u5c06\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2510.07094", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07094", "abs": "https://arxiv.org/abs/2510.07094", "authors": ["David Rytz", "Kim Tien Ly", "Ioannis Havoutis"], "title": "Sampling Strategies for Robust Universal Quadrupedal Locomotion Policies", "comment": null, "summary": "This work focuses on sampling strategies of configuration variations for\ngenerating robust universal locomotion policies for quadrupedal robots. We\ninvestigate the effects of sampling physical robot parameters and joint\nproportional-derivative gains to enable training a single reinforcement\nlearning policy that generalizes to multiple parameter configurations. Three\nfundamental joint gain sampling strategies are compared: parameter sampling\nwith (1) linear and polynomial function mappings of mass-to-gains, (2)\nperformance-based adaptive filtering, and (3) uniform random sampling. We\nimprove the robustness of the policy by biasing the configurations using\nnominal priors and reference models. All training was conducted on RaiSim,\ntested in simulation on a range of diverse quadrupeds, and zero-shot deployed\nonto hardware using the ANYmal quadruped robot. Compared to multiple baseline\nimplementations, our results demonstrate the need for significant joint\ncontroller gains randomization for robust closing of the sim-to-real gap.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u4e09\u79cd\u5173\u8282\u589e\u76ca\u91c7\u6837\u7b56\u7565\uff0c\u7528\u4e8e\u8bad\u7ec3\u80fd\u591f\u6cdb\u5316\u5230\u591a\u79cd\u53c2\u6570\u914d\u7f6e\u7684\u901a\u7528\u56db\u8db3\u673a\u5668\u4eba\u8fd0\u52a8\u7b56\u7565\uff0c\u901a\u8fc7\u663e\u8457\u968f\u673a\u5316\u5173\u8282\u63a7\u5236\u5668\u589e\u76ca\u6765\u589e\u5f3a\u7b56\u7565\u7684\u9c81\u68d2\u6027\u5e76\u7f29\u5c0f\u4eff\u771f\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u9002\u5e94\u591a\u79cd\u7269\u7406\u53c2\u6570\u914d\u7f6e\u7684\u9c81\u68d2\u901a\u7528\u56db\u8db3\u673a\u5668\u4eba\u8fd0\u52a8\u7b56\u7565\uff0c\u89e3\u51b3\u4eff\u771f\u5230\u73b0\u5b9e\u90e8\u7f72\u4e2d\u7684\u6cdb\u5316\u95ee\u9898\u3002", "method": "\u6bd4\u8f83\u4e86\u4e09\u79cd\u5173\u8282\u589e\u76ca\u91c7\u6837\u7b56\u7565\uff1a(1) \u8d28\u91cf\u5230\u589e\u76ca\u7684\u7ebf\u6027\u548c\u591a\u9879\u5f0f\u51fd\u6570\u6620\u5c04\uff1b(2) \u57fa\u4e8e\u6027\u80fd\u7684\u81ea\u9002\u5e94\u6ee4\u6ce2\uff1b(3) \u5747\u5300\u968f\u673a\u91c7\u6837\u3002\u901a\u8fc7\u4f7f\u7528\u540d\u4e49\u5148\u9a8c\u548c\u53c2\u8003\u6a21\u578b\u504f\u7f6e\u914d\u7f6e\u6765\u589e\u5f3a\u7b56\u7565\u9c81\u68d2\u6027\u3002\u5728RaiSim\u4e2d\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u5728\u591a\u79cd\u56db\u8db3\u673a\u5668\u4eba\u4e0a\u8fdb\u884c\u4eff\u771f\u6d4b\u8bd5\u3002", "result": "\u4e0e\u591a\u4e2a\u57fa\u7ebf\u5b9e\u73b0\u76f8\u6bd4\uff0c\u7ed3\u679c\u8868\u660e\u9700\u8981\u663e\u8457\u968f\u673a\u5316\u5173\u8282\u63a7\u5236\u5668\u589e\u76ca\u624d\u80fd\u5b9e\u73b0\u9c81\u68d2\u7684\u4eff\u771f\u5230\u73b0\u5b9e\u5dee\u8ddd\u7f29\u5c0f\u3002\u7b56\u7565\u6210\u529f\u96f6\u6837\u672c\u90e8\u7f72\u5230ANYmal\u56db\u8db3\u673a\u5668\u4eba\u786c\u4ef6\u4e0a\u3002", "conclusion": "\u5173\u8282\u63a7\u5236\u5668\u589e\u76ca\u7684\u663e\u8457\u968f\u673a\u5316\u5bf9\u4e8e\u5b9e\u73b0\u9c81\u68d2\u7684\u4eff\u771f\u5230\u73b0\u5b9e\u5dee\u8ddd\u7f29\u5c0f\u81f3\u5173\u91cd\u8981\uff0c\u6240\u63d0\u51fa\u7684\u91c7\u6837\u7b56\u7565\u80fd\u591f\u6709\u6548\u8bad\u7ec3\u51fa\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u901a\u7528\u8fd0\u52a8\u7b56\u7565\u3002"}}
{"id": "2510.06878", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06878", "abs": "https://arxiv.org/abs/2510.06878", "authors": ["Daria Ozerova", "Ekaterina Trofimova"], "title": "TGPR: Tree-Guided Policy Refinement for Robust Self-Debugging of LLMs", "comment": null, "summary": "Iterative refinement has been a promising paradigm to enable large language\nmodels (LLMs) to resolve difficult reasoning and problem-solving tasks. One of\nthe key challenges, however, is how to effectively search through the enormous\nsearch space of possible refinements. Existing methods typically fall back on\npredefined heuristics, which are troubled by the exploration-exploitation\ndilemma and cannot adapt based on past refinement outcomes. We introduce\nTree-Guided Policy Refinement (TGPR), a novel framework that combines GRPO with\na Thompson-Sampling-based tree search. TGPR explores both failed and successful\nrefinement paths actively, with denser training trajectories and more adaptive\npolicies. On HumanEval, MBPP, and APPS benchmarks, our method achieves up to\n+4.2 percentage points absolute improvement in pass@1 (on MBPP) and up to\n+12.51 percentage points absolute improvement in pass@10 (on APPS) compared to\na competitive GRPO baseline. Apart from debugging code, TGPR focuses on a\nprincipled approach to combining learned policies with structured search\nmethods, offering a general framework for enhancing iterative refinement and\nstateful reasoning in LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86Tree-Guided Policy Refinement (TGPR)\u6846\u67b6\uff0c\u7ed3\u5408GRPO\u548cThompson\u91c7\u6837\u6811\u641c\u7d22\uff0c\u901a\u8fc7\u4e3b\u52a8\u63a2\u7d22\u5931\u8d25\u548c\u6210\u529f\u7684\u7cbe\u5316\u8def\u5f84\u6765\u6539\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8fed\u4ee3\u7cbe\u5316\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fed\u4ee3\u7cbe\u5316\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7684\u641c\u7d22\u7a7a\u95f4\u5de8\u5927\u95ee\u9898\uff0c\u73b0\u6709\u57fa\u4e8e\u9884\u5b9a\u4e49\u542f\u53d1\u5f0f\u7684\u65b9\u6cd5\u5b58\u5728\u63a2\u7d22-\u5229\u7528\u56f0\u5883\u4e14\u65e0\u6cd5\u6839\u636e\u8fc7\u53bb\u7ed3\u679c\u81ea\u9002\u5e94\u8c03\u6574\u3002", "method": "TGPR\u6846\u67b6\u7ed3\u5408GRPO\uff08\u53ef\u80fd\u6307\u67d0\u79cd\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u4f18\u5316\uff09\u548c\u57fa\u4e8eThompson\u91c7\u6837\u7684\u6811\u641c\u7d22\uff0c\u901a\u8fc7\u5bc6\u96c6\u8bad\u7ec3\u8f68\u8ff9\u548c\u81ea\u9002\u5e94\u7b56\u7565\u6765\u63a2\u7d22\u7cbe\u5316\u8def\u5f84\u3002", "result": "\u5728HumanEval\u3001MBPP\u548cAPPS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4GRPO\u57fa\u7ebf\uff0cpass@1\u5728MBPP\u4e0a\u63d0\u53474.2\u4e2a\u767e\u5206\u70b9\uff0cpass@10\u5728APPS\u4e0a\u63d0\u534712.51\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "TGPR\u4e3a\u589e\u5f3aLLMs\u7684\u8fed\u4ee3\u7cbe\u5316\u548c\u72b6\u6001\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u6846\u67b6\uff0c\u5c06\u5b66\u4e60\u7b56\u7565\u4e0e\u7ed3\u6784\u5316\u641c\u7d22\u65b9\u6cd5\u76f8\u7ed3\u5408\u3002"}}
{"id": "2510.07133", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07133", "abs": "https://arxiv.org/abs/2510.07133", "authors": ["Tony Zhang", "Burak Kantarci", "Umair Siddique"], "title": "A Digital Twin Framework for Metamorphic Testing of Autonomous Driving Systems Using Generative Model", "comment": null, "summary": "Ensuring the safety of self-driving cars remains a major challenge due to the\ncomplexity and unpredictability of real-world driving environments. Traditional\ntesting methods face significant limitations, such as the oracle problem, which\nmakes it difficult to determine whether a system's behavior is correct, and the\ninability to cover the full range of scenarios an autonomous vehicle may\nencounter. In this paper, we introduce a digital twin-driven metamorphic\ntesting framework that addresses these challenges by creating a virtual replica\nof the self-driving system and its operating environment. By combining digital\ntwin technology with AI-based image generative models such as Stable Diffusion,\nour approach enables the systematic generation of realistic and diverse driving\nscenes. This includes variations in weather, road topology, and environmental\nfeatures, all while maintaining the core semantics of the original scenario.\nThe digital twin provides a synchronized simulation environment where changes\ncan be tested in a controlled and repeatable manner. Within this environment,\nwe define three metamorphic relations inspired by real-world traffic rules and\nvehicle behavior. We validate our framework in the Udacity self-driving\nsimulator and demonstrate that it significantly enhances test coverage and\neffectiveness. Our method achieves the highest true positive rate (0.719), F1\nscore (0.689), and precision (0.662) compared to baseline approaches. This\npaper highlights the value of integrating digital twins with AI-powered\nscenario generation to create a scalable, automated, and high-fidelity testing\nsolution for autonomous vehicle safety.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u7684\u8715\u53d8\u6d4b\u8bd5\u6846\u67b6\uff0c\u7ed3\u5408AI\u56fe\u50cf\u751f\u6210\u6280\u672f\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u521b\u5efa\u865a\u62df\u6d4b\u8bd5\u73af\u5883\uff0c\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u6d4b\u8bd5\u65b9\u6cd5\u5728\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u9a8c\u8bc1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5305\u62ec\u9884\u8a00\u673a\u95ee\u9898\u548c\u65e0\u6cd5\u8986\u76d6\u6240\u6709\u771f\u5b9e\u573a\u666f\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528\u6570\u5b57\u5b6a\u751f\u6280\u672f\u521b\u5efa\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u865a\u62df\u526f\u672c\uff0c\u7ed3\u5408Stable Diffusion\u7b49AI\u56fe\u50cf\u751f\u6210\u6a21\u578b\uff0c\u7cfb\u7edf\u751f\u6210\u591a\u6837\u5316\u9a7e\u9a76\u573a\u666f\uff0c\u5b9a\u4e49\u57fa\u4e8e\u4ea4\u901a\u89c4\u5219\u7684\u4e09\u79cd\u8715\u53d8\u5173\u7cfb\u3002", "result": "\u5728Udacity\u81ea\u52a8\u9a7e\u9a76\u6a21\u62df\u5668\u4e2d\u9a8c\u8bc1\uff0c\u83b7\u5f97\u6700\u9ad8\u771f\u9633\u6027\u7387(0.719)\u3001F1\u5206\u6570(0.689)\u548c\u7cbe\u786e\u7387(0.662)\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6570\u5b57\u5b6a\u751f\u4e0eAI\u573a\u666f\u751f\u6210\u7684\u7ed3\u5408\u4e3a\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u81ea\u52a8\u5316\u4e14\u9ad8\u4fdd\u771f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.06911", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.06911", "abs": "https://arxiv.org/abs/2510.06911", "authors": ["Hacane Hechehouche", "Andre Antakli", "Matthias Klusch"], "title": "LLM-Assisted Modeling of Semantic Web-Enabled Multi-Agents Systems with AJAN", "comment": null, "summary": "There are many established semantic Web standards for implementing\nmulti-agent driven applications. The AJAN framework allows to engineer\nmulti-agent systems based on these standards. In particular, agent knowledge is\nrepresented in RDF/RDFS and OWL, while agent behavior models are defined with\nBehavior Trees and SPARQL to access and manipulate this knowledge. However, the\nappropriate definition of RDF/RDFS and SPARQL-based agent behaviors still\nremains a major hurdle not only for agent modelers in practice. For example,\ndealing with URIs is very error-prone regarding typos and dealing with complex\nSPARQL queries in large-scale environments requires a high learning curve. In\nthis paper, we present an integrated development environment to overcome such\nhurdles of modeling AJAN agents and at the same time to extend the user\ncommunity for AJAN by the possibility to leverage Large Language Models for\nagent engineering.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u5f00\u53d1\u73af\u5883\u6765\u89e3\u51b3AJAN\u6846\u67b6\u4e2dRDF/RDFS\u548cSPARQL\u5efa\u6a21\u7684\u56f0\u96be\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u7528\u6237\u7fa4\u4f53", "motivation": "\u73b0\u6709\u7684AJAN\u6846\u67b6\u4e2d\uff0c\u4f7f\u7528RDF/RDFS\u548cSPARQL\u5b9a\u4e49\u667a\u80fd\u4f53\u884c\u4e3a\u5b58\u5728\u5f88\u5927\u969c\u788d\uff0c\u5305\u62ecURI\u5904\u7406\u5bb9\u6613\u51fa\u9519\u3001\u590d\u6742SPARQL\u67e5\u8be2\u5b66\u4e60\u66f2\u7ebf\u9ad8\u7b49\u95ee\u9898", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u96c6\u6210\u5f00\u53d1\u73af\u5883\uff0c\u901a\u8fc7\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6765\u7b80\u5316AJAN\u667a\u80fd\u4f53\u7684\u5efa\u6a21\u8fc7\u7a0b", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u80fd\u591f\u964d\u4f4e\u5efa\u6a21\u96be\u5ea6\u5e76\u6269\u5c55\u7528\u6237\u7fa4\u4f53\u7684\u5f00\u53d1\u73af\u5883", "conclusion": "\u8be5\u96c6\u6210\u5f00\u53d1\u73af\u5883\u6709\u6548\u89e3\u51b3\u4e86AJAN\u6846\u67b6\u4e2d\u7684\u5efa\u6a21\u969c\u788d\uff0c\u5e76\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u6280\u672f\u6269\u5927\u4e86\u6846\u67b6\u7684\u9002\u7528\u6027"}}
{"id": "2510.07134", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.07134", "abs": "https://arxiv.org/abs/2510.07134", "authors": ["Jiahang Liu", "Yunpeng Qi", "Jiazhao Zhang", "Minghan Li", "Shaoan Wang", "Kui Wu", "Hanjing Ye", "Hong Zhang", "Zhibo Chen", "Fangwei Zhong", "Zhizheng Zhang", "He Wang"], "title": "TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking", "comment": "Project page: https://pku-epic.github.io/TrackVLA-plus-plus-Web/", "summary": "Embodied Visual Tracking (EVT) is a fundamental ability that underpins\npractical applications, such as companion robots, guidance robots and service\nassistants, where continuously following moving targets is essential. Recent\nadvances have enabled language-guided tracking in complex and unstructured\nscenes. However, existing approaches lack explicit spatial reasoning and\neffective temporal memory, causing failures under severe occlusions or in the\npresence of similar-looking distractors. To address these challenges, we\npresent TrackVLA++, a novel Vision-Language-Action (VLA) model that enhances\nembodied visual tracking with two key modules, a spatial reasoning mechanism\nand a Target Identification Memory (TIM). The reasoning module introduces a\nChain-of-Thought paradigm, termed Polar-CoT, which infers the target's relative\nposition and encodes it as a compact polar-coordinate token for action\nprediction. Guided by these spatial priors, the TIM employs a gated update\nstrategy to preserve long-horizon target memory, ensuring spatiotemporal\nconsistency and mitigating target loss during extended occlusions. Extensive\nexperiments show that TrackVLA++ achieves state-of-the-art performance on\npublic benchmarks across both egocentric and multi-camera settings. On the\nchallenging EVT-Bench DT split, TrackVLA++ surpasses the previous leading\napproach by 5.1 and 12, respectively. Furthermore, TrackVLA++ exhibits strong\nzero-shot generalization, enabling robust real-world tracking in dynamic and\noccluded scenarios.", "AI": {"tldr": "TrackVLA++\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff0c\u901a\u8fc7\u7a7a\u95f4\u63a8\u7406\u673a\u5236\u548c\u76ee\u6807\u8bc6\u522b\u8bb0\u5fc6\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5177\u8eab\u89c6\u89c9\u8ddf\u8e2a\u5728\u906e\u6321\u548c\u5e72\u6270\u573a\u666f\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u8a00\u5f15\u5bfc\u8ddf\u8e2a\u65b9\u6cd5\u7f3a\u4e4f\u660e\u786e\u7684\u7a7a\u95f4\u63a8\u7406\u548c\u6709\u6548\u7684\u65f6\u95f4\u8bb0\u5fc6\uff0c\u5bfc\u81f4\u5728\u4e25\u91cd\u906e\u6321\u6216\u5b58\u5728\u76f8\u4f3c\u5e72\u6270\u7269\u65f6\u5bb9\u6613\u5931\u8d25\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u5173\u952e\u6a21\u5757\uff1a1) \u7a7a\u95f4\u63a8\u7406\u673a\u5236(Polar-CoT)\uff0c\u901a\u8fc7\u601d\u7ef4\u94fe\u8303\u5f0f\u63a8\u65ad\u76ee\u6807\u76f8\u5bf9\u4f4d\u7f6e\u5e76\u7f16\u7801\u4e3a\u6781\u5750\u6807\u4ee4\u724c\uff1b2) \u76ee\u6807\u8bc6\u522b\u8bb0\u5fc6(TIM)\uff0c\u91c7\u7528\u95e8\u63a7\u66f4\u65b0\u7b56\u7565\u4fdd\u6301\u957f\u671f\u76ee\u6807\u8bb0\u5fc6\u3002", "result": "\u5728\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728EVT-Bench DT\u5206\u5272\u4e0a\u5206\u522b\u8d85\u8fc7\u4e4b\u524d\u9886\u5148\u65b9\u6cd55.1\u548c12\u4e2a\u767e\u5206\u70b9\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "TrackVLA++\u901a\u8fc7\u7ed3\u5408\u7a7a\u95f4\u63a8\u7406\u548c\u957f\u671f\u8bb0\u5fc6\uff0c\u80fd\u591f\u5b9e\u73b0\u52a8\u6001\u548c\u906e\u6321\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u5b9e\u65f6\u8ddf\u8e2a\uff0c\u4e3a\u5177\u8eab\u89c6\u89c9\u8ddf\u8e2a\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.06953", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.06953", "abs": "https://arxiv.org/abs/2510.06953", "authors": ["Minju Gwak", "Guijin Son", "Jaehyung Kim"], "title": "Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces", "comment": null, "summary": "The Uniform Information Density (UID) hypothesis suggests that effective\ncommunication maintains a stable flow of information. In this work, we revisit\nthis principle in the context of large language model (LLM) reasoning traces,\nasking whether step-level uniformity reflects reasoning quality. To this end,\nwe propose an entropy-based stepwise information density metric and introduce\ntwo complementary measures of uniformity, local and global uniformity scores.\nAcross the experiments on six different reasoning benchmarks, we find that\nstep-level uniformity not only provides a strong theoretical lens but also\nyields practical performance benefits; for example, selecting reasoning traces\nwith more uniform information density at the step-level improves accuracy by\n10-32\\% relative gains over baselines at AIME2025. Our analysis further reveals\nthat correct reasoning traces tend to avoid sharp information density spikes,\nwhile incorrect traces exhibit irregular information bursts. These results\ndemonstrate that UID-inspired information density measures outperform\nalternative internal signals as predictors of reasoning quality. Results\nhighlight the uniformity of the information density as a robust diagnostic and\nselection criterion for building more reliable and accurate reasoning systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9a8c\u8bc1\u4e86\u7edf\u4e00\u4fe1\u606f\u5bc6\u5ea6(UID)\u5047\u8bbe\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u6b65\u9aa4\u7ea7\u4fe1\u606f\u5bc6\u5ea6\u5747\u5300\u6027\u80fd\u591f\u6709\u6548\u9884\u6d4b\u63a8\u7406\u8d28\u91cf\uff0c\u5e76\u53ef\u4f5c\u4e3a\u9009\u62e9\u9ad8\u8d28\u91cf\u63a8\u7406\u8f68\u8ff9\u7684\u6807\u51c6\u3002", "motivation": "\u63a2\u7d22\u7edf\u4e00\u4fe1\u606f\u5bc6\u5ea6\u5047\u8bbe\u662f\u5426\u9002\u7528\u4e8eLLM\u63a8\u7406\u8fc7\u7a0b\uff0c\u9a8c\u8bc1\u6b65\u9aa4\u7ea7\u4fe1\u606f\u5bc6\u5ea6\u5747\u5300\u6027\u662f\u5426\u80fd\u53cd\u6620\u63a8\u7406\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u71b5\u7684\u6b65\u9aa4\u7ea7\u4fe1\u606f\u5bc6\u5ea6\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5f15\u5165\u5c40\u90e8\u548c\u5168\u5c40\u5747\u5300\u6027\u8bc4\u5206\uff0c\u5728\u516d\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u6b65\u9aa4\u7ea7\u4fe1\u606f\u5bc6\u5ea6\u5747\u5300\u6027\u4e0d\u4ec5\u80fd\u63d0\u4f9b\u7406\u8bba\u89c6\u89d2\uff0c\u8fd8\u5177\u6709\u5b9e\u9645\u6027\u80fd\u4f18\u52bf\uff1a\u9009\u62e9\u4fe1\u606f\u5bc6\u5ea6\u66f4\u5747\u5300\u7684\u63a8\u7406\u8f68\u8ff9\u53ef\u4f7fAIME2025\u51c6\u786e\u7387\u76f8\u5bf9\u63d0\u534710-32%\u3002\u6b63\u786e\u63a8\u7406\u8f68\u8ff9\u907f\u514d\u4fe1\u606f\u5bc6\u5ea6\u5c16\u5cf0\uff0c\u9519\u8bef\u8f68\u8ff9\u5219\u5448\u73b0\u4e0d\u89c4\u5219\u4fe1\u606f\u7206\u53d1\u3002", "conclusion": "UID\u542f\u53d1\u7684\u4fe1\u606f\u5bc6\u5ea6\u5ea6\u91cf\u4f18\u4e8e\u5176\u4ed6\u5185\u90e8\u4fe1\u53f7\uff0c\u53ef\u4f5c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u3001\u51c6\u786e\u63a8\u7406\u7cfb\u7edf\u7684\u8bca\u65ad\u548c\u9009\u62e9\u6807\u51c6\u3002"}}
{"id": "2510.07152", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07152", "abs": "https://arxiv.org/abs/2510.07152", "authors": ["Jingkai Sun", "Gang Han", "Pihai Sun", "Wen Zhao", "Jiahang Cao", "Jiaxu Wang", "Yijie Guo", "Qiang Zhang"], "title": "DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction", "comment": null, "summary": "Recent advancements in legged robot perceptive locomotion have shown\npromising progress. However, terrain-aware humanoid locomotion remains largely\nconstrained to two paradigms: depth image-based end-to-end learning and\nelevation map-based methods. The former suffers from limited training\nefficiency and a significant sim-to-real gap in depth perception, while the\nlatter depends heavily on multiple vision sensors and localization systems,\nresulting in latency and reduced robustness. To overcome these challenges, we\npropose a novel framework that tightly integrates three key components: (1)\nTerrain-Aware Locomotion Policy with a Blind Backbone, which leverages\npre-trained elevation map-based perception to guide reinforcement learning with\nminimal visual input; (2) Multi-Modality Cross-Attention Transformer, which\nreconstructs structured terrain representations from noisy depth images; (3)\nRealistic Depth Images Synthetic Method, which employs self-occlusion-aware ray\ncasting and noise-aware modeling to synthesize realistic depth observations,\nachieving over 30\\% reduction in terrain reconstruction error. This combination\nenables efficient policy training with limited data and hardware resources,\nwhile preserving critical terrain features essential for generalization. We\nvalidate our framework on a full-sized humanoid robot, demonstrating agile and\nadaptive locomotion across diverse and challenging terrains.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u76f2\u4e3b\u5e72\u5730\u5f62\u611f\u77e5\u8fd0\u52a8\u7b56\u7565\u3001\u591a\u6a21\u6001\u4ea4\u53c9\u6ce8\u610f\u529b\u53d8\u6362\u5668\u548c\u771f\u5b9e\u6df1\u5ea6\u56fe\u50cf\u5408\u6210\u65b9\u6cd5\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u4eba\u5f62\u673a\u5668\u4eba\u5730\u5f62\u611f\u77e5\u8fd0\u52a8\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u5730\u5f62\u611f\u77e5\u4eba\u5f62\u673a\u5668\u4eba\u8fd0\u52a8\u65b9\u6cd5\u5b58\u5728\u8bad\u7ec3\u6548\u7387\u4f4e\u3001sim-to-real\u5dee\u8ddd\u5927\u3001\u4f9d\u8d56\u591a\u4f20\u611f\u5668\u5bfc\u81f4\u5ef6\u8fdf\u548c\u9c81\u68d2\u6027\u5dee\u7b49\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u9ad8\u7a0b\u5730\u56fe\u611f\u77e5\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u4ea4\u53c9\u6ce8\u610f\u529b\u53d8\u6362\u5668\u4ece\u566a\u58f0\u6df1\u5ea6\u56fe\u50cf\u91cd\u5efa\u5730\u5f62\u8868\u793a\uff0c\u5e76\u91c7\u7528\u81ea\u906e\u6321\u611f\u77e5\u5149\u7ebf\u6295\u5c04\u548c\u566a\u58f0\u611f\u77e5\u5efa\u6a21\u5408\u6210\u771f\u5b9e\u6df1\u5ea6\u56fe\u50cf\u3002", "result": "\u5b9e\u73b0\u4e86\u8d85\u8fc730%\u7684\u5730\u5f62\u91cd\u5efa\u8bef\u5dee\u51cf\u5c11\uff0c\u5728\u5b8c\u6574\u5c3a\u5bf8\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u5c55\u793a\u4e86\u5728\u591a\u6837\u5316\u6311\u6218\u6027\u5730\u5f62\u4e0a\u7684\u654f\u6377\u81ea\u9002\u5e94\u8fd0\u52a8\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u5728\u6709\u9650\u6570\u636e\u548c\u786c\u4ef6\u8d44\u6e90\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7b56\u7565\u8bad\u7ec3\uff0c\u540c\u65f6\u4fdd\u7559\u5bf9\u6cdb\u5316\u81f3\u5173\u91cd\u8981\u7684\u5173\u952e\u5730\u5f62\u7279\u5f81\u3002"}}
{"id": "2510.07038", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07038", "abs": "https://arxiv.org/abs/2510.07038", "authors": ["Wenxun Wu", "Yuanyang Li", "Guhan Chen", "Linyue Wang", "Hongyang Chen"], "title": "Tool-Augmented Policy Optimization: Synergizing Reasoning and Adaptive Tool Use with Reinforcement Learning", "comment": null, "summary": "Recent advances in large language models (LLMs) have popularized test-time\nscaling, where models generate additional reasoning tokens before producing\nfinal answers. These approaches have demonstrated significant performance\nimprovements on benchmarks involving mathematical reasoning. However, language\nmodels relying solely on direct inference still struggle with tasks demanding\nup-to-date knowledge or computational tools such as calculators and code\ninterpreters for complex arithmetic operations. To overcome these limitations,\nwe propose Tool-Augmented Policy Optimization (TAPO), a novel reinforcement\nlearning framework that systematically integrates multi-hop reasoning with\nadaptive tool-calling capabilities. Our approach employs a modified version of\nDynamic Sampling Policy Optimization (DAPO), a recently developed RL paradigm,\nwhich we adapt specifically for tool invocation scenarios, enabling models to\ndynamically interleave complex reasoning with on-demand tool usage (including\nsearch APIs and Python interpreters).\n  To support this research, we introduce two new datasets: TAPO-easy-60K and\nTAPO-hard-18K, specifically designed to train and evaluate both fact-based\nreasoning and mathematical calculation capabilities. Our experiments on\nQwen2.5-3B and Qwen2.5-7B models demonstrate the effectiveness of our approach,\nwith both models achieving state-of-the-art performance on tasks requiring\nexternal knowledge and mathematical computation among methods with comparable\nparameters. Notably, TAPO achieves more efficient tool utilization than\nbaseline methods while preventing excessive calls caused by reward hacking.\nThese results highlight the significant potential of combining advanced\nreasoning with tool usage to enhance model performance in knowledge-intensive\nand computationally demanding tasks.", "AI": {"tldr": "\u63d0\u51faTAPO\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5c06\u591a\u8df3\u63a8\u7406\u4e0e\u81ea\u9002\u5e94\u5de5\u5177\u8c03\u7528\u80fd\u529b\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3LLMs\u5728\u9700\u8981\u6700\u65b0\u77e5\u8bc6\u6216\u8ba1\u7b97\u5de5\u5177\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u4ec5\u4f9d\u8d56\u76f4\u63a5\u63a8\u7406\u96be\u4ee5\u5904\u7406\u9700\u8981\u6700\u65b0\u77e5\u8bc6\u6216\u8ba1\u7b97\u5de5\u5177\uff08\u5982\u8ba1\u7b97\u5668\u3001\u4ee3\u7801\u89e3\u91ca\u5668\uff09\u7684\u4efb\u52a1\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u7b97\u672f\u8fd0\u7b97\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "\u4f7f\u7528\u6539\u8fdb\u7684Dynamic Sampling Policy Optimization (DAPO)\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u5de5\u5177\u8c03\u7528\u573a\u666f\u8fdb\u884c\u9002\u914d\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u52a8\u6001\u5730\u5728\u590d\u6742\u63a8\u7406\u4e0e\u6309\u9700\u5de5\u5177\u4f7f\u7528\u4e4b\u95f4\u5207\u6362\u3002", "result": "\u5728Qwen2.5-3B\u548cQwen2.5-7B\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5728\u9700\u8981\u5916\u90e8\u77e5\u8bc6\u548c\u6570\u5b66\u8ba1\u7b97\u7684\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86\u540c\u7c7b\u53c2\u6570\u65b9\u6cd5\u4e2d\u7684\u6700\u4f18\u6027\u80fd\uff0c\u4e14\u5de5\u5177\u4f7f\u7528\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u7ed3\u5408\u5148\u8fdb\u63a8\u7406\u4e0e\u5de5\u5177\u4f7f\u7528\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u548c\u8ba1\u7b97\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5177\u6709\u91cd\u8981\u6f5c\u529b\u3002"}}
{"id": "2510.07160", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07160", "abs": "https://arxiv.org/abs/2510.07160", "authors": ["Fengze Xie", "Xiaozhou Fan", "Jacob Schuster", "Yisong Yue", "Morteza Gharib"], "title": "A Narwhal-Inspired Sensing-to-Control Framework for Small Fixed-Wing Aircraft", "comment": null, "summary": "Fixed-wing unmanned aerial vehicles (UAVs) offer endurance and efficiency but\nlack low-speed agility due to highly coupled dynamics. We present an end-to-end\nsensing-to-control pipeline that combines bio-inspired hardware,\nphysics-informed dynamics learning, and convex control allocation. Measuring\nairflow on a small airframe is difficult because near-body aerodynamics,\npropeller slipstream, control-surface actuation, and ambient gusts distort\npressure signals. Inspired by the narwhal's protruding tusk, we mount in-house\nmulti-hole probes far upstream and complement them with sparse, carefully\nplaced wing pressure sensors for local flow measurement. A data-driven\ncalibration maps probe pressures to airspeed and flow angles. We then learn a\ncontrol-affine dynamics model using the estimated airspeed/angles and sparse\nsensors. A soft left/right symmetry regularizer improves identifiability under\npartial observability and limits confounding between wing pressures and\nflaperon inputs. Desired wrenches (forces and moments) are realized by a\nregularized least-squares allocator that yields smooth, trimmed actuation.\nWind-tunnel studies across a wide operating range show that adding wing\npressures reduces force-estimation error by 25-30%, the proposed model degrades\nless under distribution shift (about 12% versus 44% for an unstructured\nbaseline), and force tracking improves with smoother inputs, including a 27%\nreduction in normal-force RMSE versus a plain affine model and 34% versus an\nunstructured baseline.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4eff\u751f\u786c\u4ef6\u3001\u7269\u7406\u4fe1\u606f\u52a8\u529b\u5b66\u5b66\u4e60\u548c\u51f8\u63a7\u5236\u5206\u914d\u7684\u7aef\u5230\u7aef\u611f\u77e5\u63a7\u5236\u7ba1\u9053\uff0c\u7528\u4e8e\u63d0\u5347\u56fa\u5b9a\u7ffc\u65e0\u4eba\u673a\u7684\u4f4e\u901f\u654f\u6377\u6027\u3002", "motivation": "\u56fa\u5b9a\u7ffc\u65e0\u4eba\u673a\u867d\u7136\u7eed\u822a\u548c\u6548\u7387\u4f18\u5f02\uff0c\u4f46\u7531\u4e8e\u9ad8\u5ea6\u8026\u5408\u7684\u52a8\u529b\u5b66\u7279\u6027\uff0c\u5728\u4f4e\u901f\u65f6\u7f3a\u4e4f\u654f\u6377\u6027\u3002\u6d4b\u91cf\u5c0f\u578b\u673a\u67b6\u4e0a\u7684\u6c14\u6d41\u5f88\u56f0\u96be\uff0c\u56e0\u4e3a\u8fd1\u4f53\u7a7a\u6c14\u52a8\u529b\u5b66\u3001\u87ba\u65cb\u6868\u6ed1\u6d41\u3001\u63a7\u5236\u9762\u4f5c\u52a8\u548c\u73af\u5883\u9635\u98ce\u4f1a\u626d\u66f2\u538b\u529b\u4fe1\u53f7\u3002", "method": "1. \u4eff\u751f\u786c\u4ef6\u8bbe\u8ba1\uff1a\u53d7\u72ec\u89d2\u9cb8\u957f\u7259\u542f\u53d1\uff0c\u5728\u524d\u65b9\u5b89\u88c5\u81ea\u5236\u591a\u5b54\u63a2\u9488\uff0c\u5e76\u8f85\u4ee5\u7a00\u758f\u5206\u5e03\u7684\u673a\u7ffc\u538b\u529b\u4f20\u611f\u5668\uff1b2. \u6570\u636e\u9a71\u52a8\u6821\u51c6\uff1a\u5c06\u63a2\u9488\u538b\u529b\u6620\u5c04\u5230\u7a7a\u901f\u548c\u6d41\u52a8\u89d2\u5ea6\uff1b3. \u5b66\u4e60\u63a7\u5236\u4eff\u5c04\u52a8\u529b\u5b66\u6a21\u578b\uff1a\u4f7f\u7528\u4f30\u8ba1\u7684\u7a7a\u901f/\u89d2\u5ea6\u548c\u7a00\u758f\u4f20\u611f\u5668\uff1b4. \u8f6f\u5de6\u53f3\u5bf9\u79f0\u6b63\u5219\u5316\u5668\u63d0\u9ad8\u53ef\u8bc6\u522b\u6027\uff1b5. \u6b63\u5219\u5316\u6700\u5c0f\u4e8c\u4e58\u5206\u914d\u5668\u5b9e\u73b0\u5e73\u6ed1\u3001\u914d\u5e73\u7684\u4f5c\u52a8\u3002", "result": "\u98ce\u6d1e\u7814\u7a76\u8868\u660e\uff1a\u6dfb\u52a0\u673a\u7ffc\u538b\u529b\u53ef\u5c06\u529b\u4f30\u8ba1\u8bef\u5dee\u964d\u4f4e25-30%\uff1b\u6240\u63d0\u6a21\u578b\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u6027\u80fd\u4e0b\u964d\u8f83\u5c11\uff08\u7ea612% vs \u975e\u7ed3\u6784\u5316\u57fa\u7ebf\u768444%\uff09\uff1b\u529b\u8ddf\u8e2a\u6027\u80fd\u6539\u5584\uff0c\u8f93\u5165\u66f4\u5e73\u6ed1\uff0c\u6cd5\u5411\u529bRMSE\u6bd4\u666e\u901a\u4eff\u5c04\u6a21\u578b\u964d\u4f4e27%\uff0c\u6bd4\u975e\u7ed3\u6784\u5316\u57fa\u7ebf\u964d\u4f4e34%\u3002", "conclusion": "\u8be5\u7aef\u5230\u7aef\u65b9\u6cd5\u901a\u8fc7\u4eff\u751f\u4f20\u611f\u3001\u7269\u7406\u4fe1\u606f\u5efa\u6a21\u548c\u51f8\u4f18\u5316\u63a7\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fa\u5b9a\u7ffc\u65e0\u4eba\u673a\u5728\u5bbd\u5de5\u4f5c\u8303\u56f4\u5185\u7684\u4f4e\u901f\u63a7\u5236\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2510.07064", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07064", "abs": "https://arxiv.org/abs/2510.07064", "authors": ["Manh Hung Nguyen", "Sebastian Tschiatschek", "Adish Singla"], "title": "Prompt Optimization Across Multiple Agents for Representing Diverse Human Populations", "comment": null, "summary": "The difficulty and expense of obtaining large-scale human responses make\nLarge Language Models (LLMs) an attractive alternative and a promising proxy\nfor human behavior. However, prior work shows that LLMs often produce\nhomogeneous outputs that fail to capture the rich diversity of human\nperspectives and behaviors. Thus, rather than trying to capture this diversity\nwith a single LLM agent, we propose a novel framework to construct a set of\nagents that collectively capture the diversity of a given human population.\nEach agent is an LLM whose behavior is steered by conditioning on a small set\nof human demonstrations (task-response pairs) through in-context learning. The\ncentral challenge is therefore to select a representative set of LLM agents\nfrom the exponentially large space of possible agents. We tackle this selection\nproblem from the lens of submodular optimization. In particular, we develop\nmethods that offer different trade-offs regarding time complexity and\nperformance guarantees. Extensive experiments in crowdsourcing and educational\ndomains demonstrate that our approach constructs agents that more effectively\nrepresent human populations compared to baselines. Moreover, behavioral\nanalyses on new tasks show that these agents reproduce the behavior patterns\nand perspectives of the students and annotators they are designed to represent.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u4e00\u7ec4LLM\u4ee3\u7406\u6765\u6355\u6349\u4eba\u7c7b\u7fa4\u4f53\u7684\u591a\u6837\u6027\uff0c\u6bcf\u4e2a\u4ee3\u7406\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u57fa\u4e8e\u5c11\u91cf\u4eba\u7c7b\u6f14\u793a\u6765\u8c03\u6574\u884c\u4e3a\uff0c\u4f7f\u7528\u5b50\u6a21\u4f18\u5316\u65b9\u6cd5\u9009\u62e9\u4ee3\u8868\u6027\u4ee3\u7406\u96c6\u3002", "motivation": "\u7531\u4e8e\u83b7\u53d6\u5927\u89c4\u6a21\u4eba\u7c7b\u54cd\u5e94\u7684\u56f0\u96be\u548c\u6210\u672c\u9ad8\u6602\uff0cLLMs\u6210\u4e3a\u6709\u5438\u5f15\u529b\u7684\u4eba\u7c7b\u884c\u4e3a\u4ee3\u7406\u66ff\u4ee3\u54c1\uff0c\u4f46\u73b0\u6709LLMs\u8f93\u51fa\u540c\u8d28\u5316\u4e25\u91cd\uff0c\u65e0\u6cd5\u6355\u6349\u4eba\u7c7b\u89c2\u70b9\u548c\u884c\u4e3a\u7684\u4e30\u5bcc\u591a\u6837\u6027\u3002", "method": "\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u6784\u5efa\u591a\u4e2aLLM\u4ee3\u7406\uff0c\u6bcf\u4e2a\u4ee3\u7406\u57fa\u4e8e\u5c11\u91cf\u4eba\u7c7b\u6f14\u793a\uff08\u4efb\u52a1-\u54cd\u5e94\u5bf9\uff09\u8c03\u6574\u884c\u4e3a\uff0c\u4f7f\u7528\u5b50\u6a21\u4f18\u5316\u65b9\u6cd5\u4ece\u6307\u6570\u7ea7\u5927\u7684\u4ee3\u7406\u7a7a\u95f4\u4e2d\u9009\u62e9\u4ee3\u8868\u6027\u4ee3\u7406\u96c6\u3002", "result": "\u5728\u4f17\u5305\u548c\u6559\u80b2\u9886\u57df\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6784\u5efa\u7684\u4ee3\u7406\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u66f4\u6709\u6548\u5730\u4ee3\u8868\u4eba\u7c7b\u7fa4\u4f53\uff0c\u5728\u65b0\u4efb\u52a1\u4e0a\u7684\u884c\u4e3a\u5206\u6790\u663e\u793a\u8fd9\u4e9b\u4ee3\u7406\u80fd\u591f\u91cd\u73b0\u76ee\u6807\u5b66\u751f\u548c\u6807\u6ce8\u8005\u7684\u884c\u4e3a\u6a21\u5f0f\u548c\u89c2\u70b9\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u6784\u5efa\u4e86\u80fd\u591f\u6355\u6349\u4eba\u7c7b\u7fa4\u4f53\u591a\u6837\u6027\u7684LLM\u4ee3\u7406\u96c6\uff0c\u901a\u8fc7\u5b50\u6a21\u4f18\u5316\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4ee3\u7406\u9009\u62e9\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u9886\u57df\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2510.07181", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.07181", "abs": "https://arxiv.org/abs/2510.07181", "authors": ["Yi Han", "Cheng Chi", "Enshen Zhou", "Shanyu Rong", "Jingkun An", "Pengwei Wang", "Zhongyuan Wang", "Lu Sheng", "Shanghang Zhang"], "title": "TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics", "comment": "9 pages, 6 figures", "summary": "Vision-Language Models (VLMs) have shown remarkable capabilities in spatial\nreasoning, yet they remain fundamentally limited to qualitative precision and\nlack the computational precision required for real-world robotics. Current\napproaches fail to leverage metric cues from depth sensors and camera\ncalibration, instead reducing geometric problems to pattern recognition tasks\nthat cannot deliver the centimeter-level accuracy essential for robotic\nmanipulation. We present TIGeR (Tool-Integrated Geometric Reasoning), a novel\nframework that transforms VLMs from perceptual estimators to geometric\ncomputers by enabling them to generate and execute precise geometric\ncomputations through external tools. Rather than attempting to internalize\ncomplex geometric operations within neural networks, TIGeR empowers models to\nrecognize geometric reasoning requirements, synthesize appropriate\ncomputational code, and invoke specialized libraries for exact calculations. To\nsupport this paradigm, we introduce TIGeR-300K, a comprehensive\ntool-invocation-oriented dataset covering point transformations, pose\nestimation, trajectory generation, and spatial compatibility verification,\ncomplete with tool invocation sequences and intermediate computations. Through\na two-stage training pipeline combining supervised fine-tuning (SFT) and\nreinforcement fine-tuning (RFT) with our proposed hierarchical reward design,\nTIGeR achieves SOTA performance on geometric reasoning benchmarks while\ndemonstrating centimeter-level precision in real-world robotic manipulation\ntasks.", "AI": {"tldr": "TIGeR\u662f\u4e00\u4e2a\u5c06\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4ece\u611f\u77e5\u4f30\u8ba1\u5668\u8f6c\u53d8\u4e3a\u51e0\u4f55\u8ba1\u7b97\u5668\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5916\u90e8\u5de5\u5177\u751f\u6210\u548c\u6267\u884c\u7cbe\u786e\u51e0\u4f55\u8ba1\u7b97\uff0c\u5b9e\u73b0\u5398\u7c73\u7ea7\u7cbe\u5ea6\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u63a8\u7406\u4e2d\u4ec5\u9650\u4e8e\u5b9a\u6027\u7cbe\u5ea6\uff0c\u7f3a\u4e4f\u673a\u5668\u4eba\u5e94\u7528\u6240\u9700\u7684\u8ba1\u7b97\u7cbe\u5ea6\uff0c\u65e0\u6cd5\u5229\u7528\u6df1\u5ea6\u4f20\u611f\u5668\u548c\u76f8\u673a\u6807\u5b9a\u7684\u5ea6\u91cf\u7ebf\u7d22\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7ba1\u9053\uff1a\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u5f3a\u5316\u5fae\u8c03(RFT)\uff0c\u7ed3\u5408\u5206\u5c42\u5956\u52b1\u8bbe\u8ba1\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u8bc6\u522b\u51e0\u4f55\u63a8\u7406\u9700\u6c42\u3001\u5408\u6210\u8ba1\u7b97\u4ee3\u7801\u5e76\u8c03\u7528\u4e13\u95e8\u5e93\u8fdb\u884c\u7cbe\u786e\u8ba1\u7b97\u3002", "result": "\u5728\u51e0\u4f55\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5c55\u793a\u5398\u7c73\u7ea7\u7cbe\u5ea6\u3002", "conclusion": "TIGeR\u6846\u67b6\u6210\u529f\u5c06VLMs\u8f6c\u5316\u4e3a\u51e0\u4f55\u8ba1\u7b97\u673a\uff0c\u901a\u8fc7\u5de5\u5177\u96c6\u6210\u5b9e\u73b0\u4e86\u673a\u5668\u4eba\u64cd\u4f5c\u6240\u9700\u7684\u7cbe\u786e\u51e0\u4f55\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.07069", "categories": ["cs.AI", "I.2.4"], "pdf": "https://arxiv.org/pdf/2510.07069", "abs": "https://arxiv.org/abs/2510.07069", "authors": ["Hongbo Hu", "Yisong Wang", "Yi Huang", "Kewen Wang"], "title": "Inductive Learning for Possibilistic Logic Programs Under Stable Models", "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "summary": "Possibilistic logic programs (poss-programs) under stable models are a major\nvariant of answer set programming (ASP). While its semantics (possibilistic\nstable models) and properties have been well investigated, the problem of\ninductive reasoning has not been investigated yet. This paper presents an\napproach to extracting poss-programs from a background program and examples\n(parts of intended possibilistic stable models). To this end, the notion of\ninduction tasks is first formally defined, its properties are investigated and\ntwo algorithms ilpsm and ilpsmmin for computing induction solutions are\npresented. An implementation of ilpsmmin is also provided and experimental\nresults show that when inputs are ordinary logic programs, the prototype\noutperforms a major inductive learning system for normal logic programs from\nstable models on the datasets that are randomly generated.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4ece\u80cc\u666f\u7a0b\u5e8f\u548c\u793a\u4f8b\u4e2d\u63d0\u53d6\u53ef\u80fd\u6027\u903b\u8f91\u7a0b\u5e8f\u7684\u65b9\u6cd5\uff0c\u5b9a\u4e49\u4e86\u5f52\u7eb3\u4efb\u52a1\u6982\u5ff5\uff0c\u5f00\u53d1\u4e86ilpsm\u548cilpsmmin\u7b97\u6cd5\uff0c\u5e76\u5728\u666e\u901a\u903b\u8f91\u7a0b\u5e8f\u4e0a\u4f18\u4e8e\u73b0\u6709\u5f52\u7eb3\u5b66\u4e60\u7cfb\u7edf\u3002", "motivation": "\u53ef\u80fd\u6027\u903b\u8f91\u7a0b\u5e8f\u5728\u7a33\u5b9a\u6a21\u578b\u4e0b\u7684\u5f52\u7eb3\u63a8\u7406\u95ee\u9898\u5c1a\u672a\u88ab\u7814\u7a76\uff0c\u9700\u8981\u5f00\u53d1\u4ece\u80cc\u666f\u77e5\u8bc6\u548c\u793a\u4f8b\u4e2d\u5b66\u4e60\u53ef\u80fd\u6027\u903b\u8f91\u7a0b\u5e8f\u7684\u65b9\u6cd5\u3002", "method": "\u6b63\u5f0f\u5b9a\u4e49\u5f52\u7eb3\u4efb\u52a1\u6982\u5ff5\uff0c\u7814\u7a76\u5176\u6027\u8d28\uff0c\u63d0\u51failpsm\u548cilpsmmin\u4e24\u79cd\u8ba1\u7b97\u5f52\u7eb3\u89e3\u7684\u7b97\u6cd5\uff0c\u5e76\u5b9e\u73b0\u4e86ilpsmmin\u7684\u539f\u578b\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u8f93\u5165\u4e3a\u666e\u901a\u903b\u8f91\u7a0b\u5e8f\u65f6\uff0c\u8be5\u539f\u578b\u5728\u968f\u673a\u751f\u6210\u7684\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u57fa\u4e8e\u7a33\u5b9a\u6a21\u578b\u7684\u6b63\u5e38\u903b\u8f91\u7a0b\u5e8f\u7684\u4e3b\u8981\u5f52\u7eb3\u5b66\u4e60\u7cfb\u7edf\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u89e3\u51b3\u4e86\u53ef\u80fd\u6027\u903b\u8f91\u7a0b\u5e8f\u7684\u5f52\u7eb3\u63a8\u7406\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3a\u53ef\u80fd\u6027ASP\u7684\u5f52\u7eb3\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.07197", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.07197", "abs": "https://arxiv.org/abs/2510.07197", "authors": ["Aman Singh", "Deepak Kapa", "Suryank Joshi", "Shishir Kolathaya"], "title": "COMPAct: Computational Optimization and Automated Modular design of Planetary Actuators", "comment": "8 pages, 9 Figures, 2 tables, first two authors contributed equally", "summary": "The optimal design of robotic actuators is a critical area of research, yet\nlimited attention has been given to optimizing gearbox parameters and\nautomating actuator CAD. This paper introduces COMPAct: Computational\nOptimization and Automated Modular Design of Planetary Actuators, a framework\nthat systematically identifies optimal gearbox parameters for a given motor\nacross four gearbox types, single-stage planetary gearbox (SSPG), compound\nplanetary gearbox (CPG), Wolfrom planetary gearbox (WPG), and double-stage\nplanetary gearbox (DSPG). The framework minimizes mass and actuator width while\nmaximizing efficiency, and further automates actuator CAD generation to enable\ndirect 3D printing without manual redesign. Using this framework, optimal\ngearbox designs are explored over a wide range of gear ratios, providing\ninsights into the suitability of different gearbox types across various gear\nratio ranges. In addition, the framework is used to generate CAD models of all\nfour gearbox types with varying gear ratios and motors. Two actuator types are\nfabricated and experimentally evaluated through power efficiency, no-load\nbacklash, and transmission stiffness tests. Experimental results indicate that\nthe SSPG actuator achieves a mechanical efficiency of 60-80 %, a no-load\nbacklash of 0.59 deg, and a transmission stiffness of 242.7 Nm/rad, while the\nCPG actuator demonstrates 60 % efficiency, 2.6 deg backlash, and a stiffness of\n201.6 Nm/rad. Code available at:\nhttps://anonymous.4open.science/r/COMPAct-SubNum-3408 Video:\nhttps://youtu.be/99zOKgxsDho", "AI": {"tldr": "COMPAct\u6846\u67b6\u901a\u8fc7\u8ba1\u7b97\u4f18\u5316\u548c\u81ea\u52a8\u5316CAD\u8bbe\u8ba1\uff0c\u7cfb\u7edf\u4f18\u5316\u56db\u79cd\u884c\u661f\u9f7f\u8f6e\u7bb1\u53c2\u6570\uff0c\u5b9e\u73b0\u8d28\u91cf\u6700\u5c0f\u5316\u3001\u5bbd\u5ea6\u6700\u5c0f\u5316\u548c\u6548\u7387\u6700\u5927\u5316\uff0c\u5e76\u81ea\u52a8\u751f\u6210\u53ef\u76f4\u63a53D\u6253\u5370\u7684CAD\u6a21\u578b\u3002", "motivation": "\u673a\u5668\u4eba\u6267\u884c\u5668\u8bbe\u8ba1\u4e2d\uff0c\u9f7f\u8f6e\u7bb1\u53c2\u6570\u4f18\u5316\u548cCAD\u81ea\u52a8\u5316\u8bbe\u8ba1\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u4f18\u5316\u6846\u67b6\u6765\u63d0\u5347\u6267\u884c\u5668\u6027\u80fd\u3002", "method": "\u5f00\u53d1COMPAct\u6846\u67b6\uff0c\u5bf9\u56db\u79cd\u884c\u661f\u9f7f\u8f6e\u7bb1\u7c7b\u578b\u8fdb\u884c\u53c2\u6570\u4f18\u5316\uff0c\u5305\u62ec\u5355\u7ea7\u884c\u661f\u9f7f\u8f6e\u7bb1\u3001\u590d\u5408\u884c\u661f\u9f7f\u8f6e\u7bb1\u3001Wolfrom\u884c\u661f\u9f7f\u8f6e\u7bb1\u548c\u53cc\u7ea7\u884c\u661f\u9f7f\u8f6e\u7bb1\uff0c\u5e76\u81ea\u52a8\u5316\u751f\u6210CAD\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u663e\u793aSSPG\u6267\u884c\u5668\u673a\u68b0\u6548\u738760-80%\uff0c\u7a7a\u8f7d\u56de\u5dee0.59\u5ea6\uff0c\u4f20\u52a8\u521a\u5ea6242.7 Nm/rad\uff1bCPG\u6267\u884c\u5668\u6548\u738760%\uff0c\u56de\u5dee2.6\u5ea6\uff0c\u521a\u5ea6201.6 Nm/rad\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u9f7f\u8f6e\u7bb1\u53c2\u6570\u7684\u4f18\u5316\u8bbe\u8ba1\u548cCAD\u81ea\u52a8\u5316\u751f\u6210\uff0c\u4e3a\u4e0d\u540c\u4f20\u52a8\u6bd4\u8303\u56f4\u63d0\u4f9b\u4e86\u5408\u9002\u7684\u9f7f\u8f6e\u7bb1\u7c7b\u578b\u9009\u62e9\u6307\u5bfc\u3002"}}
{"id": "2510.07073", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07073", "abs": "https://arxiv.org/abs/2510.07073", "authors": ["Andr\u00e9 Hottung", "Federico Berto", "Chuanbo Hua", "Nayeli Gast Zepeda", "Daniel Wetzel", "Michael R\u00f6mer", "Haoran Ye", "Davide Zago", "Michael Poli", "Stefano Massaroli", "Jinkyoo Park", "Kevin Tierney"], "title": "VRPAgent: LLM-Driven Discovery of Heuristic Operators for Vehicle Routing Problems", "comment": null, "summary": "Designing high-performing heuristics for vehicle routing problems (VRPs) is a\ncomplex task that requires both intuition and deep domain knowledge. Large\nlanguage model (LLM)-based code generation has recently shown promise across\nmany domains, but it still falls short of producing heuristics that rival those\ncrafted by human experts. In this paper, we propose VRPAgent, a framework that\nintegrates LLM-generated components into a metaheuristic and refines them\nthrough a novel genetic search. By using the LLM to generate problem-specific\noperators, embedded within a generic metaheuristic framework, VRPAgent keeps\ntasks manageable, guarantees correctness, and still enables the discovery of\nnovel and powerful strategies. Across multiple problems, including the\ncapacitated VRP, the VRP with time windows, and the prize-collecting VRP, our\nmethod discovers heuristic operators that outperform handcrafted methods and\nrecent learning-based approaches while requiring only a single CPU core. To our\nknowledge, \\VRPAgent is the first LLM-based paradigm to advance the\nstate-of-the-art in VRPs, highlighting a promising future for automated\nheuristics discovery.", "AI": {"tldr": "VRPAgent\u662f\u4e00\u4e2a\u5c06LLM\u751f\u6210\u7684\u7ec4\u4ef6\u96c6\u6210\u5230\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u4e2d\uff0c\u5e76\u901a\u8fc7\u9057\u4f20\u641c\u7d22\u8fdb\u884c\u4f18\u5316\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5728\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u4e0a\u8d85\u8d8a\u4eba\u5de5\u8bbe\u8ba1\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "motivation": "\u8bbe\u8ba1\u9ad8\u6027\u80fd\u7684\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u542f\u53d1\u5f0f\u7b97\u6cd5\u9700\u8981\u6df1\u539a\u7684\u9886\u57df\u77e5\u8bc6\u548c\u76f4\u89c9\uff0c\u800c\u73b0\u6709\u7684LLM\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u8fd8\u65e0\u6cd5\u4ea7\u751f\u80fd\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u5ab2\u7f8e\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "method": "\u4f7f\u7528LLM\u751f\u6210\u95ee\u9898\u7279\u5b9a\u7684\u64cd\u4f5c\u7b26\uff0c\u5e76\u5c06\u5176\u5d4c\u5165\u5230\u901a\u7528\u7684\u5143\u542f\u53d1\u5f0f\u6846\u67b6\u4e2d\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u9057\u4f20\u641c\u7d22\u6765\u4f18\u5316\u8fd9\u4e9b\u7ec4\u4ef6\u3002", "result": "\u5728\u591a\u4e2a\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u53d8\u4f53\u4e0a\uff0cVRPAgent\u53d1\u73b0\u7684\u542f\u53d1\u5f0f\u64cd\u4f5c\u7b26\u8d85\u8d8a\u4e86\u624b\u5de5\u8bbe\u8ba1\u7684\u65b9\u6cd5\u548c\u6700\u8fd1\u7684\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e14\u4ec5\u9700\u5355\u4e2aCPU\u6838\u5fc3\u3002", "conclusion": "VRPAgent\u662f\u9996\u4e2a\u5728\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u4e0a\u63a8\u8fdb\u6700\u5148\u8fdb\u6280\u672f\u7684LLM\u8303\u5f0f\uff0c\u4e3a\u81ea\u52a8\u542f\u53d1\u5f0f\u53d1\u73b0\u5c55\u793a\u4e86\u6709\u524d\u666f\u7684\u672a\u6765\u3002"}}
{"id": "2510.07210", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07210", "abs": "https://arxiv.org/abs/2510.07210", "authors": ["Donald Pfaffmann", "Matthias Klusch", "Marcel Steinmetz"], "title": "HyPlan: Hybrid Learning-Assisted Planning Under Uncertainty for Safe Autonomous Driving", "comment": null, "summary": "We present a novel hybrid learning-assisted planning method, named HyPlan,\nfor solving the collision-free navigation problem for self-driving cars in\npartially observable traffic environments. HyPlan combines methods for\nmulti-agent behavior prediction, deep reinforcement learning with proximal\npolicy optimization and approximated online POMDP planning with heuristic\nconfidence-based vertical pruning to reduce its execution time without\ncompromising safety of driving. Our experimental performance analysis on the\nCARLA-CTS2 benchmark of critical traffic scenarios with pedestrians revealed\nthat HyPlan may navigate safer than selected relevant baselines and perform\nsignificantly faster than considered alternative online POMDP planners.", "AI": {"tldr": "\u63d0\u51faHyPlan\u6df7\u5408\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u4ea4\u901a\u73af\u5883\u4e2d\u7684\u65e0\u78b0\u649e\u5bfc\u822a\u95ee\u9898\uff0c\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u884c\u4e3a\u9884\u6d4b\u3001\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u548c\u5728\u7ebfPOMDP\u89c4\u5212\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u4ea4\u901a\u73af\u5883\u4e2d\u5b89\u5168\u5bfc\u822a\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u6709\u884c\u4eba\u7684\u5173\u952e\u4ea4\u901a\u573a\u666f\u4e2d\u3002", "method": "\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u884c\u4e3a\u9884\u6d4b\u3001\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u3001\u57fa\u4e8e\u542f\u53d1\u5f0f\u7f6e\u4fe1\u5ea6\u5782\u76f4\u526a\u679d\u7684\u8fd1\u4f3c\u5728\u7ebfPOMDP\u89c4\u5212\u3002", "result": "\u5728CARLA-CTS2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHyPlan\u6bd4\u76f8\u5173\u57fa\u7ebf\u65b9\u6cd5\u66f4\u5b89\u5168\uff0c\u6bd4\u66ff\u4ee3\u5728\u7ebfPOMDP\u89c4\u5212\u5668\u6267\u884c\u901f\u5ea6\u663e\u8457\u66f4\u5feb\u3002", "conclusion": "HyPlan\u65b9\u6cd5\u5728\u4e0d\u727a\u7272\u9a7e\u9a76\u5b89\u5168\u7684\u524d\u63d0\u4e0b\uff0c\u901a\u8fc7\u5782\u76f4\u526a\u679d\u6280\u672f\u6709\u6548\u51cf\u5c11\u4e86\u6267\u884c\u65f6\u95f4\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u9ad8\u6548\u7684\u81ea\u52a8\u9a7e\u9a76\u5bfc\u822a\u3002"}}
{"id": "2510.07091", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.07091", "abs": "https://arxiv.org/abs/2510.07091", "authors": ["Baixuan Xu", "Tianshi Zheng", "Zhaowei Wang", "Hong Ting Tsang", "Weiqi Wang", "Tianqing Fang", "Yangqiu Song"], "title": "The Cognitive Bandwidth Bottleneck: Shifting Long-Horizon Agent from Planning with Actions to Planning with Schemas", "comment": "22 pages", "summary": "Enabling LLMs to effectively operate long-horizon task which requires\nlong-term planning and multiple interactions is essential for open-world\nautonomy. Conventional methods adopt planning with actions where a executable\naction list would be provided as reference. However, this action representation\nchoice would be impractical when the environment action space is combinatorial\nexploded (e.g., open-ended real world). This naturally leads to a question: As\nenvironmental action space scales, what is the optimal action representation\nfor long-horizon agents? In this paper, we systematically study the\neffectiveness of two different action representations. The first one is\nconventional planning with actions (PwA) which is predominantly adopted for its\neffectiveness on existing benchmarks. The other one is planning with schemas\n(PwS) which instantiate an action schema into action lists (e.g., \"move [OBJ]\nto [OBJ]\" -> \"move apple to desk\") to ensure concise action space and reliable\nscalability. This alternative is motivated by its alignment with human\ncognition and its compliance with environment-imposed action format\nrestriction. We propose cognitive bandwidth perspective as a conceptual\nframework to qualitatively understand the differences between these two action\nrepresentations and empirically observe a representation-choice inflection\npoint between ALFWorld (~35 actions) and SciWorld (~500 actions), which serve\nas evidence of the need for scalable representations. We further conduct\ncontrolled experiments to study how the location of this inflection point\ninteracts with different model capacities: stronger planning proficiency shifts\nthe inflection rightward, whereas better schema instantiation shifts it\nleftward. Finally, noting the suboptimal performance of PwS agents, we provide\nan actionable guide for building more capable PwS agents for better scalable\nautonomy.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u4e24\u79cd\u52a8\u4f5c\u8868\u793a\u65b9\u6cd5\u5728\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff1a\u57fa\u4e8e\u52a8\u4f5c\u7684\u89c4\u5212(PwA)\u548c\u57fa\u4e8e\u6a21\u5f0f\u7684\u89c4\u5212(PwS)\uff0c\u53d1\u73b0\u5b58\u5728\u4e00\u4e2a\u8868\u793a\u9009\u62e9\u62d0\u70b9\uff0c\u5e76\u63d0\u51fa\u4e86\u6784\u5efa\u66f4\u5f3a\u5927PwS\u667a\u80fd\u4f53\u7684\u5b9e\u7528\u6307\u5357\u3002", "motivation": "\u5f53\u73af\u5883\u52a8\u4f5c\u7a7a\u95f4\u7ec4\u5408\u7206\u70b8\u65f6\uff08\u5982\u5f00\u653e\u4e16\u754c\uff09\uff0c\u4f20\u7edf\u7684\u57fa\u4e8e\u52a8\u4f5c\u5217\u8868\u7684\u89c4\u5212\u65b9\u6cd5\u53d8\u5f97\u4e0d\u5207\u5b9e\u9645\uff0c\u9700\u8981\u5bfb\u627e\u6700\u4f18\u7684\u52a8\u4f5c\u8868\u793a\u65b9\u6cd5\u6765\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u81ea\u4e3b\u6027\u3002", "method": "\u7cfb\u7edf\u6bd4\u8f83PwA\uff08\u76f4\u63a5\u63d0\u4f9b\u53ef\u6267\u884c\u52a8\u4f5c\u5217\u8868\uff09\u548cPwS\uff08\u5c06\u52a8\u4f5c\u6a21\u5f0f\u5b9e\u4f8b\u5316\u4e3a\u52a8\u4f5c\u5217\u8868\uff09\u4e24\u79cd\u8868\u793a\u65b9\u6cd5\uff0c\u63d0\u51fa\u8ba4\u77e5\u5e26\u5bbd\u89c6\u89d2\u4f5c\u4e3a\u6982\u5ff5\u6846\u67b6\uff0c\u5728ALFWorld\u548cSciWorld\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u89c2\u5bdf\u8868\u793a\u9009\u62e9\u62d0\u70b9\u3002", "result": "\u5728ALFWorld\uff08\u7ea635\u4e2a\u52a8\u4f5c\uff09\u548cSciWorld\uff08\u7ea6500\u4e2a\u52a8\u4f5c\uff09\u4e4b\u95f4\u89c2\u5bdf\u5230\u4e00\u4e2a\u8868\u793a\u9009\u62e9\u62d0\u70b9\uff0c\u8868\u660e\u9700\u8981\u53ef\u6269\u5c55\u7684\u8868\u793a\u65b9\u6cd5\u3002\u6a21\u578b\u89c4\u5212\u80fd\u529b\u8d8a\u5f3a\uff0c\u62d0\u70b9\u8d8a\u53f3\u79fb\uff1b\u6a21\u5f0f\u5b9e\u4f8b\u5316\u80fd\u529b\u8d8a\u597d\uff0c\u62d0\u70b9\u8d8a\u5de6\u79fb\u3002", "conclusion": "PwS\u5728\u52a8\u4f5c\u7a7a\u95f4\u8f83\u5927\u65f6\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5f53\u524dPwS\u667a\u80fd\u4f53\u6027\u80fd\u6b20\u4f73\uff0c\u9700\u8981\u6784\u5efa\u66f4\u5f3a\u5927\u7684PwS\u667a\u80fd\u4f53\u6765\u5b9e\u73b0\u66f4\u597d\u7684\u53ef\u6269\u5c55\u81ea\u4e3b\u6027\u3002"}}
{"id": "2510.07117", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.07117", "abs": "https://arxiv.org/abs/2510.07117", "authors": ["Leonardo Christov-Moore", "Arthur Juliani", "Alex Kiefer", "Nicco Reggente", "B. Scott Rousse", "Adam Safron", "Nicol'as Hinrichs", "Daniel Polani", "Antonio Damasio"], "title": "The Contingencies of Physical Embodiment Allow for Open-Endedness and Care", "comment": "15 pages, 1 figure", "summary": "Physical vulnerability and mortality are often seen as obstacles to be\navoided in the development of artificial agents, which struggle to adapt to\nopen-ended environments and provide aligned care. Meanwhile, biological\norganisms survive, thrive, and care for each other in an open-ended physical\nworld with relative ease and efficiency. Understanding the role of the\nconditions of life in this disparity can aid in developing more robust,\nadaptive, and caring artificial agents. Here we define two minimal conditions\nfor physical embodiment inspired by the existentialist phenomenology of Martin\nHeidegger: being-in-the-world (the agent is a part of the environment) and\nbeing-towards-death (unless counteracted, the agent drifts toward terminal\nstates due to the second law of thermodynamics). We propose that from these\nconditions we can obtain both a homeostatic drive - aimed at maintaining\nintegrity and avoiding death by expending energy to learn and act - and an\nintrinsic drive to continue to do so in as many ways as possible. Drawing\ninspiration from Friedrich Nietzsche's existentialist concept of will-to-power,\nwe examine how intrinsic drives to maximize control over future states, e.g.,\nempowerment, allow agents to increase the probability that they will be able to\nmeet their future homeostatic needs, thereby enhancing their capacity to\nmaintain physical integrity. We formalize these concepts within a reinforcement\nlearning framework, which enables us to examine how intrinsically driven\nembodied agents learning in open-ended multi-agent environments may cultivate\nthe capacities for open-endedness and care.ov", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ece\u5b58\u5728\u4e3b\u4e49\u73b0\u8c61\u5b66\u89d2\u5ea6\u63d0\u51fa\u7269\u7406\u5177\u8eab\u7684\u4e24\u4e2a\u6700\u5c0f\u6761\u4ef6\uff0c\u5e76\u57fa\u4e8e\u6b64\u63a8\u5bfc\u51fa\u7a33\u6001\u9a71\u52a8\u548c\u5185\u5728\u9a71\u52a8\uff0c\u5728\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e2d\u5f62\u5f0f\u5316\u8fd9\u4e9b\u6982\u5ff5\uff0c\u63a2\u8ba8\u5177\u8eab\u667a\u80fd\u4f53\u5982\u4f55\u5728\u5f00\u653e\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u53d1\u5c55\u5f00\u653e\u6027\u548c\u5173\u6000\u80fd\u529b\u3002", "motivation": "\u7406\u89e3\u751f\u7269\u4f53\u5728\u5f00\u653e\u7269\u7406\u4e16\u754c\u4e2d\u751f\u5b58\u3001\u7e41\u884d\u548c\u76f8\u4e92\u5173\u6000\u7684\u673a\u5236\uff0c\u4ee5\u5e2e\u52a9\u5f00\u53d1\u66f4\u9c81\u68d2\u3001\u81ea\u9002\u5e94\u548c\u5173\u6000\u7684\u4eba\u5de5\u667a\u80fd\u4f53\u3002", "method": "\u57fa\u4e8e\u6d77\u5fb7\u683c\u5c14\u5b58\u5728\u4e3b\u4e49\u73b0\u8c61\u5b66\u5b9a\u4e49\u4e24\u4e2a\u6700\u5c0f\u5177\u8eab\u6761\u4ef6\uff1a\u5728\u4e16\u5b58\u5728\uff08\u667a\u80fd\u4f53\u662f\u73af\u5883\u7684\u4e00\u90e8\u5206\uff09\u548c\u5411\u6b7b\u5b58\u5728\uff08\u667a\u80fd\u4f53\u8d8b\u5411\u7ec8\u672b\u72b6\u6001\uff09\uff0c\u4ece\u4e2d\u63a8\u5bfc\u51fa\u7a33\u6001\u9a71\u52a8\u548c\u5185\u5728\u9a71\u52a8\uff0c\u5e76\u5728\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e2d\u5f62\u5f0f\u5316\u8fd9\u4e9b\u6982\u5ff5\u3002", "result": "\u63d0\u51fa\u4ece\u57fa\u672c\u5177\u8eab\u6761\u4ef6\u53ef\u4ee5\u63a8\u5bfc\u51fa\u7ef4\u6301\u5b8c\u6574\u6027\u548c\u907f\u514d\u6b7b\u4ea1\u7684\u7a33\u6001\u9a71\u52a8\uff0c\u4ee5\u53ca\u6700\u5927\u5316\u5bf9\u672a\u6765\u72b6\u6001\u63a7\u5236\u7684\u5185\u5728\u9a71\u52a8\uff08\u5982\u8d4b\u6743\uff09\uff0c\u8fd9\u4e9b\u9a71\u52a8\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u589e\u5f3a\u7ef4\u6301\u7269\u7406\u5b8c\u6574\u6027\u7684\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316\u8fd9\u4e9b\u5b58\u5728\u4e3b\u4e49\u542f\u53d1\u7684\u5177\u8eab\u6982\u5ff5\uff0c\u53ef\u4ee5\u7814\u7a76\u5185\u5728\u9a71\u52a8\u7684\u5177\u8eab\u667a\u80fd\u4f53\u5982\u4f55\u5728\u5f00\u653e\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u57f9\u517b\u5f00\u653e\u6027\u548c\u5173\u6000\u80fd\u529b\u3002"}}
{"id": "2510.07161", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07161", "abs": "https://arxiv.org/abs/2510.07161", "authors": ["Ali Norouzifar", "Humam Kourani", "Marcus Dees", "Wil van der Aalst"], "title": "Integrating Domain Knowledge into Process Discovery Using Large Language Models", "comment": "This paper is currently under review for publication in a journal", "summary": "Process discovery aims to derive process models from event logs, providing\ninsights into operational behavior and forming a foundation for conformance\nchecking and process improvement. However, models derived solely from event\ndata may not accurately reflect the real process, as event logs are often\nincomplete or affected by noise, and domain knowledge, an important\ncomplementary resource, is typically disregarded. As a result, the discovered\nmodels may lack reliability for downstream tasks. We propose an interactive\nframework that incorporates domain knowledge, expressed in natural language,\ninto the process discovery pipeline using Large Language Models (LLMs). Our\napproach leverages LLMs to extract declarative rules from textual descriptions\nprovided by domain experts. These rules are used to guide the IMr discovery\nalgorithm, which recursively constructs process models by combining insights\nfrom both the event log and the extracted rules, helping to avoid problematic\nprocess structures that contradict domain knowledge. The framework coordinates\ninteractions among the LLM, domain experts, and a set of backend services. We\npresent a fully implemented tool that supports this workflow and conduct an\nextensive evaluation of multiple LLMs and prompt engineering strategies. Our\nempirical study includes a case study based on a real-life event log with the\ninvolvement of domain experts, who assessed the usability and effectiveness of\nthe framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u7684\u9886\u57df\u77e5\u8bc6\u878d\u5165\u8fc7\u7a0b\u53d1\u73b0\u6d41\u7a0b\uff0c\u901a\u8fc7\u63d0\u53d6\u58f0\u660e\u6027\u89c4\u5219\u6307\u5bfc\u8fc7\u7a0b\u6a21\u578b\u6784\u5efa\uff0c\u63d0\u9ad8\u6a21\u578b\u53ef\u9760\u6027\u3002", "motivation": "\u4ec5\u4ece\u4e8b\u4ef6\u6570\u636e\u53d1\u73b0\u7684\u8fc7\u7a0b\u6a21\u578b\u53ef\u80fd\u4e0d\u51c6\u786e\uff0c\u56e0\u4e3a\u4e8b\u4ef6\u65e5\u5fd7\u901a\u5e38\u4e0d\u5b8c\u6574\u6216\u5305\u542b\u566a\u58f0\uff0c\u4e14\u5ffd\u7565\u4e86\u91cd\u8981\u7684\u9886\u57df\u77e5\u8bc6\uff0c\u5bfc\u81f4\u6a21\u578b\u5bf9\u4e0b\u6e38\u4efb\u52a1\u7f3a\u4e4f\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528LLMs\u4ece\u9886\u57df\u4e13\u5bb6\u7684\u6587\u672c\u63cf\u8ff0\u4e2d\u63d0\u53d6\u58f0\u660e\u6027\u89c4\u5219\uff0c\u6307\u5bfcIMr\u53d1\u73b0\u7b97\u6cd5\u9012\u5f52\u6784\u5efa\u8fc7\u7a0b\u6a21\u578b\uff0c\u7ed3\u5408\u4e8b\u4ef6\u65e5\u5fd7\u548c\u63d0\u53d6\u7684\u89c4\u5219\uff0c\u907f\u514d\u4e0e\u9886\u57df\u77e5\u8bc6\u51b2\u7a81\u7684\u95ee\u9898\u7ed3\u6784\u3002", "result": "\u5f00\u53d1\u4e86\u5b8c\u5168\u5b9e\u73b0\u7684\u5de5\u5177\u652f\u6301\u8be5\u5de5\u4f5c\u6d41\uff0c\u5bf9\u591a\u4e2aLLMs\u548c\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\u8fdb\u884c\u4e86\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u5305\u62ec\u57fa\u4e8e\u771f\u5b9e\u4e8b\u4ef6\u65e5\u5fd7\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u9886\u57df\u4e13\u5bb6\u8bc4\u4f30\u4e86\u6846\u67b6\u7684\u53ef\u7528\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u4ea4\u4e92\u5f0f\u6846\u67b6\u6210\u529f\u5c06\u9886\u57df\u77e5\u8bc6\u6574\u5408\u5230\u8fc7\u7a0b\u53d1\u73b0\u4e2d\uff0c\u63d0\u9ad8\u4e86\u8fc7\u7a0b\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u8fc7\u7a0b\u6316\u6398\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u57fa\u7840\u3002"}}
{"id": "2510.07172", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07172", "abs": "https://arxiv.org/abs/2510.07172", "authors": ["Tianshi Zheng", "Kelvin Kiu-Wai Tam", "Newt Hue-Nam K. Nguyen", "Baixuan Xu", "Zhaowei Wang", "Jiayang Cheng", "Hong Ting Tsang", "Weiqi Wang", "Jiaxin Bai", "Tianqing Fang", "Yangqiu Song", "Ginny Y. Wong", "Simon See"], "title": "NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents", "comment": "60 pages, 18 figures, 13 tables", "summary": "Large language models are emerging as powerful tools for scientific law\ndiscovery, a foundational challenge in AI-driven science. However, existing\nbenchmarks for this task suffer from a fundamental methodological trilemma,\nforcing a trade-off between scientific relevance, scalability, and resistance\nto memorization. Furthermore, they oversimplify discovery as static function\nfitting, failing to capture the authentic scientific process of uncovering\nembedded laws through the interactive exploration of complex model systems. To\naddress these critical gaps, we introduce NewtonBench, a benchmark comprising\n324 scientific law discovery tasks across 12 physics domains. Our design\nmitigates the evaluation trilemma by using metaphysical shifts - systematic\nalterations of canonical laws - to generate a vast suite of problems that are\nscalable, scientifically relevant, and memorization-resistant. Moreover, we\nelevate the evaluation from static function fitting to interactive model\ndiscovery, requiring agents to experimentally probe simulated complex systems\nto uncover hidden principles. Our extensive experiment reveals a clear but\nfragile capability for discovery in frontier LLMs: this ability degrades\nprecipitously with increasing system complexity and exhibits extreme\nsensitivity to observational noise. Notably, we uncover a paradoxical effect of\ntool assistance: providing a code interpreter can hinder more capable models by\ninducing a premature shift from exploration to exploitation, causing them to\nsatisfice on suboptimal solutions. These results demonstrate that robust,\ngeneralizable discovery in complex, interactive environments remains the core\nchallenge. By providing a scalable, robust, and scientifically authentic\ntestbed, NewtonBench offers a crucial tool for measuring true progress and\nguiding the development of next-generation AI agents capable of genuine\nscientific discovery.", "AI": {"tldr": "NewtonBench\u662f\u4e00\u4e2a\u5305\u542b324\u4e2a\u79d1\u5b66\u5b9a\u5f8b\u53d1\u73b0\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u5143\u7269\u7406\u53d8\u6362\u89e3\u51b3\u8bc4\u4f30\u56f0\u5883\uff0c\u5c06\u8bc4\u4f30\u4ece\u9759\u6001\u51fd\u6570\u62df\u5408\u63d0\u5347\u5230\u4ea4\u4e92\u5f0f\u6a21\u578b\u53d1\u73b0\uff0c\u63ed\u793a\u4e86\u524d\u6cbfLLMs\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u53d1\u73b0\u80fd\u529b\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u73b0\u6709\u79d1\u5b66\u53d1\u73b0\u57fa\u51c6\u5b58\u5728\u65b9\u6cd5\u5b66\u56f0\u5883\uff0c\u9700\u8981\u5728\u79d1\u5b66\u76f8\u5173\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u6297\u8bb0\u5fc6\u6027\u4e4b\u95f4\u6743\u8861\uff0c\u4e14\u8fc7\u5ea6\u7b80\u5316\u53d1\u73b0\u8fc7\u7a0b\u4e3a\u9759\u6001\u51fd\u6570\u62df\u5408\uff0c\u672a\u80fd\u6355\u6349\u771f\u5b9e\u7684\u79d1\u5b66\u63a2\u7d22\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528\u5143\u7269\u7406\u53d8\u6362\uff08\u7cfb\u7edf\u6027\u5730\u6539\u53d8\u7ecf\u5178\u5b9a\u5f8b\uff09\u751f\u6210\u5927\u91cf\u95ee\u9898\uff0c\u6784\u5efa\u5305\u542b324\u4e2a\u4efb\u52a1\u7684\u57fa\u51c6\uff0c\u8981\u6c42\u667a\u80fd\u4f53\u901a\u8fc7\u5b9e\u9a8c\u63a2\u7d22\u6a21\u62df\u590d\u6742\u7cfb\u7edf\u6765\u53d1\u73b0\u9690\u85cf\u539f\u7406\u3002", "result": "\u524d\u6cbfLLMs\u5c55\u73b0\u51fa\u6e05\u6670\u4f46\u8106\u5f31\u7684\u53d1\u73b0\u80fd\u529b\uff1a\u968f\u7740\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\u800c\u6025\u5267\u4e0b\u964d\uff0c\u5bf9\u89c2\u6d4b\u566a\u58f0\u6781\u5ea6\u654f\u611f\uff1b\u5de5\u5177\u8f85\u52a9\u5b58\u5728\u6096\u8bba\u6548\u5e94\uff0c\u4ee3\u7801\u89e3\u91ca\u5668\u53ef\u80fd\u963b\u788d\u66f4\u6709\u80fd\u529b\u7684\u6a21\u578b\u3002", "conclusion": "\u5728\u590d\u6742\u4ea4\u4e92\u73af\u5883\u4e2d\u5b9e\u73b0\u7a33\u5065\u3001\u53ef\u6cdb\u5316\u7684\u53d1\u73b0\u4ecd\u662f\u6838\u5fc3\u6311\u6218\uff0cNewtonBench\u4e3a\u8861\u91cf\u771f\u5b9e\u8fdb\u5c55\u548c\u5f00\u53d1\u4e0b\u4e00\u4ee3AI\u79d1\u5b66\u53d1\u73b0\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u5173\u952e\u5de5\u5177\u3002"}}
{"id": "2510.07276", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.07276", "abs": "https://arxiv.org/abs/2510.07276", "authors": ["Pulkit Rustagi", "Kyle Hollins Wray", "Sandhya Saisubramanian"], "title": "Multi-Objective Multi-Agent Path Finding with Lexicographic Cost Preferences", "comment": "8 pages, 7 figures", "summary": "Many real-world scenarios require multiple agents to coordinate in shared\nenvironments, while balancing trade-offs between multiple, potentially\ncompeting objectives. Current multi-objective multi-agent path finding\n(MO-MAPF) algorithms typically produce conflict-free plans by computing Pareto\nfrontiers. They do not explicitly optimize for user-defined preferences, even\nwhen the preferences are available, and scale poorly with the number of\nobjectives. We propose a lexicographic framework for modeling MO-MAPF, along\nwith an algorithm \\textit{Lexicographic Conflict-Based Search} (LCBS) that\ndirectly computes a single solution aligned with a lexicographic preference\nover objectives. LCBS integrates a priority-aware low-level $A^*$ search with\nconflict-based search, avoiding Pareto frontier construction and enabling\nefficient planning guided by preference over objectives. We provide insights\ninto optimality and scalability, and empirically demonstrate that LCBS computes\noptimal solutions while scaling to instances with up to ten objectives -- far\nbeyond the limits of existing MO-MAPF methods. Evaluations on standard and\nrandomized MAPF benchmarks show consistently higher success rates against\nstate-of-the-art baselines, especially with increasing number of objectives.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bcd\u5178\u5e8f\u504f\u597d\u7684\u591a\u76ee\u6807\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u6846\u67b6LCBS\uff0c\u76f4\u63a5\u8ba1\u7b97\u7b26\u5408\u7528\u6237\u504f\u597d\u7684\u5355\u4e00\u89e3\uff0c\u907f\u514d\u6784\u5efa\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u76ee\u6807\u60c5\u51b5\u4e0b\u7684\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709MO-MAPF\u7b97\u6cd5\u901a\u5e38\u901a\u8fc7\u8ba1\u7b97\u5e15\u7d2f\u6258\u524d\u6cbf\u6765\u751f\u6210\u65e0\u51b2\u7a81\u8def\u5f84\uff0c\u4f46\u65e0\u6cd5\u660e\u786e\u4f18\u5316\u7528\u6237\u5b9a\u4e49\u7684\u504f\u597d\uff0c\u4e14\u968f\u7740\u76ee\u6807\u6570\u91cf\u589e\u52a0\u6269\u5c55\u6027\u5dee\u3002", "method": "\u63d0\u51fa\u8bcd\u5178\u5e8f\u6846\u67b6\u548cLCBS\u7b97\u6cd5\uff0c\u7ed3\u5408\u4f18\u5148\u7ea7\u611f\u77e5\u7684\u5e95\u5c42A*\u641c\u7d22\u4e0e\u57fa\u4e8e\u51b2\u7a81\u7684\u641c\u7d22\uff0c\u76f4\u63a5\u6839\u636e\u76ee\u6807\u504f\u597d\u8fdb\u884c\u9ad8\u6548\u89c4\u5212\u3002", "result": "LCBS\u80fd\u591f\u8ba1\u7b97\u6700\u4f18\u89e3\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u591a\u8fbe10\u4e2a\u76ee\u6807\u7684\u60c5\u51b5\uff0c\u8fdc\u8d85\u8fc7\u73b0\u6709MO-MAPF\u65b9\u6cd5\u7684\u9650\u5236\u3002\u5728\u6807\u51c6\u548c\u968f\u673aMAPF\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u968f\u7740\u76ee\u6807\u6570\u91cf\u589e\u52a0\uff0c\u6210\u529f\u7387\u59cb\u7ec8\u9ad8\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\u3002", "conclusion": "\u8bcd\u5178\u5e8f\u6846\u67b6\u548cLCBS\u7b97\u6cd5\u4e3a\u591a\u76ee\u6807\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u76f4\u63a5\u5229\u7528\u7528\u6237\u504f\u597d\u8fdb\u884c\u4f18\u5316\u3002"}}
{"id": "2510.07297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.07297", "abs": "https://arxiv.org/abs/2510.07297", "authors": ["Henry Wang", "Md Sirajus Salekin", "Jake Lee", "Ross Claytor", "Shinan Zhang", "Michael Chi"], "title": "Agentic generative AI for media content discovery at the national football league", "comment": "13 pages, 7 figures, International Sports Analytics Conference and\n  Exhibition", "summary": "Generative AI has unlocked new possibilities in content discovery and\nmanagement. Through collaboration with the National Football League (NFL), we\ndemonstrate how a generative-AI based workflow enables media researchers and\nanalysts to query relevant historical plays using natural language rather than\ntraditional filter-and-click interfaces. The agentic workflow takes a user\nquery as input, breaks it into elements, and translates them into the\nunderlying database query language. Accuracy and latency are further improved\nthrough carefully designed semantic caching. The solution achieves over 95\npercent accuracy and reduces the average time to find relevant videos from 10\nminutes to 30 seconds, significantly increasing the NFL's operational\nefficiency and allowing users to focus on producing creative content and\nengaging storylines.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u5de5\u4f5c\u6d41\uff0c\u8ba9NFL\u5a92\u4f53\u7814\u7a76\u4eba\u5458\u80fd\u7528\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u5386\u53f2\u6bd4\u8d5b\u7247\u6bb5\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u7b5b\u9009\u754c\u9762\uff0c\u51c6\u786e\u7387\u8d8595%\uff0c\u5c06\u67e5\u627e\u65f6\u95f4\u4ece10\u5206\u949f\u7f29\u77ed\u523030\u79d2\u3002", "motivation": "\u4f20\u7edf\u7b5b\u9009\u754c\u9762\u6548\u7387\u4f4e\u4e0b\uff0c\u7528\u6237\u9700\u8981\u82b1\u8d39\u5927\u91cf\u65f6\u95f4\u67e5\u627e\u76f8\u5173\u89c6\u9891\u5185\u5bb9\u3002\u751f\u6210\u5f0fAI\u4e3a\u5185\u5bb9\u53d1\u73b0\u548c\u7ba1\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u901a\u8fc7\u4e0eNFL\u5408\u4f5c\uff0c\u65e8\u5728\u63d0\u9ad8\u5a92\u4f53\u7814\u7a76\u4eba\u5458\u7684\u64cd\u4f5c\u6548\u7387\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u4ee3\u7406\u5de5\u4f5c\u6d41\uff0c\u5c06\u7528\u6237\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u5206\u89e3\u4e3a\u5143\u7d20\uff0c\u5e76\u7ffb\u8bd1\u6210\u5e95\u5c42\u6570\u636e\u5e93\u67e5\u8be2\u8bed\u8a00\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8bed\u4e49\u7f13\u5b58\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u54cd\u5e94\u901f\u5ea6\u3002", "result": "\u89e3\u51b3\u65b9\u6848\u8fbe\u5230\u8d85\u8fc795%\u7684\u51c6\u786e\u7387\uff0c\u5c06\u67e5\u627e\u76f8\u5173\u89c6\u9891\u7684\u5e73\u5747\u65f6\u95f4\u4ece10\u5206\u949f\u51cf\u5c11\u523030\u79d2\uff0c\u663e\u8457\u63d0\u5347\u4e86NFL\u7684\u8fd0\u8425\u6548\u7387\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5de5\u4f5c\u6d41\u6210\u529f\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5185\u5bb9\u53d1\u73b0\uff0c\u8ba9\u7528\u6237\u80fd\u4e13\u6ce8\u4e8e\u521b\u4f5c\u521b\u610f\u5185\u5bb9\u548c\u5f15\u4eba\u5165\u80dc\u7684\u6545\u4e8b\u7ebf\uff0c\u800c\u4e0d\u662f\u82b1\u8d39\u65f6\u95f4\u5728\u67e5\u627e\u89c6\u9891\u4e0a\u3002"}}
{"id": "2204.03521", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2204.03521", "abs": "https://arxiv.org/abs/2204.03521", "authors": ["Altamirano Cabrera Miguel", "Sautenkov Oleg", "Tirado Jonathan", "Fedoseev Aleksey", "Kopanev Pavel", "Kajimoto Hiroyuki", "Tsetserukou Dzmitry"], "title": "DeepXPalm: Tilt and Position Rendering using Palm-worn Haptic Display and CNN-based Tactile Pattern Recognition", "comment": "Accepted paper in IEEE Haptic Symposium 2022, IEEE copyright", "summary": "Telemanipulation of deformable objects requires high precision and dexterity\nfrom the users, which can be increased by kinesthetic and tactile feedback.\nHowever, the object shape can change dynamically, causing ambiguous perception\nof its alignment and hence errors in the robot positioning. Therefore, the tilt\nangle and position classification problem has to be solved to present a clear\ntactile pattern to the user. This work presents a telemanipulation system for\nplastic pipettes consisting of a multi-contact haptic device LinkGlide to\ndeliver haptic feedback at the users' palm and two tactile sensors array\nembedded in the 2-finger Robotiq gripper. We propose a novel approach based on\nConvolutional Neural Networks (CNN) to detect the tilt and position while\ngrasping deformable objects. The CNN generates a mask based on recognized tilt\nand position data to render further multi-contact tactile stimuli provided to\nthe user during the telemanipulation. The study has shown that using the CNN\nalgorithm and the preset mask, tilt, and position recognition by users is\nincreased from 9.67% using the direct data to 82.5%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCNN\u7684\u503e\u659c\u89d2\u5ea6\u548c\u4f4d\u7f6e\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u67d4\u6027\u7269\u4f53\u9065\u64cd\u4f5c\u4e2d\u7684\u89e6\u89c9\u53cd\u9988\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7528\u6237\u7684\u8bc6\u522b\u51c6\u786e\u7387", "motivation": "\u67d4\u6027\u7269\u4f53\u7684\u9065\u64cd\u4f5c\u9700\u8981\u9ad8\u7cbe\u5ea6\u548c\u7075\u5de7\u6027\uff0c\u4f46\u7269\u4f53\u5f62\u72b6\u7684\u52a8\u6001\u53d8\u5316\u4f1a\u5bfc\u81f4\u5bf9\u5176\u5bf9\u9f50\u72b6\u6001\u7684\u611f\u77e5\u6a21\u7cca\uff0c\u4ece\u800c\u9020\u6210\u673a\u5668\u4eba\u5b9a\u4f4d\u9519\u8bef", "method": "\u4f7f\u7528\u591a\u89e6\u70b9\u89e6\u89c9\u8bbe\u5907LinkGlide\u548c\u5d4c\u5165Robotiq\u4e8c\u6307\u5939\u5177\u7684\u89e6\u89c9\u4f20\u611f\u5668\u9635\u5217\uff0c\u63d0\u51fa\u57fa\u4e8e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc(CNN)\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u6293\u53d6\u67d4\u6027\u7269\u4f53\u65f6\u7684\u503e\u659c\u89d2\u5ea6\u548c\u4f4d\u7f6e", "result": "\u901a\u8fc7CNN\u7b97\u6cd5\u548c\u9884\u8bbe\u63a9\u7801\uff0c\u7528\u6237\u5bf9\u503e\u659c\u89d2\u5ea6\u548c\u4f4d\u7f6e\u7684\u8bc6\u522b\u51c6\u786e\u7387\u4ece\u76f4\u63a5\u6570\u636e\u76849.67%\u63d0\u5347\u523082.5%", "conclusion": "\u57fa\u4e8eCNN\u7684\u503e\u659c\u89d2\u5ea6\u548c\u4f4d\u7f6e\u68c0\u6d4b\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8\u67d4\u6027\u7269\u4f53\u9065\u64cd\u4f5c\u4e2d\u89e6\u89c9\u53cd\u9988\u7684\u6e05\u6670\u5ea6\u548c\u7528\u6237\u611f\u77e5\u51c6\u786e\u6027"}}
{"id": "2409.15838", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2409.15838", "abs": "https://arxiv.org/abs/2409.15838", "authors": ["Miguel Altamirano Cabrera", "Jonathan Tirado", "Aleksey Fedoseev", "Oleg Sautenkov", "Vladimir Poliakov", "Pavel Kopanev", "Dzmitry Tsetserukou"], "title": "TiltXter: CNN-based Electro-tactile Rendering of Tilt Angle for Telemanipulation of Pasteur Pipettes", "comment": "Manuscript accepted to IEEE Telepresence 2024. arXiv admin note: text\n  overlap with arXiv:2204.03521 by other authors", "summary": "The shape of deformable objects can change drastically during grasping by\nrobotic grippers, causing an ambiguous perception of their alignment and hence\nresulting in errors in robot positioning and telemanipulation. Rendering clear\ntactile patterns is fundamental to increasing users' precision and dexterity\nthrough tactile haptic feedback during telemanipulation. Therefore, different\nmethods have to be studied to decode the sensors' data into haptic stimuli.\nThis work presents a telemanipulation system for plastic pipettes that consists\nof a Force Dimension Omega.7 haptic interface endowed with two\nelectro-stimulation arrays and two tactile sensor arrays embedded in the\n2-finger Robotiq gripper. We propose a novel approach based on convolutional\nneural networks (CNN) to detect the tilt of deformable objects. The CNN\ngenerates a tactile pattern based on recognized tilt data to render further\nelectro-tactile stimuli provided to the user during the telemanipulation. The\nstudy has shown that using the CNN algorithm, tilt recognition by users\nincreased from 23.13\\% with the downsized data to 57.9%, and the success rate\nduring teleoperation increased from 53.12% using the downsized data to 92.18%\nusing the tactile patterns generated by the CNN.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc(CNN)\u7684\u89e6\u89c9\u6a21\u5f0f\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u673a\u5668\u4eba\u9065\u64cd\u4f5c\u4e2d\u68c0\u6d4b\u53ef\u53d8\u5f62\u7269\u4f53\u7684\u503e\u659c\u89d2\u5ea6\uff0c\u5e76\u901a\u8fc7\u7535\u89e6\u89c9\u523a\u6fc0\u63d0\u9ad8\u7528\u6237\u7684\u611f\u77e5\u7cbe\u5ea6\u548c\u64cd\u4f5c\u6210\u529f\u7387\u3002", "motivation": "\u53ef\u53d8\u5f62\u7269\u4f53\u5728\u673a\u5668\u4eba\u6293\u53d6\u8fc7\u7a0b\u4e2d\u5f62\u72b6\u4f1a\u53d1\u751f\u5267\u70c8\u53d8\u5316\uff0c\u5bfc\u81f4\u5bf9\u5176\u5bf9\u9f50\u72b6\u6001\u7684\u611f\u77e5\u6a21\u7cca\uff0c\u4ece\u800c\u5f15\u8d77\u673a\u5668\u4eba\u5b9a\u4f4d\u548c\u9065\u64cd\u4f5c\u9519\u8bef\u3002\u9700\u8981\u6e05\u6670\u7684\u89e6\u89c9\u6a21\u5f0f\u6765\u63d0\u9ad8\u7528\u6237\u5728\u89e6\u89c9\u53cd\u9988\u4e0b\u7684\u7cbe\u786e\u5ea6\u548c\u7075\u5de7\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u9065\u64cd\u4f5c\u7cfb\u7edf\uff0c\u5305\u62ec\u5e26\u6709\u7535\u523a\u6fc0\u9635\u5217\u7684Force Dimension Omega.7\u89e6\u89c9\u63a5\u53e3\u548c\u5d4c\u5165Robotiq\u4e8c\u6307\u5939\u722a\u7684\u89e6\u89c9\u4f20\u611f\u5668\u9635\u5217\u3002\u63d0\u51fa\u57fa\u4e8eCNN\u7684\u65b9\u6cd5\u68c0\u6d4b\u53ef\u53d8\u5f62\u7269\u4f53\u503e\u659c\uff0c\u5e76\u751f\u6210\u89e6\u89c9\u6a21\u5f0f\u7528\u4e8e\u7535\u89e6\u89c9\u523a\u6fc0\u3002", "result": "\u4f7f\u7528CNN\u7b97\u6cd5\u540e\uff0c\u7528\u6237\u503e\u659c\u8bc6\u522b\u7387\u4ece23.13%(\u964d\u7ef4\u6570\u636e)\u63d0\u9ad8\u523057.9%\uff0c\u9065\u64cd\u4f5c\u6210\u529f\u7387\u4ece53.12%(\u964d\u7ef4\u6570\u636e)\u63d0\u9ad8\u523092.18%(CNN\u751f\u6210\u7684\u89e6\u89c9\u6a21\u5f0f)\u3002", "conclusion": "\u57fa\u4e8eCNN\u7684\u89e6\u89c9\u6a21\u5f0f\u751f\u6210\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u7528\u6237\u5728\u9065\u64cd\u4f5c\u4e2d\u5bf9\u53ef\u53d8\u5f62\u7269\u4f53\u503e\u659c\u7684\u611f\u77e5\u80fd\u529b\u548c\u64cd\u4f5c\u6210\u529f\u7387\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u89e6\u89c9\u53cd\u9988\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
