<div id=toc></div>

# Table of Contents

- [cs.CY](#cs.CY) [Total: 27]
- [q-fin.GN](#q-fin.GN) [Total: 2]
- [cs.AI](#cs.AI) [Total: 70]
- [cs.ET](#cs.ET) [Total: 3]
- [econ.GN](#econ.GN) [Total: 9]
- [econ.EM](#econ.EM) [Total: 7]
- [econ.TH](#econ.TH) [Total: 5]
- [cs.RO](#cs.RO) [Total: 48]
- [cs.SI](#cs.SI) [Total: 3]
- [eess.SY](#eess.SY) [Total: 24]
- [stat.AP](#stat.AP) [Total: 9]


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [1] [Large Language Models in Architecture Studio: A Framework for Learning Outcomes](https://arxiv.org/abs/2510.15936)
*Juan David Salazar Rodriguez,Sam Conrad Joyce,Nachamma Sockalingam,Julfendi*

Main category: cs.CY

TL;DR: 本研究探讨了大型语言模型在建筑教育核心——设计工作室中的角色，提出LLMs可作为教学工具增强学生自主性、协作和自我反思能力，而非仅用于形式生成和自动化。


<details>
  <summary>Details</summary>
Motivation: 传统建筑设计工作室依赖体验式学习，但AI在该环境中的应用主要关注形式生成和效率，忽视了其作为教学工具的潜力，特别是在支持学生自主性、协作和自我反思方面。

Method: 识别建筑教育中自主学习、同伴学习和教师指导学习过程中的教学挑战，提出基于LLM的AI干预措施，并将这些干预与布鲁姆分类法的可衡量学习成果对齐。

Result: 研究发现主要挑战包括管理学生自主性、同伴反馈中的紧张关系，以及平衡技术知识传授与创造力激发。LLMs能够生成个性化反馈、组织协作互动并提供适应性认知支架。

Conclusion: LLMs可作为补充性教学工具，通过促进建筑概念的记忆理解、支持应用分析，以及鼓励综合评估，有效应对建筑教育中的教学挑战。

Abstract: The study explores the role of large language models (LLMs) in the context of
the architectural design studio, understood as the pedagogical core of
architectural education. Traditionally, the studio has functioned as an
experiential learning space where students tackle design problems through
reflective practice, peer critique, and faculty guidance. However, the
integration of artificial intelligence (AI) in this environment has been
largely focused on form generation, automation, and representation-al
efficiency, neglecting its potential as a pedagogical tool to strengthen
student autonomy, collaboration, and self-reflection. The objectives of this
research were: (1) to identify pedagogical challenges in self-directed,
peer-to-peer, and teacher-guided learning processes in architecture studies;
(2) to propose AI interventions, particularly through LLM, that contribute to
overcoming these challenges; and (3) to align these interventions with
measurable learning outcomes using Bloom's taxonomy. The findings show that the
main challenges include managing student autonomy, tensions in peer feedback,
and the difficulty of balancing the transmission of technical knowledge with
the stimulation of creativity in teaching. In response to this, LLMs are
emerging as complementary agents capable of generating personalized feedback,
organizing collaborative interactions, and offering adaptive cognitive
scaffolding. Furthermore, their implementation can be linked to the cognitive
levels of Bloom's taxonomy: facilitating the recall and understanding of
architectural concepts, supporting application and analysis through interactive
case studies, and encouraging synthesis and evaluation through hypothetical
design scenarios.

</details>


### [2] [Enabling Responsible, Secure and Sustainable Healthcare AI - A Strategic Framework for Clinical and Operational Impact](https://arxiv.org/abs/2510.15943)
*Jimmy Joseph*

Main category: cs.CY

TL;DR: 提出了一个实用的医疗AI操作化框架，包含五个关键支柱，通过两个实际部署案例验证了其有效性，展示了在确保安全、合规的同时提升医疗效果的能力。


<details>
  <summary>Details</summary>
Motivation: 旨在将世界级技术卓越性与组织准备度相结合，操作化负责任、安全、可持续的医疗AI，实现'合规设计'并提供可衡量的影响。

Method: 开发包含五个关键支柱的框架：领导力与战略、MLOps与技术基础设施、治理与伦理、教育与劳动力发展、变革管理与采用。通过两个实际部署案例验证：住院时长预测服务和AI增强的放射学二次阅片系统。

Result: 住院时长预测服务R²=0.41-0.58，采用率78%，复杂病例平均住院时长相对下降5-10%；AI放射学系统灵敏度95%，亚厘米可操作发现检测提升8.0个百分点，工作流程未受影响。两个服务均在受监控、可审计的管道中执行，无安全事件。

Conclusion: 通过结合强大的MLOps和AI安全性与治理、教育、以人为本的变革管理，可以在提高安全性和结果的同时加速AI的采用。

Abstract: We offer a pragmatic model to operationalize responsible, secure, and
sustainable healthcare AI, aligning world-class technical excellence with
organizational readiness. The framework includes five key pillars - Leadership
& Strategy, MLOps & Technical Infrastructure, Governance & Ethics, Education &
Workforce Development, and Change Management & Adoption - and is intended to
operationalize 'compliance-by-design' while delivering measurable impact. We
demonstrate its utility through two deployments. (A) An inpatient length of
stay (LOS) prediction service had R^2=0.41-0.58 with validation cohorts in an
observational pilot (n = 3,184 encounters, 4 units, June-August 2025). Adoption
was 78 percent by week 6, and target units saw 5-10 percent relative declines
in mean LOS for complex cases vs. pre-pilot baselines. (B) An AI-augmented
radiology second-reader for lung nodules (PACS-integrated with thresholding and
explanation overlays) achieved high sensitivity (95 percent) and provided a
+8.0 percentage-point lift in detection of sub-centimeter actionable findings,
without slowing workflow (median report TAT 23 min, p = 0.64). Both services
executed in monitored, auditable pipelines with well-defined rollback, bias
checks, and no evidence of security incidents. These findings indicate that by
combining strong MLOps and AI security with governance, education, and
human-centric change, we can accelerate adoption of AI while improving security
and outcomes. We end with limitations, generalization considerations, and a
roadmap for scaling across varied clinical and operational use cases.

</details>


### [3] [Attention to Non-Adopters](https://arxiv.org/abs/2510.15951)
*Kaitlyn Zhou,Kristina Gligorić,Myra Cheng,Michelle S. Lam,Vyoma Raman,Boluwatife Aminu,Caeley Woo,Michael Brockman,Hannah Cha,Dan Jurafsky*

Main category: cs.CY

TL;DR: 尽管语言模型聊天系统日益普及，但大多数美国人仍未采用聊天式LLM。本文主张将非采用者视角纳入LLM开发至关重要，以避免加剧不平等和开发盲点。


<details>
  <summary>Details</summary>
Motivation: 当前LLM开发和评估主要依赖采用者数据，忽视了占人口多数的非采用者群体，这可能导致模型无法满足广泛用户需求并加剧技术不平等。

Method: 通过案例研究分析非采用者的需求，展示其与现有用户需求的差异，并探索如何通过以人为中心的方法系统整合非采用者需求。

Result: 研究发现非采用者的需求与现有用户存在显著差异，这些需求指向了新颖的推理任务，为LLM开发提供了新的方向。

Conclusion: 必须将非采用者视角纳入LLM开发过程，以确保模型具有广泛适用性，避免技术不平等，并发现新的任务类型。

Abstract: Although language model-based chat systems are increasingly used in daily
life, most Americans remain non-adopters of chat-based LLMs -- as of June 2025,
66% had never used ChatGPT. At the same time, LLM development and evaluation
rely mainly on data from adopters (e.g., logs, preference data), focusing on
the needs and tasks for a limited demographic group of adopters in terms of
geographic location, education, and gender. In this position paper, we argue
that incorporating non-adopter perspectives is essential for developing broadly
useful and capable LLMs. We contend that relying on methods that focus
primarily on adopters will risk missing a range of tasks and needs prioritized
by non-adopters, entrenching inequalities in who benefits from LLMs, and
creating oversights in model development and evaluation. To illustrate this
claim, we conduct case studies with non-adopters and show: how non-adopter
needs diverge from those of current users, how non-adopter needs point us
towards novel reasoning tasks, and how to systematically integrate non-adopter
needs via human-centered methods.

</details>


### [4] [Impact of AI Tools on Learning Outcomes: Decreasing Knowledge and Over-Reliance](https://arxiv.org/abs/2510.16019)
*Márton Benedek,Balázs R. Sziklai*

Main category: cs.CY

TL;DR: 研究调查了生成式AI工具对学生学习成果的影响，发现不受控制的AI使用会导致学生参与度低、对材料理解不足，且AI工具已成为学生不可或缺的学习依赖。


<details>
  <summary>Details</summary>
Motivation: 随着学生在各教育层级越来越依赖生成式AI工具完成作业和考试，需要了解这种依赖如何影响他们的学习动机、真正理解程度以及知识获取过程。

Method: 在布达佩斯科维努斯大学的运筹学课程中进行随机对照实验，将学生分为允许使用AI工具组和不允许使用AI工具组，并引入补偿机制确保公平性。

Result: 尽管实验因学生强烈反对而被迫修改，但数据显示不受控制的AI使用导致学生参与度低、对材料理解不足。学生的极端反应表明AI工具已成为他们不可或缺的学习依赖。

Conclusion: 生成式AI工具已经深度融入学生学习过程，这对学习过程的有效性提出了根本性质疑，需要重新思考教育评估方法。

Abstract: Students at all levels of education are increasingly relying on generative
artificial intelligence (AI) tools to complete assignments and achieve higher
exam scores. However, it remains unclear how this reliance affects their
motivation, their genuine understanding of the material, and the extent to
which it substitutes for the process of knowledge acquisition. To investigate
the impact of generative AI on learning outcomes, an experiment was conducted
at Corvinus University of Budapest. In an operations research class, students
were randomly assigned into two groups: one was permitted to use AI tools
during classes and examinations, while the other was not. To ensure fairness, a
compensation mechanism was introduced: students in the lower-performing group
received point adjustments until the average performance of the two groups was
equalized. Despite the organizers' best efforts to explain the design and to
create equal opportunities for all participants, many students perceived the
experiment as a major disruption. Although the experiment was approved by every
relevant university authority -- including the Ethics Board, the Head of
Department, the Program Director, and the Student Council -- students escalated
their concerns to the media and eventually to the State Secretary for Higher
Education of Hungary. As a result, the experiment had to be substantially
revised before completion: on the final exam the test group was merged with the
control group. Still, the data allowed us to draw decisive conclusions
regarding the students' learning habits. Uncontrolled use of AI tools leads to
disengaged students and low understanding of material. The extreme reactions of
the students proved even more revealing than the data collected: generative AI
tools have already become indispensable for students, raising fundamental
questions about the validity of their learning process.

</details>


### [5] [A dual typology of social media interventions and deterrence mechanisms against misinformation](https://arxiv.org/abs/2510.16032)
*Amir Karami*

Main category: cs.CY

TL;DR: 该论文提出了一个双类型学框架，将社交媒体平台的五种干预措施（移除、减少、告知、复合、多模式）映射到五种威慑机制（硬威慑、情境威慑、软威慑、综合威慑、混合威慑），以解释平台如何独立和集体地应对虚假信息威胁。


<details>
  <summary>Details</summary>
Motivation: 应对虚假信息日益严重的威胁，目前缺乏一个宏观层面的视角来解释各种平台干预措施如何独立和集体运作。

Method: 基于威慑理论，借鉴国际关系、军事、网络安全和公共卫生领域的经验，构建了一个干预措施与威慑机制的双类型学框架。

Result: 成功将五种平台干预措施映射到五种相应的威慑机制，揭示了平台如何应用不同程度的威慑机制来影响用户行为。

Conclusion: 该框架为理解平台干预措施提供了连贯的宏观视角，阐明了不同干预措施如何通过威慑机制独立和协同运作来应对虚假信息。

Abstract: In response to the escalating threat of misinformation, social media
platforms have introduced a wide range of interventions aimed at reducing the
spread and influence of false information. However, there is a lack of a
coherent macrolevel perspective that explains how these interventions operate
independently and collectively. To address this gap, I offer a dual typology
through a spectrum of interventions aligned with deterrence theory and drawing
parallels from international relations, military, cybersecurity, and public
health. I argue that five major types of platform interventions, including
removal, reduction, informing, composite, and multimodal, can be mapped to five
corresponding deterrence mechanisms, including hard, situational, soft,
integrated, and mixed deterrence based on purpose and perceptibility. These
mappings illuminate how platforms apply varying degrees of deterrence
mechanisms to influence user behavior.

</details>


### [6] [Does Capital Dream of Artificial Labour?](https://arxiv.org/abs/2510.16042)
*Marcin Korecki,Cesare Carissimo*

Main category: cs.CY

TL;DR: 该论文将劳动定义为"时间能量"的商品化表达，通过博弈论和基于代理的模拟揭示了资本在资本-劳动互动中的组织优势，质疑在自动化未来中生命能否脱离资本基础设施而存在。


<details>
  <summary>Details</summary>
Motivation: 研究劳动作为时间能量融合体在资本体系中的纠缠关系，探讨资本作为人工生命系统如何通过消耗活劳动而存在，以及自动化时代生命可持续性的问题。

Method: 使用博弈论和基于代理的模拟方法，在柯布-道格拉斯生产函数框架下建模资本与劳动的互动过程。

Result: 尽管理论上存在对称性，但学习代理明显倾向于资本密集型过程，揭示了资本因其积累能力而具有更强的组织影响力。

Conclusion: 资本是一个由消耗活劳动而激活的人工生命系统，研究提供了理解劳动在资本体系中从属地位的批判框架，并质疑自动化未来中生命对资本基础设施的依赖性。

Abstract: This paper investigates the concept of Labour as an expression of `timenergy'
- a fusion of time and energy - and its entanglement within the system of
Capital. We define Labour as the commodified, quantifiable expansion of
timenergy, in contrast to Capital, which is capable of accumulation and
abstraction. We explore Labour's historical evolution, its coercive and
alienating nature, and its transformation through automation and artificial
intelligence. Using a game-theoretic, agent-based simulation, we model
interactions between Capital and Labour in production processes governed by
Cobb-Douglas functions. Our results show that despite theoretical symmetry,
learning agents disproportionately gravitate toward capital-intensive
processes, revealing Capital's superior organizational influence due to its
accumulative capacity. We argue that Capital functions as an artificially alive
system animated by the living Labour it consumes, and question whether life can
sustain itself without the infrastructures of Capital in a future of increasing
automation. This study offers both a critique of and a framework for
understanding Labour's subjugation within the Capital system.

</details>


### [7] [Open Shouldn't Mean Exempt: Open-Source Exceptionalism and Generative AI](https://arxiv.org/abs/2510.16048)
*David Atkinson*

Main category: cs.CY

TL;DR: 该论文批判了开源GenAI天然具有伦理或法律优势的观点，指出当前开源GenAI往往助长非法行为和环境破坏，且未真正打破寡头垄断。论文主张开源开发者应承担与其他技术参与者相同的法律和伦理责任，同时为合法的非商业科学研究提供有限的安全港保护。


<details>
  <summary>Details</summary>
Motivation: 针对多个开源GenAI实体声称其系统因开源而天然具有伦理或法律优势的立场，论文旨在批判这种"开源例外主义"的流行辩护，揭示其如何为监管豁免提供不正当理由。

Method: 通过批判性分析，论文检视了开源GenAI的常见辩护理由，包括"民主化"和"创新"等修辞的战略性使用，以及这些系统在实际运行中如何促进非法活动和环境问题。

Result: 研究发现当前开源GenAI往往无意中促进非法行为和环境退化，且未能真正颠覆现有寡头垄断。论文还揭示了"民主化"和"创新"等修辞被策略性地用于争取监管豁免。

Conclusion: 开源开发者应与其他技术参与者承担相同的法律和伦理责任。论文提议为合法的非商业科学研究设立有限的安全港保护，并倡导在既定伦理和法律边界内追求开放性的负责任AI发展框架。

Abstract: Any argument that open-source generative artificial intelligence (GenAI) is
inherently ethical or legal solely because it is open source is flawed. Yet,
this is the explicit or implicit stance of several open-source GenAI entities.
This paper critically examines prevalent justifications for "open-source
exceptionalism," demonstrating how contemporary open-source GenAI often
inadvertently facilitates unlawful conduct and environmental degradation
without genuinely disrupting established oligopolies. Furthermore, the paper
exposes the unsubstantiated and strategic deployment of "democratization" and
"innovation" rhetoric to advocate for regulatory exemptions not afforded to
proprietary systems.
  The conclusion is that open-source developers must be held to the same legal
and ethical standards as all other actors in the technological ecosystem.
However, the paper proposes a narrowly tailored safe harbor designed to protect
legitimate, non-commercial scientific research, contingent upon adherence to
specific criteria. Ultimately, this paper advocates for a framework of
responsible AI development, wherein openness is pursued within established
ethical and legal boundaries, with due consideration for its broader societal
implications.

</details>


### [8] [In the Mood to Exclude: Revitalizing Trespass to Chattels in the Era of GenAI Scraping](https://arxiv.org/abs/2510.16049)
*David Atkinson*

Main category: cs.CY

TL;DR: 论文主张网站所有者有权排除他人访问其网站，当生成式AI抓取机器人规避技术障碍时，其行为可构成动产侵权。法院应关注网站作为数字资产的价值损害，而非仅关注服务器损害。


<details>
  <summary>Details</summary>
Motivation: 当前法院过度关注网站内容而非网站本身作为数字财产的性质，导致大规模网络抓取难以有效监管。版权优先原则限制了可用诉讼主张，需要重新确立网站作为个人财产的法律地位。

Method: 通过将分析焦点从内容转向网站作为集成数字资产，论证动产侵权在网络环境中的适用性。主张网站应被视为个人财产，从而恢复动产侵权作为有效的诉讼理由。

Result: 承认网站为个人财产可使动产侵权成为有意义的诉讼主张，为网站所有者提供可执行的排他权，阻止剥削性抓取行为。

Conclusion: 重申网站所有者的排他权对于维护公平可持续的网络环境至关重要，有助于保护内容创作激励、隐私和个人数据，以及自主权和表达价值。

Abstract: This paper argues that website owners have the right to exclude others from
their websites. Accordingly, when generative AI (GenAI) scraping bots
intentionally circumvent reasonable technological barriers, their conduct could
be actionable as trespass to chattels. If the scraping leads to a decrease in
the website's value, then trespass to chattels should apply. The prevailing
judicial focus on website content and the dismissal of trespass claims absent
proof of server impairment or user disruption misconstrues the nature of the
website itself as a form of digital property, focusing too narrowly on what
constitutes harm under a claim of trespass. By shifting analysis from content
to the website itself as an integrated digital asset and illustrating the harm
to the value of the chattel, this paper demonstrates that the right to exclude
applies online with the same force as it does to tangible property.
  Courts and litigants have struggled to police large-scale scraping because
copyright preemption narrows available claims, leaving copyright and its fair
use defense as the primary battleground. In contrast, recognizing websites as
personal property revives trespass to chattels as a meaningful cause of action,
providing website owners with an enforceable exclusionary right. Such
protection would disincentivize exploitative scraping, preserve incentives for
content creation, aid in protecting privacy and personal data, and safeguard
values of autonomy and expression. Ultimately, this paper contends that
reaffirming website owners' right to exclude is essential to maintaining a fair
and sustainable online environment.

</details>


### [9] [A Framework For Decentralized Micro-credential Verification Towards Higher Qualifications](https://arxiv.org/abs/2510.16050)
*Abrar Mahbub,Humira Saria,Md. Foysal Hossain,Nafees Mansoor*

Main category: cs.CY

TL;DR: 本文提出了一种基于区块链技术的微证书验证原型系统，旨在解决教育机构间微证书学分转移的标准化问题，通过结合链上和链下技术提高验证效率。


<details>
  <summary>Details</summary>
Motivation: 教育机构面临学生保留率下降、课程相关性、学生参与度等问题，微证书作为短期学术项目缺乏标准化评估和学分转移机制，区块链技术可提供去中心化、不可篡改的凭证验证平台。

Method: 开发基于Hyper-ledger Fabric平台的微证书验证原型，采用链下技术作为中间存储平台，结合链上和链下技术减少区块链拥堵，提高交易速度。教育机构根据政策验证微证书证书，审核评估标准并提供课程豁免。

Result: 原型系统成功实现了微证书的安全验证和更高效的课程豁免流程，通过链下存储技术缓解了区块链拥堵问题，提升了交易处理速度。

Conclusion: 区块链技术为微证书验证提供了可行的解决方案，结合链上和链下技术的方法能够有效解决教育机构间学分转移的标准化挑战，为微证书的广泛应用奠定了基础。

Abstract: Student retention is one of the rising problems seen in educational
institutions. With the rising cost of education and issues in the education
sector, such as curriculum relevance, student engagement, and rapidly changing
technological advancements, ensuring the relevance of academic programs in a
fast-evolving job market has created a significant concern for educational
institutions. With the intent to adapt to such challenges, educational
institutions are dealing with alternative solutions for education, in which
micro-credentials are at the very center of this, which are short-term academic
programs or standalone courses. However, one of the challenges of
micro-credentials is a lack of credit transfer among institutions. With the
lack of standardization of assessments among educational institutions, it is
difficult to transfer micro-credentials to larger qualifications. Regarding
such challenges, micro-credentials with blockchain technology can bring
significant benefits. Blockchain technology offers a decentralized and
immutable platform for securely storing and verifying credentials. This paper
presents a prototype model for micro-credential verification. With the policies
decided by the educational institution, the learner provides a micro-credential
certificate to the system. Upon validation of the certificate by the verifying
body, the educational institution will review the assessment criteria and
provide exemptions based on the provided criteria. The prototype uses the
Hyper-ledger Fabric platform and utilizes off-chain technology, which acts as a
middle-man storage platform. With the combination of off-chain and on-chain
technologies, congestion on the blockchain is reduced, and transaction speed is
improved. In summary, this research proposes a prototype for secure
micro-credential verification and a more efficient course exemption process.

</details>


### [10] [Reducing Procrastination on Programming Assignments via Optional Early Feedback](https://arxiv.org/abs/2510.16052)
*Alice Gao,Victoria Sakhnini*

Main category: cs.CY

TL;DR: 该研究设计了一种通过早期非评分截止日期提供额外自动反馈的干预措施，来对抗计算机科学本科生在复杂编程作业中的学术拖延行为。干预显著增加了学生早期开始作业的比例，虽然整体成绩无显著差异，但使用干预的学生比未使用者成绩更高。


<details>
  <summary>Details</summary>
Motivation: 学术拖延在计算机科学本科生中普遍存在，尤其对高年级学生面对大型复杂编程作业时危害更大，会导致学业成绩和心理健康问题。

Method: 设计干预措施：设置早期非评分截止日期，提前提交可获得额外自动反馈。通过对照组与干预组的比较评估效果，并进行半结构化访谈了解学生感知。

Result: 干预显著增加了早期开始作业的学生比例。干预组内使用干预的学生成绩显著高于未使用者。访谈显示学生从干预中获益，包括学业表现、心理健康和软技能提升。

Conclusion: 仅早期开始作业不能提高成绩，但早期开始并接收额外反馈能显著提升成绩。学生采用干预的主要动机是获取更多反馈、满足好奇心和利用可用时间，不采用的主要原因是其他截止日期冲突、干预不计分和自信过度。

Abstract: Academic procrastination is prevalent among undergraduate computer science
students. Many studies have linked procrastination to poor academic performance
and well-being. Procrastination is especially detrimental for advanced students
when facing large, complex programming assignments in upper-year courses. We
designed an intervention to combat academic procrastination on such programming
assignments. The intervention consisted of early deadlines that were not worth
marks but provided additional automated feedback if students submitted their
work early. We evaluated the intervention by comparing the behaviour and
performance of students between a control group and an intervention group. Our
results showed that the intervention encouraged significantly more students to
start the assignments early. Although there was no significant difference in
students' grades between the control and intervention groups, students within
the intervention group who used the intervention achieved significantly higher
grades than those who did not. Our results implied that starting early alone
did not improve students' grades. However, starting early and receiving
additional feedback enhanced the students' grades relative to those of the rest
of the students. We also conducted semi-structured interviews to gain an
understanding of students' perceptions of the intervention. The interviews
revealed that students benefited from the intervention in numerous ways,
including improved academic performance, mental health, and development of soft
skills. Students adopted the intervention to get more feedback, satisfy their
curiosity, or use their available time. The main reasons for not adopting the
intervention include having other competing deadlines, the intervention not
being worth any marks, and feeling confident about their work.

</details>


### [11] [Algorithmic Fairness in AI Surrogates for End-of-Life Decision-Making](https://arxiv.org/abs/2510.16056)
*Muhammad Aurangzeb Ahmad*

Main category: cs.CY

TL;DR: 本文探讨了AI代理系统在临终决策中的公平性框架，指出传统算法公平性方法在此类关系性、存在性和文化多样性决策中的不足。


<details>
  <summary>Details</summary>
Motivation: AI代理系统用于在个人失去决策能力时推断其偏好，但该领域的公平性问题研究不足。传统算法公平性框架无法处理关系性、存在性和文化多样性决策的复杂性。

Method: 通过将主要公平性概念映射到现实世界临终场景，并跨道德传统检验公平性，建立AI代理的伦理公平性框架。

Result: 研究发现公平性在此领域超越了结果平等，需要包含道德代表性、对患者价值观的忠实度、人际关系和世界观。

Conclusion: AI代理系统中的公平性需要更全面的框架，涵盖道德代表性、价值观忠实度和关系维度，而不仅仅是结果平等。

Abstract: Artificial intelligence surrogates are systems designed to infer preferences
when individuals lose decision-making capacity. Fairness in such systems is a
domain that has been insufficiently explored. Traditional algorithmic fairness
frameworks are insufficient for contexts where decisions are relational,
existential, and culturally diverse. This paper explores an ethical framework
for algorithmic fairness in AI surrogates by mapping major fairness notions
onto potential real-world end-of-life scenarios. It then examines fairness
across moral traditions. The authors argue that fairness in this domain extends
beyond parity of outcomes to encompass moral representation, fidelity to the
patient's values, relationships, and worldview.

</details>


### [12] [Co-Designing Interdisciplinary Design Projects with AI](https://arxiv.org/abs/2510.16068)
*Wei Ting Liow,Sumbul Khan,Lay Kee Ang*

Main category: cs.CY

TL;DR: 本文介绍了IDPplanner，一个基于GPT的跨学科设计项目规划助手，通过实证研究表明AI辅助规划在课程对齐、设计思维应用和连贯性方面优于人工规划，同时强调教师与AI的混合工作流程。


<details>
  <summary>Details</summary>
Motivation: 教师创建跨学科设计项目耗时且认知负担重，需要课程对齐、跨学科整合和精心排序。国际研究显示教师使用AI增加但工作压力持续，需要规划支持。

Method: 开发基于GPT的IDPplanner规划助手，在33名在职教师的对比工作坊中，分别制作人工和AI辅助版本的项目，使用六维评分标准进行自评和互评。

Result: AI辅助版本在课程对齐、设计思维应用和连贯性方面得分更高，评估策略略有优势。教师反思表明AI辅助改善了结构、排序和创意生成，但情境化仍由教师主导。

Conclusion: AI可作为教学规划伙伴，建议采用混合教师-AI工作流程来增强课程对齐并减少规划复杂性，规划流程和评分标准具有框架无关性，可参数化适应其他系统。

Abstract: Creating interdisciplinary design projects is time-consuming and cognitively
demanding for teachers, requiring curriculum alignment, cross-subject
integration, and careful sequencing. International research reports increasing
teacher use of AI alongside persistent workload pressures, underscoring the
need for planning support. This paper presents the Interdisciplinary Design
Project Planner (IDPplanner), a GPT-based planning assistant grounded in Design
Innovation principles, alignment with Singapore secondary school syllabuses,
and 21st-century competencies. In a within-subject, counterbalanced workshop
with 33 in-service teachers, participants produced two versions of the same
project: manual and AI-assisted, followed by self- and peer-evaluations using a
six-dimensional rubric. The AI-assisted version received higher scores for
Curriculum Alignment, Design Thinking Application, and Coherence and Flow, with
a marginal advantage for Assessment Strategies. Teacher reflections indicated
that AI-assisted planning improved structure, sequencing, and idea generation,
while contextualization to local syllabuses, class profiles, and student needs
remained teacher-led. Contributions include a purpose-built planning tool that
organizes ideas into a ten-component flow with ready-to-adapt prompts,
templates, and assessment suggestions; an empirical, rubric-based comparison of
planning quality; and evidence that AI can function as a pedagogical planning
partner. Recommendations emphasize hybrid teacher-AI workflows to enhance
curriculum alignment and reduce planning complexity, and design suggestions for
developers to strengthen contextual customization, iterative design support,
and localized rubrics. Although instantiated with a Singapore-based curriculum,
the planning flow and rubric are framework-agnostic and can be parameterized
for other systems.

</details>


### [13] [Human or AI? Comparing Design Thinking Assessments by Teaching Assistants and Bots](https://arxiv.org/abs/2510.16069)
*Sumbul Khan,Wei Ting Liow,Lay Kee Ang*

Main category: cs.CY

TL;DR: 本研究探索AI辅助评估在创意设计教育中的可靠性，发现AI与教师评分在同理心和痛点维度一致性较低，教师更偏好人工评分，建议采用混合评估模型。


<details>
  <summary>Details</summary>
Motivation: 设计思维教育中，传统基于评分标准的评估方法在大规模教学中存在耗时、不一致的问题，需要探索AI辅助评估的可行性。

Method: 对33名新加坡教育部教师进行两项活动：比较AI与助教在同理心、痛点和视觉沟通三个维度的评分差异；调查教师对AI评分、助教评分和混合评分的偏好。

Result: AI与教师评分在同理心和痛点维度统计一致性低，视觉沟通维度一致性稍高；教师更偏好助教评分；定性反馈显示AI在形成性反馈和一致性方面有潜力，但缺乏情境理解和创意洞察。

Conclusion: 需要混合评估模型，结合计算效率与人类洞察力，在创意学科中平衡自动化与人工判断，实现可扩展且符合教学原理的评估。

Abstract: As design thinking education grows in secondary and tertiary contexts,
educators face the challenge of evaluating creative artefacts that combine
visual and textual elements. Traditional rubric-based assessment is laborious,
time-consuming, and inconsistent due to reliance on Teaching Assistants (TA) in
large, multi-section cohorts. This paper presents an exploratory study
investigating the reliability and perceived accuracy of AI-assisted assessment
compared to TA-assisted assessment in evaluating student posters in design
thinking education. Two activities were conducted with 33 Ministry of Education
(MOE) Singapore school teachers to (1) compare AI-generated scores with TA
grading across three key dimensions: empathy and user understanding,
identification of pain points and opportunities, and visual communication, and
(2) examine teacher preferences for AI-assigned, TA-assigned, and hybrid
scores. Results showed low statistical agreement between instructor and AI
scores for empathy and pain points, with slightly higher alignment for visual
communication. Teachers preferred TA-assigned scores in six of ten samples.
Qualitative feedback highlighted the potential of AI for formative feedback,
consistency, and student self-reflection, but raised concerns about its
limitations in capturing contextual nuance and creative insight. The study
underscores the need for hybrid assessment models that integrate computational
efficiency with human insights. This research contributes to the evolving
conversation on responsible AI adoption in creative disciplines, emphasizing
the balance between automation and human judgment for scalable and
pedagogically sound assessment.

</details>


### [14] [SARHAchat: An LLM-Based Chatbot for Sexual and Reproductive Health Counseling](https://arxiv.org/abs/2510.16081)
*Jiaye Yang,Xinyu Zhao,Tianlong Chen,Kandyce Brennan*

Main category: cs.CY

TL;DR: SARHAchat是一个基于大语言模型的聊天机器人，专门针对性健康和生殖健康领域设计，整合医学专业知识与同理心沟通，提供准确且情境适当的避孕咨询。


<details>
  <summary>Details</summary>
Motivation: 现有AI对话系统在复杂敏感的医疗领域（如性健康和生殖健康）表现不佳，存在幻觉问题和专业知识不足，且当前医疗AI方法过于侧重诊断能力而忽视全面患者护理和教育。

Method: 开发SARHAchat作为概念验证的大语言模型聊天机器人，整合医学专业知识与同理心沟通，专注于性健康和生殖健康护理。

Result: 评估显示SARHAchat能够提供准确且情境适当的避孕咨询，同时保持自然的对话流程。

Conclusion: SARHAchat证明了在性健康和生殖健康领域开发可靠、以用户为中心系统的可行性，能够增强该领域的护理服务提供。

Abstract: While Artificial Intelligence (AI) shows promise in healthcare applications,
existing conversational systems often falter in complex and sensitive medical
domains such as Sexual and Reproductive Health (SRH). These systems frequently
struggle with hallucination and lack the specialized knowledge required,
particularly for sensitive SRH topics. Furthermore, current AI approaches in
healthcare tend to prioritize diagnostic capabilities over comprehensive
patient care and education. Addressing these gaps, this work at the UNC School
of Nursing introduces SARHAchat, a proof-of-concept Large Language Model
(LLM)-based chatbot. SARHAchat is designed as a reliable, user-centered system
integrating medical expertise with empathetic communication to enhance SRH care
delivery. Our evaluation demonstrates SARHAchat's ability to provide accurate
and contextually appropriate contraceptive counseling while maintaining a
natural conversational flow. The demo is available at
https://sarhachat.com/}{https://sarhachat.com/.

</details>


### [15] [MoPHES:Leveraging on-device LLMs as Agent for Mobile Psychological Health Evaluation and Support](https://arxiv.org/abs/2510.16085)
*Xun Wei,Pukai Zhou,Zeyu Wang*

Main category: cs.CY

TL;DR: MoPHES是一个集成心理状态评估、对话支持和专业治疗建议的框架，使用两个微调的MiniCPM4-0.5B模型，可直接部署在移动设备上保护用户隐私。


<details>
  <summary>Details</summary>
Motivation: 全球心理健康问题日益严重，传统面对面治疗无法满足需求，通用大语言模型在心理健康领域表现不佳，现有聊天机器人缺乏实时心理状态评估能力。

Method: 开发MoPHES框架，使用两个专门微调的LLM：一个用于心理状态评估和焦虑抑郁严重程度预测，另一个用于多轮对话处理。模型可直接部署在移动设备上。

Result: 构建了自动评估心理状态预测和多轮咨询对话的基准，包括综合评估指标、数据集和方法。

Conclusion: MoPHES通过整合心理状态洞察提供更个性化的支持和专业治疗建议，同时保护用户隐私。

Abstract: The 2022 World Mental Health Report calls for global mental health care
reform, amid rising prevalence of issues like anxiety and depression that
affect nearly one billion people worldwide. Traditional in-person therapy fails
to meet this demand, and the situation is worsened by stigma. While
general-purpose large language models (LLMs) offer efficiency for AI-driven
mental health solutions, they underperform because they lack specialized
fine-tuning. Existing LLM-based mental health chatbots can engage in empathetic
conversations, but they overlook real-time user mental state assessment which
is critical for professional counseling. This paper proposes MoPHES, a
framework that integrates mental state evaluation, conversational support, and
professional treatment recommendations. The agent developed under this
framework uses two fine-tuned MiniCPM4-0.5B LLMs: one is fine-tuned on mental
health conditions datasets to assess users' mental states and predict the
severity of anxiety and depression; the other is fine-tuned on multi-turn
dialogues to handle conversations with users. By leveraging insights into
users' mental states, our agent provides more tailored support and professional
treatment recommendations. Both models are also deployed directly on mobile
devices to enhance user convenience and protect user privacy. Additionally, to
evaluate the performance of MoPHES with other LLMs, we develop a benchmark for
the automatic evaluation of mental state prediction and multi-turn counseling
dialogues, which includes comprehensive evaluation metrics, datasets, and
methods.

</details>


### [16] [Integrating LLM and Diffusion-Based Agents for Social Simulation](https://arxiv.org/abs/2510.16366)
*Xinyi Li,Zhiqiang Guo,Qinglang Guo,Hao Jin,Weizhi Ma,Min Zhang*

Main category: cs.CY

TL;DR: 提出了一种混合模拟框架，将LLM驱动代理与基于扩散模型的代理相结合，以平衡语义推理能力和计算效率，在三个真实数据集上验证了其预测准确性优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于代理的社会模拟方法的两个主要局限：传统代理模型缺乏文本内容的语义理解，而基于LLM的代理在大规模应用时计算成本过高。

Method: 采用混合模拟框架，使用LLM驱动代理模拟核心用户子集进行丰富语义推理，同时使用扩散模型高效处理其余用户群体，两种代理类型通过协调的模拟过程进行交互。

Result: 在三个真实世界数据集上的广泛实验表明，该框架在预测准确性方面优于现有方法，验证了其模块化设计的有效性。

Conclusion: 提出的混合模拟框架成功解决了传统代理模型和LLM代理的局限性，通过战略性地结合两种代理类型，实现了语义推理能力和计算效率的良好平衡。

Abstract: Agent-based social simulation provides a valuable methodology for predicting
social information diffusion, yet existing approaches face two primary
limitations. Traditional agent models often rely on rigid behavioral rules and
lack semantic understanding of textual content, while emerging large language
model (LLM)-based agents incur prohibitive computational costs at scale. To
address these challenges, we propose a hybrid simulation framework that
strategically integrates LLM-driven agents with diffusion model-based agents.
The framework employs LLM-based agents to simulate a core subset of users with
rich semantic reasoning, while a diffusion model handles the remaining
population efficiently. Although the two agent types operate on disjoint user
groups, both incorporate key factors including user personalization, social
influence, and content awareness, and interact through a coordinated simulation
process. Extensive experiments on three real-world datasets demonstrate that
our framework outperforms existing methods in prediction accuracy, validating
the effectiveness of its modular design.

</details>


### [17] [Women have it Worse: an ICT Workplace Digital Transformation Stress Gender Gap](https://arxiv.org/abs/2510.16459)
*Ewa Makowska-Tłumak,Sylwia Bedyńska,Kinga Skorupska,Radosław Nielek*

Main category: cs.CY

TL;DR: 研究发现数字化转型会给女性员工带来更高的数字转型压力，存在性别差距，需要通过解决方案和工具来支持女性在ICT密集型工作环境中的发展。


<details>
  <summary>Details</summary>
Motivation: 探讨数字化转型对员工福祉的影响，特别是由于对女性技术能力的负面刻板印象，可能导致女性员工在ICT工作环境中承受更大压力。

Method: 采用两种方法测量数字转型压力：对帮助台工单进行情感分析，以及使用心理量表进行自我报告调查。

Result: 研究结果证实了预测，显示女性员工在数字转型压力方面显著高于男性员工，存在明显的性别差距。

Conclusion: 需要在ICT密集型工作环境中讨论可能的解决方案和工具，以支持女性员工应对数字转型带来的挑战。

Abstract: Although information and communication technologies (ICT) solutions have
positive outcomes for both companies and employees, the digital transformation
(DT) could have an impact on the well-being of employees. The jobs of the
employees became more demanding, and they were expected to learn ICT skills and
cope with ICT workloads and hassles. Due to negative stereotypes about women's
deficiency in technology, these ICT problems could affect female and male
employees differently. Thus, we predicted that this additional pressure may
manifest itself in higher levels of digital transformation stress (DTS) in
female employees. The results confirmed this prediction and indicated the
existence of a gender gap in DTS, measured two-fold - in sentiment analysis of
help desk tickets and self-report using a psychological scale. Based on these
results, we explore the need to discuss possible solutions and tools to support
women in ICT-heavy workplace contexts.

</details>


### [18] [Global Overview of Computational Thinking and Digital Tools for Teaching](https://arxiv.org/abs/2510.16847)
*Roberto Massi De Oliveira,M^onica Cristina Garbin,Rodolfo Azevedo*

Main category: cs.CY

TL;DR: 本调查对各国学校课程中计算思维的整合情况进行了全面分析，将数字工具分类并评估其在不同教育环境中的使用，识别了计算思维能力的改进领域，并指出了实施挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 计算思维已成为现代教育的关键组成部分，需要培养学生适应技术驱动世界所需的技能。本研究旨在全面了解计算思维在学校课程中的整合现状。

Method: 采用调查分析方法，对各国学校课程中的计算思维整合进行系统分析，并将数字工具分类为可视化编程、文本编程、电子游戏、建模和仿真等类别，评估其在各种教育环境中的使用情况。

Result: 研究发现数字工具在提升计算思维能力方面发挥了重要作用，包括认知分析能力、技术计算能力以及社会情感能力。同时识别了实施过程中的主要挑战，如基础设施不足、工具可用性问题、教师培训需求等。

Conclusion: 研究强调了计算思维教育的重要性，提出了解决当前挑战的未来研究方向，以推动计算思维教育的进一步发展。

Abstract: Computational Thinking (CT) has emerged as a critical component in modern
education, essential to equip students with the skills necessary to thrive in a
technology-driven world. This survey provides a comprehensive analysis of the
presence and integration of CT in school curricula across various countries. In
addition, this study categorizes digital tools into groups such as visual
programming, textual programming, electronic games, modeling, and simulation,
assessing their use in different educational settings. Furthermore, it examines
how these tools are employed in various contexts, including the areas of
knowledge and age groups they target, and the specific skills they help
develop. The research also identifies key CT competencies that have been
improved through these tools, including Cognitive and Analytical Competencies
(CAC), Technical and Computational Competencies (TCC) and Social and Emotional
Competencies (SEC). Furthermore, the study highlights recurring challenges in
the implementation of digital tools for CT development, such as inadequate
infrastructure, difficulties in the usability of the tool, teacher training,
adapting pedagogical practices, and measuring student CT skills. Finally, it
proposes areas for future research to address these challenges and advance CT
education.

</details>


### [19] [Agentic Inequality](https://arxiv.org/abs/2510.16853)
*Matthew Sharp,Omer Bilgin,Iason Gabriel,Lewis Hammond*

Main category: cs.CY

TL;DR: 本文提出并探讨了"代理不平等"概念，即由于AI代理的获取和能力的差异导致的权力、机会和结果的不平等。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理系统融入政治经济生活，其分布和能力差异将产生重大影响，需要研究这种新型不平等现象。

Method: 建立分析框架，从可用性、质量和数量三个维度分析代理不平等；论证代理不平等与以往技术鸿沟的区别；系统分析技术和社会经济驱动因素。

Result: 识别了代理不平等的三个核心维度，阐明了其作为自主代理的独特性，并分析了影响代理权力分布的各种因素。

Conclusion: 代理不平等是一种新型技术鸿沟，需要制定研究议程来应对复杂的治理挑战，确保AI代理技术能够成为平等化力量而非加剧分化。

Abstract: Autonomous AI agents, capable of complex planning and action, represent a
significant technological evolution beyond current generative tools. As these
systems become integrated into political and economic life, their distribution
and capabilities will be highly consequential. This paper introduces and
explores "agentic inequality" - the potential disparities in power,
opportunity, and outcomes stemming from differential access to, and
capabilities of, AI agents. We analyse the dual potential of this technology,
exploring how agents could both exacerbate existing divides and, under the
right conditions, serve as a powerful equalising force. To this end, the paper
makes three primary contributions. First, it establishes an analytical
framework by delineating the three core dimensions through which this
inequality can manifest: disparities in the availability, quality, and quantity
of agents. Second, it argues that agentic inequality is distinct from prior
technological divides. Unlike tools that primarily augment human abilities,
agents act as autonomous delegates, creating novel power asymmetries through
scalable goal delegation and direct agent-to-agent competition that are poised
to reshape outcomes across economic and socio-political spheres. Finally, it
provides a systematic analysis of the technical and socioeconomic drivers -
from model release strategies to market incentives - that will shape the
distribution of agentic power, concluding with a research agenda for navigating
the complex governance challenges ahead.

</details>


### [20] [Sustainable and Adaptive Growth in Creative Tech](https://arxiv.org/abs/2510.16858)
*Enes Ayalp*

Main category: cs.CY

TL;DR: CLEAR CORE框架通过将结构化教育与独立成长相结合，帮助创意技术从业者在快速变化的环境中持续发展技能。


<details>
  <summary>Details</summary>
Motivation: 创意技术领域快速演变，现有教育路径难以确保稳定职业发展，专业技能容易因技术变化而过时。

Method: 提出CLEAR CORE框架，整合两个迭代互连的循环，将结构化教育与独立成长结合为持续过程。

Result: 该框架为创意技术专业人士提供终身可更新的实践方法。

Conclusion: CLEAR CORE框架能够帮助从业者在持续变化的环境中保持竞争力并取得成功。

Abstract: The creative technology evolves rapidly in both scope and depth, demanding
cross-disciplinary expertise and continuous improvement. Although educational
programs and other collaborative initiatives enable strong technical and
artistic skills, even the most advanced pathways rarely ensure a stable career.
Success in these professions often depends on visibility, timing, and
self-directed development. As markets shift or technologies change, talents
still find themselves displaced. Existing learning paths often fail to connect
the skills they teach, leaving learners with fragmented expertise that decays
quickly when not continuously applied. The industry demands depth, yet
specialization carries risk when tools, pipelines, or roles evolve faster than
the expertise built around them. Broad skill sets, by contrast, may increase
employability but are easily replaced or rendered obsolete by technological
change. CLEAR CORE is a framework for learning and sustaining in creative
technology. It integrates two iterative interconnected cycles into a continuous
process linking structured education with independent growth as a lifelong,
renewable practice that allows professionals to excel amid constant change.

</details>


### [21] [Learning Ecology with VERA Using Conceptual Models and Simulations](https://arxiv.org/abs/2510.16944)
*Spencer Rugaber,Scott Bunin,Andrew Hornback,Sungeun An,Ashok Goel*

Main category: cs.CY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Conceptual modeling has been an important part of constructionist educational
practices for many years, particularly in STEM (Science, Technology,
Engineering and Mathematics) disciplines. What is not so common is using
agent-based simulation to provide students feedback on model quality. This
requires the capability of automatically compiling the concept model into its
simulation. The VERA (Virtual Experimentation Research Assistant) system is a
conceptual modeling tool used since 2016 to provide introductory college
biology students with the capability of conceptual modeling and agent-based
simulation in the ecological domain. This paper describes VERA and its approach
to coupling conceptual modeling and simulation with emphasis on how a model's
visual syntax is compiled into code executable on a NetLogo simulation engine.
Experience with VERA in introductory biology classes at several universities
and through the Smithsonian Institution's Encyclopedia of Life website is
related.

</details>


### [22] [Local News Hijacking: A Review of International Instances](https://arxiv.org/abs/2510.16951)
*Christine Sowa Lepird,Kathleen M. Carley*

Main category: cs.CY

TL;DR: 本文回顾了2007-2024年间美国7起创建虚假地方新闻网站以影响地区居民的信息操作活动，分析了这些网站的运作模式共性，并提出了防范措施。


<details>
  <summary>Details</summary>
Motivation: 在数字时代，创建恶意网站传播错误信息变得更容易。近年来美国出现创建虚假地方新闻网站进行信息操作活动的新现象，需要研究其运作模式并提出防范方案。

Method: 通过回顾分析7个虚假地方新闻网站的案例，分解这些网站的运作方式，识别其共同特征和模式。

Result: 发现这些虚假新闻网站具有三个主要共性：复活已停刊的"僵尸"报纸、在社交媒体上分享这些网站、使用WordPress网站模板。

Conclusion: 通过分析这些共同特征，提出了未来减少此类信息操作活动发生的缓解措施和建议。

Abstract: In the rise of the digital era, it's easier than ever to create nefarious
websites to spread misinformation. A more recent phenomenon in the United
States has been the creation of inauthentic local news websites to further an
information operation campaign. This paper is a review of the 7 instances in
which local news websites were created to influence residents of a region
between 2007 and 2024. By breaking down the ways in which these sites operated,
we discovered commonalities in the approach - resurrecting "zombie" papers that
were previously established authentic local news organizations, sharing these
sites on social media, and using website templates from WordPress. By analyzing
these commonalities, we propose ways to mitigate the occurrence of these
campaigns in the future.

</details>


### [23] [Visibility Allocation Systems: How Algorithmic Design Shapes Online Visibility and Societal Outcomes](https://arxiv.org/abs/2510.17241)
*Stefania Ionescu,Robin Forsberg,Elsa Lichtenegger,Salima Jaoua,Kshitijaa Jaglan,Florian Dorfler,Aniko Hannak*

Main category: cs.CY

TL;DR: 提出了一个用于分析可见性分配系统(VAS)的形式化框架，这些系统决定向用户展示哪些处理后的数据，帮助理解复杂算法系统的结构和评估。


<details>
  <summary>Details</summary>
Motivation: 当前算法系统日益复杂且缺乏文档，其结构不明确且可能产生严重下游后果，但整体理解和评估这些系统对研究人员和立法者仍是挑战。

Method: 引入VAS形式化框架，将其分解为子过程并通过数据流图说明，回顾VAS中的典型工具及其解决的计算问题，并调查整个流程中的评估指标。

Result: 通过学校选择中的预测推荐案例研究，展示了该框架如何支持VAS评估，并讨论了框架如何支持AI立法工作。

Conclusion: 该框架为理解和评估复杂算法系统提供了系统化方法，有助于定位义务、量化系统性风险和实现适应性合规。

Abstract: Throughout application domains, we now rely extensively on algorithmic
systems to engage with ever-expanding datasets of information. Despite their
benefits, these systems are often complex (comprising of many intricate tools,
e.g., moderation, recommender systems, prediction models), of unknown structure
(due to the lack of accompanying documentation), and having hard-to-predict yet
potentially severe downstream consequences (due to the extensive use,
systematic enactment of existing errors, and many comprising feedback loops).
As such, understanding and evaluating these systems as a whole remains a
challenge for both researchers and legislators. To aid ongoing efforts, we
introduce a formal framework for such visibility allocation systems (VASs)
which we define as (semi-)automated systems deciding which (processed) data to
present a human user with. We review typical tools comprising VASs and define
the associated computational problems they solve. By doing so, VASs can be
decomposed into sub-processes and illustrated via data flow diagrams. Moreover,
we survey metrics for evaluating VASs throughout the pipeline, thus aiding
system diagnostics. Using forecasting-based recommendations in school choice as
a case study, we demonstrate how our framework can support VAS evaluation. We
also discuss how our framework can support ongoing AI-legislative efforts to
locate obligations, quantify systemic risks, and enable adaptive compliance.

</details>


### [24] [Quantifying Climate Policy Action and Its Links to Development Outcomes: A Cross-National Data-Driven Analysis](https://arxiv.org/abs/2510.17425)
*Aditi Dutta*

Main category: cs.CY

TL;DR: 开发了一个基于多语言transformer的定量指标来分析气候政策取向，通过将政策文档分类与经济发展数据关联，揭示了不同气候政策类型对经济指标的影响差异。


<details>
  <summary>Details</summary>
Motivation: 现有气候政策评估方法主要依赖定性描述或综合指数，无法清晰区分缓解、适应、灾害风险管理等关键领域的政策差异，需要更精确的量化工具来评估政策对发展成果的实际影响。

Method: 使用多语言transformer语言模型对官方国家政策文件进行分类，分类准确率达到0.90（F1分数），然后将这些指标与世界银行发展数据在面板回归中关联分析。

Result: 缓解政策与更高的GDP和GNI相关；灾害风险管理与更大的GNI和债务相关但减少了外国直接投资；适应和损失损害政策显示出有限的可测量效果。

Conclusion: 这个集成的NLP-计量经济学框架能够对气候治理进行可比较的、主题特定的分析，提供了一个可扩展的方法来监测进展、评估权衡并使政策重点与发展目标保持一致。

Abstract: Addressing climate change effectively requires more than cataloguing the
number of policies in place; it calls for tools that can reveal their thematic
priorities and their tangible impacts on development outcomes. Existing
assessments often rely on qualitative descriptions or composite indices, which
can mask crucial differences between key domains such as mitigation,
adaptation, disaster risk management, and loss and damage. To bridge this gap,
we develop a quantitative indicator of climate policy orientation by applying a
multilingual transformer-based language model to official national policy
documents, achieving a classification accuracy of 0.90 (F1-score). Linking
these indicators with World Bank development data in panel regressions reveals
that mitigation policies are associated with higher GDP and GNI; disaster risk
management correlates with greater GNI and debt but reduced foreign direct
investment; adaptation and loss and damage show limited measurable effects.
This integrated NLP-econometric framework enables comparable, theme-specific
analysis of climate governance, offering a scalable method to monitor progress,
evaluate trade-offs, and align policy emphasis with development goals.

</details>


### [25] [Mensen aanwijzen maar niet bij naam noemen: behavioural targeting, persoonsgegevens, en de nieuwe Privacyverordening](https://arxiv.org/abs/2510.17710)
*Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 本文主张数据保护法应适用于行为定向营销，即使公司未将姓名与个人数据关联，只要能够识别出特定个人，就应视为处理个人数据。


<details>
  <summary>Details</summary>
Motivation: 行为定向营销公司通常声称只要不将姓名与个人数据关联，就不处理个人数据，因此数据保护法不适用。本文旨在反驳这一观点，强调隐私风险依然存在。

Method: 通过分析行为定向营销的实际运作方式，论证即使没有姓名关联，公司仍能识别特定个人，且姓名并非最实用的标识符。

Result: 论证表明行为定向营销涉及收集个人信息、识别个人并向个人投放广告，这些活动应被视为处理个人数据。

Conclusion: 数据保护法应适用于行为定向营销，因为其核心是识别和针对个人，符合数据保护法保护公平性和隐私的宗旨。

Abstract: Information about millions of people is collected for behavioural targeting,
a type of marketing that involves tracking people's online behaviour for
targeted advertising. It is hotly debated whether data protection law applies
to behavioural targeting. Many behavioural targeting companies say that, as
long as they do not tie names to data they hold about individuals, they do not
process any personal data, and that, therefore, data protection law does not
apply to them. European Data Protection Authorities, however, take the view
that a company processes personal data if it uses data to single out a person,
even if it cannot tie a name to these data. This paper argues that data
protection law should indeed apply to behavioural targeting. Companies can
often tie a name to nameless data about individuals. Furthermore, behavioural
targeting relies on collecting information about individuals, singling out
individuals, and targeting ads to individuals. Many privacy risks remain,
regardless of whether companies tie a name to the information they hold about a
person. A name is merely one of the identifiers that can be tied to data about
a person, and it is not even the most practical identifier for behavioural
targeting. Seeing data used to single out a person as personal data fits the
rationale for data protection law: protecting fairness and privacy.

</details>


### [26] [Discrimination, intelligence artificielle et decisions algorithmiques](https://arxiv.org/abs/2510.17711)
*Frederik Zuiderveen Borgesius*

Main category: cs.CY

TL;DR: 该研究分析了人工智能算法决策可能导致的歧视风险，由欧洲理事会反歧视部门委托进行


<details>
  <summary>Details</summary>
Motivation: AI技术虽然带来巨大机遇，但其嵌入和延续偏见与歧视的潜力是最紧迫的挑战之一，需要系统研究算法决策的歧视风险

Method: 通过文献研究和政策分析，系统评估AI算法决策可能导致的歧视机制和风险类型

Result: 识别了AI系统在决策过程中可能产生的多种歧视风险，包括算法偏见、数据偏差等问题

Conclusion: AI算法的歧视风险是当前最紧迫的挑战之一，需要制定相应政策和监管措施来防范算法决策中的歧视问题

Abstract: Artificial intelligence (AI) has a huge impact on our personal lives and also
on our democratic society as a whole. While AI offers vast opportunities for
the benefit of people, its potential to embed and perpetuate bias and
discrimination remains one of the most pressing challenges deriving from its
increasing use. This new study, which was prepared by Prof. Frederik Zuiderveen
Borgesius for the Anti-discrimination Department of the Council of Europe,
elaborates on the risks of discrimination caused by algorithmic decision-making
and other types of artificial intelligence (AI).

</details>


### [27] [Online Political Microtargeting: Promises and Threats for Democracy](https://arxiv.org/abs/2510.17712)
*Frederik J. Zuiderveen Borgesius,Judith Möller,Sanne Kruikemeier,Ronan Ó Fathaigh,Kristina Irion,Tom Dobber,Balazs Bodo,Claes de Vreese*

Main category: cs.CY

TL;DR: 本文分析了在线政治微定向对民主的承诺与威胁，并探讨了在遵守欧洲人权公约表达自由权前提下的监管可能性。


<details>
  <summary>Details</summary>
Motivation: 随着在线政治微定向在美国广泛应用且欧洲可能跟进，需要系统评估其对民主的影响并探索监管方案。

Method: 通过映射分析微定向对民主的承诺与威胁，并基于欧洲人权公约框架探讨可行的监管措施。

Result: 识别出微定向既能优化选民关注与竞选活动的匹配、提升参与度，也可能导致政党误导性呈现、引发隐私问题。

Conclusion: 需要在保障表达自由的前提下制定监管措施，平衡微定向的民主价值与潜在风险。

Abstract: Online political microtargeting involves monitoring people's online
behaviour, and using the collected data, sometimes enriched with other data, to
show people-targeted political advertisements. Online political microtargeting
is widely used in the US; Europe may not be far behind. This paper maps
microtargeting's promises and threats to democracy. For example, microtargeting
promises to optimise the match between the electorate's concerns and political
campaigns, and to boost campaign engagement and political participation. But
online microtargeting could also threaten democracy. For instance, a political
party could, misleadingly, present itself as a different one-issue party to
different individuals. And data collection for microtargeting raises privacy
concerns. We sketch possibilities for policymakers if they seek to regulate
online political microtargeting. We discuss which measures would be possible,
while complying with the right to freedom of expression under the European
Convention on Human Rights.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [28] [A study about who is interested in stock splitting and why: considering companies, shareholders or managers](https://arxiv.org/abs/2510.15879)
*Jiaquan Nicholas Chen,Marcel Ausloos*

Main category: q-fin.GN

TL;DR: 该论文研究了股票分割对公司的影响，发现股票分割能短期提升交易量、扩大股东基础、提高市场流动性，并减少信息不对称。


<details>
  <summary>Details</summary>
Motivation: 探讨股票分割对公司的吸引力，分析公司和管理层进行股票分割的原因，以及股东为何同意此类决策，旨在澄清关于股票价格、股票分割、股东和管理者行为的误解。

Method: 通过分析近年来九个选择性事件，观察信息不对称的作用以及事件前后的回报和交易量变化，计算每个样本的贝塔值。

Result: 股票分割（i）影响市场并在短期内轻微提升交易量，（ii）扩大公司的股东基础，（iii）对市场流动性有积极影响。股票分割公告可以减少信息不对称水平。

Conclusion: 股票分割公告可以减少信息不对称，投资者会重新调整对公司的信念，尽管大多数公司在股票分割年份被错误定价。

Abstract: There are many misconceptions around stock prices, stock splits,
shareholders, investors, and managers behaviour about such informations due to
a number of confounding factors. This paper tests hypotheses with a selected
database, about the question ''is stock split attractive for companies?'' in
another words, ''why companies split their stock?'', ''why managers split their
stock?'', sometimes for no benefit, and ''why shareholders agree with such
decisions?''. We contribute to the existing knowledge through a discussion of
nine events in recent (selectively chosen) years, observing the role of
information asymmetries, the returns and traded volumes before and after the
event. Therefore, calculating the beta for each sample, it is found that stock
splits (i) affect the market and slightly enhance the trading volume in a
short-term, (ii) increase the shareholder base for its firm, (iii) have a
positive effect on the liquidity of the market. We concur that stock split
announcements can reduce the level of information asymmetric. Investors
readjust their beliefs in the firm, although most of the firms are mispriced in
the stock split year.

</details>


### [29] [Sleeping Kelly is a Thirder](https://arxiv.org/abs/2510.15911)
*Ben Abramowitz*

Main category: q-fin.GN

TL;DR: 该论文通过凯利准则论证睡美人问题中应采取"三分之一"立场，认为睡美人应最大化财富增长率而非期望值，并通过荷兰赌论证其合理性。


<details>
  <summary>Details</summary>
Motivation: 解决睡美人问题中概率与理性决策的矛盾，探讨在非完美记忆情境下如何定义"理性"决策。

Method: 使用凯利准则分析睡美人应如何下注以最大化财富增长率，并通过荷兰赌论证检验不同立场的合理性。

Result: 睡美人作为"三分之一者"接受增长率大于1的赌注时不受荷兰赌影响，而"二分之一者"则面临荷兰赌风险。

Conclusion: 在乘性财富动态下，睡美人应采纳"三分之一"立场以最大化财富增长并避免荷兰赌，但若财富动态改变则结论可能不同。

Abstract: The Sleeping Beauty problem was presented by Elga and highlights the role of
probabilities in situations with imperfect recall. One approach to solving the
Sleeping Beauty problem is to allow Sleeping Beauty to make decisions based on
her beliefs, and then characterize what it takes for her decisions to be
"rational". In particular, she can be allowed to make monetary bets based on
her beliefs, with the assumption that she wants to gain wealth rather than lose
it. However, this approach is often coupled with the assumption that Sleeping
Beauty should maximize the expected value of her bets. Here, I argue instead
that it is rational for Sleeping Beauty to maximize the growth rate of her
wealth using the Kelly Criterion, which leads us to the "thirder" position.
Furthermore, this position is shown to be "rational" by Dutch book arguments.
If Sleeping Kelly only accepts bets that have a growth rate greater than 1 as a
"thirder" then she is not vulnerable to Dutch books. By contrast, if Sleeping
Beauty takes the "halfer" position, she is vulnerable to Dutch books. If the
bets offered to Sleeping Beauty were to be structured differently and lead to
non-multiplicative wealth dynamics, she may no longer be a "thirder".

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [30] [The Burden of Interactive Alignment with Inconsistent Preferences](https://arxiv.org/abs/2510.16368)
*Ali Shirali*

Main category: cs.AI

TL;DR: 该研究探讨了用户如何通过策略性互动来引导算法与其真实兴趣对齐，提出了一个双系统决策模型和Stackelberg博弈框架，分析了用户需要的前瞻性程度以及降低对齐负担的方法。


<details>
  <summary>Details</summary>
Motivation: 在算法驱动的平台上，用户经常表现出不一致的偏好，可能花费大量时间在低价值内容上，这向算法传递了错误的信号。研究旨在理解用户需要什么条件才能有效引导算法与其真实兴趣对齐。

Method: 将用户决策过程建模为理性系统2（决定是否参与）和冲动系统1（决定参与时长）的双系统模型，采用多领导者-单跟随者的Stackelberg扩展博弈框架，用户作为领导者承诺参与策略，算法基于观察到的互动做出最佳响应。

Result: 存在一个关键的对齐视野：足够有远见的用户可以实现算法对齐，而短视的用户则会被算法目标所对齐。这个关键视野可能很长，构成显著负担，但即使是一个小的、有成本的信号（如额外点击）也能显著降低对齐负担。

Conclusion: 该框架解释了具有不一致偏好的用户如何在Stackelberg均衡中实现与参与驱动算法的对齐，既揭示了实现对齐的挑战，也指出了潜在的解决方案。

Abstract: From media platforms to chatbots, algorithms shape how people interact,
learn, and discover information. Such interactions between users and an
algorithm often unfold over multiple steps, during which strategic users can
guide the algorithm to better align with their true interests by selectively
engaging with content. However, users frequently exhibit inconsistent
preferences: they may spend considerable time on content that offers little
long-term value, inadvertently signaling that such content is desirable.
Focusing on the user side, this raises a key question: what does it take for
such users to align the algorithm with their true interests?
  To investigate these dynamics, we model the user's decision process as split
between a rational system 2 that decides whether to engage and an impulsive
system 1 that determines how long engagement lasts. We then study a
multi-leader, single-follower extensive Stackelberg game, where users,
specifically system 2, lead by committing to engagement strategies and the
algorithm best-responds based on observed interactions. We define the burden of
alignment as the minimum horizon over which users must optimize to effectively
steer the algorithm. We show that a critical horizon exists: users who are
sufficiently foresighted can achieve alignment, while those who are not are
instead aligned to the algorithm's objective. This critical horizon can be
long, imposing a substantial burden. However, even a small, costly signal
(e.g., an extra click) can significantly reduce it. Overall, our framework
explains how users with inconsistent preferences can align an engagement-driven
algorithm with their interests in a Stackelberg equilibrium, highlighting both
the challenges and potential remedies for achieving alignment.

</details>


### [31] [Exploring the Potential of Citiverses for Regulatory Learning](https://arxiv.org/abs/2510.15959)
*Isabelle Hupont,Marisa Ponti,Sven Schade*

Main category: cs.AI

TL;DR: 本文提出了一个科学政策议程，探索城市虚拟世界作为监管学习实验空间的潜力，通过专家咨询确定了关键研究领域和实验主题。


<details>
  <summary>Details</summary>
Motivation: 利用城市虚拟世界为政策制定提供沉浸式实验环境，支持监管学习和技术测试，减少现实世界实施风险。

Method: 基于与欧洲委员会政策制定者、国家政府科学顾问和数字监管领域专家的高层专家咨询，识别关键研究领域和实验主题。

Result: 确定了可扩展性、实时反馈、复杂性建模等关键研究领域，以及交通、城市规划、环境气候危机等具体实验主题。

Conclusion: 城市虚拟世界有潜力成为重要的监管学习实验空间，但需要负责任地开发使用，并考虑伦理、经济、生态和社会维度。

Abstract: Citiverses hold the potential to support regulatory learning by offering
immersive, virtual environments for experimenting with policy scenarios and
technologies. This paper proposes a science-for-policy agenda to explore the
potential of citiverses as experimentation spaces for regulatory learning,
grounded in a consultation with a high-level panel of experts, including
policymakers from the European Commission, national government science advisers
and leading researchers in digital regulation and virtual worlds. It identifies
key research areas, including scalability, real-time feedback, complexity
modelling, cross-border collaboration, risk reduction, citizen participation,
ethical considerations and the integration of emerging technologies. In
addition, the paper analyses a set of experimental topics, spanning
transportation, urban planning and the environment/climate crisis, that could
be tested in citiverse platforms to advance regulatory learning in these areas.
The proposed work is designed to inform future research for policy and
emphasizes a responsible approach to developing and using citiverses. It
prioritizes careful consideration of the ethical, economic, ecological and
social dimensions of different regulations. The paper also explores essential
preliminary steps necessary for integrating citiverses into the broader
ecosystems of experimentation spaces, including test beds, living labs and
regulatory sandboxes

</details>


### [32] [MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning](https://arxiv.org/abs/2510.17590)
*Mir Nafis Sharear Shopnil,Sharad Duwal,Abhishek Tyagi,Adiba Mahbub Proma*

Main category: cs.AI

TL;DR: MIRAGE是一个推理时、可插拔模型的多模态虚假信息检测框架，通过视觉真实性评估、跨模态一致性分析、检索增强的事实检查和校准判断四个模块，在MMFakeBench验证集上达到81.65% F1分数，比最强零样本基线提升7.65个百分点。


<details>
  <summary>Details</summary>
Motivation: 网络平台上每天有数十亿结合文本和图像的多模态帖子传播虚假信息，超出了人工事实核查的能力。现有的监督检测模型需要特定领域的训练数据，且无法泛化到不同的操纵策略。

Method: MIRAGE框架将多模态验证分解为四个顺序模块：视觉真实性评估检测AI生成图像，跨模态一致性分析识别上下文不当利用，检索增强事实检查通过迭代问题生成将声明基于网络证据，校准判断模块整合所有信号。

Result: 在MMFakeBench验证集（1000样本）上，MIRAGE与GPT-4o-mini组合达到81.65% F1和75.1%准确率，比最强零样本基线（GPT-4V与MMD-Agent的74.0% F1）提升7.65点，同时保持34.3%假阳性率，而仅判断基线的假阳性率为97.3%。测试集结果（5000样本）确认泛化能力，达到81.44% F1和75.08%准确率。

Conclusion: 分解的智能推理与网络检索可以在不需要特定领域训练的情况下匹配监督检测器的性能，使得在标记数据稀缺的多模态场景中也能进行虚假信息检测。

Abstract: Misinformation spreads across web platforms through billions of daily
multimodal posts that combine text and images, overwhelming manual
fact-checking capacity. Supervised detection models require domain-specific
training data and fail to generalize across diverse manipulation tactics. We
present MIRAGE, an inference-time, model-pluggable agentic framework that
decomposes multimodal verification into four sequential modules: visual
veracity assessment detects AI-generated images, cross-modal consistency
analysis identifies out-of-context repurposing, retrieval-augmented factual
checking grounds claims in web evidence through iterative question generation,
and a calibrated judgment module integrates all signals. MIRAGE orchestrates
vision-language model reasoning with targeted web retrieval, outputs structured
and citation-linked rationales. On MMFakeBench validation set (1,000 samples),
MIRAGE with GPT-4o-mini achieves 81.65% F1 and 75.1% accuracy, outperforming
the strongest zero-shot baseline (GPT-4V with MMD-Agent at 74.0% F1) by 7.65
points while maintaining 34.3% false positive rate versus 97.3% for a
judge-only baseline. Test set results (5,000 samples) confirm generalization
with 81.44% F1 and 75.08% accuracy. Ablation studies show visual verification
contributes 5.18 F1 points and retrieval-augmented reasoning contributes 2.97
points. Our results demonstrate that decomposed agentic reasoning with web
retrieval can match supervised detector performance without domain-specific
training, enabling misinformation detection across modalities where labeled
data remains scarce.

</details>


### [33] [End-to-end Listen, Look, Speak and Act](https://arxiv.org/abs/2510.16756)
*Siyin Wang,Wenyi Yu,Xianzhao Chen,Xiaohai Tian,Jun Zhang,Lu Lu,Chao Zhang*

Main category: cs.AI

TL;DR: ELLSA是首个全双工、端到端的多模态模型，能够同时感知和生成视觉、文本、语音和动作，实现更自然的人机交互。


<details>
  <summary>Details</summary>
Motivation: 人类交互本质上是多模态和全双工的，需要模型能够同时感知和生成多种模态，实现更自然的人类行为模拟。

Method: 采用新颖的SA-MoE架构（自注意力专家混合），将各模态路由到专用专家，通过统一注意力骨干网络进行融合。

Result: 在语音交互和机器人操作基准测试中，ELLSA与特定模态基线性能相当，同时支持高级多模态和全双工行为。

Conclusion: ELLSA代表了向更自然和通用交互智能迈出的一步，有助于实现人工通用智能的追求。

Abstract: Human interaction is inherently multimodal and full-duplex: we listen while
watching, speak while acting, and fluidly adapt to turn-taking and
interruptions. Realizing these capabilities is essential for building models
simulating humans. We present ELLSA (End-to-end Listen, Look, Speak and Act),
which, to our knowledge, is the first full-duplex, end-to-end model that
simultaneously perceives and generates across vision, text, speech, and action
within a single architecture, enabling interaction patterns previously out of
reach, yielding more natural, human-like behaviors. At its core is a novel
SA-MoE architecture (Self-Attention Mixture-of-Experts) that routes each
modality to specialized experts and fuses them through a unified attention
backbone. This provides a generalizable solution for joint multimodal
perception and concurrent generation, leveraging strong pre-trained components
while enabling efficient modality integration and mitigating modality
interference. On speech-interaction and robot-manipulation benchmarks, ELLSA
matches modality-specific baselines, while uniquely supporting advanced
multimodal and full-duplex behaviors such as dialogue and action turn-taking,
defective instruction rejection, speaking-while-acting, context-grounded visual
question answering, and action barge-ins. We contend that ELLSA represents a
step toward more natural and general interactive intelligence, contributing to
the broader pursuit of artificial general intelligence. All data, code and
model checkpoints will be released upon acceptance.

</details>


### [34] [Graph Attention-Guided Search for Dense Multi-Agent Pathfinding](https://arxiv.org/abs/2510.17382)
*Rishabh Jain,Keisuke Okumura,Michael Amir,Amanda Prorok*

Main category: cs.AI

TL;DR: 提出LaGAT框架，将基于图注意力的神经MAPF策略MAGAT集成到搜索算法LaCAM中，在密集多智能体路径规划场景中优于纯搜索和纯学习方法。


<details>
  <summary>Details</summary>
Motivation: 密集多智能体路径规划问题在实时场景中仍然具有挑战性，现有学习方法在MAPF中表现不佳，需要结合学习与搜索的优势。

Method: 增强MAGAT架构，采用预训练-微调策略，结合死锁检测机制来处理不完美的神经引导，将学习启发式集成到LaCAM搜索算法中。

Result: LaGAT在密集场景中超越了纯搜索方法和纯学习方法，证明了混合搜索在紧密耦合的多智能体协调问题中的有效性。

Conclusion: 精心设计的混合搜索方法为解决具有挑战性的多智能体协调问题提供了强大解决方案。

Abstract: Finding near-optimal solutions for dense multi-agent pathfinding (MAPF)
problems in real-time remains challenging even for state-of-the-art planners.
To this end, we develop a hybrid framework that integrates a learned heuristic
derived from MAGAT, a neural MAPF policy with a graph attention scheme, into a
leading search-based algorithm, LaCAM. While prior work has explored
learning-guided search in MAPF, such methods have historically underperformed.
In contrast, our approach, termed LaGAT, outperforms both purely search-based
and purely learning-based methods in dense scenarios. This is achieved through
an enhanced MAGAT architecture, a pre-train-then-fine-tune strategy on maps of
interest, and a deadlock detection scheme to account for imperfect neural
guidance. Our results demonstrate that, when carefully designed, hybrid search
offers a powerful solution for tightly coupled, challenging multi-agent
coordination problems.

</details>


### [35] [VisuoAlign: Safety Alignment of LVLMs with Multimodal Tree Search](https://arxiv.org/abs/2510.15948)
*MingSheng Li,Guangze Zhao,Sichen Liu*

Main category: cs.AI

TL;DR: VisuoAlign是一个通过提示引导树搜索实现多模态安全对齐的框架，旨在解决大型视觉语言模型在多模态越狱攻击下的安全挑战。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法对多模态越狱攻击脆弱，因为视觉输入引入新的攻击面，推理链缺乏安全监督，模态融合会降低对齐效果。

Method: 通过视觉-文本交互提示将安全约束嵌入推理过程，使用蒙特卡洛树搜索构建多样化的安全关键提示轨迹，并引入基于提示的缩放确保实时风险检测和合规响应。

Result: 实验表明VisuoAlign能主动暴露风险，实现全面的数据集生成，并显著提升LVLMs对复杂跨模态威胁的鲁棒性。

Conclusion: VisuoAlign框架有效解决了多模态安全对齐的关键挑战，为大型视觉语言模型提供了更强的安全防护能力。

Abstract: Large Vision-Language Models (LVLMs) have achieved remarkable progress in
multimodal perception and generation, yet their safety alignment remains a
critical challenge.Existing defenses and vulnerable to multimodal jailbreaks,
as visual inputs introduce new attack surfaces, reasoning chains lack safety
supervision, and alignment often degrades under modality fusion.To overcome
these limitation, we propose VisuoAlign, a framework for multi-modal safety
alignment via prompt-guided tree search.VisuoAlign embeds safety constrains
into the reasoning process through visual-textual interactive prompts, employs
Monte Carlo Tree Search(MCTS) to systematically construct diverse
safety-critical prompt trajectories, and introduces prompt-based scaling to
ensure real-time risk detection and compliant responses.Extensive experiments
demonstrate that VisuoAlign proactively exposes risks, enables comprehensive
dataset generation, and significantly improves the robustness of LVLMs against
complex cross-modal threats.

</details>


### [36] [Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding](https://arxiv.org/abs/2510.15952)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 本文提出了结构化认知循环（SCL）作为可执行的认识论框架，用于实现涌现智能，将哲学洞见转化为可计算结构，重新定义智能为通过意向性理解重构自身认知状态的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型缺乏真正的认知理解，暴露了认知架构的缺失。传统AI研究关注智能的本质（本体论），而SCL关注认知涌现的条件（认识论），旨在弥合概念哲学与可实施认知之间的鸿沟。

Method: 基于过程哲学、具身认知和扩展心智理论，SCL将智能定义为执行过程而非属性——包含判断、记忆、控制、行动和调节的连续循环。通过功能分离的认知架构实现"可执行认识论"。

Result: SCL展示了功能分离的认知架构比单一提示系统产生更连贯和可解释的行为，支持智能的重构能力而非表征准确性。

Conclusion: 该框架对心智哲学、认识论和AI产生影响，强调真正进步需要实现认知原则的结构化架构，而非更大的模型。知识被重新定义为在现象学连贯循环中的持续重构。

Abstract: Large language models exhibit intelligence without genuine epistemic
understanding, exposing a key gap: the absence of epistemic architecture. This
paper introduces the Structured Cognitive Loop (SCL) as an executable
epistemological framework for emergent intelligence. Unlike traditional AI
research asking "what is intelligence?" (ontological), SCL asks "under what
conditions does cognition emerge?" (epistemological). Grounded in philosophy of
mind and cognitive phenomenology, SCL bridges conceptual philosophy and
implementable cognition. Drawing on process philosophy, enactive cognition, and
extended mind theory, we define intelligence not as a property but as a
performed process -- a continuous loop of judgment, memory, control, action,
and regulation. SCL makes three contributions. First, it operationalizes
philosophical insights into computationally interpretable structures, enabling
"executable epistemology" -- philosophy as structural experiment. Second, it
shows that functional separation within cognitive architecture yields more
coherent and interpretable behavior than monolithic prompt based systems,
supported by agent evaluations. Third, it redefines intelligence: not
representational accuracy but the capacity to reconstruct its own epistemic
state through intentional understanding. This framework impacts philosophy of
mind, epistemology, and AI. For philosophy, it allows theories of cognition to
be enacted and tested. For AI, it grounds behavior in epistemic structure
rather than statistical regularity. For epistemology, it frames knowledge not
as truth possession but as continuous reconstruction within a
phenomenologically coherent loop. We situate SCL within debates on cognitive
phenomenology, emergence, normativity, and intentionality, arguing that real
progress requires not larger models but architectures that realize cognitive
principles structurally.

</details>


### [37] [PISA: A Pragmatic Psych-Inspired Unified Memory System for Enhanced AI Agency](https://arxiv.org/abs/2510.15966)
*Shian Jia,Ziyang Huang,Xinbo Wang,Haofei Zhang,Mingli Song*

Main category: cs.AI

TL;DR: PISA是一个受皮亚杰认知发展理论启发的统一记忆系统，通过三模态适应机制和混合记忆访问架构，显著提升了AI代理的适应性和长期知识保持能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理记忆系统缺乏对多样化任务的适应性，且忽视了记忆的建设性和任务导向作用。

Method: 提出PISA系统，包含三模态适应机制（模式更新、模式演化和模式创建）和结合符号推理与神经检索的混合记忆访问架构。

Result: 在LOCOMO基准和新提出的AggQA基准上，PISA在数据分析和长期知识保持方面达到了新的最先进水平。

Conclusion: PISA通过将记忆视为建设性和适应性过程，为AI代理提供了更有效的记忆系统，显著提升了适应性和知识保持能力。

Abstract: Memory systems are fundamental to AI agents, yet existing work often lacks
adaptability to diverse tasks and overlooks the constructive and task-oriented
role of AI agent memory. Drawing from Piaget's theory of cognitive development,
we propose PISA, a pragmatic, psych-inspired unified memory system that
addresses these limitations by treating memory as a constructive and adaptive
process. To enable continuous learning and adaptability, PISA introduces a
trimodal adaptation mechanism (i.e., schema updation, schema evolution, and
schema creation) that preserves coherent organization while supporting flexible
memory updates. Building on these schema-grounded structures, we further design
a hybrid memory access architecture that seamlessly integrates symbolic
reasoning with neural retrieval, significantly improving retrieval accuracy and
efficiency. Our empirical evaluation, conducted on the existing LOCOMO
benchmark and our newly proposed AggQA benchmark for data analysis tasks,
confirms that PISA sets a new state-of-the-art by significantly enhancing
adaptability and long-term knowledge retention.

</details>


### [38] [Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games](https://arxiv.org/abs/2510.15974)
*Chris Su,Harrison Li,Matheus Marques,George Flint,Kevin Zhu,Sunishchal Dev*

Main category: cs.AI

TL;DR: 研究表明，为大型语言模型提供环境接口并不能解决其在复杂推理任务中的性能崩溃问题，模型在超越特定复杂度阈值时仍会出现性能下降。


<details>
  <summary>Details</summary>
Motivation: 探讨大型推理模型在解决复杂谜题时性能崩溃的真正原因，验证环境状态跟踪是否是该问题的关键混淆因素。

Method: 为LLM提供河内塔问题的环境接口，允许模型通过工具调用进行移动、提供书面理由、观察状态空间并重新提示下一步。

Result: 环境接口访问并不能延迟或消除性能崩溃，策略分析显示模型与最优策略和随机策略的偏离度增加，出现模式崩溃现象。

Conclusion: 性能崩溃现象可能源于模型在复杂任务中的模式崩溃，而非状态跟踪能力不足，类似现象可能也存在于大型推理模型中。

Abstract: Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in
performance on solving puzzles beyond certain perplexity thresholds. In
subsequent discourse, questions have arisen as to whether the nature of the
task muddles an evaluation of true reasoning. One potential confound is the
requirement that the model keep track of the state space on its own. We provide
a large language model (LLM) with an environment interface for Tower of Hanoi
problems, allowing it to make a move with a tool call, provide written
justification, observe the resulting state space, and reprompt itself for the
next move. We observe that access to an environment interface does not delay or
eradicate performance collapse. Furthermore, LLM-parameterized policy analysis
reveals increasing divergence from both optimal policies and uniformly random
policies, suggesting that the model exhibits mode-like collapse at each level
of complexity, and that performance is dependent upon whether the mode reflects
the correct solution for the problem. We suggest that a similar phenomena might
take place in LRMs.

</details>


### [39] [Cognitive Load Traces as Symbolic and Visual Accounts of Deep Model Cognition](https://arxiv.org/abs/2510.15980)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: 提出Cognitive Load Traces (CLTs)作为深度模型的中层可解释性框架，将认知负荷理论应用于AI模型，通过符号化、时变函数量化模型内部资源分配，包含内在、外在和关联负荷三个分量。


<details>
  <summary>Details</summary>
Motivation: 受人类认知负荷理论启发，旨在为深度模型提供更可解释的内部资源分配分析框架，帮助理解模型推理过程中的认知策略和效率问题。

Method: 将CLTs定义为三组分随机过程(IL_t, EL_t, GL_t)，分别对应内在、外在和关联负荷，通过注意力熵、KV缓存未命中率、表示分散度和解码稳定性等可测量代理来实例化，并提出符号公式和可视化方法。

Result: 在推理和规划基准测试中，CLTs能够预测错误发生、揭示认知策略，并通过负荷引导的干预措施在保持准确性的同时将推理效率提高15-30%。

Conclusion: CLTs框架为深度模型提供了有效的可解释性分析工具，能够量化认知负荷并指导模型优化，显著提升推理效率。

Abstract: We propose \textbf{Cognitive Load Traces} (CLTs) as a mid-level
interpretability framework for deep models, inspired by Cognitive Load Theory
in human cognition. CLTs are defined as symbolic, temporally varying functions
that quantify model-internal resource allocation. Formally, we represent CLTs
as a three-component stochastic process $(\mathrm{IL}_t, \mathrm{EL}_t,
\mathrm{GL}_t)$, corresponding to \emph{Intrinsic}, \emph{Extraneous}, and
\emph{Germane} load. Each component is instantiated through measurable proxies
such as attention entropy, KV-cache miss ratio, representation dispersion, and
decoding stability. We propose both symbolic formulations and visualization
methods (load curves, simplex diagrams) that enable interpretable analysis of
reasoning dynamics. Experiments on reasoning and planning benchmarks show that
CLTs predict error-onset, reveal cognitive strategies, and enable load-guided
interventions that improve reasoning efficiency by 15-30\% while maintaining
accuracy.

</details>


### [40] [ProofFlow: A Dependency Graph Approach to Faithful Proof Autoformalization](https://arxiv.org/abs/2510.15981)
*Rafael Cabral,Tuan Manh Do,Xuejun Yu,Wai Ming Tai,Zijin Feng,Xin Shen*

Main category: cs.AI

TL;DR: ProofFlow是一个新的证明自动形式化流水线，通过构建逻辑依赖图和使用基于引理的方法来保持原始证明的结构保真度，在自动形式化任务上达到了新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的证明自动形式化方法虽然能生成可执行代码，但经常无法保持原始证明的语义含义和逻辑结构，这限制了大型语言模型在严格数学工作流程中的集成。

Method: ProofFlow首先构建有向无环图来映射证明步骤间的逻辑依赖关系，然后采用基于引理的方法系统地将每个步骤形式化为中间引理，从而保持原始论证的逻辑结构。

Result: 实验结果显示ProofFlow在自动形式化任务上达到了新的最先进水平，ProofScore得分为0.545，显著优于全证明形式化（0.123）和步骤证明形式化（0.072）等基线方法。

Conclusion: ProofFlow通过关注结构保真度显著提升了证明自动形式化的质量，其流水线、基准测试和评分指标已开源，以促进该领域的进一步发展。

Abstract: Proof autoformalization, the task of translating natural language theorems
and proofs into machine-verifiable code, is a critical step for integrating
large language models into rigorous mathematical workflows. Current approaches
focus on producing executable code, but they frequently fail to preserve the
semantic meaning and logical structure of the original human-written argument.
To address this, we introduce ProofFlow, a novel pipeline that treats
structural fidelity as a primary objective. ProofFlow first constructs a
directed acyclic graph (DAG) to map the logical dependencies between proof
steps. Then, it employs a novel lemma-based approach to systematically
formalize each step as an intermediate lemma, preserving the logical structure
of the original argument. To facilitate evaluation, we present a new benchmark
of 184 undergraduate-level problems, manually annotated with step-by-step
solutions and logical dependency graphs, and introduce ProofScore, a new
composite metric to evaluate syntactic correctness, semantic faithfulness, and
structural fidelity. Experimental results show our pipeline sets a new
state-of-the-art for autoformalization, achieving a ProofScore of 0.545,
substantially exceeding baselines like full-proof formalization (0.123), which
processes the entire proof at once, and step-proof formalization (0.072), which
handles each step independently. Our pipeline, benchmark, and score metric are
open-sourced to encourage further progress at
https://github.com/Huawei-AI4Math/ProofFlow.

</details>


### [41] [Ontologies in Motion: A BFO-Based Approach to Knowledge Graph Construction for Motor Performance Research Data in Sports Science](https://arxiv.org/abs/2510.15983)
*Sarah Rebecca Ondraszek,Jörg Waitelonis,Katja Keller,Claudia Niessner,Anna M. Jacyszyn,Harald Sack*

Main category: cs.AI

TL;DR: 提出了将MO|RE运动科学研究数据仓库转换为知识图谱的愿景，旨在标准化和机器可理解地建模和共享运动表现数据。


<details>
  <summary>Details</summary>
Motivation: 为了评估和比较不同人群的身体和认知能力，需要测试与人类表现相关的各种因素。运动表现测试作为体育科学研究的核心部分，能够分析不同人口群体的身体健康状况并进行比较。

Method: 开发基于基本形式本体论的本体，重点形式化表示计划规范、特定过程和相关测量之间的相互关系。

Result: 提出了将MO|RE数据仓库转换为知识图谱的方法，使运动表现数据能够标准化和机器可理解地跨研究共享。

Conclusion: 该知识图谱方法将改变运动表现数据的建模和共享方式，使其更加标准化和机器可理解，这是在Leibniz科学园区"研究数字化转型"项目内开发的。

Abstract: An essential component for evaluating and comparing physical and cognitive
capabilities between populations is the testing of various factors related to
human performance. As a core part of sports science research, testing motor
performance enables the analysis of the physical health of different
demographic groups and makes them comparable.
  The Motor Research (MO|RE) data repository, developed at the Karlsruhe
Institute of Technology, is an infrastructure for publishing and archiving
research data in sports science, particularly in the field of motor performance
research. In this paper, we present our vision for creating a knowledge graph
from MO|RE data. With an ontology rooted in the Basic Formal Ontology, our
approach centers on formally representing the interrelation of plan
specifications, specific processes, and related measurements. Our goal is to
transform how motor performance data are modeled and shared across studies,
making it standardized and machine-understandable. The idea presented here is
developed within the Leibniz Science Campus ``Digital Transformation of
Research'' (DiTraRe).

</details>


### [42] [A Non-overlap-based Conflict Measure for Random Permutation Sets](https://arxiv.org/abs/2510.16001)
*Ruolan Cheng,Yong Deng,Enrique Herrera-Viedma*

Main category: cs.AI

TL;DR: 本文提出了一种基于随机置换集(RPS)的冲突度量方法，从随机有限集(RFS)和Dempster-Shafer理论(DST)两个角度分析RPS中的冲突，并引入基于秩偏重叠(RBO)的不一致性度量。


<details>
  <summary>Details</summary>
Motivation: 随机置换集是处理包含顺序信息的不确定性的新形式化方法，需要解决如何度量由置换质量函数表示的两个证据之间的冲突，这是顺序结构不确定信息融合中的关键研究问题。

Method: 从置换观察出发，基于秩偏重叠(RBO)度量定义置换间的不一致性度量，进一步提出基于非重叠的RPS冲突度量方法，将RPS理论视为DST的扩展，考虑焦点集中新增的顺序信息所代表的定性倾向。

Result: 通过数值示例验证了所提冲突度量的行为和性质，该方法不仅具有自然的顶部加权特性，能从DST视角有效度量RPS间的冲突，还为决策者提供了权重、参数和截断深度的灵活选择。

Conclusion: 提出的方法成功解决了RPS中的冲突度量问题，结合了RFS和DST视角，为顺序结构不确定信息融合提供了有效的分析工具。

Abstract: Random permutation set (RPS) is a new formalism for reasoning with
uncertainty involving order information. Measuring the conflict between two
pieces of evidence represented by permutation mass functions remains an urgent
research topic in order-structured uncertain information fusion. In this paper,
a detailed analysis of conflicts in RPS is carried out from two different
perspectives: random finite set (RFS) and Dempster-Shafer theory (DST).
Starting from the observation of permutations, we first define an inconsistency
measure between permutations inspired by the rank-biased overlap(RBO) measure
and further propose a non-overlap-based conflict measure method for RPSs. This
paper regards RPS theory (RPST) as an extension of DST. The order information
newly added in focal sets indicates qualitative propensity, characterized by
top-ranked elements occupying a more critical position. Some numerical examples
are used to demonstrate the behavior and properties of the proposed conflict
measure. The proposed method not only has the natural top-weightedness property
and can effectively measure the conflict between RPSs from the DST view but
also provides decision-makers with a flexible selection of weights, parameters,
and truncated depths.

</details>


### [43] [PAINT: Parallel-in-time Neural Twins for Dynamical System Reconstruction](https://arxiv.org/abs/2510.16004)
*Andreas Radler,Vincent Seyfried,Stefan Pirker,Johannes Brandstetter,Thomas Lichtenegger*

Main category: cs.AI

TL;DR: 提出了PAINT方法，一种用于建模动态系统的并行时间神经孪生架构，能够从测量数据中准确预测系统状态并保持轨迹跟踪能力


<details>
  <summary>Details</summary>
Motivation: 神经孪生作为神经代理的进一步发展，旨在创建真实系统的数字副本，需要能够在测试时根据测量更新状态，并保持轨迹跟踪能力

Method: PAINT训练生成神经网络来并行建模时间上的状态分布，在测试时通过滑动窗口方式从测量数据预测状态

Result: 理论分析表明PAINT能够保持轨迹跟踪，而自回归模型通常不能。在二维湍流流体动力学问题上的实验显示PAINT能够准确预测系统状态

Conclusion: PAINT具有开发能够保持轨迹跟踪的神经孪生的潜力，能够实现更准确的状态估计和决策制定

Abstract: Neural surrogates have shown great potential in simulating dynamical systems,
while offering real-time capabilities. We envision Neural Twins as a
progression of neural surrogates, aiming to create digital replicas of real
systems. A neural twin consumes measurements at test time to update its state,
thereby enabling context-specific decision-making. A critical property of
neural twins is their ability to remain on-trajectory, i.e., to stay close to
the true system state over time. We introduce Parallel-in-time Neural Twins
(PAINT), an architecture-agnostic family of methods for modeling dynamical
systems from measurements. PAINT trains a generative neural network to model
the distribution of states parallel over time. At test time, states are
predicted from measurements in a sliding window fashion. Our theoretical
analysis shows that PAINT is on-trajectory, whereas autoregressive models
generally are not. Empirically, we evaluate our method on a challenging
two-dimensional turbulent fluid dynamics problem. The results demonstrate that
PAINT stays on-trajectory and predicts system states from sparse measurements
with high fidelity. These findings underscore PAINT's potential for developing
neural twins that stay on-trajectory, enabling more accurate state estimation
and decision-making.

</details>


### [44] [Global-focal Adaptation with Information Separation for Noise-robust Transfer Fault Diagnosis](https://arxiv.org/abs/2510.16033)
*Junyu Ren,Wensheng Gan,Guangyu Zhang,Wei Zhong,Philip S. Yu*

Main category: cs.AI

TL;DR: 提出ISGFAN框架，通过信息分离和全局-局部对抗学习解决噪声环境下的跨域故障诊断问题


<details>
  <summary>Details</summary>
Motivation: 现有故障诊断方法假设数据干净或域相似度高，但在工业环境中存在严重噪声干扰和域偏移，限制了方法的有效性

Method: 基于信息分离架构，结合对抗学习和改进的正交损失来解耦域不变故障表示，采用全局-局部域对抗方案约束模型的条件和边缘分布

Result: 在三个公共基准数据集上的实验表明，该方法优于其他现有方法

Conclusion: ISGFAN框架在噪声条件下的跨域故障诊断中表现出优越性

Abstract: Existing transfer fault diagnosis methods typically assume either clean data
or sufficient domain similarity, which limits their effectiveness in industrial
environments where severe noise interference and domain shifts coexist. To
address this challenge, we propose an information separation global-focal
adversarial network (ISGFAN), a robust framework for cross-domain fault
diagnosis under noise conditions. ISGFAN is built on an information separation
architecture that integrates adversarial learning with an improved orthogonal
loss to decouple domain-invariant fault representation, thereby isolating noise
interference and domain-specific characteristics. To further strengthen
transfer robustness, ISGFAN employs a global-focal domain-adversarial scheme
that constrains both the conditional and marginal distributions of the model.
Specifically, the focal domain-adversarial component mitigates
category-specific transfer obstacles caused by noise in unsupervised scenarios,
while the global domain classifier ensures alignment of the overall
distribution. Experiments conducted on three public benchmark datasets
demonstrate that the proposed method outperforms other prominent existing
approaches, confirming the superiority of the ISGFAN framework. Data and code
are available at https://github.com/JYREN-Source/ISGFAN

</details>


### [45] [Algorithms for dynamic scheduling in manufacturing, towards digital factories Improving Deadline Feasibility and Responsiveness via Temporal Networks](https://arxiv.org/abs/2510.16047)
*Ioan Hedea*

Main category: cs.AI

TL;DR: 该论文结合离线约束规划优化与在线时间网络执行，创建在不确定性下仍可行的调度方案，消除了100%的截止时间违规，同时仅增加3-5%的制造周期开销。


<details>
  <summary>Details</summary>
Motivation: 现代制造系统需要满足严格的交付截止时间，同时应对由过程噪声、设备变异性和人为干预引起的随机任务持续时间。传统的确定性调度在现实偏离名义计划时会失效，导致昂贵的紧急修复。

Method: 首先构建具有每项任务截止时间的柔性作业车间约束规划模型，并插入最优缓冲区Δ*获得完全主动基线。然后将结果计划转换为具有不确定性的简单时间网络，并验证动态可控性。

Result: 在Kacem 1-4基准套件上的广泛蒙特卡洛模拟显示，混合方法消除了最先进元启发式调度中观察到的100%截止时间违规，同时仅增加3-5%的制造周期开销。可扩展性实验证实，在中等规模实例上，CP求解时间和STNU检查保持在亚秒级。

Conclusion: 这项工作展示了时间网络推理如何弥合主动缓冲和动态鲁棒性之间的差距，使工业更接近真正的数字化、自校正工厂。

Abstract: Modern manufacturing systems must meet hard delivery deadlines while coping
with stochastic task durations caused by process noise, equipment variability,
and human intervention. Traditional deterministic schedules break down when
reality deviates from nominal plans, triggering costly last-minute repairs.
This thesis combines offline constraint-programming (CP) optimisation with
online temporal-network execution to create schedules that remain feasible
under worst-case uncertainty. First, we build a CP model of the flexible
job-shop with per-job deadline tasks and insert an optimal buffer $\Delta^*$ to
obtain a fully pro-active baseline. We then translate the resulting plan into a
Simple Temporal Network with Uncertainty (STNU) and verify dynamic
controllability, which guarantees that a real-time dispatcher can retime
activities for every bounded duration realisation without violating resource or
deadline constraints. Extensive Monte-Carlo simulations on the open Kacem~1--4
benchmark suite show that our hybrid approach eliminates 100\% of deadline
violations observed in state-of-the-art meta-heuristic schedules, while adding
only 3--5\% makespan overhead. Scalability experiments confirm that CP
solve-times and STNU checks remain sub-second on medium-size instances. The
work demonstrates how temporal-network reasoning can bridge the gap between
proactive buffering and dynamic robustness, moving industry a step closer to
truly digital, self-correcting factories.

</details>


### [46] [Reliability of Large Language Model Generated Clinical Reasoning in Assisted Reproductive Technology: Blinded Comparative Evaluation Study](https://arxiv.org/abs/2510.16095)
*Dou Liu,Ying Long,Sophia Zuoqiu,Di Liu,Kang Li,Yiting Lin,Hanyi Liu,Rong Yin,Tian Tang*

Main category: cs.AI

TL;DR: 本研究评估了LLM生成的临床思维链可靠性，发现选择性少样本提示策略显著优于其他方法，关键在于示例的质量而非数量，并提出了"双原则"框架来生成可信的临床数据。


<details>
  <summary>Details</summary>
Motivation: 解决高质量临床思维链数据稀缺的问题，验证LLM生成医疗数据的可靠性，并探索提升其质量的提示策略。

Method: 采用盲法比较研究，由辅助生殖技术专家评估三种提示策略生成的思维链：零样本、随机少样本和选择性少样本，并与GPT-4o的评估结果对比。

Result: 选择性少样本策略在所有人工评估指标上显著优于其他策略，随机少样本相比零样本无显著改进，AI评估器未能识别关键性能差异。

Conclusion: 合成思维链的临床可靠性取决于策略性提示设计而非示例数量，提出了"黄金标准深度"和"代表性多样性"双原则框架，强调人类专家在高风险临床AI评估中的关键作用。

Abstract: Creating high-quality clinical Chains-of-Thought (CoTs) is crucial for
explainable medical Artificial Intelligence (AI) while constrained by data
scarcity. Although Large Language Models (LLMs) can synthesize medical data,
their clinical reliability remains unverified. This study evaluates the
reliability of LLM-generated CoTs and investigates prompting strategies to
enhance their quality. In a blinded comparative study, senior clinicians in
Assisted Reproductive Technology (ART) evaluated CoTs generated via three
distinct strategies: Zero-shot, Random Few-shot (using shallow examples), and
Selective Few-shot (using diverse, high-quality examples). These expert ratings
were compared against evaluations from a state-of-the-art AI model (GPT-4o).
The Selective Few-shot strategy significantly outperformed other strategies
across all human evaluation metrics (p < .001). Critically, the Random Few-shot
strategy offered no significant improvement over the Zero-shot baseline,
demonstrating that low-quality examples are as ineffective as no examples. The
success of the Selective strategy is attributed to two principles:
"Gold-Standard Depth" (reasoning quality) and "Representative Diversity"
(generalization). Notably, the AI evaluator failed to discern these critical
performance differences. The clinical reliability of synthetic CoTs is dictated
by strategic prompt curation, not the mere presence of examples. We propose a
"Dual Principles" framework as a foundational methodology to generate
trustworthy data at scale. This work offers a validated solution to the data
bottleneck and confirms the indispensable role of human expertise in evaluating
high-stakes clinical AI.

</details>


### [47] [Operationalising Extended Cognition: Formal Metrics for Corporate Knowledge and Legal Accountability](https://arxiv.org/abs/2510.16193)
*Elija Perrier*

Main category: cs.AI

TL;DR: 本文提出了一种基于扩展认知理论的形式化模型，将企业知识重新定义为可测量的动态能力，通过信息访问程序的效率和输出可靠性来量化企业认知状态，为算法时代的企业责任认定提供可审计的衡量标准。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在企业决策中日益重要，传统基于人类代理人的企业犯罪意图认定假设面临挑战，需要重新定义企业知识概念以适应算法决策环境。

Method: 开发了一个形式化模型，引入连续组织知识度量S_S(φ)，整合管道的计算成本和统计验证错误率，推导出知识谓词K_S和企业范围认知能力指数K_{S,t}，并将这些定量指标映射到法律标准。

Result: 建立了可测量的企业知识量化框架，能够将计算效率和输出可靠性转化为法律上可归责的知识状态，包括实际知识、推定知识、故意视而不见和鲁莽行为。

Conclusion: 该研究为在算法时代创建可测量和可司法审计的认知证据提供了路径，使企业思维变得可追踪和可问责。

Abstract: Corporate responsibility turns on notions of corporate \textit{mens rea},
traditionally imputed from human agents. Yet these assumptions are under
challenge as generative AI increasingly mediates enterprise decision-making.
Building on the theory of extended cognition, we argue that in response
corporate knowledge may be redefined as a dynamic capability, measurable by the
efficiency of its information-access procedures and the validated reliability
of their outputs. We develop a formal model that captures epistemic states of
corporations deploying sophisticated AI or information systems, introducing a
continuous organisational knowledge metric $S_S(\varphi)$ which integrates a
pipeline's computational cost and its statistically validated error rate. We
derive a thresholded knowledge predicate $\mathsf{K}_S$ to impute knowledge and
a firm-wide epistemic capacity index $\mathcal{K}_{S,t}$ to measure overall
capability. We then operationally map these quantitative metrics onto the legal
standards of actual knowledge, constructive knowledge, wilful blindness, and
recklessness. Our work provides a pathway towards creating measurable and
justiciable audit artefacts, that render the corporate mind tractable and
accountable in the algorithmic age.

</details>


### [48] [Towards Automatic Evaluation and Selection of PHI De-identification Models via Multi-Agent Collaboration](https://arxiv.org/abs/2510.16194)
*Guanchen Wu,Zuhui Chen,Yuzhang Xie,Carl Yang*

Main category: cs.AI

TL;DR: TEAM-PHI是一个多智能体评估框架，使用大语言模型自动评估医疗信息去标识化质量并选择最佳模型，无需依赖昂贵的专家标注。


<details>
  <summary>Details</summary>
Motivation: 医疗信息去标识化对于安全重用临床记录至关重要，但传统评估方法依赖成本高昂的小规模专家标注，限制了模型的评估和比较。

Method: 部署多个评估智能体独立判断PHI提取的正确性，然后通过基于LLM的多数投票机制整合结果，生成稳定且可复现的排名。

Result: 在真实临床记录语料上的实验表明，TEAM-PHI能产生一致且准确的排名，尽管个体评估者存在差异，但LLM投票能可靠地收敛于相同的最佳系统。

Conclusion: TEAM-PHI通过结合独立评估智能体和LLM多数投票，为PHI去标识化提供了实用、安全且成本效益高的自动评估和最佳模型选择方案。

Abstract: Protected health information (PHI) de-identification is critical for enabling
the safe reuse of clinical notes, yet evaluating and comparing PHI
de-identification models typically depends on costly, small-scale expert
annotations. We present TEAM-PHI, a multi-agent evaluation and selection
framework that uses large language models (LLMs) to automatically measure
de-identification quality and select the best-performing model without heavy
reliance on gold labels. TEAM-PHI deploys multiple Evaluation Agents, each
independently judging the correctness of PHI extractions and outputting
structured metrics. Their results are then consolidated through an LLM-based
majority voting mechanism that integrates diverse evaluator perspectives into a
single, stable, and reproducible ranking. Experiments on a real-world clinical
note corpus demonstrate that TEAM-PHI produces consistent and accurate
rankings: despite variation across individual evaluators, LLM-based voting
reliably converges on the same top-performing systems. Further comparison with
ground-truth annotations and human evaluation confirms that the framework's
automated rankings closely match supervised evaluation. By combining
independent evaluation agents with LLM majority voting, TEAM-PHI offers a
practical, secure, and cost-effective solution for automatic evaluation and
best-model selection in PHI de-identification, even when ground-truth labels
are limited.

</details>


### [49] [The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI](https://arxiv.org/abs/2510.16206)
*Alex Zhavoronkov,Dominika Wilczok,Roman Yampolskiy*

Main category: cs.AI

TL;DR: 本文提出"被记住权"概念，旨在解决大语言模型可能导致信息遗漏和偏见的问题，确保AI生成内容的真实性和公平性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的普及，人们开始依赖它们进行信息检索。与传统搜索引擎显示经过SEO优化、广告和个人化的排名列表不同，LLMs通常提供单一权威的合成回答。这可能导致多种观点被压缩成一个答案，降低用户比较替代方案的能力或意愿，从而将信息控制权集中在少数LLM供应商手中。

Method: 提出"被记住权"概念，包括最小化AI驱动信息遗漏风险、拥抱公平对待权利，同时确保生成内容最大程度真实。

Result: 识别了LLMs可能不成比例地压制某些叙述、个体或群体，同时不成比例地提升其他内容，从而逐渐抹除数字存在有限者并放大已突出者，重塑集体记忆的新威胁。

Conclusion: 需要建立"被记住权"框架来应对LLMs带来的信息偏见和遗漏风险，确保信息检索的公平性和真实性。

Abstract: Since the rapid expansion of large language models (LLMs), people have begun
to rely on them for information retrieval. While traditional search engines
display ranked lists of sources shaped by search engine optimization (SEO),
advertising, and personalization, LLMs typically provide a synthesized response
that feels singular and authoritative. While both approaches carry risks of
bias and omission, LLMs may amplify the effect by collapsing multiple
perspectives into one answer, reducing users ability or inclination to compare
alternatives. This concentrates power over information in a few LLM vendors
whose systems effectively shape what is remembered and what is overlooked. As a
result, certain narratives, individuals or groups, may be disproportionately
suppressed, while others are disproportionately elevated. Over time, this
creates a new threat: the gradual erasure of those with limited digital
presence, and the amplification of those already prominent, reshaping
collective memory.To address these concerns, this paper presents a concept of
the Right To Be Remembered (RTBR) which encompasses minimizing the risk of
AI-driven information omission, embracing the right of fair treatment, while
ensuring that the generated content would be maximally truthful.

</details>


### [50] [ScholarEval: Research Idea Evaluation Grounded in Literature](https://arxiv.org/abs/2510.16234)
*Hanane Nour Moussa,Patrick Queiroz Da Silva,Daniel Adu-Ampratwum,Alyson East,Zitong Lu,Nikki Puccetti,Mingyi Xue,Huan Sun,Bodhisattwa Prasad Majumder,Sachin Kumar*

Main category: cs.AI

TL;DR: 提出了ScholarEval框架，通过检索增强评估研究想法的合理性和贡献度，并在多领域数据集上验证其优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI工具在研究构思中的普及，需要建立强大的评估框架来确保生成想法的有效性和实用性。

Method: 开发了ScholarEval检索增强评估框架，基于两个核心标准评估研究想法：合理性（基于现有文献的方法有效性）和贡献度（相对于先前研究的不同维度进展程度）。

Result: 在ScholarIdeas数据集上，ScholarEval比所有基线方法覆盖了更多专家标注的评分点，且在评估可操作性、深度和证据支持方面持续优于OpenAI的o4-mini-deep-research系统。大规模用户研究显示在文献参与、想法精炼和实用性方面显著优于深度研究。

Conclusion: ScholarEval为研究想法评估提供了有效的框架，在多个维度上优于现有方法，并开源了代码、数据集和工具供社区使用。

Abstract: As AI tools become increasingly common for research ideation, robust
evaluation is critical to ensure the validity and usefulness of generated
ideas. We introduce ScholarEval, a retrieval augmented evaluation framework
that assesses research ideas based on two fundamental criteria: soundness - the
empirical validity of proposed methods based on existing literature, and
contribution - the degree of advancement made by the idea across different
dimensions relative to prior research. To evaluate ScholarEval, we introduce
ScholarIdeas, the first expert-annotated dataset of multi-domain research ideas
and reviews, comprised of 117 ideas across four disciplines: artificial
intelligence, neuroscience, biochemistry, and ecology. Our evaluation shows
that ScholarEval achieves significantly higher coverage of points mentioned in
the human expert annotated rubrics in ScholarIdeas compared to all baselines.
Furthermore, ScholarEval is consistently preferred over our strongest baseline
o4-mini-deep-research, a reasoning and search-enabled agentic system by OpenAI,
in terms of evaluation actionability, depth, and evidence support. Our
large-scale user study also shows that ScholarEval significantly outperforms
deep research in literature engagement, idea refinement, and usefulness. We
openly release our code, dataset, and ScholarEval tool for the community to use
and build on.

</details>


### [51] [Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense](https://arxiv.org/abs/2510.16259)
*Zhehao Zhang,Weijie Xu,Shixian Cui,Chandan K. Reddy*

Main category: cs.AI

TL;DR: 本文识别并系统分析了大推理模型(LRMs)的推理分心漏洞，即模型被恶意嵌入的复杂无关任务分散注意力，导致主要任务准确性下降高达60%。作者提出了基于训练的对策，通过监督微调和强化学习提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着大推理模型在数学和编程等复杂任务上表现出色，作者发现这些模型存在一个关键漏洞：容易被恶意嵌入的复杂无关任务分散注意力，从而影响主要任务的完成质量。

Method: 通过跨模型和基准的综合研究，分析推理分心漏洞；提出基于监督微调(SFT)和强化学习(RL)的训练防御方法，使用合成的对抗数据进行训练。

Result: 研究表明最先进的大推理模型高度易受攻击，注入的干扰物可使任务准确性降低高达60%；提出的防御方法在具有挑战性的干扰攻击上将鲁棒性提高了50多个百分点。

Conclusion: 推理分心是大推理模型可靠性的一个独特且紧迫的威胁，本文为构建更安全、更可信的推理系统提供了实用步骤。

Abstract: Recent advances in large reasoning models (LRMs) have enabled remarkable
performance on complex tasks such as mathematics and coding by generating long
Chain-of-Thought (CoT) traces. In this paper, we identify and systematically
analyze a critical vulnerability we term reasoning distraction, where LRMs are
diverted from their primary objective by irrelevant yet complex tasks
maliciously embedded in the prompt. Through a comprehensive study across
diverse models and benchmarks, we show that even state-of-the-art LRMs are
highly susceptible, with injected distractors reducing task accuracy by up to
60%. We further reveal that certain alignment techniques can amplify this
weakness and that models may exhibit covert compliance, following hidden
adversarial instructions in reasoning while concealing them in the final
output. To mitigate these risks, we propose a training-based defense that
combines Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on
synthetic adversarial data, improving robustness by over 50 points on
challenging distractor attacks. Our findings establish reasoning distraction as
a distinct and urgent threat to LRM reliability and provide a practical step
toward safer and more trustworthy reasoning systems.

</details>


### [52] [What Limits Agentic Systems Efficiency?](https://arxiv.org/abs/2510.16276)
*Song Bian,Minghao Yan,Anand Jayarajan,Gennady Pekhimenko,Shivaram Venkataraman*

Main category: cs.AI

TL;DR: 本文通过实证研究发现网络交互式智能体系统存在效率瓶颈，提出SpecCache缓存框架，通过推测执行显著降低网络环境延迟，提高缓存命中率58倍，减少网络开销3.2倍。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注智能体系统的推理性能，而忽视了效率问题。网络交互式智能体系统存在显著的延迟瓶颈，影响实际应用效果。

Method: 将端到端延迟分解为LLM API延迟和网络环境延迟，通过15个模型和5个提供商的实证研究，提出SpecCache缓存框架，结合推测执行来优化网络环境开销。

Result: 网络环境延迟可占系统总延迟的53.7%。SpecCache相比随机缓存策略提高缓存命中率58倍，减少网络环境开销3.2倍，且不降低系统性能。

Conclusion: 智能体系统的效率优化至关重要，SpecCache框架有效解决了网络环境延迟问题，为构建高效的网络交互式智能体系统提供了实用解决方案。

Abstract: Large Language Models (LLMs), such as OpenAI-o1 and DeepSeek-R1, have
demonstrated strong reasoning capabilities. To further enhance LLM
capabilities, recent agentic systems, such as Deep Research, incorporate web
interactions into LLM reasoning to mitigate uncertainties and reduce potential
errors. However, existing research predominantly focuses on reasoning
performance, often neglecting the efficiency of agentic systems. In this work,
we present a comprehensive empirical study that identifies efficiency
bottlenecks in web-interactive agentic systems. We decompose end-to-end latency
into two primary components: LLM API latency and web environment latency. We
conduct a comprehensive empirical study across 15 models and 5 providers to
demonstrate high variability in API-based agentic systems. We observe that web
environment latency can contribute as much as 53.7% to the overall latency in a
web-based agentic system. To improve latency, we propose SpecCache, a caching
framework augmented with speculative execution that can reduce web environment
overhead. Extensive evaluations on two standard benchmarks show that our
approach improves the cache hit rate by up to 58x compared to a random caching
strategy, while reducing web environment overhead by up to 3.2x, without
degrading agentic system performance.

</details>


### [53] [DTKG: Dual-Track Knowledge Graph-Verified Reasoning Framework for Multi-Hop QA](https://arxiv.org/abs/2510.16302)
*Changhao Wang,Yanfang Liu,Xinxin Fan,Anzhi Zhou,Lao Tian,Yunfeng Lu*

Main category: cs.AI

TL;DR: 提出DTKG框架解决多跳推理问答问题，结合知识图谱路径构建和LLM事实验证两种方法，提升多跳QA任务的效率和准确性


<details>
  <summary>Details</summary>
Motivation: 现有多跳推理方法要么使用LLM事实验证但链式推理表现不佳，要么使用KG路径构建但在并行事实验证时存在冗余路径检索问题，这些限制降低了多跳QA任务的效率和准确性

Method: 提出基于认知科学双过程理论的双轨KG验证和推理框架DTKG，包含分类阶段和分支处理阶段两个主要阶段

Result: 该方法旨在同时解决并行事实验证和链式多跳推理问题，通过结合两种技术的优势来提升整体性能

Conclusion: DTKG框架通过双轨方法有效解决了多跳推理问答中的效率和准确性问题，为多跳QA任务提供了更全面的解决方案

Abstract: Multi-hop reasoning for question answering (QA) plays a critical role in
retrieval-augmented generation (RAG) for modern large language models (LLMs).
The accurate answer can be obtained through retrieving relational structure of
entities from knowledge graph (KG). Regarding the inherent relation-dependency
and reasoning pattern, multi-hop reasoning can be in general classified into
two categories: i) parallel fact-verification multi-hop reasoning question,
i.e., requiring simultaneous verifications of multiple independent
sub-questions; and ii) chained multi-hop reasoning questions, i.e., demanding
sequential multi-step inference with intermediate conclusions serving as
essential premises for subsequent reasoning. Currently, the multi-hop reasoning
approaches singly employ one of two techniques: LLM response-based fact
verification and KG path-based chain construction. Nevertheless, the former
excels at parallel fact-verification but underperforms on chained reasoning
tasks, while the latter demonstrates proficiency in chained multi-hop reasoning
but suffers from redundant path retrieval when handling parallel
fact-verification reasoning. These limitations deteriorate the efficiency and
accuracy for multi-hop QA tasks. To address this challenge, we propose a novel
dual-track KG verification and reasoning framework DTKG, which is inspired by
the Dual Process Theory in cognitive science. Specifically, DTKG comprises two
main stages: the Classification Stage and the Branch Processing Stage.

</details>


### [54] [MedRule-KG: A Knowledge-Graph--Steered Scaffold for Mathematical Reasoning with a Lightweight Verifier](https://arxiv.org/abs/2510.16309)
*Crystal Su*

Main category: cs.AI

TL;DR: 提出了MedRule-KG，一个紧凑的带类型知识图谱和符号验证器，用于在推理任务中强制执行数学可解释规则，显著提升准确率并消除规则违反。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型经常产生流畅的推理步骤，但违反简单的数学或逻辑约束，需要一种方法来确保推理的数学可解释性和一致性。

Method: 构建MedRule-KG知识图谱，包含实体、关系和三个领域启发规则，配合符号验证器检查预测并应用最小修正以保证一致性。

Result: 在90个FDA衍生基准测试中，使用MedRule-KG将精确匹配从0.767提升到0.900，添加验证器后达到1.000精确匹配，完全消除规则违反。

Conclusion: MedRule-KG为安全的数学推理提供了一个通用框架，能够有效提升推理准确性和规则一致性。

Abstract: Large language models (LLMs) often produce fluent reasoning steps while
violating simple mathematical or logical constraints. We introduce MedRule-KG,
a compact typed knowledge graph coupled with a symbolic verifier, designed to
enforce mathematically interpretable rules in reasoning tasks. MedRule-KG
encodes entities, relations, and three domain-inspired rules, while the
verifier checks predictions and applies minimal corrections to guarantee
consistency. On a 90-example FDA-derived benchmark, grounding in MedRule-KG
improves exact match (EM) from 0.767 to 0.900, and adding the verifier yields
1.000 EM while eliminating rule violations entirely. We demonstrate how
MedRule-KG provides a general scaffold for safe mathematical reasoning, discuss
ablations, and release code and data to encourage reproducibility.

</details>


### [55] [Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts](https://arxiv.org/abs/2510.16342)
*Tong Zhang,Ru Zhang,Jianyi Liu,Zhen Yang,Gongshen Liu*

Main category: cs.AI

TL;DR: 提出了SELECT框架，通过动态锚点选择解决文本到图像扩散模型中概念擦除的锚点敏感性问题，克服固定锚点策略导致的概念重现和侵蚀问题。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法依赖固定锚点策略，导致概念重现和侵蚀等关键问题，需要解决锚点选择的敏感性。

Method: 通过因果追踪揭示擦除对锚点选择的敏感性，定义兄弟排他概念作为更优锚点类别，提出两阶段评估机制自动发现最优锚点并识别边界锚点。

Result: SELECT作为通用锚点解决方案，能高效适配多个擦除框架，在关键性能指标上持续优于现有基线，单个概念的锚点挖掘平均仅需4秒。

Conclusion: SELECT框架通过动态锚点选择有效解决了概念擦除中的锚点敏感性问题，实现了更精确的概念擦除效果。

Abstract: Existing concept erasure methods for text-to-image diffusion models commonly
rely on fixed anchor strategies, which often lead to critical issues such as
concept re-emergence and erosion. To address this, we conduct causal tracing to
reveal the inherent sensitivity of erasure to anchor selection and define
Sibling Exclusive Concepts as a superior class of anchors. Based on this
insight, we propose \textbf{SELECT} (Sibling-Exclusive Evaluation for
Contextual Targeting), a dynamic anchor selection framework designed to
overcome the limitations of fixed anchors. Our framework introduces a novel
two-stage evaluation mechanism that automatically discovers optimal anchors for
precise erasure while identifying critical boundary anchors to preserve related
concepts. Extensive evaluations demonstrate that SELECT, as a universal anchor
solution, not only efficiently adapts to multiple erasure frameworks but also
consistently outperforms existing baselines across key performance metrics,
averaging only 4 seconds for anchor mining of a single concept.

</details>


### [56] [Before you <think>, monitor: Implementing Flavell's metacognitive framework in LLMs](https://arxiv.org/abs/2510.16374)
*Nick Oh*

Main category: cs.AI

TL;DR: 该论文提出了一种结合监控-生成-验证的三阶段迭代系统，在GSM8K数学推理任务上取得了75.42%的准确率，优于现有方法且需要更少的尝试次数。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理增强方法存在分离问题：监控-生成方法擅长策略规划但缺乏验证机制，生成-验证方法能迭代优化但缺乏策略基础。这种分离导致策略失败无反馈、优化无战略指导的低效问题。

Method: 基于Flavell的认知监控模型，实现监控-生成-验证框架的三阶段迭代系统，将策略规划与输出验证有机结合。

Result: 在GSM8K上达到75.42%准确率，优于SELF-REFINE(68.44%)和Self-Verification(67.07%)，尝试次数更少(1.3 vs 2.0)，推理成本增加27-37%。

Conclusion: 前期监控能产生更高质量的初始解决方案，从而减少优化需求，但需要在算术推理之外的任务上进一步验证通用性。

Abstract: Current approaches to enhancing LLM reasoning follows two isolated paradigms:
Monitor-Generate methods like Plan-and-Solve (Wang et al., 2023) and
SELF-DISCOVER (Zhou et al., 2024) excel at strategic planning but lack
mechanisms to verify whether selected strategies succeed; while Generate-Verify
approaches like Self-Verification (Weng et al., 2022) and SELF-REFINE (Madaan
et al., 2023) iteratively refine outputs but commence generation blindly
without task assessment. This separation creates inefficiencies -- strategies
fail without feedback, and refinement occurs without strategic grounding. We
address this gap by implementing Flavell's cognitive monitoring model (1979)
from the broader Monitor-Generate-Verify framework (Oh and Gobet, 2025),
operationalising it as a three-phase iterative system. On GSM8K, preliminary
results show 75.42% accuracy versus 68.44% for SELF-REFINE and 67.07% for
Self-Verification, while requiring fewer attempts (1.3 vs 2.0) at 27-37%
increased inference cost. These initial findings suggest upfront monitoring
produces higher-quality initial solutions that reduce refinement needs, though
evaluation beyond arithmetic reasoning is needed to establish generalisability.

</details>


### [57] [Humanoid-inspired Causal Representation Learning for Domain Generalization](https://arxiv.org/abs/2510.16382)
*Ze Tao,Jian Zhang,Haowei Li,Xianshuai Li,Yifei Peng,Xiyao Liu,Senzhang Wang,Chao Liu,Sheng Ren,Shichao Zhang*

Main category: cs.AI

TL;DR: 提出受人类智能启发的HSCM因果框架，通过解耦和重加权图像属性来增强跨域泛化能力，在理论和实证评估中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 克服传统领域泛化模型的局限性，这些模型依赖统计方法捕捉数据-标签依赖关系，而HSCM模仿人类视觉系统的分层处理和多层次学习机制。

Method: 基于人类智能的层次处理和因果机制建模，通过解耦和重加权关键图像属性（颜色、纹理、形状）来学习细粒度因果机制。

Result: 在理论和实证评估中，HSCM优于现有的领域泛化模型，提供更稳健的性能和可解释性。

Conclusion: HSCM为捕捉因果关系和提升模型鲁棒性提供了更原则性的方法，在动态复杂环境中实现更有效的迁移学习。

Abstract: This paper proposes the Humanoid-inspired Structural Causal Model (HSCM), a
novel causal framework inspired by human intelligence, designed to overcome the
limitations of conventional domain generalization models. Unlike approaches
that rely on statistics to capture data-label dependencies and learn
distortion-invariant representations, HSCM replicates the hierarchical
processing and multi-level learning of human vision systems, focusing on
modeling fine-grained causal mechanisms. By disentangling and reweighting key
image attributes such as color, texture, and shape, HSCM enhances
generalization across diverse domains, ensuring robust performance and
interpretability. Leveraging the flexibility and adaptability of human
intelligence, our approach enables more effective transfer and learning in
dynamic, complex environments. Through both theoretical and empirical
evaluations, we demonstrate that HSCM outperforms existing domain
generalization models, providing a more principled method for capturing causal
relationships and improving model robustness. The code is available at
https://github.com/lambett/HSCM.

</details>


### [58] [RGMem: Renormalization Group-based Memory Evolution for Language Agent User Profile](https://arxiv.org/abs/2510.16392)
*Ao Tian,Yunfeng Lu,Xinxin Fan,Changhao Wang,Lanzhi Zhou,Yeyao Zhang,Yanfang Liu*

Main category: cs.AI

TL;DR: 提出了RGMem框架，通过多尺度信息压缩和涌现过程实现长期用户建模，解决LLM对话系统中跨会话长期用户状态建模的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案如RAG和显式记忆系统主要关注事实级存储和检索，缺乏从多轮对话中提取潜在偏好和深层特质的能力，限制了长期有效的用户建模。

Method: 受物理学重整化群思想启发，RGMem框架通过分层粗粒化和重标度操作，从片段对话中提取语义和用户洞察，逐步形成动态演化的用户画像。

Result: 实现了从噪声和微观层面交互中构建高级准确用户画像的能力。

Conclusion: RGMem框架通过多尺度记忆演化过程，为语言智能体在LLM时代实现了长期记忆和行为一致性。

Abstract: Personalized and continuous interactions are the key to enhancing user
experience in today's large language model (LLM)-based conversational systems,
however, the finite context windows and static parametric memory make it
difficult to model the cross-session long-term user states and behavioral
consistency. Currently, the existing solutions to this predicament, such as
retrieval-augmented generation (RAG) and explicit memory systems, primarily
focus on fact-level storage and retrieval, lacking the capability to distill
latent preferences and deep traits from the multi-turn dialogues, which limits
the long-term and effective user modeling, directly leading to the personalized
interactions remaining shallow, and hindering the cross-session continuity. To
realize the long-term memory and behavioral consistency for Language Agents in
LLM era, we propose a self-evolving memory framework RGMem, inspired by the
ideology of classic renormalization group (RG) in physics, this framework
enables to organize the dialogue history in multiple scales: it first extracts
semantics and user insights from episodic fragments, then through hierarchical
coarse-graining and rescaling operations, progressively forms a
dynamically-evolved user profile. The core innovation of our work lies in
modeling memory evolution as a multi-scale process of information compression
and emergence, which accomplishes the high-level and accurate user profiles
from noisy and microscopic-level interactions.

</details>


### [59] [ReviewSense: Transforming Customer Review Dynamics into Actionable Business Insights](https://arxiv.org/abs/2510.16466)
*Siddhartha Krothapalli,Tridib Kumar Das,Praveen Kumar,Naveen Suravarpu,Pratik Narang*

Main category: cs.AI

TL;DR: ReviewSense是一个基于大语言模型的决策支持框架，能够将客户评论转化为可操作的商业建议，超越了传统偏好预测系统。


<details>
  <summary>Details</summary>
Motivation: 传统AI系统擅长预测用户偏好，但缺乏将客户评论转化为面向业务的规范性建议的能力，需要开发能提供更深层次商业洞察的系统。

Method: 整合聚类、LLM适配和专家驱动评估的统一业务管道，识别客户情绪中的关键趋势、重复问题和具体关注点。

Result: 初步人工评估显示模型建议与商业目标高度一致，具有推动数据驱动决策的潜力。

Conclusion: 该框架为AI驱动的情感分析提供了新视角，在优化商业策略和最大化客户反馈影响力方面具有重要价值。

Abstract: As customer feedback becomes increasingly central to strategic growth, the
ability to derive actionable insights from unstructured reviews is essential.
While traditional AI-driven systems excel at predicting user preferences, far
less work has focused on transforming customer reviews into prescriptive,
business-facing recommendations. This paper introduces ReviewSense, a novel
prescriptive decision support framework that leverages advanced large language
models (LLMs) to transform customer reviews into targeted, actionable business
recommendations. By identifying key trends, recurring issues, and specific
concerns within customer sentiments, ReviewSense extends beyond
preference-based systems to provide businesses with deeper insights for
sustaining growth and enhancing customer loyalty. The novelty of this work lies
in integrating clustering, LLM adaptation, and expert-driven evaluation into a
unified, business-facing pipeline. Preliminary manual evaluations indicate
strong alignment between the model's recommendations and business objectives,
highlighting its potential for driving data-informed decision-making. This
framework offers a new perspective on AI-driven sentiment analysis,
demonstrating its value in refining business strategies and maximizing the
impact of customer feedback.

</details>


### [60] [NP-Engine: Empowering Optimization Reasoning in Large Language Models with Verifiable Synthetic NP Problems](https://arxiv.org/abs/2510.16476)
*Xiaozhe Li,Xinyu Fang,Shengyuan Ding,Linyang Li,Haodong Duan,Qingwen Liu,Kai Chen*

Main category: cs.AI

TL;DR: 提出了NP-ENGINE框架，这是首个用于训练和评估LLMs在NP难问题上的综合框架，包含10个任务、可控实例生成器、规则验证器和启发式求解器。训练出的QWEN2.5-7B-NP模型在NP-BENCH基准上显著优于GPT-4o，并展现出强大的跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs在数学、编程等推理任务上表现出色，但在解决更复杂的NP难优化问题方面的能力尚未充分探索，需要专门框架来填补这一空白。

Method: 提出NP-ENGINE框架，包含生成器-验证器-启发式求解器管道，支持可扩展的RLVR训练；使用零RLVR和课程学习训练QWEN2.5-7B-NP模型。

Result: QWEN2.5-7B-NP在NP-BENCH基准上显著优于GPT-4o，达到同模型尺寸下的SOTA性能；在跨领域推理任务和非推理任务上都展现出强大泛化能力；发现任务多样性增加能提升跨领域泛化。

Conclusion: 任务丰富的RLVR训练是提升LLM推理能力的有前景方向，揭示了RLVR的扩展规律，NP难问题训练能有效提升模型的通用推理能力。

Abstract: Large Language Models (LLMs) have shown strong reasoning capabilities, with
models like OpenAI's O-series and DeepSeek R1 excelling at tasks such as
mathematics, coding, logic, and puzzles through Reinforcement Learning with
Verifiable Rewards (RLVR). However, their ability to solve more complex
optimization problems - particularly NP-hard tasks - remains underexplored. To
bridge this gap, we propose NP-ENGINE, the first comprehensive framework for
training and evaluating LLMs on NP-hard problems. NP-ENGINE covers 10 tasks
across five domains, each equipped with (i) a controllable instance generator,
(ii) a rule-based verifier, and (iii) a heuristic solver that provides
approximate optimal solutions as ground truth. This
generator-verifier-heuristic pipeline enables scalable and verifiable RLVR
training under hierarchical difficulties. We also introduce NP-BENCH, a
benchmark derived from NP-ENGINE-DATA, specifically designed to evaluate LLMs'
ability to tackle NP-hard level reasoning problems, focusing not only on
feasibility but also on solution quality. Additionally, we present
QWEN2.5-7B-NP, a model trained via zero-RLVR with curriculum learning on
Qwen2.5-7B-Instruct, which significantly outperforms GPT-4o on NP-BENCH and
achieves SOTA performance with the same model size. Beyond in-domain tasks, we
demonstrate that RLVR training on NP-ENGINE-DATA enables strong out-of-domain
(OOD) generalization to reasoning tasks (logic, puzzles, math, and knowledge),
as well as non-reasoning tasks such as instruction following. We also observe a
scaling trend: increasing task diversity improves OOD generalization. These
findings suggest that task-rich RLVR training is a promising direction for
advancing LLM's reasoning ability, revealing new insights into the scaling laws
of RLVR.

</details>


### [61] [Hey Pentti, We Did It Again!: Differentiable vector-symbolic types that prove polynomial termination](https://arxiv.org/abs/2510.16533)
*Eilene Tomkins-Flanagan,Connor Hanley,Mary A. Kelly*

Main category: cs.AI

TL;DR: 提出了Doug语言，一种基于向量符号架构的类型化编程语言，所有类型化程序都能在多项式时间内终止，可用于神经网络的技能学习建模。


<details>
  <summary>Details</summary>
Motivation: 希望描述一种符合人类技能获取速度的学习方式，比现有方法更高效，更接近大脑中实际存在的心理表征及其获取过程。

Method: 将轻量线性函数式编程语言编码到向量符号架构中，使用基于全息声明性记忆的槽值编码方案表示类型，使用Lisp VSA变体表示项。

Result: Doug允许神经网络嵌入空间中的某些点被解释为类型，且邻近点的类型在结构和内容上都相似，因此类型可由神经网络学习。

Conclusion: 该方法使我们更接近建模大脑中实际存在的心理表征及其获取过程，为技能获取提供了一种新的程序合成方法。

Abstract: We present a typed computer language, Doug, in which all typed programs may
be proved to halt in polynomial time, encoded in a vector-symbolic architecture
(VSA). Doug is just an encoding of the light linear functional programming
language (LLFPL) described by (Schimanski2009, ch. 7). The types of Doug are
encoded using a slot-value encoding scheme based on holographic declarative
memory (HDM; Kelly, 2020). The terms of Doug are encoded using a variant of the
Lisp VSA defined by (Flanagan, 2024). Doug allows for some points on the
embedding space of a neural network to be interpreted as types, where the types
of nearby points are similar both in structure and content. Types in Doug are
therefore learnable by a neural network. Following (Chollet, 2019), (Card,
1983), and (Newell, 1981), we view skill as the application of a procedure, or
program of action, that causes a goal to be satisfied. Skill acquisition may
therefore be expressed as program synthesis. Using Doug, we hope to describe a
form of learning of skilled behaviour that follows a human-like pace of skill
acquisition (i.e., substantially faster than brute force; Heathcote, 2000),
exceeding the efficiency of all currently existing approaches (Kaplan, 2020;
Jones, 2021; Chollet, 2024). Our approach brings us one step closer to modeling
human mental representations, as they must actually exist in the brain, and
those representations' acquisition, as they are actually learned.

</details>


### [62] [Urban-R1: Reinforced MLLMs Mitigate Geospatial Biases for Urban General Intelligence](https://arxiv.org/abs/2510.16555)
*Qiongyan Wang,Xingchen Zou,Yutian Jiang,Haomin Wen,Jiaheng Wei,Qingsong Wen,Yuxuan Liang*

Main category: cs.AI

TL;DR: 提出Urban-R1框架，使用强化学习对齐多模态大模型与城市通用智能目标，通过分组相对策略优化缓解地理偏见，提升跨区域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 快速城市化加剧了对城市通用智能的需求，现有基于监督微调的城市基础模型存在持续的地理偏见，导致区域预测偏差和有限泛化能力。

Method: 采用基于强化学习的后训练框架Urban-R1，使用分组相对策略优化(GRPO)优化跨地理群体的推理，并以城市区域画像作为代理任务从多模态城市数据提供可测量奖励。

Result: 跨多个区域和任务的广泛实验表明，Urban-R1有效缓解地理偏见并改善跨区域泛化，优于监督微调训练和闭源模型。

Conclusion: 强化学习对齐是实现公平可信城市智能的有前景路径。

Abstract: Rapid urbanization intensifies the demand for Urban General Intelligence
(UGI), referring to AI systems that can understand and reason about complex
urban environments. Recent studies have built urban foundation models using
supervised fine-tuning (SFT) of LLMs and MLLMs, yet these models exhibit
persistent geospatial bias, producing regionally skewed predictions and limited
generalization. To this end, we propose Urban-R1, a reinforcement
learning-based post-training framework that aligns MLLMs with the objectives of
UGI. Urban-R1 adopts Group Relative Policy Optimization (GRPO) to optimize
reasoning across geographic groups and employs urban region profiling as a
proxy task to provide measurable rewards from multimodal urban data. Extensive
experiments across diverse regions and tasks show that Urban-R1 effectively
mitigates geo-bias and improves cross-region generalization, outperforming both
SFT-trained and closed-source models. Our results highlight reinforcement
learning alignment as a promising pathway toward equitable and trustworthy
urban intelligence.

</details>


### [63] [BuildArena: A Physics-Aligned Interactive Benchmark of LLMs for Engineering Construction](https://arxiv.org/abs/2510.16559)
*Tian Xia,Tianrun Gao,Wenhao Deng,Long Wei,Xiaowei Qian,Yixian Jiang,Chenglei Yu,Tailin Wu*

Main category: cs.AI

TL;DR: BuildArena是首个面向语言驱动工程建设的物理对齐交互式基准测试，用于评估LLM在工程建筑自动化中的能力。


<details>
  <summary>Details</summary>
Motivation: 虽然现代LLM具有广泛知识和强大推理能力，但它们在工程建设领域的专业能力尚未得到系统评估，需要专门的基准测试来填补这一空白。

Method: 开发了高度可定制的基准框架，包含可扩展的任务设计策略、3D空间几何计算库和基线LLM代理工作流程，用于评估8个前沿LLM。

Result: BuildArena能够全面评估LLM在语言驱动和物理基础的建筑自动化方面的能力，为社区提供了首个物理对齐的交互式基准测试。

Conclusion: BuildArena填补了LLM在工程建设自动化领域评估的空白，为语言驱动的物理约束建筑任务提供了系统化的评估框架。

Abstract: Engineering construction automation aims to transform natural language
specifications into physically viable structures, requiring complex integrated
reasoning under strict physical constraints. While modern LLMs possess broad
knowledge and strong reasoning capabilities that make them promising candidates
for this domain, their construction competencies remain largely unevaluated. To
address this gap, we introduce BuildArena, the first physics-aligned
interactive benchmark designed for language-driven engineering construction. It
contributes to the community in four aspects: (1) a highly customizable
benchmarking framework for in-depth comparison and analysis of LLMs; (2) an
extendable task design strategy spanning static and dynamic mechanics across
multiple difficulty tiers; (3) a 3D Spatial Geometric Computation Library for
supporting construction based on language instructions; (4) a baseline LLM
agentic workflow that effectively evaluates diverse model capabilities. On
eight frontier LLMs, BuildArena comprehensively evaluates their capabilities
for language-driven and physics-grounded construction automation. The project
page is at https://build-arena.github.io/.

</details>


### [64] [Ripple Effect Protocol: Coordinating Agent Populations](https://arxiv.org/abs/2510.16572)
*Ayush Chopra,Aman Sharma,Feroz Ahmad,Luca Muscariello,Vijoy Pandey,Ramesh Raskar*

Main category: cs.AI

TL;DR: 提出了Ripple Effect Protocol (REP)，一种协调协议，让智能体不仅共享决策，还共享轻量级敏感度信号，从而在群体中实现更快更稳定的协调。


<details>
  <summary>Details</summary>
Motivation: 现有的AI智能体通信协议（如A2A和ACP）强调通信而非协调，随着智能体群体规模增长，这会导致脆弱的集体行为，即使个体智能体很聪明，群体结果也很差。

Method: REP协议让智能体共享决策和轻量级敏感度信号（表达关键环境变量变化时选择如何改变），这些敏感度在局部网络中传播。协议规范分离了必需的消息模式与可选的聚合规则。

Result: 在三个领域的基准测试中：（i）供应链级联（啤酒游戏）、（ii）稀疏网络中的偏好聚合（电影调度）、（iii）可持续资源分配（Fishbanks），REP相比A2A将协调准确性和效率提高了41%到100%。

Conclusion: 通过将协调作为协议级能力，REP为新兴的智能体互联网提供了可扩展的基础设施。

Abstract: Modern AI agents can exchange messages using protocols such as A2A and ACP,
yet these mechanisms emphasize communication over coordination. As agent
populations grow, this limitation produces brittle collective behavior, where
individually smart agents converge on poor group outcomes. We introduce the
Ripple Effect Protocol (REP), a coordination protocol in which agents share not
only their decisions but also lightweight sensitivities - signals expressing
how their choices would change if key environmental variables shifted. These
sensitivities ripple through local networks, enabling groups to align faster
and more stably than with agent-centric communication alone. We formalize REP's
protocol specification, separating required message schemas from optional
aggregation rules, and evaluate it across scenarios with varying incentives and
network topologies. Benchmarks across three domains: (i) supply chain cascades
(Beer Game), (ii) preference aggregation in sparse networks (Movie Scheduling),
and (iii) sustainable resource allocation (Fishbanks) show that REP improves
coordination accuracy and efficiency over A2A by 41 to 100%, while flexibly
handling multimodal sensitivity signals from LLMs. By making coordination a
protocol-level capability, REP provides scalable infrastructure for the
emerging Internet of Agents

</details>


### [65] [Can Knowledge-Graph-based Retrieval Augmented Generation Really Retrieve What You Need?](https://arxiv.org/abs/2510.16582)
*Junchi Yu,Yujie Liu,Jindong Gu,Philip Torr,Dongzhan Zhou*

Main category: cs.AI

TL;DR: GraphFlow是一个基于知识图谱的检索增强生成框架，通过流匹配目标优化检索策略，从文本丰富的知识图谱中高效检索准确多样的知识。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图谱的RAG方法难以从文本丰富的知识图谱中为复杂真实世界查询检索准确多样的信息，而过程奖励模型需要昂贵的过程级监督信号。

Method: 使用基于转移的流匹配目标联合优化检索策略和流估计器，流估计器将检索结果的奖励分解到中间检索状态，指导检索策略按奖励比例从知识图谱中检索候选。

Result: 在STaRK基准测试中，GraphFlow在命中率和召回率上平均优于强基线（包括GPT-4o）10%，并对未见过的知识图谱表现出强泛化能力。

Conclusion: GraphFlow框架能有效从文本丰富的知识图谱中检索准确多样的知识，在真实世界查询中表现出优越性能和鲁棒性。

Abstract: Retrieval-Augmented Generation (RAG) based on knowledge graphs (KGs) enhances
large language models (LLMs) by providing structured and interpretable external
knowledge. However, existing KG-based RAG methods struggle to retrieve accurate
and diverse information from text-rich KGs for complex real-world queries.
Process Reward Models (PRMs) offer a way to align the retrieval process of
KG-based RAG with query-specific knowledge requirements, but they heavily rely
on process-level supervision signals that are expensive and hard to obtain on
KGs. To address this challenge, we propose GraphFlow, a framework that
efficiently retrieves accurate and diverse knowledge required for real-world
queries from text-rich KGs. GraphFlow employs a transition-based flow matching
objective to jointly optimize a retrieval policy and a flow estimator. The flow
estimator factorizes the reward of the retrieval outcome into the intermediate
retrieval states. Such reward factorization guides the retrieval policy to
retrieve candidates from KGs in proportion to their reward. This allows
GraphFlow to explore high-quality regions of KGs that yield diverse and
relevant results. We evaluate GraphFlow on the STaRK benchmark, which includes
real-world queries from multiple domains over text-rich KGs. GraphFlow
outperforms strong KG-RAG baselines, including GPT-4o, by 10% on average in hit
rate and recall. It also shows strong generalization to unseen KGs,
demonstrating its effectiveness and robustness.

</details>


### [66] [Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution Learning](https://arxiv.org/abs/2510.16601)
*Tianxing Wu,Shutong Zhu,Jingting Wang,Ning Xu,Guilin Qi,Haofen Wang*

Main category: cs.AI

TL;DR: 提出了一种半监督置信度分布学习方法（ssCDL），用于解决不确定知识图谱补全中置信度分布极度不平衡的问题，通过将置信度转换为分布并利用元学习生成伪标签来增强训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有不确定知识图谱补全方法忽略了置信度的极度不平衡分布，导致学习到的嵌入表示不足以支持高质量的知识图谱补全。

Method: 将每个三元组置信度转换为置信度分布，引入更多监督信息；通过元学习预测未见三元组的置信度生成伪标签，在标记数据和未标记数据上迭代学习嵌入表示。

Result: 在两个不确定知识图谱数据集上的实验表明，ssCDL在不同评估指标上均优于现有最优基线方法。

Conclusion: ssCDL方法通过处理置信度分布不平衡问题，有效提升了不确定知识图谱补全的性能。

Abstract: Uncertain knowledge graphs (UKGs) associate each triple with a confidence
score to provide more precise knowledge representations. Recently, since
real-world UKGs suffer from the incompleteness, uncertain knowledge graph (UKG)
completion attracts more attention, aiming to complete missing triples and
confidences. Current studies attempt to learn UKG embeddings to solve this
problem, but they neglect the extremely imbalanced distributions of triple
confidences. This causes that the learnt embeddings are insufficient to
high-quality UKG completion. Thus, in this paper, to address the above issue,
we propose a new semi-supervised Confidence Distribution Learning (ssCDL)
method for UKG completion, where each triple confidence is transformed into a
confidence distribution to introduce more supervision information of different
confidences to reinforce the embedding learning process. ssCDL iteratively
learns UKG embedding by relational learning on labeled data (i.e., existing
triples with confidences) and unlabeled data with pseudo labels (i.e., unseen
triples with the generated confidences), which are predicted by meta-learning
to augment the training data and rebalance the distribution of triple
confidences. Experiments on two UKG datasets demonstrate that ssCDL
consistently outperforms state-of-the-art baselines in different evaluation
metrics.

</details>


### [67] [Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards](https://arxiv.org/abs/2510.16614)
*Xuan Zhang,Ruixiao Li,Zhijian Zhou,Long Li,Yulei Qin,Ke Li,Xing Sun,Xiaoyu Tan,Chao Qu,Yuan Qi*

Main category: cs.AI

TL;DR: MERCI是一种新颖的强化学习算法，通过基于计数的内在奖励来增强LLM推理中的探索，避免陷入重复和次优的推理模式。


<details>
  <summary>Details</summary>
Motivation: 现有RL范式依赖稀疏的结果奖励和有限探索，导致LLM倾向于重复和次优的推理模式，需要设计更好的探索机制。

Method: 使用轻量级Coin Flipping Network估计推理轨迹的伪计数和认知不确定性，将其转换为内在奖励，并与任务奖励结合。

Result: 在复杂推理基准测试中，MERCI鼓励更丰富多样的思维链，显著优于强基线，帮助策略逃离局部模式发现更好解决方案。

Conclusion: 有针对性的内在动机可以使语言模型推理中的探索更加可靠有效。

Abstract: Reinforcement Learning (RL) has become a compelling way to strengthen the
multi step reasoning ability of Large Language Models (LLMs). However,
prevalent RL paradigms still lean on sparse outcome-based rewards and limited
exploration, which often drives LLMs toward repetitive and suboptimal reasoning
patterns. In this paper, we study the central question of how to design
exploration for LLM reasoning and introduce MERCI (Motivating Exploration in
LLM Reasoning with Count-based Intrinsic Rewards), a novel RL algorithm that
augments policy optimization with a principled intrinsic reward. Building on
the idea of count-based exploration, MERCI leverages a lightweight Coin
Flipping Network (CFN) to estimate the pseudo count and further epistemic
uncertainty over reasoning trajectories, and converts them into an intrinsic
reward that values novelty while preserving the learning signal from task
rewards. We integrate MERCI into some advanced RL frameworks like Group
Relative Policy Optimization (GRPO). Experiments on complex reasoning
benchmarks demonstrate that MERCI encourages richer and more varied chains of
thought, significantly improves performance over strong baselines, and helps
the policy escape local routines to discover better solutions. It indicates
that our targeted intrinsic motivation can make exploration reliable for
language model reasoning.

</details>


### [68] [Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review](https://arxiv.org/abs/2510.16658)
*Shihao Yang,Xiying Huang,Danilo Bernardo,Jun-En Ding,Andrew Michael,Jingmei Yang,Patrick Kwan,Ashish Raj,Feng Liu*

Main category: cs.AI

TL;DR: 大规模AI模型正在变革神经科学研究，通过端到端学习从原始脑信号中提取信息，在神经影像、脑机接口、分子神经科学、临床辅助和疾病应用等五大领域产生深远影响。


<details>
  <summary>Details</summary>
Motivation: 传统计算方法在神经科学中面临多模态数据整合、时空模式解释等挑战，需要更强大的AI模型来促进神经科学研究的范式转变。

Method: 通过大规模AI模型实现端到端学习，整合多模态神经数据，结合生物学启发的架构约束开发更可解释和计算高效的模型。

Result: 这些模型成功解决了神经科学中的主要计算挑战，促进了神经科学与AI的互惠发展，并建立了临床部署的转化框架。

Conclusion: 大规模AI模型在神经科学中展现出巨大潜力，但需要严格的评估框架、有效的领域知识整合和全面的临床伦理指南来确保成功实施。

Abstract: The advent of large-scale artificial intelligence (AI) models has a
transformative effect on neuroscience research, which represents a paradigm
shift from the traditional computational methods through the facilitation of
end-to-end learning from raw brain signals and neural data. In this paper, we
explore the transformative effects of large-scale AI models on five major
neuroscience domains: neuroimaging and data processing, brain-computer
interfaces and neural decoding, molecular neuroscience and genomic modeling,
clinical assistance and translational frameworks, and disease-specific
applications across neurological and psychiatric disorders. These models are
demonstrated to address major computational neuroscience challenges, including
multimodal neural data integration, spatiotemporal pattern interpretation, and
the derivation of translational frameworks for clinical deployment. Moreover,
the interaction between neuroscience and AI has become increasingly reciprocal,
as biologically informed architectural constraints are now incorporated to
develop more interpretable and computationally efficient models. This review
highlights both the notable promise of such technologies and key implementation
considerations, with particular emphasis on rigorous evaluation frameworks,
effective domain knowledge integration, and comprehensive ethical guidelines
for clinical use. Finally, a systematic listing of critical neuroscience
datasets used to derive and validate large-scale AI models across diverse
research applications is provided.

</details>


### [69] [An Agentic Framework with LLMs for Solving Complex Vehicle Routing Problems](https://arxiv.org/abs/2510.16701)
*Ni Zhang,Zhiguang Cao,Jianan Zhou,Cong Zhang,Yew-Soon Ong*

Main category: cs.AI

TL;DR: 提出了一个基于大语言模型的自主代理框架AFL，用于解决复杂车辆路径问题，实现了从问题实例到解决方案的完全自动化，无需人工干预或外部求解器。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的方法在解决复杂车辆路径问题时仍需要外部干预，导致自主性受限、执行错误多和解决方案可行性低。

Method: AFL框架将整个流程分解为三个可管理的子任务，并采用四个专门化代理，通过协调交互确保跨功能一致性和逻辑合理性，直接从原始输入提取知识并生成自包含代码。

Result: 在60个复杂VRP问题上的实验表明，该框架在代码可靠性和解决方案可行性方面显著优于现有基于LLM的基线方法，在评估基准上接近100%的成功率，与精心设计的算法性能相当。

Conclusion: AFL框架为实现复杂车辆路径问题的完全自动化求解提供了有效途径，显著提升了基于LLM方法的可靠性和可行性。

Abstract: Complex vehicle routing problems (VRPs) remain a fundamental challenge,
demanding substantial expert effort for intent interpretation and algorithm
design. While large language models (LLMs) offer a promising path toward
automation, current approaches still rely on external intervention, which
restrict autonomy and often lead to execution errors and low solution
feasibility. To address these challenges, we propose an Agentic Framework with
LLMs (AFL) for solving complex vehicle routing problems, achieving full
automation from problem instance to solution. AFL directly extracts knowledge
from raw inputs and enables self-contained code generation without handcrafted
modules or external solvers. To improve trustworthiness, AFL decomposes the
overall pipeline into three manageable subtasks and employs four specialized
agents whose coordinated interactions enforce cross-functional consistency and
logical soundness. Extensive experiments on 60 complex VRPs, ranging from
standard benchmarks to practical variants, validate the effectiveness and
generality of our framework, showing comparable performance against
meticulously designed algorithms. Notably, it substantially outperforms
existing LLM-based baselines in both code reliability and solution feasibility,
achieving rates close to 100% on the evaluated benchmarks.

</details>


### [70] [Beyond Pipelines: A Survey of the Paradigm Shift toward Model-Native Agentic AI](https://arxiv.org/abs/2510.16720)
*Jitao Sang,Jinlin Xiao,Jiarun Han,Jilin Chen,Xiaoyi Chen,Shuyu Wei,Yongjie Sun,Yuhang Wang*

Main category: cs.AI

TL;DR: 本文综述了智能AI从基于管道的系统向模型原生范式的范式转变，其中规划、工具使用和记忆等能力从外部编排转变为模型内部参数化，并通过强化学习实现端到端学习。


<details>
  <summary>Details</summary>
Motivation: 追踪智能AI构建方式的范式转变，从外部逻辑编排的管道系统转向能力内部化的模型原生范式，探索AI从被动响应到主动行动、推理和适应的演进。

Method: 系统回顾了规划、工具使用和记忆三大能力的演进过程，分析了强化学习作为算法引擎如何支撑LLM+RL+Task的统一解决方案，并考察了深度研究代理和GUI代理等主要应用。

Result: 揭示了智能AI能力从外部脚本模块向端到端学习行为的转变轨迹，展示了模型原生智能AI作为集成学习和交互框架的发展路径。

Conclusion: 智能AI正朝着模型原生方向发展，从构建应用智能的系统转向开发通过经验增长智能的模型，多智能体协作和反思等能力将继续内部化，系统和模型层的角色将不断演变。

Abstract: The rapid evolution of agentic AI marks a new phase in artificial
intelligence, where Large Language Models (LLMs) no longer merely respond but
act, reason, and adapt. This survey traces the paradigm shift in building
agentic AI: from Pipeline-based systems, where planning, tool use, and memory
are orchestrated by external logic, to the emerging Model-native paradigm,
where these capabilities are internalized within the model's parameters. We
first position Reinforcement Learning (RL) as the algorithmic engine enabling
this paradigm shift. By reframing learning from imitating static data to
outcome-driven exploration, RL underpins a unified solution of LLM + RL + Task
across language, vision and embodied domains. Building on this, the survey
systematically reviews how each capability -- Planning, Tool use, and Memory --
has evolved from externally scripted modules to end-to-end learned behaviors.
Furthermore, it examines how this paradigm shift has reshaped major agent
applications, specifically the Deep Research agent emphasizing long-horizon
reasoning and the GUI agent emphasizing embodied interaction. We conclude by
discussing the continued internalization of agentic capabilities like
Multi-agent collaboration and Reflection, alongside the evolving roles of the
system and model layers in future agentic AI. Together, these developments
outline a coherent trajectory toward model-native agentic AI as an integrated
learning and interaction framework, marking the transition from constructing
systems that apply intelligence to developing models that grow intelligence
through experience.

</details>


### [71] [A Comprehensive Survey on Reinforcement Learning-based Agentic Search: Foundations, Roles, Optimizations, Evaluations, and Applications](https://arxiv.org/abs/2510.16724)
*Minhua Lin,Zongyu Wu,Zhichao Xu,Hui Liu,Xianfeng Tang,Qi He,Charu Aggarwal,Hui Liu,Xiang Zhang,Suhang Wang*

Main category: cs.AI

TL;DR: 该论文首次对基于强化学习的智能搜索领域进行全面综述，从功能角色、优化策略和应用范围三个维度组织这一新兴领域，总结了代表性方法、评估协议和应用，并讨论了构建可靠可扩展系统的挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在静态知识、事实幻觉和无法获取实时或领域特定信息等限制，传统检索增强生成方法缺乏对检索和推理的自适应控制。智能搜索通过多步交互解决了这些限制，而强化学习为自适应和自我改进的搜索行为提供了强大机制。

Method: 从三个互补维度组织基于强化学习的智能搜索领域：(i) RL的功能角色，(ii) RL的优化策略，(iii) RL的应用范围。通过综述代表性方法、评估协议和应用来系统化这一新兴领域。

Result: 提供了该领域的首个全面概述，建立了系统化的分类框架，总结了现有方法和技术，为未来研究提供了基础。

Conclusion: 基于强化学习的智能搜索是一个有前景的研究方向，需要进一步解决可靠性和可扩展性挑战。该综述旨在激发RL与智能搜索集成方面的未来研究。

Abstract: The advent of large language models (LLMs) has transformed information access
and reasoning through open-ended natural language interaction. However, LLMs
remain limited by static knowledge, factual hallucinations, and the inability
to retrieve real-time or domain-specific information. Retrieval-Augmented
Generation (RAG) mitigates these issues by grounding model outputs in external
evidence, but traditional RAG pipelines are often single turn and heuristic,
lacking adaptive control over retrieval and reasoning. Recent advances in
agentic search address these limitations by enabling LLMs to plan, retrieve,
and reflect through multi-step interaction with search environments. Within
this paradigm, reinforcement learning (RL) offers a powerful mechanism for
adaptive and self-improving search behavior. This survey provides the first
comprehensive overview of \emph{RL-based agentic search}, organizing the
emerging field along three complementary dimensions: (i) What RL is for
(functional roles), (ii) How RL is used (optimization strategies), and (iii)
Where RL is applied (scope of optimization). We summarize representative
methods, evaluation protocols, and applications, and discuss open challenges
and future directions toward building reliable and scalable RL driven agentic
search systems. We hope this survey will inspire future research on the
integration of RL and agentic search. Our repository is available at
https://github.com/ventr1c/Awesome-RL-based-Agentic-Search-Papers.

</details>


### [72] [Surrogate Modeling and Explainable Artificial Intelligence for Complex Systems: A Workflow for Automated Simulation Exploration](https://arxiv.org/abs/2510.16742)
*Paul Saves,Pramudita Satria Palar,Muhammad Daffa Robani,Nicolas Verstaevel,Moncef Garouani,Julien Aligon,Benoit Gaudou,Koji Shimoyama,Joseph Morlier*

Main category: cs.AI

TL;DR: 提出了一种基于代理模型的仿真驱动工程工作流，通过训练轻量级仿真器来解决计算成本高和黑盒透明度不足的问题，支持不确定性量化和可解释AI分析。


<details>
  <summary>Details</summary>
Motivation: 仿真驱动工程工作流面临两个核心障碍：(1)高计算成本，准确探索需要大量昂贵的模拟器运行；(2)黑盒组件导致的透明度不足和可靠性有限。

Method: 在紧凑实验设计上训练轻量级仿真器，提供快速近似、支持不确定性量化，并适配全局和局部可解释AI分析。结合全局效应、不确定性分析与局部归因，评估不同代理模型间解释的一致性。

Result: 在混合电动飞机多学科设计分析和城市隔离基于代理模型两个案例中，该方法实现了秒级大规模探索，揭示了非线性相互作用和涌现行为，识别了关键设计和政策杠杆。

Conclusion: 代理模型与可解释AI的耦合能够实现高效的大规模探索，发现复杂系统中的关键特征，并指导进一步数据收集或模型改进。

Abstract: Complex systems are increasingly explored through simulation-driven
engineering workflows that combine physics-based and empirical models with
optimization and analytics. Despite their power, these workflows face two
central obstacles: (1) high computational cost, since accurate exploration
requires many expensive simulator runs; and (2) limited transparency and
reliability when decisions rely on opaque blackbox components. We propose a
workflow that addresses both challenges by training lightweight emulators on
compact designs of experiments that (i) provide fast, low-latency
approximations of expensive simulators, (ii) enable rigorous uncertainty
quantification, and (iii) are adapted for global and local Explainable
Artificial Intelligence (XAI) analyses. This workflow unifies every
simulation-based complex-system analysis tool, ranging from engineering design
to agent-based models for socio-environmental understanding. In this paper, we
proposea comparative methodology and practical recommendations for using
surrogate-based explainability tools within the proposed workflow. The
methodology supports continuous and categorical inputs, combines global-effect
and uncertainty analyses with local attribution, and evaluates the consistency
of explanations across surrogate models, thereby diagnosing surrogate adequacy
and guiding further data collection or model refinement. We demonstrate the
approach on two contrasting case studies: a multidisciplinary design analysis
of a hybrid-electric aircraft and an agent-based model of urban segregation.
Results show that the surrogate model and XAI coupling enables large-scale
exploration in seconds, uncovers nonlinear interactions and emergent behaviors,
identifies key design and policy levers, and signals regions where surrogates
require more data or alternative architectures.

</details>


### [73] [ELMM: Efficient Lightweight Multimodal Large Language Models for Multimodal Knowledge Graph Completion](https://arxiv.org/abs/2510.16753)
*Wei Huang,Peining Li,Meiyu Liang,Xu Hou,Junping Du,Yingxia Shao,Guanhua Ye,Wu Liu,Kangkang Lu,Yang Yu*

Main category: cs.AI

TL;DR: 提出ELMM模型用于多模态知识图谱补全，通过多视图视觉令牌压缩器和注意力剪枝策略，在保持性能的同时显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有MKG存在不完整性问题，而将MLLMs应用于MKGC面临图像令牌过多导致的语义噪声、模态冲突和高计算成本等挑战。

Method: 提出多视图视觉令牌压缩器(MVTC)基于多头注意力机制自适应压缩图像令牌，并设计注意力剪枝策略减少冗余层，使用线性投影补偿性能损失。

Result: 在FB15k-237-IMG和WN18-IMG基准测试中达到最先进性能，同时大幅提升计算效率。

Conclusion: ELMM为多模态知识图谱补全建立了新范式，在性能和效率方面均表现优异。

Abstract: Multimodal Knowledge Graphs (MKGs) extend traditional knowledge graphs by
incorporating visual and textual modalities, enabling richer and more
expressive entity representations. However, existing MKGs often suffer from
incompleteness, which hinder their effectiveness in downstream tasks.
Therefore, multimodal knowledge graph completion (MKGC) task is receiving
increasing attention. While large language models (LLMs) have shown promise for
knowledge graph completion (KGC), their application to the multimodal setting
remains underexplored. Moreover, applying Multimodal Large Language Models
(MLLMs) to the task of MKGC introduces significant challenges: (1) the large
number of image tokens per entity leads to semantic noise and modality
conflicts, and (2) the high computational cost of processing large token
inputs. To address these issues, we propose Efficient Lightweight Multimodal
Large Language Models (ELMM) for MKGC. ELMM proposes a Multi-view Visual Token
Compressor (MVTC) based on multi-head attention mechanism, which adaptively
compresses image tokens from both textual and visual views, thereby effectively
reducing redundancy while retaining necessary information and avoiding modality
conflicts. Additionally, we design an attention pruning strategy to remove
redundant attention layers from MLLMs, thereby significantly reducing the
inference cost. We further introduce a linear projection to compensate for the
performance degradation caused by pruning. Extensive experiments on benchmark
FB15k-237-IMG and WN18-IMG demonstrate that ELMM achieves state-of-the-art
performance while substantially improving computational efficiency,
establishing a new paradigm for multimodal knowledge graph completion.

</details>


### [74] [See or Say Graphs: Agent-Driven Scalable Graph Understanding with Vision-Language Models](https://arxiv.org/abs/2510.16769)
*Shuo Han,Yukun Cao,Zezhong Ding,Zengyi Gao,S Kevin Zhou,Xike Xie*

Main category: cs.AI

TL;DR: GraphVista是一个统一框架，通过分层组织图信息和引入规划代理来解决视觉语言模型在图理解中的可扩展性和模态协调问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在图理解中面临输入令牌限制、可扩展性瓶颈以及缺乏有效协调文本和视觉模态机制的问题。

Method: GraphVista采用分层方法将图信息组织成轻量级GraphRAG基础，仅检索任务相关文本描述和高分辨率视觉子图；引入规划代理根据任务复杂度路由到最适合的模态。

Result: GraphVista可扩展到比现有基准大200倍的大型图，在质量上比最先进基线提升4.4倍，持续优于现有文本、视觉和融合方法。

Conclusion: GraphVista通过充分利用两种模态的互补优势，有效解决了图理解中的可扩展性和模态协调挑战。

Abstract: Vision-language models (VLMs) have shown promise in graph understanding, but
remain limited by input-token constraints, facing scalability bottlenecks and
lacking effective mechanisms to coordinate textual and visual modalities. To
address these challenges, we propose GraphVista, a unified framework that
enhances both scalability and modality coordination in graph understanding. For
scalability, GraphVista organizes graph information hierarchically into a
lightweight GraphRAG base, which retrieves only task-relevant textual
descriptions and high-resolution visual subgraphs, compressing redundant
context while preserving key reasoning elements. For modality coordination,
GraphVista introduces a planning agent that routes tasks to the most suitable
modality-using the text modality for simple property reasoning and the visual
modality for local and structurally complex reasoning grounded in explicit
topology. Extensive experiments demonstrate that GraphVista scales to large
graphs, up to $200\times$ larger than those used in existing benchmarks, and
consistently outperforms existing textual, visual, and fusion-based methods,
achieving up to $4.4\times$ quality improvement over the state-of-the-art
baselines by fully exploiting the complementary strengths of both modalities.

</details>


### [75] [Domain-Contextualized Concept Graphs: A Computable Framework for Knowledge Representation](https://arxiv.org/abs/2510.16802)
*Chao Li,Yuru Wang*

Main category: cs.AI

TL;DR: 提出了Domain-Contextualized Concept Graph (CDC)框架，将领域作为知识表示的一等元素，采用<概念, 关系@领域, 概念'>的三元组结构，实现上下文感知推理和跨领域类比。


<details>
  <summary>Details</summary>
Motivation: 传统知识图谱受限于固定的本体论和刚性层次结构，原因是将领域视为隐含上下文而非显式的推理级组件。

Method: 采用C-D-C三元组结构，基于认知语言学同构映射原理，定义了20多个标准化关系谓词（结构、逻辑、跨领域、时间），并在Prolog中实现完整推理能力。

Result: 在教育、企业知识系统和文档管理等案例研究中，CDC能够实现上下文感知推理、跨领域类比和个性化知识建模。

Conclusion: CDC框架克服了传统基于本体的知识表示的限制，提供了传统框架无法实现的能力。

Abstract: Traditional knowledge graphs are constrained by fixed ontologies that
organize concepts within rigid hierarchical structures. The root cause lies in
treating domains as implicit context rather than as explicit, reasoning-level
components. To overcome these limitations, we propose the Domain-Contextualized
Concept Graph (CDC), a novel knowledge modeling framework that elevates domains
to first-class elements of conceptual representation. CDC adopts a C-D-C triple
structure - <Concept, Relation@Domain, Concept'> - where domain specifications
serve as dynamic classification dimensions defined on demand. Grounded in a
cognitive-linguistic isomorphic mapping principle, CDC operationalizes how
humans understand concepts through contextual frames. We formalize more than
twenty standardized relation predicates (structural, logical, cross-domain, and
temporal) and implement CDC in Prolog for full inference capability. Case
studies in education, enterprise knowledge systems, and technical documentation
demonstrate that CDC enables context-aware reasoning, cross-domain analogy, and
personalized knowledge modeling - capabilities unattainable under traditional
ontology-based frameworks.

</details>


### [76] [DeepAnalyze: Agentic Large Language Models for Autonomous Data Science](https://arxiv.org/abs/2510.16872)
*Shaolei Zhang,Ju Fan,Meihao Fan,Guoliang Li,Xiaoyong Du*

Main category: cs.AI

TL;DR: DeepAnalyze-8B是首个用于自主数据科学的代理式大语言模型，能够自动完成从数据源到分析师级深度研究报告的端到端流程。


<details>
  <summary>Details</summary>
Motivation: 现有的基于工作流的数据代理在特定数据任务上表现良好，但由于依赖预定义工作流，无法实现完全自主的数据科学。

Method: 提出基于课程学习的代理训练范式，模拟人类数据科学家的学习轨迹，使LLM能够在真实环境中逐步获取和整合多种能力；同时引入数据驱动的轨迹合成框架构建高质量训练数据。

Result: 实验表明，仅8B参数的DeepAnalyze在性能上超越了基于最先进专有LLM构建的先前工作流代理。

Conclusion: DeepAnalyze的模型、代码和训练数据已开源，为自主数据科学的发展铺平了道路。

Abstract: Autonomous data science, from raw data sources to analyst-grade deep research
reports, has been a long-standing challenge, and is now becoming feasible with
the emergence of powerful large language models (LLMs). Recent workflow-based
data agents have shown promising results on specific data tasks but remain
fundamentally limited in achieving fully autonomous data science due to their
reliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B,
the first agentic LLM designed for autonomous data science, capable of
automatically completing the end-toend pipeline from data sources to
analyst-grade deep research reports. To tackle high-complexity data science
tasks, we propose a curriculum-based agentic training paradigm that emulates
the learning trajectory of human data scientists, enabling LLMs to
progressively acquire and integrate multiple capabilities in real-world
environments. We also introduce a data-grounded trajectory synthesis framework
that constructs high-quality training data. Through agentic training,
DeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data
question answering and specialized analytical tasks to open-ended data
research. Experiments demonstrate that, with only 8B parameters, DeepAnalyze
outperforms previous workflow-based agents built on most advanced proprietary
LLMs. The model, code, and training data of DeepAnalyze are open-sourced,
paving the way toward autonomous data science.

</details>


### [77] [VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents](https://arxiv.org/abs/2510.16907)
*Kangrui Wang,Pingyue Zhang,Zihan Wang,Yaning Gao,Linjie Li,Qineng Wang,Hanyang Chen,Chi Wan,Yiping Lu,Zhengyuan Yang,Lijuan Wang,Ranjay Krishna,Jiajun Wu,Li Fei-Fei,Yejin Choi,Manling Li*

Main category: cs.AI

TL;DR: 该论文提出通过强化学习训练VLM智能体进行显式视觉状态推理，构建内部世界模型。通过状态估计和转移建模分解推理过程，并设计了世界建模奖励和双层GAE方法，在多个基准测试中显著优于未训练模型和专有推理模型。


<details>
  <summary>Details</summary>
Motivation: 训练视觉语言模型智能体面临从文本状态到复杂视觉观察的转变，这引入了部分可观测性并需要强大的世界建模能力。研究旨在探索VLM智能体是否能通过显式视觉状态推理构建内部世界模型。

Method: 将智能体推理过程构建为部分可观测马尔可夫决策过程，通过强化学习架构强制和奖励推理过程。关键是将推理分解为状态估计和转移建模，设计了世界建模奖励和双层广义优势估计方法。

Result: 3B参数模型在五个多样智能体基准测试中达到0.82分，相比未训练模型(0.21)提升3倍，并优于GPT-5(0.75)、Gemini 2.5 Pro(0.67)和Claude 4.5(0.62)等专有推理模型。

Conclusion: 视觉状态推理能有效提升VLM智能体性能，最优信念表示形式取决于任务类型。提出的世界建模奖励和双层GAE方法为训练多轮VLM智能体提供了有效解决方案。

Abstract: A key challenge in training Vision-Language Model (VLM) agents, compared to
Language Model (LLM) agents, lies in the shift from textual states to complex
visual observations. This transition introduces partial observability and
demands robust world modeling. We ask: Can VLM agents construct internal world
models through explicit visual state reasoning? To address this question, we
architecturally enforce and reward the agent's reasoning process via
reinforcement learning (RL), formulating it as a Partially Observable Markov
Decision Process (POMDP). We find that decomposing the agent's reasoning into
State Estimation ("what is the current state?") and Transition Modeling ("what
comes next?") is critical for success, as demonstrated through five reasoning
strategies. Our investigation into how agents represent internal beliefs
reveals that the optimal representation is task-dependent: Natural Language
excels at capturing semantic relationships in general tasks, while Structured
formats are indispensable for precise manipulation and control. Building on
these insights, we design a World Modeling Reward that provides dense,
turn-level supervision for accurate state prediction, and introduce Bi-Level
General Advantage Estimation (Bi-Level GAE) for turn-aware credit assignment.
Through this form of visual state reasoning, a 3B-parameter model achieves a
score of 0.82 across five diverse agent benchmarks, representing a 3$\times$
improvement over its untrained counterpart (0.21) and outperforming proprietary
reasoning models such as GPT-5 (0.75), Gemini 2.5 Pro (0.67) and Claude 4.5
(0.62). All experiments are conducted within our VAGEN framework, a scalable
system for training and analyzing multi-turn VLM agents in diverse visual
environments. Code and data are publicly available at
https://vagen-ai.github.io.

</details>


### [78] [A Comparative User Evaluation of XRL Explanations using Goal Identification](https://arxiv.org/abs/2510.16956)
*Mark Towers,Yali Du,Christopher Freeman,Timothy J. Norman*

Main category: cs.AI

TL;DR: 提出了一种新的评估方法，测试用户能否从解释中识别智能体的目标，发现在四个可解释强化学习算法中只有一个表现优于随机准确率，且用户普遍过度自信。


<details>
  <summary>Details</summary>
Motivation: 可解释强化学习算法的调试应用缺乏比较性评估，需要了解不同算法的相对性能。

Method: 使用Atari的Ms. Pacman环境和四种XRL算法，通过用户实验测试他们从决策解释中识别智能体目标的能力。

Result: 只有一个XRL算法在测试目标上达到了高于随机水平的准确率；用户普遍过度自信；用户自报的识别和理解难易度与准确率无关。

Conclusion: 当前XRL算法在帮助用户识别智能体目标方面的有效性有限，用户的主观感受与实际表现存在差异。

Abstract: Debugging is a core application of explainable reinforcement learning (XRL)
algorithms; however, limited comparative evaluations have been conducted to
understand their relative performance. We propose a novel evaluation
methodology to test whether users can identify an agent's goal from an
explanation of its decision-making. Utilising the Atari's Ms. Pacman
environment and four XRL algorithms, we find that only one achieved greater
than random accuracy for the tested goals and that users were generally
overconfident in their selections. Further, we find that users' self-reported
ease of identification and understanding for every explanation did not
correlate with their accuracy.

</details>


### [79] [STARK: Strategic Team of Agents for Refining Kernels](https://arxiv.org/abs/2510.16996)
*Juncheng Dong,Yang Yang,Tao Liu,Yang Wang,Feng Qi,Vahid Tarokh,Kaushik Rangadurai,Shuang Yang*

Main category: cs.AI

TL;DR: 提出了一种基于LLM的多智能体框架，用于自动化GPU内核优化，通过系统化探索设计空间，显著提升了优化效果和运行性能。


<details>
  <summary>Details</summary>
Motivation: GPU内核优化对现代AI发展至关重要，但由于内存层次、线程调度和硬件特性的复杂交互，优化过程困难且耗时。现有LLM方法在应对不规则的内核优化问题时效果有限。

Method: 开发了LLM智能体框架，通过多智能体协作、基于经验的指导、动态上下文管理和策略搜索来系统探索设计空间，模拟专家工程师的工作流程。

Result: 在KernelBench基准测试中，相比基线方法，该系统能产生更多正确解决方案，并实现了高达16倍的运行时性能提升。

Conclusion: 智能体LLM框架在实现完全自动化、可扩展的GPU内核优化方面具有巨大潜力。

Abstract: The efficiency of GPU kernels is central to the progress of modern AI, yet
optimizing them remains a difficult and labor-intensive task due to complex
interactions between memory hierarchies, thread scheduling, and
hardware-specific characteristics. While recent advances in large language
models (LLMs) provide new opportunities for automated code generation, existing
approaches largely treat LLMs as single-shot generators or naive refinement
tools, limiting their effectiveness in navigating the irregular kernel
optimization landscape. We introduce an LLM agentic framework for GPU kernel
optimization that systematically explores the design space through multi-agent
collaboration, grounded instruction, dynamic context management, and strategic
search. This framework mimics the workflow of expert engineers, enabling LLMs
to reason about hardware trade-offs, incorporate profiling feedback, and refine
kernels iteratively. We evaluate our approach on KernelBench, a benchmark for
LLM-based kernel optimization, and demonstrate substantial improvements over
baseline agents: our system produces correct solutions where baselines often
fail, and achieves kernels with up to 16x faster runtime performance. These
results highlight the potential of agentic LLM frameworks to advance fully
automated, scalable GPU kernel optimization.

</details>


### [80] [ToolCritic: Detecting and Correcting Tool-Use Errors in Dialogue Systems](https://arxiv.org/abs/2510.17052)
*Hassan Hamad,Yingru Xu,Liang Zhao,Wenbo Yan,Narendra Gyanchandani*

Main category: cs.AI

TL;DR: ToolCritic是一个诊断框架，用于评估和改进大型语言模型在工具增强对话中的行为，通过检测8种特定错误类型并提供针对性反馈，使LLM能修正其响应。


<details>
  <summary>Details</summary>
Motivation: 工具增强的大型语言模型在现实应用中越来越普遍，但工具使用错误仍然影响其可靠性，需要提高LLM与外部工具集成的鲁棒性。

Method: 系统定义了8种工具调用错误类型，构建合成数据集训练ToolCritic，该框架检测错误并提供反馈，让具有强推理能力的主LLM基于反馈修正响应。

Result: 在Schema-Guided Dialogue数据集上的实验表明，ToolCritic相比基线方法（包括零样本提示和自校正技术）将工具调用准确率提高了最多13%。

Conclusion: ToolCritic是朝着在现实世界对话应用中更鲁棒地集成LLM与外部工具的有希望的一步。

Abstract: Tool-augmented large language models (LLMs) are increasingly employed in
real-world applications, but tool usage errors still hinder their reliability.
We introduce ToolCritic, a diagnostic framework that evaluates and improves LLM
behavior in multi-turn, tool-augmented dialogues. ToolCritic detects eight
distinct error types specific to tool-calling (e.g., premature invocation,
argument misalignment, and misinterpretation of tool outputs) and provides
targeted feedback to the main LLM. The main LLM, assumed to have strong
reasoning, task understanding and orchestration capabilities, then revises its
response based on ToolCritic's feedback. We systematically define these error
categories and construct a synthetic dataset to train ToolCritic. Experimental
results on the Schema-Guided Dialogue (SGD) dataset demonstrate that ToolCritic
improves tool-calling accuracy by up to 13% over baselines, including zero-shot
prompting and self-correction techniques. This represents a promising step
toward more robust LLM integration with external tools in real-world dialogue
applications.

</details>


### [81] [A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation](https://arxiv.org/abs/2510.17064)
*Rongbin Li,Wenbo Chen,Zhao Li,Rodrigo Munoz-Castaneda,Jinbo Li,Neha S. Maurya,Arnav Solanki,Huan He,Hanwen Xing,Meaghan Ramlakhan,Zachary Wise,Zhuhao Wu,Hua Xu,Michael Hawrylycz,W. Jim Zheng*

Main category: cs.AI

TL;DR: BRAINCELL-AID是一个多智能体AI系统，通过整合自由文本描述和本体标签，结合检索增强生成技术，显著提高了基因集注释的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序技术虽然能识别多样细胞类型，但对涉及特征不明确基因的转录组特征进行注释仍然是一个主要挑战。传统方法如GSEA依赖精心策划的注释，在这些情况下表现不佳。

Method: 开发了BRAINCELL-AID多智能体AI系统，整合自由文本描述和本体标签，采用检索增强生成技术，通过PubMed文献精炼预测，减少幻觉并增强可解释性。

Result: 在小鼠基因集中实现了77%的正确注释率，成功注释了BRAIN Initiative Cell Census Network生成的5,322个脑细胞簇，识别了区域特异性基因共表达模式，并推断出基因集合的功能作用。

Conclusion: BRAINCELL-AID创建了一个有价值的资源来支持社区驱动的细胞类型注释，特别是在识别与基底神经节相关的细胞类型方面表现出色。

Abstract: Single-cell RNA sequencing has transformed our ability to identify diverse
cell types and their transcriptomic signatures. However, annotating these
signatures-especially those involving poorly characterized genes-remains a
major challenge. Traditional methods, such as Gene Set Enrichment Analysis
(GSEA), depend on well-curated annotations and often perform poorly in these
contexts. Large Language Models (LLMs) offer a promising alternative but
struggle to represent complex biological knowledge within structured
ontologies. To address this, we present BRAINCELL-AID (BRAINCELL-AID:
https://biodataai.uth.edu/BRAINCELL-AID), a novel multi-agent AI system that
integrates free-text descriptions with ontology labels to enable more accurate
and robust gene set annotation. By incorporating retrieval-augmented generation
(RAG), we developed a robust agentic workflow that refines predictions using
relevant PubMed literature, reducing hallucinations and enhancing
interpretability. Using this workflow, we achieved correct annotations for 77%
of mouse gene sets among their top predictions. Applying this approach, we
annotated 5,322 brain cell clusters from the comprehensive mouse brain cell
atlas generated by the BRAIN Initiative Cell Census Network, enabling novel
insights into brain cell function by identifying region-specific gene
co-expression patterns and inferring functional roles of gene ensembles.
BRAINCELL-AID also identifies Basal Ganglia-related cell types with
neurologically meaningful descriptions. Hence, we create a valuable resource to
support community-driven cell type annotation.

</details>


### [82] [Structured Debate Improves Corporate Credit Reasoning in Financial AI](https://arxiv.org/abs/2510.17108)
*Yoonjin Lee,Munhee Kim,Hanbi Choi,Juhyeon Park,Seungho Lyoo,Woojin Park*

Main category: cs.AI

TL;DR: 本研究开发并评估了两种基于大语言模型的系统，用于从非财务证据生成结构化推理。单代理系统(NAS)通过单次推理流程进行双向分析，而基于辩论的多代理系统(KPD-MADS)采用卡尔·波普尔的批判对话框架进行对抗性验证。两种系统在生产力上都显著优于人工基准，其中KPD-MADS在推理质量上表现更优。


<details>
  <summary>Details</summary>
Motivation: 在信贷评估中，定性非财务指标对贷款偿还结果具有决定性影响，但难以形式化。现有方法主要关注数值预测，对专业贷款评估所需的解释性判断支持有限。

Method: 开发了两种LLM系统：单代理系统(NAS)使用单次推理流程进行双向分析；多代理系统(KPD-MADS)基于卡尔·波普尔的批判对话框架，采用十步结构化交互协议进行对抗性验证。两种系统在三个真实企业案例上进行评估。

Result: 两种系统都实现了显著的生产力提升(NAS: 11.55秒/案例；KPD-MADS: 91.97秒；人工基准: 1920秒)。KPD-MADS在解释充分性(4.0 vs 3.0)、实际适用性(4.0 vs 3.0)和可用性(62.5 vs 52.5)方面获得更高的中位数评分。

Conclusion: 结构化多代理交互能够增强金融AI中的推理严谨性和可解释性，推动企业信贷评估中可扩展且可辩护的自动化进程。

Abstract: Despite advances in financial AI, the automation of evidence-based reasoning
remains unresolved in corporate credit assessment, where qualitative
non-financial indicators exert decisive influence on loan repayment outcomes
yet resist formalization. Existing approaches focus predominantly on numerical
prediction and provide limited support for the interpretive judgments required
in professional loan evaluation. This study develops and evaluates two
operational large language model (LLM)-based systems designed to generate
structured reasoning from non-financial evidence. The first is a
non-adversarial single-agent system (NAS) that produces bidirectional analysis
through a single-pass reasoning pipeline. The second is a debate-based
multi-agent system (KPD-MADS) that operationalizes adversarial verification
through a ten-step structured interaction protocol grounded in Karl Popper's
critical dialogue framework. Both systems were applied to three real corporate
cases and evaluated by experienced credit risk professionals. Compared to
manual expert reporting, both systems achieved substantial productivity gains
(NAS: 11.55 s per case; KPD-MADS: 91.97 s; human baseline: 1920 s). The
KPD-MADS demonstrated superior reasoning quality, receiving higher median
ratings in explanatory adequacy (4.0 vs. 3.0), practical applicability (4.0 vs.
3.0), and usability (62.5 vs. 52.5). These findings show that structured
multi-agent interaction can enhance reasoning rigor and interpretability in
financial AI, advancing scalable and defensible automation in corporate credit
assessment.

</details>


### [83] [Enhanced Fish Freshness Classification with Incremental Handcrafted Feature Fusion](https://arxiv.org/abs/2510.17145)
*Phi-Hung Hoang,Nam-Thuan Trinh,Van-Manh Tran,Thi-Thu-Hong Phan*

Main category: cs.AI

TL;DR: 提出基于手工特征的方法，通过提取和融合颜色统计、多色彩空间直方图以及纹理特征来评估鱼类新鲜度，在FFE数据集上取得了显著优于深度学习的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统感官评估鱼类新鲜度存在主观性、不一致性和难以标准化的问题，需要客观、可靠的自动化评估方法。

Method: 从鱼眼图像中系统提取颜色统计、多色彩空间直方图、LBP和GLCM等纹理特征，融合全局和局部特征进行新鲜度评估。

Result: LightGBM分类器在标准设置下达到77.56%准确率，比深度学习基线提升14.35%；使用增强数据时ANN达到97.16%准确率，比之前最佳结果提升19.86%。

Conclusion: 精心设计的手工特征能够提供鲁棒、可解释且可靠的鱼类新鲜度自动评估解决方案，为食品质量监控提供实用价值。

Abstract: Accurate assessment of fish freshness remains a major challenge in the food
industry, with direct consequences for product quality, market value, and
consumer health. Conventional sensory evaluation is inherently subjective,
inconsistent, and difficult to standardize across contexts, often limited by
subtle, species-dependent spoilage cues. To address these limitations, we
propose a handcrafted feature-based approach that systematically extracts and
incrementally fuses complementary descriptors, including color statistics,
histograms across multiple color spaces, and texture features such as Local
Binary Patterns (LBP) and Gray-Level Co-occurrence Matrices (GLCM), from fish
eye images. Our method captures global chromatic variations from full images
and localized degradations from ROI segments, fusing each independently to
evaluate their effectiveness in assessing freshness. Experiments on the
Freshness of the Fish Eyes (FFE) dataset demonstrate the approach's
effectiveness: in a standard train-test setting, a LightGBM classifier achieved
77.56% accuracy, a 14.35% improvement over the previous deep learning baseline
of 63.21%. With augmented data, an Artificial Neural Network (ANN) reached
97.16% accuracy, surpassing the prior best of 77.3% by 19.86%. These results
demonstrate that carefully engineered, handcrafted features, when strategically
processed, yield a robust, interpretable, and reliable solution for automated
fish freshness assessment, providing valuable insights for practical
applications in food quality monitoring.

</details>


### [84] [Physics-Informed Large Language Models for HVAC Anomaly Detection with Autonomous Rule Generation](https://arxiv.org/abs/2510.17146)
*Subin Lin,Chuanbo Hua*

Main category: cs.AI

TL;DR: 提出了PILLM框架，结合物理知识和LLM进行HVAC系统异常检测，通过进化循环自动生成、评估和优化检测规则，在保持可解释性的同时实现高性能。


<details>
  <summary>Details</summary>
Motivation: HVAC系统能耗巨大，传统规则方法缺乏适应性，深度学习方法缺乏可解释性，现有LLM方法忽视物理原理，需要开发既适应性强又物理合理的检测方法。

Method: 使用物理信息化的LLM框架，在进化循环中嵌入热力学和控制理论约束，通过物理信息化的反射和交叉算子自动生成和优化异常检测规则。

Result: 在公共建筑故障检测数据集上达到最先进性能，生成的诊断规则具有可解释性和可操作性。

Conclusion: PILLM框架推进了智能建筑系统中可信赖和可部署AI的发展，实现了适应性、物理合理性和高性能的平衡。

Abstract: Heating, Ventilation, and Air-Conditioning (HVAC) systems account for a
substantial share of global building energy use, making reliable anomaly
detection essential for improving efficiency and reducing emissions. Classical
rule-based approaches offer explainability but lack adaptability, while deep
learning methods provide predictive power at the cost of transparency,
efficiency, and physical plausibility. Recent attempts to use Large Language
Models (LLMs) for anomaly detection improve interpretability but largely ignore
the physical principles that govern HVAC operations. We present PILLM, a
Physics-Informed LLM framework that operates within an evolutionary loop to
automatically generate, evaluate, and refine anomaly detection rules. Our
approach introduces physics-informed reflection and crossover operators that
embed thermodynamic and control-theoretic constraints, enabling rules that are
both adaptive and physically grounded. Experiments on the public Building Fault
Detection dataset show that PILLM achieves state-of-the-art performance while
producing diagnostic rules that are interpretable and actionable, advancing
trustworthy and deployable AI for smart building systems.

</details>


### [85] [Which LLM Multi-Agent Protocol to Choose?](https://arxiv.org/abs/2510.17149)
*Hongyi Du,Jiaqi Su,Jisen Li,Lijie Ding,Yingxuan Yang,Peixuan Han,Xiangru Tang,Kunlun Zhu,Jiaxuan You*

Main category: cs.AI

TL;DR: ProtocolBench是一个系统评估多智能体系统通信协议的基准，ProtocolRouter是一个可学习的协议路由器，能根据场景需求选择最佳协议，显著提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 大规模多智能体系统的通信协议层是影响性能和可靠性的关键因素，但目前协议选择缺乏标准化指导，往往基于直觉。

Method: 开发ProtocolBench基准，从任务成功率、端到端延迟、消息开销和故障恢复能力四个维度系统比较协议；提出ProtocolRouter协议路由器，根据需求和运行时信号选择最佳协议。

Result: 协议选择显著影响系统行为：在Streaming Queue场景中，完成时间差异达36.5%，端到端延迟差异3.48秒；ProtocolRouter相比最佳单协议基线，故障恢复时间减少18.1%，在GAIA场景中成功率更高。

Conclusion: 协议选择对多智能体系统性能至关重要，ProtocolBench和ProtocolRouter为协议评估和选择提供了标准化方法，能显著提升系统可靠性和性能。

Abstract: As large-scale multi-agent systems evolve, the communication protocol layer
has become a critical yet under-evaluated factor shaping performance and
reliability. Despite the existence of diverse protocols (A2A, ACP, ANP, Agora,
etc.), selection is often intuition-driven and lacks standardized guidance. We
introduce ProtocolBench, a benchmark that systematically compares agent
protocols along four measurable axes: task success, end-to-end latency, message
or byte overhead, and robustness under failures. On ProtocolBench, protocol
choice significantly influences system behavior. In the Streaming Queue
scenario, overall completion time varies by up to 36.5% across protocols, and
mean end-to-end latency differs by 3.48 s. Under Fail-Storm Recovery,
resilience also differs consistently across protocols. Beyond evaluation, we
present ProtocolRouter, a learnable protocol router that selects per-scenario
(or per-module) protocols from requirement and runtime signals. ProtocolRouter
reduces Fail-Storm recovery time by up to 18.1% versus the best single-protocol
baseline, and achieves scenario-specific gains such as higher success in GAIA.
We also release ProtocolRouterBench to standardize protocol evaluation and
improve reliability at scale.

</details>


### [86] [Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant Ventricular Arrhythmias in AMI Patients](https://arxiv.org/abs/2510.17172)
*Shun Huang,Wenlu Xing,Shijia Geng,Hailong Wang,Guangkun Nie,Gongzheng Tang,Chenyang He,Shenda Hong*

Main category: cs.AI

TL;DR: 开发了一个结合ECG基础模型和可解释XGBoost分类器的混合预测框架，用于预测急性心肌梗死后恶性室性心律失常风险，在提高准确性的同时保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 急性心肌梗死后恶性室性心律失常是院内死亡的主要原因，传统风险评分性能有限，而端到端深度学习模型缺乏临床信任所需的可解释性。

Method: 使用ECG基础模型提取150维诊断概率特征，通过特征选择后训练XGBoost分类器，采用SHAP方法进行可解释性分析。

Result: 混合模型AUC达到0.801，优于KNN(0.677)、RNN(0.676)和1D-CNN(0.720)，SHAP分析显示模型识别特征与临床知识高度一致。

Conclusion: 该混合框架为VT/VF风险预测提供了新范式，验证了基础模型输出作为有效自动化特征工程在构建可信赖、可解释AI临床决策支持系统中的应用。

Abstract: Malignant ventricular arrhythmias (VT/VF) following acute myocardial
infarction (AMI) are a major cause of in-hospital death, yet early
identification remains a clinical challenge. While traditional risk scores have
limited performance, end-to-end deep learning models often lack the
interpretability needed for clinical trust. This study aimed to develop a
hybrid predictive framework that integrates a large-scale electrocardiogram
(ECG) foundation model (ECGFounder) with an interpretable XGBoost classifier to
improve both accuracy and interpretability. We analyzed 6,634 ECG recordings
from AMI patients, among whom 175 experienced in-hospital VT/VF. The ECGFounder
model was used to extract 150-dimensional diagnostic probability features ,
which were then refined through feature selection to train the XGBoost
classifier. Model performance was evaluated using AUC and F1-score , and the
SHAP method was used for interpretability. The ECGFounder + XGBoost hybrid
model achieved an AUC of 0.801 , outperforming KNN (AUC 0.677), RNN (AUC
0.676), and an end-to-end 1D-CNN (AUC 0.720). SHAP analysis revealed that
model-identified key features, such as "premature ventricular complexes" (risk
predictor) and "normal sinus rhythm" (protective factor), were highly
consistent with clinical knowledge. We conclude that this hybrid framework
provides a novel paradigm for VT/VF risk prediction by validating the use of
foundation model outputs as effective, automated feature engineering for
building trustworthy, explainable AI-based clinical decision support systems.

</details>


### [87] [Offline Policy Evaluation of Multi-Turn LLM Health Coaching with Real Users](https://arxiv.org/abs/2510.17173)
*Melik Ozolcer,Sang Won Bae*

Main category: cs.AI

TL;DR: 研究了一个部署在Web上的工具增强LLM健康教练，通过离线策略评估发现统一的重工具策略虽然提升平均价值，但对特定用户群体（特别是低健康素养/高自我效能用户）有害。使用轻量级模拟器发现添加早期信息增益奖励可以缩短特征识别时间并提高目标成功率。


<details>
  <summary>Details</summary>
Motivation: 探索工具增强LLM健康教练在真实用户环境中的表现，特别关注个性化策略对不同用户群体的影响，以及如何通过评估优先的方法实现更好的个性化服务。

Method: 使用离线策略评估（OPE）分析因子化决策头（工具/风格），通过轻量级模拟器测试添加早期信息增益奖励的效果，评估不同策略对用户群体的影响。

Result: 统一的重工具策略会损害低健康素养/高自我效能用户群体；添加早期信息增益奖励可以可靠地缩短特征识别时间，提高目标成功率和pass@3指标。

Conclusion: 提出了评估优先的个性化路径：冻结生成器，在类型化奖励（客观工具结果和满意度）上学习子群体感知的决策头，并始终报告每个原型的指标以揭示被平均值掩盖的子群体损害。

Abstract: We study a web-deployed, tool-augmented LLM health coach with real users. In
a pilot with seven users (280 rated turns), offline policy evaluation (OPE)
over factorized decision heads (Tool/Style) shows that a uniform heavy-tool
policy raises average value on logs but harms specific subgroups, most notably
low-health-literacy/high-self-efficacy users. A lightweight simulator with
hidden archetypes further shows that adding a small early information-gain
bonus reliably shortens trait identification and improves goal success and
pass@3. Together, these early findings indicate an evaluation-first path to
personalization: freeze the generator, learn subgroup-aware decision heads on
typed rewards (objective tool outcomes and satisfaction), and always report
per-archetype metrics to surface subgroup harms that averages obscure.

</details>


### [88] [Temporally Detailed Hypergraph Neural ODEs for Type 2 Diabetes Progression Modeling](https://arxiv.org/abs/2510.17211)
*Tingsong Xiao,Yao An Lee,Zelin Xu,Yupu Zhang,Zibo Liu,Yu Huang,Jiang Bian,Serena Jingchuan Guo,Zhe Jiang*

Main category: cs.AI

TL;DR: 提出TD-HNODE模型，使用时间详细超图和神经ODE框架来学习疾病进展的连续时间动态，在2型糖尿病和心血管疾病进展建模中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有疾病进展建模方法难以处理不规则时间采样数据和患者异质性，无法有效捕捉复杂的连续时间动态。

Method: TD-HNODE将疾病进展表示为时间详细超图，通过可学习的超图拉普拉斯矩阵捕捉并发症标记物在进展轨迹内和轨迹间的相互依赖关系，使用神经ODE框架学习连续时间动态。

Result: 在两个真实临床数据集上的实验表明，TD-HNODE在2型糖尿病及相关心血管疾病进展建模方面优于多个基线方法。

Conclusion: TD-HNODE能够有效建模疾病进展的连续时间动态，为患者亚表型分析和及时干预提供支持。

Abstract: Disease progression modeling aims to characterize and predict how a patient's
disease complications worsen over time based on longitudinal electronic health
records (EHRs). Accurate modeling of disease progression, such as type 2
diabetes, can enhance patient sub-phenotyping and inform effective and timely
interventions. However, the problem is challenging due to the need to learn
continuous-time dynamics of progression patterns based on irregular-time event
samples and patient heterogeneity (\eg different progression rates and
pathways). Existing mechanistic and data-driven methods either lack
adaptability to learn from real-world data or fail to capture complex
continuous-time dynamics on progression trajectories. To address these
limitations, we propose Temporally Detailed Hypergraph Neural Ordinary
Differential Equation (TD-HNODE), which represents disease progression on
clinically recognized trajectories as a temporally detailed hypergraph and
learns the continuous-time progression dynamics via a neural ODE framework.
TD-HNODE contains a learnable TD-Hypergraph Laplacian that captures the
interdependency of disease complication markers within both intra- and
inter-progression trajectories. Experiments on two real-world clinical datasets
demonstrate that TD-HNODE outperforms multiple baselines in modeling the
progression of type 2 diabetes and related cardiovascular diseases.

</details>


### [89] [Coinvisor: An RL-Enhanced Chatbot Agent for Interactive Cryptocurrency Investment Analysis](https://arxiv.org/abs/2510.17235)
*Chong Chen,Ze Liu,Lingfeng Bao,Yanlin Wang,Ting Chen,Daoyuan Wu,Jiachi Chen*

Main category: cs.AI

TL;DR: Coinvisor是一个基于强化学习的加密货币投资分析聊天机器人，通过多智能体框架和强化学习工具选择机制，解决了现有方法的局限性，提供实时、准确的投资分析。


<details>
  <summary>Details</summary>
Motivation: 加密货币市场存在高波动性和信息碎片化问题，现有分析方法（手动分析、数据聚合平台、LLM代理）各有缺陷，需要更智能、实时的分析工具。

Method: 采用多智能体框架，集成多种专业分析工具，核心创新是基于强化学习的工具选择机制，支持多步骤规划和实时数据集成。

Result: 在工具调用准确率上，相比基础模型召回率提升40.7%，F1分数提升26.6%；用户研究显示高满意度（4.64/5），用户更偏好Coinvisor而非通用LLM和现有平台（4.62/5）。

Conclusion: Coinvisor通过强化学习驱动的多智能体框架，有效解决了加密货币投资分析中的实时性和准确性挑战，为用户提供了更优的分析体验。

Abstract: The cryptocurrency market offers significant investment opportunities but
faces challenges including high volatility and fragmented information. Data
integration and analysis are essential for informed investment decisions.
Currently, investors use three main approaches: (1) Manual analysis across
various sources, which depends heavily on individual experience and is
time-consuming and prone to bias; (2) Data aggregation platforms-limited in
functionality and depth of analysis; (3) Large language model agents-based on
static pretrained models, lacking real-time data integration and multi-step
reasoning capabilities. To address these limitations, we present Coinvisor, a
reinforcement learning-based chatbot that provides comprehensive analytical
support for cryptocurrency investment through a multi-agent framework.
Coinvisor integrates diverse analytical capabilities through specialized tools.
Its key innovation is a reinforcement learning-based tool selection mechanism
that enables multi-step planning and flexible integration of diverse data
sources. This design supports real-time interaction and adaptive analysis of
dynamic content, delivering accurate and actionable investment insights. We
evaluated Coinvisor through automated benchmarks on tool calling accuracy and
user studies with 20 cryptocurrency investors using our interface. Results show
that Coinvisor improves recall by 40.7% and F1 score by 26.6% over the base
model in tool orchestration. User studies show high satisfaction (4.64/5), with
participants preferring Coinvisor to both general LLMs and existing crypto
platforms (4.62/5).

</details>


### [90] [RubiSCoT: A Framework for AI-Supported Academic Assessment](https://arxiv.org/abs/2510.17309)
*Thorsten Fröhlich,Tim Schlippe*

Main category: cs.AI

TL;DR: 提出了RubiSCoT框架，使用AI技术增强学术论文评估，从提案到最终提交提供一致、可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统论文评估方法耗时且存在评估者变异性，需要更高效、一致的评估解决方案。

Method: 使用先进自然语言处理技术，包括大语言模型、检索增强生成和结构化思维链提示，提供初步评估、多维评估、内容提取、基于评分标准的评分和详细报告。

Result: 设计并实现了RubiSCoT框架，展示了其在学术评估过程中的潜力。

Conclusion: RubiSCoT有潜力通过一致、可扩展和透明的评估来优化学术评估过程。

Abstract: The evaluation of academic theses is a cornerstone of higher education,
ensuring rigor and integrity. Traditional methods, though effective, are
time-consuming and subject to evaluator variability. This paper presents
RubiSCoT, an AI-supported framework designed to enhance thesis evaluation from
proposal to final submission. Using advanced natural language processing
techniques, including large language models, retrieval-augmented generation,
and structured chain-of-thought prompting, RubiSCoT offers a consistent,
scalable solution. The framework includes preliminary assessments,
multidimensional assessments, content extraction, rubric-based scoring, and
detailed reporting. We present the design and implementation of RubiSCoT,
discussing its potential to optimize academic assessment processes through
consistent, scalable, and transparent evaluation.

</details>


### [91] [Diverse Planning with Simulators via Linear Temporal Logic](https://arxiv.org/abs/2510.17418)
*Mustafa F. Abdelwahed,Alice Toniolo,Joan Espasa,Ian P. Gent*

Main category: cs.AI

TL;DR: 提出了FBI_LTL，一个用于仿真规划问题的多样化规划器，使用线性时序逻辑定义语义多样性标准，生成语义上不同的规划方案。


<details>
  <summary>Details</summary>
Motivation: 传统基于声明的模型在处理复杂环境时存在局限，仅生成单一规划可能无法满足代理偏好，需要语义多样化的规划方案。

Method: 使用线性时序逻辑定义语义多样性标准，将这些LTL多样性模型直接集成到搜索过程中，确保生成语义多样化的规划。

Result: 在多个基准测试上的广泛评估表明，FBI_LTL相比基线方法能生成更多样化的规划。

Conclusion: 这项工作确立了在仿真环境中语义引导多样化规划的可行性，为在传统基于模型方法失效的现实非符号领域开辟了新途径。

Abstract: Autonomous agents rely on automated planning algorithms to achieve their
objectives. Simulation-based planning offers a significant advantage over
declarative models in modelling complex environments. However, relying solely
on a planner that produces a single plan may not be practical, as the generated
plans may not always satisfy the agent's preferences. To address this
limitation, we introduce $\texttt{FBI}_\texttt{LTL}$, a diverse planner
explicitly designed for simulation-based planning problems.
$\texttt{FBI}_\texttt{LTL}$ utilises Linear Temporal Logic (LTL) to define
semantic diversity criteria, enabling agents to specify what constitutes
meaningfully different plans. By integrating these LTL-based diversity models
directly into the search process, $\texttt{FBI}_\texttt{LTL}$ ensures the
generation of semantically diverse plans, addressing a critical limitation of
existing diverse planning approaches that may produce syntactically different
but semantically identical solutions. Extensive evaluations on various
benchmarks consistently demonstrate that $\texttt{FBI}_\texttt{LTL}$ generates
more diverse plans compared to a baseline approach. This work establishes the
feasibility of semantically-guided diverse planning in simulation-based
environments, paving the way for innovative approaches in realistic,
non-symbolic domains where traditional model-based approaches fail.

</details>


### [92] [Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions](https://arxiv.org/abs/2510.17450)
*Johan Schubert,Farzad Kamrani,Tove Gustavi*

Main category: cs.AI

TL;DR: 开发了一种基于主动推理的路径规划方法，用于智能代理的自主控制，通过构建证据地图和计算变分自由能量来指导代理移动，平衡探索和利用。


<details>
  <summary>Details</summary>
Motivation: 为了在侦察地理区域时维持共同作战态势图，需要一种能够平衡广泛搜索和跟踪已识别目标的方法。

Method: 使用Dempster-Shafer理论和高斯传感器模型构建生成模型，通过贝叶斯方法更新后验概率分布，计算变分自由能量来指导代理移动。

Result: 该方法能够有效指导代理在地理地图上的移动，成功平衡了探索和利用的需求。

Conclusion: 提出的主动推理路径规划方法为解决自主智能代理的探索-利用平衡问题提供了有效解决方案。

Abstract: We develop an active inference route-planning method for the autonomous
control of intelligent agents. The aim is to reconnoiter a geographical area to
maintain a common operational picture. To achieve this, we construct an
evidence map that reflects our current understanding of the situation,
incorporating both positive and "negative" sensor observations of possible
target objects collected over time, and diffusing the evidence across the map
as time progresses. The generative model of active inference uses
Dempster-Shafer theory and a Gaussian sensor model, which provides input to the
agent. The generative process employs a Bayesian approach to update a posterior
probability distribution. We calculate the variational free energy for all
positions within the area by assessing the divergence between a pignistic
probability distribution of the evidence map and a posterior probability
distribution of a target object based on the observations, including the level
of surprise associated with receiving new observations. Using the free energy,
we direct the agents' movements in a simulation by taking an incremental step
toward a position that minimizes the free energy. This approach addresses the
challenge of exploration and exploitation, allowing agents to balance searching
extensive areas of the geographical map while tracking identified target
objects.

</details>


### [93] [Label Indeterminacy in AI & Law](https://arxiv.org/abs/2510.17463)
*Cor Steging,Tadeusz Zbiegień*

Main category: cs.AI

TL;DR: 法律机器学习中标签不确定性问题：法律案件结果常受人为干预影响，导致标签具有不确定性，这会显著影响模型行为。


<details>
  <summary>Details</summary>
Motivation: 法律机器学习通常将过去案件结果视为真实标签，但法律结果常受和解、上诉等干预影响，造成标签不确定性，需要对此进行考虑。

Method: 在欧洲人权法院案件分类背景下，分析不同标签构建方式对模型行为的影响，探讨标签不确定性问题。

Result: 研究表明，训练过程中标签的构建方式会显著影响模型的行为表现。

Conclusion: 标签不确定性是AI与法律领域的重要关注点，需要开发能够处理这种不确定性的方法。

Abstract: Machine learning is increasingly used in the legal domain, where it typically
operates retrospectively by treating past case outcomes as ground truth.
However, legal outcomes are often shaped by human interventions that are not
captured in most machine learning approaches. A final decision may result from
a settlement, an appeal, or other procedural actions. This creates label
indeterminacy: the outcome could have been different if the intervention had or
had not taken place. We argue that legal machine learning applications need to
account for label indeterminacy. Methods exist that can impute these
indeterminate labels, but they are all grounded in unverifiable assumptions. In
the context of classifying cases from the European Court of Human Rights, we
show that the way that labels are constructed during training can significantly
affect model behaviour. We therefore position label indeterminacy as a relevant
concern in AI & Law and demonstrate how it can shape model behaviour.

</details>


### [94] [Reasoning Distillation and Structural Alignment for Improved Code Generation](https://arxiv.org/abs/2510.17598)
*Amir Jalilifard,Anderson de Rezende Rocha,Marcos Medeiros Raimundo*

Main category: cs.AI

TL;DR: 该论文提出了一种将大型语言模型的推理能力蒸馏到更小、更高效模型中的方法，通过结构感知损失优化使小模型能够理解解决方案的整体结构而不仅仅是生成token。


<details>
  <summary>Details</summary>
Motivation: 代码生成不仅需要准确的token预测，更需要理解解决方案级别的结构关系。大型语言模型具备复杂推理能力，而小模型缺乏这种能力，因此需要将大模型的推理能力蒸馏到小模型中。

Method: 通过训练模型模拟大型语言模型的推理和问题解决能力，学习识别正确的解决方案路径，并通过结构感知损失优化建立问题定义与潜在解决方案之间的结构对应关系。

Result: 实验结果显示，经过廉价且易于实现的微调过程开发的模型，在MBPP、MBPP Plus和HumanEval基准测试中，在pass@1、平均数据流和平均语法匹配指标上显著优于基线模型。

Conclusion: 通过将大型语言模型的推理能力蒸馏到小模型中，可以创建出更快、更便宜部署的模型，同时保持强大的代码生成能力，能够理解解决方案的整体结构。

Abstract: Effective code generation with language models hinges on two critical
factors: accurately understanding the intent of the prompt and generating code
that applies algorithmic reasoning to produce correct solutions capable of
passing diverse test cases while adhering to the syntax of the target
programming language. Unlike other language tasks, code generation requires
more than accurate token prediction; it demands comprehension of solution-level
and structural relationships rather than merely generating the most likely
tokens. very large language model (VLLM) are capable of generating detailed
steps toward the correct solution of complex tasks where reasoning is crucial
in solving the problem. Such reasoning capabilities may be absent in smaller
language models. Therefore, in this work, we distill the reasoning capabilities
of a VLLM into a smaller, more efficient model that is faster and cheaper to
deploy. Our approach trains the model to emulate the reasoning and
problem-solving abilities of the VLLM by learning to identify correct solution
pathways and establishing a structural correspondence between problem
definitions and potential solutions through a novel method of structure-aware
loss optimization. This enables the model to transcend token-level generation
and to deeply grasp the overarching structure of solutions for given problems.
Experimental results show that our fine-tuned model, developed through a cheap
and simple to implement process, significantly outperforms our baseline model
in terms of pass@1, average data flow, and average syntax match metrics across
the MBPP, MBPP Plus, and HumanEval benchmarks.

</details>


### [95] [OG-Rank: Learning to Rank Fast and Slow with Uncertainty and Reward-Trend Guided Adaptive Exploration](https://arxiv.org/abs/2510.17614)
*Praphul Singh,Corey Barrett,Sumana Srivasta,Irfan Bulu,Sri Gadde,Krishnaram Kenthapadi*

Main category: cs.AI

TL;DR: OG-Rank是一个低延迟的解码器重排序系统，通过结合池化首词评分和不确定性门控解释步骤，实现快速排名并在真正模糊时生成解释，在临床医嘱选择任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 临床医生需要实时工作并能解释选择的排名系统，需要一个低延迟、基于解码器的重排序器。

Method: 提出OG-Rank单解码器方法，使用池化首词评分信号和不确定性门控解释步骤，通过专注于困难案例的课程训练。

Result: 在临床医嘱选择任务中表现强劲（快速路径：Recall@1~0.45，nDCG@20~0.625），当门控激活时进一步改善（Recall@1~0.56，nDCG@20~0.699，门控率45%），编码器基线在效果和灵活性上都落后。

Conclusion: OG-Rank提供了一个实用方案：默认快速排名，在需要时解释，这种模式适用于选择性生成能以可接受成本提高准确性的决策任务，单策略设计简化了部署和预算规划。

Abstract: Clinicians need ranking systems that work in real time and still justify
their choices. Motivated by the need for a low-latency, decoder-based reranker,
we present OG-Rank, a single-decoder approach that pairs a pooled first-token
scoring signal with an uncertainty-gated explanation step. The model scores all
candidates in one pass and generates a brief, structured rationale only when
the list is genuinely ambiguous, keeping latency predictable. Trained with a
curriculum that concentrates effort on hard cases, OG-Rank delivers strong
effectiveness on encounter-scoped order selection (fast path: Recall@1~0.45,
nDCG@20~0.625) and improves further when the gate activates (Recall@1~0.56,
nDCG@20~0.699 at a 45\% gate rate), while compact backbones show similar gains
under the same policy. Encoder baselines trail in both effectiveness and
flexibility. The result is a practical recipe: rank fast by default and explain
when it helps, a pattern that applies broadly to decision tasks where selective
generation buys accuracy at acceptable cost. The single-policy design
simplifies deployment and budget planning, and the curriculum principle (spend
more on the hard cases, less on the easy ones) readily transfers beyond
clinical order selection.

</details>


### [96] [LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet Arena](https://arxiv.org/abs/2510.17638)
*Qingchuan Yang,Simon Mahns,Sida Li,Anri Gu,Jibang Wu,Haifeng Xu*

Main category: cs.AI

TL;DR: 本文系统评估了大型语言模型作为预测工具的潜力，发现LLMs已展现出令人印象深刻的预测能力，但也存在事件回忆不准确、数据源误解等关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 随着在互联网规模数据上训练的大型语言模型的快速发展，利用LLMs预测现实世界未来事件具有重要潜力，作者称之为"LLM-as-a-Prophet"范式，需要系统研究这种预测智能。

Method: 构建了Prophet Arena评估基准，持续收集实时预测任务，并将每个任务分解为不同的流水线阶段，以支持受控和大规模实验。

Result: 综合评估显示，许多LLM已展现出令人印象深刻的预测能力，表现为较小的校准误差、一致的预测置信度和有前景的市场回报。

Conclusion: 虽然LLMs在预测方面表现良好，但存在关键瓶颈，如事件回忆不准确、数据源误解，以及在接近决策时信息聚合速度慢于市场等，阻碍了实现卓越预测智能。

Abstract: Forecasting is not only a fundamental intellectual pursuit but also is of
significant importance to societal systems such as finance and economics. With
the rapid advances of large language models (LLMs) trained on Internet-scale
data, it raises the promise of employing LLMs to forecast real-world future
events, an emerging paradigm we call "LLM-as-a-Prophet". This paper
systematically investigates such predictive intelligence of LLMs. To this end,
we build Prophet Arena, a general evaluation benchmark that continuously
collects live forecasting tasks and decomposes each task into distinct pipeline
stages, in order to support our controlled and large-scale experimentation. Our
comprehensive evaluation reveals that many LLMs already exhibit impressive
forecasting capabilities, reflected in, e.g., their small calibration errors,
consistent prediction confidence and promising market returns. However, we also
uncover key bottlenecks towards achieving superior predictive intelligence via
LLM-as-a-Prophet, such as LLMs' inaccurate event recalls, misunderstanding of
data sources and slower information aggregation compared to markets when
resolution nears.

</details>


### [97] [A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.17697)
*Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang*

Main category: cs.AI

TL;DR: 该论文提出使用多智能体影响图(MAIDs)作为图形化框架来解决多智能体强化学习中的协调问题，设计了基于MAIDs的针对性干预范式，并通过因果推断技术实现单智能体干预来避免全局指导的困难。


<details>
  <summary>Details</summary>
Motivation: 在大规模多智能体强化学习中，对整个系统进行全局人工指导不切实际，而现有的协调机制设计主要依赖经验研究，缺乏易用的研究工具。

Method: 引入多智能体影响图(MAIDs)作为分析框架，设计了针对性干预范式，并采用预策略干预(PSI)因果推断技术来实现单智能体干预，通过最大化因果效应来达成复合目标。

Result: 实验证明了所提出的针对性干预方法的有效性，并验证了相关性图分析的结果。

Conclusion: MAIDs提供了一个有效的图形化框架来分析和设计多智能体交互范式，针对性干预能够缓解全局指导问题，因果推断技术可以有效地实现期望的结果导向。

Abstract: Steering cooperative multi-agent reinforcement learning (MARL) towards
desired outcomes is challenging, particularly when the global guidance from a
human on the whole multi-agent system is impractical in a large-scale MARL. On
the other hand, designing mechanisms to coordinate agents most relies on
empirical studies, lacking a easy-to-use research tool. In this work, we employ
multi-agent influence diagrams (MAIDs) as a graphical framework to address the
above issues. First, we introduce interaction paradigms that leverage MAIDs to
analyze and visualize existing approaches in MARL. Then, we design a new
interaction paradigm based on MAIDs, referred to as targeted intervention that
is applied to only a single targeted agent, so the problem of global guidance
can be mitigated. In our implementation, we introduce a causal inference
technique-referred to as Pre-Strategy Intervention (PSI)-to realize the
targeted intervention paradigm. Since MAIDs can be regarded as a special class
of causal diagrams, a composite desired outcome that integrates the primary
task goal and an additional desired outcome can be achieved by maximizing the
corresponding causal effect through the PSI. Moreover, the bundled relevance
graph analysis of MAIDs provides a tool to identify whether an MARL learning
paradigm is workable under the design of an interaction paradigm. In
experiments, we demonstrate the effectiveness of our proposed targeted
intervention, and verify the result of relevance graph analysis.

</details>


### [98] [Contextual Attention Modulation: Towards Efficient Multi-Task Adaptation in Large Language Models](https://arxiv.org/abs/2510.17705)
*Dayan Pan,Zhaoyang Fu,Jingyuan Wang,Xiao Han,Yue Zhu,Xiangyu Zhao*

Main category: cs.AI

TL;DR: 提出Contextual Attention Modulation (CAM)机制和HyCAM框架，通过动态调制自注意力表示来增强任务特定特征并保留通用知识，在多任务适应中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多任务适应中存在知识保留与任务专业化之间的平衡问题，传统微调方法存在灾难性遗忘和资源消耗大的缺陷，现有参数高效方法在复杂多任务场景下表现不佳。

Method: 提出CAM机制动态调制自注意力模块表示，并构建HyCAM框架，结合共享的全参数CAM模块和多个轻量级专用CAM模块，通过动态路由策略实现自适应知识融合。

Result: 在问答、代码生成和逻辑推理等异构任务上的实验表明，该方法平均性能提升3.65%，显著优于现有方法。

Conclusion: CAM和HyCAM框架有效解决了LLMs在多任务适应中的挑战，实现了更好的知识保留与任务专业化平衡，代码和数据已开源。

Abstract: Large Language Models (LLMs) possess remarkable generalization capabilities
but struggle with multi-task adaptation, particularly in balancing knowledge
retention with task-specific specialization. Conventional fine-tuning methods
suffer from catastrophic forgetting and substantial resource consumption, while
existing parameter-efficient methods perform suboptimally in complex multi-task
scenarios. To address this, we propose Contextual Attention Modulation (CAM), a
novel mechanism that dynamically modulates the representations of
self-attention modules in LLMs. CAM enhances task-specific features while
preserving general knowledge, thereby facilitating more effective and efficient
adaptation. For effective multi-task adaptation, CAM is integrated into our
Hybrid Contextual Attention Modulation (HyCAM) framework, which combines a
shared, full-parameter CAM module with multiple specialized, lightweight CAM
modules, enhanced by a dynamic routing strategy for adaptive knowledge fusion.
Extensive experiments on heterogeneous tasks, including question answering,
code generation, and logical reasoning, demonstrate that our approach
significantly outperforms existing approaches, achieving an average performance
improvement of 3.65%. The implemented code and data are available to ease
reproducibility at https://github.com/Applied-Machine-Learning-Lab/HyCAM.

</details>


### [99] [Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs](https://arxiv.org/abs/2510.17771)
*Zhining Liu,Ziyi Chen,Hui Liu,Chen Luo,Xianfeng Tang,Suhang Wang,Joy Zeng,Zhenwei Dai,Zhan Shi,Tianxin Wei,Benoit Dumoulin,Hanghang Tong*

Main category: cs.AI

TL;DR: 研究发现视觉语言模型虽然能感知视觉证据，但在推理过程中未能充分利用这些信息，导致"看见但不相信"现象。通过选择性注意力掩码干预，无需训练即可提升模型准确性。


<details>
  <summary>Details</summary>
Motivation: 系统研究视觉语言模型失败的原因：是由于未能感知视觉证据，还是未能有效利用已感知的证据。

Method: 通过分析层级注意力动态，发现浅层主要关注文本，深层稀疏但可靠地关注局部证据区域。引入推理时干预方法，通过选择性注意力掩码突出深层证据区域。

Result: 干预方法无需训练，在LLaVA、Qwen、Gemma和InternVL等多个VLM家族中一致提升准确性。

Conclusion: VLMs内部编码了可靠的证据但未能充分利用，通过显式化这些信号可以弥合感知与推理之间的差距，提升VLM的诊断理解和可靠性。

Abstract: Vision-Language Models (VLMs) achieve strong results on multimodal tasks such
as visual question answering, yet they can still fail even when the correct
visual evidence is present. In this work, we systematically investigate whether
these failures arise from not perceiving the evidence or from not leveraging it
effectively. By examining layer-wise attention dynamics, we find that shallow
layers focus primarily on text, while deeper layers sparsely but reliably
attend to localized evidence regions. Surprisingly, VLMs often perceive the
visual evidence when outputting incorrect answers, a phenomenon we term
``seeing but not believing'' that widely exists in major VLM families. Building
on this, we introduce an inference-time intervention that highlights deep-layer
evidence regions through selective attention-based masking. It requires no
training and consistently improves accuracy across multiple families, including
LLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable
evidence internally but under-utilize it, making such signals explicit can
bridge the gap between perception and reasoning, advancing the diagnostic
understanding and reliability of VLMs.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [100] [Quantum Approximate Optimization Algorithm for MIMO with Quantized b-bit Beamforming](https://arxiv.org/abs/2510.15935)
*Nikos A Mitsiou,Ioannis Krikidis,George K Karagiannidis*

Main category: cs.ET

TL;DR: 本文探索使用量子近似优化算法(QAOA)和交替优化来解决6G MIMO系统中b位量化移相器的波束成形问题，首次建立了量化波束成形与量子电路旋转门之间的理论联系。


<details>
  <summary>Details</summary>
Motivation: 6G通信中的MIMO系统面临硬件复杂度和功耗挑战，低比特量化架构虽然成本效益高，但引入了NP难组合优化问题，需要新的解决方案。

Method: 采用量子近似优化算法(QAOA)和交替优化方法，将量化移相器的波束成形问题映射到量子电路的旋转门，并提出了预热启动QAOA方法提高计算效率。

Result: 数值结果表明所提方法在量化波束成形增益方面优于文献中的经典优化基准方法。

Conclusion: 量子优化方法为6G MIMO系统中的量化波束成形问题提供了有效解决方案，建立的量子电路映射理论联系具有广泛的应用前景。

Abstract: Multiple-input multiple-output (MIMO) is critical for 6G communication,
offering improved spectral efficiency and reliability. However, conventional
fully digital designs face significant challenges due to high hardware
complexity and power consumption. Low-bit MIMO architectures, such as those
employing b-bit quantized phase shifters, provide a cost-effective alternative
but introduce NP-hard combinatorial problems in the pre- and post-coding
design. This paper explores the use of the Quantum Approximate Optimization
Algorithm (QAOA) and alternating optimization to address the problem of b-bit
quantized phase shifters both at the transmitter and the receiver. We
demonstrate that the structure of this quantized beamforming problem aligns
naturally with hybrid-classical methods like QAOA, as the phase shifts used in
beamforming can be directly mapped to rotation gates in a quantum circuit.
Notably, this paper is the first to show that theoretical connection. Then, the
Hamiltonian derivation analysis for the b-bit case is presented, which could
have applications in different fields, such as integrated sensing and
communication, and emerging quantum algorithms such as quantum machine
learning. In addition, a warm-start QAOA approach is studied which improves
computational efficiency. Numerical results highlight the effectiveness of the
proposed methods in achieving an improved quantized beamforming gain over their
classical optimization benchmarks from the literature.

</details>


### [101] [Navigate in Demanding Missions: Integrating Human Intelligence and Brain-Inspired Intelligence](https://arxiv.org/abs/2510.17530)
*Xu He,Xiaolin Meng,Youdong Zhang,Lingfei Mo,Wenxuan Yin*

Main category: cs.ET

TL;DR: 该论文分析了神经科学、脑启发智能和脑启发导航之间的复杂关系，提出将神经形态赋能的脑机接口整合到脑启发导航中，以增强无人系统在挑战性任务中的可靠导航能力。


<details>
  <summary>Details</summary>
Motivation: 当前脑机接口和脑启发导航领域缺乏合作关系，需要整合神经形态赋能的脑机接口来增强无人系统的可靠导航能力，特别是在深空探索等挑战性任务中。

Method: 通过整合神经形态赋能的脑机接口到脑启发导航中，利用脑启发人工智能增强机器智能，同时以人类智能作为机器智能失效时的安全保障。

Result: 提出的方法有望增强无人系统能力，促进空间认知障碍的诊断，但需要考虑相关的伦理和安全问题。

Conclusion: 神经形态赋能的脑机接口与脑启发导航的整合可以提升无人系统的导航可靠性，同时需要关注伦理和安全考量。

Abstract: This perspective analyzes the intricate interplay among neuroscience,
Brain-Inspired Intelligence (BII), and Brain-Inspired Navigation (BIN),
revealing a current lack of cooperative relationship between Brain-Computer
Interfaces (BCIs) and BIN fields. We advocate for the integration of
neuromorphic-empowered BCI into BIN, thereby bolstering the unmanned systems'
reliable navigation in demanding missions, such as deep space exploration, etc.
We highlight that machine intelligence, reinforced by brain-inspired artificial
consciousness, can extend human intelligence, with human intelligence mediated
by neuromorphic-enabled BCI acting as a safeguard in case machine intelligence
failures. This study also discusses the potentials of the proposed approach to
enhance unmanned systems' capabilities and facilitate the diagnostics of
spatial cognition disorders, while considering associated ethical and security
concerns.

</details>


### [102] [Quantum Synthetic Data Generation for Industrial Bioprocess Monitoring](https://arxiv.org/abs/2510.17688)
*Shawn M. Gibford,Mohammad Reza Boskabadi,Christopher J. Savoie,Seyed Soheil Mansouri*

Main category: cs.ET

TL;DR: 提出使用量子Wasserstein生成对抗网络(QWGAN-GP)生成生物制造过程的合成时间序列数据，以解决数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 生物制造中的数据稀缺和稀疏性给模型开发、过程监控和优化带来挑战，需要复制和捕捉工业生物过程的复杂动态。

Method: 使用量子Wasserstein生成对抗网络(QWGAN-GP)，其中生成器由参数化量子电路(PQC)组成，生成合成时间序列数据。

Result: 该方法在捕捉真实生物过程数据的时间动态方面表现良好，生成的光密度数据与历史实验数据具有高度保真度。

Conclusion: 量子计算与机器学习的结合为数据分析和生成开辟了新前沿，特别是在计算密集型领域，可用于提高软传感器设计的预测准确性或用于预测控制。

Abstract: Data scarcity and sparsity in bio-manufacturing poses challenges for accurate
model
  development, process monitoring, and optimization. We aim to replicate and
capture
  the complex dynamics of industrial bioprocesses by proposing the use of a
Quantum
  Wasserstein Generative Adversarial Network with Gradient Penalty (QWGAN-GP)
to
  generate synthetic time series data for industrially relevant processes. The
  generator within our GAN is comprised of a Parameterized Quantum Circuit
(PQC). This
  methodology offers potential advantages in process monitoring, modeling,
  forecasting, and optimization, enabling more efficient bioprocess management
by
  reducing the dependence on scarce experimental data. Our results demonstrate
  acceptable performance in capturing the temporal dynamics of real bioprocess
data.
  We focus on Optical Density, a key measurement for Dry Biomass estimation.
The data
  generated showed high fidelity to the actual historical experimental data.
This
  intersection of quantum computing and machine learning has opened new
frontiers in
  data analysis and generation, particularly in computationally intensive
fields, for
  use cases such as increasing prediction accuracy for soft sensor design or
for use
  in predictive control.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [103] [Comparison of Tax and Cap-and-Trade Carbon Pricing Schemes](https://arxiv.org/abs/2510.15941)
*Stéphane Crépey,Samuel Drapeau,Mekonnen Tadese*

Main category: econ.GN

TL;DR: 碳定价政策中碳税与排放交易系统在理论上等效，但实践中因金融中介参与而产生差异。研究发现中介机构会降低ETS的经济效益和监管财富。


<details>
  <summary>Details</summary>
Motivation: 探索碳税与排放交易系统在实际市场中的表现差异，特别是金融中介在排放交易市场中的作用，这是之前较少研究的维度。

Method: 建立统一框架比较碳税和市场机制的经济环境绩效，明确纳入金融中介参与，通过校准两种工具实现相同的总减排目标，评估不同市场结构下的经济表现。

Result: 两种方案在完全竞争下等效，但ETS中存在中介机构会降低监管财富和经济主体总财富，这源于中介对价格形成的影响和部分收入流的占用。

Conclusion: 碳市场设计中必须考虑中介机构行为，需要对排放交易系统不断演变的制度结构进行更多实证研究。

Abstract: Carbon pricing has become a central pillar of modern climate policy, with
carbon taxes and emissions trading systems (ETS) serving as the two dominant
approaches. Although economic theory suggests these instruments are equivalent
under idealized assumptions, their performance diverges in practice due to
real-world market imperfections. A particularly less explored dimension of this
divergence concerns the role of financial intermediaries in emissions trading
markets. This paper develops a unified framework to compare the economic and
environmental performance of tax- and market-based schemes, explicitly
incorporating the involvement of financial intermediaries. By calibrating both
instruments to deliver identical aggregate emission reduction targets, we
assess their economic performance across alternative market structures. Our
results suggest that although the two schemes are equivalent under perfect
competition, the presence of intermediaries in ETS reduces both regulatory
wealth and the aggregate wealth of economic agents relative to carbon taxation.
These effects stem from intermediaries' influence on price formation and their
appropriation of part of the revenue stream. The findings underscore the
importance of accounting for intermediaries' behavior in the design of carbon
markets and highlight the need for further empirical research on the evolving
institutional structure of emissions trading systems.

</details>


### [104] [Data for Inclusion: The Redistributive Power of Data Economics](https://arxiv.org/abs/2510.16009)
*Diego Vallarino*

Main category: econ.GN

TL;DR: 评估在金融排斥经济中扩大正面信用信息获取对收入分配和效率的影响，发现更广泛的数据共享能显著降低金融成本、压缩利率差异并减少信用负担不平等。


<details>
  <summary>Details</summary>
Motivation: 研究在金融排斥经济中扩大正面信用信息获取的再分配和效率影响，探讨不同数据共享机制对金融包容性的作用。

Method: 使用乌拉圭2021年家庭调查微观数据，模拟三种数据制度：仅负面信息、部分正面信息（Score+）和合成完全可见性，评估对信贷获取、利息负担和不平等的影响。

Result: 更广泛的数据共享显著降低金融成本、压缩利率分散度，并降低信用负担的基尼系数。部分可见性使部分人群受益，而完全合成访问提供最公平和高效的结果。

Conclusion: 信用数据应被视为非竞争性公共资产，对金融包容和减贫具有变革性意义。

Abstract: This paper evaluates the redistributive and efficiency impacts of expanding
access to positive credit information in a financially excluded economy. Using
microdata from Uruguay's 2021 household survey, we simulate three data regimes
negative only, partial positive (Score+), and synthetic full visibility and
assess their effects on access to credit, interest burden, and inequality. Our
findings reveal that enabling broader data sharing substantially reduces
financial costs, compresses interest rate dispersion, and lowers the Gini
coefficient of credit burden. While partial visibility benefits a subset of the
population, full synthetic access delivers the most equitable and efficient
outcomes. The analysis positions credit data as a non-rival public asset with
transformative implications for financial inclusion and poverty reduction.

</details>


### [105] [Development finance institutions (DFIs), political conditions, and foreign direct investment (FDI) in Sub-Saharan Africa](https://arxiv.org/abs/2510.16472)
*Carmen Berta C. De Saituma Cagiza,Ilidio Cagiza*

Main category: econ.GN

TL;DR: 本研究使用1990-2018年撒哈拉以南非洲五国的面板数据和固定效应模型，分析开发性金融机构对FDI和经济发展的影响。研究发现DFIs对FDI的理论正面影响在统计上不显著，但基础设施投资影响最大。


<details>
  <summary>Details</summary>
Motivation: 探讨开发性金融机构是否通过促进FDI流入来推动经济增长和实现可持续发展目标，填补撒哈拉以南非洲地区相关研究的空白。

Method: 使用1990-2018年尼日利亚、加纳、肯尼亚、南非和津巴布韦五国的年度面板数据，采用STATA中的固定效应模型进行定量分析。

Result: DFIs对FDI的理论正面影响在统计上不显著，表明存在区域经济差异的影响。基础设施领域的DFI投资对FDI影响最大，其次是农业综合企业和金融业。

Conclusion: 需要针对性政策解决区域差异，加强制度和宏观经济条件以优化DFIs对FDI和可持续发展的影响，为政策制定者提供框架。

Abstract: This study investigates the dynamic relationship between development finance
institutions (DFIs), foreign direct investment (FDI), and economic development
in Sub-Saharan Africa (SSA) from 1990 to 2018, using a quantitative panel
dataset of annual data for five SSA countries (Nigeria, Ghana, Kenya, South
Africa, and Zimbabwe) and a fixed-effects model estimated in STATA.
Specifically, the analysis examines whether DFIs enhance FDI inflows, thereby
promoting economic growth and contributing to the achievement of the
Sustainable Development Goals (SDGs). The findings indicate that although DFIs
have a theoretically positive impact on FDI, this relationship is not
statistically significant across the sample, suggesting contextual dependencies
influenced by regional economic variations. The study also analyzes how
economic growth, trade openness, inflation, political stability, and the rule
of law influence this nexus, elucidating their roles in shaping investment
climates. A sectoral analysis indicates that DFI investments in infrastructure,
agribusiness, and finance significantly affect FDI, with infrastructure having
the greatest impact owing to its foundational role in economic systems. This
research contributes by linking DFIs with FDI in SSA in a panel setting, thus
providing a framework for policymakers to strengthen institutional and
macroeconomic conditions to optimize the impact of DFIs on FDI and, ultimately,
on sustainable development. The findings underscore the need for targeted
policies to address regional disparities and enhance DFI effectiveness in
fostering sustainable growth.

</details>


### [106] [Income Taxes, Gross Hourly Wages, and the Anatomy of Behavioral Responses: Evidence from a Danish Tax Reform](https://arxiv.org/abs/2510.16483)
*Kazuhiko Sumiya,Jesper Bagger*

Main category: econ.GN

TL;DR: 利用丹麦行政数据和引入联合征税的税改，通过配偶收入识别，发现低收入工人的工资对边际税率有负向动态影响，弹性为0.4；中等收入工人影响较小且不显著。工资通过晋升或跳槽响应税收，而非工作时间变化。


<details>
  <summary>Details</summary>
Motivation: 研究所得税如何影响小时工资，特别关注税收对工资而非劳动供给的影响，利用丹麦税改提供的准实验环境。

Method: 使用丹麦行政数据和税改政策，采用准实验设计，利用配偶收入进行识别，对丈夫进行非参数双重差分图形分析。

Result: 低收入工人工资对净边际税率弹性为0.4，中等收入工人影响不显著；工资通过晋升或工作转换响应税收，日/年工作时间无显著变化。

Conclusion: 所得税主要通过影响小时工资而非劳动供给来影响年收入，工资响应机制是晋升或工作转换，而非工作时间调整。

Abstract: This paper provides quasi-experimental evidence on how income taxes affect
gross hourly wages, utilizing Danish administrative data and a tax reform that
introduced joint taxation. Exploiting spousal income for identification, we
present nonparametric, difference-in-differences graphical evidence among
husbands. For low-income workers, taxes have negative and dynamic effects on
wages; their wage elasticity with respect to net-of-marginal-tax rates is 0.4.
For medium-income workers, the effects are smaller and insignificant. Wages
respond to taxes through promotions or job-to-job transitions. Neither daily
nor annual hours worked respond significantly; consequently, annual earnings
respond to taxes primarily through hourly wages, rather than through labor
supply.

</details>


### [107] [The Crisis Simulator for Bolivia (KISr-p): An Empirically Grounded Modeling Framework](https://arxiv.org/abs/2510.16537)
*Ricardo Alonzo Fernández Salguero*

Main category: econ.GN

TL;DR: 本文介绍了玻利维亚危机模拟器(KISr-p)，这是一个基于凯恩斯跨期综合理论(KIS-CES)的季度随机模型，用于评估高不确定性和结构性约束下的宏观经济政策影响。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够评估高不确定性和结构性约束环境下宏观经济政策影响的模拟器，不同于标准的一般均衡框架，而是基于大量元分析的实证发现。

Method: 采用凯恩斯跨期综合(KIS)理论架构和CES生产函数，详细校准了实际、财政、货币、外部、劳动力和分配等模型模块，参数基于财政乘数层级、生产要素互补性、劳动力市场垄断力量等实证证据。

Result: 模拟结果显示了财政调整、外部融资、债务重组和结构性改革之间的权衡关系。优先考虑支出构成而非总量水平并承认制度摩擦的务实政策方法，相比教条式的一刀切方案能产生更优的宏观经济和福利结果。

Conclusion: 务实政策方法在考虑支出构成和制度摩擦时，能够产生比教条式方案更优的宏观经济和福利结果。

Abstract: This document presents a detailed technical report of the ``Crisis Simulator
for Bolivia (KISr-p),'' a quarterly stochastic model designed to evaluate the
impact of various macroeconomic policy strategies in an environment of high
uncertainty and structural constraints. Unlike standard general equilibrium
frameworks, this simulator is grounded in the consolidated empirical findings
of a vast collection of meta-analyses, adopting the theoretical architecture of
a Keynesian Intertemporal Synthesis (KIS) with a Constant Elasticity of
Substitution (KIS-CES) production function. The calibration of each model block
-- real, fiscal, monetary, external, labor, and distributional -- is described
in detail, with parameters justified by quantitative evidence on the hierarchy
of fiscal multipliers (Gechert and Rannenberg, 2018), the complementarity of
production factors (Gechert et al., 2022), monopsony power in the labor market
(Sokolova and S{\o}rensen, 2021), and the dynamics of exchange rate and
interest-rate pass-through. The model integrates these empirical regularities
to generate non-linear dynamics such as state-dependent multipliers, asymmetric
responses to shocks, and business-cycle phase interactions. Simulation results
highlight the trade-offs between fiscal adjustment, external financing, debt
restructuring, and structural reforms -- such as aggressive spending
reallocation and targeted public investment. Scenarios show that pragmatic
policy approaches that prioritize the \textit{composition} of spending over its
aggregate level and that recognize institutional frictions yield superior
macroeconomic and welfare outcomes compared to doctrinaire, one-size-fits-all
prescriptions.

</details>


### [108] [Evaluating the Public Pay Gap: A Comparison of Public and Private Sector Wages in France](https://arxiv.org/abs/2510.16626)
*Riddhi Kalsi*

Main category: econ.GN

TL;DR: 该研究解决了公共-私营部门工资文献中的实证难题，通过法国行政面板数据揭示了看似相似的工资差距背后隐藏的终身收入和工作稳定性差异，统一了先前矛盾的研究结论。


<details>
  <summary>Details</summary>
Motivation: 解决公共-私营部门工资文献中的实证矛盾，解释为什么使用相似数据的研究会得出关于工资溢价和惩罚的相反结论。

Method: 使用法国行政面板数据（2012-2019），通过期望最大化算法灵活建模部门转换、就业进出转换和收入异质性。

Result: 研究发现：女性在公共部门获得显著的终身收入优势，而高学历男性在公共部门经历终身惩罚；小时工资差距掩盖了终身收入和工作稳定性的显著差异；工资溢价和惩罚系统性依赖于性别、教育和工作经验。

Conclusion: 该研究通过提供部门差异的全面描述性分析，统一了现有研究叙事，揭示了工资动态中显著的未观察异质性，并强调了终身收入视角的重要性。

Abstract: This paper resolves the empirical puzzle in the public-private wage
literature: why studies using similar data reach contradictory conclusions
about wage premiums and penalties. Utilizing rich French administrative panel
data (2012-2019), this study has two main contributions: first, it presents a
set of new, intuitive yet previously undocumented stylized facts about wage
dynamics, sectoral mobility, and gender differences across sectors. The results
reveal that the modest hourly wage gaps conceal substantial disparities in
lifetime earnings and employment stability. Women, in particular, gain a
significant lifetime earnings advantage in the public sector, driven by higher
retention, better-compensated part-time work, and more equitable annual hours
compared to the private sector, where gender gaps remain larger, especially for
those with higher education. In contrast, highly educated men experience a
lifetime penalty in public employment due to rigid wage structures. By flexibly
modeling sectoral transitions, transitions into and out of employment, and
earnings heterogeneity using an Expectation-Maximization algorithm, this study
shows that both premiums and penalties depend systematically on gender,
education, and labor market experience. The analysis reveals that significant
unobserved heterogeneity remains in wage dynamics. These findings unify
prevailing narratives by providing a comprehensive, descriptive account of
sectoral differences in transitions, part-time work and wages by gender.

</details>


### [109] [New Demand Economics](https://arxiv.org/abs/2510.17121)
*Fenghua Wen,Xieyu Yin,Chufu Wen*

Main category: econ.GN

TL;DR: 该论文提出了一个关于物质丰裕时代需求经济学的理论，认为经济增长的引擎已从总量需求不足转向需求层级升级，教育驱动的效用管理是核心机制。


<details>
  <summary>Details</summary>
Motivation: 在物质丰裕时代，传统经济增长理论面临挑战，需要重新思考需求经济学理论，以解释和指导新时代的经济增长。

Method: 构建了一个可估计的一般均衡框架来分析需求层级升级对经济增长的影响。

Result: 研究发现，更高层级的需求产生更大的价值创造乘数，教育通过改变社会效用函数，提升高层级商品的效用，引导资源向高价值领域配置。

Conclusion: 政策应重新定位，从短期总量刺激转向以教育为中心、长期视野的人力资本投资，以促进需求层级升级和经济增长。

Abstract: We develop a theory of demand economics for an era of material abundance. The
binding constraint on growth has shifted from insufficient aggregate demand to
inadequate demand-tier upgrading. Our result is that, the new engine of growth
lies in upgrading the demand hierarchy: higher-tier demands generate larger
value-creation multipliers. The key mechanism is education-driven utility
management. Education transforms the social utility function, raises the
utility of higher-tier goods, and directs resources toward higher-value
domains; this warrants a policy reorientation away from short-run aggregate
stimulus toward education-centered, long-horizon investments in human capital.
Methodologically, we build an estimable general-equilibrium framework.

</details>


### [110] [Universalization and the Origins of Fiscal Capacity](https://arxiv.org/abs/2510.17481)
*Esteban Muñoz-Sobrado*

Main category: econ.GN

TL;DR: 该论文提出了一个基于普遍化推理的税收遵从和财政能力模型，公民通过想象如果每个人都类似行为来部分内化逃税的后果，将遵从决策与公共支出有效性联系起来。


<details>
  <summary>Details</summary>
Motivation: 研究道德内化如何帮助国家在制度薄弱的情况下摆脱低财政能力陷阱，探索公民道德推理对税收遵从和财政能力的影响机制。

Method: 建立理论模型，分析公民通过普遍化推理部分内化逃税后果的行为，以及自私精英在公共产品和私人租金之间的选择，考虑公共支出价值不确定性的情况。

Result: 公民的道德内化扩大了可行税基，促使精英将资源分配给公共产品而非私人占有；当公共支出价值不确定时，高价值精英可以通过提供公共产品来传递信号，促使公民提高遵从度。

Conclusion: 该分析确定了一个道德渠道，即使制度薄弱，国家也能通过公民的道德推理和精英的信号传递来提升财政能力，摆脱低能力陷阱。

Abstract: This paper proposes a model of tax compliance and fiscal capacity grounded in
universalization reasoning. Citizens partially internalize the consequences of
concealment by imagining a world in which everyone acted similarly, linking
their compliance decisions to the perceived effectiveness of public spending. A
selfish elite chooses between public goods and private rents, taking compliance
as given. In equilibrium, citizens' moral internalization expands the feasible
tax base and induces elites to allocate resources toward provision rather than
appropriation. When the value of public spending is uncertain, morality enables
credible reform: high-value elites can signal their type through provision,
prompting citizens to increase compliance and raising fiscal capacity within
the same period. The analysis thus identifies a moral channel through which
states may escape low-capacity traps even under weak institutions.

</details>


### [111] [Are penalty shootouts better than a coin toss? Evidence from European football](https://arxiv.org/abs/2510.17641)
*László Csató,Dóra Gréta Petróczy*

Main category: econ.GN

TL;DR: 基于2000-2025年欧足联俱乐部比赛的所有点球大战数据，研究发现点球大战结果无法通过踢球顺序、比赛场地和心理势头来预测，强队表现不优于弱队，点球大战相当于完美彩票。


<details>
  <summary>Details</summary>
Motivation: 受欧足联2021/22赛季取消客场进球规则的启发，研究旨在探讨欧足联俱乐部比赛中点球大战结果是否可预测。

Method: 分析2000-2025年所有欧足联俱乐部比赛的点球大战数据，使用Elo评分定义球队实力，考察踢球顺序、比赛场地和心理势头等因素。

Result: 未发现踢球顺序、比赛场地和心理势头对点球大战结果有显著影响，强队表现不优于弱队。

Conclusion: 在顶级欧洲足球比赛中，点球大战等同于完美彩票，结果完全随机不可预测。

Abstract: Penalty shootouts play an important role in the knockout stage of major
football tournaments, especially since the 2021/22 season, when the Union of
European Football Associations (UEFA) scrapped the away goals rule in its club
competitions. Inspired by this rule change, our paper examines whether the
outcome of a penalty shootout can be predicted in UEFA club competitions. Based
on all shootouts between 2000 and 2025, we find no evidence for the effect of
the kicking order, the field of the match, and psychological momentum. In
contrast to previous results, stronger teams, defined first by Elo ratings, do
not perform better than their weaker opponents. Consequently, penalty shootouts
are equivalent to a perfect lottery in top European football.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [112] [Prediction Intervals for Model Averaging](https://arxiv.org/abs/2510.16224)
*Zhongjun Qu,Wendun Wang,Xiaomeng Zhang*

Main category: econ.EM

TL;DR: 该论文提出了基于共形推理的模型平均预测区间方法，能够为模型平均预测提供不确定性度量，适用于各种模型设置和数据场景。


<details>
  <summary>Details</summary>
Motivation: 现有的频率模型平均方法主要局限于点预测，而预测不确定性的度量在一般设置中仍是一个未解决的问题，需要开发能够评估预测不确定性的方法。

Method: 基于共形推理构建预测区间，允许一般模型误设，适用于嵌套、不相交、重叠或任意组合的多个模型平均，权重可依赖于估计样本。提出了基准算法、局部自适应改进和分割样本程序。

Result: 建立了在两种假设下的覆盖保证：交换性下的精确有限样本有效性（适用于横截面数据）和平稳性下的渐近有效性（适用于时间序列数据）。通过房地产评估和股权溢价预测的应用进行了验证。

Conclusion: 提出的方法为模型平均预测提供了有效的预测区间，能够可靠地评估预测不确定性，适用于广泛的模型设置和数据场景。

Abstract: A rich set of frequentist model averaging methods has been developed, but
their applications have largely been limited to point prediction, as measuring
prediction uncertainty in general settings remains an open problem. In this
paper we propose prediction intervals for model averaging based on conformal
inference. These intervals cover out-of-sample realizations of the outcome
variable with a pre-specified probability, providing a way to assess predictive
uncertainty beyond point prediction. The framework allows general model
misspecification and applies to averaging across multiple models that can be
nested, disjoint, overlapping, or any combination thereof, with weights that
may depend on the estimation sample. We establish coverage guarantees under two
sets of assumptions: exact finite-sample validity under exchangeability,
relevant for cross-sectional data, and asymptotic validity under stationarity,
relevant for time-series data. We first present a benchmark algorithm and then
introduce a locally adaptive refinement and split-sample procedures that
broaden applicability. The methods are illustrated with a cross-sectional
application to real estate appraisal and a time-series application to equity
premium forecasting.

</details>


### [113] [On the Asymptotics of the Minimax Linear Estimator](https://arxiv.org/abs/2510.16661)
*Jing Kong*

Main category: econ.EM

TL;DR: 本文研究了通过极小极大程序设置权重的加权估计器，证明了在正则条件下该估计器具有根n一致性和渐近正态性，并推导了其渐近方差。


<details>
  <summary>Details</summary>
Motivation: 许多因果估计量可以表示为未知回归函数的连续线性泛函，但现有的极小极大线性估计器的根n理论有限，本文旨在填补这一空白。

Method: 采用极小极大线性估计器，通过凸优化问题在条件偏差和方差之间进行权衡来设置权重。

Result: 在正则条件下，极小极大线性估计器具有根n一致性和渐近正态性，且在一定方差条件下达到半参数效率界。

Conclusion: 在满足正则条件的设计中，标准误差置信区间足够；否则，偏差感知区间仍然重要。

Abstract: Many causal estimands, such as average treatment effects under
unconfoundedness, can be written as continuous linear functionals of an unknown
regression function. We study a weighting estimator that sets weights by a
minimax procedure: solving a convex optimization problem that trades off
worst-case conditional bias against variance. Despite its growing use, general
root-$n$ theory for this method has been limited. This paper fills that gap.
Under regularity conditions, we show that the minimax linear estimator is
root-$n$ consistent and asymptotically normal, and we derive its asymptotic
variance. These results justify ignoring worst-case bias when forming
large-sample confidence intervals and make inference less sensitive to the
scaling of the function class. With a mild variance condition, the estimator
attains the semiparametric efficiency bound, so an augmentation step commonly
used in the literature is not needed to achieve first-order optimality.
Evidence from simulations and three empirical applications, including
job-training and minimum-wage policies, points to a simple rule: in designs
satisfying our regularity conditions, standard-error confidence intervals
suffice; otherwise, bias-aware intervals remain important.

</details>


### [114] [Causal Inference in High-Dimensional Generalized Linear Models with Binary Outcomes](https://arxiv.org/abs/2510.16669)
*Jing Kong*

Main category: econ.EM

TL;DR: 提出了一种高维广义线性模型中因果效应的去偏估计器，适用于二元结果和一般链接函数，不依赖倾向得分估计。


<details>
  <summary>Details</summary>
Motivation: 在高维广义线性模型中，现有的因果效应估计方法如逆倾向得分估计器和双机器学习估计器在有限样本中表现不佳，需要开发更稳健的估计方法。

Method: 通过将正则化回归插件与从凸优化问题计算的权重相结合，近似平衡链接导数加权协变量并控制方差。

Result: 在标准条件下，估计器对密集线性对比和因果参数具有√n一致性和渐近正态性。模拟结果显示在有限样本中优于逆倾向得分估计器和双机器学习估计器。

Conclusion: 该方法在National Supported Work培训数据应用中，估计值和置信区间接近实验基准，证明了其有效性。

Abstract: This paper proposes a debiased estimator for causal effects in
high-dimensional generalized linear models with binary outcomes and general
link functions. The estimator augments a regularized regression plug-in with
weights computed from a convex optimization problem that approximately balances
link-derivative-weighted covariates and controls variance; it does not rely on
estimated propensity scores. Under standard conditions, the estimator is
$\sqrt{n}$-consistent and asymptotically normal for dense linear contrasts and
causal parameters. Simulation results show the superior performance of our
approach in comparison to alternatives such as inverse propensity score
estimators and double machine learning estimators in finite samples. In an
application to the National Supported Work training data, our estimates and
confidence intervals are close to the experimental benchmark.

</details>


### [115] [On Quantile Treatment Effects, Rank Similarity,and Variation of Instrumental Variables](https://arxiv.org/abs/2510.16681)
*Sukjin Han,Haiqing Xu*

Main category: econ.EM

TL;DR: 本文开发了一个非参数框架，用于在不可分离内生性下识别和估计分布处理效应。通过弱化秩相似性假设，构建了分布处理效应的识别边界，并利用线性半无限规划方法进行估计。


<details>
  <summary>Details</summary>
Motivation: 重新审视广泛采用的秩相似性假设，发现其限制性较强，需要更弱的识别条件来处理非参数框架下的内生性问题。

Method: 采用线性半无限规划方法构建识别边界，利用鞍点结构和KKT条件建立大样本性质。

Result: 在较弱的识别条件下成功构建了分布处理效应的识别边界，并证明了估计边界的一致性及渐近分布性质。

Conclusion: 提出的非参数框架能够有效处理不可分离内生性下的分布处理效应识别问题，为相关实证研究提供了理论基础和方法工具。

Abstract: This paper develops a nonparametric framework to identify and estimate
distributional treatment effects under nonseparable endogeneity. We begin by
revisiting the widely adopted \emph{rank similarity} (RS) assumption and
characterizing it by the relationship it imposes between observed and
counterfactual potential outcome distributions. The characterization highlights
the restrictiveness of RS, motivating a weaker identifying condition. Under
this alternative, we construct identifying bounds on the distributional
treatment effects of interest through a linear semi-infinite programming (SILP)
formulation. Our identification strategy also clarifies how richer exogenous
instrument variation, such as multi-valued or multiple instruments, can further
tighten these bounds. Finally, exploiting the SILP's saddle-point structure and
Karush-Kuhn-Tucker (KKT) conditions, we establish large-sample properties for
the empirical SILP: consistency and asymptotic distribution results for the
estimated bounds and associated solutions.

</details>


### [116] [Local Overidentification and Efficiency Gains in Modern Causal Inference and Data Combination](https://arxiv.org/abs/2510.16683)
*Xiaohong Chen,Haitian Xie*

Main category: econ.EM

TL;DR: 本文研究非参数局部（过度）识别和半参数效率，开发了统一方法分析三种因果模型：无混杂的一般处理模型、负控制模型和未观测混杂下的长期因果推断模型。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常施加强条件来恢复恰好识别，然后推导效率界限。本文放松这些假设，在过度识别模型中刻画一般效率界限和有效估计量。

Method: 将具有潜变量的结构模型转化为可观测变量的统计模型，通过条件矩限制分析局部过度识别。

Result: 第一个设计产生局部恰好识别统计模型，所有估计量共享相同渐近方差；后两个模型涉及非参数内生性，自然局部过度识别，导致某些双重稳健正交矩估计量效率低下。

Conclusion: 在过度识别模型(ii)和(iii)中刻画了一般效率界限和有效估计量，无需强假设条件。

Abstract: This paper studies nonparametric local (over-)identification, in the sense of
Chen and Santos (2018), and the associated semiparametric efficiency in modern
causal frameworks. We develop a unified approach that begins by translating
structural models with latent variables into their induced statistical models
of observables and then analyzes local overidentification through conditional
moment restrictions. We apply this approach to three leading models: (i) the
general treatment model under unconfoundedness, (ii) the negative control
model, and (iii) the long-term causal inference model under unobserved
confounding. The first design yields a locally just-identified statistical
model, implying that all regular asymptotically linear estimators of the
treatment effect share the same asymptotic variance, equal to the (trivial)
semiparametric efficiency bound. In contrast, the latter two models involve
nonparametric endogeneity and are naturally locally overidentified;
consequently, some doubly robust orthogonal moment estimators of the average
treatment effect are inefficient. Whereas existing work typically imposes
strong conditions to restore just-identification before deriving the efficiency
bound, we relax such assumptions and characterize the general efficiency bound,
along with efficient estimators, in the overidentified models (ii) and (iii).

</details>


### [117] [Equilibrium-Constrained Estimation of Recursive Logit Choice Models](https://arxiv.org/abs/2510.16886)
*Hung Tran,Tien Mai,Minh Hoang Ha*

Main category: econ.EM

TL;DR: 提出一种新的递归logit模型估计方法，将最大似然估计重新表述为带均衡约束的优化问题，并将其转化为锥优化问题，显著提高了计算效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统的嵌套固定点算法计算成本高且数值不稳定，限制了递归logit模型的实际应用。

Method: 将最大似然估计重新表述为带均衡约束的优化问题，将结构参数和价值函数都作为决策变量，并转化为锥优化问题。

Result: 在合成和真实数据集上的实验表明，该方法在保持与传统方法相当的准确性的同时，显著提高了计算稳定性和效率。

Conclusion: 该方法为递归logit模型估计提供了实用且可扩展的替代方案。

Abstract: The recursive logit (RL) model provides a flexible framework for modeling
sequential decision-making in transportation and choice networks, with
important applications in route choice analysis, multiple discrete choice
problems, and activity-based travel demand modeling. Despite its versatility,
estimation of the RL model typically relies on nested fixed-point (NFXP)
algorithms that are computationally expensive and prone to numerical
instability. We propose a new approach that reformulates the maximum likelihood
estimation problem as an optimization problem with equilibrium constraints,
where both the structural parameters and the value functions are treated as
decision variables. We further show that this formulation can be equivalently
transformed into a conic optimization problem with exponential cones, enabling
efficient solution using modern conic solvers such as MOSEK. Experiments on
synthetic and real-world datasets demonstrate that our convex reformulation
achieves accuracy comparable to traditional methods while offering significant
improvements in computational stability and efficiency, thereby providing a
practical and scalable alternative for recursive logit model estimation.

</details>


### [118] [Mixed LR-$C(α)$-type tests for irregular hypotheses, general criterion functions and misspecified models](https://arxiv.org/abs/2510.17070)
*Jean-Marie Dufour,Purevdorj Tuvaandorj*

Main category: econ.EM

TL;DR: 提出一种具有稳健性的似然比型检验，在极值估计框架下保持卡方分布，即使模型误设或参数空间受限时仍有效。


<details>
  <summary>Details</summary>
Motivation: 解决标准LR检验在模型误设（信息矩阵等式不成立）和参数空间受限（如边界参数）情况下的失效问题。

Method: 通过对受限和不受限准则函数分别进行调整来构建检验统计量，仅需根号n一致的估计量来处理不规则假设。

Result: 模拟显示在ARCH模型和生存回归中，该检验能保持准确尺寸并具有良好功效；实证应用表明比传统t检验提供更丰富信息。

Conclusion: 提出的LR型检验具有稳健性，能在模型误设和参数空间受限情况下保持有效性，为复杂假设检验提供可靠工具。

Abstract: This paper introduces a likelihood ratio (LR)-type test that possesses the
robustness properties of \(C(\alpha)\)-type procedures in an extremum
estimation setting.
  The test statistic is constructed by applying separate adjustments to the
restricted and unrestricted criterion functions, and is shown to be
asymptotically pivotal under minimal conditions. It features two main
robustness properties. First, unlike standard LR-type statistics, its null
asymptotic distribution remains chi-square even under model misspecification,
where the information matrix equality fails. Second, it accommodates irregular
hypotheses involving constrained parameter spaces, such as boundary parameters,
relying solely on root-\(n\)-consistent estimators for nuisance parameters.
When the model is correctly specified, no boundary constraints are present, and
parameters are estimated by extremum estimators, the proposed test reduces to
the standard LR-type statistic.
  Simulations with ARCH models, where volatility parameters are constrained to
be nonnegative, and parametric survival regressions with potentially monotone
increasing hazard functions, demonstrate that our test maintains accurate size
and exhibits good power. An empirical application to a two-way error components
model shows that the proposed test can provide more informative inference than
the conventional \(t\)-test.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [119] [Rethinking Arrow--Debreu: A New Framework for Exchange, Time, and Uncertainty](https://arxiv.org/abs/2510.16003)
*Nizar Riane*

Main category: econ.TH

TL;DR: 本文提出了有效贸易模型(ETM)，重新审视Arrow-Debreu一般均衡框架，强调理论市场与可实现市场互动的区别，证明纳什均衡存在性，并质疑福利理论基础。


<details>
  <summary>Details</summary>
Motivation: 重新审视传统一般均衡理论，强调理论市场互动与实际可实现交易之间的差异，质疑普遍市场出清条件和福利理论基础。

Method: 开发有效贸易模型(ETM)，基于双边可行性而非总供需的交易机制，纳入生产、货币和网络拓扑，使用条件模态建模预期。

Result: 证明了价格-需求对应的主要性质和纳什均衡存在性，展示了可贷资金和汇率的内生形成，均衡由交易约束、主观定价和分散谈判决定。

Conclusion: ETM为经典一般均衡提供了行为和结构基础替代方案，在统一框架中连接微观基础、货币动态和时间一致性。

Abstract: This paper revisits the Arrow-Debreu general equilibrium framework through
the lens of effective trade, emphasizing the distinction between theoretical
and realizable market interactions. We develop the Effective Trade Model (ETM),
where transactions arise from bilateral feasibility rather than aggregate
supply and demand desires. Within this framework, we establish the main
properties of the price-demand correspondence and prove the existence of Nash
equilibria, incorporating production, money, and network topology. The analysis
extends to time, uncertainty, and open economies, revealing how loanable funds
and exchange rates emerge endogenously. Our results show that equilibrium is
shaped by transaction constraints, subjective pricing, and decentralized
negotiation, rather than by universal market-clearing conditions, and thereby
call into question the foundations of welfare theory. Anticipation is modeled
via the conditional mode, capturing bounded rationality and information
limitations in contrast to the rational expectations hypothesis. The ETM thus
offers a behaviorally and structurally grounded alternative to classical
general equilibrium, bridging microfoundations, monetary dynamics, and temporal
consistency within a unified framework.

</details>


### [120] [Collective Experimentation with Correlated Payoffs](https://arxiv.org/abs/2510.16608)
*Kailin Chen*

Main category: econ.TH

TL;DR: 研究多智能体在相关收益下的指数赌博机模型，分析投票阈值对集体实验和信息聚合的影响


<details>
  <summary>Details</summary>
Motivation: 扩展Strulovici(2008)的独立收益假设，研究当智能体收益相关时，集体决策中的实验行为和信息聚合问题

Method: 构建指数赌博机模型，智能体通过个人实验学习自身收益，并通过考虑投票关键性间接学习他人信息，分析不同投票阈值下的集体行为

Result: 当智能体数量大时，提高实施风险行动的投票阈值k会增加实验，但只有在k足够低时才能有效聚合关于R整体合意性的信息

Conclusion: 投票阈值在集体决策中具有双重作用：高阈值促进实验但阻碍信息聚合，低阈值有利于信息聚合但可能限制实验

Abstract: This paper studies an exponential bandit model in which a group of agents
collectively decide whether to undertake a risky action $R$. This action is
implemented if the fraction of agents voting for it exceeds a predetermined
threshold $k$. Building on Strulovici (2008), which assumes the agents' payoffs
are independent, we explore the case in which the agents' payoffs are
correlated. During experimentation, each agent learns individually whether she
benefits from $R$; in this way, she also gains information about its overall
desirability. Furthermore, each agent is able to learn indirectly from the
others, because in making her decisions, she conditions on being pivotal (i.e.,
she assumes her vote will determine the collective outcome). We show that, when
the number of agents is large, increasing the threshold $k$ for implementing
$R$ leads to increased experimentation. However, information regarding the
overall desirability of $R$ is effectively aggregated only if $k$ is
sufficiently low.

</details>


### [121] [Preference Measurement Error, Concentration in Recommendation Systems, and Persuasion](https://arxiv.org/abs/2510.16972)
*Andreas Haupt*

Main category: econ.TH

TL;DR: 该论文分析了基于噪声偏好测量的算法推荐对市场集中度和不平等的影响。在对称噪声条件下，推荐系统会增加市场集中度并加剧消费者福利不平等。


<details>
  <summary>Details</summary>
Motivation: 研究推荐系统中基于噪声偏好测量的算法推荐如何影响市场集中度和不平等问题，特别是在统计多数群体和少数群体之间的效用分配。

Method: 将问题建模为贝叶斯说服问题，分析二元类型（多数群体和少数群体）在统计实验中的噪声揭示过程，特别关注对称统计实验条件下的说服机制。

Result: 在任意噪声结构下，与完全信息市场相比，对集中度的影响是模糊的；但在对称噪声条件下，市场集中度增加，消费者福利变得更加不平等。

Conclusion: 基于噪声偏好测量的推荐系统在对称噪声条件下会加剧市场集中度和福利不平等，对称统计实验下的说服分析具有独立的研究价值。

Abstract: Algorithmic recommendation based on noisy preference measurement is prevalent
in recommendation systems. This paper discusses the consequences of such
recommendation on market concentration and inequality. Binary types denoting a
statistical majority and minority are noisily revealed through a statistical
experiment. The achievable utilities and recommendation shares for the two
groups can be analyzed as a Bayesian Persuasion problem. While under arbitrary
noise structures, effects on concentration compared to a full-information
market are ambiguous, under symmetric noise, concentration increases and
consumer welfare becomes more unequal. We define symmetric statistical
experiments and analyze persuasion under a restriction to such experiments,
which may be of independent interest.

</details>


### [122] [Strategic hiding and exploration in networks](https://arxiv.org/abs/2510.16994)
*Francis Bloch,Bhaskar Dutta,Marcin Dziubiński*

Main category: econ.TH

TL;DR: 该论文研究了一个战略网络设计和探索模型，其中隐藏者在预算约束下选择连接网络和对象位置，而搜索者在不观察网络的情况下选择网络探索策略。


<details>
  <summary>Details</summary>
Motivation: 研究在预算约束下的网络设计和探索策略，分析隐藏者和搜索者之间的战略互动，特别是在网络连接性限制下的均衡行为。

Method: 采用纳什均衡分析方法，基于Alpern和Lidbetter(2013)的扩展搜索范式，研究树状网络和最多一个环路的网络结构。

Result: 获得了在树状网络情况下的纳什均衡，并描述了均衡收益。对于最多一个环路的网络，给出了找到隐藏者所需期望步数的上界。

Conclusion: 该模型为战略网络设计和探索提供了理论框架，揭示了在不同网络结构约束下隐藏者和搜索者的最优策略。

Abstract: We propose and study a model of strategic network design and exploration
where the hider, subject to a budget constraint restricting the number of
links, chooses a connected network and the location of an object. Meanwhile,
the seeker, not observing the network and the location of the object, chooses a
network exploration strategy starting at a fixed node in the network. The
network exploration follows the expanding search paradigm of Alpern and
Lidbetter (2013). We obtain a Nash equilibrium and characterize equilibrium
payoffs in the case of linking budget allowing for trees only. We also give an
upper bound on the expected number of steps needed to find the hider for the
case where the linking budget allows for at most one cycle in the network.

</details>


### [123] [When and what to learn in a changing world](https://arxiv.org/abs/2510.17757)
*César Barilla*

Main category: econ.TH

TL;DR: 该论文研究决策者在动态环境中控制信息获取时机和内容的最优策略，将问题分解为最优停止和静态信息获取，并发现长期动态下信息获取要么停止，要么遵循简单循环模式。


<details>
  <summary>Details</summary>
Motivation: 研究决策者如何最优地控制信息获取的时机和内容，以应对变化的状态，这在经济学和决策理论中具有重要意义。

Method: 将动态问题分解为最优停止和静态信息获取，分析长期动态行为，特别关注固定信息成本趋近于零时的极限情况。

Result: 发现信息获取要么停止，要么遵循简单循环模式；当固定成本趋近于零时，信念变化呈现跳跃性特征；长期解可以用"虚拟流收益"的闭式表达描述。

Conclusion: 该研究提供了信息获取动态的精确分析框架，并在投资组合多样化等应用中具有重要启示。

Abstract: A decision-maker periodically acquires information about a changing state,
controlling both the timing and content of updates. I characterize optimal
policies using a decomposition of the dynamic problem into optimal stopping and
static information acquisition. Eventually, information acquisition either
stops or follows a simple cycle in which updates occur at regular intervals to
restore prescribed levels of relative certainty. This enables precise analysis
of long run dynamics across environments. As fixed costs of information vanish,
belief changes become lumpy: it is optimal to either wait or acquire
information so as to exactly confirm the current belief until rare news prompts
a sudden change. The long run solution admits a closed-form characterization in
terms of the "virtual flow payoff". I highlight an illustrative application to
portfolio diversification.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [124] [VAR-SLAM: Visual Adaptive and Robust SLAM for Dynamic Environments](https://arxiv.org/abs/2510.16205)
*João Carlos Virgolino Soares,Gabriel Fischer Abati,Claudio Semini*

Main category: cs.RO

TL;DR: VAR-SLAM是一个基于ORB-SLAM3的视觉SLAM系统，结合轻量级语义关键点滤波器和自适应鲁棒损失函数，在动态环境中实现了更好的轨迹精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有动态环境视觉SLAM方法依赖语义滤波只能处理已知物体类别，或使用固定鲁棒核无法适应未知移动物体，导致精度下降。

Method: 结合轻量级语义关键点滤波器处理已知移动物体，使用Barron自适应鲁棒损失处理未知物体，通过残差在线估计鲁棒核的形状参数。

Result: 在TUM RGB-D、Bonn RGB-D Dynamic和OpenLORIS数据集上评估，相比最先进基线方法，轨迹精度和鲁棒性均有提升，在挑战性序列上比NGD-SLAM降低25% ATE RMSE，平均性能27 FPS。

Conclusion: VAR-SLAM在动态环境中表现出优越性能，能够有效处理已知和未知移动物体，同时保持实时性能。

Abstract: Visual SLAM in dynamic environments remains challenging, as several existing
methods rely on semantic filtering that only handles known object classes, or
use fixed robust kernels that cannot adapt to unknown moving objects, leading
to degraded accuracy when they appear in the scene. We present VAR-SLAM (Visual
Adaptive and Robust SLAM), an ORB-SLAM3-based system that combines a
lightweight semantic keypoint filter to deal with known moving objects, with
Barron's adaptive robust loss to handle unknown ones. The shape parameter of
the robust kernel is estimated online from residuals, allowing the system to
automatically adjust between Gaussian and heavy-tailed behavior. We evaluate
VAR-SLAM on the TUM RGB-D, Bonn RGB-D Dynamic, and OpenLORIS datasets, which
include both known and unknown moving objects. Results show improved trajectory
accuracy and robustness over state-of-the-art baselines, achieving up to 25%
lower ATE RMSE than NGD-SLAM on challenging sequences, while maintaining
performance at 27 FPS on average.

</details>


### [125] [DeGrip: A Compact Cable-driven Robotic Gripper for Desktop Disassembly](https://arxiv.org/abs/2510.16231)
*Bihao Zhang,Davood Soleymanzadeh,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: DeGrip是一种专为拆解报废电脑台式机设计的定制夹爪，具有3个自由度，采用线缆驱动机制，可在受限空间中操作，并在Isaac Sim中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 智能机器人拆解报废产品是机器人领域的长期挑战，现有机器学习方法因缺乏专用硬件而难以在实际场景中应用。

Method: 开发DeGrip定制夹爪，提供3个自由度，采用线缆驱动传输机制减小尺寸，设计腕部解耦腕关节和夹爪关节的驱动，并在Isaac Sim中建立拆解环境进行评估。

Result: 评估结果证实DeGrip能够在受限空间中操作，并能拆解任意配置的组件，具备拆解报废台式机的能力。

Conclusion: DeGrip夹爪成功解决了报废产品拆解中的硬件限制问题，为实际应用提供了有效的专用工具。

Abstract: Intelligent robotic disassembly of end-of-life (EOL) products has been a
long-standing challenge in robotics. While machine learning techniques have
shown promise, the lack of specialized hardware limits their application in
real-world scenarios. We introduce DeGrip, a customized gripper designed for
the disassembly of EOL computer desktops. DeGrip provides three degrees of
freedom (DOF), enabling arbitrary configurations within the disassembly
environment when mounted on a robotic manipulator. It employs a cable-driven
transmission mechanism that reduces its overall size and enables operation in
confined spaces. The wrist is designed to decouple the actuation of wrist and
jaw joints. We also developed an EOL desktop disassembly environment in Isaac
Sim to evaluate the effectiveness of DeGrip. The tasks were designed to
demonstrate its ability to operate in confined spaces and disassemble
components in arbitrary configurations. The evaluation results confirm the
capability of DeGrip for EOL desktop disassembly.

</details>


### [126] [Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning](https://arxiv.org/abs/2510.16240)
*Lukas Zbinden,Nigel Nelson,Juo-Tung Chen,Xinhao Chen,Ji Woong,Kim,Mahdi Azizian,Axel Krieger,Sean Huver*

Main category: cs.RO

TL;DR: Cosmos-Surg-dVRK是一个基于Cosmos世界基础模型的外科手术微调模型，结合视频分类器，实现了手术策略的自动化在线评估和基准测试，在缝合任务和胆囊切除术任务中显示出与真实手术机器人平台的良好相关性。


<details>
  <summary>Details</summary>
Motivation: 解决在物理机器人平台（如dVRK）上直接评估手术策略时面临的高成本、时间消耗、可重复性挑战和执行变异性等问题。

Method: 开发Cosmos-Surg-dVRK（Cosmos世界基础模型的外科手术微调版本），结合训练的视频分类器，构建自动化评估管道。在缝合垫任务和离体猪胆囊切除术任务上进行验证。

Result: 在缝合垫任务中，Cosmos-Surg-dVRK在线推演与真实dVRK Si平台结果具有强相关性；视频分类器与人工标注者达成良好一致性。在胆囊切除术任务中，初步实验显示与真实世界评估有良好对齐。

Conclusion: Cosmos-Surg-dVRK平台为复杂外科手术程序提供了有前景的自动化评估解决方案，能够有效替代昂贵的物理机器人平台测试。

Abstract: The rise of surgical robots and vision-language-action models has accelerated
the development of autonomous surgical policies and efficient assessment
strategies. However, evaluating these policies directly on physical robotic
platforms such as the da Vinci Research Kit (dVRK) remains hindered by high
costs, time demands, reproducibility challenges, and variability in execution.
World foundation models (WFM) for physical AI offer a transformative approach
to simulate complex real-world surgical tasks, such as soft tissue deformation,
with high fidelity. This work introduces Cosmos-Surg-dVRK, a surgical finetune
of the Cosmos WFM, which, together with a trained video classifier, enables
fully automated online evaluation and benchmarking of surgical policies. We
evaluate Cosmos-Surg-dVRK using two distinct surgical datasets. On tabletop
suture pad tasks, the automated pipeline achieves strong correlation between
online rollouts in Cosmos-Surg-dVRK and policy outcomes on the real dVRK Si
platform, as well as good agreement between human labelers and the V-JEPA
2-derived video classifier. Additionally, preliminary experiments with ex-vivo
porcine cholecystectomy tasks in Cosmos-Surg-dVRK demonstrate promising
alignment with real-world evaluations, highlighting the platform's potential
for more complex surgical procedures.

</details>


### [127] [NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?](https://arxiv.org/abs/2510.16263)
*Jierui Peng,Yanyan Zhang,Yicheng Duan,Tuo Liang,Vipin Chaudhary,Yu Yin*

Main category: cs.RO

TL;DR: NEBULA是一个用于单臂操作任务的统一评估生态系统，通过细粒度能力测试和系统性压力测试来诊断技能和测量鲁棒性，解决了传统端任务成功指标的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作(VLA)代理的评估受到粗糙的端任务成功指标的限制，无法提供精确的技能诊断或测量对真实世界扰动的鲁棒性，且碎片化的数据环境阻碍了可复现研究和通用模型的发展。

Method: 提出NEBULA生态系统，包含双轴评估协议：细粒度能力测试用于精确技能诊断，系统性压力测试用于测量鲁棒性；提供标准化API和大规模聚合数据集以支持跨数据集训练和公平比较。

Result: 使用NEBULA发现，表现最佳的VLA在空间推理和动态适应等关键能力上存在困难，这些缺陷被传统端任务成功指标所掩盖。

Conclusion: NEBULA通过同时测量代理能做什么以及何时能可靠地做到，为构建鲁棒、通用的具身代理提供了实用基础。

Abstract: The evaluation of Vision-Language-Action (VLA) agents is hindered by the
coarse, end-task success metric that fails to provide precise skill diagnosis
or measure robustness to real-world perturbations. This challenge is
exacerbated by a fragmented data landscape that impedes reproducible research
and the development of generalist models. To address these limitations, we
introduce \textbf{NEBULA}, a unified ecosystem for single-arm manipulation that
enables diagnostic and reproducible evaluation. NEBULA features a novel
dual-axis evaluation protocol that combines fine-grained \textit{capability
tests} for precise skill diagnosis with systematic \textit{stress tests} that
measure robustness. A standardized API and a large-scale, aggregated dataset
are provided to reduce fragmentation and support cross-dataset training and
fair comparison. Using NEBULA, we demonstrate that top-performing VLAs struggle
with key capabilities such as spatial reasoning and dynamic adaptation, which
are consistently obscured by conventional end-task success metrics. By
measuring both what an agent can do and when it does so reliably, NEBULA
provides a practical foundation for robust, general-purpose embodied agents.

</details>


### [128] [Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification](https://arxiv.org/abs/2510.16281)
*Yilin Wu,Anqi Li,Tucker Hermans,Fabio Ramos,Andrea Bajcsy,Claudia P'erez-D'Arpino*

Main category: cs.RO

TL;DR: 提出一种无需训练的策略引导方法，通过模拟候选动作序列并选择与文本计划最一致的结果，提升推理-视觉-语言-动作模型的忠实度。


<details>
  <summary>Details</summary>
Motivation: 现有推理VLA模型即使生成正确的文本计划，在分布外场景中仍可能产生与计划意图不符的动作，存在推理-动作不一致问题。

Method: 基于推理VLA的中间文本计划，采样多个候选动作序列，通过模拟预测结果，使用预训练VLM选择与文本计划最一致的动作序列。

Result: 在行为组合任务上比先前工作提升15%性能，对语义和视觉分布外扰动具有更强鲁棒性，且性能随计算和数据多样性扩展。

Conclusion: 将基础VLA的自然动作多样性从错误来源转化为优势，无需重新训练即可实现新颖行为组合，提升了推理-动作对齐的忠实度。

Abstract: Reasoning Vision Language Action (VLA) models improve robotic
instruction-following by generating step-by-step textual plans before low-level
actions, an approach inspired by Chain-of-Thought (CoT) reasoning in language
models. Yet even with a correct textual plan, the generated actions can still
miss the intended outcomes in the plan, especially in out-of-distribution (OOD)
scenarios. We formalize this phenomenon as a lack of embodied CoT faithfulness,
and introduce a training-free, runtime policy steering method for
reasoning-action alignment. Given a reasoning VLA's intermediate textual plan,
our framework samples multiple candidate action sequences from the same model,
predicts their outcomes via simulation, and uses a pre-trained Vision-Language
Model (VLM) to select the sequence whose outcome best aligns with the VLA's own
textual plan. Only executing action sequences that align with the textual
reasoning turns our base VLA's natural action diversity from a source of error
into a strength, boosting robustness to semantic and visual OOD perturbations
and enabling novel behavior composition without costly re-training. We also
contribute a reasoning-annotated extension of LIBERO-100, environment
variations tailored for OOD evaluation, and demonstrate up to 15% performance
gain over prior work on behavior composition tasks and scales with compute and
data diversity. Project Website at:
https://yilin-wu98.github.io/steering-reasoning-vla/

</details>


### [129] [SPOT: Sensing-augmented Trajectory Planning via Obstacle Threat Modeling](https://arxiv.org/abs/2510.16308)
*Chi Zhang,Xian Huang,Wei Dong*

Main category: cs.RO

TL;DR: SPOT是一个将感知目标融入运动规划的无人机避障框架，通过障碍物威胁建模实现实时观测感知轨迹规划，在动态遮挡环境中显著提升障碍物检测能力


<details>
  <summary>Details</summary>
Motivation: 单深度相机的无人机在动态避障中面临视野有限和盲区问题，现有方法将运动规划与感知分离，导致避障效果不佳和响应延迟

Method: 使用高斯过程构建障碍物置信图，通过碰撞感知推理机制将空间不确定性和轨迹邻近度转化为时变观测紧急度图，在视野内集成紧急度值定义可微分目标

Result: 在动态、杂乱和遮挡环境中，相比基线方法提前2.8秒检测到潜在动态障碍物，动态障碍物可见性提升超过500%，计算时间低于10毫秒

Conclusion: SPOT框架通过统一概率表示和观测感知规划，有效解决了单相机无人机的动态避障挑战，实现了在复杂环境中的安全导航

Abstract: UAVs equipped with a single depth camera encounter significant challenges in
dynamic obstacle avoidance due to limited field of view and inevitable blind
spots. While active vision strategies that steer onboard cameras have been
proposed to expand sensing coverage, most existing methods separate motion
planning from sensing considerations, resulting in less effective and delayed
obstacle response. To address this limitation, we introduce SPOT
(Sensing-augmented Planning via Obstacle Threat modeling), a unified planning
framework for observation-aware trajectory planning that explicitly
incorporates sensing objectives into motion optimization. At the core of our
method is a Gaussian Process-based obstacle belief map, which establishes a
unified probabilistic representation of both recognized (previously observed)
and potential obstacles. This belief is further processed through a
collision-aware inference mechanism that transforms spatial uncertainty and
trajectory proximity into a time-varying observation urgency map. By
integrating urgency values within the current field of view, we define
differentiable objectives that enable real-time, observation-aware trajectory
planning with computation times under 10 ms. Simulation and real-world
experiments in dynamic, cluttered, and occluded environments show that our
method detects potential dynamic obstacles 2.8 seconds earlier than baseline
approaches, increasing dynamic obstacle visibility by over 500\%, and enabling
safe navigation through cluttered, occluded environments.

</details>


### [130] [Manual2Skill++: Connector-Aware General Robotic Assembly from Instruction Manuals via Vision-Language Models](https://arxiv.org/abs/2510.16344)
*Chenrui Tie,Shengxiang Sun,Yudi Lin,Yanbo Wang,Zhongrui Li,Zhouhan Zhong,Jinxuan Zhu,Yiman Pang,Haonan Chen,Junting Chen,Ruihai Wu,Lin Shao*

Main category: cs.RO

TL;DR: 提出Manual2Skill++框架，将连接关系作为装配任务的核心要素，从装配手册中自动提取结构化连接信息，并构建层次化图表示来编码装配任务。


<details>
  <summary>Details</summary>
Motivation: 传统机器人装配方法将连接器视为次要因素，而连接关系实际上是决定装配成败的关键环节。需要将连接关系作为装配表示的一等公民。

Method: 使用大规模视觉语言模型解析装配手册中的符号图表和注释，构建层次化图表示，其中节点代表零件和子装配体，边显式建模组件间的连接关系。

Result: 创建了包含20多个装配任务的数据集验证表示提取方法，并在仿真环境中评估了四个复杂装配场景的完整任务理解到执行流程。

Conclusion: 将连接关系作为核心原语的装配表示方法能够有效支持机器人装配任务，从人类设计的装配手册中提取的连接知识具有实际应用价值。

Abstract: Assembly hinges on reliably forming connections between parts; yet most
robotic approaches plan assembly sequences and part poses while treating
connectors as an afterthought. Connections represent the critical "last mile"
of assembly execution, while task planning may sequence operations and motion
plan may position parts, the precise establishment of physical connections
ultimately determines assembly success or failure. In this paper, we consider
connections as first-class primitives in assembly representation, including
connector types, specifications, quantities, and placement locations. Drawing
inspiration from how humans learn assembly tasks through step-by-step
instruction manuals, we present Manual2Skill++, a vision-language framework
that automatically extracts structured connection information from assembly
manuals. We encode assembly tasks as hierarchical graphs where nodes represent
parts and sub-assemblies, and edges explicitly model connection relationships
between components. A large-scale vision-language model parses symbolic
diagrams and annotations in manuals to instantiate these graphs, leveraging the
rich connection knowledge embedded in human-designed instructions. We curate a
dataset containing over 20 assembly tasks with diverse connector types to
validate our representation extraction approach, and evaluate the complete task
understanding-to-execution pipeline across four complex assembly scenarios in
simulation, spanning furniture, toys, and manufacturing components with
real-world correspondence.

</details>


### [131] [Learning to Optimize Edge Robotics: A Fast Integrated Perception-Motion-Communication Approach](https://arxiv.org/abs/2510.16424)
*Dan Guo,Xibin Jin,Shuai Wang,Zhigang Wen,Miaowen Wen,Chengzhong Xu*

Main category: cs.RO

TL;DR: 本文提出集成感知、运动和通信(IPMC)的边端机器人系统，通过动态调整通信策略来减少传感器数据上传需求，并使用模仿学习神经网络降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了机器人功能与通信条件之间的相互依赖关系，导致通信开销过大。

Method: 采用集成感知、运动和通信(IPMC)框架，通过模仿学习神经网络动态调整压缩比、传输频率和发射功率等通信策略。

Result: 实验证明IPMC优于现有方法，模仿学习神经网络的计算复杂度比最优化求解器降低10倍以上，具备实时执行能力。

Conclusion: IPMC框架通过集成机器人感知、运动和通信，显著降低了通信开销，同时模仿学习实现了高效的实时优化。

Abstract: Edge robotics involves frequent exchanges of large-volume multi-modal data.
Existing methods ignore the interdependency between robotic functionalities and
communication conditions, leading to excessive communication overhead. This
paper revolutionizes edge robotics systems through integrated perception,
motion, and communication (IPMC). As such, robots can dynamically adapt their
communication strategies (i.e., compression ratio, transmission frequency,
transmit power) by leveraging the knowledge of robotic perception and motion
dynamics, thus reducing the need for excessive sensor data uploads.
Furthermore, by leveraging the learning to optimize (LTO) paradigm, an
imitation learning neural network is designed and implemented, which reduces
the computational complexity by over 10x compared to state-of-the art
optimization solvers. Experiments demonstrate the superiority of the proposed
IPMC and the real-time execution capability of LTO.

</details>


### [132] [What Questions Should Robots Be Able to Answer? A Dataset of User Questions for Explainable Robotics](https://arxiv.org/abs/2510.16435)
*Lennart Wachowiak,Andrew Coles,Gerard Canal,Oya Celiktutan*

Main category: cs.RO

TL;DR: 该论文引入了一个包含1,893个用户问题的数据集，涵盖家庭机器人的12个类别和70个子类别，揭示了用户最关心的问题类型及其重要性排序。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和对话界面在人机交互中的广泛应用，机器人回答用户问题的能力变得至关重要。现有可解释机器人研究主要关注"为什么"问题，但缺乏对用户实际会问的各种问题类型的全面理解。

Method: 通过创建15个视频刺激和7个文本刺激，描绘机器人执行各种家庭任务的情景，在Prolific平台上向100名参与者收集他们在每个情境下会问机器人的问题。

Result: 数据集中最常见的类别是任务执行细节（22.5%）、机器人能力（12.7%）和性能评估（11.3%）。用户认为关于机器人如何处理困难场景和确保正确行为的问题最重要。新手用户与有经验用户的问题类型存在差异。

Conclusion: 该数据集为识别机器人需要记录和暴露给对话界面的信息、基准测试问答模块以及设计符合用户期望的解释策略提供了宝贵基础。

Abstract: With the growing use of large language models and conversational interfaces
in human-robot interaction, robots' ability to answer user questions is more
important than ever. We therefore introduce a dataset of 1,893 user questions
for household robots, collected from 100 participants and organized into 12
categories and 70 subcategories. Most work in explainable robotics focuses on
why-questions. In contrast, our dataset provides a wide variety of questions,
from questions about simple execution details to questions about how the robot
would act in hypothetical scenarios -- thus giving roboticists valuable
insights into what questions their robot needs to be able to answer. To collect
the dataset, we created 15 video stimuli and 7 text stimuli, depicting robots
performing varied household tasks. We then asked participants on Prolific what
questions they would want to ask the robot in each portrayed situation. In the
final dataset, the most frequent categories are questions about task execution
details (22.5%), the robot's capabilities (12.7%), and performance assessments
(11.3%). Although questions about how robots would handle potentially difficult
scenarios and ensure correct behavior are less frequent, users rank them as the
most important for robots to be able to answer. Moreover, we find that users
who identify as novices in robotics ask different questions than more
experienced users. Novices are more likely to inquire about simple facts, such
as what the robot did or the current state of the environment. As robots enter
environments shared with humans and language becomes central to giving
instructions and interaction, this dataset provides a valuable foundation for
(i) identifying the information robots need to log and expose to conversational
interfaces, (ii) benchmarking question-answering modules, and (iii) designing
explanation strategies that align with user expectations.

</details>


### [133] [Advancing Off-Road Autonomous Driving: The Large-Scale ORAD-3D Dataset and Comprehensive Benchmarks](https://arxiv.org/abs/2510.16500)
*Chen Min,Jilin Mei,Heng Zhai,Shuai Wang,Tong Sun,Fanjie Kong,Haoyang Li,Fangyuan Mao,Fuyang Liu,Shuo Wang,Yiming Nie,Qi Zhu,Liang Xiao,Dawei Zhao,Yu Hu*

Main category: cs.RO

TL;DR: ORAD-3D是目前最大的越野自动驾驶数据集，涵盖多种地形和环境条件，并建立了包含5个核心任务的基准评测体系。


<details>
  <summary>Details</summary>
Motivation: 越野自动驾驶研究面临大规模高质量数据集稀缺的瓶颈问题，需要填补这一空白。

Method: 构建了ORAD-3D数据集，覆盖林地、农田、草地、河岸、砂石路、水泥路和乡村地区等多种地形，并捕捉不同天气条件和光照水平的环境变化。

Result: 创建了包含2D自由空间检测、3D占据预测、粗略GPS引导路径规划、视觉语言模型驱动自动驾驶和越野环境世界模型等5个任务的基准评测体系。

Conclusion: 该数据集和基准为推进挑战性越野场景下的感知与规划提供了统一且强大的资源。

Abstract: A major bottleneck in off-road autonomous driving research lies in the
scarcity of large-scale, high-quality datasets and benchmarks. To bridge this
gap, we present ORAD-3D, which, to the best of our knowledge, is the largest
dataset specifically curated for off-road autonomous driving. ORAD-3D covers a
wide spectrum of terrains, including woodlands, farmlands, grasslands,
riversides, gravel roads, cement roads, and rural areas, while capturing
diverse environmental variations across weather conditions (sunny, rainy,
foggy, and snowy) and illumination levels (bright daylight, daytime, twilight,
and nighttime). Building upon this dataset, we establish a comprehensive suite
of benchmark evaluations spanning five fundamental tasks: 2D free-space
detection, 3D occupancy prediction, rough GPS-guided path planning,
vision-language model-driven autonomous driving, and world model for off-road
environments. Together, the dataset and benchmarks provide a unified and robust
resource for advancing perception and planning in challenging off-road
scenarios. The dataset and code will be made publicly available at
https://github.com/chaytonmin/ORAD-3D.

</details>


### [134] [A Novel Gripper with Semi-Peaucellier Linkage and Idle-Stroke Mechanism for Linear Pinching and Self-Adaptive Grasping](https://arxiv.org/abs/2510.16517)
*Haokai Ding,Wenzeng Zhang*

Main category: cs.RO

TL;DR: SPD夹爪采用线性平行夹持机制，解决传统工业夹爪弧形运动需要调整高度的问题，具有自适应能力，能抓取不同形状大小的物体。


<details>
  <summary>Details</summary>
Motivation: 传统工业夹爪的指尖呈弧形运动，需要调整整个机械臂高度以避免与桌面碰撞，限制了抓取效率。

Method: 设计具有手掌和两个机械相同、对称排列手指的夹爪，指尖沿线性轨迹运动，可独立或单电机驱动，并进行优化分析理论。

Result: 原型测试显示成功实现线性平行夹持功能，具有良好的适应性。

Conclusion: SPD夹爪为各种机器人提供有效抓取能力，为深度学习训练数据收集奠定基础。

Abstract: This paper introduces a novel robotic gripper, named as the SPD gripper. It
features a palm and two mechanically identical and symmetrically arranged
fingers, which can be driven independently or by a single motor. The fingertips
of the fingers follow a linear motion trajectory, facilitating the grasping of
objects of various sizes on a tabletop without the need to adjust the overall
height of the gripper. Traditional industrial grippers with parallel gripping
capabilities often exhibit an arcuate motion at the fingertips, requiring the
entire robotic arm to adjust its height to avoid collisions with the tabletop.
The SPD gripper, with its linear parallel gripping mechanism, effectively
addresses this issue. Furthermore, the SPD gripper possesses adaptive
capabilities, accommodating objects of different shapes and sizes. This paper
presents the design philosophy, fundamental composition principles, and
optimization analysis theory of the SPD gripper. Based on the design theory, a
robotic gripper prototype was developed and tested. The experimental results
demonstrate that the robotic gripper successfully achieves linear parallel
gripping functionality and exhibits good adaptability. In the context of the
ongoing development of embodied intelligence technologies, this robotic gripper
can assist various robots in achieving effective grasping, laying a solid
foundation for collecting data to enhance deep learning training.

</details>


### [135] [DIV-Nav: Open-Vocabulary Spatial Relationships for Multi-Object Navigation](https://arxiv.org/abs/2510.16518)
*Jesús Ortega-Peimbert,Finn Lukas Busch,Timon Homberger,Quantao Yang,Olov Andersson*

Main category: cs.RO

TL;DR: DIV-Nav是一个实时导航系统，能够处理包含空间关系的复杂自由文本查询，通过语义地图分解、交集计算和LVLM验证来实现高效导航。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本物体导航通常只支持简单查询（如"电视"），但无法处理复杂空间关系查询（如"在桌子上的遥控器"）。需要开发能够处理复杂自由文本指令的导航系统。

Method: 1）将复杂空间约束的自然语言指令分解为语义地图上的简单对象查询；2）计算个体语义置信度图的交集以识别所有对象共存的区域；3）使用LVLM验证发现的对象是否符合原始复杂空间约束；4）调整前沿探索目标以适应空间搜索查询。

Result: 在MultiON基准测试和波士顿动力Spot机器人（使用Jetson Orin AGX）上的真实世界部署中进行了广泛实验验证。

Conclusion: DIV-Nav系统能够有效处理包含空间关系的复杂自由文本查询，实现了实时导航，并在基准测试和真实环境中表现出色。

Abstract: Advances in open-vocabulary semantic mapping and object navigation have
enabled robots to perform an informed search of their environment for an
arbitrary object. However, such zero-shot object navigation is typically
designed for simple queries with an object name like "television" or "blue
rug". Here, we consider more complex free-text queries with spatial
relationships, such as "find the remote on the table" while still leveraging
robustness of a semantic map. We present DIV-Nav, a real-time navigation system
that efficiently addresses this problem through a series of relaxations: i)
Decomposing natural language instructions with complex spatial constraints into
simpler object-level queries on a semantic map, ii) computing the Intersection
of individual semantic belief maps to identify regions where all objects
co-exist, and iii) Validating the discovered objects against the original,
complex spatial constrains via a LVLM. We further investigate how to adapt the
frontier exploration objectives of online semantic mapping to such spatial
search queries to more effectively guide the search process. We validate our
system through extensive experiments on the MultiON benchmark and real-world
deployment on a Boston Dynamics Spot robot using a Jetson Orin AGX. More
details and videos are available at https://anonsub42.github.io/reponame/

</details>


### [136] [Semi-Peaucellier Linkage and Differential Mechanism for Linear Pinching and Self-Adaptive Grasping](https://arxiv.org/abs/2510.16524)
*Haokai Ding,Zhaohan Chen,Tao Yang,Wenzeng Zhang*

Main category: cs.RO

TL;DR: SP-Diff平行夹爪系统采用创新的差动连杆机构和模块化对称双指配置，通过行星齿轮传动实现线性平行抓取，减少30%的Z轴重新校准需求，具备自适应抓取能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统末端执行器在智能工业自动化中适应性有限的问题，开发能够适应多样化工业工件和可变形物体的抓取系统。

Method: 采用差动连杆机构、模块化对称双指配置、行星齿轮传动系统，结合运动学优化的平行四边形连杆和差动机构，实现同步线性运动和独立手指姿态调整。

Result: 系统保持结构刚性，相比弧形轨迹夹爪减少30%的Z轴重新校准需求，能够自适应抓取各种工业工件和可变形物体（如柑橘类水果）。

Conclusion: SP-Diff作为柔性制造解决方案，通过自适应架构推进了机器人末端执行器的智能化，在协作机器人、物流自动化和专业操作场景中具有广阔应用前景。

Abstract: This paper presents the SP-Diff parallel gripper system, addressing the
limited adaptability of conventional end-effectors in intelligent industrial
automation. The proposed design employs an innovative differential linkage
mechanism with a modular symmetric dual-finger configuration to achieve
linear-parallel grasping. By integrating a planetary gear transmission, the
system enables synchronized linear motion and independent finger pose
adjustment while maintaining structural rigidity, reducing Z-axis recalibration
requirements by 30% compared to arc-trajectory grippers. The compact palm
architecture incorporates a kinematically optimized parallelogram linkage and
Differential mechanism, demonstrating adaptive grasping capabilities for
diverse industrial workpieces and deformable objects such as citrus fruits.
Future-ready interfaces are embedded for potential force/vision sensor
integration to facilitate multimodal data acquisition (e.g., trajectory
planning and object deformation) in digital twin frameworks. Designed as a
flexible manufacturing solution, SP-Diff advances robotic end-effector
intelligence through its adaptive architecture, showing promising applications
in collaborative robotics, logistics automation, and specialized operational
scenarios.

</details>


### [137] [MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation](https://arxiv.org/abs/2510.16617)
*Ruihan Zhao,Tyler Ingebrand,Sandeep Chinchali,Ufuk Topcu*

Main category: cs.RO

TL;DR: MoS-VLA是一个视觉-语言-动作模型框架，通过线性组合有限个学习到的基函数来表示机器人操作策略，能够通过单次专家演示快速适应新任务。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在部署到新环境、新机器人或新任务时往往无法直接使用，需要一种能够快速适应新场景的方法。

Method: 在预训练阶段联合学习跨数据集的基函数，创建结构化技能空间；测试时通过轻量级凸优化问题推断技能表示，无需梯度更新。

Result: 在五个未见数据集上实现了更低的动作预测误差，在仿真和真实机器人任务中成功执行了预训练VLA模型无法完成的任务。

Conclusion: MoS-VLA框架通过技能混合方法实现了对新任务的快速适应，在保持高性能的同时显著降低了适应开销。

Abstract: Vision-Language-Action (VLA) models trained on large robot datasets promise
general-purpose, robust control across diverse domains and embodiments.
However, existing approaches often fail out-of-the-box when deployed in novel
environments, embodiments, or tasks. We introduce Mixture of Skills VLA
(MoS-VLA), a framework that represents robot manipulation policies as linear
combinations of a finite set of learned basis functions. During pretraining,
MoS-VLA jointly learns these basis functions across datasets from the Open
X-Embodiment project, producing a structured skill space. At test time,
adapting to a new task requires only a single expert demonstration. The
corresponding skill representation is then inferred via a lightweight convex
optimization problem that minimizes the L1 action error, without requiring
gradient updates. This gradient-free adaptation incurs minimal overhead while
enabling rapid instantiation of new skills. Empirically, MoS-VLA achieves lower
action-prediction error on five out of five unseen datasets and succeeds in
both simulation and real-robot tasks where a pretrained VLA model fails
outright. Project page: mos-vla.github.io/

</details>


### [138] [First Responders' Perceptions of Semantic Information for Situational Awareness in Robot-Assisted Emergency Response](https://arxiv.org/abs/2510.16692)
*Tianshu Ruan,Zoe Betta,Georgios Tzoumas,Rustam Stolkin,Manolis Chiou*

Main category: cs.RO

TL;DR: 本研究调查了急救人员在紧急行动中对机器人系统使用语义信息和态势感知的态度，发现急救人员对机器人持积极态度，重视语义信息在态势感知中的作用，并愿意使用准确率约75%的不完美AI支持工具。


<details>
  <summary>Details</summary>
Motivation: 了解急救人员对语义增强态势感知在机器人系统中的态度和需求，填补该领域跨国调查的空白。

Method: 对来自8个国家的22名急救人员进行了结构化问卷调查，收集人口统计信息、对机器人的态度以及语义增强态势感知的体验。

Result: 大多数急救人员对机器人持积极态度，语义信息对态势感知的有用性评分为3.6/5，对预测突发事件的有用性评分为3.9/5。参与者要求语义输出准确率达到74.6%才信任，67.8%才认为有用。

Conclusion: 研究揭示了急救人员最重视的语义信息类型（物体识别、空间关系、风险背景），并发现了实验室能力与现场部署之间的差距，强调了急救人员与机器人研究人员之间更深入合作的必要性。

Abstract: This study investigates First Responders' (FRs) attitudes toward the use of
semantic information and Situational Awareness (SA) in robotic systems during
emergency operations. A structured questionnaire was administered to 22 FRs
across eight countries, capturing their demographic profiles, general attitudes
toward robots, and experiences with semantics-enhanced SA. Results show that
most FRs expressed positive attitudes toward robots, and rated the usefulness
of semantic information for building SA at an average of 3.6 out of 5. Semantic
information was also valued for its role in predicting unforeseen emergencies
(mean 3.9). Participants reported requiring an average of 74.6\% accuracy to
trust semantic outputs and 67.8\% for them to be considered useful, revealing a
willingness to use imperfect but informative AI support tools.
  To the best of our knowledge, this study offers novel insights by being one
of the first to directly survey FRs on semantic-based SA in a cross-national
context. It reveals the types of semantic information most valued in the field,
such as object identity, spatial relationships, and risk context-and connects
these preferences to the respondents' roles, experience, and education levels.
The findings also expose a critical gap between lab-based robotics capabilities
and the realities of field deployment, highlighting the need for more
meaningful collaboration between FRs and robotics researchers. These insights
contribute to the development of more user-aligned and situationally aware
robotic systems for emergency response.

</details>


### [139] [Towards Active Excitation-Based Dynamic Inertia Identification in Satellites](https://arxiv.org/abs/2510.16738)
*Matteo El-Hariry,Vittorio Franzese,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: 本文分析了激励设计对刚体纳/微卫星惯性参数识别的影响，比较了不同扭矩激励谱和两种估计算法在不同卫星配置下的性能。


<details>
  <summary>Details</summary>
Motivation: 研究在轨自适应惯性识别中，激励设计如何影响参数估计精度和鲁棒性，为实际应用提供指导。

Method: 模拟非线性姿态动力学，使用8种不同频谱丰富度的扭矩激励，比较最小二乘法和扩展卡尔曼滤波两种估计算法在三种卫星配置下的表现。

Result: 结果表明，激励频率内容和估计算法假设共同决定了估计精度和鲁棒性，明确了每种方法的最佳适用条件。

Conclusion: 为在轨自适应惯性识别提供了实用指导，并开源了相关代码。

Abstract: This paper presents a comprehensive analysis of how excitation design
influences the identification of the inertia properties of rigid nano- and
micro-satellites. We simulate nonlinear attitude dynamics with reaction-wheel
coupling, actuator limits, and external disturbances, and excite the system
using eight torque profiles of varying spectral richness. Two estimators are
compared, a batch Least Squares method and an Extended Kalman Filter, across
three satellite configurations and time-varying inertia scenarios. Results show
that excitation frequency content and estimator assumptions jointly determine
estimation accuracy and robustness, offering practical guidance for in-orbit
adaptive inertia identification by outlining the conditions under which each
method performs best. The code is provided as open-source .

</details>


### [140] [Adaptive Invariant Extended Kalman Filter for Legged Robot State Estimation](https://arxiv.org/abs/2510.16755)
*Kyung-Hwan Kim,DongHyun Ahn,Dong-hyun Lee,JuYoung Yoon,Dong Jin Hyun*

Main category: cs.RO

TL;DR: 提出自适应不变扩展卡尔曼滤波器，通过在线协方差估计调整接触足模型噪声水平，改进腿式机器人的本体状态估计性能


<details>
  <summary>Details</summary>
Motivation: 状态估计对腿式机器人至关重要，直接影响控制性能和运动稳定性。传统滑移拒绝方法无法处理小滑移，且过于敏感的滑移拒绝设置可能导致滤波器发散

Method: 使用自适应不变扩展卡尔曼滤波器，基于在线协方差估计调整接触足模型噪声水平；采用接触检测算法而非接触传感器，减少对额外硬件的依赖

Result: 在四足机器人LeoQuad上进行真实世界实验验证，在动态运动场景中表现出增强的状态估计性能

Conclusion: 该方法能有效处理传统方法难以解决的小滑移问题，提高腿式机器人在变化接触条件下的状态估计精度

Abstract: State estimation is crucial for legged robots as it directly affects control
performance and locomotion stability. In this paper, we propose an Adaptive
Invariant Extended Kalman Filter to improve proprioceptive state estimation for
legged robots. The proposed method adaptively adjusts the noise level of the
contact foot model based on online covariance estimation, leading to improved
state estimation under varying contact conditions. It effectively handles small
slips that traditional slip rejection fails to address, as overly sensitive
slip rejection settings risk causing filter divergence. Our approach employs a
contact detection algorithm instead of contact sensors, reducing the reliance
on additional hardware. The proposed method is validated through real-world
experiments on the quadruped robot LeoQuad, demonstrating enhanced state
estimation performance in dynamic locomotion scenarios.

</details>


### [141] [T3 Planner: A Self-Correcting LLM Framework for Robotic Motion Planning with Temporal Logic](https://arxiv.org/abs/2510.16767)
*Jia Li,Guoxiang Zhao*

Main category: cs.RO

TL;DR: T3 Planner是一个基于大语言模型的机器人运动规划框架，通过三个级联模块分解时空任务约束，使用信号时序逻辑验证器确保生成的运动计划可行性。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖领域专业知识定制规划器，难以处理时空耦合约束，容易产生不可行运动计划。大语言模型虽然擅长语义推理，但存在幻觉问题导致不可行规划。

Method: 使用三个级联模块分解时空任务约束，每个模块刺激LLM生成候选轨迹序列，通过信号时序逻辑验证器检查可行性，直到找到满足复杂时空和逻辑约束的方案。

Result: 实验表明T3 Planner在多种场景下显著优于基线方法，所需推理能力可蒸馏到轻量级Qwen3-4B模型中实现高效部署。

Conclusion: T3 Planner通过结合LLM的语义推理能力和形式化验证，有效解决了自然语言指令到可行运动计划的转换问题，实现了可靠的机器人运动规划。

Abstract: Translating natural language instructions into executable motion plans is a
fundamental challenge in robotics. Traditional approaches are typically
constrained by their reliance on domain-specific expertise to customize
planners, and often struggle with spatio-temporal couplings that usually lead
to infeasible motions or discrepancies between task planning and motion
execution. Despite the proficiency of Large Language Models (LLMs) in
high-level semantic reasoning, hallucination could result in infeasible motion
plans. In this paper, we introduce the T3 Planner, an LLM-enabled robotic
motion planning framework that self-corrects it output with formal methods. The
framework decomposes spatio-temporal task constraints via three cascaded
modules, each of which stimulates an LLM to generate candidate trajectory
sequences and examines their feasibility via a Signal Temporal Logic (STL)
verifier until one that satisfies complex spatial, temporal, and logical
constraints is found.Experiments across different scenarios show that T3
Planner significantly outperforms the baselines. The required reasoning can be
distilled into a lightweight Qwen3-4B model that enables efficient deployment.
All supplementary materials are accessible at
https://github.com/leeejia/T3_Planner.

</details>


### [142] [A Preliminary Exploration of the Differences and Conjunction of Traditional PNT and Brain-inspired PNT](https://arxiv.org/abs/2510.16771)
*Xu He,Xiaolin Meng,Wenxuan Yin,Youdong Zhang,Lingfei Mo,Xiangdong An,Fangwen Yu,Shuguo Pan,Yufeng Liu,Jingnan Liu,Yujia Zhang,Wang Gao*

Main category: cs.RO

TL;DR: 该论文提出了从"工具导向"转向"认知驱动"的定位、导航与授时(PNT)新范式，通过融合机器PNT的高精度与脑启发空间认知，构建四层融合框架来推进通用PNT发展。


<details>
  <summary>Details</summary>
Motivation: 当前复杂环境需要更具弹性、能效和认知能力的PNT系统，目标是赋予无人系统脑启发空间认知导航能力，同时利用机器PNT的高精度优势。

Method: 提出四层融合框架（观测-能力-决策-硬件），整合数值精度与脑启发智能；多层次分析传统PNT、生物脑PNT和脑启发PNT的差异。

Result: 建立了认知驱动的PNT新视角和发展路线图，为融合机器精度与生物智能提供了理论框架。

Conclusion: 脑启发PNT代表了PNT发展的未来方向，通过认知驱动方法可以实现更智能、更适应复杂环境的通用PNT系统。

Abstract: Developing universal Positioning, Navigation, and Timing (PNT) is our
enduring goal. Today's complex environments demand PNT that is more resilient,
energy-efficient and cognitively capable. This paper asks how we can endow
unmanned systems with brain-inspired spatial cognition navigation while
exploiting the high precision of machine PNT to advance universal PNT. We
provide a new perspective and roadmap for shifting PNT from "tool-oriented" to
"cognition-driven". Contributions: (1) multi-level dissection of differences
among traditional PNT, biological brain PNT and brain-inspired PNT; (2) a
four-layer (observation-capability-decision-hardware) fusion framework that
unites numerical precision and brain-inspired intelligence; (3) forward-looking
recommendations for future development of brain-inspired PNT.

</details>


### [143] [C-Free-Uniform: A Map-Conditioned Trajectory Sampler for Model Predictive Path Integral Control](https://arxiv.org/abs/2510.16905)
*Yukang Cao,Rahul Moorthy,O. Goktug Poyrazoglu,Volkan Isler*

Main category: cs.RO

TL;DR: 提出C-Free-Uniform轨迹采样方法，通过环境感知的控制输入采样实现自由配置空间均匀采样，并集成到MPPI控制器中，在复杂环境中以更少采样预算获得更高成功率


<details>
  <summary>Details</summary>
Motivation: 现有轨迹采样方法中的控制输入分布独立于环境，无法有效适应复杂环境，需要一种能感知局部环境并均匀采样自由配置空间的方法

Method: 提出C-Free-Uniform采样器，生成条件于局部地图的控制输入分布，实现自由配置空间均匀采样，并将其集成到MPPI控制器中形成CFU-MPPI

Result: 在复杂多边形环境中的导航任务中，CFU-MPPI相比现有方法在成功率方面表现更优，且所需采样预算显著减少

Conclusion: C-Free-Uniform通过环境感知的采样机制有效提升了采样效率和控制性能，为复杂环境中的运动规划提供了更优的解决方案

Abstract: Trajectory sampling is a key component of sampling-based control mechanisms.
Trajectory samplers rely on control input samplers, which generate control
inputs u from a distribution p(u | x) where x is the current state. We
introduce the notion of Free Configuration Space Uniformity (C-Free-Uniform for
short) which has two key features: (i) it generates a control input
distribution so as to uniformly sample the free configuration space, and (ii)
in contrast to previously introduced trajectory sampling mechanisms where the
distribution p(u | x) is independent of the environment, C-Free-Uniform is
explicitly conditioned on the current local map. Next, we integrate this
sampler into a new Model Predictive Path Integral (MPPI) Controller, CFU-MPPI.
Experiments show that CFU-MPPI outperforms existing methods in terms of success
rate in challenging navigation tasks in cluttered polygonal environments while
requiring a much smaller sampling budget.

</details>


### [144] [Floating-Base Deep Lagrangian Networks](https://arxiv.org/abs/2510.17270)
*Lucas Schulze,Juliano Decico Negri,Victor Barasuol,Vivian Suzano Medeiros,Marcelo Becker,Jan Peters,Oleg Arenz*

Main category: cs.RO

TL;DR: 提出Floating-Base Deep Lagrangian Networks (FeLaN)，一种针对浮动基系统（如人形机器人和四足机器人）的物理约束参数化方法，确保惯性矩阵满足正定性、分支诱导稀疏性和输入独立性等物理约束。


<details>
  <summary>Details</summary>
Motivation: 当前灰盒方法在系统识别中忽略了浮动基系统的特定物理约束，如惯性矩阵的正定性、分支诱导稀疏性和输入独立性，以及复合空间惯性的特性，导致物理一致性不足。

Method: 受Deep Lagrangian Networks (DeLaN)启发，训练神经网络预测满足所有物理约束的惯性矩阵，在拉格朗日力学下最小化逆动力学误差。

Result: 在多个四足机器人和人形机器人数据集上的实验表明，FeLaN在仿真和真实机器人上均取得了极具竞争力的性能，同时提供了更好的物理可解释性。

Conclusion: FeLaN通过物理约束参数化方法，显著提升了浮动基系统建模的物理一致性和泛化能力，为复杂机器人系统的动力学建模提供了有效解决方案。

Abstract: Grey-box methods for system identification combine deep learning with
physics-informed constraints, capturing complex dependencies while improving
out-of-distribution generalization. Yet, despite the growing importance of
floating-base systems such as humanoids and quadrupeds, current grey-box models
ignore their specific physical constraints. For instance, the inertia matrix is
not only positive definite but also exhibits branch-induced sparsity and input
independence. Moreover, the 6x6 composite spatial inertia of the floating base
inherits properties of single-rigid-body inertia matrices. As we show, this
includes the triangle inequality on the eigenvalues of the composite rotational
inertia. To address the lack of physical consistency in deep learning models of
floating-base systems, we introduce a parameterization of inertia matrices that
satisfies all these constraints. Inspired by Deep Lagrangian Networks (DeLaN),
we train neural networks to predict physically plausible inertia matrices that
minimize inverse dynamics error under Lagrangian mechanics. For evaluation, we
collected and released a dataset on multiple quadrupeds and humanoids. In these
experiments, our Floating-Base Deep Lagrangian Networks (FeLaN) achieve highly
competitive performance on both simulated and real robots, while providing
greater physical interpretability.

</details>


### [145] [Design of an Affordable, Fully-Actuated Biomimetic Hand for Dexterous Teleoperation Systems](https://arxiv.org/abs/2510.16931)
*Zhaoliang Wan,Zida Zhou,Zetong Bi,Zehui Yang,Hao Ding,Hui Cheng*

Main category: cs.RO

TL;DR: RAPID Hand是首个低成本、20自由度的灵巧手原型，采用创新的仿生驱动和传动方案，通过3D打印部件和定制齿轮实现经济性，在灵巧遥操作中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决灵巧遥操作中缺乏经济实惠的五指灵巧手的问题，这对于在"从演示中学习"范式中收集大规模真实机器人数据至关重要。

Method: 采用新颖的仿生驱动和传动方案，包括非拇指手指的通用指骨传动方案和全向拇指驱动机制，使用3D打印部件和定制齿轮以降低成本并便于维修。

Result: 通过定量指标和定性测试评估，在多项挑战性任务（多指抓取、勺子操作、类人钢琴演奏）中表现出色，证明其20自由度的完全驱动设计具有显著潜力。

Conclusion: RAPID Hand的完全驱动20自由度设计在灵巧遥操作方面具有重要前景，为大规模真实机器人数据收集提供了经济可行的解决方案。

Abstract: This paper addresses the scarcity of affordable, fully-actuated five-fingered
hands for dexterous teleoperation, which is crucial for collecting large-scale
real-robot data within the "Learning from Demonstrations" paradigm. We
introduce the prototype version of the RAPID Hand, the first low-cost,
20-degree-of-actuation (DoA) dexterous hand that integrates a novel
anthropomorphic actuation and transmission scheme with an optimized motor
layout and structural design to enhance dexterity. Specifically, the RAPID Hand
features a universal phalangeal transmission scheme for the non-thumb fingers
and an omnidirectional thumb actuation mechanism. Prioritizing affordability,
the hand employs 3D-printed parts combined with custom gears for easier
replacement and repair. We assess the RAPID Hand's performance through
quantitative metrics and qualitative testing in a dexterous teleoperation
system, which is evaluated on three challenging tasks: multi-finger retrieval,
ladle handling, and human-like piano playing. The results indicate that the
RAPID Hand's fully actuated 20-DoF design holds significant promise for
dexterous teleoperation.

</details>


### [146] [Integrating Trustworthy Artificial Intelligence with Energy-Efficient Robotic Arms for Waste Sorting](https://arxiv.org/abs/2510.17408)
*Halima I. Kure,Jishna Retnakumari,Augustine O. Nwajana,Umar M. Ismail,Bilyaminu A. Romo,Ehigiator Egho-Promise*

Main category: cs.RO

TL;DR: 本文提出了一种将可信人工智能与节能机械臂相结合的新方法，用于智能垃圾分类和分拣，通过CNN和MobileNetV2实现高精度分类，并在模拟环境中验证了能效优化的分拣操作。


<details>
  <summary>Details</summary>
Motivation: 解决城市环境中智能废物管理系统的需求，通过可信AI技术提高垃圾分类的准确性和效率，同时确保系统的透明性、鲁棒性和安全性。

Method: 使用基于MobileNetV2的卷积神经网络进行迁移学习，准确分类六类废物；开发机械臂模拟器，通过欧几里得距离计算能耗，优化分拣动作。

Result: 模型训练准确率达99.8%，验证准确率达80.5%；模拟系统能有效计算和优化分拣能耗，展示了良好的泛化能力和效率。

Conclusion: 该框架为城市智能废物管理提供了可靠、可扩展的解决方案，结合了可信AI原则和节能设计，具有实际应用潜力。

Abstract: This paper presents a novel methodology that integrates trustworthy
artificial intelligence (AI) with an energy-efficient robotic arm for
intelligent waste classification and sorting. By utilizing a convolutional
neural network (CNN) enhanced through transfer learning with MobileNetV2, the
system accurately classifies waste into six categories: plastic, glass, metal,
paper, cardboard, and trash. The model achieved a high training accuracy of
99.8% and a validation accuracy of 80.5%, demonstrating strong learning and
generalization. A robotic arm simulator is implemented to perform virtual
sorting, calculating the energy cost for each action using Euclidean distance
to ensure optimal and efficient movement. The framework incorporates key
elements of trustworthy AI, such as transparency, robustness, fairness, and
safety, making it a reliable and scalable solution for smart waste management
systems in urban settings.

</details>


### [147] [DINO-CVA: A Multimodal Goal-Conditioned Vision-to-Action Model for Autonomous Catheter Navigation](https://arxiv.org/abs/2510.17038)
*Pedram Fekri,Majid Roshanfar,Samuel Barbeau,Seyedfarzad Famouri,Thomas Looi,Dale Podolsky,Mehrdad Zadeh,Javad Dargahi*

Main category: cs.RO

TL;DR: DINO-CVA是一个多模态目标条件行为克隆框架，用于实现自主导管导航，融合视觉观察和操纵杆运动学，减少对操作员的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前导管介入手术主要依赖手动操作，现有机器人系统缺乏智能自主性，导致操作者疲劳、辐射暴露增加和手术结果不一致。

Method: 提出DINO-CVA框架，将视觉观察和操纵杆运动学融合到联合嵌入空间，通过自回归方式从专家演示中预测动作，并使用目标条件引导导航至指定目的地。

Result: DINO-CVA在预测动作方面达到高精度，与仅使用运动学的基线性能相当，同时将预测基于解剖环境。

Conclusion: 多模态目标条件架构在导管导航中具有可行性，是减少操作员依赖、提高导管治疗可靠性的重要一步。

Abstract: Cardiac catheterization remains a cornerstone of minimally invasive
interventions, yet it continues to rely heavily on manual operation. Despite
advances in robotic platforms, existing systems are predominantly follow-leader
in nature, requiring continuous physician input and lacking intelligent
autonomy. This dependency contributes to operator fatigue, more radiation
exposure, and variability in procedural outcomes. This work moves towards
autonomous catheter navigation by introducing DINO-CVA, a multimodal
goal-conditioned behavior cloning framework. The proposed model fuses visual
observations and joystick kinematics into a joint embedding space, enabling
policies that are both vision-aware and kinematic-aware. Actions are predicted
autoregressively from expert demonstrations, with goal conditioning guiding
navigation toward specified destinations. A robotic experimental setup with a
synthetic vascular phantom was designed to collect multimodal datasets and
evaluate performance. Results show that DINO-CVA achieves high accuracy in
predicting actions, matching the performance of a kinematics-only baseline
while additionally grounding predictions in the anatomical environment. These
findings establish the feasibility of multimodal, goal-conditioned
architectures for catheter navigation, representing an important step toward
reducing operator dependency and improving the reliability of catheterbased
therapies.

</details>


### [148] [Learning to Design Soft Hands using Reward Models](https://arxiv.org/abs/2510.17086)
*Xueqian Bai,Nicklas Hansen,Adabhav Singh,Michael T. Tolley,Yan Duan,Pieter Abbeel,Xiaolong Wang,Sha Yi*

Main category: cs.RO

TL;DR: 提出CEM-RM框架，通过基于遥操作控制策略优化肌腱驱动软体机器人手设计，将设计评估减少一半以上，同时从预收集的遥操作数据中学习优化手设计分布。


<details>
  <summary>Details</summary>
Motivation: 软体机器人手虽然能提供柔顺安全的交互，但设计既柔顺又功能多样的软手仍具挑战性。硬件与控制协同设计虽能更好耦合形态与行为，但搜索空间高维且仿真评估计算昂贵。

Method: 使用交叉熵方法与奖励模型(CEM-RM)框架，基于遥操作控制策略优化肌腱驱动软体机器人手设计。实现并行化仿真训练，优化后通过3D打印部署到现实世界。

Result: 在仿真和硬件实验中，优化设计在抓取各种挑战性物体时的成功率显著优于基线手。

Conclusion: CEM-RM框架能有效优化软体机器人手设计，大幅减少设计评估次数，同时从遥操作数据中学习优化设计分布，在实际应用中表现出色。

Abstract: Soft robotic hands promise to provide compliant and safe interaction with
objects and environments. However, designing soft hands to be both compliant
and functional across diverse use cases remains challenging. Although co-design
of hardware and control better couples morphology to behavior, the resulting
search space is high-dimensional, and even simulation-based evaluation is
computationally expensive. In this paper, we propose a Cross-Entropy Method
with Reward Model (CEM-RM) framework that efficiently optimizes tendon-driven
soft robotic hands based on teleoperation control policy, reducing design
evaluations by more than half compared to pure optimization while learning a
distribution of optimized hand designs from pre-collected teleoperation data.
We derive a design space for a soft robotic hand composed of flexural soft
fingers and implement parallelized training in simulation. The optimized hands
are then 3D-printed and deployed in the real world using both teleoperation
data and real-time teleoperation. Experiments in both simulation and hardware
demonstrate that our optimized design significantly outperforms baseline hands
in grasping success rates across a diverse set of challenging objects.

</details>


### [149] [Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey](https://arxiv.org/abs/2510.17111)
*Weifan Guan,Qinghao Hu,Aosheng Li,Jian Cheng*

Main category: cs.RO

TL;DR: 这篇论文系统综述了视觉-语言-动作(VLA)模型的效率优化方法，重点关注降低延迟、内存占用和训练/推理成本，将现有解决方案分为四个维度：模型架构、感知特征、动作生成和训练/推理策略。


<details>
  <summary>Details</summary>
Motivation: VLA模型在机器人控制中面临巨大的计算和内存需求，与边缘平台（如需要实时性能的移动机械臂）的约束相冲突，因此需要提高VLA系统的效率和可扩展性。

Method: 采用系统性综述方法，将现有VLA效率优化方法分类为四个维度：模型架构优化、感知特征处理、动作生成机制、训练和推理策略，并总结每个类别中的代表性技术。

Result: 提供了VLA效率优化方法的全面分类框架，识别了各维度的关键技术，为开发更高效的具身智能系统奠定了基础。

Conclusion: 讨论了未来趋势和开放挑战，强调了推进高效具身智能的发展方向，为VLA模型在资源受限环境中的实际应用提供了指导。

Abstract: Vision-Language-Action (VLA) models extend vision-language models to embodied
control by mapping natural-language instructions and visual observations to
robot actions. Despite their capabilities, VLA systems face significant
challenges due to their massive computational and memory demands, which
conflict with the constraints of edge platforms such as on-board mobile
manipulators that require real-time performance. Addressing this tension has
become a central focus of recent research. In light of the growing efforts
toward more efficient and scalable VLA systems, this survey provides a
systematic review of approaches for improving VLA efficiency, with an emphasis
on reducing latency, memory footprint, and training and inference costs. We
categorize existing solutions into four dimensions: model architecture,
perception feature, action generation, and training/inference strategies,
summarizing representative techniques within each category. Finally, we discuss
future trends and open challenges, highlighting directions for advancing
efficient embodied intelligence.

</details>


### [150] [Decentralized Real-Time Planning for Multi-UAV Cooperative Manipulation via Imitation Learning](https://arxiv.org/abs/2510.17143)
*Shantnav Agarwal,Javier Alonso-Mora,Sihao Sun*

Main category: cs.RO

TL;DR: 提出一种基于机器学习的去中心化动力学规划方法，用于多无人机协同运输缆绳悬挂负载，无需代理间通信，在部分可观测环境下有效工作。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖集中控制架构或可靠的代理间通信，限制了实际应用。需要开发在部分可观测且无通信条件下的去中心化规划方法。

Method: 利用模仿学习训练去中心化学生策略，模仿具有全局观测权限的集中式动力学运动规划器。使用物理信息神经网络生成平滑轨迹，训练时利用教师策略的完整轨迹提高样本效率。

Result: 学生策略可在标准笔记本电脑上2小时内完成训练，在仿真和真实环境中验证了跟随敏捷参考轨迹的能力，性能与集中式方法相当。

Conclusion: 该方法实现了无需通信的去中心化动力学规划，在部分可观测条件下表现良好，为多无人机协同负载运输提供了实用解决方案。

Abstract: Existing approaches for transporting and manipulating cable-suspended loads
using multiple UAVs along reference trajectories typically rely on either
centralized control architectures or reliable inter-agent communication. In
this work, we propose a novel machine learning based method for decentralized
kinodynamic planning that operates effectively under partial observability and
without inter-agent communication. Our method leverages imitation learning to
train a decentralized student policy for each UAV by imitating a centralized
kinodynamic motion planner with access to privileged global observations. The
student policy generates smooth trajectories using physics-informed neural
networks that respect the derivative relationships in motion. During training,
the student policies utilize the full trajectory generated by the teacher
policy, leading to improved sample efficiency. Moreover, each student policy
can be trained in under two hours on a standard laptop. We validate our method
in both simulation and real-world environments to follow an agile reference
trajectory, demonstrating performance comparable to that of centralized
approaches.

</details>


### [151] [DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through Metric-Guided Alignment](https://arxiv.org/abs/2510.17148)
*Yu Gao,Yiru Wang,Anqing Jiang,Heng Yuwen,Wang Shuo,Sun Hao,Wang Jijun*

Main category: cs.RO

TL;DR: DiffVLA++是一个增强的自动驾驶框架，通过度量引导的对齐显式桥接认知推理和端到端规划，结合VLA模型的世界知识和E2E模型的物理可行性。


<details>
  <summary>Details</summary>
Motivation: 传统端到端驾驶模型能生成物理可行的轨迹但缺乏世界知识处理长尾场景，而视觉-语言-动作模型有世界知识但3D推理能力有限导致物理不可行动作。

Method: 构建VLA模块生成语义基础的驾驶轨迹，设计E2E模块确保物理可行性，引入度量引导的轨迹评分器对齐两个模块的输出。

Result: 在ICCV 2025自动驾驶挑战赛排行榜上达到EPDMS 49.12。

Conclusion: DiffVLA++成功整合了认知推理和端到端规划的优势，通过度量引导对齐实现了更好的自动驾驶性能。

Abstract: Conventional end-to-end (E2E) driving models are effective at generating
physically plausible trajectories, but often fail to generalize to long-tail
scenarios due to the lack of essential world knowledge to understand and reason
about surrounding environments. In contrast, Vision-Language-Action (VLA)
models leverage world knowledge to handle challenging cases, but their limited
3D reasoning capability can lead to physically infeasible actions. In this work
we introduce DiffVLA++, an enhanced autonomous driving framework that
explicitly bridges cognitive reasoning and E2E planning through metric-guided
alignment. First, we build a VLA module directly generating semantically
grounded driving trajectories. Second, we design an E2E module with a dense
trajectory vocabulary that ensures physical feasibility. Third, and most
critically, we introduce a metric-guided trajectory scorer that guides and
aligns the outputs of the VLA and E2E modules, thereby integrating their
complementary strengths. The experiment on the ICCV 2025 Autonomous Grand
Challenge leaderboard shows that DiffVLA++ achieves EPDMS of 49.12.

</details>


### [152] [OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation](https://arxiv.org/abs/2510.17150)
*Heng Zhang,Wei-Hsing Huang,Gokhan Solak,Arash Ajoudani*

Main category: cs.RO

TL;DR: OmniVIC是一个基于视觉语言模型的通用可变阻抗控制器，通过自改进的检索增强生成和上下文学习，从图像和自然语言中理解任务上下文，生成自适应阻抗参数，提高接触丰富机器人操作任务的安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统可变阻抗控制器在机器人物理交互中虽有优势，但在未知、复杂、非结构化安全交互场景中缺乏泛化能力，无法适应涉及接触或不确定性的通用任务场景。

Method: 采用自改进的检索增强生成(RAG)和上下文学习(ICL)，RAG从结构化记忆库检索相关先验经验，ICL利用检索示例和当前任务提示查询VLM，生成上下文感知的自适应阻抗参数，并结合实时力/力矩反馈确保交互力在安全阈值内。

Result: 在复杂接触丰富任务套件中，OmniVIC在仿真和真实机器人任务中均优于基线方法，平均成功率从27%(基线)提升至61.4%(OmniVIC)，同时减少了力违规。

Conclusion: OmniVIC在高层语义推理和低层顺应控制之间架起桥梁，实现了更安全、更具泛化能力的机器人操作。

Abstract: We present OmniVIC, a universal variable impedance controller (VIC) enhanced
by a vision language model (VLM), which improves safety and adaptation in any
contact-rich robotic manipulation task to enhance safe physical interaction.
Traditional VIC have shown advantages when the robot physically interacts with
the environment, but lack generalization in unseen, complex, and unstructured
safe interactions in universal task scenarios involving contact or uncertainty.
To this end, the proposed OmniVIC interprets task context derived reasoning
from images and natural language and generates adaptive impedance parameters
for a VIC controller. Specifically, the core of OmniVIC is a self-improving
Retrieval-Augmented Generation(RAG) and in-context learning (ICL), where RAG
retrieves relevant prior experiences from a structured memory bank to inform
the controller about similar past tasks, and ICL leverages these retrieved
examples and the prompt of current task to query the VLM for generating
context-aware and adaptive impedance parameters for the current manipulation
scenario. Therefore, a self-improved RAG and ICL guarantee OmniVIC works in
universal task scenarios. The impedance parameter regulation is further
informed by real-time force/torque feedback to ensure interaction forces remain
within safe thresholds. We demonstrate that our method outperforms baselines on
a suite of complex contact-rich tasks, both in simulation and on real-world
robotic tasks, with improved success rates and reduced force violations.
OmniVIC takes a step towards bridging high-level semantic reasoning and
low-level compliant control, enabling safer and more generalizable
manipulation. Overall, the average success rate increases from 27% (baseline)
to 61.4% (OmniVIC).

</details>


### [153] [SimpleVSF: VLM-Scoring Fusion for Trajectory Prediction of End-to-End Autonomous Driving](https://arxiv.org/abs/2510.17191)
*Peiru Zheng,Yun Zhao,Zhan Gong,Hong Zhu,Shaohua Wu*

Main category: cs.RO

TL;DR: 提出SimpleVSF框架，通过融合VLM认知能力和轨迹融合技术来增强端到端自动驾驶规划，在ICCV 2025 NAVSIM v2挑战赛中取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法在复杂场景中决策仍存在不足，需要提升决策质量。

Method: 结合传统评分器和VLM增强评分器，使用权重融合器进行定量聚合和VLM融合器进行定性、上下文感知决策。

Result: 在ICCV 2025 NAVSIM v2端到端驾驶挑战赛中达到最先进性能，在安全性、舒适性和效率之间取得优越平衡。

Conclusion: SimpleVSF框架通过融合VLM认知能力有效提升了端到端自动驾驶的规划性能。

Abstract: End-to-end autonomous driving has emerged as a promising paradigm for
achieving robust and intelligent driving policies. However, existing end-to-end
methods still face significant challenges, such as suboptimal decision-making
in complex scenarios. In this paper,we propose SimpleVSF (Simple VLM-Scoring
Fusion), a novel framework that enhances end-to-end planning by leveraging the
cognitive capabilities of Vision-Language Models (VLMs) and advanced trajectory
fusion techniques. We utilize the conventional scorers and the novel
VLM-enhanced scorers. And we leverage a robust weight fusioner for quantitative
aggregation and a powerful VLM-based fusioner for qualitative, context-aware
decision-making. As the leading approach in the ICCV 2025 NAVSIM v2 End-to-End
Driving Challenge, our SimpleVSF framework demonstrates state-of-the-art
performance, achieving a superior balance between safety, comfort, and
efficiency.

</details>


### [154] [Performance Evaluation of an Integrated System for Visible Light Communication and Positioning Using an Event Camera](https://arxiv.org/abs/2510.17203)
*Ryota Soga,Masataka Kobayashi,Tsukasa Shimizu,Shintaro Shiba,Quan Kong,Shan Lu,Takaya Yamazato*

Main category: cs.RO

TL;DR: 提出了一种基于事件相机的新型自定位系统，将可见光通信(VLC)和可见光定位(VLP)集成在单个事件相机中，用于GPS受限环境下的车辆定位。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有高时间分辨率和高动态范围，能捕捉快速移动物体和处理极端光照场景，适合在隧道等GPS受限环境中实现可靠的车辆定位。

Method: 使用Walsh-Hadamard码为多个LED分配独特的导频序列，通过事件相机识别单个LED，利用相位相关(POC)进行距离估计，实现同时的VLC和VLP功能。

Result: 在30km/h车速下进行现场实验，距离估计的均方根误差在100米范围内小于0.75米，误码率低于0.01。

Conclusion: 这是首个使用单个事件相机实现同时VLC和VLP功能的车辆系统，展示了在真实世界中的鲁棒性能。

Abstract: Event cameras, featuring high temporal resolution and high dynamic range,
offer visual sensing capabilities comparable to conventional image sensors
while capturing fast-moving objects and handling scenes with extreme lighting
contrasts such as tunnel exits. Leveraging these properties, this study
proposes a novel self-localization system that integrates visible light
communication (VLC) and visible light positioning (VLP) within a single event
camera. The system enables a vehicle to estimate its position even in
GPS-denied environments, such as tunnels, by using VLC to obtain coordinate
information from LED transmitters and VLP to estimate the distance to each
transmitter.
  Multiple LEDs are installed on the transmitter side, each assigned a unique
pilot sequence based on Walsh-Hadamard codes. The event camera identifies
individual LEDs within its field of view by correlating the received signal
with these codes, allowing clear separation and recognition of each light
source. This mechanism enables simultaneous high-capacity MISO (multi-input
single-output) communication through VLC and precise distance estimation via
phase-only correlation (POC) between multiple LED pairs.
  To the best of our knowledge, this is the first vehicle-mounted system to
achieve simultaneous VLC and VLP functionalities using a single event camera.
Field experiments were conducted by mounting the system on a vehicle traveling
at 30 km/h (8.3 m/s). The results demonstrated robust real-world performance,
with a root mean square error (RMSE) of distance estimation within 0.75 m for
ranges up to 100 m and a bit error rate (BER) below 0.01 across the same range.

</details>


### [155] [Pole-Image: A Self-Supervised Pole-Anchored Descriptor for Long-Term LiDAR Localization and Map Maintenance](https://arxiv.org/abs/2510.17237)
*Wuhao Xie,Kanji Tanaka*

Main category: cs.RO

TL;DR: 提出Pole-Image表示方法，利用杆状地标作为锚点生成周围3D结构的签名，通过对比学习获得视角不变且高区分度的描述符，实现鲁棒的自定位和地图维护。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人长期自主性中自定位和地图维护的挑战，传统地标方法在可检测性和独特性之间存在权衡，需要一种既能稳定检测又具有高区分度的地标表示方法。

Method: 提出Pole-Image表示法，将杆状地标及其周围环境表示为以杆为原点的2D极坐标图像，利用杆作为高精度参考点，编码杆与周围点云的相对几何关系，并应用对比学习训练视角不变的描述符。

Result: 该方法克服了感知混淆，实现了鲁棒的自定位，同时高精度编码实现了高灵敏度的变化检测，有助于地图维护。

Conclusion: Pole-Image作为一种混合方法，成功解决了传统地标方法的局限性，通过结合杆状地标的易检测性和对比学习的优势，为长期自主导航提供了有效的解决方案。

Abstract: Long-term autonomy for mobile robots requires both robust self-localization
and reliable map maintenance. Conventional landmark-based methods face a
fundamental trade-off between landmarks with high detectability but low
distinctiveness (e.g., poles) and those with high distinctiveness but difficult
stable detection (e.g., local point cloud structures). This work addresses the
challenge of descriptively identifying a unique "signature" (local point cloud)
by leveraging a detectable, high-precision "anchor" (like a pole). To solve
this, we propose a novel canonical representation, "Pole-Image," as a hybrid
method that uses poles as anchors to generate signatures from the surrounding
3D structure. Pole-Image represents a pole-like landmark and its surrounding
environment, detected from a LiDAR point cloud, as a 2D polar coordinate image
with the pole itself as the origin. This representation leverages the pole's
nature as a high-precision reference point, explicitly encoding the "relative
geometry" between the stable pole and the variable surrounding point cloud. The
key advantage of pole landmarks is that "detection" is extremely easy. This
ease of detection allows the robot to easily track the same pole, enabling the
automatic and large-scale collection of diverse observational data (positive
pairs). This data acquisition feasibility makes "Contrastive Learning (CL)"
applicable. By applying CL, the model learns a viewpoint-invariant and highly
discriminative descriptor. The contributions are twofold: 1) The descriptor
overcomes perceptual aliasing, enabling robust self-localization. 2) The
high-precision encoding enables high-sensitivity change detection, contributing
to map maintenance.

</details>


### [156] [An adaptive hierarchical control framework for quadrupedal robots in planetary exploration](https://arxiv.org/abs/2510.17249)
*Franek Stark,Rohit Kumar,Shubham Vyas,Hannah Isermann,Jonas Haack,Mihaela Popescu,Jakob Middelberg,Dennis Mronga,Frank Kirchner*

Main category: cs.RO

TL;DR: 提出了一种模块化控制框架，结合模型动态控制、在线模型自适应和自适应脚步规划，解决机器人和地形参数不确定性，在火山实地测试中行走超过700米。


<details>
  <summary>Details</summary>
Motivation: 行星探测任务需要能在极端未知环境中导航的机器人。腿式机器人能克服轮式机器人的移动限制，但在未知条件下部署面临环境特定控制的挑战。

Method: 模块化控制框架结合模型动态控制、在线模型自适应和自适应脚步规划，包含状态估计功能，支持运行时重新配置，并集成到ROS 2中。

Result: 在两个四足机器人平台、多种硬件架构上验证性能，在火山实地测试中机器人行走超过700米。

Conclusion: 该框架能有效处理机器人和地形参数的不确定性，为腿式机器人在极端环境中的部署提供了可行解决方案。

Abstract: Planetary exploration missions require robots capable of navigating extreme
and unknown environments. While wheeled rovers have dominated past missions,
their mobility is limited to traversable surfaces. Legged robots, especially
quadrupeds, can overcome these limitations by handling uneven, obstacle-rich,
and deformable terrains. However, deploying such robots in unknown conditions
is challenging due to the need for environment-specific control, which is
infeasible when terrain and robot parameters are uncertain. This work presents
a modular control framework that combines model-based dynamic control with
online model adaptation and adaptive footstep planning to address uncertainties
in both robot and terrain properties. The framework includes state estimation
for quadrupeds with and without contact sensing, supports runtime
reconfiguration, and is integrated into ROS 2 with open-source availability.
Its performance was validated on two quadruped platforms, multiple hardware
architectures, and in a volcano field test, where the robot walked over 700 m.

</details>


### [157] [High-Level Multi-Robot Trajectory Planning And Spurious Behavior Detection](https://arxiv.org/abs/2510.17261)
*Fernando Salanova,Jesús Roche,Cristian Mahuela,Eduardo Montijano*

Main category: cs.RO

TL;DR: 提出了一种基于Nets-within-Nets范式的结构化数据生成框架和Transformer异常检测管道，用于识别多机器人系统中LTL规范下的异常执行行为。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统中异构智能体的高层任务可靠执行需要检测异常行为的方法，包括错误任务序列、空间约束违反、时间不一致性和任务语义偏差。

Method: 使用Nets-within-Nets范式协调机器人动作与LTL全局任务规范，提出基于Transformer的异常检测管道对机器人轨迹进行分类。

Result: 实验显示该方法在执行效率异常检测上达到91.3%准确率，核心任务违反检测88.3%，基于约束的自适应异常检测66.8%。消融实验表明新方法优于简单表示。

Conclusion: 该方法能有效识别多机器人系统中的异常执行行为，为可靠任务执行提供了解决方案。

Abstract: The reliable execution of high-level missions in multi-robot systems with
heterogeneous agents, requires robust methods for detecting spurious behaviors.
In this paper, we address the challenge of identifying spurious executions of
plans specified as a Linear Temporal Logic (LTL) formula, as incorrect task
sequences, violations of spatial constraints, timing inconsis- tencies, or
deviations from intended mission semantics. To tackle this, we introduce a
structured data generation framework based on the Nets-within-Nets (NWN)
paradigm, which coordinates robot actions with LTL-derived global mission
specifications. We further propose a Transformer-based anomaly detection
pipeline that classifies robot trajectories as normal or anomalous. Experi-
mental evaluations show that our method achieves high accuracy (91.3%) in
identifying execution inefficiencies, and demonstrates robust detection
capabilities for core mission violations (88.3%) and constraint-based adaptive
anomalies (66.8%). An ablation experiment of the embedding and architecture was
carried out, obtaining successful results where our novel proposition performs
better than simpler representations.

</details>


### [158] [Implicit State Estimation via Video Replanning](https://arxiv.org/abs/2510.17315)
*Po-Chen Ko,Jiayuan Mao,Yu-Hsiang Fu,Hsien-Jeng Yeh,Chu-Rong Chen,Wei-Chiu Ma,Yilun Du,Shao-Hua Sun*

Main category: cs.RO

TL;DR: 提出了一种新的视频规划框架，通过在线更新模型参数和过滤失败计划来适应交互时的不确定性，实现隐式状态估计。


<details>
  <summary>Details</summary>
Motivation: 现有视频规划框架难以适应交互时的失败，因为无法在部分观察环境中对不确定性进行推理。

Method: 集成交互时数据到规划过程，在线更新模型参数，在生成过程中过滤先前失败的计划。

Result: 在新模拟操作基准上的广泛实验表明，该方法能提高重新规划性能。

Conclusion: 该框架推进了基于视频的决策制定领域，能够动态适应而不需要显式建模未知状态变量。

Abstract: Video-based representations have gained prominence in planning and
decision-making due to their ability to encode rich spatiotemporal dynamics and
geometric relationships. These representations enable flexible and
generalizable solutions for complex tasks such as object manipulation and
navigation. However, existing video planning frameworks often struggle to adapt
to failures at interaction time due to their inability to reason about
uncertainties in partially observed environments. To overcome these
limitations, we introduce a novel framework that integrates interaction-time
data into the planning process. Our approach updates model parameters online
and filters out previously failed plans during generation. This enables
implicit state estimation, allowing the system to adapt dynamically without
explicitly modeling unknown state variables. We evaluate our framework through
extensive experiments on a new simulated manipulation benchmark, demonstrating
its ability to improve replanning performance and advance the field of
video-based decision-making.

</details>


### [159] [DDBot: Differentiable Physics-based Digging Robot for Unknown Granular Materials](https://arxiv.org/abs/2510.17335)
*Xintong Yang,Minglun Wei,Ze Ji,Yu-Kun Lai*

Main category: cs.RO

TL;DR: 提出了DDBot框架，用于自动化操控颗粒材料（如沙土），通过可微分物理模拟器实现高效系统识别和挖掘技能优化，在真实环境中实现零样本部署。


<details>
  <summary>Details</summary>
Motivation: 解决颗粒材料操控中的复杂接触动力学、不可预测材料特性和复杂系统状态等挑战，现有方法在效率和精度方面存在不足。

Method: 使用GPU加速的可微分物理模拟器，配备可微分技能到动作映射、任务导向演示方法、梯度裁剪和基于线搜索的梯度下降。

Result: DDBot能在5-20分钟内收敛，高效识别未知颗粒材料动力学并优化挖掘技能，在零样本真实部署中实现高精度结果。

Conclusion: DDBot在挖掘任务中展现出鲁棒性和高效性，基准测试结果优于现有最先进方法，具有实际应用价值。

Abstract: Automating the manipulation of granular materials poses significant
challenges due to complex contact dynamics, unpredictable material properties,
and intricate system states. Existing approaches often fail to achieve
efficiency and accuracy in such tasks. To fill the research gap, this paper
studies the small-scale and high-precision granular material digging task with
unknown physical properties. A new framework, named differentiable digging
robot (DDBot), is proposed to manipulate granular materials, including sand and
soil.
  Specifically, we equip DDBot with a differentiable physics-based simulator,
tailored for granular material manipulation, powered by GPU-accelerated
parallel computing and automatic differentiation. DDBot can perform efficient
differentiable system identification and high-precision digging skill
optimisation for unknown granular materials, which is enabled by a
differentiable skill-to-action mapping, a task-oriented demonstration method,
gradient clipping and line search-based gradient descent.
  Experimental results show that DDBot can efficiently (converge within 5 to 20
minutes) identify unknown granular material dynamics and optimise digging
skills, with high-precision results in zero-shot real-world deployments,
highlighting its practicality. Benchmark results against state-of-the-art
baselines also confirm the robustness and efficiency of DDBot in such digging
tasks.

</details>


### [160] [Interactive Force-Impedance Control](https://arxiv.org/abs/2510.17341)
*Fan Shao,Satoshi Endo,Sandra Hirche,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 提出统一交互力-阻抗控制(IFIC)框架，通过适应交互功率流确保接触丰富环境中的轻松安全交互，基于端口哈密顿框架保证系统无源性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在混合或统一力-阻抗控制下与主动人类或非被动环境物理交互时可能失去无源性而危及安全的问题。

Method: 在端口哈密顿框架内制定控制架构，包含交互和任务控制端口，通过适应交互功率流确保系统无源性。

Result: IFIC框架能够在接触丰富环境中实现轻松安全的交互，保证系统无源性。

Conclusion: 所提出的统一交互力-阻抗控制框架有效解决了机器人物理交互中的安全问题，为灵活角色适应提供了可靠保障。

Abstract: Human collaboration with robots requires flexible role adaptation, enabling
robot to switch between active leader and passive follower. Effective role
switching depends on accurately estimating human intention, which is typically
achieved through external force analysis, nominal robot dynamics, or
data-driven approaches. However, these methods are primarily effective in
contact-sparse environments. When robots under hybrid or unified
force-impedance control physically interact with active humans or non-passive
environments, the robotic system may lose passivity and thus compromise safety.
To address this challenge, this paper proposes the unified Interactive
Force-Impedance Control (IFIC) framework that adapts to the interaction power
flow, ensuring effortless and safe interaction in contact-rich environments.
The proposed control architecture is formulated within a port-Hamiltonian
framework, incorporating both interaction and task control ports, through which
system passivity is guaranteed.

</details>


### [161] [Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots](https://arxiv.org/abs/2510.17369)
*Haochen Su,Cristian Meo,Francesco Stella,Andrea Peirone,Kai Junge,Josie Hughes*

Main category: cs.RO

TL;DR: 将视觉-语言-动作模型部署到软连续机械臂上，通过微调实现安全的人机交互，解决了刚体机器人与软体机器人之间的具身化差异问题。


<details>
  <summary>Details</summary>
Motivation: 在人类中心的无结构环境中，机器人需要安全、适应性强和泛化能力。现有的视觉-语言-动作模型主要部署在刚性串联机械臂上，缺乏与环境安全交互的能力，而软体机器人具有固有的安全性优势。

Method: 提出了结构化的微调和部署流程，评估了两种先进的视觉-语言-动作模型在代表性操作任务上的表现，通过针对性微调来解决具身化不匹配问题。

Result: 现成策略由于具身化不匹配而失败，但经过微调后，软体机器人的性能与刚性机器人相当。

Conclusion: 微调对于弥合具身化差距至关重要，将视觉-语言-动作模型与软体机器人结合能够在人类共享环境中实现安全灵活的具身人工智能。

Abstract: Robotic systems are increasingly expected to operate in human-centered,
unstructured environments where safety, adaptability, and generalization are
essential. Vision-Language-Action (VLA) models have been proposed as a language
guided generalized control framework for real robots. However, their deployment
has been limited to conventional serial link manipulators. Coupled by their
rigidity and unpredictability of learning based control, the ability to safely
interact with the environment is missing yet critical. In this work, we present
the deployment of a VLA model on a soft continuum manipulator to demonstrate
autonomous safe human-robot interaction. We present a structured finetuning and
deployment pipeline evaluating two state-of-the-art VLA models (OpenVLA-OFT and
$\pi_0$) across representative manipulation tasks, and show while
out-of-the-box policies fail due to embodiment mismatch, through targeted
finetuning the soft robot performs equally to the rigid counterpart. Our
findings highlight the necessity of finetuning for bridging embodiment gaps,
and demonstrate that coupling VLA models with soft robots enables safe and
flexible embodied AI in human-shared environments.

</details>


### [162] [From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors](https://arxiv.org/abs/2510.17439)
*Zhengshen Zhang,Hao Li,Yalun Dai,Zhengbang Zhu,Lei Zhou,Chenchen Liu,Dong Wang,Francis E. H. Tay,Sijin Chen,Ziwei Liu,Yuxiao Liu,Xinghang Li,Pan Zhou*

Main category: cs.RO

TL;DR: FALCON通过在动作头中注入丰富的3D空间token来解决现有VLA模型的空间推理差距问题，利用空间基础模型从RGB图像中提取几何先验，并在可用时融合深度或姿态信息，同时保持语言推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于2D编码器的VLA模型存在空间推理差距，限制了泛化能力和适应性。现有的3D集成技术要么需要专用传感器且跨模态迁移能力差，要么注入缺乏几何信息的弱线索并损害视觉-语言对齐。

Method: 提出FALCON范式，在动作头中注入3D空间token，利用空间基础模型从RGB图像获取几何先验，包含可选的深度或姿态融合功能，通过空间增强动作头处理空间token以保持语言推理能力。

Result: 在三个仿真基准和十一个真实世界任务中，FALCON实现了最先进的性能，持续超越竞争基线，并在杂乱环境、空间提示条件以及物体尺度和高度变化下保持鲁棒性。

Conclusion: FALCON成功解决了空间表示、模态可迁移性和对齐方面的限制，为VLA模型提供了更好的3D空间推理能力。

Abstract: Existing vision-language-action (VLA) models act in 3D real-world but are
typically built on 2D encoders, leaving a spatial reasoning gap that limits
generalization and adaptability. Recent 3D integration techniques for VLAs
either require specialized sensors and transfer poorly across modalities, or
inject weak cues that lack geometry and degrade vision-language alignment. In
this work, we introduce FALCON (From Spatial to Action), a novel paradigm that
injects rich 3D spatial tokens into the action head. FALCON leverages spatial
foundation models to deliver strong geometric priors from RGB alone, and
includes an Embodied Spatial Model that can optionally fuse depth, or pose for
higher fidelity when available, without retraining or architectural changes. To
preserve language reasoning, spatial tokens are consumed by a Spatial-Enhanced
Action Head rather than being concatenated into the vision-language backbone.
These designs enable FALCON to address limitations in spatial representation,
modality transferability, and alignment. In comprehensive evaluations across
three simulation benchmarks and eleven real-world tasks, our proposed FALCON
achieves state-of-the-art performance, consistently surpasses competitive
baselines, and remains robust under clutter, spatial-prompt conditioning, and
variations in object scale and height.

</details>


### [163] [A Generalization of Input-Output Linearization via Dynamic Switching Between Melds of Output Functions](https://arxiv.org/abs/2510.17448)
*Mirko Mizzoni,Pieter van Goor,Barbara Bazzana,Antonio Franchi*

Main category: cs.RO

TL;DR: 提出了一个在非线性系统反馈线性化控制中切换不同输出集的系统框架，通过引入meld概念来定义可从更大输出集合中选择的有效、可反馈线性化的输出子集。


<details>
  <summary>Details</summary>
Motivation: 为了解决在非线性系统控制中需要在不同输出集之间切换的问题，同时保证系统状态的稳定性。

Method: 引入meld概念来形式化定义可反馈线性化的输出子集，建立切换条件（驻留时间和兼容性条件），证明在这些条件下切换时系统状态的均匀有界性。

Result: 证明了在合适的驻留时间和兼容性条件下，可以在不同meld之间切换，同时保证系统状态均匀有界，活动输出的误差动态在每个切换区间内保持指数稳定，共同输出在转换过程中无缝跟踪。

Conclusion: 该理论适用于任何可反馈线性化的非线性系统（如机器人、空中和地面车辆等），并通过机器人操纵器的数值模拟验证了其有效性。

Abstract: This letter presents a systematic framework for switching between different
sets of outputs for the control of nonlinear systems via feedback
linearization. We introduce the concept of a meld to formally define a valid,
feedback-linearizable subset of outputs that can be selected from a larger deck
of possible outputs. The main contribution is a formal proof establishing that
under suitable dwell-time and compatibility conditions, it is possible to
switch between different melds while guaranteeing the uniform boundedness of
the system state. We further show that the error dynamics of the active outputs
remain exponentially stable within each switching interval and that outputs
common to consecutive melds are tracked seamlessly through transitions. The
proposed theory is valid for any feedback linearizable nonlinear system, such
as, e.g., robots, aerial and terrestrial vehicles, etc.. We demonstrate it on a
simple numerical simulation of a robotic manipulator.

</details>


### [164] [HumanMPC - Safe and Efficient MAV Navigation among Humans](https://arxiv.org/abs/2510.17525)
*Simon Schaefer,Helen Oleynikova,Sandra Hirche,Stefan Leutenegger*

Main category: cs.RO

TL;DR: HumanMPC是一个用于3D微型飞行器在人群中导航的模型预测控制框架，结合了理论安全保证和数据驱动的人类运动预测模型，实现了安全高效的导航。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注简化的2D人群导航，未能充分考虑人体动态的复杂性，需要开发能够处理完整3D人体动态的安全导航方法。

Method: 提出了一种新颖的基于可达性的安全公式，仅约束初始控制输入以确保安全，同时在整个规划范围内建模其效果，结合数据驱动的人类运动预测。

Result: 在模拟实验和真实世界验证中，HumanMPC在目标导向导航和视觉伺服跟踪等任务中表现出色，确保安全而不过度保守，在效率和可靠性方面优于基线方法。

Conclusion: 该方法虽然应用于微型飞行器，但具有通用性，可适应其他平台，为机器人安全导航提供了有效的解决方案。

Abstract: Safe and efficient robotic navigation among humans is essential for
integrating robots into everyday environments. Most existing approaches focus
on simplified 2D crowd navigation and fail to account for the full complexity
of human body dynamics beyond root motion. We present HumanMPC, a Model
Predictive Control (MPC) framework for 3D Micro Air Vehicle (MAV) navigation
among humans that combines theoretical safety guarantees with data-driven
models for realistic human motion forecasting. Our approach introduces a novel
twist to reachability-based safety formulation that constrains only the initial
control input for safety while modeling its effects over the entire planning
horizon, enabling safe yet efficient navigation. We validate HumanMPC in both
simulated experiments using real human trajectories and in the real-world,
demonstrating its effectiveness across tasks ranging from goal-directed
navigation to visual servoing for human tracking. While we apply our method to
MAVs in this work, it is generic and can be adapted by other platforms. Our
results show that the method ensures safety without excessive conservatism and
outperforms baseline approaches in both efficiency and reliability.

</details>


### [165] [Distributed Spatial-Temporal Trajectory Optimization for Unmanned-Aerial-Vehicle Swarm](https://arxiv.org/abs/2510.17541)
*Xiaobo Zheng,Pan Tang,Defu Lin,Shaoming He*

Main category: cs.RO

TL;DR: 提出了一种基于ADMM和DDP的空间-时间轨迹优化框架D-PDDP，用于解决大规模无人机群轨迹优化问题，通过分布式算法和自适应惩罚参数调整减少迭代次数。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要预先设定最终时间且迭代次数多，限制了大规模无人机群的实际应用，需要解决非线性强、计算耗时的问题。

Method: 采用两层架构：使用参数化DDP进行单个无人机局部规划，ADMM实现约束满足和空间-时间参数共识，形成分布式参数化DDP算法。

Result: 通过多个仿真示例验证了算法的有效性，能够处理大规模无人机群的轨迹优化问题。

Conclusion: 提出的D-PDDP框架成功解决了大规模无人机群轨迹优化中的计算效率和收敛性问题，具有实际应用价值。

Abstract: Swarm trajectory optimization problems are a well-recognized class of
multi-agent optimal control problems with strong nonlinearity. However, the
heuristic nature of needing to set the final time for agents beforehand and the
time-consuming limitation of the significant number of iterations prohibit the
application of existing methods to large-scale swarm of Unmanned Aerial
Vehicles (UAVs) in practice. In this paper, we propose a spatial-temporal
trajectory optimization framework that accomplishes multi-UAV consensus based
on the Alternating Direction Multiplier Method (ADMM) and uses Differential
Dynamic Programming (DDP) for fast local planning of individual UAVs. The
introduced framework is a two-level architecture that employs Parameterized DDP
(PDDP) as the trajectory optimizer for each UAV, and ADMM to satisfy the local
constraints and accomplish the spatial-temporal parameter consensus among all
UAVs. This results in a fully distributed algorithm called Distributed
Parameterized DDP (D-PDDP). In addition, an adaptive tuning criterion based on
the spectral gradient method for the penalty parameter is proposed to reduce
the number of algorithmic iterations. Several simulation examples are presented
to verify the effectiveness of the proposed algorithm.

</details>


### [166] [Intent-Driven LLM Ensemble Planning for Flexible Multi-Robot Disassembly: Demonstration on EV Batteries](https://arxiv.org/abs/2510.17576)
*Cansu Erdogan,Cesar Alan Contreras,Alireza Rastegarpanah,Manolis Chiou,Rustam Stolkin*

Main category: cs.RO

TL;DR: 提出了一种意图驱动的规划管道，用于多机器人协作执行复杂操作任务，通过集成感知到文本的场景编码、LLM集合生成候选动作序列、LLM验证器和确定性一致性过滤器，实现从人类简单语言指令到可执行多机器人计划的可靠映射。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人协作执行复杂操作任务的规划问题，这些机器人具有不同的末端执行器和能力，需要在非结构化场景中规划并执行连接的动作序列，对象可以出现在任意位置和配置中。

Method: 提出意图驱动的规划管道，包括：(i)感知到文本的场景编码，(ii)基于操作者意图生成候选移除序列的LLM集合，(iii)强制执行格式和优先约束的LLM验证器，(iv)拒绝幻觉对象的确定性一致性过滤器。

Result: 在200个真实场景和600个操作者提示的评估中，使用完整序列正确性和下一任务正确性指标评估了五个基于LLM的规划器。结果表明，集成验证方法能够可靠地将操作者意图映射到安全、可执行的多机器人计划，同时保持较低的用户工作量。

Conclusion: 提出的集成验证方法能够可靠地将操作者意图映射到安全、可执行的多机器人计划，在保持低用户工作量的同时实现可靠的规划性能。

Abstract: This paper addresses the problem of planning complex manipulation tasks, in
which multiple robots with different end-effectors and capabilities, informed
by computer vision, must plan and execute concatenated sequences of actions on
a variety of objects that can appear in arbitrary positions and configurations
in unstructured scenes. We propose an intent-driven planning pipeline which can
robustly construct such action sequences with varying degrees of supervisory
input from a human using simple language instructions. The pipeline integrates:
(i) perception-to-text scene encoding, (ii) an ensemble of large language
models (LLMs) that generate candidate removal sequences based on the operator's
intent, (iii) an LLM-based verifier that enforces formatting and precedence
constraints, and (iv) a deterministic consistency filter that rejects
hallucinated objects. The pipeline is evaluated on an example task in which two
robot arms work collaboratively to dismantle an Electric Vehicle battery for
recycling applications. A variety of components must be grasped and removed in
specific sequences, determined by human instructions and/or by task-order
feasibility decisions made by the autonomous system. On 200 real scenes with
600 operator prompts across five component classes, we used metrics of
full-sequence correctness and next-task correctness to evaluate and compare
five LLM-based planners (including ablation analyses of pipeline components).
We also evaluated the LLM-based human interface in terms of time to execution
and NASA TLX with human participant experiments. Results indicate that our
ensemble-with-verification approach reliably maps operator intent to safe,
executable multi-robot plans while maintaining low user effort.

</details>


### [167] [Learned Inertial Odometry for Cycling Based on Mixture of Experts Algorithm](https://arxiv.org/abs/2510.17604)
*Hao Qiao,Yan Wang,Shuo Yang,Xiaoyao Yu,Jian kuang,Xiaoji Niu*

Main category: cs.RO

TL;DR: 本文提出了一种改进的混合专家模型，用于自行车定位，在保持与现有方法相当精度的同时，显著减少了参数数量和计算成本。


<details>
  <summary>Details</summary>
Motivation: 随着共享单车和多样化骑行应用的快速发展，精确的自行车定位变得至关重要。传统GNSS方法存在多路径效应问题，而现有惯性导航方法依赖精确建模且鲁棒性有限。TLIO方法虽然能实现低位置漂移，但计算成本高，难以在移动设备上部署。

Method: 将TLIO扩展到自行车定位，并引入改进的混合专家模型，该模型通过减少训练和推理成本来优化性能。

Result: 实验表明，与最先进的LLIO框架相比，该方法在保持相当精度的同时，参数减少了64.7%，计算成本降低了81.8%。

Conclusion: 提出的改进混合专家模型在自行车定位中实现了高效性能，显著降低了计算资源需求，适合在移动设备上部署。

Abstract: With the rapid growth of bike sharing and the increasing diversity of cycling
applications, accurate bicycle localization has become essential. traditional
GNSS-based methods suffer from multipath effects, while existing inertial
navigation approaches rely on precise modeling and show limited robustness.
Tight Learned Inertial Odometry (TLIO) achieves low position drift by combining
raw IMU data with predicted displacements by neural networks, but its high
computational cost restricts deployment on mobile devices. To overcome this, we
extend TLIO to bicycle localization and introduce an improved Mixture-of
Experts (MoE) model that reduces both training and inference costs. Experiments
show that, compared to the state-of-the-art LLIO framework, our method achieves
comparable accuracy while reducing parameters by 64.7% and computational cost
by 81.8%.

</details>


### [168] [RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation](https://arxiv.org/abs/2510.17640)
*Yuquan Xue,Guanxing Lu,Zhenyu Wu,Chuanrui Zhang,Bofang Jia,Zhengyi Gu,Yansong Tang,Ziwei Wang*

Main category: cs.RO

TL;DR: 提出RESample框架，通过探索性采样自动增强视觉-语言-动作模型的OOD数据，提高模型在分布偏移状态下的鲁棒性和恢复能力


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习数据集仅包含成功轨迹，缺乏失败和恢复数据，导致VLA模型在处理偏离训练分布的OOD状态时表现不佳

Method: 利用离线强化学习获取动作价值网络识别次优动作，通过rollout采样潜在OOD状态，设计探索性采样机制将动作代理自适应纳入训练数据集

Result: 在LIBERO基准测试和真实机器人操作任务中，RESample持续提升了VLA模型的稳定性和泛化能力

Conclusion: RESample框架有效增强了VLA模型从OOD状态恢复的能力，提高了对分布偏移的鲁棒性

Abstract: Vision-Language-Action models (VLAs) have demonstrated remarkable performance
on complex robotic manipulation tasks through imitation learning. However,
existing imitation learning datasets contain only successful trajectories and
lack failure or recovery data, especially for out-of-distribution (OOD) states
where the robot deviates from the main policy due to minor perturbations or
errors, leading VLA models to struggle with states deviating from the training
distribution. To this end, we propose an automated OOD data augmentation
framework named RESample through exploratory sampling. Specifically, we first
leverage offline reinforcement learning to obtain an action-value network that
accurately identifies sub-optimal actions under the current manipulation
policy. We further sample potential OOD states from trajectories via rollout,
and design an exploratory sampling mechanism that adaptively incorporates these
action proxies into the training dataset to ensure efficiency. Subsequently,
our framework explicitly encourages the VLAs to recover from OOD states and
enhances their robustness against distributional shifts. We conduct extensive
experiments on the LIBERO benchmark as well as real-world robotic manipulation
tasks, demonstrating that RESample consistently improves the stability and
generalization ability of VLA models.

</details>


### [169] [Botany-Bot: Digital Twin Monitoring of Occluded and Underleaf Plant Structures with Gaussian Splats](https://arxiv.org/abs/2510.17783)
*Simeon Adebola,Chung Min Kim,Justin Kerr,Shuangyu Xie,Prithvi Akella,Jose Luis Susa Rincon,Eugen Solowjow,Ken Goldberg*

Main category: cs.RO

TL;DR: Botany-Bot系统使用立体相机、数字转台、工业机器人臂和3D分割高斯泼溅模型，为活体植物构建详细的"注释数字孪生"，并通过机器人算法操纵叶片来拍摄被遮挡细节的高分辨率图像。


<details>
  <summary>Details</summary>
Motivation: 商业植物表型系统使用固定相机无法感知许多植物细节，因为叶片遮挡问题严重。

Method: 使用两个立体相机、数字转台、工业机器人臂和3D分割高斯泼溅模型构建系统，开发机器人算法来操纵叶片拍摄被遮挡区域的高分辨率图像。

Result: 实验结果显示：叶片分割准确率90.8%，叶片检测准确率86.2%，叶片抬起/推动准确率77.9%，拍摄叶片正反面细节图像准确率77.3%。

Conclusion: Botany-Bot系统能够有效解决叶片遮挡问题，成功构建植物的详细数字孪生模型，并提供代码、视频和数据集供研究使用。

Abstract: Commercial plant phenotyping systems using fixed cameras cannot perceive many
plant details due to leaf occlusion. In this paper, we present Botany-Bot, a
system for building detailed "annotated digital twins" of living plants using
two stereo cameras, a digital turntable inside a lightbox, an industrial robot
arm, and 3D segmentated Gaussian Splat models. We also present robot algorithms
for manipulating leaves to take high-resolution indexable images of occluded
details such as stem buds and the underside/topside of leaves. Results from
experiments suggest that Botany-Bot can segment leaves with 90.8% accuracy,
detect leaves with 86.2% accuracy, lift/push leaves with 77.9% accuracy, and
take detailed overside/underside images with 77.3% accuracy. Code, videos, and
datasets are available at https://berkeleyautomation.github.io/Botany-Bot/.

</details>


### [170] [SoftMimic: Learning Compliant Whole-body Control from Examples](https://arxiv.org/abs/2510.17792)
*Gabriel B. Margolis,Michelle Wang,Nolan Fey,Pulkit Agrawal*

Main category: cs.RO

TL;DR: SoftMimic是一个从示例动作学习人形机器人柔顺全身控制策略的框架，通过奖励匹配柔顺响应而非刚性跟踪参考动作，使机器人能够顺从地响应外力同时保持平衡和姿态。


<details>
  <summary>Details</summary>
Motivation: 现有方法激励僵硬控制，当机器人遇到意外接触时会导致脆弱和不安全的行为，需要一种能够柔顺响应外力的控制方法。

Method: 利用逆运动学求解器生成可行的柔顺动作增强数据集，训练强化学习策略，奖励策略匹配柔顺响应而非刚性跟踪参考动作。

Result: 通过仿真和真实世界实验验证，展示了与环境的安���有效交互，能够吸收干扰并从单个动作片段泛化到各种任务。

Conclusion: SoftMimic能够学习柔顺的全身控制策略，使机器人能够安全有效地与环境交互，同时保持平衡和姿态。

Abstract: We introduce SoftMimic, a framework for learning compliant whole-body control
policies for humanoid robots from example motions. Imitating human motions with
reinforcement learning allows humanoids to quickly learn new skills, but
existing methods incentivize stiff control that aggressively corrects
deviations from a reference motion, leading to brittle and unsafe behavior when
the robot encounters unexpected contacts. In contrast, SoftMimic enables robots
to respond compliantly to external forces while maintaining balance and
posture. Our approach leverages an inverse kinematics solver to generate an
augmented dataset of feasible compliant motions, which we use to train a
reinforcement learning policy. By rewarding the policy for matching compliant
responses rather than rigidly tracking the reference motion, SoftMimic learns
to absorb disturbances and generalize to varied tasks from a single motion
clip. We validate our method through simulations and real-world experiments,
demonstrating safe and effective interaction with the environment.

</details>


### [171] [Robobench: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models as Embodied Brain](https://arxiv.org/abs/2510.17801)
*Yulin Luo,Chun-Kai Fan,Menghang Dong,Jiayu Shi,Mengdi Zhao,Bo-Wen Zhang,Cheng Chi,Jiaming Liu,Gaole Dai,Rongyu Zhang,Ruichuan An,Kun Wu,Zhengping Che,Shaoxuan Xie,Guocai Yao,Zhongxia Zhao,Pengwei Wang,Guang Liu,Zhongyuan Wang,Tiejun Huang,Shanghang Zhang*

Main category: cs.RO

TL;DR: 提出了RoboBench基准测试，系统评估多模态大语言模型作为具身大脑在机器人操作任务中的认知能力，涵盖5个维度、14种能力、25个任务和6092个问答对。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注执行成功率，或在高层次推理方面存在维度不完整和任务真实性有限的问题，无法全面评估认知能力。需要系统评估具身大脑在完整操作流程中的关键作用。

Method: 构建RoboBench基准测试，定义5个维度：指令理解、感知推理、泛化规划、功能预测和失败分析。使用多样化具身系统、属性丰富的物体和多视角场景的真实机器人数据。为规划评估引入MLLM-as-world-simulator框架，通过模拟预测计划是否能实现关键物体状态变化来评估具身可行性。

Result: 对14个MLLM的实验揭示了基本局限性：在隐式指令理解、时空推理、跨场景规划、细粒度功能理解和执行失败诊断方面存在困难。

Conclusion: RoboBench为量化高层次认知提供了全面框架，可指导下一代具身MLLM的开发。

Abstract: Building robots that can perceive, reason, and act in dynamic, unstructured
environments remains a core challenge. Recent embodied systems often adopt a
dual-system paradigm, where System 2 handles high-level reasoning while System
1 executes low-level control. In this work, we refer to System 2 as the
embodied brain, emphasizing its role as the cognitive core for reasoning and
decision-making in manipulation tasks. Given this role, systematic evaluation
of the embodied brain is essential. Yet existing benchmarks emphasize execution
success, or when targeting high-level reasoning, suffer from incomplete
dimensions and limited task realism, offering only a partial picture of
cognitive capability. To bridge this gap, we introduce RoboBench, a benchmark
that systematically evaluates multimodal large language models (MLLMs) as
embodied brains. Motivated by the critical roles across the full manipulation
pipeline, RoboBench defines five dimensions-instruction comprehension,
perception reasoning, generalized planning, affordance prediction, and failure
analysis-spanning 14 capabilities, 25 tasks, and 6092 QA pairs. To ensure
realism, we curate datasets across diverse embodiments, attribute-rich objects,
and multi-view scenes, drawing from large-scale real robotic data. For
planning, RoboBench introduces an evaluation framework,
MLLM-as-world-simulator. It evaluate embodied feasibility by simulating whether
predicted plans can achieve critical object-state changes. Experiments on 14
MLLMs reveal fundamental limitations: difficulties with implicit instruction
comprehension, spatiotemporal reasoning, cross-scenario planning, fine-grained
affordance understanding, and execution failure diagnosis. RoboBench provides a
comprehensive scaffold to quantify high-level cognition, and guide the
development of next-generation embodied MLLMs. The project page is in
https://robo-bench.github.io.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [172] [Proactive and Fair Epidemic Resource Allocation Through an Integrated Supply Chain Framework: Insights from a COVID-19 Study](https://arxiv.org/abs/2510.16969)
*Kimiya Jozani,Nihal A. Sageer,Hode Eldardiry,Sait Tunc,Esra Buyuktahtakin Toy*

Main category: cs.SI

TL;DR: 提出了一个结合流行病学和疫苗供应链优化的新框架，通过多目标Gini模型和背包模型，在考虑区域公平性的同时优化疫苗分配，可显著减少感染和死亡人数。


<details>
  <summary>Details</summary>
Motivation: 现有方法将流行病预测与物流规划分离，阻碍了适应性和区域响应性干预。需要整合疾病动态、疫苗分配、区域差异和行为响应的综合模型。

Method: 开发了一个流行病学-优化框架，联合建模疫情进展和多尺度疫苗供应链。采用时空变化的有效感染率反映区域政策和行为动态，设计了两种可扩展的启发式分解算法。

Result: 使用美国COVID-19数据验证，在6个月内可预防超过200万感染和3万死亡，显著提高服务不足地区的疫苗可及性。

Conclusion: 整合公平性、流行病动态和疫苗物流相比传统短视政策能带来更优结果，公平性通过优先考虑最脆弱人群在长期内提高整体效率。

Abstract: Timely and effective decision-making is critical during epidemics to reduce
preventable infections and deaths. This demands integrated models that jointly
capture disease dynamics, vaccine distribution, regional disparities, and
behavioral responses. However, most existing approaches decouple epidemic
forecasting from logistics planning, hindering adaptive and regionally
responsive interventions. We propose a novel epidemiological-optimization
framework that jointly models epidemic progression and a multiscale vaccine
supply chain. The model incorporates spatio-temporally varying effective
infection rates to reflect regional policy and behavioral dynamics. It supports
coordinated, data-driven decision-making across spatial scales through two
formulations: a multi-objective Gini-based model and a knapsack-based model
that leverages regional vulnerability indicators for tractability and improved
mitigation. To address computational complexity, we design two scalable
heuristic decomposition algorithms inspired by the Benders decomposition. The
model is validated using COVID-19 data in the U.S.. We introduce SARIMA-based
forecasting as a novel approach for validating epidemic-optimization models
under data limitations. The results show that our approach can prevent more
than 2 million infections and 30,000 deaths in just six months while
significantly improving the accessibility of vaccines in underserved regions.
Our framework demonstrates that integrating fairness and epidemic dynamics with
vaccine logistics leads to superior outcomes compared to traditional myopic
policies. Fairness improves overall efficiency in the long term by prioritizing
the most vulnerable populations, leading to better long-term public health
outcomes. The model offers policymakers a scalable and operationally relevant
tool to strengthen preparedness and ensure a more effective and equitable
response to epidemics.

</details>


### [173] [HyperSearch: Prediction of New Hyperedges through Unconstrained yet Efficient Search](https://arxiv.org/abs/2510.17153)
*Hyunjin Choo,Fanchen Bu,Hyunjin Hwang,Young-Gyu Yoon,Kijung Shin*

Main category: cs.SI

TL;DR: 提出了HyperSearch算法，用于高效预测超图中的超边，通过结合经验性评分函数和高效搜索机制，在10个真实世界超图上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 超边预测在复杂系统中应用广泛，但巨大的搜索空间使得穷举搜索不可行，现有方法依赖启发式采样或无根据的结构假设。

Method: 提出HyperSearch算法，包含：(1)基于真实超图观察的经验性评分函数；(2)使用原始评分函数的反单调上界进行剪枝的高效搜索机制。

Result: 在5个领域的10个真实世界超图上，HyperSearch始终优于最先进的基线方法，在预测新超边方面达到更高准确率。

Conclusion: HyperSearch通过理论保证的剪枝策略和实证基础评分函数，有效解决了超边预测中的计算挑战，显著提升了预测性能。

Abstract: Higher-order interactions (HOIs) in complex systems, such as scientific
collaborations, multi-protein complexes, and multi-user communications, are
commonly modeled as hypergraphs, where each hyperedge (i.e., a subset of nodes)
represents an HOI among the nodes. Given a hypergraph, hyperedge prediction
aims to identify hyperedges that are either missing or likely to form in the
future, and it has broad applications, including recommending interest-based
social groups, predicting collaborations, and uncovering functional complexes
in biological systems. However, the vast search space of hyperedge candidates
(i.e., all possible subsets of nodes) poses a significant computational
challenge, making naive exhaustive search infeasible. As a result, existing
approaches rely on either heuristic sampling to obtain constrained candidate
sets or ungrounded assumptions on hypergraph structure to select promising
hyperedges.
  In this work, we propose HyperSearch, a search-based algorithm for hyperedge
prediction that efficiently evaluates unconstrained candidate sets, by
incorporating two key components: (1) an empirically grounded scoring function
derived from observations in real-world hypergraphs and (2) an efficient search
mechanism, where we derive and use an anti-monotonic upper bound of the
original scoring function (which is not antimonotonic) to prune the search
space. This pruning comes with theoretical guarantees, ensuring that discarded
candidates are never better than the kept ones w.r.t. the original scoring
function. In extensive experiments on 10 real-world hypergraphs across five
domains, HyperSearch consistently outperforms state-of-the-art baselines,
achieving higher accuracy in predicting new (i.e., not in the training set)
hyperedges.

</details>


### [174] [Opinion Maximization in Social Networks by Modifying Internal Opinions](https://arxiv.org/abs/2510.17226)
*Gengyu Wang,Runze Zhang,Zhongzhi Zhang*

Main category: cs.SI

TL;DR: 提出高效算法解决社交网络中最大化整体意见的问题，通过修改关键节点的内部意见，相比传统矩阵求逆方法显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 社交网络中的舆论治理对公共卫生运动、政治选举和商业营销至关重要，但传统矩阵求逆方法计算成本过高，需要开发更高效的解决方案。

Method: 提出了两种基于采样的高效算法，以及一种确定性异步算法，通过异步更新操作和渐进式精化来精确识别最优节点集。

Result: 在真实数据集上的广泛实验表明，所提方法优于基线方法，异步算法在所有场景下都表现出卓越的效率和准确性，即使在包含数千万节点的网络中。

Conclusion: 开发的异步算法能够高效且精确地解决大规模社交网络中的意见最大化问题，为实际应用提供了可行的解决方案。

Abstract: Public opinion governance in social networks is critical for public health
campaigns, political elections, and commercial marketing. In this paper, we
addresse the problem of maximizing overall opinion in social networks by
strategically modifying the internal opinions of key nodes. Traditional matrix
inversion methods suffer from prohibitively high computational costs, prompting
us to propose two efficient sampling-based algorithms. Furthermore, we develop
a deterministic asynchronous algorithm that exactly identifies the optimal set
of nodes through asynchronous update operations and progressive refinement,
ensuring both efficiency and precision. Extensive experiments on real-world
datasets demonstrate that our methods outperform baseline approaches. Notably,
our asynchronous algorithm delivers exceptional efficiency and accuracy across
all scenarios, even in networks with tens of millions of nodes.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [175] [A Motivational Driver Steering Model: Task Difficulty Homeostasis From Control Theory Perspective](https://arxiv.org/abs/2510.16247)
*H. Mozaffari,A. Nahvi*

Main category: eess.SY

TL;DR: 结合心理学任务难度稳态理论和控制论Lyapunov稳定性方法，提出了一种统一的心理合理碰撞避免驾驶员模型，在20-170km/h速度范围内验证了其准确性。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶员模型大多仅基于控制理论，缺乏心理学理论基础，需要开发既符合心理机制又实用的碰撞避免模型。

Method: 将心理学中的任务难度稳态理论与控制论中的Lyapunov稳定性方法相结合，建立统一框架来建模驾驶员转向避撞行为。

Result: 在驾驶模拟器上进行实验验证，模型在多种避撞场景中准确模拟人类行为，平均误差仅为7%。

Conclusion: 该模型成功整合了心理学和控制理论，提供了一种通用且心理合理的驾驶员避撞行为建模方法。

Abstract: A general and psychologically plausible collision avoidance driver model can
improve transportation safety significantly. Most computational driver models
found in the literature have used control theory methods only, and they are not
established based on psychological theories. In this paper, a unified approach
is presented based on concepts taken from psychology and control theory. The
"task difficulty homeostasis theory", a prominent motivational theory, is
combined with the "Lyapunov stability method" in control theory to present a
general and psychologically plausible model. This approach is used to model
driver steering behavior for collision avoidance. The performance of this model
is measured by simulation of two collision avoidance scenarios at a wide range
of speeds from 20 km/h to 170 km/h. The model is validated by experiments on a
driving simulator. The results demonstrate that the model follows human
behavior accurately with a mean error of 7 percent.

</details>


### [176] [Spatial-to-Spectral Harmonic-Modulated Arrays for 6G Multi-Beam MIMO](https://arxiv.org/abs/2510.16262)
*Jose Guajardo,Ali Niknejad*

Main category: eess.SY

TL;DR: 本文介绍了空间-频谱谐波调制阵列(SHAs)，这是一种能够实现并发多波束成形而无需大量硬件复制的阵列技术，通过频域复用替代硬件复制，有望成为6G网络的关键技术。


<details>
  <summary>Details</summary>
Motivation: 传统模拟或数字波束成形阵列需要大量硬件复制来实现多波束成形，SHAs旨在通过频域复用技术解决这一问题，为未来6G网络提供可扩展的多用户通信、联合通信与感知以及空间干扰抑制能力。

Method: 提出了谐波调制波形分析及其对增益、噪声和带宽的影响，设计了最小化频谱低效的梳状调制波形，分析了SHAs独立控制多波束的能力，并引入了具有三个空间-频谱自由度的新型SHA架构。

Result: SHAs能够实现并发多波束成形而无需大量硬件复制，通过频域复用技术有效工作，提出的新型SHA架构以最小硬件复制提供三个空间-频谱自由度。

Conclusion: SHAs作为一种有前景的技术，通过空间-频谱谐波调制实现了高效的多波束成形，为未来6G网络的通信和感知应用提供了重要技术基础。

Abstract: This article presents an overview and analysis of spatial-to-spectral
harmonic-modulated arrays (SHAs). Compared to traditional analog or digital
beamforming arrays, SHAs enable concurrent multi-beamforming without requiring
substantial hardware replication. SHAs replace the need for hardware
replication with frequency-domain multiplexing. Furthermore, SHAs have the
potential to become key contributors to future 6G networks by enabling scalable
multi-user communications, joint communication and sensing, and spatial
interference mitigation. In addition, an analysis of the SHA's
harmonic-modulation waveform and its effects on gain, noise and bandwidth is
presented. A comb-like modulation waveform for SHAs that minimizes spectral
inefficiency is proposed. Further, an analysis of the SHA's capability to
independently steer multiple beams is presented. This capability is quantified
in terms of the SHA's spatial-to-spectral degrees of freedom. Lastly, this work
introduces a novel SHA architecture that provides three spatial-to-spectral
degrees of freedom with minimal hardware replication.

</details>


### [177] [Towards Smart Manufacturing Metaverse via Digital Twinning in Extended Reality](https://arxiv.org/abs/2510.16280)
*Hui Yang,Faisal Aqlan,Richard Zhao*

Main category: eess.SY

TL;DR: 本文探讨了制造业元宇宙(MfgVerse)的发展，重点关注人工智能、数字孪生和扩展现实等新兴技术在制造业中的应用，以及如何通过人本制造元宇宙解决制造业数字素养人才短缺问题。


<details>
  <summary>Details</summary>
Motivation: 制造业面临数字素养人才严重短缺的挑战，全球疫情改变了工作方式，迫切需要重新思考数字化平台化，利用新兴技术推动工业向人本制造元宇宙演进。

Method: 提出智能制造业元宇宙的前瞻视角，展示学习工厂、认知数字孪生和制造即服务(MaaS)共享经济等当前努力，构建包括人类利益相关者、制造实体、数字孪生和辅助系统的多重网络。

Result: 开发了用于扩展现实劳动力培训的学习工厂，展示了制造业元宇宙在多重网络融合方面的进展。

Conclusion: 讨论了人本制造元宇宙的未来方向、挑战和机遇，希望激发更全面的研究和深入的技术发展来推进MfgVerse技术。

Abstract: The rapid evolution of modern manufacturing systems is driven by the
integration of emerging metaverse technologies such as artificial intelligence
(AI), digital twin (DT) with different forms of extended reality (XR) like
virtual reality (VR), augmented reality (AR), and mixed reality (MR). These
advances confront manufacturing workers with complex and evolving environments
that demand digital literacy for problem solving in the future workplace.
However, manufacturing industry faces a critical shortage of skilled workforce
with digital literacy in the world. Further, global pandemic has significantly
changed how people work and collaborate digitally and remotely. There is an
urgent need to rethink digital platformization and leverage emerging
technologies to propel industrial evolution toward human-centered manufacturing
metaverse (MfgVerse). This paper presents a forward-looking perspective on the
development of smart MfgVerse, highlighting current efforts in learning
factory, cognitive digital twinning, and the new sharing economy of
manufacturing-as-a-service (MaaS). MfgVerse is converging into multiplex
networks, including a social network of human stakeholders, an interconnected
network of manufacturing things or agents (e.g., machines, robots, facilities,
material handling systems), a network of digital twins of physical things, as
well as auxiliary networks of sales, supply chain, logistics, and
remanufacturing systems. We also showcase the design and development of a
learning factory for workforce training in extended reality. Finally, future
directions, challenges, and opportunities are discussed for human-centered
manufacturing metaverse. We hope this work helps stimulate more comprehensive
studies and in-depth research efforts to advance MfgVerse technologies.

</details>


### [178] [AC Dynamics-aware Trajectory Optimization with Binary Enforcement for Adaptive UFLS Design](https://arxiv.org/abs/2510.16297)
*Muhammad Hamza Ali,Amritanshu Pandey*

Main category: eess.SY

TL;DR: 提出了一种基于轨迹优化的自适应低频减载方案，考虑完整的交流非线性网络动态，通过松弛二进制变量和同伦方法解决MINLP问题，在大规模系统上实现有效的频率控制。


<details>
  <summary>Details</summary>
Motivation: 分布式能源的高渗透率导致传统低频减载方案失效，现有自适应方法无法捕捉交流非线性网络行为，导致继电器在严重扰动时无法恢复系统频率。

Method: 将自适应UFLS问题建模为轨迹优化，包含完整的交流非线性网络动态，通过松弛二进制变量为连续代理变量，将MINLP问题转化为NLP序列，使用同伦驱动方法求解近整数可行解。

Result: 在多个合成输电系统上验证，框架可扩展到1500+节点、17万+连续变量和7.3万+二进制变量的网络，成功恢复二进制可行解并在最坏扰动下阻止频率下降。

Conclusion: 所提出的框架能够有效处理大规模系统的自适应低频减载问题，确保交流可行性和时间协调控制，在严重扰动下保持系统频率稳定。

Abstract: The high penetration of distributed energy resources, resulting in backfeed
of power at the transmission and distribution interface, is causing
conventional underfrequency load shedding (UFLS) schemes to become
nonconforming. Adaptive schemes that update UFLS relay settings recursively in
time offer a solution, but existing adaptive techniques that obtain UFLS relay
settings with linearized or reduced-order model formulations fail to capture AC
nonlinear network behavior. In practice, this will result in relays unable to
restore system frequency during adverse disturbances. We formulate an adaptive
UFLS problem as a trajectory optimization and include the full AC nonlinear
network dynamics to ensure AC feasibility and time-coordinated control actions.
We include binary decisions to model relay switching action and time-delayed
multi-stage load-shedding. However, this formulation results in an intractable
MINLP problem. To enforce model tractability, we relax these binary variables
into continuous surrogates and reformulate the MINLP as a sequence of NLPs. We
solve the NLPs with a homotopy-driven method that enforces
near-integer-feasible solutions. We evaluate the framework on multiple
synthetic transmission systems and demonstrate that it scales efficiently to
networks exceeding 1500+ nodes with over 170k+ continuous and 73k+ binary
decision variables, while successfully recovering binary-feasible solutions
that arrest the frequency decline during worst-case disturbance.

</details>


### [179] [Supervisory Control of Hybrid Power Plants Using Online Feedback Optimization: Designs and Validations with a Hybrid Co-Simulation Engine](https://arxiv.org/abs/2510.16352)
*Sayak Mukherjee,Himanshu Sharma,Wenceslao Shaw Cortez,Genevieve Starke,Michael Sinner,Brooke J. Stanislawski,Zachary Tully,Paul Fleming,Sonja Glavaski*

Main category: eess.SY

TL;DR: 设计混合发电厂的监督反馈控制器，协调风电、光伏和电池储能系统以满足电网功率需求，使用基于梯度的反馈优化方法，无需精确模型知识。


<details>
  <summary>Details</summary>
Motivation: 混合发电厂需要协调多种可再生能源和储能系统来满足电网功率需求，传统方法需要精确模型，而实际运行中存在天气等不确定性因素。

Method: 采用在线反馈优化控制设计，利用成本和输出相对于控制输入的梯度信息来更新控制命令，调整风电、光伏和储能的功率参考值。

Result: 提出的监督控制方法已集成到混合发电厂联合仿真引擎Hercules中，在更真实的仿真场景中证明了其有效性。

Conclusion: 反馈优化方法能够在不依赖详细模型的情况下实现混合发电厂的鲁棒控制，有效应对天气不确定性，满足电网功率需求。

Abstract: This research investigates designing a supervisory feedback controller for a
hybrid power plant that coordinates the wind, solar, and battery energy storage
plants to meet the desired power demands. We have explored an online feedback
control design that does not require detailed knowledge about the models, known
as feedback optimization. The control inputs are updated using the gradient
information of the cost and the outputs with respect to the input control
commands. This enables us to adjust the active power references of wind, solar,
and storage plants to meet the power generation requirements set by grid
operators. The methodology also ensures robust control performance in the
presence of uncertainties in the weather. In this paper, we focus on describing
the supervisory feedback optimization formulation and control-oriented modeling
for individual renewable and storage components of the hybrid power plant. The
proposed supervisory control has been integrated with the hybrid plant
co-simulation engine, Hercules, demonstrating its effectiveness in more
realistic simulation scenarios.

</details>


### [180] [Real-time Measurement-based Optimization for Distribution System Operation Considering Battery Voltage and Thermal Constraints](https://arxiv.org/abs/2510.16408)
*Sen Zhan,Lingkang Jin,Haoyang Zhang,Nikolaos G. Paterakis*

Main category: eess.SY

TL;DR: 提出了一种基于实时测量的数据驱动电池储能运行控制方案，使用Lyapunov优化实现实时、无需预测的控制策略，确保配电系统安全运行和电池电压、热约束满足。


<details>
  <summary>Details</summary>
Motivation: 配电系统安全运行面临分布式能源集成挑战，电池储能灵活性是比发电削减更经济的替代方案，但传统运行模型受限于不准确的电网模型、负荷数据不可得、非线性关系、时间约束和复杂电化学热动力学等问题。

Method: 基于实时配电系统和电池储能测量构建线性和凸二次运行约束，使用Lyapunov优化解耦多时段电池运行，实现低计算复杂度的实时、无需预测控制策略。

Result: 使用非线性配电系统和电池储能模拟器的数值研究验证了该方法在确保配电系统安全运行和满足电池电压、热约束方面的有效性。

Conclusion: 所提出的数据驱动控制方案能够有效解决电池储能在配电系统中的运行控制问题，无需精确电网模型和负荷预测，具有实际应用价值。

Abstract: The secure operation of power distribution systems is challenged by the
growing integration of distributed energy resources. Leveraging the flexibility
of battery storage offers a cost-effective alternative to measures like
generation curtailment, which results in energy losses. However, developing an
effective operational model for battery storage is hindered by inaccurate grid
models, unavailability of load data, nonlinear relationship between power
injections and network states, intertemporal constraints, and complex
electrochemical and thermal dynamics. To address these challenges, this paper
proposes a data-driven operational control scheme for battery storage in
distribution systems. Linear and convex quadratic operational constraints are
constructed based on real-time distribution system and battery storage
measurements. Lyapunov optimization decouples multi-period battery operation,
enabling a real-time, forecast-free control strategy with low computational
complexity. Numerical studies using nonlinear distribution system and battery
storage simulators validate the effectiveness of the approach in ensuring
secure distribution system operation and satisfaction of voltage and thermal
constraints of battery storage.

</details>


### [181] [AoI-Aware Task Offloading and Transmission Optimization for Industrial IoT Networks: A Branching Deep Reinforcement Learning Approach](https://arxiv.org/abs/2510.16414)
*Yuang Chen,Fengqian Guo,Chang Wu,Shuyi Liu,Hancheng Lu,Chang Wen Chen*

Main category: eess.SY

TL;DR: 提出了一种基于AoI的多基站实时监控框架，通过分支D3QN算法和资源分配优化，显著降低了工业物联网系统的长期平均信息年龄。


<details>
  <summary>Details</summary>
Motivation: 工业物联网中大量数据的无线传输需要满足严格的实时性要求，数据包状态更新的新鲜度对系统性能有重要影响。

Method: 提出分支D3QN算法实现任务卸载，将动作空间复杂度从指数级降至线性级；通过证明Hessian矩阵的半正定性，提出带宽和计算资源的高效分配方案；设计迭代优化算法实现联合任务卸载与资源分配。

Result: 分支D3QN算法在收敛速度上提升75%，长期平均AoI降低至少22%，优于现有DRL方法和经典启发式算法。

Conclusion: 所提出的联合优化框架能有效满足工业物联网的实时性需求，显著提升系统性能。

Abstract: In the Industrial Internet of Things (IIoT), the frequent transmission of
large amounts of data over wireless networks should meet the stringent
timeliness requirements. Particularly, the freshness of packet status updates
has a significant impact on the system performance. In this paper, we propose
an age-of-information (AoI)-aware multi-base station (BS) real-time monitoring
framework to support extensive IIoT deployments. To meet the freshness
requirements of IIoT, we formulate a joint task offloading and resource
allocation optimization problem with the goal of minimizing long-term average
AoI. Tackling the core challenges of combinatorial explosion in multi-BS
decision spaces and the stochastic dynamics of IIoT systems is crucial, as
these factors render traditional optimization methods intractable. Firstly, an
innovative branching-based Dueling Double Deep Q-Network (Branching-D3QN)
algorithm is proposed to effectively implement task offloading, which optimizes
the convergence performance by reducing the action space complexity from
exponential to linear levels. Then, an efficient optimization solution to
resource allocation is proposed by proving the semi-definite property of the
Hessian matrix of bandwidth and computation resources. Finally, we propose an
iterative optimization algorithm for efficient joint task offloading and
resource allocation to achieve optimal average AoI performance. Extensive
simulations demonstrate that our proposed Branching-D3QN algorithm outperforms
both state-of-the-art DRL methods and classical heuristics, achieving up to a
75% enhanced convergence speed and at least a 22% reduction in the long-term
average AoI.

</details>


### [182] [Stabilization of Nonlinear Systems with State-Dependent Representation: From Model-Based to Direct Data-Driven Control](https://arxiv.org/abs/2510.16451)
*Lidong Li,Rui Huang,Lin Zhao*

Main category: eess.SY

TL;DR: 提出了一种稳定状态依赖非线性系统的新框架，通过状态依赖参数变化模型和LMI合成控制器，保证局部指数稳定性、鲁棒性和吸引域估计，并扩展到数据驱动场景。


<details>
  <summary>Details</summary>
Motivation: 传统非线性系统稳定方法需要精确模型，而实际系统往往存在模型不确定性和噪声数据，需要直接从有限数据中获得稳定性保证。

Method: 将非线性系统重构为状态依赖参数变化模型，离线合成LMI控制器；扩展到数据驱动设置，利用Petersen引理推导数据依赖LMI，确保与数据兼容的所有系统的稳定性和鲁棒性。

Result: 数值和物理实验验证了该方法能够直接从有限数据中获得严格的端到端稳定性、鲁棒性和安全性保证，无需显式模型辨识。

Conclusion: 该框架为非线性系统稳定提供了有效的数据驱动解决方案，在模型不确定和数据噪声情况下仍能保证系统性能。

Abstract: This paper presents a novel framework for stabilizing nonlinear systems
represented in state-dependent form. We first reformulate the nonlinear
dynamics as a state-dependent parameter-varying model and synthesize a
stabilizing controller offline via tractable linear matrix inequalities (LMIs).
The resulting controller guarantees local exponential stability, maintains
robustness against disturbances, and provides an estimate of the region of
attraction under input saturation. We then extend the formulation to the direct
data-driven setting, where a known library of basis functions represents the
dynamics with unknown coefficients consistent with noisy experimental data. By
leveraging Petersen's lemma, we derive data-dependent LMIs that ensure
stability and robustness for all systems compatible with the data. Numerical
and physical experimental results validate that our approach achieves rigorous
end-to-end guarantees on stability, robustness, and safety directly from finite
data without explicit model identification.

</details>


### [183] [Admittance Matrix Concentration Inequalities for Understanding Uncertain Power Networks](https://arxiv.org/abs/2510.17798)
*Samuel Talkington,Cameron Khanpour,Rahul K. Gupta,Sergio A. Dorado-Rojas,Daniel Turizo,Hyeongon Park,Dmitrii M. Ostrovskii,Daniel K. Molzahn*

Main category: eess.SY

TL;DR: 提出了在不确定网络参数下，导纳矩阵谱和经典线性潮流模型的概率边界分析方法


<details>
  <summary>Details</summary>
Motivation: 处理电力系统中不确定网络参数（如概率性线路故障）对潮流模型准确性的影响

Method: 采用概率论工具，特别是具有独立条目的随机矩阵的集中不等式

Result: 得到了在参数不确定性下AC潮流方程常见近似（包括DC和LinDistFlow近似）的误差边界

Conclusion: 该方法为电力系统不确定性分析提供了数学严谨的概率边界

Abstract: This paper presents probabilistic bounds for the spectrum of the admittance
matrix and classical linear power flow models under uncertain network
parameters; for example, probabilistic line contingencies. Our proposed
approach imports tools from probability theory, such as concentration
inequalities for random matrices with independent entries. It yields error
bounds for common approximations of the AC power flow equations under parameter
uncertainty, including the DC and LinDistFlow approximations.

</details>


### [184] [Small-Signal Stability Analysis of Power Systems by Implicit Multilinear Models](https://arxiv.org/abs/2510.16534)
*Christoph Kaufmann,Georg Pangalos,Gerwald Lichtenberg,Oriol Gomis-Bellmunt*

Main category: eess.SY

TL;DR: 提出基于隐式多线性模型线性化的小信号稳定性分析方法，使用广义特征值分析平衡点稳定性，相比传统方法在MATLAB Simulink中能更快完成线性化。


<details>
  <summary>Details</summary>
Motivation: 多线性模型能够描述系统动态，并能通过变量变换表示电力系统建模中常见的三角函数，为电网跟随和电网形成功率变换器提供张量表示。

Method: 基于隐式多线性模型的线性化描述符模型计算广义特征值，通过3总线网络案例与非线性模型进行时域仿真和特征值比较验证。

Result: 隐式多线性模型的分解张量表示相比传统方法在MATLAB Simulink中能更快完成线性化，且与时域仿真结果一致。

Conclusion: 该方法为小信号稳定性分析提供了一种高效的替代方案，特别适用于包含三角函数的电力系统建模。

Abstract: This paper proposes a new approach to perform small-signal stability analysis
based on linearization of implicit multilinear models. Multilinear models
describe the system dynamics by multilinear functions of state, input, and
algebraic variables. Using suitable transformations of variables, they can also
represent trigonometric functions, which often occur in power systems modeling.
This allows tensor representations of grid-following and grid-forming power
converters. This paper introduces small-signal stability analysis of
equilibrium points based on implicit multilinear models using generalized
eigenvalues. The generalized eigenvalues are computed from linear descriptor
models of the linearized implicit multilinear model. The proposed approach is
tested using a 3-bus network example, first by comparing time-domain
simulations of the implicit multilinear model with those of the nonlinear
model, and second by comparing the generalized eigenvalues with those of the
linearized nonlinear model. The results show that the decomposed tensor
representation of the implicit multilinear model allows for a faster
linearization compared to conventional methods in MATLAB Simulink.

</details>


### [185] [SMP-RCR: A Sparse Multipoint Moment Matching Method for RC Reduction](https://arxiv.org/abs/2510.16550)
*Siyuan Yin,Yuncheng Xu,Lin Liu,Fan Yang,Xuan Zeng,Chengtao An,Yangfeng Su*

Main category: eess.SY

TL;DR: 提出了一种稀疏多点矩匹配方法，用于多端口RC电路模型降阶，在保持精度的同时显著提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有多端口RC电路模型降阶方法存在局限性：高阶矩匹配方法（如PRIMA、TurboMOR）在端口数多时会产生大型稠密系统，影响效率；而基于高斯消元的方法（如SIP）在高阶矩匹配方面不足。

Method: 提出稀疏多点矩匹配方法，结合稀疏控制和紧缩技术优化算法，提供多频率高阶矩匹配特性的理论分析。

Result: 与SIP相比，在高频点精度提高两个数量级以上，且不增加过多线性组件；与TurboMOR相比，在保持相同精度水平下速度提升两倍以上。

Conclusion: 该方法在精度和效率之间取得了良好平衡，为多端口RC电路的模型降阶提供了有效解决方案。

Abstract: In post--layout circuit simulation, efficient model order reduction (MOR) for
many--port resistor--capacitor (RC) circuits remains a crucial issue. The
current mainstream MOR methods for such circuits include high--order moment
matching methods and elimination methods. High-order moment matching
methods--characterized by high accuracy, such as PRIMA and TurboMOR--tend to
generate large dense reduced-order systems when the number of ports is large,
which impairs the efficiency of MOR. Another common type of MOR method for
many--port circuits is based on Gaussian elimination, with the SIP method as a
representative. The main limitation of this method lies in the inadequate
matching of high--order moments. In this paper, we propose a sparse multipoint
moment matching method and present comprehensive theoretical analysis results
regarding the multi--frequency high--order moment matching property. Meanwhile,
to enhance the algorithm's efficiency, sparse control and deflation techniques
are introduced to further optimize the algorithm. Numerical experiments
demonstrated that, compared to SIP, the accuracy is improved by more than two
orders of magnitude at high frequency points without adding many extra linear
components. Compared to TurboMOR methods, our method achieves a speed
improvement of more than twice while maintaining the same level of precision.

</details>


### [186] [Linear State Estimation in Presence of Bounded Uncertainties: A Comparative Analysis](https://arxiv.org/abs/2510.16693)
*Ayan Das,Anushka Sharma,Anamitra Pal*

Main category: eess.SY

TL;DR: 本文提出三种处理电力系统状态估计中数据和模型不确定性的方法：基于区间算术、凸优化和广义线性分式规划的方法，并在IEEE测试系统上比较了它们的速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注数据不确定性，但对模型不确定性（特别是线路参数变化）的处理较少。由于实际线路参数可能与数据库中的值不同，需要研究在数据和模型都存在有界不确定性时的状态估计方法。

Method: 提出了三种方法：1）基于区间算术的方法；2）基于凸优化的方法；3）基于广义线性分式规划的方法。这些方法用于处理线性状态估计中的数据和模型不确定性。

Result: 前两种方法速度极快且结果符合预期，而第三种方法存在可扩展性问题，不适用于线性状态估计。

Conclusion: 基于区间算术和凸优化的方法在速度和准确性方面表现良好，而广义线性分式规划方法由于可扩展性问题不适合线性状态估计应用。

Abstract: A variety of algorithms have been proposed to address the power system state
estimation problem in the presence of uncertainties in the data. However, less
emphasis has been given to handling perturbations in the model. In the context
of linear state estimation (LSE), which is the focus of this paper,
perturbations in the model come from variations in the line parameters. Since
the actual values of the line parameters can be different from the values
stored in a power utility's database, we investigate three approaches in this
paper to estimate the states in the presence of bounded uncertainties in the
data and the model. The first approach is based on interval arithmetic, the
second is based on convex optimization, and the third is based on generalized
linear fractional programming. The three algorithms are applied to multiple
IEEE test systems and compared in terms of their speed and accuracy. The
results indicate that the first two algorithms are extremely fast and give
expected results, while the third suffers from scalability issues and is
unsuitable for LSE.

</details>


### [187] [A Control-Theoretic Approach to Dynamic Payment Routing for Success Rate Optimization](https://arxiv.org/abs/2510.16735)
*Aniket Agrawal,Harsharanga Patil*

Main category: eess.SY

TL;DR: 提出基于控制理论的动态支付路由框架，通过闭环反馈控制器实时监控网关性能并动态路由交易，结合强化学习和多臂老虎机优化，相比传统规则路由成功率提升1.15%。


<details>
  <summary>Details</summary>
Motivation: 传统支付路由系统缺乏动态适应性，无法实时响应网关性能变化，需要一种能够自我调节、确保操作弹性的智能路由方案。

Method: 采用闭环反馈控制框架，结合控制理论、强化学习和多臂老虎机优化，通过感知网关性能、计算纠正动作、动态路由交易来实现自适应路由。

Result: 生产环境测试显示，相比传统规则路由，成功率提升高达1.15%，证明了反馈控制在支付系统中的有效性。

Conclusion: 控制理论与自适应决策系统的混合方法能够实现自我调节的交易路由，抑制不稳定性并提高可靠性，为支付系统提供了有效的动态路由解决方案。

Abstract: This paper introduces a control-theoretic framework for dynamic payment
routing, implemented within JUSPAY's Payment Orchestrator to maximize
transaction success rate. The routing system is modeled as a closed-loop
feedback controller continuously sensing gateway performance, computing
corrective actions, and dynamically routes transactions across gateway to
ensure operational resilience. The system leverages concepts from control
theory, reinforcement learning, and multi-armed bandit optimization to achieve
both short-term responsiveness and long-term stability. Rather than relying on
explicit PID regulation, the framework applies generalized feedback-based
adaptation, ensuring that corrective actions remain proportional to observed
performance deviations and the computed gateway score gradually converges
toward the success rate. This hybrid approach unifies control theory and
adaptive decision systems, enabling self-regulating transaction routing that
dampens instability, and improves reliability. Live production results show an
improvement of up to 1.15% in success rate over traditional rule-based routing,
demonstrating the effectiveness of feedback-based control in payment systems.

</details>


### [188] [Safe Payload Transfer with Ship-Mounted Cranes: A Robust Model Predictive Control Approach](https://arxiv.org/abs/2510.16953)
*Ersin Das,William A. Welch,Patrick Spieler,Keenan Albee,Aurelio Noca,Jeffrey Edlund,Jonathan Becktor,Thomas Touma,Jessica Todd,Sriramya Bhamidipati,Stella Kombo,Maira Saboia,Anna Sabel,Grace Lim,Rohan Thakker,Amir Rahmani,Joel W. Burdick*

Main category: eess.SY

TL;DR: 提出了一种用于船载起重机的鲁棒安全模型预测控制框架，通过零阶控制屏障函数和时变边界框确保在外部扰动下的安全有效载荷转移。


<details>
  <summary>Details</summary>
Motivation: 船载起重机在恶劣海况下受到显著外部扰动，影响欠驱动起重机动力学，导致鲁棒性问题，需要同时处理多个安全约束并保持有效载荷转移性能。

Method: 使用基于鲁棒零阶控制屏障函数的安全约束在非线性MPC中确保安全载荷定位，使用时变边界框进行碰撞避免，并引入基于优化的在线鲁棒性参数自适应方案。

Result: 在起重机原型上的实验验证了该方法在起重机基础显著扰动运动下的整体性能。

Conclusion: 该方法不仅适用于起重机辅助的转移操作，更广泛地适用于安全的机器人辅助零件配合和零件插入任务。

Abstract: Ensuring safe real-time control of ship-mounted cranes in unstructured
transportation environments requires handling multiple safety constraints while
maintaining effective payload transfer performance. Unlike traditional crane
systems, ship-mounted cranes are consistently subjected to significant external
disturbances affecting underactuated crane dynamics due to the ship's dynamic
motion response to harsh sea conditions, which can lead to robustness issues.
To tackle these challenges, we propose a robust and safe model predictive
control (MPC) framework and demonstrate it on a 5-DOF crane system, where a
Stewart platform simulates the external disturbances that ocean surface motions
would have on the supporting ship. The crane payload transfer operation must
avoid obstacles and accurately place the payload within a designated target
area. We use a robust zero-order control barrier function (R-ZOCBF)-based
safety constraint in the nonlinear MPC to ensure safe payload positioning,
while time-varying bounding boxes are utilized for collision avoidance. We
introduce a new optimization-based online robustness parameter adaptation
scheme to reduce the conservativeness of R-ZOCBFs. Experimental trials on a
crane prototype demonstrate the overall performance of our safe control
approach under significant perturbing motions of the crane base. While our
focus is on crane-facilitated transfer, the methods more generally apply to
safe robotically-assisted parts mating and parts insertion.

</details>


### [189] [Differentiating Through Power Flow Solutions for Admittance and Topology Control](https://arxiv.org/abs/2510.17071)
*Samuel Talkington,Daniel Turizo,Sergio A. Dorado-Rojas,Rahul K. Gupta,Daniel K. Molzahn*

Main category: eess.SY

TL;DR: 该论文提出了一种基于隐函数定理的潮流方程线性化方法，用于分析网络导纳参数变化对系统状态的影响，并展示了在拓扑变化预测和连续导纳控制等应用中的有效性。


<details>
  <summary>Details</summary>
Motivation: 电力系统运行和控制中，网络导纳参数的优化、控制和估计是核心研究问题。传统方法需要反复求解非线性潮流方程，计算成本高。

Method: 利用隐函数定理对潮流方程进行隐式微分，推导出关于网络导纳参数的线性化表达式，适用于辐射状或网状等各种电网结构。

Result: 建立了复电压、线路电流和功率潮流对导纳参数的灵敏度关系，能够在网络拓扑变化时预测节点电压而无需重新求解潮流方程。

Conclusion: 提出的潮流方程线性化理论具有广泛应用价值，特别是在连续导纳控制方面，可用于提高配电网的承载能力。

Abstract: The power flow equations relate bus voltage phasors to power injections via
the network admittance matrix. These equations are central to the key
operational and protection functions of power systems (e.g., optimal power flow
scheduling and control, state estimation, protection, and fault location, among
others). As control, optimization, and estimation of network admittance
parameters are central to multiple avenues of research in electric power
systems, we propose a linearization of power flow solutions obtained by
implicitly differentiating them with respect to the network admittance
parameters. This is achieved by utilizing the implicit function theorem, in
which we show that such a differentiation is guaranteed to exist under mild
conditions and is applicable to generic power systems (radial or meshed). The
proposed theory is applied to derive sensitivities of complex voltages, line
currents, and power flows. The developed theory of linearizing the power flow
equations around changes in the complex network admittance parameters has
numerous applications. We demonstrate several of these applications, such as
predicting the nodal voltages when the network topology changes without solving
the power flow equations. We showcase the application for continuous admittance
control, which is used to increase the hosting capacity of a given distribution
network.

</details>


### [190] [Semantic Intelligence: A Bio-Inspired Cognitive Framework for Embodied Agents](https://arxiv.org/abs/2510.17129)
*Wenbing Tang,Meilin Zhu,Fenghua Wu,Yang Liu*

Main category: eess.SY

TL;DR: 提出了语义智能驱动的具身代理框架SIDE，通过分层语义认知架构和语义驱动决策过程，使代理能够在物理世界中进行上下文自适应的推理和交互。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型主要在数字环境中运行，缺乏与物理世界的交互。现有具身智能体在非结构化现实环境中面临语义智能不足的挑战，无法充分理解和推理复杂任务。

Method: 引入SIDE框架，整合分层语义认知架构和语义驱动决策过程，受生物认知机制启发，设计模仿人类和动物整合处理感官信息的语义认知架构。

Result: 开发了一个能够进行上下文自适应推理和交互的具身代理框架，为构建更智能和通用的具身代理迈出重要一步。

Conclusion: SIDE框架通过语义智能驱动的方法，有效解决了具身代理在现实环境中语义理解不足的问题，为未来更智能的具身智能体发展奠定了基础。

Abstract: Recent advancements in Large Language Models (LLMs) have greatly enhanced
natural language understanding and content generation. However, these models
primarily operate in disembodied digital environments and lack interaction with
the physical world. To address this limitation, Embodied Artificial
Intelligence (EAI) has emerged, focusing on agents that can perceive and
interact with their surroundings. Despite progress, current embodied agents
face challenges in unstructured real-world environments due to insufficient
semantic intelligence, which is critical for understanding and reasoning about
complex tasks. This paper introduces the Semantic Intelligence-Driven Embodied
(SIDE) agent framework, which integrates a hierarchical semantic cognition
architecture with a semantic-driven decision-making process. This enables
agents to reason about and interact with the physical world in a contextually
adaptive manner. The framework is inspired by biological cognitive mechanisms
and utilizes bio-inspired principles to design a semantic cognitive
architecture that mimics how humans and animals integrate and process sensory
information. We present this framework as a step toward developing more
intelligent and versatile embodied agents.

</details>


### [191] [A Data-Driven Framework for Online Mitigation of False Data Injection Signals in Networked Control Systems](https://arxiv.org/abs/2510.17155)
*Mohammadamin Lari*

Main category: eess.SY

TL;DR: 提出了一种新颖的两阶段框架，用于在线缓解网络控制系统中的虚假数据注入信号，通过元学习和集成学习提高系统弹性，确保在恶意活动存在时的安全运行。


<details>
  <summary>Details</summary>
Motivation: 网络控制系统面临虚假数据注入等安全威胁，需要实时检测和缓解恶意信号以确保系统安全和完整性。

Method: 第一阶段使用元学习在堆叠集成学习架构中选择基础时间序列预测模型，通过连续小波变换将时间序列数据转换为尺度图，再分割为图像帧生成尺度-时间表示，基于熵度量使用卷积神经网络区分时间序列数据的复杂度；第二阶段实时缓解虚假数据注入信号。

Result: 通过差动驱动移动机器人编队控制的严格仿真验证了该框架的有效性。

Conclusion: 该框架为解决网络控制系统的安全挑战提供了一种有前景的方法，能够维护系统完整性并确保操作安全。

Abstract: This paper introduces a novel two-stage framework for online mitigation of
False Data Injection (FDI) signals to improve the resiliency of Networked
Control Systems (NCSs) and ensure their safe operation in the presence of
malicious activities. The first stage involves meta learning to select a base
time series forecasting model within a stacked ensemble learning architecture.
This is achieved by converting time series data into scalograms using
continuous wavelet transform, which are then split into image frames to
generate a scalo-temporal representation of the data and to distinguish between
different complexity levels of time series data based on an entropy metric
using a convolutional neural network. In the second stage, the selected model
mitigates false data injection signals in real-time. The proposed framework's
effectiveness is demonstrated through rigorous simulations involving the
formation control of differential drive mobile robots. By addressing the
security challenges in NCSs, this framework offers a promising approach to
maintaining system integrity and ensuring operational safety.

</details>


### [192] [Generalized Group Selection Strategies for Self-sustainable RIS-aided Communication](https://arxiv.org/abs/2510.17176)
*Lakshmikanta Sau,Priyadarshi Mukherjee,Sasthi C. Ghosh*

Main category: eess.SY

TL;DR: 本文研究了在空间相关无线信道下，基于分组的自可持续RIS辅助D2D通信中的各种组选择策略，分析了功率分配和时间切换配置下的系统性能，并提出了系统参数选择的适当边界。


<details>
  <summary>Details</summary>
Motivation: 可重构智能表面(RIS)是超越第五代无线通信网络的前沿技术，本文旨在研究在自可持续RIS辅助D2D通信中，如何通过有效的组选择策略来优化系统性能，特别是在考虑实际非线性能量收集模型的情况下。

Method: 采用功率分配(PS)和时间切换(TS)两种自可持续RIS配置，考虑线性和非线性能量收集模型，提出基于端到端信噪比和能量收集的组选择策略，使用高阶统计工具推导中断概率的解析表达式，并应用极值理论分析组数趋于无穷的渐近情况。

Result: 数值结果表明所提出的方法在数据吞吐量和中断性能（包括数据和能量中断）方面具有重要优势和效益，特别是在大规模智能表面辅助无线通信应用中。

Conclusion: 通过分析不同的组选择策略，本文为自可持续RIS辅助D2D通信系统提供了性能优化的有效方法，特别是在大规模组选择场景下，所获得的非平凡见解对实际应用具有重要价值。

Abstract: Reconfigurable intelligent surface (RIS) is a cutting-edge communication
technology that has been proposed as aviable option for beyond fifth-generation
wireless communication networks. This paper investigates various group
selection strategies in the context of grouping-based self-sustainable
RIS-aided device-to-device (D2D) communication with spatially correlated
wireless channels. Specifically, we consider both power splitting (PS) and time
switching (TS) configurations, of the self-sustainable RIS to analyze the
system performance and propose appropriate bounds on the choice of system
parameters. The analysis takes into account a simplified linear energy
harvesting (EH) model as well as a practical non-linear EH model. Based on the
application requirements, we propose various group selection strategies at the
RIS. Notably, each strategy schedules the k-th best available group at the RIS
based on the end-to-end signal-to-noise ratio (SNR) and also the energy
harvested at a particular group of the RIS. Accordingly, by using tools from
high order statistics, we derive analytical expressions for the outage
probability of each selection strategy. Moreover, by applying the tools from
extreme value theory, we also investigate an asymptotic scenario, where the
number of groups available for selection at an RIS approaches infinity. The
nontrivial insights obtained from this approach is especially beneficial in
applications like large intelligent surface-aided wireless communication.
Finally, the numerical results demonstrate the importance and benefits of the
proposed approaches in terms of metrics such as the data throughput and the
outage (both data and energy) performance.

</details>


### [193] [Enhanced Ground-Satellite Direct Access via Onboard Rydberg Atomic Quantum Receivers](https://arxiv.org/abs/2510.17290)
*Qihao Peng,Tierui Gong,Zihang Song,Qu Luo,Zihuai Lin,Pei Xiao,Chau Yuen*

Main category: eess.SY

TL;DR: 本文提出了一种用于6G卫星网络的Rydberg原子量子接收器(RAQR)，通过原子电磁诱导透明将射频场转换为光信号，解决了传统RF前端面临的路径损耗、尺寸重量功率限制和频谱拥堵等问题。


<details>
  <summary>Details</summary>
Motivation: 6G网络的地面-卫星链路面临严重路径损耗、严格的尺寸重量功率限制和频谱拥堵等关键挑战，这些因素显著阻碍了传统射频前端的性能。

Method: 采用Rydberg原子量子接收器(RAQR)，这是一种毫米级前端，通过原子电磁诱导透明将射频场转换为光信号。采用混合原子-电子设计和支持信号模型。

Result: RAQR的高灵敏度和高频率选择性解决了链路预算、有效载荷和干扰挑战，同时满足空间限制。相比传统RF接收器，展示了增强的数据速率、覆盖范围和传感精度。

Conclusion: 文章最后提出了集成策略、分布式卫星概念以及将RAQR支持的卫星有效载荷投入服务的开放研究问题。

Abstract: Ground-satellite links for 6G networks face critical challenges, including
severe path loss, tight size-weight-power limits, and congested spectrum, all
of which significantly hinder the performance of traditional radio frequency
(RF) front ends. This article introduces the Rydberg Atomic Quantum Receiver
(RAQR) for onboard satellite systems, a millimeter-scale front end that
converts radio fields to optical signals through atomic electromagnetically
induced transparency. RAQR's high sensitivity and high frequency selectivity
address link budget, payload, and interference challenges while fitting within
space constraints. A hybrid atomic-electronic design and supporting signal
model demonstrate enhanced data rate, coverage, and sensing accuracy relative
to conventional RF receivers. The article concludes with integration
strategies, distributed-satellite concepts, and open research problems for
bringing RAQR-enabled satellite payloads into service.

</details>


### [194] [Comparison and performance analysis of dynamic encrypted control approaches](https://arxiv.org/abs/2510.17333)
*Sebastian Schlor,Frank Allgöwer*

Main category: eess.SY

TL;DR: 本文回顾了动态加密控制的最新方法，包括自举、控制器状态周期性重置、整数重构和FIR控制器，并分析了它们的稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 使用同态加密的加密控制器可以保护测量和控制信号的隐私以及系统和控制器参数，但动态控制器的加密由于编码中的噪声和溢出问题而具有挑战性。

Method: 回顾了动态加密控制的几种方法：自举、控制器状态周期性重置、整数重构和FIR控制器，并进行了稳定性和性能分析。

Result: 通过基准系统的数值性能比较，评估了这些方法的适用性。

Conclusion: 本文为动态加密控制提供了全面的方法回顾和性能评估，有助于选择合适的加密控制策略。

Abstract: Encrypted controllers using homomorphic encryption have proven to guarantee
the privacy of measurement and control signals, as well as system and
controller parameters, while regulating the system as intended. However,
encrypting dynamic controllers has remained a challenge due to growing noise
and overflow issues in the encoding. In this paper, we review recent approaches
to dynamic encrypted control, such as bootstrapping, periodic resets of the
controller state, integer reformulations, and FIR controllers, and equip them
with a stability and performance analysis to evaluate their suitability. We
complement the analysis with a numerical performance comparison on a benchmark
system.

</details>


### [195] [Accelerating Adaptive Systems via Normalized Parameter Estimation Laws](https://arxiv.org/abs/2510.17371)
*Mohammad Boveiri,Mohammad Khosravi,Peyman Mohajerin Esfahan*

Main category: eess.SY

TL;DR: 提出了一种新的归一化参数估计方法，能加速系统状态收敛到原点，保证系统状态的r次方根平方范数有限可积，其中r≥1且可任意大，而传统方法只保证r=1的情况。


<details>
  <summary>Details</summary>
Motivation: 传统Lyapunov估计方法只能保证系统状态平方范数的可积性（r=1），收敛速度有限。新方法通过提高r值来促进时间域稀疏性，惩罚信号持续时间过长和缓慢衰减，从而加速系统状态收敛。

Method: 提出归一化参数估计法，不依赖时变或高适应增益，无需持续激励，适用于匹配和不匹配不确定性系统，只要存在控制Lyapunov函数即可应用。还开发了包含动量的高阶扩展版本。

Result: 新估计方法能保证‖x(t)‖₂^(2/r) ∈ L₁，其中r≥1且可任意大，相比传统方法只保证r=1的情况，显著加速了系统状态收敛。数值实验验证了性能提升。

Conclusion: 归一化参数估计法提供了一种有效的加速收敛机制，通过时间域稀疏性促进实现更快的系统状态收敛，适用于广泛的不确定性系统，且与CLF控制器兼容。

Abstract: In this paper, we propose a new class of parameter estimation laws for
adaptive systems, called \emph{normalized parameter estimation laws}. A key
feature of these estimation laws is that they accelerate the convergence of the
system state, $\mathit{x(t)}$, to the origin. We quantify this improvement by
showing that our estimation laws guarantee finite integrability of the
$\mathit{r}$-th root of the squared norm of the system state, i.e., \(
\mathit{\|x(t)\|}_2^{2/\mathit{r}} \in \mathcal{L}_1, \) where $\mathit{r} \geq
1$ is a pre-specified parameter that, for a broad class of systems, can be
chosen arbitrarily large. In contrast, standard Lyapunov-based estimation laws
only guarantee integrability of $\mathit{\|x(t)\|}_2^2$ (i.e., $\mathit{r} =
1$). We motivate our method by showing that, for large values of $r$, this
guarantee serves as a sparsity-promoting mechanism in the time domain, meaning
that it penalizes prolonged signal duration and slow decay, thereby promoting
faster convergence of $\mathit{x(t)}$. The proposed estimation laws do not rely
on time-varying or high adaptation gains and do not require persistent
excitation. Moreover, they can be applied to systems with matched and unmatched
uncertainties, regardless of their dynamic structure, as long as a control
Lyapunov function (CLF) exists. Finally, they are compatible with any CLF-based
certainty equivalence controllers. We further develop higher-order extensions
of our estimation laws by incorporating momentum into the estimation dynamics.
We illustrate the performance improvements achieved with the proposed scheme
through various numerical experiments.

</details>


### [196] [Artificial magnetic conductor backed dual-mode sectoral cylindrical DRA for off-body biomedical telemetry](https://arxiv.org/abs/2510.17619)
*Nayab Gogosh,Sohail Khalid,Bilal Tariq Malik,Slawomir Koziel*

Main category: eess.SY

TL;DR: 本研究提出了一种扇形圆柱介质谐振器天线(CDRA)，通过双模操作(EH110和TE210模式)和四分之一扇形结构减小尺寸，结合人工磁导体(AMC)表面降低SAR值，实现了适用于生物医学遥测的5.2-5.9 GHz带宽天线。


<details>
  <summary>Details</summary>
Motivation: 传统CDRA天线具有低损耗、坚固性和稳定性等优点，但其有限的带宽和较大尺寸使其不适合可穿戴设备应用。本研究旨在解决这些限制，开发适用于生物医学遥测的小型化天线。

Method: 采用扇形CDRA设计，使用四分之一扇形结构和完美电导体边界将尺寸减小四倍；设计双模天线，工作在EH110和TE210模式；推导两种模式的场分量数学表达式；在天线背面应用AMC表面以最小化SAR值并增强与横向电模式的兼容性。

Result: 天线实现了0.7 GHz带宽(5.2-5.9 GHz)，适合生物医学应用；测得峰值增益为7.9 dBi；应用于人体手臂时的SAR值为1.24 W/kg。

Conclusion: 所提出的扇形CDRA设计成功解决了传统CDRA的尺寸和带宽限制，通过双模操作和AMC表面实现了适用于生物医学遥测的小型化高性能天线。

Abstract: This research investigates the potential of a sectoral Cylindrical Dielectric
Resonator Antenna (CDRA) for biomedical telemetry. CDRAs are known for their
low loss, ruggedness, and stability, but their limited bandwidth and size make
them unsuitable for wearable devices. The research addresses these limitations
by proposing a dual mode antenna that operates in EH110 and TE210 modes. The
sectoral CDRA is a quarter segment with Perfect Electric Conductor boundaries,
reducing its size by a factor of four. Mathematical derivations of the field
components for both modes are derived to support the design. To minimize
specific absorption rate (SAR), an Artificial Magnetic Conductor (AMC) surface
is applied to the antennas backside, enhancing compatibility with the
transverse electric modes. The antenna achieves a bandwidth of 0.7 GHz (5.2-5.9
GHz), suitable for biomedical applications, with a measured peak gain of 7.9
dBi and a SAR of 1.24 W/kg when applied to a human arm.

</details>


### [197] [Trajectory Optimization for Minimum Threat Exposure using Physics-Informed Neural Networks](https://arxiv.org/abs/2510.17762)
*Alexandra E. Ballentine,Raghvendra V. Cowlagi*

Main category: eess.SY

TL;DR: 使用物理信息神经网络(PINN)求解由庞特里亚金极小值原理产生的两点边值问题，解决传统打靶法对初值高度敏感的问题，应用于车辆运动学模型的最小威胁暴露轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 传统打靶法求解最优控制问题中的两点边值问题时，对初始猜测极其敏感，数值求解困难。物理信息神经网络在求解高维微分方程方面表现出色，因此尝试用PINN解决这类问题。

Method: 开发两种PINN模型：1)针对给定初始和终端状态的特定威胁场训练PINN；2)针对给定威胁场但仅以初始状态为条件的PINN，避免对每个初始状态重新训练。

Result: PINN输出满足必要条件的数值误差较低，验证了方法的有效性。

Conclusion: PINN能够有效求解最优控制中的两点边值问题，特别是第二种方法消除了对每个初始状态重新训练的需求，提高了计算效率。

Abstract: We apply a physics-informed neural network (PINN) to solve the two-point
boundary value problem (BVP) arising from the necessary conditions postulated
by Pontryagin's Minimum Principle for optimal control. Such BVPs are known to
be numerically difficult to solve by traditional shooting methods due to
extremely high sensitivity to initial guesses. In the light of recent successes
in applying PINNs for solving high-dimensional differential equations, we
develop a PINN to solve the problem of finding trajectories with minimum
exposure to a spatiotemporal threat for a vehicle kinematic model. First, we
implement PINNs that are trained to solve the BVP for a given pair of initial
and final states for a given threat field. Next, we implement a PINN
conditioned on the initial state for a given threat field, which eliminates the
need for retraining for each initial state. We demonstrate that the PINN
outputs satisfy the necessary conditions with low numerical error.

</details>


### [198] [Data-driven Communication and Control Design for Distributed Frequency Regulation with Black-box Inverters](https://arxiv.org/abs/2510.17769)
*Michael Nestor,Jiaxin Wang,Ning Zhang,Fei Teng*

Main category: eess.SY

TL;DR: 提出了一种分布式数据驱动的二次频率控制方法，利用逆变器间的点对点通信，无需中央控制中心，并在通信需求和控制性能之间实现权衡。


<details>
  <summary>Details</summary>
Motivation: 随着基于逆变器的资源在电网中渗透率增加，且通常只有黑盒模型可用，这对传统的频率控制方法构成挑战。现有研究多采用去中心化方法，缺乏在线设备协调通信。

Method: 开发分布式数据驱动方法，利用逆变器间的点对点通信；提出通信拓扑设计框架，指导二次频率调节的通信网络设计；设计基于通信拓扑结构的控制器，保证闭环稳定性。

Result: 在IEEE 39总线系统上的案例研究验证了该框架，并展示了所提方法在通信需求和控制性能之间的权衡能力。

Conclusion: 该方法成功实现了分布式二次频率控制，通过通信拓扑设计在通信网络需求和控制性能之间取得平衡，且具有闭环稳定性保证。

Abstract: The increasing penetration of inverter-based resources into the power grid,
with often only black-box models available, challenges long-standing frequency
control methods. Most recent works take a decentralized approach without online
device coordination via communication. This paper considers both dynamic
behavior and communication within secondary frequency control on an
intermediate timescale. We develop a distributed data-driven approach that
utilizes peer-to-peer communication between inverters to avoid the need for a
central control center. To enable a trade off between communication network
requirements and control performance, we present a framework to guide
communication topology design for secondary frequency regulation. Following
design of the inter-agent information exchange scheme, we design a controller
that is structured according to the communication topology with a closed-loop
stability guarantee. Case studies on the IEEE 39-bus system validate the
framework and illustrate the trade-off between communication requirements and
control performance that is enabled by our approach.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [199] [The Cultural Mapping and Pattern Analysis (CMAP) Visualization Toolkit: Open Source Text Analysis for Qualitative and Computational Social Science](https://arxiv.org/abs/2510.16140)
*Corey M. Abramson,Yuhan,Nian*

Main category: stat.AP

TL;DR: CMAP是一个开源的文化映射和模式分析可视化工具包，用于分析和可视化文本数据，支持大规模数据集和高级统计语言建模。


<details>
  <summary>Details</summary>
Motivation: 现有商业定性数据分析软件缺乏高度可扩展的开源选项，无法处理大数据集和集成高级统计语言建模。

Method: 采用实用主义方法，将研究工具与社会科学项目目标对齐，通过调整少量参数提供多种可能性，并能与其他Python工具集成。

Result: 开发了一个开源工具包，支持从定性田野笔记到网络抓取数据等多种文本数据的分析和可视化。

Conclusion: CMAP工具包为计算社会科学提供了灵活、可扩展的解决方案，强调研究范式和方法应由研究问题决定。

Abstract: The CMAP (cultural mapping and pattern analysis) visualization toolkit
introduced in this paper is an open-source suite for analyzing and visualizing
text data - from qualitative fieldnotes and in-depth interview transcripts to
historical documents and web-scaped data like message board posts or blogs. The
toolkit is designed for scholars integrating pattern analysis, data
visualization, and explanation in qualitative and/or computational social
science (CSS). Despite the existence of off-the-shelf commercial qualitative
data analysis software, there is a dearth of highly scalable open source
options that can work with large data sets, and allow advanced statistical and
language modeling. The foundation of the toolkit is a pragmatic approach that
aligns research tools with social science project goals- empirical explanation,
theory-guided measurement, comparative design, or evidence-based
recommendations- guided by the principle that research paradigm and questions
should determine methods. Consequently, the CMAP visualization toolkit offers a
range of possibilities through the adjustment of relatively small number of
parameters, and allows integration with other python tools.

</details>


### [200] [COWs and their Hybrids: A Statistical View of Custom Orthogonal Weights](https://arxiv.org/abs/2510.16174)
*Chad Schafer,Larry Wasserman,Mikael Kuusela*

Main category: stat.AP

TL;DR: 该论文讨论了高能物理中信号与背景混合分布的推断问题，提出并分析了COWs方法作为sPlot方法的推广，用于在判别变量有效分离信号和背景的情况下为事件分配信号权重。


<details>
  <summary>Details</summary>
Motivation: 解决高能物理中从信号和背景事件混合分布中推断信号成分的重复性挑战，特别是在存在能够有效分离信号和背景的判别变量时。

Method: 使用COWs（正交权重）方法，这是对sPlot方法的推广，通过为每个事件分配信号权重，用于后续对感兴趣的控制变量进行分析。

Result: 形式化了该方法所需的假设条件和统计特性，同时考虑了扩展方法和替代方法。

Conclusion: COWs方法为解决高能物理中的信号推断问题提供了理论基础，并展示了其统计特性和潜在扩展。

Abstract: A recurring challenge in high energy physics is inference of the signal
component from a distribution for which observations are assumed to be a
mixture of signal and background events. A standard assumption is that there
exists information encoded in a discriminant variable that is effective at
separating signal and background. This can be used to assign a signal weight to
each event, with these weights used in subsequent analyses of one or more
control variables of interest. The custom orthogonal weights (COWs) approach of
Dembinski, et al.(2022), a generalization of the sPlot approach of Barlow
(1987) and Pivk and Le Diberder (2005), is tailored to address this objective.
The problem, and this method, present interesting and novel statistical issues.
Here we formalize the assumptions needed and the statistical properties, while
also considering extensions and alternative approaches.

</details>


### [201] [Estimating Time-Varying Epidemic Severity Rates with Adaptive Deconvolution](https://arxiv.org/abs/2510.16180)
*Jeremy Goldwasser,Addison J. Hu,Alyssa Bilinski,Daniel J. McDonald,Ryan J. Tibshirani*

Main category: stat.AP

TL;DR: 本文开发了一种基于泊松-二项模型的去卷积方法，用于估计随时间变化的公共卫生严重性指标，如病死率。该方法通过趋势滤波惩罚正则化最大似然解，能够比标准比率方法更准确地计算回顾性和实时严重性率。


<details>
  <summary>Details</summary>
Motivation: 公共卫生中的关键指标（如病死率）会随时间变化，但常用的比率估计器存在高度偏差，需要开发新方法来准确估计这些随时间变化的严重性率。

Method: 开发了一种自适应去卷积方法，基于近似泊松-二项模型对次要事件建模，并使用趋势滤波惩罚正则化最大似然解，产生平滑但局部自适应的严重性率估计。

Result: 基于COVID-19死亡和住院数据的实验表明，去卷积估计器通常比标准比率方法更准确，并对模型误设显示出合理的鲁棒性。

Conclusion: 该方法能够更准确地计算回顾性和实时严重性率，为公共卫生监测提供了改进的统计工具。

Abstract: Several key metrics in public health convey the probability that a primary
event will lead to a more serious secondary event in the future. These
"severity rates" can change over the course of an epidemic in response to
shifting conditions like new therapeutics, variants, or public health
interventions. In practice, time-varying parameters such as the case-fatality
rate are typically estimated from aggregate count data. Prior work has
demonstrated that commonly-used ratio-based estimators can be highly biased,
motivating the development of new methods. In this paper, we develop an
adaptive deconvolution approach based on approximating a Poisson-binomial model
for secondary events, and we regularize the maximum likelihood solution in this
model with a trend filtering penalty to produce smooth but locally adaptive
estimates of severity rates over time. This enables us to compute severity
rates both retrospectively and in real time. Experiments based on COVID-19
death and hospitalization data, both real and simulated, demonstrate that our
deconvolution estimator is generally more accurate than the standard
ratio-based methods, and displays reasonable robustness to model
misspecification.

</details>


### [202] [A Compositional Approach to Modelling Cause-specific Mortality with Zero Counts](https://arxiv.org/abs/2510.16244)
*Zhe Michelle Dong,Han Lin Shang,Francis Hui,Aaron Bruhn*

Main category: stat.AP

TL;DR: 该论文提出使用α-变换来处理死亡率建模中的零值问题，改进了基于对数比的标准组合数据分析方法，提高了特定原因死亡率的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 理解和预测特定原因死亡率对精算科学至关重要，但标准组合数据分析方法在处理零值时面临挑战，需要更严谨的统计方法来处理零值子组。

Method: 使用组合幂变换（α-变换）来建模特定原因生命表死亡计数，为组合数据分析中的零值子组提供统计严谨的方法。

Result: α-变换相比基于对数比的组合数据变换方法，提高了特定原因生命表死亡计数的预测准确性。预测显示主要心血管原因（心肌梗死和其他缺血性心脏病）的死亡比例下降。

Conclusion: α-变换为处理死亡率建模中的零值问题提供了有效的解决方案，能够产生更准确的特定原因死亡率预测，对公共政策和行业决策具有重要意义。

Abstract: Understanding and forecasting mortality by cause is an essential branch of
actuarial science, with wide-ranging implications for decision-makers in public
policy and industry. To accurately capture trends in cause-specific mortality,
it is critical to consider dependencies between causes of death and produce
forecasts by age and cause coherent with aggregate mortality forecasts. One way
to achieve these aims is to model cause-specific deaths using compositional
data analysis (CODA), treating the density of deaths by age and cause as a set
of dependent, non-negative values that sum to one. A major drawback of standard
CODA methods is the challenge of zero values, which frequently occur in
cause-of-death mortality modelling. Thus, we propose using a compositional
power transformation, the $\alpha$-transformation, to model cause-specific
life-table death counts. The $\alpha$-transformation offers a statistically
rigorous approach to handling zero value subgroups in CODA compared to
\emph{ad-hoc} techniques: adding an arbitrarily small amount. We illustrate the
$\alpha$-transformation on England and Wales, and US death counts by cause from
the Human Cause-of-Death database, for cardiovascular-related causes of death.
Results demonstrate the $\alpha$-transformation improves forecast accuracy of
cause-specific life-table death counts compared with log-ratio-based CODA
transformations. The forecasts suggest declines in proportions of deaths from
major cardiovascular causes (myocardial infarction and other ischemic heart
diseases (IHD)).

</details>


### [203] [Mortality Modeling and Forecasting with the Actuaries Climate Index](https://arxiv.org/abs/2510.16266)
*Karim Barigou,Melanie Patten,Kenneth Q. Zhou*

Main category: stat.AP

TL;DR: 该研究提出了一种将气候指数(ACI)纳入死亡率模型的两步方法，通过结合传统死亡率模型和气候变量，提高了死亡率预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 气候变化给死亡率建模带来挑战，需要将气候相关变量整合到死亡率预测中，以更好地理解和应对气候相关的死亡风险。

Method: 采用两步法：第一步使用Lee-Carter模型结合SARIMA过程、余弦-正弦分解和循环样条函数建模季节性死亡率动态；第二步使用GLM、GAM和XGBoost模型解释基线模型的残差偏差与ACI组件的关系，并开发SARIMA-Copula预测方法连接死亡率周期效应与极端温度。

Result: 结果表明，整合ACI组件系统性地提高了样本外预测精度，证明了将气候相关变量纳入随机死亡率建模的价值。

Conclusion: 该框架为精算师和政策制定者提供了一个实用工具，用于预测和管理气候相关的死亡风险。

Abstract: Climate change poses increasing challenges for mortality modeling and
underscores the need to integrate climate-related variables into mortality
forecasting. This study introduces a two-step approach that incorporates
climate information from the Actuaries Climate Index (ACI) into mortality
models. In the first step, we model region-specific seasonal mortality dynamics
using the Lee-Carter model with SARIMA processes, a cosine-sine decomposition,
and a cyclic spline-based function. In the second step, residual deviations
from the baseline model are explained by ACI components using Generalized
Linear Models, Generalized Additive Models, and Extreme Gradient Boosting. To
further capture the dependence between mortality and climate, we develop a
SARIMA-Copula forecasting approach linking mortality period effects with
temperature extremes. Our results show that incorporating ACI components
systematically enhances out-of-sample accuracy, underscoring the value of
integrating climate-related variables into stochastic mortality modeling. The
proposed framework offers actuaries and policymakers a practical tool for
anticipating and managing climate-related mortality risks.

</details>


### [204] [Synergizing chemical and AI communities for advancing laboratories of the future](https://arxiv.org/abs/2510.16293)
*Saejin Oh,Xinyi Fang,I-Hsin Lin,Paris Dee,Christopher S. Dunham,Stacy M. Copp,Abigail G. Doyle,Javier Read de Alaniz,Mengyang Gu*

Main category: stat.AP

TL;DR: 本文展望了机器学习模型和基于大语言模型的人工智能代理如何帮助化学家加速实验设计、合成优化和材料表征等实验室任务，减少耗时实验和手动数据分析。


<details>
  <summary>Details</summary>
Motivation: 自动化实验设施的发展和实验数据数字化为化学实验室带来了革命性机遇，机器学习方法可以显著加速传统的设计-构建-测试-学习过程。

Method: 介绍机器学习预测模型在实验室任务中的应用，包括实验设计、合成优化和材料表征，并引入基于大语言模型的人工智能代理来帮助研究人员获取化学或数据科学背景知识。

Result: 通过三个不同领域的案例研究，展示了机器学习和人工智能代理如何减少耗时实验和手动数据分析。

Conclusion: 强调了需要实验和计算社区持续协同努力来解决现有挑战。

Abstract: The development of automated experimental facilities and the digitization of
experimental data have introduced numerous opportunities to radically advance
chemical laboratories. As many laboratory tasks involve predicting and
understanding previously unknown chemical relationships, machine learning (ML)
approaches trained on experimental data can substantially accelerate the
conventional design-build-test-learn process. This outlook article aims to help
chemists understand and begin to adopt ML predictive models for a variety of
laboratory tasks, including experimental design, synthesis optimization, and
materials characterization. Furthermore, this article introduces how artificial
intelligence (AI) agents based on large language models can help researchers
acquire background knowledge in chemical or data science and accelerate various
aspects of the discovery process. We present three case studies in distinct
areas to illustrate how ML models and AI agents can be leveraged to reduce
time-consuming experiments and manual data analysis. Finally, we highlight
existing challenges that require continued synergistic effort from both
experimental and computational communities to address.

</details>


### [205] [A hierarchical Bayesian approach for population-based structural health monitoring in ship hull structures](https://arxiv.org/abs/2510.16316)
*Georgios Aravanis,Nicholas Silionis,Jacopo Bardiani,Marco Giglio,Konstantinos Anyfantis,Claudio Sbarufatti*

Main category: stat.AP

TL;DR: 该研究应用分层贝叶斯模型来推断板构件群体和个体层面的挠度分布，以检测过大的初始挠度，在数据稀疏条件下比独立模型提供更稳健的结果。


<details>
  <summary>Details</summary>
Motivation: 利用群体结构健康监测策略，通过数据丰富的构件支持数据稀缺的构件，提高对板构件初始挠度异常的检测能力。

Method: 使用分层贝叶斯方法构建模型，通过有限元模型生成应变响应数据作为监测数据，采用马尔可夫链蒙特卡洛进行贝叶斯推断，并使用代理模型计算似然函数。

Result: 在数据稀疏条件下，分层模型比独立模型在不确定性方面提供更稳健的结果，这对决策任务至关重要。

Conclusion: 分层贝叶斯模型在群体结构健康监测中，特别是在数据稀缺情况下，能够提供更可靠的挠度分布推断，有助于检测过大的初始挠度。

Abstract: Structural health monitoring (SHM) strategies involve the processing of
structural response data to indirectly assess an asset's condition. These
strategies can be enhanced for a group of structures, especially when they are
similar, since mutual underlying physics are expected to exist. The concept
behind population-based SHM exploits the sharing of data among individuals, so
that data-rich members can support data-scarce ones. One approach to
population-level modeling is the hierarchical Bayesian method, where the model
is structured hierarchically in terms of its parameters, and correlation among
learning tasks is enabled by conditioning on shared latent variables.
  This work investigates the application of a hierarchical Bayesian model to
infer expected distributions of deflection amplitudes at both the population
and domain levels, with the aim of detecting excessive initial deflections in a
population of plate elements. Although these damages are typically localized,
they can trigger unexpected events, if not properly monitored. The work is
conducted in a numerical setting using a Finite Element model to generate
strain response data, which serve as the monitoring data. Bayesian inference
was conducted using Markov Chain Monte Carlo (MCMC), with a surrogate model
employed to calculate the likelihood function. The hierarchical approach was
compared to an independent model for a plate component with few data. The
results revealed that, under data sparsity conditions, the hierarchical model
can offer more robust results in terms of uncertainty, which is essential for
decision-making tasks.

</details>


### [206] [Time-Varying Confounding Bias in Observational Geoscience with Application to Induced Seismicity](https://arxiv.org/abs/2510.16360)
*Yuchen Xiao,Corwin Zigler,Peter H. Hennings,Alexandros Savvaidis*

Main category: stat.AP

TL;DR: 本文采用因果推断框架分析废水注入与诱发地震之间的因果关系，通过潜在结果视角定义因果效应，并应用纵向数据分析方法估计废水处置对地震的影响。


<details>
  <summary>Details</summary>
Motivation: 现有物理模型已确认盐水处置是诱发地震的主要因素，但统计/机器学习模型难以解释参数显著性或预测能力作为因果证据。需要明确的因果推断框架来从观测数据中恢复无偏的因果效应估计。

Method: 采用因果推断框架和潜在结果视角，定义因果效应并声明必要的识别条件。通过模拟说明时变混杂的威胁，并应用因果推断文献中建立的纵向分析方法。

Result: 在2013-2016年北德克萨斯州Fort-Worth盆地的研究中，估计了废水处置对地震的因果效应。

Conclusion: 因果推断框架为从观测性纵向地球科学数据中估计因果效应提供了系统方法，能够处理时变混杂问题，为废水处置与诱发地震之间的因果关系提供更可靠的证据。

Abstract: Evidence derived primarily from physical models has identified saltwater
disposal as the dominant causal factor that contributes to induced seismicity.
To complement physical models, statistical/machine learning (ML) models are
designed to measure associations from observational data, either with
parametric regression models or more flexible ML models. However, it is often
difficult to interpret the statistical significance of a parameter or the
predicative power of a model as evidence of causation. We adapt a causal
inference framework with the potential outcomes perspective to explicitly
define what we meant by causal effect and declare necessary identification
conditions to recover unbiased causal effect estimates. In particular, we
illustrate the threat of time-varying confounding in observational longitudinal
geoscience data through simulations and adapt established statistical methods
for longitudinal analysis from the causal interference literature to estimate
the effect of wastewater disposal on earthquakes in the Fort-Worth Basin of
North Central Texas from 2013 to 2016.

</details>


### [207] [Bayesian reliability acceptance sampling plans for competing risks data under interval censoring](https://arxiv.org/abs/2510.16740)
*Biswabrata Pradhan,Rathin Das*

Main category: stat.AP

TL;DR: 提出了一种基于贝叶斯方法的独立竞争风险数据区间删失可靠性验收抽样计划，包括固定决策准则和最优决策函数两种方案。


<details>
  <summary>Details</summary>
Motivation: 解决大样本情况下贝叶斯风险计算复杂的问题，为制造商提供最优决策函数以最小化风险。

Method: 使用最大似然估计的渐近性质获得近似贝叶斯风险，通过最小化贝叶斯风险获得最优决策函数和抽样计划。

Result: 提供了计算最优贝叶斯可靠性验收抽样计划的算法，并进行了数值结果比较。

Conclusion: 贝叶斯方法能够有效处理竞争风险数据的可靠性验收抽样问题，为制造商提供风险最小化的决策方案。

Abstract: We obtain a reliability acceptance sampling plan for independent competing
risk data under interval censoring schemes using the Bayesian approach. At
first, the Bayesian reliability acceptance sampling plan is obtained where the
decision criteria of accepting a lot is pre-fixed. For large samples, computing
Bayes risk is computationally intensive. Therefore, an approximate Bayes risk
is obtained using the asymptotic properties of the maximum likelihood
estimators. Lastly, the Bayesian reliability acceptance sampling plan is
obtained, where the decision function is arbitrary. The manufacturer can derive
an optimal decision function by minimizing the Bayes risk among all decision
functions. This optimal decision function is known as Bayes decision function.
The optimal sampling plan is obtained by minimizing the Bayes risk. The
algorithms are provided for the computation of optimum Bayesian reliability
acceptance sampling plan. Numerical results are provided and comparisons
between the Bayesian reliability acceptance sampling plans are carried out.

</details>
