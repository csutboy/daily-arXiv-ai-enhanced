{"id": "2510.15200", "categories": ["econ.TH", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15200", "abs": "https://arxiv.org/abs/2510.15200", "authors": ["Fasheng Xu", "Xiaoyu Wang", "Wei Chen", "Karen Xie"], "title": "The Economics of AI Foundation Models: Openness, Competition, and Governance", "comment": null, "summary": "The strategic choice of model \"openness\" has become a defining issue for the\nfoundation model (FM) ecosystem. While this choice is intensely debated, its\nunderlying economic drivers remain underexplored. We construct a two-period\ngame-theoretic model to analyze how openness shapes competition in an AI value\nchain, featuring an incumbent developer, a downstream deployer, and an entrant\ndeveloper. Openness exerts a dual effect: it amplifies knowledge spillovers to\nthe entrant, but it also enhances the incumbent's advantage through a \"data\nflywheel effect,\" whereby greater user engagement today further lowers the\ndeployer's future fine-tuning cost. Our analysis reveals that the incumbent's\noptimal first-period openness is surprisingly non-monotonic in the strength of\nthe data flywheel effect. When the data flywheel effect is either weak or very\nstrong, the incumbent prefers a higher level of openness; however, for an\nintermediate range, it strategically restricts openness to impair the entrant's\nlearning. This dynamic gives rise to an \"openness trap,\" a critical policy\nparadox where transparency mandates can backfire by removing firms' strategic\nflexibility, reducing investment, and lowering welfare. We extend the model to\nshow that other common interventions can be similarly ineffective. Vertical\nintegration, for instance, only benefits the ecosystem when the data flywheel\neffect is strong enough to overcome the loss of a potentially more efficient\ncompetitor. Likewise, government subsidies intended to spur adoption can be\ncaptured entirely by the incumbent through strategic price and openness\nadjustments, leaving the rest of the value chain worse off. By modeling the\ndeveloper's strategic response to competitive and regulatory pressures, we\nprovide a robust framework for analyzing competition and designing effective\npolicy in the complex and rapidly evolving FM ecosystem."}
{"id": "2510.15547", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.SY", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15547", "abs": "https://arxiv.org/abs/2510.15547", "authors": ["Usman Ali", "Ali Zia", "Waqas Ali", "Umer Ramzan", "Abdul Rehman", "Muhammad Tayyab Chaudhry", "Wei Xiang"], "title": "Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors", "comment": "Submitted to IEEE Sensors Journal", "summary": "Reliable induction motor (IM) fault diagnosis is vital for industrial safety\nand operational continuity, mitigating costly unplanned downtime. Conventional\napproaches often struggle to capture complex multimodal signal relationships,\nare constrained to unimodal data or single fault types, and exhibit performance\ndegradation under noisy or cross-domain conditions. This paper proposes the\nMultimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified\nframework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is\nthe first to integrate contrastive learning within a hypergraph topology\nspecifically designed for multimodal sensor fusion, enabling the joint\nmodelling of intra- and inter-modal dependencies and enhancing generalisation\nbeyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis\nof bearing, stator, and rotor faults, addressing the engineering need for\nconsolidated di- agnostic capabilities. Evaluated on three real-world\nbenchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain\ngeneralisation and resilience to noise, demonstrating its suitability for\nreal-world deployment. An ablation study validates the contribution of each\ncomponent. MM-HCAN provides a scalable and robust solution for comprehensive\nmulti-fault diagnosis, supporting predictive maintenance and extended asset\nlongevity in industrial environments."}
{"id": "2510.15121", "categories": ["econ.GN", "cs.CY", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15121", "abs": "https://arxiv.org/abs/2510.15121", "authors": ["Heather Liddell", "Beth Kelley", "Liz Wachs", "Alberta Carpenter", "Joe Cresko"], "title": "A physically extended EEIO framework for material efficiency assessment in United States manufacturing supply chains", "comment": "9 pages, 4 figures. Accepted manuscript, presented at the REMADE 2025\n  Circular Economy Conference & Tech Summit, Washington DC, April 10-11, 2025", "summary": "A physical assessment of material flows in an economy (e.g., material flow\nquantification) can support the development of sustainable decarbonization and\ncircularity strategies by providing the tangible physical context of industrial\nproduction quantities and supply chain relationships. However, completing a\nphysical assessment is challenging due to the scarcity of high-quality raw data\nand poor harmonization across industry classification systems used in data\nreporting. Here we describe a new physical extension for the U.S. Department of\nEnergy's (DOE's) EEIO for Industrial Decarbonization (EEIO-IDA) model, yielding\nan expanded EEIO model that is both physically and environmentally extended. In\nthe model framework, the U.S. economy is divided into goods-producing and\nservice-producing subsectors, and mass flows are quantified for each\ngoods-producing subsector using a combination of trade data (e.g., UN Comtrade)\nand physical production data (e.g., U.S. Geological Survey). Given that\nprimary-source production data are not available for all subsectors,\nprice-imputation and mass-balance assumptions are developed and used to\ncomplete the physical flows dataset with high-quality estimations. The\nresulting dataset, when integrated with the EEIO-IDA tool, enables the\nquantification of environmental impact intensity metrics on a mass basis (e.g.,\nCO$_2$eq/kg)) for each industrial subsector. This work is designed to align\nwith existing DOE frameworks and tools, including the EEIO-IDA tool, the DOE\nIndustrial Decarbonization Roadmap (2022), and Pathways for U.S. Industrial\nTransformations study (2025)."}
{"id": "2510.15011", "categories": ["stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.15011", "abs": "https://arxiv.org/abs/2510.15011", "authors": ["Tomasz Serafin", "Weronika Nitka"], "title": "Data-driven Calibration Sample Selection and Forecast Combination in Electricity Price Forecasting: An Application of the ARHNN Method", "comment": null, "summary": "Calibration sample selection and forecast combination are two simple yet\npowerful tools used in forecasting. They can be combined with a variety of\nmodels to significantly improve prediction accuracy, at the same time offering\neasy implementation and low computational complexity. While their effectiveness\nhas been repeatedly confirmed in prior scientific literature, the topic is\nstill underexplored in the field of electricity price forecasting. In this\nresearch article we apply the Autoregressive Hybrid Nearest Neighbors (ARHNN)\nmethod to three long-term time series describing the German, Spanish and New\nEngland electricity markets. We show that it outperforms popular literature\nbenchmarks in terms of forecast accuracy by up to 10%. We also propose two\nsimplified variants of the method, granting a vast decrease in computation time\nwith only minor loss of prediction accuracy. Finally, we compare the forecasts'\nperformance in a battery storage system trading case study. We find that using\na forecast-driven strategy can achieve up to 80% of theoretical maximum profits\nwhile trading, demonstrating business value in practical applications."}
{"id": "2510.15114", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15114", "abs": "https://arxiv.org/abs/2510.15114", "authors": ["Marios-Nektarios Stamatopoulos", "Elias Small", "Shridhar Velhal", "Avijit Banerjee", "George Nikolakopoulos"], "title": "Autonomous Reactive Masonry Construction using Collaborative Heterogeneous Aerial Robots with Experimental Demonstration", "comment": null, "summary": "This article presents a fully autonomous aerial masonry construction\nframework using heterogeneous unmanned aerial vehicles (UAVs), supported by\nexperimental validation. Two specialized UAVs were developed for the task: (i)\na brick-carrier UAV equipped with a ball-joint actuation mechanism for precise\nbrick manipulation, and (ii) an adhesion UAV integrating a servo-controlled\nvalve and extruder nozzle for accurate adhesion application. The proposed\nframework employs a reactive mission planning unit that combines a dependency\ngraph of the construction layout with a conflict graph to manage simultaneous\ntask execution, while hierarchical state machines ensure robust operation and\nsafe transitions during task execution. Dynamic task allocation allows\nreal-time adaptation to environmental feedback, while minimum-jerk trajectory\ngeneration ensures smooth and precise UAV motion during brick pickup and\nplacement. Additionally, the brick-carrier UAV employs an onboard vision system\nthat estimates brick poses in real time using ArUco markers and a least-squares\noptimization filter, enabling accurate alignment during construction. To the\nbest of the authors' knowledge, this work represents the first experimental\ndemonstration of fully autonomous aerial masonry construction using\nheterogeneous UAVs, where one UAV precisely places the bricks while another\nautonomously applies adhesion material between them. The experimental results\nsupported by the video showcase the effectiveness of the proposed framework and\ndemonstrate its potential to serve as a foundation for future developments in\nautonomous aerial robotic construction."}
{"id": "2510.15324", "categories": ["econ.EM", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.15324", "abs": "https://arxiv.org/abs/2510.15324", "authors": ["Tatsuru Kikuchi"], "title": "Dynamic Spatial Treatment Effects as Continuous Functionals: Theory and Evidence from Healthcare Access", "comment": "68 pages, 10 figures", "summary": "I develop a continuous functional framework for spatial treatment effects\ngrounded in Navier-Stokes partial differential equations. Rather than discrete\ntreatment parameters, the framework characterizes treatment intensity as\ncontinuous functions $\\tau(\\mathbf{x}, t)$ over space-time, enabling rigorous\nanalysis of boundary evolution, spatial gradients, and cumulative exposure.\nEmpirical validation using 32,520 U.S. ZIP codes demonstrates exponential\nspatial decay for healthcare access ($\\kappa = 0.002837$ per km, $R^2 =\n0.0129$) with detectable boundaries at 37.1 km. The framework successfully\ndiagnoses when scope conditions hold: positive decay parameters validate\ndiffusion assumptions near hospitals, while negative parameters correctly\nsignal urban confounding effects. Heterogeneity analysis reveals 2-13 $\\times$\nstronger distance effects for elderly populations and substantial education\ngradients. Model selection strongly favors logarithmic decay over exponential\n($\\Delta \\text{AIC} > 10,000$), representing a middle ground between\nexponential and power-law decay. Applications span environmental economics,\nbanking, and healthcare policy. The continuous functional framework provides\npredictive capability ($d^*(t) = \\xi^* \\sqrt{t}$), parameter sensitivity\n($\\partial d^*/\\partial \\nu$), and diagnostic tests unavailable in traditional\ndifference-in-differences approaches."}
{"id": "2510.15121", "categories": ["econ.GN", "cs.CY", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15121", "abs": "https://arxiv.org/abs/2510.15121", "authors": ["Heather Liddell", "Beth Kelley", "Liz Wachs", "Alberta Carpenter", "Joe Cresko"], "title": "A physically extended EEIO framework for material efficiency assessment in United States manufacturing supply chains", "comment": "9 pages, 4 figures. Accepted manuscript, presented at the REMADE 2025\n  Circular Economy Conference & Tech Summit, Washington DC, April 10-11, 2025", "summary": "A physical assessment of material flows in an economy (e.g., material flow\nquantification) can support the development of sustainable decarbonization and\ncircularity strategies by providing the tangible physical context of industrial\nproduction quantities and supply chain relationships. However, completing a\nphysical assessment is challenging due to the scarcity of high-quality raw data\nand poor harmonization across industry classification systems used in data\nreporting. Here we describe a new physical extension for the U.S. Department of\nEnergy's (DOE's) EEIO for Industrial Decarbonization (EEIO-IDA) model, yielding\nan expanded EEIO model that is both physically and environmentally extended. In\nthe model framework, the U.S. economy is divided into goods-producing and\nservice-producing subsectors, and mass flows are quantified for each\ngoods-producing subsector using a combination of trade data (e.g., UN Comtrade)\nand physical production data (e.g., U.S. Geological Survey). Given that\nprimary-source production data are not available for all subsectors,\nprice-imputation and mass-balance assumptions are developed and used to\ncomplete the physical flows dataset with high-quality estimations. The\nresulting dataset, when integrated with the EEIO-IDA tool, enables the\nquantification of environmental impact intensity metrics on a mass basis (e.g.,\nCO$_2$eq/kg)) for each industrial subsector. This work is designed to align\nwith existing DOE frameworks and tools, including the EEIO-IDA tool, the DOE\nIndustrial Decarbonization Roadmap (2022), and Pathways for U.S. Industrial\nTransformations study (2025)."}
{"id": "2510.15045", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15045", "abs": "https://arxiv.org/abs/2510.15045", "authors": ["Ziqing Zhu"], "title": "Q-EnergyDEX: A Zero-Trust Distributed Energy Trading Framework Driven by Quantum Key Distribution and Blockchain", "comment": null, "summary": "The rapid decentralization and digitalization of local electricity markets\nhave introduced new cyber-physical vulnerabilities, including key leakage, data\ntampering, and identity spoofing. Existing blockchain-based solutions provide\ntransparency and traceability but still depend on classical cryptographic\nprimitives that are vulnerable to quantum attacks. To address these challenges,\nthis paper proposes Q-EnergyDEX, a zero-trust distributed energy trading\nframework driven by quantum key distribution and blockchain. The framework\nintegrates physical-layer quantum randomness with market-level operations,\nproviding an end-to-end quantum-secured infrastructure. A cloud-based Quantum\nKey Management Service continuously generates verifiable entropy and regulates\nkey generation through a rate-adaptive algorithm to sustain high-quality\nrandomness. A symmetric authentication protocol (Q-SAH) establishes secure and\nlow-latency sessions, while the quantum-aided consensus mechanism (PoR-Lite)\nachieves probabilistic ledger finality within a few seconds. Furthermore, a\nStackelberg-constrained bilateral auction couples market clearing with entropy\navailability, ensuring both economic efficiency and cryptographic security.\nSimulation results show that Q-EnergyDEX maintains robust key stability and\nnear-optimal social welfare, demonstrating its feasibility for large-scale\ndecentralized energy markets."}
{"id": "2510.15045", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15045", "abs": "https://arxiv.org/abs/2510.15045", "authors": ["Ziqing Zhu"], "title": "Q-EnergyDEX: A Zero-Trust Distributed Energy Trading Framework Driven by Quantum Key Distribution and Blockchain", "comment": null, "summary": "The rapid decentralization and digitalization of local electricity markets\nhave introduced new cyber-physical vulnerabilities, including key leakage, data\ntampering, and identity spoofing. Existing blockchain-based solutions provide\ntransparency and traceability but still depend on classical cryptographic\nprimitives that are vulnerable to quantum attacks. To address these challenges,\nthis paper proposes Q-EnergyDEX, a zero-trust distributed energy trading\nframework driven by quantum key distribution and blockchain. The framework\nintegrates physical-layer quantum randomness with market-level operations,\nproviding an end-to-end quantum-secured infrastructure. A cloud-based Quantum\nKey Management Service continuously generates verifiable entropy and regulates\nkey generation through a rate-adaptive algorithm to sustain high-quality\nrandomness. A symmetric authentication protocol (Q-SAH) establishes secure and\nlow-latency sessions, while the quantum-aided consensus mechanism (PoR-Lite)\nachieves probabilistic ledger finality within a few seconds. Furthermore, a\nStackelberg-constrained bilateral auction couples market clearing with entropy\navailability, ensuring both economic efficiency and cryptographic security.\nSimulation results show that Q-EnergyDEX maintains robust key stability and\nnear-optimal social welfare, demonstrating its feasibility for large-scale\ndecentralized energy markets."}
{"id": "2510.15142", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.15142", "abs": "https://arxiv.org/abs/2510.15142", "authors": ["Diana Wolfe", "Matt Price", "Alice Choe", "Fergus Kidd", "Hannah Wagner"], "title": "Revisiting UTAUT for the Age of AI: Understanding Employees AI Adoption and Usage Patterns Through an Extended UTAUT Framework", "comment": "45 pages, 3 figures, 6 tables", "summary": "This study investigates whether demographic factors shape adoption and\nattitudes among employees toward artificial intelligence (AI) technologies at\nwork. Building on an extended Unified Theory of Acceptance and Use of\nTechnology (UTAUT), which reintroduces affective dimensions such as attitude,\nself-efficacy, and anxiety, we surveyed 2,257 professionals across global\nregions and organizational levels within a multinational consulting firm.\nNon-parametric tests examined whether three demographic factors (i.e., years of\nexperience, hierarchical level in the organization, and geographic region) were\nassociated with AI adoption, usage intensity, and eight UTAUT constructs.\nOrganizational level significantly predicted AI adoption, with senior employees\nshowing higher usage rates, while experience and region were unrelated to\nadoption. Among AI users (n = 1,256), frequency and duration of use showed\nminimal demographic variation. However, omnibus tests revealed small but\nconsistent group differences across several UTAUT constructs, particularly\nanxiety, performance expectancy, and behavioral intention, suggesting that\nemotional and cognitive responses to AI vary modestly across contexts. These\nfindings highlight that demographic factors explain limited variance in AI\nacceptance but remain relevant for understanding contextual nuances in\ntechnology-related attitudes. The results underscore the need to integrate\naffective and organizational factors into models of technology acceptance to\nsupport equitable, confident, and sustainable engagement with AI in modern\nworkplaces."}
{"id": "2510.15096", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15096", "abs": "https://arxiv.org/abs/2510.15096", "authors": ["Alana Renda", "Jillian Ross", "Michael Cafarella", "Jacob Andreas"], "title": "OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data", "comment": null, "summary": "Real-world settings where language models (LMs) are deployed -- in domains\nspanning healthcare, finance, and other forms of knowledge work -- require\nmodels to grapple with incomplete information and reason under uncertainty. Yet\nmost LM evaluations focus on problems with well-defined answers and success\ncriteria. This gap exists in part because natural problems involving\nuncertainty are difficult to construct: given that LMs have access to most of\nthe same knowledge as humans, it is non-trivial to design questions for which\nLMs will struggle to produce correct answers, but which humans can answer\nreliably. As a result, LM performance on reasoning under uncertainty remains\npoorly characterized. To address this gap, we introduce OpenEstimate, an\nextensible, multi-domain benchmark for evaluating LMs on numerical estimation\ntasks that require models to synthesize significant amounts of background\ninformation and express predictions as probabilistic priors. We assess these\npriors for accuracy and calibration, quantifying their usefulness relative to\nsamples from the true distribution of interest. Across six frontier LMs, we\nfind that LM-elicited priors are often inaccurate and overconfident.\nPerformance improves modestly depending on how uncertainty is elicited from the\nmodel, but is largely unaffected by changes in sampling strategy, reasoning\neffort, or prompt design. The OpenEstimate benchmark thus offers a challenging\nevaluation for frontier LMs and a platform for developing models that are\nbetter at probabilistic estimation and reasoning under uncertainty."}
{"id": "2510.15045", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15045", "abs": "https://arxiv.org/abs/2510.15045", "authors": ["Ziqing Zhu"], "title": "Q-EnergyDEX: A Zero-Trust Distributed Energy Trading Framework Driven by Quantum Key Distribution and Blockchain", "comment": null, "summary": "The rapid decentralization and digitalization of local electricity markets\nhave introduced new cyber-physical vulnerabilities, including key leakage, data\ntampering, and identity spoofing. Existing blockchain-based solutions provide\ntransparency and traceability but still depend on classical cryptographic\nprimitives that are vulnerable to quantum attacks. To address these challenges,\nthis paper proposes Q-EnergyDEX, a zero-trust distributed energy trading\nframework driven by quantum key distribution and blockchain. The framework\nintegrates physical-layer quantum randomness with market-level operations,\nproviding an end-to-end quantum-secured infrastructure. A cloud-based Quantum\nKey Management Service continuously generates verifiable entropy and regulates\nkey generation through a rate-adaptive algorithm to sustain high-quality\nrandomness. A symmetric authentication protocol (Q-SAH) establishes secure and\nlow-latency sessions, while the quantum-aided consensus mechanism (PoR-Lite)\nachieves probabilistic ledger finality within a few seconds. Furthermore, a\nStackelberg-constrained bilateral auction couples market clearing with entropy\navailability, ensuring both economic efficiency and cryptographic security.\nSimulation results show that Q-EnergyDEX maintains robust key stability and\nnear-optimal social welfare, demonstrating its feasibility for large-scale\ndecentralized energy markets."}
{"id": "2510.15307", "categories": ["econ.GN", "cs.GT", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15307", "abs": "https://arxiv.org/abs/2510.15307", "authors": ["Venkat Ram Reddy Ganuthula", "Manish Kumar Singh"], "title": "Strategic Interactions in Academic Dishonesty: A Game-Theoretic Analysis of the Exam Script Swapping Mechanism", "comment": null, "summary": "This paper presents a novel game theoretic framework for analyzing academic\ndishonesty through the lens of a unique deterrent mechanism: forced exam script\nswapping between students caught copying. We model the strategic interactions\nbetween students as a non cooperative game with asymmetric information and\nexamine three base scenarios asymmetric preparation levels, mutual non\npreparation, and coordinated partial preparation. Our analysis reveals that the\nscript swapping punishment creates a stronger deterrent effect than traditional\npenalties by introducing strategic interdependence in outcomes. The Nash\nequilibrium analysis demonstrates that mutual preparation emerges as the\ndominant strategy. The framework provides insights for institutional policy\ndesign, suggesting that unconventional punishment mechanisms that create mutual\nvulnerability can be more effective than traditional individual penalties.\nFuture empirical validation and behavioral experiments are proposed to test the\nmodel predictions, including explorations of tapering off effects in punishment\nseverity over time."}
{"id": "2510.15105", "categories": ["stat.AP", "Primary 62P12, Secondary 62P10, 62H25, 62J07"], "pdf": "https://arxiv.org/pdf/2510.15105", "abs": "https://arxiv.org/abs/2510.15105", "authors": ["Mengxiang Zhu", "Riccardo Rastelli"], "title": "Bayesian Additive Regression Trees (BART) in Food Authenticity: A Classification Approach to Food Fraud Detection", "comment": "20 pages, including 12 figures and 4 tables. Preprint under review.\n  Not published", "summary": "Feature engineering plays a critical role in handling hyperspectral data and\nis essential for identifying key wavelengths in food fraud detection. This\nstudy employs Bayesian Additive Regression Trees (BART), a flexible machine\nlearning approach, to discriminate and classify samples of olive oil based on\ntheir level of purity. Leveraging its built-in variable selection mechanism, we\nemploy BART to effectively identify the most representative spectral features\nand to capture the complex interactions among variables. We use network\nrepresentation to illustrate our findings, highlighting the competitiveness of\nour proposed methodology. Results demonstrate that when principal component\nanalysis is used for dimensionality reduction, BART outperforms\nstate-of-the-art models, achieving a classification accuracy of 96.8\\% under\ndefault settings, which further improves to 97.2\\% after hyperparameter tuning.\nIf we leverage a variable selection procedure within BART, the model achieves\nperfect classification performance on this dataset, improving upon previous\noptimal results both in terms of accuracy and interpretability. Our results\ndemonstrate that three key wavelengths, 1160.71 nm, 1328.57 nm, and 1389.29 nm,\nplay a central role in discriminating the olive oil samples, thus highlighting\nan application of our methodology in the context of food quality. Further\nanalysis reveals that these variables do not function independently but rather\ninteract synergistically to achieve accurate classification, and improved\ndetection speed."}
{"id": "2510.15189", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15189", "abs": "https://arxiv.org/abs/2510.15189", "authors": ["Xiangyu Chen", "Chuhao Zhou", "Yuxi Liu", "Jianfei Yang"], "title": "RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation", "comment": null, "summary": "Precise robot manipulation is critical for fine-grained applications such as\nchemical and biological experiments, where even small errors (e.g., reagent\nspillage) can invalidate an entire task. Existing approaches often rely on\npre-collected expert demonstrations and train policies via imitation learning\n(IL) or offline reinforcement learning (RL). However, obtaining high-quality\ndemonstrations for precision tasks is difficult and time-consuming, while\noffline RL commonly suffers from distribution shifts and low data efficiency.\nWe introduce a Role-Model Reinforcement Learning (RM-RL) framework that unifies\nonline and offline training in real-world environments. The key idea is a\nrole-model strategy that automatically generates labels for online training\ndata using approximately optimal actions, eliminating the need for human\ndemonstrations. RM-RL reformulates policy learning as supervised training,\nreducing instability from distribution mismatch and improving efficiency. A\nhybrid training scheme further leverages online role-model data for offline\nreuse, enhancing data efficiency through repeated sampling. Extensive\nexperiments show that RM-RL converges faster and more stably than existing RL\nmethods, yielding significant gains in real-world manipulation: 53% improvement\nin translation accuracy and 20% in rotation accuracy. Finally, we demonstrate\nthe successful execution of a challenging task, precisely placing a cell plate\nonto a shelf, highlighting the framework's effectiveness where prior methods\nfail."}
{"id": "2510.15307", "categories": ["econ.GN", "cs.GT", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15307", "abs": "https://arxiv.org/abs/2510.15307", "authors": ["Venkat Ram Reddy Ganuthula", "Manish Kumar Singh"], "title": "Strategic Interactions in Academic Dishonesty: A Game-Theoretic Analysis of the Exam Script Swapping Mechanism", "comment": null, "summary": "This paper presents a novel game theoretic framework for analyzing academic\ndishonesty through the lens of a unique deterrent mechanism: forced exam script\nswapping between students caught copying. We model the strategic interactions\nbetween students as a non cooperative game with asymmetric information and\nexamine three base scenarios asymmetric preparation levels, mutual non\npreparation, and coordinated partial preparation. Our analysis reveals that the\nscript swapping punishment creates a stronger deterrent effect than traditional\npenalties by introducing strategic interdependence in outcomes. The Nash\nequilibrium analysis demonstrates that mutual preparation emerges as the\ndominant strategy. The framework provides insights for institutional policy\ndesign, suggesting that unconventional punishment mechanisms that create mutual\nvulnerability can be more effective than traditional individual penalties.\nFuture empirical validation and behavioral experiments are proposed to test the\nmodel predictions, including explorations of tapering off effects in punishment\nseverity over time."}
{"id": "2510.15071", "categories": ["eess.SY", "cs.SY", "math.DG"], "pdf": "https://arxiv.org/pdf/2510.15071", "abs": "https://arxiv.org/abs/2510.15071", "authors": ["Ahmed Ali", "Chiara Gabellieri", "Antonio Franchi"], "title": "Exploring a New Design Paradigm for Omnidirectional MAVs for Minimal Actuation and Internal Force Elimination: Theoretical Framework and Control", "comment": null, "summary": "This paper presents a novel concept for achieving omnidirectionality in a\nmultirotor aerial vehicle (MAV) that uses only 6 inputs and ensures no internal\nforces at the equilibria. The concept integrates a single actively-tilting\npropeller along with 3 pendulum-like links, each carrying a propeller,\nconnected by passive universal joints to the main body. We show that this\ndesign ensures omnidirectionality while minimizing the internal forces and\nwithout resorting to overactuation (i.e., more than 6 inputs). A detailed\ndynamic model of the multi-link MAV is first developed. Afterwards, the\nanalysis identifies the equilibrium configurations and illustrates that a\nforced equilibrium exists for every pose of the MAV's main platform. In order\nto render this equilibrium asymptotically stable for the closed-loop system, a\ngeometric nonlinear controller is constructed using dynamic feedback\nlinearization and backstepping techniques with the main platform configuration\nerror being the left-trivialized error on SE(3). The stability of the\nclosed-loop system is then investigated by employing standard Lyapunov\narguments on the zero dynamics. We conclude by providing numerical simulations\nvalidating the proposed approach. They demonstrate the MAV capability to\nperform decoupled attitude and translational motions under non-zero initial\nconditions, parametric uncertainty, and actuators noise."}
{"id": "2510.15071", "categories": ["eess.SY", "cs.SY", "math.DG"], "pdf": "https://arxiv.org/pdf/2510.15071", "abs": "https://arxiv.org/abs/2510.15071", "authors": ["Ahmed Ali", "Chiara Gabellieri", "Antonio Franchi"], "title": "Exploring a New Design Paradigm for Omnidirectional MAVs for Minimal Actuation and Internal Force Elimination: Theoretical Framework and Control", "comment": null, "summary": "This paper presents a novel concept for achieving omnidirectionality in a\nmultirotor aerial vehicle (MAV) that uses only 6 inputs and ensures no internal\nforces at the equilibria. The concept integrates a single actively-tilting\npropeller along with 3 pendulum-like links, each carrying a propeller,\nconnected by passive universal joints to the main body. We show that this\ndesign ensures omnidirectionality while minimizing the internal forces and\nwithout resorting to overactuation (i.e., more than 6 inputs). A detailed\ndynamic model of the multi-link MAV is first developed. Afterwards, the\nanalysis identifies the equilibrium configurations and illustrates that a\nforced equilibrium exists for every pose of the MAV's main platform. In order\nto render this equilibrium asymptotically stable for the closed-loop system, a\ngeometric nonlinear controller is constructed using dynamic feedback\nlinearization and backstepping techniques with the main platform configuration\nerror being the left-trivialized error on SE(3). The stability of the\nclosed-loop system is then investigated by employing standard Lyapunov\narguments on the zero dynamics. We conclude by providing numerical simulations\nvalidating the proposed approach. They demonstrate the MAV capability to\nperform decoupled attitude and translational motions under non-zero initial\nconditions, parametric uncertainty, and actuators noise."}
{"id": "2510.15256", "categories": ["cs.CY", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.15256", "abs": "https://arxiv.org/abs/2510.15256", "authors": ["Ricardo Alonzo Fernández Salguero"], "title": "From Murals to Memes: A Theory of Aesthetic Asymmetry in Political Mobilization", "comment": null, "summary": "Why have left-wing movements historically integrated participatory art forms\n(such as murals and protest songs) into their praxis, while right-wing\nmovements have prioritized strategic communication and, more recently, the\ndigital culture of memes? This article introduces the concept of aesthetic\nasymmetry to explain this divergence in political action. We argue that the\nasymmetry is not coincidental but the result of four interconnected structural\nfactors: the organizational ecosystem, the moral and emotional framework, the\nmaterial supports, and the historical tradition of each political spectrum.\nWhile the left tends to use art in a constitutive manner to forge community,\nsolidarity, and hope, the contemporary right tends to use it instrumentally to\nmobilize polarizing affects such as humor and resentment. Drawing on\ncomparative literature from the Theatre of the Oppressed to analyses of\nalt-right meme wars, we nuance this distinction and show how the aesthetic\nlogic of each pole aligns with its strategic objectives. The article culminates\nin a prescriptive model for artistic action, synthesizing keys to effective\nmobilization into emotional, narrative, and formatting strategies.\nUnderstanding this asymmetry is crucial for analyzing political communication\nand for designing cultural interventions capable of generating profound social\nchange."}
{"id": "2510.15120", "categories": ["cs.AI", "I.2.6, I.2.8, I.2.11, I.3.7"], "pdf": "https://arxiv.org/pdf/2510.15120", "abs": "https://arxiv.org/abs/2510.15120", "authors": ["Miraç Buğra Özkan"], "title": "Procedural Game Level Design with Deep Reinforcement Learning", "comment": "11 pages, 10 figures, IEEE conference format", "summary": "Procedural content generation (PCG) has become an increasingly popular\ntechnique in game development, allowing developers to generate dynamic,\nreplayable, and scalable environments with reduced manual effort. In this\nstudy, a novel method for procedural level design using Deep Reinforcement\nLearning (DRL) within a Unity-based 3D environment is proposed. The system\ncomprises two agents: a hummingbird agent, acting as a solver, and a floating\nisland agent, responsible for generating and placing collectible objects\n(flowers) on the terrain in a realistic and context-aware manner. The\nhummingbird is trained using the Proximal Policy Optimization (PPO) algorithm\nfrom the Unity ML-Agents toolkit. It learns to navigate through the terrain\nefficiently, locate flowers, and collect them while adapting to the\never-changing procedural layout of the island. The island agent is also trained\nusing the Proximal Policy Optimization (PPO) algorithm. It learns to generate\nflower layouts based on observed obstacle positions, the hummingbird's initial\nstate, and performance feedback from previous episodes. The interaction between\nthese agents leads to emergent behavior and robust generalization across\nvarious environmental configurations. The results demonstrate that the approach\nnot only produces effective and efficient agent behavior but also opens up new\nopportunities for autonomous game level design driven by machine learning. This\nwork highlights the potential of DRL in enabling intelligent agents to both\ngenerate and solve content in virtual environments, pushing the boundaries of\nwhat AI can contribute to creative game development processes."}
{"id": "2510.15071", "categories": ["eess.SY", "cs.SY", "math.DG"], "pdf": "https://arxiv.org/pdf/2510.15071", "abs": "https://arxiv.org/abs/2510.15071", "authors": ["Ahmed Ali", "Chiara Gabellieri", "Antonio Franchi"], "title": "Exploring a New Design Paradigm for Omnidirectional MAVs for Minimal Actuation and Internal Force Elimination: Theoretical Framework and Control", "comment": null, "summary": "This paper presents a novel concept for achieving omnidirectionality in a\nmultirotor aerial vehicle (MAV) that uses only 6 inputs and ensures no internal\nforces at the equilibria. The concept integrates a single actively-tilting\npropeller along with 3 pendulum-like links, each carrying a propeller,\nconnected by passive universal joints to the main body. We show that this\ndesign ensures omnidirectionality while minimizing the internal forces and\nwithout resorting to overactuation (i.e., more than 6 inputs). A detailed\ndynamic model of the multi-link MAV is first developed. Afterwards, the\nanalysis identifies the equilibrium configurations and illustrates that a\nforced equilibrium exists for every pose of the MAV's main platform. In order\nto render this equilibrium asymptotically stable for the closed-loop system, a\ngeometric nonlinear controller is constructed using dynamic feedback\nlinearization and backstepping techniques with the main platform configuration\nerror being the left-trivialized error on SE(3). The stability of the\nclosed-loop system is then investigated by employing standard Lyapunov\narguments on the zero dynamics. We conclude by providing numerical simulations\nvalidating the proposed approach. They demonstrate the MAV capability to\nperform decoupled attitude and translational motions under non-zero initial\nconditions, parametric uncertainty, and actuators noise."}
{"id": "2510.15399", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15399", "abs": "https://arxiv.org/abs/2510.15399", "authors": ["Pooja Batra", "Ajay Sharma"], "title": "International migration and dietary diversity of left-behind households: evidence from India", "comment": "Published in Food Security", "summary": "In this paper, we analyse the impact of international migration on the food\nconsumption and dietary diversity of left-behind households. Using the Kerala\nmigration survey 2011, we study whether households with emigrants (on account\nof international migration) have higher consumption expenditure and improved\ndietary diversity than their non-migrating counterparts. We use ordinary least\nsquare and instrumental variable approach to answer this question. The key\nfindings are that: a) emigrant households have higher overall consumption\nexpenditure as well as higher expenditure on food; b) we find that\ninternational migration leads to increase in the dietary diversity of left\nbehind households. Further, we explore the effect on food sub-group expenditure\nfor both rural and urban households. We find that emigrant households spend\nmore on protein (milk, pulses and egg, fish and meat), at the same time there\nis higher spending on non-healthy food habits (processed and ready to eat food\nitems) among them."}
{"id": "2510.15487", "categories": ["stat.AP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15487", "abs": "https://arxiv.org/abs/2510.15487", "authors": ["Manit Mishra"], "title": "AI and analytics in sports: Leveraging BERTopic to map the past and chart the future", "comment": "32 pages, 5 figures, 1 table, accepted for presentation at Australia\n  and New Zealand Marketing Academy (ANZMAC) - 2025 Conference", "summary": "Purpose: The purpose of this study is to map the body of scholarly literature\nat the intersection of artificial intelligence (AI), analytics and sports and\nthereafter, leverage the insights generated to chart guideposts for future\nresearch. Design/methodology/approach: The study carries out systematic\nliterature review (SLR). Preferred Reporting Items for Systematic Reviews and\nMeta-Analysis (PRISMA) protocol is leveraged to identify 204 journal articles\npertaining to utilization of AI and analytics in sports published during 2002\nto 2024. We follow it up with extraction of the latent topics from sampled\narticles by leveraging the topic modelling technique of BERTopic. Findings: The\nstudy identifies the following as predominant areas of extant research on usage\nof AI and analytics in sports: performance modelling, physical and mental\nhealth, social media sentiment analysis, and tactical tracking. Each extracted\ntopic is further examined in terms of its relative prominence, representative\nstudies, and key term associations. Drawing on these insights, the study\ndelineates promising avenues for future inquiry. Research\nlimitations/implications: The study offers insights to academicians and sports\nadministrators on transformational impact of AI and analytics in sports.\nOriginality/value: The study introduces BERTopic as a novel approach for\nextracting latent structures in sports research, thereby advancing both\nscholarly understanding and the methodological toolkit of the field."}
{"id": "2510.15199", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15199", "abs": "https://arxiv.org/abs/2510.15199", "authors": ["Borna Monazzah Moghaddam", "Robin Chhabra"], "title": "Lagrange-Poincaré-Kepler Equations of Disturbed Space-Manipulator Systems in Orbit", "comment": null, "summary": "This article presents an extension of the Lagrange-Poincare Equations (LPE)\nto model the dynamics of spacecraft-manipulator systems operating within a\nnon-inertial orbital reference frame. Building upon prior formulations of LPE\nfor vehicle-manipulator systems, the proposed framework, termed the\nLagrange-Poincare-Kepler Equations (LPKE), incorporates the coupling between\nspacecraft attitude dynamics, orbital motion, and manipulator kinematics. The\nformalism combines the Euler-Poincare equations for the base spacecraft,\nKeplerian orbital dynamics for the reference frame, and reduced Euler-Lagrange\nequations for the manipulator's shape space, using an exponential joint\nparametrization. Leveraging the Lagrange-d'Alembert principle on principal\nbundles, we derive novel closed-form structural matrices that explicitly\ncapture the effects of orbital disturbances and their dynamic coupling with the\nmanipulator system. The LPKE framework also systematically includes externally\napplied, symmetry-breaking wrenches, allowing for immediate integration into\nhardware-in-the-loop simulations and model-based control architectures for\nautonomous robotic operations in the orbital environment. To illustrate the\neffectiveness of the proposed model and its numerical superiority, we present a\nsimulation study analyzing orbital effects on a 7-degree-of-freedom manipulator\nmounted on a spacecraft."}
{"id": "2510.15399", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15399", "abs": "https://arxiv.org/abs/2510.15399", "authors": ["Pooja Batra", "Ajay Sharma"], "title": "International migration and dietary diversity of left-behind households: evidence from India", "comment": "Published in Food Security", "summary": "In this paper, we analyse the impact of international migration on the food\nconsumption and dietary diversity of left-behind households. Using the Kerala\nmigration survey 2011, we study whether households with emigrants (on account\nof international migration) have higher consumption expenditure and improved\ndietary diversity than their non-migrating counterparts. We use ordinary least\nsquare and instrumental variable approach to answer this question. The key\nfindings are that: a) emigrant households have higher overall consumption\nexpenditure as well as higher expenditure on food; b) we find that\ninternational migration leads to increase in the dietary diversity of left\nbehind households. Further, we explore the effect on food sub-group expenditure\nfor both rural and urban households. We find that emigrant households spend\nmore on protein (milk, pulses and egg, fish and meat), at the same time there\nis higher spending on non-healthy food habits (processed and ready to eat food\nitems) among them."}
{"id": "2510.15150", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.15150", "abs": "https://arxiv.org/abs/2510.15150", "authors": ["Tina Gao", "Shimiao Li", "Lawrence Pileggi"], "title": "Sparsity-exploiting Gaussian Process for Robust Transient Learning of Power System Dynamics", "comment": "This manuscript has been submitted to PESGM2026", "summary": "Advances in leveraging Gaussian processes (GP) have enabled learning and\ninferring dynamic grid behavior from scarce PMU measurements. However, real\nmeasurements can be corrupted by various random and targeted threats, leading\nto inaccurate and meaningless results. This paper develops robust transient\nlearning to overcome this challenge by exploiting the sparse corruption\npatterns in the data flow. Specifically, we integrate sparse optimization with\nmethod of moments (MoM) to make learning robust to a sparse distribution of\ndata corruptions; then, we optimize sparse weights to identify corrupted meter\nlocations. To improve inference speed on large-scale systems, we further adopt\nK-medoid clustering of locations to develop dimension reduction (DR) and\naggregate representation (AR) heuristics. Experimental results demonstrate\nrobustness against random large errors, targeted false data injections, and\nlocal PMU clock drifts. On a 1354-bus system, inference turns out to be 18x\nfaster using DR and 400x faster when further combined with AR heuristics."}
{"id": "2510.15150", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.15150", "abs": "https://arxiv.org/abs/2510.15150", "authors": ["Tina Gao", "Shimiao Li", "Lawrence Pileggi"], "title": "Sparsity-exploiting Gaussian Process for Robust Transient Learning of Power System Dynamics", "comment": "This manuscript has been submitted to PESGM2026", "summary": "Advances in leveraging Gaussian processes (GP) have enabled learning and\ninferring dynamic grid behavior from scarce PMU measurements. However, real\nmeasurements can be corrupted by various random and targeted threats, leading\nto inaccurate and meaningless results. This paper develops robust transient\nlearning to overcome this challenge by exploiting the sparse corruption\npatterns in the data flow. Specifically, we integrate sparse optimization with\nmethod of moments (MoM) to make learning robust to a sparse distribution of\ndata corruptions; then, we optimize sparse weights to identify corrupted meter\nlocations. To improve inference speed on large-scale systems, we further adopt\nK-medoid clustering of locations to develop dimension reduction (DR) and\naggregate representation (AR) heuristics. Experimental results demonstrate\nrobustness against random large errors, targeted false data injections, and\nlocal PMU clock drifts. On a 1354-bus system, inference turns out to be 18x\nfaster using DR and 400x faster when further combined with AR heuristics."}
{"id": "2510.15297", "categories": ["cs.CY", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.15297", "abs": "https://arxiv.org/abs/2510.15297", "authors": ["Luca Belli", "Kate Bentley", "Will Alexander", "Emily Ward", "Matt Hawrilenko", "Kelly Johnston", "Mill Brown", "Adam Chekroud"], "title": "VERA-MH Concept Paper", "comment": null, "summary": "We introduce VERA-MH (Validation of Ethical and Responsible AI in Mental\nHealth), an automated evaluation of the safety of AI chatbots used in mental\nhealth contexts, with an initial focus on suicide risk.\n  Practicing clinicians and academic experts developed a rubric informed by\nbest practices for suicide risk management for the evaluation. To fully\nautomate the process, we used two ancillary AI agents. A user-agent model\nsimulates users engaging in a mental health-based conversation with the chatbot\nunder evaluation. The user-agent role-plays specific personas with pre-defined\nrisk levels and other features. Simulated conversations are then passed to a\njudge-agent who scores them based on the rubric. The final evaluation of the\nchatbot being tested is obtained by aggregating the scoring of each\nconversation.\n  VERA-MH is actively under development and undergoing rigorous validation by\nmental health clinicians to ensure user-agents realistically act as patients\nand that the judge-agent accurately scores the AI chatbot. To date we have\nconducted preliminary evaluation of GPT-5, Claude Opus and Claude Sonnet using\ninitial versions of the VERA-MH rubric and used the findings for further design\ndevelopment. Next steps will include more robust clinical validation and\niteration, as well as refining actionable scoring. We are seeking feedback from\nthe community on both the technical and clinical aspects of our evaluation."}
{"id": "2510.15128", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15128", "abs": "https://arxiv.org/abs/2510.15128", "authors": ["Marcus A. Thomas"], "title": "Towards Error Centric Intelligence I, Beyond Observational Learning", "comment": null, "summary": "We argue that progress toward AGI is theory limited rather than data or scale\nlimited. Building on the critical rationalism of Popper and Deutsch, we\nchallenge the Platonic Representation Hypothesis. Observationally equivalent\nworlds can diverge under interventions, so observational adequacy alone cannot\nguarantee interventional competence. We begin by laying foundations,\ndefinitions of knowledge, learning, intelligence, counterfactual competence and\nAGI, and then analyze the limits of observational learning that motivate an\nerror centric shift. We recast the problem as three questions about how\nexplicit and implicit errors evolve under an agent's actions, which errors are\nunreachable within a fixed hypothesis space, and how conjecture and criticism\nexpand that space. From these questions we propose Causal Mechanics, a\nmechanisms first program in which hypothesis space change is a first class\noperation and probabilistic structure is used when useful rather than presumed.\nWe advance structural principles that make error discovery and correction\ntractable, including a differential Locality and Autonomy Principle for modular\ninterventions, a gauge invariant form of Independent Causal Mechanisms for\nseparability, and the Compositional Autonomy Principle for analogy\npreservation, together with actionable diagnostics. The aim is a scaffold for\nsystems that can convert unreachable errors into reachable ones and correct\nthem."}
{"id": "2510.15096", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15096", "abs": "https://arxiv.org/abs/2510.15096", "authors": ["Alana Renda", "Jillian Ross", "Michael Cafarella", "Jacob Andreas"], "title": "OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data", "comment": null, "summary": "Real-world settings where language models (LMs) are deployed -- in domains\nspanning healthcare, finance, and other forms of knowledge work -- require\nmodels to grapple with incomplete information and reason under uncertainty. Yet\nmost LM evaluations focus on problems with well-defined answers and success\ncriteria. This gap exists in part because natural problems involving\nuncertainty are difficult to construct: given that LMs have access to most of\nthe same knowledge as humans, it is non-trivial to design questions for which\nLMs will struggle to produce correct answers, but which humans can answer\nreliably. As a result, LM performance on reasoning under uncertainty remains\npoorly characterized. To address this gap, we introduce OpenEstimate, an\nextensible, multi-domain benchmark for evaluating LMs on numerical estimation\ntasks that require models to synthesize significant amounts of background\ninformation and express predictions as probabilistic priors. We assess these\npriors for accuracy and calibration, quantifying their usefulness relative to\nsamples from the true distribution of interest. Across six frontier LMs, we\nfind that LM-elicited priors are often inaccurate and overconfident.\nPerformance improves modestly depending on how uncertainty is elicited from the\nmodel, but is largely unaffected by changes in sampling strategy, reasoning\neffort, or prompt design. The OpenEstimate benchmark thus offers a challenging\nevaluation for frontier LMs and a platform for developing models that are\nbetter at probabilistic estimation and reasoning under uncertainty."}
{"id": "2510.15405", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15405", "abs": "https://arxiv.org/abs/2510.15405", "authors": ["Ajay Sharma"], "title": "Impact of Three-Point Rule Change on Competitive Balance in Football: A Synthetic Control Method Approach", "comment": "Published in Applied Economics", "summary": "Governing authorities in sports often make changes to rules and regulations\nto increase competitiveness. One such change was made by the English Football\nAssociation in 1981 when it changed the rule for awarding points in the\ndomestic league from two points for a win to three points. This study aims to\nmeasure this rule change's impact on the domestic league's competitive balance\nusing a quasi-experimental estimation design of a synthetic control method. The\nthree-point rule change led to an increase in competitive balance in the\nEnglish League. Further, we show no significant change in the number of goals\nscored per match."}
{"id": "2510.15572", "categories": ["stat.AP", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.15572", "abs": "https://arxiv.org/abs/2510.15572", "authors": ["Kamel Lahssini", "Guerric le Maire", "Nicolas Baghdadi", "Ibrahim Fayad"], "title": "Residual Kriging for Regional-Scale Canopy Height Mapping: Insights into GEDI-Induced Anisotropies and Sparse Sampling", "comment": "22 pages, 12 figures", "summary": "Quantifying aboveground biomass (AGB) is essential in the context of global\nclimate change. Canopy height, which is related to AGB, can be mapped using\nmachine learning models trained with multi-source spatial data and GEDI\nmeasurements. In this study, a comparative analysis of canopy height estimates\nderived from two models is presented: a U-Net deep learning model (CHNET) and a\nRandom Forest algorithm (RFH). Both models were trained using GEDI lidar data\nand utilized multi-source inputs, including optical, radar, and environmental\ndata. While CHNET can leverage its convolutional architecture to account for\nspatial correlations, we observed that it does not fully incorporate all the\nspatial autocorrelation present in GEDI canopy height measurements. By\nconducting a spatial analysis of the models' residuals, we also identified that\nGEDI data acquisition parameters, particularly the variability in laser beam\nenergy combined with the azimuthal directions of the observation tracks,\nintroduce spatial inconsistencies in the measurements in the form of periodic\npatterns. To address these anisotropies, we considered exclusively GEDI power\nbeams, and we conducted our spatial autocorrelation analysis in the GEDI track\nazimuthal direction. Next, we employed the residual kriging (RK) spatial\ninterpolation technique to account for the spatial autocorrelation of canopy\nheights and improve the accuracies of CHNET and RFH estimates. Adding RK\ncorrections improved the performance of both CHNET and RFH, with more\nsubstantial gains observed for RFH. The corrections appeared to be localized\naround the GEDI sample points and the density of usable GEDI information is\ntherefore an important factor in the effectiveness of spatial interpolation.\nFurthermore, our findings reveal that a Random Forest model combined with\nspatial interpolation can deliver performance comparable to that of a U-Net\nmodel alone."}
{"id": "2510.15220", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15220", "abs": "https://arxiv.org/abs/2510.15220", "authors": ["Kevin Christiansen Marsim", "Minho Oh", "Byeongho Yu", "Seungjae Lee", "I Made Aswin Nahrendra", "Hyungtae Lim", "Hyun Myung"], "title": "LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization", "comment": "8 Pages, 9 Figures", "summary": "Autonomous navigation for legged robots in complex and dynamic environments\nrelies on robust simultaneous localization and mapping (SLAM) systems to\naccurately map surroundings and localize the robot, ensuring safe and efficient\noperation. While prior sensor fusion-based SLAM approaches have integrated\nvarious sensor modalities to improve their robustness, these algorithms are\nstill susceptible to estimation drift in challenging environments due to their\nreliance on unsuitable fusion strategies. Therefore, we propose a robust\nLiDAR-visual-inertial-kinematic odometry system that integrates information\nfrom multiple sensors, such as a camera, LiDAR, inertial measurement unit\n(IMU), and joint encoders, for visual and LiDAR-based odometry estimation. Our\nsystem employs a fusion-based pose estimation approach that runs\noptimization-based visual-inertial-kinematic odometry (VIKO) and filter-based\nLiDAR-inertial-kinematic odometry (LIKO) based on measurement availability. In\nVIKO, we utilize the footpreintegration technique and robust LiDAR-visual depth\nconsistency using superpixel clusters in a sliding window optimization. In\nLIKO, we incorporate foot kinematics and employ a point-toplane residual in an\nerror-state iterative Kalman filter (ESIKF). Compared with other sensor\nfusion-based SLAM algorithms, our approach shows robust performance across\npublic and longterm datasets."}
{"id": "2510.15405", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15405", "abs": "https://arxiv.org/abs/2510.15405", "authors": ["Ajay Sharma"], "title": "Impact of Three-Point Rule Change on Competitive Balance in Football: A Synthetic Control Method Approach", "comment": "Published in Applied Economics", "summary": "Governing authorities in sports often make changes to rules and regulations\nto increase competitiveness. One such change was made by the English Football\nAssociation in 1981 when it changed the rule for awarding points in the\ndomestic league from two points for a win to three points. This study aims to\nmeasure this rule change's impact on the domestic league's competitive balance\nusing a quasi-experimental estimation design of a synthetic control method. The\nthree-point rule change led to an increase in competitive balance in the\nEnglish League. Further, we show no significant change in the number of goals\nscored per match."}
{"id": "2510.15152", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15152", "abs": "https://arxiv.org/abs/2510.15152", "authors": ["Wenxin Zhang", "Yueying Li", "Ciamac C. Moallemi", "Tianyi Peng"], "title": "Tail-Optimized Caching for LLM Inference", "comment": null, "summary": "Prompt caching is critical for reducing latency and cost in LLM inference:\nOpenAI and Anthropic report up to 50-90% cost savings through prompt reuse.\nDespite its widespread success, little is known about what constitutes an\noptimal prompt caching policy, particularly when optimizing tail latency, a\nmetric of central importance to practitioners. The widely used Least Recently\nUsed (LRU) policy can perform arbitrarily poor on this metric, as it is\noblivious to the heterogeneity of conversation lengths. To address this gap, we\npropose Tail-Optimized LRU, a simple two-line modification that reallocates KV\ncache capacity to prioritize high-latency conversations by evicting cache\nentries that are unlikely to affect future turns. Though the implementation is\nsimple, we prove its optimality under a natural stochastic model of\nconversation dynamics, providing the first theoretical justification for LRU in\nthis setting, a result that may be of independent interest to the caching\ncommunity. Experimentally, on real conversation data WildChat, Tail-Optimized\nLRU achieves up to 27.5% reduction in P90 tail Time to First Token latency and\n23.9% in P95 tail latency compared to LRU, along with up to 38.9% decrease in\nSLO violations of 200ms. We believe this provides a practical and theoretically\ngrounded option for practitioners seeking to optimize tail latency in\nreal-world LLM deployments."}
{"id": "2510.15152", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15152", "abs": "https://arxiv.org/abs/2510.15152", "authors": ["Wenxin Zhang", "Yueying Li", "Ciamac C. Moallemi", "Tianyi Peng"], "title": "Tail-Optimized Caching for LLM Inference", "comment": null, "summary": "Prompt caching is critical for reducing latency and cost in LLM inference:\nOpenAI and Anthropic report up to 50-90% cost savings through prompt reuse.\nDespite its widespread success, little is known about what constitutes an\noptimal prompt caching policy, particularly when optimizing tail latency, a\nmetric of central importance to practitioners. The widely used Least Recently\nUsed (LRU) policy can perform arbitrarily poor on this metric, as it is\noblivious to the heterogeneity of conversation lengths. To address this gap, we\npropose Tail-Optimized LRU, a simple two-line modification that reallocates KV\ncache capacity to prioritize high-latency conversations by evicting cache\nentries that are unlikely to affect future turns. Though the implementation is\nsimple, we prove its optimality under a natural stochastic model of\nconversation dynamics, providing the first theoretical justification for LRU in\nthis setting, a result that may be of independent interest to the caching\ncommunity. Experimentally, on real conversation data WildChat, Tail-Optimized\nLRU achieves up to 27.5% reduction in P90 tail Time to First Token latency and\n23.9% in P95 tail latency compared to LRU, along with up to 38.9% decrease in\nSLO violations of 200ms. We believe this provides a practical and theoretically\ngrounded option for practitioners seeking to optimize tail latency in\nreal-world LLM deployments."}
{"id": "2510.15442", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.15442", "abs": "https://arxiv.org/abs/2510.15442", "authors": ["Roger Waldeck", "Ann-Kristin Winkens", "Clara Lemke", "Carmen Leicht-Scholten", "Haraldur Audunsson"], "title": "Identifying curriculum disruptions in engineering education through serious gaming", "comment": null, "summary": "This workshop introduces participants to SUCRE, a serious game designed to\nenhance curriculum resilience in higher education by simulating crisis\nscenarios. While applicable to various disciplines, this session focuses on\nengineering curricula, identifying discipline-specific challenges and potential\nadaptations. Participants will engage in Step 1 of the game, analyzing trigger\nevents and their impacts on curriculum structures. At the end of the workshop,\nattendees will be able to identify key triggers that may affect curricula,\nassess their cascading effects, and reflect on the applicability of SUCRE\nwithin their own institutions."}
{"id": "2510.15144", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.15144", "abs": "https://arxiv.org/abs/2510.15144", "authors": ["Chance Jiajie Li", "Zhenze Mo", "Yuhan Tang", "Ao Qu", "Jiayi Wu", "Kaiya Ivy Zhao", "Yulu Gan", "Jie Fan", "Jiangbo Yu", "Hang Jiang", "Paul Pu Liang", "Jinhua Zhao", "Luis Alberto Alonso Pastor", "Kent Larson"], "title": "HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks", "comment": "To appear in NeurIPS 2025 Workshop on Bridging Language, Agent, and\n  World Models (LAW)", "summary": "Simulating human reasoning in open-ended tasks has been a long-standing\naspiration in AI and cognitive science. While large language models now\napproximate human responses at scale, they remain tuned to population-level\nconsensus, often erasing the individuality of reasoning styles and belief\ntrajectories. To advance the vision of more human-like reasoning in machines,\nwe introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for\naverage-to-individual reasoning adaptation. The task is to predict how a\nspecific person would reason and update their beliefs in novel scenarios, given\npartial evidence of their past views. HugAgent adopts a dual-track design: a\nsynthetic track for scale and systematic stress tests, and a human track for\necologically valid, \"out-loud\" reasoning data. This design enables scalable,\nreproducible evaluation of intra-agent fidelity: whether models can capture not\njust what people believe, but how their reasoning evolves. Experiments with\nstate-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent\nas the first extensible benchmark for aligning machine reasoning with the\nindividuality of human thought. Our benchmark and chatbot are open-sourced as\nHugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking\n(https://anonymous.4open.science/r/trace-your-thinking)."}
{"id": "2510.15114", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15114", "abs": "https://arxiv.org/abs/2510.15114", "authors": ["Marios-Nektarios Stamatopoulos", "Elias Small", "Shridhar Velhal", "Avijit Banerjee", "George Nikolakopoulos"], "title": "Autonomous Reactive Masonry Construction using Collaborative Heterogeneous Aerial Robots with Experimental Demonstration", "comment": null, "summary": "This article presents a fully autonomous aerial masonry construction\nframework using heterogeneous unmanned aerial vehicles (UAVs), supported by\nexperimental validation. Two specialized UAVs were developed for the task: (i)\na brick-carrier UAV equipped with a ball-joint actuation mechanism for precise\nbrick manipulation, and (ii) an adhesion UAV integrating a servo-controlled\nvalve and extruder nozzle for accurate adhesion application. The proposed\nframework employs a reactive mission planning unit that combines a dependency\ngraph of the construction layout with a conflict graph to manage simultaneous\ntask execution, while hierarchical state machines ensure robust operation and\nsafe transitions during task execution. Dynamic task allocation allows\nreal-time adaptation to environmental feedback, while minimum-jerk trajectory\ngeneration ensures smooth and precise UAV motion during brick pickup and\nplacement. Additionally, the brick-carrier UAV employs an onboard vision system\nthat estimates brick poses in real time using ArUco markers and a least-squares\noptimization filter, enabling accurate alignment during construction. To the\nbest of the authors' knowledge, this work represents the first experimental\ndemonstration of fully autonomous aerial masonry construction using\nheterogeneous UAVs, where one UAV precisely places the bricks while another\nautonomously applies adhesion material between them. The experimental results\nsupported by the video showcase the effectiveness of the proposed framework and\ndemonstrate its potential to serve as a foundation for future developments in\nautonomous aerial robotic construction."}
{"id": "2510.15420", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15420", "abs": "https://arxiv.org/abs/2510.15420", "authors": ["Shweta Bahl", "Ajay Sharma"], "title": "Heterogeneity among migrants, education-occupation mis-match and returns to education: Evidence from India", "comment": "Published in Regional Studies", "summary": "Using nationally representative data for India, this paper examines the\nincidence of education occupation mismatch and returns to education and EOM for\ninternal migrants while considering the heterogeneity among them. In\nparticular, this study considers heterogeneity arising because of the reason to\nmigrate, demographic characteristics, spatial factors, migration experience,\nand type of migration. The analysis reveals that there exists variation in the\nincidence and returns to EOM depending on the reason to migrate, demographic\ncharacteristics, and spatial factors. The study highlights the need of focusing\non EOM to increase the productivity benefits of migration. It also provides the\nframework for minimizing migrants' likelihood of being mismatched while\nmaximizing their returns to education."}
{"id": "2510.15580", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.15580", "abs": "https://arxiv.org/abs/2510.15580", "authors": ["Kyle Stanley", "Nicole Lazar", "Matthew Reimherr"], "title": "Temporal Functional Factor Analysis of Brain Connectivity", "comment": null, "summary": "Many analyses of functional magnetic resonance imaging (fMRI) examine\nfunctional connectivity (FC), or the statistical dependencies among distant\nbrain regions. These analyses are typically exploratory, guiding future\nconfirmatory research. In this work, we present an approach based on factor\nanalysis (FA) that is well-suited to studying FC. FA is appealing in this\ncontext because its flexible model assumptions permit a guided investigation of\nits target subspace consistent with the exploratory role of connectivity\nanalyses. However, applying FA to fMRI data poses three problems: (1) its\ntarget subspace captures short-range spatial dependencies that should be\ntreated as noise, (2) it requires factorization of a massive spatial\ncovariance, and (3) it overlooks temporal dependencies in the data. To address\nthese limitations, we develop a factor model within the framework of functional\ndata analysis--a field which views certain data as arising from smooth\nunderlying curves. The proposed approach (1) uses matrix completion techniques\nto filter short-range spatial dependencies out of its target subspace, (2)\nemploys a distributed algorithm for factorizing large-scale covariance\nmatrices, and (3) leverages functional regression to exploit temporal dynamics.\nTogether, these innovations yield a comprehensive and scalable method for\nstudying FC."}
{"id": "2510.15226", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15226", "abs": "https://arxiv.org/abs/2510.15226", "authors": ["Mrunal Sarvaiya", "Guanrui Li", "Giuseppe Loianno"], "title": "PolyFly: Polytopic Optimal Planning for Collision-Free Cable-Suspended Aerial Payload Transportation", "comment": null, "summary": "Aerial transportation robots using suspended cables have emerged as versatile\nplatforms for disaster response and rescue operations. To maximize the\ncapabilities of these systems, robots need to aggressively fly through tightly\nconstrained environments, such as dense forests and structurally unsafe\nbuildings, while minimizing flight time and avoiding obstacles. Existing\nmethods geometrically over-approximate the vehicle and obstacles, leading to\nconservative maneuvers and increased flight times. We eliminate these\nrestrictions by proposing PolyFly, an optimal global planner which considers a\nnon-conservative representation for aerial transportation by modeling each\nphysical component of the environment, and the robot (quadrotor, cable and\npayload), as independent polytopes. We further increase the model accuracy by\nincorporating the attitude of the physical components by constructing\norientation-aware polytopes. The resulting optimal control problem is\nefficiently solved by converting the polytope constraints into smooth\ndifferentiable constraints via duality theory. We compare our method against\nthe existing state-of-the-art approach in eight maze-like environments and show\nthat PolyFly produces faster trajectories in each scenario. We also\nexperimentally validate our proposed approach on a real quadrotor with a\nsuspended payload, demonstrating the practical reliability and accuracy of our\nmethod."}
{"id": "2510.15420", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15420", "abs": "https://arxiv.org/abs/2510.15420", "authors": ["Shweta Bahl", "Ajay Sharma"], "title": "Heterogeneity among migrants, education-occupation mis-match and returns to education: Evidence from India", "comment": "Published in Regional Studies", "summary": "Using nationally representative data for India, this paper examines the\nincidence of education occupation mismatch and returns to education and EOM for\ninternal migrants while considering the heterogeneity among them. In\nparticular, this study considers heterogeneity arising because of the reason to\nmigrate, demographic characteristics, spatial factors, migration experience,\nand type of migration. The analysis reveals that there exists variation in the\nincidence and returns to EOM depending on the reason to migrate, demographic\ncharacteristics, and spatial factors. The study highlights the need of focusing\non EOM to increase the productivity benefits of migration. It also provides the\nframework for minimizing migrants' likelihood of being mismatched while\nmaximizing their returns to education."}
{"id": "2510.15190", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15190", "abs": "https://arxiv.org/abs/2510.15190", "authors": ["Oumaima Barhoumi", "Ghazal Farhani", "Taufiq Rahman", "Mohamed H. Zaki", "Sofiène Tahar"], "title": "A Comparative Study of Oscillatory Perturbations in Car-Following Models", "comment": null, "summary": "As connected and autonomous vehicles become more widespread, platooning has\nemerged as a key strategy to improve road capacity, reduce fuel consumption,\nand enhance traffic flow. However, the benefits of platoons strongly depend on\ntheir ability to maintain stability. Instability can lead to unsafe spacing and\nincreased energy usage. In this work, we study platoon instability and analyze\nthe root cause of its occurrence, as well as its impacts on the following\nvehicle. To achieve this, we propose a comparative study between different\ncar-following models such as the Intelligent Driver Model (IDM), the Optimal\nVelocity Model (OVM), the General Motors Model (GMM), and the Cooperative\nAdaptive Cruise Control (CACC). In our approach, we introduce a disruption in\nthe model by varying the velocity of the leading vehicle to visualize the\nbehavior of the following vehicles. To evaluate the dynamic response of each\nmodel, we introduce controlled perturbations in the velocity of the leading\nvehicle, specifically, sinusoidal oscillations and discrete velocity changes.\nThe resulting vehicle trajectories and variations in inter-vehicle spacing are\nanalyzed to assess the robustness of each model to disturbance propagation. The\nfindings offer insight into model sensitivity, stability characteristics, and\nimplications for designing resilient platooning control strategies."}
{"id": "2510.15190", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15190", "abs": "https://arxiv.org/abs/2510.15190", "authors": ["Oumaima Barhoumi", "Ghazal Farhani", "Taufiq Rahman", "Mohamed H. Zaki", "Sofiène Tahar"], "title": "A Comparative Study of Oscillatory Perturbations in Car-Following Models", "comment": null, "summary": "As connected and autonomous vehicles become more widespread, platooning has\nemerged as a key strategy to improve road capacity, reduce fuel consumption,\nand enhance traffic flow. However, the benefits of platoons strongly depend on\ntheir ability to maintain stability. Instability can lead to unsafe spacing and\nincreased energy usage. In this work, we study platoon instability and analyze\nthe root cause of its occurrence, as well as its impacts on the following\nvehicle. To achieve this, we propose a comparative study between different\ncar-following models such as the Intelligent Driver Model (IDM), the Optimal\nVelocity Model (OVM), the General Motors Model (GMM), and the Cooperative\nAdaptive Cruise Control (CACC). In our approach, we introduce a disruption in\nthe model by varying the velocity of the leading vehicle to visualize the\nbehavior of the following vehicles. To evaluate the dynamic response of each\nmodel, we introduce controlled perturbations in the velocity of the leading\nvehicle, specifically, sinusoidal oscillations and discrete velocity changes.\nThe resulting vehicle trajectories and variations in inter-vehicle spacing are\nanalyzed to assess the robustness of each model to disturbance propagation. The\nfindings offer insight into model sensitivity, stability characteristics, and\nimplications for designing resilient platooning control strategies."}
{"id": "2510.15509", "categories": ["cs.CY", "cs.AI", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15509", "abs": "https://arxiv.org/abs/2510.15509", "authors": ["Janne Rotter", "William Bailkoski"], "title": "AI Adoption in NGOs: A Systematic Literature Review", "comment": null, "summary": "AI has the potential to significantly improve how NGOs utilize their limited\nresources for societal benefits, but evidence about how NGOs adopt AI remains\nscattered. In this study, we systematically investigate the types of AI\nadoption use cases in NGOs and identify common challenges and solutions,\ncontextualized by organizational size and geographic context. We review the\nexisting primary literature, including studies that investigate AI adoption in\nNGOs related to social impact between 2020 and 2025 in English. Following the\nPRISMA protocol, two independent reviewers conduct study selection, with\nregular cross-checking to ensure methodological rigour, resulting in a final\nliterature body of 65 studies. Leveraging a thematic and narrative approach, we\nidentify six AI use case categories in NGOs - Engagement, Creativity,\nDecision-Making, Prediction, Management, and Optimization - and extract common\nchallenges and solutions within the Technology-Organization-Environment (TOE)\nframework. By integrating our findings, this review provides a novel\nunderstanding of AI adoption in NGOs, linking specific use cases and challenges\nto organizational and environmental factors. Our results demonstrate that while\nAI is promising, adoption among NGOs remains uneven and biased towards larger\norganizations. Nevertheless, following a roadmap grounded in literature can\nhelp NGOs overcome initial barriers to AI adoption, ultimately improving\neffectiveness, engagement, and social impact."}
{"id": "2510.15221", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15221", "abs": "https://arxiv.org/abs/2510.15221", "authors": ["Xiao Sun"], "title": "WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing", "comment": "15 pages, 4 figures, 1 table. Dataset publicly available under CC BY\n  4.0 license", "summary": "Automated emotion recognition in real-world workplace settings remains a\nchallenging problem in affective computing due to the scarcity of large-scale,\nlongitudinal datasets collected in naturalistic environments. We present a\nnovel dataset comprising 733,651 facial expression records from 38 employees\ncollected over 30.5 months (November 2021 to May 2024) in an authentic office\nenvironment. Each record contains seven emotion probabilities (neutral, happy,\nsad, surprised, fear, disgusted, angry) derived from deep learning-based facial\nexpression recognition, along with comprehensive metadata including job roles,\nemployment outcomes, and personality traits. The dataset uniquely spans the\nCOVID-19 pandemic period, capturing emotional responses to major societal\nevents including the Shanghai lockdown and policy changes. We provide 32\nextended emotional metrics computed using established affective science\nmethods, including valence, arousal, volatility, predictability, inertia, and\nemotional contagion strength. Technical validation demonstrates high data\nquality through successful replication of known psychological patterns (weekend\neffect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and\nperfect predictive validity for employee turnover (AUC=1.0). Baseline\nexperiments using Random Forest and LSTM models achieve 91.2% accuracy for\nemotion classification and R2 = 0.84 for valence prediction. This is the\nlargest and longest longitudinal workplace emotion dataset publicly available,\nenabling research in emotion recognition, affective dynamics modeling,\nemotional contagion, turnover prediction, and emotion-aware system design."}
{"id": "2510.15120", "categories": ["cs.AI", "I.2.6, I.2.8, I.2.11, I.3.7"], "pdf": "https://arxiv.org/pdf/2510.15120", "abs": "https://arxiv.org/abs/2510.15120", "authors": ["Miraç Buğra Özkan"], "title": "Procedural Game Level Design with Deep Reinforcement Learning", "comment": "11 pages, 10 figures, IEEE conference format", "summary": "Procedural content generation (PCG) has become an increasingly popular\ntechnique in game development, allowing developers to generate dynamic,\nreplayable, and scalable environments with reduced manual effort. In this\nstudy, a novel method for procedural level design using Deep Reinforcement\nLearning (DRL) within a Unity-based 3D environment is proposed. The system\ncomprises two agents: a hummingbird agent, acting as a solver, and a floating\nisland agent, responsible for generating and placing collectible objects\n(flowers) on the terrain in a realistic and context-aware manner. The\nhummingbird is trained using the Proximal Policy Optimization (PPO) algorithm\nfrom the Unity ML-Agents toolkit. It learns to navigate through the terrain\nefficiently, locate flowers, and collect them while adapting to the\never-changing procedural layout of the island. The island agent is also trained\nusing the Proximal Policy Optimization (PPO) algorithm. It learns to generate\nflower layouts based on observed obstacle positions, the hummingbird's initial\nstate, and performance feedback from previous episodes. The interaction between\nthese agents leads to emergent behavior and robust generalization across\nvarious environmental configurations. The results demonstrate that the approach\nnot only produces effective and efficient agent behavior but also opens up new\nopportunities for autonomous game level design driven by machine learning. This\nwork highlights the potential of DRL in enabling intelligent agents to both\ngenerate and solve content in virtual environments, pushing the boundaries of\nwhat AI can contribute to creative game development processes."}
{"id": "2510.15617", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15617", "abs": "https://arxiv.org/abs/2510.15617", "authors": ["Felix Reichel"], "title": "Political Interventions to Reduce Single-Use Plastics (SUPs) and Price Effects: An Event Study for Austria and Germany", "comment": "11 pages, 4 figures, 2 tables, 13 references, 1 appendix", "summary": "Single-use plastics (SUPs) create large environmental costs. After Directive\n(EU) 2019/904, Austria and Germany introduced producer charges and fund\npayments meant to cover clean-up work. Using a high-frequency panel of retail\noffer spells containing prices and a fixed-effects event study with two-way\nclustered standard errors, this paper measures how much these costs drive up\nconsumer prices. We find clear price pass-through in Austria. When Austrian\nproducts are pooled, treated items are 13.01 index points higher than non-SUP\ncontrols within twelve months (DiD(12m); p<0.001) and 19.42 points over the\nfull post period (p<0.001). By product, balloons show strong and lasting\neffects (DiD(12m)=13.43, p=0.007; Full DiD=19.96, p<0.001). Cups show mixed\nshort-run movements (e.g., DiD(12m)=-22.73, p=0.096) and a positive but\nimprecise full-period contrast."}
{"id": "2510.15667", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.15667", "abs": "https://arxiv.org/abs/2510.15667", "authors": ["Davi Oliveira Chaves", "Chang Chiann", "Pedro Alberto Morettin"], "title": "A nonstationary seasonal Dynamic Factor Model: an application to temperature time series from the state of Minas Gerais", "comment": "Paper presented on the XVII MGEST (Lavras, Brazil - 2025)", "summary": "In many scientific fields, such as agriculture, temperature time series are\nof interest both as explanatory variables and as objects of study in their own\nright. However, at the state level, incorporating information from all possible\nlocations in an analysis can be overwhelming, while using a summary measure,\nsuch as the state-wide average temperature, can result in significant\ninformation loss. In this context, using Dynamic Factor Models (DFMs) provides\na compelling alternative for analyzing such multivariate time series, as they\nallow for the extraction of a small number of common factors that capture the\nmajority of the variability in the data. Given that temperature series are\ntypically seasonal, this study applies a nonstationary seasonal DFM to analyze\na multivariate temperature time series from the state of Minas Gerais. The\nresults show that the data can be effectively represented by two seasonal\nfactors: the first captures the general seasonal pattern of the state, while\nthe second contrasts the months of highest annual temperatures between two\ndistinct regions."}
{"id": "2510.15229", "categories": ["cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.15229", "abs": "https://arxiv.org/abs/2510.15229", "authors": ["Sina Kazemdehbashi", "Yanchao Liu", "Boris S. Mordukhovich"], "title": "A Generalized Sylvester-Fermat-Torricelli problem with application in disaster relief operations by UAVs", "comment": null, "summary": "Natural and human-made disasters can cause severe devastation and claim\nthousands of lives worldwide. Therefore, developing efficient methods for\ndisaster response and management is a critical task for relief teams. One of\nthe most essential components of effective response is the rapid collection of\ninformation about affected areas, damages, and victims. More data translates\ninto better coordination, faster rescue operations, and ultimately, more lives\nsaved. However, in some disasters, such as earthquakes, the communication\ninfrastructure is often partially or completely destroyed, making it extremely\ndifficult for victims to send distress signals and for rescue teams to locate\nand assist them in time. Unmanned Aerial Vehicles (UAVs) have emerged as\nvaluable tools in such scenarios. In particular, a fleet of UAVs can be\ndispatched from a mobile station to the affected area to facilitate data\ncollection and establish temporary communication networks. Nevertheless,\nreal-world deployment of UAVs faces several challenges, with adverse weather\nconditions--especially wind--being among the most significant. To address this,\nwe develop a novel mathematical framework to determine the optimal location of\na mobile UAV station while explicitly accounting for the heterogeneity of the\nUAVs and the effect of wind. In particular, we generalize the Sylvester problem\nto introduce the Sylvester-Fermat-Torricelli (SFT) problem, which captures\ncomplex factors such as wind influence, UAV heterogeneity, and back-and-forth\nmotion within a unified framework. The proposed framework enhances the\npracticality of UAV-based disaster response planning by accounting for\nreal-world factors such as wind and UAV heterogeneity. Experimental results\ndemonstrate that it can reduce wasted operational time by up to 84%, making\npost-disaster missions significantly more efficient and effective."}
{"id": "2510.15617", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15617", "abs": "https://arxiv.org/abs/2510.15617", "authors": ["Felix Reichel"], "title": "Political Interventions to Reduce Single-Use Plastics (SUPs) and Price Effects: An Event Study for Austria and Germany", "comment": "11 pages, 4 figures, 2 tables, 13 references, 1 appendix", "summary": "Single-use plastics (SUPs) create large environmental costs. After Directive\n(EU) 2019/904, Austria and Germany introduced producer charges and fund\npayments meant to cover clean-up work. Using a high-frequency panel of retail\noffer spells containing prices and a fixed-effects event study with two-way\nclustered standard errors, this paper measures how much these costs drive up\nconsumer prices. We find clear price pass-through in Austria. When Austrian\nproducts are pooled, treated items are 13.01 index points higher than non-SUP\ncontrols within twelve months (DiD(12m); p<0.001) and 19.42 points over the\nfull post period (p<0.001). By product, balloons show strong and lasting\neffects (DiD(12m)=13.43, p=0.007; Full DiD=19.96, p<0.001). Cups show mixed\nshort-run movements (e.g., DiD(12m)=-22.73, p=0.096) and a positive but\nimprecise full-period contrast."}
{"id": "2510.15239", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15239", "abs": "https://arxiv.org/abs/2510.15239", "authors": ["Ziqing Zhu"], "title": "Quantum-Key-Distribution Authenticated Aggregation and Settlement for Virtual Power Plants", "comment": null, "summary": "The proliferation of distributed energy resources (DERs) and demand-side\nflexibility has made virtual power plants (VPPs) central to modern grid\noperation. Yet their end-to-end business pipeline, covering bidding, dispatch,\nmetering, settlement, and archival, forms a tightly coupled\ncyber-physical-economic system where secure and timely communication is\ncritical. Under the combined stress of sophisticated cyberattacks and extreme\nweather shocks, conventional cryptography offers limited long-term protection.\nQuantum key distribution (QKD), with information-theoretic guarantees, is\nviewed as a gold standard for securing critical infrastructures. However,\nlimited key generation rates, routing capacity, and system overhead render key\nallocation a pressing challenge: scarce quantum keys must be scheduled across\nheterogeneous processes to minimize residual risk while maintaining latency\nguarantees. This paper introduces a quantum-authenticated aggregation and\nsettlement framework for VPPs. We first develop a system-threat model that\nconnects QKD key generation and routing with business-layer security\nstrategies, authentication strength, refresh frequency, and delay constraints.\nBuilding on this, we formulate a key-budgeted risk minimization problem that\njointly accounts for economic risk, service-level violations, and key-budget\nfeasibility, and reveal a threshold property linking marginal security value to\nshadow prices. Case studies on a representative VPP system demonstrate that the\nproposed approach significantly reduces residual risk and SLA violations,\nenhances key efficiency and robustness, and aligns observed dynamics with the\ntheoretical shadow price mechanism."}
{"id": "2510.15239", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15239", "abs": "https://arxiv.org/abs/2510.15239", "authors": ["Ziqing Zhu"], "title": "Quantum-Key-Distribution Authenticated Aggregation and Settlement for Virtual Power Plants", "comment": null, "summary": "The proliferation of distributed energy resources (DERs) and demand-side\nflexibility has made virtual power plants (VPPs) central to modern grid\noperation. Yet their end-to-end business pipeline, covering bidding, dispatch,\nmetering, settlement, and archival, forms a tightly coupled\ncyber-physical-economic system where secure and timely communication is\ncritical. Under the combined stress of sophisticated cyberattacks and extreme\nweather shocks, conventional cryptography offers limited long-term protection.\nQuantum key distribution (QKD), with information-theoretic guarantees, is\nviewed as a gold standard for securing critical infrastructures. However,\nlimited key generation rates, routing capacity, and system overhead render key\nallocation a pressing challenge: scarce quantum keys must be scheduled across\nheterogeneous processes to minimize residual risk while maintaining latency\nguarantees. This paper introduces a quantum-authenticated aggregation and\nsettlement framework for VPPs. We first develop a system-threat model that\nconnects QKD key generation and routing with business-layer security\nstrategies, authentication strength, refresh frequency, and delay constraints.\nBuilding on this, we formulate a key-budgeted risk minimization problem that\njointly accounts for economic risk, service-level violations, and key-budget\nfeasibility, and reveal a threshold property linking marginal security value to\nshadow prices. Case studies on a representative VPP system demonstrate that the\nproposed approach significantly reduces residual risk and SLA violations,\nenhances key efficiency and robustness, and aligns observed dynamics with the\ntheoretical shadow price mechanism."}
{"id": "2510.15805", "categories": ["cs.CY", "cs.HC", "cs.IT", "cs.SI", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.15805", "abs": "https://arxiv.org/abs/2510.15805", "authors": ["Bonnie Rushing", "Shouhuai Xu"], "title": "Quantifying the Engagement Effectiveness of Cyber Cognitive Attacks: A Behavioral Metric for Disinformation Campaigns", "comment": "University of Colorado Colorado Springs and Department of the Air\n  Force, US Air Force Academy. Disclaimer: The views expressed are those of the\n  author and do not reflect the official policy or position of the US Air Force\n  Academy, US Air Force, Department of Defense, or the US Government", "summary": "As disinformation-driven cognitive attacks become increasingly sophisticated,\nthe ability to quantify their impact is essential for advancing cybersecurity\ndefense strategies. This paper presents a novel framework for measuring the\nengagement effectiveness of cognitive attacks by introducing a weighted\ninteraction metric that accounts for both the type and volume of user\nengagement relative to the number of attacker-generated transmissions. Applying\nthis model to real-world disinformation campaigns across social media\nplatforms, we demonstrate how the metric captures not just reach but the\nbehavioral depth of user engagement. Our findings provide new insights into the\nbehavioral dynamics of cognitive warfare and offer actionable tools for\nresearchers and practitioners seeking to assess and counter the spread of\nmalicious influence online."}
{"id": "2510.15236", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.15236", "abs": "https://arxiv.org/abs/2510.15236", "authors": ["Brett Reynolds"], "title": "From Checklists to Clusters: A Homeostatic Account of AGI Evaluation", "comment": "27 pages, 3 figures", "summary": "Contemporary AGI evaluations report multidomain capability profiles, yet they\ntypically assign symmetric weights and rely on snapshot scores. This creates\ntwo problems: (i) equal weighting treats all domains as equally important when\nhuman intelligence research suggests otherwise, and (ii) snapshot testing can't\ndistinguish durable capabilities from brittle performances that collapse under\ndelay or stress. I argue that general intelligence -- in humans and potentially\nin machines -- is better understood as a homeostatic property cluster: a set of\nabilities plus the mechanisms that keep those abilities co-present under\nperturbation. On this view, AGI evaluation should weight domains by their\ncausal centrality (their contribution to cluster stability) and require\nevidence of persistence across sessions. I propose two battery-compatible\nextensions: a centrality-prior score that imports CHC-derived weights with\ntransparent sensitivity analysis, and a Cluster Stability Index family that\nseparates profile persistence, durable learning, and error correction. These\nadditions preserve multidomain breadth while reducing brittleness and gaming. I\nclose with testable predictions and black-box protocols labs can adopt without\narchitectural access."}
{"id": "2510.15128", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15128", "abs": "https://arxiv.org/abs/2510.15128", "authors": ["Marcus A. Thomas"], "title": "Towards Error Centric Intelligence I, Beyond Observational Learning", "comment": null, "summary": "We argue that progress toward AGI is theory limited rather than data or scale\nlimited. Building on the critical rationalism of Popper and Deutsch, we\nchallenge the Platonic Representation Hypothesis. Observationally equivalent\nworlds can diverge under interventions, so observational adequacy alone cannot\nguarantee interventional competence. We begin by laying foundations,\ndefinitions of knowledge, learning, intelligence, counterfactual competence and\nAGI, and then analyze the limits of observational learning that motivate an\nerror centric shift. We recast the problem as three questions about how\nexplicit and implicit errors evolve under an agent's actions, which errors are\nunreachable within a fixed hypothesis space, and how conjecture and criticism\nexpand that space. From these questions we propose Causal Mechanics, a\nmechanisms first program in which hypothesis space change is a first class\noperation and probabilistic structure is used when useful rather than presumed.\nWe advance structural principles that make error discovery and correction\ntractable, including a differential Locality and Autonomy Principle for modular\ninterventions, a gauge invariant form of Independent Causal Mechanisms for\nseparability, and the Compositional Autonomy Principle for analogy\npreservation, together with actionable diagnostics. The aim is a scaffold for\nsystems that can convert unreachable errors into reachable ones and correct\nthem."}
{"id": "2510.15509", "categories": ["cs.CY", "cs.AI", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15509", "abs": "https://arxiv.org/abs/2510.15509", "authors": ["Janne Rotter", "William Bailkoski"], "title": "AI Adoption in NGOs: A Systematic Literature Review", "comment": null, "summary": "AI has the potential to significantly improve how NGOs utilize their limited\nresources for societal benefits, but evidence about how NGOs adopt AI remains\nscattered. In this study, we systematically investigate the types of AI\nadoption use cases in NGOs and identify common challenges and solutions,\ncontextualized by organizational size and geographic context. We review the\nexisting primary literature, including studies that investigate AI adoption in\nNGOs related to social impact between 2020 and 2025 in English. Following the\nPRISMA protocol, two independent reviewers conduct study selection, with\nregular cross-checking to ensure methodological rigour, resulting in a final\nliterature body of 65 studies. Leveraging a thematic and narrative approach, we\nidentify six AI use case categories in NGOs - Engagement, Creativity,\nDecision-Making, Prediction, Management, and Optimization - and extract common\nchallenges and solutions within the Technology-Organization-Environment (TOE)\nframework. By integrating our findings, this review provides a novel\nunderstanding of AI adoption in NGOs, linking specific use cases and challenges\nto organizational and environmental factors. Our results demonstrate that while\nAI is promising, adoption among NGOs remains uneven and biased towards larger\norganizations. Nevertheless, following a roadmap grounded in literature can\nhelp NGOs overcome initial barriers to AI adoption, ultimately improving\neffectiveness, engagement, and social impact."}
{"id": "2510.15762", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.15762", "abs": "https://arxiv.org/abs/2510.15762", "authors": ["Antonio Remiro-Azócar", "Pepa Polavieja", "Emmanuelle Boutmy", "Alessandro Ghiretti", "Lise Lotte Nystrup Husemoen", "Khadija Rerhou Rantell", "Tatsiana Vaitsiakhovich", "David M. Phillippo", "Jay J. H. Park", "Helle Lynggaard", "Robert Bauer", "Antonia Morga"], "title": "Incorporating estimands into meta-analyses of clinical trials", "comment": "27 pages, 6 figures, 6 tables. Submitted to Research Synthesis\n  Methods", "summary": "The estimand framework is increasingly established to pose research questions\nin confirmatory clinical trials. In evidence synthesis, the uptake of estimands\nhas been modest, and the PICO (Population, Intervention, Comparator, Outcome)\nframework is more often applied. While PICOs and estimands have overlapping\nelements, the estimand framework explicitly considers different strategies for\nintercurrent events. We propose a pragmatic framework for the use of estimands\nin meta-analyses of clinical trials, highlighting the value of estimands to\nsystematically identify and mitigate key sources of quantitative heterogeneity,\nand to enhance the applicability or external validity of pooled estimates.\nFocus is placed on the role of strategies for intercurrent events, within the\nspecific context of meta-analyses for health technology assessment. We apply\nthe estimand framework to a network meta-analysis of clinical trials, comparing\nthe efficacy of semaglutide versus dulaglutide in type 2 diabetes. We explore\nthe impact of a treatment policy strategy for treatment discontinuation or\ninitiation of rescue medication versus a hypothetical strategy for the\ncorresponding intercurrent events. The specification of different target\nestimands at the meta-analytical level allows us to be explicit about the\nsource of heterogeneity, the intercurrent event strategy, driving any potential\ndifferences in results. We advocate for the integration of estimands into the\nplanning of meta-analyses, while acknowledging that potential challenges exist\nin the absence of subject-level data. Estimands can complement PICOs to\nstrengthen communication between stakeholders about what evidence syntheses\nseek to demonstrate, and to ensure that the generated evidence is maximally\nrelevant to healthcare decision-makers."}
{"id": "2510.15319", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15319", "abs": "https://arxiv.org/abs/2510.15319", "authors": ["Jeewon Kim", "Minho Oh", "Hyun Myung"], "title": "Traversability-aware Consistent Situational Graphs for Indoor Localization and Mapping", "comment": "Accepted by RiTA 2024", "summary": "Scene graphs enhance 3D mapping capabilities in robotics by understanding the\nrelationships between different spatial elements, such as rooms and objects.\nRecent research extends scene graphs to hierarchical layers, adding and\nleveraging constraints across these levels. This approach is tightly integrated\nwith pose-graph optimization, improving both localization and mapping accuracy\nsimultaneously. However, when segmenting spatial characteristics, consistently\nrecognizing rooms becomes challenging due to variations in viewpoints and\nlimited field of view (FOV) of sensors. For example, existing real-time\napproaches often over-segment large rooms into smaller, non-functional spaces\nthat are not useful for localization and mapping due to the time-dependent\nmethod. Conversely, their voxel-based room segmentation method often\nunder-segment in complex cases like not fully enclosed 3D space that are\nnon-traversable for ground robots or humans, leading to false constraints in\npose-graph optimization. We propose a traversability-aware room segmentation\nmethod that considers the interaction between robots and surroundings, with\nconsistent feasibility of traversability information. This enhances both the\nsemantic coherence and computational efficiency of pose-graph optimization.\nImproved performance is demonstrated through the re-detection frequency of the\nsame rooms in a dataset involving repeated traversals of the same space along\nthe same path, as well as the optimization time consumption."}
{"id": "2510.15509", "categories": ["cs.CY", "cs.AI", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15509", "abs": "https://arxiv.org/abs/2510.15509", "authors": ["Janne Rotter", "William Bailkoski"], "title": "AI Adoption in NGOs: A Systematic Literature Review", "comment": null, "summary": "AI has the potential to significantly improve how NGOs utilize their limited\nresources for societal benefits, but evidence about how NGOs adopt AI remains\nscattered. In this study, we systematically investigate the types of AI\nadoption use cases in NGOs and identify common challenges and solutions,\ncontextualized by organizational size and geographic context. We review the\nexisting primary literature, including studies that investigate AI adoption in\nNGOs related to social impact between 2020 and 2025 in English. Following the\nPRISMA protocol, two independent reviewers conduct study selection, with\nregular cross-checking to ensure methodological rigour, resulting in a final\nliterature body of 65 studies. Leveraging a thematic and narrative approach, we\nidentify six AI use case categories in NGOs - Engagement, Creativity,\nDecision-Making, Prediction, Management, and Optimization - and extract common\nchallenges and solutions within the Technology-Organization-Environment (TOE)\nframework. By integrating our findings, this review provides a novel\nunderstanding of AI adoption in NGOs, linking specific use cases and challenges\nto organizational and environmental factors. Our results demonstrate that while\nAI is promising, adoption among NGOs remains uneven and biased towards larger\norganizations. Nevertheless, following a roadmap grounded in literature can\nhelp NGOs overcome initial barriers to AI adoption, ultimately improving\neffectiveness, engagement, and social impact."}
{"id": "2510.15248", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15248", "abs": "https://arxiv.org/abs/2510.15248", "authors": ["Ziqing Zhu"], "title": "Techno-Economic Feasibility Analysis of Quantum Key Distribution for Power-System Communications", "comment": null, "summary": "The accelerating digitalization and decentralization of modern power systems\nexpose critical communication infrastructures to escalating cyber risks,\nparticularly under emerging quantum computing threats. This paper presents an\nintegrated techno-economic framework to evaluate the feasibility of Quantum Key\nDistribution (QKD) for secure power-system communications. A stochastic system\nmodel is developed to jointly capture time-varying key demand, QKD supply under\noptical-loss constraints, station-side buffering, and post-quantum cryptography\n(PQC) fallback mechanisms. Analytical conditions are derived for service-level\nassurance, including buffer stability, outage probability, and availability\nbounds. Building on this, two quantitative metrics, including the Levelized\nCost of Security (LCoSec) and Cost of Incremental Security (CIS), are\nformulated to unify capital, operational, and risk-related expenditures within\na discounted net-present-value framework. Using IEEE 118-bus, 123-node, and\n39-bus test systems, we conduct discrete-event simulations comparing PQC-only,\nQKD-only, and Hybrid architectures across multiple topologies and service\nprofiles. Results show that Hybrid architectures dominated by QKD significantly\nreduce key-outage probability and SLA shortfalls, achieving near-unit\navailability for real-time and confidentiality-critical services. Economic\nanalyses reveal clear breakeven zones where QKD-enhanced deployments become\ncost-effective, primarily in metropolitan and distribution-level networks under\nmoderate optical loss and buffer sizing. The proposed framework provides a\nreproducible, risk-aware decision tool for guiding large-scale, economically\njustified QKD adoption in future resilient power-system infrastructures."}
{"id": "2510.15248", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15248", "abs": "https://arxiv.org/abs/2510.15248", "authors": ["Ziqing Zhu"], "title": "Techno-Economic Feasibility Analysis of Quantum Key Distribution for Power-System Communications", "comment": null, "summary": "The accelerating digitalization and decentralization of modern power systems\nexpose critical communication infrastructures to escalating cyber risks,\nparticularly under emerging quantum computing threats. This paper presents an\nintegrated techno-economic framework to evaluate the feasibility of Quantum Key\nDistribution (QKD) for secure power-system communications. A stochastic system\nmodel is developed to jointly capture time-varying key demand, QKD supply under\noptical-loss constraints, station-side buffering, and post-quantum cryptography\n(PQC) fallback mechanisms. Analytical conditions are derived for service-level\nassurance, including buffer stability, outage probability, and availability\nbounds. Building on this, two quantitative metrics, including the Levelized\nCost of Security (LCoSec) and Cost of Incremental Security (CIS), are\nformulated to unify capital, operational, and risk-related expenditures within\na discounted net-present-value framework. Using IEEE 118-bus, 123-node, and\n39-bus test systems, we conduct discrete-event simulations comparing PQC-only,\nQKD-only, and Hybrid architectures across multiple topologies and service\nprofiles. Results show that Hybrid architectures dominated by QKD significantly\nreduce key-outage probability and SLA shortfalls, achieving near-unit\navailability for real-time and confidentiality-critical services. Economic\nanalyses reveal clear breakeven zones where QKD-enhanced deployments become\ncost-effective, primarily in metropolitan and distribution-level networks under\nmoderate optical loss and buffer sizing. The proposed framework provides a\nreproducible, risk-aware decision tool for guiding large-scale, economically\njustified QKD adoption in future resilient power-system infrastructures."}
{"id": "2510.15121", "categories": ["econ.GN", "cs.CY", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15121", "abs": "https://arxiv.org/abs/2510.15121", "authors": ["Heather Liddell", "Beth Kelley", "Liz Wachs", "Alberta Carpenter", "Joe Cresko"], "title": "A physically extended EEIO framework for material efficiency assessment in United States manufacturing supply chains", "comment": "9 pages, 4 figures. Accepted manuscript, presented at the REMADE 2025\n  Circular Economy Conference & Tech Summit, Washington DC, April 10-11, 2025", "summary": "A physical assessment of material flows in an economy (e.g., material flow\nquantification) can support the development of sustainable decarbonization and\ncircularity strategies by providing the tangible physical context of industrial\nproduction quantities and supply chain relationships. However, completing a\nphysical assessment is challenging due to the scarcity of high-quality raw data\nand poor harmonization across industry classification systems used in data\nreporting. Here we describe a new physical extension for the U.S. Department of\nEnergy's (DOE's) EEIO for Industrial Decarbonization (EEIO-IDA) model, yielding\nan expanded EEIO model that is both physically and environmentally extended. In\nthe model framework, the U.S. economy is divided into goods-producing and\nservice-producing subsectors, and mass flows are quantified for each\ngoods-producing subsector using a combination of trade data (e.g., UN Comtrade)\nand physical production data (e.g., U.S. Geological Survey). Given that\nprimary-source production data are not available for all subsectors,\nprice-imputation and mass-balance assumptions are developed and used to\ncomplete the physical flows dataset with high-quality estimations. The\nresulting dataset, when integrated with the EEIO-IDA tool, enables the\nquantification of environmental impact intensity metrics on a mass basis (e.g.,\nCO$_2$eq/kg)) for each industrial subsector. This work is designed to align\nwith existing DOE frameworks and tools, including the EEIO-IDA tool, the DOE\nIndustrial Decarbonization Roadmap (2022), and Pathways for U.S. Industrial\nTransformations study (2025)."}
{"id": "2510.15258", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.15258", "abs": "https://arxiv.org/abs/2510.15258", "authors": ["Xi Wang", "Xianyao Ling", "Kun Li", "Gang Yin", "Liang Zhang", "Jiang Wu", "Jun Xu", "Fu Zhang", "Wenbo Lei", "Annie Wang", "Peng Gong"], "title": "Multi-dimensional Data Analysis and Applications Basing on LLM Agents and Knowledge Graph Interactions", "comment": "14 pages, 7 figures, 40 references", "summary": "In the current era of big data, extracting deep insights from massive,\nheterogeneous, and complexly associated multi-dimensional data has become a\nsignificant challenge. Large Language Models (LLMs) perform well in natural\nlanguage understanding and generation, but still suffer from \"hallucination\"\nissues when processing structured knowledge and are difficult to update in\nreal-time. Although Knowledge Graphs (KGs) can explicitly store structured\nknowledge, their static nature limits dynamic interaction and analytical\ncapabilities. Therefore, this paper proposes a multi-dimensional data analysis\nmethod based on the interactions between LLM agents and KGs, constructing a\ndynamic, collaborative analytical ecosystem. This method utilizes LLM agents to\nautomatically extract product data from unstructured data, constructs and\nvisualizes the KG in real-time, and supports users in deep exploration and\nanalysis of graph nodes through an interactive platform. Experimental results\nshow that this method has significant advantages in product ecosystem analysis,\nrelationship mining, and user-driven exploratory analysis, providing new ideas\nand tools for multi-dimensional data analysis."}
{"id": "2510.15142", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.15142", "abs": "https://arxiv.org/abs/2510.15142", "authors": ["Diana Wolfe", "Matt Price", "Alice Choe", "Fergus Kidd", "Hannah Wagner"], "title": "Revisiting UTAUT for the Age of AI: Understanding Employees AI Adoption and Usage Patterns Through an Extended UTAUT Framework", "comment": "45 pages, 3 figures, 6 tables", "summary": "This study investigates whether demographic factors shape adoption and\nattitudes among employees toward artificial intelligence (AI) technologies at\nwork. Building on an extended Unified Theory of Acceptance and Use of\nTechnology (UTAUT), which reintroduces affective dimensions such as attitude,\nself-efficacy, and anxiety, we surveyed 2,257 professionals across global\nregions and organizational levels within a multinational consulting firm.\nNon-parametric tests examined whether three demographic factors (i.e., years of\nexperience, hierarchical level in the organization, and geographic region) were\nassociated with AI adoption, usage intensity, and eight UTAUT constructs.\nOrganizational level significantly predicted AI adoption, with senior employees\nshowing higher usage rates, while experience and region were unrelated to\nadoption. Among AI users (n = 1,256), frequency and duration of use showed\nminimal demographic variation. However, omnibus tests revealed small but\nconsistent group differences across several UTAUT constructs, particularly\nanxiety, performance expectancy, and behavioral intention, suggesting that\nemotional and cognitive responses to AI vary modestly across contexts. These\nfindings highlight that demographic factors explain limited variance in AI\nacceptance but remain relevant for understanding contextual nuances in\ntechnology-related attitudes. The results underscore the need to integrate\naffective and organizational factors into models of technology acceptance to\nsupport equitable, confident, and sustainable engagement with AI in modern\nworkplaces."}
{"id": "2510.15780", "categories": ["stat.AP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15780", "abs": "https://arxiv.org/abs/2510.15780", "authors": ["Alireza Moradi", "Mathieu Tanneau", "Reza Zandehshahvar", "Pascal Van Hentenryck"], "title": "Enhanced Renewable Energy Forecasting using Context-Aware Conformal Prediction", "comment": null, "summary": "Accurate forecasting is critical for reliable power grid operations,\nparticularly as the share of renewable generation, such as wind and solar,\ncontinues to grow. Given the inherent uncertainty and variability in renewable\ngeneration, probabilistic forecasts have become essential for informed\noperational decisions. However, such forecasts frequently suffer from\ncalibration issues, potentially degrading decision-making performance. Building\non recent advances in Conformal Predictions, this paper introduces a tailored\ncalibration framework that constructs context-aware calibration sets using a\nnovel weighting scheme. The proposed framework improves the quality of\nprobabilistic forecasts at the site and fleet levels, as demonstrated by\nnumerical experiments on large-scale datasets covering several systems in the\nUnited States. The results demonstrate that the proposed approach achieves\nhigher forecast reliability and robustness for renewable energy applications\ncompared to existing baselines."}
{"id": "2510.15331", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15331", "abs": "https://arxiv.org/abs/2510.15331", "authors": ["Gahee Kim", "Takamitsu Matsubara"], "title": "ASBI: Leveraging Informative Real-World Data for Active Black-Box Simulator Tuning", "comment": null, "summary": "Black-box simulators are widely used in robotics, but optimizing their\nparameters remains challenging due to inaccessible likelihoods.\nSimulation-Based Inference (SBI) tackles this issue using simulation-driven\napproaches, estimating the posterior from offline real observations and forward\nsimulations. However, in black-box scenarios, preparing observations that\ncontain sufficient information for parameter estimation is difficult due to the\nunknown relationship between parameters and observations. In this work, we\npresent Active Simulation-Based Inference (ASBI), a parameter estimation\nframework that uses robots to actively collect real-world online data to\nachieve accurate black-box simulator tuning. Our framework optimizes robot\nactions to collect informative observations by maximizing information gain,\nwhich is defined as the expected reduction in Shannon entropy between the\nposterior and the prior. While calculating information gain requires the\nlikelihood, which is inaccessible in black-box simulators, our method solves\nthis problem by leveraging Neural Posterior Estimation (NPE), which leverages a\nneural network to learn the posterior estimator. Three simulation experiments\nquantitatively verify that our method achieves accurate parameter estimation,\nwith posteriors sharply concentrated around the true parameters. Moreover, we\nshow a practical application using a real robot to estimate the simulation\nparameters of cubic particles corresponding to two real objects, beads and\ngravel, with a bucket pouring action."}
{"id": "2510.15250", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15250", "abs": "https://arxiv.org/abs/2510.15250", "authors": ["Mostafaali Ayubirad", "Zeng Qiu", "Hao Wang", "Chris Weinkauf", "Michiel Van Nieuwstadt", "Hamid R. Ossareh"], "title": "Comprehensive Dynamic Modeling and Constraint-Aware Air Supply Control for Localized Water Management in Automotive Polymer Electrolyte Membrane Fuel Cells", "comment": "This is a manuscript submitted to Applied Energy", "summary": "In this paper, a predictive constraint-aware control scheme is formulated\nwithin the Command Governor (CG) framework for localized hydration management\nof a proton exchange membrane (PEM) fuel cell system. First, a comprehensive\nnonlinear dynamic model of the fuel cell system is presented which includes a\npseudo 2-dimensional (P2D) model of the stack, reactant supply and cooling\nsubsystems. The model captures the couplings among the various subsystems and\nserves as the basis for designing output feedback controllers to track the\noptimal set-points of the air supply and cooling systems for power\noptimization. The closed-loop nonlinear model is then used to analyze the\ndynamic behavior of membrane hydration near the anode inlet, the driest region\nof the membrane in a counter-flow configuration, under various operating\nconditions. A reduced-order linearized model is then derived to approximate\nhydration behavior with sufficient fidelity for constraint enforcement. This\nmodel is used within the CG framework to adjust the air supply set-points when\nnecessary to prevent membrane dry-out. The effectiveness of the proposed\napproach in maintaining local membrane hydration while closely tracking the\nrequested net power is demonstrated through realistic drive-cycle simulations."}
{"id": "2510.15250", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15250", "abs": "https://arxiv.org/abs/2510.15250", "authors": ["Mostafaali Ayubirad", "Zeng Qiu", "Hao Wang", "Chris Weinkauf", "Michiel Van Nieuwstadt", "Hamid R. Ossareh"], "title": "Comprehensive Dynamic Modeling and Constraint-Aware Air Supply Control for Localized Water Management in Automotive Polymer Electrolyte Membrane Fuel Cells", "comment": "This is a manuscript submitted to Applied Energy", "summary": "In this paper, a predictive constraint-aware control scheme is formulated\nwithin the Command Governor (CG) framework for localized hydration management\nof a proton exchange membrane (PEM) fuel cell system. First, a comprehensive\nnonlinear dynamic model of the fuel cell system is presented which includes a\npseudo 2-dimensional (P2D) model of the stack, reactant supply and cooling\nsubsystems. The model captures the couplings among the various subsystems and\nserves as the basis for designing output feedback controllers to track the\noptimal set-points of the air supply and cooling systems for power\noptimization. The closed-loop nonlinear model is then used to analyze the\ndynamic behavior of membrane hydration near the anode inlet, the driest region\nof the membrane in a counter-flow configuration, under various operating\nconditions. A reduced-order linearized model is then derived to approximate\nhydration behavior with sufficient fidelity for constraint enforcement. This\nmodel is used within the CG framework to adjust the air supply set-points when\nnecessary to prevent membrane dry-out. The effectiveness of the proposed\napproach in maintaining local membrane hydration while closely tracking the\nrequested net power is demonstrated through realistic drive-cycle simulations."}
{"id": "2510.15144", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.15144", "abs": "https://arxiv.org/abs/2510.15144", "authors": ["Chance Jiajie Li", "Zhenze Mo", "Yuhan Tang", "Ao Qu", "Jiayi Wu", "Kaiya Ivy Zhao", "Yulu Gan", "Jie Fan", "Jiangbo Yu", "Hang Jiang", "Paul Pu Liang", "Jinhua Zhao", "Luis Alberto Alonso Pastor", "Kent Larson"], "title": "HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks", "comment": "To appear in NeurIPS 2025 Workshop on Bridging Language, Agent, and\n  World Models (LAW)", "summary": "Simulating human reasoning in open-ended tasks has been a long-standing\naspiration in AI and cognitive science. While large language models now\napproximate human responses at scale, they remain tuned to population-level\nconsensus, often erasing the individuality of reasoning styles and belief\ntrajectories. To advance the vision of more human-like reasoning in machines,\nwe introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for\naverage-to-individual reasoning adaptation. The task is to predict how a\nspecific person would reason and update their beliefs in novel scenarios, given\npartial evidence of their past views. HugAgent adopts a dual-track design: a\nsynthetic track for scale and systematic stress tests, and a human track for\necologically valid, \"out-loud\" reasoning data. This design enables scalable,\nreproducible evaluation of intra-agent fidelity: whether models can capture not\njust what people believe, but how their reasoning evolves. Experiments with\nstate-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent\nas the first extensible benchmark for aligning machine reasoning with the\nindividuality of human thought. Our benchmark and chatbot are open-sourced as\nHugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking\n(https://anonymous.4open.science/r/trace-your-thinking)."}
{"id": "2510.15259", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15259", "abs": "https://arxiv.org/abs/2510.15259", "authors": ["Chenwei Tang", "Jingyu Xing", "Xinyu Liu", "Zizhou Wang", "Jiawei Du", "Liangli Zhen", "Jiancheng Lv"], "title": "Experience-Driven Exploration for Efficient API-Free AI Agents", "comment": null, "summary": "Most existing software lacks accessible Application Programming Interfaces\n(APIs), requiring agents to operate solely through pixel-based Graphical User\nInterfaces (GUIs). In this API-free setting, large language model (LLM)-based\nagents face severe efficiency bottlenecks: limited to local visual experiences,\nthey make myopic decisions and rely on inefficient trial-and-error, hindering\nboth skill acquisition and long-term planning. To address these challenges, we\npropose KG-Agent, an experience-driven learning framework that structures an\nagent's raw pixel-level interactions into a persistent State-Action Knowledge\nGraph (SA-KG). KG-Agent overcomes inefficient exploration by linking\nfunctionally similar but visually distinct GUI states, forming a rich\nneighborhood of experience that enables the agent to generalize from a diverse\nset of historical strategies. To support long-horizon reasoning, we design a\nhybrid intrinsic reward mechanism based on the graph topology, combining a\nstate value reward for exploiting known high-value pathways with a novelty\nreward that encourages targeted exploration. This approach decouples strategic\nplanning from pure discovery, allowing the agent to effectively value setup\nactions with delayed gratification. We evaluate KG-Agent in two complex,\nopen-ended GUI-based decision-making environments (Civilization V and Slay the\nSpire), demonstrating significant improvements in exploration efficiency and\nstrategic depth over the state-of-the-art methods."}
{"id": "2510.15144", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.15144", "abs": "https://arxiv.org/abs/2510.15144", "authors": ["Chance Jiajie Li", "Zhenze Mo", "Yuhan Tang", "Ao Qu", "Jiayi Wu", "Kaiya Ivy Zhao", "Yulu Gan", "Jie Fan", "Jiangbo Yu", "Hang Jiang", "Paul Pu Liang", "Jinhua Zhao", "Luis Alberto Alonso Pastor", "Kent Larson"], "title": "HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks", "comment": "To appear in NeurIPS 2025 Workshop on Bridging Language, Agent, and\n  World Models (LAW)", "summary": "Simulating human reasoning in open-ended tasks has been a long-standing\naspiration in AI and cognitive science. While large language models now\napproximate human responses at scale, they remain tuned to population-level\nconsensus, often erasing the individuality of reasoning styles and belief\ntrajectories. To advance the vision of more human-like reasoning in machines,\nwe introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for\naverage-to-individual reasoning adaptation. The task is to predict how a\nspecific person would reason and update their beliefs in novel scenarios, given\npartial evidence of their past views. HugAgent adopts a dual-track design: a\nsynthetic track for scale and systematic stress tests, and a human track for\necologically valid, \"out-loud\" reasoning data. This design enables scalable,\nreproducible evaluation of intra-agent fidelity: whether models can capture not\njust what people believe, but how their reasoning evolves. Experiments with\nstate-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent\nas the first extensible benchmark for aligning machine reasoning with the\nindividuality of human thought. Our benchmark and chatbot are open-sourced as\nHugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking\n(https://anonymous.4open.science/r/trace-your-thinking)."}
{"id": "2510.15324", "categories": ["econ.EM", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.15324", "abs": "https://arxiv.org/abs/2510.15324", "authors": ["Tatsuru Kikuchi"], "title": "Dynamic Spatial Treatment Effects as Continuous Functionals: Theory and Evidence from Healthcare Access", "comment": "68 pages, 10 figures", "summary": "I develop a continuous functional framework for spatial treatment effects\ngrounded in Navier-Stokes partial differential equations. Rather than discrete\ntreatment parameters, the framework characterizes treatment intensity as\ncontinuous functions $\\tau(\\mathbf{x}, t)$ over space-time, enabling rigorous\nanalysis of boundary evolution, spatial gradients, and cumulative exposure.\nEmpirical validation using 32,520 U.S. ZIP codes demonstrates exponential\nspatial decay for healthcare access ($\\kappa = 0.002837$ per km, $R^2 =\n0.0129$) with detectable boundaries at 37.1 km. The framework successfully\ndiagnoses when scope conditions hold: positive decay parameters validate\ndiffusion assumptions near hospitals, while negative parameters correctly\nsignal urban confounding effects. Heterogeneity analysis reveals 2-13 $\\times$\nstronger distance effects for elderly populations and substantial education\ngradients. Model selection strongly favors logarithmic decay over exponential\n($\\Delta \\text{AIC} > 10,000$), representing a middle ground between\nexponential and power-law decay. Applications span environmental economics,\nbanking, and healthcare policy. The continuous functional framework provides\npredictive capability ($d^*(t) = \\xi^* \\sqrt{t}$), parameter sensitivity\n($\\partial d^*/\\partial \\nu$), and diagnostic tests unavailable in traditional\ndifference-in-differences approaches."}
{"id": "2510.15336", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15336", "abs": "https://arxiv.org/abs/2510.15336", "authors": ["Liviu-Mihai Stan", "Ranulfo Bezerra", "Shotaro Kojima", "Tsige Tadesse Alemayoh", "Satoshi Tadokoro", "Masashi Konyo", "Kazunori Ohno"], "title": "Adaptive Cost-Map-based Path Planning in Partially Unknown Environments with Movable Obstacles", "comment": null, "summary": "Reliable navigation in disaster-response and other unstructured indoor\nsettings requires robots not only to avoid obstacles but also to recognise when\nthose obstacles can be pushed aside. We present an adaptive, LiDAR and\nodometry-based path-planning framework that embeds this capability into the\nROS2 Nav2 stack. A new Movable Obstacles Layer labels all LiDAR returns missing\nfrom a prior static map as tentatively movable and assigns a reduced traversal\ncost. A companion Slow-Pose Progress Checker monitors the ratio of commanded to\nactual velocity; when the robot slows appreciably, the local cost is raised\nfrom light to heavy, and on a stall to lethal, prompting the global planner to\nback out and re-route. Gazebo evaluations on a Scout Mini, spanning isolated\nobjects and cluttered corridors, show higher goal-reach rates and fewer\ndeadlocks than a no-layer baseline, with traversal times broadly comparable.\nBecause the method relies only on planar scans and CPU-level computation, it\nsuits resource-constrained search and rescue robots and integrates into\nheterogeneous platforms with minimal engineering. Overall, the results indicate\nthat interaction-aware cost maps are a lightweight, ROS2-native extension for\nnavigating among potentially movable obstacles in unstructured settings. The\nfull implementation will be released as open source\nathttps://costmap-namo.github.io."}
{"id": "2510.15285", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15285", "abs": "https://arxiv.org/abs/2510.15285", "authors": ["Saeid Bayat", "Jerry Zuo", "Jing Sun"], "title": "Modeling and Dynamic Simulation of a Hybrid Wind-Wave System on a Hexagonal Semi-Submersible Platform", "comment": "28 pages, 17 figures", "summary": "Offshore renewable energy systems offer promising solutions for sustainable\npower generation, yet most existing platforms harvest either wind or wave\nenergy in isolation. This study presents a hybrid floating offshore platform\nthat integrates a wind turbine with three oscillating surge wave energy\nconverters (WECs) into a hexagonal semi-submersible structure. In this\nconfiguration, the flaps are integrated with the platform geometry to provide\nboth energy extraction and hydrodynamic stability. A modeling and simulation\nframework was developed using WEC-Sim and benchmarked against the NREL 5 MW\nsemisubmersible reference. Metacentric height analysis confirmed hydrostatic\nstability across a range of prescribed flap angles. Sensitivity analysis of\ntwelve geometric variables identified flap dimensions and tower length as\ndominant drivers of stability, energy capture, and tower stress. Time-domain\nsimulations revealed dependence on wave incidence angle, with variations in\nflap power sharing, capture width ratio (CWR), and platform response. The\nfeasibility of using flap sweeps to modulate pitch motion was also\ndemonstrated. Annual energy production (AEP) estimates based on site-specific\ndata indicate 16.86 GWh from wind and 3.65 GWh from wave energy, with WECs\ncontributing about 18% of the total. These results highlight the potential of\nintegrated wind-wave platforms and point toward future studies on structural\nmodeling and advanced control."}
{"id": "2510.15285", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15285", "abs": "https://arxiv.org/abs/2510.15285", "authors": ["Saeid Bayat", "Jerry Zuo", "Jing Sun"], "title": "Modeling and Dynamic Simulation of a Hybrid Wind-Wave System on a Hexagonal Semi-Submersible Platform", "comment": "28 pages, 17 figures", "summary": "Offshore renewable energy systems offer promising solutions for sustainable\npower generation, yet most existing platforms harvest either wind or wave\nenergy in isolation. This study presents a hybrid floating offshore platform\nthat integrates a wind turbine with three oscillating surge wave energy\nconverters (WECs) into a hexagonal semi-submersible structure. In this\nconfiguration, the flaps are integrated with the platform geometry to provide\nboth energy extraction and hydrodynamic stability. A modeling and simulation\nframework was developed using WEC-Sim and benchmarked against the NREL 5 MW\nsemisubmersible reference. Metacentric height analysis confirmed hydrostatic\nstability across a range of prescribed flap angles. Sensitivity analysis of\ntwelve geometric variables identified flap dimensions and tower length as\ndominant drivers of stability, energy capture, and tower stress. Time-domain\nsimulations revealed dependence on wave incidence angle, with variations in\nflap power sharing, capture width ratio (CWR), and platform response. The\nfeasibility of using flap sweeps to modulate pitch motion was also\ndemonstrated. Annual energy production (AEP) estimates based on site-specific\ndata indicate 16.86 GWh from wind and 3.65 GWh from wave energy, with WECs\ncontributing about 18% of the total. These results highlight the potential of\nintegrated wind-wave platforms and point toward future studies on structural\nmodeling and advanced control."}
{"id": "2510.15221", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15221", "abs": "https://arxiv.org/abs/2510.15221", "authors": ["Xiao Sun"], "title": "WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing", "comment": "15 pages, 4 figures, 1 table. Dataset publicly available under CC BY\n  4.0 license", "summary": "Automated emotion recognition in real-world workplace settings remains a\nchallenging problem in affective computing due to the scarcity of large-scale,\nlongitudinal datasets collected in naturalistic environments. We present a\nnovel dataset comprising 733,651 facial expression records from 38 employees\ncollected over 30.5 months (November 2021 to May 2024) in an authentic office\nenvironment. Each record contains seven emotion probabilities (neutral, happy,\nsad, surprised, fear, disgusted, angry) derived from deep learning-based facial\nexpression recognition, along with comprehensive metadata including job roles,\nemployment outcomes, and personality traits. The dataset uniquely spans the\nCOVID-19 pandemic period, capturing emotional responses to major societal\nevents including the Shanghai lockdown and policy changes. We provide 32\nextended emotional metrics computed using established affective science\nmethods, including valence, arousal, volatility, predictability, inertia, and\nemotional contagion strength. Technical validation demonstrates high data\nquality through successful replication of known psychological patterns (weekend\neffect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and\nperfect predictive validity for employee turnover (AUC=1.0). Baseline\nexperiments using Random Forest and LSTM models achieve 91.2% accuracy for\nemotion classification and R2 = 0.84 for valence prediction. This is the\nlargest and longest longitudinal workplace emotion dataset publicly available,\nenabling research in emotion recognition, affective dynamics modeling,\nemotional contagion, turnover prediction, and emotion-aware system design."}
{"id": "2510.15261", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15261", "abs": "https://arxiv.org/abs/2510.15261", "authors": ["Jitesh Jain", "Shubham Maheshwari", "Ning Yu", "Wen-mei Hwu", "Humphrey Shi"], "title": "AUGUSTUS: An LLM-Driven Multimodal Agent System with Contextualized User Memory", "comment": "LAW 2025 Workshop at NeurIPS 2025. Work done from late 2023 to early\n  2024", "summary": "Riding on the success of LLMs with retrieval-augmented generation (RAG),\nthere has been a growing interest in augmenting agent systems with external\nmemory databases. However, the existing systems focus on storing text\ninformation in their memory, ignoring the importance of multimodal signals.\nMotivated by the multimodal nature of human memory, we present AUGUSTUS, a\nmultimodal agent system aligned with the ideas of human memory in cognitive\nscience. Technically, our system consists of 4 stages connected in a loop: (i)\nencode: understanding the inputs; (ii) store in memory: saving important\ninformation; (iii) retrieve: searching for relevant context from memory; and\n(iv) act: perform the task. Unlike existing systems that use vector databases,\nwe propose conceptualizing information into semantic tags and associating the\ntags with their context to store them in a graph-structured multimodal\ncontextual memory for efficient concept-driven retrieval. Our system\noutperforms the traditional multimodal RAG approach while being 3.5 times\nfaster for ImageNet classification and outperforming MemGPT on the MSC\nbenchmark."}
{"id": "2510.15150", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.15150", "abs": "https://arxiv.org/abs/2510.15150", "authors": ["Tina Gao", "Shimiao Li", "Lawrence Pileggi"], "title": "Sparsity-exploiting Gaussian Process for Robust Transient Learning of Power System Dynamics", "comment": "This manuscript has been submitted to PESGM2026", "summary": "Advances in leveraging Gaussian processes (GP) have enabled learning and\ninferring dynamic grid behavior from scarce PMU measurements. However, real\nmeasurements can be corrupted by various random and targeted threats, leading\nto inaccurate and meaningless results. This paper develops robust transient\nlearning to overcome this challenge by exploiting the sparse corruption\npatterns in the data flow. Specifically, we integrate sparse optimization with\nmethod of moments (MoM) to make learning robust to a sparse distribution of\ndata corruptions; then, we optimize sparse weights to identify corrupted meter\nlocations. To improve inference speed on large-scale systems, we further adopt\nK-medoid clustering of locations to develop dimension reduction (DR) and\naggregate representation (AR) heuristics. Experimental results demonstrate\nrobustness against random large errors, targeted false data injections, and\nlocal PMU clock drifts. On a 1354-bus system, inference turns out to be 18x\nfaster using DR and 400x faster when further combined with AR heuristics."}
{"id": "2510.15350", "categories": ["cs.RO", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.15350", "abs": "https://arxiv.org/abs/2510.15350", "authors": ["Shyalan Ramesh", "Scott Mann", "Alex Stumpf"], "title": "Nauplius Optimisation for Autonomous Hydrodynamics", "comment": null, "summary": "Autonomous Underwater vehicles must operate in strong currents, limited\nacoustic bandwidth, and persistent sensing requirements where conventional\nswarm optimisation methods are unreliable. This paper presents NOAH, a novel\nnature-inspired swarm optimisation algorithm that combines current-aware drift,\nirreversible settlement in persistent sensing nodes, and colony-based\ncommunication. Drawing inspiration from the behaviour of barnacle nauplii, NOAH\naddresses the critical limitations of existing swarm algorithms by providing\nhydrodynamic awareness, irreversible anchoring mechanisms, and colony-based\ncommunication capabilities essential for underwater exploration missions. The\nalgorithm establishes a comprehensive foundation for scalable and\nenergy-efficient underwater swarm robotics with validated performance analysis.\nValidation studies demonstrate an 86% success rate for permanent anchoring\nscenarios, providing a unified formulation for hydrodynamic constraints and\nirreversible settlement behaviours with an empirical study under flow."}
{"id": "2510.15365", "categories": ["eess.SY", "cs.LG", "cs.MA", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15365", "abs": "https://arxiv.org/abs/2510.15365", "authors": ["Maonan Wang", "Yirong Chen", "Yuxin Cai", "Aoyu Pang", "Yuejiao Xie", "Zian Ma", "Chengcheng Xu", "Kemou Jiang", "Ding Wang", "Laurent Roullet", "Chung Shue Chen", "Zhiyong Cui", "Yuheng Kan", "Michael Lepech", "Man-On Pun"], "title": "TranSimHub:A Unified Air-Ground Simulation Platform for Multi-Modal Perception and Decision-Making", "comment": "9 pages, 4 figures", "summary": "Air-ground collaborative intelligence is becoming a key approach for\nnext-generation urban intelligent transportation management, where aerial and\nground systems work together on perception, communication, and decision-making.\nHowever, the lack of a unified multi-modal simulation environment has limited\nprogress in studying cross-domain perception, coordination under communication\nconstraints, and joint decision optimization. To address this gap, we present\nTranSimHub, a unified simulation platform for air-ground collaborative\nintelligence. TranSimHub offers synchronized multi-view rendering across RGB,\ndepth, and semantic segmentation modalities, ensuring consistent perception\nbetween aerial and ground viewpoints. It also supports information exchange\nbetween the two domains and includes a causal scene editor that enables\ncontrollable scenario creation and counterfactual analysis under diverse\nconditions such as different weather, emergency events, and dynamic obstacles.\nWe release TranSimHub as an open-source platform that supports end-to-end\nresearch on perception, fusion, and control across realistic air and ground\ntraffic scenes. Our code is available at\nhttps://github.com/Traffic-Alpha/TranSimHub."}
{"id": "2510.15365", "categories": ["eess.SY", "cs.LG", "cs.MA", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15365", "abs": "https://arxiv.org/abs/2510.15365", "authors": ["Maonan Wang", "Yirong Chen", "Yuxin Cai", "Aoyu Pang", "Yuejiao Xie", "Zian Ma", "Chengcheng Xu", "Kemou Jiang", "Ding Wang", "Laurent Roullet", "Chung Shue Chen", "Zhiyong Cui", "Yuheng Kan", "Michael Lepech", "Man-On Pun"], "title": "TranSimHub:A Unified Air-Ground Simulation Platform for Multi-Modal Perception and Decision-Making", "comment": "9 pages, 4 figures", "summary": "Air-ground collaborative intelligence is becoming a key approach for\nnext-generation urban intelligent transportation management, where aerial and\nground systems work together on perception, communication, and decision-making.\nHowever, the lack of a unified multi-modal simulation environment has limited\nprogress in studying cross-domain perception, coordination under communication\nconstraints, and joint decision optimization. To address this gap, we present\nTranSimHub, a unified simulation platform for air-ground collaborative\nintelligence. TranSimHub offers synchronized multi-view rendering across RGB,\ndepth, and semantic segmentation modalities, ensuring consistent perception\nbetween aerial and ground viewpoints. It also supports information exchange\nbetween the two domains and includes a causal scene editor that enables\ncontrollable scenario creation and counterfactual analysis under diverse\nconditions such as different weather, emergency events, and dynamic obstacles.\nWe release TranSimHub as an open-source platform that supports end-to-end\nresearch on perception, fusion, and control across realistic air and ground\ntraffic scenes. Our code is available at\nhttps://github.com/Traffic-Alpha/TranSimHub."}
{"id": "2510.15236", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.15236", "abs": "https://arxiv.org/abs/2510.15236", "authors": ["Brett Reynolds"], "title": "From Checklists to Clusters: A Homeostatic Account of AGI Evaluation", "comment": "27 pages, 3 figures", "summary": "Contemporary AGI evaluations report multidomain capability profiles, yet they\ntypically assign symmetric weights and rely on snapshot scores. This creates\ntwo problems: (i) equal weighting treats all domains as equally important when\nhuman intelligence research suggests otherwise, and (ii) snapshot testing can't\ndistinguish durable capabilities from brittle performances that collapse under\ndelay or stress. I argue that general intelligence -- in humans and potentially\nin machines -- is better understood as a homeostatic property cluster: a set of\nabilities plus the mechanisms that keep those abilities co-present under\nperturbation. On this view, AGI evaluation should weight domains by their\ncausal centrality (their contribution to cluster stability) and require\nevidence of persistence across sessions. I propose two battery-compatible\nextensions: a centrality-prior score that imports CHC-derived weights with\ntransparent sensitivity analysis, and a Cluster Stability Index family that\nseparates profile persistence, durable learning, and error correction. These\nadditions preserve multidomain breadth while reducing brittleness and gaming. I\nclose with testable predictions and black-box protocols labs can adopt without\narchitectural access."}
{"id": "2510.15306", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15306", "abs": "https://arxiv.org/abs/2510.15306", "authors": ["Kuang-Da Wang", "Zhao Wang", "Yotaro Shimose", "Wei-Yao Wang", "Shingo Takamatsu"], "title": "WebGen-V Bench: Structured Representation for Enhancing Visual Design in LLM-based Web Generation and Evaluation", "comment": null, "summary": "Witnessed by the recent advancements on leveraging LLM for coding and\nmultimodal understanding, we present WebGen-V, a new benchmark and framework\nfor instruction-to-HTML generation that enhances both data quality and\nevaluation granularity. WebGen-V contributes three key innovations: (1) an\nunbounded and extensible agentic crawling framework that continuously collects\nreal-world webpages and can leveraged to augment existing benchmarks; (2) a\nstructured, section-wise data representation that integrates metadata,\nlocalized UI screenshots, and JSON-formatted text and image assets, explicit\nalignment between content, layout, and visual components for detailed\nmultimodal supervision; and (3) a section-level multimodal evaluation protocol\naligning text, layout, and visuals for high-granularity assessment. Experiments\nwith state-of-the-art LLMs and ablation studies validate the effectiveness of\nour structured data and section-wise evaluation, as well as the contribution of\neach component. To the best of our knowledge, WebGen-V is the first work to\nenable high-granularity agentic crawling and evaluation for instruction-to-HTML\ngeneration, providing a unified pipeline from real-world data acquisition and\nwebpage generation to structured multimodal assessment."}
{"id": "2510.15152", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15152", "abs": "https://arxiv.org/abs/2510.15152", "authors": ["Wenxin Zhang", "Yueying Li", "Ciamac C. Moallemi", "Tianyi Peng"], "title": "Tail-Optimized Caching for LLM Inference", "comment": null, "summary": "Prompt caching is critical for reducing latency and cost in LLM inference:\nOpenAI and Anthropic report up to 50-90% cost savings through prompt reuse.\nDespite its widespread success, little is known about what constitutes an\noptimal prompt caching policy, particularly when optimizing tail latency, a\nmetric of central importance to practitioners. The widely used Least Recently\nUsed (LRU) policy can perform arbitrarily poor on this metric, as it is\noblivious to the heterogeneity of conversation lengths. To address this gap, we\npropose Tail-Optimized LRU, a simple two-line modification that reallocates KV\ncache capacity to prioritize high-latency conversations by evicting cache\nentries that are unlikely to affect future turns. Though the implementation is\nsimple, we prove its optimality under a natural stochastic model of\nconversation dynamics, providing the first theoretical justification for LRU in\nthis setting, a result that may be of independent interest to the caching\ncommunity. Experimentally, on real conversation data WildChat, Tail-Optimized\nLRU achieves up to 27.5% reduction in P90 tail Time to First Token latency and\n23.9% in P95 tail latency compared to LRU, along with up to 38.9% decrease in\nSLO violations of 200ms. We believe this provides a practical and theoretically\ngrounded option for practitioners seeking to optimize tail latency in\nreal-world LLM deployments."}
{"id": "2510.15352", "categories": ["cs.RO", "cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2510.15352", "abs": "https://arxiv.org/abs/2510.15352", "authors": ["Alejandro Escontrela", "Justin Kerr", "Arthur Allshire", "Jonas Frey", "Rocky Duan", "Carmelo Sferrazza", "Pieter Abbeel"], "title": "GaussGym: An open-source real-to-sim framework for learning locomotion from pixels", "comment": null, "summary": "We present a novel approach for photorealistic robot simulation that\nintegrates 3D Gaussian Splatting as a drop-in renderer within vectorized\nphysics simulators such as IsaacGym. This enables unprecedented speed --\nexceeding 100,000 steps per second on consumer GPUs -- while maintaining high\nvisual fidelity, which we showcase across diverse tasks. We additionally\ndemonstrate its applicability in a sim-to-real robotics setting. Beyond\ndepth-based sensing, our results highlight how rich visual semantics improve\nnavigation and decision-making, such as avoiding undesirable regions. We\nfurther showcase the ease of incorporating thousands of environments from\niPhone scans, large-scale scene datasets (e.g., GrandTour, ARKit), and outputs\nfrom generative video models like Veo, enabling rapid creation of realistic\ntraining worlds. This work bridges high-throughput simulation and high-fidelity\nperception, advancing scalable and generalizable robot learning. All code and\ndata will be open-sourced for the community to build upon. Videos, code, and\ndata available at https://escontrela.me/gauss_gym/."}
{"id": "2510.15519", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15519", "abs": "https://arxiv.org/abs/2510.15519", "authors": ["Yushu Qin", "Marcos L. L. Sartori", "Shengyu Duan", "Emre Ozer", "Rishad Shafik", "Alex Yakovlev"], "title": "A Tsetlin Machine Image Classification Accelerator on a Flexible Substrate", "comment": "accepted by International Symposium on the Tsetlin Machine (ISTM)\n  2025", "summary": "This paper introduces the first implementation of digital Tsetlin Machines\n(TMs) on flexible integrated circuit (FlexIC) using Pragmatic's 600nm\nIGZO-based FlexIC technology. TMs, known for their energy efficiency,\ninterpretability, and suitability for edge computing, have previously been\nlimited by the rigidity of conventional silicon-based chips. We develop two TM\ninference models as FlexICs: one achieving 98.5% accuracy using 6800 NAND2\nequivalent logic gates with an area of 8X8 mm2, and a second more compact\nversion achieving slightly lower prediction accuracy of 93% but using only 1420\nNAND2 equivalent gates with an area of 4X4 mm2, both of which are\ncustom-designed for an 8X8-pixel handwritten digit recognition dataset. The\npaper demonstrates the feasibility of deploying flexible TM inference engines\ninto wearable healthcare and edge computing applications."}
{"id": "2510.15519", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15519", "abs": "https://arxiv.org/abs/2510.15519", "authors": ["Yushu Qin", "Marcos L. L. Sartori", "Shengyu Duan", "Emre Ozer", "Rishad Shafik", "Alex Yakovlev"], "title": "A Tsetlin Machine Image Classification Accelerator on a Flexible Substrate", "comment": "accepted by International Symposium on the Tsetlin Machine (ISTM)\n  2025", "summary": "This paper introduces the first implementation of digital Tsetlin Machines\n(TMs) on flexible integrated circuit (FlexIC) using Pragmatic's 600nm\nIGZO-based FlexIC technology. TMs, known for their energy efficiency,\ninterpretability, and suitability for edge computing, have previously been\nlimited by the rigidity of conventional silicon-based chips. We develop two TM\ninference models as FlexICs: one achieving 98.5% accuracy using 6800 NAND2\nequivalent logic gates with an area of 8X8 mm2, and a second more compact\nversion achieving slightly lower prediction accuracy of 93% but using only 1420\nNAND2 equivalent gates with an area of 4X4 mm2, both of which are\ncustom-designed for an 8X8-pixel handwritten digit recognition dataset. The\npaper demonstrates the feasibility of deploying flexible TM inference engines\ninto wearable healthcare and edge computing applications."}
{"id": "2510.15317", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15317", "abs": "https://arxiv.org/abs/2510.15317", "authors": ["Tingqiao Xu", "Ziru Zeng", "Jiayu Chen"], "title": "VERITAS: Leveraging Vision Priors and Expert Fusion to Improve Multimodal Data", "comment": "Accepted to EMNLP 2025 (Main Conference)", "summary": "The quality of supervised fine-tuning (SFT) data is crucial for the\nperformance of large multimodal models (LMMs), yet current data enhancement\nmethods often suffer from factual errors and hallucinations due to inadequate\nvisual perception. To address this challenge, we propose VERITAS, a pipeline\nthat systematically integrates vision priors and multiple state-of-the-art LMMs\nwith statistical methods to enhance SFT data quality. VERITAS leverages visual\nrecognition models (RAM++) and OCR systems (PP-OCRv4) to extract structured\nvision priors, which are combined with images, questions, and answers. Three\nLMMs (GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro) evaluate the original answers,\nproviding critique rationales and scores that are statistically fused into a\nhigh-confidence consensus score serving as ground truth. Using this consensus,\nwe train a lightweight critic model via Group Relative Policy Optimization\n(GRPO), enhancing reasoning capabilities efficiently. Each LMM then refines the\noriginal answers based on the critiques, generating new candidate answers; we\nselect the highest-scoring one as the final refined answer. Experiments across\nsix multimodal benchmarks demonstrate that models fine-tuned with data\nprocessed by VERITAS consistently outperform those using raw data, particularly\nin text-rich and fine-grained reasoning tasks. Our critic model exhibits\nenhanced capability comparable to state-of-the-art LMMs while being\nsignificantly more efficient. We release our pipeline, datasets, and model\ncheckpoints to advance research in multimodal data optimization."}
{"id": "2510.15189", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15189", "abs": "https://arxiv.org/abs/2510.15189", "authors": ["Xiangyu Chen", "Chuhao Zhou", "Yuxi Liu", "Jianfei Yang"], "title": "RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation", "comment": null, "summary": "Precise robot manipulation is critical for fine-grained applications such as\nchemical and biological experiments, where even small errors (e.g., reagent\nspillage) can invalidate an entire task. Existing approaches often rely on\npre-collected expert demonstrations and train policies via imitation learning\n(IL) or offline reinforcement learning (RL). However, obtaining high-quality\ndemonstrations for precision tasks is difficult and time-consuming, while\noffline RL commonly suffers from distribution shifts and low data efficiency.\nWe introduce a Role-Model Reinforcement Learning (RM-RL) framework that unifies\nonline and offline training in real-world environments. The key idea is a\nrole-model strategy that automatically generates labels for online training\ndata using approximately optimal actions, eliminating the need for human\ndemonstrations. RM-RL reformulates policy learning as supervised training,\nreducing instability from distribution mismatch and improving efficiency. A\nhybrid training scheme further leverages online role-model data for offline\nreuse, enhancing data efficiency through repeated sampling. Extensive\nexperiments show that RM-RL converges faster and more stably than existing RL\nmethods, yielding significant gains in real-world manipulation: 53% improvement\nin translation accuracy and 20% in rotation accuracy. Finally, we demonstrate\nthe successful execution of a challenging task, precisely placing a cell plate\nonto a shelf, highlighting the framework's effectiveness where prior methods\nfail."}
{"id": "2510.15376", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15376", "abs": "https://arxiv.org/abs/2510.15376", "authors": ["Zhaodong Yang", "Ai-Ping Hu", "Harish Ravichandar"], "title": "Towards Automated Chicken Deboning via Learning-based Dynamically-Adaptive 6-DoF Multi-Material Cutting", "comment": "8 Pages, 8 figures", "summary": "Automating chicken shoulder deboning requires precise 6-DoF cutting through a\npartially occluded, deformable, multi-material joint, since contact with the\nbones presents serious health and safety risks. Our work makes both\nsystems-level and algorithmic contributions to train and deploy a reactive\nforce-feedback cutting policy that dynamically adapts a nominal trajectory and\nenables full 6-DoF knife control to traverse the narrow joint gap while\navoiding contact with the bones. First, we introduce an open-source\ncustom-built simulator for multi-material cutting that models coupling,\nfracture, and cutting forces, and supports reinforcement learning, enabling\nefficient training and rapid prototyping. Second, we design a reusable physical\ntestbed to emulate the chicken shoulder: two rigid \"bone\" spheres with\ncontrollable pose embedded in a softer block, enabling rigorous and repeatable\nevaluation while preserving essential multi-material characteristics of the\ntarget problem. Third, we train and deploy a residual RL policy, with\ndiscretized force observations and domain randomization, enabling robust\nzero-shot sim-to-real transfer and the first demonstration of a learned policy\nthat debones a real chicken shoulder. Our experiments in our simulator, on our\nphysical testbed, and on real chicken shoulders show that our learned policy\nreliably navigates the joint gap and reduces undesired bone/cartilage contact,\nresulting in up to a 4x improvement over existing open-loop cutting baselines\nin terms of success rate and bone avoidance. Our results also illustrate the\nnecessity of force feedback for safe and effective multi-material cutting. The\nproject website is at https://sites.google.com/view/chickendeboning-2026."}
{"id": "2510.15573", "categories": ["eess.SY", "cs.MA", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15573", "abs": "https://arxiv.org/abs/2510.15573", "authors": ["Jianguo Chen", "Zhengqin Liu", "Jinlong Lei", "Peng Yi", "Yiguang Hong", "Hong Chen"], "title": "Hypergame-based Cognition Modeling and Intention Interpretation for Human-Driven Vehicles in Connected Mixed Traffic", "comment": null, "summary": "With the practical implementation of connected and autonomous vehicles\n(CAVs), the traffic system is expected to remain a mix of CAVs and human-driven\nvehicles (HVs) for the foreseeable future. To enhance safety and traffic\nefficiency, the trajectory planning strategies of CAVs must account for the\ninfluence of HVs, necessitating accurate HV trajectory prediction. Current\nresearch often assumes that human drivers have perfect knowledge of all\nvehicles' objectives, an unrealistic premise. This paper bridges the gap by\nleveraging hypergame theory to account for cognitive and perception limitations\nin HVs. We model human bounded rationality without assuming them to be merely\npassive followers and propose a hierarchical cognition modeling framework that\ncaptures cognitive relationships among vehicles. We further analyze the\ncognitive stability of the system, proving that the strategy profile where all\nvehicles adopt cognitively equilibrium strategies constitutes a hyper Nash\nequilibrium when CAVs accurately learn HV parameters. To achieve this, we\ndevelop an inverse learning algorithm for distributed intention interpretation\nvia vehicle-to-everything (V2X) communication, which extends the framework to\nboth offline and online scenarios. Additionally, we introduce a distributed\ntrajectory prediction and planning approach for CAVs, leveraging the learned\nparameters in real time. Simulations in highway lane-changing scenarios\ndemonstrate the proposed method's accuracy in parameter learning, robustness to\nnoisy trajectory observations, and safety in HV trajectory prediction. The\nresults validate the effectiveness of our method in both offline and online\nimplementations."}
{"id": "2510.15573", "categories": ["eess.SY", "cs.MA", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15573", "abs": "https://arxiv.org/abs/2510.15573", "authors": ["Jianguo Chen", "Zhengqin Liu", "Jinlong Lei", "Peng Yi", "Yiguang Hong", "Hong Chen"], "title": "Hypergame-based Cognition Modeling and Intention Interpretation for Human-Driven Vehicles in Connected Mixed Traffic", "comment": null, "summary": "With the practical implementation of connected and autonomous vehicles\n(CAVs), the traffic system is expected to remain a mix of CAVs and human-driven\nvehicles (HVs) for the foreseeable future. To enhance safety and traffic\nefficiency, the trajectory planning strategies of CAVs must account for the\ninfluence of HVs, necessitating accurate HV trajectory prediction. Current\nresearch often assumes that human drivers have perfect knowledge of all\nvehicles' objectives, an unrealistic premise. This paper bridges the gap by\nleveraging hypergame theory to account for cognitive and perception limitations\nin HVs. We model human bounded rationality without assuming them to be merely\npassive followers and propose a hierarchical cognition modeling framework that\ncaptures cognitive relationships among vehicles. We further analyze the\ncognitive stability of the system, proving that the strategy profile where all\nvehicles adopt cognitively equilibrium strategies constitutes a hyper Nash\nequilibrium when CAVs accurately learn HV parameters. To achieve this, we\ndevelop an inverse learning algorithm for distributed intention interpretation\nvia vehicle-to-everything (V2X) communication, which extends the framework to\nboth offline and online scenarios. Additionally, we introduce a distributed\ntrajectory prediction and planning approach for CAVs, leveraging the learned\nparameters in real time. Simulations in highway lane-changing scenarios\ndemonstrate the proposed method's accuracy in parameter learning, robustness to\nnoisy trajectory observations, and safety in HV trajectory prediction. The\nresults validate the effectiveness of our method in both offline and online\nimplementations."}
{"id": "2510.15374", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15374", "abs": "https://arxiv.org/abs/2510.15374", "authors": ["Zezhong Tan", "Hang Gao", "Xinhong Ma", "Feng Zhang", "Ziqiang Dong"], "title": "Towards Flash Thinking via Decoupled Advantage Policy Optimization", "comment": null, "summary": "Recent Large Reasoning Models (LRMs) have achieved remarkable performance in\nsolving complex problems via supervised fine-tuning (SFT) and reinforcement\nlearning (RL). Although existing RL algorithms significantly enhance model\naccuracy, they still suffer from excessively lengthy responses and overthinking\nissues, resulting in increased inference latency and computational consumption,\nespecially for simple tasks that require minimal reasoning. To address this, we\npropose a novel RL framework, DEPO, to reduce inefficient reasoning for models.\nOur method mainly consists of three core components: (1) an innovative\nadvantage decoupled algorithm to guide model reduction of inefficient tokens;\n(2) a difficulty-aware length penalty to lower the overall length of model\nresponses; (3) an advantage clipping method to prevent bias in policy\noptimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and\nDeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant\nreduction in sequence length by 39% and reduces excessive reasoning paths in\ninefficient tokens, while outperforming the base model in overall accuracy."}
{"id": "2510.15190", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15190", "abs": "https://arxiv.org/abs/2510.15190", "authors": ["Oumaima Barhoumi", "Ghazal Farhani", "Taufiq Rahman", "Mohamed H. Zaki", "Sofiène Tahar"], "title": "A Comparative Study of Oscillatory Perturbations in Car-Following Models", "comment": null, "summary": "As connected and autonomous vehicles become more widespread, platooning has\nemerged as a key strategy to improve road capacity, reduce fuel consumption,\nand enhance traffic flow. However, the benefits of platoons strongly depend on\ntheir ability to maintain stability. Instability can lead to unsafe spacing and\nincreased energy usage. In this work, we study platoon instability and analyze\nthe root cause of its occurrence, as well as its impacts on the following\nvehicle. To achieve this, we propose a comparative study between different\ncar-following models such as the Intelligent Driver Model (IDM), the Optimal\nVelocity Model (OVM), the General Motors Model (GMM), and the Cooperative\nAdaptive Cruise Control (CACC). In our approach, we introduce a disruption in\nthe model by varying the velocity of the leading vehicle to visualize the\nbehavior of the following vehicles. To evaluate the dynamic response of each\nmodel, we introduce controlled perturbations in the velocity of the leading\nvehicle, specifically, sinusoidal oscillations and discrete velocity changes.\nThe resulting vehicle trajectories and variations in inter-vehicle spacing are\nanalyzed to assess the robustness of each model to disturbance propagation. The\nfindings offer insight into model sensitivity, stability characteristics, and\nimplications for designing resilient platooning control strategies."}
{"id": "2510.15446", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15446", "abs": "https://arxiv.org/abs/2510.15446", "authors": ["Ziang Guo", "Zufeng Zhang"], "title": "VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving", "comment": "1st version", "summary": "In autonomous driving, dynamic environment and corner cases pose significant\nchallenges to the robustness of ego vehicle's state understanding and decision\nmaking. We introduce VDRive, a novel pipeline for end-to-end autonomous driving\nthat explicitly models state-action mapping to address these challenges,\nenabling interpretable and robust decision making. By leveraging the\nadvancement of the state understanding of the Vision Language Action Model\n(VLA) with generative diffusion policy-based action head, our VDRive guides the\ndriving contextually and geometrically. Contextually, VLA predicts future\nobservations through token generation pre-training, where the observations are\nrepresented as discrete codes by a Conditional Vector Quantized Variational\nAutoencoder (CVQ-VAE). Geometrically, we perform reinforcement learning\nfine-tuning of the VLA to predict future trajectories and actions based on\ncurrent driving conditions. VLA supplies the current state tokens and predicted\nstate tokens for the action policy head to generate hierarchical actions and\ntrajectories. During policy training, a learned critic evaluates the actions\ngenerated by the policy and provides gradient-based feedback, forming an\nactor-critic framework that enables a reinforcement-based policy learning\npipeline. Experiments show that our VDRive achieves state-of-the-art\nperformance in the Bench2Drive closed-loop benchmark and nuScenes open-loop\nplanning."}
{"id": "2510.15598", "categories": ["eess.SY", "cs.SY", "93B07, 93C05, 15A66"], "pdf": "https://arxiv.org/pdf/2510.15598", "abs": "https://arxiv.org/abs/2510.15598", "authors": ["Michael Sebek"], "title": "Observer Design over Hypercomplex Quaternions", "comment": "Accepted for presentation at the 24th European Control Conference\n  (ECC 2026), Reykjavik, Iceland. This work was co-funded by the European Union\n  under the project ROBOPROX (reg. no. CZ.02.01.01/00/22 008/0004590)", "summary": "We develop observer design over hypercomplex quaternions in a\ncharacteristic-polynomial-free framework. Using the standard right-module\nconvention, we derive a right observable companion form and its companion\npolynomial that encodes error dynamics via right-eigenvalue similarity classes.\nThe design mirrors the real/complex case - coefficient updates in companion\ncoordinates, followed by a similarity back - yet avoids determinants,\ncharacteristic/minimal polynomials, and Cayley-Hamilton identities that do not\ntransfer to quaternions. We also give an Ackermann-type construction for the\nimportant case of closed-loop companion polynomials with real coefficients,\nensuring similarity-equivariant evaluation. The results yield simple recipes\nfor full-order observers directly over quaternions, clarify the role of right\nspectra and their similarity classes, and pinpoint when classical one-shot\nformulas remain valid. Numerical examples illustrate the method and advantages\nover vectorized or complex-adjoint surrogates."}
{"id": "2510.15598", "categories": ["eess.SY", "cs.SY", "93B07, 93C05, 15A66"], "pdf": "https://arxiv.org/pdf/2510.15598", "abs": "https://arxiv.org/abs/2510.15598", "authors": ["Michael Sebek"], "title": "Observer Design over Hypercomplex Quaternions", "comment": "Accepted for presentation at the 24th European Control Conference\n  (ECC 2026), Reykjavik, Iceland. This work was co-funded by the European Union\n  under the project ROBOPROX (reg. no. CZ.02.01.01/00/22 008/0004590)", "summary": "We develop observer design over hypercomplex quaternions in a\ncharacteristic-polynomial-free framework. Using the standard right-module\nconvention, we derive a right observable companion form and its companion\npolynomial that encodes error dynamics via right-eigenvalue similarity classes.\nThe design mirrors the real/complex case - coefficient updates in companion\ncoordinates, followed by a similarity back - yet avoids determinants,\ncharacteristic/minimal polynomials, and Cayley-Hamilton identities that do not\ntransfer to quaternions. We also give an Ackermann-type construction for the\nimportant case of closed-loop companion polynomials with real coefficients,\nensuring similarity-equivariant evaluation. The results yield simple recipes\nfor full-order observers directly over quaternions, clarify the role of right\nspectra and their similarity classes, and pinpoint when classical one-shot\nformulas remain valid. Numerical examples illustrate the method and advantages\nover vectorized or complex-adjoint surrogates."}
{"id": "2510.15387", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15387", "abs": "https://arxiv.org/abs/2510.15387", "authors": ["Davide Basso", "Luca Bortolussi", "Mirjana Videnovic-Misic", "Husni Habal"], "title": "Advancing Routing-Awareness in Analog ICs Floorplanning", "comment": null, "summary": "The adoption of machine learning-based techniques for analog integrated\ncircuit layout, unlike its digital counterpart, has been limited by the\nstringent requirements imposed by electric and problem-specific constraints,\nalong with the interdependence of floorplanning and routing steps. In this\nwork, we address a prevalent concern among layout engineers regarding the need\nfor readily available routing-aware floorplanning solutions. To this extent, we\ndevelop an automatic floorplanning engine based on reinforcement learning and\nrelational graph convolutional neural network specifically tailored to\ncondition the floorplan generation towards more routable outcomes. A\ncombination of increased grid resolution and precise pin information\nintegration, along with a dynamic routing resource estimation technique, allows\nbalancing routing and area efficiency, eventually meeting industrial standards.\nWhen analyzing the place and route effectiveness in a simulated environment,\nthe proposed approach achieves a 13.8% reduction in dead space, a 40.6%\nreduction in wirelength and a 73.4% increase in routing success when compared\nto past learning-based state-of-the-art techniques."}
{"id": "2510.15199", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15199", "abs": "https://arxiv.org/abs/2510.15199", "authors": ["Borna Monazzah Moghaddam", "Robin Chhabra"], "title": "Lagrange-Poincaré-Kepler Equations of Disturbed Space-Manipulator Systems in Orbit", "comment": null, "summary": "This article presents an extension of the Lagrange-Poincare Equations (LPE)\nto model the dynamics of spacecraft-manipulator systems operating within a\nnon-inertial orbital reference frame. Building upon prior formulations of LPE\nfor vehicle-manipulator systems, the proposed framework, termed the\nLagrange-Poincare-Kepler Equations (LPKE), incorporates the coupling between\nspacecraft attitude dynamics, orbital motion, and manipulator kinematics. The\nformalism combines the Euler-Poincare equations for the base spacecraft,\nKeplerian orbital dynamics for the reference frame, and reduced Euler-Lagrange\nequations for the manipulator's shape space, using an exponential joint\nparametrization. Leveraging the Lagrange-d'Alembert principle on principal\nbundles, we derive novel closed-form structural matrices that explicitly\ncapture the effects of orbital disturbances and their dynamic coupling with the\nmanipulator system. The LPKE framework also systematically includes externally\napplied, symmetry-breaking wrenches, allowing for immediate integration into\nhardware-in-the-loop simulations and model-based control architectures for\nautonomous robotic operations in the orbital environment. To illustrate the\neffectiveness of the proposed model and its numerical superiority, we present a\nsimulation study analyzing orbital effects on a 7-degree-of-freedom manipulator\nmounted on a spacecraft."}
{"id": "2510.15505", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15505", "abs": "https://arxiv.org/abs/2510.15505", "authors": ["Aron Distelzweig", "Faris Janjoš", "Oliver Scheel", "Sirish Reddy Varra", "Raghu Rajan", "Joschka Boedecker"], "title": "Perfect Prediction or Plenty of Proposals? What Matters Most in Planning for Autonomous Driving", "comment": "8 pages, 5 figures", "summary": "Traditionally, prediction and planning in autonomous driving (AD) have been\ntreated as separate, sequential modules. Recently, there has been a growing\nshift towards tighter integration of these components, known as Integrated\nPrediction and Planning (IPP), with the aim of enabling more informed and\nadaptive decision-making. However, it remains unclear to what extent this\nintegration actually improves planning performance. In this work, we\ninvestigate the role of prediction in IPP approaches, drawing on the widely\nadopted Val14 benchmark, which encompasses more common driving scenarios with\nrelatively low interaction complexity, and the interPlan benchmark, which\nincludes highly interactive and out-of-distribution driving situations. Our\nanalysis reveals that even access to perfect future predictions does not lead\nto better planning outcomes, indicating that current IPP methods often fail to\nfully exploit future behavior information. Instead, we focus on high-quality\nproposal generation, while using predictions primarily for collision checks. We\nfind that many imitation learning-based planners struggle to generate realistic\nand plausible proposals, performing worse than PDM - a simple lane-following\napproach. Motivated by this observation, we build on PDM with an enhanced\nproposal generation method, shifting the emphasis towards producing diverse but\nrealistic and high-quality proposals. This proposal-centric approach\nsignificantly outperforms existing methods, especially in out-of-distribution\nand highly interactive settings, where it sets new state-of-the-art results."}
{"id": "2510.15613", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15613", "abs": "https://arxiv.org/abs/2510.15613", "authors": ["Clément Moureau", "Thomas Stegen", "Mevludin Glavic", "Bertrand Cornélusse"], "title": "A Predictive Flexibility Aggregation Method for Low Voltage Distribution System Control", "comment": "8 pages, 6 figures", "summary": "This paper presents a predictive control strategy to manage low-voltage\ndistribution systems. The proposed approach relies on an aggregate of the\nflexibility at the residential unit level into a three-dimensional chart that\nrepresents the injected active and reactive power, and the flexibility cost.\nFirst, this method solves a multiparametric optimization problem offline at the\nresidential unit level to aggregate the flexibility of the assets. Then, a\nsemi-explicit model predictive control problem is solved to account for\nforecasts. By combining the results of these problems with measurements, the\nmethod generates the desired flexibility chart. The proposed approach is\ncompatible with realtime control requirements, as heavy computations are\nperformed offline locally, making it naturally parallelizable. By linking\nrealtime flexibility assessment with energy scheduling, our approach enables\nefficient, low-cost, and privacy-preserving management of low-voltage\ndistribution systems. We validate this method on a low-voltage network of 5\nbuses by comparing it with an ideal technique."}
{"id": "2510.15613", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15613", "abs": "https://arxiv.org/abs/2510.15613", "authors": ["Clément Moureau", "Thomas Stegen", "Mevludin Glavic", "Bertrand Cornélusse"], "title": "A Predictive Flexibility Aggregation Method for Low Voltage Distribution System Control", "comment": "8 pages, 6 figures", "summary": "This paper presents a predictive control strategy to manage low-voltage\ndistribution systems. The proposed approach relies on an aggregate of the\nflexibility at the residential unit level into a three-dimensional chart that\nrepresents the injected active and reactive power, and the flexibility cost.\nFirst, this method solves a multiparametric optimization problem offline at the\nresidential unit level to aggregate the flexibility of the assets. Then, a\nsemi-explicit model predictive control problem is solved to account for\nforecasts. By combining the results of these problems with measurements, the\nmethod generates the desired flexibility chart. The proposed approach is\ncompatible with realtime control requirements, as heavy computations are\nperformed offline locally, making it naturally parallelizable. By linking\nrealtime flexibility assessment with energy scheduling, our approach enables\nefficient, low-cost, and privacy-preserving management of low-voltage\ndistribution systems. We validate this method on a low-voltage network of 5\nbuses by comparing it with an ideal technique."}
{"id": "2510.15395", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15395", "abs": "https://arxiv.org/abs/2510.15395", "authors": ["Rubi Hudson"], "title": "Corrigibility Transformation: Constructing Goals That Accept Updates", "comment": null, "summary": "For an AI's training process to successfully impart a desired goal, it is\nimportant that the AI does not attempt to resist the training. However,\npartially learned goals will often incentivize an AI to avoid further goal\nupdates, as most goals are better achieved by an AI continuing to pursue them.\nWe say that a goal is corrigible if it does not incentivize taking actions that\navoid proper goal updates or shutdown. In addition to convergence in training,\ncorrigibility also allows for correcting mistakes and changes in human\npreferences, which makes it a crucial safety property. Despite this, the\nexisting literature does not include specifications for goals that are both\ncorrigible and competitive with non-corrigible alternatives. We provide a\nformal definition for corrigibility, then introduce a transformation that\nconstructs a corrigible version of any goal that can be made corrigible,\nwithout sacrificing performance. This is done by myopically eliciting\npredictions of reward conditional on costlessly preventing updates, which then\nalso determine the reward when updates are accepted. The transformation can be\nmodified to recursively extend corrigibility to any new agents created by\ncorrigible agents, and to prevent agents from deliberately modifying their\ngoals. Two gridworld experiments demonstrate that these corrigible goals can be\nlearned effectively, and that they lead to the desired behavior."}
{"id": "2510.15220", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15220", "abs": "https://arxiv.org/abs/2510.15220", "authors": ["Kevin Christiansen Marsim", "Minho Oh", "Byeongho Yu", "Seungjae Lee", "I Made Aswin Nahrendra", "Hyungtae Lim", "Hyun Myung"], "title": "LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization", "comment": "8 Pages, 9 Figures", "summary": "Autonomous navigation for legged robots in complex and dynamic environments\nrelies on robust simultaneous localization and mapping (SLAM) systems to\naccurately map surroundings and localize the robot, ensuring safe and efficient\noperation. While prior sensor fusion-based SLAM approaches have integrated\nvarious sensor modalities to improve their robustness, these algorithms are\nstill susceptible to estimation drift in challenging environments due to their\nreliance on unsuitable fusion strategies. Therefore, we propose a robust\nLiDAR-visual-inertial-kinematic odometry system that integrates information\nfrom multiple sensors, such as a camera, LiDAR, inertial measurement unit\n(IMU), and joint encoders, for visual and LiDAR-based odometry estimation. Our\nsystem employs a fusion-based pose estimation approach that runs\noptimization-based visual-inertial-kinematic odometry (VIKO) and filter-based\nLiDAR-inertial-kinematic odometry (LIKO) based on measurement availability. In\nVIKO, we utilize the footpreintegration technique and robust LiDAR-visual depth\nconsistency using superpixel clusters in a sliding window optimization. In\nLIKO, we incorporate foot kinematics and employ a point-toplane residual in an\nerror-state iterative Kalman filter (ESIKF). Compared with other sensor\nfusion-based SLAM algorithms, our approach shows robust performance across\npublic and longterm datasets."}
{"id": "2510.15530", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15530", "abs": "https://arxiv.org/abs/2510.15530", "authors": ["Zehao Ni", "Yonghao He", "Lingfeng Qian", "Jilei Mao", "Fa Fu", "Wei Sui", "Hu Su", "Junran Peng", "Zhipeng Wang", "Bin He"], "title": "VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation", "comment": null, "summary": "In the context of imitation learning, visuomotor-based diffusion policy\nlearning is one of the main directions in robotic manipulation. Most of these\napproaches rely on point clouds as observation inputs and construct scene\nrepresentations through point clouds feature learning, which enables them to\nachieve remarkable accuracy. However, the existing literature lacks an in-depth\nexploration of vision-only solutions that have significant potential. In this\npaper, we propose a Vision-Only and single-view Diffusion Policy learning\nmethod (VO-DP) that leverages pretrained visual foundation models to achieve\neffective fusion of semantic and geometric features. We utilize intermediate\nfeatures from VGGT incorporating semantic features from DINOv2 and geometric\nfeatures from Alternating Attention blocks. Features are fused via\ncross-attention and spatially compressed with a CNN to form the input to the\npolicy head. Extensive experiments demonstrate that VO-DP not only outperforms\nthe vision-only baseline DP significantly but also exhibits distinct\nperformance trends against the point cloud-based method DP3: in simulation\ntasks, VO-DP achieves an average success rate of 64.6% on par with DP3 64.0%\nand far higher than DP 34.8%, while in real-world tasks, it reaches 87.9%,\noutperforming both DP3 67.5% and DP 11.2% by a notable margin. Further\nrobustness evaluations confirm that VO-DP remains highly stable under varying\nconditions including color, size, background, and lighting. Lastly, we\nopen-source a training library for robotic manipulation. Built on Accelerate,\nthis library supports multi-machine and multi-GPU parallel training, as well as\nmixed precision training. It is compatible with visuomotor policies such as DP,\nDP3 and VO-DP, and also supports the RoboTwin simulator."}
{"id": "2510.15695", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15695", "abs": "https://arxiv.org/abs/2510.15695", "authors": ["Sheng Wang", "Muhammad Maladoh Bah"], "title": "Cross-border offshore hydrogen trade and carbon mitigation for Europe's net zero transition", "comment": null, "summary": "European countries are ambitious in both the net-zero transition and offshore\nenergy resource development. The Irish and UK governments announced their\ncommitments to offshore wind capacities - 37 and 125 GW, respectively, in 2050,\nmore than two times higher than their projected power demands. While other\ncontinental countries, such as Germany, are calling for cleaner fuel resources.\nExporting surplus offshore green hydrogen and bridging supply and demand could\nbe pivotal in carbon emission mitigation for Europe. Yet, the potentials of\nthese Island countries, are usually underestimated. This paper developed a\nbottom-up method to investigate the role of offshore hydrogen from Ireland and\nthe UK in the decarbonisation of the entire Europe. We evaluate the future\nhydrogen/ammonia trading and the contributions of each country in carbon\nemission mitigation, considering their relative cost-competitiveness in\noffshore hydrogen production, domestic hourly power and gas system operation,\nand international shipping costs. Results indicate that the offshore green\nhydrogen could reduce 175.16 Mt/year of carbon dioxide emissions in Europe. The\nUK will be the largest hydrogen supplier from 2030 to 2040, while surpassed by\nIreland in 2050, with 161 TWh of hydrogen exports to France and Spain. The\noffshore green hydrogen can contribute to 175.16 Mt of annual carbon dioxide\nemission reductions in total. This general flow of hydrogen from the West to\nthe East not only facilitates Europe's net-zero progress, but also reshapes the\nenergy supply structure and helps to ensure energy security across the European\ncontinent."}
{"id": "2510.15695", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15695", "abs": "https://arxiv.org/abs/2510.15695", "authors": ["Sheng Wang", "Muhammad Maladoh Bah"], "title": "Cross-border offshore hydrogen trade and carbon mitigation for Europe's net zero transition", "comment": null, "summary": "European countries are ambitious in both the net-zero transition and offshore\nenergy resource development. The Irish and UK governments announced their\ncommitments to offshore wind capacities - 37 and 125 GW, respectively, in 2050,\nmore than two times higher than their projected power demands. While other\ncontinental countries, such as Germany, are calling for cleaner fuel resources.\nExporting surplus offshore green hydrogen and bridging supply and demand could\nbe pivotal in carbon emission mitigation for Europe. Yet, the potentials of\nthese Island countries, are usually underestimated. This paper developed a\nbottom-up method to investigate the role of offshore hydrogen from Ireland and\nthe UK in the decarbonisation of the entire Europe. We evaluate the future\nhydrogen/ammonia trading and the contributions of each country in carbon\nemission mitigation, considering their relative cost-competitiveness in\noffshore hydrogen production, domestic hourly power and gas system operation,\nand international shipping costs. Results indicate that the offshore green\nhydrogen could reduce 175.16 Mt/year of carbon dioxide emissions in Europe. The\nUK will be the largest hydrogen supplier from 2030 to 2040, while surpassed by\nIreland in 2050, with 161 TWh of hydrogen exports to France and Spain. The\noffshore green hydrogen can contribute to 175.16 Mt of annual carbon dioxide\nemission reductions in total. This general flow of hydrogen from the West to\nthe East not only facilitates Europe's net-zero progress, but also reshapes the\nenergy supply structure and helps to ensure energy security across the European\ncontinent."}
{"id": "2510.15414", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15414", "abs": "https://arxiv.org/abs/2510.15414", "authors": ["Huining Yuan", "Zelai Xu", "Zheyue Tan", "Xiangmin Yi", "Mo Guang", "Kaiwen Long", "Haojia Hui", "Boxun Li", "Xinlei Chen", "Bo Zhao", "Xiao-Ping Zhang", "Chao Yu", "Yu Wang"], "title": "MARS: Reinforcing Multi-Agent Reasoning of LLMs through Self-Play in Strategic Games", "comment": null, "summary": "Developing Large Language Models (LLMs) to cooperate and compete effectively\nwithin multi-agent systems is a critical step towards more advanced\nintelligence. While reinforcement learning (RL) has proven effective for\nenhancing reasoning in single-agent tasks, its extension to multi-turn,\nmulti-agent scenarios remains underexplored due to the challenges of\nlong-horizon credit assignment and agent-specific advantage estimation. To\naddress these challenges, we introduce MARS, an end-to-end RL framework that\nincentivizes Multi-Agent Reasoning of LLMs through Self-play in both\ncooperative and competitive games. MARS features a turn-level advantage\nestimator that aligns learning signals with each interaction for credit\nassignment, and an agent-specific advantage normalization to stabilize\nmulti-agent training. By learning with self-play across cooperative and\ncompetitive games, the MARS agent trained from Qwen3-4B develops strong\nstrategic abilities that generalize to held-out games with up to 28.7%\nperformance improvements. More importantly, the capability acquired through\nself-play generalizes beyond games, yielding consistent performance gains of\nmulti-agent systems in reasoning benchmarks. When integrated into leading\nmulti-agent systems, our MARS agent achieves significant performance gains of\n10.0% on AIME and 12.5% on GPQA-Diamond. These results establish end-to-end RL\ntraining with self-play in strategic games as a powerful approach for\ndeveloping generalizable multi-agent reasoning capabilities in LLMs. Our code\nand models are publicly available at https://github.com/thu-nics/MARS."}
{"id": "2510.15221", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15221", "abs": "https://arxiv.org/abs/2510.15221", "authors": ["Xiao Sun"], "title": "WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing", "comment": "15 pages, 4 figures, 1 table. Dataset publicly available under CC BY\n  4.0 license", "summary": "Automated emotion recognition in real-world workplace settings remains a\nchallenging problem in affective computing due to the scarcity of large-scale,\nlongitudinal datasets collected in naturalistic environments. We present a\nnovel dataset comprising 733,651 facial expression records from 38 employees\ncollected over 30.5 months (November 2021 to May 2024) in an authentic office\nenvironment. Each record contains seven emotion probabilities (neutral, happy,\nsad, surprised, fear, disgusted, angry) derived from deep learning-based facial\nexpression recognition, along with comprehensive metadata including job roles,\nemployment outcomes, and personality traits. The dataset uniquely spans the\nCOVID-19 pandemic period, capturing emotional responses to major societal\nevents including the Shanghai lockdown and policy changes. We provide 32\nextended emotional metrics computed using established affective science\nmethods, including valence, arousal, volatility, predictability, inertia, and\nemotional contagion strength. Technical validation demonstrates high data\nquality through successful replication of known psychological patterns (weekend\neffect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and\nperfect predictive validity for employee turnover (AUC=1.0). Baseline\nexperiments using Random Forest and LSTM models achieve 91.2% accuracy for\nemotion classification and R2 = 0.84 for valence prediction. This is the\nlargest and longest longitudinal workplace emotion dataset publicly available,\nenabling research in emotion recognition, affective dynamics modeling,\nemotional contagion, turnover prediction, and emotion-aware system design."}
{"id": "2510.15533", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15533", "abs": "https://arxiv.org/abs/2510.15533", "authors": ["Shilei Li", "Dawei Shi", "Makoto Iwasaki", "Yan Ning", "Hongpeng Zhou", "Ling Shi"], "title": "Improved Extended Kalman Filter-Based Disturbance Observers for Exoskeletons", "comment": null, "summary": "The nominal performance of mechanical systems is often degraded by unknown\ndisturbances. A two-degree-of-freedom control structure can decouple nominal\nperformance from disturbance rejection. However, perfect disturbance rejection\nis unattainable when the disturbance dynamic is unknown. In this work, we\nreveal an inherent trade-off in disturbance estimation subject to tracking\nspeed and tracking uncertainty. Then, we propose two novel methods to enhance\ndisturbance estimation: an interacting multiple model extended Kalman\nfilter-based disturbance observer and a multi-kernel correntropy extended\nKalman filter-based disturbance observer. Experiments on an exoskeleton verify\nthat the proposed two methods improve the tracking accuracy $36.3\\%$ and\n$16.2\\%$ in hip joint error, and $46.3\\%$ and $24.4\\%$ in knee joint error,\nrespectively, compared to the extended Kalman filter-based disturbance\nobserver, in a time-varying interaction force scenario, demonstrating the\nsuperiority of the proposed method."}
{"id": "2510.15707", "categories": ["eess.SY", "cs.SY", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.15707", "abs": "https://arxiv.org/abs/2510.15707", "authors": ["Martín de Frutos", "Laura Botero-Bolívar", "Esteban Ferrer"], "title": "Mitigating Underwater Noise from Offshore Wind Turbines via Individual Pitch Control", "comment": null, "summary": "This paper proposes a pitch control strategy to mitigate the underwater\nacoustic footprint of offshore wind turbines, a measure that will soon become\nnecessary to minimize impacts on marine life, which rely on sound for\ncommunication, navigation, and survival. First, we quantify the underwater\nacoustic signature of blade-generated aerodynamic noise from three reference\nturbines, the NREL 5 MW, DTU 10 MW, and IEA 22 MW, using coupling blade element\nmomentum and coupled air-water acoustic propagation modeling. Second, we\npropose and implement an open-loop individual pitch control (IPC) strategy that\nmodulates the pitch of the blade at the blade passing frequency to attenuate\nthe overall sound pressure level (OSPL) and the amplitude modulation (AM) of\nthe transmitted noise. Third, we benchmark IPC performance against conventional\npitch schemes. The results indicate that up to 5 dB reductions in OSPL and a\ndecrease in AM depth 20% can be achieved with a pitch variation of\n$\\Delta\\theta\\approx 5^\\circ$, with small losses (5-10%) in energy capture.\nThese findings highlight a previously underappreciated noise pathway and\ndemonstrate that targeted blade-pitch modulation can mitigate its impact."}
{"id": "2510.15707", "categories": ["eess.SY", "cs.SY", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.15707", "abs": "https://arxiv.org/abs/2510.15707", "authors": ["Martín de Frutos", "Laura Botero-Bolívar", "Esteban Ferrer"], "title": "Mitigating Underwater Noise from Offshore Wind Turbines via Individual Pitch Control", "comment": null, "summary": "This paper proposes a pitch control strategy to mitigate the underwater\nacoustic footprint of offshore wind turbines, a measure that will soon become\nnecessary to minimize impacts on marine life, which rely on sound for\ncommunication, navigation, and survival. First, we quantify the underwater\nacoustic signature of blade-generated aerodynamic noise from three reference\nturbines, the NREL 5 MW, DTU 10 MW, and IEA 22 MW, using coupling blade element\nmomentum and coupled air-water acoustic propagation modeling. Second, we\npropose and implement an open-loop individual pitch control (IPC) strategy that\nmodulates the pitch of the blade at the blade passing frequency to attenuate\nthe overall sound pressure level (OSPL) and the amplitude modulation (AM) of\nthe transmitted noise. Third, we benchmark IPC performance against conventional\npitch schemes. The results indicate that up to 5 dB reductions in OSPL and a\ndecrease in AM depth 20% can be achieved with a pitch variation of\n$\\Delta\\theta\\approx 5^\\circ$, with small losses (5-10%) in energy capture.\nThese findings highlight a previously underappreciated noise pathway and\ndemonstrate that targeted blade-pitch modulation can mitigate its impact."}
{"id": "2510.15416", "categories": ["cs.AI", "68T05, 68T42", "I.2.11; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2510.15416", "abs": "https://arxiv.org/abs/2510.15416", "authors": ["Pavan C Shekar", "Ashwanth Krishnan"], "title": "Adaptive Minds: Empowering Agents with LoRA-as-Tools", "comment": "12 pages, 1 figure, 7 tables . Code available at:\n  https://github.com/qpiai/adaptive-minds", "summary": "We present Adaptive Minds, an agentic system that treats LoRA adapters as\ndomain-specific tools. Instead of relying on a single fine-tuned model or rigid\nrule-based routing, our approach empowers the base LLM itself to act as a\nsemantic router analyzing each query and dynamically selecting the most\nrelevant LoRA tool. This enables the agent to seamlessly switch between\ndifferent domain experts on demand. By combining the flexibility of multi-agent\norchestration with the efficiency of parameter-efficient fine-tuning, Adaptive\nMinds delivers accurate, specialized responses while preserving conversational\nability. The system is built with LangGraph for workflow management, supports\nboth API and web interfaces, and is fully open source, providing a scalable and\nextensible foundation for domain-adaptive AI assistance."}
{"id": "2510.15226", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15226", "abs": "https://arxiv.org/abs/2510.15226", "authors": ["Mrunal Sarvaiya", "Guanrui Li", "Giuseppe Loianno"], "title": "PolyFly: Polytopic Optimal Planning for Collision-Free Cable-Suspended Aerial Payload Transportation", "comment": null, "summary": "Aerial transportation robots using suspended cables have emerged as versatile\nplatforms for disaster response and rescue operations. To maximize the\ncapabilities of these systems, robots need to aggressively fly through tightly\nconstrained environments, such as dense forests and structurally unsafe\nbuildings, while minimizing flight time and avoiding obstacles. Existing\nmethods geometrically over-approximate the vehicle and obstacles, leading to\nconservative maneuvers and increased flight times. We eliminate these\nrestrictions by proposing PolyFly, an optimal global planner which considers a\nnon-conservative representation for aerial transportation by modeling each\nphysical component of the environment, and the robot (quadrotor, cable and\npayload), as independent polytopes. We further increase the model accuracy by\nincorporating the attitude of the physical components by constructing\norientation-aware polytopes. The resulting optimal control problem is\nefficiently solved by converting the polytope constraints into smooth\ndifferentiable constraints via duality theory. We compare our method against\nthe existing state-of-the-art approach in eight maze-like environments and show\nthat PolyFly produces faster trajectories in each scenario. We also\nexperimentally validate our proposed approach on a real quadrotor with a\nsuspended payload, demonstrating the practical reliability and accuracy of our\nmethod."}
{"id": "2510.15626", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15626", "abs": "https://arxiv.org/abs/2510.15626", "authors": ["Hongyu Zhou", "Xiaoyu Zhang", "Vasileios Tzoumas"], "title": "Adaptive Legged Locomotion via Online Learning for Model Predictive Control", "comment": "9 pages", "summary": "We provide an algorithm for adaptive legged locomotion via online learning\nand model predictive control. The algorithm is composed of two interacting\nmodules: model predictive control (MPC) and online learning of residual\ndynamics. The residual dynamics can represent modeling errors and external\ndisturbances. We are motivated by the future of autonomy where quadrupeds will\nautonomously perform complex tasks despite real-world unknown uncertainty, such\nas unknown payload and uneven terrains. The algorithm uses random Fourier\nfeatures to approximate the residual dynamics in reproducing kernel Hilbert\nspaces. Then, it employs MPC based on the current learned model of the residual\ndynamics. The model is updated online in a self-supervised manner using least\nsquares based on the data collected while controlling the quadruped. The\nalgorithm enjoys sublinear \\textit{dynamic regret}, defined as the\nsuboptimality against an optimal clairvoyant controller that knows how the\nresidual dynamics. We validate our algorithm in Gazebo and MuJoCo simulations,\nwhere the quadruped aims to track reference trajectories. The Gazebo\nsimulations include constant unknown external forces up to $12\\boldsymbol{g}$,\nwhere $\\boldsymbol{g}$ is the gravity vector, in flat terrain, slope terrain\nwith $20\\degree$ inclination, and rough terrain with $0.25m$ height variation.\nThe MuJoCo simulations include time-varying unknown disturbances with payload\nup to $8~kg$ and time-varying ground friction coefficients in flat terrain."}
{"id": "2510.15708", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15708", "abs": "https://arxiv.org/abs/2510.15708", "authors": ["Thomas Bernard", "François Grondin", "Jean-Michel Lavoie"], "title": "Sugar Shack 4.0: Practical Demonstration of an IIoT-Based Event-Driven Automation System", "comment": "10 pages, 15 figures", "summary": "This paper presents a practical alternative to\nprogrammable-logic-controller-centric automation by implementing an\nevent-driven architecture built with industrial Internet of Things tools. A\nlayered design on a local edge server (i) abstracts actuators, (ii) enforces\nmutual exclusion of shared physical resources through an interlock with\npriority queueing, (iii) composes deterministic singular operations, and (iv)\norchestrates complete workflows as state machines in Node-RED, with\ncommunication over MQTT. The device layer uses low-cost ESP32-based gateways to\ninterface sensors and actuators, while all automation logic is offloaded to the\nserver side. As part of a larger project involving the first\nscientifically-documented integration of Industry 4.0 technologies in a maple\nsyrup boiling center, this work demonstrates the deployment of the proposed\nsystem as a case-study. Evaluation over an entire production season shows\nmedian message time of flight around one tenth of a second, command\nissuance-to-motion latencies of about two to three seconds, and command\ncompletion near six seconds dominated by actuator mechanics; operation runtimes\nspan tens of seconds to minutes. These results indicate that network and\norchestration overheads are negligible relative to process dynamics, enabling\nmodular, distributed control without compromising determinism or fault\nisolation. The approach reduces material and integration effort, supports\nportable containerized deployment, and naturally enables an edge/cloud split in\nwhich persistence and analytics are offloaded while automation remains at the\nedge."}
{"id": "2510.15708", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15708", "abs": "https://arxiv.org/abs/2510.15708", "authors": ["Thomas Bernard", "François Grondin", "Jean-Michel Lavoie"], "title": "Sugar Shack 4.0: Practical Demonstration of an IIoT-Based Event-Driven Automation System", "comment": "10 pages, 15 figures", "summary": "This paper presents a practical alternative to\nprogrammable-logic-controller-centric automation by implementing an\nevent-driven architecture built with industrial Internet of Things tools. A\nlayered design on a local edge server (i) abstracts actuators, (ii) enforces\nmutual exclusion of shared physical resources through an interlock with\npriority queueing, (iii) composes deterministic singular operations, and (iv)\norchestrates complete workflows as state machines in Node-RED, with\ncommunication over MQTT. The device layer uses low-cost ESP32-based gateways to\ninterface sensors and actuators, while all automation logic is offloaded to the\nserver side. As part of a larger project involving the first\nscientifically-documented integration of Industry 4.0 technologies in a maple\nsyrup boiling center, this work demonstrates the deployment of the proposed\nsystem as a case-study. Evaluation over an entire production season shows\nmedian message time of flight around one tenth of a second, command\nissuance-to-motion latencies of about two to three seconds, and command\ncompletion near six seconds dominated by actuator mechanics; operation runtimes\nspan tens of seconds to minutes. These results indicate that network and\norchestration overheads are negligible relative to process dynamics, enabling\nmodular, distributed control without compromising determinism or fault\nisolation. The approach reduces material and integration effort, supports\nportable containerized deployment, and naturally enables an edge/cloud split in\nwhich persistence and analytics are offloaded while automation remains at the\nedge."}
{"id": "2510.15514", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15514", "abs": "https://arxiv.org/abs/2510.15514", "authors": ["Boyin Liu", "Zhuo Zhang", "Sen Huang", "Lipeng Xie", "Qingxu Fu", "Haoran Chen", "LI YU", "Tianyi Hu", "Zhaoyang Liu", "Bolin Ding", "Dongbin Zhao"], "title": "Taming the Judge: Deconflicting AI Feedback for Stable Reinforcement Learning", "comment": null, "summary": "However, this method often faces judgment inconsistencies that can\ndestabilize reinforcement learning. While prior research has focused on the\naccuracy of judgments, the critical issue of logical coherence especially\nissues such as preference cycles hasn't been fully addressed. To fill this gap,\nwe introduce a comprehensive framework designed to systematically detect and\nresolve these inconsistencies during the reinforcement learning training\nprocess. Our framework includes two main contributions: first, the Conflict\nDetection Rate (CDR), a new metric that quantifies judgment conflicts, and\nsecond, Deconflicted Graph Rewards (DGR), a framework that purifies signals by\nremoving cycles before policy optimization. DGR constructs preference graphs\nfrom the initial judgments, transforms them into conflict-free Directed Acyclic\nGraphs (DAGs), and generates a logically coherent reward signal that is\ncompatible with any policy optimizer. Experimental results show that our\nframework significantly enhances training stability and model performance\ncompared to strong baselines, establishing logical consistency as a crucial and\nnow manageable dimension of AI feedback."}
{"id": "2510.15229", "categories": ["cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.15229", "abs": "https://arxiv.org/abs/2510.15229", "authors": ["Sina Kazemdehbashi", "Yanchao Liu", "Boris S. Mordukhovich"], "title": "A Generalized Sylvester-Fermat-Torricelli problem with application in disaster relief operations by UAVs", "comment": null, "summary": "Natural and human-made disasters can cause severe devastation and claim\nthousands of lives worldwide. Therefore, developing efficient methods for\ndisaster response and management is a critical task for relief teams. One of\nthe most essential components of effective response is the rapid collection of\ninformation about affected areas, damages, and victims. More data translates\ninto better coordination, faster rescue operations, and ultimately, more lives\nsaved. However, in some disasters, such as earthquakes, the communication\ninfrastructure is often partially or completely destroyed, making it extremely\ndifficult for victims to send distress signals and for rescue teams to locate\nand assist them in time. Unmanned Aerial Vehicles (UAVs) have emerged as\nvaluable tools in such scenarios. In particular, a fleet of UAVs can be\ndispatched from a mobile station to the affected area to facilitate data\ncollection and establish temporary communication networks. Nevertheless,\nreal-world deployment of UAVs faces several challenges, with adverse weather\nconditions--especially wind--being among the most significant. To address this,\nwe develop a novel mathematical framework to determine the optimal location of\na mobile UAV station while explicitly accounting for the heterogeneity of the\nUAVs and the effect of wind. In particular, we generalize the Sylvester problem\nto introduce the Sylvester-Fermat-Torricelli (SFT) problem, which captures\ncomplex factors such as wind influence, UAV heterogeneity, and back-and-forth\nmotion within a unified framework. The proposed framework enhances the\npracticality of UAV-based disaster response planning by accounting for\nreal-world factors such as wind and UAV heterogeneity. Experimental results\ndemonstrate that it can reduce wasted operational time by up to 84%, making\npost-disaster missions significantly more efficient and effective."}
{"id": "2510.15638", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15638", "abs": "https://arxiv.org/abs/2510.15638", "authors": ["Jared K. Lepora", "Haoran Li", "Efi Psomopoulou", "Nathan F. Lepora"], "title": "Educational SoftHand-A: Building an Anthropomorphic Hand with Soft Synergies using LEGO MINDSTORMS", "comment": "6 pages. Accepted at IROS 2025", "summary": "This paper introduces an anthropomorphic robot hand built entirely using LEGO\nMINDSTORMS: the Educational SoftHand-A, a tendon-driven, highly-underactuated\nrobot hand based on the Pisa/IIT SoftHand and related hands. To be suitable for\nan educational context, the design is constrained to use only standard LEGO\npieces with tests using common equipment available at home. The hand features\ndual motors driving an agonist/antagonist opposing pair of tendons on each\nfinger, which are shown to result in reactive fine control. The finger motions\nare synchonized through soft synergies, implemented with a differential\nmechanism using clutch gears. Altogether, this design results in an\nanthropomorphic hand that can adaptively grasp a broad range of objects using a\nsimple actuation and control mechanism. Since the hand can be constructed from\nLEGO pieces and uses state-of-the-art design concepts for robotic hands, it has\nthe potential to educate and inspire children to learn about the frontiers of\nmodern robotics."}
{"id": "2510.15740", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15740", "abs": "https://arxiv.org/abs/2510.15740", "authors": ["Geon Roh", "Jip Kim"], "title": "Integrating Conductor Health into Dynamic Line Rating and Unit Commitment under Uncertainty", "comment": null, "summary": "Dynamic line rating (DLR) enables greater utilization of existing\ntransmission lines by leveraging real-time weather data. However, the elevated\ntemperature operation (ETO) of conductors under DLR is often overlooked,\ndespite its long-term impact on conductor health. This paper addresses this\nissue by 1) quantifying depreciation costs associated with ETO and 2) proposing\na Conductor Health-Aware Unit Commitment (CHA-UC) that internalizes these costs\nin operational decisions. The CHA-UC incorporates a robust linear approximation\nof conductor temperature and integration of expected depreciation costs due to\nhourly ETO into the objective function. Case studies on the Texas 123-bus\nbackbone test system using NOAA weather data demonstrate that the proposed\nCHA-UC model reduces the total cost by 0.8% and renewable curtailment by\n84%compared to static line rating (SLR), while conventional DLR operation\nwithout risk consideration resulted in higher costs due to excessive ETO.\nFurther analysis of the commitment decisions and the line temperature\nstatistics confirms that the CHA-UC achieves safer line flows by shifting\ngenerator commitments. Finally, we examine the emergent correlation between\nwind generation and DLR forecast errors, and show that CHA-UC adaptively\nmanages this effect by relaxing flows for risk-hedging conditions while\ntightening flows for risk-amplifying ones."}
{"id": "2510.15740", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15740", "abs": "https://arxiv.org/abs/2510.15740", "authors": ["Geon Roh", "Jip Kim"], "title": "Integrating Conductor Health into Dynamic Line Rating and Unit Commitment under Uncertainty", "comment": null, "summary": "Dynamic line rating (DLR) enables greater utilization of existing\ntransmission lines by leveraging real-time weather data. However, the elevated\ntemperature operation (ETO) of conductors under DLR is often overlooked,\ndespite its long-term impact on conductor health. This paper addresses this\nissue by 1) quantifying depreciation costs associated with ETO and 2) proposing\na Conductor Health-Aware Unit Commitment (CHA-UC) that internalizes these costs\nin operational decisions. The CHA-UC incorporates a robust linear approximation\nof conductor temperature and integration of expected depreciation costs due to\nhourly ETO into the objective function. Case studies on the Texas 123-bus\nbackbone test system using NOAA weather data demonstrate that the proposed\nCHA-UC model reduces the total cost by 0.8% and renewable curtailment by\n84%compared to static line rating (SLR), while conventional DLR operation\nwithout risk consideration resulted in higher costs due to excessive ETO.\nFurther analysis of the commitment decisions and the line temperature\nstatistics confirms that the CHA-UC achieves safer line flows by shifting\ngenerator commitments. Finally, we examine the emergent correlation between\nwind generation and DLR forecast errors, and show that CHA-UC adaptively\nmanages this effect by relaxing flows for risk-hedging conditions while\ntightening flows for risk-amplifying ones."}
{"id": "2510.15547", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.SY", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15547", "abs": "https://arxiv.org/abs/2510.15547", "authors": ["Usman Ali", "Ali Zia", "Waqas Ali", "Umer Ramzan", "Abdul Rehman", "Muhammad Tayyab Chaudhry", "Wei Xiang"], "title": "Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors", "comment": "Submitted to IEEE Sensors Journal", "summary": "Reliable induction motor (IM) fault diagnosis is vital for industrial safety\nand operational continuity, mitigating costly unplanned downtime. Conventional\napproaches often struggle to capture complex multimodal signal relationships,\nare constrained to unimodal data or single fault types, and exhibit performance\ndegradation under noisy or cross-domain conditions. This paper proposes the\nMultimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified\nframework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is\nthe first to integrate contrastive learning within a hypergraph topology\nspecifically designed for multimodal sensor fusion, enabling the joint\nmodelling of intra- and inter-modal dependencies and enhancing generalisation\nbeyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis\nof bearing, stator, and rotor faults, addressing the engineering need for\nconsolidated di- agnostic capabilities. Evaluated on three real-world\nbenchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain\ngeneralisation and resilience to noise, demonstrating its suitability for\nreal-world deployment. An ablation study validates the contribution of each\ncomponent. MM-HCAN provides a scalable and robust solution for comprehensive\nmulti-fault diagnosis, supporting predictive maintenance and extended asset\nlongevity in industrial environments."}
{"id": "2510.15236", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.15236", "abs": "https://arxiv.org/abs/2510.15236", "authors": ["Brett Reynolds"], "title": "From Checklists to Clusters: A Homeostatic Account of AGI Evaluation", "comment": "27 pages, 3 figures", "summary": "Contemporary AGI evaluations report multidomain capability profiles, yet they\ntypically assign symmetric weights and rely on snapshot scores. This creates\ntwo problems: (i) equal weighting treats all domains as equally important when\nhuman intelligence research suggests otherwise, and (ii) snapshot testing can't\ndistinguish durable capabilities from brittle performances that collapse under\ndelay or stress. I argue that general intelligence -- in humans and potentially\nin machines -- is better understood as a homeostatic property cluster: a set of\nabilities plus the mechanisms that keep those abilities co-present under\nperturbation. On this view, AGI evaluation should weight domains by their\ncausal centrality (their contribution to cluster stability) and require\nevidence of persistence across sessions. I propose two battery-compatible\nextensions: a centrality-prior score that imports CHC-derived weights with\ntransparent sensitivity analysis, and a Cluster Stability Index family that\nseparates profile persistence, durable learning, and error correction. These\nadditions preserve multidomain breadth while reducing brittleness and gaming. I\nclose with testable predictions and black-box protocols labs can adopt without\narchitectural access."}
{"id": "2510.15639", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15639", "abs": "https://arxiv.org/abs/2510.15639", "authors": ["Manuel J. Fernandez", "Alejandro Suarez", "Anibal Ollero", "Matteo Fumagalli"], "title": "Integration of a Variable Stiffness Link for Long-Reach Aerial Manipulation", "comment": null, "summary": "This paper presents the integration of a Variable Stiffness Link (VSL) for\nlong-reach aerial manipulation, enabling adaptable mechanical coupling between\nan aerial multirotor platform and a dual-arm manipulator. Conventional\nlong-reach manipulation systems rely on rigid or cable connections, which limit\nprecision or transmit disturbances to the aerial vehicle. The proposed VSL\nintroduces an adjustable stiffness mechanism that allows the link to behave\neither as a flexible rope or as a rigid rod, depending on task requirements.\n  The system is mounted on a quadrotor equipped with the LiCAS dual-arm\nmanipulator and evaluated through teleoperated experiments, involving external\ndisturbances and parcel transportation tasks. Results demonstrate that varying\nthe link stiffness significantly modifies the dynamic interaction between the\nUAV and the payload. The flexible configuration attenuates external impacts and\naerodynamic perturbations, while the rigid configuration improves positional\naccuracy during manipulation phases.\n  These results confirm that VSL enhances versatility and safety, providing a\ncontrollable trade-off between compliance and precision. Future work will focus\non autonomous stiffness regulation, multi-rope configurations, cooperative\naerial manipulation and user studies to further assess its impact on\nteleoperated and semi-autonomous aerial tasks."}
{"id": "2510.15797", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15797", "abs": "https://arxiv.org/abs/2510.15797", "authors": ["Laszlo Gacsi", "Adam K. Kiss", "Tamas G. Molnar"], "title": "Braking within Barriers: Constructive Safety-Critical Control for Input-Constrained Vehicles via the Backup Set Method", "comment": "Submitted to the IEEE Transactions on Automation Science and\n  Engineering. 14 pages, 10 figures", "summary": "This paper presents a safety-critical control framework to maintain bounded\nlateral motions for vehicles braking on asymmetric surfaces. We synthesize a\nbrake controller that assists drivers and guarantees safety against excessive\nlateral motions (i.e., prevents the vehicle from spinning out) while minimizing\nthe stopping distance. We address this safety-critical control problem in the\npresence of input constraints, since braking forces are limited by the\navailable friction on the road. We use backup control barrier functions for\nsafe control design. As this approach requires the construction of a backup set\nand a backup controller, we propose a novel, systematic method to creating\nvalid backup set-backup controller pairs based on feedback linearization and\ncontinuous-time Lyapunov equations. We use simple examples to demonstrate our\nproposed safety-critical control method. Finally, we implement our approach on\na four-wheel vehicle model for braking on asymmetric surfaces and present\nsimulation results."}
{"id": "2510.15797", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15797", "abs": "https://arxiv.org/abs/2510.15797", "authors": ["Laszlo Gacsi", "Adam K. Kiss", "Tamas G. Molnar"], "title": "Braking within Barriers: Constructive Safety-Critical Control for Input-Constrained Vehicles via the Backup Set Method", "comment": "Submitted to the IEEE Transactions on Automation Science and\n  Engineering. 14 pages, 10 figures", "summary": "This paper presents a safety-critical control framework to maintain bounded\nlateral motions for vehicles braking on asymmetric surfaces. We synthesize a\nbrake controller that assists drivers and guarantees safety against excessive\nlateral motions (i.e., prevents the vehicle from spinning out) while minimizing\nthe stopping distance. We address this safety-critical control problem in the\npresence of input constraints, since braking forces are limited by the\navailable friction on the road. We use backup control barrier functions for\nsafe control design. As this approach requires the construction of a backup set\nand a backup controller, we propose a novel, systematic method to creating\nvalid backup set-backup controller pairs based on feedback linearization and\ncontinuous-time Lyapunov equations. We use simple examples to demonstrate our\nproposed safety-critical control method. Finally, we implement our approach on\na four-wheel vehicle model for braking on asymmetric surfaces and present\nsimulation results."}
{"id": "2510.15560", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.15560", "abs": "https://arxiv.org/abs/2510.15560", "authors": ["Jiayuan Bai", "Xuan-guang Pan", "Chongyang Tao", "Shuai Ma"], "title": "JudgeSQL: Reasoning over SQL Candidates with Weighted Consensus Tournament", "comment": "13 pages", "summary": "Text-to-SQL is a pivotal task that bridges natural language understanding and\nstructured data access, yet it remains fundamentally challenging due to\nsemantic ambiguity and complex compositional reasoning. While large language\nmodels (LLMs) have greatly advanced SQL generation though prompting, supervised\nfinetuning and reinforced tuning, the shift toward test-time scaling exposes a\nnew bottleneck: selecting the correct query from a diverse candidate pool.\nExisting selection approaches, such as self-consistency or best-of-$N$\ndecoding, provide only shallow signals, making them prone to inconsistent\nscoring, fragile reasoning chains, and a failure to capture fine-grained\nsemantic distinctions between closely related SQL candidates. To this end, we\nintroduce JudgeSQL, a principled framework that redefines SQL candidate\nselection through structured reasoning and weighted consensus tournament\nmechanism. JudgeSQL develops a reasoning-based SQL judge model that distills\nreasoning traces with reinforcement learning guided by verifiable rewards,\nenabling accurate and interpretable judgments. Building on this, a weighted\nconsensus tournament integrates explicit reasoning preferences with implicit\ngenerator confidence, yielding selections that are both more reliable and more\nefficient. Extensive experiments on the BIRD benchmark demonstrate that\nJudgeSQL exhibits superior SQL judgment capabilities and good cross-scale\ngeneralization and robustness to generator capacity."}
{"id": "2510.15239", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15239", "abs": "https://arxiv.org/abs/2510.15239", "authors": ["Ziqing Zhu"], "title": "Quantum-Key-Distribution Authenticated Aggregation and Settlement for Virtual Power Plants", "comment": null, "summary": "The proliferation of distributed energy resources (DERs) and demand-side\nflexibility has made virtual power plants (VPPs) central to modern grid\noperation. Yet their end-to-end business pipeline, covering bidding, dispatch,\nmetering, settlement, and archival, forms a tightly coupled\ncyber-physical-economic system where secure and timely communication is\ncritical. Under the combined stress of sophisticated cyberattacks and extreme\nweather shocks, conventional cryptography offers limited long-term protection.\nQuantum key distribution (QKD), with information-theoretic guarantees, is\nviewed as a gold standard for securing critical infrastructures. However,\nlimited key generation rates, routing capacity, and system overhead render key\nallocation a pressing challenge: scarce quantum keys must be scheduled across\nheterogeneous processes to minimize residual risk while maintaining latency\nguarantees. This paper introduces a quantum-authenticated aggregation and\nsettlement framework for VPPs. We first develop a system-threat model that\nconnects QKD key generation and routing with business-layer security\nstrategies, authentication strength, refresh frequency, and delay constraints.\nBuilding on this, we formulate a key-budgeted risk minimization problem that\njointly accounts for economic risk, service-level violations, and key-budget\nfeasibility, and reveal a threshold property linking marginal security value to\nshadow prices. Case studies on a representative VPP system demonstrate that the\nproposed approach significantly reduces residual risk and SLA violations,\nenhances key efficiency and robustness, and aligns observed dynamics with the\ntheoretical shadow price mechanism."}
{"id": "2510.15668", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15668", "abs": "https://arxiv.org/abs/2510.15668", "authors": ["Yameng Zhang", "Dianye Huang", "Max Q. -H. Meng", "Nassir Navab", "Zhongliang Jiang"], "title": "Freehand 3D Ultrasound Imaging: Sim-in-the-Loop Probe Pose Optimization via Visual Servoing", "comment": null, "summary": "Freehand 3D ultrasound (US) imaging using conventional 2D probes offers\nflexibility and accessibility for diverse clinical applications but faces\nchallenges in accurate probe pose estimation. Traditional methods depend on\ncostly tracking systems, while neural network-based methods struggle with image\nnoise and error accumulation, compromising reconstruction precision. We propose\na cost-effective and versatile solution that leverages lightweight cameras and\nvisual servoing in simulated environments for precise 3D US imaging. These\ncameras capture visual feedback from a textured planar workspace. To counter\nocclusions and lighting issues, we introduce an image restoration method that\nreconstructs occluded regions by matching surrounding texture patterns. For\npose estimation, we develop a simulation-in-the-loop approach, which replicates\nthe system setup in simulation and iteratively minimizes pose errors between\nsimulated and real-world observations. A visual servoing controller refines the\nalignment of camera views, improving translational estimation by optimizing\nimage alignment. Validations on a soft vascular phantom, a 3D-printed conical\nmodel, and a human arm demonstrate the robustness and accuracy of our approach,\nwith Hausdorff distances to the reference reconstructions of 0.359 mm, 1.171\nmm, and 0.858 mm, respectively. These results confirm the method's potential\nfor reliable freehand 3D US reconstruction."}
{"id": "2510.15847", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15847", "abs": "https://arxiv.org/abs/2510.15847", "authors": ["Panos C. Papageorgiou", "Anastasios E. Giannopoulos", "Sotirios T. Spantideas"], "title": "Bio-inspired Microgrid Management based on Brain's Sensorimotor Gating", "comment": null, "summary": "Microgrids are emerging as key enablers of resilient, sustainable, and\nintelligent power systems, but they continue to face challenges in dynamic\ndisturbance handling, protection coordination, and uncertainty. Recent efforts\nhave explored Brain Emotional Learning (BEL) controllers as bio-inspired\nsolutions for microgrid control. Building on this growing trajectory, this\narticle introduces a new paradigm for Neuro-Microgrids, inspired by the brain's\nsensorimotor gating mechanisms, specifically the Prepulse Inhibition (PPI) and\nPrepulse Facilitation (PPF). Sensorimotor gating offers a biological model for\nselectively suppressing or amplifying responses depending on contextual\nrelevance. By mapping these principles onto the hierarchical control\narchitecture of microgrids, we propose a Sensorimotor Gating-Inspired\nNeuro-Microgrid (SG-NMG) framework. In this architecture, PPI-like control\ndecisions correspond to protective damping in primary and secondary management\nof microgrids, whereas PPF-like decisions correspond to adaptive amplification\nof corrective control actions. The framework is presented through analytical\nworkflow design, neuro-circuitry analogies, and integration with machine\nlearning methods. Finally, open challenges and research directions are\noutlined, including the mathematical modeling of gating, digital twin\nvalidation, and cross-disciplinary collaboration between neuroscience and\nindustrial power systems. The resulting paradigm highlights sensorimotor gating\nas a promising framework for designing self-protective, adaptive, and resilient\nmicrogrids."}
{"id": "2510.15847", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15847", "abs": "https://arxiv.org/abs/2510.15847", "authors": ["Panos C. Papageorgiou", "Anastasios E. Giannopoulos", "Sotirios T. Spantideas"], "title": "Bio-inspired Microgrid Management based on Brain's Sensorimotor Gating", "comment": null, "summary": "Microgrids are emerging as key enablers of resilient, sustainable, and\nintelligent power systems, but they continue to face challenges in dynamic\ndisturbance handling, protection coordination, and uncertainty. Recent efforts\nhave explored Brain Emotional Learning (BEL) controllers as bio-inspired\nsolutions for microgrid control. Building on this growing trajectory, this\narticle introduces a new paradigm for Neuro-Microgrids, inspired by the brain's\nsensorimotor gating mechanisms, specifically the Prepulse Inhibition (PPI) and\nPrepulse Facilitation (PPF). Sensorimotor gating offers a biological model for\nselectively suppressing or amplifying responses depending on contextual\nrelevance. By mapping these principles onto the hierarchical control\narchitecture of microgrids, we propose a Sensorimotor Gating-Inspired\nNeuro-Microgrid (SG-NMG) framework. In this architecture, PPI-like control\ndecisions correspond to protective damping in primary and secondary management\nof microgrids, whereas PPF-like decisions correspond to adaptive amplification\nof corrective control actions. The framework is presented through analytical\nworkflow design, neuro-circuitry analogies, and integration with machine\nlearning methods. Finally, open challenges and research directions are\noutlined, including the mathematical modeling of gating, digital twin\nvalidation, and cross-disciplinary collaboration between neuroscience and\nindustrial power systems. The resulting paradigm highlights sensorimotor gating\nas a promising framework for designing self-protective, adaptive, and resilient\nmicrogrids."}
{"id": "2510.15591", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.15591", "abs": "https://arxiv.org/abs/2510.15591", "authors": ["Lavanya Umapathy", "Patricia M Johnson", "Tarun Dutt", "Angela Tong", "Madhur Nayan", "Hersh Chandarana", "Daniel K Sodickson"], "title": "Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment", "comment": "18 pages, 5 figures, 1 table", "summary": "Temporal context in medicine is valuable in assessing key changes in patient\nhealth over time. We developed a machine learning framework to integrate\ndiverse context from prior visits to improve health monitoring, especially when\nprior visits are limited and their frequency is variable. Our model first\nestimates initial risk of disease using medical data from the most recent\npatient visit, then refines this assessment using information digested from\npreviously collected imaging and/or clinical biomarkers. We applied our\nframework to prostate cancer (PCa) risk prediction using data from a large\npopulation (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931\nblood tests) collected over nearly a decade. For predictions of the risk of\nclinically significant PCa at the time of the visit, integrating prior context\ndirectly converted false positives to true negatives, increasing overall\nspecificity while preserving high sensitivity. False positive rates were\nreduced progressively from 51% to 33% when integrating information from up to\nthree prior imaging examinations, as compared to using data from a single\nvisit, and were further reduced to 24% when also including additional context\nfrom prior clinical data. For predicting the risk of PCa within five years of\nthe visit, incorporating prior context reduced false positive rates still\nfurther (64% to 9%). Our findings show that information collected over time\nprovides relevant context to enhance the specificity of medical risk\nprediction. For a wide range of progressive conditions, sufficient reduction of\nfalse positive rates using context could offer a pathway to expand longitudinal\nhealth monitoring programs to large populations with comparatively low baseline\nrisk of disease, leading to earlier detection and improved health outcomes."}
{"id": "2510.15248", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15248", "abs": "https://arxiv.org/abs/2510.15248", "authors": ["Ziqing Zhu"], "title": "Techno-Economic Feasibility Analysis of Quantum Key Distribution for Power-System Communications", "comment": null, "summary": "The accelerating digitalization and decentralization of modern power systems\nexpose critical communication infrastructures to escalating cyber risks,\nparticularly under emerging quantum computing threats. This paper presents an\nintegrated techno-economic framework to evaluate the feasibility of Quantum Key\nDistribution (QKD) for secure power-system communications. A stochastic system\nmodel is developed to jointly capture time-varying key demand, QKD supply under\noptical-loss constraints, station-side buffering, and post-quantum cryptography\n(PQC) fallback mechanisms. Analytical conditions are derived for service-level\nassurance, including buffer stability, outage probability, and availability\nbounds. Building on this, two quantitative metrics, including the Levelized\nCost of Security (LCoSec) and Cost of Incremental Security (CIS), are\nformulated to unify capital, operational, and risk-related expenditures within\na discounted net-present-value framework. Using IEEE 118-bus, 123-node, and\n39-bus test systems, we conduct discrete-event simulations comparing PQC-only,\nQKD-only, and Hybrid architectures across multiple topologies and service\nprofiles. Results show that Hybrid architectures dominated by QKD significantly\nreduce key-outage probability and SLA shortfalls, achieving near-unit\navailability for real-time and confidentiality-critical services. Economic\nanalyses reveal clear breakeven zones where QKD-enhanced deployments become\ncost-effective, primarily in metropolitan and distribution-level networks under\nmoderate optical loss and buffer sizing. The proposed framework provides a\nreproducible, risk-aware decision tool for guiding large-scale, economically\njustified QKD adoption in future resilient power-system infrastructures."}
{"id": "2510.15679", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15679", "abs": "https://arxiv.org/abs/2510.15679", "authors": ["Yuhong Cao", "Yizhuo Wang", "Jingsong Liang", "Shuhao Liao", "Yifeng Zhang", "Peizhuo Li", "Guillaume Sartoretti"], "title": "HEADER: Hierarchical Robot Exploration via Attention-Based Deep Reinforcement Learning with Expert-Guided Reward", "comment": null, "summary": "This work pushes the boundaries of learning-based methods in autonomous robot\nexploration in terms of environmental scale and exploration efficiency. We\npresent HEADER, an attention-based reinforcement learning approach with\nhierarchical graphs for efficient exploration in large-scale environments.\nHEADER follows existing conventional methods to construct hierarchical\nrepresentations for the robot belief/map, but further designs a novel\ncommunity-based algorithm to construct and update a global graph, which remains\nfully incremental, shape-adaptive, and operates with linear complexity.\nBuilding upon attention-based networks, our planner finely reasons about the\nnearby belief within the local range while coarsely leveraging distant\ninformation at the global scale, enabling next-best-viewpoint decisions that\nconsider multi-scale spatial dependencies. Beyond novel map representation, we\nintroduce a parameter-free privileged reward that significantly improves model\nperformance and produces near-optimal exploration behaviors, by avoiding\ntraining objective bias caused by handcrafted reward shaping. In simulated\nchallenging, large-scale exploration scenarios, HEADER demonstrates better\nscalability than most existing learning and non-learning methods, while\nachieving a significant improvement in exploration efficiency (up to 20%) over\nstate-of-the-art baselines. We also deploy HEADER on hardware and validate it\nin complex, large-scale real-life scenarios, including a 300m*230m campus\nenvironment."}
{"id": "2510.15336", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15336", "abs": "https://arxiv.org/abs/2510.15336", "authors": ["Liviu-Mihai Stan", "Ranulfo Bezerra", "Shotaro Kojima", "Tsige Tadesse Alemayoh", "Satoshi Tadokoro", "Masashi Konyo", "Kazunori Ohno"], "title": "Adaptive Cost-Map-based Path Planning in Partially Unknown Environments with Movable Obstacles", "comment": null, "summary": "Reliable navigation in disaster-response and other unstructured indoor\nsettings requires robots not only to avoid obstacles but also to recognise when\nthose obstacles can be pushed aside. We present an adaptive, LiDAR and\nodometry-based path-planning framework that embeds this capability into the\nROS2 Nav2 stack. A new Movable Obstacles Layer labels all LiDAR returns missing\nfrom a prior static map as tentatively movable and assigns a reduced traversal\ncost. A companion Slow-Pose Progress Checker monitors the ratio of commanded to\nactual velocity; when the robot slows appreciably, the local cost is raised\nfrom light to heavy, and on a stall to lethal, prompting the global planner to\nback out and re-route. Gazebo evaluations on a Scout Mini, spanning isolated\nobjects and cluttered corridors, show higher goal-reach rates and fewer\ndeadlocks than a no-layer baseline, with traversal times broadly comparable.\nBecause the method relies only on planar scans and CPU-level computation, it\nsuits resource-constrained search and rescue robots and integrates into\nheterogeneous platforms with minimal engineering. Overall, the results indicate\nthat interaction-aware cost maps are a lightweight, ROS2-native extension for\nnavigating among potentially movable obstacles in unstructured settings. The\nfull implementation will be released as open source\nathttps://costmap-namo.github.io."}
{"id": "2510.15336", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15336", "abs": "https://arxiv.org/abs/2510.15336", "authors": ["Liviu-Mihai Stan", "Ranulfo Bezerra", "Shotaro Kojima", "Tsige Tadesse Alemayoh", "Satoshi Tadokoro", "Masashi Konyo", "Kazunori Ohno"], "title": "Adaptive Cost-Map-based Path Planning in Partially Unknown Environments with Movable Obstacles", "comment": null, "summary": "Reliable navigation in disaster-response and other unstructured indoor\nsettings requires robots not only to avoid obstacles but also to recognise when\nthose obstacles can be pushed aside. We present an adaptive, LiDAR and\nodometry-based path-planning framework that embeds this capability into the\nROS2 Nav2 stack. A new Movable Obstacles Layer labels all LiDAR returns missing\nfrom a prior static map as tentatively movable and assigns a reduced traversal\ncost. A companion Slow-Pose Progress Checker monitors the ratio of commanded to\nactual velocity; when the robot slows appreciably, the local cost is raised\nfrom light to heavy, and on a stall to lethal, prompting the global planner to\nback out and re-route. Gazebo evaluations on a Scout Mini, spanning isolated\nobjects and cluttered corridors, show higher goal-reach rates and fewer\ndeadlocks than a no-layer baseline, with traversal times broadly comparable.\nBecause the method relies only on planar scans and CPU-level computation, it\nsuits resource-constrained search and rescue robots and integrates into\nheterogeneous platforms with minimal engineering. Overall, the results indicate\nthat interaction-aware cost maps are a lightweight, ROS2-native extension for\nnavigating among potentially movable obstacles in unstructured settings. The\nfull implementation will be released as open source\nathttps://costmap-namo.github.io."}
{"id": "2510.15600", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.15600", "abs": "https://arxiv.org/abs/2510.15600", "authors": ["Haoran Sun", "Yankai Jiang", "Zhenyu Tang", "Yaning Pan", "Shuang Gu", "Zekai Lin", "Lilong Wang", "Wenjie Lou", "Lei Liu", "Lei Bai", "Xiaosong Wang"], "title": "Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism", "comment": null, "summary": "The foundation of reproducible science lies in protocols that are precise,\nlogically ordered, and executable. The autonomous generation of these protocols\nthrough natural language queries could greatly improve the efficiency of the\nreproduction process. However, current leading large language models (LLMs)\noften generate incomplete or inconsistent protocols, limiting their utility. To\naddress this limitation, we first introduce SciRecipe, a large-scale dataset of\nover 12K structured protocols spanning 27 biological subfields and encompassing\nboth comprehension and problem-solving tasks. To further improve protocol\ngeneration, we propose the \"Sketch-and-Fill\" paradigm, which separates\nanalysis, structuring, and expression to ensure each step is explicit and\nverifiable. Complementing this, the structured component-based reward mechanism\nevaluates step granularity, action order, and semantic fidelity, aligning model\noptimization with experimental reliability. Building on these components, we\ndevelop Thoth, trained through a staged Knowledge-to-Action process that\nprogresses from knowledge acquisition to operational reasoning and ultimately\nto robust, executable protocol generation. Across multiple benchmarks, Thoth\nconsistently surpasses both proprietary and open-source LLMs, achieving\nsignificant improvements in step alignment, logical sequencing, and semantic\naccuracy. Our approach paves the way for reliable scientific assistants that\nbridge knowledge with experimental execution. All data, code, and models will\nbe released publicly."}
{"id": "2510.15250", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15250", "abs": "https://arxiv.org/abs/2510.15250", "authors": ["Mostafaali Ayubirad", "Zeng Qiu", "Hao Wang", "Chris Weinkauf", "Michiel Van Nieuwstadt", "Hamid R. Ossareh"], "title": "Comprehensive Dynamic Modeling and Constraint-Aware Air Supply Control for Localized Water Management in Automotive Polymer Electrolyte Membrane Fuel Cells", "comment": "This is a manuscript submitted to Applied Energy", "summary": "In this paper, a predictive constraint-aware control scheme is formulated\nwithin the Command Governor (CG) framework for localized hydration management\nof a proton exchange membrane (PEM) fuel cell system. First, a comprehensive\nnonlinear dynamic model of the fuel cell system is presented which includes a\npseudo 2-dimensional (P2D) model of the stack, reactant supply and cooling\nsubsystems. The model captures the couplings among the various subsystems and\nserves as the basis for designing output feedback controllers to track the\noptimal set-points of the air supply and cooling systems for power\noptimization. The closed-loop nonlinear model is then used to analyze the\ndynamic behavior of membrane hydration near the anode inlet, the driest region\nof the membrane in a counter-flow configuration, under various operating\nconditions. A reduced-order linearized model is then derived to approximate\nhydration behavior with sufficient fidelity for constraint enforcement. This\nmodel is used within the CG framework to adjust the air supply set-points when\nnecessary to prevent membrane dry-out. The effectiveness of the proposed\napproach in maintaining local membrane hydration while closely tracking the\nrequested net power is demonstrated through realistic drive-cycle simulations."}
{"id": "2510.15686", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15686", "abs": "https://arxiv.org/abs/2510.15686", "authors": ["Taehyeon Kim", "Vishnunandan L. N. Venkatesh", "Byung-Cheol Min"], "title": "Few-Shot Demonstration-Driven Task Coordination and Trajectory Execution for Multi-Robot Systems", "comment": null, "summary": "In this paper, we propose a novel few-shot learning framework for multi-robot\nsystems that integrate both spatial and temporal elements: Few-Shot\nDemonstration-Driven Task Coordination and Trajectory Execution (DDACE). Our\napproach leverages temporal graph networks for learning task-agnostic temporal\nsequencing and Gaussian Processes for spatial trajectory modeling, ensuring\nmodularity and generalization across various tasks. By decoupling temporal and\nspatial aspects, DDACE requires only a small number of demonstrations,\nsignificantly reducing data requirements compared to traditional learning from\ndemonstration approaches. To validate our proposed framework, we conducted\nextensive experiments in task environments designed to assess various aspects\nof multi-robot coordination-such as multi-sequence execution, multi-action\ndynamics, complex trajectory generation, and heterogeneous configurations. The\nexperimental results demonstrate that our approach successfully achieves task\nexecution under few-shot learning conditions and generalizes effectively across\ndynamic and diverse settings. This work underscores the potential of modular\narchitectures in enhancing the practicality and scalability of multi-robot\nsystems in real-world applications. Additional materials are available at\nhttps://sites.google.com/view/ddace."}
{"id": "2510.15547", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.SY", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15547", "abs": "https://arxiv.org/abs/2510.15547", "authors": ["Usman Ali", "Ali Zia", "Waqas Ali", "Umer Ramzan", "Abdul Rehman", "Muhammad Tayyab Chaudhry", "Wei Xiang"], "title": "Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors", "comment": "Submitted to IEEE Sensors Journal", "summary": "Reliable induction motor (IM) fault diagnosis is vital for industrial safety\nand operational continuity, mitigating costly unplanned downtime. Conventional\napproaches often struggle to capture complex multimodal signal relationships,\nare constrained to unimodal data or single fault types, and exhibit performance\ndegradation under noisy or cross-domain conditions. This paper proposes the\nMultimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified\nframework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is\nthe first to integrate contrastive learning within a hypergraph topology\nspecifically designed for multimodal sensor fusion, enabling the joint\nmodelling of intra- and inter-modal dependencies and enhancing generalisation\nbeyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis\nof bearing, stator, and rotor faults, addressing the engineering need for\nconsolidated di- agnostic capabilities. Evaluated on three real-world\nbenchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain\ngeneralisation and resilience to noise, demonstrating its suitability for\nreal-world deployment. An ablation study validates the contribution of each\ncomponent. MM-HCAN provides a scalable and robust solution for comprehensive\nmulti-fault diagnosis, supporting predictive maintenance and extended asset\nlongevity in industrial environments."}
{"id": "2510.15547", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.SY", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15547", "abs": "https://arxiv.org/abs/2510.15547", "authors": ["Usman Ali", "Ali Zia", "Waqas Ali", "Umer Ramzan", "Abdul Rehman", "Muhammad Tayyab Chaudhry", "Wei Xiang"], "title": "Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors", "comment": "Submitted to IEEE Sensors Journal", "summary": "Reliable induction motor (IM) fault diagnosis is vital for industrial safety\nand operational continuity, mitigating costly unplanned downtime. Conventional\napproaches often struggle to capture complex multimodal signal relationships,\nare constrained to unimodal data or single fault types, and exhibit performance\ndegradation under noisy or cross-domain conditions. This paper proposes the\nMultimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified\nframework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is\nthe first to integrate contrastive learning within a hypergraph topology\nspecifically designed for multimodal sensor fusion, enabling the joint\nmodelling of intra- and inter-modal dependencies and enhancing generalisation\nbeyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis\nof bearing, stator, and rotor faults, addressing the engineering need for\nconsolidated di- agnostic capabilities. Evaluated on three real-world\nbenchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain\ngeneralisation and resilience to noise, demonstrating its suitability for\nreal-world deployment. An ablation study validates the contribution of each\ncomponent. MM-HCAN provides a scalable and robust solution for comprehensive\nmulti-fault diagnosis, supporting predictive maintenance and extended asset\nlongevity in industrial environments."}
{"id": "2510.15624", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.15624", "abs": "https://arxiv.org/abs/2510.15624", "authors": ["Ed Li", "Junyu Ren", "Xintian Pan", "Cat Yan", "Chuanhao Li", "Dirk Bergemann", "Zhuoran Yang"], "title": "Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation", "comment": "37 pages, 5 figures. Code: https://github.com/ltjed/freephdlabor", "summary": "The automation of scientific discovery represents a critical milestone in\nArtificial Intelligence (AI) research. However, existing agentic systems for\nscience suffer from two fundamental limitations: rigid, pre-programmed\nworkflows that cannot adapt to intermediate findings, and inadequate context\nmanagement that hinders long-horizon research. We present\n\\texttt{freephdlabor}, an open-source multiagent framework featuring\n\\textit{fully dynamic workflows} determined by real-time agent reasoning and a\n\\coloremph{\\textit{modular architecture}} enabling seamless customization --\nusers can modify, add, or remove agents to address domain-specific\nrequirements. The framework provides comprehensive infrastructure including\n\\textit{automatic context compaction}, \\textit{workspace-based communication}\nto prevent information degradation, \\textit{memory persistence} across\nsessions, and \\textit{non-blocking human intervention} mechanisms. These\nfeatures collectively transform automated research from isolated, single-run\nattempts into \\textit{continual research programs} that build systematically on\nprior explorations and incorporate human feedback. By providing both the\narchitectural principles and practical implementation for building customizable\nco-scientist systems, this work aims to facilitate broader adoption of\nautomated research across scientific domains, enabling practitioners to deploy\ninteractive multiagent systems that autonomously conduct end-to-end research --\nfrom ideation through experimentation to publication-ready manuscripts."}
{"id": "2510.15256", "categories": ["cs.CY", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.15256", "abs": "https://arxiv.org/abs/2510.15256", "authors": ["Ricardo Alonzo Fernández Salguero"], "title": "From Murals to Memes: A Theory of Aesthetic Asymmetry in Political Mobilization", "comment": null, "summary": "Why have left-wing movements historically integrated participatory art forms\n(such as murals and protest songs) into their praxis, while right-wing\nmovements have prioritized strategic communication and, more recently, the\ndigital culture of memes? This article introduces the concept of aesthetic\nasymmetry to explain this divergence in political action. We argue that the\nasymmetry is not coincidental but the result of four interconnected structural\nfactors: the organizational ecosystem, the moral and emotional framework, the\nmaterial supports, and the historical tradition of each political spectrum.\nWhile the left tends to use art in a constitutive manner to forge community,\nsolidarity, and hope, the contemporary right tends to use it instrumentally to\nmobilize polarizing affects such as humor and resentment. Drawing on\ncomparative literature from the Theatre of the Oppressed to analyses of\nalt-right meme wars, we nuance this distinction and show how the aesthetic\nlogic of each pole aligns with its strategic objectives. The article culminates\nin a prescriptive model for artistic action, synthesizing keys to effective\nmobilization into emotional, narrative, and formatting strategies.\nUnderstanding this asymmetry is crucial for analyzing political communication\nand for designing cultural interventions capable of generating profound social\nchange."}
{"id": "2510.15786", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15786", "abs": "https://arxiv.org/abs/2510.15786", "authors": ["Xinyue Xu", "Jieqiang Sun", "Jing", "Dai", "Siyuan Chen", "Lanjie Ma", "Ke Sun", "Bin Zhao", "Jianbo Yuan", "Yiwen Lu"], "title": "DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation", "comment": null, "summary": "We present DexCanvas, a large-scale hybrid real-synthetic human manipulation\ndataset containing 7,000 hours of dexterous hand-object interactions seeded\nfrom 70 hours of real human demonstrations, organized across 21 fundamental\nmanipulation types based on the Cutkosky taxonomy. Each entry combines\nsynchronized multi-view RGB-D, high-precision mocap with MANO hand parameters,\nand per-frame contact points with physically consistent force profiles. Our\nreal-to-sim pipeline uses reinforcement learning to train policies that control\nan actuated MANO hand in physics simulation, reproducing human demonstrations\nwhile discovering the underlying contact forces that generate the observed\nobject motion. DexCanvas is the first manipulation dataset to combine\nlarge-scale real demonstrations, systematic skill coverage based on established\ntaxonomies, and physics-validated contact annotations. The dataset can\nfacilitate research in robotic manipulation learning, contact-rich control, and\nskill transfer across different hand morphologies."}
{"id": "2510.15626", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15626", "abs": "https://arxiv.org/abs/2510.15626", "authors": ["Hongyu Zhou", "Xiaoyu Zhang", "Vasileios Tzoumas"], "title": "Adaptive Legged Locomotion via Online Learning for Model Predictive Control", "comment": "9 pages", "summary": "We provide an algorithm for adaptive legged locomotion via online learning\nand model predictive control. The algorithm is composed of two interacting\nmodules: model predictive control (MPC) and online learning of residual\ndynamics. The residual dynamics can represent modeling errors and external\ndisturbances. We are motivated by the future of autonomy where quadrupeds will\nautonomously perform complex tasks despite real-world unknown uncertainty, such\nas unknown payload and uneven terrains. The algorithm uses random Fourier\nfeatures to approximate the residual dynamics in reproducing kernel Hilbert\nspaces. Then, it employs MPC based on the current learned model of the residual\ndynamics. The model is updated online in a self-supervised manner using least\nsquares based on the data collected while controlling the quadruped. The\nalgorithm enjoys sublinear \\textit{dynamic regret}, defined as the\nsuboptimality against an optimal clairvoyant controller that knows how the\nresidual dynamics. We validate our algorithm in Gazebo and MuJoCo simulations,\nwhere the quadruped aims to track reference trajectories. The Gazebo\nsimulations include constant unknown external forces up to $12\\boldsymbol{g}$,\nwhere $\\boldsymbol{g}$ is the gravity vector, in flat terrain, slope terrain\nwith $20\\degree$ inclination, and rough terrain with $0.25m$ height variation.\nThe MuJoCo simulations include time-varying unknown disturbances with payload\nup to $8~kg$ and time-varying ground friction coefficients in flat terrain."}
{"id": "2510.15626", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15626", "abs": "https://arxiv.org/abs/2510.15626", "authors": ["Hongyu Zhou", "Xiaoyu Zhang", "Vasileios Tzoumas"], "title": "Adaptive Legged Locomotion via Online Learning for Model Predictive Control", "comment": "9 pages", "summary": "We provide an algorithm for adaptive legged locomotion via online learning\nand model predictive control. The algorithm is composed of two interacting\nmodules: model predictive control (MPC) and online learning of residual\ndynamics. The residual dynamics can represent modeling errors and external\ndisturbances. We are motivated by the future of autonomy where quadrupeds will\nautonomously perform complex tasks despite real-world unknown uncertainty, such\nas unknown payload and uneven terrains. The algorithm uses random Fourier\nfeatures to approximate the residual dynamics in reproducing kernel Hilbert\nspaces. Then, it employs MPC based on the current learned model of the residual\ndynamics. The model is updated online in a self-supervised manner using least\nsquares based on the data collected while controlling the quadruped. The\nalgorithm enjoys sublinear \\textit{dynamic regret}, defined as the\nsuboptimality against an optimal clairvoyant controller that knows how the\nresidual dynamics. We validate our algorithm in Gazebo and MuJoCo simulations,\nwhere the quadruped aims to track reference trajectories. The Gazebo\nsimulations include constant unknown external forces up to $12\\boldsymbol{g}$,\nwhere $\\boldsymbol{g}$ is the gravity vector, in flat terrain, slope terrain\nwith $20\\degree$ inclination, and rough terrain with $0.25m$ height variation.\nThe MuJoCo simulations include time-varying unknown disturbances with payload\nup to $8~kg$ and time-varying ground friction coefficients in flat terrain."}
{"id": "2510.15716", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15716", "abs": "https://arxiv.org/abs/2510.15716", "authors": ["Keertana Chidambaram", "Karthik Vinary Seetharaman", "Vasilis Syrgkanis"], "title": "Direct Preference Optimization with Unobserved Preference Heterogeneity: The Necessity of Ternary Preferences", "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) has become central to\naligning large language models with human values, typically by first learning a\nreward model from preference data which is then used to update the model with\nreinforcement learning. Recent alternatives such as Direct Preference\nOptimization (DPO) simplify this pipeline by directly optimizing on\npreferences. However, both approaches often assume uniform annotator\npreferences and rely on binary comparisons, overlooking two key limitations:\nthe diversity of human evaluators and the limitations of pairwise feedback. In\nthis work, we address both these issues. First, we connect preference learning\nin RLHF with the econometrics literature and show that binary comparisons are\ninsufficient for identifying latent user preferences from finite user data and\ninfinite users, while (even incomplete) rankings over three or more responses\nensure identifiability. Second, we introduce methods to incorporate\nheterogeneous preferences into alignment algorithms. We develop an\nExpectation-Maximization adaptation of DPO that discovers latent annotator\ntypes and trains a mixture of LLMs accordingly. Then we propose an aggregation\nalgorithm using a min-max regret fairness criterion to produce a single\ngenerative policy with equitable performance guarantees. Together, these\ncontributions establish a theoretical and algorithmic framework for fairness\nand personalization for diverse users in generative model alignment."}
{"id": "2510.15258", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.15258", "abs": "https://arxiv.org/abs/2510.15258", "authors": ["Xi Wang", "Xianyao Ling", "Kun Li", "Gang Yin", "Liang Zhang", "Jiang Wu", "Jun Xu", "Fu Zhang", "Wenbo Lei", "Annie Wang", "Peng Gong"], "title": "Multi-dimensional Data Analysis and Applications Basing on LLM Agents and Knowledge Graph Interactions", "comment": "14 pages, 7 figures, 40 references", "summary": "In the current era of big data, extracting deep insights from massive,\nheterogeneous, and complexly associated multi-dimensional data has become a\nsignificant challenge. Large Language Models (LLMs) perform well in natural\nlanguage understanding and generation, but still suffer from \"hallucination\"\nissues when processing structured knowledge and are difficult to update in\nreal-time. Although Knowledge Graphs (KGs) can explicitly store structured\nknowledge, their static nature limits dynamic interaction and analytical\ncapabilities. Therefore, this paper proposes a multi-dimensional data analysis\nmethod based on the interactions between LLM agents and KGs, constructing a\ndynamic, collaborative analytical ecosystem. This method utilizes LLM agents to\nautomatically extract product data from unstructured data, constructs and\nvisualizes the KG in real-time, and supports users in deep exploration and\nanalysis of graph nodes through an interactive platform. Experimental results\nshow that this method has significant advantages in product ecosystem analysis,\nrelationship mining, and user-driven exploratory analysis, providing new ideas\nand tools for multi-dimensional data analysis."}
{"id": "2510.15803", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15803", "abs": "https://arxiv.org/abs/2510.15803", "authors": ["Zahra Arjmandi", "Gunho Sohn"], "title": "Dynamic Recalibration in LiDAR SLAM: Integrating AI and Geometric Methods with Real-Time Feedback Using INAF Fusion", "comment": "9 pages, 9 figures", "summary": "This paper presents a novel fusion technique for LiDAR Simultaneous\nLocalization and Mapping (SLAM), aimed at improving localization and 3D mapping\nusing LiDAR sensor. Our approach centers on the Inferred Attention Fusion\n(INAF) module, which integrates AI with geometric odometry. Utilizing the KITTI\ndataset's LiDAR data, INAF dynamically adjusts attention weights based on\nenvironmental feedback, enhancing the system's adaptability and measurement\naccuracy. This method advances the precision of both localization and 3D\nmapping, demonstrating the potential of our fusion technique to enhance\nautonomous navigation systems in complex scenarios."}
{"id": "2510.15668", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15668", "abs": "https://arxiv.org/abs/2510.15668", "authors": ["Yameng Zhang", "Dianye Huang", "Max Q. -H. Meng", "Nassir Navab", "Zhongliang Jiang"], "title": "Freehand 3D Ultrasound Imaging: Sim-in-the-Loop Probe Pose Optimization via Visual Servoing", "comment": null, "summary": "Freehand 3D ultrasound (US) imaging using conventional 2D probes offers\nflexibility and accessibility for diverse clinical applications but faces\nchallenges in accurate probe pose estimation. Traditional methods depend on\ncostly tracking systems, while neural network-based methods struggle with image\nnoise and error accumulation, compromising reconstruction precision. We propose\na cost-effective and versatile solution that leverages lightweight cameras and\nvisual servoing in simulated environments for precise 3D US imaging. These\ncameras capture visual feedback from a textured planar workspace. To counter\nocclusions and lighting issues, we introduce an image restoration method that\nreconstructs occluded regions by matching surrounding texture patterns. For\npose estimation, we develop a simulation-in-the-loop approach, which replicates\nthe system setup in simulation and iteratively minimizes pose errors between\nsimulated and real-world observations. A visual servoing controller refines the\nalignment of camera views, improving translational estimation by optimizing\nimage alignment. Validations on a soft vascular phantom, a 3D-printed conical\nmodel, and a human arm demonstrate the robustness and accuracy of our approach,\nwith Hausdorff distances to the reference reconstructions of 0.359 mm, 1.171\nmm, and 0.858 mm, respectively. These results confirm the method's potential\nfor reliable freehand 3D US reconstruction."}
{"id": "2510.15668", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15668", "abs": "https://arxiv.org/abs/2510.15668", "authors": ["Yameng Zhang", "Dianye Huang", "Max Q. -H. Meng", "Nassir Navab", "Zhongliang Jiang"], "title": "Freehand 3D Ultrasound Imaging: Sim-in-the-Loop Probe Pose Optimization via Visual Servoing", "comment": null, "summary": "Freehand 3D ultrasound (US) imaging using conventional 2D probes offers\nflexibility and accessibility for diverse clinical applications but faces\nchallenges in accurate probe pose estimation. Traditional methods depend on\ncostly tracking systems, while neural network-based methods struggle with image\nnoise and error accumulation, compromising reconstruction precision. We propose\na cost-effective and versatile solution that leverages lightweight cameras and\nvisual servoing in simulated environments for precise 3D US imaging. These\ncameras capture visual feedback from a textured planar workspace. To counter\nocclusions and lighting issues, we introduce an image restoration method that\nreconstructs occluded regions by matching surrounding texture patterns. For\npose estimation, we develop a simulation-in-the-loop approach, which replicates\nthe system setup in simulation and iteratively minimizes pose errors between\nsimulated and real-world observations. A visual servoing controller refines the\nalignment of camera views, improving translational estimation by optimizing\nimage alignment. Validations on a soft vascular phantom, a 3D-printed conical\nmodel, and a human arm demonstrate the robustness and accuracy of our approach,\nwith Hausdorff distances to the reference reconstructions of 0.359 mm, 1.171\nmm, and 0.858 mm, respectively. These results confirm the method's potential\nfor reliable freehand 3D US reconstruction."}
{"id": "2510.15727", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.15727", "abs": "https://arxiv.org/abs/2510.15727", "authors": ["Sai Yashwant", "Anurag Dubey", "Praneeth Paikray", "Gantala Thulsiram"], "title": "Invoice Information Extraction: Methods and Performance Evaluation", "comment": null, "summary": "This paper presents methods for extracting structured information from\ninvoice documents and proposes a set of evaluation metrics (EM) to assess the\naccuracy of the extracted data against annotated ground truth. The approach\ninvolves pre-processing scanned or digital invoices, applying Docling and\nLlamaCloud Services to identify and extract key fields such as invoice number,\ndate, total amount, and vendor details. To ensure the reliability of the\nextraction process, we establish a robust evaluation framework comprising\nfield-level precision, consistency check failures, and exact match accuracy.\nThe proposed metrics provide a standardized way to compare different extraction\nmethods and highlight strengths and weaknesses in field-specific performance."}
{"id": "2510.15259", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15259", "abs": "https://arxiv.org/abs/2510.15259", "authors": ["Chenwei Tang", "Jingyu Xing", "Xinyu Liu", "Zizhou Wang", "Jiawei Du", "Liangli Zhen", "Jiancheng Lv"], "title": "Experience-Driven Exploration for Efficient API-Free AI Agents", "comment": null, "summary": "Most existing software lacks accessible Application Programming Interfaces\n(APIs), requiring agents to operate solely through pixel-based Graphical User\nInterfaces (GUIs). In this API-free setting, large language model (LLM)-based\nagents face severe efficiency bottlenecks: limited to local visual experiences,\nthey make myopic decisions and rely on inefficient trial-and-error, hindering\nboth skill acquisition and long-term planning. To address these challenges, we\npropose KG-Agent, an experience-driven learning framework that structures an\nagent's raw pixel-level interactions into a persistent State-Action Knowledge\nGraph (SA-KG). KG-Agent overcomes inefficient exploration by linking\nfunctionally similar but visually distinct GUI states, forming a rich\nneighborhood of experience that enables the agent to generalize from a diverse\nset of historical strategies. To support long-horizon reasoning, we design a\nhybrid intrinsic reward mechanism based on the graph topology, combining a\nstate value reward for exploiting known high-value pathways with a novelty\nreward that encourages targeted exploration. This approach decouples strategic\nplanning from pure discovery, allowing the agent to effectively value setup\nactions with delayed gratification. We evaluate KG-Agent in two complex,\nopen-ended GUI-based decision-making environments (Civilization V and Slay the\nSpire), demonstrating significant improvements in exploration efficiency and\nstrategic depth over the state-of-the-art methods."}
{"id": "2510.15739", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.15739", "abs": "https://arxiv.org/abs/2510.15739", "authors": ["Lorenzo Satta Chiris", "Ayush Mishra"], "title": "AURA: An Agent Autonomy Risk Assessment Framework", "comment": "10 pages, 2 figures. Submitted for open-access preprint on arXiv.\n  Based on the AAMAS 2026 paper template", "summary": "As autonomous agentic AI systems see increasing adoption across\norganisations, persistent challenges in alignment, governance, and risk\nmanagement threaten to impede deployment at scale. We present AURA (Agent\naUtonomy Risk Assessment), a unified framework designed to detect, quantify,\nand mitigate risks arising from agentic AI. Building on recent research and\npractical deployments, AURA introduces a gamma-based risk scoring methodology\nthat balances risk assessment accuracy with computational efficiency and\npractical considerations. AURA provides an interactive process to score,\nevaluate and mitigate the risks of running one or multiple AI Agents,\nsynchronously or asynchronously (autonomously). The framework is engineered for\nHuman-in-the-Loop (HITL) oversight and presents Agent-to-Human (A2H)\ncommunication mechanisms, allowing for seamless integration with agentic\nsystems for autonomous self-assessment, rendering it interoperable with\nestablished protocols (MCP and A2A) and tools. AURA supports a responsible and\ntransparent adoption of agentic AI and provides robust risk detection and\nmitigation while balancing computational resources, positioning it as a\ncritical enabler for large-scale, governable agentic AI in enterprise\nenvironments."}
{"id": "2510.15261", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15261", "abs": "https://arxiv.org/abs/2510.15261", "authors": ["Jitesh Jain", "Shubham Maheshwari", "Ning Yu", "Wen-mei Hwu", "Humphrey Shi"], "title": "AUGUSTUS: An LLM-Driven Multimodal Agent System with Contextualized User Memory", "comment": "LAW 2025 Workshop at NeurIPS 2025. Work done from late 2023 to early\n  2024", "summary": "Riding on the success of LLMs with retrieval-augmented generation (RAG),\nthere has been a growing interest in augmenting agent systems with external\nmemory databases. However, the existing systems focus on storing text\ninformation in their memory, ignoring the importance of multimodal signals.\nMotivated by the multimodal nature of human memory, we present AUGUSTUS, a\nmultimodal agent system aligned with the ideas of human memory in cognitive\nscience. Technically, our system consists of 4 stages connected in a loop: (i)\nencode: understanding the inputs; (ii) store in memory: saving important\ninformation; (iii) retrieve: searching for relevant context from memory; and\n(iv) act: perform the task. Unlike existing systems that use vector databases,\nwe propose conceptualizing information into semantic tags and associating the\ntags with their context to store them in a graph-structured multimodal\ncontextual memory for efficient concept-driven retrieval. Our system\noutperforms the traditional multimodal RAG approach while being 3.5 times\nfaster for ImageNet classification and outperforming MemGPT on the MSC\nbenchmark."}
{"id": "2510.15748", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15748", "abs": "https://arxiv.org/abs/2510.15748", "authors": ["Minlin Zeng", "Zhipeng Zhou", "Yang Qiu", "Zhiqi Shen"], "title": "Towards Relaxed Multimodal Inputs for Gait-based Parkinson's Disease Assessment", "comment": null, "summary": "Parkinson's disease assessment has garnered growing interest in recent years,\nparticularly with the advent of sensor data and machine learning techniques.\nAmong these, multimodal approaches have demonstrated strong performance by\neffectively integrating complementary information from various data sources.\nHowever, two major limitations hinder their practical application: (1) the need\nto synchronize all modalities during training, and (2) the dependence on all\nmodalities during inference. To address these issues, we propose the first\nParkinson's assessment system that formulates multimodal learning as a\nmulti-objective optimization (MOO) problem. This not only allows for more\nflexible modality requirements during both training and inference, but also\nhandles modality collapse issue during multimodal information fusion. In\naddition, to mitigate the imbalance within individual modalities, we introduce\na margin-based class rebalancing strategy to enhance category learning. We\nconduct extensive experiments on three public datasets under both synchronous\nand asynchronous settings. The results show that our framework-Towards Relaxed\nInPuts (TRIP)-achieves state-of-the-art performance, outperforming the best\nbaselines by 16.48, 6.89, and 11.55 percentage points in the asynchronous\nsetting, and by 4.86 and 2.30 percentage points in the synchronous setting,\nhighlighting its effectiveness and adaptability."}
{"id": "2510.15285", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15285", "abs": "https://arxiv.org/abs/2510.15285", "authors": ["Saeid Bayat", "Jerry Zuo", "Jing Sun"], "title": "Modeling and Dynamic Simulation of a Hybrid Wind-Wave System on a Hexagonal Semi-Submersible Platform", "comment": "28 pages, 17 figures", "summary": "Offshore renewable energy systems offer promising solutions for sustainable\npower generation, yet most existing platforms harvest either wind or wave\nenergy in isolation. This study presents a hybrid floating offshore platform\nthat integrates a wind turbine with three oscillating surge wave energy\nconverters (WECs) into a hexagonal semi-submersible structure. In this\nconfiguration, the flaps are integrated with the platform geometry to provide\nboth energy extraction and hydrodynamic stability. A modeling and simulation\nframework was developed using WEC-Sim and benchmarked against the NREL 5 MW\nsemisubmersible reference. Metacentric height analysis confirmed hydrostatic\nstability across a range of prescribed flap angles. Sensitivity analysis of\ntwelve geometric variables identified flap dimensions and tower length as\ndominant drivers of stability, energy capture, and tower stress. Time-domain\nsimulations revealed dependence on wave incidence angle, with variations in\nflap power sharing, capture width ratio (CWR), and platform response. The\nfeasibility of using flap sweeps to modulate pitch motion was also\ndemonstrated. Annual energy production (AEP) estimates based on site-specific\ndata indicate 16.86 GWh from wind and 3.65 GWh from wave energy, with WECs\ncontributing about 18% of the total. These results highlight the potential of\nintegrated wind-wave platforms and point toward future studies on structural\nmodeling and advanced control."}
{"id": "2510.15769", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.15769", "abs": "https://arxiv.org/abs/2510.15769", "authors": ["Allen Daniel Sunny"], "title": "Preliminary Quantitative Study on Explainability and Trust in AI Systems", "comment": "8 pages, 3 figures, 2 appendices. Quantitative user study on AI\n  explainability and trust. Preprint, 2025", "summary": "Large-scale AI models such as GPT-4 have accelerated the deployment of\nartificial intelligence across critical domains including law, healthcare, and\nfinance, raising urgent questions about trust and transparency. This study\ninvestigates the relationship between explainability and user trust in AI\nsystems through a quantitative experimental design. Using an interactive,\nweb-based loan approval simulation, we compare how different types of\nexplanations, ranging from basic feature importance to interactive\ncounterfactuals influence perceived trust. Results suggest that interactivity\nenhances both user engagement and confidence, and that the clarity and\nrelevance of explanations are key determinants of trust. These findings\ncontribute empirical evidence to the growing field of human-centered\nexplainable AI, highlighting measurable effects of explainability design on\nuser perception"}
{"id": "2510.15297", "categories": ["cs.CY", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.15297", "abs": "https://arxiv.org/abs/2510.15297", "authors": ["Luca Belli", "Kate Bentley", "Will Alexander", "Emily Ward", "Matt Hawrilenko", "Kelly Johnston", "Mill Brown", "Adam Chekroud"], "title": "VERA-MH Concept Paper", "comment": null, "summary": "We introduce VERA-MH (Validation of Ethical and Responsible AI in Mental\nHealth), an automated evaluation of the safety of AI chatbots used in mental\nhealth contexts, with an initial focus on suicide risk.\n  Practicing clinicians and academic experts developed a rubric informed by\nbest practices for suicide risk management for the evaluation. To fully\nautomate the process, we used two ancillary AI agents. A user-agent model\nsimulates users engaging in a mental health-based conversation with the chatbot\nunder evaluation. The user-agent role-plays specific personas with pre-defined\nrisk levels and other features. Simulated conversations are then passed to a\njudge-agent who scores them based on the rubric. The final evaluation of the\nchatbot being tested is obtained by aggregating the scoring of each\nconversation.\n  VERA-MH is actively under development and undergoing rigorous validation by\nmental health clinicians to ensure user-agents realistically act as patients\nand that the judge-agent accurately scores the AI chatbot. To date we have\nconducted preliminary evaluation of GPT-5, Claude Opus and Claude Sonnet using\ninitial versions of the VERA-MH rubric and used the findings for further design\ndevelopment. Next steps will include more robust clinical validation and\niteration, as well as refining actionable scoring. We are seeking feedback from\nthe community on both the technical and clinical aspects of our evaluation."}
{"id": "2510.15772", "categories": ["cs.AI", "I.2.0"], "pdf": "https://arxiv.org/pdf/2510.15772", "abs": "https://arxiv.org/abs/2510.15772", "authors": ["Richard M. Bailey"], "title": "Self-evolving expertise in complex non-verifiable subject domains: dialogue as implicit meta-RL", "comment": "50 pages, 4 figures", "summary": "So-called `wicked problems', those involving complex multi-dimensional\nsettings, non-verifiable outcomes, heterogeneous impacts and a lack of single\nobjectively correct answers, have plagued humans throughout history. Modern\nexamples include decisions over justice frameworks, solving environmental\npollution, planning for pandemic resilience and food security. The use of\nstate-of-the-art artificial intelligence systems (notably Large Language\nModel-based agents) collaborating with humans on solving such problems is being\nactively explored. While the abilities of LLMs can be improved by, for example,\nfine-tuning, hand-crafted system prompts and scaffolding with external tools,\nLLMs lack endogenous mechanisms to develop expertise through experience in such\nsettings. This work address this gap with Dialectica, a framework where agents\nengage in structured dialogue on defined topics, augmented by memory,\nself-reflection, and policy-constrained context editing. Formally, discussion\nis viewed as an implicit meta-reinforcement learning process. The\n`dialogue-trained' agents are evaluated post-hoc using judged pairwise\ncomparisons of elicited responses. Across two model architectures (locally run\nQwen3:30b and OpenAI's o4-mini) results show that enabling reflection-based\ncontext editing during discussion produces agents which dominate their baseline\ncounterparts on Elo scores, normalized Bradley-Terry-Davidson ability, and\nAlphaRank mass. The predicted signatures of learning are observed qualitatively\nin statement and reflection logs, where reflections identify weaknesses and\nreliably shape subsequent statements. Agreement between quantitative and\nqualitative evidence supports dialogue-driven context evolution as a practical\npath to targeted expertise amplification in open non-verifiable domains."}
{"id": "2510.15306", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15306", "abs": "https://arxiv.org/abs/2510.15306", "authors": ["Kuang-Da Wang", "Zhao Wang", "Yotaro Shimose", "Wei-Yao Wang", "Shingo Takamatsu"], "title": "WebGen-V Bench: Structured Representation for Enhancing Visual Design in LLM-based Web Generation and Evaluation", "comment": null, "summary": "Witnessed by the recent advancements on leveraging LLM for coding and\nmultimodal understanding, we present WebGen-V, a new benchmark and framework\nfor instruction-to-HTML generation that enhances both data quality and\nevaluation granularity. WebGen-V contributes three key innovations: (1) an\nunbounded and extensible agentic crawling framework that continuously collects\nreal-world webpages and can leveraged to augment existing benchmarks; (2) a\nstructured, section-wise data representation that integrates metadata,\nlocalized UI screenshots, and JSON-formatted text and image assets, explicit\nalignment between content, layout, and visual components for detailed\nmultimodal supervision; and (3) a section-level multimodal evaluation protocol\naligning text, layout, and visuals for high-granularity assessment. Experiments\nwith state-of-the-art LLMs and ablation studies validate the effectiveness of\nour structured data and section-wise evaluation, as well as the contribution of\neach component. To the best of our knowledge, WebGen-V is the first work to\nenable high-granularity agentic crawling and evaluation for instruction-to-HTML\ngeneration, providing a unified pipeline from real-world data acquisition and\nwebpage generation to structured multimodal assessment."}
{"id": "2510.15782", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15782", "abs": "https://arxiv.org/abs/2510.15782", "authors": ["Philip DiGiacomo", "Haoyang Wang", "Jinrui Fang", "Yan Leng", "W Michael Brode", "Ying Ding"], "title": "Demo: Guide-RAG: Evidence-Driven Corpus Curation for Retrieval-Augmented Generation in Long COVID", "comment": "Accepted to 39th Conference on Neural Information Processing Systems\n  (NeurIPS 2025) Workshop: The Second Workshop on GenAI for Health: Potential,\n  Trust, and Policy Compliance", "summary": "As AI chatbots gain adoption in clinical medicine, developing effective\nframeworks for complex, emerging diseases presents significant challenges. We\ndeveloped and evaluated six Retrieval-Augmented Generation (RAG) corpus\nconfigurations for Long COVID (LC) clinical question answering, ranging from\nexpert-curated sources to large-scale literature databases. Our evaluation\nemployed an LLM-as-a-judge framework across faithfulness, relevance, and\ncomprehensiveness metrics using LongCOVID-CQ, a novel dataset of\nexpert-generated clinical questions. Our RAG corpus configuration combining\nclinical guidelines with high-quality systematic reviews consistently\noutperformed both narrow single-guideline approaches and large-scale literature\ndatabases. Our findings suggest that for emerging diseases, retrieval grounded\nin curated secondary reviews provides an optimal balance between narrow\nconsensus documents and unfiltered primary literature, supporting clinical\ndecision-making while avoiding information overload and oversimplified\nguidance. We propose Guide-RAG, a chatbot system and accompanying evaluation\nframework that integrates both curated expert knowledge and comprehensive\nliterature databases to effectively answer LC clinical questions."}
{"id": "2510.15317", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15317", "abs": "https://arxiv.org/abs/2510.15317", "authors": ["Tingqiao Xu", "Ziru Zeng", "Jiayu Chen"], "title": "VERITAS: Leveraging Vision Priors and Expert Fusion to Improve Multimodal Data", "comment": "Accepted to EMNLP 2025 (Main Conference)", "summary": "The quality of supervised fine-tuning (SFT) data is crucial for the\nperformance of large multimodal models (LMMs), yet current data enhancement\nmethods often suffer from factual errors and hallucinations due to inadequate\nvisual perception. To address this challenge, we propose VERITAS, a pipeline\nthat systematically integrates vision priors and multiple state-of-the-art LMMs\nwith statistical methods to enhance SFT data quality. VERITAS leverages visual\nrecognition models (RAM++) and OCR systems (PP-OCRv4) to extract structured\nvision priors, which are combined with images, questions, and answers. Three\nLMMs (GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro) evaluate the original answers,\nproviding critique rationales and scores that are statistically fused into a\nhigh-confidence consensus score serving as ground truth. Using this consensus,\nwe train a lightweight critic model via Group Relative Policy Optimization\n(GRPO), enhancing reasoning capabilities efficiently. Each LMM then refines the\noriginal answers based on the critiques, generating new candidate answers; we\nselect the highest-scoring one as the final refined answer. Experiments across\nsix multimodal benchmarks demonstrate that models fine-tuned with data\nprocessed by VERITAS consistently outperform those using raw data, particularly\nin text-rich and fine-grained reasoning tasks. Our critic model exhibits\nenhanced capability comparable to state-of-the-art LMMs while being\nsignificantly more efficient. We release our pipeline, datasets, and model\ncheckpoints to advance research in multimodal data optimization."}
{"id": "2510.15862", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15862", "abs": "https://arxiv.org/abs/2510.15862", "authors": ["Yi Wan", "Jiuqi Wang", "Liam Li", "Jinsong Liu", "Ruihao Zhu", "Zheqing Zhu"], "title": "PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold", "comment": null, "summary": "Tool-augmented large language models (LLMs) are emerging as deep research\nagents, systems that decompose complex queries, retrieve external evidence, and\nsynthesize grounded responses. Yet current agents remain limited by shallow\nretrieval, weak alignment metrics, and brittle tool-use behavior. We introduce\nPokeeResearch-7B, a 7B-parameter deep research agent built under a unified\nreinforcement learning framework for robustness, alignment, and scalability.\nPokeeResearch-7B is trained by an annotation-free Reinforcement Learning from\nAI Feedback (RLAIF) framework to optimize policies using LLM-based reward\nsignals that capture factual accuracy, citation faithfulness, and instruction\nadherence. A chain-of-thought-driven multi-call reasoning scaffold further\nenhances robustness through self-verification and adaptive recovery from tool\nfailures. Among 10 popular deep research benchmarks, PokeeResearch-7B achieves\nstate-of-the-art performance among 7B-scale deep research agents. This\nhighlights that careful reinforcement learning and reasoning design can produce\nefficient, resilient, and research-grade AI agents. The model and inference\ncode is open-sourced under MIT license at\nhttps://github.com/Pokee-AI/PokeeResearchOSS."}
{"id": "2510.15319", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15319", "abs": "https://arxiv.org/abs/2510.15319", "authors": ["Jeewon Kim", "Minho Oh", "Hyun Myung"], "title": "Traversability-aware Consistent Situational Graphs for Indoor Localization and Mapping", "comment": "Accepted by RiTA 2024", "summary": "Scene graphs enhance 3D mapping capabilities in robotics by understanding the\nrelationships between different spatial elements, such as rooms and objects.\nRecent research extends scene graphs to hierarchical layers, adding and\nleveraging constraints across these levels. This approach is tightly integrated\nwith pose-graph optimization, improving both localization and mapping accuracy\nsimultaneously. However, when segmenting spatial characteristics, consistently\nrecognizing rooms becomes challenging due to variations in viewpoints and\nlimited field of view (FOV) of sensors. For example, existing real-time\napproaches often over-segment large rooms into smaller, non-functional spaces\nthat are not useful for localization and mapping due to the time-dependent\nmethod. Conversely, their voxel-based room segmentation method often\nunder-segment in complex cases like not fully enclosed 3D space that are\nnon-traversable for ground robots or humans, leading to false constraints in\npose-graph optimization. We propose a traversability-aware room segmentation\nmethod that considers the interaction between robots and surroundings, with\nconsistent feasibility of traversability information. This enhances both the\nsemantic coherence and computational efficiency of pose-graph optimization.\nImproved performance is demonstrated through the re-detection frequency of the\nsame rooms in a dataset involving repeated traversals of the same space along\nthe same path, as well as the optimization time consumption."}
{"id": "2510.15200", "categories": ["econ.TH", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15200", "abs": "https://arxiv.org/abs/2510.15200", "authors": ["Fasheng Xu", "Xiaoyu Wang", "Wei Chen", "Karen Xie"], "title": "The Economics of AI Foundation Models: Openness, Competition, and Governance", "comment": null, "summary": "The strategic choice of model \"openness\" has become a defining issue for the\nfoundation model (FM) ecosystem. While this choice is intensely debated, its\nunderlying economic drivers remain underexplored. We construct a two-period\ngame-theoretic model to analyze how openness shapes competition in an AI value\nchain, featuring an incumbent developer, a downstream deployer, and an entrant\ndeveloper. Openness exerts a dual effect: it amplifies knowledge spillovers to\nthe entrant, but it also enhances the incumbent's advantage through a \"data\nflywheel effect,\" whereby greater user engagement today further lowers the\ndeployer's future fine-tuning cost. Our analysis reveals that the incumbent's\noptimal first-period openness is surprisingly non-monotonic in the strength of\nthe data flywheel effect. When the data flywheel effect is either weak or very\nstrong, the incumbent prefers a higher level of openness; however, for an\nintermediate range, it strategically restricts openness to impair the entrant's\nlearning. This dynamic gives rise to an \"openness trap,\" a critical policy\nparadox where transparency mandates can backfire by removing firms' strategic\nflexibility, reducing investment, and lowering welfare. We extend the model to\nshow that other common interventions can be similarly ineffective. Vertical\nintegration, for instance, only benefits the ecosystem when the data flywheel\neffect is strong enough to overcome the loss of a potentially more efficient\ncompetitor. Likewise, government subsidies intended to spur adoption can be\ncaptured entirely by the incumbent through strategic price and openness\nadjustments, leaving the rest of the value chain worse off. By modeling the\ndeveloper's strategic response to competitive and regulatory pressures, we\nprovide a robust framework for analyzing competition and designing effective\npolicy in the complex and rapidly evolving FM ecosystem."}
{"id": "2510.15331", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15331", "abs": "https://arxiv.org/abs/2510.15331", "authors": ["Gahee Kim", "Takamitsu Matsubara"], "title": "ASBI: Leveraging Informative Real-World Data for Active Black-Box Simulator Tuning", "comment": null, "summary": "Black-box simulators are widely used in robotics, but optimizing their\nparameters remains challenging due to inaccessible likelihoods.\nSimulation-Based Inference (SBI) tackles this issue using simulation-driven\napproaches, estimating the posterior from offline real observations and forward\nsimulations. However, in black-box scenarios, preparing observations that\ncontain sufficient information for parameter estimation is difficult due to the\nunknown relationship between parameters and observations. In this work, we\npresent Active Simulation-Based Inference (ASBI), a parameter estimation\nframework that uses robots to actively collect real-world online data to\nachieve accurate black-box simulator tuning. Our framework optimizes robot\nactions to collect informative observations by maximizing information gain,\nwhich is defined as the expected reduction in Shannon entropy between the\nposterior and the prior. While calculating information gain requires the\nlikelihood, which is inaccessible in black-box simulators, our method solves\nthis problem by leveraging Neural Posterior Estimation (NPE), which leverages a\nneural network to learn the posterior estimator. Three simulation experiments\nquantitatively verify that our method achieves accurate parameter estimation,\nwith posteriors sharply concentrated around the true parameters. Moreover, we\nshow a practical application using a real robot to estimate the simulation\nparameters of cubic particles corresponding to two real objects, beads and\ngravel, with a bucket pouring action."}
{"id": "2510.15297", "categories": ["cs.CY", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.15297", "abs": "https://arxiv.org/abs/2510.15297", "authors": ["Luca Belli", "Kate Bentley", "Will Alexander", "Emily Ward", "Matt Hawrilenko", "Kelly Johnston", "Mill Brown", "Adam Chekroud"], "title": "VERA-MH Concept Paper", "comment": null, "summary": "We introduce VERA-MH (Validation of Ethical and Responsible AI in Mental\nHealth), an automated evaluation of the safety of AI chatbots used in mental\nhealth contexts, with an initial focus on suicide risk.\n  Practicing clinicians and academic experts developed a rubric informed by\nbest practices for suicide risk management for the evaluation. To fully\nautomate the process, we used two ancillary AI agents. A user-agent model\nsimulates users engaging in a mental health-based conversation with the chatbot\nunder evaluation. The user-agent role-plays specific personas with pre-defined\nrisk levels and other features. Simulated conversations are then passed to a\njudge-agent who scores them based on the rubric. The final evaluation of the\nchatbot being tested is obtained by aggregating the scoring of each\nconversation.\n  VERA-MH is actively under development and undergoing rigorous validation by\nmental health clinicians to ensure user-agents realistically act as patients\nand that the judge-agent accurately scores the AI chatbot. To date we have\nconducted preliminary evaluation of GPT-5, Claude Opus and Claude Sonnet using\ninitial versions of the VERA-MH rubric and used the findings for further design\ndevelopment. Next steps will include more robust clinical validation and\niteration, as well as refining actionable scoring. We are seeking feedback from\nthe community on both the technical and clinical aspects of our evaluation."}
{"id": "2510.15336", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15336", "abs": "https://arxiv.org/abs/2510.15336", "authors": ["Liviu-Mihai Stan", "Ranulfo Bezerra", "Shotaro Kojima", "Tsige Tadesse Alemayoh", "Satoshi Tadokoro", "Masashi Konyo", "Kazunori Ohno"], "title": "Adaptive Cost-Map-based Path Planning in Partially Unknown Environments with Movable Obstacles", "comment": null, "summary": "Reliable navigation in disaster-response and other unstructured indoor\nsettings requires robots not only to avoid obstacles but also to recognise when\nthose obstacles can be pushed aside. We present an adaptive, LiDAR and\nodometry-based path-planning framework that embeds this capability into the\nROS2 Nav2 stack. A new Movable Obstacles Layer labels all LiDAR returns missing\nfrom a prior static map as tentatively movable and assigns a reduced traversal\ncost. A companion Slow-Pose Progress Checker monitors the ratio of commanded to\nactual velocity; when the robot slows appreciably, the local cost is raised\nfrom light to heavy, and on a stall to lethal, prompting the global planner to\nback out and re-route. Gazebo evaluations on a Scout Mini, spanning isolated\nobjects and cluttered corridors, show higher goal-reach rates and fewer\ndeadlocks than a no-layer baseline, with traversal times broadly comparable.\nBecause the method relies only on planar scans and CPU-level computation, it\nsuits resource-constrained search and rescue robots and integrates into\nheterogeneous platforms with minimal engineering. Overall, the results indicate\nthat interaction-aware cost maps are a lightweight, ROS2-native extension for\nnavigating among potentially movable obstacles in unstructured settings. The\nfull implementation will be released as open source\nathttps://costmap-namo.github.io."}
{"id": "2510.15331", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15331", "abs": "https://arxiv.org/abs/2510.15331", "authors": ["Gahee Kim", "Takamitsu Matsubara"], "title": "ASBI: Leveraging Informative Real-World Data for Active Black-Box Simulator Tuning", "comment": null, "summary": "Black-box simulators are widely used in robotics, but optimizing their\nparameters remains challenging due to inaccessible likelihoods.\nSimulation-Based Inference (SBI) tackles this issue using simulation-driven\napproaches, estimating the posterior from offline real observations and forward\nsimulations. However, in black-box scenarios, preparing observations that\ncontain sufficient information for parameter estimation is difficult due to the\nunknown relationship between parameters and observations. In this work, we\npresent Active Simulation-Based Inference (ASBI), a parameter estimation\nframework that uses robots to actively collect real-world online data to\nachieve accurate black-box simulator tuning. Our framework optimizes robot\nactions to collect informative observations by maximizing information gain,\nwhich is defined as the expected reduction in Shannon entropy between the\nposterior and the prior. While calculating information gain requires the\nlikelihood, which is inaccessible in black-box simulators, our method solves\nthis problem by leveraging Neural Posterior Estimation (NPE), which leverages a\nneural network to learn the posterior estimator. Three simulation experiments\nquantitatively verify that our method achieves accurate parameter estimation,\nwith posteriors sharply concentrated around the true parameters. Moreover, we\nshow a practical application using a real robot to estimate the simulation\nparameters of cubic particles corresponding to two real objects, beads and\ngravel, with a bucket pouring action."}
{"id": "2510.15350", "categories": ["cs.RO", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.15350", "abs": "https://arxiv.org/abs/2510.15350", "authors": ["Shyalan Ramesh", "Scott Mann", "Alex Stumpf"], "title": "Nauplius Optimisation for Autonomous Hydrodynamics", "comment": null, "summary": "Autonomous Underwater vehicles must operate in strong currents, limited\nacoustic bandwidth, and persistent sensing requirements where conventional\nswarm optimisation methods are unreliable. This paper presents NOAH, a novel\nnature-inspired swarm optimisation algorithm that combines current-aware drift,\nirreversible settlement in persistent sensing nodes, and colony-based\ncommunication. Drawing inspiration from the behaviour of barnacle nauplii, NOAH\naddresses the critical limitations of existing swarm algorithms by providing\nhydrodynamic awareness, irreversible anchoring mechanisms, and colony-based\ncommunication capabilities essential for underwater exploration missions. The\nalgorithm establishes a comprehensive foundation for scalable and\nenergy-efficient underwater swarm robotics with validated performance analysis.\nValidation studies demonstrate an 86% success rate for permanent anchoring\nscenarios, providing a unified formulation for hydrodynamic constraints and\nirreversible settlement behaviours with an empirical study under flow."}
{"id": "2510.15352", "categories": ["cs.RO", "cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2510.15352", "abs": "https://arxiv.org/abs/2510.15352", "authors": ["Alejandro Escontrela", "Justin Kerr", "Arthur Allshire", "Jonas Frey", "Rocky Duan", "Carmelo Sferrazza", "Pieter Abbeel"], "title": "GaussGym: An open-source real-to-sim framework for learning locomotion from pixels", "comment": null, "summary": "We present a novel approach for photorealistic robot simulation that\nintegrates 3D Gaussian Splatting as a drop-in renderer within vectorized\nphysics simulators such as IsaacGym. This enables unprecedented speed --\nexceeding 100,000 steps per second on consumer GPUs -- while maintaining high\nvisual fidelity, which we showcase across diverse tasks. We additionally\ndemonstrate its applicability in a sim-to-real robotics setting. Beyond\ndepth-based sensing, our results highlight how rich visual semantics improve\nnavigation and decision-making, such as avoiding undesirable regions. We\nfurther showcase the ease of incorporating thousands of environments from\niPhone scans, large-scale scene datasets (e.g., GrandTour, ARKit), and outputs\nfrom generative video models like Veo, enabling rapid creation of realistic\ntraining worlds. This work bridges high-throughput simulation and high-fidelity\nperception, advancing scalable and generalizable robot learning. All code and\ndata will be open-sourced for the community to build upon. Videos, code, and\ndata available at https://escontrela.me/gauss_gym/."}
{"id": "2510.15352", "categories": ["cs.RO", "cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2510.15352", "abs": "https://arxiv.org/abs/2510.15352", "authors": ["Alejandro Escontrela", "Justin Kerr", "Arthur Allshire", "Jonas Frey", "Rocky Duan", "Carmelo Sferrazza", "Pieter Abbeel"], "title": "GaussGym: An open-source real-to-sim framework for learning locomotion from pixels", "comment": null, "summary": "We present a novel approach for photorealistic robot simulation that\nintegrates 3D Gaussian Splatting as a drop-in renderer within vectorized\nphysics simulators such as IsaacGym. This enables unprecedented speed --\nexceeding 100,000 steps per second on consumer GPUs -- while maintaining high\nvisual fidelity, which we showcase across diverse tasks. We additionally\ndemonstrate its applicability in a sim-to-real robotics setting. Beyond\ndepth-based sensing, our results highlight how rich visual semantics improve\nnavigation and decision-making, such as avoiding undesirable regions. We\nfurther showcase the ease of incorporating thousands of environments from\niPhone scans, large-scale scene datasets (e.g., GrandTour, ARKit), and outputs\nfrom generative video models like Veo, enabling rapid creation of realistic\ntraining worlds. This work bridges high-throughput simulation and high-fidelity\nperception, advancing scalable and generalizable robot learning. All code and\ndata will be open-sourced for the community to build upon. Videos, code, and\ndata available at https://escontrela.me/gauss_gym/."}
{"id": "2510.15509", "categories": ["cs.CY", "cs.AI", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15509", "abs": "https://arxiv.org/abs/2510.15509", "authors": ["Janne Rotter", "William Bailkoski"], "title": "AI Adoption in NGOs: A Systematic Literature Review", "comment": null, "summary": "AI has the potential to significantly improve how NGOs utilize their limited\nresources for societal benefits, but evidence about how NGOs adopt AI remains\nscattered. In this study, we systematically investigate the types of AI\nadoption use cases in NGOs and identify common challenges and solutions,\ncontextualized by organizational size and geographic context. We review the\nexisting primary literature, including studies that investigate AI adoption in\nNGOs related to social impact between 2020 and 2025 in English. Following the\nPRISMA protocol, two independent reviewers conduct study selection, with\nregular cross-checking to ensure methodological rigour, resulting in a final\nliterature body of 65 studies. Leveraging a thematic and narrative approach, we\nidentify six AI use case categories in NGOs - Engagement, Creativity,\nDecision-Making, Prediction, Management, and Optimization - and extract common\nchallenges and solutions within the Technology-Organization-Environment (TOE)\nframework. By integrating our findings, this review provides a novel\nunderstanding of AI adoption in NGOs, linking specific use cases and challenges\nto organizational and environmental factors. Our results demonstrate that while\nAI is promising, adoption among NGOs remains uneven and biased towards larger\norganizations. Nevertheless, following a roadmap grounded in literature can\nhelp NGOs overcome initial barriers to AI adoption, ultimately improving\neffectiveness, engagement, and social impact."}
{"id": "2510.15365", "categories": ["eess.SY", "cs.LG", "cs.MA", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15365", "abs": "https://arxiv.org/abs/2510.15365", "authors": ["Maonan Wang", "Yirong Chen", "Yuxin Cai", "Aoyu Pang", "Yuejiao Xie", "Zian Ma", "Chengcheng Xu", "Kemou Jiang", "Ding Wang", "Laurent Roullet", "Chung Shue Chen", "Zhiyong Cui", "Yuheng Kan", "Michael Lepech", "Man-On Pun"], "title": "TranSimHub:A Unified Air-Ground Simulation Platform for Multi-Modal Perception and Decision-Making", "comment": "9 pages, 4 figures", "summary": "Air-ground collaborative intelligence is becoming a key approach for\nnext-generation urban intelligent transportation management, where aerial and\nground systems work together on perception, communication, and decision-making.\nHowever, the lack of a unified multi-modal simulation environment has limited\nprogress in studying cross-domain perception, coordination under communication\nconstraints, and joint decision optimization. To address this gap, we present\nTranSimHub, a unified simulation platform for air-ground collaborative\nintelligence. TranSimHub offers synchronized multi-view rendering across RGB,\ndepth, and semantic segmentation modalities, ensuring consistent perception\nbetween aerial and ground viewpoints. It also supports information exchange\nbetween the two domains and includes a causal scene editor that enables\ncontrollable scenario creation and counterfactual analysis under diverse\nconditions such as different weather, emergency events, and dynamic obstacles.\nWe release TranSimHub as an open-source platform that supports end-to-end\nresearch on perception, fusion, and control across realistic air and ground\ntraffic scenes. Our code is available at\nhttps://github.com/Traffic-Alpha/TranSimHub."}
{"id": "2510.15374", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15374", "abs": "https://arxiv.org/abs/2510.15374", "authors": ["Zezhong Tan", "Hang Gao", "Xinhong Ma", "Feng Zhang", "Ziqiang Dong"], "title": "Towards Flash Thinking via Decoupled Advantage Policy Optimization", "comment": null, "summary": "Recent Large Reasoning Models (LRMs) have achieved remarkable performance in\nsolving complex problems via supervised fine-tuning (SFT) and reinforcement\nlearning (RL). Although existing RL algorithms significantly enhance model\naccuracy, they still suffer from excessively lengthy responses and overthinking\nissues, resulting in increased inference latency and computational consumption,\nespecially for simple tasks that require minimal reasoning. To address this, we\npropose a novel RL framework, DEPO, to reduce inefficient reasoning for models.\nOur method mainly consists of three core components: (1) an innovative\nadvantage decoupled algorithm to guide model reduction of inefficient tokens;\n(2) a difficulty-aware length penalty to lower the overall length of model\nresponses; (3) an advantage clipping method to prevent bias in policy\noptimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and\nDeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant\nreduction in sequence length by 39% and reduces excessive reasoning paths in\ninefficient tokens, while outperforming the base model in overall accuracy."}
{"id": "2510.15376", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15376", "abs": "https://arxiv.org/abs/2510.15376", "authors": ["Zhaodong Yang", "Ai-Ping Hu", "Harish Ravichandar"], "title": "Towards Automated Chicken Deboning via Learning-based Dynamically-Adaptive 6-DoF Multi-Material Cutting", "comment": "8 Pages, 8 figures", "summary": "Automating chicken shoulder deboning requires precise 6-DoF cutting through a\npartially occluded, deformable, multi-material joint, since contact with the\nbones presents serious health and safety risks. Our work makes both\nsystems-level and algorithmic contributions to train and deploy a reactive\nforce-feedback cutting policy that dynamically adapts a nominal trajectory and\nenables full 6-DoF knife control to traverse the narrow joint gap while\navoiding contact with the bones. First, we introduce an open-source\ncustom-built simulator for multi-material cutting that models coupling,\nfracture, and cutting forces, and supports reinforcement learning, enabling\nefficient training and rapid prototyping. Second, we design a reusable physical\ntestbed to emulate the chicken shoulder: two rigid \"bone\" spheres with\ncontrollable pose embedded in a softer block, enabling rigorous and repeatable\nevaluation while preserving essential multi-material characteristics of the\ntarget problem. Third, we train and deploy a residual RL policy, with\ndiscretized force observations and domain randomization, enabling robust\nzero-shot sim-to-real transfer and the first demonstration of a learned policy\nthat debones a real chicken shoulder. Our experiments in our simulator, on our\nphysical testbed, and on real chicken shoulders show that our learned policy\nreliably navigates the joint gap and reduces undesired bone/cartilage contact,\nresulting in up to a 4x improvement over existing open-loop cutting baselines\nin terms of success rate and bone avoidance. Our results also illustrate the\nnecessity of force feedback for safe and effective multi-material cutting. The\nproject website is at https://sites.google.com/view/chickendeboning-2026."}
{"id": "2510.15387", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15387", "abs": "https://arxiv.org/abs/2510.15387", "authors": ["Davide Basso", "Luca Bortolussi", "Mirjana Videnovic-Misic", "Husni Habal"], "title": "Advancing Routing-Awareness in Analog ICs Floorplanning", "comment": null, "summary": "The adoption of machine learning-based techniques for analog integrated\ncircuit layout, unlike its digital counterpart, has been limited by the\nstringent requirements imposed by electric and problem-specific constraints,\nalong with the interdependence of floorplanning and routing steps. In this\nwork, we address a prevalent concern among layout engineers regarding the need\nfor readily available routing-aware floorplanning solutions. To this extent, we\ndevelop an automatic floorplanning engine based on reinforcement learning and\nrelational graph convolutional neural network specifically tailored to\ncondition the floorplan generation towards more routable outcomes. A\ncombination of increased grid resolution and precise pin information\nintegration, along with a dynamic routing resource estimation technique, allows\nbalancing routing and area efficiency, eventually meeting industrial standards.\nWhen analyzing the place and route effectiveness in a simulated environment,\nthe proposed approach achieves a 13.8% reduction in dead space, a 40.6%\nreduction in wirelength and a 73.4% increase in routing success when compared\nto past learning-based state-of-the-art techniques."}
{"id": "2510.15395", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15395", "abs": "https://arxiv.org/abs/2510.15395", "authors": ["Rubi Hudson"], "title": "Corrigibility Transformation: Constructing Goals That Accept Updates", "comment": null, "summary": "For an AI's training process to successfully impart a desired goal, it is\nimportant that the AI does not attempt to resist the training. However,\npartially learned goals will often incentivize an AI to avoid further goal\nupdates, as most goals are better achieved by an AI continuing to pursue them.\nWe say that a goal is corrigible if it does not incentivize taking actions that\navoid proper goal updates or shutdown. In addition to convergence in training,\ncorrigibility also allows for correcting mistakes and changes in human\npreferences, which makes it a crucial safety property. Despite this, the\nexisting literature does not include specifications for goals that are both\ncorrigible and competitive with non-corrigible alternatives. We provide a\nformal definition for corrigibility, then introduce a transformation that\nconstructs a corrigible version of any goal that can be made corrigible,\nwithout sacrificing performance. This is done by myopically eliciting\npredictions of reward conditional on costlessly preventing updates, which then\nalso determine the reward when updates are accepted. The transformation can be\nmodified to recursively extend corrigibility to any new agents created by\ncorrigible agents, and to prevent agents from deliberately modifying their\ngoals. Two gridworld experiments demonstrate that these corrigible goals can be\nlearned effectively, and that they lead to the desired behavior."}
{"id": "2510.15414", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15414", "abs": "https://arxiv.org/abs/2510.15414", "authors": ["Huining Yuan", "Zelai Xu", "Zheyue Tan", "Xiangmin Yi", "Mo Guang", "Kaiwen Long", "Haojia Hui", "Boxun Li", "Xinlei Chen", "Bo Zhao", "Xiao-Ping Zhang", "Chao Yu", "Yu Wang"], "title": "MARS: Reinforcing Multi-Agent Reasoning of LLMs through Self-Play in Strategic Games", "comment": null, "summary": "Developing Large Language Models (LLMs) to cooperate and compete effectively\nwithin multi-agent systems is a critical step towards more advanced\nintelligence. While reinforcement learning (RL) has proven effective for\nenhancing reasoning in single-agent tasks, its extension to multi-turn,\nmulti-agent scenarios remains underexplored due to the challenges of\nlong-horizon credit assignment and agent-specific advantage estimation. To\naddress these challenges, we introduce MARS, an end-to-end RL framework that\nincentivizes Multi-Agent Reasoning of LLMs through Self-play in both\ncooperative and competitive games. MARS features a turn-level advantage\nestimator that aligns learning signals with each interaction for credit\nassignment, and an agent-specific advantage normalization to stabilize\nmulti-agent training. By learning with self-play across cooperative and\ncompetitive games, the MARS agent trained from Qwen3-4B develops strong\nstrategic abilities that generalize to held-out games with up to 28.7%\nperformance improvements. More importantly, the capability acquired through\nself-play generalizes beyond games, yielding consistent performance gains of\nmulti-agent systems in reasoning benchmarks. When integrated into leading\nmulti-agent systems, our MARS agent achieves significant performance gains of\n10.0% on AIME and 12.5% on GPQA-Diamond. These results establish end-to-end RL\ntraining with self-play in strategic games as a powerful approach for\ndeveloping generalizable multi-agent reasoning capabilities in LLMs. Our code\nand models are publicly available at https://github.com/thu-nics/MARS."}
{"id": "2510.15416", "categories": ["cs.AI", "68T05, 68T42", "I.2.11; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2510.15416", "abs": "https://arxiv.org/abs/2510.15416", "authors": ["Pavan C Shekar", "Ashwanth Krishnan"], "title": "Adaptive Minds: Empowering Agents with LoRA-as-Tools", "comment": "12 pages, 1 figure, 7 tables . Code available at:\n  https://github.com/qpiai/adaptive-minds", "summary": "We present Adaptive Minds, an agentic system that treats LoRA adapters as\ndomain-specific tools. Instead of relying on a single fine-tuned model or rigid\nrule-based routing, our approach empowers the base LLM itself to act as a\nsemantic router analyzing each query and dynamically selecting the most\nrelevant LoRA tool. This enables the agent to seamlessly switch between\ndifferent domain experts on demand. By combining the flexibility of multi-agent\norchestration with the efficiency of parameter-efficient fine-tuning, Adaptive\nMinds delivers accurate, specialized responses while preserving conversational\nability. The system is built with LangGraph for workflow management, supports\nboth API and web interfaces, and is fully open source, providing a scalable and\nextensible foundation for domain-adaptive AI assistance."}
{"id": "2510.15442", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.15442", "abs": "https://arxiv.org/abs/2510.15442", "authors": ["Roger Waldeck", "Ann-Kristin Winkens", "Clara Lemke", "Carmen Leicht-Scholten", "Haraldur Audunsson"], "title": "Identifying curriculum disruptions in engineering education through serious gaming", "comment": null, "summary": "This workshop introduces participants to SUCRE, a serious game designed to\nenhance curriculum resilience in higher education by simulating crisis\nscenarios. While applicable to various disciplines, this session focuses on\nengineering curricula, identifying discipline-specific challenges and potential\nadaptations. Participants will engage in Step 1 of the game, analyzing trigger\nevents and their impacts on curriculum structures. At the end of the workshop,\nattendees will be able to identify key triggers that may affect curricula,\nassess their cascading effects, and reflect on the applicability of SUCRE\nwithin their own institutions."}
{"id": "2510.15446", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15446", "abs": "https://arxiv.org/abs/2510.15446", "authors": ["Ziang Guo", "Zufeng Zhang"], "title": "VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving", "comment": "1st version", "summary": "In autonomous driving, dynamic environment and corner cases pose significant\nchallenges to the robustness of ego vehicle's state understanding and decision\nmaking. We introduce VDRive, a novel pipeline for end-to-end autonomous driving\nthat explicitly models state-action mapping to address these challenges,\nenabling interpretable and robust decision making. By leveraging the\nadvancement of the state understanding of the Vision Language Action Model\n(VLA) with generative diffusion policy-based action head, our VDRive guides the\ndriving contextually and geometrically. Contextually, VLA predicts future\nobservations through token generation pre-training, where the observations are\nrepresented as discrete codes by a Conditional Vector Quantized Variational\nAutoencoder (CVQ-VAE). Geometrically, we perform reinforcement learning\nfine-tuning of the VLA to predict future trajectories and actions based on\ncurrent driving conditions. VLA supplies the current state tokens and predicted\nstate tokens for the action policy head to generate hierarchical actions and\ntrajectories. During policy training, a learned critic evaluates the actions\ngenerated by the policy and provides gradient-based feedback, forming an\nactor-critic framework that enables a reinforcement-based policy learning\npipeline. Experiments show that our VDRive achieves state-of-the-art\nperformance in the Bench2Drive closed-loop benchmark and nuScenes open-loop\nplanning."}
{"id": "2510.15505", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15505", "abs": "https://arxiv.org/abs/2510.15505", "authors": ["Aron Distelzweig", "Faris Janjoš", "Oliver Scheel", "Sirish Reddy Varra", "Raghu Rajan", "Joschka Boedecker"], "title": "Perfect Prediction or Plenty of Proposals? What Matters Most in Planning for Autonomous Driving", "comment": "8 pages, 5 figures", "summary": "Traditionally, prediction and planning in autonomous driving (AD) have been\ntreated as separate, sequential modules. Recently, there has been a growing\nshift towards tighter integration of these components, known as Integrated\nPrediction and Planning (IPP), with the aim of enabling more informed and\nadaptive decision-making. However, it remains unclear to what extent this\nintegration actually improves planning performance. In this work, we\ninvestigate the role of prediction in IPP approaches, drawing on the widely\nadopted Val14 benchmark, which encompasses more common driving scenarios with\nrelatively low interaction complexity, and the interPlan benchmark, which\nincludes highly interactive and out-of-distribution driving situations. Our\nanalysis reveals that even access to perfect future predictions does not lead\nto better planning outcomes, indicating that current IPP methods often fail to\nfully exploit future behavior information. Instead, we focus on high-quality\nproposal generation, while using predictions primarily for collision checks. We\nfind that many imitation learning-based planners struggle to generate realistic\nand plausible proposals, performing worse than PDM - a simple lane-following\napproach. Motivated by this observation, we build on PDM with an enhanced\nproposal generation method, shifting the emphasis towards producing diverse but\nrealistic and high-quality proposals. This proposal-centric approach\nsignificantly outperforms existing methods, especially in out-of-distribution\nand highly interactive settings, where it sets new state-of-the-art results."}
{"id": "2510.15509", "categories": ["cs.CY", "cs.AI", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15509", "abs": "https://arxiv.org/abs/2510.15509", "authors": ["Janne Rotter", "William Bailkoski"], "title": "AI Adoption in NGOs: A Systematic Literature Review", "comment": null, "summary": "AI has the potential to significantly improve how NGOs utilize their limited\nresources for societal benefits, but evidence about how NGOs adopt AI remains\nscattered. In this study, we systematically investigate the types of AI\nadoption use cases in NGOs and identify common challenges and solutions,\ncontextualized by organizational size and geographic context. We review the\nexisting primary literature, including studies that investigate AI adoption in\nNGOs related to social impact between 2020 and 2025 in English. Following the\nPRISMA protocol, two independent reviewers conduct study selection, with\nregular cross-checking to ensure methodological rigour, resulting in a final\nliterature body of 65 studies. Leveraging a thematic and narrative approach, we\nidentify six AI use case categories in NGOs - Engagement, Creativity,\nDecision-Making, Prediction, Management, and Optimization - and extract common\nchallenges and solutions within the Technology-Organization-Environment (TOE)\nframework. By integrating our findings, this review provides a novel\nunderstanding of AI adoption in NGOs, linking specific use cases and challenges\nto organizational and environmental factors. Our results demonstrate that while\nAI is promising, adoption among NGOs remains uneven and biased towards larger\norganizations. Nevertheless, following a roadmap grounded in literature can\nhelp NGOs overcome initial barriers to AI adoption, ultimately improving\neffectiveness, engagement, and social impact."}
{"id": "2510.15514", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15514", "abs": "https://arxiv.org/abs/2510.15514", "authors": ["Boyin Liu", "Zhuo Zhang", "Sen Huang", "Lipeng Xie", "Qingxu Fu", "Haoran Chen", "LI YU", "Tianyi Hu", "Zhaoyang Liu", "Bolin Ding", "Dongbin Zhao"], "title": "Taming the Judge: Deconflicting AI Feedback for Stable Reinforcement Learning", "comment": null, "summary": "However, this method often faces judgment inconsistencies that can\ndestabilize reinforcement learning. While prior research has focused on the\naccuracy of judgments, the critical issue of logical coherence especially\nissues such as preference cycles hasn't been fully addressed. To fill this gap,\nwe introduce a comprehensive framework designed to systematically detect and\nresolve these inconsistencies during the reinforcement learning training\nprocess. Our framework includes two main contributions: first, the Conflict\nDetection Rate (CDR), a new metric that quantifies judgment conflicts, and\nsecond, Deconflicted Graph Rewards (DGR), a framework that purifies signals by\nremoving cycles before policy optimization. DGR constructs preference graphs\nfrom the initial judgments, transforms them into conflict-free Directed Acyclic\nGraphs (DAGs), and generates a logically coherent reward signal that is\ncompatible with any policy optimizer. Experimental results show that our\nframework significantly enhances training stability and model performance\ncompared to strong baselines, establishing logical consistency as a crucial and\nnow manageable dimension of AI feedback."}
{"id": "2510.15519", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15519", "abs": "https://arxiv.org/abs/2510.15519", "authors": ["Yushu Qin", "Marcos L. L. Sartori", "Shengyu Duan", "Emre Ozer", "Rishad Shafik", "Alex Yakovlev"], "title": "A Tsetlin Machine Image Classification Accelerator on a Flexible Substrate", "comment": "accepted by International Symposium on the Tsetlin Machine (ISTM)\n  2025", "summary": "This paper introduces the first implementation of digital Tsetlin Machines\n(TMs) on flexible integrated circuit (FlexIC) using Pragmatic's 600nm\nIGZO-based FlexIC technology. TMs, known for their energy efficiency,\ninterpretability, and suitability for edge computing, have previously been\nlimited by the rigidity of conventional silicon-based chips. We develop two TM\ninference models as FlexICs: one achieving 98.5% accuracy using 6800 NAND2\nequivalent logic gates with an area of 8X8 mm2, and a second more compact\nversion achieving slightly lower prediction accuracy of 93% but using only 1420\nNAND2 equivalent gates with an area of 4X4 mm2, both of which are\ncustom-designed for an 8X8-pixel handwritten digit recognition dataset. The\npaper demonstrates the feasibility of deploying flexible TM inference engines\ninto wearable healthcare and edge computing applications."}
{"id": "2510.15530", "categories": ["cs.RO", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15530", "abs": "https://arxiv.org/abs/2510.15530", "authors": ["Zehao Ni", "Yonghao He", "Lingfeng Qian", "Jilei Mao", "Fa Fu", "Wei Sui", "Hu Su", "Junran Peng", "Zhipeng Wang", "Bin He"], "title": "VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation", "comment": null, "summary": "In the context of imitation learning, visuomotor-based diffusion policy\nlearning is one of the main directions in robotic manipulation. Most of these\napproaches rely on point clouds as observation inputs and construct scene\nrepresentations through point clouds feature learning, which enables them to\nachieve remarkable accuracy. However, the existing literature lacks an in-depth\nexploration of vision-only solutions that have significant potential. In this\npaper, we propose a Vision-Only and single-view Diffusion Policy learning\nmethod (VO-DP) that leverages pretrained visual foundation models to achieve\neffective fusion of semantic and geometric features. We utilize intermediate\nfeatures from VGGT incorporating semantic features from DINOv2 and geometric\nfeatures from Alternating Attention blocks. Features are fused via\ncross-attention and spatially compressed with a CNN to form the input to the\npolicy head. Extensive experiments demonstrate that VO-DP not only outperforms\nthe vision-only baseline DP significantly but also exhibits distinct\nperformance trends against the point cloud-based method DP3: in simulation\ntasks, VO-DP achieves an average success rate of 64.6% on par with DP3 64.0%\nand far higher than DP 34.8%, while in real-world tasks, it reaches 87.9%,\noutperforming both DP3 67.5% and DP 11.2% by a notable margin. Further\nrobustness evaluations confirm that VO-DP remains highly stable under varying\nconditions including color, size, background, and lighting. Lastly, we\nopen-source a training library for robotic manipulation. Built on Accelerate,\nthis library supports multi-machine and multi-GPU parallel training, as well as\nmixed precision training. It is compatible with visuomotor policies such as DP,\nDP3 and VO-DP, and also supports the RoboTwin simulator."}
{"id": "2510.15533", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15533", "abs": "https://arxiv.org/abs/2510.15533", "authors": ["Shilei Li", "Dawei Shi", "Makoto Iwasaki", "Yan Ning", "Hongpeng Zhou", "Ling Shi"], "title": "Improved Extended Kalman Filter-Based Disturbance Observers for Exoskeletons", "comment": null, "summary": "The nominal performance of mechanical systems is often degraded by unknown\ndisturbances. A two-degree-of-freedom control structure can decouple nominal\nperformance from disturbance rejection. However, perfect disturbance rejection\nis unattainable when the disturbance dynamic is unknown. In this work, we\nreveal an inherent trade-off in disturbance estimation subject to tracking\nspeed and tracking uncertainty. Then, we propose two novel methods to enhance\ndisturbance estimation: an interacting multiple model extended Kalman\nfilter-based disturbance observer and a multi-kernel correntropy extended\nKalman filter-based disturbance observer. Experiments on an exoskeleton verify\nthat the proposed two methods improve the tracking accuracy $36.3\\%$ and\n$16.2\\%$ in hip joint error, and $46.3\\%$ and $24.4\\%$ in knee joint error,\nrespectively, compared to the extended Kalman filter-based disturbance\nobserver, in a time-varying interaction force scenario, demonstrating the\nsuperiority of the proposed method."}
{"id": "2510.15547", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.SY", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15547", "abs": "https://arxiv.org/abs/2510.15547", "authors": ["Usman Ali", "Ali Zia", "Waqas Ali", "Umer Ramzan", "Abdul Rehman", "Muhammad Tayyab Chaudhry", "Wei Xiang"], "title": "Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors", "comment": "Submitted to IEEE Sensors Journal", "summary": "Reliable induction motor (IM) fault diagnosis is vital for industrial safety\nand operational continuity, mitigating costly unplanned downtime. Conventional\napproaches often struggle to capture complex multimodal signal relationships,\nare constrained to unimodal data or single fault types, and exhibit performance\ndegradation under noisy or cross-domain conditions. This paper proposes the\nMultimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified\nframework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is\nthe first to integrate contrastive learning within a hypergraph topology\nspecifically designed for multimodal sensor fusion, enabling the joint\nmodelling of intra- and inter-modal dependencies and enhancing generalisation\nbeyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis\nof bearing, stator, and rotor faults, addressing the engineering need for\nconsolidated di- agnostic capabilities. Evaluated on three real-world\nbenchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain\ngeneralisation and resilience to noise, demonstrating its suitability for\nreal-world deployment. An ablation study validates the contribution of each\ncomponent. MM-HCAN provides a scalable and robust solution for comprehensive\nmulti-fault diagnosis, supporting predictive maintenance and extended asset\nlongevity in industrial environments."}
{"id": "2510.15560", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.15560", "abs": "https://arxiv.org/abs/2510.15560", "authors": ["Jiayuan Bai", "Xuan-guang Pan", "Chongyang Tao", "Shuai Ma"], "title": "JudgeSQL: Reasoning over SQL Candidates with Weighted Consensus Tournament", "comment": "13 pages", "summary": "Text-to-SQL is a pivotal task that bridges natural language understanding and\nstructured data access, yet it remains fundamentally challenging due to\nsemantic ambiguity and complex compositional reasoning. While large language\nmodels (LLMs) have greatly advanced SQL generation though prompting, supervised\nfinetuning and reinforced tuning, the shift toward test-time scaling exposes a\nnew bottleneck: selecting the correct query from a diverse candidate pool.\nExisting selection approaches, such as self-consistency or best-of-$N$\ndecoding, provide only shallow signals, making them prone to inconsistent\nscoring, fragile reasoning chains, and a failure to capture fine-grained\nsemantic distinctions between closely related SQL candidates. To this end, we\nintroduce JudgeSQL, a principled framework that redefines SQL candidate\nselection through structured reasoning and weighted consensus tournament\nmechanism. JudgeSQL develops a reasoning-based SQL judge model that distills\nreasoning traces with reinforcement learning guided by verifiable rewards,\nenabling accurate and interpretable judgments. Building on this, a weighted\nconsensus tournament integrates explicit reasoning preferences with implicit\ngenerator confidence, yielding selections that are both more reliable and more\nefficient. Extensive experiments on the BIRD benchmark demonstrate that\nJudgeSQL exhibits superior SQL judgment capabilities and good cross-scale\ngeneralization and robustness to generator capacity."}
{"id": "2510.15573", "categories": ["eess.SY", "cs.MA", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15573", "abs": "https://arxiv.org/abs/2510.15573", "authors": ["Jianguo Chen", "Zhengqin Liu", "Jinlong Lei", "Peng Yi", "Yiguang Hong", "Hong Chen"], "title": "Hypergame-based Cognition Modeling and Intention Interpretation for Human-Driven Vehicles in Connected Mixed Traffic", "comment": null, "summary": "With the practical implementation of connected and autonomous vehicles\n(CAVs), the traffic system is expected to remain a mix of CAVs and human-driven\nvehicles (HVs) for the foreseeable future. To enhance safety and traffic\nefficiency, the trajectory planning strategies of CAVs must account for the\ninfluence of HVs, necessitating accurate HV trajectory prediction. Current\nresearch often assumes that human drivers have perfect knowledge of all\nvehicles' objectives, an unrealistic premise. This paper bridges the gap by\nleveraging hypergame theory to account for cognitive and perception limitations\nin HVs. We model human bounded rationality without assuming them to be merely\npassive followers and propose a hierarchical cognition modeling framework that\ncaptures cognitive relationships among vehicles. We further analyze the\ncognitive stability of the system, proving that the strategy profile where all\nvehicles adopt cognitively equilibrium strategies constitutes a hyper Nash\nequilibrium when CAVs accurately learn HV parameters. To achieve this, we\ndevelop an inverse learning algorithm for distributed intention interpretation\nvia vehicle-to-everything (V2X) communication, which extends the framework to\nboth offline and online scenarios. Additionally, we introduce a distributed\ntrajectory prediction and planning approach for CAVs, leveraging the learned\nparameters in real time. Simulations in highway lane-changing scenarios\ndemonstrate the proposed method's accuracy in parameter learning, robustness to\nnoisy trajectory observations, and safety in HV trajectory prediction. The\nresults validate the effectiveness of our method in both offline and online\nimplementations."}
{"id": "2510.15591", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.15591", "abs": "https://arxiv.org/abs/2510.15591", "authors": ["Lavanya Umapathy", "Patricia M Johnson", "Tarun Dutt", "Angela Tong", "Madhur Nayan", "Hersh Chandarana", "Daniel K Sodickson"], "title": "Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment", "comment": "18 pages, 5 figures, 1 table", "summary": "Temporal context in medicine is valuable in assessing key changes in patient\nhealth over time. We developed a machine learning framework to integrate\ndiverse context from prior visits to improve health monitoring, especially when\nprior visits are limited and their frequency is variable. Our model first\nestimates initial risk of disease using medical data from the most recent\npatient visit, then refines this assessment using information digested from\npreviously collected imaging and/or clinical biomarkers. We applied our\nframework to prostate cancer (PCa) risk prediction using data from a large\npopulation (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931\nblood tests) collected over nearly a decade. For predictions of the risk of\nclinically significant PCa at the time of the visit, integrating prior context\ndirectly converted false positives to true negatives, increasing overall\nspecificity while preserving high sensitivity. False positive rates were\nreduced progressively from 51% to 33% when integrating information from up to\nthree prior imaging examinations, as compared to using data from a single\nvisit, and were further reduced to 24% when also including additional context\nfrom prior clinical data. For predicting the risk of PCa within five years of\nthe visit, incorporating prior context reduced false positive rates still\nfurther (64% to 9%). Our findings show that information collected over time\nprovides relevant context to enhance the specificity of medical risk\nprediction. For a wide range of progressive conditions, sufficient reduction of\nfalse positive rates using context could offer a pathway to expand longitudinal\nhealth monitoring programs to large populations with comparatively low baseline\nrisk of disease, leading to earlier detection and improved health outcomes."}
{"id": "2510.15598", "categories": ["eess.SY", "cs.SY", "93B07, 93C05, 15A66"], "pdf": "https://arxiv.org/pdf/2510.15598", "abs": "https://arxiv.org/abs/2510.15598", "authors": ["Michael Sebek"], "title": "Observer Design over Hypercomplex Quaternions", "comment": "Accepted for presentation at the 24th European Control Conference\n  (ECC 2026), Reykjavik, Iceland. This work was co-funded by the European Union\n  under the project ROBOPROX (reg. no. CZ.02.01.01/00/22 008/0004590)", "summary": "We develop observer design over hypercomplex quaternions in a\ncharacteristic-polynomial-free framework. Using the standard right-module\nconvention, we derive a right observable companion form and its companion\npolynomial that encodes error dynamics via right-eigenvalue similarity classes.\nThe design mirrors the real/complex case - coefficient updates in companion\ncoordinates, followed by a similarity back - yet avoids determinants,\ncharacteristic/minimal polynomials, and Cayley-Hamilton identities that do not\ntransfer to quaternions. We also give an Ackermann-type construction for the\nimportant case of closed-loop companion polynomials with real coefficients,\nensuring similarity-equivariant evaluation. The results yield simple recipes\nfor full-order observers directly over quaternions, clarify the role of right\nspectra and their similarity classes, and pinpoint when classical one-shot\nformulas remain valid. Numerical examples illustrate the method and advantages\nover vectorized or complex-adjoint surrogates."}
{"id": "2510.15600", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.15600", "abs": "https://arxiv.org/abs/2510.15600", "authors": ["Haoran Sun", "Yankai Jiang", "Zhenyu Tang", "Yaning Pan", "Shuang Gu", "Zekai Lin", "Lilong Wang", "Wenjie Lou", "Lei Liu", "Lei Bai", "Xiaosong Wang"], "title": "Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism", "comment": null, "summary": "The foundation of reproducible science lies in protocols that are precise,\nlogically ordered, and executable. The autonomous generation of these protocols\nthrough natural language queries could greatly improve the efficiency of the\nreproduction process. However, current leading large language models (LLMs)\noften generate incomplete or inconsistent protocols, limiting their utility. To\naddress this limitation, we first introduce SciRecipe, a large-scale dataset of\nover 12K structured protocols spanning 27 biological subfields and encompassing\nboth comprehension and problem-solving tasks. To further improve protocol\ngeneration, we propose the \"Sketch-and-Fill\" paradigm, which separates\nanalysis, structuring, and expression to ensure each step is explicit and\nverifiable. Complementing this, the structured component-based reward mechanism\nevaluates step granularity, action order, and semantic fidelity, aligning model\noptimization with experimental reliability. Building on these components, we\ndevelop Thoth, trained through a staged Knowledge-to-Action process that\nprogresses from knowledge acquisition to operational reasoning and ultimately\nto robust, executable protocol generation. Across multiple benchmarks, Thoth\nconsistently surpasses both proprietary and open-source LLMs, achieving\nsignificant improvements in step alignment, logical sequencing, and semantic\naccuracy. Our approach paves the way for reliable scientific assistants that\nbridge knowledge with experimental execution. All data, code, and models will\nbe released publicly."}
{"id": "2510.15613", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15613", "abs": "https://arxiv.org/abs/2510.15613", "authors": ["Clément Moureau", "Thomas Stegen", "Mevludin Glavic", "Bertrand Cornélusse"], "title": "A Predictive Flexibility Aggregation Method for Low Voltage Distribution System Control", "comment": "8 pages, 6 figures", "summary": "This paper presents a predictive control strategy to manage low-voltage\ndistribution systems. The proposed approach relies on an aggregate of the\nflexibility at the residential unit level into a three-dimensional chart that\nrepresents the injected active and reactive power, and the flexibility cost.\nFirst, this method solves a multiparametric optimization problem offline at the\nresidential unit level to aggregate the flexibility of the assets. Then, a\nsemi-explicit model predictive control problem is solved to account for\nforecasts. By combining the results of these problems with measurements, the\nmethod generates the desired flexibility chart. The proposed approach is\ncompatible with realtime control requirements, as heavy computations are\nperformed offline locally, making it naturally parallelizable. By linking\nrealtime flexibility assessment with energy scheduling, our approach enables\nefficient, low-cost, and privacy-preserving management of low-voltage\ndistribution systems. We validate this method on a low-voltage network of 5\nbuses by comparing it with an ideal technique."}
{"id": "2510.15624", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.15624", "abs": "https://arxiv.org/abs/2510.15624", "authors": ["Ed Li", "Junyu Ren", "Xintian Pan", "Cat Yan", "Chuanhao Li", "Dirk Bergemann", "Zhuoran Yang"], "title": "Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation", "comment": "37 pages, 5 figures. Code: https://github.com/ltjed/freephdlabor", "summary": "The automation of scientific discovery represents a critical milestone in\nArtificial Intelligence (AI) research. However, existing agentic systems for\nscience suffer from two fundamental limitations: rigid, pre-programmed\nworkflows that cannot adapt to intermediate findings, and inadequate context\nmanagement that hinders long-horizon research. We present\n\\texttt{freephdlabor}, an open-source multiagent framework featuring\n\\textit{fully dynamic workflows} determined by real-time agent reasoning and a\n\\coloremph{\\textit{modular architecture}} enabling seamless customization --\nusers can modify, add, or remove agents to address domain-specific\nrequirements. The framework provides comprehensive infrastructure including\n\\textit{automatic context compaction}, \\textit{workspace-based communication}\nto prevent information degradation, \\textit{memory persistence} across\nsessions, and \\textit{non-blocking human intervention} mechanisms. These\nfeatures collectively transform automated research from isolated, single-run\nattempts into \\textit{continual research programs} that build systematically on\nprior explorations and incorporate human feedback. By providing both the\narchitectural principles and practical implementation for building customizable\nco-scientist systems, this work aims to facilitate broader adoption of\nautomated research across scientific domains, enabling practitioners to deploy\ninteractive multiagent systems that autonomously conduct end-to-end research --\nfrom ideation through experimentation to publication-ready manuscripts."}
{"id": "2510.15626", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15626", "abs": "https://arxiv.org/abs/2510.15626", "authors": ["Hongyu Zhou", "Xiaoyu Zhang", "Vasileios Tzoumas"], "title": "Adaptive Legged Locomotion via Online Learning for Model Predictive Control", "comment": "9 pages", "summary": "We provide an algorithm for adaptive legged locomotion via online learning\nand model predictive control. The algorithm is composed of two interacting\nmodules: model predictive control (MPC) and online learning of residual\ndynamics. The residual dynamics can represent modeling errors and external\ndisturbances. We are motivated by the future of autonomy where quadrupeds will\nautonomously perform complex tasks despite real-world unknown uncertainty, such\nas unknown payload and uneven terrains. The algorithm uses random Fourier\nfeatures to approximate the residual dynamics in reproducing kernel Hilbert\nspaces. Then, it employs MPC based on the current learned model of the residual\ndynamics. The model is updated online in a self-supervised manner using least\nsquares based on the data collected while controlling the quadruped. The\nalgorithm enjoys sublinear \\textit{dynamic regret}, defined as the\nsuboptimality against an optimal clairvoyant controller that knows how the\nresidual dynamics. We validate our algorithm in Gazebo and MuJoCo simulations,\nwhere the quadruped aims to track reference trajectories. The Gazebo\nsimulations include constant unknown external forces up to $12\\boldsymbol{g}$,\nwhere $\\boldsymbol{g}$ is the gravity vector, in flat terrain, slope terrain\nwith $20\\degree$ inclination, and rough terrain with $0.25m$ height variation.\nThe MuJoCo simulations include time-varying unknown disturbances with payload\nup to $8~kg$ and time-varying ground friction coefficients in flat terrain."}
{"id": "2510.15638", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15638", "abs": "https://arxiv.org/abs/2510.15638", "authors": ["Jared K. Lepora", "Haoran Li", "Efi Psomopoulou", "Nathan F. Lepora"], "title": "Educational SoftHand-A: Building an Anthropomorphic Hand with Soft Synergies using LEGO MINDSTORMS", "comment": "6 pages. Accepted at IROS 2025", "summary": "This paper introduces an anthropomorphic robot hand built entirely using LEGO\nMINDSTORMS: the Educational SoftHand-A, a tendon-driven, highly-underactuated\nrobot hand based on the Pisa/IIT SoftHand and related hands. To be suitable for\nan educational context, the design is constrained to use only standard LEGO\npieces with tests using common equipment available at home. The hand features\ndual motors driving an agonist/antagonist opposing pair of tendons on each\nfinger, which are shown to result in reactive fine control. The finger motions\nare synchonized through soft synergies, implemented with a differential\nmechanism using clutch gears. Altogether, this design results in an\nanthropomorphic hand that can adaptively grasp a broad range of objects using a\nsimple actuation and control mechanism. Since the hand can be constructed from\nLEGO pieces and uses state-of-the-art design concepts for robotic hands, it has\nthe potential to educate and inspire children to learn about the frontiers of\nmodern robotics."}
{"id": "2510.15639", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15639", "abs": "https://arxiv.org/abs/2510.15639", "authors": ["Manuel J. Fernandez", "Alejandro Suarez", "Anibal Ollero", "Matteo Fumagalli"], "title": "Integration of a Variable Stiffness Link for Long-Reach Aerial Manipulation", "comment": null, "summary": "This paper presents the integration of a Variable Stiffness Link (VSL) for\nlong-reach aerial manipulation, enabling adaptable mechanical coupling between\nan aerial multirotor platform and a dual-arm manipulator. Conventional\nlong-reach manipulation systems rely on rigid or cable connections, which limit\nprecision or transmit disturbances to the aerial vehicle. The proposed VSL\nintroduces an adjustable stiffness mechanism that allows the link to behave\neither as a flexible rope or as a rigid rod, depending on task requirements.\n  The system is mounted on a quadrotor equipped with the LiCAS dual-arm\nmanipulator and evaluated through teleoperated experiments, involving external\ndisturbances and parcel transportation tasks. Results demonstrate that varying\nthe link stiffness significantly modifies the dynamic interaction between the\nUAV and the payload. The flexible configuration attenuates external impacts and\naerodynamic perturbations, while the rigid configuration improves positional\naccuracy during manipulation phases.\n  These results confirm that VSL enhances versatility and safety, providing a\ncontrollable trade-off between compliance and precision. Future work will focus\non autonomous stiffness regulation, multi-rope configurations, cooperative\naerial manipulation and user studies to further assess its impact on\nteleoperated and semi-autonomous aerial tasks."}
{"id": "2510.15668", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15668", "abs": "https://arxiv.org/abs/2510.15668", "authors": ["Yameng Zhang", "Dianye Huang", "Max Q. -H. Meng", "Nassir Navab", "Zhongliang Jiang"], "title": "Freehand 3D Ultrasound Imaging: Sim-in-the-Loop Probe Pose Optimization via Visual Servoing", "comment": null, "summary": "Freehand 3D ultrasound (US) imaging using conventional 2D probes offers\nflexibility and accessibility for diverse clinical applications but faces\nchallenges in accurate probe pose estimation. Traditional methods depend on\ncostly tracking systems, while neural network-based methods struggle with image\nnoise and error accumulation, compromising reconstruction precision. We propose\na cost-effective and versatile solution that leverages lightweight cameras and\nvisual servoing in simulated environments for precise 3D US imaging. These\ncameras capture visual feedback from a textured planar workspace. To counter\nocclusions and lighting issues, we introduce an image restoration method that\nreconstructs occluded regions by matching surrounding texture patterns. For\npose estimation, we develop a simulation-in-the-loop approach, which replicates\nthe system setup in simulation and iteratively minimizes pose errors between\nsimulated and real-world observations. A visual servoing controller refines the\nalignment of camera views, improving translational estimation by optimizing\nimage alignment. Validations on a soft vascular phantom, a 3D-printed conical\nmodel, and a human arm demonstrate the robustness and accuracy of our approach,\nwith Hausdorff distances to the reference reconstructions of 0.359 mm, 1.171\nmm, and 0.858 mm, respectively. These results confirm the method's potential\nfor reliable freehand 3D US reconstruction."}
{"id": "2510.15679", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15679", "abs": "https://arxiv.org/abs/2510.15679", "authors": ["Yuhong Cao", "Yizhuo Wang", "Jingsong Liang", "Shuhao Liao", "Yifeng Zhang", "Peizhuo Li", "Guillaume Sartoretti"], "title": "HEADER: Hierarchical Robot Exploration via Attention-Based Deep Reinforcement Learning with Expert-Guided Reward", "comment": null, "summary": "This work pushes the boundaries of learning-based methods in autonomous robot\nexploration in terms of environmental scale and exploration efficiency. We\npresent HEADER, an attention-based reinforcement learning approach with\nhierarchical graphs for efficient exploration in large-scale environments.\nHEADER follows existing conventional methods to construct hierarchical\nrepresentations for the robot belief/map, but further designs a novel\ncommunity-based algorithm to construct and update a global graph, which remains\nfully incremental, shape-adaptive, and operates with linear complexity.\nBuilding upon attention-based networks, our planner finely reasons about the\nnearby belief within the local range while coarsely leveraging distant\ninformation at the global scale, enabling next-best-viewpoint decisions that\nconsider multi-scale spatial dependencies. Beyond novel map representation, we\nintroduce a parameter-free privileged reward that significantly improves model\nperformance and produces near-optimal exploration behaviors, by avoiding\ntraining objective bias caused by handcrafted reward shaping. In simulated\nchallenging, large-scale exploration scenarios, HEADER demonstrates better\nscalability than most existing learning and non-learning methods, while\nachieving a significant improvement in exploration efficiency (up to 20%) over\nstate-of-the-art baselines. We also deploy HEADER on hardware and validate it\nin complex, large-scale real-life scenarios, including a 300m*230m campus\nenvironment."}
{"id": "2510.15686", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15686", "abs": "https://arxiv.org/abs/2510.15686", "authors": ["Taehyeon Kim", "Vishnunandan L. N. Venkatesh", "Byung-Cheol Min"], "title": "Few-Shot Demonstration-Driven Task Coordination and Trajectory Execution for Multi-Robot Systems", "comment": null, "summary": "In this paper, we propose a novel few-shot learning framework for multi-robot\nsystems that integrate both spatial and temporal elements: Few-Shot\nDemonstration-Driven Task Coordination and Trajectory Execution (DDACE). Our\napproach leverages temporal graph networks for learning task-agnostic temporal\nsequencing and Gaussian Processes for spatial trajectory modeling, ensuring\nmodularity and generalization across various tasks. By decoupling temporal and\nspatial aspects, DDACE requires only a small number of demonstrations,\nsignificantly reducing data requirements compared to traditional learning from\ndemonstration approaches. To validate our proposed framework, we conducted\nextensive experiments in task environments designed to assess various aspects\nof multi-robot coordination-such as multi-sequence execution, multi-action\ndynamics, complex trajectory generation, and heterogeneous configurations. The\nexperimental results demonstrate that our approach successfully achieves task\nexecution under few-shot learning conditions and generalizes effectively across\ndynamic and diverse settings. This work underscores the potential of modular\narchitectures in enhancing the practicality and scalability of multi-robot\nsystems in real-world applications. Additional materials are available at\nhttps://sites.google.com/view/ddace."}
{"id": "2510.15695", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15695", "abs": "https://arxiv.org/abs/2510.15695", "authors": ["Sheng Wang", "Muhammad Maladoh Bah"], "title": "Cross-border offshore hydrogen trade and carbon mitigation for Europe's net zero transition", "comment": null, "summary": "European countries are ambitious in both the net-zero transition and offshore\nenergy resource development. The Irish and UK governments announced their\ncommitments to offshore wind capacities - 37 and 125 GW, respectively, in 2050,\nmore than two times higher than their projected power demands. While other\ncontinental countries, such as Germany, are calling for cleaner fuel resources.\nExporting surplus offshore green hydrogen and bridging supply and demand could\nbe pivotal in carbon emission mitigation for Europe. Yet, the potentials of\nthese Island countries, are usually underestimated. This paper developed a\nbottom-up method to investigate the role of offshore hydrogen from Ireland and\nthe UK in the decarbonisation of the entire Europe. We evaluate the future\nhydrogen/ammonia trading and the contributions of each country in carbon\nemission mitigation, considering their relative cost-competitiveness in\noffshore hydrogen production, domestic hourly power and gas system operation,\nand international shipping costs. Results indicate that the offshore green\nhydrogen could reduce 175.16 Mt/year of carbon dioxide emissions in Europe. The\nUK will be the largest hydrogen supplier from 2030 to 2040, while surpassed by\nIreland in 2050, with 161 TWh of hydrogen exports to France and Spain. The\noffshore green hydrogen can contribute to 175.16 Mt of annual carbon dioxide\nemission reductions in total. This general flow of hydrogen from the West to\nthe East not only facilitates Europe's net-zero progress, but also reshapes the\nenergy supply structure and helps to ensure energy security across the European\ncontinent."}
{"id": "2510.15707", "categories": ["eess.SY", "cs.SY", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.15707", "abs": "https://arxiv.org/abs/2510.15707", "authors": ["Martín de Frutos", "Laura Botero-Bolívar", "Esteban Ferrer"], "title": "Mitigating Underwater Noise from Offshore Wind Turbines via Individual Pitch Control", "comment": null, "summary": "This paper proposes a pitch control strategy to mitigate the underwater\nacoustic footprint of offshore wind turbines, a measure that will soon become\nnecessary to minimize impacts on marine life, which rely on sound for\ncommunication, navigation, and survival. First, we quantify the underwater\nacoustic signature of blade-generated aerodynamic noise from three reference\nturbines, the NREL 5 MW, DTU 10 MW, and IEA 22 MW, using coupling blade element\nmomentum and coupled air-water acoustic propagation modeling. Second, we\npropose and implement an open-loop individual pitch control (IPC) strategy that\nmodulates the pitch of the blade at the blade passing frequency to attenuate\nthe overall sound pressure level (OSPL) and the amplitude modulation (AM) of\nthe transmitted noise. Third, we benchmark IPC performance against conventional\npitch schemes. The results indicate that up to 5 dB reductions in OSPL and a\ndecrease in AM depth 20% can be achieved with a pitch variation of\n$\\Delta\\theta\\approx 5^\\circ$, with small losses (5-10%) in energy capture.\nThese findings highlight a previously underappreciated noise pathway and\ndemonstrate that targeted blade-pitch modulation can mitigate its impact."}
{"id": "2510.15708", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15708", "abs": "https://arxiv.org/abs/2510.15708", "authors": ["Thomas Bernard", "François Grondin", "Jean-Michel Lavoie"], "title": "Sugar Shack 4.0: Practical Demonstration of an IIoT-Based Event-Driven Automation System", "comment": "10 pages, 15 figures", "summary": "This paper presents a practical alternative to\nprogrammable-logic-controller-centric automation by implementing an\nevent-driven architecture built with industrial Internet of Things tools. A\nlayered design on a local edge server (i) abstracts actuators, (ii) enforces\nmutual exclusion of shared physical resources through an interlock with\npriority queueing, (iii) composes deterministic singular operations, and (iv)\norchestrates complete workflows as state machines in Node-RED, with\ncommunication over MQTT. The device layer uses low-cost ESP32-based gateways to\ninterface sensors and actuators, while all automation logic is offloaded to the\nserver side. As part of a larger project involving the first\nscientifically-documented integration of Industry 4.0 technologies in a maple\nsyrup boiling center, this work demonstrates the deployment of the proposed\nsystem as a case-study. Evaluation over an entire production season shows\nmedian message time of flight around one tenth of a second, command\nissuance-to-motion latencies of about two to three seconds, and command\ncompletion near six seconds dominated by actuator mechanics; operation runtimes\nspan tens of seconds to minutes. These results indicate that network and\norchestration overheads are negligible relative to process dynamics, enabling\nmodular, distributed control without compromising determinism or fault\nisolation. The approach reduces material and integration effort, supports\nportable containerized deployment, and naturally enables an edge/cloud split in\nwhich persistence and analytics are offloaded while automation remains at the\nedge."}
{"id": "2510.15716", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15716", "abs": "https://arxiv.org/abs/2510.15716", "authors": ["Keertana Chidambaram", "Karthik Vinary Seetharaman", "Vasilis Syrgkanis"], "title": "Direct Preference Optimization with Unobserved Preference Heterogeneity: The Necessity of Ternary Preferences", "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) has become central to\naligning large language models with human values, typically by first learning a\nreward model from preference data which is then used to update the model with\nreinforcement learning. Recent alternatives such as Direct Preference\nOptimization (DPO) simplify this pipeline by directly optimizing on\npreferences. However, both approaches often assume uniform annotator\npreferences and rely on binary comparisons, overlooking two key limitations:\nthe diversity of human evaluators and the limitations of pairwise feedback. In\nthis work, we address both these issues. First, we connect preference learning\nin RLHF with the econometrics literature and show that binary comparisons are\ninsufficient for identifying latent user preferences from finite user data and\ninfinite users, while (even incomplete) rankings over three or more responses\nensure identifiability. Second, we introduce methods to incorporate\nheterogeneous preferences into alignment algorithms. We develop an\nExpectation-Maximization adaptation of DPO that discovers latent annotator\ntypes and trains a mixture of LLMs accordingly. Then we propose an aggregation\nalgorithm using a min-max regret fairness criterion to produce a single\ngenerative policy with equitable performance guarantees. Together, these\ncontributions establish a theoretical and algorithmic framework for fairness\nand personalization for diverse users in generative model alignment."}
{"id": "2510.15727", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.15727", "abs": "https://arxiv.org/abs/2510.15727", "authors": ["Sai Yashwant", "Anurag Dubey", "Praneeth Paikray", "Gantala Thulsiram"], "title": "Invoice Information Extraction: Methods and Performance Evaluation", "comment": null, "summary": "This paper presents methods for extracting structured information from\ninvoice documents and proposes a set of evaluation metrics (EM) to assess the\naccuracy of the extracted data against annotated ground truth. The approach\ninvolves pre-processing scanned or digital invoices, applying Docling and\nLlamaCloud Services to identify and extract key fields such as invoice number,\ndate, total amount, and vendor details. To ensure the reliability of the\nextraction process, we establish a robust evaluation framework comprising\nfield-level precision, consistency check failures, and exact match accuracy.\nThe proposed metrics provide a standardized way to compare different extraction\nmethods and highlight strengths and weaknesses in field-specific performance."}
{"id": "2510.15739", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.15739", "abs": "https://arxiv.org/abs/2510.15739", "authors": ["Lorenzo Satta Chiris", "Ayush Mishra"], "title": "AURA: An Agent Autonomy Risk Assessment Framework", "comment": "10 pages, 2 figures. Submitted for open-access preprint on arXiv.\n  Based on the AAMAS 2026 paper template", "summary": "As autonomous agentic AI systems see increasing adoption across\norganisations, persistent challenges in alignment, governance, and risk\nmanagement threaten to impede deployment at scale. We present AURA (Agent\naUtonomy Risk Assessment), a unified framework designed to detect, quantify,\nand mitigate risks arising from agentic AI. Building on recent research and\npractical deployments, AURA introduces a gamma-based risk scoring methodology\nthat balances risk assessment accuracy with computational efficiency and\npractical considerations. AURA provides an interactive process to score,\nevaluate and mitigate the risks of running one or multiple AI Agents,\nsynchronously or asynchronously (autonomously). The framework is engineered for\nHuman-in-the-Loop (HITL) oversight and presents Agent-to-Human (A2H)\ncommunication mechanisms, allowing for seamless integration with agentic\nsystems for autonomous self-assessment, rendering it interoperable with\nestablished protocols (MCP and A2A) and tools. AURA supports a responsible and\ntransparent adoption of agentic AI and provides robust risk detection and\nmitigation while balancing computational resources, positioning it as a\ncritical enabler for large-scale, governable agentic AI in enterprise\nenvironments."}
{"id": "2510.15740", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15740", "abs": "https://arxiv.org/abs/2510.15740", "authors": ["Geon Roh", "Jip Kim"], "title": "Integrating Conductor Health into Dynamic Line Rating and Unit Commitment under Uncertainty", "comment": null, "summary": "Dynamic line rating (DLR) enables greater utilization of existing\ntransmission lines by leveraging real-time weather data. However, the elevated\ntemperature operation (ETO) of conductors under DLR is often overlooked,\ndespite its long-term impact on conductor health. This paper addresses this\nissue by 1) quantifying depreciation costs associated with ETO and 2) proposing\na Conductor Health-Aware Unit Commitment (CHA-UC) that internalizes these costs\nin operational decisions. The CHA-UC incorporates a robust linear approximation\nof conductor temperature and integration of expected depreciation costs due to\nhourly ETO into the objective function. Case studies on the Texas 123-bus\nbackbone test system using NOAA weather data demonstrate that the proposed\nCHA-UC model reduces the total cost by 0.8% and renewable curtailment by\n84%compared to static line rating (SLR), while conventional DLR operation\nwithout risk consideration resulted in higher costs due to excessive ETO.\nFurther analysis of the commitment decisions and the line temperature\nstatistics confirms that the CHA-UC achieves safer line flows by shifting\ngenerator commitments. Finally, we examine the emergent correlation between\nwind generation and DLR forecast errors, and show that CHA-UC adaptively\nmanages this effect by relaxing flows for risk-hedging conditions while\ntightening flows for risk-amplifying ones."}
{"id": "2510.15748", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15748", "abs": "https://arxiv.org/abs/2510.15748", "authors": ["Minlin Zeng", "Zhipeng Zhou", "Yang Qiu", "Zhiqi Shen"], "title": "Towards Relaxed Multimodal Inputs for Gait-based Parkinson's Disease Assessment", "comment": null, "summary": "Parkinson's disease assessment has garnered growing interest in recent years,\nparticularly with the advent of sensor data and machine learning techniques.\nAmong these, multimodal approaches have demonstrated strong performance by\neffectively integrating complementary information from various data sources.\nHowever, two major limitations hinder their practical application: (1) the need\nto synchronize all modalities during training, and (2) the dependence on all\nmodalities during inference. To address these issues, we propose the first\nParkinson's assessment system that formulates multimodal learning as a\nmulti-objective optimization (MOO) problem. This not only allows for more\nflexible modality requirements during both training and inference, but also\nhandles modality collapse issue during multimodal information fusion. In\naddition, to mitigate the imbalance within individual modalities, we introduce\na margin-based class rebalancing strategy to enhance category learning. We\nconduct extensive experiments on three public datasets under both synchronous\nand asynchronous settings. The results show that our framework-Towards Relaxed\nInPuts (TRIP)-achieves state-of-the-art performance, outperforming the best\nbaselines by 16.48, 6.89, and 11.55 percentage points in the asynchronous\nsetting, and by 4.86 and 2.30 percentage points in the synchronous setting,\nhighlighting its effectiveness and adaptability."}
{"id": "2510.15769", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.15769", "abs": "https://arxiv.org/abs/2510.15769", "authors": ["Allen Daniel Sunny"], "title": "Preliminary Quantitative Study on Explainability and Trust in AI Systems", "comment": "8 pages, 3 figures, 2 appendices. Quantitative user study on AI\n  explainability and trust. Preprint, 2025", "summary": "Large-scale AI models such as GPT-4 have accelerated the deployment of\nartificial intelligence across critical domains including law, healthcare, and\nfinance, raising urgent questions about trust and transparency. This study\ninvestigates the relationship between explainability and user trust in AI\nsystems through a quantitative experimental design. Using an interactive,\nweb-based loan approval simulation, we compare how different types of\nexplanations, ranging from basic feature importance to interactive\ncounterfactuals influence perceived trust. Results suggest that interactivity\nenhances both user engagement and confidence, and that the clarity and\nrelevance of explanations are key determinants of trust. These findings\ncontribute empirical evidence to the growing field of human-centered\nexplainable AI, highlighting measurable effects of explainability design on\nuser perception"}
{"id": "2510.15772", "categories": ["cs.AI", "I.2.0"], "pdf": "https://arxiv.org/pdf/2510.15772", "abs": "https://arxiv.org/abs/2510.15772", "authors": ["Richard M. Bailey"], "title": "Self-evolving expertise in complex non-verifiable subject domains: dialogue as implicit meta-RL", "comment": "50 pages, 4 figures", "summary": "So-called `wicked problems', those involving complex multi-dimensional\nsettings, non-verifiable outcomes, heterogeneous impacts and a lack of single\nobjectively correct answers, have plagued humans throughout history. Modern\nexamples include decisions over justice frameworks, solving environmental\npollution, planning for pandemic resilience and food security. The use of\nstate-of-the-art artificial intelligence systems (notably Large Language\nModel-based agents) collaborating with humans on solving such problems is being\nactively explored. While the abilities of LLMs can be improved by, for example,\nfine-tuning, hand-crafted system prompts and scaffolding with external tools,\nLLMs lack endogenous mechanisms to develop expertise through experience in such\nsettings. This work address this gap with Dialectica, a framework where agents\nengage in structured dialogue on defined topics, augmented by memory,\nself-reflection, and policy-constrained context editing. Formally, discussion\nis viewed as an implicit meta-reinforcement learning process. The\n`dialogue-trained' agents are evaluated post-hoc using judged pairwise\ncomparisons of elicited responses. Across two model architectures (locally run\nQwen3:30b and OpenAI's o4-mini) results show that enabling reflection-based\ncontext editing during discussion produces agents which dominate their baseline\ncounterparts on Elo scores, normalized Bradley-Terry-Davidson ability, and\nAlphaRank mass. The predicted signatures of learning are observed qualitatively\nin statement and reflection logs, where reflections identify weaknesses and\nreliably shape subsequent statements. Agreement between quantitative and\nqualitative evidence supports dialogue-driven context evolution as a practical\npath to targeted expertise amplification in open non-verifiable domains."}
{"id": "2510.15782", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15782", "abs": "https://arxiv.org/abs/2510.15782", "authors": ["Philip DiGiacomo", "Haoyang Wang", "Jinrui Fang", "Yan Leng", "W Michael Brode", "Ying Ding"], "title": "Demo: Guide-RAG: Evidence-Driven Corpus Curation for Retrieval-Augmented Generation in Long COVID", "comment": "Accepted to 39th Conference on Neural Information Processing Systems\n  (NeurIPS 2025) Workshop: The Second Workshop on GenAI for Health: Potential,\n  Trust, and Policy Compliance", "summary": "As AI chatbots gain adoption in clinical medicine, developing effective\nframeworks for complex, emerging diseases presents significant challenges. We\ndeveloped and evaluated six Retrieval-Augmented Generation (RAG) corpus\nconfigurations for Long COVID (LC) clinical question answering, ranging from\nexpert-curated sources to large-scale literature databases. Our evaluation\nemployed an LLM-as-a-judge framework across faithfulness, relevance, and\ncomprehensiveness metrics using LongCOVID-CQ, a novel dataset of\nexpert-generated clinical questions. Our RAG corpus configuration combining\nclinical guidelines with high-quality systematic reviews consistently\noutperformed both narrow single-guideline approaches and large-scale literature\ndatabases. Our findings suggest that for emerging diseases, retrieval grounded\nin curated secondary reviews provides an optimal balance between narrow\nconsensus documents and unfiltered primary literature, supporting clinical\ndecision-making while avoiding information overload and oversimplified\nguidance. We propose Guide-RAG, a chatbot system and accompanying evaluation\nframework that integrates both curated expert knowledge and comprehensive\nliterature databases to effectively answer LC clinical questions."}
{"id": "2510.15786", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15786", "abs": "https://arxiv.org/abs/2510.15786", "authors": ["Xinyue Xu", "Jieqiang Sun", "Jing", "Dai", "Siyuan Chen", "Lanjie Ma", "Ke Sun", "Bin Zhao", "Jianbo Yuan", "Yiwen Lu"], "title": "DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation", "comment": null, "summary": "We present DexCanvas, a large-scale hybrid real-synthetic human manipulation\ndataset containing 7,000 hours of dexterous hand-object interactions seeded\nfrom 70 hours of real human demonstrations, organized across 21 fundamental\nmanipulation types based on the Cutkosky taxonomy. Each entry combines\nsynchronized multi-view RGB-D, high-precision mocap with MANO hand parameters,\nand per-frame contact points with physically consistent force profiles. Our\nreal-to-sim pipeline uses reinforcement learning to train policies that control\nan actuated MANO hand in physics simulation, reproducing human demonstrations\nwhile discovering the underlying contact forces that generate the observed\nobject motion. DexCanvas is the first manipulation dataset to combine\nlarge-scale real demonstrations, systematic skill coverage based on established\ntaxonomies, and physics-validated contact annotations. The dataset can\nfacilitate research in robotic manipulation learning, contact-rich control, and\nskill transfer across different hand morphologies."}
{"id": "2510.15797", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15797", "abs": "https://arxiv.org/abs/2510.15797", "authors": ["Laszlo Gacsi", "Adam K. Kiss", "Tamas G. Molnar"], "title": "Braking within Barriers: Constructive Safety-Critical Control for Input-Constrained Vehicles via the Backup Set Method", "comment": "Submitted to the IEEE Transactions on Automation Science and\n  Engineering. 14 pages, 10 figures", "summary": "This paper presents a safety-critical control framework to maintain bounded\nlateral motions for vehicles braking on asymmetric surfaces. We synthesize a\nbrake controller that assists drivers and guarantees safety against excessive\nlateral motions (i.e., prevents the vehicle from spinning out) while minimizing\nthe stopping distance. We address this safety-critical control problem in the\npresence of input constraints, since braking forces are limited by the\navailable friction on the road. We use backup control barrier functions for\nsafe control design. As this approach requires the construction of a backup set\nand a backup controller, we propose a novel, systematic method to creating\nvalid backup set-backup controller pairs based on feedback linearization and\ncontinuous-time Lyapunov equations. We use simple examples to demonstrate our\nproposed safety-critical control method. Finally, we implement our approach on\na four-wheel vehicle model for braking on asymmetric surfaces and present\nsimulation results."}
{"id": "2510.15803", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.15803", "abs": "https://arxiv.org/abs/2510.15803", "authors": ["Zahra Arjmandi", "Gunho Sohn"], "title": "Dynamic Recalibration in LiDAR SLAM: Integrating AI and Geometric Methods with Real-Time Feedback Using INAF Fusion", "comment": "9 pages, 9 figures", "summary": "This paper presents a novel fusion technique for LiDAR Simultaneous\nLocalization and Mapping (SLAM), aimed at improving localization and 3D mapping\nusing LiDAR sensor. Our approach centers on the Inferred Attention Fusion\n(INAF) module, which integrates AI with geometric odometry. Utilizing the KITTI\ndataset's LiDAR data, INAF dynamically adjusts attention weights based on\nenvironmental feedback, enhancing the system's adaptability and measurement\naccuracy. This method advances the precision of both localization and 3D\nmapping, demonstrating the potential of our fusion technique to enhance\nautonomous navigation systems in complex scenarios."}
{"id": "2510.15805", "categories": ["cs.CY", "cs.HC", "cs.IT", "cs.SI", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.15805", "abs": "https://arxiv.org/abs/2510.15805", "authors": ["Bonnie Rushing", "Shouhuai Xu"], "title": "Quantifying the Engagement Effectiveness of Cyber Cognitive Attacks: A Behavioral Metric for Disinformation Campaigns", "comment": "University of Colorado Colorado Springs and Department of the Air\n  Force, US Air Force Academy. Disclaimer: The views expressed are those of the\n  author and do not reflect the official policy or position of the US Air Force\n  Academy, US Air Force, Department of Defense, or the US Government", "summary": "As disinformation-driven cognitive attacks become increasingly sophisticated,\nthe ability to quantify their impact is essential for advancing cybersecurity\ndefense strategies. This paper presents a novel framework for measuring the\nengagement effectiveness of cognitive attacks by introducing a weighted\ninteraction metric that accounts for both the type and volume of user\nengagement relative to the number of attacker-generated transmissions. Applying\nthis model to real-world disinformation campaigns across social media\nplatforms, we demonstrate how the metric captures not just reach but the\nbehavioral depth of user engagement. Our findings provide new insights into the\nbehavioral dynamics of cognitive warfare and offer actionable tools for\nresearchers and practitioners seeking to assess and counter the spread of\nmalicious influence online."}
{"id": "2510.15847", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15847", "abs": "https://arxiv.org/abs/2510.15847", "authors": ["Panos C. Papageorgiou", "Anastasios E. Giannopoulos", "Sotirios T. Spantideas"], "title": "Bio-inspired Microgrid Management based on Brain's Sensorimotor Gating", "comment": null, "summary": "Microgrids are emerging as key enablers of resilient, sustainable, and\nintelligent power systems, but they continue to face challenges in dynamic\ndisturbance handling, protection coordination, and uncertainty. Recent efforts\nhave explored Brain Emotional Learning (BEL) controllers as bio-inspired\nsolutions for microgrid control. Building on this growing trajectory, this\narticle introduces a new paradigm for Neuro-Microgrids, inspired by the brain's\nsensorimotor gating mechanisms, specifically the Prepulse Inhibition (PPI) and\nPrepulse Facilitation (PPF). Sensorimotor gating offers a biological model for\nselectively suppressing or amplifying responses depending on contextual\nrelevance. By mapping these principles onto the hierarchical control\narchitecture of microgrids, we propose a Sensorimotor Gating-Inspired\nNeuro-Microgrid (SG-NMG) framework. In this architecture, PPI-like control\ndecisions correspond to protective damping in primary and secondary management\nof microgrids, whereas PPF-like decisions correspond to adaptive amplification\nof corrective control actions. The framework is presented through analytical\nworkflow design, neuro-circuitry analogies, and integration with machine\nlearning methods. Finally, open challenges and research directions are\noutlined, including the mathematical modeling of gating, digital twin\nvalidation, and cross-disciplinary collaboration between neuroscience and\nindustrial power systems. The resulting paradigm highlights sensorimotor gating\nas a promising framework for designing self-protective, adaptive, and resilient\nmicrogrids."}
{"id": "2510.15862", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15862", "abs": "https://arxiv.org/abs/2510.15862", "authors": ["Yi Wan", "Jiuqi Wang", "Liam Li", "Jinsong Liu", "Ruihao Zhu", "Zheqing Zhu"], "title": "PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold", "comment": null, "summary": "Tool-augmented large language models (LLMs) are emerging as deep research\nagents, systems that decompose complex queries, retrieve external evidence, and\nsynthesize grounded responses. Yet current agents remain limited by shallow\nretrieval, weak alignment metrics, and brittle tool-use behavior. We introduce\nPokeeResearch-7B, a 7B-parameter deep research agent built under a unified\nreinforcement learning framework for robustness, alignment, and scalability.\nPokeeResearch-7B is trained by an annotation-free Reinforcement Learning from\nAI Feedback (RLAIF) framework to optimize policies using LLM-based reward\nsignals that capture factual accuracy, citation faithfulness, and instruction\nadherence. A chain-of-thought-driven multi-call reasoning scaffold further\nenhances robustness through self-verification and adaptive recovery from tool\nfailures. Among 10 popular deep research benchmarks, PokeeResearch-7B achieves\nstate-of-the-art performance among 7B-scale deep research agents. This\nhighlights that careful reinforcement learning and reasoning design can produce\nefficient, resilient, and research-grade AI agents. The model and inference\ncode is open-sourced under MIT license at\nhttps://github.com/Pokee-AI/PokeeResearchOSS."}
{"id": "2510.15121", "categories": ["econ.GN", "cs.CY", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15121", "abs": "https://arxiv.org/abs/2510.15121", "authors": ["Heather Liddell", "Beth Kelley", "Liz Wachs", "Alberta Carpenter", "Joe Cresko"], "title": "A physically extended EEIO framework for material efficiency assessment in United States manufacturing supply chains", "comment": "9 pages, 4 figures. Accepted manuscript, presented at the REMADE 2025\n  Circular Economy Conference & Tech Summit, Washington DC, April 10-11, 2025", "summary": "A physical assessment of material flows in an economy (e.g., material flow\nquantification) can support the development of sustainable decarbonization and\ncircularity strategies by providing the tangible physical context of industrial\nproduction quantities and supply chain relationships. However, completing a\nphysical assessment is challenging due to the scarcity of high-quality raw data\nand poor harmonization across industry classification systems used in data\nreporting. Here we describe a new physical extension for the U.S. Department of\nEnergy's (DOE's) EEIO for Industrial Decarbonization (EEIO-IDA) model, yielding\nan expanded EEIO model that is both physically and environmentally extended. In\nthe model framework, the U.S. economy is divided into goods-producing and\nservice-producing subsectors, and mass flows are quantified for each\ngoods-producing subsector using a combination of trade data (e.g., UN Comtrade)\nand physical production data (e.g., U.S. Geological Survey). Given that\nprimary-source production data are not available for all subsectors,\nprice-imputation and mass-balance assumptions are developed and used to\ncomplete the physical flows dataset with high-quality estimations. The\nresulting dataset, when integrated with the EEIO-IDA tool, enables the\nquantification of environmental impact intensity metrics on a mass basis (e.g.,\nCO$_2$eq/kg)) for each industrial subsector. This work is designed to align\nwith existing DOE frameworks and tools, including the EEIO-IDA tool, the DOE\nIndustrial Decarbonization Roadmap (2022), and Pathways for U.S. Industrial\nTransformations study (2025)."}
{"id": "2510.15200", "categories": ["econ.TH", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15200", "abs": "https://arxiv.org/abs/2510.15200", "authors": ["Fasheng Xu", "Xiaoyu Wang", "Wei Chen", "Karen Xie"], "title": "The Economics of AI Foundation Models: Openness, Competition, and Governance", "comment": null, "summary": "The strategic choice of model \"openness\" has become a defining issue for the\nfoundation model (FM) ecosystem. While this choice is intensely debated, its\nunderlying economic drivers remain underexplored. We construct a two-period\ngame-theoretic model to analyze how openness shapes competition in an AI value\nchain, featuring an incumbent developer, a downstream deployer, and an entrant\ndeveloper. Openness exerts a dual effect: it amplifies knowledge spillovers to\nthe entrant, but it also enhances the incumbent's advantage through a \"data\nflywheel effect,\" whereby greater user engagement today further lowers the\ndeployer's future fine-tuning cost. Our analysis reveals that the incumbent's\noptimal first-period openness is surprisingly non-monotonic in the strength of\nthe data flywheel effect. When the data flywheel effect is either weak or very\nstrong, the incumbent prefers a higher level of openness; however, for an\nintermediate range, it strategically restricts openness to impair the entrant's\nlearning. This dynamic gives rise to an \"openness trap,\" a critical policy\nparadox where transparency mandates can backfire by removing firms' strategic\nflexibility, reducing investment, and lowering welfare. We extend the model to\nshow that other common interventions can be similarly ineffective. Vertical\nintegration, for instance, only benefits the ecosystem when the data flywheel\neffect is strong enough to overcome the loss of a potentially more efficient\ncompetitor. Likewise, government subsidies intended to spur adoption can be\ncaptured entirely by the incumbent through strategic price and openness\nadjustments, leaving the rest of the value chain worse off. By modeling the\ndeveloper's strategic response to competitive and regulatory pressures, we\nprovide a robust framework for analyzing competition and designing effective\npolicy in the complex and rapidly evolving FM ecosystem."}
{"id": "2510.15307", "categories": ["econ.GN", "cs.GT", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.15307", "abs": "https://arxiv.org/abs/2510.15307", "authors": ["Venkat Ram Reddy Ganuthula", "Manish Kumar Singh"], "title": "Strategic Interactions in Academic Dishonesty: A Game-Theoretic Analysis of the Exam Script Swapping Mechanism", "comment": null, "summary": "This paper presents a novel game theoretic framework for analyzing academic\ndishonesty through the lens of a unique deterrent mechanism: forced exam script\nswapping between students caught copying. We model the strategic interactions\nbetween students as a non cooperative game with asymmetric information and\nexamine three base scenarios asymmetric preparation levels, mutual non\npreparation, and coordinated partial preparation. Our analysis reveals that the\nscript swapping punishment creates a stronger deterrent effect than traditional\npenalties by introducing strategic interdependence in outcomes. The Nash\nequilibrium analysis demonstrates that mutual preparation emerges as the\ndominant strategy. The framework provides insights for institutional policy\ndesign, suggesting that unconventional punishment mechanisms that create mutual\nvulnerability can be more effective than traditional individual penalties.\nFuture empirical validation and behavioral experiments are proposed to test the\nmodel predictions, including explorations of tapering off effects in punishment\nseverity over time."}
{"id": "2510.15487", "categories": ["stat.AP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15487", "abs": "https://arxiv.org/abs/2510.15487", "authors": ["Manit Mishra"], "title": "AI and analytics in sports: Leveraging BERTopic to map the past and chart the future", "comment": "32 pages, 5 figures, 1 table, accepted for presentation at Australia\n  and New Zealand Marketing Academy (ANZMAC) - 2025 Conference", "summary": "Purpose: The purpose of this study is to map the body of scholarly literature\nat the intersection of artificial intelligence (AI), analytics and sports and\nthereafter, leverage the insights generated to chart guideposts for future\nresearch. Design/methodology/approach: The study carries out systematic\nliterature review (SLR). Preferred Reporting Items for Systematic Reviews and\nMeta-Analysis (PRISMA) protocol is leveraged to identify 204 journal articles\npertaining to utilization of AI and analytics in sports published during 2002\nto 2024. We follow it up with extraction of the latent topics from sampled\narticles by leveraging the topic modelling technique of BERTopic. Findings: The\nstudy identifies the following as predominant areas of extant research on usage\nof AI and analytics in sports: performance modelling, physical and mental\nhealth, social media sentiment analysis, and tactical tracking. Each extracted\ntopic is further examined in terms of its relative prominence, representative\nstudies, and key term associations. Drawing on these insights, the study\ndelineates promising avenues for future inquiry. Research\nlimitations/implications: The study offers insights to academicians and sports\nadministrators on transformational impact of AI and analytics in sports.\nOriginality/value: The study introduces BERTopic as a novel approach for\nextracting latent structures in sports research, thereby advancing both\nscholarly understanding and the methodological toolkit of the field."}
{"id": "2510.15780", "categories": ["stat.AP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15780", "abs": "https://arxiv.org/abs/2510.15780", "authors": ["Alireza Moradi", "Mathieu Tanneau", "Reza Zandehshahvar", "Pascal Van Hentenryck"], "title": "Enhanced Renewable Energy Forecasting using Context-Aware Conformal Prediction", "comment": null, "summary": "Accurate forecasting is critical for reliable power grid operations,\nparticularly as the share of renewable generation, such as wind and solar,\ncontinues to grow. Given the inherent uncertainty and variability in renewable\ngeneration, probabilistic forecasts have become essential for informed\noperational decisions. However, such forecasts frequently suffer from\ncalibration issues, potentially degrading decision-making performance. Building\non recent advances in Conformal Predictions, this paper introduces a tailored\ncalibration framework that constructs context-aware calibration sets using a\nnovel weighting scheme. The proposed framework improves the quality of\nprobabilistic forecasts at the site and fleet levels, as demonstrated by\nnumerical experiments on large-scale datasets covering several systems in the\nUnited States. The results demonstrate that the proposed approach achieves\nhigher forecast reliability and robustness for renewable energy applications\ncompared to existing baselines."}
