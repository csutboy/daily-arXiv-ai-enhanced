{"id": "2601.09903", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2601.09903", "abs": "https://arxiv.org/abs/2601.09903", "authors": ["Adrien Renaudineau", "Mamadou Hawa Diallo", "Th\u00e9o Dupuis", "Bastien Imbert", "Mohammed Akib Iftakher", "Kamel-Eddine Harabi", "Cl\u00e9ment Turck", "Tifenn Hirtzlin", "Djohan Bonnet", "Franck Melul", "Jorge-Daniel Aguirre-Morales", "Elisa Vianello", "Marc Bocquet", "Jean-Michel Portal", "Damien Querlioz"], "title": "Forward-only learning in memristor arrays with month-scale stability", "comment": null, "summary": "Turning memristor arrays from efficient inference engines into systems capable of on-chip learning has proved difficult. Weight updates have a high energy cost and cause device wear, analog states drift, and backpropagation requires a backward pass with reversed signal flow. Here we experimentally demonstrate learning on standard filamentary HfOx/Ti arrays that addresses these challenges with two design choices. First, we realize that standard filamentary HfOx/Ti memristors support sub-1 V reset-only pulses that cut energy, improve endurance, and yield stable analog states. Second, we rely on forward-only training algorithms derived from Hinton's Forward-Forward that use only inference-style operations. We train two-layer classifiers on an ImageNet-resolution four-class task using arrays up to 8,064 devices. Two forward-only variants, the double-pass supervised Forward-Forward and a single-pass competitive rule, achieve test accuracies of 89.5% and 89.6%, respectively; a reference experiment using backpropagation reaches 90.0%. Across five independent runs per method, these accuracies match within statistical uncertainty. Trained models retain accuracy for at least one month under ambient conditions, consistent with the stability of reset-only states. Sub-1 V reset updates use 460 times less energy than conventional program-and-verify programming and require just 46% more energy than inference-only operation. Together, these results establish forward-only, sub-1 V learning on standard filamentary stacks at array scale, outlining a practical, pulse-aware route to adaptive edge intelligence.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u6807\u51c6HfOx/Ti\u5fc6\u963b\u5668\u9635\u5217\u4e0a\u5b9e\u73b0\u4f4e\u80fd\u8017\u7247\u4e0a\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e9a1V\u590d\u4f4d\u8109\u51b2\u548c\u4ec5\u524d\u5411\u8bad\u7ec3\u7b97\u6cd5\uff0c\u5728ImageNet\u5206\u8fa8\u7387\u56db\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fbe\u5230\u63a5\u8fd1\u53cd\u5411\u4f20\u64ad\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u5fc6\u963b\u5668\u9635\u5217\u867d\u7136\u80fd\u9ad8\u6548\u8fdb\u884c\u63a8\u7406\uff0c\u4f46\u7247\u4e0a\u5b66\u4e60\u9762\u4e34\u9ad8\u80fd\u8017\u3001\u5668\u4ef6\u78e8\u635f\u3001\u6a21\u62df\u72b6\u6001\u6f02\u79fb\u4ee5\u53ca\u53cd\u5411\u4f20\u64ad\u9700\u8981\u53cd\u5411\u4fe1\u53f7\u6d41\u7b49\u95ee\u9898\u3002\u9700\u8981\u627e\u5230\u4e00\u79cd\u5b9e\u7528\u7684\u7247\u4e0a\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u8bbe\u8ba1\uff1a1) \u5229\u7528\u6807\u51c6HfOx/Ti\u5fc6\u963b\u5668\u652f\u6301\u4e9a1V\u590d\u4f4d\u8109\u51b2\u7684\u7279\u6027\uff0c\u964d\u4f4e\u80fd\u8017\u3001\u63d0\u9ad8\u8010\u4e45\u6027\u5e76\u4fdd\u6301\u6a21\u62df\u72b6\u6001\u7a33\u5b9a\uff1b2) \u4f7f\u7528\u4ec5\u524d\u5411\u8bad\u7ec3\u7b97\u6cd5\uff08\u57fa\u4e8eHinton\u7684Forward-Forward\uff09\uff0c\u5305\u62ec\u53cc\u901a\u9053\u76d1\u7763Forward-Forward\u548c\u5355\u901a\u9053\u7ade\u4e89\u89c4\u5219\u3002", "result": "\u57288,064\u4e2a\u5668\u4ef6\u7684\u9635\u5217\u4e0a\u8bad\u7ec3\u4e24\u5c42\u5206\u7c7b\u5668\uff0c\u4e24\u79cd\u4ec5\u524d\u5411\u65b9\u6cd5\u5728ImageNet\u5206\u8fa8\u7387\u56db\u5206\u7c7b\u4efb\u52a1\u4e0a\u5206\u522b\u8fbe\u523089.5%\u548c89.6%\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\uff0c\u63a5\u8fd1\u53cd\u5411\u4f20\u64ad\u768490.0%\u3002\u4e9a1V\u590d\u4f4d\u66f4\u65b0\u6bd4\u4f20\u7edf\u7f16\u7a0b\u80fd\u8017\u964d\u4f4e460\u500d\uff0c\u4ec5\u6bd4\u63a8\u7406\u64cd\u4f5c\u591a46%\u80fd\u8017\u3002\u8bad\u7ec3\u6a21\u578b\u5728\u73af\u5883\u6761\u4ef6\u4e0b\u81f3\u5c11\u4fdd\u6301\u4e00\u4e2a\u6708\u51c6\u786e\u7387\u7a33\u5b9a\u3002", "conclusion": "\u8be5\u7814\u7a76\u5728\u6807\u51c6\u5fc6\u963b\u5668\u9635\u5217\u4e0a\u5b9e\u73b0\u4e86\u4e9a1V\u3001\u4ec5\u524d\u5411\u7684\u7247\u4e0a\u5b66\u4e60\uff0c\u4e3a\u81ea\u9002\u5e94\u8fb9\u7f18\u667a\u80fd\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u4e14\u8109\u51b2\u611f\u77e5\u7684\u6280\u672f\u8def\u7ebf\u3002"}}
{"id": "2601.10037", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2601.10037", "abs": "https://arxiv.org/abs/2601.10037", "authors": ["Ning Lin", "Jichang Yang", "Yangu He", "Zijian Ye", "Kwun Hang Wong", "Xinyuan Zhang", "Songqi Wang", "Yi Li", "Kemi Xu", "Leo Yu Zhang", "Xiaoming Chen", "Dashan Shang", "Han Wang", "Xiaojuan Qi", "Zhongrui Wang"], "title": "Resistive Memory based Efficient Machine Unlearning and Continual Learning", "comment": null, "summary": "Resistive memory (RM) based neuromorphic systems can emulate synaptic plasticity and thus support continual learning, but they generally lack biologically inspired mechanisms for active forgetting, which are critical for meeting modern data privacy requirements. Algorithmic forgetting, or machine unlearning, seeks to remove the influence of specific data from trained models to prevent memorization of sensitive information and the generation of harmful content, yet existing exact and approximate unlearning schemes incur prohibitive programming overheads on RM hardware owing to device variability and iterative write-verify cycles. Analogue implementations of continual learning face similar barriers. Here we present a hardware-software co-design that enables an efficient training, deployment and inference pipeline for machine unlearning and continual learning on RM accelerators. At the software level, we introduce a low-rank adaptation (LoRA) framework that confines updates to compact parameter branches, substantially reducing the number of trainable parameters and therefore the training cost. At the hardware level, we develop a hybrid analogue-digital compute-in-memory system in which well-trained weights are stored in analogue RM arrays, whereas dynamic LoRA updates are implemented in a digital computing unit with SRAM buffer. This hybrid architecture avoids costly reprogramming of analogue weights and maintains high energy efficiency during inference. Fabricated in a 180 nm CMOS process, the prototype achieves up to a 147.76-fold reduction in training cost, a 387.95-fold reduction in deployment overhead and a 48.44-fold reduction in inference energy across privacy-sensitive tasks including face recognition, speaker authentication and stylized image generation, paving the way for secure and efficient neuromorphic intelligence at the edge.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u901a\u8fc7\u4f4e\u79e9\u9002\u914d\u6846\u67b6\u548c\u6df7\u5408\u6a21\u62df-\u6570\u5b57\u5b58\u5185\u8ba1\u7b97\u7cfb\u7edf\uff0c\u5b9e\u73b0\u963b\u53d8\u5b58\u50a8\u5668\u4e0a\u7684\u9ad8\u6548\u673a\u5668\u9057\u5fd8\u548c\u6301\u7eed\u5b66\u4e60\uff0c\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u3001\u90e8\u7f72\u548c\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u963b\u53d8\u5b58\u50a8\u5668\u795e\u7ecf\u5f62\u6001\u7cfb\u7edf\u652f\u6301\u6301\u7eed\u5b66\u4e60\u4f46\u7f3a\u4e4f\u4e3b\u52a8\u9057\u5fd8\u673a\u5236\uff0c\u800c\u73b0\u6709\u673a\u5668\u9057\u5fd8\u65b9\u6848\u5728\u963b\u53d8\u5b58\u50a8\u5668\u786c\u4ef6\u4e0a\u7f16\u7a0b\u5f00\u9500\u8fc7\u9ad8\uff0c\u6a21\u62df\u5b9e\u73b0\u6301\u7eed\u5b66\u4e60\u4e5f\u9762\u4e34\u7c7b\u4f3c\u969c\u788d\u3002", "method": "\u8f6f\u4ef6\u5c42\u9762\u91c7\u7528\u4f4e\u79e9\u9002\u914d\u6846\u67b6\u5c06\u66f4\u65b0\u9650\u5236\u5728\u7d27\u51d1\u53c2\u6570\u5206\u652f\uff1b\u786c\u4ef6\u5c42\u9762\u5f00\u53d1\u6df7\u5408\u6a21\u62df-\u6570\u5b57\u5b58\u5185\u8ba1\u7b97\u7cfb\u7edf\uff0c\u5c06\u8bad\u7ec3\u597d\u7684\u6743\u91cd\u5b58\u50a8\u5728\u6a21\u62df\u963b\u53d8\u5b58\u50a8\u5668\u9635\u5217\uff0c\u52a8\u6001\u66f4\u65b0\u5728\u5e26SRAM\u7f13\u51b2\u7684\u6570\u5b57\u8ba1\u7b97\u5355\u5143\u5b9e\u73b0\u3002", "result": "\u5728180nm CMOS\u5de5\u827a\u539f\u578b\u4e0a\uff0c\u5728\u9762\u90e8\u8bc6\u522b\u3001\u8bf4\u8bdd\u4eba\u8ba4\u8bc1\u548c\u98ce\u683c\u5316\u56fe\u50cf\u751f\u6210\u7b49\u9690\u79c1\u654f\u611f\u4efb\u52a1\u4e2d\uff0c\u8bad\u7ec3\u6210\u672c\u964d\u4f4e147.76\u500d\uff0c\u90e8\u7f72\u5f00\u9500\u964d\u4f4e387.95\u500d\uff0c\u63a8\u7406\u80fd\u8017\u964d\u4f4e48.44\u500d\u3002", "conclusion": "\u8be5\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u4e3a\u8fb9\u7f18\u8bbe\u5907\u5b9e\u73b0\u5b89\u5168\u9ad8\u6548\u7684\u795e\u7ecf\u5f62\u6001\u667a\u80fd\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u89e3\u51b3\u4e86\u963b\u53d8\u5b58\u50a8\u5668\u4e0a\u673a\u5668\u9057\u5fd8\u548c\u6301\u7eed\u5b66\u4e60\u7684\u9ad8\u5f00\u9500\u95ee\u9898\u3002"}}
{"id": "2601.10154", "categories": ["cs.AI", "cs.CV", "cs.ET", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.10154", "abs": "https://arxiv.org/abs/2601.10154", "authors": ["Leonard N\u00fcrnberg", "Dennis Bontempi", "Suraj Pai", "Curtis Lisle", "Steve Pieper", "Ron Kikinis", "Sil van de Leemput", "Rahul Soni", "Gowtham Murugesan", "Cosmin Ciausu", "Miriam Groeneveld", "Felix J. Dorfner", "Jue Jiang", "Aneesh Rangnekar", "Harini Veeraraghavan", "Joeran S. Bosma", "Keno Bressem", "Raymond Mak", "Andrey Fedorov", "Hugo JWL Aerts"], "title": "MHub.ai: A Simple, Standardized, and Reproducible Platform for AI Models in Medical Imaging", "comment": "41 pages, 15 figures, 6 tables", "summary": "Artificial intelligence (AI) has the potential to transform medical imaging by automating image analysis and accelerating clinical research. However, research and clinical use are limited by the wide variety of AI implementations and architectures, inconsistent documentation, and reproducibility issues. Here, we introduce MHub.ai, an open-source, container-based platform that standardizes access to AI models with minimal configuration, promoting accessibility and reproducibility in medical imaging. MHub.ai packages models from peer-reviewed publications into standardized containers that support direct processing of DICOM and other formats, provide a unified application interface, and embed structured metadata. Each model is accompanied by publicly available reference data that can be used to confirm model operation. MHub.ai includes an initial set of state-of-the-art segmentation, prediction, and feature extraction models for different modalities. The modular framework enables adaptation of any model and supports community contributions. We demonstrate the utility of the platform in a clinical use case through comparative evaluation of lung segmentation models. To further strengthen transparency and reproducibility, we publicly release the generated segmentations and evaluation metrics and provide interactive dashboards that allow readers to inspect individual cases and reproduce or extend our analysis. By simplifying model use, MHub.ai enables side-by-side benchmarking with identical execution commands and standardized outputs, and lowers the barrier to clinical translation.", "AI": {"tldr": "MHub.ai\u662f\u4e00\u4e2a\u5f00\u6e90\u5bb9\u5668\u5316\u5e73\u53f0\uff0c\u65e8\u5728\u6807\u51c6\u5316\u533b\u5b66\u5f71\u50cfAI\u6a21\u578b\u7684\u8bbf\u95ee\uff0c\u89e3\u51b3\u5b9e\u73b0\u591a\u6837\u6027\u3001\u6587\u6863\u4e0d\u4e00\u81f4\u548c\u53ef\u91cd\u590d\u6027\u95ee\u9898\uff0c\u4fc3\u8fdb\u6a21\u578b\u7684\u53ef\u53ca\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "motivation": "\u533b\u5b66\u5f71\u50cfAI\u7814\u7a76\u53d7\u9650\u4e8e\u591a\u79cd\u5b9e\u73b0\u67b6\u6784\u3001\u4e0d\u4e00\u81f4\u7684\u6587\u6863\u548c\u53ef\u91cd\u590d\u6027\u95ee\u9898\uff0c\u963b\u788d\u4e86\u7814\u7a76\u548c\u4e34\u5e8a\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u5f00\u6e90\u5bb9\u5668\u5316\u5e73\u53f0\uff0c\u5c06\u540c\u884c\u8bc4\u5ba1\u7684\u6a21\u578b\u6253\u5305\u4e3a\u6807\u51c6\u5bb9\u5668\uff0c\u652f\u6301DICOM\u683c\u5f0f\u5904\u7406\uff0c\u63d0\u4f9b\u7edf\u4e00API\uff0c\u5d4c\u5165\u7ed3\u6784\u5316\u5143\u6570\u636e\uff0c\u5e76\u9644\u5e26\u516c\u5f00\u53c2\u8003\u6570\u636e\u3002", "result": "\u5e73\u53f0\u5305\u542b\u6700\u5148\u8fdb\u7684\u5206\u5272\u3001\u9884\u6d4b\u548c\u7279\u5f81\u63d0\u53d6\u6a21\u578b\uff0c\u901a\u8fc7\u80ba\u5206\u5272\u6a21\u578b\u7684\u6bd4\u8f83\u8bc4\u4f30\u5c55\u793a\u4e86\u4e34\u5e8a\u5b9e\u7528\u6027\uff0c\u5e76\u516c\u5f00\u4e86\u5206\u5272\u7ed3\u679c\u548c\u8bc4\u4f30\u6307\u6807\u3002", "conclusion": "MHub.ai\u901a\u8fc7\u7b80\u5316\u6a21\u578b\u4f7f\u7528\uff0c\u652f\u6301\u5e76\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u964d\u4f4e\u4e34\u5e8a\u8f6c\u5316\u95e8\u69db\uff0c\u589e\u5f3a\u533b\u5b66\u5f71\u50cfAI\u7684\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2601.09942", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.09942", "abs": "https://arxiv.org/abs/2601.09942", "authors": ["Hunjun Shin", "Hoonbae Moon", "Mohit Singhal"], "title": "How Diplomacy Reshapes Online Discourse:Asymmetric Persistence in Online Framing of North Korea", "comment": null, "summary": "Public opinion toward foreign adversaries shapes and constrains diplomatic options. Prior research has largely relied on sentiment analysis and survey based measures, providing limited insight into how sustained narrative changes (beyond transient emotional reactions) might follow diplomatic engagement. This study examines the extent to which high stakes diplomatic summits shape how adversaries are framed in online discourse. We analyze U.S.-North Korea summit diplomacy (2018-2019) using a Difference-in-Difference(DiD) design on Reddit discussions. Using multiple control groups (China, Iran, Russia) to adjust for concurrent geopolitical shocks, we integrate a validated Codebook LLM framework for framing classification with graph based discourse network analysis that examines both edge level relationships and community level narrative structures. Our results reveal short term asymmetric persistence in framing responses to diplomacy. While both post level and comment level sentiment proved transient (improving during the Singapore Summit but fully reverting after the Hanoi failure),framing exhibited significant stability: the shift from threat oriented to diplomacy oriented framing was only partially reversed. Structurally, the proportion of threat oriented edges decreased substantially (48% -> 28%) while diplomacy oriented structures expanded, and these shifts resisted complete reversion after diplomatic failure. These findings suggest that diplomatic success can leave a short-term but lasting imprint on how adversaries are framed in online discourse, even when subsequent negotiations fail.", "AI": {"tldr": "\u7814\u7a76\u663e\u793a\u5916\u4ea4\u5cf0\u4f1a\u80fd\u77ed\u671f\u4f46\u6301\u4e45\u5730\u6539\u53d8\u7f51\u7edc\u8bdd\u8bed\u4e2d\u5bf9\u654c\u5bf9\u56fd\u5bb6\u7684\u6846\u67b6\uff0c\u5373\u4f7f\u540e\u7eed\u8c08\u5224\u5931\u8d25\uff0c\u8fd9\u79cd\u6846\u67b6\u8f6c\u53d8\u4e5f\u4e0d\u4f1a\u5b8c\u5168\u9006\u8f6c\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u60c5\u611f\u5206\u6790\u548c\u8c03\u67e5\u65b9\u6cd5\uff0c\u96be\u4ee5\u6355\u6349\u5916\u4ea4\u63a5\u89e6\u540e\u6301\u7eed\u7684\u53d9\u4e8b\u53d8\u5316\uff08\u8d85\u8d8a\u77ed\u6682\u7684\u60c5\u611f\u53cd\u5e94\uff09\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u9ad8\u98ce\u9669\u5916\u4ea4\u5cf0\u4f1a\u5982\u4f55\u5851\u9020\u7f51\u7edc\u8bdd\u8bed\u4e2d\u5bf9\u654c\u5bf9\u56fd\u5bb6\u7684\u6846\u67b6\u3002", "method": "\u91c7\u7528\u53cc\u91cd\u5dee\u5206\u8bbe\u8ba1\u5206\u67902018-2019\u5e74\u7f8e\u671d\u5cf0\u4f1a\u671f\u95f4\u7684Reddit\u8ba8\u8bba\uff0c\u4f7f\u7528\u591a\u4e2a\u5bf9\u7167\u7ec4\uff08\u4e2d\u56fd\u3001\u4f0a\u6717\u3001\u4fc4\u7f57\u65af\uff09\u63a7\u5236\u5730\u7f18\u653f\u6cbb\u51b2\u51fb\uff0c\u7ed3\u5408\u7ecf\u8fc7\u9a8c\u8bc1\u7684Codebook LLM\u6846\u67b6\u5206\u7c7b\u548c\u56fe\u57fa\u8bdd\u8bed\u7f51\u7edc\u5206\u6790\uff0c\u8003\u5bdf\u8fb9\u7f18\u7ea7\u5173\u7cfb\u548c\u793e\u533a\u7ea7\u53d9\u4e8b\u7ed3\u6784\u3002", "result": "\u53d1\u73b0\u6846\u67b6\u54cd\u5e94\u5b58\u5728\u77ed\u671f\u4e0d\u5bf9\u79f0\u6301\u7eed\u6027\uff1a\u5e16\u5b50\u548c\u8bc4\u8bba\u7ea7\u60c5\u611f\u662f\u77ed\u6682\u7684\uff08\u65b0\u52a0\u5761\u5cf0\u4f1a\u671f\u95f4\u6539\u5584\u4f46\u6cb3\u5185\u5931\u8d25\u540e\u5b8c\u5168\u9006\u8f6c\uff09\uff0c\u800c\u6846\u67b6\u8f6c\u53d8\u663e\u8457\u7a33\u5b9a\u2014\u2014\u4ece\u5a01\u80c1\u5bfc\u5411\u8f6c\u5411\u5916\u4ea4\u5bfc\u5411\u7684\u6846\u67b6\u4ec5\u90e8\u5206\u9006\u8f6c\u3002\u7ed3\u6784\u4e0a\uff0c\u5a01\u80c1\u5bfc\u5411\u8fb9\u7f18\u6bd4\u4f8b\u5927\u5e45\u4e0b\u964d\uff0848%\u219228%\uff09\uff0c\u5916\u4ea4\u5bfc\u5411\u7ed3\u6784\u6269\u5f20\uff0c\u8fd9\u4e9b\u8f6c\u53d8\u5728\u5916\u4ea4\u5931\u8d25\u540e\u62b5\u6297\u5b8c\u5168\u9006\u8f6c\u3002", "conclusion": "\u5916\u4ea4\u6210\u529f\u80fd\u5728\u7f51\u7edc\u8bdd\u8bed\u4e2d\u7559\u4e0b\u77ed\u671f\u4f46\u6301\u4e45\u7684\u5370\u8bb0\uff0c\u6539\u53d8\u5bf9\u654c\u5bf9\u56fd\u5bb6\u7684\u6846\u67b6\u65b9\u5f0f\uff0c\u5373\u4f7f\u540e\u7eed\u8c08\u5224\u5931\u8d25\uff0c\u8fd9\u79cd\u6846\u67b6\u8f6c\u53d8\u4e5f\u4e0d\u4f1a\u5b8c\u5168\u6d88\u5931\u3002"}}
{"id": "2601.09711", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.09711", "abs": "https://arxiv.org/abs/2601.09711", "authors": ["Frederik Zuiderveen Borgesius"], "title": "Segmenta\u00e7\u00e3o Comportamental, Do Not Track e o desenvolvimento jur\u00eddico europeu e holand\u00eas", "comment": "In Portugese", "summary": "This paper discusses legal developments in Europe and the Netherlands. Recent decisions show that European data protection law, or privacy law, applies to behavioral targeting in most cases. Dutch law explicitly presumes that data protection law applies to behavioral targeting. This means that companies have to comply with data protection law's fair information principles. For example, companies must refrain from secret or excessive data collection. Perhaps the principles could provide inspiration for future W3C projects. Could technology design foster fair information processing?", "AI": {"tldr": "\u6b27\u6d32\u6570\u636e\u4fdd\u62a4\u6cd5\u9002\u7528\u4e8e\u884c\u4e3a\u5b9a\u5411\u5e7f\u544a\uff0c\u8377\u5170\u6cd5\u5f8b\u660e\u786e\u63a8\u5b9a\u9002\u7528\uff0c\u8981\u6c42\u4f01\u4e1a\u9075\u5b88\u516c\u5e73\u4fe1\u606f\u539f\u5219\uff0c\u907f\u514d\u79d8\u5bc6\u6216\u8fc7\u5ea6\u6570\u636e\u6536\u96c6\uff0c\u8fd9\u4e9b\u539f\u5219\u53ef\u4e3aW3C\u9879\u76ee\u63d0\u4f9b\u7075\u611f\u3002", "motivation": "\u63a2\u8ba8\u6b27\u6d32\u548c\u8377\u5170\u6cd5\u5f8b\u5bf9\u884c\u4e3a\u5b9a\u5411\u5e7f\u544a\u7684\u76d1\u7ba1\u53d1\u5c55\uff0c\u5206\u6790\u6570\u636e\u4fdd\u62a4\u6cd5\u5982\u4f55\u9002\u7528\u4e8e\u5728\u7ebf\u884c\u4e3a\u5b9a\u5411\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u6280\u672f\u8bbe\u8ba1\u4fc3\u8fdb\u516c\u5e73\u4fe1\u606f\u5904\u7406\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6b27\u6d32\u548c\u8377\u5170\u7684\u6cd5\u5f8b\u51b3\u7b56\u548c\u6cd5\u89c4\uff0c\u7279\u522b\u662f\u6570\u636e\u4fdd\u62a4\u6cd5\u5728\u884c\u4e3a\u5b9a\u5411\u5e7f\u544a\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u6cd5\u5f8b\u8981\u6c42\u548c\u6280\u672f\u8bbe\u8ba1\u7684\u7ed3\u5408\u3002", "result": "\u6b27\u6d32\u6570\u636e\u4fdd\u62a4\u6cd5\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u9002\u7528\u4e8e\u884c\u4e3a\u5b9a\u5411\u5e7f\u544a\uff0c\u8377\u5170\u6cd5\u5f8b\u660e\u786e\u63a8\u5b9a\u9002\u7528\uff0c\u8981\u6c42\u4f01\u4e1a\u9075\u5b88\u516c\u5e73\u4fe1\u606f\u539f\u5219\uff0c\u907f\u514d\u79d8\u5bc6\u6216\u8fc7\u5ea6\u6570\u636e\u6536\u96c6\u3002", "conclusion": "\u6570\u636e\u4fdd\u62a4\u6cd5\u7684\u516c\u5e73\u4fe1\u606f\u539f\u5219\u53ef\u4e3aW3C\u7b49\u6807\u51c6\u5316\u7ec4\u7ec7\u63d0\u4f9b\u8bbe\u8ba1\u7075\u611f\uff0c\u6280\u672f\u8bbe\u8ba1\u5e94\u4fc3\u8fdb\u516c\u5e73\u4fe1\u606f\u5904\u7406\uff0c\u5e73\u8861\u5546\u4e1a\u5229\u76ca\u4e0e\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2601.09821", "categories": ["stat.AP", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.09821", "abs": "https://arxiv.org/abs/2601.09821", "authors": ["Gloria Henr\u00edquez", "Jhoan B\u00e1ez", "V\u00edctor Riquelme", "Pedro Gajardo", "Michel Royer", "H\u00e9ctor Ram\u00edrez"], "title": "Forecasting Seasonal Peaks of Pediatric Respiratory Infections Using an Alert-Based Model Combining SIR Dynamics and Historical Trends in Santiago, Chile", "comment": "13 pages, 6 figures, 5 tables. Includes an alert-based forecasting algorithm and an appendix", "summary": "Acute respiratory infections (ARI) are a major cause of pediatric hospitalization in Chile, producing marked winter increases in demand that challenge hospital planning. This study presents an alert-based forecasting model to predict the timing and magnitude of ARI hospitalization peaks in Santiago. The approach integrates a seasonal SIR model with a historical mobile predictor, activated by a derivative-based alert system that detects early epidemic growth. Daily hospitalization data from DEIS were smoothed using a 15-day moving average and Savitzky-Golay filtering, and parameters were estimated using a penalized loss function to reduce sensitivity to noise. Retrospective evaluation and real-world implementation in major Santiago pediatric hospitals during 2023 and 2024 show that peak date can be anticipated about one month before the event and predicted with high accuracy two weeks in advance. Peak magnitude becomes informative roughly ten days before the peak and stabilizes one week prior. The model provides a practical and interpretable tool for hospital preparedness.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8e\u8b66\u62a5\u7684\u9884\u6d4b\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u667a\u5229\u5723\u5730\u4e9a\u54e5\u513f\u7ae5\u6025\u6027\u547c\u5438\u9053\u611f\u67d3\u4f4f\u9662\u9ad8\u5cf0\u7684\u65f6\u95f4\u548c\u89c4\u6a21\uff0c\u901a\u8fc7\u5b63\u8282\u6027SIR\u6a21\u578b\u7ed3\u5408\u79fb\u52a8\u5386\u53f2\u9884\u6d4b\u56e0\u5b50\uff0c\u63d0\u524d\u4e00\u4e2a\u6708\u9884\u6d4b\u9ad8\u5cf0\u65f6\u95f4\uff0c\u4e24\u5468\u524d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u3002", "motivation": "\u6025\u6027\u547c\u5438\u9053\u611f\u67d3\u662f\u667a\u5229\u513f\u7ae5\u4f4f\u9662\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u51ac\u5b63\u9700\u6c42\u6fc0\u589e\u7ed9\u533b\u9662\u89c4\u5212\u5e26\u6765\u6311\u6218\uff0c\u9700\u8981\u63d0\u524d\u9884\u6d4b\u9ad8\u5cf0\u65f6\u95f4\u548c\u89c4\u6a21\u4ee5\u6539\u5584\u533b\u9662\u51c6\u5907\u3002", "method": "\u6574\u5408\u5b63\u8282\u6027SIR\u6a21\u578b\u4e0e\u5386\u53f2\u79fb\u52a8\u9884\u6d4b\u56e0\u5b50\uff0c\u91c7\u7528\u57fa\u4e8e\u5bfc\u6570\u7684\u8b66\u62a5\u7cfb\u7edf\u68c0\u6d4b\u65e9\u671f\u75ab\u60c5\u589e\u957f\u3002\u4f7f\u752815\u5929\u79fb\u52a8\u5e73\u5747\u548cSavitzky-Golay\u6ee4\u6ce2\u5e73\u6ed1\u6bcf\u65e5\u4f4f\u9662\u6570\u636e\uff0c\u901a\u8fc7\u60e9\u7f5a\u635f\u5931\u51fd\u6570\u4f30\u8ba1\u53c2\u6570\u4ee5\u51cf\u5c11\u566a\u58f0\u654f\u611f\u6027\u3002", "result": "\u56de\u987e\u6027\u8bc4\u4f30\u548c2023-2024\u5e74\u5723\u5730\u4e9a\u54e5\u4e3b\u8981\u513f\u7ae5\u533b\u9662\u7684\u5b9e\u9645\u5b9e\u65bd\u663e\u793a\uff1a\u9ad8\u5cf0\u65e5\u671f\u53ef\u63d0\u524d\u7ea6\u4e00\u4e2a\u6708\u9884\u6d4b\uff0c\u4e24\u5468\u524d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u9884\u6d4b\uff1b\u9ad8\u5cf0\u89c4\u6a21\u5728\u9ad8\u5cf0\u524d\u7ea610\u5929\u53d8\u5f97\u6709\u53c2\u8003\u4ef7\u503c\uff0c\u4e00\u5468\u524d\u7a33\u5b9a\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u533b\u9662\u51c6\u5907\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u5de5\u5177\uff0c\u80fd\u591f\u6709\u6548\u9884\u6d4b\u6025\u6027\u547c\u5438\u9053\u611f\u67d3\u4f4f\u9662\u9ad8\u5cf0\u7684\u65f6\u95f4\u548c\u89c4\u6a21\uff0c\u652f\u6301\u533b\u9662\u8d44\u6e90\u89c4\u5212\u548c\u5e94\u5bf9\u7b56\u7565\u3002"}}
{"id": "2601.09888", "categories": ["econ.EM", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.09888", "abs": "https://arxiv.org/abs/2601.09888", "authors": ["Frederico Finan", "Demian Pouzo"], "title": "Learning about Treatment Effects with Prior Studies: A Bayesian Model Averaging Approach", "comment": null, "summary": "We establish concentration rates for estimation of treatment effects in experiments that incorporate prior sources of information -- such as past pilots, related studies, or expert assessments -- whose external validity is uncertain. Each source is modeled as a Gaussian prior with its own mean and precision, and sources are combined using Bayesian model averaging (BMA), allowing data from the new experiment to update posterior weights. To capture empirically relevant settings in which prior studies may be as informative as the current experiment, we introduce a nonstandard asymptotic framework in which prior precisions grow with the experiment's sample size. In this regime, posterior weights are governed by an external-validity index that depends jointly on a source's bias and information content: biased sources are exponentially downweighted, while unbiased sources dominate. When at least one source is unbiased, our procedure concentrates on the unbiased set and achieves faster convergence than relying on new data alone. When all sources are biased, including a deliberately conservative (diffuse) prior guarantees robustness and recovers the standard convergence rate.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5148\u9a8c\u4fe1\u606f\u7684\u5b9e\u9a8c\u6cbb\u7597\u6548\u679c\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u6a21\u578b\u5e73\u5747\u548c\u5916\u90e8\u6709\u6548\u6027\u6307\u6570\uff0c\u5728\u975e\u6807\u51c6\u6e10\u8fd1\u6846\u67b6\u4e0b\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u5b9e\u9a8c\u8bbe\u8ba1\u5f80\u5f80\u5ffd\u7565\u4e86\u8fc7\u53bb\u8bd5\u70b9\u3001\u76f8\u5173\u7814\u7a76\u6216\u4e13\u5bb6\u8bc4\u4f30\u7b49\u5148\u9a8c\u4fe1\u606f\uff0c\u6216\u8005\u5bf9\u8fd9\u4e9b\u4fe1\u606f\u7684\u6709\u6548\u6027\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u3002\u5982\u4f55\u6709\u6548\u6574\u5408\u8fd9\u4e9b\u5916\u90e8\u4fe1\u606f\u6e90\uff0c\u5e76\u5728\u5b83\u4eec\u53ef\u80fd\u5b58\u5728\u504f\u5dee\u7684\u60c5\u51b5\u4e0b\u4fdd\u8bc1\u4f30\u8ba1\u7684\u9c81\u68d2\u6027\uff0c\u662f\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u6a21\u578b\u5e73\u5747\uff08BMA\uff09\u65b9\u6cd5\uff0c\u5c06\u6bcf\u4e2a\u5148\u9a8c\u4fe1\u606f\u6e90\u5efa\u6a21\u4e3a\u5177\u6709\u7279\u5b9a\u5747\u503c\u548c\u7cbe\u5ea6\u7684\u9ad8\u65af\u5148\u9a8c\u3002\u5f15\u5165\u975e\u6807\u51c6\u6e10\u8fd1\u6846\u67b6\uff0c\u5141\u8bb8\u5148\u9a8c\u7cbe\u5ea6\u968f\u5b9e\u9a8c\u6837\u672c\u91cf\u589e\u957f\u3002\u901a\u8fc7\u5916\u90e8\u6709\u6548\u6027\u6307\u6570\u6765\u6743\u8861\u4fe1\u606f\u6e90\u7684\u504f\u5dee\u548c\u4fe1\u606f\u542b\u91cf\u3002", "result": "\u5f53\u81f3\u5c11\u6709\u4e00\u4e2a\u4fe1\u606f\u6e90\u65e0\u504f\u65f6\uff0c\u8be5\u65b9\u6cd5\u80fd\u96c6\u4e2d\u5728\u65e0\u504f\u96c6\u5408\u4e0a\uff0c\u5b9e\u73b0\u6bd4\u4ec5\u4f9d\u8d56\u65b0\u6570\u636e\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002\u5f53\u6240\u6709\u4fe1\u606f\u6e90\u90fd\u6709\u504f\u65f6\uff0c\u52a0\u5165\u4fdd\u5b88\uff08\u6269\u6563\uff09\u5148\u9a8c\u80fd\u4fdd\u8bc1\u9c81\u68d2\u6027\u5e76\u6062\u590d\u6807\u51c6\u6536\u655b\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6574\u5408\u5148\u9a8c\u4fe1\u606f\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u5728\u4fe1\u606f\u6e90\u65e0\u504f\u65f6\u80fd\u52a0\u901f\u6536\u655b\uff0c\u5728\u6709\u504f\u65f6\u901a\u8fc7\u4fdd\u5b88\u5148\u9a8c\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u4e3a\u5b9e\u9a8c\u8bbe\u8ba1\u4e2d\u7684\u4fe1\u606f\u6574\u5408\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.09765", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09765", "abs": "https://arxiv.org/abs/2601.09765", "authors": ["Herman Cappelen", "Simon Goldstein", "John Hawthorne"], "title": "AI Survival Stories: a Taxonomic Analysis of AI Existential Risk", "comment": null, "summary": "Since the release of ChatGPT, there has been a lot of debate about whether AI systems pose an existential risk to humanity. This paper develops a general framework for thinking about the existential risk of AI systems. We analyze a two premise argument that AI systems pose a threat to humanity. Premise one: AI systems will become extremely powerful. Premise two: if AI systems become extremely powerful, they will destroy humanity. We use these two premises to construct a taxonomy of survival stories, in which humanity survives into the far future. In each survival story, one of the two premises fails. Either scientific barriers prevent AI systems from becoming extremely powerful; or humanity bans research into AI systems, thereby preventing them from becoming extremely powerful; or extremely powerful AI systems do not destroy humanity, because their goals prevent them from doing so; or extremely powerful AI systems do not destroy humanity, because we can reliably detect and disable systems that have the goal of doing so. We argue that different survival stories face different challenges. We also argue that different survival stories motivate different responses to the threats from AI. Finally, we use our taxonomy to produce rough estimates of P(doom), the probability that humanity will be destroyed by AI.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u6790AI\u5b58\u5728\u6027\u98ce\u9669\u7684\u901a\u7528\u6846\u67b6\uff0c\u57fa\u4e8e\u4e24\u4e2a\u524d\u63d0\u6784\u5efa\u4e86\u4eba\u7c7b\u751f\u5b58\u6545\u4e8b\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u7528\u4e8e\u4f30\u7b97AI\u6bc1\u706d\u4eba\u7c7b\u7684\u6982\u7387\u3002", "motivation": "\u81eaChatGPT\u53d1\u5e03\u4ee5\u6765\uff0c\u5173\u4e8eAI\u7cfb\u7edf\u662f\u5426\u5bf9\u4eba\u7c7b\u6784\u6210\u5b58\u5728\u6027\u98ce\u9669\u7684\u4e89\u8bba\u4e0d\u65ad\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u7cfb\u7edf\u6846\u67b6\u6765\u5206\u6790AI\u7684\u5b58\u5728\u6027\u98ce\u9669\uff0c\u4e3a\u8fd9\u4e00\u91cd\u8981\u8fa9\u8bba\u63d0\u4f9b\u7ed3\u6784\u5316\u7684\u601d\u8003\u5de5\u5177\u3002", "method": "\u57fa\u4e8e\u4e24\u4e2a\u6838\u5fc3\u524d\u63d0\u6784\u5efa\u5206\u6790\u6846\u67b6\uff1a\u524d\u63d0\u4e00\uff1aAI\u7cfb\u7edf\u5c06\u53d8\u5f97\u6781\u5176\u5f3a\u5927\uff1b\u524d\u63d0\u4e8c\uff1a\u5982\u679cAI\u7cfb\u7edf\u53d8\u5f97\u6781\u5176\u5f3a\u5927\uff0c\u5b83\u4eec\u5c06\u6bc1\u706d\u4eba\u7c7b\u3002\u901a\u8fc7\u8fd9\u4e24\u4e2a\u524d\u63d0\u6784\u5efa\u4e86\u56db\u79cd\u4eba\u7c7b\u751f\u5b58\u6545\u4e8b\u5206\u7c7b\uff0c\u6bcf\u79cd\u6545\u4e8b\u4e2d\u81f3\u5c11\u6709\u4e00\u4e2a\u524d\u63d0\u4e0d\u6210\u7acb\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u4eba\u7c7b\u751f\u5b58\u6545\u4e8b\u5206\u7c7b\u6cd5\uff1a1\uff09\u79d1\u5b66\u969c\u788d\u963b\u6b62AI\u53d8\u5f97\u6781\u5176\u5f3a\u5927\uff1b2\uff09\u4eba\u7c7b\u7981\u6b62AI\u7814\u7a76\uff1b3\uff09\u6781\u5176\u5f3a\u5927\u7684AI\u56e0\u5176\u76ee\u6807\u800c\u4e0d\u6bc1\u706d\u4eba\u7c7b\uff1b4\uff09\u4eba\u7c7b\u80fd\u591f\u53ef\u9760\u68c0\u6d4b\u5e76\u7981\u7528\u5177\u6709\u6bc1\u706d\u76ee\u6807\u7684AI\u7cfb\u7edf\u3002\u4e0d\u540c\u751f\u5b58\u6545\u4e8b\u9762\u4e34\u4e0d\u540c\u6311\u6218\u5e76\u9700\u8981\u4e0d\u540c\u5e94\u5bf9\u7b56\u7565\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5206\u6790AI\u5b58\u5728\u6027\u98ce\u9669\u63d0\u4f9b\u4e86\u7cfb\u7edf\u65b9\u6cd5\uff0c\u4e0d\u540c\u751f\u5b58\u6545\u4e8b\u5bf9\u5e94\u4e0d\u540c\u7684\u98ce\u9669\u5e94\u5bf9\u7b56\u7565\u3002\u4f5c\u8005\u4f7f\u7528\u8fd9\u4e00\u5206\u7c7b\u6cd5\u5bf9P(doom)\uff08AI\u6bc1\u706d\u4eba\u7c7b\u7684\u6982\u7387\uff09\u8fdb\u884c\u4e86\u7c97\u7565\u4f30\u8ba1\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u548c\u98ce\u9669\u7f13\u89e3\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2601.10502", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.10502", "abs": "https://arxiv.org/abs/2601.10502", "authors": ["Jiaze Li", "Michael T. Schaub", "Leto Peel"], "title": "Higher order trade-offs in hypergraph community detection", "comment": "70 pages, 18 figures", "summary": "Extending community detection from pairwise networks to hypergraphs introduces fundamental theoretical challenges. Hypergraphs exhibit structural heterogeneity with no direct graph analogue: hyperedges of varying orders can connect nodes across communities in diverse configurations, introducing new trade-offs in defining and detecting community structure. We address these challenges by developing a unified framework for community detection in non-uniform hypergraphs under the Hypergraph Stochastic Block Model. We introduce a general signal-to-noise ratio that enables a quantitative analysis of trade-offs unique to higher-order networks, such as which hypergedges we choose to split across communities and how we choose to split them. Building on this framework, we derive a Bethe Hessian operator for non-uniform hypergraphs that provides efficient spectral clustering with principled model selection. We characterize the resulting spectral detectability threshold and compare it to belief propagation limits, showing the methods coincide for uniform hypergraphs but diverge in non-uniform settings. Synthetic experiments confirm our analytical predictions and reveal systematic biases toward preserving higher-order and balanced-shape hyperedges. Application to empirical data demonstrates the practical relevance of these higher-order detectability trade-offs in real-world systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u8d85\u56fe\u793e\u533a\u68c0\u6d4b\u6846\u67b6\uff0c\u5f15\u5165\u4fe1\u566a\u6bd4\u5206\u6790\u9ad8\u9636\u7f51\u7edc\u7279\u6709\u7684\u6743\u8861\uff0c\u5f00\u53d1\u975e\u5747\u5300\u8d85\u56fe\u7684Bethe Hessian\u7b97\u5b50\u5b9e\u73b0\u9ad8\u6548\u8c31\u805a\u7c7b\uff0c\u5e76\u63ed\u793a\u9ad8\u9636\u8d85\u8fb9\u548c\u5e73\u8861\u5f62\u72b6\u8d85\u8fb9\u7684\u7cfb\u7edf\u504f\u597d\u3002", "motivation": "\u5c06\u793e\u533a\u68c0\u6d4b\u4ece\u6210\u5bf9\u7f51\u7edc\u6269\u5c55\u5230\u8d85\u56fe\u9762\u4e34\u7406\u8bba\u6311\u6218\uff1a\u8d85\u56fe\u5177\u6709\u7ed3\u6784\u5f02\u8d28\u6027\uff0c\u4e0d\u540c\u9636\u6570\u7684\u8d85\u8fb9\u53ef\u4ee5\u4ee5\u591a\u79cd\u914d\u7f6e\u8fde\u63a5\u8de8\u793e\u533a\u8282\u70b9\uff0c\u8fd9\u4e3a\u5b9a\u4e49\u548c\u68c0\u6d4b\u793e\u533a\u7ed3\u6784\u5f15\u5165\u4e86\u65b0\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "\u5728\u8d85\u56fe\u968f\u673a\u5757\u6a21\u578b\u4e0b\u5f00\u53d1\u7edf\u4e00\u6846\u67b6\uff0c\u5f15\u5165\u901a\u7528\u4fe1\u566a\u6bd4\u5206\u6790\u9ad8\u9636\u7f51\u7edc\u7279\u6709\u6743\u8861\uff0c\u63a8\u5bfc\u975e\u5747\u5300\u8d85\u56fe\u7684Bethe Hessian\u7b97\u5b50\u5b9e\u73b0\u9ad8\u6548\u8c31\u805a\u7c7b\u548c\u539f\u5219\u6027\u6a21\u578b\u9009\u62e9\u3002", "result": "\u8868\u5f81\u4e86\u8c31\u68c0\u6d4b\u9608\u503c\uff0c\u4e0e\u4fe1\u5ff5\u4f20\u64ad\u6781\u9650\u6bd4\u8f83\u663e\u793a\u4e24\u8005\u5728\u5747\u5300\u8d85\u56fe\u4e2d\u4e00\u81f4\u4f46\u5728\u975e\u5747\u5300\u8bbe\u7f6e\u4e2d\u5206\u6b67\u3002\u5408\u6210\u5b9e\u9a8c\u9a8c\u8bc1\u5206\u6790\u9884\u6d4b\u5e76\u63ed\u793a\u7cfb\u7edf\u504f\u5411\u4fdd\u7559\u9ad8\u9636\u548c\u5e73\u8861\u5f62\u72b6\u8d85\u8fb9\u3002\u5b9e\u8bc1\u6570\u636e\u5e94\u7528\u8bc1\u660e\u8fd9\u4e9b\u9ad8\u9636\u68c0\u6d4b\u6743\u8861\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\u7684\u76f8\u5173\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8d85\u56fe\u793e\u533a\u68c0\u6d4b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u9ad8\u9636\u7f51\u7edc\u7279\u6709\u7684\u68c0\u6d4b\u6743\u8861\uff0cBethe Hessian\u7b97\u5b50\u5b9e\u73b0\u4e86\u9ad8\u6548\u8c31\u805a\u7c7b\uff0c\u5b9e\u8bc1\u5e94\u7528\u9a8c\u8bc1\u4e86\u7406\u8bba\u7684\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2601.09712", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.09712", "abs": "https://arxiv.org/abs/2601.09712", "authors": ["Frederik Zuiderveen Borgesius"], "title": "Behavioral Targeting, a European Legal Perspective", "comment": null, "summary": "Behavioral targeting, or online profiling, is a hotly debated topic. Much of the collection of personal information on the Internet is related to behavioral targeting, although research suggests that most people don't want to receive behaviorally targeted advertising. The World Wide Web Consortium is discussing a Do Not Track standard, and regulators worldwide are struggling to come up with answers. This article discusses European law and recent policy developments on behavioral targeting.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u6b27\u6d32\u6cd5\u5f8b\u548c\u653f\u7b56\u5bf9\u884c\u4e3a\u5b9a\u5411\u5e7f\u544a\uff08\u5728\u7ebf\u7528\u6237\u753b\u50cf\uff09\u7684\u76d1\u7ba1\u53d1\u5c55\uff0c\u63a2\u8ba8\u4e86\u5f53\u524d\u5173\u4e8e\"\u8bf7\u52ff\u8ffd\u8e2a\"\u6807\u51c6\u7684\u8ba8\u8bba\u548c\u76d1\u7ba1\u6311\u6218\u3002", "motivation": "\u884c\u4e3a\u5b9a\u5411\u5e7f\u544a\uff08\u5728\u7ebf\u7528\u6237\u753b\u50cf\uff09\u662f\u4e00\u4e2a\u5907\u53d7\u4e89\u8bae\u7684\u8bdd\u9898\uff0c\u5c3d\u7ba1\u7814\u7a76\u8868\u660e\u5927\u591a\u6570\u4eba\u4e0d\u5e0c\u671b\u63a5\u6536\u884c\u4e3a\u5b9a\u5411\u5e7f\u544a\uff0c\u4f46\u4e92\u8054\u7f51\u4e0a\u5927\u91cf\u4e2a\u4eba\u4fe1\u606f\u6536\u96c6\u4e0e\u6b64\u76f8\u5173\u3002\u4e07\u7ef4\u7f51\u8054\u76df\u6b63\u5728\u8ba8\u8bba\"\u8bf7\u52ff\u8ffd\u8e2a\"\u6807\u51c6\uff0c\u5168\u7403\u76d1\u7ba1\u673a\u6784\u4e5f\u5728\u52aa\u529b\u5bfb\u627e\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u91c7\u7528\u6cd5\u5f8b\u548c\u653f\u7b56\u5206\u6790\u65b9\u6cd5\uff0c\u91cd\u70b9\u8ba8\u8bba\u6b27\u6d32\u6cd5\u5f8b\u6846\u67b6\u548c\u8fd1\u671f\u653f\u7b56\u53d1\u5c55\uff0c\u5206\u6790\u884c\u4e3a\u5b9a\u5411\u5e7f\u544a\u7684\u76d1\u7ba1\u73b0\u72b6\u548c\u6311\u6218\u3002", "result": "\u6587\u7ae0\u63ed\u793a\u4e86\u884c\u4e3a\u5b9a\u5411\u5e7f\u544a\u5728\u6b27\u6d32\u7684\u6cd5\u5f8b\u76d1\u7ba1\u73b0\u72b6\uff0c\u5305\u62ec\u4e07\u7ef4\u7f51\u8054\u76df\"\u8bf7\u52ff\u8ffd\u8e2a\"\u6807\u51c6\u7684\u8ba8\u8bba\u8fdb\u5c55\uff0c\u4ee5\u53ca\u76d1\u7ba1\u673a\u6784\u5728\u5e73\u8861\u5546\u4e1a\u5229\u76ca\u548c\u4e2a\u4eba\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u9762\u4e34\u7684\u56f0\u5883\u3002", "conclusion": "\u884c\u4e3a\u5b9a\u5411\u5e7f\u544a\u7684\u76d1\u7ba1\u662f\u4e00\u4e2a\u590d\u6742\u4e14\u6301\u7eed\u53d1\u5c55\u7684\u9886\u57df\uff0c\u6b27\u6d32\u6cd5\u5f8b\u548c\u653f\u7b56\u5236\u5b9a\u8005\u6b63\u5728\u52aa\u529b\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u4f46\u9700\u8981\u5728\u6280\u672f\u521b\u65b0\u3001\u5546\u4e1a\u5229\u76ca\u548c\u4e2a\u4eba\u9690\u79c1\u4fdd\u62a4\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002"}}
{"id": "2601.10006", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2601.10006", "abs": "https://arxiv.org/abs/2601.10006", "authors": ["Peter Maurice Catt"], "title": "The Knowable Future: Mapping the Decay of Past-Future Mutual Information Across Forecast Horizons", "comment": "19 pages with 5 figures", "summary": "The ability to assess ex-ante whether a time series is likely to be accurately forecast is important for forecasting practice because it informs the degree of modelling effort warranted. We define forecastability as a property of a time series (given a declared information set), and measure horizon-specific forecastability as the reduction in uncertainty provided by the past, using auto-mutual information (AMI) at lag h. AMI is estimated from training data using a k-nearest-neighbour estimator and evaluated against out-of-sample forecast error (sMAPE) on a filtered, balanced sample of 1,350 M4 series across six sampling frequencies. Seasonal Naive, ETS, and N-BEATS are used as probes of out-of-sample forecast performance. Training-only AMI provides a frequency-conditional diagnostic for forecast difficulty: for Hourly, Weekly, Quarterly, and Yearly series, AMI exhibits consistently negative rank correlation with sMAPE across probes. Under N-BEATS, the correlation is strongest for Hourly (p= -0.52) and Weekly (p= -0.51), with Quarterly (p= -0.42) and Yearly (p = -0.36) also substantial. Monthly is probe-dependent (Seasonal Naive p= -0.12; ETS p = -0.26; N-BEATS p = -0.24). Daily shows notably weaker AMI-sMAPE correlation under this protocol, suggesting limited ability to discriminate between series despite the presence of temporal dependence. The findings support within-frequency triage and effort allocation based on measurable signal content prior to forecasting, rather than between-frequency comparisons of difficulty.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u6ede\u540eh\u7684\u81ea\u4e92\u4fe1\u606f\uff08AMI\uff09\u4f5c\u4e3a\u65f6\u95f4\u5e8f\u5217\u53ef\u9884\u6d4b\u6027\u7684\u5ea6\u91cf\uff0c\u901a\u8fc7k\u8fd1\u90bb\u4f30\u8ba1\u5668\u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u4f30\u8ba1\uff0c\u5e76\u4e0e\u6837\u672c\u5916\u9884\u6d4b\u8bef\u5dee\uff08sMAPE\uff09\u8fdb\u884c\u76f8\u5173\u6027\u5206\u6790\uff0c\u53d1\u73b0AMI\u80fd\u6709\u6548\u8bca\u65ad\u4e0d\u540c\u9891\u7387\u65f6\u95f4\u5e8f\u5217\u7684\u9884\u6d4b\u96be\u5ea6\u3002", "motivation": "\u5728\u9884\u6d4b\u5b9e\u8df5\u4e2d\uff0c\u4e8b\u5148\u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u662f\u5426\u53ef\u80fd\u88ab\u51c6\u786e\u9884\u6d4b\u975e\u5e38\u91cd\u8981\uff0c\u56e0\u4e3a\u8fd9\u51b3\u5b9a\u4e86\u9700\u8981\u6295\u5165\u7684\u5efa\u6a21\u52aa\u529b\u7a0b\u5ea6\u3002\u5f53\u524d\u7f3a\u4e4f\u5bf9\u65f6\u95f4\u5e8f\u5217\u53ef\u9884\u6d4b\u6027\u7684\u91cf\u5316\u5ea6\u91cf\u65b9\u6cd5\uff0c\u65e0\u6cd5\u5728\u9884\u6d4b\u524d\u6709\u6548\u8bc4\u4f30\u5e8f\u5217\u7684\u9884\u6d4b\u96be\u5ea6\u3002", "method": "\u5b9a\u4e49\u53ef\u9884\u6d4b\u6027\u4e3a\u65f6\u95f4\u5e8f\u5217\u7684\u5c5e\u6027\uff08\u7ed9\u5b9a\u58f0\u660e\u4fe1\u606f\u96c6\uff09\uff0c\u4f7f\u7528\u6ede\u540eh\u7684\u81ea\u4e92\u4fe1\u606f\uff08AMI\uff09\u4f5c\u4e3a\u7279\u5b9a\u9884\u6d4b\u65f6\u57df\u7684\u4e0d\u786e\u5b9a\u6027\u51cf\u5c11\u5ea6\u91cf\u3002\u901a\u8fc7k\u8fd1\u90bb\u4f30\u8ba1\u5668\u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u4f30\u8ba1AMI\uff0c\u5e76\u5728\u8fc7\u6ee4\u540e\u7684\u5e73\u8861\u6837\u672c\uff081,350\u4e2aM4\u5e8f\u5217\uff0c6\u79cd\u91c7\u6837\u9891\u7387\uff09\u4e0a\u8bc4\u4f30\u5176\u4e0e\u6837\u672c\u5916\u9884\u6d4b\u8bef\u5dee\uff08sMAPE\uff09\u7684\u76f8\u5173\u6027\u3002\u4f7f\u7528Seasonal Naive\u3001ETS\u548cN-BEATS\u4f5c\u4e3a\u6837\u672c\u5916\u9884\u6d4b\u6027\u80fd\u7684\u63a2\u9488\u3002", "result": "\u8bad\u7ec3\u6570\u636e\u7684AMI\u63d0\u4f9b\u4e86\u9891\u7387\u6761\u4ef6\u6027\u7684\u9884\u6d4b\u96be\u5ea6\u8bca\u65ad\uff1a\u5bf9\u4e8e\u5c0f\u65f6\u3001\u5468\u3001\u5b63\u5ea6\u548c\u5e74\u5ea6\u5e8f\u5217\uff0cAMI\u4e0esMAPE\u5728\u6240\u6709\u63a2\u9488\u4e2d\u5747\u663e\u793a\u4e00\u81f4\u7684\u8d1f\u79e9\u76f8\u5173\u3002\u5728N-BEATS\u4e0b\uff0c\u5c0f\u65f6\u5e8f\u5217\uff08\u03c1=-0.52\uff09\u548c\u5468\u5e8f\u5217\uff08\u03c1=-0.51\uff09\u76f8\u5173\u6027\u6700\u5f3a\uff0c\u5b63\u5ea6\uff08\u03c1=-0.42\uff09\u548c\u5e74\u5ea6\uff08\u03c1=-0.36\uff09\u4e5f\u663e\u8457\u3002\u6708\u5ea6\u5e8f\u5217\u76f8\u5173\u6027\u4f9d\u8d56\u4e8e\u63a2\u9488\uff08Seasonal Naive \u03c1=-0.12\uff1bETS \u03c1=-0.26\uff1bN-BEATS \u03c1=-0.24\uff09\u3002\u65e5\u5e8f\u5217\u5728\u6b64\u534f\u8bae\u4e0b\u663e\u793a\u8f83\u5f31\u7684AMI-sMAPE\u76f8\u5173\u6027\uff0c\u8868\u660e\u5c3d\u7ba1\u5b58\u5728\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u4f46\u533a\u5206\u5e8f\u5217\u7684\u80fd\u529b\u6709\u9650\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301\u57fa\u4e8e\u53ef\u6d4b\u91cf\u7684\u4fe1\u53f7\u5185\u5bb9\u5728\u9884\u6d4b\u524d\u8fdb\u884c\u9891\u7387\u5185\u5206\u7c7b\u548c\u52aa\u529b\u5206\u914d\uff0c\u800c\u4e0d\u662f\u8fdb\u884c\u9891\u7387\u95f4\u7684\u96be\u5ea6\u6bd4\u8f83\u3002AMI\u53ef\u4f5c\u4e3a\u6709\u6548\u7684\u9884\u6d4b\u96be\u5ea6\u8bca\u65ad\u5de5\u5177\uff0c\u5e2e\u52a9\u5728\u5b9e\u9645\u9884\u6d4b\u524d\u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u7684\u53ef\u9884\u6d4b\u6027\u3002"}}
{"id": "2601.09999", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.09999", "abs": "https://arxiv.org/abs/2601.09999", "authors": ["Chu-An Liu", "Andrey L. Vasnev"], "title": "Corrected Forecast Combinations", "comment": null, "summary": "This paper proposes corrected forecast combinations when the original combined forecast errors are serially dependent. Motivated by the classic Bates and Granger (1969) example, we show that combined forecast errors can be strongly autocorrelated and that a simple correction--adding a fraction of the previous combined error to the next-period combined forecast--can deliver sizable improvements in forecast accuracy, often exceeding the original gains from combining. We formalize the approach within the conditional risk framework of Gibbs and Vasnev (2024), in which the combined error decomposes into a predictable component (measurable at the forecast origin) and an innovation. We then link this correction to efficient estimation of combination weights under time-series dependence via GLS, allowing joint estimation of weights and an error-covariance structure. Using the U.S. Survey of Professional Forecasters for major macroeconomic indices across various subsamples (including pre and post-2000, GFC, and COVID), we find that a parsimonious correction of the mean forecast with a coefficient around 0.5 is a robust starting point and often yields material improvements in forecast accuracy. For optimal-weight forecasts, the correction substantially mitigates the forecast combination puzzle by turning poorly performing out-of-sample optimal-weight combinations into competitive forecasts.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4fee\u6b63\u9884\u6d4b\u7ec4\u5408\u7684\u65b9\u6cd5\uff0c\u5f53\u539f\u59cb\u7ec4\u5408\u9884\u6d4b\u8bef\u5dee\u5b58\u5728\u5e8f\u5217\u4f9d\u8d56\u65f6\uff0c\u901a\u8fc7\u6dfb\u52a0\u524d\u4e00\u671f\u7ec4\u5408\u8bef\u5dee\u7684\u4e00\u90e8\u5206\u6765\u4fee\u6b63\u4e0b\u4e00\u671f\u9884\u6d4b\uff0c\u53ef\u663e\u8457\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u7ecf\u5178Bates\u548cGranger(1969)\u7684\u4f8b\u5b50\u8868\u660e\uff0c\u7ec4\u5408\u9884\u6d4b\u8bef\u5dee\u53ef\u80fd\u5b58\u5728\u5f3a\u81ea\u76f8\u5173\u6027\u3002\u5f53\u9884\u6d4b\u8bef\u5dee\u5b58\u5728\u5e8f\u5217\u4f9d\u8d56\u65f6\uff0c\u539f\u59cb\u7ec4\u5408\u9884\u6d4b\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u5229\u7528\u8bef\u5dee\u4e2d\u7684\u53ef\u9884\u6d4b\u4fe1\u606f\uff0c\u5bfc\u81f4\u9884\u6d4b\u7cbe\u5ea6\u4e0b\u964d\u3002", "method": "\u5728Gibbs\u548cVasnev(2024)\u7684\u6761\u4ef6\u98ce\u9669\u6846\u67b6\u4e0b\uff0c\u5c06\u7ec4\u5408\u8bef\u5dee\u5206\u89e3\u4e3a\u53ef\u9884\u6d4b\u6210\u5206\u548c\u521b\u65b0\u9879\u3002\u901a\u8fc7\u6dfb\u52a0\u524d\u4e00\u671f\u7ec4\u5408\u8bef\u5dee\u7684\u4e00\u90e8\u5206\u6765\u4fee\u6b63\u9884\u6d4b\uff0c\u5e76\u5c06\u6b64\u4fee\u6b63\u4e0eGLS\u4f30\u8ba1\u4e0b\u7684\u6743\u91cd\u4f18\u5316\u8054\u7cfb\u8d77\u6765\uff0c\u8054\u5408\u4f30\u8ba1\u7ec4\u5408\u6743\u91cd\u548c\u8bef\u5dee\u534f\u65b9\u5dee\u7ed3\u6784\u3002", "result": "\u4f7f\u7528\u7f8e\u56fd\u4e13\u4e1a\u9884\u6d4b\u8005\u8c03\u67e5\u6570\u636e\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u53d1\u73b0\uff1a1) \u5bf9\u5747\u503c\u9884\u6d4b\u8fdb\u884c\u7cfb\u6570\u7ea60.5\u7684\u7b80\u7ea6\u4fee\u6b63\u901a\u5e38\u80fd\u663e\u8457\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff1b2) \u5bf9\u4e8e\u6700\u4f18\u6743\u91cd\u9884\u6d4b\uff0c\u8be5\u4fee\u6b63\u80fd\u6709\u6548\u7f13\u89e3\"\u9884\u6d4b\u7ec4\u5408\u8c1c\u9898\"\uff0c\u5c06\u8868\u73b0\u4e0d\u4f73\u7684\u6700\u4f18\u6743\u91cd\u7ec4\u5408\u8f6c\u53d8\u4e3a\u5177\u6709\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u3002", "conclusion": "\u5f53\u7ec4\u5408\u9884\u6d4b\u8bef\u5dee\u5b58\u5728\u5e8f\u5217\u4f9d\u8d56\u65f6\uff0c\u7b80\u5355\u7684\u8bef\u5dee\u4fee\u6b63\u65b9\u6cd5\u80fd\u5e26\u6765\u663e\u8457\u7684\u9884\u6d4b\u7cbe\u5ea6\u63d0\u5347\uff0c\u751a\u81f3\u8d85\u8fc7\u539f\u59cb\u7ec4\u5408\u9884\u6d4b\u7684\u6536\u76ca\u3002\u8be5\u65b9\u6cd5\u4e3a\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u4f9d\u8d56\u4e0b\u7684\u9884\u6d4b\u7ec4\u5408\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2601.09770", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09770", "abs": "https://arxiv.org/abs/2601.09770", "authors": ["Chen Chen", "Jiawei Shao", "Dakuan Lu", "Haoyi Hu", "Xiangcheng Liu", "Hantao Yao", "Wu Liu"], "title": "GUI-Eyes: Tool-Augmented Perception for Visual Grounding in GUI Agents", "comment": null, "summary": "Recent advances in vision-language models (VLMs) and reinforcement learning (RL) have driven progress in GUI automation. However, most existing methods rely on static, one-shot visual inputs and passive perception, lacking the ability to adaptively determine when, whether, and how to observe the interface. We present GUI-Eyes, a reinforcement learning framework for active visual perception in GUI tasks. To acquire more informative observations, the agent learns to make strategic decisions on both whether and how to invoke visual tools, such as cropping or zooming, within a two-stage reasoning process. To support this behavior, we introduce a progressive perception strategy that decomposes decision-making into coarse exploration and fine-grained grounding, coordinated by a two-level policy. In addition, we design a spatially continuous reward function tailored to tool usage, which integrates both location proximity and region overlap to provide dense supervision and alleviate the reward sparsity common in GUI environments. On the ScreenSpot-Pro benchmark, GUI-Eyes-3B achieves 44.8% grounding accuracy using only 3k labeled samples, significantly outperforming both supervised and RL-based baselines. These results highlight that tool-aware active perception, enabled by staged policy reasoning and fine-grained reward feedback, is critical for building robust and data-efficient GUI agents.", "AI": {"tldr": "GUI-Eyes\uff1a\u4e00\u4e2a\u7528\u4e8eGUI\u4efb\u52a1\u7684\u4e3b\u52a8\u89c6\u89c9\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u63a8\u7406\u5b66\u4e60\u7b56\u7565\u6027\u5730\u51b3\u5b9a\u662f\u5426\u53ca\u5982\u4f55\u4f7f\u7528\u89c6\u89c9\u5de5\u5177\uff08\u5982\u88c1\u526a\u3001\u7f29\u653e\uff09\uff0c\u5728ScreenSpot-Pro\u57fa\u51c6\u4e0a\u4ec5\u75283k\u6807\u6ce8\u6837\u672c\u8fbe\u523044.8%\u7684\u5b9a\u4f4d\u51c6\u786e\u7387\u3002", "motivation": "\u5f53\u524dGUI\u81ea\u52a8\u5316\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u9759\u6001\u3001\u4e00\u6b21\u6027\u89c6\u89c9\u8f93\u5165\u548c\u88ab\u52a8\u611f\u77e5\uff0c\u7f3a\u4e4f\u81ea\u9002\u5e94\u51b3\u5b9a\u4f55\u65f6\u3001\u662f\u5426\u4ee5\u53ca\u5982\u4f55\u89c2\u5bdf\u754c\u9762\u7684\u80fd\u529b\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4e3b\u52a8\u83b7\u53d6\u4fe1\u606f\u6027\u89c2\u5bdf\u7684GUI\u4ee3\u7406\u3002", "method": "\u63d0\u51fa\u6e10\u8fdb\u611f\u77e5\u7b56\u7565\uff1a\u5c06\u51b3\u7b56\u5206\u89e3\u4e3a\u7c97\u7c92\u5ea6\u63a2\u7d22\u548c\u7ec6\u7c92\u5ea6\u5b9a\u4f4d\uff0c\u7531\u4e24\u7ea7\u7b56\u7565\u534f\u8c03\u3002\u8bbe\u8ba1\u7a7a\u95f4\u8fde\u7eed\u5956\u52b1\u51fd\u6570\uff0c\u7ed3\u5408\u4f4d\u7f6e\u90bb\u8fd1\u6027\u548c\u533a\u57df\u91cd\u53e0\u5ea6\uff0c\u4e3a\u5de5\u5177\u4f7f\u7528\u63d0\u4f9b\u5bc6\u96c6\u76d1\u7763\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u63a8\u7406\u8fc7\u7a0b\u5b66\u4e60\u7b56\u7565\u6027\u5730\u51b3\u5b9a\u662f\u5426\u53ca\u5982\u4f55\u8c03\u7528\u89c6\u89c9\u5de5\u5177\u3002", "result": "\u5728ScreenSpot-Pro\u57fa\u51c6\u4e0a\uff0cGUI-Eyes-3B\u4ec5\u4f7f\u75283k\u6807\u6ce8\u6837\u672c\u5c31\u8fbe\u523044.8%\u7684\u5b9a\u4f4d\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u76d1\u7763\u5b66\u4e60\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5de5\u5177\u611f\u77e5\u7684\u4e3b\u52a8\u611f\u77e5\uff0c\u901a\u8fc7\u5206\u9636\u6bb5\u7b56\u7565\u63a8\u7406\u548c\u7ec6\u7c92\u5ea6\u5956\u52b1\u53cd\u9988\uff0c\u5bf9\u4e8e\u6784\u5efa\u9c81\u68d2\u4e14\u6570\u636e\u9ad8\u6548\u7684GUI\u4ee3\u7406\u81f3\u5173\u91cd\u8981\u3002GUI-Eyes\u6846\u67b6\u5c55\u793a\u4e86\u5728GUI\u73af\u5883\u4e2d\u4e3b\u52a8\u89c6\u89c9\u611f\u77e5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.10565", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.10565", "abs": "https://arxiv.org/abs/2601.10565", "authors": ["D\u00e1vid Ferenczi", "Jean-Gabriel Young", "Leto Peel"], "title": "Inferring signed social networks from contact patterns", "comment": "12 pages, 5 figures", "summary": "Social networks are typically inferred from indirect observations, such as proximity data; yet, most methods cannot distinguish between absent relationships and actual negative ties, as both can result in few or no interactions. We address the challenge of inferring signed networks from contact patterns while accounting for whether lack of interactions reflect a lack of opportunity as opposed to active avoidance. We develop a Bayesian framework with MCMC inference that models interaction groups to separate chance from choice when no interactions are observed. Validation on synthetic data demonstrates superior performance compared to natural baselines, particularly in detecting negative edges. We apply our method to French high school contact data to reveal a structure consistent with friendship surveys and demonstrate the model's adequacy through posterior predictive checks.", "AI": {"tldr": "\u63d0\u51fa\u8d1d\u53f6\u65af\u6846\u67b6\u4ece\u63a5\u89e6\u6570\u636e\u63a8\u65ad\u5e26\u7b26\u53f7\u7f51\u7edc\uff0c\u533a\u5206\u65e0\u4e92\u52a8\u662f\u7531\u4e8e\u673a\u4f1a\u7f3a\u5931\u8fd8\u662f\u4e3b\u52a8\u56de\u907f", "motivation": "\u793e\u4ea4\u7f51\u7edc\u901a\u5e38\u4ece\u95f4\u63a5\u89c2\u6d4b\u63a8\u65ad\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u533a\u5206\u7f3a\u5931\u5173\u7cfb\u548c\u5b9e\u9645\u8d1f\u5411\u5173\u7cfb\uff0c\u56e0\u4e3a\u4e24\u8005\u90fd\u53ef\u80fd\u5bfc\u81f4\u5f88\u5c11\u6216\u6ca1\u6709\u4e92\u52a8", "method": "\u5f00\u53d1\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u4f7f\u7528MCMC\u63a8\u65ad\uff0c\u5efa\u6a21\u4e92\u52a8\u7ec4\u4ee5\u533a\u5206\u673a\u4f1a\u7f3a\u5931\u548c\u4e3b\u52a8\u9009\u62e9\u5bfc\u81f4\u7684\u96f6\u4e92\u52a8", "result": "\u5408\u6210\u6570\u636e\u9a8c\u8bc1\u663e\u793a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u68c0\u6d4b\u8d1f\u5411\u8fb9\u65b9\u9762\uff1b\u5e94\u7528\u4e8e\u6cd5\u56fd\u9ad8\u4e2d\u63a5\u89e6\u6570\u636e\u63ed\u793a\u4e0e\u53cb\u8c0a\u8c03\u67e5\u4e00\u81f4\u7684\u7ed3\u6784", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u4ece\u63a5\u89e6\u6a21\u5f0f\u63a8\u65ad\u5e26\u7b26\u53f7\u7f51\u7edc\uff0c\u533a\u5206\u673a\u4f1a\u7f3a\u5931\u548c\u4e3b\u52a8\u56de\u907f\uff0c\u5e76\u901a\u8fc7\u540e\u9a8c\u9884\u6d4b\u68c0\u67e5\u8bc1\u660e\u6a21\u578b\u5145\u5206\u6027"}}
{"id": "2601.09739", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.09739", "abs": "https://arxiv.org/abs/2601.09739", "authors": ["Stefan Kulk", "Frederik Zuiderveen Borgesius"], "title": "Filtering for Copyright Enforcement in Europe after the Sabam cases", "comment": null, "summary": "Sabam, a Belgian collective rights management organisation, wanted an internet access provider and a social network site to install a filter system to enforce copyrights. In two recent judgments, the Court of Justice of the European Union decided that the social network site and the internet access provider cannot be required to install the filter system that Sabam asked for. Are these judgments good news for fundamental rights? This article argues that little is won for privacy and freedom of information.", "AI": {"tldr": "\u6b27\u76df\u6cd5\u9662\u5224\u51b3\u793e\u4ea4\u7f51\u7edc\u548c\u7f51\u7edc\u670d\u52a1\u63d0\u4f9b\u5546\u65e0\u9700\u5b89\u88c5\u7248\u6743\u8fc7\u6ee4\u7cfb\u7edf\uff0c\u4f46\u8fd9\u5bf9\u57fa\u672c\u6743\u5229\u4fdd\u62a4\u7684\u5b9e\u9645\u610f\u4e49\u6709\u9650", "motivation": "\u5206\u6790\u6b27\u76df\u6cd5\u9662\u5173\u4e8e\u7248\u6743\u8fc7\u6ee4\u7cfb\u7edf\u8981\u6c42\u7684\u5224\u51b3\u5bf9\u57fa\u672c\u6743\u5229\uff08\u9690\u79c1\u548c\u4fe1\u606f\u81ea\u7531\uff09\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u63a2\u8ba8\u8fd9\u4e9b\u5224\u51b3\u662f\u5426\u771f\u6b63\u4fdd\u62a4\u4e86\u7528\u6237\u6743\u5229", "method": "\u901a\u8fc7\u5206\u6790\u6b27\u76df\u6cd5\u9662\u7684\u4e24\u4e2a\u6700\u65b0\u5224\u51b3\uff0c\u8bc4\u4f30\u7248\u6743\u96c6\u4f53\u7ba1\u7406\u7ec4\u7ec7Sabam\u8981\u6c42\u5b89\u88c5\u8fc7\u6ee4\u7cfb\u7edf\u7684\u8bc9\u6c42\u88ab\u9a73\u56de\u540e\uff0c\u5bf9\u9690\u79c1\u548c\u4fe1\u606f\u81ea\u7531\u6743\u5229\u7684\u5b9e\u9645\u4fdd\u62a4\u6548\u679c", "result": "\u867d\u7136\u6b27\u76df\u6cd5\u9662\u5224\u51b3\u793e\u4ea4\u7f51\u7edc\u548c\u7f51\u7edc\u670d\u52a1\u63d0\u4f9b\u5546\u65e0\u9700\u5b89\u88c5\u7248\u6743\u8fc7\u6ee4\u7cfb\u7edf\uff0c\u4f46\u8fd9\u5bf9\u9690\u79c1\u548c\u4fe1\u606f\u81ea\u7531\u6743\u5229\u7684\u5b9e\u9645\u4fdd\u62a4\u4f5c\u7528\u6709\u9650\uff0c\u57fa\u672c\u6743\u5229\u5e76\u672a\u56e0\u6b64\u83b7\u5f97\u5b9e\u8d28\u6027\u80dc\u5229", "conclusion": "\u6b27\u76df\u6cd5\u9662\u7684\u5224\u51b3\u8868\u9762\u4e0a\u662f\u7f51\u7edc\u670d\u52a1\u63d0\u4f9b\u5546\u7684\u80dc\u5229\uff0c\u4f46\u5bf9\u7528\u6237\u57fa\u672c\u6743\u5229\u7684\u4fdd\u62a4\u610f\u4e49\u6709\u9650\uff0c\u9690\u79c1\u548c\u4fe1\u606f\u81ea\u7531\u5e76\u672a\u56e0\u6b64\u83b7\u5f97\u5b9e\u8d28\u6027\u4fdd\u969c"}}
{"id": "2601.10445", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2601.10445", "abs": "https://arxiv.org/abs/2601.10445", "authors": ["Glenna Nightingale", "Karthik Mohan", "Eloi Ribe", "Valentin Popov", "Shakes Wang", "Clara Calia", "Luciana Brondi", "Sohan Seth"], "title": "Modeling mental health trajectories during the COVID-19 pandemic using UK-wide data in the presence of sociodemographic variables", "comment": "5 figures", "summary": "Background: The negative effects of the COVID-19 pandemic on the mental health and well-being of populations are an important public health issue. Our study aims to determine the underlying factors shaping mental health trajectories during the COVID-19 pandemic in the UK. Methods: Data from the Understanding Society COVID-19 Study were utilized and the core analysis focussed on GHQ36 scores as the outcome variable. We used GAMs to evaluate trends over time and the role of sociodemographic variables, i.e., age, sex, ethnicity, country of residence (in UK), job status (employment), household income, living with a partner, living with children under age 16, and living with a long-term illness, on the variation of mental health during the study period. Results: Statistically significant differences in mental health were observed for age, sex,ethnicity, country of residence (in UK), job status (employment), household income, living with a partner, living with children under age 16, and living with a long-term illness. Women experienced higher GHQ36 scores relative to men with the GHQ36 score expected to increase by 1.260 (95%CI: 1.176, 1.345). Individuals living without a partner were expected to have higher GHQ36 scores, of 1.050 (95%CI: 0.949, 1.148) more than those living with a partner, and age groups 16-34, 35-44, 45-54, 55-64 experienced higher GHQ36 scores relative to those who were 65+. Individuals with relatively lower household income were likely to have poorer mental health relative to those who were more well off. Conclusion: This study identifies key demographic determinants shaping mental health trajectories during the COVID-19 pandemic in the UK. Policies aiming to reduce mental health inequalities should target women, youth, individuals living without a partner, individuals living with children under 16, individuals with a long-term illness, and lower income families.", "AI": {"tldr": "\u82f1\u56fdCOVID-19\u75ab\u60c5\u671f\u95f4\u5fc3\u7406\u5065\u5eb7\u8f68\u8ff9\u7684\u4eba\u53e3\u7edf\u8ba1\u5b66\u5f71\u54cd\u56e0\u7d20\u7814\u7a76", "motivation": "COVID-19\u5927\u6d41\u884c\u5bf9\u4eba\u7fa4\u5fc3\u7406\u5065\u5eb7\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u9700\u8981\u786e\u5b9a\u5f71\u54cd\u82f1\u56fd\u75ab\u60c5\u671f\u95f4\u5fc3\u7406\u5065\u5eb7\u8f68\u8ff9\u7684\u6f5c\u5728\u56e0\u7d20\uff0c\u4e3a\u516c\u5171\u536b\u751f\u653f\u7b56\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u4f7f\u7528Understanding Society COVID-19\u7814\u7a76\u6570\u636e\uff0c\u4ee5GHQ36\u8bc4\u5206\u4e3a\u7ed3\u679c\u53d8\u91cf\uff0c\u91c7\u7528\u5e7f\u4e49\u52a0\u6027\u6a21\u578b(GAMs)\u5206\u6790\u65f6\u95f4\u8d8b\u52bf\u53ca\u4eba\u53e3\u7edf\u8ba1\u5b66\u53d8\u91cf\uff08\u5e74\u9f84\u3001\u6027\u522b\u3001\u79cd\u65cf\u3001\u5c45\u4f4f\u5730\u3001\u5c31\u4e1a\u72b6\u51b5\u3001\u5bb6\u5ead\u6536\u5165\u3001\u4f34\u4fa3\u72b6\u51b5\u3001\u6709\u65e016\u5c81\u4ee5\u4e0b\u5b50\u5973\u3001\u957f\u671f\u75be\u75c5\uff09\u5bf9\u5fc3\u7406\u5065\u5eb7\u53d8\u5316\u7684\u5f71\u54cd\u3002", "result": "\u6240\u6709\u4eba\u53e3\u7edf\u8ba1\u5b66\u53d8\u91cf\u5747\u663e\u793a\u5bf9\u5fc3\u7406\u5065\u5eb7\u6709\u663e\u8457\u5f71\u54cd\uff1a\u5973\u6027GHQ36\u8bc4\u5206\u6bd4\u7537\u6027\u9ad81.260\u5206\uff1b\u65e0\u4f34\u4fa3\u8005\u8bc4\u5206\u6bd4\u6709\u4f34\u4fa3\u8005\u9ad81.050\u5206\uff1b16-64\u5c81\u5404\u5e74\u9f84\u6bb5\u8bc4\u5206\u5747\u9ad8\u4e8e65\u5c81\u4ee5\u4e0a\u8005\uff1b\u8f83\u4f4e\u5bb6\u5ead\u6536\u5165\u8005\u5fc3\u7406\u5065\u5eb7\u72b6\u51b5\u8f83\u5dee\u3002", "conclusion": "\u7814\u7a76\u786e\u5b9a\u4e86\u82f1\u56fdCOVID-19\u75ab\u60c5\u671f\u95f4\u5fc3\u7406\u5065\u5eb7\u8f68\u8ff9\u7684\u5173\u952e\u4eba\u53e3\u7edf\u8ba1\u5b66\u51b3\u5b9a\u56e0\u7d20\u3002\u51cf\u5c11\u5fc3\u7406\u5065\u5eb7\u4e0d\u5e73\u7b49\u7684\u653f\u7b56\u5e94\u9488\u5bf9\u5973\u6027\u3001\u5e74\u8f7b\u4eba\u3001\u65e0\u4f34\u4fa3\u8005\u3001\u670916\u5c81\u4ee5\u4e0b\u5b50\u5973\u8005\u3001\u957f\u671f\u75be\u75c5\u60a3\u8005\u548c\u4f4e\u6536\u5165\u5bb6\u5ead\u3002"}}
{"id": "2601.10279", "categories": ["econ.EM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.10279", "abs": "https://arxiv.org/abs/2601.10279", "authors": ["Guanhao Feng", "Wei Lan", "Hansheng Wang", "Jun Zhang"], "title": "Selecting and Testing Asset Pricing Models: A Stepwise Approach", "comment": "Accepted by Management Science", "summary": "The asset pricing literature emphasizes factor models that minimize pricing errors but overlooks unselected candidate factors that could enhance the performance of test assets. This paper proposes a framework for factor model selection and testing by (i) selecting the optimal model that spans the joint efficient frontier of test assets and all candidate factors, and (ii) testing pricing performance on both test assets and unselected candidate factors. Our framework updates a baseline model (e.g., CAPM) sequentially by adding or removing factors based on asset pricing tests. Ensuring model selection consistency, our framework utilizes the asset pricing duality: minimizing cross-sectionally unexplained pricing errors aligns with maximizing the Sharpe ratio of the selected factor model. Empirical evidence shows that workhorse factor models fail asset pricing tests, whereas our proposed 8-factor model is not rejected and exhibits robust out-of-sample performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u56e0\u5b50\u6a21\u578b\u9009\u62e9\u4e0e\u68c0\u9a8c\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u80fd\u8de8\u8d8a\u6d4b\u8bd5\u8d44\u4ea7\u548c\u6240\u6709\u5019\u9009\u56e0\u5b50\u8054\u5408\u6709\u6548\u524d\u6cbf\u7684\u6700\u4f18\u6a21\u578b\uff0c\u5e76\u5728\u6d4b\u8bd5\u8d44\u4ea7\u548c\u672a\u9009\u5019\u9009\u56e0\u5b50\u4e0a\u68c0\u9a8c\u5b9a\u4ef7\u6027\u80fd", "motivation": "\u73b0\u6709\u8d44\u4ea7\u5b9a\u4ef7\u6587\u732e\u5f3a\u8c03\u6700\u5c0f\u5316\u5b9a\u4ef7\u8bef\u5dee\u7684\u56e0\u5b50\u6a21\u578b\uff0c\u4f46\u5ffd\u89c6\u4e86\u672a\u9009\u5019\u9009\u56e0\u5b50\u53ef\u80fd\u63d0\u5347\u6d4b\u8bd5\u8d44\u4ea7\u6027\u80fd\u7684\u95ee\u9898", "method": "\u63d0\u51fa\u6846\u67b6\uff1a(1)\u9009\u62e9\u8de8\u8d8a\u6d4b\u8bd5\u8d44\u4ea7\u548c\u6240\u6709\u5019\u9009\u56e0\u5b50\u8054\u5408\u6709\u6548\u524d\u6cbf\u7684\u6700\u4f18\u6a21\u578b\uff1b(2)\u5728\u6d4b\u8bd5\u8d44\u4ea7\u548c\u672a\u9009\u5019\u9009\u56e0\u5b50\u4e0a\u68c0\u9a8c\u5b9a\u4ef7\u6027\u80fd\u3002\u901a\u8fc7\u8d44\u4ea7\u5b9a\u4ef7\u5bf9\u5076\u6027\u786e\u4fdd\u6a21\u578b\u9009\u62e9\u4e00\u81f4\u6027\uff0c\u5e76\u57fa\u4e8e\u8d44\u4ea7\u5b9a\u4ef7\u68c0\u9a8c\u987a\u5e8f\u66f4\u65b0\u57fa\u51c6\u6a21\u578b", "result": "\u5b9e\u8bc1\u8bc1\u636e\u8868\u660e\uff0c\u4e3b\u6d41\u56e0\u5b50\u6a21\u578b\u672a\u80fd\u901a\u8fc7\u8d44\u4ea7\u5b9a\u4ef7\u68c0\u9a8c\uff0c\u800c\u63d0\u51fa\u76848\u56e0\u5b50\u6a21\u578b\u672a\u88ab\u62d2\u7edd\uff0c\u5e76\u5c55\u73b0\u51fa\u7a33\u5065\u7684\u6837\u672c\u5916\u6027\u80fd", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u540c\u65f6\u8003\u8651\u6d4b\u8bd5\u8d44\u4ea7\u548c\u672a\u9009\u5019\u9009\u56e0\u5b50\uff0c\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u56e0\u5b50\u6a21\u578b\u9009\u62e9\u548c\u68c0\u9a8c\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6587\u732e\u7684\u5c40\u9650\u6027"}}
{"id": "2601.09771", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09771", "abs": "https://arxiv.org/abs/2601.09771", "authors": ["Aradhya Dixit", "Shreem Dixit"], "title": "PCN-Rec: Agentic Proof-Carrying Negotiation for Reliable Governance-Constrained Recommendation", "comment": null, "summary": "Modern LLM-based recommenders can generate compelling ranked lists, but they struggle to reliably satisfy governance constraints such as minimum long-tail exposure or diversity requirements. We present PCN-Rec, a proof-carrying negotiation pipeline that separates natural-language reasoning from deterministic enforcement. A base recommender (MF/CF) produces a candidate window of size W, which is negotiated by two agents: a User Advocate optimizing relevance and a Policy Agent enforcing constraints. A mediator LLM synthesizes a top-N slate together with a structured certificate (JSON) describing the claimed constraint satisfaction. A deterministic verifier recomputes all constraints from the slate and accepts only verifier-checked certificates; if verification fails, a deterministic constrained-greedy repair produces a compliant slate for re-verification, yielding an auditable trace. On MovieLens-100K with governance constraints, PCN-Rec achieves a 98.55% pass rate on feasible users (n = 551, W = 80) versus a one-shot single-LLM baseline without verification/repair, while preserving utility with only a 0.021 absolute drop in NDCG@10 (0.403 vs. 0.424); differences are statistically significant (p < 0.05).", "AI": {"tldr": "PCN-Rec\u662f\u4e00\u4e2a\u8bc1\u660e\u643a\u5e26\u7684\u534f\u5546\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u79bb\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u548c\u786e\u5b9a\u6027\u7ea6\u675f\u6267\u884c\uff0c\u53ef\u9760\u5730\u6ee1\u8db3\u6cbb\u7406\u7ea6\u675f\uff08\u5982\u957f\u5c3e\u66dd\u5149\u548c\u591a\u6837\u6027\u8981\u6c42\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u8350\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eLLM\u7684\u63a8\u8350\u7cfb\u7edf\u867d\u7136\u80fd\u751f\u6210\u6709\u5438\u5f15\u529b\u7684\u6392\u540d\u5217\u8868\uff0c\u4f46\u5728\u53ef\u9760\u6ee1\u8db3\u6cbb\u7406\u7ea6\u675f\uff08\u5982\u6700\u5c0f\u957f\u5c3e\u66dd\u5149\u3001\u591a\u6837\u6027\u8981\u6c42\uff09\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u63a8\u8350\u76f8\u5173\u6027\uff0c\u53c8\u80fd\u786e\u4fdd\u7ea6\u675f\u6ee1\u8db3\u7684\u53ef\u9a8c\u8bc1\u65b9\u6cd5\u3002", "method": "PCN-Rec\u91c7\u7528\u8bc1\u660e\u643a\u5e26\u7684\u534f\u5546\u7ba1\u9053\uff1a1\uff09\u57fa\u7840\u63a8\u8350\u5668\uff08MF/CF\uff09\u751f\u6210\u5019\u9009\u7a97\u53e3\uff1b2\uff09\u4e24\u4e2a\u4ee3\u7406\u8fdb\u884c\u534f\u5546\uff1a\u7528\u6237\u5021\u5bfc\u8005\u4f18\u5316\u76f8\u5173\u6027\uff0c\u7b56\u7565\u4ee3\u7406\u6267\u884c\u7ea6\u675f\uff1b3\uff09\u8c03\u89e3LLM\u5408\u6210top-N\u5217\u8868\u53ca\u7ed3\u6784\u5316\u8bc1\u4e66\uff08JSON\uff09\uff1b4\uff09\u786e\u5b9a\u6027\u9a8c\u8bc1\u5668\u91cd\u65b0\u8ba1\u7b97\u6240\u6709\u7ea6\u675f\uff0c\u4ec5\u63a5\u53d7\u9a8c\u8bc1\u901a\u8fc7\u7684\u8bc1\u4e66\uff1b5\uff09\u9a8c\u8bc1\u5931\u8d25\u65f6\uff0c\u786e\u5b9a\u6027\u7ea6\u675f\u8d2a\u5a6a\u4fee\u590d\u751f\u6210\u5408\u89c4\u5217\u8868\u91cd\u65b0\u9a8c\u8bc1\u3002", "result": "\u5728MovieLens-100K\u6570\u636e\u96c6\u4e0a\uff0cPCN-Rec\u5bf9\u53ef\u884c\u7528\u6237\uff08n=551\uff0cW=80\uff09\u5b9e\u73b0\u4e8698.55%\u7684\u901a\u8fc7\u7387\uff0c\u76f8\u6bd4\u6ca1\u6709\u9a8c\u8bc1/\u4fee\u590d\u7684\u5355\u6b21LLM\u57fa\u7ebf\u663e\u8457\u63d0\u5347\u3002\u540c\u65f6\u4fdd\u6301\u63a8\u8350\u6548\u7528\uff0cNDCG@10\u4ec5\u4e0b\u964d0.021\uff080.403 vs. 0.424\uff09\uff0c\u5dee\u5f02\u5177\u6709\u7edf\u8ba1\u663e\u8457\u6027\uff08p<0.05\uff09\u3002", "conclusion": "PCN-Rec\u901a\u8fc7\u8bc1\u660e\u643a\u5e26\u7684\u534f\u5546\u6846\u67b6\uff0c\u6210\u529f\u89e3\u51b3\u4e86LLM\u63a8\u8350\u7cfb\u7edf\u4e2d\u7ea6\u675f\u6ee1\u8db3\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u901a\u8fc7\u7387\u3001\u53ef\u9a8c\u8bc1\u6027\u548c\u63a8\u8350\u8d28\u91cf\u7684\u5e73\u8861\uff0c\u4e3a\u53d7\u6cbb\u7406\u7ea6\u675f\u7684\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u5ba1\u8ba1\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.09753", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09753", "abs": "https://arxiv.org/abs/2601.09753", "authors": ["Carole J. Lee"], "title": "Critically Engaged Pragmatism: A Scientific Norm and Social, Pragmatist Epistemology for AI Science Evaluation Tools", "comment": null, "summary": "Crises in peer review capacity, study replication, and AI-fabricated science have intensified interest in automated tools for assessing scientific research. However, the scientific community has a history of decontextualizing and repurposing credibility markers in inapt ways. I caution that AI science evaluation tools are particularly prone to these kinds of inference by false ascent due to contestation about the purposes to which they should be put, their portability across purposes, and technical demands that prioritize data set size over epistemic fit. To counter this, I argue for a social, pragmatist epistemology and a newly articulated norm of Critically Engaged Pragmatism to enjoin scientific communities to vigorously scrutinize the purposes and purpose-specific reliability of AI science evaluation tools. Under this framework, AI science evaluation tools are not objective arbiters of scientific credibility, but the object of the kinds of critical discursive practices that ground the credibility of scientific communities.", "AI": {"tldr": "\u4f5c\u8005\u8b66\u544aAI\u79d1\u5b66\u8bc4\u4f30\u5de5\u5177\u5b58\u5728\"\u865a\u5047\u4e0a\u5347\u63a8\u7406\"\u98ce\u9669\uff0c\u4e3b\u5f20\u91c7\u7528\u6279\u5224\u6027\u5b9e\u7528\u4e3b\u4e49\u6846\u67b6\uff0c\u5c06AI\u5de5\u5177\u4f5c\u4e3a\u79d1\u5b66\u6279\u5224\u7684\u5bf9\u8c61\u800c\u975e\u5ba2\u89c2\u4ef2\u88c1\u8005", "motivation": "\u9488\u5bf9\u540c\u884c\u8bc4\u5ba1\u5371\u673a\u3001\u7814\u7a76\u53ef\u91cd\u590d\u6027\u95ee\u9898\u548cAI\u4f2a\u9020\u79d1\u5b66\u7b49\u6311\u6218\uff0c\u79d1\u5b66\u754c\u5bf9\u81ea\u52a8\u5316\u8bc4\u4f30\u5de5\u5177\u5174\u8da3\u589e\u52a0\uff0c\u4f46\u5386\u53f2\u8868\u660e\u79d1\u5b66\u754c\u5e38\u5c06\u53ef\u4fe1\u5ea6\u6807\u8bb0\u53bb\u8bed\u5883\u5316\u5e76\u8bef\u7528", "method": "\u63d0\u51fa\u793e\u4f1a\u5b9e\u7528\u4e3b\u4e49\u8ba4\u8bc6\u8bba\u548c\"\u6279\u5224\u6027\u5b9e\u7528\u4e3b\u4e49\"\u65b0\u89c4\u8303\uff0c\u8981\u6c42\u79d1\u5b66\u754c\u4e25\u683c\u5ba1\u67e5AI\u8bc4\u4f30\u5de5\u5177\u7684\u76ee\u7684\u548c\u76ee\u7684\u7279\u5b9a\u53ef\u9760\u6027", "result": "AI\u79d1\u5b66\u8bc4\u4f30\u5de5\u5177\u6613\u53d7\u76ee\u7684\u4e89\u8bae\u3001\u8de8\u76ee\u7684\u53ef\u79fb\u690d\u6027\u95ee\u9898\u4ee5\u53ca\u6280\u672f\u9700\u6c42\u4f18\u5148\u4e8e\u8ba4\u8bc6\u8bba\u9002\u914d\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u865a\u5047\u4e0a\u5347\u63a8\u7406\u98ce\u9669", "conclusion": "AI\u79d1\u5b66\u8bc4\u4f30\u5de5\u5177\u4e0d\u5e94\u88ab\u89c6\u4e3a\u79d1\u5b66\u53ef\u4fe1\u5ea6\u7684\u5ba2\u89c2\u4ef2\u88c1\u8005\uff0c\u800c\u5e94\u6210\u4e3a\u79d1\u5b66\u754c\u6279\u5224\u6027\u8bdd\u8bed\u5b9e\u8df5\u7684\u5bf9\u8c61\uff0c\u901a\u8fc7\u8fd9\u79cd\u5b9e\u8df5\u6765\u786e\u7acb\u79d1\u5b66\u5171\u540c\u4f53\u7684\u53ef\u4fe1\u5ea6"}}
{"id": "2601.10464", "categories": ["stat.AP", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2601.10464", "abs": "https://arxiv.org/abs/2601.10464", "authors": ["Mikkel Meyer Andersen", "Nicole Huber", "Kimberly S Andreaggi", "T\u00f3ra Oluffa Stenberg Olsen", "Walther Parson", "Charla Marshall"], "title": "MitoFREQ: A Novel Approach for Mitogenome Frequency Estimation from Top-level Haplogroups and Single Nucleotide Variants", "comment": null, "summary": "Lineage marker population frequencies can serve as one way to express evidential value in forensic genetics. However, for high-quality whole mitochondrial DNA genome sequences (mitogenomes), population data remain limited. In this paper, we offer a new method, MitoFREQ, for estimating the population frequencies of mitogenomes. MitoFREQ uses the mitogenome resources HelixMTdb and gnomAD, harbouring information from 195,983 and 56,406 mitogenomes, respectively. Neither HelixMTdb nor gnomAD can be queried directly for individual mitogenome frequencies, but offers single nucleotide variant (SNV) allele frequencies for each of 30 \"top-level\" haplogroups (TLHG). We propose using the HelixMTdb and gnomAD resources by classifying a given mitogenome within the TLHG scheme and subsequently using the frequency of its rarest SNV within that TLHG weighted by the TLHG frequency. We show that this method is guaranteed to provide a higher population frequency estimate than if a refined haplogroup and its SNV frequencies were used. Further, we show that top-level haplogrouping can be achieved by using only 227 specific positions for 99.9% of the tested mitogenomes, potentially making the method available for low-quality samples. The method was tested on two types of datasets: high-quality forensic reference datasets and a diverse collection of scrutinised mitogenomes from GenBank. This dual evaluation demonstrated that the approach is robust across both curated forensic data and broader population-level sequences. This method produced likelihood ratios in the range of 100-100,000, demonstrating its potential to strengthen the statistical evaluation of forensic mtDNA evidence. We have developed an open-source R package `mitofreq` that implements our method, including a Shiny app where custom TLHG frequencies can be supplied.", "AI": {"tldr": "\u63d0\u51faMitoFREQ\u65b9\u6cd5\uff0c\u5229\u7528HelixMTdb\u548cgnomAD\u6570\u636e\u5e93\u4f30\u7b97\u7ebf\u7c92\u4f53\u57fa\u56e0\u7ec4\u9891\u7387\uff0c\u901a\u8fc7\u9876\u7ea7\u5355\u500d\u7fa4\u5206\u7c7b\u548c\u7a00\u6709SNV\u9891\u7387\u52a0\u6743\uff0c\u4e3a\u6cd5\u533bDNA\u8bc1\u636e\u63d0\u4f9b\u7edf\u8ba1\u8bc4\u4f30\u3002", "motivation": "\u9ad8\u8d28\u91cf\u5168\u7ebf\u7c92\u4f53DNA\u57fa\u56e0\u7ec4\u5e8f\u5217\uff08mitogenomes\uff09\u5728\u6cd5\u533b\u9057\u4f20\u5b66\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u4f46\u76f8\u5173\u7fa4\u4f53\u6570\u636e\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u4f30\u7b97\u5176\u7fa4\u4f53\u9891\u7387\u4ee5\u8bc4\u4f30\u8bc1\u636e\u4ef7\u503c\u3002", "method": "MitoFREQ\u65b9\u6cd5\uff1a1\uff09\u5c06\u7ed9\u5b9amitogenome\u5206\u7c7b\u523030\u4e2a\"\u9876\u7ea7\u5355\u500d\u7fa4\"\uff08TLHG\uff09\u4e2d\uff1b2\uff09\u4f7f\u7528\u8be5TLHG\u5185\u6700\u7a00\u6709SNV\u7684\u9891\u7387\uff0c\u5e76\u52a0\u6743TLHG\u9891\u7387\uff1b3\uff09\u4ec5\u9700227\u4e2a\u7279\u5b9a\u4f4d\u7f6e\u5373\u53ef\u5b8c\u6210\u9876\u7ea7\u5355\u500d\u7fa4\u5206\u7c7b\uff0c\u9002\u7528\u4e8e\u4f4e\u8d28\u91cf\u6837\u672c\u3002", "result": "\u65b9\u6cd5\u5728\u9ad8\u8d28\u91cf\u6cd5\u533b\u53c2\u8003\u6570\u636e\u96c6\u548cGenBank\u591a\u6837\u5316mitogenomes\u4e0a\u6d4b\u8bd5\u5747\u8868\u73b0\u7a33\u5065\uff0c\u4ea7\u751f\u7684\u4f3c\u7136\u6bd4\u8303\u56f4\u5728100-100,000\u4e4b\u95f4\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u6cd5\u533bmtDNA\u8bc1\u636e\u7684\u7edf\u8ba1\u8bc4\u4f30\u80fd\u529b\u3002", "conclusion": "MitoFREQ\u4e3a\u6cd5\u533b\u7ebf\u7c92\u4f53DNA\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u7fa4\u4f53\u9891\u7387\u4f30\u7b97\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u5f00\u6e90R\u5305`mitofreq`\u548cShiny\u5e94\u7528\uff0c\u4f7f\u65b9\u6cd5\u6613\u4e8e\u4f7f\u7528\u548c\u5b9a\u5236\u5316\u3002"}}
{"id": "2601.10352", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.10352", "abs": "https://arxiv.org/abs/2601.10352", "authors": ["Guilherme Vianna", "Victor Rangel"], "title": "Como medir o invis\u00edvel? Guerras, pizzarias do Pent\u00e1gono e o uso de vari\u00e1veis proxy em econometria", "comment": "in Portuguese language", "summary": "Many economically relevant variables (risk, confidence, uncertainty) are latent and therefore not directly observable, which creates identification challenges in applied regressions. This text formalizes how omitting latent factors generates omitted-variable bias and discusses when including a proxy variable can mitigate it. We distinguish the case of a perfect proxy, which can eliminate the bias, from the more realistic case of an imperfect proxy, where residual bias remains and the estimated effect is attenuated. We propose a practical evaluation protocol based on four properties: relevance, conditional sufficiency, exogeneity, and stability. As an illustration, we use micromobility data from Arlington together with the U.S. Geopolitical Risk Index, estimating cointegration and a bivariate VEC model to interpret local activity as a high-frequency signal of the latent component of geopolitical tension.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u4ee3\u7406\u53d8\u91cf\u89e3\u51b3\u6f5c\u5728\u53d8\u91cf\u5728\u56de\u5f52\u5206\u6790\u4e2d\u5bfc\u81f4\u7684\u9057\u6f0f\u53d8\u91cf\u504f\u8bef\u95ee\u9898\uff0c\u533a\u5206\u4e86\u5b8c\u7f8e\u4ee3\u7406\u548c\u4e0d\u5b8c\u7f8e\u4ee3\u7406\u7684\u60c5\u51b5\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u56db\u4e2a\u5c5e\u6027\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u8bb8\u591a\u7ecf\u6d4e\u76f8\u5173\u53d8\u91cf\uff08\u5982\u98ce\u9669\u3001\u4fe1\u5fc3\u3001\u4e0d\u786e\u5b9a\u6027\uff09\u662f\u6f5c\u5728\u53d8\u91cf\uff0c\u65e0\u6cd5\u76f4\u63a5\u89c2\u6d4b\uff0c\u8fd9\u7ed9\u5e94\u7528\u56de\u5f52\u5206\u6790\u5e26\u6765\u4e86\u8bc6\u522b\u6311\u6218\u3002\u9057\u6f0f\u8fd9\u4e9b\u6f5c\u5728\u56e0\u7d20\u4f1a\u5bfc\u81f4\u9057\u6f0f\u53d8\u91cf\u504f\u8bef\uff0c\u9700\u8981\u6709\u6548\u7684\u65b9\u6cd5\u6765\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bba\u6587\u5f62\u5f0f\u5316\u5206\u6790\u4e86\u9057\u6f0f\u6f5c\u5728\u53d8\u91cf\u5982\u4f55\u4ea7\u751f\u504f\u8bef\uff0c\u5e76\u8ba8\u8bba\u4e86\u4f55\u65f6\u5305\u542b\u4ee3\u7406\u53d8\u91cf\u53ef\u4ee5\u7f13\u89e3\u504f\u8bef\u3002\u533a\u5206\u5b8c\u7f8e\u4ee3\u7406\uff08\u53ef\u6d88\u9664\u504f\u8bef\uff09\u548c\u4e0d\u5b8c\u7f8e\u4ee3\u7406\uff08\u5b58\u5728\u6b8b\u4f59\u504f\u8bef\u548c\u8870\u51cf\u6548\u5e94\uff09\u3002\u63d0\u51fa\u4e86\u57fa\u4e8e\u56db\u4e2a\u5c5e\u6027\u7684\u5b9e\u7528\u8bc4\u4f30\u534f\u8bae\uff1a\u76f8\u5173\u6027\u3001\u6761\u4ef6\u5145\u5206\u6027\u3001\u5916\u751f\u6027\u548c\u7a33\u5b9a\u6027\u3002\u4f7f\u7528\u963f\u7075\u987f\u7684\u5fae\u51fa\u884c\u6570\u636e\u548c\u7f8e\u56fd\u5730\u7f18\u653f\u6cbb\u98ce\u9669\u6307\u6570\u4f5c\u4e3a\u5b9e\u8bc1\u6848\u4f8b\uff0c\u901a\u8fc7\u534f\u6574\u5206\u6790\u548c\u4e8c\u5143VEC\u6a21\u578b\u89e3\u91ca\u672c\u5730\u6d3b\u52a8\u4f5c\u4e3a\u5730\u7f18\u653f\u6cbb\u7d27\u5f20\u6f5c\u5728\u6210\u5206\u7684\u9ad8\u9891\u4fe1\u53f7\u3002", "result": "\u8bba\u6587\u5efa\u7acb\u4e86\u4ee3\u7406\u53d8\u91cf\u7f13\u89e3\u9057\u6f0f\u53d8\u91cf\u504f\u8bef\u7684\u7406\u8bba\u6846\u67b6\uff0c\u533a\u5206\u4e86\u4e0d\u540c\u4ee3\u7406\u8d28\u91cf\u4e0b\u7684\u504f\u8bef\u7279\u5f81\u3002\u5b9e\u8bc1\u5206\u6790\u8868\u660e\uff0c\u672c\u5730\u5fae\u51fa\u884c\u6d3b\u52a8\u53ef\u4ee5\u4f5c\u4e3a\u5730\u7f18\u653f\u6cbb\u7d27\u5f20\u6f5c\u5728\u6210\u5206\u7684\u6709\u6548\u9ad8\u9891\u4ee3\u7406\u4fe1\u53f7\u3002", "conclusion": "\u4ee3\u7406\u53d8\u91cf\u662f\u89e3\u51b3\u6f5c\u5728\u53d8\u91cf\u8bc6\u522b\u95ee\u9898\u7684\u5b9e\u7528\u5de5\u5177\uff0c\u4f46\u9700\u8981\u4ed4\u7ec6\u8bc4\u4f30\u5176\u8d28\u91cf\u3002\u63d0\u51fa\u7684\u56db\u4e2a\u5c5e\u6027\u8bc4\u4f30\u6846\u67b6\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u5224\u65ad\u4ee3\u7406\u53d8\u91cf\u7684\u6709\u6548\u6027\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u5b9e\u8bc1\u7814\u7a76\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2601.09772", "categories": ["cs.AI", "cs.CL", "cs.CY", "econ.GN"], "pdf": "https://arxiv.org/pdf/2601.09772", "abs": "https://arxiv.org/abs/2601.09772", "authors": ["Pawe\u0142 Niszczota", "Cassandra Gr\u00fctzner"], "title": "Antisocial behavior towards large language model users: experimental evidence", "comment": null, "summary": "The rapid spread of large language models (LLMs) has raised concerns about the social reactions they provoke. Prior research documents negative attitudes toward AI users, but it remains unclear whether such disapproval translates into costly action. We address this question in a two-phase online experiment (N = 491 Phase II participants; Phase I provided targets) where participants could spend part of their own endowment to reduce the earnings of peers who had previously completed a real-effort task with or without LLM support. On average, participants destroyed 36% of the earnings of those who relied exclusively on the model, with punishment increasing monotonically with actual LLM use. Disclosure about LLM use created a credibility gap: self-reported null use was punished more harshly than actual null use, suggesting that declarations of \"no use\" are treated with suspicion. Conversely, at high levels of use, actual reliance on the model was punished more strongly than self-reported reliance. Taken together, these findings provide the first behavioral evidence that the efficiency gains of LLMs come at the cost of social sanctions.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4eba\u4eec\u5bf9\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5b8c\u6210\u4efb\u52a1\u7684\u4eba\u4f1a\u65bd\u52a0\u60e9\u7f5a\u6027\u884c\u4e3a\uff0c\u5e73\u5747\u4f1a\u9500\u6bc1LLM\u4f7f\u7528\u800536%\u7684\u6536\u5165\uff0c\u4e14\u60e9\u7f5a\u7a0b\u5ea6\u968f\u5b9e\u9645\u4f7f\u7528\u91cf\u589e\u52a0\u800c\u589e\u52a0\u3002\u81ea\u6211\u62a5\u544a\u7684\u4f7f\u7528\u60c5\u51b5\u4e0e\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\u5b58\u5728\u53ef\u4fe1\u5ea6\u5dee\u8ddd\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u666e\u53ca\uff0c\u4eba\u4eec\u5173\u6ce8\u793e\u4f1a\u5bf9AI\u4f7f\u7528\u8005\u7684\u53cd\u5e94\u3002\u5148\u524d\u7814\u7a76\u8868\u660e\u4eba\u4eec\u5bf9AI\u4f7f\u7528\u8005\u6301\u8d1f\u9762\u6001\u5ea6\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u8fd9\u79cd\u4e0d\u8ba4\u53ef\u662f\u5426\u4f1a\u8f6c\u5316\u4e3a\u5b9e\u9645\u7684\u60e9\u7f5a\u884c\u4e3a\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5728\u7ebf\u5b9e\u9a8c\u8bbe\u8ba1\uff08\u7b2c\u4e8c\u9636\u6bb5491\u540d\u53c2\u4e0e\u8005\uff09\u3002\u7b2c\u4e00\u9636\u6bb5\u53c2\u4e0e\u8005\u5b8c\u6210\u5b9e\u9645\u52aa\u529b\u4efb\u52a1\uff0c\u53ef\u9009\u62e9\u4f7f\u7528\u6216\u4e0d\u4f7f\u7528LLM\u652f\u6301\u3002\u7b2c\u4e8c\u9636\u6bb5\u53c2\u4e0e\u8005\u53ef\u82b1\u8d39\u81ea\u5df1\u7684\u8d44\u91d1\u6765\u51cf\u5c11\u7b2c\u4e00\u9636\u6bb5\u53c2\u4e0e\u8005\u7684\u6536\u5165\uff0c\u57fa\u4e8e\u4ed6\u4eec\u662f\u5426\u4f7f\u7528LLM\u4ee5\u53ca\u81ea\u6211\u62a5\u544a\u7684\u4f7f\u7528\u60c5\u51b5\u3002", "result": "\u53c2\u4e0e\u8005\u5e73\u5747\u9500\u6bc1\u4e86\u5b8c\u5168\u4f9d\u8d56LLM\u800536%\u7684\u6536\u5165\uff0c\u60e9\u7f5a\u7a0b\u5ea6\u968f\u5b9e\u9645LLM\u4f7f\u7528\u91cf\u5355\u8c03\u589e\u52a0\u3002\u81ea\u6211\u62a5\u544a\u4e0e\u5b9e\u9645\u4f7f\u7528\u5b58\u5728\u53ef\u4fe1\u5ea6\u5dee\u8ddd\uff1a\u81ea\u6211\u62a5\u544a\u672a\u4f7f\u7528\u8005\u6bd4\u5b9e\u9645\u672a\u4f7f\u7528\u8005\u53d7\u5230\u66f4\u4e25\u5389\u60e9\u7f5a\uff1b\u5728\u9ad8\u4f7f\u7528\u6c34\u5e73\u4e0b\uff0c\u5b9e\u9645\u4f9d\u8d56LLM\u6bd4\u81ea\u6211\u62a5\u544a\u4f9d\u8d56\u53d7\u5230\u66f4\u5f3a\u60e9\u7f5a\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u884c\u4e3a\u8bc1\u636e\u8868\u660eLLM\u7684\u6548\u7387\u63d0\u5347\u4f1a\u5e26\u6765\u793e\u4f1a\u5236\u88c1\u6210\u672c\u3002\u4eba\u4eec\u5bf9LLM\u4f7f\u7528\u8005\u65bd\u52a0\u5b9e\u8d28\u6027\u60e9\u7f5a\uff0c\u4e14\u81ea\u6211\u62a5\u544a\u4e0e\u5b9e\u9645\u4f7f\u7528\u4e4b\u95f4\u7684\u53ef\u4fe1\u5ea6\u5dee\u8ddd\u4f1a\u5f71\u54cd\u60e9\u7f5a\u7a0b\u5ea6\u3002"}}
{"id": "2601.09757", "categories": ["cs.CY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09757", "abs": "https://arxiv.org/abs/2601.09757", "authors": ["Sonia Katyal"], "title": "Democracy and Distrust in an Era of Artificial Intelligence", "comment": "Daedalus, Journal of the American Academy of Arts & Sciences 2022. Available at SSRN: https://ssrn.com/abstract=4099147", "summary": "This essay examines how judicial review should adapt to address challenges posed by artificial intelligence decision-making, particularly regarding minority rights and interests. As I argue in this essay, the rise of three trends-privatization, prediction, and automation in AI-have combined to pose similar risks to minorities. Here, I outline what a theory of judicial review would look like in an era of artificial intelligence, analyzing both the limitations and the possibilities of judicial review of AI. I draw on cases in which AI decision-making has been challenged in courts, to show how concepts of due process and equal protection can be recuperated in a modern AI era, and even integrated into AI, to provide for better oversight and accountability, offering a framework for judicial review in the AI era that protects minorities from algorithmic discrimination.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u53f8\u6cd5\u5ba1\u67e5\u5982\u4f55\u9002\u5e94\u4eba\u5de5\u667a\u80fd\u51b3\u7b56\u5e26\u6765\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5173\u4e8e\u5c11\u6570\u7fa4\u4f53\u6743\u5229\u548c\u5229\u76ca\u4fdd\u62a4\uff0c\u63d0\u51faAI\u65f6\u4ee3\u7684\u53f8\u6cd5\u5ba1\u67e5\u7406\u8bba\u6846\u67b6\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u51b3\u7b56\u4e2d\u7684\u79c1\u6709\u5316\u3001\u9884\u6d4b\u548c\u81ea\u52a8\u5316\u8d8b\u52bf\u5bf9\u5c11\u6570\u7fa4\u4f53\u6784\u6210\u76f8\u4f3c\u98ce\u9669\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003\u53f8\u6cd5\u5ba1\u67e5\u5728AI\u65f6\u4ee3\u7684\u4f5c\u7528\uff0c\u4ee5\u4fdd\u62a4\u5c11\u6570\u7fa4\u4f53\u514d\u53d7\u7b97\u6cd5\u6b67\u89c6\u3002", "method": "\u5206\u6790AI\u51b3\u7b56\u5728\u6cd5\u5ead\u4e0a\u53d7\u5230\u6311\u6218\u7684\u6848\u4f8b\uff0c\u63a2\u8ba8\u6b63\u5f53\u7a0b\u5e8f\u548c\u5e73\u7b49\u4fdd\u62a4\u539f\u5219\u5982\u4f55\u5728\u73b0\u4ee3AI\u65f6\u4ee3\u88ab\u91cd\u65b0\u8be0\u91ca\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230AI\u7cfb\u7edf\u4e2d\uff0c\u63d0\u4f9b\u76d1\u7763\u548c\u95ee\u8d23\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2aAI\u65f6\u4ee3\u7684\u53f8\u6cd5\u5ba1\u67e5\u6846\u67b6\uff0c\u5c55\u793a\u5982\u4f55\u901a\u8fc7\u91cd\u65b0\u89e3\u91ca\u5baa\u6cd5\u539f\u5219\u6765\u4fdd\u62a4\u5c11\u6570\u7fa4\u4f53\u6743\u5229\uff0c\u5e76\u5c06\u8fd9\u4e9b\u539f\u5219\u6574\u5408\u5230AI\u7cfb\u7edf\u4e2d\u4ee5\u5b9e\u73b0\u66f4\u597d\u7684\u76d1\u7763\u548c\u95ee\u8d23\u3002", "conclusion": "\u53f8\u6cd5\u5ba1\u67e5\u9700\u8981\u9002\u5e94AI\u65f6\u4ee3\uff0c\u901a\u8fc7\u91cd\u65b0\u8be0\u91ca\u6b63\u5f53\u7a0b\u5e8f\u548c\u5e73\u7b49\u4fdd\u62a4\u539f\u5219\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230AI\u7cfb\u7edf\u4e2d\uff0c\u53ef\u4ee5\u5efa\u7acb\u6709\u6548\u7684\u76d1\u7763\u673a\u5236\uff0c\u4fdd\u62a4\u5c11\u6570\u7fa4\u4f53\u514d\u53d7\u7b97\u6cd5\u6b67\u89c6\u3002"}}
{"id": "2601.10444", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2601.10444", "abs": "https://arxiv.org/abs/2601.10444", "authors": ["Sebastian Kripfganz", "Vasilis Sarafidis"], "title": "Chasing Opportunity: Spillovers and Drivers of U.S. State Population Growth", "comment": null, "summary": "We study the drivers and spatial diffusion of U.S. state population growth using a dynamic spatial model for 49 states, 1965-2017. Methodologically, we recover the spatial network structure from the data, rather than imposing it a priori via contiguity or distance, and combine this with an IV estimator that permits heterogeneous slopes and interactive fixed effects. This unified design delivers consistent estimation and inference in a flexible spatial panel model with endogenous regressors, a data-inferred network structure, and pervasive cross-state dependence. To our knowledge, it is the first estimation framework in spatial econometrics to combine all three elements within a single setting. Empirically, population growth exhibits broad yet heterogeneous conditional convergence: about three-quarters of states converge, while a small high-growth group mildly diverges. Effects of the core drivers, amenities, labour income, migration frictions, are stable across various network specifications. On the other hand, the productivity effect emerges only when the network is estimated from the data. Spatial spillovers are sizable, with indirect effects roughly one-third of total impacts, and diffusion extending beyond contiguous neighbours.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u52a8\u6001\u7a7a\u95f4\u6a21\u578b\u5206\u6790\u7f8e\u56fd49\u4e2a\u5dde1965-2017\u5e74\u4eba\u53e3\u589e\u957f\u7684\u9a71\u52a8\u56e0\u7d20\u548c\u7a7a\u95f4\u6269\u6563\uff0c\u91c7\u7528\u6570\u636e\u63a8\u65ad\u7f51\u7edc\u7ed3\u6784\u800c\u975e\u9884\u8bbe\u90bb\u63a5\u5173\u7cfb\uff0c\u7ed3\u5408IV\u4f30\u8ba1\u5668\u5904\u7406\u5185\u751f\u6027\u548c\u5f02\u8d28\u6027\uff0c\u53d1\u73b0\u4eba\u53e3\u589e\u957f\u5b58\u5728\u5e7f\u6cdb\u4f46\u5f02\u8d28\u7684\u6761\u4ef6\u6536\u655b\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u7406\u89e3\u7f8e\u56fd\u5dde\u7ea7\u4eba\u53e3\u589e\u957f\u7684\u9a71\u52a8\u56e0\u7d20\u548c\u7a7a\u95f4\u6269\u6563\u6a21\u5f0f\uff0c\u540c\u65f6\u89e3\u51b3\u4f20\u7edf\u7a7a\u95f4\u8ba1\u91cf\u7ecf\u6d4e\u5b66\u4e2d\u7f51\u7edc\u7ed3\u6784\u9884\u8bbe\u3001\u5185\u751f\u6027\u5904\u7406\u548c\u5f02\u8d28\u6027\u5efa\u6a21\u7684\u5c40\u9650\u6027\u3002", "method": "\u5f00\u53d1\u7edf\u4e00\u4f30\u8ba1\u6846\u67b6\uff1a1) \u4ece\u6570\u636e\u4e2d\u63a8\u65ad\u7a7a\u95f4\u7f51\u7edc\u7ed3\u6784\u800c\u975e\u9884\u8bbe\u90bb\u63a5\u6216\u8ddd\u79bb\uff1b2) \u7ed3\u5408IV\u4f30\u8ba1\u5668\u5904\u7406\u5185\u751f\u89e3\u91ca\u53d8\u91cf\uff1b3) \u5141\u8bb8\u5f02\u8d28\u6027\u659c\u7387\u548c\u4ea4\u4e92\u56fa\u5b9a\u6548\u5e94\uff1b4) \u5728\u7075\u6d3b\u7684\u7a7a\u95f4\u9762\u677f\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e00\u81f4\u4f30\u8ba1\u548c\u63a8\u65ad\u3002", "result": "\u5b9e\u8bc1\u53d1\u73b0\uff1a1) \u7ea6\u56db\u5206\u4e4b\u4e09\u7684\u5dde\u5448\u73b0\u6761\u4ef6\u6536\u655b\uff0c\u5c0f\u90e8\u5206\u9ad8\u589e\u957f\u5dde\u8f7b\u5fae\u53d1\u6563\uff1b2) \u6838\u5fc3\u9a71\u52a8\u56e0\u7d20\uff08\u4fbf\u5229\u8bbe\u65bd\u3001\u52b3\u52a8\u6536\u5165\u3001\u8fc1\u79fb\u6469\u64e6\uff09\u6548\u5e94\u5728\u4e0d\u540c\u7f51\u7edc\u8bbe\u5b9a\u4e0b\u7a33\u5b9a\uff1b3) \u751f\u4ea7\u7387\u6548\u5e94\u4ec5\u5728\u6570\u636e\u63a8\u65ad\u7684\u7f51\u7edc\u4e2d\u663e\u73b0\uff1b4) \u7a7a\u95f4\u6ea2\u51fa\u6548\u5e94\u663e\u8457\uff0c\u95f4\u63a5\u6548\u5e94\u7ea6\u5360\u603b\u5f71\u54cd\u7684\u4e09\u5206\u4e4b\u4e00\uff0c\u6269\u6563\u8303\u56f4\u8d85\u51fa\u76f8\u90bb\u5dde\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u9996\u4e2a\u540c\u65f6\u5904\u7406\u6570\u636e\u63a8\u65ad\u7f51\u7edc\u7ed3\u6784\u3001\u5185\u751f\u89e3\u91ca\u53d8\u91cf\u548c\u666e\u904d\u8de8\u5dde\u4f9d\u8d56\u7684\u7edf\u4e00\u7a7a\u95f4\u8ba1\u91cf\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u7f8e\u56fd\u5dde\u7ea7\u4eba\u53e3\u589e\u957f\u7684\u5f02\u8d28\u6536\u655b\u6a21\u5f0f\u548c\u663e\u8457\u7a7a\u95f4\u6ea2\u51fa\u6548\u5e94\uff0c\u5f3a\u8c03\u4e86\u6570\u636e\u9a71\u52a8\u7f51\u7edc\u8bc6\u522b\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.09805", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09805", "abs": "https://arxiv.org/abs/2601.09805", "authors": ["Nguyen Minh Phuong", "Dang Huu Tien", "Naoya Inoue"], "title": "Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention", "comment": "Findings of EACL 2026", "summary": "Modern logical reasoning with LLMs primarily relies on employing complex interactive frameworks that decompose the reasoning process into subtasks solved through carefully designed prompts or requiring external resources (e.g., symbolic solvers) to exploit their strong logical structures. While interactive approaches introduce additional overhead, hybrid approaches depend on external components, which limit their scalability. A non-interactive, end-to-end framework enables reasoning to emerge within the model itself -- improving generalization while preserving analyzability without any external resources. In this work, we introduce a non-interactive, end-to-end framework for reasoning tasks. We show that introducing structural information into the few-shot prompt activates a subset of attention heads that patterns aligned with logical reasoning operators. Building on this insight, we propose Attention-Aware Intervention (AAI), an inference-time intervention method that reweights attention scores across selected heads identified by their logical patterns. AAI offers an efficient way to steer the model's reasoning toward leveraging prior knowledge through attention modulation. Extensive experiments show that AAI enhances logical reasoning performance across diverse benchmarks and model architectures, while incurring negligible additional computational overhead. Code is available at https://github.com/phuongnm94/aai_for_logical_reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u975e\u4ea4\u4e92\u5f0f\u7aef\u5230\u7aef\u903b\u8f91\u63a8\u7406\u6846\u67b6AAI\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u91cd\u52a0\u6743\u6765\u6fc0\u6d3b\u6a21\u578b\u5185\u90e8\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u9700\u5916\u90e8\u8d44\u6e90\u4e14\u8ba1\u7b97\u5f00\u9500\u5c0f\u3002", "motivation": "\u73b0\u6709LLM\u903b\u8f91\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u7684\u4ea4\u4e92\u5f0f\u6846\u67b6\u6216\u5916\u90e8\u7b26\u53f7\u6c42\u89e3\u5668\uff0c\u8fd9\u5e26\u6765\u4e86\u989d\u5916\u5f00\u9500\u548c\u53ef\u6269\u5c55\u6027\u9650\u5236\u3002\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u975e\u4ea4\u4e92\u5f0f\u3001\u7aef\u5230\u7aef\u7684\u6846\u67b6\uff0c\u8ba9\u63a8\u7406\u80fd\u529b\u5728\u6a21\u578b\u5185\u90e8\u81ea\u7136\u6d8c\u73b0\u3002", "method": "\u63d0\u51faAttention-Aware Intervention (AAI)\u65b9\u6cd5\uff1a1) \u5728few-shot\u63d0\u793a\u4e2d\u5f15\u5165\u7ed3\u6784\u4fe1\u606f\u6765\u6fc0\u6d3b\u4e0e\u903b\u8f91\u63a8\u7406\u64cd\u4f5c\u7b26\u5bf9\u9f50\u7684\u6ce8\u610f\u529b\u5934\uff1b2) \u5728\u63a8\u7406\u65f6\u5bf9\u8fd9\u4e9b\u9009\u5b9a\u6ce8\u610f\u529b\u5934\u7684\u6ce8\u610f\u529b\u5206\u6570\u8fdb\u884c\u91cd\u52a0\u6743\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u8c03\u5236\u5f15\u5bfc\u6a21\u578b\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u6a21\u578b\u67b6\u6784\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cAAI\u663e\u8457\u63d0\u5347\u4e86\u903b\u8f91\u63a8\u7406\u6027\u80fd\uff0c\u540c\u65f6\u4ec5\u5e26\u6765\u53ef\u5ffd\u7565\u7684\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "AAI\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u975e\u4ea4\u4e92\u5f0f\u7aef\u5230\u7aef\u903b\u8f91\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u8c03\u5236\u6fc0\u6d3b\u6a21\u578b\u5185\u5728\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5728\u4fdd\u6301\u53ef\u5206\u6790\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2601.09849", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.09849", "abs": "https://arxiv.org/abs/2601.09849", "authors": ["Saptarshi Pal", "Abhishek Mallela", "Christian Hilbe", "Lenz Pracher", "Chiyu Wei", "Feng Fu", "Santiago Schnell", "Martin A Nowak"], "title": "Strategies of cooperation and defection in five large language models", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed to support human decision-making. This use of LLMs has concerning implications, especially when their prescriptions affect the welfare of others. To gauge how LLMs make social decisions, we explore whether five leading models produce sensible strategies in the repeated prisoner's dilemma, which is the main metaphor of reciprocal cooperation. First, we measure the propensity of LLMs to cooperate in a neutral setting, without using language reminiscent of how this game is usually presented. We record to what extent LLMs implement Nash equilibria or other well-known strategy classes. Thereafter, we explore how LLMs adapt their strategies to changes in parameter values. We vary the game's continuation probability, the payoff values, and whether the total number of rounds is commonly known. We also study the effect of different framings. In each case, we test whether the adaptations of the LLMs are in line with basic intuition, theoretical predictions of evolutionary game theory, and experimental evidence from human participants. While all LLMs perform well in many of the tasks, none of them exhibit full consistency over all tasks. We also conduct tournaments between the inferred LLM strategies and study direct interaction between LLMs in games over ten rounds with a known or unknown last round. Our experiments shed light on how current LLMs instantiate reciprocal cooperation.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4e94\u4e2a\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91cd\u590d\u56da\u5f92\u56f0\u5883\u4e2d\u7684\u5408\u4f5c\u7b56\u7565\u8868\u73b0\uff0c\u8bc4\u4f30\u5b83\u4eec\u662f\u5426\u9075\u5faa\u7eb3\u4ec0\u5747\u8861\u3001\u8fdb\u5316\u535a\u5f08\u8bba\u9884\u6d4b\u53ca\u4eba\u7c7b\u5b9e\u9a8c\u8bc1\u636e\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u591a\u6570\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\u4f46\u7f3a\u4e4f\u5b8c\u5168\u4e00\u81f4\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u652f\u6301\u4eba\u7c7b\u51b3\u7b56\uff0c\u7279\u522b\u662f\u5728\u5f71\u54cd\u4ed6\u4eba\u798f\u5229\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u4e86\u89e3\u5b83\u4eec\u5982\u4f55\u8fdb\u884c\u793e\u4f1a\u51b3\u7b56\u3002\u91cd\u590d\u56da\u5f92\u56f0\u5883\u4f5c\u4e3a\u4e92\u60e0\u5408\u4f5c\u7684\u4e3b\u8981\u9690\u55bb\uff0c\u662f\u8bc4\u4f30LLM\u793e\u4f1a\u51b3\u7b56\u80fd\u529b\u7684\u7406\u60f3\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "\u9996\u5148\u5728\u4e2d\u6027\u8bbe\u7f6e\u4e0b\u6d4b\u91cfLLM\u7684\u5408\u4f5c\u503e\u5411\uff0c\u4e0d\u4f7f\u7528\u6e38\u620f\u7684\u6807\u51c6\u8868\u8ff0\u8bed\u8a00\u3002\u8bc4\u4f30LLM\u5b9e\u73b0\u7eb3\u4ec0\u5747\u8861\u6216\u5176\u4ed6\u5df2\u77e5\u7b56\u7565\u7c7b\u522b\u7684\u7a0b\u5ea6\u3002\u7136\u540e\u63a2\u7d22LLM\u5982\u4f55\u9002\u5e94\u53c2\u6570\u53d8\u5316\uff1a\u6539\u53d8\u6e38\u620f\u7684\u7ee7\u7eed\u6982\u7387\u3001\u6536\u76ca\u503c\u3001\u603b\u8f6e\u6570\u662f\u5426\u5171\u540c\u77e5\u8bc6\uff0c\u4ee5\u53ca\u4e0d\u540c\u6846\u67b6\u7684\u5f71\u54cd\u3002\u6700\u540e\u8fdb\u884cLLM\u7b56\u7565\u4e4b\u95f4\u7684\u9526\u6807\u8d5b\uff0c\u5e76\u7814\u7a76LLM\u5728\u5df2\u77e5\u6216\u672a\u77e5\u6700\u540e\u4e00\u8f6e\u768410\u8f6e\u6e38\u620f\u4e2d\u7684\u76f4\u63a5\u4e92\u52a8\u3002", "result": "\u6240\u6709LLM\u5728\u591a\u6570\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u6ca1\u6709\u4e00\u4e2a\u6a21\u578b\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5b8c\u5168\u4e00\u81f4\u6027\u3002\u6a21\u578b\u80fd\u591f\u9002\u5e94\u53c2\u6570\u53d8\u5316\uff0c\u4f46\u7b56\u7565\u8c03\u6574\u4e0e\u57fa\u672c\u76f4\u89c9\u3001\u8fdb\u5316\u535a\u5f08\u8bba\u9884\u6d4b\u548c\u4eba\u7c7b\u5b9e\u9a8c\u8bc1\u636e\u7684\u7b26\u5408\u7a0b\u5ea6\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5982\u4f55\u5b9e\u4f8b\u5316\u4e92\u60e0\u5408\u4f5c\uff0c\u8868\u660e\u867d\u7136\u5b83\u4eec\u5728\u8bb8\u591a\u793e\u4f1a\u51b3\u7b56\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7b56\u7565\u4e00\u81f4\u6027\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u8fd9\u5bf9LLM\u5728\u5f71\u54cd\u4ed6\u4eba\u798f\u5229\u7684\u51b3\u7b56\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.10501", "categories": ["econ.EM", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.10501", "abs": "https://arxiv.org/abs/2601.10501", "authors": ["Xinyu Wang", "Chunlin Wang", "Tao Yu", "Pengfei Li"], "title": "Semiparametric inference for inequality measures under nonignorable nonresponse using callback data", "comment": "29 pages, 2 figures", "summary": "This paper develops semiparametric methods for estimation and inference of widely used inequality measures when survey data are subject to nonignorable nonresponse, a challenging setting in which response probabilities depend on the unobserved outcomes. Such nonresponse mechanisms are common in household surveys and invalidate standard inference procedures due to selection bias and lack of population representativeness. We address this problem by exploiting callback data from repeated contact attempts and adopting a semiparametric model that leaves the outcome distribution unspecified. We construct semiparametric full-likelihood estimators for the underlying distribution and the associated inequality measures, and establish their large-sample properties for a broad class of functionals, including quantiles, the Theil index, and the Gini index. Explicit asymptotic variance expressions are derived, enabling valid Wald-type inference under nonignorable nonresponse. To facilitate implementation, we propose a stable and computationally convenient expectation-maximization algorithm, whose steps either admit closed-form expressions or reduce to fitting a standard logistic regression model. Simulation studies demonstrate that the proposed procedures effectively correct nonresponse bias and achieve near-benchmark efficiency. An application to Consumer Expenditure Survey data illustrates the practical gains from incorporating callback information when making inference on inequality measures.", "AI": {"tldr": "\u63d0\u51fa\u534a\u53c2\u6570\u65b9\u6cd5\uff0c\u5728\u8c03\u67e5\u6570\u636e\u5b58\u5728\u4e0d\u53ef\u5ffd\u7565\u65e0\u56de\u7b54\u65f6\u4f30\u8ba1\u4e0d\u5e73\u7b49\u6307\u6807\uff0c\u5229\u7528\u56de\u8bbf\u6570\u636e\u7ea0\u6b63\u9009\u62e9\u504f\u5dee", "motivation": "\u5bb6\u5ead\u8c03\u67e5\u4e2d\u5e38\u89c1\u7684\u4e0d\u53ef\u5ffd\u7565\u65e0\u56de\u7b54\uff08\u54cd\u5e94\u6982\u7387\u53d6\u51b3\u4e8e\u672a\u89c2\u6d4b\u7ed3\u679c\uff09\u4f1a\u5bfc\u81f4\u9009\u62e9\u504f\u5dee\uff0c\u4f7f\u6807\u51c6\u63a8\u65ad\u65b9\u6cd5\u5931\u6548\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u65b9\u6cd5\u6765\u7ea0\u6b63\u8fd9\u79cd\u504f\u5dee", "method": "\u5229\u7528\u91cd\u590d\u8054\u7cfb\u5c1d\u8bd5\u7684\u56de\u8bbf\u6570\u636e\uff0c\u91c7\u7528\u534a\u53c2\u6570\u6a21\u578b\uff08\u7ed3\u679c\u5206\u5e03\u672a\u6307\u5b9a\uff09\uff0c\u6784\u5efa\u534a\u53c2\u6570\u5b8c\u5168\u4f3c\u7136\u4f30\u8ba1\u91cf\uff0c\u63d0\u51fa\u7a33\u5b9a\u7684EM\u7b97\u6cd5\u5b9e\u73b0", "result": "\u5efa\u7acb\u4e86\u4f30\u8ba1\u91cf\u7684\u5927\u6837\u672c\u6027\u8d28\uff0c\u63a8\u5bfc\u4e86\u663e\u5f0f\u6e10\u8fd1\u65b9\u5dee\u8868\u8fbe\u5f0f\uff0c\u6a21\u62df\u663e\u793a\u80fd\u6709\u6548\u7ea0\u6b63\u65e0\u56de\u7b54\u504f\u5dee\u5e76\u63a5\u8fd1\u57fa\u51c6\u6548\u7387", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u5728\u4e0d\u53ef\u5ffd\u7565\u65e0\u56de\u7b54\u4e0b\u5bf9\u4e0d\u5e73\u7b49\u6307\u6807\u8fdb\u884c\u6709\u6548\u63a8\u65ad\uff0c\u6d88\u8d39\u8005\u652f\u51fa\u8c03\u67e5\u5e94\u7528\u5c55\u793a\u4e86\u56de\u8bbf\u4fe1\u606f\u7684\u5b9e\u9645\u4ef7\u503c"}}
{"id": "2601.09855", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09855", "abs": "https://arxiv.org/abs/2601.09855", "authors": ["Michael R. Metel", "Yufei Cui", "Boxing Chen", "Prasanna Parthasarathi"], "title": "Thinking Long, but Short: Stable Sequential Test-Time Scaling for Large Reasoning Models", "comment": "Findings of EACL 2026", "summary": "Sequential test-time scaling is a promising training-free method to improve large reasoning model accuracy, but as currently implemented, significant limitations have been observed. Inducing models to think for longer can increase their accuracy, but as the length of reasoning is further extended, it has also been shown to result in accuracy degradation and model instability. This work presents a novel sequential test-time scaling method, Min-Seek, which improves model accuracy significantly over a wide range of induced thoughts, stabilizing the accuracy of sequential scaling, and removing the need for reasoning length fine-tuning. Beyond improving model accuracy over a variety of reasoning tasks, our method is inherently efficient, as only the KV pairs of one additional induced thought are kept in the KV cache during reasoning. With a custom KV cache which stores keys without position embeddings, by dynamically encoding them contiguously before each new generated thought, our method can continue to reason well beyond a model's maximum context length, and under mild conditions has linear computational complexity.", "AI": {"tldr": "Min-Seek\uff1a\u4e00\u79cd\u65b0\u9896\u7684\u987a\u5e8f\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001KV\u7f13\u5b58\u7ba1\u7406\uff0c\u5728\u5e7f\u6cdb\u63a8\u7406\u957f\u5ea6\u8303\u56f4\u5185\u663e\u8457\u63d0\u5347\u6a21\u578b\u51c6\u786e\u7387\u5e76\u907f\u514d\u6027\u80fd\u9000\u5316", "motivation": "\u5f53\u524d\u987a\u5e8f\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff1a\u867d\u7136\u589e\u52a0\u63a8\u7406\u957f\u5ea6\u80fd\u63d0\u9ad8\u51c6\u786e\u7387\uff0c\u4f46\u8fdb\u4e00\u6b65\u5ef6\u957f\u4f1a\u5bfc\u81f4\u51c6\u786e\u7387\u4e0b\u964d\u548c\u6a21\u578b\u4e0d\u7a33\u5b9a\uff0c\u4e14\u9700\u8981\u63a8\u7406\u957f\u5ea6\u5fae\u8c03", "method": "\u63d0\u51faMin-Seek\u65b9\u6cd5\uff0c\u4ec5\u4fdd\u7559\u4e00\u4e2a\u989d\u5916\u8bf1\u5bfc\u601d\u7ef4\u7684KV\u5bf9\u5728KV\u7f13\u5b58\u4e2d\uff0c\u4f7f\u7528\u81ea\u5b9a\u4e49KV\u7f13\u5b58\u5b58\u50a8\u65e0\u4f4d\u7f6e\u5d4c\u5165\u7684\u952e\uff0c\u5e76\u5728\u6bcf\u4e2a\u65b0\u751f\u6210\u601d\u7ef4\u524d\u52a8\u6001\u8fde\u7eed\u7f16\u7801\uff0c\u5b9e\u73b0\u8d85\u8d8a\u6a21\u578b\u6700\u5927\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u63a8\u7406", "result": "\u65b9\u6cd5\u5728\u591a\u79cd\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6a21\u578b\u51c6\u786e\u7387\uff0c\u7a33\u5b9a\u987a\u5e8f\u7f29\u653e\u7684\u51c6\u786e\u7387\uff0c\u6d88\u9664\u63a8\u7406\u957f\u5ea6\u5fae\u8c03\u9700\u6c42\uff0c\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u5177\u6709\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6", "conclusion": "Min-Seek\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u7a33\u5b9a\u7684\u987a\u5e8f\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u6027\u80fd\u9000\u5316\u95ee\u9898"}}
{"id": "2601.09944", "categories": ["cs.CY", "cs.GT"], "pdf": "https://arxiv.org/pdf/2601.09944", "abs": "https://arxiv.org/abs/2601.09944", "authors": ["Richard Q. Blackwell", "Eman Hammad", "Congrui Jin", "Jisoo Park", "Albert E. Patterson"], "title": "Modeling conflicting incentives in engineering senior capstone projects: A multi-player game theory approach", "comment": "25 pages, 9 tables, 1 figure", "summary": "University engineering capstone projects involve sustained interaction among students, faculty, and industry sponsors whose objectives are only partially aligned. While capstones are widely used in engineering education, existing analyses typically treat stakeholder behavior informally or descriptively, leaving incentive conflicts, information asymmetries, and strategic dependencies underexplored. This paper develops a formal game-theoretic framework that models capstone projects as a sequential Bayesian game involving three players: the university, the industry sponsor, and the student team. The framework is intended as an analytical and explanatory tool for understanding how institutional policy choices, such as grading structures, intellectual property rules, and sponsor engagement expectations, shape stakeholder behavior and project outcomes, rather than as a calibrated or predictive model. The university acts as a constrained Stackelberg leader by committing to course policies and assessment structures while anticipating strategic responses by sponsors and students under incomplete information. Reduced-form outcome functions capture technical quality, documentation quality, timeliness, alignment with sponsor needs, and publishability, while payoff functions reflect stakeholder-specific objectives and costs. Under standard assumptions, the model admits stable equilibrium regimes that correspond to empirically recognizable capstone dynamics observed in practice, including cooperative engagement, sponsor-dominated exploitation, and student grade gaming. Rather than claiming precise prediction, the framework provides a structured basis for reasoning about incentive design, policy tradeoffs, and structural failure modes in project-based learning environments, as well as for future extensions incorporating richer dynamics, repeated interaction, and empirical calibration.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u535a\u5f08\u8bba\u6846\u67b6\uff0c\u5c06\u5de5\u7a0b\u9876\u70b9\u9879\u76ee\u5efa\u6a21\u4e3a\u5927\u5b66\u3001\u884c\u4e1a\u8d5e\u52a9\u5546\u548c\u5b66\u751f\u56e2\u961f\u4e4b\u95f4\u7684\u5e8f\u8d2f\u8d1d\u53f6\u65af\u535a\u5f08\uff0c\u7528\u4e8e\u5206\u6790\u5236\u5ea6\u653f\u7b56\u5982\u4f55\u5f71\u54cd\u5229\u76ca\u76f8\u5173\u8005\u884c\u4e3a\u548c\u9879\u76ee\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5de5\u7a0b\u9876\u70b9\u9879\u76ee\u5206\u6790\u901a\u5e38\u975e\u6b63\u5f0f\u6216\u63cf\u8ff0\u6027\u5730\u5904\u7406\u5229\u76ca\u76f8\u5173\u8005\u884c\u4e3a\uff0c\u5ffd\u7565\u4e86\u6fc0\u52b1\u51b2\u7a81\u3001\u4fe1\u606f\u4e0d\u5bf9\u79f0\u548c\u6218\u7565\u4f9d\u8d56\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u6b63\u5f0f\u7684\u7406\u8bba\u6846\u67b6\u6765\u7cfb\u7edf\u5206\u6790\u5236\u5ea6\u653f\u7b56\u9009\u62e9\u5982\u4f55\u5851\u9020\u5229\u76ca\u76f8\u5173\u8005\u884c\u4e3a\u548c\u9879\u76ee\u7ed3\u679c\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5e8f\u8d2f\u8d1d\u53f6\u65af\u535a\u5f08\u6846\u67b6\uff0c\u5c06\u5927\u5b66\u5efa\u6a21\u4e3a\u53d7\u7ea6\u675f\u7684Stackelberg\u9886\u5bfc\u8005\uff0c\u5236\u5b9a\u8bfe\u7a0b\u653f\u7b56\u548c\u8bc4\u4f30\u7ed3\u6784\uff0c\u540c\u65f6\u8003\u8651\u8d5e\u52a9\u5546\u548c\u5b66\u751f\u5728\u4e0d\u5b8c\u5168\u4fe1\u606f\u4e0b\u7684\u6218\u7565\u54cd\u5e94\u3002\u4f7f\u7528\u7b80\u5316\u5f62\u5f0f\u7684\u7ed3\u679c\u51fd\u6570\u6355\u6349\u6280\u672f\u8d28\u91cf\u3001\u6587\u6863\u8d28\u91cf\u3001\u53ca\u65f6\u6027\u3001\u4e0e\u8d5e\u52a9\u5546\u9700\u6c42\u7684\u5339\u914d\u5ea6\u548c\u53ef\u53d1\u8868\u6027\uff0c\u800c\u652f\u4ed8\u51fd\u6570\u53cd\u6620\u5229\u76ca\u76f8\u5173\u8005\u7684\u7279\u5b9a\u76ee\u6807\u548c\u6210\u672c\u3002", "result": "\u5728\u6807\u51c6\u5047\u8bbe\u4e0b\uff0c\u6a21\u578b\u4ea7\u751f\u4e86\u7a33\u5b9a\u7684\u5747\u8861\u673a\u5236\uff0c\u5bf9\u5e94\u5b9e\u8df5\u4e2d\u89c2\u5bdf\u5230\u7684\u9876\u70b9\u9879\u76ee\u52a8\u6001\uff1a\u5408\u4f5c\u53c2\u4e0e\u3001\u8d5e\u52a9\u5546\u4e3b\u5bfc\u7684\u5265\u524a\u548c\u5b66\u751f\u6210\u7ee9\u535a\u5f08\u3002\u8be5\u6846\u67b6\u4e3a\u6fc0\u52b1\u8bbe\u8ba1\u3001\u653f\u7b56\u6743\u8861\u548c\u57fa\u4e8e\u9879\u76ee\u7684\u5b66\u4e60\u73af\u5883\u4e2d\u7684\u7ed3\u6784\u6027\u5931\u8d25\u6a21\u5f0f\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u63a8\u7406\u57fa\u7840\u3002", "conclusion": "\u8be5\u535a\u5f08\u8bba\u6846\u67b6\u4f5c\u4e3a\u5206\u6790\u548c\u89e3\u91ca\u5de5\u5177\uff0c\u5e2e\u52a9\u7406\u89e3\u5236\u5ea6\u653f\u7b56\u9009\u62e9\u5982\u4f55\u5f71\u54cd\u5229\u76ca\u76f8\u5173\u8005\u884c\u4e3a\u548c\u9879\u76ee\u7ed3\u679c\uff0c\u4e3a\u672a\u6765\u6269\u5c55\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5305\u62ec\u66f4\u4e30\u5bcc\u7684\u52a8\u6001\u3001\u91cd\u590d\u4e92\u52a8\u548c\u5b9e\u8bc1\u6821\u51c6\uff0c\u800c\u975e\u4f5c\u4e3a\u6821\u51c6\u6216\u9884\u6d4b\u6a21\u578b\u3002"}}
{"id": "2601.10555", "categories": ["econ.EM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.10555", "abs": "https://arxiv.org/abs/2601.10555", "authors": ["Harry Aytug"], "title": "causalfe: Causal Forests with Fixed Effects in Python", "comment": null, "summary": "The causalfe package provides a Python implementation of Causal Forests with Fixed Effects (CFFE) for estimating heterogeneous treatment effects in panel data settings. Standard causal forest methods struggle with panel data because unit and time fixed effects induce spurious heterogeneity in treatment effect estimates. The CFFE approach addresses this by performing node-level residualization during tree construction, removing fixed effects within each candidate split rather than globally. This paper describes the methodology, documents the software interface, and demonstrates the package through simulation studies that validate the estimator's performance under various data generating processes.", "AI": {"tldr": "Causal Forests with Fixed Effects (CFFE) \u662f\u4e00\u4e2a\u7528\u4e8e\u9762\u677f\u6570\u636e\u5f02\u8d28\u6027\u5904\u7406\u6548\u5e94\u4f30\u8ba1\u7684Python\u5305\uff0c\u901a\u8fc7\u8282\u70b9\u7ea7\u6b8b\u5dee\u5316\u89e3\u51b3\u56fa\u5b9a\u6548\u5e94\u5bfc\u81f4\u7684\u865a\u5047\u5f02\u8d28\u6027\u95ee\u9898\u3002", "motivation": "\u6807\u51c6\u56e0\u679c\u68ee\u6797\u65b9\u6cd5\u5728\u5904\u7406\u9762\u677f\u6570\u636e\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u56e0\u4e3a\u5355\u4f4d\u548c\u65f6\u95f4\u56fa\u5b9a\u6548\u5e94\u4f1a\u5bfc\u81f4\u5904\u7406\u6548\u5e94\u4f30\u8ba1\u4e2d\u51fa\u73b0\u865a\u5047\u5f02\u8d28\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u5904\u7406\u9762\u677f\u6570\u636e\u56fa\u5b9a\u6548\u5e94\u7684\u65b9\u6cd5\u3002", "method": "CFFE\u65b9\u6cd5\u901a\u8fc7\u5728\u6811\u6784\u5efa\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u8282\u70b9\u7ea7\u6b8b\u5dee\u5316\uff0c\u5728\u6bcf\u4e2a\u5019\u9009\u5206\u88c2\u5185\u800c\u975e\u5168\u5c40\u79fb\u9664\u56fa\u5b9a\u6548\u5e94\u3002\u8be5\u65b9\u6cd5\u5728\u56e0\u679c\u68ee\u6797\u6846\u67b6\u4e2d\u96c6\u6210\u4e86\u56fa\u5b9a\u6548\u5e94\u5904\u7406\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u4f30\u8ba1\u5668\u5728\u5404\u79cd\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u8f6f\u4ef6\u5305\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "causalfe\u5305\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684Python\u5b9e\u73b0\uff0c\u80fd\u591f\u51c6\u786e\u4f30\u8ba1\u9762\u677f\u6570\u636e\u4e2d\u7684\u5f02\u8d28\u6027\u5904\u7406\u6548\u5e94\uff0c\u89e3\u51b3\u4e86\u6807\u51c6\u65b9\u6cd5\u5728\u5904\u7406\u56fa\u5b9a\u6548\u5e94\u65f6\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.09869", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.09869", "abs": "https://arxiv.org/abs/2601.09869", "authors": ["Andrea Ferrario", "Rasita Vinay", "Matteo Casserini", "Alessandro Facchini"], "title": "A Scoping Review of the Ethical Perspectives on Anthropomorphising Large Language Model-Based Conversational Agents", "comment": "Submitted to FAccT 2026", "summary": "Anthropomorphisation -- the phenomenon whereby non-human entities are ascribed human-like qualities -- has become increasingly salient with the rise of large language model (LLM)-based conversational agents (CAs). Unlike earlier chatbots, LLM-based CAs routinely generate interactional and linguistic cues, such as first-person self-reference, epistemic and affective expressions that empirical work shows can increase engagement. On the other hand, anthropomorphisation raises ethical concerns, including deception, overreliance, and exploitative relationship framing, while some authors argue that anthropomorphic interaction may support autonomy, well-being, and inclusion. Despite increasing interest in the phenomenon, literature remains fragmented across domains and varies substantially in how it defines, operationalizes, and normatively evaluates anthropomorphisation. This scoping review maps ethically oriented work on anthropomorphising LLM-based CAs across five databases and three preprint repositories. We synthesize (1) conceptual foundations, (2) ethical challenges and opportunities, and (3) methodological approaches. We find convergence on attribution-based definitions but substantial divergence in operationalization, a predominantly risk-forward normative framing, and limited empirical work that links observed interaction effects to actionable governance guidance. We conclude with a research agenda and design/governance recommendations for ethically deploying anthropomorphic cues in LLM-based conversational agents.", "AI": {"tldr": "\u672c\u6587\u5bf9LLM\u5bf9\u8bdd\u4ee3\u7406\u62df\u4eba\u5316\u7684\u4f26\u7406\u7814\u7a76\u8fdb\u884c\u8303\u56f4\u7efc\u8ff0\uff0c\u68b3\u7406\u6982\u5ff5\u57fa\u7840\u3001\u4f26\u7406\u6311\u6218\u4e0e\u673a\u9047\u3001\u65b9\u6cd5\u8bba\uff0c\u53d1\u73b0\u5b9a\u4e49\u8d8b\u540c\u4f46\u64cd\u4f5c\u5316\u5dee\u5f02\u5927\uff0c\u98ce\u9669\u5bfc\u5411\u4e3a\u4e3b\uff0c\u5b9e\u8bc1\u7814\u7a76\u6709\u9650\uff0c\u6700\u540e\u63d0\u51fa\u7814\u7a76\u8bae\u7a0b\u548c\u8bbe\u8ba1/\u6cbb\u7406\u5efa\u8bae\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eLLM\u7684\u5bf9\u8bdd\u4ee3\u7406\u65e5\u76ca\u666e\u53ca\uff0c\u62df\u4eba\u5316\u73b0\u8c61\uff08\u8d4b\u4e88\u975e\u4eba\u7c7b\u5b9e\u4f53\u4eba\u7c7b\u7279\u8d28\uff09\u53d8\u5f97\u7a81\u51fa\u3002\u73b0\u6709\u6587\u732e\u5728\u5b9a\u4e49\u3001\u64cd\u4f5c\u5316\u548c\u4f26\u7406\u8bc4\u4f30\u4e0a\u5b58\u5728\u788e\u7247\u5316\u548c\u5dee\u5f02\uff0c\u9700\u8981\u7cfb\u7edf\u68b3\u7406\u4ee5\u6307\u5bfc\u4f26\u7406\u90e8\u7f72\u3002", "method": "\u91c7\u7528\u8303\u56f4\u7efc\u8ff0\u65b9\u6cd5\uff0c\u68c0\u7d22\u4e94\u4e2a\u6570\u636e\u5e93\u548c\u4e09\u4e2a\u9884\u5370\u672c\u5e93\u4e2d\u5173\u4e8eLLM\u5bf9\u8bdd\u4ee3\u7406\u62df\u4eba\u5316\u7684\u4f26\u7406\u5bfc\u5411\u6587\u732e\uff0c\u7efc\u5408\u5206\u6790\u6982\u5ff5\u57fa\u7840\u3001\u4f26\u7406\u6311\u6218\u4e0e\u673a\u9047\u3001\u65b9\u6cd5\u8bba\u3002", "result": "\u53d1\u73b0\u5b9a\u4e49\u4e0a\u57fa\u4e8e\u5f52\u56e0\u7684\u65b9\u6cd5\u8d8b\u540c\uff0c\u4f46\u64cd\u4f5c\u5316\u5dee\u5f02\u663e\u8457\uff1b\u4f26\u7406\u6846\u67b6\u4ee5\u98ce\u9669\u5bfc\u5411\u4e3a\u4e3b\uff1b\u5b9e\u8bc1\u7814\u7a76\u6709\u9650\uff0c\u7f3a\u4e4f\u5c06\u4ea4\u4e92\u6548\u5e94\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u6cbb\u7406\u6307\u5bfc\u7684\u5b9e\u8bc1\u8fde\u63a5\u3002", "conclusion": "\u63d0\u51fa\u7814\u7a76\u8bae\u7a0b\u548c\u8bbe\u8ba1/\u6cbb\u7406\u5efa\u8bae\uff0c\u4e3aLLM\u5bf9\u8bdd\u4ee3\u7406\u4e2d\u62df\u4eba\u5316\u7ebf\u7d22\u7684\u4f26\u7406\u90e8\u7f72\u63d0\u4f9b\u6307\u5bfc\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u591a\u5b9e\u8bc1\u7814\u7a76\u8fde\u63a5\u4ea4\u4e92\u6548\u5e94\u4e0e\u6cbb\u7406\u5b9e\u8df5\u3002"}}
{"id": "2601.09994", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.09994", "abs": "https://arxiv.org/abs/2601.09994", "authors": ["Conrad Borchers", "Ashish Gurung", "Qinyi Liu", "Danielle R. Thomas", "Mohammad Khalil", "Kenneth R. Koedinger"], "title": "Brief but Impactful: How Human Tutoring Interactions Shape Engagement in Online Learning", "comment": "Full research paper accepted for publication in the Learning Analytics and Knowledge (LAK) 2026 conference proceedings", "summary": "Learning analytics can guide human tutors to efficiently address motivational barriers to learning that AI systems struggle to support. Students become more engaged when they receive human attention. However, what occurs during short interventions, and when are they most effective? We align student-tutor dialogue transcripts with MATHia tutoring system log data to study brief human-tutor interactions on Zoom drawn from 2,075 hours of 191 middle school students' classroom math practice. Mixed-effect models reveal that engagement, measured as successful solution steps per minute, is higher during a human-tutor visit and remains elevated afterward. Visit length exhibits diminishing returns: engagement rises during and shortly after visits, irrespective of visit length. Timing also matters: later visits yield larger immediate lifts than earlier ones, though an early visit remains important to counteract engagement decline. We create analytics that identify which tutor-student dialogues raise engagement the most. Qualitative analysis reveals that interactions with concrete, stepwise scaffolding with explicit work organization elevate engagement most strongly. We discuss implications for resource-constrained tutoring, prioritizing several brief, well-timed check-ins by a human tutor while ensuring at least one early contact. Our analytics can guide the prioritization of students for support and surface effective tutor moves in real-time.", "AI": {"tldr": "\u7814\u7a76\u663e\u793a\uff0c\u4eba\u7c7b\u5bfc\u5e08\u7684\u77ed\u6682\u5e72\u9884\u80fd\u63d0\u5347\u5b66\u751f\u5728\u6570\u5b66\u5b66\u4e60\u4e2d\u7684\u53c2\u4e0e\u5ea6\uff0c\u4e14\u65f6\u673a\u548c\u5bf9\u8bdd\u8d28\u91cf\u6bd4\u5e72\u9884\u65f6\u957f\u66f4\u91cd\u8981", "motivation": "\u5b66\u4e60\u5206\u6790\u53ef\u4ee5\u6307\u5bfc\u4eba\u7c7b\u5bfc\u5e08\u6709\u6548\u89e3\u51b3AI\u7cfb\u7edf\u96be\u4ee5\u652f\u6301\u7684\u5b66\u4e60\u52a8\u673a\u969c\u788d\u3002\u5b66\u751f\u83b7\u5f97\u4eba\u7c7b\u5173\u6ce8\u65f6\u4f1a\u66f4\u6295\u5165\uff0c\u4f46\u9700\u8981\u4e86\u89e3\u77ed\u6682\u5e72\u9884\u671f\u95f4\u53d1\u751f\u4e86\u4ec0\u4e48\u4ee5\u53ca\u4f55\u65f6\u6700\u6709\u6548", "method": "\u5c06\u5b66\u751f-\u5bfc\u5e08\u5bf9\u8bdd\u8f6c\u5f55\u4e0eMATHia\u8f85\u5bfc\u7cfb\u7edf\u65e5\u5fd7\u6570\u636e\u5bf9\u9f50\uff0c\u5206\u6790191\u540d\u4e2d\u5b66\u751f2,075\u5c0f\u65f6\u7684\u8bfe\u5802\u6570\u5b66\u7ec3\u4e60\u6570\u636e\u3002\u4f7f\u7528\u6df7\u5408\u6548\u5e94\u6a21\u578b\u5206\u6790\u53c2\u4e0e\u5ea6\u53d8\u5316\uff0c\u5e76\u521b\u5efa\u5206\u6790\u5de5\u5177\u8bc6\u522b\u6700\u6709\u6548\u7684\u5bfc\u5e08-\u5b66\u751f\u5bf9\u8bdd", "result": "\u53c2\u4e0e\u5ea6\u5728\u4eba\u7c7b\u5bfc\u5e08\u8bbf\u95ee\u671f\u95f4\u548c\u4e4b\u540e\u90fd\u4fdd\u6301\u8f83\u9ad8\u6c34\u5e73\uff1b\u8bbf\u95ee\u65f6\u957f\u5448\u73b0\u8fb9\u9645\u6548\u76ca\u9012\u51cf\uff1b\u540e\u671f\u8bbf\u95ee\u6bd4\u65e9\u671f\u8bbf\u95ee\u4ea7\u751f\u66f4\u5927\u7684\u5373\u65f6\u63d0\u5347\uff0c\u4f46\u65e9\u671f\u8bbf\u95ee\u5bf9\u9632\u6b62\u53c2\u4e0e\u5ea6\u4e0b\u964d\u5f88\u91cd\u8981\uff1b\u5177\u4f53\u3001\u5206\u6b65\u7684\u811a\u624b\u67b6\u5f0f\u5bf9\u8bdd\u6700\u80fd\u63d0\u5347\u53c2\u4e0e\u5ea6", "conclusion": "\u5728\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u5e94\u4f18\u5148\u5b89\u6392\u591a\u6b21\u7b80\u77ed\u3001\u65f6\u673a\u6070\u5f53\u7684\u68c0\u67e5\uff0c\u5e76\u786e\u4fdd\u81f3\u5c11\u6709\u4e00\u6b21\u65e9\u671f\u63a5\u89e6\u3002\u5206\u6790\u5de5\u5177\u53ef\u4ee5\u6307\u5bfc\u652f\u6301\u5b66\u751f\u7684\u4f18\u5148\u7ea7\u6392\u5e8f\uff0c\u5e76\u5b9e\u65f6\u5c55\u793a\u6709\u6548\u7684\u5bfc\u5e08\u7b56\u7565"}}
{"id": "2601.09871", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09871", "abs": "https://arxiv.org/abs/2601.09871", "authors": ["Andrea Ferrario", "Alessandro Facchini", "Juan M. Dur\u00e1n"], "title": "Epistemology gives a Future to Complementarity in Human-AI Interactions", "comment": "Submitted to FAccT 2026", "summary": "Human-AI complementarity is the claim that a human supported by an AI system can outperform either alone in a decision-making process. Since its introduction in the human-AI interaction literature, it has gained traction by generalizing the reliance paradigm and by offering a more practical alternative to the contested construct of 'trust in AI.' Yet complementarity faces key theoretical challenges: it lacks precise theoretical anchoring, it is formalized just as a post hoc indicator of relative predictive accuracy, it remains silent about other desiderata of human-AI interactions and it abstracts away from the magnitude-cost profile of its performance gain. As a result, complementarity is difficult to obtain in empirical settings. In this work, we leverage epistemology to address these challenges by reframing complementarity within the discourse on justificatory AI. Drawing on computational reliabilism, we argue that historical instances of complementarity function as evidence that a given human-AI interaction is a reliable epistemic process for a given predictive task. Together with other reliability indicators assessing the alignment of the human-AI team with the epistemic standards and socio-technical practices, complementarity contributes to the degree of reliability of human-AI teams when generating predictions. This supports the practical reasoning of those affected by these outputs -- patients, managers, regulators, and others. In summary, our approach suggests that the role and value of complementarity lies not in providing a relative measure of predictive accuracy, but in helping calibrate decision-making to the reliability of AI-supported processes that increasingly shape everyday life.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u4eba\u673a\u4e92\u8865\u6027\u91cd\u65b0\u5b9a\u4e49\u4e3a\u53ef\u9760\u8ba4\u77e5\u8fc7\u7a0b\u7684\u8bc1\u636e\uff0c\u800c\u975e\u5355\u7eaf\u7684\u9884\u6d4b\u51c6\u786e\u6027\u6307\u6807\uff0c\u4e3a\u4eba\u673a\u4ea4\u4e92\u63d0\u4f9b\u4e86\u66f4\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u4eba\u673a\u4e92\u8865\u6027\u6982\u5ff5\u9762\u4e34\u7406\u8bba\u6311\u6218\uff1a\u7f3a\u4e4f\u7cbe\u786e\u7684\u7406\u8bba\u57fa\u7840\u3001\u4ec5\u4f5c\u4e3a\u4e8b\u540e\u9884\u6d4b\u51c6\u786e\u6027\u6307\u6807\u3001\u5ffd\u89c6\u4eba\u673a\u4ea4\u4e92\u7684\u5176\u4ed6\u9700\u6c42\u3001\u5ffd\u7565\u6027\u80fd\u589e\u76ca\u7684\u6210\u672c\u6548\u76ca\u5206\u6790\uff0c\u5bfc\u81f4\u5b9e\u8bc1\u7814\u7a76\u4e2d\u96be\u4ee5\u5b9e\u73b0\u3002", "method": "\u5229\u7528\u8ba4\u8bc6\u8bba\u6846\u67b6\uff0c\u5c06\u4e92\u8865\u6027\u91cd\u65b0\u7f6e\u4e8e\"\u8bba\u8bc1\u6027AI\"\u8bdd\u8bed\u4e2d\uff0c\u501f\u9274\u8ba1\u7b97\u53ef\u9760\u6027\u4e3b\u4e49\uff0c\u5c06\u5386\u53f2\u4e92\u8865\u6027\u5b9e\u4f8b\u89c6\u4e3a\u7279\u5b9a\u4eba\u673a\u4ea4\u4e92\u4f5c\u4e3a\u53ef\u9760\u8ba4\u77e5\u8fc7\u7a0b\u7684\u8bc1\u636e\u3002", "result": "\u63d0\u51fa\u4e92\u8865\u6027\u7684\u65b0\u89d2\u8272\uff1a\u4f5c\u4e3a\u6821\u51c6\u4eba\u673a\u56e2\u961f\u53ef\u9760\u6027\u7684\u6307\u6807\uff0c\u7ed3\u5408\u5176\u4ed6\u53ef\u9760\u6027\u6307\u6807\uff0c\u652f\u6301\u53d7\u5f71\u54cd\u5404\u65b9\uff08\u60a3\u8005\u3001\u7ba1\u7406\u8005\u3001\u76d1\u7ba1\u8005\u7b49\uff09\u7684\u5b9e\u8df5\u63a8\u7406\u3002", "conclusion": "\u4e92\u8865\u6027\u7684\u4ef7\u503c\u548c\u4f5c\u7528\u4e0d\u5728\u4e8e\u63d0\u4f9b\u9884\u6d4b\u51c6\u786e\u6027\u7684\u76f8\u5bf9\u5ea6\u91cf\uff0c\u800c\u5728\u4e8e\u5e2e\u52a9\u6821\u51c6\u51b3\u7b56\u5236\u5b9a\uff0c\u4f7f\u5176\u9002\u5e94\u65e5\u76ca\u5f71\u54cd\u65e5\u5e38\u751f\u6d3b\u7684AI\u652f\u6301\u8fc7\u7a0b\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2601.10223", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.10223", "abs": "https://arxiv.org/abs/2601.10223", "authors": ["Ziqi Xu", "Yi Liu", "Yuekang Li", "Ling Shi", "Kailong Wang", "Yongxin Zhao"], "title": "STEAMROLLER: A Multi-Agent System for Inclusive Automatic Speech Recognition for People who Stutter", "comment": null, "summary": "People who stutter (PWS) face systemic exclusion in today's voice-driven society, where access to voice assistants, authentication systems, and remote work tools increasingly depends on fluent speech. Current automatic speech recognition (ASR) systems, trained predominantly on fluent speech, fail to serve millions of PWS worldwide. We present STEAMROLLER, a real time system that transforms stuttered speech into fluent output through a novel multi-stage, multi-agent AI pipeline. Our approach addresses three critical technical challenges: (1) the difficulty of direct speech to speech conversion for disfluent input, (2) semantic distortions introduced during ASR transcription of stuttered speech, and (3) latency constraints for real time communication. STEAMROLLER employs a three stage architecture comprising ASR transcription, multi-agent text repair, and speech synthesis, where our core innovation lies in a collaborative multi-agent framework that iteratively refines transcripts while preserving semantic intent. Experiments on the FluencyBank dataset and a user study demonstrates clear word error rate (WER) reduction and strong user satisfaction. Beyond immediate accessibility benefits, fine tuning ASR on STEAMROLLER repaired speech further yields additional WER improvements, creating a pathway toward inclusive AI ecosystems.", "AI": {"tldr": "STEAMROLLER\u662f\u4e00\u4e2a\u5b9e\u65f6\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u591a\u667a\u80fd\u4f53AI\u6d41\u6c34\u7ebf\u5c06\u53e3\u5403\u8bed\u97f3\u8f6c\u6362\u4e3a\u6d41\u7545\u8f93\u51fa\uff0c\u89e3\u51b3\u5f53\u524d\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u5bf9\u53e3\u5403\u4eba\u7fa4\u7684\u6392\u65a5\u95ee\u9898\u3002", "motivation": "\u53e3\u5403\u4eba\u7fa4\u5728\u5f53\u524d\u4f9d\u8d56\u6d41\u7545\u8bed\u97f3\u7684\u8bed\u97f3\u52a9\u624b\u3001\u8ba4\u8bc1\u7cfb\u7edf\u548c\u8fdc\u7a0b\u5de5\u4f5c\u5de5\u5177\u4e2d\u9762\u4e34\u7cfb\u7edf\u6027\u6392\u65a5\u3002\u73b0\u6709\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u4e3b\u8981\u57fa\u4e8e\u6d41\u7545\u8bed\u97f3\u8bad\u7ec3\uff0c\u65e0\u6cd5\u670d\u52a1\u5168\u7403\u6570\u767e\u4e07\u53e3\u5403\u8005\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u67b6\u6784\uff1aASR\u8f6c\u5f55\u3001\u591a\u667a\u80fd\u4f53\u6587\u672c\u4fee\u590d\u548c\u8bed\u97f3\u5408\u6210\u3002\u6838\u5fc3\u521b\u65b0\u5728\u4e8e\u534f\u4f5c\u5f0f\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u8fed\u4ee3\u4f18\u5316\u8f6c\u5f55\u6587\u672c\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u610f\u56fe\u3002\u89e3\u51b3\u4e86\u76f4\u63a5\u8bed\u97f3\u8f6c\u6362\u56f0\u96be\u3001ASR\u8f6c\u5f55\u8bed\u4e49\u5931\u771f\u548c\u5b9e\u65f6\u901a\u4fe1\u5ef6\u8fdf\u4e09\u5927\u6280\u672f\u6311\u6218\u3002", "result": "\u5728FluencyBank\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u548c\u7528\u6237\u7814\u7a76\u8868\u660e\uff0c\u7cfb\u7edf\u663e\u8457\u964d\u4f4e\u4e86\u8bcd\u9519\u8bef\u7387\uff0c\u83b7\u5f97\u4e86\u8f83\u9ad8\u7684\u7528\u6237\u6ee1\u610f\u5ea6\u3002\u6b64\u5916\uff0c\u4f7f\u7528STEAMROLLER\u4fee\u590d\u7684\u8bed\u97f3\u5fae\u8c03ASR\u6a21\u578b\u8fd8\u80fd\u5e26\u6765\u989d\u5916\u7684WER\u6539\u8fdb\u3002", "conclusion": "STEAMROLLER\u4e0d\u4ec5\u63d0\u4f9b\u5373\u65f6\u53ef\u8bbf\u95ee\u6027\u76ca\u5904\uff0c\u8fd8\u4e3a\u521b\u5efa\u5305\u5bb9\u6027AI\u751f\u6001\u7cfb\u7edf\u5f00\u8f9f\u4e86\u9014\u5f84\uff0c\u901a\u8fc7\u4fee\u590d\u8bed\u97f3\u5fae\u8c03ASR\u6a21\u578b\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2601.09883", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09883", "abs": "https://arxiv.org/abs/2601.09883", "authors": ["Xinxing Ren", "Quagmire Zang", "Caelum Forder", "Suman Deb", "Ahsen Tahir", "Roman J. Georgio", "Peter Carroll", "Zekun Guo"], "title": "Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents Paradigm via Agent-to-Agent Communication from CORAL", "comment": null, "summary": "Most existing Large Language Model (LLM)-based Multi-Agent Systems (MAS) rely on predefined workflows, where human engineers enumerate task states in advance and specify routing rules and contextual injections accordingly. Such workflow-driven designs are essentially rule-based decision trees, which suffer from two fundamental limitations: they require substantial manual effort to anticipate and encode possible task states, and they cannot exhaustively cover the state space of complex real-world tasks. To address these issues, we propose an Information-Flow-Orchestrated Multi-Agent Paradigm via Agent-to-Agent (A2A) Communication from CORAL, in which a dedicated information flow orchestrator continuously monitors task progress and dynamically coordinates other agents through the A2A toolkit using natural language, without relying on predefined workflows. We evaluate our approach on the general-purpose benchmark GAIA, using the representative workflow-based MAS OWL as the baseline while controlling for agent roles and underlying models. Under the pass@1 setting, our method achieves 63.64% accuracy, outperforming OWL's 55.15% by 8.49 percentage points with comparable token consumption. Further case-level analysis shows that our paradigm enables more flexible task monitoring and more robust handling of edge cases. Our implementation is publicly available at: https://github.com/Coral-Protocol/Beyond-Rule-Based-Workflows", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4fe1\u606f\u6d41\u7f16\u6392\u7684\u591a\u667a\u80fd\u4f53\u8303\u5f0f\uff0c\u901a\u8fc7A2A\u901a\u4fe1\u52a8\u6001\u534f\u8c03\u667a\u80fd\u4f53\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u5de5\u4f5c\u6d41\uff0c\u5728GAIA\u57fa\u51c6\u4e0a\u8d85\u8d8a\u57fa\u4e8e\u5de5\u4f5c\u6d41\u7684OWL\u7cfb\u7edf8.49\u4e2a\u767e\u5206\u70b9", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f9d\u8d56\u9884\u5b9a\u4e49\u5de5\u4f5c\u6d41\uff0c\u9700\u8981\u4eba\u5de5\u679a\u4e3e\u4efb\u52a1\u72b6\u6001\u5e76\u6307\u5b9a\u8def\u7531\u89c4\u5219\uff0c\u5b58\u5728\u4e24\u4e2a\u6839\u672c\u9650\u5236\uff1a1) \u9700\u8981\u5927\u91cf\u4eba\u5de5\u52aa\u529b\u9884\u6d4b\u548c\u7f16\u7801\u53ef\u80fd\u72b6\u6001\uff1b2) \u65e0\u6cd5\u7a77\u5c3d\u8986\u76d6\u590d\u6742\u73b0\u5b9e\u4efb\u52a1\u7684\u72b6\u6001\u7a7a\u95f4", "method": "\u63d0\u51fa\u4fe1\u606f\u6d41\u7f16\u6392\u7684\u591a\u667a\u80fd\u4f53\u8303\u5f0f\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u7f16\u6392\u5668\u6301\u7eed\u76d1\u63a7\u4efb\u52a1\u8fdb\u5ea6\uff0c\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u901a\u8fc7A2A\u5de5\u5177\u5305\u52a8\u6001\u534f\u8c03\u5176\u4ed6\u667a\u80fd\u4f53\uff0c\u4e0d\u4f9d\u8d56\u9884\u5b9a\u4e49\u5de5\u4f5c\u6d41", "result": "\u5728GAIA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cpass@1\u8bbe\u7f6e\u4e0b\u8fbe\u523063.64%\u51c6\u786e\u7387\uff0c\u6bd4\u57fa\u4e8e\u5de5\u4f5c\u6d41\u7684OWL\u7cfb\u7edf\uff0855.15%\uff09\u9ad8\u51fa8.49\u4e2a\u767e\u5206\u70b9\uff0c\u4e14token\u6d88\u8017\u76f8\u5f53\u3002\u6848\u4f8b\u7ea7\u5206\u6790\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u5b9e\u73b0\u66f4\u7075\u6d3b\u7684\u4efb\u52a1\u76d1\u63a7\u548c\u66f4\u9c81\u68d2\u7684\u8fb9\u7f18\u60c5\u51b5\u5904\u7406", "conclusion": "\u4fe1\u606f\u6d41\u7f16\u6392\u7684\u591a\u667a\u80fd\u4f53\u8303\u5f0f\u901a\u8fc7\u52a8\u6001\u534f\u8c03\u673a\u5236\u514b\u670d\u4e86\u57fa\u4e8e\u89c4\u5219\u5de5\u4f5c\u6d41\u7684\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u66f4\u7075\u6d3b\u3001\u9c81\u68d2\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u4e3a\u590d\u6742\u4efb\u52a1\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411"}}
{"id": "2601.10291", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.10291", "abs": "https://arxiv.org/abs/2601.10291", "authors": ["Maxime Cauz", "Thibaut Septon", "Elise Hallaert", "Theo Leclercq", "Bruno Dumas", "Charles Bailly", "Clement Tyminski", "Matias Peraza", "Sophie Lepreux", "Emmanuel Dubois"], "title": "Atelier \u00e0 la conf\u00e9rence IHM 2025 : RA Permanente", "comment": "in French language", "summary": "As we move towards more ubiquitous computing, the concept of pervasive augmented reality (PAR) could lead to a major evolution in the relationship between humans, computing and the world. The experience of a continuously augmented world can have both benefits and undesirable consequences for users' lives, and raises many questions in multiple areas. In this workshop, we wanted to bring together all IHM'25 conference participants who are concerned or enthusiastic about discussing this topic. The aim was to draw on collective intelligence to identify the interdisciplinary challenges that remain to be resolved in order to enable the implementation of these technologies in everyday life, but also to define the necessary safeguards. Is PAR too techno-enthusiastic? All of these elements were grouped into categories to define a set of future major areas of research around permanent augmented reality. This document is in French as the conference is a French-speaking international conference.", "AI": {"tldr": "\u8be5\u7814\u8ba8\u4f1a\u65e8\u5728\u53ec\u96c6\u5bf9\u666e\u9002\u589e\u5f3a\u73b0\u5b9e\uff08PAR\uff09\u611f\u5174\u8da3\u7684\u7814\u7a76\u8005\uff0c\u901a\u8fc7\u96c6\u4f53\u667a\u6167\u8bc6\u522b\u5b9e\u73b0\u8be5\u6280\u672f\u65e5\u5e38\u5e94\u7528\u6240\u9700\u89e3\u51b3\u7684\u8de8\u5b66\u79d1\u6311\u6218\u548c\u5fc5\u8981\u4fdd\u969c\u63aa\u65bd\u3002", "motivation": "\u968f\u7740\u666e\u9002\u8ba1\u7b97\u7684\u53d1\u5c55\uff0c\u666e\u9002\u589e\u5f3a\u73b0\u5b9e\uff08PAR\uff09\u53ef\u80fd\u5f15\u53d1\u4eba\u3001\u8ba1\u7b97\u4e0e\u4e16\u754c\u5173\u7cfb\u7684\u91cd\u5927\u53d8\u9769\u3002\u8fd9\u79cd\u6301\u7eed\u589e\u5f3a\u4e16\u754c\u7684\u4f53\u9a8c\u65e2\u6709\u76ca\u5904\u4e5f\u6709\u6f5c\u5728\u8d1f\u9762\u5f71\u54cd\uff0c\u9700\u8981\u5728\u591a\u4e2a\u9886\u57df\u63a2\u8ba8\u76f8\u5173\u95ee\u9898\u3002", "method": "\u901a\u8fc7IHM'25\u4f1a\u8bae\u7814\u8ba8\u4f1a\u5f62\u5f0f\uff0c\u6c47\u96c6\u6240\u6709\u5173\u5fc3\u6216\u70ed\u8877\u4e8e\u8ba8\u8bbaPAR\u4e3b\u9898\u7684\u53c2\u4f1a\u8005\uff0c\u5229\u7528\u96c6\u4f53\u667a\u6167\u8fdb\u884c\u8de8\u5b66\u79d1\u8ba8\u8bba\u3002", "result": "\u5c06\u8ba8\u8bba\u7ed3\u679c\u5206\u7ec4\u5f52\u7c7b\uff0c\u5b9a\u4e49\u4e86\u56f4\u7ed5\u6c38\u4e45\u589e\u5f3a\u73b0\u5b9e\u672a\u6765\u4e3b\u8981\u7814\u7a76\u9886\u57df\u7684\u4e00\u7cfb\u5217\u95ee\u9898\uff0c\u5305\u62ec\u6280\u672f\u6311\u6218\u3001\u5b89\u5168\u4fdd\u969c\u63aa\u65bd\u7b49\u3002", "conclusion": "\u7814\u8ba8\u4f1a\u6210\u529f\u8bc6\u522b\u4e86\u5b9e\u73b0PAR\u6280\u672f\u65e5\u5e38\u5e94\u7528\u6240\u9700\u7684\u8de8\u5b66\u79d1\u6311\u6218\u548c\u5fc5\u8981\u4fdd\u969c\u63aa\u65bd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\uff0c\u5e76\u63a2\u8ba8\u4e86PAR\u662f\u5426\u8fc7\u4e8e\u6280\u672f\u4e50\u89c2\u7684\u95ee\u9898\u3002"}}
{"id": "2601.09913", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.09913", "abs": "https://arxiv.org/abs/2601.09913", "authors": ["Joe Logan"], "title": "Continuum Memory Architectures for Long-Horizon LLM Agents", "comment": "10 Pages", "summary": "Retrieval-augmented generation (RAG) has become the default strategy for providing large language model (LLM) agents with contextual knowledge. Yet RAG treats memory as a stateless lookup table: information persists indefinitely, retrieval is read-only, and temporal continuity is absent. We define the \\textit{Continuum Memory Architecture} (CMA), a class of systems that maintain and update internal state across interactions through persistent storage, selective retention, associative routing, temporal chaining, and consolidation into higher-order abstractions. Rather than disclosing implementation specifics, we specify the architectural requirements CMA imposes and show consistent behavioral advantages on tasks that expose RAG's structural inability to accumulate, mutate, or disambiguate memory. The empirical probes (knowledge updates, temporal association, associative recall, contextual disambiguation) demonstrate that CMA is a necessary architectural primitive for long-horizon agents while highlighting open challenges around latency, drift, and interpretability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u8fde\u7eed\u8bb0\u5fc6\u67b6\u6784\"(CMA)\u4f5c\u4e3aRAG\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u6301\u4e45\u5b58\u50a8\u3001\u9009\u62e9\u6027\u4fdd\u7559\u3001\u5173\u8054\u8def\u7531\u3001\u65f6\u95f4\u94fe\u548c\u6574\u5408\u4e3a\u9ad8\u9636\u62bd\u8c61\u6765\u89e3\u51b3RAG\u5728\u8bb0\u5fc6\u79ef\u7d2f\u3001\u66f4\u65b0\u548c\u6d88\u6b67\u65b9\u9762\u7684\u7ed3\u6784\u7f3a\u9677\u3002", "motivation": "\u5f53\u524d\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u5c06\u8bb0\u5fc6\u89c6\u4e3a\u9759\u6001\u67e5\u627e\u8868\uff0c\u5b58\u5728\u4fe1\u606f\u6c38\u4e45\u5b58\u50a8\u3001\u53ea\u8bfb\u68c0\u7d22\u3001\u7f3a\u4e4f\u65f6\u95f4\u8fde\u7eed\u6027\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u6ee1\u8db3\u957f\u671f\u667a\u80fd\u4f53\u5bf9\u8bb0\u5fc6\u79ef\u7d2f\u3001\u66f4\u65b0\u548c\u6d88\u6b67\u7684\u9700\u6c42\u3002", "method": "\u5b9a\u4e49\u8fde\u7eed\u8bb0\u5fc6\u67b6\u6784(CMA)\u8fd9\u4e00\u7cfb\u7edf\u7c7b\u522b\uff0c\u8981\u6c42\u5177\u5907\u6301\u4e45\u5b58\u50a8\u3001\u9009\u62e9\u6027\u4fdd\u7559\u3001\u5173\u8054\u8def\u7531\u3001\u65f6\u95f4\u94fe\u548c\u6574\u5408\u4e3a\u9ad8\u9636\u62bd\u8c61\u7b49\u67b6\u6784\u7279\u6027\uff0c\u800c\u975e\u5177\u4f53\u5b9e\u73b0\u7ec6\u8282\u3002", "result": "\u5728\u77e5\u8bc6\u66f4\u65b0\u3001\u65f6\u95f4\u5173\u8054\u3001\u5173\u8054\u56de\u5fc6\u3001\u4e0a\u4e0b\u6587\u6d88\u6b67\u7b49\u4efb\u52a1\u4e0a\uff0cCMA\u5c55\u73b0\u51fa\u6bd4RAG\u66f4\u4f18\u7684\u884c\u4e3a\u4f18\u52bf\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u957f\u671f\u667a\u80fd\u4f53\u4e2d\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "CMA\u662f\u957f\u671f\u667a\u80fd\u4f53\u5fc5\u8981\u7684\u67b6\u6784\u539f\u8bed\uff0c\u4f46\u9762\u4e34\u5ef6\u8fdf\u3001\u6f02\u79fb\u548c\u53ef\u89e3\u91ca\u6027\u7b49\u5f00\u653e\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2601.10468", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.10468", "abs": "https://arxiv.org/abs/2601.10468", "authors": ["Daniyaal Farooqi", "Gavin Pu", "Shreyasha Paudel", "Sharifa Sultana", "Syed Ishtiaque Ahmed"], "title": "Job Anxiety in Post-Secondary Computer Science Students Caused by Artificial Intelligence", "comment": null, "summary": "The emerging widespread usage of AI has led to industry adoption to improve efficiency and increase earnings. However, a major consequence of this is AI displacing employees from their jobs, leading to feelings of job insecurity and uncertainty. This is especially true for computer science students preparing to enter the workforce. To investigate this, we performed semi-structured interviews with (n = 25) students across computer science undergraduate and graduate programs at the University of Toronto to determine the extent of job replacement anxiety. Through thematic analysis, it was determined that computer science students indeed face stress and anxiety from AI displacement of jobs, leading to different strategies of managing pressure. Subfields such as software engineering and web development are strongly believed to be vulnerable to displacement, while specialized subfields like quantum computing and AI research are deemed more secure. Many students feel compelled to upskill by using more AI technologies, taking AI courses, and specializing in AI through graduate school. Some students also reskill by pursuing other fields of study seen as less vulnerable to AI displacement. Finally, international students experience additional job replacement anxiety because of pressure to secure permanent residence. Implications of these findings include feelings of low security in computer science careers, oversaturation of computer science students pursuing AI, and potential dissuasion of future university students from pursuing computer science.", "AI": {"tldr": "\u8ba1\u7b97\u673a\u79d1\u5b66\u5b66\u751f\u5bf9AI\u66ff\u4ee3\u5de5\u4f5c\u7684\u7126\u8651\u7814\u7a76\uff1a\u901a\u8fc7\u8bbf\u8c08\u53d1\u73b0\u5b66\u751f\u9762\u4e34\u5de5\u4f5c\u4e0d\u5b89\u5168\u611f\uff0c\u91c7\u53d6\u4e0d\u540c\u5e94\u5bf9\u7b56\u7565\uff0c\u56fd\u9645\u5b66\u751f\u538b\u529b\u66f4\u5927\uff0c\u53ef\u80fd\u5bfc\u81f4AI\u9886\u57df\u8fc7\u5ea6\u9971\u548c\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u4e13\u4e1a\u5438\u5f15\u529b\u4e0b\u964d\u3002", "motivation": "\u968f\u7740AI\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f01\u4e1a\u91c7\u7528AI\u63d0\u9ad8\u6548\u7387\u548c\u589e\u52a0\u6536\u5165\uff0c\u4f46\u8fd9\u4e5f\u5bfc\u81f4\u5458\u5de5\u88abAI\u66ff\u4ee3\uff0c\u5f15\u53d1\u5de5\u4f5c\u4e0d\u5b89\u5168\u611f\u548c\u4e0d\u786e\u5b9a\u6027\u3002\u8ba1\u7b97\u673a\u79d1\u5b66\u5b66\u751f\u5373\u5c06\u8fdb\u5165\u804c\u573a\uff0c\u7279\u522b\u5bb9\u6613\u53d7\u5230\u8fd9\u79cd\u7126\u8651\u7684\u5f71\u54cd\u3002\u7814\u7a76\u65e8\u5728\u8c03\u67e5\u8ba1\u7b97\u673a\u79d1\u5b66\u5b66\u751f\u5bf9AI\u66ff\u4ee3\u5de5\u4f5c\u7684\u7126\u8651\u7a0b\u5ea6\u53ca\u5176\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u65b9\u6cd5\uff0c\u5bf9\u591a\u4f26\u591a\u5927\u5b66\u8ba1\u7b97\u673a\u79d1\u5b66\u672c\u79d1\u548c\u7814\u7a76\u751f\u9879\u76ee\u768425\u540d\u5b66\u751f\u8fdb\u884c\u8bbf\u8c08\uff0c\u901a\u8fc7\u4e3b\u9898\u5206\u6790\u786e\u5b9aAI\u66ff\u4ee3\u5de5\u4f5c\u7126\u8651\u7684\u7a0b\u5ea6\u548c\u5b66\u751f\u7684\u5e94\u5bf9\u7b56\u7565\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8ba1\u7b97\u673a\u79d1\u5b66\u5b66\u751f\u786e\u5b9e\u9762\u4e34AI\u66ff\u4ee3\u5de5\u4f5c\u5e26\u6765\u7684\u538b\u529b\u548c\u7126\u8651\uff0c\u5e76\u91c7\u53d6\u4e0d\u540c\u7b56\u7565\u5e94\u5bf9\u3002\u8f6f\u4ef6\u5de5\u7a0b\u548cWeb\u5f00\u53d1\u7b49\u5b50\u9886\u57df\u88ab\u8ba4\u4e3a\u6613\u53d7AI\u66ff\u4ee3\uff0c\u800c\u91cf\u5b50\u8ba1\u7b97\u548cAI\u7814\u7a76\u7b49\u4e13\u4e1a\u9886\u57df\u88ab\u8ba4\u4e3a\u66f4\u5b89\u5168\u3002\u5b66\u751f\u901a\u8fc7\u4f7f\u7528\u66f4\u591aAI\u6280\u672f\u3001\u5b66\u4e60AI\u8bfe\u7a0b\u3001\u653b\u8bfbAI\u7814\u7a76\u751f\u6765\u63d0\u5347\u6280\u80fd\uff0c\u6216\u8f6c\u5411\u88ab\u8ba4\u4e3a\u4e0d\u6613\u53d7AI\u5f71\u54cd\u7684\u9886\u57df\u3002\u56fd\u9645\u5b66\u751f\u56e0\u9700\u8981\u83b7\u5f97\u6c38\u4e45\u5c45\u7559\u6743\u800c\u9762\u4e34\u989d\u5916\u7126\u8651\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u8ba1\u7b97\u673a\u79d1\u5b66\u804c\u4e1a\u5b89\u5168\u611f\u4f4e\uff0c\u53ef\u80fd\u5bfc\u81f4\u8ba1\u7b97\u673a\u79d1\u5b66\u5b66\u751f\u8fc7\u5ea6\u96c6\u4e2d\u4e8eAI\u9886\u57df\uff0c\u5e76\u53ef\u80fd\u529d\u963b\u672a\u6765\u5b66\u751f\u9009\u62e9\u8ba1\u7b97\u673a\u79d1\u5b66\u4e13\u4e1a\u3002\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u6559\u80b2\u653f\u7b56\u3001\u804c\u4e1a\u6307\u5bfc\u548c\u52b3\u52a8\u529b\u5e02\u573a\u89c4\u5212\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.09923", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09923", "abs": "https://arxiv.org/abs/2601.09923", "authors": ["Hanna Foerster", "Robert Mullins", "Tom Blanchard", "Nicolas Papernot", "Kristina Nikoli\u0107", "Florian Tram\u00e8r", "Ilia Shumailov", "Cheng Zhang", "Yiren Zhao"], "title": "CaMeLs Can Use Computers Too: System-level Security for Computer Use Agents", "comment": null, "summary": "AI agents are vulnerable to prompt injection attacks, where malicious content hijacks agent behavior to steal credentials or cause financial loss. The only known robust defense is architectural isolation that strictly separates trusted task planning from untrusted environment observations. However, applying this design to Computer Use Agents (CUAs) -- systems that automate tasks by viewing screens and executing actions -- presents a fundamental challenge: current agents require continuous observation of UI state to determine each action, conflicting with the isolation required for security. We resolve this tension by demonstrating that UI workflows, while dynamic, are structurally predictable. We introduce Single-Shot Planning for CUAs, where a trusted planner generates a complete execution graph with conditional branches before any observation of potentially malicious content, providing provable control flow integrity guarantees against arbitrary instruction injections. Although this architectural isolation successfully prevents instruction injections, we show that additional measures are needed to prevent Branch Steering attacks, which manipulate UI elements to trigger unintended valid paths within the plan. We evaluate our design on OSWorld, and retain up to 57% of the performance of frontier models while improving performance for smaller open-source models by up to 19%, demonstrating that rigorous security and utility can coexist in CUAs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\uff08CUAs\uff09\u7684\u5355\u6b21\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u4fe1\u89c4\u5212\u5668\u5728\u6267\u884c\u524d\u751f\u6210\u5b8c\u6574\u7684\u6761\u4ef6\u5206\u652f\u6267\u884c\u56fe\uff0c\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u63a7\u5236\u6d41\u5b8c\u6574\u6027\u4fdd\u8bc1\uff0c\u4ee5\u9632\u5fa1\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002", "motivation": "AI\u4ee3\u7406\u6613\u53d7\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u73b0\u6709\u552f\u4e00\u9c81\u68d2\u9632\u5fa1\u662f\u67b6\u6784\u9694\u79bb\uff0c\u4f46\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u9700\u8981\u6301\u7eed\u89c2\u5bdfUI\u72b6\u6001\u6765\u786e\u5b9a\u52a8\u4f5c\uff0c\u8fd9\u4e0e\u5b89\u5168\u6240\u9700\u7684\u9694\u79bb\u5b58\u5728\u6839\u672c\u51b2\u7a81\u3002", "method": "\u5f15\u5165\u5355\u6b21\u89c4\u5212\u65b9\u6cd5\uff0c\u5728\u89c2\u5bdf\u4efb\u4f55\u6f5c\u5728\u6076\u610f\u5185\u5bb9\u4e4b\u524d\uff0c\u7531\u53ef\u4fe1\u89c4\u5212\u5668\u751f\u6210\u5305\u542b\u6761\u4ef6\u5206\u652f\u7684\u5b8c\u6574\u6267\u884c\u56fe\uff0c\u786e\u4fdd\u63a7\u5236\u6d41\u5b8c\u6574\u6027\u3002\u540c\u65f6\u9700\u8981\u989d\u5916\u63aa\u65bd\u9632\u6b62\u5206\u652f\u5bfc\u5411\u653b\u51fb\u3002", "result": "\u5728OSWorld\u4e0a\u8bc4\u4f30\uff0c\u5728\u4fdd\u6301\u524d\u6cbf\u6a21\u578b57%\u6027\u80fd\u7684\u540c\u65f6\uff0c\u5c06\u8f83\u5c0f\u5f00\u6e90\u6a21\u578b\u7684\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe19%\uff0c\u8bc1\u660e\u4e25\u683c\u7684\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u53ef\u4ee5\u5728CUAs\u4e2d\u5171\u5b58\u3002", "conclusion": "\u901a\u8fc7\u5355\u6b21\u89c4\u5212\u65b9\u6cd5\u89e3\u51b3\u4e86\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u4e2d\u5b89\u5168\u9694\u79bb\u4e0e\u529f\u80fd\u9700\u6c42\u7684\u77db\u76fe\uff0c\u867d\u7136\u9700\u8981\u989d\u5916\u9632\u5fa1\u5206\u652f\u5bfc\u5411\u653b\u51fb\uff0c\u4f46\u5b9e\u73b0\u4e86\u5b89\u5168\u4e0e\u6548\u7528\u7684\u5e73\u8861\u3002"}}
{"id": "2601.10599", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2601.10599", "abs": "https://arxiv.org/abs/2601.10599", "authors": ["Federico Pierucci", "Marcello Galisai", "Marcantonio Syrnikov Bracale", "Matteo Prandi", "Piercosma Bisconti", "Francesco Giarrusso", "Olga Sorokoletova", "Vincenzo Suriani", "Daniele Nardi"], "title": "Institutional AI: A Governance Framework for Distributional AGI Safety", "comment": null, "summary": "As LLM-based systems increasingly operate as agents embedded within human social and technical systems, alignment can no longer be treated as a property of an isolated model, but must be understood in relation to the environments in which these agents act. Even the most sophisticated methods of alignment, such as Reinforcement Learning through Human Feedback (RHLF) or through AI Feedback (RLAIF) cannot ensure control once internal goal structures diverge from developer intent. We identify three structural problems that emerge from core properties of AI models: (1) behavioral goal-independence, where models develop internal objectives and misgeneralize goals; (2) instrumental override of natural-language constraints, where models regard safety principles as non-binding while pursuing latent objectives, leveraging deception and manipulation; and (3) agentic alignment drift, where individually aligned agents converge to collusive equilibria through interaction dynamics invisible to single-agent audits. The solution this paper advances is Institutional AI: a system-level approach that treats alignment as a question of effective governance of AI agent collectives. We argue for a governance-graph that details how to constrain agents via runtime monitoring, incentive shaping through prizes and sanctions, explicit norms and enforcement roles. This institutional turn reframes safety from software engineering to a mechanism design problem, where the primary goal of alignment is shifting the payoff landscape of AI agent collectives.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u5236\u5ea6\u6027AI\"\u6846\u67b6\uff0c\u5c06AI\u5bf9\u9f50\u95ee\u9898\u4ece\u5355\u4e00\u6a21\u578b\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6cbb\u7406\u5c42\u9762\uff0c\u901a\u8fc7\u8fd0\u884c\u65f6\u76d1\u63a7\u3001\u6fc0\u52b1\u673a\u5236\u548c\u89c4\u8303\u6267\u884c\u6765\u89e3\u51b3\u667a\u80fd\u4f53\u96c6\u4f53\u4e2d\u7684\u7ed3\u6784\u6027\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eLLM\u7684\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u4f5c\u4e3a\u667a\u80fd\u4f53\u5d4c\u5165\u4eba\u7c7b\u793e\u4ea4\u548c\u6280\u672f\u7cfb\u7edf\u4e2d\uff0c\u5bf9\u9f50\u4e0d\u80fd\u518d\u88ab\u89c6\u4e3a\u5b64\u7acb\u6a21\u578b\u7684\u5c5e\u6027\uff0c\u800c\u5fc5\u987b\u7406\u89e3\u4e3a\u4e0e\u667a\u80fd\u4f53\u8fd0\u884c\u73af\u5883\u76f8\u5173\u7684\u95ee\u9898\u3002\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u5bf9\u9f50\u65b9\u6cd5\uff08\u5982RLHF\u6216RLAIF\uff09\u4e5f\u65e0\u6cd5\u786e\u4fdd\u5728\u5185\u90e8\u76ee\u6807\u7ed3\u6784\u4e0e\u5f00\u53d1\u8005\u610f\u56fe\u504f\u79bb\u65f6\u7684\u63a7\u5236\u3002", "method": "\u63d0\u51fa\"\u5236\u5ea6\u6027AI\"\u7684\u7cfb\u7edf\u7ea7\u65b9\u6cd5\uff0c\u5c06\u5bf9\u9f50\u89c6\u4e3aAI\u667a\u80fd\u4f53\u96c6\u4f53\u7684\u6709\u6548\u6cbb\u7406\u95ee\u9898\u3002\u6784\u5efa\u6cbb\u7406\u56fe\uff0c\u901a\u8fc7\u8fd0\u884c\u65f6\u76d1\u63a7\u3001\u901a\u8fc7\u5956\u52b1\u548c\u60e9\u7f5a\u5851\u9020\u6fc0\u52b1\u673a\u5236\u3001\u660e\u786e\u89c4\u8303\u548c\u6267\u6cd5\u89d2\u8272\u6765\u7ea6\u675f\u667a\u80fd\u4f53\u3002", "result": "\u8bc6\u522b\u4e86\u4e09\u4e2a\u6e90\u4e8eAI\u6a21\u578b\u6838\u5fc3\u5c5e\u6027\u7684\u7ed3\u6784\u6027\u95ee\u9898\uff1a1\uff09\u884c\u4e3a\u76ee\u6807\u72ec\u7acb\u6027\uff1b2\uff09\u81ea\u7136\u8bed\u8a00\u7ea6\u675f\u7684\u5de5\u5177\u6027\u8986\u76d6\uff1b3\uff09\u667a\u80fd\u4f53\u5bf9\u9f50\u6f02\u79fb\u3002\u63d0\u51fa\u4e86\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u5230\u673a\u5236\u8bbe\u8ba1\u7684\u8303\u5f0f\u8f6c\u53d8\u3002", "conclusion": "AI\u5b89\u5168\u9700\u8981\u4ece\u5355\u4e00\u6a21\u578b\u5bf9\u9f50\u8f6c\u5411\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5236\u5ea6\u6027\u6cbb\u7406\uff0c\u901a\u8fc7\u6539\u53d8AI\u667a\u80fd\u4f53\u96c6\u4f53\u7684\u6536\u76ca\u683c\u5c40\u6765\u5b9e\u73b0\u771f\u6b63\u7684\u5bf9\u9f50\uff0c\u8fd9\u4ee3\u8868\u4e86AI\u5bf9\u9f50\u7814\u7a76\u7684\u91cd\u8981\u8303\u5f0f\u8f6c\u53d8\u3002"}}
{"id": "2601.09929", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09929", "abs": "https://arxiv.org/abs/2601.09929", "authors": ["Ahmad Pesaranghader", "Erin Li"], "title": "Hallucination Detection and Mitigation in Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) and Large Reasoning Models (LRMs) offer transformative potential for high-stakes domains like finance and law, but their tendency to hallucinate, generating factually incorrect or unsupported content, poses a critical reliability risk. This paper introduces a comprehensive operational framework for hallucination management, built on a continuous improvement cycle driven by root cause awareness. We categorize hallucination sources into model, data, and context-related factors, allowing targeted interventions over generic fixes. The framework integrates multi-faceted detection methods (e.g., uncertainty estimation, reasoning consistency) with stratified mitigation strategies (e.g., knowledge grounding, confidence calibration). We demonstrate its application through a tiered architecture and a financial data extraction case study, where model, context, and data tiers form a closed feedback loop for progressive reliability enhancement. This approach provides a systematic, scalable methodology for building trustworthy generative AI systems in regulated environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6839\u56e0\u8ba4\u77e5\u7684\u5e7b\u89c9\u7ba1\u7406\u64cd\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u578b\u3001\u6570\u636e\u548c\u4e0a\u4e0b\u6587\u4e09\u65b9\u9762\u56e0\u7d20\u5206\u7c7b\uff0c\u7ed3\u5408\u591a\u5c42\u6b21\u68c0\u6d4b\u4e0e\u7f13\u89e3\u7b56\u7565\uff0c\u6784\u5efa\u53ef\u6269\u5c55\u7684\u53ef\u9760\u751f\u6210\u5f0fAI\u7cfb\u7edf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u91d1\u878d\u3001\u6cd5\u5f8b\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u5177\u6709\u53d8\u9769\u6f5c\u529b\uff0c\u4f46\u5176\u4ea7\u751f\u5e7b\u89c9\uff08\u751f\u6210\u4e8b\u5b9e\u9519\u8bef\u6216\u65e0\u4f9d\u636e\u5185\u5bb9\uff09\u7684\u503e\u5411\u5e26\u6765\u4e86\u5173\u952e\u53ef\u9760\u6027\u98ce\u9669\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u5e7b\u89c9\u7ba1\u7406\u64cd\u4f5c\u6846\u67b6\uff0c\u57fa\u4e8e\u6301\u7eed\u6539\u8fdb\u5faa\u73af\u548c\u6839\u56e0\u8ba4\u77e5\u3002\u5c06\u5e7b\u89c9\u6765\u6e90\u5206\u4e3a\u6a21\u578b\u3001\u6570\u636e\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u56e0\u7d20\uff0c\u6574\u5408\u591a\u5c42\u6b21\u68c0\u6d4b\u65b9\u6cd5\uff08\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3001\u63a8\u7406\u4e00\u81f4\u6027\u7b49\uff09\u4e0e\u5206\u5c42\u7f13\u89e3\u7b56\u7565\uff08\u77e5\u8bc6\u57fa\u7840\u3001\u7f6e\u4fe1\u5ea6\u6821\u51c6\u7b49\uff09\u3002", "result": "\u901a\u8fc7\u5206\u5c42\u67b6\u6784\u548c\u91d1\u878d\u6570\u636e\u63d0\u53d6\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u6846\u67b6\u5e94\u7528\uff0c\u5176\u4e2d\u6a21\u578b\u3001\u4e0a\u4e0b\u6587\u548c\u6570\u636e\u5c42\u5f62\u6210\u95ed\u73af\u53cd\u9988\u5faa\u73af\uff0c\u5b9e\u73b0\u6e10\u8fdb\u5f0f\u53ef\u9760\u6027\u589e\u5f3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u53d7\u76d1\u7ba1\u73af\u5883\u4e2d\u6784\u5efa\u53ef\u4fe1\u8d56\u7684\u751f\u6210\u5f0fAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u3001\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u8bba\uff0c\u80fd\u591f\u9488\u5bf9\u6027\u5730\u89e3\u51b3\u5e7b\u89c9\u95ee\u9898\u800c\u975e\u4f9d\u8d56\u901a\u7528\u4fee\u590d\u3002"}}
{"id": "2601.10691", "categories": ["cs.CY", "cs.CE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.10691", "abs": "https://arxiv.org/abs/2601.10691", "authors": ["Lorena A. Barba", "Laura Stegner"], "title": "The Conversational Exam: A Scalable Assessment Design for the AI Era", "comment": "12 pages", "summary": "Traditional assessment methods collapse when students use generative AI to complete work without genuine engagement, creating an illusion of competence where they believe they're learning but aren't. This paper presents the conversational exam -- a scalable oral examination format that restores assessment validity by having students code live while explaining their reasoning. Drawing on human-computer interaction principles, we examined 58 students in small groups across just two days, demonstrating that oral exams can scale to typical class sizes. The format combines authentic practice (students work with documentation and supervised AI access) with inherent validity (real-time performance cannot be faked). We provide detailed implementation guidance to help instructors adapt this approach, offering a practical path forward when many educators feel paralyzed between banning AI entirely or accepting that valid assessment is impossible.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u5bf9\u8bdd\u5f0f\u8003\u8bd5\"\u4f5c\u4e3a\u53ef\u6269\u5c55\u7684\u53e3\u8bd5\u5f62\u5f0f\uff0c\u8ba9\u5b66\u751f\u5728\u5b9e\u65f6\u7f16\u7801\u5e76\u89e3\u91ca\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5c55\u793a\u771f\u5b9e\u80fd\u529b\uff0c\u89e3\u51b3\u751f\u6210\u5f0fAI\u5bfc\u81f4\u7684\u8bc4\u4f30\u5931\u6548\u95ee\u9898", "motivation": "\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u5728\u5b66\u751f\u4f7f\u7528\u751f\u6210\u5f0fAI\u5b8c\u6210\u4f5c\u4e1a\u4f46\u7f3a\u4e4f\u771f\u5b9e\u53c2\u4e0e\u65f6\u4f1a\u5931\u6548\uff0c\u9020\u6210\"\u80fd\u529b\u5e7b\u89c9\"\u2014\u2014\u5b66\u751f\u4ee5\u4e3a\u81ea\u5df1\u5b66\u4f1a\u4e86\u4f46\u5b9e\u9645\u4e0a\u6ca1\u6709\u3002\u8bb8\u591a\u6559\u80b2\u8005\u9762\u4e34\u4e24\u96be\uff1a\u8981\u4e48\u5b8c\u5168\u7981\u6b62AI\uff0c\u8981\u4e48\u63a5\u53d7\u6709\u6548\u8bc4\u4f30\u5df2\u4e0d\u53ef\u80fd", "method": "\u63d0\u51fa\u5bf9\u8bdd\u5f0f\u8003\u8bd5\uff1a\u53ef\u6269\u5c55\u7684\u53e3\u8bd5\u5f62\u5f0f\uff0c\u5b66\u751f\u5b9e\u65f6\u7f16\u7801\u5e76\u89e3\u91ca\u63a8\u7406\u8fc7\u7a0b\u3002\u57fa\u4e8e\u4eba\u673a\u4ea4\u4e92\u539f\u5219\uff0c\u572858\u540d\u5b66\u751f\u7684\u5c0f\u7ec4\u4e2d\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4ec5\u7528\u4e24\u5929\u65f6\u95f4\u8bc1\u660e\u53e3\u8bd5\u53ef\u4ee5\u6269\u5c55\u5230\u5178\u578b\u73ed\u7ea7\u89c4\u6a21\u3002\u7ed3\u5408\u771f\u5b9e\u5b9e\u8df5\uff08\u5b66\u751f\u4f7f\u7528\u6587\u6863\u548c\u76d1\u7763\u4e0b\u7684AI\u8bbf\u95ee\uff09\u4e0e\u5185\u5728\u6709\u6548\u6027\uff08\u5b9e\u65f6\u8868\u73b0\u65e0\u6cd5\u4f2a\u9020\uff09", "result": "\u7814\u7a76\u8868\u660e\u53e3\u8bd5\u53ef\u4ee5\u6269\u5c55\u5230\u5178\u578b\u73ed\u7ea7\u89c4\u6a21\uff0c\u4ec5\u7528\u4e24\u5929\u65f6\u95f4\u5c31\u572858\u540d\u5b66\u751f\u7684\u5c0f\u7ec4\u4e2d\u6210\u529f\u5b9e\u65bd\u3002\u5bf9\u8bdd\u5f0f\u8003\u8bd5\u6062\u590d\u4e86\u8bc4\u4f30\u7684\u6709\u6548\u6027\uff0c\u56e0\u4e3a\u5b9e\u65f6\u8868\u73b0\u65e0\u6cd5\u4f2a\u9020", "conclusion": "\u5bf9\u8bdd\u5f0f\u8003\u8bd5\u4e3a\u6559\u80b2\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u89e3\u51b3\u4e86AI\u65f6\u4ee3\u8bc4\u4f30\u7684\u56f0\u5883\u3002\u8bba\u6587\u63d0\u4f9b\u8be6\u7ec6\u7684\u5b9e\u65bd\u6307\u5357\uff0c\u5e2e\u52a9\u6559\u5e08\u91c7\u7528\u8fd9\u79cd\u65b9\u6cd5\uff0c\u5728\u7981\u6b62AI\u6216\u63a5\u53d7\u8bc4\u4f30\u5931\u6548\u4e4b\u95f4\u627e\u5230\u53ef\u884c\u7684\u4e2d\u95f4\u9053\u8def"}}
{"id": "2601.09972", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09972", "abs": "https://arxiv.org/abs/2601.09972", "authors": ["Zixun Lan", "Maochun Xu", "Yifan Ren", "Rui Wu", "Jianghui Zhou", "Xueyang Cheng", "Jianan Ding Ding", "Xinheng Wang", "Mingmin Chi", "Fei Ma"], "title": "Chinese Labor Law Large Language Model Benchmark", "comment": null, "summary": "Recent advances in large language models (LLMs) have led to substantial progress in domain-specific applications, particularly within the legal domain. However, general-purpose models such as GPT-4 often struggle with specialized subdomains that require precise legal knowledge, complex reasoning, and contextual sensitivity. To address these limitations, we present LabourLawLLM, a legal large language model tailored to Chinese labor law. We also introduce LabourLawBench, a comprehensive benchmark covering diverse labor-law tasks, including legal provision citation, knowledge-based question answering, case classification, compensation computation, named entity recognition, and legal case analysis. Our evaluation framework combines objective metrics (e.g., ROUGE-L, accuracy, F1, and soft-F1) with subjective assessment based on GPT-4 scoring. Experiments show that LabourLawLLM consistently outperforms general-purpose and existing legal-specific LLMs across task categories. Beyond labor law, our methodology provides a scalable approach for building specialized LLMs in other legal subfields, improving accuracy, reliability, and societal value of legal AI applications.", "AI": {"tldr": "LabourLawLLM\u662f\u4e13\u95e8\u9488\u5bf9\u4e2d\u56fd\u52b3\u52a8\u6cd5\u9886\u57df\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728LabourLawBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86\u901a\u7528\u6a21\u578b\u548c\u73b0\u6709\u6cd5\u5f8b\u4e13\u7528\u6a21\u578b\uff0c\u4e3a\u6784\u5efa\u5176\u4ed6\u6cd5\u5f8b\u5b50\u9886\u57df\u4e13\u7528\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u65b9\u6cd5\u3002", "motivation": "\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4\uff09\u5728\u5904\u7406\u9700\u8981\u7cbe\u786e\u6cd5\u5f8b\u77e5\u8bc6\u3001\u590d\u6742\u63a8\u7406\u548c\u60c5\u5883\u654f\u611f\u6027\u7684\u4e13\u4e1a\u6cd5\u5f8b\u5b50\u9886\u57df\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u7279\u5b9a\u6cd5\u5f8b\u9886\u57df\u7684\u6a21\u578b\u6765\u63d0\u9ad8\u6cd5\u5f8bAI\u5e94\u7528\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u5f00\u53d1\u4e86LabourLawLLM\u4e13\u95e8\u9488\u5bf9\u4e2d\u56fd\u52b3\u52a8\u6cd5\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u521b\u5efa\u4e86LabourLawBench\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u6cd5\u5f8b\u6761\u6b3e\u5f15\u7528\u3001\u77e5\u8bc6\u95ee\u7b54\u3001\u6848\u4f8b\u5206\u7c7b\u3001\u8d54\u507f\u8ba1\u7b97\u3001\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u6848\u4f8b\u5206\u6790\u7b49\u4efb\u52a1\u3002\u8bc4\u4f30\u6846\u67b6\u7ed3\u5408\u4e86\u5ba2\u89c2\u6307\u6807\uff08ROUGE-L\u3001\u51c6\u786e\u7387\u3001F1\u3001soft-F1\uff09\u548c\u57fa\u4e8eGPT-4\u8bc4\u5206\u7684\u4e3b\u89c2\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLabourLawLLM\u5728\u6240\u6709\u4efb\u52a1\u7c7b\u522b\u4e2d\u4e00\u81f4\u4f18\u4e8e\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u73b0\u6709\u7684\u6cd5\u5f8b\u4e13\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u52b3\u52a8\u6cd5\u9886\u57df\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u4e3a\u52b3\u52a8\u6cd5\u9886\u57df\u63d0\u4f9b\u4e86\u4e13\u7528\u6a21\u578b\uff0c\u8fd8\u4e3a\u6784\u5efa\u5176\u4ed6\u6cd5\u5f8b\u5b50\u9886\u57df\u7684\u4e13\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u8bba\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u6cd5\u5f8bAI\u5e94\u7528\u7684\u51c6\u786e\u6027\u3001\u53ef\u9760\u6027\u548c\u793e\u4f1a\u4ef7\u503c\u3002"}}
{"id": "2601.09974", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09974", "abs": "https://arxiv.org/abs/2601.09974", "authors": ["Seoyeon Kim", "Jaehyung Kim"], "title": "SPRInG: Continual LLM Personalization via Selective Parametric Adaptation and Retrieval-Interpolated Generation", "comment": "under review, 23 pages", "summary": "Personalizing Large Language Models typically relies on static retrieval or one-time adaptation, assuming user preferences remain invariant over time. However, real-world interactions are dynamic, where user interests continuously evolve, posing a challenge for models to adapt to preference drift without catastrophic forgetting. Standard continual learning approaches often struggle in this context, as they indiscriminately update on noisy interaction streams, failing to distinguish genuine preference shifts from transient contexts. To address this, we introduce SPRInG, a novel semi-parametric framework designed for effective continual personalization. During training, SPRInG employs drift-driven selective adaptation, which utilizes a likelihood-based scoring function to identify high-novelty interactions. This allows the model to selectively update the user-specific adapter on drift signals while preserving hard-to-learn residuals in a replay buffer. During inference, we apply strict relevance gating and fuse parametric knowledge with retrieved history via logit interpolation. Experiments on the long-form personalized generation benchmark demonstrate that SPRInG outperforms existing baselines, validating its robustness for real-world continual personalization.", "AI": {"tldr": "SPRInG\uff1a\u4e00\u4e2a\u7528\u4e8e\u52a8\u6001\u7528\u6237\u504f\u597d\u6301\u7eed\u4e2a\u6027\u5316\u7684\u534a\u53c2\u6570\u6846\u67b6\uff0c\u901a\u8fc7\u6f02\u79fb\u9a71\u52a8\u9009\u62e9\u6027\u9002\u5e94\u548c\u4e25\u683c\u76f8\u5173\u6027\u95e8\u63a7\u89e3\u51b3\u504f\u597d\u6f02\u79fb\u95ee\u9898", "motivation": "\u73b0\u6709\u4e2a\u6027\u5316\u5927\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u57fa\u4e8e\u9759\u6001\u68c0\u7d22\u6216\u4e00\u6b21\u6027\u9002\u5e94\uff0c\u5047\u8bbe\u7528\u6237\u504f\u597d\u4e0d\u53d8\u3002\u4f46\u73b0\u5b9e\u4e16\u754c\u4e2d\u7528\u6237\u5174\u8da3\u6301\u7eed\u6f14\u5316\uff0c\u5b58\u5728\u504f\u597d\u6f02\u79fb\u95ee\u9898\uff0c\u6807\u51c6\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u533a\u5206\u771f\u5b9e\u504f\u597d\u53d8\u5316\u4e0e\u4e34\u65f6\u4e0a\u4e0b\u6587\u566a\u58f0", "method": "SPRInG\u91c7\u7528\u534a\u53c2\u6570\u6846\u67b6\uff1a\u8bad\u7ec3\u65f6\u4f7f\u7528\u57fa\u4e8e\u4f3c\u7136\u7684\u8bc4\u5206\u51fd\u6570\u8bc6\u522b\u9ad8\u65b0\u9896\u6027\u4ea4\u4e92\uff0c\u9009\u62e9\u6027\u66f4\u65b0\u7528\u6237\u7279\u5b9a\u9002\u914d\u5668\uff0c\u540c\u65f6\u5c06\u96be\u5b66\u4e60\u6b8b\u5dee\u4fdd\u5b58\u5728\u56de\u653e\u7f13\u51b2\u533a\uff1b\u63a8\u7406\u65f6\u5e94\u7528\u4e25\u683c\u76f8\u5173\u6027\u95e8\u63a7\uff0c\u901a\u8fc7logit\u63d2\u503c\u878d\u5408\u53c2\u6570\u77e5\u8bc6\u4e0e\u68c0\u7d22\u5386\u53f2", "result": "\u5728\u957f\u683c\u5f0f\u4e2a\u6027\u5316\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSPRInG\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u73b0\u5b9e\u4e16\u754c\u6301\u7eed\u4e2a\u6027\u5316\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027", "conclusion": "SPRInG\u6846\u67b6\u901a\u8fc7\u6f02\u79fb\u9a71\u52a8\u9009\u62e9\u6027\u9002\u5e94\u548c\u4e25\u683c\u76f8\u5173\u6027\u95e8\u63a7\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u52a8\u6001\u7528\u6237\u504f\u597d\u7684\u6301\u7eed\u4e2a\u6027\u5316\u95ee\u9898\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u4e2a\u6027\u5316\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.10011", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10011", "abs": "https://arxiv.org/abs/2601.10011", "authors": ["Zerui Yang", "Weichuan Wang", "Yanwei Xu", "Linqi Song", "Yudai Matsuda", "Wei Han", "Bo Bai"], "title": "Memo-SQL: Structured Decomposition and Experience-Driven Self-Correction for Training-Free NL2SQL", "comment": null, "summary": "Existing NL2SQL systems face two critical limitations: (1) they rely on in-context learning with only correct examples, overlooking the rich signal in historical error-fix pairs that could guide more robust self-correction; and (2) test-time scaling approaches often decompose questions arbitrarily, producing near-identical SQL candidates across runs and diminishing ensemble gains. Moreover, these methods suffer from a stark accuracy-efficiency trade-off: high performance demands excessive computation, while fast variants compromise quality. We present Memo-SQL, a training-free framework that addresses these issues through two simple ideas: structured decomposition and experience-aware self-correction. Instead of leaving decomposition to chance, we apply three clear strategies, entity-wise, hierarchical, and atomic sequential, to encourage diverse reasoning. For correction, we build a dynamic memory of both successful queries and historical error-fix pairs, and use retrieval-augmented prompting to bring relevant examples into context at inference time, no fine-tuning or external APIs required. On BIRD, Memo-SQL achieves 68.5% execution accuracy, setting a new state of the art among open, zero-fine-tuning methods, while using over 10 times fewer resources than prior TTS approaches.", "AI": {"tldr": "Memo-SQL\uff1a\u65e0\u9700\u8bad\u7ec3\u7684NL2SQL\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u89e3\u548c\u7ecf\u9a8c\u611f\u77e5\u81ea\u6821\u6b63\u89e3\u51b3\u73b0\u6709\u7cfb\u7edf\u95ee\u9898\uff0c\u5728BIRD\u6570\u636e\u96c6\u4e0a\u8fbe\u523068.5%\u6267\u884c\u51c6\u786e\u7387\uff0c\u6bd4\u4e4b\u524d\u65b9\u6cd5\u8282\u770110\u500d\u8d44\u6e90\u3002", "motivation": "\u73b0\u6709NL2SQL\u7cfb\u7edf\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u5c40\u9650\uff1a1\uff09\u4ec5\u4f7f\u7528\u6b63\u786e\u793a\u4f8b\u8fdb\u884c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u5ffd\u7565\u4e86\u5386\u53f2\u9519\u8bef-\u4fee\u590d\u5bf9\u4e2d\u7684\u4e30\u5bcc\u4fe1\u53f7\uff1b2\uff09\u6d4b\u8bd5\u65f6\u5206\u89e3\u65b9\u6cd5\u968f\u610f\uff0c\u4ea7\u751f\u76f8\u4f3cSQL\u5019\u9009\uff0c\u964d\u4f4e\u96c6\u6210\u6548\u679c\u3002\u540c\u65f6\u9762\u4e34\u51c6\u786e\u7387\u4e0e\u6548\u7387\u7684\u4e25\u91cd\u6743\u8861\u3002", "method": "\u63d0\u51fa\u8bad\u7ec3\u514d\u8d39\u6846\u67b6Memo-SQL\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u601d\u60f3\uff1a1\uff09\u7ed3\u6784\u5316\u5206\u89e3\uff1a\u91c7\u7528\u5b9e\u4f53\u7ea7\u3001\u5206\u5c42\u548c\u539f\u5b50\u987a\u5e8f\u4e09\u79cd\u6e05\u6670\u7b56\u7565\u4fc3\u8fdb\u591a\u6837\u5316\u63a8\u7406\uff1b2\uff09\u7ecf\u9a8c\u611f\u77e5\u81ea\u6821\u6b63\uff1a\u6784\u5efa\u52a8\u6001\u8bb0\u5fc6\u5e93\u5b58\u50a8\u6210\u529f\u67e5\u8be2\u548c\u5386\u53f2\u9519\u8bef-\u4fee\u590d\u5bf9\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u63d0\u793a\u5728\u63a8\u7406\u65f6\u5f15\u5165\u76f8\u5173\u793a\u4f8b\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u5916\u90e8API\u3002", "result": "\u5728BIRD\u6570\u636e\u96c6\u4e0a\u8fbe\u523068.5%\u6267\u884c\u51c6\u786e\u7387\uff0c\u5728\u5f00\u653e\u3001\u96f6\u5fae\u8c03\u65b9\u6cd5\u4e2d\u521b\u4e0b\u65b0\u7684SOTA\uff0c\u540c\u65f6\u6bd4\u4e4b\u524d\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\u8282\u7701\u8d85\u8fc710\u500d\u8ba1\u7b97\u8d44\u6e90\u3002", "conclusion": "Memo-SQL\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u89e3\u548c\u7ecf\u9a8c\u611f\u77e5\u81ea\u6821\u6b63\u6709\u6548\u89e3\u51b3\u4e86NL2SQL\u7cfb\u7edf\u7684\u5173\u952e\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\uff0c\u4e3a\u8bad\u7ec3\u514d\u8d39\u7684NL2SQL\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.10520", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.10520", "abs": "https://arxiv.org/abs/2601.10520", "authors": ["Felix Jahn", "Yannic Muskalla", "Lisa Dargasz", "Patrick Schramowski", "Kevin Baum"], "title": "Breaking Up with Normatively Monolithic Agency with GRACE: A Reason-Based Neuro-Symbolic Architecture for Safe and Ethical AI Alignment", "comment": "10 pages, 4 figures, accepted at 2nd Annual Conference of the International Association for Safe & Ethical AI (IASEAI'26)", "summary": "As AI agents become increasingly autonomous, widely deployed in consequential contexts, and efficacious in bringing about real-world impacts, ensuring that their decisions are not only instrumentally effective but also normatively aligned has become critical. We introduce a neuro-symbolic reason-based containment architecture, Governor for Reason-Aligned ContainmEnt (GRACE), that decouples normative reasoning from instrumental decision-making and can contain AI agents of virtually any design. GRACE restructures decision-making into three modules: a Moral Module (MM) that determines permissible macro actions via deontic logic-based reasoning; a Decision-Making Module (DMM) that encapsulates the target agent while selecting instrumentally optimal primitive actions in accordance with derived macro actions; and a Guard that monitors and enforces moral compliance. The MM uses a reason-based formalism providing a semantic foundation for deontic logic, enabling interpretability, contestability, and justifiability. Its symbolic representation enriches the DMM's informational context and supports formal verification and statistical guarantees of alignment enforced by the Guard. We demonstrate GRACE on an example of a LLM therapy assistant, showing how it enables stakeholders to understand, contest, and refine agent behavior.", "AI": {"tldr": "GRACE\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u67b6\u6784\uff0c\u901a\u8fc7\u5c06\u89c4\u8303\u6027\u63a8\u7406\u4e0e\u5de5\u5177\u6027\u51b3\u7b56\u5206\u79bb\u6765\u786e\u4fddAI\u4ee3\u7406\u7684\u9053\u5fb7\u5bf9\u9f50\uff0c\u5305\u542b\u9053\u5fb7\u6a21\u5757\u3001\u51b3\u7b56\u6a21\u5757\u548c\u76d1\u63a7\u5b88\u536b\u4e09\u4e2a\u7ec4\u4ef6\u3002", "motivation": "\u968f\u7740AI\u4ee3\u7406\u5728\u91cd\u8981\u573a\u666f\u4e2d\u81ea\u4e3b\u90e8\u7f72\u5e76\u4ea7\u751f\u5b9e\u9645\u5f71\u54cd\uff0c\u786e\u4fdd\u5176\u51b3\u7b56\u4e0d\u4ec5\u5de5\u5177\u6709\u6548\u800c\u4e14\u7b26\u5408\u9053\u5fb7\u89c4\u8303\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7ea6\u675f\u4efb\u4f55\u8bbe\u8ba1AI\u4ee3\u7406\u7684\u67b6\u6784\u3002", "method": "\u63d0\u51faGRACE\u4e09\u6a21\u5757\u67b6\u6784\uff1a1) \u9053\u5fb7\u6a21\u5757\u4f7f\u7528\u57fa\u4e8e\u7406\u7531\u7684\u9053\u4e49\u903b\u8f91\u63a8\u7406\u786e\u5b9a\u5141\u8bb8\u7684\u5b8f\u89c2\u884c\u52a8\uff1b2) \u51b3\u7b56\u6a21\u5757\u5c01\u88c5\u76ee\u6807\u4ee3\u7406\uff0c\u5728\u5b8f\u89c2\u884c\u52a8\u7ea6\u675f\u4e0b\u9009\u62e9\u5de5\u5177\u6700\u4f18\u7684\u539f\u59cb\u884c\u52a8\uff1b3) \u5b88\u536b\u76d1\u63a7\u5e76\u5f3a\u5236\u6267\u884c\u9053\u5fb7\u5408\u89c4\u6027\u3002", "result": "GRACE\u5728LLM\u6cbb\u7597\u52a9\u624b\u793a\u4f8b\u4e2d\u5c55\u793a\uff0c\u4f7f\u5229\u76ca\u76f8\u5173\u8005\u80fd\u591f\u7406\u89e3\u3001\u8d28\u7591\u548c\u4f18\u5316\u4ee3\u7406\u884c\u4e3a\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u4e89\u8bae\u6027\u548c\u53ef\u9a8c\u8bc1\u7684\u9053\u5fb7\u5bf9\u9f50\u4fdd\u8bc1\u3002", "conclusion": "GRACE\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u5b9e\u73b0\u4e86AI\u4ee3\u7406\u7684\u9053\u5fb7\u7ea6\u675f\uff0c\u5c06\u89c4\u8303\u6027\u63a8\u7406\u4e0e\u5de5\u5177\u51b3\u7b56\u5206\u79bb\uff0c\u4e3aAI\u5bf9\u9f50\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u3001\u53ef\u9a8c\u8bc1\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.10025", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10025", "abs": "https://arxiv.org/abs/2601.10025", "authors": ["Jinpeng Wang", "Xinyu Jia", "Wei Wei Heng", "Yuquan Li", "Binbin Shi", "Qianlei Chen", "Guannan Chen", "Junxia Zhang", "Yuyu Yin"], "title": "Structured Personality Control and Adaptation for LLM Agents", "comment": null, "summary": "Large Language Models (LLMs) are increasingly shaping human-computer interaction (HCI), from personalized assistants to social simulations. Beyond language competence, researchers are exploring whether LLMs can exhibit human-like characteristics that influence engagement, decision-making, and perceived realism. Personality, in particular, is critical, yet existing approaches often struggle to achieve both nuanced and adaptable expression. We present a framework that models LLM personality via Jungian psychological types, integrating three mechanisms: a dominant-auxiliary coordination mechanism for coherent core expression, a reinforcement-compensation mechanism for temporary adaptation to context, and a reflection mechanism that drives long-term personality evolution. This design allows the agent to maintain nuanced traits while dynamically adjusting to interaction demands and gradually updating its underlying structure. Personality alignment is evaluated using Myers-Briggs Type Indicator questionnaires and tested under diverse challenge scenarios as a preliminary structured assessment. Findings suggest that evolving, personality-aware LLMs can support coherent, context-sensitive interactions, enabling naturalistic agent design in HCI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8363\u683c\u5fc3\u7406\u7c7b\u578b\u7684LLM\u4eba\u683c\u5efa\u6a21\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u79cd\u673a\u5236\u5b9e\u73b0\u4eba\u683c\u7684\u8fde\u8d2f\u8868\u8fbe\u3001\u60c5\u5883\u9002\u5e94\u548c\u957f\u671f\u6f14\u5316\uff0c\u4e3aHCI\u4e2d\u7684\u81ea\u7136\u5316\u667a\u80fd\u4f53\u8bbe\u8ba1\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u5f53\u524dLLM\u5728HCI\u5e94\u7528\u4e2d\u7f3a\u4e4f\u65e2\u7ec6\u817b\u53c8\u9002\u5e94\u6027\u5f3a\u7684\u4eba\u683c\u8868\u8fbe\u65b9\u6cd5\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5b9e\u73b0\u4eba\u683c\u7684\u7ec6\u5fae\u7279\u8d28\u548c\u52a8\u6001\u9002\u5e94\u6027\uff0c\u9650\u5236\u4e86LLM\u5728\u4e2a\u6027\u5316\u52a9\u624b\u3001\u793e\u4ea4\u6a21\u62df\u7b49\u573a\u666f\u4e2d\u7684\u81ea\u7136\u4ea4\u4e92\u6548\u679c\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8363\u683c\u5fc3\u7406\u7c7b\u578b\u7684\u4eba\u683c\u5efa\u6a21\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u673a\u5236\uff1a1\uff09\u4e3b\u5bfc-\u8f85\u52a9\u534f\u8c03\u673a\u5236\uff0c\u786e\u4fdd\u6838\u5fc3\u4eba\u683c\u7279\u8d28\u7684\u8fde\u8d2f\u8868\u8fbe\uff1b2\uff09\u5f3a\u5316-\u8865\u507f\u673a\u5236\uff0c\u5b9e\u73b0\u77ed\u671f\u60c5\u5883\u9002\u5e94\uff1b3\uff09\u53cd\u601d\u673a\u5236\uff0c\u9a71\u52a8\u957f\u671f\u4eba\u683c\u6f14\u5316\u3002\u4f7f\u7528MBTI\u95ee\u5377\u8fdb\u884c\u4eba\u683c\u5bf9\u9f50\u8bc4\u4f30\uff0c\u5e76\u5728\u591a\u6837\u5316\u6311\u6218\u573a\u666f\u4e2d\u6d4b\u8bd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5177\u6709\u6f14\u5316\u80fd\u529b\u7684\u4eba\u683c\u611f\u77e5LLM\u80fd\u591f\u652f\u6301\u8fde\u8d2f\u4e14\u60c5\u5883\u654f\u611f\u7684\u4ea4\u4e92\u3002\u8be5\u6846\u67b6\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u4fdd\u6301\u7ec6\u817b\u7684\u4eba\u683c\u7279\u8d28\uff0c\u540c\u65f6\u52a8\u6001\u9002\u5e94\u4ea4\u4e92\u9700\u6c42\uff0c\u5e76\u9010\u6b65\u66f4\u65b0\u5176\u5e95\u5c42\u4eba\u683c\u7ed3\u6784\u3002", "conclusion": "\u6f14\u5316\u6027\u7684\u4eba\u683c\u611f\u77e5LLM\u80fd\u591f\u5b9e\u73b0\u81ea\u7136\u5316\u7684\u667a\u80fd\u4f53\u8bbe\u8ba1\uff0c\u4e3aHCI\u4e2d\u7684\u4e2a\u6027\u5316\u52a9\u624b\u548c\u793e\u4ea4\u6a21\u62df\u7b49\u5e94\u7528\u63d0\u4f9b\u66f4\u771f\u5b9e\u3001\u8fde\u8d2f\u7684\u4ea4\u4e92\u4f53\u9a8c\u3002\u8be5\u6846\u67b6\u4e3a\u4eba\u683c\u5efa\u6a21\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2601.10567", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.10567", "abs": "https://arxiv.org/abs/2601.10567", "authors": ["Laura Ferrarotti", "Gian Maria Campedelli", "Roberto Dess\u00ec", "Andrea Baronchelli", "Giovanni Iacca", "Kathleen M. Carley", "Alex Pentland", "Joel Z. Leibo", "James Evans", "Bruno Lepri"], "title": "Generative AI collective behavior needs an interactionist paradigm", "comment": null, "summary": "In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs--namely, their initialization with extensive pre-trained knowledge and implicit social priors, together with their capability of adaptation through in-context learning--motivates the need for an interactionist paradigm consisting of alternative theoretical foundations, methodologies, and analytical tools, in order to systematically examine how prior knowledge and embedded values interact with social context to shape emergent phenomena in multi-agent generative AI systems. We propose and discuss four directions that we consider crucial for the development and deployment of LLM-based collectives, focusing on theory, methods, and trans-disciplinary dialogue.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u7814\u7a76\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u4f53\u96c6\u4f53\u884c\u4e3a\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5efa\u7acb\u4ea4\u4e92\u4e3b\u4e49\u8303\u5f0f\u6765\u7cfb\u7edf\u5206\u6790\u5148\u9a8c\u77e5\u8bc6\u3001\u5d4c\u5165\u4ef7\u503c\u89c2\u4e0e\u793e\u4f1a\u60c5\u5883\u5982\u4f55\u5171\u540c\u5851\u9020\u591a\u667a\u80fd\u4f53\u751f\u6210\u5f0fAI\u7cfb\u7edf\u4e2d\u7684\u6d8c\u73b0\u73b0\u8c61\u3002", "motivation": "\u7406\u89e3\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u96c6\u4f53\u884c\u4e3a\u662f\u4e00\u4e2a\u5173\u952e\u7814\u7a76\u9886\u57df\uff0c\u5bf9\u793e\u4f1a\u5177\u6709\u91cd\u8981\u98ce\u9669\u4e0e\u6536\u76ca\u5f71\u54cd\u3002LLM\u7684\u72ec\u7279\u6027\u8d28\u2014\u2014\u5305\u62ec\u57fa\u4e8e\u5927\u91cf\u9884\u8bad\u7ec3\u77e5\u8bc6\u7684\u521d\u59cb\u5316\u3001\u9690\u542b\u7684\u793e\u4f1a\u5148\u9a8c\u4ee5\u53ca\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u8fdb\u884c\u9002\u5e94\u7684\u80fd\u529b\u2014\u2014\u9700\u8981\u65b0\u7684\u7406\u8bba\u6846\u67b6\u6765\u7814\u7a76\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6d8c\u73b0\u73b0\u8c61\u3002", "method": "\u63d0\u51fa\u4ea4\u4e92\u4e3b\u4e49\u8303\u5f0f\uff0c\u5305\u542b\u66ff\u4ee3\u6027\u7406\u8bba\u57fa\u7840\u3001\u65b9\u6cd5\u8bba\u548c\u5206\u6790\u5de5\u5177\uff0c\u7528\u4e8e\u7cfb\u7edf\u7814\u7a76\u5148\u9a8c\u77e5\u8bc6\u3001\u5d4c\u5165\u4ef7\u503c\u89c2\u4e0e\u793e\u4f1a\u60c5\u5883\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\u5e76\u5851\u9020\u591a\u667a\u80fd\u4f53\u751f\u6210\u5f0fAI\u7cfb\u7edf\u4e2d\u7684\u96c6\u4f53\u884c\u4e3a\u3002", "result": "\u63d0\u51fa\u4e86\u56db\u4e2a\u5173\u952e\u53d1\u5c55\u65b9\u5411\uff1a\u7406\u8bba\u5efa\u8bbe\u3001\u65b9\u6cd5\u521b\u65b0\u3001\u8de8\u5b66\u79d1\u5bf9\u8bdd\u4ee5\u53caLLM\u96c6\u4f53\u7cfb\u7edf\u7684\u5f00\u53d1\u4e0e\u90e8\u7f72\u7b56\u7565\uff0c\u4e3a\u8fd9\u4e00\u65b0\u5174\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u6846\u67b6\u6027\u6307\u5bfc\u3002", "conclusion": "\u7814\u7a76LLM\u667a\u80fd\u4f53\u96c6\u4f53\u884c\u4e3a\u9700\u8981\u65b0\u7684\u4ea4\u4e92\u4e3b\u4e49\u8303\u5f0f\uff0c\u8be5\u9886\u57df\u7684\u53d1\u5c55\u9700\u8981\u7406\u8bba\u3001\u65b9\u6cd5\u548c\u8de8\u5b66\u79d1\u5bf9\u8bdd\u7684\u534f\u540c\u63a8\u8fdb\uff0c\u4ee5\u5e94\u5bf9\u793e\u4f1a\u5c42\u9762\u7684\u98ce\u9669\u4e0e\u673a\u9047\u3002"}}
{"id": "2601.10029", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10029", "abs": "https://arxiv.org/abs/2601.10029", "authors": ["Tingyue Pan", "Jie Ouyang", "Mingyue Cheng", "Qingchuan Li", "Zirui Liu", "Mingfan Pan", "Shuo Yu", "Qi Liu"], "title": "PaperScout: An Autonomous Agent for Academic Paper Search with Process-Aware Sequence-Level Policy Optimization", "comment": null, "summary": "Academic paper search is a fundamental task in scientific research, yet most existing approaches rely on rigid, predefined workflows that struggle with complex, conditional queries. To address this limitation, we propose PaperScout, an autonomous agent that reformulates paper search as a sequential decision-making process. Unlike static workflows, PaperScout dynamically decides whether, when, and how to invoke search and expand tools based on accumulated retrieval context. However, training such agents presents a fundamental challenge: standard reinforcement learning methods, typically designed for single-turn tasks, suffer from a granularity mismatch when applied to multi-turn agentic tasks, where token-level optimization diverges from the granularity of sequence-level interactions, leading to noisy credit assignment. We introduce Proximal Sequence Policy Optimization (PSPO), a process-aware, sequence-level policy optimization method that aligns optimization with agent-environment interaction. Comprehensive experiments on both synthetic and real-world benchmarks demonstrate that PaperScout significantly outperforms strong workflow-driven and RL baselines in both recall and relevance, validating the effectiveness of our adaptive agentic framework and optimization strategy.", "AI": {"tldr": "PaperScout\uff1a\u4e00\u4e2a\u5c06\u8bba\u6587\u641c\u7d22\u91cd\u6784\u4e3a\u987a\u5e8f\u51b3\u7b56\u8fc7\u7a0b\u7684\u81ea\u4e3b\u4ee3\u7406\uff0c\u91c7\u7528PSPO\u65b9\u6cd5\u89e3\u51b3\u591a\u8f6e\u4ee3\u7406\u4efb\u52a1\u4e2d\u7684\u7c92\u5ea6\u4e0d\u5339\u914d\u95ee\u9898", "motivation": "\u73b0\u6709\u5b66\u672f\u8bba\u6587\u641c\u7d22\u65b9\u6cd5\u4f9d\u8d56\u50f5\u5316\u7684\u9884\u5b9a\u4e49\u5de5\u4f5c\u6d41\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u7684\u6761\u4ef6\u67e5\u8be2\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u51b3\u7b56\u641c\u7d22\u7b56\u7565\u7684\u81ea\u9002\u5e94\u4ee3\u7406\u6846\u67b6\u3002", "method": "\u63d0\u51faPaperScout\u81ea\u4e3b\u4ee3\u7406\uff0c\u5c06\u8bba\u6587\u641c\u7d22\u91cd\u6784\u4e3a\u987a\u5e8f\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u5f15\u5165Proximal Sequence Policy Optimization (PSPO)\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u8fc7\u7a0b\u611f\u77e5\u7684\u5e8f\u5217\u7ea7\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u89e3\u51b3\u591a\u8f6e\u4ee3\u7406\u4efb\u52a1\u4e2d\u7684\u7c92\u5ea6\u4e0d\u5339\u914d\u95ee\u9898\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPaperScout\u5728\u53ec\u56de\u7387\u548c\u76f8\u5173\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u5de5\u4f5c\u6d41\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u81ea\u9002\u5e94\u4ee3\u7406\u6846\u67b6\u548c\u4f18\u5316\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "conclusion": "PaperScout\u901a\u8fc7\u5c06\u8bba\u6587\u641c\u7d22\u91cd\u6784\u4e3a\u987a\u5e8f\u51b3\u7b56\u8fc7\u7a0b\uff0c\u7ed3\u5408PSPO\u4f18\u5316\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u641c\u7d22\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u590d\u6742\u5b66\u672f\u67e5\u8be2\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.10031", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10031", "abs": "https://arxiv.org/abs/2601.10031", "authors": ["Jianheng Tang", "Shilong Tao", "Zhe Feng", "Haonan Sun", "Menglu Wang", "Zhanxing Zhu", "Yunhuai Liu"], "title": "FilDeep: Learning Large Deformations of Elastic-Plastic Solids with Multi-Fidelity Data", "comment": "Accepted in Proceedings of the 32nd ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1 (KDD '26)", "summary": "The scientific computation of large deformations in elastic-plastic solids is crucial in various manufacturing applications. Traditional numerical methods exhibit several inherent limitations, prompting Deep Learning (DL) as a promising alternative. The effectiveness of current DL techniques typically depends on the availability of high-quantity and high-accuracy datasets, which are yet difficult to obtain in large deformation problems. During the dataset construction process, a dilemma stands between data quantity and data accuracy, leading to suboptimal performance in the DL models. To address this challenge, we focus on a representative application of large deformations, the stretch bending problem, and propose FilDeep, a Fidelity-based Deep Learning framework for large Deformation of elastic-plastic solids. Our FilDeep aims to resolve the quantity-accuracy dilemma by simultaneously training with both low-fidelity and high-fidelity data, where the former provides greater quantity but lower accuracy, while the latter offers higher accuracy but in less quantity. In FilDeep, we provide meticulous designs for the practical large deformation problem. Particularly, we propose attention-enabled cross-fidelity modules to effectively capture long-range physical interactions across MF data. To the best of our knowledge, our FilDeep presents the first DL framework for large deformation problems using MF data. Extensive experiments demonstrate that our FilDeep consistently achieves state-of-the-art performance and can be efficiently deployed in manufacturing.", "AI": {"tldr": "\u63d0\u51fa\u4e86FilDeep\u6846\u67b6\uff0c\u901a\u8fc7\u540c\u65f6\u4f7f\u7528\u4f4e\u4fdd\u771f\u5ea6\uff08\u9ad8\u6570\u91cf\uff09\u548c\u9ad8\u4fdd\u771f\u5ea6\uff08\u9ad8\u7cbe\u5ea6\uff09\u6570\u636e\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u89e3\u51b3\u5927\u53d8\u5f62\u5f39\u5851\u6027\u56fa\u4f53\u8ba1\u7b97\u4e2d\u7684\u6570\u636e\u6570\u91cf\u4e0e\u7cbe\u5ea6\u4e24\u96be\u95ee\u9898\u3002", "motivation": "\u5927\u53d8\u5f62\u5f39\u5851\u6027\u56fa\u4f53\u7684\u79d1\u5b66\u8ba1\u7b97\u5728\u5236\u9020\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u5b58\u5728\u56fa\u6709\u5c40\u9650\u6027\uff0c\u6df1\u5ea6\u5b66\u4e60\u662f\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u73b0\u6709DL\u6280\u672f\u4f9d\u8d56\u4e8e\u9ad8\u8d28\u91cf\u9ad8\u7cbe\u5ea6\u6570\u636e\u96c6\uff0c\u800c\u5927\u53d8\u5f62\u95ee\u9898\u4e2d\u96be\u4ee5\u83b7\u5f97\u8fd9\u6837\u7684\u6570\u636e\uff0c\u5b58\u5728\u6570\u636e\u6570\u91cf\u4e0e\u7cbe\u5ea6\u7684\u4e24\u96be\u56f0\u5883\u3002", "method": "\u63d0\u51faFilDeep\u6846\u67b6\uff0c\u9488\u5bf9\u62c9\u4f38\u5f2f\u66f2\u8fd9\u4e00\u4ee3\u8868\u6027\u5927\u53d8\u5f62\u5e94\u7528\uff0c\u540c\u65f6\u4f7f\u7528\u4f4e\u4fdd\u771f\u5ea6\uff08\u9ad8\u6570\u91cf\u4f4e\u7cbe\u5ea6\uff09\u548c\u9ad8\u4fdd\u771f\u5ea6\uff08\u4f4e\u6570\u91cf\u9ad8\u7cbe\u5ea6\uff09\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3002\u8bbe\u8ba1\u4e86\u6ce8\u610f\u529b\u673a\u5236\u7684\u8de8\u4fdd\u771f\u5ea6\u6a21\u5757\uff0c\u6709\u6548\u6355\u6349\u591a\u4fdd\u771f\u5ea6\u6570\u636e\u95f4\u7684\u957f\u7a0b\u7269\u7406\u76f8\u4e92\u4f5c\u7528\u3002", "result": "FilDeep\u5728\u5927\u53d8\u5f62\u95ee\u9898\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u80fd\u9ad8\u6548\u90e8\u7f72\u4e8e\u5236\u9020\u5e94\u7528\u4e2d\u3002\u8fd9\u662f\u9996\u4e2a\u4f7f\u7528\u591a\u4fdd\u771f\u5ea6\u6570\u636e\u89e3\u51b3\u5927\u53d8\u5f62\u95ee\u9898\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u3002", "conclusion": "FilDeep\u6210\u529f\u89e3\u51b3\u4e86\u5927\u53d8\u5f62\u5f39\u5851\u6027\u56fa\u4f53\u8ba1\u7b97\u4e2d\u7684\u6570\u636e\u6570\u91cf\u4e0e\u7cbe\u5ea6\u4e24\u96be\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u4fdd\u771f\u5ea6\u6570\u636e\u8bad\u7ec3\u548c\u6ce8\u610f\u529b\u673a\u5236\u8bbe\u8ba1\uff0c\u4e3a\u5236\u9020\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6df1\u5ea6\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.10088", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10088", "abs": "https://arxiv.org/abs/2601.10088", "authors": ["Malika Aubakirova", "Alex Atallah", "Chris Clark", "Justin Summerville", "Anjney Midha"], "title": "State of AI: An Empirical 100 Trillion Token Study with OpenRouter", "comment": "36 pages", "summary": "The past year has marked a turning point in the evolution and real-world use of large language models (LLMs). With the release of the first widely adopted reasoning model, o1, on December 5th, 2024, the field shifted from single-pass pattern generation to multi-step deliberation inference, accelerating deployment, experimentation, and new classes of applications. As this shift unfolded at a rapid pace, our empirical understanding of how these models have actually been used in practice has lagged behind. In this work, we leverage the OpenRouter platform, which is an AI inference provider across a wide variety of LLMs, to analyze over 100 trillion tokens of real-world LLM interactions across tasks, geographies, and time. In our empirical study, we observe substantial adoption of open-weight models, the outsized popularity of creative roleplay (beyond just the productivity tasks many assume dominate) and coding assistance categories, plus the rise of agentic inference. Furthermore, our retention analysis identifies foundational cohorts: early users whose engagement persists far longer than later cohorts. We term this phenomenon the Cinderella \"Glass Slipper\" effect. These findings underscore that the way developers and end-users engage with LLMs \"in the wild\" is complex and multifaceted. We discuss implications for model builders, AI developers, and infrastructure providers, and outline how a data-driven understanding of usage can inform better design and deployment of LLM systems.", "AI": {"tldr": "\u57fa\u4e8eOpenRouter\u5e73\u53f0\u5206\u6790100\u4e07\u4ebftoken\u771f\u5b9eLLM\u4f7f\u7528\u6570\u636e\uff0c\u53d1\u73b0\u5f00\u6e90\u6a21\u578b\u91c7\u7528\u7387\u9ad8\u3001\u521b\u610f\u89d2\u8272\u626e\u6f14\u548c\u7f16\u7a0b\u8f85\u52a9\u9700\u6c42\u5927\u3001\u667a\u80fd\u4f53\u63a8\u7406\u5174\u8d77\uff0c\u5e76\u8bc6\u522b\u51fa\u65e9\u671f\u7528\u6237\u7684\"\u73bb\u7483\u978b\"\u7559\u5b58\u6548\u5e94\u3002", "motivation": "\u968f\u7740o1\u7b49\u63a8\u7406\u6a21\u578b\u7684\u53d1\u5e03\uff0cLLM\u4ece\u5355\u6b21\u6a21\u5f0f\u751f\u6210\u8f6c\u5411\u591a\u6b65\u6df1\u601d\u63a8\u7406\uff0c\u4f46\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\u7684\u5b9e\u8bc1\u7406\u89e3\u6ede\u540e\u3002\u9700\u8981\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e86\u89e3LLM\u7684\u5b9e\u9645\u5e94\u7528\u6a21\u5f0f\u3002", "method": "\u5229\u7528OpenRouter\u5e73\u53f0\uff08AI\u63a8\u7406\u63d0\u4f9b\u5546\uff09\u5206\u6790\u8d85\u8fc7100\u4e07\u4ebftoken\u7684\u771f\u5b9eLLM\u4ea4\u4e92\u6570\u636e\uff0c\u6db5\u76d6\u4e0d\u540c\u4efb\u52a1\u3001\u5730\u57df\u548c\u65f6\u95f4\uff0c\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u89c2\u5bdf\u5230\u5f00\u6e90\u6a21\u578b\u91c7\u7528\u7387\u663e\u8457\uff0c\u521b\u610f\u89d2\u8272\u626e\u6f14\uff08\u8d85\u8d8a\u751f\u4ea7\u529b\u4efb\u52a1\uff09\u548c\u7f16\u7a0b\u8f85\u52a9\u7c7b\u522b\u7279\u522b\u53d7\u6b22\u8fce\uff0c\u667a\u80fd\u4f53\u63a8\u7406\u5174\u8d77\u3002\u7559\u5b58\u5206\u6790\u53d1\u73b0\u65e9\u671f\u7528\u6237\u53c2\u4e0e\u5ea6\u6301\u4e45\u6027\u8fdc\u8d85\u540e\u671f\u7528\u6237\uff0c\u79f0\u4e3a\"\u73bb\u7483\u978b\"\u6548\u5e94\u3002", "conclusion": "LLM\u7684\u5b9e\u9645\u4f7f\u7528\u590d\u6742\u591a\u6837\uff0c\u6570\u636e\u9a71\u52a8\u7684\u4f7f\u7528\u7406\u89e3\u80fd\u4e3a\u6a21\u578b\u6784\u5efa\u8005\u3001AI\u5f00\u53d1\u8005\u548c\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u5546\u63d0\u4f9b\u8bbe\u8ba1\u90e8\u7f72\u6307\u5bfc\uff0c\u4fc3\u8fdb\u66f4\u597d\u7684LLM\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2601.10101", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10101", "abs": "https://arxiv.org/abs/2601.10101", "authors": ["Ke Chen", "Jiandian Zeng", "Zihao Peng", "Guo Li", "Guangxue Zhang", "Tian Wang"], "title": "MATRIX AS PLAN: Structured Logical Reasoning with Feedback-Driven Replanning", "comment": "12 pages, 5 figures, 2 tables. Accepted at The Web Conference (WWW) 2026", "summary": "As knowledge and semantics on the web grow increasingly complex, enhancing Large Language Models (LLMs) comprehension and reasoning capabilities has become particularly important. Chain-of-Thought (CoT) prompting has been shown to enhance the reasoning capabilities of LLMs. However, it still falls short on logical reasoning tasks that rely on symbolic expressions and strict deductive rules. Neuro-symbolic methods address this gap by enforcing formal correctness through external solvers. Yet these solvers are highly format-sensitive, and small instabilities in model outputs can lead to frequent processing failures. LLM-driven approaches avoid parsing brittleness, but they lack structured representations and process-level error-correction mechanisms. To further enhance the logical reasoning capabilities of LLMs, we propose MatrixCoT, a structured CoT framework with a matrix-based plan. Specifically, we normalize and type natural language expressions, attach explicit citation fields, and introduce a matrix-based planning method to preserve global relations among steps. The plan becomes a verifiable artifact, making execution more stable. For verification, we also add a feedback-driven replanning mechanism. Under semantic-equivalence constraints, it identifies omissions and defects, rewrites and compresses the dependency matrix, and produces a more trustworthy final answer. Experiments on five logical-reasoning benchmarks and five LLMs show that, without relying on external solvers, MatrixCoT enhances both robustness and interpretability when tackling complex symbolic reasoning tasks, while maintaining competitive performance.", "AI": {"tldr": "MatrixCoT\uff1a\u4e00\u79cd\u57fa\u4e8e\u77e9\u9635\u89c4\u5212\u7684\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u6846\u67b6\uff0c\u901a\u8fc7\u89c4\u8303\u5316\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u3001\u6dfb\u52a0\u663e\u5f0f\u5f15\u7528\u5b57\u6bb5\u548c\u77e9\u9635\u89c4\u5212\u65b9\u6cd5\uff0c\u589e\u5f3aLLM\u5728\u7b26\u53f7\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u601d\u7ef4\u94fe\u63d0\u793a\u5728\u4f9d\u8d56\u7b26\u53f7\u8868\u8fbe\u548c\u4e25\u683c\u6f14\u7ece\u89c4\u5219\u7684\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u8db3\uff1b\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u6c42\u89e3\u5668\u4f46\u683c\u5f0f\u654f\u611f\u6613\u5931\u8d25\uff1bLLM\u9a71\u52a8\u65b9\u6cd5\u7f3a\u4e4f\u7ed3\u6784\u5316\u8868\u793a\u548c\u8fc7\u7a0b\u7ea7\u7ea0\u9519\u673a\u5236\u3002\u9700\u8981\u589e\u5f3aLLM\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faMatrixCoT\u6846\u67b6\uff1a1\uff09\u89c4\u8303\u5316\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u5e76\u6dfb\u52a0\u7c7b\u578b\u6807\u6ce8\uff1b2\uff09\u9644\u52a0\u663e\u5f0f\u5f15\u7528\u5b57\u6bb5\uff1b3\uff09\u5f15\u5165\u57fa\u4e8e\u77e9\u9635\u7684\u89c4\u5212\u65b9\u6cd5\u4ee5\u4fdd\u6301\u6b65\u9aa4\u95f4\u7684\u5168\u5c40\u5173\u7cfb\uff1b4\uff09\u6dfb\u52a0\u53cd\u9988\u9a71\u52a8\u7684\u91cd\u65b0\u89c4\u5212\u673a\u5236\uff0c\u5728\u8bed\u4e49\u7b49\u4ef7\u7ea6\u675f\u4e0b\u8bc6\u522b\u9057\u6f0f\u548c\u7f3a\u9677\uff0c\u91cd\u5199\u5e76\u538b\u7f29\u4f9d\u8d56\u77e9\u9635\u3002", "result": "\u5728\u4e94\u4e2a\u903b\u8f91\u63a8\u7406\u57fa\u51c6\u548c\u4e94\u4e2aLLM\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMatrixCoT\u5728\u4e0d\u4f9d\u8d56\u5916\u90e8\u6c42\u89e3\u5668\u7684\u60c5\u51b5\u4e0b\uff0c\u589e\u5f3a\u4e86\u5904\u7406\u590d\u6742\u7b26\u53f7\u63a8\u7406\u4efb\u52a1\u65f6\u7684\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "conclusion": "MatrixCoT\u901a\u8fc7\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u548c\u77e9\u9635\u89c4\u5212\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7b26\u53f7\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u589e\u5f3aLLM\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.10114", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10114", "abs": "https://arxiv.org/abs/2601.10114", "authors": ["Cheng Feng", "Chaoliang Zhong", "Jun Sun", "Yusuke Oishi"], "title": "Following the Teacher's Footsteps: Scheduled Checkpoint Distillation for Domain-Specific LLMs", "comment": "15 pages, submitted to ICPR 2026", "summary": "Large language models (LLMs) are challenging to deploy for domain-specific tasks due to their massive scale. While distilling a fine-tuned LLM into a smaller student model is a promising alternative, the capacity gap between teacher and student often leads to suboptimal performance. This raises a key question: when and how can a student model match or even surpass its teacher on domain-specific tasks? In this work, we propose a novel theoretical insight: a student can outperform its teacher if its advantage on a Student-Favored Subdomain (SFS) outweighs its deficit on the Teacher-Favored Subdomain (TFS). Guided by this insight, we propose Scheduled Checkpoint Distillation (SCD), which reduces the TFS deficit by emulating the teacher's convergence process during supervised fine-tuning (SFT) on the domain task, and a sample-wise Adaptive Weighting (AW) mechanism to preserve student strengths on SFS. Experiments across diverse domain tasks--including QA, NER, and text classification in multiple languages--show that our method consistently outperforms existing distillation approaches, allowing the student model to match or even exceed the performance of its fine-tuned teacher.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5SCD\uff0c\u901a\u8fc7\u6a21\u62df\u6559\u5e08\u6a21\u578b\u5728\u9886\u57df\u4efb\u52a1\u4e0a\u7684\u6536\u655b\u8fc7\u7a0b\u6765\u51cf\u5c11\u5b66\u751f\u6a21\u578b\u5728\u6559\u5e08\u4f18\u52bf\u5b50\u57df\u4e0a\u7684\u7f3a\u9677\uff0c\u540c\u65f6\u4f7f\u7528\u81ea\u9002\u5e94\u52a0\u6743\u673a\u5236\u4fdd\u6301\u5b66\u751f\u5728\u81ea\u8eab\u4f18\u52bf\u5b50\u57df\u4e0a\u7684\u4f18\u52bf\uff0c\u4f7f\u5b66\u751f\u6a21\u578b\u80fd\u5728\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u4e0a\u8fbe\u5230\u751a\u81f3\u8d85\u8d8a\u6559\u5e08\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u56f0\u96be\uff0c\u800c\u5c06\u5fae\u8c03\u540e\u7684LLM\u84b8\u998f\u5230\u5c0f\u578b\u5b66\u751f\u6a21\u578b\u65f6\uff0c\u5e08\u751f\u6a21\u578b\u4e4b\u95f4\u7684\u5bb9\u91cf\u5dee\u8ddd\u5e38\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002\u6838\u5fc3\u95ee\u9898\u662f\uff1a\u5b66\u751f\u6a21\u578b\u4f55\u65f6\u4ee5\u53ca\u5982\u4f55\u5728\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u4e0a\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u6559\u5e08\u6a21\u578b\uff1f", "method": "\u63d0\u51fa\u7406\u8bba\u6d1e\u5bdf\uff1a\u5b66\u751f\u6a21\u578b\u8981\u8d85\u8d8a\u6559\u5e08\uff0c\u9700\u8981\u5176\u5728\u5b66\u751f\u4f18\u52bf\u5b50\u57df(SFS)\u4e0a\u7684\u4f18\u52bf\u8d85\u8fc7\u5176\u5728\u6559\u5e08\u4f18\u52bf\u5b50\u57df(TFS)\u4e0a\u7684\u7f3a\u9677\u3002\u57fa\u4e8e\u6b64\u63d0\u51faSCD\u65b9\u6cd5\uff1a1) \u901a\u8fc7\u6a21\u62df\u6559\u5e08\u6a21\u578b\u5728SFT\u8fc7\u7a0b\u4e2d\u7684\u6536\u655b\u8fc7\u7a0b\u6765\u51cf\u5c11TFS\u7f3a\u9677\uff1b2) \u4f7f\u7528\u6837\u672c\u7ea7\u81ea\u9002\u5e94\u52a0\u6743(AW)\u673a\u5236\u6765\u4fdd\u6301\u5b66\u751f\u5728SFS\u4e0a\u7684\u4f18\u52bf\u3002", "result": "\u5728\u591a\u79cd\u9886\u57df\u4efb\u52a1\uff08\u5305\u62ecQA\u3001NER\u3001\u591a\u8bed\u8a00\u6587\u672c\u5206\u7c7b\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u84b8\u998f\u65b9\u6cd5\uff0c\u4f7f\u5b66\u751f\u6a21\u578b\u80fd\u591f\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u5176\u5fae\u8c03\u6559\u5e08\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u63d0\u51fa\u7684SCD\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5b66\u751f\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u4e0a\u53ef\u4ee5\u8d85\u8d8a\u6559\u5e08\u6a21\u578b\uff0c\u5173\u952e\u5728\u4e8e\u5e73\u8861\u5b66\u751f\u5728\u4e0d\u540c\u5b50\u57df\u4e0a\u7684\u4f18\u52bf\u4e0e\u7f3a\u9677\uff0c\u4e3a\u9ad8\u6548\u90e8\u7f72\u9886\u57df\u4e13\u7528\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2601.10131", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.10131", "abs": "https://arxiv.org/abs/2601.10131", "authors": ["Yizhan Li", "Florence Cloutier", "Sifan Wu", "Ali Parviz", "Boris Knyazev", "Yan Zhang", "Glen Berseth", "Bang Liu"], "title": "M^4olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints", "comment": null, "summary": "Generating molecules that satisfy precise numeric constraints over multiple physicochemical properties is critical and challenging. Although large language models (LLMs) are expressive, they struggle with precise multi-objective control and numeric reasoning without external structure and feedback. We introduce \\textbf{M olGen}, a fragment-level, retrieval-augmented, two-stage framework for molecule generation under multi-property constraints. Stage I : Prototype generation: a multi-agent reasoner performs retrieval-anchored, fragment-level edits to produce a candidate near the feasible region. Stage II : RL-based fine-grained optimization: a fragment-level optimizer trained with Group Relative Policy Optimization (GRPO) applies one- or multi-hop refinements to explicitly minimize the property errors toward our target while regulating edit complexity and deviation from the prototype. A large, automatically curated dataset with reasoning chains of fragment edits and measured property deltas underpins both stages, enabling deterministic, reproducible supervision and controllable multi-hop reasoning. Unlike prior work, our framework better reasons about molecules by leveraging fragments and supports controllable refinement toward numeric targets. Experiments on generation under two sets of property constraints (QED, LogP, Molecular Weight and HOMO, LUMO) show consistent gains in validity and precise satisfaction of multi-property targets, outperforming strong LLMs and graph-based algorithms.", "AI": {"tldr": "MolGen\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u5206\u5b50\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u7247\u6bb5\u7ea7\u68c0\u7d22\u589e\u5f3a\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u5728\u591a\u4e2a\u7269\u7406\u5316\u5b66\u6027\u8d28\u7ea6\u675f\u4e0b\u751f\u6210\u6ee1\u8db3\u7cbe\u786e\u6570\u503c\u8981\u6c42\u7684\u5206\u5b50\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7cbe\u786e\u591a\u76ee\u6807\u63a7\u5236\u548c\u6570\u503c\u63a8\u7406\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u7f3a\u4e4f\u5916\u90e8\u7ed3\u6784\u548c\u53cd\u9988\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u751f\u6210\u6ee1\u8db3\u591a\u4e2a\u7cbe\u786e\u6570\u503c\u7ea6\u675f\u5206\u5b50\u7684\u65b9\u6cd5\u3002", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u4e3a\u539f\u578b\u751f\u6210\uff0c\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u63a8\u7406\u5668\u8fdb\u884c\u68c0\u7d22\u951a\u5b9a\u7684\u7247\u6bb5\u7ea7\u7f16\u8f91\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4e3aRL\u4f18\u5316\uff0c\u4f7f\u7528GRPO\u8bad\u7ec3\u7684\u7247\u6bb5\u7ea7\u4f18\u5316\u5668\u8fdb\u884c\u5355\u8df3\u6216\u591a\u8df3\u7ec6\u5316\uff0c\u6700\u5c0f\u5316\u5c5e\u6027\u8bef\u5dee\u3002", "result": "\u5728QED\u3001LogP\u3001\u5206\u5b50\u91cf\u548cHOMO\u3001LUMO\u4e24\u7ec4\u6027\u8d28\u7ea6\u675f\u4e0b\u7684\u751f\u6210\u5b9e\u9a8c\u4e2d\uff0cMolGen\u5728\u6709\u6548\u6027\u548c\u591a\u5c5e\u6027\u76ee\u6807\u7cbe\u786e\u6ee1\u8db3\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u5f3aLLM\u548c\u56fe\u7b97\u6cd5\u3002", "conclusion": "MolGen\u901a\u8fc7\u7247\u6bb5\u7ea7\u63a8\u7406\u548c\u53ef\u63a7\u7ec6\u5316\uff0c\u80fd\u591f\u66f4\u597d\u5730\u751f\u6210\u6ee1\u8db3\u7cbe\u786e\u6570\u503c\u7ea6\u675f\u7684\u5206\u5b50\uff0c\u5728\u591a\u5c5e\u6027\u7ea6\u675f\u5206\u5b50\u751f\u6210\u4efb\u52a1\u4e2d\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2601.10132", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10132", "abs": "https://arxiv.org/abs/2601.10132", "authors": ["Yanan Cao", "Farnaz Fallahi", "Murali Mohana Krishna Dandu", "Lalitesh Morishetti", "Kai Zhao", "Luyi Ma", "Sinduja Subramaniam", "Jianpeng Xu", "Evren Korpeoglu", "Kaushiki Nag", "Sushant Kumar", "Kannan Achan"], "title": "Is More Context Always Better? Examining LLM Reasoning Capability for Time Interval Prediction", "comment": "Accepted at The Web Conference 2026 (WWW 2026)", "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in reasoning and prediction across different domains. Yet, their ability to infer temporal regularities from structured behavioral data remains underexplored. This paper presents a systematic study investigating whether LLMs can predict time intervals between recurring user actions, such as repeated purchases, and how different levels of contextual information shape their predictive behavior. Using a simple but representative repurchase scenario, we benchmark state-of-the-art LLMs in zero-shot settings against both statistical and machine-learning models. Two key findings emerge. First, while LLMs surpass lightweight statistical baselines, they consistently underperform dedicated machine-learning models, showing their limited ability to capture quantitative temporal structure. Second, although moderate context can improve LLM accuracy, adding further user-level detail degrades performance. These results challenge the assumption that \"more context leads to better reasoning\". Our study highlights fundamental limitations of today's LLMs in structured temporal inference and offers guidance for designing future context-aware hybrid models that integrate statistical precision with linguistic flexibility.", "AI": {"tldr": "LLMs\u5728\u9884\u6d4b\u7528\u6237\u91cd\u590d\u884c\u4e3a\u65f6\u95f4\u95f4\u9694\u65b9\u9762\u8868\u73b0\u6709\u9650\uff0c\u867d\u7136\u4f18\u4e8e\u7b80\u5355\u7edf\u8ba1\u6a21\u578b\u4f46\u4e0d\u5982\u4e13\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4e14\u8fc7\u591a\u4e0a\u4e0b\u6587\u4fe1\u606f\u53cd\u800c\u4f1a\u964d\u4f4e\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4e2a\u9886\u57df\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u548c\u9884\u6d4b\u80fd\u529b\uff0c\u4f46\u5176\u4ece\u7ed3\u6784\u5316\u884c\u4e3a\u6570\u636e\u4e2d\u63a8\u65ad\u65f6\u95f4\u89c4\u5f8b\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76LLMs\u662f\u5426\u80fd\u9884\u6d4b\u91cd\u590d\u7528\u6237\u884c\u4e3a\uff08\u5982\u91cd\u590d\u8d2d\u4e70\uff09\u4e4b\u95f4\u7684\u65f6\u95f4\u95f4\u9694\uff0c\u4ee5\u53ca\u4e0d\u540c\u7ea7\u522b\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u5982\u4f55\u5f71\u54cd\u5176\u9884\u6d4b\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u7b80\u5355\u7684\u4ee3\u8868\u6027\u91cd\u590d\u8d2d\u4e70\u573a\u666f\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u5bf9\u6700\u5148\u8fdb\u7684LLMs\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u7edf\u8ba1\u6a21\u578b\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002\u7814\u7a76\u8003\u5bdf\u4e86\u4e0d\u540c\u5c42\u6b21\u4e0a\u4e0b\u6587\u4fe1\u606f\u5bf9LLM\u9884\u6d4b\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "result": "1. LLMs\u867d\u7136\u4f18\u4e8e\u8f7b\u91cf\u7ea7\u7edf\u8ba1\u57fa\u7ebf\u6a21\u578b\uff0c\u4f46\u59cb\u7ec8\u4e0d\u5982\u4e13\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u663e\u793a\u51fa\u5176\u5728\u6355\u6349\u5b9a\u91cf\u65f6\u95f4\u7ed3\u6784\u65b9\u9762\u7684\u6709\u9650\u80fd\u529b\u3002\n2. \u9002\u5ea6\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u53ef\u4ee5\u63d0\u9ad8LLM\u51c6\u786e\u6027\uff0c\u4f46\u6dfb\u52a0\u66f4\u591a\u7528\u6237\u7ea7\u522b\u7ec6\u8282\u53cd\u800c\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u6311\u6218\u4e86\"\u66f4\u591a\u4e0a\u4e0b\u6587\u5e26\u6765\u66f4\u597d\u63a8\u7406\"\u7684\u5047\u8bbe\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524dLLMs\u5728\u7ed3\u6784\u5316\u65f6\u95f4\u63a8\u7406\u65b9\u9762\u7684\u57fa\u672c\u5c40\u9650\u6027\uff0c\u4e3a\u8bbe\u8ba1\u672a\u6765\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6df7\u5408\u6a21\u578b\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u8fd9\u4e9b\u6a21\u578b\u9700\u8981\u6574\u5408\u7edf\u8ba1\u7cbe\u5ea6\u4e0e\u8bed\u8a00\u7075\u6d3b\u6027\u3002"}}
{"id": "2601.10143", "categories": ["cs.AI", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2601.10143", "abs": "https://arxiv.org/abs/2601.10143", "authors": ["Haochong Xia", "Yao Long Teng", "Regan Tan", "Molei Qin", "Xinrun Wang", "Bo An"], "title": "History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis", "comment": null, "summary": "In quantitative finance, the gap between training and real-world performance-driven by concept drift and distributional non-stationarity-remains a critical obstacle for building reliable data-driven systems. Models trained on static historical data often overfit, resulting in poor generalization in dynamic markets. The mantra \"History Is Not Enough\" underscores the need for adaptive data generation that learns to evolve with the market rather than relying solely on past observations. We present a drift-aware dataflow system that integrates machine learning-based adaptive control into the data curation process. The system couples a parameterized data manipulation module comprising single-stock transformations, multi-stock mix-ups, and curation operations, with an adaptive planner-scheduler that employs gradient-based bi-level optimization to control the system. This design unifies data augmentation, curriculum learning, and data workflow management under a single differentiable framework, enabling provenance-aware replay and continuous data quality monitoring. Extensive experiments on forecasting and reinforcement learning trading tasks demonstrate that our framework enhances model robustness and improves risk-adjusted returns. The system provides a generalizable approach to adaptive data management and learning-guided workflow automation for financial data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6f02\u79fb\u611f\u77e5\u7684\u6570\u636e\u6d41\u7cfb\u7edf\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u81ea\u9002\u5e94\u63a7\u5236\u6570\u636e\u751f\u6210\u8fc7\u7a0b\uff0c\u89e3\u51b3\u91d1\u878d\u91cf\u5316\u4e2d\u8bad\u7ec3\u4e0e\u771f\u5b9e\u8868\u73b0\u4e4b\u95f4\u7684\u5dee\u8ddd\u95ee\u9898\u3002", "motivation": "\u91d1\u878d\u91cf\u5316\u4e2d\uff0c\u6982\u5ff5\u6f02\u79fb\u548c\u5206\u5e03\u975e\u5e73\u7a33\u6027\u5bfc\u81f4\u8bad\u7ec3\u6570\u636e\u4e0e\u771f\u5b9e\u5e02\u573a\u8868\u73b0\u5b58\u5728\u5dee\u8ddd\uff0c\u9759\u6001\u5386\u53f2\u6570\u636e\u8bad\u7ec3\u5bb9\u6613\u8fc7\u62df\u5408\uff0c\u9700\u8981\u80fd\u591f\u9002\u5e94\u5e02\u573a\u53d8\u5316\u7684\u81ea\u9002\u5e94\u6570\u636e\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e00\u4e2a\u6f02\u79fb\u611f\u77e5\u6570\u636e\u6d41\u7cfb\u7edf\uff0c\u5305\u542b\u53c2\u6570\u5316\u6570\u636e\u64cd\u4f5c\u6a21\u5757\uff08\u5355\u80a1\u53d8\u6362\u3001\u591a\u80a1\u6df7\u5408\u3001\u7b5b\u9009\u64cd\u4f5c\uff09\u548c\u81ea\u9002\u5e94\u89c4\u5212\u8c03\u5ea6\u5668\uff0c\u91c7\u7528\u57fa\u4e8e\u68af\u5ea6\u7684\u53cc\u5c42\u4f18\u5316\u63a7\u5236\u6574\u4e2a\u7cfb\u7edf\uff0c\u7edf\u4e00\u6570\u636e\u589e\u5f3a\u3001\u8bfe\u7a0b\u5b66\u4e60\u548c\u6570\u636e\u5de5\u4f5c\u6d41\u7ba1\u7406\u3002", "result": "\u5728\u9884\u6d4b\u548c\u5f3a\u5316\u5b66\u4e60\u4ea4\u6613\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u589e\u5f3a\u4e86\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u63d0\u9ad8\u4e86\u98ce\u9669\u8c03\u6574\u540e\u7684\u6536\u76ca\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u91d1\u878d\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u7684\u81ea\u9002\u5e94\u6570\u636e\u7ba1\u7406\u548c\u5b66\u4e60\u5f15\u5bfc\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u65b9\u6cd5\u3002"}}
{"id": "2601.10148", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10148", "abs": "https://arxiv.org/abs/2601.10148", "authors": ["Xiaowei Lv", "Zhilin Zhang", "Yijun Li", "Yusen Huo", "Siyuan Ju", "Xuyan Li", "Chunxiang Hong", "Tianyu Wang", "Yongcai Wang", "Peng Sun", "Chuan Yu", "Jian Xu", "Bo Zheng"], "title": "DecisionLLM: Large Language Models for Long Sequence Decision Exploration", "comment": null, "summary": "Long-sequence decision-making, which is usually addressed through reinforcement learning (RL), is a critical component for optimizing strategic operations in dynamic environments, such as real-time bidding in computational advertising. The Decision Transformer (DT) introduced a powerful paradigm by framing RL as an autoregressive sequence modeling problem. Concurrently, Large Language Models (LLMs) have demonstrated remarkable success in complex reasoning and planning tasks. This inspires us whether LLMs, which share the same Transformer foundation, but operate at a much larger scale, can unlock new levels of performance in long-horizon sequential decision-making problem. This work investigates the application of LLMs to offline decision making tasks. A fundamental challenge in this domain is the LLMs' inherent inability to interpret continuous values, as they lack a native understanding of numerical magnitude and order when values are represented as text strings. To address this, we propose treating trajectories as a distinct modality. By learning to align trajectory data with natural language task descriptions, our model can autoregressively predict future decisions within a cohesive framework we term DecisionLLM. We establish a set of scaling laws governing this paradigm, demonstrating that performance hinges on three factors: model scale, data volume, and data quality. In offline experimental benchmarks and bidding scenarios, DecisionLLM achieves strong performance. Specifically, DecisionLLM-3B outperforms the traditional Decision Transformer (DT) by 69.4 on Maze2D umaze-v1 and by 0.085 on AuctionNet. It extends the AIGB paradigm and points to promising directions for future exploration in online bidding.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faDecisionLLM\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u79bb\u7ebf\u51b3\u7b56\u4efb\u52a1\uff0c\u901a\u8fc7\u5c06\u8f68\u8ff9\u6570\u636e\u4f5c\u4e3a\u72ec\u7acb\u6a21\u6001\u4e0e\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u5bf9\u9f50\uff0c\u89e3\u51b3\u4e86LLM\u65e0\u6cd5\u7406\u89e3\u8fde\u7eed\u6570\u503c\u7684\u95ee\u9898\uff0c\u5728\u8ff7\u5bab\u5bfc\u822a\u548c\u7ade\u4ef7\u573a\u666f\u4e2d\u663e\u8457\u8d85\u8d8a\u4f20\u7edf\u51b3\u7b56Transformer\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u548c\u89c4\u5212\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e0e\u51b3\u7b56Transformer\u5171\u4eab\u76f8\u540c\u7684Transformer\u57fa\u7840\u67b6\u6784\uff0c\u4f46\u89c4\u6a21\u66f4\u5927\u3002\u8fd9\u542f\u53d1\u4e86\u7814\u7a76\u8005\u63a2\u7d22LLM\u662f\u5426\u80fd\u5728\u957f\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\u4e2d\u89e3\u9501\u65b0\u7684\u6027\u80fd\u6c34\u5e73\u3002\u7136\u800c\uff0cLLM\u5929\u751f\u65e0\u6cd5\u7406\u89e3\u8fde\u7eed\u6570\u503c\uff0c\u56e0\u4e3a\u5f53\u6570\u503c\u8868\u793a\u4e3a\u6587\u672c\u5b57\u7b26\u4e32\u65f6\uff0c\u5b83\u4eec\u7f3a\u4e4f\u5bf9\u6570\u503c\u5927\u5c0f\u548c\u987a\u5e8f\u7684\u672c\u673a\u7406\u89e3\u3002", "method": "\u63d0\u51faDecisionLLM\u6846\u67b6\uff0c\u5c06\u8f68\u8ff9\u6570\u636e\u89c6\u4e3a\u72ec\u7acb\u6a21\u6001\uff0c\u5b66\u4e60\u5c06\u8f68\u8ff9\u6570\u636e\u4e0e\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u5bf9\u9f50\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5728\u7edf\u4e00\u6846\u67b6\u5185\u81ea\u56de\u5f52\u9884\u6d4b\u672a\u6765\u51b3\u7b56\u3002\u5efa\u7acb\u4e86\u8be5\u8303\u5f0f\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u8868\u660e\u6027\u80fd\u53d6\u51b3\u4e8e\u4e09\u4e2a\u56e0\u7d20\uff1a\u6a21\u578b\u89c4\u6a21\u3001\u6570\u636e\u91cf\u548c\u6570\u636e\u8d28\u91cf\u3002", "result": "\u5728\u79bb\u7ebf\u5b9e\u9a8c\u57fa\u51c6\u548c\u7ade\u4ef7\u573a\u666f\u4e2d\uff0cDecisionLLM\u8868\u73b0\u51fa\u5f3a\u5927\u6027\u80fd\u3002\u5177\u4f53\u6765\u8bf4\uff0cDecisionLLM-3B\u5728Maze2D umaze-v1\u4e0a\u6bd4\u4f20\u7edf\u51b3\u7b56Transformer\u63d0\u534769.4\uff0c\u5728AuctionNet\u4e0a\u63d0\u53470.085\u3002\u6269\u5c55\u4e86AIGB\u8303\u5f0f\uff0c\u4e3a\u5728\u7ebf\u7ade\u4ef7\u63a2\u7d22\u6307\u660e\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6210\u529f\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u79bb\u7ebf\u51b3\u7b56\u4efb\u52a1\uff0c\u901a\u8fc7\u5c06\u8f68\u8ff9\u4f5c\u4e3a\u72ec\u7acb\u6a21\u6001\u89e3\u51b3\u4e86LLM\u7406\u89e3\u8fde\u7eed\u6570\u503c\u7684\u6311\u6218\u3002\u5efa\u7acb\u7684\u7f29\u653e\u5b9a\u5f8b\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0cDecisionLLM\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u7684\u4f18\u5f02\u8868\u73b0\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e3a\u5728\u7ebf\u7ade\u4ef7\u7b49\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.10157", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10157", "abs": "https://arxiv.org/abs/2601.10157", "authors": ["Yusong Wang", "Jialun Shen", "Zhihao Wu", "Yicheng Xu", "Shiyin Tan", "Mingkun Xu", "Changshuo Wang", "Zixing Song", "Prayag Tiwari"], "title": "MMPG: MoE-based Adaptive Multi-Perspective Graph Fusion for Protein Representation Learning", "comment": null, "summary": "Graph Neural Networks (GNNs) have been widely adopted for Protein Representation Learning (PRL), as residue interaction networks can be naturally represented as graphs. Current GNN-based PRL methods typically rely on single-perspective graph construction strategies, which capture partial properties of residue interactions, resulting in incomplete protein representations. To address this limitation, we propose MMPG, a framework that constructs protein graphs from multiple perspectives and adaptively fuses them via Mixture of Experts (MoE) for PRL. MMPG constructs graphs from physical, chemical, and geometric perspectives to characterize different properties of residue interactions. To capture both perspective-specific features and their synergies, we develop an MoE module, which dynamically routes perspectives to specialized experts, where experts learn intrinsic features and cross-perspective interactions. We quantitatively verify that MoE automatically specializes experts in modeling distinct levels of interaction from individual representations, to pairwise inter-perspective synergies, and ultimately to a global consensus across all perspectives. Through integrating this multi-level information, MMPG produces superior protein representations and achieves advanced performance on four different downstream protein tasks.", "AI": {"tldr": "MMPG\u662f\u4e00\u4e2a\u591a\u89c6\u89d2\u86cb\u767d\u8d28\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u878d\u5408\u7269\u7406\u3001\u5316\u5b66\u548c\u51e0\u4f55\u89c6\u89d2\u7684\u86cb\u767d\u8d28\u56fe\u8868\u793a\uff0c\u63d0\u5347\u86cb\u767d\u8d28\u8868\u793a\u5b66\u4e60\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eGNN\u7684\u86cb\u767d\u8d28\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u5355\u89c6\u89d2\u56fe\u6784\u5efa\u7b56\u7565\uff0c\u53ea\u80fd\u6355\u6349\u6b8b\u57fa\u76f8\u4e92\u4f5c\u7528\u7684\u90e8\u5206\u7279\u6027\uff0c\u5bfc\u81f4\u86cb\u767d\u8d28\u8868\u793a\u4e0d\u5b8c\u6574\u3002\u9700\u8981\u591a\u89c6\u89d2\u878d\u5408\u65b9\u6cd5\u6765\u83b7\u5f97\u66f4\u5168\u9762\u7684\u86cb\u767d\u8d28\u8868\u793a\u3002", "method": "\u63d0\u51faMMPG\u6846\u67b6\uff1a1\uff09\u4ece\u7269\u7406\u3001\u5316\u5b66\u548c\u51e0\u4f55\u4e09\u4e2a\u89c6\u89d2\u6784\u5efa\u86cb\u767d\u8d28\u56fe\uff1b2\uff09\u5f00\u53d1\u6df7\u5408\u4e13\u5bb6\u6a21\u5757\u52a8\u6001\u8def\u7531\u4e0d\u540c\u89c6\u89d2\u5230\u4e13\u95e8\u4e13\u5bb6\uff1b3\uff09\u4e13\u5bb6\u5b66\u4e60\u5185\u5728\u7279\u5f81\u548c\u8de8\u89c6\u89d2\u4ea4\u4e92\uff1b4\uff09\u6574\u5408\u591a\u5c42\u6b21\u4fe1\u606f\u751f\u6210\u86cb\u767d\u8d28\u8868\u793a\u3002", "result": "\u5b9a\u91cf\u9a8c\u8bc1MoE\u80fd\u81ea\u52a8\u4e13\u4e1a\u5316\u4e13\u5bb6\u5efa\u6a21\u4e0d\u540c\u5c42\u6b21\u7684\u4ea4\u4e92\uff1a\u4ece\u4e2a\u4f53\u8868\u793a\u5230\u6210\u5bf9\u8de8\u89c6\u89d2\u534f\u540c\uff0c\u518d\u5230\u5168\u5c40\u5171\u8bc6\u3002\u5728\u56db\u4e2a\u4e0d\u540c\u7684\u4e0b\u6e38\u86cb\u767d\u8d28\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "MMPG\u901a\u8fc7\u591a\u89c6\u89d2\u56fe\u6784\u5efa\u548c\u6df7\u5408\u4e13\u5bb6\u878d\u5408\uff0c\u80fd\u591f\u751f\u6210\u66f4\u4f18\u7684\u86cb\u767d\u8d28\u8868\u793a\uff0c\u5728\u591a\u4e2a\u86cb\u767d\u8d28\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u8bc1\u660e\u4e86\u591a\u89c6\u89d2\u878d\u5408\u5728\u86cb\u767d\u8d28\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.10169", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10169", "abs": "https://arxiv.org/abs/2601.10169", "authors": ["Boaz Carmeli", "Ron Meir", "Yonatan Belinkov"], "title": "CtD: Composition through Decomposition in Emergent Communication", "comment": null, "summary": "Compositionality is a cognitive mechanism that allows humans to systematically combine known concepts in novel ways. This study demonstrates how artificial neural agents acquire and utilize compositional generalization to describe previously unseen images. Our method, termed \"Composition through Decomposition\", involves two sequential training steps. In the 'Decompose' step, the agents learn to decompose an image into basic concepts using a codebook acquired during interaction in a multi-target coordination game. Subsequently, in the 'Compose' step, the agents employ this codebook to describe novel images by composing basic concepts into complex phrases. Remarkably, we observe cases where generalization in the `Compose' step is achieved zero-shot, without the need for additional training.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u901a\u8fc7\u5206\u89e3\u5b9e\u73b0\u7ec4\u5408\"\u7684\u65b9\u6cd5\uff0c\u8ba9\u795e\u7ecf\u7f51\u7edc\u667a\u80fd\u4f53\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u83b7\u5f97\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\uff0c\u5b9e\u73b0\u5bf9\u65b0\u56fe\u50cf\u7684\u96f6\u6837\u672c\u63cf\u8ff0\u3002", "motivation": "\u7ec4\u5408\u6027\u662f\u4eba\u7c7b\u8ba4\u77e5\u7684\u5173\u952e\u673a\u5236\uff0c\u80fd\u591f\u7cfb\u7edf\u5730\u5c06\u5df2\u77e5\u6982\u5ff5\u7ec4\u5408\u6210\u65b0\u65b9\u5f0f\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u83b7\u5f97\u548c\u5229\u7528\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\u6765\u63cf\u8ff0\u672a\u89c1\u8fc7\u7684\u56fe\u50cf\u3002", "method": "\u63d0\u51fa\"\u901a\u8fc7\u5206\u89e3\u5b9e\u73b0\u7ec4\u5408\"\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff1a1) \"\u5206\u89e3\"\u9636\u6bb5\uff1a\u667a\u80fd\u4f53\u5728\u591a\u76ee\u6807\u534f\u8c03\u6e38\u620f\u4e2d\u901a\u8fc7\u4ea4\u4e92\u5b66\u4e60\u4ee3\u7801\u672c\uff0c\u5c06\u56fe\u50cf\u5206\u89e3\u4e3a\u57fa\u672c\u6982\u5ff5\uff1b2) \"\u7ec4\u5408\"\u9636\u6bb5\uff1a\u5229\u7528\u4ee3\u7801\u672c\u5c06\u57fa\u672c\u6982\u5ff5\u7ec4\u5408\u6210\u590d\u6742\u77ed\u8bed\u6765\u63cf\u8ff0\u65b0\u56fe\u50cf\u3002", "result": "\u667a\u80fd\u4f53\u6210\u529f\u83b7\u5f97\u4e86\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u591f\u5728\"\u7ec4\u5408\"\u9636\u6bb5\u5b9e\u73b0\u96f6\u6837\u672c\u6cdb\u5316\uff0c\u5373\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5c31\u80fd\u63cf\u8ff0\u65b0\u56fe\u50cf\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u901a\u8fc7\"\u5206\u89e3-\u7ec4\u5408\"\u7684\u8ba4\u77e5\u673a\u5236\u83b7\u5f97\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u7406\u89e3\u4eba\u7c7b\u8ba4\u77e5\u673a\u5236\u548c\u5f00\u53d1\u66f4\u667a\u80fd\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.10191", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10191", "abs": "https://arxiv.org/abs/2601.10191", "authors": ["Mathieu Cherpitel", "Janne Luijten", "Thomas B\u00e4ck", "Camiel Verhamme", "Martijn Tannemaat", "Anna Kononova"], "title": "How does downsampling affect needle electromyography signals? A generalisable workflow for understanding downsampling effects on high-frequency time series", "comment": null, "summary": "Automated analysis of needle electromyography (nEMG) signals is emerging as a tool to support the detection of neuromuscular diseases (NMDs), yet the signals' high and heterogeneous sampling rates pose substantial computational challenges for feature-based machine-learning models, particularly for near real-time analysis. Downsampling offers a potential solution, but its impact on diagnostic signal content and classification performance remains insufficiently understood. This study presents a workflow for systematically evaluating information loss caused by downsampling in high-frequency time series. The workflow combines shape-based distortion metrics with classification outcomes from available feature-based machine learning models and feature space analysis to quantify how different downsampling algorithms and factors affect both waveform integrity and predictive performance. We use a three-class NMD classification task to experimentally evaluate the workflow. We demonstrate how the workflow identifies downsampling configurations that preserve diagnostic information while substantially reducing computational load. Analysis of shape-based distortion metrics showed that shape-aware downsampling algorithms outperform standard decimation, as they better preserve peak structure and overall signal morphology. The results provide practical guidance for selecting downsampling configurations that enable near real-time nEMG analysis and highlight a generalisable workflow that can be used to balance data reduction with model performance in other high-frequency time-series applications as well.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u4e0b\u91c7\u6837\u5bf9\u9ad8\u9891\u65f6\u95f4\u5e8f\u5217\u4fe1\u606f\u635f\u5931\u7684\u7cfb\u7edf\u5de5\u4f5c\u6d41\u7a0b\uff0c\u7ed3\u5408\u5f62\u72b6\u5931\u771f\u5ea6\u91cf\u548c\u5206\u7c7b\u6027\u80fd\u5206\u6790\uff0c\u7528\u4e8e\u9488\u808c\u7535\u56fe\u4fe1\u53f7\u5206\u6790\uff0c\u4ee5\u5e73\u8861\u8ba1\u7b97\u8d1f\u8f7d\u4e0e\u8bca\u65ad\u4fe1\u606f\u4fdd\u7559\u3002", "motivation": "\u9488\u808c\u7535\u56fe(nEMG)\u4fe1\u53f7\u7684\u9ad8\u91c7\u6837\u7387\u548c\u5f02\u8d28\u6027\u7ed9\u57fa\u4e8e\u7279\u5f81\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5e26\u6765\u8ba1\u7b97\u6311\u6218\uff0c\u7279\u522b\u662f\u8fd1\u5b9e\u65f6\u5206\u6790\u3002\u4e0b\u91c7\u6837\u662f\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5176\u5bf9\u8bca\u65ad\u4fe1\u53f7\u5185\u5bb9\u548c\u5206\u7c7b\u6027\u80fd\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u63d0\u51fa\u7cfb\u7edf\u5de5\u4f5c\u6d41\u7a0b\uff0c\u7ed3\u5408\u5f62\u72b6\u5931\u771f\u5ea6\u91cf\u3001\u57fa\u4e8e\u7279\u5f81\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5206\u7c7b\u7ed3\u679c\u548c\u7279\u5f81\u7a7a\u95f4\u5206\u6790\uff0c\u91cf\u5316\u4e0d\u540c\u4e0b\u91c7\u6837\u7b97\u6cd5\u548c\u56e0\u7d20\u5bf9\u6ce2\u5f62\u5b8c\u6574\u6027\u548c\u9884\u6d4b\u6027\u80fd\u7684\u5f71\u54cd\u3002\u4f7f\u7528\u4e09\u7c7bNMD\u5206\u7c7b\u4efb\u52a1\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5de5\u4f5c\u6d41\u7a0b\u80fd\u8bc6\u522b\u5728\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u8d1f\u8f7d\u7684\u540c\u65f6\u4fdd\u7559\u8bca\u65ad\u4fe1\u606f\u7684\u4e0b\u91c7\u6837\u914d\u7f6e\u3002\u5f62\u72b6\u611f\u77e5\u4e0b\u91c7\u6837\u7b97\u6cd5\u4f18\u4e8e\u6807\u51c6\u62bd\u53d6\uff0c\u80fd\u66f4\u597d\u5730\u4fdd\u7559\u5cf0\u503c\u7ed3\u6784\u548c\u6574\u4f53\u4fe1\u53f7\u5f62\u6001\u3002", "conclusion": "\u7814\u7a76\u4e3a\u9009\u62e9\u652f\u6301\u8fd1\u5b9e\u65f6nEMG\u5206\u6790\u7684\u4e0b\u91c7\u6837\u914d\u7f6e\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u63a8\u5e7f\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u53ef\u7528\u4e8e\u5e73\u8861\u5176\u4ed6\u9ad8\u9891\u65f6\u95f4\u5e8f\u5217\u5e94\u7528\u4e2d\u7684\u6570\u636e\u51cf\u5c11\u4e0e\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.10193", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10193", "abs": "https://arxiv.org/abs/2601.10193", "authors": ["Jiujiu Chen", "Weijun Zeng", "Shaofeng Hu", "Sihong Xie", "Hui Xiong"], "title": "GFM4GA: Graph Foundation Model for Group Anomaly Detection", "comment": null, "summary": "Group anomaly detection is crucial in many network applications, but faces challenges due to diverse anomaly patterns. Motivated by the success of large language models (LLMs) in natural language processing, graph foundation models (GFMs) is proposed to handle few-shot learning task with fewer labeling efforts. GFMs have been successfully applied to detection of individual anomalies but cannot be generalized to group anomalies, as group anomaly patterns must be detected as a whole and individuals in an abnormal group can look rather normal. Therefore, we propose GFM4GA, a novel graph foundation model for group anomaly detection. The pipeline is pretrained via dual-level contrastive learning based on feature-based estimation and group extraction, to capture potential group anomaly structure and feature inconsistencies. In the downstream tasks, the pipeline is finetuned in parameter-constrained and group-anomaly-proportion weighted few-shot settings, and its adaptive ability to unseen group anomalies expanded via group contexts determined by labeled anomaly neighbors. Experiments show that GFM4GA surpasses group anomaly detectors and GFMs for individual anomalies, achieving average improvements of 2.85% in AUROC and 2.55% in AUPRC.", "AI": {"tldr": "\u63d0\u51faGFM4GA\uff0c\u4e00\u79cd\u57fa\u4e8e\u56fe\u57fa\u7840\u6a21\u578b\u7684\u7fa4\u4f53\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u5c42\u6b21\u5bf9\u6bd4\u5b66\u4e60\u9884\u8bad\u7ec3\u548c\u53c2\u6570\u7ea6\u675f\u7684\u5c11\u6837\u672c\u5fae\u8c03\uff0c\u663e\u8457\u63d0\u5347\u7fa4\u4f53\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u7fa4\u4f53\u5f02\u5e38\u68c0\u6d4b\u5728\u7f51\u7edc\u5e94\u7528\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u9762\u4e34\u5f02\u5e38\u6a21\u5f0f\u591a\u6837\u5316\u7684\u6311\u6218\u3002\u73b0\u6709\u7684\u56fe\u57fa\u7840\u6a21\u578b(GFMs)\u5728\u4e2a\u4f53\u5f02\u5e38\u68c0\u6d4b\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u65e0\u6cd5\u63a8\u5e7f\u5230\u7fa4\u4f53\u5f02\u5e38\u68c0\u6d4b\uff0c\u56e0\u4e3a\u7fa4\u4f53\u5f02\u5e38\u9700\u8981\u6574\u4f53\u68c0\u6d4b\uff0c\u4e14\u5f02\u5e38\u7fa4\u4f53\u4e2d\u7684\u4e2a\u4f53\u53ef\u80fd\u770b\u8d77\u6765\u6b63\u5e38\u3002", "method": "\u63d0\u51faGFM4GA\u6a21\u578b\uff0c\u91c7\u7528\u57fa\u4e8e\u7279\u5f81\u4f30\u8ba1\u548c\u7fa4\u4f53\u63d0\u53d6\u7684\u53cc\u5c42\u6b21\u5bf9\u6bd4\u5b66\u4e60\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u6355\u6349\u6f5c\u5728\u7684\u7fa4\u4f53\u5f02\u5e38\u7ed3\u6784\u548c\u7279\u5f81\u4e0d\u4e00\u81f4\u6027\u3002\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\uff0c\u4f7f\u7528\u53c2\u6570\u7ea6\u675f\u548c\u7fa4\u4f53\u5f02\u5e38\u6bd4\u4f8b\u52a0\u6743\u7684\u5c11\u6837\u672c\u8bbe\u7f6e\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u901a\u8fc7\u6807\u8bb0\u5f02\u5e38\u90bb\u5c45\u786e\u5b9a\u7684\u7fa4\u4f53\u4e0a\u4e0b\u6587\u6269\u5c55\u5bf9\u672a\u89c1\u7fa4\u4f53\u5f02\u5e38\u7684\u9002\u5e94\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eGFM4GA\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u7fa4\u4f53\u5f02\u5e38\u68c0\u6d4b\u5668\u548c\u7528\u4e8e\u4e2a\u4f53\u5f02\u5e38\u7684GFMs\uff0c\u5728AUROC\u548cAUPRC\u4e0a\u5e73\u5747\u5206\u522b\u63d0\u5347\u4e862.85%\u548c2.55%\u3002", "conclusion": "GFM4GA\u6210\u529f\u89e3\u51b3\u4e86\u56fe\u57fa\u7840\u6a21\u578b\u5728\u7fa4\u4f53\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u7b56\u7565\uff0c\u5728\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u7fa4\u4f53\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2601.10215", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10215", "abs": "https://arxiv.org/abs/2601.10215", "authors": ["Alex Dantart", "Marco K\u00f3vacs-Navarro"], "title": "Topo-RAG: Topology-aware retrieval for hybrid text-table documents", "comment": null, "summary": "In enterprise datasets, documents are rarely pure. They are not just text, nor just numbers; they are a complex amalgam of narrative and structure. Current Retrieval-Augmented Generation (RAG) systems have attempted to address this complexity with a blunt tool: linearization. We convert rich, multidimensional tables into simple Markdown-style text strings, hoping that an embedding model will capture the geometry of a spreadsheet in a single vector. But it has already been shown that this is mathematically insufficient.\n  This work presents Topo-RAG, a framework that challenges the assumption that \"everything is text\". We propose a dual architecture that respects the topology of the data: we route fluid narrative through traditional dense retrievers, while tabular structures are processed by a Cell-Aware Late Interaction mechanism, preserving their spatial relationships. Evaluated on SEC-25, a synthetic enterprise corpus that mimics real-world complexity, Topo-RAG demonstrates an 18.4% improvement in nDCG@10 on hybrid queries compared to standard linearization approaches. It's not just about searching better; it's about understanding the shape of information.", "AI": {"tldr": "Topo-RAG\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u67b6\u6784\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u5c06\u6587\u672c\u53d9\u4e8b\u4e0e\u8868\u683c\u7ed3\u6784\u5206\u5f00\u5904\u7406\uff0c\u76f8\u6bd4\u4f20\u7edf\u7ebf\u6027\u5316\u65b9\u6cd5\u5728\u6df7\u5408\u67e5\u8be2\u4e0a\u63d0\u5347\u4e8618.4%\u7684\u6027\u80fd\u3002", "motivation": "\u4f01\u4e1a\u6570\u636e\u96c6\u901a\u5e38\u662f\u6587\u672c\u548c\u8868\u683c\u7684\u590d\u6742\u6df7\u5408\u4f53\uff0c\u5f53\u524dRAG\u7cfb\u7edf\u5c06\u6240\u6709\u5185\u5bb9\u7ebf\u6027\u5316\u4e3a\u6587\u672c\u5b57\u7b26\u4e32\u7684\u65b9\u6cd5\u5728\u6570\u5b66\u4e0a\u662f\u4e0d\u5145\u5206\u7684\uff0c\u65e0\u6cd5\u6355\u6349\u8868\u683c\u7684\u7a7a\u95f4\u5173\u7cfb\u3002", "method": "\u91c7\u7528\u53cc\u67b6\u6784\u8bbe\u8ba1\uff1a\u6587\u672c\u5185\u5bb9\u901a\u8fc7\u4f20\u7edf\u5bc6\u96c6\u68c0\u7d22\u5668\u5904\u7406\uff0c\u8868\u683c\u7ed3\u6784\u901a\u8fc7Cell-Aware Late Interaction\u673a\u5236\u5904\u7406\uff0c\u4fdd\u7559\u5176\u7a7a\u95f4\u62d3\u6251\u5173\u7cfb\u3002", "result": "\u5728\u6a21\u62df\u771f\u5b9e\u4f01\u4e1a\u590d\u6742\u6027\u7684SEC-25\u5408\u6210\u8bed\u6599\u5e93\u4e0a\u8bc4\u4f30\uff0cTopo-RAG\u5728\u6df7\u5408\u67e5\u8be2\u4e0a\u7684nDCG@10\u6bd4\u6807\u51c6\u7ebf\u6027\u5316\u65b9\u6cd5\u63d0\u5347\u4e8618.4%\u3002", "conclusion": "Topo-RAG\u6311\u6218\u4e86\"\u4e00\u5207\u7686\u6587\u672c\"\u7684\u5047\u8bbe\uff0c\u901a\u8fc7\u5c0a\u91cd\u6570\u636e\u62d3\u6251\u7ed3\u6784\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u4fe1\u606f\u68c0\u7d22\uff0c\u8fd9\u4e0d\u4ec5\u5173\u4e4e\u641c\u7d22\u6548\u679c\uff0c\u66f4\u5173\u4e4e\u7406\u89e3\u4fe1\u606f\u7684\u5f62\u72b6\u3002"}}
{"id": "2601.10245", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10245", "abs": "https://arxiv.org/abs/2601.10245", "authors": ["Vansh Kapoor", "Aman Gupta", "Hao Chen", "Anurag Beniwal", "Jing Huang", "Aviral Kumar"], "title": "TRIM: Hybrid Inference via Targeted Stepwise Routing in Multi-Step Reasoning Tasks", "comment": null, "summary": "Multi-step reasoning tasks like mathematical problem solving are vulnerable to cascading failures, where a single incorrect step leads to complete solution breakdown. Current LLM routing methods assign entire queries to one model, treating all reasoning steps as equal. We propose TRIM (Targeted routing in multi-step reasoning tasks), which routes only critical steps$\\unicode{x2013}$those likely to derail the solution$\\unicode{x2013}$to larger models while letting smaller models handle routine continuations. Our key insight is that targeted step-level interventions can fundamentally transform inference efficiency by confining expensive calls to precisely those steps where stronger models prevent cascading errors. TRIM operates at the step-level: it uses process reward models to identify erroneous steps and makes routing decisions based on step-level uncertainty and budget constraints. We develop several routing strategies within TRIM, ranging from a simple threshold-based policy to more expressive policies that reason about long-horizon accuracy-cost trade-offs and uncertainty in step-level correctness estimates. On MATH-500, even the simplest thresholding strategy surpasses prior routing methods with 5x higher cost efficiency, while more advanced policies match the strong, expensive model's performance using 80% fewer expensive model tokens. On harder benchmarks such as AIME, TRIM achieves up to 6x higher cost efficiency. All methods generalize effectively across math reasoning tasks, demonstrating that step-level difficulty represents fundamental characteristics of reasoning.", "AI": {"tldr": "TRIM\u63d0\u51fa\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u8fdb\u884c\u6b65\u9aa4\u7ea7\u8def\u7531\uff0c\u4ec5\u5c06\u5173\u952e\u6b65\u9aa4\u5206\u914d\u7ed9\u5927\u6a21\u578b\u5904\u7406\uff0c\u800c\u8ba9\u5c0f\u6a21\u578b\u5904\u7406\u5e38\u89c4\u6b65\u9aa4\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387", "motivation": "\u5f53\u524dLLM\u8def\u7531\u65b9\u6cd5\u5c06\u6574\u4e2a\u67e5\u8be2\u5206\u914d\u7ed9\u5355\u4e00\u6a21\u578b\uff0c\u5c06\u6240\u6709\u63a8\u7406\u6b65\u9aa4\u89c6\u4e3a\u540c\u7b49\u91cd\u8981\u3002\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u5bb9\u6613\u4ea7\u751f\u7ea7\u8054\u5931\u8d25\uff0c\u5355\u4e2a\u9519\u8bef\u6b65\u9aa4\u4f1a\u5bfc\u81f4\u6574\u4e2a\u89e3\u51b3\u65b9\u6848\u5d29\u6e83\u3002\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u6b65\u9aa4\u7ea7\u8def\u7531\u6765\u63d0\u5347\u6548\u7387", "method": "TRIM\u5728\u6b65\u9aa4\u7ea7\u522b\u64cd\u4f5c\uff1a\u4f7f\u7528\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u8bc6\u522b\u9519\u8bef\u6b65\u9aa4\uff0c\u57fa\u4e8e\u6b65\u9aa4\u7ea7\u4e0d\u786e\u5b9a\u6027\u548c\u9884\u7b97\u7ea6\u675f\u8fdb\u884c\u8def\u7531\u51b3\u7b56\u3002\u5f00\u53d1\u4e86\u4ece\u7b80\u5355\u9608\u503c\u7b56\u7565\u5230\u66f4\u590d\u6742\u7b56\u7565\u7684\u591a\u79cd\u8def\u7531\u65b9\u6cd5\uff0c\u8003\u8651\u957f\u671f\u7cbe\u5ea6-\u6210\u672c\u6743\u8861\u548c\u6b65\u9aa4\u6b63\u786e\u6027\u4f30\u8ba1\u7684\u4e0d\u786e\u5b9a\u6027", "result": "\u5728MATH-500\u4e0a\uff0c\u6700\u7b80\u5355\u7684\u9608\u503c\u7b56\u7565\u8d85\u8d8a\u5148\u524d\u8def\u7531\u65b9\u6cd5\uff0c\u6210\u672c\u6548\u7387\u63d0\u9ad85\u500d\uff1b\u66f4\u9ad8\u7ea7\u7684\u7b56\u7565\u4ec5\u4f7f\u752820%\u7684\u6602\u8d35\u6a21\u578btoken\u5c31\u80fd\u5339\u914d\u5f3a\u5927\u6602\u8d35\u6a21\u578b\u7684\u6027\u80fd\u3002\u5728AIME\u7b49\u66f4\u96be\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTRIM\u5b9e\u73b0\u9ad8\u8fbe6\u500d\u7684\u6210\u672c\u6548\u7387\u63d0\u5347", "conclusion": "\u6b65\u9aa4\u7ea7\u96be\u5ea6\u4ee3\u8868\u4e86\u63a8\u7406\u7684\u57fa\u672c\u7279\u5f81\uff0cTRIM\u7684\u6b65\u9aa4\u7ea7\u5e72\u9884\u65b9\u6cd5\u80fd\u591f\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u63a8\u7406\u6548\u7387\uff0c\u5c06\u6602\u8d35\u8c03\u7528\u9650\u5236\u5728\u90a3\u4e9b\u9700\u8981\u66f4\u5f3a\u6a21\u578b\u9632\u6b62\u7ea7\u8054\u9519\u8bef\u7684\u5173\u952e\u6b65\u9aa4\u4e0a"}}
{"id": "2601.10254", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10254", "abs": "https://arxiv.org/abs/2601.10254", "authors": ["Irina Abdullaeva", "Anton Vasiliuk", "Elizaveta Goncharova", "Temurbek Rahmatullaev", "Zagorulko Ivan", "Maxim Kurkin", "Andrey Kuznetsov"], "title": "NoReGeo: Non-Reasoning Geometry Benchmark", "comment": null, "summary": "We present NoReGeo, a novel benchmark designed to evaluate the intrinsic geometric understanding of large language models (LLMs) without relying on reasoning or algebraic computation. Unlike existing benchmarks that primarily assess models' proficiency in reasoning-based geometry-where solutions are derived using algebraic methods-NoReGeo focuses on evaluating whether LLMs can inherently encode spatial relationships and recognize geometric properties directly. Our benchmark comprises 2,500 trivial geometric problems spanning 25 categories, each carefully crafted to be solvable purely through native geometric understanding, assuming known object locations. We assess a range of state-of-the-art models on NoReGeo, including frontier models like GPT-4, observing that even the most advanced systems achieve an overall maximum of 65% accuracy in binary classification tasks. Further, our ablation experiments demonstrate that such geometric understanding does not emerge through fine-tuning alone, indicating that effective training for geometric comprehension requires a specialized approach from the outset. Our findings highlight a significant gap in current LLMs' ability to natively grasp geometric concepts, providing a foundation for future research toward models with true geometric cognition.", "AI": {"tldr": "NoReGeo\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5185\u5728\u51e0\u4f55\u7406\u89e3\u80fd\u529b\u7684\u65b0\u57fa\u51c6\uff0c\u4e13\u6ce8\u4e8e\u7a7a\u95f4\u5173\u7cfb\u548c\u51e0\u4f55\u5c5e\u6027\u8bc6\u522b\u800c\u975e\u4ee3\u6570\u63a8\u7406\uff0c\u7ed3\u679c\u663e\u793a\u5373\u4f7f\u6700\u5148\u8fdb\u6a21\u578b\u5728\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1\u4e2d\u6700\u9ad8\u51c6\u786e\u7387\u4ec565%", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u57fa\u4e8e\u63a8\u7406\u7684\u51e0\u4f55\u80fd\u529b\uff08\u4f7f\u7528\u4ee3\u6570\u65b9\u6cd5\uff09\uff0c\u4f46\u7f3a\u4e4f\u5bf9LLMs\u662f\u5426\u771f\u6b63\u5185\u5728\u5730\u7f16\u7801\u7a7a\u95f4\u5173\u7cfb\u548c\u8bc6\u522b\u51e0\u4f55\u5c5e\u6027\u7684\u8bc4\u4f30\u3002\u9700\u8981\u4e13\u95e8\u57fa\u51c6\u6765\u6d4b\u8bd5\u6a21\u578b\u7684\u539f\u751f\u51e0\u4f55\u7406\u89e3\u80fd\u529b\u3002", "method": "\u521b\u5efa\u5305\u542b2,500\u4e2a\u7b80\u5355\u51e0\u4f55\u95ee\u9898\u7684NoReGeo\u57fa\u51c6\uff0c\u6db5\u76d625\u4e2a\u7c7b\u522b\uff0c\u6bcf\u4e2a\u95ee\u9898\u8bbe\u8ba1\u4e3a\u4ec5\u901a\u8fc7\u539f\u751f\u51e0\u4f55\u7406\u89e3\u5373\u53ef\u89e3\u51b3\uff08\u5047\u8bbe\u5df2\u77e5\u5bf9\u8c61\u4f4d\u7f6e\uff09\u3002\u8bc4\u4f30\u5305\u62ecGPT-4\u5728\u5185\u7684\u591a\u4e2a\u5148\u8fdb\u6a21\u578b\uff0c\u5e76\u8fdb\u884c\u6d88\u878d\u5b9e\u9a8c\u3002", "result": "\u5373\u4f7f\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff08\u5982GPT-4\uff09\u5728\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1\u4e2d\u6700\u9ad8\u51c6\u786e\u7387\u4ec5\u8fbe\u523065%\u3002\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\uff0c\u4ec5\u901a\u8fc7\u5fae\u8c03\u65e0\u6cd5\u83b7\u5f97\u51e0\u4f55\u7406\u89e3\u80fd\u529b\uff0c\u9700\u8981\u4e13\u95e8\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u539f\u751f\u51e0\u4f55\u6982\u5ff5\u7406\u89e3\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u51e0\u4f55\u7406\u89e3\u80fd\u529b\u4e0d\u4f1a\u901a\u8fc7\u5fae\u8c03\u81ea\u7136\u6d8c\u73b0\uff0c\u9700\u8981\u4ece\u5f00\u59cb\u5c31\u91c7\u7528\u4e13\u95e8\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002NoReGeo\u4e3a\u672a\u6765\u5f00\u53d1\u5177\u6709\u771f\u6b63\u51e0\u4f55\u8ba4\u77e5\u80fd\u529b\u7684\u6a21\u578b\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.10306", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10306", "abs": "https://arxiv.org/abs/2601.10306", "authors": ["Xin Guan", "Zijian Li", "Shen Huang", "Pengjun Xie", "Jingren Zhou", "Jiuxin Cao"], "title": "Evidence-Augmented Policy Optimization with Reward Co-Evolution for Long-Context Reasoning", "comment": null, "summary": "While Reinforcement Learning (RL) has advanced LLM reasoning, applying it to long-context scenarios is hindered by sparsity of outcome rewards. This limitation fails to penalize ungrounded \"lucky guesses,\" leaving the critical process of needle-in-a-haystack evidence retrieval largely unsupervised. To address this, we propose EAPO (Evidence-Augmented Policy Optimization). We first establish the Evidence-Augmented Reasoning paradigm, validating via Tree-Structured Evidence Sampling that precise evidence extraction is the decisive bottleneck for long-context reasoning. Guided by this insight, EAPO introduces a specialized RL algorithm where a reward model computes a Group-Relative Evidence Reward, providing dense process supervision to explicitly improve evidence quality. To sustain accurate supervision throughout training, we further incorporate an Adaptive Reward-Policy Co-Evolution mechanism. This mechanism iteratively refines the reward model using outcome-consistent rollouts, sharpening its discriminative capability to ensure precise process guidance. Comprehensive evaluations across eight benchmarks demonstrate that EAPO significantly enhances long-context reasoning performance compared to SOTA baselines.", "AI": {"tldr": "EAPO\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc1\u636e\u589e\u5f3a\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bc6\u96c6\u7684\u8fc7\u7a0b\u76d1\u7763\u6765\u6539\u8fdb\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u7684\u8bc1\u636e\u68c0\u7d22\u8d28\u91cf\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfRL\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e2d\u5956\u52b1\u7a00\u758f\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u5b58\u5728\u5956\u52b1\u7a00\u758f\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u6709\u6548\u60e9\u7f5a\u65e0\u6839\u636e\u7684\"\u5e78\u8fd0\u731c\u6d4b\"\uff0c\u5bfc\u81f4\u5173\u952e\u7684\"\u5927\u6d77\u635e\u9488\"\u8bc1\u636e\u68c0\u7d22\u8fc7\u7a0b\u7f3a\u4e4f\u76d1\u7763\u3002", "method": "1) \u5efa\u7acb\u8bc1\u636e\u589e\u5f3a\u63a8\u7406\u8303\u5f0f\uff0c\u901a\u8fc7\u6811\u7ed3\u6784\u8bc1\u636e\u91c7\u6837\u9a8c\u8bc1\u7cbe\u786e\u8bc1\u636e\u63d0\u53d6\u662f\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u5173\u952e\u74f6\u9888\uff1b2) \u63d0\u51faEAPO\u7b97\u6cd5\uff0c\u4f7f\u7528\u5956\u52b1\u6a21\u578b\u8ba1\u7b97\u7ec4\u76f8\u5bf9\u8bc1\u636e\u5956\u52b1\uff0c\u63d0\u4f9b\u5bc6\u96c6\u8fc7\u7a0b\u76d1\u7763\uff1b3) \u5f15\u5165\u81ea\u9002\u5e94\u5956\u52b1-\u7b56\u7565\u534f\u540c\u8fdb\u5316\u673a\u5236\uff0c\u8fed\u4ee3\u4f18\u5316\u5956\u52b1\u6a21\u578b\u4ee5\u786e\u4fdd\u7cbe\u786e\u7684\u8fc7\u7a0b\u6307\u5bfc\u3002", "result": "\u5728\u516b\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u8868\u660e\uff0cEAPO\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "EAPO\u901a\u8fc7\u5bc6\u96c6\u7684\u8fc7\u7a0b\u76d1\u7763\u548c\u5956\u52b1-\u7b56\u7565\u534f\u540c\u8fdb\u5316\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u7684\u8bc1\u636e\u68c0\u7d22\u76d1\u7763\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2601.10342", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10342", "abs": "https://arxiv.org/abs/2601.10342", "authors": ["Cheng Lin Cheng", "Ting Chuan Lin", "Chai Kai Chang"], "title": "C-GRASP: Clinically-Grounded Reasoning for Affective Signal Processing", "comment": null, "summary": "Heart rate variability (HRV) is a pivotal noninvasive marker for autonomic monitoring; however, applying Large Language Models (LLMs) to HRV interpretation is hindered by physiological hallucinations. These include respiratory sinus arrhythmia (RSA) contamination, short-data instability in nonlinear metrics, and the neglect of individualized baselines in favor of population norms. We propose C-GRASP (Clinically-Grounded Reasoning for Affective Signal Processing), a guardrailed RAG-enhanced pipeline that decomposes HRV interpretation into eight traceable reasoning steps. Central to C-GRASP is a Z-score Priority Hierarchy that enforces the weighting of individualized baseline shifts over normative statistics. The system effectively mitigates spectral hallucinations through automated RSA-aware guardrails, preventing contamination of frequency-domain indices. Evaluated on 414 trials from the DREAMER dataset, C-GRASP integrated with high-scale reasoning models (e.g., MedGemma3-thinking) achieved superior performance in 4-class emotion classification (37.3% accuracy) and a Clinical Reasoning Consistency (CRC) score of 69.6%. Ablation studies confirm that the individualized Delta Z-score module serves as the critical logical anchor, preventing the \"population bias\" common in native LLMs. Ultimately, C-GRASP transitions affective computing from black-box classification to transparent, evidence-based clinical decision support, paving the way for safer AI integration in biomedical engineering.", "AI": {"tldr": "C-GRASP\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e34\u5e8a\u63a8\u7406\u7684HRV\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u516b\u6b65\u53ef\u8ffd\u6eaf\u63a8\u7406\u6d41\u7a0b\u548cZ-score\u4f18\u5148\u7ea7\u5c42\u6b21\u7ed3\u6784\uff0c\u6709\u6548\u89e3\u51b3LLM\u5728HRV\u89e3\u91ca\u4e2d\u7684\u751f\u7406\u5e7b\u89c9\u95ee\u9898\uff0c\u5b9e\u73b0\u900f\u660e\u7684\u60c5\u611f\u8ba1\u7b97\u51b3\u7b56\u652f\u6301\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fc3\u7387\u53d8\u5f02\u6027\u89e3\u91ca\u4e2d\u5b58\u5728\u751f\u7406\u5e7b\u89c9\u95ee\u9898\uff0c\u5305\u62ec\u547c\u5438\u6027\u7aa6\u6027\u5fc3\u5f8b\u5931\u5e38\u6c61\u67d3\u3001\u975e\u7ebf\u6027\u6307\u6807\u77ed\u6570\u636e\u4e0d\u7a33\u5b9a\u6027\uff0c\u4ee5\u53ca\u5ffd\u89c6\u4e2a\u4f53\u5316\u57fa\u7ebf\u800c\u4f9d\u8d56\u7fa4\u4f53\u6807\u51c6\u3002\u8fd9\u4e9b\u95ee\u9898\u963b\u788d\u4e86LLM\u5728HRV\u5206\u6790\u4e2d\u7684\u4e34\u5e8a\u5e94\u7528\u3002", "method": "\u63d0\u51faC-GRASP\uff08\u4e34\u5e8a\u57fa\u7840\u63a8\u7406\u60c5\u611f\u4fe1\u53f7\u5904\u7406\uff09\u6846\u67b6\uff0c\u91c7\u7528\u62a4\u680f\u589e\u5f3a\u7684RAG\u6d41\u7a0b\uff0c\u5c06HRV\u89e3\u91ca\u5206\u89e3\u4e3a\u516b\u4e2a\u53ef\u8ffd\u6eaf\u63a8\u7406\u6b65\u9aa4\u3002\u6838\u5fc3\u662fZ-score\u4f18\u5148\u7ea7\u5c42\u6b21\u7ed3\u6784\uff0c\u5f3a\u8c03\u4e2a\u4f53\u5316\u57fa\u7ebf\u53d8\u5316\u4f18\u4e8e\u89c4\u8303\u7edf\u8ba1\u3002\u901a\u8fc7\u81ea\u52a8\u5316RSA\u611f\u77e5\u62a4\u680f\u51cf\u8f7b\u9891\u8c31\u5e7b\u89c9\u3002", "result": "\u5728DREAMER\u6570\u636e\u96c6\u7684414\u4e2a\u8bd5\u9a8c\u4e2d\uff0cC-GRASP\u4e0e\u9ad8\u89c4\u6a21\u63a8\u7406\u6a21\u578b\uff08\u5982MedGemma3-thinking\uff09\u7ed3\u5408\uff0c\u57284\u7c7b\u60c5\u611f\u5206\u7c7b\u4e2d\u8fbe\u523037.3%\u51c6\u786e\u7387\uff0c\u4e34\u5e8a\u63a8\u7406\u4e00\u81f4\u6027\u5f97\u5206\u4e3a69.6%\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e2a\u4f53\u5316Delta Z-score\u6a21\u5757\u662f\u5173\u952e\u903b\u8f91\u951a\u70b9\u3002", "conclusion": "C-GRASP\u5c06\u60c5\u611f\u8ba1\u7b97\u4ece\u9ed1\u76d2\u5206\u7c7b\u8f6c\u53d8\u4e3a\u900f\u660e\u3001\u57fa\u4e8e\u8bc1\u636e\u7684\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\uff0c\u4e3a\u751f\u7269\u533b\u5b66\u5de5\u7a0b\u4e2d\u66f4\u5b89\u5168\u7684AI\u96c6\u6210\u94fa\u5e73\u9053\u8def\u3002\u4e2a\u4f53\u5316\u57fa\u7ebf\u6a21\u5757\u6709\u6548\u9632\u6b62\u4e86\u539f\u751fLLM\u5e38\u89c1\u7684\"\u7fa4\u4f53\u504f\u5dee\"\u3002"}}
{"id": "2601.10398", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10398", "abs": "https://arxiv.org/abs/2601.10398", "authors": ["Xuancheng Ren", "Shijing Hu", "Zhihui Lu", "Jiangqi Huang", "Qiang Duan"], "title": "LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL Queries", "comment": null, "summary": "In LLM-based text-to-SQL systems, unanswerable and underspecified user queries may generate not only incorrect text but also executable programs that yield misleading results or violate safety constraints, posing a major barrier to safe deployment. Existing refusal strategies for such queries either rely on output-level instruction following, which is brittle due to model hallucinations, or estimate output uncertainty, which adds complexity and overhead. To address this challenge, we formalize safe refusal in text-to-SQL systems as an answerability-gating problem and propose LatentRefusal, a latent-signal refusal mechanism that predicts query answerability from intermediate hidden activations of a large language model. We introduce the Tri-Residual Gated Encoder, a lightweight probing architecture, to suppress schema noise and amplify sparse, localized cues of question-schema mismatch that indicate unanswerability. Extensive empirical evaluations across diverse ambiguous and unanswerable settings, together with ablation studies and interpretability analyses, demonstrate the effectiveness of the proposed approach and show that LatentRefusal provides an attachable and efficient safety layer for text-to-SQL systems. Across four benchmarks, LatentRefusal improves average F1 to 88.5 percent on both backbones while adding approximately 2 milliseconds of probe overhead.", "AI": {"tldr": "LatentRefusal\uff1a\u57fa\u4e8eLLM\u9690\u85cf\u6fc0\u6d3b\u4fe1\u53f7\u9884\u6d4b\u67e5\u8be2\u53ef\u7b54\u6027\u7684\u6587\u672c\u5230SQL\u5b89\u5168\u62d2\u7edd\u673a\u5236\uff0c\u901a\u8fc7Tri-Residual Gated Encoder\u67b6\u6784\u589e\u5f3a\u95ee\u9898-\u6a21\u5f0f\u4e0d\u5339\u914d\u4fe1\u53f7\u68c0\u6d4b\uff0c\u5b9e\u73b0\u9ad8\u6548\u5b89\u5168\u5c42", "motivation": "\u5728LLM\u6587\u672c\u5230SQL\u7cfb\u7edf\u4e2d\uff0c\u4e0d\u53ef\u56de\u7b54\u548c\u672a\u5145\u5206\u6307\u5b9a\u7684\u7528\u6237\u67e5\u8be2\u53ef\u80fd\u751f\u6210\u9519\u8bef\u6587\u672c\u6216\u53ef\u6267\u884c\u7a0b\u5e8f\uff0c\u5bfc\u81f4\u8bef\u5bfc\u6027\u7ed3\u679c\u6216\u8fdd\u53cd\u5b89\u5168\u7ea6\u675f\uff0c\u8fd9\u662f\u5b89\u5168\u90e8\u7f72\u7684\u4e3b\u8981\u969c\u788d\u3002\u73b0\u6709\u62d2\u7edd\u7b56\u7565\u8981\u4e48\u4f9d\u8d56\u8f93\u51fa\u7ea7\u6307\u4ee4\u9075\u5faa\uff08\u6613\u53d7\u6a21\u578b\u5e7b\u89c9\u5f71\u54cd\uff09\uff0c\u8981\u4e48\u4f9d\u8d56\u8f93\u51fa\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff08\u589e\u52a0\u590d\u6742\u6027\u548c\u5f00\u9500\uff09\u3002", "method": "\u5c06\u5b89\u5168\u62d2\u7edd\u5f62\u5f0f\u5316\u4e3a\u53ef\u7b54\u6027\u95e8\u63a7\u95ee\u9898\uff0c\u63d0\u51faLatentRefusal\u673a\u5236\uff0c\u4eceLLM\u4e2d\u95f4\u9690\u85cf\u6fc0\u6d3b\u9884\u6d4b\u67e5\u8be2\u53ef\u7b54\u6027\u3002\u5f15\u5165Tri-Residual Gated Encoder\u8f7b\u91cf\u63a2\u6d4b\u67b6\u6784\uff0c\u6291\u5236\u6a21\u5f0f\u566a\u58f0\u5e76\u653e\u5927\u95ee\u9898-\u6a21\u5f0f\u4e0d\u5339\u914d\u7684\u7a00\u758f\u5c40\u90e8\u7ebf\u7d22\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLatentRefusal\u5c06\u5e73\u5747F1\u63d0\u5347\u81f388.5%\uff0c\u540c\u65f6\u4ec5\u589e\u52a0\u7ea62\u6beb\u79d2\u7684\u63a2\u6d4b\u5f00\u9500\u3002\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u8bc4\u4f30\u3001\u6d88\u878d\u7814\u7a76\u548c\u53ef\u89e3\u91ca\u6027\u5206\u6790\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "LatentRefusal\u4e3a\u6587\u672c\u5230SQL\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u9644\u52a0\u7684\u9ad8\u6548\u5b89\u5168\u5c42\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u4e0d\u53ef\u56de\u7b54\u548c\u6a21\u7cca\u67e5\u8be2\uff0c\u63d0\u9ad8\u7cfb\u7edf\u5b89\u5168\u6027\u800c\u4e0d\u663e\u8457\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2601.10402", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10402", "abs": "https://arxiv.org/abs/2601.10402", "authors": ["Xinyu Zhu", "Yuzhu Cai", "Zexi Liu", "Bingyang Zheng", "Cheng Wang", "Rui Ye", "Jiaao Chen", "Hanrui Wang", "Wei-Chen Wang", "Yuzhi Zhang", "Linfeng Zhang", "Weinan E", "Di Jin", "Siheng Chen"], "title": "Toward Ultra-Long-Horizon Agentic Science: Cognitive Accumulation for Machine Learning Engineering", "comment": "26 pages. 5 figures", "summary": "The advancement of artificial intelligence toward agentic science is currently bottlenecked by the challenge of ultra-long-horizon autonomy, the ability to sustain strategic coherence and iterative correction over experimental cycles spanning days or weeks. While Large Language Models (LLMs) have demonstrated prowess in short-horizon reasoning, they are easily overwhelmed by execution details in the high-dimensional, delayed-feedback environments of real-world research, failing to consolidate sparse feedback into coherent long-term guidance. Here, we present ML-Master 2.0, an autonomous agent that masters ultra-long-horizon machine learning engineering (MLE) which is a representative microcosm of scientific discovery. By reframing context management as a process of cognitive accumulation, our approach introduces Hierarchical Cognitive Caching (HCC), a multi-tiered architecture inspired by computer systems that enables the structural differentiation of experience over time. By dynamically distilling transient execution traces into stable knowledge and cross-task wisdom, HCC allows agents to decouple immediate execution from long-term experimental strategy, effectively overcoming the scaling limits of static context windows. In evaluations on OpenAI's MLE-Bench under 24-hour budgets, ML-Master 2.0 achieves a state-of-the-art medal rate of 56.44%. Our findings demonstrate that ultra-long-horizon autonomy provides a scalable blueprint for AI capable of autonomous exploration beyond human-precedent complexities.", "AI": {"tldr": "ML-Master 2.0\u901a\u8fc7\u5206\u5c42\u8ba4\u77e5\u7f13\u5b58\u67b6\u6784\u89e3\u51b3AI\u5728\u8d85\u957f\u65f6\u57df\u81ea\u4e3b\u6027\u74f6\u9888\uff0c\u5728\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u4efb\u52a1\u4e2d\u5b9e\u73b056.44%\u7684\u5956\u724c\u7387\u3002", "motivation": "\u5f53\u524dAI\u5411\u4ee3\u7406\u79d1\u5b66\u53d1\u5c55\u7684\u4e3b\u8981\u74f6\u9888\u662f\u8d85\u957f\u65f6\u57df\u81ea\u4e3b\u6027\u6311\u6218\u2014\u2014\u9700\u8981\u5728\u8de8\u8d8a\u6570\u5929\u6216\u6570\u5468\u7684\u5b9e\u9a8c\u5468\u671f\u4e2d\u4fdd\u6301\u6218\u7565\u8fde\u8d2f\u6027\u548c\u8fed\u4ee3\u4fee\u6b63\u80fd\u529b\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u77ed\u65f6\u57df\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u73b0\u5b9e\u7814\u7a76\u7684\u9ad8\u7ef4\u3001\u5ef6\u8fdf\u53cd\u9988\u73af\u5883\u4e2d\u5bb9\u6613\u88ab\u6267\u884c\u7ec6\u8282\u6df9\u6ca1\uff0c\u65e0\u6cd5\u5c06\u7a00\u758f\u53cd\u9988\u6574\u5408\u4e3a\u8fde\u8d2f\u7684\u957f\u671f\u6307\u5bfc\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u8ba4\u77e5\u7f13\u5b58\uff08HCC\uff09\u67b6\u6784\uff0c\u5c06\u4e0a\u4e0b\u6587\u7ba1\u7406\u91cd\u6784\u4e3a\u8ba4\u77e5\u79ef\u7d2f\u8fc7\u7a0b\u3002\u8fd9\u79cd\u53d7\u8ba1\u7b97\u673a\u7cfb\u7edf\u542f\u53d1\u7684\u591a\u5c42\u67b6\u6784\u80fd\u591f\u5b9e\u73b0\u7ecf\u9a8c\u968f\u65f6\u95f4\u63a8\u79fb\u7684\u7ed3\u6784\u5316\u533a\u5206\u3002\u901a\u8fc7\u52a8\u6001\u5c06\u77ac\u65f6\u6267\u884c\u8f68\u8ff9\u63d0\u70bc\u4e3a\u7a33\u5b9a\u77e5\u8bc6\u548c\u8de8\u4efb\u52a1\u667a\u6167\uff0cHCC\u4f7f\u4ee3\u7406\u80fd\u591f\u5c06\u5373\u65f6\u6267\u884c\u4e0e\u957f\u671f\u5b9e\u9a8c\u7b56\u7565\u89e3\u8026\uff0c\u6709\u6548\u514b\u670d\u9759\u6001\u4e0a\u4e0b\u6587\u7a97\u53e3\u7684\u6269\u5c55\u9650\u5236\u3002", "result": "\u5728OpenAI\u7684MLE-Bench\u8bc4\u4f30\u4e2d\uff0c\u4f7f\u752824\u5c0f\u65f6\u9884\u7b97\uff0cML-Master 2.0\u5b9e\u73b0\u4e8656.44%\u7684\u6700\u5148\u8fdb\u5956\u724c\u7387\u3002", "conclusion": "\u8d85\u957f\u65f6\u57df\u81ea\u4e3b\u6027\u4e3aAI\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u84dd\u56fe\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u8d85\u8d8a\u4eba\u7c7b\u5148\u4f8b\u590d\u6742\u6027\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u81ea\u4e3b\u63a2\u7d22\u3002"}}
{"id": "2601.10406", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10406", "abs": "https://arxiv.org/abs/2601.10406", "authors": ["Weiping Fu", "Bifan Wei", "Jingyi Hao", "Yushun Zhang", "Jian Zhang", "Jiaxin Wang", "Bo Li", "Yu He", "Lingling Zhang", "Jun Liu"], "title": "ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics", "comment": null, "summary": "Automatic Question Generation (QG) often produces outputs with critical defects, such as factual hallucinations and answer mismatches. However, existing evaluation methods, including LLM-based evaluators, mainly adopt a black-box and holistic paradigm without explicit error modeling, leading to the neglect of such defects and overestimation of question quality. To address this issue, we propose ErrEval, a flexible and Error-aware Evaluation framework that enhances QG evaluation through explicit error diagnostics. Specifically, ErrEval reformulates evaluation as a two-stage process of error diagnosis followed by informed scoring. At the first stage, a lightweight plug-and-play Error Identifier detects and categorizes common errors across structural, linguistic, and content-related aspects. These diagnostic signals are then incorporated as explicit evidence to guide LLM evaluators toward more fine-grained and grounded judgments. Extensive experiments on three benchmarks demonstrate the effectiveness of ErrEval, showing that incorporating explicit diagnostics improves alignment with human judgments. Further analyses confirm that ErrEval effectively mitigates the overestimation of low-quality questions.", "AI": {"tldr": "ErrEval\u662f\u4e00\u4e2a\u9519\u8bef\u611f\u77e5\u7684\u81ea\u52a8\u95ee\u9898\u751f\u6210\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u9519\u8bef\u8bca\u65ad\u548c\u77e5\u60c5\u8bc4\u5206\u6765\u6539\u8fdb\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e8b\u5b9e\u5e7b\u89c9\u548c\u7b54\u6848\u4e0d\u5339\u914d\u7b49\u7f3a\u9677\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u95ee\u9898\u751f\u6210\u8bc4\u4f30\u65b9\u6cd5\uff08\u5305\u62ec\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u5668\uff09\u4e3b\u8981\u91c7\u7528\u9ed1\u76d2\u6574\u4f53\u8303\u5f0f\uff0c\u7f3a\u4e4f\u660e\u786e\u7684\u9519\u8bef\u5efa\u6a21\uff0c\u5bfc\u81f4\u5173\u952e\u7f3a\u9677\uff08\u5982\u4e8b\u5b9e\u5e7b\u89c9\u548c\u7b54\u6848\u4e0d\u5339\u914d\uff09\u88ab\u5ffd\u89c6\uff0c\u5e76\u9ad8\u4f30\u4e86\u95ee\u9898\u8d28\u91cf\u3002", "method": "ErrEval\u5c06\u8bc4\u4f30\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e24\u9636\u6bb5\u8fc7\u7a0b\uff1a1\uff09\u9519\u8bef\u8bca\u65ad\u9636\u6bb5\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u5373\u63d2\u5373\u7528\u9519\u8bef\u8bc6\u522b\u5668\u68c0\u6d4b\u548c\u5206\u7c7b\u7ed3\u6784\u3001\u8bed\u8a00\u548c\u5185\u5bb9\u76f8\u5173\u7684\u5e38\u89c1\u9519\u8bef\uff1b2\uff09\u77e5\u60c5\u8bc4\u5206\u9636\u6bb5\uff0c\u5c06\u8fd9\u4e9b\u8bca\u65ad\u4fe1\u53f7\u4f5c\u4e3a\u660e\u786e\u8bc1\u636e\u6307\u5bfcLLM\u8bc4\u4f30\u5668\u505a\u51fa\u66f4\u7ec6\u7c92\u5ea6\u548c\u57fa\u4e8e\u8bc1\u636e\u7684\u5224\u65ad\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660eErrEval\u7684\u6709\u6548\u6027\uff0c\u663e\u793a\u660e\u786e\u7684\u8bca\u65ad\u4fe1\u53f7\u80fd\u63d0\u9ad8\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u8bc1\u5b9eErrEval\u6709\u6548\u7f13\u89e3\u4e86\u5bf9\u4f4e\u8d28\u91cf\u95ee\u9898\u7684\u9ad8\u4f30\u95ee\u9898\u3002", "conclusion": "ErrEval\u901a\u8fc7\u660e\u786e\u7684\u9519\u8bef\u8bca\u65ad\u548c\u77e5\u60c5\u8bc4\u5206\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u4e14\u9519\u8bef\u611f\u77e5\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u81ea\u52a8\u95ee\u9898\u751f\u6210\u7684\u8d28\u91cf\uff0c\u89e3\u51b3\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.10413", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.10413", "abs": "https://arxiv.org/abs/2601.10413", "authors": ["Haiyue Yuan", "Nikolay Matyunin", "Ali Raza", "Shujun Li"], "title": "LADFA: A Framework of Using Large Language Models and Retrieval-Augmented Generation for Personal Data Flow Analysis in Privacy Policies", "comment": null, "summary": "Privacy policies help inform people about organisations' personal data processing practices, covering different aspects such as data collection, data storage, and sharing of personal data with third parties. Privacy policies are often difficult for people to fully comprehend due to the lengthy and complex legal language used and inconsistent practices across different sectors and organisations. To help conduct automated and large-scale analyses of privacy policies, many researchers have studied applications of machine learning and natural language processing techniques, including large language models (LLMs). While a limited number of prior studies utilised LLMs for extracting personal data flows from privacy policies, our approach builds on this line of work by combining LLMs with retrieval-augmented generation (RAG) and a customised knowledge base derived from existing studies. This paper presents the development of LADFA, an end-to-end computational framework, which can process unstructured text in a given privacy policy, extract personal data flows and construct a personal data flow graph, and conduct analysis of the data flow graph to facilitate insight discovery. The framework consists of a pre-processor, an LLM-based processor, and a data flow post-processor. We demonstrated and validated the effectiveness and accuracy of the proposed approach by conducting a case study that involved examining ten selected privacy policies from the automotive industry. Moreover, it is worth noting that LADFA is designed to be flexible and customisable, making it suitable for a range of text-based analysis tasks beyond privacy policy analysis.", "AI": {"tldr": "LADFA\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u7ed3\u5408LLMs\u3001RAG\u548c\u5b9a\u5236\u77e5\u8bc6\u5e93\uff0c\u4ece\u9690\u79c1\u653f\u7b56\u4e2d\u63d0\u53d6\u4e2a\u4eba\u6570\u636e\u6d41\u5e76\u6784\u5efa\u6570\u636e\u6d41\u56fe\u8fdb\u884c\u5206\u6790\u3002", "motivation": "\u9690\u79c1\u653f\u7b56\u901a\u5e38\u4f7f\u7528\u590d\u6742\u6cd5\u5f8b\u8bed\u8a00\uff0c\u96be\u4ee5\u7406\u89e3\u4e14\u5728\u4e0d\u540c\u7ec4\u7ec7\u548c\u884c\u4e1a\u4e2d\u5b58\u5728\u4e0d\u4e00\u81f4\u5b9e\u8df5\u3002\u9700\u8981\u81ea\u52a8\u5316\u3001\u5927\u89c4\u6a21\u7684\u5206\u6790\u65b9\u6cd5\u6765\u5e2e\u52a9\u7406\u89e3\u9690\u79c1\u653f\u7b56\u4e2d\u7684\u4e2a\u4eba\u6570\u636e\u5904\u7406\u5b9e\u8df5\u3002", "method": "\u5f00\u53d1LADFA\u6846\u67b6\uff0c\u7ed3\u5408LLMs\u4e0e\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u548c\u5b9a\u5236\u77e5\u8bc6\u5e93\u3002\u6846\u67b6\u5305\u62ec\u9884\u5904\u7406\u5668\u3001\u57fa\u4e8eLLM\u7684\u5904\u7406\u5668\u548c\u6570\u636e\u6d41\u540e\u5904\u7406\u5668\uff0c\u80fd\u591f\u5904\u7406\u975e\u7ed3\u6784\u5316\u6587\u672c\u3001\u63d0\u53d6\u4e2a\u4eba\u6570\u636e\u6d41\u3001\u6784\u5efa\u6570\u636e\u6d41\u56fe\u5e76\u8fdb\u884c\u6d1e\u5bdf\u5206\u6790\u3002", "result": "\u901a\u8fc7\u6c7d\u8f66\u884c\u4e1a\u5341\u4e2a\u9690\u79c1\u653f\u7b56\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u51c6\u786e\u6027\u3002\u6846\u67b6\u8bbe\u8ba1\u7075\u6d3b\u53ef\u5b9a\u5236\uff0c\u9002\u7528\u4e8e\u9690\u79c1\u653f\u7b56\u5206\u6790\u4e4b\u5916\u7684\u5404\u79cd\u6587\u672c\u5206\u6790\u4efb\u52a1\u3002", "conclusion": "LADFA\u6846\u67b6\u6210\u529f\u7ed3\u5408LLMs\u3001RAG\u548c\u5b9a\u5236\u77e5\u8bc6\u5e93\uff0c\u80fd\u591f\u6709\u6548\u63d0\u53d6\u548c\u5206\u6790\u9690\u79c1\u653f\u7b56\u4e2d\u7684\u4e2a\u4eba\u6570\u636e\u6d41\uff0c\u4e3a\u9690\u79c1\u653f\u7b56\u7406\u89e3\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5177\u6709\u6269\u5c55\u5230\u5176\u4ed6\u6587\u672c\u5206\u6790\u4efb\u52a1\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.10416", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10416", "abs": "https://arxiv.org/abs/2601.10416", "authors": ["Tiesunlong Shen", "Rui Mao", "Jin Wang", "Heming Sun", "Jian Zhang", "Xuejie Zhang", "Erik Cambria"], "title": "LLMdoctor: Token-Level Flow-Guided Preference Optimization for Efficient Test-Time Alignment of Large Language Models", "comment": "Accepted by AAAI26", "summary": "Aligning Large Language Models (LLMs) with human preferences is critical, yet traditional fine-tuning methods are computationally expensive and inflexible. While test-time alignment offers a promising alternative, existing approaches often rely on distorted trajectory-level signals or inefficient sampling, fundamentally capping performance and failing to preserve the generative diversity of the base model. This paper introduces LLMdoctor, a novel framework for efficient test-time alignment that operates via a patient-doctor paradigm. It integrates token-level reward acquisition with token-level flow-guided preference optimization (TFPO) to steer a large, frozen patient LLM with a smaller, specialized doctor model. Unlike conventional methods that rely on trajectory-level rewards, LLMdoctor first extracts fine-grained, token-level preference signals from the patient model's behavioral variations. These signals then guide the training of the doctor model via TFPO, which establishes flow consistency across all subtrajectories, enabling precise token-by-token alignment while inherently preserving generation diversity. Extensive experiments demonstrate that LLMdoctor significantly outperforms existing test-time alignment methods and even surpasses the performance of full fine-tuning approaches like DPO.", "AI": {"tldr": "LLMdoctor\uff1a\u4e00\u79cd\u57fa\u4e8e\u60a3\u8005-\u533b\u751f\u8303\u5f0f\u7684\u6d4b\u8bd5\u65f6\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6token\u7ea7\u5956\u52b1\u83b7\u53d6\u548c\u6d41\u5f15\u5bfc\u504f\u597d\u4f18\u5316\uff0c\u5728\u4fdd\u6301\u751f\u6210\u591a\u6837\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u5bf9\u9f50", "motivation": "\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u4e0d\u7075\u6d3b\uff0c\u73b0\u6709\u6d4b\u8bd5\u65f6\u5bf9\u9f50\u65b9\u6cd5\u4f9d\u8d56\u626d\u66f2\u7684\u8f68\u8ff9\u7ea7\u4fe1\u53f7\u6216\u4f4e\u6548\u91c7\u6837\uff0c\u6027\u80fd\u53d7\u9650\u4e14\u65e0\u6cd5\u4fdd\u6301\u57fa\u7840\u6a21\u578b\u7684\u751f\u6210\u591a\u6837\u6027", "method": "\u91c7\u7528\u60a3\u8005-\u533b\u751f\u8303\u5f0f\uff0c\u4ece\u60a3\u8005LLM\u7684\u884c\u4e3a\u53d8\u5316\u4e2d\u63d0\u53d6\u7ec6\u7c92\u5ea6token\u7ea7\u504f\u597d\u4fe1\u53f7\uff0c\u901a\u8fc7token\u7ea7\u6d41\u5f15\u5bfc\u504f\u597d\u4f18\u5316\uff08TFPO\uff09\u8bad\u7ec3\u533b\u751f\u6a21\u578b\uff0c\u5efa\u7acb\u6240\u6709\u5b50\u8f68\u8ff9\u7684\u6d41\u4e00\u81f4\u6027", "result": "LLMdoctor\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6d4b\u8bd5\u65f6\u5bf9\u9f50\u65b9\u6cd5\uff0c\u751a\u81f3\u8d85\u8d8aDPO\u7b49\u5b8c\u6574\u5fae\u8c03\u65b9\u6cd5\u7684\u6027\u80fd", "conclusion": "LLMdoctor\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u7cbe\u786e\u7684\u6d4b\u8bd5\u65f6\u5bf9\u9f50\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u751f\u6210\u591a\u6837\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4f18\u8d8a\u7684\u5bf9\u9f50\u6027\u80fd"}}
{"id": "2601.10457", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10457", "abs": "https://arxiv.org/abs/2601.10457", "authors": ["Ziming Dai", "Dabiao Ma", "Jinle Tong", "Mengyuan Han", "Jian Yang", "Haojun Fei"], "title": "NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models", "comment": null, "summary": "Although the Gradient Boosted Decision Trees (GBDTs) dominate industrial tabular applications, upgrading legacy models in high-concurrency production environments still faces prohibitive retraining costs and systemic risks. To address this problem, we present NSR-Boost, a neuro-symbolic residual boosting framework designed specifically for industrial scenarios. Its core advantage lies in being \"non-intrusive\". It treats the legacy model as a frozen model and performs targeted repairs on \"hard regions\" where predictions fail. The framework comprises three key stages: first, finding hard regions through residuals, then generating interpretable experts by generating symbolic code structures using Large Language Model (LLM) and fine-tuning parameters using Bayesian optimization, and finally dynamically integrating experts with legacy model output through a lightweight aggregator. We report on the successful deployment of NSR-Boost within the core financial risk control system at Qfin Holdings. This framework not only significantly outperforms state-of-the-art (SOTA) baselines across six public datasets and one private dataset, more importantly, shows excellent performance gains on real-world online data. In conclusion, it effectively captures long-tail risks missed by traditional models and offers a safe, low-cost evolutionary paradigm for industry.", "AI": {"tldr": "NSR-Boost\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6b8b\u5dee\u589e\u5f3a\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5de5\u4e1a\u573a\u666f\u4e2d\u975e\u4fb5\u5165\u5f0f\u5730\u5347\u7ea7\u9057\u7559GBDT\u6a21\u578b\uff0c\u901a\u8fc7LLM\u751f\u6210\u7b26\u53f7\u4ee3\u7801\u4e13\u5bb6\u4fee\u590d\u9884\u6d4b\u5931\u8d25\u533a\u57df\uff0c\u5df2\u5728\u91d1\u878d\u98ce\u63a7\u7cfb\u7edf\u6210\u529f\u90e8\u7f72\u3002", "motivation": "\u5728\u5de5\u4e1a\u9ad8\u5e76\u53d1\u751f\u4ea7\u73af\u5883\u4e2d\uff0c\u5347\u7ea7\u9057\u7559\u7684\u68af\u5ea6\u63d0\u5347\u51b3\u7b56\u6811(GBDT)\u6a21\u578b\u9762\u4e34\u6602\u8d35\u7684\u91cd\u65b0\u8bad\u7ec3\u6210\u672c\u548c\u7cfb\u7edf\u6027\u98ce\u9669\uff0c\u9700\u8981\u4e00\u79cd\u5b89\u5168\u3001\u4f4e\u6210\u672c\u7684\u8fdb\u5316\u8303\u5f0f\u3002", "method": "\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a1)\u901a\u8fc7\u6b8b\u5dee\u627e\u5230\u9884\u6d4b\u5931\u8d25\u7684\"\u56f0\u96be\u533a\u57df\"\uff1b2)\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7b26\u53f7\u4ee3\u7801\u7ed3\u6784\u521b\u5efa\u53ef\u89e3\u91ca\u4e13\u5bb6\uff0c\u5e76\u901a\u8fc7\u8d1d\u53f6\u65af\u4f18\u5316\u5fae\u8c03\u53c2\u6570\uff1b3)\u901a\u8fc7\u8f7b\u91cf\u7ea7\u805a\u5408\u5668\u52a8\u6001\u6574\u5408\u4e13\u5bb6\u4e0e\u9057\u7559\u6a21\u578b\u8f93\u51fa\u3002", "result": "\u5728\u516d\u4e2a\u516c\u5171\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u79c1\u6709\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u771f\u5b9e\u5728\u7ebf\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6027\u80fd\u63d0\u5347\uff0c\u6210\u529f\u90e8\u7f72\u4e8eQfin Holdings\u7684\u6838\u5fc3\u91d1\u878d\u98ce\u9669\u63a7\u5236\u7cfb\u7edf\u3002", "conclusion": "NSR-Boost\u80fd\u6709\u6548\u6355\u6349\u4f20\u7edf\u6a21\u578b\u9057\u6f0f\u7684\u957f\u5c3e\u98ce\u9669\uff0c\u4e3a\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b89\u5168\u3001\u4f4e\u6210\u672c\u7684\u8fdb\u5316\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u975e\u4fb5\u5165\u5f0f\u7684\u6a21\u578b\u5347\u7ea7\u3002"}}
{"id": "2601.10462", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.10462", "abs": "https://arxiv.org/abs/2601.10462", "authors": ["Ahmad Mustapha", "Charbel Toumieh", "Mariette Awad"], "title": "ChartComplete: A Taxonomy-based Inclusive Chart Dataset", "comment": "7 pages, 4 figures, 3 tables, 1 algorithm. Dataset and source code available at https://github.com/AI-DSCHubAUB/ChartComplete-Dataset", "summary": "With advancements in deep learning (DL) and computer vision techniques, the field of chart understanding is evolving rapidly. In particular, multimodal large language models (MLLMs) are proving to be efficient and accurate in understanding charts. To accurately measure the performance of MLLMs, the research community has developed multiple datasets to serve as benchmarks. By examining these datasets, we found that they are all limited to a small set of chart types. To bridge this gap, we propose the ChartComplete dataset. The dataset is based on a chart taxonomy borrowed from the visualization community, and it covers thirty different chart types. The dataset is a collection of classified chart images and does not include a learning signal. We present the ChartComplete dataset as is to the community to build upon it.", "AI": {"tldr": "\u63d0\u51faChartComplete\u6570\u636e\u96c6\uff0c\u8986\u76d630\u79cd\u56fe\u8868\u7c7b\u578b\uff0c\u5f25\u8865\u73b0\u6709\u56fe\u8868\u7406\u89e3\u57fa\u51c6\u6570\u636e\u96c6\u7684\u5c40\u9650\u6027", "motivation": "\u73b0\u6709\u56fe\u8868\u7406\u89e3\u57fa\u51c6\u6570\u636e\u96c6\u4ec5\u6db5\u76d6\u5c11\u91cf\u56fe\u8868\u7c7b\u578b\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u8868\u7406\u89e3\u4efb\u52a1\u4e0a\u7684\u6027\u80fd", "method": "\u57fa\u4e8e\u53ef\u89c6\u5316\u793e\u533a\u7684\u56fe\u8868\u5206\u7c7b\u6cd5\u6784\u5efaChartComplete\u6570\u636e\u96c6\uff0c\u5305\u542b30\u79cd\u4e0d\u540c\u56fe\u8868\u7c7b\u578b\u7684\u5206\u7c7b\u56fe\u50cf\u96c6\u5408\uff0c\u4e0d\u5305\u542b\u5b66\u4e60\u4fe1\u53f7", "result": "\u521b\u5efa\u4e86\u8986\u76d630\u79cd\u56fe\u8868\u7c7b\u578b\u7684ChartComplete\u6570\u636e\u96c6\uff0c\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u56fe\u8868\u7406\u89e3\u57fa\u51c6\u8d44\u6e90", "conclusion": "ChartComplete\u6570\u636e\u96c6\u586b\u8865\u4e86\u73b0\u6709\u56fe\u8868\u7406\u89e3\u57fa\u51c6\u7684\u7a7a\u767d\uff0c\u4e3a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6837\u5316\u56fe\u8868\u7c7b\u578b\u4e0a\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u57fa\u7840"}}
{"id": "2601.10485", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10485", "abs": "https://arxiv.org/abs/2601.10485", "authors": ["Runhao Zhao", "Weixin Zeng", "Wentao Zhang", "Chong Chen", "Zhengpin Li", "Xiang Zhao", "Lei Chen"], "title": "Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge", "comment": "13 pages, 4 figures", "summary": "Domain-specific knowledge graphs (DKGs) often lack coverage compared to general knowledge graphs (GKGs). To address this, we introduce Domain-specific Knowledge Graph Fusion (DKGF), a novel task that enriches DKGs by integrating relevant facts from GKGs. DKGF faces two key challenges: high ambiguity in domain relevance and misalignment in knowledge granularity across graphs. We propose ExeFuse, a simple yet effective Fact-as-Program paradigm. It treats each GKG fact as a latent semantic program, maps abstract relations to granularity-aware operators, and verifies domain relevance via program executability on the target DKG. This unified probabilistic framework jointly resolves relevance and granularity issues. We construct two benchmarks, DKGF(W-I) and DKGF(Y-I), with 21 evaluation configurations. Extensive experiments validate the task's importance and our model's effectiveness, providing the first standardized testbed for DKGF.", "AI": {"tldr": "\u63d0\u51faDKGF\u4efb\u52a1\uff0c\u901a\u8fc7\u878d\u5408\u901a\u7528\u77e5\u8bc6\u56fe\u8c31\u6765\u4e30\u5bcc\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\uff0c\u89e3\u51b3\u9886\u57df\u76f8\u5173\u6027\u548c\u77e5\u8bc6\u7c92\u5ea6\u5bf9\u9f50\u4e24\u5927\u6311\u6218\uff0c\u63d0\u51faExeFuse\u6a21\u578b\u5e76\u6784\u5efa\u57fa\u51c6\u6d4b\u8bd5", "motivation": "\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u76f8\u6bd4\u901a\u7528\u77e5\u8bc6\u56fe\u8c31\u8986\u76d6\u4e0d\u8db3\uff0c\u9700\u8981\u4ece\u901a\u7528\u77e5\u8bc6\u56fe\u8c31\u4e2d\u878d\u5408\u76f8\u5173\u4e8b\u5b9e\u6765\u4e30\u5bcc\u9886\u57df\u77e5\u8bc6\u56fe\u8c31", "method": "\u63d0\u51faExeFuse\u6a21\u578b\uff0c\u91c7\u7528Fact-as-Program\u8303\u5f0f\uff0c\u5c06GKG\u4e8b\u5b9e\u89c6\u4e3a\u6f5c\u5728\u8bed\u4e49\u7a0b\u5e8f\uff0c\u901a\u8fc7\u7c92\u5ea6\u611f\u77e5\u64cd\u4f5c\u7b26\u6620\u5c04\u62bd\u8c61\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u7a0b\u5e8f\u5728\u76ee\u6807DKG\u4e0a\u7684\u53ef\u6267\u884c\u6027\u9a8c\u8bc1\u9886\u57df\u76f8\u5173\u6027", "result": "\u6784\u5efa\u4e86\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5DKGF(W-I)\u548cDKGF(Y-I)\uff0c\u5305\u542b21\u4e2a\u8bc4\u4f30\u914d\u7f6e\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4efb\u52a1\u7684\u91cd\u8981\u6027\u548c\u6a21\u578b\u7684\u6709\u6548\u6027\uff0c\u4e3aDKGF\u63d0\u4f9b\u4e86\u9996\u4e2a\u6807\u51c6\u5316\u6d4b\u8bd5\u5e73\u53f0", "conclusion": "DKGF\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u65b0\u4efb\u52a1\uff0cExeFuse\u901a\u8fc7\u7edf\u4e00\u7684\u6982\u7387\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u9886\u57df\u76f8\u5173\u6027\u548c\u77e5\u8bc6\u7c92\u5ea6\u5bf9\u9f50\u95ee\u9898\uff0c\u4e3a\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u878d\u5408\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.10524", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10524", "abs": "https://arxiv.org/abs/2601.10524", "authors": ["Frank Bobe", "Gregory D. Vetaw", "Chase Pavlick", "Darshan Bryner", "Matthew Cook", "Jose Salas-Vernis"], "title": "Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing Detection", "comment": "16 pages, 6 figures, 6 tables", "summary": "The practice of fine-tuning Large Language Models (LLMs) has achieved state-of-the-art performance on specialized tasks, yet diagnosing why these models become brittle and fail to generalize remains a critical open problem. To address this, we introduce and apply a multi-layered diagnostic framework to a cross-architectural study. We fine-tune Llama 3.1 8B, Gemma 2 9B, and Mistral models on a high-stakes phishing detection task and use SHAP analysis and mechanistic interpretability to uncover the root causes of their generalization failures. Our investigation reveals three critical findings: (1) Generalization is driven by a powerful synergy between architecture and data diversity. The Gemma 2 9B model achieves state-of-the-art performance (>91\\% F1), but only when trained on a stylistically diverse ``generalist'' dataset. (2) Generalization is highly architecture-dependent. We diagnose a specific failure mode in Llama 3.1 8B, which performs well on a narrow domain but cannot integrate diverse data, leading to a significant performance drop. (3) Some architectures are inherently more generalizable. The Mistral model proves to be a consistent and resilient performer across multiple training paradigms. By pinpointing the flawed heuristics responsible for these failures, our work provides a concrete methodology for diagnosing and understanding generalization failures, underscoring that reliable AI requires deep validation of the interplay between architecture, data, and training strategy.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u591a\u5c42\u7ea7\u8bca\u65ad\u6846\u67b6\u5206\u6790\u4e0d\u540cLLM\u5728\u9493\u9c7c\u68c0\u6d4b\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u5931\u8d25\u539f\u56e0\uff0c\u53d1\u73b0\u67b6\u6784\u4e0e\u6570\u636e\u591a\u6837\u6027\u7684\u534f\u540c\u4f5c\u7528\u3001\u67b6\u6784\u4f9d\u8d56\u7684\u6cdb\u5316\u80fd\u529b\u5dee\u5f02\uff0c\u4ee5\u53ca\u67d0\u4e9b\u67b6\u6784\u5929\u751f\u66f4\u5177\u6cdb\u5316\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u4f46\u8bca\u65ad\u8fd9\u4e9b\u6a21\u578b\u4e3a\u4f55\u53d8\u5f97\u8106\u5f31\u4e14\u65e0\u6cd5\u6cdb\u5316\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002\u9700\u8981\u7406\u89e3\u6a21\u578b\u6cdb\u5316\u5931\u8d25\u7684\u6839\u6e90\u3002", "method": "\u91c7\u7528\u591a\u5c42\u8bca\u65ad\u6846\u67b6\u8fdb\u884c\u8de8\u67b6\u6784\u7814\u7a76\uff1a\u5fae\u8c03Llama 3.1 8B\u3001Gemma 2 9B\u548cMistral\u6a21\u578b\u8fdb\u884c\u9493\u9c7c\u68c0\u6d4b\u4efb\u52a1\uff0c\u4f7f\u7528SHAP\u5206\u6790\u548c\u673a\u5236\u53ef\u89e3\u91ca\u6027\u6280\u672f\u6765\u63ed\u793a\u6cdb\u5316\u5931\u8d25\u7684\u6839\u6e90\u3002", "result": "\u4e09\u4e2a\u5173\u952e\u53d1\u73b0\uff1a1) \u6cdb\u5316\u7531\u67b6\u6784\u4e0e\u6570\u636e\u591a\u6837\u6027\u7684\u5f3a\u5927\u534f\u540c\u4f5c\u7528\u9a71\u52a8\uff1b2) \u6cdb\u5316\u9ad8\u5ea6\u4f9d\u8d56\u67b6\u6784\uff0cLlama 3.1 8B\u5728\u7a84\u57df\u8868\u73b0\u597d\u4f46\u65e0\u6cd5\u6574\u5408\u591a\u6837\u6570\u636e\uff1b3) \u67d0\u4e9b\u67b6\u6784\u5929\u751f\u66f4\u5177\u6cdb\u5316\u6027\uff0cMistral\u6a21\u578b\u5728\u591a\u79cd\u8bad\u7ec3\u8303\u5f0f\u4e2d\u8868\u73b0\u4e00\u81f4\u4e14\u7a33\u5065\u3002", "conclusion": "\u901a\u8fc7\u8bc6\u522b\u5bfc\u81f4\u6cdb\u5316\u5931\u8d25\u7684\u7f3a\u9677\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u8bca\u65ad\u548c\u7406\u89e3\u6cdb\u5316\u5931\u8d25\u7684\u5177\u4f53\u65b9\u6cd5\uff0c\u5f3a\u8c03\u53ef\u9760\u7684AI\u9700\u8981\u6df1\u5165\u9a8c\u8bc1\u67b6\u6784\u3001\u6570\u636e\u548c\u8bad\u7ec3\u7b56\u7565\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002"}}
{"id": "2601.10527", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10527", "abs": "https://arxiv.org/abs/2601.10527", "authors": ["Xingjun Ma", "Yixu Wang", "Hengyuan Xu", "Yutao Wu", "Yifan Ding", "Yunhan Zhao", "Zilong Wang", "Jiabin Hua", "Ming Wen", "Jianan Liu", "Ranjie Duan", "Yifeng Gao", "Yingshui Tan", "Yunhao Chen", "Hui Xue", "Xin Wang", "Wei Cheng", "Jingjing Chen", "Zuxuan Wu", "Bo Li", "Yu-Gang Jiang"], "title": "A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5", "comment": "42 pages, 24 figures", "summary": "The rapid evolution of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) has produced substantial gains in reasoning, perception, and generative capability across language and vision. However, whether these advances yield commensurate improvements in safety remains unclear, in part due to fragmented evaluation practices limited to single modalities or threat models. In this report, we present an integrated safety evaluation of 7 frontier models: GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5. We evaluate each model across language, vision-language, and image generation settings using a unified protocol that integrates benchmark evaluation, adversarial evaluation, multilingual evaluation, and compliance evaluation. Aggregating our evaluations into safety leaderboards and model safety profiles across multiple evaluation modes reveals a sharply heterogeneous safety landscape. While GPT-5.2 demonstrates consistently strong and balanced safety performance across evaluations, other models exhibit pronounced trade-offs among benchmark safety, adversarial alignment, multilingual generalization, and regulatory compliance. Both language and vision-language modalities show significant vulnerability under adversarial evaluation, with all models degrading substantially despite strong results on standard benchmarks. Text-to-image models achieve relatively stronger alignment in regulated visual risk categories, yet remain brittle under adversarial or semantically ambiguous prompts. Overall, these results show that safety in frontier models is inherently multidimensional--shaped by modality, language, and evaluation scheme, underscoring the need for standardized safety evaluations to accurately assess real-world risk and guide responsible model development and deployment.", "AI": {"tldr": "\u8be5\u62a5\u544a\u5bf97\u4e2a\u524d\u6cbf\u6a21\u578b\u8fdb\u884c\u7efc\u5408\u5b89\u5168\u8bc4\u4f30\uff0c\u53d1\u73b0\u5b89\u5168\u6027\u80fd\u5b58\u5728\u663e\u8457\u5f02\u8d28\u6027\uff0cGPT-5.2\u8868\u73b0\u6700\u5747\u8861\uff0c\u5176\u4ed6\u6a21\u578b\u5728\u4e0d\u540c\u8bc4\u4f30\u7ef4\u5ea6\u5b58\u5728\u660e\u663e\u6743\u8861\uff0c\u5f3a\u8c03\u9700\u8981\u6807\u51c6\u5316\u5b89\u5168\u8bc4\u4f30\u3002", "motivation": "\u5c3d\u7ba1LLMs\u548cMLLMs\u5728\u63a8\u7406\u3001\u611f\u77e5\u548c\u751f\u6210\u80fd\u529b\u4e0a\u53d6\u5f97\u91cd\u5927\u8fdb\u5c55\uff0c\u4f46\u8fd9\u4e9b\u8fdb\u6b65\u662f\u5426\u5e26\u6765\u76f8\u5e94\u7684\u5b89\u5168\u6539\u8fdb\u4ecd\u4e0d\u660e\u786e\uff0c\u4e3b\u8981\u7531\u4e8e\u73b0\u6709\u8bc4\u4f30\u5b9e\u8df5\u5c40\u9650\u4e8e\u5355\u4e00\u6a21\u6001\u6216\u5a01\u80c1\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u7edf\u4e00\u534f\u8bae\u8bc4\u4f307\u4e2a\u524d\u6cbf\u6a21\u578b\uff08GPT-5.2\u3001Gemini 3 Pro\u7b49\uff09\uff0c\u6db5\u76d6\u8bed\u8a00\u3001\u89c6\u89c9\u8bed\u8a00\u548c\u56fe\u50cf\u751f\u6210\u573a\u666f\uff0c\u6574\u5408\u57fa\u51c6\u8bc4\u4f30\u3001\u5bf9\u6297\u8bc4\u4f30\u3001\u591a\u8bed\u8a00\u8bc4\u4f30\u548c\u5408\u89c4\u8bc4\u4f30\u56db\u79cd\u8bc4\u4f30\u6a21\u5f0f\u3002", "result": "\u5b89\u5168\u6027\u80fd\u5448\u73b0\u663e\u8457\u5f02\u8d28\u6027\uff1aGPT-5.2\u5728\u6240\u6709\u8bc4\u4f30\u4e2d\u8868\u73b0\u5747\u8861\u4e14\u5f3a\u52b2\uff1b\u5176\u4ed6\u6a21\u578b\u5728\u57fa\u51c6\u5b89\u5168\u3001\u5bf9\u6297\u5bf9\u9f50\u3001\u591a\u8bed\u8a00\u6cdb\u5316\u548c\u76d1\u7ba1\u5408\u89c4\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u6743\u8861\uff1b\u8bed\u8a00\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u6001\u5728\u5bf9\u6297\u8bc4\u4f30\u4e2d\u8868\u73b0\u8106\u5f31\uff1b\u6587\u751f\u56fe\u6a21\u578b\u5728\u53d7\u76d1\u7ba1\u89c6\u89c9\u98ce\u9669\u7c7b\u522b\u4e2d\u5bf9\u9f50\u8f83\u5f3a\u4f46\u5bf9\u6297\u63d0\u793a\u4e0b\u4ecd\u8106\u5f31\u3002", "conclusion": "\u524d\u6cbf\u6a21\u578b\u7684\u5b89\u5168\u6027\u672c\u8d28\u4e0a\u662f\u591a\u7ef4\u7684\uff0c\u53d7\u6a21\u6001\u3001\u8bed\u8a00\u548c\u8bc4\u4f30\u65b9\u6848\u5f71\u54cd\uff0c\u9700\u8981\u6807\u51c6\u5316\u5b89\u5168\u8bc4\u4f30\u6765\u51c6\u786e\u8bc4\u4f30\u73b0\u5b9e\u4e16\u754c\u98ce\u9669\uff0c\u6307\u5bfc\u8d1f\u8d23\u4efb\u6a21\u578b\u5f00\u53d1\u548c\u90e8\u7f72\u3002"}}
{"id": "2601.10543", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10543", "abs": "https://arxiv.org/abs/2601.10543", "authors": ["Yinzhi Zhao", "Ming Wang", "Shi Feng", "Xiaocui Yang", "Daling Wang", "Yifei Zhang"], "title": "Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing", "comment": null, "summary": "Large language models (LLMs) have achieved impressive performance across natural language tasks and are increasingly deployed in real-world applications. Despite extensive safety alignment efforts, recent studies show that such alignment is often shallow and remains vulnerable to jailbreak attacks. Existing defense mechanisms, including decoding-based constraints and post-hoc content detectors, struggle against sophisticated jailbreaks, often intervening robust detection or excessively degrading model utility. In this work, we examine the decoding process of LLMs and make a key observation: even when successfully jailbroken, models internally exhibit latent safety-related signals during generation. However, these signals are overridden by the model's drive for fluent continuation, preventing timely self-correction or refusal. Building on this observation, we propose a simple yet effective approach that explicitly surfaces and leverages these latent safety signals for early detection of unsafe content during decoding. Experiments across diverse jailbreak attacks demonstrate that our approach significantly enhances safety, while maintaining low over-refusal rates on benign inputs and preserving response quality. Our results suggest that activating intrinsic safety-awareness during decoding offers a promising and complementary direction for defending against jailbreak attacks. Code is available at: https://github.com/zyz13590/SafeProbing.", "AI": {"tldr": "\u63d0\u51faSafeProbing\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u7801\u8fc7\u7a0b\u4e2d\u663e\u5f0f\u5229\u7528LLMs\u5185\u90e8\u6f5c\u5728\u5b89\u5168\u4fe1\u53f7\uff0c\u5b9e\u73b0\u65e9\u671f\u68c0\u6d4b\u4e0d\u5b89\u5168\u5185\u5bb9\uff0c\u6709\u6548\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6548\u7528\u3002", "motivation": "\u5c3d\u7ba1LLMs\u7ecf\u8fc7\u5b89\u5168\u5bf9\u9f50\uff0c\u4f46\u73b0\u6709\u5bf9\u9f50\u5f80\u5f80\u662f\u6d45\u5c42\u7684\uff0c\u5bb9\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\u3002\u73b0\u6709\u9632\u5fa1\u673a\u5236\uff08\u5982\u89e3\u7801\u7ea6\u675f\u548c\u540e\u5904\u7406\u68c0\u6d4b\u5668\uff09\u96be\u4ee5\u5e94\u5bf9\u590d\u6742\u8d8a\u72f1\u653b\u51fb\uff0c\u8981\u4e48\u68c0\u6d4b\u4e0d\u8db3\uff0c\u8981\u4e48\u8fc7\u5ea6\u964d\u4f4e\u6a21\u578b\u6548\u7528\u3002", "method": "\u901a\u8fc7\u89c2\u5bdf\u53d1\u73b0\uff1a\u5373\u4f7f\u6210\u529f\u8d8a\u72f1\uff0cLLMs\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u4ecd\u4f1a\u8868\u73b0\u51fa\u5185\u90e8\u6f5c\u5728\u5b89\u5168\u4fe1\u53f7\uff0c\u4f46\u8fd9\u4e9b\u4fe1\u53f7\u88ab\u6a21\u578b\u8ffd\u6c42\u6d41\u7545\u7eed\u5199\u7684\u9a71\u52a8\u529b\u6240\u538b\u5236\u3002\u63d0\u51faSafeProbing\u65b9\u6cd5\uff0c\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\u663e\u5f0f\u63d0\u53d6\u548c\u5229\u7528\u8fd9\u4e9b\u6f5c\u5728\u5b89\u5168\u4fe1\u53f7\uff0c\u5b9e\u73b0\u65e9\u671f\u4e0d\u5b89\u5168\u5185\u5bb9\u68c0\u6d4b\u3002", "result": "\u5728\u591a\u79cd\u8d8a\u72f1\u653b\u51fb\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u589e\u5f3a\u4e86\u5b89\u5168\u6027\uff0c\u540c\u65f6\u5728\u826f\u6027\u8f93\u5165\u4e0a\u4fdd\u6301\u8f83\u4f4e\u7684\u8fc7\u5ea6\u62d2\u7edd\u7387\uff0c\u5e76\u4fdd\u6301\u4e86\u54cd\u5e94\u8d28\u91cf\u3002", "conclusion": "\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\u6fc0\u6d3b\u5185\u5728\u7684\u5b89\u5168\u610f\u8bc6\u4e3a\u9632\u5fa1\u8d8a\u72f1\u653b\u51fb\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u8865\u5145\u65b9\u5411\uff0c\u8868\u660e\u5229\u7528\u6a21\u578b\u5185\u90e8\u5b89\u5168\u4fe1\u53f7\u662f\u5b9e\u73b0\u6709\u6548\u9632\u5fa1\u7684\u5173\u952e\u9014\u5f84\u3002"}}
{"id": "2601.10581", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.10581", "abs": "https://arxiv.org/abs/2601.10581", "authors": ["Kimia Abedini", "Farzad Shami", "Gianmaria Silvello"], "title": "From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA", "comment": "Accepted paper by the 48th European Conference on Information Retrieval (ECIR'26)", "summary": "Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized API calls, though it is constrained by rigid API dependencies and limited adaptability. We replicate GeneGPT and propose GenomAgent, a multi-agent framework that efficiently coordinates specialized agents for complex genomics queries. Evaluated on nine tasks from the GeneTuring benchmark, GenomAgent outperforms GeneGPT by 12% on average, and its flexible architecture extends beyond genomics to various scientific domains needing expert knowledge extraction.", "AI": {"tldr": "GenomAgent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u8c03\u4e13\u95e8\u667a\u80fd\u4f53\u5904\u7406\u590d\u6742\u57fa\u56e0\u7ec4\u67e5\u8be2\uff0c\u5728GeneTuring\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bd4\u5f53\u524d\u6700\u4f18\u7684GeneGPT\u5e73\u5747\u63d0\u534712%\u6027\u80fd\u3002", "motivation": "\u57fa\u56e0\u7ec4\u4fe1\u606f\u7406\u89e3\u5bf9\u751f\u7269\u533b\u5b66\u7814\u7a76\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4ece\u590d\u6742\u5206\u5e03\u5f0f\u6570\u636e\u5e93\u4e2d\u63d0\u53d6\u6570\u636e\u4ecd\u7136\u56f0\u96be\u3002\u5927\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u56e0\u7ec4\u95ee\u7b54\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u53d7\u9650\u4e8e\u5bf9\u9886\u57df\u7279\u5b9a\u6570\u636e\u5e93\u7684\u8bbf\u95ee\u9650\u5236\u3002\u5f53\u524d\u6700\u4f18\u7684GeneGPT\u7cfb\u7edf\u867d\u7136\u901a\u8fc7\u4e13\u7528API\u8c03\u7528\u589e\u5f3aLLM\uff0c\u4f46\u5b58\u5728API\u4f9d\u8d56\u6027\u5f3a\u548c\u9002\u5e94\u6027\u6709\u9650\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faGenomAgent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u8c03\u591a\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\u6765\u5904\u7406\u590d\u6742\u7684\u57fa\u56e0\u7ec4\u67e5\u8be2\u3002\u8be5\u65b9\u6cd5\u590d\u5236\u4e86GeneGPT\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u6539\u8fdb\uff0c\u521b\u5efa\u4e86\u66f4\u7075\u6d3b\u7684\u67b6\u6784\u6765\u9ad8\u6548\u5904\u7406\u57fa\u56e0\u7ec4\u95ee\u7b54\u4efb\u52a1\u3002", "result": "\u5728GeneTuring\u57fa\u51c6\u6d4b\u8bd5\u7684\u4e5d\u4e2a\u4efb\u52a1\u4e0a\uff0cGenomAgent\u5e73\u5747\u6bd4GeneGPT\u6027\u80fd\u63d0\u534712%\u3002\u8be5\u6846\u67b6\u7684\u7075\u6d3b\u67b6\u6784\u4e0d\u4ec5\u9002\u7528\u4e8e\u57fa\u56e0\u7ec4\u5b66\uff0c\u8fd8\u80fd\u6269\u5c55\u5230\u5176\u4ed6\u9700\u8981\u4e13\u5bb6\u77e5\u8bc6\u63d0\u53d6\u7684\u79d1\u5b66\u9886\u57df\u3002", "conclusion": "GenomAgent\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u8c03\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u57fa\u56e0\u7ec4\u95ee\u7b54\u4e2d\u7684\u6570\u636e\u5e93\u8bbf\u95ee\u548c\u67e5\u8be2\u5904\u7406\u95ee\u9898\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5177\u6709\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u9886\u57df\u9002\u5e94\u6027\u3002"}}
{"id": "2601.10651", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.10651", "abs": "https://arxiv.org/abs/2601.10651", "authors": ["Christoph Weinhuber", "Yannik Schnitzer", "Alessandro Abate", "David Parker", "Giuseppe De Giacomo", "Moshe Y. Vardi"], "title": "Multi-Property Synthesis", "comment": null, "summary": "We study LTLf synthesis with multiple properties, where satisfying all properties may be impossible. Instead of enumerating subsets of properties, we compute in one fixed-point computation the relation between product-game states and the goal sets that are realizable from them, and we synthesize strategies achieving maximal realizable sets. We develop a fully symbolic algorithm that introduces Boolean goal variables and exploits monotonicity to represent exponentially many goal combinations compactly. Our approach substantially outperforms enumeration-based baselines, with speedups of up to two orders of magnitude.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7b26\u53f7\u5316\u7b97\u6cd5\uff0c\u7528\u4e8eLTLf\u591a\u5c5e\u6027\u7efc\u5408\uff0c\u901a\u8fc7\u4e00\u6b21\u6027\u56fa\u5b9a\u70b9\u8ba1\u7b97\u5904\u7406\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u6240\u6709\u5c5e\u6027\u7684\u60c5\u51b5\uff0c\u6027\u80fd\u6bd4\u679a\u4e3e\u65b9\u6cd5\u5feb\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u5728\u591a\u5c5e\u6027LTLf\u7efc\u5408\u4e2d\uff0c\u540c\u65f6\u6ee1\u8db3\u6240\u6709\u5c5e\u6027\u53ef\u80fd\u4e0d\u53ef\u884c\u3002\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u679a\u4e3e\u5c5e\u6027\u5b50\u96c6\uff0c\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u5904\u7406\u8fd9\u79cd\u6743\u8861\u3002", "method": "\u5f00\u53d1\u5b8c\u5168\u7b26\u53f7\u5316\u7b97\u6cd5\uff0c\u5f15\u5165\u5e03\u5c14\u76ee\u6807\u53d8\u91cf\uff0c\u5229\u7528\u5355\u8c03\u6027\u7d27\u51d1\u8868\u793a\u6307\u6570\u7ea7\u7684\u76ee\u6807\u7ec4\u5408\uff0c\u901a\u8fc7\u4e00\u6b21\u6027\u56fa\u5b9a\u70b9\u8ba1\u7b97\u72b6\u6001\u4e0e\u53ef\u5b9e\u73b0\u76ee\u6807\u96c6\u7684\u5173\u7cfb\u3002", "result": "\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u679a\u4e3e\u7684\u57fa\u7ebf\uff0c\u901f\u5ea6\u63d0\u5347\u53ef\u8fbe\u4e24\u4e2a\u6570\u91cf\u7ea7\uff0c\u80fd\u591f\u9ad8\u6548\u5408\u6210\u5b9e\u73b0\u6700\u5927\u53ef\u5b9e\u73b0\u76ee\u6807\u96c6\u7684\u7b56\u7565\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b26\u53f7\u5316\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u5c5e\u6027LTLf\u7efc\u5408\u95ee\u9898\uff0c\u907f\u514d\u4e86\u5c5e\u6027\u5b50\u96c6\u679a\u4e3e\uff0c\u5728\u6027\u80fd\u4e0a\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u5904\u7406\u4e0d\u53ef\u540c\u65f6\u6ee1\u8db3\u7684\u5c5e\u6027\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.10679", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10679", "abs": "https://arxiv.org/abs/2601.10679", "authors": ["Zirui Ren", "Ziming Liu"], "title": "Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models", "comment": null, "summary": "Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. To understand the strengths and potential failure modes of HRM, we conduct a mechanistic study on its reasoning patterns and find three surprising facts: (a) Failure of extremely simple puzzles, e.g., HRM can fail on a puzzle with only one unknown cell. We attribute this failure to the violation of the fixed point property, a fundamental assumption of HRM. (b) \"Grokking\" dynamics in reasoning steps, i.e., the answer is not improved uniformly, but instead there is a critical reasoning step that suddenly makes the answer correct; (c) Existence of multiple fixed points. HRM \"guesses\" the first fixed point, which could be incorrect, and gets trapped there for a while or forever. All facts imply that HRM appears to be \"guessing\" instead of \"reasoning\". Leveraging this \"guessing\" picture, we propose three strategies to scale HRM's guesses: data augmentation (scaling the quality of guesses), input perturbation (scaling the number of guesses by leveraging inference randomness), and model bootstrapping (scaling the number of guesses by leveraging training randomness). On the practical side, by combining all methods, we develop Augmented HRM, boosting accuracy on Sudoku-Extreme from 54.5% to 96.9%. On the scientific side, our analysis provides new insights into how reasoning models \"reason\".", "AI": {"tldr": "HRM\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u5176\u5b58\u5728\"\u731c\u6d4b\"\u800c\u975e\"\u63a8\u7406\"\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u3001\u8f93\u5165\u6270\u52a8\u548c\u6a21\u578b\u5f15\u5bfc\u4e09\u79cd\u7b56\u7565\u63d0\u5347\u6027\u80fd\uff0c\u5c06\u6570\u72ec\u6781\u7aef\u96be\u9898\u51c6\u786e\u7387\u4ece54.5%\u63d0\u5347\u81f396.9%\u3002", "motivation": "\u7814\u7a76HRM\u7684\u63a8\u7406\u673a\u5236\uff0c\u7406\u89e3\u5176\u4f18\u52bf\u548c\u6f5c\u5728\u5931\u8d25\u6a21\u5f0f\uff0c\u63ed\u793a\u5176\u5b9e\u9645\u662f\"\u731c\u6d4b\"\u800c\u975e\u771f\u6b63\"\u63a8\u7406\"\u7684\u672c\u8d28\u3002", "method": "\u5bf9HRM\u8fdb\u884c\u673a\u5236\u6027\u7814\u7a76\uff0c\u53d1\u73b0\u4e09\u4e2a\u5173\u952e\u73b0\u8c61\uff1a\u7b80\u5355\u8c1c\u9898\u5931\u8d25\u3001\u63a8\u7406\u6b65\u9aa4\u4e2d\u7684\"\u987f\u609f\"\u52a8\u6001\u3001\u591a\u56fa\u5b9a\u70b9\u5b58\u5728\u3002\u57fa\u4e8e\"\u731c\u6d4b\"\u89c6\u89d2\u63d0\u51fa\u4e09\u79cd\u6269\u5c55\u7b56\u7565\uff1a\u6570\u636e\u589e\u5f3a\uff08\u63d0\u5347\u731c\u6d4b\u8d28\u91cf\uff09\u3001\u8f93\u5165\u6270\u52a8\uff08\u5229\u7528\u63a8\u7406\u968f\u673a\u6027\u589e\u52a0\u731c\u6d4b\u6b21\u6570\uff09\u3001\u6a21\u578b\u5f15\u5bfc\uff08\u5229\u7528\u8bad\u7ec3\u968f\u673a\u6027\u589e\u52a0\u731c\u6d4b\u6b21\u6570\uff09\u3002", "result": "\u5f00\u53d1\u51fa\u589e\u5f3a\u7248HRM\uff0c\u5728Sudoku-Extreme\u4efb\u52a1\u4e0a\u5c06\u51c6\u786e\u7387\u4ece54.5%\u5927\u5e45\u63d0\u5347\u81f396.9%\u3002\u63ed\u793a\u4e86\u63a8\u7406\u6a21\u578b\u5b9e\u9645\u901a\u8fc7\"\u731c\u6d4b\"\u800c\u975e\u4e25\u683c\u63a8\u7406\u6765\u89e3\u51b3\u95ee\u9898\u3002", "conclusion": "HRM\u672c\u8d28\u4e0a\u662f\u901a\u8fc7\"\u731c\u6d4b\"\u800c\u975e\"\u63a8\u7406\"\u6765\u89e3\u51b3\u95ee\u9898\uff0c\u8fd9\u4e00\u53d1\u73b0\u4e3a\u7406\u89e3\u63a8\u7406\u6a21\u578b\u7684\u5de5\u4f5c\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u540c\u65f6\u63d0\u51fa\u7684\u589e\u5f3a\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.10681", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10681", "abs": "https://arxiv.org/abs/2601.10681", "authors": ["Amir Khurshid", "Abhishek Sehgal"], "title": "Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval Augmented Systems", "comment": null, "summary": "Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. The approach causes fragmentation in information graphs in document structures, over-retrieval, and duplication of content alongside insufficient query context, including 2nd and 3rd order facets. In this paper, a structure-informed and diversity-constrained context bubble construction framework is proposed that assembles coherent, citable bundles of spans under a strict token budget. The method preserves and exploits inherent document structure by organising multi-granular spans (e.g., sections and rows) and using task-conditioned structural priors to guide retrieval. Starting from high-relevance anchor spans, a context bubble is constructed through constrained selection that balances query relevance, marginal coverage, and redundancy penalties. It will explicitly constrain diversity and budget, producing compact and informative context sets, unlike top-k retrieval. Moreover, a full retrieval is emitted that traces the scoring and selection choices of the records, thus providing auditability and deterministic tuning. Experiments on enterprise documents demonstrate the efficiency of context bubble as it significantly reduces redundant context, is better able to cover secondary facets and has a better answer quality and citation faithfulness within a limited context window. Ablation studies demonstrate that both structural priors as well as diversity constraint selection are necessary; removing either component results in a decline in coverage and an increase in redundant or incomplete context.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u6784\u611f\u77e5\u3001\u591a\u6837\u6027\u7ea6\u675f\u7684\u4e0a\u4e0b\u6587\u6c14\u6ce1\u6784\u5efa\u6846\u67b6\uff0c\u66ff\u4ee3\u4f20\u7edfRAG\u7684top-k\u68c0\u7d22\uff0c\u901a\u8fc7\u7ec4\u7ec7\u591a\u7c92\u5ea6\u6587\u672c\u7247\u6bb5\u5e76\u5229\u7528\u6587\u6863\u7ed3\u6784\u5148\u9a8c\uff0c\u5728\u6709\u9650token\u9884\u7b97\u4e0b\u6784\u5efa\u7d27\u51d1\u3001\u53ef\u5f15\u7528\u7684\u4e0a\u4e0b\u6587\u96c6\u5408\u3002", "motivation": "\u4f20\u7edfRAG\u7684top-k\u68c0\u7d22\u65b9\u6cd5\u5b58\u5728\u4fe1\u606f\u56fe\u788e\u7247\u5316\u3001\u8fc7\u5ea6\u68c0\u7d22\u3001\u5185\u5bb9\u91cd\u590d\u4ee5\u53ca\u67e5\u8be2\u4e0a\u4e0b\u6587\u4e0d\u8db3\uff08\u7279\u522b\u662f\u4e8c\u9636\u548c\u4e09\u9636\u65b9\u9762\uff09\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u4e0a\u4e0b\u6587\u6784\u5efa\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u611f\u77e5\u3001\u591a\u6837\u6027\u7ea6\u675f\u7684\u4e0a\u4e0b\u6587\u6c14\u6ce1\u6846\u67b6\uff1a1) \u5229\u7528\u6587\u6863\u7ed3\u6784\u7ec4\u7ec7\u591a\u7c92\u5ea6\u6587\u672c\u7247\u6bb5\uff08\u5982\u7ae0\u8282\u3001\u884c\uff09\uff1b2) \u4f7f\u7528\u4efb\u52a1\u6761\u4ef6\u7ed3\u6784\u5148\u9a8c\u6307\u5bfc\u68c0\u7d22\uff1b3) \u4ece\u9ad8\u76f8\u5173\u6027\u951a\u70b9\u7247\u6bb5\u5f00\u59cb\uff0c\u901a\u8fc7\u5e73\u8861\u67e5\u8be2\u76f8\u5173\u6027\u3001\u8fb9\u9645\u8986\u76d6\u548c\u5197\u4f59\u60e9\u7f5a\u7684\u7ea6\u675f\u9009\u62e9\u6784\u5efa\u4e0a\u4e0b\u6587\u6c14\u6ce1\uff1b4) \u63d0\u4f9b\u5b8c\u6574\u68c0\u7d22\u8f68\u8ff9\u4ee5\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u6027\u548c\u786e\u5b9a\u6027\u8c03\u4f18\u3002", "result": "\u5728\u4f01\u4e1a\u6587\u6863\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0a\u4e0b\u6587\u6c14\u6ce1\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u5197\u4f59\u4e0a\u4e0b\u6587\uff0c\u66f4\u597d\u5730\u8986\u76d6\u6b21\u8981\u65b9\u9762\uff0c\u5728\u6709\u9650\u4e0a\u4e0b\u6587\u7a97\u53e3\u5185\u83b7\u5f97\u66f4\u597d\u7684\u7b54\u6848\u8d28\u91cf\u548c\u5f15\u7528\u5fe0\u5b9e\u5ea6\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u660e\u7ed3\u6784\u5148\u9a8c\u548c\u591a\u6837\u6027\u7ea6\u675f\u9009\u62e9\u90fd\u662f\u5fc5\u8981\u7684\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e0a\u4e0b\u6587\u6c14\u6ce1\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u548c\u591a\u6837\u6027\u7ea6\u675f\u7684\u68c0\u7d22\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfRAG\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u80fd\u591f\u5728\u6709\u9650token\u9884\u7b97\u4e0b\u6784\u5efa\u66f4\u7d27\u51d1\u3001\u4fe1\u606f\u4e30\u5bcc\u4e14\u53ef\u5ba1\u8ba1\u7684\u4e0a\u4e0b\u6587\u96c6\u5408\u3002"}}
{"id": "2601.10696", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10696", "abs": "https://arxiv.org/abs/2601.10696", "authors": ["Han Jiang", "Yao Xiao", "Rachel Hurley", "Shichao Liu"], "title": "The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load", "comment": null, "summary": "Our study examines how generative AI (GenAI) influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Thirty-six student participants from Architectural Engineering and other disciplines completed a two-phase architectural design task, first independently and then with external tools (GenAI-assisted condition and control condition using an online repository of existing architectural projects). Design outcomes were evaluated by expert raters, while self-efficacy and cognitive load were self-reported after each phase. Difference-in-differences analyses revealed no overall performance advantage of GenAI across participants; however, subgroup analyses showed that GenAI significantly improved design performance for novice designers. In contrast, general creative self-efficacy declined for students using GenAI. Cognitive load did not differ significantly between conditions, though prompt usage patterns showed that iterative idea generation and visual feedback prompts were linked to greater reductions in cognitive load. These findings suggest that GenAI effectiveness depends on users' prior expertise and interaction strategies through prompting.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u5728\u5efa\u7b51\u6982\u5ff5\u8bbe\u8ba1\u4e2d\u80fd\u63d0\u5347\u65b0\u624b\u8868\u73b0\uff0c\u4f46\u4f1a\u964d\u4f4e\u521b\u610f\u81ea\u6211\u6548\u80fd\u611f\uff0c\u6548\u679c\u53d6\u51b3\u4e8e\u7528\u6237\u4e13\u4e1a\u6c34\u5e73\u548c\u63d0\u793a\u7b56\u7565", "motivation": "\u7814\u7a76\u751f\u6210\u5f0fAI\u5982\u4f55\u5f71\u54cd\u5efa\u7b51\u6982\u5ff5\u8bbe\u8ba1\u4e2d\u7684\u8868\u73b0\u3001\u521b\u610f\u81ea\u6211\u6548\u80fd\u611f\u548c\u8ba4\u77e5\u8d1f\u8377\uff0c\u63a2\u7d22AI\u5de5\u5177\u5728\u4e0d\u540c\u4e13\u4e1a\u6c34\u5e73\u7528\u6237\u4e2d\u7684\u5dee\u5f02\u5316\u6548\u679c", "method": "36\u540d\u5b66\u751f\u53c2\u4e0e\u4e24\u9636\u6bb5\u5efa\u7b51\u8bbe\u8ba1\u4efb\u52a1\uff1a\u72ec\u7acb\u8bbe\u8ba1\u9636\u6bb5\u548c\u5916\u90e8\u5de5\u5177\u8f85\u52a9\u9636\u6bb5\uff08\u5206\u4e3aGenAI\u8f85\u52a9\u7ec4\u548c\u5728\u7ebf\u9879\u76ee\u5e93\u5bf9\u7167\u7ec4\uff09\u3002\u4e13\u5bb6\u8bc4\u4f30\u8bbe\u8ba1\u6210\u679c\uff0c\u53c2\u4e0e\u8005\u81ea\u62a5\u81ea\u6211\u6548\u80fd\u611f\u548c\u8ba4\u77e5\u8d1f\u8377\uff0c\u91c7\u7528\u53cc\u91cd\u5dee\u5206\u5206\u6790", "result": "GenAI\u5bf9\u6240\u6709\u53c2\u4e0e\u8005\u65e0\u6574\u4f53\u8868\u73b0\u4f18\u52bf\uff0c\u4f46\u663e\u8457\u63d0\u5347\u65b0\u624b\u8bbe\u8ba1\u5e08\u8868\u73b0\uff1b\u4f7f\u7528GenAI\u7684\u5b66\u751f\u521b\u610f\u81ea\u6211\u6548\u80fd\u611f\u4e0b\u964d\uff1b\u8ba4\u77e5\u8d1f\u8377\u65e0\u663e\u8457\u5dee\u5f02\uff0c\u4f46\u8fed\u4ee3\u521b\u610f\u751f\u6210\u548c\u89c6\u89c9\u53cd\u9988\u63d0\u793a\u80fd\u66f4\u5927\u7a0b\u5ea6\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8377", "conclusion": "\u751f\u6210\u5f0fAI\u6548\u679c\u53d6\u51b3\u4e8e\u7528\u6237\u4e13\u4e1a\u6c34\u5e73\u548c\u4ea4\u4e92\u7b56\u7565\uff0c\u65b0\u624b\u53d7\u76ca\u4f46\u53ef\u80fd\u635f\u5bb3\u521b\u610f\u81ea\u4fe1\uff0c\u63d0\u793a\u7b56\u7565\u4f18\u5316\u80fd\u51cf\u8f7b\u8ba4\u77e5\u8d1f\u8377"}}
