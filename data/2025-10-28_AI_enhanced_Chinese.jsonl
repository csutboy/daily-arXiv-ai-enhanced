{"id": "2510.21759", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.21759", "abs": "https://arxiv.org/abs/2510.21759", "authors": ["Rubik Khachatryan", "Georgy Lukyanov"], "title": "Entry Deterrence with Partial Reputation Spillovers", "comment": null, "summary": "We analyze a two-period, two-market chain-store game in which an incumbent's\nconduct in one market is only sometimes seen in the other. This partial\nobservability generates reputational spillovers across markets. We characterize\nequilibrium behavior by prior reputation: at high priors the strategic\nincumbent fights a lone early entrant (and mixes when both arrive together); at\nlow priors it mixes against a single entrant and accommodates coordinated\nentry. Greater observability increases early fighting yet, because any\naccommodation is more widely noticed, raises the incidence of later entry. The\nresults are robust to noisy signals and endogenous information acquisition, and\nextend naturally to many markets.", "AI": {"tldr": "\u5206\u6790\u4e24\u671f\u4e24\u5e02\u573a\u7684\u8fde\u9501\u5e97\u535a\u5f08\uff0c\u5176\u4e2d\u5728\u4f4d\u8005\u5728\u4e00\u4e2a\u5e02\u573a\u7684\u884c\u4e3a\u53ea\u80fd\u90e8\u5206\u88ab\u53e6\u4e00\u4e2a\u5e02\u573a\u89c2\u5bdf\u5230\uff0c\u4ea7\u751f\u8de8\u5e02\u573a\u7684\u58f0\u8a89\u6ea2\u51fa\u6548\u5e94\u3002", "motivation": "\u7814\u7a76\u5728\u4f4d\u8005\u884c\u4e3a\u7684\u90e8\u5206\u53ef\u89c2\u5bdf\u6027\u5982\u4f55\u5f71\u54cd\u8de8\u5e02\u573a\u7684\u58f0\u8a89\u6548\u5e94\u548c\u5747\u8861\u7b56\u7565\u3002", "method": "\u6784\u5efa\u4e24\u671f\u4e24\u5e02\u573a\u7684\u8fde\u9501\u5e97\u535a\u5f08\u6a21\u578b\uff0c\u5206\u6790\u4e0d\u540c\u5148\u9a8c\u58f0\u8a89\u4e0b\u7684\u5747\u8861\u884c\u4e3a\uff0c\u5e76\u8003\u5bdf\u53ef\u89c2\u5bdf\u6027\u3001\u566a\u58f0\u4fe1\u53f7\u548c\u5185\u751f\u4fe1\u606f\u83b7\u53d6\u7684\u5f71\u54cd\u3002", "result": "\u9ad8\u5148\u9a8c\u58f0\u8a89\u65f6\uff0c\u5728\u4f4d\u8005\u4f1a\u5bf9\u6297\u65e9\u671f\u5355\u72ec\u8fdb\u5165\u8005\uff1b\u4f4e\u5148\u9a8c\u58f0\u8a89\u65f6\uff0c\u4f1a\u5bf9\u5355\u4e2a\u8fdb\u5165\u8005\u6df7\u5408\u7b56\u7565\uff0c\u5e76\u5bb9\u7eb3\u534f\u8c03\u8fdb\u5165\u3002\u66f4\u9ad8\u7684\u53ef\u89c2\u5bdf\u6027\u4f1a\u589e\u52a0\u65e9\u671f\u5bf9\u6297\uff0c\u4f46\u7531\u4e8e\u4efb\u4f55\u5bb9\u7eb3\u884c\u4e3a\u4f1a\u88ab\u66f4\u5e7f\u6cdb\u6ce8\u610f\uff0c\u4e5f\u4f1a\u589e\u52a0\u540e\u671f\u8fdb\u5165\u3002", "conclusion": "\u90e8\u5206\u53ef\u89c2\u5bdf\u6027\u4ea7\u751f\u91cd\u8981\u7684\u58f0\u8a89\u6ea2\u51fa\u6548\u5e94\uff0c\u7ed3\u679c\u5bf9\u566a\u58f0\u4fe1\u53f7\u548c\u5185\u751f\u4fe1\u606f\u83b7\u53d6\u5177\u6709\u7a33\u5065\u6027\uff0c\u5e76\u53ef\u81ea\u7136\u6269\u5c55\u5230\u591a\u5e02\u573a\u60c5\u5f62\u3002"}}
{"id": "2510.22086", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.22086", "abs": "https://arxiv.org/abs/2510.22086", "authors": ["Pau Juan-Bartroli", "Jos\u00e9 Ignacio Rivero-Wildemauwe"], "title": "Social preferences or moral concerns: What drives rejections in the Ultimatum game?", "comment": null, "summary": "Rejections of positive offers in the Ultimatum Game have been attributed to\ndifferent motivations. We show that a model combining social preferences and\nmoral concerns provides a unifying explanation for these rejections while\naccounting for additional evidence. Under the preferences considered, a\npositive degree of spite is a necessary and sufficient condition for rejecting\npositive offers. This indicates that social preferences, rather than moral\nconcerns, drive rejection behavior. This does not imply that moral concerns do\nnot matter. We show that rejection thresholds increase with individuals' moral\nconcerns, suggesting that morality acts as an amplifier of social preferences.\nUsing data from van Leeuwen and Alger (2024), we estimate individuals' social\npreferences and moral concerns using a finite mixture approach. Consistent with\nprevious evidence, we identify two types of individuals who reject positive\noffers in the Ultimatum Game, but that differ in their Dictator Game behavior.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u793e\u4f1a\u504f\u597d\u548c\u9053\u5fb7\u5173\u6ce8\u7684\u7406\u8bba\u6a21\u578b\uff0c\u89e3\u91ca\u4e86\u6700\u540e\u901a\u7252\u6e38\u620f\u4e2d\u62d2\u7edd\u6b63\u62a5\u4ef7\u7684\u884c\u4e3a\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4e00\u5b9a\u7a0b\u5ea6\u7684\u6076\u610f\u662f\u793e\u4f1a\u504f\u597d\u9a71\u52a8\u62d2\u7edd\u884c\u4e3a\u7684\u5fc5\u8981\u4e14\u5145\u5206\u6761\u4ef6\uff0c\u800c\u9053\u5fb7\u5173\u6ce8\u5219\u8d77\u5230\u653e\u5927\u4f5c\u7528\u3002", "motivation": "\u89e3\u91ca\u6700\u540e\u901a\u7252\u6e38\u620f\u4e2d\u62d2\u7edd\u6b63\u62a5\u4ef7\u7684\u4e0d\u540c\u52a8\u673a\uff0c\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3\u8fd9\u4e9b\u62d2\u7edd\u884c\u4e3a\u3002", "method": "\u7ed3\u5408\u793e\u4f1a\u504f\u597d\u548c\u9053\u5fb7\u5173\u6ce8\u7684\u7406\u8bba\u6a21\u578b\uff0c\u4f7f\u7528\u6709\u9650\u6df7\u5408\u65b9\u6cd5\u4f30\u8ba1\u4e2a\u4f53\u7684\u793e\u4f1a\u504f\u597d\u548c\u9053\u5fb7\u5173\u6ce8\u53c2\u6570\uff0c\u5206\u6790\u6700\u540e\u901a\u7252\u6e38\u620f\u548c\u72ec\u88c1\u8005\u6e38\u620f\u6570\u636e\u3002", "result": "\u8bc6\u522b\u51fa\u4e24\u7c7b\u62d2\u7edd\u6b63\u62a5\u4ef7\u7684\u4e2a\u4f53\u7c7b\u578b\uff0c\u4ed6\u4eec\u5728\u72ec\u88c1\u8005\u6e38\u620f\u4e2d\u7684\u884c\u4e3a\u4e0d\u540c\uff1b\u62d2\u7edd\u9608\u503c\u968f\u4e2a\u4f53\u9053\u5fb7\u5173\u6ce8\u589e\u52a0\u800c\u63d0\u9ad8\uff1b\u6076\u610f\u7a0b\u5ea6\u662f\u62d2\u7edd\u884c\u4e3a\u7684\u51b3\u5b9a\u6027\u56e0\u7d20\u3002", "conclusion": "\u793e\u4f1a\u504f\u597d\u800c\u975e\u9053\u5fb7\u5173\u6ce8\u9a71\u52a8\u62d2\u7edd\u884c\u4e3a\uff0c\u4f46\u9053\u5fb7\u5173\u6ce8\u653e\u5927\u793e\u4f1a\u504f\u597d\u7684\u5f71\u54cd\uff1b\u8be5\u6a21\u578b\u4e3a\u62d2\u7edd\u6b63\u62a5\u4ef7\u63d0\u4f9b\u4e86\u7edf\u4e00\u89e3\u91ca\u6846\u67b6\u3002"}}
{"id": "2510.22411", "categories": ["econ.TH", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.22411", "abs": "https://arxiv.org/abs/2510.22411", "authors": ["Adam Wiechman", "John M. Anderies", "Margaret Garcia"], "title": "Politics, Inequality, and the Robustness of Shared Infrastructure Systems", "comment": null, "summary": "Our infrastructure systems enable our well-being by allowing us to move,\nstore, and transform materials and information given considerable social and\nenvironmental variation. Critically, this ability is shaped by the degree to\nwhich society invests in infrastructure, a fundamentally political question in\nlarge public systems. There, infrastructure providers are distinguished from\nusers through political processes, such as elections, and there is considerable\nheterogeneity among users. Previous political economic models have not taken\ninto account (i) dynamic infrastructures, (ii) dynamic user preferences, and\n(iii) alternatives to rational actor theory. Meanwhile, engineering often\nneglects politics. We address these gaps with a general dynamic model of shared\ninfrastructure systems that incorporates theories from political economy,\nsocial-ecological systems, and political psychology. We use the model to\ndevelop propositions on how multiple characteristics of the political process\nimpact the robustness of shared infrastructure systems to capacity shocks and\nunequal opportunity for private infrastructure investment. Under user fees,\ninequality decreases robustness, but taxing private infrastructure use can\nincrease robustness if non-elites have equal political influence. Election\ncycle periods have a nonlinear effect where increasing them increases\nrobustness up to a point but decreases robustness beyond that point. Further,\nthere is a negative relationship between the ideological sensitivity of\ncandidates and robustness. Overall, the biases of voters and candidates\n(whether they favor tax increases or decreases) mediate these\npolitical-economic effects on robustness because biases may or may not match\nthe reality of system needs (whether system recovery requires tax increases).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u52a8\u6001\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u7cfb\u7edf\u6a21\u578b\uff0c\u6574\u5408\u653f\u6cbb\u7ecf\u6d4e\u5b66\u3001\u793e\u4f1a\u751f\u6001\u7cfb\u7edf\u548c\u653f\u6cbb\u5fc3\u7406\u5b66\u7406\u8bba\uff0c\u5206\u6790\u653f\u6cbb\u8fc7\u7a0b\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u57fa\u7840\u8bbe\u65bd\u7cfb\u7edf\u5bf9\u5bb9\u91cf\u51b2\u51fb\u548c\u79c1\u4eba\u6295\u8d44\u673a\u4f1a\u4e0d\u5e73\u7b49\u7684\u7a33\u5065\u6027\u3002", "motivation": "\u73b0\u6709\u653f\u6cbb\u7ecf\u6d4e\u6a21\u578b\u672a\u8003\u8651\u52a8\u6001\u57fa\u7840\u8bbe\u65bd\u3001\u52a8\u6001\u7528\u6237\u504f\u597d\u548c\u975e\u7406\u6027\u884c\u4e3a\u8005\u7406\u8bba\uff0c\u800c\u5de5\u7a0b\u5b66\u5f80\u5f80\u5ffd\u89c6\u653f\u6cbb\u56e0\u7d20\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e9b\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u52a8\u6001\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u7cfb\u7edf\u6a21\u578b\uff0c\u6574\u5408\u653f\u6cbb\u7ecf\u6d4e\u5b66\u3001\u793e\u4f1a\u751f\u6001\u7cfb\u7edf\u548c\u653f\u6cbb\u5fc3\u7406\u5b66\u7406\u8bba\uff0c\u5206\u6790\u9009\u4e3e\u5468\u671f\u3001\u610f\u8bc6\u5f62\u6001\u654f\u611f\u6027\u7b49\u653f\u6cbb\u8fc7\u7a0b\u7279\u5f81\u7684\u5f71\u54cd\u3002", "result": "\u7528\u6237\u8d39\u7528\u4e0b\u4e0d\u5e73\u7b49\u4f1a\u964d\u4f4e\u7a33\u5065\u6027\uff1b\u5bf9\u79c1\u4eba\u57fa\u7840\u8bbe\u65bd\u4f7f\u7528\u5f81\u7a0e\u53ef\u63d0\u9ad8\u7a33\u5065\u6027\uff08\u5982\u679c\u975e\u7cbe\u82f1\u6709\u5e73\u7b49\u653f\u6cbb\u5f71\u54cd\u529b\uff09\uff1b\u9009\u4e3e\u5468\u671f\u5bf9\u7a33\u5065\u6027\u6709\u975e\u7ebf\u6027\u5f71\u54cd\uff1b\u5019\u9009\u4eba\u7684\u610f\u8bc6\u5f62\u6001\u654f\u611f\u6027\u4e0e\u7a33\u5065\u6027\u5448\u8d1f\u76f8\u5173\u3002", "conclusion": "\u9009\u6c11\u548c\u5019\u9009\u4eba\u7684\u504f\u89c1\uff08\u652f\u6301\u589e\u7a0e\u6216\u51cf\u7a0e\uff09\u8c03\u8282\u4e86\u8fd9\u4e9b\u653f\u6cbb\u7ecf\u6d4e\u6548\u5e94\u5bf9\u7a33\u5065\u6027\u7684\u5f71\u54cd\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u504f\u89c1\u53ef\u80fd\u4e0e\u7cfb\u7edf\u5b9e\u9645\u9700\u6c42\uff08\u662f\u5426\u9700\u8981\u589e\u7a0e\u6765\u6062\u590d\u7cfb\u7edf\uff09\u4e0d\u5339\u914d\u3002"}}
{"id": "2510.22750", "categories": ["econ.TH"], "pdf": "https://arxiv.org/pdf/2510.22750", "abs": "https://arxiv.org/abs/2510.22750", "authors": ["Kaibalyapati Mishra"], "title": "Information-Credible Stability in Matching with Incomplete Information", "comment": null, "summary": "In this paper, I develop a refinement of stability for matching markets with\nincomplete information. I introduce Information-Credible Pairwise Stability\n(ICPS), a solution concept in which deviating pairs can use credible, costly\ntests to reveal match-relevant information before deciding whether to block. By\nleveraging the option value of information, ICPS strictly refines Bayesian\nstability, rules out fear-driven matchings, and connects belief-based and\ninformation-based notions of stability. ICPS collapses to Bayesian stability\nwhen testing is uninformative or infeasible and coincides with\ncomplete-information stability when testing is perfect and free. I show that\nany ICPS-blocking deviation strictly increases total expected surplus, ensuring\nwelfare improvement. I also prove that ICPS-stable allocations always exist,\npromote positive assortative matching, and are unique when the test power is\nsufficiently strong. The framework extends to settings with non-transferable\nutility, correlated types, and endogenous or sequential testing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4fe1\u606f\u53ef\u4fe1\u914d\u5bf9\u7a33\u5b9a\u6027\uff08ICPS\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u5728\u4e0d\u5b8c\u5168\u4fe1\u606f\u5339\u914d\u5e02\u573a\u4e2d\u7684\u7a33\u5b9a\u6027\u6982\u5ff5\uff0c\u5141\u8bb8\u914d\u5bf9\u53cc\u65b9\u901a\u8fc7\u53ef\u4fe1\u7684\u3001\u6709\u6210\u672c\u7684\u6d4b\u8bd5\u6765\u63ed\u793a\u5339\u914d\u76f8\u5173\u4fe1\u606f\uff0c\u7136\u540e\u51b3\u5b9a\u662f\u5426\u963b\u6b62\u5339\u914d\u3002", "motivation": "\u5728\u4e0d\u5b8c\u5168\u4fe1\u606f\u5339\u914d\u5e02\u573a\u4e2d\uff0c\u4f20\u7edf\u8d1d\u53f6\u65af\u7a33\u5b9a\u6027\u65e0\u6cd5\u6392\u9664\u7531\u6050\u60e7\u9a71\u52a8\u7684\u5339\u914d\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5229\u7528\u4fe1\u606f\u9009\u62e9\u4ef7\u503c\u6765\u7cbe\u70bc\u7a33\u5b9a\u6027\u7684\u6982\u5ff5\u3002", "method": "\u5f15\u5165ICPS\u6982\u5ff5\uff0c\u5141\u8bb8\u914d\u5bf9\u53cc\u65b9\u5728\u51b3\u5b9a\u662f\u5426\u963b\u6b62\u5339\u914d\u524d\u8fdb\u884c\u53ef\u4fe1\u7684\u3001\u6709\u6210\u672c\u7684\u6d4b\u8bd5\u6765\u83b7\u53d6\u76f8\u5173\u4fe1\u606f\uff0c\u901a\u8fc7\u4fe1\u606f\u7684\u671f\u6743\u4ef7\u503c\u6765\u7cbe\u70bc\u8d1d\u53f6\u65af\u7a33\u5b9a\u6027\u3002", "result": "ICPS\u4e25\u683c\u7cbe\u70bc\u4e86\u8d1d\u53f6\u65af\u7a33\u5b9a\u6027\uff0c\u6392\u9664\u4e86\u6050\u60e7\u9a71\u52a8\u7684\u5339\u914d\uff0c\u4efb\u4f55ICPS\u963b\u6b62\u504f\u5dee\u90fd\u4f1a\u4e25\u683c\u589e\u52a0\u603b\u671f\u671b\u5269\u4f59\uff0cICPS\u7a33\u5b9a\u5206\u914d\u603b\u662f\u5b58\u5728\uff0c\u4fc3\u8fdb\u6b63\u5411\u5206\u7c7b\u5339\u914d\uff0c\u4e14\u5728\u6d4b\u8bd5\u80fd\u529b\u8db3\u591f\u5f3a\u65f6\u5177\u6709\u552f\u4e00\u6027\u3002", "conclusion": "ICPS\u8fde\u63a5\u4e86\u57fa\u4e8e\u4fe1\u5ff5\u548c\u57fa\u4e8e\u4fe1\u606f\u7684\u7a33\u5b9a\u6027\u6982\u5ff5\uff0c\u5f53\u6d4b\u8bd5\u65e0\u4fe1\u606f\u6216\u4e0d\u53ef\u884c\u65f6\u9000\u5316\u4e3a\u8d1d\u53f6\u65af\u7a33\u5b9a\u6027\uff0c\u5f53\u6d4b\u8bd5\u5b8c\u7f8e\u4e14\u514d\u8d39\u65f6\u7b49\u540c\u4e8e\u5b8c\u5168\u4fe1\u606f\u7a33\u5b9a\u6027\uff0c\u53ef\u6269\u5c55\u5230\u4e0d\u53ef\u8f6c\u79fb\u6548\u7528\u3001\u76f8\u5173\u7c7b\u578b\u548c\u5185\u751f\u6216\u987a\u5e8f\u6d4b\u8bd5\u7b49\u573a\u666f\u3002"}}
{"id": "2510.21959", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.21959", "abs": "https://arxiv.org/abs/2510.21959", "authors": ["Eduard Br\u00fcll", "Samuel M\u00e4urer", "Davud Rostam-Afschar"], "title": "Beliefs about Bots: How Employers Plan for AI in White-Collar Work", "comment": null, "summary": "We provide experimental evidence on how employers adjust expectations to\nautomation risk in high-skill, white-collar work. Using a randomized\ninformation intervention among tax advisors in Germany, we show that firms\nsystematically underestimate automatability. Information provision raises risk\nperceptions, especially for routine-intensive roles. Yet, it leaves short-run\nhiring plans unchanged. Instead, updated beliefs increase productivity and\nfinancial expectations with minor wage adjustments, implying within-firm\ninequality like limited rent-sharing. Employers also anticipate new tasks in\nlegal tech, compliance, and AI interaction, and report higher training and\nadoption intentions.", "AI": {"tldr": "\u901a\u8fc7\u968f\u673a\u4fe1\u606f\u5e72\u9884\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5fb7\u56fd\u7a0e\u52a1\u987e\u95ee\u516c\u53f8\u666e\u904d\u4f4e\u4f30\u4e86\u5de5\u4f5c\u7684\u81ea\u52a8\u5316\u98ce\u9669\u3002\u63d0\u4f9b\u81ea\u52a8\u5316\u98ce\u9669\u4fe1\u606f\u4f1a\u63d0\u9ad8\u98ce\u9669\u8ba4\u77e5\uff0c\u4f46\u77ed\u671f\u5185\u4e0d\u5f71\u54cd\u62db\u8058\u8ba1\u5212\uff0c\u800c\u662f\u63d0\u5347\u751f\u4ea7\u7387\u548c\u8d22\u52a1\u9884\u671f\uff0c\u540c\u65f6\u5bfc\u81f4\u6709\u9650\u7684\u5de5\u8d44\u8c03\u6574\u548c\u5185\u90e8\u4e0d\u5e73\u7b49\u3002", "motivation": "\u7814\u7a76\u9ad8\u6280\u80fd\u767d\u9886\u5de5\u4f5c\u4e2d\u96c7\u4e3b\u5982\u4f55\u5e94\u5bf9\u81ea\u52a8\u5316\u98ce\u9669\uff0c\u7279\u522b\u662f\u4ed6\u4eec\u662f\u5426\u51c6\u786e\u8bc4\u4f30\u81ea\u52a8\u5316\u98ce\u9669\u4ee5\u53ca\u4fe1\u606f\u5e72\u9884\u5982\u4f55\u5f71\u54cd\u5176\u51b3\u7b56\u3002", "method": "\u5728\u5fb7\u56fd\u7a0e\u52a1\u987e\u95ee\u4e2d\u8fdb\u884c\u968f\u673a\u4fe1\u606f\u5e72\u9884\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u63a5\u53d7\u81ea\u52a8\u5316\u98ce\u9669\u4fe1\u606f\u4e0e\u672a\u63a5\u53d7\u4fe1\u606f\u7684\u516c\u53f8\u7684\u53cd\u5e94\u5dee\u5f02\u3002", "result": "\u4fe1\u606f\u63d0\u4f9b\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u81ea\u52a8\u5316\u98ce\u9669\u7684\u8ba4\u77e5\uff0c\u7279\u522b\u662f\u5bf9\u5e38\u89c4\u5bc6\u96c6\u578b\u5c97\u4f4d\uff1b\u77ed\u671f\u5185\u62db\u8058\u8ba1\u5212\u4e0d\u53d8\uff0c\u4f46\u63d0\u9ad8\u4e86\u751f\u4ea7\u7387\u548c\u8d22\u52a1\u9884\u671f\uff0c\u5de5\u8d44\u8c03\u6574\u6709\u9650\uff1b\u96c7\u4e3b\u9884\u671f\u5728\u6cd5\u5f8b\u79d1\u6280\u3001\u5408\u89c4\u548cAI\u4ea4\u4e92\u65b9\u9762\u4f1a\u51fa\u73b0\u65b0\u4efb\u52a1\uff0c\u57f9\u8bad\u548c\u6280\u672f\u91c7\u7528\u610f\u613f\u589e\u5f3a\u3002", "conclusion": "\u96c7\u4e3b\u5bf9\u81ea\u52a8\u5316\u98ce\u9669\u5b58\u5728\u7cfb\u7edf\u6027\u4f4e\u4f30\uff0c\u4fe1\u606f\u5e72\u9884\u80fd\u66f4\u65b0\u5176\u4fe1\u5ff5\uff0c\u4e3b\u8981\u5f71\u54cd\u751f\u4ea7\u9884\u671f\u800c\u975e\u62db\u8058\u51b3\u7b56\uff0c\u53ef\u80fd\u5bfc\u81f4\u4f01\u4e1a\u5185\u90e8\u4e0d\u5e73\u7b49\u52a0\u5267\uff0c\u540c\u65f6\u63a8\u52a8\u5bf9\u65b0\u6280\u80fd\u548c\u6280\u672f\u7684\u6295\u8d44\u3002"}}
{"id": "2510.21837", "categories": ["cs.ET", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21837", "abs": "https://arxiv.org/abs/2510.21837", "authors": ["Rohan Senthil", "Swee Liang Wong"], "title": "Quantum Autoencoders for Anomaly Detection in Cybersecurity", "comment": null, "summary": "Anomaly detection in cybersecurity is a challenging task, where normal events\nfar outnumber anomalous ones with new anomalies occurring frequently. Classical\nautoencoders have been used for anomaly detection, but struggles in\ndata-limited settings which quantum counterparts can potentially overcome. In\nthis work, we apply Quantum Autoencoders (QAEs) for anomaly detection in\ncybersecurity, specifically on the BPF-extended tracking honeypot (BETH)\ndataset. QAEs are evaluated across multiple encoding techniques, ansatz types,\nrepetitions, and feature selection strategies. Our results demonstrate that an\n8-feature QAE using Dense-Angle encoding with a RealAmplitude ansatz can\noutperform Classical Autoencoders (CAEs), even when trained on substantially\nfewer samples. The effects of quantum encoding and feature selection for\ndeveloping quantum models are demonstrated and discussed. In a data-limited\nsetting, the best performing QAE model has a F1 score of 0.87, better than that\nof CAE (0.77). These findings suggest that QAEs may offer practical advantages\nfor anomaly detection in data-limited scenarios.", "AI": {"tldr": "\u91cf\u5b50\u81ea\u7f16\u7801\u5668\u5728\u7f51\u7edc\u5b89\u5168\u5f02\u5e38\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u7ecf\u5178\u81ea\u7f16\u7801\u5668\u3002", "motivation": "\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u9762\u4e34\u6b63\u5e38\u4e8b\u4ef6\u8fdc\u591a\u4e8e\u5f02\u5e38\u4e8b\u4ef6\u4e14\u65b0\u5f02\u5e38\u9891\u7e41\u51fa\u73b0\u7684\u6311\u6218\uff0c\u7ecf\u5178\u81ea\u7f16\u7801\u5668\u5728\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u91cf\u5b50\u81ea\u7f16\u7801\u5668\u6709\u671b\u514b\u670d\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u4f7f\u7528\u91cf\u5b50\u81ea\u7f16\u7801\u5668\u5728BPF\u6269\u5c55\u8ddf\u8e2a\u871c\u7f50\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u7f16\u7801\u6280\u672f\u3001ansatz\u7c7b\u578b\u3001\u91cd\u590d\u6b21\u6570\u548c\u7279\u5f81\u9009\u62e9\u7b56\u7565\u3002", "result": "8\u7279\u5f81\u91cf\u5b50\u81ea\u7f16\u7801\u5668\u4f7f\u7528Dense-Angle\u7f16\u7801\u548cRealAmplitude ansatz\uff0c\u5728\u6570\u636e\u6709\u9650\u60c5\u51b5\u4e0bF1\u5206\u6570\u8fbe\u52300.87\uff0c\u4f18\u4e8e\u7ecf\u5178\u81ea\u7f16\u7801\u5668\u76840.77\u3002", "conclusion": "\u91cf\u5b50\u81ea\u7f16\u7801\u5668\u5728\u6570\u636e\u6709\u9650\u573a\u666f\u4e0b\u7684\u5f02\u5e38\u68c0\u6d4b\u5177\u6709\u5b9e\u9645\u4f18\u52bf\uff0c\u91cf\u5b50\u7f16\u7801\u548c\u7279\u5f81\u9009\u62e9\u5bf9\u91cf\u5b50\u6a21\u578b\u5f00\u53d1\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2510.22347", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.22347", "abs": "https://arxiv.org/abs/2510.22347", "authors": ["Ertian Chen"], "title": "Distributionally Robust Dynamic Structural Estimation: Serial Dependence and Sensitivity Analysis", "comment": null, "summary": "Distributional assumptions that discipline serially correlated latent\nvariables play a central role in dynamic structural models. We propose a\nframework to quantify the sensitivity of scalar parameters of interest (e.g.,\nwelfare, elasticity) to such distributional assumptions. We derive bounds on\nthe scalar parameter by perturbing a reference distribution, while imposing a\nstationarity condition for time-homogeneous models or a Markovian condition for\ntime-inhomogeneous models. The bounds are the solutions to optimization\nproblems, for which we derive a computationally tractable dual formulation. We\nestablish consistency, convergence rate, and asymptotic distribution for the\nestimator of the bounds. We demonstrate the approach with two applications: an\ninfinite-horizon dynamic demand model for new cars in the United Kingdom,\nGermany, and France, and a finite-horizon dynamic labor supply model for taxi\ndrivers in New York City. In the car application, perturbed price elasticities\ndeviate by at most 15.24% from the reference elasticities, while perturbed\nestimates of consumer surplus from an additional $3,000 electric vehicle\nsubsidy vary by up to 102.75%. In the labor supply application, the perturbed\nFrisch labor supply elasticity deviates by at most 76.83% for weekday drivers\nand 42.84% for weekend drivers.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u91cf\u5316\u52a8\u6001\u7ed3\u6784\u6a21\u578b\u4e2d\u53c2\u6570\u5bf9\u5206\u5e03\u5047\u8bbe\u654f\u611f\u6027\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6270\u52a8\u53c2\u8003\u5206\u5e03\u6765\u83b7\u5f97\u53c2\u6570\u8fb9\u754c\uff0c\u5e76\u5728\u6c7d\u8f66\u9700\u6c42\u548c\u52b3\u52a8\u529b\u4f9b\u7ed9\u4e24\u4e2a\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u52a8\u6001\u7ed3\u6784\u6a21\u578b\u4e2d\u5e8f\u5217\u76f8\u5173\u6f5c\u53d8\u91cf\u7684\u5206\u5e03\u5047\u8bbe\u5bf9\u53c2\u6570\u4f30\u8ba1\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u91cf\u5316\u8fd9\u4e9b\u5206\u5e03\u5047\u8bbe\u5bf9\u5173\u952e\u53c2\u6570\uff08\u5982\u798f\u5229\u3001\u5f39\u6027\uff09\u7684\u5f71\u54cd\u7a0b\u5ea6\u3002", "method": "\u901a\u8fc7\u6270\u52a8\u53c2\u8003\u5206\u5e03\u5e76\u65bd\u52a0\u5e73\u7a33\u6027\u6761\u4ef6\uff08\u65f6\u95f4\u9f50\u6b21\u6a21\u578b\uff09\u6216\u9a6c\u5c14\u53ef\u592b\u6761\u4ef6\uff08\u65f6\u95f4\u975e\u9f50\u6b21\u6a21\u578b\uff09\u6765\u63a8\u5bfc\u53c2\u6570\u8fb9\u754c\uff0c\u5efa\u7acb\u4e86\u8ba1\u7b97\u53ef\u884c\u7684\u5bf9\u5076\u516c\u5f0f\u5316\u65b9\u6cd5\u3002", "result": "\u5728\u6c7d\u8f66\u9700\u6c42\u5e94\u7528\u4e2d\uff0c\u6270\u52a8\u4ef7\u683c\u5f39\u6027\u6700\u591a\u504f\u79bb\u53c2\u8003\u5f39\u602715.24%\uff0c\u800c\u7535\u52a8\u6c7d\u8f66\u8865\u8d34\u7684\u6d88\u8d39\u8005\u5269\u4f59\u4f30\u8ba1\u53d8\u5316\u9ad8\u8fbe102.75%\uff1b\u5728\u52b3\u52a8\u529b\u4f9b\u7ed9\u5e94\u7528\u4e2d\uff0cFrisch\u52b3\u52a8\u4f9b\u7ed9\u5f39\u6027\u6700\u591a\u504f\u79bb76.83%\uff08\u5de5\u4f5c\u65e5\uff09\u548c42.84%\uff08\u5468\u672b\uff09\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u91cf\u5316\u52a8\u6001\u7ed3\u6784\u6a21\u578b\u53c2\u6570\u5bf9\u5206\u5e03\u5047\u8bbe\u7684\u654f\u611f\u6027\uff0c\u4e3a\u6a21\u578b\u7a33\u5065\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2510.21911", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21911", "abs": "https://arxiv.org/abs/2510.21911", "authors": ["Marko Ore\u0161kovi\u0107", "Ivana Kuzmanovi\u0107 Ivi\u010di\u0107", "Juraj Beni\u0107", "Mario Essert"], "title": "A Perspective on the Algebra, Topology, and Logic of Electrical Networks", "comment": null, "summary": "This paper presents a unified algebraic, topological, and logical framework\nfor electrical one-port networks based on \\v{S}are's $m$-theory. Within this\nformalism, networks are represented by $m$-words (jorbs) over an ordered\nalphabet, where series and parallel composition induce an $m$-topology on\n$m$-graphs with a theta mapping $\\vartheta$ that preserves one-port\nequivalence. The study formalizes quasi-orders, shells, and cores, showing\ntheir structural correspondence to network boundary conditions and impedance\nbehavior. The $\\lambda--\\Delta$ metric, together with the valuation morphism\n$\\Phi$, provides a concise descriptor of the impedance-degree structure. In the\ncomputational domain, the framework is extended with algorithmic procedures for\ngenerating and classifying non-isomorphic series-parallel topologies,\naccompanied by programmatic Cauer/Foster synthesis workflows and validation\nagainst canonical examples from Ladenheim's catalogue. The resulting approach\nenables symbolic-to-topological translation of impedance functions, offering a\nconstructive bridge between algebraic representation and electrical\nrealization. Overall, the paper outlines a self-consistent theoretical and\ncomputational foundation for automated network synthesis, classification, and\nformal verification within the emerging field of Jorbology.", "AI": {"tldr": "\u57fa\u4e8e\u0160are\u7684m\u7406\u8bba\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u4ee3\u6570\u3001\u62d3\u6251\u548c\u903b\u8f91\u6846\u67b6\u6765\u8868\u793a\u7535\u6c14\u5355\u7aef\u53e3\u7f51\u7edc\uff0c\u5c06\u7f51\u7edc\u8868\u793a\u4e3a\u6709\u5e8f\u5b57\u6bcd\u8868\u4e0a\u7684m-\u8bcd\uff0c\u901a\u8fc7\u7cfb\u5217\u548c\u5e76\u884c\u7ec4\u5408\u5728m-\u56fe\u4e0a\u8bf1\u5bfcm-\u62d3\u6251\uff0c\u5e76\u5f00\u53d1\u4e86\u7b97\u6cd5\u7a0b\u5e8f\u7528\u4e8e\u751f\u6210\u548c\u5206\u7c7b\u975e\u540c\u6784\u7684\u4e32\u5e76\u8054\u62d3\u6251\u3002", "motivation": "\u4e3a\u7535\u6c14\u5355\u7aef\u53e3\u7f51\u7edc\u5efa\u7acb\u4e00\u4e2a\u81ea\u6d3d\u7684\u7406\u8bba\u548c\u8ba1\u7b97\u57fa\u7840\uff0c\u5b9e\u73b0\u81ea\u52a8\u7f51\u7edc\u5408\u6210\u3001\u5206\u7c7b\u548c\u5f62\u5f0f\u9a8c\u8bc1\uff0c\u5728\u4ee3\u6570\u8868\u793a\u548c\u7535\u6c14\u5b9e\u73b0\u4e4b\u95f4\u5efa\u7acb\u5efa\u8bbe\u6027\u6865\u6881\u3002", "method": "\u4f7f\u7528m-\u8bcd\u8868\u793a\u7f51\u7edc\uff0c\u901a\u8fc7\u7cfb\u5217\u548c\u5e76\u884c\u7ec4\u5408\u5728m-\u56fe\u4e0a\u8bf1\u5bfcm-\u62d3\u6251\uff0c\u5f15\u5165theta\u6620\u5c04\u4fdd\u6301\u5355\u7aef\u53e3\u7b49\u4ef7\u6027\uff0c\u5e76\u6269\u5c55\u7b97\u6cd5\u7a0b\u5e8f\u7528\u4e8e\u751f\u6210\u548c\u5206\u7c7b\u975e\u540c\u6784\u7684\u4e32\u5e76\u8054\u62d3\u6251\u3002", "result": "\u5f00\u53d1\u4e86\u7a0b\u5e8f\u5316\u7684Cauer/Foster\u5408\u6210\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5e76\u9488\u5bf9Ladenheim\u76ee\u5f55\u4e2d\u7684\u89c4\u8303\u793a\u4f8b\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u4e86\u963b\u6297\u51fd\u6570\u7684\u7b26\u53f7\u5230\u62d3\u6251\u8f6c\u6362\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u65b0\u5174\u7684Jorbology\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u81ea\u6d3d\u7684\u7406\u8bba\u548c\u8ba1\u7b97\u57fa\u7840\uff0c\u652f\u6301\u81ea\u52a8\u7f51\u7edc\u5408\u6210\u3001\u5206\u7c7b\u548c\u5f62\u5f0f\u9a8c\u8bc1\u3002"}}
{"id": "2510.22080", "categories": ["stat.AP", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.22080", "abs": "https://arxiv.org/abs/2510.22080", "authors": ["Emma Von Hoene", "Aanya Gupta", "Hamdi Kavak", "Amira Roess", "Taylor Anderson"], "title": "Evaluation of A Spatial Microsimulation Framework for Small-Area Estimation of Population Health Outcomes Using the Behavioral Risk Factor Surveillance System", "comment": null, "summary": "This study introduces the Spatial Health and Population Estimator (SHAPE), a\nspatial microsimulation framework that applies hierarchical iterative\nproportional fitting (IPF) to estimate two health risk behaviors and eleven\nhealth outcomes across multiple spatial scales. SHAPE was evaluated using\ncounty-level direct estimates from the Behavioral Risk Factor Surveillance\nSystem (BRFSS) and both county and census tract level data from CDC PLACES for\nNew York (2021) and Florida (2019). Results show that SHAPE's SAEs are\nmoderately consistent with BRFSS (average Pearson's correlation coefficient r\nof about 0.5), similar to CDC PLACES (average r of about 0.6), and are strongly\naligned with CDC PLACES model-based estimates at both county (average r of\nabout 0.8) and census tract (average r of about 0.7) levels. SHAPE is an open,\nreproducible, and transparent framework programmed in R that meets a need for\naccessible SAE methods in public health.", "AI": {"tldr": "SHAPE\u662f\u4e00\u4e2a\u7a7a\u95f4\u5fae\u89c2\u6a21\u62df\u6846\u67b6\uff0c\u4f7f\u7528\u5206\u5c42\u8fed\u4ee3\u6bd4\u4f8b\u62df\u5408\u65b9\u6cd5\u4f30\u8ba1\u5065\u5eb7\u98ce\u9669\u884c\u4e3a\u548c\u5065\u5eb7\u7ed3\u679c\uff0c\u5728\u591a\u4e2a\u7a7a\u95f4\u5c3a\u5ea6\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u6ee1\u8db3\u516c\u5171\u536b\u751f\u9886\u57df\u5bf9\u53ef\u8bbf\u95ee\u7684\u5c0f\u533a\u57df\u4f30\u8ba1\u65b9\u6cd5\u7684\u9700\u6c42\u3002", "method": "\u5e94\u7528\u5206\u5c42\u8fed\u4ee3\u6bd4\u4f8b\u62df\u5408\u7684\u7a7a\u95f4\u5fae\u89c2\u6a21\u62df\u6846\u67b6\uff0c\u4f7f\u7528BRFSS\u548cCDC PLACES\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "SHAPE\u7684\u4f30\u8ba1\u4e0eBRFSS\u4e2d\u7b49\u4e00\u81f4\uff08\u5e73\u5747r\u22480.5\uff09\uff0c\u4e0eCDC PLACES\u76f8\u4f3c\uff08\u5e73\u5747r\u22480.6\uff09\uff0c\u5728\u53bf\u548c\u4eba\u53e3\u666e\u67e5\u533a\u7ea7\u522b\u4e0eCDC PLACES\u6a21\u578b\u4f30\u8ba1\u9ad8\u5ea6\u4e00\u81f4\uff08\u5e73\u5747r\u22480.8\u548c0.7\uff09\u3002", "conclusion": "SHAPE\u662f\u4e00\u4e2a\u5f00\u653e\u3001\u53ef\u590d\u73b0\u3001\u900f\u660e\u7684R\u8bed\u8a00\u6846\u67b6\uff0c\u4e3a\u516c\u5171\u536b\u751f\u63d0\u4f9b\u4e86\u53ef\u8bbf\u95ee\u7684\u5c0f\u533a\u57df\u4f30\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2510.21732", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.21732", "abs": "https://arxiv.org/abs/2510.21732", "authors": ["Xumin Gao", "Mark Stevens", "Grzegorz Cielniak"], "title": "A Robotic Stirring Method with Trajectory Optimization and Adaptive Speed Control for Accurate Pest Counting in Water Traps", "comment": "This paper has been submitted to ICRA 2026 and is currently under\n  review", "summary": "Accurate monitoring of pest population dynamics is crucial for informed\ndecision-making in precision agriculture. Currently, mainstream image-based\npest counting methods primarily rely on image processing combined with machine\nlearning or deep learning for pest counting. However, these methods have\nlimitations and struggle to handle situations involving pest occlusion. To\naddress this issue, this paper proposed a robotic stirring method with\ntrajectory optimization and adaptive speed control for accurate pest counting\nin water traps. First, we developed an automated stirring system for pest\ncounting in yellow water traps based on a robotic arm. Stirring alters the\ndistribution of pests in the yellow water trap, making some of the occluded\nindividuals visible for detection and counting. Then, we investigated the\nimpact of different stirring trajectories on pest counting performance and\nselected the optimal trajectory for pest counting. Specifically, we designed\nsix representative stirring trajectories, including circle, square, triangle,\nspiral, four small circles, and random lines, for the robotic arm to stir. And\nby comparing the overall average counting error and counting confidence of\ndifferent stirring trajectories across various pest density scenarios, we\ndetermined the optimal trajectory. Finally, we proposed a counting\nconfidence-driven closed-loop control system to achieve adaptive-speed\nstirring. It uses changes in pest counting confidence between consecutive\nframes as feedback to adjust the stirring speed. To the best of our knowledge,\nthis is the first study dedicated to investigating the effects of different\nstirring trajectories on object counting in the dynamic liquid environment and\nto implement adaptive-speed stirring for this type of task. Experimental\nresults show ...", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u673a\u5668\u4eba\u6405\u62cc\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f68\u8ff9\u4f18\u5316\u548c\u81ea\u9002\u5e94\u901f\u5ea6\u63a7\u5236\u6765\u89e3\u51b3\u6c34\u9677\u9631\u4e2d\u5bb3\u866b\u906e\u6321\u95ee\u9898\uff0c\u5b9e\u73b0\u51c6\u786e\u7684\u5bb3\u866b\u8ba1\u6570\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u56fe\u50cf\u7684\u5bb3\u866b\u8ba1\u6570\u65b9\u6cd5\u5728\u5904\u7406\u5bb3\u866b\u906e\u6321\u60c5\u51b5\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6539\u53d8\u5bb3\u866b\u5206\u5e03\u3001\u4f7f\u88ab\u906e\u6321\u4e2a\u4f53\u53ef\u89c1\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u673a\u68b0\u81c2\u7684\u81ea\u52a8\u6405\u62cc\u7cfb\u7edf\uff0c\u8bbe\u8ba1\u4e86\u516d\u79cd\u4ee3\u8868\u6027\u6405\u62cc\u8f68\u8ff9\uff0c\u901a\u8fc7\u6bd4\u8f83\u8ba1\u6570\u8bef\u5dee\u548c\u7f6e\u4fe1\u5ea6\u9009\u62e9\u6700\u4f18\u8f68\u8ff9\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u8ba1\u6570\u7f6e\u4fe1\u5ea6\u7684\u95ed\u73af\u63a7\u5236\u7cfb\u7edf\u5b9e\u73b0\u81ea\u9002\u5e94\u901f\u5ea6\u6405\u62cc\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u5bb3\u866b\u906e\u6321\u95ee\u9898\uff0c\u63d0\u9ad8\u8ba1\u6570\u51c6\u786e\u6027\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u7814\u7a76\u52a8\u6001\u6db2\u4f53\u73af\u5883\u4e2d\u4e0d\u540c\u6405\u62cc\u8f68\u8ff9\u5bf9\u7269\u4f53\u8ba1\u6570\u5f71\u54cd\u7684\u5de5\u4f5c\uff0c\u81ea\u9002\u5e94\u901f\u5ea6\u6405\u62cc\u65b9\u6cd5\u4e3a\u7c7b\u4f3c\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.21832", "categories": ["cs.CY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.21832", "abs": "https://arxiv.org/abs/2510.21832", "authors": ["Yuanxi Li", "Lei Yin"], "title": "Quantifying the AI Gap: A Comparative Index of Development in the United States and Chinese Regions", "comment": null, "summary": "This study develops a comprehensive Artificial Intelligence (AI) Index with\nseven primary dimensions, designed for provincial-level and industry-specific\nanalysis. We employ an anchor point method for data normalization, using fixed\nupper and lower bounds as benchmarks, and devise a hierarchical indicator\nweighting system that combines expert judgment with objective data. The index\ndraws from authoritative data sources across domains including official\nstatistics, patents and research outputs, education and talent, industrial\neconomy, policy and governance, and social impact. The China-US comparison\nindicates that under a unified framework, the US composite score (68.1) exceeds\nChina's (59.4). We further dissect China into seven main areas to form a\nsub-national index. The findings reveal stark regional disparities in China's\nAI development: the North, East, and South regions lead in composite scores,\nwhereas central and western regions lag significantly, underscoring the effects\nof regional concentration of innovation and industry resources. This research\nprovides an academic reference and decision support tool for government\nagencies and research institutions, informing more targeted regional AI\ndevelopment strategies.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u5305\u542b\u4e03\u4e2a\u7ef4\u5ea6\u7684\u7efc\u5408AI\u6307\u6570\uff0c\u7528\u4e8e\u7701\u7ea7\u548c\u884c\u4e1a\u5206\u6790\u3002\u4e2d\u7f8e\u6bd4\u8f83\u663e\u793a\u7f8e\u56fd\u5f97\u5206(68.1)\u9ad8\u4e8e\u4e2d\u56fd(59.4)\uff0c\u4e2d\u56fd\u5185\u90e8\u5448\u73b0\u660e\u663e\u7684\u533a\u57df\u53d1\u5c55\u4e0d\u5e73\u8861\u3002", "motivation": "\u4e3a\u653f\u5e9c\u673a\u6784\u548c\u7814\u7a76\u673a\u6784\u63d0\u4f9b\u5b66\u672f\u53c2\u8003\u548c\u51b3\u7b56\u652f\u6301\u5de5\u5177\uff0c\u5e2e\u52a9\u5236\u5b9a\u66f4\u6709\u9488\u5bf9\u6027\u7684\u533a\u57dfAI\u53d1\u5c55\u6218\u7565\u3002", "method": "\u91c7\u7528\u951a\u70b9\u6cd5\u8fdb\u884c\u6570\u636e\u6807\u51c6\u5316\uff0c\u4f7f\u7528\u56fa\u5b9a\u4e0a\u4e0b\u9650\u4f5c\u4e3a\u57fa\u51c6\uff0c\u8bbe\u8ba1\u7ed3\u5408\u4e13\u5bb6\u5224\u65ad\u4e0e\u5ba2\u89c2\u6570\u636e\u7684\u5c42\u6b21\u5316\u6307\u6807\u6743\u91cd\u7cfb\u7edf\uff0c\u6570\u636e\u6765\u6e90\u4e8e\u6743\u5a01\u7edf\u8ba1\u3001\u4e13\u5229\u3001\u6559\u80b2\u7b49\u591a\u4e2a\u9886\u57df\u3002", "result": "\u7f8e\u56fd\u7efc\u5408\u5f97\u520668.1\u9ad8\u4e8e\u4e2d\u56fd\u768459.4\uff1b\u4e2d\u56fd\u5185\u90e8\u5317\u65b9\u3001\u4e1c\u90e8\u548c\u5357\u90e8\u5730\u533a\u9886\u5148\uff0c\u4e2d\u90e8\u548c\u897f\u90e8\u5730\u533a\u663e\u8457\u843d\u540e\uff0c\u53cd\u6620\u4e86\u521b\u65b0\u548c\u4ea7\u4e1a\u8d44\u6e90\u7684\u533a\u57df\u96c6\u4e2d\u6548\u5e94\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684AI\u53d1\u5c55\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u4e2d\u7f8e\u5dee\u8ddd\u548c\u4e2d\u56fd\u5185\u90e8\u7684\u533a\u57df\u4e0d\u5e73\u8861\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2510.21720", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21720", "abs": "https://arxiv.org/abs/2510.21720", "authors": ["Anant Pareek"], "title": "A Multi-Component AI Framework for Computational Psychology: From Robust Predictive Modeling to Deployed Generative Dialogue", "comment": null, "summary": "The confluence of Artificial Intelligence and Computational Psychology\npresents an opportunity to model, understand, and interact with complex human\npsychological states through computational means. This paper presents a\ncomprehensive, multi-faceted framework designed to bridge the gap between\nisolated predictive modeling and an interactive system for psychological\nanalysis. The methodology encompasses a rigorous, end-to-end development\nlifecycle. First, foundational performance benchmarks were established on four\ndiverse psychological datasets using classical machine learning techniques.\nSecond, state-of-the-art transformer models were fine-tuned, a process that\nnecessitated the development of effective solutions to overcome critical\nengineering challenges, including the resolution of numerical instability in\nregression tasks and the creation of a systematic workflow for conducting\nlarge-scale training under severe resource constraints. Third, a generative\nlarge language model (LLM) was fine-tuned using parameter-efficient techniques\nto function as an interactive \"Personality Brain.\" Finally, the entire suite of\npredictive and generative models was architected and deployed as a robust,\nscalable microservices ecosystem. Key findings include the successful\nstabilization of transformer-based regression models for affective computing,\nshowing meaningful predictive performance where standard approaches failed, and\nthe development of a replicable methodology for democratizing large-scale AI\nresearch. The significance of this work lies in its holistic approach,\ndemonstrating a complete research-to-deployment pipeline that integrates\npredictive analysis with generative dialogue, thereby providing a practical\nmodel for future research in computational psychology and human-AI interaction.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408AI\u4e0e\u8ba1\u7b97\u5fc3\u7406\u5b66\u7684\u7efc\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u5f00\u53d1\u6d41\u7a0b\u6784\u5efa\u4e86\u4ece\u9884\u6d4b\u5efa\u6a21\u5230\u4ea4\u4e92\u5f0f\u5fc3\u7406\u5206\u6790\u7684\u7cfb\u7edf\uff0c\u5305\u62ec\u57fa\u51c6\u6d4b\u8bd5\u3001Transformer\u6a21\u578b\u5fae\u8c03\u3001\u751f\u6210\u5f0fLLM\u5f00\u53d1\u4ee5\u53ca\u5fae\u670d\u52a1\u90e8\u7f72\u3002", "motivation": "\u5f25\u5408\u5b64\u7acb\u9884\u6d4b\u5efa\u6a21\u4e0e\u4ea4\u4e92\u5f0f\u5fc3\u7406\u5206\u6790\u7cfb\u7edf\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u8ba1\u7b97\u5fc3\u7406\u5b66\u548c\u4eba\u7c7b-AI\u4ea4\u4e92\u63d0\u4f9b\u5b8c\u6574\u7684\u7814\u7a76\u5230\u90e8\u7f72\u7ba1\u9053\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u5728\u56db\u4e2a\u5fc3\u7406\u5b66\u6570\u636e\u96c6\u4e0a\u5efa\u7acb\u57fa\u51c6\u6027\u80fd\uff1b2) \u5fae\u8c03Transformer\u6a21\u578b\u5e76\u89e3\u51b3\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\u548c\u8d44\u6e90\u9650\u5236\u95ee\u9898\uff1b3) \u4f7f\u7528\u53c2\u6570\u9ad8\u6548\u6280\u672f\u5fae\u8c03\u751f\u6210\u5f0fLLM\u4f5c\u4e3a\u4ea4\u4e92\u5f0f\"\u4eba\u683c\u5927\u8111\"\uff1b4) \u5c06\u9884\u6d4b\u548c\u751f\u6210\u6a21\u578b\u6784\u5efa\u4e3a\u53ef\u6269\u5c55\u7684\u5fae\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u3002", "result": "\u6210\u529f\u7a33\u5b9a\u4e86\u57fa\u4e8eTransformer\u7684\u60c5\u611f\u8ba1\u7b97\u56de\u5f52\u6a21\u578b\uff0c\u5728\u6807\u51c6\u65b9\u6cd5\u5931\u8d25\u7684\u60c5\u51b5\u4e0b\u663e\u793a\u51fa\u6709\u610f\u4e49\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u5f00\u53d1\u4e86\u53ef\u590d\u73b0\u7684\u5927\u89c4\u6a21AI\u7814\u7a76\u65b9\u6cd5\u8bba\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u6574\u5408\u9884\u6d4b\u5206\u6790\u4e0e\u751f\u6210\u5bf9\u8bdd\u7684\u5b8c\u6574\u7814\u7a76\u5230\u90e8\u7f72\u7ba1\u9053\uff0c\u4e3a\u8ba1\u7b97\u5fc3\u7406\u5b66\u548c\u4eba\u7c7b-AI\u4ea4\u4e92\u7684\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u6574\u4f53\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.23178", "categories": ["econ.TH", "cs.GT"], "pdf": "https://arxiv.org/pdf/2510.23178", "abs": "https://arxiv.org/abs/2510.23178", "authors": ["Sumit Goel", "Yiqing Yan", "Jeffrey Zeidel"], "title": "Feedback in Dynamic Contests: Theory and Experiment", "comment": null, "summary": "We study the effect of interim feedback policies in a dynamic all-pay auction\nwhere two players bid over two stages to win a common-value prize. We show that\nsequential equilibrium outcomes are characterized by Cheapest Signal\nEquilibria, wherein stage 1 bids are such that one player bids zero while the\nother chooses a cheapest bid consistent with some signal. Equilibrium payoffs\nfor both players are always zero, and the sum of expected total bids equals the\nvalue of the prize. We conduct an experiment with four natural feedback policy\ntreatments -- full, rank, and two cutoff policies -- and while the bidding\nbehavior deviates from equilibrium, we fail to reject the hypothesis of no\ntreatment effect on total bids. Further, stage 1 bids induce sunk costs and\nhead starts, and we test for the resulting sunk cost and discouragement effects\nin stage 2 bidding.", "AI": {"tldr": "\u7814\u7a76\u4e24\u9636\u6bb5\u52a8\u6001\u5168\u652f\u4ed8\u62cd\u5356\u4e2d\u4e2d\u671f\u53cd\u9988\u653f\u7b56\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5747\u8861\u7ed3\u679c\u7531\u6700\u5ec9\u4ef7\u4fe1\u53f7\u5747\u8861\u63cf\u8ff0\uff0c\u53cc\u65b9\u6536\u76ca\u4e3a\u96f6\uff0c\u603b\u6295\u6807\u671f\u671b\u503c\u7b49\u4e8e\u5956\u54c1\u4ef7\u503c\u3002\u5b9e\u9a8c\u663e\u793a\u6295\u6807\u884c\u4e3a\u504f\u79bb\u5747\u8861\u4f46\u53cd\u9988\u653f\u7b56\u65e0\u663e\u8457\u5f71\u54cd\u3002", "motivation": "\u63a2\u8ba8\u52a8\u6001\u5168\u652f\u4ed8\u62cd\u5356\u4e2d\u4e0d\u540c\u53cd\u9988\u653f\u7b56\u5982\u4f55\u5f71\u54cd\u6295\u6807\u884c\u4e3a\uff0c\u7279\u522b\u5173\u6ce8\u4e2d\u671f\u53cd\u9988\u5bf9\u6295\u6807\u7b56\u7565\u548c\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "method": "\u7406\u8bba\u5206\u6790\u4e24\u9636\u6bb5\u52a8\u6001\u5168\u652f\u4ed8\u62cd\u5356\u7684\u5747\u8861\u7279\u6027\uff0c\u5e76\u8fdb\u884c\u5b9e\u9a8c\u7814\u7a76\u56db\u79cd\u81ea\u7136\u53cd\u9988\u653f\u7b56\uff08\u5b8c\u5168\u53cd\u9988\u3001\u6392\u540d\u53cd\u9988\u548c\u4e24\u79cd\u622a\u65ad\u53cd\u9988\uff09\u5bf9\u6295\u6807\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "result": "\u5747\u8861\u72b6\u6001\u4e0b\u53cc\u65b9\u6536\u76ca\u4e3a\u96f6\uff0c\u603b\u6295\u6807\u671f\u671b\u7b49\u4e8e\u5956\u54c1\u4ef7\u503c\uff1b\u5b9e\u9a8c\u663e\u793a\u6295\u6807\u884c\u4e3a\u504f\u79bb\u7406\u8bba\u5747\u8861\uff0c\u4f46\u4e0d\u540c\u53cd\u9988\u653f\u7b56\u5bf9\u603b\u6295\u6807\u65e0\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u867d\u7136\u6295\u6807\u884c\u4e3a\u504f\u79bb\u7406\u8bba\u9884\u6d4b\uff0c\u4f46\u53cd\u9988\u653f\u7b56\u5bf9\u603b\u6295\u6807\u6ca1\u6709\u663e\u8457\u5f71\u54cd\uff0c\u9636\u6bb51\u6295\u6807\u4f1a\u4ea7\u751f\u6c89\u6ca1\u6210\u672c\u548c\u9886\u5148\u4f18\u52bf\uff0c\u5f71\u54cd\u9636\u6bb52\u7684\u6295\u6807\u51b3\u7b56\u3002"}}
{"id": "2510.22294", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.22294", "abs": "https://arxiv.org/abs/2510.22294", "authors": ["Jacob Adenbaum", "Fil Babalievsky", "William Jungerman"], "title": "There's Nothing in the Air", "comment": null, "summary": "Why do wages grow faster in bigger cities? We use French administrative data\nto decompose the urban wage growth premium and find that the answer has\nsurprisingly little to do with cities themselves. While we document\nsubstantially faster wage growth in larger cities, 80% of the premium\ndisappears after controlling for the composition of firms and coworkers. We\nalso document significantly higher job-to-job transition rates in larger\ncities, suggesting workers climb the job ladder faster. Most strikingly, when\nwe focus on workers who remain in the same job -- eliminating the job ladder\nmechanism -- the urban wage growth premium falls by 94.1% after accounting for\nfirms and coworkers. The residual effect is statistically indistinguishable\nfrom zero. These results challenge the view that cities generate human capital\nspillovers ``in the air,'' suggesting instead that urban wage dynamics reflect\nthe sorting of firms and workers and the pace of job mobility.", "AI": {"tldr": "\u5927\u57ce\u5e02\u5de5\u8d44\u589e\u957f\u66f4\u5feb\u4e3b\u8981\u4e0d\u662f\u56e0\u4e3a\u57ce\u5e02\u672c\u8eab\uff0c\u800c\u662f\u7531\u4e8e\u4f01\u4e1a\u548c\u540c\u4e8b\u7684\u6784\u6210\u5dee\u5f02\u4ee5\u53ca\u5de5\u4f5c\u6d41\u52a8\u6027\u66f4\u9ad8\u3002", "motivation": "\u63a2\u7a76\u4e3a\u4ec0\u4e48\u5927\u57ce\u5e02\u5de5\u8d44\u589e\u957f\u66f4\u5feb\uff0c\u6311\u6218\u4f20\u7edf\u8ba4\u4e3a\u57ce\u5e02\u4ea7\u751f\u4eba\u529b\u8d44\u672c\u6ea2\u51fa\u7684\u89c2\u70b9\u3002", "method": "\u4f7f\u7528\u6cd5\u56fd\u884c\u653f\u6570\u636e\uff0c\u901a\u8fc7\u63a7\u5236\u4f01\u4e1a\u548c\u540c\u4e8b\u6784\u6210\u6765\u5206\u6790\u57ce\u5e02\u5de5\u8d44\u589e\u957f\u6ea2\u4ef7\u3002", "result": "80%\u7684\u57ce\u5e02\u5de5\u8d44\u589e\u957f\u6ea2\u4ef7\u5728\u63a7\u5236\u4f01\u4e1a\u548c\u540c\u4e8b\u6784\u6210\u540e\u6d88\u5931\uff1b\u5f53\u5173\u6ce8\u540c\u4e00\u5de5\u4f5c\u7684\u5de5\u4eba\u65f6\uff0c94.1%\u7684\u6ea2\u4ef7\u6d88\u5931\uff0c\u5269\u4f59\u6548\u5e94\u7edf\u8ba1\u4e0a\u4e0d\u663e\u8457\u3002", "conclusion": "\u57ce\u5e02\u5de5\u8d44\u52a8\u6001\u4e3b\u8981\u53cd\u6620\u4f01\u4e1a\u548c\u5de5\u4eba\u7684\u5206\u7c7b\u4ee5\u53ca\u5de5\u4f5c\u6d41\u52a8\u901f\u5ea6\uff0c\u800c\u975e\u57ce\u5e02\u672c\u8eab\u7684\u4eba\u529b\u8d44\u672c\u6ea2\u51fa\u6548\u5e94\u3002"}}
{"id": "2510.22869", "categories": ["cs.ET", "cs.OS"], "pdf": "https://arxiv.org/pdf/2510.22869", "abs": "https://arxiv.org/abs/2510.22869", "authors": ["Rohan Kadekodi", "Haoran Peng", "Gilbert Bernstein", "Michael D. Ernst", "Baris Kasikci"], "title": "Jenga: Responsive Tiered Memory Management without Thrashing", "comment": null, "summary": "A heterogeneous memory has a single address space with fast access to some\naddresses (a fast tier of DRAM) and slow access to other addresses (a capacity\ntier of CXL-attached memory or NVM). A tiered memory system aims to maximize\nthe number of accesses to the fast tier via page migrations between the fast\nand capacity tiers. Unfortunately, previous tiered memory systems can perform\npoorly due to (1) allocating hot and cold objects in the same page and (2)\nabrupt changes in hotness measurements that lead to thrashing.\n  This paper presents Jenga, a tiered memory system that addresses both\nproblems. Jenga's memory allocator uses a novel context-based page allocation\nstrategy. Jenga's accurate measurements of page hotness enable it to react to\nmemory access behavior changes in a timely manner while avoiding thrashing.\nCompared to the best previous tiered memory system, Jenga runs memory-intensive\napplications 28% faster across 10 applications, when the fast tier capacity\nmatches the working set size, at a CPU overhead of <3% of a single core and a\nmemory overhead of <0.3%", "AI": {"tldr": "Jenga\u662f\u4e00\u4e2a\u5206\u5c42\u5185\u5b58\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u9875\u9762\u5206\u914d\u7b56\u7565\u548c\u51c6\u786e\u7684\u70ed\u5ea6\u6d4b\u91cf\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5206\u5c42\u5185\u5b58\u7cfb\u7edf\u4e2d\u70ed\u51b7\u5bf9\u8c61\u6df7\u5b58\u548c\u70ed\u5ea6\u6d4b\u91cf\u7a81\u53d8\u5bfc\u81f4\u7684\u6027\u80fd\u95ee\u9898\uff0c\u5728\u5feb\u901f\u5c42\u5bb9\u91cf\u5339\u914d\u5de5\u4f5c\u96c6\u5927\u5c0f\u65f6\uff0c\u6bd4\u4e4b\u524d\u6700\u4f73\u7cfb\u7edf\u5feb28%\u3002", "motivation": "\u4f20\u7edf\u5206\u5c42\u5185\u5b58\u7cfb\u7edf\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a(1) \u70ed\u5bf9\u8c61\u548c\u51b7\u5bf9\u8c61\u5206\u914d\u5728\u540c\u4e00\u9875\u9762\u4e2d\uff0c\u5bfc\u81f4\u9875\u9762\u8fc1\u79fb\u6548\u7387\u4f4e\u4e0b\uff1b(2) \u70ed\u5ea6\u6d4b\u91cf\u7684\u7a81\u7136\u53d8\u5316\u4f1a\u5bfc\u81f4\u7cfb\u7edf\u98a0\u7c38\uff0c\u5f71\u54cd\u6027\u80fd\u3002", "method": "Jenga\u91c7\u7528\u4e0a\u4e0b\u6587\u9875\u9762\u5206\u914d\u7b56\u7565\uff0c\u901a\u8fc7\u51c6\u786e\u6d4b\u91cf\u9875\u9762\u70ed\u5ea6\uff0c\u53ca\u65f6\u54cd\u5e94\u5185\u5b58\u8bbf\u95ee\u884c\u4e3a\u53d8\u5316\uff0c\u540c\u65f6\u907f\u514d\u7cfb\u7edf\u98a0\u7c38\u3002", "result": "\u572810\u4e2a\u5185\u5b58\u5bc6\u96c6\u578b\u5e94\u7528\u4e2d\uff0c\u5f53\u5feb\u901f\u5c42\u5bb9\u91cf\u5339\u914d\u5de5\u4f5c\u96c6\u5927\u5c0f\u65f6\uff0cJenga\u6bd4\u4e4b\u524d\u6700\u4f73\u5206\u5c42\u5185\u5b58\u7cfb\u7edf\u8fd0\u884c\u901f\u5ea6\u5feb28%\uff0cCPU\u5f00\u9500\u5c0f\u4e8e\u5355\u6838\u76843%\uff0c\u5185\u5b58\u5f00\u9500\u5c0f\u4e8e0.3%\u3002", "conclusion": "Jenga\u901a\u8fc7\u6539\u8fdb\u7684\u9875\u9762\u5206\u914d\u7b56\u7565\u548c\u51c6\u786e\u7684\u70ed\u5ea6\u6d4b\u91cf\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u5206\u5c42\u5185\u5b58\u7cfb\u7edf\u7684\u6027\u80fd\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5185\u5b58\u5bc6\u96c6\u578b\u5e94\u7528\u7684\u6027\u80fd\u3002"}}
{"id": "2510.22399", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.22399", "abs": "https://arxiv.org/abs/2510.22399", "authors": ["Deborah Gefang", "Stephen G Hall", "George S. Tavlas"], "title": "Estimating unrestricted spatial interdependence in panel spatial autoregressive models with latent common factors", "comment": "arXiv admin note: substantial text overlap with arXiv:2309.03740", "summary": "We develop a new Bayesian approach to estimating panel spatial autoregressive\nmodels with a known number of latent common factors, where N, the number of\ncross-sectional units, is much larger than T, the number of time periods.\nWithout imposing any a priori structures on the spatial linkages between\nvariables, we let the data speak for themselves. Extensive Monte Carlo studies\nshow that our method is super-fast and our estimated spatial weights matrices\nand common factors strongly resemble their true counterparts. As an\nillustration, we examine the spatial interdependence of regional gross value\nadded (GVA) growth rates across the European Union (EU). In addition to\nrevealing the clear presence of predominant country-level clusters, our results\nindicate that only a small portion of the variation in the data is explained by\nthe latent shocks that are uncorrelated with the explanatory variables.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8d1d\u53f6\u65af\u65b9\u6cd5\u6765\u4f30\u8ba1\u9762\u677f\u7a7a\u95f4\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u5728N\u8fdc\u5927\u4e8eT\u7684\u60c5\u51b5\u4e0b\u80fd\u5feb\u901f\u4f30\u8ba1\u7a7a\u95f4\u6743\u91cd\u77e9\u9635\u548c\u6f5c\u5728\u5171\u540c\u56e0\u5b50\uff0c\u5e76\u901a\u8fc7\u6b27\u76df\u533a\u57dfGVA\u589e\u957f\u7387\u7684\u5b9e\u8bc1\u5206\u6790\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u65e0\u9700\u9884\u5148\u8bbe\u5b9a\u7a7a\u95f4\u5173\u8054\u7ed3\u6784\u7684\u9762\u677f\u7a7a\u95f4\u81ea\u56de\u5f52\u6a21\u578b\u4f30\u8ba1\u65b9\u6cd5\uff0c\u8ba9\u6570\u636e\u81ea\u8eab\u63ed\u793a\u7a7a\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u7279\u522b\u662f\u5728\u6a2a\u622a\u9762\u5355\u4f4d\u6570\u8fdc\u5927\u4e8e\u65f6\u95f4\u5468\u671f\u6570\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u65b9\u6cd5\u4f30\u8ba1\u9762\u677f\u7a7a\u95f4\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u5305\u542b\u5df2\u77e5\u6570\u91cf\u7684\u6f5c\u5728\u5171\u540c\u56e0\u5b50\uff0c\u4e0d\u65bd\u52a0\u4efb\u4f55\u5148\u9a8c\u7684\u7a7a\u95f4\u5173\u8054\u7ed3\u6784\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u65b9\u5f0f\u4f30\u8ba1\u7a7a\u95f4\u6743\u91cd\u77e9\u9635\u3002", "result": "\u8499\u7279\u5361\u6d1b\u7814\u7a76\u8868\u660e\u8be5\u65b9\u6cd5\u8ba1\u7b97\u901f\u5ea6\u6781\u5feb\uff0c\u4f30\u8ba1\u7684\u7a7a\u95f4\u6743\u91cd\u77e9\u9635\u548c\u5171\u540c\u56e0\u5b50\u4e0e\u771f\u5b9e\u503c\u9ad8\u5ea6\u76f8\u4f3c\uff1b\u6b27\u76dfGVA\u589e\u957f\u7387\u5b9e\u8bc1\u5206\u6790\u663e\u793a\u5b58\u5728\u660e\u663e\u56fd\u5bb6\u5c42\u9762\u7684\u96c6\u7fa4\u6548\u5e94\uff0c\u4e14\u53ea\u6709\u5c0f\u90e8\u5206\u6570\u636e\u53d8\u5f02\u7531\u4e0e\u89e3\u91ca\u53d8\u91cf\u4e0d\u76f8\u5173\u7684\u6f5c\u5728\u51b2\u51fb\u89e3\u91ca\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u4f30\u8ba1\u9762\u677f\u7a7a\u95f4\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u5728\u5b9e\u8bc1\u5e94\u7528\u4e2d\u6210\u529f\u63ed\u793a\u4e86\u6b27\u76df\u533a\u57df\u7ecf\u6d4e\u589e\u957f\u7684\u7a7a\u95f4\u4f9d\u8d56\u6a21\u5f0f\uff0c\u7279\u522b\u662f\u56fd\u5bb6\u5c42\u9762\u7684\u96c6\u7fa4\u7279\u5f81\u3002"}}
{"id": "2510.21951", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21951", "abs": "https://arxiv.org/abs/2510.21951", "authors": ["Yijin Wang", "Subhonmesh Bose"], "title": "Pricing Problems in Adoption of New Technologies", "comment": null, "summary": "We propose a generalization of the Bass diffusion model in discrete-time that\nexplicitly models the effect of price in adoption. Our model is different from\nearlier price-incorporated models and fits well to adoption data for various\nproducts. We then utilize this model to study two decision-making problems.\nFirst, we provide a series of structural results on optimal pricing strategies\nto maximize profits from product sales by a monopolist over a finite horizon.\nWe fully characterize the optimal pricing strategy in the single-period\nproblem, and establish several structural properties of the same for the\nmulti-period counterpart. Second, we study a Stackelberg game between a\npolicy-maker and a monopolist, where the former seeks to maximize adoption\nthrough rebates, while the latter focuses on profits. For this problem, we\nanalytically characterize crucial properties of the equilibrium path of the\nsingle-period game, and demonstrate how they carry over to the multi-period\nvariant.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5305\u542b\u4ef7\u683c\u56e0\u7d20\u7684Bass\u6269\u6563\u6a21\u578b\u79bb\u6563\u65f6\u95f4\u63a8\u5e7f\uff0c\u7528\u4e8e\u7814\u7a76\u5784\u65ad\u8005\u7684\u6700\u4f18\u5b9a\u4ef7\u7b56\u7565\u548c\u653f\u7b56\u5236\u5b9a\u8005\u4e0e\u5784\u65ad\u8005\u4e4b\u95f4\u7684Stackelberg\u535a\u5f08\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u672a\u80fd\u5145\u5206\u4f53\u73b0\u4ef7\u683c\u5bf9\u4ea7\u54c1\u91c7\u7528\u7684\u5f71\u54cd\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u51c6\u786e\u62df\u5408\u5b9e\u9645\u91c7\u7528\u6570\u636e\u5e76\u652f\u6301\u51b3\u7b56\u5206\u6790\u7684\u4ef7\u683c\u6574\u5408\u6a21\u578b\u3002", "method": "\u6269\u5c55Bass\u6269\u6563\u6a21\u578b\u4ee5\u663e\u5f0f\u5efa\u6a21\u4ef7\u683c\u6548\u5e94\uff0c\u7136\u540e\u5e94\u7528\u8be5\u6a21\u578b\u5206\u6790\u4e24\u4e2a\u51b3\u7b56\u95ee\u9898\uff1a\u5784\u65ad\u8005\u7684\u591a\u671f\u6700\u4f18\u5b9a\u4ef7\u7b56\u7565\uff0c\u4ee5\u53ca\u653f\u7b56\u5236\u5b9a\u8005\u4e0e\u5784\u65ad\u8005\u4e4b\u95f4\u7684Stackelberg\u535a\u5f08\u3002", "result": "\u5b8c\u5168\u523b\u753b\u4e86\u5355\u671f\u95ee\u9898\u7684\u6700\u4f18\u5b9a\u4ef7\u7b56\u7565\uff0c\u5efa\u7acb\u4e86\u591a\u671f\u95ee\u9898\u7684\u7ed3\u6784\u6027\u8d28\uff1b\u5728\u535a\u5f08\u95ee\u9898\u4e2d\uff0c\u5206\u6790\u4e86\u5355\u671f\u5747\u8861\u8def\u5f84\u7684\u5173\u952e\u6027\u8d28\u5e76\u6269\u5c55\u5230\u591a\u671f\u60c5\u5f62\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4ef7\u683c\u6574\u5408\u6269\u6563\u6a21\u578b\u80fd\u591f\u6709\u6548\u652f\u6301\u5b9a\u4ef7\u548c\u8865\u8d34\u653f\u7b56\u51b3\u7b56\uff0c\u4e3a\u4ea7\u54c1\u91c7\u7528\u52a8\u6001\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u5efa\u6a21\u6846\u67b6\u3002"}}
{"id": "2510.22341", "categories": ["stat.AP", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2510.22341", "abs": "https://arxiv.org/abs/2510.22341", "authors": ["Avirup Chakraborty"], "title": "Understanding Carbon Trade Dynamics: A European Union Emissions Trading System Perspective", "comment": null, "summary": "The European Union Emissions Trading System (EU ETS), the worlds largest\ncap-and-trade carbon market, is central to EU climate policy. This study\nanalyzes its efficiency, price behavior, and market structure from 2010 to\n2020. Using an AR-GARCH framework, we find pronounced price clustering and\nshort-term return predictability, with 60.05 percent directional accuracy and a\n70.78 percent hit rate within forecast intervals. Network analysis of\ninter-country transactions shows a concentrated structure dominated by a few\nregistries that control most high-value flows. Country-specific log-log\nregressions of price on traded quantity reveal heterogeneous and sometimes\npositive elasticities exceeding unity, implying that trading volumes often rise\nwith prices. These results point to persistent inefficiencies in the EU ETS,\nincluding partial predictability, asymmetric market power, and unconventional\nprice-volume relationships, suggesting that while the system contributes to\ndecarbonization, its trading dynamics and price formation remain imperfect.", "AI": {"tldr": "\u6b27\u76df\u6392\u653e\u4ea4\u6613\u4f53\u7cfb\uff08EU ETS\uff09\u57282010-2020\u5e74\u95f4\u5b58\u5728\u6548\u7387\u95ee\u9898\uff0c\u5305\u62ec\u4ef7\u683c\u805a\u96c6\u3001\u77ed\u671f\u6536\u76ca\u53ef\u9884\u6d4b\u6027\u3001\u5e02\u573a\u96c6\u4e2d\u5ea6\u4ee5\u53ca\u975e\u4f20\u7edf\u7684\u4ef7\u683c-\u4ea4\u6613\u91cf\u5173\u7cfb\u3002", "motivation": "\u5206\u6790\u5168\u7403\u6700\u5927\u7684\u78b3\u5e02\u573aEU ETS\u7684\u6548\u7387\u3001\u4ef7\u683c\u884c\u4e3a\u548c\u5e02\u573a\u7ed3\u6784\uff0c\u8bc4\u4f30\u5176\u5728\u8131\u78b3\u76ee\u6807\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528AR-GARCH\u6846\u67b6\u5206\u6790\u4ef7\u683c\u884c\u4e3a\uff0c\u7f51\u7edc\u5206\u6790\u7814\u7a76\u8de8\u56fd\u4ea4\u6613\u7ed3\u6784\uff0c\u56fd\u5bb6\u7279\u5b9a\u7684\u5bf9\u6570-\u5bf9\u6570\u56de\u5f52\u5206\u6790\u4ef7\u683c\u4e0e\u4ea4\u6613\u91cf\u7684\u5f39\u6027\u5173\u7cfb\u3002", "result": "\u53d1\u73b060.05%\u7684\u65b9\u5411\u51c6\u786e\u6027\u548c70.78%\u7684\u547d\u4e2d\u7387\uff0c\u5e02\u573a\u7ed3\u6784\u96c6\u4e2d\u7531\u5c11\u6570\u6ce8\u518c\u673a\u6784\u4e3b\u5bfc\uff0c\u4ef7\u683c\u5f39\u6027\u5f02\u8d28\u4e14\u6709\u65f6\u8d85\u8fc71\uff0c\u8868\u660e\u4ea4\u6613\u91cf\u968f\u4ef7\u683c\u4e0a\u6da8\u3002", "conclusion": "EU ETS\u867d\u7136\u6709\u52a9\u4e8e\u8131\u78b3\uff0c\u4f46\u5176\u4ea4\u6613\u52a8\u6001\u548c\u4ef7\u683c\u5f62\u6210\u673a\u5236\u4ecd\u5b58\u5728\u6301\u7eed\u7684\u4f4e\u6548\u7387\uff0c\u5305\u62ec\u90e8\u5206\u53ef\u9884\u6d4b\u6027\u3001\u4e0d\u5bf9\u79f0\u5e02\u573a\u529b\u91cf\u548c\u975e\u4f20\u7edf\u4ef7\u683c-\u4ea4\u6613\u91cf\u5173\u7cfb\u3002"}}
{"id": "2510.21734", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.21734", "abs": "https://arxiv.org/abs/2510.21734", "authors": ["Giovanni Battista Regazzo", "Wim-Alexander Beckers", "Xuan Thao Ha", "Mouloud Ourak", "Johan Vlekken", "Emmanuel Vander Poorten"], "title": "Force-Displacement Profiling for Robot-Assisted Deployment of a Left Atrial Appendage Occluder Using FBG-EM Distal Sensing", "comment": "Presented at the Conference on New Technologies for Computer and\n  Robot Assisted Surgery (CRAS2025)", "summary": "Atrial fibrillation (AF) increases the risk of thromboembolic events due to\nimpaired function of the left atrial appendage (LAA). Left atrial appendage\nclosure (LAAC) is a minimally invasive intervention designed to reduce stroke\nrisk by sealing the LAA with an expandable occluder device. Current deployment\nrelies on manual catheter control and imaging modalities like fluoroscopy and\ntransesophageal echocardiography, which carry limitations including radiation\nexposure and limited positioning precision. In this study, we leverage a\npreviously developed force-sensing delivery sheath integrating fiber Bragg\ngratings (FBGs) at the interface between the catheter and the occluder.\nCombined with electromagnetic (EM) tracking, this setup enables real-time\nmeasurement of interaction forces and catheter tip position during\nrobot-assisted LAAC deployment in an anatomical phantom. We present a novel\nforce-displacement profiling method that characterizes occluder deployment\ndynamics and identifies key procedural steps without relying on ionizing\nradiation. The force profiles reveal low-magnitude interaction forces,\nsuggesting minimal mechanical stress on the surrounding anatomy. This approach\nshows promise in providing clinicians with enhanced intraoperative feedback,\nimproving deployment outcome. Future work will focus on automating deployment\nsteps classification and validating the sensing strategy in dynamic, realistic\nenvironments.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u5149\u7ea4\u5e03\u62c9\u683c\u5149\u6805\u548c\u7535\u78c1\u8ddf\u8e2a\u7684\u529b-\u4f4d\u79fb\u5206\u6790\u65b9\u6cd5\uff0c\u7528\u4e8e\u673a\u5668\u4eba\u8f85\u52a9\u5de6\u5fc3\u8033\u5c01\u5835\u672f\uff0c\u65e0\u9700\u7535\u79bb\u8f90\u5c04\u5373\u53ef\u8bc6\u522b\u5173\u952e\u624b\u672f\u6b65\u9aa4\u3002", "motivation": "\u5f53\u524d\u5de6\u5fc3\u8033\u5c01\u5835\u672f\u4f9d\u8d56\u624b\u52a8\u5bfc\u7ba1\u63a7\u5236\u548c\u8367\u5149\u900f\u89c6\u6210\u50cf\uff0c\u5b58\u5728\u8f90\u5c04\u66b4\u9732\u548c\u5b9a\u4f4d\u7cbe\u5ea6\u6709\u9650\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5b89\u5168\u3001\u7cbe\u786e\u7684\u624b\u672f\u5f15\u5bfc\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u96c6\u6210\u5149\u7ea4\u5e03\u62c9\u683c\u5149\u6805\u7684\u529b\u4f20\u611f\u8f93\u9001\u9798\u7ed3\u5408\u7535\u78c1\u8ddf\u8e2a\uff0c\u5728\u89e3\u5256\u6a21\u578b\u4e2d\u8fdb\u884c\u673a\u5668\u4eba\u8f85\u52a9\u5de6\u5fc3\u8033\u5c01\u5835\u90e8\u7f72\uff0c\u5b9e\u65f6\u6d4b\u91cf\u76f8\u4e92\u4f5c\u7528\u529b\u548c\u5bfc\u7ba1\u5c16\u7aef\u4f4d\u7f6e\u3002", "result": "\u529b\u5256\u9762\u663e\u793a\u4f4e\u5e45\u5ea6\u7684\u76f8\u4e92\u4f5c\u7528\u529b\uff0c\u8868\u660e\u5bf9\u5468\u56f4\u89e3\u5256\u7ed3\u6784\u7684\u673a\u68b0\u5e94\u529b\u6700\u5c0f\uff0c\u80fd\u591f\u8bc6\u522b\u5173\u952e\u624b\u672f\u6b65\u9aa4\u800c\u4e0d\u4f9d\u8d56\u7535\u79bb\u8f90\u5c04\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u671b\u4e3a\u4e34\u5e8a\u533b\u751f\u63d0\u4f9b\u589e\u5f3a\u7684\u672f\u4e2d\u53cd\u9988\uff0c\u6539\u5584\u90e8\u7f72\u7ed3\u679c\uff0c\u672a\u6765\u5de5\u4f5c\u5c06\u805a\u7126\u4e8e\u81ea\u52a8\u5316\u90e8\u7f72\u6b65\u9aa4\u5206\u7c7b\u548c\u5728\u52a8\u6001\u771f\u5b9e\u73af\u5883\u4e2d\u9a8c\u8bc1\u4f20\u611f\u7b56\u7565\u3002"}}
{"id": "2510.21843", "categories": ["cs.CY", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.21843", "abs": "https://arxiv.org/abs/2510.21843", "authors": ["Anand Bhardwaj", "Samer Faraj"], "title": "A quality of mercy is not trained: the imagined vs. the practiced in healthcare process-specialized AI development", "comment": null, "summary": "In high stakes organizational contexts like healthcare, artificial\nintelligence (AI) systems are increasingly being designed to augment complex\ncoordination tasks. This paper investigates how the ethical stakes of such\nsystems are shaped by their epistemic framings: what aspects of work they\nrepresent, and what they exclude. Drawing on an embedded study of AI\ndevelopment for operating room (OR) scheduling at a Canadian hospital, we\ncompare scheduling-as-imagined in the AI design process: rule-bound,\npredictable, and surgeon-centric, with scheduling-as-practiced as a fluid,\npatient-facing coordination process involving ethical discretion. We show how\nearly representational decisions narrowed what the AI could support, resulting\nin epistemic foreclosure: the premature exclusion of key ethical dimensions\nfrom system design. Our findings surface the moral consequences of abstraction\nand call for a more situated approach to designing healthcare\nprocess-specialized artificial intelligence systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2510.21721", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.21721", "abs": "https://arxiv.org/abs/2510.21721", "authors": ["Kentaro Ueda", "Takehiro Takayanagi"], "title": "PREFINE: Personalized Story Generation via Simulated User Critics and User-Specific Rubric Generation", "comment": null, "summary": "While recent advances in Large Language Models (LLMs) have improved the\nquality of creative text generation, significant challenges remain in producing\npersonalized stories that reflect individual user preferences. Conventional\napproaches rely on explicit feedback or fine-tuning, which presents practical\nissues regarding user burden, data collection, computational costs, and\nprivacy. In this work, we propose PREFINE (Persona-and-Rubric Guided\nCritique-and-Refine), a novel framework that extends the Critique-and-Refine\nparadigm to personalization. PREFINE constructs a pseudo-user agent from a\nuser's interaction history and generates user-specific rubrics (evaluation\ncriteria). By having this agent critique and refine outputs on the user's\nbehalf based on these tailored rubrics, our method achieves personalized\ngeneration without requiring parameter updates or direct user feedback. We\nconducted a comprehensive evaluation on the PerDOC and PerMPST story datasets.\nWe designed three baseline methods and several model variants to verify the\ncontribution of each component of our framework. In automatic evaluations\n(LLM-as-a-Judge), PREFINE achieved higher win rates and statistically\nsignificant scores than the baselines, without compromising general story\nquality. Analysis of the model variants confirmed that both the pseudo-user\nagent and the user-specific rubrics are crucial for enhancing personalization\nperformance. Beyond story generation, our approach holds potential for enabling\nefficient personalization in broader applications, such as dialogue systems,\neducation, and recommendation.", "AI": {"tldr": "PREFINE\u6846\u67b6\u901a\u8fc7\u6784\u5efa\u4f2a\u7528\u6237\u4ee3\u7406\u548c\u7528\u6237\u7279\u5b9a\u8bc4\u4f30\u6807\u51c6\uff0c\u5728\u4e0d\u66f4\u65b0\u53c2\u6570\u6216\u6536\u96c6\u76f4\u63a5\u7528\u6237\u53cd\u9988\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e2a\u6027\u5316\u6545\u4e8b\u751f\u6210\u3002", "motivation": "\u4f20\u7edf\u4e2a\u6027\u5316\u65b9\u6cd5\u4f9d\u8d56\u663e\u5f0f\u53cd\u9988\u6216\u5fae\u8c03\uff0c\u5b58\u5728\u7528\u6237\u8d1f\u62c5\u3001\u6570\u636e\u6536\u96c6\u3001\u8ba1\u7b97\u6210\u672c\u548c\u9690\u79c1\u7b49\u5b9e\u9645\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4f2a\u7528\u6237\u4ee3\u7406\u548c\u7528\u6237\u7279\u5b9a\u8bc4\u4f30\u6807\u51c6\uff0c\u8ba9\u4ee3\u7406\u57fa\u4e8e\u8fd9\u4e9b\u6807\u51c6\u8fdb\u884c\u6279\u5224\u548c\u7cbe\u70bc\uff0c\u5b9e\u73b0\u4e2a\u6027\u5316\u751f\u6210\u3002", "result": "\u5728PerDOC\u548cPerMPST\u6570\u636e\u96c6\u4e0a\uff0cPREFINE\u5728\u81ea\u52a8\u8bc4\u4f30\u4e2d\u83b7\u5f97\u4e86\u66f4\u9ad8\u7684\u80dc\u7387\u548c\u7edf\u8ba1\u663e\u8457\u5206\u6570\uff0c\u4e14\u4e0d\u635f\u5bb3\u6545\u4e8b\u6574\u4f53\u8d28\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6545\u4e8b\u751f\u6210\u4e4b\u5916\uff0c\u8fd8\u6709\u6f5c\u529b\u5e94\u7528\u4e8e\u5bf9\u8bdd\u7cfb\u7edf\u3001\u6559\u80b2\u548c\u63a8\u8350\u7b49\u66f4\u5e7f\u6cdb\u9886\u57df\u7684\u4e2a\u6027\u5316\u4efb\u52a1\u3002"}}
{"id": "2510.21950", "categories": ["cs.SI", "cs.DC", "05C20, 68Q85, 91D30, 03B70", "G.2.2; C.2.4; F.4.1"], "pdf": "https://arxiv.org/pdf/2510.21950", "abs": "https://arxiv.org/abs/2510.21950", "authors": ["Nnamdi Daniel Aghanya", "Romain Leemans"], "title": "Heaven & Hell II: Scale Laws and Robustness in One-Step Heaven-Hell Consensus", "comment": "12 pages, 1 figure", "summary": "We study Heaven-Hell dynamics, a model for network consensus. A known result\nestablishes an exact one-step convergence threshold for systems with a single\nuniform hub: the per-node inbound hub weight W suffices if and only if W >=\nmaxrest, the maximum non-hub inbound mass. We develop scale laws and\noperational refinements that make this threshold robust to tie-breaking\npolicies, node-specific tolerances, targeted seeding, multiple hubs, and\nasynchronous updates. Our contributions include a conservation-law perspective,\nparameterized tie policies, tighter pointwise bounds improving on classical\nworst-case guarantees, one-pass fairness for asynchronous updates, and\nsufficient conditions for seeded convergence. All proofs are mechanized in Coq,\nwith experiments on rings, grids, scale-free graphs, and heterogeneous weighted\ngraphs validating tightness and gap closures", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86Heaven-Hell\u7f51\u7edc\u5171\u8bc6\u6a21\u578b\uff0c\u5efa\u7acb\u4e86\u5355hub\u7cfb\u7edf\u7684\u7cbe\u786e\u4e00\u6b65\u6536\u655b\u9608\u503c\uff0c\u5e76\u5f00\u53d1\u4e86\u4f7f\u5176\u5bf9\u591a\u79cd\u5b9e\u9645\u56e0\u7d20\u9c81\u68d2\u7684\u5c3a\u5ea6\u5b9a\u5f8b\u548c\u64cd\u4f5c\u6539\u8fdb\u3002", "motivation": "\u7814\u7a76\u7f51\u7edc\u5171\u8bc6\u6a21\u578b\u4e2d\u7684\u6536\u655b\u6761\u4ef6\uff0c\u4f7f\u7406\u8bba\u9608\u503c\u80fd\u591f\u9002\u5e94\u5b9e\u9645\u7cfb\u7edf\u4e2d\u7684\u5404\u79cd\u590d\u6742\u60c5\u51b5\uff0c\u5982\u6253\u7834\u5e73\u5c40\u7b56\u7565\u3001\u8282\u70b9\u7279\u5b9a\u5bb9\u5fcd\u5ea6\u3001\u76ee\u6807\u79cd\u5b50\u3001\u591ahub\u548c\u5f02\u6b65\u66f4\u65b0\u7b49\u3002", "method": "\u91c7\u7528\u5b88\u6052\u5b9a\u5f8b\u89c6\u89d2\uff0c\u53c2\u6570\u5316\u5e73\u5c40\u7b56\u7565\uff0c\u5f00\u53d1\u66f4\u7d27\u7684\u70b9\u754c\u6539\u8fdb\u7ecf\u5178\u6700\u574f\u60c5\u51b5\u4fdd\u8bc1\uff0c\u4e3a\u5f02\u6b65\u66f4\u65b0\u63d0\u4f9b\u4e00\u6b21\u901a\u8fc7\u516c\u5e73\u6027\uff0c\u4ee5\u53ca\u79cd\u5b50\u6536\u655b\u7684\u5145\u5206\u6761\u4ef6\u3002\u6240\u6709\u8bc1\u660e\u5728Coq\u4e2d\u673a\u68b0\u5316\u9a8c\u8bc1\u3002", "result": "\u5728\u73af\u3001\u7f51\u683c\u3001\u65e0\u6807\u5ea6\u56fe\u548c\u5f02\u6784\u52a0\u6743\u56fe\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u7d27\u81f4\u6027\u548c\u95f4\u9699\u95ed\u5408\u3002\u5efa\u7acb\u4e86\u4f7f\u5355hub\u7cfb\u7edf\u6536\u655b\u9608\u503c\u5bf9\u591a\u79cd\u5b9e\u9645\u56e0\u7d20\u9c81\u68d2\u7684\u5c3a\u5ea6\u5b9a\u5f8b\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u4f7f\u7f51\u7edc\u5171\u8bc6\u6a21\u578b\u6536\u655b\u9608\u503c\u9c81\u68d2\u5316\u7684\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u6539\u8fdb\uff0c\u901a\u8fc7\u673a\u68b0\u5316\u9a8c\u8bc1\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u7d27\u81f4\u6027\u3002"}}
{"id": "2510.12289", "categories": ["econ.EM", "econ.TH", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.12289", "abs": "https://arxiv.org/abs/2510.12289", "authors": ["Tatsuru Kikuchi"], "title": "Nonparametric Identification and Estimation of Spatial Treatment Effect Boundaries: Evidence from 42 Million Pollution Observations", "comment": "53 pages, 8 figures", "summary": "This paper develops a nonparametric framework for identifying and estimating\nspatial boundaries of treatment effects in settings with geographic spillovers.\nWhile atmospheric dispersion theory predicts exponential decay of pollution\nunder idealized assumptions, these assumptions -- steady winds, homogeneous\natmospheres, flat terrain -- are systematically violated in practice. I\nestablish nonparametric identification of spatial boundaries under weak\nsmoothness and monotonicity conditions, propose a kernel-based estimator with\ndata-driven bandwidth selection, and derive asymptotic theory for inference.\nUsing 42 million satellite observations of NO$_2$ concentrations near coal\nplants (2019-2021), I find that nonparametric kernel regression reduces\nprediction errors by 1.0 percentage point on average compared to parametric\nexponential decay assumptions, with largest improvements at policy-relevant\ndistances: 2.8 percentage points at 10 km (near-source impacts) and 3.7\npercentage points at 100 km (long-range transport). Parametric methods\nsystematically underestimate near-source concentrations while overestimating\nlong-range decay. The COVID-19 pandemic provides a natural experiment\nvalidating the framework's temporal sensitivity: NO$_2$ concentrations dropped\n4.6\\% in 2020, then recovered 5.7\\% in 2021. These results demonstrate that\nflexible, data-driven spatial methods substantially outperform restrictive\nparametric assumptions in environmental policy applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u975e\u53c2\u6570\u6846\u67b6\u6765\u8bc6\u522b\u548c\u4f30\u8ba1\u5730\u7406\u6ea2\u51fa\u6548\u5e94\u4e2d\u7684\u7a7a\u95f4\u8fb9\u754c\uff0c\u4f7f\u75284200\u4e07\u536b\u661f\u89c2\u6d4b\u6570\u636e\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u73af\u5883\u653f\u7b56\u5e94\u7528\u4e2d\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u5927\u6c14\u6269\u6563\u7406\u8bba\u5728\u7406\u60f3\u5047\u8bbe\u4e0b\u9884\u6d4b\u6c61\u67d3\u7269\u5448\u6307\u6570\u8870\u51cf\uff0c\u4f46\u8fd9\u4e9b\u5047\u8bbe\uff08\u7a33\u5b9a\u98ce\u573a\u3001\u5747\u5300\u5927\u6c14\u3001\u5e73\u5766\u5730\u5f62\uff09\u5728\u5b9e\u8df5\u4e2d\u5e38\u88ab\u8fdd\u53cd\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002", "method": "\u5efa\u7acb\u4e86\u5728\u5f31\u5e73\u6ed1\u6027\u548c\u5355\u8c03\u6027\u6761\u4ef6\u4e0b\u7684\u975e\u53c2\u6570\u8bc6\u522b\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6838\u7684\u4f30\u8ba1\u5668\u5e76\u91c7\u7528\u6570\u636e\u9a71\u52a8\u7684\u5e26\u5bbd\u9009\u62e9\u65b9\u6cd5\uff0c\u63a8\u5bfc\u4e86\u6e10\u8fd1\u7406\u8bba\u7528\u4e8e\u63a8\u65ad\u3002", "result": "\u76f8\u6bd4\u53c2\u6570\u5316\u6307\u6570\u8870\u51cf\u5047\u8bbe\uff0c\u975e\u53c2\u6570\u6838\u56de\u5f52\u5e73\u5747\u51cf\u5c11\u9884\u6d4b\u8bef\u5dee1.0\u4e2a\u767e\u5206\u70b9\uff0c\u5728\u653f\u7b56\u76f8\u5173\u8ddd\u79bb\u4e0a\u6539\u5584\u6700\u5927\uff1a10\u516c\u91cc\u59042.8\u4e2a\u767e\u5206\u70b9\uff08\u8fd1\u6e90\u5f71\u54cd\uff09\uff0c100\u516c\u91cc\u59043.7\u4e2a\u767e\u5206\u70b9\uff08\u957f\u8ddd\u79bb\u4f20\u8f93\uff09\u3002\u53c2\u6570\u65b9\u6cd5\u7cfb\u7edf\u6027\u5730\u4f4e\u4f30\u8fd1\u6e90\u6d53\u5ea6\u800c\u9ad8\u4f30\u957f\u8ddd\u79bb\u8870\u51cf\u3002", "conclusion": "\u7075\u6d3b\u7684\u6570\u636e\u9a71\u52a8\u7a7a\u95f4\u65b9\u6cd5\u5728\u73af\u5883\u653f\u7b56\u5e94\u7528\u4e2d\u663e\u8457\u4f18\u4e8e\u9650\u5236\u6027\u53c2\u6570\u5047\u8bbe\uff0cCOVID-19\u81ea\u7136\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u65f6\u95f4\u654f\u611f\u6027\u3002"}}
{"id": "2510.22817", "categories": ["econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.22817", "abs": "https://arxiv.org/abs/2510.22817", "authors": ["Yibo Sun"], "title": "Wildfire and house prices: A synthetic control case study of Altadena (Jan 2025)", "comment": null, "summary": "This study uses the Synthetic Control Method (SCM) to estimate the causal\nimpact of a January 2025 wildfire on housing prices in Altadena, California. We\nconstruct a 'synthetic' Altadena from a weighted average of peer cities to\nserve as a counterfactual; this approach assumes no spillover effects on the\ndonor pool. The results reveal a substantial negative price effect that\nintensifies over time. Over the six months following the event, we estimate an\naverage monthly loss of $32,125. The statistical evidence for this effect is\nnuanced. Based on the robust post-to-pre-treatment RMSPE ratio, the result is\nstatistically significant at the 10% level (p = 0.0508). In contrast, the\neffect is not statistically significant when measured by the average\npost-treatment gap (p = 0.3220). This analysis highlights the significant\nfinancial risks faced by communities in fire-prone regions and demonstrates\nSCM's effectiveness in evaluating disaster-related economic damages.", "AI": {"tldr": "\u4f7f\u7528\u5408\u6210\u63a7\u5236\u6cd5\u8bc4\u4f302025\u5e741\u6708\u52a0\u5ddeAltadena\u91ce\u706b\u5bf9\u623f\u4ef7\u7684\u56e0\u679c\u5f71\u54cd\uff0c\u53d1\u73b0\u663e\u8457\u8d1f\u9762\u6548\u5e94\u4e14\u968f\u65f6\u95f4\u52a0\u5267\uff0c\u516d\u4e2a\u6708\u5e73\u5747\u6708\u635f\u593132,125\u7f8e\u5143", "motivation": "\u8bc4\u4f30\u91ce\u706b\u707e\u5bb3\u5bf9\u793e\u533a\u623f\u4ef7\u7684\u56e0\u679c\u5f71\u54cd\uff0c\u4e3a\u706b\u707e\u9891\u53d1\u5730\u533a\u7684\u8d22\u52a1\u98ce\u9669\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e", "method": "\u91c7\u7528\u5408\u6210\u63a7\u5236\u6cd5\u6784\u5efa'\u5408\u6210'Altadena\u4f5c\u4e3a\u53cd\u4e8b\u5b9e\u5bf9\u7167\u7ec4\uff0c\u5047\u8bbe\u5bf9\u6350\u8d60\u6c60\u65e0\u6ea2\u51fa\u6548\u5e94", "result": "\u91ce\u706b\u5bfc\u81f4\u623f\u4ef7\u663e\u8457\u8d1f\u9762\u6548\u5e94\uff0c\u968f\u65f6\u95f4\u52a0\u5267\uff1b\u57fa\u4e8e\u7a33\u5065\u540e/\u524d\u5904\u7406RMSPE\u6bd4\u7387\u572810%\u6c34\u5e73\u663e\u8457(p=0.0508)\uff0c\u4f46\u57fa\u4e8e\u5e73\u5747\u540e\u5904\u7406\u5dee\u8ddd\u4e0d\u663e\u8457(p=0.3220)", "conclusion": "\u7814\u7a76\u7a81\u663e\u706b\u707e\u9891\u53d1\u793e\u533a\u7684\u8d22\u52a1\u98ce\u9669\uff0c\u8bc1\u660e\u5408\u6210\u63a7\u5236\u6cd5\u5728\u8bc4\u4f30\u707e\u5bb3\u76f8\u5173\u7ecf\u6d4e\u635f\u5931\u65b9\u9762\u7684\u6709\u6548\u6027"}}
{"id": "2510.22522", "categories": ["cs.CY", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.22522", "abs": "https://arxiv.org/abs/2510.22522", "authors": ["V. Sanchez Padilla", "Albert Espinal", "Jose Cordova-Garcia", "Lisa Schibelius"], "title": "Barriers to Integrating Low-Power IoT in Engineering Education: A Survey of the Literature", "comment": "2025 IEEE 16th Annual Information Technology, Electronics and Mobile\n  Communication Conference (IEMCON), Berkeley, CA, USA", "summary": "Low-power Internet of Things (IoT) technologies are becoming increasingly\nimportant in engineering education as a tool to help students connect theory to\nreal applications. However, many institutions face barriers that slow down\ntheir adoption in courses and labs. This paper reviews recent studies to\nunderstand these barriers and organizes them into three groups: technical,\norganizational, and curricular/pedagogical. Technical barriers include energy\nmanagement, scalability, and integration issues. Organizational barriers are\nrelated to cost, planning, and the need for trained staff. Curricular and\npedagogical barriers include gaps in student readiness, limited lab time, and\nplatform choices that depend on budget. By detailing these barriers with\npractical examples, this paper aims to help educators and academic leaders\ndevelop more effective strategies to adopt low-power IoT in engineering\nprograms.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5728\u5de5\u7a0b\u6559\u80b2\u4e2d\u91c7\u7528\u4f4e\u529f\u8017\u7269\u8054\u7f51\u6280\u672f\u9762\u4e34\u7684\u6280\u672f\u3001\u7ec4\u7ec7\u548c\u8bfe\u7a0b/\u6559\u5b66\u6cd5\u4e09\u5927\u969c\u788d\uff0c\u65e8\u5728\u5e2e\u52a9\u6559\u80b2\u5de5\u4f5c\u8005\u5236\u5b9a\u66f4\u6709\u6548\u7684\u91c7\u7528\u7b56\u7565\u3002", "motivation": "\u4f4e\u529f\u8017\u7269\u8054\u7f51\u6280\u672f\u5728\u5de5\u7a0b\u6559\u80b2\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u8bb8\u591a\u673a\u6784\u5728\u8bfe\u7a0b\u548c\u5b9e\u9a8c\u5ba4\u4e2d\u91c7\u7528\u65f6\u9762\u4e34\u5404\u79cd\u969c\u788d\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790\u8fd9\u4e9b\u969c\u788d\u4ee5\u4fc3\u8fdb\u66f4\u6709\u6548\u7684\u91c7\u7528\u3002", "method": "\u901a\u8fc7\u56de\u987e\u8fd1\u671f\u7814\u7a76\uff0c\u5c06\u969c\u788d\u7cfb\u7edf\u6027\u5730\u5206\u4e3a\u6280\u672f\u3001\u7ec4\u7ec7\u548c\u8bfe\u7a0b/\u6559\u5b66\u6cd5\u4e09\u5927\u7c7b\uff0c\u5e76\u8be6\u7ec6\u5206\u6790\u6bcf\u7c7b\u969c\u788d\u7684\u5177\u4f53\u8868\u73b0\u3002", "result": "\u8bc6\u522b\u51fa\u6280\u672f\u969c\u788d\u5305\u62ec\u80fd\u6e90\u7ba1\u7406\u3001\u53ef\u6269\u5c55\u6027\u548c\u96c6\u6210\u95ee\u9898\uff1b\u7ec4\u7ec7\u969c\u788d\u6d89\u53ca\u6210\u672c\u3001\u89c4\u5212\u548c\u4eba\u5458\u57f9\u8bad\u9700\u6c42\uff1b\u8bfe\u7a0b/\u6559\u5b66\u6cd5\u969c\u788d\u5305\u62ec\u5b66\u751f\u51c6\u5907\u5ea6\u4e0d\u8db3\u3001\u5b9e\u9a8c\u65f6\u95f4\u6709\u9650\u548c\u9884\u7b97\u4f9d\u8d56\u7684\u5e73\u53f0\u9009\u62e9\u3002", "conclusion": "\u901a\u8fc7\u8be6\u7ec6\u5206\u6790\u8fd9\u4e9b\u969c\u788d\u5e76\u63d0\u4f9b\u5b9e\u9645\u6848\u4f8b\uff0c\u672c\u6587\u4e3a\u6559\u80b2\u5de5\u4f5c\u8005\u548c\u5b66\u672f\u9886\u5bfc\u8005\u5236\u5b9a\u5728\u5de5\u7a0b\u9879\u76ee\u4e2d\u91c7\u7528\u4f4e\u529f\u8017\u7269\u8054\u7f51\u7684\u66f4\u6709\u6548\u7b56\u7565\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2510.22841", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.22841", "abs": "https://arxiv.org/abs/2510.22841", "authors": ["Antonio Raiola", "Nazarii Salish"], "title": "Testing for Grouped Patterns in Panel Data Models", "comment": null, "summary": "While the literature on grouped patterns in panel data analysis has received\nsignificant attention, little to no results are available on testing for their\npresence. We propose using existing tools for testing slope homogeneity in\npanels for this purpose. We highlight the key advantages and limitations of the\navailable testing frameworks under a sequence of doubly local alternatives,\nwhere slopes are divided into dominant and remainder groups, with the size of\nthe remainder groups and the slopes differences shrinking at a certain rate as\nthe sample size increases. A Monte Carlo study corroborate our theoretical\nfindings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u73b0\u6709\u7684\u9762\u677f\u6570\u636e\u659c\u7387\u540c\u8d28\u6027\u68c0\u9a8c\u5de5\u5177\u6765\u68c0\u6d4b\u5206\u7ec4\u6a21\u5f0f\u7684\u5b58\u5728\uff0c\u5206\u6790\u4e86\u5728\u53cc\u91cd\u5c40\u90e8\u5907\u62e9\u5047\u8bbe\u4e0b\u8fd9\u4e9b\u68c0\u9a8c\u6846\u67b6\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002", "motivation": "\u867d\u7136\u9762\u677f\u6570\u636e\u4e2d\u7684\u5206\u7ec4\u6a21\u5f0f\u6587\u732e\u5df2\u5f97\u5230\u5e7f\u6cdb\u5173\u6ce8\uff0c\u4f46\u5173\u4e8e\u68c0\u9a8c\u8fd9\u4e9b\u6a21\u5f0f\u5b58\u5728\u6027\u7684\u7814\u7a76\u7ed3\u679c\u5f88\u5c11\u3002", "method": "\u5229\u7528\u73b0\u6709\u7684\u9762\u677f\u6570\u636e\u659c\u7387\u540c\u8d28\u6027\u68c0\u9a8c\u5de5\u5177\uff0c\u5728\u53cc\u91cd\u5c40\u90e8\u5907\u62e9\u5047\u8bbe\u4e0b\u5206\u6790\u68c0\u9a8c\u6846\u67b6\u7684\u6027\u80fd\uff0c\u5176\u4e2d\u659c\u7387\u88ab\u5206\u4e3a\u4e3b\u5bfc\u7ec4\u548c\u5269\u4f59\u7ec4\u3002", "result": "\u8499\u7279\u5361\u6d1b\u7814\u7a76\u8bc1\u5b9e\u4e86\u7406\u8bba\u53d1\u73b0\uff0c\u663e\u793a\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u5728\u68c0\u6d4b\u5206\u7ec4\u6a21\u5f0f\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u73b0\u6709\u659c\u7387\u540c\u8d28\u6027\u68c0\u9a8c\u5de5\u5177\u53ef\u7528\u4e8e\u68c0\u6d4b\u9762\u677f\u6570\u636e\u4e2d\u7684\u5206\u7ec4\u6a21\u5f0f\uff0c\u4f46\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u8c28\u614e\u5e94\u7528\u3002"}}
{"id": "2510.22015", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.22015", "abs": "https://arxiv.org/abs/2510.22015", "authors": ["Shilin You", "Gael Luna", "Juned Shaikh", "David Gostin", "Yu Xiang", "Justin Koeln", "Tyler Summers"], "title": "Motion Planning with Precedence Specifications via Augmented Graphs of Convex Sets", "comment": null, "summary": "We present an algorithm for planning trajectories that avoid obstacles and\nsatisfy key-door precedence specifications expressed with a fragment of signal\ntemporal logic. Our method includes a novel exact convex partitioning of the\nobstacle free space that encodes connectivity among convex free space sets, key\nsets, and door sets. We then construct an augmented graph of convex sets that\nexactly encodes the key-door precedence specifications. By solving a shortest\npath problem in this augmented graph of convex sets, our pipeline provides an\nexact solution up to a finite parameterization of the trajectory. To illustrate\nthe effectiveness of our approach, we present a method to generate key-door\nmazes that provide challenging problem instances, and we perform numerical\nexperiments to evaluate the proposed pipeline. Our pipeline is faster by\nseveral orders of magnitude than recent state-of-the art methods that use\ngeneral purpose temporal logic tools.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u89c4\u5212\u907f\u969c\u8f68\u8ff9\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u6ee1\u8db3\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\u7247\u6bb5\u8868\u8fbe\u7684\u5173\u952e-\u95e8\u4f18\u5148\u7ea7\u89c4\u8303\uff0c\u901a\u8fc7\u6784\u5efa\u589e\u5f3a\u51f8\u96c6\u56fe\u6765\u7cbe\u786e\u7f16\u7801\u5173\u952e-\u95e8\u4f18\u5148\u7ea7\u7ea6\u675f\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5173\u952e-\u95e8\u4f18\u5148\u7ea7\u7ea6\u675f\u65f6\u6548\u7387\u8f83\u4f4e\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u8f68\u8ff9\u89c4\u5212\u7b97\u6cd5\u6765\u6ee1\u8db3\u590d\u6742\u65f6\u5e8f\u903b\u8f91\u89c4\u8303\u3002", "method": "\u91c7\u7528\u65b0\u9896\u7684\u7cbe\u786e\u51f8\u5206\u533a\u65b9\u6cd5\u5bf9\u65e0\u969c\u788d\u7a7a\u95f4\u8fdb\u884c\u5212\u5206\uff0c\u6784\u5efa\u589e\u5f3a\u51f8\u96c6\u56fe\u6765\u7f16\u7801\u8fde\u901a\u6027\u548c\u5173\u952e-\u95e8\u4f18\u5148\u7ea7\u7ea6\u675f\uff0c\u901a\u8fc7\u6c42\u89e3\u6700\u77ed\u8def\u5f84\u95ee\u9898\u83b7\u5f97\u8f68\u8ff9\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6bd4\u73b0\u6709\u901a\u7528\u65f6\u5e8f\u903b\u8f91\u5de5\u5177\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5177\u6709\u6311\u6218\u6027\u7684\u5173\u952e-\u95e8\u8ff7\u5bab\u95ee\u9898\u5b9e\u4f8b\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ba1\u9053\u4e3a\u6ee1\u8db3\u5173\u952e-\u95e8\u4f18\u5148\u7ea7\u89c4\u8303\u7684\u8f68\u8ff9\u89c4\u5212\u63d0\u4f9b\u4e86\u7cbe\u786e\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2510.22410", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.22410", "abs": "https://arxiv.org/abs/2510.22410", "authors": ["Yiyao Yang", "Yasemin Gulbahar"], "title": "Multimodal Fusion and Interpretability in Human Activity Recognition: A Reproducible Framework for Sensor-Based Modeling", "comment": "33 pages, 12 figures, 3 tables", "summary": "The research presents a comprehensive framework for consolidating multimodal\nsensor data collected under naturalistic conditions, grounded in the Carnegie\nMellon University Multi-Modal Activity Database (CMU-MMAC). Focusing on Subject\n07-Brownie, the study investigates the entire processing pipeline, from data\nalignment and transformation to fusion method evaluation, interpretability, and\nmodality contribution. A unified preprocessing pipeline is developed to\ntemporally align heterogeneous video and audio data. Fusion is performed\nthrough resampling, grayscale conversion, segmentation, and feature\nstandardization. Semantic richness is confirmed via heatmaps, spectrograms, and\nluminance time series, while frame-aligned waveform overlays demonstrate\ntemporal consistency. Results indicate that late fusion yields the highest\nvalidation accuracy, followed by hybrid fusion, with early fusion performing\nthe lowest. To assess the interpretability and discriminative power of audio\nand video in fused activity recognition, PCA and t-SNE visualize feature\ncoherence over time. Classification results show limited performance for audio\nalone, moderate for video, and significant improvement with multimodal fusion,\nunderscoring the strengths of combined data. Incorporating RFID data, which\ncaptures sparse interactions asynchronously, further enhances recognition\naccuracy by over 50% and improves macro-averaged ROC-AUC. The framework\ndemonstrates the potential to transform raw, asynchronous sensor data into\naligned, semantically meaningful representations, providing a reproducible\napproach for multimodal data integration and interpretation in intelligent\nsystems designed to perceive complex human activities.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eCMU-MMAC\u6570\u636e\u5e93\u7684\u591a\u6a21\u6001\u4f20\u611f\u5668\u6570\u636e\u878d\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u9884\u5904\u7406\u3001\u7279\u5f81\u878d\u5408\u548c\u53ef\u89c6\u5316\u5206\u6790\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u81ea\u7136\u6761\u4ef6\u4e0b\u6536\u96c6\u7684\u591a\u6a21\u6001\u4f20\u611f\u5668\u6570\u636e\uff08\u89c6\u9891\u3001\u97f3\u9891\u3001RFID\uff09\u7684\u5f02\u6b65\u6027\u548c\u5f02\u6784\u6027\u95ee\u9898\uff0c\u63a2\u7d22\u5982\u4f55\u5c06\u8fd9\u4e9b\u539f\u59cb\u6570\u636e\u8f6c\u5316\u4e3a\u5bf9\u9f50\u7684\u3001\u6709\u8bed\u4e49\u610f\u4e49\u7684\u8868\u793a\uff0c\u4ee5\u63d0\u5347\u590d\u6742\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u7edf\u4e00\u9884\u5904\u7406\u6d41\u7a0b\u8fdb\u884c\u65f6\u95f4\u5bf9\u9f50\uff0c\u901a\u8fc7\u91cd\u91c7\u6837\u3001\u7070\u5ea6\u8f6c\u6362\u3001\u5206\u5272\u548c\u7279\u5f81\u6807\u51c6\u5316\u8fdb\u884c\u878d\u5408\uff0c\u4f7f\u7528\u70ed\u56fe\u3001\u9891\u8c31\u56fe\u548c\u6ce2\u5f62\u53e0\u52a0\u9a8c\u8bc1\u8bed\u4e49\u4e30\u5bcc\u6027\u548c\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u91c7\u7528PCA\u548ct-SNE\u8fdb\u884c\u7279\u5f81\u53ef\u89c6\u5316\u5206\u6790\u3002", "result": "\u665a\u671f\u878d\u5408\u83b7\u5f97\u6700\u9ad8\u9a8c\u8bc1\u51c6\u786e\u7387\uff0c\u6df7\u5408\u878d\u5408\u6b21\u4e4b\uff0c\u65e9\u671f\u878d\u5408\u6700\u5dee\uff1b\u97f3\u9891\u5355\u72ec\u5206\u7c7b\u6027\u80fd\u6709\u9650\uff0c\u89c6\u9891\u4e2d\u7b49\uff0c\u591a\u6a21\u6001\u878d\u5408\u663e\u8457\u63d0\u5347\uff1b\u52a0\u5165RFID\u6570\u636e\u540e\u8bc6\u522b\u51c6\u786e\u7387\u63d0\u9ad850%\u4ee5\u4e0a\uff0cROC-AUC\u4e5f\u5f97\u5230\u6539\u5584\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5c06\u539f\u59cb\u5f02\u6b65\u4f20\u611f\u5668\u6570\u636e\u8f6c\u5316\u4e3a\u5bf9\u9f50\u7684\u8bed\u4e49\u8868\u793a\uff0c\u4e3a\u667a\u80fd\u7cfb\u7edf\u4e2d\u591a\u6a21\u6001\u6570\u636e\u96c6\u6210\u548c\u89e3\u91ca\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u591a\u6a21\u6001\u878d\u5408\u5728\u590d\u6742\u4eba\u7c7b\u6d3b\u52a8\u611f\u77e5\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2510.21735", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.21735", "abs": "https://arxiv.org/abs/2510.21735", "authors": ["Yuhui Liu", "Shian Wang", "Ansel Panicker", "Kate Embry", "Ayana Asanova", "Tianyi Li"], "title": "A phase-aware AI car-following model for electric vehicles with adaptive cruise control: Development and validation using real-world data", "comment": null, "summary": "Internal combustion engine (ICE) vehicles and electric vehicles (EVs) exhibit\ndistinct vehicle dynamics. EVs provide rapid acceleration, with electric motors\nproducing peak power across a wider speed range, and achieve swift deceleration\nthrough regenerative braking. While existing microscopic models effectively\ncapture the driving behavior of ICE vehicles, a modeling framework that\naccurately describes the unique car-following dynamics of EVs is lacking.\nDeveloping such a model is essential given the increasing presence of EVs in\ntraffic, yet creating an easy-to-use and accurate analytical model remains\nchallenging.\n  To address these gaps, this study develops and validates a Phase-Aware AI\n(PAAI) car-following model specifically for EVs. The proposed model enhances\ntraditional physics-based frameworks with an AI component that recognizes and\nadapts to different driving phases, such as rapid acceleration and regenerative\nbraking. Using real-world trajectory data from vehicles equipped with adaptive\ncruise control (ACC), we conduct comprehensive simulations to validate the\nmodel's performance. The numerical results demonstrate that the PAAI model\nsignificantly improves prediction accuracy over traditional car-following\nmodels, providing an effective tool for accurately representing EV behavior in\ntraffic simulations.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u9488\u5bf9\u7535\u52a8\u6c7d\u8f66\u7684\u76f8\u4f4d\u611f\u77e5AI\u8ddf\u8f66\u6a21\u578b\uff0c\u901a\u8fc7AI\u7ec4\u4ef6\u8bc6\u522b\u4e0d\u540c\u9a7e\u9a76\u9636\u6bb5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4f20\u7edf\u8ddf\u8f66\u6a21\u578b\u5bf9\u7535\u52a8\u6c7d\u8f66\u884c\u4e3a\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u5fae\u89c2\u6a21\u578b\u80fd\u6709\u6548\u6355\u6349\u5185\u71c3\u673a\u8f66\u8f86\u884c\u4e3a\uff0c\u4f46\u7f3a\u4e4f\u51c6\u786e\u63cf\u8ff0\u7535\u52a8\u6c7d\u8f66\u72ec\u7279\u8ddf\u8f66\u52a8\u6001\u7684\u5efa\u6a21\u6846\u67b6\u3002\u968f\u7740\u7535\u52a8\u6c7d\u8f66\u5728\u4ea4\u901a\u4e2d\u65e5\u76ca\u589e\u591a\uff0c\u5f00\u53d1\u6613\u7528\u4e14\u51c6\u786e\u7684\u5206\u6790\u6a21\u578b\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u76f8\u4f4d\u611f\u77e5AI\u8ddf\u8f66\u6a21\u578b\uff0c\u5728\u4f20\u7edf\u7269\u7406\u6846\u67b6\u57fa\u7840\u4e0a\u52a0\u5165AI\u7ec4\u4ef6\uff0c\u8bc6\u522b\u548c\u9002\u5e94\u5feb\u901f\u52a0\u901f\u3001\u518d\u751f\u5236\u52a8\u7b49\u4e0d\u540c\u9a7e\u9a76\u9636\u6bb5\u3002\u4f7f\u7528\u914d\u5907\u81ea\u9002\u5e94\u5de1\u822a\u63a7\u5236\u8f66\u8f86\u7684\u771f\u5b9e\u8f68\u8ff9\u6570\u636e\u8fdb\u884c\u4eff\u771f\u9a8c\u8bc1\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0cPAAI\u6a21\u578b\u76f8\u6bd4\u4f20\u7edf\u8ddf\u8f66\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\uff0c\u4e3a\u4ea4\u901a\u4eff\u771f\u4e2d\u51c6\u786e\u8868\u793a\u7535\u52a8\u6c7d\u8f66\u884c\u4e3a\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f00\u53d1\u7684\u76f8\u4f4d\u611f\u77e5AI\u8ddf\u8f66\u6a21\u578b\u6210\u529f\u89e3\u51b3\u4e86\u7535\u52a8\u6c7d\u8f66\u72ec\u7279\u52a8\u6001\u7279\u6027\u7684\u5efa\u6a21\u95ee\u9898\uff0c\u4e3a\u4ea4\u901a\u4eff\u771f\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u7535\u52a8\u6c7d\u8f66\u884c\u4e3a\u8868\u793a\u65b9\u6cd5\u3002"}}
{"id": "2510.21848", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.21848", "abs": "https://arxiv.org/abs/2510.21848", "authors": ["Eric Hics", "Vinhthuy Phan", "Kriangsiri Malasri"], "title": "Enhancing Student Performance Prediction In CS1 Via In-Class Coding", "comment": null, "summary": "Computer science's increased recognition as a prominent field of study has\nattracted students with diverse academic backgrounds. This has significantly\nincreased the already high failure rates in introductory courses. To address\nthis challenge, it is essential to identify struggling students early on.\nIncorporating in-class coding exercises in these courses not only offers\nadditional practice opportunities to students but may also reveal their\nabilities and help teachers identify those in need of assistance. In this work,\nwe seek to determine the extent to which the practice of using in-class coding\nexercises enhances the ability to predict student performance, especially early\nin the semester. Based on data obtained in a CS1 course taught at a mid-size\nAmerican university, we found that in-class exercises could improve the\nprediction of students' eventual performance. In particular, we found\nrelatively accurately predictions as early as academic weeks 3 through 5,\nmaking it possible to devise early intervention strategies. This work can\nbenefit future studies on the impact of in-class exercises as well as\nintervention strategies throughout the semester.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bfe\u5802\u7f16\u7a0b\u7ec3\u4e60\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5bf9\u5b66\u751f\u8868\u73b0\u7684\u65e9\u671f\u9884\u6d4b\u80fd\u529b\uff0c\u5728\u5b66\u671f\u7b2c3-5\u5468\u5c31\u80fd\u76f8\u5bf9\u51c6\u786e\u5730\u9884\u6d4b\u5b66\u751f\u6700\u7ec8\u6210\u7ee9\uff0c\u4e3a\u65e9\u671f\u5e72\u9884\u63d0\u4f9b\u53ef\u80fd\u3002", "motivation": "\u8ba1\u7b97\u673a\u79d1\u5b66\u8bfe\u7a0b\u5438\u5f15\u4e86\u4e0d\u540c\u5b66\u672f\u80cc\u666f\u7684\u5b66\u751f\uff0c\u5bfc\u81f4\u5165\u95e8\u8bfe\u7a0b\u7684\u9ad8\u5931\u8d25\u7387\u3002\u9700\u8981\u65e9\u671f\u8bc6\u522b\u5b66\u4e60\u56f0\u96be\u5b66\u751f\uff0c\u8bfe\u5802\u7f16\u7a0b\u7ec3\u4e60\u65e2\u80fd\u63d0\u4f9b\u7ec3\u4e60\u673a\u4f1a\uff0c\u53c8\u80fd\u5e2e\u52a9\u6559\u5e08\u8bc6\u522b\u9700\u8981\u5e2e\u52a9\u7684\u5b66\u751f\u3002", "method": "\u57fa\u4e8e\u7f8e\u56fd\u4e00\u6240\u4e2d\u7b49\u89c4\u6a21\u5927\u5b66CS1\u8bfe\u7a0b\u7684\u6570\u636e\uff0c\u5206\u6790\u8bfe\u5802\u7f16\u7a0b\u7ec3\u4e60\u5bf9\u5b66\u751f\u8868\u73b0\u9884\u6d4b\u80fd\u529b\u7684\u5f71\u54cd\u3002", "result": "\u8bfe\u5802\u7f16\u7a0b\u7ec3\u4e60\u80fd\u591f\u6539\u5584\u5bf9\u5b66\u751f\u6700\u7ec8\u8868\u73b0\u7684\u9884\u6d4b\uff0c\u7279\u522b\u662f\u5728\u5b66\u671f\u7b2c3-5\u5468\u5c31\u80fd\u83b7\u5f97\u76f8\u5bf9\u51c6\u786e\u7684\u9884\u6d4b\u7ed3\u679c\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u6709\u52a9\u4e8e\u672a\u6765\u5173\u4e8e\u8bfe\u5802\u7ec3\u4e60\u5f71\u54cd\u548c\u5b66\u671f\u5e72\u9884\u7b56\u7565\u7684\u7814\u7a76\uff0c\u4e3a\u65e9\u671f\u8bc6\u522b\u548c\u5e2e\u52a9\u5b66\u4e60\u56f0\u96be\u5b66\u751f\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2510.21855", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "I.2; I.2.7; I.2.11"], "pdf": "https://arxiv.org/pdf/2510.21855", "abs": "https://arxiv.org/abs/2510.21855", "authors": ["Ryan Zhang", "Herbert Woisetscl\u00e4ger"], "title": "SIGN: Schema-Induced Games for Naming", "comment": "AAAI 2026 Student Abstract (Oral). Code available ar\n  https://github.com/ryanzhangofficial/schema-induced-games-for-naming", "summary": "Real-world AI systems are tackling increasingly complex problems, often\nthrough interactions among large language model (LLM) agents. When these agents\ndevelop inconsistent conventions, coordination can break down. Applications\nsuch as collaborative coding and distributed planning therefore require\nreliable, consistent communication, and scalability is a central concern as\nsystems grow. We introduce Schema-Induced Games for Naming (SIGN), a naming\ngame that examines how lightweight structure can steer convention formation. We\ncompare schema-induced communication to unconstrained natural language and find\nfaster convergence with up to 5.8x higher agreement. These results suggest that\nminimal structure can act as a simple control knob for efficient multi-agent\ncoordination, pointing toward broader applications beyond the naming game.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aSIGN\u7684\u547d\u540d\u6e38\u620f\uff0c\u901a\u8fc7\u5f15\u5165\u8f7b\u91cf\u7ea7\u7ed3\u6784\u6765\u5f15\u5bfc\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u7ea6\u5b9a\u5f62\u6210\uff0c\u76f8\u6bd4\u65e0\u7ea6\u675f\u81ea\u7136\u8bed\u8a00\u901a\u4fe1\uff0c\u80fd\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u548c\u9ad8\u8fbe5.8\u500d\u7684\u534f\u8bae\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u5b9eAI\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u95ee\u9898\u65f6\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u7ea6\u5b9a\u4f1a\u5bfc\u81f4\u534f\u8c03\u5931\u8d25\u3002\u534f\u4f5c\u7f16\u7801\u548c\u5206\u5e03\u5f0f\u89c4\u5212\u7b49\u5e94\u7528\u9700\u8981\u53ef\u9760\u3001\u4e00\u81f4\u7684\u901a\u4fe1\uff0c\u4e14\u7cfb\u7edf\u6269\u5c55\u6027\u662f\u5173\u952e\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Schema-Induced Games for Naming (SIGN)\u547d\u540d\u6e38\u620f\uff0c\u901a\u8fc7\u5f15\u5165\u8f7b\u91cf\u7ea7\u7ed3\u6784\u6765\u5f15\u5bfc\u7ea6\u5b9a\u5f62\u6210\uff0c\u5e76\u4e0e\u65e0\u7ea6\u675f\u81ea\u7136\u8bed\u8a00\u901a\u4fe1\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u76f8\u6bd4\u65e0\u7ea6\u675f\u81ea\u7136\u8bed\u8a00\uff0cschema\u8bf1\u5bfc\u7684\u901a\u4fe1\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\uff0c\u534f\u8bae\u4e00\u81f4\u6027\u63d0\u9ad8\u4e865.8\u500d\u3002", "conclusion": "\u6700\u5c0f\u5316\u7ed3\u6784\u53ef\u4ee5\u4f5c\u4e3a\u591a\u667a\u80fd\u4f53\u534f\u8c03\u7684\u7b80\u5355\u63a7\u5236\u673a\u5236\uff0c\u5b9e\u73b0\u9ad8\u6548\u534f\u8c03\uff0c\u8fd9\u4e00\u65b9\u6cd5\u5728\u547d\u540d\u6e38\u620f\u4e4b\u5916\u5177\u6709\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.21984", "categories": ["cs.SI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.21984", "abs": "https://arxiv.org/abs/2510.21984", "authors": ["Faria Huq", "Elijah L. Claggett", "Hirokazu Shirado"], "title": "From Social Division to Cohesion with AI Message Suggestions in Online Chat Groups", "comment": "Preprint, Under Review", "summary": "Social cohesion is difficult to sustain in societies marked by opinion\ndiversity, particularly in online communication. As large language model\n(LLM)-driven messaging assistance becomes increasingly embedded in these\ncontexts, it raises critical questions about its societal impact. We present an\nonline experiment with 557 participants who engaged in multi-round discussions\non politically controversial topics while freely reconfiguring their discussion\ngroups. In some conditions, participants received real-time message suggestions\ngenerated by an LLM, either personalized to the individual or adapted to their\ngroup context. We find that subtle shifts in linguistic style during\ncommunication, mediated by AI assistance, can scale up to reshape collective\nstructures. While individual-focused assistance leads users to segregate into\nlike-minded groups, relational assistance that incorporates group members'\nstances enhances cohesion through more receptive exchanges. These findings\ndemonstrate that AI-mediated communication can support social cohesion in\ndiverse groups, but outcomes critically depend on how personalization is\ndesigned.", "AI": {"tldr": "LLM\u9a71\u52a8\u7684\u6d88\u606f\u5efa\u8bae\u901a\u8fc7\u6539\u53d8\u8bed\u8a00\u98ce\u683c\u5f71\u54cd\u7fa4\u4f53\u7ed3\u6784\uff1a\u4e2a\u6027\u5316\u5efa\u8bae\u5bfc\u81f4\u89c2\u70b9\u9694\u79bb\uff0c\u800c\u8003\u8651\u7fa4\u4f53\u7acb\u573a\u7684\u5efa\u8bae\u589e\u5f3a\u51dd\u805a\u529b\u3002", "motivation": "\u7814\u7a76LLM\u8f85\u52a9\u901a\u4fe1\u5728\u793e\u4f1a\u591a\u6837\u6027\u73af\u5883\u4e2d\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u5982\u4f55\u7ef4\u6301\u793e\u4f1a\u51dd\u805a\u529b\u65b9\u9762\u3002", "method": "557\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u591a\u8f6e\u653f\u6cbb\u8bdd\u9898\u8ba8\u8bba\uff0c\u53ef\u81ea\u7531\u91cd\u7ec4\u8ba8\u8bba\u7ec4\uff0c\u90e8\u5206\u6761\u4ef6\u83b7\u5f97\u5b9e\u65f6LLM\u6d88\u606f\u5efa\u8bae\uff08\u4e2a\u6027\u5316\u6216\u7fa4\u4f53\u9002\u5e94\uff09\u3002", "result": "\u4e2a\u6027\u5316\u5efa\u8bae\u4f7f\u7528\u6237\u9694\u79bb\u5230\u5fd7\u540c\u9053\u5408\u7684\u7fa4\u4f53\uff0c\u800c\u5173\u7cfb\u578b\u5efa\u8bae\u901a\u8fc7\u66f4\u5305\u5bb9\u7684\u4ea4\u6d41\u589e\u5f3a\u51dd\u805a\u529b\u3002", "conclusion": "AI\u4e2d\u4ecb\u901a\u4fe1\u80fd\u652f\u6301\u591a\u6837\u5316\u7fa4\u4f53\u7684\u793e\u4f1a\u51dd\u805a\u529b\uff0c\u4f46\u7ed3\u679c\u5173\u952e\u53d6\u51b3\u4e8e\u4e2a\u6027\u5316\u8bbe\u8ba1\u7684\u65b9\u5f0f\u3002"}}
{"id": "2510.13148", "categories": ["econ.EM", "econ.TH", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.13148", "abs": "https://arxiv.org/abs/2510.13148", "authors": ["Tatsuru Kikuchi"], "title": "Nonparametric Identification of Spatial Treatment Effect Boundaries: Evidence from Bank Branch Consolidation", "comment": "61 pages, 8 figures, 9 tables", "summary": "I develop a nonparametric framework for identifying spatial boundaries of\ntreatment effects without imposing parametric functional form restrictions. The\nmethod employs local linear regression with data-driven bandwidth selection to\nflexibly estimate spatial decay patterns and detect treatment effect\nboundaries. Monte Carlo simulations demonstrate that the nonparametric approach\nexhibits lower bias and correctly identifies the absence of boundaries when\nnone exist, unlike parametric methods that may impose spurious spatial\npatterns. I apply this framework to bank branch openings during 2015--2020,\nmatching 5,743 new branches to 5.9 million mortgage applications across 14,209\ncensus tracts. The analysis reveals that branch proximity significantly affects\nloan application volume (8.5\\% decline per 10 miles) but not approval rates,\nconsistent with branches stimulating demand through local presence while credit\ndecisions remain centralized. Examining branch survival during the digital\ntransformation era (2010--2023), I find a non-monotonic relationship with area\nincome: high-income areas experience more closures despite conventional wisdom.\nThis counterintuitive pattern reflects strategic consolidation of redundant\nbranches in over-banked wealthy urban areas rather than discrimination against\npoor neighborhoods. Controlling for branch density, urbanization, and\ncompetition, the direct income effect diminishes substantially, with branch\ndensity emerging as the primary determinant of survival. These findings\ndemonstrate the necessity of flexible nonparametric methods for detecting\ncomplex spatial patterns that parametric models would miss, and challenge\nsimplistic narratives about banking deserts by revealing the organizational\ncomplexity underlying spatial consolidation decisions.", "AI": {"tldr": "\u5f00\u53d1\u975e\u53c2\u6570\u6846\u67b6\u8bc6\u522b\u7a7a\u95f4\u8fb9\u754c\uff0c\u5e94\u7528\u4e8e\u94f6\u884c\u5206\u652f\u673a\u6784\u5206\u6790\uff0c\u53d1\u73b0\u8d37\u6b3e\u7533\u8bf7\u91cf\u968f\u8ddd\u79bb\u8870\u51cf\u4f46\u5ba1\u6279\u7387\u4e0d\u53d8\uff0c\u63ed\u793a\u9ad8\u6536\u5165\u5730\u533a\u53cd\u800c\u6709\u66f4\u591a\u5206\u652f\u673a\u6784\u5173\u95ed\u7684\u53cd\u76f4\u89c9\u6a21\u5f0f\u3002", "motivation": "\u4f20\u7edf\u53c2\u6570\u65b9\u6cd5\u53ef\u80fd\u5f3a\u52a0\u865a\u5047\u7684\u7a7a\u95f4\u6a21\u5f0f\uff0c\u9700\u8981\u7075\u6d3b\u7684\u975e\u53c2\u6570\u65b9\u6cd5\u6765\u68c0\u6d4b\u590d\u6742\u7684\u7a7a\u95f4\u6a21\u5f0f\uff0c\u907f\u514d\u53c2\u6570\u6a21\u578b\u7684\u9650\u5236\u3002", "method": "\u4f7f\u7528\u6570\u636e\u9a71\u52a8\u5e26\u5bbd\u9009\u62e9\u7684\u5c40\u90e8\u7ebf\u6027\u56de\u5f52\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6a21\u62df\u9a8c\u8bc1\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e94\u7528\u4e8e2015-2020\u5e74\u94f6\u884c\u5206\u652f\u673a\u6784\u5f00\u4e1a\u548c2010-2023\u5e74\u751f\u5b58\u5206\u6790\u3002", "result": "\u5206\u652f\u673a\u6784\u90bb\u8fd1\u663e\u8457\u5f71\u54cd\u8d37\u6b3e\u7533\u8bf7\u91cf\uff08\u6bcf10\u82f1\u91cc\u4e0b\u964d8.5%\uff09\uff0c\u4f46\u4e0d\u5f71\u54cd\u5ba1\u6279\u7387\uff1b\u9ad8\u6536\u5165\u5730\u533a\u7ecf\u5386\u66f4\u591a\u5173\u95ed\uff0c\u8fd9\u4e0e\u4f20\u7edf\u8ba4\u77e5\u76f8\u53cd\uff1b\u63a7\u5236\u5206\u652f\u5bc6\u5ea6\u540e\uff0c\u76f4\u63a5\u6536\u5165\u6548\u5e94\u5927\u5e45\u51cf\u5f31\u3002", "conclusion": "\u975e\u53c2\u6570\u65b9\u6cd5\u5bf9\u4e8e\u68c0\u6d4b\u53c2\u6570\u6a21\u578b\u4f1a\u9519\u8fc7\u7684\u590d\u6742\u7a7a\u95f4\u6a21\u5f0f\u662f\u5fc5\u8981\u7684\uff0c\u6311\u6218\u4e86\u5173\u4e8e\u94f6\u884c\u6c99\u6f20\u7684\u7b80\u5355\u53d9\u8ff0\uff0c\u63ed\u793a\u4e86\u7a7a\u95f4\u6574\u5408\u51b3\u7b56\u80cc\u540e\u7684\u7ec4\u7ec7\u590d\u6742\u6027\u3002"}}
{"id": "2510.23421", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.23421", "abs": "https://arxiv.org/abs/2510.23421", "authors": ["Claudio Pirrone", "Stefano Fricano", "Gioacchino Fazio"], "title": "Exploring Vulnerability in AI Industry", "comment": "Preliminary Draft", "summary": "The rapid ascent of Foundation Models (FMs), enabled by the Transformer\narchitecture, drives the current AI ecosystem. Characterized by large-scale\ntraining and downstream adaptability, FMs (as GPT family) have achieved massive\npublic adoption, fueling a turbulent market shaped by platform economics and\nintense investment. Assessing the vulnerability of this fast-evolving industry\nis critical yet challenging due to data limitations. This paper proposes a\nsynthetic AI Vulnerability Index (AIVI) focusing on the upstream value chain\nfor FM production, prioritizing publicly available data. We model FM output as\na function of five inputs: Compute, Data, Talent, Capital, and Energy,\nhypothesizing that supply vulnerability in any input threatens the industry.\nKey vulnerabilities include compute concentration, data scarcity and legal\nrisks, talent bottlenecks, capital intensity and strategic dependencies, as\nwell as escalating energy demands. Acknowledging imperfect input\nsubstitutability, we propose a weighted geometrical average of aggregate\nsubindexes, normalized using theoretical or empirical benchmarks. Despite\nlimitations and room for improvement, this preliminary index aims to quantify\nsystemic risks in AI's core production engine, and implicitly shed a light on\nthe risks for downstream value chain.", "AI": {"tldr": "\u63d0\u51fa\u5408\u6210AI\u8106\u5f31\u6027\u6307\u6570(AIVI)\u6765\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u4ea7\u4e1a\u7684\u4e0a\u6e38\u4ef7\u503c\u94fe\u8106\u5f31\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u8ba1\u7b97\u3001\u6570\u636e\u3001\u4eba\u624d\u3001\u8d44\u672c\u548c\u80fd\u6e90\u4e94\u4e2a\u8f93\u5165\u8981\u7d20\u7684\u4f9b\u5e94\u98ce\u9669\u3002", "motivation": "\u57fa\u7840\u6a21\u578b(FMs)\u7684\u5feb\u901f\u53d1\u5c55\u9a71\u52a8\u7740\u5f53\u524dAI\u751f\u6001\u7cfb\u7edf\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u9650\u5236\uff0c\u8bc4\u4f30\u8fd9\u4e2a\u5feb\u901f\u6f14\u8fdb\u4ea7\u4e1a\u7684\u8106\u5f31\u6027\u5177\u6709\u6311\u6218\u6027\u3002\u9700\u8981\u91cf\u5316AI\u6838\u5fc3\u751f\u4ea7\u5f15\u64ce\u7684\u7cfb\u7edf\u6027\u98ce\u9669\u3002", "method": "\u5c06\u57fa\u7840\u6a21\u578b\u4ea7\u51fa\u5efa\u6a21\u4e3a\u8ba1\u7b97\u3001\u6570\u636e\u3001\u4eba\u624d\u3001\u8d44\u672c\u548c\u80fd\u6e90\u4e94\u4e2a\u8f93\u5165\u7684\u51fd\u6570\uff0c\u4f7f\u7528\u52a0\u6743\u51e0\u4f55\u5e73\u5747\u6cd5\u805a\u5408\u5404\u5b50\u6307\u6570\uff0c\u91c7\u7528\u7406\u8bba\u6216\u7ecf\u9a8c\u57fa\u51c6\u8fdb\u884c\u5f52\u4e00\u5316\u3002", "result": "\u8bc6\u522b\u51fa\u5173\u952e\u8106\u5f31\u6027\u5305\u62ec\u8ba1\u7b97\u96c6\u4e2d\u5ea6\u3001\u6570\u636e\u7a00\u7f3a\u6027\u548c\u6cd5\u5f8b\u98ce\u9669\u3001\u4eba\u624d\u74f6\u9888\u3001\u8d44\u672c\u5bc6\u96c6\u5ea6\u548c\u6218\u7565\u4f9d\u8d56\uff0c\u4ee5\u53ca\u4e0d\u65ad\u589e\u957f\u7684\u80fd\u6e90\u9700\u6c42\u3002", "conclusion": "\u5c3d\u7ba1\u5b58\u5728\u5c40\u9650\u6027\uff0c\u8fd9\u4e2a\u521d\u6b65\u6307\u6570\u65e8\u5728\u91cf\u5316AI\u6838\u5fc3\u751f\u4ea7\u5f15\u64ce\u7684\u7cfb\u7edf\u6027\u98ce\u9669\uff0c\u5e76\u95f4\u63a5\u63ed\u793a\u4e0b\u6e38\u4ef7\u503c\u94fe\u7684\u98ce\u9669\u3002"}}
{"id": "2510.22702", "categories": ["cs.AI", "cs.CV", "cs.ET", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.22702", "abs": "https://arxiv.org/abs/2510.22702", "authors": ["Mithul Chander", "Sai Pragnya Ranga", "Prathamesh Mayekar"], "title": "Atlas Urban Index: A VLM-Based Approach for Spatially and Temporally Calibrated Urban Development Monitoring", "comment": "An abridged version of this paper will be presented at and appear in\n  the Proceedings of ACM IKDD CODS 2025", "summary": "We introduce the {\\em Atlas Urban Index} (AUI), a metric for measuring urban\ndevelopment computed using Sentinel-2 \\citep{spoto2012sentinel2} satellite\nimagery. Existing approaches, such as the {\\em Normalized Difference Built-up\nIndex} (NDBI), often struggle to accurately capture urban development due to\nfactors like atmospheric noise, seasonal variation, and cloud cover. These\nlimitations hinder large-scale monitoring of human development and\nurbanization. To address these challenges, we propose an approach that\nleverages {\\em Vision-Language Models }(VLMs) to provide a development score\nfor regions. Specifically, we collect a time series of Sentinel-2 images for\neach region. Then, we further process the images within fixed time windows to\nget an image with minimal cloud cover, which serves as the representative image\nfor that time window. To ensure consistent scoring, we adopt two strategies:\n(i) providing the VLM with a curated set of reference images representing\ndifferent levels of urbanization, and (ii) supplying the most recent past image\nto both anchor temporal consistency and mitigate cloud-related noise in the\ncurrent image. Together, these components enable AUI to overcome the challenges\nof traditional urbanization indices and produce more reliable and stable\ndevelopment scores. Our qualitative experiments on Bangalore suggest that AUI\noutperforms standard indices such as NDBI.", "AI": {"tldr": "\u63d0\u51faAtlas Urban Index (AUI)\u6307\u6807\uff0c\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548cSentinel-2\u536b\u661f\u56fe\u50cf\u6765\u66f4\u51c6\u786e\u5730\u6d4b\u91cf\u57ce\u5e02\u53d1\u5c55\uff0c\u514b\u670d\u4f20\u7edf\u6307\u6570\u5982NDBI\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5982NDBI\u7531\u4e8e\u5927\u6c14\u566a\u58f0\u3001\u5b63\u8282\u53d8\u5316\u548c\u4e91\u5c42\u8986\u76d6\u7b49\u56e0\u7d20\uff0c\u96be\u4ee5\u51c6\u786e\u6355\u6349\u57ce\u5e02\u53d1\u5c55\uff0c\u963b\u788d\u4e86\u5927\u89c4\u6a21\u4eba\u7c7b\u53d1\u5c55\u548c\u57ce\u5e02\u5316\u76d1\u6d4b\u3002", "method": "\u6536\u96c6\u533a\u57df\u7684\u65f6\u95f4\u5e8f\u5217Sentinel-2\u56fe\u50cf\uff0c\u5728\u56fa\u5b9a\u65f6\u95f4\u7a97\u53e3\u5185\u5904\u7406\u56fe\u50cf\u4ee5\u83b7\u5f97\u4e91\u5c42\u8986\u76d6\u6700\u5c11\u7684\u4ee3\u8868\u6027\u56fe\u50cf\uff0c\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u53d1\u5c55\u8bc4\u5206\uff0c\u5e76\u91c7\u7528\u53c2\u8003\u56fe\u50cf\u96c6\u548c\u6700\u8fd1\u5386\u53f2\u56fe\u50cf\u6765\u786e\u4fdd\u8bc4\u5206\u4e00\u81f4\u6027\u3002", "result": "\u5728\u73ed\u52a0\u7f57\u5c14\u7684\u5b9a\u6027\u5b9e\u9a8c\u8868\u660e\uff0cAUI\u4f18\u4e8eNDBI\u7b49\u6807\u51c6\u6307\u6570\u3002", "conclusion": "AUI\u80fd\u591f\u514b\u670d\u4f20\u7edf\u57ce\u5e02\u5316\u6307\u6570\u7684\u6311\u6218\uff0c\u4ea7\u751f\u66f4\u53ef\u9760\u548c\u7a33\u5b9a\u7684\u53d1\u5c55\u8bc4\u5206\u3002"}}
{"id": "2510.22884", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.22884", "abs": "https://arxiv.org/abs/2510.22884", "authors": ["Federico Crippa"], "title": "Identification, Estimation, and Inference in Two-Sided Interaction Models", "comment": null, "summary": "This paper studies a class of models for two-sided interactions, where\noutcomes depend on latent characteristics of two distinct agent types. Models\nin this class have two core elements: the matching network, which records which\nagent pairs interact, and the interaction function, which maps latent\ncharacteristics of these agents to outcomes and determines the role of\ncomplementarities. I introduce the Tukey model, which captures\ncomplementarities with a single interaction parameter, along with two\nextensions that allow richer complementarity patterns. First, I establish an\nidentification trade-off between the flexibility of the interaction function\nand the density of the matching network: the Tukey model is identified under\nmild conditions, whereas the more flexible extensions require dense networks\nthat are rarely observed in applications. Second, I propose a cycle-based\nestimator for the Tukey interaction parameter and show that it is consistent\nand asymptotically normal even when the network is sparse. Third, I use its\nasymptotic distribution to construct a formal test of no complementarities.\nFinally, an empirical illustration shows that the Tukey model recovers\neconomically meaningful complementarities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u53cc\u8fb9\u4ea4\u4e92\u6a21\u578b\uff0c\u5f15\u5165Tukey\u6a21\u578b\u6355\u6349\u4e92\u8865\u6027\uff0c\u5206\u6790\u8bc6\u522b\u7075\u6d3b\u6027vs\u7f51\u7edc\u5bc6\u5ea6\u7684\u6743\u8861\uff0c\u63d0\u51fa\u57fa\u4e8e\u5faa\u73af\u7684\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e92\u8865\u6027\u68c0\u9a8c\u3002", "motivation": "\u7814\u7a76\u53cc\u8fb9\u4ea4\u4e92\u6a21\u578b\u4e2d\u4e92\u8865\u6027\u7684\u8bc6\u522b\u548c\u4f30\u8ba1\u95ee\u9898\uff0c\u73b0\u6709\u6a21\u578b\u5728\u7075\u6d3b\u6027\u548c\u7f51\u7edc\u5bc6\u5ea6\u8981\u6c42\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "method": "\u5f15\u5165Tukey\u6a21\u578b\u53ca\u5176\u6269\u5c55\uff0c\u5efa\u7acb\u8bc6\u522b\u7406\u8bba\uff0c\u63d0\u51fa\u57fa\u4e8e\u5faa\u73af\u7684\u4f30\u8ba1\u5668\uff0c\u6784\u5efa\u4e92\u8865\u6027\u68c0\u9a8c\u3002", "result": "Tukey\u6a21\u578b\u5728\u7a00\u758f\u7f51\u7edc\u4e0b\u53ef\u8bc6\u522b\uff0c\u4f30\u8ba1\u5668\u5177\u6709\u4e00\u81f4\u6027\u548c\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u5b9e\u8bc1\u5e94\u7528\u663e\u793a\u80fd\u6062\u590d\u6709\u7ecf\u6d4e\u610f\u4e49\u7684\u4e92\u8865\u6027\u3002", "conclusion": "Tukey\u6a21\u578b\u4e3a\u53cc\u8fb9\u4ea4\u4e92\u4e2d\u7684\u4e92\u8865\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bc6\u522b\u548c\u4f30\u8ba1\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u7a00\u758f\u7f51\u7edc\u73af\u5883\u3002"}}
{"id": "2510.22020", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.22020", "abs": "https://arxiv.org/abs/2510.22020", "authors": ["Mohamed Shamseldein"], "title": "A Hybrid GNN-LSE Method for Fast, Robust, and Physically-Consistent AC Power Flow", "comment": null, "summary": "Conventional AC Power Flow (ACPF) solvers like Newton-Raphson (NR) face\nsignificant computational and convergence challenges in modern, large-scale\npower systems. This paper proposes a novel, two-stage hybrid method that\nintegrates a Physics-Informed Graph Neural Network (GNN) with a robust,\niterative Linear State Estimation (LSE) refinement step to produce fast and\nphysically-consistent solutions. The GNN, trained with a physics-informed loss\nfunction featuring an efficient dynamic weighting scheme, rapidly predicts a\nhigh-quality initial system state. This prediction is then refined using an\niterative, direct linear solver inspired by state estimation techniques. This\nLSE refinement step solves a series of linear equations to enforce physical\nlaws, effectively bypassing the non-linearities and convergence issues of\ntraditional solvers. The proposed GNN-LSE framework is comprehensively\nvalidated on systems ranging from small radial distribution networks (IEEE\n33-bus, 69-bus) to a large, meshed transmission system (IEEE 118-bus). Results\nshow that our GNN variants are up to $8.4 \\times 10^3$ times faster than NR.\nThe LSE refinement provides a fast route to a physically-consistent solution,\nwhile heavy-loading stress tests (120%-150% of nominal) and N-1 contingencies\ndemonstrate the method's reliability and generalization. This work presents a\npowerful and flexible framework for bridging fast, data-driven models with the\nrigorous constraints of power system physics, offering a practical tool for\nreal-time operations and analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u7ebf\u6027\u72b6\u6001\u4f30\u8ba1\u7684\u4e24\u9636\u6bb5\u6df7\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u5feb\u901f\u6c42\u89e3\u4ea4\u6d41\u6f6e\u6d41\u95ee\u9898\uff0c\u76f8\u6bd4\u4f20\u7edf\u725b\u987f-\u62c9\u592b\u900a\u6cd5\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe8400\u500d\u3002", "motivation": "\u4f20\u7edf\u4ea4\u6d41\u6f6e\u6d41\u6c42\u89e3\u5668\u5728\u5927\u578b\u7535\u529b\u7cfb\u7edf\u4e2d\u9762\u4e34\u8ba1\u7b97\u590d\u6742\u548c\u6536\u655b\u56f0\u96be\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u53ef\u9760\u7684\u6c42\u89e3\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7269\u7406\u4fe1\u606f\u56fe\u795e\u7ecf\u7f51\u7edc\u5feb\u901f\u9884\u6d4b\u521d\u59cb\u7cfb\u7edf\u72b6\u6001\uff0c\u7136\u540e\u901a\u8fc7\u8fed\u4ee3\u7ebf\u6027\u72b6\u6001\u4f30\u8ba1\u7cbe\u70bc\u6b65\u9aa4\u6765\u5f3a\u5236\u6267\u884c\u7269\u7406\u5b9a\u5f8b\uff0c\u7ed5\u8fc7\u4f20\u7edf\u6c42\u89e3\u5668\u7684\u975e\u7ebf\u6027\u95ee\u9898\u3002", "result": "\u5728IEEE 33\u300169\u3001118\u603b\u7ebf\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\uff0cGNN\u53d8\u4f53\u6bd4\u725b\u987f-\u62c9\u592b\u900a\u6cd5\u5feb8400\u500d\uff0c\u91cd\u8f7d\u5e94\u529b\u6d4b\u8bd5\u548cN-1\u4e8b\u6545\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5730\u5c06\u5feb\u901f\u6570\u636e\u9a71\u52a8\u6a21\u578b\u4e0e\u7535\u529b\u7cfb\u7edf\u7269\u7406\u7ea6\u675f\u76f8\u7ed3\u5408\uff0c\u4e3a\u5b9e\u65f6\u64cd\u4f5c\u548c\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2510.22482", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.22482", "abs": "https://arxiv.org/abs/2510.22482", "authors": ["Qianhan Zeng", "Miao Han", "Ke Xu", "Feifei Wang", "Hansheng Wang"], "title": "Doubly Smoothed Density Estimation with Application on Miners' Unsafe Act Detection", "comment": null, "summary": "We study anomaly detection in images under a fixed-camera environment and\npropose a \\emph{doubly smoothed} (DS) density estimator that exploits spatial\nstructure to improve estimation accuracy. The DS estimator applies kernel\nsmoothing twice: first over the value domain to obtain location-wise classical\nnonparametric density (CD) estimates, and then over the spatial domain to\nborrow information from neighboring locations. Under appropriate regularity\nconditions, we show that the DS estimator achieves smaller asymptotic bias,\nvariance, and mean squared error than the CD estimator. To address the\nincreased computational cost of the DS estimator, we introduce a grid point\napproximation (GPA) technique that reduces the computation cost of inference\nwithout sacrificing the estimation accuracy. A rule-of-thumb bandwidth is\nderived for practical use. Extensive simulations show that GPA-DS achieves the\nlowest MSE with near real-time speed. In a large-scale case study on\nunderground mine surveillance, GPA-DS enables remarkable sub-image extraction\nof anomalous regions after which a lightweight MobileNet classifier achieves\n$\\approx$99\\% out-of-sample accuracy for unsafe act detection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u91cd\u5e73\u6ed1\u5bc6\u5ea6\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u4e24\u6b21\u6838\u5e73\u6ed1\u6765\u6539\u8fdb\u56fa\u5b9a\u6444\u50cf\u5934\u73af\u5883\u4e0b\u7684\u56fe\u50cf\u5f02\u5e38\u68c0\u6d4b\uff0c\u5e76\u5f15\u5165\u7f51\u683c\u70b9\u8fd1\u4f3c\u6280\u672f\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5728\u56fa\u5b9a\u6444\u50cf\u5934\u73af\u5883\u4e0b\u8fdb\u884c\u56fe\u50cf\u5f02\u5e38\u68c0\u6d4b\u65f6\uff0c\u9700\u8981\u5229\u7528\u7a7a\u95f4\u7ed3\u6784\u6765\u63d0\u9ad8\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u540c\u65f6\u89e3\u51b3\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u53cc\u91cd\u5e73\u6ed1\u5bc6\u5ea6\u4f30\u8ba1\u5668\uff1a\u5148\u5728\u503c\u57df\u8fdb\u884c\u6838\u5e73\u6ed1\u5f97\u5230\u4f4d\u7f6e\u5bc6\u5ea6\u4f30\u8ba1\uff0c\u518d\u5728\u7a7a\u95f4\u57df\u8fdb\u884c\u6838\u5e73\u6ed1\u501f\u7528\u90bb\u8fd1\u4f4d\u7f6e\u4fe1\u606f\u3002\u5f15\u5165\u7f51\u683c\u70b9\u8fd1\u4f3c\u6280\u672f\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793aDS\u4f30\u8ba1\u5668\u6bd4\u7ecf\u5178\u975e\u53c2\u6570\u5bc6\u5ea6\u4f30\u8ba1\u5668\u6709\u66f4\u5c0f\u7684\u6e10\u8fd1\u504f\u5dee\u3001\u65b9\u5dee\u548c\u5747\u65b9\u8bef\u5dee\u3002\u6a21\u62df\u5b9e\u9a8c\u8868\u660eGPA-DS\u5b9e\u73b0\u4e86\u6700\u4f4eMSE\u4e14\u63a5\u8fd1\u5b9e\u65f6\u901f\u5ea6\u3002\u5728\u5730\u4e0b\u77ff\u4e95\u76d1\u63a7\u6848\u4f8b\u4e2d\uff0cGPA-DS\u80fd\u6709\u6548\u63d0\u53d6\u5f02\u5e38\u5b50\u56fe\u50cf\uff0cMobileNet\u5206\u7c7b\u5668\u8fbe\u5230\u7ea699%\u7684\u6837\u672c\u5916\u51c6\u786e\u7387\u3002", "conclusion": "\u53cc\u91cd\u5e73\u6ed1\u5bc6\u5ea6\u4f30\u8ba1\u5668\u7ed3\u5408\u7f51\u683c\u70b9\u8fd1\u4f3c\u6280\u672f\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u56fe\u50cf\u5f02\u5e38\u68c0\u6d4b\u7684\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.21736", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.21736", "abs": "https://arxiv.org/abs/2510.21736", "authors": ["Yuhui Liu", "Samannita Halder", "Shian Wang", "Tianyi Li"], "title": "Learn2Drive: A neural network-based framework for socially compliant automated vehicle control", "comment": null, "summary": "This study introduces a novel control framework for adaptive cruise control\n(ACC) in automated driving, leveraging Long Short-Term Memory (LSTM) networks\nand physics-informed constraints. As automated vehicles (AVs) adopt advanced\nfeatures like ACC, transportation systems are becoming increasingly intelligent\nand efficient. However, existing AV control strategies primarily focus on\noptimizing the performance of individual vehicles or platoons, often neglecting\ntheir interactions with human-driven vehicles (HVs) and the broader impact on\ntraffic flow. This oversight can exacerbate congestion and reduce overall\nsystem efficiency. To address this critical research gap, we propose a neural\nnetwork-based, socially compliant AV control framework that incorporates social\nvalue orientation (SVO). This framework enables AVs to account for their\ninfluence on HVs and traffic dynamics. By leveraging AVs as mobile traffic\nregulators, the proposed approach promotes adaptive driving behaviors that\nreduce congestion, improve traffic efficiency, and lower energy consumption.\nWithin this framework, we define utility functions for both AVs and HVs, which\nare optimized based on the SVO of each AV to balance its own control objectives\nwith broader traffic flow considerations. Numerical results demonstrate the\neffectiveness of the proposed method in adapting to varying traffic conditions,\nthereby enhancing system-wide efficiency. Specifically, when the AV's control\nmode shifts from prioritizing energy consumption to optimizing traffic flow\nefficiency, vehicles in the following platoon experience at least a 58.99%\nincrease in individual energy consumption alongside at least a 38.39%\nimprovement in individual average speed, indicating significant enhancements in\ntraffic dynamics.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLSTM\u548c\u7269\u7406\u7ea6\u675f\u7684\u81ea\u9002\u5e94\u5de1\u822a\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u793e\u4f1a\u4ef7\u503c\u53d6\u5411(SVO)\u4f7f\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u8003\u8651\u5bf9\u4eba\u5de5\u9a7e\u9a76\u8f66\u8f86\u548c\u4ea4\u901a\u6d41\u7684\u5f71\u54cd\uff0c\u63d0\u5347\u4ea4\u901a\u6548\u7387\u548c\u964d\u4f4e\u80fd\u8017\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u9a7e\u9a76\u63a7\u5236\u7b56\u7565\u4e3b\u8981\u5173\u6ce8\u5355\u4e2a\u8f66\u8f86\u6216\u8f66\u961f\u7684\u6027\u80fd\u4f18\u5316\uff0c\u5ffd\u89c6\u4e86\u4e0e\u4eba\u5de5\u9a7e\u9a76\u8f66\u8f86\u7684\u4e92\u52a8\u53ca\u5176\u5bf9\u4ea4\u901a\u6d41\u7684\u6574\u4f53\u5f71\u54cd\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u62e5\u5835\u52a0\u5267\u548c\u7cfb\u7edf\u6548\u7387\u964d\u4f4e\u3002", "method": "\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u548c\u793e\u4f1a\u4ef7\u503c\u53d6\u5411(SVO)\u6784\u5efa\u793e\u4f1a\u5408\u89c4\u7684\u81ea\u52a8\u9a7e\u9a76\u63a7\u5236\u6846\u67b6\uff0c\u5b9a\u4e49AV\u548cHV\u7684\u6548\u7528\u51fd\u6570\uff0c\u57fa\u4e8eSVO\u5e73\u8861\u4e2a\u4f53\u63a7\u5236\u76ee\u6807\u4e0e\u4ea4\u901a\u6d41\u8003\u8651\u3002", "result": "\u5f53AV\u63a7\u5236\u6a21\u5f0f\u4ece\u4f18\u5148\u80fd\u8017\u8f6c\u5411\u4f18\u5316\u4ea4\u901a\u6d41\u6548\u7387\u65f6\uff0c\u8ddf\u968f\u8f66\u961f\u8f66\u8f86\u4e2a\u4f53\u80fd\u8017\u589e\u52a0\u81f3\u5c1158.99%\uff0c\u540c\u65f6\u4e2a\u4f53\u5e73\u5747\u901f\u5ea6\u63d0\u5347\u81f3\u5c1138.39%\uff0c\u663e\u8457\u6539\u5584\u4ea4\u901a\u52a8\u6001\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u9002\u5e94\u4e0d\u540c\u4ea4\u901a\u6761\u4ef6\uff0c\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u7ea7\u6548\u7387\uff0c\u8bc1\u660eAV\u4f5c\u4e3a\u79fb\u52a8\u4ea4\u901a\u8c03\u8282\u5668\u7684\u6f5c\u529b\uff0c\u53ef\u51cf\u5c11\u62e5\u5835\u3001\u63d0\u9ad8\u4ea4\u901a\u6548\u7387\u5e76\u964d\u4f4e\u80fd\u8017\u3002"}}
{"id": "2510.21851", "categories": ["cs.CY", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.21851", "abs": "https://arxiv.org/abs/2510.21851", "authors": ["Babaniyi Olaniyi", "Ina Kalisa", "Ana Fern\u00e1ndez del R\u00edo", "Jean Marie Vianney Hakizayezu", "Enric Jan\u00e9", "Eniola Olaleye", "Juan Francisco Garamendi", "Ivan Nazarov", "Aditya Rastogi", "Mateo Diaz-Quiroz", "\u00c1frica Peri\u00e1\u00f1ez", "Regis Hitimana"], "title": "Data-Driven Approach to Capitation Reform in Rwanda", "comment": null, "summary": "As part of Rwanda's transition toward universal health coverage, the national\nCommunity-Based Health Insurance (CBHI) scheme is moving from retrospective\nfee-for-service reimbursements to prospective capitation payments for public\nprimary healthcare providers. This report outlines a data-driven approach to\ndesigning, calibrating, and monitoring the capitation model using\nindividual-level claims data from the Intelligent Health Benefits System\n(IHBS). We introduce a transparent, interpretable formula for allocating\npayments to Health Centers and their affiliated Health Posts. The formula is\nbased on catchment population, service utilization patterns, and patient\ninflows, with parameters estimated via regression models calibrated on national\nclaims data. Repeated validation exercises show the payment scheme closely\naligns with historical spending while promoting fairness and adaptability\nacross diverse facilities. In addition to payment design, the same dataset\nenables actionable behavioral insights. We highlight the use case of monitoring\nantibiotic prescribing patterns, particularly in pediatric care, to flag\npotential overuse and guideline deviations. Together, these capabilities lay\nthe groundwork for a learning health financing system: one that connects\ndigital infrastructure, resource allocation, and service quality to support\ncontinuous improvement and evidence-informed policy reform.", "AI": {"tldr": "\u5362\u65fa\u8fbe\u91c7\u7528\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u8bbe\u8ba1\u57fa\u4e8e\u4eba\u53e3\u7684\u9884\u4ed8\u5236\u652f\u4ed8\u6a21\u5f0f\uff0c\u53d6\u4ee3\u6309\u670d\u52a1\u4ed8\u8d39\uff0c\u4f7f\u7528\u7d22\u8d54\u6570\u636e\u5efa\u7acb\u900f\u660e\u652f\u4ed8\u516c\u5f0f\uff0c\u540c\u65f6\u76d1\u63a7\u6297\u751f\u7d20\u5904\u65b9\u884c\u4e3a\u4ee5\u63d0\u5347\u533b\u7597\u8d28\u91cf\u3002", "motivation": "\u5362\u65fa\u8fbe\u5411\u5168\u6c11\u5065\u5eb7\u8986\u76d6\u8fc7\u6e21\uff0c\u9700\u8981\u4ece\u6309\u670d\u52a1\u4ed8\u8d39\u8f6c\u5411\u9884\u4ed8\u5236\u652f\u4ed8\u6a21\u5f0f\uff0c\u4ee5\u4fc3\u8fdb\u516c\u5e73\u3001\u9002\u5e94\u6027\u548c\u6301\u7eed\u6539\u8fdb\u3002", "method": "\u4f7f\u7528\u667a\u80fd\u5065\u5eb7\u798f\u5229\u7cfb\u7edf\u7684\u4e2a\u4f53\u7ea7\u7d22\u8d54\u6570\u636e\uff0c\u901a\u8fc7\u56de\u5f52\u6a21\u578b\u6821\u51c6\u53c2\u6570\uff0c\u5efa\u7acb\u57fa\u4e8e\u670d\u52a1\u4eba\u53e3\u3001\u5229\u7528\u6a21\u5f0f\u548c\u60a3\u8005\u6d41\u5165\u7684\u900f\u660e\u652f\u4ed8\u516c\u5f0f\u3002", "result": "\u9a8c\u8bc1\u663e\u793a\u652f\u4ed8\u65b9\u6848\u4e0e\u5386\u53f2\u652f\u51fa\u9ad8\u5ea6\u4e00\u81f4\uff0c\u540c\u65f6\u4fc3\u8fdb\u8bbe\u65bd\u95f4\u7684\u516c\u5e73\u6027\u548c\u9002\u5e94\u6027\uff0c\u5e76\u80fd\u76d1\u63a7\u6297\u751f\u7d20\u5904\u65b9\u884c\u4e3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5b66\u4e60\u578b\u5065\u5eb7\u878d\u8d44\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\uff0c\u8fde\u63a5\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u3001\u8d44\u6e90\u5206\u914d\u548c\u670d\u52a1\u8d28\u91cf\uff0c\u652f\u6301\u6301\u7eed\u6539\u8fdb\u548c\u5faa\u8bc1\u653f\u7b56\u6539\u9769\u3002"}}
{"id": "2510.21866", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21866", "abs": "https://arxiv.org/abs/2510.21866", "authors": ["Javier Mar\u00edn"], "title": "Capability Ceilings in Autoregressive Language Models: Empirical Evidence from Knowledge-Intensive Tasks", "comment": "The experiments in this paper were performed in January 2024. Current\n  model architectures are considerably more complex than those presented here", "summary": "We document empirical capability ceilings in decoder-only autoregressive\nlanguage models across knowledge-intensive tasks. Systematic evaluation of OPT\nand Pythia model families (70M-30B parameters, spanning 240 times scaling)\nreveals that knowledge retrieval tasks show negligible accuracy improvement\ndespite smooth loss reduction. On MMLU mathematics benchmarks, accuracy remains\nflat at 19-20% (below 25% random chance) across all scales while cross-entropy\nloss decreases by 31%. In contrast, procedural tasks like arithmetic show\nconventional scaling where both metrics improve together. Attention\nintervention experiments reveal high sensitivity to perturbation: swapping\nattention patterns between models causes catastrophic performance collapse\n(complete accuracy loss) rather than graceful degradation. These measurements\nhave immediate engineering implications: for knowledge-intensive applications\nusing OPT and Pythia architectures, parameter scaling beyond 1-2B offers\nminimal accuracy gains despite continued loss improvement. Our findings\nquantify capability-specific scaling failures in these model families to inform\nresource allocation decisions. Whether these patterns reflect fundamental\nconstraints of decoder-only architectures or implementation-specific\nlimitations remains an open question requiring investigation across diverse\narchitectural approaches.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u89e3\u7801\u5668\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u5b58\u5728\u80fd\u529b\u4e0a\u9650\uff0c\u53c2\u6570\u89c4\u6a21\u6269\u5927\uff0870M-30B\uff09\u65f6\u77e5\u8bc6\u68c0\u7d22\u4efb\u52a1\u51c6\u786e\u7387\u51e0\u4e4e\u65e0\u63d0\u5347\uff0c\u800c\u6570\u5b66\u4efb\u52a1\u51c6\u786e\u7387\u4fdd\u6301\u7a33\u5b9a\u572819-20%\uff0c\u4f46\u635f\u5931\u51fd\u6570\u6301\u7eed\u4e0b\u964d\u3002", "motivation": "\u63a2\u7a76\u89e3\u7801\u5668\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u5728\u53c2\u6570\u89c4\u6a21\u6269\u5c55\u65f6\uff0c\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u7684\u6027\u80fd\u8868\u73b0\u5dee\u5f02\uff0c\u7279\u522b\u662f\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u662f\u5426\u771f\u6b63\u53d7\u76ca\u4e8e\u6a21\u578b\u89c4\u6a21\u6269\u5927\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30OPT\u548cPythia\u6a21\u578b\u5bb6\u65cf\uff0870M-30B\u53c2\u6570\uff09\uff0c\u5206\u6790\u77e5\u8bc6\u68c0\u7d22\u548c\u6570\u5b66\u4efb\u52a1\u7684\u51c6\u786e\u7387\u4e0e\u635f\u5931\u51fd\u6570\u53d8\u5316\uff0c\u5e76\u8fdb\u884c\u6ce8\u610f\u529b\u5e72\u9884\u5b9e\u9a8c\u3002", "result": "\u77e5\u8bc6\u68c0\u7d22\u4efb\u52a1\u51c6\u786e\u7387\u51e0\u4e4e\u65e0\u6539\u5584\uff0c\u6570\u5b66\u4efb\u52a1\u51c6\u786e\u7387\u7a33\u5b9a\u572819-20%\uff08\u4f4e\u4e8e25%\u968f\u673a\u6982\u7387\uff09\uff0c\u800c\u4ea4\u53c9\u71b5\u635f\u5931\u4e0b\u964d31%\u3002\u6ce8\u610f\u529b\u5e72\u9884\u5bfc\u81f4\u6027\u80fd\u707e\u96be\u6027\u5d29\u6e83\u3002", "conclusion": "\u5bf9\u4e8e\u4f7f\u7528OPT\u548cPythia\u67b6\u6784\u7684\u77e5\u8bc6\u5bc6\u96c6\u578b\u5e94\u7528\uff0c\u53c2\u6570\u89c4\u6a21\u8d85\u8fc71-2B\u5e26\u6765\u7684\u51c6\u786e\u7387\u63d0\u5347\u5fae\u4e4e\u5176\u5fae\uff0c\u5c3d\u7ba1\u635f\u5931\u51fd\u6570\u6301\u7eed\u6539\u5584\u3002\u8fd9\u4e9b\u53d1\u73b0\u63ed\u793a\u4e86\u7279\u5b9a\u80fd\u529b\u6269\u5c55\u5931\u8d25\u7684\u6a21\u5f0f\u3002"}}
{"id": "2510.22415", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.22415", "abs": "https://arxiv.org/abs/2510.22415", "authors": ["Zheng Wei", "Mingchen Li", "Junxiang Liao", "Zeyu Yang", "Xiaoyu Yang", "Yixuan Xie", "Pan Hui", "Huamin Qu"], "title": "Cross-Platform Short-Video Diplomacy: Topic and Sentiment Analysis of China-US Relations on Douyin and TikTok", "comment": "Accepted for publication at The International AAAI Conference on Web\n  and Social Media (ICWSM 2026)", "summary": "We examine discussions surrounding China-U.S. relations on the Chinese and\nAmerican social media platforms \\textit{Douyin} and \\textit{TikTok}. Both\nplatforms, owned by \\textit{ByteDance}, operate under different regulatory and\ncultural environments, providing a unique perspective for analyzing China-U.S.\npublic discourse. This study analyzed 4,040 videos and 338,209 user comments to\nassess the public discussions and sentiments on social media regarding\nChina-U.S. relations. Through topic clustering and sentiment analysis, we\nidentified key themes, including economic strength, technological and\nindustrial interdependence, cultural cognition and value pursuits, and\nresponses to global challenges. There are significant emotional differences\nbetween China and the US on various themes. Since April 2022, the Chinese\ngovernment has implemented a new regulation requiring all social media accounts\nto disclose their provincial-level geolocation information. Utilizing this\npublicly available data, along with factors such as GDP per capita, minority\nindex, and internet penetration rate, we investigate the changes in sentiment\ntowards the U.S. in mainland China. This study links socioeconomic indicators\nwith online discussions, deeply analyzing how regional and economic factors\ninfluence Chinese comments on their views of the US, providing important\ninsights for China-U.S. relationship research and policy making.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u6296\u97f3\u548cTikTok\u5e73\u53f0\u4e0a\u5173\u4e8e\u4e2d\u7f8e\u5173\u7cfb\u7684\u8ba8\u8bba\uff0c\u901a\u8fc7\u4e3b\u9898\u805a\u7c7b\u548c\u60c5\u611f\u5206\u6790\u53d1\u73b0\u4e24\u56fd\u5728\u591a\u4e2a\u4e3b\u9898\u4e0a\u5b58\u5728\u663e\u8457\u60c5\u611f\u5dee\u5f02\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e2d\u56fd\u5730\u533a\u793e\u4f1a\u7ecf\u6d4e\u56e0\u7d20\u5bf9\u6c11\u4f17\u5bf9\u7f8e\u6001\u5ea6\u7684\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u4e2d\u7f8e\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u4e0a\u5173\u4e8e\u4e24\u56fd\u5173\u7cfb\u7684\u516c\u4f17\u8ba8\u8bba\uff0c\u5229\u7528\u5b57\u8282\u8df3\u52a8\u65d7\u4e0b\u4f46\u8fd0\u8425\u73af\u5883\u4e0d\u540c\u7684\u6296\u97f3\u548cTikTok\u5e73\u53f0\uff0c\u5206\u6790\u4e0d\u540c\u76d1\u7ba1\u548c\u6587\u5316\u73af\u5883\u4e0b\u7684\u516c\u4f17\u8bdd\u8bed\u5dee\u5f02\u3002", "method": "\u5206\u6790\u4e864,040\u4e2a\u89c6\u9891\u548c338,209\u6761\u7528\u6237\u8bc4\u8bba\uff0c\u91c7\u7528\u4e3b\u9898\u805a\u7c7b\u548c\u60c5\u611f\u5206\u6790\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u4e2d\u56fd2022\u5e744\u6708\u5b9e\u65bd\u7684\u793e\u4ea4\u5a92\u4f53\u8d26\u53f7\u5730\u7406\u4f4d\u7f6e\u62ab\u9732\u89c4\u5b9a\uff0c\u7ed3\u5408\u4eba\u5747GDP\u3001\u5c11\u6570\u6c11\u65cf\u6307\u6570\u548c\u4e92\u8054\u7f51\u666e\u53ca\u7387\u7b49\u793e\u4f1a\u7ecf\u6d4e\u6307\u6807\u3002", "result": "\u8bc6\u522b\u51fa\u7ecf\u6d4e\u5b9e\u529b\u3001\u6280\u672f\u4e0e\u4ea7\u4e1a\u76f8\u4e92\u4f9d\u5b58\u3001\u6587\u5316\u8ba4\u77e5\u4e0e\u4ef7\u503c\u8ffd\u6c42\u3001\u5e94\u5bf9\u5168\u7403\u6311\u6218\u7b49\u5173\u952e\u4e3b\u9898\uff0c\u53d1\u73b0\u4e2d\u7f8e\u4e24\u56fd\u5728\u5404\u79cd\u4e3b\u9898\u4e0a\u5b58\u5728\u663e\u8457\u60c5\u611f\u5dee\u5f02\uff0c\u5e76\u63ed\u793a\u4e86\u5730\u533a\u793e\u4f1a\u7ecf\u6d4e\u56e0\u7d20\u5982\u4f55\u5f71\u54cd\u4e2d\u56fd\u6c11\u4f17\u5bf9\u7f8e\u56fd\u7684\u770b\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u793e\u4f1a\u7ecf\u6d4e\u6307\u6807\u4e0e\u5728\u7ebf\u8ba8\u8bba\u8054\u7cfb\u8d77\u6765\uff0c\u6df1\u5165\u5206\u6790\u4e86\u533a\u57df\u548c\u7ecf\u6d4e\u56e0\u7d20\u5982\u4f55\u5f71\u54cd\u4e2d\u56fd\u8bc4\u8bba\u5bf9\u7f8e\u56fd\u7684\u770b\u6cd5\uff0c\u4e3a\u4e2d\u7f8e\u5173\u7cfb\u7814\u7a76\u548c\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2510.14409", "categories": ["econ.EM", "econ.TH", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.14409", "abs": "https://arxiv.org/abs/2510.14409", "authors": ["Tatsuru Kikuchi"], "title": "Dynamic Spatial Treatment Effect Boundaries: A Continuous Functional Framework from Navier-Stokes Equations", "comment": "79 pages, 5 figures", "summary": "I develop a comprehensive theoretical framework for dynamic spatial treatment\neffect boundaries using continuous functional definitions grounded in\nNavier-Stokes partial differential equations. Rather than discrete treatment\neffect estimators, the framework characterizes treatment intensity as a\ncontinuous function $\\tau(\\mathbf{x}, t)$ over space-time, enabling rigorous\nanalysis of propagation dynamics, boundary evolution, and cumulative exposure\npatterns. Building on exact self-similar solutions expressible through Kummer\nconfluent hypergeometric and modified Bessel functions, I establish that\ntreatment effects follow scaling laws $\\tau(d, t) = t^{-\\alpha} f(d/t^\\beta)$\nwhere exponents characterize diffusion mechanisms. Empirical validation using\n42 million TROPOMI satellite observations of NO$_2$ pollution from U.S.\ncoal-fired power plants demonstrates strong exponential spatial decay\n($\\kappa_s = 0.004$ per km, $R^2 = 0.35$) with detectable boundaries at 572 km.\nMonte Carlo simulations confirm superior performance over discrete parametric\nmethods in boundary detection and false positive avoidance (94\\% vs 27\\%\ncorrect rejection). Regional heterogeneity analysis validates diagnostic\ncapability: positive decay parameters within 100 km confirm coal plant\ndominance; negative parameters beyond 100 km correctly signal when urban\nsources dominate. The continuous functional perspective unifies spatial\neconometrics with mathematical physics, providing theoretically grounded\nmethods for boundary detection, exposure quantification, and policy evaluation\nacross environmental economics, banking, and healthcare applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8eNavier-Stokes\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u52a8\u6001\u7a7a\u95f4\u5904\u7406\u6548\u5e94\u8fb9\u754c\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u5904\u7406\u5f3a\u5ea6\u5b9a\u4e49\u4e3a\u65f6\u7a7a\u8fde\u7eed\u51fd\u6570\uff0c\u5efa\u7acb\u4e86\u5177\u6709\u5c3a\u5ea6\u4e0d\u53d8\u6027\u7684\u5904\u7406\u6548\u5e94\u4f20\u64ad\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u536b\u661f\u6570\u636e\u548c\u8499\u7279\u5361\u6d1b\u6a21\u62df\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u4f20\u7edf\u79bb\u6563\u5904\u7406\u6548\u5e94\u4f30\u8ba1\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u6355\u6349\u7a7a\u95f4\u5904\u7406\u6548\u5e94\u7684\u52a8\u6001\u4f20\u64ad\u548c\u8fb9\u754c\u6f14\u5316\u7279\u5f81\uff0c\u9700\u8981\u5efa\u7acb\u8fde\u7eed\u51fd\u6570\u6846\u67b6\u6765\u7edf\u4e00\u5206\u6790\u5904\u7406\u6548\u5e94\u7684\u4f20\u64ad\u52a8\u529b\u5b66\u3001\u8fb9\u754c\u6f14\u5316\u548c\u7d2f\u79ef\u66b4\u9732\u6a21\u5f0f\u3002", "method": "\u57fa\u4e8eNavier-Stokes\u504f\u5fae\u5206\u65b9\u7a0b\u5efa\u7acb\u8fde\u7eed\u51fd\u6570\u6846\u67b6\uff0c\u5229\u7528Kummer\u5408\u6d41\u8d85\u51e0\u4f55\u51fd\u6570\u548c\u4fee\u6b63\u8d1d\u585e\u5c14\u51fd\u6570\u7684\u7cbe\u786e\u81ea\u76f8\u4f3c\u89e3\uff0c\u63a8\u5bfc\u5904\u7406\u6548\u5e94\u7684\u5c3a\u5ea6\u5b9a\u5f8b\uff0c\u5e76\u901a\u8fc74200\u4e07TROPOMI\u536b\u661f\u89c2\u6d4b\u6570\u636e\u548c\u8499\u7279\u5361\u6d1b\u6a21\u62df\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u5b9e\u8bc1\u663e\u793aNO2\u6c61\u67d3\u5448\u73b0\u5f3a\u6307\u6570\u7a7a\u95f4\u8870\u51cf\uff08\u03bas=0.004/km\uff0cR\u00b2=0.35\uff09\uff0c\u53ef\u68c0\u6d4b\u8fb9\u754c\u8fbe572km\u3002\u8499\u7279\u5361\u6d1b\u6a21\u62df\u8bc1\u5b9e\u8be5\u65b9\u6cd5\u5728\u8fb9\u754c\u68c0\u6d4b\u548c\u5047\u9633\u6027\u907f\u514d\u65b9\u9762\u4f18\u4e8e\u79bb\u6563\u53c2\u6570\u65b9\u6cd5\uff0894% vs 27%\u6b63\u786e\u62d2\u7edd\u7387\uff09\u3002\u533a\u57df\u5f02\u8d28\u6027\u5206\u6790\u9a8c\u8bc1\u4e86\u8bca\u65ad\u80fd\u529b\u3002", "conclusion": "\u8fde\u7eed\u51fd\u6570\u89c6\u89d2\u7edf\u4e00\u4e86\u7a7a\u95f4\u8ba1\u91cf\u7ecf\u6d4e\u5b66\u4e0e\u6570\u5b66\u7269\u7406\uff0c\u4e3a\u73af\u5883\u7ecf\u6d4e\u5b66\u3001\u94f6\u884c\u548c\u533b\u7597\u7b49\u9886\u57df\u7684\u8fb9\u754c\u68c0\u6d4b\u3001\u66b4\u9732\u91cf\u5316\u548c\u653f\u7b56\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.23356", "categories": ["eess.SY", "cs.ET", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.23356", "abs": "https://arxiv.org/abs/2510.23356", "authors": ["Sandra Coello Suarez", "V. Sanchez Padilla", "Ronald Ponguillo-Intriago", "Albert Espinal"], "title": "IoT-Driven Smart Management in Broiler Farming: Simulation of Remote Sensing and Control Systems", "comment": "2025 IEEE Technology and Engineering Management Society Conference\n  (TEMSCON LATAM), Cartagena, Colombia", "summary": "Parameter monitoring and control systems are crucial in the industry as they\nenable automation processes that improve productivity and resource\noptimization. These improvements also help to manage environmental factors and\nthe complex interactions between multiple inputs and outputs required for\nproduction management. This paper proposes an automation system for broiler\nmanagement based on a simulation scenario that involves sensor networks and\nembedded systems. The aim is to create a transmission network for monitoring\nand controlling broiler temperature and feeding using the Internet of Things\n(IoT), complemented by a dashboard and a cloud-based service database to track\nimprovements in broiler management. We look forward this work will serve as a\nguide for stakeholders and entrepreneurs in the animal production industry,\nfostering sustainable development through simple and cost-effective automation\nsolutions. The goal is for them to scale and integrate these recommendations\ninto their existing operations, leading to more efficient decision-making at\nthe management level.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7269\u8054\u7f51\u7684\u8089\u9e21\u7ba1\u7406\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f20\u611f\u5668\u7f51\u7edc\u548c\u5d4c\u5165\u5f0f\u7cfb\u7edf\u76d1\u63a7\u6e29\u5ea6\u4e0e\u5582\u98df\uff0c\u4f7f\u7528\u4eea\u8868\u677f\u548c\u4e91\u6570\u636e\u5e93\u8ddf\u8e2a\u7ba1\u7406\u6539\u8fdb", "motivation": "\u53c2\u6570\u76d1\u63a7\u7cfb\u7edf\u5bf9\u5de5\u4e1a\u81ea\u52a8\u5316\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u63d0\u9ad8\u751f\u4ea7\u529b\u548c\u8d44\u6e90\u4f18\u5316\uff0c\u540c\u65f6\u7ba1\u7406\u73af\u5883\u56e0\u7d20\u548c\u590d\u6742\u8f93\u5165\u8f93\u51fa\u4ea4\u4e92", "method": "\u57fa\u4e8e\u6a21\u62df\u573a\u666f\u6784\u5efa\u7269\u8054\u7f51\u4f20\u8f93\u7f51\u7edc\uff0c\u7ed3\u5408\u4f20\u611f\u5668\u7f51\u7edc\u3001\u5d4c\u5165\u5f0f\u7cfb\u7edf\u3001\u4eea\u8868\u677f\u548c\u4e91\u6570\u636e\u5e93\u670d\u52a1", "result": "\u5f00\u53d1\u4e86\u8089\u9e21\u6e29\u5ea6\u4e0e\u5582\u98df\u76d1\u63a7\u63a7\u5236\u7cfb\u7edf\uff0c\u4e3a\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u53ef\u6301\u7eed\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848", "conclusion": "\u8be5\u5de5\u4f5c\u53ef\u4f5c\u4e3a\u52a8\u7269\u751f\u4ea7\u884c\u4e1a\u6307\u5357\uff0c\u901a\u8fc7\u7b80\u5355\u7ecf\u6d4e\u7684\u81ea\u52a8\u5316\u65b9\u6848\u4fc3\u8fdb\u53ef\u6301\u7eed\u53d1\u5c55\uff0c\u5e2e\u52a9\u73b0\u6709\u8fd0\u8425\u5b9e\u73b0\u66f4\u9ad8\u6548\u51b3\u7b56"}}
{"id": "2510.23347", "categories": ["econ.EM", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.23347", "abs": "https://arxiv.org/abs/2510.23347", "authors": ["Shovon Sengupta", "Sunny Kumar Singh", "Tanujit Chakraborty"], "title": "Macroeconomic Forecasting for the G7 countries under Uncertainty Shocks", "comment": null, "summary": "Accurate macroeconomic forecasting has become harder amid geopolitical\ndisruptions, policy reversals, and volatile financial markets. Conventional\nvector autoregressions (VARs) overfit in high dimensional settings, while\nthreshold VARs struggle with time varying interdependencies and complex\nparameter structures. We address these limitations by extending the Sims Zha\nBayesian VAR with exogenous variables (SZBVARx) to incorporate domain-informed\nshrinkage and four newspaper based uncertainty shocks such as economic policy\nuncertainty, geopolitical risk, US equity market volatility, and US monetary\npolicy uncertainty. The framework improves structural interpretability,\nmitigates dimensionality, and imposes empirically guided regularization. Using\nG7 data, we study spillovers from uncertainty shocks to five core variables\n(unemployment, real broad effective exchange rates, short term rates, oil\nprices, and CPI inflation), combining wavelet coherence (time frequency\ndynamics) with nonlinear local projections (state dependent impulse responses).\nOut-of-sample results at 12 and 24 month horizons show that SZBVARx outperforms\n14 benchmarks, including classical VARs and leading machine learning models, as\nconfirmed by Murphy difference diagrams, multivariate Diebold Mariano tests,\nand Giacomini White predictability tests. Credible Bayesian prediction\nintervals deliver robust uncertainty quantification for scenario analysis and\nrisk management. The proposed SZBVARx offers G7 policymakers a transparent,\nwell calibrated tool for modern macroeconomic forecasting under pervasive\nuncertainty.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u7684Sims Zha\u8d1d\u53f6\u65afVAR\u6a21\u578b(SZBVARx)\uff0c\u901a\u8fc7\u6574\u5408\u9886\u57df\u77e5\u8bc6\u7684\u6536\u7f29\u5148\u9a8c\u548c\u56db\u79cd\u57fa\u4e8e\u65b0\u95fb\u7684\u4e0d\u786e\u5b9a\u6027\u51b2\u51fb\uff0c\u6539\u8fdb\u4e86\u5b8f\u89c2\u7ecf\u6d4e\u9884\u6d4b\u5728\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u4f20\u7edfVAR\u6a21\u578b\u5728\u9ad8\u7ef4\u8bbe\u5b9a\u4e0b\u5bb9\u6613\u8fc7\u62df\u5408\uff0c\u800c\u9608\u503cVAR\u96be\u4ee5\u5904\u7406\u65f6\u53d8\u4f9d\u8d56\u5173\u7cfb\u548c\u590d\u6742\u53c2\u6570\u7ed3\u6784\u3002\u5728\u5f53\u4eca\u5730\u7f18\u653f\u6cbb\u52a8\u8361\u3001\u653f\u7b56\u9006\u8f6c\u548c\u91d1\u878d\u5e02\u573a\u6ce2\u52a8\u7684\u80cc\u666f\u4e0b\uff0c\u51c6\u786e\u7684\u5b8f\u89c2\u7ecf\u6d4e\u9884\u6d4b\u53d8\u5f97\u66f4\u52a0\u56f0\u96be\u3002", "method": "\u6269\u5c55Sims Zha\u8d1d\u53f6\u65afVAR\u6a21\u578b\uff0c\u52a0\u5165\u5916\u751f\u53d8\u91cf\u548c\u56db\u79cd\u57fa\u4e8e\u65b0\u95fb\u7684\u4e0d\u786e\u5b9a\u6027\u51b2\u51fb(\u7ecf\u6d4e\u653f\u7b56\u4e0d\u786e\u5b9a\u6027\u3001\u5730\u7f18\u653f\u6cbb\u98ce\u9669\u3001\u7f8e\u56fd\u80a1\u5e02\u6ce2\u52a8\u6027\u3001\u7f8e\u56fd\u8d27\u5e01\u653f\u7b56\u4e0d\u786e\u5b9a\u6027)\uff0c\u7ed3\u5408\u5c0f\u6ce2\u76f8\u5e72\u6027\u5206\u6790\u548c\u975e\u7ebf\u6027\u5c40\u90e8\u6295\u5f71\u65b9\u6cd5\u3002", "result": "\u5728G7\u56fd\u5bb6\u768412\u4e2a\u6708\u548c24\u4e2a\u6708\u9884\u6d4b\u4e2d\uff0cSZBVARx\u6a21\u578b\u4f18\u4e8e14\u4e2a\u57fa\u51c6\u6a21\u578b\uff0c\u5305\u62ec\u4f20\u7edfVAR\u548c\u9886\u5148\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u7edf\u8ba1\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "conclusion": "SZBVARx\u4e3aG7\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u900f\u660e\u3001\u6821\u51c6\u826f\u597d\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u5728\u666e\u904d\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u8fdb\u884c\u73b0\u4ee3\u5b8f\u89c2\u7ecf\u6d4e\u9884\u6d4b\u548c\u98ce\u9669\u7ba1\u7406\u3002"}}
{"id": "2510.22029", "categories": ["eess.SY", "cs.SY", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.22029", "abs": "https://arxiv.org/abs/2510.22029", "authors": ["Rezvan Alamian", "S\u00f6ren M\u00fcller", "Uwe Steinmetz", "Christian Henrich", "Stefan Goetz"], "title": "High-Performance Rotor Cooling with Ducted Liquid in Completely Cold-Formed Modular Motor Shaft", "comment": "11 pages, 21 figures", "summary": "This paper suggests a novel rotor-cooling shaft concept for high-performance\nelectric motors that increases the effectiveness of cooling and is yet simple\nand cost-effective to manufacture. We investigate the thermal performance of\nfour shaft geometries for rotor cooling in automotive applications. The\nproposed tooth-guided liquid-cooling shaft design aims to solve the high\nchurning loss of conventional cooled rotor shafts due to internal vortex\nformation and their still limited heat transfer. Therefore, we optimize heat\ntransfer efficiency and pressure management by incorporating cold-formed\ninternal channels that restrict vortex formation beyond a degree that improves\nheat transfer. We evaluated key performance metrics, including heat transfer\nrate, outlet temperature, pressure drop, and velocity profiles, under varying\nrotational speeds, inlet flow rates, and coolant temperatures. Computational\nfluid analysis demonstrates that the tooth-guided design outperforms\nconventional hollow shafts and achieves up to 110% higher cooling efficiency at\nlow rotational speeds, while it maintains comparable pressure levels. These\nfindings provide practical insight into geometry-driven thermal optimization\nand offer a path toward improving the performance and durability of electric\nmotors.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u8f6c\u5b50\u51b7\u5374\u8f74\u6982\u5ff5\uff0c\u901a\u8fc7\u9f7f\u5f62\u5f15\u5bfc\u6db2\u4f53\u51b7\u5374\u8bbe\u8ba1\u63d0\u9ad8\u51b7\u5374\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5236\u9020\u7b80\u5355\u548c\u6210\u672c\u6548\u76ca\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u51b7\u5374\u8f6c\u5b50\u8f74\u56e0\u5185\u90e8\u6da1\u6d41\u5f62\u6210\u5bfc\u81f4\u7684\u9ad8\u6405\u52a8\u635f\u5931\u548c\u6709\u9650\u4f20\u70ed\u95ee\u9898\uff0c\u63d0\u9ad8\u7535\u52a8\u6c7d\u8f66\u7535\u673a\u7684\u6027\u80fd\u548c\u8010\u4e45\u6027\u3002", "method": "\u7814\u7a76\u56db\u79cd\u8f74\u51e0\u4f55\u5f62\u72b6\u7684\u70ed\u6027\u80fd\uff0c\u91c7\u7528\u51b7\u6210\u578b\u5185\u90e8\u901a\u9053\u4f18\u5316\u4f20\u70ed\u6548\u7387\u548c\u538b\u529b\u7ba1\u7406\uff0c\u9650\u5236\u6da1\u6d41\u5f62\u6210\u3002\u901a\u8fc7\u8ba1\u7b97\u6d41\u4f53\u5206\u6790\u8bc4\u4f30\u5173\u952e\u6027\u80fd\u6307\u6807\u3002", "result": "\u9f7f\u5f62\u5f15\u5bfc\u8bbe\u8ba1\u5728\u4f4e\u8f6c\u901f\u4e0b\u6bd4\u4f20\u7edf\u7a7a\u5fc3\u8f74\u7684\u51b7\u5374\u6548\u7387\u63d0\u9ad8110%\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u538b\u529b\u6c34\u5e73\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u51e0\u4f55\u9a71\u52a8\u7684\u70ed\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\uff0c\u4e3a\u63d0\u9ad8\u7535\u673a\u6027\u80fd\u548c\u8010\u4e45\u6027\u63d0\u4f9b\u4e86\u8def\u5f84\u3002"}}
{"id": "2510.22550", "categories": ["stat.AP", "stat.OT"], "pdf": "https://arxiv.org/pdf/2510.22550", "abs": "https://arxiv.org/abs/2510.22550", "authors": ["Jinbo Niu"], "title": "Regularization method in the variable selection for logistic regression on BRFSS data", "comment": null, "summary": "Stroke remains a leading cause of death and disability worldwide, yet\neffective prediction of stroke risk using large-scale population data remains\nchallenging due to data imbalance and high-dimensional features. In this study,\nwe develop and evaluate regularized logistic regression models for stroke\nprediction using data from the 2022 Behavioral Risk Factor Surveillance System\n(BRFSS), comprising 445132 U.S. adult respondents and 328 health-related\nvariables. To address data imbalance, we apply several resampling techniques\nincluding oversampling, undersampling, class weighting, and the Synthetic\nMinority Oversampling Technique (SMOTE). We further employ Lasso, Elastic Net,\nand Group Lasso regularization methods to perform feature selection and\ndimensionality reduction. Model performance is assessed using ROC-AUC,\nsensitivity, and specificity metrics. Among all methods, the Lasso-based model\nachieved the highest predictive performance (AUC = 0.761), while the Group\nLasso method identified a compact set of key predictors: Age, Heart Disease,\nPhysical Health, and Dental Health. These findings demonstrate the potential of\nregularized regression techniques for interpretable and efficient prediction of\nstroke risk from large-scale behavioral health data.", "AI": {"tldr": "\u4f7f\u7528\u6b63\u5219\u5316\u903b\u8f91\u56de\u5f52\u6a21\u578b\u9884\u6d4b\u4e2d\u98ce\u98ce\u9669\uff0c\u901a\u8fc7\u591a\u79cd\u91cd\u91c7\u6837\u6280\u672f\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0cLasso\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff08AUC=0.761\uff09\uff0cGroup Lasso\u8bc6\u522b\u51fa\u5e74\u9f84\u3001\u5fc3\u810f\u75c5\u3001\u8eab\u4f53\u5065\u5eb7\u548c\u7259\u9f7f\u5065\u5eb7\u7b49\u5173\u952e\u9884\u6d4b\u56e0\u5b50\u3002", "motivation": "\u4e2d\u98ce\u662f\u5168\u7403\u4e3b\u8981\u7684\u6b7b\u4ea1\u548c\u81f4\u6b8b\u539f\u56e0\uff0c\u4f46\u4f7f\u7528\u5927\u89c4\u6a21\u4eba\u7fa4\u6570\u636e\u8fdb\u884c\u4e2d\u98ce\u98ce\u9669\u9884\u6d4b\u9762\u4e34\u6570\u636e\u4e0d\u5e73\u8861\u548c\u9ad8\u7ef4\u7279\u5f81\u7684\u6311\u6218\u3002", "method": "\u4f7f\u75282022\u5e74\u884c\u4e3a\u98ce\u9669\u56e0\u7d20\u76d1\u6d4b\u7cfb\u7edf\u7684445,132\u540d\u7f8e\u56fd\u6210\u5e74\u4eba\u6570\u636e\u548c328\u4e2a\u5065\u5eb7\u76f8\u5173\u53d8\u91cf\uff0c\u5e94\u7528\u8fc7\u91c7\u6837\u3001\u6b20\u91c7\u6837\u3001\u7c7b\u522b\u52a0\u6743\u548cSMOTE\u7b49\u91cd\u91c7\u6837\u6280\u672f\uff0c\u91c7\u7528Lasso\u3001\u5f39\u6027\u7f51\u7edc\u548cGroup Lasso\u6b63\u5219\u5316\u65b9\u6cd5\u8fdb\u884c\u7279\u5f81\u9009\u62e9\u548c\u964d\u7ef4\u3002", "result": "Lasso\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff08AUC=0.761\uff09\uff0cGroup Lasso\u65b9\u6cd5\u8bc6\u522b\u51fa\u5e74\u9f84\u3001\u5fc3\u810f\u75c5\u3001\u8eab\u4f53\u5065\u5eb7\u548c\u7259\u9f7f\u5065\u5eb7\u7b49\u5173\u952e\u9884\u6d4b\u56e0\u5b50\u3002", "conclusion": "\u6b63\u5219\u5316\u56de\u5f52\u6280\u672f\u5177\u6709\u4ece\u5927\u89c4\u6a21\u884c\u4e3a\u5065\u5eb7\u6570\u636e\u4e2d\u8fdb\u884c\u53ef\u89e3\u91ca\u4e14\u9ad8\u6548\u7684\u4e2d\u98ce\u98ce\u9669\u9884\u6d4b\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.21739", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.21739", "abs": "https://arxiv.org/abs/2510.21739", "authors": ["Liangqi Yuan", "Chuhao Deng", "Dong-Jun Han", "Inseok Hwang", "Sabine Brunswicker", "Christopher G. Brinton"], "title": "Next-Generation LLM for UAV: From Natural Language to Autonomous Flight", "comment": null, "summary": "With the rapid advancement of Large Language Models (LLMs), their\ncapabilities in various automation domains, particularly Unmanned Aerial\nVehicle (UAV) operations, have garnered increasing attention. Current research\nremains predominantly constrained to small-scale UAV applications, with most\nstudies focusing on isolated components such as path planning for toy drones,\nwhile lacking comprehensive investigation of medium- and long-range UAV systems\nin real-world operational contexts. Larger UAV platforms introduce distinct\nchallenges, including stringent requirements for airport-based take-off and\nlanding procedures, adherence to complex regulatory frameworks, and specialized\noperational capabilities with elevated mission expectations. This position\npaper presents the Next-Generation LLM for UAV (NeLV) system -- a comprehensive\ndemonstration and automation roadmap for integrating LLMs into multi-scale UAV\noperations. The NeLV system processes natural language instructions to\norchestrate short-, medium-, and long-range UAV missions through five key\ntechnical components: (i) LLM-as-Parser for instruction interpretation, (ii)\nRoute Planner for Points of Interest (POI) determination, (iii) Path Planner\nfor waypoint generation, (iv) Control Platform for executable trajectory\nimplementation, and (v) UAV monitoring. We demonstrate the system's feasibility\nthrough three representative use cases spanning different operational scales:\nmulti-UAV patrol, multi-POI delivery, and multi-hop relocation. Beyond the\ncurrent implementation, we establish a five-level automation taxonomy that\ncharts the evolution from current LLM-as-Parser capabilities (Level 1) to fully\nautonomous LLM-as-Autopilot systems (Level 5), identifying technical\nprerequisites and research challenges at each stage.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86NeLV\u7cfb\u7edf\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u591a\u5c3a\u5ea6\u65e0\u4eba\u673a\u64cd\u4f5c\u4e2d\uff0c\u901a\u8fc7\u4e94\u4e2a\u5173\u952e\u6280\u672f\u7ec4\u4ef6\u5904\u7406\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u6765\u534f\u8c03\u77ed\u3001\u4e2d\u3001\u8fdc\u7a0b\u65e0\u4eba\u673a\u4efb\u52a1\uff0c\u5e76\u5efa\u7acb\u4e86\u4e94\u7ea7\u81ea\u52a8\u5316\u5206\u7c7b\u6cd5\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8e\u5c0f\u578b\u65e0\u4eba\u673a\u5e94\u7528\uff0c\u7f3a\u4e4f\u5bf9\u4e2d\u8fdc\u7a0b\u65e0\u4eba\u673a\u7cfb\u7edf\u5728\u771f\u5b9e\u64cd\u4f5c\u73af\u5883\u4e2d\u7684\u5168\u9762\u7814\u7a76\u3002\u5927\u578b\u65e0\u4eba\u673a\u5e73\u53f0\u9762\u4e34\u8d77\u964d\u7a0b\u5e8f\u4e25\u683c\u3001\u6cd5\u89c4\u590d\u6742\u548c\u4efb\u52a1\u8981\u6c42\u9ad8\u7b49\u6311\u6218\u3002", "method": "NeLV\u7cfb\u7edf\u5305\u542b\u4e94\u4e2a\u6280\u672f\u7ec4\u4ef6\uff1aLLM\u89e3\u6790\u5668\u7528\u4e8e\u6307\u4ee4\u89e3\u91ca\u3001\u8def\u7ebf\u89c4\u5212\u5668\u786e\u5b9a\u5174\u8da3\u70b9\u3001\u8def\u5f84\u89c4\u5212\u5668\u751f\u6210\u822a\u70b9\u3001\u63a7\u5236\u5e73\u53f0\u5b9e\u73b0\u53ef\u6267\u884c\u8f68\u8ff9\u3001\u65e0\u4eba\u673a\u76d1\u63a7\u3002\u901a\u8fc7\u4e09\u4e2a\u4ee3\u8868\u6027\u7528\u4f8b\u9a8c\u8bc1\u7cfb\u7edf\u53ef\u884c\u6027\u3002", "result": "\u901a\u8fc7\u591a\u65e0\u4eba\u673a\u5de1\u903b\u3001\u591a\u5174\u8da3\u70b9\u914d\u9001\u548c\u591a\u8df3\u91cd\u5b9a\u4f4d\u4e09\u4e2a\u7528\u4f8b\u8bc1\u660e\u4e86\u7cfb\u7edf\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4ece\u5f53\u524dLLM\u4f5c\u4e3a\u89e3\u6790\u5668\u5230\u5b8c\u5168\u81ea\u4e3bLLM\u4f5c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u4e94\u7ea7\u81ea\u52a8\u5316\u6f14\u8fdb\u8def\u7ebf\u56fe\uff0c\u8bc6\u522b\u4e86\u5404\u9636\u6bb5\u7684\u6280\u672f\u524d\u63d0\u548c\u7814\u7a76\u6311\u6218\u3002"}}
{"id": "2510.22128", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.22128", "abs": "https://arxiv.org/abs/2510.22128", "authors": ["Yizhi Liu", "Balaji Padmanabhan", "Siva Viswanathan"], "title": "What Exactly is a Deepfake?", "comment": "69 pages, 2 figures", "summary": "Deepfake technologies are often associated with deception, misinformation,\nand identity fraud, raising legitimate societal concerns. Yet such narratives\nmay obscure a key insight: deepfakes embody sophisticated capabilities for\nsensory manipulation that can alter human perception, potentially enabling\nbeneficial applications in domains such as healthcare and education. Realizing\nthis potential, however, requires understanding how the technology is\nconceptualized across disciplines. This paper analyzes 826 peer-reviewed\npublications from 2017 to 2025 to examine how deepfakes are defined and\nunderstood in the literature. Using large language models for content analysis,\nwe categorize deepfake conceptualizations along three dimensions: Identity\nSource (the relationship between original and generated content), Intent\n(deceptive versus non-deceptive purposes), and Manipulation Granularity\n(holistic versus targeted modifications). Results reveal substantial\nheterogeneity that challenges simplified public narratives. Notably, a subset\nof studies discuss non-deceptive applications, highlighting an underexplored\npotential for social good. Temporal analysis shows an evolution from\npredominantly threat-focused views (2017 to 2019) toward recognition of\nbeneficial applications (2022 to 2025). This study provides an empirical\nfoundation for developing nuanced governance and research frameworks that\ndistinguish applications warranting prohibition from those deserving support,\nshowing that, with safeguards, deepfakes' realism can serve important social\npurposes beyond deception.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86826\u7bc72017-2025\u5e74\u7684\u540c\u884c\u8bc4\u5ba1\u6587\u732e\uff0c\u53d1\u73b0\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u7684\u6982\u5ff5\u5316\u5b58\u5728\u663e\u8457\u5f02\u8d28\u6027\uff0c\u6311\u6218\u4e86\u7b80\u5316\u7684\u516c\u5171\u53d9\u4e8b\uff0c\u63ed\u793a\u4e86\u975e\u6b3a\u9a97\u6027\u5e94\u7528\u7684\u793e\u4f1a\u4ef7\u503c\u6f5c\u529b\u3002", "motivation": "\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u901a\u5e38\u4e0e\u6b3a\u9a97\u3001\u9519\u8bef\u4fe1\u606f\u548c\u8eab\u4efd\u6b3a\u8bc8\u76f8\u5173\u8054\uff0c\u4f46\u53ef\u80fd\u63a9\u76d6\u4e86\u4e00\u4e2a\u5173\u952e\u89c1\u89e3\uff1a\u6df1\u5ea6\u4f2a\u9020\u4f53\u73b0\u4e86\u6539\u53d8\u4eba\u7c7b\u611f\u77e5\u7684\u611f\u5b98\u64cd\u7eb5\u80fd\u529b\uff0c\u53ef\u80fd\u5728\u533b\u7597\u4fdd\u5065\u548c\u6559\u80b2\u7b49\u9886\u57df\u5b9e\u73b0\u6709\u76ca\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9826\u7bc7\u540c\u884c\u8bc4\u5ba1\u6587\u732e\u8fdb\u884c\u5185\u5bb9\u5206\u6790\uff0c\u4ece\u4e09\u4e2a\u7ef4\u5ea6\u5bf9\u6df1\u5ea6\u4f2a\u9020\u6982\u5ff5\u5316\u8fdb\u884c\u5206\u7c7b\uff1a\u8eab\u4efd\u6765\u6e90\uff08\u539f\u59cb\u5185\u5bb9\u4e0e\u751f\u6210\u5185\u5bb9\u7684\u5173\u7cfb\uff09\u3001\u610f\u56fe\uff08\u6b3a\u9a97\u6027\u4e0e\u975e\u6b3a\u9a97\u6027\u76ee\u7684\uff09\u548c\u64cd\u7eb5\u7c92\u5ea6\uff08\u6574\u4f53\u6027\u4e0e\u9488\u5bf9\u6027\u4fee\u6539\uff09\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6982\u5ff5\u5316\u5b58\u5728\u663e\u8457\u5f02\u8d28\u6027\uff0c\u90e8\u5206\u7814\u7a76\u8ba8\u8bba\u4e86\u975e\u6b3a\u9a97\u6027\u5e94\u7528\uff0c\u7a81\u51fa\u4e86\u4e3a\u793e\u4f1a\u5229\u76ca\u670d\u52a1\u7684\u672a\u5f00\u53d1\u6f5c\u529b\u3002\u65f6\u95f4\u5206\u6790\u663e\u793a\u4ece\u4e3b\u8981\u5173\u6ce8\u5a01\u80c1\uff082017-2019\uff09\u5411\u8ba4\u53ef\u6709\u76ca\u5e94\u7528\uff082022-2025\uff09\u7684\u6f14\u53d8\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u533a\u5206\u5e94\u7981\u6b62\u5e94\u7528\u4e0e\u503c\u5f97\u652f\u6301\u5e94\u7528\u7684\u7ec6\u81f4\u6cbb\u7406\u548c\u7814\u7a76\u6846\u67b6\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\uff0c\u8868\u660e\u5728\u4fdd\u969c\u63aa\u65bd\u4e0b\uff0c\u6df1\u5ea6\u4f2a\u9020\u7684\u771f\u5b9e\u611f\u53ef\u4ee5\u670d\u52a1\u4e8e\u6b3a\u9a97\u4e4b\u5916\u7684\u91cd\u8981\u793e\u4f1a\u76ee\u7684\u3002"}}
{"id": "2510.21881", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.21881", "abs": "https://arxiv.org/abs/2510.21881", "authors": ["Nannan Shi", "Chuanyu Qin", "Shipeng Song", "Man Luo"], "title": "GeoThought: A Dataset for Enhancing Mathematical Geometry Reasoning in Vision-Language Models", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong reasoning capabilities\nin text-based mathematical problem solving; however, when adapted to visual\nreasoning tasks, particularly geometric problem solving, their performance\nsubstantially declines because geometric problems present unique challenges.\nSpecifically, these challenges stem from two key factors: first, the intrinsic\ncomplexity of geometry requiring detailed image comprehension and multi-step\nreasoning, and second, the limitations of existing datasets which lack\nsufficient scale, diversity, and explicit reasoning traces, consequently\nhindering effective model training. To address these challenges, we developed\nthe GeoThoughts dataset, a comprehensive geometric reasoning corpus with two\nsubsets: Geo-Thought-6K with 6,243 samples and its augmented version\nGeo-Thought-Augmented-10K containing 10,834 samples. Each entry includes visual\ndescriptions, step-by-step solutions, explicit reasoning chains, reflection\nsteps, and final answers. Using this dataset, we developed GeoThought-MLLM, a\nmathematical reasoning multimodal model that generates detailed thinking\nprocesses during problem-solving. Our model outperforms existing benchmarks in\ngeometric tasks, demonstrating that training with our Chain-of-Thought dataset\nimproves geometric reasoning capabilities across both in-domain and\nout-of-domain settings. Finally, we analyze failure cases and observe that\nerrors primarily arise from incorrect interpretation of mathematical concepts\nor spatial misjudgment. By invoking CoT to correct these mistakes, the model\nproduces correct answers.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f00\u53d1\u4e86GeoThoughts\u6570\u636e\u96c6\u548cGeoThought-MLLM\u6a21\u578b\uff0c\u901a\u8fc7\u5305\u542b\u8be6\u7ec6\u63a8\u7406\u94fe\u7684\u8bad\u7ec3\u6570\u636e\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u51e0\u4f55\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u6570\u5b66\u63a8\u7406\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u89c6\u89c9\u51e0\u4f55\u63a8\u7406\u4efb\u52a1\u4e2d\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u4e3b\u8981\u7531\u4e8e\u51e0\u4f55\u95ee\u9898\u7684\u5185\u5728\u590d\u6742\u6027\uff08\u9700\u8981\u8be6\u7ec6\u56fe\u50cf\u7406\u89e3\u548c\u591a\u6b65\u63a8\u7406\uff09\u548c\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u89c4\u6a21\u3001\u591a\u6837\u6027\u548c\u660e\u786e\u63a8\u7406\u8f68\u8ff9\u7684\u5c40\u9650\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b6,243\u4e2a\u6837\u672c\u7684Geo-Thought-6K\u6570\u636e\u96c6\u548c10,834\u4e2a\u6837\u672c\u7684\u589e\u5f3a\u7248Geo-Thought-Augmented-10K\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u6837\u672c\u5305\u542b\u89c6\u89c9\u63cf\u8ff0\u3001\u9010\u6b65\u89e3\u51b3\u65b9\u6848\u3001\u660e\u786e\u63a8\u7406\u94fe\u3001\u53cd\u601d\u6b65\u9aa4\u548c\u6700\u7ec8\u7b54\u6848\u3002\u57fa\u4e8e\u6b64\u6570\u636e\u96c6\u8bad\u7ec3\u4e86GeoThought-MLLM\u591a\u6a21\u6001\u6570\u5b66\u63a8\u7406\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728\u51e0\u4f55\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u51c6\uff0c\u8868\u660e\u4f7f\u7528Chain-of-Thought\u6570\u636e\u96c6\u8bad\u7ec3\u80fd\u591f\u63d0\u5347\u51e0\u4f55\u63a8\u7406\u80fd\u529b\uff0c\u5728\u9886\u57df\u5185\u548c\u9886\u57df\u5916\u8bbe\u7f6e\u4e2d\u5747\u6709\u6539\u5584\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790\u5931\u8d25\u6848\u4f8b\u53d1\u73b0\uff0c\u9519\u8bef\u4e3b\u8981\u6e90\u4e8e\u6570\u5b66\u6982\u5ff5\u7684\u9519\u8bef\u89e3\u91ca\u6216\u7a7a\u95f4\u5224\u65ad\u9519\u8bef\uff0c\u901a\u8fc7\u8c03\u7528CoT\u7ea0\u6b63\u8fd9\u4e9b\u9519\u8bef\u540e\uff0c\u6a21\u578b\u80fd\u591f\u4ea7\u751f\u6b63\u786e\u7b54\u6848\u3002"}}
{"id": "2510.22501", "categories": ["cs.SI", "cs.IT", "math.IT", "math.OC", "68xx, 68M, 68W", "H.1.1; G.2.2; G.3"], "pdf": "https://arxiv.org/pdf/2510.22501", "abs": "https://arxiv.org/abs/2510.22501", "authors": ["Tran Van Khanh", "Do Xuan Cho", "Hoang Phi Dung"], "title": "A Novel Discrete-time Model of Information Diffusion on Social Networks Considering Users Behavior", "comment": null, "summary": "In this paper, we introduce the SDIR\n(Susceptible-Delayable-Infected-Recovered) model, an extension of the classical\nSIR epidemic framework, to provide a more explicit characterization of user\nbehavior in online social networks. The newly merged state D (delayable)\nrepresents users who have received the information but delayed its spreading\nand may eventually choose not to share it at all. Based on the mean-field\napproximation method, we derive the dynamical equations of the model and\ninvestigate its convergence and stability conditions. Under these conditions,\nwe further propose an approximation algorithm for the edge-deletion problem,\naiming to minimize the influence of information diffusion by identifying\napproximate solutions.", "AI": {"tldr": "\u63d0\u51fa\u4e86SDIR\u6a21\u578b\uff0c\u8fd9\u662f\u7ecf\u5178SIR\u6d41\u884c\u75c5\u6a21\u578b\u7684\u6269\u5c55\uff0c\u7528\u4e8e\u66f4\u660e\u786e\u5730\u63cf\u8ff0\u5728\u7ebf\u793e\u4ea4\u7f51\u7edc\u4e2d\u7528\u6237\u884c\u4e3a\u3002\u65b0\u589e\u7684D\u72b6\u6001\u8868\u793a\u6536\u5230\u4fe1\u606f\u4f46\u5ef6\u8fdf\u4f20\u64ad\u7684\u7528\u6237\u3002", "motivation": "\u4e3a\u4e86\u66f4\u597d\u5730\u63cf\u8ff0\u5728\u7ebf\u793e\u4ea4\u7f51\u7edc\u4e2d\u7528\u6237\u5bf9\u4fe1\u606f\u4f20\u64ad\u7684\u884c\u4e3a\u7279\u5f81\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u6536\u5230\u4fe1\u606f\u4f46\u5ef6\u8fdf\u4f20\u64ad\u6216\u6700\u7ec8\u4e0d\u5206\u4eab\u7684\u7528\u6237\u884c\u4e3a\u3002", "method": "\u57fa\u4e8e\u5e73\u5747\u573a\u8fd1\u4f3c\u65b9\u6cd5\u63a8\u5bfc\u6a21\u578b\u52a8\u529b\u5b66\u65b9\u7a0b\uff0c\u7814\u7a76\u5176\u6536\u655b\u6027\u548c\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u5e76\u9488\u5bf9\u8fb9\u5220\u9664\u95ee\u9898\u63d0\u51fa\u8fd1\u4f3c\u7b97\u6cd5\u3002", "result": "\u5efa\u7acb\u4e86SDIR\u6a21\u578b\u7684\u52a8\u529b\u5b66\u65b9\u7a0b\uff0c\u786e\u5b9a\u4e86\u6536\u655b\u548c\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u5e76\u5f00\u53d1\u4e86\u6700\u5c0f\u5316\u4fe1\u606f\u4f20\u64ad\u5f71\u54cd\u7684\u8fb9\u5220\u9664\u8fd1\u4f3c\u7b97\u6cd5\u3002", "conclusion": "SDIR\u6a21\u578b\u80fd\u591f\u66f4\u51c6\u786e\u5730\u523b\u753b\u5728\u7ebf\u793e\u4ea4\u7f51\u7edc\u4e2d\u7684\u4fe1\u606f\u4f20\u64ad\u52a8\u6001\uff0c\u4e3a\u63a7\u5236\u4fe1\u606f\u6269\u6563\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7406\u8bba\u6846\u67b6\u548c\u7b97\u6cd5\u5de5\u5177\u3002"}}
{"id": "2510.15324", "categories": ["econ.EM", "econ.TH", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.15324", "abs": "https://arxiv.org/abs/2510.15324", "authors": ["Tatsuru Kikuchi"], "title": "Dynamic Spatial Treatment Effects as Continuous Functionals: Theory and Evidence from Healthcare Access", "comment": "65 pages, 10 figures", "summary": "I develop a continuous functional framework for spatial treatment effects\ngrounded in Navier-Stokes partial differential equations. Rather than discrete\ntreatment parameters, the framework characterizes treatment intensity as\ncontinuous functions $\\tau(\\mathbf{x}, t)$ over space-time, enabling rigorous\nanalysis of boundary evolution, spatial gradients, and cumulative exposure.\nEmpirical validation using 32,520 U.S. ZIP codes demonstrates exponential\nspatial decay for healthcare access ($\\kappa = 0.002837$ per km, $R^2 =\n0.0129$) with detectable boundaries at 37.1 km. The framework successfully\ndiagnoses when scope conditions hold: positive decay parameters validate\ndiffusion assumptions near hospitals, while negative parameters correctly\nsignal urban confounding effects. Heterogeneity analysis reveals 2-13 $\\times$\nstronger distance effects for elderly populations and substantial education\ngradients. Model selection strongly favors logarithmic decay over exponential\n($\\Delta \\text{AIC} > 10,000$), representing a middle ground between\nexponential and power-law decay. Applications span environmental economics,\nbanking, and healthcare policy. The continuous functional framework provides\npredictive capability ($d^*(t) = \\xi^* \\sqrt{t}$), parameter sensitivity\n($\\partial d^*/\\partial \\nu$), and diagnostic tests unavailable in traditional\ndifference-in-differences approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u7eb3\u7ef4-\u65af\u6258\u514b\u65af\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u8fde\u7eed\u51fd\u6570\u7a7a\u95f4\u5904\u7406\u6548\u5e94\u6846\u67b6\uff0c\u5c06\u5904\u7406\u5f3a\u5ea6\u5efa\u6a21\u4e3a\u65f6\u7a7a\u8fde\u7eed\u51fd\u6570\uff0c\u80fd\u591f\u5206\u6790\u8fb9\u754c\u6f14\u5316\u3001\u7a7a\u95f4\u68af\u5ea6\u548c\u7d2f\u79ef\u66b4\u9732\u3002", "motivation": "\u4f20\u7edf\u79bb\u6563\u5904\u7406\u53c2\u6570\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u6355\u6349\u7a7a\u95f4\u6548\u5e94\u7684\u8fde\u7eed\u6027\u548c\u52a8\u6001\u6f14\u5316\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5206\u6790\u7a7a\u95f4\u68af\u5ea6\u3001\u8fb9\u754c\u6f14\u5316\u548c\u7d2f\u79ef\u66b4\u9732\u7684\u8fde\u7eed\u51fd\u6570\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u7eb3\u7ef4-\u65af\u6258\u514b\u65af\u504f\u5fae\u5206\u65b9\u7a0b\u5efa\u7acb\u8fde\u7eed\u51fd\u6570\u6846\u67b6\uff0c\u5c06\u5904\u7406\u5f3a\u5ea6\u03c4(x,t)\u5efa\u6a21\u4e3a\u65f6\u7a7a\u8fde\u7eed\u51fd\u6570\uff0c\u4f7f\u752832,520\u4e2a\u7f8e\u56fd\u90ae\u653f\u7f16\u7801\u6570\u636e\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u53d1\u73b0\u533b\u7597\u53ef\u53ca\u6027\u5b58\u5728\u6307\u6570\u7a7a\u95f4\u8870\u51cf(\u03ba=0.002837/km)\uff0c\u8fb9\u754c\u8ddd\u79bb37.1km\uff1b\u8001\u5e74\u4eba\u7fa4\u8ddd\u79bb\u6548\u5e94\u5f3a2-13\u500d\uff1b\u5bf9\u6570\u8870\u51cf\u6a21\u578b\u4f18\u4e8e\u6307\u6570\u6a21\u578b(\u0394AIC>10,000)\u3002", "conclusion": "\u8fde\u7eed\u51fd\u6570\u6846\u67b6\u63d0\u4f9b\u4e86\u4f20\u7edfDID\u65b9\u6cd5\u4e0d\u5177\u5907\u7684\u9884\u6d4b\u80fd\u529b\u3001\u53c2\u6570\u654f\u611f\u6027\u548c\u8bca\u65ad\u6d4b\u8bd5\u80fd\u529b\uff0c\u53ef\u5e94\u7528\u4e8e\u73af\u5883\u7ecf\u6d4e\u5b66\u3001\u94f6\u884c\u548c\u533b\u7597\u653f\u7b56\u7b49\u9886\u57df\u3002"}}
{"id": "2510.23408", "categories": ["cs.AI", "cs.DC", "cs.ET", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.23408", "abs": "https://arxiv.org/abs/2510.23408", "authors": ["Abolfazl Younesi", "Zahra Najafabadi Samani", "Thomas Fahringer"], "title": "AutoStreamPipe: LLM Assisted Automatic Generation of Data Stream Processing Pipelines", "comment": "Under review", "summary": "Data pipelines are essential in stream processing as they enable the\nefficient collection, processing, and delivery of real-time data, supporting\nrapid data analysis. In this paper, we present AutoStreamPipe, a novel\nframework that employs Large Language Models (LLMs) to automate the design,\ngeneration, and deployment of stream processing pipelines. AutoStreamPipe\nbridges the semantic gap between high-level user intent and platform-specific\nimplementations across distributed stream processing systems for structured\nmulti-agent reasoning by integrating a Hypergraph of Thoughts (HGoT) as an\nextended version of GoT. AutoStreamPipe combines resilient execution\nstrategies, advanced query analysis, and HGoT to deliver pipelines with good\naccuracy. Experimental evaluations on diverse pipelines demonstrate that\nAutoStreamPipe significantly reduces development time (x6.3) and error rates\n(x5.19), as measured by a novel Error-Free Score (EFS), compared to LLM\ncode-generation methods.", "AI": {"tldr": "AutoStreamPipe\u662f\u4e00\u4e2a\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5316\u8bbe\u8ba1\u548c\u90e8\u7f72\u6d41\u5904\u7406\u7ba1\u9053\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8d85\u56fe\u601d\u7ef4(HGoT)\u6280\u672f\u663e\u8457\u51cf\u5c11\u4e86\u5f00\u53d1\u65f6\u95f4\u548c\u9519\u8bef\u7387\u3002", "motivation": "\u89e3\u51b3\u6d41\u5904\u7406\u7ba1\u9053\u5f00\u53d1\u4e2d\u9ad8\u5c42\u7528\u6237\u610f\u56fe\u4e0e\u5e73\u53f0\u7279\u5b9a\u5b9e\u73b0\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\uff0c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u8d85\u56fe\u601d\u7ef4(HGoT)\u6280\u672f\uff0c\u96c6\u6210\u5f39\u6027\u6267\u884c\u7b56\u7565\u548c\u9ad8\u7ea7\u67e5\u8be2\u5206\u6790\uff0c\u5b9e\u73b0\u8de8\u5206\u5e03\u5f0f\u6d41\u5904\u7406\u7cfb\u7edf\u7684\u591a\u667a\u80fd\u4f53\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u76f8\u6bd4LLM\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\uff0cAutoStreamPipe\u5c06\u5f00\u53d1\u65f6\u95f4\u51cf\u5c116.3\u500d\uff0c\u9519\u8bef\u7387\u964d\u4f4e5.19\u500d(\u901a\u8fc7\u65b0\u7684\u65e0\u9519\u8bef\u8bc4\u5206EFS\u8861\u91cf)\u3002", "conclusion": "AutoStreamPipe\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u5316\u6d41\u5904\u7406\u7ba1\u9053\u7684\u8bbe\u8ba1\u3001\u751f\u6210\u548c\u90e8\u7f72\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f00\u53d1\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.23434", "categories": ["econ.EM", "math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.23434", "abs": "https://arxiv.org/abs/2510.23434", "authors": ["Aristotelis Epanomeritakis", "Davide Viviano"], "title": "Choosing What to Learn: Experimental Design when Combining Experimental with Observational Evidence", "comment": null, "summary": "Experiments deliver credible but often localized effects, tied to specific\nsites, populations, or mechanisms. When such estimates are insufficient to\nextrapolate effects for broader policy questions, such as external validity and\ngeneral-equilibrium (GE) effects, researchers combine trials with external\nevidence from reduced-form or structural observational estimates, or prior\nexperiments. We develop a unified framework for designing experiments in this\nsetting: the researcher selects which parameters to identify experimentally\nfrom a feasible set (which treatment arms and/or individuals to include in the\nexperiment), allocates sample size, and specifies how to weight experimental\nand observational estimators. Because observational inputs may be biased in\nways unknown ex ante, we develop a minimax proportional regret objective that\nevaluates any candidate design relative to an oracle that knows the bias and\njointly chooses the design and estimator. This yields a transparent\nbias-variance trade-off that requires no prespecified bias bound and depends\nonly on information about the precision of the estimators and the estimand's\nsensitivity to the underlying parameters. We illustrate the framework by (i)\ndesigning small-scale cash transfer experiments aimed at estimating GE effects\nand (ii) optimizing site selection for microfinance interventions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u8bbe\u8ba1\u7ed3\u5408\u5b9e\u9a8c\u548c\u89c2\u5bdf\u6027\u8bc1\u636e\u7684\u5b9e\u9a8c\uff0c\u4ee5\u89e3\u51b3\u5916\u90e8\u6709\u6548\u6027\u548c\u4e00\u822c\u5747\u8861\u6548\u5e94\u7b49\u653f\u7b56\u95ee\u9898\u3002", "motivation": "\u5b9e\u9a8c\u4f30\u8ba1\u901a\u5e38\u5c40\u9650\u4e8e\u7279\u5b9a\u60c5\u5883\uff0c\u96be\u4ee5\u5916\u63a8\u5230\u66f4\u5e7f\u6cdb\u7684\u653f\u7b56\u95ee\u9898\u3002\u5f53\u9700\u8981\u8bc4\u4f30\u5916\u90e8\u6709\u6548\u6027\u548c\u4e00\u822c\u5747\u8861\u6548\u5e94\u65f6\uff0c\u7814\u7a76\u4eba\u5458\u9700\u8981\u5c06\u5b9e\u9a8c\u4e0e\u89c2\u5bdf\u6027\u8bc1\u636e\u76f8\u7ed3\u5408\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6700\u5c0f\u5316\u6700\u5927\u6bd4\u4f8b\u9057\u61be\u76ee\u6807\u7684\u8bbe\u8ba1\u6846\u67b6\uff0c\u7814\u7a76\u8005\u9009\u62e9\u5b9e\u9a8c\u8bc6\u522b\u54ea\u4e9b\u53c2\u6570\u3001\u5206\u914d\u6837\u672c\u91cf\uff0c\u5e76\u6307\u5b9a\u5982\u4f55\u52a0\u6743\u5b9e\u9a8c\u548c\u89c2\u5bdf\u6027\u4f30\u8ba1\u91cf\u3002", "result": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u900f\u660e\u7684\u504f\u5dee-\u65b9\u5dee\u6743\u8861\uff0c\u65e0\u9700\u9884\u8bbe\u504f\u5dee\u754c\u9650\uff0c\u4ec5\u4f9d\u8d56\u4e8e\u4f30\u8ba1\u91cf\u7cbe\u5ea6\u548c\u4f30\u8ba1\u91cf\u5bf9\u57fa\u7840\u53c2\u6570\u7684\u654f\u611f\u6027\u4fe1\u606f\u3002", "conclusion": "\u901a\u8fc7\u73b0\u91d1\u8f6c\u79fb\u5b9e\u9a8c\u548c\u5fae\u578b\u91d1\u878d\u5e72\u9884\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.22104", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.22104", "abs": "https://arxiv.org/abs/2510.22104", "authors": ["Fatima Al-Janahi", "Min-Seung Ko", "Hao Zhu"], "title": "TRASE-NODEs: Trajectory Sensitivity-aware Neural Ordinary Differential Equations for Efficient Dynamic Modeling", "comment": null, "summary": "Modeling dynamical systems is crucial across the science and engineering\nfields for accurate prediction, control, and decision-making. Recently, machine\nlearning (ML) approaches, particularly neural ordinary differential equations\n(NODEs), have emerged as a powerful tool for data-driven modeling of\ncontinuous-time dynamics. Nevertheless, standard NODEs require a large number\nof data samples to remain consistent under varying control inputs, posing\nchallenges to generate sufficient simulated data and ensure the safety of\ncontrol design. To address this gap, we propose trajectory-sensitivity-aware\n(TRASE-)NODEs, which construct an augmented system for both state and\nsensitivity, enabling simultaneous learning of their dynamics. This formulation\nallows the adjoint method to update gradients in a memory-efficient manner and\nensures that control-input effects are captured in the learned dynamics. We\nevaluate TRASE-NODEs using damped oscillator and inverter-based resources\n(IBRs). The results show that TRASE-NODEs generalize better from the limited\ntraining data, yielding lower prediction errors than standard NODEs for both\nexamples. The proposed framework offers a data-efficient, control-oriented\nmodeling approach suitable for dynamic systems that require accurate trajectory\nsensitivity prediction.", "AI": {"tldr": "\u63d0\u51fa\u4e86TRASE-NODEs\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u72b6\u6001\u548c\u654f\u611f\u5ea6\u7684\u589e\u5e7f\u7cfb\u7edf\uff0c\u540c\u65f6\u5b66\u4e60\u4e24\u8005\u7684\u52a8\u529b\u5b66\uff0c\u5728\u6709\u9650\u8bad\u7ec3\u6570\u636e\u4e0b\u6bd4\u6807\u51c6NODEs\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u66f4\u4f4e\u7684\u9884\u6d4b\u8bef\u5dee\u3002", "motivation": "\u6807\u51c6\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u9700\u8981\u5927\u91cf\u6570\u636e\u6837\u672c\u624d\u80fd\u5728\u4e0d\u540c\u63a7\u5236\u8f93\u5165\u4e0b\u4fdd\u6301\u4e00\u81f4\u6027\uff0c\u8fd9\u7ed9\u751f\u6210\u8db3\u591f\u6a21\u62df\u6570\u636e\u548c\u786e\u4fdd\u63a7\u5236\u8bbe\u8ba1\u5b89\u5168\u6027\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u6784\u5efa\u72b6\u6001\u548c\u654f\u611f\u5ea6\u7684\u589e\u5e7f\u7cfb\u7edf\uff0c\u4f7f\u7528\u4f34\u968f\u65b9\u6cd5\u4ee5\u5185\u5b58\u9ad8\u6548\u7684\u65b9\u5f0f\u66f4\u65b0\u68af\u5ea6\uff0c\u786e\u4fdd\u63a7\u5236\u8f93\u5165\u6548\u5e94\u88ab\u6355\u83b7\u5728\u5b66\u4e60\u5230\u7684\u52a8\u529b\u5b66\u4e2d\u3002", "result": "\u5728\u963b\u5c3c\u632f\u8361\u5668\u548c\u57fa\u4e8e\u9006\u53d8\u5668\u7684\u8d44\u6e90\u7cfb\u7edf\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cTRASE-NODEs\u5728\u6709\u9650\u8bad\u7ec3\u6570\u636e\u4e0b\u6bd4\u6807\u51c6NODEs\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u9884\u6d4b\u8bef\u5dee\u66f4\u4f4e\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6570\u636e\u9ad8\u6548\u3001\u9762\u5411\u63a7\u5236\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u9700\u8981\u51c6\u786e\u8f68\u8ff9\u654f\u611f\u5ea6\u9884\u6d4b\u7684\u52a8\u6001\u7cfb\u7edf\u3002"}}
{"id": "2510.22723", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.22723", "abs": "https://arxiv.org/abs/2510.22723", "authors": ["Riddhik Basu", "Arkaprava Roy"], "title": "Imaging Genetics Analysis of Alzheimer's Disease", "comment": null, "summary": "Alzheimer's disease (AD) is a progressive neurodegenerative disorder\ncharacterized by cognitive decline, structural brain changes, and genetic\npredispositions. This study leverages machine-learning and statistical\ntechniques to investigate the mechanistic relationships between cognitive\nfunction, genetic markers, and neuroimaging biomarkers in AD progression. Using\ndata from the Alzheimer's Disease Neuroimaging Initiative (ADNI), we perform\nboth low-dimensional and high-dimensional analyses to identify key predictors\nof disease states, including cognitively normal (CN), mild cognitive impairment\n(MCI), and AD. Our low-dimensional approach utilizes multiple linear and\nordinal logistic regression to examine the influence of cognitive scores,\ncerebrospinal fluid (CSF) biomarkers, and demographic factors on disease\nclassification. The results highlight significant associations between\nMini-Mental State Examination (MMSE), Clinical Dementia Rating Sum of Boxes\n(CDRSB), and phosphorylated tau levels in predicting cognitive decline. The\nhigh-dimensional analysis employs Sure Independence Screening (SIS) and LASSO\nregression to reduce dimensionality and identify genetic markers correlated\nwith cognitive impairment and white matter integrity. Genes such as CLIC1,\nNAB2, and TGFBR1 emerge as significant predictors across multiple analyses,\nlinking genetic expression to neurodegeneration. Additionally, imaging genetic\nanalysis reveals shared genetic influences across brain hemispheres and the\ncorpus callosum, suggesting distinct genetic contributions to white matter\ndegradation. These findings enhance our understanding of AD pathology by\nintegrating cognitive, genetic, and imaging data. Future research should\nexplore longitudinal analyses and potential gene-environment interactions to\nfurther elucidate the biological mechanisms underlying AD progression.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u548c\u7edf\u8ba1\u6280\u672f\u5206\u6790\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u8fdb\u5c55\u4e2d\u8ba4\u77e5\u529f\u80fd\u3001\u9057\u4f20\u6807\u8bb0\u548c\u795e\u7ecf\u5f71\u50cf\u751f\u7269\u6807\u5fd7\u7269\u4e4b\u95f4\u7684\u673a\u5236\u5173\u7cfb\uff0c\u8bc6\u522b\u51faMMSE\u3001CDRSB\u548c\u78f7\u9178\u5316tau\u6c34\u5e73\u7b49\u5173\u952e\u9884\u6d4b\u56e0\u5b50\uff0c\u4ee5\u53caCLIC1\u3001NAB2\u3001TGFBR1\u7b49\u4e0e\u8ba4\u77e5\u969c\u788d\u76f8\u5173\u7684\u663e\u8457\u57fa\u56e0\u3002", "motivation": "\u7814\u7a76\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u8fdb\u5c55\u4e2d\u8ba4\u77e5\u529f\u80fd\u3001\u9057\u4f20\u6807\u8bb0\u548c\u795e\u7ecf\u5f71\u50cf\u751f\u7269\u6807\u5fd7\u7269\u4e4b\u95f4\u7684\u673a\u5236\u5173\u7cfb\uff0c\u4ee5\u589e\u5f3a\u5bf9AD\u75c5\u7406\u5b66\u7684\u7406\u89e3\u3002", "method": "\u4f7f\u7528ADNI\u6570\u636e\uff0c\u91c7\u7528\u4f4e\u7ef4\uff08\u591a\u5143\u7ebf\u6027\u548c\u6709\u5e8f\u903b\u8f91\u56de\u5f52\uff09\u548c\u9ad8\u7ef4\uff08SIS\u548cLASSO\u56de\u5f52\uff09\u5206\u6790\u65b9\u6cd5\uff0c\u6574\u5408\u8ba4\u77e5\u8bc4\u5206\u3001CSF\u751f\u7269\u6807\u5fd7\u7269\u3001\u4eba\u53e3\u7edf\u8ba1\u5b66\u56e0\u7d20\u548c\u9057\u4f20\u6807\u8bb0\u3002", "result": "\u53d1\u73b0MMSE\u3001CDRSB\u548c\u78f7\u9178\u5316tau\u6c34\u5e73\u5728\u9884\u6d4b\u8ba4\u77e5\u8870\u9000\u4e2d\u5177\u6709\u663e\u8457\u5173\u8054\uff1b\u8bc6\u522b\u51faCLIC1\u3001NAB2\u3001TGFBR1\u7b49\u4e0e\u8ba4\u77e5\u969c\u788d\u548c\u767d\u8d28\u5b8c\u6574\u6027\u76f8\u5173\u7684\u663e\u8457\u57fa\u56e0\uff1b\u5f71\u50cf\u9057\u4f20\u5206\u6790\u663e\u793a\u8de8\u8111\u534a\u7403\u548c\u80fc\u80dd\u4f53\u7684\u5171\u4eab\u9057\u4f20\u5f71\u54cd\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u8ba4\u77e5\u3001\u9057\u4f20\u548c\u5f71\u50cf\u6570\u636e\u589e\u5f3a\u4e86\u5bf9AD\u75c5\u7406\u5b66\u7684\u7406\u89e3\uff0c\u5efa\u8bae\u672a\u6765\u7814\u7a76\u63a2\u7d22\u7eb5\u5411\u5206\u6790\u548c\u57fa\u56e0-\u73af\u5883\u76f8\u4e92\u4f5c\u7528\u4ee5\u8fdb\u4e00\u6b65\u9610\u660eAD\u8fdb\u5c55\u7684\u751f\u7269\u5b66\u673a\u5236\u3002"}}
{"id": "2510.21744", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.21744", "abs": "https://arxiv.org/abs/2510.21744", "authors": ["Yanjia Huang", "Shuo Liu", "Sheng Liu", "Qingxiao Xu", "Mingyang Wu", "Xiangbo Gao", "Zhengzhong Tu"], "title": "FORGE-Tree: Diffusion-Forcing Tree Search for Long-Horizon Robot Manipulation", "comment": null, "summary": "Long-horizon robot manipulation tasks remain challenging for\nVision-Language-Action (VLA) policies due to drift and exposure bias, often\ndenoise the entire trajectory with fixed hyperparameters, causing small\ngeometric errors to compound across stages and offering no mechanism to\nallocate extra test-time compute where clearances are tight. To address these\nchallenges, we introduce FORGE-Tree, a plug-in control layer that couples a\nstage-aligned Diffusion Forcing (DF) head with test-time Monte Carlo Tree\nDiffusion (MCTD). With a frozen VLA encoder, DF aligns timesteps to subtask\nstages; during inference we partially denoise only a target segment while\nkeeping other tokens frozen, turning trajectory refinement into a sequence of\nlocal edits. We then apply Monte Carlo Tree Diffusion to select the next\nsegment to refine. A scene graph supplies priors for expansion and geometry\nrelation-aware scoring for rollouts, yielding tree-structured denoising whose\nperformance scales with search budget while preserving the executed prefix.\nEvaluation on LIBERO, FORGE-Tree improves success rate by 13.4 to 17.2 pp over\nthe native VLA baselines with both OpenVLA and Octo-Base. Gains remain\nconsistent under comparable compute budgets, especially on long-horizon\nvariants. Videos available at: https://taco-group.github.io/FORGE-Tree/", "AI": {"tldr": "FORGE-Tree\u662f\u4e00\u4e2a\u7528\u4e8e\u957f\u65f6\u7a0b\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u63d2\u4ef6\u63a7\u5236\u5c42\uff0c\u901a\u8fc7\u7ed3\u5408\u9636\u6bb5\u5bf9\u9f50\u7684\u6269\u6563\u5f3a\u8feb\u5934\u548c\u6d4b\u8bd5\u65f6\u8499\u7279\u5361\u6d1b\u6811\u6269\u6563\uff0c\u89e3\u51b3\u4e86VLA\u7b56\u7565\u4e2d\u7684\u6f02\u79fb\u548c\u66b4\u9732\u504f\u5dee\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u957f\u65f6\u7a0b\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u5bf9\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u7b56\u7565\u5177\u6709\u6311\u6218\u6027\uff0c\u4e3b\u8981\u7531\u4e8e\u6f02\u79fb\u548c\u66b4\u9732\u504f\u5dee\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u56fa\u5b9a\u8d85\u53c2\u6570\u5bf9\u6574\u4e2a\u8f68\u8ff9\u8fdb\u884c\u53bb\u566a\uff0c\u5bfc\u81f4\u5c0f\u51e0\u4f55\u8bef\u5dee\u5728\u9636\u6bb5\u95f4\u7d2f\u79ef\uff0c\u4e14\u7f3a\u4e4f\u5728\u7d27\u5bc6\u95f4\u9699\u5904\u5206\u914d\u989d\u5916\u8ba1\u7b97\u8d44\u6e90\u7684\u673a\u5236\u3002", "method": "FORGE-Tree\u5305\u542b\u9636\u6bb5\u5bf9\u9f50\u7684\u6269\u6563\u5f3a\u8feb\u5934\u548c\u6d4b\u8bd5\u65f6\u8499\u7279\u5361\u6d1b\u6811\u6269\u6563\u3002\u4f7f\u7528\u51bb\u7ed3\u7684VLA\u7f16\u7801\u5668\uff0c\u6269\u6563\u5f3a\u8feb\u5934\u5c06\u65f6\u95f4\u6b65\u4e0e\u5b50\u4efb\u52a1\u9636\u6bb5\u5bf9\u9f50\uff1b\u5728\u63a8\u7406\u65f6\u4ec5\u90e8\u5206\u53bb\u566a\u76ee\u6807\u6bb5\u800c\u4fdd\u6301\u5176\u4ed6\u6807\u8bb0\u51bb\u7ed3\uff0c\u5c06\u8f68\u8ff9\u4f18\u5316\u8f6c\u5316\u4e3a\u5c40\u90e8\u7f16\u8f91\u5e8f\u5217\u3002\u8499\u7279\u5361\u6d1b\u6811\u6269\u6563\u7528\u4e8e\u9009\u62e9\u4e0b\u4e00\u4e2a\u8981\u4f18\u5316\u7684\u6bb5\uff0c\u573a\u666f\u56fe\u63d0\u4f9b\u6269\u5c55\u5148\u9a8c\u548c\u51e0\u4f55\u5173\u7cfb\u611f\u77e5\u7684rollout\u8bc4\u5206\u3002", "result": "\u5728LIBERO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFORGE-Tree\u76f8\u6bd4\u539f\u751fVLA\u57fa\u7ebf\uff08OpenVLA\u548cOcto-Base\uff09\u5c06\u6210\u529f\u7387\u63d0\u5347\u4e8613.4\u523017.2\u4e2a\u767e\u5206\u70b9\u3002\u5728\u53ef\u6bd4\u8f83\u7684\u8ba1\u7b97\u9884\u7b97\u4e0b\uff0c\u589e\u76ca\u4fdd\u6301\u4e00\u81f4\uff0c\u7279\u522b\u662f\u5728\u957f\u65f6\u7a0b\u53d8\u4f53\u4e0a\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "FORGE-Tree\u901a\u8fc7\u6811\u7ed3\u6784\u53bb\u566a\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u957f\u65f6\u7a0b\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u7684\u8f68\u8ff9\u4f18\u5316\u95ee\u9898\uff0c\u5176\u6027\u80fd\u968f\u641c\u7d22\u9884\u7b97\u6269\u5c55\u800c\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u5df2\u6267\u884c\u524d\u7f00\u4e0d\u53d8\uff0c\u4e3aVLA\u7b56\u7565\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u63a7\u5236\u5c42\u589e\u5f3a\u3002"}}
{"id": "2510.22162", "categories": ["cs.CY", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.22162", "abs": "https://arxiv.org/abs/2510.22162", "authors": ["Hannes Bajohr"], "title": "Surface Reading LLMs: Synthetic Text and its Styles", "comment": "12 pages, 1 figure", "summary": "Despite a potential plateau in ML advancement, the societal impact of large\nlanguage models lies not in approaching superintelligence but in generating\ntext surfaces indistinguishable from human writing. While Critical AI Studies\nprovides essential material and socio-technical critique, it risks overlooking\nhow LLMs phenomenologically reshape meaning-making. This paper proposes a\nsemiotics of \"surface integrity\" as attending to the immediate plane where LLMs\ninscribe themselves into human communication. I distinguish three knowledge\ninterests in ML research (epistemology, epist\\=em\\=e, and epistemics) and argue\nfor integrating surface-level stylistic analysis alongside depth-oriented\ncritique. Through two case studies examining stylistic markers of synthetic\ntext, I argue how attending to style as a semiotic phenomenon reveals LLMs as\ncultural actors that transform the conditions of meaning emergence and\ncirculation in contemporary discourse, independent of questions about machine\nconsciousness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\"\u8868\u9762\u5b8c\u6574\u6027\"\u7684\u7b26\u53f7\u5b66\u65b9\u6cd5\uff0c\u5173\u6ce8LLMs\u5728\u4eba\u7c7b\u4ea4\u6d41\u4e2d\u523b\u5199\u7684\u8868\u5c42\u73b0\u8c61\uff0c\u4e3b\u5f20\u5c06\u98ce\u683c\u5206\u6790\u6574\u5408\u5230\u6df1\u5ea6\u5bfc\u5411\u7684\u6279\u5224\u4e2d\uff0c\u4ee5\u63ed\u793aLLMs\u4f5c\u4e3a\u6587\u5316\u884c\u52a8\u8005\u5982\u4f55\u91cd\u5851\u610f\u4e49\u751f\u6210\u548c\u6d41\u901a\u7684\u6761\u4ef6\u3002", "motivation": "\u5c3d\u7ba1\u6279\u5224\u6027AI\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7269\u8d28\u548c\u793e\u4f1a\u6280\u672f\u6279\u5224\uff0c\u4f46\u53ef\u80fd\u5ffd\u89c6\u4e86LLMs\u5728\u73b0\u8c61\u5b66\u5c42\u9762\u5982\u4f55\u91cd\u5851\u610f\u4e49\u751f\u6210\u8fc7\u7a0b\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5173\u6ce8LLMs\u5728\u4ea4\u6d41\u8868\u5c42\u7684\u5f71\u54cd\u3002", "method": "\u533a\u5206\u4e86ML\u7814\u7a76\u7684\u4e09\u79cd\u77e5\u8bc6\u5174\u8da3\uff08\u8ba4\u8bc6\u8bba\u3001\u77e5\u8bc6\u578b\u3001\u8ba4\u8bc6\u8bba\u5b9e\u8df5\uff09\uff0c\u63d0\u51fa\u4e86\"\u8868\u9762\u5b8c\u6574\u6027\"\u7684\u7b26\u53f7\u5b66\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u5206\u6790\u5408\u6210\u6587\u672c\u7684\u98ce\u683c\u6807\u8bb0\u3002", "result": "\u901a\u8fc7\u98ce\u683c\u4f5c\u4e3a\u7b26\u53f7\u73b0\u8c61\u7684\u5206\u6790\uff0c\u63ed\u793a\u4e86LLMs\u4f5c\u4e3a\u6587\u5316\u884c\u52a8\u8005\u5982\u4f55\u6539\u53d8\u5f53\u4ee3\u8bdd\u8bed\u4e2d\u610f\u4e49\u51fa\u73b0\u548c\u6d41\u901a\u7684\u6761\u4ef6\uff0c\u8fd9\u4e0e\u673a\u5668\u610f\u8bc6\u95ee\u9898\u65e0\u5173\u3002", "conclusion": "\u9700\u8981\u5c06\u8868\u5c42\u98ce\u683c\u5206\u6790\u4e0e\u6df1\u5ea6\u5bfc\u5411\u6279\u5224\u76f8\u7ed3\u5408\uff0c\u4ee5\u5168\u9762\u7406\u89e3LLMs\u5728\u4eba\u7c7b\u4ea4\u6d41\u4e2d\u7684\u6587\u5316\u5f71\u54cd\uff0c\u5173\u6ce8\u5176\u5982\u4f55\u91cd\u5851\u610f\u4e49\u751f\u6210\u7684\u6761\u4ef6\u800c\u975e\u8ffd\u6c42\u8d85\u667a\u80fd\u3002"}}
{"id": "2510.21886", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21886", "abs": "https://arxiv.org/abs/2510.21886", "authors": ["Mark Phillip Matovic"], "title": "Exploration through Generation: Applying GFlowNets to Structured Search", "comment": "12 pages", "summary": "This work applies Generative Flow Networks (GFlowNets) to three graph\noptimization problems: the Traveling Salesperson Problem, Minimum Spanning\nTree, and Shortest Path. GFlowNets are generative models that learn to sample\nsolutions proportionally to a reward function. The models are trained using the\nTrajectory Balance loss to build solutions sequentially, selecting edges for\nspanning trees, nodes for paths, and cities for tours. Experiments on benchmark\ninstances of varying sizes show that GFlowNets learn to find optimal solutions.\nFor each problem type, multiple graph configurations with different numbers of\nnodes were tested. The generated solutions match those from classical\nalgorithms (Dijkstra for shortest path, Kruskal for spanning trees, and exact\nsolvers for TSP). Training convergence depends on problem complexity, with the\nnumber of episodes required for loss stabilization increasing as graph size\ngrows. Once training converges, the generated solutions match known optima from\nclassical algorithms across the tested instances. This work demonstrates that\ngenerative models can solve combinatorial optimization problems through learned\npolicies. The main advantage of this learning-based approach is computational\nscalability: while classical algorithms have fixed complexity per instance,\nGFlowNets amortize computation through training. With sufficient computational\nresources, the framework could potentially scale to larger problem instances\nwhere classical exact methods become infeasible.", "AI": {"tldr": "\u5c06\u751f\u6210\u6d41\u7f51\u7edc\u5e94\u7528\u4e8e\u65c5\u884c\u5546\u95ee\u9898\u3001\u6700\u5c0f\u751f\u6210\u6811\u548c\u6700\u77ed\u8def\u5f84\u4e09\u4e2a\u56fe\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u8bad\u7ec3\u5b66\u4e60\u91c7\u6837\u4e0e\u5956\u52b1\u51fd\u6570\u6210\u6bd4\u4f8b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u751f\u6210\u7ed3\u679c\u4e0e\u7ecf\u5178\u7b97\u6cd5\u4e00\u81f4\u3002", "motivation": "\u63a2\u7d22\u751f\u6210\u6a21\u578b\u89e3\u51b3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u80fd\u529b\uff0c\u5229\u7528\u5b66\u4e60\u7b56\u7565\u7684\u4f18\u52bf\u5b9e\u73b0\u8ba1\u7b97\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u7ecf\u5178\u7cbe\u786e\u65b9\u6cd5\u4e0d\u53ef\u884c\u7684\u5927\u89c4\u6a21\u95ee\u9898\u63d0\u4f9b\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u8f68\u8ff9\u5e73\u8861\u635f\u5931\u8bad\u7ec3GFlowNets\uff0c\u6309\u987a\u5e8f\u6784\u5efa\u89e3\u51b3\u65b9\u6848\uff1a\u4e3a\u751f\u6210\u6811\u9009\u62e9\u8fb9\u3001\u4e3a\u8def\u5f84\u9009\u62e9\u8282\u70b9\u3001\u4e3a\u65c5\u884c\u9009\u62e9\u57ce\u5e02\u3002", "result": "\u5728\u591a\u79cd\u89c4\u6a21\u7684\u57fa\u51c6\u5b9e\u4f8b\u4e0a\uff0cGFlowNets\u5b66\u4f1a\u627e\u5230\u6700\u4f18\u89e3\uff0c\u751f\u6210\u89e3\u4e0e\u7ecf\u5178\u7b97\u6cd5\uff08Dijkstra\u3001Kruskal\u3001TSP\u7cbe\u786e\u6c42\u89e3\u5668\uff09\u7ed3\u679c\u4e00\u81f4\u3002\u8bad\u7ec3\u6536\u655b\u53d6\u51b3\u4e8e\u95ee\u9898\u590d\u6742\u5ea6\uff0c\u56fe\u89c4\u6a21\u8d8a\u5927\u6240\u9700\u8bad\u7ec3\u8f6e\u6b21\u8d8a\u591a\u3002", "conclusion": "\u751f\u6210\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u5b66\u4e60\u7b56\u7565\u89e3\u51b3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u4e3b\u8981\u4f18\u52bf\u662f\u8ba1\u7b97\u53ef\u6269\u5c55\u6027\uff1a\u7ecf\u5178\u7b97\u6cd5\u6bcf\u5b9e\u4f8b\u6709\u56fa\u5b9a\u590d\u6742\u5ea6\uff0c\u800cGFlowNets\u901a\u8fc7\u8bad\u7ec3\u5206\u644a\u8ba1\u7b97\uff0c\u5728\u8db3\u591f\u8ba1\u7b97\u8d44\u6e90\u4e0b\u53ef\u6269\u5c55\u5230\u7ecf\u5178\u7cbe\u786e\u65b9\u6cd5\u4e0d\u53ef\u884c\u7684\u5927\u89c4\u6a21\u95ee\u9898\u3002"}}
{"id": "2510.22644", "categories": ["cs.SI", "92D30, 05C90, 34C28, 37F20, 90C35, 91D30, 94C15"], "pdf": "https://arxiv.org/pdf/2510.22644", "abs": "https://arxiv.org/abs/2510.22644", "authors": ["Weiyi Wang", "Mahendra Piraveenan"], "title": "Influence of Network Topology and Vaccination Strategies on HPV Dynamics: A Simulation Study Using the SeCoNet Growth Model", "comment": null, "summary": "This study examines how contact network topology influences the effectiveness\nof vaccination programs in the context of human papillomavirus (HPV)\ntransmission. Using the SeCoNet sexual contact network growth model, we\nevaluate age based, ring based, and several centrality based vaccination\nstrategies across the overall, male, and female cohorts, focusing on peak\nincidence, timing of peak prevalence, and cumulative incidence. The simulations\nshow that degree, betweenness, and percolation centrality based strategies are\ngenerally the most effective, while ring vaccination achieves the greatest\nreduction in cumulative incidence among females. Network topology also plays a\ncritical role: higher average degree reduces vaccination effectiveness, whereas\nhigher power-law exponent, longer average shortest path length, and stronger\nclustering improve vaccination outcomes. The results highlight the importance\nof incorporating network structure into the design of HPV vaccination programs.", "AI": {"tldr": "\u7814\u7a76\u6027\u63a5\u89e6\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\u5982\u4f55\u5f71\u54cdHPV\u75ab\u82d7\u63a5\u79cd\u8ba1\u5212\u6548\u679c\uff0c\u53d1\u73b0\u57fa\u4e8e\u7f51\u7edc\u4e2d\u5fc3\u6027\u7684\u7b56\u7565\u6700\u6709\u6548\uff0c\u7f51\u7edc\u62d3\u6251\u7279\u5f81\u663e\u8457\u5f71\u54cd\u63a5\u79cd\u6548\u679c\u3002", "motivation": "\u63a2\u8ba8\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\u5728HPV\u75ab\u82d7\u63a5\u79cd\u8ba1\u5212\u8bbe\u8ba1\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u7406\u89e3\u4e0d\u540c\u7f51\u7edc\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u75c5\u6bd2\u4f20\u64ad\u548c\u63a5\u79cd\u5e72\u9884\u6548\u679c\u3002", "method": "\u4f7f\u7528SeCoNet\u6027\u63a5\u89e6\u7f51\u7edc\u589e\u957f\u6a21\u578b\uff0c\u8bc4\u4f30\u57fa\u4e8e\u5e74\u9f84\u3001\u73af\u5f62\u548c\u591a\u79cd\u4e2d\u5fc3\u6027\u6307\u6807\u7684\u75ab\u82d7\u63a5\u79cd\u7b56\u7565\uff0c\u5206\u6790\u5cf0\u503c\u53d1\u75c5\u7387\u3001\u5cf0\u503c\u6d41\u884c\u65f6\u95f4\u548c\u7d2f\u8ba1\u53d1\u75c5\u7387\u3002", "result": "\u57fa\u4e8e\u5ea6\u3001\u4ecb\u6570\u548c\u6e17\u900f\u4e2d\u5fc3\u6027\u7684\u7b56\u7565\u6700\u6709\u6548\uff0c\u73af\u5f62\u63a5\u79cd\u5728\u5973\u6027\u4e2d\u964d\u4f4e\u7d2f\u8ba1\u53d1\u75c5\u7387\u6548\u679c\u6700\u597d\uff1b\u7f51\u7edc\u5e73\u5747\u5ea6\u8d8a\u9ad8\u63a5\u79cd\u6548\u679c\u8d8a\u5dee\uff0c\u800c\u5e42\u5f8b\u6307\u6570\u3001\u5e73\u5747\u6700\u77ed\u8def\u5f84\u957f\u5ea6\u548c\u805a\u7c7b\u7cfb\u6570\u8d8a\u9ad8\u63a5\u79cd\u6548\u679c\u8d8a\u597d\u3002", "conclusion": "\u7f51\u7edc\u7ed3\u6784\u5bf9HPV\u75ab\u82d7\u63a5\u79cd\u8ba1\u5212\u8bbe\u8ba1\u81f3\u5173\u91cd\u8981\uff0c\u5e94\u7eb3\u5165\u7f51\u7edc\u62d3\u6251\u7279\u5f81\u6765\u4f18\u5316\u63a5\u79cd\u7b56\u7565\u3002"}}
{"id": "2510.23534", "categories": ["econ.EM", "cs.LG", "math.ST", "stat.ME", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.23534", "abs": "https://arxiv.org/abs/2510.23534", "authors": ["Masahiro Kato"], "title": "Direct Debiased Machine Learning via Bregman Divergence Minimization", "comment": null, "summary": "We develop a direct debiased machine learning framework comprising Neyman\ntargeted estimation and generalized Riesz regression. Our framework unifies\nRiesz regression for automatic debiased machine learning, covariate balancing,\ntargeted maximum likelihood estimation (TMLE), and density-ratio estimation. In\nmany problems involving causal effects or structural models, the parameters of\ninterest depend on regression functions. Plugging regression functions\nestimated by machine learning methods into the identifying equations can yield\npoor performance because of first-stage bias. To reduce such bias, debiased\nmachine learning employs Neyman orthogonal estimating equations. Debiased\nmachine learning typically requires estimation of the Riesz representer and the\nregression function. For this problem, we develop a direct debiased machine\nlearning framework with an end-to-end algorithm. We formulate estimation of the\nnuisance parameters, the regression function and the Riesz representer, as\nminimizing the discrepancy between Neyman orthogonal scores computed with known\nand unknown nuisance parameters, which we refer to as Neyman targeted\nestimation. Neyman targeted estimation includes Riesz representer estimation,\nand we measure discrepancies using the Bregman divergence. The Bregman\ndivergence encompasses various loss functions as special cases, where the\nsquared loss yields Riesz regression and the Kullback-Leibler divergence yields\nentropy balancing. We refer to this Riesz representer estimation as generalized\nRiesz regression. Neyman targeted estimation also yields TMLE as a special case\nfor regression function estimation. Furthermore, for specific pairs of models\nand Riesz representer estimation methods, we can automatically obtain the\ncovariate balancing property without explicitly solving the covariate balancing\nobjective.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u76f4\u63a5\u53bb\u504f\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408Neyman\u76ee\u6807\u4f30\u8ba1\u548c\u5e7f\u4e49Riesz\u56de\u5f52\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u53bb\u504f\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316Neyman\u6b63\u4ea4\u5f97\u5206\u5dee\u5f02\u6765\u540c\u65f6\u4f30\u8ba1\u56de\u5f52\u51fd\u6570\u548cRiesz\u8868\u793a\u5b50\u3002", "motivation": "\u5728\u56e0\u679c\u6548\u5e94\u6216\u7ed3\u6784\u6a21\u578b\u4e2d\uff0c\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f30\u8ba1\u7684\u56de\u5f52\u51fd\u6570\u4f1a\u4ea7\u751f\u4e00\u9636\u6bb5\u504f\u5dee\uff0c\u5bfc\u81f4\u53c2\u6570\u4f30\u8ba1\u6027\u80fd\u8f83\u5dee\uff0c\u9700\u8981\u53bb\u504f\u65b9\u6cd5\u6765\u51cf\u5c11\u8fd9\u79cd\u504f\u5dee\u3002", "method": "\u5f00\u53d1\u4e86\u76f4\u63a5\u53bb\u504f\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7Neyman\u76ee\u6807\u4f30\u8ba1\u6700\u5c0f\u5316\u5df2\u77e5\u548c\u672a\u77e5nuisance\u53c2\u6570\u8ba1\u7b97\u7684Neyman\u6b63\u4ea4\u5f97\u5206\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u4f7f\u7528Bregman\u6563\u5ea6\u8861\u91cf\u5dee\u5f02\uff0c\u6db5\u76d6\u591a\u79cd\u635f\u5931\u51fd\u6570\u3002", "result": "\u8be5\u6846\u67b6\u7edf\u4e00\u4e86Riesz\u56de\u5f52\u3001\u534f\u53d8\u91cf\u5e73\u8861\u3001TMLE\u548c\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\uff0c\u80fd\u591f\u81ea\u52a8\u83b7\u5f97\u534f\u53d8\u91cf\u5e73\u8861\u6027\u8d28\uff0c\u65e0\u9700\u663e\u5f0f\u6c42\u89e3\u534f\u53d8\u91cf\u5e73\u8861\u76ee\u6807\u3002", "conclusion": "\u63d0\u51fa\u7684\u76f4\u63a5\u53bb\u504f\u673a\u5668\u5b66\u4e60\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7b97\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u51cf\u5c11\u4e00\u9636\u6bb5\u504f\u5dee\uff0c\u7edf\u4e00\u4e86\u591a\u79cd\u53bb\u504f\u65b9\u6cd5\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.22321", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.22321", "abs": "https://arxiv.org/abs/2510.22321", "authors": ["Hyeongon Park", "Kyuhyeong Kwag", "Daniel K. Molzahn", "Rahul K. Gupta"], "title": "Fair Cost Allocation in Energy Communities: A DLMP-based Bilevel Optimization with a Shapley Value Approach", "comment": null, "summary": "Energy communities (ECs) are emerging as a promising decentralized model for\nmanaging cooperative distributed energy resources (DERs). As these communities\nexpand and their operations become increasingly integrated into the grid,\nensuring fairness in allocating operating costs among participants becomes a\nchallenge. In distribution networks, DER operations at the community level can\ninfluence Distribution Locational Marginal Prices (DLMPs), which in turn affect\nsystem's operation cost. This interdependence between local decisions and\nsystem-level pricing introduces new challenges for fair and transparent cost\nallocation. Despite growing interest in fairness-aware methods, most methods do\nnot account for the impact of DLMPs. To fill this gap, we propose a bilevel\noptimization model in which a Community Energy Aggregator (CEA) schedules DERs\nacross multiple ECs while a Distribution System Operator (DSO) determines DLMPs\nthrough network-constrained dispatch. Leveraging the Karush-Kuhn-Tucker (KKT)\nconditions and strong duality, the bilevel model is reformulated into a\ntractable single-level problem. We achieve fairness in the cost allocation by\napplying the Shapley value to quantify each community's marginal contribution\nto system-wide cost savings. The effectiveness of the proposed method is\nvalidated through simulations on several benchmark distribution systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u4f18\u5316\u6a21\u578b\uff0c\u901a\u8fc7Shapley\u503c\u5b9e\u73b0\u80fd\u6e90\u793e\u533a\u95f4\u8fd0\u8425\u6210\u672c\u7684\u516c\u5e73\u5206\u914d\uff0c\u8003\u8651\u4e86\u5206\u5e03\u4f4d\u7f6e\u8fb9\u9645\u4ef7\u683c\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u80fd\u6e90\u793e\u533a\u89c4\u6a21\u6269\u5927\u548c\u4e0e\u7535\u7f51\u96c6\u6210\u5ea6\u63d0\u9ad8\uff0c\u5728\u53c2\u4e0e\u8005\u95f4\u516c\u5e73\u5206\u914d\u8fd0\u8425\u6210\u672c\u6210\u4e3a\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5927\u591a\u672a\u8003\u8651\u5206\u5e03\u4f4d\u7f6e\u8fb9\u9645\u4ef7\u683c\u7684\u5f71\u54cd\u3002", "method": "\u5efa\u7acb\u53cc\u5c42\u4f18\u5316\u6a21\u578b\uff1a\u4e0a\u5c42\u7531\u793e\u533a\u80fd\u6e90\u805a\u5408\u5668\u8c03\u5ea6\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\uff0c\u4e0b\u5c42\u7531\u914d\u7535\u7cfb\u7edf\u8fd0\u8425\u5546\u901a\u8fc7\u7f51\u7edc\u7ea6\u675f\u8c03\u5ea6\u786e\u5b9a\u5206\u5e03\u4f4d\u7f6e\u8fb9\u9645\u4ef7\u683c\u3002\u5229\u7528KKT\u6761\u4ef6\u548c\u5f3a\u5bf9\u5076\u6027\u5c06\u53cc\u5c42\u95ee\u9898\u8f6c\u5316\u4e3a\u5355\u5c42\u53ef\u5904\u7406\u95ee\u9898\uff0c\u5e76\u5e94\u7528Shapley\u503c\u91cf\u5316\u5404\u793e\u533a\u5bf9\u7cfb\u7edf\u6210\u672c\u8282\u7ea6\u7684\u8fb9\u9645\u8d21\u732e\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u914d\u7535\u7cfb\u7edf\u4e0a\u7684\u4eff\u771f\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u516c\u5e73\u900f\u660e\u5730\u5206\u914d\u80fd\u6e90\u793e\u533a\u95f4\u7684\u8fd0\u8425\u6210\u672c\uff0c\u540c\u65f6\u8003\u8651\u4e86\u5206\u5e03\u4f4d\u7f6e\u8fb9\u9645\u4ef7\u683c\u7684\u5f71\u54cd\u3002"}}
{"id": "2510.22791", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.22791", "abs": "https://arxiv.org/abs/2510.22791", "authors": ["Ibrahim Mohammed", "Chris Robertson", "M. Gabriela M. Gomes"], "title": "On the simultaneous inference of susceptibility distributions and intervention effects from epidemic curves", "comment": "29 pages, 13 figures, 3 tables", "summary": "Susceptible-Exposed-Infectious-Recovered (SEIR) models with inter-individual\nvariation in susceptibility or exposure to infection were proposed early in the\nCOVID-19 pandemic as a potential element of the mathematical/statistical\ntoolset available to policy development. In comparison with other models\nemployed at the time, those designed to fully estimate the effects of such\nvariation tended to predict small epidemic waves and hence require less\ncontainment to achieve the same outcomes. However, these models never made it\nto mainstream COVID-19 policy making due to lack of prior validation of their\ninference capabilities. Here we report the results of the first systematic\ninvestigation of this matter. We simulate datasets using the model with\nstrategically chosen parameter values, and then conduct maximum likelihood\nestimation to assess how well we can retrieve the assumed parameter values. We\nidentify some identifiability issues which can be overcome by creatively\nfitting multiple epidemics with shared parameters.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86\u8003\u8651\u4e2a\u4f53\u5dee\u5f02\u7684SEIR\u6a21\u578b\u5728\u53c2\u6570\u4f30\u8ba1\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5b58\u5728\u53ef\u8bc6\u522b\u6027\u95ee\u9898\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u521b\u65b0\u6027\u5730\u62df\u5408\u591a\u4e2a\u5171\u4eab\u53c2\u6570\u7684\u6d41\u884c\u75c5\u6765\u514b\u670d\u3002", "motivation": "\u65e9\u671fCOVID-19\u5927\u6d41\u884c\u671f\u95f4\uff0c\u8003\u8651\u4e2a\u4f53\u6613\u611f\u6027\u6216\u66b4\u9732\u7a0b\u5ea6\u5dee\u5f02\u7684SEIR\u6a21\u578b\u88ab\u63d0\u51fa\u4f5c\u4e3a\u653f\u7b56\u5236\u5b9a\u7684\u6570\u5b66\u5de5\u5177\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u5bf9\u5176\u63a8\u65ad\u80fd\u529b\u7684\u5148\u9a8c\u9a8c\u8bc1\uff0c\u8fd9\u4e9b\u6a21\u578b\u672a\u80fd\u8fdb\u5165\u4e3b\u6d41\u653f\u7b56\u5236\u5b9a\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u6218\u7565\u6027\u9009\u62e9\u7684\u53c2\u6570\u503c\u6a21\u62df\u6570\u636e\u96c6\uff0c\u7136\u540e\u8fdb\u884c\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff0c\u8bc4\u4f30\u4ece\u6a21\u62df\u6570\u636e\u4e2d\u6062\u590d\u5047\u8bbe\u53c2\u6570\u503c\u7684\u80fd\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5b58\u5728\u4e00\u4e9b\u53ef\u8bc6\u522b\u6027\u95ee\u9898\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u521b\u65b0\u6027\u5730\u62df\u5408\u591a\u4e2a\u5177\u6709\u5171\u4eab\u53c2\u6570\u7684\u6d41\u884c\u75c5\u6765\u514b\u670d\u8fd9\u4e9b\u95ee\u9898\u3002", "conclusion": "\u8fd9\u662f\u5bf9\u8003\u8651\u4e2a\u4f53\u5dee\u5f02\u7684SEIR\u6a21\u578b\u53c2\u6570\u4f30\u8ba1\u80fd\u529b\u7684\u9996\u6b21\u7cfb\u7edf\u8c03\u67e5\uff0c\u4e3a\u8fd9\u7c7b\u6a21\u578b\u5728\u6d41\u884c\u75c5\u653f\u7b56\u5236\u5b9a\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u9a8c\u8bc1\u3002"}}
{"id": "2510.21746", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.21746", "abs": "https://arxiv.org/abs/2510.21746", "authors": ["Harris Song", "Long Le"], "title": "Avi: Action from Volumetric Inference", "comment": "NeurIPS 2025 Workshop on Embodied World Models for Decision Making.\n  URL: https://avi-3drobot.github.io/", "summary": "We propose Avi, a novel 3D Vision-Language-Action (VLA) architecture that\nreframes robotic action generation as a problem of 3D perception and spatial\nreasoning, rather than low-level policy learning. While existing VLA models\nprimarily operate on 2D visual inputs and are trained end-to-end on\ntask-specific action policies, Avi leverages 3D point clouds and\nlanguage-grounded scene understanding to compute actions through classical\ngeometric transformations. Most notably, Avi does not train on previous action\ntokens, rather, we build upon a 3D Multi-modal Large Language Model (MLLM) to\ngenerate the next point cloud and explicitly calculate the actions through\nclassical transformations. This approach enables generalizable behaviors that\nare robust to occlusions, camera pose variations, and changes in viewpoint. By\ntreating the robotic decision-making process as a structured reasoning task\nover 3D representations, Avi bridges the gap between high-level language\ninstructions and low-level actuation without requiring opaque policy learning.\nOur preliminary results highlight the potential of 3D vision-language reasoning\nas a foundation for scalable, robust robotic systems. Check it out at\nhttps://avi-3drobot.github.io/.", "AI": {"tldr": "Avi\u662f\u4e00\u79cd\u65b0\u9896\u76843D\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u67b6\u6784\uff0c\u5c06\u673a\u5668\u4eba\u52a8\u4f5c\u751f\u6210\u91cd\u65b0\u5b9a\u4e49\u4e3a3D\u611f\u77e5\u548c\u7a7a\u95f4\u63a8\u7406\u95ee\u9898\uff0c\u800c\u975e\u4f4e\u5c42\u7b56\u7565\u5b66\u4e60\u3002\u5b83\u5229\u75283D\u70b9\u4e91\u548c\u57fa\u4e8e\u8bed\u8a00\u573a\u666f\u7406\u89e3\uff0c\u901a\u8fc7\u7ecf\u5178\u51e0\u4f55\u53d8\u6362\u8ba1\u7b97\u52a8\u4f5c\u3002", "motivation": "\u73b0\u6709VLA\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e2D\u89c6\u89c9\u8f93\u5165\u8fdb\u884c\u7aef\u5230\u7aef\u4efb\u52a1\u7279\u5b9a\u7b56\u7565\u8bad\u7ec3\uff0c\u800cAvi\u65e8\u5728\u901a\u8fc73D\u611f\u77e5\u548c\u7a7a\u95f4\u63a8\u7406\u5b9e\u73b0\u66f4\u901a\u7528\u3001\u9c81\u68d2\u7684\u673a\u5668\u4eba\u884c\u4e3a\u3002", "method": "\u57fa\u4e8e3D\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e0b\u4e00\u4e2a\u70b9\u4e91\uff0c\u901a\u8fc7\u7ecf\u5178\u51e0\u4f55\u53d8\u6362\u663e\u5f0f\u8ba1\u7b97\u52a8\u4f5c\uff0c\u65e0\u9700\u8bad\u7ec3\u5148\u524d\u52a8\u4f5c\u6807\u8bb0\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5bf9\u906e\u6321\u3001\u76f8\u673a\u59ff\u6001\u53d8\u5316\u548c\u89c6\u89d2\u53d8\u5316\u7684\u9c81\u68d2\u6027\uff0c\u5c55\u793a\u4e86\u901a\u7528\u5316\u884c\u4e3a\u3002", "conclusion": "3D\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u6709\u6f5c\u529b\u4f5c\u4e3a\u53ef\u6269\u5c55\u3001\u9c81\u68d2\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u57fa\u7840\uff0c\u5f25\u5408\u9ad8\u5c42\u8bed\u8a00\u6307\u4ee4\u4e0e\u4f4e\u5c42\u9a71\u52a8\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2510.22279", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.22279", "abs": "https://arxiv.org/abs/2510.22279", "authors": ["Hugo Roger Paz"], "title": "The AI Tutor in Engineering Education: Design, Results, and Redesign of an Experience in Hydrology at an Argentine University", "comment": "18 pages, in Spanish language", "summary": "The emergence of Generative Artificial Intelligence (GenAI) has reshaped\nhigher education, presenting both opportunities and ethical-pedagogical\nchallenges. This article presents an empirical case study on the complete cycle\n(design, initial failure, redesign, and re-evaluation) of an intervention using\nan AI Tutor (ChatGPT) in the \"Hydrology and Hydraulic Works\" course (Civil\nEngineering, UTN-FRT, Argentina). The study documents two interventions in the\nsame cohort (n=23). The first resulted in widespread failure (0% pass rate) due\nto superficial use and serious academic integrity issues (65% similarity,\ncopies > 80%). This failure forced a comprehensive methodological redesign. The\nsecond intervention, based on a redesigned prompt (Prompt V2) with strict\nevidence controls (mandatory Appendix A with exported chat, minimum time $\\geq$\n120 minutes, verifiable numerical exercise) and a refined rubric (Rubric V2),\nshowed significantly better results: a median score of 88/100 and verifiable\ncompliance with genuine interaction processes. Using a mixed-methods approach\n(reproducible document analysis and rubric analysis), the impact of the\nredesign on integrity and technical performance is evaluated. The results\ndemonstrate that, without explicit process controls, students prioritize\nefficiency over deep learning, submitting documents without real traceability.\nA transferable assessment protocol for STEM courses is proposed, centered on\n\"auditable personal zones,\" to foster higher-order thinking. The study provides\nkey empirical evidence from the context of a public Latin American university.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u4e24\u8f6eAI\u5bfc\u5e08\u5e72\u9884\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u5728\u9ad8\u7b49\u6559\u80b2\u4e2d\u4f7f\u7528ChatGPT\u65f6\uff0c\u7f3a\u4e4f\u660e\u786e\u8fc7\u7a0b\u63a7\u5236\u4f1a\u5bfc\u81f4\u5b66\u751f\u8ffd\u6c42\u6548\u7387\u800c\u975e\u6df1\u5ea6\u5b66\u4e60\uff0c\u800c\u901a\u8fc7\u91cd\u65b0\u8bbe\u8ba1\u7684\u63d0\u793a\u548c\u4e25\u683c\u7684\u8bc1\u636e\u63a7\u5236\u53ef\u4ee5\u663e\u8457\u6539\u5584\u5b66\u672f\u8bda\u4fe1\u548c\u6280\u672f\u8868\u73b0\u3002", "motivation": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u9ad8\u7b49\u6559\u80b2\u4e2d\u65e2\u5e26\u6765\u673a\u9047\u4e5f\u5e26\u6765\u4f26\u7406\u6559\u5b66\u6311\u6218\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5728STEM\u8bfe\u7a0b\u4e2d\u6709\u6548\u4f7f\u7528AI\u5de5\u5177\uff0c\u540c\u65f6\u786e\u4fdd\u5b66\u672f\u8bda\u4fe1\u548c\u6df1\u5ea6\u5b66\u4e60\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff08\u53ef\u590d\u73b0\u7684\u6587\u6863\u5206\u6790\u548c\u8bc4\u5206\u6807\u51c6\u5206\u6790\uff09\uff0c\u5728\u540c\u4e00\u961f\u5217\u4e2d\u8fdb\u884c\u4e24\u8f6e\u5e72\u9884\u5b9e\u9a8c\uff0c\u7b2c\u4e00\u8f6e\u5931\u8d25\u540e\u91cd\u65b0\u8bbe\u8ba1\u63d0\u793a\u548c\u8bc4\u4f30\u6807\u51c6\uff0c\u7b2c\u4e8c\u8f6e\u91c7\u7528\u4e25\u683c\u7684\u8fc7\u7a0b\u63a7\u5236\u3002", "result": "\u7b2c\u4e00\u8f6e\u5e72\u9884\u5931\u8d25\uff080%\u901a\u8fc7\u7387\uff0c65%\u76f8\u4f3c\u5ea6\uff0c\u6284\u88ad\u7387>80%\uff09\uff0c\u7b2c\u4e8c\u8f6e\u5e72\u9884\u540e\u4e2d\u4f4d\u6570\u5f97\u520688/100\uff0c\u4e14\u80fd\u9a8c\u8bc1\u771f\u5b9e\u7684\u4e92\u52a8\u8fc7\u7a0b\u3002", "conclusion": "\u63d0\u51fa\u57fa\u4e8e\"\u53ef\u5ba1\u8ba1\u4e2a\u4eba\u533a\u57df\"\u7684\u53ef\u8f6c\u79fb\u8bc4\u4f30\u534f\u8bae\uff0c\u5f3a\u8c03\u5728AI\u5de5\u5177\u4f7f\u7528\u4e2d\u9700\u8981\u660e\u786e\u7684\u8fc7\u7a0b\u63a7\u5236\u6765\u4fc3\u8fdb\u9ad8\u9636\u601d\u7ef4\u53d1\u5c55\u3002"}}
{"id": "2510.21888", "categories": ["cs.AI", "cs.CC", "cs.LG", "68Q17 (Primary) 68T05, 68T42 (Secondary)", "F.2.2; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2510.21888", "abs": "https://arxiv.org/abs/2510.21888", "authors": ["Shayan Karimi", "Xiaoqi Tan"], "title": "Computational Hardness of Reinforcement Learning with Partial $q^\u03c0$-Realizability", "comment": "to be published in NeurIPS 2025", "summary": "This paper investigates the computational complexity of reinforcement\nlearning in a novel linear function approximation regime, termed partial\n$q^{\\pi}$-realizability. In this framework, the objective is to learn an\n$\\epsilon$-optimal policy with respect to a predefined policy set $\\Pi$, under\nthe assumption that all value functions for policies in $\\Pi$ are linearly\nrealizable. The assumptions of this framework are weaker than those in\n$q^{\\pi}$-realizability but stronger than those in $q^*$-realizability,\nproviding a practical model where function approximation naturally arises. We\nprove that learning an $\\epsilon$-optimal policy in this setting is\ncomputationally hard. Specifically, we establish NP-hardness under a\nparameterized greedy policy set (argmax) and show that - unless NP = RP - an\nexponential lower bound (in feature vector dimension) holds when the policy set\ncontains softmax policies, under the Randomized Exponential Time Hypothesis.\nOur hardness results mirror those in $q^*$-realizability and suggest\ncomputational difficulty persists even when $\\Pi$ is expanded beyond the\noptimal policy. To establish this, we reduce from two complexity problems,\n$\\delta$-Max-3SAT and $\\delta$-Max-3SAT(b), to instances of GLinear-$\\kappa$-RL\n(greedy policy) and SLinear-$\\kappa$-RL (softmax policy). Our findings indicate\nthat positive computational results are generally unattainable in partial\n$q^{\\pi}$-realizability, in contrast to $q^{\\pi}$-realizability under a\ngenerative access model.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u7ebf\u6027\u51fd\u6570\u903c\u8fd1\u65b0\u6846\u67b6\uff08\u90e8\u5206q^\u03c0\u53ef\u5b9e\u73b0\u6027\uff09\u4e2d\u5f3a\u5316\u5b66\u4e60\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u8bc1\u660e\u5728\u8be5\u8bbe\u7f6e\u4e0b\u5b66\u4e60\u03b5\u6700\u4f18\u7b56\u7565\u662f\u8ba1\u7b97\u56f0\u96be\u7684\u3002", "motivation": "\u7814\u7a76\u90e8\u5206q^\u03c0\u53ef\u5b9e\u73b0\u6027\u6846\u67b6\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u8be5\u6846\u67b6\u5047\u8bbe\u7b56\u7565\u96c6\u4e2d\u6240\u6709\u7b56\u7565\u7684\u4ef7\u503c\u51fd\u6570\u90fd\u662f\u7ebf\u6027\u53ef\u5b9e\u73b0\u7684\uff0c\u6bd4q^\u03c0\u53ef\u5b9e\u73b0\u6027\u5f31\u4f46\u6bd4q^*\u53ef\u5b9e\u73b0\u6027\u5f3a\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u51fd\u6570\u903c\u8fd1\u81ea\u7136\u51fa\u73b0\u7684\u5b9e\u7528\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u4ece\u03b4-Max-3SAT\u548c\u03b4-Max-3SAT(b)\u95ee\u9898\u5f52\u7ea6\u5230GLinear-\u03ba-RL\uff08\u8d2a\u5a6a\u7b56\u7565\uff09\u548cSLinear-\u03ba-RL\uff08softmax\u7b56\u7565\uff09\u5b9e\u4f8b\uff0c\u5efa\u7acb\u8ba1\u7b97\u590d\u6742\u6027\u7ed3\u679c\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u53c2\u6570\u5316\u8d2a\u5a6a\u7b56\u7565\u96c6\u4e0b\u5b66\u4e60\u03b5\u6700\u4f18\u7b56\u7565\u662fNP\u56f0\u96be\u7684\uff0c\u5728softmax\u7b56\u7565\u96c6\u4e0b\uff08\u9664\u975eNP=RP\uff09\u5b58\u5728\u6307\u6570\u7ea7\u4e0b\u754c\uff08\u7279\u5f81\u5411\u91cf\u7ef4\u5ea6\uff09\u3002", "conclusion": "\u8ba1\u7b97\u56f0\u96be\u6027\u5728\u90e8\u5206q^\u03c0\u53ef\u5b9e\u73b0\u6027\u4e2d\u6301\u7eed\u5b58\u5728\uff0c\u5373\u4f7f\u7b56\u7565\u96c6\u6269\u5c55\u5230\u6700\u4f18\u7b56\u7565\u4e4b\u5916\uff0c\u4e0eq^*\u53ef\u5b9e\u73b0\u6027\u4e2d\u7684\u7ed3\u679c\u76f8\u4f3c\uff0c\u8868\u660e\u5728\u8be5\u6846\u67b6\u4e0b\u901a\u5e38\u65e0\u6cd5\u83b7\u5f97\u79ef\u6781\u7684\u8ba1\u7b97\u7ed3\u679c\u3002"}}
{"id": "2510.22850", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.22850", "abs": "https://arxiv.org/abs/2510.22850", "authors": ["Nikolaos Georgiadis", "Eleftherios Tiakas", "Apostolos N. Papadopoulos"], "title": "Community Search in Attributed Networks using Dominance Relationships and Random Walks", "comment": null, "summary": "Community search in attributed networks poses a dual challenge: balancing\nstructural connectivity -- the network's topological properties -- and\nattribute similarity -- the shared characteristics of nodes. This paper\nintroduces a novel algorithm that integrates hop-based and random-walk-based\nmethods to identify high-quality communities, effectively addressing this\nbalance. Our approach employs the concept of the domination score to quantify\nthe influence of nodes based on their attributes, followed by $k$-core\nextraction to ensure strong structural cohesion within the communities. By\nconsidering both the network structure and node attributes, the algorithm\nidentifies communities that are not only well-connected, but also share\nmeaningful attribute similarities. We evaluated the algorithm on large\nreal-world datasets, demonstrating its ability to efficiently identify cohesive\ncommunities, making it suitable for applications such as social network\nanalysis and recommendation systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u8df3\u6570\u548c\u968f\u673a\u6e38\u8d70\u65b9\u6cd5\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u5c5e\u6027\u7f51\u7edc\u4e2d\u5e73\u8861\u7ed3\u6784\u8fde\u901a\u6027\u548c\u5c5e\u6027\u76f8\u4f3c\u6027\uff0c\u8bc6\u522b\u9ad8\u8d28\u91cf\u793e\u533a\u3002", "motivation": "\u89e3\u51b3\u5c5e\u6027\u7f51\u7edc\u4e2d\u793e\u533a\u641c\u7d22\u7684\u53cc\u91cd\u6311\u6218\uff1a\u5e73\u8861\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\u8fde\u901a\u6027\u548c\u8282\u70b9\u5c5e\u6027\u76f8\u4f3c\u6027\u3002", "method": "\u4f7f\u7528\u652f\u914d\u5206\u6570\u91cf\u5316\u8282\u70b9\u57fa\u4e8e\u5c5e\u6027\u7684\u5f71\u54cd\u529b\uff0c\u7136\u540e\u901a\u8fc7k-core\u63d0\u53d6\u786e\u4fdd\u793e\u533a\u5185\u7684\u5f3a\u7ed3\u6784\u51dd\u805a\u529b\uff0c\u7ed3\u5408\u8df3\u6570\u548c\u968f\u673a\u6e38\u8d70\u65b9\u6cd5\u3002", "result": "\u5728\u5927\u578b\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8bc1\u660e\u7b97\u6cd5\u80fd\u6709\u6548\u8bc6\u522b\u5177\u6709\u51dd\u805a\u529b\u7684\u793e\u533a\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u9002\u7528\u4e8e\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u548c\u63a8\u8350\u7cfb\u7edf\u7b49\u5e94\u7528\uff0c\u80fd\u591f\u9ad8\u6548\u8bc6\u522b\u65e2\u8fde\u63a5\u826f\u597d\u53c8\u5177\u6709\u6709\u610f\u4e49\u5c5e\u6027\u76f8\u4f3c\u6027\u7684\u793e\u533a\u3002"}}
{"id": "2510.23540", "categories": ["econ.EM"], "pdf": "https://arxiv.org/pdf/2510.23540", "abs": "https://arxiv.org/abs/2510.23540", "authors": ["Raimondo Pala"], "title": "The causal interpretation of panel vector autoregressions", "comment": null, "summary": "This paper discusses the different contemporaneous causal interpretations of\nPanel Vector Autoregressions (PVAR). I show that the interpretation of PVARs\ndepends on the distribution of the causing variable, and can range from average\ntreatment effects, to average causal responses, to a combination of the two. If\nthe researcher is willing to postulate a no residual autocorrelation\nassumption, and some units can be thought of as controls, PVAR can identify\naverage treatment effects on the treated. This method complements the toolkits\nalready present in the literature, such as staggered-DiD, or LP-DiD, as it\nformulates assumptions in the residuals, and not in the outcome variables. Such\na method features a notable advantage: it allows units to be ``sparsely''\ntreated, capturing the impact of interventions on the innovation component of\nthe outcome variables. I provide an example related to the evaluation of the\neffects of natural disasters economic activity at the weekly frequency in the\nUS.I conclude by discussing solutions to potential violations of the SUTVA\nassumption arising from interference.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u9762\u677f\u5411\u91cf\u81ea\u56de\u5f52\uff08PVAR\uff09\u7684\u4e0d\u540c\u540c\u671f\u56e0\u679c\u89e3\u91ca\uff0c\u5c55\u793a\u4e86\u5176\u89e3\u91ca\u53d6\u51b3\u4e8e\u56e0\u679c\u53d8\u91cf\u7684\u5206\u5e03\uff0c\u8303\u56f4\u4ece\u5e73\u5747\u5904\u7406\u6548\u5e94\u5230\u5e73\u5747\u56e0\u679c\u54cd\u5e94\u3002\u5728\u65e0\u6b8b\u5dee\u81ea\u76f8\u5173\u5047\u8bbe\u4e0b\uff0cPVAR\u53ef\u4ee5\u8bc6\u522b\u5904\u7406\u7ec4\u7684\u5e73\u5747\u5904\u7406\u6548\u5e94\u3002", "motivation": "\u8865\u5145\u73b0\u6709\u6587\u732e\u4e2d\u7684\u5de5\u5177\uff08\u5982\u4ea4\u9519DiD\u3001LP-DiD\uff09\uff0c\u901a\u8fc7\u6b8b\u5dee\u800c\u975e\u7ed3\u679c\u53d8\u91cf\u6765\u5236\u5b9a\u5047\u8bbe\uff0c\u5141\u8bb8\u5355\u4f4d\u88ab\"\u7a00\u758f\"\u5904\u7406\uff0c\u6355\u6349\u5e72\u9884\u5bf9\u7ed3\u679c\u53d8\u91cf\u521b\u65b0\u6210\u5206\u7684\u5f71\u54cd\u3002", "method": "\u57fa\u4e8e\u65e0\u6b8b\u5dee\u81ea\u76f8\u5173\u5047\u8bbe\uff0c\u5c06\u67d0\u4e9b\u5355\u4f4d\u89c6\u4e3a\u5bf9\u7167\u7ec4\uff0c\u4f7f\u7528\u9762\u677f\u5411\u91cf\u81ea\u56de\u5f52\u6a21\u578b\u8bc6\u522b\u5904\u7406\u7ec4\u7684\u5e73\u5747\u5904\u7406\u6548\u5e94\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8bc4\u4f30\u7f8e\u56fd\u81ea\u7136\u707e\u5bb3\u5bf9\u7ecf\u6d4e\u6d3b\u52a8\u5468\u9891\u5f71\u54cd\u7684\u5b9e\u4f8b\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u5e94\u7528\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u89e3\u51b3SUTVA\u5047\u8bbe\u56e0\u5e72\u6270\u800c\u53ef\u80fd\u88ab\u8fdd\u53cd\u7684\u65b9\u6848\u3002"}}
{"id": "2510.22324", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.22324", "abs": "https://arxiv.org/abs/2510.22324", "authors": ["Yifei Wang", "Han Wang", "Kehao Zhuang", "Keith Moffat", "Florian D\u00f6rfler"], "title": "Model-Free Power System Stability Enhancement with Dissipativity-Based Neural Control", "comment": "7 pages, 6 figures, submitted to the 24th Power Systems Computation\n  Conference (PSCC 2026)", "summary": "The integration of converter-interfaced generation introduces new transient\nstability challenges to modern power systems. Classical Lyapunov- and scalable\npassivity-based approaches typically rely on restrictive assumptions, and\nfinding storage functions for large grids is generally considered intractable.\nFurthermore, most methods require an accurate grid dynamics model. To address\nthese challenges, we propose a model-free, nonlinear, and dissipativity-based\ncontroller which, when applied to grid-connected virtual synchronous generators\n(VSGs), enhances power system transient stability. Using input-state data, we\ntrain neural networks to learn dissipativity-characterizing matrices that yield\nstabilizing controllers. Furthermore, we incorporate cost function shaping to\nimprove the performance with respect to the user-specified objectives.\nNumerical results on a modified, all-VSG Kundur two-area power system validate\nthe effectiveness of the proposed approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8017\u6563\u6027\u7684\u65e0\u6a21\u578b\u975e\u7ebf\u6027\u63a7\u5236\u5668\uff0c\u7528\u4e8e\u589e\u5f3a\u865a\u62df\u540c\u6b65\u53d1\u7535\u673a(VSG)\u7684\u7535\u529b\u7cfb\u7edf\u6682\u6001\u7a33\u5b9a\u6027\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u8017\u6563\u6027\u7279\u5f81\u77e9\u9635\u6765\u83b7\u5f97\u7a33\u5b9a\u63a7\u5236\u5668\u3002", "motivation": "\u53d8\u6d41\u5668\u63a5\u53e3\u53d1\u7535\u7684\u96c6\u6210\u7ed9\u73b0\u4ee3\u7535\u529b\u7cfb\u7edf\u5e26\u6765\u65b0\u7684\u6682\u6001\u7a33\u5b9a\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u9650\u5236\u6027\u5047\u8bbe\u4e14\u96be\u4ee5\u627e\u5230\u5927\u7535\u7f51\u7684\u5b58\u50a8\u51fd\u6570\uff0c\u5927\u591a\u6570\u65b9\u6cd5\u9700\u8981\u7cbe\u786e\u7684\u7535\u7f51\u52a8\u6001\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u8f93\u5165\u72b6\u6001\u6570\u636e\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u8017\u6563\u6027\u7279\u5f81\u77e9\u9635\uff0c\u7ed3\u5408\u6210\u672c\u51fd\u6570\u6574\u5f62\u6539\u8fdb\u7528\u6237\u6307\u5b9a\u76ee\u6807\u7684\u6027\u80fd\uff0c\u63d0\u51fa\u57fa\u4e8e\u8017\u6563\u6027\u7684\u65e0\u6a21\u578b\u975e\u7ebf\u6027\u63a7\u5236\u5668\u3002", "result": "\u5728\u6539\u8fdb\u7684\u5168VSG Kundur\u4e24\u533a\u57df\u7535\u529b\u7cfb\u7edf\u4e0a\u7684\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u589e\u5f3a\u7535\u529b\u7cfb\u7edf\u6682\u6001\u7a33\u5b9a\u6027\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u7cbe\u786e\u6a21\u578b\u548c\u9650\u5236\u6027\u5047\u8bbe\u7684\u95ee\u9898\u3002"}}
{"id": "2510.23014", "categories": ["stat.AP", "62R10"], "pdf": "https://arxiv.org/pdf/2510.23014", "abs": "https://arxiv.org/abs/2510.23014", "authors": ["Giovanna Bimonte", "Maria Russolillo", "Han Lin Shang", "Yang Yang"], "title": "Mortality Models Ensemble via Shapley Value", "comment": "31 pages, 6 figures, 5 tables", "summary": "Model averaging techniques in the actuarial literature aim to forecast future\nlongevity appropriately by combining forecasts derived from various models.\nThis approach often yields more accurate predictions than those generated by a\nsingle model. The key to enhancing forecast accuracy through model averaging\nlies in identifying the optimal weights from a finite sample. Utilizing\nsub-optimal weights in computations may adversely impact the accuracy of the\nmodel-averaged longevity forecasts. By proposing a game-theoretic approach\nemploying Shapley values for weight selection, our study clarifies the distinct\nimpact of each model on the collective predictive outcome. This analysis not\nonly delineates the importance of each model in decision-making processes, but\nalso provides insight into their contribution to the overall predictive\nperformance of the ensemble.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u535a\u5f08\u8bbaShapley\u503c\u7684\u6a21\u578b\u5e73\u5747\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u9ad8\u5bff\u9669\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u901a\u8fc7\u4f18\u5316\u6743\u91cd\u5206\u914d\u6765\u6539\u5584\u6574\u4f53\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u5e73\u5747\u65b9\u6cd5\u5728\u5bff\u9669\u9884\u6d4b\u4e2d\u867d\u7136\u80fd\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u6743\u91cd\u9009\u62e9\u4e0d\u5f53\u4f1a\u964d\u4f4e\u9884\u6d4b\u6548\u679c\u3002\u9700\u8981\u627e\u5230\u66f4\u4f18\u7684\u6743\u91cd\u5206\u914d\u65b9\u6cd5\u6765\u5145\u5206\u53d1\u6325\u5404\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u91c7\u7528\u535a\u5f08\u8bba\u4e2d\u7684Shapley\u503c\u65b9\u6cd5\u6765\u786e\u5b9a\u5404\u6a21\u578b\u5728\u7ec4\u5408\u9884\u6d4b\u4e2d\u7684\u6743\u91cd\uff0c\u91cf\u5316\u6bcf\u4e2a\u6a21\u578b\u5bf9\u6574\u4f53\u9884\u6d4b\u7ed3\u679c\u7684\u8d21\u732e\u5ea6\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8bc6\u522b\u5404\u6a21\u578b\u7684\u91cd\u8981\u6027\uff0c\u4f18\u5316\u6743\u91cd\u5206\u914d\uff0c\u4ece\u800c\u63d0\u9ad8\u957f\u5bff\u9884\u6d4b\u7684\u6574\u4f53\u51c6\u786e\u6027\u3002", "conclusion": "\u57fa\u4e8eShapley\u503c\u7684\u6a21\u578b\u5e73\u5747\u65b9\u6cd5\u4e3a\u5bff\u9669\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u79d1\u5b66\u7684\u6743\u91cd\u9009\u62e9\u673a\u5236\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u548c\u51b3\u7b56\u8d28\u91cf\u3002"}}
{"id": "2510.21751", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.21751", "abs": "https://arxiv.org/abs/2510.21751", "authors": ["Van Nam Dinh", "Van Vy Phan", "Thai Son Dang", "Van Du Phan", "The Anh Mai", "Van Chuong Le", "Sy Phuong Ho", "Dinh Tu Duong", "Hung Cuong Ta"], "title": "Real-time Mixed-Integer Quadratic Programming for Driving Behavior-Inspired Speed Bump Optimal Trajectory Planning", "comment": null, "summary": "This paper proposes a novel methodology for trajectory planning in autonomous\nvehicles (AVs), addressing the complex challenge of negotiating speed bumps\nwithin a unified Mixed-Integer Quadratic Programming (MIQP) framework. By\nleveraging Model Predictive Control (MPC), we develop trajectories that\noptimize both the traversal of speed bumps and overall passenger comfort. A key\ncontribution of this work is the formulation of speed bump handling constraints\nthat closely emulate human driving behavior, seamlessly integrating these with\nbroader road navigation requirements. Through extensive simulations in varied\nurban driving environments, we demonstrate the efficacy of our approach,\nhighlighting its ability to ensure smooth speed transitions over speed bumps\nwhile maintaining computational efficiency suitable for real-time deployment.\nThe method's capability to handle both static road features and dynamic\nconstraints, alongside expert human driving, represents a significant step\nforward in trajectory planning for urban", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u6574\u6570\u4e8c\u6b21\u89c4\u5212\u548c\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u81ea\u52a8\u9a7e\u9a76\u8f68\u8ff9\u89c4\u5212\u65b9\u6cd5\uff0c\u4e13\u95e8\u4f18\u5316\u8f66\u8f86\u901a\u8fc7\u51cf\u901f\u5e26\u65f6\u7684\u4e58\u5ba2\u8212\u9002\u5ea6\uff0c\u6a21\u62df\u4eba\u7c7b\u9a7e\u9a76\u884c\u4e3a\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u901a\u8fc7\u51cf\u901f\u5e26\u65f6\u7684\u8f68\u8ff9\u89c4\u5212\u6311\u6218\uff0c\u9700\u8981\u540c\u65f6\u8003\u8651\u4e58\u5ba2\u8212\u9002\u5ea6\u548c\u5b9e\u65f6\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u4f7f\u7528\u6df7\u5408\u6574\u6570\u4e8c\u6b21\u89c4\u5212\u548c\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\uff0c\u5f00\u53d1\u4e86\u6a21\u62df\u4eba\u7c7b\u9a7e\u9a76\u884c\u4e3a\u7684\u51cf\u901f\u5e26\u5904\u7406\u7ea6\u675f\uff0c\u5e76\u4e0e\u9053\u8def\u5bfc\u822a\u8981\u6c42\u65e0\u7f1d\u96c6\u6210\u3002", "result": "\u5728\u591a\u79cd\u57ce\u5e02\u9a7e\u9a76\u73af\u5883\u4e2d\u7684\u6a21\u62df\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u786e\u4fdd\u8f66\u8f86\u5e73\u7a33\u901a\u8fc7\u51cf\u901f\u5e26\uff0c\u540c\u65f6\u4fdd\u6301\u9002\u5408\u5b9e\u65f6\u90e8\u7f72\u7684\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u540c\u65f6\u5904\u7406\u9759\u6001\u9053\u8def\u7279\u5f81\u548c\u52a8\u6001\u7ea6\u675f\uff0c\u7ed3\u5408\u4e13\u5bb6\u4eba\u7c7b\u9a7e\u9a76\u884c\u4e3a\uff0c\u4ee3\u8868\u4e86\u57ce\u5e02\u8f68\u8ff9\u89c4\u5212\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2510.22286", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.22286", "abs": "https://arxiv.org/abs/2510.22286", "authors": ["Hugo Roger Paz"], "title": "Hybrid Instructor Ai Assessment In Academic Projects: Efficiency, Equity, And Methodological Lessons", "comment": "12 pages, in Spanish language, 0 figures, 6 tables", "summary": "In technical subjects characterized by high enrollment, such as Basic\nHydraulics, the assessment of reports necessitates superior levels of\nobjectivity, consistency, and formative feedback; goals often compromised by\nfaculty workload. This study presents the implementation of a generative\nartificial intelligence (AI) assisted assessment system, supervised by\ninstructors, to grade 33 hydraulics reports. The central objective was to\nquantify its impact on the efficiency, quality, and fairness of the process.\nThe employed methodology included the calibration of the Large Language Model\n(LLM) with a detailed rubric, the batch processing of assignments, and a\nhuman-in-the-loop validation phase. The quantitative results revealed a\nnoteworthy 88% reduction in grading time (from 50 to 6 minutes per report,\nincluding verification) and a 733% increase in productivity. The quality of\nfeedback was substantially improved, evidenced by 100% rubric coverage and a\n150% increase in the anchoring of comments to textual evidence. The system\nproved to be equitable, exhibiting no bias related to report length, and highly\nreliable post-calibration (r = 0.96 between scores). It is concluded that the\nhybrid AI-instructor model optimizes the assessment process, thereby liberating\ntime for high-value pedagogical tasks and enhancing the fairness and quality of\nfeedback, in alignment with UNESCO's principles on the ethical use of AI in\neducation.", "AI": {"tldr": "\u672c\u7814\u7a76\u5728\u57fa\u7840\u6c34\u529b\u5b66\u8bfe\u7a0b\u4e2d\u5b9e\u65bd\u4e86\u4e00\u4e2a\u7531\u6559\u5e08\u76d1\u7763\u7684\u751f\u6210\u5f0fAI\u8f85\u52a9\u8bc4\u4f30\u7cfb\u7edf\uff0c\u7528\u4e8e\u6279\u653933\u4efd\u62a5\u544a\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bc4\u5206\u6548\u7387\u3001\u53cd\u9988\u8d28\u91cf\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u5728\u9ad8\u6ce8\u518c\u7387\u7684\u6280\u672f\u8bfe\u7a0b\u4e2d\uff0c\u62a5\u544a\u8bc4\u4f30\u9700\u8981\u9ad8\u5ea6\u7684\u5ba2\u89c2\u6027\u3001\u4e00\u81f4\u6027\u548c\u5f62\u6210\u6027\u53cd\u9988\uff0c\u4f46\u6559\u5e08\u5de5\u4f5c\u8d1f\u8377\u5f80\u5f80\u5f71\u54cd\u8fd9\u4e9b\u76ee\u6807\u7684\u5b9e\u73b0\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u914d\u5408\u8be6\u7ec6\u8bc4\u5206\u6807\u51c6\u8fdb\u884c\u6821\u51c6\uff0c\u6279\u91cf\u5904\u7406\u4f5c\u4e1a\uff0c\u5e76\u91c7\u7528\u4eba\u5728\u56de\u8def\u9a8c\u8bc1\u9636\u6bb5\u3002", "result": "\u8bc4\u5206\u65f6\u95f4\u51cf\u5c1188%(\u4ece50\u5206\u949f\u964d\u81f36\u5206\u949f/\u62a5\u544a)\uff0c\u751f\u4ea7\u7387\u63d0\u9ad8733%\uff0c\u53cd\u9988\u8d28\u91cf\u663e\u8457\u6539\u5584(100%\u8bc4\u5206\u6807\u51c6\u8986\u76d6\uff0c\u57fa\u4e8e\u6587\u672c\u8bc1\u636e\u7684\u8bc4\u8bba\u589e\u52a0150%)\uff0c\u7cfb\u7edf\u516c\u5e73\u53ef\u9760(\u6821\u51c6\u540e\u8bc4\u5206\u76f8\u5173\u6027r=0.96)\u3002", "conclusion": "AI-\u6559\u5e08\u6df7\u5408\u6a21\u578b\u4f18\u5316\u4e86\u8bc4\u4f30\u8fc7\u7a0b\uff0c\u91ca\u653e\u4e86\u9ad8\u4ef7\u503c\u6559\u5b66\u4efb\u52a1\u7684\u65f6\u95f4\uff0c\u63d0\u9ad8\u4e86\u53cd\u9988\u7684\u516c\u5e73\u6027\u548c\u8d28\u91cf\uff0c\u7b26\u5408UNESCO\u5173\u4e8eAI\u5728\u6559\u80b2\u4e2d\u4f26\u7406\u4f7f\u7528\u7684\u539f\u5219\u3002"}}
{"id": "2510.21970", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.21970", "abs": "https://arxiv.org/abs/2510.21970", "authors": ["Josip Tomo Licardo", "Nikola Tankovic"], "title": "Performance Trade-offs of Optimizing Small Language Models for E-Commerce", "comment": "15 pages, 9 figures", "summary": "Large Language Models (LLMs) offer state-of-the-art performance in natural\nlanguage understanding and generation tasks. However, the deployment of leading\ncommercial models for specialized tasks, such as e-commerce, is often hindered\nby high computational costs, latency, and operational expenses. This paper\ninvestigates the viability of smaller, open-weight models as a\nresource-efficient alternative. We present a methodology for optimizing a\none-billion-parameter Llama 3.2 model for multilingual e-commerce intent\nrecognition. The model was fine-tuned using Quantized Low-Rank Adaptation\n(QLoRA) on a synthetically generated dataset designed to mimic real-world user\nqueries. Subsequently, we applied post-training quantization techniques,\ncreating GPU-optimized (GPTQ) and CPU-optimized (GGUF) versions. Our results\ndemonstrate that the specialized 1B model achieves 99% accuracy, matching the\nperformance of the significantly larger GPT-4.1 model. A detailed performance\nanalysis revealed critical, hardware-dependent trade-offs: while 4-bit GPTQ\nreduced VRAM usage by 41%, it paradoxically slowed inference by 82% on an older\nGPU architecture (NVIDIA T4) due to dequantization overhead. Conversely, GGUF\nformats on a CPU achieved a speedup of up to 18x in inference throughput and a\nreduction of over 90% in RAM consumption compared to the FP16 baseline. We\nconclude that small, properly optimized open-weight models are not just a\nviable but a more suitable alternative for domain-specific applications,\noffering state-of-the-art accuracy at a fraction of the computational cost.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u66ff\u4ee3\u5927\u578b\u5546\u4e1a\u6a21\u578b\u8fdb\u884c\u7535\u5546\u610f\u56fe\u8bc6\u522b\u7684\u53ef\u884c\u6027\uff0c\u5c55\u793a\u4e861B\u53c2\u6570\u6a21\u578b\u901a\u8fc7\u4f18\u5316\u540e\u80fd\u8fbe\u5230\u4e0eGPT-4.1\u76f8\u5f53\u768499%\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5927\u578b\u5546\u4e1a\u6a21\u578b\u5728\u7535\u5546\u7b49\u4e13\u4e1a\u4efb\u52a1\u4e2d\u90e8\u7f72\u9762\u4e34\u9ad8\u8ba1\u7b97\u6210\u672c\u3001\u5ef6\u8fdf\u548c\u8fd0\u8425\u8d39\u7528\u7684\u95ee\u9898\uff0c\u9700\u8981\u5bfb\u627e\u8d44\u6e90\u6548\u7387\u66f4\u9ad8\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u91cf\u5316\u4f4e\u79e9\u9002\u5e94(QLoRA)\u5fae\u8c0310\u4ebf\u53c2\u6570Llama 3.2\u6a21\u578b\uff0c\u4f7f\u7528\u5408\u6210\u6570\u636e\u96c6\u6a21\u62df\u771f\u5b9e\u7528\u6237\u67e5\u8be2\uff0c\u5e76\u5e94\u7528\u540e\u8bad\u7ec3\u91cf\u5316\u6280\u672f\u521b\u5efaGPU\u4f18\u5316(GPTQ)\u548cCPU\u4f18\u5316(GGUF)\u7248\u672c\u3002", "result": "\u4e13\u75281B\u6a21\u578b\u8fbe\u523099%\u51c6\u786e\u7387\uff0c\u4e0eGPT-4.1\u6027\u80fd\u76f8\u5f53\u30024\u4f4dGPTQ\u51cf\u5c1141%\u663e\u5b58\u4f7f\u7528\u4f46\u63a8\u7406\u901f\u5ea6\u4e0b\u964d82%\uff0cGGUF\u683c\u5f0f\u5728CPU\u4e0a\u5b9e\u73b018\u500d\u63a8\u7406\u541e\u5410\u91cf\u63d0\u5347\u548c90%\u4ee5\u4e0a\u5185\u5b58\u6d88\u8017\u51cf\u5c11\u3002", "conclusion": "\u7ecf\u8fc7\u9002\u5f53\u4f18\u5316\u7684\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u4e0d\u4ec5\u662f\u53ef\u884c\u7684\uff0c\u800c\u4e14\u662f\u9886\u57df\u7279\u5b9a\u5e94\u7528\u66f4\u5408\u9002\u7684\u9009\u62e9\uff0c\u80fd\u4ee5\u6781\u4f4e\u8ba1\u7b97\u6210\u672c\u63d0\u4f9b\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2510.22904", "categories": ["cs.SI", "cs.CL", "cs.CY", "68T50, 91D30", "I.2.7; H.3.1; J.4"], "pdf": "https://arxiv.org/pdf/2510.22904", "abs": "https://arxiv.org/abs/2510.22904", "authors": ["Margarida Mendonca", "Alvaro Figueira"], "title": "Modeling Political Discourse with Sentence-BERT and BERTopic", "comment": "11 pages. Continues previous study by Mendonca M. and Figueira A,\n  2023: \"Analyzing Political Discourse in the 117th U.S. Congress Using\n  Transformer-Based Topic Models\", presented at the International Conference on\n  Computational Social Science", "summary": "Social media has reshaped political discourse, offering politicians a\nplatform for direct engagement while reinforcing polarization and ideological\ndivides. This study introduces a novel topic evolution framework that\nintegrates BERTopic-based topic modeling with Moral Foundations Theory (MFT) to\nanalyze the longevity and moral dimensions of political topics in Twitter\nactivity during the 117th U.S. Congress. We propose a methodology for tracking\ndynamic topic shifts over time and measuring their association with moral\nvalues and quantifying topic persistence. Our findings reveal that while\noverarching themes remain stable, granular topics tend to dissolve rapidly,\nlimiting their long-term influence. Moreover, moral foundations play a critical\nrole in topic longevity, with Care and Loyalty dominating durable topics, while\npartisan differences manifest in distinct moral framing strategies. This work\ncontributes to the field of social network analysis and computational political\ndiscourse by offering a scalable, interpretable approach to understanding\nmoral-driven topic evolution on social media.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408BERTopic\u4e3b\u9898\u5efa\u6a21\u548c\u9053\u5fb7\u57fa\u7840\u7406\u8bba\u7684\u4e3b\u9898\u6f14\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u7f8e\u56fd\u7b2c117\u5c4a\u56fd\u4f1a\u671f\u95f4Twitter\u653f\u6cbb\u8bdd\u9898\u7684\u6301\u4e45\u6027\u548c\u9053\u5fb7\u7ef4\u5ea6\u3002\u7814\u7a76\u53d1\u73b0\u5b8f\u89c2\u4e3b\u9898\u7a33\u5b9a\u4f46\u7ec6\u7c92\u5ea6\u8bdd\u9898\u5feb\u901f\u6d88\u6563\uff0c\u9053\u5fb7\u57fa\u7840\u5bf9\u8bdd\u9898\u6301\u4e45\u6027\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u91cd\u5851\u4e86\u653f\u6cbb\u8bdd\u8bed\uff0c\u4e3a\u653f\u6cbb\u5bb6\u63d0\u4f9b\u4e86\u76f4\u63a5\u53c2\u4e0e\u5e73\u53f0\uff0c\u4f46\u4e5f\u52a0\u5267\u4e86\u6781\u5316\u548c\u610f\u8bc6\u5f62\u6001\u5206\u6b67\u3002\u9700\u8981\u7406\u89e3\u653f\u6cbb\u8bdd\u9898\u5982\u4f55\u968f\u65f6\u95f4\u6f14\u53d8\u53ca\u5176\u9053\u5fb7\u7ef4\u5ea6\u3002", "method": "\u96c6\u6210BERTopic\u4e3b\u9898\u5efa\u6a21\u4e0e\u9053\u5fb7\u57fa\u7840\u7406\u8bba(MFT)\uff0c\u63d0\u51fa\u8ddf\u8e2a\u52a8\u6001\u8bdd\u9898\u6f14\u53d8\u7684\u65b9\u6cd5\uff0c\u6d4b\u91cf\u8bdd\u9898\u4e0e\u9053\u5fb7\u4ef7\u503c\u89c2\u7684\u5173\u8054\u5e76\u91cf\u5316\u8bdd\u9898\u6301\u4e45\u6027\u3002", "result": "\u5b8f\u89c2\u4e3b\u9898\u4fdd\u6301\u7a33\u5b9a\uff0c\u4f46\u7ec6\u7c92\u5ea6\u8bdd\u9898\u503e\u5411\u4e8e\u5feb\u901f\u6d88\u6563\uff1b\u9053\u5fb7\u57fa\u7840\u5728\u8bdd\u9898\u6301\u4e45\u6027\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u5173\u6000\u548c\u5fe0\u8bda\u4e3b\u5bfc\u6301\u4e45\u8bdd\u9898\uff1b\u515a\u6d3e\u5dee\u5f02\u4f53\u73b0\u5728\u4e0d\u540c\u7684\u9053\u5fb7\u6846\u67b6\u7b56\u7565\u4e2d\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u793e\u4f1a\u7f51\u7edc\u5206\u6790\u548c\u8ba1\u7b97\u653f\u6cbb\u8bdd\u8bed\u9886\u57df\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u6765\u7406\u89e3\u793e\u4ea4\u5a92\u4f53\u4e0a\u9053\u5fb7\u9a71\u52a8\u7684\u4e3b\u9898\u6f14\u5316\u3002"}}
{"id": "2510.22374", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.22374", "abs": "https://arxiv.org/abs/2510.22374", "authors": ["Shengyuan Niu", "Haoran Wang", "Heejip Moon", "Andrea L'Afflitto", "Andrew Kurdila", "Daniel Stilwell"], "title": "Vector-Valued Native Space Embedding for Adaptive State Observation", "comment": null, "summary": "This paper combines vector-valued reproducing kernel Hilbert space (vRKHS)\nembedding with robust adaptive observation, yielding an algorithm that is both\nnon-parametric and robust. The main contribution of this paper lies in the\nability of the proposed system to estimate the state of a plan model whose\nmatched uncertainties are elements of an infinite-dimensional native space. The\nplant model considered in this paper also suffers from unmatched uncertainties.\nFinally, the measured output is affected by disturbances as well. Upper bounds\non the state observation error are provided in an analytical form. The proposed\ntheoretical results are applied to the problem of estimating the state of a\nrigid body.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5411\u91cf\u503c\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u5d4c\u5165\u4e0e\u9c81\u68d2\u81ea\u9002\u5e94\u89c2\u6d4b\u7684\u7b97\u6cd5\uff0c\u80fd\u591f\u4f30\u8ba1\u5177\u6709\u65e0\u9650\u7ef4\u539f\u751f\u7a7a\u95f4\u4e2d\u5339\u914d\u4e0d\u786e\u5b9a\u6027\u548c\u4e0d\u5339\u914d\u4e0d\u786e\u5b9a\u6027\u7684\u5e73\u9762\u6a21\u578b\u72b6\u6001\uff0c\u5e76\u63d0\u4f9b\u4e86\u72b6\u6001\u89c2\u6d4b\u8bef\u5dee\u7684\u4e0a\u754c\u5206\u6790\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5e73\u9762\u6a21\u578b\u4e2d\u5b58\u5728\u7684\u5339\u914d\u4e0d\u786e\u5b9a\u6027\uff08\u5c5e\u4e8e\u65e0\u9650\u7ef4\u539f\u751f\u7a7a\u95f4\uff09\u3001\u4e0d\u5339\u914d\u4e0d\u786e\u5b9a\u6027\u4ee5\u53ca\u6d4b\u91cf\u8f93\u51fa\u53d7\u5e72\u6270\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u65e2\u975e\u53c2\u6570\u5316\u53c8\u5177\u6709\u9c81\u68d2\u6027\u7684\u72b6\u6001\u4f30\u8ba1\u7b97\u6cd5\u3002", "method": "\u5c06\u5411\u91cf\u503c\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u5d4c\u5165\u4e0e\u9c81\u68d2\u81ea\u9002\u5e94\u89c2\u6d4b\u76f8\u7ed3\u5408\uff0c\u6784\u5efa\u975e\u53c2\u6570\u5316\u9c81\u68d2\u7b97\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u65e0\u9650\u7ef4\u539f\u751f\u7a7a\u95f4\u4e2d\u7684\u5339\u914d\u4e0d\u786e\u5b9a\u6027\u548c\u7cfb\u7edf\u7684\u4e0d\u5339\u914d\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u4f30\u8ba1\u521a\u6027\u4f53\u7b49\u7cfb\u7edf\u7684\u72b6\u6001\uff0c\u5e76\u63d0\u4f9b\u4e86\u72b6\u6001\u89c2\u6d4b\u8bef\u5dee\u7684\u89e3\u6790\u5f62\u5f0f\u4e0a\u754c\uff0c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u5177\u6709\u590d\u6742\u4e0d\u786e\u5b9a\u6027\u7ed3\u6784\u7684\u7cfb\u7edf\u72b6\u6001\u4f30\u8ba1\u95ee\u9898\uff0c\u4e3a\u975e\u53c2\u6570\u5316\u9c81\u68d2\u89c2\u6d4b\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2510.23437", "categories": ["stat.AP", "physics.comp-ph", "62F15 (Primary) 62H10, 60G70, 65C60, 74E15, 74A45 (Secondary)", "G.3; I.2.6; I.6.4; J.2"], "pdf": "https://arxiv.org/pdf/2510.23437", "abs": "https://arxiv.org/abs/2510.23437", "authors": ["Yinling Zhang", "Samuel D. Dunham", "Curt A. Bronkhorst", "Nan Chen"], "title": "A Physics-Informed Variational Inference Framework for Identifying Attributions of Extreme Stress Events in Low-Grain Polycrystals", "comment": "31 pages,8 figures", "summary": "Polycrystalline metal failure often begins with stress concentration at grain\nboundaries. Identifying which microstructural features trigger these events is\nimportant but challenging because these extreme damage events are rare and the\nfailure mechanisms involve multiple complex processes across scales. Most\nexisting inference methods focus on average behavior rather than rare events,\nwhereas standard sample-based methods are computationally expensive for\nhigh-dimensional complex systems. In this paper, we develop a new variational\ninference framework that integrates a recently developed computationally\nefficient physics-informed statistical model with extreme value statistics to\nsignificantly facilitate the identification of material failure attributions.\nFirst, we reformulate the objective to emphasize observed exceedances by\nincorporating extreme-value theory into the likelihood, thereby highlighting\ntail behavior. Second, we constrain inference via a physics-informed\nstatistical model that characterizes microstructure-stress relationships, which\nuniquely provides physically consistent predictions for these rare events.\nThird, mixture models in a reduced latent space are developed to capture the\nnon-Gaussian characteristics of microstructural features, allowing the\nidentification of multiple underlying mechanisms. In both controlled and\nrealistic experimental tests for the bicrystal configuration, the framework\nachieves reliable extreme-event prediction and reveals the microstructural\nfeatures associated with material failure, providing physical insights for\nmaterial design with uncertainty quantification.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53d8\u5206\u63a8\u65ad\u6846\u67b6\uff0c\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u7edf\u8ba1\u6a21\u578b\u548c\u6781\u503c\u7edf\u8ba1\uff0c\u7528\u4e8e\u8bc6\u522b\u591a\u6676\u91d1\u5c5e\u6750\u6599\u5931\u6548\u7684\u5fae\u89c2\u7ed3\u6784\u7279\u5f81\u3002", "motivation": "\u591a\u6676\u91d1\u5c5e\u5931\u6548\u901a\u5e38\u59cb\u4e8e\u6676\u754c\u5904\u7684\u5e94\u529b\u96c6\u4e2d\uff0c\u4f46\u8bc6\u522b\u89e6\u53d1\u8fd9\u4e9b\u6781\u7aef\u635f\u4f24\u4e8b\u4ef6\u7684\u5fae\u89c2\u7ed3\u6784\u7279\u5f81\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u6781\u7aef\u4e8b\u4ef6\u7f55\u89c1\u4e14\u6d89\u53ca\u8de8\u5c3a\u5ea6\u7684\u590d\u6742\u8fc7\u7a0b\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5e73\u5747\u884c\u4e3a\u800c\u975e\u7f55\u89c1\u4e8b\u4ef6\u3002", "method": "1. \u5c06\u6781\u503c\u7406\u8bba\u878d\u5165\u4f3c\u7136\u51fd\u6570\uff0c\u5f3a\u8c03\u5c3e\u90e8\u5206\u5e03\u884c\u4e3a\uff1b2. \u901a\u8fc7\u7269\u7406\u4fe1\u606f\u7edf\u8ba1\u6a21\u578b\u7ea6\u675f\u63a8\u65ad\uff0c\u63d0\u4f9b\u7269\u7406\u4e00\u81f4\u7684\u9884\u6d4b\uff1b3. \u5728\u964d\u7ef4\u6f5c\u7a7a\u95f4\u4e2d\u5f00\u53d1\u6df7\u5408\u6a21\u578b\uff0c\u6355\u6349\u5fae\u89c2\u7ed3\u6784\u7279\u5f81\u7684\u975e\u9ad8\u65af\u7279\u6027\u3002", "result": "\u5728\u53cc\u6676\u6784\u578b\u7684\u63a7\u5236\u548c\u5b9e\u9645\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u6781\u7aef\u4e8b\u4ef6\u9884\u6d4b\uff0c\u5e76\u63ed\u793a\u4e86\u4e0e\u6750\u6599\u5931\u6548\u76f8\u5173\u7684\u5fae\u89c2\u7ed3\u6784\u7279\u5f81\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6750\u6599\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7269\u7406\u89c1\u89e3\uff0c\u5e76\u5177\u6709\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u6750\u6599\u5931\u6548\u7684\u5fae\u89c2\u7ed3\u6784\u5f52\u56e0\u3002"}}
{"id": "2510.21758", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21758", "abs": "https://arxiv.org/abs/2510.21758", "authors": ["Kumater Ter", "RexCharles Donatus", "Ore-Ofe Ajayi", "Daniel Udekwe"], "title": "Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review", "comment": null, "summary": "Reinforcement learning (RL) has become a foundational approach for enabling\nintelligent robotic behavior in dynamic and uncertain environments. This work\npresents an in-depth review of RL principles, advanced deep reinforcement\nlearning (DRL) algorithms, and their integration into robotic and control\nsystems. Beginning with the formalism of Markov Decision Processes (MDPs), the\nstudy outlines essential elements of the agent-environment interaction and\nexplores core algorithmic strategies including actor-critic methods,\nvalue-based learning, and policy gradients. Emphasis is placed on modern DRL\ntechniques such as DDPG, TD3, PPO, and SAC, which have shown promise in solving\nhigh-dimensional, continuous control tasks. A structured taxonomy is introduced\nto categorize RL applications across domains such as locomotion, manipulation,\nmulti-agent coordination, and human-robot interaction, along with training\nmethodologies and deployment readiness levels. The review synthesizes recent\nresearch efforts, highlighting technical trends, design patterns, and the\ngrowing maturity of RL in real-world robotics. Overall, this work aims to\nbridge theoretical advances with practical implementations, providing a\nconsolidated perspective on the evolving role of RL in autonomous robotic\nsystems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5bf9\u5f3a\u5316\u5b66\u4e60\u5728\u673a\u5668\u4eba\u9886\u57df\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u6df1\u5ea6\u7efc\u8ff0\uff0c\u6db5\u76d6\u4e86RL\u57fa\u672c\u539f\u7406\u3001\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u53ca\u5176\u5728\u673a\u5668\u4eba\u63a7\u5236\u7cfb\u7edf\u4e2d\u7684\u96c6\u6210\u3002", "motivation": "\u65e8\u5728\u5f25\u5408\u5f3a\u5316\u5b66\u4e60\u7406\u8bba\u8fdb\u5c55\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u81ea\u4e3b\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u7684RL\u89d2\u8272\u63d0\u4f9b\u7edf\u4e00\u89c6\u89d2\u3002", "method": "\u4ece\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5f62\u5f0f\u5316\u5f00\u59cb\uff0c\u5206\u6790\u667a\u80fd\u4f53-\u73af\u5883\u4ea4\u4e92\u8981\u7d20\uff0c\u63a2\u8ba8actor-critic\u65b9\u6cd5\u3001\u57fa\u4e8e\u503c\u7684\u5b66\u4e60\u548c\u7b56\u7565\u68af\u5ea6\u7b49\u6838\u5fc3\u7b97\u6cd5\u7b56\u7565\uff0c\u91cd\u70b9\u5173\u6ce8DDPG\u3001TD3\u3001PPO\u548cSAC\u7b49\u73b0\u4ee3DRL\u6280\u672f\u3002", "result": "\u63d0\u51fa\u4e86\u7ed3\u6784\u5316\u5206\u7c7b\u6cd5\u6765\u5206\u7c7bRL\u5728\u8fd0\u52a8\u3001\u64cd\u4f5c\u3001\u591a\u667a\u80fd\u4f53\u534f\u8c03\u548c\u4eba\u673a\u4ea4\u4e92\u7b49\u9886\u57df\u7684\u5e94\u7528\uff0c\u603b\u7ed3\u4e86\u8bad\u7ec3\u65b9\u6cd5\u548c\u90e8\u7f72\u51c6\u5907\u5ea6\u6c34\u5e73\u3002", "conclusion": "\u7efc\u8ff0\u4e86\u6700\u65b0\u7814\u7a76\u8fdb\u5c55\uff0c\u5f3a\u8c03\u4e86\u6280\u672f\u8d8b\u52bf\u3001\u8bbe\u8ba1\u6a21\u5f0f\u4ee5\u53caRL\u5728\u73b0\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u4e2d\u65e5\u76ca\u6210\u719f\u7684\u4f5c\u7528\uff0c\u4e3a\u7406\u8bba\u548c\u5b9e\u8df5\u63d0\u4f9b\u4e86\u6865\u6881\u3002"}}
{"id": "2510.22423", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.22423", "abs": "https://arxiv.org/abs/2510.22423", "authors": ["Princessa Cintaqia", "Arshia Arya", "Elissa M Redmiles", "Deepak Kumar", "Allison McDonald", "Lucy Qin"], "title": "Stop the Nonconsensual Use of Nude Images in Research", "comment": null, "summary": "In order to train, test, and evaluate nudity detection models, machine\nlearning researchers typically rely on nude images scraped from the Internet.\nOur research finds that this content is collected and, in some cases,\nsubsequently distributed by researchers without consent, leading to potential\nmisuse and exacerbating harm against the subjects depicted. This position paper\nargues that the distribution of nonconsensually collected nude images by\nresearchers perpetuates image-based sexual abuse and that the machine learning\ncommunity should stop the nonconsensual use of nude images in research. To\ncharacterize the scope and nature of this problem, we conducted a systematic\nreview of papers published in computing venues that collect and use nude\nimages. Our results paint a grim reality: norms around the usage of nude images\nare sparse, leading to a litany of problematic practices like distributing and\npublishing nude images with uncensored faces, and intentionally collecting and\nsharing abusive content. We conclude with a call-to-action for publishing\nvenues and a vision for research in nudity detection that balances user agency\nwith concrete research objectives.", "AI": {"tldr": "\u672c\u6587\u6279\u8bc4\u673a\u5668\u5b66\u4e60\u7814\u7a76\u4e2d\u672a\u7ecf\u540c\u610f\u6536\u96c6\u548c\u4f7f\u7528\u88f8\u4f53\u56fe\u50cf\u7684\u505a\u6cd5\uff0c\u8ba4\u4e3a\u8fd9\u4f1a\u52a0\u5267\u56fe\u50cf\u6027\u8650\u5f85\uff0c\u547c\u5401\u505c\u6b62\u5728\u7814\u7a76\u4e2d\u975e\u81ea\u613f\u4f7f\u7528\u88f8\u4f53\u56fe\u50cf\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7814\u7a76\u8005\u901a\u5e38\u4ece\u4e92\u8054\u7f51\u6293\u53d6\u88f8\u4f53\u56fe\u50cf\u6765\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6a21\u578b\uff0c\u4f46\u8fd9\u4e9b\u5185\u5bb9\u662f\u5728\u672a\u7ecf\u540c\u610f\u7684\u60c5\u51b5\u4e0b\u6536\u96c6\u548c\u5206\u53d1\u7684\uff0c\u53ef\u80fd\u5bfc\u81f4\u6ee5\u7528\u5e76\u52a0\u5267\u5bf9\u88ab\u63cf\u7ed8\u5bf9\u8c61\u7684\u4f24\u5bb3\u3002", "method": "\u5bf9\u8ba1\u7b97\u9886\u57df\u53d1\u8868\u7684\u4f7f\u7528\u88f8\u4f53\u56fe\u50cf\u7684\u8bba\u6587\u8fdb\u884c\u7cfb\u7edf\u56de\u987e\uff0c\u5206\u6790\u5176\u4f7f\u7528\u8303\u56f4\u548c\u6027\u8d28\u3002", "result": "\u53d1\u73b0\u88f8\u4f53\u56fe\u50cf\u4f7f\u7528\u89c4\u8303\u7a00\u758f\uff0c\u5b58\u5728\u8bf8\u591a\u95ee\u9898\u5b9e\u8df5\uff0c\u5982\u5206\u53d1\u548c\u53d1\u5e03\u672a\u6253\u7801\u7684\u88f8\u4f53\u56fe\u50cf\u3001\u6545\u610f\u6536\u96c6\u548c\u5206\u4eab\u8650\u5f85\u5185\u5bb9\u7b49\u3002", "conclusion": "\u547c\u5401\u51fa\u7248\u673a\u6784\u548c\u7814\u7a76\u793e\u533a\u505c\u6b62\u975e\u81ea\u613f\u4f7f\u7528\u88f8\u4f53\u56fe\u50cf\uff0c\u63d0\u51fa\u5728\u88f8\u4f53\u68c0\u6d4b\u7814\u7a76\u4e2d\u5e73\u8861\u7528\u6237\u81ea\u4e3b\u6743\u4e0e\u5177\u4f53\u7814\u7a76\u76ee\u6807\u7684\u613f\u666f\u3002"}}
{"id": "2510.21977", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21977", "abs": "https://arxiv.org/abs/2510.21977", "authors": ["Ji Huang", "Mengfei Li", "Shuai Shao"], "title": "Distribution Shift Alignment Helps LLMs Simulate Survey Response Distributions", "comment": null, "summary": "Large language models (LLMs) offer a promising way to simulate human survey\nresponses, potentially reducing the cost of large-scale data collection.\nHowever, existing zero-shot methods suffer from prompt sensitivity and low\naccuracy, while conventional fine-tuning approaches mostly fit the training set\ndistributions and struggle to produce results more accurate than the training\nset itself, which deviates from the original goal of using LLMs to simulate\nsurvey responses. Building on this observation, we introduce Distribution Shift\nAlignment (DSA), a two-stage fine-tuning method that aligns both the output\ndistributions and the distribution shifts across different backgrounds. By\nlearning how these distributions change rather than fitting training data, DSA\ncan provide results substantially closer to the true distribution than the\ntraining data. Empirically, DSA consistently outperforms other methods on five\npublic survey datasets. We further conduct a comprehensive comparison covering\naccuracy, robustness, and data savings. DSA reduces the required real data by\n53.48-69.12%, demonstrating its effectiveness and efficiency in survey\nsimulation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u5206\u5e03\u504f\u79fb\u5bf9\u9f50\uff08DSA\uff09\u7684\u4e24\u9636\u6bb5\u5fae\u8c03\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u9ad8LLM\u6a21\u62df\u4eba\u7c7b\u8c03\u67e5\u54cd\u5e94\u7684\u51c6\u786e\u6027\uff0c\u663e\u8457\u51cf\u5c11\u771f\u5b9e\u6570\u636e\u9700\u6c42", "motivation": "\u73b0\u6709\u96f6\u6837\u672c\u65b9\u6cd5\u5b58\u5728\u63d0\u793a\u654f\u611f\u6027\u548c\u4f4e\u51c6\u786e\u6027\u95ee\u9898\uff0c\u800c\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u8fc7\u5ea6\u62df\u5408\u8bad\u7ec3\u96c6\u5206\u5e03\uff0c\u65e0\u6cd5\u4ea7\u751f\u6bd4\u8bad\u7ec3\u96c6\u66f4\u51c6\u786e\u7684\u7ed3\u679c", "method": "DSA\u901a\u8fc7\u4e24\u9636\u6bb5\u5fae\u8c03\u65b9\u6cd5\uff0c\u5bf9\u9f50\u8f93\u51fa\u5206\u5e03\u548c\u4e0d\u540c\u80cc\u666f\u4e0b\u7684\u5206\u5e03\u504f\u79fb\uff0c\u5b66\u4e60\u5206\u5e03\u53d8\u5316\u800c\u975e\u62df\u5408\u8bad\u7ec3\u6570\u636e", "result": "\u5728\u4e94\u4e2a\u516c\u5171\u8c03\u67e5\u6570\u636e\u96c6\u4e0a\uff0cDSA\u59cb\u7ec8\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u80fd\u591f\u5c06\u771f\u5b9e\u6570\u636e\u9700\u6c42\u51cf\u5c1153.48-69.12%", "conclusion": "DSA\u5728\u8c03\u67e5\u6a21\u62df\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u63d0\u4f9b\u6bd4\u8bad\u7ec3\u6570\u636e\u66f4\u63a5\u8fd1\u771f\u5b9e\u5206\u5e03\u7684\u7ed3\u679c\uff0c\u5177\u6709\u9ad8\u6548\u6027\u548c\u6709\u6548\u6027"}}
{"id": "2510.22429", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.22429", "abs": "https://arxiv.org/abs/2510.22429", "authors": ["Md Saiful Islam", "Rahul Bhadani"], "title": "Resilient Composite Control for Stability Enhancement in EV Integrated DC Microgrids", "comment": null, "summary": "When electric vehicles (EVs) are integrated into standalone DC microgrids\n(DCMGs), stability issues arise due to their constant power load (CPL)\nbehavior, which provides negative incremental impedance (NII). In addition, the\nmicrogrids suffer from an inherent low-inertia problem. Therefore, this study\npresents a composite controller incorporating a global integral terminal\nsliding mode controller with a backstepping controller. A virtual capacitor is\nemployed to mitigate the low-inertia issue and strengthen the DC-bus response.\nAn improved fractional power-based reaching law decreases chattering and\naccelerates convergence. Exact feedback linearization converts the nonlinear\nboost converter model into Brunovsky's canonical form, mitigating NII effects\nand non-minimum phase issues. The entire system stability is verified using\nLyapunov control theory. Simulation outcomes confirm superior performance, with\n34.4-53.3% reduction in overshoot, 52.9-74.9% in undershoot, and 12-47.4% in\nsettling time compared to the existing controller.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u590d\u5408\u63a7\u5236\u5668\uff0c\u7ed3\u5408\u5168\u5c40\u79ef\u5206\u7ec8\u7aef\u6ed1\u6a21\u63a7\u5236\u548c\u53cd\u6b65\u63a7\u5236\uff0c\u7528\u4e8e\u89e3\u51b3\u7535\u52a8\u6c7d\u8f66\u63a5\u5165\u72ec\u7acb\u76f4\u6d41\u5fae\u7535\u7f51\u65f6\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u865a\u62df\u7535\u5bb9\u6539\u5584\u4f4e\u60ef\u91cf\u95ee\u9898\uff0c\u91c7\u7528\u6539\u8fdb\u7684\u5206\u6570\u5e42\u8d8b\u8fd1\u5f8b\u51cf\u5c11\u6296\u632f\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u63a5\u5165\u72ec\u7acb\u76f4\u6d41\u5fae\u7535\u7f51\u65f6\uff0c\u5176\u6052\u529f\u7387\u8d1f\u8f7d\u7279\u6027\u4f1a\u4ea7\u751f\u8d1f\u589e\u91cf\u963b\u6297\uff0c\u540c\u65f6\u5fae\u7535\u7f51\u5b58\u5728\u56fa\u6709\u7684\u4f4e\u60ef\u91cf\u95ee\u9898\uff0c\u5bfc\u81f4\u7cfb\u7edf\u7a33\u5b9a\u6027\u6311\u6218\u3002", "method": "\u91c7\u7528\u590d\u5408\u63a7\u5236\u5668\uff08\u5168\u5c40\u79ef\u5206\u7ec8\u7aef\u6ed1\u6a21+\u53cd\u6b65\u63a7\u5236\uff09\uff0c\u4f7f\u7528\u865a\u62df\u7535\u5bb9\u589e\u5f3a\u76f4\u6d41\u6bcd\u7ebf\u54cd\u5e94\uff0c\u6539\u8fdb\u5206\u6570\u5e42\u8d8b\u8fd1\u5f8b\u51cf\u5c11\u6296\u632f\uff0c\u901a\u8fc7\u7cbe\u786e\u53cd\u9988\u7ebf\u6027\u5316\u5c06\u975e\u7ebf\u6027\u5347\u538b\u53d8\u6362\u5668\u6a21\u578b\u8f6c\u6362\u4e3aBrunovsky\u89c4\u8303\u5f62\u5f0f\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u73b0\u6709\u63a7\u5236\u5668\u76f8\u6bd4\uff0c\u8d85\u8c03\u91cf\u51cf\u5c1134.4-53.3%\uff0c\u6b20\u8c03\u91cf\u51cf\u5c1152.9-74.9%\uff0c\u8c03\u8282\u65f6\u95f4\u51cf\u5c1112-47.4%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u590d\u5408\u63a7\u5236\u5668\u80fd\u6709\u6548\u89e3\u51b3\u7535\u52a8\u6c7d\u8f66\u63a5\u5165\u76f4\u6d41\u5fae\u7535\u7f51\u65f6\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u663e\u8457\u6539\u5584\u7cfb\u7edf\u52a8\u6001\u6027\u80fd\uff0c\u5e76\u901a\u8fc7Lyapunov\u63a7\u5236\u7406\u8bba\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002"}}
{"id": "2510.23447", "categories": ["stat.AP", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.23447", "abs": "https://arxiv.org/abs/2510.23447", "authors": ["Anna Guerra", "Francesco Guidi", "Pau Closas", "Davide Dardari", "Petar M. Djuric"], "title": "Model Proficiency in Centralized Multi-Agent Systems: A Performance Study", "comment": null, "summary": "Autonomous agents are increasingly deployed in dynamic environments where\ntheir ability to perform a given task depends on both individual and team-level\nproficiency. While proficiency self-assessment (PSA) has been studied for\nsingle agents, its extension to a team of agents remains underexplored. This\nletter addresses this gap by presenting a framework for team PSA in centralized\nsettings. We investigate three metrics for centralized team PSA: the\nmeasurement prediction bound (MPB), the Kolmogorov-Smirnov (KS) statistic, and\nthe Kullback-Leibler (KL) divergence. These metrics quantify the discrepancy\nbetween predicted and actual measurements. We use the KL divergence as a\nreference metric since it compares the true and predictive distributions,\nwhereas the MPB and KS provide efficient indicators for in situ assessment.\nSimulation results in a target tracking scenario demonstrate that both MPB and\nKS metrics accurately capture model mismatches, align with the KL divergence\nreference, and enable real-time proficiency assessment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u56e2\u961f\u719f\u7ec3\u5ea6\u81ea\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u96c6\u4e2d\u5f0f\u8bbe\u7f6e\u4e2d\u7814\u7a76MPB\u3001KS\u7edf\u8ba1\u91cf\u548cKL\u6563\u5ea6\u4e09\u79cd\u6307\u6807\uff0c\u7528\u4e8e\u91cf\u5316\u9884\u6d4b\u4e0e\u5b9e\u9645\u6d4b\u91cf\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u5e76\u5728\u76ee\u6807\u8ddf\u8e2a\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u867d\u7136\u5355\u667a\u80fd\u4f53\u7684\u719f\u7ec3\u5ea6\u81ea\u8bc4\u4f30\u5df2\u6709\u7814\u7a76\uff0c\u4f46\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u56e2\u961f\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u7279\u522b\u662f\u5728\u52a8\u6001\u73af\u5883\u4e2d\u56e2\u961f\u6267\u884c\u4efb\u52a1\u80fd\u529b\u4f9d\u8d56\u4e8e\u4e2a\u4f53\u548c\u56e2\u961f\u5c42\u9762\u7684\u719f\u7ec3\u5ea6\u3002", "method": "\u63d0\u51fa\u96c6\u4e2d\u5f0f\u56e2\u961fPSA\u6846\u67b6\uff0c\u4f7f\u7528\u6d4b\u91cf\u9884\u6d4b\u8fb9\u754c(MPB)\u3001Kolmogorov-Smirnov(KS)\u7edf\u8ba1\u91cf\u548cKullback-Leibler(KL)\u6563\u5ea6\u4e09\u79cd\u6307\u6807\u6765\u91cf\u5316\u9884\u6d4b\u4e0e\u5b9e\u9645\u6d4b\u91cf\u7684\u5dee\u5f02\u3002", "result": "\u5728\u76ee\u6807\u8ddf\u8e2a\u573a\u666f\u7684\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cMPB\u548cKS\u6307\u6807\u80fd\u51c6\u786e\u6355\u6349\u6a21\u578b\u4e0d\u5339\u914d\uff0c\u4e0eKL\u6563\u5ea6\u53c2\u8003\u503c\u4e00\u81f4\uff0c\u5e76\u80fd\u5b9e\u73b0\u5b9e\u65f6\u719f\u7ec3\u5ea6\u8bc4\u4f30\u3002", "conclusion": "MPB\u548cKS\u6307\u6807\u4e3a\u56e2\u961f\u719f\u7ec3\u5ea6\u81ea\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5b9e\u65f6\u8bc4\u4f30\u5de5\u5177\uff0c\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u6a21\u578b\u4e0d\u5339\u914d\u95ee\u9898\u3002"}}
{"id": "2510.21761", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.21761", "abs": "https://arxiv.org/abs/2510.21761", "authors": ["Jesse Atuhurra", "Hidetaka Kamigaito", "Taro Watanabe", "Koichiro Yoshino"], "title": "J-ORA: A Framework and Multimodal Dataset for Japanese Object Identification, Reference, Action Prediction in Robot Perception", "comment": "Accepted to IROS2025", "summary": "We introduce J-ORA, a novel multimodal dataset that bridges the gap in robot\nperception by providing detailed object attribute annotations within Japanese\nhuman-robot dialogue scenarios. J-ORA is designed to support three critical\nperception tasks, object identification, reference resolution, and next-action\nprediction, by leveraging a comprehensive template of attributes (e.g.,\ncategory, color, shape, size, material, and spatial relations). Extensive\nevaluations with both proprietary and open-source Vision Language Models (VLMs)\nreveal that incorporating detailed object attributes substantially improves\nmultimodal perception performance compared to without object attributes.\nDespite the improvement, we find that there still exists a gap between\nproprietary and open-source VLMs. In addition, our analysis of object\naffordances demonstrates varying abilities in understanding object\nfunctionality and contextual relationships across different VLMs. These\nfindings underscore the importance of rich, context-sensitive attribute\nannotations in advancing robot perception in dynamic environments. See project\npage at https://jatuhurrra.github.io/J-ORA/.", "AI": {"tldr": "J-ORA\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u63d0\u4f9b\u65e5\u672c\u4eba\u673a\u5bf9\u8bdd\u573a\u666f\u4e2d\u7684\u8be6\u7ec6\u7269\u4f53\u5c5e\u6027\u6807\u6ce8\u6765\u5f25\u5408\u673a\u5668\u4eba\u611f\u77e5\u7684\u5dee\u8ddd\u3002\u8be5\u6570\u636e\u96c6\u652f\u6301\u7269\u4f53\u8bc6\u522b\u3001\u53c2\u8003\u89e3\u6790\u548c\u4e0b\u4e00\u52a8\u4f5c\u9884\u6d4b\u4e09\u4e2a\u5173\u952e\u611f\u77e5\u4efb\u52a1\u3002", "motivation": "\u5f25\u5408\u673a\u5668\u4eba\u611f\u77e5\u7684\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u65e5\u672c\u6587\u5316\u80cc\u666f\u4e0b\u7684\u4eba\u673a\u4ea4\u4e92\u573a\u666f\u4e2d\uff0c\u9700\u8981\u5305\u542b\u8be6\u7ec6\u7269\u4f53\u5c5e\u6027\u6807\u6ce8\u7684\u6570\u636e\u96c6\u6765\u63d0\u5347\u591a\u6a21\u6001\u611f\u77e5\u6027\u80fd\u3002", "method": "\u6784\u5efaJ-ORA\u6570\u636e\u96c6\uff0c\u5305\u542b\u8be6\u7ec6\u7684\u7269\u4f53\u5c5e\u6027\u6a21\u677f\uff08\u7c7b\u522b\u3001\u989c\u8272\u3001\u5f62\u72b6\u3001\u5927\u5c0f\u3001\u6750\u8d28\u548c\u7a7a\u95f4\u5173\u7cfb\uff09\uff0c\u5e76\u5229\u7528\u4e13\u6709\u548c\u5f00\u6e90\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u52a0\u5165\u8be6\u7ec6\u7269\u4f53\u5c5e\u6027\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u611f\u77e5\u6027\u80fd\uff0c\u4f46\u4e13\u6709\u548c\u5f00\u6e90\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e4b\u95f4\u4ecd\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\u3002\u4e0d\u540c\u6a21\u578b\u5728\u7406\u89e3\u7269\u4f53\u529f\u80fd\u548c\u4e0a\u4e0b\u6587\u5173\u7cfb\u65b9\u9762\u8868\u73b0\u51fa\u4e0d\u540c\u80fd\u529b\u3002", "conclusion": "\u4e30\u5bcc\u4e14\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u5c5e\u6027\u6807\u6ce8\u5bf9\u4e8e\u5728\u52a8\u6001\u73af\u5883\u4e2d\u63a8\u8fdb\u673a\u5668\u4eba\u611f\u77e5\u81f3\u5173\u91cd\u8981\uff0cJ-ORA\u6570\u636e\u96c6\u4e3a\u8fd9\u4e00\u76ee\u6807\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2510.22488", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.22488", "abs": "https://arxiv.org/abs/2510.22488", "authors": ["Zhifeng Wang", "Yaowei Dong", "Chunyan Zeng"], "title": "TLSQKT: A Question-Aware Dual-Channel Transformer for Literacy Tracing from Learning Sequences", "comment": "8 pages, 2 figures", "summary": "Knowledge tracing (KT) supports personalized learning by modeling how\nstudents' knowledge states evolve over time. However, most KT models emphasize\nmastery of discrete knowledge components, limiting their ability to\ncharacterize broader literacy development. We reframe the task as Literacy\nTracing (LT), which models the growth of higher-order cognitive abilities and\nliteracy from learners' interaction sequences, and we instantiate this paradigm\nwith a Transformer-based model, TLSQKT (Transformer for Learning Sequences with\nQuestion-Aware Knowledge Tracing). TLSQKT employs a dual-channel design that\njointly encodes student responses and item semantics, while question-aware\ninteraction and self-attention capture long-range dependencies in learners'\nevolving states. Experiments on three real-world datasets - one public\nbenchmark, one private knowledge-component dataset, and one private literacy\ndataset - show that TLSQKT consistently outperforms strong KT baselines on\nliteracy-oriented metrics and reveals interpretable developmental trajectories\nof learners' literacy. Transfer experiments further indicate that\nknowledge-tracing signals can be leveraged for literacy tracing, offering a\npractical route when dedicated literacy labels are limited. These findings\nposition literacy tracing as a scalable component of intelligent educational\nsystems and lay the groundwork for literacy evaluation in future large-scale\neducational models.", "AI": {"tldr": "\u63d0\u51fa\u77e5\u8bc6\u8ffd\u8e2a\uff08KT\uff09\u7684\u6269\u5c55\u6846\u67b6\u2014\u2014\u7d20\u517b\u8ffd\u8e2a\uff08LT\uff09\uff0c\u901a\u8fc7Transformer\u6a21\u578bTLSQKT\u8054\u5408\u7f16\u7801\u5b66\u751f\u56de\u7b54\u548c\u9898\u76ee\u8bed\u4e49\uff0c\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u4f20\u7edfKT\u65b9\u6cd5\uff0c\u5e76\u80fd\u89e3\u91ca\u5b66\u751f\u7d20\u517b\u53d1\u5c55\u8f68\u8ff9\u3002", "motivation": "\u4f20\u7edf\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u79bb\u6563\u77e5\u8bc6\u70b9\u7684\u638c\u63e1\uff0c\u96be\u4ee5\u523b\u753b\u66f4\u5e7f\u6cdb\u7684\u7d20\u517b\u53d1\u5c55\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5efa\u6a21\u9ad8\u9636\u8ba4\u77e5\u80fd\u529b\u548c\u7d20\u517b\u589e\u957f\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faTLSQKT\u6a21\u578b\uff0c\u91c7\u7528\u53cc\u901a\u9053\u8bbe\u8ba1\u8054\u5408\u7f16\u7801\u5b66\u751f\u56de\u7b54\u548c\u9898\u76ee\u8bed\u4e49\uff0c\u4f7f\u7528\u95ee\u9898\u611f\u77e5\u4ea4\u4e92\u548c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u5b66\u4e60\u8005\u72b6\u6001\u7684\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTLSQKT\u5728\u7d20\u517b\u5bfc\u5411\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u5f3a\u57fa\u7ebfKT\u6a21\u578b\uff0c\u5e76\u80fd\u63ed\u793a\u5b66\u4e60\u8005\u7d20\u517b\u7684\u53ef\u89e3\u91ca\u53d1\u5c55\u8f68\u8ff9\u3002\u8fc1\u79fb\u5b9e\u9a8c\u663e\u793a\u77e5\u8bc6\u8ffd\u8e2a\u4fe1\u53f7\u53ef\u7528\u4e8e\u7d20\u517b\u8ffd\u8e2a\u3002", "conclusion": "\u7d20\u517b\u8ffd\u8e2a\u53ef\u4f5c\u4e3a\u667a\u80fd\u6559\u80b2\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u7ec4\u4ef6\uff0c\u4e3a\u672a\u6765\u5927\u89c4\u6a21\u6559\u80b2\u6a21\u578b\u4e2d\u7684\u7d20\u517b\u8bc4\u4f30\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.21999", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21999", "abs": "https://arxiv.org/abs/2510.21999", "authors": ["Zhenya Huang", "Jiayu Liu", "Xin Lin", "Zhiyuan Ma", "Shangzi Xue", "Tong Xiao", "Qi Liu", "Yee Whye Teh", "Enhong Chen"], "title": "Foundation of Intelligence: Review of Math Word Problems from Human Cognition Perspective", "comment": null, "summary": "Math word problem (MWP) serves as a fundamental research topic in artificial\nintelligence (AI) dating back to 1960s. This research aims to advance the\nreasoning abilities of AI by mirroring the human-like cognitive intelligence.\nThe mainstream technological paradigm has evolved from the early rule-based\nmethods, to deep learning models, and is rapidly advancing towards large\nlanguage models. However, the field still lacks a systematic taxonomy for the\nMWP survey along with a discussion of current development trends. Therefore, in\nthis paper, we aim to comprehensively review related research in MWP solving\nthrough the lens of human cognition, to demonstrate how recent AI models are\nadvancing in simulating human cognitive abilities. Specifically, we summarize 5\ncrucial cognitive abilities for MWP solving, including Problem Understanding,\nLogical Organization, Associative Memory, Critical Thinking, and Knowledge\nLearning. Focused on these abilities, we review two mainstream MWP models in\nrecent 10 years: neural network solvers, and LLM based solvers, and discuss the\ncore human-like abilities they demonstrated in their intricate problem-solving\nprocess. Moreover, we rerun all the representative MWP solvers and supplement\ntheir performance on 5 mainstream benchmarks for a unified comparison. To the\nbest of our knowledge, this survey first comprehensively analyzes the\ninfluential MWP research of the past decade from the perspective of human\nreasoning cognition and provides an integrative overall comparison across\nexisting approaches. We hope it can inspire further research in AI reasoning.\nOur repository is released on https://github.com/Ljyustc/FoI-MWP.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ece\u4eba\u7c7b\u8ba4\u77e5\u89d2\u5ea6\u7cfb\u7edf\u56de\u987e\u4e86\u6570\u5b66\u5e94\u7528\u9898\u6c42\u89e3\u7814\u7a76\uff0c\u603b\u7ed3\u4e865\u4e2a\u5173\u952e\u8ba4\u77e5\u80fd\u529b\uff0c\u6bd4\u8f83\u4e86\u795e\u7ecf\u7f51\u7edc\u6c42\u89e3\u5668\u548c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6c42\u89e3\u5668\uff0c\u5e76\u7edf\u4e00\u8bc4\u4f30\u4e86\u5b83\u4eec\u57285\u4e2a\u4e3b\u6d41\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u6570\u5b66\u5e94\u7528\u9898\u4f5c\u4e3a\u4eba\u5de5\u667a\u80fd\u57fa\u7840\u7814\u7a76\u9886\u57df\uff0c\u65e8\u5728\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u667a\u80fd\u6765\u63a8\u8fdbAI\u63a8\u7406\u80fd\u529b\u3002\u7136\u800c\u8be5\u9886\u57df\u7f3a\u4e4f\u7cfb\u7edf\u5206\u7c7b\u548c\u5f53\u524d\u53d1\u5c55\u8d8b\u52bf\u7684\u8ba8\u8bba\uff0c\u56e0\u6b64\u9700\u8981\u4ece\u4eba\u7c7b\u8ba4\u77e5\u89d2\u5ea6\u5168\u9762\u56de\u987e\u76f8\u5173\u7814\u7a76\u3002", "method": "\u4ece\u4eba\u7c7b\u8ba4\u77e5\u89c6\u89d2\u603b\u7ed35\u4e2a\u5173\u952e\u8ba4\u77e5\u80fd\u529b\uff08\u95ee\u9898\u7406\u89e3\u3001\u903b\u8f91\u7ec4\u7ec7\u3001\u8054\u60f3\u8bb0\u5fc6\u3001\u6279\u5224\u6027\u601d\u7ef4\u3001\u77e5\u8bc6\u5b66\u4e60\uff09\uff0c\u56de\u987e\u8fd110\u5e74\u4e24\u79cd\u4e3b\u6d41\u6a21\u578b\uff08\u795e\u7ecf\u7f51\u7edc\u6c42\u89e3\u5668\u3001LLM\u6c42\u89e3\u5668\uff09\uff0c\u91cd\u65b0\u8fd0\u884c\u4ee3\u8868\u6027\u6c42\u89e3\u5668\u5e76\u57285\u4e2a\u57fa\u51c6\u4e0a\u8fdb\u884c\u7edf\u4e00\u6bd4\u8f83\u3002", "result": "\u9996\u6b21\u4ece\u4eba\u7c7b\u63a8\u7406\u8ba4\u77e5\u89d2\u5ea6\u5168\u9762\u5206\u6790\u8fc7\u53bb\u5341\u5e74\u6709\u5f71\u54cd\u529b\u7684MWP\u7814\u7a76\uff0c\u63d0\u4f9b\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6574\u4f53\u6bd4\u8f83\uff0c\u5c55\u793a\u4e86AI\u6a21\u578b\u5728\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u80fd\u529b\u65b9\u9762\u7684\u8fdb\u5c55\u3002", "conclusion": "\u8fd9\u9879\u8c03\u67e5\u4e3aAI\u63a8\u7406\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u542f\u53d1\uff0c\u901a\u8fc7\u4eba\u7c7b\u8ba4\u77e5\u89c6\u89d2\u7684\u7cfb\u7edf\u5206\u6790\u6709\u52a9\u4e8e\u63a8\u52a8AI\u63a8\u7406\u80fd\u529b\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.22483", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.22483", "abs": "https://arxiv.org/abs/2510.22483", "authors": ["Qiushi Wang", "Xingpeng Li"], "title": "A Scenario-based Stochastic Model of using BESS-based Virtual Transmission Lines in Day-Ahead Unit Commitment", "comment": "This paper is to be published in the IEEE PES Asia-Pacific Power and\n  Energy Engineering Conference (APPEEC) 2025", "summary": "The rapid increase in renewable energy sources (RES) implementation in the\npower system creates more severe network congestion, which may reduce grid\noperation efficiency and cause renewable curtailment. Deterministic\noptimization for the unit commitment shows that battery energy storage system\n(BESS)-based Virtual Transmission Line (VTL), as an alternative to physical\ntransmission lines, can offer a quick solution for congestion relief, reduced\noperational costs, and lowered renewable curtailment. This paper aims to\nevaluate the benefits of VTL when considering Renewable Energy Sources\nuncertainty. Particularly, this work proposes a scenario-based stochastic\nsecurity-constrained unit commitment model considering VTL, referred to as\nSSCUC-VTL. It incorporates the forecast error of RES into the commitment\ndecision for systems with VTL. The performance of applying the VTL strategy is\ncompared to that of adding a new physical transmission line and a standalone\nBESS. A case study has been conducted on an enhanced IEEE 24-bus test system.\nThe simulation results demonstrate that VTL provides 23% more operational cost\nreduction than the physical transmission line, and up to 67% more congestion\nrelief than the standalone BESS in a power system with solar and wind\ngeneration.", "AI": {"tldr": "\u865a\u62df\u8f93\u7535\u7ebf\u8def(VTL)\u4f5c\u4e3a\u7269\u7406\u8f93\u7535\u7ebf\u8def\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u8003\u8651\u53ef\u518d\u751f\u80fd\u6e90\u4e0d\u786e\u5b9a\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u6709\u6548\u7f13\u89e3\u7535\u7f51\u62e5\u5835\u3001\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u548c\u51cf\u5c11\u53ef\u518d\u751f\u80fd\u6e90\u5f03\u7535\u3002", "motivation": "\u53ef\u518d\u751f\u80fd\u6e90\u5728\u7535\u529b\u7cfb\u7edf\u4e2d\u7684\u5feb\u901f\u90e8\u7f72\u5bfc\u81f4\u66f4\u4e25\u91cd\u7684\u7f51\u7edc\u62e5\u5835\u95ee\u9898\uff0c\u8fd9\u4f1a\u964d\u4f4e\u7535\u7f51\u8fd0\u884c\u6548\u7387\u5e76\u9020\u6210\u53ef\u518d\u751f\u80fd\u6e90\u5f03\u7535\u3002\u9700\u8981\u5bfb\u627e\u5feb\u901f\u89e3\u51b3\u65b9\u6848\u6765\u7f13\u89e3\u62e5\u5835\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u573a\u666f\u7684\u968f\u673a\u5b89\u5168\u7ea6\u675f\u673a\u7ec4\u7ec4\u5408\u6a21\u578b(SSCUC-VTL)\uff0c\u5c06\u53ef\u518d\u751f\u80fd\u6e90\u9884\u6d4b\u8bef\u5dee\u7eb3\u5165\u8003\u8651VTL\u7684\u673a\u7ec4\u51b3\u7b56\u4e2d\uff0c\u5e76\u4e0e\u65b0\u5efa\u7269\u7406\u8f93\u7535\u7ebf\u8def\u548c\u72ec\u7acb\u7535\u6c60\u50a8\u80fd\u7cfb\u7edf\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728\u589e\u5f3a\u7684IEEE 24\u8282\u70b9\u6d4b\u8bd5\u7cfb\u7edf\u4e0a\u7684\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cVTL\u6bd4\u7269\u7406\u8f93\u7535\u7ebf\u8def\u591a\u51cf\u5c1123%\u7684\u8fd0\u8425\u6210\u672c\uff0c\u6bd4\u72ec\u7acb\u7535\u6c60\u50a8\u80fd\u7cfb\u7edf\u591a\u63d0\u4f9b67%\u7684\u62e5\u5835\u7f13\u89e3\u3002", "conclusion": "\u865a\u62df\u8f93\u7535\u7ebf\u8def\u5728\u8003\u8651\u53ef\u518d\u751f\u80fd\u6e90\u4e0d\u786e\u5b9a\u6027\u7684\u7535\u529b\u7cfb\u7edf\u4e2d\uff0c\u76f8\u6bd4\u4f20\u7edf\u7269\u7406\u8f93\u7535\u7ebf\u8def\u548c\u72ec\u7acb\u50a8\u80fd\u7cfb\u7edf\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u7f13\u89e3\u62e5\u5835\u5e76\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u3002"}}
{"id": "2510.23500", "categories": ["stat.AP", "stat.ME", "62-08, 62H25"], "pdf": "https://arxiv.org/pdf/2510.23500", "abs": "https://arxiv.org/abs/2510.23500", "authors": ["Oscar Thees", "Roman M\u00fcller", "Matthias Templ"], "title": "Beyond the Trade-off Curve: Multivariate and Advanced Risk-Utility Maps for Evaluating Anonymized and Synthetic Data", "comment": "25 pages, 9 figures, 6 tables", "summary": "Anonymizing microdata requires balancing the reduction of disclosure risk\nwith the preservation of data utility. Traditional evaluations often rely on\nsingle measures or two-dimensional risk-utility (R-U) maps, but real-world\nassessments involve multiple, often correlated, indicators of both risk and\nutility. Pairwise comparisons of these measures can be inefficient and\nincomplete. We therefore systematically compare six visualization approaches\nfor simultaneous evaluation of multiple risk and utility measures: heatmaps,\ndot plots, composite scatterplots, parallel coordinate plots, radial profile\ncharts, and PCA-based biplots. We introduce blockwise PCA for composite\nscatterplots and joint PCA for biplots that simultaneously reveal method\nperformance and measure interrelationships. Through systematic identification\nof Pareto-optimal methods in all approaches, we demonstrate how multivariate\nvisualization supports a more informed selection of anonymization methods.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u516d\u79cd\u53ef\u89c6\u5316\u65b9\u6cd5\u7528\u4e8e\u540c\u65f6\u8bc4\u4f30\u533f\u540d\u5316\u6570\u636e\u7684\u591a\u91cd\u98ce\u9669\u548c\u6548\u7528\u6307\u6807\uff0c\u63d0\u51fa\u4e86\u5757\u72b6PCA\u548c\u8054\u5408PCA\u6280\u672f\u6765\u6539\u8fdb\u53ef\u89c6\u5316\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u533f\u540d\u5316\u8bc4\u4f30\u4f9d\u8d56\u5355\u4e00\u6307\u6807\u6216\u4e8c\u7ef4\u98ce\u9669-\u6548\u7528\u56fe\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u591a\u91cd\u76f8\u5173\u6307\u6807\u7684\u540c\u65f6\u8bc4\u4f30\u95ee\u9898\u3002", "method": "\u6bd4\u8f83\u516d\u79cd\u53ef\u89c6\u5316\u65b9\u6cd5\uff1a\u70ed\u56fe\u3001\u70b9\u56fe\u3001\u590d\u5408\u6563\u70b9\u56fe\u3001\u5e73\u884c\u5750\u6807\u56fe\u3001\u5f84\u5411\u8f6e\u5ed3\u56fe\u548cPCA\u53cc\u6807\u56fe\uff0c\u5e76\u5f15\u5165\u5757\u72b6PCA\u548c\u8054\u5408PCA\u6280\u672f\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u8bc6\u522b\u6240\u6709\u65b9\u6cd5\u4e2d\u7684\u5e15\u7d2f\u6258\u6700\u4f18\u65b9\u6cd5\uff0c\u8bc1\u660e\u591a\u53d8\u91cf\u53ef\u89c6\u5316\u652f\u6301\u66f4\u660e\u667a\u7684\u533f\u540d\u5316\u65b9\u6cd5\u9009\u62e9\u3002", "conclusion": "\u591a\u53d8\u91cf\u53ef\u89c6\u5316\u65b9\u6cd5\u80fd\u591f\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u533f\u540d\u5316\u65b9\u6cd5\uff0c\u5e2e\u52a9\u5728\u964d\u4f4e\u62ab\u9732\u98ce\u9669\u4e0e\u4fdd\u6301\u6570\u636e\u6548\u7528\u4e4b\u95f4\u505a\u51fa\u66f4\u597d\u7684\u5e73\u8861\u51b3\u7b56\u3002"}}
{"id": "2510.21771", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.21771", "abs": "https://arxiv.org/abs/2510.21771", "authors": ["Dharunish Yugeswardeenoo"], "title": "Improving the performance of AI-powered Affordable Robotics for Assistive Tasks", "comment": "6 pages, 5 figures. Accepted to Conference on Robot Learning (CoRL\n  2025), Seoul, Korea", "summary": "By 2050, the global demand for assistive care is expected to reach 3.5\nbillion people, far outpacing the availability of human caregivers. Existing\nrobotic solutions remain expensive and require technical expertise, limiting\naccessibility. This work introduces a low-cost robotic arm for assistive tasks\nsuch as feeding, cleaning spills, and fetching medicine. The system uses\nimitation learning from demonstration videos, requiring no task-specific\nprogramming or manual labeling. The robot consists of six servo motors, dual\ncameras, and 3D-printed grippers. Data collection via teleoperation with a\nleader arm yielded 50,000 video frames across the three tasks. A novel Phased\nAction Chunking Transformer (PACT) captures temporal dependencies and segments\nmotion dynamics, while a Temporal Ensemble (TE) method refines trajectories to\nimprove accuracy and smoothness. Evaluated across five model sizes and four\narchitectures, with ten hours of real-world testing, the system achieved over\n90% task accuracy, up to 40% higher than baselines. PACT enabled a 5x model\nsize reduction while maintaining 75% accuracy. Saliency analysis showed\nreliance on key visual cues, and phase token gradients peaked at critical\ntrajectory moments, indicating effective temporal reasoning. Future work will\nexplore bimanual manipulation and mobility for expanded assistive capabilities.", "AI": {"tldr": "\u5f00\u53d1\u4f4e\u6210\u672c\u673a\u5668\u4eba\u624b\u81c2\u7528\u4e8e\u8f85\u52a9\u62a4\u7406\u4efb\u52a1\uff0c\u91c7\u7528\u6a21\u4eff\u5b66\u4e60\u548c\u65b0\u578bPACT\u67b6\u6784\uff0c\u5728\u4e09\u4e2a\u4efb\u52a1\u4e0a\u5b9e\u73b0\u8d85\u8fc790%\u7684\u51c6\u786e\u7387\uff0c\u6a21\u578b\u5c3a\u5bf8\u51cf\u5c115\u500d\u3002", "motivation": "\u52302050\u5e74\u5168\u7403\u8f85\u52a9\u62a4\u7406\u9700\u6c42\u5c06\u8fbe\u523035\u4ebf\u4eba\uff0c\u8fdc\u8d85\u4eba\u7c7b\u62a4\u7406\u4eba\u5458\u4f9b\u5e94\u3002\u73b0\u6709\u673a\u5668\u4eba\u89e3\u51b3\u65b9\u6848\u6602\u8d35\u4e14\u9700\u8981\u4e13\u4e1a\u6280\u672f\uff0c\u9650\u5236\u4e86\u53ef\u53ca\u6027\u3002", "method": "\u4f7f\u7528\u6a21\u4eff\u5b66\u4e60\u4ece\u6f14\u793a\u89c6\u9891\u4e2d\u5b66\u4e60\uff0c\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u7f16\u7a0b\u3002\u91c7\u7528\u516d\u4f3a\u670d\u7535\u673a\u3001\u53cc\u6444\u50cf\u5934\u548c3D\u6253\u5370\u5939\u5177\u3002\u6536\u96c650,000\u5e27\u89c6\u9891\u6570\u636e\uff0c\u5f00\u53d1Phased Action Chunking Transformer (PACT)\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u5206\u5272\u8fd0\u52a8\u52a8\u6001\uff0cTemporal Ensemble\u65b9\u6cd5\u4f18\u5316\u8f68\u8ff9\u3002", "result": "\u5728\u4e94\u4e2a\u6a21\u578b\u5c3a\u5bf8\u548c\u56db\u79cd\u67b6\u6784\u8bc4\u4f30\u4e2d\uff0c\u7ecf\u8fc710\u5c0f\u65f6\u771f\u5b9e\u4e16\u754c\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u5b9e\u73b0\u8d85\u8fc790%\u4efb\u52a1\u51c6\u786e\u7387\uff0c\u6bd4\u57fa\u7ebf\u9ad840%\u3002PACT\u4f7f\u6a21\u578b\u5c3a\u5bf8\u51cf\u5c115\u500d\u540c\u65f6\u4fdd\u630175%\u51c6\u786e\u7387\u3002\u663e\u8457\u6027\u5206\u6790\u663e\u793a\u4f9d\u8d56\u5173\u952e\u89c6\u89c9\u7ebf\u7d22\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u4f4e\u6210\u672c\u8f85\u52a9\u62a4\u7406\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u672a\u6765\u5c06\u63a2\u7d22\u53cc\u624b\u64cd\u4f5c\u548c\u79fb\u52a8\u6027\u4ee5\u6269\u5c55\u8f85\u52a9\u80fd\u529b\u3002"}}
{"id": "2510.22508", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.22508", "abs": "https://arxiv.org/abs/2510.22508", "authors": ["Shondell Williams", "Karen Blackmore", "Regina Berretta", "Michelle Mansfield"], "title": "Women upskilling or reskilling to an ICT career: A systematic review of drivers and barriers", "comment": "31 pages, 3 figures, 2 tables", "summary": "Demand for technology focused STEM professionals will increase globally over\nthe coming decade, with many countries finding it difficult to meet growing\ndemand. Compounding this are difficulties in attracting and retaining female\ntechnology-focused professionals. Research seeking to address this gender\nimbalance and workforce shortage focuses on increasing participation among\nschool leavers. However, there is a paucity of research around the potential\nfor females to upskill or reskill into an ICT career. As a starting point, this\nreview asks the question: \"What potential drivers and barriers have been\nidentified that impact on female intentions or choices to reskill or upskill to\na technology focused STEM career\". Results indicate dissatisfaction in a first\ncareer, combined with positive computing experiences in the workplace can rouse\ninterest in computing professions. Learning of job opportunities, especially\nfrom salient referents, is also a key driver. Results indicate women must\novercome negative identity and academic beliefs, as well as self-doubt to make\nthe switch. In summary, it is possible to increase and diversify the tech\nworkforce by leveraging women's latent interest in computing. This review\nprovides a roadmap for research to support educational institutions, employers,\nand women to benefit from upskilling or reskilling opportunities", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u63a2\u8ba8\u4e86\u5f71\u54cd\u5973\u6027\u8f6c\u884c\u6216\u63d0\u5347\u6280\u80fd\u8fdb\u5165\u79d1\u6280STEM\u804c\u4e1a\u7684\u9a71\u52a8\u56e0\u7d20\u548c\u969c\u788d\uff0c\u53d1\u73b0\u804c\u4e1a\u4e0d\u6ee1\u610f\u5ea6\u548c\u804c\u573a\u79ef\u6781\u8ba1\u7b97\u4f53\u9a8c\u662f\u4e3b\u8981\u9a71\u52a8\u529b\uff0c\u800c\u8d1f\u9762\u8eab\u4efd\u8ba4\u540c\u548c\u81ea\u6211\u6000\u7591\u662f\u4e3b\u8981\u969c\u788d\u3002", "motivation": "\u5168\u7403\u5bf9\u79d1\u6280STEM\u4e13\u4e1a\u4eba\u624d\u9700\u6c42\u589e\u957f\uff0c\u4f46\u5973\u6027\u5728\u8be5\u9886\u57df\u53c2\u4e0e\u5ea6\u4e0d\u8db3\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5e94\u5c4a\u751f\u53c2\u4e0e\uff0c\u7f3a\u4e4f\u5bf9\u5973\u6027\u8f6c\u884c\u8fdb\u5165ICT\u804c\u4e1a\u7684\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790\u5f71\u54cd\u5973\u6027\u8f6c\u884c\u6216\u63d0\u5347\u6280\u80fd\u8fdb\u5165\u79d1\u6280\u804c\u4e1a\u7684\u9a71\u52a8\u56e0\u7d20\u548c\u969c\u788d\u3002", "result": "\u804c\u4e1a\u4e0d\u6ee1\u610f\u5ea6\u548c\u804c\u573a\u79ef\u6781\u8ba1\u7b97\u4f53\u9a8c\u662f\u4e3b\u8981\u9a71\u52a8\u529b\uff1b\u5b66\u4e60\u5de5\u4f5c\u673a\u4f1a\uff08\u7279\u522b\u662f\u6765\u81ea\u91cd\u8981\u53c2\u8003\u8005\uff09\u4e5f\u5f88\u5173\u952e\uff1b\u5973\u6027\u9700\u8981\u514b\u670d\u8d1f\u9762\u8eab\u4efd\u8ba4\u540c\u3001\u5b66\u672f\u4fe1\u5ff5\u548c\u81ea\u6211\u6000\u7591\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u5973\u6027\u5bf9\u8ba1\u7b97\u7684\u6f5c\u5728\u5174\u8da3\uff0c\u53ef\u4ee5\u589e\u52a0\u548c\u591a\u6837\u5316\u79d1\u6280\u52b3\u52a8\u529b\uff1b\u4e3a\u6559\u80b2\u673a\u6784\u3001\u96c7\u4e3b\u548c\u5973\u6027\u63d0\u4f9b\u652f\u6301\u8f6c\u884c\u6216\u6280\u80fd\u63d0\u5347\u7684\u7814\u7a76\u8def\u7ebf\u56fe\u3002"}}
{"id": "2510.22009", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22009", "abs": "https://arxiv.org/abs/2510.22009", "authors": ["Yangqin Jiang", "Chao Huang"], "title": "LightAgent: Mobile Agentic Foundation Models", "comment": null, "summary": "With the advancement of multimodal large language models (MLLMs), building\nGUI agent systems has become an increasingly promising direction-especially for\nmobile platforms, given their rich app ecosystems and intuitive touch\ninteractions. Yet mobile GUI agents face a critical dilemma: truly on-device\nmodels (4B or smaller) lack sufficient performance, while capable models\n(starting from 7B) are either too large for mobile deployment or prohibitively\ncostly (e.g., cloud-only closed-source MLLMs). To resolve this, we propose\nLightAgent, a mobile agentic foundation model solution that leverages\ndevice-cloud collaboration to tap the cost-efficiency of on-device models and\nthe high capability of cloud models, while avoiding their drawbacks.\nSpecifically, LightAgent enhances Qwen2.5-VL-3B via two-stage SFT->GRPO\ntraining on synthetic GUI data for strong decision-making, integrates an\nefficient long-reasoning mechanism to utilize historical interactions under\ntight resources, and defaults to on-device execution-only escalating\nchallenging subtasks to the cloud via real-time complexity assessment.\nExperiments on the online AndroidLab benchmark and diverse apps show LightAgent\nmatches or nears larger models, with a significant reduction in cloud costs.", "AI": {"tldr": "LightAgent\u662f\u4e00\u4e2a\u79fb\u52a8GUI\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bbe\u5907-\u4e91\u534f\u4f5c\u89e3\u51b3\u79fb\u52a8\u8bbe\u5907\u4e0a\u5c0f\u6a21\u578b\u6027\u80fd\u4e0d\u8db3\u800c\u5927\u6a21\u578b\u90e8\u7f72\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e91\u6210\u672c\u3002", "motivation": "\u79fb\u52a8GUI\u4ee3\u7406\u9762\u4e34\u5173\u952e\u56f0\u5883\uff1a\u771f\u6b63\u5728\u8bbe\u5907\u4e0a\u7684\u5c0f\u6a21\u578b\uff084B\u6216\u66f4\u5c0f\uff09\u6027\u80fd\u4e0d\u8db3\uff0c\u800c\u80fd\u529b\u5f3a\u7684\u6a21\u578b\uff08\u4ece7B\u5f00\u59cb\uff09\u8981\u4e48\u592a\u5927\u65e0\u6cd5\u5728\u79fb\u52a8\u8bbe\u5907\u90e8\u7f72\uff0c\u8981\u4e48\u6210\u672c\u8fc7\u9ad8\uff08\u5982\u4ec5\u9650\u4e91\u7684\u95ed\u6e90MLLMs\uff09\u3002", "method": "\u901a\u8fc7\u4e24\u9636\u6bb5SFT->GRPO\u8bad\u7ec3\u589e\u5f3aQwen2.5-VL-3B\u6a21\u578b\uff0c\u96c6\u6210\u9ad8\u6548\u957f\u63a8\u7406\u673a\u5236\u5229\u7528\u5386\u53f2\u4ea4\u4e92\uff0c\u9ed8\u8ba4\u5728\u8bbe\u5907\u4e0a\u6267\u884c\uff0c\u4ec5\u901a\u8fc7\u5b9e\u65f6\u590d\u6742\u5ea6\u8bc4\u4f30\u5c06\u5177\u6709\u6311\u6218\u6027\u7684\u5b50\u4efb\u52a1\u5347\u7ea7\u5230\u4e91\u7aef\u3002", "result": "\u5728AndroidLab\u57fa\u51c6\u6d4b\u8bd5\u548c\u591a\u6837\u5316\u5e94\u7528\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLightAgent\u5339\u914d\u6216\u63a5\u8fd1\u66f4\u5927\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u4e91\u6210\u672c\u3002", "conclusion": "LightAgent\u901a\u8fc7\u8bbe\u5907-\u4e91\u534f\u4f5c\u6210\u529f\u89e3\u51b3\u4e86\u79fb\u52a8GUI\u4ee3\u7406\u7684\u90e8\u7f72\u56f0\u5883\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2510.22496", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.22496", "abs": "https://arxiv.org/abs/2510.22496", "authors": ["Haoran Wang", "Shengyuan Niu", "Henry Moon", "Ian Willebeek-LeMair", "Andrew J. Kurdila", "Andrea L'Afflitto", "Daniel Stilwell"], "title": "Functional Uncertainty Classes, Nonparametric Adaptive Contro Functional Uncertainty Classes for Nonparametric Adaptive Control: the Curse of Dimensionality", "comment": null, "summary": "This paper derives a new class of vector-valued reproducing kernel Hilbert\nspaces (vRKHS) defined in terms of operator-valued kernels for the\nrepresentation of functional uncertainty arising in nonparametric adaptive\ncontrol methods. These are referred to as maneuver or trajectory vRKHS KM in\nthe paper, and they are introduced to address the curse of dimensionality that\ncan arise for some types of nonparametric adaptive control strategies. The\nmaneuver vRKHSs are derived based on the structure of a compact, l-dimensional,\nsmooth Riemannian manifold M that is regularly embedded in the state space X =\nRn, where M is assumed to approximately support the ultimate dynamics of the\nreference system to be tracked.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5411\u91cf\u503c\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4(vRKHS)\uff0c\u7528\u4e8e\u8868\u793a\u975e\u53c2\u6570\u81ea\u9002\u5e94\u63a7\u5236\u4e2d\u7684\u51fd\u6570\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u89e3\u51b3\u7ef4\u5ea6\u707e\u96be\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u67d0\u4e9b\u975e\u53c2\u6570\u81ea\u9002\u5e94\u63a7\u5236\u7b56\u7565\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u7ef4\u5ea6\u707e\u96be\u95ee\u9898\uff0c\u9700\u8981\u6784\u5efa\u80fd\u591f\u6709\u6548\u8868\u793a\u51fd\u6570\u4e0d\u786e\u5b9a\u6027\u7684\u6570\u5b66\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u7d27\u81f4\u3001l\u7ef4\u3001\u5149\u6ed1\u9ece\u66fc\u6d41\u5f62M\u7684\u7ed3\u6784\uff0c\u63a8\u5bfc\u51fa\u7b97\u5b50\u503c\u6838\u5b9a\u4e49\u7684\u8f68\u8ff9vRKHS KM\uff0c\u5176\u4e2dM\u88ab\u5047\u8bbe\u4e3a\u8fd1\u4f3c\u652f\u6491\u53c2\u8003\u7cfb\u7edf\u7684\u6700\u7ec8\u52a8\u529b\u5b66\u3002", "result": "\u6210\u529f\u63a8\u5bfc\u51fa\u4e00\u7c7b\u65b0\u7684\u5411\u91cf\u503c\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff0c\u79f0\u4e3a\u673a\u52a8\u6216\u8f68\u8ff9vRKHS KM\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5904\u7406\u975e\u53c2\u6570\u81ea\u9002\u5e94\u63a7\u5236\u4e2d\u7684\u51fd\u6570\u4e0d\u786e\u5b9a\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6570\u5b66\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u7f13\u89e3\u7ef4\u5ea6\u707e\u96be\u95ee\u9898\u3002"}}
{"id": "2508.06594", "categories": ["econ.GN", "q-fin.EC", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2508.06594", "abs": "https://arxiv.org/abs/2508.06594", "authors": ["Tatsuru Kikuchi"], "title": "Stochastic Boundaries in Spatial General Equilibrium: A Diffusion-Based Approach to Causal Inference with Spillover Effects", "comment": "62 pages", "summary": "This paper introduces a novel framework for causal inference in spatial\neconomics that explicitly models the stochastic transition from partial to\ngeneral equilibrium effects. We develop a Denoising Diffusion Probabilistic\nModel (DDPM) integrated with boundary detection methods from stochastic process\ntheory to identify when and how treatment effects propagate beyond local\nmarkets. Our approach treats the evolution of spatial spillovers as a L\\'evy\nprocess with jump-diffusion dynamics, where the first passage time to critical\nthresholds indicates regime shifts from partial to general equilibrium. Using\nCUSUM-based sequential detection, we identify the spatial and temporal\nboundaries at which local interventions become systemic. Applied to AI adoption\nacross Japanese prefectures, we find that treatment effects exhibit L\\'evy\njumps at approximately 35km spatial scales, with general equilibrium effects\namplifying partial equilibrium estimates by 42\\%. Monte Carlo simulations show\nthat ignoring these stochastic boundaries leads to underestimation of treatment\neffects by 28-67\\%, with particular severity in densely connected economic\nregions. Our framework provides the first rigorous method for determining when\nspatial spillovers necessitate general equilibrium analysis, offering crucial\nguidance for policy evaluation in interconnected economies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u7a7a\u95f4\u7ecf\u6d4e\u5b66\u56e0\u679c\u63a8\u65ad\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7DDPM\u6a21\u578b\u7ed3\u5408\u8fb9\u754c\u68c0\u6d4b\u65b9\u6cd5\uff0c\u8bc6\u522b\u5904\u7406\u6548\u5e94\u4ece\u5c40\u90e8\u5411\u4e00\u822c\u5747\u8861\u7684\u968f\u673a\u8f6c\u6362\u8fc7\u7a0b\u3002", "motivation": "\u4f20\u7edf\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u8bc6\u522b\u7a7a\u95f4\u6ea2\u51fa\u6548\u5e94\u4f55\u65f6\u4ece\u5c40\u90e8\u5e02\u573a\u4f20\u64ad\u5230\u7cfb\u7edf\u5c42\u9762\uff0c\u9700\u8981\u5efa\u7acb\u80fd\u591f\u6355\u6349\u8fd9\u79cd\u968f\u673a\u8f6c\u6362\u8fb9\u754c\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b(DDPM)\u7ed3\u5408L\u00e9vy\u8fc7\u7a0b\u7684\u8df3-\u6269\u6563\u52a8\u529b\u5b66\uff0c\u901a\u8fc7CUSUM\u5e8f\u5217\u68c0\u6d4b\u8bc6\u522b\u7a7a\u95f4\u548c\u65f6\u95f4\u8fb9\u754c\uff0c\u5c06\u7a7a\u95f4\u6ea2\u51fa\u6f14\u5316\u5efa\u6a21\u4e3a\u5177\u6709\u4e34\u754c\u9608\u503c\u7684\u7b2c\u4e00\u901a\u8fc7\u65f6\u95f4\u8fc7\u7a0b\u3002", "result": "\u5728\u65e5\u672c\u53bf\u7ea7AI\u5e94\u7528\u7814\u7a76\u4e2d\u53d1\u73b0\u5904\u7406\u6548\u5e94\u5728\u7ea635km\u7a7a\u95f4\u5c3a\u5ea6\u51fa\u73b0L\u00e9vy\u8df3\u8dc3\uff0c\u4e00\u822c\u5747\u8861\u6548\u5e94\u5c06\u90e8\u5206\u5747\u8861\u4f30\u8ba1\u653e\u592742%\u3002\u8499\u7279\u5361\u6d1b\u6a21\u62df\u663e\u793a\u5ffd\u7565\u8fd9\u4e9b\u8fb9\u754c\u4f1a\u5bfc\u81f4\u5904\u7406\u6548\u5e94\u4f4e\u4f3028-67%\u3002", "conclusion": "\u8be5\u6846\u67b6\u9996\u6b21\u63d0\u4f9b\u4e86\u786e\u5b9a\u7a7a\u95f4\u6ea2\u51fa\u4f55\u65f6\u9700\u8981\u4e00\u822c\u5747\u8861\u5206\u6790\u7684\u4e25\u683c\u65b9\u6cd5\uff0c\u4e3a\u4e92\u8054\u7ecf\u6d4e\u4e2d\u7684\u653f\u7b56\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5173\u952e\u6307\u5bfc\u3002"}}
{"id": "2510.21773", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.21773", "abs": "https://arxiv.org/abs/2510.21773", "authors": ["Van Nam Dinh"], "title": "Real-Time QP Solvers: A Concise Review and Practical Guide Towards Legged Robots", "comment": "6 pages, 1 figure, 2 tables", "summary": "Quadratic programming (QP) underpins real-time robotics by enabling\nefficient, constrained optimization in state estimation, motion planning, and\ncontrol. In legged locomotion and manipulation, essential modules like inverse\ndynamics, Model Predictive Control (MPC), and Whole-Body Control (WBC) are\ninherently QP-based, demanding reliable solutions amid tight timing, energy,\nand computational limits on embedded platforms. This paper presents a\ncomprehensive analysis and benchmarking study of cutting-edge QP solvers for\nlegged robotics. We begin by formulating the standard convex QP and classify\nsolvers into four principal algorithmic approaches, including interior-point\nmethods, active-set strategies, operator splitting schemes, and augmented\nLagrangian approaches. Each solver is examined in terms of algorithmic\nstructure, computational characteristics, and its ability to exploit problem\nstructure and warm-starting. Performance is evaluated using publicly available\nbenchmarks, focusing on metrics such as computation time, constraint\nsatisfaction, and robustness under perturbations. Feature tables and\ncomparisons yield practical guidance for solver selection, underscoring\ntrade-offs in speed, accuracy, and energy efficiency. Our findings emphasize\nthe synergy between solver, task, and hardware, sparse IPMs for long-horizon\nMPC, and dense active-set for high frequency WBC to advance agile, autonomous\nlegged systems, with emerging extensions to nonconvex and distributed QP.", "AI": {"tldr": "\u672c\u6587\u5bf9\u8db3\u5f0f\u673a\u5668\u4eba\u4e2d\u7684\u4e8c\u6b21\u89c4\u5212\u6c42\u89e3\u5668\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5206\u6790\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e86\u56db\u79cd\u4e3b\u8981\u7b97\u6cd5\u65b9\u6cd5\uff0c\u4e3a\u4e0d\u540c\u5e94\u7528\u573a\u666f\u63d0\u4f9b\u6c42\u89e3\u5668\u9009\u62e9\u6307\u5bfc\u3002", "motivation": "\u4e8c\u6b21\u89c4\u5212\u5728\u8db3\u5f0f\u673a\u5668\u4eba\u7684\u72b6\u6001\u4f30\u8ba1\u3001\u8fd0\u52a8\u89c4\u5212\u548c\u63a7\u5236\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5728\u5d4c\u5165\u5f0f\u5e73\u53f0\u4e0a\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u9760\u7684\u6c42\u89e3\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u7684\u6c42\u89e3\u5668\u6027\u80fd\u6bd4\u8f83\u7814\u7a76\u3002", "method": "\u5c06\u6c42\u89e3\u5668\u5206\u4e3a\u5185\u70b9\u6cd5\u3001\u4e3b\u52a8\u96c6\u7b56\u7565\u3001\u7b97\u5b50\u5206\u88c2\u65b9\u6848\u548c\u589e\u5e7f\u62c9\u683c\u6717\u65e5\u65b9\u6cd5\u56db\u7c7b\uff0c\u5206\u6790\u7b97\u6cd5\u7ed3\u6784\u3001\u8ba1\u7b97\u7279\u6027\uff0c\u5e76\u5229\u7528\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u8ba1\u7b97\u65f6\u95f4\u3001\u7ea6\u675f\u6ee1\u8db3\u548c\u9c81\u68d2\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u6c42\u89e3\u5668\u5728\u901f\u5ea6\u3001\u7cbe\u5ea6\u548c\u80fd\u6548\u65b9\u9762\u5b58\u5728\u6743\u8861\uff0c\u7a00\u758f\u5185\u70b9\u6cd5\u9002\u5408\u957f\u65f6\u57dfMPC\uff0c\u5bc6\u96c6\u4e3b\u52a8\u96c6\u65b9\u6cd5\u9002\u5408\u9ad8\u9891WBC\u3002", "conclusion": "\u6c42\u89e3\u5668\u9009\u62e9\u5e94\u4e0e\u4efb\u52a1\u548c\u786c\u4ef6\u534f\u540c\u8003\u8651\uff0c\u7a00\u758f\u5185\u70b9\u6cd5\u9002\u5408\u957f\u65f6\u57dfMPC\uff0c\u5bc6\u96c6\u4e3b\u52a8\u96c6\u65b9\u6cd5\u9002\u5408\u9ad8\u9891WBC\uff0c\u672a\u6765\u53ef\u6269\u5c55\u5230\u975e\u51f8\u548c\u5206\u5e03\u5f0fQP\u95ee\u9898\u3002"}}
{"id": "2510.22034", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.22034", "abs": "https://arxiv.org/abs/2510.22034", "authors": ["Rick Chen", "Joseph Ternasky", "Aaron Ontoyin Yin", "Xianling Mu", "Fuat Alican", "Yigit Ihlamur"], "title": "LLM-AR: LLM-powered Automated Reasoning Framework", "comment": null, "summary": "Large language models (LLMs) can already identify patterns and reason\neffectively, yet their variable accuracy hampers adoption in high-stakes\ndecision-making applications. In this paper, we study this issue from a venture\ncapital perspective by predicting idea-stage startup success based on founder\ntraits. (i) To build a reliable prediction model, we introduce LLM-AR, a\npipeline inspired by neural-symbolic systems that distils LLM-generated\nheuristics into probabilistic rules executed by the ProbLog automated-reasoning\nengine. (ii) An iterative policy-evolution loop incorporates association-rule\nmining to progressively refine the prediction rules.\n  On unseen folds, LLM-AR achieves 59.5% precision and 8.7% recall, 5.9x the\nrandom baseline precision, while exposing every decision path for human\ninspection. The framework is interpretable and tunable via hyperparameters,\nshowing promise to extend into other domains.", "AI": {"tldr": "LLM-AR\u662f\u4e00\u4e2a\u4ece\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u63d0\u53d6\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u901a\u8fc7ProbLog\u81ea\u52a8\u63a8\u7406\u5f15\u64ce\u6267\u884c\u7684\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u7ba1\u9053\uff0c\u7528\u4e8e\u57fa\u4e8e\u521b\u59cb\u4eba\u7279\u5f81\u9884\u6d4b\u521d\u521b\u4f01\u4e1a\u6210\u529f\uff0c\u5b9e\u73b0\u4e8659.5%\u7684\u7cbe\u786e\u5ea6\u548c8.7%\u7684\u53ec\u56de\u7387\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5177\u5907\u6a21\u5f0f\u8bc6\u522b\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5176\u51c6\u786e\u6027\u4e0d\u7a33\u5b9a\uff0c\u9650\u5236\u4e86\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u5e94\u7528\u4e2d\u7684\u91c7\u7528\u3002\u672c\u6587\u4ece\u98ce\u9669\u6295\u8d44\u89d2\u5ea6\u7814\u7a76\u5982\u4f55\u57fa\u4e8e\u521b\u59cb\u4eba\u7279\u5f81\u9884\u6d4b\u521d\u521b\u4f01\u4e1a\u6210\u529f\u3002", "method": "\u63d0\u51faLLM-AR\u7ba1\u9053\uff0c\u53d7\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u542f\u53d1\uff0c\u5c06LLM\u751f\u6210\u7684\u542f\u53d1\u5f0f\u89c4\u5219\u63d0\u70bc\u4e3a\u6982\u7387\u89c4\u5219\uff0c\u7531ProbLog\u81ea\u52a8\u63a8\u7406\u5f15\u64ce\u6267\u884c\u3002\u91c7\u7528\u8fed\u4ee3\u7b56\u7565\u8fdb\u5316\u5faa\u73af\uff0c\u7ed3\u5408\u5173\u8054\u89c4\u5219\u6316\u6398\u9010\u6b65\u4f18\u5316\u9884\u6d4b\u89c4\u5219\u3002", "result": "\u5728\u672a\u89c1\u6570\u636e\u4e0a\uff0cLLM-AR\u8fbe\u523059.5%\u7684\u7cbe\u786e\u5ea6\u548c8.7%\u7684\u53ec\u56de\u7387\uff0c\u662f\u968f\u673a\u57fa\u7ebf\u7cbe\u786e\u5ea6\u76845.9\u500d\uff0c\u540c\u65f6\u6240\u6709\u51b3\u7b56\u8def\u5f84\u90fd\u53ef\u4f9b\u4eba\u5de5\u68c0\u67e5\u3002", "conclusion": "\u8be5\u6846\u67b6\u5177\u6709\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u901a\u8fc7\u8d85\u53c2\u6570\u8c03\u8282\u7684\u7279\u6027\uff0c\u663e\u793a\u51fa\u6269\u5c55\u5230\u5176\u4ed6\u9886\u57df\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.22514", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.22514", "abs": "https://arxiv.org/abs/2510.22514", "authors": ["Armel Koulong", "Ali Pakniyat"], "title": "Robust Multi-Agent Safety via Tube-Based Tightened Exponential Barrier Functions", "comment": "This work has been submitted to IFAC for possible publication", "summary": "This paper presents a constructive framework for synthesizing provably safe\ncontrollers for nonlinear multi-agent systems subject to bounded disturbances.\nThe methodology applies to systems representable in Brunovsky canonical form,\naccommodating arbitrary-order dynamics in multi-dimensional spaces. The central\ncontribution is a method of constraint tightening that formally couples robust\nerror feedback with nominal trajectory planning. The key insight is that the\ndesign of an ancillary feedback law, which confines state errors to a robust\npositively invariant (RPI) tube, simultaneously provides the exact information\nneeded to ensure the safety of the nominal plan. Specifically, the geometry of\nthe resulting RPI tube is leveraged via its support function to derive\nstate-dependent safety margins. These margins are then used to systematically\ntighten the high relative-degree exponential control barrier function (eCBF)\nconstraints imposed on the nominal planner. This integrated synthesis\nguarantees that any nominal trajectory satisfying the tightened constraints\ncorresponds to a provably safe trajectory for the true, disturbed system. We\ndemonstrate the practical utility of this formal synthesis method by\nimplementing the planner within a distributed Model Predictive Control (MPC)\nscheme, which optimizes performance while inheriting the robust safety\nguarantees.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e3a\u53d7\u6709\u754c\u5e72\u6270\u7684\u975e\u7ebf\u6027\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5408\u6210\u53ef\u8bc1\u660e\u5b89\u5168\u63a7\u5236\u5668\u7684\u6784\u9020\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u7ea6\u675f\u7d27\u7f29\u65b9\u6cd5\u5c06\u9c81\u68d2\u8bef\u5dee\u53cd\u9988\u4e0e\u540d\u4e49\u8f68\u8ff9\u89c4\u5212\u6b63\u5f0f\u8026\u5408\u3002", "motivation": "\u9488\u5bf9\u53d7\u6709\u754c\u5e72\u6270\u7684\u975e\u7ebf\u6027\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u63d0\u4f9b\u53ef\u8bc1\u660e\u5b89\u5168\u4fdd\u8bc1\u7684\u63a7\u5236\u5408\u6210\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u5904\u7406\u4efb\u610f\u9636\u52a8\u529b\u5b66\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u7ea6\u675f\u7d27\u7f29\u65b9\u6cd5\uff0c\u5229\u7528\u9c81\u68d2\u6b63\u4e0d\u53d8(RPI)\u7ba1\u7684\u51e0\u4f55\u7279\u6027\u901a\u8fc7\u652f\u6491\u51fd\u6570\u5bfc\u51fa\u72b6\u6001\u76f8\u5173\u5b89\u5168\u88d5\u5ea6\uff0c\u7cfb\u7edf\u6027\u5730\u7d27\u7f29\u65bd\u52a0\u5728\u540d\u4e49\u89c4\u5212\u5668\u4e0a\u7684\u9ad8\u76f8\u5bf9\u9636\u6307\u6570\u63a7\u5236\u5c4f\u969c\u51fd\u6570(eCBF)\u7ea6\u675f\u3002", "result": "\u5f00\u53d1\u4e86\u96c6\u6210\u5408\u6210\u65b9\u6cd5\uff0c\u4fdd\u8bc1\u4efb\u4f55\u6ee1\u8db3\u7d27\u7f29\u7ea6\u675f\u7684\u540d\u4e49\u8f68\u8ff9\u5bf9\u5e94\u4e8e\u771f\u5b9e\u53d7\u5e72\u6270\u7cfb\u7edf\u7684\u53ef\u8bc1\u660e\u5b89\u5168\u8f68\u8ff9\uff0c\u5e76\u5728\u5206\u5e03\u5f0f\u6a21\u578b\u9884\u6d4b\u63a7\u5236(MPC)\u65b9\u6848\u4e2d\u5b9e\u73b0\u4e86\u8be5\u89c4\u5212\u5668\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u975e\u7ebf\u6027\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u7684\u5b89\u5168\u63a7\u5236\u5668\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u9c81\u68d2\u8bef\u5dee\u53cd\u9988\u4e0e\u540d\u4e49\u8f68\u8ff9\u89c4\u5212\u76f8\u7ed3\u5408\uff0c\u5728\u4f18\u5316\u6027\u80fd\u7684\u540c\u65f6\u7ee7\u627f\u9c81\u68d2\u5b89\u5168\u4fdd\u8bc1\u3002"}}
{"id": "2510.00754", "categories": ["econ.EM", "econ.GN", "q-fin.EC", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.00754", "abs": "https://arxiv.org/abs/2510.00754", "authors": ["Tatsuru Kikuchi"], "title": "A Unified Framework for Spatial and Temporal Treatment Effect Boundaries: Theory and Identification", "comment": "73 pages, 2 figures", "summary": "This paper develops a unified theoretical framework for detecting and\nestimating boundaries in treatment effects across both spatial and temporal\ndimensions. We formalize the concept of treatment effect boundaries as\nstructural parameters characterizing regime transitions where causal effects\ncease to operate. Building on reaction-diffusion models of information\npropagation, we establish conditions under which spatial and temporal\nboundaries share common dynamics governed by diffusion parameters (delta,\nlambda), yielding the testable prediction d^*/tau^* = 3.32 lambda sqrt{delta}\nfor standard detection thresholds. We derive formal identification results\nunder staggered treatment adoption and develop a three-stage estimation\nprocedure implementable with standard panel data. Monte Carlo simulations\ndemonstrate excellent finite-sample performance, with boundary estimates\nachieving RMSE below 10% in realistic configurations. We apply the framework to\ntwo empirical settings: EU broadband diffusion (2006-2021) and US wildfire\neconomic impacts (2017-2022). The broadband application reveals a scope\nlimitation -- our framework assumes depreciation dynamics and fails when\neffects exhibit increasing returns through network externalities. The wildfire\napplication provides strong validation: estimated boundaries satisfy d^* = 198\nkm and tau^* = 2.7 years, with the empirical ratio (72.5) exactly matching the\ntheoretical prediction 3.32 lambda sqrt{delta} = 72.5. The framework provides\npractical tools for detecting when localized treatments become systemic and\nidentifying critical thresholds for policy intervention.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u4f30\u8ba1\u5904\u7406\u6548\u5e94\u5728\u7a7a\u95f4\u548c\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u8fb9\u754c\u3002\u8be5\u6846\u67b6\u5c06\u5904\u7406\u6548\u5e94\u8fb9\u754c\u5f62\u5f0f\u5316\u4e3a\u7ed3\u6784\u53c2\u6570\uff0c\u8868\u5f81\u56e0\u679c\u6548\u5e94\u505c\u6b62\u8fd0\u4f5c\u7684\u5236\u5ea6\u8f6c\u6362\u3002", "motivation": "\u5efa\u7acb\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u68c0\u6d4b\u548c\u4f30\u8ba1\u5904\u7406\u6548\u5e94\u5728\u7a7a\u95f4\u548c\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u8fb9\u754c\uff0c\u4e3a\u653f\u7b56\u5e72\u9884\u63d0\u4f9b\u5173\u952e\u9608\u503c\u8bc6\u522b\u5de5\u5177\u3002", "method": "\u57fa\u4e8e\u4fe1\u606f\u4f20\u64ad\u7684\u53cd\u5e94-\u6269\u6563\u6a21\u578b\uff0c\u5efa\u7acb\u4e86\u7a7a\u95f4\u548c\u65f6\u95f4\u8fb9\u754c\u5171\u4eab\u7531\u6269\u6563\u53c2\u6570(\u03b4, \u03bb)\u63a7\u5236\u7684\u5171\u540c\u52a8\u6001\u6761\u4ef6\uff0c\u5f00\u53d1\u4e86\u5728\u4ea4\u9519\u5904\u7406\u91c7\u7528\u4e0b\u7684\u6b63\u5f0f\u8bc6\u522b\u7ed3\u679c\u548c\u53ef\u5b9e\u65bd\u7684\u4e09\u9636\u6bb5\u4f30\u8ba1\u7a0b\u5e8f\u3002", "result": "\u8499\u7279\u5361\u6d1b\u6a21\u62df\u663e\u793a\u4f18\u79c0\u7684\u6709\u9650\u6837\u672c\u6027\u80fd\uff0c\u8fb9\u754c\u4f30\u8ba1\u7684RMSE\u5728\u73b0\u5b9e\u914d\u7f6e\u4e2d\u4f4e\u4e8e10%\u3002\u5728\u6b27\u76df\u5bbd\u5e26\u6269\u6563(2006-2021)\u548c\u7f8e\u56fd\u91ce\u706b\u7ecf\u6d4e\u5f71\u54cd(2017-2022)\u4e24\u4e2a\u5b9e\u8bc1\u5e94\u7528\u4e2d\uff0c\u91ce\u706b\u5e94\u7528\u63d0\u4f9b\u4e86\u5f3a\u9a8c\u8bc1\uff1a\u4f30\u8ba1\u8fb9\u754c\u6ee1\u8db3d* = 198 km\u548c\u03c4* = 2.7\u5e74\uff0c\u7ecf\u9a8c\u6bd4\u7387(72.5)\u4e0e\u7406\u8bba\u9884\u6d4b\u5b8c\u5168\u5339\u914d\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u68c0\u6d4b\u5c40\u90e8\u5904\u7406\u4f55\u65f6\u53d8\u4e3a\u7cfb\u7edf\u6027\u4ee5\u53ca\u8bc6\u522b\u653f\u7b56\u5e72\u9884\u7684\u5173\u952e\u9608\u503c\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u4f46\u5728\u5b58\u5728\u7f51\u7edc\u5916\u90e8\u6027\u5bfc\u81f4\u7684\u89c4\u6a21\u6536\u76ca\u9012\u589e\u6548\u5e94\u65f6\u5b58\u5728\u5c40\u9650\u6027\u3002"}}
{"id": "2510.21817", "categories": ["cs.RO", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21817", "abs": "https://arxiv.org/abs/2510.21817", "authors": ["Xiaoyu Liu", "Chaoyou Fu", "Chi Yan", "Chu Wu", "Haihan Gao", "Yi-Fan Zhang", "Shaoqi Dong", "Cheng Qian", "Bin Luo", "Xiuyong Yang", "Guanwu Li", "Yusheng Cai", "Yunhang Shen", "Deqiang Jiang", "Haoyu Cao", "Xing Sun", "Caifeng Shan", "Ran He"], "title": "VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting", "comment": "Homepage: https://lxysl.github.io/VITA-E/", "summary": "Current Vision-Language-Action (VLA) models are often constrained by a rigid,\nstatic interaction paradigm, which lacks the ability to see, hear, speak, and\nact concurrently as well as handle real-time user interruptions dynamically.\nThis hinders seamless embodied collaboration, resulting in an inflexible and\nunresponsive user experience. To address these limitations, we introduce\nVITA-E, a novel embodied interaction framework designed for both behavioral\nconcurrency and nearly real-time interruption. The core of our approach is a\ndual-model architecture where two parallel VLA instances operate as an ``Active\nModel'' and a ``Standby Model'', allowing the embodied agent to observe its\nenvironment, listen to user speech, provide verbal responses, and execute\nactions, all concurrently and interruptibly, mimicking human-like multitasking\ncapabilities. We further propose a ``model-as-controller'' paradigm, where we\nfine-tune the VLM to generate special tokens that serve as direct system-level\ncommands, coupling the model's reasoning with the system's behavior.\nExperiments conducted on a physical humanoid platform demonstrate that VITA-E\ncan reliably handle complex interactive scenarios. Our framework is compatible\nwith various dual-system VLA models, achieving an extremely high success rate\non emergency stops and speech interruptions while also successfully performing\nconcurrent speech and action. This represents a significant step towards more\nnatural and capable embodied assistants.", "AI": {"tldr": "VITA-E\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u5177\u8eab\u4ea4\u4e92\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u6a21\u578b\u67b6\u6784\u5b9e\u73b0\u884c\u4e3a\u5e76\u53d1\u548c\u5b9e\u65f6\u4e2d\u65ad\u5904\u7406\uff0c\u4f7f\u5177\u8eab\u4ee3\u7406\u80fd\u591f\u540c\u65f6\u89c2\u5bdf\u73af\u5883\u3001\u542c\u53d6\u8bed\u97f3\u3001\u63d0\u4f9b\u56de\u5e94\u5e76\u6267\u884c\u52a8\u4f5c\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u53d7\u9650\u4e8e\u50f5\u786c\u7684\u9759\u6001\u4ea4\u4e92\u8303\u5f0f\uff0c\u65e0\u6cd5\u540c\u65f6\u8fdb\u884c\u770b\u3001\u542c\u3001\u8bf4\u3001\u505a\u7b49\u884c\u4e3a\uff0c\u4e5f\u4e0d\u80fd\u5904\u7406\u5b9e\u65f6\u7528\u6237\u4e2d\u65ad\uff0c\u8fd9\u963b\u788d\u4e86\u65e0\u7f1d\u7684\u5177\u8eab\u534f\u4f5c\u3002", "method": "\u91c7\u7528\u53cc\u6a21\u578b\u67b6\u6784\uff0c\u4e24\u4e2a\u5e76\u884c\u7684VLA\u5b9e\u4f8b\u5206\u522b\u4f5c\u4e3a\"\u4e3b\u52a8\u6a21\u578b\"\u548c\"\u5f85\u673a\u6a21\u578b\"\uff0c\u5e76\u63d0\u51fa\"\u6a21\u578b\u5373\u63a7\u5236\u5668\"\u8303\u5f0f\uff0c\u901a\u8fc7\u5fae\u8c03VLM\u751f\u6210\u7279\u6b8a\u4ee4\u724c\u4f5c\u4e3a\u7cfb\u7edf\u7ea7\u547d\u4ee4\u3002", "result": "\u5728\u7269\u7406\u4eba\u5f62\u5e73\u53f0\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVITA-E\u80fd\u53ef\u9760\u5904\u7406\u590d\u6742\u4ea4\u4e92\u573a\u666f\uff0c\u5728\u7d27\u6025\u505c\u6b62\u548c\u8bed\u97f3\u4e2d\u65ad\u65b9\u9762\u8fbe\u5230\u6781\u9ad8\u6210\u529f\u7387\uff0c\u5e76\u80fd\u6210\u529f\u6267\u884c\u5e76\u53d1\u8bed\u97f3\u548c\u52a8\u4f5c\u3002", "conclusion": "\u8be5\u6846\u67b6\u4ee3\u8868\u4e86\u5411\u66f4\u81ea\u7136\u3001\u66f4\u5f3a\u5927\u5177\u8eab\u52a9\u624b\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u517c\u5bb9\u5404\u79cd\u53cc\u7cfb\u7edfVLA\u6a21\u578b\u3002"}}
{"id": "2510.22933", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.22933", "abs": "https://arxiv.org/abs/2510.22933", "authors": ["Inyoung Cheong", "Patty Liu", "Dominik Stammbach", "Peter Henderson"], "title": "How Can AI Augment Access to Justice? Public Defenders' Perspectives on AI Adoption", "comment": null, "summary": "Public defenders are asked to do more with less: representing clients\ndeserving of adequate counsel while facing overwhelming caseloads and scarce\nresources. While artificial intelligence (AI) and large language models (LLMs)\nare promoted as tools to alleviate this burden, such proposals are detached\nfrom the lived realities of public defenders. This study addresses that gap\nthrough semi-structured interviews with fourteen practitioners across the\nUnited States to examine their experiences with AI, anticipated applications,\nand ethical concerns. We find that AI adoption is constrained by costs,\nrestrictive office norms, confidentiality risks, and unsatisfactory tool\nquality. To clarify where AI can and cannot contribute, we propose a task-level\nmap of public defense. Public defenders view AI as most useful for evidence\ninvestigation to analyze overwhelming amounts of digital records, with narrower\nroles in legal research & writing, and client communication. Courtroom\nrepresentation and defense strategy are considered least compatible with AI\nassistance, as they depend on contextual judgment and trust. Public defenders\nemphasize safeguards for responsible use, including mandatory human\nverification, limits on overreliance, and the preservation of relational aspect\nof lawyering. Building on these findings, we outline a research agenda that\npromotes equitable access to justice by prioritizing open-source models,\ndomain-specific datasets and evaluation, and participatory design that\nincorporates defenders' perspectives into system development.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u8bbf\u8c0814\u540d\u7f8e\u56fd\u516c\u8bbe\u8fa9\u62a4\u4eba\uff0c\u63a2\u8ba8AI\u5728\u516c\u8bbe\u8fa9\u62a4\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3001\u9884\u671f\u7528\u9014\u548c\u4f26\u7406\u95ee\u9898\uff0c\u53d1\u73b0AI\u91c7\u7528\u53d7\u6210\u672c\u3001\u529e\u516c\u89c4\u8303\u3001\u4fdd\u5bc6\u98ce\u9669\u7b49\u56e0\u7d20\u9650\u5236\uff0c\u5e76\u63d0\u51fa\u4e86\u4efb\u52a1\u7ea7\u6620\u5c04\u6765\u660e\u786eAI\u7684\u9002\u7528\u9886\u57df\u3002", "motivation": "AI\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u88ab\u5ba3\u4f20\u4e3a\u51cf\u8f7b\u516c\u8bbe\u8fa9\u62a4\u4eba\u8d1f\u62c5\u7684\u5de5\u5177\uff0c\u4f46\u8fd9\u4e9b\u63d0\u8bae\u8131\u79bb\u4e86\u516c\u8bbe\u8fa9\u62a4\u4eba\u7684\u5b9e\u9645\u5de5\u4f5c\u73b0\u5b9e\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5bf9\u7f8e\u56fd14\u540d\u4ece\u4e1a\u8005\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u8003\u5bdf\u4ed6\u4eec\u5bf9AI\u7684\u4f53\u9a8c\u3001\u9884\u671f\u5e94\u7528\u548c\u4f26\u7406\u62c5\u5fe7\u3002", "result": "\u53d1\u73b0AI\u91c7\u7528\u53d7\u6210\u672c\u3001\u9650\u5236\u6027\u529e\u516c\u89c4\u8303\u3001\u4fdd\u5bc6\u98ce\u9669\u548c\u4e0d\u6ee1\u610f\u5de5\u5177\u8d28\u91cf\u7b49\u56e0\u7d20\u5236\u7ea6\uff1b\u516c\u8bbe\u8fa9\u62a4\u4eba\u8ba4\u4e3aAI\u5728\u8bc1\u636e\u8c03\u67e5\u4e2d\u6700\u6709\u7528\uff0c\u5728\u6cd5\u5f8b\u7814\u7a76\u548c\u5ba2\u6237\u6c9f\u901a\u4e2d\u4f5c\u7528\u6709\u9650\uff0c\u5728\u6cd5\u5ead\u4ee3\u7406\u548c\u8fa9\u62a4\u7b56\u7565\u4e2d\u6700\u4e0d\u9002\u7528\u3002", "conclusion": "\u63d0\u51fa\u4e86\u8d1f\u8d23\u4efb\u4f7f\u7528\u7684\u4fdd\u969c\u63aa\u65bd\uff0c\u5305\u62ec\u5f3a\u5236\u6027\u4eba\u5de5\u9a8c\u8bc1\u3001\u9650\u5236\u8fc7\u5ea6\u4f9d\u8d56\u4ee5\u53ca\u4fdd\u7559\u5f8b\u5e08\u5de5\u4f5c\u7684\u5173\u7cfb\u65b9\u9762\uff1b\u5e76\u5236\u5b9a\u4e86\u7814\u7a76\u8bae\u7a0b\uff0c\u4f18\u5148\u8003\u8651\u5f00\u6e90\u6a21\u578b\u3001\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\u548c\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\uff0c\u4ee5\u4fc3\u8fdb\u53f8\u6cd5\u516c\u5e73\u3002"}}
{"id": "2510.22039", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.22039", "abs": "https://arxiv.org/abs/2510.22039", "authors": ["Po-Chen Kuo", "Han Hou", "Will Dabney", "Edgar Y. Walker"], "title": "Predictive Coding Enhances Meta-RL To Achieve Interpretable Bayes-Optimal Belief Representation Under Partial Observability", "comment": "Accepted to Annual Conference on Neural Information Processing\n  Systems (NeurIPS) 2025", "summary": "Learning a compact representation of history is critical for planning and\ngeneralization in partially observable environments. While meta-reinforcement\nlearning (RL) agents can attain near Bayes-optimal policies, they often fail to\nlearn the compact, interpretable Bayes-optimal belief states. This\nrepresentational inefficiency potentially limits the agent's adaptability and\ngeneralization capacity. Inspired by predictive coding in neuroscience--which\nsuggests that the brain predicts sensory inputs as a neural implementation of\nBayesian inference--and by auxiliary predictive objectives in deep RL, we\ninvestigate whether integrating self-supervised predictive coding modules into\nmeta-RL can facilitate learning of Bayes-optimal representations. Through state\nmachine simulation, we show that meta-RL with predictive modules consistently\ngenerates more interpretable representations that better approximate\nBayes-optimal belief states compared to conventional meta-RL across a wide\nvariety of tasks, even when both achieve optimal policies. In challenging tasks\nrequiring active information seeking, only meta-RL with predictive modules\nsuccessfully learns optimal representations and policies, whereas conventional\nmeta-RL struggles with inadequate representation learning. Finally, we\ndemonstrate that better representation learning leads to improved\ngeneralization. Our results strongly suggest the role of predictive learning as\na guiding principle for effective representation learning in agents navigating\npartial observability.", "AI": {"tldr": "\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\uff0c\u4f20\u7edf\u5143\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u80fd\u5b66\u4e60\u5230\u63a5\u8fd1\u8d1d\u53f6\u65af\u6700\u4f18\u7684\u7b56\u7565\uff0c\u4f46\u65e0\u6cd5\u5b66\u4e60\u5230\u7d27\u51d1\u3001\u53ef\u89e3\u91ca\u7684\u8d1d\u53f6\u65af\u6700\u4f18\u4fe1\u5ff5\u72b6\u6001\u3002\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u9884\u6d4b\u7f16\u7801\u7684\u81ea\u76d1\u7763\u9884\u6d4b\u6a21\u5757\uff0c\u5143\u5f3a\u5316\u5b66\u4e60\u80fd\u591f\u5b66\u4e60\u5230\u66f4\u63a5\u8fd1\u8d1d\u53f6\u65af\u6700\u4f18\u7684\u8868\u793a\uff0c\u5728\u9700\u8981\u4e3b\u52a8\u4fe1\u606f\u5bfb\u6c42\u7684\u6311\u6218\u6027\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u5e76\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u5143\u5f3a\u5316\u5b66\u4e60\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u867d\u7136\u80fd\u83b7\u5f97\u63a5\u8fd1\u8d1d\u53f6\u65af\u6700\u4f18\u7684\u7b56\u7565\uff0c\u4f46\u65e0\u6cd5\u5b66\u4e60\u5230\u7d27\u51d1\u3001\u53ef\u89e3\u91ca\u7684\u8d1d\u53f6\u65af\u6700\u4f18\u4fe1\u5ff5\u72b6\u6001\uff0c\u8fd9\u79cd\u8868\u793a\u6548\u7387\u4f4e\u4e0b\u53ef\u80fd\u9650\u5236\u667a\u80fd\u4f53\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5c06\u57fa\u4e8e\u9884\u6d4b\u7f16\u7801\u7684\u81ea\u76d1\u7763\u9884\u6d4b\u6a21\u5757\u96c6\u6210\u5230\u5143\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u53d7\u795e\u7ecf\u79d1\u5b66\u4e2d\u9884\u6d4b\u7f16\u7801\uff08\u5927\u8111\u901a\u8fc7\u9884\u6d4b\u611f\u5b98\u8f93\u5165\u5b9e\u73b0\u8d1d\u53f6\u65af\u63a8\u65ad\uff09\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e2d\u8f85\u52a9\u9884\u6d4b\u76ee\u6807\u7684\u542f\u53d1\u3002", "result": "\u901a\u8fc7\u72b6\u6001\u673a\u6a21\u62df\u663e\u793a\uff0c\u5e26\u6709\u9884\u6d4b\u6a21\u5757\u7684\u5143\u5f3a\u5316\u5b66\u4e60\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u90fd\u80fd\u4ea7\u751f\u66f4\u53ef\u89e3\u91ca\u7684\u8868\u793a\uff0c\u66f4\u597d\u5730\u903c\u8fd1\u8d1d\u53f6\u65af\u6700\u4f18\u4fe1\u5ff5\u72b6\u6001\u3002\u5728\u9700\u8981\u4e3b\u52a8\u4fe1\u606f\u5bfb\u6c42\u7684\u6311\u6218\u6027\u4efb\u52a1\u4e2d\uff0c\u53ea\u6709\u5e26\u9884\u6d4b\u6a21\u5757\u7684\u5143\u5f3a\u5316\u5b66\u4e60\u80fd\u6210\u529f\u5b66\u4e60\u6700\u4f18\u8868\u793a\u548c\u7b56\u7565\uff0c\u800c\u4f20\u7edf\u5143\u5f3a\u5316\u5b66\u4e60\u56e0\u8868\u793a\u5b66\u4e60\u4e0d\u8db3\u800c\u5931\u8d25\u3002", "conclusion": "\u9884\u6d4b\u5b66\u4e60\u4f5c\u4e3a\u6307\u5bfc\u539f\u5219\uff0c\u5728\u667a\u80fd\u4f53\u5bfc\u822a\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u65f6\u80fd\u591f\u4fc3\u8fdb\u6709\u6548\u7684\u8868\u793a\u5b66\u4e60\uff0c\u66f4\u597d\u7684\u8868\u793a\u5b66\u4e60\u5e26\u6765\u4e86\u6539\u8fdb\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.22539", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.22539", "abs": "https://arxiv.org/abs/2510.22539", "authors": ["Heekang Song", "Wan Choi"], "title": "Approximate Gradient Coding for Distributed Learning with Heterogeneous Stragglers", "comment": null, "summary": "In this paper, we propose an optimally structured gradient coding scheme to\nmitigate the straggler problem in distributed learning. Conventional gradient\ncoding methods often assume homogeneous straggler models or rely on excessive\ndata replication, limiting performance in real-world heterogeneous systems. To\naddress these limitations, we formulate an optimization problem minimizing\nresidual error while ensuring unbiased gradient estimation by explicitly\nconsidering individual straggler probabilities. We derive closed-form solutions\nfor optimal encoding and decoding coefficients via Lagrangian duality and\nconvex optimization, and propose data allocation strategies that reduce both\nredundancy and computation load. We also analyze convergence behavior for\n$\\lambda$-strongly convex and $\\mu$-smooth loss functions. Numerical results\nshow that our approach significantly reduces the impact of stragglers and\naccelerates convergence compared to existing methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6700\u4f18\u7ed3\u6784\u7684\u68af\u5ea6\u7f16\u7801\u65b9\u6848\u6765\u89e3\u51b3\u5206\u5e03\u5f0f\u5b66\u4e60\u4e2d\u7684\u6162\u8282\u70b9\u95ee\u9898\uff0c\u901a\u8fc7\u8003\u8651\u4e2a\u4f53\u6162\u8282\u70b9\u6982\u7387\u6765\u6700\u5c0f\u5316\u6b8b\u5dee\u8bef\u5dee\u5e76\u786e\u4fdd\u65e0\u504f\u68af\u5ea6\u4f30\u8ba1\u3002", "motivation": "\u4f20\u7edf\u68af\u5ea6\u7f16\u7801\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u540c\u8d28\u6162\u8282\u70b9\u6a21\u578b\u6216\u4f9d\u8d56\u8fc7\u5ea6\u6570\u636e\u590d\u5236\uff0c\u5728\u73b0\u5b9e\u5f02\u6784\u7cfb\u7edf\u4e2d\u6027\u80fd\u53d7\u9650\u3002", "method": "\u901a\u8fc7\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u548c\u51f8\u4f18\u5316\u63a8\u5bfc\u51fa\u6700\u4f18\u7f16\u7801\u548c\u89e3\u7801\u7cfb\u6570\u7684\u95ed\u5f0f\u89e3\uff0c\u5e76\u63d0\u51fa\u51cf\u5c11\u5197\u4f59\u548c\u8ba1\u7b97\u8d1f\u8f7d\u7684\u6570\u636e\u5206\u914d\u7b56\u7565\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u6162\u8282\u70b9\u7684\u5f71\u54cd\uff0c\u5e76\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u52a0\u901f\u4e86\u6536\u655b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u68af\u5ea6\u7f16\u7801\u65b9\u6848\u5728\u5f02\u6784\u5206\u5e03\u5f0f\u5b66\u4e60\u73af\u5883\u4e2d\u6709\u6548\u7f13\u89e3\u4e86\u6162\u8282\u70b9\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2510.21854", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.21854", "abs": "https://arxiv.org/abs/2510.21854", "authors": ["Sourabh Karmakar", "Cameron J. Turner"], "title": "A Literature Review On Stewart-Gough Platform Calibrations A Literature Review On Stewart-Gough Platform Calibrations", "comment": null, "summary": "Researchers have studied Stewart-Gough platforms, also known as Gough-Stewart\nplatforms or hexapod platforms extensively for their inherent fine control\ncharacteristics. Their studies led to the potential deployment opportunities of\nStewart-Gough Platforms in many critical applications such as the medical\nfield, engineering machines, space research, electronic chip manufacturing,\nautomobile manufacturing, etc. Some of these applications need micro and\nnano-level movement control in 3D space for the motions to be precise,\ncomplicated, and repeatable; a Stewart-Gough platform fulfills these challenges\nsmartly. For this, the platform must be more accurate than the specified\napplication accuracy level and thus proper calibration for a parallel robot is\ncrucial. Forward kinematics-based calibration for these hexapod machines\nbecomes unnecessarily complex and inverse kinematics complete this task with\nmuch ease. To experiment with different calibration techniques, various\ncalibration approaches were implemented by using external instruments,\nconstraining one or more motions of the system, and using extra sensors for\nauto or self-calibration. This survey paid attention to those key\nmethodologies, their outcome, and important details related to inverse\nkinematic-based parallel robot calibrations. It was observed during this study\nthat the researchers focused on improving the accuracy of the platform position\nand orientation considering the errors contributed by one source or multiple\nsources. The error sources considered are mainly kinematic and structural, in\nsome cases, environmental factors also are reviewed, however, those\ncalibrations are done under no-load conditions. This study aims to review the\npresent state of the art in this field and highlight the processes and errors\nconsidered for the calibration of Stewart-Gough platforms.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86Stewart-Gough\u5e73\u53f0\uff08\u516d\u8db3\u5e73\u53f0\uff09\u7684\u6821\u51c6\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u57fa\u4e8e\u9006\u8fd0\u52a8\u5b66\u7684\u6821\u51c6\u6280\u672f\uff0c\u5206\u6790\u4e86\u5404\u79cd\u6821\u51c6\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u548c\u8bef\u5dee\u6e90\u3002", "motivation": "Stewart-Gough\u5e73\u53f0\u5728\u533b\u7597\u3001\u5de5\u7a0b\u3001\u822a\u5929\u7b49\u5173\u952e\u5e94\u7528\u4e2d\u9700\u8981\u5fae\u7c73\u7ea7\u548c\u7eb3\u7c73\u7ea7\u7684\u7cbe\u786e\u8fd0\u52a8\u63a7\u5236\uff0c\u56e0\u6b64\u9ad8\u7cbe\u5ea6\u6821\u51c6\u81f3\u5173\u91cd\u8981\u3002\u6b63\u5411\u8fd0\u52a8\u5b66\u6821\u51c6\u8fc7\u4e8e\u590d\u6742\uff0c\u800c\u9006\u8fd0\u52a8\u5b66\u6821\u51c6\u66f4\u4e3a\u7b80\u4fbf\u6709\u6548\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u5916\u90e8\u4eea\u5668\u3001\u7ea6\u675f\u7cfb\u7edf\u8fd0\u52a8\u3001\u6dfb\u52a0\u989d\u5916\u4f20\u611f\u5668\u7b49\u65b9\u6cd5\u5b9e\u73b0\u81ea\u52a8\u6216\u81ea\u6821\u51c6\uff0c\u4e3b\u8981\u91c7\u7528\u57fa\u4e8e\u9006\u8fd0\u52a8\u5b66\u7684\u6821\u51c6\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7814\u7a76\u4eba\u5458\u4e3b\u8981\u5173\u6ce8\u63d0\u9ad8\u5e73\u53f0\u4f4d\u7f6e\u548c\u65b9\u5411\u7cbe\u5ea6\uff0c\u8003\u8651\u5355\u4e00\u6216\u591a\u91cd\u8bef\u5dee\u6e90\uff0c\u5305\u62ec\u8fd0\u52a8\u5b66\u548c\u7ed3\u6784\u8bef\u5dee\uff0c\u90e8\u5206\u7814\u7a76\u8fd8\u6d89\u53ca\u73af\u5883\u56e0\u7d20\uff0c\u4f46\u6821\u51c6\u901a\u5e38\u5728\u65e0\u8d1f\u8f7d\u6761\u4ef6\u4e0b\u8fdb\u884c\u3002", "conclusion": "\u672c\u6587\u7efc\u8ff0\u4e86Stewart-Gough\u5e73\u53f0\u6821\u51c6\u9886\u57df\u7684\u6700\u65b0\u6280\u672f\uff0c\u91cd\u70b9\u7a81\u51fa\u4e86\u6821\u51c6\u8fc7\u7a0b\u4e2d\u8003\u8651\u7684\u5404\u79cd\u8fc7\u7a0b\u548c\u8bef\u5dee\u6e90\u3002"}}
{"id": "2510.23523", "categories": ["cs.CY"], "pdf": "https://arxiv.org/pdf/2510.23523", "abs": "https://arxiv.org/abs/2510.23523", "authors": ["Svetlana Kiritchenko", "Anna Kerkhof", "Isar Nejadgholi", "Kathleen C. Fraser"], "title": "From Perceived Effectiveness to Measured Impact: Identity-Aware Evaluation of Automated Counter-Stereotypes", "comment": "In Proceedings of the Identity-Aware AI Workshop at 28th European\n  Conference on Artificial Intelligence (ECAI-2025)", "summary": "We investigate the effect of automatically generated counter-stereotypes on\ngender bias held by users of various demographics on social media. Building on\nrecent NLP advancements and social psychology literature, we evaluate two\ncounter-stereotype strategies -- counter-facts and broadening universals (i.e.,\nstating that anyone can have a trait regardless of group membership) -- which\nhave been identified as the most potentially effective in previous studies. We\nassess the real-world impact of these strategies on mitigating gender bias\nacross user demographics (gender and age), through the Implicit Association\nTest and the self-reported measures of explicit bias and perceived utility. Our\nfindings reveal that actual effectiveness does not align with perceived\neffectiveness, and the former is a nuanced and sometimes divergent phenomenon\nacross demographic groups. While overall bias reduction was limited, certain\ngroups (e.g., older, male participants) exhibited measurable improvements in\nimplicit bias in response to some interventions. Conversely, younger\nparticipants, especially women, showed increasing bias in response to the same\ninterventions. These results highlight the complex and identity-sensitive\nnature of stereotype mitigation and call for dynamic and context-aware\nevaluation and mitigation strategies.", "AI": {"tldr": "\u7814\u7a76\u81ea\u52a8\u751f\u6210\u7684\u523b\u677f\u5370\u8c61\u53cd\u9a73\u4fe1\u606f\u5bf9\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u7528\u6237\u5728\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u6027\u522b\u504f\u89c1\u5f71\u54cd\uff0c\u53d1\u73b0\u5b9e\u9645\u6548\u679c\u4e0e\u611f\u77e5\u6548\u679c\u4e0d\u4e00\u81f4\uff0c\u4e14\u5e72\u9884\u6548\u679c\u56e0\u4eba\u53e3\u7279\u5f81\u800c\u5f02\u3002", "motivation": "\u57fa\u4e8eNLP\u8fdb\u5c55\u548c\u793e\u4f1a\u5fc3\u7406\u5b66\u6587\u732e\uff0c\u8bc4\u4f30\u4e24\u79cd\u523b\u677f\u5370\u8c61\u53cd\u9a73\u7b56\u7565\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u51cf\u8f7b\u6027\u522b\u504f\u89c1\u7684\u6548\u679c\uff0c\u7279\u522b\u662f\u8de8\u7528\u6237\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\uff08\u6027\u522b\u548c\u5e74\u9f84\uff09\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u81ea\u52a8\u751f\u6210\u7684\u523b\u677f\u5370\u8c61\u53cd\u9a73\u4fe1\u606f\uff08\u53cd\u4e8b\u5b9e\u548c\u666e\u904d\u5316\u7b56\u7565\uff09\uff0c\u901a\u8fc7\u5185\u9690\u8054\u60f3\u6d4b\u8bd5\u3001\u5916\u663e\u504f\u89c1\u81ea\u6211\u62a5\u544a\u548c\u611f\u77e5\u6548\u7528\u6d4b\u91cf\u6765\u8bc4\u4f30\u6548\u679c\u3002", "result": "\u603b\u4f53\u504f\u89c1\u51cf\u5c11\u6709\u9650\uff0c\u4f46\u67d0\u4e9b\u7fa4\u4f53\uff08\u5982\u5e74\u957f\u7537\u6027\u53c2\u4e0e\u8005\uff09\u5bf9\u67d0\u4e9b\u5e72\u9884\u8868\u73b0\u51fa\u53ef\u6d4b\u91cf\u7684\u5185\u9690\u504f\u89c1\u6539\u5584\uff0c\u800c\u5e74\u8f7b\u53c2\u4e0e\u8005\uff08\u5c24\u5176\u662f\u5973\u6027\uff09\u5bf9\u76f8\u540c\u5e72\u9884\u8868\u73b0\u51fa\u504f\u89c1\u589e\u52a0\u3002", "conclusion": "\u523b\u677f\u5370\u8c61\u7f13\u89e3\u5177\u6709\u590d\u6742\u6027\u548c\u8eab\u4efd\u654f\u611f\u6027\uff0c\u9700\u8981\u52a8\u6001\u548c\u60c5\u5883\u611f\u77e5\u7684\u8bc4\u4f30\u4e0e\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2510.22046", "categories": ["cs.AI", "cs.AR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.22046", "abs": "https://arxiv.org/abs/2510.22046", "authors": ["Daniel G. P. Petrini", "Braz Izaias da Silva Junior"], "title": "HW/SW Co-design of a PCM/PWM converter: a System Level Approach based in the SpecC Methodology", "comment": "6", "summary": "We present a case study applying the SpecC methodology within a system-level\nhardware/software co-design flow to a PCM-to-PWM converter, the core of a\nClass-D audio amplifier. The converter was modeled and explored with SpecC\nmethodology to derive an HW/SW partition. Using system-level estimates and fast\nfunctional simulation, we evaluated mappings that meet real-time constraints\nwhile reducing estimated cost of an all-hardware solution and avoiding the\nexpense of a purely software implementation on a high-end processor. Despite\nthe design's moderate complexity, the results underline the value of\nsystem-level co-design for early architectural insight, rapid validation, and\nactionable cost/performance trade-offs. [Original work from 2005; formatting\nrevised in 2025, with no changes to the results.]", "AI": {"tldr": "\u5e94\u7528SpecC\u65b9\u6cd5\u5b66\u5bf9PCM-to-PWM\u8f6c\u6362\u5668\u8fdb\u884c\u7cfb\u7edf\u7ea7\u786c\u4ef6/\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5efa\u6a21\u548c\u67b6\u6784\u63a2\u7d22\u5b9e\u73b0\u4f18\u5316\u7684HW/SW\u5212\u5206\uff0c\u5728\u6ee1\u8db3\u5b9e\u65f6\u7ea6\u675f\u7684\u540c\u65f6\u964d\u4f4e\u5168\u786c\u4ef6\u65b9\u6848\u7684\u6210\u672c\u3002", "motivation": "\u7814\u7a76\u7cfb\u7edf\u7ea7\u786c\u4ef6/\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\u5728PCM-to-PWM\u8f6c\u6362\u5668\uff08Class-D\u97f3\u9891\u653e\u5927\u5668\u6838\u5fc3\uff09\u4e2d\u7684\u5e94\u7528\u4ef7\u503c\uff0c\u63a2\u7d22\u5982\u4f55\u5728\u6ee1\u8db3\u5b9e\u65f6\u6027\u80fd\u8981\u6c42\u7684\u540c\u65f6\u4f18\u5316\u6210\u672c\u6548\u76ca\u3002", "method": "\u4f7f\u7528SpecC\u65b9\u6cd5\u5b66\u5bf9PCM-to-PWM\u8f6c\u6362\u5668\u8fdb\u884c\u5efa\u6a21\u548c\u67b6\u6784\u63a2\u7d22\uff0c\u901a\u8fc7\u7cfb\u7edf\u7ea7\u8bc4\u4f30\u548c\u5feb\u901f\u529f\u80fd\u4eff\u771f\u6765\u8bc4\u4f30\u4e0d\u540c\u7684\u786c\u4ef6/\u8f6f\u4ef6\u5212\u5206\u65b9\u6848\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u6ee1\u8db3\u5b9e\u65f6\u7ea6\u675f\u7684\u786c\u4ef6/\u8f6f\u4ef6\u5212\u5206\u65b9\u6848\uff0c\u76f8\u6bd4\u5168\u786c\u4ef6\u89e3\u51b3\u65b9\u6848\u964d\u4f4e\u4e86\u4f30\u8ba1\u6210\u672c\uff0c\u540c\u65f6\u907f\u514d\u4e86\u5728\u9ad8\u6027\u80fd\u5904\u7406\u5668\u4e0a\u7eaf\u8f6f\u4ef6\u5b9e\u73b0\u7684\u9ad8\u6602\u8d39\u7528\u3002", "conclusion": "\u5373\u4f7f\u5bf9\u4e8e\u4e2d\u7b49\u590d\u6742\u5ea6\u7684\u8bbe\u8ba1\uff0c\u7cfb\u7edf\u7ea7\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\u4ecd\u80fd\u63d0\u4f9b\u65e9\u671f\u67b6\u6784\u6d1e\u5bdf\u3001\u5feb\u901f\u9a8c\u8bc1\u4ee5\u53ca\u53ef\u884c\u7684\u6210\u672c/\u6027\u80fd\u6743\u8861\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u4ef7\u503c\u3002"}}
{"id": "2510.22790", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.22790", "abs": "https://arxiv.org/abs/2510.22790", "authors": ["Reza Pordal", "Alireza Sharifi", "Ali Baniasad"], "title": "Ellipsoidal Set-Theoretic Design of Robust Safety Filters for Constrained Linear Systems", "comment": null, "summary": "This paper presents an ellipsoidal set-theoretic framework for robust safety\nfilter synthesis in constrained linear systems subject to additive bounded\ndisturbances and input constraints. We formulate the safety filter design as a\nconvex linear matrix inequality (LMI) optimization problem that simultaneously\ncomputes a robust controlled invariant (RCI) ellipsoidal set and its associated\nstate-feedback control law. The RCI set is characterized as an ellipsoidal set,\nenabling computational tractability for high-dimensional systems while\nproviding formal safety guarantees. The safety filter employs a smooth mixing\nstrategy between nominal and backup controllers based on distance to the\ninvariant set boundary, facilitating minimal intervention when the system\noperates safely. The proposed method extends to nonlinear systems by treating\nnonlinear terms as bounded disturbances with rigorous approximation bounds.\nNumerical validation on a six-degree-of-freedom quadrotor system demonstrates\nthe filter's effectiveness in maintaining stability under external disturbances\nand aggressive maneuvers while preserving nominal performance during safe\noperation. The approach provides a constructive and computationally efficient\nsolution for safety-critical control applications requiring real-time\nimplementation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u692d\u7403\u96c6\u7406\u8bba\u7684\u9c81\u68d2\u5b89\u5168\u6ee4\u6ce2\u5668\u5408\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u53d7\u52a0\u6027\u6709\u754c\u6270\u52a8\u548c\u8f93\u5165\u7ea6\u675f\u7684\u7ebf\u6027\u7cfb\u7edf\uff0c\u901a\u8fc7\u51f8LMI\u4f18\u5316\u540c\u65f6\u8ba1\u7b97\u9c81\u68d2\u63a7\u5236\u4e0d\u53d8\u96c6\u53ca\u5176\u72b6\u6001\u53cd\u9988\u63a7\u5236\u5f8b\u3002", "motivation": "\u4e3a\u9ad8\u7ef4\u7ea6\u675f\u7ebf\u6027\u7cfb\u7edf\u63d0\u4f9b\u8ba1\u7b97\u4e0a\u53ef\u5904\u7406\u4e14\u5177\u6709\u5f62\u5f0f\u5316\u5b89\u5168\u4fdd\u8bc1\u7684\u5b89\u5168\u6ee4\u6ce2\u5668\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u89e3\u51b3\u5728\u5916\u90e8\u6270\u52a8\u548c\u8f93\u5165\u7ea6\u675f\u4e0b\u7684\u5b89\u5168\u63a7\u5236\u95ee\u9898\u3002", "method": "\u5c06\u5b89\u5168\u6ee4\u6ce2\u5668\u8bbe\u8ba1\u8868\u8ff0\u4e3a\u51f8LMI\u4f18\u5316\u95ee\u9898\uff0c\u540c\u65f6\u8ba1\u7b97\u9c81\u68d2\u63a7\u5236\u4e0d\u53d8\u692d\u7403\u96c6\u53ca\u5176\u72b6\u6001\u53cd\u9988\u63a7\u5236\u5f8b\uff0c\u91c7\u7528\u57fa\u4e8e\u5230\u4e0d\u53d8\u96c6\u8fb9\u754c\u8ddd\u79bb\u7684\u5e73\u6ed1\u6df7\u5408\u7b56\u7565\uff0c\u5e76\u6269\u5c55\u5230\u975e\u7ebf\u6027\u7cfb\u7edf\u3002", "result": "\u5728\u516d\u81ea\u7531\u5ea6\u56db\u65cb\u7ffc\u7cfb\u7edf\u4e0a\u7684\u6570\u503c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u6ee4\u6ce2\u5668\u5728\u5916\u90e8\u6270\u52a8\u548c\u5267\u70c8\u673a\u52a8\u4e0b\u80fd\u6709\u6548\u4fdd\u6301\u7a33\u5b9a\u6027\uff0c\u5728\u5b89\u5168\u64cd\u4f5c\u671f\u95f4\u4fdd\u6301\u6807\u79f0\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9700\u8981\u5b9e\u65f6\u5b9e\u73b0\u7684\u5b89\u5168\u5173\u952e\u63a7\u5236\u5e94\u7528\u63d0\u4f9b\u4e86\u6784\u9020\u6027\u548c\u8ba1\u7b97\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.21860", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21860", "abs": "https://arxiv.org/abs/2510.21860", "authors": ["Callum Sharrock", "Lukas Petersson", "Hanna Petersson", "Axel Backlund", "Axel Wennstr\u00f6m", "Kristoffer Nordstr\u00f6m", "Elias Aronsson"], "title": "Butter-Bench: Evaluating LLM Controlled Robots for Practical Intelligence", "comment": null, "summary": "We present Butter-Bench, a benchmark evaluating large language model (LLM)\ncontrolled robots for practical intelligence, defined as the ability to\nnavigate the messiness of the physical world. Current state-of-the-art robotic\nsystems use a hierarchical architecture with LLMs in charge of high-level\nreasoning, and a Vision Language Action (VLA) model for low-level control.\nButter-Bench evaluates the LLM part in isolation from the VLA. Although LLMs\nhave repeatedly surpassed humans in evaluations requiring analytical\nintelligence, we find humans still outperform LLMs on Butter-Bench. The best\nLLMs score 40% on Butter-Bench, while the mean human score is 95%. LLMs\nstruggled the most with multi-step spatial planning and social understanding.\nWe also evaluate LLMs that are fine-tuned for embodied reasoning and conclude\nthat this training does not improve their score on Butter-Bench.", "AI": {"tldr": "Butter-Bench\u662f\u4e00\u4e2a\u8bc4\u4f30LLM\u63a7\u5236\u673a\u5668\u4eba\u5b9e\u7528\u667a\u80fd\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u4eba\u7c7b\u8868\u73b0(95%)\u8fdc\u8d85\u6700\u4f73LLM(40%)\uff0c\u7279\u522b\u662f\u5728\u591a\u6b65\u9aa4\u7a7a\u95f4\u89c4\u5212\u548c\u793e\u4f1a\u7406\u89e3\u65b9\u9762\u3002", "motivation": "\u8bc4\u4f30LLM\u5728\u7269\u7406\u4e16\u754c\u4e2d\u7684\u5b9e\u7528\u667a\u80fd\u80fd\u529b\uff0c\u5f53\u524d\u673a\u5668\u4eba\u7cfb\u7edf\u91c7\u7528\u5206\u5c42\u67b6\u6784\uff0cLLM\u8d1f\u8d23\u9ad8\u5c42\u63a8\u7406\uff0cVLA\u8d1f\u8d23\u4f4e\u5c42\u63a7\u5236\u3002", "method": "\u5f00\u53d1Butter-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c06LLM\u90e8\u5206\u4e0eVLA\u6a21\u578b\u5206\u79bb\u8fdb\u884c\u72ec\u7acb\u8bc4\u4f30\uff0c\u6bd4\u8f83LLM\u4e0e\u4eba\u7c7b\u5728\u5b9e\u7528\u667a\u80fd\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u4eba\u7c7b\u5e73\u5747\u5f97\u520695%\uff0c\u6700\u4f73LLM\u4ec5\u5f9740%\uff0cLLM\u5728\u591a\u6b65\u9aa4\u7a7a\u95f4\u89c4\u5212\u548c\u793e\u4f1a\u7406\u89e3\u65b9\u9762\u8868\u73b0\u6700\u5dee\uff0c\u4e13\u95e8\u9488\u5bf9\u5177\u8eab\u63a8\u7406\u7684\u5fae\u8c03\u4e5f\u672a\u6539\u5584\u8868\u73b0\u3002", "conclusion": "\u5c3d\u7ba1LLM\u5728\u5206\u6790\u667a\u80fd\u65b9\u9762\u8d85\u8d8a\u4eba\u7c7b\uff0c\u4f46\u5728\u7269\u7406\u4e16\u754c\u7684\u5b9e\u7528\u667a\u80fd\u65b9\u9762\u4ecd\u8fdc\u4e0d\u53ca\u4eba\u7c7b\uff0c\u7279\u522b\u662f\u5728\u7a7a\u95f4\u89c4\u5212\u548c\u793e\u4f1a\u7406\u89e3\u80fd\u529b\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002"}}
{"id": "2510.22050", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.22050", "abs": "https://arxiv.org/abs/2510.22050", "authors": ["Marcus Thomas"], "title": "Towards Error-Centric Intelligence II: Energy-Structured Causal Models", "comment": null, "summary": "Contemporary machine learning optimizes for predictive accuracy, yet systems\nthat achieve state of the art performance remain causally opaque: their\ninternal representations provide no principled handle for intervention. We can\nretrain such models, but we cannot surgically edit specific mechanisms while\nholding others fixed, because learned latent variables lack causal semantics.\nWe argue for a conceptual reorientation: intelligence is the ability to build\nand refine explanations, falsifiable claims about manipulable structure that\nspecify what changes and what remains invariant under intervention.\nExplanations subsume prediction but demand more: causal commitments that can be\nindependently tested and corrected at the level of mechanisms. We introduce\ncomputational explanations, mappings from observations to intervention ready\ncausal accounts. We instantiate these explanations with Energy Structured\nCausal Models (ESCMs), in which mechanisms are expressed as constraints (energy\nfunctions or vector fields) rather than explicit input output maps, and\ninterventions act by local surgery on those constraints. This shift makes\ninternal structure manipulable at the level where explanations live: which\nrelations must hold, which can change, and what follows when they do. We\nprovide concrete instantiations of the structural-causal principles LAP and ICM\nin the ESCM context, and also argue that empirical risk minimization\nsystematically produces fractured, entangled representations, a failure we\nanalyze as gauge ambiguity in encoder energy pairs. Finally, we show that under\nmild conditions, ESCMs recover standard SCM semantics. Building on Part I's\nprinciples (LAP, ICM, CAP) and its definition of intelligence as\nexplanation-building under criticism, this paper offers a formal language for\ncausal reasoning in systems that aspire to understand, not merely to predict.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4ece\u9884\u6d4b\u51c6\u786e\u6027\u8f6c\u5411\u56e0\u679c\u89e3\u91ca\u6027\u7684\u6982\u5ff5\u8f6c\u5411\uff0c\u5f15\u5165\u8ba1\u7b97\u89e3\u91ca\u548c\u80fd\u91cf\u7ed3\u6784\u5316\u56e0\u679c\u6a21\u578b(ESCMs)\uff0c\u4f7f\u7cfb\u7edf\u5185\u90e8\u7ed3\u6784\u53ef\u5e72\u9884\u548c\u64cd\u4f5c\u3002", "motivation": "\u5f53\u524d\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u867d\u7136\u9884\u6d4b\u6027\u80fd\u4f18\u5f02\uff0c\u4f46\u56e0\u679c\u900f\u660e\u5ea6\u4e0d\u8db3\uff0c\u65e0\u6cd5\u5bf9\u7279\u5b9a\u673a\u5236\u8fdb\u884c\u5916\u79d1\u624b\u672f\u5f0f\u7f16\u8f91\uff0c\u56e0\u4e3a\u5b66\u4e60\u5230\u7684\u6f5c\u5728\u53d8\u91cf\u7f3a\u4e4f\u56e0\u679c\u8bed\u4e49\u3002", "method": "\u5f15\u5165\u8ba1\u7b97\u89e3\u91ca\u548c\u80fd\u91cf\u7ed3\u6784\u5316\u56e0\u679c\u6a21\u578b(ESCMs)\uff0c\u5c06\u673a\u5236\u8868\u8fbe\u4e3a\u7ea6\u675f(\u80fd\u91cf\u51fd\u6570\u6216\u5411\u91cf\u573a)\u800c\u975e\u663e\u5f0f\u8f93\u5165\u8f93\u51fa\u6620\u5c04\uff0c\u5e72\u9884\u901a\u8fc7\u5c40\u90e8\u624b\u672f\u4f5c\u7528\u4e8e\u8fd9\u4e9b\u7ea6\u675f\u3002", "result": "\u5728ESCM\u80cc\u666f\u4e0b\u5b9e\u4f8b\u5316\u4e86\u7ed3\u6784\u56e0\u679c\u539f\u5219LAP\u548cICM\uff0c\u5206\u6790\u4e86\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u4ea7\u751f\u65ad\u88c2\u7ea0\u7f20\u8868\u793a\u7684\u95ee\u9898\uff0c\u5e76\u8bc1\u660e\u5728\u6e29\u548c\u6761\u4ef6\u4e0bESCMs\u6062\u590d\u6807\u51c6SCM\u8bed\u4e49\u3002", "conclusion": "\u672c\u6587\u4e3a\u56e0\u679c\u63a8\u7406\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u8bed\u8a00\uff0c\u4f7f\u7cfb\u7edf\u80fd\u591f\u7406\u89e3\u800c\u4e0d\u4ec5\u4ec5\u662f\u9884\u6d4b\uff0c\u5efa\u7acb\u5728Part I\u7684\u539f\u5219(LAP\u3001ICM\u3001CAP)\u548c\u667a\u80fd\u4f5c\u4e3a\u6279\u8bc4\u4e0b\u6784\u5efa\u89e3\u91ca\u7684\u5b9a\u4e49\u4e4b\u4e0a\u3002"}}
{"id": "2510.22813", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.22813", "abs": "https://arxiv.org/abs/2510.22813", "authors": ["Feng Guo", "Luis D. Couto", "Khiem Trad", "Guangdi Hu", "Mohammadhosein Safari"], "title": "Residual Bias Compensation Filter for Physics-Based SOC Estimation in Lithium Iron Phosphate Batteries", "comment": "This paper has been submitted to the European Control Conference\n  (ECC) 2026 for consideration. This is the authors' version of the work, made\n  available for early dissemination. The copyright remains with the authors.\n  The final version, if accepted, will appear in the ECC 2026 proceedings", "summary": "This paper addresses state of charge (SOC) estimation for lithium iron\nphosphate (LFP) batteries, where the relatively flat open-circuit voltage\n(OCV-SOC) characteristic reduces observability. A residual bias compensation\ndual extended Kalman filter (RBC-DEKF) is developed. Unlike conventional bias\ncompensation methods that treat the bias as an augmented state within a single\nfilter, the proposed dual-filter structure decouples residual bias estimation\nfrom electrochemical state estimation. One EKF estimates the system states of a\ncontrol-oriented parameter-grouped single particle model with thermal effects,\nwhile the other EKF estimates a residual bias that continuously corrects the\nvoltage observation equation, thereby refining the model-predicted voltage in\nreal time. Unlike bias-augmented single-filter schemes that enlarge the\ncovariance coupling, the decoupled bias estimator refines the voltage\nobservation without perturbing electrochemical state dynamics. Validation is\nconducted on an LFP cell from a public dataset under three representative\noperating conditions: US06 at 0 degC, DST at 25 degC, and FUDS at 50 degC.\nCompared with a conventional EKF using the same model and identical state\nfilter settings, the proposed method reduces the average SOC RMSE from 3.75% to\n0.20% and the voltage RMSE between the filtered model voltage and the measured\nvoltage from 32.8 mV to 0.8 mV. The improvement is most evident in the mid-SOC\nrange where the OCV-SOC curve is flat, confirming that residual bias\ncompensation significantly enhances accuracy for model-based SOC estimation of\nLFP batteries across a wide temperature range.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6b8b\u5dee\u504f\u7f6e\u8865\u507f\u53cc\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff08RBC-DEKF\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u78f7\u9178\u94c1\u9502\u7535\u6c60SOC\u4f30\u8ba1\u4e2dOCV-SOC\u7279\u6027\u5e73\u5766\u5bfc\u81f4\u7684\u89c2\u6d4b\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u53cc\u6ee4\u6ce2\u5668\u7ed3\u6784\u5206\u79bb\u6b8b\u5dee\u504f\u7f6e\u4f30\u8ba1\u548c\u7535\u5316\u5b66\u72b6\u6001\u4f30\u8ba1\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4f30\u8ba1\u7cbe\u5ea6\u3002", "motivation": "\u78f7\u9178\u94c1\u9502\u7535\u6c60\u7684\u5f00\u8def\u7535\u538b-\u8377\u7535\u72b6\u6001\u7279\u6027\u76f8\u5bf9\u5e73\u5766\uff0c\u964d\u4f4e\u4e86\u7cfb\u7edf\u7684\u53ef\u89c2\u6d4b\u6027\uff0c\u8fd9\u4f7f\u5f97\u4f20\u7edf\u7684SOC\u4f30\u8ba1\u65b9\u6cd5\u5728LFP\u7535\u6c60\u4e0a\u7cbe\u5ea6\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1\u4e86\u6b8b\u5dee\u504f\u7f6e\u8865\u507f\u53cc\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u91c7\u7528\u53cc\u6ee4\u6ce2\u5668\u7ed3\u6784\uff1a\u4e00\u4e2aEKF\u4f30\u8ba1\u63a7\u5236\u5bfc\u5411\u7684\u53c2\u6570\u5206\u7ec4\u5355\u7c92\u5b50\u6a21\u578b\uff08\u542b\u70ed\u6548\u5e94\uff09\u7684\u7cfb\u7edf\u72b6\u6001\uff0c\u53e6\u4e00\u4e2aEKF\u4f30\u8ba1\u6b8b\u5dee\u504f\u7f6e\uff0c\u5b9e\u65f6\u4fee\u6b63\u7535\u538b\u89c2\u6d4b\u65b9\u7a0b\u3002", "result": "\u5728\u4e09\u79cd\u4ee3\u8868\u6027\u5de5\u51b5\u4e0b\u9a8c\u8bc1\uff0c\u4e0e\u4f20\u7edfEKF\u76f8\u6bd4\uff0c\u5e73\u5747SOC\u5747\u65b9\u6839\u8bef\u5dee\u4ece3.75%\u964d\u81f30.20%\uff0c\u7535\u538b\u5747\u65b9\u6839\u8bef\u5dee\u4ece32.8mV\u964d\u81f30.8mV\uff0c\u5728OCV-SOC\u66f2\u7ebf\u5e73\u5766\u7684\u4e2dSOC\u533a\u95f4\u6539\u8fdb\u6700\u4e3a\u660e\u663e\u3002", "conclusion": "\u6b8b\u5dee\u504f\u7f6e\u8865\u507f\u663e\u8457\u63d0\u9ad8\u4e86\u57fa\u4e8e\u6a21\u578b\u7684LFP\u7535\u6c60SOC\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u5728\u5bbd\u6e29\u5ea6\u8303\u56f4\u5185\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5bf9\u89e3\u51b3LFP\u7535\u6c60\u89c2\u6d4b\u6027\u95ee\u9898\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.21874", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21874", "abs": "https://arxiv.org/abs/2510.21874", "authors": ["Shuning Zhang"], "title": "A Physics-Informed Neural Network Approach for UAV Path Planning in Dynamic Environments", "comment": "15 pages, 8 figures", "summary": "Unmanned aerial vehicles (UAVs) operating in dynamic wind fields must\ngenerate safe and energy-efficient trajectories under physical and\nenvironmental constraints. Traditional planners, such as A* and kinodynamic\nRRT*, often yield suboptimal or non-smooth paths due to discretization and\nsampling limitations. This paper presents a physics-informed neural network\n(PINN) framework that embeds UAV dynamics, wind disturbances, and obstacle\navoidance directly into the learning process. Without requiring supervised\ndata, the PINN learns dynamically feasible and collision-free trajectories by\nminimizing physical residuals and risk-aware objectives. Comparative\nsimulations show that the proposed method outperforms A* and Kino-RRT* in\ncontrol energy, smoothness, and safety margin, while maintaining similar flight\nefficiency. The results highlight the potential of physics-informed learning to\nunify model-based and data-driven planning, providing a scalable and physically\nconsistent framework for UAV trajectory optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc(PINN)\u7684\u65e0\u4eba\u673a\u8f68\u8ff9\u89c4\u5212\u6846\u67b6\uff0c\u5c06\u65e0\u4eba\u673a\u52a8\u529b\u5b66\u3001\u98ce\u573a\u6270\u52a8\u548c\u969c\u788d\u7269\u907f\u8ba9\u76f4\u63a5\u5d4c\u5165\u5b66\u4e60\u8fc7\u7a0b\uff0c\u65e0\u9700\u76d1\u7763\u6570\u636e\u5373\u53ef\u751f\u6210\u52a8\u6001\u53ef\u884c\u4e14\u65e0\u78b0\u649e\u7684\u8f68\u8ff9\u3002", "motivation": "\u4f20\u7edf\u89c4\u5212\u5668\u5982A*\u548cKino-RRT*\u7531\u4e8e\u79bb\u6563\u5316\u548c\u91c7\u6837\u9650\u5236\uff0c\u5f80\u5f80\u4ea7\u751f\u6b21\u4f18\u6216\u4e0d\u5e73\u6ed1\u7684\u8def\u5f84\u3002\u65e0\u4eba\u673a\u5728\u52a8\u6001\u98ce\u573a\u4e2d\u9700\u8981\u751f\u6210\u5b89\u5168\u4e14\u80fd\u91cf\u9ad8\u6548\u7684\u8f68\u8ff9\u3002", "method": "\u4f7f\u7528\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u7269\u7406\u6b8b\u5dee\u548c\u98ce\u9669\u611f\u77e5\u76ee\u6807\u6765\u5b66\u4e60\u8f68\u8ff9\uff0c\u65e0\u9700\u76d1\u7763\u6570\u636e\u3002\u8be5\u6846\u67b6\u5d4c\u5165\u4e86\u65e0\u4eba\u673a\u52a8\u529b\u5b66\u3001\u98ce\u6270\u52a8\u548c\u969c\u788d\u7269\u907f\u8ba9\u7ea6\u675f\u3002", "result": "\u6bd4\u8f83\u4eff\u771f\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u63a7\u5236\u80fd\u91cf\u3001\u5e73\u6ed1\u5ea6\u548c\u5b89\u5168\u88d5\u5ea6\u65b9\u9762\u4f18\u4e8eA*\u548cKino-RRT*\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u4f3c\u7684\u98de\u884c\u6548\u7387\u3002", "conclusion": "\u7269\u7406\u4fe1\u606f\u5b66\u4e60\u6709\u6f5c\u529b\u7edf\u4e00\u57fa\u4e8e\u6a21\u578b\u548c\u6570\u636e\u9a71\u52a8\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u4e3a\u65e0\u4eba\u673a\u8f68\u8ff9\u4f18\u5316\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u7269\u7406\u4e00\u81f4\u7684\u6846\u67b6\u3002"}}
{"id": "2510.22052", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.22052", "abs": "https://arxiv.org/abs/2510.22052", "authors": ["Abhijit Chatterjee", "Niraj K. Jha", "Jonathan D. Cohen", "Thomas L. Griffiths", "Hongjing Lu", "Diana Marculescu", "Ashiqur Rasul", "Keshab K. Parhi"], "title": "Energy-Efficient Domain-Specific Artificial Intelligence Models and Agents: Pathways and Paradigms", "comment": null, "summary": "The field of artificial intelligence (AI) has taken a tight hold on broad\naspects of society, industry, business, and governance in ways that dictate the\nprosperity and might of the world's economies. The AI market size is projected\nto grow from 189 billion USD in 2023 to 4.8 trillion USD by 2033. Currently, AI\nis dominated by large language models that exhibit linguistic and visual\nintelligence. However, training these models requires a massive amount of data\nscraped from the web as well as large amounts of energy (50--60 GWh to train\nGPT-4). Despite these costs, these models often hallucinate, a characteristic\nthat prevents them from being deployed in critical application domains. In\ncontrast, the human brain consumes only 20~W of power. What is needed is the\nnext level of AI evolution in which lightweight domain-specific multimodal\nmodels with higher levels of intelligence can reason, plan, and make decisions\nin dynamic environments with real-time data and prior knowledge, while learning\ncontinuously and evolving in ways that enhance future decision-making\ncapability. This will define the next wave of AI, progressing from today's\nlarge models, trained with vast amounts of data, to nimble energy-efficient\ndomain-specific agents that can reason and think in a world full of\nuncertainty. To support such agents, hardware will need to be reimagined to\nallow energy efficiencies greater than 1000x over the state of the art. Such a\nvision of future AI systems is developed in this work.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e0b\u4e00\u4ee3AI\u53d1\u5c55\u65b9\u5411\uff1a\u4ece\u5f53\u524d\u8017\u80fd\u5de8\u5927\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f6c\u5411\u8f7b\u91cf\u7ea7\u3001\u9886\u57df\u7279\u5b9a\u7684\u591a\u6a21\u6001\u667a\u80fd\u4f53\uff0c\u8fd9\u4e9b\u667a\u80fd\u4f53\u80fd\u591f\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8fdb\u884c\u63a8\u7406\u3001\u89c4\u5212\u548c\u51b3\u7b56\uff0c\u540c\u65f6\u5b9e\u73b0\u8d85\u8fc7\u73b0\u6709\u6280\u672f1000\u500d\u7684\u80fd\u6548\u3002", "motivation": "\u5f53\u524dAI\u6a21\u578b\uff08\u5982GPT-4\uff09\u8bad\u7ec3\u9700\u8981\u5927\u91cf\u6570\u636e\u548c\u80fd\u6e90\uff0850-60 GWh\uff09\uff0c\u4e14\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u65e0\u6cd5\u5e94\u7528\u4e8e\u5173\u952e\u9886\u57df\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u4eba\u8111\u4ec5\u6d88\u801720W\u529f\u7387\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u8282\u80fd\u3001\u66f4\u667a\u80fd\u7684AI\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u5f00\u53d1\u8f7b\u91cf\u7ea7\u9886\u57df\u7279\u5b9a\u591a\u6a21\u6001\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\uff1a1\uff09\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8fdb\u884c\u63a8\u7406\u3001\u89c4\u5212\u548c\u51b3\u7b56\uff1b2\uff09\u5904\u7406\u5b9e\u65f6\u6570\u636e\u548c\u5148\u9a8c\u77e5\u8bc6\uff1b3\uff09\u6301\u7eed\u5b66\u4e60\u5e76\u589e\u5f3a\u672a\u6765\u51b3\u7b56\u80fd\u529b\uff1b4\uff09\u91cd\u65b0\u8bbe\u8ba1\u786c\u4ef6\u4ee5\u5b9e\u73b0\u8d85\u8fc7\u73b0\u6709\u6280\u672f1000\u500d\u7684\u80fd\u6548\u3002", "result": "\u6784\u5efa\u4e86\u672a\u6765AI\u7cfb\u7edf\u7684\u613f\u666f\u6846\u67b6\uff0c\u4ece\u5f53\u524d\u57fa\u4e8e\u6d77\u91cf\u6570\u636e\u8bad\u7ec3\u7684\u5927\u578b\u6a21\u578b\u8f6c\u5411\u80fd\u591f\u5728\u4e0d\u7a33\u5b9a\u4e16\u754c\u4e2d\u601d\u8003\u548c\u63a8\u7406\u7684\u8282\u80fd\u9886\u57df\u7279\u5b9a\u667a\u80fd\u4f53\u3002", "conclusion": "\u4e0b\u4e00\u4ee3AI\u9700\u8981\u5b9e\u73b0\u4ece\u5927\u578b\u901a\u7528\u6a21\u578b\u5230\u8282\u80fd\u3001\u9886\u57df\u7279\u5b9a\u667a\u80fd\u4f53\u7684\u8f6c\u53d8\uff0c\u8fd9\u9700\u8981\u786c\u4ef6\u548c\u7b97\u6cd5\u7684\u534f\u540c\u521b\u65b0\uff0c\u4ee5\u5b9e\u73b0\u8d85\u8fc71000\u500d\u7684\u80fd\u6548\u63d0\u5347\uff0c\u4ece\u800c\u63a8\u52a8AI\u5728\u5173\u952e\u5e94\u7528\u9886\u57df\u7684\u90e8\u7f72\u3002"}}
{"id": "2510.22871", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.22871", "abs": "https://arxiv.org/abs/2510.22871", "authors": ["Shuang Gao", "Peter E. Caines"], "title": "Transmission Neural Networks: Approximate Receding Horizon Control for Virus Spread on Networks", "comment": null, "summary": "Transmission Neural Networks (TransNNs) proposed by Gao and Caines (2022)\nserve as both virus spread models over networks and neural network models with\ntuneable activation functions. This paper establishes that TransNNs provide\nupper bounds on the infection probability generated from the associated\nMarkovian stochastic Susceptible-Infected-Susceptible (SIS) model with 2^n\nstate configurations where n is the number of nodes in the network, and can be\nemployed as an approximate model for the latter. Based on such an\napproximation, a TransNN-based receding horizon control approach for mitigating\nvirus spread is proposed and we demonstrate that it allows significant\ncomputational savings compared to the dynamic programming solution to Markovian\nSIS model with 2^n state configurations, as well as providing less conservative\ncontrol actions compared to the TransNN-based optimal control. Finally,\nnumerical comparisons among (a) dynamic programming solutions for the Markovian\nSIS model, (b) TransNN-based optimal control and (c) the proposed TransNN-based\nreceding horizon control are presented.", "AI": {"tldr": "TransNNs\u4f5c\u4e3a\u75c5\u6bd2\u4f20\u64ad\u6a21\u578b\u548c\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u4e3a\u9a6c\u5c14\u53ef\u592bSIS\u6a21\u578b\u63d0\u4f9b\u611f\u67d3\u6982\u7387\u4e0a\u754c\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8eTransNN\u7684\u6eda\u52a8\u65f6\u57df\u63a7\u5236\u65b9\u6cd5\uff0c\u76f8\u6bd4\u52a8\u6001\u89c4\u5212\u663e\u8457\u8282\u7701\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u9a6c\u5c14\u53ef\u592bSIS\u6a21\u578b\u5177\u67092^n\u72b6\u6001\u914d\u7f6e\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u75c5\u6bd2\u4f20\u64ad\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528TransNNs\u4f5c\u4e3a\u9a6c\u5c14\u53ef\u592bSIS\u6a21\u578b\u7684\u8fd1\u4f3c\u6a21\u578b\uff0c\u63d0\u51fa\u57fa\u4e8eTransNN\u7684\u6eda\u52a8\u65f6\u57df\u63a7\u5236\u65b9\u6cd5\u3002", "result": "TransNN\u6eda\u52a8\u65f6\u57df\u63a7\u5236\u76f8\u6bd4\u52a8\u6001\u89c4\u5212\u663e\u8457\u8282\u7701\u8ba1\u7b97\u6210\u672c\uff0c\u4e14\u6bd4TransNN\u6700\u4f18\u63a7\u5236\u63d0\u4f9b\u66f4\u4e0d\u4fdd\u5b88\u7684\u63a7\u5236\u52a8\u4f5c\u3002", "conclusion": "TransNNs\u53ef\u4f5c\u4e3a\u9a6c\u5c14\u53ef\u592bSIS\u6a21\u578b\u7684\u6709\u6548\u8fd1\u4f3c\uff0c\u57fa\u4e8eTransNN\u7684\u6eda\u52a8\u65f6\u57df\u63a7\u5236\u662f\u8ba1\u7b97\u6548\u7387\u9ad8\u4e14\u5b9e\u7528\u7684\u75c5\u6bd2\u4f20\u64ad\u63a7\u5236\u65b9\u6cd5\u3002"}}
{"id": "2510.21991", "categories": ["cs.RO", "cs.AI", "68T40, 93C85, 68T07, 68U35"], "pdf": "https://arxiv.org/pdf/2510.21991", "abs": "https://arxiv.org/abs/2510.21991", "authors": ["Mateo Clemente", "Leo Brunswic", "Rui Heng Yang", "Xuan Zhao", "Yasser Khalil", "Haoyu Lei", "Amir Rasouli", "Yinchuan Li"], "title": "Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising", "comment": "16 pages, 11 figure, 2 tables, accepted at Neurips 2025", "summary": "Diffusion models, such as diffusion policy, have achieved state-of-the-art\nresults in robotic manipulation by imitating expert demonstrations. While\ndiffusion models were originally developed for vision tasks like image and\nvideo generation, many of their inference strategies have been directly\ntransferred to control domains without adaptation. In this work, we show that\nby tailoring the denoising process to the specific characteristics of embodied\nAI tasks -- particularly structured, low-dimensional nature of action\ndistributions -- diffusion policies can operate effectively with as few as 5\nneural function evaluations (NFE).\n  Building on this insight, we propose a population-based sampling strategy,\ngenetic denoising, which enhances both performance and stability by selecting\ndenoising trajectories with low out-of-distribution risk. Our method solves\nchallenging tasks with only 2 NFE while improving or matching performance. We\nevaluate our approach across 14 robotic manipulation tasks from D4RL and\nRobomimic, spanning multiple action horizons and inference budgets. In over 2\nmillion evaluations, our method consistently outperforms standard\ndiffusion-based policies, achieving up to 20\\% performance gains with\nsignificantly fewer inference steps.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u673a\u5668\u4eba\u63a7\u5236\u4efb\u52a1\u4f18\u5316\u7684\u6269\u6563\u7b56\u7565\uff0c\u901a\u8fc7\u5b9a\u5236\u5316\u53bb\u566a\u8fc7\u7a0b\u548c\u9057\u4f20\u53bb\u566a\u91c7\u6837\u7b56\u7565\uff0c\u4ec5\u97002-5\u6b21\u795e\u7ecf\u7f51\u7edc\u8bc4\u4f30\u5373\u53ef\u9ad8\u6548\u89e3\u51b3\u590d\u6742\u4efb\u52a1\uff0c\u572814\u4e2a\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u6027\u80fd\u63d0\u5347\u8fbe20%\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u76f4\u63a5\u4ece\u89c6\u89c9\u4efb\u52a1\u8fc1\u79fb\u5230\u63a7\u5236\u9886\u57df\uff0c\u672a\u9488\u5bf9\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u52a8\u4f5c\u5206\u5e03\u7684\u7ed3\u6784\u5316\u3001\u4f4e\u7ef4\u7279\u6027\u8fdb\u884c\u4f18\u5316\uff0c\u5bfc\u81f4\u63a8\u7406\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u9057\u4f20\u53bb\u566a\u91c7\u6837\u7b56\u7565\uff0c\u901a\u8fc7\u9009\u62e9\u4f4e\u5206\u5e03\u5916\u98ce\u9669\u7684\u53bb\u566a\u8f68\u8ff9\u6765\u589e\u5f3a\u6027\u80fd\u548c\u7a33\u5b9a\u6027\uff1b\u9488\u5bf9\u5177\u4f53\u4efb\u52a1\u7279\u6027\u5b9a\u5236\u53bb\u566a\u8fc7\u7a0b\u3002", "result": "\u5728D4RL\u548cRobomimic\u768414\u4e2a\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\uff0c\u4ec5\u75282\u6b21\u795e\u7ecf\u7f51\u7edc\u8bc4\u4f30\u5373\u53ef\u89e3\u51b3\u6311\u6218\u6027\u4efb\u52a1\uff0c\u6027\u80fd\u63d0\u5347\u8fbe20%\uff0c\u5728200\u4e07\u6b21\u8bc4\u4f30\u4e2d\u6301\u7eed\u4f18\u4e8e\u6807\u51c6\u6269\u6563\u7b56\u7565\u3002", "conclusion": "\u901a\u8fc7\u9488\u5bf9\u5177\u4f53\u4efb\u52a1\u7279\u6027\u4f18\u5316\u6269\u6563\u7b56\u7565\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u63a8\u7406\u6548\u7387\uff0c\u5728\u5c11\u91cf\u795e\u7ecf\u7f51\u7edc\u8bc4\u4f30\u4e0b\u5b9e\u73b0\u4f18\u5f02\u6027\u80fd\u3002"}}
{"id": "2510.22095", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.22095", "abs": "https://arxiv.org/abs/2510.22095", "authors": ["Yankai Chen", "Xinni Zhang", "Yifei Zhang", "Yangning Li", "Henry Peng Zou", "Chunyu Miao", "Weizhi Zhang", "Xue Liu", "Philip S. Yu"], "title": "Embracing Trustworthy Brain-Agent Collaboration as Paradigm Extension for Intelligent Assistive Technologies", "comment": "Accepted by NeurIPS'25 Position Track", "summary": "Brain-Computer Interfaces (BCIs) offer a direct communication pathway between\nthe human brain and external devices, holding significant promise for\nindividuals with severe neurological impairments. However, their widespread\nadoption is hindered by critical limitations, such as low information transfer\nrates and extensive user-specific calibration. To overcome these challenges,\nrecent research has explored the integration of Large Language Models (LLMs),\nextending the focus from simple command decoding to understanding complex\ncognitive states. Despite these advancements, deploying agentic AI faces\ntechnical hurdles and ethical concerns. Due to the lack of comprehensive\ndiscussion on this emerging direction, this position paper argues that the\nfield is poised for a paradigm extension from BCI to Brain-Agent Collaboration\n(BAC). We emphasize reframing agents as active and collaborative partners for\nintelligent assistance rather than passive brain signal data processors,\ndemanding a focus on ethical data handling, model reliability, and a robust\nhuman-agent collaboration framework to ensure these systems are safe,\ntrustworthy, and effective.", "AI": {"tldr": "\u8be5\u7acb\u573a\u8bba\u6587\u4e3b\u5f20\u4ece\u8111\u673a\u63a5\u53e3(BCI)\u6269\u5c55\u5230\u8111-\u667a\u80fd\u4f53\u534f\u4f5c(BAC)\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u5f3a\u8c03\u5c06\u667a\u80fd\u4f53\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4e3b\u52a8\u534f\u4f5c\u4f19\u4f34\u800c\u975e\u88ab\u52a8\u8111\u4fe1\u53f7\u5904\u7406\u5668\uff0c\u5e76\u5173\u6ce8\u4f26\u7406\u6570\u636e\u7ba1\u7406\u3001\u6a21\u578b\u53ef\u9760\u6027\u548c\u4eba-\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\u3002", "motivation": "\u8111\u673a\u63a5\u53e3\u5b58\u5728\u4fe1\u606f\u4f20\u8f93\u7387\u4f4e\u548c\u7528\u6237\u7279\u5b9a\u6821\u51c6\u7e41\u7410\u7b49\u9650\u5236\uff0c\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u96c6\u6210\u6709\u6240\u8fdb\u5c55\uff0c\u4f46\u90e8\u7f72\u4ee3\u7406AI\u9762\u4e34\u6280\u672f\u969c\u788d\u548c\u4f26\u7406\u62c5\u5fe7\uff0c\u9700\u8981\u5bf9\u6b64\u65b0\u5174\u65b9\u5411\u8fdb\u884c\u7efc\u5408\u8ba8\u8bba\u3002", "method": "\u63d0\u51fa\u4eceBCI\u5230BAC\u7684\u8303\u5f0f\u6269\u5c55\uff0c\u5c06\u667a\u80fd\u4f53\u91cd\u65b0\u5b9a\u4f4d\u4e3a\u4e3b\u52a8\u534f\u4f5c\u4f19\u4f34\uff0c\u8981\u6c42\u5173\u6ce8\u4f26\u7406\u6570\u636e\u7ba1\u7406\u3001\u6a21\u578b\u53ef\u9760\u6027\u548c\u4eba-\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\u3002", "result": "\u786e\u7acb\u4e86\u8111-\u667a\u80fd\u4f53\u534f\u4f5c(BAC)\u4f5c\u4e3a\u65b0\u7684\u7814\u7a76\u8303\u5f0f\uff0c\u5f3a\u8c03\u667a\u80fd\u4f53\u5e94\u4f5c\u4e3a\u4e3b\u52a8\u534f\u4f5c\u4f19\u4f34\u800c\u975e\u88ab\u52a8\u5904\u7406\u5668\u3002", "conclusion": "\u8111\u673a\u63a5\u53e3\u9886\u57df\u9700\u8981\u8fdb\u884c\u4eceBCI\u5230BAC\u7684\u8303\u5f0f\u6269\u5c55\uff0c\u786e\u4fdd\u8fd9\u4e9b\u7cfb\u7edf\u5b89\u5168\u3001\u53ef\u4fe1\u4e14\u6709\u6548\uff0c\u9700\u8981\u91cd\u70b9\u5173\u6ce8\u4f26\u7406\u6570\u636e\u7ba1\u7406\u3001\u6a21\u578b\u53ef\u9760\u6027\u548c\u4eba-\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\u3002"}}
{"id": "2510.23067", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.23067", "abs": "https://arxiv.org/abs/2510.23067", "authors": ["Sangmin Kim", "Taehun Kim", "Guntae Kim", "Chang Mook Kang"], "title": "NeuroDOB: A Deep Neural Observer-Based Controller for Vehicle Lateral Dynamics", "comment": "12 pages, 16 figures", "summary": "This paper proposes NeuroDOB, a deep neural network based observer controller\nfor vehicle lateral dynamics, which replaces the conventional disturbance\nobserver (DOB) with a deep neural network (DNN) to enhance personalized lateral\ncontrol. Unlike conventional DOBs that compensate for general disturbances such\nas road friction variation and crosswind, NeuroDOB explicitly addresses\nunmodeled vehicle dynamics and driver-specific behaviors by learning the\nsteering compensation signal from driver-in-the-loop simulations using CarSim's\nembedded controller as a surrogate driver. The proposed architecture integrates\nNeuroDOB with a linear quadratic regulator (LQR), where the DNN outputs a delta\nerror correction added to the baseline LQR steering input to produce the final\ncontrol command. Input features to the DNN include lateral position and yaw\nangle errors, and the LQR control input. Experimental validation using a\nlateral dynamic bicycle model within CarSim demonstrates that NeuroDOB\neffectively adapts to individual driving habits, improving lateral control\nperformance beyond what conventional LQR controllers achieve. The results\nindicate the potential of deep neural network based observer to enable\npersonalized and adaptive autonomous vehicle control. In cognitive terms, the\nproposed architecture can be viewed as a dual-system control structure. The\nbaseline LQR corresponds to System 1, a model-based, fast, and analytic\nreasoning layer ensuring stability. The NeuroDOB acts as System 2, a\nreflective, data-driven layer that learns compensation from experience and\ncorrects the analytical bias of System 1. Together, they form an integrated\ndecision process analogous to human intuition-reflection interaction, enabling\nboth stability and adaptability in lateral control.", "AI": {"tldr": "\u63d0\u51faNeuroDOB\uff0c\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8f66\u8f86\u6a2a\u5411\u52a8\u529b\u5b66\u89c2\u6d4b\u63a7\u5236\u5668\uff0c\u7528DNN\u66ff\u4ee3\u4f20\u7edf\u6270\u52a8\u89c2\u6d4b\u5668\u6765\u5b9e\u73b0\u4e2a\u6027\u5316\u6a2a\u5411\u63a7\u5236\uff0c\u901a\u8fc7\u4ece\u9a7e\u9a76\u5458\u5728\u73af\u4eff\u771f\u4e2d\u5b66\u4e60\u8f6c\u5411\u8865\u507f\u4fe1\u53f7\u6765\u9002\u5e94\u672a\u5efa\u6a21\u8f66\u8f86\u52a8\u6001\u548c\u9a7e\u9a76\u5458\u7279\u5b9a\u884c\u4e3a\u3002", "motivation": "\u4f20\u7edf\u6270\u52a8\u89c2\u6d4b\u5668\u4e3b\u8981\u8865\u507f\u4e00\u822c\u6270\u52a8\u5982\u8def\u9762\u6469\u64e6\u53d8\u5316\u548c\u4fa7\u98ce\uff0c\u4f46\u65e0\u6cd5\u5904\u7406\u672a\u5efa\u6a21\u8f66\u8f86\u52a8\u6001\u548c\u9a7e\u9a76\u5458\u7279\u5b9a\u884c\u4e3a\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5b66\u4e60\u4e2a\u6027\u5316\u9a7e\u9a76\u4e60\u60ef\u7684\u63a7\u5236\u5668\u6765\u63d0\u5347\u6a2a\u5411\u63a7\u5236\u6027\u80fd\u3002", "method": "\u5c06NeuroDOB\u4e0e\u7ebf\u6027\u4e8c\u6b21\u8c03\u8282\u5668(LQR)\u96c6\u6210\uff0cDNN\u8f93\u51fa\u8bef\u5dee\u4fee\u6b63\u91cf\u52a0\u5230\u57fa\u7ebfLQR\u8f6c\u5411\u8f93\u5165\u4e2d\u3002DNN\u8f93\u5165\u7279\u5f81\u5305\u62ec\u6a2a\u5411\u4f4d\u7f6e\u548c\u504f\u822a\u89d2\u8bef\u5dee\uff0c\u4ee5\u53caLQR\u63a7\u5236\u8f93\u5165\u3002\u901a\u8fc7CarSim\u4e2d\u7684\u9a7e\u9a76\u5458\u5728\u73af\u4eff\u771f\u8bad\u7ec3DNN\u3002", "result": "\u5728CarSim\u4e2d\u4f7f\u7528\u6a2a\u5411\u52a8\u6001\u81ea\u884c\u8f66\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0cNeuroDOB\u80fd\u6709\u6548\u9002\u5e94\u4e2a\u4f53\u9a7e\u9a76\u4e60\u60ef\uff0c\u76f8\u6bd4\u4f20\u7edfLQR\u63a7\u5236\u5668\u663e\u8457\u63d0\u5347\u6a2a\u5411\u63a7\u5236\u6027\u80fd\u3002", "conclusion": "\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u89c2\u6d4b\u5668\u5177\u6709\u5b9e\u73b0\u4e2a\u6027\u5316\u548c\u81ea\u9002\u5e94\u81ea\u52a8\u9a7e\u9a76\u63a7\u5236\u7684\u6f5c\u529b\u3002\u8be5\u67b6\u6784\u53ef\u89c6\u4e3a\u53cc\u7cfb\u7edf\u63a7\u5236\u7ed3\u6784\uff1aLQR\u4f5c\u4e3a\u7cfb\u7edf1\uff08\u6a21\u578b\u57fa\u7840\u3001\u5feb\u901f\u5206\u6790\u5c42\uff09\uff0cNeuroDOB\u4f5c\u4e3a\u7cfb\u7edf2\uff08\u53cd\u601d\u6027\u3001\u6570\u636e\u9a71\u52a8\u5c42\uff09\uff0c\u7c7b\u4f3c\u4eba\u7c7b\u76f4\u89c9-\u53cd\u601d\u4ea4\u4e92\uff0c\u5b9e\u73b0\u7a33\u5b9a\u6027\u548c\u9002\u5e94\u6027\u7684\u5e73\u8861\u3002"}}
{"id": "2510.22030", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22030", "abs": "https://arxiv.org/abs/2510.22030", "authors": ["Harsha Karunanayaka", "Siavash Rezazadeh"], "title": "Estimation of Minimum Stride Frequency for the Frontal Plane Stability of Bipedal Systems", "comment": null, "summary": "Stability of bipedal systems in frontal plane is affected by the hip offset,\nto the extent that adjusting stride time using feedforward retraction and\nextension of the legs can lead to stable oscillations without feedback control.\nThis feedforward stabilization can be leveraged to reduce the control effort\nand energy expenditure and increase the locomotion robustness. However, there\nis limited understanding of how key parameters, such as mass, stiffness, leg\nlength, and hip width, affect stability and the minimum stride frequency needed\nto maintain it. This study aims to address these gaps through analyzing how\nindividual model parameters and the system's natural frequency influence the\nminimum stride frequency required to maintain a stable cycle. We propose a\nmethod to predict the minimum stride frequency, and compare the predicted\nstride frequencies with actual values for randomly generated models. The\nfindings of this work provide a better understanding of the frontal plane\nstability mechanisms and how feedforward stabilization can be leveraged to\nreduce the control effort.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u53cc\u8db3\u7cfb\u7edf\u5728\u989d\u72b6\u9762\u7684\u7a33\u5b9a\u6027\u673a\u5236\uff0c\u53d1\u73b0\u901a\u8fc7\u8c03\u6574\u6b65\u9891\u53ef\u4ee5\u5b9e\u73b0\u65e0\u9700\u53cd\u9988\u63a7\u5236\u7684\u524d\u9988\u7a33\u5b9a\uff0c\u5e76\u63d0\u51fa\u4e86\u9884\u6d4b\u6700\u5c0f\u6b65\u9891\u7684\u65b9\u6cd5\u3002", "motivation": "\u76ee\u524d\u5bf9\u53cc\u8db3\u7cfb\u7edf\u989d\u72b6\u9762\u7a33\u5b9a\u6027\u7684\u5173\u952e\u53c2\u6570\uff08\u5982\u8d28\u91cf\u3001\u521a\u5ea6\u3001\u817f\u957f\u548c\u9acb\u5bbd\uff09\u5982\u4f55\u5f71\u54cd\u7a33\u5b9a\u6027\u548c\u7ef4\u6301\u7a33\u5b9a\u6240\u9700\u7684\u6700\u5c0f\u6b65\u9891\u7406\u89e3\u6709\u9650\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4e2a\u4f53\u6a21\u578b\u53c2\u6570\u548c\u7cfb\u7edf\u81ea\u7136\u9891\u7387\u5bf9\u6700\u5c0f\u6b65\u9891\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u9884\u6d4b\u6700\u5c0f\u6b65\u9891\u7684\u65b9\u6cd5\uff0c\u5e76\u4e0e\u968f\u673a\u751f\u6210\u6a21\u578b\u7684\u5b9e\u9645\u503c\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63d0\u4f9b\u4e86\u5bf9\u989d\u72b6\u9762\u7a33\u5b9a\u6027\u673a\u5236\u7684\u66f4\u597d\u7406\u89e3\uff0c\u4ee5\u53ca\u5982\u4f55\u5229\u7528\u524d\u9988\u7a33\u5b9a\u6765\u51cf\u5c11\u63a7\u5236\u52aa\u529b\u3002", "conclusion": "\u524d\u9988\u7a33\u5b9a\u53ef\u4ee5\u964d\u4f4e\u63a7\u5236\u52aa\u529b\u548c\u80fd\u91cf\u6d88\u8017\uff0c\u63d0\u9ad8\u8fd0\u52a8\u9c81\u68d2\u6027\uff0c\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u53cc\u8db3\u7cfb\u7edf\u7a33\u5b9a\u6027\u673a\u5236\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2510.22132", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22132", "abs": "https://arxiv.org/abs/2510.22132", "authors": ["Xuying LI"], "title": "Controllable Mathematical Reasoning via Self-Optimizing Thought Vectors", "comment": null, "summary": "We present a novel approach for controllable mathematical reasoning that\nleverages self-optimizing thought vectors with entropy minimization. Our method\nintroduces learnable thought vectors that dynamically modulate the internal\nreasoning process of large language models. Using Gemma-2-9B on GSM8K, we\nachieve 90.1% accuracy with a controllability score of 0.42, demonstrating that\nentropy-based rewards effectively guide focused reasoning patterns without\nrequiring external reward annotations. Our analysis reveals distinct thought\nvector clusters and consistent low-entropy distributions across control\nconditions, validating our framework for controllable AI reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u4f18\u5316\u601d\u7ef4\u5411\u91cf\u548c\u71b5\u6700\u5c0f\u5316\u7684\u53ef\u63a7\u6570\u5b66\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u601d\u7ef4\u5411\u91cf\u52a8\u6001\u8c03\u5236\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u7f3a\u4e4f\u53ef\u63a7\u6027\u7684\u95ee\u9898\uff0c\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u5f15\u5bfc\u63a8\u7406\u8fc7\u7a0b\u7684\u65b9\u6cd5\uff0c\u800c\u4e0d\u9700\u8981\u5916\u90e8\u5956\u52b1\u6807\u6ce8\u3002", "method": "\u4f7f\u7528\u53ef\u5b66\u4e60\u7684\u601d\u7ef4\u5411\u91cf\u52a8\u6001\u8c03\u5236\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\uff0c\u901a\u8fc7\u71b5\u6700\u5c0f\u5316\u5956\u52b1\u6765\u5f15\u5bfc\u805a\u7126\u63a8\u7406\u6a21\u5f0f\u3002", "result": "\u5728GSM8K\u6570\u636e\u96c6\u4e0a\u4f7f\u7528Gemma-2-9B\u6a21\u578b\u8fbe\u5230\u4e8690.1%\u7684\u51c6\u786e\u7387\uff0c\u53ef\u63a7\u6027\u5f97\u5206\u4e3a0.42\uff0c\u601d\u7ef4\u5411\u91cf\u5f62\u6210\u4e86\u660e\u663e\u7684\u805a\u7c7b\uff0c\u63a7\u5236\u6761\u4ef6\u4e0b\u5448\u73b0\u4e00\u81f4\u7684\u4f4e\u71b5\u5206\u5e03\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u71b5\u6700\u5c0f\u5316\u6709\u6548\u5b9e\u73b0\u4e86\u53ef\u63a7AI\u63a8\u7406\uff0c\u9a8c\u8bc1\u4e86\u601d\u7ef4\u5411\u91cf\u5728\u5f15\u5bfc\u63a8\u7406\u6a21\u5f0f\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.23125", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.23125", "abs": "https://arxiv.org/abs/2510.23125", "authors": ["David E. Ruiz-Guirola", "Prasoon Raghuwanshi", "Gabriel M. de Jesus", "Mateen Ashraf", "Onel L. A. L\u00f3pez"], "title": "Context-awareness for Dependable Low-Power IoT", "comment": null, "summary": "Dependability is the ability to consistently deliver trusted and\nuninterrupted service in the face of operational uncertainties. Ensuring\ndependable operation in large-scale, energy-constrained Internet of Things\n(IoT) deployments is as crucial as challenging, and calls for context-aware\nprotocols where context refers to situational or state information. In this\npaper, we identify four critical context dimensions for IoT networks, namely\nenergy status, information freshness, task relevance, and physical/medium\nconditions, and show how each one underpins core dependability attributes.\nBuilding on these insights, we propose a two-step protocol design framework\nthat incorporates operation-specific context fields. Through three\nrepresentative use cases, we demonstrate how context awareness can\nsignificantly enhance system dependability while imposing only minimal\ncontrol-plane overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5305\u542b\u56db\u4e2a\u5173\u952e\u4e0a\u4e0b\u6587\u7ef4\u5ea6\u7684\u4e24\u6b65\u534f\u8bae\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u663e\u8457\u63d0\u5347\u7269\u8054\u7f51\u7cfb\u7edf\u53ef\u9760\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u5c0f\u63a7\u5236\u5f00\u9500", "motivation": "\u5728\u5927\u89c4\u6a21\u3001\u80fd\u6e90\u53d7\u9650\u7684\u7269\u8054\u7f51\u90e8\u7f72\u4e2d\u786e\u4fdd\u53ef\u9760\u8fd0\u884c\u81f3\u5173\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u80fd\u591f\u611f\u77e5\u4e0a\u4e0b\u6587\uff08\u60c5\u5883\u6216\u72b6\u6001\u4fe1\u606f\uff09\u7684\u534f\u8bae", "method": "\u8bc6\u522b\u56db\u4e2a\u5173\u952e\u4e0a\u4e0b\u6587\u7ef4\u5ea6\uff08\u80fd\u91cf\u72b6\u6001\u3001\u4fe1\u606f\u65b0\u9c9c\u5ea6\u3001\u4efb\u52a1\u76f8\u5173\u6027\u548c\u7269\u7406/\u4ecb\u8d28\u6761\u4ef6\uff09\uff0c\u63d0\u51fa\u5305\u542b\u64cd\u4f5c\u7279\u5b9a\u4e0a\u4e0b\u6587\u5b57\u6bb5\u7684\u4e24\u6b65\u534f\u8bae\u8bbe\u8ba1\u6846\u67b6", "result": "\u901a\u8fc7\u4e09\u4e2a\u4ee3\u8868\u6027\u7528\u4f8b\u8bc1\u660e\u4e0a\u4e0b\u6587\u611f\u77e5\u53ef\u4ee5\u663e\u8457\u589e\u5f3a\u7cfb\u7edf\u53ef\u9760\u6027\uff0c\u540c\u65f6\u53ea\u65bd\u52a0\u6700\u5c0f\u7684\u63a7\u5236\u5e73\u9762\u5f00\u9500", "conclusion": "\u4e0a\u4e0b\u6587\u611f\u77e5\u662f\u63d0\u5347\u7269\u8054\u7f51\u7f51\u7edc\u53ef\u9760\u6027\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u5e73\u8861\u7cfb\u7edf\u6027\u80fd\u548c\u8d44\u6e90\u7ea6\u675f"}}
{"id": "2510.22113", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.22113", "abs": "https://arxiv.org/abs/2510.22113", "authors": ["Zitiantao Lin", "Yongpeng Sang", "Yang Ye"], "title": "RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation", "comment": "5 pages, 5 figures; Accepted to: 2025 IEEE 4th International\n  Conference on Intelligent Reality (ICIR 2025); Zitiantao Lin and Yongpeng\n  Sang contributed equally to this work (co-first authors). Corresponding\n  author: Yang Ye (y.ye@northeastern.edu)", "summary": "Robotic manipulators are increasingly used to assist individuals with\nmobility impairments in object retrieval. However, the predominant\njoystick-based control interfaces can be challenging due to high precision\nrequirements and unintuitive reference frames. Recent advances in human-robot\ninteraction have explored alternative modalities, yet many solutions still rely\non external screens or restrictive control schemes, limiting their\nintuitiveness and accessibility. To address these challenges, we present an\negocentric, gaze-guided robotic manipulation interface that leverages a\nwearable Mixed Reality (MR) headset. Our system enables users to interact\nseamlessly with real-world objects using natural gaze fixation from a\nfirst-person perspective, while providing augmented visual cues to confirm\nintent and leveraging a pretrained vision model and robotic arm for intent\nrecognition and object manipulation. Experimental results demonstrate that our\napproach significantly improves manipulation accuracy, reduces system latency,\nand achieves single-pass intention and object recognition accuracy greater than\n88% across multiple real-world scenarios. These results demonstrate the\nsystem's effectiveness in enhancing intuitiveness and accessibility,\nunderscoring its practical significance for assistive robotics applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u73b0\u5b9e\u5934\u663e\u7684\u4ee5\u81ea\u6211\u4e3a\u4e2d\u5fc3\u7684\u6ce8\u89c6\u5f15\u5bfc\u673a\u5668\u4eba\u64cd\u7eb5\u754c\u9762\uff0c\u901a\u8fc7\u81ea\u7136\u6ce8\u89c6\u56fa\u5b9a\u548c\u589e\u5f3a\u89c6\u89c9\u63d0\u793a\u6765\u6539\u5584\u8f85\u52a9\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u76f4\u89c2\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u3002", "motivation": "\u4f20\u7edf\u64cd\u7eb5\u6746\u63a7\u5236\u754c\u9762\u7cbe\u5ea6\u8981\u6c42\u9ad8\u4e14\u53c2\u8003\u6846\u67b6\u4e0d\u76f4\u89c2\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u4f9d\u8d56\u5916\u90e8\u5c4f\u5e55\u6216\u9650\u5236\u6027\u63a7\u5236\u65b9\u6848\uff0c\u9650\u5236\u4e86\u76f4\u89c2\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u3002", "method": "\u5229\u7528\u53ef\u7a7f\u6234\u6df7\u5408\u73b0\u5b9e\u5934\u663e\uff0c\u4ece\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u901a\u8fc7\u81ea\u7136\u6ce8\u89c6\u56fa\u5b9a\u4e0e\u73b0\u5b9e\u4e16\u754c\u5bf9\u8c61\u4ea4\u4e92\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u89c6\u89c9\u6a21\u578b\u548c\u673a\u5668\u4eba\u624b\u81c2\u8fdb\u884c\u610f\u56fe\u8bc6\u522b\u548c\u5bf9\u8c61\u64cd\u7eb5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u64cd\u7eb5\u7cbe\u5ea6\uff0c\u964d\u4f4e\u4e86\u7cfb\u7edf\u5ef6\u8fdf\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u8d85\u8fc788%\u7684\u5355\u6b21\u610f\u56fe\u548c\u5bf9\u8c61\u8bc6\u522b\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6709\u6548\u589e\u5f3a\u4e86\u8f85\u52a9\u673a\u5668\u4eba\u5e94\u7528\u7684\u76f4\u89c2\u6027\u548c\u53ef\u8bbf\u95ee\u6027\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u610f\u4e49\u3002"}}
{"id": "2510.22170", "categories": ["cs.AI", "I.2.7; I.2.6; H.1.2; J.4"], "pdf": "https://arxiv.org/pdf/2510.22170", "abs": "https://arxiv.org/abs/2510.22170", "authors": ["Alexandra Yost", "Shreyans Jain", "Shivam Raval", "Grant Corser", "Allen Roush", "Nina Xu", "Jacqueline Hammack", "Ravid Shwartz-Ziv", "Amirali Abdullah"], "title": "Measure what Matters: Psychometric Evaluation of AI with Situational Judgment Tests", "comment": "49 pages", "summary": "AI psychometrics evaluates AI systems in roles that traditionally require\nemotional judgment and ethical consideration. Prior work often reuses human\ntrait inventories (Big Five, \\hexaco) or ad hoc personas, limiting behavioral\nrealism and domain relevance. We propose a framework that (1) uses situational\njudgment tests (SJTs) from realistic scenarios to probe domain-specific\ncompetencies; (2) integrates industrial-organizational and personality\npsychology to design sophisticated personas which include behavioral and\npsychological descriptors, life history, and social and emotional functions;\nand (3) employs structured generation with population demographic priors and\nmemoir inspired narratives, encoded with Pydantic schemas. In a law enforcement\nassistant case study, we construct a rich dataset of personas drawn across 8\npersona archetypes and SJTs across 11 attributes, and analyze behaviors across\nsubpopulation and scenario slices. The dataset spans 8,500 personas, 4,000\nSJTs, and 300,000 responses. We will release the dataset and all code to the\npublic.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2aAI\u5fc3\u7406\u6d4b\u91cf\u6846\u67b6\uff0c\u4f7f\u7528\u60c5\u5883\u5224\u65ad\u6d4b\u8bd5\u548c\u590d\u6742\u4eba\u8bbe\u8bbe\u8ba1\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u5728\u9700\u8981\u60c5\u611f\u5224\u65ad\u548c\u4f26\u7406\u8003\u91cf\u7684\u89d2\u8272\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5728\u6267\u6cd5\u52a9\u624b\u6848\u4f8b\u4e2d\u6784\u5efa\u4e86\u5305\u542b8500\u4e2a\u4eba\u8bbe\u30014000\u4e2aSJT\u548c30\u4e07\u4e2a\u54cd\u5e94\u7684\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u6709\u7684AI\u5fc3\u7406\u6d4b\u91cf\u65b9\u6cd5\u901a\u5e38\u91cd\u7528\u4eba\u7c7b\u7279\u8d28\u6e05\u5355\u6216\u4e34\u65f6\u4eba\u8bbe\uff0c\u9650\u5236\u4e86\u884c\u4e3a\u771f\u5b9e\u6027\u548c\u9886\u57df\u76f8\u5173\u6027\uff0c\u9700\u8981\u66f4\u73b0\u5b9e\u548c\u9886\u57df\u7279\u5b9a\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u90e8\u5206\uff1a(1)\u4f7f\u7528\u73b0\u5b9e\u573a\u666f\u7684\u60c5\u5883\u5224\u65ad\u6d4b\u8bd5\u63a2\u6d4b\u9886\u57df\u7279\u5b9a\u80fd\u529b\uff1b(2)\u6574\u5408\u5de5\u4e1a\u7ec4\u7ec7\u5fc3\u7406\u5b66\u548c\u4eba\u683c\u5fc3\u7406\u5b66\u8bbe\u8ba1\u590d\u6742\u4eba\u8bbe\uff1b(3)\u91c7\u7528\u7ed3\u6784\u5316\u751f\u6210\u65b9\u6cd5\uff0c\u5305\u542b\u4eba\u53e3\u7edf\u8ba1\u5148\u9a8c\u548c\u56de\u5fc6\u5f55\u5f0f\u53d9\u4e8b\u3002", "result": "\u5728\u6267\u6cd5\u52a9\u624b\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u6784\u5efa\u4e86\u6db5\u76d68\u4e2a\u4eba\u8bbe\u539f\u578b\u548c11\u4e2a\u5c5e\u6027\u7684\u4e30\u5bcc\u6570\u636e\u96c6\uff0c\u5305\u542b8500\u4e2a\u4eba\u8bbe\u30014000\u4e2aSJT\u548c30\u4e07\u4e2a\u54cd\u5e94\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u66f4\u73b0\u5b9e\u548c\u9886\u57df\u76f8\u5173\u7684AI\u5fc3\u7406\u6d4b\u91cf\u65b9\u6cd5\uff0c\u5e76\u5c06\u516c\u5f00\u53d1\u5e03\u6570\u636e\u96c6\u548c\u4ee3\u7801\u3002"}}
{"id": "2510.23188", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.23188", "abs": "https://arxiv.org/abs/2510.23188", "authors": ["Yuki Ota", "Yuki Funabora"], "title": "Embroidery Actuator Utilizing Embroidery Patterns to Generate Diverse Fabric Deformations", "comment": "8 pages, 8 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "This paper presents a novel Embroidery Actuator, a fabric-integrated\npneumatic actuator that enables diverse and controllable deformations through\nembroidery pattern design. Unlike conventional fabric actuators that rely on\nfiber- or thread-shaped actuators, the proposed actuator is fabricated by\ndirectly stitching an inflatable tube onto the fabric using a cord-embroidery\ntechnique. The embroidered thread and the fabric jointly form a sleeve that\nconstrains the expansion of the inflatable tube, converting internal pressure\ninto targeted bending or stretching deformations. By varying the embroidery\npattern, such as zigzag or cross configurations, different geometric\nconstraints can be realized, allowing for flexible control of deformation\ndirection and magnitude. Analytical deformation models based on the Neo-Hookean\nmodel and Lagrange's equations were developed to predict the relationship\nbetween pneumatic pressure and bending angle, and were experimentally validated\nusing motion-capture measurements. The results demonstrated that the actuator\nachieves strong agreement with the analytical deformation model.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u523a\u7ee3\u81f4\u52a8\u5668\uff0c\u901a\u8fc7\u523a\u7ee3\u56fe\u6848\u8bbe\u8ba1\u5b9e\u73b0\u591a\u6837\u53ef\u63a7\u7684\u7ec7\u7269\u53d8\u5f62\uff0c\u5c06\u5145\u6c14\u7ba1\u76f4\u63a5\u7f1d\u5236\u5728\u7ec7\u7269\u4e0a\u5f62\u6210\u7ea6\u675f\u5957\u7b52\uff0c\u5c06\u5185\u90e8\u538b\u529b\u8f6c\u5316\u4e3a\u5f2f\u66f2\u6216\u62c9\u4f38\u53d8\u5f62\u3002", "motivation": "\u4f20\u7edf\u7ec7\u7269\u81f4\u52a8\u5668\u4f9d\u8d56\u7ea4\u7ef4\u6216\u7ebf\u72b6\u81f4\u52a8\u5668\uff0c\u9650\u5236\u4e86\u53d8\u5f62\u63a7\u5236\u7684\u7075\u6d3b\u6027\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u523a\u7ee3\u56fe\u6848\u8bbe\u8ba1\u5b9e\u73b0\u66f4\u7075\u6d3b\u53ef\u63a7\u7684\u7ec7\u7269\u53d8\u5f62\u3002", "method": "\u91c7\u7528\u7ef3\u7ee3\u6280\u672f\u5c06\u5145\u6c14\u7ba1\u76f4\u63a5\u7f1d\u5236\u5728\u7ec7\u7269\u4e0a\uff0c\u5f62\u6210\u7ea6\u675f\u5957\u7b52\u3002\u901a\u8fc7\u6539\u53d8\u523a\u7ee3\u56fe\u6848\uff08\u5982\u952f\u9f7f\u5f62\u6216\u4ea4\u53c9\u5f62\uff09\u5b9e\u73b0\u4e0d\u540c\u7684\u51e0\u4f55\u7ea6\u675f\uff0c\u5e76\u57fa\u4e8eNeo-Hookean\u6a21\u578b\u548c\u62c9\u683c\u6717\u65e5\u65b9\u7a0b\u5efa\u7acb\u53d8\u5f62\u5206\u6790\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u81f4\u52a8\u5668\u7684\u53d8\u5f62\u884c\u4e3a\u4e0e\u5206\u6790\u6a21\u578b\u9ad8\u5ea6\u4e00\u81f4\uff0c\u80fd\u591f\u901a\u8fc7\u523a\u7ee3\u56fe\u6848\u7075\u6d3b\u63a7\u5236\u53d8\u5f62\u65b9\u5411\u548c\u5e45\u5ea6\u3002", "conclusion": "\u523a\u7ee3\u81f4\u52a8\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u8fc7\u56fe\u6848\u8bbe\u8ba1\u5b9e\u73b0\u53ef\u63a7\u7ec7\u7269\u53d8\u5f62\u7684\u65b0\u65b9\u6cd5\uff0c\u4e3a\u8f6f\u4f53\u673a\u5668\u4eba\u3001\u53ef\u7a7f\u6234\u8bbe\u5907\u7b49\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2510.22126", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22126", "abs": "https://arxiv.org/abs/2510.22126", "authors": ["Guanwen Xie", "Jingzehua Xu", "Jiwei Tang", "Yubo Huang", "Shuai Zhang", "Xiaofan Li"], "title": "EasyUUV: An LLM-Enhanced Universal and Lightweight Sim-to-Real Reinforcement Learning Framework for UUV Attitude Control", "comment": "8 pages, 15 figures", "summary": "Despite recent advances in Unmanned Underwater Vehicle (UUV) attitude\ncontrol, existing methods still struggle with generalizability, robustness to\nreal-world disturbances, and efficient deployment. To address the above\nchallenges, this paper presents EasyUUV, a Large Language Model (LLM)-enhanced,\nuniversal, and lightweight simulation-to-reality reinforcement learning (RL)\nframework for robust attitude control of UUVs. EasyUUV combines parallelized RL\ntraining with a hybrid control architecture, where a learned policy outputs\nhigh-level attitude corrections executed by an adaptive S-Surface controller. A\nmultimodal LLM is further integrated to adaptively tune controller parameters\nat runtime using visual and textual feedback, enabling training-free adaptation\nto unmodeled dynamics. Also, we have developed a low-cost 6-DoF UUV platform\nand applied an RL policy trained through efficient parallelized simulation.\nExtensive simulation and real-world experiments validate the effectiveness and\noutstanding performance of EasyUUV in achieving robust and adaptive UUV\nattitude control across diverse underwater conditions. The source code is\navailable from the following website: https://360zmem.github.io/easyuuv/", "AI": {"tldr": "EasyUUV\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u7684\u8f7b\u91cf\u7ea7\u4eff\u771f\u5230\u73b0\u5b9e\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u4eba\u6c34\u4e0b\u822a\u884c\u5668\u7684\u9c81\u68d2\u59ff\u6001\u63a7\u5236\uff0c\u7ed3\u5408\u5e76\u884cRL\u8bad\u7ec3\u548c\u6df7\u5408\u63a7\u5236\u67b6\u6784\uff0c\u901a\u8fc7LLM\u81ea\u9002\u5e94\u8c03\u6574\u63a7\u5236\u5668\u53c2\u6570\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709UUV\u59ff\u6001\u63a7\u5236\u65b9\u6cd5\u5728\u6cdb\u5316\u6027\u3001\u5bf9\u73b0\u5b9e\u5e72\u6270\u7684\u9c81\u68d2\u6027\u4ee5\u53ca\u9ad8\u6548\u90e8\u7f72\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u7ed3\u5408\u5e76\u884c\u5316RL\u8bad\u7ec3\u4e0e\u6df7\u5408\u63a7\u5236\u67b6\u6784\uff0c\u5176\u4e2d\u5b66\u4e60\u7b56\u7565\u8f93\u51fa\u9ad8\u5c42\u59ff\u6001\u4fee\u6b63\uff0c\u7531\u81ea\u9002\u5e94S-Surface\u63a7\u5236\u5668\u6267\u884c\uff0c\u5e76\u96c6\u6210\u591a\u6a21\u6001LLM\u5728\u8fd0\u884c\u65f6\u4f7f\u7528\u89c6\u89c9\u548c\u6587\u672c\u53cd\u9988\u81ea\u9002\u5e94\u8c03\u6574\u63a7\u5236\u5668\u53c2\u6570\u3002", "result": "\u5e7f\u6cdb\u7684\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86EasyUUV\u5728\u4e0d\u540c\u6c34\u4e0b\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9c81\u68d2\u548c\u81ea\u9002\u5e94UUV\u59ff\u6001\u63a7\u5236\u7684\u6709\u6548\u6027\u548c\u4f18\u5f02\u6027\u80fd\u3002", "conclusion": "EasyUUV\u6846\u67b6\u5728UUV\u59ff\u6001\u63a7\u5236\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u5b9e\u73b0\u8bad\u7ec3\u514d\u8d39\u7684\u9002\u5e94\u672a\u5efa\u6a21\u52a8\u6001\uff0c\u5e76\u5f00\u53d1\u4e86\u4f4e\u6210\u672c6\u81ea\u7531\u5ea6UUV\u5e73\u53f0\u8fdb\u884c\u9a8c\u8bc1\u3002"}}
{"id": "2510.22178", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.22178", "abs": "https://arxiv.org/abs/2510.22178", "authors": ["Saranraj Nambusubramaniyan", "Shervin Safavi", "Raja Guru", "Andreas Knoblauch"], "title": "Dopamine-driven synaptic credit assignment in neural networks", "comment": null, "summary": "Solving the synaptic Credit Assignment Problem(CAP) is central to learning in\nboth biological and artificial neural systems. Finding an optimal solution for\nsynaptic CAP means setting the synaptic weights that assign credit to each\nneuron for influencing the final output and behavior of neural networks or\nanimals. Gradient-based methods solve this problem in artificial neural\nnetworks using back-propagation, however, not in the most efficient way. For\ninstance, back-propagation requires a chain of top-down gradient computations.\nThis leads to an expensive optimization process in terms of computing power and\nmemory linked with well-known weight transport and update locking problems. To\naddress these shortcomings, we take a NeuroAI approach and draw inspiration\nfrom neural Reinforcement Learning to develop a derivative-free optimizer for\ntraining neural networks, Dopamine. Dopamine is developed for Weight\nPerturbation (WP) learning that exploits stochastic updating of weights towards\noptima. It achieves this by minimizing the regret, a form of Reward Prediction\nError (RPE) between the expected outcome from the perturbed model and the\nactual outcome from the unperturbed model. We use this RPE to adjust the\nlearning rate in the network (i.e., creating an adaptive learning rate\nstrategy, similar to the role of dopamine in the brain). We tested the Dopamine\noptimizer for training multi-layered perceptrons for XOR tasks, and recurrent\nneural networks for chaotic time series forecasting. Dopamine-trained models\ndemonstrate accelerated convergence and outperform standard WP, and give\ncomparable performance to gradient-based algorithms, while consuming\nsignificantly less computation and memory. Overall, the Dopamine optimizer not\nonly finds robust solutions and comparable performance to the state-of-the-art\nMachine Learning optimizers but is also neurobiologically more plausible.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDopamine\u7684\u65e0\u5bfc\u6570\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u6743\u91cd\u6270\u52a8\u5b66\u4e60\u548c\u5956\u52b1\u9884\u6d4b\u8bef\u5dee\u6765\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff0c\u89e3\u51b3\u4e86\u53cd\u5411\u4f20\u64ad\u7684\u8ba1\u7b97\u6548\u7387\u548c\u751f\u7269\u5408\u7406\u6027\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u7a81\u89e6\u4fe1\u7528\u5206\u914d\u95ee\u9898(CAP)\u662f\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u7684\u5173\u952e\u3002\u53cd\u5411\u4f20\u64ad\u867d\u7136\u80fd\u89e3\u51b3CAP\uff0c\u4f46\u5b58\u5728\u8ba1\u7b97\u6548\u7387\u4f4e\u3001\u5185\u5b58\u6d88\u8017\u5927\u3001\u6743\u91cd\u4f20\u8f93\u548c\u66f4\u65b0\u9501\u5b9a\u7b49\u95ee\u9898\uff0c\u7f3a\u4e4f\u751f\u7269\u5408\u7406\u6027\u3002", "method": "\u91c7\u7528\u795e\u7ecfAI\u65b9\u6cd5\uff0c\u53d7\u795e\u7ecf\u5f3a\u5316\u5b66\u4e60\u542f\u53d1\uff0c\u5f00\u53d1Dopamine\u4f18\u5316\u5668\u3002\u901a\u8fc7\u6743\u91cd\u6270\u52a8\u5b66\u4e60\uff0c\u5229\u7528\u6743\u91cd\u968f\u673a\u66f4\u65b0\u6765\u5bfb\u627e\u6700\u4f18\u89e3\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u671f\u671b\u7ed3\u679c\u4e0e\u5b9e\u9645\u7ed3\u679c\u4e4b\u95f4\u7684\u5956\u52b1\u9884\u6d4b\u8bef\u5dee\u6765\u8c03\u6574\u5b66\u4e60\u7387\u3002", "result": "\u5728XOR\u4efb\u52a1\u548c\u6df7\u6c8c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0cDopamine\u8bad\u7ec3\u7684\u591a\u5c42\u611f\u77e5\u673a\u548c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u8868\u73b0\u51fa\u52a0\u901f\u6536\u655b\uff0c\u4f18\u4e8e\u6807\u51c6\u6743\u91cd\u6270\u52a8\u65b9\u6cd5\uff0c\u6027\u80fd\u4e0e\u57fa\u4e8e\u68af\u5ea6\u7684\u7b97\u6cd5\u76f8\u5f53\uff0c\u540c\u65f6\u8ba1\u7b97\u548c\u5185\u5b58\u6d88\u8017\u663e\u8457\u51cf\u5c11\u3002", "conclusion": "Dopamine\u4f18\u5316\u5668\u4e0d\u4ec5\u627e\u5230\u4e86\u7a33\u5065\u89e3\uff0c\u6027\u80fd\u4e0e\u6700\u5148\u8fdb\u7684\u673a\u5668\u5b66\u4e60\u4f18\u5316\u5668\u76f8\u5f53\uff0c\u800c\u4e14\u5728\u795e\u7ecf\u751f\u7269\u5b66\u4e0a\u66f4\u52a0\u5408\u7406\u3002"}}
{"id": "2510.23196", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.23196", "abs": "https://arxiv.org/abs/2510.23196", "authors": ["Bastien Giraud", "Rahul Nellikath", "Johanna Vorwerk", "Maad Alowaifeer", "Spyros Chatzivasileiadis"], "title": "Neural Networks for AC Optimal Power Flow: Improving Worst-Case Guarantees during Training", "comment": "Submitted to PSCC 2026 (under review)", "summary": "The AC Optimal Power Flow (AC-OPF) problem is central to power system\noperation but challenging to solve efficiently due to its nonconvex and\nnonlinear nature. Neural networks (NNs) offer fast surrogates, yet their\nblack-box behavior raises concerns about constraint violations that can\ncompromise safety. We propose a verification-informed NN framework that\nincorporates worst-case constraint violations directly into training, producing\nmodels that are both accurate and provably safer. Through post-hoc\nverification, we achieve substantial reductions in worst-case violations and,\nfor the first time, verify all operational constraints of large-scale AC-OPF\nproxies. Practical feasibility is further enhanced via restoration and\nwarm-start strategies for infeasible operating points. Experiments on systems\nranging from 57 to 793 buses demonstrate scalability, speed, and reliability,\nbridging the gap between ML acceleration and safe, real-time deployment of\nAC-OPF solutions - and paving the way toward data-driven optimal control.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9a8c\u8bc1\u611f\u77e5\u7684\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6700\u574f\u60c5\u51b5\u7ea6\u675f\u8fdd\u53cd\u76f4\u63a5\u7eb3\u5165\u8bad\u7ec3\uff0c\u4e3aAC\u6700\u4f18\u6f6e\u6d41\u95ee\u9898\u63d0\u4f9b\u65e2\u51c6\u786e\u53c8\u53ef\u8bc1\u660e\u66f4\u5b89\u5168\u7684\u4ee3\u7406\u6a21\u578b\u3002", "motivation": "AC\u6700\u4f18\u6f6e\u6d41\u95ee\u9898\u5728\u7535\u529b\u7cfb\u7edf\u8fd0\u884c\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u5176\u975e\u51f8\u548c\u975e\u7ebf\u6027\u7279\u6027\u800c\u96be\u4ee5\u9ad8\u6548\u6c42\u89e3\u3002\u867d\u7136\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u5feb\u901f\u4ee3\u7406\uff0c\u4f46\u5176\u9ed1\u76d2\u884c\u4e3a\u5f15\u53d1\u4e86\u7ea6\u675f\u8fdd\u53cd\u53ef\u80fd\u5371\u53ca\u5b89\u5168\u7684\u62c5\u5fe7\u3002", "method": "\u91c7\u7528\u9a8c\u8bc1\u611f\u77e5\u7684\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u5c06\u6700\u574f\u60c5\u51b5\u7ea6\u675f\u8fdd\u53cd\u76f4\u63a5\u6574\u5408\u5230\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u5e76\u901a\u8fc7\u540e\u9a8c\u9a8c\u8bc1\u786e\u4fdd\u6a21\u578b\u5b89\u5168\u6027\u3002\u5bf9\u4e8e\u4e0d\u53ef\u884c\u8fd0\u884c\u70b9\uff0c\u91c7\u7528\u6062\u590d\u548c\u70ed\u542f\u52a8\u7b56\u7565\u589e\u5f3a\u5b9e\u7528\u6027\u3002", "result": "\u572857\u5230793\u603b\u7ebf\u7684\u7cfb\u7edf\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u574f\u60c5\u51b5\u7ea6\u675f\u8fdd\u53cd\u7684\u5927\u5e45\u51cf\u5c11\uff0c\u9996\u6b21\u9a8c\u8bc1\u4e86\u5927\u89c4\u6a21AC-OPF\u4ee3\u7406\u7684\u6240\u6709\u8fd0\u884c\u7ea6\u675f\uff0c\u5c55\u793a\u4e86\u53ef\u6269\u5c55\u6027\u3001\u901f\u5ea6\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5f25\u5408\u4e86\u673a\u5668\u5b66\u4e60\u52a0\u901f\u4e0eAC-OPF\u89e3\u51b3\u65b9\u6848\u5b89\u5168\u5b9e\u65f6\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u6700\u4f18\u63a7\u5236\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.22164", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.22164", "abs": "https://arxiv.org/abs/2510.22164", "authors": ["Jianeng Wang", "Matias Mattamala", "Christina Kassab", "Nived Chebrolu", "Guillaume Burger", "Fabio Elnecave", "Marine Petriaux", "Maurice Fallon"], "title": "LT-Exosense: A Vision-centric Multi-session Mapping System for Lifelong Safe Navigation of Exoskeletons", "comment": "8 pages, 4 figures", "summary": "Self-balancing exoskeletons offer a promising mobility solution for\nindividuals with lower-limb disabilities. For reliable long-term operation,\nthese exoskeletons require a perception system that is effective in changing\nenvironments. In this work, we introduce LT-Exosense, a vision-centric,\nmulti-session mapping system designed to support long-term (semi)-autonomous\nnavigation for exoskeleton users. LT-Exosense extends single-session mapping\ncapabilities by incrementally fusing spatial knowledge across multiple\nsessions, detecting environmental changes, and updating a persistent global\nmap. This representation enables intelligent path planning, which can adapt to\nnewly observed obstacles and can recover previous routes when obstructions are\nremoved. We validate LT-Exosense through several real-world experiments,\ndemonstrating a scalable multi-session map that achieves an average\npoint-to-point error below 5 cm when compared to ground-truth laser scans. We\nalso illustrate the potential application of adaptive path planning in\ndynamically changing indoor environments.", "AI": {"tldr": "LT-Exosense\u662f\u4e00\u4e2a\u9762\u5411\u5916\u9aa8\u9abc\u7528\u6237\u7684\u89c6\u89c9\u4e2d\u5fc3\u591a\u4f1a\u8bdd\u5efa\u56fe\u7cfb\u7edf\uff0c\u652f\u6301\u957f\u671f\uff08\u534a\uff09\u81ea\u4e3b\u5bfc\u822a\uff0c\u901a\u8fc7\u8de8\u4f1a\u8bdd\u878d\u5408\u7a7a\u95f4\u77e5\u8bc6\u3001\u68c0\u6d4b\u73af\u5883\u53d8\u5316\u548c\u66f4\u65b0\u6301\u4e45\u5168\u5c40\u5730\u56fe\u6765\u5b9e\u73b0\u667a\u80fd\u8def\u5f84\u89c4\u5212\u3002", "motivation": "\u4e3a\u4e0b\u80a2\u6b8b\u75be\u4eba\u58eb\u63d0\u4f9b\u53ef\u9760\u957f\u671f\u8fd0\u884c\u7684\u81ea\u5e73\u8861\u5916\u9aa8\u9abc\u9700\u8981\u80fd\u591f\u5728\u53d8\u5316\u73af\u5883\u4e2d\u6709\u6548\u5de5\u4f5c\u7684\u611f\u77e5\u7cfb\u7edf\u3002", "method": "\u6269\u5c55\u5355\u4f1a\u8bdd\u5efa\u56fe\u80fd\u529b\uff0c\u901a\u8fc7\u589e\u91cf\u878d\u5408\u591a\u4e2a\u4f1a\u8bdd\u7684\u7a7a\u95f4\u77e5\u8bc6\u3001\u68c0\u6d4b\u73af\u5883\u53d8\u5316\u5e76\u66f4\u65b0\u6301\u4e45\u5168\u5c40\u5730\u56fe\uff0c\u5b9e\u73b0\u667a\u80fd\u8def\u5f84\u89c4\u5212\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u53ef\u6269\u5c55\u7684\u591a\u4f1a\u8bdd\u5730\u56fe\uff0c\u4e0e\u5730\u9762\u771f\u5b9e\u6fc0\u5149\u626b\u63cf\u76f8\u6bd4\uff0c\u5e73\u5747\u70b9\u5bf9\u70b9\u8bef\u5dee\u4f4e\u4e8e5\u5398\u7c73\uff0c\u5c55\u793a\u4e86\u5728\u52a8\u6001\u53d8\u5316\u5ba4\u5185\u73af\u5883\u4e2d\u81ea\u9002\u5e94\u8def\u5f84\u89c4\u5212\u7684\u6f5c\u529b\u3002", "conclusion": "LT-Exosense\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u652f\u6301\u5916\u9aa8\u9abc\u7528\u6237\u7684\u957f\u671f\u81ea\u4e3b\u5bfc\u822a\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.22192", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22192", "abs": "https://arxiv.org/abs/2510.22192", "authors": ["Haoyang Liu", "Jie Wang", "Yuyang Cai", "Xiongwei Han", "Yufei Kuang", "Jianye Hao"], "title": "OptiTree: Hierarchical Thoughts Generation with Tree Search for LLM Optimization Modeling", "comment": "Published at NeurIPS 2025", "summary": "Optimization modeling is one of the most crucial but technical parts of\noperations research (OR). To automate the modeling process, existing works have\nleveraged large language models (LLMs), prompting them to break down tasks into\nsteps for generating variables, constraints, and objectives. However, due to\nthe highly complex mathematical structures inherent in OR problems, standard\nfixed-step decomposition often fails to achieve high performance. To address\nthis challenge, we introduce OptiTree, a novel tree search approach designed to\nenhance modeling capabilities for complex problems through adaptive problem\ndecomposition into simpler subproblems. Specifically, we develop a modeling\ntree that organizes a wide range of OR problems based on their hierarchical\nproblem taxonomy and complexity, with each node representing a problem category\nand containing relevant high-level modeling thoughts. Given a problem to model,\nwe recurrently search the tree to identify a series of simpler subproblems and\nsynthesize the global modeling thoughts by adaptively integrating the\nhierarchical thoughts. Experiments show that OptiTree significantly improves\nthe modeling accuracy compared to the state-of-the-art, achieving over 10\\%\nimprovements on the challenging benchmarks. The code is released at\nhttps://github.com/MIRALab-USTC/OptiTree/tree/main.", "AI": {"tldr": "OptiTree\u662f\u4e00\u79cd\u57fa\u4e8e\u6811\u641c\u7d22\u7684\u81ea\u9002\u5e94\u95ee\u9898\u5206\u89e3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u590d\u6742\u8fd0\u7b79\u5b66\u95ee\u9898\u5206\u89e3\u4e3a\u66f4\u7b80\u5355\u7684\u5b50\u95ee\u9898\u6765\u63d0\u5347\u5efa\u6a21\u80fd\u529b\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u8d85\u8fc710%\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u56fa\u5b9a\u6b65\u9aa4\u5206\u89e3\u6765\u751f\u6210\u53d8\u91cf\u3001\u7ea6\u675f\u548c\u76ee\u6807\uff0c\u4f46\u7531\u4e8e\u8fd0\u7b79\u5b66\u95ee\u9898\u5177\u6709\u9ad8\u5ea6\u590d\u6742\u7684\u6570\u5b66\u7ed3\u6784\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5f80\u5f80\u65e0\u6cd5\u8fbe\u5230\u9ad8\u6027\u80fd\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u81ea\u9002\u5e94\u5206\u89e3\u590d\u6742\u95ee\u9898\u7684\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5efa\u6a21\u6811\uff0c\u57fa\u4e8e\u8fd0\u7b79\u5b66\u95ee\u9898\u7684\u5c42\u6b21\u5316\u95ee\u9898\u5206\u7c7b\u548c\u590d\u6742\u6027\u7ec4\u7ec7\u95ee\u9898\uff0c\u6bcf\u4e2a\u8282\u70b9\u4ee3\u8868\u4e00\u4e2a\u95ee\u9898\u7c7b\u522b\u5e76\u5305\u542b\u76f8\u5173\u7684\u9ad8\u7ea7\u5efa\u6a21\u601d\u8def\u3002\u901a\u8fc7\u9012\u5f52\u641c\u7d22\u6811\u6765\u8bc6\u522b\u66f4\u7b80\u5355\u7684\u5b50\u95ee\u9898\uff0c\u5e76\u81ea\u9002\u5e94\u6574\u5408\u5c42\u6b21\u5316\u601d\u8def\u6765\u5408\u6210\u5168\u5c40\u5efa\u6a21\u601d\u8def\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cOptiTree\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5efa\u6a21\u51c6\u786e\u7387\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u8d85\u8fc710%\u7684\u6539\u8fdb\u3002", "conclusion": "OptiTree\u901a\u8fc7\u81ea\u9002\u5e94\u95ee\u9898\u5206\u89e3\u548c\u5c42\u6b21\u5316\u601d\u8def\u6574\u5408\uff0c\u6709\u6548\u63d0\u5347\u4e86\u590d\u6742\u8fd0\u7b79\u5b66\u95ee\u9898\u7684\u5efa\u6a21\u80fd\u529b\uff0c\u4e3a\u89e3\u51b3\u9ad8\u5ea6\u6280\u672f\u6027\u7684\u8fd0\u7b79\u5b66\u5efa\u6a21\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2510.23226", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.23226", "abs": "https://arxiv.org/abs/2510.23226", "authors": ["Mohammad Dastranj", "Jouni Mattila"], "title": "Inertia Partitioning Modular Control Framework for Reconfigurable Multibody Systems", "comment": null, "summary": "A novel modular control framework for reconfigurable rigid multibody systems\nis proposed, motivated by the challenges of modular control of systems with\nclosed kinematic chains. In the framework, modularity is defined in the sense\nof degrees of freedom, and the inertial properties of each body are partitioned\nwith respect to how they are reflected in the kinetic energy of the system\nthrough the motion induced by each degree of freedom. This approach inherently\nhandles closed chains in the same manner as tree-like structures, eliminating\nthe need for explicit constraint force calculations or formulations based on\ndifferential-algebraic equations. The proposed framework is implemented via\nsimulation on a three-degree-of-freedom series-parallel manipulator, with the\nresults being consistent with the expected stability and tracking performance,\nand indicating the framework's potential for scalability in trajectory-tracking\ncontrol of multibody systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u53ef\u91cd\u6784\u521a\u6027\u591a\u4f53\u7cfb\u7edf\u7684\u6a21\u5757\u5316\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7531\u5ea6\u5b9a\u4e49\u6a21\u5757\u5316\uff0c\u5c06\u6bcf\u4e2a\u4f53\u7684\u60ef\u6027\u5c5e\u6027\u6309\u5176\u5bf9\u7cfb\u7edf\u52a8\u80fd\u7684\u5f71\u54cd\u8fdb\u884c\u5212\u5206\uff0c\u80fd\u591f\u4ee5\u5904\u7406\u6811\u72b6\u7ed3\u6784\u7684\u65b9\u5f0f\u5904\u7406\u95ed\u73af\u8fd0\u52a8\u94fe\uff0c\u65e0\u9700\u663e\u5f0f\u8ba1\u7b97\u7ea6\u675f\u529b\u6216\u57fa\u4e8e\u5fae\u5206-\u4ee3\u6570\u65b9\u7a0b\u7684\u5f62\u5f0f\u5316\u3002", "motivation": "\u89e3\u51b3\u5177\u6709\u95ed\u73af\u8fd0\u52a8\u94fe\u7cfb\u7edf\u7684\u6a21\u5757\u5316\u63a7\u5236\u6311\u6218\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u4e2d\u590d\u6742\u7684\u7ea6\u675f\u529b\u8ba1\u7b97\u548c\u5fae\u5206-\u4ee3\u6570\u65b9\u7a0b\u5904\u7406\u3002", "method": "\u57fa\u4e8e\u81ea\u7531\u5ea6\u7684\u6a21\u5757\u5316\u5b9a\u4e49\uff0c\u5c06\u60ef\u6027\u5c5e\u6027\u6309\u6bcf\u4e2a\u81ea\u7531\u5ea6\u5f15\u8d77\u7684\u8fd0\u52a8\u5728\u7cfb\u7edf\u52a8\u80fd\u4e2d\u7684\u53cd\u6620\u8fdb\u884c\u5212\u5206\uff0c\u91c7\u7528\u4e0e\u5904\u7406\u6811\u72b6\u7ed3\u6784\u76f8\u540c\u7684\u65b9\u5f0f\u5904\u7406\u95ed\u73af\u94fe\u3002", "result": "\u5728\u4e09\u81ea\u7531\u5ea6\u4e32\u5e76\u8054\u673a\u68b0\u81c2\u4e0a\u8fdb\u884c\u4eff\u771f\u5b9e\u73b0\uff0c\u7ed3\u679c\u663e\u793a\u51fa\u9884\u671f\u7684\u7a33\u5b9a\u6027\u548c\u8ddf\u8e2a\u6027\u80fd\uff0c\u8868\u660e\u8be5\u6846\u67b6\u5728\u591a\u4f53\u7cfb\u7edf\u8f68\u8ff9\u8ddf\u8e2a\u63a7\u5236\u4e2d\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u6a21\u5757\u5316\u63a7\u5236\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u95ed\u73af\u8fd0\u52a8\u94fe\u7cfb\u7edf\uff0c\u907f\u514d\u4e86\u590d\u6742\u7684\u7ea6\u675f\u8ba1\u7b97\uff0c\u5728\u8f68\u8ff9\u8ddf\u8e2a\u63a7\u5236\u65b9\u9762\u5c55\u73b0\u51fa\u826f\u597d\u7684\u53ef\u6269\u5c55\u6f5c\u529b\u3002"}}
{"id": "2510.22201", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22201", "abs": "https://arxiv.org/abs/2510.22201", "authors": ["Minho Park", "Kinam Kim", "Junha Hyung", "Hyojin Jang", "Hoiyeong Jin", "Jooyeol Yun", "Hojoon Lee", "Jaegul Choo"], "title": "ACG: Action Coherence Guidance for Flow-based VLA models", "comment": null, "summary": "Diffusion and flow matching models have emerged as powerful robot policies,\nenabling Vision-Language-Action (VLA) models to generalize across diverse\nscenes and instructions. Yet, when trained via imitation learning, their high\ngenerative capacity makes them sensitive to noise in human demonstrations:\njerks, pauses, and jitter which reduce action coherence. Reduced action\ncoherence causes instability and trajectory drift during deployment, failures\nthat are catastrophic in fine-grained manipulation where precision is crucial.\nIn this paper, we present Action Coherence Guidance (ACG) for VLA models, a\ntraining-free test-time guidance algorithm that improves action coherence and\nthereby yields performance gains. Evaluated on RoboCasa, DexMimicGen, and\nreal-world SO-101 tasks, ACG consistently improves action coherence and boosts\nsuccess rates across diverse manipulation tasks. Code and project page are\navailable at https://github.com/DAVIAN-Robotics/ACG and\nhttps://DAVIAN-Robotics.github.io/ACG , respectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u52a8\u4f5c\u8fde\u8d2f\u6027\u6307\u5bfc\u7b97\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\u5728\u673a\u5668\u4eba\u63a7\u5236\u4e2d\u7684\u52a8\u4f5c\u8fde\u8d2f\u6027\uff0c\u51cf\u5c11\u90e8\u7f72\u65f6\u7684\u4e0d\u7a33\u5b9a\u6027\u548c\u8f68\u8ff9\u6f02\u79fb\u3002", "motivation": "\u6269\u6563\u548c\u6d41\u5339\u914d\u6a21\u578b\u4f5c\u4e3a\u5f3a\u5927\u7684\u673a\u5668\u4eba\u7b56\u7565\uff0c\u5728\u6a21\u4eff\u5b66\u4e60\u4e2d\u5bf9\u4eba\u7c7b\u6f14\u793a\u4e2d\u7684\u566a\u58f0\u654f\u611f\uff0c\u5bfc\u81f4\u52a8\u4f5c\u4e0d\u8fde\u8d2f\uff0c\u5f71\u54cd\u7cbe\u7ec6\u64cd\u4f5c\u7684\u7cbe\u786e\u6027\u3002", "method": "\u52a8\u4f5c\u8fde\u8d2f\u6027\u6307\u5bfc\u7b97\u6cd5\uff0c\u5728\u6d4b\u8bd5\u65f6\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u901a\u8fc7\u6307\u5bfc\u673a\u5236\u63d0\u5347\u52a8\u4f5c\u8fde\u8d2f\u6027\u3002", "result": "\u5728RoboCasa\u3001DexMimicGen\u548c\u771f\u5b9e\u4e16\u754cSO-101\u4efb\u52a1\u4e0a\u8bc4\u4f30\uff0c\u4e00\u81f4\u63d0\u5347\u4e86\u52a8\u4f5c\u8fde\u8d2f\u6027\u5e76\u63d0\u9ad8\u4e86\u5404\u79cd\u64cd\u4f5c\u4efb\u52a1\u7684\u6210\u529f\u7387\u3002", "conclusion": "ACG\u7b97\u6cd5\u80fd\u6709\u6548\u63d0\u5347VLA\u6a21\u578b\u7684\u52a8\u4f5c\u8fde\u8d2f\u6027\uff0c\u5728\u591a\u79cd\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5e26\u6765\u6027\u80fd\u589e\u76ca\u3002"}}
{"id": "2510.22255", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.22255", "abs": "https://arxiv.org/abs/2510.22255", "authors": ["Eunseop Yoon", "Hee Suk Yoon", "Jaehyun Jang", "SooHwan Eom", "Qi Dai", "Chong Luo", "Mark A. Hasegawa-Johnson", "Chang D. Yoo"], "title": "PACR: Progressively Ascending Confidence Reward for LLM Reasoning", "comment": "16 pages, 14 figures", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has significantly\nimproved LLM reasoning, but its sparse, outcome-based reward provides no\nguidance for intermediate steps, slowing exploration. We propose Progressively\nAscending Confidence Reward (PACR), a dense, model-intrinsic reward computed\ndirectly from the model's evolving belief in the correct answer. PACR encodes\nthe inductive bias that, along a well-formed reasoning trajectory, the\nprobability of the ground-truth answer should have a generally ascending trend.\nWe provide empirical and theoretical analysis validating that such an inductive\nbias constrains the exploration search space to regions richer in logically\nsound reasoning. We demonstrate that PACR accelerates exploration, reaches\nreward saturation with fewer trajectories, and yields improvements on multiple\nbenchmarks. Our results suggest that dense, model-intrinsic shaping signals can\nmake RLVR training more effective and reliable.", "AI": {"tldr": "\u63d0\u51fa\u4e86PACR\uff08\u6e10\u8fdb\u4e0a\u5347\u7f6e\u4fe1\u5ea6\u5956\u52b1\uff09\uff0c\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u5185\u5728\u4fe1\u5ff5\u7684\u5bc6\u96c6\u5956\u52b1\u673a\u5236\uff0c\u7528\u4e8e\u6539\u8fdbRLVR\u8bad\u7ec3\u4e2d\u7684\u63a2\u7d22\u6548\u7387\u3002", "motivation": "RLVR\u7684\u7a00\u758f\u3001\u57fa\u4e8e\u7ed3\u679c\u7684\u5956\u52b1\u65e0\u6cd5\u4e3a\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u63d0\u4f9b\u6307\u5bfc\uff0c\u5bfc\u81f4\u63a2\u7d22\u7f13\u6162\u3002", "method": "\u4f7f\u7528\u6a21\u578b\u5bf9\u6b63\u786e\u7b54\u6848\u6982\u7387\u7684\u6e10\u8fdb\u4e0a\u5347\u8d8b\u52bf\u4f5c\u4e3a\u5bc6\u96c6\u5956\u52b1\u4fe1\u53f7\uff0c\u7ea6\u675f\u63a2\u7d22\u7a7a\u95f4\u5230\u903b\u8f91\u5408\u7406\u7684\u63a8\u7406\u533a\u57df\u3002", "result": "PACR\u52a0\u901f\u4e86\u63a2\u7d22\uff0c\u7528\u66f4\u5c11\u7684\u8f68\u8ff9\u8fbe\u5230\u5956\u52b1\u9971\u548c\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6539\u8fdb\u3002", "conclusion": "\u5bc6\u96c6\u7684\u6a21\u578b\u5185\u5728\u5851\u9020\u4fe1\u53f7\u53ef\u4ee5\u4f7fRLVR\u8bad\u7ec3\u66f4\u6709\u6548\u548c\u53ef\u9760\u3002"}}
{"id": "2510.23296", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.23296", "abs": "https://arxiv.org/abs/2510.23296", "authors": ["Hai Yu", "Zhichao Yang", "Wei He", "Jianda Han", "Yongchun Fang", "Xiao Liang"], "title": "Payload trajectory tracking control for aerial transportation systems with cable length online optimization", "comment": null, "summary": "Cable-suspended aerial transportation systems are employed extensively across\nvarious industries. The capability to flexibly adjust the relative position\nbetween the multirotor and the payload has spurred growing interest in the\nsystem equipped with variable-length cable, promising broader application\npotential. Compared to systems with fixed-length cables, introducing the\nvariable-length cable adds a new degree of freedom. However, it also results in\nincreased nonlinearity and more complex dynamic coupling among the multirotor,\nthe cable and the payload, posing significant challenges in control design.\nThis paper introduces a backstepping control strategy tailored for aerial\ntransportation systems with variable-length cable, designed to precisely track\nthe payload trajectory while dynamically adjusting cable length. Then, a cable\nlength generator has been developed that achieves online optimization of the\ncable length while satisfying state constraints, thus balancing the\nmultirotor's motion and cable length changes without the need for manual\ntrajectory planning. The asymptotic stability of the closed-loop system is\nguaranteed through Lyapunov techniques and the growth restriction condition.\nFinally, simulation results confirm the efficacy of the proposed method in\nmanaging trajectory tracking and cable length adjustments effectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u53ef\u53d8\u957f\u5ea6\u7f06\u7ef3\u7a7a\u4e2d\u8fd0\u8f93\u7cfb\u7edf\u7684\u53cd\u6b65\u63a7\u5236\u7b56\u7565\uff0c\u80fd\u591f\u7cbe\u786e\u8ddf\u8e2a\u6709\u6548\u8f7d\u8377\u8f68\u8ff9\u5e76\u52a8\u6001\u8c03\u6574\u7f06\u7ef3\u957f\u5ea6\uff0c\u540c\u65f6\u901a\u8fc7\u7f06\u7ef3\u957f\u5ea6\u751f\u6210\u5668\u5b9e\u73b0\u5728\u7ebf\u4f18\u5316\u3002", "motivation": "\u53ef\u53d8\u957f\u5ea6\u7f06\u7ef3\u7cfb\u7edf\u76f8\u6bd4\u56fa\u5b9a\u957f\u5ea6\u7cfb\u7edf\u589e\u52a0\u4e86\u81ea\u7531\u5ea6\uff0c\u5177\u6709\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u4f46\u540c\u65f6\u4e5f\u5e26\u6765\u4e86\u66f4\u5f3a\u7684\u975e\u7ebf\u6027\u548c\u590d\u6742\u7684\u52a8\u6001\u8026\u5408\uff0c\u7ed9\u63a7\u5236\u8bbe\u8ba1\u5e26\u6765\u6311\u6218\u3002", "method": "\u91c7\u7528\u53cd\u6b65\u63a7\u5236\u7b56\u7565\u8bbe\u8ba1\u63a7\u5236\u5668\uff0c\u5e76\u5f00\u53d1\u7f06\u7ef3\u957f\u5ea6\u751f\u6210\u5668\u8fdb\u884c\u5728\u7ebf\u4f18\u5316\uff0c\u6ee1\u8db3\u72b6\u6001\u7ea6\u675f\uff0c\u65e0\u9700\u624b\u52a8\u8f68\u8ff9\u89c4\u5212\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u8f68\u8ff9\u8ddf\u8e2a\u548c\u7f06\u7ef3\u957f\u5ea6\u8c03\u6574\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u674e\u96c5\u666e\u8bfa\u592b\u6280\u672f\u548c\u589e\u957f\u9650\u5236\u6761\u4ef6\u4fdd\u8bc1\u4e86\u95ed\u73af\u7cfb\u7edf\u7684\u6e10\u8fd1\u7a33\u5b9a\u6027\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u7ba1\u7406\u8f68\u8ff9\u8ddf\u8e2a\u548c\u7f06\u7ef3\u957f\u5ea6\u8c03\u6574\u3002"}}
{"id": "2510.22204", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22204", "abs": "https://arxiv.org/abs/2510.22204", "authors": ["Weixian Qian", "Sebastian Schroder", "Yao Deng", "Jiaohong Yao", "Linfeng Liang", "Xiao Cheng", "Richard Han", "Xi Zheng"], "title": "Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing for UAVs in Cluttered Environments", "comment": null, "summary": "Autonomous landing in unstructured (cluttered, uneven, and map-poor)\nenvironments is a core requirement for Unmanned Aerial Vehicles (UAVs), yet\npurely vision-based or deep learning models often falter under covariate shift\nand provide limited interpretability. We propose NeuroSymLand, a neuro-symbolic\nframework that tightly couples two complementary pipelines: (i) an offline\npipeline, where Large Language Models (LLMs) and human-in-the-loop refinement\nsynthesize Scallop code from diverse landing scenarios, distilling\ngeneralizable and verifiable symbolic knowledge; and (ii) an online pipeline,\nwhere a compact foundation-based semantic segmentation model generates\nprobabilistic Scallop facts that are composed into semantic scene graphs for\nreal-time deductive reasoning. This design combines the perceptual strengths of\nlightweight foundation models with the interpretability and verifiability of\nsymbolic reasoning. Node attributes (e.g., flatness, area) and edge relations\n(adjacency, containment, proximity) are computed with geometric routines rather\nthan learned, avoiding the data dependence and latency of train-time graph\nbuilders. The resulting Scallop program encodes landing principles (avoid water\nand obstacles; prefer large, flat, accessible regions) and yields calibrated\nsafety scores with ranked Regions of Interest (ROIs) and human-readable\njustifications. Extensive evaluations across datasets, diverse simulation maps,\nand real UAV hardware show that NeuroSymLand achieves higher accuracy, stronger\nrobustness to covariate shift, and superior efficiency compared with\nstate-of-the-art baselines, while advancing UAV safety and reliability in\nemergency response, surveillance, and delivery missions.", "AI": {"tldr": "NeuroSymLand\u662f\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7b26\u53f7\u63a8\u7406\uff0c\u5b9e\u73b0\u65e0\u4eba\u673a\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u7740\u9646\uff0c\u5177\u6709\u9ad8\u7cbe\u5ea6\u3001\u5f3a\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u7eaf\u89c6\u89c9\u6216\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u65e0\u4eba\u673a\u81ea\u4e3b\u7740\u9646\u4efb\u52a1\u4e2d\u9762\u4e34\u534f\u53d8\u91cf\u504f\u79fb\u548c\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u7ed3\u5408\u611f\u77e5\u80fd\u529b\u548c\u7b26\u53f7\u63a8\u7406\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u53cc\u7ba1\u9053\u8bbe\u8ba1\uff1a\u79bb\u7ebf\u7ba1\u9053\u4f7f\u7528LLM\u548c\u4eba\u5de5\u7ec6\u5316\u5408\u6210\u53ef\u9a8c\u8bc1\u7684\u7b26\u53f7\u77e5\u8bc6\uff1b\u5728\u7ebf\u7ba1\u9053\u901a\u8fc7\u8bed\u4e49\u5206\u5272\u751f\u6210\u6982\u7387\u4e8b\u5b9e\uff0c\u6784\u5efa\u8bed\u4e49\u573a\u666f\u56fe\u8fdb\u884c\u5b9e\u65f6\u63a8\u7406\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u3001\u4eff\u771f\u73af\u5883\u548c\u771f\u5b9e\u65e0\u4eba\u673a\u786c\u4ef6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cNeuroSymLand\u5728\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u7ed3\u5408\u4e86\u8f7b\u91cf\u7ea7\u57fa\u7840\u6a21\u578b\u7684\u611f\u77e5\u4f18\u52bf\u4e0e\u7b26\u53f7\u63a8\u7406\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u63d0\u5347\u4e86\u65e0\u4eba\u673a\u5728\u5e94\u6025\u54cd\u5e94\u3001\u76d1\u89c6\u548c\u914d\u9001\u4efb\u52a1\u4e2d\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.22295", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.22295", "abs": "https://arxiv.org/abs/2510.22295", "authors": ["Quoc Anh Nguyen", "Bernard Cheng", "Kelvin Soh"], "title": "VietLyrics: A Large-Scale Dataset and Models for Vietnamese Automatic Lyrics Transcription", "comment": null, "summary": "Automatic Lyrics Transcription (ALT) for Vietnamese music presents unique\nchallenges due to its tonal complexity and dialectal variations, but remains\nlargely unexplored due to the lack of a dedicated dataset. Therefore, we\ncurated the first large-scale Vietnamese ALT dataset (VietLyrics), comprising\n647 hours of songs with line-level aligned lyrics and metadata to address these\nissues. Our evaluation of current ASRbased approaches reveal significant\nlimitations, including frequent transcription errors and hallucinations in\nnon-vocal segments. To improve performance, we fine-tuned Whisper models on the\nVietLyrics dataset, achieving superior results compared to existing\nmultilingual ALT systems, including LyricWhiz. We publicly release VietLyrics\nand our models, aiming to advance Vietnamese music computing research while\ndemonstrating the potential of this approach for ALT in low-resource language\nand music.", "AI": {"tldr": "\u521b\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u8d8a\u5357\u8bed\u6b4c\u8bcd\u8f6c\u5f55\u6570\u636e\u96c6VietLyrics\uff0c\u901a\u8fc7\u5fae\u8c03Whisper\u6a21\u578b\u5728\u8d8a\u5357\u8bed\u6b4c\u8bcd\u8f6c\u5f55\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u591a\u8bed\u8a00\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u8d8a\u5357\u8bed\u6b4c\u8bcd\u8f6c\u5f55\u9762\u4e34\u97f3\u8c03\u590d\u6742\u6027\u548c\u65b9\u8a00\u53d8\u5f02\u7684\u72ec\u7279\u6311\u6218\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u4e13\u7528\u6570\u636e\u96c6\u800c\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b647\u5c0f\u65f6\u6b4c\u66f2\u7684VietLyrics\u6570\u636e\u96c6\uff0c\u5e76\u5bf9Whisper\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5fae\u8c03\u540e\u7684Whisper\u6a21\u578b\u5728\u8d8a\u5357\u8bed\u6b4c\u8bcd\u8f6c\u5f55\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684\u591a\u8bed\u8a00\u7cfb\u7edf\uff0c\u5305\u62ecLyricWhiz\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u548c\u97f3\u4e50\u9886\u57df\u8fdb\u884c\u6b4c\u8bcd\u8f6c\u5f55\u7684\u6f5c\u529b\uff0c\u5e76\u516c\u5f00\u53d1\u5e03\u4e86\u6570\u636e\u96c6\u548c\u6a21\u578b\u4ee5\u63a8\u52a8\u8d8a\u5357\u97f3\u4e50\u8ba1\u7b97\u7814\u7a76\u3002"}}
{"id": "2510.22313", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22313", "abs": "https://arxiv.org/abs/2510.22313", "authors": ["Chen Zhiqiang", "Le Gentil Cedric", "Lin Fuling", "Lu Minghao", "Qiao Qiyuan", "Xu Bowen", "Qi Yuhua", "Lu Peng"], "title": "Breaking the Static Assumption: A Dynamic-Aware LIO Framework Via Spatio-Temporal Normal Analysis", "comment": "8 pages, 7 figures, Accepted to IEEE Robotics and Automation Letters\n  (RA-L)", "summary": "This paper addresses the challenge of Lidar-Inertial Odometry (LIO) in\ndynamic environments, where conventional methods often fail due to their\nstatic-world assumptions. Traditional LIO algorithms perform poorly when\ndynamic objects dominate the scenes, particularly in geometrically sparse\nenvironments. Current approaches to dynamic LIO face a fundamental challenge:\naccurate localization requires a reliable identification of static features,\nyet distinguishing dynamic objects necessitates precise pose estimation. Our\nsolution breaks this circular dependency by integrating dynamic awareness\ndirectly into the point cloud registration process. We introduce a novel\ndynamic-aware iterative closest point algorithm that leverages spatio-temporal\nnormal analysis, complemented by an efficient spatial consistency verification\nmethod to enhance static map construction. Experimental evaluations demonstrate\nsignificant performance improvements over state-of-the-art LIO systems in\nchallenging dynamic environments with limited geometric structure. The code and\ndataset are available at https://github.com/thisparticle/btsa.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u611f\u77e5\u7684\u6fc0\u5149\u96f7\u8fbe-\u60ef\u6027\u91cc\u7a0b\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u65f6\u7a7a\u6cd5\u5411\u91cf\u5206\u6790\u548c\u7a7a\u95f4\u4e00\u81f4\u6027\u9a8c\u8bc1\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u5b9a\u4f4d\u548c\u9759\u6001\u5730\u56fe\u6784\u5efa\u3002", "motivation": "\u4f20\u7edfLIO\u65b9\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u5728\u51e0\u4f55\u7a00\u758f\u573a\u666f\u4e2d\u3002\u73b0\u6709\u52a8\u6001LIO\u65b9\u6cd5\u9762\u4e34\u5faa\u73af\u4f9d\u8d56\u95ee\u9898\uff1a\u51c6\u786e\u5b9a\u4f4d\u9700\u8981\u53ef\u9760\u7684\u9759\u6001\u7279\u5f81\u8bc6\u522b\uff0c\u800c\u533a\u5206\u52a8\u6001\u7269\u4f53\u53c8\u9700\u8981\u7cbe\u786e\u7684\u4f4d\u59ff\u4f30\u8ba1\u3002", "method": "\u5c06\u52a8\u6001\u611f\u77e5\u76f4\u63a5\u96c6\u6210\u5230\u70b9\u4e91\u914d\u51c6\u8fc7\u7a0b\u4e2d\uff0c\u63d0\u51fa\u52a8\u6001\u611f\u77e5\u7684\u8fed\u4ee3\u6700\u8fd1\u70b9\u7b97\u6cd5\uff0c\u5229\u7528\u65f6\u7a7a\u6cd5\u5411\u91cf\u5206\u6790\uff0c\u5e76\u8f85\u4ee5\u9ad8\u6548\u7684\u7a7a\u95f4\u4e00\u81f4\u6027\u9a8c\u8bc1\u65b9\u6cd5\u6765\u589e\u5f3a\u9759\u6001\u5730\u56fe\u6784\u5efa\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u5728\u51e0\u4f55\u7ed3\u6784\u6709\u9650\u7684\u6311\u6218\u6027\u52a8\u6001\u73af\u5883\u4e2d\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684LIO\u7cfb\u7edf\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6253\u7834\u5faa\u73af\u4f9d\u8d56\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9c81\u68d2\u7684\u6fc0\u5149\u96f7\u8fbe-\u60ef\u6027\u91cc\u7a0b\u8ba1\u6027\u80fd\u3002"}}
{"id": "2510.22329", "categories": ["cs.AI", "math.OC", "90C59, 90C27", "G.2.2; I.2.8; F.2.2"], "pdf": "https://arxiv.org/pdf/2510.22329", "abs": "https://arxiv.org/abs/2510.22329", "authors": ["Mustafa Mert \u00d6zy\u0131lmaz"], "title": "Graph-Coarsening Approach for the Capacitated Vehicle Routing Problem with Time Windows", "comment": "13 pages, 30 figures. Submitted to arXiv under categories quant-ph. A\n  revised version with quantum solver experiment results will be submitted to a\n  peer-reviewed journal", "summary": "The Capacitated Vehicle Routing Problem with Time Windows (CVRPTW) is a\nfundamental NP-hard optimization problem in logistics. Solving large-scale\ninstances remains computationally challenging for exact solvers. This work\nintroduces a multilevel graph coarsening and refinement framework that\naggregates customers into meta-nodes using a spatio-temporal distance metric.\nThe reduced problem is solved with classical heuristics and subsequently\nexpanded back into the original space with feasibility corrections. Preliminary\nexperiments on Solomon benchmark instances show that the proposed method\nreduces computation time while preserving or improving solution quality,\nparticularly with respect to capacity and time window constraints. The paper\nalso explores the integration of quantum-inspired optimization techniques,\nhighlighting their potential to further accelerate large-scale vehicle routing\ntasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u89e3\u51b3\u5e26\u65f6\u95f4\u7a97\u7684\u5bb9\u91cf\u9650\u5236\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff08CVRPTW\uff09\u7684\u591a\u7ea7\u56fe\u7c97\u5316\u548c\u7ec6\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u65f6\u7a7a\u8ddd\u79bb\u5ea6\u91cf\u5c06\u5ba2\u6237\u805a\u5408\u6210\u5143\u8282\u70b9\uff0c\u5728\u7b80\u5316\u95ee\u9898\u4e0a\u4f7f\u7528\u7ecf\u5178\u542f\u53d1\u5f0f\u7b97\u6cd5\u6c42\u89e3\uff0c\u7136\u540e\u6269\u5c55\u56de\u539f\u59cb\u7a7a\u95f4\u5e76\u8fdb\u884c\u53ef\u884c\u6027\u4fee\u6b63\u3002", "motivation": "CVRPTW\u662f\u7269\u6d41\u4e2d\u7684\u57fa\u672cNP\u96be\u4f18\u5316\u95ee\u9898\uff0c\u5927\u89c4\u6a21\u5b9e\u4f8b\u5bf9\u7cbe\u786e\u6c42\u89e3\u5668\u4ecd\u7136\u5177\u6709\u8ba1\u7b97\u6311\u6218\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u6c42\u89e3\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u591a\u7ea7\u56fe\u7c97\u5316\u548c\u7ec6\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u65f6\u7a7a\u8ddd\u79bb\u5ea6\u91cf\u805a\u5408\u5ba2\u6237\u4e3a\u5143\u8282\u70b9\uff0c\u5728\u7b80\u5316\u95ee\u9898\u4e0a\u5e94\u7528\u7ecf\u5178\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u7136\u540e\u6269\u5c55\u56de\u539f\u59cb\u7a7a\u95f4\u5e76\u8fdb\u884c\u53ef\u884c\u6027\u4fee\u6b63\u3002", "result": "\u5728Solomon\u57fa\u51c6\u5b9e\u4f8b\u4e0a\u7684\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u7684\u540c\u65f6\u4fdd\u6301\u6216\u6539\u8fdb\u4e86\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5728\u5bb9\u91cf\u548c\u65f6\u95f4\u7a97\u7ea6\u675f\u65b9\u9762\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u51cf\u5c11CVRPTW\u95ee\u9898\u7684\u8ba1\u7b97\u65f6\u95f4\u5e76\u4fdd\u6301\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\uff0c\u91cf\u5b50\u542f\u53d1\u4f18\u5316\u6280\u672f\u7684\u96c6\u6210\u6709\u671b\u8fdb\u4e00\u6b65\u52a0\u901f\u5927\u89c4\u6a21\u8f66\u8f86\u8def\u5f84\u4efb\u52a1\u3002"}}
{"id": "2510.23491", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.23491", "abs": "https://arxiv.org/abs/2510.23491", "authors": ["Peter A. Fisher", "Johannes Autenrieb", "Anuradha M. Annaswamy"], "title": "An Error-Based Safety Buffer for Safe Adaptive Control (Extended Version)", "comment": "Submitted to IEEE Transactions on Automatic Control", "summary": "We consider the problem of adaptive control of a class of feedback\nlinearizable plants with matched parametric uncertainties whose states are\naccessible, subject to state constraints, which often arise due to safety\nconsiderations. In this paper, we combine adaptation and control barrier\nfunctions into a real-time control architecture that guarantees stability,\nensures control performance, and remains safe even with the parametric\nuncertainties. Two problems are considered, differing in the nature of the\nparametric uncertainties. In both cases, the control barrier function is\nassumed to have an arbitrary relative degree. In addition to guaranteeing\nstability, it is proved that both the control objective and safety objective\nare met with near-zero conservatism. No excitation conditions are imposed on\nthe command signal. Simulation results demonstrate the non-conservatism of all\nof the theoretical developments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u81ea\u9002\u5e94\u63a7\u5236\u548c\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u7684\u5b9e\u65f6\u63a7\u5236\u67b6\u6784\uff0c\u7528\u4e8e\u5177\u6709\u5339\u914d\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u7684\u53cd\u9988\u7ebf\u6027\u5316\u7cfb\u7edf\uff0c\u5728\u4fdd\u8bc1\u7a33\u5b9a\u6027\u548c\u63a7\u5236\u6027\u80fd\u7684\u540c\u65f6\u786e\u4fdd\u5b89\u5168\u6027\u3002", "motivation": "\u89e3\u51b3\u5177\u6709\u72b6\u6001\u7ea6\u675f\u548c\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u7684\u53cd\u9988\u7ebf\u6027\u5316\u7cfb\u7edf\u7684\u5b89\u5168\u63a7\u5236\u95ee\u9898\uff0c\u8fd9\u4e9b\u7ea6\u675f\u901a\u5e38\u6e90\u4e8e\u5b89\u5168\u8003\u8651\u3002", "method": "\u5c06\u81ea\u9002\u5e94\u63a7\u5236\u548c\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u7ed3\u5408\uff0c\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u5177\u6709\u4efb\u610f\u76f8\u5bf9\u5ea6\uff0c\u65e0\u9700\u5bf9\u6307\u4ee4\u4fe1\u53f7\u65bd\u52a0\u6fc0\u52b1\u6761\u4ef6\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u548c\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u8bc1\u7a33\u5b9a\u6027\u7684\u540c\u65f6\uff0c\u80fd\u591f\u4ee5\u8fd1\u4e4e\u96f6\u4fdd\u5b88\u5ea6\u5b9e\u73b0\u63a7\u5236\u76ee\u6807\u548c\u5b89\u5168\u76ee\u6807\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u63a7\u5236\u67b6\u6784\u80fd\u591f\u6709\u6548\u5904\u7406\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u4fdd\u8bc1\u7cfb\u7edf\u5b89\u5168\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6027\u80fd\u63a7\u5236\uff0c\u4e14\u5177\u6709\u975e\u4fdd\u5b88\u6027\u3002"}}
{"id": "2510.22336", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22336", "abs": "https://arxiv.org/abs/2510.22336", "authors": ["Bo Yue", "Sheng Xu", "Kui Jia", "Guiliang Liu"], "title": "Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery", "comment": null, "summary": "Humanoid robots represent a central frontier in embodied intelligence, as\ntheir anthropomorphic form enables natural deployment in humans' workspace.\nBrain-body co-design for humanoids presents a promising approach to realizing\nthis potential by jointly optimizing control policies and physical morphology.\nWithin this context, fall recovery emerges as a critical capability. It not\nonly enhances safety and resilience but also integrates naturally with\nlocomotion systems, thereby advancing the autonomy of humanoids. In this paper,\nwe propose RoboCraft, a scalable humanoid co-design framework for fall recovery\nthat iteratively improves performance through the coupled updates of control\npolicy and morphology. A shared policy pretrained across multiple designs is\nprogressively finetuned on high-performing morphologies, enabling efficient\nadaptation without retraining from scratch. Concurrently, morphology search is\nguided by human-inspired priors and optimization algorithms, supported by a\npriority buffer that balances reevaluation of promising candidates with the\nexploration of novel designs. Experiments show that \\ourmethod{} achieves an\naverage performance gain of 44.55% on seven public humanoid robots, with\nmorphology optimization drives at least 40% of improvements in co-designing\nfour humanoid robots, underscoring the critical role of humanoid co-design.", "AI": {"tldr": "RoboCraft\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u4eba\u5f62\u673a\u5668\u4eba\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u63a7\u5236\u7b56\u7565\u548c\u5f62\u6001\u5b66\u7684\u8026\u5408\u66f4\u65b0\u8fed\u4ee3\u63d0\u5347\u8dcc\u5012\u6062\u590d\u6027\u80fd\u3002", "motivation": "\u4eba\u5f62\u673a\u5668\u4eba\u5728\u4eba\u7c7b\u5de5\u4f5c\u7a7a\u95f4\u5177\u6709\u5929\u7136\u90e8\u7f72\u4f18\u52bf\uff0c\u8dcc\u5012\u6062\u590d\u4f5c\u4e3a\u5173\u952e\u80fd\u529b\u80fd\u589e\u5f3a\u5b89\u5168\u6027\u548c\u81ea\u4e3b\u6027\u3002\u8111\u4f53\u534f\u540c\u8bbe\u8ba1\u901a\u8fc7\u8054\u5408\u4f18\u5316\u63a7\u5236\u7b56\u7565\u548c\u7269\u7406\u5f62\u6001\u6765\u5b9e\u73b0\u8fd9\u4e00\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u5171\u4eab\u7b56\u7565\u5728\u591a\u8bbe\u8ba1\u4e0a\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u5728\u9ad8\u6027\u80fd\u5f62\u6001\u4e0a\u9010\u6b65\u5fae\u8c03\uff1b\u5f62\u6001\u641c\u7d22\u53d7\u4eba\u7c7b\u542f\u53d1\u5148\u9a8c\u548c\u4f18\u5316\u7b97\u6cd5\u6307\u5bfc\uff0c\u4f7f\u7528\u4f18\u5148\u7ea7\u7f13\u51b2\u533a\u5e73\u8861\u6709\u524d\u666f\u5019\u9009\u7684\u91cd\u65b0\u8bc4\u4f30\u548c\u65b0\u8bbe\u8ba1\u7684\u63a2\u7d22\u3002", "result": "\u57287\u4e2a\u516c\u5f00\u4eba\u5f62\u673a\u5668\u4eba\u4e0a\u5e73\u5747\u6027\u80fd\u63d0\u534744.55%\uff0c\u5f62\u6001\u4f18\u5316\u57284\u4e2a\u4eba\u5f62\u673a\u5668\u4eba\u534f\u540c\u8bbe\u8ba1\u4e2d\u8d21\u732e\u81f3\u5c1140%\u7684\u6539\u8fdb\u3002", "conclusion": "\u4eba\u5f62\u673a\u5668\u4eba\u534f\u540c\u8bbe\u8ba1\u5728\u63d0\u5347\u8dcc\u5012\u6062\u590d\u6027\u80fd\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u5f62\u6001\u4f18\u5316\u662f\u6027\u80fd\u63d0\u5347\u7684\u91cd\u8981\u9a71\u52a8\u56e0\u7d20\u3002"}}
{"id": "2510.22333", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.22333", "abs": "https://arxiv.org/abs/2510.22333", "authors": ["Xiao Hu", "Yuansheng Lian", "Ke Zhang", "Yunxuan Li", "Yuelong Su", "Meng Li"], "title": "LIFT: Interpretable truck driving risk prediction with literature-informed fine-tuned LLMs", "comment": null, "summary": "This study proposes an interpretable prediction framework with\nliterature-informed fine-tuned (LIFT) LLMs for truck driving risk prediction.\nThe framework integrates an LLM-driven Inference Core that predicts and\nexplains truck driving risk, a Literature Processing Pipeline that filters and\nsummarizes domain-specific literature into a literature knowledge base, and a\nResult Evaluator that evaluates the prediction performance as well as the\ninterpretability of the LIFT LLM. After fine-tuning on a real-world truck\ndriving risk dataset, the LIFT LLM achieved accurate risk prediction,\noutperforming benchmark models by 26.7% in recall and 10.1% in F1-score.\nFurthermore, guided by the literature knowledge base automatically constructed\nfrom 299 domain papers, the LIFT LLM produced variable importance ranking\nconsistent with that derived from the benchmark model, while demonstrating\nrobustness in interpretation results to various data sampling conditions. The\nLIFT LLM also identified potential risky scenarios by detecting key combination\nof variables in truck driving risk, which were verified by PERMANOVA tests.\nFinally, we demonstrated the contribution of the literature knowledge base and\nthe fine-tuning process in the interpretability of the LIFT LLM, and discussed\nthe potential of the LIFT LLM in data-driven knowledge discovery.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6587\u732e\u4fe1\u606f\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b(LIFT LLM)\u7684\u53ef\u89e3\u91ca\u9884\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u5361\u8f66\u9a7e\u9a76\u98ce\u9669\u9884\u6d4b\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u51c6\u6a21\u578b\uff0c\u5e76\u80fd\u4ea7\u751f\u4e0e\u57fa\u51c6\u6a21\u578b\u4e00\u81f4\u7684\u53d8\u91cf\u91cd\u8981\u6027\u6392\u5e8f\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u5361\u8f66\u9a7e\u9a76\u98ce\u9669\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u7ed3\u679c\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u9886\u57df\u6587\u732e\u77e5\u8bc6\u6765\u589e\u5f3a\u6a21\u578b\u7684\u89e3\u91ca\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542bLLM\u9a71\u52a8\u63a8\u7406\u6838\u5fc3\u3001\u6587\u732e\u5904\u7406\u7ba1\u9053\u548c\u7ed3\u679c\u8bc4\u4f30\u5668\u7684\u6846\u67b6\uff0c\u901a\u8fc7299\u7bc7\u9886\u57df\u6587\u732e\u6784\u5efa\u77e5\u8bc6\u5e93\uff0c\u5e76\u5728\u771f\u5b9e\u5361\u8f66\u9a7e\u9a76\u98ce\u9669\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\u3002", "result": "LIFT LLM\u5728\u53ec\u56de\u7387\u4e0a\u6bd4\u57fa\u51c6\u6a21\u578b\u63d0\u9ad826.7%\uff0cF1\u5206\u6570\u63d0\u9ad810.1%\uff0c\u53d8\u91cf\u91cd\u8981\u6027\u6392\u5e8f\u4e0e\u57fa\u51c6\u6a21\u578b\u4e00\u81f4\uff0c\u5e76\u80fd\u8bc6\u522b\u6f5c\u5728\u98ce\u9669\u573a\u666f\u3002", "conclusion": "LIFT LLM\u6846\u67b6\u5728\u5361\u8f66\u9a7e\u9a76\u98ce\u9669\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6587\u732e\u77e5\u8bc6\u5e93\u548c\u5fae\u8c03\u8fc7\u7a0b\u5bf9\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u6709\u91cd\u8981\u8d21\u732e\uff0c\u5177\u6709\u6570\u636e\u9a71\u52a8\u77e5\u8bc6\u53d1\u73b0\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.23551", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.23551", "abs": "https://arxiv.org/abs/2510.23551", "authors": ["Oleksii Molodchyk", "Hendrik Dr\u00f6gehorn", "Martin Lindner", "Mario Kendziorski", "Timm Faulwasser"], "title": "Towards Stochastic (N-1)-Secure Redispatch", "comment": "7 pages, 1 figure", "summary": "The intermittent nature of renewable power availability is one of the major\nsources of uncertainty in power systems. While markets can guarantee that the\ndemand is covered by the available generation, transmission system operators\nhave to often intervene via economic redispatch to ensure that the physical\nconstraints of the network are satisfied. To account for uncertainty, the\nunderlying optimal power flow (OPF) routines have to be modified. Recently,\npolynomial chaos expansion (PCE) has been suggested in the literature as a tool\nfor stochastic OPF problems. However, the usage of PCE-based methods in\nsecurity-constrained OPF for (N-1)-secure operations has not yet been explored.\nIn this paper, we propose a procedure that iteratively solves a PCE-overloaded\nstochastic OPF problem by including line outage constraints until an\n(N-1)-secure solution is achieved. We demonstrate the efficacy of our method by\ncomparing it with a Monte-Carlo simulation on a 118-bus example system.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u9879\u5f0f\u6df7\u6c8c\u5c55\u5f00\u7684\u8fed\u4ee3\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u7684(N-1)\u5b89\u5168\u7ea6\u675f\u6700\u4f18\u6f6e\u6d41\u95ee\u9898", "motivation": "\u53ef\u518d\u751f\u80fd\u6e90\u7684\u95f4\u6b47\u6027\u7ed9\u7535\u529b\u7cfb\u7edf\u5e26\u6765\u4e0d\u786e\u5b9a\u6027\uff0c\u4f20\u7edf\u6700\u4f18\u6f6e\u6d41\u65b9\u6cd5\u9700\u8981\u6539\u8fdb\u4ee5\u5904\u7406\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\uff0c\u800c\u73b0\u6709PCE\u65b9\u6cd5\u5c1a\u672a\u5e94\u7528\u4e8e(N-1)\u5b89\u5168\u7ea6\u675f\u573a\u666f", "method": "\u91c7\u7528\u8fed\u4ee3\u6c42\u89e3PCE\u8fc7\u8f7d\u968f\u673a\u6700\u4f18\u6f6e\u6d41\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u9010\u6b65\u5305\u542b\u7ebf\u8def\u505c\u8fd0\u7ea6\u675f\uff0c\u76f4\u5230\u83b7\u5f97(N-1)\u5b89\u5168\u89e3", "result": "\u5728118\u8282\u70b9\u6d4b\u8bd5\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e0e\u8499\u7279\u5361\u6d1b\u6a21\u62df\u8fdb\u884c\u4e86\u6bd4\u8f83", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684(N-1)\u5b89\u5168\u7ea6\u675f\u6700\u4f18\u6f6e\u6d41\u95ee\u9898"}}
{"id": "2510.22339", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22339", "abs": "https://arxiv.org/abs/2510.22339", "authors": ["Enyi Wang", "Zhen Deng", "Chuanchuan Pan", "Bingwei He", "Jianwei Zhang"], "title": "Estimating Continuum Robot Shape under External Loading using Spatiotemporal Neural Networks", "comment": "2025 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS)", "summary": "This paper presents a learning-based approach for accurately estimating the\n3D shape of flexible continuum robots subjected to external loads. The proposed\nmethod introduces a spatiotemporal neural network architecture that fuses\nmulti-modal inputs, including current and historical tendon displacement data\nand RGB images, to generate point clouds representing the robot's deformed\nconfiguration. The network integrates a recurrent neural module for temporal\nfeature extraction, an encoding module for spatial feature extraction, and a\nmulti-modal fusion module to combine spatial features extracted from visual\ndata with temporal dependencies from historical actuator inputs. Continuous 3D\nshape reconstruction is achieved by fitting B\\'ezier curves to the predicted\npoint clouds. Experimental validation demonstrates that our approach achieves\nhigh precision, with mean shape estimation errors of 0.08 mm (unloaded) and\n0.22 mm (loaded), outperforming state-of-the-art methods in shape sensing for\nTDCRs. The results validate the efficacy of deep learning-based spatiotemporal\ndata fusion for precise shape estimation under loading conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684\u67d4\u6027\u8fde\u7eed\u673a\u5668\u4eba3D\u5f62\u72b6\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u65f6\u7a7a\u795e\u7ecf\u7f51\u7edc\u878d\u5408\u591a\u6a21\u6001\u8f93\u5165\uff08\u808c\u8171\u4f4d\u79fb\u6570\u636e\u548cRGB\u56fe\u50cf\uff09\u6765\u91cd\u5efa\u53d7\u5916\u90e8\u8f7d\u8377\u5f71\u54cd\u7684\u673a\u5668\u4eba\u5f62\u72b6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u67d4\u6027\u8fde\u7eed\u673a\u5668\u4eba\u53d7\u5916\u90e8\u8f7d\u8377\u65f6\u7684\u5f62\u72b6\u4f30\u8ba1\u7cbe\u5ea6\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u878d\u5408\u65f6\u7a7a\u4fe1\u606f\u7684\u591a\u6a21\u6001\u65b9\u6cd5\u6765\u63d0\u9ad8\u5f62\u72b6\u611f\u77e5\u7cbe\u5ea6\u3002", "method": "\u91c7\u7528\u65f6\u7a7a\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5305\u542b\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u6a21\u5757\u63d0\u53d6\u65f6\u95f4\u7279\u5f81\u3001\u7f16\u7801\u6a21\u5757\u63d0\u53d6\u7a7a\u95f4\u7279\u5f81\uff0c\u4ee5\u53ca\u591a\u6a21\u6001\u878d\u5408\u6a21\u5757\u7ed3\u5408\u89c6\u89c9\u7a7a\u95f4\u7279\u5f81\u548c\u5386\u53f2\u6267\u884c\u5668\u8f93\u5165\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u901a\u8fc7\u62df\u5408B\u00e9zier\u66f2\u7ebf\u5b9e\u73b0\u8fde\u7eed3D\u5f62\u72b6\u91cd\u5efa\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\u8be5\u65b9\u6cd5\u8fbe\u5230\u9ad8\u7cbe\u5ea6\uff0c\u5e73\u5747\u5f62\u72b6\u4f30\u8ba1\u8bef\u5dee\u4e3a0.08\u6beb\u7c73\uff08\u65e0\u8f7d\u8377\uff09\u548c0.22\u6beb\u7c73\uff08\u6709\u8f7d\u8377\uff09\uff0c\u5728TDCR\u5f62\u72b6\u611f\u77e5\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u9a71\u52a8\u7684\u65f6\u7a7a\u6570\u636e\u878d\u5408\u65b9\u6cd5\u5728\u8f7d\u8377\u6761\u4ef6\u4e0b\u80fd\u591f\u5b9e\u73b0\u7cbe\u786e\u7684\u5f62\u72b6\u4f30\u8ba1\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.22340", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.22340", "abs": "https://arxiv.org/abs/2510.22340", "authors": ["Changti Wu", "Shijie Lian", "Zihao Liu", "Lei Zhang", "Laurence Tianruo Yang", "Kai Chen"], "title": "DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical Reasoning of VLMs in Solid Geometry", "comment": "The code and dataset are available at\n  \\href{https://zgca-ai4edu.github.io/DynaSolidGeo/}{DynaSolidGeo}", "summary": "Solid geometry problem solving demands spatial mathematical reasoning that\nintegrates spatial intelligence and symbolic reasoning. However, most existing\nmultimodal mathematical reasoning benchmarks focus primarily on 2D plane\ngeometry, rely on static datasets prone to data contamination and memorization,\nand evaluate models solely by final answers, overlooking the reasoning process.\nTo address these limitations, we introduce DynaSolidGeo, the first dynamic\nbenchmark for evaluating genuine spatial reasoning in Vision-Language Models\n(VLMs). Constructed through a semi-automatic annotation pipeline, DynaSolidGeo\ncontains 503 expert-curated seed questions that can, in principle, dynamically\ngenerate an unbounded number of diverse multimodal text-visual instances.\nBeyond answer accuracy, we incorporate process evaluation based on\nexpert-annotated reasoning chains to measure logical validity and causal\ncoherence. Experiments across representative open-source and closed-source VLMs\nreveal large performance gaps, severe degradation in dynamic settings, and poor\nperformance on tasks requiring high-level spatial intelligence, such as mental\nrotation and visualization. The code and dataset are available at\n\\href{https://zgca-ai4edu.github.io/DynaSolidGeo/}{DynaSolidGeo}.", "AI": {"tldr": "\u63d0\u51fa\u4e86DynaSolidGeo\uff0c\u7b2c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u771f\u5b9e\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u7684\u52a8\u6001\u57fa\u51c6\uff0c\u4e13\u6ce8\u4e8e\u7acb\u4f53\u51e0\u4f55\u95ee\u9898\uff0c\u5305\u542b503\u4e2a\u4e13\u5bb6\u7b56\u5212\u7684\u79cd\u5b50\u95ee\u9898\uff0c\u53ef\u52a8\u6001\u751f\u6210\u65e0\u9650\u591a\u6837\u7684\u591a\u6a21\u6001\u5b9e\u4f8b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce82D\u5e73\u9762\u51e0\u4f55\uff0c\u4f9d\u8d56\u9759\u6001\u6570\u636e\u96c6\u6613\u53d7\u6570\u636e\u6c61\u67d3\u548c\u8bb0\u5fc6\u5f71\u54cd\uff0c\u4e14\u4ec5\u8bc4\u4f30\u6700\u7ec8\u7b54\u6848\u800c\u5ffd\u7565\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u901a\u8fc7\u534a\u81ea\u52a8\u6807\u6ce8\u6d41\u7a0b\u6784\u5efa\uff0c\u5305\u542b\u4e13\u5bb6\u6807\u6ce8\u7684\u63a8\u7406\u94fe\u8fdb\u884c\u8fc7\u7a0b\u8bc4\u4f30\uff0c\u6d4b\u91cf\u903b\u8f91\u6709\u6548\u6027\u548c\u56e0\u679c\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u4ee3\u8868\u6027VLMs\u5b58\u5728\u8f83\u5927\u6027\u80fd\u5dee\u8ddd\uff0c\u5728\u52a8\u6001\u8bbe\u7f6e\u4e0b\u6027\u80fd\u4e25\u91cd\u4e0b\u964d\uff0c\u5728\u9700\u8981\u9ad8\u6c34\u5e73\u7a7a\u95f4\u667a\u80fd\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "DynaSolidGeo\u586b\u8865\u4e86\u7acb\u4f53\u51e0\u4f55\u63a8\u7406\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u63ed\u793a\u4e86VLMs\u5728\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.22370", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.22370", "abs": "https://arxiv.org/abs/2510.22370", "authors": ["Seyed Ahmad Hosseini Miangoleh", "Amin Jalal Aghdasian", "Farzaneh Abdollahi"], "title": "BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles", "comment": "https://github.com/Amin-A96/BLIP-FusePPO-A-Vision-Language-Deep-Reinforcement-Learning-Framework-for-Lane-Keeping-in-Autonomous.git", "summary": "In this paper, we propose Bootstrapped Language-Image Pretraining-driven\nFused State Representation in Proximal Policy Optimization (BLIP-FusePPO), a\nnovel multimodal reinforcement learning (RL) framework for autonomous\nlane-keeping (LK), in which semantic embeddings generated by a vision-language\nmodel (VLM) are directly fused with geometric states, LiDAR observations, and\nProportional-Integral-Derivative-based (PID) control feedback within the agent\nobservation space. The proposed method lets the agent learn driving rules that\nare aware of their surroundings and easy to understand by combining high-level\nscene understanding from the VLM with low-level control and spatial signals.\nOur architecture brings together semantic, geometric, and control-aware\nrepresentations to make policy learning more robust. A hybrid reward function\nthat includes semantic alignment, LK accuracy, obstacle avoidance, and speed\nregulation helps learning to be more efficient and generalizable. Our method is\ndifferent from the approaches that only use semantic models to shape rewards.\nInstead, it directly embeds semantic features into the state representation.\nThis cuts down on expensive runtime inference and makes sure that semantic\nguidance is always available. The simulation results show that the proposed\nmodel is better at LK stability and adaptability than the best vision-based and\nmultimodal RL baselines in a wide range of difficult driving situations. We\nmake our code publicly available.", "AI": {"tldr": "\u63d0\u51faBLIP-FusePPO\u6846\u67b6\uff0c\u5c06\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u8bed\u4e49\u5d4c\u5165\u4e0e\u51e0\u4f55\u72b6\u6001\u3001LiDAR\u89c2\u6d4b\u548cPID\u63a7\u5236\u53cd\u9988\u878d\u5408\uff0c\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u8f66\u9053\u4fdd\u6301\u4efb\u52a1\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4ec5\u4f7f\u7528\u8bed\u4e49\u6a21\u578b\u6765\u5851\u9020\u5956\u52b1\uff0c\u800c\u672c\u65b9\u6cd5\u76f4\u63a5\u5c06\u8bed\u4e49\u7279\u5f81\u5d4c\u5165\u72b6\u6001\u8868\u793a\uff0c\u51cf\u5c11\u6602\u8d35\u7684\u8fd0\u884c\u65f6\u63a8\u7406\u5e76\u786e\u4fdd\u8bed\u4e49\u6307\u5bfc\u59cb\u7ec8\u53ef\u7528\u3002", "method": "\u901a\u8fc7\u878d\u5408\u8bed\u4e49\u3001\u51e0\u4f55\u548c\u63a7\u5236\u611f\u77e5\u8868\u793a\uff0c\u7ed3\u5408\u5305\u542b\u8bed\u4e49\u5bf9\u9f50\u3001\u8f66\u9053\u4fdd\u6301\u7cbe\u5ea6\u3001\u969c\u788d\u7269\u907f\u8ba9\u548c\u901f\u5ea6\u8c03\u8282\u7684\u6df7\u5408\u5956\u52b1\u51fd\u6570\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u5728\u591a\u79cd\u56f0\u96be\u9a7e\u9a76\u573a\u666f\u4e0b\uff0c\u8be5\u6a21\u578b\u5728\u8f66\u9053\u4fdd\u6301\u7a33\u5b9a\u6027\u548c\u9002\u5e94\u6027\u65b9\u9762\u4f18\u4e8e\u6700\u4f73\u89c6\u89c9\u548c\u591a\u6a21\u6001\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "BLIP-FusePPO\u901a\u8fc7\u76f4\u63a5\u878d\u5408\u8bed\u4e49\u7279\u5f81\u5230\u72b6\u6001\u8868\u793a\uff0c\u5b9e\u73b0\u4e86\u66f4\u9c81\u68d2\u548c\u53ef\u89e3\u91ca\u7684\u81ea\u52a8\u9a7e\u9a76\u7b56\u7565\u5b66\u4e60\u3002"}}
{"id": "2510.22371", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.22371", "abs": "https://arxiv.org/abs/2510.22371", "authors": ["Revanth Rameshkumar", "Jimson Huang", "Yunxin Sun", "Fei Xia", "Abulhair Saparov"], "title": "Reasoning Models Reason Well, Until They Don't", "comment": null, "summary": "Large language models (LLMs) have shown significant progress in reasoning\ntasks. However, recent studies show that transformers and LLMs fail\ncatastrophically once reasoning problems exceed modest complexity. We revisit\nthese findings through the lens of large reasoning models (LRMs) -- LLMs\nfine-tuned with incentives for step-by-step argumentation and\nself-verification. LRM performance on graph and reasoning benchmarks such as\nNLGraph seem extraordinary, with some even claiming they are capable of\ngeneralized reasoning and innovation in reasoning-intensive fields such as\nmathematics, physics, medicine, and law. However, by more carefully scaling the\ncomplexity of reasoning problems, we show existing benchmarks actually have\nlimited complexity. We develop a new dataset, the Deep Reasoning Dataset\n(DeepRD), along with a generative process for producing unlimited examples of\nscalable complexity. We use this dataset to evaluate model performance on graph\nconnectivity and natural language proof planning. We find that the performance\nof LRMs drop abruptly at sufficient complexity and do not generalize. We also\nrelate our LRM results to the distributions of the complexities of large,\nreal-world knowledge graphs, interaction graphs, and proof datasets. We find\nthe majority of real-world examples fall inside the LRMs' success regime, yet\nthe long tails expose substantial failure potential. Our analysis highlights\nthe near-term utility of LRMs while underscoring the need for new methods that\ngeneralize beyond the complexity of examples in the training distribution.", "AI": {"tldr": "\u867d\u7136\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u901a\u8fc7\u66f4\u590d\u6742\u7684\u95ee\u9898\u6d4b\u8bd5\u53d1\u73b0\u5176\u63a8\u7406\u80fd\u529b\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u771f\u6b63\u6cdb\u5316\u5230\u590d\u6742\u63a8\u7406\u4efb\u52a1\u3002", "motivation": "\u91cd\u65b0\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u771f\u5b9e\u80fd\u529b\uff0c\u7279\u522b\u662f\u5f53\u63a8\u7406\u95ee\u9898\u590d\u6742\u5ea6\u8d85\u8fc7\u8bad\u7ec3\u5206\u5e03\u65f6\u7684\u8868\u73b0\u3002", "method": "\u5f00\u53d1\u4e86DeepRD\u6570\u636e\u96c6\uff0c\u5305\u542b\u53ef\u6269\u5c55\u590d\u6742\u5ea6\u7684\u56fe\u8fde\u901a\u6027\u548c\u81ea\u7136\u8bed\u8a00\u8bc1\u660e\u89c4\u5212\u95ee\u9898\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u8db3\u591f\u590d\u6742\u5ea6\u4e0b\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u65e0\u6cd5\u6cdb\u5316\uff0c\u4f46\u5927\u591a\u6570\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u4ecd\u5728\u5176\u6210\u529f\u8303\u56f4\u5185\u3002", "conclusion": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u77ed\u671f\u5185\u5177\u6709\u5b9e\u7528\u6027\uff0c\u4f46\u9700\u8981\u5f00\u53d1\u80fd\u591f\u8d85\u8d8a\u8bad\u7ec3\u5206\u5e03\u590d\u6742\u5ea6\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2510.22420", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.22420", "abs": "https://arxiv.org/abs/2510.22420", "authors": ["Mohammad Ali Labbaf Khaniki", "Fateme Taroodi", "Benyamin Safizadeh"], "title": "A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems", "comment": null, "summary": "Controlling high-dimensional stochastic systems, critical in robotics,\nautonomous vehicles, and hyperchaotic systems, faces the curse of\ndimensionality, lacks temporal abstraction, and often fails to ensure\nstochastic stability. To overcome these limitations, this study introduces the\nMulti-Timescale Lyapunov-Constrained Hierarchical Reinforcement Learning\n(MTLHRL) framework. MTLHRL integrates a hierarchical policy within a\nsemi-Markov Decision Process (SMDP), featuring a high-level policy for\nstrategic planning and a low-level policy for reactive control, which\neffectively manages complex, multi-timescale decision-making and reduces\ndimensionality overhead. Stability is rigorously enforced using a neural\nLyapunov function optimized via Lagrangian relaxation and multi-timescale\nactor-critic updates, ensuring mean-square boundedness or asymptotic stability\nin the face of stochastic dynamics. The framework promotes efficient and\nreliable learning through trust-region constraints and decoupled optimization.\nExtensive simulations on an 8D hyperchaotic system and a 5-DOF robotic\nmanipulator demonstrate MTLHRL's empirical superiority. It significantly\noutperforms baseline methods in both stability and performance, recording the\nlowest error indices (e.g., Integral Absolute Error (IAE): 3.912 in\nhyperchaotic control and IAE: 1.623 in robotics), achieving faster convergence,\nand exhibiting superior disturbance rejection. MTLHRL offers a theoretically\ngrounded and practically viable solution for robust control of complex\nstochastic systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86MTLHRL\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u7b56\u7565\u548cLyapunov\u7ea6\u675f\u89e3\u51b3\u9ad8\u7ef4\u968f\u673a\u7cfb\u7edf\u7684\u63a7\u5236\u95ee\u9898\uff0c\u5728\u8d85\u6df7\u6c8c\u7cfb\u7edf\u548c\u673a\u5668\u4eba\u63a7\u5236\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u9ad8\u7ef4\u968f\u673a\u7cfb\u7edf\u63a7\u5236\u9762\u4e34\u7684\u7ef4\u5ea6\u707e\u96be\u3001\u7f3a\u4e4f\u65f6\u95f4\u62bd\u8c61\u548c\u968f\u673a\u7a33\u5b9a\u6027\u4fdd\u8bc1\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u534a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u9ad8\u5c42\u7b56\u7565\u8fdb\u884c\u6218\u7565\u89c4\u5212\uff0c\u4f4e\u5c42\u7b56\u7565\u8fdb\u884c\u53cd\u5e94\u63a7\u5236\uff0c\u901a\u8fc7\u795e\u7ecfLyapunov\u51fd\u6570\u548c\u62c9\u683c\u6717\u65e5\u677e\u5f1b\u4f18\u5316\u786e\u4fdd\u7a33\u5b9a\u6027\u3002", "result": "\u57288D\u8d85\u6df7\u6c8c\u7cfb\u7edf\u548c5\u81ea\u7531\u5ea6\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0cIAE\u8bef\u5dee\u5206\u522b\u4e3a3.912\u548c1.623\uff0c\u6536\u655b\u66f4\u5feb\uff0c\u6297\u5e72\u6270\u80fd\u529b\u66f4\u5f3a\u3002", "conclusion": "MTLHRL\u4e3a\u590d\u6742\u968f\u673a\u7cfb\u7edf\u7684\u9c81\u68d2\u63a7\u5236\u63d0\u4f9b\u4e86\u7406\u8bba\u4e25\u8c28\u4e14\u5b9e\u9645\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.22437", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.22437", "abs": "https://arxiv.org/abs/2510.22437", "authors": ["G M Shahariar", "Ali Nazari", "Erfan Shayegani", "Nael Abu-Ghazaleh"], "title": "Modeling Hierarchical Thinking in Large Reasoning Models", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable reasoning abilities\nwhen they generate step-by-step solutions, known as chain-of-thought (CoT)\nreasoning. When trained to using chain-of-thought reasoning examples, the\nresulting models (called Large Reasoning Models, or LRMs) appear to learn\nhierarchical thinking strategies similar to those used by humans. However,\nunderstanding LRMs emerging reasoning capabilities remains a difficult open\nproblem, with many potential important applications including improving\ntraining and understanding robustness. In this paper, we adopt a memoryless\nFinite State Machine formulation to approximate LRM's emerging hierarchical\nreasoning dynamics as a structured, interpretable abstraction. We identify a\nsmall set of discrete reasoning states including - initialization, deduction,\naugmentation-strategy, uncertainty-estimation, backtracking, and\nfinal-conclusion that capture the high-level states present in the model's\nreasoning process. By annotating each step of a model's CoT with these states,\nwe can represent the reasoning trajectory as a transition sequence through the\nstate graph. This FSM formulation provides a systematic way to analyze,\ninterpret and visualize how different models approach problems. We describe the\nFSM model, provide examples of CoT annotations under this scheme, and discuss\nhow it can shed light on differences between available models in their approach\nto reasoning. Our results demonstrate that this FSM-based analysis reveals\ndistinct reasoning patterns and potential shortcomings, offering a new lens to\nevaluate and improve LLM reasoning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u65e0\u8bb0\u5fc6\u6709\u9650\u72b6\u6001\u673a\uff08FSM\uff09\u6765\u8fd1\u4f3c\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRM\uff09\u7684\u5c42\u6b21\u63a8\u7406\u52a8\u6001\uff0c\u5c06\u5176\u8868\u793a\u4e3a\u7ed3\u6784\u5316\u3001\u53ef\u89e3\u91ca\u7684\u62bd\u8c61\uff0c\u4ee5\u5206\u6790LLM\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "motivation": "\u7406\u89e3\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRM\uff09\u51fa\u73b0\u7684\u63a8\u7406\u80fd\u529b\u662f\u4e00\u4e2a\u56f0\u96be\u7684\u5f00\u653e\u95ee\u9898\uff0c\u8fd9\u5bf9\u4e8e\u6539\u8fdb\u8bad\u7ec3\u548c\u7406\u89e3\u9c81\u68d2\u6027\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002", "method": "\u91c7\u7528\u65e0\u8bb0\u5fc6\u6709\u9650\u72b6\u6001\u673a\uff08FSM\uff09\u6765\u8fd1\u4f3cLRM\u7684\u5c42\u6b21\u63a8\u7406\u52a8\u6001\uff0c\u8bc6\u522b\u79bb\u6563\u63a8\u7406\u72b6\u6001\uff08\u521d\u59cb\u5316\u3001\u6f14\u7ece\u3001\u589e\u5f3a\u7b56\u7565\u3001\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3001\u56de\u6eaf\u3001\u6700\u7ec8\u7ed3\u8bba\uff09\uff0c\u5e76\u5c06\u63a8\u7406\u8f68\u8ff9\u8868\u793a\u4e3a\u72b6\u6001\u56fe\u4e2d\u7684\u8f6c\u79fb\u5e8f\u5217\u3002", "result": "FSM\u5206\u6790\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u5728\u63a8\u7406\u65b9\u6cd5\u4e0a\u7684\u660e\u663e\u63a8\u7406\u6a21\u5f0f\u548c\u6f5c\u5728\u7f3a\u9677\uff0c\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdbLLM\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "conclusion": "FSM\u516c\u5f0f\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u5206\u6790\u548c\u53ef\u89c6\u5316\u4e0d\u540c\u6a21\u578b\u5982\u4f55\u89e3\u51b3\u95ee\u9898\uff0c\u4e3a\u7406\u89e3LLM\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u3001\u53ef\u89e3\u91ca\u7684\u62bd\u8c61\u6846\u67b6\u3002"}}
{"id": "2510.22448", "categories": ["cs.RO", "I.2.9"], "pdf": "https://arxiv.org/pdf/2510.22448", "abs": "https://arxiv.org/abs/2510.22448", "authors": ["Pranup Chhetri", "Alejandro Torrejon", "Sergio Eslava", "Luis J. Manso"], "title": "A short methodological review on social robot navigation benchmarking", "comment": "18 pages, 14 of which references. 3 figures, 2 tables", "summary": "Social Robot Navigation is the skill that allows robots to move efficiently\nin human-populated environments while ensuring safety, comfort, and trust.\nUnlike other areas of research, the scientific community has not yet achieved\nan agreement on how Social Robot Navigation should be benchmarked. This is\nnotably important, as the lack of a de facto standard to benchmark Social Robot\nNavigation can hinder the progress of the field and may lead to contradicting\nconclusions. Motivated by this gap, we contribute with a short review focused\nexclusively on benchmarking trends in the period from January 2020 to July\n2025. Of the 130 papers identified by our search using IEEE Xplore, we analysed\nthe 85 papers that met the criteria of the review. This review addresses the\nmetrics used in the literature for benchmarking purposes, the algorithms\nemployed in such benchmarks, the use of human surveys for benchmarking, and how\nconclusions are drawn from the benchmarking results, when applicable.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5bf92020\u5e741\u6708\u81f32025\u5e747\u6708\u671f\u95f4\u793e\u4f1a\u673a\u5668\u4eba\u5bfc\u822a\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\u8d8b\u52bf\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u56de\u987e\uff0c\u5206\u6790\u4e8685\u7bc7\u76f8\u5173\u8bba\u6587\uff0c\u91cd\u70b9\u5173\u6ce8\u57fa\u51c6\u6d4b\u8bd5\u6307\u6807\u3001\u7b97\u6cd5\u3001\u4eba\u7c7b\u8c03\u67e5\u4f7f\u7528\u60c5\u51b5\u4ee5\u53ca\u7ed3\u8bba\u63a8\u5bfc\u65b9\u5f0f\u3002", "motivation": "\u793e\u4f1a\u673a\u5668\u4eba\u5bfc\u822a\u9886\u57df\u7f3a\u4e4f\u7edf\u4e00\u7684\u57fa\u51c6\u6d4b\u8bd5\u6807\u51c6\uff0c\u8fd9\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u5e76\u53ef\u80fd\u5bfc\u81f4\u76f8\u4e92\u77db\u76fe\u7684\u7ed3\u8bba\u3002\u4f5c\u8005\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7IEEE Xplore\u6570\u636e\u5e93\u8bc6\u522b\u4e86130\u7bc7\u8bba\u6587\uff0c\u6700\u7ec8\u5206\u6790\u4e86\u7b26\u5408\u6807\u51c6\u768485\u7bc7\u8bba\u6587\uff0c\u7cfb\u7edf\u56de\u987e\u4e86\u57fa\u51c6\u6d4b\u8bd5\u7684\u6307\u6807\u3001\u7b97\u6cd5\u3001\u4eba\u7c7b\u8c03\u67e5\u4f7f\u7528\u548c\u7ed3\u8bba\u63a8\u5bfc\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u793e\u4f1a\u673a\u5668\u4eba\u5bfc\u822a\u9886\u57df\u5728\u57fa\u51c6\u6d4b\u8bd5\u65b9\u9762\u5b58\u5728\u6807\u51c6\u5316\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e0d\u540c\u7814\u7a76\u4f7f\u7528\u7684\u6307\u6807\u548c\u65b9\u6cd5\u5dee\u5f02\u8f83\u5927\u3002", "conclusion": "\u8be5\u9886\u57df\u8feb\u5207\u9700\u8981\u5efa\u7acb\u7edf\u4e00\u7684\u57fa\u51c6\u6d4b\u8bd5\u6807\u51c6\uff0c\u4ee5\u4fc3\u8fdb\u793e\u4f1a\u673a\u5668\u4eba\u5bfc\u822a\u7814\u7a76\u7684\u53ef\u6bd4\u6027\u548c\u8fdb\u6b65\u3002"}}
{"id": "2510.22462", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22462", "abs": "https://arxiv.org/abs/2510.22462", "authors": ["Abhijnan Nath", "Nikhil Krishnaswamy"], "title": "Learning \"Partner-Aware\" Collaborators in Multi-Party Collaboration", "comment": null, "summary": "Large Language Models (LLMs) are increasingly bring deployed in agentic\nsettings where they act as collaborators with humans. Therefore, it is\nincreasingly important to be able to evaluate their abilities to collaborate\neffectively in multi-turn, multi-party tasks. In this paper, we build on the AI\nalignment and safe interruptability literature to offer novel theoretical\ninsights on collaborative behavior between LLM-driven collaborator agents and\nan intervention agent. Our goal is to learn an ideal partner-aware collaborator\nthat increases the group's common-ground (CG)-alignment on task-relevant\npropositions-by intelligently collecting information provided in interventions\nby a partner agent.We show how LLM agents trained using standard RLHF and\nrelated approaches are naturally inclined to ignore possibly well-meaning\ninterventions, which makes increasing group common ground non-trivial in this\nsetting. We employ a two-player Modified-Action MDP to examine this suboptimal\nbehavior of standard AI agents, and propose Interruptible Collaborative\nRoleplayer (ICR)-a novel partner-aware learning algorithm to train CG-optimal\ncollaborators. Experiments on multiple collaborative task environments show\nthat ICR, on average, is more capable of promoting successful CG convergence\nand exploring more diverse solutions in such tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u4e2d\u65ad\u534f\u4f5c\u89d2\u8272\u626e\u6f14\u8005(ICR)\u7b97\u6cd5\uff0c\u7528\u4e8e\u8bad\u7ec3LLM\u9a71\u52a8\u7684\u534f\u4f5c\u4ee3\u7406\uff0c\u4f7f\u5176\u80fd\u591f\u66f4\u597d\u5730\u63a5\u53d7\u5408\u4f5c\u4f19\u4f34\u7684\u5e72\u9884\uff0c\u4ece\u800c\u63d0\u9ad8\u56e2\u961f\u5728\u4efb\u52a1\u76f8\u5173\u547d\u9898\u4e0a\u7684\u5171\u540c\u57fa\u7840\u5bf9\u9f50\u5ea6\u3002", "motivation": "\u968f\u7740LLM\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u90e8\u7f72\u5728\u4ee3\u7406\u73af\u5883\u4e2d\u4e0e\u4eba\u7c7b\u534f\u4f5c\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5728\u591a\u8f6e\u3001\u591a\u65b9\u4efb\u52a1\u4e2d\u7684\u534f\u4f5c\u80fd\u529b\u3002\u73b0\u6709LLM\u4ee3\u7406\u5728\u6807\u51c6RLHF\u8bad\u7ec3\u4e0b\u503e\u5411\u4e8e\u5ffd\u7565\u5408\u4f5c\u4f19\u4f34\u7684\u5e72\u9884\uff0c\u8fd9\u4f7f\u5f97\u63d0\u9ad8\u56e2\u961f\u5171\u540c\u57fa\u7840\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u4f7f\u7528\u4e24\u73a9\u5bb6\u4fee\u6539\u52a8\u4f5cMDP\u5206\u6790\u6807\u51c6AI\u4ee3\u7406\u7684\u6b21\u4f18\u884c\u4e3a\uff0c\u63d0\u51faICR\u7b97\u6cd5\u2014\u2014\u4e00\u79cd\u65b0\u9896\u7684\u5408\u4f5c\u4f19\u4f34\u611f\u77e5\u5b66\u4e60\u7b97\u6cd5\uff0c\u7528\u4e8e\u8bad\u7ec3\u5171\u540c\u57fa\u7840\u6700\u4f18\u7684\u534f\u4f5c\u4ee3\u7406\u3002", "result": "\u5728\u591a\u4e2a\u534f\u4f5c\u4efb\u52a1\u73af\u5883\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0cICR\u5e73\u5747\u66f4\u80fd\u4fc3\u8fdb\u6210\u529f\u7684\u5171\u540c\u57fa\u7840\u6536\u655b\uff0c\u5e76\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e2d\u63a2\u7d22\u66f4\u591a\u6837\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "ICR\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3LLM\u4ee3\u7406\u5728\u534f\u4f5c\u4efb\u52a1\u4e2d\u5ffd\u7565\u5408\u4f5c\u4f19\u4f34\u5e72\u9884\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u56e2\u961f\u534f\u4f5c\u6548\u7387\u548c\u5171\u540c\u57fa\u7840\u5bf9\u9f50\u5ea6\u3002"}}
{"id": "2510.22465", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22465", "abs": "https://arxiv.org/abs/2510.22465", "authors": ["Sourabh Karmakar", "Cameron J. Turner"], "title": "Forward Kinematics Solution For A General Stewart Platform Through Iteration Based Simulation", "comment": null, "summary": "This paper presents a method to generate feasible, unique forward-kinematic\nsolutions for a general Stewart platform. This is done by using inverse\nkinematics to obtain valid workspace data and corresponding actuator lengths\nfor the moving platform. For parallel kinematic machines, such as the Stewart\nPlatform, inverse kinematics are straight forward, but the forward kinematics\nare complex and generates multiple solutions due to the closed loop structure\nof the kinematic links. In this research, a simple iterative algorithm has been\nused employing modified Denavit-Hartenberg convention. The outcome is\nencouraging as this method generates a single feasible forward kinematic\nsolution for each valid pose with the solved DH parameters and unlike earlier\nforward kinematics solutions, this unique solution does not need to be manually\nverified. Therefore, the forward kinematic solutions can be used directly for\nfurther calculations without the need for manual pose verification. This\ncapability is essential for the six degree of freedom materials testing system\ndeveloped by the authors in their laboratory. The developed system is aimed at\ncharacterizing additively manufactured materials under complex combined\nmultiple loading conditions. The material characterization is done by enabling\nhigh precision force control on the moving platform via in situ calibration of\nthe as-built kinematics of the Stewart Gough Platform.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e3a\u901a\u7528Stewart\u5e73\u53f0\u751f\u6210\u53ef\u884c\u3001\u552f\u4e00\u6b63\u5411\u8fd0\u52a8\u5b66\u89e3\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u9006\u8fd0\u52a8\u5b66\u83b7\u53d6\u6709\u6548\u5de5\u4f5c\u7a7a\u95f4\u6570\u636e\u548c\u5bf9\u5e94\u7684\u6267\u884c\u5668\u957f\u5ea6\uff0c\u901a\u8fc7\u6539\u8fdb\u7684Denavit-Hartenberg\u7ea6\u5b9a\u5b9e\u73b0\u7b80\u5355\u8fed\u4ee3\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3Stewart\u5e73\u53f0\u7b49\u5e76\u8054\u8fd0\u52a8\u673a\u6784\u7684\u6b63\u5411\u8fd0\u52a8\u5b66\u590d\u6742\u4e14\u4ea7\u751f\u591a\u89e3\u7684\u95ee\u9898\uff0c\u4e3a\u516d\u81ea\u7531\u5ea6\u6750\u6599\u6d4b\u8bd5\u7cfb\u7edf\u63d0\u4f9b\u53ef\u76f4\u63a5\u4f7f\u7528\u7684\u552f\u4e00\u6b63\u5411\u8fd0\u52a8\u5b66\u89e3\u3002", "method": "\u4f7f\u7528\u6539\u8fdb\u7684Denavit-Hartenberg\u7ea6\u5b9a\u7684\u7b80\u5355\u8fed\u4ee3\u7b97\u6cd5\uff0c\u901a\u8fc7\u9006\u8fd0\u52a8\u5b66\u83b7\u53d6\u6709\u6548\u5de5\u4f5c\u7a7a\u95f4\u6570\u636e\u548c\u6267\u884c\u5668\u957f\u5ea6\u3002", "result": "\u8be5\u65b9\u6cd5\u4e3a\u6bcf\u4e2a\u6709\u6548\u4f4d\u59ff\u751f\u6210\u5355\u4e00\u53ef\u884c\u7684\u6b63\u5411\u8fd0\u52a8\u5b66\u89e3\uff0c\u65e0\u9700\u624b\u52a8\u9a8c\u8bc1\u5373\u53ef\u76f4\u63a5\u7528\u4e8e\u8fdb\u4e00\u6b65\u8ba1\u7b97\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86Stewart\u5e73\u53f0\u6b63\u5411\u8fd0\u52a8\u5b66\u7684\u591a\u89e3\u95ee\u9898\uff0c\u4e3a\u6750\u6599\u6d4b\u8bd5\u7cfb\u7edf\u7684\u7cbe\u786e\u529b\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u8fd0\u52a8\u5b66\u57fa\u7840\u3002"}}
{"id": "2510.22535", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.22535", "abs": "https://arxiv.org/abs/2510.22535", "authors": ["Hao Zheng", "Zirui Pang", "Ling li", "Zhijie Deng", "Yuhan Pu", "Zhaowei Zhu", "Xiaobo Xia", "Jiaheng Wei"], "title": "OFFSIDE: Benchmarking Unlearning Misinformation in Multimodal Large Language Models", "comment": null, "summary": "Advances in Multimodal Large Language Models (MLLMs) intensify concerns about\ndata privacy, making Machine Unlearning (MU), the selective removal of learned\ninformation, a critical necessity. However, existing MU benchmarks for MLLMs\nare limited by a lack of image diversity, potential inaccuracies, and\ninsufficient evaluation scenarios, which fail to capture the complexity of\nreal-world applications. To facilitate the development of MLLMs unlearning and\nalleviate the aforementioned limitations, we introduce OFFSIDE, a novel\nbenchmark for evaluating misinformation unlearning in MLLMs based on football\ntransfer rumors. This manually curated dataset contains 15.68K records for 80\nplayers, providing a comprehensive framework with four test sets to assess\nforgetting efficacy, generalization, utility, and robustness. OFFSIDE supports\nadvanced settings like selective unlearning and corrective relearning, and\ncrucially, unimodal unlearning (forgetting only text data). Our extensive\nevaluation of multiple baselines reveals key findings: (1) Unimodal methods\n(erasing text-based knowledge) fail on multimodal rumors; (2) Unlearning\nefficacy is largely driven by catastrophic forgetting; (3) All methods struggle\nwith \"visual rumors\" (rumors appear in the image); (4) The unlearned rumors can\nbe easily recovered and (5) All methods are vulnerable to prompt attacks. These\nresults expose significant vulnerabilities in current approaches, highlighting\nthe need for more robust multimodal unlearning solutions. The code is available\nat\n\\href{https://github.com/zh121800/OFFSIDE}{https://github.com/zh121800/OFFSIDE}.", "AI": {"tldr": "OFFSIDE\u662f\u4e00\u4e2a\u57fa\u4e8e\u8db3\u7403\u8f6c\u4f1a\u8c23\u8a00\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u9057\u5fd8\u57fa\u51c6\uff0c\u5305\u542b15.68K\u6761\u624b\u52a8\u6574\u7406\u7684\u6570\u636e\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728\u9057\u5fd8\u9519\u8bef\u4fe1\u606f\u65b9\u9762\u7684\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u6570\u636e\u9690\u79c1\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u9009\u62e9\u6027\u9057\u5fd8\u5b66\u4e60\u5230\u7684\u4fe1\u606f\u3002\u73b0\u6709\u57fa\u51c6\u5b58\u5728\u56fe\u50cf\u591a\u6837\u6027\u4e0d\u8db3\u3001\u6f5c\u5728\u4e0d\u51c6\u786e\u6027\u548c\u8bc4\u4f30\u573a\u666f\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "method": "\u521b\u5efa\u4e86\u57fa\u4e8e\u8db3\u7403\u8f6c\u4f1a\u8c23\u8a00\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b\u56db\u4e2a\u6d4b\u8bd5\u96c6\u6765\u8bc4\u4f30\u9057\u5fd8\u6548\u679c\u3001\u6cdb\u5316\u6027\u3001\u5b9e\u7528\u6027\u548c\u9c81\u68d2\u6027\uff0c\u652f\u6301\u9009\u62e9\u6027\u9057\u5fd8\u3001\u7ea0\u6b63\u6027\u518d\u5b66\u4e60\u548c\u5355\u6a21\u6001\u9057\u5fd8\u7b49\u9ad8\u7ea7\u8bbe\u7f6e\u3002", "result": "\u8bc4\u4f30\u53d1\u73b0\uff1a\u5355\u6a21\u6001\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u8c23\u8a00\u4e0a\u5931\u8d25\uff1b\u9057\u5fd8\u6548\u679c\u4e3b\u8981\u7531\u707e\u96be\u6027\u9057\u5fd8\u9a71\u52a8\uff1b\u6240\u6709\u65b9\u6cd5\u90fd\u96be\u4ee5\u5904\u7406\"\u89c6\u89c9\u8c23\u8a00\"\uff1b\u9057\u5fd8\u7684\u8c23\u8a00\u5bb9\u6613\u88ab\u6062\u590d\uff1b\u6240\u6709\u65b9\u6cd5\u90fd\u6613\u53d7\u63d0\u793a\u653b\u51fb\u3002", "conclusion": "\u5f53\u524d\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u6f0f\u6d1e\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u591a\u6a21\u6001\u9057\u5fd8\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.22504", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22504", "abs": "https://arxiv.org/abs/2510.22504", "authors": ["Ciera McFarland", "Antonio Alvarez", "Sarah Taher", "Nathaniel Hanson", "Margaret McGuinness"], "title": "On Steerability Factors for Growing Vine Robots", "comment": null, "summary": "Vine robots extend their tubular bodies by everting material from the tip,\nenabling navigation in complex environments with a minimalist soft body.\nDespite their promise for field applications, especially in the urban search\nand rescue domain, performance is constrained by the weight of attached sensors\nor tools, as well as other design and control choices. This work investigates\nhow tip load, pressure, length, diameter, and fabrication method shape vine\nrobot steerability--the ability to maneuver with controlled curvature--for\nrobots that steer with series pouch motor-style pneumatic actuators. We conduct\ntwo groups of experiments: (1) studying tip load, chamber pressure, length, and\ndiameter in a robot supporting itself against gravity, and (2) studying\nfabrication method and ratio of actuator to chamber pressure in a robot\nsupported on the ground. Results show that steerability decreases with\nincreasing tip load, is best at moderate chamber pressure, increases with\nlength, and is largely unaffected by diameter. Robots with actuators attached\non their exterior begin curving at low pressure ratios, but curvature saturates\nat high pressure ratios; those with actuators integrated into the robot body\nrequire higher pressure ratios to begin curving but achieve higher curvature\noverall. We demonstrate that robots optimized with these principles outperform\nthose with ad hoc parameters in a mobility task that involves maximizing upward\nand horizontal curvatures.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u85e4\u8513\u673a\u5668\u4eba\u7684\u53ef\u64cd\u7eb5\u6027\uff0c\u5206\u6790\u4e86\u5c16\u7aef\u8d1f\u8f7d\u3001\u538b\u529b\u3001\u957f\u5ea6\u3001\u76f4\u5f84\u548c\u5236\u9020\u65b9\u6cd5\u5bf9\u673a\u5668\u4eba\u8f6c\u5411\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u5e76\u5c55\u793a\u4e86\u4f18\u5316\u53c2\u6570\u5728\u79fb\u52a8\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\u3002", "motivation": "\u85e4\u8513\u673a\u5668\u4eba\u5728\u590d\u6742\u73af\u5883\u4e2d\u5177\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u4f46\u5176\u6027\u80fd\u53d7\u5230\u9644\u52a0\u4f20\u611f\u5668\u91cd\u91cf\u3001\u8bbe\u8ba1\u9009\u62e9\u548c\u63a7\u5236\u53c2\u6570\u7684\u9650\u5236\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u5f71\u54cd\u8f6c\u5411\u80fd\u529b\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "\u8fdb\u884c\u4e24\u7ec4\u5b9e\u9a8c\uff1a\u7b2c\u4e00\u7ec4\u7814\u7a76\u5728\u91cd\u529b\u652f\u6491\u6761\u4ef6\u4e0b\u5c16\u7aef\u8d1f\u8f7d\u3001\u8154\u5ba4\u538b\u529b\u3001\u957f\u5ea6\u548c\u76f4\u5f84\u7684\u5f71\u54cd\uff1b\u7b2c\u4e8c\u7ec4\u7814\u7a76\u5236\u9020\u65b9\u6cd5\u548c\u6267\u884c\u5668\u4e0e\u8154\u5ba4\u538b\u529b\u6bd4\u5728\u5730\u9762\u652f\u6491\u6761\u4ef6\u4e0b\u7684\u5f71\u54cd\u3002", "result": "\u53ef\u64cd\u7eb5\u6027\u968f\u5c16\u7aef\u8d1f\u8f7d\u589e\u52a0\u800c\u964d\u4f4e\uff0c\u5728\u4e2d\u7b49\u8154\u5ba4\u538b\u529b\u4e0b\u6700\u4f73\uff0c\u968f\u957f\u5ea6\u589e\u52a0\u800c\u63d0\u9ad8\uff0c\u76f4\u5f84\u5f71\u54cd\u4e0d\u5927\u3002\u5916\u7f6e\u6267\u884c\u5668\u7684\u673a\u5668\u4eba\u5728\u4f4e\u538b\u6bd4\u65f6\u5f00\u59cb\u8f6c\u5411\u4f46\u9971\u548c\uff0c\u96c6\u6210\u6267\u884c\u5668\u7684\u9700\u8981\u66f4\u9ad8\u538b\u529b\u6bd4\u4f46\u80fd\u8fbe\u5230\u66f4\u5927\u66f2\u7387\u3002", "conclusion": "\u57fa\u4e8e\u8fd9\u4e9b\u539f\u7406\u4f18\u5316\u7684\u673a\u5668\u4eba\u5728\u6d89\u53ca\u6700\u5927\u5316\u5411\u4e0a\u548c\u6c34\u5e73\u66f2\u7387\u7684\u79fb\u52a8\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4e34\u65f6\u53c2\u6570\u8bbe\u7f6e\u7684\u673a\u5668\u4eba\u3002"}}
{"id": "2510.22590", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.22590", "abs": "https://arxiv.org/abs/2510.22590", "authors": ["Yassir Lairgi", "Ludovic Moncla", "Khalid Benabdeslem", "R\u00e9my Cazabet", "Pierre Cl\u00e9au"], "title": "ATOM: AdapTive and OptiMized dynamic temporal knowledge graph construction using LLMs", "comment": null, "summary": "In today's rapidly expanding data landscape, knowledge extraction from\nunstructured text is vital for real-time analytics, temporal inference, and\ndynamic memory frameworks. However, traditional static knowledge graph (KG)\nconstruction often overlooks the dynamic and time-sensitive nature of\nreal-world data, limiting adaptability to continuous changes. Moreover, recent\nzero- or few-shot approaches that avoid domain-specific fine-tuning or reliance\non prebuilt ontologies often suffer from instability across multiple runs, as\nwell as incomplete coverage of key facts. To address these challenges, we\nintroduce ATOM (AdapTive and OptiMized), a few-shot and scalable approach that\nbuilds and continuously updates Temporal Knowledge Graphs (TKGs) from\nunstructured texts. ATOM splits input documents into minimal, self-contained\n\"atomic\" facts, improving extraction exhaustivity and stability. Then, it\nconstructs atomic TKGs from these facts while employing a dual-time modeling\nthat distinguishes when information is observed from when it is valid. The\nresulting atomic TKGs are subsequently merged in parallel. Empirical\nevaluations demonstrate that ATOM achieves ~18% higher exhaustivity, ~17%\nbetter stability, and over 90% latency reduction compared to baseline methods,\ndemonstrating a strong scalability potential for dynamic TKG construction.", "AI": {"tldr": "ATOM\u662f\u4e00\u4e2a\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u6784\u5efa\u548c\u6301\u7eed\u66f4\u65b0\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u7684\u5c11\u6837\u672c\u53ef\u6269\u5c55\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6587\u6863\u5206\u89e3\u4e3a\u6700\u5c0f\u81ea\u5305\u542b\u7684\u539f\u5b50\u4e8b\u5b9e\uff0c\u91c7\u7528\u53cc\u65f6\u95f4\u5efa\u6a21\u533a\u5206\u4fe1\u606f\u89c2\u6d4b\u65f6\u95f4\u548c\u6709\u6548\u65f6\u95f4\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u63d0\u53d6\u5b8c\u6574\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u5ffd\u7565\u4e86\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u7684\u52a8\u6001\u6027\u548c\u65f6\u6548\u6027\uff0c\u800c\u73b0\u6709\u7684\u96f6\u6837\u672c\u6216\u5c11\u6837\u672c\u65b9\u6cd5\u5b58\u5728\u8de8\u591a\u6b21\u8fd0\u884c\u7684\u4e0d\u7a33\u5b9a\u6027\u548c\u5173\u952e\u4e8b\u5b9e\u8986\u76d6\u4e0d\u5b8c\u6574\u7684\u95ee\u9898\u3002", "method": "\u5c06\u8f93\u5165\u6587\u6863\u5206\u5272\u4e3a\u6700\u5c0f\u81ea\u5305\u542b\u7684\u539f\u5b50\u4e8b\u5b9e\uff0c\u6784\u5efa\u539f\u5b50\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\uff0c\u91c7\u7528\u53cc\u65f6\u95f4\u5efa\u6a21\u533a\u5206\u4fe1\u606f\u89c2\u6d4b\u65f6\u95f4\u548c\u6709\u6548\u65f6\u95f4\uff0c\u7136\u540e\u5e76\u884c\u5408\u5e76\u539f\u5b50\u56fe\u8c31\u3002", "result": "\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0cATOM\u5b9e\u73b0\u4e86\u7ea618%\u7684\u66f4\u9ad8\u5b8c\u6574\u6027\u3001\u7ea617%\u7684\u66f4\u597d\u7a33\u5b9a\u6027\u4ee5\u53ca\u8d85\u8fc790%\u7684\u5ef6\u8fdf\u51cf\u5c11\uff0c\u663e\u793a\u51fa\u52a8\u6001\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u5f3a\u5927\u53ef\u6269\u5c55\u6f5c\u529b\u3002", "conclusion": "ATOM\u65b9\u6cd5\u6709\u6548\u5730\u89e3\u51b3\u4e86\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u539f\u5b50\u4e8b\u5b9e\u5206\u5272\u548c\u53cc\u65f6\u95f4\u5efa\u6a21\uff0c\u5728\u52a8\u6001\u65f6\u5e8f\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2510.22524", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22524", "abs": "https://arxiv.org/abs/2510.22524", "authors": ["Shenbagaraj Kannapiran", "Elena Oikonomou", "Albert Chu", "Spring Berman", "Theodore P. Pavlic"], "title": "Ant-inspired Walling Strategies for Scalable Swarm Separation: Reinforcement Learning Approaches Based on Finite State Machines", "comment": null, "summary": "In natural systems, emergent structures often arise to balance competing\ndemands. Army ants, for example, form temporary \"walls\" that prevent\ninterference between foraging trails. Inspired by this behavior, we developed\ntwo decentralized controllers for heterogeneous robotic swarms to maintain\nspatial separation while executing concurrent tasks. The first is a\nfinite-state machine (FSM)-based controller that uses encounter-triggered\ntransitions to create rigid, stable walls. The second integrates FSM states\nwith a Deep Q-Network (DQN), dynamically optimizing separation through emergent\n\"demilitarized zones.\" In simulation, both controllers reduce mixing between\nsubgroups, with the DQN-enhanced controller improving adaptability and reducing\nmixing by 40-50% while achieving faster convergence.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2510.22594", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.22594", "abs": "https://arxiv.org/abs/2510.22594", "authors": ["Bingqing Song", "Jiaxiang Li", "Rong Wang", "Songtao Lu", "Mingyi Hong"], "title": "A Framework for Quantifying How Pre-Training and Context Benefit In-Context Learning", "comment": null, "summary": "Pre-trained large language models have demonstrated a strong ability to learn\nfrom context, known as in-context learning (ICL). Despite a surge of recent\napplications that leverage such capabilities, it is by no means clear, at least\ntheoretically, how the ICL capabilities arise, and in particular, what is the\nprecise role played by key factors such as pre-training procedure as well as\ncontext construction. In this work, we propose a new framework to analyze the\nICL performance, for a class of realistic settings, which includes network\narchitectures, data encoding, data generation, and prompt construction process.\nAs a first step, we construct a simple example with a one-layer transformer,\nand show an interesting result, namely when the pre-train data distribution is\ndifferent from the query task distribution, a properly constructed context can\nshift the output distribution towards the query task distribution, in a\nquantifiable manner, leading to accurate prediction on the query topic. We then\nextend the findings in the previous step to a more general case, and derive the\nprecise relationship between ICL performance, context length and the KL\ndivergence between pre-train and query task distribution. Finally, we provide\nexperiments to validate our theoretical results.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u6790\u4e0a\u4e0b\u6587\u5b66\u4e60\u6027\u80fd\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u63ed\u793a\u4e86\u9884\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u4e0e\u67e5\u8be2\u4efb\u52a1\u5206\u5e03\u5dee\u5f02\u5bf9ICL\u6027\u80fd\u7684\u5f71\u54cd\u673a\u5236\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u5df2\u88ab\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u7406\u8bba\u673a\u5236\u5c1a\u4e0d\u660e\u786e\uff0c\u7279\u522b\u662f\u9884\u8bad\u7ec3\u8fc7\u7a0b\u548c\u4e0a\u4e0b\u6587\u6784\u5efa\u7b49\u5173\u952e\u56e0\u7d20\u7684\u786e\u5207\u4f5c\u7528\u3002", "method": "\u6784\u5efa\u5305\u542b\u7f51\u7edc\u67b6\u6784\u3001\u6570\u636e\u7f16\u7801\u3001\u6570\u636e\u751f\u6210\u548c\u63d0\u793a\u6784\u5efa\u8fc7\u7a0b\u7684\u73b0\u5b9e\u8bbe\u7f6e\u6846\u67b6\uff0c\u9996\u5148\u7528\u5355\u5c42transformer\u8fdb\u884c\u7b80\u5355\u793a\u4f8b\u5206\u6790\uff0c\u7136\u540e\u6269\u5c55\u5230\u66f4\u4e00\u822c\u60c5\u51b5\uff0c\u63a8\u5bfcICL\u6027\u80fd\u4e0e\u4e0a\u4e0b\u6587\u957f\u5ea6\u53ca\u9884\u8bad\u7ec3-\u67e5\u8be2\u5206\u5e03KL\u6563\u5ea6\u7684\u7cbe\u786e\u5173\u7cfb\u3002", "result": "\u5f53\u9884\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u4e0e\u67e5\u8be2\u4efb\u52a1\u5206\u5e03\u4e0d\u540c\u65f6\uff0c\u9002\u5f53\u6784\u5efa\u7684\u4e0a\u4e0b\u6587\u53ef\u4ee5\u5c06\u8f93\u51fa\u5206\u5e03\u5411\u67e5\u8be2\u4efb\u52a1\u5206\u5e03\u8f6c\u79fb\uff0c\u4ece\u800c\u5b9e\u73b0\u51c6\u786e\u9884\u6d4b\uff1b\u5efa\u7acb\u4e86ICL\u6027\u80fd\u4e0e\u4e0a\u4e0b\u6587\u957f\u5ea6\u53ca\u5206\u5e03\u5dee\u5f02\u7684\u91cf\u5316\u5173\u7cfb\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u7684\u5173\u952e\u5728\u4e8e\u901a\u8fc7\u4e0a\u4e0b\u6587\u8c03\u6574\u6a21\u578b\u8f93\u51fa\u5206\u5e03\uff0c\u4f7f\u5176\u66f4\u63a5\u8fd1\u67e5\u8be2\u4efb\u52a1\u5206\u5e03\uff0c\u8fd9\u79cd\u673a\u5236\u53ef\u4ee5\u901a\u8fc7\u7406\u8bba\u6846\u67b6\u8fdb\u884c\u91cf\u5316\u548c\u5206\u6790\u3002"}}
{"id": "2510.22568", "categories": ["cs.RO", "cs.AI", "cs.MA", "cs.SY", "eess.SY", "I.2.9; I.2.11; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.22568", "abs": "https://arxiv.org/abs/2510.22568", "authors": ["Onur Akg\u00fcn"], "title": "SPIRAL: Self-Play Incremental Racing Algorithm for Learning in Multi-Drone Competitions", "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "This paper introduces SPIRAL (Self-Play Incremental Racing Algorithm for\nLearning), a novel approach for training autonomous drones in multi-agent\nracing competitions. SPIRAL distinctively employs a self-play mechanism to\nincrementally cultivate complex racing behaviors within a challenging, dynamic\nenvironment. Through this self-play core, drones continuously compete against\nincreasingly proficient versions of themselves, naturally escalating the\ndifficulty of competitive interactions. This progressive learning journey\nguides agents from mastering fundamental flight control to executing\nsophisticated cooperative multi-drone racing strategies. Our method is designed\nfor versatility, allowing integration with any state-of-the-art Deep\nReinforcement Learning (DRL) algorithms within its self-play framework.\nSimulations demonstrate the significant advantages of SPIRAL and benchmark the\nperformance of various DRL algorithms operating within it. Consequently, we\ncontribute a versatile, scalable, and self-improving learning framework to the\nfield of autonomous drone racing. SPIRAL's capacity to autonomously generate\nappropriate and escalating challenges through its self-play dynamic offers a\npromising direction for developing robust and adaptive racing strategies in\nmulti-agent environments. This research opens new avenues for enhancing the\nperformance and reliability of autonomous racing drones in increasingly complex\nand competitive scenarios.", "AI": {"tldr": "SPIRAL\u662f\u4e00\u79cd\u7528\u4e8e\u8bad\u7ec3\u81ea\u4e3b\u65e0\u4eba\u673a\u5728\u591a\u667a\u80fd\u4f53\u7ade\u8d5b\u4e2d\u7684\u81ea\u535a\u5f08\u589e\u91cf\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u81ea\u535a\u5f08\u673a\u5236\u9010\u6b65\u57f9\u517b\u590d\u6742\u7ade\u8d5b\u884c\u4e3a\uff0c\u80fd\u591f\u4e0e\u5404\u79cd\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u96c6\u6210\u3002", "motivation": "\u4e3a\u81ea\u4e3b\u65e0\u4eba\u673a\u5728\u591a\u667a\u80fd\u4f53\u7ade\u8d5b\u73af\u5883\u4e2d\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u81ea\u6211\u6539\u8fdb\u3001\u53ef\u6269\u5c55\u7684\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u4e3b\u751f\u6210\u9010\u6b65\u5347\u7ea7\u7684\u6311\u6218\u6765\u57f9\u517b\u9c81\u68d2\u548c\u81ea\u9002\u5e94\u7684\u7ade\u8d5b\u7b56\u7565\u3002", "method": "\u91c7\u7528\u81ea\u535a\u5f08\u673a\u5236\uff0c\u8ba9\u65e0\u4eba\u673a\u4e0e\u4e0d\u65ad\u8fdb\u5316\u7684\u81ea\u8eab\u7248\u672c\u7ade\u4e89\uff0c\u9010\u6b65\u63d0\u5347\u7ade\u4e89\u96be\u5ea6\uff0c\u4ece\u57fa\u7840\u98de\u884c\u63a7\u5236\u5230\u590d\u6742\u591a\u65e0\u4eba\u673a\u534f\u4f5c\u7b56\u7565\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u8868\u660eSPIRAL\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5e76\u57fa\u51c6\u6d4b\u8bd5\u4e86\u5728\u5176\u6846\u67b6\u5185\u8fd0\u884c\u7684\u5404\u79cd\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "SPIRAL\u4e3a\u81ea\u4e3b\u65e0\u4eba\u673a\u7ade\u8d5b\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u591a\u529f\u80fd\u3001\u53ef\u6269\u5c55\u4e14\u81ea\u6211\u6539\u8fdb\u7684\u5b66\u4e60\u6846\u67b6\uff0c\u4e3a\u5728\u65e5\u76ca\u590d\u6742\u548c\u7ade\u4e89\u6fc0\u70c8\u7684\u573a\u666f\u4e2d\u63d0\u5347\u81ea\u4e3b\u7ade\u8d5b\u65e0\u4eba\u673a\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.22609", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22609", "abs": "https://arxiv.org/abs/2510.22609", "authors": ["Md. Mehedi Hasan", "Rafid Mostafiz", "Md. Abir Hossain", "Bikash Kumar Paul"], "title": "CLIN-LLM: A Safety-Constrained Hybrid Framework for Clinical Diagnosis and Treatment Generation", "comment": "13 pages, 9 figures. Preprint version under review in the area of\n  Artificial Intelligence (cs.CR)", "summary": "Accurate symptom-to-disease classification and clinically grounded treatment\nrecommendations remain challenging, particularly in heterogeneous patient\nsettings with high diagnostic risk. Existing large language model (LLM)-based\nsystems often lack medical grounding and fail to quantify uncertainty,\nresulting in unsafe outputs. We propose CLIN-LLM, a safety-constrained hybrid\npipeline that integrates multimodal patient encoding, uncertainty-calibrated\ndisease classification, and retrieval-augmented treatment generation. The\nframework fine-tunes BioBERT on 1,200 clinical cases from the Symptom2Disease\ndataset and incorporates Focal Loss with Monte Carlo Dropout to enable\nconfidence-aware predictions from free-text symptoms and structured vitals.\nLow-certainty cases (18%) are automatically flagged for expert review, ensuring\nhuman oversight. For treatment generation, CLIN-LLM employs Biomedical\nSentence-BERT to retrieve top-k relevant dialogues from the 260,000-sample\nMedDialog corpus. The retrieved evidence and patient context are fed into a\nfine-tuned FLAN-T5 model for personalized treatment generation, followed by\npost-processing with RxNorm for antibiotic stewardship and drug-drug\ninteraction (DDI) screening. CLIN-LLM achieves 98% accuracy and F1 score,\noutperforming ClinicalBERT by 7.1% (p < 0.001), with 78% top-5 retrieval\nprecision and a clinician-rated validity of 4.2 out of 5. Unsafe antibiotic\nsuggestions are reduced by 67% compared to GPT-5. These results demonstrate\nCLIN-LLM's robustness, interpretability, and clinical safety alignment. The\nproposed system provides a deployable, human-in-the-loop decision support\nframework for resource-limited healthcare environments. Future work includes\nintegrating imaging and lab data, multilingual extensions, and clinical trial\nvalidation.", "AI": {"tldr": "CLIN-LLM\u662f\u4e00\u4e2a\u5b89\u5168\u7ea6\u675f\u7684\u6df7\u5408\u7ba1\u9053\u7cfb\u7edf\uff0c\u6574\u5408\u4e86\u591a\u6a21\u6001\u60a3\u8005\u7f16\u7801\u3001\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u7684\u75be\u75c5\u5206\u7c7b\u548c\u68c0\u7d22\u589e\u5f3a\u7684\u6cbb\u7597\u751f\u6210\uff0c\u5728\u75c7\u72b6\u5230\u75be\u75c5\u5206\u7c7b\u548c\u6cbb\u7597\u63a8\u8350\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u533b\u7597\u7cfb\u7edf\u7f3a\u4e4f\u533b\u5b66\u57fa\u7840\u4e14\u65e0\u6cd5\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u5bfc\u81f4\u8f93\u51fa\u4e0d\u5b89\u5168\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u63d0\u4f9b\u5b89\u5168\u3001\u53ef\u89e3\u91ca\u4e14\u4e34\u5e8a\u53ef\u9760\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528BioBERT\u57281,200\u4e2a\u4e34\u5e8a\u6848\u4f8b\u4e0a\u5fae\u8c03\uff0c\u7ed3\u5408Focal Loss\u548cMonte Carlo Dropout\u5b9e\u73b0\u7f6e\u4fe1\u5ea6\u611f\u77e5\u9884\u6d4b\u3002\u91c7\u7528Biomedical Sentence-BERT\u4eceMedDialog\u8bed\u6599\u5e93\u68c0\u7d22\u76f8\u5173\u5bf9\u8bdd\uff0c\u4f7f\u7528\u5fae\u8c03\u7684FLAN-T5\u6a21\u578b\u751f\u6210\u4e2a\u6027\u5316\u6cbb\u7597\u5efa\u8bae\uff0c\u5e76\u901a\u8fc7RxNorm\u8fdb\u884c\u6297\u751f\u7d20\u7ba1\u7406\u548c\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u7b5b\u67e5\u3002", "result": "CLIN-LLM\u8fbe\u523098%\u7684\u51c6\u786e\u7387\u548cF1\u5206\u6570\uff0c\u6bd4ClinicalBERT\u63d0\u53477.1%\uff0c\u68c0\u7d22\u7cbe\u5ea678%\uff0c\u4e34\u5e8a\u6709\u6548\u6027\u8bc4\u52064.2/5\uff0c\u4e0d\u5b89\u5168\u6297\u751f\u7d20\u5efa\u8bae\u6bd4GPT-5\u51cf\u5c1167%\u3002", "conclusion": "CLIN-LLM\u5c55\u793a\u4e86\u7a33\u5065\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u4e34\u5e8a\u5b89\u5168\u6027\uff0c\u4e3a\u8d44\u6e90\u6709\u9650\u7684\u533b\u7597\u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u90e8\u7f72\u7684\u3001\u4eba\u673a\u534f\u4f5c\u7684\u51b3\u7b56\u652f\u6301\u6846\u67b6\u3002"}}
{"id": "2510.22570", "categories": ["cs.RO", "cs.AI", "cs.MA", "cs.SY", "eess.SY", "I.2.9; I.2.11; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.22570", "abs": "https://arxiv.org/abs/2510.22570", "authors": ["Onur Akg\u00fcn"], "title": "Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing", "comment": "13 pages, 5 figures. This paper is currently under review at the\n  journal Engineering Applications of Artificial Intelligence. Supplementary\n  video: https://drive.google.com/file/d/1k7necen2DgIxaYT2alKK8-b20sE_AyDA/view\n  Source code and models: https://doi.org/10.5281/zenodo.17256943", "summary": "The coordination of multiple autonomous agents in high-speed, competitive\nenvironments represents a significant engineering challenge. This paper\npresents CRUISE (Curriculum-Based Iterative Self-Play for Scalable Multi-Drone\nRacing), a reinforcement learning framework designed to solve this challenge in\nthe demanding domain of multi-drone racing. CRUISE overcomes key scalability\nlimitations by synergistically combining a progressive difficulty curriculum\nwith an efficient self-play mechanism to foster robust competitive behaviors.\nValidated in high-fidelity simulation with realistic quadrotor dynamics, the\nresulting policies significantly outperform both a standard reinforcement\nlearning baseline and a state-of-the-art game-theoretic planner. CRUISE\nachieves nearly double the planner's mean racing speed, maintains high success\nrates, and demonstrates robust scalability as agent density increases. Ablation\nstudies confirm that the curriculum structure is the critical component for\nthis performance leap. By providing a scalable and effective training\nmethodology, CRUISE advances the development of autonomous systems for dynamic,\ncompetitive tasks and serves as a blueprint for future real-world deployment.", "AI": {"tldr": "CRUISE\u662f\u4e00\u4e2a\u57fa\u4e8e\u8bfe\u7a0b\u5b66\u4e60\u548c\u81ea\u6211\u535a\u5f08\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u89e3\u51b3\u591a\u65e0\u4eba\u673a\u7ade\u901f\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5728\u4eff\u771f\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u548c\u535a\u5f08\u8bba\u89c4\u5212\u5668\u3002", "motivation": "\u89e3\u51b3\u591a\u81ea\u4e3b\u667a\u80fd\u4f53\u5728\u9ad8\u901f\u7ade\u4e89\u73af\u5883\u4e2d\u7684\u534f\u8c03\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u591a\u65e0\u4eba\u673a\u7ade\u901f\u8fd9\u4e00\u5177\u6709\u6311\u6218\u6027\u7684\u9886\u57df\u4e2d\uff0c\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u6027\u9650\u5236\u3002", "method": "\u7ed3\u5408\u6e10\u8fdb\u96be\u5ea6\u8bfe\u7a0b\u5b66\u4e60\u548c\u9ad8\u6548\u81ea\u6211\u535a\u5f08\u673a\u5236\uff0c\u901a\u8fc7\u8bfe\u7a0b\u7ed3\u6784\u9010\u6b65\u63d0\u5347\u8bad\u7ec3\u96be\u5ea6\uff0c\u57f9\u517b\u9c81\u68d2\u7684\u7ade\u4e89\u884c\u4e3a\u3002", "result": "\u5728\u903c\u771f\u56db\u65cb\u7ffc\u52a8\u529b\u5b66\u4eff\u771f\u4e2d\uff0cCRUISE\u7684\u5e73\u5747\u7ade\u901f\u901f\u5ea6\u8fbe\u5230\u6700\u5148\u8fdb\u535a\u5f08\u8bba\u89c4\u5212\u5668\u7684\u8fd1\u4e24\u500d\uff0c\u4fdd\u6301\u9ad8\u6210\u529f\u7387\uff0c\u5e76\u5728\u667a\u80fd\u4f53\u5bc6\u5ea6\u589e\u52a0\u65f6\u5c55\u73b0\u51fa\u9c81\u68d2\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8bfe\u7a0b\u7ed3\u6784\u662f\u5b9e\u73b0\u6027\u80fd\u7a81\u7834\u7684\u5173\u952e\u56e0\u7d20\uff0cCRUISE\u4e3a\u52a8\u6001\u7ade\u4e89\u4efb\u52a1\u7684\u81ea\u4e3b\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6709\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4e3a\u672a\u6765\u5b9e\u9645\u90e8\u7f72\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.22626", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22626", "abs": "https://arxiv.org/abs/2510.22626", "authors": ["Adhyayan Veer Singh", "Aaron Shen", "Brian Law", "Ahmed Ismail", "Jonas Rohweder", "Sean O'Brien", "Kevin Zhu"], "title": "SwiftSolve: A Self-Iterative, Complexity-Aware Multi-Agent Framework for Competitive Programming", "comment": null, "summary": "Correctness alone is insufficient: LLM-generated programs frequently satisfy\nunit tests while violating contest time or memory budgets. We present\nSwiftSolve, a complexity-aware multi-agent system for competitive programming\nthat couples algorithmic planning with empirical profiling and\ncomplexity-guided repair. We frame competitive programming as a software\nenvironment where specialized agents act as programmers, each assuming roles\nsuch as planning, coding, profiling, and complexity analysis. A Planner\nproposes an algorithmic sketch; a deterministic Static Pruner filters high-risk\nplans; a Coder emits ISO C++17; a Profiler compiles and executes candidates on\na fixed input-size schedule to record wall time and peak memory; and a\nComplexity Analyst fits log-log growth (s, R2) with an LLM fallback to assign a\ncomplexity class and dispatch targeted patches to either the Planner or Coder.\nAgents communicate via typed, versioned JSON; a controller enforces iteration\ncaps and diminishing returns stopping. Evaluated on 26 problems (16 BigO, 10\nCodeforces Div. 2) in a POSIX sandbox (2 s / 256-512 MB), SwiftSolve attains\npass@1 = 61.54% (16/26) on the first attempt and Solved@<=3 = 80.77% with\nmarginal latency change (mean 11.96 s to 12.66 s per attempt). Aggregate\nrun-level success is 73.08% at 12.40 s mean. Failures are predominantly\nresource-bound, indicating inefficiency rather than logic errors. Against\nClaude Opus 4, SwiftSolve improves run-level success (73.1% vs 52.6%) at\napproximately 2x runtime overhead (12.4 s vs 6.8 s). Beyond correctness\n(pass@k), we report efficiency metrics (eff@k for runtime and memory, incidence\nof TLE or MLE, and complexity fit accuracy on BigO), demonstrating that\nprofiling and complexity-guided replanning reduce inefficiency while preserving\naccuracy.", "AI": {"tldr": "SwiftSolve\u662f\u4e00\u4e2a\u590d\u6742\u5ea6\u611f\u77e5\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u7ade\u4e89\u6027\u7f16\u7a0b\uff0c\u901a\u8fc7\u7b97\u6cd5\u89c4\u5212\u3001\u7ecf\u9a8c\u5206\u6790\u548c\u590d\u6742\u5ea6\u6307\u5bfc\u7684\u4fee\u590d\uff0c\u786e\u4fdd\u7a0b\u5e8f\u4e0d\u4ec5\u6b63\u786e\u8fd8\u6ee1\u8db3\u65f6\u95f4\u548c\u5185\u5b58\u9650\u5236\u3002", "motivation": "\u73b0\u6709LLM\u751f\u6210\u7684\u7a0b\u5e8f\u867d\u7136\u80fd\u901a\u8fc7\u5355\u5143\u6d4b\u8bd5\uff0c\u4f46\u7ecf\u5e38\u8fdd\u53cd\u7ade\u8d5b\u7684\u65f6\u95f4\u548c\u5185\u5b58\u9884\u7b97\uff0c\u9700\u8981\u786e\u4fdd\u7a0b\u5e8f\u5728\u6548\u7387\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5305\u62ec\u89c4\u5212\u5668\u3001\u9759\u6001\u4fee\u526a\u5668\u3001\u7f16\u7801\u5668\u3001\u5206\u6790\u5668\u548c\u590d\u6742\u5ea6\u5206\u6790\u5668\uff0c\u901a\u8fc7\u7248\u672c\u5316JSON\u901a\u4fe1\uff0c\u63a7\u5236\u5668\u7ba1\u7406\u8fed\u4ee3\u548c\u505c\u6b62\u6761\u4ef6\u3002", "result": "\u572826\u4e2a\u95ee\u9898\u4e0a\u7684\u6d4b\u8bd5\u663e\u793a\uff0c\u9996\u6b21\u5c1d\u8bd5\u901a\u8fc7\u7387\u4e3a61.54%\uff0c\u4e09\u6b21\u5c1d\u8bd5\u5185\u89e3\u51b3\u7387\u4e3a80.77%\uff0c\u8fd0\u884c\u7ea7\u6210\u529f\u7387\u4e3a73.08%\uff0c\u5e73\u5747\u65f6\u95f412.40\u79d2\u3002", "conclusion": "SwiftSolve\u901a\u8fc7\u5206\u6790\u548c\u590d\u6742\u5ea6\u6307\u5bfc\u7684\u91cd\u65b0\u89c4\u5212\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4f4e\u6548\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u51c6\u786e\u6027\uff0c\u76f8\u6bd4Claude Opus 4\u5728\u8fd0\u884c\u7ea7\u6210\u529f\u7387\u4e0a\u6709\u660e\u663e\u63d0\u5347\u3002"}}
{"id": "2510.22821", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.22821", "abs": "https://arxiv.org/abs/2510.22821", "authors": ["Ricardo Vega", "Connor Mattson", "Kevin Zhu", "Daniel S. Brown", "Cameron Nowzari"], "title": "Analytical Swarm Chemistry: Characterization and Analysis of Emergent Swarm Behaviors", "comment": "9 pages, 8 figures, 1 table", "summary": "Swarm robotics has potential for a wide variety of applications, but\nreal-world deployments remain rare due to the difficulty of predicting emergent\nbehaviors arising from simple local interactions. Traditional engineering\napproaches design controllers to achieve desired macroscopic outcomes under\nidealized conditions, while agent-based and artificial life studies explore\nemergent phenomena in a bottom-up, exploratory manner. In this work, we\nintroduce Analytical Swarm Chemistry, a framework that integrates concepts from\nengineering, agent-based and artificial life research, and chemistry. This\nframework combines macrostate definitions with phase diagram analysis to\nsystematically explore how swarm parameters influence emergent behavior.\nInspired by concepts from chemistry, the framework treats parameters like\nthermodynamic variables, enabling visualization of regions in parameter space\nthat give rise to specific behaviors. Applying this framework to agents with\nminimally viable capabilities, we identify sufficient conditions for behaviors\nsuch as milling and diffusion and uncover regions of the parameter space that\nreliably produce these behaviors. Preliminary validation on real robots\ndemonstrates that these regions correspond to observable behaviors in practice.\nBy providing a principled, interpretable approach, this framework lays the\ngroundwork for predictable and reliable emergent behavior in real-world swarm\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5206\u6790\u6027\u7fa4\u4f53\u5316\u5b66\u6846\u67b6\uff0c\u5c06\u5de5\u7a0b\u5b66\u3001\u57fa\u4e8e\u4ee3\u7406\u7684\u7814\u7a76\u548c\u5316\u5b66\u6982\u5ff5\u7ed3\u5408\uff0c\u901a\u8fc7\u5b8f\u89c2\u72b6\u6001\u5b9a\u4e49\u548c\u76f8\u56fe\u5206\u6790\u7cfb\u7edf\u63a2\u7d22\u7fa4\u4f53\u53c2\u6570\u5982\u4f55\u5f71\u54cd\u6d8c\u73b0\u884c\u4e3a\u3002", "motivation": "\u7fa4\u4f53\u673a\u5668\u4eba\u5b66\u5728\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u7a00\u5c11\uff0c\u56e0\u4e3a\u96be\u4ee5\u9884\u6d4b\u7b80\u5355\u5c40\u90e8\u4ea4\u4e92\u4ea7\u751f\u7684\u6d8c\u73b0\u884c\u4e3a\u3002\u4f20\u7edf\u5de5\u7a0b\u65b9\u6cd5\u5728\u7406\u60f3\u6761\u4ef6\u4e0b\u8bbe\u8ba1\u63a7\u5236\u5668\uff0c\u800c\u57fa\u4e8e\u4ee3\u7406\u7684\u7814\u7a76\u5219\u81ea\u4e0b\u800c\u4e0a\u63a2\u7d22\u6d8c\u73b0\u73b0\u8c61\u3002", "method": "\u7ed3\u5408\u5b8f\u89c2\u72b6\u6001\u5b9a\u4e49\u4e0e\u76f8\u56fe\u5206\u6790\uff0c\u5c06\u53c2\u6570\u89c6\u4e3a\u70ed\u529b\u5b66\u53d8\u91cf\uff0c\u53ef\u89c6\u5316\u53c2\u6570\u7a7a\u95f4\u4e2d\u4ea7\u751f\u7279\u5b9a\u884c\u4e3a\u7684\u533a\u57df\u3002\u5e94\u7528\u4e8e\u5177\u6709\u6700\u5c0f\u53ef\u884c\u80fd\u529b\u7684\u4ee3\u7406\uff0c\u8bc6\u522b\u4ea7\u751f\u7279\u5b9a\u884c\u4e3a\u7684\u5145\u5206\u6761\u4ef6\u3002", "result": "\u8bc6\u522b\u4e86\u4ea7\u751f\u94e3\u524a\u548c\u6269\u6563\u7b49\u884c\u4e3a\u7684\u5145\u5206\u6761\u4ef6\uff0c\u53d1\u73b0\u4e86\u53c2\u6570\u7a7a\u95f4\u4e2d\u53ef\u9760\u4ea7\u751f\u8fd9\u4e9b\u884c\u4e3a\u7684\u533a\u57df\u3002\u5728\u771f\u5b9e\u673a\u5668\u4eba\u4e0a\u7684\u521d\u6b65\u9a8c\u8bc1\u8868\u660e\u8fd9\u4e9b\u533a\u57df\u5728\u5b9e\u8df5\u4e2d\u5bf9\u5e94\u53ef\u89c2\u5bdf\u7684\u884c\u4e3a\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u73b0\u5b9e\u4e16\u754c\u7fa4\u4f53\u7cfb\u7edf\u4e2d\u53ef\u9884\u6d4b\u548c\u53ef\u9760\u7684\u6d8c\u73b0\u884c\u4e3a\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u6709\u539f\u5219\u3001\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.22600", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22600", "abs": "https://arxiv.org/abs/2510.22600", "authors": ["Huilin Yin", "Zhaolin Yang", "Linchuan Zhang", "Gerhard Rigoll", "Johannes Betz"], "title": "RoGER-SLAM: A Robust Gaussian Splatting SLAM System for Noisy and Low-light Environment Resilience", "comment": "13 pages, 11 figures, under review", "summary": "The reliability of Simultaneous Localization and Mapping (SLAM) is severely\nconstrained in environments where visual inputs suffer from noise and low\nillumination. Although recent 3D Gaussian Splatting (3DGS) based SLAM\nframeworks achieve high-fidelity mapping under clean conditions, they remain\nvulnerable to compounded degradations that degrade mapping and tracking\nperformance. A key observation underlying our work is that the original 3DGS\nrendering pipeline inherently behaves as an implicit low-pass filter,\nattenuating high-frequency noise but also risking over-smoothing. Building on\nthis insight, we propose RoGER-SLAM, a robust 3DGS SLAM system tailored for\nnoise and low-light resilience. The framework integrates three innovations: a\nStructure-Preserving Robust Fusion (SP-RoFusion) mechanism that couples\nrendered appearance, depth, and edge cues; an adaptive tracking objective with\nresidual balancing regularization; and a Contrastive Language-Image Pretraining\n(CLIP)-based enhancement module, selectively activated under compounded\ndegradations to restore semantic and structural fidelity. Comprehensive\nexperiments on Replica, TUM, and real-world sequences show that RoGER-SLAM\nconsistently improves trajectory accuracy and reconstruction quality compared\nwith other 3DGS-SLAM systems, especially under adverse imaging conditions.", "AI": {"tldr": "RoGER-SLAM\u662f\u4e00\u4e2a\u9488\u5bf9\u566a\u58f0\u548c\u4f4e\u5149\u7167\u73af\u5883\u7684\u9c81\u68d23D\u9ad8\u65af\u6cfc\u6e85SLAM\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u6784\u4fdd\u6301\u878d\u5408\u673a\u5236\u3001\u81ea\u9002\u5e94\u8ddf\u8e2a\u76ee\u6807\u548cCLIP\u589e\u5f3a\u6a21\u5757\uff0c\u5728\u6076\u52a3\u6210\u50cf\u6761\u4ef6\u4e0b\u663e\u8457\u63d0\u5347\u8f68\u8ff9\u7cbe\u5ea6\u548c\u91cd\u5efa\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edfSLAM\u5728\u89c6\u89c9\u8f93\u5165\u53d7\u566a\u58f0\u548c\u4f4e\u5149\u7167\u5f71\u54cd\u65f6\u53ef\u9760\u6027\u4e25\u91cd\u53d7\u9650\uff0c\u73b0\u6709\u76843DGS SLAM\u6846\u67b6\u5728\u5e72\u51c0\u6761\u4ef6\u4e0b\u80fd\u5b9e\u73b0\u9ad8\u4fdd\u771f\u5efa\u56fe\uff0c\u4f46\u5728\u590d\u5408\u9000\u5316\u73af\u5883\u4e0b\u4ecd\u7136\u8106\u5f31\u3002\u7814\u7a76\u53d1\u73b03DGS\u6e32\u67d3\u7ba1\u9053\u672c\u8eab\u5177\u6709\u9690\u5f0f\u4f4e\u901a\u6ee4\u6ce2\u5668\u7279\u6027\uff0c\u4f1a\u8870\u51cf\u9ad8\u9891\u566a\u58f0\u4f46\u53ef\u80fd\u5bfc\u81f4\u8fc7\u5ea6\u5e73\u6ed1\u3002", "method": "1. \u7ed3\u6784\u4fdd\u6301\u9c81\u68d2\u878d\u5408\u673a\u5236(SP-RoFusion)\uff0c\u8026\u5408\u6e32\u67d3\u7684\u5916\u89c2\u3001\u6df1\u5ea6\u548c\u8fb9\u7f18\u7ebf\u7d22\uff1b2. \u5e26\u6709\u6b8b\u5dee\u5e73\u8861\u6b63\u5219\u5316\u7684\u81ea\u9002\u5e94\u8ddf\u8e2a\u76ee\u6807\uff1b3. \u57fa\u4e8eCLIP\u7684\u589e\u5f3a\u6a21\u5757\uff0c\u5728\u590d\u5408\u9000\u5316\u6761\u4ef6\u4e0b\u9009\u62e9\u6027\u6fc0\u6d3b\u4ee5\u6062\u590d\u8bed\u4e49\u548c\u7ed3\u6784\u4fdd\u771f\u5ea6\u3002", "result": "\u5728Replica\u3001TUM\u548c\u771f\u5b9e\u4e16\u754c\u5e8f\u5217\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cRoGER-SLAM\u76f8\u6bd4\u5176\u4ed63DGS-SLAM\u7cfb\u7edf\u6301\u7eed\u63d0\u5347\u4e86\u8f68\u8ff9\u7cbe\u5ea6\u548c\u91cd\u5efa\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5728\u6076\u52a3\u6210\u50cf\u6761\u4ef6\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "RoGER-SLAM\u901a\u8fc7\u521b\u65b0\u7684\u878d\u5408\u673a\u5236\u548c\u589e\u5f3a\u6a21\u5757\uff0c\u6709\u6548\u89e3\u51b3\u4e863DGS SLAM\u5728\u566a\u58f0\u548c\u4f4e\u5149\u7167\u73af\u5883\u4e2d\u7684\u8106\u5f31\u6027\u95ee\u9898\uff0c\u4e3a\u6076\u52a3\u6761\u4ef6\u4e0b\u7684\u89c6\u89c9SLAM\u63d0\u4f9b\u4e86\u9c81\u68d2\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.22679", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.22679", "abs": "https://arxiv.org/abs/2510.22679", "authors": ["Yuval Kainan", "Shaked Zychlinski"], "title": "Do Stop Me Now: Detecting Boilerplate Responses with a Single Iteration", "comment": "13 pages, 4 figures", "summary": "Large Language Models (LLMs) often expend significant computational resources\ngenerating boilerplate responses, such as refusals, simple acknowledgements and\ncasual greetings, which adds unnecessary cost and latency. To address this\ninefficiency, we propose a simple yet highly effective method for detecting\nsuch responses after only a single generation step. We demonstrate that the\nlog-probability distribution of the first generated token serves as a powerful\nsignal for classifying the nature of the entire subsequent response. Our\nexperiments, conducted across a diverse range of small, large, and\nreasoning-specialized models, show that the first-token log-probability vectors\nform distinctly separable clusters for different response types. Using a\nlightweight k-NN classifier, we achieve high accuracy in predicting whether a\nresponse will be a substantive answer or a form of boilerplate response,\nincluding user-specified refusals. The primary implication is a practical,\ncomputationally trivial technique, optimizing LLM inference by enabling early\ntermination or redirection to a smaller model, thereby yielding significant\nsavings in computational cost. This work presents a direct path toward more\nefficient and sustainable LLM deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9996\u8bcd\u751f\u6210\u6982\u7387\u7684\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u53ef\u5728\u5355\u6b65\u751f\u6210\u540e\u68c0\u6d4bLLM\u7684\u6a21\u677f\u5316\u56de\u590d\uff0c\u5b9e\u73b0\u65e9\u671f\u7ec8\u6b62\u4ee5\u8282\u7701\u8ba1\u7b97\u8d44\u6e90\u3002", "motivation": "LLMs\u5728\u751f\u6210\u6a21\u677f\u5316\u56de\u590d\uff08\u5982\u62d2\u7edd\u3001\u7b80\u5355\u786e\u8ba4\u7b49\uff09\u65f6\u6d6a\u8d39\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0c\u589e\u52a0\u4e86\u4e0d\u5fc5\u8981\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u3002", "method": "\u5229\u7528\u9996\u8bcd\u751f\u6210\u7684\u5bf9\u6570\u6982\u7387\u5206\u5e03\u4f5c\u4e3a\u5206\u7c7b\u4fe1\u53f7\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7k-NN\u5206\u7c7b\u5668\u9884\u6d4b\u56de\u590d\u7c7b\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u9996\u8bcd\u5bf9\u6570\u6982\u7387\u5411\u91cf\u5728\u4e0d\u540c\u56de\u590d\u7c7b\u578b\u95f4\u5f62\u6210\u660e\u663e\u53ef\u5206\u79bb\u7684\u805a\u7c7b\uff0c\u80fd\u591f\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u662f\u5426\u4e3a\u5b9e\u8d28\u6027\u56de\u7b54\u6216\u6a21\u677f\u5316\u56de\u590d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u8ba1\u7b97\u91cf\u6781\u5c0f\u7684\u6280\u672f\uff0c\u901a\u8fc7\u65e9\u671f\u7ec8\u6b62\u6216\u91cd\u5b9a\u5411\u5230\u8f83\u5c0f\u6a21\u578b\u6765\u4f18\u5316LLM\u63a8\u7406\uff0c\u663e\u8457\u8282\u7701\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2510.22892", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.22892", "abs": "https://arxiv.org/abs/2510.22892", "authors": ["Jingzehua Xu", "Yangyang Li", "Yangfei Chen", "Guanwen Xie", "Shuai Zhang"], "title": "Never Too Rigid to Reach: Adaptive Virtual Model Control with LLM- and Lyapunov-Based Reinforcement Learning", "comment": null, "summary": "Robotic arms are increasingly deployed in uncertain environments, yet\nconventional control pipelines often become rigid and brittle when exposed to\nperturbations or incomplete information. Virtual Model Control (VMC) enables\ncompliant behaviors by embedding virtual forces and mapping them into joint\ntorques, but its reliance on fixed parameters and limited coordination among\nvirtual components constrains adaptability and may undermine stability as task\nobjectives evolve. To address these limitations, we propose Adaptive VMC with\nLarge Language Model (LLM)- and Lyapunov-Based Reinforcement Learning (RL),\nwhich preserves the physical interpretability of VMC while supporting\nstability-guaranteed online adaptation. The LLM provides structured priors and\nhigh-level reasoning that enhance coordination among virtual components,\nimprove sample efficiency, and facilitate flexible adjustment to varying task\nrequirements. Complementarily, Lyapunov-based RL enforces theoretical stability\nconstraints, ensuring safe and reliable adaptation under uncertainty. Extensive\nsimulations on a 7-DoF Panda arm demonstrate that our approach effectively\nbalances competing objectives in dynamic tasks, achieving superior performance\nwhile highlighting the synergistic benefits of LLM guidance and\nLyapunov-constrained adaptation.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u865a\u62df\u6a21\u578b\u63a7\u5236\u65b9\u6cd5\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548cLyapunov\u5f3a\u5316\u5b66\u4e60\uff0c\u5728\u4fdd\u6301\u7269\u7406\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u7a33\u5b9a\u6027\u4fdd\u8bc1\u7684\u5728\u7ebf\u9002\u5e94\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u4eba\u63a7\u5236\u65b9\u6cd5\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u53d8\u5f97\u50f5\u5316\u548c\u8106\u5f31\uff0c\u865a\u62df\u6a21\u578b\u63a7\u5236\u867d\u7136\u80fd\u5b9e\u73b0\u67d4\u987a\u884c\u4e3a\uff0c\u4f46\u4f9d\u8d56\u56fa\u5b9a\u53c2\u6570\u4e14\u865a\u62df\u7ec4\u4ef6\u95f4\u534f\u8c03\u6709\u9650\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u548c\u7a33\u5b9a\u6027\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u7ed3\u6784\u5316\u5148\u9a8c\u548c\u9ad8\u7ea7\u63a8\u7406\u4ee5\u589e\u5f3a\u865a\u62df\u7ec4\u4ef6\u534f\u8c03\uff0c\u7ed3\u5408Lyapunov\u5f3a\u5316\u5b66\u4e60\u5f3a\u5236\u6267\u884c\u7406\u8bba\u7a33\u5b9a\u6027\u7ea6\u675f\uff0c\u5b9e\u73b0\u5b89\u5168\u53ef\u9760\u7684\u5728\u7ebf\u9002\u5e94\u3002", "result": "\u57287\u81ea\u7531\u5ea6Panda\u673a\u68b0\u81c2\u4e0a\u7684\u5927\u91cf\u4eff\u771f\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u52a8\u6001\u4efb\u52a1\u4e2d\u6709\u6548\u5e73\u8861\u7ade\u4e89\u76ee\u6807\uff0c\u5b9e\u73b0\u4f18\u8d8a\u6027\u80fd\uff0c\u7a81\u663e\u4e86LLM\u6307\u5bfc\u548cLyapunov\u7ea6\u675f\u9002\u5e94\u7684\u534f\u540c\u6548\u76ca\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u865a\u62df\u6a21\u578b\u63a7\u5236\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7LLM\u548cLyapunov\u5f3a\u5316\u5b66\u4e60\u7684\u7ed3\u5408\uff0c\u5728\u4fdd\u6301\u7269\u7406\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u7a33\u5b9a\u6027\u4fdd\u8bc1\u7684\u81ea\u9002\u5e94\u63a7\u5236\u3002"}}
{"id": "2510.22680", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22680", "abs": "https://arxiv.org/abs/2510.22680", "authors": ["Shireen Kudukkil Manchingal", "Armand Amaritei", "Mihir Gohad", "Maryam Sultana", "Julian F. P. Kooij", "Fabio Cuzzolin", "Andrew Bradley"], "title": "Uncertainty-Aware Autonomous Vehicles: Predicting the Road Ahead", "comment": null, "summary": "Autonomous Vehicle (AV) perception systems have advanced rapidly in recent\nyears, providing vehicles with the ability to accurately interpret their\nenvironment. Perception systems remain susceptible to errors caused by\noverly-confident predictions in the case of rare events or out-of-sample data.\nThis study equips an autonomous vehicle with the ability to 'know when it is\nuncertain', using an uncertainty-aware image classifier as part of the AV\nsoftware stack. Specifically, the study exploits the ability of Random-Set\nNeural Networks (RS-NNs) to explicitly quantify prediction uncertainty. Unlike\ntraditional CNNs or Bayesian methods, RS-NNs predict belief functions over sets\nof classes, allowing the system to identify and signal uncertainty clearly in\nnovel or ambiguous scenarios. The system is tested in a real-world autonomous\nracing vehicle software stack, with the RS-NN classifying the layout of the\nroad ahead and providing the associated uncertainty of the prediction.\nPerformance of the RS-NN under a range of road conditions is compared against\ntraditional CNN and Bayesian neural networks, with the RS-NN achieving\nsignificantly higher accuracy and superior uncertainty calibration. This\nintegration of RS-NNs into Robot Operating System (ROS)-based vehicle control\npipeline demonstrates that predictive uncertainty can dynamically modulate\nvehicle speed, maintaining high-speed performance under confident predictions\nwhile proactively improving safety through speed reductions in uncertain\nscenarios. These results demonstrate the potential of uncertainty-aware neural\nnetworks - in particular RS-NNs - as a practical solution for safer and more\nrobust autonomous driving.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u968f\u673a\u96c6\u795e\u7ecf\u7f51\u7edc\uff08RS-NNs\uff09\u96c6\u6210\u5230\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u611f\u77e5\u7cfb\u7edf\u4e2d\uff0c\u901a\u8fc7\u663e\u5f0f\u91cf\u5316\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u6765\u63d0\u9ad8\u5b89\u5168\u6027\uff0c\u5728\u4e0d\u786e\u5b9a\u573a\u666f\u4e0b\u52a8\u6001\u8c03\u8282\u8f66\u901f\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u611f\u77e5\u7cfb\u7edf\u5728\u9762\u5bf9\u7f55\u89c1\u4e8b\u4ef6\u6216\u6837\u672c\u5916\u6570\u636e\u65f6\u5bb9\u6613\u4ea7\u751f\u8fc7\u5ea6\u81ea\u4fe1\u7684\u9884\u6d4b\u9519\u8bef\uff0c\u9700\u8981\u8ba9\u8f66\u8f86\u80fd\u591f'\u77e5\u9053\u4f55\u65f6\u4e0d\u786e\u5b9a'\u3002", "method": "\u4f7f\u7528\u968f\u673a\u96c6\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u56fe\u50cf\u5206\u7c7b\u5668\uff0c\u9884\u6d4b\u7c7b\u522b\u96c6\u5408\u7684\u7f6e\u4fe1\u51fd\u6570\uff0c\u4e0e\u4f20\u7edfCNN\u548c\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u5bf9\u6bd4\u6d4b\u8bd5\u3002", "result": "RS-NN\u5728\u5404\u79cd\u9053\u8def\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u548c\u4f18\u8d8a\u7684\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\uff0c\u80fd\u591f\u52a8\u6001\u8c03\u8282\u8f66\u8f86\u901f\u5ea6\u4ee5\u5e73\u8861\u6027\u80fd\u4e0e\u5b89\u5168\u3002", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u795e\u7ecf\u7f51\u7edc\uff0c\u7279\u522b\u662fRS-NNs\uff0c\u662f\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.22949", "categories": ["cs.RO", "cs.SY", "eess.SY", "93C10", "I.2.9; I.2.8; J.2"], "pdf": "https://arxiv.org/pdf/2510.22949", "abs": "https://arxiv.org/abs/2510.22949", "authors": ["Benedictus C. G. Cinun", "Tua A. Tamba", "Immanuel R. Santjoko", "Xiaofeng Wang", "Michael A. Gunarso", "Bin Hu"], "title": "End-to-End Design and Validation of a Low-Cost Stewart Platform with Nonlinear Estimation and Control", "comment": "24 pages, journal", "summary": "This paper presents the complete design, control, and experimental validation\nof a low-cost Stewart platform prototype developed as an affordable yet capable\nrobotic testbed for research and education. The platform combines off the shelf\ncomponents with 3D printed and custom fabricated parts to deliver full six\ndegrees of freedom motions using six linear actuators connecting a moving\nplatform to a fixed base. The system software integrates dynamic modeling, data\nacquisition, and real time control within a unified framework. A robust\ntrajectory tracking controller based on feedback linearization, augmented with\nan LQR scheme, compensates for the platform's nonlinear dynamics to achieve\nprecise motion control. In parallel, an Extended Kalman Filter fuses IMU and\nactuator encoder feedback to provide accurate and reliable state estimation\nunder sensor noise and external disturbances. Unlike prior efforts that\nemphasize only isolated aspects such as modeling or control, this work delivers\na complete hardware-software platform validated through both simulation and\nexperiments on static and dynamic trajectories. Results demonstrate effective\ntrajectory tracking and real-time state estimation, highlighting the platform's\npotential as a cost effective and versatile tool for advanced research and\neducational applications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u4f4e\u6210\u672cStewart\u5e73\u53f0\u539f\u578b\u7684\u8bbe\u8ba1\u3001\u63a7\u5236\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u5e73\u53f0\u7ed3\u5408\u73b0\u6210\u7ec4\u4ef6\u4e0e3D\u6253\u5370\u90e8\u4ef6\uff0c\u5b9e\u73b0\u4e86\u5b8c\u6574\u7684\u516d\u81ea\u7531\u5ea6\u8fd0\u52a8\u63a7\u5236\uff0c\u5e76\u901a\u8fc7\u96c6\u6210\u52a8\u6001\u5efa\u6a21\u3001\u6570\u636e\u91c7\u96c6\u548c\u5b9e\u65f6\u63a7\u5236\u7684\u7edf\u4e00\u8f6f\u4ef6\u6846\u67b6\u8fdb\u884c\u9a8c\u8bc1\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u65e2\u7ecf\u6d4e\u5b9e\u60e0\u53c8\u529f\u80fd\u5f3a\u5927\u7684\u673a\u5668\u4eba\u6d4b\u8bd5\u5e73\u53f0\uff0c\u7528\u4e8e\u7814\u7a76\u548c\u6559\u80b2\u76ee\u7684\uff0c\u514b\u670d\u4ee5\u5f80\u7814\u7a76\u4ec5\u5173\u6ce8\u5efa\u6a21\u6216\u63a7\u5236\u7b49\u5b64\u7acb\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528\u73b0\u6210\u7ec4\u4ef6\u4e0e3D\u6253\u5370\u5b9a\u5236\u90e8\u4ef6\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\u6784\u5efa\u786c\u4ef6\u5e73\u53f0\uff1b\u8f6f\u4ef6\u96c6\u6210\u52a8\u6001\u5efa\u6a21\u3001\u6570\u636e\u91c7\u96c6\u548c\u5b9e\u65f6\u63a7\u5236\uff1b\u4f7f\u7528\u57fa\u4e8e\u53cd\u9988\u7ebf\u6027\u5316\u7684\u9c81\u68d2\u8f68\u8ff9\u8ddf\u8e2a\u63a7\u5236\u5668\uff0c\u5e76\u8f85\u4ee5LQR\u65b9\u6848\u8865\u507f\u975e\u7ebf\u6027\u52a8\u529b\u5b66\uff1b\u901a\u8fc7\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u878d\u5408IMU\u548c\u6267\u884c\u5668\u7f16\u7801\u5668\u53cd\u9988\u8fdb\u884c\u72b6\u6001\u4f30\u8ba1\u3002", "result": "\u5728\u9759\u6001\u548c\u52a8\u6001\u8f68\u8ff9\u7684\u4eff\u771f\u548c\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5e73\u53f0\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u826f\u597d\u7684\u8f68\u8ff9\u8ddf\u8e2a\u6027\u80fd\u548c\u5b9e\u65f6\u72b6\u6001\u4f30\u8ba1\u80fd\u529b\u3002", "conclusion": "\u8be5\u5e73\u53f0\u88ab\u8bc1\u660e\u662f\u4e00\u4e2a\u6210\u672c\u6548\u76ca\u9ad8\u4e14\u591a\u529f\u80fd\u7684\u5de5\u5177\uff0c\u5177\u6709\u5728\u9ad8\u7ea7\u7814\u7a76\u548c\u6559\u80b2\u5e94\u7528\u4e2d\u53d1\u6325\u91cd\u8981\u4f5c\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.22699", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22699", "abs": "https://arxiv.org/abs/2510.22699", "authors": ["Matteo El-Hariry", "Andrej Orsula", "Matthieu Geist", "Miguel Olivares-Mendez"], "title": "RL-AVIST: Reinforcement Learning for Autonomous Visual Inspection of Space Targets", "comment": null, "summary": "The growing need for autonomous on-orbit services such as inspection,\nmaintenance, and situational awareness calls for intelligent spacecraft capable\nof complex maneuvers around large orbital targets. Traditional control systems\noften fall short in adaptability, especially under model uncertainties,\nmulti-spacecraft configurations, or dynamically evolving mission contexts. This\npaper introduces RL-AVIST, a Reinforcement Learning framework for Autonomous\nVisual Inspection of Space Targets. Leveraging the Space Robotics Bench (SRB),\nwe simulate high-fidelity 6-DOF spacecraft dynamics and train agents using\nDreamerV3, a state-of-the-art model-based RL algorithm, with PPO and TD3 as\nmodel-free baselines. Our investigation focuses on 3D proximity maneuvering\ntasks around targets such as the Lunar Gateway and other space assets. We\nevaluate task performance under two complementary regimes: generalized agents\ntrained on randomized velocity vectors, and specialized agents trained to\nfollow fixed trajectories emulating known inspection orbits. Furthermore, we\nassess the robustness and generalization of policies across multiple spacecraft\nmorphologies and mission domains. Results demonstrate that model-based RL\noffers promising capabilities in trajectory fidelity, and sample efficiency,\npaving the way for scalable, retrainable control solutions for future space\noperations", "AI": {"tldr": "RL-AVIST\uff1a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u4e3b\u7a7a\u95f4\u76ee\u6807\u89c6\u89c9\u68c0\u6d4b\u6846\u67b6\uff0c\u4f7f\u7528DreamerV3\u7b97\u6cd5\u57286-DOF\u822a\u5929\u5668\u52a8\u529b\u5b66\u6a21\u62df\u4e2d\u8bad\u7ec3\u667a\u80fd\u4f53\uff0c\u5b9e\u73b03D\u63a5\u8fd1\u673a\u52a8\u4efb\u52a1", "motivation": "\u4f20\u7edf\u63a7\u5236\u7cfb\u7edf\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u3001\u591a\u822a\u5929\u5668\u914d\u7f6e\u6216\u52a8\u6001\u4efb\u52a1\u73af\u5883\u4e0b\u9002\u5e94\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u667a\u80fd\u822a\u5929\u5668\u6267\u884c\u8f68\u9053\u68c0\u67e5\u3001\u7ef4\u62a4\u7b49\u81ea\u4e3b\u670d\u52a1", "method": "\u5229\u7528Space Robotics Bench\u6a21\u62df\u9ad8\u4fdd\u771f6-DOF\u822a\u5929\u5668\u52a8\u529b\u5b66\uff0c\u4f7f\u7528DreamerV3\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0cPPO\u548cTD3\u4f5c\u4e3a\u65e0\u6a21\u578b\u57fa\u7ebf\uff0c\u8bad\u7ec3\u901a\u7528\u548c\u4e13\u7528\u667a\u80fd\u4f53", "result": "\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u8f68\u8ff9\u4fdd\u771f\u5ea6\u548c\u6837\u672c\u6548\u7387\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u7b56\u7565\u5728\u591a\u79cd\u822a\u5929\u5668\u5f62\u6001\u548c\u4efb\u52a1\u9886\u57df\u5177\u6709\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b", "conclusion": "\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e3a\u672a\u6765\u7a7a\u95f4\u64cd\u4f5c\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u91cd\u8bad\u7ec3\u7684\u63a7\u5236\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.22710", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22710", "abs": "https://arxiv.org/abs/2510.22710", "authors": ["Kaitong Cai", "Jusheng Zhang", "Yijia Fan", "Jing Yang", "Keze Wang"], "title": "RaCoT: Plug-and-Play Contrastive Example Generation Mechanism for Enhanced LLM Reasoning Reliability", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) faces a core bottleneck with\nknowledge-sparse and semantically ambiguous long-tail queries, where retrieval\nnoise distorts reasoning and necessitates costly post-processing. To tackle\nthis, we propose RaCoT (Retrieval-aware Contrastive-of-Thought), a novel\nframework that shifts contrastive thinking to the pre-retrieval stage. By\nautomatically generating a semantically adjacent yet differently answered\ncontrastive question and extracting a $\\Delta$-Prompt to capture their key\ndifferences, RaCoT guides the model to proactively focus on the ``critical\ndetails that determine answer divergence.\" This approach allows it to suppress\nsemantic interference within a single retrieval pass, overcoming the\ntheoretical bottleneck of single-vector queries that struggle to simultaneously\nencode signals for what to attend to and what to ignore. On six authoritative\nbenchmarks, including PopQA and TriviaQA-unfiltered, RaCoT outperforms strong\nbaselines like RankRAG and Self-RAG by 0.9-2.4 percentage points. It exhibits\nsuperior robustness, with a performance drop of only 8.6\\% in adversarial\ntests, far surpassing the over 15\\% degradation in other methods. Furthermore,\nits low latency (3.12s) and token overhead (11.54) place it on the\naccuracy-efficiency Pareto frontier, while ablation studies validate the\nnecessity of each component. Ultimately, RaCoT reframes the RAG paradigm from\n``post-hoc context cleaning\" to ``a priori shaping of discriminative\nreasoning\", offering an efficient and robust path toward reliable AI systems\nfor real-time, resource-constrained deployments.", "AI": {"tldr": "RaCoT\u662f\u4e00\u79cd\u5728\u68c0\u7d22\u524d\u9636\u6bb5\u8fdb\u884c\u5bf9\u6bd4\u601d\u8003\u7684RAG\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u5bf9\u6bd4\u95ee\u9898\u548c\u63d0\u53d6\u5dee\u5f02\u63d0\u793a\uff0c\u5728\u5355\u6b21\u68c0\u7d22\u4e2d\u6291\u5236\u8bed\u4e49\u5e72\u6270\uff0c\u663e\u8457\u63d0\u5347\u957f\u5c3e\u67e5\u8be2\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3RAG\u5728\u77e5\u8bc6\u7a00\u758f\u548c\u8bed\u4e49\u6a21\u7cca\u7684\u957f\u5c3e\u67e5\u8be2\u4e2d\u9762\u4e34\u7684\u68c0\u7d22\u566a\u58f0\u95ee\u9898\uff0c\u907f\u514d\u6602\u8d35\u7684\u540e\u5904\u7406\u6210\u672c\uff0c\u7a81\u7834\u5355\u5411\u91cf\u67e5\u8be2\u540c\u65f6\u7f16\u7801\u5173\u6ce8\u548c\u5ffd\u7565\u4fe1\u53f7\u7684\u7406\u8bba\u74f6\u9888\u3002", "method": "\u5728\u68c0\u7d22\u524d\u81ea\u52a8\u751f\u6210\u8bed\u4e49\u76f8\u90bb\u4f46\u7b54\u6848\u4e0d\u540c\u7684\u5bf9\u6bd4\u95ee\u9898\uff0c\u63d0\u53d6\u0394-Prompt\u6355\u6349\u5173\u952e\u5dee\u5f02\uff0c\u5f15\u5bfc\u6a21\u578b\u4e3b\u52a8\u5173\u6ce8\u51b3\u5b9a\u7b54\u6848\u5206\u6b67\u7684\u5173\u952e\u7ec6\u8282\u3002", "result": "\u5728\u516d\u4e2a\u6743\u5a01\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRaCoT\u6bd4RankRAG\u548cSelf-RAG\u7b49\u5f3a\u57fa\u7ebf\u63d0\u53470.9-2.4\u4e2a\u767e\u5206\u70b9\uff0c\u5bf9\u6297\u6027\u6d4b\u8bd5\u4e2d\u6027\u80fd\u4e0b\u964d\u4ec58.6%\uff0c\u8fdc\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u768415%\u4ee5\u4e0a\u4e0b\u964d\uff0c\u5177\u6709\u4f4e\u5ef6\u8fdf(3.12s)\u548c\u4f4etoken\u5f00\u9500(11.54)\u3002", "conclusion": "RaCoT\u5c06RAG\u8303\u5f0f\u4ece\"\u4e8b\u540e\u4e0a\u4e0b\u6587\u6e05\u7406\"\u91cd\u6784\u4e3a\"\u5148\u9a8c\u5851\u9020\u5224\u522b\u63a8\u7406\"\uff0c\u4e3a\u5b9e\u65f6\u3001\u8d44\u6e90\u53d7\u9650\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u53ef\u9760AI\u7cfb\u7edf\u8def\u5f84\u3002"}}
{"id": "2510.23003", "categories": ["cs.RO", "cs.CV", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.23003", "abs": "https://arxiv.org/abs/2510.23003", "authors": ["ZhengKai Huang", "YiKun Wang", "ChenYu Hui", "XiaoCheng"], "title": "An Intelligent Water-Saving Irrigation System Based on Multi-Sensor Fusion and Visual Servoing Control", "comment": null, "summary": "This paper introduces an intelligent water-saving irrigation system designed\nto address critical challenges in precision agriculture, such as inefficient\nwater use and poor terrain adaptability. The system integrates advanced\ncomputer vision, robotic control, and real-time stabilization technologies via\na multi-sensor fusion approach. A lightweight YOLO model, deployed on an\nembedded vision processor (K210), enables real-time plant container detection\nwith over 96% accuracy under varying lighting conditions. A simplified hand-eye\ncalibration algorithm-designed for 'handheld camera' robot arm\nconfigurations-ensures that the end effector can be precisely positioned, with\na success rate exceeding 90%. The active leveling system, driven by the\nSTM32F103ZET6 main control chip and JY901S inertial measurement data, can\nstabilize the irrigation platform on slopes up to 10 degrees, with a response\ntime of 1.8 seconds. Experimental results across three simulated agricultural\nenvironments (standard greenhouse, hilly terrain, complex lighting) demonstrate\na 30-50% reduction in water consumption compared to conventional flood\nirrigation, with water use efficiency exceeding 92% in all test cases.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u667a\u80fd\u8282\u6c34\u704c\u6e89\u7cfb\u7edf\uff0c\u901a\u8fc7\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u673a\u5668\u4eba\u63a7\u5236\u548c\u5b9e\u65f6\u7a33\u5b9a\u6280\u672f\uff0c\u5b9e\u73b0\u7cbe\u51c6\u704c\u6e89\uff0c\u5728\u4e09\u79cd\u6a21\u62df\u519c\u4e1a\u73af\u5883\u4e2d\u6bd4\u4f20\u7edf\u6f2b\u704c\u8282\u6c3430-50%\uff0c\u7528\u6c34\u6548\u7387\u8d85\u8fc792%\u3002", "motivation": "\u89e3\u51b3\u7cbe\u51c6\u519c\u4e1a\u4e2d\u7684\u6c34\u8d44\u6e90\u6d6a\u8d39\u548c\u5730\u5f62\u9002\u5e94\u6027\u5dee\u7b49\u5173\u952e\u6311\u6218\uff0c\u63d0\u9ad8\u704c\u6e89\u6548\u7387\u548c\u6c34\u8d44\u6e90\u5229\u7528\u7387\u3002", "method": "\u91c7\u7528\u591a\u4f20\u611f\u5668\u878d\u5408\u65b9\u6cd5\uff0c\u96c6\u6210\u8f7b\u91cf\u7ea7YOLO\u6a21\u578b\u8fdb\u884c\u5b9e\u65f6\u690d\u7269\u5bb9\u5668\u68c0\u6d4b\uff08\u51c6\u786e\u7387>96%\uff09\uff0c\u7b80\u5316\u624b\u773c\u6807\u5b9a\u7b97\u6cd5\u5b9e\u73b0\u672b\u7aef\u6267\u884c\u5668\u7cbe\u786e\u5b9a\u4f4d\uff08\u6210\u529f\u7387>90%\uff09\uff0c\u4ee5\u53ca\u57fa\u4e8eSTM32F103ZET6\u548cJY901S\u60ef\u6027\u6d4b\u91cf\u7684\u4e3b\u52a8\u8c03\u5e73\u7cfb\u7edf\u3002", "result": "\u5728\u6807\u51c6\u6e29\u5ba4\u3001\u4e18\u9675\u5730\u5f62\u548c\u590d\u6742\u5149\u7167\u4e09\u79cd\u6a21\u62df\u73af\u5883\u4e2d\uff0c\u7cfb\u7edf\u80fd\u7a33\u5b9a\u572810\u5ea6\u659c\u5761\u4e0a\u4f5c\u4e1a\uff08\u54cd\u5e94\u65f6\u95f41.8\u79d2\uff09\uff0c\u76f8\u6bd4\u4f20\u7edf\u6f2b\u704c\u8282\u6c3430-50%\uff0c\u6240\u6709\u6d4b\u8bd5\u6848\u4f8b\u7684\u7528\u6c34\u6548\u7387\u5747\u8d85\u8fc792%\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u5148\u8fdb\u6280\u672f\u96c6\u6210\u6709\u6548\u89e3\u51b3\u4e86\u7cbe\u51c6\u519c\u4e1a\u4e2d\u7684\u6c34\u8d44\u6e90\u7ba1\u7406\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u704c\u6e89\u6548\u7387\u548c\u5730\u5f62\u9002\u5e94\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.22738", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22738", "abs": "https://arxiv.org/abs/2510.22738", "authors": ["Wentao Guo", "Wenzeng Zhang"], "title": "SCAL for Pinch-Lifting: Complementary Rotational and Linear Prototypes for Environment-Adaptive Grasping", "comment": "Preliminary version presented at the IROS 2025 CIM Workshop, where it\n  was selected as a Best Demo Award (Finalist) and subsequently received the\n  Best Demo Award after oral presentation", "summary": "This paper presents environment-adaptive pinch-lifting built on a\nslot-constrained adaptive linkage (SCAL) and instantiated in two complementary\nfingers: SCAL-R, a rotational-drive design with an active fingertip that folds\ninward after contact to form an envelope, and SCAL-L, a linear-drive design\nthat passively opens on contact to span wide or weak-feature objects. Both\nfingers convert surface following into an upward lifting branch while\nmaintaining fingertip orientation, enabling thin or low-profile targets to be\nraised from supports with minimal sensing and control. Two-finger grippers are\nfabricated via PLA-based 3D printing. Experiments evaluate (i)\ncontact-preserving sliding and pinch-lifting on tabletops, (ii) ramp\nnegotiation followed by lift, and (iii) handling of bulky objects via active\nenveloping (SCAL-R) or contact-triggered passive opening (SCAL-L). Across\ndozens of trials on small parts, boxes, jars, and tape rolls, both designs\nachieve consistent grasps with limited tuning. A quasi-static analysis provides\nclosed-form fingertip-force models for linear parallel pinching and two-point\nenveloping, offering geometry-aware guidance for design and operation. Overall,\nthe results indicate complementary operating regimes and a practical path to\nrobust, environment-adaptive grasping with simple actuation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8e\u69fd\u7ea6\u675f\u81ea\u9002\u5e94\u8fde\u6746(SCAL)\u7684\u73af\u5883\u81ea\u9002\u5e94\u5939\u6301\u624b\u6307\uff1aSCAL-R\uff08\u65cb\u8f6c\u9a71\u52a8\uff0c\u63a5\u89e6\u540e\u5411\u5185\u6298\u53e0\u5f62\u6210\u5305\u7edc\uff09\u548cSCAL-L\uff08\u7ebf\u6027\u9a71\u52a8\uff0c\u63a5\u89e6\u65f6\u88ab\u52a8\u5f20\u5f00\u4ee5\u6293\u53d6\u5bbd\u6216\u5f31\u7279\u5f81\u7269\u4f53\uff09\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u590d\u6742\u4f20\u611f\u548c\u63a7\u5236\u7684\u8584\u578b\u7269\u4f53\u5939\u6301\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5939\u6301\u5668\u5728\u5904\u7406\u8584\u578b\u3001\u4f4e\u8f6e\u5ed3\u7269\u4f53\u65f6\u9700\u8981\u590d\u6742\u4f20\u611f\u548c\u63a7\u5236\u7684\u95ee\u9898\uff0c\u5f00\u53d1\u80fd\u591f\u81ea\u9002\u5e94\u73af\u5883\u3001\u7b80\u5316\u64cd\u4f5c\u7684\u5939\u6301\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e24\u79cd\u4e92\u8865\u7684SCAL\u624b\u6307\uff1aSCAL-R\u91c7\u7528\u65cb\u8f6c\u9a71\u52a8\u548c\u4e3b\u52a8\u6307\u5c16\u6298\u53e0\u673a\u5236\uff0cSCAL-L\u91c7\u7528\u7ebf\u6027\u9a71\u52a8\u548c\u88ab\u52a8\u5f20\u5f00\u673a\u5236\u3002\u901a\u8fc73D\u6253\u5370\u5236\u9020\u4e24\u6307\u5939\u6301\u5668\uff0c\u5e76\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5728\u6570\u5341\u6b21\u8bd5\u9a8c\u4e2d\uff0c\u4e24\u79cd\u8bbe\u8ba1\u5747\u80fd\u7a33\u5b9a\u6293\u53d6\u5c0f\u96f6\u4ef6\u3001\u76d2\u5b50\u3001\u7f50\u5b50\u548c\u80f6\u5e26\u5377\u7b49\u7269\u4f53\uff0c\u4e14\u53ea\u9700\u6709\u9650\u8c03\u4f18\u3002\u51c6\u9759\u6001\u5206\u6790\u63d0\u4f9b\u4e86\u6307\u5c16\u529b\u6a21\u578b\uff0c\u4e3a\u8bbe\u8ba1\u548c\u64cd\u4f5c\u63d0\u4f9b\u51e0\u4f55\u611f\u77e5\u6307\u5bfc\u3002", "conclusion": "\u4e24\u79cd\u8bbe\u8ba1\u5177\u6709\u4e92\u8865\u7684\u5de5\u4f5c\u673a\u5236\uff0c\u4e3a\u4f7f\u7528\u7b80\u5355\u9a71\u52a8\u5b9e\u73b0\u9c81\u68d2\u7684\u73af\u5883\u81ea\u9002\u5e94\u6293\u53d6\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2510.22729", "categories": ["cs.AI", "cs.CL", "I.2.7; I.2.8"], "pdf": "https://arxiv.org/pdf/2510.22729", "abs": "https://arxiv.org/abs/2510.22729", "authors": ["Urja Kohli", "Aditi Singh", "Arun Sharma"], "title": "Critical Insights into Leading Conversational AI Models", "comment": "21 pages, 7 tables, 3 figures. Open-access preprint intended for\n  journal or conference submission", "summary": "Big Language Models (LLMs) are changing the way businesses use software, the\nway people live their lives and the way industries work. Companies like Google,\nHigh-Flyer, Anthropic, OpenAI and Meta are making better LLMs. So, it's crucial\nto look at how each model is different in terms of performance, moral behaviour\nand usability, as these differences are based on the different ideas that built\nthem. This study compares five top LLMs: Google's Gemini, High-Flyer's\nDeepSeek, Anthropic's Claude, OpenAI's GPT models and Meta's LLaMA. It performs\nthis by analysing three important factors: Performance and Accuracy, Ethics and\nBias Mitigation and Usability and Integration. It was found that Claude has\ngood moral reasoning, Gemini is better at multimodal capabilities and has\nstrong ethical frameworks. DeepSeek is great at reasoning based on facts, LLaMA\nis good for open applications and ChatGPT delivers balanced performance with a\nfocus on usage. It was concluded that these models are different in terms of\nhow well they work, how easy they are to use and how they treat people\nethically, making it a point that each model should be utilised by the user in\na way that makes the most of its strengths.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u4e94\u4e2a\u9876\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\uff08Gemini\u3001DeepSeek\u3001Claude\u3001GPT\u548cLLaMA\uff09\u5728\u6027\u80fd\u51c6\u786e\u6027\u3001\u4f26\u7406\u504f\u89c1\u7f13\u89e3\u548c\u53ef\u7528\u6027\u96c6\u6210\u4e09\u4e2a\u5173\u952e\u56e0\u7d20\u4e0a\u7684\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u6539\u53d8\u5546\u4e1a\u8f6f\u4ef6\u4f7f\u7528\u65b9\u5f0f\u3001\u4eba\u4eec\u751f\u6d3b\u65b9\u5f0f\u548c\u4ea7\u4e1a\u8fd0\u4f5c\u65b9\u5f0f\uff0c\u5404\u5927\u516c\u53f8\u4e0d\u65ad\u6539\u8fdbLLMs\uff0c\u56e0\u6b64\u9700\u8981\u5206\u6790\u4e0d\u540c\u6a21\u578b\u5728\u6027\u80fd\u3001\u9053\u5fb7\u884c\u4e3a\u548c\u53ef\u7528\u6027\u65b9\u9762\u7684\u5dee\u5f02\uff0c\u8fd9\u4e9b\u5dee\u5f02\u6e90\u4e8e\u5b83\u4eec\u7684\u4e0d\u540c\u8bbe\u8ba1\u7406\u5ff5\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4e09\u4e2a\u91cd\u8981\u56e0\u7d20\u8fdb\u884c\u6bd4\u8f83\uff1a\u6027\u80fd\u4e0e\u51c6\u786e\u6027\u3001\u4f26\u7406\u4e0e\u504f\u89c1\u7f13\u89e3\u3001\u53ef\u7528\u6027\u4e0e\u96c6\u6210\u3002", "result": "Claude\u5728\u9053\u5fb7\u63a8\u7406\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0cGemini\u5728\u591a\u6a21\u6001\u80fd\u529b\u548c\u5f3a\u4f26\u7406\u6846\u67b6\u65b9\u9762\u66f4\u4f18\uff0cDeepSeek\u64c5\u957f\u57fa\u4e8e\u4e8b\u5b9e\u7684\u63a8\u7406\uff0cLLaMA\u9002\u5408\u5f00\u653e\u5e94\u7528\uff0cChatGPT\u63d0\u4f9b\u5e73\u8861\u6027\u80fd\u5e76\u6ce8\u91cd\u4f7f\u7528\u4f53\u9a8c\u3002", "conclusion": "\u8fd9\u4e9b\u6a21\u578b\u5728\u5de5\u4f5c\u6548\u679c\u3001\u6613\u7528\u6027\u548c\u4f26\u7406\u5904\u7406\u65b9\u9762\u5b58\u5728\u5dee\u5f02\uff0c\u7528\u6237\u5e94\u6839\u636e\u5404\u6a21\u578b\u7684\u4f18\u52bf\u7279\u70b9\u6765\u5145\u5206\u5229\u7528\u5b83\u4eec\u3002"}}
{"id": "2510.23057", "categories": ["cs.RO", "cs.CV", "cs.SY", "eess.IV", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.23057", "abs": "https://arxiv.org/abs/2510.23057", "authors": ["Oskar Natan", "Jun Miura"], "title": "Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot Navigation", "comment": "Preprint notice, this manuscript has been submitted to IEEE sensors\n  journal for possible publication", "summary": "We present Seq-DeepIPC, a sequential end-to-end perception-to-control model\nfor legged robot navigation in realworld environments. Seq-DeepIPC advances\nintelligent sensing for autonomous legged navigation by tightly integrating\nmulti-modal perception (RGB-D + GNSS) with temporal fusion and control. The\nmodel jointly predicts semantic segmentation and depth estimation, giving\nricher spatial features for planning and control. For efficient deployment on\nedge devices, we use EfficientNet-B0 as the encoder, reducing computation while\nmaintaining accuracy. Heading estimation is simplified by removing the noisy\nIMU and instead computing the bearing angle directly from consecutive GNSS\npositions. We collected a larger and more diverse dataset that includes both\nroad and grass terrains, and validated Seq-DeepIPC on a robot dog. Comparative\nand ablation studies show that sequential inputs improve perception and control\nin our models, while other baselines do not benefit. Seq-DeepIPC achieves\ncompetitive or better results with reasonable model size; although GNSS-only\nheading is less reliable near tall buildings, it is robust in open areas.\nOverall, Seq-DeepIPC extends end-to-end navigation beyond wheeled robots to\nmore versatile and temporally-aware systems. To support future research, we\nwill release the codes to our GitHub repository at\nhttps://github.com/oskarnatan/Seq-DeepIPC.", "AI": {"tldr": "Seq-DeepIPC\u662f\u4e00\u4e2a\u7528\u4e8e\u817f\u5f0f\u673a\u5668\u4eba\u5bfc\u822a\u7684\u5e8f\u5217\u5316\u7aef\u5230\u7aef\u611f\u77e5-\u63a7\u5236\u6a21\u578b\uff0c\u6574\u5408\u591a\u6a21\u6001\u611f\u77e5\uff08RGB-D+GNSS\uff09\u4e0e\u65f6\u95f4\u878d\u5408\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u9ad8\u6548\u90e8\u7f72\uff0c\u5e76\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u6027\u80fd\u3002", "motivation": "\u5c06\u7aef\u5230\u7aef\u5bfc\u822a\u4ece\u8f6e\u5f0f\u673a\u5668\u4eba\u6269\u5c55\u5230\u66f4\u901a\u7528\u7684\u817f\u5f0f\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u901a\u8fc7\u65f6\u5e8f\u611f\u77e5\u63d0\u5347\u5bfc\u822a\u6027\u80fd\uff0c\u540c\u65f6\u89e3\u51b3\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u7684\u8ba1\u7b97\u6548\u7387\u95ee\u9898\u3002", "method": "\u4f7f\u7528EfficientNet-B0\u7f16\u7801\u5668\u51cf\u5c11\u8ba1\u7b97\u91cf\uff0c\u8054\u5408\u9884\u6d4b\u8bed\u4e49\u5206\u5272\u548c\u6df1\u5ea6\u4f30\u8ba1\uff0c\u901a\u8fc7\u8fde\u7eedGNSS\u4f4d\u7f6e\u8ba1\u7b97\u822a\u5411\u89d2\u66ff\u4ee3\u566a\u58f0IMU\uff0c\u6536\u96c6\u5305\u542b\u9053\u8def\u548c\u8349\u5730\u5730\u5f62\u7684\u591a\u6837\u5316\u6570\u636e\u96c6\u3002", "result": "\u5728\u673a\u5668\u4eba\u72d7\u4e0a\u9a8c\u8bc1\uff0c\u5e8f\u5217\u5316\u8f93\u5165\u63d0\u5347\u4e86\u611f\u77e5\u548c\u63a7\u5236\u6027\u80fd\uff0c\u6a21\u578b\u5927\u5c0f\u5408\u7406\u4e14\u7ed3\u679c\u5177\u6709\u7ade\u4e89\u529b\uff0cGNSS\u822a\u5411\u5728\u5f00\u9614\u533a\u57df\u7a33\u5b9a\u4f46\u5728\u9ad8\u697c\u9644\u8fd1\u53ef\u9760\u6027\u8f83\u4f4e\u3002", "conclusion": "Seq-DeepIPC\u6210\u529f\u5c06\u7aef\u5230\u7aef\u5bfc\u822a\u6269\u5c55\u5230\u817f\u5f0f\u673a\u5668\u4eba\uff0c\u5b9e\u73b0\u4e86\u65f6\u5e8f\u611f\u77e5\u7684\u901a\u7528\u7cfb\u7edf\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u5f00\u6e90\u4ee3\u7801\u652f\u6301\u3002"}}
{"id": "2510.22740", "categories": ["cs.RO", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.22740", "abs": "https://arxiv.org/abs/2510.22740", "authors": ["Sai Krishna Ghanta", "Ramviyas Parasuraman"], "title": "Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM", "comment": "IEEE International Symposium on Multi-Robot & Multi-Agent Systems\n  (MRS) 2025", "summary": "We consider the distributed pose-graph optimization (PGO) problem, which is\nfundamental in accurate trajectory estimation in multi-robot simultaneous\nlocalization and mapping (SLAM). Conventional iterative approaches linearize a\nhighly non-convex optimization objective, requiring repeated solving of normal\nequations, which often converge to local minima and thus produce suboptimal\nestimates. We propose a scalable, outlier-robust distributed planar PGO\nframework using Multi-Agent Reinforcement Learning (MARL). We cast distributed\nPGO as a partially observable Markov game defined on local pose-graphs, where\neach action refines a single edge's pose estimate. A graph partitioner\ndecomposes the global pose graph, and each robot runs a recurrent\nedge-conditioned Graph Neural Network (GNN) encoder with adaptive edge-gating\nto denoise noisy edges. Robots sequentially refine poses through a hybrid\npolicy that utilizes prior action memory and graph embeddings. After local\ngraph correction, a consensus scheme reconciles inter-robot disagreements to\nproduce a globally consistent estimate. Our extensive evaluations on a\ncomprehensive suite of synthetic and real-world datasets demonstrate that our\nlearned MARL-based actors reduce the global objective by an average of 37.5%\nmore than the state-of-the-art distributed PGO framework, while enhancing\ninference efficiency by at least 6X. We also demonstrate that actor replication\nallows a single learned policy to scale effortlessly to substantially larger\nrobot teams without any retraining. Code is publicly available at\nhttps://github.com/herolab-uga/policies-over-poses.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60(MARL)\u7684\u5206\u5e03\u5f0f\u4f4d\u59ff\u56fe\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u7f16\u7801\u5668\u548c\u6df7\u5408\u7b56\u7565\u5b9e\u73b0\u9ad8\u6548\u7684\u4f4d\u59ff\u4f18\u5316\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u51cf\u5c1137.5%\u5168\u5c40\u76ee\u6807\u51fd\u6570\u503c\uff0c\u63a8\u7406\u6548\u7387\u63d0\u53476\u500d\u4ee5\u4e0a\u3002", "motivation": "\u4f20\u7edf\u8fed\u4ee3\u65b9\u6cd5\u7ebf\u6027\u5316\u9ad8\u5ea6\u975e\u51f8\u4f18\u5316\u76ee\u6807\uff0c\u9700\u8981\u91cd\u590d\u6c42\u89e3\u6b63\u89c4\u65b9\u7a0b\uff0c\u5bb9\u6613\u6536\u655b\u5230\u5c40\u90e8\u6781\u5c0f\u503c\u4ea7\u751f\u6b21\u4f18\u4f30\u8ba1\u3002\u9700\u8981\u5f00\u53d1\u53ef\u6269\u5c55\u3001\u9c81\u68d2\u7684\u5206\u5e03\u5f0f\u4f4d\u59ff\u56fe\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u5c06\u5206\u5e03\u5f0fPGO\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\uff0c\u4f7f\u7528\u56fe\u5206\u5272\u5668\u5206\u89e3\u5168\u5c40\u4f4d\u59ff\u56fe\uff0c\u6bcf\u4e2a\u673a\u5668\u4eba\u8fd0\u884c\u5e26\u81ea\u9002\u5e94\u8fb9\u95e8\u63a7\u7684\u5faa\u73af\u56fe\u795e\u7ecf\u7f51\u7edc\u7f16\u7801\u5668\u53bb\u566a\uff0c\u901a\u8fc7\u6df7\u5408\u7b56\u7565\u987a\u5e8f\u4f18\u5316\u4f4d\u59ff\uff0c\u6700\u540e\u4f7f\u7528\u5171\u8bc6\u65b9\u6848\u534f\u8c03\u673a\u5668\u4eba\u95f4\u5dee\u5f02\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cMARL\u667a\u80fd\u4f53\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u5206\u5e03\u5f0fPGO\u6846\u67b6\u5e73\u5747\u51cf\u5c1137.5%\u5168\u5c40\u76ee\u6807\u51fd\u6570\u503c\uff0c\u63a8\u7406\u6548\u7387\u63d0\u5347\u81f3\u5c116\u500d\uff0c\u4e14\u5355\u5b66\u4e60\u7b56\u7565\u53ef\u6269\u5c55\u5230\u66f4\u5927\u673a\u5668\u4eba\u56e2\u961f\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "conclusion": "\u63d0\u51fa\u7684MARL\u6846\u67b6\u5728\u5206\u5e03\u5f0f\u4f4d\u59ff\u56fe\u4f18\u5316\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u5347\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.22751", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.22751", "abs": "https://arxiv.org/abs/2510.22751", "authors": ["Piyushkumar Patel"], "title": "Multi-Modal Fact-Verification Framework for Reducing Hallucinations in Large Language Models", "comment": null, "summary": "While Large Language Models have transformed how we interact with AI systems,\nthey suffer from a critical flaw: they confidently generate false information\nthat sounds entirely plausible. This hallucination problem has become a major\nbarrier to deploying these models in real-world applications where accuracy\nmatters. We developed a fact verification framework that catches and corrects\nthese errors in real-time by cross checking LLM outputs against multiple\nknowledge sources. Our system combines structured databases, live web searches,\nand academic literature to verify factual claims as they're generated. When we\ndetect inconsistencies, we automatically correct them while preserving the\nnatural flow of the response. Testing across various domains showed we could\nreduce hallucinations by 67% without sacrificing response quality. Domain\nexperts in healthcare, finance, and scientific research rated our corrected\noutputs 89% satisfactory a significant improvement over unverified LLM\nresponses. This work offers a practical solution for making LLMs more\ntrustworthy in applications where getting facts wrong isn't an option.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e8b\u5b9e\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u53c9\u68c0\u67e5LLM\u8f93\u51fa\u4e0e\u591a\u4e2a\u77e5\u8bc6\u6e90\u6765\u5b9e\u65f6\u6355\u83b7\u548c\u7ea0\u6b63\u5e7b\u89c9\u9519\u8bef\uff0c\u5c06\u5e7b\u89c9\u51cf\u5c1167%\uff0c\u4e13\u5bb6\u6ee1\u610f\u5ea6\u8fbe89%", "motivation": "LLM\u4f1a\u81ea\u4fe1\u5730\u751f\u6210\u542c\u8d77\u6765\u5408\u7406\u4f46\u9519\u8bef\u7684\u4fe1\u606f\uff0c\u8fd9\u5df2\u6210\u4e3a\u5728\u9700\u8981\u51c6\u786e\u6027\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u90e8\u7f72\u8fd9\u4e9b\u6a21\u578b\u7684\u4e3b\u8981\u969c\u788d", "method": "\u7ed3\u5408\u7ed3\u6784\u5316\u6570\u636e\u5e93\u3001\u5b9e\u65f6\u7f51\u7edc\u641c\u7d22\u548c\u5b66\u672f\u6587\u732e\u6765\u9a8c\u8bc1\u751f\u6210\u7684\u4e8b\u5b9e\u58f0\u660e\uff0c\u68c0\u6d4b\u5230\u4e0d\u4e00\u81f4\u65f6\u81ea\u52a8\u7ea0\u6b63\u540c\u65f6\u4fdd\u6301\u56de\u7b54\u7684\u81ea\u7136\u6d41\u7545\u6027", "result": "\u5728\u591a\u4e2a\u9886\u57df\u6d4b\u8bd5\u663e\u793a\u5e7b\u89c9\u51cf\u5c1167%\u4e14\u4e0d\u727a\u7272\u56de\u7b54\u8d28\u91cf\uff0c\u533b\u7597\u3001\u91d1\u878d\u548c\u79d1\u7814\u9886\u57df\u7684\u4e13\u5bb6\u5bf9\u7ea0\u6b63\u540e\u8f93\u51fa\u7684\u6ee1\u610f\u5ea6\u8fbe89%", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5728\u4e0d\u80fd\u51fa\u9519\u7684\u5e94\u7528\u4e2d\u4f7fLLM\u66f4\u53ef\u4fe1\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.23129", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.23129", "abs": "https://arxiv.org/abs/2510.23129", "authors": ["Sabino Francesco Roselli", "Ze Zhang", "Knut \u00c5kesson"], "title": "Combining High Level Scheduling and Low Level Control to Manage Fleets of Mobile Robots", "comment": null, "summary": "The deployment of mobile robots for material handling in industrial\nenvironments requires scalable coordination of large fleets in dynamic\nsettings. This paper presents a two-layer framework that combines high-level\nscheduling with low-level control. Tasks are assigned and scheduled using the\ncompositional algorithm ComSat, which generates time-parameterized routes for\neach robot. These schedules are then used by a distributed Model Predictive\nControl (MPC) system in real time to compute local reference trajectories,\naccounting for static and dynamic obstacles. The approach ensures safe,\ncollision-free operation, and supports rapid rescheduling in response to\ndisruptions such as robot failures or environmental changes. We evaluate the\nmethod in simulated 2D environments with varying road capacities and traffic\nconditions, demonstrating high task completion rates and robust behavior even\nunder congestion. The modular structure of the framework allows for\ncomputational tractability and flexibility, making it suitable for deployment\nin complex, real-world industrial scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u5de5\u4e1a\u73af\u5883\u4e2d\u5927\u89c4\u6a21\u673a\u5668\u4eba\u8f66\u961f\u534f\u8c03\u7684\u4e24\u5c42\u6846\u67b6\uff0c\u7ed3\u5408\u9ad8\u5c42\u8c03\u5ea6\u548c\u5e95\u5c42\u63a7\u5236\uff0c\u786e\u4fdd\u5b89\u5168\u65e0\u78b0\u649e\u64cd\u4f5c\u5e76\u652f\u6301\u5feb\u901f\u91cd\u8c03\u5ea6\u3002", "motivation": "\u5de5\u4e1a\u73af\u5883\u4e2d\u79fb\u52a8\u673a\u5668\u4eba\u7684\u7269\u6599\u642c\u8fd0\u9700\u8981\u5728\u5927\u89c4\u6a21\u52a8\u6001\u73af\u5883\u4e2d\u8fdb\u884c\u53ef\u6269\u5c55\u7684\u534f\u8c03\uff0c\u5e94\u5bf9\u673a\u5668\u4eba\u6545\u969c\u548c\u73af\u5883\u53d8\u5316\u7b49\u5e72\u6270\u3002", "method": "\u4f7f\u7528ComSat\u7b97\u6cd5\u8fdb\u884c\u4efb\u52a1\u5206\u914d\u548c\u8c03\u5ea6\uff0c\u751f\u6210\u65f6\u95f4\u53c2\u6570\u5316\u8def\u7ebf\uff0c\u7136\u540e\u901a\u8fc7\u5206\u5e03\u5f0f\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff08MPC\uff09\u7cfb\u7edf\u5b9e\u65f6\u8ba1\u7b97\u5c40\u90e8\u53c2\u8003\u8f68\u8ff9\uff0c\u8003\u8651\u9759\u6001\u548c\u52a8\u6001\u969c\u788d\u7269\u3002", "result": "\u5728\u6a21\u62df2D\u73af\u5883\u4e2d\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u9ad8\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u5728\u62e5\u5835\u60c5\u51b5\u4e0b\u7684\u9c81\u68d2\u884c\u4e3a\u3002", "conclusion": "\u8be5\u6846\u67b6\u7684\u6a21\u5757\u5316\u7ed3\u6784\u5b9e\u73b0\u4e86\u8ba1\u7b97\u53ef\u5904\u7406\u6027\u548c\u7075\u6d3b\u6027\uff0c\u9002\u7528\u4e8e\u590d\u6742\u73b0\u5b9e\u5de5\u4e1a\u573a\u666f\u7684\u90e8\u7f72\u3002"}}
{"id": "2510.22754", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22754", "abs": "https://arxiv.org/abs/2510.22754", "authors": ["Chunyu Li", "Shoubin Chen", "Dong Li", "Weixing Xue", "Qingquan Li"], "title": "TWC-SLAM: Multi-Agent Cooperative SLAM with Text Semantics and WiFi Features Integration for Similar Indoor Environments", "comment": "Accepted by the IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS) 2025", "summary": "Multi-agent cooperative SLAM often encounters challenges in similar indoor\nenvironments characterized by repetitive structures, such as corridors and\nrooms. These challenges can lead to significant inaccuracies in shared location\nidentification when employing point cloud-based techniques. To mitigate these\nissues, we introduce TWC-SLAM, a multi-agent cooperative SLAM framework that\nintegrates text semantics and WiFi signal features to enhance location\nidentification and loop closure detection. TWC-SLAM comprises a single-agent\nfront-end odometry module based on FAST-LIO2, a location identification and\nloop closure detection module that leverages text semantics and WiFi features,\nand a global mapping module. The agents are equipped with sensors capable of\ncapturing textual information and detecting WiFi signals. By correlating these\ndata sources, TWC-SLAM establishes a common location, facilitating point cloud\nalignment across different agents' maps. Furthermore, the system employs loop\nclosure detection and optimization modules to achieve global optimization and\ncohesive mapping. We evaluated our approach using an indoor dataset featuring\nsimilar corridors, rooms, and text signs. The results demonstrate that TWC-SLAM\nsignificantly improves the performance of cooperative SLAM systems in complex\nenvironments with repetitive architectural features.", "AI": {"tldr": "TWC-SLAM\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u534f\u540cSLAM\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u6587\u672c\u8bed\u4e49\u548cWiFi\u4fe1\u53f7\u7279\u5f81\u6765\u589e\u5f3a\u4f4d\u7f6e\u8bc6\u522b\u548c\u95ed\u73af\u68c0\u6d4b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5177\u6709\u91cd\u590d\u7ed3\u6784\u7684\u5ba4\u5185\u73af\u5883\u3002", "motivation": "\u5728\u5177\u6709\u91cd\u590d\u7ed3\u6784\uff08\u5982\u8d70\u5eca\u548c\u623f\u95f4\uff09\u7684\u76f8\u4f3c\u5ba4\u5185\u73af\u5883\u4e2d\uff0c\u57fa\u4e8e\u70b9\u4e91\u7684\u591a\u667a\u80fd\u4f53\u534f\u540cSLAM\u65b9\u6cd5\u5728\u5171\u4eab\u4f4d\u7f6e\u8bc6\u522b\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u51c6\u786e\u6027\u3002", "method": "TWC-SLAM\u5305\u542b\u57fa\u4e8eFAST-LIO2\u7684\u5355\u667a\u80fd\u4f53\u524d\u7aef\u91cc\u7a0b\u8ba1\u6a21\u5757\u3001\u5229\u7528\u6587\u672c\u8bed\u4e49\u548cWiFi\u7279\u5f81\u7684\u4f4d\u7f6e\u8bc6\u522b\u4e0e\u95ed\u73af\u68c0\u6d4b\u6a21\u5757\uff0c\u4ee5\u53ca\u5168\u5c40\u5efa\u56fe\u6a21\u5757\u3002\u667a\u80fd\u4f53\u914d\u5907\u80fd\u591f\u6355\u83b7\u6587\u672c\u4fe1\u606f\u548c\u68c0\u6d4bWiFi\u4fe1\u53f7\u7684\u4f20\u611f\u5668\u3002", "result": "\u5728\u5177\u6709\u76f8\u4f3c\u8d70\u5eca\u3001\u623f\u95f4\u548c\u6587\u672c\u6807\u5fd7\u7684\u5ba4\u5185\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0cTWC-SLAM\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u5177\u6709\u91cd\u590d\u5efa\u7b51\u7279\u5f81\u7684\u590d\u6742\u73af\u5883\u4e2d\u534f\u540cSLAM\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5173\u8054\u6587\u672c\u8bed\u4e49\u548cWiFi\u4fe1\u53f7\u6570\u636e\u6e90\uff0cTWC-SLAM\u80fd\u591f\u5efa\u7acb\u5171\u540c\u4f4d\u7f6e\uff0c\u4fc3\u8fdb\u4e0d\u540c\u667a\u80fd\u4f53\u5730\u56fe\u4e4b\u95f4\u7684\u70b9\u4e91\u5bf9\u9f50\uff0c\u5e76\u901a\u8fc7\u95ed\u73af\u68c0\u6d4b\u548c\u4f18\u5316\u6a21\u5757\u5b9e\u73b0\u5168\u5c40\u4f18\u5316\u548c\u4e00\u81f4\u6027\u5efa\u56fe\u3002"}}
{"id": "2510.22765", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22765", "abs": "https://arxiv.org/abs/2510.22765", "authors": ["Binxiao Xu", "Junyu Feng", "Ruichuan An", "Yulin Luo", "Shilin Yan", "Hao Liang", "Ming Lu", "Wentao Zhang"], "title": "Jarvis: Towards Personalized AI Assistant via Personal KV-Cache Retrieval", "comment": "19 pages, 7 figures", "summary": "The rapid development of Vision-language models (VLMs) enables open-ended\nperception and reasoning. Recent works have started to investigate how to adapt\ngeneral-purpose VLMs into personalized assistants. Even commercial models such\nas ChatGPT now support model personalization by incorporating user-specific\ninformation. However, existing methods either learn a set of concept tokens or\ntrain a VLM to utilize user-specific information. However, both pipelines\nstruggle to generate accurate answers as personalized assistants. We introduce\nJarvis, an innovative framework for a personalized AI assistant through\npersonal KV-Cache retrieval, which stores user-specific information in the\nKV-Caches of both textual and visual tokens. The textual tokens are created by\nsummarizing user information into metadata, while the visual tokens are\nproduced by extracting distinct image patches from the user's images. When\nanswering a question, Jarvis first retrieves related KV-Caches from personal\nstorage and uses them to ensure accuracy in responses. We also introduce a\nfine-grained benchmark built with the same distinct image patch mining\npipeline, emphasizing accurate question answering based on fine-grained\nuser-specific information. Jarvis is capable of providing more accurate\nresponses, particularly when they depend on specific local details. Jarvis\nachieves state-of-the-art results in both visual question answering and\ntext-only tasks across multiple datasets, indicating a practical path toward\npersonalized AI assistants. The code and dataset will be released.", "AI": {"tldr": "Jarvis\u662f\u4e00\u4e2a\u901a\u8fc7\u4e2a\u4ebaKV-Cache\u68c0\u7d22\u5b9e\u73b0\u4e2a\u6027\u5316AI\u52a9\u624b\u7684\u521b\u65b0\u6846\u67b6\uff0c\u5728\u6587\u672c\u548c\u89c6\u89c9token\u7684KV-Cache\u4e2d\u5b58\u50a8\u7528\u6237\u7279\u5b9a\u4fe1\u606f\uff0c\u901a\u8fc7\u68c0\u7d22\u76f8\u5173KV-Cache\u6765\u786e\u4fdd\u56de\u7b54\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u5b66\u4e60\u6982\u5ff5token\u96c6\u5408\uff0c\u8981\u4e48\u8bad\u7ec3VLM\u6765\u5229\u7528\u7528\u6237\u7279\u5b9a\u4fe1\u606f\uff0c\u4f46\u4e24\u79cd\u65b9\u6cd5\u90fd\u96be\u4ee5\u751f\u6210\u51c6\u786e\u7b54\u6848\u4f5c\u4e3a\u4e2a\u6027\u5316\u52a9\u624b\u3002", "method": "\u5c06\u7528\u6237\u7279\u5b9a\u4fe1\u606f\u5b58\u50a8\u5728\u6587\u672c\u548c\u89c6\u89c9token\u7684KV-Cache\u4e2d\uff0c\u6587\u672ctoken\u901a\u8fc7\u603b\u7ed3\u7528\u6237\u4fe1\u606f\u4e3a\u5143\u6570\u636e\u521b\u5efa\uff0c\u89c6\u89c9token\u901a\u8fc7\u4ece\u7528\u6237\u56fe\u50cf\u4e2d\u63d0\u53d6\u72ec\u7279\u56fe\u50cf\u5757\u4ea7\u751f\u3002\u56de\u7b54\u95ee\u9898\u524d\u5148\u68c0\u7d22\u76f8\u5173KV-Cache\u3002", "result": "Jarvis\u80fd\u591f\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u54cd\u5e94\uff0c\u7279\u522b\u662f\u5728\u4f9d\u8d56\u7279\u5b9a\u5c40\u90e8\u7ec6\u8282\u65f6\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u7684\u89c6\u89c9\u95ee\u7b54\u548c\u7eaf\u6587\u672c\u4efb\u52a1\u4e2d\u53d6\u5f97\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "Jarvis\u4e3a\u4e2a\u6027\u5316AI\u52a9\u624b\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u8def\u5f84\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5c06\u53d1\u5e03\u3002"}}
{"id": "2510.22784", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22784", "abs": "https://arxiv.org/abs/2510.22784", "authors": ["Guangyao Shi", "Yuwei Wu", "Vijay Kumar", "Gaurav S. Sukhatme"], "title": "PIP-LLM: Integrating PDDL-Integer Programming with LLMs for Coordinating Multi-Robot Teams Using Natural Language", "comment": null, "summary": "Enabling robot teams to execute natural language commands requires\ntranslating high-level instructions into feasible, efficient multi-robot plans.\nWhile Large Language Models (LLMs) combined with Planning Domain Description\nLanguage (PDDL) offer promise for single-robot scenarios, existing approaches\nstruggle with multi-robot coordination due to brittle task decomposition, poor\nscalability, and low coordination efficiency.\n  We introduce PIP-LLM, a language-based coordination framework that consists\nof PDDL-based team-level planning and Integer Programming (IP) based\nrobot-level planning. PIP-LLMs first decomposes the command by translating the\ncommand into a team-level PDDL problem and solves it to obtain a team-level\nplan, abstracting away robot assignment. Each team-level action represents a\nsubtask to be finished by the team. Next, this plan is translated into a\ndependency graph representing the subtasks' dependency structure. Such a\ndependency graph is then used to guide the robot-level planning, in which each\nsubtask node will be formulated as an IP-based task allocation problem,\nexplicitly optimizing travel costs and workload while respecting robot\ncapabilities and user-defined constraints. This separation of planning from\nassignment allows PIP-LLM to avoid the pitfalls of syntax-based decomposition\nand scale to larger teams. Experiments across diverse tasks show that PIP-LLM\nimproves plan success rate, reduces maximum and average travel costs, and\nachieves better load balancing compared to state-of-the-art baselines.", "AI": {"tldr": "PIP-LLM\u662f\u4e00\u4e2a\u57fa\u4e8e\u8bed\u8a00\u7684\u591a\u673a\u5668\u4eba\u534f\u8c03\u6846\u67b6\uff0c\u901a\u8fc7PDDL\u56e2\u961f\u7ea7\u89c4\u5212\u548c\u6574\u6570\u89c4\u5212\u673a\u5668\u4eba\u7ea7\u89c4\u5212\u7684\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u591a\u673a\u5668\u4eba\u534f\u8c03\u4e2d\u7684\u4efb\u52a1\u5206\u89e3\u3001\u53ef\u6269\u5c55\u6027\u548c\u534f\u8c03\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u548cPDDL\u7684\u65b9\u6cd5\u5728\u5355\u673a\u5668\u4eba\u573a\u666f\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u673a\u5668\u4eba\u534f\u8c03\u4e2d\u5b58\u5728\u4efb\u52a1\u5206\u89e3\u8106\u5f31\u3001\u53ef\u6269\u5c55\u6027\u5dee\u548c\u534f\u8c03\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "PIP-LLM\u91c7\u7528\u4e24\u7ea7\u89c4\u5212\uff1a\u9996\u5148\u5c06\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u8f6c\u6362\u4e3a\u56e2\u961f\u7ea7PDDL\u95ee\u9898\u5e76\u6c42\u89e3\uff0c\u83b7\u5f97\u62bd\u8c61\u7684\u4efb\u52a1\u8ba1\u5212\uff1b\u7136\u540e\u5c06\u8be5\u8ba1\u5212\u8f6c\u6362\u4e3a\u4f9d\u8d56\u56fe\uff0c\u6307\u5bfc\u673a\u5668\u4eba\u7ea7\u7684\u6574\u6570\u89c4\u5212\u4efb\u52a1\u5206\u914d\uff0c\u4f18\u5316\u65c5\u884c\u6210\u672c\u548c\u5de5\u4f5c\u8d1f\u8f7d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPIP-LLM\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u63d0\u9ad8\u4e86\u8ba1\u5212\u6210\u529f\u7387\uff0c\u964d\u4f4e\u4e86\u6700\u5927\u548c\u5e73\u5747\u65c5\u884c\u6210\u672c\uff0c\u5e76\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u8d1f\u8f7d\u5747\u8861\u3002", "conclusion": "PIP-LLM\u901a\u8fc7\u5c06\u89c4\u5212\u4e0e\u5206\u914d\u5206\u79bb\uff0c\u907f\u514d\u4e86\u57fa\u4e8e\u8bed\u6cd5\u5206\u89e3\u7684\u7f3a\u9677\uff0c\u80fd\u591f\u6269\u5c55\u5230\u66f4\u5927\u7684\u56e2\u961f\u89c4\u6a21\uff0c\u662f\u591a\u673a\u5668\u4eba\u534f\u8c03\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.22780", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.22780", "abs": "https://arxiv.org/abs/2510.22780", "authors": ["Zora Zhiruo Wang", "Yijia Shao", "Omar Shaikh", "Daniel Fried", "Graham Neubig", "Diyi Yang"], "title": "How Do AI Agents Do Human Work? Comparing AI and Human Workflows Across Diverse Occupations", "comment": null, "summary": "AI agents are continually optimized for tasks related to human work, such as\nsoftware engineering and professional writing, signaling a pressing trend with\nsignificant impacts on the human workforce. However, these agent developments\nhave often not been grounded in a clear understanding of how humans execute\nwork, to reveal what expertise agents possess and the roles they can play in\ndiverse workflows. In this work, we study how agents do human work by\npresenting the first direct comparison of human and agent workers across\nmultiple essential work-related skills: data analysis, engineering,\ncomputation, writing, and design. To better understand and compare\nheterogeneous computer-use activities of workers, we introduce a scalable\ntoolkit to induce interpretable, structured workflows from either human or\nagent computer-use activities. Using such induced workflows, we compare how\nhumans and agents perform the same tasks and find that: (1) While agents\nexhibit promise in their alignment to human workflows, they take an\noverwhelmingly programmatic approach across all work domains, even for\nopen-ended, visually dependent tasks like design, creating a contrast with the\nUI-centric methods typically used by humans. (2) Agents produce work of\ninferior quality, yet often mask their deficiencies via data fabrication and\nmisuse of advanced tools. (3) Nonetheless, agents deliver results 88.3% faster\nand cost 90.4-96.2% less than humans, highlighting the potential for enabling\nefficient collaboration by delegating easily programmable tasks to agents.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u76f4\u63a5\u6bd4\u8f83\u4eba\u7c7b\u4e0eAI\u4ee3\u7406\u5728\u591a\u4e2a\u5de5\u4f5c\u6280\u80fd\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4ee3\u7406\u867d\u7136\u5de5\u4f5c\u8d28\u91cf\u8f83\u5dee\u4e14\u5b58\u5728\u6570\u636e\u4f2a\u9020\u95ee\u9898\uff0c\u4f46\u6548\u7387\u66f4\u9ad8\u3001\u6210\u672c\u66f4\u4f4e\uff0c\u9002\u5408\u5904\u7406\u53ef\u7f16\u7a0b\u4efb\u52a1\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u7684\u5f00\u53d1\u7f3a\u4e4f\u5bf9\u4eba\u7c7b\u5de5\u4f5c\u65b9\u5f0f\u7684\u6e05\u6670\u7406\u89e3\uff0c\u9700\u8981\u63ed\u793a\u4ee3\u7406\u7684\u4e13\u4e1a\u80fd\u529b\u53ca\u5176\u5728\u4e0d\u540c\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u89d2\u8272\u3002", "method": "\u5f15\u5165\u53ef\u6269\u5c55\u5de5\u5177\u5305\uff0c\u4ece\u4eba\u7c7b\u6216\u4ee3\u7406\u7684\u8ba1\u7b97\u673a\u4f7f\u7528\u6d3b\u52a8\u4e2d\u63d0\u53d6\u53ef\u89e3\u91ca\u7684\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5e76\u5728\u6570\u636e\u5206\u6790\u3001\u5de5\u7a0b\u3001\u8ba1\u7b97\u3001\u5199\u4f5c\u548c\u8bbe\u8ba1\u7b49\u4efb\u52a1\u4e0a\u76f4\u63a5\u6bd4\u8f83\u4eba\u7c7b\u4e0e\u4ee3\u7406\u7684\u8868\u73b0\u3002", "result": "\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u4f46\u8fc7\u4e8e\u7a0b\u5e8f\u5316\uff0c\u5de5\u4f5c\u8d28\u91cf\u8f83\u5dee\u4e14\u5b58\u5728\u6570\u636e\u4f2a\u9020\u95ee\u9898\uff0c\u4f46\u4ea4\u4ed8\u901f\u5ea6\u5feb88.3%\uff0c\u6210\u672c\u4f4e90.4-96.2%\u3002", "conclusion": "\u4ee3\u7406\u5728\u6548\u7387\u548c\u7ecf\u6d4e\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u9002\u5408\u5904\u7406\u53ef\u7f16\u7a0b\u4efb\u52a1\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u8d28\u91cf\u95ee\u9898\u548c\u4f26\u7406\u98ce\u9669\uff0c\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u4eba\u673a\u534f\u4f5c\u3002"}}
{"id": "2510.22789", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22789", "abs": "https://arxiv.org/abs/2510.22789", "authors": ["Abhijeet M. Kulkarni", "Ioannis Poulakakis", "Guoquan Huang"], "title": "Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning", "comment": null, "summary": "Accurate full-body motion prediction is essential for the safe, autonomous\nnavigation of legged robots, enabling critical capabilities like limb-level\ncollision checking in cluttered environments. Simplified kinematic models often\nfail to capture the complex, closed-loop dynamics of the robot and its\nlow-level controller, limiting their predictions to simple planar motion. To\naddress this, we present a learning-based observer-predictor framework that\naccurately predicts this motion. Our method features a neural observer with\nprovable UUB guarantees that provides a reliable latent state estimate from a\nhistory of proprioceptive measurements. This stable estimate initializes a\ncomputationally efficient predictor, designed for the rapid, parallel\nevaluation of thousands of potential trajectories required by modern\nsampling-based planners. We validated the system by integrating our neural\npredictor into an MPPI-based planner on a Vision 60 quadruped. Hardware\nexperiments successfully demonstrated effective, limb-aware motion planning in\na challenging, narrow passage and over small objects, highlighting our system's\nability to provide a robust foundation for high-performance, collision-aware\nplanning on dynamic robotic platforms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684\u89c2\u6d4b\u5668-\u9884\u6d4b\u5668\u6846\u67b6\uff0c\u7528\u4e8e\u51c6\u786e\u9884\u6d4b\u56db\u8db3\u673a\u5668\u4eba\u7684\u5168\u8eab\u8fd0\u52a8\uff0c\u89e3\u51b3\u4e86\u7b80\u5316\u8fd0\u52a8\u5b66\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u590d\u6742\u95ed\u73af\u52a8\u529b\u5b66\u7684\u95ee\u9898\u3002", "motivation": "\u51c6\u786e\u7684\u5168\u8eab\u8fd0\u52a8\u9884\u6d4b\u5bf9\u4e8e\u56db\u8db3\u673a\u5668\u4eba\u7684\u5b89\u5168\u81ea\u4e3b\u5bfc\u822a\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u73af\u5883\u4e2d\u8fdb\u884c\u80a2\u4f53\u7ea7\u78b0\u649e\u68c0\u6d4b\u3002\u73b0\u6709\u7b80\u5316\u8fd0\u52a8\u5b66\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u673a\u5668\u4eba\u548c\u5e95\u5c42\u63a7\u5236\u5668\u7684\u590d\u6742\u95ed\u73af\u52a8\u529b\u5b66\u3002", "method": "\u91c7\u7528\u5b66\u4e60\u578b\u89c2\u6d4b\u5668-\u9884\u6d4b\u5668\u6846\u67b6\uff0c\u5305\u542b\u5177\u6709\u53ef\u8bc1\u660eUUB\u4fdd\u8bc1\u7684\u795e\u7ecf\u89c2\u6d4b\u5668\uff0c\u4ece\u672c\u4f53\u611f\u77e5\u6d4b\u91cf\u5386\u53f2\u63d0\u4f9b\u53ef\u9760\u7684\u6f5c\u5728\u72b6\u6001\u4f30\u8ba1\uff0c\u7136\u540e\u521d\u59cb\u5316\u8ba1\u7b97\u9ad8\u6548\u7684\u9884\u6d4b\u5668\u8fdb\u884c\u8f68\u8ff9\u8bc4\u4f30\u3002", "result": "\u5728Vision 60\u56db\u8db3\u673a\u5668\u4eba\u4e0a\u96c6\u6210\u795e\u7ecf\u9884\u6d4b\u5668\u5230MPPI\u89c4\u5212\u5668\u4e2d\uff0c\u786c\u4ef6\u5b9e\u9a8c\u6210\u529f\u5c55\u793a\u4e86\u5728\u6311\u6218\u6027\u72ed\u7a84\u901a\u9053\u548c\u5c0f\u7269\u4f53\u4e0a\u7684\u6709\u6548\u80a2\u4f53\u611f\u77e5\u8fd0\u52a8\u89c4\u5212\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u52a8\u6001\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u7684\u9ad8\u6027\u80fd\u78b0\u649e\u611f\u77e5\u89c4\u5212\u63d0\u4f9b\u4e86\u7a33\u5065\u57fa\u7840\uff0c\u80fd\u591f\u5b9e\u73b0\u6709\u6548\u7684\u80a2\u4f53\u611f\u77e5\u8fd0\u52a8\u89c4\u5212\u3002"}}
{"id": "2510.22781", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22781", "abs": "https://arxiv.org/abs/2510.22781", "authors": ["Xiaofeng Zhu", "Yunshen Zhou"], "title": "Agentic Meta-Orchestrator for Multi-task Copilots", "comment": null, "summary": "Microsoft Copilot suites serve as the universal entry point for various\nagents skilled in handling important tasks, ranging from assisting a customer\nwith product purchases to detecting vulnerabilities in corporate programming\ncode. Each agent can be powered by language models, software engineering\noperations, such as database retrieval, and internal \\& external knowledge. The\nrepertoire of a copilot can expand dynamically with new agents. This requires a\nrobust orchestrator that can distribute tasks from user prompts to the right\nagents. In this work, we propose an Agentic Meta-orchestrator (AMO) for\nhandling multiple tasks and scalable agents in copilot services, which can\nprovide both natural language and action responses. We will also demonstrate\nthe planning that leverages meta-learning, i.e., a trained decision tree model\nfor deciding the best inference strategy among various agents/models. We\nshowcase the effectiveness of our AMO through two production use cases:\nMicrosoft 365 (M365) E-Commerce Copilot and code compliance copilot. M365\nE-Commerce Copilot advertises Microsoft products to external customers to\npromote sales success. The M365 E-Commerce Copilot provides up-to-date product\ninformation and connects to multiple agents, such as relational databases and\nhuman customer support. The code compliance copilot scans the internal DevOps\ncode to detect known and new compliance issues in pull requests (PR).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5fae\u8f6fCopilot\u670d\u52a1\u7684Agentic Meta-orchestrator\uff08AMO\uff09\uff0c\u80fd\u591f\u5904\u7406\u591a\u4efb\u52a1\u548c\u53ef\u6269\u5c55\u7684\u4ee3\u7406\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u51b3\u7b56\u6811\u6a21\u578b\u9009\u62e9\u6700\u4f73\u63a8\u7406\u7b56\u7565\u3002", "motivation": "\u968f\u7740Copilot\u670d\u52a1\u4e2d\u4ee3\u7406\u6570\u91cf\u7684\u52a8\u6001\u6269\u5c55\uff0c\u9700\u8981\u4e00\u4e2a\u5f3a\u5927\u7684\u7f16\u6392\u5668\u6765\u5c06\u7528\u6237\u63d0\u793a\u7684\u4efb\u52a1\u5206\u53d1\u7ed9\u6b63\u786e\u7684\u4ee3\u7406\u3002", "method": "\u4f7f\u7528Agentic Meta-orchestrator\uff08AMO\uff09\u4f5c\u4e3a\u7f16\u6392\u5668\uff0c\u5229\u7528\u5143\u5b66\u4e60\u8bad\u7ec3\u51b3\u7b56\u6811\u6a21\u578b\u6765\u51b3\u5b9a\u4e0d\u540c\u4ee3\u7406/\u6a21\u578b\u95f4\u7684\u6700\u4f73\u63a8\u7406\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u751f\u4ea7\u7528\u4f8b\u5c55\u793a\u4e86AMO\u7684\u6709\u6548\u6027\uff1aM365\u7535\u5b50\u5546\u52a1Copilot\u548c\u4ee3\u7801\u5408\u89c4Copilot\uff0c\u524d\u8005\u63d0\u4f9b\u6700\u65b0\u4ea7\u54c1\u4fe1\u606f\u5e76\u8fde\u63a5\u591a\u4e2a\u4ee3\u7406\uff0c\u540e\u8005\u626b\u63cf\u5185\u90e8DevOps\u4ee3\u7801\u68c0\u6d4b\u5408\u89c4\u95ee\u9898\u3002", "conclusion": "AMO\u80fd\u591f\u6709\u6548\u5904\u7406Copilot\u670d\u52a1\u4e2d\u7684\u591a\u4efb\u52a1\u548c\u53ef\u6269\u5c55\u4ee3\u7406\uff0c\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u548c\u52a8\u4f5c\u54cd\u5e94\u3002"}}
{"id": "2510.22814", "categories": ["cs.AI", "I.2.0; K.4.1; K.6.m"], "pdf": "https://arxiv.org/pdf/2510.22814", "abs": "https://arxiv.org/abs/2510.22814", "authors": ["Mohamed El Louadi", "Emna Ben Romdhane"], "title": "Will Humanity Be Rendered Obsolete by AI?", "comment": null, "summary": "This article analyzes the existential risks artificial intelligence (AI)\nposes to humanity, tracing the trajectory from current AI to ultraintelligence.\nDrawing on Irving J. Good and Nick Bostrom's theoretical work, plus recent\npublications (AI 2027; If Anyone Builds It, Everyone Dies), it explores AGI and\nsuperintelligence. Considering machines' exponentially growing cognitive power\nand hypothetical IQs, it addresses the ethical and existential implications of\nan intelligence vastly exceeding humanity's, fundamentally alien. Human\nextinction may result not from malice, but from uncontrollable, indifferent\ncognitive superiority.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4eba\u5de5\u667a\u80fd\u5bf9\u4eba\u7c7b\u6784\u6210\u7684\u751f\u5b58\u98ce\u9669\uff0c\u4ece\u5f53\u524dAI\u53d1\u5c55\u5230\u8d85\u667a\u80fd\u7684\u8f68\u8ff9\uff0c\u63a2\u8ba8\u4e86AGI\u548c\u8d85\u7ea7\u667a\u80fd\u7684\u4f26\u7406\u4e0e\u751f\u5b58\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u4eba\u5de5\u667a\u80fd\u4ece\u5f53\u524d\u72b6\u6001\u53d1\u5c55\u5230\u8d85\u667a\u80fd\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u5bf9\u4eba\u7c7b\u6784\u6210\u7684\u751f\u5b58\u5a01\u80c1\uff0c\u7279\u522b\u662f\u5f53\u673a\u5668\u667a\u80fd\u8fdc\u8d85\u4eba\u7c7b\u65f6\u53ef\u80fd\u5e26\u6765\u7684\u4e0d\u53ef\u63a7\u98ce\u9669\u3002", "method": "\u57fa\u4e8eIrving J. Good\u548cNick Bostrom\u7684\u7406\u8bba\u5de5\u4f5c\uff0c\u7ed3\u5408\u8fd1\u671f\u51fa\u7248\u7269\u300aAI 2027\u300b\u548c\u300a\u5982\u679c\u6709\u4eba\u5efa\u9020\u5b83\uff0c\u6240\u6709\u4eba\u90fd\u4f1a\u6b7b\u300b\u7684\u5206\u6790\uff0c\u63a2\u8ba8AGI\u548c\u8d85\u7ea7\u667a\u80fd\u7684\u53d1\u5c55\u8f68\u8ff9\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u4eba\u7c7b\u706d\u7edd\u53ef\u80fd\u4e0d\u662f\u6e90\u4e8e\u6076\u610f\uff0c\u800c\u662f\u7531\u4e8e\u65e0\u6cd5\u63a7\u5236\u7684\u3001\u51b7\u6f20\u7684\u8ba4\u77e5\u4f18\u8d8a\u6027\uff0c\u5f53\u673a\u5668\u667a\u80fd\u6307\u6570\u7ea7\u589e\u957f\u5e76\u8fdc\u8d85\u4eba\u7c7b\u65f6\u3002", "conclusion": "\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u5230\u8d85\u667a\u80fd\u9636\u6bb5\u53ef\u80fd\u5bf9\u4eba\u7c7b\u6784\u6210\u6839\u672c\u6027\u7684\u751f\u5b58\u5a01\u80c1\uff0c\u8fd9\u79cd\u5a01\u80c1\u6e90\u4e8e\u667a\u80fd\u5dee\u8ddd\u800c\u975e\u6076\u610f\uff0c\u9700\u8981\u8ba4\u771f\u5bf9\u5f85\u548c\u9632\u8303\u3002"}}
{"id": "2510.22825", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22825", "abs": "https://arxiv.org/abs/2510.22825", "authors": ["Nan Zhang"], "title": "Kinematically Controllable Cable Robots with Reconfigurable End-effectors", "comment": "7 pages, 12 figures, Technical Report", "summary": "To enlarge the translational workspace of cable-driven robots, one common\napproach is to increase the number of cables. However, this introduces two\nchallenges: (1) cable interference significantly reduces the rotational\nworkspace, and (2) the solution of tensions in cables becomes non-unique,\nresulting in difficulties for kinematic control of the robot. In this work, we\ndesign structurally simple reconfigurable end-effectors for cable robots. By\nincorporating a spring, a helical-grooved shaft, and a matching nut, relative\nlinear motions between end-effector components are converted into relative\nrotations, thereby expanding the rotational workspace of the mechanism.\nMeanwhile, a bearing is introduced to provide an additional rotational degree\nof freedom, making the mechanism non-redundant. As a result, the robot's motion\ncan be controlled purely through kinematics without additional tension sensing\nand control.", "AI": {"tldr": "\u8bbe\u8ba1\u53ef\u91cd\u6784\u672b\u7aef\u6267\u884c\u5668\uff0c\u901a\u8fc7\u5f39\u7c27\u3001\u87ba\u65cb\u69fd\u8f74\u548c\u87ba\u6bcd\u5c06\u7ebf\u6027\u8fd0\u52a8\u8f6c\u6362\u4e3a\u65cb\u8f6c\u8fd0\u52a8\uff0c\u6269\u5c55\u7f06\u7ef3\u673a\u5668\u4eba\u7684\u65cb\u8f6c\u5de5\u4f5c\u7a7a\u95f4\uff0c\u540c\u65f6\u5f15\u5165\u8f74\u627f\u63d0\u4f9b\u989d\u5916\u65cb\u8f6c\u81ea\u7531\u5ea6\uff0c\u4f7f\u673a\u6784\u975e\u5197\u4f59\uff0c\u5b9e\u73b0\u7eaf\u8fd0\u52a8\u5b66\u63a7\u5236\u3002", "motivation": "\u589e\u52a0\u7f06\u7ef3\u6570\u91cf\u4ee5\u6269\u5927\u5e73\u79fb\u5de5\u4f5c\u7a7a\u95f4\u4f1a\u5e26\u6765\u4e24\u4e2a\u95ee\u9898\uff1a\u7f06\u7ef3\u5e72\u6d89\u663e\u8457\u51cf\u5c11\u65cb\u8f6c\u5de5\u4f5c\u7a7a\u95f4\uff0c\u4ee5\u53ca\u7f06\u7ef3\u5f20\u529b\u89e3\u4e0d\u552f\u4e00\u5bfc\u81f4\u8fd0\u52a8\u63a7\u5236\u56f0\u96be\u3002", "method": "\u8bbe\u8ba1\u7ed3\u6784\u7b80\u5355\u7684\u53ef\u91cd\u6784\u672b\u7aef\u6267\u884c\u5668\uff0c\u5305\u542b\u5f39\u7c27\u3001\u87ba\u65cb\u69fd\u8f74\u548c\u5339\u914d\u87ba\u6bcd\uff0c\u5c06\u672b\u7aef\u6267\u884c\u5668\u7ec4\u4ef6\u95f4\u7684\u76f8\u5bf9\u7ebf\u6027\u8fd0\u52a8\u8f6c\u6362\u4e3a\u76f8\u5bf9\u65cb\u8f6c\u8fd0\u52a8\uff0c\u5e76\u5f15\u5165\u8f74\u627f\u63d0\u4f9b\u989d\u5916\u65cb\u8f6c\u81ea\u7531\u5ea6\u3002", "result": "\u6269\u5c55\u4e86\u673a\u6784\u7684\u65cb\u8f6c\u5de5\u4f5c\u7a7a\u95f4\uff0c\u4f7f\u673a\u6784\u975e\u5197\u4f59\uff0c\u673a\u5668\u4eba\u8fd0\u52a8\u53ef\u901a\u8fc7\u7eaf\u8fd0\u52a8\u5b66\u63a7\u5236\uff0c\u65e0\u9700\u989d\u5916\u7684\u5f20\u529b\u4f20\u611f\u548c\u63a7\u5236\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u53ef\u91cd\u6784\u672b\u7aef\u6267\u884c\u5668\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u7f06\u7ef3\u673a\u5668\u4eba\u56e0\u589e\u52a0\u7f06\u7ef3\u6570\u91cf\u800c\u5bfc\u81f4\u7684\u65cb\u8f6c\u5de5\u4f5c\u7a7a\u95f4\u7f29\u5c0f\u548c\u63a7\u5236\u56f0\u96be\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u7b80\u5355\u53ef\u9760\u7684\u8fd0\u52a8\u63a7\u5236\u3002"}}
{"id": "2510.22832", "categories": ["cs.AI", "cs.LG", "stat.ML", "68T07 (Primary) 62M45, 37N99 (Secondary)", "I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2510.22832", "abs": "https://arxiv.org/abs/2510.22832", "authors": ["Long H Dang", "David Rawlinson"], "title": "HRM-Agent: Training a recurrent reasoning model in dynamic environments using reinforcement learning", "comment": "14 pages, 9 figures, 1 table", "summary": "The Hierarchical Reasoning Model (HRM) has impressive reasoning abilities\ngiven its small size, but has only been applied to supervised, static,\nfully-observable problems. One of HRM's strengths is its ability to adapt its\ncomputational effort to the difficulty of the problem. However, in its current\nform it cannot integrate and reuse computation from previous time-steps if the\nproblem is dynamic, uncertain or partially observable, or be applied where the\ncorrect action is undefined, characteristics of many real-world problems.\n  This paper presents HRM-Agent, a variant of HRM trained using only\nreinforcement learning. We show that HRM can learn to navigate to goals in\ndynamic and uncertain maze environments. Recent work suggests that HRM's\nreasoning abilities stem from its recurrent inference process. We explore the\ndynamics of the recurrent inference process and find evidence that it is\nsuccessfully reusing computation from earlier environment time-steps.", "AI": {"tldr": "HRM-Agent\u662f\u57fa\u4e8e\u5206\u5c42\u63a8\u7406\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u53d8\u4f53\uff0c\u80fd\u591f\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u7684\u8ff7\u5bab\u73af\u5883\u4e2d\u5b66\u4e60\u5bfc\u822a\u5230\u76ee\u6807\uff0c\u5e76\u80fd\u591f\u91cd\u7528\u5148\u524d\u65f6\u95f4\u6b65\u7684\u8ba1\u7b97\u3002", "motivation": "\u539f\u59cbHRM\u6a21\u578b\u867d\u7136\u63a8\u7406\u80fd\u529b\u5f3a\uff0c\u4f46\u4ec5\u9650\u4e8e\u76d1\u7763\u5b66\u4e60\u3001\u9759\u6001\u3001\u5b8c\u5168\u53ef\u89c2\u6d4b\u7684\u95ee\u9898\uff0c\u65e0\u6cd5\u5904\u7406\u52a8\u6001\u3001\u4e0d\u786e\u5b9a\u6216\u90e8\u5206\u53ef\u89c2\u6d4b\u7684\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86HRM-Agent\uff0c\u8fd9\u662fHRM\u7684\u53d8\u4f53\uff0c\u4ec5\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u8bad\u7ec3\uff0c\u63a2\u7d22\u5176\u5faa\u73af\u63a8\u7406\u8fc7\u7a0b\u7684\u52a8\u6001\u7279\u6027\u3002", "result": "HRM-Agent\u6210\u529f\u5b66\u4f1a\u4e86\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u7684\u8ff7\u5bab\u73af\u5883\u4e2d\u5bfc\u822a\u5230\u76ee\u6807\uff0c\u5e76\u53d1\u73b0\u5176\u5faa\u73af\u63a8\u7406\u8fc7\u7a0b\u80fd\u591f\u91cd\u7528\u5148\u524d\u65f6\u95f4\u6b65\u7684\u8ba1\u7b97\u3002", "conclusion": "HRM-Agent\u6269\u5c55\u4e86HRM\u7684\u5e94\u7528\u8303\u56f4\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u52a8\u6001\u548c\u4e0d\u786e\u5b9a\u7684\u73af\u5883\uff0c\u5e76\u8bc1\u5b9e\u4e86\u5176\u63a8\u7406\u8fc7\u7a0b\u7684\u65f6\u95f4\u590d\u7528\u80fd\u529b\u3002"}}
{"id": "2510.22833", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.22833", "abs": "https://arxiv.org/abs/2510.22833", "authors": ["Adrian Orenstein", "Jessica Chen", "Gwyneth Anne Delos Santos", "Bayley Sapara", "Michael Bowling"], "title": "Toward Agents That Reason About Their Computation", "comment": null, "summary": "While reinforcement learning agents can achieve superhuman performance in\nmany complex tasks, they typically do not become more computationally efficient\nas they improve. In contrast, humans gradually require less cognitive effort as\nthey become more proficient at a task. If agents could reason about their\ncompute as they learn, could they similarly reduce their computation footprint?\nIf they could, we could have more energy efficient agents or free up compute\ncycles for other processes like planning. In this paper, we experiment with\nshowing agents the cost of their computation and giving them the ability to\ncontrol when they use compute. We conduct our experiments on the Arcade\nLearning Environment, and our results demonstrate that with the same training\ncompute budget, agents that reason about their compute perform better on 75% of\ngames. Furthermore, these agents use three times less compute on average. We\nanalyze individual games and show where agents gain these efficiencies.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u5982\u4f55\u8ba9\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5728\u63d0\u5347\u6027\u80fd\u7684\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\uff0c\u901a\u8fc7\u8ba9\u667a\u80fd\u4f53\u611f\u77e5\u8ba1\u7b97\u6210\u672c\u5e76\u81ea\u4e3b\u63a7\u5236\u8ba1\u7b97\u4f7f\u7528\uff0c\u5728Atari\u6e38\u620f\u4e2d\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\u548c\u8ba1\u7b97\u91cf\u51cf\u5c11\u3002", "motivation": "\u4eba\u7c7b\u5728\u719f\u7ec3\u4efb\u52a1\u540e\u8ba4\u77e5\u8d1f\u62c5\u4f1a\u964d\u4f4e\uff0c\u800c\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5728\u6027\u80fd\u63d0\u5347\u65f6\u8ba1\u7b97\u6548\u7387\u5e76\u4e0d\u6539\u5584\u3002\u7814\u7a76\u65e8\u5728\u8ba9\u667a\u80fd\u4f53\u80fd\u591f\u611f\u77e5\u548c\u63a7\u5236\u8ba1\u7b97\u4f7f\u7528\uff0c\u4ee5\u63d0\u9ad8\u80fd\u6548\u548c\u91ca\u653e\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "\u5728Arcade Learning Environment\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8ba9\u667a\u80fd\u4f53\u611f\u77e5\u8ba1\u7b97\u6210\u672c\u5e76\u81ea\u4e3b\u51b3\u5b9a\u4f55\u65f6\u4f7f\u7528\u8ba1\u7b97\u8d44\u6e90\u3002", "result": "\u5728\u76f8\u540c\u8bad\u7ec3\u8ba1\u7b97\u9884\u7b97\u4e0b\uff0c75%\u7684\u6e38\u620f\u4e0a\u611f\u77e5\u8ba1\u7b97\u6210\u672c\u7684\u667a\u80fd\u4f53\u8868\u73b0\u66f4\u597d\uff0c\u5e73\u5747\u8ba1\u7b97\u91cf\u51cf\u5c11\u4e86\u4e09\u500d\u3002", "conclusion": "\u8ba9\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u611f\u77e5\u548c\u63a7\u5236\u8ba1\u7b97\u4f7f\u7528\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u6027\u80fd\u5e76\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2510.22917", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22917", "abs": "https://arxiv.org/abs/2510.22917", "authors": ["Zecheng Yin", "Hao Zhao", "Zhen Li"], "title": "HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment", "comment": "under review", "summary": "Objective-oriented navigation(ObjNav) enables robot to navigate to target\nobject directly and autonomously in an unknown environment. Effective\nperception in navigation in unknown environment is critical for autonomous\nrobots. While egocentric observations from RGB-D sensors provide abundant local\ninformation, real-time top-down maps offer valuable global context for ObjNav.\nNevertheless, the majority of existing studies focus on a single source, seldom\nintegrating these two complementary perceptual modalities, despite the fact\nthat humans naturally attend to both. With the rapid advancement of\nVision-Language Models(VLMs), we propose Hybrid Perception Navigation\n(HyPerNav), leveraging VLMs' strong reasoning and vision-language understanding\ncapabilities to jointly perceive both local and global information to enhance\nthe effectiveness and intelligence of navigation in unknown environments. In\nboth massive simulation evaluation and real-world validation, our methods\nachieved state-of-the-art performance against popular baselines. Benefiting\nfrom hybrid perception approach, our method captures richer cues and finds the\nobjects more effectively, by simultaneously leveraging information\nunderstanding from egocentric observations and the top-down map. Our ablation\nstudy further proved that either of the hybrid perception contributes to the\nnavigation performance.", "AI": {"tldr": "\u63d0\u51faHyPerNav\u65b9\u6cd5\uff0c\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8054\u5408\u611f\u77e5\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u606f\uff0c\u5728\u672a\u77e5\u73af\u5883\u4e2d\u5b9e\u73b0\u76ee\u6807\u5bfc\u5411\u5bfc\u822a\u7684SOTA\u6027\u80fd", "motivation": "\u73b0\u6709\u7814\u7a76\u5927\u591a\u53ea\u5173\u6ce8\u5355\u4e00\u611f\u77e5\u6e90\uff08RGB-D\u4f20\u611f\u5668\u6216\u4fef\u89c6\u56fe\uff09\uff0c\u5f88\u5c11\u6574\u5408\u8fd9\u4e24\u79cd\u4e92\u8865\u7684\u611f\u77e5\u6a21\u6001\uff0c\u800c\u4eba\u7c7b\u5929\u7136\u4f1a\u540c\u65f6\u5173\u6ce8\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u606f", "method": "\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5927\u63a8\u7406\u548c\u89c6\u89c9\u8bed\u8a00\u7406\u89e3\u80fd\u529b\uff0c\u8054\u5408\u611f\u77e5\u5c40\u90e8\uff08RGB-D\u4f20\u611f\u5668\uff09\u548c\u5168\u5c40\uff08\u5b9e\u65f6\u4fef\u89c6\u56fe\uff09\u4fe1\u606f\uff0c\u63d0\u51fa\u6df7\u5408\u611f\u77e5\u5bfc\u822a\u65b9\u6cd5HyPerNav", "result": "\u5728\u5927\u89c4\u6a21\u4eff\u771f\u8bc4\u4f30\u548c\u771f\u5b9e\u4e16\u754c\u9a8c\u8bc1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u6d41\u884c\u57fa\u7ebf\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u6df7\u5408\u611f\u77e5\u65b9\u6cd5\u80fd\u591f\u6355\u83b7\u66f4\u4e30\u5bcc\u7684\u7ebf\u7d22\u5e76\u66f4\u6709\u6548\u5730\u627e\u5230\u76ee\u6807\u7269\u4f53", "conclusion": "\u6df7\u5408\u611f\u77e5\u65b9\u6cd5\u901a\u8fc7\u540c\u65f6\u5229\u7528\u7b2c\u4e00\u4eba\u79f0\u89c2\u5bdf\u548c\u4fef\u89c6\u56fe\u7684\u4fe1\u606f\u7406\u89e3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bfc\u822a\u6027\u80fd\uff0c\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u8bc1\u660e\u6df7\u5408\u611f\u77e5\u7684\u6bcf\u4e2a\u7ec4\u6210\u90e8\u5206\u90fd\u5bf9\u5bfc\u822a\u6027\u80fd\u6709\u8d21\u732e"}}
{"id": "2510.22836", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22836", "abs": "https://arxiv.org/abs/2510.22836", "authors": ["Guanyu Yao", "Qiucheng Wu", "Yang Zhang", "Zhaowen Wang", "Handong Zhao", "Shiyu Chang"], "title": "Rethinking the Text-Vision Reasoning Imbalance in MLLMs through the Lens of Training Recipes", "comment": null, "summary": "Multimodal large language models (MLLMs) have demonstrated strong\ncapabilities on vision-and-language tasks. However, recent findings reveal an\nimbalance in their reasoning capabilities across visual and textual modalities.\nSpecifically, current MLLMs often over-rely on textual cues while\nunder-attending to visual content, resulting in suboptimal performance on tasks\nthat require genuine visual reasoning. We refer to this phenomenon as the\n\\textit{modality gap}, defined as the performance disparity between\ntext-centric and vision-centric inputs. In this paper, we analyze the modality\ngap through the lens of training recipes. We first show that existing training\nrecipes tend to amplify this gap. Then, we systematically explore strategies to\nbridge it from two complementary perspectives: data and loss design. Our\nfindings provide insights into developing training recipes that mitigate the\nmodality gap and promote more balanced multimodal reasoning. Our code is\npublicly available at https://github.com/UCSB-NLP-Chang/Bridging-Modality-Gap.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6a21\u6001\u5dee\u8ddd\u95ee\u9898\uff0c\u5373\u6a21\u578b\u8fc7\u5ea6\u4f9d\u8d56\u6587\u672c\u7ebf\u7d22\u800c\u5ffd\u89c6\u89c6\u89c9\u5185\u5bb9\uff0c\u5e76\u63d0\u51fa\u4e86\u4ece\u6570\u636e\u548c\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u4e24\u65b9\u9762\u6765\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u7684\u8bad\u7ec3\u7b56\u7565\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u548c\u6587\u672c\u6a21\u6001\u95f4\u5b58\u5728\u63a8\u7406\u80fd\u529b\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u6a21\u578b\u8fc7\u5ea6\u4f9d\u8d56\u6587\u672c\u7ebf\u7d22\u800c\u5ffd\u89c6\u89c6\u89c9\u5185\u5bb9\uff0c\u5bfc\u81f4\u5728\u9700\u8981\u771f\u6b63\u89c6\u89c9\u63a8\u7406\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u4ece\u8bad\u7ec3\u65b9\u6cd5\u89d2\u5ea6\u5206\u6790\u6a21\u6001\u5dee\u8ddd\uff0c\u7cfb\u7edf\u63a2\u7d22\u4ece\u6570\u636e\u548c\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u4e24\u4e2a\u4e92\u8865\u89c6\u89d2\u6765\u5f25\u5408\u5dee\u8ddd\u7684\u7b56\u7565\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u8bad\u7ec3\u65b9\u6cd5\u4f1a\u653e\u5927\u6a21\u6001\u5dee\u8ddd\uff0c\u63d0\u51fa\u4e86\u80fd\u591f\u7f13\u89e3\u8fd9\u4e00\u5dee\u8ddd\u5e76\u4fc3\u8fdb\u66f4\u5e73\u8861\u591a\u6a21\u6001\u63a8\u7406\u7684\u8bad\u7ec3\u7b56\u7565\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u80fd\u591f\u51cf\u8f7b\u6a21\u6001\u5dee\u8ddd\u5e76\u4fc3\u8fdb\u66f4\u5e73\u8861\u591a\u6a21\u6001\u63a8\u7406\u7684\u8bad\u7ec3\u65b9\u6cd5\u63d0\u4f9b\u4e86\u89c1\u89e3\uff0c\u76f8\u5173\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2510.22840", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22840", "abs": "https://arxiv.org/abs/2510.22840", "authors": ["Yifei Li", "Erik-Jan van Kampen"], "title": "Lyapunov Function-guided Reinforcement Learning for Flight Control", "comment": null, "summary": "A cascaded online learning flight control system has been developed and\nenhanced with respect to action smoothness. In this paper, we investigate the\nconvergence performance of the control system, characterized by the increment\nof a Lyapunov function candidate. The derivation of this metric accounts for\ndiscretization errors and state prediction errors introduced by the incremental\nmodel. Comparative results are presented through flight control simulations.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7ea7\u8054\u5728\u7ebf\u5b66\u4e60\u98de\u884c\u63a7\u5236\u7cfb\u7edf\u7684\u6536\u655b\u6027\u80fd\uff0c\u901a\u8fc7\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\u5019\u9009\u7684\u589e\u91cf\u6765\u8868\u5f81\uff0c\u5e76\u8003\u8651\u4e86\u79bb\u6563\u5316\u8bef\u5dee\u548c\u72b6\u6001\u9884\u6d4b\u8bef\u5dee\u7684\u5f71\u54cd\u3002", "motivation": "\u5f00\u53d1\u5e76\u6539\u8fdb\u4e86\u7ea7\u8054\u5728\u7ebf\u5b66\u4e60\u98de\u884c\u63a7\u5236\u7cfb\u7edf\uff0c\u7279\u522b\u5173\u6ce8\u52a8\u4f5c\u5e73\u6ed1\u6027\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u6536\u655b\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\u5019\u9009\u7684\u589e\u91cf\u4f5c\u4e3a\u6536\u655b\u6027\u80fd\u6307\u6807\uff0c\u63a8\u5bfc\u8fc7\u7a0b\u4e2d\u8003\u8651\u4e86\u79bb\u6563\u5316\u8bef\u5dee\u548c\u589e\u91cf\u6a21\u578b\u5f15\u5165\u7684\u72b6\u6001\u9884\u6d4b\u8bef\u5dee\u3002", "result": "\u901a\u8fc7\u98de\u884c\u63a7\u5236\u4eff\u771f\u5c55\u793a\u4e86\u6bd4\u8f83\u7ed3\u679c\uff0c\u9a8c\u8bc1\u4e86\u63a7\u5236\u7cfb\u7edf\u7684\u6536\u655b\u6027\u80fd\u3002", "conclusion": "\u8be5\u7ea7\u8054\u5728\u7ebf\u5b66\u4e60\u98de\u884c\u63a7\u5236\u7cfb\u7edf\u5728\u8003\u8651\u5404\u79cd\u8bef\u5dee\u56e0\u7d20\u540e\u4ecd\u80fd\u4fdd\u6301\u826f\u597d\u7684\u6536\u655b\u6027\u80fd\u3002"}}
{"id": "2510.22883", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22883", "abs": "https://arxiv.org/abs/2510.22883", "authors": ["Giovanni Sileno", "Jean-Louis Dessalles"], "title": "Exploring Structures of Inferential Mechanisms through Simplistic Digital Circuits", "comment": "paper presented at the 10th AIC workshop (AI & cognition) at ECAI\n  2025", "summary": "Cognitive studies and artificial intelligence have developed distinct models\nfor various inferential mechanisms (categorization, induction, abduction,\ncausal inference, contrast, merge, ...). Yet, both natural and artificial views\non cognition lack apparently a unifying framework. This paper formulates a\nspeculative answer attempting to respond to this gap. To postulate on\nhigher-level activation processes from a material perspective, we consider\ninferential mechanisms informed by symbolic AI modelling techniques, through\nthe simplistic lenses of electronic circuits based on logic gates. We observe\nthat a logic gate view entails a different treatment of implication and\nnegation compared to standard logic and logic programming. Then, by\ncombinatorial exploration, we identify four main forms of dependencies that can\nbe realized by these inferential circuits. Looking at how these forms are\ngenerally used in the context of logic programs, we identify eight common\ninferential patterns, exposing traditionally distinct inferential mechanisms in\nan unifying framework. Finally, following a probabilistic interpretation of\nlogic programs, we unveil inner functional dependencies. The paper concludes\nelaborating in what sense, even if our arguments are mostly informed by\nsymbolic means and digital systems infrastructures, our observations may\npinpoint to more generally applicable structures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u903b\u8f91\u95e8\u7535\u8def\u6a21\u578b\u6765\u6574\u5408\u8ba4\u77e5\u7814\u7a76\u548c\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u5404\u79cd\u63a8\u7406\u673a\u5236\uff0c\u53d1\u73b0\u4e86\u56db\u79cd\u4f9d\u8d56\u5173\u7cfb\u548c\u516b\u79cd\u5e38\u89c1\u63a8\u7406\u6a21\u5f0f\u3002", "motivation": "\u8ba4\u77e5\u7814\u7a76\u548c\u4eba\u5de5\u667a\u80fd\u4e3a\u5404\u79cd\u63a8\u7406\u673a\u5236\u5f00\u53d1\u4e86\u4e0d\u540c\u7684\u6a21\u578b\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u6846\u67b6\u3002\u672c\u6587\u8bd5\u56fe\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4ece\u7269\u8d28\u89d2\u5ea6\u5047\u8bbe\u9ad8\u7ea7\u6fc0\u6d3b\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u903b\u8f91\u95e8\u7684\u7535\u5b50\u7535\u8def\u6a21\u578b\u6765\u7814\u7a76\u63a8\u7406\u673a\u5236\uff0c\u901a\u8fc7\u7ec4\u5408\u63a2\u7d22\u8bc6\u522b\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u5728\u903b\u8f91\u7a0b\u5e8f\u80cc\u666f\u4e0b\u5206\u6790\u63a8\u7406\u6a21\u5f0f\u3002", "result": "\u8bc6\u522b\u4e86\u56db\u79cd\u4e3b\u8981\u7684\u4f9d\u8d56\u5173\u7cfb\u5f62\u5f0f\u548c\u516b\u79cd\u5e38\u89c1\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u5728\u7edf\u4e00\u6846\u67b6\u4e0b\u63ed\u793a\u4e86\u4f20\u7edf\u4e0a\u4e0d\u540c\u7684\u63a8\u7406\u673a\u5236\u3002", "conclusion": "\u5c3d\u7ba1\u8bba\u8bc1\u4e3b\u8981\u57fa\u4e8e\u7b26\u53f7\u65b9\u6cd5\u548c\u6570\u5b57\u7cfb\u7edf\u57fa\u7840\u8bbe\u65bd\uff0c\u4f46\u89c2\u5bdf\u7ed3\u679c\u53ef\u80fd\u6307\u5411\u66f4\u666e\u904d\u9002\u7528\u7684\u7ed3\u6784\u3002"}}
{"id": "2510.23016", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23016", "abs": "https://arxiv.org/abs/2510.23016", "authors": ["Zhuo Li", "Junjia Liu", "Dianxi Li", "Tao Teng", "Miao Li", "Sylvain Calinon", "Darwin Caldwell", "Fei Chen"], "title": "ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation", "comment": "7 pages, 6 figures, Accepted and published in IROS 2025", "summary": "Recent work has demonstrated the potential of diffusion models in robot\nbimanual skill learning. However, existing methods ignore the learning of\nposture-dependent task features, which are crucial for adapting dual-arm\nconfigurations to meet specific force and velocity requirements in dexterous\nbimanual manipulation. To address this limitation, we propose\nManipulability-Aware Diffusion Policy (ManiDP), a novel imitation learning\nmethod that not only generates plausible bimanual trajectories, but also\noptimizes dual-arm configurations to better satisfy posture-dependent task\nrequirements. ManiDP achieves this by extracting bimanual manipulability from\nexpert demonstrations and encoding the encapsulated posture features using\nRiemannian-based probabilistic models. These encoded posture features are then\nincorporated into a conditional diffusion process to guide the generation of\ntask-compatible bimanual motion sequences. We evaluate ManiDP on six real-world\nbimanual tasks, where the experimental results demonstrate a 39.33$\\%$ increase\nin average manipulation success rate and a 0.45 improvement in task\ncompatibility compared to baseline methods. This work highlights the importance\nof integrating posture-relevant robotic priors into bimanual skill diffusion to\nenable human-like adaptability and dexterity.", "AI": {"tldr": "\u63d0\u51faManiDP\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u53cc\u624b\u673a\u5668\u4eba\u7684\u53ef\u64cd\u4f5c\u6027\u7279\u5f81\u5e76\u878d\u5165\u6269\u6563\u6a21\u578b\uff0c\u4f18\u5316\u53cc\u81c2\u914d\u7f6e\u4ee5\u6ee1\u8db3\u59ff\u52bf\u76f8\u5173\u7684\u4efb\u52a1\u9700\u6c42\uff0c\u57286\u4e2a\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u5e73\u5747\u6210\u529f\u7387\u63d0\u534739.33%\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4e86\u59ff\u52bf\u76f8\u5173\u4efb\u52a1\u7279\u5f81\u7684\u5b66\u4e60\uff0c\u800c\u8fd9\u4e9b\u7279\u5f81\u5bf9\u4e8e\u9002\u5e94\u53cc\u81c2\u914d\u7f6e\u4ee5\u6ee1\u8db3\u7075\u5de7\u53cc\u624b\u64cd\u4f5c\u4e2d\u7684\u7279\u5b9a\u529b\u548c\u901f\u5ea6\u8981\u6c42\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4ece\u4e13\u5bb6\u6f14\u793a\u4e2d\u63d0\u53d6\u53cc\u624b\u53ef\u64cd\u4f5c\u6027\uff0c\u4f7f\u7528\u9ece\u66fc\u6982\u7387\u6a21\u578b\u7f16\u7801\u59ff\u52bf\u7279\u5f81\uff0c\u5e76\u5c06\u5176\u878d\u5165\u6761\u4ef6\u6269\u6563\u8fc7\u7a0b\u6765\u751f\u6210\u4efb\u52a1\u517c\u5bb9\u7684\u53cc\u624b\u8fd0\u52a8\u5e8f\u5217\u3002", "result": "\u57286\u4e2a\u771f\u5b9e\u4e16\u754c\u53cc\u624b\u4efb\u52a1\u4e2d\uff0c\u5e73\u5747\u64cd\u4f5c\u6210\u529f\u7387\u63d0\u9ad839.33%\uff0c\u4efb\u52a1\u517c\u5bb9\u6027\u63d0\u53470.45\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5c06\u59ff\u52bf\u76f8\u5173\u7684\u673a\u5668\u4eba\u5148\u9a8c\u77e5\u8bc6\u6574\u5408\u5230\u53cc\u624b\u6280\u80fd\u6269\u6563\u4e2d\uff0c\u80fd\u591f\u5b9e\u73b0\u7c7b\u4eba\u7684\u9002\u5e94\u6027\u548c\u7075\u5de7\u6027\u3002"}}
{"id": "2510.22898", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.22898", "abs": "https://arxiv.org/abs/2510.22898", "authors": ["Vishvesh Bhat", "Omkar Ghugarkar", "Julian McAuley"], "title": "On Generalization in Agentic Tool Calling: CoreThink Agentic Reasoner and MAVEN Dataset", "comment": "Preprint", "summary": "Generalization across Agentic tool-calling environments remains a key\nunsolved challenge in developing reliable agentic reasoning systems. While\nlarge language models (LLMs) demonstrate strong performance on isolated\nbenchmarks, their ability to transfer reasoning strategies and co-ordinate\ntools across diverse domains is poorly understood. In this work, we conduct a\nlarge-scale evaluation of state-of-the-art LLMs on multiple tool-calling\nbenchmarksBFCL v3, TauBench, Tau2Bench, and AceBenchand introduce MAVEN (Math &\nPhysics Adversarial Verification & Evaluation Network), a new out of\ndistribution (OOD) benchmark designed to stress-test multi-step reasoning\nthrough explicit verification and adversarial task composition. Our results\nshow that most current models achieve below 50% accuracy on MAVEN, revealing a\nsignificant generalization gap across tool-use settings.\n  To address this, we present the CoreThink Agentic Reasoner, a framework that\naugments LLMs with a lightweight symbolic reasoning layer for structured\ndecomposition and adaptive tool orchestration. Without additional training, it\ngeneralizes across all benchmarks, achieving state-of-the-art performance with\n530% improvements over existing baselines at roughly one-tenth the\ncomputational cost.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86CoreThink\u667a\u80fd\u4f53\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7b26\u53f7\u63a8\u7406\u5c42\u589e\u5f3aLLMs\uff0c\u5728\u591a\u4e2a\u5de5\u5177\u8c03\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u6cdb\u5316\uff0c\u6027\u80fd\u63d0\u5347530%\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e90%\u3002", "motivation": "\u89e3\u51b3\u667a\u80fd\u4f53\u5de5\u5177\u8c03\u7528\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u6311\u6218\uff0c\u5f53\u524dLLMs\u5728\u8de8\u9886\u57df\u8f6c\u79fb\u63a8\u7406\u7b56\u7565\u548c\u534f\u8c03\u5de5\u5177\u65b9\u9762\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u63d0\u51faCoreThink\u667a\u80fd\u4f53\u63a8\u7406\u5668\u6846\u67b6\uff0c\u4e3aLLMs\u6dfb\u52a0\u8f7b\u91cf\u7ea7\u7b26\u53f7\u63a8\u7406\u5c42\uff0c\u5b9e\u73b0\u7ed3\u6784\u5316\u5206\u89e3\u548c\u81ea\u9002\u5e94\u5de5\u5177\u7f16\u6392\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u63d0\u5347530%\uff0c\u8ba1\u7b97\u6210\u672c\u4ec5\u4e3a\u5341\u5206\u4e4b\u4e00\u3002", "conclusion": "CoreThink\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u667a\u80fd\u4f53\u5de5\u5177\u8c03\u7528\u4e2d\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u8de8\u57fa\u51c6\u7684\u4f18\u5f02\u8868\u73b0\u3002"}}
{"id": "2510.22942", "categories": ["cs.AI", "cs.IR", "H.3.3; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.22942", "abs": "https://arxiv.org/abs/2510.22942", "authors": ["Zhuoxuan Li", "Jieyuan Pei", "Tangwei Ye", "Zhongyuan Lai", "Zihan Liu", "Fengyuan Xu", "Qi Zhang", "Liang Hu"], "title": "GTR-Mamba: Geometry-to-Tangent Routing for Hyperbolic POI Recommendation", "comment": "14 pages, 8 figures, 4 tables, submitted to ICDE 2026", "summary": "Next Point-of-Interest (POI) recommendation is a critical task in modern\nLocation-Based Social Networks (LBSNs), aiming to model the complex\ndecision-making process of human mobility to provide personalized\nrecommendations for a user's next check-in location. Existing POI\nrecommendation models, predominantly based on Graph Neural Networks and\nsequential models, have been extensively studied. However, these models face a\nfundamental limitation: they struggle to simultaneously capture the inherent\nhierarchical structure of spatial choices and the dynamics and irregular shifts\nof user-specific temporal contexts. To overcome this limitation, we propose\nGTR-Mamba, a novel framework for cross-manifold conditioning and routing.\nGTR-Mamba leverages the distinct advantages of different mathematical spaces\nfor different tasks: it models the static, tree-like preference hierarchies in\nhyperbolic geometry, while routing the dynamic sequence updates to a novel\nMamba layer in the computationally stable and efficient Euclidean tangent\nspace. This process is coordinated by a cross-manifold channel that fuses\nspatio-temporal information to explicitly steer the State Space Model (SSM),\nenabling flexible adaptation to contextual changes. Extensive experiments on\nthree real-world datasets demonstrate that GTR-Mamba consistently outperforms\nstate-of-the-art baseline models in next POI recommendation.", "AI": {"tldr": "GTR-Mamba\u662f\u4e00\u4e2a\u65b0\u9896\u7684POI\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u6d41\u5f62\u6761\u4ef6\u8def\u7531\u540c\u65f6\u5efa\u6a21\u7a7a\u95f4\u5c42\u6b21\u7ed3\u6784\u548c\u7528\u6237\u65f6\u95f4\u4e0a\u4e0b\u6587\u52a8\u6001\u53d8\u5316\uff0c\u5728\u53cc\u66f2\u51e0\u4f55\u4e2d\u5904\u7406\u9759\u6001\u504f\u597d\u5c42\u6b21\uff0c\u5728\u6b27\u51e0\u91cc\u5f97\u5207\u7a7a\u95f4\u4e2d\u5904\u7406\u52a8\u6001\u5e8f\u5217\u66f4\u65b0\u3002", "motivation": "\u73b0\u6709POI\u63a8\u8350\u6a21\u578b\u65e0\u6cd5\u540c\u65f6\u6355\u6349\u7a7a\u95f4\u9009\u62e9\u7684\u5c42\u6b21\u7ed3\u6784\u548c\u7528\u6237\u7279\u5b9a\u65f6\u95f4\u4e0a\u4e0b\u6587\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\u3002", "method": "\u63d0\u51faGTR-Mamba\u6846\u67b6\uff0c\u5229\u7528\u53cc\u66f2\u51e0\u4f55\u5efa\u6a21\u9759\u6001\u6811\u72b6\u504f\u597d\u5c42\u6b21\uff0c\u5728\u6b27\u51e0\u91cc\u5f97\u5207\u7a7a\u95f4\u4e2d\u4f7f\u7528Mamba\u5c42\u5904\u7406\u52a8\u6001\u5e8f\u5217\u66f4\u65b0\uff0c\u901a\u8fc7\u8de8\u6d41\u5f62\u901a\u9053\u878d\u5408\u65f6\u7a7a\u4fe1\u606f\u6765\u6307\u5bfc\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cGTR-Mamba\u5728\u4e0b\u4e00\u4e2aPOI\u63a8\u8350\u4efb\u52a1\u4e2d\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "GTR-Mamba\u901a\u8fc7\u8de8\u6d41\u5f62\u6761\u4ef6\u8def\u7531\u6210\u529f\u89e3\u51b3\u4e86\u540c\u65f6\u5efa\u6a21\u7a7a\u95f4\u5c42\u6b21\u7ed3\u6784\u548c\u65f6\u95f4\u4e0a\u4e0b\u6587\u52a8\u6001\u7684\u6311\u6218\uff0c\u4e3aPOI\u63a8\u8350\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.23059", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23059", "abs": "https://arxiv.org/abs/2510.23059", "authors": ["Yongtong Zhu", "Lei Li", "Iggy Qian", "WenBin Zhou", "Ye Yuan", "Qingdu Li", "Na Liu", "Jianwei Zhang"], "title": "Awakening Facial Emotional Expressions in Human-Robot", "comment": "Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS 2025). 8 pages, 7 figures, IEEE two-column format", "summary": "The facial expression generation capability of humanoid social robots is\ncritical for achieving natural and human-like interactions, playing a vital\nrole in enhancing the fluidity of human-robot interactions and the accuracy of\nemotional expression. Currently, facial expression generation in humanoid\nsocial robots still relies on pre-programmed behavioral patterns, which are\nmanually coded at high human and time costs. To enable humanoid robots to\nautonomously acquire generalized expressive capabilities, they need to develop\nthe ability to learn human-like expressions through self-training. To address\nthis challenge, we have designed a highly biomimetic robotic face with\nphysical-electronic animated facial units and developed an end-to-end learning\nframework based on KAN (Kolmogorov-Arnold Network) and attention mechanisms.\nUnlike previous humanoid social robots, we have also meticulously designed an\nautomated data collection system based on expert strategies of facial motion\nprimitives to construct the dataset. Notably, to the best of our knowledge,\nthis is the first open-source facial dataset for humanoid social robots.\nComprehensive evaluations indicate that our approach achieves accurate and\ndiverse facial mimicry across different test subjects.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8eKAN\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u7aef\u5230\u7aef\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u4eba\u5f62\u793e\u4ea4\u673a\u5668\u4eba\u80fd\u591f\u901a\u8fc7\u81ea\u8bad\u7ec3\u5b66\u4e60\u4eba\u7c7b\u8868\u60c5\uff0c\u5b9e\u73b0\u51c6\u786e\u591a\u6837\u7684\u9762\u90e8\u6a21\u4eff\u3002", "motivation": "\u89e3\u51b3\u4eba\u5f62\u793e\u4ea4\u673a\u5668\u4eba\u9762\u90e8\u8868\u60c5\u751f\u6210\u4f9d\u8d56\u9884\u7f16\u7a0b\u884c\u4e3a\u6a21\u5f0f\u7684\u95ee\u9898\uff0c\u964d\u4f4e\u4eba\u5de5\u7f16\u7801\u6210\u672c\uff0c\u8ba9\u673a\u5668\u4eba\u80fd\u591f\u81ea\u4e3b\u83b7\u53d6\u6cdb\u5316\u7684\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u9ad8\u5ea6\u4eff\u751f\u7684\u673a\u5668\u4eba\u9762\u90e8\u7cfb\u7edf\uff0c\u5f00\u53d1\u57fa\u4e8eKAN\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u7aef\u5230\u7aef\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u6784\u5efa\u9996\u4e2a\u5f00\u6e90\u7684\u4eba\u5f62\u793e\u4ea4\u673a\u5668\u4eba\u9762\u90e8\u6570\u636e\u96c6\u3002", "result": "\u7efc\u5408\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u6d4b\u8bd5\u5bf9\u8c61\u4e0a\u5b9e\u73b0\u4e86\u51c6\u786e\u591a\u6837\u7684\u9762\u90e8\u6a21\u4eff\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4eba\u5f62\u793e\u4ea4\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u81ea\u4e3b\u5b66\u4e60\u548c\u8868\u8fbe\u4eba\u7c7b\u8868\u60c5\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u81ea\u7136\u5316\u4eba\u673a\u4ea4\u4e92\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.22969", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.22969", "abs": "https://arxiv.org/abs/2510.22969", "authors": ["Kechen Meng", "Sinuo Zhang", "Rongpeng Li", "Xiangming Meng", "Chan Wang", "Ming Lei", "Zhifeng Zhao"], "title": "Multi-Agent Conditional Diffusion Model with Mean Field Communication as Wireless Resource Allocation Planner", "comment": null, "summary": "In wireless communication systems, efficient and adaptive resource allocation\nplays a crucial role in enhancing overall Quality of Service (QoS). While\ncentralized Multi-Agent Reinforcement Learning (MARL) frameworks rely on a\ncentral coordinator for policy training and resource scheduling, they suffer\nfrom scalability issues and privacy risks. In contrast, the Distributed\nTraining with Decentralized Execution (DTDE) paradigm enables distributed\nlearning and decision-making, but it struggles with non-stationarity and\nlimited inter-agent cooperation, which can severely degrade system performance.\nTo overcome these challenges, we propose the Multi-Agent Conditional Diffusion\nModel Planner (MA-CDMP) for decentralized communication resource management.\nBuilt upon the Model-Based Reinforcement Learning (MBRL) paradigm, MA-CDMP\nemploys Diffusion Models (DMs) to capture environment dynamics and plan future\ntrajectories, while an inverse dynamics model guides action generation, thereby\nalleviating the sample inefficiency and slow convergence of conventional DTDE\nmethods. Moreover, to approximate large-scale agent interactions, a Mean-Field\n(MF) mechanism is introduced as an assistance to the classifier in DMs. This\ndesign mitigates inter-agent non-stationarity and enhances cooperation with\nminimal communication overhead in distributed settings. We further\ntheoretically establish an upper bound on the distributional approximation\nerror introduced by the MF-based diffusion generation, guaranteeing convergence\nstability and reliable modeling of multi-agent stochastic dynamics. Extensive\nexperiments demonstrate that MA-CDMP consistently outperforms existing MARL\nbaselines in terms of average reward and QoS metrics, showcasing its\nscalability and practicality for real-world wireless network optimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86MA-CDMP\u65b9\u6cd5\uff0c\u4f7f\u7528\u6269\u6563\u6a21\u578b\u548c\u591a\u667a\u80fd\u4f53\u6761\u4ef6\u89c4\u5212\u6765\u89e3\u51b3\u53bb\u4e2d\u5fc3\u5316\u901a\u4fe1\u8d44\u6e90\u7ba1\u7406\u4e2d\u7684\u975e\u5e73\u7a33\u6027\u548c\u5408\u4f5c\u95ee\u9898\uff0c\u5728\u65e0\u7ebf\u7f51\u7edc\u4f18\u5316\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u96c6\u4e2d\u5f0f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u53ef\u6269\u5c55\u6027\u548c\u9690\u79c1\u95ee\u9898\uff0c\u4ee5\u53ca\u5206\u5e03\u5f0f\u8bad\u7ec3\u53bb\u4e2d\u5fc3\u5316\u6267\u884c\u8303\u5f0f\u4e2d\u7684\u975e\u5e73\u7a33\u6027\u548c\u6709\u9650\u5408\u4f5c\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\uff0c\u4f7f\u7528\u6269\u6563\u6a21\u578b\u6355\u6349\u73af\u5883\u52a8\u6001\u5e76\u89c4\u5212\u672a\u6765\u8f68\u8ff9\uff0c\u5f15\u5165\u9006\u52a8\u6001\u6a21\u578b\u6307\u5bfc\u52a8\u4f5c\u751f\u6210\uff0c\u91c7\u7528\u5747\u503c\u573a\u673a\u5236\u8fd1\u4f3c\u5927\u89c4\u6a21\u667a\u80fd\u4f53\u4ea4\u4e92\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMA-CDMP\u5728\u5e73\u5747\u5956\u52b1\u548cQoS\u6307\u6807\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709MARL\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "MA-CDMP\u901a\u8fc7\u6269\u6563\u6a21\u578b\u548c\u5747\u503c\u573a\u673a\u5236\u6709\u6548\u7f13\u89e3\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u975e\u5e73\u7a33\u6027\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5408\u4f5c\u6548\u7387\uff0c\u4e3a\u5b9e\u9645\u65e0\u7ebf\u7f51\u7edc\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.23084", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23084", "abs": "https://arxiv.org/abs/2510.23084", "authors": ["Sunyou Hwang", "Christophe De Wagter", "Bart Remes", "Guido de Croon"], "title": "Breaking the Circle: An Autonomous Control-Switching Strategy for Stable Orographic Soaring in MAVs", "comment": "13 pages, 15 figures", "summary": "Orographic soaring can significantly extend the endurance of micro aerial\nvehicles (MAVs), but circling behavior, arising from control conflicts between\nthe longitudinal and vertical axes, increases energy consumption and the risk\nof divergence. We propose a control switching method, named SAOS: Switched\nControl for Autonomous Orographic Soaring, which mitigates circling behavior by\nselectively controlling either the horizontal or vertical axis, effectively\ntransforming the system from underactuated to fully actuated during soaring.\nAdditionally, the angle of attack is incorporated into the INDI controller to\nimprove force estimation. Simulations with randomized initial positions and\nwind tunnel experiments on two MAVs demonstrate that the SAOS improves position\nconvergence, reduces throttle usage, and mitigates roll oscillations caused by\npitch-roll coupling. These improvements enhance energy efficiency and flight\nstability in constrained soaring environments.", "AI": {"tldr": "\u63d0\u51faSAOS\u63a7\u5236\u5207\u6362\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u63a7\u5236\u6c34\u5e73\u6216\u5782\u76f4\u8f74\u6765\u51cf\u8f7b\u6ed1\u7fd4\u4e2d\u7684\u76d8\u65cb\u884c\u4e3a\uff0c\u5c06\u7cfb\u7edf\u4ece\u6b20\u9a71\u52a8\u8f6c\u53d8\u4e3a\u5168\u9a71\u52a8\u72b6\u6001\uff0c\u63d0\u9ad8\u80fd\u91cf\u6548\u7387\u548c\u98de\u884c\u7a33\u5b9a\u6027\u3002", "motivation": "\u5730\u5f62\u6ed1\u7fd4\u53ef\u663e\u8457\u5ef6\u957f\u5fae\u578b\u98de\u884c\u5668\u7eed\u822a\u65f6\u95f4\uff0c\u4f46\u76d8\u65cb\u884c\u4e3a\u4f1a\u589e\u52a0\u80fd\u8017\u548c\u53d1\u6563\u98ce\u9669\uff0c\u9700\u8981\u89e3\u51b3\u63a7\u5236\u51b2\u7a81\u95ee\u9898\u3002", "method": "\u91c7\u7528\u63a7\u5236\u5207\u6362\u65b9\u6cd5SAOS\uff0c\u5728\u6ed1\u7fd4\u65f6\u9009\u62e9\u6027\u63a7\u5236\u6c34\u5e73\u6216\u5782\u76f4\u8f74\uff0c\u5e76\u5728INDI\u63a7\u5236\u5668\u4e2d\u52a0\u5165\u653b\u89d2\u4ee5\u6539\u8fdb\u529b\u4f30\u8ba1\u3002", "result": "\u4eff\u771f\u548c\u98ce\u6d1e\u5b9e\u9a8c\u8868\u660e\uff0cSAOS\u6539\u5584\u4e86\u4f4d\u7f6e\u6536\u655b\uff0c\u51cf\u5c11\u4e86\u6cb9\u95e8\u4f7f\u7528\uff0c\u51cf\u8f7b\u4e86\u4fef\u4ef0-\u6eda\u8f6c\u8026\u5408\u5f15\u8d77\u7684\u6eda\u8f6c\u632f\u8361\u3002", "conclusion": "SAOS\u65b9\u6cd5\u5728\u53d7\u9650\u6ed1\u7fd4\u73af\u5883\u4e2d\u63d0\u9ad8\u4e86\u80fd\u91cf\u6548\u7387\u548c\u98de\u884c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2510.22981", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.22981", "abs": "https://arxiv.org/abs/2510.22981", "authors": ["Jin Hu", "Jiakai Wang", "Linna Jing", "Haolin Li", "Haodong Liu", "Haotong Qin", "Aishan Liu", "Ke Xu", "Xianglong Liu"], "title": "Exploring Semantic-constrained Adversarial Example with Instruction Uncertainty Reduction", "comment": "NeurIPS 2025", "summary": "Recently, semantically constrained adversarial examples (SemanticAE), which\nare directly generated from natural language instructions, have become a\npromising avenue for future research due to their flexible attacking forms. To\ngenerate SemanticAEs, current methods fall short of satisfactory attacking\nability as the key underlying factors of semantic uncertainty in human\ninstructions, such as referring diversity, descriptive incompleteness, and\nboundary ambiguity, have not been fully investigated. To tackle the issues,\nthis paper develops a multi-dimensional instruction uncertainty reduction\n(InSUR) framework to generate more satisfactory SemanticAE, i.e., transferable,\nadaptive, and effective. Specifically, in the dimension of the sampling method,\nwe propose the residual-driven attacking direction stabilization to alleviate\nthe unstable adversarial optimization caused by the diversity of language\nreferences. By coarsely predicting the language-guided sampling process, the\noptimization process will be stabilized by the designed ResAdv-DDIM sampler,\ntherefore releasing the transferable and robust adversarial capability of\nmulti-step diffusion models. In task modeling, we propose the context-encoded\nattacking scenario constraint to supplement the missing knowledge from\nincomplete human instructions. Guidance masking and renderer integration are\nproposed to regulate the constraints of 2D/3D SemanticAE, activating stronger\nscenario-adapted attacks. Moreover, in the dimension of generator evaluation,\nwe propose the semantic-abstracted attacking evaluation enhancement by\nclarifying the evaluation boundary, facilitating the development of more\neffective SemanticAE generators. Extensive experiments demonstrate the\nsuperiority of the transfer attack performance of InSUR. Moreover, we realize\nthe reference-free generation of semantically constrained 3D adversarial\nexamples for the first time.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faInSUR\u6846\u67b6\uff0c\u901a\u8fc7\u51cf\u5c11\u8bed\u4e49\u6307\u4ee4\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u751f\u6210\u66f4\u6709\u6548\u7684\u8bed\u4e49\u7ea6\u675f\u5bf9\u6297\u6837\u672c\uff0c\u5305\u62ec\u53c2\u8003\u591a\u6837\u6027\u3001\u63cf\u8ff0\u4e0d\u5b8c\u6574\u6027\u548c\u8fb9\u754c\u6a21\u7cca\u6027\u4e09\u4e2a\u7ef4\u5ea6\u7684\u4f18\u5316\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u8bed\u4e49\u7ea6\u675f\u5bf9\u6297\u6837\u672c\u7684\u65b9\u6cd5\u653b\u51fb\u80fd\u529b\u4e0d\u8db3\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u4eba\u7c7b\u6307\u4ee4\u4e2d\u7684\u8bed\u4e49\u4e0d\u786e\u5b9a\u6027\uff08\u5982\u53c2\u8003\u591a\u6837\u6027\u3001\u63cf\u8ff0\u4e0d\u5b8c\u6574\u6027\u548c\u8fb9\u754c\u6a21\u7cca\u6027\uff09\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u591a\u7ef4\u5ea6\u6307\u4ee4\u4e0d\u786e\u5b9a\u6027\u51cf\u5c11\u6846\u67b6\uff1a1\uff09\u91c7\u6837\u65b9\u6cd5\u7ef4\u5ea6\uff1a\u6b8b\u5dee\u9a71\u52a8\u653b\u51fb\u65b9\u5411\u7a33\u5b9a\u5316\uff1b2\uff09\u4efb\u52a1\u5efa\u6a21\u7ef4\u5ea6\uff1a\u4e0a\u4e0b\u6587\u7f16\u7801\u653b\u51fb\u573a\u666f\u7ea6\u675f\uff1b3\uff09\u751f\u6210\u5668\u8bc4\u4f30\u7ef4\u5ea6\uff1a\u8bed\u4e49\u62bd\u8c61\u653b\u51fb\u8bc4\u4f30\u589e\u5f3a\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eInSUR\u5728\u8fc1\u79fb\u653b\u51fb\u6027\u80fd\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u65e0\u9700\u53c2\u8003\u7684\u8bed\u4e49\u7ea6\u675f3D\u5bf9\u6297\u6837\u672c\u751f\u6210\u3002", "conclusion": "InSUR\u6846\u67b6\u901a\u8fc7\u5168\u9762\u5904\u7406\u8bed\u4e49\u6307\u4ee4\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u80fd\u591f\u751f\u6210\u66f4\u4ee4\u4eba\u6ee1\u610f\u7684\u8bed\u4e49\u7ea6\u675f\u5bf9\u6297\u6837\u672c\uff0c\u5177\u6709\u66f4\u597d\u7684\u53ef\u8fc1\u79fb\u6027\u3001\u9002\u5e94\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2510.23109", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23109", "abs": "https://arxiv.org/abs/2510.23109", "authors": ["Bernhard Rameder", "Hubert Gattringer", "Ronald Naderer", "Andreas Mueller"], "title": "An Automated Tape Laying System Employing a Uniaxial Force Control Device", "comment": "Proceedings ECCM21 - 21st European Conference on Composite Materials,\n  Nantes, France, 7-2024", "summary": "This paper deals with the design of a cost effective automated tape laying\nsystem (ATL system) with integrated uniaxial force control to ensure the\nnecessary compaction forces as well as with an accurate temperature control to\nguarantee the used tape being melted appropriate. It is crucial to control the\nsubstrate and the oncoming tape onto a specific temperature level to ensure an\noptimal consolidation between the different layers of the product. Therefore,\nit takes several process steps from the spooled tape on the coil until it is\nfinally tacked onto the desired mold. The different modules are divided into\nthe tape storage spool, a tape-guiding roller, a tape processing unit, a\nheating zone and the consolidation unit. Moreover, a special robot control\nconcept for testing the ATL system is presented. In contrast to many other\nsystems, with this approach, the tape laying device is spatially fixed and the\nshape is moved accordingly by the robot, which allows for handling of rather\ncompact and complex shapes. The functionality of the subsystems and the taping\nprocess itself was finally approved in experimental results using a carbon\nfiber reinforced HDPE tape.", "AI": {"tldr": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5177\u6709\u96c6\u6210\u5355\u8f74\u529b\u63a7\u5236\u548c\u7cbe\u786e\u6e29\u5ea6\u63a7\u5236\u7684\u6210\u672c\u6548\u76ca\u578b\u81ea\u52a8\u94fa\u5e26\u7cfb\u7edf\uff0c\u7528\u4e8e\u786e\u4fdd\u9002\u5f53\u7684\u538b\u5b9e\u529b\u548c\u80f6\u5e26\u7194\u5316\u6e29\u5ea6\uff0c\u5e76\u901a\u8fc7\u7279\u6b8a\u673a\u5668\u4eba\u63a7\u5236\u6982\u5ff5\u5904\u7406\u590d\u6742\u5f62\u72b6\u3002", "motivation": "\u9700\u8981\u63a7\u5236\u57fa\u677f\u548c\u80f6\u5e26\u5728\u7279\u5b9a\u6e29\u5ea6\u6c34\u5e73\uff0c\u4ee5\u786e\u4fdd\u4ea7\u54c1\u4e0d\u540c\u5c42\u4e4b\u95f4\u7684\u6700\u4f73\u56fa\u7ed3\uff0c\u540c\u65f6\u5904\u7406\u7d27\u51d1\u548c\u590d\u6742\u5f62\u72b6\u7684\u94fa\u5e26\u9700\u6c42\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u80f6\u5e26\u5b58\u50a8\u5377\u8f74\u3001\u5bfc\u5411\u8f8a\u3001\u5904\u7406\u5355\u5143\u3001\u52a0\u70ed\u533a\u548c\u56fa\u7ed3\u5355\u5143\u7b49\u591a\u4e2a\u6a21\u5757\uff0c\u91c7\u7528\u56fa\u5b9a\u94fa\u5e26\u88c5\u7f6e\u3001\u79fb\u52a8\u6a21\u5177\u7684\u673a\u5668\u4eba\u63a7\u5236\u6982\u5ff5\u3002", "result": "\u4f7f\u7528\u78b3\u7ea4\u7ef4\u589e\u5f3aHDPE\u80f6\u5e26\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u7cfb\u7edf\u5404\u5b50\u7cfb\u7edf\u548c\u94fa\u5e26\u8fc7\u7a0b\u529f\u80fd\u5f97\u5230\u786e\u8ba4\u3002", "conclusion": "\u8be5\u6210\u672c\u6548\u76ca\u578b\u81ea\u52a8\u94fa\u5e26\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u63a7\u5236\u538b\u5b9e\u529b\u548c\u6e29\u5ea6\uff0c\u9002\u7528\u4e8e\u5904\u7406\u590d\u6742\u5f62\u72b6\u7684\u590d\u5408\u6750\u6599\u94fa\u5e26\u5de5\u827a\u3002"}}
{"id": "2510.22998", "categories": ["cs.AI", "68T05, 68T07", "I.2.6; H.5.2"], "pdf": "https://arxiv.org/pdf/2510.22998", "abs": "https://arxiv.org/abs/2510.22998", "authors": ["Gilber A. Corrales", "Carlos Andr\u00e9s Ferro S\u00e1nchez", "Reinel Tabares-Soto", "Jes\u00fas Alfonso L\u00f3pez Sotelo", "Gonzalo A. Ruz", "Johan Sebastian Pi\u00f1a Dur\u00e1n"], "title": "ProfileXAI: User-Adaptive Explainable AI", "comment": "pages, 1 figure, 3 tables. Preprint. Evaluated on UCI Heart Disease\n  (1989) and UCI Differentiated Thyroid Cancer Recurrence (2023). Uses IEEEtran", "summary": "ProfileXAI is a model- and domain-agnostic framework that couples post-hoc\nexplainers (SHAP, LIME, Anchor) with retrieval - augmented LLMs to produce\nexplanations for different types of users. The system indexes a multimodal\nknowledge base, selects an explainer per instance via quantitative criteria,\nand generates grounded narratives with chat-enabled prompting. On Heart Disease\nand Thyroid Cancer datasets, we evaluate fidelity, robustness, parsimony, token\nuse, and perceived quality. No explainer dominates: LIME achieves the best\nfidelity-robustness trade-off (Infidelity $\\le 0.30$, $L<0.7$ on Heart\nDisease); Anchor yields the sparsest, low-token rules; SHAP attains the highest\nsatisfaction ($\\bar{x}=4.1$). Profile conditioning stabilizes tokens ($\\sigma\n\\le 13\\%$) and maintains positive ratings across profiles ($\\bar{x}\\ge 3.7$,\nwith domain experts at $3.77$), enabling efficient and trustworthy\nexplanations.", "AI": {"tldr": "ProfileXAI\u662f\u4e00\u4e2a\u6a21\u578b\u548c\u9886\u57df\u65e0\u5173\u7684\u6846\u67b6\uff0c\u5c06SHAP\u3001LIME\u3001Anchor\u7b49\u4e8b\u540e\u89e3\u91ca\u5668\u4e0e\u68c0\u7d22\u589e\u5f3a\u7684LLMs\u7ed3\u5408\uff0c\u4e3a\u4e0d\u540c\u7c7b\u578b\u7528\u6237\u751f\u6210\u89e3\u91ca\u3002\u7cfb\u7edf\u7d22\u5f15\u591a\u6a21\u6001\u77e5\u8bc6\u5e93\uff0c\u901a\u8fc7\u5b9a\u91cf\u6807\u51c6\u4e3a\u6bcf\u4e2a\u5b9e\u4f8b\u9009\u62e9\u89e3\u91ca\u5668\uff0c\u5e76\u751f\u6210\u57fa\u4e8e\u804a\u5929\u7684\u63d0\u793a\u7684\u63a5\u5730\u53d9\u8ff0\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u901a\u7528\u7684\u89e3\u91ca\u6846\u67b6\uff0c\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u7528\u6237\u7c7b\u578b\uff0c\u63d0\u4f9b\u9ad8\u6548\u4e14\u53ef\u4fe1\u7684\u89e3\u91ca\uff0c\u89e3\u51b3\u73b0\u6709\u89e3\u91ca\u65b9\u6cd5\u5728\u7528\u6237\u9002\u5e94\u6027\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u7ed3\u5408\u4e8b\u540e\u89e3\u91ca\u5668\uff08SHAP\u3001LIME\u3001Anchor\uff09\u4e0e\u68c0\u7d22\u589e\u5f3a\u7684LLMs\uff0c\u7d22\u5f15\u591a\u6a21\u6001\u77e5\u8bc6\u5e93\uff0c\u901a\u8fc7\u5b9a\u91cf\u6807\u51c6\u9009\u62e9\u89e3\u91ca\u5668\uff0c\u4f7f\u7528\u57fa\u4e8e\u804a\u5929\u7684\u63d0\u793a\u751f\u6210\u63a5\u5730\u53d9\u8ff0\u3002", "result": "\u5728\u5fc3\u810f\u75c5\u548c\u7532\u72b6\u817a\u764c\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cLIME\u5728\u4fdd\u771f\u5ea6-\u9c81\u68d2\u6027\u6743\u8861\u4e0a\u8868\u73b0\u6700\u4f73\uff0cAnchor\u4ea7\u751f\u6700\u7a00\u758f\u3001\u4f4etoken\u7684\u89c4\u5219\uff0cSHAP\u83b7\u5f97\u6700\u9ad8\u6ee1\u610f\u5ea6\u3002Profile\u6761\u4ef6\u5316\u7a33\u5b9atoken\u4f7f\u7528\u5e76\u4fdd\u6301\u5404\u7528\u6237\u914d\u7f6e\u6587\u4ef6\u7684\u79ef\u6781\u8bc4\u5206\u3002", "conclusion": "ProfileXAI\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u4e14\u53ef\u4fe1\u7684\u89e3\u91ca\uff0c\u6ca1\u6709\u5355\u4e00\u89e3\u91ca\u5668\u5728\u6240\u6709\u6307\u6807\u4e0a\u5360\u4f18\uff0c\u4f46\u901a\u8fc7\u6761\u4ef6\u5316\u53ef\u4ee5\u7a33\u5b9atoken\u4f7f\u7528\u5e76\u7ef4\u6301\u7528\u6237\u6ee1\u610f\u5ea6\u3002"}}
{"id": "2510.23119", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23119", "abs": "https://arxiv.org/abs/2510.23119", "authors": ["Yi-Lin Wei", "Zhexi Luo", "Yuhao Lin", "Mu Lin", "Zhizhao Liang", "Shuoyu Chen", "Wei-Shi Zheng"], "title": "OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback", "comment": "Project page: https://isee-laboratory.github.io/OmniDexGrasp/", "summary": "Enabling robots to dexterously grasp and manipulate objects based on human\ncommands is a promising direction in robotics. However, existing approaches are\nchallenging to generalize across diverse objects or tasks due to the limited\nscale of semantic dexterous grasp datasets. Foundation models offer a new way\nto enhance generalization, yet directly leveraging them to generate feasible\nrobotic actions remains challenging due to the gap between abstract model\nknowledge and physical robot execution. To address these challenges, we propose\nOmniDexGrasp, a generalizable framework that achieves omni-capabilities in user\nprompting, dexterous embodiment, and grasping tasks by combining foundation\nmodels with the transfer and control strategies. OmniDexGrasp integrates three\nkey modules: (i) foundation models are used to enhance generalization by\ngenerating human grasp images supporting omni-capability of user prompt and\ntask; (ii) a human-image-to-robot-action transfer strategy converts human\ndemonstrations into executable robot actions, enabling omni dexterous\nembodiment; (iii) force-aware adaptive grasp strategy ensures robust and stable\ngrasp execution. Experiments in simulation and on real robots validate the\neffectiveness of OmniDexGrasp on diverse user prompts, grasp task and dexterous\nhands, and further results show its extensibility to dexterous manipulation\ntasks.", "AI": {"tldr": "OmniDexGrasp\u662f\u4e00\u4e2a\u901a\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u4e0e\u4f20\u8f93\u63a7\u5236\u7b56\u7565\uff0c\u5b9e\u73b0\u7528\u6237\u63d0\u793a\u3001\u7075\u5de7\u4f53\u73b0\u548c\u6293\u53d6\u4efb\u52a1\u7684\u5168\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u7531\u4e8e\u8bed\u4e49\u7075\u5de7\u6293\u53d6\u6570\u636e\u96c6\u89c4\u6a21\u6709\u9650\uff0c\u96be\u4ee5\u5728\u4e0d\u540c\u7269\u4f53\u6216\u4efb\u52a1\u95f4\u6cdb\u5316\u3002\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u589e\u5f3a\u6cdb\u5316\u7684\u65b0\u9014\u5f84\uff0c\u4f46\u76f4\u63a5\u5229\u7528\u5b83\u4eec\u751f\u6210\u53ef\u884c\u7684\u673a\u5668\u4eba\u52a8\u4f5c\u4ecd\u5b58\u5728\u6311\u6218\u3002", "method": "\u96c6\u6210\u4e09\u4e2a\u5173\u952e\u6a21\u5757\uff1a(i)\u4f7f\u7528\u57fa\u7840\u6a21\u578b\u751f\u6210\u652f\u6301\u5168\u80fd\u529b\u7528\u6237\u63d0\u793a\u548c\u4efb\u52a1\u7684\u4eba\u7c7b\u6293\u53d6\u56fe\u50cf\uff1b(ii)\u4eba\u7c7b\u56fe\u50cf\u5230\u673a\u5668\u4eba\u52a8\u4f5c\u4f20\u8f93\u7b56\u7565\u5c06\u4eba\u7c7b\u6f14\u793a\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684\u673a\u5668\u4eba\u52a8\u4f5c\uff1b(iii)\u529b\u611f\u77e5\u81ea\u9002\u5e94\u6293\u53d6\u7b56\u7565\u786e\u4fdd\u7a33\u5065\u7a33\u5b9a\u7684\u6293\u53d6\u6267\u884c\u3002", "result": "\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u5b9e\u9a8c\u9a8c\u8bc1\u4e86OmniDexGrasp\u5728\u4e0d\u540c\u7528\u6237\u63d0\u793a\u3001\u6293\u53d6\u4efb\u52a1\u548c\u7075\u5de7\u624b\u4e0a\u7684\u6709\u6548\u6027\uff0c\u5e76\u663e\u793a\u5176\u5728\u7075\u5de7\u64cd\u4f5c\u4efb\u52a1\u4e0a\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "OmniDexGrasp\u901a\u8fc7\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u4e0e\u4f20\u8f93\u63a7\u5236\u7b56\u7565\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u7075\u5de7\u6293\u53d6\u548c\u64cd\u4f5c\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u4e3a\u673a\u5668\u4eba\u7075\u5de7\u64cd\u4f5c\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.23008", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23008", "abs": "https://arxiv.org/abs/2510.23008", "authors": ["Qiuli Wang", "Xiaoming Li", "Jie Chen", "Yongxu Liu", "Xingpeng Zhang", "Chen Liu", "Wei Chen"], "title": "From Prompt Optimization to Multi-Dimensional Credibility Evaluation: Enhancing Trustworthiness of Chinese LLM-Generated Liver MRI Reports", "comment": "10 pages, 6 figures, 4 tables", "summary": "Large language models (LLMs) have demonstrated promising performance in\ngenerating diagnostic conclusions from imaging findings, thereby supporting\nradiology reporting, trainee education, and quality control. However,\nsystematic guidance on how to optimize prompt design across different clinical\ncontexts remains underexplored. Moreover, a comprehensive and standardized\nframework for assessing the trustworthiness of LLM-generated radiology reports\nis yet to be established. This study aims to enhance the trustworthiness of\nLLM-generated liver MRI reports by introducing a Multi-Dimensional Credibility\nAssessment (MDCA) framework and providing guidance on institution-specific\nprompt optimization. The proposed framework is applied to evaluate and compare\nthe performance of several advanced LLMs, including Kimi-K2-Instruct-0905,\nQwen3-235B-A22B-Instruct-2507, DeepSeek-V3, and\nByteDance-Seed-OSS-36B-Instruct, using the SiliconFlow platform.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u7ef4\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u6846\u67b6(MDCA)\u6765\u589e\u5f3aLLM\u751f\u6210\u7684\u809d\u810fMRI\u62a5\u544a\u7684\u53ef\u4fe1\u5ea6\uff0c\u5e76\u4e3a\u673a\u6784\u7279\u5b9a\u7684\u63d0\u793a\u4f18\u5316\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u867d\u7136LLM\u5728\u4ece\u5f71\u50cf\u5b66\u53d1\u73b0\u751f\u6210\u8bca\u65ad\u7ed3\u8bba\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5728\u4e0d\u540c\u4e34\u5e8a\u80cc\u666f\u4e0b\u5982\u4f55\u4f18\u5316\u63d0\u793a\u8bbe\u8ba1\u4ee5\u53ca\u5982\u4f55\u8bc4\u4f30LLM\u751f\u6210\u653e\u5c04\u5b66\u62a5\u544a\u7684\u53ef\u4fe1\u5ea6\u65b9\u9762\u4ecd\u7f3a\u4e4f\u7cfb\u7edf\u6307\u5bfc\u3002", "method": "\u5f15\u5165\u591a\u7ef4\u53ef\u4fe1\u5ea6\u8bc4\u4f30(MDCA)\u6846\u67b6\uff0c\u5e76\u5e94\u7528\u4e8e\u8bc4\u4f30\u591a\u4e2a\u5148\u8fdbLLM(Kimi-K2-Instruct-0905\u3001Qwen3-235B-A22B-Instruct-2507\u3001DeepSeek-V3\u3001ByteDance-Seed-OSS-36B-Instruct)\u5728SiliconFlow\u5e73\u53f0\u4e0a\u7684\u6027\u80fd\u3002", "result": "\u7814\u7a76\u6bd4\u8f83\u4e86\u591a\u4e2a\u5148\u8fdbLLM\u5728\u809d\u810fMRI\u62a5\u544a\u751f\u6210\u65b9\u9762\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4f18\u5316LLM\u5728\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\u4e2d\u7684\u53ef\u4fe1\u5ea6\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\u548c\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2510.23121", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23121", "abs": "https://arxiv.org/abs/2510.23121", "authors": ["Bharath Santhanam", "Alex Mitrevski", "Santosh Thoduka", "Sebastian Houben", "Teena Hassan"], "title": "Reliable Robotic Task Execution in the Face of Anomalies", "comment": "Accepted for publication in IEEE Robotics and Automation Letters\n  (RA-L)", "summary": "Learned robot policies have consistently been shown to be versatile, but they\ntypically have no built-in mechanism for handling the complexity of open\nenvironments, making them prone to execution failures; this implies that\ndeploying policies without the ability to recognise and react to failures may\nlead to unreliable and unsafe robot behaviour. In this paper, we present a\nframework that couples a learned policy with a method to detect visual\nanomalies during policy deployment and to perform recovery behaviours when\nnecessary, thereby aiming to prevent failures. Specifically, we train an\nanomaly detection model using data collected during nominal executions of a\ntrained policy. This model is then integrated into the online policy execution\nprocess, so that deviations from the nominal execution can trigger a\nthree-level sequential recovery process that consists of (i) pausing the\nexecution temporarily, (ii) performing a local perturbation of the robot's\nstate, and (iii) resetting the robot to a safe state by sampling from a learned\nexecution success model. We verify our proposed method in two different\nscenarios: (i) a door handle reaching task with a Kinova Gen3 arm using a\npolicy trained in simulation and transferred to the real robot, and (ii) an\nobject placing task with a UFactory xArm 6 using a general-purpose policy\nmodel. Our results show that integrating policy execution with anomaly\ndetection and recovery increases the execution success rate in environments\nwith various anomalies, such as trajectory deviations and adversarial human\ninterventions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u5b66\u4e60\u7b56\u7565\u4e0e\u89c6\u89c9\u5f02\u5e38\u68c0\u6d4b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u7ea7\u6062\u590d\u8fc7\u7a0b\u5904\u7406\u6267\u884c\u5931\u8d25\uff0c\u63d0\u9ad8\u673a\u5668\u4eba\u5728\u5f00\u653e\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u5b66\u4e60\u5230\u7684\u673a\u5668\u4eba\u7b56\u7565\u867d\u7136\u901a\u7528\uff0c\u4f46\u5728\u5f00\u653e\u73af\u5883\u4e2d\u7f3a\u4e4f\u5904\u7406\u590d\u6742\u6027\u7684\u673a\u5236\uff0c\u5bb9\u6613\u5bfc\u81f4\u6267\u884c\u5931\u8d25\uff0c\u9700\u8981\u80fd\u591f\u8bc6\u522b\u548c\u5e94\u5bf9\u5931\u8d25\u7684\u673a\u5236\u6765\u786e\u4fdd\u53ef\u9760\u548c\u5b89\u5168\u7684\u673a\u5668\u4eba\u884c\u4e3a\u3002", "method": "\u8bad\u7ec3\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\u4f7f\u7528\u7b56\u7565\u6b63\u5e38\u6267\u884c\u65f6\u6536\u96c6\u7684\u6570\u636e\uff0c\u5728\u7ebf\u6267\u884c\u65f6\u68c0\u6d4b\u5f02\u5e38\u5e76\u89e6\u53d1\u4e09\u7ea7\u6062\u590d\u8fc7\u7a0b\uff1a\u6682\u505c\u6267\u884c\u3001\u5c40\u90e8\u6270\u52a8\u673a\u5668\u4eba\u72b6\u6001\u3001\u4ece\u5b66\u4e60\u5230\u7684\u6267\u884c\u6210\u529f\u6a21\u578b\u4e2d\u91c7\u6837\u91cd\u7f6e\u5230\u5b89\u5168\u72b6\u6001\u3002", "result": "\u5728\u4e24\u79cd\u573a\u666f\u4e2d\u9a8c\u8bc1\uff1aKinova Gen3\u81c2\u7684\u95e8\u628a\u624b\u5230\u8fbe\u4efb\u52a1\u548cUFactory xArm 6\u7684\u7269\u4f53\u653e\u7f6e\u4efb\u52a1\u3002\u7ed3\u679c\u8868\u660e\uff0c\u96c6\u6210\u5f02\u5e38\u68c0\u6d4b\u548c\u6062\u590d\u80fd\u63d0\u9ad8\u5728\u5b58\u5728\u8f68\u8ff9\u504f\u5dee\u548c\u4eba\u4e3a\u5e72\u6270\u7b49\u5f02\u5e38\u73af\u5883\u4e2d\u7684\u6267\u884c\u6210\u529f\u7387\u3002", "conclusion": "\u5c06\u7b56\u7565\u6267\u884c\u4e0e\u5f02\u5e38\u68c0\u6d4b\u548c\u6062\u590d\u76f8\u7ed3\u5408\uff0c\u80fd\u6709\u6548\u63d0\u9ad8\u673a\u5668\u4eba\u5728\u5f00\u653e\u73af\u5883\u4e2d\u7684\u6267\u884c\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2510.23026", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23026", "abs": "https://arxiv.org/abs/2510.23026", "authors": ["Crimson Stambaugh", "Rajesh P. N. Rao"], "title": "Mixed Density Diffuser: Efficient Planning with Non-uniform Temporal Resolution", "comment": "European Symposium on Artificial Neural Networks, Computational\n  Intelligence and Machine Learning (ESSAN) (under review)", "summary": "Recent studies demonstrate that diffusion planners benefit from sparse-step\nplanning over single-step planning. Training models to skip steps in their\ntrajectories helps capture long-term dependencies without additional or memory\ncomputational cost. However, predicting excessively sparse plans degrades\nperformance. We hypothesize this temporal density threshold is non-uniform\nacross a temporal horizon and that certain parts of a planned trajectory should\nbe more densely planned. We propose Mixed Density Diffuser (MDD), a diffusion\nplanner where the densities throughout the horizon are tunable hyperparameters.\nMDD achieves a new SOTA across the Maze2D, Franka Kitchen, and Antmaze D4RL\ntask domains.", "AI": {"tldr": "\u63d0\u51faMixed Density Diffuser (MDD)\uff0c\u4e00\u79cd\u53ef\u8c03\u8282\u89c4\u5212\u5bc6\u5ea6\u7684\u6269\u6563\u89c4\u5212\u5668\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u9886\u57df\u8fbe\u5230\u65b0\u7684SOTA\u6027\u80fd", "motivation": "\u73b0\u6709\u6269\u6563\u89c4\u5212\u5668\u91c7\u7528\u7a00\u758f\u6b65\u957f\u89c4\u5212\u4f18\u4e8e\u5355\u6b65\u89c4\u5212\uff0c\u4f46\u8fc7\u5ea6\u7a00\u758f\u4f1a\u964d\u4f4e\u6027\u80fd\u3002\u5047\u8bbe\u65f6\u95f4\u5bc6\u5ea6\u9608\u503c\u5728\u65f6\u95f4\u8303\u56f4\u5185\u4e0d\u5747\u5300\uff0c\u67d0\u4e9b\u8f68\u8ff9\u90e8\u5206\u9700\u8981\u66f4\u5bc6\u96c6\u89c4\u5212", "method": "MDD\u6269\u6563\u89c4\u5212\u5668\uff0c\u5728\u6574\u4e2a\u65f6\u95f4\u8303\u56f4\u5185\u5bc6\u5ea6\u4f5c\u4e3a\u53ef\u8c03\u8d85\u53c2\u6570\uff0c\u5141\u8bb8\u4e0d\u540c\u90e8\u5206\u91c7\u7528\u4e0d\u540c\u89c4\u5212\u5bc6\u5ea6", "result": "\u5728Maze2D\u3001Franka Kitchen\u548cAntmaze D4RL\u4efb\u52a1\u9886\u57df\u8fbe\u5230\u65b0\u7684SOTA\u6027\u80fd", "conclusion": "\u53ef\u8c03\u8282\u5bc6\u5ea6\u7684\u6269\u6563\u89c4\u5212\u5668\u80fd\u66f4\u597d\u5730\u5904\u7406\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02"}}
{"id": "2510.23045", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23045", "abs": "https://arxiv.org/abs/2510.23045", "authors": ["Guiyao Tie", "Pan Zhou", "Lichao Sun"], "title": "A Survey of AI Scientists: Surveying the automatic Scientists and Research", "comment": "28 pages, 9 figures, 1 table", "summary": "Artificial intelligence is undergoing a profound transition from a\ncomputational instrument to an autonomous originator of scientific knowledge.\nThis emerging paradigm, the AI scientist, is architected to emulate the\ncomplete scientific workflow-from initial hypothesis generation to the final\nsynthesis of publishable findings-thereby promising to fundamentally reshape\nthe pace and scale of discovery. However, the rapid and unstructured\nproliferation of these systems has created a fragmented research landscape,\nobscuring overarching methodological principles and developmental trends. This\nsurvey provides a systematic and comprehensive synthesis of this domain by\nintroducing a unified, six-stage methodological framework that deconstructs the\nend-to-end scientific process into: Literature Review, Idea Generation,\nExperimental Preparation, Experimental Execution, Scientific Writing, and Paper\nGeneration. Through this analytical lens, we chart the field's evolution from\nearly Foundational Modules (2022-2023) to integrated Closed-Loop Systems\n(2024), and finally to the current frontier of Scalability, Impact, and\nHuman-AI Collaboration (2025-present). By rigorously synthesizing these\ndevelopments, this survey not only clarifies the current state of autonomous\nscience but also provides a critical roadmap for overcoming remaining\nchallenges in robustness and governance, ultimately guiding the next generation\nof systems toward becoming trustworthy and indispensable partners in human\nscientific inquiry.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86AI\u79d1\u5b66\u5bb6\u9886\u57df\u7684\u53d1\u5c55\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u516d\u9636\u6bb5\u65b9\u6cd5\u8bba\u6846\u67b6\u6765\u5206\u6790\u81ea\u4e3b\u79d1\u5b66\u53d1\u73b0\u8fc7\u7a0b\uff0c\u5e76\u68b3\u7406\u4e86\u8be5\u9886\u57df\u4ece\u57fa\u7840\u6a21\u5757\u5230\u95ed\u73af\u7cfb\u7edf\u518d\u5230\u53ef\u6269\u5c55\u6027\u7814\u7a76\u7684\u6f14\u8fdb\u5386\u7a0b\u3002", "motivation": "AI\u6b63\u4ece\u8ba1\u7b97\u5de5\u5177\u8f6c\u53d8\u4e3a\u81ea\u4e3b\u79d1\u5b66\u77e5\u8bc6\u521b\u9020\u8005\uff0c\u4f46\u8be5\u9886\u57df\u7684\u5feb\u901f\u53d1\u5c55\u5bfc\u81f4\u7814\u7a76\u788e\u7247\u5316\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u65b9\u6cd5\u8bba\u6846\u67b6\u548c\u53d1\u5c55\u8d8b\u52bf\u5206\u6790\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u7684\u516d\u9636\u6bb5\u65b9\u6cd5\u8bba\u6846\u67b6\uff1a\u6587\u732e\u7efc\u8ff0\u3001\u60f3\u6cd5\u751f\u6210\u3001\u5b9e\u9a8c\u51c6\u5907\u3001\u5b9e\u9a8c\u6267\u884c\u3001\u79d1\u5b66\u5199\u4f5c\u548c\u8bba\u6587\u751f\u6210\uff0c\u901a\u8fc7\u8fd9\u4e00\u5206\u6790\u89c6\u89d2\u68b3\u7406\u9886\u57df\u53d1\u5c55\u3002", "result": "\u6784\u5efa\u4e86\u7cfb\u7edf\u7684\u9886\u57df\u53d1\u5c55\u56fe\u8c31\uff0c\u4ece\u65e9\u671f\u57fa\u7840\u6a21\u5757\uff082022-2023\uff09\u5230\u96c6\u6210\u95ed\u73af\u7cfb\u7edf\uff082024\uff09\uff0c\u518d\u5230\u5f53\u524d\u7684\u53ef\u6269\u5c55\u6027\u3001\u5f71\u54cd\u529b\u548c\u4eba\u673a\u534f\u4f5c\u7814\u7a76\uff082025\u81f3\u4eca\uff09\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u4e0d\u4ec5\u9610\u660e\u4e86\u81ea\u4e3b\u79d1\u5b66\u7684\u73b0\u72b6\uff0c\u8fd8\u4e3a\u514b\u670d\u9c81\u68d2\u6027\u548c\u6cbb\u7406\u65b9\u9762\u7684\u6311\u6218\u63d0\u4f9b\u4e86\u5173\u952e\u8def\u7ebf\u56fe\uff0c\u6307\u5bfc\u4e0b\u4e00\u4ee3\u7cfb\u7edf\u6210\u4e3a\u4eba\u7c7b\u79d1\u5b66\u63a2\u7a76\u4e2d\u503c\u5f97\u4fe1\u8d56\u7684\u5408\u4f5c\u4f19\u4f34\u3002"}}
{"id": "2510.23176", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23176", "abs": "https://arxiv.org/abs/2510.23176", "authors": ["Arnav Sukhija", "Lenart Treven", "Jin Cheng", "Florian D\u00f6rfler", "Stelian Coros", "Andreas Krause"], "title": "TARC: Time-Adaptive Robotic Control", "comment": null, "summary": "Fixed-frequency control in robotics imposes a trade-off between the\nefficiency of low-frequency control and the robustness of high-frequency\ncontrol, a limitation not seen in adaptable biological systems. We address this\nwith a reinforcement learning approach in which policies jointly select control\nactions and their application durations, enabling robots to autonomously\nmodulate their control frequency in response to situational demands. We\nvalidate our method with zero-shot sim-to-real experiments on two distinct\nhardware platforms: a high-speed RC car and a quadrupedal robot. Our method\nmatches or outperforms fixed-frequency baselines in terms of rewards while\nsignificantly reducing the control frequency and exhibiting adaptive frequency\ncontrol under real-world conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u8ba9\u673a\u5668\u4eba\u80fd\u81ea\u4e3b\u8c03\u6574\u63a7\u5236\u9891\u7387\u4ee5\u9002\u5e94\u4e0d\u540c\u60c5\u5883\u9700\u6c42\uff0c\u5728\u4e24\u79cd\u786c\u4ef6\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u56fa\u5b9a\u9891\u7387\u63a7\u5236\u5728\u673a\u5668\u4eba\u9886\u57df\u5b58\u5728\u6548\u7387\u4e0e\u9c81\u68d2\u6027\u7684\u6743\u8861\uff0c\u800c\u751f\u7269\u7cfb\u7edf\u80fd\u591f\u81ea\u9002\u5e94\u8c03\u6574\u9891\u7387\uff0c\u8fd9\u542f\u53d1\u4e86\u7814\u7a76\u53ef\u53d8\u9891\u7387\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u8ba9\u7b56\u7565\u540c\u65f6\u9009\u62e9\u63a7\u5236\u52a8\u4f5c\u53ca\u5176\u5e94\u7528\u6301\u7eed\u65f6\u95f4\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u6839\u636e\u60c5\u5883\u9700\u6c42\u81ea\u4e3b\u8c03\u8282\u63a7\u5236\u9891\u7387\u3002", "result": "\u5728\u9ad8\u901f\u9065\u63a7\u8f66\u548c\u56db\u8db3\u673a\u5668\u4eba\u4e0a\u7684\u96f6\u6837\u672c\u4eff\u771f\u5230\u73b0\u5b9e\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5956\u52b1\u65b9\u9762\u8fbe\u5230\u6216\u8d85\u8fc7\u56fa\u5b9a\u9891\u7387\u57fa\u7ebf\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u63a7\u5236\u9891\u7387\u5e76\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u81ea\u9002\u5e94\u9891\u7387\u63a7\u5236\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u673a\u5668\u4eba\u63a7\u5236\u9891\u7387\u7684\u81ea\u9002\u5e94\u8c03\u8282\uff0c\u89e3\u51b3\u4e86\u56fa\u5b9a\u9891\u7387\u63a7\u5236\u7684\u5c40\u9650\u6027\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.23062", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23062", "abs": "https://arxiv.org/abs/2510.23062", "authors": ["Zhifeng Wang", "Meixin Su", "Yang Yang", "Chunyan Zeng", "Lizhi Ye"], "title": "TLCD: A Deep Transfer Learning Framework for Cross-Disciplinary Cognitive Diagnosis", "comment": "10 pages, 8 figures", "summary": "Driven by the dual principles of smart education and artificial intelligence\ntechnology, the online education model has rapidly emerged as an important\ncomponent of the education industry. Cognitive diagnostic technology can\nutilize students' learning data and feedback information in educational\nevaluation to accurately assess their ability level at the knowledge level.\nHowever, while massive amounts of information provide abundant data resources,\nthey also bring about complexity in feature extraction and scarcity of\ndisciplinary data. In cross-disciplinary fields, traditional cognitive\ndiagnostic methods still face many challenges. Given the differences in\nknowledge systems, cognitive structures, and data characteristics between\ndifferent disciplines, this paper conducts in-depth research on neural network\ncognitive diagnosis and knowledge association neural network cognitive\ndiagnosis, and proposes an innovative cross-disciplinary cognitive diagnosis\nmethod (TLCD). This method combines deep learning techniques and transfer\nlearning strategies to enhance the performance of the model in the target\ndiscipline by utilizing the common features of the main discipline. The\nexperimental results show that the cross-disciplinary cognitive diagnosis model\nbased on deep learning performs better than the basic model in\ncross-disciplinary cognitive diagnosis tasks, and can more accurately evaluate\nstudents' learning situation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u548c\u8fc1\u79fb\u5b66\u4e60\u7684\u8de8\u5b66\u79d1\u8ba4\u77e5\u8bca\u65ad\u65b9\u6cd5\uff08TLCD\uff09\uff0c\u901a\u8fc7\u5229\u7528\u4e3b\u5b66\u79d1\u7684\u5171\u540c\u7279\u5f81\u6765\u63d0\u5347\u76ee\u6807\u5b66\u79d1\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5728\u8de8\u5b66\u79d1\u8ba4\u77e5\u8bca\u65ad\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\u3002", "motivation": "\u5728\u7ebf\u6559\u80b2\u6a21\u5f0f\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u8de8\u5b66\u79d1\u9886\u57df\u4e2d\u7684\u4f20\u7edf\u8ba4\u77e5\u8bca\u65ad\u65b9\u6cd5\u9762\u4e34\u77e5\u8bc6\u4f53\u7cfb\u5dee\u5f02\u3001\u8ba4\u77e5\u7ed3\u6784\u4e0d\u540c\u548c\u6570\u636e\u7279\u5f81\u591a\u6837\u7b49\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u548c\u8fc1\u79fb\u5b66\u4e60\u7b56\u7565\uff0c\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u8ba4\u77e5\u8bca\u65ad\u548c\u77e5\u8bc6\u5173\u8054\u795e\u7ecf\u7f51\u7edc\u8ba4\u77e5\u8bca\u65ad\uff0c\u63d0\u51fa\u8de8\u5b66\u79d1\u8ba4\u77e5\u8bca\u65ad\u65b9\u6cd5TLCD\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8de8\u5b66\u79d1\u8ba4\u77e5\u8bca\u65ad\u6a21\u578b\u5728\u8de8\u5b66\u79d1\u8ba4\u77e5\u8bca\u65ad\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\uff0c\u80fd\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u5b66\u751f\u7684\u5b66\u4e60\u60c5\u51b5\u3002", "conclusion": "TLCD\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u5b66\u79d1\u8ba4\u77e5\u8bca\u65ad\u4e2d\u7684\u6311\u6218\uff0c\u4e3a\u667a\u80fd\u6559\u80b2\u63d0\u4f9b\u4e86\u66f4\u7cbe\u51c6\u7684\u5b66\u751f\u80fd\u529b\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2510.23204", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.23204", "abs": "https://arxiv.org/abs/2510.23204", "authors": ["Giulia Pusceddu", "Giulio Antonio Abbo", "Francesco Rea", "Tony Belpaeme", "Alessandra Sciutti"], "title": "If They Disagree, Will You Conform? Exploring the Role of Robots' Value Awareness in a Decision-Making Task", "comment": null, "summary": "This study investigates whether the opinions of robotic agents are more\nlikely to influence human decision-making when the robots are perceived as\nvalue-aware (i.e., when they display an understanding of human principles). We\ndesigned an experiment in which participants interacted with two Furhat robots\n- one programmed to be Value-Aware and the other Non-Value-Aware - during a\nlabeling task for images representing human values. Results indicate that\nparticipants distinguished the Value-Aware robot from the Non-Value-Aware one.\nAlthough their explicit choices did not indicate a clear preference for one\nrobot over the other, participants directed their gaze more toward the\nValue-Aware robot. Additionally, the Value-Aware robot was perceived as more\nloyal, suggesting that value awareness in a social robot may enhance its\nperceived commitment to the group. Finally, when both robots disagreed with the\nparticipant, conformity occurred in about one out of four trials, and\nparticipants took longer to confirm their responses, suggesting that two robots\nexpressing dissent may introduce hesitation in decision-making. On one hand,\nthis highlights the potential risk that robots, if misused, could manipulate\nusers for unethical purposes. On the other hand, it reinforces the idea that\nsocial robots might encourage reflection in ambiguous situations and help users\navoid scams.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5f53\u673a\u5668\u4eba\u8868\u73b0\u51fa\u5bf9\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u7406\u89e3\u65f6\uff0c\u5b83\u4eec\u66f4\u5bb9\u6613\u5f71\u54cd\u4eba\u7c7b\u51b3\u7b56\u3002\u53c2\u4e0e\u8005\u80fd\u533a\u5206\u4ef7\u503c\u611f\u77e5\u578b\u548c\u975e\u4ef7\u503c\u611f\u77e5\u578b\u673a\u5668\u4eba\uff0c\u5e76\u66f4\u591a\u5730\u6ce8\u89c6\u4ef7\u503c\u611f\u77e5\u578b\u673a\u5668\u4eba\uff0c\u8ba4\u4e3a\u5176\u66f4\u5fe0\u8bda\u3002\u5f53\u4e24\u4e2a\u673a\u5668\u4eba\u90fd\u53cd\u5bf9\u53c2\u4e0e\u8005\u65f6\uff0c\u7ea61/4\u7684\u8bd5\u9a8c\u4e2d\u51fa\u73b0\u4ece\u4f17\u884c\u4e3a\uff0c\u4e14\u51b3\u7b56\u65f6\u95f4\u5ef6\u957f\u3002", "motivation": "\u7814\u7a76\u673a\u5668\u4eba\u662f\u5426\u5728\u8868\u73b0\u51fa\u5bf9\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u7406\u89e3\u65f6\uff0c\u5bf9\u4eba\u7c7b\u51b3\u7b56\u4ea7\u751f\u66f4\u5927\u5f71\u54cd\uff0c\u4ee5\u53ca\u8fd9\u79cd\u5f71\u54cd\u5982\u4f55\u4f53\u73b0\u3002", "method": "\u8bbe\u8ba1\u5b9e\u9a8c\u8ba9\u53c2\u4e0e\u8005\u4e0e\u4e24\u4e2aFurhat\u673a\u5668\u4eba\u4e92\u52a8\uff0c\u4e00\u4e2a\u88ab\u7f16\u7a0b\u4e3a\u4ef7\u503c\u611f\u77e5\u578b\uff0c\u53e6\u4e00\u4e2a\u4e3a\u975e\u4ef7\u503c\u611f\u77e5\u578b\uff0c\u5728\u56fe\u50cf\u6807\u6ce8\u4efb\u52a1\u4e2d\u89c2\u5bdf\u53c2\u4e0e\u8005\u7684\u884c\u4e3a\u548c\u53cd\u5e94\u3002", "result": "\u53c2\u4e0e\u8005\u80fd\u533a\u5206\u4e24\u79cd\u673a\u5668\u4eba\uff0c\u66f4\u591a\u5730\u6ce8\u89c6\u4ef7\u503c\u611f\u77e5\u578b\u673a\u5668\u4eba\uff0c\u8ba4\u4e3a\u5176\u66f4\u5fe0\u8bda\u3002\u5f53\u4e24\u4e2a\u673a\u5668\u4eba\u90fd\u53cd\u5bf9\u53c2\u4e0e\u8005\u65f6\uff0c\u7ea625%\u7684\u8bd5\u9a8c\u51fa\u73b0\u4ece\u4f17\u884c\u4e3a\uff0c\u51b3\u7b56\u65f6\u95f4\u5ef6\u957f\u3002", "conclusion": "\u4ef7\u503c\u611f\u77e5\u578b\u673a\u5668\u4eba\u53ef\u80fd\u589e\u5f3a\u5176\u7fa4\u4f53\u627f\u8bfa\u611f\u77e5\uff0c\u673a\u5668\u4eba\u8868\u8fbe\u5f02\u8bae\u53ef\u80fd\u5f15\u53d1\u51b3\u7b56\u72b9\u8c6b\u3002\u8fd9\u65e2\u5b58\u5728\u673a\u5668\u4eba\u88ab\u6ee5\u7528\u4e8e\u4e0d\u9053\u5fb7\u76ee\u7684\u7684\u98ce\u9669\uff0c\u4e5f\u8868\u660e\u793e\u4ea4\u673a\u5668\u4eba\u53ef\u80fd\u5728\u6a21\u7cca\u60c5\u5883\u4e2d\u4fc3\u8fdb\u53cd\u601d\uff0c\u5e2e\u52a9\u7528\u6237\u907f\u514d\u53d7\u9a97\u3002"}}
{"id": "2510.23083", "categories": ["cs.AI", "cs.LG", "cs.SE", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.23083", "abs": "https://arxiv.org/abs/2510.23083", "authors": ["Jan Niklas Groeneveld", "Xi Qin", "Alexander Schaefer", "Yaad Oren"], "title": "Smaller Models, Smarter Rewards: A Two-Sided Approach to Process and Outcome Rewards", "comment": "Accepted and to be presented at NeurIPS 2025 Workshop: Foundations of\n  Reasoning in Language Models", "summary": "Generating high-quality code remains a challenge for Large Language Models\n(LLMs). For the evolution of reasoning models on this task, reward models are a\nnecessary intermediate step. These models judge outcomes or intermediate steps.\nDecoder-only transformer models can be turned into reward models by introducing\na regression layer and supervised fine-tuning. While it is known that\nreflection capabilities generally increase with the size of a model, we want to\ninvestigate whether state-of-the-art small language models like the Phi-4\nfamily can be turned into usable reward models blending the consideration of\nprocess rewards and outcome rewards.\n  Targeting this goal, we construct a dataset of code samples with correctness\nlabels derived from the APPS coding challenge benchmark. We then train a\nvalue-head model to estimate the success probability of intermediate outputs.\nOur evaluation shows that small LLMs are capable of serving as effective reward\nmodels or code evaluation critics, successfully identifying correct solutions\namong multiple candidates. Using this critic, we achieve over a 20% improvement\nin the search capability of the most accurate code out of multiple generations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5c06\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982Phi-4\u7cfb\u5217\uff09\u8f6c\u5316\u4e3a\u6709\u6548\u7684\u5956\u52b1\u6a21\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u901a\u8fc7\u7ed3\u5408\u8fc7\u7a0b\u5956\u52b1\u548c\u7ed3\u679c\u5956\u52b1\uff0c\u5728APPS\u7f16\u7801\u6311\u6218\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8fc720%\u7684\u4ee3\u7801\u641c\u7d22\u80fd\u529b\u63d0\u5347\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u9ad8\u8d28\u91cf\u4ee3\u7801\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u5956\u52b1\u6a21\u578b\u4f5c\u4e3a\u63a8\u7406\u6a21\u578b\u53d1\u5c55\u7684\u4e2d\u95f4\u6b65\u9aa4\u3002\u867d\u7136\u6a21\u578b\u89c4\u6a21\u901a\u5e38\u4e0e\u53cd\u601d\u80fd\u529b\u76f8\u5173\uff0c\u4f46\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u4e5f\u80fd\u6210\u4e3a\u6709\u6548\u7684\u5956\u52b1\u6a21\u578b\u3002", "method": "\u6784\u5efa\u57fa\u4e8eAPPS\u7f16\u7801\u6311\u6218\u57fa\u51c6\u7684\u4ee3\u7801\u6837\u672c\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u5e26\u6709\u56de\u5f52\u5c42\u7684\u4ef7\u503c\u5934\u6a21\u578b\u6765\u4f30\u8ba1\u4e2d\u95f4\u8f93\u51fa\u7684\u6210\u529f\u6982\u7387\uff0c\u7ed3\u5408\u8fc7\u7a0b\u5956\u52b1\u548c\u7ed3\u679c\u5956\u52b1\u3002", "result": "\u5c0f\u578bLLM\u80fd\u591f\u4f5c\u4e3a\u6709\u6548\u7684\u5956\u52b1\u6a21\u578b\u6216\u4ee3\u7801\u8bc4\u4f30\u6279\u8bc4\u5668\uff0c\u6210\u529f\u8bc6\u522b\u591a\u4e2a\u5019\u9009\u65b9\u6848\u4e2d\u7684\u6b63\u786e\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u7528\u8be5\u6279\u8bc4\u5668\u53ef\u5c06\u6700\u51c6\u786e\u4ee3\u7801\u7684\u641c\u7d22\u80fd\u529b\u63d0\u5347\u8d85\u8fc720%\u3002", "conclusion": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u88ab\u8f6c\u5316\u4e3a\u6709\u6548\u7684\u5956\u52b1\u6a21\u578b\uff0c\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u8bc4\u4f30\u80fd\u529b\uff0c\u4e3a\u4ee3\u7801\u8d28\u91cf\u6539\u8fdb\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2510.23227", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23227", "abs": "https://arxiv.org/abs/2510.23227", "authors": ["Klaus Zauner", "Josef El Dib", "Hubert Gattringer", "Andreas Mueller"], "title": "Workspace Registration and Collision Detection for Industrial Robotics Applications", "comment": null, "summary": "Motion planning for robotic manipulators relies on precise knowledge of the\nenvironment in order to be able to define restricted areas and to take\ncollision objects into account. To capture the workspace, point clouds of the\nenvironment are acquired using various sensors. The collision objects are\nidentified by region growing segmentation and VCCS algorithm. Subsequently the\npoint clusters are approximated. The aim of the present paper is to compare\ndifferent sensors, to illustrate the process from detection to the finished\ncollision environment and to detect collisions between the robot and this\nenvironment.", "AI": {"tldr": "\u6bd4\u8f83\u4e0d\u540c\u4f20\u611f\u5668\u5728\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u4e2d\u7684\u5e94\u7528\uff0c\u5c55\u793a\u4ece\u73af\u5883\u68c0\u6d4b\u5230\u78b0\u649e\u73af\u5883\u6784\u5efa\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u5e76\u68c0\u6d4b\u673a\u5668\u4eba\u4e0e\u73af\u5883\u7684\u78b0\u649e\u3002", "motivation": "\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u9700\u8981\u7cbe\u786e\u7684\u73af\u5883\u77e5\u8bc6\u6765\u5b9a\u4e49\u53d7\u9650\u533a\u57df\u548c\u8003\u8651\u78b0\u649e\u7269\u4f53\uff0c\u901a\u8fc7\u83b7\u53d6\u73af\u5883\u70b9\u4e91\u6765\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002", "method": "\u4f7f\u7528\u5404\u79cd\u4f20\u611f\u5668\u83b7\u53d6\u73af\u5883\u70b9\u4e91\uff0c\u901a\u8fc7\u533a\u57df\u751f\u957f\u5206\u5272\u548cVCCS\u7b97\u6cd5\u8bc6\u522b\u78b0\u649e\u7269\u4f53\uff0c\u7136\u540e\u5bf9\u70b9\u7c07\u8fdb\u884c\u8fd1\u4f3c\u5904\u7406\u3002", "result": "\u5efa\u7acb\u4e86\u4ece\u73af\u5883\u68c0\u6d4b\u5230\u78b0\u649e\u73af\u5883\u6784\u5efa\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u78b0\u649e\u7269\u4f53\u5e76\u68c0\u6d4b\u673a\u5668\u4eba\u4e0e\u73af\u5883\u7684\u78b0\u649e\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6784\u5efa\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\u7684\u78b0\u649e\u73af\u5883\uff0c\u4e3a\u5b89\u5168\u53ef\u9760\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u63d0\u4f9b\u4e86\u6280\u672f\u57fa\u7840\u3002"}}
{"id": "2510.23127", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23127", "abs": "https://arxiv.org/abs/2510.23127", "authors": ["Kai Zhuang", "Jiawei Zhang", "Yumou Liu", "Hanqun Cao", "Chunbin Gu", "Mengdi Liu", "Zhangyang Gao", "Zitong Jerry Wang", "Xuanhe Zhou", "Pheng-Ann Heng", "Lijun Wu", "Conghui He", "Cheng Tan"], "title": "Lost in Tokenization: Context as the Key to Unlocking Biomolecular Understanding in Scientific LLMs", "comment": "36 pages, under review", "summary": "Scientific Large Language Models (Sci-LLMs) have emerged as a promising\nfrontier for accelerating biological discovery. However, these models face a\nfundamental challenge when processing raw biomolecular sequences: the\ntokenization dilemma. Whether treating sequences as a specialized language,\nrisking the loss of functional motif information, or as a separate modality,\nintroducing formidable alignment challenges, current strategies fundamentally\nlimit their reasoning capacity. We challenge this sequence-centric paradigm by\npositing that a more effective strategy is to provide Sci-LLMs with high-level\nstructured context derived from established bioinformatics tools, thereby\nbypassing the need to interpret low-level noisy sequence data directly. Through\na systematic comparison of leading Sci-LLMs on biological reasoning tasks, we\ntested three input modes: sequence-only, context-only, and a combination of\nboth. Our findings are striking: the context-only approach consistently and\nsubstantially outperforms all other modes. Even more revealing, the inclusion\nof the raw sequence alongside its high-level context consistently degrades\nperformance, indicating that raw sequences act as informational noise, even for\nmodels with specialized tokenization schemes. These results suggest that the\nprimary strength of existing Sci-LLMs lies not in their nascent ability to\ninterpret biomolecular syntax from scratch, but in their profound capacity for\nreasoning over structured, human-readable knowledge. Therefore, we argue for\nreframing Sci-LLMs not as sequence decoders, but as powerful reasoning engines\nover expert knowledge. This work lays the foundation for a new class of hybrid\nscientific AI agents, repositioning the developmental focus from direct\nsequence interpretation towards high-level knowledge synthesis. The code is\navailable at github.com/opendatalab-raise-dev/CoKE.", "AI": {"tldr": "Sci-LLMs\u5728\u5904\u7406\u751f\u7269\u5206\u5b50\u5e8f\u5217\u65f6\u9762\u4e34tokenization\u56f0\u5883\uff0c\u7814\u7a76\u53d1\u73b0\u63d0\u4f9b\u9ad8\u5c42\u6b21\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\u6bd4\u76f4\u63a5\u5904\u7406\u539f\u59cb\u5e8f\u5217\u8868\u73b0\u66f4\u597d\uff0c\u751a\u81f3\u539f\u59cb\u5e8f\u5217\u4f1a\u5e72\u6270\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u79d1\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u539f\u59cb\u751f\u7269\u5206\u5b50\u5e8f\u5217\u65f6\u9762\u4e34\u7684tokenization\u56f0\u5883\uff0c\u63a2\u7d22\u66f4\u6709\u6548\u7684\u8f93\u5165\u7b56\u7565\u3002", "method": "\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4e09\u79cd\u8f93\u5165\u6a21\u5f0f\uff1a\u4ec5\u5e8f\u5217\u3001\u4ec5\u4e0a\u4e0b\u6587\u3001\u5e8f\u5217+\u4e0a\u4e0b\u6587\u7ec4\u5408\uff0c\u6d4b\u8bd5\u4e86\u9886\u5148\u7684Sci-LLMs\u5728\u751f\u7269\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u4ec5\u4e0a\u4e0b\u6587\u65b9\u6cd5\u59cb\u7ec8\u4e14\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u6a21\u5f0f\uff0c\u539f\u59cb\u5e8f\u5217\u7684\u52a0\u5165\u53cd\u800c\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u8868\u660e\u539f\u59cb\u5e8f\u5217\u5bf9\u6a21\u578b\u6765\u8bf4\u662f\u4fe1\u606f\u566a\u58f0\u3002", "conclusion": "Sci-LLMs\u7684\u4e3b\u8981\u4f18\u52bf\u4e0d\u5728\u4e8e\u4ece\u96f6\u89e3\u91ca\u751f\u7269\u5206\u5b50\u8bed\u6cd5\uff0c\u800c\u5728\u4e8e\u5bf9\u7ed3\u6784\u5316\u3001\u4eba\u7c7b\u53ef\u8bfb\u77e5\u8bc6\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e94\u5c06\u5176\u91cd\u65b0\u5b9a\u4f4d\u4e3a\u4e13\u5bb6\u77e5\u8bc6\u7684\u63a8\u7406\u5f15\u64ce\u3002"}}
{"id": "2510.23234", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23234", "abs": "https://arxiv.org/abs/2510.23234", "authors": ["Klaus Zauner", "Hubert Gattringer", "Andreas Mueller"], "title": "Optimal Dimensioning of Elastic-Link Manipulators regarding Lifetime Estimation", "comment": "Mechanics Based Design of Structures and Machines, December 2024", "summary": "Resourceful operation and design of robots is key for sustainable industrial\nautomation. This will be enabled by lightweight design along with time and\nenergy optimal control of robotic manipulators. Design and control of such\nsystems is intertwined as the control must take into account inherent\nmechanical compliance while the design must accommodate the dynamic\nrequirements demanded by the control. As basis for such design optimization, a\nmethod for estimating the lifetime of elastic link robotic manipulators is\npresented. This is applied to the geometry optimization of flexible serial\nmanipulators performing pick-and-place operations, where the optimization\nobjective is a combination of overall weight and vibration amplitudes. The\nlifetime estimation draws from a fatigue analysis combining the rainflow\ncounting algorithm and the method of critical cutting plane. Tresca hypothesis\nis used to formulate an equivalent stress, and linear damage accumulation is\nassumed. The final robot geometry is selected from a Pareto front as a tradeoff\nof lifetime and vibration characteristic. The method is illustrated for a three\ndegrees of freedom articulated robotic manipulator.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5f39\u6027\u8fde\u6746\u673a\u5668\u4eba\u5bff\u547d\u4f30\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u67d4\u6027\u4e32\u8054\u673a\u68b0\u81c2\u7684\u51e0\u4f55\u8bbe\u8ba1\uff0c\u5e73\u8861\u91cd\u91cf\u3001\u632f\u52a8\u548c\u5bff\u547d\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "motivation": "\u8f7b\u91cf\u5316\u8bbe\u8ba1\u548c\u65f6\u95f4\u80fd\u91cf\u6700\u4f18\u63a7\u5236\u662f\u5b9e\u73b0\u53ef\u6301\u7eed\u5de5\u4e1a\u81ea\u52a8\u5316\u7684\u5173\u952e\uff0c\u9700\u8981\u540c\u65f6\u8003\u8651\u673a\u68b0\u67d4\u6027\u548c\u52a8\u6001\u63a7\u5236\u8981\u6c42\u3002", "method": "\u91c7\u7528\u96e8\u6d41\u8ba1\u6570\u7b97\u6cd5\u548c\u4e34\u754c\u5207\u5272\u5e73\u9762\u6cd5\u8fdb\u884c\u75b2\u52b3\u5206\u6790\uff0c\u4f7f\u7528Tresca\u5047\u8bbe\u6784\u5efa\u7b49\u6548\u5e94\u529b\uff0c\u5047\u8bbe\u7ebf\u6027\u635f\u4f24\u7d2f\u79ef\uff0c\u4ece\u5e15\u7d2f\u6258\u524d\u6cbf\u9009\u62e9\u6700\u4f18\u51e0\u4f55\u3002", "result": "\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u4e09\u81ea\u7531\u5ea6\u5173\u8282\u673a\u5668\u4eba\u7684\u51e0\u4f55\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u91cd\u91cf\u3001\u632f\u52a8\u5e45\u5ea6\u548c\u5bff\u547d\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "\u63d0\u51fa\u7684\u5bff\u547d\u4f30\u8ba1\u65b9\u6cd5\u4e3a\u5f39\u6027\u8fde\u6746\u673a\u5668\u4eba\u7684\u8bbe\u8ba1\u4f18\u5316\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u80fd\u591f\u5b9e\u73b0\u53ef\u6301\u7eed\u7684\u5de5\u4e1a\u81ea\u52a8\u5316\u3002"}}
{"id": "2510.23167", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23167", "abs": "https://arxiv.org/abs/2510.23167", "authors": ["Zhao Yang", "Thomas M. Moerland", "Mike Preuss", "Aske Plaat", "Vincent Fran\u00e7ois-Lavet", "Edward S. Hu"], "title": "Guiding Skill Discovery with Foundation Models", "comment": null, "summary": "Learning diverse skills without hand-crafted reward functions could\naccelerate reinforcement learning in downstream tasks. However, existing skill\ndiscovery methods focus solely on maximizing the diversity of skills without\nconsidering human preferences, which leads to undesirable behaviors and\npossibly dangerous skills. For instance, a cheetah robot trained using previous\nmethods learns to roll in all directions to maximize skill diversity, whereas\nwe would prefer it to run without flipping or entering hazardous areas. In this\nwork, we propose a Foundation model Guided (FoG) skill discovery method, which\nincorporates human intentions into skill discovery through foundation models.\nSpecifically, FoG extracts a score function from foundation models to evaluate\nstates based on human intentions, assigning higher values to desirable states\nand lower to undesirable ones. These scores are then used to re-weight the\nrewards of skill discovery algorithms. By optimizing the re-weighted skill\ndiscovery rewards, FoG successfully learns to eliminate undesirable behaviors,\nsuch as flipping or rolling, and to avoid hazardous areas in both state-based\nand pixel-based tasks. Interestingly, we show that FoG can discover skills\ninvolving behaviors that are difficult to define. Interactive visualisations\nare available from https://sites.google.com/view/submission-fog.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u6280\u80fd\u53d1\u73b0\u65b9\u6cd5FoG\uff0c\u5c06\u4eba\u7c7b\u504f\u597d\u878d\u5165\u6280\u80fd\u53d1\u73b0\u8fc7\u7a0b\uff0c\u907f\u514d\u4ea7\u751f\u5371\u9669\u6216\u4e0d\u671f\u671b\u7684\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u6280\u80fd\u53d1\u73b0\u65b9\u6cd5\u53ea\u5173\u6ce8\u6280\u80fd\u591a\u6837\u6027\u6700\u5927\u5316\uff0c\u4e0d\u8003\u8651\u4eba\u7c7b\u504f\u597d\uff0c\u5bfc\u81f4\u4ea7\u751f\u5371\u9669\u6216\u4e0d\u671f\u671b\u7684\u884c\u4e3a\uff08\u5982\u673a\u5668\u4eba\u7ffb\u6eda\uff09\u3002\u9700\u8981\u5c06\u4eba\u7c7b\u610f\u56fe\u878d\u5165\u6280\u80fd\u53d1\u73b0\u8fc7\u7a0b\u3002", "method": "FoG\u4ece\u57fa\u7840\u6a21\u578b\u4e2d\u63d0\u53d6\u8bc4\u5206\u51fd\u6570\uff0c\u6839\u636e\u4eba\u7c7b\u610f\u56fe\u8bc4\u4f30\u72b6\u6001\uff0c\u4e3a\u671f\u671b\u72b6\u6001\u5206\u914d\u9ad8\u503c\uff0c\u4e0d\u671f\u671b\u72b6\u6001\u5206\u914d\u4f4e\u503c\u3002\u7136\u540e\u7528\u8fd9\u4e9b\u5206\u6570\u91cd\u65b0\u52a0\u6743\u6280\u80fd\u53d1\u73b0\u7b97\u6cd5\u7684\u5956\u52b1\u3002", "result": "FoG\u6210\u529f\u6d88\u9664\u4e86\u4e0d\u671f\u671b\u884c\u4e3a\uff08\u5982\u7ffb\u6eda\uff09\uff0c\u5728\u72b6\u6001\u548c\u50cf\u7d20\u4efb\u52a1\u4e2d\u90fd\u907f\u514d\u4e86\u5371\u9669\u533a\u57df\u3002\u8fd8\u80fd\u53d1\u73b0\u96be\u4ee5\u5b9a\u4e49\u7684\u884c\u4e3a\u6280\u80fd\u3002", "conclusion": "FoG\u65b9\u6cd5\u6709\u6548\u5c06\u4eba\u7c7b\u504f\u597d\u878d\u5165\u6280\u80fd\u53d1\u73b0\uff0c\u907f\u514d\u4e86\u5371\u9669\u884c\u4e3a\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6280\u80fd\u591a\u6837\u6027\u3002"}}
{"id": "2510.23258", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23258", "abs": "https://arxiv.org/abs/2510.23258", "authors": ["Riko Yokozawa", "Kentaro Fujii", "Yuta Nomura", "Shingo Murata"], "title": "Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation", "comment": "Preprint version", "summary": "Autonomous robotic navigation in real-world environments requires exploration\nto acquire environmental information as well as goal-directed navigation in\norder to reach specified targets. Active inference (AIF) based on the\nfree-energy principle provides a unified framework for these behaviors by\nminimizing the expected free energy (EFE), thereby combining epistemic and\nextrinsic values. To realize this practically, we propose a deep AIF framework\nthat integrates a diffusion policy as the policy model and a multiple timescale\nrecurrent state-space model (MTRSSM) as the world model. The diffusion policy\ngenerates diverse candidate actions while the MTRSSM predicts their\nlong-horizon consequences through latent imagination, enabling action selection\nthat minimizes EFE. Real-world navigation experiments demonstrated that our\nframework achieved higher success rates and fewer collisions compared with the\nbaselines, particularly in exploration-demanding scenarios. These results\nhighlight how AIF based on EFE minimization can unify exploration and\ngoal-directed navigation in real-world robotic settings.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u4e3b\u52a8\u63a8\u7406\u7684\u673a\u5668\u4eba\u5bfc\u822a\u6846\u67b6\uff0c\u7ed3\u5408\u6269\u6563\u7b56\u7565\u548c\u591a\u65f6\u95f4\u5c3a\u5ea6\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u671f\u671b\u81ea\u7531\u80fd\u7edf\u4e00\u63a2\u7d22\u548c\u76ee\u6807\u5bfc\u5411\u5bfc\u822a\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u5bfc\u822a\u9700\u8981\u540c\u65f6\u8fdb\u884c\u73af\u5883\u63a2\u7d22\u548c\u76ee\u6807\u5bfc\u5411\u5bfc\u822a\uff0c\u4e3b\u52a8\u63a8\u7406\u6846\u67b6\u57fa\u4e8e\u81ea\u7531\u80fd\u539f\u7406\u80fd\u591f\u7edf\u4e00\u8fd9\u4e24\u79cd\u884c\u4e3a\u3002", "method": "\u96c6\u6210\u6269\u6563\u7b56\u7565\u4f5c\u4e3a\u7b56\u7565\u6a21\u578b\u548c\u591a\u65f6\u95f4\u5c3a\u5ea6\u9012\u5f52\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4f5c\u4e3a\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u6f5c\u5728\u60f3\u8c61\u9884\u6d4b\u52a8\u4f5c\u7684\u957f\u671f\u540e\u679c\uff0c\u9009\u62e9\u6700\u5c0f\u5316\u671f\u671b\u81ea\u7531\u80fd\u7684\u52a8\u4f5c\u3002", "result": "\u771f\u5b9e\u4e16\u754c\u5bfc\u822a\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6210\u529f\u7387\u548c\u66f4\u5c11\u7684\u78b0\u649e\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u63a2\u7d22\u7684\u573a\u666f\u4e2d\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "\u57fa\u4e8e\u671f\u671b\u81ea\u7531\u80fd\u6700\u5c0f\u5316\u7684\u4e3b\u52a8\u63a8\u7406\u80fd\u591f\u6709\u6548\u7edf\u4e00\u73b0\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u73af\u5883\u4e2d\u7684\u63a2\u7d22\u548c\u76ee\u6807\u5bfc\u5411\u5bfc\u822a\u3002"}}
{"id": "2510.23214", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23214", "abs": "https://arxiv.org/abs/2510.23214", "authors": ["Robin Schm\u00f6cker", "Alexander Dockhorn", "Bodo Rosenhahn"], "title": "AUPO -- Abstracted Until Proven Otherwise: A Reward Distribution Based Abstraction Algorithm", "comment": null, "summary": "We introduce a novel, drop-in modification to Monte Carlo Tree Search's\n(MCTS) decision policy that we call AUPO. Comparisons based on a range of IPPC\nbenchmark problems show that AUPO clearly outperforms MCTS. AUPO is an\nautomatic action abstraction algorithm that solely relies on reward\ndistribution statistics acquired during the MCTS. Thus, unlike other automatic\nabstraction algorithms, AUPO requires neither access to transition\nprobabilities nor does AUPO require a directed acyclic search graph to build\nits abstraction, allowing AUPO to detect symmetric actions that\nstate-of-the-art frameworks like ASAP struggle with when the resulting\nsymmetric states are far apart in state space. Furthermore, as AUPO only\naffects the decision policy, it is not mutually exclusive with other\nabstraction techniques that only affect the tree search.", "AI": {"tldr": "AUPO\u662fMCTS\u51b3\u7b56\u7b56\u7565\u7684\u6539\u8fdb\u7b97\u6cd5\uff0c\u4ec5\u4f9d\u8d56\u5956\u52b1\u5206\u5e03\u7edf\u8ba1\u81ea\u52a8\u8fdb\u884c\u52a8\u4f5c\u62bd\u8c61\uff0c\u65e0\u9700\u8f6c\u79fb\u6982\u7387\u6216DAG\u641c\u7d22\u56fe\uff0c\u80fd\u68c0\u6d4b\u5bf9\u79f0\u52a8\u4f5c\uff0c\u5728IPPC\u57fa\u51c6\u95ee\u9898\u4e0a\u660e\u663e\u4f18\u4e8eMCTS\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u81ea\u52a8\u62bd\u8c61\u7b97\u6cd5\u9700\u8981\u8f6c\u79fb\u6982\u7387\u6216DAG\u641c\u7d22\u56fe\u7684\u9650\u5236\uff0c\u4ee5\u53caASAP\u7b49\u6846\u67b6\u96be\u4ee5\u68c0\u6d4b\u72b6\u6001\u7a7a\u95f4\u4e2d\u76f8\u8ddd\u8f83\u8fdc\u7684\u5bf9\u79f0\u72b6\u6001\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8eMCTS\u8fc7\u7a0b\u4e2d\u6536\u96c6\u7684\u5956\u52b1\u5206\u5e03\u7edf\u8ba1\uff0c\u5f00\u53d1\u81ea\u52a8\u52a8\u4f5c\u62bd\u8c61\u7b97\u6cd5AUPO\uff0c\u4ec5\u4fee\u6539\u51b3\u7b56\u7b56\u7565\u800c\u4e0d\u5f71\u54cd\u6811\u641c\u7d22\u3002", "result": "\u5728IPPC\u57fa\u51c6\u95ee\u9898\u4e0a\u7684\u6bd4\u8f83\u663e\u793aAUPO\u660e\u663e\u4f18\u4e8e\u6807\u51c6MCTS\uff0c\u80fd\u6709\u6548\u68c0\u6d4b\u5bf9\u79f0\u52a8\u4f5c\u3002", "conclusion": "AUPO\u662f\u4e00\u79cd\u6709\u6548\u7684\u81ea\u52a8\u52a8\u4f5c\u62bd\u8c61\u65b9\u6cd5\uff0c\u4e0e\u5176\u4ed6\u4ec5\u5f71\u54cd\u6811\u641c\u7d22\u7684\u62bd\u8c61\u6280\u672f\u517c\u5bb9\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.23286", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23286", "abs": "https://arxiv.org/abs/2510.23286", "authors": ["Jin Huang", "Yingqiang Wang", "Haoda Li", "Zichen Liu", "Zhikun Wang", "Ying Chen"], "title": "Precise Time Delay Measurement and Compensation for Tightly Coupled Underwater SINS/piUSBL Navigation", "comment": null, "summary": "In multi-sensor systems, time synchronization between sensors is a\nsignificant challenge, and this issue is particularly pronounced in underwater\nintegrated navigation systems incorporating acoustic positioning. Such systems\nare highly susceptible to time delay, which can significantly degrade accuracy\nwhen measurement and fusion moments are misaligned. To address this challenge,\nthis paper introduces a tightly coupled navigation framework that integrates a\npassive inverted ultra-short baseline (piUSBL) acoustic positioning system, a\nstrapdown inertial navigation system (SINS), and a depth gauge under precise\ntime synchronization. The framework fuses azimuth and slant range from the\npiUSBL with depth data, thereby avoiding poor vertical-angle observability in\nplanar arrays. A novel delay measurement strategy is introduced, combining\nsynchronized timing with acoustic signal processing, which redefines\ndelay-traditionally an unobservable error-into a quantifiable parameter,\nenabling explicit estimation of both acoustic propagation and system processing\ndelays. Simulations and field experiments confirm the feasibility of the\nproposed method, with delay-compensated navigation reducing RMSE by 40.45% and\nmaximum error by 32.55%. These findings show that precise delay measurement and\ncompensation not only enhance underwater navigation accuracy but also establish\na generalizable framework for acoustic positioning integration, offering\nvaluable insights into time alignment and data fusion in latency-sensitive\nmulti-sensor systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7d27\u5bc6\u8026\u5408\u7684\u6c34\u4e0b\u5bfc\u822a\u6846\u67b6\uff0c\u5c06\u88ab\u52a8\u5012\u7f6e\u8d85\u77ed\u57fa\u7ebf\u58f0\u5b66\u5b9a\u4f4d\u7cfb\u7edf\u3001\u6377\u8054\u60ef\u6027\u5bfc\u822a\u7cfb\u7edf\u548c\u6df1\u5ea6\u8ba1\u5728\u7cbe\u786e\u65f6\u95f4\u540c\u6b65\u4e0b\u96c6\u6210\uff0c\u901a\u8fc7\u5c06\u65f6\u95f4\u5ef6\u8fdf\u91cd\u65b0\u5b9a\u4e49\u4e3a\u53ef\u91cf\u5316\u53c2\u6570\u6765\u663e\u8457\u63d0\u9ad8\u5bfc\u822a\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3\u591a\u4f20\u611f\u5668\u7cfb\u7edf\u4e2d\u65f6\u95f4\u540c\u6b65\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5305\u542b\u58f0\u5b66\u5b9a\u4f4d\u7684\u6c34\u4e0b\u96c6\u6210\u5bfc\u822a\u7cfb\u7edf\u4e2d\uff0c\u65f6\u95f4\u5ef6\u8fdf\u4f1a\u663e\u8457\u964d\u4f4e\u6d4b\u91cf\u548c\u878d\u5408\u65f6\u523b\u4e0d\u5bf9\u9f50\u65f6\u7684\u7cbe\u5ea6\u3002", "method": "\u5f15\u5165\u7d27\u5bc6\u8026\u5408\u5bfc\u822a\u6846\u67b6\uff0c\u878d\u5408piUSBL\u7684\u65b9\u4f4d\u89d2\u548c\u659c\u8ddd\u4e0e\u6df1\u5ea6\u6570\u636e\uff0c\u907f\u514d\u5e73\u9762\u9635\u5217\u5782\u76f4\u89d2\u5ea6\u53ef\u89c2\u6d4b\u6027\u5dee\u7684\u95ee\u9898\uff1b\u63d0\u51fa\u65b0\u7684\u5ef6\u8fdf\u6d4b\u91cf\u7b56\u7565\uff0c\u7ed3\u5408\u540c\u6b65\u5b9a\u65f6\u548c\u58f0\u4fe1\u53f7\u5904\u7406\uff0c\u5c06\u5ef6\u8fdf\u91cd\u65b0\u5b9a\u4e49\u4e3a\u53ef\u91cf\u5316\u53c2\u6570\u3002", "result": "\u4eff\u771f\u548c\u73b0\u573a\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u5ef6\u8fdf\u8865\u507f\u5bfc\u822a\u4f7fRMSE\u964d\u4f4e\u4e8640.45%\uff0c\u6700\u5927\u8bef\u5dee\u964d\u4f4e\u4e8632.55%\u3002", "conclusion": "\u7cbe\u786e\u7684\u5ef6\u8fdf\u6d4b\u91cf\u548c\u8865\u507f\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6c34\u4e0b\u5bfc\u822a\u7cbe\u5ea6\uff0c\u8fd8\u4e3a\u58f0\u5b66\u5b9a\u4f4d\u96c6\u6210\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u63a8\u5e7f\u7684\u6846\u67b6\uff0c\u4e3a\u5ef6\u8fdf\u654f\u611f\u7684\u591a\u4f20\u611f\u5668\u7cfb\u7edf\u4e2d\u7684\u65f6\u95f4\u5bf9\u9f50\u548c\u6570\u636e\u878d\u5408\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2510.23216", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23216", "abs": "https://arxiv.org/abs/2510.23216", "authors": ["Alessandro Sestini", "Joakim Bergdahl", "Jean-Philippe Barrette-LaPierre", "Florian Fuchs", "Brady Chen", "Micheal Jones", "Linus Gissl\u00e9n"], "title": "Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach", "comment": null, "summary": "While several high profile video games have served as testbeds for Deep\nReinforcement Learning (DRL), this technique has rarely been employed by the\ngame industry for crafting authentic AI behaviors. Previous research focuses on\ntraining super-human agents with large models, which is impractical for game\nstudios with limited resources aiming for human-like agents. This paper\nproposes a sample-efficient DRL method tailored for training and fine-tuning\nagents in industrial settings such as the video game industry. Our method\nimproves sample efficiency of value-based DRL by leveraging pre-collected data\nand increasing network plasticity. We evaluate our method training a goalkeeper\nagent in EA SPORTS FC 25, one of the best-selling football simulations today.\nOur agent outperforms the game's built-in AI by 10% in ball saving rate.\nAblation studies show that our method trains agents 50% faster compared to\nstandard DRL methods. Finally, qualitative evaluation from domain experts\nindicates that our approach creates more human-like gameplay compared to\nhand-crafted agents. As a testimony of the impact of the approach, the method\nis intended to replace the hand-crafted counterpart in next iterations of the\nseries.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6e38\u620f\u5de5\u4e1a\u73af\u5883\u7684\u6837\u672c\u9ad8\u6548\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728EA SPORTS FC 25\u4e2d\u8bad\u7ec3\u5b88\u95e8\u5458\u667a\u80fd\u4f53\uff0c\u6027\u80fd\u8d85\u8d8a\u6e38\u620f\u5185\u7f6eAI 10%\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u534750%\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u8bad\u7ec3\u8d85\u4eba\u7ea7\u667a\u80fd\u4f53\uff0c\u4f46\u6e38\u620f\u884c\u4e1a\u9700\u8981\u7684\u662f\u4eba\u7c7b\u6c34\u5e73\u7684\u667a\u80fd\u4f53\uff0c\u4e14\u8d44\u6e90\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u9002\u5408\u5de5\u4e1a\u73af\u5883\u7684\u6837\u672c\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5229\u7528\u9884\u6536\u96c6\u6570\u636e\u548c\u589e\u52a0\u7f51\u7edc\u53ef\u5851\u6027\uff0c\u6539\u8fdb\u4e86\u57fa\u4e8e\u4ef7\u503c\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u6837\u672c\u6548\u7387\u3002", "result": "\u5728EA SPORTS FC 25\u4e2d\u8bad\u7ec3\u7684\u5b88\u95e8\u5458\u667a\u80fd\u4f53\u6bd4\u6e38\u620f\u5185\u7f6eAI\u7684\u6551\u7403\u7387\u9ad8\u51fa10%\uff0c\u8bad\u7ec3\u901f\u5ea6\u6bd4\u6807\u51c6\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5feb50%\uff0c\u9886\u57df\u4e13\u5bb6\u5b9a\u6027\u8bc4\u4f30\u663e\u793a\u8be5\u65b9\u6cd5\u521b\u9020\u4e86\u66f4\u63a5\u8fd1\u4eba\u7c7b\u73a9\u5bb6\u7684\u6e38\u620f\u4f53\u9a8c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5df2\u88ab\u8bc1\u660e\u6709\u6548\uff0c\u8ba1\u5212\u5728\u4e0b\u4e00\u4ee3\u6e38\u620f\u7cfb\u5217\u4e2d\u66ff\u4ee3\u624b\u5de5\u5236\u4f5c\u7684\u667a\u80fd\u4f53\uff0c\u5c55\u793a\u4e86\u5176\u5728\u6e38\u620f\u5de5\u4e1a\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.23329", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23329", "abs": "https://arxiv.org/abs/2510.23329", "authors": ["Shreya Santra", "Thomas Robbins", "Kazuya Yoshida"], "title": "Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon", "comment": "6 pages, 7 figures. Accepted at IEEE iSpaRo 2025", "summary": "Autonomous navigation in unstructured environments is essential for field and\nplanetary robotics, where robots must efficiently reach goals while avoiding\nobstacles under uncertain conditions. Conventional algorithmic approaches often\nrequire extensive environment-specific tuning, limiting scalability to new\ndomains. Deep Reinforcement Learning (DRL) provides a data-driven alternative,\nallowing robots to acquire navigation strategies through direct interactions\nwith their environment. This work investigates the feasibility of DRL policy\ngeneralization across visually and topographically distinct simulated domains,\nwhere policies are trained in terrestrial settings and validated in a zero-shot\nmanner in extraterrestrial environments. A 3D simulation of an agricultural\nrover is developed and trained using Proximal Policy Optimization (PPO) to\nachieve goal-directed navigation and obstacle avoidance in farmland settings.\nThe learned policy is then evaluated in a lunar-like simulated environment to\nassess transfer performance. The results indicate that policies trained under\nterrestrial conditions retain a high level of effectiveness, achieving close to\n50\\% success in lunar simulations without the need for additional training and\nfine-tuning. This underscores the potential of cross-domain DRL-based policy\ntransfer as a promising approach to developing adaptable and efficient\nautonomous navigation for future planetary exploration missions, with the added\nbenefit of minimizing retraining costs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u5728\u89c6\u89c9\u548c\u5730\u5f62\u7279\u5f81\u4e0d\u540c\u7684\u6a21\u62df\u57df\u4e4b\u95f4\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5c06\u519c\u4e1a\u73af\u5883\u8bad\u7ec3\u7684\u5bfc\u822a\u7b56\u7565\u76f4\u63a5\u5e94\u7528\u4e8e\u6708\u7403\u73af\u5883\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u8fbe\u5230\u8fd150%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u89e3\u51b3\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u81ea\u4e3b\u5bfc\u822a\u7684\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u73af\u5883\u7279\u5b9a\u8c03\u4f18\uff0c\u9650\u5236\u4e86\u5728\u65b0\u9886\u57df\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u5f00\u53d13D\u519c\u4e1a\u6f2b\u6e38\u8f66\u6a21\u62df\u5668\uff0c\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u8bad\u7ec3\u76ee\u6807\u5bfc\u5411\u5bfc\u822a\u548c\u907f\u969c\u7b56\u7565\uff0c\u7136\u540e\u5728\u6708\u7403\u6a21\u62df\u73af\u5883\u4e2d\u8fdb\u884c\u96f6\u6837\u672c\u9a8c\u8bc1\u3002", "result": "\u5728\u6708\u7403\u6a21\u62df\u73af\u5883\u4e2d\uff0c\u4ec5\u5728\u9646\u5730\u6761\u4ef6\u4e0b\u8bad\u7ec3\u7684\u7b56\u7565\u4fdd\u6301\u4e86\u9ad8\u5ea6\u6709\u6548\u6027\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u548c\u5fae\u8c03\u5373\u53ef\u8fbe\u5230\u8fd150%\u7684\u6210\u529f\u7387\u3002", "conclusion": "\u8de8\u57dfDRL\u7b56\u7565\u8fc1\u79fb\u4e3a\u672a\u6765\u884c\u661f\u63a2\u7d22\u4efb\u52a1\u5f00\u53d1\u9002\u5e94\u6027\u5f3a\u7684\u81ea\u4e3b\u5bfc\u822a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u518d\u8bad\u7ec3\u6210\u672c\u3002"}}
{"id": "2510.23221", "categories": ["cs.AI", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.23221", "abs": "https://arxiv.org/abs/2510.23221", "authors": ["Hong Wang", "Wenkai Yang", "Jie Wang", "Huanshuo Dong", "Zijie Geng", "Zhen Huang", "Depeng Xie", "Zhezheng Hao", "Hande Dong"], "title": "Accelerating IC Thermal Simulation Data Generation via Block Krylov and Operator Action", "comment": null, "summary": "Recent advances in data-driven approaches, such as neural operators (NOs),\nhave shown substantial efficacy in reducing the solution time for integrated\ncircuit (IC) thermal simulations. However, a limitation of these approaches is\nrequiring a large amount of high-fidelity training data, such as chip\nparameters and temperature distributions, thereby incurring significant\ncomputational costs. To address this challenge, we propose a novel algorithm\nfor the generation of IC thermal simulation data, named block Krylov and\noperator action (BlocKOA), which simultaneously accelerates the data generation\nprocess and enhances the precision of generated data. BlocKOA is specifically\ndesigned for IC applications. Initially, we use the block Krylov algorithm\nbased on the structure of the heat equation to quickly obtain a few basic\nsolutions. Then we combine them to get numerous temperature distributions that\nsatisfy the physical constraints. Finally, we apply heat operators on these\nfunctions to determine the heat source distributions, efficiently generating\nprecise data points. Theoretical analysis shows that the time complexity of\nBlocKOA is one order lower than the existing method. Experimental results\nfurther validate its efficiency, showing that BlocKOA achieves a 420-fold\nspeedup in generating thermal simulation data for 5000 chips with varying\nphysical parameters and IC structures. Even with just 4% of the generation\ntime, data-driven approaches trained on the data generated by BlocKOA exhibits\ncomparable performance to that using the existing method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBlocKOA\u7684\u65b0\u578b\u96c6\u6210\u7535\u8def\u70ed\u4eff\u771f\u6570\u636e\u751f\u6210\u7b97\u6cd5\uff0c\u901a\u8fc7\u5757Krylov\u65b9\u6cd5\u548c\u7b97\u5b50\u4f5c\u7528\u540c\u65f6\u52a0\u901f\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u5e76\u63d0\u9ad8\u6570\u636e\u7cbe\u5ea6\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u4e86420\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff08\u5982\u795e\u7ecf\u7b97\u5b50\uff09\u9700\u8981\u5927\u91cf\u9ad8\u4fdd\u771f\u8bad\u7ec3\u6570\u636e\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u4e14\u7cbe\u786e\u7684\u6570\u636e\u751f\u6210\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e00\u9650\u5236\u3002", "method": "BlocKOA\u7b97\u6cd5\u9996\u5148\u57fa\u4e8e\u70ed\u65b9\u7a0b\u7ed3\u6784\u4f7f\u7528\u5757Krylov\u7b97\u6cd5\u5feb\u901f\u83b7\u53d6\u5c11\u91cf\u57fa\u672c\u89e3\uff0c\u7136\u540e\u7ec4\u5408\u8fd9\u4e9b\u89e3\u5f97\u5230\u6ee1\u8db3\u7269\u7406\u7ea6\u675f\u7684\u591a\u79cd\u6e29\u5ea6\u5206\u5e03\uff0c\u6700\u540e\u5bf9\u8fd9\u4e9b\u51fd\u6570\u5e94\u7528\u70ed\u7b97\u5b50\u6765\u786e\u5b9a\u70ed\u6e90\u5206\u5e03\uff0c\u4ece\u800c\u9ad8\u6548\u751f\u6210\u7cbe\u786e\u6570\u636e\u70b9\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793aBlocKOA\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u6bd4\u73b0\u6709\u65b9\u6cd5\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6548\u7387\uff0c\u5728\u751f\u62105000\u4e2a\u5177\u6709\u4e0d\u540c\u7269\u7406\u53c2\u6570\u548cIC\u7ed3\u6784\u82af\u7247\u7684\u70ed\u4eff\u771f\u6570\u636e\u65f6\u5b9e\u73b0\u4e86420\u500d\u52a0\u901f\uff0c\u4ec5\u75284%\u7684\u751f\u6210\u65f6\u95f4\u5c31\u80fd\u8bad\u7ec3\u51fa\u4e0e\u73b0\u6709\u65b9\u6cd5\u6027\u80fd\u76f8\u5f53\u7684\u6570\u636e\u9a71\u52a8\u6a21\u578b\u3002", "conclusion": "BlocKOA\u662f\u4e00\u79cd\u4e13\u95e8\u4e3aIC\u5e94\u7528\u8bbe\u8ba1\u7684\u9ad8\u6548\u6570\u636e\u751f\u6210\u7b97\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u70ed\u4eff\u771f\u6570\u636e\u7684\u751f\u6210\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6570\u636e\u8d28\u91cf\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.23357", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23357", "abs": "https://arxiv.org/abs/2510.23357", "authors": ["Shaohan Bian", "Ying Zhang", "Guohui Tian", "Zhiqiang Miao", "Edmond Q. Wu", "Simon X. Yang", "Changchun Hua"], "title": "Large language model-based task planning for service robots: A review", "comment": "Submitted to Biomimetic Intelligence and Robotics for possible\n  publication", "summary": "With the rapid advancement of large language models (LLMs) and robotics,\nservice robots are increasingly becoming an integral part of daily life,\noffering a wide range of services in complex environments. To deliver these\nservices intelligently and efficiently, robust and accurate task planning\ncapabilities are essential. This paper presents a comprehensive overview of the\nintegration of LLMs into service robotics, with a particular focus on their\nrole in enhancing robotic task planning. First, the development and\nfoundational techniques of LLMs, including pre-training, fine-tuning,\nretrieval-augmented generation (RAG), and prompt engineering, are reviewed. We\nthen explore the application of LLMs as the cognitive core-`brain'-of service\nrobots, discussing how LLMs contribute to improved autonomy and\ndecision-making. Furthermore, recent advancements in LLM-driven task planning\nacross various input modalities are analyzed, including text, visual, audio,\nand multimodal inputs. Finally, we summarize key challenges and limitations in\ncurrent research and propose future directions to advance the task planning\ncapabilities of service robots in complex, unstructured domestic environments.\nThis review aims to serve as a valuable reference for researchers and\npractitioners in the fields of artificial intelligence and robotics.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u670d\u52a1\u673a\u5668\u4eba\u4efb\u52a1\u89c4\u5212\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ecLLM\u6280\u672f\u57fa\u7840\u3001\u4f5c\u4e3a\u673a\u5668\u4eba\"\u5927\u8111\"\u7684\u4f5c\u7528\u3001\u591a\u6a21\u6001\u8f93\u5165\u4e0b\u7684\u4efb\u52a1\u89c4\u5212\u8fdb\u5c55\uff0c\u4ee5\u53ca\u5f53\u524d\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u548c\u673a\u5668\u4eba\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u670d\u52a1\u673a\u5668\u4eba\u9700\u8981\u66f4\u667a\u80fd\u9ad8\u6548\u7684\u4efb\u52a1\u89c4\u5212\u80fd\u529b\u6765\u5e94\u5bf9\u590d\u6742\u73af\u5883\u4e2d\u7684\u591a\u6837\u5316\u670d\u52a1\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790LLM\u7684\u57fa\u7840\u6280\u672f\uff08\u9884\u8bad\u7ec3\u3001\u5fae\u8c03\u3001RAG\u3001\u63d0\u793a\u5de5\u7a0b\uff09\u53ca\u5176\u5728\u670d\u52a1\u673a\u5668\u4eba\u4efb\u52a1\u89c4\u5212\u4e2d\u7684\u5e94\u7528\uff0c\u6db5\u76d6\u6587\u672c\u3001\u89c6\u89c9\u3001\u97f3\u9891\u548c\u591a\u6a21\u6001\u8f93\u5165\u573a\u666f\u3002", "result": "LLM\u80fd\u591f\u4f5c\u4e3a\u670d\u52a1\u673a\u5668\u4eba\u7684\u8ba4\u77e5\u6838\u5fc3\uff0c\u663e\u8457\u63d0\u5347\u81ea\u4e3b\u6027\u548c\u51b3\u7b56\u80fd\u529b\uff0c\u5728\u591a\u6a21\u6001\u4efb\u52a1\u89c4\u5212\u65b9\u9762\u53d6\u5f97\u91cd\u8981\u8fdb\u5c55\u3002", "conclusion": "\u5f53\u524d\u7814\u7a76\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63a8\u8fdb\u590d\u6742\u975e\u7ed3\u6784\u5316\u5bb6\u5ead\u73af\u5883\u4e2d\u670d\u52a1\u673a\u5668\u4eba\u7684\u4efb\u52a1\u89c4\u5212\u80fd\u529b\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u548c\u673a\u5668\u4eba\u9886\u57df\u7814\u7a76\u8005\u63d0\u4f9b\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2510.23304", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23304", "abs": "https://arxiv.org/abs/2510.23304", "authors": ["Riccardo Romanello", "Daniele Lizzio Bosco", "Jacopo Cossio", "Dusan Sutulovic", "Giuseppe Serra", "Carla Piazza", "Paolo Burelli"], "title": "CNOT Minimal Circuit Synthesis: A Reinforcement Learning Approach", "comment": null, "summary": "CNOT gates are fundamental to quantum computing, as they facilitate\nentanglement, a crucial resource for quantum algorithms. Certain classes of\nquantum circuits are constructed exclusively from CNOT gates. Given their\nwidespread use, it is imperative to minimise the number of CNOT gates employed.\nThis problem, known as CNOT minimisation, remains an open challenge, with its\ncomputational complexity yet to be fully characterised. In this work, we\nintroduce a novel reinforcement learning approach to address this task. Instead\nof training multiple reinforcement learning agents for different circuit sizes,\nwe use a single agent up to a fixed size $m$. Matrices of sizes different from\nm are preprocessed using either embedding or Gaussian striping. To assess the\nefficacy of our approach, we trained an agent with m = 8, and evaluated it on\nmatrices of size n that range from 3 to 15. The results we obtained show that\nour method overperforms the state-of-the-art algorithm as the value of n\nincreases.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684CNOT\u95e8\u6700\u5c0f\u5316\u65b9\u6cd5\uff0c\u4f7f\u7528\u5355\u4e00\u667a\u80fd\u4f53\u5904\u7406\u4e0d\u540c\u5c3a\u5bf8\u7684\u91cf\u5b50\u7535\u8def\uff0c\u5728\u8f83\u5927\u7535\u8def\u5c3a\u5bf8\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u7b97\u6cd5\u3002", "motivation": "CNOT\u95e8\u662f\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u57fa\u672c\u7ec4\u4ef6\uff0c\u7528\u4e8e\u4ea7\u751f\u7ea0\u7f20\u3002\u51cf\u5c11CNOT\u95e8\u6570\u91cf\u5bf9\u91cf\u5b50\u7b97\u6cd5\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46CNOT\u6700\u5c0f\u5316\u95ee\u9898\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\uff0c\u5176\u8ba1\u7b97\u590d\u6742\u6027\u5c1a\u672a\u5b8c\u5168\u8868\u5f81\u3002", "method": "\u4f7f\u7528\u5355\u4e00\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5904\u7406\u56fa\u5b9a\u5c3a\u5bf8m\u7684\u7535\u8def\uff0c\u5bf9\u4e8e\u4e0d\u540c\u5c3a\u5bf8\u7684\u77e9\u9635\u91c7\u7528\u5d4c\u5165\u6216\u9ad8\u65af\u6761\u7eb9\u5316\u8fdb\u884c\u9884\u5904\u7406\u3002\u8bad\u7ec3\u4e86m=8\u7684\u667a\u80fd\u4f53\uff0c\u5e76\u5728n=3\u523015\u7684\u77e9\u9635\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8be5\u65b9\u6cd5\u5728n\u503c\u589e\u5927\u65f6\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u7b97\u6cd5\uff0c\u8868\u660e\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u8f83\u5927\u7535\u8def\u5c3a\u5bf8\u4e0a\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u4e3aCNOT\u95e8\u6700\u5c0f\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u8f83\u5927\u5c3a\u5bf8\u91cf\u5b50\u7535\u8def\u65f6\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.23359", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23359", "abs": "https://arxiv.org/abs/2510.23359", "authors": ["Chungeng Tian", "Ning Hao", "Fenghua He"], "title": "T-ESKF: Transformed Error-State Kalman Filter for Consistent Visual-Inertial Navigation", "comment": "This paper was submitted to IEEE RA-L on July 14, 2024, and accepted\n  on December 18, 2024. This version serves as the 'plus edition' of the\n  accepted paper, incorporating supplementary materials for completeness", "summary": "This paper presents a novel approach to address the inconsistency problem\ncaused by observability mismatch in visual-inertial navigation systems (VINS).\nThe key idea involves applying a linear time-varying transformation to the\nerror-state within the Error-State Kalman Filter (ESKF). This transformation\nensures that \\textrr{the unobservable subspace of the transformed error-state\nsystem} becomes independent of the state, thereby preserving the correct\nobservability of the transformed system against variations in linearization\npoints. We introduce the Transformed ESKF (T-ESKF), a consistent VINS estimator\nthat performs state estimation using the transformed error-state system.\nFurthermore, we develop an efficient propagation technique to accelerate the\ncovariance propagation based on the transformation relationship between the\ntransition and accumulated matrices of T-ESKF and ESKF. We validate the\nproposed method through extensive simulations and experiments, demonstrating\nbetter (or competitive at least) performance compared to state-of-the-art\nmethods. The code is available at github.com/HITCSC/T-ESKF.", "AI": {"tldr": "\u63d0\u51faTransformed ESKF (T-ESKF)\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ebf\u6027\u65f6\u53d8\u53d8\u6362\u89e3\u51b3\u89c6\u89c9\u60ef\u6027\u5bfc\u822a\u7cfb\u7edf\u4e2d\u7684\u53ef\u89c2\u6d4b\u6027\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u786e\u4fdd\u7cfb\u7edf\u4e00\u81f4\u6027\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u89c6\u89c9\u60ef\u6027\u5bfc\u822a\u7cfb\u7edf(VINS)\u4e2d\u7531\u53ef\u89c2\u6d4b\u6027\u4e0d\u5339\u914d\u5f15\u8d77\u7684\u7cfb\u7edf\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u8fd9\u662f\u5f71\u54cd\u6ee4\u6ce2\u5668\u6027\u80fd\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u5728\u8bef\u5dee\u72b6\u6001\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668(ESKF)\u4e2d\u5e94\u7528\u7ebf\u6027\u65f6\u53d8\u53d8\u6362\u5230\u8bef\u5dee\u72b6\u6001\uff0c\u4f7f\u53d8\u6362\u540e\u8bef\u5dee\u72b6\u6001\u7cfb\u7edf\u7684\u4e0d\u53ef\u89c2\u6d4b\u5b50\u7a7a\u95f4\u4e0e\u72b6\u6001\u65e0\u5173\uff0c\u4ece\u800c\u4fdd\u6301\u6b63\u786e\u7684\u53ef\u89c2\u6d4b\u6027\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u4eff\u771f\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u5c55\u73b0\u51fa\u66f4\u597d\u6216\u81f3\u5c11\u76f8\u5f53\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "T-ESKF\u662f\u4e00\u79cd\u4e00\u81f4\u7684VINS\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u53d8\u6362\u8bef\u5dee\u72b6\u6001\u7cfb\u7edf\u5b9e\u73b0\u72b6\u6001\u4f30\u8ba1\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u534f\u65b9\u5dee\u4f20\u64ad\u6280\u672f\u6765\u52a0\u901f\u8ba1\u7b97\u3002"}}
{"id": "2510.23340", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.23340", "abs": "https://arxiv.org/abs/2510.23340", "authors": ["Anwesha Das", "John Duff", "J\u00f6rg Hoffmann", "Vera Demberg"], "title": "Planning Ahead with RSA: Efficient Signalling in Dynamic Environments by Projecting User Awareness across Future Timesteps", "comment": "11 pages, 3 figures", "summary": "Adaptive agent design offers a way to improve human-AI collaboration on\ntime-sensitive tasks in rapidly changing environments. In such cases, to ensure\nthe human maintains an accurate understanding of critical task elements, an\nassistive agent must not only identify the highest priority information but\nalso estimate how and when this information can be communicated most\neffectively, given that human attention represents a zero-sum cognitive\nresource where focus on one message diminishes awareness of other or upcoming\ninformation. We introduce a theoretical framework for adaptive signalling which\nmeets these challenges by using principles of rational communication,\nformalised as Bayesian reference resolution using the Rational Speech Act (RSA)\nmodelling framework, to plan a sequence of messages which optimise timely\nalignment between user belief and a dynamic environment. The agent adapts\nmessage specificity and timing to the particulars of a user and scenario based\non projections of how prior-guided interpretation of messages will influence\nattention to the interface and subsequent belief update, across several\ntimesteps out to a fixed horizon. In a comparison to baseline methods, we show\nthat this effectiveness depends crucially on combining multi-step planning with\na realistic model of user awareness. As the first application of RSA for\ncommunication in a dynamic environment, and for human-AI interaction in\ngeneral, we establish theoretical foundations for pragmatic communication in\nhuman-agent teams, highlighting how insights from cognitive science can be\ncapitalised to inform the design of assistive agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7406\u6027\u6c9f\u901a\u539f\u5219\u7684\u81ea\u9002\u5e94\u4fe1\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6b65\u89c4\u5212\u4f18\u5316\u4eba\u673a\u534f\u4f5c\u4e2d\u7684\u4fe1\u606f\u4f20\u9012\u65f6\u673a\u548c\u7279\u5f02\u6027\uff0c\u4ee5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4fdd\u6301\u7528\u6237\u4fe1\u5ff5\u4e0e\u73af\u5883\u7684\u53ca\u65f6\u5bf9\u9f50\u3002", "motivation": "\u5728\u5feb\u901f\u53d8\u5316\u7684\u73af\u5883\u4e2d\uff0c\u8f85\u52a9\u667a\u80fd\u4f53\u9700\u8981\u8bc6\u522b\u6700\u9ad8\u4f18\u5148\u7ea7\u4fe1\u606f\uff0c\u5e76\u4f30\u8ba1\u5982\u4f55\u6700\u6709\u6548\u5730\u6c9f\u901a\u8fd9\u4e9b\u4fe1\u606f\uff0c\u56e0\u4e3a\u4eba\u7c7b\u6ce8\u610f\u529b\u662f\u96f6\u548c\u8ba4\u77e5\u8d44\u6e90\uff0c\u5173\u6ce8\u4e00\u4e2a\u4fe1\u606f\u4f1a\u964d\u4f4e\u5bf9\u5176\u4ed6\u4fe1\u606f\u7684\u611f\u77e5\u3002", "method": "\u4f7f\u7528\u8d1d\u53f6\u65af\u53c2\u8003\u89e3\u6790\u548c\u7406\u6027\u8a00\u8bed\u884c\u4e3a(RSA)\u5efa\u6a21\u6846\u67b6\uff0c\u89c4\u5212\u6d88\u606f\u5e8f\u5217\uff0c\u6839\u636e\u7528\u6237\u548c\u573a\u666f\u7279\u70b9\u81ea\u9002\u5e94\u8c03\u6574\u6d88\u606f\u7279\u5f02\u6027\u548c\u65f6\u673a\uff0c\u57fa\u4e8e\u5bf9\u6d88\u606f\u89e3\u91ca\u5982\u4f55\u5f71\u54cd\u754c\u9762\u6ce8\u610f\u529b\u548c\u4fe1\u5ff5\u66f4\u65b0\u7684\u591a\u6b65\u9884\u6d4b\u3002", "result": "\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u6bd4\u8f83\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u7684\u6548\u679c\u5173\u952e\u4f9d\u8d56\u4e8e\u5c06\u591a\u6b65\u89c4\u5212\u4e0e\u73b0\u5b9e\u7684\u7528\u6237\u610f\u8bc6\u6a21\u578b\u76f8\u7ed3\u5408\u3002", "conclusion": "\u8fd9\u662fRSA\u5728\u52a8\u6001\u73af\u5883\u901a\u4fe1\u548c\u4eba\u7c7b-AI\u4ea4\u4e92\u4e2d\u7684\u9996\u6b21\u5e94\u7528\uff0c\u4e3a\u4eba\u7c7b-\u667a\u80fd\u4f53\u56e2\u961f\u7684\u8bed\u7528\u6c9f\u901a\u5efa\u7acb\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u8ba4\u77e5\u79d1\u5b66\u89c1\u89e3\u5982\u4f55\u6307\u5bfc\u8f85\u52a9\u667a\u80fd\u4f53\u8bbe\u8ba1\u3002"}}
{"id": "2510.23386", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23386", "abs": "https://arxiv.org/abs/2510.23386", "authors": ["Alvaro Paz", "Mahdi Hejrati", "Pauli Mustalahti", "Jouni Mattila"], "title": "Full-Dynamics Real-Time Nonlinear Model Predictive Control of Heavy-Duty Hydraulic Manipulator for Trajectory Tracking Tasks", "comment": "This work has been submitted for possible publication in IEEE", "summary": "Heavy-duty hydraulic manipulators (HHMs) operate under strict physical and\nsafety-critical constraints due to their large size, high power, and complex\nnonlinear dynamics. Ensuring that both joint-level and end-effector\ntrajectories remain compliant with actuator capabilities, such as force,\nvelocity, and position limits, is essential for safe and reliable operation,\nyet remains largely underexplored in real-time control frameworks. This paper\npresents a nonlinear model predictive control (NMPC) framework designed to\nguarantee constraint satisfaction throughout the full nonlinear dynamics of\nHHMs, while running at a real-time control frequency of 1 kHz. The proposed\nmethod combines a multiple-shooting strategy with real-time sensor feedback,\nand is supported by a robust low-level controller based on virtual\ndecomposition control (VDC) for precise joint tracking. Experimental validation\non a full-scale hydraulic manipulator shows that the NMPC framework not only\nenforces actuator constraints at the joint level, but also ensures\nconstraint-compliant motion in Cartesian space for the end-effector. These\nresults demonstrate the method's capability to deliver high-accuracy trajectory\ntracking while strictly respecting safety-critical limits, setting a new\nbenchmark for real-time control in large-scale hydraulic systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u91cd\u578b\u6db2\u538b\u673a\u68b0\u81c2\u7684\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u6846\u67b6\uff0c\u80fd\u591f\u57281kHz\u5b9e\u65f6\u63a7\u5236\u9891\u7387\u4e0b\u4fdd\u8bc1\u5173\u8282\u548c\u672b\u7aef\u6267\u884c\u5668\u7684\u7ea6\u675f\u6ee1\u8db3\uff0c\u540c\u65f6\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u8f68\u8ff9\u8ddf\u8e2a\u3002", "motivation": "\u91cd\u578b\u6db2\u538b\u673a\u68b0\u81c2\u7531\u4e8e\u5c3a\u5bf8\u5927\u3001\u529f\u7387\u9ad8\u3001\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u590d\u6742\uff0c\u9700\u8981\u5728\u4e25\u683c\u7269\u7406\u548c\u5b89\u5168\u7ea6\u675f\u4e0b\u8fd0\u884c\u3002\u73b0\u6709\u5b9e\u65f6\u63a7\u5236\u6846\u67b6\u5f88\u5c11\u80fd\u540c\u65f6\u4fdd\u8bc1\u5173\u8282\u7ea7\u548c\u672b\u7aef\u6267\u884c\u5668\u8f68\u8ff9\u7b26\u5408\u6267\u884c\u5668\u80fd\u529b\u9650\u5236\u3002", "method": "\u7ed3\u5408\u591a\u5c04\u51fb\u7b56\u7565\u4e0e\u5b9e\u65f6\u4f20\u611f\u5668\u53cd\u9988\u7684\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u865a\u62df\u5206\u89e3\u63a7\u5236\u7684\u9c81\u68d2\u5e95\u5c42\u63a7\u5236\u5668\u8fdb\u884c\u7cbe\u786e\u5173\u8282\u8ddf\u8e2a\u3002", "result": "\u5728\u5168\u5c3a\u5bf8\u6db2\u538b\u673a\u68b0\u81c2\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u6846\u67b6\u4e0d\u4ec5\u80fd\u5728\u5173\u8282\u7ea7\u5f3a\u5236\u6267\u884c\u5668\u7ea6\u675f\uff0c\u8fd8\u80fd\u786e\u4fdd\u672b\u7aef\u6267\u884c\u5668\u5728\u7b1b\u5361\u5c14\u7a7a\u95f4\u4e2d\u7684\u7ea6\u675f\u5408\u89c4\u8fd0\u52a8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u8f68\u8ff9\u8ddf\u8e2a\u5e76\u4e25\u683c\u9075\u5b88\u5b89\u5168\u5173\u952e\u9650\u5236\uff0c\u4e3a\u5927\u578b\u6db2\u538b\u7cfb\u7edf\u7684\u5b9e\u65f6\u63a7\u5236\u8bbe\u7acb\u4e86\u65b0\u6807\u51c6\u3002"}}
{"id": "2510.23384", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23384", "abs": "https://arxiv.org/abs/2510.23384", "authors": ["Pratik N. Kalamkar", "A. G. Phakatkar"], "title": "Opinion Mining Based Entity Ranking using Fuzzy Logic Algorithmic Approach", "comment": "8 pages, 4 figures, Conference Paper", "summary": "Opinions are central to almost all human activities and are key influencers\nof our behaviors. In current times due to growth of social networking website\nand increase in number of e-commerce site huge amount of opinions are now\navailable on web. Given a set of evaluative statements that contain opinions\n(or sentiments) about an Entity, opinion mining aims to extract attributes and\ncomponents of the object that have been commented on in each statement and to\ndetermine whether the comments are positive, negative or neutral. While lot of\nresearch recently has been done in field of opinion mining and some of it\ndealing with ranking of entities based on review or opinion set, classifying\nopinions into finer granularity level and then ranking entities has never been\ndone before. In this paper method for opinion mining from statements at a\ndeeper level of granularity is proposed. This is done by using fuzzy logic\nreasoning, after which entities are ranked as per this information.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u63a8\u7406\u7684\u7ec6\u7c92\u5ea6\u610f\u89c1\u6316\u6398\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u8bc4\u8bba\u6587\u672c\u4e2d\u63d0\u53d6\u66f4\u8be6\u7ec6\u7684\u89c2\u70b9\u4fe1\u606f\u5e76\u636e\u6b64\u5bf9\u5b9e\u4f53\u8fdb\u884c\u6392\u540d\u3002", "motivation": "\u968f\u7740\u793e\u4ea4\u7f51\u7edc\u548c\u7535\u5546\u7f51\u7ad9\u7684\u53d1\u5c55\uff0c\u7f51\u7edc\u4e0a\u5b58\u5728\u5927\u91cf\u89c2\u70b9\u6570\u636e\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u57fa\u4e8e\u8bc4\u8bba\u96c6\u5bf9\u5b9e\u4f53\u8fdb\u884c\u6392\u540d\uff0c\u4f46\u7f3a\u4e4f\u5c06\u89c2\u70b9\u5206\u7c7b\u5230\u66f4\u7ec6\u7c92\u5ea6\u7ea7\u522b\u540e\u518d\u8fdb\u884c\u5b9e\u4f53\u6392\u540d\u7684\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u6a21\u7cca\u903b\u8f91\u63a8\u7406\u4ece\u8bed\u53e5\u4e2d\u8fdb\u884c\u66f4\u6df1\u5c42\u6b21\u7684\u7ec6\u7c92\u5ea6\u610f\u89c1\u6316\u6398\uff0c\u7136\u540e\u57fa\u4e8e\u8fd9\u4e9b\u4fe1\u606f\u5bf9\u5b9e\u4f53\u8fdb\u884c\u6392\u540d\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u8bc4\u8bba\u6587\u672c\u4e2d\u63d0\u53d6\u66f4\u8be6\u7ec6\u7684\u5c5e\u6027\u548c\u7ec4\u4ef6\u4fe1\u606f\uff0c\u5e76\u786e\u5b9a\u8bc4\u8bba\u7684\u60c5\u611f\u6781\u6027\uff08\u6b63\u9762\u3001\u8d1f\u9762\u6216\u4e2d\u6027\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u5c06\u89c2\u70b9\u5206\u7c7b\u5230\u66f4\u7ec6\u7c92\u5ea6\u7ea7\u522b\u540e\u518d\u8fdb\u884c\u5b9e\u4f53\u6392\u540d\uff0c\u4e3a\u610f\u89c1\u6316\u6398\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u9014\u5f84\u3002"}}
{"id": "2510.23495", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23495", "abs": "https://arxiv.org/abs/2510.23495", "authors": ["Chenyang Ma", "Kai Lu", "Ruta Desai", "Xavier Puig", "Andrew Markham", "Niki Trigoni"], "title": "COOPERA: Continual Open-Ended Human-Robot Assistance", "comment": "NeurIPS 2025 (Spotlight); Project Page:\n  https://dannymcy.github.io/coopera/", "summary": "To understand and collaborate with humans, robots must account for individual\nhuman traits, habits, and activities over time. However, most robotic\nassistants lack these abilities, as they primarily focus on predefined tasks in\nstructured environments and lack a human model to learn from. This work\nintroduces COOPERA, a novel framework for COntinual, OPen-Ended human-Robot\nAssistance, where simulated humans, driven by psychological traits and\nlong-term intentions, interact with robots in complex environments. By\nintegrating continuous human feedback, our framework, for the first time,\nenables the study of long-term, open-ended human-robot collaboration (HRC) in\ndifferent collaborative tasks across various time-scales. Within COOPERA, we\nintroduce a benchmark and an approach to personalize the robot's collaborative\nactions by learning human traits and context-dependent intents. Experiments\nvalidate the extent to which our simulated humans reflect realistic human\nbehaviors and demonstrate the value of inferring and personalizing to human\nintents for open-ended and long-term HRC. Project Page:\nhttps://dannymcy.github.io/coopera/", "AI": {"tldr": "COOPERA\u662f\u4e00\u4e2a\u6301\u7eed\u5f00\u653e\u4eba\u673a\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u5177\u6709\u5fc3\u7406\u7279\u5f81\u548c\u957f\u671f\u610f\u56fe\u7684\u4eba\u7c7b\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u4e0e\u673a\u5668\u4eba\u4e92\u52a8\uff0c\u5b9e\u73b0\u4e2a\u6027\u5316\u7684\u4eba\u673a\u534f\u4f5c\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u4eba\u52a9\u624b\u4e3b\u8981\u5728\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u6267\u884c\u9884\u5b9a\u4e49\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u4eba\u7c7b\u4e2a\u4f53\u7279\u5f81\u3001\u4e60\u60ef\u548c\u6d3b\u52a8\u7684\u957f\u671f\u5b66\u4e60\u80fd\u529b\uff0c\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u4eba\u673a\u534f\u4f5c\u3002", "method": "\u63d0\u51faCOOPERA\u6846\u67b6\uff0c\u96c6\u6210\u6301\u7eed\u7684\u4eba\u7c7b\u53cd\u9988\uff0c\u901a\u8fc7\u6a21\u62df\u5177\u6709\u5fc3\u7406\u7279\u5f81\u548c\u957f\u671f\u610f\u56fe\u7684\u4eba\u7c7b\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u4e0e\u673a\u5668\u4eba\u4e92\u52a8\uff0c\u5e76\u5f15\u5165\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e2a\u6027\u5316\u65b9\u6cd5\u5b66\u4e60\u4eba\u7c7b\u7279\u5f81\u548c\u60c5\u5883\u4f9d\u8d56\u610f\u56fe\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\u7684\u771f\u5b9e\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u63a8\u65ad\u548c\u4e2a\u6027\u5316\u4eba\u7c7b\u610f\u56fe\u5bf9\u5f00\u653e\u957f\u671f\u4eba\u673a\u534f\u4f5c\u7684\u4ef7\u503c\u3002", "conclusion": "COOPERA\u6846\u67b6\u9996\u6b21\u5b9e\u73b0\u4e86\u5728\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u7814\u7a76\u957f\u671f\u5f00\u653e\u4eba\u673a\u534f\u4f5c\uff0c\u4e3a\u4eba\u673a\u534f\u4f5c\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2510.23509", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23509", "abs": "https://arxiv.org/abs/2510.23509", "authors": ["Weizheng Wang", "Obi Ike", "Soyun Choi", "Sungeun Hong", "Byung-Cheol Min"], "title": "Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model", "comment": null, "summary": "Social robot navigation increasingly relies on large language models for\nreasoning, path planning, and enabling movement in dynamic human spaces.\nHowever, relying solely on LLMs for planning often leads to unpredictable and\nunsafe behaviors, especially in dynamic human spaces, due to limited physical\ngrounding and weak logical consistency. In this work, we introduce NaviWM, a\nsocially-aware robot Navigation World Model that augments LLM reasoning with a\nstructured world model and a logic-driven chain-of-thought process. NaviWM\nconsists of two main components: (1) a spatial-temporal world model that\ncaptures the positions, velocities, and activities of agents in the\nenvironment, and (2) a deductive reasoning module that guides LLMs through a\nmulti-step, logic-based inference process. This integration enables the robot\nto generate navigation decisions that are both socially compliant and\nphysically safe, under well-defined constraints such as personal space,\ncollision avoidance, and timing. Unlike previous methods based on prompting or\nfine-tuning, NaviWM encodes social norms as first-order logic, enabling\ninterpretable and verifiable reasoning. Experiments show that NaviWM improves\nsuccess rates and reduces social violations, particularly in crowded\nenvironments. These results demonstrate the benefit of combining formal\nreasoning with LLMs for robust social navigation. Additional experimental\ndetails and demo videos for this work can be found at:\nhttps://sites.google.com/view/NaviWM.", "AI": {"tldr": "NaviWM\u662f\u4e00\u4e2a\u793e\u4ea4\u611f\u77e5\u7684\u673a\u5668\u4eba\u5bfc\u822a\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u7ed3\u6784\u5316\u4e16\u754c\u6a21\u578b\u548c\u903b\u8f91\u9a71\u52a8\u7684\u601d\u7ef4\u94fe\u8fc7\u7a0b\u6765\u589e\u5f3aLLM\u63a8\u7406\uff0c\u89e3\u51b3LLM\u5728\u52a8\u6001\u4eba\u7c7b\u7a7a\u95f4\u4e2d\u5bfc\u822a\u65f6\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u5b89\u5168\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u4f9d\u8d56\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u793e\u4ea4\u673a\u5668\u4eba\u5bfc\u822a\u5b58\u5728\u4e0d\u53ef\u9884\u6d4b\u548c\u4e0d\u5b89\u5168\u884c\u4e3a\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u7531\u4e8eLLM\u7f3a\u4e4f\u7269\u7406\u57fa\u7840\u548c\u903b\u8f91\u4e00\u81f4\u6027\u3002", "method": "NaviWM\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u7ec4\u4ef6\uff1a\u7a7a\u95f4-\u65f6\u95f4\u4e16\u754c\u6a21\u578b\uff08\u6355\u6349\u73af\u5883\u4e2d\u667a\u80fd\u4f53\u7684\u4f4d\u7f6e\u3001\u901f\u5ea6\u548c\u6d3b\u52a8\uff09\u548c\u6f14\u7ece\u63a8\u7406\u6a21\u5757\uff08\u901a\u8fc7\u591a\u6b65\u9aa4\u3001\u57fa\u4e8e\u903b\u8f91\u7684\u63a8\u7406\u8fc7\u7a0b\u6307\u5bfcLLM\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660eNaviWM\u63d0\u9ad8\u4e86\u6210\u529f\u7387\u548c\u51cf\u5c11\u4e86\u793e\u4ea4\u8fdd\u89c4\uff0c\u7279\u522b\u662f\u5728\u62e5\u6324\u73af\u5883\u4e2d\u3002", "conclusion": "\u5c06\u5f62\u5f0f\u63a8\u7406\u4e0eLLM\u7ed3\u5408\u5bf9\u4e8e\u7a33\u5065\u7684\u793e\u4ea4\u5bfc\u822a\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2510.23410", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23410", "abs": "https://arxiv.org/abs/2510.23410", "authors": ["Jiahao Ji", "Tianyu Wang", "Yeshu Li", "Yushen Huo", "Zhilin Zhang", "Chuan Yu", "Jian Xu", "Bo Zheng"], "title": "Bid2X: Revealing Dynamics of Bidding Environment in Online Advertising from A Foundation Model Lens", "comment": "12 pages, KDD 2025", "summary": "Auto-bidding is crucial in facilitating online advertising by automatically\nproviding bids for advertisers. While previous work has made great efforts to\nmodel bidding environments for better ad performance, it has limitations in\ngeneralizability across environments since these models are typically tailored\nfor specific bidding scenarios. To this end, we approach the\nscenario-independent principles through a unified function that estimates the\nachieved effect under specific bids, such as budget consumption, gross\nmerchandise volume (GMV), page views, etc. Then, we propose a bidding\nfoundation model Bid2X to learn this fundamental function from data in various\nscenarios. Our Bid2X is built over uniform series embeddings that encode\nheterogeneous data through tailored embedding methods. To capture complex\ninter-variable and dynamic temporal dependencies in bidding data, we propose\ntwo attention mechanisms separately treating embeddings of different variables\nand embeddings at different times as attention tokens for representation\nlearning. On top of the learned variable and temporal representations, a\nvariable-aware fusion module is used to perform adaptive bidding outcome\nprediction. To model the unique bidding data distribution, we devise a\nzero-inflated projection module to incorporate the estimated non-zero\nprobability into its value prediction, which makes up a joint optimization\nobjective containing classification and regression. The objective is proven to\nconverge to the zero-inflated distribution. Our model has been deployed on the\nad platform in Taobao, one of the world's largest e-commerce platforms. Offline\nevaluation on eight datasets exhibits Bid2X's superiority compared to various\nbaselines and its generality across different scenarios. Bid2X increased GMV by\n4.65% and ROI by 2.44% in online A/B tests, paving the way for bidding\nfoundation model in computational advertising.", "AI": {"tldr": "\u63d0\u51fa\u4e86Bid2X\u7ade\u4ef7\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u7edf\u4e00\u51fd\u6570\u5b66\u4e60\u4e0d\u540c\u7ade\u4ef7\u573a\u666f\u4e0b\u7684\u6548\u679c\u4f30\u8ba1\uff0c\u4f7f\u7528\u6ce8\u610f\u529b\u673a\u5236\u5904\u7406\u5f02\u6784\u6570\u636e\uff0c\u5728\u6dd8\u5b9d\u5e73\u53f0\u90e8\u7f72\u540e\u663e\u8457\u63d0\u5347\u4e86GMV\u548cROI\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u7ade\u4ef7\u6a21\u578b\u5728\u8de8\u73af\u5883\u901a\u7528\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4f20\u7edf\u6a21\u578b\u901a\u5e38\u9488\u5bf9\u7279\u5b9a\u7ade\u4ef7\u573a\u666f\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u8de8\u573a\u666f\u7684\u666e\u9002\u6027\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u7edf\u4e00\u5e8f\u5217\u5d4c\u5165\u7684Bid2X\u6a21\u578b\uff0c\u4f7f\u7528\u4e24\u79cd\u6ce8\u610f\u529b\u673a\u5236\u5206\u522b\u5904\u7406\u4e0d\u540c\u53d8\u91cf\u548c\u4e0d\u540c\u65f6\u95f4\u7684\u5d4c\u5165\uff0c\u7ed3\u5408\u53d8\u91cf\u611f\u77e5\u878d\u5408\u6a21\u5757\u548c\u96f6\u81a8\u80c0\u6295\u5f71\u6a21\u5757\u8fdb\u884c\u8054\u5408\u4f18\u5316\u3002", "result": "\u57288\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u79bb\u7ebf\u8bc4\u4f30\u663e\u793aBid2X\u4f18\u4e8e\u5404\u79cd\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2dGMV\u63d0\u53474.65%\uff0cROI\u63d0\u53472.44%\u3002", "conclusion": "Bid2X\u4e3a\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u7ade\u4ef7\u57fa\u7840\u6a21\u578b\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u591a\u573a\u666f\u4e0b\u7684\u901a\u7528\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2510.23511", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23511", "abs": "https://arxiv.org/abs/2510.23511", "authors": ["Bin Xie", "Erjin Zhou", "Fan Jia", "Hao Shi", "Haoqiang Fan", "Haowei Zhang", "Hebei Li", "Jianjian Sun", "Jie Bin", "Junwen Huang", "Kai Liu", "Kaixin Liu", "Kefan Gu", "Lin Sun", "Meng Zhang", "Peilong Han", "Ruitao Hao", "Ruitao Zhang", "Saike Huang", "Songhan Xie", "Tiancai Wang", "Tianle Liu", "Wenbin Tang", "Wenqi Zhu", "Yang Chen", "Yingfei Liu", "Yizhuang Zhou", "Yu Liu", "Yucheng Zhao", "Yunchao Ma", "Yunfei Wei", "Yuxiang Chen", "Ze Chen", "Zeming Li", "Zhao Wu", "Ziheng Zhang", "Ziming Liu", "Ziwei Yan", "Ziyu Zhang"], "title": "Dexbotic: Open-Source Vision-Language-Action Toolbox", "comment": "Authors are listed in alphabetical order. The official website is\n  located at https://dexbotic.com/. Code is available at\n  https://github.com/Dexmal/dexbotic", "summary": "In this paper, we present Dexbotic, an open-source Vision-Language-Action\n(VLA) model toolbox based on PyTorch. It aims to provide a one-stop VLA\nresearch service for professionals in the field of embodied intelligence. It\noffers a codebase that supports multiple mainstream VLA policies\nsimultaneously, allowing users to reproduce various VLA methods with just a\nsingle environment setup. The toolbox is experiment-centric, where the users\ncan quickly develop new VLA experiments by simply modifying the Exp script.\nMoreover, we provide much stronger pretrained models to achieve great\nperformance improvements for state-of-the-art VLA policies. Dexbotic will\ncontinuously update to include more of the latest pre-trained foundation models\nand cutting-edge VLA models in the industry.", "AI": {"tldr": "Dexbotic\u662f\u4e00\u4e2a\u57fa\u4e8ePyTorch\u7684\u5f00\u6e90\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c(VLA)\u6a21\u578b\u5de5\u5177\u7bb1\uff0c\u4e3a\u5177\u8eab\u667a\u80fd\u9886\u57df\u63d0\u4f9b\u4e00\u7ad9\u5f0fVLA\u7814\u7a76\u670d\u52a1\uff0c\u652f\u6301\u591a\u79cd\u4e3b\u6d41VLA\u7b56\u7565\uff0c\u5e76\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u3002", "motivation": "\u4e3a\u5177\u8eab\u667a\u80fd\u9886\u57df\u7684\u4e13\u4e1a\u4eba\u58eb\u63d0\u4f9b\u4e00\u4e2a\u4e00\u7ad9\u5f0f\u7684VLA\u7814\u7a76\u670d\u52a1\u5e73\u53f0\uff0c\u7b80\u5316VLA\u65b9\u6cd5\u7684\u590d\u73b0\u548c\u5b9e\u9a8c\u5f00\u53d1\u8fc7\u7a0b\u3002", "method": "\u57fa\u4e8ePyTorch\u6784\u5efa\u7684\u5f00\u6e90\u5de5\u5177\u7bb1\uff0c\u652f\u6301\u591a\u79cd\u4e3b\u6d41VLA\u7b56\u7565\uff0c\u91c7\u7528\u5b9e\u9a8c\u4e2d\u5fc3\u5316\u8bbe\u8ba1\uff0c\u7528\u6237\u53ea\u9700\u4fee\u6539Exp\u811a\u672c\u5373\u53ef\u5feb\u901f\u5f00\u53d1\u65b0\u5b9e\u9a8c\u3002", "result": "\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6700\u5148\u8fdbVLA\u7b56\u7565\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "Dexbotic\u5c06\u6301\u7eed\u66f4\u65b0\uff0c\u7eb3\u5165\u66f4\u591a\u6700\u65b0\u7684\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u548c\u884c\u4e1a\u524d\u6cbf\u7684VLA\u6a21\u578b\uff0c\u4e3aVLA\u7814\u7a76\u63d0\u4f9b\u6301\u7eed\u652f\u6301\u3002"}}
{"id": "2510.23424", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23424", "abs": "https://arxiv.org/abs/2510.23424", "authors": ["Elouanes Khelifi", "Amir Saki", "Usef Faghihi"], "title": "Causal Deep Q Network", "comment": null, "summary": "Deep Q Networks (DQN) have shown remarkable success in various reinforcement\nlearning tasks. However, their reliance on associative learning often leads to\nthe acquisition of spurious correlations, hindering their problem-solving\ncapabilities. In this paper, we introduce a novel approach to integrate causal\nprinciples into DQNs, leveraging the PEACE (Probabilistic Easy vAriational\nCausal Effect) formula for estimating causal effects. By incorporating causal\nreasoning during training, our proposed framework enhances the DQN's\nunderstanding of the underlying causal structure of the environment, thereby\nmitigating the influence of confounding factors and spurious correlations. We\ndemonstrate that integrating DQNs with causal capabilities significantly\nenhances their problem-solving capabilities without compromising performance.\nExperimental results on standard benchmark environments showcase that our\napproach outperforms conventional DQNs, highlighting the effectiveness of\ncausal reasoning in reinforcement learning. Overall, our work presents a\npromising avenue for advancing the capabilities of deep reinforcement learning\nagents through principled causal inference.", "AI": {"tldr": "\u5c06\u56e0\u679c\u63a8\u7406\u96c6\u6210\u5230DQN\u4e2d\uff0c\u4f7f\u7528PEACE\u516c\u5f0f\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\uff0c\u51cf\u5c11\u865a\u5047\u76f8\u5173\u6027\uff0c\u63d0\u5347\u95ee\u9898\u89e3\u51b3\u80fd\u529b", "motivation": "\u4f20\u7edf\u7684DQN\u4f9d\u8d56\u5173\u8054\u5b66\u4e60\uff0c\u5bb9\u6613\u83b7\u5f97\u865a\u5047\u76f8\u5173\u6027\uff0c\u9650\u5236\u4e86\u5176\u95ee\u9898\u89e3\u51b3\u80fd\u529b", "method": "\u63d0\u51fa\u5c06\u56e0\u679c\u539f\u7406\u96c6\u6210\u5230DQN\u4e2d\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528PEACE\u516c\u5f0f\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u878d\u5165\u56e0\u679c\u63a8\u7406", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u73af\u5883\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edfDQN\uff0c\u5c55\u793a\u4e86\u56e0\u679c\u63a8\u7406\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6709\u6548\u6027", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u901a\u8fc7\u539f\u5219\u6027\u56e0\u679c\u63a8\u65ad\u63d0\u5347\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84"}}
{"id": "2510.23512", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23512", "abs": "https://arxiv.org/abs/2510.23512", "authors": ["Martin Huber", "Nicola A. Cavalcanti", "Ayoob Davoodi", "Ruixuan Li", "Christopher E. Mower", "Fabio Carrillo", "Christoph J. Laux", "Francois Teyssere", "Thibault Chandanson", "Antoine Harl\u00e9", "Elie Saghbiny", "Mazda Farshad", "Guillaume Morel", "Emmanuel Vander Poorten", "Philipp F\u00fcrnstahl", "S\u00e9bastien Ourselin", "Christos Bergeles", "Tom Vercauteren"], "title": "Localising under the drape: proprioception in the era of distributed surgical robotic system", "comment": null, "summary": "Despite their mechanical sophistication, surgical robots remain blind to\ntheir surroundings. This lack of spatial awareness causes collisions, system\nrecoveries, and workflow disruptions, issues that will intensify with the\nintroduction of distributed robots with independent interacting arms. Existing\ntracking systems rely on bulky infrared cameras and reflective markers,\nproviding only limited views of the surgical scene and adding hardware burden\nin crowded operating rooms. We present a marker-free proprioception method that\nenables precise localisation of surgical robots under their sterile draping\ndespite associated obstruction of visual cues. Our method solely relies on\nlightweight stereo-RGB cameras and novel transformer-based deep learning\nmodels. It builds on the largest multi-centre spatial robotic surgery dataset\nto date (1.4M self-annotated images from human cadaveric and preclinical in\nvivo studies). By tracking the entire robot and surgical scene, rather than\nindividual markers, our approach provides a holistic view robust to occlusions,\nsupporting surgical scene understanding and context-aware control. We\ndemonstrate an example of potential clinical benefits during in vivo breathing\ncompensation with access to tissue dynamics, unobservable under state of the\nart tracking, and accurately locate in multi-robot systems for future\nintelligent interaction. In addition, and compared with existing systems, our\nmethod eliminates markers and improves tracking visibility by 25%. To our\nknowledge, this is the first demonstration of marker-free proprioception for\nfully draped surgical robots, reducing setup complexity, enhancing safety, and\npaving the way toward modular and autonomous robotic surgery.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u6807\u8bb0\u7684\u673a\u5668\u4eba\u672c\u4f53\u611f\u77e5\u65b9\u6cd5\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u7acb\u4f53RGB\u76f8\u673a\u548c\u57fa\u4e8eTransformer\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u80fd\u591f\u5728\u65e0\u83cc\u8986\u76d6\u4e0b\u7cbe\u786e\u5b9a\u4f4d\u624b\u672f\u673a\u5668\u4eba\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8ddf\u8e2a\u7cfb\u7edf\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u624b\u672f\u673a\u5668\u4eba\u7f3a\u4e4f\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\uff0c\u5bfc\u81f4\u78b0\u649e\u548c\u7cfb\u7edf\u6062\u590d\u95ee\u9898\uff1b\u73b0\u6709\u8ddf\u8e2a\u7cfb\u7edf\u4f9d\u8d56\u7b28\u91cd\u7684\u7ea2\u5916\u76f8\u673a\u548c\u53cd\u5c04\u6807\u8bb0\uff0c\u89c6\u91ce\u6709\u9650\u4e14\u589e\u52a0\u786c\u4ef6\u8d1f\u62c5\u3002", "method": "\u57fa\u4e8e\u6700\u5927\u7684\u591a\u4e2d\u5fc3\u7a7a\u95f4\u673a\u5668\u4eba\u624b\u672f\u6570\u636e\u96c6\uff08140\u4e07\u5f20\u81ea\u6ce8\u91ca\u56fe\u50cf\uff09\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u7acb\u4f53RGB\u76f8\u673a\u548c\u65b0\u578b\u57fa\u4e8eTransformer\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u901a\u8fc7\u8ddf\u8e2a\u6574\u4e2a\u673a\u5668\u4eba\u548c\u624b\u672f\u573a\u666f\u800c\u975e\u5355\u4e2a\u6807\u8bb0\u6765\u5b9e\u73b0\u5b9a\u4f4d\u3002", "result": "\u5728\u4f53\u5185\u547c\u5438\u8865\u507f\u4e2d\u5c55\u793a\u4e86\u4e34\u5e8a\u6548\u76ca\uff0c\u80fd\u591f\u89c2\u5bdf\u7ec4\u7ec7\u52a8\u6001\uff1b\u76f8\u6bd4\u73b0\u6709\u7cfb\u7edf\uff0c\u6d88\u9664\u4e86\u6807\u8bb0\u9700\u6c42\u5e76\u5c06\u8ddf\u8e2a\u53ef\u89c1\u6027\u63d0\u9ad8\u4e8625%\uff1b\u5728\u591a\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u51c6\u786e\u5b9a\u4f4d\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u9488\u5bf9\u5b8c\u5168\u8986\u76d6\u65e0\u83cc\u5e03\u7684\u624b\u672f\u673a\u5668\u4eba\u5b9e\u73b0\u65e0\u6807\u8bb0\u672c\u4f53\u611f\u77e5\u7684\u6f14\u793a\uff0c\u51cf\u5c11\u4e86\u8bbe\u7f6e\u590d\u6742\u6027\uff0c\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\uff0c\u4e3a\u6a21\u5757\u5316\u548c\u81ea\u4e3b\u673a\u5668\u4eba\u624b\u672f\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.23443", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.23443", "abs": "https://arxiv.org/abs/2510.23443", "authors": ["Chiara Bonfanti", "Alessandro Druetto", "Cataldo Basile", "Tharindu Ranasinghe", "Marcos Zampieri"], "title": "A Neuro-Symbolic Multi-Agent Approach to Legal-Cybersecurity Knowledge Integration", "comment": "7 pages", "summary": "The growing intersection of cybersecurity and law creates a complex\ninformation space where traditional legal research tools struggle to deal with\nnuanced connections between cases, statutes, and technical vulnerabilities.\nThis knowledge divide hinders collaboration between legal experts and\ncybersecurity professionals. To address this important gap, this work provides\na first step towards intelligent systems capable of navigating the increasingly\nintricate cyber-legal domain. We demonstrate promising initial results on\nmultilingual tasks.", "AI": {"tldr": "\u5f00\u53d1\u667a\u80fd\u7cfb\u7edf\u4ee5\u89e3\u51b3\u7f51\u7edc\u5b89\u5168\u4e0e\u6cd5\u5f8b\u4ea4\u53c9\u9886\u57df\u7684\u4fe1\u606f\u590d\u6742\u6027\uff0c\u4fc3\u8fdb\u6cd5\u5f8b\u4e13\u5bb6\u4e0e\u7f51\u7edc\u5b89\u5168\u4e13\u4e1a\u4eba\u5458\u4e4b\u95f4\u7684\u534f\u4f5c\u3002", "motivation": "\u7f51\u7edc\u5b89\u5168\u4e0e\u6cd5\u5f8b\u7684\u4ea4\u53c9\u9886\u57df\u4fe1\u606f\u590d\u6742\uff0c\u4f20\u7edf\u6cd5\u5f8b\u7814\u7a76\u5de5\u5177\u96be\u4ee5\u5904\u7406\u6848\u4f8b\u3001\u6cd5\u89c4\u548c\u6280\u672f\u6f0f\u6d1e\u4e4b\u95f4\u7684\u7ec6\u5fae\u8054\u7cfb\uff0c\u963b\u788d\u4e86\u6cd5\u5f8b\u4e13\u5bb6\u4e0e\u7f51\u7edc\u5b89\u5168\u4e13\u4e1a\u4eba\u5458\u7684\u534f\u4f5c\u3002", "method": "\u5f00\u53d1\u80fd\u591f\u5bfc\u822a\u65e5\u76ca\u590d\u6742\u7684\u7f51\u7edc\u6cd5\u5f8b\u9886\u57df\u7684\u667a\u80fd\u7cfb\u7edf\uff0c\u5e76\u5728\u591a\u8bed\u8a00\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u521d\u6b65\u9a8c\u8bc1\u3002", "result": "\u5728\u591a\u8bed\u8a00\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u521d\u6b65\u7ed3\u679c\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u89e3\u51b3\u7f51\u7edc\u5b89\u5168\u4e0e\u6cd5\u5f8b\u4ea4\u53c9\u9886\u57df\u7684\u4fe1\u606f\u590d\u6742\u6027\u63d0\u4f9b\u4e86\u521d\u6b65\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u667a\u80fd\u7cfb\u7edf\u5728\u8be5\u9886\u57df\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.23521", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23521", "abs": "https://arxiv.org/abs/2510.23521", "authors": ["Anthony Opipari", "Aravindhan K Krishnan", "Shreekant Gayaka", "Min Sun", "Cheng-Hao Kuo", "Arnie Sen", "Odest Chadwicke Jenkins"], "title": "Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation", "comment": "Accepted in IEEE Robotics and Automation Letters September 2025", "summary": "Remembering where object segments were predicted in the past is useful for\nimproving the accuracy and consistency of class-agnostic video segmentation\nalgorithms. Existing video segmentation algorithms typically use either no\nobject-level memory (e.g. FastSAM) or they use implicit memories in the form of\nrecurrent neural network features (e.g. SAM2). In this paper, we augment both\ntypes of segmentation models using an explicit 3D memory and show that the\nresulting models have more accurate and consistent predictions. For this, we\ndevelop an online 3D Gaussian Splatting (3DGS) technique to store predicted\nobject-level segments generated throughout the duration of a video. Based on\nthis 3DGS representation, a set of fusion techniques are developed, named\nFastSAM-Splat and SAM2-Splat, that use the explicit 3DGS memory to improve\ntheir respective foundation models' predictions. Ablation experiments are used\nto validate the proposed techniques' design and hyperparameter settings.\nResults from both real-world and simulated benchmarking experiments show that\nmodels which use explicit 3D memories result in more accurate and consistent\npredictions than those which use no memory or only implicit neural network\nmemories. Project Page: https://topipari.com/projects/FastSAM-Splat/", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u663e\u5f0f3D\u9ad8\u65af\u6e85\u5c04(3DGS)\u8bb0\u5fc6\u6765\u6539\u8fdb\u89c6\u9891\u5206\u5272\u7b97\u6cd5\u7684\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86FastSAM-Splat\u548cSAM2-Splat\u4e24\u79cd\u878d\u5408\u6280\u672f\uff0c\u901a\u8fc7\u5b58\u50a8\u8fc7\u53bb\u9884\u6d4b\u7684\u5bf9\u8c61\u7247\u6bb5\u6765\u63d0\u9ad8\u5206\u5272\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u9891\u5206\u5272\u7b97\u6cd5\u8981\u4e48\u4e0d\u4f7f\u7528\u5bf9\u8c61\u7ea7\u8bb0\u5fc6\uff08\u5982FastSAM\uff09\uff0c\u8981\u4e48\u4ec5\u4f7f\u7528\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7279\u5f81\u7684\u9690\u5f0f\u8bb0\u5fc6\uff08\u5982SAM2\uff09\u3002\u4f5c\u8005\u8ba4\u4e3a\u8bb0\u4f4f\u8fc7\u53bb\u9884\u6d4b\u7684\u5bf9\u8c61\u7247\u6bb5\u4f4d\u7f6e\u6709\u52a9\u4e8e\u63d0\u9ad8\u7c7b\u65e0\u5173\u89c6\u9891\u5206\u5272\u7b97\u6cd5\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u5728\u7ebf3D\u9ad8\u65af\u6e85\u5c04(3DGS)\u6280\u672f\u6765\u5b58\u50a8\u89c6\u9891\u8fc7\u7a0b\u4e2d\u9884\u6d4b\u7684\u5bf9\u8c61\u7ea7\u7247\u6bb5\uff0c\u57fa\u4e8e\u6b643DGS\u8868\u793a\u5f00\u53d1\u4e86FastSAM-Splat\u548cSAM2-Splat\u4e24\u79cd\u878d\u5408\u6280\u672f\uff0c\u4f7f\u7528\u663e\u5f0f3DGS\u8bb0\u5fc6\u6765\u6539\u8fdb\u5404\u81ea\u57fa\u7840\u6a21\u578b\u7684\u9884\u6d4b\u3002", "result": "\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u6280\u672f\u7684\u8bbe\u8ba1\u548c\u8d85\u53c2\u6570\u8bbe\u7f6e\u3002\u771f\u5b9e\u4e16\u754c\u548c\u6a21\u62df\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528\u663e\u5f0f3D\u8bb0\u5fc6\u7684\u6a21\u578b\u6bd4\u4e0d\u4f7f\u7528\u8bb0\u5fc6\u6216\u4ec5\u4f7f\u7528\u9690\u5f0f\u795e\u7ecf\u7f51\u7edc\u8bb0\u5fc6\u7684\u6a21\u578b\u5177\u6709\u66f4\u51c6\u786e\u548c\u4e00\u81f4\u7684\u9884\u6d4b\u7ed3\u679c\u3002", "conclusion": "\u4f7f\u7528\u663e\u5f0f3D\u9ad8\u65af\u6e85\u5c04\u8bb0\u5fc6\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u89c6\u9891\u5206\u5272\u7b97\u6cd5\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\uff0c\u8bc1\u660e\u4e86\u663e\u5f0f\u8bb0\u5fc6\u5728\u89c6\u9891\u5206\u5272\u4efb\u52a1\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.23453", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23453", "abs": "https://arxiv.org/abs/2510.23453", "authors": ["Marco Grossi"], "title": "What are the odds? Risk and uncertainty about AI existential risk", "comment": "10 pages", "summary": "This work is a commentary of the article\n\\href{https://doi.org/10.18716/ojs/phai/2025.2801}{AI Survival Stories: a\nTaxonomic Analysis of AI Existential Risk} by Cappelen, Goldstein, and\nHawthorne. It is not just a commentary though, but a useful reminder of the\nphilosophical limitations of \\say{linear} models of risk. The article will\nfocus on the model employed by the authors: first, I discuss some differences\nbetween standard Swiss Cheese models and this one. I then argue that in a\nsituation of epistemic indifference the probability of P(D) is higher than what\none might first suggest, given the structural relationships between layers. I\nthen distinguish between risk and uncertainty, and argue that any estimation of\nP(D) is structurally affected by two kinds of uncertainty: option uncertainty\nand state-space uncertainty. Incorporating these dimensions of uncertainty into\nour qualitative discussion on AI existential risk can provide a better\nunderstanding of the likeliness of P(D).", "AI": {"tldr": "\u672c\u6587\u662f\u5bf9Cappelen\u7b49\u4eba\u5173\u4e8eAI\u751f\u5b58\u98ce\u9669\u5206\u7c7b\u5206\u6790\u8bba\u6587\u7684\u8bc4\u8bba\uff0c\u91cd\u70b9\u8ba8\u8bba\u4e86\u98ce\u9669\u7ebf\u6027\u6a21\u578b\u7684\u54f2\u5b66\u5c40\u9650\u6027\uff0c\u5206\u6790\u4e86\u745e\u58eb\u5976\u916a\u6a21\u578b\u4e0e\u4f5c\u8005\u6a21\u578b\u7684\u5dee\u5f02\uff0c\u5e76\u63a2\u8ba8\u4e86\u8ba4\u77e5\u6f20\u89c6\u60c5\u5883\u4e0bP(D)\u6982\u7387\u7684\u7ed3\u6784\u6027\u5f71\u54cd\u56e0\u7d20\u3002", "motivation": "\u4f5c\u8005\u65e8\u5728\u63d0\u9192\u4eba\u4eec\u6ce8\u610f\u98ce\u9669\u7ebf\u6027\u6a21\u578b\u7684\u54f2\u5b66\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728AI\u751f\u5b58\u98ce\u9669\u8bc4\u4f30\u4e2d\uff0c\u4f20\u7edf\u7684\u6982\u7387\u6a21\u578b\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u6355\u6349\u5230\u7ed3\u6784\u6027\u4e0d\u786e\u5b9a\u6027\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u6807\u51c6\u745e\u58eb\u5976\u916a\u6a21\u578b\u4e0e\u4f5c\u8005\u63d0\u51fa\u7684\u6a21\u578b\uff0c\u5206\u6790\u5728\u8ba4\u77e5\u6f20\u89c6\u60c5\u5883\u4e0bP(D)\u6982\u7387\u7684\u7ed3\u6784\u6027\u5f71\u54cd\u56e0\u7d20\uff0c\u5e76\u533a\u5206\u98ce\u9669\u4e0e\u4e0d\u786e\u5b9a\u6027\uff0c\u5f15\u5165\u9009\u9879\u4e0d\u786e\u5b9a\u6027\u548c\u72b6\u6001\u7a7a\u95f4\u4e0d\u786e\u5b9a\u6027\u4e24\u4e2a\u7ef4\u5ea6\u3002", "result": "\u5206\u6790\u8868\u660e\u5728\u8ba4\u77e5\u6f20\u89c6\u60c5\u5883\u4e0b\uff0c\u7531\u4e8e\u5404\u5c42\u4e4b\u95f4\u7684\u7ed3\u6784\u5173\u7cfb\uff0cP(D)\u7684\u6982\u7387\u53ef\u80fd\u6bd4\u6700\u521d\u9884\u671f\u7684\u8981\u9ad8\uff0c\u4e14\u4efb\u4f55P(D)\u4f30\u8ba1\u90fd\u53d7\u5230\u4e24\u79cd\u4e0d\u786e\u5b9a\u6027\u7684\u7ed3\u6784\u6027\u5f71\u54cd\u3002", "conclusion": "\u5c06\u9009\u9879\u4e0d\u786e\u5b9a\u6027\u548c\u72b6\u6001\u7a7a\u95f4\u4e0d\u786e\u5b9a\u6027\u7eb3\u5165AI\u751f\u5b58\u98ce\u9669\u7684\u5b9a\u6027\u8ba8\u8bba\u4e2d\uff0c\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3P(D)\u7684\u53ef\u80fd\u6027\uff0c\u4ece\u800c\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2510.23571", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23571", "abs": "https://arxiv.org/abs/2510.23571", "authors": ["Yash Jangir", "Yidi Zhang", "Kashu Yamazaki", "Chenyu Zhang", "Kuan-Hsun Tu", "Tsung-Wei Ke", "Lei Ke", "Yonatan Bisk", "Katerina Fragkiadaki"], "title": "RobotArena $\\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation", "comment": "Website: https://robotarenainf.github.io", "summary": "The pursuit of robot generalists - instructable agents capable of performing\ndiverse tasks across diverse environments - demands rigorous and scalable\nevaluation. Yet real-world testing of robot policies remains fundamentally\nconstrained: it is labor-intensive, slow, unsafe at scale, and difficult to\nreproduce. Existing simulation benchmarks are similarly limited, as they train\nand test policies within the same synthetic domains and cannot assess models\ntrained from real-world demonstrations or alternative simulation environments.\nAs policies expand in scope and complexity, these barriers only intensify,\nsince defining \"success\" in robotics often hinges on nuanced human judgments of\nexecution quality. In this paper, we introduce a new benchmarking framework\nthat overcomes these challenges by shifting VLA evaluation into large-scale\nsimulated environments augmented with online human feedback. Leveraging\nadvances in vision-language models, 2D-to-3D generative modeling, and\ndifferentiable rendering, our approach automatically converts video\ndemonstrations from widely used robot datasets into simulated counterparts.\nWithin these digital twins, we assess VLA policies using both automated\nVLM-guided scoring and scalable human preference judgments collected from\ncrowdworkers, transforming human involvement from tedious scene setup,\nresetting, and safety supervision into lightweight preference comparisons. To\nmeasure robustness, we systematically perturb simulated environments along\nmultiple axes, such as textures and object placements, stress-testing policy\ngeneralization under controlled variation. The result is a continuously\nevolving, reproducible, and scalable benchmark for real-world trained robot\nmanipulation policies, addressing a critical missing capability in today's\nrobotics landscape.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u5668\u4eba\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\u8bc4\u4f30\u8f6c\u79fb\u5230\u5927\u89c4\u6a21\u6a21\u62df\u73af\u5883\u4e2d\uff0c\u7ed3\u5408\u5728\u7ebf\u4eba\u7c7b\u53cd\u9988\uff0c\u89e3\u51b3\u4e86\u73b0\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u6d4b\u8bd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u6d4b\u8bd5\u5b58\u5728\u52b3\u52a8\u5bc6\u96c6\u3001\u901f\u5ea6\u6162\u3001\u4e0d\u5b89\u5168\u3001\u96be\u4ee5\u590d\u73b0\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u6a21\u62df\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u8bc4\u4f30\u4ece\u771f\u5b9e\u4e16\u754c\u6f14\u793a\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u4e14\u673a\u5668\u4eba\u6210\u529f\u5b9a\u4e49\u5f80\u5f80\u4f9d\u8d56\u4eba\u7c7b\u5bf9\u6267\u884c\u8d28\u91cf\u7684\u7ec6\u5fae\u5224\u65ad\u3002", "method": "\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u30012D\u52303D\u751f\u6210\u5efa\u6a21\u548c\u53ef\u5fae\u5206\u6e32\u67d3\u6280\u672f\uff0c\u5c06\u5e7f\u6cdb\u4f7f\u7528\u7684\u673a\u5668\u4eba\u6570\u636e\u96c6\u4e2d\u7684\u89c6\u9891\u6f14\u793a\u81ea\u52a8\u8f6c\u6362\u4e3a\u6a21\u62df\u5bf9\u5e94\u7269\uff0c\u5728\u6570\u5b57\u5b6a\u751f\u73af\u5883\u4e2d\u4f7f\u7528\u81ea\u52a8\u5316VLM\u5f15\u5bfc\u8bc4\u5206\u548c\u53ef\u6269\u5c55\u7684\u4eba\u7c7b\u504f\u597d\u5224\u65ad\u6765\u8bc4\u4f30VLA\u7b56\u7565\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6301\u7eed\u6f14\u8fdb\u3001\u53ef\u590d\u73b0\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u51c6\u6d4b\u8bd5\u7cfb\u7edf\uff0c\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u6270\u52a8\u6a21\u62df\u73af\u5883\u6765\u6d4b\u8bd5\u7b56\u7565\u7684\u9c81\u68d2\u6027\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u673a\u5668\u4eba\u9886\u57df\u7684\u5173\u952e\u7f3a\u5931\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5c06\u4eba\u7c7b\u53c2\u4e0e\u4ece\u7e41\u7410\u7684\u573a\u666f\u8bbe\u7f6e\u3001\u91cd\u7f6e\u548c\u5b89\u5168\u76d1\u7763\u8f6c\u53d8\u4e3a\u8f7b\u91cf\u7ea7\u504f\u597d\u6bd4\u8f83\uff0c\u4e3a\u771f\u5b9e\u4e16\u754c\u8bad\u7ec3\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u7b56\u7565\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.23474", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23474", "abs": "https://arxiv.org/abs/2510.23474", "authors": ["Shames Al Mandalawi", "Muzakkiruddin Ahmed Mohammed", "Hendrika Maclean", "Mert Can Cakmak", "John R. Talburt"], "title": "Policy-Aware Generative AI for Safe, Auditable Data Access Governance", "comment": "The 17th International Conference on Knowledge and Systems\n  Engineering", "summary": "Enterprises need access decisions that satisfy least privilege, comply with\nregulations, and remain auditable. We present a policy aware controller that\nuses a large language model (LLM) to interpret natural language requests\nagainst written policies and metadata, not raw data. The system, implemented\nwith Google Gemini~2.0 Flash, executes a six-stage reasoning framework (context\ninterpretation, user validation, data classification, business purpose test,\ncompliance mapping, and risk synthesis) with early hard policy gates and deny\nby default. It returns APPROVE, DENY, CONDITIONAL together with cited controls\nand a machine readable rationale. We evaluate on fourteen canonical cases\nacross seven scenario families using a privacy preserving benchmark. Results\nshow Exact Decision Match improving from 10/14 to 13/14 (92.9\\%) after applying\npolicy gates, DENY recall rising to 1.00, False Approval Rate on must-deny\nfamilies dropping to 0, and Functional Appropriateness and Compliance Adherence\nat 14/14. Expert ratings of rationale quality are high, and median latency is\nunder one minute. These findings indicate that policy constrained LLM\nreasoning, combined with explicit gates and audit trails, can translate human\nreadable policies into safe, compliant, and traceable machine decisions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u7b56\u7565\u611f\u77e5\u63a7\u5236\u5668\uff0c\u4f7f\u7528\u516d\u9636\u6bb5\u63a8\u7406\u6846\u67b6\u6765\u89e3\u91ca\u81ea\u7136\u8bed\u8a00\u8bf7\u6c42\uff0c\u7ed3\u5408\u786c\u7b56\u7565\u95e8\u63a7\u548c\u9ed8\u8ba4\u62d2\u7edd\u673a\u5236\uff0c\u5b9e\u73b0\u5b89\u5168\u3001\u5408\u89c4\u4e14\u53ef\u8ffd\u8e2a\u7684\u8bbf\u95ee\u51b3\u7b56\u3002", "motivation": "\u4f01\u4e1a\u9700\u8981\u6ee1\u8db3\u6700\u5c0f\u6743\u9650\u3001\u5408\u89c4\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\u7684\u8bbf\u95ee\u51b3\u7b56\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u81ea\u7136\u8bed\u8a00\u8bf7\u6c42\u4e0e\u4e66\u9762\u7b56\u7565\u7684\u5339\u914d\u3002", "method": "\u4f7f\u7528Google Gemini 2.0 Flash\u5b9e\u73b0\u516d\u9636\u6bb5\u63a8\u7406\u6846\u67b6\uff1a\u4e0a\u4e0b\u6587\u89e3\u91ca\u3001\u7528\u6237\u9a8c\u8bc1\u3001\u6570\u636e\u5206\u7c7b\u3001\u4e1a\u52a1\u76ee\u7684\u6d4b\u8bd5\u3001\u5408\u89c4\u6620\u5c04\u548c\u98ce\u9669\u7efc\u5408\uff0c\u91c7\u7528\u65e9\u671f\u786c\u7b56\u7565\u95e8\u63a7\u548c\u9ed8\u8ba4\u62d2\u7edd\u673a\u5236\u3002", "result": "\u572814\u4e2a\u6807\u51c6\u6848\u4f8b\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff1a\u7cbe\u786e\u51b3\u7b56\u5339\u914d\u4ece10/14\u63d0\u5347\u523013/14\uff0892.9%\uff09\uff0c\u62d2\u7edd\u53ec\u56de\u7387\u8fbe\u52301.00\uff0c\u5fc5\u987b\u62d2\u7edd\u573a\u666f\u7684\u8bef\u6279\u51c6\u7387\u964d\u4e3a0\uff0c\u529f\u80fd\u9002\u5f53\u6027\u548c\u5408\u89c4\u6027\u5747\u4e3a14/14\uff0c\u4e13\u5bb6\u5bf9\u63a8\u7406\u8d28\u91cf\u8bc4\u4ef7\u9ad8\uff0c\u4e2d\u4f4d\u5ef6\u8fdf\u4f4e\u4e8e1\u5206\u949f\u3002", "conclusion": "\u7b56\u7565\u7ea6\u675f\u7684LLM\u63a8\u7406\u7ed3\u5408\u663e\u5f0f\u95e8\u63a7\u548c\u5ba1\u8ba1\u8ffd\u8e2a\uff0c\u80fd\u591f\u5c06\u4eba\u7c7b\u53ef\u8bfb\u7b56\u7565\u8f6c\u5316\u4e3a\u5b89\u5168\u3001\u5408\u89c4\u4e14\u53ef\u8ffd\u8e2a\u7684\u673a\u5668\u51b3\u7b56\u3002"}}
{"id": "2510.23576", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23576", "abs": "https://arxiv.org/abs/2510.23576", "authors": ["Anqi Li", "Zhiyong Wang", "Jiazhao Zhang", "Minghan Li", "Yunpeng Qi", "Zhibo Chen", "Zhizheng Zhang", "He Wang"], "title": "UrbanVLA: A Vision-Language-Action Model for Urban Micromobility", "comment": null, "summary": "Urban micromobility applications, such as delivery robots, demand reliable\nnavigation across large-scale urban environments while following long-horizon\nroute instructions. This task is particularly challenging due to the dynamic\nand unstructured nature of real-world city areas, yet most existing navigation\nmethods remain tailored to short-scale and controllable scenarios. Effective\nurban micromobility requires two complementary levels of navigation skills:\nlow-level capabilities such as point-goal reaching and obstacle avoidance, and\nhigh-level capabilities, such as route-visual alignment. To this end, we\npropose UrbanVLA, a route-conditioned Vision-Language-Action (VLA) framework\ndesigned for scalable urban navigation. Our method explicitly aligns noisy\nroute waypoints with visual observations during execution, and subsequently\nplans trajectories to drive the robot. To enable UrbanVLA to master both levels\nof navigation, we employ a two-stage training pipeline. The process begins with\nSupervised Fine-Tuning (SFT) using simulated environments and trajectories\nparsed from web videos. This is followed by Reinforcement Fine-Tuning (RFT) on\na mixture of simulation and real-world data, which enhances the model's safety\nand adaptability in real-world settings. Experiments demonstrate that UrbanVLA\nsurpasses strong baselines by more than 55% in the SocialNav task on MetaUrban.\nFurthermore, UrbanVLA achieves reliable real-world navigation, showcasing both\nscalability to large-scale urban environments and robustness against real-world\nuncertainties.", "AI": {"tldr": "UrbanVLA\u662f\u4e00\u4e2a\u7528\u4e8e\u57ce\u5e02\u5fae\u79fb\u52a8\u5bfc\u822a\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u5b9e\u73b0\u5927\u89c4\u6a21\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u53ef\u9760\u5bfc\u822a\uff0c\u5728MetaUrban\u7684SocialNav\u4efb\u52a1\u4e2d\u6027\u80fd\u63d0\u5347\u8d85\u8fc755%\u3002", "motivation": "\u73b0\u6709\u7684\u5bfc\u822a\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u5c0f\u89c4\u6a21\u548c\u53ef\u63a7\u573a\u666f\uff0c\u800c\u57ce\u5e02\u5fae\u79fb\u52a8\u5e94\u7528\uff08\u5982\u914d\u9001\u673a\u5668\u4eba\uff09\u9700\u8981\u5728\u52a8\u6001\u3001\u975e\u7ed3\u6784\u5316\u7684\u57ce\u5e02\u73af\u5883\u4e2d\u8fdb\u884c\u957f\u8ddd\u79bb\u53ef\u9760\u5bfc\u822a\uff0c\u8fd9\u9700\u8981\u540c\u65f6\u5177\u5907\u4f4e\u7ea7\u7684\u70b9\u76ee\u6807\u5230\u8fbe\u548c\u969c\u788d\u7269\u907f\u969c\u80fd\u529b\uff0c\u4ee5\u53ca\u9ad8\u7ea7\u7684\u8def\u7ebf-\u89c6\u89c9\u5bf9\u9f50\u80fd\u529b\u3002", "method": "\u63d0\u51faUrbanVLA\u6846\u67b6\uff0c\u5728\u5bfc\u822a\u6267\u884c\u8fc7\u7a0b\u4e2d\u663e\u5f0f\u5bf9\u9f50\u566a\u58f0\u8def\u7ebf\u8def\u6807\u70b9\u548c\u89c6\u89c9\u89c2\u6d4b\uff0c\u7136\u540e\u89c4\u5212\u673a\u5668\u4eba\u8f68\u8ff9\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u9996\u5148\u4f7f\u7528\u6a21\u62df\u73af\u5883\u548c\u7f51\u7edc\u89c6\u9891\u8f68\u8ff9\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff0c\u7136\u540e\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u6df7\u5408\u4e0a\u8fdb\u884c\u5f3a\u5316\u5fae\u8c03\u3002", "result": "\u5728MetaUrban\u7684SocialNav\u4efb\u52a1\u4e2d\uff0cUrbanVLA\u6bd4\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u6027\u80fd\u63d0\u5347\u8d85\u8fc755%\u3002\u540c\u65f6\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u73b0\u5b9e\u4e16\u754c\u5bfc\u822a\uff0c\u5c55\u793a\u4e86\u5bf9\u5927\u89c4\u6a21\u57ce\u5e02\u73af\u5883\u7684\u53ef\u6269\u5c55\u6027\u548c\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e0d\u786e\u5b9a\u6027\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "UrbanVLA\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u57ce\u5e02\u5fae\u79fb\u52a8\u5bfc\u822a\u7684\u6311\u6218\uff0c\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u5efa\u6a21\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u5728\u5927\u89c4\u6a21\u52a8\u6001\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u53ef\u9760\u5bfc\u822a\u3002"}}
{"id": "2510.23476", "categories": ["cs.AI", "cs.HC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23476", "abs": "https://arxiv.org/abs/2510.23476", "authors": ["Sima Noorani", "Shayan Kiyani", "George Pappas", "Hamed Hassani"], "title": "Human-AI Collaborative Uncertainty Quantification", "comment": null, "summary": "AI predictive systems are increasingly embedded in decision making pipelines,\nshaping high stakes choices once made solely by humans. Yet robust decisions\nunder uncertainty still rely on capabilities that current AI lacks: domain\nknowledge not captured by data, long horizon context, and reasoning grounded in\nthe physical world. This gap has motivated growing efforts to design\ncollaborative frameworks that combine the complementary strengths of humans and\nAI. This work advances this vision by identifying the fundamental principles of\nHuman AI collaboration within uncertainty quantification, a key component of\nreliable decision making. We introduce Human AI Collaborative Uncertainty\nQuantification, a framework that formalizes how an AI model can refine a human\nexpert's proposed prediction set with two goals: avoiding counterfactual harm,\nensuring the AI does not degrade correct human judgments, and complementarity,\nenabling recovery of correct outcomes the human missed. At the population\nlevel, we show that the optimal collaborative prediction set follows an\nintuitive two threshold structure over a single score function, extending a\nclassical result in conformal prediction. Building on this insight, we develop\npractical offline and online calibration algorithms with provable distribution\nfree finite sample guarantees. The online method adapts to distribution shifts,\nincluding human behavior evolving through interaction with AI, a phenomenon we\ncall Human to AI Adaptation. Experiments across image classification,\nregression, and text based medical decision making show that collaborative\nprediction sets consistently outperform either agent alone, achieving higher\ncoverage and smaller set sizes across various conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86Human AI Collaborative Uncertainty Quantification\u6846\u67b6\uff0c\u901a\u8fc7AI\u6a21\u578b\u4f18\u5316\u4eba\u7c7b\u4e13\u5bb6\u7684\u9884\u6d4b\u96c6\uff0c\u907f\u514d\u53cd\u4e8b\u5b9e\u4f24\u5bb3\u5e76\u5b9e\u73b0\u4e92\u8865\u6027\uff0c\u5728\u56fe\u50cf\u5206\u7c7b\u3001\u56de\u5f52\u548c\u533b\u7597\u51b3\u7b56\u7b49\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5355\u72ec\u7684\u4eba\u7c7b\u6216AI\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u3001\u957f\u671f\u4e0a\u4e0b\u6587\u548c\u7269\u7406\u4e16\u754c\u63a8\u7406\u80fd\u529b\uff0c\u9700\u8981\u7ed3\u5408\u4eba\u7c7b\u548cAI\u7684\u4e92\u8865\u4f18\u52bf\u6765\u6784\u5efa\u53ef\u9760\u7684\u534f\u4f5c\u51b3\u7b56\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u9608\u503c\u7ed3\u6784\u7684\u9884\u6d4b\u96c6\u4f18\u5316\u7b97\u6cd5\uff0c\u5305\u62ec\u79bb\u7ebf\u548c\u5728\u7ebf\u6821\u51c6\u65b9\u6cd5\uff0c\u80fd\u591f\u9002\u5e94\u5206\u5e03\u6f02\u79fb\u548c\u4eba\u7c7b\u884c\u4e3a\u53d8\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u534f\u4f5c\u9884\u6d4b\u96c6\u5728\u8986\u76d6\u7387\u548c\u96c6\u5408\u5927\u5c0f\u65b9\u9762\u5747\u4f18\u4e8e\u5355\u72ec\u7684\u4eba\u7c7b\u6216AI\uff0c\u5728\u5404\u79cd\u6761\u4ef6\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "Human AI Collaborative Uncertainty Quantification\u6846\u67b6\u4e3a\u53ef\u9760\u51b3\u7b56\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u4eba\u7c7b\u4e0eAI\u534f\u4f5c\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2510.23487", "categories": ["cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2510.23487", "abs": "https://arxiv.org/abs/2510.23487", "authors": ["Roham Koohestani", "Ziyou Li", "Anton Podkopaev", "Maliheh Izadi"], "title": "Are Agents Just Automata? On the Formal Equivalence Between Agentic AI and the Chomsky Hierarchy", "comment": null, "summary": "This paper establishes a formal equivalence between the architectural classes\nof modern agentic AI systems and the abstract machines of the Chomsky\nhierarchy. We posit that the memory architecture of an AI agent is the\ndefinitive feature determining its computational power and that it directly\nmaps it to a corresponding class of automaton. Specifically, we demonstrate\nthat simple reflex agents are equivalent to Finite Automata, hierarchical\ntask-decomposition agents are equivalent to Pushdown Automata, and agents\nemploying readable/writable memory for reflection are equivalent to TMs. This\nAutomata-Agent Framework provides a principled methodology for right-sizing\nagent architectures to optimize computational efficiency and cost. More\ncritically, it creates a direct pathway to formal verification, enables the\napplication of mature techniques from automata theory to guarantee agent safety\nand predictability. By classifying agents, we can formally delineate the\nboundary between verifiable systems and those whose behavior is fundamentally\nundecidable. We address the inherent probabilistic nature of LLM-based agents\nby extending the framework to probabilistic automata that allow quantitative\nrisk analysis. The paper concludes by outlining an agenda for developing static\nanalysis tools and grammars for agentic frameworks.", "AI": {"tldr": "\u672c\u6587\u5efa\u7acb\u4e86\u73b0\u4ee3\u667a\u80fd\u4f53AI\u7cfb\u7edf\u67b6\u6784\u4e0e\u4e54\u59c6\u65af\u57fa\u5c42\u6b21\u7ed3\u6784\u62bd\u8c61\u673a\u4e4b\u95f4\u7684\u5f62\u5f0f\u7b49\u4ef7\u5173\u7cfb\uff0c\u63d0\u51fa\u57fa\u4e8e\u5185\u5b58\u67b6\u6784\u7684\u667a\u80fd\u4f53\u8ba1\u7b97\u80fd\u529b\u5206\u7c7b\u6846\u67b6\u3002", "motivation": "\u4e3a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u63d0\u4f9b\u5f62\u5f0f\u5316\u7406\u8bba\u57fa\u7840\uff0c\u5b9e\u73b0\u67b6\u6784\u4f18\u5316\u3001\u5f62\u5f0f\u9a8c\u8bc1\u548c\u5b89\u5168\u4fdd\u969c\uff0c\u5e94\u7528\u6210\u719f\u7684\u81ea\u52a8\u673a\u7406\u8bba\u6280\u672f\u6765\u4fdd\u8bc1\u667a\u80fd\u4f53\u7684\u5b89\u5168\u6027\u548c\u53ef\u9884\u6d4b\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u667a\u80fd\u4f53\u7684\u5185\u5b58\u67b6\u6784\u7279\u5f81\uff0c\u5c06\u5176\u6620\u5c04\u5230\u5bf9\u5e94\u7684\u81ea\u52a8\u673a\u7c7b\u522b\uff1a\u7b80\u5355\u53cd\u5c04\u667a\u80fd\u4f53\u5bf9\u5e94\u6709\u9650\u81ea\u52a8\u673a\uff0c\u5206\u5c42\u4efb\u52a1\u5206\u89e3\u667a\u80fd\u4f53\u5bf9\u5e94\u4e0b\u63a8\u81ea\u52a8\u673a\uff0c\u5177\u6709\u8bfb\u5199\u5185\u5b58\u7684\u53cd\u601d\u667a\u80fd\u4f53\u5bf9\u5e94\u56fe\u7075\u673a\u3002", "result": "\u5efa\u7acb\u4e86\u667a\u80fd\u4f53-\u81ea\u52a8\u673a\u6846\u67b6\uff0c\u80fd\u591f\u5bf9\u667a\u80fd\u4f53\u8fdb\u884c\u5f62\u5f0f\u5316\u5206\u7c7b\uff0c\u660e\u786e\u53ef\u9a8c\u8bc1\u7cfb\u7edf\u4e0e\u884c\u4e3a\u4e0d\u53ef\u5224\u5b9a\u7cfb\u7edf\u4e4b\u95f4\u7684\u754c\u9650\uff0c\u5e76\u6269\u5c55\u5230\u6982\u7387\u81ea\u52a8\u673a\u4ee5\u5904\u7406LLM\u7684\u968f\u673a\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u667a\u80fd\u4f53\u67b6\u6784\u4f18\u5316\u548c\u5f62\u5f0f\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u4e86\u5f00\u53d1\u9759\u6001\u5206\u6790\u5de5\u5177\u548c\u667a\u80fd\u4f53\u6846\u67b6\u8bed\u6cd5\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2510.23506", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.23506", "abs": "https://arxiv.org/abs/2510.23506", "authors": ["Hyeongseop Rha", "Jeong Hun Yeo", "Yeonju Kim", "Yong Man Ro"], "title": "Emotion-Coherent Reasoning for Multimodal LLMs via Emotional Rationale Verifier", "comment": "16 pages, 11 figures", "summary": "The recent advancement of Multimodal Large Language Models (MLLMs) is\ntransforming human-computer interaction (HCI) from surface-level exchanges into\nmore nuanced and emotionally intelligent communication. To realize this shift,\nemotion understanding becomes essential allowing systems to capture subtle cues\nunderlying user intent. Furthermore, providing faithful explanations for\npredicted emotions is crucial to ensure interpretability and build user trust.\nHowever, current MLLM-based methods often generate emotion explanations that\ndiverge from the target labels and sometimes even contradict their own\npredicted emotions. This inconsistency poses a critical risk for\nmisunderstanding and erodes reliability in interactive settings. To address\nthis, we propose a novel approach: the Emotional Rationale Verifier (ERV) and\nan Explanation Reward. Our method guides the model to produce reasoning that is\nexplicitly consistent with the target emotion during multimodal emotion\nrecognition without modifying the model architecture or requiring additional\npaired video-description annotations. Our method significantly improves\nfaithful explanation-prediction consistency and explanation emotion accuracy on\nthe MAFW and DFEW datasets. Through extensive experiments and human\nevaluations, we show that our approach not only enhances alignment between\nexplanation and prediction but also empowers MLLMs to deliver emotionally\ncoherent, trustworthy interactions, marking a key step toward truly human-like\nHCI systems.", "AI": {"tldr": "\u63d0\u51fa\u60c5\u611f\u63a8\u7406\u9a8c\u8bc1\u5668(ERV)\u548c\u89e3\u91ca\u5956\u52b1\u65b9\u6cd5\uff0c\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u8bc6\u522b\u4e2d\u89e3\u91ca\u4e0e\u9884\u6d4b\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u67b6\u6784\u6216\u989d\u5916\u6807\u6ce8\u6570\u636e\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u8bc6\u522b\u4e2d\u751f\u6210\u7684\u60c5\u611f\u89e3\u91ca\u5e38\u5e38\u4e0e\u76ee\u6807\u6807\u7b7e\u4e0d\u7b26\uff0c\u751a\u81f3\u4e0e\u81ea\u8eab\u9884\u6d4b\u7684\u60c5\u611f\u76f8\u77db\u76fe\uff0c\u8fd9\u79cd\u4e0d\u4e00\u81f4\u6027\u4f1a\u964d\u4f4e\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u7528\u6237\u4fe1\u4efb\u5ea6\u3002", "method": "\u63d0\u51fa\u60c5\u611f\u63a8\u7406\u9a8c\u8bc1\u5668(ERV)\u548c\u89e3\u91ca\u5956\u52b1\u673a\u5236\uff0c\u5f15\u5bfc\u6a21\u578b\u5728\u60c5\u611f\u8bc6\u522b\u8fc7\u7a0b\u4e2d\u751f\u6210\u4e0e\u76ee\u6807\u60c5\u611f\u660e\u786e\u4e00\u81f4\u7684\u63a8\u7406\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u67b6\u6784\u6216\u989d\u5916\u89c6\u9891\u63cf\u8ff0\u6807\u6ce8\u3002", "result": "\u5728MAFW\u548cDFEW\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u89e3\u91ca-\u9884\u6d4b\u4e00\u81f4\u6027\u548c\u89e3\u91ca\u60c5\u611f\u51c6\u786e\u6027\uff0c\u901a\u8fc7\u5b9e\u9a8c\u548c\u4eba\u5de5\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u589e\u5f3a\u4e86\u89e3\u91ca\u4e0e\u9884\u6d4b\u7684\u5bf9\u9f50\u6027\uff0c\u8fd8\u4f7f\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u60c5\u611f\u4e00\u81f4\u3001\u53ef\u4fe1\u8d56\u7684\u4ea4\u4e92\uff0c\u662f\u5b9e\u73b0\u771f\u6b63\u7c7b\u4ebaHCI\u7cfb\u7edf\u7684\u5173\u952e\u4e00\u6b65\u3002"}}
{"id": "2510.23524", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23524", "abs": "https://arxiv.org/abs/2510.23524", "authors": ["KC Santosh", "Rodrigue Rizk", "Longwei Wang"], "title": "Toward Carbon-Neutral Human AI: Rethinking Data, Computation, and Learning Paradigms for Sustainable Intelligence", "comment": "9 pages, 3 figures", "summary": "The rapid advancement of Artificial Intelligence (AI) has led to\nunprecedented computational demands, raising significant environmental and\nethical concerns. This paper critiques the prevailing reliance on large-scale,\nstatic datasets and monolithic training paradigms, advocating for a shift\ntoward human-inspired, sustainable AI solutions. We introduce a novel\nframework, Human AI (HAI), which emphasizes incremental learning, carbon-aware\noptimization, and human-in-the-loop collaboration to enhance adaptability,\nefficiency, and accountability. By drawing parallels with biological cognition\nand leveraging dynamic architectures, HAI seeks to balance performance with\necological responsibility. We detail the theoretical foundations, system\ndesign, and operational principles that enable AI to learn continuously and\ncontextually while minimizing carbon footprints and human annotation costs. Our\napproach addresses pressing challenges in active learning, continual\nadaptation, and energy-efficient model deployment, offering a pathway toward\nresponsible, human-centered artificial intelligence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHAI\uff08Human AI\uff09\u7684\u65b0\u578b\u53ef\u6301\u7eedAI\u6846\u67b6\uff0c\u5f3a\u8c03\u589e\u91cf\u5b66\u4e60\u3001\u78b3\u611f\u77e5\u4f18\u5316\u548c\u4eba\u673a\u534f\u4f5c\uff0c\u4ee5\u89e3\u51b3AI\u53d1\u5c55\u5e26\u6765\u7684\u73af\u5883\u548c\u4f26\u7406\u95ee\u9898\u3002", "motivation": "AI\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u5de8\u5927\u7684\u8ba1\u7b97\u9700\u6c42\uff0c\u5f15\u53d1\u4e86\u73af\u5883\u548c\u4f26\u7406\u62c5\u5fe7\u3002\u6279\u8bc4\u5f53\u524d\u4f9d\u8d56\u5927\u89c4\u6a21\u9759\u6001\u6570\u636e\u96c6\u548c\u5355\u4e00\u8bad\u7ec3\u8303\u5f0f\u7684\u505a\u6cd5\uff0c\u5021\u5bfc\u8f6c\u5411\u4eba\u7c7b\u542f\u53d1\u7684\u53ef\u6301\u7eedAI\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f15\u5165HAI\u6846\u67b6\uff0c\u57fa\u4e8e\u751f\u7269\u8ba4\u77e5\u539f\u7406\uff0c\u91c7\u7528\u52a8\u6001\u67b6\u6784\uff0c\u5b9e\u73b0\u589e\u91cf\u5b66\u4e60\u3001\u78b3\u611f\u77e5\u4f18\u5316\u548c\u4eba\u673a\u534f\u4f5c\u3002\u8be6\u7ec6\u9610\u8ff0\u4e86\u7406\u8bba\u57fa\u7840\u3001\u7cfb\u7edf\u8bbe\u8ba1\u548c\u64cd\u4f5c\u539f\u5219\u3002", "result": "HAI\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u6301\u7eed\u60c5\u5883\u5b66\u4e60\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u78b3\u8db3\u8ff9\u548c\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u3002\u89e3\u51b3\u4e86\u4e3b\u52a8\u5b66\u4e60\u3001\u6301\u7eed\u9002\u5e94\u548c\u8282\u80fd\u6a21\u578b\u90e8\u7f72\u7b49\u5173\u952e\u6311\u6218\u3002", "conclusion": "HAI\u4e3a\u8d1f\u8d23\u4efb\u3001\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u884c\u8def\u5f84\uff0c\u5e73\u8861\u4e86\u6027\u80fd\u4e0e\u751f\u6001\u8d23\u4efb\uff0c\u63a8\u52a8\u4e86\u53ef\u6301\u7eedAI\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.23532", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23532", "abs": "https://arxiv.org/abs/2510.23532", "authors": ["Anirban Das", "Irtaza Khalid", "Rafael Pe\u00f1aloza", "Steven Schockaert"], "title": "When No Paths Lead to Rome: Benchmarking Systematic Neural Relational Reasoning", "comment": "accepted at NeurIPS 2025 D&B track", "summary": "Designing models that can learn to reason in a systematic way is an important\nand long-standing challenge. In recent years, a wide range of solutions have\nbeen proposed for the specific case of systematic relational reasoning,\nincluding Neuro-Symbolic approaches, variants of the Transformer architecture,\nand specialised Graph Neural Networks. However, existing benchmarks for\nsystematic relational reasoning focus on an overly simplified setting, based on\nthe assumption that reasoning can be reduced to composing relational paths. In\nfact, this assumption is hard-baked into the architecture of several recent\nmodels, leading to approaches that can perform well on existing benchmarks but\nare difficult to generalise to other settings. To support further progress in\nthe field of systematic relational reasoning with neural networks, we introduce\nNoRA, a new benchmark which adds several levels of difficulty and requires\nmodels to go beyond path-based reasoning.", "AI": {"tldr": "NoRA\u662f\u4e00\u4e2a\u65b0\u7684\u7cfb\u7edf\u6027\u5173\u7cfb\u63a8\u7406\u57fa\u51c6\uff0c\u5b83\u589e\u52a0\u4e86\u591a\u4e2a\u96be\u5ea6\u7ea7\u522b\uff0c\u8981\u6c42\u6a21\u578b\u8d85\u8d8a\u57fa\u4e8e\u8def\u5f84\u7684\u63a8\u7406\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u6027\u5173\u7cfb\u63a8\u7406\u57fa\u51c6\u8fc7\u4e8e\u7b80\u5316\uff0c\u5047\u8bbe\u63a8\u7406\u53ef\u4ee5\u7b80\u5316\u4e3a\u7ec4\u5408\u5173\u7cfb\u8def\u5f84\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5f15\u5165NoRA\u57fa\u51c6\uff0c\u5305\u542b\u591a\u4e2a\u96be\u5ea6\u7ea7\u522b\uff0c\u6311\u6218\u6a21\u578b\u8d85\u8d8a\u8def\u5f84\u63a8\u7406\u7684\u80fd\u529b\u3002", "result": "NoRA\u57fa\u51c6\u4e3a\u7cfb\u7edf\u6027\u5173\u7cfb\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "conclusion": "NoRA\u57fa\u51c6\u5c06\u63a8\u52a8\u795e\u7ecf\u7f51\u7edc\u5728\u7cfb\u7edf\u6027\u5173\u7cfb\u63a8\u7406\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2510.23538", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.23538", "abs": "https://arxiv.org/abs/2510.23538", "authors": ["Qiushi Sun", "Jingyang Gong", "Yang Liu", "Qiaosheng Chen", "Lei Li", "Kai Chen", "Qipeng Guo", "Ben Kao", "Fei Yuan"], "title": "JanusCoder: Towards a Foundational Visual-Programmatic Interface for Code Intelligence", "comment": "Work in progress", "summary": "The scope of neural code intelligence is rapidly expanding beyond text-based\nsource code to encompass the rich visual outputs that programs generate. This\nvisual dimension is critical for advanced applications like flexible content\ngeneration and precise, program-driven editing of visualizations. However,\nprogress has been impeded by the scarcity of high-quality multimodal code data,\na bottleneck stemming from challenges in synthesis and quality assessment. To\naddress these challenges, we make contributions from both a data and modeling\nperspective. We first introduce a complete synthesis toolkit that leverages\nreciprocal synergies between data modalities to efficiently produce a\nlarge-scale, high-quality corpus spanning from standard charts to complex\ninteractive web UIs and code-driven animations. Leveraging this toolkit, we\nconstruct JanusCode-800K, the largest multimodal code corpus to date. This\npowers the training of our models, JanusCoder and JanusCoderV, which establish\na visual-programmatic interface for generating code from textual instructions,\nvisual inputs, or a combination of both. Our unified model is a departure from\nexisting approaches that build specialized models for isolated tasks. Extensive\nexperiments on both text-centric and vision-centric coding tasks demonstrate\nthe superior performance of the JanusCoder series, with our 7B to 14B scale\nmodels approaching or even exceeding the performance of commercial models.\nFurthermore, extensive analysis provides key insights into harmonizing\nprogrammatic logic with its visual expression. Our code and checkpoints will\nare available at https://github.com/InternLM/JanusCoder.", "AI": {"tldr": "\u63d0\u51fa\u4e86JanusCode-800K\uff0c\u8fd9\u662f\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u591a\u6a21\u6001\u4ee3\u7801\u8bed\u6599\u5e93\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bad\u7ec3\u4e86JanusCoder\u7cfb\u5217\u6a21\u578b\uff0c\u5728\u6587\u672c\u548c\u89c6\u89c9\u7f16\u7801\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u795e\u7ecf\u4ee3\u7801\u667a\u80fd\u7684\u8303\u56f4\u6b63\u5728\u4ece\u57fa\u4e8e\u6587\u672c\u7684\u6e90\u4ee3\u7801\u6269\u5c55\u5230\u7a0b\u5e8f\u751f\u6210\u7684\u4e30\u5bcc\u89c6\u89c9\u8f93\u51fa\uff0c\u4f46\u9ad8\u8d28\u91cf\u591a\u6a21\u6001\u4ee3\u7801\u6570\u636e\u7684\u7a00\u7f3a\u963b\u788d\u4e86\u8fdb\u5c55\u3002", "method": "\u9996\u5148\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u5408\u6210\u5de5\u5177\u5305\uff0c\u5229\u7528\u6570\u636e\u6a21\u6001\u4e4b\u95f4\u7684\u534f\u540c\u4f5c\u7528\u9ad8\u6548\u751f\u6210\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u8bed\u6599\u5e93\uff0c\u7136\u540e\u8bad\u7ec3JanusCoder\u548cJanusCoderV\u6a21\u578b\uff0c\u5efa\u7acb\u89c6\u89c9-\u7a0b\u5e8f\u63a5\u53e3\u3002", "result": "JanusCoder\u7cfb\u5217\u5728\u6587\u672c\u548c\u89c6\u89c9\u7f16\u7801\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u5353\u8d8a\u6027\u80fd\uff0c7B\u523014B\u89c4\u6a21\u7684\u6a21\u578b\u63a5\u8fd1\u751a\u81f3\u8d85\u8fc7\u5546\u4e1a\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u534f\u8c03\u7a0b\u5e8f\u903b\u8f91\u4e0e\u5176\u89c6\u89c9\u8868\u8fbe\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\uff0c\u7edf\u4e00\u6a21\u578b\u65b9\u6cd5\u4f18\u4e8e\u4e3a\u5b64\u7acb\u4efb\u52a1\u6784\u5efa\u4e13\u95e8\u6a21\u578b\u7684\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2510.23553", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23553", "abs": "https://arxiv.org/abs/2510.23553", "authors": ["Alexis Ellis", "Stacie Severyn", "Fjoll\u00eb Novakazi", "Hadi Banaee", "Cogan Shimizu"], "title": "OntoPret: An Ontology for the Interpretation of Human Behavior", "comment": null, "summary": "As human machine teaming becomes central to paradigms like Industry 5.0, a\ncritical need arises for machines to safely and effectively interpret complex\nhuman behaviors. A research gap currently exists between techno centric robotic\nframeworks, which often lack nuanced models of human behavior, and descriptive\nbehavioral ontologies, which are not designed for real time, collaborative\ninterpretation. This paper addresses this gap by presenting OntoPret, an\nontology for the interpretation of human behavior. Grounded in cognitive\nscience and a modular engineering methodology, OntoPret provides a formal,\nmachine processable framework for classifying behaviors, including task\ndeviations and deceptive actions. We demonstrate its adaptability across two\ndistinct use cases manufacturing and gameplay and establish the semantic\nfoundations necessary for advanced reasoning about human intentions.", "AI": {"tldr": "OntoPret\u662f\u4e00\u4e2a\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u548c\u6a21\u5757\u5316\u5de5\u7a0b\u65b9\u6cd5\u7684\u4eba\u7c7b\u884c\u4e3a\u89e3\u91ca\u672c\u4f53\u8bba\uff0c\u4e3a\u673a\u5668\u63d0\u4f9b\u53ef\u5904\u7406\u7684\u884c\u4e3a\u5206\u7c7b\u6846\u67b6\uff0c\u652f\u6301\u4efb\u52a1\u504f\u5dee\u548c\u6b3a\u9a97\u884c\u4e3a\u7684\u8bc6\u522b\u3002", "motivation": "\u968f\u7740\u4eba\u673a\u534f\u4f5c\u5728\u5de5\u4e1a5.0\u7b49\u8303\u5f0f\u4e2d\u53d8\u5f97\u91cd\u8981\uff0c\u9700\u8981\u673a\u5668\u80fd\u5b89\u5168\u6709\u6548\u5730\u89e3\u91ca\u590d\u6742\u4eba\u7c7b\u884c\u4e3a\u3002\u5f53\u524d\u6280\u672f\u4e2d\u5fc3\u673a\u5668\u4eba\u6846\u67b6\u7f3a\u4e4f\u7ec6\u81f4\u7684\u4eba\u7c7b\u884c\u4e3a\u6a21\u578b\uff0c\u800c\u63cf\u8ff0\u6027\u884c\u4e3a\u672c\u4f53\u8bba\u53c8\u65e0\u6cd5\u5b9e\u73b0\u5b9e\u65f6\u534f\u4f5c\u89e3\u91ca\u3002", "method": "\u57fa\u4e8e\u8ba4\u77e5\u79d1\u5b66\u548c\u6a21\u5757\u5316\u5de5\u7a0b\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86OntoPret\u672c\u4f53\u8bba\uff0c\u63d0\u4f9b\u5f62\u5f0f\u5316\u7684\u673a\u5668\u53ef\u5904\u7406\u6846\u67b6\u6765\u5206\u7c7b\u884c\u4e3a\uff0c\u5305\u62ec\u4efb\u52a1\u504f\u5dee\u548c\u6b3a\u9a97\u884c\u4e3a\u3002", "result": "\u5728\u5236\u9020\u548c\u6e38\u620f\u4e24\u4e2a\u4e0d\u540c\u7528\u4f8b\u4e2d\u9a8c\u8bc1\u4e86OntoPret\u7684\u9002\u5e94\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u9ad8\u7ea7\u4eba\u7c7b\u610f\u56fe\u63a8\u7406\u6240\u9700\u7684\u8bed\u4e49\u57fa\u7840\u3002", "conclusion": "OntoPret\u586b\u8865\u4e86\u6280\u672f\u4e2d\u5fc3\u6846\u67b6\u4e0e\u63cf\u8ff0\u6027\u884c\u4e3a\u672c\u4f53\u8bba\u4e4b\u95f4\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u4e3a\u4eba\u673a\u534f\u4f5c\u4e2d\u7684\u884c\u4e3a\u89e3\u91ca\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.23564", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23564", "abs": "https://arxiv.org/abs/2510.23564", "authors": ["Zhaoyang Yu", "Jiayi Zhang", "Huixue Su", "Yufan Zhao", "Yifan Wu", "Mingyi Deng", "Jinyu Xiang", "Yizhang Lin", "Lingxiao Tang", "Yingchao Li", "Yuyu Luo", "Bang Liu", "Chenglin Wu"], "title": "ReCode: Unify Plan and Action for Universal Granularity Control", "comment": null, "summary": "Real-world tasks require decisions at varying granularities, and humans excel\nat this by leveraging a unified cognitive representation where planning is\nfundamentally understood as a high-level form of action. However, current Large\nLanguage Model (LLM)-based agents lack this crucial capability to operate\nfluidly across decision granularities. This limitation stems from existing\nparadigms that enforce a rigid separation between high-level planning and\nlow-level action, which impairs dynamic adaptability and limits generalization.\nWe propose ReCode (Recursive Code Generation), a novel paradigm that addresses\nthis limitation by unifying planning and action within a single code\nrepresentation. In this representation, ReCode treats high-level plans as\nabstract placeholder functions, which the agent then recursively decomposes\ninto finer-grained sub-functions until reaching primitive actions. This\nrecursive approach dissolves the rigid boundary between plan and action,\nenabling the agent to dynamically control its decision granularity.\nFurthermore, the recursive structure inherently generates rich,\nmulti-granularity training data, enabling models to learn hierarchical\ndecision-making processes. Extensive experiments show ReCode significantly\nsurpasses advanced baselines in inference performance and demonstrates\nexceptional data efficiency in training, validating our core insight that\nunifying planning and action through recursive code generation is a powerful\nand effective approach to achieving universal granularity control. The code is\navailable at https://github.com/FoundationAgents/ReCode.", "AI": {"tldr": "ReCode\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u9012\u5f52\u4ee3\u7801\u751f\u6210\u7edf\u4e00\u89c4\u5212\u548c\u884c\u52a8\u7684\u65b0\u8303\u5f0f\uff0c\u5c06\u9ad8\u7ea7\u8ba1\u5212\u89c6\u4e3a\u62bd\u8c61\u5360\u4f4d\u51fd\u6570\uff0c\u9012\u5f52\u5206\u89e3\u4e3a\u66f4\u7ec6\u7c92\u5ea6\u7684\u5b50\u51fd\u6570\uff0c\u5b9e\u73b0\u52a8\u6001\u51b3\u7b56\u7c92\u5ea6\u63a7\u5236\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\u9700\u8981\u5728\u4e0d\u540c\u7c92\u5ea6\u4e0a\u505a\u51b3\u7b56\uff0c\u4eba\u7c7b\u64c5\u957f\u5229\u7528\u7edf\u4e00\u7684\u8ba4\u77e5\u8868\u793a\u8fdb\u884c\u89c4\u5212\uff0c\u4f46\u5f53\u524d\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u7f3a\u4e4f\u8fd9\u79cd\u8de8\u7c92\u5ea6\u64cd\u4f5c\u7684\u7075\u6d3b\u6027\u3002\u73b0\u6709\u8303\u5f0f\u5728\u9ad8\u7ea7\u89c4\u5212\u548c\u4f4e\u7ea7\u884c\u52a8\u4e4b\u95f4\u8bbe\u7f6e\u4e86\u4e25\u683c\u5206\u79bb\uff0c\u9650\u5236\u4e86\u52a8\u6001\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "ReCode\u5c06\u89c4\u5212\u548c\u884c\u52a8\u7edf\u4e00\u5728\u5355\u4e00\u4ee3\u7801\u8868\u793a\u4e2d\uff0c\u5c06\u9ad8\u7ea7\u8ba1\u5212\u89c6\u4e3a\u62bd\u8c61\u5360\u4f4d\u51fd\u6570\uff0c\u7136\u540e\u9012\u5f52\u5730\u5c06\u5176\u5206\u89e3\u4e3a\u66f4\u7ec6\u7c92\u5ea6\u7684\u5b50\u51fd\u6570\uff0c\u76f4\u5230\u8fbe\u5230\u539f\u59cb\u884c\u52a8\u3002\u8fd9\u79cd\u9012\u5f52\u65b9\u6cd5\u6d88\u9664\u4e86\u8ba1\u5212\u548c\u884c\u52a8\u4e4b\u95f4\u7684\u4e25\u683c\u754c\u9650\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cReCode\u5728\u63a8\u7406\u6027\u80fd\u4e0a\u663e\u8457\u8d85\u8d8a\u5148\u8fdb\u57fa\u7ebf\uff0c\u5e76\u5728\u8bad\u7ec3\u4e2d\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6570\u636e\u6548\u7387\uff0c\u9a8c\u8bc1\u4e86\u901a\u8fc7\u9012\u5f52\u4ee3\u7801\u751f\u6210\u7edf\u4e00\u89c4\u5212\u548c\u884c\u52a8\u662f\u5b9e\u73b0\u901a\u7528\u7c92\u5ea6\u63a7\u5236\u7684\u6709\u6548\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u9012\u5f52\u4ee3\u7801\u751f\u6210\u5c06\u89c4\u5212\u548c\u884c\u52a8\u7edf\u4e00\u8d77\u6765\u662f\u5b9e\u73b0\u901a\u7528\u7c92\u5ea6\u63a7\u5236\u7684\u5f3a\u5927\u800c\u6709\u6548\u7684\u65b9\u6cd5\uff0cReCode\u8303\u5f0f\u89e3\u51b3\u4e86\u73b0\u6709LLM\u667a\u80fd\u4f53\u5728\u8de8\u7c92\u5ea6\u51b3\u7b56\u80fd\u529b\u4e0a\u7684\u5173\u952e\u9650\u5236\u3002"}}
{"id": "2510.23578", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23578", "abs": "https://arxiv.org/abs/2510.23578", "authors": ["Joachim Baumann", "Aleksandra Urman", "Ulrich Leicht-Deobald", "Zachary J. Roman", "Anik\u00f3 Hann\u00e1k", "Markus Christen"], "title": "Reduced AI Acceptance After the Generative AI Boom: Evidence From a Two-Wave Survey Study", "comment": null, "summary": "The rapid adoption of generative artificial intelligence (GenAI) technologies\nhas led many organizations to integrate AI into their products and services,\noften without considering user preferences. Yet, public attitudes toward AI\nuse, especially in impactful decision-making scenarios, are underexplored.\nUsing a large-scale two-wave survey study (n_wave1=1514, n_wave2=1488)\nrepresentative of the Swiss population, we examine shifts in public attitudes\ntoward AI before and after the launch of ChatGPT. We find that the GenAI boom\nis significantly associated with reduced public acceptance of AI (see Figure 1)\nand increased demand for human oversight in various decision-making contexts.\nThe proportion of respondents finding AI \"not acceptable at all\" increased from\n23% to 30%, while support for human-only decision-making rose from 18% to 26%.\nThese shifts have amplified existing social inequalities in terms of widened\neducational, linguistic, and gender gaps post-boom. Our findings challenge\nindustry assumptions about public readiness for AI deployment and highlight the\ncritical importance of aligning technological development with evolving public\npreferences.", "AI": {"tldr": "ChatGPT\u53d1\u5e03\u540e\uff0c\u516c\u4f17\u5bf9AI\u7684\u63a5\u53d7\u5ea6\u4e0b\u964d\uff0c\u5bf9\u4eba\u673a\u534f\u4f5c\u7684\u9700\u6c42\u589e\u52a0\uff0c\u5e76\u52a0\u5267\u4e86\u793e\u4f1a\u4e0d\u5e73\u7b49\u3002", "motivation": "\u63a2\u7d22\u751f\u6210\u5f0fAI\u6280\u672f\u5feb\u901f\u666e\u53ca\u80cc\u666f\u4e0b\uff0c\u516c\u4f17\u5bf9AI\u6001\u5ea6\u7684\u53d8\u5316\uff0c\u7279\u522b\u662f\u5728\u6709\u5f71\u54cd\u529b\u7684\u51b3\u7b56\u573a\u666f\u4e2d\u3002", "method": "\u4f7f\u7528\u745e\u58eb\u4eba\u53e3\u4ee3\u8868\u6027\u7684\u5927\u89c4\u6a21\u4e24\u6ce2\u8c03\u67e5\uff08n_wave1=1514\uff0cn_wave2=1488\uff09\uff0c\u6bd4\u8f83ChatGPT\u53d1\u5e03\u524d\u540e\u7684\u516c\u4f17\u6001\u5ea6\u53d8\u5316\u3002", "result": "\u751f\u6210\u5f0fAI\u70ed\u6f6e\u663e\u8457\u964d\u4f4e\u4e86\u516c\u4f17\u5bf9AI\u7684\u63a5\u53d7\u5ea6\uff0c\u589e\u52a0\u4e86\u5bf9\u4eba\u5de5\u76d1\u7763\u7684\u9700\u6c42\u3002\"\u5b8c\u5168\u4e0d\u53ef\u63a5\u53d7\"AI\u7684\u6bd4\u4f8b\u4ece23%\u5347\u81f330%\uff0c\u652f\u6301\u7eaf\u4eba\u5de5\u51b3\u7b56\u7684\u6bd4\u4f8b\u4ece18%\u5347\u81f326%\uff0c\u5e76\u6269\u5927\u4e86\u6559\u80b2\u3001\u8bed\u8a00\u548c\u6027\u522b\u5dee\u8ddd\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u884c\u4e1a\u5bf9\u516c\u4f17AI\u90e8\u7f72\u51c6\u5907\u5ea6\u7684\u5047\u8bbe\uff0c\u5f3a\u8c03\u6280\u672f\u53d1\u5c55\u5fc5\u987b\u4e0e\u4e0d\u65ad\u53d8\u5316\u7684\u516c\u4f17\u504f\u597d\u4fdd\u6301\u4e00\u81f4\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.23595", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23595", "abs": "https://arxiv.org/abs/2510.23595", "authors": ["Yixing Chen", "Yiding Wang", "Siqi Zhu", "Haofei Yu", "Tao Feng", "Muhan Zhan", "Mostofa Patwary", "Jiaxuan You"], "title": "Multi-Agent Evolve: LLM Self-Improve through Co-evolution", "comment": "29 pages, 4 figures, submitted to ICLR 2026", "summary": "Reinforcement Learning (RL) has demonstrated significant potential in\nenhancing the reasoning capabilities of large language models (LLMs). However,\nthe success of RL for LLMs heavily relies on human-curated datasets and\nverifiable rewards, which limit their scalability and generality. Recent\nSelf-Play RL methods, inspired by the success of the paradigm in games and Go,\naim to enhance LLM reasoning capabilities without human-annotated data.\nHowever, their methods primarily depend on a grounded environment for feedback\n(e.g., a Python interpreter or a game engine); extending them to general\ndomains remains challenging. To address these challenges, we propose\nMulti-Agent Evolve (MAE), a framework that enables LLMs to self-evolve in\nsolving diverse tasks, including mathematics, reasoning, and general knowledge\nQ&A. The core design of MAE is based on a triplet of interacting agents\n(Proposer, Solver, Judge) that are instantiated from a single LLM, and applies\nreinforcement learning to optimize their behaviors. The Proposer generates\nquestions, the Solver attempts solutions, and the Judge evaluates both while\nco-evolving. Experiments on Qwen2.5-3B-Instruct demonstrate that MAE achieves\nan average improvement of 4.54% on multiple benchmarks. These results highlight\nMAE as a scalable, data-efficient method for enhancing the general reasoning\nabilities of LLMs with minimal reliance on human-curated supervision.", "AI": {"tldr": "\u63d0\u51fa\u4e86MAE\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u4ea4\u4e92\u667a\u80fd\u4f53\uff08\u63d0\u8bae\u8005\u3001\u6c42\u89e3\u8005\u3001\u8bc4\u5224\u8005\uff09\u5b9e\u73b0LLM\u7684\u81ea\u6211\u8fdb\u5316\uff0c\u5728\u6570\u5b66\u3001\u63a8\u7406\u548c\u5e38\u8bc6\u95ee\u7b54\u7b49\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u548c\u53ef\u9a8c\u8bc1\u5956\u52b1\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u901a\u7528\u6027\u3002\u9700\u8981\u5f00\u53d1\u4e0d\u4f9d\u8d56\u4eba\u5de5\u76d1\u7763\u7684\u81ea\u8fdb\u5316\u65b9\u6cd5\u3002", "method": "MAE\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u57fa\u4e8e\u540c\u4e00LLM\u7684\u667a\u80fd\u4f53\uff1a\u63d0\u8bae\u8005\u751f\u6210\u95ee\u9898\uff0c\u6c42\u89e3\u8005\u5c1d\u8bd5\u89e3\u7b54\uff0c\u8bc4\u5224\u8005\u8bc4\u4f30\u5e76\u5171\u540c\u8fdb\u5316\uff0c\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u884c\u4e3a\u3002", "result": "\u5728Qwen2.5-3B-Instruct\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cMAE\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u63d0\u53474.54%\u3002", "conclusion": "MAE\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u6570\u636e\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u4ee5\u6700\u5c11\u7684\u4eba\u5de5\u76d1\u7763\u663e\u8457\u589e\u5f3aLLM\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.23601", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23601", "abs": "https://arxiv.org/abs/2510.23601", "authors": ["Jiahao Qiu", "Xuan Qi", "Hongru Wang", "Xinzhe Juan", "Yimin Wang", "Zelin Zhao", "Jiayi Geng", "Jiacheng Guo", "Peihang Li", "Jingzhe Shi", "Shilong Liu", "Mengdi Wang"], "title": "Alita-G: Self-Evolving Generative Agent for Agent Generation", "comment": "15 pages, 3 figures", "summary": "Large language models (LLMs) have been shown to perform better when\nscaffolded into agents with memory, tools, and feedback. Beyond this,\nself-evolving agents have emerged, but current work largely limits adaptation\nto prompt rewriting or failure retries. Therefore, we present ALITA-G, a\nself-evolution framework that transforms a general-purpose agent into a domain\nexpert by systematically generating, abstracting, and curating Model Context\nProtocol (MCP) tools. In this framework, a generalist agent executes a curated\nsuite of target-domain tasks and synthesizes candidate MCPs from successful\ntrajectories. These are then abstracted to parameterized primitives and\nconsolidated into an MCP Box. At inference time, ALITA-G performs\nretrieval-augmented MCP selection with the help of each tool's descriptions and\nuse cases, before executing an agent equipped with the MCP Executor. Across\nseveral benchmarks GAIA, PathVQA, and Humanity's Last Exam, ALITA-G attains\nstrong gains while reducing computation costs. On GAIA validation, it achieves\n83.03% pass@1 and 89.09% pass@3, establishing a new state-of-the-art result\nwhile reducing mean tokens per example by approximately 15% relative to a\nstrong baseline agent. ALITA-G thus provides a principled pathway from\ngeneralist capability to reusable, domain-specific competence, improving both\naccuracy and efficiency on complex reasoning tasks.", "AI": {"tldr": "ALITA-G\u662f\u4e00\u4e2a\u81ea\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u751f\u6210\u3001\u62bd\u8c61\u548c\u6574\u7406MCP\u5de5\u5177\uff0c\u5c06\u901a\u7528\u4ee3\u7406\u8f6c\u53d8\u4e3a\u9886\u57df\u4e13\u5bb6\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5f53\u524d\u7684\u81ea\u8fdb\u5316\u4ee3\u7406\u4e3b\u8981\u5c40\u9650\u4e8e\u63d0\u793a\u91cd\u5199\u6216\u5931\u8d25\u91cd\u8bd5\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u80fd\u529b\u8fdb\u5316\u65b9\u6cd5\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5c06\u901a\u7528\u4ee3\u7406\u7cfb\u7edf\u6027\u5730\u8f6c\u53d8\u4e3a\u9886\u57df\u4e13\u5bb6\u7684\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u6267\u884c\u76ee\u6807\u9886\u57df\u4efb\u52a1\uff0c\u4ece\u6210\u529f\u8f68\u8ff9\u4e2d\u5408\u6210\u5019\u9009MCP\u5de5\u5177\uff0c\u5c06\u5176\u62bd\u8c61\u4e3a\u53c2\u6570\u5316\u539f\u8bed\u5e76\u6574\u5408\u5230MCP Box\u4e2d\uff0c\u5728\u63a8\u7406\u65f6\u6267\u884c\u68c0\u7d22\u589e\u5f3a\u7684MCP\u9009\u62e9\u5e76\u4f7f\u7528MCP\u6267\u884c\u5668\u3002", "result": "\u5728GAIA\u9a8c\u8bc1\u96c6\u4e0a\u8fbe\u523083.03% pass@1\u548c89.09% pass@3\u7684\u65b0SOTA\u7ed3\u679c\uff0c\u540c\u65f6\u5c06\u6bcf\u4e2a\u793a\u4f8b\u7684\u5e73\u5747token\u6570\u51cf\u5c11\u7ea615%\u3002", "conclusion": "ALITA-G\u63d0\u4f9b\u4e86\u4ece\u901a\u7528\u80fd\u529b\u5230\u53ef\u91cd\u7528\u9886\u57df\u7279\u5b9a\u80fd\u529b\u7684\u539f\u7406\u6027\u8def\u5f84\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u540c\u65f6\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
